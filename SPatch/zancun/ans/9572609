
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>[V3,2/7] mm: move MADV_FREE pages into LRU_INACTIVE_FILE list - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    [V3,2/7] mm: move MADV_FREE pages into LRU_INACTIVE_FILE list</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=117011">Shaohua Li</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>Feb. 14, 2017, 7:36 p.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;5c38c5f4d91e92ce86ee4f253e49c78708094632.1487100204.git.shli@fb.com&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/9572609/mbox/"
   >mbox</a>
|
   <a href="/patch/9572609/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/9572609/">/patch/9572609/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
	[172.30.200.125])
	by pdx-korg-patchwork.web.codeaurora.org (Postfix) with ESMTP id
	1FAD160573 for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Tue, 14 Feb 2017 19:37:17 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 175E9267EC
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Tue, 14 Feb 2017 19:37:17 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id 0C17E27D16; Tue, 14 Feb 2017 19:37:17 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-7.0 required=2.0 tests=BAYES_00,DKIM_SIGNED,
	DKIM_VALID, DKIM_VALID_AU,
	RCVD_IN_DNSWL_HI autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 00E20267EC
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Tue, 14 Feb 2017 19:37:15 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1754180AbdBNThN (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Tue, 14 Feb 2017 14:37:13 -0500
Received: from mx0a-00082601.pphosted.com ([67.231.145.42]:33718 &quot;EHLO
	mx0a-00082601.pphosted.com&quot; rhost-flags-OK-OK-OK-OK)
	by vger.kernel.org with ESMTP id S1752293AbdBNTgR (ORCPT
	&lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Tue, 14 Feb 2017 14:36:17 -0500
Received: from pps.filterd (m0044010.ppops.net [127.0.0.1])
	by mx0a-00082601.pphosted.com (8.16.0.20/8.16.0.20) with SMTP id
	v1EJYr4T013696
	for &lt;linux-kernel@vger.kernel.org&gt;; Tue, 14 Feb 2017 11:36:16 -0800
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed; d=fb.com;
	h=from : to : cc : subject
	: date : message-id : in-reply-to : references : mime-version :
	content-type; s=facebook;
	bh=M7xYQyQiSn0LdWMAti2YJIPAbaxBIPYaqYFUGzPP0SU=; 
	b=lSde1pxdDDGU5z1vJK4S2VJaSjNVUgher2dveWsrVrpqOfoMb85u5HIwuMRM20joF3iC
	/QL+xsWuKZjCE33a50IMnmotlWbupCHLweiZDVOCg7Oe4OWFpi8aacq5rQfyqDpjj2r/
	1i1x+X3dq2ZxwBW/9RBngTwekKpGHjX4WiU= 
Received: from mail.thefacebook.com ([199.201.64.23])
	by mx0a-00082601.pphosted.com with ESMTP id 28m6rbgent-2
	(version=TLSv1 cipher=ECDHE-RSA-AES256-SHA bits=256 verify=NOT)
	for &lt;linux-kernel@vger.kernel.org&gt;; Tue, 14 Feb 2017 11:36:16 -0800
Received: from mx-out.facebook.com (192.168.52.123) by
	PRN-CHUB14.TheFacebook.com (192.168.16.24) with Microsoft SMTP Server
	(TLS) id 14.3.294.0; Tue, 14 Feb 2017 11:36:15 -0800
Received: from facebook.com (2401:db00:21:603d:face:0:19:0)     by
	mx-out.facebook.com (10.223.100.97) with ESMTP id
	d896eaf6f2ec11e6938a24be0593f280-8d5fca00 for
	&lt;linux-kernel@vger.kernel.org&gt;; Tue, 14 Feb 2017 11:36:14 -0800
Received: by devbig638.prn2.facebook.com (Postfix, from userid 11222)   id
	279F046A163B; Tue, 14 Feb 2017 11:36:13 -0800 (PST)
Smtp-Origin-Hostprefix: devbig
From: Shaohua Li &lt;shli@fb.com&gt;
Smtp-Origin-Hostname: devbig638.prn2.facebook.com
To: &lt;linux-mm@kvack.org&gt;, &lt;linux-kernel@vger.kernel.org&gt;
CC: &lt;Kernel-team@fb.com&gt;, &lt;mhocko@suse.com&gt;, &lt;minchan@kernel.org&gt;,
	&lt;hughd@google.com&gt;, &lt;hannes@cmpxchg.org&gt;, &lt;riel@redhat.com&gt;,
	&lt;mgorman@techsingularity.net&gt;, &lt;akpm@linux-foundation.org&gt;
Smtp-Origin-Cluster: prn2c22
Subject: [PATCH V3 2/7] mm: move MADV_FREE pages into LRU_INACTIVE_FILE list
Date: Tue, 14 Feb 2017 11:36:08 -0800
Message-ID: &lt;5c38c5f4d91e92ce86ee4f253e49c78708094632.1487100204.git.shli@fb.com&gt;
X-Mailer: git-send-email 2.9.3
In-Reply-To: &lt;cover.1487100204.git.shli@fb.com&gt;
References: &lt;cover.1487100204.git.shli@fb.com&gt;
X-FB-Internal: Safe
MIME-Version: 1.0
Content-Type: text/plain
X-Proofpoint-Spam-Reason: safe
X-FB-Internal: Safe
X-Proofpoint-Virus-Version: vendor=fsecure engine=2.50.10432:, ,
	definitions=2017-02-14_12:, , signatures=0
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=117011">Shaohua Li</a> - Feb. 14, 2017, 7:36 p.m.</div>
<pre class="content">
madv MADV_FREE indicate pages are &#39;lazyfree&#39;. They are still anonymous
pages, but they can be freed without pageout. To destinguish them
against normal anonymous pages, we clear their SwapBacked flag.

MADV_FREE pages could be freed without pageout, so they pretty much like
used once file pages. For such pages, we&#39;d like to reclaim them once
there is memory pressure. Also it might be unfair reclaiming MADV_FREE
pages always before used once file pages and we definitively want to
reclaim the pages before other anonymous and file pages.

To speed up MADV_FREE pages reclaim, we put the pages into
LRU_INACTIVE_FILE list. The rationale is LRU_INACTIVE_FILE list is tiny
nowadays and should be full of used once file pages. Reclaiming
MADV_FREE pages will not have much interfere of anonymous and active
file pages. And the inactive file pages and MADV_FREE pages will be
reclaimed according to their age, so we don&#39;t reclaim too many MADV_FREE
pages too. Putting the MADV_FREE pages into LRU_INACTIVE_FILE_LIST also
means we can reclaim the pages without swap support. This idea is
suggested by Johannes.

This patch doesn&#39;t move MADV_FREE pages to LRU_INACTIVE_FILE list yet to
avoid bisect failure, next patch will do it.

The patch is based on Minchan&#39;s original patch.

Cc: Michal Hocko &lt;mhocko@suse.com&gt;
Cc: Minchan Kim &lt;minchan@kernel.org&gt;
Cc: Hugh Dickins &lt;hughd@google.com&gt;
Cc: Rik van Riel &lt;riel@redhat.com&gt;
Cc: Mel Gorman &lt;mgorman@techsingularity.net&gt;
Cc: Andrew Morton &lt;akpm@linux-foundation.org&gt;
Suggested-by: Johannes Weiner &lt;hannes@cmpxchg.org&gt;
<span class="signed-off-by">Signed-off-by: Shaohua Li &lt;shli@fb.com&gt;</span>
---
 include/linux/mm_inline.h     | 20 +++++++++++++++++
 include/linux/swap.h          |  2 +-
 include/linux/vm_event_item.h |  2 +-
 mm/huge_memory.c              |  3 ---
 mm/madvise.c                  |  2 --
 mm/swap.c                     | 51 ++++++++++++++++++++++++-------------------
 mm/vmstat.c                   |  1 +
 7 files changed, 52 insertions(+), 29 deletions(-)
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=45">Johannes Weiner</a> - Feb. 16, 2017, 5:52 p.m.</div>
<pre class="content">
On Tue, Feb 14, 2017 at 11:36:08AM -0800, Shaohua Li wrote:
<span class="quote">&gt; @@ -126,4 +126,24 @@ static __always_inline enum lru_list page_lru(struct page *page)</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  #define lru_to_page(head) (list_entry((head)-&gt;prev, struct page, lru))</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; +/*</span>
<span class="quote">&gt; + * lazyfree pages are clean anonymous pages. They have SwapBacked flag cleared</span>
<span class="quote">&gt; + * to destinguish normal anonymous pages.</span>
<span class="quote">&gt; + */</span>
<span class="quote">&gt; +static inline void set_page_lazyfree(struct page *page)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	VM_BUG_ON_PAGE(!PageAnon(page) || !PageSwapBacked(page), page);</span>
<span class="quote">&gt; +	ClearPageSwapBacked(page);</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +static inline void clear_page_lazyfree(struct page *page)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	VM_BUG_ON_PAGE(!PageAnon(page) || PageSwapBacked(page), page);</span>
<span class="quote">&gt; +	SetPageSwapBacked(page);</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +static inline bool page_is_lazyfree(struct page *page)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	return PageAnon(page) &amp;&amp; !PageSwapBacked(page);</span>
<span class="quote">&gt; +}</span>

Sorry for not getting to v2 in time, but I have to say I strongly
agree with your first iterations and would much prefer this to be
open-coded.

IMO this needlessly introduces a new state opaquely called &quot;lazyfree&quot;,
when really that&#39;s just anonymous pages that don&#39;t need to be swapped
before reclaim - PageAnon &amp;&amp; !PageSwapBacked. Very simple MM concept.

That especially shows when we later combine it with page_is_file_cache
checks like the next patch does.

The rest of the patch looks good to me.
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=117011">Shaohua Li</a> - Feb. 17, 2017, 12:35 a.m.</div>
<pre class="content">
On Thu, Feb 16, 2017 at 12:52:53PM -0500, Johannes Weiner wrote:
<span class="quote">&gt; On Tue, Feb 14, 2017 at 11:36:08AM -0800, Shaohua Li wrote:</span>
<span class="quote">&gt; &gt; @@ -126,4 +126,24 @@ static __always_inline enum lru_list page_lru(struct page *page)</span>
<span class="quote">&gt; &gt;  </span>
<span class="quote">&gt; &gt;  #define lru_to_page(head) (list_entry((head)-&gt;prev, struct page, lru))</span>
<span class="quote">&gt; &gt;  </span>
<span class="quote">&gt; &gt; +/*</span>
<span class="quote">&gt; &gt; + * lazyfree pages are clean anonymous pages. They have SwapBacked flag cleared</span>
<span class="quote">&gt; &gt; + * to destinguish normal anonymous pages.</span>
<span class="quote">&gt; &gt; + */</span>
<span class="quote">&gt; &gt; +static inline void set_page_lazyfree(struct page *page)</span>
<span class="quote">&gt; &gt; +{</span>
<span class="quote">&gt; &gt; +	VM_BUG_ON_PAGE(!PageAnon(page) || !PageSwapBacked(page), page);</span>
<span class="quote">&gt; &gt; +	ClearPageSwapBacked(page);</span>
<span class="quote">&gt; &gt; +}</span>
<span class="quote">&gt; &gt; +</span>
<span class="quote">&gt; &gt; +static inline void clear_page_lazyfree(struct page *page)</span>
<span class="quote">&gt; &gt; +{</span>
<span class="quote">&gt; &gt; +	VM_BUG_ON_PAGE(!PageAnon(page) || PageSwapBacked(page), page);</span>
<span class="quote">&gt; &gt; +	SetPageSwapBacked(page);</span>
<span class="quote">&gt; &gt; +}</span>
<span class="quote">&gt; &gt; +</span>
<span class="quote">&gt; &gt; +static inline bool page_is_lazyfree(struct page *page)</span>
<span class="quote">&gt; &gt; +{</span>
<span class="quote">&gt; &gt; +	return PageAnon(page) &amp;&amp; !PageSwapBacked(page);</span>
<span class="quote">&gt; &gt; +}</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Sorry for not getting to v2 in time, but I have to say I strongly</span>
<span class="quote">&gt; agree with your first iterations and would much prefer this to be</span>
<span class="quote">&gt; open-coded.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; IMO this needlessly introduces a new state opaquely called &quot;lazyfree&quot;,</span>
<span class="quote">&gt; when really that&#39;s just anonymous pages that don&#39;t need to be swapped</span>
<span class="quote">&gt; before reclaim - PageAnon &amp;&amp; !PageSwapBacked. Very simple MM concept.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; That especially shows when we later combine it with page_is_file_cache</span>
<span class="quote">&gt; checks like the next patch does.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; The rest of the patch looks good to me.</span>

Thanks! I do agree checking PageSwapBacked is clearer, but Minchan convinced me
because of the accounting issue. Where do you suggest we should put the
accounting to?

Thanks,
Shaohua
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=45">Johannes Weiner</a> - Feb. 17, 2017, 4:22 p.m.</div>
<pre class="content">
On Thu, Feb 16, 2017 at 04:35:25PM -0800, Shaohua Li wrote:
<span class="quote">&gt; On Thu, Feb 16, 2017 at 12:52:53PM -0500, Johannes Weiner wrote:</span>
<span class="quote">&gt; &gt; On Tue, Feb 14, 2017 at 11:36:08AM -0800, Shaohua Li wrote:</span>
<span class="quote">&gt; &gt; &gt; @@ -126,4 +126,24 @@ static __always_inline enum lru_list page_lru(struct page *page)</span>
<span class="quote">&gt; &gt; &gt;  </span>
<span class="quote">&gt; &gt; &gt;  #define lru_to_page(head) (list_entry((head)-&gt;prev, struct page, lru))</span>
<span class="quote">&gt; &gt; &gt;  </span>
<span class="quote">&gt; &gt; &gt; +/*</span>
<span class="quote">&gt; &gt; &gt; + * lazyfree pages are clean anonymous pages. They have SwapBacked flag cleared</span>
<span class="quote">&gt; &gt; &gt; + * to destinguish normal anonymous pages.</span>
<span class="quote">&gt; &gt; &gt; + */</span>
<span class="quote">&gt; &gt; &gt; +static inline void set_page_lazyfree(struct page *page)</span>
<span class="quote">&gt; &gt; &gt; +{</span>
<span class="quote">&gt; &gt; &gt; +	VM_BUG_ON_PAGE(!PageAnon(page) || !PageSwapBacked(page), page);</span>
<span class="quote">&gt; &gt; &gt; +	ClearPageSwapBacked(page);</span>
<span class="quote">&gt; &gt; &gt; +}</span>
<span class="quote">&gt; &gt; &gt; +</span>
<span class="quote">&gt; &gt; &gt; +static inline void clear_page_lazyfree(struct page *page)</span>
<span class="quote">&gt; &gt; &gt; +{</span>
<span class="quote">&gt; &gt; &gt; +	VM_BUG_ON_PAGE(!PageAnon(page) || PageSwapBacked(page), page);</span>
<span class="quote">&gt; &gt; &gt; +	SetPageSwapBacked(page);</span>
<span class="quote">&gt; &gt; &gt; +}</span>
<span class="quote">&gt; &gt; &gt; +</span>
<span class="quote">&gt; &gt; &gt; +static inline bool page_is_lazyfree(struct page *page)</span>
<span class="quote">&gt; &gt; &gt; +{</span>
<span class="quote">&gt; &gt; &gt; +	return PageAnon(page) &amp;&amp; !PageSwapBacked(page);</span>
<span class="quote">&gt; &gt; &gt; +}</span>
<span class="quote">&gt; &gt; </span>
<span class="quote">&gt; &gt; Sorry for not getting to v2 in time, but I have to say I strongly</span>
<span class="quote">&gt; &gt; agree with your first iterations and would much prefer this to be</span>
<span class="quote">&gt; &gt; open-coded.</span>
<span class="quote">&gt; &gt; </span>
<span class="quote">&gt; &gt; IMO this needlessly introduces a new state opaquely called &quot;lazyfree&quot;,</span>
<span class="quote">&gt; &gt; when really that&#39;s just anonymous pages that don&#39;t need to be swapped</span>
<span class="quote">&gt; &gt; before reclaim - PageAnon &amp;&amp; !PageSwapBacked. Very simple MM concept.</span>
<span class="quote">&gt; &gt; </span>
<span class="quote">&gt; &gt; That especially shows when we later combine it with page_is_file_cache</span>
<span class="quote">&gt; &gt; checks like the next patch does.</span>
<span class="quote">&gt; &gt; </span>
<span class="quote">&gt; &gt; The rest of the patch looks good to me.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Thanks! I do agree checking PageSwapBacked is clearer, but Minchan convinced me</span>
<span class="quote">&gt; because of the accounting issue. Where do you suggest we should put the</span>
<span class="quote">&gt; accounting to?</span>

I now proposed quite a few changes to the setting and clearing sites,
so it&#39;s harder to judge, but AFAICT once those sites are consolidated,
open-coding the stat updates as well shouldn&#39;t be too bad, right?

One site to clear during MADV_FREE, one site to set during reclaim.
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/include/linux/mm_inline.h b/include/linux/mm_inline.h</span>
<span class="p_header">index e030a68..e6e3af1 100644</span>
<span class="p_header">--- a/include/linux/mm_inline.h</span>
<span class="p_header">+++ b/include/linux/mm_inline.h</span>
<span class="p_chunk">@@ -126,4 +126,24 @@</span> <span class="p_context"> static __always_inline enum lru_list page_lru(struct page *page)</span>
 
 #define lru_to_page(head) (list_entry((head)-&gt;prev, struct page, lru))
 
<span class="p_add">+/*</span>
<span class="p_add">+ * lazyfree pages are clean anonymous pages. They have SwapBacked flag cleared</span>
<span class="p_add">+ * to destinguish normal anonymous pages.</span>
<span class="p_add">+ */</span>
<span class="p_add">+static inline void set_page_lazyfree(struct page *page)</span>
<span class="p_add">+{</span>
<span class="p_add">+	VM_BUG_ON_PAGE(!PageAnon(page) || !PageSwapBacked(page), page);</span>
<span class="p_add">+	ClearPageSwapBacked(page);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline void clear_page_lazyfree(struct page *page)</span>
<span class="p_add">+{</span>
<span class="p_add">+	VM_BUG_ON_PAGE(!PageAnon(page) || PageSwapBacked(page), page);</span>
<span class="p_add">+	SetPageSwapBacked(page);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline bool page_is_lazyfree(struct page *page)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return PageAnon(page) &amp;&amp; !PageSwapBacked(page);</span>
<span class="p_add">+}</span>
 #endif
<span class="p_header">diff --git a/include/linux/swap.h b/include/linux/swap.h</span>
<span class="p_header">index 45e91dd..486494e 100644</span>
<span class="p_header">--- a/include/linux/swap.h</span>
<span class="p_header">+++ b/include/linux/swap.h</span>
<span class="p_chunk">@@ -279,7 +279,7 @@</span> <span class="p_context"> extern void lru_add_drain_cpu(int cpu);</span>
 extern void lru_add_drain_all(void);
 extern void rotate_reclaimable_page(struct page *page);
 extern void deactivate_file_page(struct page *page);
<span class="p_del">-extern void deactivate_page(struct page *page);</span>
<span class="p_add">+extern void mark_page_lazyfree(struct page *page);</span>
 extern void swap_setup(void);
 
 extern void add_page_to_unevictable_list(struct page *page);
<span class="p_header">diff --git a/include/linux/vm_event_item.h b/include/linux/vm_event_item.h</span>
<span class="p_header">index 6aa1b6c..94e58da 100644</span>
<span class="p_header">--- a/include/linux/vm_event_item.h</span>
<span class="p_header">+++ b/include/linux/vm_event_item.h</span>
<span class="p_chunk">@@ -25,7 +25,7 @@</span> <span class="p_context"> enum vm_event_item { PGPGIN, PGPGOUT, PSWPIN, PSWPOUT,</span>
 		FOR_ALL_ZONES(PGALLOC),
 		FOR_ALL_ZONES(ALLOCSTALL),
 		FOR_ALL_ZONES(PGSCAN_SKIP),
<span class="p_del">-		PGFREE, PGACTIVATE, PGDEACTIVATE,</span>
<span class="p_add">+		PGFREE, PGACTIVATE, PGDEACTIVATE, PGLAZYFREE,</span>
 		PGFAULT, PGMAJFAULT,
 		PGLAZYFREED,
 		PGREFILL,
<span class="p_header">diff --git a/mm/huge_memory.c b/mm/huge_memory.c</span>
<span class="p_header">index e602265..4ddda58 100644</span>
<span class="p_header">--- a/mm/huge_memory.c</span>
<span class="p_header">+++ b/mm/huge_memory.c</span>
<span class="p_chunk">@@ -1562,9 +1562,6 @@</span> <span class="p_context"> bool madvise_free_huge_pmd(struct mmu_gather *tlb, struct vm_area_struct *vma,</span>
 		ClearPageDirty(page);
 	unlock_page(page);
 
<span class="p_del">-	if (PageActive(page))</span>
<span class="p_del">-		deactivate_page(page);</span>
<span class="p_del">-</span>
 	if (pmd_young(orig_pmd) || pmd_dirty(orig_pmd)) {
 		orig_pmd = pmdp_huge_get_and_clear_full(tlb-&gt;mm, addr, pmd,
 			tlb-&gt;fullmm);
<span class="p_header">diff --git a/mm/madvise.c b/mm/madvise.c</span>
<span class="p_header">index 11fc65f..639c476 100644</span>
<span class="p_header">--- a/mm/madvise.c</span>
<span class="p_header">+++ b/mm/madvise.c</span>
<span class="p_chunk">@@ -410,8 +410,6 @@</span> <span class="p_context"> static int madvise_free_pte_range(pmd_t *pmd, unsigned long addr,</span>
 			ptent = pte_mkold(ptent);
 			ptent = pte_mkclean(ptent);
 			set_pte_at(mm, addr, pte, ptent);
<span class="p_del">-			if (PageActive(page))</span>
<span class="p_del">-				deactivate_page(page);</span>
 			tlb_remove_tlb_entry(tlb, pte, addr);
 		}
 	}
<span class="p_header">diff --git a/mm/swap.c b/mm/swap.c</span>
<span class="p_header">index c4910f1..9305c23 100644</span>
<span class="p_header">--- a/mm/swap.c</span>
<span class="p_header">+++ b/mm/swap.c</span>
<span class="p_chunk">@@ -46,7 +46,7 @@</span> <span class="p_context"> int page_cluster;</span>
 static DEFINE_PER_CPU(struct pagevec, lru_add_pvec);
 static DEFINE_PER_CPU(struct pagevec, lru_rotate_pvecs);
 static DEFINE_PER_CPU(struct pagevec, lru_deactivate_file_pvecs);
<span class="p_del">-static DEFINE_PER_CPU(struct pagevec, lru_deactivate_pvecs);</span>
<span class="p_add">+static DEFINE_PER_CPU(struct pagevec, lru_lazyfree_pvecs);</span>
 #ifdef CONFIG_SMP
 static DEFINE_PER_CPU(struct pagevec, activate_page_pvecs);
 #endif
<span class="p_chunk">@@ -268,6 +268,12 @@</span> <span class="p_context"> static void __activate_page(struct page *page, struct lruvec *lruvec,</span>
 		int lru = page_lru_base_type(page);
 
 		del_page_from_lru_list(page, lruvec, lru);
<span class="p_add">+		if (page_is_lazyfree(page)) {</span>
<span class="p_add">+			clear_page_lazyfree(page);</span>
<span class="p_add">+			/* charge to anon scanned/rotated reclaim_stat */</span>
<span class="p_add">+			file = 0;</span>
<span class="p_add">+			lru = LRU_INACTIVE_ANON;</span>
<span class="p_add">+		}</span>
 		SetPageActive(page);
 		lru += LRU_ACTIVE;
 		add_page_to_lru_list(page, lruvec, lru);
<span class="p_chunk">@@ -561,20 +567,21 @@</span> <span class="p_context"> static void lru_deactivate_file_fn(struct page *page, struct lruvec *lruvec,</span>
 }
 
 
<span class="p_del">-static void lru_deactivate_fn(struct page *page, struct lruvec *lruvec,</span>
<span class="p_add">+static void lru_lazyfree_fn(struct page *page, struct lruvec *lruvec,</span>
 			    void *arg)
 {
<span class="p_del">-	if (PageLRU(page) &amp;&amp; PageActive(page) &amp;&amp; !PageUnevictable(page)) {</span>
<span class="p_del">-		int file = page_is_file_cache(page);</span>
<span class="p_del">-		int lru = page_lru_base_type(page);</span>
<span class="p_add">+	if (PageLRU(page) &amp;&amp; PageAnon(page) &amp;&amp; PageSwapBacked(page) &amp;&amp;</span>
<span class="p_add">+	    !PageUnevictable(page)) {</span>
<span class="p_add">+		bool active = PageActive(page);</span>
 
<span class="p_del">-		del_page_from_lru_list(page, lruvec, lru + LRU_ACTIVE);</span>
<span class="p_add">+		del_page_from_lru_list(page, lruvec, LRU_INACTIVE_ANON + active);</span>
 		ClearPageActive(page);
 		ClearPageReferenced(page);
<span class="p_del">-		add_page_to_lru_list(page, lruvec, lru);</span>
<span class="p_add">+		set_page_lazyfree(page);</span>
<span class="p_add">+		add_page_to_lru_list(page, lruvec, LRU_INACTIVE_FILE);</span>
 
<span class="p_del">-		__count_vm_event(PGDEACTIVATE);</span>
<span class="p_del">-		update_page_reclaim_stat(lruvec, file, 0);</span>
<span class="p_add">+		__count_vm_events(PGLAZYFREE, hpage_nr_pages(page));</span>
<span class="p_add">+		update_page_reclaim_stat(lruvec, 1, 0);</span>
 	}
 }
 
<span class="p_chunk">@@ -604,9 +611,9 @@</span> <span class="p_context"> void lru_add_drain_cpu(int cpu)</span>
 	if (pagevec_count(pvec))
 		pagevec_lru_move_fn(pvec, lru_deactivate_file_fn, NULL);
 
<span class="p_del">-	pvec = &amp;per_cpu(lru_deactivate_pvecs, cpu);</span>
<span class="p_add">+	pvec = &amp;per_cpu(lru_lazyfree_pvecs, cpu);</span>
 	if (pagevec_count(pvec))
<span class="p_del">-		pagevec_lru_move_fn(pvec, lru_deactivate_fn, NULL);</span>
<span class="p_add">+		pagevec_lru_move_fn(pvec, lru_lazyfree_fn, NULL);</span>
 
 	activate_page_drain(cpu);
 }
<span class="p_chunk">@@ -638,22 +645,22 @@</span> <span class="p_context"> void deactivate_file_page(struct page *page)</span>
 }
 
 /**
<span class="p_del">- * deactivate_page - deactivate a page</span>
<span class="p_add">+ * mark_page_lazyfree - make an anon page lazyfree</span>
  * @page: page to deactivate
  *
<span class="p_del">- * deactivate_page() moves @page to the inactive list if @page was on the active</span>
<span class="p_del">- * list and was not an unevictable page.  This is done to accelerate the reclaim</span>
<span class="p_del">- * of @page.</span>
<span class="p_add">+ * mark_page_lazyfree() moves @page to the inactive file list.</span>
<span class="p_add">+ * This is done to accelerate the reclaim of @page.</span>
  */
<span class="p_del">-void deactivate_page(struct page *page)</span>
<span class="p_del">-{</span>
<span class="p_del">-	if (PageLRU(page) &amp;&amp; PageActive(page) &amp;&amp; !PageUnevictable(page)) {</span>
<span class="p_del">-		struct pagevec *pvec = &amp;get_cpu_var(lru_deactivate_pvecs);</span>
<span class="p_add">+void mark_page_lazyfree(struct page *page)</span>
<span class="p_add">+ {</span>
<span class="p_add">+	if (PageLRU(page) &amp;&amp; PageAnon(page) &amp;&amp; PageSwapBacked(page) &amp;&amp;</span>
<span class="p_add">+	    !PageUnevictable(page)) {</span>
<span class="p_add">+		struct pagevec *pvec = &amp;get_cpu_var(lru_lazyfree_pvecs);</span>
 
 		get_page(page);
 		if (!pagevec_add(pvec, page) || PageCompound(page))
<span class="p_del">-			pagevec_lru_move_fn(pvec, lru_deactivate_fn, NULL);</span>
<span class="p_del">-		put_cpu_var(lru_deactivate_pvecs);</span>
<span class="p_add">+			pagevec_lru_move_fn(pvec, lru_lazyfree_fn, NULL);</span>
<span class="p_add">+		put_cpu_var(lru_lazyfree_pvecs);</span>
 	}
 }
 
<span class="p_chunk">@@ -704,7 +711,7 @@</span> <span class="p_context"> void lru_add_drain_all(void)</span>
 		if (pagevec_count(&amp;per_cpu(lru_add_pvec, cpu)) ||
 		    pagevec_count(&amp;per_cpu(lru_rotate_pvecs, cpu)) ||
 		    pagevec_count(&amp;per_cpu(lru_deactivate_file_pvecs, cpu)) ||
<span class="p_del">-		    pagevec_count(&amp;per_cpu(lru_deactivate_pvecs, cpu)) ||</span>
<span class="p_add">+		    pagevec_count(&amp;per_cpu(lru_lazyfree_pvecs, cpu)) ||</span>
 		    need_activate_page_drain(cpu)) {
 			INIT_WORK(work, lru_add_drain_per_cpu);
 			queue_work_on(cpu, lru_add_drain_wq, work);
<span class="p_header">diff --git a/mm/vmstat.c b/mm/vmstat.c</span>
<span class="p_header">index 69f9aff..7774196 100644</span>
<span class="p_header">--- a/mm/vmstat.c</span>
<span class="p_header">+++ b/mm/vmstat.c</span>
<span class="p_chunk">@@ -992,6 +992,7 @@</span> <span class="p_context"> const char * const vmstat_text[] = {</span>
 	&quot;pgfree&quot;,
 	&quot;pgactivate&quot;,
 	&quot;pgdeactivate&quot;,
<span class="p_add">+	&quot;pglazyfree&quot;,</span>
 
 	&quot;pgfault&quot;,
 	&quot;pgmajfault&quot;,

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



