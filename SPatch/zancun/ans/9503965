
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>[RFC,35/55] KVM: arm/arm64: Support mmu for the virtual EL2 execution - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    [RFC,35/55] KVM: arm/arm64: Support mmu for the virtual EL2 execution</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=171407">Jintack Lim</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>Jan. 9, 2017, 6:24 a.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;1483943091-1364-36-git-send-email-jintack@cs.columbia.edu&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/9503965/mbox/"
   >mbox</a>
|
   <a href="/patch/9503965/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/9503965/">/patch/9503965/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
	[172.30.200.125])
	by pdx-korg-patchwork.web.codeaurora.org (Postfix) with ESMTP id
	59DE260757 for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Mon,  9 Jan 2017 06:34:02 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 48CF3280D0
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Mon,  9 Jan 2017 06:34:02 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id 3D4C8281D2; Mon,  9 Jan 2017 06:34:02 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-6.4 required=2.0 tests=BAYES_00, RCVD_IN_DNSWL_HI, 
	RCVD_IN_SORBS_SPAM autolearn=unavailable version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 2E5CD2811C
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Mon,  9 Jan 2017 06:34:01 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1033986AbdAIGdv (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Mon, 9 Jan 2017 01:33:51 -0500
Received: from outprodmail02.cc.columbia.edu ([128.59.72.51]:52253 &quot;EHLO
	outprodmail02.cc.columbia.edu&quot; rhost-flags-OK-OK-OK-OK)
	by vger.kernel.org with ESMTP id S939751AbdAIG0W (ORCPT
	&lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Mon, 9 Jan 2017 01:26:22 -0500
Received: from hazelnut (hazelnut.cc.columbia.edu [128.59.213.250])
	by outprodmail02.cc.columbia.edu (8.14.4/8.14.4) with ESMTP id
	v096Q5h4006221
	for &lt;linux-kernel@vger.kernel.org&gt;; Mon, 9 Jan 2017 01:26:18 -0500
Received: from hazelnut (localhost.localdomain [127.0.0.1])
	by hazelnut (Postfix) with ESMTP id 3735084
	for &lt;linux-kernel@vger.kernel.org&gt;;
	Mon,  9 Jan 2017 01:26:18 -0500 (EST)
Received: from sendprodmail04.cc.columbia.edu
	(sendprodmail04.cc.columbia.edu [128.59.72.16])
	by hazelnut (Postfix) with ESMTP id 1C3577E
	for &lt;linux-kernel@vger.kernel.org&gt;;
	Mon,  9 Jan 2017 01:26:18 -0500 (EST)
Received: from mail-qt0-f199.google.com (mail-qt0-f199.google.com
	[209.85.216.199])
	by sendprodmail04.cc.columbia.edu (8.14.4/8.14.4) with ESMTP id
	v096QHo3005431
	(version=TLSv1/SSLv3 cipher=AES128-GCM-SHA256 bits=128 verify=NOT)
	for &lt;linux-kernel@vger.kernel.org&gt;; Mon, 9 Jan 2017 01:26:18 -0500
Received: by mail-qt0-f199.google.com with SMTP id k15so94308586qtg.5
	for &lt;linux-kernel@vger.kernel.org&gt;;
	Sun, 08 Jan 2017 22:26:17 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
	d=1e100.net; s=20161025;
	h=x-gm-message-state:from:to:cc:subject:date:message-id:in-reply-to
	:references;
	bh=6vz2ju2snh66VzVGTG4Gz29if7I34CwnWPmUjCHLgDk=;
	b=s3qRwmwYvC64mc/2aFw79MnHhtxrwAQHjOEAIe16dC3RCeAY0tm5AJTzrmMALIu4AX
	Ujxmj5Plb0QlonJeoH7LA7P7g0LB5CBKSstbBWGi+5wXrBEfiazpH4/mAOAT21PbWn7a
	88R7N5pAmEzjza0tF5LJr1tg6Ot7u/o47xwiqL5OMKmb9QIxEzxEeJZAQcwNyw/wQssO
	yrvXITCT6/kMThmSia4YcTM6HhanUsIWRk913FuzxU4eNfEg5e1dY9MPvsEh0uPRBSqU
	jZ0oqDZgMLOtLXL3FMWv5sUF/eWsOqvjFz59CzpX0DZz57YcbfJY6A2csDJWbjCKqozC
	NCAg==
X-Gm-Message-State: AIkVDXK4jCVwG0/AfnD571ZPG8Op41fbqegWVchRzpBE8TCyagjDzP9+DJio8oj9Xqe+8lP5VE1cD4gUfdVkLVDyw8duADLTc1poQ32MsYw6FcD2Je2HFcI5/u7aw9gtpYULIz2QarL6obGK9QKHTaKd0MQ=
X-Received: by 10.55.176.194 with SMTP id z185mr1489417qke.26.1483943177056; 
	Sun, 08 Jan 2017 22:26:17 -0800 (PST)
X-Received: by 10.55.176.194 with SMTP id z185mr1489377qke.26.1483943176712; 
	Sun, 08 Jan 2017 22:26:16 -0800 (PST)
Received: from jintack.cs.columbia.edu
	([2001:18d8:ffff:16:21a:4aff:feaa:f900])
	by smtp.gmail.com with ESMTPSA id
	h3sm8623257qtc.6.2017.01.08.22.26.15
	(version=TLS1_2 cipher=ECDHE-RSA-AES128-SHA bits=128/128);
	Sun, 08 Jan 2017 22:26:16 -0800 (PST)
From: Jintack Lim &lt;jintack@cs.columbia.edu&gt;
To: christoffer.dall@linaro.org, marc.zyngier@arm.com,
	pbonzini@redhat.com, rkrcmar@redhat.com, linux@armlinux.org.uk,
	catalin.marinas@arm.com, will.deacon@arm.com,
	vladimir.murzin@arm.com, suzuki.poulose@arm.com,
	mark.rutland@arm.com, james.morse@arm.com,
	lorenzo.pieralisi@arm.com, kevin.brodsky@arm.com,
	wcohen@redhat.com, shankerd@codeaurora.org, geoff@infradead.org,
	andre.przywara@arm.com, eric.auger@redhat.com,
	anna-maria@linutronix.de, shihwei@cs.columbia.edu,
	linux-arm-kernel@lists.infradead.org, kvmarm@lists.cs.columbia.edu,
	kvm@vger.kernel.org, linux-kernel@vger.kernel.org
Cc: jintack@cs.columbia.edu
Subject: [RFC 35/55] KVM: arm/arm64: Support mmu for the virtual EL2
	execution
Date: Mon,  9 Jan 2017 01:24:31 -0500
Message-Id: &lt;1483943091-1364-36-git-send-email-jintack@cs.columbia.edu&gt;
X-Mailer: git-send-email 1.9.1
In-Reply-To: &lt;1483943091-1364-1-git-send-email-jintack@cs.columbia.edu&gt;
References: &lt;1483943091-1364-1-git-send-email-jintack@cs.columbia.edu&gt;
X-No-Spam-Score: Local
X-Scanned-By: MIMEDefang 2.78 on 128.59.72.16
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=171407">Jintack Lim</a> - Jan. 9, 2017, 6:24 a.m.</div>
<pre class="content">
<span class="from">From: Christoffer Dall &lt;christoffer.dall@linaro.org&gt;</span>

When running a guest hypervisor in virtual EL2, the translation context
has to be separate from the rest of the system, including the guest
EL1/0 translation regime, so we allocate a separate VMID for this mode.

Considering that we have two different vttbr values due to separate
VMIDs, it&#39;s racy to keep a vttbr value in a struct (kvm_s2_mmu) and
share it between multiple vcpus. So, keep the vttbr value per vcpu.

Hypercalls to flush tlb now have vttbr as a parameter instead of mmu,
since mmu structure does not have vttbr any more.
<span class="signed-off-by">
Signed-off-by: Christoffer Dall &lt;christoffer.dall@linaro.org&gt;</span>
<span class="signed-off-by">Signed-off-by: Jintack Lim &lt;jintack@cs.columbia.edu&gt;</span>
---
 arch/arm/include/asm/kvm_asm.h       |  6 ++--
 arch/arm/include/asm/kvm_emulate.h   |  4 +++
 arch/arm/include/asm/kvm_host.h      | 14 ++++++---
 arch/arm/include/asm/kvm_mmu.h       | 11 +++++++
 arch/arm/kvm/arm.c                   | 60 +++++++++++++++++++-----------------
 arch/arm/kvm/hyp/switch.c            |  4 +--
 arch/arm/kvm/hyp/tlb.c               | 15 ++++-----
 arch/arm/kvm/mmu.c                   |  9 ++++--
 arch/arm64/include/asm/kvm_asm.h     |  6 ++--
 arch/arm64/include/asm/kvm_emulate.h |  8 +++++
 arch/arm64/include/asm/kvm_host.h    | 14 ++++++---
 arch/arm64/include/asm/kvm_mmu.h     | 11 +++++++
 arch/arm64/kvm/hyp/switch.c          |  4 +--
 arch/arm64/kvm/hyp/tlb.c             | 16 ++++------
 14 files changed, 112 insertions(+), 70 deletions(-)
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=172427">Christoffer Dall</a> - Feb. 22, 2017, 1:38 p.m.</div>
<pre class="content">
On Mon, Jan 09, 2017 at 01:24:31AM -0500, Jintack Lim wrote:
<span class="quote">&gt; From: Christoffer Dall &lt;christoffer.dall@linaro.org&gt;</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; When running a guest hypervisor in virtual EL2, the translation context</span>
<span class="quote">&gt; has to be separate from the rest of the system, including the guest</span>
<span class="quote">&gt; EL1/0 translation regime, so we allocate a separate VMID for this mode.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Considering that we have two different vttbr values due to separate</span>
<span class="quote">&gt; VMIDs, it&#39;s racy to keep a vttbr value in a struct (kvm_s2_mmu) and</span>
<span class="quote">&gt; share it between multiple vcpus. So, keep the vttbr value per vcpu.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Hypercalls to flush tlb now have vttbr as a parameter instead of mmu,</span>
<span class="quote">&gt; since mmu structure does not have vttbr any more.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Signed-off-by: Christoffer Dall &lt;christoffer.dall@linaro.org&gt;</span>
<span class="quote">&gt; Signed-off-by: Jintack Lim &lt;jintack@cs.columbia.edu&gt;</span>
<span class="quote">&gt; ---</span>
<span class="quote">&gt;  arch/arm/include/asm/kvm_asm.h       |  6 ++--</span>
<span class="quote">&gt;  arch/arm/include/asm/kvm_emulate.h   |  4 +++</span>
<span class="quote">&gt;  arch/arm/include/asm/kvm_host.h      | 14 ++++++---</span>
<span class="quote">&gt;  arch/arm/include/asm/kvm_mmu.h       | 11 +++++++</span>
<span class="quote">&gt;  arch/arm/kvm/arm.c                   | 60 +++++++++++++++++++-----------------</span>
<span class="quote">&gt;  arch/arm/kvm/hyp/switch.c            |  4 +--</span>
<span class="quote">&gt;  arch/arm/kvm/hyp/tlb.c               | 15 ++++-----</span>
<span class="quote">&gt;  arch/arm/kvm/mmu.c                   |  9 ++++--</span>
<span class="quote">&gt;  arch/arm64/include/asm/kvm_asm.h     |  6 ++--</span>
<span class="quote">&gt;  arch/arm64/include/asm/kvm_emulate.h |  8 +++++</span>
<span class="quote">&gt;  arch/arm64/include/asm/kvm_host.h    | 14 ++++++---</span>
<span class="quote">&gt;  arch/arm64/include/asm/kvm_mmu.h     | 11 +++++++</span>
<span class="quote">&gt;  arch/arm64/kvm/hyp/switch.c          |  4 +--</span>
<span class="quote">&gt;  arch/arm64/kvm/hyp/tlb.c             | 16 ++++------</span>
<span class="quote">&gt;  14 files changed, 112 insertions(+), 70 deletions(-)</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; diff --git a/arch/arm/include/asm/kvm_asm.h b/arch/arm/include/asm/kvm_asm.h</span>
<span class="quote">&gt; index 36e3856..aa214f7 100644</span>
<span class="quote">&gt; --- a/arch/arm/include/asm/kvm_asm.h</span>
<span class="quote">&gt; +++ b/arch/arm/include/asm/kvm_asm.h</span>
<span class="quote">&gt; @@ -65,9 +65,9 @@</span>
<span class="quote">&gt;  extern char __kvm_hyp_vector[];</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  extern void __kvm_flush_vm_context(void);</span>
<span class="quote">&gt; -extern void __kvm_tlb_flush_vmid_ipa(struct kvm_s2_mmu *mmu, phys_addr_t ipa);</span>
<span class="quote">&gt; -extern void __kvm_tlb_flush_vmid(struct kvm_s2_mmu *mmu);</span>
<span class="quote">&gt; -extern void __kvm_tlb_flush_local_vmid(struct kvm_s2_mmu *mmu);</span>
<span class="quote">&gt; +extern void __kvm_tlb_flush_vmid_ipa(u64 vttbr, phys_addr_t ipa);</span>
<span class="quote">&gt; +extern void __kvm_tlb_flush_vmid(u64 vttbr);</span>
<span class="quote">&gt; +extern void __kvm_tlb_flush_local_vmid(u64 vttbr);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  extern int __kvm_vcpu_run(struct kvm_vcpu *vcpu);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; diff --git a/arch/arm/include/asm/kvm_emulate.h b/arch/arm/include/asm/kvm_emulate.h</span>
<span class="quote">&gt; index 05d5906..6285f4f 100644</span>
<span class="quote">&gt; --- a/arch/arm/include/asm/kvm_emulate.h</span>
<span class="quote">&gt; +++ b/arch/arm/include/asm/kvm_emulate.h</span>
<span class="quote">&gt; @@ -305,4 +305,8 @@ static inline unsigned long vcpu_data_host_to_guest(struct kvm_vcpu *vcpu,</span>
<span class="quote">&gt;  	}</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; +static inline struct kvm_s2_vmid *vcpu_get_active_vmid(struct kvm_vcpu *vcpu)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	return &amp;vcpu-&gt;kvm-&gt;arch.mmu.vmid;</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt;  #endif /* __ARM_KVM_EMULATE_H__ */</span>
<span class="quote">&gt; diff --git a/arch/arm/include/asm/kvm_host.h b/arch/arm/include/asm/kvm_host.h</span>
<span class="quote">&gt; index f84a59c..da45394 100644</span>
<span class="quote">&gt; --- a/arch/arm/include/asm/kvm_host.h</span>
<span class="quote">&gt; +++ b/arch/arm/include/asm/kvm_host.h</span>
<span class="quote">&gt; @@ -53,16 +53,18 @@</span>
<span class="quote">&gt;  int kvm_reset_vcpu(struct kvm_vcpu *vcpu);</span>
<span class="quote">&gt;  void kvm_reset_coprocs(struct kvm_vcpu *vcpu);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; -struct kvm_s2_mmu {</span>
<span class="quote">&gt; +struct kvm_s2_vmid {</span>
<span class="quote">&gt;  	/* The VMID generation used for the virt. memory system */</span>
<span class="quote">&gt;  	u64    vmid_gen;</span>
<span class="quote">&gt;  	u32    vmid;</span>
<span class="quote">&gt; +};</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +struct kvm_s2_mmu {</span>
<span class="quote">&gt; +	struct kvm_s2_vmid vmid;</span>
<span class="quote">&gt; +	struct kvm_s2_vmid el2_vmid;</span>

So this is subtle:  We use struct kvm_s2_mmu for the stage-2 context
used for the L1 VM, and for the L2 VM as well, right?  But only in the
first case can the el2_vmid have any valid meaning, and it&#39;s simply
ignored in other contexts.

Not sure if we can improve on this data structure design, but we could
at least add a comment on this somewhere.

Thanks,
-Christoffer
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/arch/arm/include/asm/kvm_asm.h b/arch/arm/include/asm/kvm_asm.h</span>
<span class="p_header">index 36e3856..aa214f7 100644</span>
<span class="p_header">--- a/arch/arm/include/asm/kvm_asm.h</span>
<span class="p_header">+++ b/arch/arm/include/asm/kvm_asm.h</span>
<span class="p_chunk">@@ -65,9 +65,9 @@</span> <span class="p_context"></span>
 extern char __kvm_hyp_vector[];
 
 extern void __kvm_flush_vm_context(void);
<span class="p_del">-extern void __kvm_tlb_flush_vmid_ipa(struct kvm_s2_mmu *mmu, phys_addr_t ipa);</span>
<span class="p_del">-extern void __kvm_tlb_flush_vmid(struct kvm_s2_mmu *mmu);</span>
<span class="p_del">-extern void __kvm_tlb_flush_local_vmid(struct kvm_s2_mmu *mmu);</span>
<span class="p_add">+extern void __kvm_tlb_flush_vmid_ipa(u64 vttbr, phys_addr_t ipa);</span>
<span class="p_add">+extern void __kvm_tlb_flush_vmid(u64 vttbr);</span>
<span class="p_add">+extern void __kvm_tlb_flush_local_vmid(u64 vttbr);</span>
 
 extern int __kvm_vcpu_run(struct kvm_vcpu *vcpu);
 
<span class="p_header">diff --git a/arch/arm/include/asm/kvm_emulate.h b/arch/arm/include/asm/kvm_emulate.h</span>
<span class="p_header">index 05d5906..6285f4f 100644</span>
<span class="p_header">--- a/arch/arm/include/asm/kvm_emulate.h</span>
<span class="p_header">+++ b/arch/arm/include/asm/kvm_emulate.h</span>
<span class="p_chunk">@@ -305,4 +305,8 @@</span> <span class="p_context"> static inline unsigned long vcpu_data_host_to_guest(struct kvm_vcpu *vcpu,</span>
 	}
 }
 
<span class="p_add">+static inline struct kvm_s2_vmid *vcpu_get_active_vmid(struct kvm_vcpu *vcpu)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return &amp;vcpu-&gt;kvm-&gt;arch.mmu.vmid;</span>
<span class="p_add">+}</span>
 #endif /* __ARM_KVM_EMULATE_H__ */
<span class="p_header">diff --git a/arch/arm/include/asm/kvm_host.h b/arch/arm/include/asm/kvm_host.h</span>
<span class="p_header">index f84a59c..da45394 100644</span>
<span class="p_header">--- a/arch/arm/include/asm/kvm_host.h</span>
<span class="p_header">+++ b/arch/arm/include/asm/kvm_host.h</span>
<span class="p_chunk">@@ -53,16 +53,18 @@</span> <span class="p_context"></span>
 int kvm_reset_vcpu(struct kvm_vcpu *vcpu);
 void kvm_reset_coprocs(struct kvm_vcpu *vcpu);
 
<span class="p_del">-struct kvm_s2_mmu {</span>
<span class="p_add">+struct kvm_s2_vmid {</span>
 	/* The VMID generation used for the virt. memory system */
 	u64    vmid_gen;
 	u32    vmid;
<span class="p_add">+};</span>
<span class="p_add">+</span>
<span class="p_add">+struct kvm_s2_mmu {</span>
<span class="p_add">+	struct kvm_s2_vmid vmid;</span>
<span class="p_add">+	struct kvm_s2_vmid el2_vmid;</span>
 
 	/* Stage-2 page table */
 	pgd_t *pgd;
<span class="p_del">-</span>
<span class="p_del">-	/* VTTBR value associated with above pgd and vmid */</span>
<span class="p_del">-	u64    vttbr;</span>
 };
 
 struct kvm_arch {
<span class="p_chunk">@@ -196,6 +198,9 @@</span> <span class="p_context"> struct kvm_vcpu_arch {</span>
 
 	/* Stage 2 paging state used by the hardware on next switch */
 	struct kvm_s2_mmu *hw_mmu;
<span class="p_add">+</span>
<span class="p_add">+	/* VTTBR value used by the hardware on next switch */</span>
<span class="p_add">+	u64 hw_vttbr;</span>
 };
 
 struct kvm_vm_stat {
<span class="p_chunk">@@ -242,6 +247,7 @@</span> <span class="p_context"> static inline void kvm_arch_mmu_notifier_invalidate_page(struct kvm *kvm,</span>
 {
 }
 
<span class="p_add">+unsigned int get_kvm_vmid_bits(void);</span>
 struct kvm_vcpu *kvm_arm_get_running_vcpu(void);
 struct kvm_vcpu __percpu **kvm_get_running_vcpus(void);
 void kvm_arm_halt_guest(struct kvm *kvm);
<span class="p_header">diff --git a/arch/arm/include/asm/kvm_mmu.h b/arch/arm/include/asm/kvm_mmu.h</span>
<span class="p_header">index 74a44727..1b3309c 100644</span>
<span class="p_header">--- a/arch/arm/include/asm/kvm_mmu.h</span>
<span class="p_header">+++ b/arch/arm/include/asm/kvm_mmu.h</span>
<span class="p_chunk">@@ -230,6 +230,17 @@</span> <span class="p_context"> static inline unsigned int kvm_get_vmid_bits(void)</span>
 	return 8;
 }
 
<span class="p_add">+static inline u64 kvm_get_vttbr(struct kvm_s2_vmid *vmid,</span>
<span class="p_add">+				struct kvm_s2_mmu *mmu)</span>
<span class="p_add">+{</span>
<span class="p_add">+	u64 vmid_field, baddr;</span>
<span class="p_add">+</span>
<span class="p_add">+	baddr = virt_to_phys(mmu-&gt;pgd);</span>
<span class="p_add">+	vmid_field = ((u64)vmid-&gt;vmid &lt;&lt; VTTBR_VMID_SHIFT) &amp;</span>
<span class="p_add">+		VTTBR_VMID_MASK(get_kvm_vmid_bits());</span>
<span class="p_add">+	return baddr | vmid_field;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 #endif	/* !__ASSEMBLY__ */
 
 #endif /* __ARM_KVM_MMU_H__ */
<span class="p_header">diff --git a/arch/arm/kvm/arm.c b/arch/arm/kvm/arm.c</span>
<span class="p_header">index eb3e709..aa8771d 100644</span>
<span class="p_header">--- a/arch/arm/kvm/arm.c</span>
<span class="p_header">+++ b/arch/arm/kvm/arm.c</span>
<span class="p_chunk">@@ -75,6 +75,11 @@</span> <span class="p_context"> static void kvm_arm_set_running_vcpu(struct kvm_vcpu *vcpu)</span>
 	__this_cpu_write(kvm_arm_running_vcpu, vcpu);
 }
 
<span class="p_add">+unsigned int get_kvm_vmid_bits(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return kvm_vmid_bits;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 /**
  * kvm_arm_get_running_vcpu - get the vcpu running on the current CPU.
  * Must be called from non-preemptible context
<span class="p_chunk">@@ -139,7 +144,8 @@</span> <span class="p_context"> int kvm_arch_init_vm(struct kvm *kvm, unsigned long type)</span>
 	kvm_timer_init(kvm);
 
 	/* Mark the initial VMID generation invalid */
<span class="p_del">-	kvm-&gt;arch.mmu.vmid_gen = 0;</span>
<span class="p_add">+	kvm-&gt;arch.mmu.vmid.vmid_gen = 0;</span>
<span class="p_add">+	kvm-&gt;arch.mmu.el2_vmid.vmid_gen = 0;</span>
 
 	/* The maximum number of VCPUs is limited by the host&#39;s GIC model */
 	kvm-&gt;arch.max_vcpus = vgic_present ?
<span class="p_chunk">@@ -312,6 +318,8 @@</span> <span class="p_context"> void kvm_arch_vcpu_unblocking(struct kvm_vcpu *vcpu)</span>
 
 int kvm_arch_vcpu_init(struct kvm_vcpu *vcpu)
 {
<span class="p_add">+	struct kvm_s2_mmu *mmu = &amp;vcpu-&gt;kvm-&gt;arch.mmu;</span>
<span class="p_add">+</span>
 	/* Force users to call KVM_ARM_VCPU_INIT */
 	vcpu-&gt;arch.target = -1;
 	bitmap_zero(vcpu-&gt;arch.features, KVM_VCPU_MAX_FEATURES);
<span class="p_chunk">@@ -321,7 +329,8 @@</span> <span class="p_context"> int kvm_arch_vcpu_init(struct kvm_vcpu *vcpu)</span>
 
 	kvm_arm_reset_debug_ptr(vcpu);
 
<span class="p_del">-	vcpu-&gt;arch.hw_mmu = &amp;vcpu-&gt;kvm-&gt;arch.mmu;</span>
<span class="p_add">+	vcpu-&gt;arch.hw_mmu = mmu;</span>
<span class="p_add">+	vcpu-&gt;arch.hw_vttbr = kvm_get_vttbr(&amp;mmu-&gt;vmid, mmu);</span>
 
 	return 0;
 }
<span class="p_chunk">@@ -337,7 +346,10 @@</span> <span class="p_context"> void kvm_arch_vcpu_load(struct kvm_vcpu *vcpu, int cpu)</span>
 	 * over-invalidation doesn&#39;t affect correctness.
 	 */
 	if (*last_ran != vcpu-&gt;vcpu_id) {
<span class="p_del">-		kvm_call_hyp(__kvm_tlb_flush_local_vmid, &amp;vcpu-&gt;kvm-&gt;arch.mmu);</span>
<span class="p_add">+		struct kvm_s2_mmu *mmu = &amp;vcpu-&gt;kvm-&gt;arch.mmu;</span>
<span class="p_add">+		u64 vttbr = kvm_get_vttbr(&amp;mmu-&gt;vmid, mmu);</span>
<span class="p_add">+</span>
<span class="p_add">+		kvm_call_hyp(__kvm_tlb_flush_local_vmid, vttbr);</span>
 		*last_ran = vcpu-&gt;vcpu_id;
 	}
 
<span class="p_chunk">@@ -415,36 +427,33 @@</span> <span class="p_context"> void force_vm_exit(const cpumask_t *mask)</span>
 
 /**
  * need_new_vmid_gen - check that the VMID is still valid
<span class="p_del">- * @kvm: The VM&#39;s VMID to check</span>
<span class="p_add">+ * @vmid: The VMID to check</span>
  *
  * return true if there is a new generation of VMIDs being used
  *
<span class="p_del">- * The hardware supports only 256 values with the value zero reserved for the</span>
<span class="p_del">- * host, so we check if an assigned value belongs to a previous generation,</span>
<span class="p_del">- * which which requires us to assign a new value. If we&#39;re the first to use a</span>
<span class="p_del">- * VMID for the new generation, we must flush necessary caches and TLBs on all</span>
<span class="p_del">- * CPUs.</span>
<span class="p_add">+ * The hardware supports a limited set of values with the value zero reserved</span>
<span class="p_add">+ * for the host, so we check if an assigned value belongs to a previous</span>
<span class="p_add">+ * generation, which which requires us to assign a new value. If we&#39;re the</span>
<span class="p_add">+ * first to use a VMID for the new generation, we must flush necessary caches</span>
<span class="p_add">+ * and TLBs on all CPUs.</span>
  */
<span class="p_del">-static bool need_new_vmid_gen(struct kvm_s2_mmu *mmu)</span>
<span class="p_add">+static bool need_new_vmid_gen(struct kvm_s2_vmid *vmid)</span>
 {
<span class="p_del">-	return unlikely(mmu-&gt;vmid_gen != atomic64_read(&amp;kvm_vmid_gen));</span>
<span class="p_add">+	return unlikely(vmid-&gt;vmid_gen != atomic64_read(&amp;kvm_vmid_gen));</span>
 }
 
 /**
  * update_vttbr - Update the VTTBR with a valid VMID before the guest runs
  * @kvm:	The guest that we are about to run
<span class="p_del">- * @mmu:	The stage-2 translation context to update</span>
<span class="p_add">+ * @vmid:	The stage-2 VMID information struct</span>
  *
  * Called from kvm_arch_vcpu_ioctl_run before entering the guest to ensure the
  * VM has a valid VMID, otherwise assigns a new one and flushes corresponding
  * caches and TLBs.
  */
<span class="p_del">-static void update_vttbr(struct kvm *kvm, struct kvm_s2_mmu *mmu)</span>
<span class="p_add">+static void update_vttbr(struct kvm *kvm, struct kvm_s2_vmid *vmid)</span>
 {
<span class="p_del">-	phys_addr_t pgd_phys;</span>
<span class="p_del">-	u64 vmid;</span>
<span class="p_del">-</span>
<span class="p_del">-	if (!need_new_vmid_gen(mmu))</span>
<span class="p_add">+	if (!need_new_vmid_gen(vmid))</span>
 		return;
 
 	spin_lock(&amp;kvm_vmid_lock);
<span class="p_chunk">@@ -454,7 +463,7 @@</span> <span class="p_context"> static void update_vttbr(struct kvm *kvm, struct kvm_s2_mmu *mmu)</span>
 	 * already allocated a valid vmid for this vm, then this vcpu should
 	 * use the same vmid.
 	 */
<span class="p_del">-	if (!need_new_vmid_gen(mmu)) {</span>
<span class="p_add">+	if (!need_new_vmid_gen(vmid)) {</span>
 		spin_unlock(&amp;kvm_vmid_lock);
 		return;
 	}
<span class="p_chunk">@@ -478,18 +487,11 @@</span> <span class="p_context"> static void update_vttbr(struct kvm *kvm, struct kvm_s2_mmu *mmu)</span>
 		kvm_call_hyp(__kvm_flush_vm_context);
 	}
 
<span class="p_del">-	mmu-&gt;vmid_gen = atomic64_read(&amp;kvm_vmid_gen);</span>
<span class="p_del">-	mmu-&gt;vmid = kvm_next_vmid;</span>
<span class="p_add">+	vmid-&gt;vmid_gen = atomic64_read(&amp;kvm_vmid_gen);</span>
<span class="p_add">+	vmid-&gt;vmid = kvm_next_vmid;</span>
 	kvm_next_vmid++;
 	kvm_next_vmid &amp;= (1 &lt;&lt; kvm_vmid_bits) - 1;
 
<span class="p_del">-	/* update vttbr to be used with the new vmid */</span>
<span class="p_del">-	pgd_phys = virt_to_phys(mmu-&gt;pgd);</span>
<span class="p_del">-	BUG_ON(pgd_phys &amp; ~VTTBR_BADDR_MASK);</span>
<span class="p_del">-	vmid = ((u64)(mmu-&gt;vmid) &lt;&lt; VTTBR_VMID_SHIFT) &amp;</span>
<span class="p_del">-	       VTTBR_VMID_MASK(kvm_vmid_bits);</span>
<span class="p_del">-	mmu-&gt;vttbr = pgd_phys | vmid;</span>
<span class="p_del">-</span>
 	spin_unlock(&amp;kvm_vmid_lock);
 }
 
<span class="p_chunk">@@ -615,7 +617,7 @@</span> <span class="p_context"> int kvm_arch_vcpu_ioctl_run(struct kvm_vcpu *vcpu, struct kvm_run *run)</span>
 		 */
 		cond_resched();
 
<span class="p_del">-		update_vttbr(vcpu-&gt;kvm, vcpu-&gt;arch.hw_mmu);</span>
<span class="p_add">+		update_vttbr(vcpu-&gt;kvm, vcpu_get_active_vmid(vcpu));</span>
 
 		if (vcpu-&gt;arch.power_off || vcpu-&gt;arch.pause)
 			vcpu_sleep(vcpu);
<span class="p_chunk">@@ -640,7 +642,7 @@</span> <span class="p_context"> int kvm_arch_vcpu_ioctl_run(struct kvm_vcpu *vcpu, struct kvm_run *run)</span>
 			run-&gt;exit_reason = KVM_EXIT_INTR;
 		}
 
<span class="p_del">-		if (ret &lt;= 0 || need_new_vmid_gen(vcpu-&gt;arch.hw_mmu) ||</span>
<span class="p_add">+		if (ret &lt;= 0 || need_new_vmid_gen(vcpu_get_active_vmid(vcpu)) ||</span>
 			vcpu-&gt;arch.power_off || vcpu-&gt;arch.pause) {
 			local_irq_enable();
 			kvm_pmu_sync_hwstate(vcpu);
<span class="p_header">diff --git a/arch/arm/kvm/hyp/switch.c b/arch/arm/kvm/hyp/switch.c</span>
<span class="p_header">index 6f99de1..65d0b5b 100644</span>
<span class="p_header">--- a/arch/arm/kvm/hyp/switch.c</span>
<span class="p_header">+++ b/arch/arm/kvm/hyp/switch.c</span>
<span class="p_chunk">@@ -73,9 +73,7 @@</span> <span class="p_context"> static void __hyp_text __deactivate_traps(struct kvm_vcpu *vcpu)</span>
 
 static void __hyp_text __activate_vm(struct kvm_vcpu *vcpu)
 {
<span class="p_del">-	struct kvm_s2_mmu *mmu = kern_hyp_va(vcpu-&gt;arch.hw_mmu);</span>
<span class="p_del">-</span>
<span class="p_del">-	write_sysreg(mmu-&gt;vttbr, VTTBR);</span>
<span class="p_add">+	write_sysreg(vcpu-&gt;arch.hw_vttbr, VTTBR);</span>
 	write_sysreg(vcpu-&gt;arch.midr, VPIDR);
 }
 
<span class="p_header">diff --git a/arch/arm/kvm/hyp/tlb.c b/arch/arm/kvm/hyp/tlb.c</span>
<span class="p_header">index 56f0a49..562ad0b 100644</span>
<span class="p_header">--- a/arch/arm/kvm/hyp/tlb.c</span>
<span class="p_header">+++ b/arch/arm/kvm/hyp/tlb.c</span>
<span class="p_chunk">@@ -34,13 +34,12 @@</span> <span class="p_context"></span>
  * As v7 does not support flushing per IPA, just nuke the whole TLB
  * instead, ignoring the ipa value.
  */
<span class="p_del">-void __hyp_text __kvm_tlb_flush_vmid(struct kvm_s2_mmu *mmu)</span>
<span class="p_add">+void __hyp_text __kvm_tlb_flush_vmid(u64 vttbr)</span>
 {
 	dsb(ishst);
 
 	/* Switch to requested VMID */
<span class="p_del">-	mmu = kern_hyp_va(mmu);</span>
<span class="p_del">-	write_sysreg(mmu-&gt;vttbr, VTTBR);</span>
<span class="p_add">+	write_sysreg(vttbr, VTTBR);</span>
 	isb();
 
 	write_sysreg(0, TLBIALLIS);
<span class="p_chunk">@@ -50,17 +49,15 @@</span> <span class="p_context"> void __hyp_text __kvm_tlb_flush_vmid(struct kvm_s2_mmu *mmu)</span>
 	write_sysreg(0, VTTBR);
 }
 
<span class="p_del">-void __hyp_text __kvm_tlb_flush_vmid_ipa(struct kvm_s2_mmu *mmu,</span>
<span class="p_del">-					 phys_addr_t ipa)</span>
<span class="p_add">+void __hyp_text __kvm_tlb_flush_vmid_ipa(u64 vttbr, phys_addr_t ipa)</span>
 {
<span class="p_del">-	__kvm_tlb_flush_vmid(mmu);</span>
<span class="p_add">+	__kvm_tlb_flush_vmid(vttbr);</span>
 }
 
<span class="p_del">-void __hyp_text __kvm_tlb_flush_local_vmid(struct kvm_s2_mmu *mmu)</span>
<span class="p_add">+void __hyp_text __kvm_tlb_flush_local_vmid(u64 vttbr)</span>
 {
 	/* Switch to requested VMID */
<span class="p_del">-	mmu = kern_hyp_va(mmu);</span>
<span class="p_del">-	write_sysreg(mmu-&gt;vttbr, VTTBR);</span>
<span class="p_add">+	write_sysreg(vttbr, VTTBR);</span>
 	isb();
 
 	write_sysreg(0, TLBIALL);
<span class="p_header">diff --git a/arch/arm/kvm/mmu.c b/arch/arm/kvm/mmu.c</span>
<span class="p_header">index a27a204..5ca3a04 100644</span>
<span class="p_header">--- a/arch/arm/kvm/mmu.c</span>
<span class="p_header">+++ b/arch/arm/kvm/mmu.c</span>
<span class="p_chunk">@@ -60,12 +60,17 @@</span> <span class="p_context"> static bool memslot_is_logging(struct kvm_memory_slot *memslot)</span>
  */
 void kvm_flush_remote_tlbs(struct kvm *kvm)
 {
<span class="p_del">-	kvm_call_hyp(__kvm_tlb_flush_vmid, kvm);</span>
<span class="p_add">+	struct kvm_s2_mmu *mmu = &amp;kvm-&gt;arch.mmu;</span>
<span class="p_add">+	u64 vttbr = kvm_get_vttbr(&amp;mmu-&gt;vmid, mmu);</span>
<span class="p_add">+</span>
<span class="p_add">+	kvm_call_hyp(__kvm_tlb_flush_vmid, vttbr);</span>
 }
 
 static void kvm_tlb_flush_vmid_ipa(struct kvm_s2_mmu *mmu, phys_addr_t ipa)
 {
<span class="p_del">-	kvm_call_hyp(__kvm_tlb_flush_vmid_ipa, mmu, ipa);</span>
<span class="p_add">+	u64 vttbr = kvm_get_vttbr(&amp;mmu-&gt;vmid, mmu);</span>
<span class="p_add">+</span>
<span class="p_add">+	kvm_call_hyp(__kvm_tlb_flush_vmid_ipa, vttbr, ipa);</span>
 }
 
 /*
<span class="p_header">diff --git a/arch/arm64/include/asm/kvm_asm.h b/arch/arm64/include/asm/kvm_asm.h</span>
<span class="p_header">index ed8139f..27dce47 100644</span>
<span class="p_header">--- a/arch/arm64/include/asm/kvm_asm.h</span>
<span class="p_header">+++ b/arch/arm64/include/asm/kvm_asm.h</span>
<span class="p_chunk">@@ -53,9 +53,9 @@</span> <span class="p_context"></span>
 extern char __kvm_hyp_vector[];
 
 extern void __kvm_flush_vm_context(void);
<span class="p_del">-extern void __kvm_tlb_flush_vmid_ipa(struct kvm_s2_mmu *mmu, phys_addr_t ipa);</span>
<span class="p_del">-extern void __kvm_tlb_flush_vmid(struct kvm_s2_mmu *mmu);</span>
<span class="p_del">-extern void __kvm_tlb_flush_local_vmid(struct kvm_s2_mmu *mmu);</span>
<span class="p_add">+extern void __kvm_tlb_flush_vmid_ipa(u64 vttbr, phys_addr_t ipa);</span>
<span class="p_add">+extern void __kvm_tlb_flush_vmid(u64 vttbr);</span>
<span class="p_add">+extern void __kvm_tlb_flush_local_vmid(u64 vttbr);</span>
 
 extern int __kvm_vcpu_run(struct kvm_vcpu *vcpu);
 
<span class="p_header">diff --git a/arch/arm64/include/asm/kvm_emulate.h b/arch/arm64/include/asm/kvm_emulate.h</span>
<span class="p_header">index a9c993f..94068e7 100644</span>
<span class="p_header">--- a/arch/arm64/include/asm/kvm_emulate.h</span>
<span class="p_header">+++ b/arch/arm64/include/asm/kvm_emulate.h</span>
<span class="p_chunk">@@ -363,4 +363,12 @@</span> <span class="p_context"> static inline unsigned long vcpu_data_host_to_guest(struct kvm_vcpu *vcpu,</span>
 	return data;		/* Leave LE untouched */
 }
 
<span class="p_add">+static inline struct kvm_s2_vmid *vcpu_get_active_vmid(struct kvm_vcpu *vcpu)</span>
<span class="p_add">+{</span>
<span class="p_add">+	if (unlikely(vcpu_mode_el2(vcpu)))</span>
<span class="p_add">+		return &amp;vcpu-&gt;kvm-&gt;arch.mmu.el2_vmid;</span>
<span class="p_add">+</span>
<span class="p_add">+	return &amp;vcpu-&gt;kvm-&gt;arch.mmu.vmid;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 #endif /* __ARM64_KVM_EMULATE_H__ */
<span class="p_header">diff --git a/arch/arm64/include/asm/kvm_host.h b/arch/arm64/include/asm/kvm_host.h</span>
<span class="p_header">index 954d6de..b33d35d 100644</span>
<span class="p_header">--- a/arch/arm64/include/asm/kvm_host.h</span>
<span class="p_header">+++ b/arch/arm64/include/asm/kvm_host.h</span>
<span class="p_chunk">@@ -50,17 +50,19 @@</span> <span class="p_context"></span>
 int kvm_arch_dev_ioctl_check_extension(struct kvm *kvm, long ext);
 void __extended_idmap_trampoline(phys_addr_t boot_pgd, phys_addr_t idmap_start);
 
<span class="p_del">-struct kvm_s2_mmu {</span>
<span class="p_add">+struct kvm_s2_vmid {</span>
 	/* The VMID generation used for the virt. memory system */
 	u64    vmid_gen;
 	u32    vmid;
<span class="p_add">+};</span>
<span class="p_add">+</span>
<span class="p_add">+struct kvm_s2_mmu {</span>
<span class="p_add">+	struct kvm_s2_vmid vmid;</span>
<span class="p_add">+	struct kvm_s2_vmid el2_vmid;</span>
 
 	/* 1-level 2nd stage table and lock */
 	spinlock_t pgd_lock;
 	pgd_t *pgd;
<span class="p_del">-</span>
<span class="p_del">-	/* VTTBR value associated with above pgd and vmid */</span>
<span class="p_del">-	u64    vttbr;</span>
 };
 
 struct kvm_arch {
<span class="p_chunk">@@ -334,6 +336,9 @@</span> <span class="p_context"> struct kvm_vcpu_arch {</span>
 
 	/* Stage 2 paging state used by the hardware on next switch */
 	struct kvm_s2_mmu *hw_mmu;
<span class="p_add">+</span>
<span class="p_add">+	/* VTTBR value used by the hardware on next switch */</span>
<span class="p_add">+	u64 hw_vttbr;</span>
 };
 
 #define vcpu_gp_regs(v)		(&amp;(v)-&gt;arch.ctxt.gp_regs)
<span class="p_chunk">@@ -391,6 +396,7 @@</span> <span class="p_context"> static inline void kvm_arch_mmu_notifier_invalidate_page(struct kvm *kvm,</span>
 {
 }
 
<span class="p_add">+unsigned int get_kvm_vmid_bits(void);</span>
 struct kvm_vcpu *kvm_arm_get_running_vcpu(void);
 struct kvm_vcpu * __percpu *kvm_get_running_vcpus(void);
 void kvm_arm_halt_guest(struct kvm *kvm);
<span class="p_header">diff --git a/arch/arm64/include/asm/kvm_mmu.h b/arch/arm64/include/asm/kvm_mmu.h</span>
<span class="p_header">index 6f72fe8..e3455c4 100644</span>
<span class="p_header">--- a/arch/arm64/include/asm/kvm_mmu.h</span>
<span class="p_header">+++ b/arch/arm64/include/asm/kvm_mmu.h</span>
<span class="p_chunk">@@ -314,5 +314,16 @@</span> <span class="p_context"> static inline unsigned int kvm_get_vmid_bits(void)</span>
 	return (cpuid_feature_extract_unsigned_field(reg, ID_AA64MMFR1_VMIDBITS_SHIFT) == 2) ? 16 : 8;
 }
 
<span class="p_add">+static inline u64 kvm_get_vttbr(struct kvm_s2_vmid *vmid,</span>
<span class="p_add">+				struct kvm_s2_mmu *mmu)</span>
<span class="p_add">+{</span>
<span class="p_add">+	u64 vmid_field, baddr;</span>
<span class="p_add">+</span>
<span class="p_add">+	baddr = virt_to_phys(mmu-&gt;pgd);</span>
<span class="p_add">+	vmid_field = ((u64)vmid-&gt;vmid &lt;&lt; VTTBR_VMID_SHIFT) &amp;</span>
<span class="p_add">+		VTTBR_VMID_MASK(get_kvm_vmid_bits());</span>
<span class="p_add">+	return baddr | vmid_field;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 #endif /* __ASSEMBLY__ */
 #endif /* __ARM64_KVM_MMU_H__ */
<span class="p_header">diff --git a/arch/arm64/kvm/hyp/switch.c b/arch/arm64/kvm/hyp/switch.c</span>
<span class="p_header">index 3207009a..c80b2ae 100644</span>
<span class="p_header">--- a/arch/arm64/kvm/hyp/switch.c</span>
<span class="p_header">+++ b/arch/arm64/kvm/hyp/switch.c</span>
<span class="p_chunk">@@ -135,9 +135,7 @@</span> <span class="p_context"> static void __hyp_text __deactivate_traps(struct kvm_vcpu *vcpu)</span>
 
 static void __hyp_text __activate_vm(struct kvm_vcpu *vcpu)
 {
<span class="p_del">-	struct kvm_s2_mmu *mmu = kern_hyp_va(vcpu-&gt;arch.hw_mmu);</span>
<span class="p_del">-</span>
<span class="p_del">-	write_sysreg(mmu-&gt;vttbr, vttbr_el2);</span>
<span class="p_add">+	write_sysreg(vcpu-&gt;arch.hw_vttbr, vttbr_el2);</span>
 }
 
 static void __hyp_text __deactivate_vm(struct kvm_vcpu *vcpu)
<span class="p_header">diff --git a/arch/arm64/kvm/hyp/tlb.c b/arch/arm64/kvm/hyp/tlb.c</span>
<span class="p_header">index 71a62ea..82350e7 100644</span>
<span class="p_header">--- a/arch/arm64/kvm/hyp/tlb.c</span>
<span class="p_header">+++ b/arch/arm64/kvm/hyp/tlb.c</span>
<span class="p_chunk">@@ -17,14 +17,12 @@</span> <span class="p_context"></span>
 
 #include &lt;asm/kvm_hyp.h&gt;
 
<span class="p_del">-void __hyp_text __kvm_tlb_flush_vmid_ipa(struct kvm_s2_mmu *mmu,</span>
<span class="p_del">-					 phys_addr_t ipa)</span>
<span class="p_add">+void __hyp_text __kvm_tlb_flush_vmid_ipa(u64 vttbr, phys_addr_t ipa)</span>
 {
 	dsb(ishst);
 
 	/* Switch to requested VMID */
<span class="p_del">-	mmu = kern_hyp_va(mmu);</span>
<span class="p_del">-	write_sysreg(mmu-&gt;vttbr, vttbr_el2);</span>
<span class="p_add">+	write_sysreg(vttbr, vttbr_el2);</span>
 	isb();
 
 	/*
<span class="p_chunk">@@ -49,13 +47,12 @@</span> <span class="p_context"> void __hyp_text __kvm_tlb_flush_vmid_ipa(struct kvm_s2_mmu *mmu,</span>
 	write_sysreg(0, vttbr_el2);
 }
 
<span class="p_del">-void __hyp_text __kvm_tlb_flush_vmid(struct kvm_s2_mmu *mmu)</span>
<span class="p_add">+void __hyp_text __kvm_tlb_flush_vmid(u64 vttbr)</span>
 {
 	dsb(ishst);
 
 	/* Switch to requested VMID */
<span class="p_del">-	mmu = kern_hyp_va(mmu);</span>
<span class="p_del">-	write_sysreg(mmu-&gt;vttbr, vttbr_el2);</span>
<span class="p_add">+	write_sysreg(vttbr, vttbr_el2);</span>
 	isb();
 
 	asm volatile(&quot;tlbi vmalls12e1is&quot; : : );
<span class="p_chunk">@@ -65,11 +62,10 @@</span> <span class="p_context"> void __hyp_text __kvm_tlb_flush_vmid(struct kvm_s2_mmu *mmu)</span>
 	write_sysreg(0, vttbr_el2);
 }
 
<span class="p_del">-void __hyp_text __kvm_tlb_flush_local_vmid(struct kvm_s2_mmu *mmu)</span>
<span class="p_add">+void __hyp_text __kvm_tlb_flush_local_vmid(u64 vttbr)</span>
 {
 	/* Switch to requested VMID */
<span class="p_del">-	mmu = kern_hyp_va(mmu);</span>
<span class="p_del">-	write_sysreg(mmu-&gt;vttbr, vttbr_el2);</span>
<span class="p_add">+	write_sysreg(vttbr, vttbr_el2);</span>
 	isb();
 
 	asm volatile(&quot;tlbi vmalle1&quot; : : );

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



