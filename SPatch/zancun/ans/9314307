
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>[RFC,v2,6/7] arm64: KVM: Handle trappable TLB instructions - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    [RFC,v2,6/7] arm64: KVM: Handle trappable TLB instructions</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=58591">Punit Agrawal</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>Sept. 5, 2016, 4:31 p.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;1473093097-30932-7-git-send-email-punit.agrawal@arm.com&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/9314307/mbox/"
   >mbox</a>
|
   <a href="/patch/9314307/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/9314307/">/patch/9314307/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
	[172.30.200.125])
	by pdx-korg-patchwork.web.codeaurora.org (Postfix) with ESMTP id
	E88BC607D3 for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Mon,  5 Sep 2016 16:33:43 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id DBA3F28AF9
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Mon,  5 Sep 2016 16:33:43 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id D062A28B01; Mon,  5 Sep 2016 16:33:43 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-6.9 required=2.0 tests=BAYES_00,RCVD_IN_DNSWL_HI
	autolearn=unavailable version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 5E29028AFF
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Mon,  5 Sep 2016 16:33:42 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S933796AbcIEQdZ (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Mon, 5 Sep 2016 12:33:25 -0400
Received: from fw-tnat.cambridge.arm.com ([217.140.96.140]:28925 &quot;EHLO
	cam-smtp0.cambridge.arm.com&quot; rhost-flags-OK-OK-OK-FAIL)
	by vger.kernel.org with ESMTP id S932324AbcIEQdJ (ORCPT
	&lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Mon, 5 Sep 2016 12:33:09 -0400
Received: from e105922-lin.cambridge.arm.com (e105922-lin.cambridge.arm.com
	[10.1.194.52])
	by cam-smtp0.cambridge.arm.com (8.13.8/8.13.8) with SMTP id
	u85GWWiX009220; Mon, 5 Sep 2016 17:32:32 +0100
Received: by e105922-lin.cambridge.arm.com (sSMTP sendmail emulation);
	Mon, 05 Sep 2016 17:32:32 +0100
From: Punit Agrawal &lt;punit.agrawal@arm.com&gt;
To: linux-kernel@vger.kernel.org, kvm@vger.kernel.org,
	kvmarm@lists.cs.columbia.edu, linux-arm-kernel@lists.infradead.org
Cc: Punit Agrawal &lt;punit.agrawal@arm.com&gt;,
	Christoffer Dall &lt;christoffer.dall@linaro.org&gt;,
	Marc Zyngier &lt;marc.zyngier@arm.com&gt;,
	Steven Rostedt &lt;rostedt@goodmis.org&gt;, Ingo Molnar &lt;mingo@redhat.com&gt;,
	Will Deacon &lt;will.deacon@arm.com&gt;
Subject: [RFC v2 PATCH 6/7] arm64: KVM: Handle trappable TLB instructions
Date: Mon,  5 Sep 2016 17:31:36 +0100
Message-Id: &lt;1473093097-30932-7-git-send-email-punit.agrawal@arm.com&gt;
X-Mailer: git-send-email 2.8.1
In-Reply-To: &lt;1473093097-30932-1-git-send-email-punit.agrawal@arm.com&gt;
References: &lt;1473093097-30932-1-git-send-email-punit.agrawal@arm.com&gt;
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=58591">Punit Agrawal</a> - Sept. 5, 2016, 4:31 p.m.</div>
<pre class="content">
The ARMv8 architecture allows trapping of TLB maintenane instructions
from EL0/EL1 to higher exception levels. On encountering a trappable TLB
instruction in a guest, an exception is taken to EL2.

Add functionality to handle emulating the TLB instructions.
<span class="signed-off-by">
Signed-off-by: Punit Agrawal &lt;punit.agrawal@arm.com&gt;</span>
Cc: Christoffer Dall &lt;christoffer.dall@linaro.org&gt;
Cc: Marc Zyngier &lt;marc.zyngier@arm.com&gt;
---
 arch/arm64/include/asm/kvm_asm.h |  1 +
 arch/arm64/kvm/hyp/tlb.c         | 69 ++++++++++++++++++++++++++++++++++
 arch/arm64/kvm/sys_regs.c        | 81 ++++++++++++++++++++++++++++++++++++++++
 arch/arm64/kvm/trace.h           | 16 ++++++++
 4 files changed, 167 insertions(+)
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=68151">Christoffer Dall</a> - Sept. 6, 2016, 10:21 a.m.</div>
<pre class="content">
On Mon, Sep 05, 2016 at 05:31:36PM +0100, Punit Agrawal wrote:
<span class="quote">&gt; The ARMv8 architecture allows trapping of TLB maintenane instructions</span>
<span class="quote">&gt; from EL0/EL1 to higher exception levels. On encountering a trappable TLB</span>
<span class="quote">&gt; instruction in a guest, an exception is taken to EL2.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Add functionality to handle emulating the TLB instructions.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Signed-off-by: Punit Agrawal &lt;punit.agrawal@arm.com&gt;</span>
<span class="quote">&gt; Cc: Christoffer Dall &lt;christoffer.dall@linaro.org&gt;</span>
<span class="quote">&gt; Cc: Marc Zyngier &lt;marc.zyngier@arm.com&gt;</span>
<span class="quote">&gt; ---</span>
<span class="quote">&gt;  arch/arm64/include/asm/kvm_asm.h |  1 +</span>
<span class="quote">&gt;  arch/arm64/kvm/hyp/tlb.c         | 69 ++++++++++++++++++++++++++++++++++</span>
<span class="quote">&gt;  arch/arm64/kvm/sys_regs.c        | 81 ++++++++++++++++++++++++++++++++++++++++</span>
<span class="quote">&gt;  arch/arm64/kvm/trace.h           | 16 ++++++++</span>
<span class="quote">&gt;  4 files changed, 167 insertions(+)</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; diff --git a/arch/arm64/include/asm/kvm_asm.h b/arch/arm64/include/asm/kvm_asm.h</span>
<span class="quote">&gt; index 7561f63..1ac1cc3 100644</span>
<span class="quote">&gt; --- a/arch/arm64/include/asm/kvm_asm.h</span>
<span class="quote">&gt; +++ b/arch/arm64/include/asm/kvm_asm.h</span>
<span class="quote">&gt; @@ -49,6 +49,7 @@ extern char __kvm_hyp_vector[];</span>
<span class="quote">&gt;  extern void __kvm_flush_vm_context(void);</span>
<span class="quote">&gt;  extern void __kvm_tlb_flush_vmid_ipa(struct kvm *kvm, phys_addr_t ipa);</span>
<span class="quote">&gt;  extern void __kvm_tlb_flush_vmid(struct kvm *kvm);</span>
<span class="quote">&gt; +extern void __kvm_emulate_tlb_invalidate(struct kvm *kvm, u32 sysreg, u64 regval);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  extern int __kvm_vcpu_run(struct kvm_vcpu *vcpu);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; diff --git a/arch/arm64/kvm/hyp/tlb.c b/arch/arm64/kvm/hyp/tlb.c</span>
<span class="quote">&gt; index 4cda100..1210f58 100644</span>
<span class="quote">&gt; --- a/arch/arm64/kvm/hyp/tlb.c</span>
<span class="quote">&gt; +++ b/arch/arm64/kvm/hyp/tlb.c</span>
<span class="quote">&gt; @@ -78,3 +78,72 @@ static void __hyp_text __tlb_flush_vm_context(void)</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  __alias(__tlb_flush_vm_context) void __kvm_flush_vm_context(void);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +/* Intentionally empty functions */</span>
<span class="quote">&gt; +static void __hyp_text __switch_to_hyp_role_nvhe(void) { }</span>
<span class="quote">&gt; +static void __hyp_text __switch_to_host_role_nvhe(void) { }</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +static void __hyp_text __switch_to_hyp_role_vhe(void)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	u64 hcr = read_sysreg(hcr_el2);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	hcr &amp;= ~HCR_TGE;</span>
<span class="quote">&gt; +	write_sysreg(hcr, hcr_el2);</span>

why do we need to clear TGE for the TLB maintenance instructions to
work?

Perhaps this is worth explaining in a comment.

Otherwise this looks ok to me.

-Christoffer
<span class="quote">
&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +static void __hyp_text __switch_to_host_role_vhe(void)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	u64 hcr = read_sysreg(hcr_el2);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	hcr |= HCR_TGE;</span>
<span class="quote">&gt; +	write_sysreg(hcr, hcr_el2);</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +static hyp_alternate_select(__switch_to_hyp_role,</span>
<span class="quote">&gt; +			    __switch_to_hyp_role_nvhe,</span>
<span class="quote">&gt; +			    __switch_to_hyp_role_vhe,</span>
<span class="quote">&gt; +			    ARM64_HAS_VIRT_HOST_EXTN);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +static hyp_alternate_select(__switch_to_host_role,</span>
<span class="quote">&gt; +			    __switch_to_host_role_nvhe,</span>
<span class="quote">&gt; +			    __switch_to_host_role_vhe,</span>
<span class="quote">&gt; +			    ARM64_HAS_VIRT_HOST_EXTN);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +static void __hyp_text __switch_to_guest_regime(struct kvm *kvm)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	write_sysreg(kvm-&gt;arch.vttbr, vttbr_el2);</span>
<span class="quote">&gt; +	__switch_to_hyp_role();</span>
<span class="quote">&gt; +	isb();</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +static void __hyp_text __switch_to_host_regime(void)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	__switch_to_host_role();</span>
<span class="quote">&gt; +	write_sysreg(0, vttbr_el2);</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +void __hyp_text</span>
<span class="quote">&gt; +__kvm_emulate_tlb_invalidate(struct kvm *kvm, u32 sys_op, u64 regval)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	kvm = kern_hyp_va(kvm);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	/*</span>
<span class="quote">&gt; +	 * Switch to the guest before performing any TLB operations to</span>
<span class="quote">&gt; +	 * target the appropriate VMID</span>
<span class="quote">&gt; +	 */</span>
<span class="quote">&gt; +	__switch_to_guest_regime(kvm);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	/*</span>
<span class="quote">&gt; +	 *  TLB maintenance operations are broadcast to</span>
<span class="quote">&gt; +	 *  inner-shareable domain when HCR_FB is set (default for</span>
<span class="quote">&gt; +	 *  KVM).</span>
<span class="quote">&gt; +	 *</span>
<span class="quote">&gt; +	 *  Nuke all Stage 1 TLB entries for the VM. This will kill</span>
<span class="quote">&gt; +	 *  performance but it&#39;s always safe to do as we don&#39;t leave</span>
<span class="quote">&gt; +	 *  behind any strays in the TLB</span>
<span class="quote">&gt; +	 */</span>
<span class="quote">&gt; +	__tlbi(vmalle1is);</span>
<span class="quote">&gt; +	isb();</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	__switch_to_host_regime();</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; diff --git a/arch/arm64/kvm/sys_regs.c b/arch/arm64/kvm/sys_regs.c</span>
<span class="quote">&gt; index e51367d..0e70da9 100644</span>
<span class="quote">&gt; --- a/arch/arm64/kvm/sys_regs.c</span>
<span class="quote">&gt; +++ b/arch/arm64/kvm/sys_regs.c</span>
<span class="quote">&gt; @@ -790,6 +790,18 @@ static bool access_pmuserenr(struct kvm_vcpu *vcpu, struct sys_reg_params *p,</span>
<span class="quote">&gt;  	return true;</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; +static bool emulate_tlb_invalidate(struct kvm_vcpu *vcpu, struct sys_reg_params *p,</span>
<span class="quote">&gt; +				  const struct sys_reg_desc *r)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	u32 opcode = sys_reg(p-&gt;Op0, p-&gt;Op1, p-&gt;CRn, p-&gt;CRm, p-&gt;Op2);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	kvm_call_hyp(__kvm_emulate_tlb_invalidate,</span>
<span class="quote">&gt; +		     vcpu-&gt;kvm, opcode, p-&gt;regval);</span>
<span class="quote">&gt; +	trace_kvm_tlb_invalidate(*vcpu_pc(vcpu), opcode);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	return true;</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt;  /* Silly macro to expand the DBG{BCR,BVR,WVR,WCR}n_EL1 registers in one go */</span>
<span class="quote">&gt;  #define DBG_BCR_BVR_WCR_WVR_EL1(n)					\</span>
<span class="quote">&gt;  	/* DBGBVRn_EL1 */						\</span>
<span class="quote">&gt; @@ -841,6 +853,35 @@ static const struct sys_reg_desc sys_reg_descs[] = {</span>
<span class="quote">&gt;  	{ Op0(0b01), Op1(0b000), CRn(0b0111), CRm(0b1110), Op2(0b010),</span>
<span class="quote">&gt;  	  access_dcsw },</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; +	/*</span>
<span class="quote">&gt; +	 * ARMv8 ARM: Table C5-4 TLB maintenance instructions</span>
<span class="quote">&gt; +	 * (Ref: ARMv8 ARM C5.1 version: ARM DDI 0487A.j)</span>
<span class="quote">&gt; +	 */</span>
<span class="quote">&gt; +	/* TLBI VMALLE1IS */</span>
<span class="quote">&gt; +	{ Op0(1), Op1(0), CRn(8), CRm(3), Op2(0), emulate_tlb_invalidate },</span>
<span class="quote">&gt; +	/* TLBI VAE1IS */</span>
<span class="quote">&gt; +	{ Op0(1), Op1(0), CRn(8), CRm(3), Op2(1), emulate_tlb_invalidate },</span>
<span class="quote">&gt; +	/* TLBI ASIDE1IS */</span>
<span class="quote">&gt; +	{ Op0(1), Op1(0), CRn(8), CRm(3), Op2(2), emulate_tlb_invalidate },</span>
<span class="quote">&gt; +	/* TLBI VAAE1IS */</span>
<span class="quote">&gt; +	{ Op0(1), Op1(0), CRn(8), CRm(3), Op2(3), emulate_tlb_invalidate },</span>
<span class="quote">&gt; +	/* TLBI VALE1IS */</span>
<span class="quote">&gt; +	{ Op0(1), Op1(0), CRn(8), CRm(3), Op2(5), emulate_tlb_invalidate },</span>
<span class="quote">&gt; +	/* TLBI VAALE1IS */</span>
<span class="quote">&gt; +	{ Op0(1), Op1(0), CRn(8), CRm(3), Op2(7), emulate_tlb_invalidate },</span>
<span class="quote">&gt; +	/* TLBI VMALLE1 */</span>
<span class="quote">&gt; +	{ Op0(1), Op1(0), CRn(8), CRm(7), Op2(0), emulate_tlb_invalidate },</span>
<span class="quote">&gt; +	/* TLBI VAE1 */</span>
<span class="quote">&gt; +	{ Op0(1), Op1(0), CRn(8), CRm(7), Op2(1), emulate_tlb_invalidate },</span>
<span class="quote">&gt; +	/* TLBI ASIDE1 */</span>
<span class="quote">&gt; +	{ Op0(1), Op1(0), CRn(8), CRm(7), Op2(2), emulate_tlb_invalidate },</span>
<span class="quote">&gt; +	/* TLBI VAAE1 */</span>
<span class="quote">&gt; +	{ Op0(1), Op1(0), CRn(8), CRm(7), Op2(3), emulate_tlb_invalidate },</span>
<span class="quote">&gt; +	/* TLBI VALE1 */</span>
<span class="quote">&gt; +	{ Op0(1), Op1(0), CRn(8), CRm(7), Op2(5), emulate_tlb_invalidate },</span>
<span class="quote">&gt; +	/* TLBI VAALE1 */</span>
<span class="quote">&gt; +	{ Op0(1), Op1(0), CRn(8), CRm(7), Op2(7), emulate_tlb_invalidate },</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt;  	DBG_BCR_BVR_WCR_WVR_EL1(0),</span>
<span class="quote">&gt;  	DBG_BCR_BVR_WCR_WVR_EL1(1),</span>
<span class="quote">&gt;  	/* MDCCINT_EL1 */</span>
<span class="quote">&gt; @@ -1329,6 +1370,46 @@ static const struct sys_reg_desc cp15_regs[] = {</span>
<span class="quote">&gt;  	{ Op1( 0), CRn( 7), CRm(10), Op2( 2), access_dcsw },</span>
<span class="quote">&gt;  	{ Op1( 0), CRn( 7), CRm(14), Op2( 2), access_dcsw },</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; +	/*</span>
<span class="quote">&gt; +	 * TLB operations</span>
<span class="quote">&gt; +	 */</span>
<span class="quote">&gt; +	/* TLBIALLIS */</span>
<span class="quote">&gt; +	{ Op1( 0), CRn( 8), CRm( 3), Op2( 0), emulate_tlb_invalidate},</span>
<span class="quote">&gt; +	/* TLBIMVAIS */</span>
<span class="quote">&gt; +	{ Op1( 0), CRn( 8), CRm( 3), Op2( 1), emulate_tlb_invalidate},</span>
<span class="quote">&gt; +	/* TLBIASIDIS */</span>
<span class="quote">&gt; +	{ Op1( 0), CRn( 8), CRm( 3), Op2( 2), emulate_tlb_invalidate},</span>
<span class="quote">&gt; +	/* TLBIMVAAIS */</span>
<span class="quote">&gt; +	{ Op1( 0), CRn( 8), CRm( 3), Op2( 3), emulate_tlb_invalidate},</span>
<span class="quote">&gt; +	/* TLBIMVALIS */</span>
<span class="quote">&gt; +	{ Op1( 0), CRn( 8), CRm( 3), Op2( 5), emulate_tlb_invalidate},</span>
<span class="quote">&gt; +	/* TLBIMVAALIS */</span>
<span class="quote">&gt; +	{ Op1( 0), CRn( 8), CRm( 3), Op2( 7), emulate_tlb_invalidate},</span>
<span class="quote">&gt; +	/* ITLBIALL */</span>
<span class="quote">&gt; +	{ Op1( 0), CRn( 8), CRm( 5), Op2( 0), emulate_tlb_invalidate},</span>
<span class="quote">&gt; +	/* ITLBIMVA */</span>
<span class="quote">&gt; +	{ Op1( 0), CRn( 8), CRm( 5), Op2( 1), emulate_tlb_invalidate},</span>
<span class="quote">&gt; +	/* ITLBIASID */</span>
<span class="quote">&gt; +	{ Op1( 0), CRn( 8), CRm( 5), Op2( 2), emulate_tlb_invalidate},</span>
<span class="quote">&gt; +	/* DTLBIALL */</span>
<span class="quote">&gt; +	{ Op1( 0), CRn( 8), CRm( 6), Op2( 0), emulate_tlb_invalidate},</span>
<span class="quote">&gt; +	/* DTLBIMVA */</span>
<span class="quote">&gt; +	{ Op1( 0), CRn( 8), CRm( 6), Op2( 1), emulate_tlb_invalidate},</span>
<span class="quote">&gt; +	/* DTLBIASID */</span>
<span class="quote">&gt; +	{ Op1( 0), CRn( 8), CRm( 6), Op2( 2), emulate_tlb_invalidate},</span>
<span class="quote">&gt; +	/* TLBIALL */</span>
<span class="quote">&gt; +	{ Op1( 0), CRn( 8), CRm( 7), Op2( 0), emulate_tlb_invalidate},</span>
<span class="quote">&gt; +	/* TLBIMVA */</span>
<span class="quote">&gt; +	{ Op1( 0), CRn( 8), CRm( 7), Op2( 1), emulate_tlb_invalidate},</span>
<span class="quote">&gt; +	/* TLBIASID */</span>
<span class="quote">&gt; +	{ Op1( 0), CRn( 8), CRm( 7), Op2( 2), emulate_tlb_invalidate},</span>
<span class="quote">&gt; +	/* TLBIMVAA */</span>
<span class="quote">&gt; +	{ Op1( 0), CRn( 8), CRm( 7), Op2( 3), emulate_tlb_invalidate},</span>
<span class="quote">&gt; +	/* TLBIMVAL */</span>
<span class="quote">&gt; +	{ Op1( 0), CRn( 8), CRm( 7), Op2( 5), emulate_tlb_invalidate},</span>
<span class="quote">&gt; +	/* TLBIMVAAL */</span>
<span class="quote">&gt; +	{ Op1( 0), CRn( 8), CRm( 7), Op2( 7), emulate_tlb_invalidate},</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt;  	/* PMU */</span>
<span class="quote">&gt;  	{ Op1( 0), CRn( 9), CRm(12), Op2( 0), access_pmcr },</span>
<span class="quote">&gt;  	{ Op1( 0), CRn( 9), CRm(12), Op2( 1), access_pmcnten },</span>
<span class="quote">&gt; diff --git a/arch/arm64/kvm/trace.h b/arch/arm64/kvm/trace.h</span>
<span class="quote">&gt; index 7fb0008..c4d577f 100644</span>
<span class="quote">&gt; --- a/arch/arm64/kvm/trace.h</span>
<span class="quote">&gt; +++ b/arch/arm64/kvm/trace.h</span>
<span class="quote">&gt; @@ -166,6 +166,22 @@ TRACE_EVENT(kvm_set_guest_debug,</span>
<span class="quote">&gt;  	TP_printk(&quot;vcpu: %p, flags: 0x%08x&quot;, __entry-&gt;vcpu, __entry-&gt;guest_debug)</span>
<span class="quote">&gt;  );</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; +TRACE_EVENT(kvm_tlb_invalidate,</span>
<span class="quote">&gt; +	TP_PROTO(unsigned long vcpu_pc, u32 opcode),</span>
<span class="quote">&gt; +	TP_ARGS(vcpu_pc, opcode),</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	TP_STRUCT__entry(</span>
<span class="quote">&gt; +		__field(unsigned long, vcpu_pc)</span>
<span class="quote">&gt; +		__field(u32, opcode)</span>
<span class="quote">&gt; +	),</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	TP_fast_assign(</span>
<span class="quote">&gt; +		__entry-&gt;vcpu_pc = vcpu_pc;</span>
<span class="quote">&gt; +		__entry-&gt;opcode = opcode;</span>
<span class="quote">&gt; +	),</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	TP_printk(&quot;vcpu_pc=0x%16lx opcode=%08x&quot;, __entry-&gt;vcpu_pc, __entry-&gt;opcode)</span>
<span class="quote">&gt; +);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  #endif /* _TRACE_ARM64_KVM_H */</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; -- </span>
<span class="quote">&gt; 2.8.1</span>
<span class="quote">&gt;</span>
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=58591">Punit Agrawal</a> - Sept. 6, 2016, 3:44 p.m.</div>
<pre class="content">
Christoffer Dall &lt;christoffer.dall@linaro.org&gt; writes:
<span class="quote">
&gt; On Mon, Sep 05, 2016 at 05:31:36PM +0100, Punit Agrawal wrote:</span>
<span class="quote">&gt;&gt; The ARMv8 architecture allows trapping of TLB maintenane instructions</span>
<span class="quote">&gt;&gt; from EL0/EL1 to higher exception levels. On encountering a trappable TLB</span>
<span class="quote">&gt;&gt; instruction in a guest, an exception is taken to EL2.</span>
<span class="quote">&gt;&gt; </span>
<span class="quote">&gt;&gt; Add functionality to handle emulating the TLB instructions.</span>
<span class="quote">&gt;&gt; </span>
<span class="quote">&gt;&gt; Signed-off-by: Punit Agrawal &lt;punit.agrawal@arm.com&gt;</span>
<span class="quote">&gt;&gt; Cc: Christoffer Dall &lt;christoffer.dall@linaro.org&gt;</span>
<span class="quote">&gt;&gt; Cc: Marc Zyngier &lt;marc.zyngier@arm.com&gt;</span>
<span class="quote">&gt;&gt; ---</span>
<span class="quote">&gt;&gt;  arch/arm64/include/asm/kvm_asm.h |  1 +</span>
<span class="quote">&gt;&gt;  arch/arm64/kvm/hyp/tlb.c         | 69 ++++++++++++++++++++++++++++++++++</span>
<span class="quote">&gt;&gt;  arch/arm64/kvm/sys_regs.c        | 81 ++++++++++++++++++++++++++++++++++++++++</span>
<span class="quote">&gt;&gt;  arch/arm64/kvm/trace.h           | 16 ++++++++</span>
<span class="quote">&gt;&gt;  4 files changed, 167 insertions(+)</span>
<span class="quote">&gt;&gt; </span>
<span class="quote">&gt;&gt; diff --git a/arch/arm64/include/asm/kvm_asm.h b/arch/arm64/include/asm/kvm_asm.h</span>
<span class="quote">&gt;&gt; index 7561f63..1ac1cc3 100644</span>
<span class="quote">&gt;&gt; --- a/arch/arm64/include/asm/kvm_asm.h</span>
<span class="quote">&gt;&gt; +++ b/arch/arm64/include/asm/kvm_asm.h</span>
<span class="quote">&gt;&gt; @@ -49,6 +49,7 @@ extern char __kvm_hyp_vector[];</span>
<span class="quote">&gt;&gt;  extern void __kvm_flush_vm_context(void);</span>
<span class="quote">&gt;&gt;  extern void __kvm_tlb_flush_vmid_ipa(struct kvm *kvm, phys_addr_t ipa);</span>
<span class="quote">&gt;&gt;  extern void __kvm_tlb_flush_vmid(struct kvm *kvm);</span>
<span class="quote">&gt;&gt; +extern void __kvm_emulate_tlb_invalidate(struct kvm *kvm, u32 sysreg, u64 regval);</span>
<span class="quote">&gt;&gt;  </span>
<span class="quote">&gt;&gt;  extern int __kvm_vcpu_run(struct kvm_vcpu *vcpu);</span>
<span class="quote">&gt;&gt;  </span>
<span class="quote">&gt;&gt; diff --git a/arch/arm64/kvm/hyp/tlb.c b/arch/arm64/kvm/hyp/tlb.c</span>
<span class="quote">&gt;&gt; index 4cda100..1210f58 100644</span>
<span class="quote">&gt;&gt; --- a/arch/arm64/kvm/hyp/tlb.c</span>
<span class="quote">&gt;&gt; +++ b/arch/arm64/kvm/hyp/tlb.c</span>
<span class="quote">&gt;&gt; @@ -78,3 +78,72 @@ static void __hyp_text __tlb_flush_vm_context(void)</span>
<span class="quote">&gt;&gt;  }</span>
<span class="quote">&gt;&gt;  </span>
<span class="quote">&gt;&gt;  __alias(__tlb_flush_vm_context) void __kvm_flush_vm_context(void);</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +/* Intentionally empty functions */</span>
<span class="quote">&gt;&gt; +static void __hyp_text __switch_to_hyp_role_nvhe(void) { }</span>
<span class="quote">&gt;&gt; +static void __hyp_text __switch_to_host_role_nvhe(void) { }</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +static void __hyp_text __switch_to_hyp_role_vhe(void)</span>
<span class="quote">&gt;&gt; +{</span>
<span class="quote">&gt;&gt; +	u64 hcr = read_sysreg(hcr_el2);</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +	hcr &amp;= ~HCR_TGE;</span>
<span class="quote">&gt;&gt; +	write_sysreg(hcr, hcr_el2);</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; why do we need to clear TGE for the TLB maintenance instructions to</span>
<span class="quote">&gt; work?</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; Perhaps this is worth explaining in a comment.</span>

I&#39;ve added the following comment before clearing TGE bit.

&quot;When VHE is enabled and HCR_EL2.TGE=1, EL1&amp;0 TLB operations
apply to EL2&amp;0 translation regime. As we prepare to emulate
guest TLB operation clear HCR_TGE to target TLB operations
to EL1&amp;0 (guest).&quot;
<span class="quote">
&gt;</span>
<span class="quote">&gt; Otherwise this looks ok to me.</span>

Thanks for taking a look.

Punit
<span class="quote">
&gt;</span>
<span class="quote">&gt; -Christoffer</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;&gt; +}</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +static void __hyp_text __switch_to_host_role_vhe(void)</span>
<span class="quote">&gt;&gt; +{</span>
<span class="quote">&gt;&gt; +	u64 hcr = read_sysreg(hcr_el2);</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +	hcr |= HCR_TGE;</span>
<span class="quote">&gt;&gt; +	write_sysreg(hcr, hcr_el2);</span>
<span class="quote">&gt;&gt; +}</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +static hyp_alternate_select(__switch_to_hyp_role,</span>
<span class="quote">&gt;&gt; +			    __switch_to_hyp_role_nvhe,</span>
<span class="quote">&gt;&gt; +			    __switch_to_hyp_role_vhe,</span>
<span class="quote">&gt;&gt; +			    ARM64_HAS_VIRT_HOST_EXTN);</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +static hyp_alternate_select(__switch_to_host_role,</span>
<span class="quote">&gt;&gt; +			    __switch_to_host_role_nvhe,</span>
<span class="quote">&gt;&gt; +			    __switch_to_host_role_vhe,</span>
<span class="quote">&gt;&gt; +			    ARM64_HAS_VIRT_HOST_EXTN);</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +static void __hyp_text __switch_to_guest_regime(struct kvm *kvm)</span>
<span class="quote">&gt;&gt; +{</span>
<span class="quote">&gt;&gt; +	write_sysreg(kvm-&gt;arch.vttbr, vttbr_el2);</span>
<span class="quote">&gt;&gt; +	__switch_to_hyp_role();</span>
<span class="quote">&gt;&gt; +	isb();</span>
<span class="quote">&gt;&gt; +}</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +static void __hyp_text __switch_to_host_regime(void)</span>
<span class="quote">&gt;&gt; +{</span>
<span class="quote">&gt;&gt; +	__switch_to_host_role();</span>
<span class="quote">&gt;&gt; +	write_sysreg(0, vttbr_el2);</span>
<span class="quote">&gt;&gt; +}</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +void __hyp_text</span>
<span class="quote">&gt;&gt; +__kvm_emulate_tlb_invalidate(struct kvm *kvm, u32 sys_op, u64 regval)</span>
<span class="quote">&gt;&gt; +{</span>
<span class="quote">&gt;&gt; +	kvm = kern_hyp_va(kvm);</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +	/*</span>
<span class="quote">&gt;&gt; +	 * Switch to the guest before performing any TLB operations to</span>
<span class="quote">&gt;&gt; +	 * target the appropriate VMID</span>
<span class="quote">&gt;&gt; +	 */</span>
<span class="quote">&gt;&gt; +	__switch_to_guest_regime(kvm);</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +	/*</span>
<span class="quote">&gt;&gt; +	 *  TLB maintenance operations are broadcast to</span>
<span class="quote">&gt;&gt; +	 *  inner-shareable domain when HCR_FB is set (default for</span>
<span class="quote">&gt;&gt; +	 *  KVM).</span>
<span class="quote">&gt;&gt; +	 *</span>
<span class="quote">&gt;&gt; +	 *  Nuke all Stage 1 TLB entries for the VM. This will kill</span>
<span class="quote">&gt;&gt; +	 *  performance but it&#39;s always safe to do as we don&#39;t leave</span>
<span class="quote">&gt;&gt; +	 *  behind any strays in the TLB</span>
<span class="quote">&gt;&gt; +	 */</span>
<span class="quote">&gt;&gt; +	__tlbi(vmalle1is);</span>
<span class="quote">&gt;&gt; +	isb();</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +	__switch_to_host_regime();</span>
<span class="quote">&gt;&gt; +}</span>
<span class="quote">&gt;&gt; diff --git a/arch/arm64/kvm/sys_regs.c b/arch/arm64/kvm/sys_regs.c</span>
<span class="quote">&gt;&gt; index e51367d..0e70da9 100644</span>
<span class="quote">&gt;&gt; --- a/arch/arm64/kvm/sys_regs.c</span>
<span class="quote">&gt;&gt; +++ b/arch/arm64/kvm/sys_regs.c</span>
<span class="quote">&gt;&gt; @@ -790,6 +790,18 @@ static bool access_pmuserenr(struct kvm_vcpu *vcpu, struct sys_reg_params *p,</span>
<span class="quote">&gt;&gt;  	return true;</span>
<span class="quote">&gt;&gt;  }</span>
<span class="quote">&gt;&gt;  </span>
<span class="quote">&gt;&gt; +static bool emulate_tlb_invalidate(struct kvm_vcpu *vcpu, struct sys_reg_params *p,</span>
<span class="quote">&gt;&gt; +				  const struct sys_reg_desc *r)</span>
<span class="quote">&gt;&gt; +{</span>
<span class="quote">&gt;&gt; +	u32 opcode = sys_reg(p-&gt;Op0, p-&gt;Op1, p-&gt;CRn, p-&gt;CRm, p-&gt;Op2);</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +	kvm_call_hyp(__kvm_emulate_tlb_invalidate,</span>
<span class="quote">&gt;&gt; +		     vcpu-&gt;kvm, opcode, p-&gt;regval);</span>
<span class="quote">&gt;&gt; +	trace_kvm_tlb_invalidate(*vcpu_pc(vcpu), opcode);</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +	return true;</span>
<span class="quote">&gt;&gt; +}</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt;  /* Silly macro to expand the DBG{BCR,BVR,WVR,WCR}n_EL1 registers in one go */</span>
<span class="quote">&gt;&gt;  #define DBG_BCR_BVR_WCR_WVR_EL1(n)					\</span>
<span class="quote">&gt;&gt;  	/* DBGBVRn_EL1 */						\</span>
<span class="quote">&gt;&gt; @@ -841,6 +853,35 @@ static const struct sys_reg_desc sys_reg_descs[] = {</span>
<span class="quote">&gt;&gt;  	{ Op0(0b01), Op1(0b000), CRn(0b0111), CRm(0b1110), Op2(0b010),</span>
<span class="quote">&gt;&gt;  	  access_dcsw },</span>
<span class="quote">&gt;&gt;  </span>
<span class="quote">&gt;&gt; +	/*</span>
<span class="quote">&gt;&gt; +	 * ARMv8 ARM: Table C5-4 TLB maintenance instructions</span>
<span class="quote">&gt;&gt; +	 * (Ref: ARMv8 ARM C5.1 version: ARM DDI 0487A.j)</span>
<span class="quote">&gt;&gt; +	 */</span>
<span class="quote">&gt;&gt; +	/* TLBI VMALLE1IS */</span>
<span class="quote">&gt;&gt; +	{ Op0(1), Op1(0), CRn(8), CRm(3), Op2(0), emulate_tlb_invalidate },</span>
<span class="quote">&gt;&gt; +	/* TLBI VAE1IS */</span>
<span class="quote">&gt;&gt; +	{ Op0(1), Op1(0), CRn(8), CRm(3), Op2(1), emulate_tlb_invalidate },</span>
<span class="quote">&gt;&gt; +	/* TLBI ASIDE1IS */</span>
<span class="quote">&gt;&gt; +	{ Op0(1), Op1(0), CRn(8), CRm(3), Op2(2), emulate_tlb_invalidate },</span>
<span class="quote">&gt;&gt; +	/* TLBI VAAE1IS */</span>
<span class="quote">&gt;&gt; +	{ Op0(1), Op1(0), CRn(8), CRm(3), Op2(3), emulate_tlb_invalidate },</span>
<span class="quote">&gt;&gt; +	/* TLBI VALE1IS */</span>
<span class="quote">&gt;&gt; +	{ Op0(1), Op1(0), CRn(8), CRm(3), Op2(5), emulate_tlb_invalidate },</span>
<span class="quote">&gt;&gt; +	/* TLBI VAALE1IS */</span>
<span class="quote">&gt;&gt; +	{ Op0(1), Op1(0), CRn(8), CRm(3), Op2(7), emulate_tlb_invalidate },</span>
<span class="quote">&gt;&gt; +	/* TLBI VMALLE1 */</span>
<span class="quote">&gt;&gt; +	{ Op0(1), Op1(0), CRn(8), CRm(7), Op2(0), emulate_tlb_invalidate },</span>
<span class="quote">&gt;&gt; +	/* TLBI VAE1 */</span>
<span class="quote">&gt;&gt; +	{ Op0(1), Op1(0), CRn(8), CRm(7), Op2(1), emulate_tlb_invalidate },</span>
<span class="quote">&gt;&gt; +	/* TLBI ASIDE1 */</span>
<span class="quote">&gt;&gt; +	{ Op0(1), Op1(0), CRn(8), CRm(7), Op2(2), emulate_tlb_invalidate },</span>
<span class="quote">&gt;&gt; +	/* TLBI VAAE1 */</span>
<span class="quote">&gt;&gt; +	{ Op0(1), Op1(0), CRn(8), CRm(7), Op2(3), emulate_tlb_invalidate },</span>
<span class="quote">&gt;&gt; +	/* TLBI VALE1 */</span>
<span class="quote">&gt;&gt; +	{ Op0(1), Op1(0), CRn(8), CRm(7), Op2(5), emulate_tlb_invalidate },</span>
<span class="quote">&gt;&gt; +	/* TLBI VAALE1 */</span>
<span class="quote">&gt;&gt; +	{ Op0(1), Op1(0), CRn(8), CRm(7), Op2(7), emulate_tlb_invalidate },</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt;  	DBG_BCR_BVR_WCR_WVR_EL1(0),</span>
<span class="quote">&gt;&gt;  	DBG_BCR_BVR_WCR_WVR_EL1(1),</span>
<span class="quote">&gt;&gt;  	/* MDCCINT_EL1 */</span>
<span class="quote">&gt;&gt; @@ -1329,6 +1370,46 @@ static const struct sys_reg_desc cp15_regs[] = {</span>
<span class="quote">&gt;&gt;  	{ Op1( 0), CRn( 7), CRm(10), Op2( 2), access_dcsw },</span>
<span class="quote">&gt;&gt;  	{ Op1( 0), CRn( 7), CRm(14), Op2( 2), access_dcsw },</span>
<span class="quote">&gt;&gt;  </span>
<span class="quote">&gt;&gt; +	/*</span>
<span class="quote">&gt;&gt; +	 * TLB operations</span>
<span class="quote">&gt;&gt; +	 */</span>
<span class="quote">&gt;&gt; +	/* TLBIALLIS */</span>
<span class="quote">&gt;&gt; +	{ Op1( 0), CRn( 8), CRm( 3), Op2( 0), emulate_tlb_invalidate},</span>
<span class="quote">&gt;&gt; +	/* TLBIMVAIS */</span>
<span class="quote">&gt;&gt; +	{ Op1( 0), CRn( 8), CRm( 3), Op2( 1), emulate_tlb_invalidate},</span>
<span class="quote">&gt;&gt; +	/* TLBIASIDIS */</span>
<span class="quote">&gt;&gt; +	{ Op1( 0), CRn( 8), CRm( 3), Op2( 2), emulate_tlb_invalidate},</span>
<span class="quote">&gt;&gt; +	/* TLBIMVAAIS */</span>
<span class="quote">&gt;&gt; +	{ Op1( 0), CRn( 8), CRm( 3), Op2( 3), emulate_tlb_invalidate},</span>
<span class="quote">&gt;&gt; +	/* TLBIMVALIS */</span>
<span class="quote">&gt;&gt; +	{ Op1( 0), CRn( 8), CRm( 3), Op2( 5), emulate_tlb_invalidate},</span>
<span class="quote">&gt;&gt; +	/* TLBIMVAALIS */</span>
<span class="quote">&gt;&gt; +	{ Op1( 0), CRn( 8), CRm( 3), Op2( 7), emulate_tlb_invalidate},</span>
<span class="quote">&gt;&gt; +	/* ITLBIALL */</span>
<span class="quote">&gt;&gt; +	{ Op1( 0), CRn( 8), CRm( 5), Op2( 0), emulate_tlb_invalidate},</span>
<span class="quote">&gt;&gt; +	/* ITLBIMVA */</span>
<span class="quote">&gt;&gt; +	{ Op1( 0), CRn( 8), CRm( 5), Op2( 1), emulate_tlb_invalidate},</span>
<span class="quote">&gt;&gt; +	/* ITLBIASID */</span>
<span class="quote">&gt;&gt; +	{ Op1( 0), CRn( 8), CRm( 5), Op2( 2), emulate_tlb_invalidate},</span>
<span class="quote">&gt;&gt; +	/* DTLBIALL */</span>
<span class="quote">&gt;&gt; +	{ Op1( 0), CRn( 8), CRm( 6), Op2( 0), emulate_tlb_invalidate},</span>
<span class="quote">&gt;&gt; +	/* DTLBIMVA */</span>
<span class="quote">&gt;&gt; +	{ Op1( 0), CRn( 8), CRm( 6), Op2( 1), emulate_tlb_invalidate},</span>
<span class="quote">&gt;&gt; +	/* DTLBIASID */</span>
<span class="quote">&gt;&gt; +	{ Op1( 0), CRn( 8), CRm( 6), Op2( 2), emulate_tlb_invalidate},</span>
<span class="quote">&gt;&gt; +	/* TLBIALL */</span>
<span class="quote">&gt;&gt; +	{ Op1( 0), CRn( 8), CRm( 7), Op2( 0), emulate_tlb_invalidate},</span>
<span class="quote">&gt;&gt; +	/* TLBIMVA */</span>
<span class="quote">&gt;&gt; +	{ Op1( 0), CRn( 8), CRm( 7), Op2( 1), emulate_tlb_invalidate},</span>
<span class="quote">&gt;&gt; +	/* TLBIASID */</span>
<span class="quote">&gt;&gt; +	{ Op1( 0), CRn( 8), CRm( 7), Op2( 2), emulate_tlb_invalidate},</span>
<span class="quote">&gt;&gt; +	/* TLBIMVAA */</span>
<span class="quote">&gt;&gt; +	{ Op1( 0), CRn( 8), CRm( 7), Op2( 3), emulate_tlb_invalidate},</span>
<span class="quote">&gt;&gt; +	/* TLBIMVAL */</span>
<span class="quote">&gt;&gt; +	{ Op1( 0), CRn( 8), CRm( 7), Op2( 5), emulate_tlb_invalidate},</span>
<span class="quote">&gt;&gt; +	/* TLBIMVAAL */</span>
<span class="quote">&gt;&gt; +	{ Op1( 0), CRn( 8), CRm( 7), Op2( 7), emulate_tlb_invalidate},</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt;  	/* PMU */</span>
<span class="quote">&gt;&gt;  	{ Op1( 0), CRn( 9), CRm(12), Op2( 0), access_pmcr },</span>
<span class="quote">&gt;&gt;  	{ Op1( 0), CRn( 9), CRm(12), Op2( 1), access_pmcnten },</span>
<span class="quote">&gt;&gt; diff --git a/arch/arm64/kvm/trace.h b/arch/arm64/kvm/trace.h</span>
<span class="quote">&gt;&gt; index 7fb0008..c4d577f 100644</span>
<span class="quote">&gt;&gt; --- a/arch/arm64/kvm/trace.h</span>
<span class="quote">&gt;&gt; +++ b/arch/arm64/kvm/trace.h</span>
<span class="quote">&gt;&gt; @@ -166,6 +166,22 @@ TRACE_EVENT(kvm_set_guest_debug,</span>
<span class="quote">&gt;&gt;  	TP_printk(&quot;vcpu: %p, flags: 0x%08x&quot;, __entry-&gt;vcpu, __entry-&gt;guest_debug)</span>
<span class="quote">&gt;&gt;  );</span>
<span class="quote">&gt;&gt;  </span>
<span class="quote">&gt;&gt; +TRACE_EVENT(kvm_tlb_invalidate,</span>
<span class="quote">&gt;&gt; +	TP_PROTO(unsigned long vcpu_pc, u32 opcode),</span>
<span class="quote">&gt;&gt; +	TP_ARGS(vcpu_pc, opcode),</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +	TP_STRUCT__entry(</span>
<span class="quote">&gt;&gt; +		__field(unsigned long, vcpu_pc)</span>
<span class="quote">&gt;&gt; +		__field(u32, opcode)</span>
<span class="quote">&gt;&gt; +	),</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +	TP_fast_assign(</span>
<span class="quote">&gt;&gt; +		__entry-&gt;vcpu_pc = vcpu_pc;</span>
<span class="quote">&gt;&gt; +		__entry-&gt;opcode = opcode;</span>
<span class="quote">&gt;&gt; +	),</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +	TP_printk(&quot;vcpu_pc=0x%16lx opcode=%08x&quot;, __entry-&gt;vcpu_pc, __entry-&gt;opcode)</span>
<span class="quote">&gt;&gt; +);</span>
<span class="quote">&gt;&gt;  </span>
<span class="quote">&gt;&gt;  #endif /* _TRACE_ARM64_KVM_H */</span>
<span class="quote">&gt;&gt;  </span>
<span class="quote">&gt;&gt; -- </span>
<span class="quote">&gt;&gt; 2.8.1</span>
<span class="quote">&gt;&gt; </span>
<span class="quote">&gt; _______________________________________________</span>
<span class="quote">&gt; kvmarm mailing list</span>
<span class="quote">&gt; kvmarm@lists.cs.columbia.edu</span>
<span class="quote">&gt; https://lists.cs.columbia.edu/mailman/listinfo/kvmarm</span>
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=68151">Christoffer Dall</a> - Sept. 6, 2016, 4:59 p.m.</div>
<pre class="content">
On Tue, Sep 06, 2016 at 04:44:11PM +0100, Punit Agrawal wrote:
<span class="quote">&gt; Christoffer Dall &lt;christoffer.dall@linaro.org&gt; writes:</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; &gt; On Mon, Sep 05, 2016 at 05:31:36PM +0100, Punit Agrawal wrote:</span>
<span class="quote">&gt; &gt;&gt; The ARMv8 architecture allows trapping of TLB maintenane instructions</span>
<span class="quote">&gt; &gt;&gt; from EL0/EL1 to higher exception levels. On encountering a trappable TLB</span>
<span class="quote">&gt; &gt;&gt; instruction in a guest, an exception is taken to EL2.</span>
<span class="quote">&gt; &gt;&gt; </span>
<span class="quote">&gt; &gt;&gt; Add functionality to handle emulating the TLB instructions.</span>
<span class="quote">&gt; &gt;&gt; </span>
<span class="quote">&gt; &gt;&gt; Signed-off-by: Punit Agrawal &lt;punit.agrawal@arm.com&gt;</span>
<span class="quote">&gt; &gt;&gt; Cc: Christoffer Dall &lt;christoffer.dall@linaro.org&gt;</span>
<span class="quote">&gt; &gt;&gt; Cc: Marc Zyngier &lt;marc.zyngier@arm.com&gt;</span>
<span class="quote">&gt; &gt;&gt; ---</span>
<span class="quote">&gt; &gt;&gt;  arch/arm64/include/asm/kvm_asm.h |  1 +</span>
<span class="quote">&gt; &gt;&gt;  arch/arm64/kvm/hyp/tlb.c         | 69 ++++++++++++++++++++++++++++++++++</span>
<span class="quote">&gt; &gt;&gt;  arch/arm64/kvm/sys_regs.c        | 81 ++++++++++++++++++++++++++++++++++++++++</span>
<span class="quote">&gt; &gt;&gt;  arch/arm64/kvm/trace.h           | 16 ++++++++</span>
<span class="quote">&gt; &gt;&gt;  4 files changed, 167 insertions(+)</span>
<span class="quote">&gt; &gt;&gt; </span>
<span class="quote">&gt; &gt;&gt; diff --git a/arch/arm64/include/asm/kvm_asm.h b/arch/arm64/include/asm/kvm_asm.h</span>
<span class="quote">&gt; &gt;&gt; index 7561f63..1ac1cc3 100644</span>
<span class="quote">&gt; &gt;&gt; --- a/arch/arm64/include/asm/kvm_asm.h</span>
<span class="quote">&gt; &gt;&gt; +++ b/arch/arm64/include/asm/kvm_asm.h</span>
<span class="quote">&gt; &gt;&gt; @@ -49,6 +49,7 @@ extern char __kvm_hyp_vector[];</span>
<span class="quote">&gt; &gt;&gt;  extern void __kvm_flush_vm_context(void);</span>
<span class="quote">&gt; &gt;&gt;  extern void __kvm_tlb_flush_vmid_ipa(struct kvm *kvm, phys_addr_t ipa);</span>
<span class="quote">&gt; &gt;&gt;  extern void __kvm_tlb_flush_vmid(struct kvm *kvm);</span>
<span class="quote">&gt; &gt;&gt; +extern void __kvm_emulate_tlb_invalidate(struct kvm *kvm, u32 sysreg, u64 regval);</span>
<span class="quote">&gt; &gt;&gt;  </span>
<span class="quote">&gt; &gt;&gt;  extern int __kvm_vcpu_run(struct kvm_vcpu *vcpu);</span>
<span class="quote">&gt; &gt;&gt;  </span>
<span class="quote">&gt; &gt;&gt; diff --git a/arch/arm64/kvm/hyp/tlb.c b/arch/arm64/kvm/hyp/tlb.c</span>
<span class="quote">&gt; &gt;&gt; index 4cda100..1210f58 100644</span>
<span class="quote">&gt; &gt;&gt; --- a/arch/arm64/kvm/hyp/tlb.c</span>
<span class="quote">&gt; &gt;&gt; +++ b/arch/arm64/kvm/hyp/tlb.c</span>
<span class="quote">&gt; &gt;&gt; @@ -78,3 +78,72 @@ static void __hyp_text __tlb_flush_vm_context(void)</span>
<span class="quote">&gt; &gt;&gt;  }</span>
<span class="quote">&gt; &gt;&gt;  </span>
<span class="quote">&gt; &gt;&gt;  __alias(__tlb_flush_vm_context) void __kvm_flush_vm_context(void);</span>
<span class="quote">&gt; &gt;&gt; +</span>
<span class="quote">&gt; &gt;&gt; +/* Intentionally empty functions */</span>
<span class="quote">&gt; &gt;&gt; +static void __hyp_text __switch_to_hyp_role_nvhe(void) { }</span>
<span class="quote">&gt; &gt;&gt; +static void __hyp_text __switch_to_host_role_nvhe(void) { }</span>
<span class="quote">&gt; &gt;&gt; +</span>
<span class="quote">&gt; &gt;&gt; +static void __hyp_text __switch_to_hyp_role_vhe(void)</span>
<span class="quote">&gt; &gt;&gt; +{</span>
<span class="quote">&gt; &gt;&gt; +	u64 hcr = read_sysreg(hcr_el2);</span>
<span class="quote">&gt; &gt;&gt; +</span>
<span class="quote">&gt; &gt;&gt; +	hcr &amp;= ~HCR_TGE;</span>
<span class="quote">&gt; &gt;&gt; +	write_sysreg(hcr, hcr_el2);</span>
<span class="quote">&gt; &gt;</span>
<span class="quote">&gt; &gt; why do we need to clear TGE for the TLB maintenance instructions to</span>
<span class="quote">&gt; &gt; work?</span>
<span class="quote">&gt; &gt;</span>
<span class="quote">&gt; &gt; Perhaps this is worth explaining in a comment.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; I&#39;ve added the following comment before clearing TGE bit.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; &quot;When VHE is enabled and HCR_EL2.TGE=1, EL1&amp;0 TLB operations</span>
<span class="quote">&gt; apply to EL2&amp;0 translation regime. As we prepare to emulate</span>
<span class="quote">&gt; guest TLB operation clear HCR_TGE to target TLB operations</span>
<span class="quote">&gt; to EL1&amp;0 (guest).&quot;</span>
<span class="quote">&gt; </span>

Ah, right, obvious when I read this comment.

Thanks,
-Christoffer
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/arch/arm64/include/asm/kvm_asm.h b/arch/arm64/include/asm/kvm_asm.h</span>
<span class="p_header">index 7561f63..1ac1cc3 100644</span>
<span class="p_header">--- a/arch/arm64/include/asm/kvm_asm.h</span>
<span class="p_header">+++ b/arch/arm64/include/asm/kvm_asm.h</span>
<span class="p_chunk">@@ -49,6 +49,7 @@</span> <span class="p_context"> extern char __kvm_hyp_vector[];</span>
 extern void __kvm_flush_vm_context(void);
 extern void __kvm_tlb_flush_vmid_ipa(struct kvm *kvm, phys_addr_t ipa);
 extern void __kvm_tlb_flush_vmid(struct kvm *kvm);
<span class="p_add">+extern void __kvm_emulate_tlb_invalidate(struct kvm *kvm, u32 sysreg, u64 regval);</span>
 
 extern int __kvm_vcpu_run(struct kvm_vcpu *vcpu);
 
<span class="p_header">diff --git a/arch/arm64/kvm/hyp/tlb.c b/arch/arm64/kvm/hyp/tlb.c</span>
<span class="p_header">index 4cda100..1210f58 100644</span>
<span class="p_header">--- a/arch/arm64/kvm/hyp/tlb.c</span>
<span class="p_header">+++ b/arch/arm64/kvm/hyp/tlb.c</span>
<span class="p_chunk">@@ -78,3 +78,72 @@</span> <span class="p_context"> static void __hyp_text __tlb_flush_vm_context(void)</span>
 }
 
 __alias(__tlb_flush_vm_context) void __kvm_flush_vm_context(void);
<span class="p_add">+</span>
<span class="p_add">+/* Intentionally empty functions */</span>
<span class="p_add">+static void __hyp_text __switch_to_hyp_role_nvhe(void) { }</span>
<span class="p_add">+static void __hyp_text __switch_to_host_role_nvhe(void) { }</span>
<span class="p_add">+</span>
<span class="p_add">+static void __hyp_text __switch_to_hyp_role_vhe(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	u64 hcr = read_sysreg(hcr_el2);</span>
<span class="p_add">+</span>
<span class="p_add">+	hcr &amp;= ~HCR_TGE;</span>
<span class="p_add">+	write_sysreg(hcr, hcr_el2);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static void __hyp_text __switch_to_host_role_vhe(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	u64 hcr = read_sysreg(hcr_el2);</span>
<span class="p_add">+</span>
<span class="p_add">+	hcr |= HCR_TGE;</span>
<span class="p_add">+	write_sysreg(hcr, hcr_el2);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static hyp_alternate_select(__switch_to_hyp_role,</span>
<span class="p_add">+			    __switch_to_hyp_role_nvhe,</span>
<span class="p_add">+			    __switch_to_hyp_role_vhe,</span>
<span class="p_add">+			    ARM64_HAS_VIRT_HOST_EXTN);</span>
<span class="p_add">+</span>
<span class="p_add">+static hyp_alternate_select(__switch_to_host_role,</span>
<span class="p_add">+			    __switch_to_host_role_nvhe,</span>
<span class="p_add">+			    __switch_to_host_role_vhe,</span>
<span class="p_add">+			    ARM64_HAS_VIRT_HOST_EXTN);</span>
<span class="p_add">+</span>
<span class="p_add">+static void __hyp_text __switch_to_guest_regime(struct kvm *kvm)</span>
<span class="p_add">+{</span>
<span class="p_add">+	write_sysreg(kvm-&gt;arch.vttbr, vttbr_el2);</span>
<span class="p_add">+	__switch_to_hyp_role();</span>
<span class="p_add">+	isb();</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static void __hyp_text __switch_to_host_regime(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	__switch_to_host_role();</span>
<span class="p_add">+	write_sysreg(0, vttbr_el2);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void __hyp_text</span>
<span class="p_add">+__kvm_emulate_tlb_invalidate(struct kvm *kvm, u32 sys_op, u64 regval)</span>
<span class="p_add">+{</span>
<span class="p_add">+	kvm = kern_hyp_va(kvm);</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Switch to the guest before performing any TLB operations to</span>
<span class="p_add">+	 * target the appropriate VMID</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	__switch_to_guest_regime(kvm);</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 *  TLB maintenance operations are broadcast to</span>
<span class="p_add">+	 *  inner-shareable domain when HCR_FB is set (default for</span>
<span class="p_add">+	 *  KVM).</span>
<span class="p_add">+	 *</span>
<span class="p_add">+	 *  Nuke all Stage 1 TLB entries for the VM. This will kill</span>
<span class="p_add">+	 *  performance but it&#39;s always safe to do as we don&#39;t leave</span>
<span class="p_add">+	 *  behind any strays in the TLB</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	__tlbi(vmalle1is);</span>
<span class="p_add">+	isb();</span>
<span class="p_add">+</span>
<span class="p_add">+	__switch_to_host_regime();</span>
<span class="p_add">+}</span>
<span class="p_header">diff --git a/arch/arm64/kvm/sys_regs.c b/arch/arm64/kvm/sys_regs.c</span>
<span class="p_header">index e51367d..0e70da9 100644</span>
<span class="p_header">--- a/arch/arm64/kvm/sys_regs.c</span>
<span class="p_header">+++ b/arch/arm64/kvm/sys_regs.c</span>
<span class="p_chunk">@@ -790,6 +790,18 @@</span> <span class="p_context"> static bool access_pmuserenr(struct kvm_vcpu *vcpu, struct sys_reg_params *p,</span>
 	return true;
 }
 
<span class="p_add">+static bool emulate_tlb_invalidate(struct kvm_vcpu *vcpu, struct sys_reg_params *p,</span>
<span class="p_add">+				  const struct sys_reg_desc *r)</span>
<span class="p_add">+{</span>
<span class="p_add">+	u32 opcode = sys_reg(p-&gt;Op0, p-&gt;Op1, p-&gt;CRn, p-&gt;CRm, p-&gt;Op2);</span>
<span class="p_add">+</span>
<span class="p_add">+	kvm_call_hyp(__kvm_emulate_tlb_invalidate,</span>
<span class="p_add">+		     vcpu-&gt;kvm, opcode, p-&gt;regval);</span>
<span class="p_add">+	trace_kvm_tlb_invalidate(*vcpu_pc(vcpu), opcode);</span>
<span class="p_add">+</span>
<span class="p_add">+	return true;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 /* Silly macro to expand the DBG{BCR,BVR,WVR,WCR}n_EL1 registers in one go */
 #define DBG_BCR_BVR_WCR_WVR_EL1(n)					\
 	/* DBGBVRn_EL1 */						\
<span class="p_chunk">@@ -841,6 +853,35 @@</span> <span class="p_context"> static const struct sys_reg_desc sys_reg_descs[] = {</span>
 	{ Op0(0b01), Op1(0b000), CRn(0b0111), CRm(0b1110), Op2(0b010),
 	  access_dcsw },
 
<span class="p_add">+	/*</span>
<span class="p_add">+	 * ARMv8 ARM: Table C5-4 TLB maintenance instructions</span>
<span class="p_add">+	 * (Ref: ARMv8 ARM C5.1 version: ARM DDI 0487A.j)</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	/* TLBI VMALLE1IS */</span>
<span class="p_add">+	{ Op0(1), Op1(0), CRn(8), CRm(3), Op2(0), emulate_tlb_invalidate },</span>
<span class="p_add">+	/* TLBI VAE1IS */</span>
<span class="p_add">+	{ Op0(1), Op1(0), CRn(8), CRm(3), Op2(1), emulate_tlb_invalidate },</span>
<span class="p_add">+	/* TLBI ASIDE1IS */</span>
<span class="p_add">+	{ Op0(1), Op1(0), CRn(8), CRm(3), Op2(2), emulate_tlb_invalidate },</span>
<span class="p_add">+	/* TLBI VAAE1IS */</span>
<span class="p_add">+	{ Op0(1), Op1(0), CRn(8), CRm(3), Op2(3), emulate_tlb_invalidate },</span>
<span class="p_add">+	/* TLBI VALE1IS */</span>
<span class="p_add">+	{ Op0(1), Op1(0), CRn(8), CRm(3), Op2(5), emulate_tlb_invalidate },</span>
<span class="p_add">+	/* TLBI VAALE1IS */</span>
<span class="p_add">+	{ Op0(1), Op1(0), CRn(8), CRm(3), Op2(7), emulate_tlb_invalidate },</span>
<span class="p_add">+	/* TLBI VMALLE1 */</span>
<span class="p_add">+	{ Op0(1), Op1(0), CRn(8), CRm(7), Op2(0), emulate_tlb_invalidate },</span>
<span class="p_add">+	/* TLBI VAE1 */</span>
<span class="p_add">+	{ Op0(1), Op1(0), CRn(8), CRm(7), Op2(1), emulate_tlb_invalidate },</span>
<span class="p_add">+	/* TLBI ASIDE1 */</span>
<span class="p_add">+	{ Op0(1), Op1(0), CRn(8), CRm(7), Op2(2), emulate_tlb_invalidate },</span>
<span class="p_add">+	/* TLBI VAAE1 */</span>
<span class="p_add">+	{ Op0(1), Op1(0), CRn(8), CRm(7), Op2(3), emulate_tlb_invalidate },</span>
<span class="p_add">+	/* TLBI VALE1 */</span>
<span class="p_add">+	{ Op0(1), Op1(0), CRn(8), CRm(7), Op2(5), emulate_tlb_invalidate },</span>
<span class="p_add">+	/* TLBI VAALE1 */</span>
<span class="p_add">+	{ Op0(1), Op1(0), CRn(8), CRm(7), Op2(7), emulate_tlb_invalidate },</span>
<span class="p_add">+</span>
 	DBG_BCR_BVR_WCR_WVR_EL1(0),
 	DBG_BCR_BVR_WCR_WVR_EL1(1),
 	/* MDCCINT_EL1 */
<span class="p_chunk">@@ -1329,6 +1370,46 @@</span> <span class="p_context"> static const struct sys_reg_desc cp15_regs[] = {</span>
 	{ Op1( 0), CRn( 7), CRm(10), Op2( 2), access_dcsw },
 	{ Op1( 0), CRn( 7), CRm(14), Op2( 2), access_dcsw },
 
<span class="p_add">+	/*</span>
<span class="p_add">+	 * TLB operations</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	/* TLBIALLIS */</span>
<span class="p_add">+	{ Op1( 0), CRn( 8), CRm( 3), Op2( 0), emulate_tlb_invalidate},</span>
<span class="p_add">+	/* TLBIMVAIS */</span>
<span class="p_add">+	{ Op1( 0), CRn( 8), CRm( 3), Op2( 1), emulate_tlb_invalidate},</span>
<span class="p_add">+	/* TLBIASIDIS */</span>
<span class="p_add">+	{ Op1( 0), CRn( 8), CRm( 3), Op2( 2), emulate_tlb_invalidate},</span>
<span class="p_add">+	/* TLBIMVAAIS */</span>
<span class="p_add">+	{ Op1( 0), CRn( 8), CRm( 3), Op2( 3), emulate_tlb_invalidate},</span>
<span class="p_add">+	/* TLBIMVALIS */</span>
<span class="p_add">+	{ Op1( 0), CRn( 8), CRm( 3), Op2( 5), emulate_tlb_invalidate},</span>
<span class="p_add">+	/* TLBIMVAALIS */</span>
<span class="p_add">+	{ Op1( 0), CRn( 8), CRm( 3), Op2( 7), emulate_tlb_invalidate},</span>
<span class="p_add">+	/* ITLBIALL */</span>
<span class="p_add">+	{ Op1( 0), CRn( 8), CRm( 5), Op2( 0), emulate_tlb_invalidate},</span>
<span class="p_add">+	/* ITLBIMVA */</span>
<span class="p_add">+	{ Op1( 0), CRn( 8), CRm( 5), Op2( 1), emulate_tlb_invalidate},</span>
<span class="p_add">+	/* ITLBIASID */</span>
<span class="p_add">+	{ Op1( 0), CRn( 8), CRm( 5), Op2( 2), emulate_tlb_invalidate},</span>
<span class="p_add">+	/* DTLBIALL */</span>
<span class="p_add">+	{ Op1( 0), CRn( 8), CRm( 6), Op2( 0), emulate_tlb_invalidate},</span>
<span class="p_add">+	/* DTLBIMVA */</span>
<span class="p_add">+	{ Op1( 0), CRn( 8), CRm( 6), Op2( 1), emulate_tlb_invalidate},</span>
<span class="p_add">+	/* DTLBIASID */</span>
<span class="p_add">+	{ Op1( 0), CRn( 8), CRm( 6), Op2( 2), emulate_tlb_invalidate},</span>
<span class="p_add">+	/* TLBIALL */</span>
<span class="p_add">+	{ Op1( 0), CRn( 8), CRm( 7), Op2( 0), emulate_tlb_invalidate},</span>
<span class="p_add">+	/* TLBIMVA */</span>
<span class="p_add">+	{ Op1( 0), CRn( 8), CRm( 7), Op2( 1), emulate_tlb_invalidate},</span>
<span class="p_add">+	/* TLBIASID */</span>
<span class="p_add">+	{ Op1( 0), CRn( 8), CRm( 7), Op2( 2), emulate_tlb_invalidate},</span>
<span class="p_add">+	/* TLBIMVAA */</span>
<span class="p_add">+	{ Op1( 0), CRn( 8), CRm( 7), Op2( 3), emulate_tlb_invalidate},</span>
<span class="p_add">+	/* TLBIMVAL */</span>
<span class="p_add">+	{ Op1( 0), CRn( 8), CRm( 7), Op2( 5), emulate_tlb_invalidate},</span>
<span class="p_add">+	/* TLBIMVAAL */</span>
<span class="p_add">+	{ Op1( 0), CRn( 8), CRm( 7), Op2( 7), emulate_tlb_invalidate},</span>
<span class="p_add">+</span>
 	/* PMU */
 	{ Op1( 0), CRn( 9), CRm(12), Op2( 0), access_pmcr },
 	{ Op1( 0), CRn( 9), CRm(12), Op2( 1), access_pmcnten },
<span class="p_header">diff --git a/arch/arm64/kvm/trace.h b/arch/arm64/kvm/trace.h</span>
<span class="p_header">index 7fb0008..c4d577f 100644</span>
<span class="p_header">--- a/arch/arm64/kvm/trace.h</span>
<span class="p_header">+++ b/arch/arm64/kvm/trace.h</span>
<span class="p_chunk">@@ -166,6 +166,22 @@</span> <span class="p_context"> TRACE_EVENT(kvm_set_guest_debug,</span>
 	TP_printk(&quot;vcpu: %p, flags: 0x%08x&quot;, __entry-&gt;vcpu, __entry-&gt;guest_debug)
 );
 
<span class="p_add">+TRACE_EVENT(kvm_tlb_invalidate,</span>
<span class="p_add">+	TP_PROTO(unsigned long vcpu_pc, u32 opcode),</span>
<span class="p_add">+	TP_ARGS(vcpu_pc, opcode),</span>
<span class="p_add">+</span>
<span class="p_add">+	TP_STRUCT__entry(</span>
<span class="p_add">+		__field(unsigned long, vcpu_pc)</span>
<span class="p_add">+		__field(u32, opcode)</span>
<span class="p_add">+	),</span>
<span class="p_add">+</span>
<span class="p_add">+	TP_fast_assign(</span>
<span class="p_add">+		__entry-&gt;vcpu_pc = vcpu_pc;</span>
<span class="p_add">+		__entry-&gt;opcode = opcode;</span>
<span class="p_add">+	),</span>
<span class="p_add">+</span>
<span class="p_add">+	TP_printk(&quot;vcpu_pc=0x%16lx opcode=%08x&quot;, __entry-&gt;vcpu_pc, __entry-&gt;opcode)</span>
<span class="p_add">+);</span>
 
 #endif /* _TRACE_ARM64_KVM_H */
 

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



