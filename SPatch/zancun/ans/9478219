
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>[RFC,11/14] sparc64: add routines to look for vmsa which can share context - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    [RFC,11/14] sparc64: add routines to look for vmsa which can share context</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=124511">Mike Kravetz</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>Dec. 16, 2016, 6:35 p.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;1481913337-9331-12-git-send-email-mike.kravetz@oracle.com&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/9478219/mbox/"
   >mbox</a>
|
   <a href="/patch/9478219/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/9478219/">/patch/9478219/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
	[172.30.200.125])
	by pdx-korg-patchwork.web.codeaurora.org (Postfix) with ESMTP id
	5E282601C2 for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Fri, 16 Dec 2016 18:37:32 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 52DF128783
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Fri, 16 Dec 2016 18:37:32 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id 46D2428787; Fri, 16 Dec 2016 18:37:32 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-6.9 required=2.0 tests=BAYES_00, RCVD_IN_DNSWL_HI, 
	UNPARSEABLE_RELAY autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 7D0C128780
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Fri, 16 Dec 2016 18:37:31 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1761720AbcLPShM (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Fri, 16 Dec 2016 13:37:12 -0500
Received: from aserp1040.oracle.com ([141.146.126.69]:39040 &quot;EHLO
	aserp1040.oracle.com&quot; rhost-flags-OK-OK-OK-OK) by vger.kernel.org
	with ESMTP id S1758298AbcLPSgR (ORCPT
	&lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Fri, 16 Dec 2016 13:36:17 -0500
Received: from userv0021.oracle.com (userv0021.oracle.com [156.151.31.71])
	by aserp1040.oracle.com (Sentrion-MTA-4.3.2/Sentrion-MTA-4.3.2) with
	ESMTP id uBGIa3CQ025239
	(version=TLSv1.2 cipher=ECDHE-RSA-AES256-GCM-SHA384 bits=256
	verify=OK); Fri, 16 Dec 2016 18:36:04 GMT
Received: from aserv0122.oracle.com (aserv0122.oracle.com [141.146.126.236])
	by userv0021.oracle.com (8.14.4/8.14.4) with ESMTP id
	uBGIa31B017793
	(version=TLSv1/SSLv3 cipher=DHE-RSA-AES256-GCM-SHA384 bits=256
	verify=OK); Fri, 16 Dec 2016 18:36:03 GMT
Received: from abhmp0002.oracle.com (abhmp0002.oracle.com [141.146.116.8])
	by aserv0122.oracle.com (8.14.4/8.14.4) with ESMTP id uBGIa3Tb012391; 
	Fri, 16 Dec 2016 18:36:03 GMT
Received: from monkey.oracle.com (/50.188.161.229)
	by default (Oracle Beehive Gateway v4.0)
	with ESMTP ; Fri, 16 Dec 2016 10:36:02 -0800
From: Mike Kravetz &lt;mike.kravetz@oracle.com&gt;
To: sparclinux@vger.kernel.org, linux-mm@kvack.org,
	linux-kernel@vger.kernel.org
Cc: &quot;David S . Miller&quot; &lt;davem@davemloft.net&gt;,
	Bob Picco &lt;bob.picco@oracle.com&gt;, Nitin Gupta &lt;nitin.m.gupta@oracle.com&gt;,
	Vijay Kumar &lt;vijay.ac.kumar@oracle.com&gt;,
	Julian Calaby &lt;julian.calaby@gmail.com&gt;,
	Adam Buchbinder &lt;adam.buchbinder@gmail.com&gt;,
	&quot;Kirill A . Shutemov&quot; &lt;kirill.shutemov@linux.intel.com&gt;,
	Michal Hocko &lt;mhocko@suse.com&gt;,
	Andrew Morton &lt;akpm@linux-foundation.org&gt;,
	Mike Kravetz &lt;mike.kravetz@oracle.com&gt;
Subject: [RFC PATCH 11/14] sparc64: add routines to look for vmsa which can
	share context
Date: Fri, 16 Dec 2016 10:35:34 -0800
Message-Id: &lt;1481913337-9331-12-git-send-email-mike.kravetz@oracle.com&gt;
X-Mailer: git-send-email 2.7.4
In-Reply-To: &lt;1481913337-9331-1-git-send-email-mike.kravetz@oracle.com&gt;
References: &lt;1481913337-9331-1-git-send-email-mike.kravetz@oracle.com&gt;
X-Source-IP: userv0021.oracle.com [156.151.31.71]
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=124511">Mike Kravetz</a> - Dec. 16, 2016, 6:35 p.m.</div>
<pre class="content">
When a shared context mapping is requested, a search of the other
vmas mapping the same object is searched.  For simplicity, vmas
can only share context if the following is true:
- They both request shared context mapping
- The are at the same virtual address
- They are of the same size
In addition, a task is only allowed to have a single vma with shared
context.

Some of these contstraints can be relaxed at a later date.  They
make the code simpler for now.
<span class="signed-off-by">
Signed-off-by: Mike Kravetz &lt;mike.kravetz@oracle.com&gt;</span>
---
 arch/sparc/include/asm/mmu_context_64.h |  1 +
 arch/sparc/include/asm/page_64.h        |  1 +
 arch/sparc/mm/hugetlbpage.c             | 78 ++++++++++++++++++++++++++++++++-
 arch/sparc/mm/init_64.c                 | 19 ++++++++
 mm/hugetlb.c                            |  9 ++++
 5 files changed, 106 insertions(+), 2 deletions(-)
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/arch/sparc/include/asm/mmu_context_64.h b/arch/sparc/include/asm/mmu_context_64.h</span>
<span class="p_header">index 0dc95cb5..46c2c7e 100644</span>
<span class="p_header">--- a/arch/sparc/include/asm/mmu_context_64.h</span>
<span class="p_header">+++ b/arch/sparc/include/asm/mmu_context_64.h</span>
<span class="p_chunk">@@ -23,6 +23,7 @@</span> <span class="p_context"> void get_new_mmu_shared_context(struct mm_struct *mm);</span>
 void put_shared_context(struct mm_struct *mm);
 void set_mm_shared_ctx(struct mm_struct *mm, struct shared_mmu_ctx *ctx);
 void destroy_shared_context(struct mm_struct *mm);
<span class="p_add">+void set_vma_shared_ctx(struct vm_area_struct *vma);</span>
 #endif
 #ifdef CONFIG_SMP
 void smp_new_mmu_context_version(void);
<span class="p_header">diff --git a/arch/sparc/include/asm/page_64.h b/arch/sparc/include/asm/page_64.h</span>
<span class="p_header">index c1263fc..ccceb76 100644</span>
<span class="p_header">--- a/arch/sparc/include/asm/page_64.h</span>
<span class="p_header">+++ b/arch/sparc/include/asm/page_64.h</span>
<span class="p_chunk">@@ -33,6 +33,7 @@</span> <span class="p_context"></span>
 #if defined(CONFIG_HUGETLB_PAGE) || defined(CONFIG_TRANSPARENT_HUGEPAGE)
 struct pt_regs;
 void hugetlb_setup(struct pt_regs *regs);
<span class="p_add">+void hugetlb_shared_setup(struct pt_regs *regs);</span>
 #endif
 
 #define WANT_PAGE_VIRTUAL
<span class="p_header">diff --git a/arch/sparc/mm/hugetlbpage.c b/arch/sparc/mm/hugetlbpage.c</span>
<span class="p_header">index 2039d45..5681df6 100644</span>
<span class="p_header">--- a/arch/sparc/mm/hugetlbpage.c</span>
<span class="p_header">+++ b/arch/sparc/mm/hugetlbpage.c</span>
<span class="p_chunk">@@ -127,6 +127,80 @@</span> <span class="p_context"> hugetlb_get_unmapped_area(struct file *file, unsigned long addr,</span>
 				pgoff, flags);
 }
 
<span class="p_add">+#if defined(CONFIG_SHARED_MMU_CTX)</span>
<span class="p_add">+static bool huge_vma_can_share_ctx(struct vm_area_struct *vma,</span>
<span class="p_add">+					struct vm_area_struct *tvma)</span>
<span class="p_add">+{</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Do not match unless there is an actual context value.  It</span>
<span class="p_add">+	 * could be the case that tvma is a new mapping with VM_SHARED_CTX</span>
<span class="p_add">+	 * set, but still not associated with a shared context ID.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	if (!vma_shared_ctx_val(tvma))</span>
<span class="p_add">+		return false;</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * For simple functionality now, vmas must be exactly the same</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	if ((vma-&gt;vm_flags &amp; VM_LOCKED_CLEAR_MASK) ==</span>
<span class="p_add">+	    (tvma-&gt;vm_flags &amp; VM_LOCKED_CLEAR_MASK) &amp;&amp;</span>
<span class="p_add">+	    vma-&gt;vm_pgoff == tvma-&gt;vm_pgoff &amp;&amp;</span>
<span class="p_add">+	    vma-&gt;vm_start == tvma-&gt;vm_start &amp;&amp;</span>
<span class="p_add">+	    vma-&gt;vm_end == tvma-&gt;vm_end)</span>
<span class="p_add">+		return true;</span>
<span class="p_add">+</span>
<span class="p_add">+	return false;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+/*</span>
<span class="p_add">+ * If vma is marked as desiring shared contexxt, search for a context to</span>
<span class="p_add">+ * share.  If no context found, assign one.</span>
<span class="p_add">+ */</span>
<span class="p_add">+void huge_get_shared_ctx(struct mm_struct *mm, unsigned long addr)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct vm_area_struct *vma = find_vma(mm, addr);</span>
<span class="p_add">+	struct address_space *mapping = vma-&gt;vm_file-&gt;f_mapping;</span>
<span class="p_add">+	pgoff_t idx = ((addr - vma-&gt;vm_start) &gt;&gt; PAGE_SHIFT) +</span>
<span class="p_add">+			vma-&gt;vm_pgoff;</span>
<span class="p_add">+	struct vm_area_struct *tvma;</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * FIXME</span>
<span class="p_add">+	 *</span>
<span class="p_add">+	 * For now limit a task to a single shared context mapping</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	if (!(vma-&gt;vm_flags &amp; VM_SHARED_CTX) || vma_shared_ctx_val(vma) ||</span>
<span class="p_add">+	    mm_shared_ctx_val(mm))</span>
<span class="p_add">+		return;</span>
<span class="p_add">+</span>
<span class="p_add">+	i_mmap_lock_write(mapping);</span>
<span class="p_add">+	vma_interval_tree_foreach(tvma, &amp;mapping-&gt;i_mmap, idx, idx) {</span>
<span class="p_add">+		if (tvma == vma)</span>
<span class="p_add">+			continue;</span>
<span class="p_add">+</span>
<span class="p_add">+		if (huge_vma_can_share_ctx(vma, tvma)) {</span>
<span class="p_add">+			set_mm_shared_ctx(mm, tvma-&gt;vm_shared_mmu_ctx.ctx);</span>
<span class="p_add">+			set_vma_shared_ctx(vma);</span>
<span class="p_add">+			if (likely(mm_shared_ctx_val(mm))) {</span>
<span class="p_add">+				load_secondary_context(mm);</span>
<span class="p_add">+				/*</span>
<span class="p_add">+				 * What about multiple matches ?</span>
<span class="p_add">+				 */</span>
<span class="p_add">+				break;</span>
<span class="p_add">+			}</span>
<span class="p_add">+		}</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	if (!mm_shared_ctx_val(mm)) {</span>
<span class="p_add">+		get_new_mmu_shared_context(mm);</span>
<span class="p_add">+		set_vma_shared_ctx(vma);</span>
<span class="p_add">+		load_secondary_context(mm);</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	i_mmap_unlock_write(mapping);</span>
<span class="p_add">+}</span>
<span class="p_add">+#endif</span>
<span class="p_add">+</span>
 pte_t *huge_pte_alloc(struct mm_struct *mm,
 			unsigned long addr, unsigned long sz)
 {
<span class="p_chunk">@@ -164,7 +238,7 @@</span> <span class="p_context"> void set_huge_pte_at(struct mm_struct *mm, unsigned long addr,</span>
 
 	if (!pte_present(*ptep) &amp;&amp; pte_present(entry)) {
 #if defined(CONFIG_SHARED_MMU_CTX)
<span class="p_del">-		if (pte_val(entry) | _PAGE_SHR_CTX_4V)</span>
<span class="p_add">+		if (is_sharedctx_pte(entry))</span>
 			mm-&gt;context.shared_hugetlb_pte_count++;
 		else
 #endif
<span class="p_chunk">@@ -188,7 +262,7 @@</span> <span class="p_context"> pte_t huge_ptep_get_and_clear(struct mm_struct *mm, unsigned long addr,</span>
 	entry = *ptep;
 	if (pte_present(entry)) {
 #if defined(CONFIG_SHARED_MMU_CTX)
<span class="p_del">-		if (pte_val(entry) | _PAGE_SHR_CTX_4V)</span>
<span class="p_add">+		if (is_sharedctx_pte(entry))</span>
 			mm-&gt;context.shared_hugetlb_pte_count--;
 		else
 #endif
<span class="p_header">diff --git a/arch/sparc/mm/init_64.c b/arch/sparc/mm/init_64.c</span>
<span class="p_header">index 2b310e5..25ad5bd 100644</span>
<span class="p_header">--- a/arch/sparc/mm/init_64.c</span>
<span class="p_header">+++ b/arch/sparc/mm/init_64.c</span>
<span class="p_chunk">@@ -813,6 +813,25 @@</span> <span class="p_context"> void set_mm_shared_ctx(struct mm_struct *mm, struct shared_mmu_ctx *ctx)</span>
 	atomic_inc(&amp;ctx-&gt;refcount);
 	mm-&gt;context.shared_ctx = ctx;
 }
<span class="p_add">+</span>
<span class="p_add">+/*</span>
<span class="p_add">+ * Set the shared context value in the vma to that in the mm.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * Note that we are called from mmap with mmap_sem held.</span>
<span class="p_add">+ */</span>
<span class="p_add">+void set_vma_shared_ctx(struct vm_area_struct *vma)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct mm_struct *mm = vma-&gt;vm_mm;</span>
<span class="p_add">+</span>
<span class="p_add">+	BUG_ON(vma-&gt;vm_shared_mmu_ctx.ctx);</span>
<span class="p_add">+</span>
<span class="p_add">+	if (!mm_shared_ctx_val(mm))</span>
<span class="p_add">+		return;</span>
<span class="p_add">+</span>
<span class="p_add">+	atomic_inc(&amp;mm-&gt;context.shared_ctx-&gt;refcount);</span>
<span class="p_add">+	vma-&gt;vm_shared_mmu_ctx.ctx = mm-&gt;context.shared_ctx;</span>
<span class="p_add">+}</span>
 #endif
 
 static int numa_enabled = 1;
<span class="p_header">diff --git a/mm/hugetlb.c b/mm/hugetlb.c</span>
<span class="p_header">index 418bf01..3733ba1 100644</span>
<span class="p_header">--- a/mm/hugetlb.c</span>
<span class="p_header">+++ b/mm/hugetlb.c</span>
<span class="p_chunk">@@ -3150,6 +3150,15 @@</span> <span class="p_context"> static pte_t make_huge_pte(struct vm_area_struct *vma, struct page *page,</span>
 	entry = pte_mkhuge(entry);
 	entry = arch_make_huge_pte(entry, vma, page, writable);
 
<span class="p_add">+#if defined(CONFIG_SHARED_MMU_CTX)</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * FIXME</span>
<span class="p_add">+	 * needs arch independent way of setting - perhaps arch_make_huge_pte</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	if (vma-&gt;vm_flags &amp; VM_SHARED_CTX)</span>
<span class="p_add">+		pte_val(entry) |= _PAGE_SHR_CTX_4V;</span>
<span class="p_add">+#endif</span>
<span class="p_add">+</span>
 	return entry;
 }
 

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



