
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>[PATCHv3,5/6] arm64: Use __pa_symbol for kernel symbols - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    [PATCHv3,5/6] arm64: Use __pa_symbol for kernel symbols</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=130411">Laura Abbott</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>Nov. 18, 2016, 1:16 a.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;1479431816-5028-6-git-send-email-labbott@redhat.com&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/9435609/mbox/"
   >mbox</a>
|
   <a href="/patch/9435609/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/9435609/">/patch/9435609/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
	[172.30.200.125])
	by pdx-korg-patchwork.web.codeaurora.org (Postfix) with ESMTP id
	8686C60471 for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Fri, 18 Nov 2016 01:17:36 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 76761293AD
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Fri, 18 Nov 2016 01:17:36 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id 6B2AD296B9; Fri, 18 Nov 2016 01:17:36 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-6.4 required=2.0 tests=BAYES_00, RCVD_IN_DNSWL_HI, 
	RCVD_IN_SORBS_SPAM autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 998EA29731
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Fri, 18 Nov 2016 01:17:34 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1752819AbcKRBRW (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Thu, 17 Nov 2016 20:17:22 -0500
Received: from mail-it0-f50.google.com ([209.85.214.50]:34354 &quot;EHLO
	mail-it0-f50.google.com&quot; rhost-flags-OK-OK-OK-OK) by vger.kernel.org
	with ESMTP id S1752476AbcKRBRO (ORCPT
	&lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Thu, 17 Nov 2016 20:17:14 -0500
Received: by mail-it0-f50.google.com with SMTP id l8so1428031iti.1
	for &lt;linux-kernel@vger.kernel.org&gt;;
	Thu, 17 Nov 2016 17:17:13 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
	d=1e100.net; s=20130820;
	h=x-gm-message-state:from:to:cc:subject:date:message-id:in-reply-to
	:references;
	bh=7AxmRktU64uJnYh6dr4/tEb0lLrNfd/IkW9rCzjQnTY=;
	b=gASspNael0bvgQVOnfbXLc2wleiKh0zKfuO3UyAWTFYsXBntMzOig0mnj4UmNtu7QN
	N8L13cKW3TbohUk4PaTZUjManTIBOEEsY0OgqOQrBLtvZntl63fQjpgj0P6LWJNExQqU
	CFi943nmD52JW2VBd6hFdzVbHwqqc9EwfZcxEDYt6C3Zcte1OIT8r51ZlwmkTPX2hKYB
	3xoonoG8bJWvQoQAX5girQCxaXG38wZx1VVOi3hjYHkUKVL1Um4whaFNJ0aqaTuQ9AfQ
	0wDIfIZrixF2fXtaGvbEvhVEuaZjiv8FkIwQneB9wFZHboouoZvvKEpQvMzogaam41ZH
	BFDg==
X-Gm-Message-State: ABUngvd3MGpXI51L0AxHGmYPTccW6zZqvTQDIbjz4yBHxhO0fZzfDazeeHFSEUHg9qTMX7XZ
X-Received: by 10.36.73.70 with SMTP id z67mr6729739ita.63.1479431832816;
	Thu, 17 Nov 2016 17:17:12 -0800 (PST)
Received: from labbott-redhat-machine.redhat.com ([2601:602:9800:177f::df9b])
	by smtp.gmail.com with ESMTPSA id
	i8sm254953itc.11.2016.11.17.17.17.10
	(version=TLS1_2 cipher=ECDHE-RSA-AES128-GCM-SHA256 bits=128/128);
	Thu, 17 Nov 2016 17:17:11 -0800 (PST)
From: Laura Abbott &lt;labbott@redhat.com&gt;
To: Mark Rutland &lt;mark.rutland@arm.com&gt;,
	Ard Biesheuvel &lt;ard.biesheuvel@linaro.org&gt;,
	Will Deacon &lt;will.deacon@arm.com&gt;,
	Catalin Marinas &lt;catalin.marinas@arm.com&gt;
Cc: Laura Abbott &lt;labbott@redhat.com&gt;, Thomas Gleixner &lt;tglx@linutronix.de&gt;,
	Ingo Molnar &lt;mingo@redhat.com&gt;,
	&quot;H. Peter Anvin&quot; &lt;hpa@zytor.com&gt;, x86@kernel.org,
	linux-kernel@vger.kernel.org, linux-mm@kvack.org,
	Andrew Morton &lt;akpm@linux-foundation.org&gt;,
	Marek Szyprowski &lt;m.szyprowski@samsung.com&gt;,
	Joonsoo Kim &lt;iamjoonsoo.kim@lge.com&gt;,
	linux-arm-kernel@lists.infradead.org
Subject: [PATCHv3 5/6] arm64: Use __pa_symbol for kernel symbols
Date: Thu, 17 Nov 2016 17:16:55 -0800
Message-Id: &lt;1479431816-5028-6-git-send-email-labbott@redhat.com&gt;
X-Mailer: git-send-email 2.7.4
In-Reply-To: &lt;1479431816-5028-1-git-send-email-labbott@redhat.com&gt;
References: &lt;1479431816-5028-1-git-send-email-labbott@redhat.com&gt;
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=130411">Laura Abbott</a> - Nov. 18, 2016, 1:16 a.m.</div>
<pre class="content">
__pa_symbol is technically the marco that should be used for kernel
symbols. Switch to this as a pre-requisite for DEBUG_VIRTUAL which
will do bounds checking.
<span class="signed-off-by">
Signed-off-by: Laura Abbott &lt;labbott@redhat.com&gt;</span>
---
v3: Conversion of more sites besides just _end. Addition of __lm_sym_addr
macro to take care of the _va(__pa_symbol(..)) idiom.

Note that a copy of __pa_symbol was added to avoid a mess of headers
since the #ifndef __pa_symbol case is defined in linux/mm.h
---
 arch/arm64/include/asm/kvm_mmu.h          |  4 ++--
 arch/arm64/include/asm/memory.h           |  6 ++++++
 arch/arm64/include/asm/mmu_context.h      |  6 +++---
 arch/arm64/include/asm/pgtable.h          |  2 +-
 arch/arm64/kernel/acpi_parking_protocol.c |  2 +-
 arch/arm64/kernel/cpufeature.c            |  2 +-
 arch/arm64/kernel/hibernate.c             |  9 +++------
 arch/arm64/kernel/insn.c                  |  2 +-
 arch/arm64/kernel/psci.c                  |  2 +-
 arch/arm64/kernel/setup.c                 |  8 ++++----
 arch/arm64/kernel/smp_spin_table.c        |  2 +-
 arch/arm64/kernel/vdso.c                  |  4 ++--
 arch/arm64/mm/init.c                      | 11 ++++++-----
 arch/arm64/mm/mmu.c                       | 24 ++++++++++++------------
 drivers/firmware/psci.c                   |  2 +-
 15 files changed, 45 insertions(+), 41 deletions(-)
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=30282">Mark Rutland</a> - Nov. 18, 2016, 2:35 p.m.</div>
<pre class="content">
Hi Laura,

On Thu, Nov 17, 2016 at 05:16:55PM -0800, Laura Abbott wrote:
<span class="quote">&gt; </span>
<span class="quote">&gt; __pa_symbol is technically the marco that should be used for kernel</span>
<span class="quote">&gt; symbols. Switch to this as a pre-requisite for DEBUG_VIRTUAL which</span>
<span class="quote">&gt; will do bounds checking.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Signed-off-by: Laura Abbott &lt;labbott@redhat.com&gt;</span>
<span class="quote">&gt; ---</span>
<span class="quote">&gt; v3: Conversion of more sites besides just _end. Addition of __lm_sym_addr</span>
<span class="quote">&gt; macro to take care of the _va(__pa_symbol(..)) idiom.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Note that a copy of __pa_symbol was added to avoid a mess of headers</span>
<span class="quote">&gt; since the #ifndef __pa_symbol case is defined in linux/mm.h</span>

I think we also need to fix up virt_to_phys(__cpu_soft_restart) in
arch/arm64/kernel/cpu-reset.h. Otherwise, this looks complete for uses
falling under arch/arm64/.

I also think it&#39;s worth mentioning in the commit message that this patch
adds and __lm_sym_addr() and uses it in some places so that low-level
helpers can use virt_to_phys() or __pa() consistently.

The PSCI change doesn&#39;t conflict with patches [1] that&#39;ll go via
arm-soc, so I&#39;m happy for that PSCI change to go via the arm64 tree,
though it may be worth splitting into its own patch just in case
something unexpected crops up.

With those fixed up:
<span class="reviewed-by">
Reviewed-by: Mark Rutland &lt;mark.rutland@arm.com&gt;</span>

[1] http://lists.infradead.org/pipermail/linux-arm-kernel/2016-November/466522.html

Otherwise, I just have a few nits below.
<span class="quote">
&gt; @@ -271,7 +271,7 @@ static inline void __kvm_flush_dcache_pud(pud_t pud)</span>
<span class="quote">&gt;  	kvm_flush_dcache_to_poc(page_address(page), PUD_SIZE);</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; -#define kvm_virt_to_phys(x)		__virt_to_phys((unsigned long)(x))</span>
<span class="quote">&gt; +#define kvm_virt_to_phys(x)		__pa_symbol((unsigned long)(x))</span>

Nit: we can drop the unsigned long cast given __pa_symbol() contains
one.
<span class="quote">
&gt; diff --git a/arch/arm64/include/asm/pgtable.h b/arch/arm64/include/asm/pgtable.h</span>
<span class="quote">&gt; index ffbb9a5..c2041a3 100644</span>
<span class="quote">&gt; --- a/arch/arm64/include/asm/pgtable.h</span>
<span class="quote">&gt; +++ b/arch/arm64/include/asm/pgtable.h</span>
<span class="quote">&gt; @@ -52,7 +52,7 @@ extern void __pgd_error(const char *file, int line, unsigned long val);</span>
<span class="quote">&gt;   * for zero-mapped memory areas etc..</span>
<span class="quote">&gt;   */</span>
<span class="quote">&gt;  extern unsigned long empty_zero_page[PAGE_SIZE / sizeof(unsigned long)];</span>
<span class="quote">&gt; -#define ZERO_PAGE(vaddr)	pfn_to_page(PHYS_PFN(__pa(empty_zero_page)))</span>
<span class="quote">&gt; +#define ZERO_PAGE(vaddr)	pfn_to_page(PHYS_PFN(__pa_symbol(empty_zero_page)))</span>

Nit: I think we can also simplify this to:

	phys_to_page(__pa_symbol(empty_zero_page))

... since phys_to_page(p) is (pfn_to_page(__phys_to_pfn(p)))
... and __phys_to_pfn(p) is PHYS_PFN(p)
<span class="quote">
&gt; diff --git a/arch/arm64/kernel/insn.c b/arch/arm64/kernel/insn.c</span>
<span class="quote">&gt; index 6f2ac4f..af8967a 100644</span>
<span class="quote">&gt; --- a/arch/arm64/kernel/insn.c</span>
<span class="quote">&gt; +++ b/arch/arm64/kernel/insn.c</span>
<span class="quote">&gt; @@ -97,7 +97,7 @@ static void __kprobes *patch_map(void *addr, int fixmap)</span>
<span class="quote">&gt;  	if (module &amp;&amp; IS_ENABLED(CONFIG_DEBUG_SET_MODULE_RONX))</span>
<span class="quote">&gt;  		page = vmalloc_to_page(addr);</span>
<span class="quote">&gt;  	else if (!module)</span>
<span class="quote">&gt; -		page = pfn_to_page(PHYS_PFN(__pa(addr)));</span>
<span class="quote">&gt; +		page = pfn_to_page(PHYS_PFN(__pa_symbol(addr)));</span>

Nit: likewise, we can use phys_to_page() here.
<span class="quote">
&gt; diff --git a/arch/arm64/kernel/vdso.c b/arch/arm64/kernel/vdso.c</span>
<span class="quote">&gt; index a2c2478..791e87a 100644</span>
<span class="quote">&gt; --- a/arch/arm64/kernel/vdso.c</span>
<span class="quote">&gt; +++ b/arch/arm64/kernel/vdso.c</span>
<span class="quote">&gt; @@ -140,11 +140,11 @@ static int __init vdso_init(void)</span>
<span class="quote">&gt;  		return -ENOMEM;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	/* Grab the vDSO data page. */</span>
<span class="quote">&gt; -	vdso_pagelist[0] = pfn_to_page(PHYS_PFN(__pa(vdso_data)));</span>
<span class="quote">&gt; +	vdso_pagelist[0] = pfn_to_page(PHYS_PFN(__pa_symbol(vdso_data)));</span>

Nit: phys_to_page() again.
<span class="quote">
&gt;  </span>
<span class="quote">&gt;  	/* Grab the vDSO code pages. */</span>
<span class="quote">&gt;  	for (i = 0; i &lt; vdso_pages; i++)</span>
<span class="quote">&gt; -		vdso_pagelist[i + 1] = pfn_to_page(PHYS_PFN(__pa(&amp;vdso_start)) + i);</span>
<span class="quote">&gt; +		vdso_pagelist[i + 1] = pfn_to_page(PHYS_PFN(__pa_symbol(&amp;vdso_start)) + i);</span>

Nit: phys_to_page() again.

Thanks,
Mark.
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=30282">Mark Rutland</a> - Nov. 18, 2016, 4:46 p.m.</div>
<pre class="content">
On Fri, Nov 18, 2016 at 02:35:44PM +0000, Mark Rutland wrote:
<span class="quote">&gt; Hi Laura,</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; On Thu, Nov 17, 2016 at 05:16:55PM -0800, Laura Abbott wrote:</span>
<span class="quote">&gt; &gt; </span>
<span class="quote">&gt; &gt; __pa_symbol is technically the marco that should be used for kernel</span>
<span class="quote">&gt; &gt; symbols. Switch to this as a pre-requisite for DEBUG_VIRTUAL which</span>
<span class="quote">&gt; &gt; will do bounds checking.</span>
<span class="quote">&gt; &gt; </span>
<span class="quote">&gt; &gt; Signed-off-by: Laura Abbott &lt;labbott@redhat.com&gt;</span>
<span class="quote">&gt; &gt; ---</span>
<span class="quote">&gt; &gt; v3: Conversion of more sites besides just _end. Addition of __lm_sym_addr</span>
<span class="quote">&gt; &gt; macro to take care of the _va(__pa_symbol(..)) idiom.</span>
<span class="quote">&gt; &gt; </span>
<span class="quote">&gt; &gt; Note that a copy of __pa_symbol was added to avoid a mess of headers</span>
<span class="quote">&gt; &gt; since the #ifndef __pa_symbol case is defined in linux/mm.h</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; I think we also need to fix up virt_to_phys(__cpu_soft_restart) in</span>
<span class="quote">&gt; arch/arm64/kernel/cpu-reset.h. Otherwise, this looks complete for uses</span>
<span class="quote">&gt; falling under arch/arm64/.</span>

I think I spoke too soon. :(

In the kasan code, use of tmp_pg_dir, kasan_zero_{page,pte,pmd,pud} all
need to be vetted, as those are in the image, but get passed directly to
functions which will end up doing a virt_to_phys behind the scenes (e.g.
cpu_replace_ttbr1(), pmd_populate_kernel()).

There&#39;s also some virt_to_pfn(&lt;symbol&gt;) usage that needs to be fixed up
in arch/arm64/kernel/hibernate.c.

... there&#39;s also more of that in common kernel code. :(

Thanks,
Mark.
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=130411">Laura Abbott</a> - Nov. 21, 2016, 5:40 p.m.</div>
<pre class="content">
On 11/18/2016 06:35 AM, Mark Rutland wrote:
<span class="quote">&gt; Hi Laura,</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; On Thu, Nov 17, 2016 at 05:16:55PM -0800, Laura Abbott wrote:</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; __pa_symbol is technically the marco that should be used for kernel</span>
<span class="quote">&gt;&gt; symbols. Switch to this as a pre-requisite for DEBUG_VIRTUAL which</span>
<span class="quote">&gt;&gt; will do bounds checking.</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; Signed-off-by: Laura Abbott &lt;labbott@redhat.com&gt;</span>
<span class="quote">&gt;&gt; ---</span>
<span class="quote">&gt;&gt; v3: Conversion of more sites besides just _end. Addition of __lm_sym_addr</span>
<span class="quote">&gt;&gt; macro to take care of the _va(__pa_symbol(..)) idiom.</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; Note that a copy of __pa_symbol was added to avoid a mess of headers</span>
<span class="quote">&gt;&gt; since the #ifndef __pa_symbol case is defined in linux/mm.h</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; I think we also need to fix up virt_to_phys(__cpu_soft_restart) in</span>
<span class="quote">&gt; arch/arm64/kernel/cpu-reset.h. Otherwise, this looks complete for uses</span>
<span class="quote">&gt; falling under arch/arm64/.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; I also think it&#39;s worth mentioning in the commit message that this patch</span>
<span class="quote">&gt; adds and __lm_sym_addr() and uses it in some places so that low-level</span>
<span class="quote">&gt; helpers can use virt_to_phys() or __pa() consistently.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; The PSCI change doesn&#39;t conflict with patches [1] that&#39;ll go via</span>
<span class="quote">&gt; arm-soc, so I&#39;m happy for that PSCI change to go via the arm64 tree,</span>
<span class="quote">&gt; though it may be worth splitting into its own patch just in case</span>
<span class="quote">&gt; something unexpected crops up.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; With those fixed up:</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Reviewed-by: Mark Rutland &lt;mark.rutland@arm.com&gt;</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; [1] http://lists.infradead.org/pipermail/linux-arm-kernel/2016-November/466522.html</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Otherwise, I just have a few nits below.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt;&gt; @@ -271,7 +271,7 @@ static inline void __kvm_flush_dcache_pud(pud_t pud)</span>
<span class="quote">&gt;&gt;  	kvm_flush_dcache_to_poc(page_address(page), PUD_SIZE);</span>
<span class="quote">&gt;&gt;  }</span>
<span class="quote">&gt;&gt;  </span>
<span class="quote">&gt;&gt; -#define kvm_virt_to_phys(x)		__virt_to_phys((unsigned long)(x))</span>
<span class="quote">&gt;&gt; +#define kvm_virt_to_phys(x)		__pa_symbol((unsigned long)(x))</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Nit: we can drop the unsigned long cast given __pa_symbol() contains</span>
<span class="quote">&gt; one.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt;&gt; diff --git a/arch/arm64/include/asm/pgtable.h b/arch/arm64/include/asm/pgtable.h</span>
<span class="quote">&gt;&gt; index ffbb9a5..c2041a3 100644</span>
<span class="quote">&gt;&gt; --- a/arch/arm64/include/asm/pgtable.h</span>
<span class="quote">&gt;&gt; +++ b/arch/arm64/include/asm/pgtable.h</span>
<span class="quote">&gt;&gt; @@ -52,7 +52,7 @@ extern void __pgd_error(const char *file, int line, unsigned long val);</span>
<span class="quote">&gt;&gt;   * for zero-mapped memory areas etc..</span>
<span class="quote">&gt;&gt;   */</span>
<span class="quote">&gt;&gt;  extern unsigned long empty_zero_page[PAGE_SIZE / sizeof(unsigned long)];</span>
<span class="quote">&gt;&gt; -#define ZERO_PAGE(vaddr)	pfn_to_page(PHYS_PFN(__pa(empty_zero_page)))</span>
<span class="quote">&gt;&gt; +#define ZERO_PAGE(vaddr)	pfn_to_page(PHYS_PFN(__pa_symbol(empty_zero_page)))</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Nit: I think we can also simplify this to:</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; 	phys_to_page(__pa_symbol(empty_zero_page))</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; ... since phys_to_page(p) is (pfn_to_page(__phys_to_pfn(p)))</span>
<span class="quote">&gt; ... and __phys_to_pfn(p) is PHYS_PFN(p)</span>
<span class="quote">&gt; </span>
<span class="quote">&gt;&gt; diff --git a/arch/arm64/kernel/insn.c b/arch/arm64/kernel/insn.c</span>
<span class="quote">&gt;&gt; index 6f2ac4f..af8967a 100644</span>
<span class="quote">&gt;&gt; --- a/arch/arm64/kernel/insn.c</span>
<span class="quote">&gt;&gt; +++ b/arch/arm64/kernel/insn.c</span>
<span class="quote">&gt;&gt; @@ -97,7 +97,7 @@ static void __kprobes *patch_map(void *addr, int fixmap)</span>
<span class="quote">&gt;&gt;  	if (module &amp;&amp; IS_ENABLED(CONFIG_DEBUG_SET_MODULE_RONX))</span>
<span class="quote">&gt;&gt;  		page = vmalloc_to_page(addr);</span>
<span class="quote">&gt;&gt;  	else if (!module)</span>
<span class="quote">&gt;&gt; -		page = pfn_to_page(PHYS_PFN(__pa(addr)));</span>
<span class="quote">&gt;&gt; +		page = pfn_to_page(PHYS_PFN(__pa_symbol(addr)));</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Nit: likewise, we can use phys_to_page() here.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt;&gt; diff --git a/arch/arm64/kernel/vdso.c b/arch/arm64/kernel/vdso.c</span>
<span class="quote">&gt;&gt; index a2c2478..791e87a 100644</span>
<span class="quote">&gt;&gt; --- a/arch/arm64/kernel/vdso.c</span>
<span class="quote">&gt;&gt; +++ b/arch/arm64/kernel/vdso.c</span>
<span class="quote">&gt;&gt; @@ -140,11 +140,11 @@ static int __init vdso_init(void)</span>
<span class="quote">&gt;&gt;  		return -ENOMEM;</span>
<span class="quote">&gt;&gt;  </span>
<span class="quote">&gt;&gt;  	/* Grab the vDSO data page. */</span>
<span class="quote">&gt;&gt; -	vdso_pagelist[0] = pfn_to_page(PHYS_PFN(__pa(vdso_data)));</span>
<span class="quote">&gt;&gt; +	vdso_pagelist[0] = pfn_to_page(PHYS_PFN(__pa_symbol(vdso_data)));</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Nit: phys_to_page() again.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt;&gt;  </span>
<span class="quote">&gt;&gt;  	/* Grab the vDSO code pages. */</span>
<span class="quote">&gt;&gt;  	for (i = 0; i &lt; vdso_pages; i++)</span>
<span class="quote">&gt;&gt; -		vdso_pagelist[i + 1] = pfn_to_page(PHYS_PFN(__pa(&amp;vdso_start)) + i);</span>
<span class="quote">&gt;&gt; +		vdso_pagelist[i + 1] = pfn_to_page(PHYS_PFN(__pa_symbol(&amp;vdso_start)) + i);</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Nit: phys_to_page() again.</span>

I think it makes sense to keep this one as is. It&#39;s offsetting
by pfn number and trying force phys_to_page would make it more
difficult to read.
<span class="quote">
&gt; </span>
<span class="quote">&gt; Thanks,</span>
<span class="quote">&gt; Mark.</span>
<span class="quote">&gt; </span>

Thanks,
Laura
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=30282">Mark Rutland</a> - Nov. 23, 2016, 9:48 a.m.</div>
<pre class="content">
On Mon, Nov 21, 2016 at 09:40:06AM -0800, Laura Abbott wrote:
<span class="quote">&gt; On 11/18/2016 06:35 AM, Mark Rutland wrote:</span>
<span class="quote">&gt; &gt; On Thu, Nov 17, 2016 at 05:16:55PM -0800, Laura Abbott wrote:</span>
<span class="quote">&gt; &gt;&gt;  	/* Grab the vDSO code pages. */</span>
<span class="quote">&gt; &gt;&gt;  	for (i = 0; i &lt; vdso_pages; i++)</span>
<span class="quote">&gt; &gt;&gt; -		vdso_pagelist[i + 1] = pfn_to_page(PHYS_PFN(__pa(&amp;vdso_start)) + i);</span>
<span class="quote">&gt; &gt;&gt; +		vdso_pagelist[i + 1] = pfn_to_page(PHYS_PFN(__pa_symbol(&amp;vdso_start)) + i);</span>
<span class="quote">&gt; &gt; </span>
<span class="quote">&gt; &gt; Nit: phys_to_page() again.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; I think it makes sense to keep this one as is. It&#39;s offsetting</span>
<span class="quote">&gt; by pfn number and trying force phys_to_page would make it more</span>
<span class="quote">&gt; difficult to read.</span>

My bad; I failed to spot the + i.

That sounds good to me; sorry for the noise there.

Thanks,
Mark.
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/arch/arm64/include/asm/kvm_mmu.h b/arch/arm64/include/asm/kvm_mmu.h</span>
<span class="p_header">index 6f72fe8..79a472c 100644</span>
<span class="p_header">--- a/arch/arm64/include/asm/kvm_mmu.h</span>
<span class="p_header">+++ b/arch/arm64/include/asm/kvm_mmu.h</span>
<span class="p_chunk">@@ -47,7 +47,7 @@</span> <span class="p_context"></span>
  * If the page is in the bottom half, we have to use the top half. If
  * the page is in the top half, we have to use the bottom half:
  *
<span class="p_del">- * T = __virt_to_phys(__hyp_idmap_text_start)</span>
<span class="p_add">+ * T = __pa_symbol(__hyp_idmap_text_start)</span>
  * if (T &amp; BIT(VA_BITS - 1))
  *	HYP_VA_MIN = 0  //idmap in upper half
  * else
<span class="p_chunk">@@ -271,7 +271,7 @@</span> <span class="p_context"> static inline void __kvm_flush_dcache_pud(pud_t pud)</span>
 	kvm_flush_dcache_to_poc(page_address(page), PUD_SIZE);
 }
 
<span class="p_del">-#define kvm_virt_to_phys(x)		__virt_to_phys((unsigned long)(x))</span>
<span class="p_add">+#define kvm_virt_to_phys(x)		__pa_symbol((unsigned long)(x))</span>
 
 void kvm_set_way_flush(struct kvm_vcpu *vcpu);
 void kvm_toggle_cache(struct kvm_vcpu *vcpu, bool was_enabled);
<span class="p_header">diff --git a/arch/arm64/include/asm/memory.h b/arch/arm64/include/asm/memory.h</span>
<span class="p_header">index d773e2c..1e65299 100644</span>
<span class="p_header">--- a/arch/arm64/include/asm/memory.h</span>
<span class="p_header">+++ b/arch/arm64/include/asm/memory.h</span>
<span class="p_chunk">@@ -202,11 +202,17 @@</span> <span class="p_context"> static inline void *phys_to_virt(phys_addr_t x)</span>
  * Drivers should NOT use these either.
  */
 #define __pa(x)			__virt_to_phys((unsigned long)(x))
<span class="p_add">+#define __pa_symbol(x)		__pa(RELOC_HIDE((unsigned long)(x), 0))</span>
 #define __va(x)			((void *)__phys_to_virt((phys_addr_t)(x)))
 #define pfn_to_kaddr(pfn)	__va((pfn) &lt;&lt; PAGE_SHIFT)
 #define virt_to_pfn(x)      __phys_to_pfn(__virt_to_phys((unsigned long)(x)))
 
 /*
<span class="p_add">+ * translates a kernel image symbol address into its linear alias.</span>
<span class="p_add">+ */</span>
<span class="p_add">+#define __lm_sym_addr(x)	__va(__pa_symbol(x))</span>
<span class="p_add">+</span>
<span class="p_add">+/*</span>
  *  virt_to_page(k)	convert a _valid_ virtual address to struct page *
  *  virt_addr_valid(k)	indicates whether a virtual address is valid
  */
<span class="p_header">diff --git a/arch/arm64/include/asm/mmu_context.h b/arch/arm64/include/asm/mmu_context.h</span>
<span class="p_header">index a501853..0322322 100644</span>
<span class="p_header">--- a/arch/arm64/include/asm/mmu_context.h</span>
<span class="p_header">+++ b/arch/arm64/include/asm/mmu_context.h</span>
<span class="p_chunk">@@ -44,7 +44,7 @@</span> <span class="p_context"> static inline void contextidr_thread_switch(struct task_struct *next)</span>
  */
 static inline void cpu_set_reserved_ttbr0(void)
 {
<span class="p_del">-	unsigned long ttbr = virt_to_phys(empty_zero_page);</span>
<span class="p_add">+	unsigned long ttbr = __pa_symbol(empty_zero_page);</span>
 
 	write_sysreg(ttbr, ttbr0_el1);
 	isb();
<span class="p_chunk">@@ -113,7 +113,7 @@</span> <span class="p_context"> static inline void cpu_install_idmap(void)</span>
 	local_flush_tlb_all();
 	cpu_set_idmap_tcr_t0sz();
 
<span class="p_del">-	cpu_switch_mm(idmap_pg_dir, &amp;init_mm);</span>
<span class="p_add">+	cpu_switch_mm(__lm_sym_addr(idmap_pg_dir), &amp;init_mm);</span>
 }
 
 /*
<span class="p_chunk">@@ -128,7 +128,7 @@</span> <span class="p_context"> static inline void cpu_replace_ttbr1(pgd_t *pgd)</span>
 
 	phys_addr_t pgd_phys = virt_to_phys(pgd);
 
<span class="p_del">-	replace_phys = (void *)virt_to_phys(idmap_cpu_replace_ttbr1);</span>
<span class="p_add">+	replace_phys = (void *)__pa_symbol(idmap_cpu_replace_ttbr1);</span>
 
 	cpu_install_idmap();
 	replace_phys(pgd_phys);
<span class="p_header">diff --git a/arch/arm64/include/asm/pgtable.h b/arch/arm64/include/asm/pgtable.h</span>
<span class="p_header">index ffbb9a5..c2041a3 100644</span>
<span class="p_header">--- a/arch/arm64/include/asm/pgtable.h</span>
<span class="p_header">+++ b/arch/arm64/include/asm/pgtable.h</span>
<span class="p_chunk">@@ -52,7 +52,7 @@</span> <span class="p_context"> extern void __pgd_error(const char *file, int line, unsigned long val);</span>
  * for zero-mapped memory areas etc..
  */
 extern unsigned long empty_zero_page[PAGE_SIZE / sizeof(unsigned long)];
<span class="p_del">-#define ZERO_PAGE(vaddr)	pfn_to_page(PHYS_PFN(__pa(empty_zero_page)))</span>
<span class="p_add">+#define ZERO_PAGE(vaddr)	pfn_to_page(PHYS_PFN(__pa_symbol(empty_zero_page)))</span>
 
 #define pte_ERROR(pte)		__pte_error(__FILE__, __LINE__, pte_val(pte))
 
<span class="p_header">diff --git a/arch/arm64/kernel/acpi_parking_protocol.c b/arch/arm64/kernel/acpi_parking_protocol.c</span>
<span class="p_header">index a32b401..df58310 100644</span>
<span class="p_header">--- a/arch/arm64/kernel/acpi_parking_protocol.c</span>
<span class="p_header">+++ b/arch/arm64/kernel/acpi_parking_protocol.c</span>
<span class="p_chunk">@@ -109,7 +109,7 @@</span> <span class="p_context"> static int acpi_parking_protocol_cpu_boot(unsigned int cpu)</span>
 	 * that read this address need to convert this address to the
 	 * Boot-Loader&#39;s endianness before jumping.
 	 */
<span class="p_del">-	writeq_relaxed(__pa(secondary_entry), &amp;mailbox-&gt;entry_point);</span>
<span class="p_add">+	writeq_relaxed(__pa_symbol(secondary_entry), &amp;mailbox-&gt;entry_point);</span>
 	writel_relaxed(cpu_entry-&gt;gic_cpu_id, &amp;mailbox-&gt;cpu_id);
 
 	arch_send_wakeup_ipi_mask(cpumask_of(cpu));
<span class="p_header">diff --git a/arch/arm64/kernel/cpufeature.c b/arch/arm64/kernel/cpufeature.c</span>
<span class="p_header">index c02504e..6ccadf2 100644</span>
<span class="p_header">--- a/arch/arm64/kernel/cpufeature.c</span>
<span class="p_header">+++ b/arch/arm64/kernel/cpufeature.c</span>
<span class="p_chunk">@@ -736,7 +736,7 @@</span> <span class="p_context"> static bool runs_at_el2(const struct arm64_cpu_capabilities *entry, int __unused</span>
 static bool hyp_offset_low(const struct arm64_cpu_capabilities *entry,
 			   int __unused)
 {
<span class="p_del">-	phys_addr_t idmap_addr = virt_to_phys(__hyp_idmap_text_start);</span>
<span class="p_add">+	phys_addr_t idmap_addr = __pa_symbol(__hyp_idmap_text_start);</span>
 
 	/*
 	 * Activate the lower HYP offset only if:
<span class="p_header">diff --git a/arch/arm64/kernel/hibernate.c b/arch/arm64/kernel/hibernate.c</span>
<span class="p_header">index d55a7b0..7103b8b 100644</span>
<span class="p_header">--- a/arch/arm64/kernel/hibernate.c</span>
<span class="p_header">+++ b/arch/arm64/kernel/hibernate.c</span>
<span class="p_chunk">@@ -50,9 +50,6 @@</span> <span class="p_context"></span>
  */
 extern int in_suspend;
 
<span class="p_del">-/* Find a symbols alias in the linear map */</span>
<span class="p_del">-#define LMADDR(x)	phys_to_virt(virt_to_phys(x))</span>
<span class="p_del">-</span>
 /* Do we need to reset el2? */
 #define el2_reset_needed() (is_hyp_mode_available() &amp;&amp; !is_kernel_in_hyp_mode())
 
<span class="p_chunk">@@ -125,12 +122,12 @@</span> <span class="p_context"> int arch_hibernation_header_save(void *addr, unsigned int max_size)</span>
 		return -EOVERFLOW;
 
 	arch_hdr_invariants(&amp;hdr-&gt;invariants);
<span class="p_del">-	hdr-&gt;ttbr1_el1		= virt_to_phys(swapper_pg_dir);</span>
<span class="p_add">+	hdr-&gt;ttbr1_el1		= __pa_symbol(swapper_pg_dir);</span>
 	hdr-&gt;reenter_kernel	= _cpu_resume;
 
 	/* We can&#39;t use __hyp_get_vectors() because kvm may still be loaded */
 	if (el2_reset_needed())
<span class="p_del">-		hdr-&gt;__hyp_stub_vectors = virt_to_phys(__hyp_stub_vectors);</span>
<span class="p_add">+		hdr-&gt;__hyp_stub_vectors = __pa_symbol(__hyp_stub_vectors);</span>
 	else
 		hdr-&gt;__hyp_stub_vectors = 0;
 
<span class="p_chunk">@@ -484,7 +481,7 @@</span> <span class="p_context"> int swsusp_arch_resume(void)</span>
 	 * Since we only copied the linear map, we need to find restore_pblist&#39;s
 	 * linear map address.
 	 */
<span class="p_del">-	lm_restore_pblist = LMADDR(restore_pblist);</span>
<span class="p_add">+	lm_restore_pblist = __lm_sym_addr(restore_pblist);</span>
 
 	/*
 	 * We need a zero page that is zero before &amp; after resume in order to
<span class="p_header">diff --git a/arch/arm64/kernel/insn.c b/arch/arm64/kernel/insn.c</span>
<span class="p_header">index 6f2ac4f..af8967a 100644</span>
<span class="p_header">--- a/arch/arm64/kernel/insn.c</span>
<span class="p_header">+++ b/arch/arm64/kernel/insn.c</span>
<span class="p_chunk">@@ -97,7 +97,7 @@</span> <span class="p_context"> static void __kprobes *patch_map(void *addr, int fixmap)</span>
 	if (module &amp;&amp; IS_ENABLED(CONFIG_DEBUG_SET_MODULE_RONX))
 		page = vmalloc_to_page(addr);
 	else if (!module)
<span class="p_del">-		page = pfn_to_page(PHYS_PFN(__pa(addr)));</span>
<span class="p_add">+		page = pfn_to_page(PHYS_PFN(__pa_symbol(addr)));</span>
 	else
 		return addr;
 
<span class="p_header">diff --git a/arch/arm64/kernel/psci.c b/arch/arm64/kernel/psci.c</span>
<span class="p_header">index 42816be..f0f2abb 100644</span>
<span class="p_header">--- a/arch/arm64/kernel/psci.c</span>
<span class="p_header">+++ b/arch/arm64/kernel/psci.c</span>
<span class="p_chunk">@@ -45,7 +45,7 @@</span> <span class="p_context"> static int __init cpu_psci_cpu_prepare(unsigned int cpu)</span>
 
 static int cpu_psci_cpu_boot(unsigned int cpu)
 {
<span class="p_del">-	int err = psci_ops.cpu_on(cpu_logical_map(cpu), __pa(secondary_entry));</span>
<span class="p_add">+	int err = psci_ops.cpu_on(cpu_logical_map(cpu), __pa_symbol(secondary_entry));</span>
 	if (err)
 		pr_err(&quot;failed to boot CPU%d (%d)\n&quot;, cpu, err);
 
<span class="p_header">diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c</span>
<span class="p_header">index f534f49..e2dbc02 100644</span>
<span class="p_header">--- a/arch/arm64/kernel/setup.c</span>
<span class="p_header">+++ b/arch/arm64/kernel/setup.c</span>
<span class="p_chunk">@@ -199,10 +199,10 @@</span> <span class="p_context"> static void __init request_standard_resources(void)</span>
 	struct memblock_region *region;
 	struct resource *res;
 
<span class="p_del">-	kernel_code.start   = virt_to_phys(_text);</span>
<span class="p_del">-	kernel_code.end     = virt_to_phys(__init_begin - 1);</span>
<span class="p_del">-	kernel_data.start   = virt_to_phys(_sdata);</span>
<span class="p_del">-	kernel_data.end     = virt_to_phys(_end - 1);</span>
<span class="p_add">+	kernel_code.start   = __pa_symbol(_text);</span>
<span class="p_add">+	kernel_code.end     = __pa_symbol(__init_begin - 1);</span>
<span class="p_add">+	kernel_data.start   = __pa_symbol(_sdata);</span>
<span class="p_add">+	kernel_data.end     = __pa_symbol(_end - 1);</span>
 
 	for_each_memblock(memory, region) {
 		res = alloc_bootmem_low(sizeof(*res));
<span class="p_header">diff --git a/arch/arm64/kernel/smp_spin_table.c b/arch/arm64/kernel/smp_spin_table.c</span>
<span class="p_header">index 9a00eee..25fccca 100644</span>
<span class="p_header">--- a/arch/arm64/kernel/smp_spin_table.c</span>
<span class="p_header">+++ b/arch/arm64/kernel/smp_spin_table.c</span>
<span class="p_chunk">@@ -98,7 +98,7 @@</span> <span class="p_context"> static int smp_spin_table_cpu_prepare(unsigned int cpu)</span>
 	 * boot-loader&#39;s endianess before jumping. This is mandated by
 	 * the boot protocol.
 	 */
<span class="p_del">-	writeq_relaxed(__pa(secondary_holding_pen), release_addr);</span>
<span class="p_add">+	writeq_relaxed(__pa_symbol(secondary_holding_pen), release_addr);</span>
 	__flush_dcache_area((__force void *)release_addr,
 			    sizeof(*release_addr));
 
<span class="p_header">diff --git a/arch/arm64/kernel/vdso.c b/arch/arm64/kernel/vdso.c</span>
<span class="p_header">index a2c2478..791e87a 100644</span>
<span class="p_header">--- a/arch/arm64/kernel/vdso.c</span>
<span class="p_header">+++ b/arch/arm64/kernel/vdso.c</span>
<span class="p_chunk">@@ -140,11 +140,11 @@</span> <span class="p_context"> static int __init vdso_init(void)</span>
 		return -ENOMEM;
 
 	/* Grab the vDSO data page. */
<span class="p_del">-	vdso_pagelist[0] = pfn_to_page(PHYS_PFN(__pa(vdso_data)));</span>
<span class="p_add">+	vdso_pagelist[0] = pfn_to_page(PHYS_PFN(__pa_symbol(vdso_data)));</span>
 
 	/* Grab the vDSO code pages. */
 	for (i = 0; i &lt; vdso_pages; i++)
<span class="p_del">-		vdso_pagelist[i + 1] = pfn_to_page(PHYS_PFN(__pa(&amp;vdso_start)) + i);</span>
<span class="p_add">+		vdso_pagelist[i + 1] = pfn_to_page(PHYS_PFN(__pa_symbol(&amp;vdso_start)) + i);</span>
 
 	vdso_spec[0].pages = &amp;vdso_pagelist[0];
 	vdso_spec[1].pages = &amp;vdso_pagelist[1];
<span class="p_header">diff --git a/arch/arm64/mm/init.c b/arch/arm64/mm/init.c</span>
<span class="p_header">index 212c4d1..a2981a7 100644</span>
<span class="p_header">--- a/arch/arm64/mm/init.c</span>
<span class="p_header">+++ b/arch/arm64/mm/init.c</span>
<span class="p_chunk">@@ -209,8 +209,8 @@</span> <span class="p_context"> void __init arm64_memblock_init(void)</span>
 	 * linear mapping. Take care not to clip the kernel which may be
 	 * high in memory.
 	 */
<span class="p_del">-	memblock_remove(max_t(u64, memstart_addr + linear_region_size, __pa(_end)),</span>
<span class="p_del">-			ULLONG_MAX);</span>
<span class="p_add">+	memblock_remove(max_t(u64, memstart_addr + linear_region_size,</span>
<span class="p_add">+			__pa_symbol(_end)), ULLONG_MAX);</span>
 	if (memstart_addr + linear_region_size &lt; memblock_end_of_DRAM()) {
 		/* ensure that memstart_addr remains sufficiently aligned */
 		memstart_addr = round_up(memblock_end_of_DRAM() - linear_region_size,
<span class="p_chunk">@@ -225,7 +225,7 @@</span> <span class="p_context"> void __init arm64_memblock_init(void)</span>
 	 */
 	if (memory_limit != (phys_addr_t)ULLONG_MAX) {
 		memblock_mem_limit_remove_map(memory_limit);
<span class="p_del">-		memblock_add(__pa(_text), (u64)(_end - _text));</span>
<span class="p_add">+		memblock_add(__pa_symbol(_text), (u64)(_end - _text));</span>
 	}
 
 	if (IS_ENABLED(CONFIG_BLK_DEV_INITRD) &amp;&amp; initrd_start) {
<span class="p_chunk">@@ -278,7 +278,7 @@</span> <span class="p_context"> void __init arm64_memblock_init(void)</span>
 	 * Register the kernel text, kernel data, initrd, and initial
 	 * pagetables with memblock.
 	 */
<span class="p_del">-	memblock_reserve(__pa(_text), _end - _text);</span>
<span class="p_add">+	memblock_reserve(__pa_symbol(_text), _end - _text);</span>
 #ifdef CONFIG_BLK_DEV_INITRD
 	if (initrd_start) {
 		memblock_reserve(initrd_start, initrd_end - initrd_start);
<span class="p_chunk">@@ -483,7 +483,8 @@</span> <span class="p_context"> void __init mem_init(void)</span>
 
 void free_initmem(void)
 {
<span class="p_del">-	free_reserved_area(__va(__pa(__init_begin)), __va(__pa(__init_end)),</span>
<span class="p_add">+	free_reserved_area(__lm_sym_addr(__init_begin),</span>
<span class="p_add">+			   __lm_sym_addr(__init_end),</span>
 			   0, &quot;unused kernel&quot;);
 	/*
 	 * Unmap the __init region but leave the VM area in place. This
<span class="p_header">diff --git a/arch/arm64/mm/mmu.c b/arch/arm64/mm/mmu.c</span>
<span class="p_header">index 05615a3..cf04157 100644</span>
<span class="p_header">--- a/arch/arm64/mm/mmu.c</span>
<span class="p_header">+++ b/arch/arm64/mm/mmu.c</span>
<span class="p_chunk">@@ -319,8 +319,8 @@</span> <span class="p_context"> static void create_mapping_late(phys_addr_t phys, unsigned long virt,</span>
 
 static void __init __map_memblock(pgd_t *pgd, phys_addr_t start, phys_addr_t end)
 {
<span class="p_del">-	unsigned long kernel_start = __pa(_text);</span>
<span class="p_del">-	unsigned long kernel_end = __pa(__init_begin);</span>
<span class="p_add">+	unsigned long kernel_start = __pa_symbol(_text);</span>
<span class="p_add">+	unsigned long kernel_end = __pa_symbol(__init_begin);</span>
 
 	/*
 	 * Take care not to create a writable alias for the
<span class="p_chunk">@@ -387,21 +387,21 @@</span> <span class="p_context"> void mark_rodata_ro(void)</span>
 	unsigned long section_size;
 
 	section_size = (unsigned long)_etext - (unsigned long)_text;
<span class="p_del">-	create_mapping_late(__pa(_text), (unsigned long)_text,</span>
<span class="p_add">+	create_mapping_late(__pa_symbol(_text), (unsigned long)_text,</span>
 			    section_size, PAGE_KERNEL_ROX);
 	/*
 	 * mark .rodata as read only. Use __init_begin rather than __end_rodata
 	 * to cover NOTES and EXCEPTION_TABLE.
 	 */
 	section_size = (unsigned long)__init_begin - (unsigned long)__start_rodata;
<span class="p_del">-	create_mapping_late(__pa(__start_rodata), (unsigned long)__start_rodata,</span>
<span class="p_add">+	create_mapping_late(__pa_symbol(__start_rodata), (unsigned long)__start_rodata,</span>
 			    section_size, PAGE_KERNEL_RO);
 }
 
 static void __init map_kernel_segment(pgd_t *pgd, void *va_start, void *va_end,
 				      pgprot_t prot, struct vm_struct *vma)
 {
<span class="p_del">-	phys_addr_t pa_start = __pa(va_start);</span>
<span class="p_add">+	phys_addr_t pa_start = __pa_symbol(va_start);</span>
 	unsigned long size = va_end - va_start;
 
 	BUG_ON(!PAGE_ALIGNED(pa_start));
<span class="p_chunk">@@ -449,7 +449,7 @@</span> <span class="p_context"> static void __init map_kernel(pgd_t *pgd)</span>
 		 */
 		BUG_ON(!IS_ENABLED(CONFIG_ARM64_16K_PAGES));
 		set_pud(pud_set_fixmap_offset(pgd, FIXADDR_START),
<span class="p_del">-			__pud(__pa(bm_pmd) | PUD_TYPE_TABLE));</span>
<span class="p_add">+			__pud(__pa_symbol(bm_pmd) | PUD_TYPE_TABLE));</span>
 		pud_clear_fixmap();
 	} else {
 		BUG();
<span class="p_chunk">@@ -480,7 +480,7 @@</span> <span class="p_context"> void __init paging_init(void)</span>
 	 */
 	cpu_replace_ttbr1(__va(pgd_phys));
 	memcpy(swapper_pg_dir, pgd, PAGE_SIZE);
<span class="p_del">-	cpu_replace_ttbr1(swapper_pg_dir);</span>
<span class="p_add">+	cpu_replace_ttbr1(__lm_sym_addr(swapper_pg_dir));</span>
 
 	pgd_clear_fixmap();
 	memblock_free(pgd_phys, PAGE_SIZE);
<span class="p_chunk">@@ -489,7 +489,7 @@</span> <span class="p_context"> void __init paging_init(void)</span>
 	 * We only reuse the PGD from the swapper_pg_dir, not the pud + pmd
 	 * allocated with it.
 	 */
<span class="p_del">-	memblock_free(__pa(swapper_pg_dir) + PAGE_SIZE,</span>
<span class="p_add">+	memblock_free(__pa_symbol(swapper_pg_dir) + PAGE_SIZE,</span>
 		      SWAPPER_DIR_SIZE - PAGE_SIZE);
 }
 
<span class="p_chunk">@@ -609,7 +609,7 @@</span> <span class="p_context"> void __init early_fixmap_init(void)</span>
 
 	pgd = pgd_offset_k(addr);
 	if (CONFIG_PGTABLE_LEVELS &gt; 3 &amp;&amp;
<span class="p_del">-	    !(pgd_none(*pgd) || pgd_page_paddr(*pgd) == __pa(bm_pud))) {</span>
<span class="p_add">+	    !(pgd_none(*pgd) || pgd_page_paddr(*pgd) == __pa_symbol(bm_pud))) {</span>
 		/*
 		 * We only end up here if the kernel mapping and the fixmap
 		 * share the top level pgd entry, which should only happen on
<span class="p_chunk">@@ -618,12 +618,12 @@</span> <span class="p_context"> void __init early_fixmap_init(void)</span>
 		BUG_ON(!IS_ENABLED(CONFIG_ARM64_16K_PAGES));
 		pud = pud_offset_kimg(pgd, addr);
 	} else {
<span class="p_del">-		pgd_populate(&amp;init_mm, pgd, bm_pud);</span>
<span class="p_add">+		pgd_populate(&amp;init_mm, pgd, __lm_sym_addr(bm_pud));</span>
 		pud = fixmap_pud(addr);
 	}
<span class="p_del">-	pud_populate(&amp;init_mm, pud, bm_pmd);</span>
<span class="p_add">+	pud_populate(&amp;init_mm, pud, __lm_sym_addr(bm_pmd));</span>
 	pmd = fixmap_pmd(addr);
<span class="p_del">-	pmd_populate_kernel(&amp;init_mm, pmd, bm_pte);</span>
<span class="p_add">+	pmd_populate_kernel(&amp;init_mm, pmd, __lm_sym_addr(bm_pte));</span>
 
 	/*
 	 * The boot-ioremap range spans multiple pmds, for which
<span class="p_header">diff --git a/drivers/firmware/psci.c b/drivers/firmware/psci.c</span>
<span class="p_header">index 8263429..9defbe2 100644</span>
<span class="p_header">--- a/drivers/firmware/psci.c</span>
<span class="p_header">+++ b/drivers/firmware/psci.c</span>
<span class="p_chunk">@@ -383,7 +383,7 @@</span> <span class="p_context"> static int psci_suspend_finisher(unsigned long index)</span>
 	u32 *state = __this_cpu_read(psci_power_state);
 
 	return psci_ops.cpu_suspend(state[index - 1],
<span class="p_del">-				    virt_to_phys(cpu_resume));</span>
<span class="p_add">+				    __pa_symbol(cpu_resume));</span>
 }
 
 int psci_cpu_suspend_enter(unsigned long index)

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



