
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>Linux 3.16.36 - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    Linux 3.16.36</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=131">Ben Hutchings</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>June 16, 2016, 10:54 a.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;20160616105438.GB7555@decadent.org.uk&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/9180469/mbox/"
   >mbox</a>
|
   <a href="/patch/9180469/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/9180469/">/patch/9180469/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
	[172.30.200.125])
	by pdx-korg-patchwork.web.codeaurora.org (Postfix) with ESMTP id
	BCBCE60760 for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Thu, 16 Jun 2016 10:55:36 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 9D57E27DA4
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Thu, 16 Jun 2016 10:55:36 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id 9044D282EE; Thu, 16 Jun 2016 10:55:36 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-6.9 required=2.0 tests=BAYES_00,RCVD_IN_DNSWL_HI
	autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 64EED27DA4
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Thu, 16 Jun 2016 10:55:26 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1754172AbcFPKzO (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Thu, 16 Jun 2016 06:55:14 -0400
Received: from shadbolt.e.decadent.org.uk ([88.96.1.126]:36196 &quot;EHLO
	shadbolt.e.decadent.org.uk&quot; rhost-flags-OK-OK-OK-OK)
	by vger.kernel.org with ESMTP id S1751683AbcFPKyx (ORCPT
	&lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Thu, 16 Jun 2016 06:54:53 -0400
Received: from ben by shadbolt.decadent.org.uk with local (Exim 4.84_2)
	(envelope-from &lt;ben@decadent.org.uk&gt;)
	id 1bDUwY-000630-SY; Thu, 16 Jun 2016 11:54:48 +0100
Date: Thu, 16 Jun 2016 11:54:38 +0100
From: Ben Hutchings &lt;ben@decadent.org.uk&gt;
To: linux-kernel@vger.kernel.org, Andrew Morton &lt;akpm@linux-foundation.org&gt;,
	torvalds@linux-foundation.org, Jiri Slaby &lt;jslaby@suse.cz&gt;,
	stable@vger.kernel.org
Cc: lwn@lwn.net
Message-ID: &lt;20160616105438.GB7555@decadent.org.uk&gt;
MIME-Version: 1.0
Content-Type: multipart/signed; micalg=pgp-sha512;
	protocol=&quot;application/pgp-signature&quot;; boundary=&quot;p0aHTXLXY/BobAxh&quot;
Content-Disposition: inline
X-Mailer: LinuxStableQueue (scripts by bwh)
User-Agent: Mutt/1.5.23 (2014-03-12)
X-SA-Exim-Connect-IP: &lt;locally generated&gt;
X-SA-Exim-Mail-From: ben@decadent.org.uk
Subject: Linux 3.16.36
X-SA-Exim-Version: 4.2.1 (built Mon, 26 Dec 2011 16:24:06 +0000)
X-SA-Exim-Scanned: Yes (on shadbolt.decadent.org.uk)
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=131">Ben Hutchings</a> - June 16, 2016, 10:54 a.m.</div>
<pre class="content">
I&#39;m announcing the release of the 3.16.36 kernel.

All users of the 3.16 kernel series should upgrade.

The updated 3.16.y git tree can be found at:
        https://git.kernel.org/pub/scm/linux/kernel/git/stable/linux-stable.git linux-3.16.y
and can be browsed at the normal kernel.org git web browser:
        https://git.kernel.org/?p=linux/kernel/git/stable/linux-stable.git

The diff from 3.16.35 is attached to this message.

Ben.

------------

 Documentation/kernel-parameters.txt            |   2 +
 MAINTAINERS                                    |   4 +-
 Makefile                                       |   2 +-
 arch/arc/include/asm/atomic.h                  |   2 +-
 arch/arm/mach-omap2/omap_hwmod.c               |  12 ++-
 arch/arm/mach-socfpga/headsmp.S                |   1 +
 arch/arm64/kernel/Makefile                     |   3 +-
 arch/arm64/kernel/head.S                       |   5 +
 arch/arm64/kernel/psci-call.S                  |  28 ++++++
 arch/arm64/kernel/psci.c                       |  37 +------
 arch/arm64/mm/proc-macros.S                    |  12 +++
 arch/arm64/mm/proc.S                           |   4 +-
 arch/parisc/kernel/syscall.S                   |   2 +-
 arch/powerpc/include/asm/word-at-a-time.h      |   2 +-
 arch/powerpc/include/uapi/asm/cputable.h       |   1 +
 arch/powerpc/kernel/prom.c                     |   2 +-
 arch/s390/include/asm/hugetlb.h                |   1 +
 arch/s390/lib/spinlock.c                       |   1 +
 arch/x86/include/asm/hugetlb.h                 |   1 +
 arch/x86/kernel/sysfb_efi.c                    |  14 ++-
 arch/x86/kernel/tsc_msr.c                      |   2 +-
 arch/x86/kvm/x86.c                             |  10 +-
 crypto/ahash.c                                 |   3 +-
 drivers/acpi/acpica/dsmethod.c                 |   3 +
 drivers/ata/libahci.c                          |   1 +
 drivers/base/regmap/regmap-spmi.c              |   2 +-
 drivers/block/rbd.c                            |  43 ++++-----
 drivers/crypto/ccp/ccp-crypto-aes-cmac.c       |   3 +
 drivers/crypto/ccp/ccp-crypto-sha.c            |   3 +
 drivers/edac/i7core_edac.c                     |   2 +-
 drivers/edac/sb_edac.c                         |   2 +-
 drivers/firmware/efi/vars.c                    |  37 ++++---
 drivers/gpu/drm/i915/i915_drv.c                |  32 +++++++
 drivers/gpu/drm/i915/i915_gem_userptr.c        |  29 +++---
 drivers/gpu/drm/i915/intel_crt.c               |   8 +-
 drivers/gpu/drm/qxl/qxl_display.c              |  13 ++-
 drivers/gpu/drm/qxl/qxl_drv.h                  |   2 +
 drivers/gpu/drm/radeon/atombios_crtc.c         |  10 ++
 drivers/gpu/drm/radeon/atombios_encoders.c     |   4 +
 drivers/gpu/drm/radeon/si_dpm.c                |   1 +
 drivers/hid/usbhid/hid-core.c                  |  73 +++++++-------
 drivers/hv/ring_buffer.c                       |  34 ++++---
 drivers/i2c/busses/i2c-exynos5.c               |  24 ++++-
 drivers/iio/magnetometer/ak8975.c              |   4 +-
 drivers/infiniband/core/ucm.c                  |   4 +
 drivers/infiniband/core/ucma.c                 |   3 +
 drivers/infiniband/core/uverbs_main.c          |   5 +
 drivers/infiniband/hw/ipath/ipath_file_ops.c   |   5 +
 drivers/infiniband/hw/qib/qib_file_ops.c       |   5 +
 drivers/input/misc/pmic8xxx-pwrkey.c           |   7 +-
 drivers/input/tablet/gtco.c                    |  10 +-
 drivers/net/ethernet/atheros/atlx/atl2.c       |   2 +-
 drivers/net/ethernet/broadcom/genet/bcmgenet.c |   6 +-
 drivers/net/ethernet/mellanox/mlx4/en_tx.c     |   6 +-
 drivers/net/ethernet/ti/davinci_emac.c         |   3 +-
 drivers/net/macvtap.c                          |   2 +-
 drivers/pinctrl/pinctrl-single.c               |   6 +-
 drivers/regulator/s2mps11.c                    |   4 +-
 drivers/s390/block/scm_blk.c                   |   2 +-
 drivers/spi/spi-ti-qspi.c                      |  45 +++++----
 drivers/usb/core/hcd-pci.c                     |   9 ++
 drivers/usb/host/xhci-mem.c                    |   6 ++
 drivers/usb/host/xhci-pci.c                    |   4 +-
 drivers/usb/serial/cp210x.c                    |   4 +
 drivers/usb/storage/uas.c                      |  14 ++-
 drivers/usb/storage/unusual_uas.h              |   7 ++
 drivers/usb/storage/usb.c                      |   5 +-
 drivers/virtio/virtio_balloon.c                |  15 ++-
 fs/ceph/mds_client.c                           |   6 +-
 fs/isofs/rock.c                                |  13 ++-
 fs/namei.c                                     |  20 +---
 fs/ocfs2/acl.c                                 |  63 ++++++++++++
 fs/ocfs2/acl.h                                 |   4 +
 fs/ocfs2/namei.c                               |  23 +----
 fs/ocfs2/refcounttree.c                        |  17 +---
 fs/ocfs2/xattr.c                               |  14 +--
 fs/ocfs2/xattr.h                               |   4 +-
 fs/pnode.c                                     |  32 ++++---
 fs/proc/base.c                                 |   3 +-
 fs/xfs/xfs_bmap_util.c                         |  53 +++++-----
 fs/xfs/xfs_file.c                              |  76 +++++++++++----
 fs/xfs/xfs_inode.c                             | 128 +++++++++++++++++++------
 fs/xfs/xfs_inode.h                             |  29 ++++--
 fs/xfs/xfs_ioctl.c                             |   4 +-
 fs/xfs/xfs_iops.c                              |  31 +++---
 fs/xfs/xfs_super.c                             |   2 +
 fs/xfs/xfs_trace.h                             |   3 +
 include/linux/balloon_compaction.h             |  97 +++++--------------
 include/linux/ceph/auth.h                      |  10 +-
 include/linux/ceph/osd_client.h                |   1 -
 include/linux/compiler-gcc.h                   | 120 ++++++++++++++++++++++-
 include/linux/compiler-gcc3.h                  |  23 -----
 include/linux/compiler-gcc4.h                  |  88 -----------------
 include/linux/compiler-gcc5.h                  |  66 -------------
 include/linux/hash.h                           |  20 ++++
 include/linux/hugetlb.h                        |  17 ++--
 include/linux/mfd/samsung/s2mps11.h            |   2 +
 include/linux/migrate.h                        |  11 +--
 include/linux/mm.h                             |  19 ++++
 include/linux/netdevice.h                      |  21 +---
 include/linux/usb_usual.h                      |   2 +
 include/rdma/ib.h                              |  16 ++++
 kernel/futex.c                                 |   2 +-
 kernel/sched/core.c                            |  60 +++++++++---
 kernel/sched/deadline.c                        |  68 +++++++------
 kernel/sched/rt.c                              |  74 +++++++-------
 kernel/sched/sched.h                           |  19 +++-
 kernel/trace/trace_events.c                    |   9 +-
 kernel/workqueue.c                             |  29 ++++++
 lib/asn1_decoder.c                             |  16 ++--
 lib/assoc_array.c                              |   4 +-
 lib/lz4/lz4defs.h                              |  21 ++--
 mm/balloon_compaction.c                        |  28 +++---
 mm/compaction.c                                |   2 +-
 mm/huge_memory.c                               |   6 +-
 mm/migrate.c                                   |  70 +++++++-------
 net/ax25/ax25_ip.c                             |  15 ---
 net/batman-adv/distributed-arp-table.c         |  20 ++--
 net/batman-adv/routing.c                       |   9 ++
 net/batman-adv/send.c                          |   6 ++
 net/batman-adv/soft-interface.c                |   8 +-
 net/batman-adv/translation-table.c             |  44 +--------
 net/batman-adv/types.h                         |   2 +
 net/ceph/auth.c                                |   8 +-
 net/ceph/auth_none.c                           |  71 +++++++-------
 net/ceph/auth_none.h                           |   3 +-
 net/ceph/auth_x.c                              |  21 ++--
 net/ceph/auth_x.h                              |   1 +
 net/ceph/osd_client.c                          |   9 +-
 net/core/rtnetlink.c                           |  18 ++--
 net/llc/af_llc.c                               |   1 +
 net/netfilter/nf_conntrack_core.c              |   4 +-
 net/packet/af_packet.c                         |   1 +
 net/wireless/nl80211.c                         |   2 +-
 net/x25/x25_facilities.c                       |   1 +
 sound/pci/hda/patch_realtek.c                  |  14 +++
 sound/soc/codecs/rt5640.c                      |   2 +-
 sound/soc/codecs/rt5640.h                      |  36 +++----
 sound/usb/mixer_maps.c                         |  14 +++
 tools/lib/traceevent/parse-filter.c            |   4 +-
 140 files changed, 1416 insertions(+), 1004 deletions(-)

Al Viro (2):
      atomic_open(): fix the handling of create_error
      get_rock_ridge_filename(): handle malformed NM entries

Alan Stern (1):
      HID: usbhid: fix inconsistent reset/resume/reset-resume behavior

Alex Deucher (2):
      drm/radeon: add a quirk for a XFX R9 270X
      drm/radeon: make sure vertical front porch is at least 1

Anton Blanchard (2):
      powerpc: scan_features() updates incorrect bits for REAL_LE
      powerpc: Fix bad inline asm constraint in create_zero_mask()

Antonio Quartulli (1):
      batman-adv: fix DAT candidate selection (must use vid)

Ben Hutchings (6):
      Revert &quot;ax25: add link layer header validation function&quot;
      Revert &quot;net: validate variable length ll headers&quot;
      spi: spi-ti-qspi: Fix FLEN and WLEN settings if bits_per_word is overridden
      spi: spi-ti-qspi: Handle truncated frames properly
      atl2: Disable unimplemented scatter/gather feature
      Linux 3.16.36

Chen Yu (1):
      x86/tsc: Read all ratio bits from MSR_PLATFORM_INFO

Chris Wilson (1):
      drm/i915/userptr: Hold mmref whilst calling get-user-pages

Christopher Oo (1):
      Drivers: hv_vmbus: Fix signal to host condition

Chunyu Hu (1):
      tracing: Don&#39;t display trigger file for events that can&#39;t be enabled

Conrad Kostecki (1):
      ALSA: hda - Add dock support for ThinkPad X260

Dan Carpenter (1):
      ocfs2: dereferencing freed pointers in ocfs2_reflink()

Daniel Vetter (1):
      drm/i915: Bail out of pipe config compute loop on LPT

Dave Chinner (8):
      xfs: fix swapext ilock deadlock
      xfs: introduce mmap/truncate lock
      xfs: use i_mmaplock on read faults
      xfs: use i_mmaplock on write faults
      xfs: take i_mmap_lock on extent manipulation operations
      xfs: xfs_setattr_size no longer races with page faults
      xfs: lock out page faults from extent swap operations
      xfs: mmap lock needs to be inside freeze protection

David Howells (1):
      KEYS: Fix ASN.1 indefinite length object parsing

David Matlack (1):
      kvm: x86: do not leak guest xcr0 into host interrupt handlers

Davidlohr Bueso (1):
      futex: Acknowledge a new waiter in counter before plist

Dmitry Ivanov (1):
      nl80211: check netlink protocol in socket release notification

Dmitry V. Levin (1):
      parisc: fix a bug when syscall number of tracee is __NR_Linux_syscalls

Dominik Dingel (2):
      mm: hugetlb: allow hugepages_supported to be architecture specific
      s390/hugetlb: add hugepages_supported define

Eric Dumazet (3):
      net: bcmgenet: device stats are unsigned long
      net/mlx4_en: fix spurious timestamping callbacks
      macvtap: segmented packet is consumed

Eric W. Biederman (1):
      propogate_mnt: Handle the first propogated copy being a slave

Hans de Goede (1):
      USB: uas: Add a new NO_REPORT_LUNS quirk

Heiko Carstens (1):
      s390/spinlock: avoid yield to non existent cpu

Herbert Xu (1):
      crypto: hash - Fix page length clamping in hash walk

Hugh Dickins (1):
      mm: migrate dirty page without clear_page_dirty_for_io etc

Ilya Dryomov (3):
      libceph: kfree() in put_osd() shouldn&#39;t depend on authorizer
      libceph: make authorizer destruction independent of ceph_auth_client
      rbd: fix rbd map vs notify races

Imre Deak (1):
      drm/i915: Fix system resume if PCI device remained enabled

Jack Pham (1):
      regmap: spmi: Fix regmap_spmi_ext_read in multi-byte case

Jan Beulich (1):
      x86/mm/xen: Suppress hugetlbfs in PV guests

Jasem Mutlaq (1):
      USB: serial: cp210x: add Straizona Focusers device ids

Jason Gunthorpe (1):
      IB/security: Restrict use of the write() interface

Javier Martinez Canillas (1):
      i2c: exynos5: Fix possible ABBA deadlock by keeping I2C clock prepared

Jerome Marchand (1):
      assoc_array: don&#39;t call compare_object() on a node

Joe Perches (1):
      compiler-gcc: integrate the various compiler-gcc[345].h files

John Keeping (1):
      drm/qxl: fix cursor position with non-zero hotspot

Jon Hunter (1):
      ARM: OMAP2+: Only write the sysconfig on idle when necessary

Junxiao Bi (1):
      ocfs2: fix posix_acl_create deadlock

K. Y. Srinivasan (1):
      Drivers: hv: vmbus: Fix signaling logic in hv_need_to_signal_on_read()

Kaho Ng (1):
      ALSA: hda - Fix white noise on Asus UX501VW headset

Kailang Yang (1):
      ALSA: usb-audio: Skip volume controls triggers hangup on Dell USB Dock

Kangjie Lu (3):
      net: fix infoleak in llc
      net: fix infoleak in rtnetlink
      net: fix a kernel infoleak in x25 module

Keerthy (1):
      pinctrl: single: Fix pcs_parse_bits_in_pinctrl_entry to use __ffs than ffs

Konstantin Khlebnikov (3):
      mm/huge_memory: replace VM_NO_THP VM_BUG_ON with actual VMA check
      mm/balloon_compaction: redesign ballooned pages management
      mm/balloon_compaction: fix deflation when compaction is disabled

Krzysztof Kozlowski (2):
      regulator: s2mps11: Fix invalid selector mask and voltages for buck9
      iio: ak8975: Fix NULL pointer exception on early interrupt

Laszlo Ersek (1):
      efi: Fix out-of-bounds read in variable_matches()

Linus Lüssing (1):
      batman-adv: Fix broadcast/ogm queue limit on a removed interface

Linus Torvalds (3):
      Make hash_64() use a 64-bit multiply when appropriate
      Minimal fix-up of bad hashing behavior of hash_64()
      nf_conntrack: avoid kernel pointer value leak in slab name

Lokesh Vutla (1):
      ARM: OMAP2+: hwmod: Fix updating of sysconfig register

Lorenzo Pieralisi (1):
      arm64: kernel: fix architected PMU registers unconditional access

Lu Baolu (1):
      usb: xhci: fix wild pointers in xhci_mem_cleanup

Lucas Stach (1):
      drm/radeon: fix PLL sharing on DCE6.1 (v2)

Mathias Krause (2):
      packet: fix heap info leak in PACKET_DIAG_MCLIST sock_diag interface
      proc: prevent accessing /proc/&lt;PID&gt;/environ until it&#39;s ready

Matt Fleming (1):
      MAINTAINERS: Remove asterisk from EFI directory names

Maxim Patlasov (1):
      fs/pnode.c: treat zero mnt_group_id-s as unequal

Mike Manning (1):
      USB: serial: cp210x: add ID for Link ECU

Neil Armstrong (2):
      net: ethernet: davinci_emac: Fix Unbalanced pm_runtime_enable
      net: ethernet: davinci_emac: Fix platform_data overwrite

Peter Zijlstra (6):
      sched: Replace post_schedule with a balance callback list
      sched: Allow balance callbacks for check_class_changed()
      sched,rt: Remove return value from pull_rt_task()
      sched, rt: Convert switched_{from, to}_rt() / prio_changed_rt() to balance callbacks
      sched,dl: Remove return value from pull_dl_task()
      sched, dl: Convert switched_{from, to}_dl() / prio_changed_dl() to balance callbacks

Prarit Bhargava (1):
      ACPICA: Dispatcher: Update thread ID for recursive method calls

Rafal Redzimski (1):
      usb: xhci: applying XHCI_PME_STUCK_QUIRK to Intel BXT B0 host

Robert Dobrowolski (1):
      usb: hcd: out of bounds access in for_each_companion

Roman Pen (1):
      workqueue: fix ghost PENDING flag while doing MQ IO

Rui Salvaterra (1):
      lib: lz4: fixed zram with lz4 on big endian machines

Sascha Hauer (1):
      ARM: SoCFPGA: Fix secondary CPU startup in thumb2 kernel

Sebastian Ott (1):
      s390/scm_blk: fix deadlock for requests != REQ_TYPE_FS

Srinivas Kandagatla (1):
      libahci: save port map for forced port map

Stephen Boyd (1):
      Input: pmic8xxx-pwrkey - fix algorithm for converting trigger delay

Steven Rostedt (1):
      tools lib traceevent: Do not reassign parg after collapse_tree()

Sugar Zhang (1):
      ASoC: rt5640: Correct the digital interface data select

Sven Eckelmann (4):
      batman-adv: Check skb size before using encapsulated ETH+VLAN header
      batman-adv: Reduce refcnt of removed router when updating route
      batman-adv: Fix invalid stack access in batadv_dat_select_candidates
      batman-adv: Fix reference counting of vlan object for tt_local_entry

Tom Lendacky (1):
      crypto: ccp - Prevent information leakage on export

Tony Luck (1):
      EDAC: i7core, sb_edac: Don&#39;t return NOTIFY_BAD from mce_decoder callback

Vineet Gupta (1):
      ARC: unbork !LLSC build

Vladis Dronov (1):
      Input: gtco - fix crash on detecting device without endpoints

Wang YanQing (1):
      x86/sysfb_efi: Fix valid BAR address range check

Will Deacon (1):
      arm64: psci: move psci firmware calls out of line

Yura Pakhuchiy (1):
      ALSA: hda - Fix subwoofer pin on ASUS N751 and N551
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/Documentation/kernel-parameters.txt b/Documentation/kernel-parameters.txt</span>
<span class="p_header">index f6ca2e530727..590bf00677a5 100644</span>
<span class="p_header">--- a/Documentation/kernel-parameters.txt</span>
<span class="p_header">+++ b/Documentation/kernel-parameters.txt</span>
<span class="p_chunk">@@ -3469,6 +3469,8 @@</span> <span class="p_context"> bytes respectively. Such letter suffixes can also be entirely omitted.</span>
 					sector if the number is odd);
 				i = IGNORE_DEVICE (don&#39;t bind to this
 					device);
<span class="p_add">+				j = NO_REPORT_LUNS (don&#39;t use report luns</span>
<span class="p_add">+					command, uas only);</span>
 				l = NOT_LOCKABLE (don&#39;t try to lock and
 					unlock ejectable media);
 				m = MAX_SECTORS_64 (don&#39;t transfer more
<span class="p_header">diff --git a/MAINTAINERS b/MAINTAINERS</span>
<span class="p_header">index 1278d1950d05..8a5cae0ca281 100644</span>
<span class="p_header">--- a/MAINTAINERS</span>
<span class="p_header">+++ b/MAINTAINERS</span>
<span class="p_chunk">@@ -3394,8 +3394,8 @@</span> <span class="p_context"> F:	Documentation/x86/efi-stub.txt</span>
 F:	arch/ia64/kernel/efi.c
 F:	arch/x86/boot/compressed/eboot.[ch]
 F:	arch/x86/include/asm/efi.h
<span class="p_del">-F:	arch/x86/platform/efi/*</span>
<span class="p_del">-F:	drivers/firmware/efi/*</span>
<span class="p_add">+F:	arch/x86/platform/efi/</span>
<span class="p_add">+F:	drivers/firmware/efi/</span>
 F:	include/linux/efi*.h
 
 EFI VARIABLE FILESYSTEM
<span class="p_header">diff --git a/Makefile b/Makefile</span>
<span class="p_header">index c0de843980f0..50b4f93c0054 100644</span>
<span class="p_header">--- a/Makefile</span>
<span class="p_header">+++ b/Makefile</span>
<span class="p_chunk">@@ -1,6 +1,6 @@</span> <span class="p_context"></span>
 VERSION = 3
 PATCHLEVEL = 16
<span class="p_del">-SUBLEVEL = 35</span>
<span class="p_add">+SUBLEVEL = 36</span>
 EXTRAVERSION =
 NAME = Museum of Fishiegoodies
 
<span class="p_header">diff --git a/arch/arc/include/asm/atomic.h b/arch/arc/include/asm/atomic.h</span>
<span class="p_header">index 223138716c2e..7ace56e6ad23 100644</span>
<span class="p_header">--- a/arch/arc/include/asm/atomic.h</span>
<span class="p_header">+++ b/arch/arc/include/asm/atomic.h</span>
<span class="p_chunk">@@ -109,7 +109,7 @@</span> <span class="p_context"> static inline void atomic_##op(int i, atomic_t *v)			\</span>
 	atomic_ops_unlock(flags);					\
 }
 
<span class="p_del">-#define ATOMIC_OP_RETURN(op, c_op)					\</span>
<span class="p_add">+#define ATOMIC_OP_RETURN(op, c_op, asm_op)				\</span>
 static inline int atomic_##op##_return(int i, atomic_t *v)		\
 {									\
 	unsigned long flags;						\
<span class="p_header">diff --git a/arch/arm/mach-omap2/omap_hwmod.c b/arch/arm/mach-omap2/omap_hwmod.c</span>
<span class="p_header">index 4711dd06d7b5..6849ae81a560 100644</span>
<span class="p_header">--- a/arch/arm/mach-omap2/omap_hwmod.c</span>
<span class="p_header">+++ b/arch/arm/mach-omap2/omap_hwmod.c</span>
<span class="p_chunk">@@ -1439,9 +1439,7 @@</span> <span class="p_context"> static void _enable_sysc(struct omap_hwmod *oh)</span>
 	    (sf &amp; SYSC_HAS_CLOCKACTIVITY))
 		_set_clockactivity(oh, oh-&gt;class-&gt;sysc-&gt;clockact, &amp;v);
 
<span class="p_del">-	/* If the cached value is the same as the new value, skip the write */</span>
<span class="p_del">-	if (oh-&gt;_sysc_cache != v)</span>
<span class="p_del">-		_write_sysconfig(v, oh);</span>
<span class="p_add">+	_write_sysconfig(v, oh);</span>
 
 	/*
 	 * Set the autoidle bit only after setting the smartidle bit
<span class="p_chunk">@@ -1504,7 +1502,9 @@</span> <span class="p_context"> static void _idle_sysc(struct omap_hwmod *oh)</span>
 		_set_master_standbymode(oh, idlemode, &amp;v);
 	}
 
<span class="p_del">-	_write_sysconfig(v, oh);</span>
<span class="p_add">+	/* If the cached value is the same as the new value, skip the write */</span>
<span class="p_add">+	if (oh-&gt;_sysc_cache != v)</span>
<span class="p_add">+		_write_sysconfig(v, oh);</span>
 }
 
 /**
<span class="p_chunk">@@ -1946,7 +1946,9 @@</span> <span class="p_context"> static int _ocp_softreset(struct omap_hwmod *oh)</span>
 	if (ret)
 		goto dis_opt_clks;
 
<span class="p_del">-	_write_sysconfig(v, oh);</span>
<span class="p_add">+	/* If the cached value is the same as the new value, skip the write */</span>
<span class="p_add">+	if (oh-&gt;_sysc_cache != v)</span>
<span class="p_add">+		_write_sysconfig(v, oh);</span>
 
 	if (oh-&gt;class-&gt;sysc-&gt;srst_udelay)
 		udelay(oh-&gt;class-&gt;sysc-&gt;srst_udelay);
<span class="p_header">diff --git a/arch/arm/mach-socfpga/headsmp.S b/arch/arm/mach-socfpga/headsmp.S</span>
<span class="p_header">index 95c115d8b5ee..b143f946bb79 100644</span>
<span class="p_header">--- a/arch/arm/mach-socfpga/headsmp.S</span>
<span class="p_header">+++ b/arch/arm/mach-socfpga/headsmp.S</span>
<span class="p_chunk">@@ -11,6 +11,7 @@</span> <span class="p_context"></span>
 #include &lt;linux/init.h&gt;
 
 	.arch	armv7-a
<span class="p_add">+	.arm</span>
 
 ENTRY(secondary_trampoline)
 	movw	r2, #:lower16:cpu1start_addr
<span class="p_header">diff --git a/arch/arm64/kernel/Makefile b/arch/arm64/kernel/Makefile</span>
<span class="p_header">index cdaedad3afe5..d271e55e778e 100644</span>
<span class="p_header">--- a/arch/arm64/kernel/Makefile</span>
<span class="p_header">+++ b/arch/arm64/kernel/Makefile</span>
<span class="p_chunk">@@ -15,7 +15,8 @@</span> <span class="p_context"> CFLAGS_REMOVE_return_address.o = -pg</span>
 arm64-obj-y		:= cputable.o debug-monitors.o entry.o irq.o fpsimd.o	\
 			   entry-fpsimd.o process.o ptrace.o setup.o signal.o	\
 			   sys.o stacktrace.o time.o traps.o io.o vdso.o	\
<span class="p_del">-			   hyp-stub.o psci.o cpu_ops.o insn.o return_address.o</span>
<span class="p_add">+			   hyp-stub.o psci.o psci-call.o cpu_ops.o insn.o	\</span>
<span class="p_add">+			   return_address.o</span>
 
 arm64-obj-$(CONFIG_COMPAT)		+= sys32.o kuser32.o signal32.o 	\
 					   sys_compat.o
<span class="p_header">diff --git a/arch/arm64/kernel/head.S b/arch/arm64/kernel/head.S</span>
<span class="p_header">index a089ce8d52b3..e6739fe1effc 100644</span>
<span class="p_header">--- a/arch/arm64/kernel/head.S</span>
<span class="p_header">+++ b/arch/arm64/kernel/head.S</span>
<span class="p_chunk">@@ -316,9 +316,14 @@</span> <span class="p_context"> CPU_LE(	movk	x0, #0x30d0, lsl #16	)	// Clear EE and E0E on LE systems</span>
 #endif
 
 	/* EL2 debug */
<span class="p_add">+	mrs	x0, id_aa64dfr0_el1		// Check ID_AA64DFR0_EL1 PMUVer</span>
<span class="p_add">+	sbfx	x0, x0, #8, #4</span>
<span class="p_add">+	cmp	x0, #1</span>
<span class="p_add">+	b.lt	4f				// Skip if no PMU present</span>
 	mrs	x0, pmcr_el0			// Disable debug access traps
 	ubfx	x0, x0, #11, #5			// to EL2 and allow access to
 	msr	mdcr_el2, x0			// all PMU counters from EL1
<span class="p_add">+4:</span>
 
 	/* Stage-2 translation */
 	msr	vttbr_el2, xzr
<span class="p_header">diff --git a/arch/arm64/kernel/psci-call.S b/arch/arm64/kernel/psci-call.S</span>
new file mode 100644
<span class="p_header">index 000000000000..cf83e61cd3b5</span>
<span class="p_header">--- /dev/null</span>
<span class="p_header">+++ b/arch/arm64/kernel/psci-call.S</span>
<span class="p_chunk">@@ -0,0 +1,28 @@</span> <span class="p_context"></span>
<span class="p_add">+/*</span>
<span class="p_add">+ * This program is free software; you can redistribute it and/or modify</span>
<span class="p_add">+ * it under the terms of the GNU General Public License version 2 as</span>
<span class="p_add">+ * published by the Free Software Foundation.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * This program is distributed in the hope that it will be useful,</span>
<span class="p_add">+ * but WITHOUT ANY WARRANTY; without even the implied warranty of</span>
<span class="p_add">+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the</span>
<span class="p_add">+ * GNU General Public License for more details.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * Copyright (C) 2015 ARM Limited</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * Author: Will Deacon &lt;will.deacon@arm.com&gt;</span>
<span class="p_add">+ */</span>
<span class="p_add">+</span>
<span class="p_add">+#include &lt;linux/linkage.h&gt;</span>
<span class="p_add">+</span>
<span class="p_add">+/* int __invoke_psci_fn_hvc(u64 function_id, u64 arg0, u64 arg1, u64 arg2) */</span>
<span class="p_add">+ENTRY(__invoke_psci_fn_hvc)</span>
<span class="p_add">+	hvc	#0</span>
<span class="p_add">+	ret</span>
<span class="p_add">+ENDPROC(__invoke_psci_fn_hvc)</span>
<span class="p_add">+</span>
<span class="p_add">+/* int __invoke_psci_fn_smc(u64 function_id, u64 arg0, u64 arg1, u64 arg2) */</span>
<span class="p_add">+ENTRY(__invoke_psci_fn_smc)</span>
<span class="p_add">+	smc	#0</span>
<span class="p_add">+	ret</span>
<span class="p_add">+ENDPROC(__invoke_psci_fn_smc)</span>
<span class="p_header">diff --git a/arch/arm64/kernel/psci.c b/arch/arm64/kernel/psci.c</span>
<span class="p_header">index 9e9798f91172..2a8689b89492 100644</span>
<span class="p_header">--- a/arch/arm64/kernel/psci.c</span>
<span class="p_header">+++ b/arch/arm64/kernel/psci.c</span>
<span class="p_chunk">@@ -55,6 +55,9 @@</span> <span class="p_context"> static struct psci_operations psci_ops;</span>
 static int (*invoke_psci_fn)(u64, u64, u64, u64);
 typedef int (*psci_initcall_t)(const struct device_node *);
 
<span class="p_add">+asmlinkage int __invoke_psci_fn_hvc(u64, u64, u64, u64);</span>
<span class="p_add">+asmlinkage int __invoke_psci_fn_smc(u64, u64, u64, u64);</span>
<span class="p_add">+</span>
 enum psci_function {
 	PSCI_FN_CPU_SUSPEND,
 	PSCI_FN_CPU_ON,
<span class="p_chunk">@@ -93,40 +96,6 @@</span> <span class="p_context"> static u32 psci_power_state_pack(struct psci_power_state state)</span>
 		 &amp; PSCI_0_2_POWER_STATE_AFFL_MASK);
 }
 
<span class="p_del">-/*</span>
<span class="p_del">- * The following two functions are invoked via the invoke_psci_fn pointer</span>
<span class="p_del">- * and will not be inlined, allowing us to piggyback on the AAPCS.</span>
<span class="p_del">- */</span>
<span class="p_del">-static noinline int __invoke_psci_fn_hvc(u64 function_id, u64 arg0, u64 arg1,</span>
<span class="p_del">-					 u64 arg2)</span>
<span class="p_del">-{</span>
<span class="p_del">-	asm volatile(</span>
<span class="p_del">-			__asmeq(&quot;%0&quot;, &quot;x0&quot;)</span>
<span class="p_del">-			__asmeq(&quot;%1&quot;, &quot;x1&quot;)</span>
<span class="p_del">-			__asmeq(&quot;%2&quot;, &quot;x2&quot;)</span>
<span class="p_del">-			__asmeq(&quot;%3&quot;, &quot;x3&quot;)</span>
<span class="p_del">-			&quot;hvc	#0\n&quot;</span>
<span class="p_del">-		: &quot;+r&quot; (function_id)</span>
<span class="p_del">-		: &quot;r&quot; (arg0), &quot;r&quot; (arg1), &quot;r&quot; (arg2));</span>
<span class="p_del">-</span>
<span class="p_del">-	return function_id;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static noinline int __invoke_psci_fn_smc(u64 function_id, u64 arg0, u64 arg1,</span>
<span class="p_del">-					 u64 arg2)</span>
<span class="p_del">-{</span>
<span class="p_del">-	asm volatile(</span>
<span class="p_del">-			__asmeq(&quot;%0&quot;, &quot;x0&quot;)</span>
<span class="p_del">-			__asmeq(&quot;%1&quot;, &quot;x1&quot;)</span>
<span class="p_del">-			__asmeq(&quot;%2&quot;, &quot;x2&quot;)</span>
<span class="p_del">-			__asmeq(&quot;%3&quot;, &quot;x3&quot;)</span>
<span class="p_del">-			&quot;smc	#0\n&quot;</span>
<span class="p_del">-		: &quot;+r&quot; (function_id)</span>
<span class="p_del">-		: &quot;r&quot; (arg0), &quot;r&quot; (arg1), &quot;r&quot; (arg2));</span>
<span class="p_del">-</span>
<span class="p_del">-	return function_id;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
 static int psci_get_version(void)
 {
 	int err;
<span class="p_header">diff --git a/arch/arm64/mm/proc-macros.S b/arch/arm64/mm/proc-macros.S</span>
<span class="p_header">index 005d29e2977d..99d2b5bc6606 100644</span>
<span class="p_header">--- a/arch/arm64/mm/proc-macros.S</span>
<span class="p_header">+++ b/arch/arm64/mm/proc-macros.S</span>
<span class="p_chunk">@@ -52,3 +52,15 @@</span> <span class="p_context"></span>
 	mov	\reg, #4			// bytes per word
 	lsl	\reg, \reg, \tmp		// actual cache line size
 	.endm
<span class="p_add">+</span>
<span class="p_add">+/*</span>
<span class="p_add">+ * reset_pmuserenr_el0 - reset PMUSERENR_EL0 if PMUv3 present</span>
<span class="p_add">+ */</span>
<span class="p_add">+	.macro	reset_pmuserenr_el0, tmpreg</span>
<span class="p_add">+	mrs	\tmpreg, id_aa64dfr0_el1	// Check ID_AA64DFR0_EL1 PMUVer</span>
<span class="p_add">+	sbfx	\tmpreg, \tmpreg, #8, #4</span>
<span class="p_add">+	cmp	\tmpreg, #1			// Skip if no PMU present</span>
<span class="p_add">+	b.lt	9000f</span>
<span class="p_add">+	msr	pmuserenr_el0, xzr		// Disable PMU access from EL0</span>
<span class="p_add">+9000:</span>
<span class="p_add">+	.endm</span>
<span class="p_header">diff --git a/arch/arm64/mm/proc.S b/arch/arm64/mm/proc.S</span>
<span class="p_header">index 7b9c2e673577..dc34442ff728 100644</span>
<span class="p_header">--- a/arch/arm64/mm/proc.S</span>
<span class="p_header">+++ b/arch/arm64/mm/proc.S</span>
<span class="p_chunk">@@ -149,7 +149,7 @@</span> <span class="p_context"> ENTRY(cpu_do_resume)</span>
 	 */
 	ubfx	x11, x11, #1, #1
 	msr	oslar_el1, x11
<span class="p_del">-	msr	pmuserenr_el0, xzr		// Disable PMU access from EL0</span>
<span class="p_add">+	reset_pmuserenr_el0 x0			// Disable PMU access from EL0</span>
 	mov	x0, x12
 	dsb	nsh		// Make sure local tlb invalidation completed
 	isb
<span class="p_chunk">@@ -189,7 +189,7 @@</span> <span class="p_context"> ENTRY(__cpu_setup)</span>
 	msr	cpacr_el1, x0			// Enable FP/ASIMD
 	mov	x0, #1 &lt;&lt; 12			// Reset mdscr_el1 and disable
 	msr	mdscr_el1, x0			// access to the DCC from EL0
<span class="p_del">-	msr	pmuserenr_el0, xzr		// Disable PMU access from EL0</span>
<span class="p_add">+	reset_pmuserenr_el0 x0			// Disable PMU access from EL0</span>
 	/*
 	 * Memory region attributes for LPAE:
 	 *
<span class="p_header">diff --git a/arch/parisc/kernel/syscall.S b/arch/parisc/kernel/syscall.S</span>
<span class="p_header">index 0b8d26d3ba43..7105610ac3fd 100644</span>
<span class="p_header">--- a/arch/parisc/kernel/syscall.S</span>
<span class="p_header">+++ b/arch/parisc/kernel/syscall.S</span>
<span class="p_chunk">@@ -342,7 +342,7 @@</span> <span class="p_context"> tracesys_next:</span>
 	stw     %r21, -56(%r30)                 /* 6th argument */
 #endif
 
<span class="p_del">-	comiclr,&gt;&gt;=	__NR_Linux_syscalls, %r20, %r0</span>
<span class="p_add">+	comiclr,&gt;&gt;	__NR_Linux_syscalls, %r20, %r0</span>
 	b,n	.Lsyscall_nosys
 
 	LDREGX  %r20(%r19), %r19
<span class="p_header">diff --git a/arch/powerpc/include/asm/word-at-a-time.h b/arch/powerpc/include/asm/word-at-a-time.h</span>
<span class="p_header">index 9a5c928bb3c6..67af1f8b4583 100644</span>
<span class="p_header">--- a/arch/powerpc/include/asm/word-at-a-time.h</span>
<span class="p_header">+++ b/arch/powerpc/include/asm/word-at-a-time.h</span>
<span class="p_chunk">@@ -62,7 +62,7 @@</span> <span class="p_context"> static inline unsigned long find_zero(unsigned long mask)</span>
 	     &quot;andc %1,%1,%2\n\t&quot;
 	     &quot;popcntd %0,%1&quot;
 	     : &quot;=r&quot; (leading_zero_bits), &quot;=&amp;r&quot; (trailing_zero_bit_mask)
<span class="p_del">-	     : &quot;r&quot; (mask));</span>
<span class="p_add">+	     : &quot;b&quot; (mask));</span>
 	return leading_zero_bits &gt;&gt; 3;
 }
 
<span class="p_header">diff --git a/arch/powerpc/include/uapi/asm/cputable.h b/arch/powerpc/include/uapi/asm/cputable.h</span>
<span class="p_header">index de2c0e4ee1aa..67de80a8e178 100644</span>
<span class="p_header">--- a/arch/powerpc/include/uapi/asm/cputable.h</span>
<span class="p_header">+++ b/arch/powerpc/include/uapi/asm/cputable.h</span>
<span class="p_chunk">@@ -31,6 +31,7 @@</span> <span class="p_context"></span>
 #define PPC_FEATURE_PSERIES_PERFMON_COMPAT \
 					0x00000040
 
<span class="p_add">+/* Reserved - do not use		0x00000004 */</span>
 #define PPC_FEATURE_TRUE_LE		0x00000002
 #define PPC_FEATURE_PPC_LE		0x00000001
 
<span class="p_header">diff --git a/arch/powerpc/kernel/prom.c b/arch/powerpc/kernel/prom.c</span>
<span class="p_header">index b694b0730971..b76f3c3fce32 100644</span>
<span class="p_header">--- a/arch/powerpc/kernel/prom.c</span>
<span class="p_header">+++ b/arch/powerpc/kernel/prom.c</span>
<span class="p_chunk">@@ -160,7 +160,7 @@</span> <span class="p_context"> static struct ibm_pa_feature {</span>
 	{CPU_FTR_NOEXECUTE, 0, 0,	0, 6, 0},
 	{CPU_FTR_NODSISRALIGN, 0, 0,	1, 1, 1},
 	{0, MMU_FTR_CI_LARGE_PAGE, 0,	1, 2, 0},
<span class="p_del">-	{CPU_FTR_REAL_LE, PPC_FEATURE_TRUE_LE, 5, 0, 0},</span>
<span class="p_add">+	{CPU_FTR_REAL_LE, 0, PPC_FEATURE_TRUE_LE, 5, 0, 0},</span>
 };
 
 static void __init scan_features(unsigned long node, const unsigned char *ftrs,
<span class="p_header">diff --git a/arch/s390/include/asm/hugetlb.h b/arch/s390/include/asm/hugetlb.h</span>
<span class="p_header">index 11eae5f55b70..9787b61e0758 100644</span>
<span class="p_header">--- a/arch/s390/include/asm/hugetlb.h</span>
<span class="p_header">+++ b/arch/s390/include/asm/hugetlb.h</span>
<span class="p_chunk">@@ -14,6 +14,7 @@</span> <span class="p_context"></span>
 
 #define is_hugepage_only_range(mm, addr, len)	0
 #define hugetlb_free_pgd_range			free_pgd_range
<span class="p_add">+#define hugepages_supported()			(MACHINE_HAS_HPAGE)</span>
 
 void set_huge_pte_at(struct mm_struct *mm, unsigned long addr,
 		     pte_t *ptep, pte_t pte);
<span class="p_header">diff --git a/arch/s390/lib/spinlock.c b/arch/s390/lib/spinlock.c</span>
<span class="p_header">index 5b0e445bc3f3..9beb186b3af5 100644</span>
<span class="p_header">--- a/arch/s390/lib/spinlock.c</span>
<span class="p_header">+++ b/arch/s390/lib/spinlock.c</span>
<span class="p_chunk">@@ -75,6 +75,7 @@</span> <span class="p_context"> void arch_spin_lock_wait_flags(arch_spinlock_t *lp, unsigned long flags)</span>
 			if (_raw_compare_and_swap(&amp;lp-&gt;lock, 0, cpu))
 				return;
 			local_irq_restore(flags);
<span class="p_add">+			continue;</span>
 		}
 		/* Check if the lock owner is running. */
 		if (!smp_vcpu_scheduled(~owner)) {
<span class="p_header">diff --git a/arch/x86/include/asm/hugetlb.h b/arch/x86/include/asm/hugetlb.h</span>
<span class="p_header">index 68c05398bba9..7aadd3cea843 100644</span>
<span class="p_header">--- a/arch/x86/include/asm/hugetlb.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/hugetlb.h</span>
<span class="p_chunk">@@ -4,6 +4,7 @@</span> <span class="p_context"></span>
 #include &lt;asm/page.h&gt;
 #include &lt;asm-generic/hugetlb.h&gt;
 
<span class="p_add">+#define hugepages_supported() cpu_has_pse</span>
 
 static inline int is_hugepage_only_range(struct mm_struct *mm,
 					 unsigned long addr,
<span class="p_header">diff --git a/arch/x86/kernel/sysfb_efi.c b/arch/x86/kernel/sysfb_efi.c</span>
<span class="p_header">index b285d4e8c68e..5da924bbf0a0 100644</span>
<span class="p_header">--- a/arch/x86/kernel/sysfb_efi.c</span>
<span class="p_header">+++ b/arch/x86/kernel/sysfb_efi.c</span>
<span class="p_chunk">@@ -106,14 +106,24 @@</span> <span class="p_context"> static int __init efifb_set_system(const struct dmi_system_id *id)</span>
 					continue;
 				for (i = 0; i &lt; DEVICE_COUNT_RESOURCE; i++) {
 					resource_size_t start, end;
<span class="p_add">+					unsigned long flags;</span>
<span class="p_add">+</span>
<span class="p_add">+					flags = pci_resource_flags(dev, i);</span>
<span class="p_add">+					if (!(flags &amp; IORESOURCE_MEM))</span>
<span class="p_add">+						continue;</span>
<span class="p_add">+</span>
<span class="p_add">+					if (flags &amp; IORESOURCE_UNSET)</span>
<span class="p_add">+						continue;</span>
<span class="p_add">+</span>
<span class="p_add">+					if (pci_resource_len(dev, i) == 0)</span>
<span class="p_add">+						continue;</span>
 
 					start = pci_resource_start(dev, i);
<span class="p_del">-					if (start == 0)</span>
<span class="p_del">-						break;</span>
 					end = pci_resource_end(dev, i);
 					if (screen_info.lfb_base &gt;= start &amp;&amp;
 					    screen_info.lfb_base &lt; end) {
 						found_bar = 1;
<span class="p_add">+						break;</span>
 					}
 				}
 			}
<span class="p_header">diff --git a/arch/x86/kernel/tsc_msr.c b/arch/x86/kernel/tsc_msr.c</span>
<span class="p_header">index 92ae6acac8a7..6aa0f4d9eea6 100644</span>
<span class="p_header">--- a/arch/x86/kernel/tsc_msr.c</span>
<span class="p_header">+++ b/arch/x86/kernel/tsc_msr.c</span>
<span class="p_chunk">@@ -92,7 +92,7 @@</span> <span class="p_context"> unsigned long try_msr_calibrate_tsc(void)</span>
 
 	if (freq_desc_tables[cpu_index].msr_plat) {
 		rdmsr(MSR_PLATFORM_INFO, lo, hi);
<span class="p_del">-		ratio = (lo &gt;&gt; 8) &amp; 0x1f;</span>
<span class="p_add">+		ratio = (lo &gt;&gt; 8) &amp; 0xff;</span>
 	} else {
 		rdmsr(MSR_IA32_PERF_STATUS, lo, hi);
 		ratio = (hi &gt;&gt; 8) &amp; 0x1f;
<span class="p_header">diff --git a/arch/x86/kvm/x86.c b/arch/x86/kvm/x86.c</span>
<span class="p_header">index 26a4541e190a..ba6f9822c474 100644</span>
<span class="p_header">--- a/arch/x86/kvm/x86.c</span>
<span class="p_header">+++ b/arch/x86/kvm/x86.c</span>
<span class="p_chunk">@@ -626,7 +626,6 @@</span> <span class="p_context"> int __kvm_set_xcr(struct kvm_vcpu *vcpu, u32 index, u64 xcr)</span>
 	if ((!(xcr0 &amp; XSTATE_BNDREGS)) != (!(xcr0 &amp; XSTATE_BNDCSR)))
 		return 1;
 
<span class="p_del">-	kvm_put_guest_xcr0(vcpu);</span>
 	vcpu-&gt;arch.xcr0 = xcr0;
 
 	if ((xcr0 ^ old_xcr0) &amp; XSTATE_EXTEND_MASK)
<span class="p_chunk">@@ -6072,8 +6071,6 @@</span> <span class="p_context"> static int vcpu_enter_guest(struct kvm_vcpu *vcpu)</span>
 	kvm_x86_ops-&gt;prepare_guest_switch(vcpu);
 	if (vcpu-&gt;fpu_active)
 		kvm_load_guest_fpu(vcpu);
<span class="p_del">-	kvm_load_guest_xcr0(vcpu);</span>
<span class="p_del">-</span>
 	vcpu-&gt;mode = IN_GUEST_MODE;
 
 	srcu_read_unlock(&amp;vcpu-&gt;kvm-&gt;srcu, vcpu-&gt;srcu_idx);
<span class="p_chunk">@@ -6096,6 +6093,8 @@</span> <span class="p_context"> static int vcpu_enter_guest(struct kvm_vcpu *vcpu)</span>
 		goto cancel_injection;
 	}
 
<span class="p_add">+	kvm_load_guest_xcr0(vcpu);</span>
<span class="p_add">+</span>
 	if (req_immediate_exit)
 		smp_send_reschedule(vcpu-&gt;cpu);
 
<span class="p_chunk">@@ -6144,6 +6143,8 @@</span> <span class="p_context"> static int vcpu_enter_guest(struct kvm_vcpu *vcpu)</span>
 	vcpu-&gt;mode = OUTSIDE_GUEST_MODE;
 	smp_wmb();
 
<span class="p_add">+	kvm_put_guest_xcr0(vcpu);</span>
<span class="p_add">+</span>
 	/* Interrupt is enabled by handle_external_intr() */
 	kvm_x86_ops-&gt;handle_external_intr(vcpu);
 
<span class="p_chunk">@@ -6782,7 +6783,6 @@</span> <span class="p_context"> void kvm_load_guest_fpu(struct kvm_vcpu *vcpu)</span>
 	 * and assume host would use all available bits.
 	 * Guest xcr0 would be loaded later.
 	 */
<span class="p_del">-	kvm_put_guest_xcr0(vcpu);</span>
 	vcpu-&gt;guest_fpu_loaded = 1;
 	__kernel_fpu_begin();
 	fpu_restore_checking(&amp;vcpu-&gt;arch.guest_fpu);
<span class="p_chunk">@@ -6791,8 +6791,6 @@</span> <span class="p_context"> void kvm_load_guest_fpu(struct kvm_vcpu *vcpu)</span>
 
 void kvm_put_guest_fpu(struct kvm_vcpu *vcpu)
 {
<span class="p_del">-	kvm_put_guest_xcr0(vcpu);</span>
<span class="p_del">-</span>
 	if (!vcpu-&gt;guest_fpu_loaded)
 		return;
 
<span class="p_header">diff --git a/crypto/ahash.c b/crypto/ahash.c</span>
<span class="p_header">index 4f5e0eb3547f..8a25fdafa97f 100644</span>
<span class="p_header">--- a/crypto/ahash.c</span>
<span class="p_header">+++ b/crypto/ahash.c</span>
<span class="p_chunk">@@ -68,8 +68,9 @@</span> <span class="p_context"> static int hash_walk_new_entry(struct crypto_hash_walk *walk)</span>
 	struct scatterlist *sg;
 
 	sg = walk-&gt;sg;
<span class="p_del">-	walk-&gt;pg = sg_page(sg);</span>
 	walk-&gt;offset = sg-&gt;offset;
<span class="p_add">+	walk-&gt;pg = sg_page(walk-&gt;sg) + (walk-&gt;offset &gt;&gt; PAGE_SHIFT);</span>
<span class="p_add">+	walk-&gt;offset = offset_in_page(walk-&gt;offset);</span>
 	walk-&gt;entrylen = sg-&gt;length;
 
 	if (walk-&gt;entrylen &gt; walk-&gt;total)
<span class="p_header">diff --git a/drivers/acpi/acpica/dsmethod.c b/drivers/acpi/acpica/dsmethod.c</span>
<span class="p_header">index 3c7f7378b94d..86ddd0b3a7bf 100644</span>
<span class="p_header">--- a/drivers/acpi/acpica/dsmethod.c</span>
<span class="p_header">+++ b/drivers/acpi/acpica/dsmethod.c</span>
<span class="p_chunk">@@ -412,6 +412,9 @@</span> <span class="p_context"> acpi_ds_begin_method_execution(struct acpi_namespace_node *method_node,</span>
 				obj_desc-&gt;method.mutex-&gt;mutex.
 				    original_sync_level =
 				    obj_desc-&gt;method.mutex-&gt;mutex.sync_level;
<span class="p_add">+</span>
<span class="p_add">+				obj_desc-&gt;method.mutex-&gt;mutex.thread_id =</span>
<span class="p_add">+				    acpi_os_get_thread_id();</span>
 			}
 		}
 
<span class="p_header">diff --git a/drivers/ata/libahci.c b/drivers/ata/libahci.c</span>
<span class="p_header">index 9b82d2b1afdf..2012122d4c4a 100644</span>
<span class="p_header">--- a/drivers/ata/libahci.c</span>
<span class="p_header">+++ b/drivers/ata/libahci.c</span>
<span class="p_chunk">@@ -472,6 +472,7 @@</span> <span class="p_context"> void ahci_save_initial_config(struct device *dev,</span>
 		dev_info(dev, &quot;forcing port_map 0x%x -&gt; 0x%x\n&quot;,
 			 port_map, force_port_map);
 		port_map = force_port_map;
<span class="p_add">+		hpriv-&gt;saved_port_map = port_map;</span>
 	}
 
 	if (mask_port_map) {
<span class="p_header">diff --git a/drivers/base/regmap/regmap-spmi.c b/drivers/base/regmap/regmap-spmi.c</span>
<span class="p_header">index d7026dc33388..b394aaef3867 100644</span>
<span class="p_header">--- a/drivers/base/regmap/regmap-spmi.c</span>
<span class="p_header">+++ b/drivers/base/regmap/regmap-spmi.c</span>
<span class="p_chunk">@@ -153,7 +153,7 @@</span> <span class="p_context"> static int regmap_spmi_ext_read(void *context,</span>
 	while (val_size) {
 		len = min_t(size_t, val_size, 8);
 
<span class="p_del">-		err = spmi_ext_register_readl(context, addr, val, val_size);</span>
<span class="p_add">+		err = spmi_ext_register_readl(context, addr, val, len);</span>
 		if (err)
 			goto err_out;
 
<span class="p_header">diff --git a/drivers/block/rbd.c b/drivers/block/rbd.c</span>
<span class="p_header">index 34cd70d06d3b..6eea35b05f6a 100644</span>
<span class="p_header">--- a/drivers/block/rbd.c</span>
<span class="p_header">+++ b/drivers/block/rbd.c</span>
<span class="p_chunk">@@ -528,7 +528,6 @@</span> <span class="p_context"> static int _rbd_dev_v2_snap_size(struct rbd_device *rbd_dev, u64 snap_id,</span>
 				u8 *order, u64 *snap_size);
 static int _rbd_dev_v2_snap_features(struct rbd_device *rbd_dev, u64 snap_id,
 		u64 *snap_features);
<span class="p_del">-static u64 rbd_snap_id_by_name(struct rbd_device *rbd_dev, const char *name);</span>
 
 static int rbd_open(struct block_device *bdev, fmode_t mode)
 {
<span class="p_chunk">@@ -2957,9 +2956,6 @@</span> <span class="p_context"> static void rbd_watch_cb(u64 ver, u64 notify_id, u8 opcode, void *data)</span>
 	struct rbd_device *rbd_dev = (struct rbd_device *)data;
 	int ret;
 
<span class="p_del">-	if (!rbd_dev)</span>
<span class="p_del">-		return;</span>
<span class="p_del">-</span>
 	dout(&quot;%s: \&quot;%s\&quot; notify_id %llu opcode %u\n&quot;, __func__,
 		rbd_dev-&gt;header_name, (unsigned long long)notify_id,
 		(unsigned int)opcode);
<span class="p_chunk">@@ -3099,6 +3095,9 @@</span> <span class="p_context"> out_cancel:</span>
 	ceph_osdc_cancel_event(rbd_dev-&gt;watch_event);
 	rbd_dev-&gt;watch_event = NULL;
 
<span class="p_add">+	dout(&quot;%s flushing notifies\n&quot;, __func__);</span>
<span class="p_add">+	ceph_osdc_flush_notifies(&amp;rbd_dev-&gt;rbd_client-&gt;client-&gt;osdc);</span>
<span class="p_add">+</span>
 	return ret;
 }
 
<span class="p_chunk">@@ -3534,21 +3533,14 @@</span> <span class="p_context"> static void rbd_exists_validate(struct rbd_device *rbd_dev)</span>
 static void rbd_dev_update_size(struct rbd_device *rbd_dev)
 {
 	sector_t size;
<span class="p_del">-	bool removing;</span>
 
 	/*
<span class="p_del">-	 * Don&#39;t hold the lock while doing disk operations,</span>
<span class="p_del">-	 * or lock ordering will conflict with the bdev mutex via:</span>
<span class="p_del">-	 * rbd_add() -&gt; blkdev_get() -&gt; rbd_open()</span>
<span class="p_add">+	 * If EXISTS is not set, rbd_dev-&gt;disk may be NULL, so don&#39;t</span>
<span class="p_add">+	 * try to update its size.  If REMOVING is set, updating size</span>
<span class="p_add">+	 * is just useless work since the device can&#39;t be opened.</span>
 	 */
<span class="p_del">-	spin_lock_irq(&amp;rbd_dev-&gt;lock);</span>
<span class="p_del">-	removing = test_bit(RBD_DEV_FLAG_REMOVING, &amp;rbd_dev-&gt;flags);</span>
<span class="p_del">-	spin_unlock_irq(&amp;rbd_dev-&gt;lock);</span>
<span class="p_del">-	/*</span>
<span class="p_del">-	 * If the device is being removed, rbd_dev-&gt;disk has</span>
<span class="p_del">-	 * been destroyed, so don&#39;t try to update its size</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	if (!removing) {</span>
<span class="p_add">+	if (test_bit(RBD_DEV_FLAG_EXISTS, &amp;rbd_dev-&gt;flags) &amp;&amp;</span>
<span class="p_add">+	    !test_bit(RBD_DEV_FLAG_REMOVING, &amp;rbd_dev-&gt;flags)) {</span>
 		size = (sector_t)rbd_dev-&gt;mapping.size / SECTOR_SIZE;
 		dout(&quot;setting size to %llu sectors&quot;, (unsigned long long)size);
 		set_capacity(rbd_dev-&gt;disk, size);
<span class="p_chunk">@@ -5078,6 +5070,10 @@</span> <span class="p_context"> out_err:</span>
 	return ret;
 }
 
<span class="p_add">+/*</span>
<span class="p_add">+ * rbd_dev-&gt;header_rwsem must be locked for write and will be unlocked</span>
<span class="p_add">+ * upon return.</span>
<span class="p_add">+ */</span>
 static int rbd_dev_device_setup(struct rbd_device *rbd_dev)
 {
 	int ret;
<span class="p_chunk">@@ -5086,7 +5082,7 @@</span> <span class="p_context"> static int rbd_dev_device_setup(struct rbd_device *rbd_dev)</span>
 
 	ret = rbd_dev_id_get(rbd_dev);
 	if (ret)
<span class="p_del">-		return ret;</span>
<span class="p_add">+		goto err_out_unlock;</span>
 
 	BUILD_BUG_ON(DEV_NAME_LEN
 			&lt; sizeof (RBD_DRV_NAME) + MAX_INT_FORMAT_WIDTH);
<span class="p_chunk">@@ -5133,8 +5129,9 @@</span> <span class="p_context"> static int rbd_dev_device_setup(struct rbd_device *rbd_dev)</span>
 	/* Everything&#39;s ready.  Announce the disk to the world. */
 
 	set_bit(RBD_DEV_FLAG_EXISTS, &amp;rbd_dev-&gt;flags);
<span class="p_del">-	add_disk(rbd_dev-&gt;disk);</span>
<span class="p_add">+	up_write(&amp;rbd_dev-&gt;header_rwsem);</span>
 
<span class="p_add">+	add_disk(rbd_dev-&gt;disk);</span>
 	pr_info(&quot;%s: added with size 0x%llx\n&quot;, rbd_dev-&gt;disk-&gt;disk_name,
 		(unsigned long long) rbd_dev-&gt;mapping.size);
 
<span class="p_chunk">@@ -5153,6 +5150,8 @@</span> <span class="p_context"> err_out_blkdev:</span>
 err_out_id:
 	rbd_dev_id_put(rbd_dev);
 	rbd_dev_mapping_clear(rbd_dev);
<span class="p_add">+err_out_unlock:</span>
<span class="p_add">+	up_write(&amp;rbd_dev-&gt;header_rwsem);</span>
 
 	return ret;
 }
<span class="p_chunk">@@ -5315,6 +5314,7 @@</span> <span class="p_context"> static ssize_t do_rbd_add(struct bus_type *bus,</span>
 	rbdc = NULL;		/* rbd_dev now owns this */
 	spec = NULL;		/* rbd_dev now owns this */
 
<span class="p_add">+	down_write(&amp;rbd_dev-&gt;header_rwsem);</span>
 	rc = rbd_dev_image_probe(rbd_dev, 0);
 	if (rc &lt; 0)
 		goto err_out_rbd_dev;
<span class="p_chunk">@@ -5340,6 +5340,7 @@</span> <span class="p_context"> static ssize_t do_rbd_add(struct bus_type *bus,</span>
 	return count;
 
 err_out_rbd_dev:
<span class="p_add">+	up_write(&amp;rbd_dev-&gt;header_rwsem);</span>
 	rbd_dev_destroy(rbd_dev);
 err_out_client:
 	rbd_put_client(rbdc);
<span class="p_chunk">@@ -5453,12 +5454,6 @@</span> <span class="p_context"> static ssize_t do_rbd_remove(struct bus_type *bus,</span>
 		return ret;
 
 	rbd_dev_header_unwatch_sync(rbd_dev);
<span class="p_del">-	/*</span>
<span class="p_del">-	 * flush remaining watch callbacks - these must be complete</span>
<span class="p_del">-	 * before the osd_client is shutdown</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	dout(&quot;%s: flushing notifies&quot;, __func__);</span>
<span class="p_del">-	ceph_osdc_flush_notifies(&amp;rbd_dev-&gt;rbd_client-&gt;client-&gt;osdc);</span>
 
 	/*
 	 * Don&#39;t free anything from rbd_dev-&gt;disk until after all
<span class="p_header">diff --git a/drivers/crypto/ccp/ccp-crypto-aes-cmac.c b/drivers/crypto/ccp/ccp-crypto-aes-cmac.c</span>
<span class="p_header">index 5c93afb1841a..f10b4998937d 100644</span>
<span class="p_header">--- a/drivers/crypto/ccp/ccp-crypto-aes-cmac.c</span>
<span class="p_header">+++ b/drivers/crypto/ccp/ccp-crypto-aes-cmac.c</span>
<span class="p_chunk">@@ -206,6 +206,9 @@</span> <span class="p_context"> static int ccp_aes_cmac_export(struct ahash_request *req, void *out)</span>
 	struct ccp_aes_cmac_req_ctx *rctx = ahash_request_ctx(req);
 	struct ccp_aes_cmac_exp_ctx state;
 
<span class="p_add">+	/* Don&#39;t let anything leak to &#39;out&#39; */</span>
<span class="p_add">+	memset(&amp;state, 0, sizeof(state));</span>
<span class="p_add">+</span>
 	state.null_msg = rctx-&gt;null_msg;
 	memcpy(state.iv, rctx-&gt;iv, sizeof(state.iv));
 	state.buf_count = rctx-&gt;buf_count;
<span class="p_header">diff --git a/drivers/crypto/ccp/ccp-crypto-sha.c b/drivers/crypto/ccp/ccp-crypto-sha.c</span>
<span class="p_header">index 4c6742fc2146..52e08fa389bb 100644</span>
<span class="p_header">--- a/drivers/crypto/ccp/ccp-crypto-sha.c</span>
<span class="p_header">+++ b/drivers/crypto/ccp/ccp-crypto-sha.c</span>
<span class="p_chunk">@@ -198,6 +198,9 @@</span> <span class="p_context"> static int ccp_sha_export(struct ahash_request *req, void *out)</span>
 	struct ccp_sha_req_ctx *rctx = ahash_request_ctx(req);
 	struct ccp_sha_exp_ctx state;
 
<span class="p_add">+	/* Don&#39;t let anything leak to &#39;out&#39; */</span>
<span class="p_add">+	memset(&amp;state, 0, sizeof(state));</span>
<span class="p_add">+</span>
 	state.type = rctx-&gt;type;
 	state.msg_bits = rctx-&gt;msg_bits;
 	state.first = rctx-&gt;first;
<span class="p_header">diff --git a/drivers/edac/i7core_edac.c b/drivers/edac/i7core_edac.c</span>
<span class="p_header">index 9cd0b301f81b..f84ef75b6487 100644</span>
<span class="p_header">--- a/drivers/edac/i7core_edac.c</span>
<span class="p_header">+++ b/drivers/edac/i7core_edac.c</span>
<span class="p_chunk">@@ -1874,7 +1874,7 @@</span> <span class="p_context"> static int i7core_mce_check_error(struct notifier_block *nb, unsigned long val,</span>
 
 	i7_dev = get_i7core_dev(mce-&gt;socketid);
 	if (!i7_dev)
<span class="p_del">-		return NOTIFY_BAD;</span>
<span class="p_add">+		return NOTIFY_DONE;</span>
 
 	mci = i7_dev-&gt;mci;
 	pvt = mci-&gt;pvt_info;
<span class="p_header">diff --git a/drivers/edac/sb_edac.c b/drivers/edac/sb_edac.c</span>
<span class="p_header">index ff75f8904735..beac1858e94f 100644</span>
<span class="p_header">--- a/drivers/edac/sb_edac.c</span>
<span class="p_header">+++ b/drivers/edac/sb_edac.c</span>
<span class="p_chunk">@@ -1841,7 +1841,7 @@</span> <span class="p_context"> static int sbridge_mce_check_error(struct notifier_block *nb, unsigned long val,</span>
 
 	mci = get_mci_for_node_id(mce-&gt;socketid);
 	if (!mci)
<span class="p_del">-		return NOTIFY_BAD;</span>
<span class="p_add">+		return NOTIFY_DONE;</span>
 	pvt = mci-&gt;pvt_info;
 
 	/*
<span class="p_header">diff --git a/drivers/firmware/efi/vars.c b/drivers/firmware/efi/vars.c</span>
<span class="p_header">index 4e2f46938bf0..e7566d4931c6 100644</span>
<span class="p_header">--- a/drivers/firmware/efi/vars.c</span>
<span class="p_header">+++ b/drivers/firmware/efi/vars.c</span>
<span class="p_chunk">@@ -202,29 +202,44 @@</span> <span class="p_context"> static const struct variable_validate variable_validate[] = {</span>
 	{ NULL_GUID, &quot;&quot;, NULL },
 };
 
<span class="p_add">+/*</span>
<span class="p_add">+ * Check if @var_name matches the pattern given in @match_name.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * @var_name: an array of @len non-NUL characters.</span>
<span class="p_add">+ * @match_name: a NUL-terminated pattern string, optionally ending in &quot;*&quot;. A</span>
<span class="p_add">+ *              final &quot;*&quot; character matches any trailing characters @var_name,</span>
<span class="p_add">+ *              including the case when there are none left in @var_name.</span>
<span class="p_add">+ * @match: on output, the number of non-wildcard characters in @match_name</span>
<span class="p_add">+ *         that @var_name matches, regardless of the return value.</span>
<span class="p_add">+ * @return: whether @var_name fully matches @match_name.</span>
<span class="p_add">+ */</span>
 static bool
 variable_matches(const char *var_name, size_t len, const char *match_name,
 		 int *match)
 {
 	for (*match = 0; ; (*match)++) {
 		char c = match_name[*match];
<span class="p_del">-		char u = var_name[*match];</span>
 
<span class="p_del">-		/* Wildcard in the matching name means we&#39;ve matched */</span>
<span class="p_del">-		if (c == &#39;*&#39;)</span>
<span class="p_add">+		switch (c) {</span>
<span class="p_add">+		case &#39;*&#39;:</span>
<span class="p_add">+			/* Wildcard in @match_name means we&#39;ve matched. */</span>
 			return true;
 
<span class="p_del">-		/* Case sensitive match */</span>
<span class="p_del">-		if (!c &amp;&amp; *match == len)</span>
<span class="p_del">-			return true;</span>
<span class="p_add">+		case &#39;\0&#39;:</span>
<span class="p_add">+			/* @match_name has ended. Has @var_name too? */</span>
<span class="p_add">+			return (*match == len);</span>
 
<span class="p_del">-		if (c != u)</span>
<span class="p_add">+		default:</span>
<span class="p_add">+			/*</span>
<span class="p_add">+			 * We&#39;ve reached a non-wildcard char in @match_name.</span>
<span class="p_add">+			 * Continue only if there&#39;s an identical character in</span>
<span class="p_add">+			 * @var_name.</span>
<span class="p_add">+			 */</span>
<span class="p_add">+			if (*match &lt; len &amp;&amp; c == var_name[*match])</span>
<span class="p_add">+				continue;</span>
 			return false;
<span class="p_del">-</span>
<span class="p_del">-		if (!c)</span>
<span class="p_del">-			return true;</span>
<span class="p_add">+		}</span>
 	}
<span class="p_del">-	return true;</span>
 }
 
 bool
<span class="p_header">diff --git a/drivers/gpu/drm/i915/i915_drv.c b/drivers/gpu/drm/i915/i915_drv.c</span>
<span class="p_header">index 17d375344f46..76964900f06d 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/i915/i915_drv.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/i915/i915_drv.c</span>
<span class="p_chunk">@@ -686,6 +686,8 @@</span> <span class="p_context"> static int i915_drm_thaw(struct drm_device *dev)</span>
 
 static int i915_resume_early(struct drm_device *dev)
 {
<span class="p_add">+	int ret;</span>
<span class="p_add">+</span>
 	if (dev-&gt;switch_power_state == DRM_SWITCH_POWER_OFF)
 		return 0;
 
<span class="p_chunk">@@ -698,6 +700,36 @@</span> <span class="p_context"> static int i915_resume_early(struct drm_device *dev)</span>
 	 * FIXME: This should be solved with a special hdmi sink device or
 	 * similar so that power domains can be employed.
 	 */
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Note that we need to set the power state explicitly, since we</span>
<span class="p_add">+	 * powered off the device during freeze and the PCI core won&#39;t power</span>
<span class="p_add">+	 * it back up for us during thaw. Powering off the device during</span>
<span class="p_add">+	 * freeze is not a hard requirement though, and during the</span>
<span class="p_add">+	 * suspend/resume phases the PCI core makes sure we get here with the</span>
<span class="p_add">+	 * device powered on. So in case we change our freeze logic and keep</span>
<span class="p_add">+	 * the device powered we can also remove the following set power state</span>
<span class="p_add">+	 * call.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	ret = pci_set_power_state(dev-&gt;pdev, PCI_D0);</span>
<span class="p_add">+	if (ret) {</span>
<span class="p_add">+		DRM_ERROR(&quot;failed to set PCI D0 power state (%d)\n&quot;, ret);</span>
<span class="p_add">+		return ret;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Note that pci_enable_device() first enables any parent bridge</span>
<span class="p_add">+	 * device and only then sets the power state for this device. The</span>
<span class="p_add">+	 * bridge enabling is a nop though, since bridge devices are resumed</span>
<span class="p_add">+	 * first. The order of enabling power and enabling the device is</span>
<span class="p_add">+	 * imposed by the PCI core as described above, so here we preserve the</span>
<span class="p_add">+	 * same order for the freeze/thaw phases.</span>
<span class="p_add">+	 *</span>
<span class="p_add">+	 * TODO: eventually we should remove pci_disable_device() /</span>
<span class="p_add">+	 * pci_enable_enable_device() from suspend/resume. Due to how they</span>
<span class="p_add">+	 * depend on the device enable refcount we can&#39;t anyway depend on them</span>
<span class="p_add">+	 * disabling/enabling the device.</span>
<span class="p_add">+	 */</span>
 	if (pci_enable_device(dev-&gt;pdev))
 		return -EIO;
 
<span class="p_header">diff --git a/drivers/gpu/drm/i915/i915_gem_userptr.c b/drivers/gpu/drm/i915/i915_gem_userptr.c</span>
<span class="p_header">index 3d98e0d2903d..3ac65a3c7124 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/i915/i915_gem_userptr.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/i915/i915_gem_userptr.c</span>
<span class="p_chunk">@@ -411,19 +411,24 @@</span> <span class="p_context"> __i915_gem_userptr_get_pages_worker(struct work_struct *_work)</span>
 	if (pvec != NULL) {
 		struct mm_struct *mm = obj-&gt;userptr.mm;
 
<span class="p_del">-		down_read(&amp;mm-&gt;mmap_sem);</span>
<span class="p_del">-		while (pinned &lt; num_pages) {</span>
<span class="p_del">-			ret = get_user_pages(work-&gt;task, mm,</span>
<span class="p_del">-					     obj-&gt;userptr.ptr + pinned * PAGE_SIZE,</span>
<span class="p_del">-					     num_pages - pinned,</span>
<span class="p_del">-					     !obj-&gt;userptr.read_only, 0,</span>
<span class="p_del">-					     pvec + pinned, NULL);</span>
<span class="p_del">-			if (ret &lt; 0)</span>
<span class="p_del">-				break;</span>
<span class="p_del">-</span>
<span class="p_del">-			pinned += ret;</span>
<span class="p_add">+		ret = -EFAULT;</span>
<span class="p_add">+		if (atomic_inc_not_zero(&amp;mm-&gt;mm_users)) {</span>
<span class="p_add">+			down_read(&amp;mm-&gt;mmap_sem);</span>
<span class="p_add">+			while (pinned &lt; num_pages) {</span>
<span class="p_add">+				ret = get_user_pages</span>
<span class="p_add">+					(work-&gt;task, mm,</span>
<span class="p_add">+					 obj-&gt;userptr.ptr + pinned * PAGE_SIZE,</span>
<span class="p_add">+					 num_pages - pinned,</span>
<span class="p_add">+					 !obj-&gt;userptr.read_only, 0,</span>
<span class="p_add">+					 pvec + pinned, NULL);</span>
<span class="p_add">+				if (ret &lt; 0)</span>
<span class="p_add">+					break;</span>
<span class="p_add">+</span>
<span class="p_add">+				pinned += ret;</span>
<span class="p_add">+			}</span>
<span class="p_add">+			up_read(&amp;mm-&gt;mmap_sem);</span>
<span class="p_add">+			mmput(mm);</span>
 		}
<span class="p_del">-		up_read(&amp;mm-&gt;mmap_sem);</span>
 	}
 
 	mutex_lock(&amp;dev-&gt;struct_mutex);
<span class="p_header">diff --git a/drivers/gpu/drm/i915/intel_crt.c b/drivers/gpu/drm/i915/intel_crt.c</span>
<span class="p_header">index 3e1edbfa8e07..61183c1642b2 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/i915/intel_crt.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/i915/intel_crt.c</span>
<span class="p_chunk">@@ -285,8 +285,14 @@</span> <span class="p_context"> static bool intel_crt_compute_config(struct intel_encoder *encoder,</span>
 		pipe_config-&gt;has_pch_encoder = true;
 
 	/* LPT FDI RX only supports 8bpc. */
<span class="p_del">-	if (HAS_PCH_LPT(dev))</span>
<span class="p_add">+	if (HAS_PCH_LPT(dev)) {</span>
<span class="p_add">+		if (pipe_config-&gt;bw_constrained &amp;&amp; pipe_config-&gt;pipe_bpp &lt; 24) {</span>
<span class="p_add">+			DRM_DEBUG_KMS(&quot;LPT only supports 24bpp\n&quot;);</span>
<span class="p_add">+			return false;</span>
<span class="p_add">+		}</span>
<span class="p_add">+</span>
 		pipe_config-&gt;pipe_bpp = 24;
<span class="p_add">+	}</span>
 
 	/* FDI must always be 2.7 GHz */
 	if (HAS_DDI(dev))
<span class="p_header">diff --git a/drivers/gpu/drm/qxl/qxl_display.c b/drivers/gpu/drm/qxl/qxl_display.c</span>
<span class="p_header">index 7780a5edfdbb..e06f3372ebad 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/qxl/qxl_display.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/qxl/qxl_display.c</span>
<span class="p_chunk">@@ -295,10 +295,15 @@</span> <span class="p_context"> static int qxl_crtc_cursor_set2(struct drm_crtc *crtc,</span>
 
 	qxl_bo_kunmap(user_bo);
 
<span class="p_add">+	qcrtc-&gt;cur_x += qcrtc-&gt;hot_spot_x - hot_x;</span>
<span class="p_add">+	qcrtc-&gt;cur_y += qcrtc-&gt;hot_spot_y - hot_y;</span>
<span class="p_add">+	qcrtc-&gt;hot_spot_x = hot_x;</span>
<span class="p_add">+	qcrtc-&gt;hot_spot_y = hot_y;</span>
<span class="p_add">+</span>
 	cmd = (struct qxl_cursor_cmd *)qxl_release_map(qdev, release);
 	cmd-&gt;type = QXL_CURSOR_SET;
<span class="p_del">-	cmd-&gt;u.set.position.x = qcrtc-&gt;cur_x;</span>
<span class="p_del">-	cmd-&gt;u.set.position.y = qcrtc-&gt;cur_y;</span>
<span class="p_add">+	cmd-&gt;u.set.position.x = qcrtc-&gt;cur_x + qcrtc-&gt;hot_spot_x;</span>
<span class="p_add">+	cmd-&gt;u.set.position.y = qcrtc-&gt;cur_y + qcrtc-&gt;hot_spot_y;</span>
 
 	cmd-&gt;u.set.shape = qxl_bo_physical_address(qdev, cursor_bo, 0);
 
<span class="p_chunk">@@ -361,8 +366,8 @@</span> <span class="p_context"> static int qxl_crtc_cursor_move(struct drm_crtc *crtc,</span>
 
 	cmd = (struct qxl_cursor_cmd *)qxl_release_map(qdev, release);
 	cmd-&gt;type = QXL_CURSOR_MOVE;
<span class="p_del">-	cmd-&gt;u.position.x = qcrtc-&gt;cur_x;</span>
<span class="p_del">-	cmd-&gt;u.position.y = qcrtc-&gt;cur_y;</span>
<span class="p_add">+	cmd-&gt;u.position.x = qcrtc-&gt;cur_x + qcrtc-&gt;hot_spot_x;</span>
<span class="p_add">+	cmd-&gt;u.position.y = qcrtc-&gt;cur_y + qcrtc-&gt;hot_spot_y;</span>
 	qxl_release_unmap(qdev, release, &amp;cmd-&gt;release_info);
 
 	qxl_push_cursor_ring_release(qdev, release, QXL_CMD_CURSOR, false);
<span class="p_header">diff --git a/drivers/gpu/drm/qxl/qxl_drv.h b/drivers/gpu/drm/qxl/qxl_drv.h</span>
<span class="p_header">index 8aa077ca8244..d5ebf3e33f8e 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/qxl/qxl_drv.h</span>
<span class="p_header">+++ b/drivers/gpu/drm/qxl/qxl_drv.h</span>
<span class="p_chunk">@@ -139,6 +139,8 @@</span> <span class="p_context"> struct qxl_crtc {</span>
 	int index;
 	int cur_x;
 	int cur_y;
<span class="p_add">+	int hot_spot_x;</span>
<span class="p_add">+	int hot_spot_y;</span>
 };
 
 struct qxl_output {
<span class="p_header">diff --git a/drivers/gpu/drm/radeon/atombios_crtc.c b/drivers/gpu/drm/radeon/atombios_crtc.c</span>
<span class="p_header">index ce8cab52285b..2f2e50a0feb4 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/radeon/atombios_crtc.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/radeon/atombios_crtc.c</span>
<span class="p_chunk">@@ -1730,6 +1730,7 @@</span> <span class="p_context"> static u32 radeon_get_pll_use_mask(struct drm_crtc *crtc)</span>
 static int radeon_get_shared_dp_ppll(struct drm_crtc *crtc)
 {
 	struct drm_device *dev = crtc-&gt;dev;
<span class="p_add">+	struct radeon_device *rdev = dev-&gt;dev_private;</span>
 	struct drm_crtc *test_crtc;
 	struct radeon_crtc *test_radeon_crtc;
 
<span class="p_chunk">@@ -1739,6 +1740,10 @@</span> <span class="p_context"> static int radeon_get_shared_dp_ppll(struct drm_crtc *crtc)</span>
 		test_radeon_crtc = to_radeon_crtc(test_crtc);
 		if (test_radeon_crtc-&gt;encoder &amp;&amp;
 		    ENCODER_MODE_IS_DP(atombios_get_encoder_mode(test_radeon_crtc-&gt;encoder))) {
<span class="p_add">+			/* PPLL2 is exclusive to UNIPHYA on DCE61 */</span>
<span class="p_add">+			if (ASIC_IS_DCE61(rdev) &amp;&amp; !ASIC_IS_DCE8(rdev) &amp;&amp;</span>
<span class="p_add">+			    test_radeon_crtc-&gt;pll_id == ATOM_PPLL2)</span>
<span class="p_add">+				continue;</span>
 			/* for DP use the same PLL for all */
 			if (test_radeon_crtc-&gt;pll_id != ATOM_PPLL_INVALID)
 				return test_radeon_crtc-&gt;pll_id;
<span class="p_chunk">@@ -1760,6 +1765,7 @@</span> <span class="p_context"> static int radeon_get_shared_nondp_ppll(struct drm_crtc *crtc)</span>
 {
 	struct radeon_crtc *radeon_crtc = to_radeon_crtc(crtc);
 	struct drm_device *dev = crtc-&gt;dev;
<span class="p_add">+	struct radeon_device *rdev = dev-&gt;dev_private;</span>
 	struct drm_crtc *test_crtc;
 	struct radeon_crtc *test_radeon_crtc;
 	u32 adjusted_clock, test_adjusted_clock;
<span class="p_chunk">@@ -1775,6 +1781,10 @@</span> <span class="p_context"> static int radeon_get_shared_nondp_ppll(struct drm_crtc *crtc)</span>
 		test_radeon_crtc = to_radeon_crtc(test_crtc);
 		if (test_radeon_crtc-&gt;encoder &amp;&amp;
 		    !ENCODER_MODE_IS_DP(atombios_get_encoder_mode(test_radeon_crtc-&gt;encoder))) {
<span class="p_add">+			/* PPLL2 is exclusive to UNIPHYA on DCE61 */</span>
<span class="p_add">+			if (ASIC_IS_DCE61(rdev) &amp;&amp; !ASIC_IS_DCE8(rdev) &amp;&amp;</span>
<span class="p_add">+			    test_radeon_crtc-&gt;pll_id == ATOM_PPLL2)</span>
<span class="p_add">+				continue;</span>
 			/* check if we are already driving this connector with another crtc */
 			if (test_radeon_crtc-&gt;connector == radeon_crtc-&gt;connector) {
 				/* if we are, return that pll */
<span class="p_header">diff --git a/drivers/gpu/drm/radeon/atombios_encoders.c b/drivers/gpu/drm/radeon/atombios_encoders.c</span>
<span class="p_header">index f74f3d59978b..6af1728c5c2b 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/radeon/atombios_encoders.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/radeon/atombios_encoders.c</span>
<span class="p_chunk">@@ -332,6 +332,10 @@</span> <span class="p_context"> static bool radeon_atom_mode_fixup(struct drm_encoder *encoder,</span>
 	    &amp;&amp; (mode-&gt;crtc_vsync_start &lt; (mode-&gt;crtc_vdisplay + 2)))
 		adjusted_mode-&gt;crtc_vsync_start = adjusted_mode-&gt;crtc_vdisplay + 2;
 
<span class="p_add">+	/* vertical FP must be at least 1 */</span>
<span class="p_add">+	if (mode-&gt;crtc_vsync_start == mode-&gt;crtc_vdisplay)</span>
<span class="p_add">+		adjusted_mode-&gt;crtc_vsync_start++;</span>
<span class="p_add">+</span>
 	/* get the native mode for LVDS */
 	if (radeon_encoder-&gt;active_device &amp; (ATOM_DEVICE_LCD_SUPPORT))
 		radeon_panel_mode_fixup(encoder, adjusted_mode);
<span class="p_header">diff --git a/drivers/gpu/drm/radeon/si_dpm.c b/drivers/gpu/drm/radeon/si_dpm.c</span>
<span class="p_header">index 42b2baf0e6d7..92d849e68f14 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/radeon/si_dpm.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/radeon/si_dpm.c</span>
<span class="p_chunk">@@ -2926,6 +2926,7 @@</span> <span class="p_context"> static struct si_dpm_quirk si_dpm_quirk_list[] = {</span>
 	{ PCI_VENDOR_ID_ATI, 0x6811, 0x1462, 0x2015, 0, 120000 },
 	{ PCI_VENDOR_ID_ATI, 0x6811, 0x1043, 0x2015, 0, 120000 },
 	{ PCI_VENDOR_ID_ATI, 0x6811, 0x148c, 0x2015, 0, 120000 },
<span class="p_add">+	{ PCI_VENDOR_ID_ATI, 0x6810, 0x1682, 0x9275, 0, 120000 },</span>
 	{ 0, 0, 0, 0 },
 };
 
<span class="p_header">diff --git a/drivers/hid/usbhid/hid-core.c b/drivers/hid/usbhid/hid-core.c</span>
<span class="p_header">index 421187ba053a..b8021c499bbd 100644</span>
<span class="p_header">--- a/drivers/hid/usbhid/hid-core.c</span>
<span class="p_header">+++ b/drivers/hid/usbhid/hid-core.c</span>
<span class="p_chunk">@@ -955,14 +955,6 @@</span> <span class="p_context"> static int usbhid_output_report(struct hid_device *hid, __u8 *buf, size_t count)</span>
 	return ret;
 }
 
<span class="p_del">-static void usbhid_restart_queues(struct usbhid_device *usbhid)</span>
<span class="p_del">-{</span>
<span class="p_del">-	if (usbhid-&gt;urbout &amp;&amp; !test_bit(HID_OUT_RUNNING, &amp;usbhid-&gt;iofl))</span>
<span class="p_del">-		usbhid_restart_out_queue(usbhid);</span>
<span class="p_del">-	if (!test_bit(HID_CTRL_RUNNING, &amp;usbhid-&gt;iofl))</span>
<span class="p_del">-		usbhid_restart_ctrl_queue(usbhid);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
 static void hid_free_buffers(struct usb_device *dev, struct hid_device *hid)
 {
 	struct usbhid_device *usbhid = hid-&gt;driver_data;
<span class="p_chunk">@@ -1408,6 +1400,37 @@</span> <span class="p_context"> static void hid_cease_io(struct usbhid_device *usbhid)</span>
 	usb_kill_urb(usbhid-&gt;urbout);
 }
 
<span class="p_add">+static void hid_restart_io(struct hid_device *hid)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct usbhid_device *usbhid = hid-&gt;driver_data;</span>
<span class="p_add">+	int clear_halt = test_bit(HID_CLEAR_HALT, &amp;usbhid-&gt;iofl);</span>
<span class="p_add">+	int reset_pending = test_bit(HID_RESET_PENDING, &amp;usbhid-&gt;iofl);</span>
<span class="p_add">+</span>
<span class="p_add">+	spin_lock_irq(&amp;usbhid-&gt;lock);</span>
<span class="p_add">+	clear_bit(HID_SUSPENDED, &amp;usbhid-&gt;iofl);</span>
<span class="p_add">+	usbhid_mark_busy(usbhid);</span>
<span class="p_add">+</span>
<span class="p_add">+	if (clear_halt || reset_pending)</span>
<span class="p_add">+		schedule_work(&amp;usbhid-&gt;reset_work);</span>
<span class="p_add">+	usbhid-&gt;retry_delay = 0;</span>
<span class="p_add">+	spin_unlock_irq(&amp;usbhid-&gt;lock);</span>
<span class="p_add">+</span>
<span class="p_add">+	if (reset_pending || !test_bit(HID_STARTED, &amp;usbhid-&gt;iofl))</span>
<span class="p_add">+		return;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (!clear_halt) {</span>
<span class="p_add">+		if (hid_start_in(hid) &lt; 0)</span>
<span class="p_add">+			hid_io_error(hid);</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	spin_lock_irq(&amp;usbhid-&gt;lock);</span>
<span class="p_add">+	if (usbhid-&gt;urbout &amp;&amp; !test_bit(HID_OUT_RUNNING, &amp;usbhid-&gt;iofl))</span>
<span class="p_add">+		usbhid_restart_out_queue(usbhid);</span>
<span class="p_add">+	if (!test_bit(HID_CTRL_RUNNING, &amp;usbhid-&gt;iofl))</span>
<span class="p_add">+		usbhid_restart_ctrl_queue(usbhid);</span>
<span class="p_add">+	spin_unlock_irq(&amp;usbhid-&gt;lock);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 /* Treat USB reset pretty much the same as suspend/resume */
 static int hid_pre_reset(struct usb_interface *intf)
 {
<span class="p_chunk">@@ -1457,14 +1480,14 @@</span> <span class="p_context"> static int hid_post_reset(struct usb_interface *intf)</span>
 		return 1;
 	}
 
<span class="p_add">+	/* No need to do another reset or clear a halted endpoint */</span>
 	spin_lock_irq(&amp;usbhid-&gt;lock);
 	clear_bit(HID_RESET_PENDING, &amp;usbhid-&gt;iofl);
<span class="p_add">+	clear_bit(HID_CLEAR_HALT, &amp;usbhid-&gt;iofl);</span>
 	spin_unlock_irq(&amp;usbhid-&gt;lock);
 	hid_set_idle(dev, intf-&gt;cur_altsetting-&gt;desc.bInterfaceNumber, 0, 0);
<span class="p_del">-	status = hid_start_in(hid);</span>
<span class="p_del">-	if (status &lt; 0)</span>
<span class="p_del">-		hid_io_error(hid);</span>
<span class="p_del">-	usbhid_restart_queues(usbhid);</span>
<span class="p_add">+</span>
<span class="p_add">+	hid_restart_io(hid);</span>
 
 	return 0;
 }
<span class="p_chunk">@@ -1487,25 +1510,9 @@</span> <span class="p_context"> void usbhid_put_power(struct hid_device *hid)</span>
 #ifdef CONFIG_PM
 static int hid_resume_common(struct hid_device *hid, bool driver_suspended)
 {
<span class="p_del">-	struct usbhid_device *usbhid = hid-&gt;driver_data;</span>
<span class="p_del">-	int status;</span>
<span class="p_del">-</span>
<span class="p_del">-	spin_lock_irq(&amp;usbhid-&gt;lock);</span>
<span class="p_del">-	clear_bit(HID_SUSPENDED, &amp;usbhid-&gt;iofl);</span>
<span class="p_del">-	usbhid_mark_busy(usbhid);</span>
<span class="p_del">-</span>
<span class="p_del">-	if (test_bit(HID_CLEAR_HALT, &amp;usbhid-&gt;iofl) ||</span>
<span class="p_del">-			test_bit(HID_RESET_PENDING, &amp;usbhid-&gt;iofl))</span>
<span class="p_del">-		schedule_work(&amp;usbhid-&gt;reset_work);</span>
<span class="p_del">-	usbhid-&gt;retry_delay = 0;</span>
<span class="p_del">-</span>
<span class="p_del">-	usbhid_restart_queues(usbhid);</span>
<span class="p_del">-	spin_unlock_irq(&amp;usbhid-&gt;lock);</span>
<span class="p_del">-</span>
<span class="p_del">-	status = hid_start_in(hid);</span>
<span class="p_del">-	if (status &lt; 0)</span>
<span class="p_del">-		hid_io_error(hid);</span>
<span class="p_add">+	int status = 0;</span>
 
<span class="p_add">+	hid_restart_io(hid);</span>
 	if (driver_suspended &amp;&amp; hid-&gt;driver &amp;&amp; hid-&gt;driver-&gt;resume)
 		status = hid-&gt;driver-&gt;resume(hid);
 	return status;
<span class="p_chunk">@@ -1574,12 +1581,8 @@</span> <span class="p_context"> static int hid_suspend(struct usb_interface *intf, pm_message_t message)</span>
 static int hid_resume(struct usb_interface *intf)
 {
 	struct hid_device *hid = usb_get_intfdata (intf);
<span class="p_del">-	struct usbhid_device *usbhid = hid-&gt;driver_data;</span>
 	int status;
 
<span class="p_del">-	if (!test_bit(HID_STARTED, &amp;usbhid-&gt;iofl))</span>
<span class="p_del">-		return 0;</span>
<span class="p_del">-</span>
 	status = hid_resume_common(hid, true);
 	dev_dbg(&amp;intf-&gt;dev, &quot;resume status %d\n&quot;, status);
 	return 0;
<span class="p_chunk">@@ -1588,10 +1591,8 @@</span> <span class="p_context"> static int hid_resume(struct usb_interface *intf)</span>
 static int hid_reset_resume(struct usb_interface *intf)
 {
 	struct hid_device *hid = usb_get_intfdata(intf);
<span class="p_del">-	struct usbhid_device *usbhid = hid-&gt;driver_data;</span>
 	int status;
 
<span class="p_del">-	clear_bit(HID_SUSPENDED, &amp;usbhid-&gt;iofl);</span>
 	status = hid_post_reset(intf);
 	if (status &gt;= 0 &amp;&amp; hid-&gt;driver &amp;&amp; hid-&gt;driver-&gt;reset_resume) {
 		int ret = hid-&gt;driver-&gt;reset_resume(hid);
<span class="p_header">diff --git a/drivers/hv/ring_buffer.c b/drivers/hv/ring_buffer.c</span>
<span class="p_header">index 15db66b74141..5648add68e51 100644</span>
<span class="p_header">--- a/drivers/hv/ring_buffer.c</span>
<span class="p_header">+++ b/drivers/hv/ring_buffer.c</span>
<span class="p_chunk">@@ -103,17 +103,30 @@</span> <span class="p_context"> static bool hv_need_to_signal(u32 old_write, struct hv_ring_buffer_info *rbi)</span>
  *    there is room for the producer to send the pending packet.
  */
 
<span class="p_del">-static bool hv_need_to_signal_on_read(u32 old_rd,</span>
<span class="p_del">-					 struct hv_ring_buffer_info *rbi)</span>
<span class="p_add">+static bool hv_need_to_signal_on_read(struct hv_ring_buffer_info *rbi)</span>
 {
<span class="p_del">-	u32 prev_write_sz;</span>
 	u32 cur_write_sz;
 	u32 r_size;
<span class="p_del">-	u32 write_loc = rbi-&gt;ring_buffer-&gt;write_index;</span>
<span class="p_add">+	u32 write_loc;</span>
 	u32 read_loc = rbi-&gt;ring_buffer-&gt;read_index;
<span class="p_del">-	u32 pending_sz = rbi-&gt;ring_buffer-&gt;pending_send_sz;</span>
<span class="p_add">+	u32 pending_sz;</span>
 
 	/*
<span class="p_add">+	 * Issue a full memory barrier before making the signaling decision.</span>
<span class="p_add">+	 * Here is the reason for having this barrier:</span>
<span class="p_add">+	 * If the reading of the pend_sz (in this function)</span>
<span class="p_add">+	 * were to be reordered and read before we commit the new read</span>
<span class="p_add">+	 * index (in the calling function)  we could</span>
<span class="p_add">+	 * have a problem. If the host were to set the pending_sz after we</span>
<span class="p_add">+	 * have sampled pending_sz and go to sleep before we commit the</span>
<span class="p_add">+	 * read index, we could miss sending the interrupt. Issue a full</span>
<span class="p_add">+	 * memory barrier to address this.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	mb();</span>
<span class="p_add">+</span>
<span class="p_add">+	pending_sz = rbi-&gt;ring_buffer-&gt;pending_send_sz;</span>
<span class="p_add">+	write_loc = rbi-&gt;ring_buffer-&gt;write_index;</span>
<span class="p_add">+	/*</span>
 	 * If the other end is not blocked on write don&#39;t bother.
 	 */
 	if (pending_sz == 0)
<span class="p_chunk">@@ -123,11 +136,7 @@</span> <span class="p_context"> static bool hv_need_to_signal_on_read(u32 old_rd,</span>
 	cur_write_sz = write_loc &gt;= read_loc ? r_size - (write_loc - read_loc) :
 			read_loc - write_loc;
 
<span class="p_del">-	prev_write_sz = write_loc &gt;= old_rd ? r_size - (write_loc - old_rd) :</span>
<span class="p_del">-			old_rd - write_loc;</span>
<span class="p_del">-</span>
<span class="p_del">-</span>
<span class="p_del">-	if ((prev_write_sz &lt; pending_sz) &amp;&amp; (cur_write_sz &gt;= pending_sz))</span>
<span class="p_add">+	if (cur_write_sz &gt;= pending_sz)</span>
 		return true;
 
 	return false;
<span class="p_chunk">@@ -512,7 +521,6 @@</span> <span class="p_context"> int hv_ringbuffer_read(struct hv_ring_buffer_info *inring_info, void *buffer,</span>
 	u32 next_read_location = 0;
 	u64 prev_indices = 0;
 	unsigned long flags;
<span class="p_del">-	u32 old_read;</span>
 
 	if (buflen &lt;= 0)
 		return -EINVAL;
<span class="p_chunk">@@ -523,8 +531,6 @@</span> <span class="p_context"> int hv_ringbuffer_read(struct hv_ring_buffer_info *inring_info, void *buffer,</span>
 				&amp;bytes_avail_toread,
 				&amp;bytes_avail_towrite);
 
<span class="p_del">-	old_read = bytes_avail_toread;</span>
<span class="p_del">-</span>
 	/* Make sure there is something to read */
 	if (bytes_avail_toread &lt; buflen) {
 		spin_unlock_irqrestore(&amp;inring_info-&gt;ring_lock, flags);
<span class="p_chunk">@@ -555,7 +561,7 @@</span> <span class="p_context"> int hv_ringbuffer_read(struct hv_ring_buffer_info *inring_info, void *buffer,</span>
 
 	spin_unlock_irqrestore(&amp;inring_info-&gt;ring_lock, flags);
 
<span class="p_del">-	*signal = hv_need_to_signal_on_read(old_read, inring_info);</span>
<span class="p_add">+	*signal = hv_need_to_signal_on_read(inring_info);</span>
 
 	return 0;
 }
<span class="p_header">diff --git a/drivers/i2c/busses/i2c-exynos5.c b/drivers/i2c/busses/i2c-exynos5.c</span>
<span class="p_header">index 63d229202854..c35d44d2f8c1 100644</span>
<span class="p_header">--- a/drivers/i2c/busses/i2c-exynos5.c</span>
<span class="p_header">+++ b/drivers/i2c/busses/i2c-exynos5.c</span>
<span class="p_chunk">@@ -615,7 +615,9 @@</span> <span class="p_context"> static int exynos5_i2c_xfer(struct i2c_adapter *adap,</span>
 		return -EIO;
 	}
 
<span class="p_del">-	clk_prepare_enable(i2c-&gt;clk);</span>
<span class="p_add">+	ret = clk_enable(i2c-&gt;clk);</span>
<span class="p_add">+	if (ret)</span>
<span class="p_add">+		return ret;</span>
 
 	for (i = 0; i &lt; num; i++, msgs++) {
 		stop = (i == num - 1);
<span class="p_chunk">@@ -639,7 +641,7 @@</span> <span class="p_context"> static int exynos5_i2c_xfer(struct i2c_adapter *adap,</span>
 	}
 
  out:
<span class="p_del">-	clk_disable_unprepare(i2c-&gt;clk);</span>
<span class="p_add">+	clk_disable(i2c-&gt;clk);</span>
 	return ret;
 }
 
<span class="p_chunk">@@ -691,7 +693,9 @@</span> <span class="p_context"> static int exynos5_i2c_probe(struct platform_device *pdev)</span>
 		return -ENOENT;
 	}
 
<span class="p_del">-	clk_prepare_enable(i2c-&gt;clk);</span>
<span class="p_add">+	ret = clk_prepare_enable(i2c-&gt;clk);</span>
<span class="p_add">+	if (ret)</span>
<span class="p_add">+		return ret;</span>
 
 	mem = platform_get_resource(pdev, IORESOURCE_MEM, 0);
 	i2c-&gt;regs = devm_ioremap_resource(&amp;pdev-&gt;dev, mem);
<span class="p_chunk">@@ -742,6 +746,10 @@</span> <span class="p_context"> static int exynos5_i2c_probe(struct platform_device *pdev)</span>
 
 	platform_set_drvdata(pdev, i2c);
 
<span class="p_add">+	clk_disable(i2c-&gt;clk);</span>
<span class="p_add">+</span>
<span class="p_add">+	return 0;</span>
<span class="p_add">+</span>
  err_clk:
 	clk_disable_unprepare(i2c-&gt;clk);
 	return ret;
<span class="p_chunk">@@ -753,6 +761,8 @@</span> <span class="p_context"> static int exynos5_i2c_remove(struct platform_device *pdev)</span>
 
 	i2c_del_adapter(&amp;i2c-&gt;adap);
 
<span class="p_add">+	clk_unprepare(i2c-&gt;clk);</span>
<span class="p_add">+</span>
 	return 0;
 }
 
<span class="p_chunk">@@ -764,6 +774,8 @@</span> <span class="p_context"> static int exynos5_i2c_suspend_noirq(struct device *dev)</span>
 
 	i2c-&gt;suspended = 1;
 
<span class="p_add">+	clk_unprepare(i2c-&gt;clk);</span>
<span class="p_add">+</span>
 	return 0;
 }
 
<span class="p_chunk">@@ -773,7 +785,9 @@</span> <span class="p_context"> static int exynos5_i2c_resume_noirq(struct device *dev)</span>
 	struct exynos5_i2c *i2c = platform_get_drvdata(pdev);
 	int ret = 0;
 
<span class="p_del">-	clk_prepare_enable(i2c-&gt;clk);</span>
<span class="p_add">+	ret = clk_prepare_enable(i2c-&gt;clk);</span>
<span class="p_add">+	if (ret)</span>
<span class="p_add">+		return ret;</span>
 
 	ret = exynos5_hsi2c_clock_setup(i2c);
 	if (ret) {
<span class="p_chunk">@@ -782,7 +796,7 @@</span> <span class="p_context"> static int exynos5_i2c_resume_noirq(struct device *dev)</span>
 	}
 
 	exynos5_i2c_init(i2c);
<span class="p_del">-	clk_disable_unprepare(i2c-&gt;clk);</span>
<span class="p_add">+	clk_disable(i2c-&gt;clk);</span>
 	i2c-&gt;suspended = 0;
 
 	return 0;
<span class="p_header">diff --git a/drivers/iio/magnetometer/ak8975.c b/drivers/iio/magnetometer/ak8975.c</span>
<span class="p_header">index ea08313af0d2..ff12a18c5ad8 100644</span>
<span class="p_header">--- a/drivers/iio/magnetometer/ak8975.c</span>
<span class="p_header">+++ b/drivers/iio/magnetometer/ak8975.c</span>
<span class="p_chunk">@@ -160,6 +160,8 @@</span> <span class="p_context"> static int ak8975_setup_irq(struct ak8975_data *data)</span>
 	int rc;
 	int irq;
 
<span class="p_add">+	init_waitqueue_head(&amp;data-&gt;data_ready_queue);</span>
<span class="p_add">+	clear_bit(0, &amp;data-&gt;flags);</span>
 	if (client-&gt;irq)
 		irq = client-&gt;irq;
 	else
<span class="p_chunk">@@ -175,8 +177,6 @@</span> <span class="p_context"> static int ak8975_setup_irq(struct ak8975_data *data)</span>
 		return rc;
 	}
 
<span class="p_del">-	init_waitqueue_head(&amp;data-&gt;data_ready_queue);</span>
<span class="p_del">-	clear_bit(0, &amp;data-&gt;flags);</span>
 	data-&gt;eoc_irq = irq;
 
 	return rc;
<span class="p_header">diff --git a/drivers/infiniband/core/ucm.c b/drivers/infiniband/core/ucm.c</span>
<span class="p_header">index f2f63933e8a9..5befec118a18 100644</span>
<span class="p_header">--- a/drivers/infiniband/core/ucm.c</span>
<span class="p_header">+++ b/drivers/infiniband/core/ucm.c</span>
<span class="p_chunk">@@ -48,6 +48,7 @@</span> <span class="p_context"></span>
 
 #include &lt;asm/uaccess.h&gt;
 
<span class="p_add">+#include &lt;rdma/ib.h&gt;</span>
 #include &lt;rdma/ib_cm.h&gt;
 #include &lt;rdma/ib_user_cm.h&gt;
 #include &lt;rdma/ib_marshall.h&gt;
<span class="p_chunk">@@ -1104,6 +1105,9 @@</span> <span class="p_context"> static ssize_t ib_ucm_write(struct file *filp, const char __user *buf,</span>
 	struct ib_ucm_cmd_hdr hdr;
 	ssize_t result;
 
<span class="p_add">+	if (WARN_ON_ONCE(!ib_safe_file_access(filp)))</span>
<span class="p_add">+		return -EACCES;</span>
<span class="p_add">+</span>
 	if (len &lt; sizeof(hdr))
 		return -EINVAL;
 
<span class="p_header">diff --git a/drivers/infiniband/core/ucma.c b/drivers/infiniband/core/ucma.c</span>
<span class="p_header">index 45d67e9228d7..81dd84d0b68b 100644</span>
<span class="p_header">--- a/drivers/infiniband/core/ucma.c</span>
<span class="p_header">+++ b/drivers/infiniband/core/ucma.c</span>
<span class="p_chunk">@@ -1487,6 +1487,9 @@</span> <span class="p_context"> static ssize_t ucma_write(struct file *filp, const char __user *buf,</span>
 	struct rdma_ucm_cmd_hdr hdr;
 	ssize_t ret;
 
<span class="p_add">+	if (WARN_ON_ONCE(!ib_safe_file_access(filp)))</span>
<span class="p_add">+		return -EACCES;</span>
<span class="p_add">+</span>
 	if (len &lt; sizeof(hdr))
 		return -EINVAL;
 
<span class="p_header">diff --git a/drivers/infiniband/core/uverbs_main.c b/drivers/infiniband/core/uverbs_main.c</span>
<span class="p_header">index 8802d5ccd93d..f3ecfe4b9571 100644</span>
<span class="p_header">--- a/drivers/infiniband/core/uverbs_main.c</span>
<span class="p_header">+++ b/drivers/infiniband/core/uverbs_main.c</span>
<span class="p_chunk">@@ -48,6 +48,8 @@</span> <span class="p_context"></span>
 
 #include &lt;asm/uaccess.h&gt;
 
<span class="p_add">+#include &lt;rdma/ib.h&gt;</span>
<span class="p_add">+</span>
 #include &quot;uverbs.h&quot;
 
 MODULE_AUTHOR(&quot;Roland Dreier&quot;);
<span class="p_chunk">@@ -605,6 +607,9 @@</span> <span class="p_context"> static ssize_t ib_uverbs_write(struct file *filp, const char __user *buf,</span>
 	struct ib_uverbs_cmd_hdr hdr;
 	__u32 flags;
 
<span class="p_add">+	if (WARN_ON_ONCE(!ib_safe_file_access(filp)))</span>
<span class="p_add">+		return -EACCES;</span>
<span class="p_add">+</span>
 	if (count &lt; sizeof hdr)
 		return -EINVAL;
 
<span class="p_header">diff --git a/drivers/infiniband/hw/ipath/ipath_file_ops.c b/drivers/infiniband/hw/ipath/ipath_file_ops.c</span>
<span class="p_header">index 6d7f453b4d05..a0626b8c61c5 100644</span>
<span class="p_header">--- a/drivers/infiniband/hw/ipath/ipath_file_ops.c</span>
<span class="p_header">+++ b/drivers/infiniband/hw/ipath/ipath_file_ops.c</span>
<span class="p_chunk">@@ -45,6 +45,8 @@</span> <span class="p_context"></span>
 #include &lt;linux/cpu.h&gt;
 #include &lt;asm/pgtable.h&gt;
 
<span class="p_add">+#include &lt;rdma/ib.h&gt;</span>
<span class="p_add">+</span>
 #include &quot;ipath_kernel.h&quot;
 #include &quot;ipath_common.h&quot;
 #include &quot;ipath_user_sdma.h&quot;
<span class="p_chunk">@@ -2240,6 +2242,9 @@</span> <span class="p_context"> static ssize_t ipath_write(struct file *fp, const char __user *data,</span>
 	ssize_t ret = 0;
 	void *dest;
 
<span class="p_add">+	if (WARN_ON_ONCE(!ib_safe_file_access(fp)))</span>
<span class="p_add">+		return -EACCES;</span>
<span class="p_add">+</span>
 	if (count &lt; sizeof(cmd.type)) {
 		ret = -EINVAL;
 		goto bail;
<span class="p_header">diff --git a/drivers/infiniband/hw/qib/qib_file_ops.c b/drivers/infiniband/hw/qib/qib_file_ops.c</span>
<span class="p_header">index b15e34eeef68..3ab8229b1d8c 100644</span>
<span class="p_header">--- a/drivers/infiniband/hw/qib/qib_file_ops.c</span>
<span class="p_header">+++ b/drivers/infiniband/hw/qib/qib_file_ops.c</span>
<span class="p_chunk">@@ -45,6 +45,8 @@</span> <span class="p_context"></span>
 #include &lt;linux/delay.h&gt;
 #include &lt;linux/export.h&gt;
 
<span class="p_add">+#include &lt;rdma/ib.h&gt;</span>
<span class="p_add">+</span>
 #include &quot;qib.h&quot;
 #include &quot;qib_common.h&quot;
 #include &quot;qib_user_sdma.h&quot;
<span class="p_chunk">@@ -2058,6 +2060,9 @@</span> <span class="p_context"> static ssize_t qib_write(struct file *fp, const char __user *data,</span>
 	ssize_t ret = 0;
 	void *dest;
 
<span class="p_add">+	if (WARN_ON_ONCE(!ib_safe_file_access(fp)))</span>
<span class="p_add">+		return -EACCES;</span>
<span class="p_add">+</span>
 	if (count &lt; sizeof(cmd.type)) {
 		ret = -EINVAL;
 		goto bail;
<span class="p_header">diff --git a/drivers/input/misc/pmic8xxx-pwrkey.c b/drivers/input/misc/pmic8xxx-pwrkey.c</span>
<span class="p_header">index c91e3d33aea9..88db9204bac2 100644</span>
<span class="p_header">--- a/drivers/input/misc/pmic8xxx-pwrkey.c</span>
<span class="p_header">+++ b/drivers/input/misc/pmic8xxx-pwrkey.c</span>
<span class="p_chunk">@@ -94,7 +94,8 @@</span> <span class="p_context"> static int pmic8xxx_pwrkey_probe(struct platform_device *pdev)</span>
 	if (of_property_read_u32(pdev-&gt;dev.of_node, &quot;debounce&quot;, &amp;kpd_delay))
 		kpd_delay = 15625;
 
<span class="p_del">-	if (kpd_delay &gt; 62500 || kpd_delay == 0) {</span>
<span class="p_add">+	/* Valid range of pwr key trigger delay is 1/64 sec to 2 seconds. */</span>
<span class="p_add">+	if (kpd_delay &gt; USEC_PER_SEC * 2 || kpd_delay &lt; USEC_PER_SEC / 64) {</span>
 		dev_err(&amp;pdev-&gt;dev, &quot;invalid power key trigger delay\n&quot;);
 		return -EINVAL;
 	}
<span class="p_chunk">@@ -124,8 +125,8 @@</span> <span class="p_context"> static int pmic8xxx_pwrkey_probe(struct platform_device *pdev)</span>
 	pwr-&gt;name = &quot;pmic8xxx_pwrkey&quot;;
 	pwr-&gt;phys = &quot;pmic8xxx_pwrkey/input0&quot;;
 
<span class="p_del">-	delay = (kpd_delay &lt;&lt; 10) / USEC_PER_SEC;</span>
<span class="p_del">-	delay = 1 + ilog2(delay);</span>
<span class="p_add">+	delay = (kpd_delay &lt;&lt; 6) / USEC_PER_SEC;</span>
<span class="p_add">+	delay = ilog2(delay);</span>
 
 	err = regmap_read(regmap, PON_CNTL_1, &amp;pon_cntl);
 	if (err &lt; 0) {
<span class="p_header">diff --git a/drivers/input/tablet/gtco.c b/drivers/input/tablet/gtco.c</span>
<span class="p_header">index 858045694e9d..a51de543a0b2 100644</span>
<span class="p_header">--- a/drivers/input/tablet/gtco.c</span>
<span class="p_header">+++ b/drivers/input/tablet/gtco.c</span>
<span class="p_chunk">@@ -868,6 +868,14 @@</span> <span class="p_context"> static int gtco_probe(struct usb_interface *usbinterface,</span>
 		goto err_free_buf;
 	}
 
<span class="p_add">+	/* Sanity check that a device has an endpoint */</span>
<span class="p_add">+	if (usbinterface-&gt;altsetting[0].desc.bNumEndpoints &lt; 1) {</span>
<span class="p_add">+		dev_err(&amp;usbinterface-&gt;dev,</span>
<span class="p_add">+			&quot;Invalid number of endpoints\n&quot;);</span>
<span class="p_add">+		error = -EINVAL;</span>
<span class="p_add">+		goto err_free_urb;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
 	/*
 	 * The endpoint is always altsetting 0, we know this since we know
 	 * this device only has one interrupt endpoint
<span class="p_chunk">@@ -889,7 +897,7 @@</span> <span class="p_context"> static int gtco_probe(struct usb_interface *usbinterface,</span>
 	 * HID report descriptor
 	 */
 	if (usb_get_extra_descriptor(usbinterface-&gt;cur_altsetting,
<span class="p_del">-				     HID_DEVICE_TYPE, &amp;hid_desc) != 0){</span>
<span class="p_add">+				     HID_DEVICE_TYPE, &amp;hid_desc) != 0) {</span>
 		dev_err(&amp;usbinterface-&gt;dev,
 			&quot;Can&#39;t retrieve exta USB descriptor to get hid report descriptor length\n&quot;);
 		error = -EIO;
<span class="p_header">diff --git a/drivers/net/ethernet/atheros/atlx/atl2.c b/drivers/net/ethernet/atheros/atlx/atl2.c</span>
<span class="p_header">index 6746bd717146..daec2e5a27ef 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/atheros/atlx/atl2.c</span>
<span class="p_header">+++ b/drivers/net/ethernet/atheros/atlx/atl2.c</span>
<span class="p_chunk">@@ -1412,7 +1412,7 @@</span> <span class="p_context"> static int atl2_probe(struct pci_dev *pdev, const struct pci_device_id *ent)</span>
 
 	err = -EIO;
 
<span class="p_del">-	netdev-&gt;hw_features = NETIF_F_SG | NETIF_F_HW_VLAN_CTAG_RX;</span>
<span class="p_add">+	netdev-&gt;hw_features = NETIF_F_HW_VLAN_CTAG_RX;</span>
 	netdev-&gt;features |= (NETIF_F_HW_VLAN_CTAG_TX | NETIF_F_HW_VLAN_CTAG_RX);
 
 	/* Init PHY as early as possible due to power saving issue  */
<span class="p_header">diff --git a/drivers/net/ethernet/broadcom/genet/bcmgenet.c b/drivers/net/ethernet/broadcom/genet/bcmgenet.c</span>
<span class="p_header">index 25f267cc967a..9cbfda2961ec 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/broadcom/genet/bcmgenet.c</span>
<span class="p_header">+++ b/drivers/net/ethernet/broadcom/genet/bcmgenet.c</span>
<span class="p_chunk">@@ -715,7 +715,11 @@</span> <span class="p_context"> static void bcmgenet_get_ethtool_stats(struct net_device *dev,</span>
 		else
 			p = (char *)priv;
 		p += s-&gt;stat_offset;
<span class="p_del">-		data[i] = *(u32 *)p;</span>
<span class="p_add">+		if (sizeof(unsigned long) != sizeof(u32) &amp;&amp;</span>
<span class="p_add">+		    s-&gt;stat_sizeof == sizeof(unsigned long))</span>
<span class="p_add">+			data[i] = *(unsigned long *)p;</span>
<span class="p_add">+		else</span>
<span class="p_add">+			data[i] = *(u32 *)p;</span>
 	}
 }
 
<span class="p_header">diff --git a/drivers/net/ethernet/mellanox/mlx4/en_tx.c b/drivers/net/ethernet/mellanox/mlx4/en_tx.c</span>
<span class="p_header">index 8068b0557c5a..c5be6d890e94 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/mellanox/mlx4/en_tx.c</span>
<span class="p_header">+++ b/drivers/net/ethernet/mellanox/mlx4/en_tx.c</span>
<span class="p_chunk">@@ -371,7 +371,6 @@</span> <span class="p_context"> static bool mlx4_en_process_tx_cq(struct net_device *dev,</span>
 	u32 packets = 0;
 	u32 bytes = 0;
 	int factor = priv-&gt;cqe_factor;
<span class="p_del">-	u64 timestamp = 0;</span>
 	int done = 0;
 	int budget = priv-&gt;tx_work_limit;
 
<span class="p_chunk">@@ -405,9 +404,12 @@</span> <span class="p_context"> static bool mlx4_en_process_tx_cq(struct net_device *dev,</span>
 		new_index = be16_to_cpu(cqe-&gt;wqe_index) &amp; size_mask;
 
 		do {
<span class="p_add">+			u64 timestamp = 0;</span>
<span class="p_add">+</span>
 			txbbs_skipped += ring-&gt;last_nr_txbb;
 			ring_index = (ring_index + ring-&gt;last_nr_txbb) &amp; size_mask;
<span class="p_del">-			if (ring-&gt;tx_info[ring_index].ts_requested)</span>
<span class="p_add">+</span>
<span class="p_add">+			if (unlikely(ring-&gt;tx_info[ring_index].ts_requested))</span>
 				timestamp = mlx4_en_get_cqe_ts(cqe);
 
 			/* free next descriptor */
<span class="p_header">diff --git a/drivers/net/ethernet/ti/davinci_emac.c b/drivers/net/ethernet/ti/davinci_emac.c</span>
<span class="p_header">index 35a139e9a833..16d95002b9c1 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/ti/davinci_emac.c</span>
<span class="p_header">+++ b/drivers/net/ethernet/ti/davinci_emac.c</span>
<span class="p_chunk">@@ -1843,8 +1843,6 @@</span> <span class="p_context"> davinci_emac_of_get_pdata(struct platform_device *pdev, struct emac_priv *priv)</span>
 		pdata-&gt;hw_ram_addr = auxdata-&gt;hw_ram_addr;
 	}
 
<span class="p_del">-	pdev-&gt;dev.platform_data = pdata;</span>
<span class="p_del">-</span>
 	return  pdata;
 }
 
<span class="p_chunk">@@ -2033,6 +2031,7 @@</span> <span class="p_context"> static int davinci_emac_remove(struct platform_device *pdev)</span>
 	cpdma_ctlr_destroy(priv-&gt;dma);
 
 	unregister_netdev(ndev);
<span class="p_add">+	pm_runtime_disable(&amp;pdev-&gt;dev);</span>
 	free_netdev(ndev);
 
 	return 0;
<span class="p_header">diff --git a/drivers/net/macvtap.c b/drivers/net/macvtap.c</span>
<span class="p_header">index e9c3677a196e..faa79040d336 100644</span>
<span class="p_header">--- a/drivers/net/macvtap.c</span>
<span class="p_header">+++ b/drivers/net/macvtap.c</span>
<span class="p_chunk">@@ -310,7 +310,7 @@</span> <span class="p_context"> static rx_handler_result_t macvtap_handle_frame(struct sk_buff **pskb)</span>
 			goto wake_up;
 		}
 
<span class="p_del">-		kfree_skb(skb);</span>
<span class="p_add">+		consume_skb(skb);</span>
 		while (segs) {
 			struct sk_buff *nskb = segs-&gt;next;
 
<span class="p_header">diff --git a/drivers/pinctrl/pinctrl-single.c b/drivers/pinctrl/pinctrl-single.c</span>
<span class="p_header">index 2960557bfed9..8fda801c5c48 100644</span>
<span class="p_header">--- a/drivers/pinctrl/pinctrl-single.c</span>
<span class="p_header">+++ b/drivers/pinctrl/pinctrl-single.c</span>
<span class="p_chunk">@@ -1329,9 +1329,9 @@</span> <span class="p_context"> static int pcs_parse_bits_in_pinctrl_entry(struct pcs_device *pcs,</span>
 
 		/* Parse pins in each row from LSB */
 		while (mask) {
<span class="p_del">-			bit_pos = ffs(mask);</span>
<span class="p_add">+			bit_pos = __ffs(mask);</span>
 			pin_num_from_lsb = bit_pos / pcs-&gt;bits_per_pin;
<span class="p_del">-			mask_pos = ((pcs-&gt;fmask) &lt;&lt; (bit_pos - 1));</span>
<span class="p_add">+			mask_pos = ((pcs-&gt;fmask) &lt;&lt; bit_pos);</span>
 			val_pos = val &amp; mask_pos;
 			submask = mask &amp; mask_pos;
 
<span class="p_chunk">@@ -1908,7 +1908,7 @@</span> <span class="p_context"> static int pcs_probe(struct platform_device *pdev)</span>
 	ret = of_property_read_u32(np, &quot;pinctrl-single,function-mask&quot;,
 				   &amp;pcs-&gt;fmask);
 	if (!ret) {
<span class="p_del">-		pcs-&gt;fshift = ffs(pcs-&gt;fmask) - 1;</span>
<span class="p_add">+		pcs-&gt;fshift = __ffs(pcs-&gt;fmask);</span>
 		pcs-&gt;fmax = pcs-&gt;fmask &gt;&gt; pcs-&gt;fshift;
 	} else {
 		/* If mask property doesn&#39;t exist, function mux is invalid. */
<span class="p_header">diff --git a/drivers/regulator/s2mps11.c b/drivers/regulator/s2mps11.c</span>
<span class="p_header">index 02e2fb2fca66..c9562a773e28 100644</span>
<span class="p_header">--- a/drivers/regulator/s2mps11.c</span>
<span class="p_header">+++ b/drivers/regulator/s2mps11.c</span>
<span class="p_chunk">@@ -335,10 +335,10 @@</span> <span class="p_context"> static struct regulator_ops s2mps11_buck_ops = {</span>
 	.owner		= THIS_MODULE,				\
 	.min_uV		= S2MPS11_BUCK_MIN3,			\
 	.uV_step	= S2MPS11_BUCK_STEP3,			\
<span class="p_del">-	.n_voltages	= S2MPS11_BUCK_N_VOLTAGES,		\</span>
<span class="p_add">+	.n_voltages	= S2MPS11_BUCK9_N_VOLTAGES,		\</span>
 	.ramp_delay	= S2MPS11_RAMP_DELAY,			\
 	.vsel_reg	= S2MPS11_REG_B9CTRL2,			\
<span class="p_del">-	.vsel_mask	= S2MPS11_BUCK_VSEL_MASK,		\</span>
<span class="p_add">+	.vsel_mask	= S2MPS11_BUCK9_VSEL_MASK,		\</span>
 	.enable_reg	= S2MPS11_REG_B9CTRL1,			\
 	.enable_mask	= S2MPS11_ENABLE_MASK			\
 }
<span class="p_header">diff --git a/drivers/s390/block/scm_blk.c b/drivers/s390/block/scm_blk.c</span>
<span class="p_header">index 76bed1743db1..bc1ea58040d7 100644</span>
<span class="p_header">--- a/drivers/s390/block/scm_blk.c</span>
<span class="p_header">+++ b/drivers/s390/block/scm_blk.c</span>
<span class="p_chunk">@@ -210,7 +210,7 @@</span> <span class="p_context"> static void scm_blk_request(struct request_queue *rq)</span>
 		if (req-&gt;cmd_type != REQ_TYPE_FS) {
 			blk_start_request(req);
 			blk_dump_rq_flags(req, KMSG_COMPONENT &quot; bad request&quot;);
<span class="p_del">-			blk_end_request_all(req, -EIO);</span>
<span class="p_add">+			__blk_end_request_all(req, -EIO);</span>
 			continue;
 		}
 
<span class="p_header">diff --git a/drivers/spi/spi-ti-qspi.c b/drivers/spi/spi-ti-qspi.c</span>
<span class="p_header">index b68511204367..d09d05b9c54d 100644</span>
<span class="p_header">--- a/drivers/spi/spi-ti-qspi.c</span>
<span class="p_header">+++ b/drivers/spi/spi-ti-qspi.c</span>
<span class="p_chunk">@@ -91,6 +91,7 @@</span> <span class="p_context"> struct ti_qspi {</span>
 /* Command */
 #define QSPI_EN_CS(n)			(n &lt;&lt; 28)
 #define QSPI_WLEN(n)			((n - 1) &lt;&lt; 19)
<span class="p_add">+#define QSPI_WLEN_MASK			QSPI_WLEN(128)</span>
 #define QSPI_3_PIN			(1 &lt;&lt; 18)
 #define QSPI_RD_SNGL			(1 &lt;&lt; 16)
 #define QSPI_WR_SNGL			(2 &lt;&lt; 16)
<span class="p_chunk">@@ -199,15 +200,15 @@</span> <span class="p_context"> static void ti_qspi_restore_ctx(struct ti_qspi *qspi)</span>
 	ti_qspi_write(qspi, ctx_reg-&gt;clkctrl, QSPI_SPI_CLOCK_CNTRL_REG);
 }
 
<span class="p_del">-static int qspi_write_msg(struct ti_qspi *qspi, struct spi_transfer *t)</span>
<span class="p_add">+static int qspi_write_msg(struct ti_qspi *qspi, struct spi_transfer *t,</span>
<span class="p_add">+			  int count)</span>
 {
<span class="p_del">-	int wlen, count, ret;</span>
<span class="p_add">+	int wlen, ret;</span>
 	unsigned int cmd;
 	const u8 *txbuf;
 
 	txbuf = t-&gt;tx_buf;
 	cmd = qspi-&gt;cmd | QSPI_WR_SNGL;
<span class="p_del">-	count = t-&gt;len;</span>
 	wlen = t-&gt;bits_per_word &gt;&gt; 3;	/* in bytes */
 
 	while (count) {
<span class="p_chunk">@@ -243,9 +244,10 @@</span> <span class="p_context"> static int qspi_write_msg(struct ti_qspi *qspi, struct spi_transfer *t)</span>
 	return 0;
 }
 
<span class="p_del">-static int qspi_read_msg(struct ti_qspi *qspi, struct spi_transfer *t)</span>
<span class="p_add">+static int qspi_read_msg(struct ti_qspi *qspi, struct spi_transfer *t,</span>
<span class="p_add">+			 int count)</span>
 {
<span class="p_del">-	int wlen, count, ret;</span>
<span class="p_add">+	int wlen, ret;</span>
 	unsigned int cmd;
 	u8 *rxbuf;
 
<span class="p_chunk">@@ -262,7 +264,6 @@</span> <span class="p_context"> static int qspi_read_msg(struct ti_qspi *qspi, struct spi_transfer *t)</span>
 		cmd |= QSPI_RD_SNGL;
 		break;
 	}
<span class="p_del">-	count = t-&gt;len;</span>
 	wlen = t-&gt;bits_per_word &gt;&gt; 3;	/* in bytes */
 
 	while (count) {
<span class="p_chunk">@@ -292,12 +293,13 @@</span> <span class="p_context"> static int qspi_read_msg(struct ti_qspi *qspi, struct spi_transfer *t)</span>
 	return 0;
 }
 
<span class="p_del">-static int qspi_transfer_msg(struct ti_qspi *qspi, struct spi_transfer *t)</span>
<span class="p_add">+static int qspi_transfer_msg(struct ti_qspi *qspi, struct spi_transfer *t,</span>
<span class="p_add">+			     int count)</span>
 {
 	int ret;
 
 	if (t-&gt;tx_buf) {
<span class="p_del">-		ret = qspi_write_msg(qspi, t);</span>
<span class="p_add">+		ret = qspi_write_msg(qspi, t, count);</span>
 		if (ret) {
 			dev_dbg(qspi-&gt;dev, &quot;Error while writing\n&quot;);
 			return ret;
<span class="p_chunk">@@ -305,7 +307,7 @@</span> <span class="p_context"> static int qspi_transfer_msg(struct ti_qspi *qspi, struct spi_transfer *t)</span>
 	}
 
 	if (t-&gt;rx_buf) {
<span class="p_del">-		ret = qspi_read_msg(qspi, t);</span>
<span class="p_add">+		ret = qspi_read_msg(qspi, t, count);</span>
 		if (ret) {
 			dev_dbg(qspi-&gt;dev, &quot;Error while reading\n&quot;);
 			return ret;
<span class="p_chunk">@@ -322,7 +324,8 @@</span> <span class="p_context"> static int ti_qspi_start_transfer_one(struct spi_master *master,</span>
 	struct spi_device *spi = m-&gt;spi;
 	struct spi_transfer *t;
 	int status = 0, ret;
<span class="p_del">-	int frame_length;</span>
<span class="p_add">+	unsigned int frame_len_words, transfer_len_words;</span>
<span class="p_add">+	int wlen;</span>
 
 	/* setup device control reg */
 	qspi-&gt;dc = 0;
<span class="p_chunk">@@ -334,14 +337,15 @@</span> <span class="p_context"> static int ti_qspi_start_transfer_one(struct spi_master *master,</span>
 	if (spi-&gt;mode &amp; SPI_CS_HIGH)
 		qspi-&gt;dc |= QSPI_CSPOL(spi-&gt;chip_select);
 
<span class="p_del">-	frame_length = (m-&gt;frame_length &lt;&lt; 3) / spi-&gt;bits_per_word;</span>
<span class="p_del">-</span>
<span class="p_del">-	frame_length = clamp(frame_length, 0, QSPI_FRAME);</span>
<span class="p_add">+	frame_len_words = 0;</span>
<span class="p_add">+	list_for_each_entry(t, &amp;m-&gt;transfers, transfer_list)</span>
<span class="p_add">+		frame_len_words += t-&gt;len / (t-&gt;bits_per_word &gt;&gt; 3);</span>
<span class="p_add">+	frame_len_words = min_t(unsigned int, frame_len_words, QSPI_FRAME);</span>
 
 	/* setup command reg */
 	qspi-&gt;cmd = 0;
 	qspi-&gt;cmd |= QSPI_EN_CS(spi-&gt;chip_select);
<span class="p_del">-	qspi-&gt;cmd |= QSPI_FLEN(frame_length);</span>
<span class="p_add">+	qspi-&gt;cmd |= QSPI_FLEN(frame_len_words);</span>
 	qspi-&gt;cmd |= QSPI_WC_CMD_INT_EN;
 
 	ti_qspi_write(qspi, QSPI_WC_INT_EN, QSPI_INTR_ENABLE_SET_REG);
<span class="p_chunk">@@ -350,16 +354,23 @@</span> <span class="p_context"> static int ti_qspi_start_transfer_one(struct spi_master *master,</span>
 	mutex_lock(&amp;qspi-&gt;list_lock);
 
 	list_for_each_entry(t, &amp;m-&gt;transfers, transfer_list) {
<span class="p_del">-		qspi-&gt;cmd |= QSPI_WLEN(t-&gt;bits_per_word);</span>
<span class="p_add">+		qspi-&gt;cmd = ((qspi-&gt;cmd &amp; ~QSPI_WLEN_MASK) |</span>
<span class="p_add">+			     QSPI_WLEN(t-&gt;bits_per_word));</span>
<span class="p_add">+</span>
<span class="p_add">+		wlen = t-&gt;bits_per_word &gt;&gt; 3;</span>
<span class="p_add">+		transfer_len_words = min(t-&gt;len / wlen, frame_len_words);</span>
 
<span class="p_del">-		ret = qspi_transfer_msg(qspi, t);</span>
<span class="p_add">+		ret = qspi_transfer_msg(qspi, t, transfer_len_words * wlen);</span>
 		if (ret) {
 			dev_dbg(qspi-&gt;dev, &quot;transfer message failed\n&quot;);
 			mutex_unlock(&amp;qspi-&gt;list_lock);
 			return -EINVAL;
 		}
 
<span class="p_del">-		m-&gt;actual_length += t-&gt;len;</span>
<span class="p_add">+		m-&gt;actual_length += transfer_len_words * wlen;</span>
<span class="p_add">+		frame_len_words -= transfer_len_words;</span>
<span class="p_add">+		if (frame_len_words == 0)</span>
<span class="p_add">+			break;</span>
 	}
 
 	mutex_unlock(&amp;qspi-&gt;list_lock);
<span class="p_header">diff --git a/drivers/usb/core/hcd-pci.c b/drivers/usb/core/hcd-pci.c</span>
<span class="p_header">index 82044b5d6113..f6bbfaf05573 100644</span>
<span class="p_header">--- a/drivers/usb/core/hcd-pci.c</span>
<span class="p_header">+++ b/drivers/usb/core/hcd-pci.c</span>
<span class="p_chunk">@@ -74,6 +74,15 @@</span> <span class="p_context"> static void for_each_companion(struct pci_dev *pdev, struct usb_hcd *hcd,</span>
 		if (companion-&gt;bus != pdev-&gt;bus ||
 				PCI_SLOT(companion-&gt;devfn) != slot)
 			continue;
<span class="p_add">+</span>
<span class="p_add">+		/*</span>
<span class="p_add">+		 * Companion device should be either UHCI,OHCI or EHCI host</span>
<span class="p_add">+		 * controller, otherwise skip.</span>
<span class="p_add">+		 */</span>
<span class="p_add">+		if (companion-&gt;class != CL_UHCI &amp;&amp; companion-&gt;class != CL_OHCI &amp;&amp;</span>
<span class="p_add">+				companion-&gt;class != CL_EHCI)</span>
<span class="p_add">+			continue;</span>
<span class="p_add">+</span>
 		companion_hcd = pci_get_drvdata(companion);
 		if (!companion_hcd || !companion_hcd-&gt;self.root_hub)
 			continue;
<span class="p_header">diff --git a/drivers/usb/host/xhci-mem.c b/drivers/usb/host/xhci-mem.c</span>
<span class="p_header">index f08e81f42951..e46c3b1414b9 100644</span>
<span class="p_header">--- a/drivers/usb/host/xhci-mem.c</span>
<span class="p_header">+++ b/drivers/usb/host/xhci-mem.c</span>
<span class="p_chunk">@@ -1882,6 +1882,12 @@</span> <span class="p_context"> no_bw:</span>
 	kfree(xhci-&gt;rh_bw);
 	kfree(xhci-&gt;ext_caps);
 
<span class="p_add">+	xhci-&gt;usb2_ports = NULL;</span>
<span class="p_add">+	xhci-&gt;usb3_ports = NULL;</span>
<span class="p_add">+	xhci-&gt;port_array = NULL;</span>
<span class="p_add">+	xhci-&gt;rh_bw = NULL;</span>
<span class="p_add">+	xhci-&gt;ext_caps = NULL;</span>
<span class="p_add">+</span>
 	xhci-&gt;page_size = 0;
 	xhci-&gt;page_shift = 0;
 	xhci-&gt;bus_state[0].bus_suspended = 0;
<span class="p_header">diff --git a/drivers/usb/host/xhci-pci.c b/drivers/usb/host/xhci-pci.c</span>
<span class="p_header">index 749a77d253e1..3a8696c2c228 100644</span>
<span class="p_header">--- a/drivers/usb/host/xhci-pci.c</span>
<span class="p_header">+++ b/drivers/usb/host/xhci-pci.c</span>
<span class="p_chunk">@@ -41,6 +41,7 @@</span> <span class="p_context"></span>
 #define PCI_DEVICE_ID_INTEL_SUNRISEPOINT_H_XHCI		0xa12f
 #define PCI_DEVICE_ID_INTEL_SUNRISEPOINT_LP_XHCI	0x9d2f
 #define PCI_DEVICE_ID_INTEL_BROXTON_M_XHCI		0x0aa8
<span class="p_add">+#define PCI_DEVICE_ID_INTEL_BROXTON_B_XHCI		0x1aa8</span>
 
 static const char hcd_name[] = &quot;xhci_hcd&quot;;
 
<span class="p_chunk">@@ -140,7 +141,8 @@</span> <span class="p_context"> static void xhci_pci_quirks(struct device *dev, struct xhci_hcd *xhci)</span>
 		(pdev-&gt;device == PCI_DEVICE_ID_INTEL_SUNRISEPOINT_LP_XHCI ||
 		 pdev-&gt;device == PCI_DEVICE_ID_INTEL_SUNRISEPOINT_H_XHCI ||
 		 pdev-&gt;device == PCI_DEVICE_ID_INTEL_CHERRYVIEW_XHCI ||
<span class="p_del">-		 pdev-&gt;device == PCI_DEVICE_ID_INTEL_BROXTON_M_XHCI)) {</span>
<span class="p_add">+		 pdev-&gt;device == PCI_DEVICE_ID_INTEL_BROXTON_M_XHCI ||</span>
<span class="p_add">+		 pdev-&gt;device == PCI_DEVICE_ID_INTEL_BROXTON_B_XHCI)) {</span>
 		xhci-&gt;quirks |= XHCI_PME_STUCK_QUIRK;
 	}
 	if (pdev-&gt;vendor == PCI_VENDOR_ID_ETRON &amp;&amp;
<span class="p_header">diff --git a/drivers/usb/serial/cp210x.c b/drivers/usb/serial/cp210x.c</span>
<span class="p_header">index b689a2fd960c..16f1b199d46b 100644</span>
<span class="p_header">--- a/drivers/usb/serial/cp210x.c</span>
<span class="p_header">+++ b/drivers/usb/serial/cp210x.c</span>
<span class="p_chunk">@@ -108,6 +108,7 @@</span> <span class="p_context"> static const struct usb_device_id id_table[] = {</span>
 	{ USB_DEVICE(0x10C4, 0x826B) }, /* Cygnal Integrated Products, Inc., Fasttrax GPS demonstration module */
 	{ USB_DEVICE(0x10C4, 0x8281) }, /* Nanotec Plug &amp; Drive */
 	{ USB_DEVICE(0x10C4, 0x8293) }, /* Telegesis ETRX2USB */
<span class="p_add">+	{ USB_DEVICE(0x10C4, 0x82F4) }, /* Starizona MicroTouch */</span>
 	{ USB_DEVICE(0x10C4, 0x82F9) }, /* Procyon AVS */
 	{ USB_DEVICE(0x10C4, 0x8341) }, /* Siemens MC35PU GPRS Modem */
 	{ USB_DEVICE(0x10C4, 0x8382) }, /* Cygnal Integrated Products, Inc. */
<span class="p_chunk">@@ -117,6 +118,7 @@</span> <span class="p_context"> static const struct usb_device_id id_table[] = {</span>
 	{ USB_DEVICE(0x10C4, 0x8418) }, /* IRZ Automation Teleport SG-10 GSM/GPRS Modem */
 	{ USB_DEVICE(0x10C4, 0x846E) }, /* BEI USB Sensor Interface (VCP) */
 	{ USB_DEVICE(0x10C4, 0x8477) }, /* Balluff RFID */
<span class="p_add">+	{ USB_DEVICE(0x10C4, 0x84B6) }, /* Starizona Hyperion */</span>
 	{ USB_DEVICE(0x10C4, 0x85EA) }, /* AC-Services IBUS-IF */
 	{ USB_DEVICE(0x10C4, 0x85EB) }, /* AC-Services CIS-IBUS */
 	{ USB_DEVICE(0x10C4, 0x85F8) }, /* Virtenio Preon32 */
<span class="p_chunk">@@ -140,6 +142,8 @@</span> <span class="p_context"> static const struct usb_device_id id_table[] = {</span>
 	{ USB_DEVICE(0x10C4, 0xF004) }, /* Elan Digital Systems USBcount50 */
 	{ USB_DEVICE(0x10C5, 0xEA61) }, /* Silicon Labs MobiData GPRS USB Modem */
 	{ USB_DEVICE(0x10CE, 0xEA6A) }, /* Silicon Labs MobiData GPRS USB Modem 100EU */
<span class="p_add">+	{ USB_DEVICE(0x12B8, 0xEC60) }, /* Link G4 ECU */</span>
<span class="p_add">+	{ USB_DEVICE(0x12B8, 0xEC62) }, /* Link G4+ ECU */</span>
 	{ USB_DEVICE(0x13AD, 0x9999) }, /* Baltech card reader */
 	{ USB_DEVICE(0x1555, 0x0004) }, /* Owen AC4 USB-RS485 Converter */
 	{ USB_DEVICE(0x166A, 0x0201) }, /* Clipsal 5500PACA C-Bus Pascal Automation Controller */
<span class="p_header">diff --git a/drivers/usb/storage/uas.c b/drivers/usb/storage/uas.c</span>
<span class="p_header">index c8adef24368c..88ccb9c6516e 100644</span>
<span class="p_header">--- a/drivers/usb/storage/uas.c</span>
<span class="p_header">+++ b/drivers/usb/storage/uas.c</span>
<span class="p_chunk">@@ -2,7 +2,7 @@</span> <span class="p_context"></span>
  * USB Attached SCSI
  * Note that this is not the same as the USB Mass Storage driver
  *
<span class="p_del">- * Copyright Hans de Goede &lt;hdegoede@redhat.com&gt; for Red Hat, Inc. 2013</span>
<span class="p_add">+ * Copyright Hans de Goede &lt;hdegoede@redhat.com&gt; for Red Hat, Inc. 2013 - 2016</span>
  * Copyright Matthew Wilcox for Intel Corp, 2010
  * Copyright Sarah Sharp for Intel Corp, 2010
  *
<span class="p_chunk">@@ -936,6 +936,17 @@</span> <span class="p_context"> static int uas_eh_bus_reset_handler(struct scsi_cmnd *cmnd)</span>
 	return SUCCESS;
 }
 
<span class="p_add">+static int uas_target_alloc(struct scsi_target *starget)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct uas_dev_info *devinfo = (struct uas_dev_info *)</span>
<span class="p_add">+			dev_to_shost(starget-&gt;dev.parent)-&gt;hostdata;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (devinfo-&gt;flags &amp; US_FL_NO_REPORT_LUNS)</span>
<span class="p_add">+		starget-&gt;no_report_luns = 1;</span>
<span class="p_add">+</span>
<span class="p_add">+	return 0;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static int uas_slave_alloc(struct scsi_device *sdev)
 {
 	struct uas_dev_info *devinfo =
<span class="p_chunk">@@ -988,6 +999,7 @@</span> <span class="p_context"> static struct scsi_host_template uas_host_template = {</span>
 	.module = THIS_MODULE,
 	.name = &quot;uas&quot;,
 	.queuecommand = uas_queuecommand,
<span class="p_add">+	.target_alloc = uas_target_alloc,</span>
 	.slave_alloc = uas_slave_alloc,
 	.slave_configure = uas_slave_configure,
 	.eh_abort_handler = uas_eh_abort_handler,
<span class="p_header">diff --git a/drivers/usb/storage/unusual_uas.h b/drivers/usb/storage/unusual_uas.h</span>
<span class="p_header">index ac2f9d491419..d696eaf71cf9 100644</span>
<span class="p_header">--- a/drivers/usb/storage/unusual_uas.h</span>
<span class="p_header">+++ b/drivers/usb/storage/unusual_uas.h</span>
<span class="p_chunk">@@ -54,6 +54,13 @@</span> <span class="p_context"> UNUSUAL_DEV(0x0bc2, 0x3312, 0x0000, 0x9999,</span>
 		USB_SC_DEVICE, USB_PR_DEVICE, NULL,
 		US_FL_NO_ATA_1X),
 
<span class="p_add">+/* Reported-by: David Webb &lt;djw@noc.ac.uk&gt; */</span>
<span class="p_add">+UNUSUAL_DEV(0x0bc2, 0x331a, 0x0000, 0x9999,</span>
<span class="p_add">+		&quot;Seagate&quot;,</span>
<span class="p_add">+		&quot;Expansion Desk&quot;,</span>
<span class="p_add">+		USB_SC_DEVICE, USB_PR_DEVICE, NULL,</span>
<span class="p_add">+		US_FL_NO_REPORT_LUNS),</span>
<span class="p_add">+</span>
 /* Reported-by: Hans de Goede &lt;hdegoede@redhat.com&gt; */
 UNUSUAL_DEV(0x0bc2, 0x3320, 0x0000, 0x9999,
 		&quot;Seagate&quot;,
<span class="p_header">diff --git a/drivers/usb/storage/usb.c b/drivers/usb/storage/usb.c</span>
<span class="p_header">index 79323d008f2d..93b567fddf07 100644</span>
<span class="p_header">--- a/drivers/usb/storage/usb.c</span>
<span class="p_header">+++ b/drivers/usb/storage/usb.c</span>
<span class="p_chunk">@@ -478,7 +478,7 @@</span> <span class="p_context"> void usb_stor_adjust_quirks(struct usb_device *udev, unsigned long *fflags)</span>
 			US_FL_NO_READ_DISC_INFO | US_FL_NO_READ_CAPACITY_16 |
 			US_FL_INITIAL_READ10 | US_FL_WRITE_CACHE |
 			US_FL_NO_ATA_1X | US_FL_NO_REPORT_OPCODES |
<span class="p_del">-			US_FL_MAX_SECTORS_240);</span>
<span class="p_add">+			US_FL_MAX_SECTORS_240 | US_FL_NO_REPORT_LUNS);</span>
 
 	p = quirks;
 	while (*p) {
<span class="p_chunk">@@ -528,6 +528,9 @@</span> <span class="p_context"> void usb_stor_adjust_quirks(struct usb_device *udev, unsigned long *fflags)</span>
 		case &#39;i&#39;:
 			f |= US_FL_IGNORE_DEVICE;
 			break;
<span class="p_add">+		case &#39;j&#39;:</span>
<span class="p_add">+			f |= US_FL_NO_REPORT_LUNS;</span>
<span class="p_add">+			break;</span>
 		case &#39;l&#39;:
 			f |= US_FL_NOT_LOCKABLE;
 			break;
<span class="p_header">diff --git a/drivers/virtio/virtio_balloon.c b/drivers/virtio/virtio_balloon.c</span>
<span class="p_header">index eb35e3fa984a..7490e92c03d5 100644</span>
<span class="p_header">--- a/drivers/virtio/virtio_balloon.c</span>
<span class="p_header">+++ b/drivers/virtio/virtio_balloon.c</span>
<span class="p_chunk">@@ -163,8 +163,8 @@</span> <span class="p_context"> static void release_pages_by_pfn(const u32 pfns[], unsigned int num)</span>
 	/* Find pfns pointing at start of each page, get pages and free them. */
 	for (i = 0; i &lt; num; i += VIRTIO_BALLOON_PAGES_PER_PAGE) {
 		struct page *page = balloon_pfn_to_page(pfns[i]);
<span class="p_del">-		balloon_page_free(page);</span>
 		adjust_managed_page_count(page, 1);
<span class="p_add">+		put_page(page); /* balloon reference */</span>
 	}
 }
 
<span class="p_chunk">@@ -395,6 +395,8 @@</span> <span class="p_context"> static int virtballoon_migratepage(struct address_space *mapping,</span>
 	if (!mutex_trylock(&amp;vb-&gt;balloon_lock))
 		return -EAGAIN;
 
<span class="p_add">+	get_page(newpage); /* balloon reference */</span>
<span class="p_add">+</span>
 	/* balloon&#39;s page migration 1st step  -- inflate &quot;newpage&quot; */
 	spin_lock_irqsave(&amp;vb_dev_info-&gt;pages_lock, flags);
 	balloon_page_insert(newpage, mapping, &amp;vb_dev_info-&gt;pages);
<span class="p_chunk">@@ -404,12 +406,7 @@</span> <span class="p_context"> static int virtballoon_migratepage(struct address_space *mapping,</span>
 	set_page_pfns(vb-&gt;pfns, newpage);
 	tell_host(vb, vb-&gt;inflate_vq);
 
<span class="p_del">-	/*</span>
<span class="p_del">-	 * balloon&#39;s page migration 2nd step -- deflate &quot;page&quot;</span>
<span class="p_del">-	 *</span>
<span class="p_del">-	 * It&#39;s safe to delete page-&gt;lru here because this page is at</span>
<span class="p_del">-	 * an isolated migration list, and this step is expected to happen here</span>
<span class="p_del">-	 */</span>
<span class="p_add">+	/* balloon&#39;s page migration 2nd step -- deflate &quot;page&quot; */</span>
 	balloon_page_delete(page);
 	vb-&gt;num_pfns = VIRTIO_BALLOON_PAGES_PER_PAGE;
 	set_page_pfns(vb-&gt;pfns, page);
<span class="p_chunk">@@ -417,7 +414,9 @@</span> <span class="p_context"> static int virtballoon_migratepage(struct address_space *mapping,</span>
 
 	mutex_unlock(&amp;vb-&gt;balloon_lock);
 
<span class="p_del">-	return MIGRATEPAGE_BALLOON_SUCCESS;</span>
<span class="p_add">+	put_page(page); /* balloon reference */</span>
<span class="p_add">+</span>
<span class="p_add">+	return MIGRATEPAGE_SUCCESS;</span>
 }
 
 /* define the balloon_mapping-&gt;a_ops callback to allow balloon page migration */
<span class="p_header">diff --git a/fs/ceph/mds_client.c b/fs/ceph/mds_client.c</span>
<span class="p_header">index 6b6f11b8f36a..8f5835c89194 100644</span>
<span class="p_header">--- a/fs/ceph/mds_client.c</span>
<span class="p_header">+++ b/fs/ceph/mds_client.c</span>
<span class="p_chunk">@@ -366,9 +366,7 @@</span> <span class="p_context"> void ceph_put_mds_session(struct ceph_mds_session *s)</span>
 	     atomic_read(&amp;s-&gt;s_ref), atomic_read(&amp;s-&gt;s_ref)-1);
 	if (atomic_dec_and_test(&amp;s-&gt;s_ref)) {
 		if (s-&gt;s_auth.authorizer)
<span class="p_del">-			ceph_auth_destroy_authorizer(</span>
<span class="p_del">-				s-&gt;s_mdsc-&gt;fsc-&gt;client-&gt;monc.auth,</span>
<span class="p_del">-				s-&gt;s_auth.authorizer);</span>
<span class="p_add">+			ceph_auth_destroy_authorizer(s-&gt;s_auth.authorizer);</span>
 		kfree(s);
 	}
 }
<span class="p_chunk">@@ -3601,7 +3599,7 @@</span> <span class="p_context"> static struct ceph_auth_handshake *get_authorizer(struct ceph_connection *con,</span>
 	struct ceph_auth_handshake *auth = &amp;s-&gt;s_auth;
 
 	if (force_new &amp;&amp; auth-&gt;authorizer) {
<span class="p_del">-		ceph_auth_destroy_authorizer(ac, auth-&gt;authorizer);</span>
<span class="p_add">+		ceph_auth_destroy_authorizer(auth-&gt;authorizer);</span>
 		auth-&gt;authorizer = NULL;
 	}
 	if (!auth-&gt;authorizer) {
<span class="p_header">diff --git a/fs/isofs/rock.c b/fs/isofs/rock.c</span>
<span class="p_header">index 735d7522a3a9..204659a5f6db 100644</span>
<span class="p_header">--- a/fs/isofs/rock.c</span>
<span class="p_header">+++ b/fs/isofs/rock.c</span>
<span class="p_chunk">@@ -203,6 +203,8 @@</span> <span class="p_context"> int get_rock_ridge_filename(struct iso_directory_record *de,</span>
 	int retnamlen = 0;
 	int truncate = 0;
 	int ret = 0;
<span class="p_add">+	char *p;</span>
<span class="p_add">+	int len;</span>
 
 	if (!ISOFS_SB(inode-&gt;i_sb)-&gt;s_rock)
 		return 0;
<span class="p_chunk">@@ -267,12 +269,17 @@</span> <span class="p_context"> repeat:</span>
 					rr-&gt;u.NM.flags);
 				break;
 			}
<span class="p_del">-			if ((strlen(retname) + rr-&gt;len - 5) &gt;= 254) {</span>
<span class="p_add">+			len = rr-&gt;len - 5;</span>
<span class="p_add">+			if (retnamlen + len &gt;= 254) {</span>
 				truncate = 1;
 				break;
 			}
<span class="p_del">-			strncat(retname, rr-&gt;u.NM.name, rr-&gt;len - 5);</span>
<span class="p_del">-			retnamlen += rr-&gt;len - 5;</span>
<span class="p_add">+			p = memchr(rr-&gt;u.NM.name, &#39;\0&#39;, len);</span>
<span class="p_add">+			if (unlikely(p))</span>
<span class="p_add">+				len = p - rr-&gt;u.NM.name;</span>
<span class="p_add">+			memcpy(retname + retnamlen, rr-&gt;u.NM.name, len);</span>
<span class="p_add">+			retnamlen += len;</span>
<span class="p_add">+			retname[retnamlen] = &#39;\0&#39;;</span>
 			break;
 		case SIG(&#39;R&#39;, &#39;E&#39;):
 			kfree(rs.buffer);
<span class="p_header">diff --git a/fs/namei.c b/fs/namei.c</span>
<span class="p_header">index 34f8224be4ed..55c97a75e5a7 100644</span>
<span class="p_header">--- a/fs/namei.c</span>
<span class="p_header">+++ b/fs/namei.c</span>
<span class="p_chunk">@@ -2797,22 +2797,10 @@</span> <span class="p_context"> no_open:</span>
 		dentry = lookup_real(dir, dentry, nd-&gt;flags);
 		if (IS_ERR(dentry))
 			return PTR_ERR(dentry);
<span class="p_del">-</span>
<span class="p_del">-		if (create_error) {</span>
<span class="p_del">-			int open_flag = op-&gt;open_flag;</span>
<span class="p_del">-</span>
<span class="p_del">-			error = create_error;</span>
<span class="p_del">-			if ((open_flag &amp; O_EXCL)) {</span>
<span class="p_del">-				if (!dentry-&gt;d_inode)</span>
<span class="p_del">-					goto out;</span>
<span class="p_del">-			} else if (!dentry-&gt;d_inode) {</span>
<span class="p_del">-				goto out;</span>
<span class="p_del">-			} else if ((open_flag &amp; O_TRUNC) &amp;&amp;</span>
<span class="p_del">-				   S_ISREG(dentry-&gt;d_inode-&gt;i_mode)) {</span>
<span class="p_del">-				goto out;</span>
<span class="p_del">-			}</span>
<span class="p_del">-			/* will fail later, go on to get the right error */</span>
<span class="p_del">-		}</span>
<span class="p_add">+	}</span>
<span class="p_add">+	if (create_error &amp;&amp; !dentry-&gt;d_inode) {</span>
<span class="p_add">+		error = create_error;</span>
<span class="p_add">+		goto out;</span>
 	}
 looked_up:
 	path-&gt;dentry = dentry;
<span class="p_header">diff --git a/fs/ocfs2/acl.c b/fs/ocfs2/acl.c</span>
<span class="p_header">index 7e8282dcea2a..7f9e4484c6f6 100644</span>
<span class="p_header">--- a/fs/ocfs2/acl.c</span>
<span class="p_header">+++ b/fs/ocfs2/acl.c</span>
<span class="p_chunk">@@ -310,3 +310,66 @@</span> <span class="p_context"> struct posix_acl *ocfs2_iop_get_acl(struct inode *inode, int type)</span>
 
 	return acl;
 }
<span class="p_add">+</span>
<span class="p_add">+/*</span>
<span class="p_add">+ * Initialize the ACLs of a new inode. If parent directory has default ACL,</span>
<span class="p_add">+ * then clone to new inode. Called from ocfs2_mknod.</span>
<span class="p_add">+ */</span>
<span class="p_add">+int ocfs2_init_acl(handle_t *handle,</span>
<span class="p_add">+		   struct inode *inode,</span>
<span class="p_add">+		   struct inode *dir,</span>
<span class="p_add">+		   struct buffer_head *di_bh,</span>
<span class="p_add">+		   struct buffer_head *dir_bh,</span>
<span class="p_add">+		   struct ocfs2_alloc_context *meta_ac,</span>
<span class="p_add">+		   struct ocfs2_alloc_context *data_ac)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct ocfs2_super *osb = OCFS2_SB(inode-&gt;i_sb);</span>
<span class="p_add">+	struct posix_acl *acl = NULL;</span>
<span class="p_add">+	int ret = 0, ret2;</span>
<span class="p_add">+	umode_t mode;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (!S_ISLNK(inode-&gt;i_mode)) {</span>
<span class="p_add">+		if (osb-&gt;s_mount_opt &amp; OCFS2_MOUNT_POSIX_ACL) {</span>
<span class="p_add">+			acl = ocfs2_get_acl_nolock(dir, ACL_TYPE_DEFAULT,</span>
<span class="p_add">+						   dir_bh);</span>
<span class="p_add">+			if (IS_ERR(acl))</span>
<span class="p_add">+				return PTR_ERR(acl);</span>
<span class="p_add">+		}</span>
<span class="p_add">+		if (!acl) {</span>
<span class="p_add">+			mode = inode-&gt;i_mode &amp; ~current_umask();</span>
<span class="p_add">+			ret = ocfs2_acl_set_mode(inode, di_bh, handle, mode);</span>
<span class="p_add">+			if (ret) {</span>
<span class="p_add">+				mlog_errno(ret);</span>
<span class="p_add">+				goto cleanup;</span>
<span class="p_add">+			}</span>
<span class="p_add">+		}</span>
<span class="p_add">+	}</span>
<span class="p_add">+	if ((osb-&gt;s_mount_opt &amp; OCFS2_MOUNT_POSIX_ACL) &amp;&amp; acl) {</span>
<span class="p_add">+		if (S_ISDIR(inode-&gt;i_mode)) {</span>
<span class="p_add">+			ret = ocfs2_set_acl(handle, inode, di_bh,</span>
<span class="p_add">+					    ACL_TYPE_DEFAULT, acl,</span>
<span class="p_add">+					    meta_ac, data_ac);</span>
<span class="p_add">+			if (ret)</span>
<span class="p_add">+				goto cleanup;</span>
<span class="p_add">+		}</span>
<span class="p_add">+		mode = inode-&gt;i_mode;</span>
<span class="p_add">+		ret = __posix_acl_create(&amp;acl, GFP_NOFS, &amp;mode);</span>
<span class="p_add">+		if (ret &lt; 0)</span>
<span class="p_add">+			return ret;</span>
<span class="p_add">+</span>
<span class="p_add">+		ret2 = ocfs2_acl_set_mode(inode, di_bh, handle, mode);</span>
<span class="p_add">+		if (ret2) {</span>
<span class="p_add">+			mlog_errno(ret2);</span>
<span class="p_add">+			ret = ret2;</span>
<span class="p_add">+			goto cleanup;</span>
<span class="p_add">+		}</span>
<span class="p_add">+		if (ret &gt; 0) {</span>
<span class="p_add">+			ret = ocfs2_set_acl(handle, inode,</span>
<span class="p_add">+					    di_bh, ACL_TYPE_ACCESS,</span>
<span class="p_add">+					    acl, meta_ac, data_ac);</span>
<span class="p_add">+		}</span>
<span class="p_add">+	}</span>
<span class="p_add">+cleanup:</span>
<span class="p_add">+	posix_acl_release(acl);</span>
<span class="p_add">+	return ret;</span>
<span class="p_add">+}</span>
<span class="p_header">diff --git a/fs/ocfs2/acl.h b/fs/ocfs2/acl.h</span>
<span class="p_header">index 3fce68d08625..1c7203d1d6eb 100644</span>
<span class="p_header">--- a/fs/ocfs2/acl.h</span>
<span class="p_header">+++ b/fs/ocfs2/acl.h</span>
<span class="p_chunk">@@ -35,5 +35,9 @@</span> <span class="p_context"> int ocfs2_set_acl(handle_t *handle,</span>
 			 struct posix_acl *acl,
 			 struct ocfs2_alloc_context *meta_ac,
 			 struct ocfs2_alloc_context *data_ac);
<span class="p_add">+extern int ocfs2_init_acl(handle_t *, struct inode *, struct inode *,</span>
<span class="p_add">+			  struct buffer_head *, struct buffer_head *,</span>
<span class="p_add">+			  struct ocfs2_alloc_context *,</span>
<span class="p_add">+			  struct ocfs2_alloc_context *);</span>
 
 #endif /* OCFS2_ACL_H */
<span class="p_header">diff --git a/fs/ocfs2/namei.c b/fs/ocfs2/namei.c</span>
<span class="p_header">index e2f3a6c5224f..a9ef9ec08c23 100644</span>
<span class="p_header">--- a/fs/ocfs2/namei.c</span>
<span class="p_header">+++ b/fs/ocfs2/namei.c</span>
<span class="p_chunk">@@ -253,7 +253,6 @@</span> <span class="p_context"> static int ocfs2_mknod(struct inode *dir,</span>
 	struct ocfs2_dir_lookup_result lookup = { NULL, };
 	sigset_t oldset;
 	int did_block_signals = 0;
<span class="p_del">-	struct posix_acl *default_acl = NULL, *acl = NULL;</span>
 	struct ocfs2_dentry_lock *dl = NULL;
 
 	trace_ocfs2_mknod(dir, dentry, dentry-&gt;d_name.len, dentry-&gt;d_name.name,
<span class="p_chunk">@@ -356,12 +355,6 @@</span> <span class="p_context"> static int ocfs2_mknod(struct inode *dir,</span>
 		goto leave;
 	}
 
<span class="p_del">-	status = posix_acl_create(dir, &amp;inode-&gt;i_mode, &amp;default_acl, &amp;acl);</span>
<span class="p_del">-	if (status) {</span>
<span class="p_del">-		mlog_errno(status);</span>
<span class="p_del">-		goto leave;</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
 	handle = ocfs2_start_trans(osb, ocfs2_mknod_credits(osb-&gt;sb,
 							    S_ISDIR(mode),
 							    xattr_credits));
<span class="p_chunk">@@ -410,16 +403,8 @@</span> <span class="p_context"> static int ocfs2_mknod(struct inode *dir,</span>
 		inc_nlink(dir);
 	}
 
<span class="p_del">-	if (default_acl) {</span>
<span class="p_del">-		status = ocfs2_set_acl(handle, inode, new_fe_bh,</span>
<span class="p_del">-				       ACL_TYPE_DEFAULT, default_acl,</span>
<span class="p_del">-				       meta_ac, data_ac);</span>
<span class="p_del">-	}</span>
<span class="p_del">-	if (!status &amp;&amp; acl) {</span>
<span class="p_del">-		status = ocfs2_set_acl(handle, inode, new_fe_bh,</span>
<span class="p_del">-				       ACL_TYPE_ACCESS, acl,</span>
<span class="p_del">-				       meta_ac, data_ac);</span>
<span class="p_del">-	}</span>
<span class="p_add">+	status = ocfs2_init_acl(handle, inode, dir, new_fe_bh, parent_fe_bh,</span>
<span class="p_add">+			 meta_ac, data_ac);</span>
 
 	if (status &lt; 0) {
 		mlog_errno(status);
<span class="p_chunk">@@ -461,10 +446,6 @@</span> <span class="p_context"> static int ocfs2_mknod(struct inode *dir,</span>
 	d_instantiate(dentry, inode);
 	status = 0;
 leave:
<span class="p_del">-	if (default_acl)</span>
<span class="p_del">-		posix_acl_release(default_acl);</span>
<span class="p_del">-	if (acl)</span>
<span class="p_del">-		posix_acl_release(acl);</span>
 	if (status &lt; 0 &amp;&amp; did_quota_inode)
 		dquot_free_inode(inode);
 	if (handle)
<span class="p_header">diff --git a/fs/ocfs2/refcounttree.c b/fs/ocfs2/refcounttree.c</span>
<span class="p_header">index 636aab69ead5..017aa195a278 100644</span>
<span class="p_header">--- a/fs/ocfs2/refcounttree.c</span>
<span class="p_header">+++ b/fs/ocfs2/refcounttree.c</span>
<span class="p_chunk">@@ -4268,20 +4268,12 @@</span> <span class="p_context"> static int ocfs2_reflink(struct dentry *old_dentry, struct inode *dir,</span>
 	struct inode *inode = old_dentry-&gt;d_inode;
 	struct buffer_head *old_bh = NULL;
 	struct inode *new_orphan_inode = NULL;
<span class="p_del">-	struct posix_acl *default_acl, *acl;</span>
<span class="p_del">-	umode_t mode;</span>
 
 	if (!ocfs2_refcount_tree(OCFS2_SB(inode-&gt;i_sb)))
 		return -EOPNOTSUPP;
 
<span class="p_del">-	mode = inode-&gt;i_mode;</span>
<span class="p_del">-	error = posix_acl_create(dir, &amp;mode, &amp;default_acl, &amp;acl);</span>
<span class="p_del">-	if (error) {</span>
<span class="p_del">-		mlog_errno(error);</span>
<span class="p_del">-		goto out;</span>
<span class="p_del">-	}</span>
 
<span class="p_del">-	error = ocfs2_create_inode_in_orphan(dir, mode,</span>
<span class="p_add">+	error = ocfs2_create_inode_in_orphan(dir, inode-&gt;i_mode,</span>
 					     &amp;new_orphan_inode);
 	if (error) {
 		mlog_errno(error);
<span class="p_chunk">@@ -4320,16 +4312,11 @@</span> <span class="p_context"> static int ocfs2_reflink(struct dentry *old_dentry, struct inode *dir,</span>
 	/* If the security isn&#39;t preserved, we need to re-initialize them. */
 	if (!preserve) {
 		error = ocfs2_init_security_and_acl(dir, new_orphan_inode,
<span class="p_del">-						    &amp;new_dentry-&gt;d_name,</span>
<span class="p_del">-						    default_acl, acl);</span>
<span class="p_add">+						    &amp;new_dentry-&gt;d_name);</span>
 		if (error)
 			mlog_errno(error);
 	}
 out:
<span class="p_del">-	if (default_acl)</span>
<span class="p_del">-		posix_acl_release(default_acl);</span>
<span class="p_del">-	if (acl)</span>
<span class="p_del">-		posix_acl_release(acl);</span>
 	if (!error) {
 		error = ocfs2_mv_orphaned_inode_to_new(dir, new_orphan_inode,
 						       new_dentry);
<span class="p_header">diff --git a/fs/ocfs2/xattr.c b/fs/ocfs2/xattr.c</span>
<span class="p_header">index 016f01df3825..c237008c010d 100644</span>
<span class="p_header">--- a/fs/ocfs2/xattr.c</span>
<span class="p_header">+++ b/fs/ocfs2/xattr.c</span>
<span class="p_chunk">@@ -7207,12 +7207,10 @@</span> <span class="p_context"> out:</span>
  */
 int ocfs2_init_security_and_acl(struct inode *dir,
 				struct inode *inode,
<span class="p_del">-				const struct qstr *qstr,</span>
<span class="p_del">-				struct posix_acl *default_acl,</span>
<span class="p_del">-				struct posix_acl *acl)</span>
<span class="p_add">+				const struct qstr *qstr)</span>
 {
<span class="p_del">-	struct buffer_head *dir_bh = NULL;</span>
 	int ret = 0;
<span class="p_add">+	struct buffer_head *dir_bh = NULL;</span>
 
 	ret = ocfs2_init_security_get(inode, dir, qstr, NULL);
 	if (ret) {
<span class="p_chunk">@@ -7225,11 +7223,9 @@</span> <span class="p_context"> int ocfs2_init_security_and_acl(struct inode *dir,</span>
 		mlog_errno(ret);
 		goto leave;
 	}
<span class="p_del">-</span>
<span class="p_del">-	if (!ret &amp;&amp; default_acl)</span>
<span class="p_del">-		ret = ocfs2_iop_set_acl(inode, default_acl, ACL_TYPE_DEFAULT);</span>
<span class="p_del">-	if (!ret &amp;&amp; acl)</span>
<span class="p_del">-		ret = ocfs2_iop_set_acl(inode, acl, ACL_TYPE_ACCESS);</span>
<span class="p_add">+	ret = ocfs2_init_acl(NULL, inode, dir, NULL, dir_bh, NULL, NULL);</span>
<span class="p_add">+	if (ret)</span>
<span class="p_add">+		mlog_errno(ret);</span>
 
 	ocfs2_inode_unlock(dir, 0);
 	brelse(dir_bh);
<span class="p_header">diff --git a/fs/ocfs2/xattr.h b/fs/ocfs2/xattr.h</span>
<span class="p_header">index f10d5b93c366..1633cc15ea1f 100644</span>
<span class="p_header">--- a/fs/ocfs2/xattr.h</span>
<span class="p_header">+++ b/fs/ocfs2/xattr.h</span>
<span class="p_chunk">@@ -94,7 +94,5 @@</span> <span class="p_context"> int ocfs2_reflink_xattrs(struct inode *old_inode,</span>
 			 bool preserve_security);
 int ocfs2_init_security_and_acl(struct inode *dir,
 				struct inode *inode,
<span class="p_del">-				const struct qstr *qstr,</span>
<span class="p_del">-				struct posix_acl *default_acl,</span>
<span class="p_del">-				struct posix_acl *acl);</span>
<span class="p_add">+				const struct qstr *qstr);</span>
 #endif /* OCFS2_XATTR_H */
<span class="p_header">diff --git a/fs/pnode.c b/fs/pnode.c</span>
<span class="p_header">index aae331a5d03b..18e56fc4a88c 100644</span>
<span class="p_header">--- a/fs/pnode.c</span>
<span class="p_header">+++ b/fs/pnode.c</span>
<span class="p_chunk">@@ -198,10 +198,15 @@</span> <span class="p_context"> static struct mount *next_group(struct mount *m, struct mount *origin)</span>
 
 /* all accesses are serialized by namespace_sem */
 static struct user_namespace *user_ns;
<span class="p_del">-static struct mount *last_dest, *last_source, *dest_master;</span>
<span class="p_add">+static struct mount *last_dest, *first_source, *last_source, *dest_master;</span>
 static struct mountpoint *mp;
 static struct hlist_head *list;
 
<span class="p_add">+static inline bool peers(struct mount *m1, struct mount *m2)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return m1-&gt;mnt_group_id == m2-&gt;mnt_group_id &amp;&amp; m1-&gt;mnt_group_id;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static int propagate_one(struct mount *m)
 {
 	struct mount *child;
<span class="p_chunk">@@ -212,24 +217,26 @@</span> <span class="p_context"> static int propagate_one(struct mount *m)</span>
 	/* skip if mountpoint isn&#39;t covered by it */
 	if (!is_subdir(mp-&gt;m_dentry, m-&gt;mnt.mnt_root))
 		return 0;
<span class="p_del">-	if (m-&gt;mnt_group_id == last_dest-&gt;mnt_group_id) {</span>
<span class="p_add">+	if (peers(m, last_dest)) {</span>
 		type = CL_MAKE_SHARED;
 	} else {
 		struct mount *n, *p;
<span class="p_add">+		bool done;</span>
 		for (n = m; ; n = p) {
 			p = n-&gt;mnt_master;
<span class="p_del">-			if (p == dest_master || IS_MNT_MARKED(p)) {</span>
<span class="p_del">-				while (last_dest-&gt;mnt_master != p) {</span>
<span class="p_del">-					last_source = last_source-&gt;mnt_master;</span>
<span class="p_del">-					last_dest = last_source-&gt;mnt_parent;</span>
<span class="p_del">-				}</span>
<span class="p_del">-				if (n-&gt;mnt_group_id != last_dest-&gt;mnt_group_id) {</span>
<span class="p_del">-					last_source = last_source-&gt;mnt_master;</span>
<span class="p_del">-					last_dest = last_source-&gt;mnt_parent;</span>
<span class="p_del">-				}</span>
<span class="p_add">+			if (p == dest_master || IS_MNT_MARKED(p))</span>
 				break;
<span class="p_del">-			}</span>
 		}
<span class="p_add">+		do {</span>
<span class="p_add">+			struct mount *parent = last_source-&gt;mnt_parent;</span>
<span class="p_add">+			if (last_source == first_source)</span>
<span class="p_add">+				break;</span>
<span class="p_add">+			done = parent-&gt;mnt_master == p;</span>
<span class="p_add">+			if (done &amp;&amp; peers(n, parent))</span>
<span class="p_add">+				break;</span>
<span class="p_add">+			last_source = last_source-&gt;mnt_master;</span>
<span class="p_add">+		} while (!done);</span>
<span class="p_add">+</span>
 		type = CL_SLAVE;
 		/* beginning of peer group among the slaves? */
 		if (IS_MNT_SHARED(m))
<span class="p_chunk">@@ -280,6 +287,7 @@</span> <span class="p_context"> int propagate_mnt(struct mount *dest_mnt, struct mountpoint *dest_mp,</span>
 	 */
 	user_ns = current-&gt;nsproxy-&gt;mnt_ns-&gt;user_ns;
 	last_dest = dest_mnt;
<span class="p_add">+	first_source = source_mnt;</span>
 	last_source = source_mnt;
 	mp = dest_mp;
 	list = tree_list;
<span class="p_header">diff --git a/fs/proc/base.c b/fs/proc/base.c</span>
<span class="p_header">index 2d038a7e16a1..0897f5cb4957 100644</span>
<span class="p_header">--- a/fs/proc/base.c</span>
<span class="p_header">+++ b/fs/proc/base.c</span>
<span class="p_chunk">@@ -809,7 +809,8 @@</span> <span class="p_context"> static ssize_t environ_read(struct file *file, char __user *buf,</span>
 	int ret = 0;
 	struct mm_struct *mm = file-&gt;private_data;
 
<span class="p_del">-	if (!mm)</span>
<span class="p_add">+	/* Ensure the process spawned far enough to have an environment. */</span>
<span class="p_add">+	if (!mm || !mm-&gt;env_end)</span>
 		return 0;
 
 	page = (char *)__get_free_page(GFP_TEMPORARY);
<span class="p_header">diff --git a/fs/xfs/xfs_bmap_util.c b/fs/xfs/xfs_bmap_util.c</span>
<span class="p_header">index 64731ef3324d..3d807ef4f821 100644</span>
<span class="p_header">--- a/fs/xfs/xfs_bmap_util.c</span>
<span class="p_header">+++ b/fs/xfs/xfs_bmap_util.c</span>
<span class="p_chunk">@@ -1633,6 +1633,7 @@</span> <span class="p_context"> xfs_swap_extents(</span>
 	int		aforkblks = 0;
 	int		taforkblks = 0;
 	__uint64_t	tmp;
<span class="p_add">+	int		lock_flags;</span>
 
 	tempifp = kmem_alloc(sizeof(xfs_ifork_t), KM_MAYFAIL);
 	if (!tempifp) {
<span class="p_chunk">@@ -1641,13 +1642,14 @@</span> <span class="p_context"> xfs_swap_extents(</span>
 	}
 
 	/*
<span class="p_del">-	 * we have to do two separate lock calls here to keep lockdep</span>
<span class="p_del">-	 * happy. If we try to get all the locks in one call, lock will</span>
<span class="p_del">-	 * report false positives when we drop the ILOCK and regain them</span>
<span class="p_del">-	 * below.</span>
<span class="p_add">+	 * Lock the inodes against other IO, page faults and truncate to</span>
<span class="p_add">+	 * begin with.  Then we can ensure the inodes are flushed and have no</span>
<span class="p_add">+	 * page cache safely. Once we have done this we can take the ilocks and</span>
<span class="p_add">+	 * do the rest of the checks.</span>
 	 */
<span class="p_add">+	lock_flags = XFS_IOLOCK_EXCL | XFS_MMAPLOCK_EXCL;</span>
 	xfs_lock_two_inodes(ip, tip, XFS_IOLOCK_EXCL);
<span class="p_del">-	xfs_lock_two_inodes(ip, tip, XFS_ILOCK_EXCL);</span>
<span class="p_add">+	xfs_lock_two_inodes(ip, tip, XFS_MMAPLOCK_EXCL);</span>
 
 	/* Verify that both files have the same format */
 	if ((ip-&gt;i_d.di_mode &amp; S_IFMT) != (tip-&gt;i_d.di_mode &amp; S_IFMT)) {
<span class="p_chunk">@@ -1666,6 +1668,9 @@</span> <span class="p_context"> xfs_swap_extents(</span>
 		goto out_unlock;
 	truncate_pagecache_range(VFS_I(tip), 0, -1);
 
<span class="p_add">+	xfs_lock_two_inodes(ip, tip, XFS_ILOCK_EXCL);</span>
<span class="p_add">+	lock_flags |= XFS_ILOCK_EXCL;</span>
<span class="p_add">+</span>
 	/* Verify O_DIRECT for ftmp */
 	if (VN_CACHED(VFS_I(tip)) != 0) {
 		error = XFS_ERROR(EINVAL);
<span class="p_chunk">@@ -1707,19 +1712,9 @@</span> <span class="p_context"> xfs_swap_extents(</span>
 		goto out_unlock;
 	}
 
<span class="p_del">-	/* We need to fail if the file is memory mapped.  Once we have tossed</span>
<span class="p_del">-	 * all existing pages, the page fault will have no option</span>
<span class="p_del">-	 * but to go to the filesystem for pages. By making the page fault call</span>
<span class="p_del">-	 * vop_read (or write in the case of autogrow) they block on the iolock</span>
<span class="p_del">-	 * until we have switched the extents.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	if (VN_MAPPED(VFS_I(ip))) {</span>
<span class="p_del">-		error = XFS_ERROR(EBUSY);</span>
<span class="p_del">-		goto out_unlock;</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
 	xfs_iunlock(ip, XFS_ILOCK_EXCL);
 	xfs_iunlock(tip, XFS_ILOCK_EXCL);
<span class="p_add">+	lock_flags &amp;= ~XFS_ILOCK_EXCL;</span>
 
 	/*
 	 * There is a race condition here since we gave up the
<span class="p_chunk">@@ -1732,13 +1727,18 @@</span> <span class="p_context"> xfs_swap_extents(</span>
 
 	tp = xfs_trans_alloc(mp, XFS_TRANS_SWAPEXT);
 	error = xfs_trans_reserve(tp, &amp;M_RES(mp)-&gt;tr_ichange, 0, 0);
<span class="p_del">-	if (error) {</span>
<span class="p_del">-		xfs_iunlock(ip,  XFS_IOLOCK_EXCL);</span>
<span class="p_del">-		xfs_iunlock(tip, XFS_IOLOCK_EXCL);</span>
<span class="p_del">-		xfs_trans_cancel(tp, 0);</span>
<span class="p_del">-		goto out;</span>
<span class="p_del">-	}</span>
<span class="p_add">+	if (error)</span>
<span class="p_add">+		goto out_trans_cancel;</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Lock and join the inodes to the tansaction so that transaction commit</span>
<span class="p_add">+	 * or cancel will unlock the inodes from this point onwards.</span>
<span class="p_add">+	 */</span>
 	xfs_lock_two_inodes(ip, tip, XFS_ILOCK_EXCL);
<span class="p_add">+	lock_flags |= XFS_ILOCK_EXCL;</span>
<span class="p_add">+	xfs_trans_ijoin(tp, ip, lock_flags);</span>
<span class="p_add">+	xfs_trans_ijoin(tp, tip, lock_flags);</span>
<span class="p_add">+</span>
 
 	/*
 	 * Count the number of extended attribute blocks
<span class="p_chunk">@@ -1757,9 +1757,6 @@</span> <span class="p_context"> xfs_swap_extents(</span>
 			goto out_trans_cancel;
 	}
 
<span class="p_del">-	xfs_trans_ijoin(tp, ip, XFS_ILOCK_EXCL | XFS_IOLOCK_EXCL);</span>
<span class="p_del">-	xfs_trans_ijoin(tp, tip, XFS_ILOCK_EXCL | XFS_IOLOCK_EXCL);</span>
<span class="p_del">-</span>
 	/*
 	 * Before we&#39;ve swapped the forks, lets set the owners of the forks
 	 * appropriately. We have to do this as we are demand paging the btree
<span class="p_chunk">@@ -1887,11 +1884,11 @@</span> <span class="p_context"> out:</span>
 	return error;
 
 out_unlock:
<span class="p_del">-	xfs_iunlock(ip,  XFS_ILOCK_EXCL | XFS_IOLOCK_EXCL);</span>
<span class="p_del">-	xfs_iunlock(tip, XFS_ILOCK_EXCL | XFS_IOLOCK_EXCL);</span>
<span class="p_add">+	xfs_iunlock(ip, lock_flags);</span>
<span class="p_add">+	xfs_iunlock(tip, lock_flags);</span>
 	goto out;
 
 out_trans_cancel:
 	xfs_trans_cancel(tp, 0);
<span class="p_del">-	goto out_unlock;</span>
<span class="p_add">+	goto out;</span>
 }
<span class="p_header">diff --git a/fs/xfs/xfs_file.c b/fs/xfs/xfs_file.c</span>
<span class="p_header">index c768860e22ab..d2f4cb598b46 100644</span>
<span class="p_header">--- a/fs/xfs/xfs_file.c</span>
<span class="p_header">+++ b/fs/xfs/xfs_file.c</span>
<span class="p_chunk">@@ -786,7 +786,7 @@</span> <span class="p_context"> xfs_file_fallocate(</span>
 		     FALLOC_FL_COLLAPSE_RANGE | FALLOC_FL_ZERO_RANGE))
 		return -EOPNOTSUPP;
 
<span class="p_del">-	xfs_ilock(ip, XFS_IOLOCK_EXCL);</span>
<span class="p_add">+	xfs_ilock(ip, XFS_IOLOCK_EXCL | XFS_MMAPLOCK_EXCL);</span>
 	if (mode &amp; FALLOC_FL_PUNCH_HOLE) {
 		error = xfs_free_file_space(ip, offset, len);
 		if (error)
<span class="p_chunk">@@ -866,7 +866,7 @@</span> <span class="p_context"> xfs_file_fallocate(</span>
 	}
 
 out_unlock:
<span class="p_del">-	xfs_iunlock(ip, XFS_IOLOCK_EXCL);</span>
<span class="p_add">+	xfs_iunlock(ip, XFS_IOLOCK_EXCL | XFS_MMAPLOCK_EXCL);</span>
 	return -error;
 }
 
<span class="p_chunk">@@ -957,20 +957,6 @@</span> <span class="p_context"> xfs_file_mmap(</span>
 }
 
 /*
<span class="p_del">- * mmap()d file has taken write protection fault and is being made</span>
<span class="p_del">- * writable. We can set the page state up correctly for a writable</span>
<span class="p_del">- * page, which means we can do correct delalloc accounting (ENOSPC</span>
<span class="p_del">- * checking!) and unwritten extent mapping.</span>
<span class="p_del">- */</span>
<span class="p_del">-STATIC int</span>
<span class="p_del">-xfs_vm_page_mkwrite(</span>
<span class="p_del">-	struct vm_area_struct	*vma,</span>
<span class="p_del">-	struct vm_fault		*vmf)</span>
<span class="p_del">-{</span>
<span class="p_del">-	return block_page_mkwrite(vma, vmf, xfs_get_blocks);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-/*</span>
  * This type is designed to indicate the type of offset we would like
  * to search from page cache for either xfs_seek_data() or xfs_seek_hole().
  */
<span class="p_chunk">@@ -1417,6 +1403,60 @@</span> <span class="p_context"> xfs_file_llseek(</span>
 	}
 }
 
<span class="p_add">+/*</span>
<span class="p_add">+ * Locking for serialisation of IO during page faults. This results in a lock</span>
<span class="p_add">+ * ordering of:</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * mmap_sem (MM)</span>
<span class="p_add">+ *   i_mmap_lock (XFS - truncate serialisation)</span>
<span class="p_add">+ *     page_lock (MM)</span>
<span class="p_add">+ *       i_lock (XFS - extent map serialisation)</span>
<span class="p_add">+ */</span>
<span class="p_add">+STATIC int</span>
<span class="p_add">+xfs_filemap_fault(</span>
<span class="p_add">+	struct vm_area_struct	*vma,</span>
<span class="p_add">+	struct vm_fault		*vmf)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct xfs_inode	*ip = XFS_I(vma-&gt;vm_file-&gt;f_mapping-&gt;host);</span>
<span class="p_add">+	int			error;</span>
<span class="p_add">+</span>
<span class="p_add">+	trace_xfs_filemap_fault(ip);</span>
<span class="p_add">+</span>
<span class="p_add">+	xfs_ilock(ip, XFS_MMAPLOCK_SHARED);</span>
<span class="p_add">+	error = filemap_fault(vma, vmf);</span>
<span class="p_add">+	xfs_iunlock(ip, XFS_MMAPLOCK_SHARED);</span>
<span class="p_add">+</span>
<span class="p_add">+	return error;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+/*</span>
<span class="p_add">+ * mmap()d file has taken write protection fault and is being made writable. We</span>
<span class="p_add">+ * can set the page state up correctly for a writable page, which means we can</span>
<span class="p_add">+ * do correct delalloc accounting (ENOSPC checking!) and unwritten extent</span>
<span class="p_add">+ * mapping.</span>
<span class="p_add">+ */</span>
<span class="p_add">+STATIC int</span>
<span class="p_add">+xfs_filemap_page_mkwrite(</span>
<span class="p_add">+	struct vm_area_struct	*vma,</span>
<span class="p_add">+	struct vm_fault		*vmf)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct xfs_inode	*ip = XFS_I(vma-&gt;vm_file-&gt;f_mapping-&gt;host);</span>
<span class="p_add">+	int			ret;</span>
<span class="p_add">+</span>
<span class="p_add">+	trace_xfs_filemap_page_mkwrite(ip);</span>
<span class="p_add">+</span>
<span class="p_add">+	sb_start_pagefault(VFS_I(ip)-&gt;i_sb);</span>
<span class="p_add">+	file_update_time(vma-&gt;vm_file);</span>
<span class="p_add">+	xfs_ilock(ip, XFS_MMAPLOCK_SHARED);</span>
<span class="p_add">+</span>
<span class="p_add">+	ret = __block_page_mkwrite(vma, vmf, xfs_get_blocks);</span>
<span class="p_add">+</span>
<span class="p_add">+	xfs_iunlock(ip, XFS_MMAPLOCK_SHARED);</span>
<span class="p_add">+	sb_end_pagefault(VFS_I(ip)-&gt;i_sb);</span>
<span class="p_add">+</span>
<span class="p_add">+	return block_page_mkwrite_return(ret);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 const struct file_operations xfs_file_operations = {
 	.llseek		= xfs_file_llseek,
 	.read		= new_sync_read,
<span class="p_chunk">@@ -1449,8 +1489,8 @@</span> <span class="p_context"> const struct file_operations xfs_dir_file_operations = {</span>
 };
 
 static const struct vm_operations_struct xfs_file_vm_ops = {
<span class="p_del">-	.fault		= filemap_fault,</span>
<span class="p_add">+	.fault		= xfs_filemap_fault,</span>
 	.map_pages	= filemap_map_pages,
<span class="p_del">-	.page_mkwrite	= xfs_vm_page_mkwrite,</span>
<span class="p_add">+	.page_mkwrite	= xfs_filemap_page_mkwrite,</span>
 	.remap_pages	= generic_file_remap_pages,
 };
<span class="p_header">diff --git a/fs/xfs/xfs_inode.c b/fs/xfs/xfs_inode.c</span>
<span class="p_header">index 97f066419ee1..634dbe50c292 100644</span>
<span class="p_header">--- a/fs/xfs/xfs_inode.c</span>
<span class="p_header">+++ b/fs/xfs/xfs_inode.c</span>
<span class="p_chunk">@@ -119,24 +119,34 @@</span> <span class="p_context"> xfs_ilock_attr_map_shared(</span>
 }
 
 /*
<span class="p_del">- * The xfs inode contains 2 locks: a multi-reader lock called the</span>
<span class="p_del">- * i_iolock and a multi-reader lock called the i_lock.  This routine</span>
<span class="p_del">- * allows either or both of the locks to be obtained.</span>
<span class="p_add">+ * The xfs inode contains 3 multi-reader locks: the i_iolock the i_mmap_lock and</span>
<span class="p_add">+ * the i_lock.  This routine allows various combinations of the locks to be</span>
<span class="p_add">+ * obtained.</span>
  *
<span class="p_del">- * The 2 locks should always be ordered so that the IO lock is</span>
<span class="p_del">- * obtained first in order to prevent deadlock.</span>
<span class="p_add">+ * The 3 locks should always be ordered so that the IO lock is obtained first,</span>
<span class="p_add">+ * the mmap lock second and the ilock last in order to prevent deadlock.</span>
  *
<span class="p_del">- * ip -- the inode being locked</span>
<span class="p_del">- * lock_flags -- this parameter indicates the inode&#39;s locks</span>
<span class="p_del">- *       to be locked.  It can be:</span>
<span class="p_del">- *		XFS_IOLOCK_SHARED,</span>
<span class="p_del">- *		XFS_IOLOCK_EXCL,</span>
<span class="p_del">- *		XFS_ILOCK_SHARED,</span>
<span class="p_del">- *		XFS_ILOCK_EXCL,</span>
<span class="p_del">- *		XFS_IOLOCK_SHARED | XFS_ILOCK_SHARED,</span>
<span class="p_del">- *		XFS_IOLOCK_SHARED | XFS_ILOCK_EXCL,</span>
<span class="p_del">- *		XFS_IOLOCK_EXCL | XFS_ILOCK_SHARED,</span>
<span class="p_del">- *		XFS_IOLOCK_EXCL | XFS_ILOCK_EXCL</span>
<span class="p_add">+ * Basic locking order:</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * i_iolock -&gt; i_mmap_lock -&gt; page_lock -&gt; i_ilock</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * mmap_sem locking order:</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * i_iolock -&gt; page lock -&gt; mmap_sem</span>
<span class="p_add">+ * mmap_sem -&gt; i_mmap_lock -&gt; page_lock</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * The difference in mmap_sem locking order mean that we cannot hold the</span>
<span class="p_add">+ * i_mmap_lock over syscall based read(2)/write(2) based IO. These IO paths can</span>
<span class="p_add">+ * fault in pages during copy in/out (for buffered IO) or require the mmap_sem</span>
<span class="p_add">+ * in get_user_pages() to map the user pages into the kernel address space for</span>
<span class="p_add">+ * direct IO. Similarly the i_iolock cannot be taken inside a page fault because</span>
<span class="p_add">+ * page faults already hold the mmap_sem.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * Hence to serialise fully against both syscall and mmap based IO, we need to</span>
<span class="p_add">+ * take both the i_iolock and the i_mmap_lock. These locks should *only* be both</span>
<span class="p_add">+ * taken in places where we need to invalidate the page cache in a race</span>
<span class="p_add">+ * free manner (e.g. truncate, hole punch and other extent manipulation</span>
<span class="p_add">+ * functions).</span>
  */
 void
 xfs_ilock(
<span class="p_chunk">@@ -152,6 +162,8 @@</span> <span class="p_context"> xfs_ilock(</span>
 	 */
 	ASSERT((lock_flags &amp; (XFS_IOLOCK_SHARED | XFS_IOLOCK_EXCL)) !=
 	       (XFS_IOLOCK_SHARED | XFS_IOLOCK_EXCL));
<span class="p_add">+	ASSERT((lock_flags &amp; (XFS_MMAPLOCK_SHARED | XFS_MMAPLOCK_EXCL)) !=</span>
<span class="p_add">+	       (XFS_MMAPLOCK_SHARED | XFS_MMAPLOCK_EXCL));</span>
 	ASSERT((lock_flags &amp; (XFS_ILOCK_SHARED | XFS_ILOCK_EXCL)) !=
 	       (XFS_ILOCK_SHARED | XFS_ILOCK_EXCL));
 	ASSERT((lock_flags &amp; ~(XFS_LOCK_MASK | XFS_LOCK_DEP_MASK)) == 0);
<span class="p_chunk">@@ -161,6 +173,11 @@</span> <span class="p_context"> xfs_ilock(</span>
 	else if (lock_flags &amp; XFS_IOLOCK_SHARED)
 		mraccess_nested(&amp;ip-&gt;i_iolock, XFS_IOLOCK_DEP(lock_flags));
 
<span class="p_add">+	if (lock_flags &amp; XFS_MMAPLOCK_EXCL)</span>
<span class="p_add">+		mrupdate_nested(&amp;ip-&gt;i_mmaplock, XFS_MMAPLOCK_DEP(lock_flags));</span>
<span class="p_add">+	else if (lock_flags &amp; XFS_MMAPLOCK_SHARED)</span>
<span class="p_add">+		mraccess_nested(&amp;ip-&gt;i_mmaplock, XFS_MMAPLOCK_DEP(lock_flags));</span>
<span class="p_add">+</span>
 	if (lock_flags &amp; XFS_ILOCK_EXCL)
 		mrupdate_nested(&amp;ip-&gt;i_lock, XFS_ILOCK_DEP(lock_flags));
 	else if (lock_flags &amp; XFS_ILOCK_SHARED)
<span class="p_chunk">@@ -193,6 +210,8 @@</span> <span class="p_context"> xfs_ilock_nowait(</span>
 	 */
 	ASSERT((lock_flags &amp; (XFS_IOLOCK_SHARED | XFS_IOLOCK_EXCL)) !=
 	       (XFS_IOLOCK_SHARED | XFS_IOLOCK_EXCL));
<span class="p_add">+	ASSERT((lock_flags &amp; (XFS_MMAPLOCK_SHARED | XFS_MMAPLOCK_EXCL)) !=</span>
<span class="p_add">+	       (XFS_MMAPLOCK_SHARED | XFS_MMAPLOCK_EXCL));</span>
 	ASSERT((lock_flags &amp; (XFS_ILOCK_SHARED | XFS_ILOCK_EXCL)) !=
 	       (XFS_ILOCK_SHARED | XFS_ILOCK_EXCL));
 	ASSERT((lock_flags &amp; ~(XFS_LOCK_MASK | XFS_LOCK_DEP_MASK)) == 0);
<span class="p_chunk">@@ -204,21 +223,35 @@</span> <span class="p_context"> xfs_ilock_nowait(</span>
 		if (!mrtryaccess(&amp;ip-&gt;i_iolock))
 			goto out;
 	}
<span class="p_add">+</span>
<span class="p_add">+	if (lock_flags &amp; XFS_MMAPLOCK_EXCL) {</span>
<span class="p_add">+		if (!mrtryupdate(&amp;ip-&gt;i_mmaplock))</span>
<span class="p_add">+			goto out_undo_iolock;</span>
<span class="p_add">+	} else if (lock_flags &amp; XFS_MMAPLOCK_SHARED) {</span>
<span class="p_add">+		if (!mrtryaccess(&amp;ip-&gt;i_mmaplock))</span>
<span class="p_add">+			goto out_undo_iolock;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
 	if (lock_flags &amp; XFS_ILOCK_EXCL) {
 		if (!mrtryupdate(&amp;ip-&gt;i_lock))
<span class="p_del">-			goto out_undo_iolock;</span>
<span class="p_add">+			goto out_undo_mmaplock;</span>
 	} else if (lock_flags &amp; XFS_ILOCK_SHARED) {
 		if (!mrtryaccess(&amp;ip-&gt;i_lock))
<span class="p_del">-			goto out_undo_iolock;</span>
<span class="p_add">+			goto out_undo_mmaplock;</span>
 	}
 	return 1;
 
<span class="p_del">- out_undo_iolock:</span>
<span class="p_add">+out_undo_mmaplock:</span>
<span class="p_add">+	if (lock_flags &amp; XFS_MMAPLOCK_EXCL)</span>
<span class="p_add">+		mrunlock_excl(&amp;ip-&gt;i_mmaplock);</span>
<span class="p_add">+	else if (lock_flags &amp; XFS_MMAPLOCK_SHARED)</span>
<span class="p_add">+		mrunlock_shared(&amp;ip-&gt;i_mmaplock);</span>
<span class="p_add">+out_undo_iolock:</span>
 	if (lock_flags &amp; XFS_IOLOCK_EXCL)
 		mrunlock_excl(&amp;ip-&gt;i_iolock);
 	else if (lock_flags &amp; XFS_IOLOCK_SHARED)
 		mrunlock_shared(&amp;ip-&gt;i_iolock);
<span class="p_del">- out:</span>
<span class="p_add">+out:</span>
 	return 0;
 }
 
<span class="p_chunk">@@ -246,6 +279,8 @@</span> <span class="p_context"> xfs_iunlock(</span>
 	 */
 	ASSERT((lock_flags &amp; (XFS_IOLOCK_SHARED | XFS_IOLOCK_EXCL)) !=
 	       (XFS_IOLOCK_SHARED | XFS_IOLOCK_EXCL));
<span class="p_add">+	ASSERT((lock_flags &amp; (XFS_MMAPLOCK_SHARED | XFS_MMAPLOCK_EXCL)) !=</span>
<span class="p_add">+	       (XFS_MMAPLOCK_SHARED | XFS_MMAPLOCK_EXCL));</span>
 	ASSERT((lock_flags &amp; (XFS_ILOCK_SHARED | XFS_ILOCK_EXCL)) !=
 	       (XFS_ILOCK_SHARED | XFS_ILOCK_EXCL));
 	ASSERT((lock_flags &amp; ~(XFS_LOCK_MASK | XFS_LOCK_DEP_MASK)) == 0);
<span class="p_chunk">@@ -256,6 +291,11 @@</span> <span class="p_context"> xfs_iunlock(</span>
 	else if (lock_flags &amp; XFS_IOLOCK_SHARED)
 		mrunlock_shared(&amp;ip-&gt;i_iolock);
 
<span class="p_add">+	if (lock_flags &amp; XFS_MMAPLOCK_EXCL)</span>
<span class="p_add">+		mrunlock_excl(&amp;ip-&gt;i_mmaplock);</span>
<span class="p_add">+	else if (lock_flags &amp; XFS_MMAPLOCK_SHARED)</span>
<span class="p_add">+		mrunlock_shared(&amp;ip-&gt;i_mmaplock);</span>
<span class="p_add">+</span>
 	if (lock_flags &amp; XFS_ILOCK_EXCL)
 		mrunlock_excl(&amp;ip-&gt;i_lock);
 	else if (lock_flags &amp; XFS_ILOCK_SHARED)
<span class="p_chunk">@@ -273,11 +313,14 @@</span> <span class="p_context"> xfs_ilock_demote(</span>
 	xfs_inode_t		*ip,
 	uint			lock_flags)
 {
<span class="p_del">-	ASSERT(lock_flags &amp; (XFS_IOLOCK_EXCL|XFS_ILOCK_EXCL));</span>
<span class="p_del">-	ASSERT((lock_flags &amp; ~(XFS_IOLOCK_EXCL|XFS_ILOCK_EXCL)) == 0);</span>
<span class="p_add">+	ASSERT(lock_flags &amp; (XFS_IOLOCK_EXCL|XFS_MMAPLOCK_EXCL|XFS_ILOCK_EXCL));</span>
<span class="p_add">+	ASSERT((lock_flags &amp;</span>
<span class="p_add">+		~(XFS_IOLOCK_EXCL|XFS_MMAPLOCK_EXCL|XFS_ILOCK_EXCL)) == 0);</span>
 
 	if (lock_flags &amp; XFS_ILOCK_EXCL)
 		mrdemote(&amp;ip-&gt;i_lock);
<span class="p_add">+	if (lock_flags &amp; XFS_MMAPLOCK_EXCL)</span>
<span class="p_add">+		mrdemote(&amp;ip-&gt;i_mmaplock);</span>
 	if (lock_flags &amp; XFS_IOLOCK_EXCL)
 		mrdemote(&amp;ip-&gt;i_iolock);
 
<span class="p_chunk">@@ -296,6 +339,12 @@</span> <span class="p_context"> xfs_isilocked(</span>
 		return rwsem_is_locked(&amp;ip-&gt;i_lock.mr_lock);
 	}
 
<span class="p_add">+	if (lock_flags &amp; (XFS_MMAPLOCK_EXCL|XFS_MMAPLOCK_SHARED)) {</span>
<span class="p_add">+		if (!(lock_flags &amp; XFS_MMAPLOCK_SHARED))</span>
<span class="p_add">+			return !!ip-&gt;i_mmaplock.mr_writer;</span>
<span class="p_add">+		return rwsem_is_locked(&amp;ip-&gt;i_mmaplock.mr_lock);</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
 	if (lock_flags &amp; (XFS_IOLOCK_EXCL|XFS_IOLOCK_SHARED)) {
 		if (!(lock_flags &amp; XFS_IOLOCK_SHARED))
 			return !!ip-&gt;i_iolock.mr_writer;
<span class="p_chunk">@@ -316,14 +365,27 @@</span> <span class="p_context"> int xfs_lock_delays;</span>
 #endif
 
 /*
<span class="p_del">- * Bump the subclass so xfs_lock_inodes() acquires each lock with</span>
<span class="p_del">- * a different value</span>
<span class="p_add">+ * Bump the subclass so xfs_lock_inodes() acquires each lock with a different</span>
<span class="p_add">+ * value. This shouldn&#39;t be called for page fault locking, but we also need to</span>
<span class="p_add">+ * ensure we don&#39;t overrun the number of lockdep subclasses for the iolock or</span>
<span class="p_add">+ * mmaplock as that is limited to 12 by the mmap lock lockdep annotations.</span>
  */
 static inline int
 xfs_lock_inumorder(int lock_mode, int subclass)
 {
<span class="p_del">-	if (lock_mode &amp; (XFS_IOLOCK_SHARED|XFS_IOLOCK_EXCL))</span>
<span class="p_add">+	if (lock_mode &amp; (XFS_IOLOCK_SHARED|XFS_IOLOCK_EXCL)) {</span>
<span class="p_add">+		ASSERT(subclass + XFS_LOCK_INUMORDER &lt;</span>
<span class="p_add">+			(1 &lt;&lt; (XFS_MMAPLOCK_SHIFT - XFS_IOLOCK_SHIFT)));</span>
 		lock_mode |= (subclass + XFS_LOCK_INUMORDER) &lt;&lt; XFS_IOLOCK_SHIFT;
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	if (lock_mode &amp; (XFS_MMAPLOCK_SHARED|XFS_MMAPLOCK_EXCL)) {</span>
<span class="p_add">+		ASSERT(subclass + XFS_LOCK_INUMORDER &lt;</span>
<span class="p_add">+			(1 &lt;&lt; (XFS_ILOCK_SHIFT - XFS_MMAPLOCK_SHIFT)));</span>
<span class="p_add">+		lock_mode |= (subclass + XFS_LOCK_INUMORDER) &lt;&lt;</span>
<span class="p_add">+							XFS_MMAPLOCK_SHIFT;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
 	if (lock_mode &amp; (XFS_ILOCK_SHARED|XFS_ILOCK_EXCL))
 		lock_mode |= (subclass + XFS_LOCK_INUMORDER) &lt;&lt; XFS_ILOCK_SHIFT;
 
<span class="p_chunk">@@ -442,10 +504,10 @@</span> <span class="p_context"> again:</span>
 }
 
 /*
<span class="p_del">- * xfs_lock_two_inodes() can only be used to lock one type of lock</span>
<span class="p_del">- * at a time - the iolock or the ilock, but not both at once. If</span>
<span class="p_del">- * we lock both at once, lockdep will report false positives saying</span>
<span class="p_del">- * we have violated locking orders.</span>
<span class="p_add">+ * xfs_lock_two_inodes() can only be used to lock one type of lock at a time -</span>
<span class="p_add">+ * the iolock, the mmaplock or the ilock, but not more than one at a time. If we</span>
<span class="p_add">+ * lock more than one at a time, lockdep will report false positives saying we</span>
<span class="p_add">+ * have violated locking orders.</span>
  */
 void
 xfs_lock_two_inodes(
<span class="p_chunk">@@ -457,8 +519,12 @@</span> <span class="p_context"> xfs_lock_two_inodes(</span>
 	int			attempts = 0;
 	xfs_log_item_t		*lp;
 
<span class="p_del">-	if (lock_mode &amp; (XFS_IOLOCK_SHARED|XFS_IOLOCK_EXCL))</span>
<span class="p_del">-		ASSERT((lock_mode &amp; (XFS_ILOCK_SHARED|XFS_ILOCK_EXCL)) == 0);</span>
<span class="p_add">+	if (lock_mode &amp; (XFS_IOLOCK_SHARED|XFS_IOLOCK_EXCL)) {</span>
<span class="p_add">+		ASSERT(!(lock_mode &amp; (XFS_MMAPLOCK_SHARED|XFS_MMAPLOCK_EXCL)));</span>
<span class="p_add">+		ASSERT(!(lock_mode &amp; (XFS_ILOCK_SHARED|XFS_ILOCK_EXCL)));</span>
<span class="p_add">+	} else if (lock_mode &amp; (XFS_MMAPLOCK_SHARED|XFS_MMAPLOCK_EXCL))</span>
<span class="p_add">+		ASSERT(!(lock_mode &amp; (XFS_ILOCK_SHARED|XFS_ILOCK_EXCL)));</span>
<span class="p_add">+</span>
 	ASSERT(ip0-&gt;i_ino != ip1-&gt;i_ino);
 
 	if (ip0-&gt;i_ino &gt; ip1-&gt;i_ino) {
<span class="p_header">diff --git a/fs/xfs/xfs_inode.h b/fs/xfs/xfs_inode.h</span>
<span class="p_header">index f8397df396d7..4ef966204da0 100644</span>
<span class="p_header">--- a/fs/xfs/xfs_inode.h</span>
<span class="p_header">+++ b/fs/xfs/xfs_inode.h</span>
<span class="p_chunk">@@ -57,6 +57,7 @@</span> <span class="p_context"> typedef struct xfs_inode {</span>
 	struct xfs_inode_log_item *i_itemp;	/* logging information */
 	mrlock_t		i_lock;		/* inode lock */
 	mrlock_t		i_iolock;	/* inode IO lock */
<span class="p_add">+	mrlock_t		i_mmaplock;	/* inode mmap IO lock */</span>
 	atomic_t		i_pincount;	/* inode pin count */
 	spinlock_t		i_flags_lock;	/* inode i_flags lock */
 	/* Miscellaneous state. */
<span class="p_chunk">@@ -264,15 +265,20 @@</span> <span class="p_context"> static inline int xfs_isiflocked(struct xfs_inode *ip)</span>
 #define	XFS_IOLOCK_SHARED	(1&lt;&lt;1)
 #define	XFS_ILOCK_EXCL		(1&lt;&lt;2)
 #define	XFS_ILOCK_SHARED	(1&lt;&lt;3)
<span class="p_add">+#define	XFS_MMAPLOCK_EXCL	(1&lt;&lt;4)</span>
<span class="p_add">+#define	XFS_MMAPLOCK_SHARED	(1&lt;&lt;5)</span>
 
 #define XFS_LOCK_MASK		(XFS_IOLOCK_EXCL | XFS_IOLOCK_SHARED \
<span class="p_del">-				| XFS_ILOCK_EXCL | XFS_ILOCK_SHARED)</span>
<span class="p_add">+				| XFS_ILOCK_EXCL | XFS_ILOCK_SHARED \</span>
<span class="p_add">+				| XFS_MMAPLOCK_EXCL | XFS_MMAPLOCK_SHARED)</span>
 
 #define XFS_LOCK_FLAGS \
 	{ XFS_IOLOCK_EXCL,	&quot;IOLOCK_EXCL&quot; }, \
 	{ XFS_IOLOCK_SHARED,	&quot;IOLOCK_SHARED&quot; }, \
 	{ XFS_ILOCK_EXCL,	&quot;ILOCK_EXCL&quot; }, \
<span class="p_del">-	{ XFS_ILOCK_SHARED,	&quot;ILOCK_SHARED&quot; }</span>
<span class="p_add">+	{ XFS_ILOCK_SHARED,	&quot;ILOCK_SHARED&quot; }, \</span>
<span class="p_add">+	{ XFS_MMAPLOCK_EXCL,	&quot;MMAPLOCK_EXCL&quot; }, \</span>
<span class="p_add">+	{ XFS_MMAPLOCK_SHARED,	&quot;MMAPLOCK_SHARED&quot; }</span>
 
 
 /*
<span class="p_chunk">@@ -303,17 +309,26 @@</span> <span class="p_context"> static inline int xfs_isiflocked(struct xfs_inode *ip)</span>
 #define XFS_IOLOCK_SHIFT	16
 #define	XFS_IOLOCK_PARENT	(XFS_LOCK_PARENT &lt;&lt; XFS_IOLOCK_SHIFT)
 
<span class="p_add">+#define XFS_MMAPLOCK_SHIFT	20</span>
<span class="p_add">+</span>
 #define XFS_ILOCK_SHIFT		24
 #define	XFS_ILOCK_PARENT	(XFS_LOCK_PARENT &lt;&lt; XFS_ILOCK_SHIFT)
 #define	XFS_ILOCK_RTBITMAP	(XFS_LOCK_RTBITMAP &lt;&lt; XFS_ILOCK_SHIFT)
 #define	XFS_ILOCK_RTSUM		(XFS_LOCK_RTSUM &lt;&lt; XFS_ILOCK_SHIFT)
 
<span class="p_del">-#define XFS_IOLOCK_DEP_MASK	0x00ff0000</span>
<span class="p_add">+#define XFS_IOLOCK_DEP_MASK	0x000f0000</span>
<span class="p_add">+#define XFS_MMAPLOCK_DEP_MASK	0x00f00000</span>
 #define XFS_ILOCK_DEP_MASK	0xff000000
<span class="p_del">-#define XFS_LOCK_DEP_MASK	(XFS_IOLOCK_DEP_MASK | XFS_ILOCK_DEP_MASK)</span>
<span class="p_del">-</span>
<span class="p_del">-#define XFS_IOLOCK_DEP(flags)	(((flags) &amp; XFS_IOLOCK_DEP_MASK) &gt;&gt; XFS_IOLOCK_SHIFT)</span>
<span class="p_del">-#define XFS_ILOCK_DEP(flags)	(((flags) &amp; XFS_ILOCK_DEP_MASK) &gt;&gt; XFS_ILOCK_SHIFT)</span>
<span class="p_add">+#define XFS_LOCK_DEP_MASK	(XFS_IOLOCK_DEP_MASK | \</span>
<span class="p_add">+				 XFS_MMAPLOCK_DEP_MASK | \</span>
<span class="p_add">+				 XFS_ILOCK_DEP_MASK)</span>
<span class="p_add">+</span>
<span class="p_add">+#define XFS_IOLOCK_DEP(flags)	(((flags) &amp; XFS_IOLOCK_DEP_MASK) \</span>
<span class="p_add">+					&gt;&gt; XFS_IOLOCK_SHIFT)</span>
<span class="p_add">+#define XFS_MMAPLOCK_DEP(flags)	(((flags) &amp; XFS_MMAPLOCK_DEP_MASK) \</span>
<span class="p_add">+					&gt;&gt; XFS_MMAPLOCK_SHIFT)</span>
<span class="p_add">+#define XFS_ILOCK_DEP(flags)	(((flags) &amp; XFS_ILOCK_DEP_MASK) \</span>
<span class="p_add">+					&gt;&gt; XFS_ILOCK_SHIFT)</span>
 
 /*
  * For multiple groups support: if S_ISGID bit is set in the parent
<span class="p_header">diff --git a/fs/xfs/xfs_ioctl.c b/fs/xfs/xfs_ioctl.c</span>
<span class="p_header">index 8bc1bbce7451..afc859f44d01 100644</span>
<span class="p_header">--- a/fs/xfs/xfs_ioctl.c</span>
<span class="p_header">+++ b/fs/xfs/xfs_ioctl.c</span>
<span class="p_chunk">@@ -640,7 +640,7 @@</span> <span class="p_context"> xfs_ioc_space(</span>
 	if (error)
 		return error;
 
<span class="p_del">-	xfs_ilock(ip, XFS_IOLOCK_EXCL);</span>
<span class="p_add">+	xfs_ilock(ip, XFS_IOLOCK_EXCL | XFS_MMAPLOCK_EXCL);</span>
 
 	switch (bf-&gt;l_whence) {
 	case 0: /*SEEK_SET*/
<span class="p_chunk">@@ -757,7 +757,7 @@</span> <span class="p_context"> xfs_ioc_space(</span>
 	error = xfs_trans_commit(tp, 0);
 
 out_unlock:
<span class="p_del">-	xfs_iunlock(ip, XFS_IOLOCK_EXCL);</span>
<span class="p_add">+	xfs_iunlock(ip, XFS_IOLOCK_EXCL | XFS_MMAPLOCK_EXCL);</span>
 	mnt_drop_write_file(filp);
 	return -error;
 }
<span class="p_header">diff --git a/fs/xfs/xfs_iops.c b/fs/xfs/xfs_iops.c</span>
<span class="p_header">index 537d8daeaa9e..125da8969c72 100644</span>
<span class="p_header">--- a/fs/xfs/xfs_iops.c</span>
<span class="p_header">+++ b/fs/xfs/xfs_iops.c</span>
<span class="p_chunk">@@ -759,6 +759,7 @@</span> <span class="p_context"> xfs_setattr_size(</span>
 		return XFS_ERROR(error);
 
 	ASSERT(xfs_isilocked(ip, XFS_IOLOCK_EXCL));
<span class="p_add">+	ASSERT(xfs_isilocked(ip, XFS_MMAPLOCK_EXCL));</span>
 	ASSERT(S_ISREG(ip-&gt;i_d.di_mode));
 	ASSERT((iattr-&gt;ia_valid &amp; (ATTR_UID|ATTR_GID|ATTR_ATIME|ATTR_ATIME_SET|
 		ATTR_MTIME_SET|ATTR_KILL_PRIV|ATTR_TIMES_SET)) == 0);
<span class="p_chunk">@@ -822,19 +823,21 @@</span> <span class="p_context"> xfs_setattr_size(</span>
 	inode_dio_wait(inode);
 
 	/*
<span class="p_del">-	 * Do all the page cache truncate work outside the transaction context</span>
<span class="p_del">-	 * as the &quot;lock&quot; order is page lock-&gt;log space reservation.  i.e.</span>
<span class="p_del">-	 * locking pages inside the transaction can ABBA deadlock with</span>
<span class="p_del">-	 * writeback. We have to do the VFS inode size update before we truncate</span>
<span class="p_del">-	 * the pagecache, however, to avoid racing with page faults beyond the</span>
<span class="p_del">-	 * new EOF they are not serialised against truncate operations except by</span>
<span class="p_del">-	 * page locks and size updates.</span>
<span class="p_add">+	 * We&#39;ve already locked out new page faults, so now we can safely remove</span>
<span class="p_add">+	 * pages from the page cache knowing they won&#39;t get refaulted until we</span>
<span class="p_add">+	 * drop the XFS_MMAP_EXCL lock after the extent manipulations are</span>
<span class="p_add">+	 * complete. The truncate_setsize() call also cleans partial EOF page</span>
<span class="p_add">+	 * PTEs on extending truncates and hence ensures sub-page block size</span>
<span class="p_add">+	 * filesystems are correctly handled, too.</span>
 	 *
<span class="p_del">-	 * Hence we are in a situation where a truncate can fail with ENOMEM</span>
<span class="p_del">-	 * from xfs_trans_reserve(), but having already truncated the in-memory</span>
<span class="p_del">-	 * version of the file (i.e. made user visible changes). There&#39;s not</span>
<span class="p_del">-	 * much we can do about this, except to hope that the caller sees ENOMEM</span>
<span class="p_del">-	 * and retries the truncate operation.</span>
<span class="p_add">+	 * We have to do all the page cache truncate work outside the</span>
<span class="p_add">+	 * transaction context as the &quot;lock&quot; order is page lock-&gt;log space</span>
<span class="p_add">+	 * reservation as defined by extent allocation in the writeback path.</span>
<span class="p_add">+	 * Hence a truncate can fail with ENOMEM from xfs_trans_reserve(), but</span>
<span class="p_add">+	 * having already truncated the in-memory version of the file (i.e. made</span>
<span class="p_add">+	 * user visible changes). There&#39;s not much we can do about this, except</span>
<span class="p_add">+	 * to hope that the caller sees ENOMEM and retries the truncate</span>
<span class="p_add">+	 * operation.</span>
 	 */
 	error = -block_truncate_page(inode-&gt;i_mapping, newsize, xfs_get_blocks);
 	if (error)
<span class="p_chunk">@@ -935,9 +938,9 @@</span> <span class="p_context"> xfs_vn_setattr(</span>
 	int			error;
 
 	if (iattr-&gt;ia_valid &amp; ATTR_SIZE) {
<span class="p_del">-		xfs_ilock(ip, XFS_IOLOCK_EXCL);</span>
<span class="p_add">+		xfs_ilock(ip, XFS_IOLOCK_EXCL | XFS_MMAPLOCK_EXCL);</span>
 		error = xfs_setattr_size(ip, iattr);
<span class="p_del">-		xfs_iunlock(ip, XFS_IOLOCK_EXCL);</span>
<span class="p_add">+		xfs_iunlock(ip, XFS_IOLOCK_EXCL | XFS_MMAPLOCK_EXCL);</span>
 	} else {
 		error = xfs_setattr_nonsize(ip, iattr, 0);
 	}
<span class="p_header">diff --git a/fs/xfs/xfs_super.c b/fs/xfs/xfs_super.c</span>
<span class="p_header">index 0ee601b67d9e..a4fcd32134fa 100644</span>
<span class="p_header">--- a/fs/xfs/xfs_super.c</span>
<span class="p_header">+++ b/fs/xfs/xfs_super.c</span>
<span class="p_chunk">@@ -982,6 +982,8 @@</span> <span class="p_context"> xfs_fs_inode_init_once(</span>
 	atomic_set(&amp;ip-&gt;i_pincount, 0);
 	spin_lock_init(&amp;ip-&gt;i_flags_lock);
 
<span class="p_add">+	mrlock_init(&amp;ip-&gt;i_mmaplock, MRLOCK_ALLOW_EQUAL_PRI|MRLOCK_BARRIER,</span>
<span class="p_add">+		     &quot;xfsino&quot;, ip-&gt;i_ino);</span>
 	mrlock_init(&amp;ip-&gt;i_lock, MRLOCK_ALLOW_EQUAL_PRI|MRLOCK_BARRIER,
 		     &quot;xfsino&quot;, ip-&gt;i_ino);
 }
<span class="p_header">diff --git a/fs/xfs/xfs_trace.h b/fs/xfs/xfs_trace.h</span>
<span class="p_header">index 152f82782630..24799bb43739 100644</span>
<span class="p_header">--- a/fs/xfs/xfs_trace.h</span>
<span class="p_header">+++ b/fs/xfs/xfs_trace.h</span>
<span class="p_chunk">@@ -684,6 +684,9 @@</span> <span class="p_context"> DEFINE_INODE_EVENT(xfs_inode_set_eofblocks_tag);</span>
 DEFINE_INODE_EVENT(xfs_inode_clear_eofblocks_tag);
 DEFINE_INODE_EVENT(xfs_inode_free_eofblocks_invalid);
 
<span class="p_add">+DEFINE_INODE_EVENT(xfs_filemap_fault);</span>
<span class="p_add">+DEFINE_INODE_EVENT(xfs_filemap_page_mkwrite);</span>
<span class="p_add">+</span>
 DECLARE_EVENT_CLASS(xfs_iref_class,
 	TP_PROTO(struct xfs_inode *ip, unsigned long caller_ip),
 	TP_ARGS(ip, caller_ip),
<span class="p_header">diff --git a/include/linux/balloon_compaction.h b/include/linux/balloon_compaction.h</span>
<span class="p_header">index 089743ade734..38aa07d5b81c 100644</span>
<span class="p_header">--- a/include/linux/balloon_compaction.h</span>
<span class="p_header">+++ b/include/linux/balloon_compaction.h</span>
<span class="p_chunk">@@ -27,10 +27,13 @@</span> <span class="p_context"></span>
  *      counter raised only while it is under our special handling;
  *
  * iii. after the lockless scan step have selected a potential balloon page for
<span class="p_del">- *      isolation, re-test the page-&gt;mapping flags and the page ref counter</span>
<span class="p_add">+ *      isolation, re-test the PageBalloon mark and the PagePrivate flag</span>
  *      under the proper page lock, to ensure isolating a valid balloon page
  *      (not yet isolated, nor under release procedure)
  *
<span class="p_add">+ *  iv. isolation or dequeueing procedure must clear PagePrivate flag under</span>
<span class="p_add">+ *      page lock together with removing page from balloon device page list.</span>
<span class="p_add">+ *</span>
  * The functions provided by this interface are placed to help on coping with
  * the aforementioned balloon page corner case, as well as to ensure the simple
  * set of exposed rules are satisfied while we are dealing with balloon pages
<span class="p_chunk">@@ -71,28 +74,6 @@</span> <span class="p_context"> static inline void balloon_devinfo_free(struct balloon_dev_info *b_dev_info)</span>
 	kfree(b_dev_info);
 }
 
<span class="p_del">-/*</span>
<span class="p_del">- * balloon_page_free - release a balloon page back to the page free lists</span>
<span class="p_del">- * @page: ballooned page to be set free</span>
<span class="p_del">- *</span>
<span class="p_del">- * This function must be used to properly set free an isolated/dequeued balloon</span>
<span class="p_del">- * page at the end of a sucessful page migration, or at the balloon driver&#39;s</span>
<span class="p_del">- * page release procedure.</span>
<span class="p_del">- */</span>
<span class="p_del">-static inline void balloon_page_free(struct page *page)</span>
<span class="p_del">-{</span>
<span class="p_del">-	/*</span>
<span class="p_del">-	 * Balloon pages always get an extra refcount before being isolated</span>
<span class="p_del">-	 * and before being dequeued to help on sorting out fortuite colisions</span>
<span class="p_del">-	 * between a thread attempting to isolate and another thread attempting</span>
<span class="p_del">-	 * to release the very same balloon page.</span>
<span class="p_del">-	 *</span>
<span class="p_del">-	 * Before we handle the page back to Buddy, lets drop its extra refcnt.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	put_page(page);</span>
<span class="p_del">-	__free_page(page);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
 #ifdef CONFIG_BALLOON_COMPACTION
 extern bool balloon_page_isolate(struct page *page);
 extern void balloon_page_putback(struct page *page);
<span class="p_chunk">@@ -108,74 +89,33 @@</span> <span class="p_context"> static inline void balloon_mapping_free(struct address_space *balloon_mapping)</span>
 }
 
 /*
<span class="p_del">- * page_flags_cleared - helper to perform balloon @page -&gt;flags tests.</span>
<span class="p_del">- *</span>
<span class="p_del">- * As balloon pages are obtained from buddy and we do not play with page-&gt;flags</span>
<span class="p_del">- * at driver level (exception made when we get the page lock for compaction),</span>
<span class="p_del">- * we can safely identify a ballooned page by checking if the</span>
<span class="p_del">- * PAGE_FLAGS_CHECK_AT_PREP page-&gt;flags are all cleared.  This approach also</span>
<span class="p_del">- * helps us skip ballooned pages that are locked for compaction or release, thus</span>
<span class="p_del">- * mitigating their racy check at balloon_page_movable()</span>
<span class="p_del">- */</span>
<span class="p_del">-static inline bool page_flags_cleared(struct page *page)</span>
<span class="p_del">-{</span>
<span class="p_del">-	return !(page-&gt;flags &amp; PAGE_FLAGS_CHECK_AT_PREP);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-/*</span>
<span class="p_del">- * __is_movable_balloon_page - helper to perform @page mapping-&gt;flags tests</span>
<span class="p_add">+ * __is_movable_balloon_page - helper to perform @page PageBalloon tests</span>
  */
 static inline bool __is_movable_balloon_page(struct page *page)
 {
<span class="p_del">-	struct address_space *mapping = page-&gt;mapping;</span>
<span class="p_del">-	return mapping_balloon(mapping);</span>
<span class="p_add">+	return PageBalloon(page);</span>
 }
 
 /*
<span class="p_del">- * balloon_page_movable - test page-&gt;mapping-&gt;flags to identify balloon pages</span>
<span class="p_del">- *			  that can be moved by compaction/migration.</span>
<span class="p_del">- *</span>
<span class="p_del">- * This function is used at core compaction&#39;s page isolation scheme, therefore</span>
<span class="p_del">- * most pages exposed to it are not enlisted as balloon pages and so, to avoid</span>
<span class="p_del">- * undesired side effects like racing against __free_pages(), we cannot afford</span>
<span class="p_del">- * holding the page locked while testing page-&gt;mapping-&gt;flags here.</span>
<span class="p_add">+ * balloon_page_movable - test PageBalloon to identify balloon pages</span>
<span class="p_add">+ *			  and PagePrivate to check that the page is not</span>
<span class="p_add">+ *			  isolated and can be moved by compaction/migration.</span>
  *
  * As we might return false positives in the case of a balloon page being just
<span class="p_del">- * released under us, the page-&gt;mapping-&gt;flags need to be re-tested later,</span>
<span class="p_del">- * under the proper page lock, at the functions that will be coping with the</span>
<span class="p_del">- * balloon page case.</span>
<span class="p_add">+ * released under us, this need to be re-tested later, under the page lock.</span>
  */
 static inline bool balloon_page_movable(struct page *page)
 {
<span class="p_del">-	/*</span>
<span class="p_del">-	 * Before dereferencing and testing mapping-&gt;flags, let&#39;s make sure</span>
<span class="p_del">-	 * this is not a page that uses -&gt;mapping in a different way</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	if (page_flags_cleared(page) &amp;&amp; !page_mapped(page) &amp;&amp;</span>
<span class="p_del">-	    page_count(page) == 1)</span>
<span class="p_del">-		return __is_movable_balloon_page(page);</span>
<span class="p_del">-</span>
<span class="p_del">-	return false;</span>
<span class="p_add">+	return PageBalloon(page) &amp;&amp; PagePrivate(page);</span>
 }
 
 /*
  * isolated_balloon_page - identify an isolated balloon page on private
  *			   compaction/migration page lists.
<span class="p_del">- *</span>
<span class="p_del">- * After a compaction thread isolates a balloon page for migration, it raises</span>
<span class="p_del">- * the page refcount to prevent concurrent compaction threads from re-isolating</span>
<span class="p_del">- * the same page. For that reason putback_movable_pages(), or other routines</span>
<span class="p_del">- * that need to identify isolated balloon pages on private pagelists, cannot</span>
<span class="p_del">- * rely on balloon_page_movable() to accomplish the task.</span>
  */
 static inline bool isolated_balloon_page(struct page *page)
 {
<span class="p_del">-	/* Already isolated balloon pages, by default, have a raised refcount */</span>
<span class="p_del">-	if (page_flags_cleared(page) &amp;&amp; !page_mapped(page) &amp;&amp;</span>
<span class="p_del">-	    page_count(page) &gt;= 2)</span>
<span class="p_del">-		return __is_movable_balloon_page(page);</span>
<span class="p_del">-</span>
<span class="p_del">-	return false;</span>
<span class="p_add">+	return PageBalloon(page);</span>
 }
 
 /*
<span class="p_chunk">@@ -192,6 +132,8 @@</span> <span class="p_context"> static inline void balloon_page_insert(struct page *page,</span>
 				       struct address_space *mapping,
 				       struct list_head *head)
 {
<span class="p_add">+	__SetPageBalloon(page);</span>
<span class="p_add">+	SetPagePrivate(page);</span>
 	page-&gt;mapping = mapping;
 	list_add(&amp;page-&gt;lru, head);
 }
<span class="p_chunk">@@ -206,8 +148,12 @@</span> <span class="p_context"> static inline void balloon_page_insert(struct page *page,</span>
  */
 static inline void balloon_page_delete(struct page *page)
 {
<span class="p_add">+	__ClearPageBalloon(page);</span>
 	page-&gt;mapping = NULL;
<span class="p_del">-	list_del(&amp;page-&gt;lru);</span>
<span class="p_add">+	if (PagePrivate(page)) {</span>
<span class="p_add">+		ClearPagePrivate(page);</span>
<span class="p_add">+		list_del(&amp;page-&gt;lru);</span>
<span class="p_add">+	}</span>
 }
 
 /*
<span class="p_chunk">@@ -258,6 +204,11 @@</span> <span class="p_context"> static inline void balloon_page_delete(struct page *page)</span>
 	list_del(&amp;page-&gt;lru);
 }
 
<span class="p_add">+static inline bool __is_movable_balloon_page(struct page *page)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return false;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static inline bool balloon_page_movable(struct page *page)
 {
 	return false;
<span class="p_header">diff --git a/include/linux/ceph/auth.h b/include/linux/ceph/auth.h</span>
<span class="p_header">index 5f3386844134..d78c18173e93 100644</span>
<span class="p_header">--- a/include/linux/ceph/auth.h</span>
<span class="p_header">+++ b/include/linux/ceph/auth.h</span>
<span class="p_chunk">@@ -12,7 +12,10 @@</span> <span class="p_context"></span>
  */
 
 struct ceph_auth_client;
<span class="p_del">-struct ceph_authorizer;</span>
<span class="p_add">+</span>
<span class="p_add">+struct ceph_authorizer {</span>
<span class="p_add">+	void (*destroy)(struct ceph_authorizer *);</span>
<span class="p_add">+};</span>
 
 struct ceph_auth_handshake {
 	struct ceph_authorizer *authorizer;
<span class="p_chunk">@@ -57,8 +60,6 @@</span> <span class="p_context"> struct ceph_auth_client_ops {</span>
 				 struct ceph_auth_handshake *auth);
 	int (*verify_authorizer_reply)(struct ceph_auth_client *ac,
 				       struct ceph_authorizer *a, size_t len);
<span class="p_del">-	void (*destroy_authorizer)(struct ceph_auth_client *ac,</span>
<span class="p_del">-				   struct ceph_authorizer *a);</span>
 	void (*invalidate_authorizer)(struct ceph_auth_client *ac,
 				      int peer_type);
 
<span class="p_chunk">@@ -102,8 +103,7 @@</span> <span class="p_context"> extern int ceph_auth_is_authenticated(struct ceph_auth_client *ac);</span>
 extern int ceph_auth_create_authorizer(struct ceph_auth_client *ac,
 				       int peer_type,
 				       struct ceph_auth_handshake *auth);
<span class="p_del">-extern void ceph_auth_destroy_authorizer(struct ceph_auth_client *ac,</span>
<span class="p_del">-					 struct ceph_authorizer *a);</span>
<span class="p_add">+void ceph_auth_destroy_authorizer(struct ceph_authorizer *a);</span>
 extern int ceph_auth_update_authorizer(struct ceph_auth_client *ac,
 				       int peer_type,
 				       struct ceph_auth_handshake *a);
<span class="p_header">diff --git a/include/linux/ceph/osd_client.h b/include/linux/ceph/osd_client.h</span>
<span class="p_header">index 94ec69672164..b2a24e0f5c60 100644</span>
<span class="p_header">--- a/include/linux/ceph/osd_client.h</span>
<span class="p_header">+++ b/include/linux/ceph/osd_client.h</span>
<span class="p_chunk">@@ -16,7 +16,6 @@</span> <span class="p_context"> struct ceph_msg;</span>
 struct ceph_snap_context;
 struct ceph_osd_request;
 struct ceph_osd_client;
<span class="p_del">-struct ceph_authorizer;</span>
 
 /*
  * completion callback for async writepages
<span class="p_header">diff --git a/include/linux/compiler-gcc.h b/include/linux/compiler-gcc.h</span>
<span class="p_header">index 02ae99e8e6d3..bb2cdcd929c6 100644</span>
<span class="p_header">--- a/include/linux/compiler-gcc.h</span>
<span class="p_header">+++ b/include/linux/compiler-gcc.h</span>
<span class="p_chunk">@@ -100,10 +100,122 @@</span> <span class="p_context"></span>
 #define __maybe_unused			__attribute__((unused))
 #define __always_unused			__attribute__((unused))
 
<span class="p_del">-#define __gcc_header(x) #x</span>
<span class="p_del">-#define _gcc_header(x) __gcc_header(linux/compiler-gcc##x.h)</span>
<span class="p_del">-#define gcc_header(x) _gcc_header(x)</span>
<span class="p_del">-#include gcc_header(__GNUC__)</span>
<span class="p_add">+/* gcc version specific checks */</span>
<span class="p_add">+</span>
<span class="p_add">+#if GCC_VERSION &lt; 30200</span>
<span class="p_add">+# error Sorry, your compiler is too old - please upgrade it.</span>
<span class="p_add">+#endif</span>
<span class="p_add">+</span>
<span class="p_add">+#if GCC_VERSION &lt; 30300</span>
<span class="p_add">+# define __used			__attribute__((__unused__))</span>
<span class="p_add">+#else</span>
<span class="p_add">+# define __used			__attribute__((__used__))</span>
<span class="p_add">+#endif</span>
<span class="p_add">+</span>
<span class="p_add">+#ifdef CONFIG_GCOV_KERNEL</span>
<span class="p_add">+# if GCC_VERSION &lt; 30400</span>
<span class="p_add">+#   error &quot;GCOV profiling support for gcc versions below 3.4 not included&quot;</span>
<span class="p_add">+# endif /* __GNUC_MINOR__ */</span>
<span class="p_add">+#endif /* CONFIG_GCOV_KERNEL */</span>
<span class="p_add">+</span>
<span class="p_add">+#if GCC_VERSION &gt;= 30400</span>
<span class="p_add">+#define __must_check		__attribute__((warn_unused_result))</span>
<span class="p_add">+#endif</span>
<span class="p_add">+</span>
<span class="p_add">+#if GCC_VERSION &gt;= 40000</span>
<span class="p_add">+</span>
<span class="p_add">+/* GCC 4.1.[01] miscompiles __weak */</span>
<span class="p_add">+#ifdef __KERNEL__</span>
<span class="p_add">+# if GCC_VERSION &gt;= 40100 &amp;&amp;  GCC_VERSION &lt;= 40101</span>
<span class="p_add">+#  error Your version of gcc miscompiles the __weak directive</span>
<span class="p_add">+# endif</span>
<span class="p_add">+#endif</span>
<span class="p_add">+</span>
<span class="p_add">+#define __used			__attribute__((__used__))</span>
<span class="p_add">+#define __compiler_offsetof(a, b)					\</span>
<span class="p_add">+	__builtin_offsetof(a, b)</span>
<span class="p_add">+</span>
<span class="p_add">+#if GCC_VERSION &gt;= 40100 &amp;&amp; GCC_VERSION &lt; 40600</span>
<span class="p_add">+# define __compiletime_object_size(obj) __builtin_object_size(obj, 0)</span>
<span class="p_add">+#endif</span>
<span class="p_add">+</span>
<span class="p_add">+#if GCC_VERSION &gt;= 40300</span>
<span class="p_add">+/* Mark functions as cold. gcc will assume any path leading to a call</span>
<span class="p_add">+ * to them will be unlikely.  This means a lot of manual unlikely()s</span>
<span class="p_add">+ * are unnecessary now for any paths leading to the usual suspects</span>
<span class="p_add">+ * like BUG(), printk(), panic() etc. [but let&#39;s keep them for now for</span>
<span class="p_add">+ * older compilers]</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * Early snapshots of gcc 4.3 don&#39;t support this and we can&#39;t detect this</span>
<span class="p_add">+ * in the preprocessor, but we can live with this because they&#39;re unreleased.</span>
<span class="p_add">+ * Maketime probing would be overkill here.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * gcc also has a __attribute__((__hot__)) to move hot functions into</span>
<span class="p_add">+ * a special section, but I don&#39;t see any sense in this right now in</span>
<span class="p_add">+ * the kernel context</span>
<span class="p_add">+ */</span>
<span class="p_add">+#define __cold			__attribute__((__cold__))</span>
<span class="p_add">+</span>
<span class="p_add">+#define __UNIQUE_ID(prefix) __PASTE(__PASTE(__UNIQUE_ID_, prefix), __COUNTER__)</span>
<span class="p_add">+</span>
<span class="p_add">+#ifndef __CHECKER__</span>
<span class="p_add">+# define __compiletime_warning(message) __attribute__((warning(message)))</span>
<span class="p_add">+# define __compiletime_error(message) __attribute__((error(message)))</span>
<span class="p_add">+#endif /* __CHECKER__ */</span>
<span class="p_add">+#endif /* GCC_VERSION &gt;= 40300 */</span>
<span class="p_add">+</span>
<span class="p_add">+#if GCC_VERSION &gt;= 40500</span>
<span class="p_add">+/*</span>
<span class="p_add">+ * Mark a position in code as unreachable.  This can be used to</span>
<span class="p_add">+ * suppress control flow warnings after asm blocks that transfer</span>
<span class="p_add">+ * control elsewhere.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * Early snapshots of gcc 4.5 don&#39;t support this and we can&#39;t detect</span>
<span class="p_add">+ * this in the preprocessor, but we can live with this because they&#39;re</span>
<span class="p_add">+ * unreleased.  Really, we need to have autoconf for the kernel.</span>
<span class="p_add">+ */</span>
<span class="p_add">+#define unreachable() __builtin_unreachable()</span>
<span class="p_add">+</span>
<span class="p_add">+/* Mark a function definition as prohibited from being cloned. */</span>
<span class="p_add">+#define __noclone	__attribute__((__noclone__))</span>
<span class="p_add">+</span>
<span class="p_add">+#endif /* GCC_VERSION &gt;= 40500 */</span>
<span class="p_add">+</span>
<span class="p_add">+#if GCC_VERSION &gt;= 40600</span>
<span class="p_add">+/*</span>
<span class="p_add">+ * Tell the optimizer that something else uses this function or variable.</span>
<span class="p_add">+ */</span>
<span class="p_add">+#define __visible	__attribute__((externally_visible))</span>
<span class="p_add">+#endif</span>
<span class="p_add">+</span>
<span class="p_add">+/*</span>
<span class="p_add">+ * GCC &#39;asm goto&#39; miscompiles certain code sequences:</span>
<span class="p_add">+ *</span>
<span class="p_add">+ *   http://gcc.gnu.org/bugzilla/show_bug.cgi?id=58670</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * Work it around via a compiler barrier quirk suggested by Jakub Jelinek.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * (asm goto is automatically volatile - the naming reflects this.)</span>
<span class="p_add">+ */</span>
<span class="p_add">+#define asm_volatile_goto(x...)	do { asm goto(x); asm (&quot;&quot;); } while (0)</span>
<span class="p_add">+</span>
<span class="p_add">+#ifdef CONFIG_ARCH_USE_BUILTIN_BSWAP</span>
<span class="p_add">+#if GCC_VERSION &gt;= 40400</span>
<span class="p_add">+#define __HAVE_BUILTIN_BSWAP32__</span>
<span class="p_add">+#define __HAVE_BUILTIN_BSWAP64__</span>
<span class="p_add">+#endif</span>
<span class="p_add">+#if GCC_VERSION &gt;= 40800 || (defined(__powerpc__) &amp;&amp; GCC_VERSION &gt;= 40600)</span>
<span class="p_add">+#define __HAVE_BUILTIN_BSWAP16__</span>
<span class="p_add">+#endif</span>
<span class="p_add">+#endif /* CONFIG_ARCH_USE_BUILTIN_BSWAP */</span>
<span class="p_add">+</span>
<span class="p_add">+#if GCC_VERSION &gt;= 50000</span>
<span class="p_add">+#define KASAN_ABI_VERSION 4</span>
<span class="p_add">+#elif GCC_VERSION &gt;= 40902</span>
<span class="p_add">+#define KASAN_ABI_VERSION 3</span>
<span class="p_add">+#endif</span>
<span class="p_add">+</span>
<span class="p_add">+#endif	/* gcc version &gt;= 40000 specific checks */</span>
 
 #if !defined(__noclone)
 #define __noclone	/* not needed */
<span class="p_header">diff --git a/include/linux/compiler-gcc3.h b/include/linux/compiler-gcc3.h</span>
deleted file mode 100644
<span class="p_header">index 7d89febe4d79..000000000000</span>
<span class="p_header">--- a/include/linux/compiler-gcc3.h</span>
<span class="p_header">+++ /dev/null</span>
<span class="p_chunk">@@ -1,23 +0,0 @@</span> <span class="p_context"></span>
<span class="p_del">-#ifndef __LINUX_COMPILER_H</span>
<span class="p_del">-#error &quot;Please don&#39;t include &lt;linux/compiler-gcc3.h&gt; directly, include &lt;linux/compiler.h&gt; instead.&quot;</span>
<span class="p_del">-#endif</span>
<span class="p_del">-</span>
<span class="p_del">-#if GCC_VERSION &lt; 30200</span>
<span class="p_del">-# error Sorry, your compiler is too old - please upgrade it.</span>
<span class="p_del">-#endif</span>
<span class="p_del">-</span>
<span class="p_del">-#if GCC_VERSION &gt;= 30300</span>
<span class="p_del">-# define __used			__attribute__((__used__))</span>
<span class="p_del">-#else</span>
<span class="p_del">-# define __used			__attribute__((__unused__))</span>
<span class="p_del">-#endif</span>
<span class="p_del">-</span>
<span class="p_del">-#if GCC_VERSION &gt;= 30400</span>
<span class="p_del">-#define __must_check		__attribute__((warn_unused_result))</span>
<span class="p_del">-#endif</span>
<span class="p_del">-</span>
<span class="p_del">-#ifdef CONFIG_GCOV_KERNEL</span>
<span class="p_del">-# if GCC_VERSION &lt; 30400</span>
<span class="p_del">-#   error &quot;GCOV profiling support for gcc versions below 3.4 not included&quot;</span>
<span class="p_del">-# endif /* __GNUC_MINOR__ */</span>
<span class="p_del">-#endif /* CONFIG_GCOV_KERNEL */</span>
<span class="p_header">diff --git a/include/linux/compiler-gcc4.h b/include/linux/compiler-gcc4.h</span>
deleted file mode 100644
<span class="p_header">index cc7da99ad58d..000000000000</span>
<span class="p_header">--- a/include/linux/compiler-gcc4.h</span>
<span class="p_header">+++ /dev/null</span>
<span class="p_chunk">@@ -1,88 +0,0 @@</span> <span class="p_context"></span>
<span class="p_del">-#ifndef __LINUX_COMPILER_H</span>
<span class="p_del">-#error &quot;Please don&#39;t include &lt;linux/compiler-gcc4.h&gt; directly, include &lt;linux/compiler.h&gt; instead.&quot;</span>
<span class="p_del">-#endif</span>
<span class="p_del">-</span>
<span class="p_del">-/* GCC 4.1.[01] miscompiles __weak */</span>
<span class="p_del">-#ifdef __KERNEL__</span>
<span class="p_del">-# if GCC_VERSION &gt;= 40100 &amp;&amp;  GCC_VERSION &lt;= 40101</span>
<span class="p_del">-#  error Your version of gcc miscompiles the __weak directive</span>
<span class="p_del">-# endif</span>
<span class="p_del">-#endif</span>
<span class="p_del">-</span>
<span class="p_del">-#define __used			__attribute__((__used__))</span>
<span class="p_del">-#define __must_check 		__attribute__((warn_unused_result))</span>
<span class="p_del">-#define __compiler_offsetof(a,b) __builtin_offsetof(a,b)</span>
<span class="p_del">-</span>
<span class="p_del">-#if GCC_VERSION &gt;= 40100 &amp;&amp; GCC_VERSION &lt; 40600</span>
<span class="p_del">-# define __compiletime_object_size(obj) __builtin_object_size(obj, 0)</span>
<span class="p_del">-#endif</span>
<span class="p_del">-</span>
<span class="p_del">-#if GCC_VERSION &gt;= 40300</span>
<span class="p_del">-/* Mark functions as cold. gcc will assume any path leading to a call</span>
<span class="p_del">-   to them will be unlikely.  This means a lot of manual unlikely()s</span>
<span class="p_del">-   are unnecessary now for any paths leading to the usual suspects</span>
<span class="p_del">-   like BUG(), printk(), panic() etc. [but let&#39;s keep them for now for</span>
<span class="p_del">-   older compilers]</span>
<span class="p_del">-</span>
<span class="p_del">-   Early snapshots of gcc 4.3 don&#39;t support this and we can&#39;t detect this</span>
<span class="p_del">-   in the preprocessor, but we can live with this because they&#39;re unreleased.</span>
<span class="p_del">-   Maketime probing would be overkill here.</span>
<span class="p_del">-</span>
<span class="p_del">-   gcc also has a __attribute__((__hot__)) to move hot functions into</span>
<span class="p_del">-   a special section, but I don&#39;t see any sense in this right now in</span>
<span class="p_del">-   the kernel context */</span>
<span class="p_del">-#define __cold			__attribute__((__cold__))</span>
<span class="p_del">-</span>
<span class="p_del">-#define __UNIQUE_ID(prefix) __PASTE(__PASTE(__UNIQUE_ID_, prefix), __COUNTER__)</span>
<span class="p_del">-</span>
<span class="p_del">-#ifndef __CHECKER__</span>
<span class="p_del">-# define __compiletime_warning(message) __attribute__((warning(message)))</span>
<span class="p_del">-# define __compiletime_error(message) __attribute__((error(message)))</span>
<span class="p_del">-#endif /* __CHECKER__ */</span>
<span class="p_del">-#endif /* GCC_VERSION &gt;= 40300 */</span>
<span class="p_del">-</span>
<span class="p_del">-#if GCC_VERSION &gt;= 40500</span>
<span class="p_del">-/*</span>
<span class="p_del">- * Mark a position in code as unreachable.  This can be used to</span>
<span class="p_del">- * suppress control flow warnings after asm blocks that transfer</span>
<span class="p_del">- * control elsewhere.</span>
<span class="p_del">- *</span>
<span class="p_del">- * Early snapshots of gcc 4.5 don&#39;t support this and we can&#39;t detect</span>
<span class="p_del">- * this in the preprocessor, but we can live with this because they&#39;re</span>
<span class="p_del">- * unreleased.  Really, we need to have autoconf for the kernel.</span>
<span class="p_del">- */</span>
<span class="p_del">-#define unreachable() __builtin_unreachable()</span>
<span class="p_del">-</span>
<span class="p_del">-/* Mark a function definition as prohibited from being cloned. */</span>
<span class="p_del">-#define __noclone	__attribute__((__noclone__, __optimize__(&quot;no-tracer&quot;)))</span>
<span class="p_del">-</span>
<span class="p_del">-#endif /* GCC_VERSION &gt;= 40500 */</span>
<span class="p_del">-</span>
<span class="p_del">-#if GCC_VERSION &gt;= 40600</span>
<span class="p_del">-/*</span>
<span class="p_del">- * Tell the optimizer that something else uses this function or variable.</span>
<span class="p_del">- */</span>
<span class="p_del">-#define __visible __attribute__((externally_visible))</span>
<span class="p_del">-#endif</span>
<span class="p_del">-</span>
<span class="p_del">-/*</span>
<span class="p_del">- * GCC &#39;asm goto&#39; miscompiles certain code sequences:</span>
<span class="p_del">- *</span>
<span class="p_del">- *   http://gcc.gnu.org/bugzilla/show_bug.cgi?id=58670</span>
<span class="p_del">- *</span>
<span class="p_del">- * Work it around via a compiler barrier quirk suggested by Jakub Jelinek.</span>
<span class="p_del">- * Fixed in GCC 4.8.2 and later versions.</span>
<span class="p_del">- *</span>
<span class="p_del">- * (asm goto is automatically volatile - the naming reflects this.)</span>
<span class="p_del">- */</span>
<span class="p_del">-#define asm_volatile_goto(x...)	do { asm goto(x); asm (&quot;&quot;); } while (0)</span>
<span class="p_del">-</span>
<span class="p_del">-#ifdef CONFIG_ARCH_USE_BUILTIN_BSWAP</span>
<span class="p_del">-#if GCC_VERSION &gt;= 40400</span>
<span class="p_del">-#define __HAVE_BUILTIN_BSWAP32__</span>
<span class="p_del">-#define __HAVE_BUILTIN_BSWAP64__</span>
<span class="p_del">-#endif</span>
<span class="p_del">-#if GCC_VERSION &gt;= 40800 || (defined(__powerpc__) &amp;&amp; GCC_VERSION &gt;= 40600)</span>
<span class="p_del">-#define __HAVE_BUILTIN_BSWAP16__</span>
<span class="p_del">-#endif</span>
<span class="p_del">-#endif /* CONFIG_ARCH_USE_BUILTIN_BSWAP */</span>
<span class="p_header">diff --git a/include/linux/compiler-gcc5.h b/include/linux/compiler-gcc5.h</span>
deleted file mode 100644
<span class="p_header">index be39624de8b5..000000000000</span>
<span class="p_header">--- a/include/linux/compiler-gcc5.h</span>
<span class="p_header">+++ /dev/null</span>
<span class="p_chunk">@@ -1,66 +0,0 @@</span> <span class="p_context"></span>
<span class="p_del">-#ifndef __LINUX_COMPILER_H</span>
<span class="p_del">-#error &quot;Please don&#39;t include &lt;linux/compiler-gcc5.h&gt; directly, include &lt;linux/compiler.h&gt; instead.&quot;</span>
<span class="p_del">-#endif</span>
<span class="p_del">-</span>
<span class="p_del">-#define __used				__attribute__((__used__))</span>
<span class="p_del">-#define __must_check			__attribute__((warn_unused_result))</span>
<span class="p_del">-#define __compiler_offsetof(a, b)	__builtin_offsetof(a, b)</span>
<span class="p_del">-</span>
<span class="p_del">-/* Mark functions as cold. gcc will assume any path leading to a call</span>
<span class="p_del">-   to them will be unlikely.  This means a lot of manual unlikely()s</span>
<span class="p_del">-   are unnecessary now for any paths leading to the usual suspects</span>
<span class="p_del">-   like BUG(), printk(), panic() etc. [but let&#39;s keep them for now for</span>
<span class="p_del">-   older compilers]</span>
<span class="p_del">-</span>
<span class="p_del">-   Early snapshots of gcc 4.3 don&#39;t support this and we can&#39;t detect this</span>
<span class="p_del">-   in the preprocessor, but we can live with this because they&#39;re unreleased.</span>
<span class="p_del">-   Maketime probing would be overkill here.</span>
<span class="p_del">-</span>
<span class="p_del">-   gcc also has a __attribute__((__hot__)) to move hot functions into</span>
<span class="p_del">-   a special section, but I don&#39;t see any sense in this right now in</span>
<span class="p_del">-   the kernel context */</span>
<span class="p_del">-#define __cold			__attribute__((__cold__))</span>
<span class="p_del">-</span>
<span class="p_del">-#define __UNIQUE_ID(prefix) __PASTE(__PASTE(__UNIQUE_ID_, prefix), __COUNTER__)</span>
<span class="p_del">-</span>
<span class="p_del">-#ifndef __CHECKER__</span>
<span class="p_del">-# define __compiletime_warning(message) __attribute__((warning(message)))</span>
<span class="p_del">-# define __compiletime_error(message) __attribute__((error(message)))</span>
<span class="p_del">-#endif /* __CHECKER__ */</span>
<span class="p_del">-</span>
<span class="p_del">-/*</span>
<span class="p_del">- * Mark a position in code as unreachable.  This can be used to</span>
<span class="p_del">- * suppress control flow warnings after asm blocks that transfer</span>
<span class="p_del">- * control elsewhere.</span>
<span class="p_del">- *</span>
<span class="p_del">- * Early snapshots of gcc 4.5 don&#39;t support this and we can&#39;t detect</span>
<span class="p_del">- * this in the preprocessor, but we can live with this because they&#39;re</span>
<span class="p_del">- * unreleased.  Really, we need to have autoconf for the kernel.</span>
<span class="p_del">- */</span>
<span class="p_del">-#define unreachable() __builtin_unreachable()</span>
<span class="p_del">-</span>
<span class="p_del">-/* Mark a function definition as prohibited from being cloned. */</span>
<span class="p_del">-#define __noclone	__attribute__((__noclone__, __optimize__(&quot;no-tracer&quot;)))</span>
<span class="p_del">-</span>
<span class="p_del">-/*</span>
<span class="p_del">- * Tell the optimizer that something else uses this function or variable.</span>
<span class="p_del">- */</span>
<span class="p_del">-#define __visible __attribute__((externally_visible))</span>
<span class="p_del">-</span>
<span class="p_del">-/*</span>
<span class="p_del">- * GCC &#39;asm goto&#39; miscompiles certain code sequences:</span>
<span class="p_del">- *</span>
<span class="p_del">- *   http://gcc.gnu.org/bugzilla/show_bug.cgi?id=58670</span>
<span class="p_del">- *</span>
<span class="p_del">- * Work it around via a compiler barrier quirk suggested by Jakub Jelinek.</span>
<span class="p_del">- * Fixed in GCC 4.8.2 and later versions.</span>
<span class="p_del">- *</span>
<span class="p_del">- * (asm goto is automatically volatile - the naming reflects this.)</span>
<span class="p_del">- */</span>
<span class="p_del">-#define asm_volatile_goto(x...)	do { asm goto(x); asm (&quot;&quot;); } while (0)</span>
<span class="p_del">-</span>
<span class="p_del">-#ifdef CONFIG_ARCH_USE_BUILTIN_BSWAP</span>
<span class="p_del">-#define __HAVE_BUILTIN_BSWAP32__</span>
<span class="p_del">-#define __HAVE_BUILTIN_BSWAP64__</span>
<span class="p_del">-#define __HAVE_BUILTIN_BSWAP16__</span>
<span class="p_del">-#endif /* CONFIG_ARCH_USE_BUILTIN_BSWAP */</span>
<span class="p_header">diff --git a/include/linux/hash.h b/include/linux/hash.h</span>
<span class="p_header">index bd1754c7ecef..a75b1009d3f7 100644</span>
<span class="p_header">--- a/include/linux/hash.h</span>
<span class="p_header">+++ b/include/linux/hash.h</span>
<span class="p_chunk">@@ -33,10 +33,29 @@</span> <span class="p_context"></span>
 #error Wordsize not 32 or 64
 #endif
 
<span class="p_add">+/*</span>
<span class="p_add">+ * The above primes are actively bad for hashing, since they are</span>
<span class="p_add">+ * too sparse. The 32-bit one is mostly ok, the 64-bit one causes</span>
<span class="p_add">+ * real problems. Besides, the &quot;prime&quot; part is pointless for the</span>
<span class="p_add">+ * multiplicative hash.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * Although a random odd number will do, it turns out that the golden</span>
<span class="p_add">+ * ratio phi = (sqrt(5)-1)/2, or its negative, has particularly nice</span>
<span class="p_add">+ * properties.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * These are the negative, (1 - phi) = (phi^2) = (3 - sqrt(5))/2.</span>
<span class="p_add">+ * (See Knuth vol 3, section 6.4, exercise 9.)</span>
<span class="p_add">+ */</span>
<span class="p_add">+#define GOLDEN_RATIO_32 0x61C88647</span>
<span class="p_add">+#define GOLDEN_RATIO_64 0x61C8864680B583EBull</span>
<span class="p_add">+</span>
 static __always_inline u64 hash_64(u64 val, unsigned int bits)
 {
 	u64 hash = val;
 
<span class="p_add">+#if BITS_PER_LONG == 64</span>
<span class="p_add">+	hash = hash * GOLDEN_RATIO_64;</span>
<span class="p_add">+#else</span>
 	/*  Sigh, gcc can&#39;t optimise this alone like it does for 32 bits. */
 	u64 n = hash;
 	n &lt;&lt;= 18;
<span class="p_chunk">@@ -51,6 +70,7 @@</span> <span class="p_context"> static __always_inline u64 hash_64(u64 val, unsigned int bits)</span>
 	hash += n;
 	n &lt;&lt;= 2;
 	hash += n;
<span class="p_add">+#endif</span>
 
 	/* High bits are more random, so use them. */
 	return hash &gt;&gt; (64 - bits);
<span class="p_header">diff --git a/include/linux/hugetlb.h b/include/linux/hugetlb.h</span>
<span class="p_header">index 26534ba1aef3..62e94d2517bd 100644</span>
<span class="p_header">--- a/include/linux/hugetlb.h</span>
<span class="p_header">+++ b/include/linux/hugetlb.h</span>
<span class="p_chunk">@@ -416,15 +416,14 @@</span> <span class="p_context"> static inline spinlock_t *huge_pte_lockptr(struct hstate *h,</span>
 	return &amp;mm-&gt;page_table_lock;
 }
 
<span class="p_del">-static inline bool hugepages_supported(void)</span>
<span class="p_del">-{</span>
<span class="p_del">-	/*</span>
<span class="p_del">-	 * Some platform decide whether they support huge pages at boot</span>
<span class="p_del">-	 * time. On these, such as powerpc, HPAGE_SHIFT is set to 0 when</span>
<span class="p_del">-	 * there is no such support</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	return HPAGE_SHIFT != 0;</span>
<span class="p_del">-}</span>
<span class="p_add">+#ifndef hugepages_supported</span>
<span class="p_add">+/*</span>
<span class="p_add">+ * Some platform decide whether they support huge pages at boot</span>
<span class="p_add">+ * time. Some of them, such as powerpc, set HPAGE_SHIFT to 0</span>
<span class="p_add">+ * when there is no such support</span>
<span class="p_add">+ */</span>
<span class="p_add">+#define hugepages_supported() (HPAGE_SHIFT != 0)</span>
<span class="p_add">+#endif</span>
 
 #else	/* CONFIG_HUGETLB_PAGE */
 struct hstate {};
<span class="p_header">diff --git a/include/linux/mfd/samsung/s2mps11.h b/include/linux/mfd/samsung/s2mps11.h</span>
<span class="p_header">index b3ddf98dec37..8b1266895f71 100644</span>
<span class="p_header">--- a/include/linux/mfd/samsung/s2mps11.h</span>
<span class="p_header">+++ b/include/linux/mfd/samsung/s2mps11.h</span>
<span class="p_chunk">@@ -182,10 +182,12 @@</span> <span class="p_context"> enum s2mps11_regulators {</span>
 #define S2MPS11_LDO_STEP2	25000
 #define S2MPS11_LDO_VSEL_MASK	0x3F
 #define S2MPS11_BUCK_VSEL_MASK	0xFF
<span class="p_add">+#define S2MPS11_BUCK9_VSEL_MASK	0x1F</span>
 #define S2MPS11_ENABLE_MASK	(0x03 &lt;&lt; S2MPS11_ENABLE_SHIFT)
 #define S2MPS11_ENABLE_SHIFT	0x06
 #define S2MPS11_LDO_N_VOLTAGES	(S2MPS11_LDO_VSEL_MASK + 1)
 #define S2MPS11_BUCK_N_VOLTAGES (S2MPS11_BUCK_VSEL_MASK + 1)
<span class="p_add">+#define S2MPS11_BUCK9_N_VOLTAGES (S2MPS11_BUCK9_VSEL_MASK + 1)</span>
 #define S2MPS11_RAMP_DELAY	25000		/* uV/us */
 
 
<span class="p_header">diff --git a/include/linux/migrate.h b/include/linux/migrate.h</span>
<span class="p_header">index a2901c414664..b33347f4e4b7 100644</span>
<span class="p_header">--- a/include/linux/migrate.h</span>
<span class="p_header">+++ b/include/linux/migrate.h</span>
<span class="p_chunk">@@ -13,18 +13,9 @@</span> <span class="p_context"> typedef void free_page_t(struct page *page, unsigned long private);</span>
  * Return values from addresss_space_operations.migratepage():
  * - negative errno on page migration failure;
  * - zero on page migration success;
<span class="p_del">- *</span>
<span class="p_del">- * The balloon page migration introduces this special case where a &#39;distinct&#39;</span>
<span class="p_del">- * return code is used to flag a successful page migration to unmap_and_move().</span>
<span class="p_del">- * This approach is necessary because page migration can race against balloon</span>
<span class="p_del">- * deflation procedure, and for such case we could introduce a nasty page leak</span>
<span class="p_del">- * if a successfully migrated balloon page gets released concurrently with</span>
<span class="p_del">- * migration&#39;s unmap_and_move() wrap-up steps.</span>
  */
 #define MIGRATEPAGE_SUCCESS		0
<span class="p_del">-#define MIGRATEPAGE_BALLOON_SUCCESS	1 /* special ret code for balloon page</span>
<span class="p_del">-					   * sucessful migration case.</span>
<span class="p_del">-					   */</span>
<span class="p_add">+</span>
 enum migrate_reason {
 	MR_COMPACTION,
 	MR_MEMORY_FAILURE,
<span class="p_header">diff --git a/include/linux/mm.h b/include/linux/mm.h</span>
<span class="p_header">index 8ab91ce46487..7ac72a725798 100644</span>
<span class="p_header">--- a/include/linux/mm.h</span>
<span class="p_header">+++ b/include/linux/mm.h</span>
<span class="p_chunk">@@ -553,6 +553,25 @@</span> <span class="p_context"> static inline void __ClearPageBuddy(struct page *page)</span>
 	atomic_set(&amp;page-&gt;_mapcount, -1);
 }
 
<span class="p_add">+#define PAGE_BALLOON_MAPCOUNT_VALUE (-256)</span>
<span class="p_add">+</span>
<span class="p_add">+static inline int PageBalloon(struct page *page)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return atomic_read(&amp;page-&gt;_mapcount) == PAGE_BALLOON_MAPCOUNT_VALUE;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline void __SetPageBalloon(struct page *page)</span>
<span class="p_add">+{</span>
<span class="p_add">+	VM_BUG_ON_PAGE(atomic_read(&amp;page-&gt;_mapcount) != -1, page);</span>
<span class="p_add">+	atomic_set(&amp;page-&gt;_mapcount, PAGE_BALLOON_MAPCOUNT_VALUE);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline void __ClearPageBalloon(struct page *page)</span>
<span class="p_add">+{</span>
<span class="p_add">+	VM_BUG_ON_PAGE(!PageBalloon(page), page);</span>
<span class="p_add">+	atomic_set(&amp;page-&gt;_mapcount, -1);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 void put_page(struct page *page);
 void put_pages_list(struct list_head *pages);
 
<span class="p_header">diff --git a/include/linux/netdevice.h b/include/linux/netdevice.h</span>
<span class="p_header">index bfc3f9dfd928..b3404718fda1 100644</span>
<span class="p_header">--- a/include/linux/netdevice.h</span>
<span class="p_header">+++ b/include/linux/netdevice.h</span>
<span class="p_chunk">@@ -262,7 +262,6 @@</span> <span class="p_context"> struct header_ops {</span>
 	void	(*cache_update)(struct hh_cache *hh,
 				const struct net_device *dev,
 				const unsigned char *haddr);
<span class="p_del">-	bool	(*validate)(const char *ll_header, unsigned int len);</span>
 };
 
 /* These flag bits are private to the generic network queueing
<span class="p_chunk">@@ -1348,7 +1347,7 @@</span> <span class="p_context"> struct net_device {</span>
 
 	unsigned int		mtu;	/* interface MTU value		*/
 	unsigned short		type;	/* interface hardware type	*/
<span class="p_del">-	unsigned short		hard_header_len; /* maximum hardware hdr length	*/</span>
<span class="p_add">+	unsigned short		hard_header_len;	/* hardware hdr length	*/</span>
 
 	/* extra head- and tailroom the hardware may need, but not in all cases
 	 * can this be guaranteed, especially tailroom. Some cases also use
<span class="p_chunk">@@ -2072,24 +2071,6 @@</span> <span class="p_context"> static inline int dev_rebuild_header(struct sk_buff *skb)</span>
 	return dev-&gt;header_ops-&gt;rebuild(skb);
 }
 
<span class="p_del">-/* ll_header must have at least hard_header_len allocated */</span>
<span class="p_del">-static inline bool dev_validate_header(const struct net_device *dev,</span>
<span class="p_del">-				       char *ll_header, int len)</span>
<span class="p_del">-{</span>
<span class="p_del">-	if (likely(len &gt;= dev-&gt;hard_header_len))</span>
<span class="p_del">-		return true;</span>
<span class="p_del">-</span>
<span class="p_del">-	if (capable(CAP_SYS_RAWIO)) {</span>
<span class="p_del">-		memset(ll_header + len, 0, dev-&gt;hard_header_len - len);</span>
<span class="p_del">-		return true;</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">-	if (dev-&gt;header_ops &amp;&amp; dev-&gt;header_ops-&gt;validate)</span>
<span class="p_del">-		return dev-&gt;header_ops-&gt;validate(ll_header, len);</span>
<span class="p_del">-</span>
<span class="p_del">-	return false;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
 typedef int gifconf_func_t(struct net_device * dev, char __user * bufptr, int len);
 int register_gifconf(unsigned int family, gifconf_func_t *gifconf);
 static inline int unregister_gifconf(unsigned int family)
<span class="p_header">diff --git a/include/linux/usb_usual.h b/include/linux/usb_usual.h</span>
<span class="p_header">index 7f5f78bd15ad..245f57dbbb61 100644</span>
<span class="p_header">--- a/include/linux/usb_usual.h</span>
<span class="p_header">+++ b/include/linux/usb_usual.h</span>
<span class="p_chunk">@@ -79,6 +79,8 @@</span> <span class="p_context"></span>
 		/* Cannot handle MI_REPORT_SUPPORTED_OPERATION_CODES */	\
 	US_FLAG(MAX_SECTORS_240,	0x08000000)		\
 		/* Sets max_sectors to 240 */			\
<span class="p_add">+	US_FLAG(NO_REPORT_LUNS,	0x10000000)			\</span>
<span class="p_add">+		/* Cannot handle REPORT_LUNS */			\</span>
 
 #define US_FLAG(name, value)	US_FL_##name = value ,
 enum { US_DO_ALL_FLAGS };
<span class="p_header">diff --git a/include/rdma/ib.h b/include/rdma/ib.h</span>
<span class="p_header">index cf8f9e700e48..a6b93706b0fc 100644</span>
<span class="p_header">--- a/include/rdma/ib.h</span>
<span class="p_header">+++ b/include/rdma/ib.h</span>
<span class="p_chunk">@@ -34,6 +34,7 @@</span> <span class="p_context"></span>
 #define _RDMA_IB_H
 
 #include &lt;linux/types.h&gt;
<span class="p_add">+#include &lt;linux/sched.h&gt;</span>
 
 struct ib_addr {
 	union {
<span class="p_chunk">@@ -86,4 +87,19 @@</span> <span class="p_context"> struct sockaddr_ib {</span>
 	__u64			sib_scope_id;
 };
 
<span class="p_add">+/*</span>
<span class="p_add">+ * The IB interfaces that use write() as bi-directional ioctl() are</span>
<span class="p_add">+ * fundamentally unsafe, since there are lots of ways to trigger &quot;write()&quot;</span>
<span class="p_add">+ * calls from various contexts with elevated privileges. That includes the</span>
<span class="p_add">+ * traditional suid executable error message writes, but also various kernel</span>
<span class="p_add">+ * interfaces that can write to file descriptors.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * This function provides protection for the legacy API by restricting the</span>
<span class="p_add">+ * calling context.</span>
<span class="p_add">+ */</span>
<span class="p_add">+static inline bool ib_safe_file_access(struct file *filp)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return filp-&gt;f_cred == current_cred() &amp;&amp; segment_eq(get_fs(), USER_DS);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 #endif /* _RDMA_IB_H */
<span class="p_header">diff --git a/kernel/futex.c b/kernel/futex.c</span>
<span class="p_header">index 12b5f5264328..af67d3eaf232 100644</span>
<span class="p_header">--- a/kernel/futex.c</span>
<span class="p_header">+++ b/kernel/futex.c</span>
<span class="p_chunk">@@ -1398,8 +1398,8 @@</span> <span class="p_context"> void requeue_futex(struct futex_q *q, struct futex_hash_bucket *hb1,</span>
 	if (likely(&amp;hb1-&gt;chain != &amp;hb2-&gt;chain)) {
 		plist_del(&amp;q-&gt;list, &amp;hb1-&gt;chain);
 		hb_waiters_dec(hb1);
<span class="p_del">-		plist_add(&amp;q-&gt;list, &amp;hb2-&gt;chain);</span>
 		hb_waiters_inc(hb2);
<span class="p_add">+		plist_add(&amp;q-&gt;list, &amp;hb2-&gt;chain);</span>
 		q-&gt;lock_ptr = &amp;hb2-&gt;lock;
 	}
 	get_futex_key_refs(key2);
<span class="p_header">diff --git a/kernel/sched/core.c b/kernel/sched/core.c</span>
<span class="p_header">index 9cce028a77a4..8cbf68e6985d 100644</span>
<span class="p_header">--- a/kernel/sched/core.c</span>
<span class="p_header">+++ b/kernel/sched/core.c</span>
<span class="p_chunk">@@ -999,6 +999,13 @@</span> <span class="p_context"> inline int task_curr(const struct task_struct *p)</span>
 	return cpu_curr(task_cpu(p)) == p;
 }
 
<span class="p_add">+/*</span>
<span class="p_add">+ * switched_from, switched_to and prio_changed must _NOT_ drop rq-&gt;lock,</span>
<span class="p_add">+ * use the balance_callback list if you want balancing.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * this means any call to check_class_changed() must be followed by a call to</span>
<span class="p_add">+ * balance_callback().</span>
<span class="p_add">+ */</span>
 static inline void check_class_changed(struct rq *rq, struct task_struct *p,
 				       const struct sched_class *prev_class,
 				       int oldprio)
<span class="p_chunk">@@ -1500,8 +1507,12 @@</span> <span class="p_context"> ttwu_do_wakeup(struct rq *rq, struct task_struct *p, int wake_flags)</span>
 
 	p-&gt;state = TASK_RUNNING;
 #ifdef CONFIG_SMP
<span class="p_del">-	if (p-&gt;sched_class-&gt;task_woken)</span>
<span class="p_add">+	if (p-&gt;sched_class-&gt;task_woken) {</span>
<span class="p_add">+		/*</span>
<span class="p_add">+		 * XXX can drop rq-&gt;lock; most likely ok.</span>
<span class="p_add">+		 */</span>
 		p-&gt;sched_class-&gt;task_woken(rq, p);
<span class="p_add">+	}</span>
 
 	if (rq-&gt;idle_stamp) {
 		u64 delta = rq_clock(rq) - rq-&gt;idle_stamp;
<span class="p_chunk">@@ -2258,23 +2269,35 @@</span> <span class="p_context"> static void finish_task_switch(struct rq *rq, struct task_struct *prev)</span>
 #ifdef CONFIG_SMP
 
 /* rq-&gt;lock is NOT held, but preemption is disabled */
<span class="p_del">-static inline void post_schedule(struct rq *rq)</span>
<span class="p_add">+static void __balance_callback(struct rq *rq)</span>
 {
<span class="p_del">-	if (rq-&gt;post_schedule) {</span>
<span class="p_del">-		unsigned long flags;</span>
<span class="p_add">+	struct callback_head *head, *next;</span>
<span class="p_add">+	void (*func)(struct rq *rq);</span>
<span class="p_add">+	unsigned long flags;</span>
 
<span class="p_del">-		raw_spin_lock_irqsave(&amp;rq-&gt;lock, flags);</span>
<span class="p_del">-		if (rq-&gt;curr-&gt;sched_class-&gt;post_schedule)</span>
<span class="p_del">-			rq-&gt;curr-&gt;sched_class-&gt;post_schedule(rq);</span>
<span class="p_del">-		raw_spin_unlock_irqrestore(&amp;rq-&gt;lock, flags);</span>
<span class="p_add">+	raw_spin_lock_irqsave(&amp;rq-&gt;lock, flags);</span>
<span class="p_add">+	head = rq-&gt;balance_callback;</span>
<span class="p_add">+	rq-&gt;balance_callback = NULL;</span>
<span class="p_add">+	while (head) {</span>
<span class="p_add">+		func = (void (*)(struct rq *))head-&gt;func;</span>
<span class="p_add">+		next = head-&gt;next;</span>
<span class="p_add">+		head-&gt;next = NULL;</span>
<span class="p_add">+		head = next;</span>
 
<span class="p_del">-		rq-&gt;post_schedule = 0;</span>
<span class="p_add">+		func(rq);</span>
 	}
<span class="p_add">+	raw_spin_unlock_irqrestore(&amp;rq-&gt;lock, flags);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline void balance_callback(struct rq *rq)</span>
<span class="p_add">+{</span>
<span class="p_add">+	if (unlikely(rq-&gt;balance_callback))</span>
<span class="p_add">+		__balance_callback(rq);</span>
 }
 
 #else
 
<span class="p_del">-static inline void post_schedule(struct rq *rq)</span>
<span class="p_add">+static inline void balance_callback(struct rq *rq)</span>
 {
 }
 
<span class="p_chunk">@@ -2295,7 +2318,7 @@</span> <span class="p_context"> asmlinkage __visible void schedule_tail(struct task_struct *prev)</span>
 	 * FIXME: do we need to worry about rq being invalidated by the
 	 * task_switch?
 	 */
<span class="p_del">-	post_schedule(rq);</span>
<span class="p_add">+	balance_callback(rq);</span>
 
 #ifdef __ARCH_WANT_UNLOCKED_CTXSW
 	/* In this case, finish_task_switch does not reenable preemption */
<span class="p_chunk">@@ -2822,7 +2845,7 @@</span> <span class="p_context"> need_resched:</span>
 	} else
 		raw_spin_unlock_irq(&amp;rq-&gt;lock);
 
<span class="p_del">-	post_schedule(rq);</span>
<span class="p_add">+	balance_callback(rq);</span>
 
 	sched_preempt_enable_no_resched();
 	if (need_resched())
<span class="p_chunk">@@ -3040,7 +3063,11 @@</span> <span class="p_context"> void rt_mutex_setprio(struct task_struct *p, int prio)</span>
 
 	check_class_changed(rq, p, prev_class, oldprio);
 out_unlock:
<span class="p_add">+	preempt_disable(); /* avoid rq from going away on us */</span>
 	__task_rq_unlock(rq);
<span class="p_add">+</span>
<span class="p_add">+	balance_callback(rq);</span>
<span class="p_add">+	preempt_enable();</span>
 }
 #endif
 
<span class="p_chunk">@@ -3563,10 +3590,17 @@</span> <span class="p_context"> change:</span>
 	}
 
 	check_class_changed(rq, p, prev_class, oldprio);
<span class="p_add">+	preempt_disable(); /* avoid rq from going away on us */</span>
 	task_rq_unlock(rq, p, &amp;flags);
 
 	rt_mutex_adjust_pi(p);
 
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Run balance callbacks after we&#39;ve adjusted the PI chain.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	balance_callback(rq);</span>
<span class="p_add">+	preempt_enable();</span>
<span class="p_add">+</span>
 	return 0;
 }
 
<span class="p_chunk">@@ -7001,7 +7035,7 @@</span> <span class="p_context"> void __init sched_init(void)</span>
 		rq-&gt;sd = NULL;
 		rq-&gt;rd = NULL;
 		rq-&gt;cpu_capacity = SCHED_CAPACITY_SCALE;
<span class="p_del">-		rq-&gt;post_schedule = 0;</span>
<span class="p_add">+		rq-&gt;balance_callback = NULL;</span>
 		rq-&gt;active_balance = 0;
 		rq-&gt;next_balance = jiffies;
 		rq-&gt;push_cpu = 0;
<span class="p_header">diff --git a/kernel/sched/deadline.c b/kernel/sched/deadline.c</span>
<span class="p_header">index d10e40862f7f..ab8b917ce8f6 100644</span>
<span class="p_header">--- a/kernel/sched/deadline.c</span>
<span class="p_header">+++ b/kernel/sched/deadline.c</span>
<span class="p_chunk">@@ -213,9 +213,23 @@</span> <span class="p_context"> static inline bool need_pull_dl_task(struct rq *rq, struct task_struct *prev)</span>
 	return dl_task(prev);
 }
 
<span class="p_del">-static inline void set_post_schedule(struct rq *rq)</span>
<span class="p_add">+static DEFINE_PER_CPU(struct callback_head, dl_push_head);</span>
<span class="p_add">+static DEFINE_PER_CPU(struct callback_head, dl_pull_head);</span>
<span class="p_add">+</span>
<span class="p_add">+static void push_dl_tasks(struct rq *);</span>
<span class="p_add">+static void pull_dl_task(struct rq *);</span>
<span class="p_add">+</span>
<span class="p_add">+static inline void queue_push_tasks(struct rq *rq)</span>
<span class="p_add">+{</span>
<span class="p_add">+	if (!has_pushable_dl_tasks(rq))</span>
<span class="p_add">+		return;</span>
<span class="p_add">+</span>
<span class="p_add">+	queue_balance_callback(rq, &amp;per_cpu(dl_push_head, rq-&gt;cpu), push_dl_tasks);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline void queue_pull_task(struct rq *rq)</span>
 {
<span class="p_del">-	rq-&gt;post_schedule = has_pushable_dl_tasks(rq);</span>
<span class="p_add">+	queue_balance_callback(rq, &amp;per_cpu(dl_pull_head, rq-&gt;cpu), pull_dl_task);</span>
 }
 
 #else
<span class="p_chunk">@@ -245,12 +259,15 @@</span> <span class="p_context"> static inline bool need_pull_dl_task(struct rq *rq, struct task_struct *prev)</span>
 	return false;
 }
 
<span class="p_del">-static inline int pull_dl_task(struct rq *rq)</span>
<span class="p_add">+static inline void pull_dl_task(struct rq *rq)</span>
<span class="p_add">+{</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline void queue_push_tasks(struct rq *rq)</span>
 {
<span class="p_del">-	return 0;</span>
 }
 
<span class="p_del">-static inline void set_post_schedule(struct rq *rq)</span>
<span class="p_add">+static inline void queue_pull_task(struct rq *rq)</span>
 {
 }
 #endif /* CONFIG_SMP */
<span class="p_chunk">@@ -950,8 +967,6 @@</span> <span class="p_context"> static void check_preempt_equal_dl(struct rq *rq, struct task_struct *p)</span>
 	resched_task(rq-&gt;curr);
 }
 
<span class="p_del">-static int pull_dl_task(struct rq *this_rq);</span>
<span class="p_del">-</span>
 #endif /* CONFIG_SMP */
 
 /*
<span class="p_chunk">@@ -1043,7 +1058,7 @@</span> <span class="p_context"> struct task_struct *pick_next_task_dl(struct rq *rq, struct task_struct *prev)</span>
 		start_hrtick_dl(rq, p);
 #endif
 
<span class="p_del">-	set_post_schedule(rq);</span>
<span class="p_add">+	queue_push_tasks(rq);</span>
 
 	return p;
 }
<span class="p_chunk">@@ -1373,15 +1388,16 @@</span> <span class="p_context"> static void push_dl_tasks(struct rq *rq)</span>
 		;
 }
 
<span class="p_del">-static int pull_dl_task(struct rq *this_rq)</span>
<span class="p_add">+static void pull_dl_task(struct rq *this_rq)</span>
 {
<span class="p_del">-	int this_cpu = this_rq-&gt;cpu, ret = 0, cpu;</span>
<span class="p_add">+	int this_cpu = this_rq-&gt;cpu, cpu;</span>
 	struct task_struct *p;
<span class="p_add">+	bool resched = false;</span>
 	struct rq *src_rq;
 	u64 dmin = LONG_MAX;
 
 	if (likely(!dl_overloaded(this_rq)))
<span class="p_del">-		return 0;</span>
<span class="p_add">+		return;</span>
 
 	/*
 	 * Match the barrier from dl_set_overloaded; this guarantees that if we
<span class="p_chunk">@@ -1436,7 +1452,7 @@</span> <span class="p_context"> static int pull_dl_task(struct rq *this_rq)</span>
 					   src_rq-&gt;curr-&gt;dl.deadline))
 				goto skip;
 
<span class="p_del">-			ret = 1;</span>
<span class="p_add">+			resched = true;</span>
 
 			deactivate_task(src_rq, p, 0);
 			set_task_cpu(p, this_cpu);
<span class="p_chunk">@@ -1449,12 +1465,8 @@</span> <span class="p_context"> skip:</span>
 		double_unlock_balance(this_rq, src_rq);
 	}
 
<span class="p_del">-	return ret;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static void post_schedule_dl(struct rq *rq)</span>
<span class="p_del">-{</span>
<span class="p_del">-	push_dl_tasks(rq);</span>
<span class="p_add">+	if (resched)</span>
<span class="p_add">+		resched_task(this_rq-&gt;curr);</span>
 }
 
 /*
<span class="p_chunk">@@ -1559,7 +1571,7 @@</span> <span class="p_context"> static void switched_from_dl(struct rq *rq, struct task_struct *p)</span>
 	 * from an overloaded cpu, if any.
 	 */
 	if (!rq-&gt;dl.dl_nr_running)
<span class="p_del">-		pull_dl_task(rq);</span>
<span class="p_add">+		queue_pull_task(rq);</span>
 #endif
 }
 
<span class="p_chunk">@@ -1569,8 +1581,6 @@</span> <span class="p_context"> static void switched_from_dl(struct rq *rq, struct task_struct *p)</span>
  */
 static void switched_to_dl(struct rq *rq, struct task_struct *p)
 {
<span class="p_del">-	int check_resched = 1;</span>
<span class="p_del">-</span>
 	/*
 	 * If p is throttled, don&#39;t consider the possibility
 	 * of preempting rq-&gt;curr, the check will be done right
<span class="p_chunk">@@ -1581,12 +1591,12 @@</span> <span class="p_context"> static void switched_to_dl(struct rq *rq, struct task_struct *p)</span>
 
 	if (p-&gt;on_rq &amp;&amp; rq-&gt;curr != p) {
 #ifdef CONFIG_SMP
<span class="p_del">-		if (rq-&gt;dl.overloaded &amp;&amp; push_dl_task(rq) &amp;&amp; rq != task_rq(p))</span>
<span class="p_del">-			/* Only reschedule if pushing failed */</span>
<span class="p_del">-			check_resched = 0;</span>
<span class="p_del">-#endif /* CONFIG_SMP */</span>
<span class="p_del">-		if (check_resched &amp;&amp; task_has_dl_policy(rq-&gt;curr))</span>
<span class="p_add">+		if (rq-&gt;dl.overloaded)</span>
<span class="p_add">+			queue_push_tasks(rq);</span>
<span class="p_add">+#else</span>
<span class="p_add">+		if (task_has_dl_policy(rq-&gt;curr))</span>
 			check_preempt_curr_dl(rq, p, 0);
<span class="p_add">+#endif /* CONFIG_SMP */</span>
 	}
 }
 
<span class="p_chunk">@@ -1606,15 +1616,14 @@</span> <span class="p_context"> static void prio_changed_dl(struct rq *rq, struct task_struct *p,</span>
 		 * or lowering its prio, so...
 		 */
 		if (!rq-&gt;dl.overloaded)
<span class="p_del">-			pull_dl_task(rq);</span>
<span class="p_add">+			queue_pull_task(rq);</span>
 
 		/*
 		 * If we now have a earlier deadline task than p,
 		 * then reschedule, provided p is still on this
 		 * runqueue.
 		 */
<span class="p_del">-		if (dl_time_before(rq-&gt;dl.earliest_dl.curr, p-&gt;dl.deadline) &amp;&amp;</span>
<span class="p_del">-		    rq-&gt;curr == p)</span>
<span class="p_add">+		if (dl_time_before(rq-&gt;dl.earliest_dl.curr, p-&gt;dl.deadline))</span>
 			resched_task(p);
 #else
 		/*
<span class="p_chunk">@@ -1644,7 +1653,6 @@</span> <span class="p_context"> const struct sched_class dl_sched_class = {</span>
 	.set_cpus_allowed       = set_cpus_allowed_dl,
 	.rq_online              = rq_online_dl,
 	.rq_offline             = rq_offline_dl,
<span class="p_del">-	.post_schedule		= post_schedule_dl,</span>
 	.task_woken		= task_woken_dl,
 #endif
 
<span class="p_header">diff --git a/kernel/sched/rt.c b/kernel/sched/rt.c</span>
<span class="p_header">index 5d720ac96246..e0e5b3314c5b 100644</span>
<span class="p_header">--- a/kernel/sched/rt.c</span>
<span class="p_header">+++ b/kernel/sched/rt.c</span>
<span class="p_chunk">@@ -244,7 +244,7 @@</span> <span class="p_context"> int alloc_rt_sched_group(struct task_group *tg, struct task_group *parent)</span>
 
 #ifdef CONFIG_SMP
 
<span class="p_del">-static int pull_rt_task(struct rq *this_rq);</span>
<span class="p_add">+static void pull_rt_task(struct rq *this_rq);</span>
 
 static inline bool need_pull_rt_task(struct rq *rq, struct task_struct *prev)
 {
<span class="p_chunk">@@ -338,13 +338,23 @@</span> <span class="p_context"> static inline int has_pushable_tasks(struct rq *rq)</span>
 	return !plist_head_empty(&amp;rq-&gt;rt.pushable_tasks);
 }
 
<span class="p_del">-static inline void set_post_schedule(struct rq *rq)</span>
<span class="p_add">+static DEFINE_PER_CPU(struct callback_head, rt_push_head);</span>
<span class="p_add">+static DEFINE_PER_CPU(struct callback_head, rt_pull_head);</span>
<span class="p_add">+</span>
<span class="p_add">+static void push_rt_tasks(struct rq *);</span>
<span class="p_add">+static void pull_rt_task(struct rq *);</span>
<span class="p_add">+</span>
<span class="p_add">+static inline void queue_push_tasks(struct rq *rq)</span>
 {
<span class="p_del">-	/*</span>
<span class="p_del">-	 * We detect this state here so that we can avoid taking the RQ</span>
<span class="p_del">-	 * lock again later if there is no need to push</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	rq-&gt;post_schedule = has_pushable_tasks(rq);</span>
<span class="p_add">+	if (!has_pushable_tasks(rq))</span>
<span class="p_add">+		return;</span>
<span class="p_add">+</span>
<span class="p_add">+	queue_balance_callback(rq, &amp;per_cpu(rt_push_head, rq-&gt;cpu), push_rt_tasks);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline void queue_pull_task(struct rq *rq)</span>
<span class="p_add">+{</span>
<span class="p_add">+	queue_balance_callback(rq, &amp;per_cpu(rt_pull_head, rq-&gt;cpu), pull_rt_task);</span>
 }
 
 static void enqueue_pushable_task(struct rq *rq, struct task_struct *p)
<span class="p_chunk">@@ -396,12 +406,11 @@</span> <span class="p_context"> static inline bool need_pull_rt_task(struct rq *rq, struct task_struct *prev)</span>
 	return false;
 }
 
<span class="p_del">-static inline int pull_rt_task(struct rq *this_rq)</span>
<span class="p_add">+static inline void pull_rt_task(struct rq *this_rq)</span>
 {
<span class="p_del">-	return 0;</span>
 }
 
<span class="p_del">-static inline void set_post_schedule(struct rq *rq)</span>
<span class="p_add">+static inline void queue_push_tasks(struct rq *rq)</span>
 {
 }
 #endif /* CONFIG_SMP */
<span class="p_chunk">@@ -1472,7 +1481,7 @@</span> <span class="p_context"> pick_next_task_rt(struct rq *rq, struct task_struct *prev)</span>
 	if (p)
 		dequeue_pushable_task(rq, p);
 
<span class="p_del">-	set_post_schedule(rq);</span>
<span class="p_add">+	queue_push_tasks(rq);</span>
 
 	return p;
 }
<span class="p_chunk">@@ -1769,14 +1778,15 @@</span> <span class="p_context"> static void push_rt_tasks(struct rq *rq)</span>
 		;
 }
 
<span class="p_del">-static int pull_rt_task(struct rq *this_rq)</span>
<span class="p_add">+static void pull_rt_task(struct rq *this_rq)</span>
 {
<span class="p_del">-	int this_cpu = this_rq-&gt;cpu, ret = 0, cpu;</span>
<span class="p_add">+	int this_cpu = this_rq-&gt;cpu, cpu;</span>
<span class="p_add">+	bool resched = false;</span>
 	struct task_struct *p;
 	struct rq *src_rq;
 
 	if (likely(!rt_overloaded(this_rq)))
<span class="p_del">-		return 0;</span>
<span class="p_add">+		return;</span>
 
 	/*
 	 * Match the barrier from rt_set_overloaded; this guarantees that if we
<span class="p_chunk">@@ -1833,7 +1843,7 @@</span> <span class="p_context"> static int pull_rt_task(struct rq *this_rq)</span>
 			if (p-&gt;prio &lt; src_rq-&gt;curr-&gt;prio)
 				goto skip;
 
<span class="p_del">-			ret = 1;</span>
<span class="p_add">+			resched = true;</span>
 
 			deactivate_task(src_rq, p, 0);
 			set_task_cpu(p, this_cpu);
<span class="p_chunk">@@ -1849,12 +1859,8 @@</span> <span class="p_context"> skip:</span>
 		double_unlock_balance(this_rq, src_rq);
 	}
 
<span class="p_del">-	return ret;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static void post_schedule_rt(struct rq *rq)</span>
<span class="p_del">-{</span>
<span class="p_del">-	push_rt_tasks(rq);</span>
<span class="p_add">+	if (resched)</span>
<span class="p_add">+		resched_task(this_rq-&gt;curr);</span>
 }
 
 /*
<span class="p_chunk">@@ -1950,8 +1956,7 @@</span> <span class="p_context"> static void switched_from_rt(struct rq *rq, struct task_struct *p)</span>
 	if (!p-&gt;on_rq || rq-&gt;rt.rt_nr_running)
 		return;
 
<span class="p_del">-	if (pull_rt_task(rq))</span>
<span class="p_del">-		resched_task(rq-&gt;curr);</span>
<span class="p_add">+	queue_pull_task(rq);</span>
 }
 
 void __init init_sched_rt_class(void)
<span class="p_chunk">@@ -1972,8 +1977,6 @@</span> <span class="p_context"> void __init init_sched_rt_class(void)</span>
  */
 static void switched_to_rt(struct rq *rq, struct task_struct *p)
 {
<span class="p_del">-	int check_resched = 1;</span>
<span class="p_del">-</span>
 	/*
 	 * If we are already running, then there&#39;s nothing
 	 * that needs to be done. But if we are not running
<span class="p_chunk">@@ -1983,13 +1986,12 @@</span> <span class="p_context"> static void switched_to_rt(struct rq *rq, struct task_struct *p)</span>
 	 */
 	if (p-&gt;on_rq &amp;&amp; rq-&gt;curr != p) {
 #ifdef CONFIG_SMP
<span class="p_del">-		if (p-&gt;nr_cpus_allowed &gt; 1 &amp;&amp; rq-&gt;rt.overloaded &amp;&amp;</span>
<span class="p_del">-		    /* Don&#39;t resched if we changed runqueues */</span>
<span class="p_del">-		    push_rt_task(rq) &amp;&amp; rq != task_rq(p))</span>
<span class="p_del">-			check_resched = 0;</span>
<span class="p_del">-#endif /* CONFIG_SMP */</span>
<span class="p_del">-		if (check_resched &amp;&amp; p-&gt;prio &lt; rq-&gt;curr-&gt;prio)</span>
<span class="p_add">+		if (p-&gt;nr_cpus_allowed &gt; 1 &amp;&amp; rq-&gt;rt.overloaded)</span>
<span class="p_add">+			queue_push_tasks(rq);</span>
<span class="p_add">+#else</span>
<span class="p_add">+		if (p-&gt;prio &lt; rq-&gt;curr-&gt;prio)</span>
 			resched_task(rq-&gt;curr);
<span class="p_add">+#endif /* CONFIG_SMP */</span>
 	}
 }
 
<span class="p_chunk">@@ -2010,14 +2012,13 @@</span> <span class="p_context"> prio_changed_rt(struct rq *rq, struct task_struct *p, int oldprio)</span>
 		 * may need to pull tasks to this runqueue.
 		 */
 		if (oldprio &lt; p-&gt;prio)
<span class="p_del">-			pull_rt_task(rq);</span>
<span class="p_add">+			queue_pull_task(rq);</span>
<span class="p_add">+</span>
 		/*
 		 * If there&#39;s a higher priority task waiting to run
<span class="p_del">-		 * then reschedule. Note, the above pull_rt_task</span>
<span class="p_del">-		 * can release the rq lock and p could migrate.</span>
<span class="p_del">-		 * Only reschedule if p is still on the same runqueue.</span>
<span class="p_add">+		 * then reschedule.</span>
 		 */
<span class="p_del">-		if (p-&gt;prio &gt; rq-&gt;rt.highest_prio.curr &amp;&amp; rq-&gt;curr == p)</span>
<span class="p_add">+		if (p-&gt;prio &gt; rq-&gt;rt.highest_prio.curr)</span>
 			resched_task(p);
 #else
 		/* For UP simply resched on drop of prio */
<span class="p_chunk">@@ -2128,7 +2129,6 @@</span> <span class="p_context"> const struct sched_class rt_sched_class = {</span>
 	.set_cpus_allowed       = set_cpus_allowed_rt,
 	.rq_online              = rq_online_rt,
 	.rq_offline             = rq_offline_rt,
<span class="p_del">-	.post_schedule		= post_schedule_rt,</span>
 	.task_woken		= task_woken_rt,
 	.switched_from		= switched_from_rt,
 #endif
<span class="p_header">diff --git a/kernel/sched/sched.h b/kernel/sched/sched.h</span>
<span class="p_header">index 94353b16cfe5..3b45ba18f7f4 100644</span>
<span class="p_header">--- a/kernel/sched/sched.h</span>
<span class="p_header">+++ b/kernel/sched/sched.h</span>
<span class="p_chunk">@@ -569,9 +569,10 @@</span> <span class="p_context"> struct rq {</span>
 
 	unsigned long cpu_capacity;
 
<span class="p_add">+	struct callback_head *balance_callback;</span>
<span class="p_add">+</span>
 	unsigned char idle_balance;
 	/* For active balancing */
<span class="p_del">-	int post_schedule;</span>
 	int active_balance;
 	int push_cpu;
 	struct cpu_stop_work active_balance_work;
<span class="p_chunk">@@ -670,6 +671,21 @@</span> <span class="p_context"> extern int migrate_swap(struct task_struct *, struct task_struct *);</span>
 
 #ifdef CONFIG_SMP
 
<span class="p_add">+static inline void</span>
<span class="p_add">+queue_balance_callback(struct rq *rq,</span>
<span class="p_add">+		       struct callback_head *head,</span>
<span class="p_add">+		       void (*func)(struct rq *rq))</span>
<span class="p_add">+{</span>
<span class="p_add">+	lockdep_assert_held(&amp;rq-&gt;lock);</span>
<span class="p_add">+</span>
<span class="p_add">+	if (unlikely(head-&gt;next))</span>
<span class="p_add">+		return;</span>
<span class="p_add">+</span>
<span class="p_add">+	head-&gt;func = (void (*)(struct callback_head *))func;</span>
<span class="p_add">+	head-&gt;next = rq-&gt;balance_callback;</span>
<span class="p_add">+	rq-&gt;balance_callback = head;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 extern void sched_ttwu_pending(void);
 
 #define rcu_dereference_check_sched_domain(p) \
<span class="p_chunk">@@ -1127,7 +1143,6 @@</span> <span class="p_context"> struct sched_class {</span>
 	int  (*select_task_rq)(struct task_struct *p, int task_cpu, int sd_flag, int flags);
 	void (*migrate_task_rq)(struct task_struct *p, int next_cpu);
 
<span class="p_del">-	void (*post_schedule) (struct rq *this_rq);</span>
 	void (*task_waking) (struct task_struct *task);
 	void (*task_woken) (struct rq *this_rq, struct task_struct *task);
 
<span class="p_header">diff --git a/kernel/trace/trace_events.c b/kernel/trace/trace_events.c</span>
<span class="p_header">index ecf3e9fb8ee4..1e0729443d93 100644</span>
<span class="p_header">--- a/kernel/trace/trace_events.c</span>
<span class="p_header">+++ b/kernel/trace/trace_events.c</span>
<span class="p_chunk">@@ -1584,8 +1584,13 @@</span> <span class="p_context"> event_create_dir(struct dentry *parent, struct ftrace_event_file *file)</span>
 	trace_create_file(&quot;filter&quot;, 0644, file-&gt;dir, file,
 			  &amp;ftrace_event_filter_fops);
 
<span class="p_del">-	trace_create_file(&quot;trigger&quot;, 0644, file-&gt;dir, file,</span>
<span class="p_del">-			  &amp;event_trigger_fops);</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Only event directories that can be enabled should have</span>
<span class="p_add">+	 * triggers.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	if (!(call-&gt;flags &amp; TRACE_EVENT_FL_IGNORE_ENABLE))</span>
<span class="p_add">+		trace_create_file(&quot;trigger&quot;, 0644, file-&gt;dir, file,</span>
<span class="p_add">+				  &amp;event_trigger_fops);</span>
 
 	trace_create_file(&quot;format&quot;, 0444, file-&gt;dir, call,
 			  &amp;ftrace_event_format_fops);
<span class="p_header">diff --git a/kernel/workqueue.c b/kernel/workqueue.c</span>
<span class="p_header">index 6ab1f683ac49..5e6cafeeb048 100644</span>
<span class="p_header">--- a/kernel/workqueue.c</span>
<span class="p_header">+++ b/kernel/workqueue.c</span>
<span class="p_chunk">@@ -634,6 +634,35 @@</span> <span class="p_context"> static void set_work_pool_and_clear_pending(struct work_struct *work,</span>
 	 */
 	smp_wmb();
 	set_work_data(work, (unsigned long)pool_id &lt;&lt; WORK_OFFQ_POOL_SHIFT, 0);
<span class="p_add">+	/*</span>
<span class="p_add">+	 * The following mb guarantees that previous clear of a PENDING bit</span>
<span class="p_add">+	 * will not be reordered with any speculative LOADS or STORES from</span>
<span class="p_add">+	 * work-&gt;current_func, which is executed afterwards.  This possible</span>
<span class="p_add">+	 * reordering can lead to a missed execution on attempt to qeueue</span>
<span class="p_add">+	 * the same @work.  E.g. consider this case:</span>
<span class="p_add">+	 *</span>
<span class="p_add">+	 *   CPU#0                         CPU#1</span>
<span class="p_add">+	 *   ----------------------------  --------------------------------</span>
<span class="p_add">+	 *</span>
<span class="p_add">+	 * 1  STORE event_indicated</span>
<span class="p_add">+	 * 2  queue_work_on() {</span>
<span class="p_add">+	 * 3    test_and_set_bit(PENDING)</span>
<span class="p_add">+	 * 4 }                             set_..._and_clear_pending() {</span>
<span class="p_add">+	 * 5                                 set_work_data() # clear bit</span>
<span class="p_add">+	 * 6                                 smp_mb()</span>
<span class="p_add">+	 * 7                               work-&gt;current_func() {</span>
<span class="p_add">+	 * 8				      LOAD event_indicated</span>
<span class="p_add">+	 *				   }</span>
<span class="p_add">+	 *</span>
<span class="p_add">+	 * Without an explicit full barrier speculative LOAD on line 8 can</span>
<span class="p_add">+	 * be executed before CPU#0 does STORE on line 1.  If that happens,</span>
<span class="p_add">+	 * CPU#0 observes the PENDING bit is still set and new execution of</span>
<span class="p_add">+	 * a @work is not queued in a hope, that CPU#1 will eventually</span>
<span class="p_add">+	 * finish the queued @work.  Meanwhile CPU#1 does not see</span>
<span class="p_add">+	 * event_indicated is set, because speculative LOAD was executed</span>
<span class="p_add">+	 * before actual STORE.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	smp_mb();</span>
 }
 
 static void clear_work_data(struct work_struct *work)
<span class="p_header">diff --git a/lib/asn1_decoder.c b/lib/asn1_decoder.c</span>
<span class="p_header">index d60ce8a53650..806c5b6b4b3a 100644</span>
<span class="p_header">--- a/lib/asn1_decoder.c</span>
<span class="p_header">+++ b/lib/asn1_decoder.c</span>
<span class="p_chunk">@@ -69,7 +69,7 @@</span> <span class="p_context"> next_tag:</span>
 
 	/* Extract a tag from the data */
 	tag = data[dp++];
<span class="p_del">-	if (tag == 0) {</span>
<span class="p_add">+	if (tag == ASN1_EOC) {</span>
 		/* It appears to be an EOC. */
 		if (data[dp++] != 0)
 			goto invalid_eoc;
<span class="p_chunk">@@ -91,10 +91,8 @@</span> <span class="p_context"> next_tag:</span>
 
 	/* Extract the length */
 	len = data[dp++];
<span class="p_del">-	if (len &lt;= 0x7f) {</span>
<span class="p_del">-		dp += len;</span>
<span class="p_del">-		goto next_tag;</span>
<span class="p_del">-	}</span>
<span class="p_add">+	if (len &lt;= 0x7f)</span>
<span class="p_add">+		goto check_length;</span>
 
 	if (unlikely(len == ASN1_INDEFINITE_LENGTH)) {
 		/* Indefinite length */
<span class="p_chunk">@@ -105,14 +103,18 @@</span> <span class="p_context"> next_tag:</span>
 	}
 
 	n = len - 0x80;
<span class="p_del">-	if (unlikely(n &gt; sizeof(size_t) - 1))</span>
<span class="p_add">+	if (unlikely(n &gt; sizeof(len) - 1))</span>
 		goto length_too_long;
 	if (unlikely(n &gt; datalen - dp))
 		goto data_overrun_error;
<span class="p_del">-	for (len = 0; n &gt; 0; n--) {</span>
<span class="p_add">+	len = 0;</span>
<span class="p_add">+	for (; n &gt; 0; n--) {</span>
 		len &lt;&lt;= 8;
 		len |= data[dp++];
 	}
<span class="p_add">+check_length:</span>
<span class="p_add">+	if (len &gt; datalen - dp)</span>
<span class="p_add">+		goto data_overrun_error;</span>
 	dp += len;
 	goto next_tag;
 
<span class="p_header">diff --git a/lib/assoc_array.c b/lib/assoc_array.c</span>
<span class="p_header">index 2404d03e251a..03a77f4740c1 100644</span>
<span class="p_header">--- a/lib/assoc_array.c</span>
<span class="p_header">+++ b/lib/assoc_array.c</span>
<span class="p_chunk">@@ -523,7 +523,9 @@</span> <span class="p_context"> static bool assoc_array_insert_into_terminal_node(struct assoc_array_edit *edit,</span>
 			free_slot = i;
 			continue;
 		}
<span class="p_del">-		if (ops-&gt;compare_object(assoc_array_ptr_to_leaf(ptr), index_key)) {</span>
<span class="p_add">+		if (assoc_array_ptr_is_leaf(ptr) &amp;&amp;</span>
<span class="p_add">+		    ops-&gt;compare_object(assoc_array_ptr_to_leaf(ptr),</span>
<span class="p_add">+					index_key)) {</span>
 			pr_devel(&quot;replace in slot %d\n&quot;, i);
 			edit-&gt;leaf_p = &amp;node-&gt;slots[i];
 			edit-&gt;dead_leaf = node-&gt;slots[i];
<span class="p_header">diff --git a/lib/lz4/lz4defs.h b/lib/lz4/lz4defs.h</span>
<span class="p_header">index abcecdc2d0f2..0710a62ad2f6 100644</span>
<span class="p_header">--- a/lib/lz4/lz4defs.h</span>
<span class="p_header">+++ b/lib/lz4/lz4defs.h</span>
<span class="p_chunk">@@ -11,8 +11,7 @@</span> <span class="p_context"></span>
 /*
  * Detects 64 bits mode
  */
<span class="p_del">-#if (defined(__x86_64__) || defined(__x86_64) || defined(__amd64__) \</span>
<span class="p_del">-	|| defined(__ppc64__) || defined(__LP64__))</span>
<span class="p_add">+#if defined(CONFIG_64BIT)</span>
 #define LZ4_ARCH64 1
 #else
 #define LZ4_ARCH64 0
<span class="p_chunk">@@ -35,6 +34,10 @@</span> <span class="p_context"> typedef struct _U64_S { u64 v; } U64_S;</span>
 
 #define PUT4(s, d) (A32(d) = A32(s))
 #define PUT8(s, d) (A64(d) = A64(s))
<span class="p_add">+</span>
<span class="p_add">+#define LZ4_READ_LITTLEENDIAN_16(d, s, p)	\</span>
<span class="p_add">+	(d = s - A16(p))</span>
<span class="p_add">+</span>
 #define LZ4_WRITE_LITTLEENDIAN_16(p, v)	\
 	do {	\
 		A16(p) = v; \
<span class="p_chunk">@@ -51,10 +54,13 @@</span> <span class="p_context"> typedef struct _U64_S { u64 v; } U64_S;</span>
 #define PUT8(s, d) \
 	put_unaligned(get_unaligned((const u64 *) s), (u64 *) d)
 
<span class="p_del">-#define LZ4_WRITE_LITTLEENDIAN_16(p, v)	\</span>
<span class="p_del">-	do {	\</span>
<span class="p_del">-		put_unaligned(v, (u16 *)(p)); \</span>
<span class="p_del">-		p += 2; \</span>
<span class="p_add">+#define LZ4_READ_LITTLEENDIAN_16(d, s, p)	\</span>
<span class="p_add">+	(d = s - get_unaligned_le16(p))</span>
<span class="p_add">+</span>
<span class="p_add">+#define LZ4_WRITE_LITTLEENDIAN_16(p, v)			\</span>
<span class="p_add">+	do {						\</span>
<span class="p_add">+		put_unaligned_le16(v, (u16 *)(p));	\</span>
<span class="p_add">+		p += 2;					\</span>
 	} while (0)
 #endif
 
<span class="p_chunk">@@ -140,9 +146,6 @@</span> <span class="p_context"> typedef struct _U64_S { u64 v; } U64_S;</span>
 
 #endif
 
<span class="p_del">-#define LZ4_READ_LITTLEENDIAN_16(d, s, p) \</span>
<span class="p_del">-	(d = s - get_unaligned_le16(p))</span>
<span class="p_del">-</span>
 #define LZ4_WILDCOPY(s, d, e)		\
 	do {				\
 		LZ4_COPYPACKET(s, d);	\
<span class="p_header">diff --git a/mm/balloon_compaction.c b/mm/balloon_compaction.c</span>
<span class="p_header">index 9b0f218af70b..89440af54753 100644</span>
<span class="p_header">--- a/mm/balloon_compaction.c</span>
<span class="p_header">+++ b/mm/balloon_compaction.c</span>
<span class="p_chunk">@@ -94,16 +94,13 @@</span> <span class="p_context"> struct page *balloon_page_dequeue(struct balloon_dev_info *b_dev_info)</span>
 		 * to be released by the balloon driver.
 		 */
 		if (trylock_page(page)) {
<span class="p_del">-			/*</span>
<span class="p_del">-			 * Raise the page refcount here to prevent any wrong</span>
<span class="p_del">-			 * attempt to isolate this page, in case of coliding</span>
<span class="p_del">-			 * with balloon_page_isolate() just after we release</span>
<span class="p_del">-			 * the page lock.</span>
<span class="p_del">-			 *</span>
<span class="p_del">-			 * balloon_page_free() will take care of dropping</span>
<span class="p_del">-			 * this extra refcount later.</span>
<span class="p_del">-			 */</span>
<span class="p_del">-			get_page(page);</span>
<span class="p_add">+#ifdef CONFIG_BALLOON_COMPACTION</span>
<span class="p_add">+			if (!PagePrivate(page)) {</span>
<span class="p_add">+				/* raced with isolation */</span>
<span class="p_add">+				unlock_page(page);</span>
<span class="p_add">+				continue;</span>
<span class="p_add">+			}</span>
<span class="p_add">+#endif</span>
 			balloon_page_delete(page);
 			unlock_page(page);
 			dequeued_page = true;
<span class="p_chunk">@@ -187,7 +184,9 @@</span> <span class="p_context"> static inline void __isolate_balloon_page(struct page *page)</span>
 {
 	struct balloon_dev_info *b_dev_info = page-&gt;mapping-&gt;private_data;
 	unsigned long flags;
<span class="p_add">+</span>
 	spin_lock_irqsave(&amp;b_dev_info-&gt;pages_lock, flags);
<span class="p_add">+	ClearPagePrivate(page);</span>
 	list_del(&amp;page-&gt;lru);
 	b_dev_info-&gt;isolated_pages++;
 	spin_unlock_irqrestore(&amp;b_dev_info-&gt;pages_lock, flags);
<span class="p_chunk">@@ -197,7 +196,9 @@</span> <span class="p_context"> static inline void __putback_balloon_page(struct page *page)</span>
 {
 	struct balloon_dev_info *b_dev_info = page-&gt;mapping-&gt;private_data;
 	unsigned long flags;
<span class="p_add">+</span>
 	spin_lock_irqsave(&amp;b_dev_info-&gt;pages_lock, flags);
<span class="p_add">+	SetPagePrivate(page);</span>
 	list_add(&amp;page-&gt;lru, &amp;b_dev_info-&gt;pages);
 	b_dev_info-&gt;isolated_pages--;
 	spin_unlock_irqrestore(&amp;b_dev_info-&gt;pages_lock, flags);
<span class="p_chunk">@@ -235,12 +236,11 @@</span> <span class="p_context"> bool balloon_page_isolate(struct page *page)</span>
 		 */
 		if (likely(trylock_page(page))) {
 			/*
<span class="p_del">-			 * A ballooned page, by default, has just one refcount.</span>
<span class="p_add">+			 * A ballooned page, by default, has PagePrivate set.</span>
 			 * Prevent concurrent compaction threads from isolating
<span class="p_del">-			 * an already isolated balloon page by refcount check.</span>
<span class="p_add">+			 * an already isolated balloon page by clearing it.</span>
 			 */
<span class="p_del">-			if (__is_movable_balloon_page(page) &amp;&amp;</span>
<span class="p_del">-			    page_count(page) == 2) {</span>
<span class="p_add">+			if (balloon_page_movable(page)) {</span>
 				__isolate_balloon_page(page);
 				unlock_page(page);
 				return true;
<span class="p_header">diff --git a/mm/compaction.c b/mm/compaction.c</span>
<span class="p_header">index c7c6ae59f787..0ff73c7352ad 100644</span>
<span class="p_header">--- a/mm/compaction.c</span>
<span class="p_header">+++ b/mm/compaction.c</span>
<span class="p_chunk">@@ -597,7 +597,7 @@</span> <span class="p_context"> isolate_migratepages_range(struct zone *zone, struct compact_control *cc,</span>
 		 */
 		if (!PageLRU(page)) {
 			if (unlikely(balloon_page_movable(page))) {
<span class="p_del">-				if (locked &amp;&amp; balloon_page_isolate(page)) {</span>
<span class="p_add">+				if (balloon_page_isolate(page)) {</span>
 					/* Successfully isolated */
 					goto isolate_success;
 				}
<span class="p_header">diff --git a/mm/huge_memory.c b/mm/huge_memory.c</span>
<span class="p_header">index 479b57cc5195..dc528a51ccbf 100644</span>
<span class="p_header">--- a/mm/huge_memory.c</span>
<span class="p_header">+++ b/mm/huge_memory.c</span>
<span class="p_chunk">@@ -2068,10 +2068,9 @@</span> <span class="p_context"> int khugepaged_enter_vma_merge(struct vm_area_struct *vma,</span>
 		 * page fault if needed.
 		 */
 		return 0;
<span class="p_del">-	if (vma-&gt;vm_ops)</span>
<span class="p_add">+	if (vma-&gt;vm_ops || (vm_flags &amp; VM_NO_THP))</span>
 		/* khugepaged not yet working on file or special mappings */
 		return 0;
<span class="p_del">-	VM_BUG_ON(vm_flags &amp; VM_NO_THP);</span>
 	hstart = (vma-&gt;vm_start + ~HPAGE_PMD_MASK) &amp; HPAGE_PMD_MASK;
 	hend = vma-&gt;vm_end &amp; HPAGE_PMD_MASK;
 	if (hstart &lt; hend)
<span class="p_chunk">@@ -2376,8 +2375,7 @@</span> <span class="p_context"> static bool hugepage_vma_check(struct vm_area_struct *vma)</span>
 		return false;
 	if (is_vma_temporary_stack(vma))
 		return false;
<span class="p_del">-	VM_BUG_ON(vma-&gt;vm_flags &amp; VM_NO_THP);</span>
<span class="p_del">-	return true;</span>
<span class="p_add">+	return !(vma-&gt;vm_flags &amp; VM_NO_THP);</span>
 }
 
 static void collapse_huge_page(struct mm_struct *mm,
<span class="p_header">diff --git a/mm/migrate.c b/mm/migrate.c</span>
<span class="p_header">index f6296904a324..56d273e828d6 100644</span>
<span class="p_header">--- a/mm/migrate.c</span>
<span class="p_header">+++ b/mm/migrate.c</span>
<span class="p_chunk">@@ -30,6 +30,7 @@</span> <span class="p_context"></span>
 #include &lt;linux/mempolicy.h&gt;
 #include &lt;linux/vmalloc.h&gt;
 #include &lt;linux/security.h&gt;
<span class="p_add">+#include &lt;linux/backing-dev.h&gt;</span>
 #include &lt;linux/memcontrol.h&gt;
 #include &lt;linux/syscalls.h&gt;
 #include &lt;linux/hugetlb.h&gt;
<span class="p_chunk">@@ -342,6 +343,8 @@</span> <span class="p_context"> int migrate_page_move_mapping(struct address_space *mapping,</span>
 		struct buffer_head *head, enum migrate_mode mode,
 		int extra_count)
 {
<span class="p_add">+	struct zone *oldzone, *newzone;</span>
<span class="p_add">+	int dirty;</span>
 	int expected_count = 1 + extra_count;
 	void **pslot;
 
<span class="p_chunk">@@ -352,6 +355,9 @@</span> <span class="p_context"> int migrate_page_move_mapping(struct address_space *mapping,</span>
 		return MIGRATEPAGE_SUCCESS;
 	}
 
<span class="p_add">+	oldzone = page_zone(page);</span>
<span class="p_add">+	newzone = page_zone(newpage);</span>
<span class="p_add">+</span>
 	spin_lock_irq(&amp;mapping-&gt;tree_lock);
 
 	pslot = radix_tree_lookup_slot(&amp;mapping-&gt;page_tree,
<span class="p_chunk">@@ -392,6 +398,13 @@</span> <span class="p_context"> int migrate_page_move_mapping(struct address_space *mapping,</span>
 		set_page_private(newpage, page_private(page));
 	}
 
<span class="p_add">+	/* Move dirty while page refs frozen and newpage not yet exposed */</span>
<span class="p_add">+	dirty = PageDirty(page);</span>
<span class="p_add">+	if (dirty) {</span>
<span class="p_add">+		ClearPageDirty(page);</span>
<span class="p_add">+		SetPageDirty(newpage);</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
 	radix_tree_replace_slot(pslot, newpage);
 
 	/*
<span class="p_chunk">@@ -401,6 +414,9 @@</span> <span class="p_context"> int migrate_page_move_mapping(struct address_space *mapping,</span>
 	 */
 	page_unfreeze_refs(page, expected_count - 1);
 
<span class="p_add">+	spin_unlock(&amp;mapping-&gt;tree_lock);</span>
<span class="p_add">+	/* Leave irq disabled to prevent preemption while updating stats */</span>
<span class="p_add">+</span>
 	/*
 	 * If moved to a different zone then also account
 	 * the page for that zone. Other VM counters will be
<span class="p_chunk">@@ -411,13 +427,19 @@</span> <span class="p_context"> int migrate_page_move_mapping(struct address_space *mapping,</span>
 	 * via NR_FILE_PAGES and NR_ANON_PAGES if they
 	 * are mapped to swap space.
 	 */
<span class="p_del">-	__dec_zone_page_state(page, NR_FILE_PAGES);</span>
<span class="p_del">-	__inc_zone_page_state(newpage, NR_FILE_PAGES);</span>
<span class="p_del">-	if (!PageSwapCache(page) &amp;&amp; PageSwapBacked(page)) {</span>
<span class="p_del">-		__dec_zone_page_state(page, NR_SHMEM);</span>
<span class="p_del">-		__inc_zone_page_state(newpage, NR_SHMEM);</span>
<span class="p_add">+	if (newzone != oldzone) {</span>
<span class="p_add">+		__dec_zone_state(oldzone, NR_FILE_PAGES);</span>
<span class="p_add">+		__inc_zone_state(newzone, NR_FILE_PAGES);</span>
<span class="p_add">+		if (PageSwapBacked(page) &amp;&amp; !PageSwapCache(page)) {</span>
<span class="p_add">+			__dec_zone_state(oldzone, NR_SHMEM);</span>
<span class="p_add">+			__inc_zone_state(newzone, NR_SHMEM);</span>
<span class="p_add">+		}</span>
<span class="p_add">+		if (dirty &amp;&amp; mapping_cap_account_dirty(mapping)) {</span>
<span class="p_add">+			__dec_zone_state(oldzone, NR_FILE_DIRTY);</span>
<span class="p_add">+			__inc_zone_state(newzone, NR_FILE_DIRTY);</span>
<span class="p_add">+		}</span>
 	}
<span class="p_del">-	spin_unlock_irq(&amp;mapping-&gt;tree_lock);</span>
<span class="p_add">+	local_irq_enable();</span>
 
 	return MIGRATEPAGE_SUCCESS;
 }
<span class="p_chunk">@@ -541,20 +563,9 @@</span> <span class="p_context"> void migrate_page_copy(struct page *newpage, struct page *page)</span>
 	if (PageMappedToDisk(page))
 		SetPageMappedToDisk(newpage);
 
<span class="p_del">-	if (PageDirty(page)) {</span>
<span class="p_del">-		clear_page_dirty_for_io(page);</span>
<span class="p_del">-		/*</span>
<span class="p_del">-		 * Want to mark the page and the radix tree as dirty, and</span>
<span class="p_del">-		 * redo the accounting that clear_page_dirty_for_io undid,</span>
<span class="p_del">-		 * but we can&#39;t use set_page_dirty because that function</span>
<span class="p_del">-		 * is actually a signal that all of the page has become dirty.</span>
<span class="p_del">-		 * Whereas only part of our page may be dirty.</span>
<span class="p_del">-		 */</span>
<span class="p_del">-		if (PageSwapBacked(page))</span>
<span class="p_del">-			SetPageDirty(newpage);</span>
<span class="p_del">-		else</span>
<span class="p_del">-			__set_page_dirty_nobuffers(newpage);</span>
<span class="p_del">- 	}</span>
<span class="p_add">+	/* Move dirty on pages not done by migrate_page_move_mapping() */</span>
<span class="p_add">+	if (PageDirty(page))</span>
<span class="p_add">+		SetPageDirty(newpage);</span>
 
 	/*
 	 * Copy NUMA information to the new page, to prevent over-eager
<span class="p_chunk">@@ -879,7 +890,7 @@</span> <span class="p_context"> static int __unmap_and_move(struct page *page, struct page *newpage,</span>
 		}
 	}
 
<span class="p_del">-	if (unlikely(balloon_page_movable(page))) {</span>
<span class="p_add">+	if (unlikely(isolated_balloon_page(page))) {</span>
 		/*
 		 * A ballooned page does not need any special attention from
 		 * physical to virtual reverse mapping procedures.
<span class="p_chunk">@@ -928,8 +939,7 @@</span> <span class="p_context"> skip_unmap:</span>
 
 uncharge:
 	mem_cgroup_end_migration(mem, page, newpage,
<span class="p_del">-				 (rc == MIGRATEPAGE_SUCCESS ||</span>
<span class="p_del">-				  rc == MIGRATEPAGE_BALLOON_SUCCESS));</span>
<span class="p_add">+				 rc == MIGRATEPAGE_SUCCESS);</span>
 	unlock_page(page);
 out:
 	return rc;
<span class="p_chunk">@@ -961,17 +971,6 @@</span> <span class="p_context"> static int unmap_and_move(new_page_t get_new_page, free_page_t put_new_page,</span>
 
 	rc = __unmap_and_move(page, newpage, force, mode);
 
<span class="p_del">-	if (unlikely(rc == MIGRATEPAGE_BALLOON_SUCCESS)) {</span>
<span class="p_del">-		/*</span>
<span class="p_del">-		 * A ballooned page has been migrated already.</span>
<span class="p_del">-		 * Now, it&#39;s the time to wrap-up counters,</span>
<span class="p_del">-		 * handle the page back to Buddy and return.</span>
<span class="p_del">-		 */</span>
<span class="p_del">-		dec_zone_page_state(page, NR_ISOLATED_ANON +</span>
<span class="p_del">-				    page_is_file_cache(page));</span>
<span class="p_del">-		balloon_page_free(page);</span>
<span class="p_del">-		return MIGRATEPAGE_SUCCESS;</span>
<span class="p_del">-	}</span>
 out:
 	if (rc != -EAGAIN) {
 		/*
<span class="p_chunk">@@ -994,6 +993,9 @@</span> <span class="p_context"> out:</span>
 	if (rc != MIGRATEPAGE_SUCCESS &amp;&amp; put_new_page) {
 		ClearPageSwapBacked(newpage);
 		put_new_page(newpage, private);
<span class="p_add">+	} else if (unlikely(__is_movable_balloon_page(newpage))) {</span>
<span class="p_add">+		/* drop our reference, page already in the balloon */</span>
<span class="p_add">+		put_page(newpage);</span>
 	} else
 		putback_lru_page(newpage);
 
<span class="p_header">diff --git a/net/ax25/ax25_ip.c b/net/ax25/ax25_ip.c</span>
<span class="p_header">index 5ee8c6fc1a75..67de6b33f2c3 100644</span>
<span class="p_header">--- a/net/ax25/ax25_ip.c</span>
<span class="p_header">+++ b/net/ax25/ax25_ip.c</span>
<span class="p_chunk">@@ -231,24 +231,9 @@</span> <span class="p_context"> int ax25_rebuild_header(struct sk_buff *skb)</span>
 
 #endif
 
<span class="p_del">-static bool ax25_validate_header(const char *header, unsigned int len)</span>
<span class="p_del">-{</span>
<span class="p_del">-	ax25_digi digi;</span>
<span class="p_del">-</span>
<span class="p_del">-	if (!len)</span>
<span class="p_del">-		return false;</span>
<span class="p_del">-</span>
<span class="p_del">-	if (header[0])</span>
<span class="p_del">-		return true;</span>
<span class="p_del">-</span>
<span class="p_del">-	return ax25_addr_parse(header + 1, len - 1, NULL, NULL, &amp;digi, NULL,</span>
<span class="p_del">-			       NULL);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
 const struct header_ops ax25_header_ops = {
 	.create = ax25_hard_header,
 	.rebuild = ax25_rebuild_header,
<span class="p_del">-	.validate = ax25_validate_header,</span>
 };
 
 EXPORT_SYMBOL(ax25_hard_header);
<span class="p_header">diff --git a/net/batman-adv/distributed-arp-table.c b/net/batman-adv/distributed-arp-table.c</span>
<span class="p_header">index 28d70b941bb5..f49badcfd8a1 100644</span>
<span class="p_header">--- a/net/batman-adv/distributed-arp-table.c</span>
<span class="p_header">+++ b/net/batman-adv/distributed-arp-table.c</span>
<span class="p_chunk">@@ -521,6 +521,7 @@</span> <span class="p_context"> static void batadv_choose_next_candidate(struct batadv_priv *bat_priv,</span>
  * be sent to
  * @bat_priv: the bat priv with all the soft interface information
  * @ip_dst: ipv4 to look up in the DHT
<span class="p_add">+ * @vid: VLAN identifier</span>
  *
  * An originator O is selected if and only if its DHT_ID value is one of three
  * closest values (from the LEFT, with wrap around if needed) then the hash
<span class="p_chunk">@@ -529,11 +530,13 @@</span> <span class="p_context"> static void batadv_choose_next_candidate(struct batadv_priv *bat_priv,</span>
  * Returns the candidate array of size BATADV_DAT_CANDIDATE_NUM.
  */
 static struct batadv_dat_candidate *
<span class="p_del">-batadv_dat_select_candidates(struct batadv_priv *bat_priv, __be32 ip_dst)</span>
<span class="p_add">+batadv_dat_select_candidates(struct batadv_priv *bat_priv, __be32 ip_dst,</span>
<span class="p_add">+			     unsigned short vid)</span>
 {
 	int select;
 	batadv_dat_addr_t last_max = BATADV_DAT_ADDR_MAX, ip_key;
 	struct batadv_dat_candidate *res;
<span class="p_add">+	struct batadv_dat_entry dat;</span>
 
 	if (!bat_priv-&gt;orig_hash)
 		return NULL;
<span class="p_chunk">@@ -542,7 +545,9 @@</span> <span class="p_context"> batadv_dat_select_candidates(struct batadv_priv *bat_priv, __be32 ip_dst)</span>
 	if (!res)
 		return NULL;
 
<span class="p_del">-	ip_key = (batadv_dat_addr_t)batadv_hash_dat(&amp;ip_dst,</span>
<span class="p_add">+	dat.ip = ip_dst;</span>
<span class="p_add">+	dat.vid = vid;</span>
<span class="p_add">+	ip_key = (batadv_dat_addr_t)batadv_hash_dat(&amp;dat,</span>
 						    BATADV_DAT_ADDR_MAX);
 
 	batadv_dbg(BATADV_DBG_DAT, bat_priv,
<span class="p_chunk">@@ -561,6 +566,7 @@</span> <span class="p_context"> batadv_dat_select_candidates(struct batadv_priv *bat_priv, __be32 ip_dst)</span>
  * @bat_priv: the bat priv with all the soft interface information
  * @skb: payload to send
  * @ip: the DHT key
<span class="p_add">+ * @vid: VLAN identifier</span>
  * @packet_subtype: unicast4addr packet subtype to use
  *
  * This function copies the skb with pskb_copy() and is sent as unicast packet
<span class="p_chunk">@@ -571,7 +577,7 @@</span> <span class="p_context"> batadv_dat_select_candidates(struct batadv_priv *bat_priv, __be32 ip_dst)</span>
  */
 static bool batadv_dat_send_data(struct batadv_priv *bat_priv,
 				 struct sk_buff *skb, __be32 ip,
<span class="p_del">-				 int packet_subtype)</span>
<span class="p_add">+				 unsigned short vid, int packet_subtype)</span>
 {
 	int i;
 	bool ret = false;
<span class="p_chunk">@@ -580,7 +586,7 @@</span> <span class="p_context"> static bool batadv_dat_send_data(struct batadv_priv *bat_priv,</span>
 	struct sk_buff *tmp_skb;
 	struct batadv_dat_candidate *cand;
 
<span class="p_del">-	cand = batadv_dat_select_candidates(bat_priv, ip);</span>
<span class="p_add">+	cand = batadv_dat_select_candidates(bat_priv, ip, vid);</span>
 	if (!cand)
 		goto out;
 
<span class="p_chunk">@@ -969,7 +975,7 @@</span> <span class="p_context"> bool batadv_dat_snoop_outgoing_arp_request(struct batadv_priv *bat_priv,</span>
 		ret = true;
 	} else {
 		/* Send the request to the DHT */
<span class="p_del">-		ret = batadv_dat_send_data(bat_priv, skb, ip_dst,</span>
<span class="p_add">+		ret = batadv_dat_send_data(bat_priv, skb, ip_dst, vid,</span>
 					   BATADV_P_DAT_DHT_GET);
 	}
 out:
<span class="p_chunk">@@ -1097,8 +1103,8 @@</span> <span class="p_context"> void batadv_dat_snoop_outgoing_arp_reply(struct batadv_priv *bat_priv,</span>
 	/* Send the ARP reply to the candidates for both the IP addresses that
 	 * the node obtained from the ARP reply
 	 */
<span class="p_del">-	batadv_dat_send_data(bat_priv, skb, ip_src, BATADV_P_DAT_DHT_PUT);</span>
<span class="p_del">-	batadv_dat_send_data(bat_priv, skb, ip_dst, BATADV_P_DAT_DHT_PUT);</span>
<span class="p_add">+	batadv_dat_send_data(bat_priv, skb, ip_src, vid, BATADV_P_DAT_DHT_PUT);</span>
<span class="p_add">+	batadv_dat_send_data(bat_priv, skb, ip_dst, vid, BATADV_P_DAT_DHT_PUT);</span>
 }
 /**
  * batadv_dat_snoop_incoming_arp_reply - snoop the ARP reply and fill the local
<span class="p_header">diff --git a/net/batman-adv/routing.c b/net/batman-adv/routing.c</span>
<span class="p_header">index 35141534938e..fb0c4e6069a7 100644</span>
<span class="p_header">--- a/net/batman-adv/routing.c</span>
<span class="p_header">+++ b/net/batman-adv/routing.c</span>
<span class="p_chunk">@@ -88,6 +88,15 @@</span> <span class="p_context"> static void _batadv_update_route(struct batadv_priv *bat_priv,</span>
 		neigh_node = NULL;
 
 	spin_lock_bh(&amp;orig_node-&gt;neigh_list_lock);
<span class="p_add">+	/* curr_router used earlier may not be the current orig_ifinfo-&gt;router</span>
<span class="p_add">+	 * anymore because it was dereferenced outside of the neigh_list_lock</span>
<span class="p_add">+	 * protected region. After the new best neighbor has replace the current</span>
<span class="p_add">+	 * best neighbor the reference counter needs to decrease. Consequently,</span>
<span class="p_add">+	 * the code needs to ensure the curr_router variable contains a pointer</span>
<span class="p_add">+	 * to the replaced best neighbor.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	curr_router = rcu_dereference_protected(orig_ifinfo-&gt;router, true);</span>
<span class="p_add">+</span>
 	rcu_assign_pointer(orig_ifinfo-&gt;router, neigh_node);
 	spin_unlock_bh(&amp;orig_node-&gt;neigh_list_lock);
 	batadv_orig_ifinfo_free_ref(orig_ifinfo);
<span class="p_header">diff --git a/net/batman-adv/send.c b/net/batman-adv/send.c</span>
<span class="p_header">index 3d64ed20c393..6004c2de7b2a 100644</span>
<span class="p_header">--- a/net/batman-adv/send.c</span>
<span class="p_header">+++ b/net/batman-adv/send.c</span>
<span class="p_chunk">@@ -611,6 +611,9 @@</span> <span class="p_context"> batadv_purge_outstanding_packets(struct batadv_priv *bat_priv,</span>
 
 		if (pending) {
 			hlist_del(&amp;forw_packet-&gt;list);
<span class="p_add">+			if (!forw_packet-&gt;own)</span>
<span class="p_add">+				atomic_inc(&amp;bat_priv-&gt;bcast_queue_left);</span>
<span class="p_add">+</span>
 			batadv_forw_packet_free(forw_packet);
 		}
 	}
<span class="p_chunk">@@ -638,6 +641,9 @@</span> <span class="p_context"> batadv_purge_outstanding_packets(struct batadv_priv *bat_priv,</span>
 
 		if (pending) {
 			hlist_del(&amp;forw_packet-&gt;list);
<span class="p_add">+			if (!forw_packet-&gt;own)</span>
<span class="p_add">+				atomic_inc(&amp;bat_priv-&gt;batman_queue_left);</span>
<span class="p_add">+</span>
 			batadv_forw_packet_free(forw_packet);
 		}
 	}
<span class="p_header">diff --git a/net/batman-adv/soft-interface.c b/net/batman-adv/soft-interface.c</span>
<span class="p_header">index 3348eccf3e22..ad40f170824d 100644</span>
<span class="p_header">--- a/net/batman-adv/soft-interface.c</span>
<span class="p_header">+++ b/net/batman-adv/soft-interface.c</span>
<span class="p_chunk">@@ -378,11 +378,17 @@</span> <span class="p_context"> void batadv_interface_rx(struct net_device *soft_iface,</span>
 	 */
 	nf_reset(skb);
 
<span class="p_add">+	if (unlikely(!pskb_may_pull(skb, ETH_HLEN)))</span>
<span class="p_add">+		goto dropped;</span>
<span class="p_add">+</span>
 	vid = batadv_get_vid(skb, 0);
 	ethhdr = eth_hdr(skb);
 
 	switch (ntohs(ethhdr-&gt;h_proto)) {
 	case ETH_P_8021Q:
<span class="p_add">+		if (!pskb_may_pull(skb, VLAN_ETH_HLEN))</span>
<span class="p_add">+			goto dropped;</span>
<span class="p_add">+</span>
 		vhdr = (struct vlan_ethhdr *)skb-&gt;data;
 
 		if (vhdr-&gt;h_vlan_encapsulated_proto != ethertype)
<span class="p_chunk">@@ -394,8 +400,6 @@</span> <span class="p_context"> void batadv_interface_rx(struct net_device *soft_iface,</span>
 	}
 
 	/* skb-&gt;dev &amp; skb-&gt;pkt_type are set here */
<span class="p_del">-	if (unlikely(!pskb_may_pull(skb, ETH_HLEN)))</span>
<span class="p_del">-		goto dropped;</span>
 	skb-&gt;protocol = eth_type_trans(skb, soft_iface);
 
 	/* should not be necessary anymore as we use skb_pull_rcsum()
<span class="p_header">diff --git a/net/batman-adv/translation-table.c b/net/batman-adv/translation-table.c</span>
<span class="p_header">index 57968d30f8c8..eadf11fa083d 100644</span>
<span class="p_header">--- a/net/batman-adv/translation-table.c</span>
<span class="p_header">+++ b/net/batman-adv/translation-table.c</span>
<span class="p_chunk">@@ -176,8 +176,10 @@</span> <span class="p_context"> batadv_tt_global_hash_find(struct batadv_priv *bat_priv, const uint8_t *addr,</span>
 static void
 batadv_tt_local_entry_free_ref(struct batadv_tt_local_entry *tt_local_entry)
 {
<span class="p_del">-	if (atomic_dec_and_test(&amp;tt_local_entry-&gt;common.refcount))</span>
<span class="p_add">+	if (atomic_dec_and_test(&amp;tt_local_entry-&gt;common.refcount)) {</span>
<span class="p_add">+		batadv_softif_vlan_free_ref(tt_local_entry-&gt;vlan);</span>
 		kfree_rcu(tt_local_entry, common.rcu);
<span class="p_add">+	}</span>
 }
 
 /**
<span class="p_chunk">@@ -595,6 +597,7 @@</span> <span class="p_context"> bool batadv_tt_local_add(struct net_device *soft_iface, const uint8_t *addr,</span>
 	atomic_set(&amp;tt_local-&gt;common.refcount, 2);
 	tt_local-&gt;last_seen = jiffies;
 	tt_local-&gt;common.added_at = tt_local-&gt;last_seen;
<span class="p_add">+	tt_local-&gt;vlan = vlan;</span>
 
 	/* the batman interface mac and multicast addresses should never be
 	 * purged
<span class="p_chunk">@@ -908,7 +911,6 @@</span> <span class="p_context"> int batadv_tt_local_seq_print_text(struct seq_file *seq, void *offset)</span>
 	struct batadv_tt_common_entry *tt_common_entry;
 	struct batadv_tt_local_entry *tt_local;
 	struct batadv_hard_iface *primary_if;
<span class="p_del">-	struct batadv_softif_vlan *vlan;</span>
 	struct hlist_head *head;
 	unsigned short vid;
 	uint32_t i;
<span class="p_chunk">@@ -944,14 +946,6 @@</span> <span class="p_context"> int batadv_tt_local_seq_print_text(struct seq_file *seq, void *offset)</span>
 			last_seen_msecs = last_seen_msecs % 1000;
 
 			no_purge = tt_common_entry-&gt;flags &amp; np_flag;
<span class="p_del">-</span>
<span class="p_del">-			vlan = batadv_softif_vlan_get(bat_priv, vid);</span>
<span class="p_del">-			if (!vlan) {</span>
<span class="p_del">-				seq_printf(seq, &quot;Cannot retrieve VLAN %d\n&quot;,</span>
<span class="p_del">-					   BATADV_PRINT_VID(vid));</span>
<span class="p_del">-				continue;</span>
<span class="p_del">-			}</span>
<span class="p_del">-</span>
 			seq_printf(seq,
 				   &quot; * %pM %4i [%c%c%c%c%c%c] %3u.%03u   (%#.8x)\n&quot;,
 				   tt_common_entry-&gt;addr,
<span class="p_chunk">@@ -969,9 +963,7 @@</span> <span class="p_context"> int batadv_tt_local_seq_print_text(struct seq_file *seq, void *offset)</span>
 				    BATADV_TT_CLIENT_ISOLA ? &#39;I&#39; : &#39;.&#39;),
 				   no_purge ? 0 : last_seen_secs,
 				   no_purge ? 0 : last_seen_msecs,
<span class="p_del">-				   vlan-&gt;tt.crc);</span>
<span class="p_del">-</span>
<span class="p_del">-			batadv_softif_vlan_free_ref(vlan);</span>
<span class="p_add">+				   tt_local-&gt;vlan-&gt;tt.crc);</span>
 		}
 		rcu_read_unlock();
 	}
<span class="p_chunk">@@ -1016,7 +1008,6 @@</span> <span class="p_context"> uint16_t batadv_tt_local_remove(struct batadv_priv *bat_priv,</span>
 {
 	struct batadv_tt_local_entry *tt_local_entry;
 	uint16_t flags, curr_flags = BATADV_NO_FLAGS;
<span class="p_del">-	struct batadv_softif_vlan *vlan;</span>
 	void *tt_entry_exists;
 
 	tt_local_entry = batadv_tt_local_hash_find(bat_priv, addr, vid);
<span class="p_chunk">@@ -1056,14 +1047,6 @@</span> <span class="p_context"> uint16_t batadv_tt_local_remove(struct batadv_priv *bat_priv,</span>
 	/* extra call to free the local tt entry */
 	batadv_tt_local_entry_free_ref(tt_local_entry);
 
<span class="p_del">-	/* decrease the reference held for this vlan */</span>
<span class="p_del">-	vlan = batadv_softif_vlan_get(bat_priv, vid);</span>
<span class="p_del">-	if (!vlan)</span>
<span class="p_del">-		goto out;</span>
<span class="p_del">-</span>
<span class="p_del">-	batadv_softif_vlan_free_ref(vlan);</span>
<span class="p_del">-	batadv_softif_vlan_free_ref(vlan);</span>
<span class="p_del">-</span>
 out:
 	if (tt_local_entry)
 		batadv_tt_local_entry_free_ref(tt_local_entry);
<span class="p_chunk">@@ -1136,7 +1119,6 @@</span> <span class="p_context"> static void batadv_tt_local_table_free(struct batadv_priv *bat_priv)</span>
 	spinlock_t *list_lock; /* protects write access to the hash lists */
 	struct batadv_tt_common_entry *tt_common_entry;
 	struct batadv_tt_local_entry *tt_local;
<span class="p_del">-	struct batadv_softif_vlan *vlan;</span>
 	struct hlist_node *node_tmp;
 	struct hlist_head *head;
 	uint32_t i;
<span class="p_chunk">@@ -1158,14 +1140,6 @@</span> <span class="p_context"> static void batadv_tt_local_table_free(struct batadv_priv *bat_priv)</span>
 						struct batadv_tt_local_entry,
 						common);
 
<span class="p_del">-			/* decrease the reference held for this vlan */</span>
<span class="p_del">-			vlan = batadv_softif_vlan_get(bat_priv,</span>
<span class="p_del">-						      tt_common_entry-&gt;vid);</span>
<span class="p_del">-			if (vlan) {</span>
<span class="p_del">-				batadv_softif_vlan_free_ref(vlan);</span>
<span class="p_del">-				batadv_softif_vlan_free_ref(vlan);</span>
<span class="p_del">-			}</span>
<span class="p_del">-</span>
 			batadv_tt_local_entry_free_ref(tt_local);
 		}
 		spin_unlock_bh(list_lock);
<span class="p_chunk">@@ -3174,7 +3148,6 @@</span> <span class="p_context"> static void batadv_tt_local_purge_pending_clients(struct batadv_priv *bat_priv)</span>
 	struct batadv_hashtable *hash = bat_priv-&gt;tt.local_hash;
 	struct batadv_tt_common_entry *tt_common;
 	struct batadv_tt_local_entry *tt_local;
<span class="p_del">-	struct batadv_softif_vlan *vlan;</span>
 	struct hlist_node *node_tmp;
 	struct hlist_head *head;
 	spinlock_t *list_lock; /* protects write access to the hash lists */
<span class="p_chunk">@@ -3204,13 +3177,6 @@</span> <span class="p_context"> static void batadv_tt_local_purge_pending_clients(struct batadv_priv *bat_priv)</span>
 						struct batadv_tt_local_entry,
 						common);
 
<span class="p_del">-			/* decrease the reference held for this vlan */</span>
<span class="p_del">-			vlan = batadv_softif_vlan_get(bat_priv, tt_common-&gt;vid);</span>
<span class="p_del">-			if (vlan) {</span>
<span class="p_del">-				batadv_softif_vlan_free_ref(vlan);</span>
<span class="p_del">-				batadv_softif_vlan_free_ref(vlan);</span>
<span class="p_del">-			}</span>
<span class="p_del">-</span>
 			batadv_tt_local_entry_free_ref(tt_local);
 		}
 		spin_unlock_bh(list_lock);
<span class="p_header">diff --git a/net/batman-adv/types.h b/net/batman-adv/types.h</span>
<span class="p_header">index 27dddb453725..53f2833552f3 100644</span>
<span class="p_header">--- a/net/batman-adv/types.h</span>
<span class="p_header">+++ b/net/batman-adv/types.h</span>
<span class="p_chunk">@@ -934,10 +934,12 @@</span> <span class="p_context"> struct batadv_tt_common_entry {</span>
  * struct batadv_tt_local_entry - translation table local entry data
  * @common: general translation table data
  * @last_seen: timestamp used for purging stale tt local entries
<span class="p_add">+ * @vlan: soft-interface vlan of the entry</span>
  */
 struct batadv_tt_local_entry {
 	struct batadv_tt_common_entry common;
 	unsigned long last_seen;
<span class="p_add">+	struct batadv_softif_vlan *vlan;</span>
 };
 
 /**
<span class="p_header">diff --git a/net/ceph/auth.c b/net/ceph/auth.c</span>
<span class="p_header">index 6b923bcaa2a4..2bc5965fdd1e 100644</span>
<span class="p_header">--- a/net/ceph/auth.c</span>
<span class="p_header">+++ b/net/ceph/auth.c</span>
<span class="p_chunk">@@ -293,13 +293,9 @@</span> <span class="p_context"> int ceph_auth_create_authorizer(struct ceph_auth_client *ac,</span>
 }
 EXPORT_SYMBOL(ceph_auth_create_authorizer);
 
<span class="p_del">-void ceph_auth_destroy_authorizer(struct ceph_auth_client *ac,</span>
<span class="p_del">-				  struct ceph_authorizer *a)</span>
<span class="p_add">+void ceph_auth_destroy_authorizer(struct ceph_authorizer *a)</span>
 {
<span class="p_del">-	mutex_lock(&amp;ac-&gt;mutex);</span>
<span class="p_del">-	if (ac-&gt;ops &amp;&amp; ac-&gt;ops-&gt;destroy_authorizer)</span>
<span class="p_del">-		ac-&gt;ops-&gt;destroy_authorizer(ac, a);</span>
<span class="p_del">-	mutex_unlock(&amp;ac-&gt;mutex);</span>
<span class="p_add">+	a-&gt;destroy(a);</span>
 }
 EXPORT_SYMBOL(ceph_auth_destroy_authorizer);
 
<span class="p_header">diff --git a/net/ceph/auth_none.c b/net/ceph/auth_none.c</span>
<span class="p_header">index 8c93fa8d81bc..5f836f02ae36 100644</span>
<span class="p_header">--- a/net/ceph/auth_none.c</span>
<span class="p_header">+++ b/net/ceph/auth_none.c</span>
<span class="p_chunk">@@ -16,7 +16,6 @@</span> <span class="p_context"> static void reset(struct ceph_auth_client *ac)</span>
 	struct ceph_auth_none_info *xi = ac-&gt;private;
 
 	xi-&gt;starting = true;
<span class="p_del">-	xi-&gt;built_authorizer = false;</span>
 }
 
 static void destroy(struct ceph_auth_client *ac)
<span class="p_chunk">@@ -39,6 +38,27 @@</span> <span class="p_context"> static int should_authenticate(struct ceph_auth_client *ac)</span>
 	return xi-&gt;starting;
 }
 
<span class="p_add">+static int ceph_auth_none_build_authorizer(struct ceph_auth_client *ac,</span>
<span class="p_add">+					   struct ceph_none_authorizer *au)</span>
<span class="p_add">+{</span>
<span class="p_add">+	void *p = au-&gt;buf;</span>
<span class="p_add">+	void *const end = p + sizeof(au-&gt;buf);</span>
<span class="p_add">+	int ret;</span>
<span class="p_add">+</span>
<span class="p_add">+	ceph_encode_8_safe(&amp;p, end, 1, e_range);</span>
<span class="p_add">+	ret = ceph_entity_name_encode(ac-&gt;name, &amp;p, end);</span>
<span class="p_add">+	if (ret &lt; 0)</span>
<span class="p_add">+		return ret;</span>
<span class="p_add">+</span>
<span class="p_add">+	ceph_encode_64_safe(&amp;p, end, ac-&gt;global_id, e_range);</span>
<span class="p_add">+	au-&gt;buf_len = p - (void *)au-&gt;buf;</span>
<span class="p_add">+	dout(&quot;%s built authorizer len %d\n&quot;, __func__, au-&gt;buf_len);</span>
<span class="p_add">+	return 0;</span>
<span class="p_add">+</span>
<span class="p_add">+e_range:</span>
<span class="p_add">+	return -ERANGE;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static int build_request(struct ceph_auth_client *ac, void *buf, void *end)
 {
 	return 0;
<span class="p_chunk">@@ -57,32 +77,32 @@</span> <span class="p_context"> static int handle_reply(struct ceph_auth_client *ac, int result,</span>
 	return result;
 }
 
<span class="p_add">+static void ceph_auth_none_destroy_authorizer(struct ceph_authorizer *a)</span>
<span class="p_add">+{</span>
<span class="p_add">+	kfree(a);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 /*
<span class="p_del">- * build an &#39;authorizer&#39; with our entity_name and global_id.  we can</span>
<span class="p_del">- * reuse a single static copy since it is identical for all services</span>
<span class="p_del">- * we connect to.</span>
<span class="p_add">+ * build an &#39;authorizer&#39; with our entity_name and global_id.  it is</span>
<span class="p_add">+ * identical for all services we connect to.</span>
  */
 static int ceph_auth_none_create_authorizer(
 	struct ceph_auth_client *ac, int peer_type,
 	struct ceph_auth_handshake *auth)
 {
<span class="p_del">-	struct ceph_auth_none_info *ai = ac-&gt;private;</span>
<span class="p_del">-	struct ceph_none_authorizer *au = &amp;ai-&gt;au;</span>
<span class="p_del">-	void *p, *end;</span>
<span class="p_add">+	struct ceph_none_authorizer *au;</span>
 	int ret;
 
<span class="p_del">-	if (!ai-&gt;built_authorizer) {</span>
<span class="p_del">-		p = au-&gt;buf;</span>
<span class="p_del">-		end = p + sizeof(au-&gt;buf);</span>
<span class="p_del">-		ceph_encode_8(&amp;p, 1);</span>
<span class="p_del">-		ret = ceph_entity_name_encode(ac-&gt;name, &amp;p, end - 8);</span>
<span class="p_del">-		if (ret &lt; 0)</span>
<span class="p_del">-			goto bad;</span>
<span class="p_del">-		ceph_decode_need(&amp;p, end, sizeof(u64), bad2);</span>
<span class="p_del">-		ceph_encode_64(&amp;p, ac-&gt;global_id);</span>
<span class="p_del">-		au-&gt;buf_len = p - (void *)au-&gt;buf;</span>
<span class="p_del">-		ai-&gt;built_authorizer = true;</span>
<span class="p_del">-		dout(&quot;built authorizer len %d\n&quot;, au-&gt;buf_len);</span>
<span class="p_add">+	au = kmalloc(sizeof(*au), GFP_NOFS);</span>
<span class="p_add">+	if (!au)</span>
<span class="p_add">+		return -ENOMEM;</span>
<span class="p_add">+</span>
<span class="p_add">+	au-&gt;base.destroy = ceph_auth_none_destroy_authorizer;</span>
<span class="p_add">+</span>
<span class="p_add">+	ret = ceph_auth_none_build_authorizer(ac, au);</span>
<span class="p_add">+	if (ret) {</span>
<span class="p_add">+		kfree(au);</span>
<span class="p_add">+		return ret;</span>
 	}
 
 	auth-&gt;authorizer = (struct ceph_authorizer *) au;
<span class="p_chunk">@@ -92,17 +112,6 @@</span> <span class="p_context"> static int ceph_auth_none_create_authorizer(</span>
 	auth-&gt;authorizer_reply_buf_len = sizeof (au-&gt;reply_buf);
 
 	return 0;
<span class="p_del">-</span>
<span class="p_del">-bad2:</span>
<span class="p_del">-	ret = -ERANGE;</span>
<span class="p_del">-bad:</span>
<span class="p_del">-	return ret;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static void ceph_auth_none_destroy_authorizer(struct ceph_auth_client *ac,</span>
<span class="p_del">-				      struct ceph_authorizer *a)</span>
<span class="p_del">-{</span>
<span class="p_del">-	/* nothing to do */</span>
 }
 
 static const struct ceph_auth_client_ops ceph_auth_none_ops = {
<span class="p_chunk">@@ -114,7 +123,6 @@</span> <span class="p_context"> static const struct ceph_auth_client_ops ceph_auth_none_ops = {</span>
 	.build_request = build_request,
 	.handle_reply = handle_reply,
 	.create_authorizer = ceph_auth_none_create_authorizer,
<span class="p_del">-	.destroy_authorizer = ceph_auth_none_destroy_authorizer,</span>
 };
 
 int ceph_auth_none_init(struct ceph_auth_client *ac)
<span class="p_chunk">@@ -127,7 +135,6 @@</span> <span class="p_context"> int ceph_auth_none_init(struct ceph_auth_client *ac)</span>
 		return -ENOMEM;
 
 	xi-&gt;starting = true;
<span class="p_del">-	xi-&gt;built_authorizer = false;</span>
 
 	ac-&gt;protocol = CEPH_AUTH_NONE;
 	ac-&gt;private = xi;
<span class="p_header">diff --git a/net/ceph/auth_none.h b/net/ceph/auth_none.h</span>
<span class="p_header">index 059a3ce4b53f..62021535ae4a 100644</span>
<span class="p_header">--- a/net/ceph/auth_none.h</span>
<span class="p_header">+++ b/net/ceph/auth_none.h</span>
<span class="p_chunk">@@ -12,6 +12,7 @@</span> <span class="p_context"></span>
  */
 
 struct ceph_none_authorizer {
<span class="p_add">+	struct ceph_authorizer base;</span>
 	char buf[128];
 	int buf_len;
 	char reply_buf[0];
<span class="p_chunk">@@ -19,8 +20,6 @@</span> <span class="p_context"> struct ceph_none_authorizer {</span>
 
 struct ceph_auth_none_info {
 	bool starting;
<span class="p_del">-	bool built_authorizer;</span>
<span class="p_del">-	struct ceph_none_authorizer au;   /* we only need one; it&#39;s static */</span>
 };
 
 int ceph_auth_none_init(struct ceph_auth_client *ac);
<span class="p_header">diff --git a/net/ceph/auth_x.c b/net/ceph/auth_x.c</span>
<span class="p_header">index de6662b14e1f..ab2cc55b73a0 100644</span>
<span class="p_header">--- a/net/ceph/auth_x.c</span>
<span class="p_header">+++ b/net/ceph/auth_x.c</span>
<span class="p_chunk">@@ -538,6 +538,14 @@</span> <span class="p_context"> static int ceph_x_handle_reply(struct ceph_auth_client *ac, int result,</span>
 	return -EAGAIN;
 }
 
<span class="p_add">+static void ceph_x_destroy_authorizer(struct ceph_authorizer *a)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct ceph_x_authorizer *au = (void *)a;</span>
<span class="p_add">+</span>
<span class="p_add">+	ceph_buffer_put(au-&gt;buf);</span>
<span class="p_add">+	kfree(au);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static int ceph_x_create_authorizer(
 	struct ceph_auth_client *ac, int peer_type,
 	struct ceph_auth_handshake *auth)
<span class="p_chunk">@@ -554,6 +562,8 @@</span> <span class="p_context"> static int ceph_x_create_authorizer(</span>
 	if (!au)
 		return -ENOMEM;
 
<span class="p_add">+	au-&gt;base.destroy = ceph_x_destroy_authorizer;</span>
<span class="p_add">+</span>
 	ret = ceph_x_build_authorizer(ac, th, au);
 	if (ret) {
 		kfree(au);
<span class="p_chunk">@@ -618,16 +628,6 @@</span> <span class="p_context"> static int ceph_x_verify_authorizer_reply(struct ceph_auth_client *ac,</span>
 	return ret;
 }
 
<span class="p_del">-static void ceph_x_destroy_authorizer(struct ceph_auth_client *ac,</span>
<span class="p_del">-				      struct ceph_authorizer *a)</span>
<span class="p_del">-{</span>
<span class="p_del">-	struct ceph_x_authorizer *au = (void *)a;</span>
<span class="p_del">-</span>
<span class="p_del">-	ceph_buffer_put(au-&gt;buf);</span>
<span class="p_del">-	kfree(au);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-</span>
 static void ceph_x_reset(struct ceph_auth_client *ac)
 {
 	struct ceph_x_info *xi = ac-&gt;private;
<span class="p_chunk">@@ -678,7 +678,6 @@</span> <span class="p_context"> static const struct ceph_auth_client_ops ceph_x_ops = {</span>
 	.create_authorizer = ceph_x_create_authorizer,
 	.update_authorizer = ceph_x_update_authorizer,
 	.verify_authorizer_reply = ceph_x_verify_authorizer_reply,
<span class="p_del">-	.destroy_authorizer = ceph_x_destroy_authorizer,</span>
 	.invalidate_authorizer = ceph_x_invalidate_authorizer,
 	.reset =  ceph_x_reset,
 	.destroy = ceph_x_destroy,
<span class="p_header">diff --git a/net/ceph/auth_x.h b/net/ceph/auth_x.h</span>
<span class="p_header">index 65ee72082d99..2b06f4627c23 100644</span>
<span class="p_header">--- a/net/ceph/auth_x.h</span>
<span class="p_header">+++ b/net/ceph/auth_x.h</span>
<span class="p_chunk">@@ -26,6 +26,7 @@</span> <span class="p_context"> struct ceph_x_ticket_handler {</span>
 
 
 struct ceph_x_authorizer {
<span class="p_add">+	struct ceph_authorizer base;</span>
 	struct ceph_buffer *buf;
 	unsigned int service;
 	u64 nonce;
<span class="p_header">diff --git a/net/ceph/osd_client.c b/net/ceph/osd_client.c</span>
<span class="p_header">index 446548de09f8..b30776ab1e6e 100644</span>
<span class="p_header">--- a/net/ceph/osd_client.c</span>
<span class="p_header">+++ b/net/ceph/osd_client.c</span>
<span class="p_chunk">@@ -993,10 +993,9 @@</span> <span class="p_context"> static void put_osd(struct ceph_osd *osd)</span>
 {
 	dout(&quot;put_osd %p %d -&gt; %d\n&quot;, osd, atomic_read(&amp;osd-&gt;o_ref),
 	     atomic_read(&amp;osd-&gt;o_ref) - 1);
<span class="p_del">-	if (atomic_dec_and_test(&amp;osd-&gt;o_ref) &amp;&amp; osd-&gt;o_auth.authorizer) {</span>
<span class="p_del">-		struct ceph_auth_client *ac = osd-&gt;o_osdc-&gt;client-&gt;monc.auth;</span>
<span class="p_del">-</span>
<span class="p_del">-		ceph_auth_destroy_authorizer(ac, osd-&gt;o_auth.authorizer);</span>
<span class="p_add">+	if (atomic_dec_and_test(&amp;osd-&gt;o_ref)) {</span>
<span class="p_add">+		if (osd-&gt;o_auth.authorizer)</span>
<span class="p_add">+			ceph_auth_destroy_authorizer(osd-&gt;o_auth.authorizer);</span>
 		kfree(osd);
 	}
 }
<span class="p_chunk">@@ -2872,7 +2871,7 @@</span> <span class="p_context"> static struct ceph_auth_handshake *get_authorizer(struct ceph_connection *con,</span>
 	struct ceph_auth_handshake *auth = &amp;o-&gt;o_auth;
 
 	if (force_new &amp;&amp; auth-&gt;authorizer) {
<span class="p_del">-		ceph_auth_destroy_authorizer(ac, auth-&gt;authorizer);</span>
<span class="p_add">+		ceph_auth_destroy_authorizer(auth-&gt;authorizer);</span>
 		auth-&gt;authorizer = NULL;
 	}
 	if (!auth-&gt;authorizer) {
<span class="p_header">diff --git a/net/core/rtnetlink.c b/net/core/rtnetlink.c</span>
<span class="p_header">index 147c63784052..e4666af74141 100644</span>
<span class="p_header">--- a/net/core/rtnetlink.c</span>
<span class="p_header">+++ b/net/core/rtnetlink.c</span>
<span class="p_chunk">@@ -1013,14 +1013,16 @@</span> <span class="p_context"> static int rtnl_fill_ifinfo(struct sk_buff *skb, struct net_device *dev,</span>
 		goto nla_put_failure;
 
 	if (1) {
<span class="p_del">-		struct rtnl_link_ifmap map = {</span>
<span class="p_del">-			.mem_start   = dev-&gt;mem_start,</span>
<span class="p_del">-			.mem_end     = dev-&gt;mem_end,</span>
<span class="p_del">-			.base_addr   = dev-&gt;base_addr,</span>
<span class="p_del">-			.irq         = dev-&gt;irq,</span>
<span class="p_del">-			.dma         = dev-&gt;dma,</span>
<span class="p_del">-			.port        = dev-&gt;if_port,</span>
<span class="p_del">-		};</span>
<span class="p_add">+		struct rtnl_link_ifmap map;</span>
<span class="p_add">+</span>
<span class="p_add">+		memset(&amp;map, 0, sizeof(map));</span>
<span class="p_add">+		map.mem_start   = dev-&gt;mem_start;</span>
<span class="p_add">+		map.mem_end     = dev-&gt;mem_end;</span>
<span class="p_add">+		map.base_addr   = dev-&gt;base_addr;</span>
<span class="p_add">+		map.irq         = dev-&gt;irq;</span>
<span class="p_add">+		map.dma         = dev-&gt;dma;</span>
<span class="p_add">+		map.port        = dev-&gt;if_port;</span>
<span class="p_add">+</span>
 		if (nla_put(skb, IFLA_MAP, sizeof(map), &amp;map))
 			goto nla_put_failure;
 	}
<span class="p_header">diff --git a/net/llc/af_llc.c b/net/llc/af_llc.c</span>
<span class="p_header">index 0080d2b0a8ae..a76a67d38ec3 100644</span>
<span class="p_header">--- a/net/llc/af_llc.c</span>
<span class="p_header">+++ b/net/llc/af_llc.c</span>
<span class="p_chunk">@@ -626,6 +626,7 @@</span> <span class="p_context"> static void llc_cmsg_rcv(struct msghdr *msg, struct sk_buff *skb)</span>
 	if (llc-&gt;cmsg_flags &amp; LLC_CMSG_PKTINFO) {
 		struct llc_pktinfo info;
 
<span class="p_add">+		memset(&amp;info, 0, sizeof(info));</span>
 		info.lpi_ifindex = llc_sk(skb-&gt;sk)-&gt;dev-&gt;ifindex;
 		llc_pdu_decode_dsap(skb, &amp;info.lpi_sap);
 		llc_pdu_decode_da(skb, info.lpi_mac);
<span class="p_header">diff --git a/net/netfilter/nf_conntrack_core.c b/net/netfilter/nf_conntrack_core.c</span>
<span class="p_header">index 1f4f954c4b47..054638c824dd 100644</span>
<span class="p_header">--- a/net/netfilter/nf_conntrack_core.c</span>
<span class="p_header">+++ b/net/netfilter/nf_conntrack_core.c</span>
<span class="p_chunk">@@ -1791,6 +1791,7 @@</span> <span class="p_context"> void nf_conntrack_init_end(void)</span>
 
 int nf_conntrack_init_net(struct net *net)
 {
<span class="p_add">+	static atomic64_t unique_id;</span>
 	int ret = -ENOMEM;
 	int cpu;
 
<span class="p_chunk">@@ -1814,7 +1815,8 @@</span> <span class="p_context"> int nf_conntrack_init_net(struct net *net)</span>
 	if (!net-&gt;ct.stat)
 		goto err_pcpu_lists;
 
<span class="p_del">-	net-&gt;ct.slabname = kasprintf(GFP_KERNEL, &quot;nf_conntrack_%p&quot;, net);</span>
<span class="p_add">+	net-&gt;ct.slabname = kasprintf(GFP_KERNEL, &quot;nf_conntrack_%llu&quot;,</span>
<span class="p_add">+				(u64)atomic64_inc_return(&amp;unique_id));</span>
 	if (!net-&gt;ct.slabname)
 		goto err_slabname;
 
<span class="p_header">diff --git a/net/packet/af_packet.c b/net/packet/af_packet.c</span>
<span class="p_header">index b5c38ab3a93f..d6dfe65f4a74 100644</span>
<span class="p_header">--- a/net/packet/af_packet.c</span>
<span class="p_header">+++ b/net/packet/af_packet.c</span>
<span class="p_chunk">@@ -3155,6 +3155,7 @@</span> <span class="p_context"> static int packet_mc_add(struct sock *sk, struct packet_mreq_max *mreq)</span>
 	i-&gt;ifindex = mreq-&gt;mr_ifindex;
 	i-&gt;alen = mreq-&gt;mr_alen;
 	memcpy(i-&gt;addr, mreq-&gt;mr_address, i-&gt;alen);
<span class="p_add">+	memset(i-&gt;addr + i-&gt;alen, 0, sizeof(i-&gt;addr) - i-&gt;alen);</span>
 	i-&gt;count = 1;
 	i-&gt;next = po-&gt;mclist;
 	po-&gt;mclist = i;
<span class="p_header">diff --git a/net/wireless/nl80211.c b/net/wireless/nl80211.c</span>
<span class="p_header">index d316a9568238..56918f89a1d6 100644</span>
<span class="p_header">--- a/net/wireless/nl80211.c</span>
<span class="p_header">+++ b/net/wireless/nl80211.c</span>
<span class="p_chunk">@@ -11752,7 +11752,7 @@</span> <span class="p_context"> static int nl80211_netlink_notify(struct notifier_block * nb,</span>
 	struct wireless_dev *wdev;
 	struct cfg80211_beacon_registration *reg, *tmp;
 
<span class="p_del">-	if (state != NETLINK_URELEASE)</span>
<span class="p_add">+	if (state != NETLINK_URELEASE || notify-&gt;protocol != NETLINK_GENERIC)</span>
 		return NOTIFY_DONE;
 
 	rcu_read_lock();
<span class="p_header">diff --git a/net/x25/x25_facilities.c b/net/x25/x25_facilities.c</span>
<span class="p_header">index 7ecd04c21360..997ff7b2509b 100644</span>
<span class="p_header">--- a/net/x25/x25_facilities.c</span>
<span class="p_header">+++ b/net/x25/x25_facilities.c</span>
<span class="p_chunk">@@ -277,6 +277,7 @@</span> <span class="p_context"> int x25_negotiate_facilities(struct sk_buff *skb, struct sock *sk,</span>
 
 	memset(&amp;theirs, 0, sizeof(theirs));
 	memcpy(new, ours, sizeof(*new));
<span class="p_add">+	memset(dte, 0, sizeof(*dte));</span>
 
 	len = x25_parse_facilities(skb, &amp;theirs, dte, &amp;x25-&gt;vc_facil_mask);
 	if (len &lt; 0)
<span class="p_header">diff --git a/sound/pci/hda/patch_realtek.c b/sound/pci/hda/patch_realtek.c</span>
<span class="p_header">index 88c351ed416b..50d661fe4da0 100644</span>
<span class="p_header">--- a/sound/pci/hda/patch_realtek.c</span>
<span class="p_header">+++ b/sound/pci/hda/patch_realtek.c</span>
<span class="p_chunk">@@ -5024,6 +5024,7 @@</span> <span class="p_context"> static const struct snd_pci_quirk alc269_fixup_tbl[] = {</span>
 	SND_PCI_QUIRK(0x17aa, 0x5034, &quot;Thinkpad T450&quot;, ALC292_FIXUP_TPT440_DOCK),
 	SND_PCI_QUIRK(0x17aa, 0x5036, &quot;Thinkpad T450s&quot;, ALC292_FIXUP_TPT440_DOCK),
 	SND_PCI_QUIRK(0x17aa, 0x503c, &quot;Thinkpad L450&quot;, ALC292_FIXUP_TPT440_DOCK),
<span class="p_add">+	SND_PCI_QUIRK(0x17aa, 0x504a, &quot;ThinkPad X260&quot;, ALC292_FIXUP_TPT440_DOCK),</span>
 	SND_PCI_QUIRK(0x17aa, 0x504b, &quot;Thinkpad&quot;, ALC293_FIXUP_LENOVO_SPK_NOISE),
 	SND_PCI_QUIRK(0x17aa, 0x5109, &quot;Thinkpad&quot;, ALC269_FIXUP_LIMIT_INT_MIC_BOOST),
 	SND_PCI_QUIRK(0x17aa, 0x3bf8, &quot;Quanta FL1&quot;, ALC269_FIXUP_PCM_44K),
<span class="p_chunk">@@ -5828,6 +5829,7 @@</span> <span class="p_context"> enum {</span>
 	ALC668_FIXUP_DELL_DISABLE_AAMIX,
 	ALC668_FIXUP_DELL_XPS13,
 	ALC662_FIXUP_ASUS_Nx50,
<span class="p_add">+	ALC668_FIXUP_ASUS_Nx51,</span>
 };
 
 static const struct hda_fixup alc662_fixups[] = {
<span class="p_chunk">@@ -6060,6 +6062,15 @@</span> <span class="p_context"> static const struct hda_fixup alc662_fixups[] = {</span>
 		.chained = true,
 		.chain_id = ALC662_FIXUP_BASS_1A
 	},
<span class="p_add">+	[ALC668_FIXUP_ASUS_Nx51] = {</span>
<span class="p_add">+		.type = HDA_FIXUP_PINS,</span>
<span class="p_add">+		.v.pins = (const struct hda_pintbl[]) {</span>
<span class="p_add">+			{0x1a, 0x90170151}, /* bass speaker */</span>
<span class="p_add">+			{}</span>
<span class="p_add">+		},</span>
<span class="p_add">+		.chained = true,</span>
<span class="p_add">+		.chain_id = ALC662_FIXUP_BASS_CHMAP,</span>
<span class="p_add">+	},</span>
 };
 
 static const struct snd_pci_quirk alc662_fixup_tbl[] = {
<span class="p_chunk">@@ -6079,11 +6090,14 @@</span> <span class="p_context"> static const struct snd_pci_quirk alc662_fixup_tbl[] = {</span>
 	SND_PCI_QUIRK(0x1028, 0x0696, &quot;Dell&quot;, ALC668_FIXUP_DELL_MIC_NO_PRESENCE),
 	SND_PCI_QUIRK(0x1028, 0x0698, &quot;Dell&quot;, ALC668_FIXUP_DELL_MIC_NO_PRESENCE),
 	SND_PCI_QUIRK(0x103c, 0x1632, &quot;HP RP5800&quot;, ALC662_FIXUP_HP_RP5800),
<span class="p_add">+	SND_PCI_QUIRK(0x1043, 0x1080, &quot;Asus UX501VW&quot;, ALC668_FIXUP_HEADSET_MODE),</span>
 	SND_PCI_QUIRK(0x1043, 0x11cd, &quot;Asus N550&quot;, ALC662_FIXUP_ASUS_Nx50),
 	SND_PCI_QUIRK(0x1043, 0x13df, &quot;Asus N550JX&quot;, ALC662_FIXUP_BASS_1A),
 	SND_PCI_QUIRK(0x1043, 0x129d, &quot;Asus N750&quot;, ALC662_FIXUP_ASUS_Nx50),
 	SND_PCI_QUIRK(0x1043, 0x1477, &quot;ASUS N56VZ&quot;, ALC662_FIXUP_BASS_MODE4_CHMAP),
 	SND_PCI_QUIRK(0x1043, 0x15a7, &quot;ASUS UX51VZH&quot;, ALC662_FIXUP_BASS_16),
<span class="p_add">+	SND_PCI_QUIRK(0x1043, 0x177d, &quot;ASUS N551&quot;, ALC668_FIXUP_ASUS_Nx51),</span>
<span class="p_add">+	SND_PCI_QUIRK(0x1043, 0x17bd, &quot;ASUS N751&quot;, ALC668_FIXUP_ASUS_Nx51),</span>
 	SND_PCI_QUIRK(0x1043, 0x1b73, &quot;ASUS N55SF&quot;, ALC662_FIXUP_BASS_16),
 	SND_PCI_QUIRK(0x1043, 0x1bf3, &quot;ASUS N76VZ&quot;, ALC662_FIXUP_BASS_MODE4_CHMAP),
 	SND_PCI_QUIRK(0x1043, 0x8469, &quot;ASUS mobo&quot;, ALC662_FIXUP_NO_JACK_DETECT),
<span class="p_header">diff --git a/sound/soc/codecs/rt5640.c b/sound/soc/codecs/rt5640.c</span>
<span class="p_header">index fdfb09bece91..7aeb69bace7a 100644</span>
<span class="p_header">--- a/sound/soc/codecs/rt5640.c</span>
<span class="p_header">+++ b/sound/soc/codecs/rt5640.c</span>
<span class="p_chunk">@@ -361,7 +361,7 @@</span> <span class="p_context"> static unsigned int bst_tlv[] = {</span>
 
 /* Interface data select */
 static const char * const rt5640_data_select[] = {
<span class="p_del">-	&quot;Normal&quot;, &quot;left copy to right&quot;, &quot;right copy to left&quot;, &quot;Swap&quot;};</span>
<span class="p_add">+	&quot;Normal&quot;, &quot;Swap&quot;, &quot;left copy to right&quot;, &quot;right copy to left&quot;};</span>
 
 static SOC_ENUM_SINGLE_DECL(rt5640_if1_dac_enum, RT5640_DIG_INF_DATA,
 			    RT5640_IF1_DAC_SEL_SFT, rt5640_data_select);
<span class="p_header">diff --git a/sound/soc/codecs/rt5640.h b/sound/soc/codecs/rt5640.h</span>
<span class="p_header">index 58ebe96b86da..5dadf7e94e10 100644</span>
<span class="p_header">--- a/sound/soc/codecs/rt5640.h</span>
<span class="p_header">+++ b/sound/soc/codecs/rt5640.h</span>
<span class="p_chunk">@@ -442,39 +442,39 @@</span> <span class="p_context"></span>
 #define RT5640_IF1_DAC_SEL_MASK			(0x3 &lt;&lt; 14)
 #define RT5640_IF1_DAC_SEL_SFT			14
 #define RT5640_IF1_DAC_SEL_NOR			(0x0 &lt;&lt; 14)
<span class="p_del">-#define RT5640_IF1_DAC_SEL_L2R			(0x1 &lt;&lt; 14)</span>
<span class="p_del">-#define RT5640_IF1_DAC_SEL_R2L			(0x2 &lt;&lt; 14)</span>
<span class="p_del">-#define RT5640_IF1_DAC_SEL_SWAP			(0x3 &lt;&lt; 14)</span>
<span class="p_add">+#define RT5640_IF1_DAC_SEL_SWAP			(0x1 &lt;&lt; 14)</span>
<span class="p_add">+#define RT5640_IF1_DAC_SEL_L2R			(0x2 &lt;&lt; 14)</span>
<span class="p_add">+#define RT5640_IF1_DAC_SEL_R2L			(0x3 &lt;&lt; 14)</span>
 #define RT5640_IF1_ADC_SEL_MASK			(0x3 &lt;&lt; 12)
 #define RT5640_IF1_ADC_SEL_SFT			12
 #define RT5640_IF1_ADC_SEL_NOR			(0x0 &lt;&lt; 12)
<span class="p_del">-#define RT5640_IF1_ADC_SEL_L2R			(0x1 &lt;&lt; 12)</span>
<span class="p_del">-#define RT5640_IF1_ADC_SEL_R2L			(0x2 &lt;&lt; 12)</span>
<span class="p_del">-#define RT5640_IF1_ADC_SEL_SWAP			(0x3 &lt;&lt; 12)</span>
<span class="p_add">+#define RT5640_IF1_ADC_SEL_SWAP			(0x1 &lt;&lt; 12)</span>
<span class="p_add">+#define RT5640_IF1_ADC_SEL_L2R			(0x2 &lt;&lt; 12)</span>
<span class="p_add">+#define RT5640_IF1_ADC_SEL_R2L			(0x3 &lt;&lt; 12)</span>
 #define RT5640_IF2_DAC_SEL_MASK			(0x3 &lt;&lt; 10)
 #define RT5640_IF2_DAC_SEL_SFT			10
 #define RT5640_IF2_DAC_SEL_NOR			(0x0 &lt;&lt; 10)
<span class="p_del">-#define RT5640_IF2_DAC_SEL_L2R			(0x1 &lt;&lt; 10)</span>
<span class="p_del">-#define RT5640_IF2_DAC_SEL_R2L			(0x2 &lt;&lt; 10)</span>
<span class="p_del">-#define RT5640_IF2_DAC_SEL_SWAP			(0x3 &lt;&lt; 10)</span>
<span class="p_add">+#define RT5640_IF2_DAC_SEL_SWAP			(0x1 &lt;&lt; 10)</span>
<span class="p_add">+#define RT5640_IF2_DAC_SEL_L2R			(0x2 &lt;&lt; 10)</span>
<span class="p_add">+#define RT5640_IF2_DAC_SEL_R2L			(0x3 &lt;&lt; 10)</span>
 #define RT5640_IF2_ADC_SEL_MASK			(0x3 &lt;&lt; 8)
 #define RT5640_IF2_ADC_SEL_SFT			8
 #define RT5640_IF2_ADC_SEL_NOR			(0x0 &lt;&lt; 8)
<span class="p_del">-#define RT5640_IF2_ADC_SEL_L2R			(0x1 &lt;&lt; 8)</span>
<span class="p_del">-#define RT5640_IF2_ADC_SEL_R2L			(0x2 &lt;&lt; 8)</span>
<span class="p_del">-#define RT5640_IF2_ADC_SEL_SWAP			(0x3 &lt;&lt; 8)</span>
<span class="p_add">+#define RT5640_IF2_ADC_SEL_SWAP			(0x1 &lt;&lt; 8)</span>
<span class="p_add">+#define RT5640_IF2_ADC_SEL_L2R			(0x2 &lt;&lt; 8)</span>
<span class="p_add">+#define RT5640_IF2_ADC_SEL_R2L			(0x3 &lt;&lt; 8)</span>
 #define RT5640_IF3_DAC_SEL_MASK			(0x3 &lt;&lt; 6)
 #define RT5640_IF3_DAC_SEL_SFT			6
 #define RT5640_IF3_DAC_SEL_NOR			(0x0 &lt;&lt; 6)
<span class="p_del">-#define RT5640_IF3_DAC_SEL_L2R			(0x1 &lt;&lt; 6)</span>
<span class="p_del">-#define RT5640_IF3_DAC_SEL_R2L			(0x2 &lt;&lt; 6)</span>
<span class="p_del">-#define RT5640_IF3_DAC_SEL_SWAP			(0x3 &lt;&lt; 6)</span>
<span class="p_add">+#define RT5640_IF3_DAC_SEL_SWAP			(0x1 &lt;&lt; 6)</span>
<span class="p_add">+#define RT5640_IF3_DAC_SEL_L2R			(0x2 &lt;&lt; 6)</span>
<span class="p_add">+#define RT5640_IF3_DAC_SEL_R2L			(0x3 &lt;&lt; 6)</span>
 #define RT5640_IF3_ADC_SEL_MASK			(0x3 &lt;&lt; 4)
 #define RT5640_IF3_ADC_SEL_SFT			4
 #define RT5640_IF3_ADC_SEL_NOR			(0x0 &lt;&lt; 4)
<span class="p_del">-#define RT5640_IF3_ADC_SEL_L2R			(0x1 &lt;&lt; 4)</span>
<span class="p_del">-#define RT5640_IF3_ADC_SEL_R2L			(0x2 &lt;&lt; 4)</span>
<span class="p_del">-#define RT5640_IF3_ADC_SEL_SWAP			(0x3 &lt;&lt; 4)</span>
<span class="p_add">+#define RT5640_IF3_ADC_SEL_SWAP			(0x1 &lt;&lt; 4)</span>
<span class="p_add">+#define RT5640_IF3_ADC_SEL_L2R			(0x2 &lt;&lt; 4)</span>
<span class="p_add">+#define RT5640_IF3_ADC_SEL_R2L			(0x3 &lt;&lt; 4)</span>
 
 /* REC Left Mixer Control 1 (0x3b) */
 #define RT5640_G_HP_L_RM_L_MASK			(0x7 &lt;&lt; 13)
<span class="p_header">diff --git a/sound/usb/mixer_maps.c b/sound/usb/mixer_maps.c</span>
<span class="p_header">index e89789a9baed..bfcc295c7412 100644</span>
<span class="p_header">--- a/sound/usb/mixer_maps.c</span>
<span class="p_header">+++ b/sound/usb/mixer_maps.c</span>
<span class="p_chunk">@@ -344,6 +344,16 @@</span> <span class="p_context"> static struct usbmix_name_map bose_companion5_map[] = {</span>
 };
 
 /*
<span class="p_add">+ * Dell usb dock with ALC4020 codec had a firmware problem where it got</span>
<span class="p_add">+ * screwed up when zero volume is passed; just skip it as a workaround</span>
<span class="p_add">+ */</span>
<span class="p_add">+static const struct usbmix_name_map dell_alc4020_map[] = {</span>
<span class="p_add">+	{ 16, NULL },</span>
<span class="p_add">+	{ 19, NULL },</span>
<span class="p_add">+	{ 0 }</span>
<span class="p_add">+};</span>
<span class="p_add">+</span>
<span class="p_add">+/*</span>
  * Control map entries
  */
 
<span class="p_chunk">@@ -426,6 +436,10 @@</span> <span class="p_context"> static struct usbmix_ctl_map usbmix_ctl_maps[] = {</span>
 		.map = aureon_51_2_map,
 	},
 	{
<span class="p_add">+		.id = USB_ID(0x0bda, 0x4014),</span>
<span class="p_add">+		.map = dell_alc4020_map,</span>
<span class="p_add">+	},</span>
<span class="p_add">+	{</span>
 		.id = USB_ID(0x13e5, 0x0001),
 		.map = scratch_live_map,
 		.ignore_ctl_error = 1,
<span class="p_header">diff --git a/tools/lib/traceevent/parse-filter.c b/tools/lib/traceevent/parse-filter.c</span>
<span class="p_header">index b50234402fc2..15a43ee8e8b5 100644</span>
<span class="p_header">--- a/tools/lib/traceevent/parse-filter.c</span>
<span class="p_header">+++ b/tools/lib/traceevent/parse-filter.c</span>
<span class="p_chunk">@@ -1163,11 +1163,11 @@</span> <span class="p_context"> process_filter(struct event_format *event, struct filter_arg **parg,</span>
 		current_op = current_exp;
 
 	ret = collapse_tree(current_op, parg, error_str);
<span class="p_add">+	/* collapse_tree() may free current_op, and updates parg accordingly */</span>
<span class="p_add">+	current_op = NULL;</span>
 	if (ret &lt; 0)
 		goto fail;
 
<span class="p_del">-	*parg = current_op;</span>
<span class="p_del">-</span>
 	return 0;
 
  fail_alloc:

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



