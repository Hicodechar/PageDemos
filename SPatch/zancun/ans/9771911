
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>Linux 4.11.4 - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    Linux 4.11.4</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=37061">gregkh@linuxfoundation.org</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>June 7, 2017, 4:13 p.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;20170607161356.GB9491@kroah.com&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/9771911/mbox/"
   >mbox</a>
|
   <a href="/patch/9771911/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/9771911/">/patch/9771911/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
	[172.30.200.125])
	by pdx-korg-patchwork.web.codeaurora.org (Postfix) with ESMTP id
	10A3C60350 for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Wed,  7 Jun 2017 16:14:30 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id C9BB228539
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Wed,  7 Jun 2017 16:14:29 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id BB0572853C; Wed,  7 Jun 2017 16:14:29 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-6.9 required=2.0 tests=BAYES_00,RCVD_IN_DNSWL_HI
	autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id D959E284E4
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Wed,  7 Jun 2017 16:14:21 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1751848AbdFGQOM (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Wed, 7 Jun 2017 12:14:12 -0400
Received: from mail.linuxfoundation.org ([140.211.169.12]:33898 &quot;EHLO
	mail.linuxfoundation.org&quot; rhost-flags-OK-OK-OK-OK) by vger.kernel.org
	with ESMTP id S1751476AbdFGQOE (ORCPT
	&lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Wed, 7 Jun 2017 12:14:04 -0400
Received: from localhost (LFbn-1-12060-104.w90-92.abo.wanadoo.fr
	[90.92.122.104])
	by mail.linuxfoundation.org (Postfix) with ESMTPSA id 0C685B50;
	Wed,  7 Jun 2017 16:14:01 +0000 (UTC)
Date: Wed, 7 Jun 2017 18:13:56 +0200
From: Greg KH &lt;gregkh@linuxfoundation.org&gt;
To: linux-kernel@vger.kernel.org, Andrew Morton &lt;akpm@linux-foundation.org&gt;,
	torvalds@linux-foundation.org, stable@vger.kernel.org
Cc: lwn@lwn.net, Jiri Slaby &lt;jslaby@suse.cz&gt;
Subject: Re: Linux 4.11.4
Message-ID: &lt;20170607161356.GB9491@kroah.com&gt;
References: &lt;20170607161353.GA9491@kroah.com&gt;
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Disposition: inline
In-Reply-To: &lt;20170607161353.GA9491@kroah.com&gt;
User-Agent: Mutt/1.8.3 (2017-05-23)
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=37061">gregkh@linuxfoundation.org</a> - June 7, 2017, 4:13 p.m.</div>
<pre class="content">

</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/Documentation/acpi/acpi-lid.txt b/Documentation/acpi/acpi-lid.txt</span>
<span class="p_header">index 22cb3091f297..effe7af3a5af 100644</span>
<span class="p_header">--- a/Documentation/acpi/acpi-lid.txt</span>
<span class="p_header">+++ b/Documentation/acpi/acpi-lid.txt</span>
<span class="p_chunk">@@ -59,20 +59,28 @@</span> <span class="p_context"> button driver uses the following 3 modes in order not to trigger issues.</span>
 If the userspace hasn&#39;t been prepared to ignore the unreliable &quot;opened&quot;
 events and the unreliable initial state notification, Linux users can use
 the following kernel parameters to handle the possible issues:
<span class="p_del">-A. button.lid_init_state=open:</span>
<span class="p_add">+A. button.lid_init_state=method:</span>
<span class="p_add">+   When this option is specified, the ACPI button driver reports the</span>
<span class="p_add">+   initial lid state using the returning value of the _LID control method</span>
<span class="p_add">+   and whether the &quot;opened&quot;/&quot;closed&quot; events are paired fully relies on the</span>
<span class="p_add">+   firmware implementation.</span>
<span class="p_add">+   This option can be used to fix some platforms where the returning value</span>
<span class="p_add">+   of the _LID control method is reliable but the initial lid state</span>
<span class="p_add">+   notification is missing.</span>
<span class="p_add">+   This option is the default behavior during the period the userspace</span>
<span class="p_add">+   isn&#39;t ready to handle the buggy AML tables.</span>
<span class="p_add">+B. button.lid_init_state=open:</span>
    When this option is specified, the ACPI button driver always reports the
    initial lid state as &quot;opened&quot; and whether the &quot;opened&quot;/&quot;closed&quot; events
    are paired fully relies on the firmware implementation.
    This may fix some platforms where the returning value of the _LID
    control method is not reliable and the initial lid state notification is
    missing.
<span class="p_del">-   This option is the default behavior during the period the userspace</span>
<span class="p_del">-   isn&#39;t ready to handle the buggy AML tables.</span>
 
 If the userspace has been prepared to ignore the unreliable &quot;opened&quot; events
 and the unreliable initial state notification, Linux users should always
 use the following kernel parameter:
<span class="p_del">-B. button.lid_init_state=ignore:</span>
<span class="p_add">+C. button.lid_init_state=ignore:</span>
    When this option is specified, the ACPI button driver never reports the
    initial lid state and there is a compensation mechanism implemented to
    ensure that the reliable &quot;closed&quot; notifications can always be delievered
<span class="p_header">diff --git a/Makefile b/Makefile</span>
<span class="p_header">index 7bab1279d0b5..741814dca844 100644</span>
<span class="p_header">--- a/Makefile</span>
<span class="p_header">+++ b/Makefile</span>
<span class="p_chunk">@@ -1,6 +1,6 @@</span> <span class="p_context"></span>
 VERSION = 4
 PATCHLEVEL = 11
<span class="p_del">-SUBLEVEL = 3</span>
<span class="p_add">+SUBLEVEL = 4</span>
 EXTRAVERSION =
 NAME = Fearless Coyote
 
<span class="p_header">diff --git a/arch/arm64/net/bpf_jit_comp.c b/arch/arm64/net/bpf_jit_comp.c</span>
<span class="p_header">index ce8ab0409deb..4b0e0eda698b 100644</span>
<span class="p_header">--- a/arch/arm64/net/bpf_jit_comp.c</span>
<span class="p_header">+++ b/arch/arm64/net/bpf_jit_comp.c</span>
<span class="p_chunk">@@ -252,8 +252,9 @@</span> <span class="p_context"> static int emit_bpf_tail_call(struct jit_ctx *ctx)</span>
 	 */
 	off = offsetof(struct bpf_array, ptrs);
 	emit_a64_mov_i64(tmp, off, ctx);
<span class="p_del">-	emit(A64_LDR64(tmp, r2, tmp), ctx);</span>
<span class="p_del">-	emit(A64_LDR64(prg, tmp, r3), ctx);</span>
<span class="p_add">+	emit(A64_ADD(1, tmp, r2, tmp), ctx);</span>
<span class="p_add">+	emit(A64_LSL(1, prg, r3, 3), ctx);</span>
<span class="p_add">+	emit(A64_LDR64(prg, tmp, prg), ctx);</span>
 	emit(A64_CBZ(1, prg, jmp_offset), ctx);
 
 	/* goto *(prog-&gt;bpf_func + prologue_size); */
<span class="p_header">diff --git a/arch/powerpc/kernel/prom.c b/arch/powerpc/kernel/prom.c</span>
<span class="p_header">index f5d399e46193..8d2d98f9ad02 100644</span>
<span class="p_header">--- a/arch/powerpc/kernel/prom.c</span>
<span class="p_header">+++ b/arch/powerpc/kernel/prom.c</span>
<span class="p_chunk">@@ -161,7 +161,9 @@</span> <span class="p_context"> static struct ibm_pa_feature {</span>
 	{ .pabyte = 0,  .pabit = 3, .cpu_features  = CPU_FTR_CTRL },
 	{ .pabyte = 0,  .pabit = 6, .cpu_features  = CPU_FTR_NOEXECUTE },
 	{ .pabyte = 1,  .pabit = 2, .mmu_features  = MMU_FTR_CI_LARGE_PAGE },
<span class="p_add">+#ifdef CONFIG_PPC_RADIX_MMU</span>
 	{ .pabyte = 40, .pabit = 0, .mmu_features  = MMU_FTR_TYPE_RADIX },
<span class="p_add">+#endif</span>
 	{ .pabyte = 1,  .pabit = 1, .invert = 1, .cpu_features = CPU_FTR_NODSISRALIGN },
 	{ .pabyte = 5,  .pabit = 0, .cpu_features  = CPU_FTR_REAL_LE,
 				    .cpu_user_ftrs = PPC_FEATURE_TRUE_LE },
<span class="p_header">diff --git a/arch/powerpc/platforms/cell/spu_base.c b/arch/powerpc/platforms/cell/spu_base.c</span>
<span class="p_header">index 96c2b8a40630..0c45cdbac4cf 100644</span>
<span class="p_header">--- a/arch/powerpc/platforms/cell/spu_base.c</span>
<span class="p_header">+++ b/arch/powerpc/platforms/cell/spu_base.c</span>
<span class="p_chunk">@@ -197,7 +197,9 @@</span> <span class="p_context"> static int __spu_trap_data_map(struct spu *spu, unsigned long ea, u64 dsisr)</span>
 	    (REGION_ID(ea) != USER_REGION_ID)) {
 
 		spin_unlock(&amp;spu-&gt;register_lock);
<span class="p_del">-		ret = hash_page(ea, _PAGE_PRESENT | _PAGE_READ, 0x300, dsisr);</span>
<span class="p_add">+		ret = hash_page(ea,</span>
<span class="p_add">+				_PAGE_PRESENT | _PAGE_READ | _PAGE_PRIVILEGED,</span>
<span class="p_add">+				0x300, dsisr);</span>
 		spin_lock(&amp;spu-&gt;register_lock);
 
 		if (!ret) {
<span class="p_header">diff --git a/arch/sparc/include/asm/hugetlb.h b/arch/sparc/include/asm/hugetlb.h</span>
<span class="p_header">index dcbf985ab243..d1f837dc77a4 100644</span>
<span class="p_header">--- a/arch/sparc/include/asm/hugetlb.h</span>
<span class="p_header">+++ b/arch/sparc/include/asm/hugetlb.h</span>
<span class="p_chunk">@@ -24,9 +24,11 @@</span> <span class="p_context"> static inline int is_hugepage_only_range(struct mm_struct *mm,</span>
 static inline int prepare_hugepage_range(struct file *file,
 			unsigned long addr, unsigned long len)
 {
<span class="p_del">-	if (len &amp; ~HPAGE_MASK)</span>
<span class="p_add">+	struct hstate *h = hstate_file(file);</span>
<span class="p_add">+</span>
<span class="p_add">+	if (len &amp; ~huge_page_mask(h))</span>
 		return -EINVAL;
<span class="p_del">-	if (addr &amp; ~HPAGE_MASK)</span>
<span class="p_add">+	if (addr &amp; ~huge_page_mask(h))</span>
 		return -EINVAL;
 	return 0;
 }
<span class="p_header">diff --git a/arch/sparc/include/asm/pgtable_32.h b/arch/sparc/include/asm/pgtable_32.h</span>
<span class="p_header">index ce6f56980aef..cf190728360b 100644</span>
<span class="p_header">--- a/arch/sparc/include/asm/pgtable_32.h</span>
<span class="p_header">+++ b/arch/sparc/include/asm/pgtable_32.h</span>
<span class="p_chunk">@@ -91,9 +91,9 @@</span> <span class="p_context"> extern unsigned long pfn_base;</span>
  * ZERO_PAGE is a global shared page that is always zero: used
  * for zero-mapped memory areas etc..
  */
<span class="p_del">-extern unsigned long empty_zero_page;</span>
<span class="p_add">+extern unsigned long empty_zero_page[PAGE_SIZE / sizeof(unsigned long)];</span>
 
<span class="p_del">-#define ZERO_PAGE(vaddr) (virt_to_page(&amp;empty_zero_page))</span>
<span class="p_add">+#define ZERO_PAGE(vaddr) (virt_to_page(empty_zero_page))</span>
 
 /*
  * In general all page table modifications should use the V8 atomic
<span class="p_header">diff --git a/arch/sparc/include/asm/setup.h b/arch/sparc/include/asm/setup.h</span>
<span class="p_header">index 478bf6bb4598..3fae200dd251 100644</span>
<span class="p_header">--- a/arch/sparc/include/asm/setup.h</span>
<span class="p_header">+++ b/arch/sparc/include/asm/setup.h</span>
<span class="p_chunk">@@ -16,7 +16,7 @@</span> <span class="p_context"> extern char reboot_command[];</span>
  */
 extern unsigned char boot_cpu_id;
 
<span class="p_del">-extern unsigned long empty_zero_page;</span>
<span class="p_add">+extern unsigned long empty_zero_page[PAGE_SIZE / sizeof(unsigned long)];</span>
 
 extern int serial_console;
 static inline int con_is_present(void)
<span class="p_header">diff --git a/arch/sparc/kernel/ftrace.c b/arch/sparc/kernel/ftrace.c</span>
<span class="p_header">index 6bcff698069b..cec54dc4ab81 100644</span>
<span class="p_header">--- a/arch/sparc/kernel/ftrace.c</span>
<span class="p_header">+++ b/arch/sparc/kernel/ftrace.c</span>
<span class="p_chunk">@@ -130,17 +130,16 @@</span> <span class="p_context"> unsigned long prepare_ftrace_return(unsigned long parent,</span>
 	if (unlikely(atomic_read(&amp;current-&gt;tracing_graph_pause)))
 		return parent + 8UL;
 
<span class="p_del">-	if (ftrace_push_return_trace(parent, self_addr, &amp;trace.depth,</span>
<span class="p_del">-				     frame_pointer, NULL) == -EBUSY)</span>
<span class="p_del">-		return parent + 8UL;</span>
<span class="p_del">-</span>
 	trace.func = self_addr;
<span class="p_add">+	trace.depth = current-&gt;curr_ret_stack + 1;</span>
 
 	/* Only trace if the calling function expects to */
<span class="p_del">-	if (!ftrace_graph_entry(&amp;trace)) {</span>
<span class="p_del">-		current-&gt;curr_ret_stack--;</span>
<span class="p_add">+	if (!ftrace_graph_entry(&amp;trace))</span>
<span class="p_add">+		return parent + 8UL;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (ftrace_push_return_trace(parent, self_addr, &amp;trace.depth,</span>
<span class="p_add">+				     frame_pointer, NULL) == -EBUSY)</span>
 		return parent + 8UL;
<span class="p_del">-	}</span>
 
 	return return_hooker;
 }
<span class="p_header">diff --git a/arch/sparc/mm/init_32.c b/arch/sparc/mm/init_32.c</span>
<span class="p_header">index c6afe98de4d9..3bd0d513bddb 100644</span>
<span class="p_header">--- a/arch/sparc/mm/init_32.c</span>
<span class="p_header">+++ b/arch/sparc/mm/init_32.c</span>
<span class="p_chunk">@@ -290,7 +290,7 @@</span> <span class="p_context"> void __init mem_init(void)</span>
 
 
 	/* Saves us work later. */
<span class="p_del">-	memset((void *)&amp;empty_zero_page, 0, PAGE_SIZE);</span>
<span class="p_add">+	memset((void *)empty_zero_page, 0, PAGE_SIZE);</span>
 
 	i = last_valid_pfn &gt;&gt; ((20 - PAGE_SHIFT) + 5);
 	i += 1;
<span class="p_header">diff --git a/arch/x86/boot/compressed/Makefile b/arch/x86/boot/compressed/Makefile</span>
<span class="p_header">index 44163e8c3868..2c860ad4fe06 100644</span>
<span class="p_header">--- a/arch/x86/boot/compressed/Makefile</span>
<span class="p_header">+++ b/arch/x86/boot/compressed/Makefile</span>
<span class="p_chunk">@@ -94,7 +94,7 @@</span> <span class="p_context"> vmlinux-objs-$(CONFIG_EFI_MIXED) += $(obj)/efi_thunk_$(BITS).o</span>
 quiet_cmd_check_data_rel = DATAREL $@
 define cmd_check_data_rel
 	for obj in $(filter %.o,$^); do \
<span class="p_del">-		readelf -S $$obj | grep -qF .rel.local &amp;&amp; { \</span>
<span class="p_add">+		${CROSS_COMPILE}readelf -S $$obj | grep -qF .rel.local &amp;&amp; { \</span>
 			echo &quot;error: $$obj has data relocations!&quot; &gt;&amp;2; \
 			exit 1; \
 		} || true; \
<span class="p_header">diff --git a/arch/x86/include/asm/mce.h b/arch/x86/include/asm/mce.h</span>
<span class="p_header">index e63873683d4a..f1f68c720675 100644</span>
<span class="p_header">--- a/arch/x86/include/asm/mce.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/mce.h</span>
<span class="p_chunk">@@ -264,6 +264,7 @@</span> <span class="p_context"> static inline int umc_normaddr_to_sysaddr(u64 norm_addr, u16 nid, u8 umc, u64 *s</span>
 #endif
 
 int mce_available(struct cpuinfo_x86 *c);
<span class="p_add">+bool mce_is_memory_error(struct mce *m);</span>
 
 DECLARE_PER_CPU(unsigned, mce_exception_count);
 DECLARE_PER_CPU(unsigned, mce_poll_count);
<span class="p_header">diff --git a/arch/x86/kernel/cpu/mcheck/mce.c b/arch/x86/kernel/cpu/mcheck/mce.c</span>
<span class="p_header">index af44ebeb593f..104cda1f9073 100644</span>
<span class="p_header">--- a/arch/x86/kernel/cpu/mcheck/mce.c</span>
<span class="p_header">+++ b/arch/x86/kernel/cpu/mcheck/mce.c</span>
<span class="p_chunk">@@ -643,16 +643,14 @@</span> <span class="p_context"> static void mce_read_aux(struct mce *m, int i)</span>
 	}
 }
 
<span class="p_del">-static bool memory_error(struct mce *m)</span>
<span class="p_add">+bool mce_is_memory_error(struct mce *m)</span>
 {
<span class="p_del">-	struct cpuinfo_x86 *c = &amp;boot_cpu_data;</span>
<span class="p_del">-</span>
<span class="p_del">-	if (c-&gt;x86_vendor == X86_VENDOR_AMD) {</span>
<span class="p_add">+	if (m-&gt;cpuvendor == X86_VENDOR_AMD) {</span>
 		/* ErrCodeExt[20:16] */
 		u8 xec = (m-&gt;status &gt;&gt; 16) &amp; 0x1f;
 
 		return (xec == 0x0 || xec == 0x8);
<span class="p_del">-	} else if (c-&gt;x86_vendor == X86_VENDOR_INTEL) {</span>
<span class="p_add">+	} else if (m-&gt;cpuvendor == X86_VENDOR_INTEL) {</span>
 		/*
 		 * Intel SDM Volume 3B - 15.9.2 Compound Error Codes
 		 *
<span class="p_chunk">@@ -673,6 +671,7 @@</span> <span class="p_context"> static bool memory_error(struct mce *m)</span>
 
 	return false;
 }
<span class="p_add">+EXPORT_SYMBOL_GPL(mce_is_memory_error);</span>
 
 DEFINE_PER_CPU(unsigned, mce_poll_count);
 
<span class="p_chunk">@@ -734,7 +733,7 @@</span> <span class="p_context"> bool machine_check_poll(enum mcp_flags flags, mce_banks_t *b)</span>
 
 		severity = mce_severity(&amp;m, mca_cfg.tolerant, NULL, false);
 
<span class="p_del">-		if (severity == MCE_DEFERRED_SEVERITY &amp;&amp; memory_error(&amp;m))</span>
<span class="p_add">+		if (severity == MCE_DEFERRED_SEVERITY &amp;&amp; mce_is_memory_error(&amp;m))</span>
 			if (m.status &amp; MCI_STATUS_ADDRV)
 				m.severity = severity;
 
<span class="p_header">diff --git a/crypto/skcipher.c b/crypto/skcipher.c</span>
<span class="p_header">index 014af741fc6a..4faa0fd53b0c 100644</span>
<span class="p_header">--- a/crypto/skcipher.c</span>
<span class="p_header">+++ b/crypto/skcipher.c</span>
<span class="p_chunk">@@ -764,6 +764,44 @@</span> <span class="p_context"> static int crypto_init_skcipher_ops_ablkcipher(struct crypto_tfm *tfm)</span>
 	return 0;
 }
 
<span class="p_add">+static int skcipher_setkey_unaligned(struct crypto_skcipher *tfm,</span>
<span class="p_add">+				     const u8 *key, unsigned int keylen)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long alignmask = crypto_skcipher_alignmask(tfm);</span>
<span class="p_add">+	struct skcipher_alg *cipher = crypto_skcipher_alg(tfm);</span>
<span class="p_add">+	u8 *buffer, *alignbuffer;</span>
<span class="p_add">+	unsigned long absize;</span>
<span class="p_add">+	int ret;</span>
<span class="p_add">+</span>
<span class="p_add">+	absize = keylen + alignmask;</span>
<span class="p_add">+	buffer = kmalloc(absize, GFP_ATOMIC);</span>
<span class="p_add">+	if (!buffer)</span>
<span class="p_add">+		return -ENOMEM;</span>
<span class="p_add">+</span>
<span class="p_add">+	alignbuffer = (u8 *)ALIGN((unsigned long)buffer, alignmask + 1);</span>
<span class="p_add">+	memcpy(alignbuffer, key, keylen);</span>
<span class="p_add">+	ret = cipher-&gt;setkey(tfm, alignbuffer, keylen);</span>
<span class="p_add">+	kzfree(buffer);</span>
<span class="p_add">+	return ret;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static int skcipher_setkey(struct crypto_skcipher *tfm, const u8 *key,</span>
<span class="p_add">+			   unsigned int keylen)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct skcipher_alg *cipher = crypto_skcipher_alg(tfm);</span>
<span class="p_add">+	unsigned long alignmask = crypto_skcipher_alignmask(tfm);</span>
<span class="p_add">+</span>
<span class="p_add">+	if (keylen &lt; cipher-&gt;min_keysize || keylen &gt; cipher-&gt;max_keysize) {</span>
<span class="p_add">+		crypto_skcipher_set_flags(tfm, CRYPTO_TFM_RES_BAD_KEY_LEN);</span>
<span class="p_add">+		return -EINVAL;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	if ((unsigned long)key &amp; alignmask)</span>
<span class="p_add">+		return skcipher_setkey_unaligned(tfm, key, keylen);</span>
<span class="p_add">+</span>
<span class="p_add">+	return cipher-&gt;setkey(tfm, key, keylen);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static void crypto_skcipher_exit_tfm(struct crypto_tfm *tfm)
 {
 	struct crypto_skcipher *skcipher = __crypto_skcipher_cast(tfm);
<span class="p_chunk">@@ -784,7 +822,7 @@</span> <span class="p_context"> static int crypto_skcipher_init_tfm(struct crypto_tfm *tfm)</span>
 	    tfm-&gt;__crt_alg-&gt;cra_type == &amp;crypto_givcipher_type)
 		return crypto_init_skcipher_ops_ablkcipher(tfm);
 
<span class="p_del">-	skcipher-&gt;setkey = alg-&gt;setkey;</span>
<span class="p_add">+	skcipher-&gt;setkey = skcipher_setkey;</span>
 	skcipher-&gt;encrypt = alg-&gt;encrypt;
 	skcipher-&gt;decrypt = alg-&gt;decrypt;
 	skcipher-&gt;ivsize = alg-&gt;ivsize;
<span class="p_header">diff --git a/drivers/acpi/acpica/tbutils.c b/drivers/acpi/acpica/tbutils.c</span>
<span class="p_header">index 5a968a78652b..7abe66505739 100644</span>
<span class="p_header">--- a/drivers/acpi/acpica/tbutils.c</span>
<span class="p_header">+++ b/drivers/acpi/acpica/tbutils.c</span>
<span class="p_chunk">@@ -418,11 +418,7 @@</span> <span class="p_context"> acpi_tb_get_table(struct acpi_table_desc *table_desc,</span>
 
 	table_desc-&gt;validation_count++;
 	if (table_desc-&gt;validation_count == 0) {
<span class="p_del">-		ACPI_ERROR((AE_INFO,</span>
<span class="p_del">-			    &quot;Table %p, Validation count is zero after increment\n&quot;,</span>
<span class="p_del">-			    table_desc));</span>
 		table_desc-&gt;validation_count--;
<span class="p_del">-		return_ACPI_STATUS(AE_LIMIT);</span>
 	}
 
 	*out_table = table_desc-&gt;pointer;
<span class="p_header">diff --git a/drivers/acpi/button.c b/drivers/acpi/button.c</span>
<span class="p_header">index 668137e4a069..e19f530f1083 100644</span>
<span class="p_header">--- a/drivers/acpi/button.c</span>
<span class="p_header">+++ b/drivers/acpi/button.c</span>
<span class="p_chunk">@@ -57,6 +57,7 @@</span> <span class="p_context"></span>
 
 #define ACPI_BUTTON_LID_INIT_IGNORE	0x00
 #define ACPI_BUTTON_LID_INIT_OPEN	0x01
<span class="p_add">+#define ACPI_BUTTON_LID_INIT_METHOD	0x02</span>
 
 #define _COMPONENT		ACPI_BUTTON_COMPONENT
 ACPI_MODULE_NAME(&quot;button&quot;);
<span class="p_chunk">@@ -112,7 +113,7 @@</span> <span class="p_context"> struct acpi_button {</span>
 
 static BLOCKING_NOTIFIER_HEAD(acpi_lid_notifier);
 static struct acpi_device *lid_device;
<span class="p_del">-static u8 lid_init_state = ACPI_BUTTON_LID_INIT_OPEN;</span>
<span class="p_add">+static u8 lid_init_state = ACPI_BUTTON_LID_INIT_METHOD;</span>
 
 static unsigned long lid_report_interval __read_mostly = 500;
 module_param(lid_report_interval, ulong, 0644);
<span class="p_chunk">@@ -376,6 +377,9 @@</span> <span class="p_context"> static void acpi_lid_initialize_state(struct acpi_device *device)</span>
 	case ACPI_BUTTON_LID_INIT_OPEN:
 		(void)acpi_lid_notify_state(device, 1);
 		break;
<span class="p_add">+	case ACPI_BUTTON_LID_INIT_METHOD:</span>
<span class="p_add">+		(void)acpi_lid_update_state(device);</span>
<span class="p_add">+		break;</span>
 	case ACPI_BUTTON_LID_INIT_IGNORE:
 	default:
 		break;
<span class="p_chunk">@@ -559,6 +563,9 @@</span> <span class="p_context"> static int param_set_lid_init_state(const char *val, struct kernel_param *kp)</span>
 	if (!strncmp(val, &quot;open&quot;, sizeof(&quot;open&quot;) - 1)) {
 		lid_init_state = ACPI_BUTTON_LID_INIT_OPEN;
 		pr_info(&quot;Notify initial lid state as open\n&quot;);
<span class="p_add">+	} else if (!strncmp(val, &quot;method&quot;, sizeof(&quot;method&quot;) - 1)) {</span>
<span class="p_add">+		lid_init_state = ACPI_BUTTON_LID_INIT_METHOD;</span>
<span class="p_add">+		pr_info(&quot;Notify initial lid state with _LID return value\n&quot;);</span>
 	} else if (!strncmp(val, &quot;ignore&quot;, sizeof(&quot;ignore&quot;) - 1)) {
 		lid_init_state = ACPI_BUTTON_LID_INIT_IGNORE;
 		pr_info(&quot;Do not notify initial lid state\n&quot;);
<span class="p_chunk">@@ -572,6 +579,8 @@</span> <span class="p_context"> static int param_get_lid_init_state(char *buffer, struct kernel_param *kp)</span>
 	switch (lid_init_state) {
 	case ACPI_BUTTON_LID_INIT_OPEN:
 		return sprintf(buffer, &quot;open&quot;);
<span class="p_add">+	case ACPI_BUTTON_LID_INIT_METHOD:</span>
<span class="p_add">+		return sprintf(buffer, &quot;method&quot;);</span>
 	case ACPI_BUTTON_LID_INIT_IGNORE:
 		return sprintf(buffer, &quot;ignore&quot;);
 	default:
<span class="p_header">diff --git a/drivers/acpi/nfit/mce.c b/drivers/acpi/nfit/mce.c</span>
<span class="p_header">index 3ba1c3472cf9..fd86bec98dea 100644</span>
<span class="p_header">--- a/drivers/acpi/nfit/mce.c</span>
<span class="p_header">+++ b/drivers/acpi/nfit/mce.c</span>
<span class="p_chunk">@@ -26,7 +26,7 @@</span> <span class="p_context"> static int nfit_handle_mce(struct notifier_block *nb, unsigned long val,</span>
 	struct nfit_spa *nfit_spa;
 
 	/* We only care about memory errors */
<span class="p_del">-	if (!(mce-&gt;status &amp; MCACOD))</span>
<span class="p_add">+	if (!mce_is_memory_error(mce))</span>
 		return NOTIFY_DONE;
 
 	/*
<span class="p_header">diff --git a/drivers/acpi/sysfs.c b/drivers/acpi/sysfs.c</span>
<span class="p_header">index cf05ae973381..5180fef9eb49 100644</span>
<span class="p_header">--- a/drivers/acpi/sysfs.c</span>
<span class="p_header">+++ b/drivers/acpi/sysfs.c</span>
<span class="p_chunk">@@ -333,14 +333,17 @@</span> <span class="p_context"> static ssize_t acpi_table_show(struct file *filp, struct kobject *kobj,</span>
 	    container_of(bin_attr, struct acpi_table_attr, attr);
 	struct acpi_table_header *table_header = NULL;
 	acpi_status status;
<span class="p_add">+	ssize_t rc;</span>
 
 	status = acpi_get_table(table_attr-&gt;name, table_attr-&gt;instance,
 				&amp;table_header);
 	if (ACPI_FAILURE(status))
 		return -ENODEV;
 
<span class="p_del">-	return memory_read_from_buffer(buf, count, &amp;offset,</span>
<span class="p_del">-				       table_header, table_header-&gt;length);</span>
<span class="p_add">+	rc = memory_read_from_buffer(buf, count, &amp;offset, table_header,</span>
<span class="p_add">+			table_header-&gt;length);</span>
<span class="p_add">+	acpi_put_table(table_header);</span>
<span class="p_add">+	return rc;</span>
 }
 
 static int acpi_table_attr_init(struct kobject *tables_obj,
<span class="p_header">diff --git a/drivers/char/pcmcia/cm4040_cs.c b/drivers/char/pcmcia/cm4040_cs.c</span>
<span class="p_header">index d4dbd8d8e524..382c864814d9 100644</span>
<span class="p_header">--- a/drivers/char/pcmcia/cm4040_cs.c</span>
<span class="p_header">+++ b/drivers/char/pcmcia/cm4040_cs.c</span>
<span class="p_chunk">@@ -374,7 +374,7 @@</span> <span class="p_context"> static ssize_t cm4040_write(struct file *filp, const char __user *buf,</span>
 
 	rc = write_sync_reg(SCR_HOST_TO_READER_START, dev);
 	if (rc &lt;= 0) {
<span class="p_del">-		DEBUGP(5, dev, &quot;write_sync_reg c=%.2Zx\n&quot;, rc);</span>
<span class="p_add">+		DEBUGP(5, dev, &quot;write_sync_reg c=%.2zx\n&quot;, rc);</span>
 		DEBUGP(2, dev, &quot;&lt;- cm4040_write (failed)\n&quot;);
 		if (rc == -ERESTARTSYS)
 			return rc;
<span class="p_chunk">@@ -387,7 +387,7 @@</span> <span class="p_context"> static ssize_t cm4040_write(struct file *filp, const char __user *buf,</span>
 	for (i = 0; i &lt; bytes_to_write; i++) {
 		rc = wait_for_bulk_out_ready(dev);
 		if (rc &lt;= 0) {
<span class="p_del">-			DEBUGP(5, dev, &quot;wait_for_bulk_out_ready rc=%.2Zx\n&quot;,</span>
<span class="p_add">+			DEBUGP(5, dev, &quot;wait_for_bulk_out_ready rc=%.2zx\n&quot;,</span>
 			       rc);
 			DEBUGP(2, dev, &quot;&lt;- cm4040_write (failed)\n&quot;);
 			if (rc == -ERESTARTSYS)
<span class="p_chunk">@@ -403,7 +403,7 @@</span> <span class="p_context"> static ssize_t cm4040_write(struct file *filp, const char __user *buf,</span>
 	rc = write_sync_reg(SCR_HOST_TO_READER_DONE, dev);
 
 	if (rc &lt;= 0) {
<span class="p_del">-		DEBUGP(5, dev, &quot;write_sync_reg c=%.2Zx\n&quot;, rc);</span>
<span class="p_add">+		DEBUGP(5, dev, &quot;write_sync_reg c=%.2zx\n&quot;, rc);</span>
 		DEBUGP(2, dev, &quot;&lt;- cm4040_write (failed)\n&quot;);
 		if (rc == -ERESTARTSYS)
 			return rc;
<span class="p_header">diff --git a/drivers/gpu/drm/amd/powerplay/hwmgr/smu7_hwmgr.c b/drivers/gpu/drm/amd/powerplay/hwmgr/smu7_hwmgr.c</span>
<span class="p_header">index f75ee33ec5bb..98bfa5e41e3b 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/amd/powerplay/hwmgr/smu7_hwmgr.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/amd/powerplay/hwmgr/smu7_hwmgr.c</span>
<span class="p_chunk">@@ -2656,6 +2656,28 @@</span> <span class="p_context"> static int smu7_get_power_state_size(struct pp_hwmgr *hwmgr)</span>
 	return sizeof(struct smu7_power_state);
 }
 
<span class="p_add">+static int smu7_vblank_too_short(struct pp_hwmgr *hwmgr,</span>
<span class="p_add">+				 uint32_t vblank_time_us)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct smu7_hwmgr *data = (struct smu7_hwmgr *)(hwmgr-&gt;backend);</span>
<span class="p_add">+	uint32_t switch_limit_us;</span>
<span class="p_add">+</span>
<span class="p_add">+	switch (hwmgr-&gt;chip_id) {</span>
<span class="p_add">+	case CHIP_POLARIS10:</span>
<span class="p_add">+	case CHIP_POLARIS11:</span>
<span class="p_add">+	case CHIP_POLARIS12:</span>
<span class="p_add">+		switch_limit_us = data-&gt;is_memory_gddr5 ? 190 : 150;</span>
<span class="p_add">+		break;</span>
<span class="p_add">+	default:</span>
<span class="p_add">+		switch_limit_us = data-&gt;is_memory_gddr5 ? 450 : 150;</span>
<span class="p_add">+		break;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	if (vblank_time_us &lt; switch_limit_us)</span>
<span class="p_add">+		return true;</span>
<span class="p_add">+	else</span>
<span class="p_add">+		return false;</span>
<span class="p_add">+}</span>
 
 static int smu7_apply_state_adjust_rules(struct pp_hwmgr *hwmgr,
 				struct pp_power_state *request_ps,
<span class="p_chunk">@@ -2670,6 +2692,7 @@</span> <span class="p_context"> static int smu7_apply_state_adjust_rules(struct pp_hwmgr *hwmgr,</span>
 	bool disable_mclk_switching;
 	bool disable_mclk_switching_for_frame_lock;
 	struct cgs_display_info info = {0};
<span class="p_add">+	struct cgs_mode_info mode_info = {0};</span>
 	const struct phm_clock_and_voltage_limits *max_limits;
 	uint32_t i;
 	struct smu7_hwmgr *data = (struct smu7_hwmgr *)(hwmgr-&gt;backend);
<span class="p_chunk">@@ -2678,6 +2701,7 @@</span> <span class="p_context"> static int smu7_apply_state_adjust_rules(struct pp_hwmgr *hwmgr,</span>
 	int32_t count;
 	int32_t stable_pstate_sclk = 0, stable_pstate_mclk = 0;
 
<span class="p_add">+	info.mode_info = &amp;mode_info;</span>
 	data-&gt;battery_state = (PP_StateUILabel_Battery ==
 			request_ps-&gt;classification.ui_label);
 
<span class="p_chunk">@@ -2704,8 +2728,6 @@</span> <span class="p_context"> static int smu7_apply_state_adjust_rules(struct pp_hwmgr *hwmgr,</span>
 
 	cgs_get_active_displays_info(hwmgr-&gt;device, &amp;info);
 
<span class="p_del">-	/*TO DO result = PHM_CheckVBlankTime(hwmgr, &amp;vblankTooShort);*/</span>
<span class="p_del">-</span>
 	minimum_clocks.engineClock = hwmgr-&gt;display_config.min_core_set_clock;
 	minimum_clocks.memoryClock = hwmgr-&gt;display_config.min_mem_set_clock;
 
<span class="p_chunk">@@ -2770,8 +2792,10 @@</span> <span class="p_context"> static int smu7_apply_state_adjust_rules(struct pp_hwmgr *hwmgr,</span>
 				    PHM_PlatformCaps_DisableMclkSwitchingForFrameLock);
 
 
<span class="p_del">-	disable_mclk_switching = (1 &lt; info.display_count) ||</span>
<span class="p_del">-				    disable_mclk_switching_for_frame_lock;</span>
<span class="p_add">+	disable_mclk_switching = ((1 &lt; info.display_count) ||</span>
<span class="p_add">+				  disable_mclk_switching_for_frame_lock ||</span>
<span class="p_add">+				  smu7_vblank_too_short(hwmgr, mode_info.vblank_time_us) ||</span>
<span class="p_add">+				  (mode_info.refresh_rate &gt; 120));</span>
 
 	sclk = smu7_ps-&gt;performance_levels[0].engine_clock;
 	mclk = smu7_ps-&gt;performance_levels[0].memory_clock;
<span class="p_header">diff --git a/drivers/gpu/drm/gma500/psb_intel_lvds.c b/drivers/gpu/drm/gma500/psb_intel_lvds.c</span>
<span class="p_header">index 483fdce74e39..97c444856d09 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/gma500/psb_intel_lvds.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/gma500/psb_intel_lvds.c</span>
<span class="p_chunk">@@ -760,20 +760,23 @@</span> <span class="p_context"> void psb_intel_lvds_init(struct drm_device *dev,</span>
 		if (scan-&gt;type &amp; DRM_MODE_TYPE_PREFERRED) {
 			mode_dev-&gt;panel_fixed_mode =
 			    drm_mode_duplicate(dev, scan);
<span class="p_add">+			DRM_DEBUG_KMS(&quot;Using mode from DDC\n&quot;);</span>
 			goto out;	/* FIXME: check for quirks */
 		}
 	}
 
 	/* Failed to get EDID, what about VBT? do we need this? */
<span class="p_del">-	if (mode_dev-&gt;vbt_mode)</span>
<span class="p_add">+	if (dev_priv-&gt;lfp_lvds_vbt_mode) {</span>
 		mode_dev-&gt;panel_fixed_mode =
<span class="p_del">-		    drm_mode_duplicate(dev, mode_dev-&gt;vbt_mode);</span>
<span class="p_add">+			drm_mode_duplicate(dev, dev_priv-&gt;lfp_lvds_vbt_mode);</span>
 
<span class="p_del">-	if (!mode_dev-&gt;panel_fixed_mode)</span>
<span class="p_del">-		if (dev_priv-&gt;lfp_lvds_vbt_mode)</span>
<span class="p_del">-			mode_dev-&gt;panel_fixed_mode =</span>
<span class="p_del">-				drm_mode_duplicate(dev,</span>
<span class="p_del">-					dev_priv-&gt;lfp_lvds_vbt_mode);</span>
<span class="p_add">+		if (mode_dev-&gt;panel_fixed_mode) {</span>
<span class="p_add">+			mode_dev-&gt;panel_fixed_mode-&gt;type |=</span>
<span class="p_add">+				DRM_MODE_TYPE_PREFERRED;</span>
<span class="p_add">+			DRM_DEBUG_KMS(&quot;Using mode from VBT\n&quot;);</span>
<span class="p_add">+			goto out;</span>
<span class="p_add">+		}</span>
<span class="p_add">+	}</span>
 
 	/*
 	 * If we didn&#39;t get EDID, try checking if the panel is already turned
<span class="p_chunk">@@ -790,6 +793,7 @@</span> <span class="p_context"> void psb_intel_lvds_init(struct drm_device *dev,</span>
 		if (mode_dev-&gt;panel_fixed_mode) {
 			mode_dev-&gt;panel_fixed_mode-&gt;type |=
 			    DRM_MODE_TYPE_PREFERRED;
<span class="p_add">+			DRM_DEBUG_KMS(&quot;Using pre-programmed mode\n&quot;);</span>
 			goto out;	/* FIXME: check for quirks */
 		}
 	}
<span class="p_header">diff --git a/drivers/gpu/drm/radeon/ci_dpm.c b/drivers/gpu/drm/radeon/ci_dpm.c</span>
<span class="p_header">index 7ba450832e6b..ea36dc4dd5d2 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/radeon/ci_dpm.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/radeon/ci_dpm.c</span>
<span class="p_chunk">@@ -776,6 +776,12 @@</span> <span class="p_context"> bool ci_dpm_vblank_too_short(struct radeon_device *rdev)</span>
 	u32 vblank_time = r600_dpm_get_vblank_time(rdev);
 	u32 switch_limit = pi-&gt;mem_gddr5 ? 450 : 300;
 
<span class="p_add">+	/* disable mclk switching if the refresh is &gt;120Hz, even if the</span>
<span class="p_add">+        * blanking period would allow it</span>
<span class="p_add">+        */</span>
<span class="p_add">+	if (r600_dpm_get_vrefresh(rdev) &gt; 120)</span>
<span class="p_add">+		return true;</span>
<span class="p_add">+</span>
 	if (vblank_time &lt; switch_limit)
 		return true;
 	else
<span class="p_header">diff --git a/drivers/gpu/drm/radeon/cik.c b/drivers/gpu/drm/radeon/cik.c</span>
<span class="p_header">index f6ff41a0eed6..edee6a5f4da9 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/radeon/cik.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/radeon/cik.c</span>
<span class="p_chunk">@@ -7416,7 +7416,7 @@</span> <span class="p_context"> static inline void cik_irq_ack(struct radeon_device *rdev)</span>
 		WREG32(DC_HPD5_INT_CONTROL, tmp);
 	}
 	if (rdev-&gt;irq.stat_regs.cik.disp_int_cont5 &amp; DC_HPD6_INTERRUPT) {
<span class="p_del">-		tmp = RREG32(DC_HPD5_INT_CONTROL);</span>
<span class="p_add">+		tmp = RREG32(DC_HPD6_INT_CONTROL);</span>
 		tmp |= DC_HPDx_INT_ACK;
 		WREG32(DC_HPD6_INT_CONTROL, tmp);
 	}
<span class="p_chunk">@@ -7446,7 +7446,7 @@</span> <span class="p_context"> static inline void cik_irq_ack(struct radeon_device *rdev)</span>
 		WREG32(DC_HPD5_INT_CONTROL, tmp);
 	}
 	if (rdev-&gt;irq.stat_regs.cik.disp_int_cont5 &amp; DC_HPD6_RX_INTERRUPT) {
<span class="p_del">-		tmp = RREG32(DC_HPD5_INT_CONTROL);</span>
<span class="p_add">+		tmp = RREG32(DC_HPD6_INT_CONTROL);</span>
 		tmp |= DC_HPDx_RX_INT_ACK;
 		WREG32(DC_HPD6_INT_CONTROL, tmp);
 	}
<span class="p_header">diff --git a/drivers/gpu/drm/radeon/evergreen.c b/drivers/gpu/drm/radeon/evergreen.c</span>
<span class="p_header">index 0b6b5766216f..6068b8a01016 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/radeon/evergreen.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/radeon/evergreen.c</span>
<span class="p_chunk">@@ -4933,7 +4933,7 @@</span> <span class="p_context"> static void evergreen_irq_ack(struct radeon_device *rdev)</span>
 		WREG32(DC_HPD5_INT_CONTROL, tmp);
 	}
 	if (rdev-&gt;irq.stat_regs.evergreen.disp_int_cont5 &amp; DC_HPD6_INTERRUPT) {
<span class="p_del">-		tmp = RREG32(DC_HPD5_INT_CONTROL);</span>
<span class="p_add">+		tmp = RREG32(DC_HPD6_INT_CONTROL);</span>
 		tmp |= DC_HPDx_INT_ACK;
 		WREG32(DC_HPD6_INT_CONTROL, tmp);
 	}
<span class="p_chunk">@@ -4964,7 +4964,7 @@</span> <span class="p_context"> static void evergreen_irq_ack(struct radeon_device *rdev)</span>
 		WREG32(DC_HPD5_INT_CONTROL, tmp);
 	}
 	if (rdev-&gt;irq.stat_regs.evergreen.disp_int_cont5 &amp; DC_HPD6_RX_INTERRUPT) {
<span class="p_del">-		tmp = RREG32(DC_HPD5_INT_CONTROL);</span>
<span class="p_add">+		tmp = RREG32(DC_HPD6_INT_CONTROL);</span>
 		tmp |= DC_HPDx_RX_INT_ACK;
 		WREG32(DC_HPD6_INT_CONTROL, tmp);
 	}
<span class="p_header">diff --git a/drivers/gpu/drm/radeon/r600.c b/drivers/gpu/drm/radeon/r600.c</span>
<span class="p_header">index a951881c2a50..f2eac6b6c46a 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/radeon/r600.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/radeon/r600.c</span>
<span class="p_chunk">@@ -3995,7 +3995,7 @@</span> <span class="p_context"> static void r600_irq_ack(struct radeon_device *rdev)</span>
 			WREG32(DC_HPD5_INT_CONTROL, tmp);
 		}
 		if (rdev-&gt;irq.stat_regs.r600.disp_int_cont2 &amp; DC_HPD6_INTERRUPT) {
<span class="p_del">-			tmp = RREG32(DC_HPD5_INT_CONTROL);</span>
<span class="p_add">+			tmp = RREG32(DC_HPD6_INT_CONTROL);</span>
 			tmp |= DC_HPDx_INT_ACK;
 			WREG32(DC_HPD6_INT_CONTROL, tmp);
 		}
<span class="p_header">diff --git a/drivers/gpu/drm/radeon/si.c b/drivers/gpu/drm/radeon/si.c</span>
<span class="p_header">index 414776811e71..c8047548f8be 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/radeon/si.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/radeon/si.c</span>
<span class="p_chunk">@@ -6345,7 +6345,7 @@</span> <span class="p_context"> static inline void si_irq_ack(struct radeon_device *rdev)</span>
 		WREG32(DC_HPD5_INT_CONTROL, tmp);
 	}
 	if (rdev-&gt;irq.stat_regs.evergreen.disp_int_cont5 &amp; DC_HPD6_INTERRUPT) {
<span class="p_del">-		tmp = RREG32(DC_HPD5_INT_CONTROL);</span>
<span class="p_add">+		tmp = RREG32(DC_HPD6_INT_CONTROL);</span>
 		tmp |= DC_HPDx_INT_ACK;
 		WREG32(DC_HPD6_INT_CONTROL, tmp);
 	}
<span class="p_chunk">@@ -6376,7 +6376,7 @@</span> <span class="p_context"> static inline void si_irq_ack(struct radeon_device *rdev)</span>
 		WREG32(DC_HPD5_INT_CONTROL, tmp);
 	}
 	if (rdev-&gt;irq.stat_regs.evergreen.disp_int_cont5 &amp; DC_HPD6_RX_INTERRUPT) {
<span class="p_del">-		tmp = RREG32(DC_HPD5_INT_CONTROL);</span>
<span class="p_add">+		tmp = RREG32(DC_HPD6_INT_CONTROL);</span>
 		tmp |= DC_HPDx_RX_INT_ACK;
 		WREG32(DC_HPD6_INT_CONTROL, tmp);
 	}
<span class="p_header">diff --git a/drivers/hid/wacom_wac.c b/drivers/hid/wacom_wac.c</span>
<span class="p_header">index c68ac65db7ff..4859926332c1 100644</span>
<span class="p_header">--- a/drivers/hid/wacom_wac.c</span>
<span class="p_header">+++ b/drivers/hid/wacom_wac.c</span>
<span class="p_chunk">@@ -1571,37 +1571,38 @@</span> <span class="p_context"> static int wacom_tpc_irq(struct wacom_wac *wacom, size_t len)</span>
 {
 	unsigned char *data = wacom-&gt;data;
 
<span class="p_del">-	if (wacom-&gt;pen_input)</span>
<span class="p_add">+	if (wacom-&gt;pen_input) {</span>
 		dev_dbg(wacom-&gt;pen_input-&gt;dev.parent,
 			&quot;%s: received report #%d\n&quot;, __func__, data[0]);
<span class="p_del">-	else if (wacom-&gt;touch_input)</span>
<span class="p_add">+</span>
<span class="p_add">+		if (len == WACOM_PKGLEN_PENABLED ||</span>
<span class="p_add">+		    data[0] == WACOM_REPORT_PENABLED)</span>
<span class="p_add">+			return wacom_tpc_pen(wacom);</span>
<span class="p_add">+	}</span>
<span class="p_add">+	else if (wacom-&gt;touch_input) {</span>
 		dev_dbg(wacom-&gt;touch_input-&gt;dev.parent,
 			&quot;%s: received report #%d\n&quot;, __func__, data[0]);
 
<span class="p_del">-	switch (len) {</span>
<span class="p_del">-	case WACOM_PKGLEN_TPC1FG:</span>
<span class="p_del">-		return wacom_tpc_single_touch(wacom, len);</span>
<span class="p_add">+		switch (len) {</span>
<span class="p_add">+		case WACOM_PKGLEN_TPC1FG:</span>
<span class="p_add">+			return wacom_tpc_single_touch(wacom, len);</span>
 
<span class="p_del">-	case WACOM_PKGLEN_TPC2FG:</span>
<span class="p_del">-		return wacom_tpc_mt_touch(wacom);</span>
<span class="p_add">+		case WACOM_PKGLEN_TPC2FG:</span>
<span class="p_add">+			return wacom_tpc_mt_touch(wacom);</span>
 
<span class="p_del">-	case WACOM_PKGLEN_PENABLED:</span>
<span class="p_del">-		return wacom_tpc_pen(wacom);</span>
<span class="p_add">+		default:</span>
<span class="p_add">+			switch (data[0]) {</span>
<span class="p_add">+			case WACOM_REPORT_TPC1FG:</span>
<span class="p_add">+			case WACOM_REPORT_TPCHID:</span>
<span class="p_add">+			case WACOM_REPORT_TPCST:</span>
<span class="p_add">+			case WACOM_REPORT_TPC1FGE:</span>
<span class="p_add">+				return wacom_tpc_single_touch(wacom, len);</span>
 
<span class="p_del">-	default:</span>
<span class="p_del">-		switch (data[0]) {</span>
<span class="p_del">-		case WACOM_REPORT_TPC1FG:</span>
<span class="p_del">-		case WACOM_REPORT_TPCHID:</span>
<span class="p_del">-		case WACOM_REPORT_TPCST:</span>
<span class="p_del">-		case WACOM_REPORT_TPC1FGE:</span>
<span class="p_del">-			return wacom_tpc_single_touch(wacom, len);</span>
<span class="p_del">-</span>
<span class="p_del">-		case WACOM_REPORT_TPCMT:</span>
<span class="p_del">-		case WACOM_REPORT_TPCMT2:</span>
<span class="p_del">-			return wacom_mt_touch(wacom);</span>
<span class="p_add">+			case WACOM_REPORT_TPCMT:</span>
<span class="p_add">+			case WACOM_REPORT_TPCMT2:</span>
<span class="p_add">+				return wacom_mt_touch(wacom);</span>
 
<span class="p_del">-		case WACOM_REPORT_PENABLED:</span>
<span class="p_del">-			return wacom_tpc_pen(wacom);</span>
<span class="p_add">+			}</span>
 		}
 	}
 
<span class="p_header">diff --git a/drivers/i2c/busses/i2c-tiny-usb.c b/drivers/i2c/busses/i2c-tiny-usb.c</span>
<span class="p_header">index 0ed77eeff31e..a2e3dd715380 100644</span>
<span class="p_header">--- a/drivers/i2c/busses/i2c-tiny-usb.c</span>
<span class="p_header">+++ b/drivers/i2c/busses/i2c-tiny-usb.c</span>
<span class="p_chunk">@@ -178,22 +178,39 @@</span> <span class="p_context"> static int usb_read(struct i2c_adapter *adapter, int cmd,</span>
 		    int value, int index, void *data, int len)
 {
 	struct i2c_tiny_usb *dev = (struct i2c_tiny_usb *)adapter-&gt;algo_data;
<span class="p_add">+	void *dmadata = kmalloc(len, GFP_KERNEL);</span>
<span class="p_add">+	int ret;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (!dmadata)</span>
<span class="p_add">+		return -ENOMEM;</span>
 
 	/* do control transfer */
<span class="p_del">-	return usb_control_msg(dev-&gt;usb_dev, usb_rcvctrlpipe(dev-&gt;usb_dev, 0),</span>
<span class="p_add">+	ret = usb_control_msg(dev-&gt;usb_dev, usb_rcvctrlpipe(dev-&gt;usb_dev, 0),</span>
 			       cmd, USB_TYPE_VENDOR | USB_RECIP_INTERFACE |
<span class="p_del">-			       USB_DIR_IN, value, index, data, len, 2000);</span>
<span class="p_add">+			       USB_DIR_IN, value, index, dmadata, len, 2000);</span>
<span class="p_add">+</span>
<span class="p_add">+	memcpy(data, dmadata, len);</span>
<span class="p_add">+	kfree(dmadata);</span>
<span class="p_add">+	return ret;</span>
 }
 
 static int usb_write(struct i2c_adapter *adapter, int cmd,
 		     int value, int index, void *data, int len)
 {
 	struct i2c_tiny_usb *dev = (struct i2c_tiny_usb *)adapter-&gt;algo_data;
<span class="p_add">+	void *dmadata = kmemdup(data, len, GFP_KERNEL);</span>
<span class="p_add">+	int ret;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (!dmadata)</span>
<span class="p_add">+		return -ENOMEM;</span>
 
 	/* do control transfer */
<span class="p_del">-	return usb_control_msg(dev-&gt;usb_dev, usb_sndctrlpipe(dev-&gt;usb_dev, 0),</span>
<span class="p_add">+	ret = usb_control_msg(dev-&gt;usb_dev, usb_sndctrlpipe(dev-&gt;usb_dev, 0),</span>
 			       cmd, USB_TYPE_VENDOR | USB_RECIP_INTERFACE,
<span class="p_del">-			       value, index, data, len, 2000);</span>
<span class="p_add">+			       value, index, dmadata, len, 2000);</span>
<span class="p_add">+</span>
<span class="p_add">+	kfree(dmadata);</span>
<span class="p_add">+	return ret;</span>
 }
 
 static void i2c_tiny_usb_free(struct i2c_tiny_usb *dev)
<span class="p_header">diff --git a/drivers/infiniband/hw/hfi1/rc.c b/drivers/infiniband/hw/hfi1/rc.c</span>
<span class="p_header">index 7382be11afca..aa71b7384640 100644</span>
<span class="p_header">--- a/drivers/infiniband/hw/hfi1/rc.c</span>
<span class="p_header">+++ b/drivers/infiniband/hw/hfi1/rc.c</span>
<span class="p_chunk">@@ -2149,8 +2149,11 @@</span> <span class="p_context"> void hfi1_rc_rcv(struct hfi1_packet *packet)</span>
 		ret = hfi1_rvt_get_rwqe(qp, 1);
 		if (ret &lt; 0)
 			goto nack_op_err;
<span class="p_del">-		if (!ret)</span>
<span class="p_add">+		if (!ret) {</span>
<span class="p_add">+			/* peer will send again */</span>
<span class="p_add">+			rvt_put_ss(&amp;qp-&gt;r_sge);</span>
 			goto rnr_nak;
<span class="p_add">+		}</span>
 		wc.ex.imm_data = ohdr-&gt;u.rc.imm_data;
 		wc.wc_flags = IB_WC_WITH_IMM;
 		goto send_last;
<span class="p_header">diff --git a/drivers/infiniband/hw/qib/qib_rc.c b/drivers/infiniband/hw/qib/qib_rc.c</span>
<span class="p_header">index 12658e3fe154..f7dfccf9a1e1 100644</span>
<span class="p_header">--- a/drivers/infiniband/hw/qib/qib_rc.c</span>
<span class="p_header">+++ b/drivers/infiniband/hw/qib/qib_rc.c</span>
<span class="p_chunk">@@ -1947,8 +1947,10 @@</span> <span class="p_context"> void qib_rc_rcv(struct qib_ctxtdata *rcd, struct ib_header *hdr,</span>
 		ret = qib_get_rwqe(qp, 1);
 		if (ret &lt; 0)
 			goto nack_op_err;
<span class="p_del">-		if (!ret)</span>
<span class="p_add">+		if (!ret) {</span>
<span class="p_add">+			rvt_put_ss(&amp;qp-&gt;r_sge);</span>
 			goto rnr_nak;
<span class="p_add">+		}</span>
 		wc.ex.imm_data = ohdr-&gt;u.rc.imm_data;
 		hdrsize += 4;
 		wc.wc_flags = IB_WC_WITH_IMM;
<span class="p_header">diff --git a/drivers/infiniband/ulp/srp/ib_srp.c b/drivers/infiniband/ulp/srp/ib_srp.c</span>
<span class="p_header">index cee46266f434..f6b5e14a7eab 100644</span>
<span class="p_header">--- a/drivers/infiniband/ulp/srp/ib_srp.c</span>
<span class="p_header">+++ b/drivers/infiniband/ulp/srp/ib_srp.c</span>
<span class="p_chunk">@@ -570,7 +570,7 @@</span> <span class="p_context"> static int srp_create_ch_ib(struct srp_rdma_ch *ch)</span>
 	return 0;
 
 err_qp:
<span class="p_del">-	srp_destroy_qp(ch, qp);</span>
<span class="p_add">+	ib_destroy_qp(qp);</span>
 
 err_send_cq:
 	ib_free_cq(send_cq);
<span class="p_header">diff --git a/drivers/mmc/host/sdhci-iproc.c b/drivers/mmc/host/sdhci-iproc.c</span>
<span class="p_header">index 3275d4995812..61666d269771 100644</span>
<span class="p_header">--- a/drivers/mmc/host/sdhci-iproc.c</span>
<span class="p_header">+++ b/drivers/mmc/host/sdhci-iproc.c</span>
<span class="p_chunk">@@ -187,7 +187,8 @@</span> <span class="p_context"> static const struct sdhci_iproc_data iproc_cygnus_data = {</span>
 };
 
 static const struct sdhci_pltfm_data sdhci_iproc_pltfm_data = {
<span class="p_del">-	.quirks = SDHCI_QUIRK_DATA_TIMEOUT_USES_SDCLK,</span>
<span class="p_add">+	.quirks = SDHCI_QUIRK_DATA_TIMEOUT_USES_SDCLK |</span>
<span class="p_add">+		  SDHCI_QUIRK_MULTIBLOCK_READ_ACMD12,</span>
 	.quirks2 = SDHCI_QUIRK2_ACMD23_BROKEN,
 	.ops = &amp;sdhci_iproc_ops,
 };
<span class="p_header">diff --git a/drivers/net/bonding/bond_3ad.c b/drivers/net/bonding/bond_3ad.c</span>
<span class="p_header">index edc70ffad660..6dcc42d79cab 100644</span>
<span class="p_header">--- a/drivers/net/bonding/bond_3ad.c</span>
<span class="p_header">+++ b/drivers/net/bonding/bond_3ad.c</span>
<span class="p_chunk">@@ -2573,7 +2573,7 @@</span> <span class="p_context"> int __bond_3ad_get_active_agg_info(struct bonding *bond,</span>
 		return -1;
 
 	ad_info-&gt;aggregator_id = aggregator-&gt;aggregator_identifier;
<span class="p_del">-	ad_info-&gt;ports = aggregator-&gt;num_of_ports;</span>
<span class="p_add">+	ad_info-&gt;ports = __agg_active_ports(aggregator);</span>
 	ad_info-&gt;actor_key = aggregator-&gt;actor_oper_aggregator_key;
 	ad_info-&gt;partner_key = aggregator-&gt;partner_oper_aggregator_key;
 	ether_addr_copy(ad_info-&gt;partner_system,
<span class="p_header">diff --git a/drivers/net/ethernet/emulex/benet/be_main.c b/drivers/net/ethernet/emulex/benet/be_main.c</span>
<span class="p_header">index 6be3b9aba8ed..ff617beb8502 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/emulex/benet/be_main.c</span>
<span class="p_header">+++ b/drivers/net/ethernet/emulex/benet/be_main.c</span>
<span class="p_chunk">@@ -5027,9 +5027,11 @@</span> <span class="p_context"> static netdev_features_t be_features_check(struct sk_buff *skb,</span>
 	struct be_adapter *adapter = netdev_priv(dev);
 	u8 l4_hdr = 0;
 
<span class="p_del">-	/* The code below restricts offload features for some tunneled packets.</span>
<span class="p_add">+	/* The code below restricts offload features for some tunneled and</span>
<span class="p_add">+	 * Q-in-Q packets.</span>
 	 * Offload features for normal (non tunnel) packets are unchanged.
 	 */
<span class="p_add">+	features = vlan_features_check(skb, features);</span>
 	if (!skb-&gt;encapsulation ||
 	    !(adapter-&gt;flags &amp; BE_FLAGS_VXLAN_OFFLOADS))
 		return features;
<span class="p_header">diff --git a/drivers/net/ethernet/mellanox/mlx5/core/cmd.c b/drivers/net/ethernet/mellanox/mlx5/core/cmd.c</span>
<span class="p_header">index a380353a78c2..f95c869c7c29 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/mellanox/mlx5/core/cmd.c</span>
<span class="p_header">+++ b/drivers/net/ethernet/mellanox/mlx5/core/cmd.c</span>
<span class="p_chunk">@@ -770,7 +770,7 @@</span> <span class="p_context"> static void cb_timeout_handler(struct work_struct *work)</span>
 	mlx5_core_warn(dev, &quot;%s(0x%x) timeout. Will cause a leak of a command resource\n&quot;,
 		       mlx5_command_str(msg_to_opcode(ent-&gt;in)),
 		       msg_to_opcode(ent-&gt;in));
<span class="p_del">-	mlx5_cmd_comp_handler(dev, 1UL &lt;&lt; ent-&gt;idx);</span>
<span class="p_add">+	mlx5_cmd_comp_handler(dev, 1UL &lt;&lt; ent-&gt;idx, true);</span>
 }
 
 static void cmd_work_handler(struct work_struct *work)
<span class="p_chunk">@@ -800,6 +800,7 @@</span> <span class="p_context"> static void cmd_work_handler(struct work_struct *work)</span>
 	}
 
 	cmd-&gt;ent_arr[ent-&gt;idx] = ent;
<span class="p_add">+	set_bit(MLX5_CMD_ENT_STATE_PENDING_COMP, &amp;ent-&gt;state);</span>
 	lay = get_inst(cmd, ent-&gt;idx);
 	ent-&gt;lay = lay;
 	memset(lay, 0, sizeof(*lay));
<span class="p_chunk">@@ -821,6 +822,20 @@</span> <span class="p_context"> static void cmd_work_handler(struct work_struct *work)</span>
 	if (ent-&gt;callback)
 		schedule_delayed_work(&amp;ent-&gt;cb_timeout_work, cb_timeout);
 
<span class="p_add">+	/* Skip sending command to fw if internal error */</span>
<span class="p_add">+	if (pci_channel_offline(dev-&gt;pdev) ||</span>
<span class="p_add">+	    dev-&gt;state == MLX5_DEVICE_STATE_INTERNAL_ERROR) {</span>
<span class="p_add">+		u8 status = 0;</span>
<span class="p_add">+		u32 drv_synd;</span>
<span class="p_add">+</span>
<span class="p_add">+		ent-&gt;ret = mlx5_internal_err_ret_value(dev, msg_to_opcode(ent-&gt;in), &amp;drv_synd, &amp;status);</span>
<span class="p_add">+		MLX5_SET(mbox_out, ent-&gt;out, status, status);</span>
<span class="p_add">+		MLX5_SET(mbox_out, ent-&gt;out, syndrome, drv_synd);</span>
<span class="p_add">+</span>
<span class="p_add">+		mlx5_cmd_comp_handler(dev, 1UL &lt;&lt; ent-&gt;idx, true);</span>
<span class="p_add">+		return;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
 	/* ring doorbell after the descriptor is valid */
 	mlx5_core_dbg(dev, &quot;writing 0x%x to command doorbell\n&quot;, 1 &lt;&lt; ent-&gt;idx);
 	wmb();
<span class="p_chunk">@@ -831,7 +846,7 @@</span> <span class="p_context"> static void cmd_work_handler(struct work_struct *work)</span>
 		poll_timeout(ent);
 		/* make sure we read the descriptor after ownership is SW */
 		rmb();
<span class="p_del">-		mlx5_cmd_comp_handler(dev, 1UL &lt;&lt; ent-&gt;idx);</span>
<span class="p_add">+		mlx5_cmd_comp_handler(dev, 1UL &lt;&lt; ent-&gt;idx, (ent-&gt;ret == -ETIMEDOUT));</span>
 	}
 }
 
<span class="p_chunk">@@ -875,7 +890,7 @@</span> <span class="p_context"> static int wait_func(struct mlx5_core_dev *dev, struct mlx5_cmd_work_ent *ent)</span>
 		wait_for_completion(&amp;ent-&gt;done);
 	} else if (!wait_for_completion_timeout(&amp;ent-&gt;done, timeout)) {
 		ent-&gt;ret = -ETIMEDOUT;
<span class="p_del">-		mlx5_cmd_comp_handler(dev, 1UL &lt;&lt; ent-&gt;idx);</span>
<span class="p_add">+		mlx5_cmd_comp_handler(dev, 1UL &lt;&lt; ent-&gt;idx, true);</span>
 	}
 
 	err = ent-&gt;ret;
<span class="p_chunk">@@ -1371,7 +1386,7 @@</span> <span class="p_context"> static void free_msg(struct mlx5_core_dev *dev, struct mlx5_cmd_msg *msg)</span>
 	}
 }
 
<span class="p_del">-void mlx5_cmd_comp_handler(struct mlx5_core_dev *dev, u64 vec)</span>
<span class="p_add">+void mlx5_cmd_comp_handler(struct mlx5_core_dev *dev, u64 vec, bool forced)</span>
 {
 	struct mlx5_cmd *cmd = &amp;dev-&gt;cmd;
 	struct mlx5_cmd_work_ent *ent;
<span class="p_chunk">@@ -1391,6 +1406,19 @@</span> <span class="p_context"> void mlx5_cmd_comp_handler(struct mlx5_core_dev *dev, u64 vec)</span>
 			struct semaphore *sem;
 
 			ent = cmd-&gt;ent_arr[i];
<span class="p_add">+</span>
<span class="p_add">+			/* if we already completed the command, ignore it */</span>
<span class="p_add">+			if (!test_and_clear_bit(MLX5_CMD_ENT_STATE_PENDING_COMP,</span>
<span class="p_add">+						&amp;ent-&gt;state)) {</span>
<span class="p_add">+				/* only real completion can free the cmd slot */</span>
<span class="p_add">+				if (!forced) {</span>
<span class="p_add">+					mlx5_core_err(dev, &quot;Command completion arrived after timeout (entry idx = %d).\n&quot;,</span>
<span class="p_add">+						      ent-&gt;idx);</span>
<span class="p_add">+					free_ent(cmd, ent-&gt;idx);</span>
<span class="p_add">+				}</span>
<span class="p_add">+				continue;</span>
<span class="p_add">+			}</span>
<span class="p_add">+</span>
 			if (ent-&gt;callback)
 				cancel_delayed_work(&amp;ent-&gt;cb_timeout_work);
 			if (ent-&gt;page_queue)
<span class="p_chunk">@@ -1413,7 +1441,10 @@</span> <span class="p_context"> void mlx5_cmd_comp_handler(struct mlx5_core_dev *dev, u64 vec)</span>
 				mlx5_core_dbg(dev, &quot;command completed. ret 0x%x, delivery status %s(0x%x)\n&quot;,
 					      ent-&gt;ret, deliv_status_to_str(ent-&gt;status), ent-&gt;status);
 			}
<span class="p_del">-			free_ent(cmd, ent-&gt;idx);</span>
<span class="p_add">+</span>
<span class="p_add">+			/* only real completion will free the entry slot */</span>
<span class="p_add">+			if (!forced)</span>
<span class="p_add">+				free_ent(cmd, ent-&gt;idx);</span>
 
 			if (ent-&gt;callback) {
 				ds = ent-&gt;ts2 - ent-&gt;ts1;
<span class="p_header">diff --git a/drivers/net/ethernet/mellanox/mlx5/core/en_ethtool.c b/drivers/net/ethernet/mellanox/mlx5/core/en_ethtool.c</span>
<span class="p_header">index a004a5a1a4c2..949fbadd7817 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/mellanox/mlx5/core/en_ethtool.c</span>
<span class="p_header">+++ b/drivers/net/ethernet/mellanox/mlx5/core/en_ethtool.c</span>
<span class="p_chunk">@@ -773,7 +773,6 @@</span> <span class="p_context"> static void get_supported(u32 eth_proto_cap,</span>
 	ptys2ethtool_supported_port(link_ksettings, eth_proto_cap);
 	ptys2ethtool_supported_link(supported, eth_proto_cap);
 	ethtool_link_ksettings_add_link_mode(link_ksettings, supported, Pause);
<span class="p_del">-	ethtool_link_ksettings_add_link_mode(link_ksettings, supported, Asym_Pause);</span>
 }
 
 static void get_advertising(u32 eth_proto_cap, u8 tx_pause,
<span class="p_chunk">@@ -783,7 +782,7 @@</span> <span class="p_context"> static void get_advertising(u32 eth_proto_cap, u8 tx_pause,</span>
 	unsigned long *advertising = link_ksettings-&gt;link_modes.advertising;
 
 	ptys2ethtool_adver_link(advertising, eth_proto_cap);
<span class="p_del">-	if (tx_pause)</span>
<span class="p_add">+	if (rx_pause)</span>
 		ethtool_link_ksettings_add_link_mode(link_ksettings, advertising, Pause);
 	if (tx_pause ^ rx_pause)
 		ethtool_link_ksettings_add_link_mode(link_ksettings, advertising, Asym_Pause);
<span class="p_chunk">@@ -828,6 +827,8 @@</span> <span class="p_context"> static int mlx5e_get_link_ksettings(struct net_device *netdev,</span>
 	struct mlx5e_priv *priv    = netdev_priv(netdev);
 	struct mlx5_core_dev *mdev = priv-&gt;mdev;
 	u32 out[MLX5_ST_SZ_DW(ptys_reg)] = {0};
<span class="p_add">+	u32 rx_pause = 0;</span>
<span class="p_add">+	u32 tx_pause = 0;</span>
 	u32 eth_proto_cap;
 	u32 eth_proto_admin;
 	u32 eth_proto_lp;
<span class="p_chunk">@@ -850,11 +851,13 @@</span> <span class="p_context"> static int mlx5e_get_link_ksettings(struct net_device *netdev,</span>
 	an_disable_admin = MLX5_GET(ptys_reg, out, an_disable_admin);
 	an_status        = MLX5_GET(ptys_reg, out, an_status);
 
<span class="p_add">+	mlx5_query_port_pause(mdev, &amp;rx_pause, &amp;tx_pause);</span>
<span class="p_add">+</span>
 	ethtool_link_ksettings_zero_link_mode(link_ksettings, supported);
 	ethtool_link_ksettings_zero_link_mode(link_ksettings, advertising);
 
 	get_supported(eth_proto_cap, link_ksettings);
<span class="p_del">-	get_advertising(eth_proto_admin, 0, 0, link_ksettings);</span>
<span class="p_add">+	get_advertising(eth_proto_admin, tx_pause, rx_pause, link_ksettings);</span>
 	get_speed_duplex(netdev, eth_proto_oper, link_ksettings);
 
 	eth_proto_oper = eth_proto_oper ? eth_proto_oper : eth_proto_cap;
<span class="p_header">diff --git a/drivers/net/ethernet/mellanox/mlx5/core/eq.c b/drivers/net/ethernet/mellanox/mlx5/core/eq.c</span>
<span class="p_header">index ea5d8d37a75c..33eae5ad2fb0 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/mellanox/mlx5/core/eq.c</span>
<span class="p_header">+++ b/drivers/net/ethernet/mellanox/mlx5/core/eq.c</span>
<span class="p_chunk">@@ -422,7 +422,7 @@</span> <span class="p_context"> static irqreturn_t mlx5_eq_int(int irq, void *eq_ptr)</span>
 			break;
 
 		case MLX5_EVENT_TYPE_CMD:
<span class="p_del">-			mlx5_cmd_comp_handler(dev, be32_to_cpu(eqe-&gt;data.cmd.vector));</span>
<span class="p_add">+			mlx5_cmd_comp_handler(dev, be32_to_cpu(eqe-&gt;data.cmd.vector), false);</span>
 			break;
 
 		case MLX5_EVENT_TYPE_PORT_CHANGE:
<span class="p_header">diff --git a/drivers/net/ethernet/mellanox/mlx5/core/health.c b/drivers/net/ethernet/mellanox/mlx5/core/health.c</span>
<span class="p_header">index d0515391d33b..44f59b1d6f0f 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/mellanox/mlx5/core/health.c</span>
<span class="p_header">+++ b/drivers/net/ethernet/mellanox/mlx5/core/health.c</span>
<span class="p_chunk">@@ -90,7 +90,7 @@</span> <span class="p_context"> static void trigger_cmd_completions(struct mlx5_core_dev *dev)</span>
 	spin_unlock_irqrestore(&amp;dev-&gt;cmd.alloc_lock, flags);
 
 	mlx5_core_dbg(dev, &quot;vector 0x%llx\n&quot;, vector);
<span class="p_del">-	mlx5_cmd_comp_handler(dev, vector);</span>
<span class="p_add">+	mlx5_cmd_comp_handler(dev, vector, true);</span>
 	return;
 
 no_trig:
<span class="p_header">diff --git a/drivers/net/geneve.c b/drivers/net/geneve.c</span>
<span class="p_header">index dec5d563ab19..959fd12d2e67 100644</span>
<span class="p_header">--- a/drivers/net/geneve.c</span>
<span class="p_header">+++ b/drivers/net/geneve.c</span>
<span class="p_chunk">@@ -1293,7 +1293,7 @@</span> <span class="p_context"> static int geneve_fill_info(struct sk_buff *skb, const struct net_device *dev)</span>
 	if (nla_put_u32(skb, IFLA_GENEVE_ID, vni))
 		goto nla_put_failure;
 
<span class="p_del">-	if (ip_tunnel_info_af(info) == AF_INET) {</span>
<span class="p_add">+	if (rtnl_dereference(geneve-&gt;sock4)) {</span>
 		if (nla_put_in_addr(skb, IFLA_GENEVE_REMOTE,
 				    info-&gt;key.u.ipv4.dst))
 			goto nla_put_failure;
<span class="p_chunk">@@ -1302,8 +1302,10 @@</span> <span class="p_context"> static int geneve_fill_info(struct sk_buff *skb, const struct net_device *dev)</span>
 			       !!(info-&gt;key.tun_flags &amp; TUNNEL_CSUM)))
 			goto nla_put_failure;
 
<span class="p_add">+	}</span>
<span class="p_add">+</span>
 #if IS_ENABLED(CONFIG_IPV6)
<span class="p_del">-	} else {</span>
<span class="p_add">+	if (rtnl_dereference(geneve-&gt;sock6)) {</span>
 		if (nla_put_in6_addr(skb, IFLA_GENEVE_REMOTE6,
 				     &amp;info-&gt;key.u.ipv6.dst))
 			goto nla_put_failure;
<span class="p_chunk">@@ -1315,8 +1317,8 @@</span> <span class="p_context"> static int geneve_fill_info(struct sk_buff *skb, const struct net_device *dev)</span>
 		if (nla_put_u8(skb, IFLA_GENEVE_UDP_ZERO_CSUM6_RX,
 			       !geneve-&gt;use_udp6_rx_checksums))
 			goto nla_put_failure;
<span class="p_del">-#endif</span>
 	}
<span class="p_add">+#endif</span>
 
 	if (nla_put_u8(skb, IFLA_GENEVE_TTL, info-&gt;key.ttl) ||
 	    nla_put_u8(skb, IFLA_GENEVE_TOS, info-&gt;key.tos) ||
<span class="p_header">diff --git a/drivers/net/phy/marvell.c b/drivers/net/phy/marvell.c</span>
<span class="p_header">index 272b051a0199..9097e42bec2e 100644</span>
<span class="p_header">--- a/drivers/net/phy/marvell.c</span>
<span class="p_header">+++ b/drivers/net/phy/marvell.c</span>
<span class="p_chunk">@@ -255,34 +255,6 @@</span> <span class="p_context"> static int marvell_config_aneg(struct phy_device *phydev)</span>
 {
 	int err;
 
<span class="p_del">-	/* The Marvell PHY has an errata which requires</span>
<span class="p_del">-	 * that certain registers get written in order</span>
<span class="p_del">-	 * to restart autonegotiation */</span>
<span class="p_del">-	err = phy_write(phydev, MII_BMCR, BMCR_RESET);</span>
<span class="p_del">-</span>
<span class="p_del">-	if (err &lt; 0)</span>
<span class="p_del">-		return err;</span>
<span class="p_del">-</span>
<span class="p_del">-	err = phy_write(phydev, 0x1d, 0x1f);</span>
<span class="p_del">-	if (err &lt; 0)</span>
<span class="p_del">-		return err;</span>
<span class="p_del">-</span>
<span class="p_del">-	err = phy_write(phydev, 0x1e, 0x200c);</span>
<span class="p_del">-	if (err &lt; 0)</span>
<span class="p_del">-		return err;</span>
<span class="p_del">-</span>
<span class="p_del">-	err = phy_write(phydev, 0x1d, 0x5);</span>
<span class="p_del">-	if (err &lt; 0)</span>
<span class="p_del">-		return err;</span>
<span class="p_del">-</span>
<span class="p_del">-	err = phy_write(phydev, 0x1e, 0);</span>
<span class="p_del">-	if (err &lt; 0)</span>
<span class="p_del">-		return err;</span>
<span class="p_del">-</span>
<span class="p_del">-	err = phy_write(phydev, 0x1e, 0x100);</span>
<span class="p_del">-	if (err &lt; 0)</span>
<span class="p_del">-		return err;</span>
<span class="p_del">-</span>
 	err = marvell_set_polarity(phydev, phydev-&gt;mdix_ctrl);
 	if (err &lt; 0)
 		return err;
<span class="p_chunk">@@ -316,6 +288,42 @@</span> <span class="p_context"> static int marvell_config_aneg(struct phy_device *phydev)</span>
 	return 0;
 }
 
<span class="p_add">+static int m88e1101_config_aneg(struct phy_device *phydev)</span>
<span class="p_add">+{</span>
<span class="p_add">+	int err;</span>
<span class="p_add">+</span>
<span class="p_add">+	/* This Marvell PHY has an errata which requires</span>
<span class="p_add">+	 * that certain registers get written in order</span>
<span class="p_add">+	 * to restart autonegotiation</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	err = phy_write(phydev, MII_BMCR, BMCR_RESET);</span>
<span class="p_add">+</span>
<span class="p_add">+	if (err &lt; 0)</span>
<span class="p_add">+		return err;</span>
<span class="p_add">+</span>
<span class="p_add">+	err = phy_write(phydev, 0x1d, 0x1f);</span>
<span class="p_add">+	if (err &lt; 0)</span>
<span class="p_add">+		return err;</span>
<span class="p_add">+</span>
<span class="p_add">+	err = phy_write(phydev, 0x1e, 0x200c);</span>
<span class="p_add">+	if (err &lt; 0)</span>
<span class="p_add">+		return err;</span>
<span class="p_add">+</span>
<span class="p_add">+	err = phy_write(phydev, 0x1d, 0x5);</span>
<span class="p_add">+	if (err &lt; 0)</span>
<span class="p_add">+		return err;</span>
<span class="p_add">+</span>
<span class="p_add">+	err = phy_write(phydev, 0x1e, 0);</span>
<span class="p_add">+	if (err &lt; 0)</span>
<span class="p_add">+		return err;</span>
<span class="p_add">+</span>
<span class="p_add">+	err = phy_write(phydev, 0x1e, 0x100);</span>
<span class="p_add">+	if (err &lt; 0)</span>
<span class="p_add">+		return err;</span>
<span class="p_add">+</span>
<span class="p_add">+	return marvell_config_aneg(phydev);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static int m88e1111_config_aneg(struct phy_device *phydev)
 {
 	int err;
<span class="p_chunk">@@ -1892,7 +1900,7 @@</span> <span class="p_context"> static struct phy_driver marvell_drivers[] = {</span>
 		.flags = PHY_HAS_INTERRUPT,
 		.probe = marvell_probe,
 		.config_init = &amp;marvell_config_init,
<span class="p_del">-		.config_aneg = &amp;marvell_config_aneg,</span>
<span class="p_add">+		.config_aneg = &amp;m88e1101_config_aneg,</span>
 		.read_status = &amp;genphy_read_status,
 		.ack_interrupt = &amp;marvell_ack_interrupt,
 		.config_intr = &amp;marvell_config_intr,
<span class="p_header">diff --git a/drivers/net/usb/qmi_wwan.c b/drivers/net/usb/qmi_wwan.c</span>
<span class="p_header">index 4e34568db64f..87746c2bc3d3 100644</span>
<span class="p_header">--- a/drivers/net/usb/qmi_wwan.c</span>
<span class="p_header">+++ b/drivers/net/usb/qmi_wwan.c</span>
<span class="p_chunk">@@ -902,6 +902,8 @@</span> <span class="p_context"> static const struct usb_device_id products[] = {</span>
 	{QMI_FIXED_INTF(0x1199, 0x9071, 10)},	/* Sierra Wireless MC74xx */
 	{QMI_FIXED_INTF(0x1199, 0x9079, 8)},	/* Sierra Wireless EM74xx */
 	{QMI_FIXED_INTF(0x1199, 0x9079, 10)},	/* Sierra Wireless EM74xx */
<span class="p_add">+	{QMI_FIXED_INTF(0x1199, 0x907b, 8)},	/* Sierra Wireless EM74xx */</span>
<span class="p_add">+	{QMI_FIXED_INTF(0x1199, 0x907b, 10)},	/* Sierra Wireless EM74xx */</span>
 	{QMI_FIXED_INTF(0x1bbb, 0x011e, 4)},	/* Telekom Speedstick LTE II (Alcatel One Touch L100V LTE) */
 	{QMI_FIXED_INTF(0x1bbb, 0x0203, 2)},	/* Alcatel L800MA */
 	{QMI_FIXED_INTF(0x2357, 0x0201, 4)},	/* TP-LINK HSUPA Modem MA180 */
<span class="p_header">diff --git a/drivers/net/virtio_net.c b/drivers/net/virtio_net.c</span>
<span class="p_header">index f36584616e7d..d9d8f4f43f90 100644</span>
<span class="p_header">--- a/drivers/net/virtio_net.c</span>
<span class="p_header">+++ b/drivers/net/virtio_net.c</span>
<span class="p_chunk">@@ -1894,6 +1894,7 @@</span> <span class="p_context"> static const struct net_device_ops virtnet_netdev = {</span>
 	.ndo_poll_controller = virtnet_netpoll,
 #endif
 	.ndo_xdp		= virtnet_xdp,
<span class="p_add">+	.ndo_features_check	= passthru_features_check,</span>
 };
 
 static void virtnet_config_changed_work(struct work_struct *work)
<span class="p_header">diff --git a/drivers/net/vrf.c b/drivers/net/vrf.c</span>
<span class="p_header">index 7d909c8183e9..df74efcf237b 100644</span>
<span class="p_header">--- a/drivers/net/vrf.c</span>
<span class="p_header">+++ b/drivers/net/vrf.c</span>
<span class="p_chunk">@@ -851,6 +851,7 @@</span> <span class="p_context"> static u32 vrf_fib_table(const struct net_device *dev)</span>
 
 static int vrf_rcv_finish(struct net *net, struct sock *sk, struct sk_buff *skb)
 {
<span class="p_add">+	kfree_skb(skb);</span>
 	return 0;
 }
 
<span class="p_chunk">@@ -860,7 +861,7 @@</span> <span class="p_context"> static struct sk_buff *vrf_rcv_nfhook(u8 pf, unsigned int hook,</span>
 {
 	struct net *net = dev_net(dev);
 
<span class="p_del">-	if (NF_HOOK(pf, hook, net, NULL, skb, dev, NULL, vrf_rcv_finish) &lt; 0)</span>
<span class="p_add">+	if (nf_hook(pf, hook, net, NULL, skb, dev, NULL, vrf_rcv_finish) != 1)</span>
 		skb = NULL;    /* kfree_skb(skb) handled by nf code */
 
 	return skb;
<span class="p_header">diff --git a/drivers/nvme/host/core.c b/drivers/nvme/host/core.c</span>
<span class="p_header">index eeb409c287b8..b3d3c5c2c92f 100644</span>
<span class="p_header">--- a/drivers/nvme/host/core.c</span>
<span class="p_header">+++ b/drivers/nvme/host/core.c</span>
<span class="p_chunk">@@ -2006,7 +2006,6 @@</span> <span class="p_context"> static void nvme_ns_remove(struct nvme_ns *ns)</span>
 		if (ns-&gt;ndev)
 			nvme_nvm_unregister_sysfs(ns);
 		del_gendisk(ns-&gt;disk);
<span class="p_del">-		blk_mq_abort_requeue_list(ns-&gt;queue);</span>
 		blk_cleanup_queue(ns-&gt;queue);
 	}
 
<span class="p_chunk">@@ -2344,8 +2343,16 @@</span> <span class="p_context"> void nvme_kill_queues(struct nvme_ctrl *ctrl)</span>
 			continue;
 		revalidate_disk(ns-&gt;disk);
 		blk_set_queue_dying(ns-&gt;queue);
<span class="p_del">-		blk_mq_abort_requeue_list(ns-&gt;queue);</span>
<span class="p_del">-		blk_mq_start_stopped_hw_queues(ns-&gt;queue, true);</span>
<span class="p_add">+</span>
<span class="p_add">+		/*</span>
<span class="p_add">+		 * Forcibly start all queues to avoid having stuck requests.</span>
<span class="p_add">+		 * Note that we must ensure the queues are not stopped</span>
<span class="p_add">+		 * when the final removal happens.</span>
<span class="p_add">+		 */</span>
<span class="p_add">+		blk_mq_start_hw_queues(ns-&gt;queue);</span>
<span class="p_add">+</span>
<span class="p_add">+		/* draining requests in requeue list */</span>
<span class="p_add">+		blk_mq_kick_requeue_list(ns-&gt;queue);</span>
 	}
 	mutex_unlock(&amp;ctrl-&gt;namespaces_mutex);
 }
<span class="p_header">diff --git a/drivers/nvme/host/rdma.c b/drivers/nvme/host/rdma.c</span>
<span class="p_header">index 16f84eb0b95e..0aba367ae465 100644</span>
<span class="p_header">--- a/drivers/nvme/host/rdma.c</span>
<span class="p_header">+++ b/drivers/nvme/host/rdma.c</span>
<span class="p_chunk">@@ -1029,6 +1029,19 @@</span> <span class="p_context"> static void nvme_rdma_send_done(struct ib_cq *cq, struct ib_wc *wc)</span>
 		nvme_rdma_wr_error(cq, wc, &quot;SEND&quot;);
 }
 
<span class="p_add">+static inline int nvme_rdma_queue_sig_limit(struct nvme_rdma_queue *queue)</span>
<span class="p_add">+{</span>
<span class="p_add">+	int sig_limit;</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * We signal completion every queue depth/2 and also handle the</span>
<span class="p_add">+	 * degenerated case of a  device with queue_depth=1, where we</span>
<span class="p_add">+	 * would need to signal every message.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	sig_limit = max(queue-&gt;queue_size / 2, 1);</span>
<span class="p_add">+	return (++queue-&gt;sig_count % sig_limit) == 0;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static int nvme_rdma_post_send(struct nvme_rdma_queue *queue,
 		struct nvme_rdma_qe *qe, struct ib_sge *sge, u32 num_sge,
 		struct ib_send_wr *first, bool flush)
<span class="p_chunk">@@ -1056,9 +1069,6 @@</span> <span class="p_context"> static int nvme_rdma_post_send(struct nvme_rdma_queue *queue,</span>
 	 * Would have been way to obvious to handle this in hardware or
 	 * at least the RDMA stack..
 	 *
<span class="p_del">-	 * This messy and racy code sniplet is copy and pasted from the iSER</span>
<span class="p_del">-	 * initiator, and the magic &#39;32&#39; comes from there as well.</span>
<span class="p_del">-	 *</span>
 	 * Always signal the flushes. The magic request used for the flush
 	 * sequencer is not allocated in our driver&#39;s tagset and it&#39;s
 	 * triggered to be freed by blk_cleanup_queue(). So we need to
<span class="p_chunk">@@ -1066,7 +1076,7 @@</span> <span class="p_context"> static int nvme_rdma_post_send(struct nvme_rdma_queue *queue,</span>
 	 * embedded in request&#39;s payload, is not freed when __ib_process_cq()
 	 * calls wr_cqe-&gt;done().
 	 */
<span class="p_del">-	if ((++queue-&gt;sig_count % 32) == 0 || flush)</span>
<span class="p_add">+	if (nvme_rdma_queue_sig_limit(queue) || flush)</span>
 		wr.send_flags |= IB_SEND_SIGNALED;
 
 	if (first)
<span class="p_header">diff --git a/drivers/s390/net/qeth_core.h b/drivers/s390/net/qeth_core.h</span>
<span class="p_header">index d9561e39c3b2..a26b7e8c0d10 100644</span>
<span class="p_header">--- a/drivers/s390/net/qeth_core.h</span>
<span class="p_header">+++ b/drivers/s390/net/qeth_core.h</span>
<span class="p_chunk">@@ -714,6 +714,7 @@</span> <span class="p_context"> enum qeth_discipline_id {</span>
 };
 
 struct qeth_discipline {
<span class="p_add">+	const struct device_type *devtype;</span>
 	void (*start_poll)(struct ccw_device *, int, unsigned long);
 	qdio_handler_t *input_handler;
 	qdio_handler_t *output_handler;
<span class="p_chunk">@@ -889,6 +890,9 @@</span> <span class="p_context"> extern struct qeth_discipline qeth_l2_discipline;</span>
 extern struct qeth_discipline qeth_l3_discipline;
 extern const struct attribute_group *qeth_generic_attr_groups[];
 extern const struct attribute_group *qeth_osn_attr_groups[];
<span class="p_add">+extern const struct attribute_group qeth_device_attr_group;</span>
<span class="p_add">+extern const struct attribute_group qeth_device_blkt_group;</span>
<span class="p_add">+extern const struct device_type qeth_generic_devtype;</span>
 extern struct workqueue_struct *qeth_wq;
 
 int qeth_card_hw_is_reachable(struct qeth_card *);
<span class="p_header">diff --git a/drivers/s390/net/qeth_core_main.c b/drivers/s390/net/qeth_core_main.c</span>
<span class="p_header">index 9a5f99ccb122..3a8ff756a025 100644</span>
<span class="p_header">--- a/drivers/s390/net/qeth_core_main.c</span>
<span class="p_header">+++ b/drivers/s390/net/qeth_core_main.c</span>
<span class="p_chunk">@@ -5460,10 +5460,12 @@</span> <span class="p_context"> void qeth_core_free_discipline(struct qeth_card *card)</span>
 	card-&gt;discipline = NULL;
 }
 
<span class="p_del">-static const struct device_type qeth_generic_devtype = {</span>
<span class="p_add">+const struct device_type qeth_generic_devtype = {</span>
 	.name = &quot;qeth_generic&quot;,
 	.groups = qeth_generic_attr_groups,
 };
<span class="p_add">+EXPORT_SYMBOL_GPL(qeth_generic_devtype);</span>
<span class="p_add">+</span>
 static const struct device_type qeth_osn_devtype = {
 	.name = &quot;qeth_osn&quot;,
 	.groups = qeth_osn_attr_groups,
<span class="p_chunk">@@ -5589,23 +5591,22 @@</span> <span class="p_context"> static int qeth_core_probe_device(struct ccwgroup_device *gdev)</span>
 		goto err_card;
 	}
 
<span class="p_del">-	if (card-&gt;info.type == QETH_CARD_TYPE_OSN)</span>
<span class="p_del">-		gdev-&gt;dev.type = &amp;qeth_osn_devtype;</span>
<span class="p_del">-	else</span>
<span class="p_del">-		gdev-&gt;dev.type = &amp;qeth_generic_devtype;</span>
<span class="p_del">-</span>
 	switch (card-&gt;info.type) {
 	case QETH_CARD_TYPE_OSN:
 	case QETH_CARD_TYPE_OSM:
 		rc = qeth_core_load_discipline(card, QETH_DISCIPLINE_LAYER2);
 		if (rc)
 			goto err_card;
<span class="p_add">+</span>
<span class="p_add">+		gdev-&gt;dev.type = (card-&gt;info.type != QETH_CARD_TYPE_OSN)</span>
<span class="p_add">+					? card-&gt;discipline-&gt;devtype</span>
<span class="p_add">+					: &amp;qeth_osn_devtype;</span>
 		rc = card-&gt;discipline-&gt;setup(card-&gt;gdev);
 		if (rc)
 			goto err_disc;
<span class="p_del">-	case QETH_CARD_TYPE_OSD:</span>
<span class="p_del">-	case QETH_CARD_TYPE_OSX:</span>
<span class="p_add">+		break;</span>
 	default:
<span class="p_add">+		gdev-&gt;dev.type = &amp;qeth_generic_devtype;</span>
 		break;
 	}
 
<span class="p_chunk">@@ -5661,8 +5662,10 @@</span> <span class="p_context"> static int qeth_core_set_online(struct ccwgroup_device *gdev)</span>
 		if (rc)
 			goto err;
 		rc = card-&gt;discipline-&gt;setup(card-&gt;gdev);
<span class="p_del">-		if (rc)</span>
<span class="p_add">+		if (rc) {</span>
<span class="p_add">+			qeth_core_free_discipline(card);</span>
 			goto err;
<span class="p_add">+		}</span>
 	}
 	rc = card-&gt;discipline-&gt;set_online(gdev);
 err:
<span class="p_header">diff --git a/drivers/s390/net/qeth_core_sys.c b/drivers/s390/net/qeth_core_sys.c</span>
<span class="p_header">index 75b29fd2fcf4..db6a285d41e0 100644</span>
<span class="p_header">--- a/drivers/s390/net/qeth_core_sys.c</span>
<span class="p_header">+++ b/drivers/s390/net/qeth_core_sys.c</span>
<span class="p_chunk">@@ -413,12 +413,16 @@</span> <span class="p_context"> static ssize_t qeth_dev_layer2_store(struct device *dev,</span>
 
 	if (card-&gt;options.layer2 == newdis)
 		goto out;
<span class="p_del">-	else {</span>
<span class="p_del">-		card-&gt;info.mac_bits  = 0;</span>
<span class="p_del">-		if (card-&gt;discipline) {</span>
<span class="p_del">-			card-&gt;discipline-&gt;remove(card-&gt;gdev);</span>
<span class="p_del">-			qeth_core_free_discipline(card);</span>
<span class="p_del">-		}</span>
<span class="p_add">+	if (card-&gt;info.type == QETH_CARD_TYPE_OSM) {</span>
<span class="p_add">+		/* fixed layer, can&#39;t switch */</span>
<span class="p_add">+		rc = -EOPNOTSUPP;</span>
<span class="p_add">+		goto out;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	card-&gt;info.mac_bits = 0;</span>
<span class="p_add">+	if (card-&gt;discipline) {</span>
<span class="p_add">+		card-&gt;discipline-&gt;remove(card-&gt;gdev);</span>
<span class="p_add">+		qeth_core_free_discipline(card);</span>
 	}
 
 	rc = qeth_core_load_discipline(card, newdis);
<span class="p_chunk">@@ -426,6 +430,8 @@</span> <span class="p_context"> static ssize_t qeth_dev_layer2_store(struct device *dev,</span>
 		goto out;
 
 	rc = card-&gt;discipline-&gt;setup(card-&gt;gdev);
<span class="p_add">+	if (rc)</span>
<span class="p_add">+		qeth_core_free_discipline(card);</span>
 out:
 	mutex_unlock(&amp;card-&gt;discipline_mutex);
 	return rc ? rc : count;
<span class="p_chunk">@@ -703,10 +709,11 @@</span> <span class="p_context"> static struct attribute *qeth_blkt_device_attrs[] = {</span>
 	&amp;dev_attr_inter_jumbo.attr,
 	NULL,
 };
<span class="p_del">-static struct attribute_group qeth_device_blkt_group = {</span>
<span class="p_add">+const struct attribute_group qeth_device_blkt_group = {</span>
 	.name = &quot;blkt&quot;,
 	.attrs = qeth_blkt_device_attrs,
 };
<span class="p_add">+EXPORT_SYMBOL_GPL(qeth_device_blkt_group);</span>
 
 static struct attribute *qeth_device_attrs[] = {
 	&amp;dev_attr_state.attr,
<span class="p_chunk">@@ -726,9 +733,10 @@</span> <span class="p_context"> static struct attribute *qeth_device_attrs[] = {</span>
 	&amp;dev_attr_switch_attrs.attr,
 	NULL,
 };
<span class="p_del">-static struct attribute_group qeth_device_attr_group = {</span>
<span class="p_add">+const struct attribute_group qeth_device_attr_group = {</span>
 	.attrs = qeth_device_attrs,
 };
<span class="p_add">+EXPORT_SYMBOL_GPL(qeth_device_attr_group);</span>
 
 const struct attribute_group *qeth_generic_attr_groups[] = {
 	&amp;qeth_device_attr_group,
<span class="p_header">diff --git a/drivers/s390/net/qeth_l2.h b/drivers/s390/net/qeth_l2.h</span>
<span class="p_header">index 29d9fb3890ad..0d59f9a45ea9 100644</span>
<span class="p_header">--- a/drivers/s390/net/qeth_l2.h</span>
<span class="p_header">+++ b/drivers/s390/net/qeth_l2.h</span>
<span class="p_chunk">@@ -8,6 +8,8 @@</span> <span class="p_context"></span>
 
 #include &quot;qeth_core.h&quot;
 
<span class="p_add">+extern const struct attribute_group *qeth_l2_attr_groups[];</span>
<span class="p_add">+</span>
 int qeth_l2_create_device_attributes(struct device *);
 void qeth_l2_remove_device_attributes(struct device *);
 void qeth_l2_setup_bridgeport_attrs(struct qeth_card *card);
<span class="p_header">diff --git a/drivers/s390/net/qeth_l2_main.c b/drivers/s390/net/qeth_l2_main.c</span>
<span class="p_header">index af4e6a639fec..a2bb77d7e5bb 100644</span>
<span class="p_header">--- a/drivers/s390/net/qeth_l2_main.c</span>
<span class="p_header">+++ b/drivers/s390/net/qeth_l2_main.c</span>
<span class="p_chunk">@@ -1006,11 +1006,21 @@</span> <span class="p_context"> static int qeth_l2_stop(struct net_device *dev)</span>
 	return 0;
 }
 
<span class="p_add">+static const struct device_type qeth_l2_devtype = {</span>
<span class="p_add">+	.name = &quot;qeth_layer2&quot;,</span>
<span class="p_add">+	.groups = qeth_l2_attr_groups,</span>
<span class="p_add">+};</span>
<span class="p_add">+</span>
 static int qeth_l2_probe_device(struct ccwgroup_device *gdev)
 {
 	struct qeth_card *card = dev_get_drvdata(&amp;gdev-&gt;dev);
<span class="p_add">+	int rc;</span>
 
<span class="p_del">-	qeth_l2_create_device_attributes(&amp;gdev-&gt;dev);</span>
<span class="p_add">+	if (gdev-&gt;dev.type == &amp;qeth_generic_devtype) {</span>
<span class="p_add">+		rc = qeth_l2_create_device_attributes(&amp;gdev-&gt;dev);</span>
<span class="p_add">+		if (rc)</span>
<span class="p_add">+			return rc;</span>
<span class="p_add">+	}</span>
 	INIT_LIST_HEAD(&amp;card-&gt;vid_list);
 	hash_init(card-&gt;mac_htable);
 	card-&gt;options.layer2 = 1;
<span class="p_chunk">@@ -1022,7 +1032,8 @@</span> <span class="p_context"> static void qeth_l2_remove_device(struct ccwgroup_device *cgdev)</span>
 {
 	struct qeth_card *card = dev_get_drvdata(&amp;cgdev-&gt;dev);
 
<span class="p_del">-	qeth_l2_remove_device_attributes(&amp;cgdev-&gt;dev);</span>
<span class="p_add">+	if (cgdev-&gt;dev.type == &amp;qeth_generic_devtype)</span>
<span class="p_add">+		qeth_l2_remove_device_attributes(&amp;cgdev-&gt;dev);</span>
 	qeth_set_allowed_threads(card, 0, 1);
 	wait_event(card-&gt;wait_q, qeth_threads_running(card, 0xffffffff) == 0);
 
<span class="p_chunk">@@ -1080,7 +1091,6 @@</span> <span class="p_context"> static int qeth_l2_setup_netdev(struct qeth_card *card)</span>
 	case QETH_CARD_TYPE_OSN:
 		card-&gt;dev = alloc_netdev(0, &quot;osn%d&quot;, NET_NAME_UNKNOWN,
 					 ether_setup);
<span class="p_del">-		card-&gt;dev-&gt;flags |= IFF_NOARP;</span>
 		break;
 	default:
 		card-&gt;dev = alloc_etherdev(0);
<span class="p_chunk">@@ -1095,9 +1105,12 @@</span> <span class="p_context"> static int qeth_l2_setup_netdev(struct qeth_card *card)</span>
 	card-&gt;dev-&gt;min_mtu = 64;
 	card-&gt;dev-&gt;max_mtu = ETH_MAX_MTU;
 	card-&gt;dev-&gt;netdev_ops = &amp;qeth_l2_netdev_ops;
<span class="p_del">-	card-&gt;dev-&gt;ethtool_ops =</span>
<span class="p_del">-		(card-&gt;info.type != QETH_CARD_TYPE_OSN) ?</span>
<span class="p_del">-		&amp;qeth_l2_ethtool_ops : &amp;qeth_l2_osn_ops;</span>
<span class="p_add">+	if (card-&gt;info.type == QETH_CARD_TYPE_OSN) {</span>
<span class="p_add">+		card-&gt;dev-&gt;ethtool_ops = &amp;qeth_l2_osn_ops;</span>
<span class="p_add">+		card-&gt;dev-&gt;flags |= IFF_NOARP;</span>
<span class="p_add">+	} else {</span>
<span class="p_add">+		card-&gt;dev-&gt;ethtool_ops = &amp;qeth_l2_ethtool_ops;</span>
<span class="p_add">+	}</span>
 	card-&gt;dev-&gt;features |= NETIF_F_HW_VLAN_CTAG_FILTER;
 	if (card-&gt;info.type == QETH_CARD_TYPE_OSD &amp;&amp; !card-&gt;info.guestlan) {
 		card-&gt;dev-&gt;hw_features = NETIF_F_SG;
<span class="p_chunk">@@ -1406,6 +1419,7 @@</span> <span class="p_context"> static int qeth_l2_control_event(struct qeth_card *card,</span>
 }
 
 struct qeth_discipline qeth_l2_discipline = {
<span class="p_add">+	.devtype = &amp;qeth_l2_devtype,</span>
 	.start_poll = qeth_qdio_start_poll,
 	.input_handler = (qdio_handler_t *) qeth_qdio_input_handler,
 	.output_handler = (qdio_handler_t *) qeth_qdio_output_handler,
<span class="p_header">diff --git a/drivers/s390/net/qeth_l2_sys.c b/drivers/s390/net/qeth_l2_sys.c</span>
<span class="p_header">index 692db49e3d2a..a48ed9e7e168 100644</span>
<span class="p_header">--- a/drivers/s390/net/qeth_l2_sys.c</span>
<span class="p_header">+++ b/drivers/s390/net/qeth_l2_sys.c</span>
<span class="p_chunk">@@ -272,3 +272,11 @@</span> <span class="p_context"> void qeth_l2_setup_bridgeport_attrs(struct qeth_card *card)</span>
 	} else
 		qeth_bridgeport_an_set(card, 0);
 }
<span class="p_add">+</span>
<span class="p_add">+const struct attribute_group *qeth_l2_attr_groups[] = {</span>
<span class="p_add">+	&amp;qeth_device_attr_group,</span>
<span class="p_add">+	&amp;qeth_device_blkt_group,</span>
<span class="p_add">+	/* l2 specific, see l2_{create,remove}_device_attributes(): */</span>
<span class="p_add">+	&amp;qeth_l2_bridgeport_attr_group,</span>
<span class="p_add">+	NULL,</span>
<span class="p_add">+};</span>
<span class="p_header">diff --git a/drivers/s390/net/qeth_l3_main.c b/drivers/s390/net/qeth_l3_main.c</span>
<span class="p_header">index 653f0fb76573..d2fb50fd03dc 100644</span>
<span class="p_header">--- a/drivers/s390/net/qeth_l3_main.c</span>
<span class="p_header">+++ b/drivers/s390/net/qeth_l3_main.c</span>
<span class="p_chunk">@@ -3153,8 +3153,13 @@</span> <span class="p_context"> static int qeth_l3_setup_netdev(struct qeth_card *card)</span>
 static int qeth_l3_probe_device(struct ccwgroup_device *gdev)
 {
 	struct qeth_card *card = dev_get_drvdata(&amp;gdev-&gt;dev);
<span class="p_add">+	int rc;</span>
 
<span class="p_del">-	qeth_l3_create_device_attributes(&amp;gdev-&gt;dev);</span>
<span class="p_add">+	rc = qeth_l3_create_device_attributes(&amp;gdev-&gt;dev);</span>
<span class="p_add">+	if (rc)</span>
<span class="p_add">+		return rc;</span>
<span class="p_add">+	hash_init(card-&gt;ip_htable);</span>
<span class="p_add">+	hash_init(card-&gt;ip_mc_htable);</span>
 	card-&gt;options.layer2 = 0;
 	card-&gt;info.hwtrap = 0;
 	return 0;
<span class="p_chunk">@@ -3431,6 +3436,7 @@</span> <span class="p_context"> static int qeth_l3_control_event(struct qeth_card *card,</span>
 }
 
 struct qeth_discipline qeth_l3_discipline = {
<span class="p_add">+	.devtype = &amp;qeth_generic_devtype,</span>
 	.start_poll = qeth_qdio_start_poll,
 	.input_handler = (qdio_handler_t *) qeth_qdio_input_handler,
 	.output_handler = (qdio_handler_t *) qeth_qdio_output_handler,
<span class="p_header">diff --git a/drivers/scsi/device_handler/scsi_dh_rdac.c b/drivers/scsi/device_handler/scsi_dh_rdac.c</span>
<span class="p_header">index 3cbab8710e58..2ceff585f189 100644</span>
<span class="p_header">--- a/drivers/scsi/device_handler/scsi_dh_rdac.c</span>
<span class="p_header">+++ b/drivers/scsi/device_handler/scsi_dh_rdac.c</span>
<span class="p_chunk">@@ -265,18 +265,16 @@</span> <span class="p_context"> static unsigned int rdac_failover_get(struct rdac_controller *ctlr,</span>
 				      struct list_head *list,
 				      unsigned char *cdb)
 {
<span class="p_del">-	struct scsi_device *sdev = ctlr-&gt;ms_sdev;</span>
<span class="p_del">-	struct rdac_dh_data *h = sdev-&gt;handler_data;</span>
 	struct rdac_mode_common *common;
 	unsigned data_size;
 	struct rdac_queue_data *qdata;
 	u8 *lun_table;
 
<span class="p_del">-	if (h-&gt;ctlr-&gt;use_ms10) {</span>
<span class="p_add">+	if (ctlr-&gt;use_ms10) {</span>
 		struct rdac_pg_expanded *rdac_pg;
 
 		data_size = sizeof(struct rdac_pg_expanded);
<span class="p_del">-		rdac_pg = &amp;h-&gt;ctlr-&gt;mode_select.expanded;</span>
<span class="p_add">+		rdac_pg = &amp;ctlr-&gt;mode_select.expanded;</span>
 		memset(rdac_pg, 0, data_size);
 		common = &amp;rdac_pg-&gt;common;
 		rdac_pg-&gt;page_code = RDAC_PAGE_CODE_REDUNDANT_CONTROLLER + 0x40;
<span class="p_chunk">@@ -288,7 +286,7 @@</span> <span class="p_context"> static unsigned int rdac_failover_get(struct rdac_controller *ctlr,</span>
 		struct rdac_pg_legacy *rdac_pg;
 
 		data_size = sizeof(struct rdac_pg_legacy);
<span class="p_del">-		rdac_pg = &amp;h-&gt;ctlr-&gt;mode_select.legacy;</span>
<span class="p_add">+		rdac_pg = &amp;ctlr-&gt;mode_select.legacy;</span>
 		memset(rdac_pg, 0, data_size);
 		common = &amp;rdac_pg-&gt;common;
 		rdac_pg-&gt;page_code = RDAC_PAGE_CODE_REDUNDANT_CONTROLLER;
<span class="p_chunk">@@ -304,7 +302,7 @@</span> <span class="p_context"> static unsigned int rdac_failover_get(struct rdac_controller *ctlr,</span>
 	}
 
 	/* Prepare the command. */
<span class="p_del">-	if (h-&gt;ctlr-&gt;use_ms10) {</span>
<span class="p_add">+	if (ctlr-&gt;use_ms10) {</span>
 		cdb[0] = MODE_SELECT_10;
 		cdb[7] = data_size &gt;&gt; 8;
 		cdb[8] = data_size &amp; 0xff;
<span class="p_header">diff --git a/drivers/scsi/ibmvscsi_tgt/ibmvscsi_tgt.c b/drivers/scsi/ibmvscsi_tgt/ibmvscsi_tgt.c</span>
<span class="p_header">index d390325c99ec..abf6026645dd 100644</span>
<span class="p_header">--- a/drivers/scsi/ibmvscsi_tgt/ibmvscsi_tgt.c</span>
<span class="p_header">+++ b/drivers/scsi/ibmvscsi_tgt/ibmvscsi_tgt.c</span>
<span class="p_chunk">@@ -1170,6 +1170,8 @@</span> <span class="p_context"> static struct ibmvscsis_cmd *ibmvscsis_get_free_cmd(struct scsi_info *vscsi)</span>
 		cmd = list_first_entry_or_null(&amp;vscsi-&gt;free_cmd,
 					       struct ibmvscsis_cmd, list);
 		if (cmd) {
<span class="p_add">+			if (cmd-&gt;abort_cmd)</span>
<span class="p_add">+				cmd-&gt;abort_cmd = NULL;</span>
 			cmd-&gt;flags &amp;= ~(DELAY_SEND);
 			list_del(&amp;cmd-&gt;list);
 			cmd-&gt;iue = iue;
<span class="p_chunk">@@ -1774,6 +1776,7 @@</span> <span class="p_context"> static void ibmvscsis_send_messages(struct scsi_info *vscsi)</span>
 				if (cmd-&gt;abort_cmd) {
 					retry = true;
 					cmd-&gt;abort_cmd-&gt;flags &amp;= ~(DELAY_SEND);
<span class="p_add">+					cmd-&gt;abort_cmd = NULL;</span>
 				}
 
 				/*
<span class="p_chunk">@@ -1788,6 +1791,25 @@</span> <span class="p_context"> static void ibmvscsis_send_messages(struct scsi_info *vscsi)</span>
 					list_del(&amp;cmd-&gt;list);
 					ibmvscsis_free_cmd_resources(vscsi,
 								     cmd);
<span class="p_add">+					/*</span>
<span class="p_add">+					 * With a successfully aborted op</span>
<span class="p_add">+					 * through LIO we want to increment the</span>
<span class="p_add">+					 * the vscsi credit so that when we dont</span>
<span class="p_add">+					 * send a rsp to the original scsi abort</span>
<span class="p_add">+					 * op (h_send_crq), but the tm rsp to</span>
<span class="p_add">+					 * the abort is sent, the credit is</span>
<span class="p_add">+					 * correctly sent with the abort tm rsp.</span>
<span class="p_add">+					 * We would need 1 for the abort tm rsp</span>
<span class="p_add">+					 * and 1 credit for the aborted scsi op.</span>
<span class="p_add">+					 * Thus we need to increment here.</span>
<span class="p_add">+					 * Also we want to increment the credit</span>
<span class="p_add">+					 * here because we want to make sure</span>
<span class="p_add">+					 * cmd is actually released first</span>
<span class="p_add">+					 * otherwise the client will think it</span>
<span class="p_add">+					 * it can send a new cmd, and we could</span>
<span class="p_add">+					 * find ourselves short of cmd elements.</span>
<span class="p_add">+					 */</span>
<span class="p_add">+					vscsi-&gt;credit += 1;</span>
 				} else {
 					iue = cmd-&gt;iue;
 
<span class="p_chunk">@@ -2962,10 +2984,7 @@</span> <span class="p_context"> static long srp_build_response(struct scsi_info *vscsi,</span>
 
 	rsp-&gt;opcode = SRP_RSP;
 
<span class="p_del">-	if (vscsi-&gt;credit &gt; 0 &amp;&amp; vscsi-&gt;state == SRP_PROCESSING)</span>
<span class="p_del">-		rsp-&gt;req_lim_delta = cpu_to_be32(vscsi-&gt;credit);</span>
<span class="p_del">-	else</span>
<span class="p_del">-		rsp-&gt;req_lim_delta = cpu_to_be32(1 + vscsi-&gt;credit);</span>
<span class="p_add">+	rsp-&gt;req_lim_delta = cpu_to_be32(1 + vscsi-&gt;credit);</span>
 	rsp-&gt;tag = cmd-&gt;rsp.tag;
 	rsp-&gt;flags = 0;
 
<span class="p_header">diff --git a/drivers/scsi/scsi_lib.c b/drivers/scsi/scsi_lib.c</span>
<span class="p_header">index 15c9fe766071..464e7a989cc5 100644</span>
<span class="p_header">--- a/drivers/scsi/scsi_lib.c</span>
<span class="p_header">+++ b/drivers/scsi/scsi_lib.c</span>
<span class="p_chunk">@@ -1850,7 +1850,7 @@</span> <span class="p_context"> static int scsi_mq_prep_fn(struct request *req)</span>
 
 	/* zero out the cmd, except for the embedded scsi_request */
 	memset((char *)cmd + sizeof(cmd-&gt;req), 0,
<span class="p_del">-		sizeof(*cmd) - sizeof(cmd-&gt;req));</span>
<span class="p_add">+		sizeof(*cmd) - sizeof(cmd-&gt;req) + shost-&gt;hostt-&gt;cmd_size);</span>
 
 	req-&gt;special = cmd;
 
<span class="p_header">diff --git a/drivers/target/iscsi/iscsi_target.c b/drivers/target/iscsi/iscsi_target.c</span>
<span class="p_header">index 8beed3451346..fd45b48480cb 100644</span>
<span class="p_header">--- a/drivers/target/iscsi/iscsi_target.c</span>
<span class="p_header">+++ b/drivers/target/iscsi/iscsi_target.c</span>
<span class="p_chunk">@@ -3810,6 +3810,8 @@</span> <span class="p_context"> int iscsi_target_tx_thread(void *arg)</span>
 {
 	int ret = 0;
 	struct iscsi_conn *conn = arg;
<span class="p_add">+	bool conn_freed = false;</span>
<span class="p_add">+</span>
 	/*
 	 * Allow ourselves to be interrupted by SIGINT so that a
 	 * connection recovery / failure event can be triggered externally.
<span class="p_chunk">@@ -3835,12 +3837,14 @@</span> <span class="p_context"> int iscsi_target_tx_thread(void *arg)</span>
 			goto transport_err;
 
 		ret = iscsit_handle_response_queue(conn);
<span class="p_del">-		if (ret == 1)</span>
<span class="p_add">+		if (ret == 1) {</span>
 			goto get_immediate;
<span class="p_del">-		else if (ret == -ECONNRESET)</span>
<span class="p_add">+		} else if (ret == -ECONNRESET) {</span>
<span class="p_add">+			conn_freed = true;</span>
 			goto out;
<span class="p_del">-		else if (ret &lt; 0)</span>
<span class="p_add">+		} else if (ret &lt; 0) {</span>
 			goto transport_err;
<span class="p_add">+		}</span>
 	}
 
 transport_err:
<span class="p_chunk">@@ -3850,8 +3854,13 @@</span> <span class="p_context"> int iscsi_target_tx_thread(void *arg)</span>
 	 * responsible for cleaning up the early connection failure.
 	 */
 	if (conn-&gt;conn_state != TARG_CONN_STATE_IN_LOGIN)
<span class="p_del">-		iscsit_take_action_for_connection_exit(conn);</span>
<span class="p_add">+		iscsit_take_action_for_connection_exit(conn, &amp;conn_freed);</span>
 out:
<span class="p_add">+	if (!conn_freed) {</span>
<span class="p_add">+		while (!kthread_should_stop()) {</span>
<span class="p_add">+			msleep(100);</span>
<span class="p_add">+		}</span>
<span class="p_add">+	}</span>
 	return 0;
 }
 
<span class="p_chunk">@@ -4024,6 +4033,7 @@</span> <span class="p_context"> int iscsi_target_rx_thread(void *arg)</span>
 {
 	int rc;
 	struct iscsi_conn *conn = arg;
<span class="p_add">+	bool conn_freed = false;</span>
 
 	/*
 	 * Allow ourselves to be interrupted by SIGINT so that a
<span class="p_chunk">@@ -4036,7 +4046,7 @@</span> <span class="p_context"> int iscsi_target_rx_thread(void *arg)</span>
 	 */
 	rc = wait_for_completion_interruptible(&amp;conn-&gt;rx_login_comp);
 	if (rc &lt; 0 || iscsi_target_check_conn_state(conn))
<span class="p_del">-		return 0;</span>
<span class="p_add">+		goto out;</span>
 
 	if (!conn-&gt;conn_transport-&gt;iscsit_get_rx_pdu)
 		return 0;
<span class="p_chunk">@@ -4045,7 +4055,15 @@</span> <span class="p_context"> int iscsi_target_rx_thread(void *arg)</span>
 
 	if (!signal_pending(current))
 		atomic_set(&amp;conn-&gt;transport_failed, 1);
<span class="p_del">-	iscsit_take_action_for_connection_exit(conn);</span>
<span class="p_add">+	iscsit_take_action_for_connection_exit(conn, &amp;conn_freed);</span>
<span class="p_add">+</span>
<span class="p_add">+out:</span>
<span class="p_add">+	if (!conn_freed) {</span>
<span class="p_add">+		while (!kthread_should_stop()) {</span>
<span class="p_add">+			msleep(100);</span>
<span class="p_add">+		}</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
 	return 0;
 }
 
<span class="p_header">diff --git a/drivers/target/iscsi/iscsi_target_erl0.c b/drivers/target/iscsi/iscsi_target_erl0.c</span>
<span class="p_header">index 9a96e17bf7cd..7fe2aa73cff6 100644</span>
<span class="p_header">--- a/drivers/target/iscsi/iscsi_target_erl0.c</span>
<span class="p_header">+++ b/drivers/target/iscsi/iscsi_target_erl0.c</span>
<span class="p_chunk">@@ -930,8 +930,10 @@</span> <span class="p_context"> static void iscsit_handle_connection_cleanup(struct iscsi_conn *conn)</span>
 	}
 }
 
<span class="p_del">-void iscsit_take_action_for_connection_exit(struct iscsi_conn *conn)</span>
<span class="p_add">+void iscsit_take_action_for_connection_exit(struct iscsi_conn *conn, bool *conn_freed)</span>
 {
<span class="p_add">+	*conn_freed = false;</span>
<span class="p_add">+</span>
 	spin_lock_bh(&amp;conn-&gt;state_lock);
 	if (atomic_read(&amp;conn-&gt;connection_exit)) {
 		spin_unlock_bh(&amp;conn-&gt;state_lock);
<span class="p_chunk">@@ -942,6 +944,7 @@</span> <span class="p_context"> void iscsit_take_action_for_connection_exit(struct iscsi_conn *conn)</span>
 	if (conn-&gt;conn_state == TARG_CONN_STATE_IN_LOGOUT) {
 		spin_unlock_bh(&amp;conn-&gt;state_lock);
 		iscsit_close_connection(conn);
<span class="p_add">+		*conn_freed = true;</span>
 		return;
 	}
 
<span class="p_chunk">@@ -955,4 +958,5 @@</span> <span class="p_context"> void iscsit_take_action_for_connection_exit(struct iscsi_conn *conn)</span>
 	spin_unlock_bh(&amp;conn-&gt;state_lock);
 
 	iscsit_handle_connection_cleanup(conn);
<span class="p_add">+	*conn_freed = true;</span>
 }
<span class="p_header">diff --git a/drivers/target/iscsi/iscsi_target_erl0.h b/drivers/target/iscsi/iscsi_target_erl0.h</span>
<span class="p_header">index 60e69e2af6ed..3822d9cd1230 100644</span>
<span class="p_header">--- a/drivers/target/iscsi/iscsi_target_erl0.h</span>
<span class="p_header">+++ b/drivers/target/iscsi/iscsi_target_erl0.h</span>
<span class="p_chunk">@@ -15,6 +15,6 @@</span> <span class="p_context"> extern int iscsit_stop_time2retain_timer(struct iscsi_session *);</span>
 extern void iscsit_connection_reinstatement_rcfr(struct iscsi_conn *);
 extern void iscsit_cause_connection_reinstatement(struct iscsi_conn *, int);
 extern void iscsit_fall_back_to_erl0(struct iscsi_session *);
<span class="p_del">-extern void iscsit_take_action_for_connection_exit(struct iscsi_conn *);</span>
<span class="p_add">+extern void iscsit_take_action_for_connection_exit(struct iscsi_conn *, bool *);</span>
 
 #endif   /*** ISCSI_TARGET_ERL0_H ***/
<span class="p_header">diff --git a/drivers/target/iscsi/iscsi_target_login.c b/drivers/target/iscsi/iscsi_target_login.c</span>
<span class="p_header">index 66238477137b..92b96b51d506 100644</span>
<span class="p_header">--- a/drivers/target/iscsi/iscsi_target_login.c</span>
<span class="p_header">+++ b/drivers/target/iscsi/iscsi_target_login.c</span>
<span class="p_chunk">@@ -1464,5 +1464,9 @@</span> <span class="p_context"> int iscsi_target_login_thread(void *arg)</span>
 			break;
 	}
 
<span class="p_add">+	while (!kthread_should_stop()) {</span>
<span class="p_add">+		msleep(100);</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
 	return 0;
 }
<span class="p_header">diff --git a/drivers/target/iscsi/iscsi_target_nego.c b/drivers/target/iscsi/iscsi_target_nego.c</span>
<span class="p_header">index 7ccc9c1cbfd1..6f88b31242b0 100644</span>
<span class="p_header">--- a/drivers/target/iscsi/iscsi_target_nego.c</span>
<span class="p_header">+++ b/drivers/target/iscsi/iscsi_target_nego.c</span>
<span class="p_chunk">@@ -493,14 +493,60 @@</span> <span class="p_context"> static void iscsi_target_restore_sock_callbacks(struct iscsi_conn *conn)</span>
 
 static int iscsi_target_do_login(struct iscsi_conn *, struct iscsi_login *);
 
<span class="p_del">-static bool iscsi_target_sk_state_check(struct sock *sk)</span>
<span class="p_add">+static bool __iscsi_target_sk_check_close(struct sock *sk)</span>
 {
 	if (sk-&gt;sk_state == TCP_CLOSE_WAIT || sk-&gt;sk_state == TCP_CLOSE) {
<span class="p_del">-		pr_debug(&quot;iscsi_target_sk_state_check: TCP_CLOSE_WAIT|TCP_CLOSE,&quot;</span>
<span class="p_add">+		pr_debug(&quot;__iscsi_target_sk_check_close: TCP_CLOSE_WAIT|TCP_CLOSE,&quot;</span>
 			&quot;returning FALSE\n&quot;);
<span class="p_del">-		return false;</span>
<span class="p_add">+		return true;</span>
 	}
<span class="p_del">-	return true;</span>
<span class="p_add">+	return false;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static bool iscsi_target_sk_check_close(struct iscsi_conn *conn)</span>
<span class="p_add">+{</span>
<span class="p_add">+	bool state = false;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (conn-&gt;sock) {</span>
<span class="p_add">+		struct sock *sk = conn-&gt;sock-&gt;sk;</span>
<span class="p_add">+</span>
<span class="p_add">+		read_lock_bh(&amp;sk-&gt;sk_callback_lock);</span>
<span class="p_add">+		state = (__iscsi_target_sk_check_close(sk) ||</span>
<span class="p_add">+			 test_bit(LOGIN_FLAGS_CLOSED, &amp;conn-&gt;login_flags));</span>
<span class="p_add">+		read_unlock_bh(&amp;sk-&gt;sk_callback_lock);</span>
<span class="p_add">+	}</span>
<span class="p_add">+	return state;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static bool iscsi_target_sk_check_flag(struct iscsi_conn *conn, unsigned int flag)</span>
<span class="p_add">+{</span>
<span class="p_add">+	bool state = false;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (conn-&gt;sock) {</span>
<span class="p_add">+		struct sock *sk = conn-&gt;sock-&gt;sk;</span>
<span class="p_add">+</span>
<span class="p_add">+		read_lock_bh(&amp;sk-&gt;sk_callback_lock);</span>
<span class="p_add">+		state = test_bit(flag, &amp;conn-&gt;login_flags);</span>
<span class="p_add">+		read_unlock_bh(&amp;sk-&gt;sk_callback_lock);</span>
<span class="p_add">+	}</span>
<span class="p_add">+	return state;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static bool iscsi_target_sk_check_and_clear(struct iscsi_conn *conn, unsigned int flag)</span>
<span class="p_add">+{</span>
<span class="p_add">+	bool state = false;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (conn-&gt;sock) {</span>
<span class="p_add">+		struct sock *sk = conn-&gt;sock-&gt;sk;</span>
<span class="p_add">+</span>
<span class="p_add">+		write_lock_bh(&amp;sk-&gt;sk_callback_lock);</span>
<span class="p_add">+		state = (__iscsi_target_sk_check_close(sk) ||</span>
<span class="p_add">+			 test_bit(LOGIN_FLAGS_CLOSED, &amp;conn-&gt;login_flags));</span>
<span class="p_add">+		if (!state)</span>
<span class="p_add">+			clear_bit(flag, &amp;conn-&gt;login_flags);</span>
<span class="p_add">+		write_unlock_bh(&amp;sk-&gt;sk_callback_lock);</span>
<span class="p_add">+	}</span>
<span class="p_add">+	return state;</span>
 }
 
 static void iscsi_target_login_drop(struct iscsi_conn *conn, struct iscsi_login *login)
<span class="p_chunk">@@ -540,6 +586,20 @@</span> <span class="p_context"> static void iscsi_target_do_login_rx(struct work_struct *work)</span>
 
 	pr_debug(&quot;entering iscsi_target_do_login_rx, conn: %p, %s:%d\n&quot;,
 			conn, current-&gt;comm, current-&gt;pid);
<span class="p_add">+	/*</span>
<span class="p_add">+	 * If iscsi_target_do_login_rx() has been invoked by -&gt;sk_data_ready()</span>
<span class="p_add">+	 * before initial PDU processing in iscsi_target_start_negotiation()</span>
<span class="p_add">+	 * has completed, go ahead and retry until it&#39;s cleared.</span>
<span class="p_add">+	 *</span>
<span class="p_add">+	 * Otherwise if the TCP connection drops while this is occuring,</span>
<span class="p_add">+	 * iscsi_target_start_negotiation() will detect the failure, call</span>
<span class="p_add">+	 * cancel_delayed_work_sync(&amp;conn-&gt;login_work), and cleanup the</span>
<span class="p_add">+	 * remaining iscsi connection resources from iscsi_np process context.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	if (iscsi_target_sk_check_flag(conn, LOGIN_FLAGS_INITIAL_PDU)) {</span>
<span class="p_add">+		schedule_delayed_work(&amp;conn-&gt;login_work, msecs_to_jiffies(10));</span>
<span class="p_add">+		return;</span>
<span class="p_add">+	}</span>
 
 	spin_lock(&amp;tpg-&gt;tpg_state_lock);
 	state = (tpg-&gt;tpg_state == TPG_STATE_ACTIVE);
<span class="p_chunk">@@ -547,26 +607,12 @@</span> <span class="p_context"> static void iscsi_target_do_login_rx(struct work_struct *work)</span>
 
 	if (!state) {
 		pr_debug(&quot;iscsi_target_do_login_rx: tpg_state != TPG_STATE_ACTIVE\n&quot;);
<span class="p_del">-		iscsi_target_restore_sock_callbacks(conn);</span>
<span class="p_del">-		iscsi_target_login_drop(conn, login);</span>
<span class="p_del">-		iscsit_deaccess_np(np, tpg, tpg_np);</span>
<span class="p_del">-		return;</span>
<span class="p_add">+		goto err;</span>
 	}
 
<span class="p_del">-	if (conn-&gt;sock) {</span>
<span class="p_del">-		struct sock *sk = conn-&gt;sock-&gt;sk;</span>
<span class="p_del">-</span>
<span class="p_del">-		read_lock_bh(&amp;sk-&gt;sk_callback_lock);</span>
<span class="p_del">-		state = iscsi_target_sk_state_check(sk);</span>
<span class="p_del">-		read_unlock_bh(&amp;sk-&gt;sk_callback_lock);</span>
<span class="p_del">-</span>
<span class="p_del">-		if (!state) {</span>
<span class="p_del">-			pr_debug(&quot;iscsi_target_do_login_rx, TCP state CLOSE\n&quot;);</span>
<span class="p_del">-			iscsi_target_restore_sock_callbacks(conn);</span>
<span class="p_del">-			iscsi_target_login_drop(conn, login);</span>
<span class="p_del">-			iscsit_deaccess_np(np, tpg, tpg_np);</span>
<span class="p_del">-			return;</span>
<span class="p_del">-		}</span>
<span class="p_add">+	if (iscsi_target_sk_check_close(conn)) {</span>
<span class="p_add">+		pr_debug(&quot;iscsi_target_do_login_rx, TCP state CLOSE\n&quot;);</span>
<span class="p_add">+		goto err;</span>
 	}
 
 	conn-&gt;login_kworker = current;
<span class="p_chunk">@@ -584,34 +630,29 @@</span> <span class="p_context"> static void iscsi_target_do_login_rx(struct work_struct *work)</span>
 	flush_signals(current);
 	conn-&gt;login_kworker = NULL;
 
<span class="p_del">-	if (rc &lt; 0) {</span>
<span class="p_del">-		iscsi_target_restore_sock_callbacks(conn);</span>
<span class="p_del">-		iscsi_target_login_drop(conn, login);</span>
<span class="p_del">-		iscsit_deaccess_np(np, tpg, tpg_np);</span>
<span class="p_del">-		return;</span>
<span class="p_del">-	}</span>
<span class="p_add">+	if (rc &lt; 0)</span>
<span class="p_add">+		goto err;</span>
 
 	pr_debug(&quot;iscsi_target_do_login_rx after rx_login_io, %p, %s:%d\n&quot;,
 			conn, current-&gt;comm, current-&gt;pid);
 
 	rc = iscsi_target_do_login(conn, login);
 	if (rc &lt; 0) {
<span class="p_del">-		iscsi_target_restore_sock_callbacks(conn);</span>
<span class="p_del">-		iscsi_target_login_drop(conn, login);</span>
<span class="p_del">-		iscsit_deaccess_np(np, tpg, tpg_np);</span>
<span class="p_add">+		goto err;</span>
 	} else if (!rc) {
<span class="p_del">-		if (conn-&gt;sock) {</span>
<span class="p_del">-			struct sock *sk = conn-&gt;sock-&gt;sk;</span>
<span class="p_del">-</span>
<span class="p_del">-			write_lock_bh(&amp;sk-&gt;sk_callback_lock);</span>
<span class="p_del">-			clear_bit(LOGIN_FLAGS_READ_ACTIVE, &amp;conn-&gt;login_flags);</span>
<span class="p_del">-			write_unlock_bh(&amp;sk-&gt;sk_callback_lock);</span>
<span class="p_del">-		}</span>
<span class="p_add">+		if (iscsi_target_sk_check_and_clear(conn, LOGIN_FLAGS_READ_ACTIVE))</span>
<span class="p_add">+			goto err;</span>
 	} else if (rc == 1) {
 		iscsi_target_nego_release(conn);
 		iscsi_post_login_handler(np, conn, zero_tsih);
 		iscsit_deaccess_np(np, tpg, tpg_np);
 	}
<span class="p_add">+	return;</span>
<span class="p_add">+</span>
<span class="p_add">+err:</span>
<span class="p_add">+	iscsi_target_restore_sock_callbacks(conn);</span>
<span class="p_add">+	iscsi_target_login_drop(conn, login);</span>
<span class="p_add">+	iscsit_deaccess_np(np, tpg, tpg_np);</span>
 }
 
 static void iscsi_target_do_cleanup(struct work_struct *work)
<span class="p_chunk">@@ -659,31 +700,54 @@</span> <span class="p_context"> static void iscsi_target_sk_state_change(struct sock *sk)</span>
 		orig_state_change(sk);
 		return;
 	}
<span class="p_add">+	state = __iscsi_target_sk_check_close(sk);</span>
<span class="p_add">+	pr_debug(&quot;__iscsi_target_sk_close_change: state: %d\n&quot;, state);</span>
<span class="p_add">+</span>
 	if (test_bit(LOGIN_FLAGS_READ_ACTIVE, &amp;conn-&gt;login_flags)) {
 		pr_debug(&quot;Got LOGIN_FLAGS_READ_ACTIVE=1 sk_state_change&quot;
 			 &quot; conn: %p\n&quot;, conn);
<span class="p_add">+		if (state)</span>
<span class="p_add">+			set_bit(LOGIN_FLAGS_CLOSED, &amp;conn-&gt;login_flags);</span>
 		write_unlock_bh(&amp;sk-&gt;sk_callback_lock);
 		orig_state_change(sk);
 		return;
 	}
<span class="p_del">-	if (test_and_set_bit(LOGIN_FLAGS_CLOSED, &amp;conn-&gt;login_flags)) {</span>
<span class="p_add">+	if (test_bit(LOGIN_FLAGS_CLOSED, &amp;conn-&gt;login_flags)) {</span>
 		pr_debug(&quot;Got LOGIN_FLAGS_CLOSED=1 sk_state_change conn: %p\n&quot;,
 			 conn);
 		write_unlock_bh(&amp;sk-&gt;sk_callback_lock);
 		orig_state_change(sk);
 		return;
 	}
<span class="p_add">+	/*</span>
<span class="p_add">+	 * If the TCP connection has dropped, go ahead and set LOGIN_FLAGS_CLOSED,</span>
<span class="p_add">+	 * but only queue conn-&gt;login_work -&gt; iscsi_target_do_login_rx()</span>
<span class="p_add">+	 * processing if LOGIN_FLAGS_INITIAL_PDU has already been cleared.</span>
<span class="p_add">+	 *</span>
<span class="p_add">+	 * When iscsi_target_do_login_rx() runs, iscsi_target_sk_check_close()</span>
<span class="p_add">+	 * will detect the dropped TCP connection from delayed workqueue context.</span>
<span class="p_add">+	 *</span>
<span class="p_add">+	 * If LOGIN_FLAGS_INITIAL_PDU is still set, which means the initial</span>
<span class="p_add">+	 * iscsi_target_start_negotiation() is running, iscsi_target_do_login()</span>
<span class="p_add">+	 * via iscsi_target_sk_check_close() or iscsi_target_start_negotiation()</span>
<span class="p_add">+	 * via iscsi_target_sk_check_and_clear() is responsible for detecting the</span>
<span class="p_add">+	 * dropped TCP connection in iscsi_np process context, and cleaning up</span>
<span class="p_add">+	 * the remaining iscsi connection resources.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	if (state) {</span>
<span class="p_add">+		pr_debug(&quot;iscsi_target_sk_state_change got failed state\n&quot;);</span>
<span class="p_add">+		set_bit(LOGIN_FLAGS_CLOSED, &amp;conn-&gt;login_flags);</span>
<span class="p_add">+		state = test_bit(LOGIN_FLAGS_INITIAL_PDU, &amp;conn-&gt;login_flags);</span>
<span class="p_add">+		write_unlock_bh(&amp;sk-&gt;sk_callback_lock);</span>
 
<span class="p_del">-	state = iscsi_target_sk_state_check(sk);</span>
<span class="p_del">-	write_unlock_bh(&amp;sk-&gt;sk_callback_lock);</span>
<span class="p_del">-</span>
<span class="p_del">-	pr_debug(&quot;iscsi_target_sk_state_change: state: %d\n&quot;, state);</span>
<span class="p_add">+		orig_state_change(sk);</span>
 
<span class="p_del">-	if (!state) {</span>
<span class="p_del">-		pr_debug(&quot;iscsi_target_sk_state_change got failed state\n&quot;);</span>
<span class="p_del">-		schedule_delayed_work(&amp;conn-&gt;login_cleanup_work, 0);</span>
<span class="p_add">+		if (!state)</span>
<span class="p_add">+			schedule_delayed_work(&amp;conn-&gt;login_work, 0);</span>
 		return;
 	}
<span class="p_add">+	write_unlock_bh(&amp;sk-&gt;sk_callback_lock);</span>
<span class="p_add">+</span>
 	orig_state_change(sk);
 }
 
<span class="p_chunk">@@ -946,6 +1010,15 @@</span> <span class="p_context"> static int iscsi_target_do_login(struct iscsi_conn *conn, struct iscsi_login *lo</span>
 			if (iscsi_target_handle_csg_one(conn, login) &lt; 0)
 				return -1;
 			if (login_rsp-&gt;flags &amp; ISCSI_FLAG_LOGIN_TRANSIT) {
<span class="p_add">+				/*</span>
<span class="p_add">+				 * Check to make sure the TCP connection has not</span>
<span class="p_add">+				 * dropped asynchronously while session reinstatement</span>
<span class="p_add">+				 * was occuring in this kthread context, before</span>
<span class="p_add">+				 * transitioning to full feature phase operation.</span>
<span class="p_add">+				 */</span>
<span class="p_add">+				if (iscsi_target_sk_check_close(conn))</span>
<span class="p_add">+					return -1;</span>
<span class="p_add">+</span>
 				login-&gt;tsih = conn-&gt;sess-&gt;tsih;
 				login-&gt;login_complete = 1;
 				iscsi_target_restore_sock_callbacks(conn);
<span class="p_chunk">@@ -972,21 +1045,6 @@</span> <span class="p_context"> static int iscsi_target_do_login(struct iscsi_conn *conn, struct iscsi_login *lo</span>
 		break;
 	}
 
<span class="p_del">-	if (conn-&gt;sock) {</span>
<span class="p_del">-		struct sock *sk = conn-&gt;sock-&gt;sk;</span>
<span class="p_del">-		bool state;</span>
<span class="p_del">-</span>
<span class="p_del">-		read_lock_bh(&amp;sk-&gt;sk_callback_lock);</span>
<span class="p_del">-		state = iscsi_target_sk_state_check(sk);</span>
<span class="p_del">-		read_unlock_bh(&amp;sk-&gt;sk_callback_lock);</span>
<span class="p_del">-</span>
<span class="p_del">-		if (!state) {</span>
<span class="p_del">-			pr_debug(&quot;iscsi_target_do_login() failed state for&quot;</span>
<span class="p_del">-				 &quot; conn: %p\n&quot;, conn);</span>
<span class="p_del">-			return -1;</span>
<span class="p_del">-		}</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
 	return 0;
 }
 
<span class="p_chunk">@@ -1255,10 +1313,22 @@</span> <span class="p_context"> int iscsi_target_start_negotiation(</span>
 
 		write_lock_bh(&amp;sk-&gt;sk_callback_lock);
 		set_bit(LOGIN_FLAGS_READY, &amp;conn-&gt;login_flags);
<span class="p_add">+		set_bit(LOGIN_FLAGS_INITIAL_PDU, &amp;conn-&gt;login_flags);</span>
 		write_unlock_bh(&amp;sk-&gt;sk_callback_lock);
 	}
<span class="p_del">-</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * If iscsi_target_do_login returns zero to signal more PDU</span>
<span class="p_add">+	 * exchanges are required to complete the login, go ahead and</span>
<span class="p_add">+	 * clear LOGIN_FLAGS_INITIAL_PDU but only if the TCP connection</span>
<span class="p_add">+	 * is still active.</span>
<span class="p_add">+	 *</span>
<span class="p_add">+	 * Otherwise if TCP connection dropped asynchronously, go ahead</span>
<span class="p_add">+	 * and perform connection cleanup now.</span>
<span class="p_add">+	 */</span>
 	ret = iscsi_target_do_login(conn, login);
<span class="p_add">+	if (!ret &amp;&amp; iscsi_target_sk_check_and_clear(conn, LOGIN_FLAGS_INITIAL_PDU))</span>
<span class="p_add">+		ret = -1;</span>
<span class="p_add">+</span>
 	if (ret &lt; 0) {
 		cancel_delayed_work_sync(&amp;conn-&gt;login_work);
 		cancel_delayed_work_sync(&amp;conn-&gt;login_cleanup_work);
<span class="p_header">diff --git a/drivers/tty/serdev/serdev-ttyport.c b/drivers/tty/serdev/serdev-ttyport.c</span>
<span class="p_header">index d05393594f15..06e17faa6dfb 100644</span>
<span class="p_header">--- a/drivers/tty/serdev/serdev-ttyport.c</span>
<span class="p_header">+++ b/drivers/tty/serdev/serdev-ttyport.c</span>
<span class="p_chunk">@@ -101,9 +101,6 @@</span> <span class="p_context"> static int ttyport_open(struct serdev_controller *ctrl)</span>
 		return PTR_ERR(tty);
 	serport-&gt;tty = tty;
 
<span class="p_del">-	serport-&gt;port-&gt;client_ops = &amp;client_ops;</span>
<span class="p_del">-	serport-&gt;port-&gt;client_data = ctrl;</span>
<span class="p_del">-</span>
 	if (tty-&gt;ops-&gt;open)
 		tty-&gt;ops-&gt;open(serport-&gt;tty, NULL);
 	else
<span class="p_chunk">@@ -181,6 +178,7 @@</span> <span class="p_context"> struct device *serdev_tty_port_register(struct tty_port *port,</span>
 					struct device *parent,
 					struct tty_driver *drv, int idx)
 {
<span class="p_add">+	const struct tty_port_client_operations *old_ops;</span>
 	struct serdev_controller *ctrl;
 	struct serport *serport;
 	int ret;
<span class="p_chunk">@@ -199,15 +197,22 @@</span> <span class="p_context"> struct device *serdev_tty_port_register(struct tty_port *port,</span>
 
 	ctrl-&gt;ops = &amp;ctrl_ops;
 
<span class="p_add">+	old_ops = port-&gt;client_ops;</span>
<span class="p_add">+	port-&gt;client_ops = &amp;client_ops;</span>
<span class="p_add">+	port-&gt;client_data = ctrl;</span>
<span class="p_add">+</span>
 	ret = serdev_controller_add(ctrl);
 	if (ret)
<span class="p_del">-		goto err_controller_put;</span>
<span class="p_add">+		goto err_reset_data;</span>
 
 	dev_info(&amp;ctrl-&gt;dev, &quot;tty port %s%d registered\n&quot;, drv-&gt;name, idx);
 	return &amp;ctrl-&gt;dev;
 
<span class="p_del">-err_controller_put:</span>
<span class="p_add">+err_reset_data:</span>
<span class="p_add">+	port-&gt;client_data = NULL;</span>
<span class="p_add">+	port-&gt;client_ops = old_ops;</span>
 	serdev_controller_put(ctrl);
<span class="p_add">+</span>
 	return ERR_PTR(ret);
 }
 
<span class="p_header">diff --git a/drivers/tty/serial/8250/8250_port.c b/drivers/tty/serial/8250/8250_port.c</span>
<span class="p_header">index 6119516ef5fc..4c26d15ad7d9 100644</span>
<span class="p_header">--- a/drivers/tty/serial/8250/8250_port.c</span>
<span class="p_header">+++ b/drivers/tty/serial/8250/8250_port.c</span>
<span class="p_chunk">@@ -1337,7 +1337,7 @@</span> <span class="p_context"> static void autoconfig(struct uart_8250_port *up)</span>
 	/*
 	 * Check if the device is a Fintek F81216A
 	 */
<span class="p_del">-	if (port-&gt;type == PORT_16550A)</span>
<span class="p_add">+	if (port-&gt;type == PORT_16550A &amp;&amp; port-&gt;iotype == UPIO_PORT)</span>
 		fintek_8250_probe(up);
 
 	if (up-&gt;capabilities != old_capabilities) {
<span class="p_header">diff --git a/drivers/tty/tty_port.c b/drivers/tty/tty_port.c</span>
<span class="p_header">index 1d21a9c1d33e..0c880f17d27e 100644</span>
<span class="p_header">--- a/drivers/tty/tty_port.c</span>
<span class="p_header">+++ b/drivers/tty/tty_port.c</span>
<span class="p_chunk">@@ -16,7 +16,6 @@</span> <span class="p_context"></span>
 #include &lt;linux/bitops.h&gt;
 #include &lt;linux/delay.h&gt;
 #include &lt;linux/module.h&gt;
<span class="p_del">-#include &lt;linux/serdev.h&gt;</span>
 
 static int tty_port_default_receive_buf(struct tty_port *port,
 					const unsigned char *p,
<span class="p_chunk">@@ -129,15 +128,7 @@</span> <span class="p_context"> struct device *tty_port_register_device_attr(struct tty_port *port,</span>
 		struct device *device, void *drvdata,
 		const struct attribute_group **attr_grp)
 {
<span class="p_del">-	struct device *dev;</span>
<span class="p_del">-</span>
 	tty_port_link_device(port, driver, index);
<span class="p_del">-</span>
<span class="p_del">-	dev = serdev_tty_port_register(port, device, driver, index);</span>
<span class="p_del">-	if (PTR_ERR(dev) != -ENODEV)</span>
<span class="p_del">-		/* Skip creating cdev if we registered a serdev device */</span>
<span class="p_del">-		return dev;</span>
<span class="p_del">-</span>
 	return tty_register_device_attr(driver, index, device, drvdata,
 			attr_grp);
 }
<span class="p_chunk">@@ -189,9 +180,6 @@</span> <span class="p_context"> static void tty_port_destructor(struct kref *kref)</span>
 	/* check if last port ref was dropped before tty release */
 	if (WARN_ON(port-&gt;itty))
 		return;
<span class="p_del">-</span>
<span class="p_del">-	serdev_tty_port_unregister(port);</span>
<span class="p_del">-</span>
 	if (port-&gt;xmit_buf)
 		free_page((unsigned long)port-&gt;xmit_buf);
 	tty_port_destroy(port);
<span class="p_header">diff --git a/fs/dax.c b/fs/dax.c</span>
<span class="p_header">index db0cc52eb22e..285f4ab6f498 100644</span>
<span class="p_header">--- a/fs/dax.c</span>
<span class="p_header">+++ b/fs/dax.c</span>
<span class="p_chunk">@@ -1129,6 +1129,17 @@</span> <span class="p_context"> static int dax_iomap_pte_fault(struct vm_fault *vmf,</span>
 		return dax_fault_return(PTR_ERR(entry));
 
 	/*
<span class="p_add">+	 * It is possible, particularly with mixed reads &amp; writes to private</span>
<span class="p_add">+	 * mappings, that we have raced with a PMD fault that overlaps with</span>
<span class="p_add">+	 * the PTE we need to set up.  If so just return and the fault will be</span>
<span class="p_add">+	 * retried.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	if (pmd_trans_huge(*vmf-&gt;pmd) || pmd_devmap(*vmf-&gt;pmd)) {</span>
<span class="p_add">+		vmf_ret = VM_FAULT_NOPAGE;</span>
<span class="p_add">+		goto unlock_entry;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
 	 * Note that we don&#39;t bother to use iomap_apply here: DAX required
 	 * the file system block size to be equal the page size, which means
 	 * that we never have to deal with more than a single extent here.
<span class="p_chunk">@@ -1363,6 +1374,18 @@</span> <span class="p_context"> static int dax_iomap_pmd_fault(struct vm_fault *vmf,</span>
 		goto fallback;
 
 	/*
<span class="p_add">+	 * It is possible, particularly with mixed reads &amp; writes to private</span>
<span class="p_add">+	 * mappings, that we have raced with a PTE fault that overlaps with</span>
<span class="p_add">+	 * the PMD we need to set up.  If so just return and the fault will be</span>
<span class="p_add">+	 * retried.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	if (!pmd_none(*vmf-&gt;pmd) &amp;&amp; !pmd_trans_huge(*vmf-&gt;pmd) &amp;&amp;</span>
<span class="p_add">+			!pmd_devmap(*vmf-&gt;pmd)) {</span>
<span class="p_add">+		result = 0;</span>
<span class="p_add">+		goto unlock_entry;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
 	 * Note that we don&#39;t use iomap_apply here.  We aren&#39;t doing I/O, only
 	 * setting up a mapping, so really we&#39;re using iomap_begin() as a way
 	 * to look up our filesystem block.
<span class="p_header">diff --git a/fs/ufs/super.c b/fs/ufs/super.c</span>
<span class="p_header">index 131b2b77c818..29ecaf739449 100644</span>
<span class="p_header">--- a/fs/ufs/super.c</span>
<span class="p_header">+++ b/fs/ufs/super.c</span>
<span class="p_chunk">@@ -812,9 +812,8 @@</span> <span class="p_context"> static int ufs_fill_super(struct super_block *sb, void *data, int silent)</span>
 	uspi-&gt;s_dirblksize = UFS_SECTOR_SIZE;
 	super_block_offset=UFS_SBLOCK;
 
<span class="p_del">-	/* Keep 2Gig file limit. Some UFS variants need to override </span>
<span class="p_del">-	   this but as I don&#39;t know which I&#39;ll let those in the know loosen</span>
<span class="p_del">-	   the rules */</span>
<span class="p_add">+	sb-&gt;s_maxbytes = MAX_LFS_FILESIZE;</span>
<span class="p_add">+</span>
 	switch (sbi-&gt;s_mount_opt &amp; UFS_MOUNT_UFSTYPE) {
 	case UFS_MOUNT_UFSTYPE_44BSD:
 		UFSD(&quot;ufstype=44bsd\n&quot;);
<span class="p_header">diff --git a/fs/xfs/libxfs/xfs_bmap.c b/fs/xfs/libxfs/xfs_bmap.c</span>
<span class="p_header">index 9bd104f32908..6c68f3b888b0 100644</span>
<span class="p_header">--- a/fs/xfs/libxfs/xfs_bmap.c</span>
<span class="p_header">+++ b/fs/xfs/libxfs/xfs_bmap.c</span>
<span class="p_chunk">@@ -2106,8 +2106,10 @@</span> <span class="p_context"> xfs_bmap_add_extent_delay_real(</span>
 		}
 		temp = xfs_bmap_worst_indlen(bma-&gt;ip, temp);
 		temp2 = xfs_bmap_worst_indlen(bma-&gt;ip, temp2);
<span class="p_del">-		diff = (int)(temp + temp2 - startblockval(PREV.br_startblock) -</span>
<span class="p_del">-			(bma-&gt;cur ? bma-&gt;cur-&gt;bc_private.b.allocated : 0));</span>
<span class="p_add">+		diff = (int)(temp + temp2 -</span>
<span class="p_add">+			     (startblockval(PREV.br_startblock) -</span>
<span class="p_add">+			      (bma-&gt;cur ?</span>
<span class="p_add">+			       bma-&gt;cur-&gt;bc_private.b.allocated : 0)));</span>
 		if (diff &gt; 0) {
 			error = xfs_mod_fdblocks(bma-&gt;ip-&gt;i_mount,
 						 -((int64_t)diff), false);
<span class="p_chunk">@@ -2164,7 +2166,6 @@</span> <span class="p_context"> xfs_bmap_add_extent_delay_real(</span>
 		temp = da_new;
 		if (bma-&gt;cur)
 			temp += bma-&gt;cur-&gt;bc_private.b.allocated;
<span class="p_del">-		ASSERT(temp &lt;= da_old);</span>
 		if (temp &lt; da_old)
 			xfs_mod_fdblocks(bma-&gt;ip-&gt;i_mount,
 					(int64_t)(da_old - temp), false);
<span class="p_chunk">@@ -3863,7 +3864,7 @@</span> <span class="p_context"> xfs_bmap_remap_alloc(</span>
 {
 	struct xfs_trans	*tp = ap-&gt;tp;
 	struct xfs_mount	*mp = tp-&gt;t_mountp;
<span class="p_del">-	xfs_agblock_t		bno;</span>
<span class="p_add">+	xfs_fsblock_t		bno;</span>
 	struct xfs_alloc_arg	args;
 	int			error;
 
<span class="p_header">diff --git a/fs/xfs/libxfs/xfs_btree.c b/fs/xfs/libxfs/xfs_btree.c</span>
<span class="p_header">index c3decedc9455..3d0f96d159ff 100644</span>
<span class="p_header">--- a/fs/xfs/libxfs/xfs_btree.c</span>
<span class="p_header">+++ b/fs/xfs/libxfs/xfs_btree.c</span>
<span class="p_chunk">@@ -4395,7 +4395,7 @@</span> <span class="p_context"> xfs_btree_visit_blocks(</span>
 			xfs_btree_readahead_ptr(cur, ptr, 1);
 
 			/* save for the next iteration of the loop */
<span class="p_del">-			lptr = *ptr;</span>
<span class="p_add">+			xfs_btree_copy_ptrs(cur, &amp;lptr, ptr, 1);</span>
 		}
 
 		/* for each buffer in the level */
<span class="p_header">diff --git a/fs/xfs/libxfs/xfs_refcount.c b/fs/xfs/libxfs/xfs_refcount.c</span>
<span class="p_header">index b177ef33cd4c..82a38d86ebad 100644</span>
<span class="p_header">--- a/fs/xfs/libxfs/xfs_refcount.c</span>
<span class="p_header">+++ b/fs/xfs/libxfs/xfs_refcount.c</span>
<span class="p_chunk">@@ -1629,13 +1629,28 @@</span> <span class="p_context"> xfs_refcount_recover_cow_leftovers(</span>
 	if (mp-&gt;m_sb.sb_agblocks &gt;= XFS_REFC_COW_START)
 		return -EOPNOTSUPP;
 
<span class="p_del">-	error = xfs_alloc_read_agf(mp, NULL, agno, 0, &amp;agbp);</span>
<span class="p_add">+	INIT_LIST_HEAD(&amp;debris);</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * In this first part, we use an empty transaction to gather up</span>
<span class="p_add">+	 * all the leftover CoW extents so that we can subsequently</span>
<span class="p_add">+	 * delete them.  The empty transaction is used to avoid</span>
<span class="p_add">+	 * a buffer lock deadlock if there happens to be a loop in the</span>
<span class="p_add">+	 * refcountbt because we&#39;re allowed to re-grab a buffer that is</span>
<span class="p_add">+	 * already attached to our transaction.  When we&#39;re done</span>
<span class="p_add">+	 * recording the CoW debris we cancel the (empty) transaction</span>
<span class="p_add">+	 * and everything goes away cleanly.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	error = xfs_trans_alloc_empty(mp, &amp;tp);</span>
 	if (error)
 		return error;
<span class="p_del">-	cur = xfs_refcountbt_init_cursor(mp, NULL, agbp, agno, NULL);</span>
<span class="p_add">+</span>
<span class="p_add">+	error = xfs_alloc_read_agf(mp, tp, agno, 0, &amp;agbp);</span>
<span class="p_add">+	if (error)</span>
<span class="p_add">+		goto out_trans;</span>
<span class="p_add">+	cur = xfs_refcountbt_init_cursor(mp, tp, agbp, agno, NULL);</span>
 
 	/* Find all the leftover CoW staging extents. */
<span class="p_del">-	INIT_LIST_HEAD(&amp;debris);</span>
 	memset(&amp;low, 0, sizeof(low));
 	memset(&amp;high, 0, sizeof(high));
 	low.rc.rc_startblock = XFS_REFC_COW_START;
<span class="p_chunk">@@ -1645,10 +1660,11 @@</span> <span class="p_context"> xfs_refcount_recover_cow_leftovers(</span>
 	if (error)
 		goto out_cursor;
 	xfs_btree_del_cursor(cur, XFS_BTREE_NOERROR);
<span class="p_del">-	xfs_buf_relse(agbp);</span>
<span class="p_add">+	xfs_trans_brelse(tp, agbp);</span>
<span class="p_add">+	xfs_trans_cancel(tp);</span>
 
 	/* Now iterate the list to free the leftovers */
<span class="p_del">-	list_for_each_entry(rr, &amp;debris, rr_list) {</span>
<span class="p_add">+	list_for_each_entry_safe(rr, n, &amp;debris, rr_list) {</span>
 		/* Set up transaction. */
 		error = xfs_trans_alloc(mp, &amp;M_RES(mp)-&gt;tr_write, 0, 0, 0, &amp;tp);
 		if (error)
<span class="p_chunk">@@ -1676,8 +1692,16 @@</span> <span class="p_context"> xfs_refcount_recover_cow_leftovers(</span>
 		error = xfs_trans_commit(tp);
 		if (error)
 			goto out_free;
<span class="p_add">+</span>
<span class="p_add">+		list_del(&amp;rr-&gt;rr_list);</span>
<span class="p_add">+		kmem_free(rr);</span>
 	}
 
<span class="p_add">+	return error;</span>
<span class="p_add">+out_defer:</span>
<span class="p_add">+	xfs_defer_cancel(&amp;dfops);</span>
<span class="p_add">+out_trans:</span>
<span class="p_add">+	xfs_trans_cancel(tp);</span>
 out_free:
 	/* Free the leftover list */
 	list_for_each_entry_safe(rr, n, &amp;debris, rr_list) {
<span class="p_chunk">@@ -1688,11 +1712,6 @@</span> <span class="p_context"> xfs_refcount_recover_cow_leftovers(</span>
 
 out_cursor:
 	xfs_btree_del_cursor(cur, XFS_BTREE_ERROR);
<span class="p_del">-	xfs_buf_relse(agbp);</span>
<span class="p_del">-	goto out_free;</span>
<span class="p_del">-</span>
<span class="p_del">-out_defer:</span>
<span class="p_del">-	xfs_defer_cancel(&amp;dfops);</span>
<span class="p_del">-	xfs_trans_cancel(tp);</span>
<span class="p_del">-	goto out_free;</span>
<span class="p_add">+	xfs_trans_brelse(tp, agbp);</span>
<span class="p_add">+	goto out_trans;</span>
 }
<span class="p_header">diff --git a/fs/xfs/libxfs/xfs_trans_space.h b/fs/xfs/libxfs/xfs_trans_space.h</span>
<span class="p_header">index 7917f6e44286..d787c677d2a3 100644</span>
<span class="p_header">--- a/fs/xfs/libxfs/xfs_trans_space.h</span>
<span class="p_header">+++ b/fs/xfs/libxfs/xfs_trans_space.h</span>
<span class="p_chunk">@@ -21,8 +21,20 @@</span> <span class="p_context"></span>
 /*
  * Components of space reservations.
  */
<span class="p_add">+</span>
<span class="p_add">+/* Worst case number of rmaps that can be held in a block. */</span>
 #define XFS_MAX_CONTIG_RMAPS_PER_BLOCK(mp)    \
 		(((mp)-&gt;m_rmap_mxr[0]) - ((mp)-&gt;m_rmap_mnr[0]))
<span class="p_add">+</span>
<span class="p_add">+/* Adding one rmap could split every level up to the top of the tree. */</span>
<span class="p_add">+#define XFS_RMAPADD_SPACE_RES(mp) ((mp)-&gt;m_rmap_maxlevels)</span>
<span class="p_add">+</span>
<span class="p_add">+/* Blocks we might need to add &quot;b&quot; rmaps to a tree. */</span>
<span class="p_add">+#define XFS_NRMAPADD_SPACE_RES(mp, b)\</span>
<span class="p_add">+	(((b + XFS_MAX_CONTIG_RMAPS_PER_BLOCK(mp) - 1) / \</span>
<span class="p_add">+	  XFS_MAX_CONTIG_RMAPS_PER_BLOCK(mp)) * \</span>
<span class="p_add">+	  XFS_RMAPADD_SPACE_RES(mp))</span>
<span class="p_add">+</span>
 #define XFS_MAX_CONTIG_EXTENTS_PER_BLOCK(mp)    \
 		(((mp)-&gt;m_alloc_mxr[0]) - ((mp)-&gt;m_alloc_mnr[0]))
 #define	XFS_EXTENTADD_SPACE_RES(mp,w)	(XFS_BM_MAXLEVELS(mp,w) - 1)
<span class="p_chunk">@@ -30,13 +42,12 @@</span> <span class="p_context"></span>
 	(((b + XFS_MAX_CONTIG_EXTENTS_PER_BLOCK(mp) - 1) / \
 	  XFS_MAX_CONTIG_EXTENTS_PER_BLOCK(mp)) * \
 	  XFS_EXTENTADD_SPACE_RES(mp,w))
<span class="p_add">+</span>
<span class="p_add">+/* Blocks we might need to add &quot;b&quot; mappings &amp; rmappings to a file. */</span>
 #define XFS_SWAP_RMAP_SPACE_RES(mp,b,w)\
<span class="p_del">-	(((b + XFS_MAX_CONTIG_EXTENTS_PER_BLOCK(mp) - 1) / \</span>
<span class="p_del">-	  XFS_MAX_CONTIG_EXTENTS_PER_BLOCK(mp)) * \</span>
<span class="p_del">-	  XFS_EXTENTADD_SPACE_RES(mp,w) + \</span>
<span class="p_del">-	 ((b + XFS_MAX_CONTIG_RMAPS_PER_BLOCK(mp) - 1) / \</span>
<span class="p_del">-	  XFS_MAX_CONTIG_RMAPS_PER_BLOCK(mp)) * \</span>
<span class="p_del">-	  (mp)-&gt;m_rmap_maxlevels)</span>
<span class="p_add">+	(XFS_NEXTENTADD_SPACE_RES((mp), (b), (w)) + \</span>
<span class="p_add">+	 XFS_NRMAPADD_SPACE_RES((mp), (b)))</span>
<span class="p_add">+</span>
 #define	XFS_DAENTER_1B(mp,w)	\
 	((w) == XFS_DATA_FORK ? (mp)-&gt;m_dir_geo-&gt;fsbcount : 1)
 #define	XFS_DAENTER_DBS(mp,w)	\
<span class="p_header">diff --git a/fs/xfs/xfs_aops.c b/fs/xfs/xfs_aops.c</span>
<span class="p_header">index 61494295d92f..a7645be51d87 100644</span>
<span class="p_header">--- a/fs/xfs/xfs_aops.c</span>
<span class="p_header">+++ b/fs/xfs/xfs_aops.c</span>
<span class="p_chunk">@@ -111,11 +111,11 @@</span> <span class="p_context"> xfs_finish_page_writeback(</span>
 
 	bsize = bh-&gt;b_size;
 	do {
<span class="p_add">+		if (off &gt; end)</span>
<span class="p_add">+			break;</span>
 		next = bh-&gt;b_this_page;
 		if (off &lt; bvec-&gt;bv_offset)
 			goto next_bh;
<span class="p_del">-		if (off &gt; end)</span>
<span class="p_del">-			break;</span>
 		bh-&gt;b_end_io(bh, !error);
 next_bh:
 		off += bsize;
<span class="p_header">diff --git a/fs/xfs/xfs_bmap_item.c b/fs/xfs/xfs_bmap_item.c</span>
<span class="p_header">index 9bf57c76623b..c4b90e794e41 100644</span>
<span class="p_header">--- a/fs/xfs/xfs_bmap_item.c</span>
<span class="p_header">+++ b/fs/xfs/xfs_bmap_item.c</span>
<span class="p_chunk">@@ -34,6 +34,8 @@</span> <span class="p_context"></span>
 #include &quot;xfs_bmap.h&quot;
 #include &quot;xfs_icache.h&quot;
 #include &quot;xfs_trace.h&quot;
<span class="p_add">+#include &quot;xfs_bmap_btree.h&quot;</span>
<span class="p_add">+#include &quot;xfs_trans_space.h&quot;</span>
 
 
 kmem_zone_t	*xfs_bui_zone;
<span class="p_chunk">@@ -446,7 +448,8 @@</span> <span class="p_context"> xfs_bui_recover(</span>
 		return -EIO;
 	}
 
<span class="p_del">-	error = xfs_trans_alloc(mp, &amp;M_RES(mp)-&gt;tr_itruncate, 0, 0, 0, &amp;tp);</span>
<span class="p_add">+	error = xfs_trans_alloc(mp, &amp;M_RES(mp)-&gt;tr_itruncate,</span>
<span class="p_add">+			XFS_EXTENTADD_SPACE_RES(mp, XFS_DATA_FORK), 0, 0, &amp;tp);</span>
 	if (error)
 		return error;
 	budp = xfs_trans_get_bud(tp, buip);
<span class="p_header">diff --git a/fs/xfs/xfs_bmap_util.c b/fs/xfs/xfs_bmap_util.c</span>
<span class="p_header">index 828532ce0adc..70fbecbb2845 100644</span>
<span class="p_header">--- a/fs/xfs/xfs_bmap_util.c</span>
<span class="p_header">+++ b/fs/xfs/xfs_bmap_util.c</span>
<span class="p_chunk">@@ -583,9 +583,13 @@</span> <span class="p_context"> xfs_getbmap(</span>
 		}
 		break;
 	default:
<span class="p_add">+		/* Local format data forks report no extents. */</span>
<span class="p_add">+		if (ip-&gt;i_d.di_format == XFS_DINODE_FMT_LOCAL) {</span>
<span class="p_add">+			bmv-&gt;bmv_entries = 0;</span>
<span class="p_add">+			return 0;</span>
<span class="p_add">+		}</span>
 		if (ip-&gt;i_d.di_format != XFS_DINODE_FMT_EXTENTS &amp;&amp;
<span class="p_del">-		    ip-&gt;i_d.di_format != XFS_DINODE_FMT_BTREE &amp;&amp;</span>
<span class="p_del">-		    ip-&gt;i_d.di_format != XFS_DINODE_FMT_LOCAL)</span>
<span class="p_add">+		    ip-&gt;i_d.di_format != XFS_DINODE_FMT_BTREE)</span>
 			return -EINVAL;
 
 		if (xfs_get_extsz_hint(ip) ||
<span class="p_chunk">@@ -713,7 +717,7 @@</span> <span class="p_context"> xfs_getbmap(</span>
 			 * extents.
 			 */
 			if (map[i].br_startblock == DELAYSTARTBLOCK &amp;&amp;
<span class="p_del">-			    map[i].br_startoff &lt;= XFS_B_TO_FSB(mp, XFS_ISIZE(ip)))</span>
<span class="p_add">+			    map[i].br_startoff &lt; XFS_B_TO_FSB(mp, XFS_ISIZE(ip)))</span>
 				ASSERT((iflags &amp; BMV_IF_DELALLOC) != 0);
 
                         if (map[i].br_startblock == HOLESTARTBLOCK &amp;&amp;
<span class="p_chunk">@@ -904,9 +908,9 @@</span> <span class="p_context"> xfs_can_free_eofblocks(struct xfs_inode *ip, bool force)</span>
 }
 
 /*
<span class="p_del">- * This is called by xfs_inactive to free any blocks beyond eof</span>
<span class="p_del">- * when the link count isn&#39;t zero and by xfs_dm_punch_hole() when</span>
<span class="p_del">- * punching a hole to EOF.</span>
<span class="p_add">+ * This is called to free any blocks beyond eof. The caller must hold</span>
<span class="p_add">+ * IOLOCK_EXCL unless we are in the inode reclaim path and have the only</span>
<span class="p_add">+ * reference to the inode.</span>
  */
 int
 xfs_free_eofblocks(
<span class="p_chunk">@@ -921,8 +925,6 @@</span> <span class="p_context"> xfs_free_eofblocks(</span>
 	struct xfs_bmbt_irec	imap;
 	struct xfs_mount	*mp = ip-&gt;i_mount;
 
<span class="p_del">-	ASSERT(xfs_isilocked(ip, XFS_IOLOCK_EXCL));</span>
<span class="p_del">-</span>
 	/*
 	 * Figure out if there are any blocks beyond the end
 	 * of the file.  If not, then there is nothing to do.
<span class="p_header">diff --git a/fs/xfs/xfs_buf.c b/fs/xfs/xfs_buf.c</span>
<span class="p_header">index b6208728ba39..4e19fdabac9d 100644</span>
<span class="p_header">--- a/fs/xfs/xfs_buf.c</span>
<span class="p_header">+++ b/fs/xfs/xfs_buf.c</span>
<span class="p_chunk">@@ -97,12 +97,16 @@</span> <span class="p_context"> static inline void</span>
 xfs_buf_ioacct_inc(
 	struct xfs_buf	*bp)
 {
<span class="p_del">-	if (bp-&gt;b_flags &amp; (XBF_NO_IOACCT|_XBF_IN_FLIGHT))</span>
<span class="p_add">+	if (bp-&gt;b_flags &amp; XBF_NO_IOACCT)</span>
 		return;
 
 	ASSERT(bp-&gt;b_flags &amp; XBF_ASYNC);
<span class="p_del">-	bp-&gt;b_flags |= _XBF_IN_FLIGHT;</span>
<span class="p_del">-	percpu_counter_inc(&amp;bp-&gt;b_target-&gt;bt_io_count);</span>
<span class="p_add">+	spin_lock(&amp;bp-&gt;b_lock);</span>
<span class="p_add">+	if (!(bp-&gt;b_state &amp; XFS_BSTATE_IN_FLIGHT)) {</span>
<span class="p_add">+		bp-&gt;b_state |= XFS_BSTATE_IN_FLIGHT;</span>
<span class="p_add">+		percpu_counter_inc(&amp;bp-&gt;b_target-&gt;bt_io_count);</span>
<span class="p_add">+	}</span>
<span class="p_add">+	spin_unlock(&amp;bp-&gt;b_lock);</span>
 }
 
 /*
<span class="p_chunk">@@ -110,14 +114,24 @@</span> <span class="p_context"> xfs_buf_ioacct_inc(</span>
  * freed and unaccount from the buftarg.
  */
 static inline void
<span class="p_del">-xfs_buf_ioacct_dec(</span>
<span class="p_add">+__xfs_buf_ioacct_dec(</span>
 	struct xfs_buf	*bp)
 {
<span class="p_del">-	if (!(bp-&gt;b_flags &amp; _XBF_IN_FLIGHT))</span>
<span class="p_del">-		return;</span>
<span class="p_add">+	ASSERT(spin_is_locked(&amp;bp-&gt;b_lock));</span>
 
<span class="p_del">-	bp-&gt;b_flags &amp;= ~_XBF_IN_FLIGHT;</span>
<span class="p_del">-	percpu_counter_dec(&amp;bp-&gt;b_target-&gt;bt_io_count);</span>
<span class="p_add">+	if (bp-&gt;b_state &amp; XFS_BSTATE_IN_FLIGHT) {</span>
<span class="p_add">+		bp-&gt;b_state &amp;= ~XFS_BSTATE_IN_FLIGHT;</span>
<span class="p_add">+		percpu_counter_dec(&amp;bp-&gt;b_target-&gt;bt_io_count);</span>
<span class="p_add">+	}</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline void</span>
<span class="p_add">+xfs_buf_ioacct_dec(</span>
<span class="p_add">+	struct xfs_buf	*bp)</span>
<span class="p_add">+{</span>
<span class="p_add">+	spin_lock(&amp;bp-&gt;b_lock);</span>
<span class="p_add">+	__xfs_buf_ioacct_dec(bp);</span>
<span class="p_add">+	spin_unlock(&amp;bp-&gt;b_lock);</span>
 }
 
 /*
<span class="p_chunk">@@ -149,9 +163,9 @@</span> <span class="p_context"> xfs_buf_stale(</span>
 	 * unaccounted (released to LRU) before that occurs. Drop in-flight
 	 * status now to preserve accounting consistency.
 	 */
<span class="p_del">-	xfs_buf_ioacct_dec(bp);</span>
<span class="p_del">-</span>
 	spin_lock(&amp;bp-&gt;b_lock);
<span class="p_add">+	__xfs_buf_ioacct_dec(bp);</span>
<span class="p_add">+</span>
 	atomic_set(&amp;bp-&gt;b_lru_ref, 0);
 	if (!(bp-&gt;b_state &amp; XFS_BSTATE_DISPOSE) &amp;&amp;
 	    (list_lru_del(&amp;bp-&gt;b_target-&gt;bt_lru, &amp;bp-&gt;b_lru)))
<span class="p_chunk">@@ -979,12 +993,12 @@</span> <span class="p_context"> xfs_buf_rele(</span>
 		 * ensures the decrement occurs only once per-buf.
 		 */
 		if ((atomic_read(&amp;bp-&gt;b_hold) == 1) &amp;&amp; !list_empty(&amp;bp-&gt;b_lru))
<span class="p_del">-			xfs_buf_ioacct_dec(bp);</span>
<span class="p_add">+			__xfs_buf_ioacct_dec(bp);</span>
 		goto out_unlock;
 	}
 
 	/* the last reference has been dropped ... */
<span class="p_del">-	xfs_buf_ioacct_dec(bp);</span>
<span class="p_add">+	__xfs_buf_ioacct_dec(bp);</span>
 	if (!(bp-&gt;b_flags &amp; XBF_STALE) &amp;&amp; atomic_read(&amp;bp-&gt;b_lru_ref)) {
 		/*
 		 * If the buffer is added to the LRU take a new reference to the
<span class="p_chunk">@@ -1079,6 +1093,8 @@</span> <span class="p_context"> void</span>
 xfs_buf_unlock(
 	struct xfs_buf		*bp)
 {
<span class="p_add">+	ASSERT(xfs_buf_islocked(bp));</span>
<span class="p_add">+</span>
 	XB_CLEAR_OWNER(bp);
 	up(&amp;bp-&gt;b_sema);
 
<span class="p_chunk">@@ -1815,6 +1831,28 @@</span> <span class="p_context"> xfs_alloc_buftarg(</span>
 }
 
 /*
<span class="p_add">+ * Cancel a delayed write list.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * Remove each buffer from the list, clear the delwri queue flag and drop the</span>
<span class="p_add">+ * associated buffer reference.</span>
<span class="p_add">+ */</span>
<span class="p_add">+void</span>
<span class="p_add">+xfs_buf_delwri_cancel(</span>
<span class="p_add">+	struct list_head	*list)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct xfs_buf		*bp;</span>
<span class="p_add">+</span>
<span class="p_add">+	while (!list_empty(list)) {</span>
<span class="p_add">+		bp = list_first_entry(list, struct xfs_buf, b_list);</span>
<span class="p_add">+</span>
<span class="p_add">+		xfs_buf_lock(bp);</span>
<span class="p_add">+		bp-&gt;b_flags &amp;= ~_XBF_DELWRI_Q;</span>
<span class="p_add">+		list_del_init(&amp;bp-&gt;b_list);</span>
<span class="p_add">+		xfs_buf_relse(bp);</span>
<span class="p_add">+	}</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+/*</span>
  * Add a buffer to the delayed write list.
  *
  * This queues a buffer for writeout if it hasn&#39;t already been.  Note that
<span class="p_header">diff --git a/fs/xfs/xfs_buf.h b/fs/xfs/xfs_buf.h</span>
<span class="p_header">index 3c867e5a63e1..39d9334e59ee 100644</span>
<span class="p_header">--- a/fs/xfs/xfs_buf.h</span>
<span class="p_header">+++ b/fs/xfs/xfs_buf.h</span>
<span class="p_chunk">@@ -63,7 +63,6 @@</span> <span class="p_context"> typedef enum {</span>
 #define _XBF_KMEM	 (1 &lt;&lt; 21)/* backed by heap memory */
 #define _XBF_DELWRI_Q	 (1 &lt;&lt; 22)/* buffer on a delwri queue */
 #define _XBF_COMPOUND	 (1 &lt;&lt; 23)/* compound buffer */
<span class="p_del">-#define _XBF_IN_FLIGHT	 (1 &lt;&lt; 25) /* I/O in flight, for accounting purposes */</span>
 
 typedef unsigned int xfs_buf_flags_t;
 
<span class="p_chunk">@@ -84,14 +83,14 @@</span> <span class="p_context"> typedef unsigned int xfs_buf_flags_t;</span>
 	{ _XBF_PAGES,		&quot;PAGES&quot; }, \
 	{ _XBF_KMEM,		&quot;KMEM&quot; }, \
 	{ _XBF_DELWRI_Q,	&quot;DELWRI_Q&quot; }, \
<span class="p_del">-	{ _XBF_COMPOUND,	&quot;COMPOUND&quot; }, \</span>
<span class="p_del">-	{ _XBF_IN_FLIGHT,	&quot;IN_FLIGHT&quot; }</span>
<span class="p_add">+	{ _XBF_COMPOUND,	&quot;COMPOUND&quot; }</span>
 
 
 /*
  * Internal state flags.
  */
 #define XFS_BSTATE_DISPOSE	 (1 &lt;&lt; 0)	/* buffer being discarded */
<span class="p_add">+#define XFS_BSTATE_IN_FLIGHT	 (1 &lt;&lt; 1)	/* I/O in flight */</span>
 
 /*
  * The xfs_buftarg contains 2 notions of &quot;sector size&quot; -
<span class="p_chunk">@@ -330,6 +329,7 @@</span> <span class="p_context"> extern void *xfs_buf_offset(struct xfs_buf *, size_t);</span>
 extern void xfs_buf_stale(struct xfs_buf *bp);
 
 /* Delayed Write Buffer Routines */
<span class="p_add">+extern void xfs_buf_delwri_cancel(struct list_head *);</span>
 extern bool xfs_buf_delwri_queue(struct xfs_buf *, struct list_head *);
 extern int xfs_buf_delwri_submit(struct list_head *);
 extern int xfs_buf_delwri_submit_nowait(struct list_head *);
<span class="p_header">diff --git a/fs/xfs/xfs_dir2_readdir.c b/fs/xfs/xfs_dir2_readdir.c</span>
<span class="p_header">index ad9396e516f6..20b7a5c6eb2f 100644</span>
<span class="p_header">--- a/fs/xfs/xfs_dir2_readdir.c</span>
<span class="p_header">+++ b/fs/xfs/xfs_dir2_readdir.c</span>
<span class="p_chunk">@@ -394,6 +394,7 @@</span> <span class="p_context"> xfs_dir2_leaf_readbuf(</span>
 
 	/*
 	 * Do we need more readahead?
<span class="p_add">+	 * Each loop tries to process 1 full dir blk; last may be partial.</span>
 	 */
 	blk_start_plug(&amp;plug);
 	for (mip-&gt;ra_index = mip-&gt;ra_offset = i = 0;
<span class="p_chunk">@@ -404,7 +405,8 @@</span> <span class="p_context"> xfs_dir2_leaf_readbuf(</span>
 		 * Read-ahead a contiguous directory block.
 		 */
 		if (i &gt; mip-&gt;ra_current &amp;&amp;
<span class="p_del">-		    map[mip-&gt;ra_index].br_blockcount &gt;= geo-&gt;fsbcount) {</span>
<span class="p_add">+		    (map[mip-&gt;ra_index].br_blockcount - mip-&gt;ra_offset) &gt;=</span>
<span class="p_add">+		    geo-&gt;fsbcount) {</span>
 			xfs_dir3_data_readahead(dp,
 				map[mip-&gt;ra_index].br_startoff + mip-&gt;ra_offset,
 				XFS_FSB_TO_DADDR(dp-&gt;i_mount,
<span class="p_chunk">@@ -425,14 +427,19 @@</span> <span class="p_context"> xfs_dir2_leaf_readbuf(</span>
 		}
 
 		/*
<span class="p_del">-		 * Advance offset through the mapping table.</span>
<span class="p_add">+		 * Advance offset through the mapping table, processing a full</span>
<span class="p_add">+		 * dir block even if it is fragmented into several extents.</span>
<span class="p_add">+		 * But stop if we have consumed all valid mappings, even if</span>
<span class="p_add">+		 * it&#39;s not yet a full directory block.</span>
 		 */
<span class="p_del">-		for (j = 0; j &lt; geo-&gt;fsbcount; j += length ) {</span>
<span class="p_add">+		for (j = 0;</span>
<span class="p_add">+		     j &lt; geo-&gt;fsbcount &amp;&amp; mip-&gt;ra_index &lt; mip-&gt;map_valid;</span>
<span class="p_add">+		     j += length ) {</span>
 			/*
 			 * The rest of this extent but not more than a dir
 			 * block.
 			 */
<span class="p_del">-			length = min_t(int, geo-&gt;fsbcount,</span>
<span class="p_add">+			length = min_t(int, geo-&gt;fsbcount - j,</span>
 					map[mip-&gt;ra_index].br_blockcount -
 							mip-&gt;ra_offset);
 			mip-&gt;ra_offset += length;
<span class="p_header">diff --git a/fs/xfs/xfs_file.c b/fs/xfs/xfs_file.c</span>
<span class="p_header">index 35703a801372..dc0e4cb7029b 100644</span>
<span class="p_header">--- a/fs/xfs/xfs_file.c</span>
<span class="p_header">+++ b/fs/xfs/xfs_file.c</span>
<span class="p_chunk">@@ -1043,13 +1043,13 @@</span> <span class="p_context"> xfs_find_get_desired_pgoff(</span>
 
 	index = startoff &gt;&gt; PAGE_SHIFT;
 	endoff = XFS_FSB_TO_B(mp, map-&gt;br_startoff + map-&gt;br_blockcount);
<span class="p_del">-	end = endoff &gt;&gt; PAGE_SHIFT;</span>
<span class="p_add">+	end = (endoff - 1) &gt;&gt; PAGE_SHIFT;</span>
 	do {
 		int		want;
 		unsigned	nr_pages;
 		unsigned int	i;
 
<span class="p_del">-		want = min_t(pgoff_t, end - index, PAGEVEC_SIZE);</span>
<span class="p_add">+		want = min_t(pgoff_t, end - index, PAGEVEC_SIZE - 1) + 1;</span>
 		nr_pages = pagevec_lookup(&amp;pvec, inode-&gt;i_mapping, index,
 					  want);
 		/*
<span class="p_chunk">@@ -1076,17 +1076,6 @@</span> <span class="p_context"> xfs_find_get_desired_pgoff(</span>
 			break;
 		}
 
<span class="p_del">-		/*</span>
<span class="p_del">-		 * At lease we found one page.  If this is the first time we</span>
<span class="p_del">-		 * step into the loop, and if the first page index offset is</span>
<span class="p_del">-		 * greater than the given search offset, a hole was found.</span>
<span class="p_del">-		 */</span>
<span class="p_del">-		if (type == HOLE_OFF &amp;&amp; lastoff == startoff &amp;&amp;</span>
<span class="p_del">-		    lastoff &lt; page_offset(pvec.pages[0])) {</span>
<span class="p_del">-			found = true;</span>
<span class="p_del">-			break;</span>
<span class="p_del">-		}</span>
<span class="p_del">-</span>
 		for (i = 0; i &lt; nr_pages; i++) {
 			struct page	*page = pvec.pages[i];
 			loff_t		b_offset;
<span class="p_chunk">@@ -1098,18 +1087,18 @@</span> <span class="p_context"> xfs_find_get_desired_pgoff(</span>
 			 * file mapping. However, page-&gt;index will not change
 			 * because we have a reference on the page.
 			 *
<span class="p_del">-			 * Searching done if the page index is out of range.</span>
<span class="p_del">-			 * If the current offset is not reaches the end of</span>
<span class="p_del">-			 * the specified search range, there should be a hole</span>
<span class="p_del">-			 * between them.</span>
<span class="p_add">+			 * If current page offset is beyond where we&#39;ve ended,</span>
<span class="p_add">+			 * we&#39;ve found a hole.</span>
 			 */
<span class="p_del">-			if (page-&gt;index &gt; end) {</span>
<span class="p_del">-				if (type == HOLE_OFF &amp;&amp; lastoff &lt; endoff) {</span>
<span class="p_del">-					*offset = lastoff;</span>
<span class="p_del">-					found = true;</span>
<span class="p_del">-				}</span>
<span class="p_add">+			if (type == HOLE_OFF &amp;&amp; lastoff &lt; endoff &amp;&amp;</span>
<span class="p_add">+			    lastoff &lt; page_offset(pvec.pages[i])) {</span>
<span class="p_add">+				found = true;</span>
<span class="p_add">+				*offset = lastoff;</span>
 				goto out;
 			}
<span class="p_add">+			/* Searching done if the page index is out of range. */</span>
<span class="p_add">+			if (page-&gt;index &gt; end)</span>
<span class="p_add">+				goto out;</span>
 
 			lock_page(page);
 			/*
<span class="p_header">diff --git a/fs/xfs/xfs_icache.c b/fs/xfs/xfs_icache.c</span>
<span class="p_header">index 3531f8f72fa5..f61c84f8e31a 100644</span>
<span class="p_header">--- a/fs/xfs/xfs_icache.c</span>
<span class="p_header">+++ b/fs/xfs/xfs_icache.c</span>
<span class="p_chunk">@@ -262,6 +262,22 @@</span> <span class="p_context"> xfs_inode_clear_reclaim_tag(</span>
 	xfs_perag_clear_reclaim_tag(pag);
 }
 
<span class="p_add">+static void</span>
<span class="p_add">+xfs_inew_wait(</span>
<span class="p_add">+	struct xfs_inode	*ip)</span>
<span class="p_add">+{</span>
<span class="p_add">+	wait_queue_head_t *wq = bit_waitqueue(&amp;ip-&gt;i_flags, __XFS_INEW_BIT);</span>
<span class="p_add">+	DEFINE_WAIT_BIT(wait, &amp;ip-&gt;i_flags, __XFS_INEW_BIT);</span>
<span class="p_add">+</span>
<span class="p_add">+	do {</span>
<span class="p_add">+		prepare_to_wait(wq, &amp;wait.wait, TASK_UNINTERRUPTIBLE);</span>
<span class="p_add">+		if (!xfs_iflags_test(ip, XFS_INEW))</span>
<span class="p_add">+			break;</span>
<span class="p_add">+		schedule();</span>
<span class="p_add">+	} while (true);</span>
<span class="p_add">+	finish_wait(wq, &amp;wait.wait);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 /*
  * When we recycle a reclaimable inode, we need to re-initialise the VFS inode
  * part of the structure. This is made more complex by the fact we store
<span class="p_chunk">@@ -366,14 +382,17 @@</span> <span class="p_context"> xfs_iget_cache_hit(</span>
 
 		error = xfs_reinit_inode(mp, inode);
 		if (error) {
<span class="p_add">+			bool wake;</span>
 			/*
 			 * Re-initializing the inode failed, and we are in deep
 			 * trouble.  Try to re-add it to the reclaim list.
 			 */
 			rcu_read_lock();
 			spin_lock(&amp;ip-&gt;i_flags_lock);
<span class="p_del">-</span>
<span class="p_add">+			wake = !!__xfs_iflags_test(ip, XFS_INEW);</span>
 			ip-&gt;i_flags &amp;= ~(XFS_INEW | XFS_IRECLAIM);
<span class="p_add">+			if (wake)</span>
<span class="p_add">+				wake_up_bit(&amp;ip-&gt;i_flags, __XFS_INEW_BIT);</span>
 			ASSERT(ip-&gt;i_flags &amp; XFS_IRECLAIMABLE);
 			trace_xfs_iget_reclaim_fail(ip);
 			goto out_error;
<span class="p_chunk">@@ -623,9 +642,11 @@</span> <span class="p_context"> xfs_iget(</span>
 
 STATIC int
 xfs_inode_ag_walk_grab(
<span class="p_del">-	struct xfs_inode	*ip)</span>
<span class="p_add">+	struct xfs_inode	*ip,</span>
<span class="p_add">+	int			flags)</span>
 {
 	struct inode		*inode = VFS_I(ip);
<span class="p_add">+	bool			newinos = !!(flags &amp; XFS_AGITER_INEW_WAIT);</span>
 
 	ASSERT(rcu_read_lock_held());
 
<span class="p_chunk">@@ -643,7 +664,8 @@</span> <span class="p_context"> xfs_inode_ag_walk_grab(</span>
 		goto out_unlock_noent;
 
 	/* avoid new or reclaimable inodes. Leave for reclaim code to flush */
<span class="p_del">-	if (__xfs_iflags_test(ip, XFS_INEW | XFS_IRECLAIMABLE | XFS_IRECLAIM))</span>
<span class="p_add">+	if ((!newinos &amp;&amp; __xfs_iflags_test(ip, XFS_INEW)) ||</span>
<span class="p_add">+	    __xfs_iflags_test(ip, XFS_IRECLAIMABLE | XFS_IRECLAIM))</span>
 		goto out_unlock_noent;
 	spin_unlock(&amp;ip-&gt;i_flags_lock);
 
<span class="p_chunk">@@ -671,7 +693,8 @@</span> <span class="p_context"> xfs_inode_ag_walk(</span>
 					   void *args),
 	int			flags,
 	void			*args,
<span class="p_del">-	int			tag)</span>
<span class="p_add">+	int			tag,</span>
<span class="p_add">+	int			iter_flags)</span>
 {
 	uint32_t		first_index;
 	int			last_error = 0;
<span class="p_chunk">@@ -713,7 +736,7 @@</span> <span class="p_context"> xfs_inode_ag_walk(</span>
 		for (i = 0; i &lt; nr_found; i++) {
 			struct xfs_inode *ip = batch[i];
 
<span class="p_del">-			if (done || xfs_inode_ag_walk_grab(ip))</span>
<span class="p_add">+			if (done || xfs_inode_ag_walk_grab(ip, iter_flags))</span>
 				batch[i] = NULL;
 
 			/*
<span class="p_chunk">@@ -741,6 +764,9 @@</span> <span class="p_context"> xfs_inode_ag_walk(</span>
 		for (i = 0; i &lt; nr_found; i++) {
 			if (!batch[i])
 				continue;
<span class="p_add">+			if ((iter_flags &amp; XFS_AGITER_INEW_WAIT) &amp;&amp;</span>
<span class="p_add">+			    xfs_iflags_test(batch[i], XFS_INEW))</span>
<span class="p_add">+				xfs_inew_wait(batch[i]);</span>
 			error = execute(batch[i], flags, args);
 			IRELE(batch[i]);
 			if (error == -EAGAIN) {
<span class="p_chunk">@@ -820,12 +846,13 @@</span> <span class="p_context"> xfs_cowblocks_worker(</span>
 }
 
 int
<span class="p_del">-xfs_inode_ag_iterator(</span>
<span class="p_add">+xfs_inode_ag_iterator_flags(</span>
 	struct xfs_mount	*mp,
 	int			(*execute)(struct xfs_inode *ip, int flags,
 					   void *args),
 	int			flags,
<span class="p_del">-	void			*args)</span>
<span class="p_add">+	void			*args,</span>
<span class="p_add">+	int			iter_flags)</span>
 {
 	struct xfs_perag	*pag;
 	int			error = 0;
<span class="p_chunk">@@ -835,7 +862,8 @@</span> <span class="p_context"> xfs_inode_ag_iterator(</span>
 	ag = 0;
 	while ((pag = xfs_perag_get(mp, ag))) {
 		ag = pag-&gt;pag_agno + 1;
<span class="p_del">-		error = xfs_inode_ag_walk(mp, pag, execute, flags, args, -1);</span>
<span class="p_add">+		error = xfs_inode_ag_walk(mp, pag, execute, flags, args, -1,</span>
<span class="p_add">+					  iter_flags);</span>
 		xfs_perag_put(pag);
 		if (error) {
 			last_error = error;
<span class="p_chunk">@@ -847,6 +875,17 @@</span> <span class="p_context"> xfs_inode_ag_iterator(</span>
 }
 
 int
<span class="p_add">+xfs_inode_ag_iterator(</span>
<span class="p_add">+	struct xfs_mount	*mp,</span>
<span class="p_add">+	int			(*execute)(struct xfs_inode *ip, int flags,</span>
<span class="p_add">+					   void *args),</span>
<span class="p_add">+	int			flags,</span>
<span class="p_add">+	void			*args)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return xfs_inode_ag_iterator_flags(mp, execute, flags, args, 0);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+int</span>
 xfs_inode_ag_iterator_tag(
 	struct xfs_mount	*mp,
 	int			(*execute)(struct xfs_inode *ip, int flags,
<span class="p_chunk">@@ -863,7 +902,8 @@</span> <span class="p_context"> xfs_inode_ag_iterator_tag(</span>
 	ag = 0;
 	while ((pag = xfs_perag_get_tag(mp, ag, tag))) {
 		ag = pag-&gt;pag_agno + 1;
<span class="p_del">-		error = xfs_inode_ag_walk(mp, pag, execute, flags, args, tag);</span>
<span class="p_add">+		error = xfs_inode_ag_walk(mp, pag, execute, flags, args, tag,</span>
<span class="p_add">+					  0);</span>
 		xfs_perag_put(pag);
 		if (error) {
 			last_error = error;
<span class="p_header">diff --git a/fs/xfs/xfs_icache.h b/fs/xfs/xfs_icache.h</span>
<span class="p_header">index 8a7c849b4dea..9183f77958ef 100644</span>
<span class="p_header">--- a/fs/xfs/xfs_icache.h</span>
<span class="p_header">+++ b/fs/xfs/xfs_icache.h</span>
<span class="p_chunk">@@ -48,6 +48,11 @@</span> <span class="p_context"> struct xfs_eofblocks {</span>
 #define XFS_IGET_UNTRUSTED	0x2
 #define XFS_IGET_DONTCACHE	0x4
 
<span class="p_add">+/*</span>
<span class="p_add">+ * flags for AG inode iterator</span>
<span class="p_add">+ */</span>
<span class="p_add">+#define XFS_AGITER_INEW_WAIT	0x1	/* wait on new inodes */</span>
<span class="p_add">+</span>
 int xfs_iget(struct xfs_mount *mp, struct xfs_trans *tp, xfs_ino_t ino,
 	     uint flags, uint lock_flags, xfs_inode_t **ipp);
 
<span class="p_chunk">@@ -79,6 +84,9 @@</span> <span class="p_context"> void xfs_cowblocks_worker(struct work_struct *);</span>
 int xfs_inode_ag_iterator(struct xfs_mount *mp,
 	int (*execute)(struct xfs_inode *ip, int flags, void *args),
 	int flags, void *args);
<span class="p_add">+int xfs_inode_ag_iterator_flags(struct xfs_mount *mp,</span>
<span class="p_add">+	int (*execute)(struct xfs_inode *ip, int flags, void *args),</span>
<span class="p_add">+	int flags, void *args, int iter_flags);</span>
 int xfs_inode_ag_iterator_tag(struct xfs_mount *mp,
 	int (*execute)(struct xfs_inode *ip, int flags, void *args),
 	int flags, void *args, int tag);
<span class="p_header">diff --git a/fs/xfs/xfs_inode.c b/fs/xfs/xfs_inode.c</span>
<span class="p_header">index 7605d8396596..ec9826c56500 100644</span>
<span class="p_header">--- a/fs/xfs/xfs_inode.c</span>
<span class="p_header">+++ b/fs/xfs/xfs_inode.c</span>
<span class="p_chunk">@@ -1906,12 +1906,13 @@</span> <span class="p_context"> xfs_inactive(</span>
 		 * force is true because we are evicting an inode from the
 		 * cache. Post-eof blocks must be freed, lest we end up with
 		 * broken free space accounting.
<span class="p_add">+		 *</span>
<span class="p_add">+		 * Note: don&#39;t bother with iolock here since lockdep complains</span>
<span class="p_add">+		 * about acquiring it in reclaim context. We have the only</span>
<span class="p_add">+		 * reference to the inode at this point anyways.</span>
 		 */
<span class="p_del">-		if (xfs_can_free_eofblocks(ip, true)) {</span>
<span class="p_del">-			xfs_ilock(ip, XFS_IOLOCK_EXCL);</span>
<span class="p_add">+		if (xfs_can_free_eofblocks(ip, true))</span>
 			xfs_free_eofblocks(ip);
<span class="p_del">-			xfs_iunlock(ip, XFS_IOLOCK_EXCL);</span>
<span class="p_del">-		}</span>
 
 		return;
 	}
<span class="p_header">diff --git a/fs/xfs/xfs_inode.h b/fs/xfs/xfs_inode.h</span>
<span class="p_header">index 10dcf27b4c85..10e89fcb49d7 100644</span>
<span class="p_header">--- a/fs/xfs/xfs_inode.h</span>
<span class="p_header">+++ b/fs/xfs/xfs_inode.h</span>
<span class="p_chunk">@@ -216,7 +216,8 @@</span> <span class="p_context"> static inline bool xfs_is_reflink_inode(struct xfs_inode *ip)</span>
 #define XFS_IRECLAIM		(1 &lt;&lt; 0) /* started reclaiming this inode */
 #define XFS_ISTALE		(1 &lt;&lt; 1) /* inode has been staled */
 #define XFS_IRECLAIMABLE	(1 &lt;&lt; 2) /* inode can be reclaimed */
<span class="p_del">-#define XFS_INEW		(1 &lt;&lt; 3) /* inode has just been allocated */</span>
<span class="p_add">+#define __XFS_INEW_BIT		3	 /* inode has just been allocated */</span>
<span class="p_add">+#define XFS_INEW		(1 &lt;&lt; __XFS_INEW_BIT)</span>
 #define XFS_ITRUNCATED		(1 &lt;&lt; 5) /* truncated down so flush-on-close */
 #define XFS_IDIRTY_RELEASE	(1 &lt;&lt; 6) /* dirty release already seen */
 #define __XFS_IFLOCK_BIT	7	 /* inode is being flushed right now */
<span class="p_chunk">@@ -464,6 +465,7 @@</span> <span class="p_context"> static inline void xfs_finish_inode_setup(struct xfs_inode *ip)</span>
 	xfs_iflags_clear(ip, XFS_INEW);
 	barrier();
 	unlock_new_inode(VFS_I(ip));
<span class="p_add">+	wake_up_bit(&amp;ip-&gt;i_flags, __XFS_INEW_BIT);</span>
 }
 
 static inline void xfs_setup_existing_inode(struct xfs_inode *ip)
<span class="p_header">diff --git a/fs/xfs/xfs_ioctl.c b/fs/xfs/xfs_ioctl.c</span>
<span class="p_header">index 2fd7fdf5438f..6d30b06e79bc 100644</span>
<span class="p_header">--- a/fs/xfs/xfs_ioctl.c</span>
<span class="p_header">+++ b/fs/xfs/xfs_ioctl.c</span>
<span class="p_chunk">@@ -1543,10 +1543,11 @@</span> <span class="p_context"> xfs_ioc_getbmap(</span>
 	unsigned int		cmd,
 	void			__user *arg)
 {
<span class="p_del">-	struct getbmapx		bmx;</span>
<span class="p_add">+	struct getbmapx		bmx = { 0 };</span>
 	int			error;
 
<span class="p_del">-	if (copy_from_user(&amp;bmx, arg, sizeof(struct getbmapx)))</span>
<span class="p_add">+	/* struct getbmap is a strict subset of struct getbmapx. */</span>
<span class="p_add">+	if (copy_from_user(&amp;bmx, arg, offsetof(struct getbmapx, bmv_iflags)))</span>
 		return -EFAULT;
 
 	if (bmx.bmv_count &lt; 2)
<span class="p_header">diff --git a/fs/xfs/xfs_iomap.c b/fs/xfs/xfs_iomap.c</span>
<span class="p_header">index 288ee5b840d7..79e6dfac3dd6 100644</span>
<span class="p_header">--- a/fs/xfs/xfs_iomap.c</span>
<span class="p_header">+++ b/fs/xfs/xfs_iomap.c</span>
<span class="p_chunk">@@ -1170,10 +1170,10 @@</span> <span class="p_context"> xfs_xattr_iomap_begin(</span>
 	if (XFS_FORCED_SHUTDOWN(mp))
 		return -EIO;
 
<span class="p_del">-	lockmode = xfs_ilock_data_map_shared(ip);</span>
<span class="p_add">+	lockmode = xfs_ilock_attr_map_shared(ip);</span>
 
 	/* if there are no attribute fork or extents, return ENOENT */
<span class="p_del">-	if (XFS_IFORK_Q(ip) || !ip-&gt;i_d.di_anextents) {</span>
<span class="p_add">+	if (!XFS_IFORK_Q(ip) || !ip-&gt;i_d.di_anextents) {</span>
 		error = -ENOENT;
 		goto out_unlock;
 	}
<span class="p_header">diff --git a/fs/xfs/xfs_log.c b/fs/xfs/xfs_log.c</span>
<span class="p_header">index b1469f0a91a6..bb58cd1873c9 100644</span>
<span class="p_header">--- a/fs/xfs/xfs_log.c</span>
<span class="p_header">+++ b/fs/xfs/xfs_log.c</span>
<span class="p_chunk">@@ -1293,7 +1293,7 @@</span> <span class="p_context"> void</span>
 xfs_log_work_queue(
 	struct xfs_mount        *mp)
 {
<span class="p_del">-	queue_delayed_work(mp-&gt;m_log_workqueue, &amp;mp-&gt;m_log-&gt;l_work,</span>
<span class="p_add">+	queue_delayed_work(mp-&gt;m_sync_workqueue, &amp;mp-&gt;m_log-&gt;l_work,</span>
 				msecs_to_jiffies(xfs_syncd_centisecs * 10));
 }
 
<span class="p_header">diff --git a/fs/xfs/xfs_mount.h b/fs/xfs/xfs_mount.h</span>
<span class="p_header">index 6db6fd6b82b0..22b2185e93a0 100644</span>
<span class="p_header">--- a/fs/xfs/xfs_mount.h</span>
<span class="p_header">+++ b/fs/xfs/xfs_mount.h</span>
<span class="p_chunk">@@ -183,6 +183,7 @@</span> <span class="p_context"> typedef struct xfs_mount {</span>
 	struct workqueue_struct	*m_reclaim_workqueue;
 	struct workqueue_struct	*m_log_workqueue;
 	struct workqueue_struct *m_eofblocks_workqueue;
<span class="p_add">+	struct workqueue_struct	*m_sync_workqueue;</span>
 
 	/*
 	 * Generation of the filesysyem layout.  This is incremented by each
<span class="p_header">diff --git a/fs/xfs/xfs_qm.c b/fs/xfs/xfs_qm.c</span>
<span class="p_header">index b669b123287b..8b9a9f15f022 100644</span>
<span class="p_header">--- a/fs/xfs/xfs_qm.c</span>
<span class="p_header">+++ b/fs/xfs/xfs_qm.c</span>
<span class="p_chunk">@@ -1384,12 +1384,7 @@</span> <span class="p_context"> xfs_qm_quotacheck(</span>
 	mp-&gt;m_qflags |= flags;
 
  error_return:
<span class="p_del">-	while (!list_empty(&amp;buffer_list)) {</span>
<span class="p_del">-		struct xfs_buf *bp =</span>
<span class="p_del">-			list_first_entry(&amp;buffer_list, struct xfs_buf, b_list);</span>
<span class="p_del">-		list_del_init(&amp;bp-&gt;b_list);</span>
<span class="p_del">-		xfs_buf_relse(bp);</span>
<span class="p_del">-	}</span>
<span class="p_add">+	xfs_buf_delwri_cancel(&amp;buffer_list);</span>
 
 	if (error) {
 		xfs_warn(mp,
<span class="p_header">diff --git a/fs/xfs/xfs_qm_syscalls.c b/fs/xfs/xfs_qm_syscalls.c</span>
<span class="p_header">index 475a3882a81f..9cb5c381b01c 100644</span>
<span class="p_header">--- a/fs/xfs/xfs_qm_syscalls.c</span>
<span class="p_header">+++ b/fs/xfs/xfs_qm_syscalls.c</span>
<span class="p_chunk">@@ -759,5 +759,6 @@</span> <span class="p_context"> xfs_qm_dqrele_all_inodes(</span>
 	uint		 flags)
 {
 	ASSERT(mp-&gt;m_quotainfo);
<span class="p_del">-	xfs_inode_ag_iterator(mp, xfs_dqrele_inode, flags, NULL);</span>
<span class="p_add">+	xfs_inode_ag_iterator_flags(mp, xfs_dqrele_inode, flags, NULL,</span>
<span class="p_add">+				    XFS_AGITER_INEW_WAIT);</span>
 }
<span class="p_header">diff --git a/fs/xfs/xfs_reflink.c b/fs/xfs/xfs_reflink.c</span>
<span class="p_header">index 4a84c5ea266d..20c46d2ff4f5 100644</span>
<span class="p_header">--- a/fs/xfs/xfs_reflink.c</span>
<span class="p_header">+++ b/fs/xfs/xfs_reflink.c</span>
<span class="p_chunk">@@ -709,8 +709,22 @@</span> <span class="p_context"> xfs_reflink_end_cow(</span>
 	offset_fsb = XFS_B_TO_FSBT(ip-&gt;i_mount, offset);
 	end_fsb = XFS_B_TO_FSB(ip-&gt;i_mount, offset + count);
 
<span class="p_del">-	/* Start a rolling transaction to switch the mappings */</span>
<span class="p_del">-	resblks = XFS_EXTENTADD_SPACE_RES(ip-&gt;i_mount, XFS_DATA_FORK);</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Start a rolling transaction to switch the mappings.  We&#39;re</span>
<span class="p_add">+	 * unlikely ever to have to remap 16T worth of single-block</span>
<span class="p_add">+	 * extents, so just cap the worst case extent count to 2^32-1.</span>
<span class="p_add">+	 * Stick a warning in just in case, and avoid 64-bit division.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	BUILD_BUG_ON(MAX_RW_COUNT &gt; UINT_MAX);</span>
<span class="p_add">+	if (end_fsb - offset_fsb &gt; UINT_MAX) {</span>
<span class="p_add">+		error = -EFSCORRUPTED;</span>
<span class="p_add">+		xfs_force_shutdown(ip-&gt;i_mount, SHUTDOWN_CORRUPT_INCORE);</span>
<span class="p_add">+		ASSERT(0);</span>
<span class="p_add">+		goto out;</span>
<span class="p_add">+	}</span>
<span class="p_add">+	resblks = XFS_NEXTENTADD_SPACE_RES(ip-&gt;i_mount,</span>
<span class="p_add">+			(unsigned int)(end_fsb - offset_fsb),</span>
<span class="p_add">+			XFS_DATA_FORK);</span>
 	error = xfs_trans_alloc(ip-&gt;i_mount, &amp;M_RES(ip-&gt;i_mount)-&gt;tr_write,
 			resblks, 0, 0, &amp;tp);
 	if (error)
<span class="p_header">diff --git a/fs/xfs/xfs_super.c b/fs/xfs/xfs_super.c</span>
<span class="p_header">index 685c042a120f..47d239dcf3f4 100644</span>
<span class="p_header">--- a/fs/xfs/xfs_super.c</span>
<span class="p_header">+++ b/fs/xfs/xfs_super.c</span>
<span class="p_chunk">@@ -877,8 +877,15 @@</span> <span class="p_context"> xfs_init_mount_workqueues(</span>
 	if (!mp-&gt;m_eofblocks_workqueue)
 		goto out_destroy_log;
 
<span class="p_add">+	mp-&gt;m_sync_workqueue = alloc_workqueue(&quot;xfs-sync/%s&quot;, WQ_FREEZABLE, 0,</span>
<span class="p_add">+					       mp-&gt;m_fsname);</span>
<span class="p_add">+	if (!mp-&gt;m_sync_workqueue)</span>
<span class="p_add">+		goto out_destroy_eofb;</span>
<span class="p_add">+</span>
 	return 0;
 
<span class="p_add">+out_destroy_eofb:</span>
<span class="p_add">+	destroy_workqueue(mp-&gt;m_eofblocks_workqueue);</span>
 out_destroy_log:
 	destroy_workqueue(mp-&gt;m_log_workqueue);
 out_destroy_reclaim:
<span class="p_chunk">@@ -899,6 +906,7 @@</span> <span class="p_context"> STATIC void</span>
 xfs_destroy_mount_workqueues(
 	struct xfs_mount	*mp)
 {
<span class="p_add">+	destroy_workqueue(mp-&gt;m_sync_workqueue);</span>
 	destroy_workqueue(mp-&gt;m_eofblocks_workqueue);
 	destroy_workqueue(mp-&gt;m_log_workqueue);
 	destroy_workqueue(mp-&gt;m_reclaim_workqueue);
<span class="p_header">diff --git a/fs/xfs/xfs_trans.c b/fs/xfs/xfs_trans.c</span>
<span class="p_header">index 70f42ea86dfb..a280e126491f 100644</span>
<span class="p_header">--- a/fs/xfs/xfs_trans.c</span>
<span class="p_header">+++ b/fs/xfs/xfs_trans.c</span>
<span class="p_chunk">@@ -263,6 +263,28 @@</span> <span class="p_context"> xfs_trans_alloc(</span>
 }
 
 /*
<span class="p_add">+ * Create an empty transaction with no reservation.  This is a defensive</span>
<span class="p_add">+ * mechanism for routines that query metadata without actually modifying</span>
<span class="p_add">+ * them -- if the metadata being queried is somehow cross-linked (think a</span>
<span class="p_add">+ * btree block pointer that points higher in the tree), we risk deadlock.</span>
<span class="p_add">+ * However, blocks grabbed as part of a transaction can be re-grabbed.</span>
<span class="p_add">+ * The verifiers will notice the corrupt block and the operation will fail</span>
<span class="p_add">+ * back to userspace without deadlocking.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * Note the zero-length reservation; this transaction MUST be cancelled</span>
<span class="p_add">+ * without any dirty data.</span>
<span class="p_add">+ */</span>
<span class="p_add">+int</span>
<span class="p_add">+xfs_trans_alloc_empty(</span>
<span class="p_add">+	struct xfs_mount		*mp,</span>
<span class="p_add">+	struct xfs_trans		**tpp)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct xfs_trans_res		resv = {0};</span>
<span class="p_add">+</span>
<span class="p_add">+	return xfs_trans_alloc(mp, &amp;resv, 0, 0, XFS_TRANS_NO_WRITECOUNT, tpp);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+/*</span>
  * Record the indicated change to the given field for application
  * to the file system&#39;s superblock when the transaction commits.
  * For now, just store the change in the transaction structure.
<span class="p_header">diff --git a/fs/xfs/xfs_trans.h b/fs/xfs/xfs_trans.h</span>
<span class="p_header">index 1646f659b60f..2a9292df6640 100644</span>
<span class="p_header">--- a/fs/xfs/xfs_trans.h</span>
<span class="p_header">+++ b/fs/xfs/xfs_trans.h</span>
<span class="p_chunk">@@ -158,6 +158,8 @@</span> <span class="p_context"> typedef struct xfs_trans {</span>
 int		xfs_trans_alloc(struct xfs_mount *mp, struct xfs_trans_res *resp,
 			uint blocks, uint rtextents, uint flags,
 			struct xfs_trans **tpp);
<span class="p_add">+int		xfs_trans_alloc_empty(struct xfs_mount *mp,</span>
<span class="p_add">+			struct xfs_trans **tpp);</span>
 void		xfs_trans_mod_sb(xfs_trans_t *, uint, int64_t);
 
 struct xfs_buf	*xfs_trans_get_buf_map(struct xfs_trans *tp,
<span class="p_header">diff --git a/include/linux/if_vlan.h b/include/linux/if_vlan.h</span>
<span class="p_header">index 8d5fcd6284ce..283dc2f5364d 100644</span>
<span class="p_header">--- a/include/linux/if_vlan.h</span>
<span class="p_header">+++ b/include/linux/if_vlan.h</span>
<span class="p_chunk">@@ -614,14 +614,16 @@</span> <span class="p_context"> static inline bool skb_vlan_tagged_multi(const struct sk_buff *skb)</span>
 static inline netdev_features_t vlan_features_check(const struct sk_buff *skb,
 						    netdev_features_t features)
 {
<span class="p_del">-	if (skb_vlan_tagged_multi(skb))</span>
<span class="p_del">-		features = netdev_intersect_features(features,</span>
<span class="p_del">-						     NETIF_F_SG |</span>
<span class="p_del">-						     NETIF_F_HIGHDMA |</span>
<span class="p_del">-						     NETIF_F_FRAGLIST |</span>
<span class="p_del">-						     NETIF_F_HW_CSUM |</span>
<span class="p_del">-						     NETIF_F_HW_VLAN_CTAG_TX |</span>
<span class="p_del">-						     NETIF_F_HW_VLAN_STAG_TX);</span>
<span class="p_add">+	if (skb_vlan_tagged_multi(skb)) {</span>
<span class="p_add">+		/* In the case of multi-tagged packets, use a direct mask</span>
<span class="p_add">+		 * instead of using netdev_interesect_features(), to make</span>
<span class="p_add">+		 * sure that only devices supporting NETIF_F_HW_CSUM will</span>
<span class="p_add">+		 * have checksum offloading support.</span>
<span class="p_add">+		 */</span>
<span class="p_add">+		features &amp;= NETIF_F_SG | NETIF_F_HIGHDMA | NETIF_F_HW_CSUM |</span>
<span class="p_add">+			    NETIF_F_FRAGLIST | NETIF_F_HW_VLAN_CTAG_TX |</span>
<span class="p_add">+			    NETIF_F_HW_VLAN_STAG_TX;</span>
<span class="p_add">+	}</span>
 
 	return features;
 }
<span class="p_header">diff --git a/include/linux/memblock.h b/include/linux/memblock.h</span>
<span class="p_header">index bdfc65af4152..14dbc4fd0a92 100644</span>
<span class="p_header">--- a/include/linux/memblock.h</span>
<span class="p_header">+++ b/include/linux/memblock.h</span>
<span class="p_chunk">@@ -423,12 +423,20 @@</span> <span class="p_context"> static inline void early_memtest(phys_addr_t start, phys_addr_t end)</span>
 }
 #endif
 
<span class="p_add">+extern unsigned long memblock_reserved_memory_within(phys_addr_t start_addr,</span>
<span class="p_add">+		phys_addr_t end_addr);</span>
 #else
 static inline phys_addr_t memblock_alloc(phys_addr_t size, phys_addr_t align)
 {
 	return 0;
 }
 
<span class="p_add">+static inline unsigned long memblock_reserved_memory_within(phys_addr_t start_addr,</span>
<span class="p_add">+		phys_addr_t end_addr)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return 0;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 #endif /* CONFIG_HAVE_MEMBLOCK */
 
 #endif /* __KERNEL__ */
<span class="p_header">diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h</span>
<span class="p_header">index 2fcff6b4503f..c965d1165df6 100644</span>
<span class="p_header">--- a/include/linux/mlx5/driver.h</span>
<span class="p_header">+++ b/include/linux/mlx5/driver.h</span>
<span class="p_chunk">@@ -785,7 +785,12 @@</span> <span class="p_context"> enum {</span>
 
 typedef void (*mlx5_cmd_cbk_t)(int status, void *context);
 
<span class="p_add">+enum {</span>
<span class="p_add">+	MLX5_CMD_ENT_STATE_PENDING_COMP,</span>
<span class="p_add">+};</span>
<span class="p_add">+</span>
 struct mlx5_cmd_work_ent {
<span class="p_add">+	unsigned long		state;</span>
 	struct mlx5_cmd_msg    *in;
 	struct mlx5_cmd_msg    *out;
 	void		       *uout;
<span class="p_chunk">@@ -979,7 +984,7 @@</span> <span class="p_context"> void mlx5_cq_completion(struct mlx5_core_dev *dev, u32 cqn);</span>
 void mlx5_rsc_event(struct mlx5_core_dev *dev, u32 rsn, int event_type);
 void mlx5_srq_event(struct mlx5_core_dev *dev, u32 srqn, int event_type);
 struct mlx5_core_srq *mlx5_core_get_srq(struct mlx5_core_dev *dev, u32 srqn);
<span class="p_del">-void mlx5_cmd_comp_handler(struct mlx5_core_dev *dev, u64 vec);</span>
<span class="p_add">+void mlx5_cmd_comp_handler(struct mlx5_core_dev *dev, u64 vec, bool forced);</span>
 void mlx5_cq_event(struct mlx5_core_dev *dev, u32 cqn, int event_type);
 int mlx5_create_map_eq(struct mlx5_core_dev *dev, struct mlx5_eq *eq, u8 vecidx,
 		       int nent, u64 mask, const char *name,
<span class="p_header">diff --git a/include/linux/mm.h b/include/linux/mm.h</span>
<span class="p_header">index 00a8fa7e366a..018b134f6427 100644</span>
<span class="p_header">--- a/include/linux/mm.h</span>
<span class="p_header">+++ b/include/linux/mm.h</span>
<span class="p_chunk">@@ -2315,6 +2315,17 @@</span> <span class="p_context"> static inline struct page *follow_page(struct vm_area_struct *vma,</span>
 #define FOLL_REMOTE	0x2000	/* we are working on non-current tsk/mm */
 #define FOLL_COW	0x4000	/* internal GUP flag */
 
<span class="p_add">+static inline int vm_fault_to_errno(int vm_fault, int foll_flags)</span>
<span class="p_add">+{</span>
<span class="p_add">+	if (vm_fault &amp; VM_FAULT_OOM)</span>
<span class="p_add">+		return -ENOMEM;</span>
<span class="p_add">+	if (vm_fault &amp; (VM_FAULT_HWPOISON | VM_FAULT_HWPOISON_LARGE))</span>
<span class="p_add">+		return (foll_flags &amp; FOLL_HWPOISON) ? -EHWPOISON : -EFAULT;</span>
<span class="p_add">+	if (vm_fault &amp; (VM_FAULT_SIGBUS | VM_FAULT_SIGSEGV))</span>
<span class="p_add">+		return -EFAULT;</span>
<span class="p_add">+	return 0;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 typedef int (*pte_fn_t)(pte_t *pte, pgtable_t token, unsigned long addr,
 			void *data);
 extern int apply_to_page_range(struct mm_struct *mm, unsigned long address,
<span class="p_header">diff --git a/include/linux/mmzone.h b/include/linux/mmzone.h</span>
<span class="p_header">index d45172b559d8..a3e9b7ba2c25 100644</span>
<span class="p_header">--- a/include/linux/mmzone.h</span>
<span class="p_header">+++ b/include/linux/mmzone.h</span>
<span class="p_chunk">@@ -672,6 +672,7 @@</span> <span class="p_context"> typedef struct pglist_data {</span>
 	 * is the first PFN that needs to be initialised.
 	 */
 	unsigned long first_deferred_pfn;
<span class="p_add">+	unsigned long static_init_size;</span>
 #endif /* CONFIG_DEFERRED_STRUCT_PAGE_INIT */
 
 #ifdef CONFIG_TRANSPARENT_HUGEPAGE
<span class="p_header">diff --git a/include/net/dst.h b/include/net/dst.h</span>
<span class="p_header">index 049af33da3b6..cfc043784166 100644</span>
<span class="p_header">--- a/include/net/dst.h</span>
<span class="p_header">+++ b/include/net/dst.h</span>
<span class="p_chunk">@@ -107,10 +107,16 @@</span> <span class="p_context"> struct dst_entry {</span>
 	};
 };
 
<span class="p_add">+struct dst_metrics {</span>
<span class="p_add">+	u32		metrics[RTAX_MAX];</span>
<span class="p_add">+	atomic_t	refcnt;</span>
<span class="p_add">+};</span>
<span class="p_add">+extern const struct dst_metrics dst_default_metrics;</span>
<span class="p_add">+</span>
 u32 *dst_cow_metrics_generic(struct dst_entry *dst, unsigned long old);
<span class="p_del">-extern const u32 dst_default_metrics[];</span>
 
 #define DST_METRICS_READ_ONLY		0x1UL
<span class="p_add">+#define DST_METRICS_REFCOUNTED		0x2UL</span>
 #define DST_METRICS_FLAGS		0x3UL
 #define __DST_METRICS_PTR(Y)	\
 	((u32 *)((Y) &amp; ~DST_METRICS_FLAGS))
<span class="p_header">diff --git a/include/net/ip_fib.h b/include/net/ip_fib.h</span>
<span class="p_header">index 368bb4024b78..892f8dccc835 100644</span>
<span class="p_header">--- a/include/net/ip_fib.h</span>
<span class="p_header">+++ b/include/net/ip_fib.h</span>
<span class="p_chunk">@@ -114,11 +114,11 @@</span> <span class="p_context"> struct fib_info {</span>
 	__be32			fib_prefsrc;
 	u32			fib_tb_id;
 	u32			fib_priority;
<span class="p_del">-	u32			*fib_metrics;</span>
<span class="p_del">-#define fib_mtu fib_metrics[RTAX_MTU-1]</span>
<span class="p_del">-#define fib_window fib_metrics[RTAX_WINDOW-1]</span>
<span class="p_del">-#define fib_rtt fib_metrics[RTAX_RTT-1]</span>
<span class="p_del">-#define fib_advmss fib_metrics[RTAX_ADVMSS-1]</span>
<span class="p_add">+	struct dst_metrics	*fib_metrics;</span>
<span class="p_add">+#define fib_mtu fib_metrics-&gt;metrics[RTAX_MTU-1]</span>
<span class="p_add">+#define fib_window fib_metrics-&gt;metrics[RTAX_WINDOW-1]</span>
<span class="p_add">+#define fib_rtt fib_metrics-&gt;metrics[RTAX_RTT-1]</span>
<span class="p_add">+#define fib_advmss fib_metrics-&gt;metrics[RTAX_ADVMSS-1]</span>
 	int			fib_nhs;
 #ifdef CONFIG_IP_ROUTE_MULTIPATH
 	int			fib_weight;
<span class="p_header">diff --git a/include/target/iscsi/iscsi_target_core.h b/include/target/iscsi/iscsi_target_core.h</span>
<span class="p_header">index 275581d483dd..5f17fb770477 100644</span>
<span class="p_header">--- a/include/target/iscsi/iscsi_target_core.h</span>
<span class="p_header">+++ b/include/target/iscsi/iscsi_target_core.h</span>
<span class="p_chunk">@@ -557,6 +557,7 @@</span> <span class="p_context"> struct iscsi_conn {</span>
 #define LOGIN_FLAGS_READ_ACTIVE		1
 #define LOGIN_FLAGS_CLOSED		2
 #define LOGIN_FLAGS_READY		4
<span class="p_add">+#define LOGIN_FLAGS_INITIAL_PDU		8</span>
 	unsigned long		login_flags;
 	struct delayed_work	login_work;
 	struct delayed_work	login_cleanup_work;
<span class="p_header">diff --git a/kernel/bpf/arraymap.c b/kernel/bpf/arraymap.c</span>
<span class="p_header">index 6b6f41f0b211..892f47c28377 100644</span>
<span class="p_header">--- a/kernel/bpf/arraymap.c</span>
<span class="p_header">+++ b/kernel/bpf/arraymap.c</span>
<span class="p_chunk">@@ -83,6 +83,7 @@</span> <span class="p_context"> static struct bpf_map *array_map_alloc(union bpf_attr *attr)</span>
 	array-&gt;map.key_size = attr-&gt;key_size;
 	array-&gt;map.value_size = attr-&gt;value_size;
 	array-&gt;map.max_entries = attr-&gt;max_entries;
<span class="p_add">+	array-&gt;map.map_flags = attr-&gt;map_flags;</span>
 	array-&gt;elem_size = elem_size;
 
 	if (!percpu)
<span class="p_header">diff --git a/kernel/bpf/lpm_trie.c b/kernel/bpf/lpm_trie.c</span>
<span class="p_header">index b37bd9ab7f57..7ab9e42180ab 100644</span>
<span class="p_header">--- a/kernel/bpf/lpm_trie.c</span>
<span class="p_header">+++ b/kernel/bpf/lpm_trie.c</span>
<span class="p_chunk">@@ -432,6 +432,7 @@</span> <span class="p_context"> static struct bpf_map *trie_alloc(union bpf_attr *attr)</span>
 	trie-&gt;map.key_size = attr-&gt;key_size;
 	trie-&gt;map.value_size = attr-&gt;value_size;
 	trie-&gt;map.max_entries = attr-&gt;max_entries;
<span class="p_add">+	trie-&gt;map.map_flags = attr-&gt;map_flags;</span>
 	trie-&gt;data_size = attr-&gt;key_size -
 			  offsetof(struct bpf_lpm_trie_key, data);
 	trie-&gt;max_prefixlen = trie-&gt;data_size * 8;
<span class="p_header">diff --git a/kernel/bpf/stackmap.c b/kernel/bpf/stackmap.c</span>
<span class="p_header">index 22aa45cd0324..96f604317685 100644</span>
<span class="p_header">--- a/kernel/bpf/stackmap.c</span>
<span class="p_header">+++ b/kernel/bpf/stackmap.c</span>
<span class="p_chunk">@@ -88,6 +88,7 @@</span> <span class="p_context"> static struct bpf_map *stack_map_alloc(union bpf_attr *attr)</span>
 	smap-&gt;map.key_size = attr-&gt;key_size;
 	smap-&gt;map.value_size = value_size;
 	smap-&gt;map.max_entries = attr-&gt;max_entries;
<span class="p_add">+	smap-&gt;map.map_flags = attr-&gt;map_flags;</span>
 	smap-&gt;n_buckets = n_buckets;
 	smap-&gt;map.pages = round_up(cost, PAGE_SIZE) &gt;&gt; PAGE_SHIFT;
 
<span class="p_header">diff --git a/kernel/bpf/verifier.c b/kernel/bpf/verifier.c</span>
<span class="p_header">index 6fd78d4c4164..904decd32783 100644</span>
<span class="p_header">--- a/kernel/bpf/verifier.c</span>
<span class="p_header">+++ b/kernel/bpf/verifier.c</span>
<span class="p_chunk">@@ -140,7 +140,7 @@</span> <span class="p_context"> struct bpf_verifier_stack_elem {</span>
 	struct bpf_verifier_stack_elem *next;
 };
 
<span class="p_del">-#define BPF_COMPLEXITY_LIMIT_INSNS	65536</span>
<span class="p_add">+#define BPF_COMPLEXITY_LIMIT_INSNS	98304</span>
 #define BPF_COMPLEXITY_LIMIT_STACK	1024
 
 struct bpf_call_arg_meta {
<span class="p_chunk">@@ -2546,6 +2546,7 @@</span> <span class="p_context"> static int check_cfg(struct bpf_verifier_env *env)</span>
 				env-&gt;explored_states[t + 1] = STATE_LIST_MARK;
 		} else {
 			/* conditional jump with two edges */
<span class="p_add">+			env-&gt;explored_states[t] = STATE_LIST_MARK;</span>
 			ret = push_insn(t, t + 1, FALLTHROUGH, env);
 			if (ret == 1)
 				goto peek_stack;
<span class="p_chunk">@@ -2704,6 +2705,12 @@</span> <span class="p_context"> static bool states_equal(struct bpf_verifier_env *env,</span>
 		     rcur-&gt;type != NOT_INIT))
 			continue;
 
<span class="p_add">+		/* Don&#39;t care about the reg-&gt;id in this case. */</span>
<span class="p_add">+		if (rold-&gt;type == PTR_TO_MAP_VALUE_OR_NULL &amp;&amp;</span>
<span class="p_add">+		    rcur-&gt;type == PTR_TO_MAP_VALUE_OR_NULL &amp;&amp;</span>
<span class="p_add">+		    rold-&gt;map_ptr == rcur-&gt;map_ptr)</span>
<span class="p_add">+			continue;</span>
<span class="p_add">+</span>
 		if (rold-&gt;type == PTR_TO_PACKET &amp;&amp; rcur-&gt;type == PTR_TO_PACKET &amp;&amp;
 		    compare_ptrs_to_packet(rold, rcur))
 			continue;
<span class="p_chunk">@@ -2838,6 +2845,9 @@</span> <span class="p_context"> static int do_check(struct bpf_verifier_env *env)</span>
 			goto process_bpf_exit;
 		}
 
<span class="p_add">+		if (need_resched())</span>
<span class="p_add">+			cond_resched();</span>
<span class="p_add">+</span>
 		if (log_level &amp;&amp; do_print_state) {
 			verbose(&quot;\nfrom %d to %d:&quot;, prev_insn_idx, insn_idx);
 			print_verifier_state(&amp;env-&gt;cur_state);
<span class="p_header">diff --git a/mm/gup.c b/mm/gup.c</span>
<span class="p_header">index 04aa405350dc..fb87cbf37e52 100644</span>
<span class="p_header">--- a/mm/gup.c</span>
<span class="p_header">+++ b/mm/gup.c</span>
<span class="p_chunk">@@ -407,12 +407,10 @@</span> <span class="p_context"> static int faultin_page(struct task_struct *tsk, struct vm_area_struct *vma,</span>
 
 	ret = handle_mm_fault(vma, address, fault_flags);
 	if (ret &amp; VM_FAULT_ERROR) {
<span class="p_del">-		if (ret &amp; VM_FAULT_OOM)</span>
<span class="p_del">-			return -ENOMEM;</span>
<span class="p_del">-		if (ret &amp; (VM_FAULT_HWPOISON | VM_FAULT_HWPOISON_LARGE))</span>
<span class="p_del">-			return *flags &amp; FOLL_HWPOISON ? -EHWPOISON : -EFAULT;</span>
<span class="p_del">-		if (ret &amp; (VM_FAULT_SIGBUS | VM_FAULT_SIGSEGV))</span>
<span class="p_del">-			return -EFAULT;</span>
<span class="p_add">+		int err = vm_fault_to_errno(ret, *flags);</span>
<span class="p_add">+</span>
<span class="p_add">+		if (err)</span>
<span class="p_add">+			return err;</span>
 		BUG();
 	}
 
<span class="p_chunk">@@ -723,12 +721,10 @@</span> <span class="p_context"> int fixup_user_fault(struct task_struct *tsk, struct mm_struct *mm,</span>
 	ret = handle_mm_fault(vma, address, fault_flags);
 	major |= ret &amp; VM_FAULT_MAJOR;
 	if (ret &amp; VM_FAULT_ERROR) {
<span class="p_del">-		if (ret &amp; VM_FAULT_OOM)</span>
<span class="p_del">-			return -ENOMEM;</span>
<span class="p_del">-		if (ret &amp; (VM_FAULT_HWPOISON | VM_FAULT_HWPOISON_LARGE))</span>
<span class="p_del">-			return -EHWPOISON;</span>
<span class="p_del">-		if (ret &amp; (VM_FAULT_SIGBUS | VM_FAULT_SIGSEGV))</span>
<span class="p_del">-			return -EFAULT;</span>
<span class="p_add">+		int err = vm_fault_to_errno(ret, 0);</span>
<span class="p_add">+</span>
<span class="p_add">+		if (err)</span>
<span class="p_add">+			return err;</span>
 		BUG();
 	}
 
<span class="p_header">diff --git a/mm/hugetlb.c b/mm/hugetlb.c</span>
<span class="p_header">index e5828875f7bb..3eedb187e549 100644</span>
<span class="p_header">--- a/mm/hugetlb.c</span>
<span class="p_header">+++ b/mm/hugetlb.c</span>
<span class="p_chunk">@@ -4170,6 +4170,11 @@</span> <span class="p_context"> long follow_hugetlb_page(struct mm_struct *mm, struct vm_area_struct *vma,</span>
 			}
 			ret = hugetlb_fault(mm, vma, vaddr, fault_flags);
 			if (ret &amp; VM_FAULT_ERROR) {
<span class="p_add">+				int err = vm_fault_to_errno(ret, flags);</span>
<span class="p_add">+</span>
<span class="p_add">+				if (err)</span>
<span class="p_add">+					return err;</span>
<span class="p_add">+</span>
 				remainder = 0;
 				break;
 			}
<span class="p_header">diff --git a/mm/ksm.c b/mm/ksm.c</span>
<span class="p_header">index 19b4f2dea7a5..11891ca81e40 100644</span>
<span class="p_header">--- a/mm/ksm.c</span>
<span class="p_header">+++ b/mm/ksm.c</span>
<span class="p_chunk">@@ -1028,8 +1028,7 @@</span> <span class="p_context"> static int try_to_merge_one_page(struct vm_area_struct *vma,</span>
 		goto out;
 
 	if (PageTransCompound(page)) {
<span class="p_del">-		err = split_huge_page(page);</span>
<span class="p_del">-		if (err)</span>
<span class="p_add">+		if (split_huge_page(page))</span>
 			goto out_unlock;
 	}
 
<span class="p_header">diff --git a/mm/memblock.c b/mm/memblock.c</span>
<span class="p_header">index 696f06d17c4e..a749101ed2a2 100644</span>
<span class="p_header">--- a/mm/memblock.c</span>
<span class="p_header">+++ b/mm/memblock.c</span>
<span class="p_chunk">@@ -1713,6 +1713,29 @@</span> <span class="p_context"> static void __init_memblock memblock_dump(struct memblock_type *type)</span>
 	}
 }
 
<span class="p_add">+extern unsigned long __init_memblock</span>
<span class="p_add">+memblock_reserved_memory_within(phys_addr_t start_addr, phys_addr_t end_addr)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct memblock_region *rgn;</span>
<span class="p_add">+	unsigned long size = 0;</span>
<span class="p_add">+	int idx;</span>
<span class="p_add">+</span>
<span class="p_add">+	for_each_memblock_type((&amp;memblock.reserved), rgn) {</span>
<span class="p_add">+		phys_addr_t start, end;</span>
<span class="p_add">+</span>
<span class="p_add">+		if (rgn-&gt;base + rgn-&gt;size &lt; start_addr)</span>
<span class="p_add">+			continue;</span>
<span class="p_add">+		if (rgn-&gt;base &gt; end_addr)</span>
<span class="p_add">+			continue;</span>
<span class="p_add">+</span>
<span class="p_add">+		start = rgn-&gt;base;</span>
<span class="p_add">+		end = start + rgn-&gt;size;</span>
<span class="p_add">+		size += end - start;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	return size;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 void __init_memblock __memblock_dump_all(void)
 {
 	pr_info(&quot;MEMBLOCK configuration:\n&quot;);
<span class="p_header">diff --git a/mm/memory-failure.c b/mm/memory-failure.c</span>
<span class="p_header">index 27f7210e7fab..d7780dfdf541 100644</span>
<span class="p_header">--- a/mm/memory-failure.c</span>
<span class="p_header">+++ b/mm/memory-failure.c</span>
<span class="p_chunk">@@ -1587,12 +1587,8 @@</span> <span class="p_context"> static int soft_offline_huge_page(struct page *page, int flags)</span>
 	if (ret) {
 		pr_info(&quot;soft offline: %#lx: migration failed %d, type %lx\n&quot;,
 			pfn, ret, page-&gt;flags);
<span class="p_del">-		/*</span>
<span class="p_del">-		 * We know that soft_offline_huge_page() tries to migrate</span>
<span class="p_del">-		 * only one hugepage pointed to by hpage, so we need not</span>
<span class="p_del">-		 * run through the pagelist here.</span>
<span class="p_del">-		 */</span>
<span class="p_del">-		putback_active_hugepage(hpage);</span>
<span class="p_add">+		if (!list_empty(&amp;pagelist))</span>
<span class="p_add">+			putback_movable_pages(&amp;pagelist);</span>
 		if (ret &gt; 0)
 			ret = -EIO;
 	} else {
<span class="p_header">diff --git a/mm/memory.c b/mm/memory.c</span>
<span class="p_header">index 235ba51b2fbf..2437dc08ab36 100644</span>
<span class="p_header">--- a/mm/memory.c</span>
<span class="p_header">+++ b/mm/memory.c</span>
<span class="p_chunk">@@ -3029,6 +3029,17 @@</span> <span class="p_context"> static int __do_fault(struct vm_fault *vmf)</span>
 	return ret;
 }
 
<span class="p_add">+/*</span>
<span class="p_add">+ * The ordering of these checks is important for pmds with _PAGE_DEVMAP set.</span>
<span class="p_add">+ * If we check pmd_trans_unstable() first we will trip the bad_pmd() check</span>
<span class="p_add">+ * inside of pmd_none_or_trans_huge_or_clear_bad(). This will end up correctly</span>
<span class="p_add">+ * returning 1 but not before it spams dmesg with the pmd_clear_bad() output.</span>
<span class="p_add">+ */</span>
<span class="p_add">+static int pmd_devmap_trans_unstable(pmd_t *pmd)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return pmd_devmap(*pmd) || pmd_trans_unstable(pmd);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static int pte_alloc_one_map(struct vm_fault *vmf)
 {
 	struct vm_area_struct *vma = vmf-&gt;vma;
<span class="p_chunk">@@ -3052,18 +3063,27 @@</span> <span class="p_context"> static int pte_alloc_one_map(struct vm_fault *vmf)</span>
 map_pte:
 	/*
 	 * If a huge pmd materialized under us just retry later.  Use
<span class="p_del">-	 * pmd_trans_unstable() instead of pmd_trans_huge() to ensure the pmd</span>
<span class="p_del">-	 * didn&#39;t become pmd_trans_huge under us and then back to pmd_none, as</span>
<span class="p_del">-	 * a result of MADV_DONTNEED running immediately after a huge pmd fault</span>
<span class="p_del">-	 * in a different thread of this mm, in turn leading to a misleading</span>
<span class="p_del">-	 * pmd_trans_huge() retval.  All we have to ensure is that it is a</span>
<span class="p_del">-	 * regular pmd that we can walk with pte_offset_map() and we can do that</span>
<span class="p_del">-	 * through an atomic read in C, which is what pmd_trans_unstable()</span>
<span class="p_del">-	 * provides.</span>
<span class="p_add">+	 * pmd_trans_unstable() via pmd_devmap_trans_unstable() instead of</span>
<span class="p_add">+	 * pmd_trans_huge() to ensure the pmd didn&#39;t become pmd_trans_huge</span>
<span class="p_add">+	 * under us and then back to pmd_none, as a result of MADV_DONTNEED</span>
<span class="p_add">+	 * running immediately after a huge pmd fault in a different thread of</span>
<span class="p_add">+	 * this mm, in turn leading to a misleading pmd_trans_huge() retval.</span>
<span class="p_add">+	 * All we have to ensure is that it is a regular pmd that we can walk</span>
<span class="p_add">+	 * with pte_offset_map() and we can do that through an atomic read in</span>
<span class="p_add">+	 * C, which is what pmd_trans_unstable() provides.</span>
 	 */
<span class="p_del">-	if (pmd_trans_unstable(vmf-&gt;pmd) || pmd_devmap(*vmf-&gt;pmd))</span>
<span class="p_add">+	if (pmd_devmap_trans_unstable(vmf-&gt;pmd))</span>
 		return VM_FAULT_NOPAGE;
 
<span class="p_add">+	/*</span>
<span class="p_add">+	 * At this point we know that our vmf-&gt;pmd points to a page of ptes</span>
<span class="p_add">+	 * and it cannot become pmd_none(), pmd_devmap() or pmd_trans_huge()</span>
<span class="p_add">+	 * for the duration of the fault.  If a racing MADV_DONTNEED runs and</span>
<span class="p_add">+	 * we zap the ptes pointed to by our vmf-&gt;pmd, the vmf-&gt;ptl will still</span>
<span class="p_add">+	 * be valid and we will re-check to make sure the vmf-&gt;pte isn&#39;t</span>
<span class="p_add">+	 * pte_none() under vmf-&gt;ptl protection when we return to</span>
<span class="p_add">+	 * alloc_set_pte().</span>
<span class="p_add">+	 */</span>
 	vmf-&gt;pte = pte_offset_map_lock(vma-&gt;vm_mm, vmf-&gt;pmd, vmf-&gt;address,
 			&amp;vmf-&gt;ptl);
 	return 0;
<span class="p_chunk">@@ -3690,7 +3710,7 @@</span> <span class="p_context"> static int handle_pte_fault(struct vm_fault *vmf)</span>
 		vmf-&gt;pte = NULL;
 	} else {
 		/* See comment in pte_alloc_one_map() */
<span class="p_del">-		if (pmd_trans_unstable(vmf-&gt;pmd) || pmd_devmap(*vmf-&gt;pmd))</span>
<span class="p_add">+		if (pmd_devmap_trans_unstable(vmf-&gt;pmd))</span>
 			return 0;
 		/*
 		 * A regular pmd is established and it can&#39;t morph into a huge
<span class="p_header">diff --git a/mm/mlock.c b/mm/mlock.c</span>
<span class="p_header">index 0dd9ca18e19e..721679a2c1aa 100644</span>
<span class="p_header">--- a/mm/mlock.c</span>
<span class="p_header">+++ b/mm/mlock.c</span>
<span class="p_chunk">@@ -286,7 +286,7 @@</span> <span class="p_context"> static void __munlock_pagevec(struct pagevec *pvec, struct zone *zone)</span>
 {
 	int i;
 	int nr = pagevec_count(pvec);
<span class="p_del">-	int delta_munlocked;</span>
<span class="p_add">+	int delta_munlocked = -nr;</span>
 	struct pagevec pvec_putback;
 	int pgrescued = 0;
 
<span class="p_chunk">@@ -306,6 +306,8 @@</span> <span class="p_context"> static void __munlock_pagevec(struct pagevec *pvec, struct zone *zone)</span>
 				continue;
 			else
 				__munlock_isolation_failed(page);
<span class="p_add">+		} else {</span>
<span class="p_add">+			delta_munlocked++;</span>
 		}
 
 		/*
<span class="p_chunk">@@ -317,7 +319,6 @@</span> <span class="p_context"> static void __munlock_pagevec(struct pagevec *pvec, struct zone *zone)</span>
 		pagevec_add(&amp;pvec_putback, pvec-&gt;pages[i]);
 		pvec-&gt;pages[i] = NULL;
 	}
<span class="p_del">-	delta_munlocked = -nr + pagevec_count(&amp;pvec_putback);</span>
 	__mod_zone_page_state(zone, NR_MLOCK, delta_munlocked);
 	spin_unlock_irq(zone_lru_lock(zone));
 
<span class="p_header">diff --git a/mm/page_alloc.c b/mm/page_alloc.c</span>
<span class="p_header">index c5fee5a0316d..a2019fc9d94d 100644</span>
<span class="p_header">--- a/mm/page_alloc.c</span>
<span class="p_header">+++ b/mm/page_alloc.c</span>
<span class="p_chunk">@@ -291,6 +291,26 @@</span> <span class="p_context"> int page_group_by_mobility_disabled __read_mostly;</span>
 #ifdef CONFIG_DEFERRED_STRUCT_PAGE_INIT
 static inline void reset_deferred_meminit(pg_data_t *pgdat)
 {
<span class="p_add">+	unsigned long max_initialise;</span>
<span class="p_add">+	unsigned long reserved_lowmem;</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Initialise at least 2G of a node but also take into account that</span>
<span class="p_add">+	 * two large system hashes that can take up 1GB for 0.25TB/node.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	max_initialise = max(2UL &lt;&lt; (30 - PAGE_SHIFT),</span>
<span class="p_add">+		(pgdat-&gt;node_spanned_pages &gt;&gt; 8));</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Compensate the all the memblock reservations (e.g. crash kernel)</span>
<span class="p_add">+	 * from the initial estimation to make sure we will initialize enough</span>
<span class="p_add">+	 * memory to boot.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	reserved_lowmem = memblock_reserved_memory_within(pgdat-&gt;node_start_pfn,</span>
<span class="p_add">+			pgdat-&gt;node_start_pfn + max_initialise);</span>
<span class="p_add">+	max_initialise += reserved_lowmem;</span>
<span class="p_add">+</span>
<span class="p_add">+	pgdat-&gt;static_init_size = min(max_initialise, pgdat-&gt;node_spanned_pages);</span>
 	pgdat-&gt;first_deferred_pfn = ULONG_MAX;
 }
 
<span class="p_chunk">@@ -313,20 +333,11 @@</span> <span class="p_context"> static inline bool update_defer_init(pg_data_t *pgdat,</span>
 				unsigned long pfn, unsigned long zone_end,
 				unsigned long *nr_initialised)
 {
<span class="p_del">-	unsigned long max_initialise;</span>
<span class="p_del">-</span>
 	/* Always populate low zones for address-contrained allocations */
 	if (zone_end &lt; pgdat_end_pfn(pgdat))
 		return true;
<span class="p_del">-	/*</span>
<span class="p_del">-	 * Initialise at least 2G of a node but also take into account that</span>
<span class="p_del">-	 * two large system hashes that can take up 1GB for 0.25TB/node.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	max_initialise = max(2UL &lt;&lt; (30 - PAGE_SHIFT),</span>
<span class="p_del">-		(pgdat-&gt;node_spanned_pages &gt;&gt; 8));</span>
<span class="p_del">-</span>
 	(*nr_initialised)++;
<span class="p_del">-	if ((*nr_initialised &gt; max_initialise) &amp;&amp;</span>
<span class="p_add">+	if ((*nr_initialised &gt; pgdat-&gt;static_init_size) &amp;&amp;</span>
 	    (pfn &amp; (PAGES_PER_SECTION - 1)) == 0) {
 		pgdat-&gt;first_deferred_pfn = pfn;
 		return false;
<span class="p_chunk">@@ -3834,7 +3845,9 @@</span> <span class="p_context"> __alloc_pages_slowpath(gfp_t gfp_mask, unsigned int order,</span>
 		goto got_pg;
 
 	/* Avoid allocations with no watermarks from looping endlessly */
<span class="p_del">-	if (test_thread_flag(TIF_MEMDIE))</span>
<span class="p_add">+	if (test_thread_flag(TIF_MEMDIE) &amp;&amp;</span>
<span class="p_add">+	    (alloc_flags == ALLOC_NO_WATERMARKS ||</span>
<span class="p_add">+	     (gfp_mask &amp; __GFP_NOMEMALLOC)))</span>
 		goto nopage;
 
 	/* Retry as long as the OOM killer is making progress */
<span class="p_chunk">@@ -6098,7 +6111,6 @@</span> <span class="p_context"> void __paginginit free_area_init_node(int nid, unsigned long *zones_size,</span>
 	/* pg_data_t should be reset to zero when it&#39;s allocated */
 	WARN_ON(pgdat-&gt;nr_zones || pgdat-&gt;kswapd_classzone_idx);
 
<span class="p_del">-	reset_deferred_meminit(pgdat);</span>
 	pgdat-&gt;node_id = nid;
 	pgdat-&gt;node_start_pfn = node_start_pfn;
 	pgdat-&gt;per_cpu_nodestats = NULL;
<span class="p_chunk">@@ -6120,6 +6132,7 @@</span> <span class="p_context"> void __paginginit free_area_init_node(int nid, unsigned long *zones_size,</span>
 		(unsigned long)pgdat-&gt;node_mem_map);
 #endif
 
<span class="p_add">+	reset_deferred_meminit(pgdat);</span>
 	free_area_init_core(pgdat);
 }
 
<span class="p_header">diff --git a/mm/slub.c b/mm/slub.c</span>
<span class="p_header">index 7f4bc7027ed5..e3863a22e10d 100644</span>
<span class="p_header">--- a/mm/slub.c</span>
<span class="p_header">+++ b/mm/slub.c</span>
<span class="p_chunk">@@ -5512,6 +5512,7 @@</span> <span class="p_context"> static void memcg_propagate_slab_attrs(struct kmem_cache *s)</span>
 		char mbuf[64];
 		char *buf;
 		struct slab_attribute *attr = to_slab_attr(slab_attrs[i]);
<span class="p_add">+		ssize_t len;</span>
 
 		if (!attr || !attr-&gt;store || !attr-&gt;show)
 			continue;
<span class="p_chunk">@@ -5536,8 +5537,9 @@</span> <span class="p_context"> static void memcg_propagate_slab_attrs(struct kmem_cache *s)</span>
 			buf = buffer;
 		}
 
<span class="p_del">-		attr-&gt;show(root_cache, buf);</span>
<span class="p_del">-		attr-&gt;store(s, buf, strlen(buf));</span>
<span class="p_add">+		len = attr-&gt;show(root_cache, buf);</span>
<span class="p_add">+		if (len &gt; 0)</span>
<span class="p_add">+			attr-&gt;store(s, buf, len);</span>
 	}
 
 	if (buffer)
<span class="p_header">diff --git a/net/bridge/br_netlink.c b/net/bridge/br_netlink.c</span>
<span class="p_header">index 225ef7d53701..0488c6735c46 100644</span>
<span class="p_header">--- a/net/bridge/br_netlink.c</span>
<span class="p_header">+++ b/net/bridge/br_netlink.c</span>
<span class="p_chunk">@@ -828,6 +828,13 @@</span> <span class="p_context"> static int br_validate(struct nlattr *tb[], struct nlattr *data[])</span>
 			return -EPROTONOSUPPORT;
 		}
 	}
<span class="p_add">+</span>
<span class="p_add">+	if (data[IFLA_BR_VLAN_DEFAULT_PVID]) {</span>
<span class="p_add">+		__u16 defpvid = nla_get_u16(data[IFLA_BR_VLAN_DEFAULT_PVID]);</span>
<span class="p_add">+</span>
<span class="p_add">+		if (defpvid &gt;= VLAN_VID_MASK)</span>
<span class="p_add">+			return -EINVAL;</span>
<span class="p_add">+	}</span>
 #endif
 
 	return 0;
<span class="p_header">diff --git a/net/bridge/br_stp_if.c b/net/bridge/br_stp_if.c</span>
<span class="p_header">index 08341d2aa9c9..0db8102995a5 100644</span>
<span class="p_header">--- a/net/bridge/br_stp_if.c</span>
<span class="p_header">+++ b/net/bridge/br_stp_if.c</span>
<span class="p_chunk">@@ -179,6 +179,7 @@</span> <span class="p_context"> static void br_stp_start(struct net_bridge *br)</span>
 		br_debug(br, &quot;using kernel STP\n&quot;);
 
 		/* To start timers on any ports left in blocking */
<span class="p_add">+		mod_timer(&amp;br-&gt;hello_timer, jiffies + br-&gt;hello_time);</span>
 		br_port_state_selection(br);
 	}
 
<span class="p_header">diff --git a/net/bridge/br_stp_timer.c b/net/bridge/br_stp_timer.c</span>
<span class="p_header">index c98b3e5c140a..60b6fe277a8b 100644</span>
<span class="p_header">--- a/net/bridge/br_stp_timer.c</span>
<span class="p_header">+++ b/net/bridge/br_stp_timer.c</span>
<span class="p_chunk">@@ -40,7 +40,7 @@</span> <span class="p_context"> static void br_hello_timer_expired(unsigned long arg)</span>
 	if (br-&gt;dev-&gt;flags &amp; IFF_UP) {
 		br_config_bpdu_generation(br);
 
<span class="p_del">-		if (br-&gt;stp_enabled != BR_USER_STP)</span>
<span class="p_add">+		if (br-&gt;stp_enabled == BR_KERNEL_STP)</span>
 			mod_timer(&amp;br-&gt;hello_timer,
 				  round_jiffies(jiffies + br-&gt;hello_time));
 	}
<span class="p_header">diff --git a/net/core/dst.c b/net/core/dst.c</span>
<span class="p_header">index 960e503b5a52..6192f11beec9 100644</span>
<span class="p_header">--- a/net/core/dst.c</span>
<span class="p_header">+++ b/net/core/dst.c</span>
<span class="p_chunk">@@ -151,13 +151,13 @@</span> <span class="p_context"> int dst_discard_out(struct net *net, struct sock *sk, struct sk_buff *skb)</span>
 }
 EXPORT_SYMBOL(dst_discard_out);
 
<span class="p_del">-const u32 dst_default_metrics[RTAX_MAX + 1] = {</span>
<span class="p_add">+const struct dst_metrics dst_default_metrics = {</span>
 	/* This initializer is needed to force linker to place this variable
 	 * into const section. Otherwise it might end into bss section.
 	 * We really want to avoid false sharing on this variable, and catch
 	 * any writes on it.
 	 */
<span class="p_del">-	[RTAX_MAX] = 0xdeadbeef,</span>
<span class="p_add">+	.refcnt = ATOMIC_INIT(1),</span>
 };
 
 void dst_init(struct dst_entry *dst, struct dst_ops *ops,
<span class="p_chunk">@@ -169,7 +169,7 @@</span> <span class="p_context"> void dst_init(struct dst_entry *dst, struct dst_ops *ops,</span>
 	if (dev)
 		dev_hold(dev);
 	dst-&gt;ops = ops;
<span class="p_del">-	dst_init_metrics(dst, dst_default_metrics, true);</span>
<span class="p_add">+	dst_init_metrics(dst, dst_default_metrics.metrics, true);</span>
 	dst-&gt;expires = 0UL;
 	dst-&gt;path = dst;
 	dst-&gt;from = NULL;
<span class="p_chunk">@@ -314,25 +314,30 @@</span> <span class="p_context"> EXPORT_SYMBOL(dst_release);</span>
 
 u32 *dst_cow_metrics_generic(struct dst_entry *dst, unsigned long old)
 {
<span class="p_del">-	u32 *p = kmalloc(sizeof(u32) * RTAX_MAX, GFP_ATOMIC);</span>
<span class="p_add">+	struct dst_metrics *p = kmalloc(sizeof(*p), GFP_ATOMIC);</span>
 
 	if (p) {
<span class="p_del">-		u32 *old_p = __DST_METRICS_PTR(old);</span>
<span class="p_add">+		struct dst_metrics *old_p = (struct dst_metrics *)__DST_METRICS_PTR(old);</span>
 		unsigned long prev, new;
 
<span class="p_del">-		memcpy(p, old_p, sizeof(u32) * RTAX_MAX);</span>
<span class="p_add">+		atomic_set(&amp;p-&gt;refcnt, 1);</span>
<span class="p_add">+		memcpy(p-&gt;metrics, old_p-&gt;metrics, sizeof(p-&gt;metrics));</span>
 
 		new = (unsigned long) p;
 		prev = cmpxchg(&amp;dst-&gt;_metrics, old, new);
 
 		if (prev != old) {
 			kfree(p);
<span class="p_del">-			p = __DST_METRICS_PTR(prev);</span>
<span class="p_add">+			p = (struct dst_metrics *)__DST_METRICS_PTR(prev);</span>
 			if (prev &amp; DST_METRICS_READ_ONLY)
 				p = NULL;
<span class="p_add">+		} else if (prev &amp; DST_METRICS_REFCOUNTED) {</span>
<span class="p_add">+			if (atomic_dec_and_test(&amp;old_p-&gt;refcnt))</span>
<span class="p_add">+				kfree(old_p);</span>
 		}
 	}
<span class="p_del">-	return p;</span>
<span class="p_add">+	BUILD_BUG_ON(offsetof(struct dst_metrics, metrics) != 0);</span>
<span class="p_add">+	return (u32 *)p;</span>
 }
 EXPORT_SYMBOL(dst_cow_metrics_generic);
 
<span class="p_chunk">@@ -341,7 +346,7 @@</span> <span class="p_context"> void __dst_destroy_metrics_generic(struct dst_entry *dst, unsigned long old)</span>
 {
 	unsigned long prev, new;
 
<span class="p_del">-	new = ((unsigned long) dst_default_metrics) | DST_METRICS_READ_ONLY;</span>
<span class="p_add">+	new = ((unsigned long) &amp;dst_default_metrics) | DST_METRICS_READ_ONLY;</span>
 	prev = cmpxchg(&amp;dst-&gt;_metrics, old, new);
 	if (prev == old)
 		kfree(__DST_METRICS_PTR(old));
<span class="p_header">diff --git a/net/core/filter.c b/net/core/filter.c</span>
<span class="p_header">index ebaeaf2e46e8..6ca3b05eb627 100644</span>
<span class="p_header">--- a/net/core/filter.c</span>
<span class="p_header">+++ b/net/core/filter.c</span>
<span class="p_chunk">@@ -2266,6 +2266,7 @@</span> <span class="p_context"> bool bpf_helper_changes_pkt_data(void *func)</span>
 	    func == bpf_skb_change_head ||
 	    func == bpf_skb_change_tail ||
 	    func == bpf_skb_pull_data ||
<span class="p_add">+	    func == bpf_clone_redirect ||</span>
 	    func == bpf_l3_csum_replace ||
 	    func == bpf_l4_csum_replace ||
 	    func == bpf_xdp_adjust_head)
<span class="p_header">diff --git a/net/core/rtnetlink.c b/net/core/rtnetlink.c</span>
<span class="p_header">index 69daf393cbe1..8d4a185a8143 100644</span>
<span class="p_header">--- a/net/core/rtnetlink.c</span>
<span class="p_header">+++ b/net/core/rtnetlink.c</span>
<span class="p_chunk">@@ -1620,13 +1620,13 @@</span> <span class="p_context"> static int rtnl_dump_ifinfo(struct sk_buff *skb, struct netlink_callback *cb)</span>
 					       cb-&gt;nlh-&gt;nlmsg_seq, 0,
 					       flags,
 					       ext_filter_mask);
<span class="p_del">-			/* If we ran out of room on the first message,</span>
<span class="p_del">-			 * we&#39;re in trouble</span>
<span class="p_del">-			 */</span>
<span class="p_del">-			WARN_ON((err == -EMSGSIZE) &amp;&amp; (skb-&gt;len == 0));</span>
 
<span class="p_del">-			if (err &lt; 0)</span>
<span class="p_del">-				goto out;</span>
<span class="p_add">+			if (err &lt; 0) {</span>
<span class="p_add">+				if (likely(skb-&gt;len))</span>
<span class="p_add">+					goto out;</span>
<span class="p_add">+</span>
<span class="p_add">+				goto out_err;</span>
<span class="p_add">+			}</span>
 
 			nl_dump_check_consistent(cb, nlmsg_hdr(skb));
 cont:
<span class="p_chunk">@@ -1634,10 +1634,12 @@</span> <span class="p_context"> static int rtnl_dump_ifinfo(struct sk_buff *skb, struct netlink_callback *cb)</span>
 		}
 	}
 out:
<span class="p_add">+	err = skb-&gt;len;</span>
<span class="p_add">+out_err:</span>
 	cb-&gt;args[1] = idx;
 	cb-&gt;args[0] = h;
 
<span class="p_del">-	return skb-&gt;len;</span>
<span class="p_add">+	return err;</span>
 }
 
 int rtnl_nla_parse_ifla(struct nlattr **tb, const struct nlattr *head, int len)
<span class="p_chunk">@@ -3427,8 +3429,12 @@</span> <span class="p_context"> static int rtnl_bridge_getlink(struct sk_buff *skb, struct netlink_callback *cb)</span>
 				err = br_dev-&gt;netdev_ops-&gt;ndo_bridge_getlink(
 						skb, portid, seq, dev,
 						filter_mask, NLM_F_MULTI);
<span class="p_del">-				if (err &lt; 0 &amp;&amp; err != -EOPNOTSUPP)</span>
<span class="p_del">-					break;</span>
<span class="p_add">+				if (err &lt; 0 &amp;&amp; err != -EOPNOTSUPP) {</span>
<span class="p_add">+					if (likely(skb-&gt;len))</span>
<span class="p_add">+						break;</span>
<span class="p_add">+</span>
<span class="p_add">+					goto out_err;</span>
<span class="p_add">+				}</span>
 			}
 			idx++;
 		}
<span class="p_chunk">@@ -3439,16 +3445,22 @@</span> <span class="p_context"> static int rtnl_bridge_getlink(struct sk_buff *skb, struct netlink_callback *cb)</span>
 							      seq, dev,
 							      filter_mask,
 							      NLM_F_MULTI);
<span class="p_del">-				if (err &lt; 0 &amp;&amp; err != -EOPNOTSUPP)</span>
<span class="p_del">-					break;</span>
<span class="p_add">+				if (err &lt; 0 &amp;&amp; err != -EOPNOTSUPP) {</span>
<span class="p_add">+					if (likely(skb-&gt;len))</span>
<span class="p_add">+						break;</span>
<span class="p_add">+</span>
<span class="p_add">+					goto out_err;</span>
<span class="p_add">+				}</span>
 			}
 			idx++;
 		}
 	}
<span class="p_add">+	err = skb-&gt;len;</span>
<span class="p_add">+out_err:</span>
 	rcu_read_unlock();
 	cb-&gt;args[0] = idx;
 
<span class="p_del">-	return skb-&gt;len;</span>
<span class="p_add">+	return err;</span>
 }
 
 static inline size_t bridge_nlmsg_size(void)
<span class="p_header">diff --git a/net/core/sock.c b/net/core/sock.c</span>
<span class="p_header">index 2c4f574168fb..59edc0e8c71a 100644</span>
<span class="p_header">--- a/net/core/sock.c</span>
<span class="p_header">+++ b/net/core/sock.c</span>
<span class="p_chunk">@@ -138,10 +138,7 @@</span> <span class="p_context"></span>
 
 #include &lt;trace/events/sock.h&gt;
 
<span class="p_del">-#ifdef CONFIG_INET</span>
 #include &lt;net/tcp.h&gt;
<span class="p_del">-#endif</span>
<span class="p_del">-</span>
 #include &lt;net/busy_poll.h&gt;
 
 static DEFINE_MUTEX(proto_list_mutex);
<span class="p_chunk">@@ -1699,28 +1696,24 @@</span> <span class="p_context"> EXPORT_SYMBOL(skb_set_owner_w);</span>
  * delay queue. We want to allow the owner socket to send more
  * packets, as if they were already TX completed by a typical driver.
  * But we also want to keep skb-&gt;sk set because some packet schedulers
<span class="p_del">- * rely on it (sch_fq for example). So we set skb-&gt;truesize to a small</span>
<span class="p_del">- * amount (1) and decrease sk_wmem_alloc accordingly.</span>
<span class="p_add">+ * rely on it (sch_fq for example).</span>
  */
 void skb_orphan_partial(struct sk_buff *skb)
 {
<span class="p_del">-	/* If this skb is a TCP pure ACK or already went here,</span>
<span class="p_del">-	 * we have nothing to do. 2 is already a very small truesize.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	if (skb-&gt;truesize &lt;= 2)</span>
<span class="p_add">+	if (skb_is_tcp_pure_ack(skb))</span>
 		return;
 
<span class="p_del">-	/* TCP stack sets skb-&gt;ooo_okay based on sk_wmem_alloc,</span>
<span class="p_del">-	 * so we do not completely orphan skb, but transfert all</span>
<span class="p_del">-	 * accounted bytes but one, to avoid unexpected reorders.</span>
<span class="p_del">-	 */</span>
 	if (skb-&gt;destructor == sock_wfree
 #ifdef CONFIG_INET
 	    || skb-&gt;destructor == tcp_wfree
 #endif
 		) {
<span class="p_del">-		atomic_sub(skb-&gt;truesize - 1, &amp;skb-&gt;sk-&gt;sk_wmem_alloc);</span>
<span class="p_del">-		skb-&gt;truesize = 1;</span>
<span class="p_add">+		struct sock *sk = skb-&gt;sk;</span>
<span class="p_add">+</span>
<span class="p_add">+		if (atomic_inc_not_zero(&amp;sk-&gt;sk_refcnt)) {</span>
<span class="p_add">+			atomic_sub(skb-&gt;truesize, &amp;sk-&gt;sk_wmem_alloc);</span>
<span class="p_add">+			skb-&gt;destructor = sock_efree;</span>
<span class="p_add">+		}</span>
 	} else {
 		skb_orphan(skb);
 	}
<span class="p_header">diff --git a/net/dccp/ipv6.c b/net/dccp/ipv6.c</span>
<span class="p_header">index d9b6a4e403e7..b6bbb71e713e 100644</span>
<span class="p_header">--- a/net/dccp/ipv6.c</span>
<span class="p_header">+++ b/net/dccp/ipv6.c</span>
<span class="p_chunk">@@ -426,6 +426,9 @@</span> <span class="p_context"> static struct sock *dccp_v6_request_recv_sock(const struct sock *sk,</span>
 		newsk-&gt;sk_backlog_rcv = dccp_v4_do_rcv;
 		newnp-&gt;pktoptions  = NULL;
 		newnp-&gt;opt	   = NULL;
<span class="p_add">+		newnp-&gt;ipv6_mc_list = NULL;</span>
<span class="p_add">+		newnp-&gt;ipv6_ac_list = NULL;</span>
<span class="p_add">+		newnp-&gt;ipv6_fl_list = NULL;</span>
 		newnp-&gt;mcast_oif   = inet6_iif(skb);
 		newnp-&gt;mcast_hops  = ipv6_hdr(skb)-&gt;hop_limit;
 
<span class="p_chunk">@@ -490,6 +493,9 @@</span> <span class="p_context"> static struct sock *dccp_v6_request_recv_sock(const struct sock *sk,</span>
 	/* Clone RX bits */
 	newnp-&gt;rxopt.all = np-&gt;rxopt.all;
 
<span class="p_add">+	newnp-&gt;ipv6_mc_list = NULL;</span>
<span class="p_add">+	newnp-&gt;ipv6_ac_list = NULL;</span>
<span class="p_add">+	newnp-&gt;ipv6_fl_list = NULL;</span>
 	newnp-&gt;pktoptions = NULL;
 	newnp-&gt;opt	  = NULL;
 	newnp-&gt;mcast_oif  = inet6_iif(skb);
<span class="p_header">diff --git a/net/ipv4/fib_frontend.c b/net/ipv4/fib_frontend.c</span>
<span class="p_header">index 8f2133ffc2ff..a2f7de26670e 100644</span>
<span class="p_header">--- a/net/ipv4/fib_frontend.c</span>
<span class="p_header">+++ b/net/ipv4/fib_frontend.c</span>
<span class="p_chunk">@@ -760,7 +760,7 @@</span> <span class="p_context"> static int inet_dump_fib(struct sk_buff *skb, struct netlink_callback *cb)</span>
 	unsigned int e = 0, s_e;
 	struct fib_table *tb;
 	struct hlist_head *head;
<span class="p_del">-	int dumped = 0;</span>
<span class="p_add">+	int dumped = 0, err;</span>
 
 	if (nlmsg_len(cb-&gt;nlh) &gt;= sizeof(struct rtmsg) &amp;&amp;
 	    ((struct rtmsg *) nlmsg_data(cb-&gt;nlh))-&gt;rtm_flags &amp; RTM_F_CLONED)
<span class="p_chunk">@@ -780,20 +780,27 @@</span> <span class="p_context"> static int inet_dump_fib(struct sk_buff *skb, struct netlink_callback *cb)</span>
 			if (dumped)
 				memset(&amp;cb-&gt;args[2], 0, sizeof(cb-&gt;args) -
 						 2 * sizeof(cb-&gt;args[0]));
<span class="p_del">-			if (fib_table_dump(tb, skb, cb) &lt; 0)</span>
<span class="p_del">-				goto out;</span>
<span class="p_add">+			err = fib_table_dump(tb, skb, cb);</span>
<span class="p_add">+			if (err &lt; 0) {</span>
<span class="p_add">+				if (likely(skb-&gt;len))</span>
<span class="p_add">+					goto out;</span>
<span class="p_add">+</span>
<span class="p_add">+				goto out_err;</span>
<span class="p_add">+			}</span>
 			dumped = 1;
 next:
 			e++;
 		}
 	}
 out:
<span class="p_add">+	err = skb-&gt;len;</span>
<span class="p_add">+out_err:</span>
 	rcu_read_unlock();
 
 	cb-&gt;args[1] = e;
 	cb-&gt;args[0] = h;
 
<span class="p_del">-	return skb-&gt;len;</span>
<span class="p_add">+	return err;</span>
 }
 
 /* Prepare and feed intra-kernel routing request.
<span class="p_header">diff --git a/net/ipv4/fib_semantics.c b/net/ipv4/fib_semantics.c</span>
<span class="p_header">index 317026a39cfa..6cf74de06467 100644</span>
<span class="p_header">--- a/net/ipv4/fib_semantics.c</span>
<span class="p_header">+++ b/net/ipv4/fib_semantics.c</span>
<span class="p_chunk">@@ -204,6 +204,7 @@</span> <span class="p_context"> static void rt_fibinfo_free_cpus(struct rtable __rcu * __percpu *rtp)</span>
 static void free_fib_info_rcu(struct rcu_head *head)
 {
 	struct fib_info *fi = container_of(head, struct fib_info, rcu);
<span class="p_add">+	struct dst_metrics *m;</span>
 
 	change_nexthops(fi) {
 		if (nexthop_nh-&gt;nh_dev)
<span class="p_chunk">@@ -214,8 +215,9 @@</span> <span class="p_context"> static void free_fib_info_rcu(struct rcu_head *head)</span>
 		rt_fibinfo_free(&amp;nexthop_nh-&gt;nh_rth_input);
 	} endfor_nexthops(fi);
 
<span class="p_del">-	if (fi-&gt;fib_metrics != (u32 *) dst_default_metrics)</span>
<span class="p_del">-		kfree(fi-&gt;fib_metrics);</span>
<span class="p_add">+	m = fi-&gt;fib_metrics;</span>
<span class="p_add">+	if (m != &amp;dst_default_metrics &amp;&amp; atomic_dec_and_test(&amp;m-&gt;refcnt))</span>
<span class="p_add">+		kfree(m);</span>
 	kfree(fi);
 }
 
<span class="p_chunk">@@ -975,11 +977,11 @@</span> <span class="p_context"> fib_convert_metrics(struct fib_info *fi, const struct fib_config *cfg)</span>
 			val = 255;
 		if (type == RTAX_FEATURES &amp;&amp; (val &amp; ~RTAX_FEATURE_MASK))
 			return -EINVAL;
<span class="p_del">-		fi-&gt;fib_metrics[type - 1] = val;</span>
<span class="p_add">+		fi-&gt;fib_metrics-&gt;metrics[type - 1] = val;</span>
 	}
 
 	if (ecn_ca)
<span class="p_del">-		fi-&gt;fib_metrics[RTAX_FEATURES - 1] |= DST_FEATURE_ECN_CA;</span>
<span class="p_add">+		fi-&gt;fib_metrics-&gt;metrics[RTAX_FEATURES - 1] |= DST_FEATURE_ECN_CA;</span>
 
 	return 0;
 }
<span class="p_chunk">@@ -1037,11 +1039,12 @@</span> <span class="p_context"> struct fib_info *fib_create_info(struct fib_config *cfg)</span>
 		goto failure;
 	fib_info_cnt++;
 	if (cfg-&gt;fc_mx) {
<span class="p_del">-		fi-&gt;fib_metrics = kzalloc(sizeof(u32) * RTAX_MAX, GFP_KERNEL);</span>
<span class="p_add">+		fi-&gt;fib_metrics = kzalloc(sizeof(*fi-&gt;fib_metrics), GFP_KERNEL);</span>
 		if (!fi-&gt;fib_metrics)
 			goto failure;
<span class="p_add">+		atomic_set(&amp;fi-&gt;fib_metrics-&gt;refcnt, 1);</span>
 	} else
<span class="p_del">-		fi-&gt;fib_metrics = (u32 *) dst_default_metrics;</span>
<span class="p_add">+		fi-&gt;fib_metrics = (struct dst_metrics *)&amp;dst_default_metrics;</span>
 
 	fi-&gt;fib_net = net;
 	fi-&gt;fib_protocol = cfg-&gt;fc_protocol;
<span class="p_chunk">@@ -1242,7 +1245,7 @@</span> <span class="p_context"> int fib_dump_info(struct sk_buff *skb, u32 portid, u32 seq, int event,</span>
 	if (fi-&gt;fib_priority &amp;&amp;
 	    nla_put_u32(skb, RTA_PRIORITY, fi-&gt;fib_priority))
 		goto nla_put_failure;
<span class="p_del">-	if (rtnetlink_put_metrics(skb, fi-&gt;fib_metrics) &lt; 0)</span>
<span class="p_add">+	if (rtnetlink_put_metrics(skb, fi-&gt;fib_metrics-&gt;metrics) &lt; 0)</span>
 		goto nla_put_failure;
 
 	if (fi-&gt;fib_prefsrc &amp;&amp;
<span class="p_header">diff --git a/net/ipv4/fib_trie.c b/net/ipv4/fib_trie.c</span>
<span class="p_header">index 2f0d8233950f..08709fb62d2e 100644</span>
<span class="p_header">--- a/net/ipv4/fib_trie.c</span>
<span class="p_header">+++ b/net/ipv4/fib_trie.c</span>
<span class="p_chunk">@@ -2079,6 +2079,8 @@</span> <span class="p_context"> static int fn_trie_dump_leaf(struct key_vector *l, struct fib_table *tb,</span>
 
 	/* rcu_read_lock is hold by caller */
 	hlist_for_each_entry_rcu(fa, &amp;l-&gt;leaf, fa_list) {
<span class="p_add">+		int err;</span>
<span class="p_add">+</span>
 		if (i &lt; s_i) {
 			i++;
 			continue;
<span class="p_chunk">@@ -2089,17 +2091,14 @@</span> <span class="p_context"> static int fn_trie_dump_leaf(struct key_vector *l, struct fib_table *tb,</span>
 			continue;
 		}
 
<span class="p_del">-		if (fib_dump_info(skb, NETLINK_CB(cb-&gt;skb).portid,</span>
<span class="p_del">-				  cb-&gt;nlh-&gt;nlmsg_seq,</span>
<span class="p_del">-				  RTM_NEWROUTE,</span>
<span class="p_del">-				  tb-&gt;tb_id,</span>
<span class="p_del">-				  fa-&gt;fa_type,</span>
<span class="p_del">-				  xkey,</span>
<span class="p_del">-				  KEYLENGTH - fa-&gt;fa_slen,</span>
<span class="p_del">-				  fa-&gt;fa_tos,</span>
<span class="p_del">-				  fa-&gt;fa_info, NLM_F_MULTI) &lt; 0) {</span>
<span class="p_add">+		err = fib_dump_info(skb, NETLINK_CB(cb-&gt;skb).portid,</span>
<span class="p_add">+				    cb-&gt;nlh-&gt;nlmsg_seq, RTM_NEWROUTE,</span>
<span class="p_add">+				    tb-&gt;tb_id, fa-&gt;fa_type,</span>
<span class="p_add">+				    xkey, KEYLENGTH - fa-&gt;fa_slen,</span>
<span class="p_add">+				    fa-&gt;fa_tos, fa-&gt;fa_info, NLM_F_MULTI);</span>
<span class="p_add">+		if (err &lt; 0) {</span>
 			cb-&gt;args[4] = i;
<span class="p_del">-			return -1;</span>
<span class="p_add">+			return err;</span>
 		}
 		i++;
 	}
<span class="p_chunk">@@ -2121,10 +2120,13 @@</span> <span class="p_context"> int fib_table_dump(struct fib_table *tb, struct sk_buff *skb,</span>
 	t_key key = cb-&gt;args[3];
 
 	while ((l = leaf_walk_rcu(&amp;tp, key)) != NULL) {
<span class="p_del">-		if (fn_trie_dump_leaf(l, tb, skb, cb) &lt; 0) {</span>
<span class="p_add">+		int err;</span>
<span class="p_add">+</span>
<span class="p_add">+		err = fn_trie_dump_leaf(l, tb, skb, cb);</span>
<span class="p_add">+		if (err &lt; 0) {</span>
 			cb-&gt;args[3] = key;
 			cb-&gt;args[2] = count;
<span class="p_del">-			return -1;</span>
<span class="p_add">+			return err;</span>
 		}
 
 		++count;
<span class="p_header">diff --git a/net/ipv4/inet_connection_sock.c b/net/ipv4/inet_connection_sock.c</span>
<span class="p_header">index 5e313c1ac94f..1054d330bf9d 100644</span>
<span class="p_header">--- a/net/ipv4/inet_connection_sock.c</span>
<span class="p_header">+++ b/net/ipv4/inet_connection_sock.c</span>
<span class="p_chunk">@@ -794,6 +794,8 @@</span> <span class="p_context"> struct sock *inet_csk_clone_lock(const struct sock *sk,</span>
 		/* listeners have SOCK_RCU_FREE, not the children */
 		sock_reset_flag(newsk, SOCK_RCU_FREE);
 
<span class="p_add">+		inet_sk(newsk)-&gt;mc_list = NULL;</span>
<span class="p_add">+</span>
 		newsk-&gt;sk_mark = inet_rsk(req)-&gt;ir_mark;
 		atomic64_set(&amp;newsk-&gt;sk_cookie,
 			     atomic64_read(&amp;inet_rsk(req)-&gt;ir_cookie));
<span class="p_header">diff --git a/net/ipv4/route.c b/net/ipv4/route.c</span>
<span class="p_header">index d9724889ff09..e0cc6c1fe69d 100644</span>
<span class="p_header">--- a/net/ipv4/route.c</span>
<span class="p_header">+++ b/net/ipv4/route.c</span>
<span class="p_chunk">@@ -1389,8 +1389,12 @@</span> <span class="p_context"> static void rt_add_uncached_list(struct rtable *rt)</span>
 
 static void ipv4_dst_destroy(struct dst_entry *dst)
 {
<span class="p_add">+	struct dst_metrics *p = (struct dst_metrics *)DST_METRICS_PTR(dst);</span>
 	struct rtable *rt = (struct rtable *) dst;
 
<span class="p_add">+	if (p != &amp;dst_default_metrics &amp;&amp; atomic_dec_and_test(&amp;p-&gt;refcnt))</span>
<span class="p_add">+		kfree(p);</span>
<span class="p_add">+</span>
 	if (!list_empty(&amp;rt-&gt;rt_uncached)) {
 		struct uncached_list *ul = rt-&gt;rt_uncached_list;
 
<span class="p_chunk">@@ -1442,7 +1446,11 @@</span> <span class="p_context"> static void rt_set_nexthop(struct rtable *rt, __be32 daddr,</span>
 			rt-&gt;rt_gateway = nh-&gt;nh_gw;
 			rt-&gt;rt_uses_gateway = 1;
 		}
<span class="p_del">-		dst_init_metrics(&amp;rt-&gt;dst, fi-&gt;fib_metrics, true);</span>
<span class="p_add">+		dst_init_metrics(&amp;rt-&gt;dst, fi-&gt;fib_metrics-&gt;metrics, true);</span>
<span class="p_add">+		if (fi-&gt;fib_metrics != &amp;dst_default_metrics) {</span>
<span class="p_add">+			rt-&gt;dst._metrics |= DST_METRICS_REFCOUNTED;</span>
<span class="p_add">+			atomic_inc(&amp;fi-&gt;fib_metrics-&gt;refcnt);</span>
<span class="p_add">+		}</span>
 #ifdef CONFIG_IP_ROUTE_CLASSID
 		rt-&gt;dst.tclassid = nh-&gt;nh_tclassid;
 #endif
<span class="p_header">diff --git a/net/ipv4/tcp.c b/net/ipv4/tcp.c</span>
<span class="p_header">index 2dc7fcf60bf3..651f1f058a64 100644</span>
<span class="p_header">--- a/net/ipv4/tcp.c</span>
<span class="p_header">+++ b/net/ipv4/tcp.c</span>
<span class="p_chunk">@@ -1084,9 +1084,12 @@</span> <span class="p_context"> static int tcp_sendmsg_fastopen(struct sock *sk, struct msghdr *msg,</span>
 {
 	struct tcp_sock *tp = tcp_sk(sk);
 	struct inet_sock *inet = inet_sk(sk);
<span class="p_add">+	struct sockaddr *uaddr = msg-&gt;msg_name;</span>
 	int err, flags;
 
<span class="p_del">-	if (!(sysctl_tcp_fastopen &amp; TFO_CLIENT_ENABLE))</span>
<span class="p_add">+	if (!(sysctl_tcp_fastopen &amp; TFO_CLIENT_ENABLE) ||</span>
<span class="p_add">+	    (uaddr &amp;&amp; msg-&gt;msg_namelen &gt;= sizeof(uaddr-&gt;sa_family) &amp;&amp;</span>
<span class="p_add">+	     uaddr-&gt;sa_family == AF_UNSPEC))</span>
 		return -EOPNOTSUPP;
 	if (tp-&gt;fastopen_req)
 		return -EALREADY; /* Another Fast Open is in progress */
<span class="p_chunk">@@ -1108,7 +1111,7 @@</span> <span class="p_context"> static int tcp_sendmsg_fastopen(struct sock *sk, struct msghdr *msg,</span>
 		}
 	}
 	flags = (msg-&gt;msg_flags &amp; MSG_DONTWAIT) ? O_NONBLOCK : 0;
<span class="p_del">-	err = __inet_stream_connect(sk-&gt;sk_socket, msg-&gt;msg_name,</span>
<span class="p_add">+	err = __inet_stream_connect(sk-&gt;sk_socket, uaddr,</span>
 				    msg-&gt;msg_namelen, flags, 1);
 	/* fastopen_req could already be freed in __inet_stream_connect
 	 * if the connection times out or gets rst
<span class="p_header">diff --git a/net/ipv4/tcp_input.c b/net/ipv4/tcp_input.c</span>
<span class="p_header">index 3c6c8787b42e..896a0458e578 100644</span>
<span class="p_header">--- a/net/ipv4/tcp_input.c</span>
<span class="p_header">+++ b/net/ipv4/tcp_input.c</span>
<span class="p_chunk">@@ -1174,13 +1174,14 @@</span> <span class="p_context"> static int tcp_match_skb_to_sack(struct sock *sk, struct sk_buff *skb,</span>
 		 */
 		if (pkt_len &gt; mss) {
 			unsigned int new_len = (pkt_len / mss) * mss;
<span class="p_del">-			if (!in_sack &amp;&amp; new_len &lt; pkt_len) {</span>
<span class="p_add">+			if (!in_sack &amp;&amp; new_len &lt; pkt_len)</span>
 				new_len += mss;
<span class="p_del">-				if (new_len &gt;= skb-&gt;len)</span>
<span class="p_del">-					return 0;</span>
<span class="p_del">-			}</span>
 			pkt_len = new_len;
 		}
<span class="p_add">+</span>
<span class="p_add">+		if (pkt_len &gt;= skb-&gt;len &amp;&amp; !in_sack)</span>
<span class="p_add">+			return 0;</span>
<span class="p_add">+</span>
 		err = tcp_fragment(sk, skb, pkt_len, mss, GFP_ATOMIC);
 		if (err &lt; 0)
 			return err;
<span class="p_chunk">@@ -3188,7 +3189,7 @@</span> <span class="p_context"> static int tcp_clean_rtx_queue(struct sock *sk, int prior_fackets,</span>
 			int delta;
 
 			/* Non-retransmitted hole got filled? That&#39;s reordering */
<span class="p_del">-			if (reord &lt; prior_fackets)</span>
<span class="p_add">+			if (reord &lt; prior_fackets &amp;&amp; reord &lt;= tp-&gt;fackets_out)</span>
 				tcp_update_reordering(sk, tp-&gt;fackets_out - reord, 0);
 
 			delta = tcp_is_fack(tp) ? pkts_acked :
<span class="p_header">diff --git a/net/ipv6/ip6_gre.c b/net/ipv6/ip6_gre.c</span>
<span class="p_header">index 6fcb7cb49bb2..4d60164c17e2 100644</span>
<span class="p_header">--- a/net/ipv6/ip6_gre.c</span>
<span class="p_header">+++ b/net/ipv6/ip6_gre.c</span>
<span class="p_chunk">@@ -537,11 +537,10 @@</span> <span class="p_context"> static inline int ip6gre_xmit_ipv4(struct sk_buff *skb, struct net_device *dev)</span>
 
 	memcpy(&amp;fl6, &amp;t-&gt;fl.u.ip6, sizeof(fl6));
 
<span class="p_del">-	dsfield = ipv4_get_dsfield(iph);</span>
<span class="p_del">-</span>
 	if (t-&gt;parms.flags &amp; IP6_TNL_F_USE_ORIG_TCLASS)
<span class="p_del">-		fl6.flowlabel |= htonl((__u32)iph-&gt;tos &lt;&lt; IPV6_TCLASS_SHIFT)</span>
<span class="p_del">-					  &amp; IPV6_TCLASS_MASK;</span>
<span class="p_add">+		dsfield = ipv4_get_dsfield(iph);</span>
<span class="p_add">+	else</span>
<span class="p_add">+		dsfield = ip6_tclass(t-&gt;parms.flowinfo);</span>
 	if (t-&gt;parms.flags &amp; IP6_TNL_F_USE_ORIG_FWMARK)
 		fl6.flowi6_mark = skb-&gt;mark;
 
<span class="p_chunk">@@ -596,9 +595,11 @@</span> <span class="p_context"> static inline int ip6gre_xmit_ipv6(struct sk_buff *skb, struct net_device *dev)</span>
 
 	memcpy(&amp;fl6, &amp;t-&gt;fl.u.ip6, sizeof(fl6));
 
<span class="p_del">-	dsfield = ipv6_get_dsfield(ipv6h);</span>
 	if (t-&gt;parms.flags &amp; IP6_TNL_F_USE_ORIG_TCLASS)
<span class="p_del">-		fl6.flowlabel |= (*(__be32 *) ipv6h &amp; IPV6_TCLASS_MASK);</span>
<span class="p_add">+		dsfield = ipv6_get_dsfield(ipv6h);</span>
<span class="p_add">+	else</span>
<span class="p_add">+		dsfield = ip6_tclass(t-&gt;parms.flowinfo);</span>
<span class="p_add">+</span>
 	if (t-&gt;parms.flags &amp; IP6_TNL_F_USE_ORIG_FLOWLABEL)
 		fl6.flowlabel |= ip6_flowlabel(ipv6h);
 	if (t-&gt;parms.flags &amp; IP6_TNL_F_USE_ORIG_FWMARK)
<span class="p_header">diff --git a/net/ipv6/ip6_offload.c b/net/ipv6/ip6_offload.c</span>
<span class="p_header">index 93e58a5e1837..280268f1dd7b 100644</span>
<span class="p_header">--- a/net/ipv6/ip6_offload.c</span>
<span class="p_header">+++ b/net/ipv6/ip6_offload.c</span>
<span class="p_chunk">@@ -63,7 +63,6 @@</span> <span class="p_context"> static struct sk_buff *ipv6_gso_segment(struct sk_buff *skb,</span>
 	const struct net_offload *ops;
 	int proto;
 	struct frag_hdr *fptr;
<span class="p_del">-	unsigned int unfrag_ip6hlen;</span>
 	unsigned int payload_len;
 	u8 *prevhdr;
 	int offset = 0;
<span class="p_chunk">@@ -116,8 +115,10 @@</span> <span class="p_context"> static struct sk_buff *ipv6_gso_segment(struct sk_buff *skb,</span>
 		skb-&gt;network_header = (u8 *)ipv6h - skb-&gt;head;
 
 		if (udpfrag) {
<span class="p_del">-			unfrag_ip6hlen = ip6_find_1stfragopt(skb, &amp;prevhdr);</span>
<span class="p_del">-			fptr = (struct frag_hdr *)((u8 *)ipv6h + unfrag_ip6hlen);</span>
<span class="p_add">+			int err = ip6_find_1stfragopt(skb, &amp;prevhdr);</span>
<span class="p_add">+			if (err &lt; 0)</span>
<span class="p_add">+				return ERR_PTR(err);</span>
<span class="p_add">+			fptr = (struct frag_hdr *)((u8 *)ipv6h + err);</span>
 			fptr-&gt;frag_off = htons(offset);
 			if (skb-&gt;next)
 				fptr-&gt;frag_off |= htons(IP6_MF);
<span class="p_header">diff --git a/net/ipv6/ip6_output.c b/net/ipv6/ip6_output.c</span>
<span class="p_header">index 58f6288e9ba5..bf8a58a1c32d 100644</span>
<span class="p_header">--- a/net/ipv6/ip6_output.c</span>
<span class="p_header">+++ b/net/ipv6/ip6_output.c</span>
<span class="p_chunk">@@ -597,7 +597,10 @@</span> <span class="p_context"> int ip6_fragment(struct net *net, struct sock *sk, struct sk_buff *skb,</span>
 	int ptr, offset = 0, err = 0;
 	u8 *prevhdr, nexthdr = 0;
 
<span class="p_del">-	hlen = ip6_find_1stfragopt(skb, &amp;prevhdr);</span>
<span class="p_add">+	err = ip6_find_1stfragopt(skb, &amp;prevhdr);</span>
<span class="p_add">+	if (err &lt; 0)</span>
<span class="p_add">+		goto fail;</span>
<span class="p_add">+	hlen = err;</span>
 	nexthdr = *prevhdr;
 
 	mtu = ip6_skb_dst_mtu(skb);
<span class="p_chunk">@@ -1463,6 +1466,11 @@</span> <span class="p_context"> static int __ip6_append_data(struct sock *sk,</span>
 			 */
 			alloclen += sizeof(struct frag_hdr);
 
<span class="p_add">+			copy = datalen - transhdrlen - fraggap;</span>
<span class="p_add">+			if (copy &lt; 0) {</span>
<span class="p_add">+				err = -EINVAL;</span>
<span class="p_add">+				goto error;</span>
<span class="p_add">+			}</span>
 			if (transhdrlen) {
 				skb = sock_alloc_send_skb(sk,
 						alloclen + hh_len,
<span class="p_chunk">@@ -1512,13 +1520,9 @@</span> <span class="p_context"> static int __ip6_append_data(struct sock *sk,</span>
 				data += fraggap;
 				pskb_trim_unique(skb_prev, maxfraglen);
 			}
<span class="p_del">-			copy = datalen - transhdrlen - fraggap;</span>
<span class="p_del">-</span>
<span class="p_del">-			if (copy &lt; 0) {</span>
<span class="p_del">-				err = -EINVAL;</span>
<span class="p_del">-				kfree_skb(skb);</span>
<span class="p_del">-				goto error;</span>
<span class="p_del">-			} else if (copy &gt; 0 &amp;&amp; getfrag(from, data + transhdrlen, offset, copy, fraggap, skb) &lt; 0) {</span>
<span class="p_add">+			if (copy &gt; 0 &amp;&amp;</span>
<span class="p_add">+			    getfrag(from, data + transhdrlen, offset,</span>
<span class="p_add">+				    copy, fraggap, skb) &lt; 0) {</span>
 				err = -EFAULT;
 				kfree_skb(skb);
 				goto error;
<span class="p_header">diff --git a/net/ipv6/ip6_tunnel.c b/net/ipv6/ip6_tunnel.c</span>
<span class="p_header">index a9692ec0cd6d..15ff33934f79 100644</span>
<span class="p_header">--- a/net/ipv6/ip6_tunnel.c</span>
<span class="p_header">+++ b/net/ipv6/ip6_tunnel.c</span>
<span class="p_chunk">@@ -1196,7 +1196,7 @@</span> <span class="p_context"> int ip6_tnl_xmit(struct sk_buff *skb, struct net_device *dev, __u8 dsfield,</span>
 	skb_push(skb, sizeof(struct ipv6hdr));
 	skb_reset_network_header(skb);
 	ipv6h = ipv6_hdr(skb);
<span class="p_del">-	ip6_flow_hdr(ipv6h, INET_ECN_encapsulate(0, dsfield),</span>
<span class="p_add">+	ip6_flow_hdr(ipv6h, dsfield,</span>
 		     ip6_make_flowlabel(net, skb, fl6-&gt;flowlabel, true, fl6));
 	ipv6h-&gt;hop_limit = hop_limit;
 	ipv6h-&gt;nexthdr = proto;
<span class="p_chunk">@@ -1231,8 +1231,6 @@</span> <span class="p_context"> ip4ip6_tnl_xmit(struct sk_buff *skb, struct net_device *dev)</span>
 	if (tproto != IPPROTO_IPIP &amp;&amp; tproto != 0)
 		return -1;
 
<span class="p_del">-	dsfield = ipv4_get_dsfield(iph);</span>
<span class="p_del">-</span>
 	if (t-&gt;parms.collect_md) {
 		struct ip_tunnel_info *tun_info;
 		const struct ip_tunnel_key *key;
<span class="p_chunk">@@ -1246,6 +1244,7 @@</span> <span class="p_context"> ip4ip6_tnl_xmit(struct sk_buff *skb, struct net_device *dev)</span>
 		fl6.flowi6_proto = IPPROTO_IPIP;
 		fl6.daddr = key-&gt;u.ipv6.dst;
 		fl6.flowlabel = key-&gt;label;
<span class="p_add">+		dsfield = ip6_tclass(key-&gt;label);</span>
 	} else {
 		if (!(t-&gt;parms.flags &amp; IP6_TNL_F_IGN_ENCAP_LIMIT))
 			encap_limit = t-&gt;parms.encap_limit;
<span class="p_chunk">@@ -1254,8 +1253,9 @@</span> <span class="p_context"> ip4ip6_tnl_xmit(struct sk_buff *skb, struct net_device *dev)</span>
 		fl6.flowi6_proto = IPPROTO_IPIP;
 
 		if (t-&gt;parms.flags &amp; IP6_TNL_F_USE_ORIG_TCLASS)
<span class="p_del">-			fl6.flowlabel |= htonl((__u32)iph-&gt;tos &lt;&lt; IPV6_TCLASS_SHIFT)</span>
<span class="p_del">-					 &amp; IPV6_TCLASS_MASK;</span>
<span class="p_add">+			dsfield = ipv4_get_dsfield(iph);</span>
<span class="p_add">+		else</span>
<span class="p_add">+			dsfield = ip6_tclass(t-&gt;parms.flowinfo);</span>
 		if (t-&gt;parms.flags &amp; IP6_TNL_F_USE_ORIG_FWMARK)
 			fl6.flowi6_mark = skb-&gt;mark;
 	}
<span class="p_chunk">@@ -1265,6 +1265,8 @@</span> <span class="p_context"> ip4ip6_tnl_xmit(struct sk_buff *skb, struct net_device *dev)</span>
 	if (iptunnel_handle_offloads(skb, SKB_GSO_IPXIP6))
 		return -1;
 
<span class="p_add">+	dsfield = INET_ECN_encapsulate(dsfield, ipv4_get_dsfield(iph));</span>
<span class="p_add">+</span>
 	skb_set_inner_ipproto(skb, IPPROTO_IPIP);
 
 	err = ip6_tnl_xmit(skb, dev, dsfield, &amp;fl6, encap_limit, &amp;mtu,
<span class="p_chunk">@@ -1298,8 +1300,6 @@</span> <span class="p_context"> ip6ip6_tnl_xmit(struct sk_buff *skb, struct net_device *dev)</span>
 	    ip6_tnl_addr_conflict(t, ipv6h))
 		return -1;
 
<span class="p_del">-	dsfield = ipv6_get_dsfield(ipv6h);</span>
<span class="p_del">-</span>
 	if (t-&gt;parms.collect_md) {
 		struct ip_tunnel_info *tun_info;
 		const struct ip_tunnel_key *key;
<span class="p_chunk">@@ -1313,6 +1313,7 @@</span> <span class="p_context"> ip6ip6_tnl_xmit(struct sk_buff *skb, struct net_device *dev)</span>
 		fl6.flowi6_proto = IPPROTO_IPV6;
 		fl6.daddr = key-&gt;u.ipv6.dst;
 		fl6.flowlabel = key-&gt;label;
<span class="p_add">+		dsfield = ip6_tclass(key-&gt;label);</span>
 	} else {
 		offset = ip6_tnl_parse_tlv_enc_lim(skb, skb_network_header(skb));
 		/* ip6_tnl_parse_tlv_enc_lim() might have reallocated skb-&gt;head */
<span class="p_chunk">@@ -1335,7 +1336,9 @@</span> <span class="p_context"> ip6ip6_tnl_xmit(struct sk_buff *skb, struct net_device *dev)</span>
 		fl6.flowi6_proto = IPPROTO_IPV6;
 
 		if (t-&gt;parms.flags &amp; IP6_TNL_F_USE_ORIG_TCLASS)
<span class="p_del">-			fl6.flowlabel |= (*(__be32 *)ipv6h &amp; IPV6_TCLASS_MASK);</span>
<span class="p_add">+			dsfield = ipv6_get_dsfield(ipv6h);</span>
<span class="p_add">+		else</span>
<span class="p_add">+			dsfield = ip6_tclass(t-&gt;parms.flowinfo);</span>
 		if (t-&gt;parms.flags &amp; IP6_TNL_F_USE_ORIG_FLOWLABEL)
 			fl6.flowlabel |= ip6_flowlabel(ipv6h);
 		if (t-&gt;parms.flags &amp; IP6_TNL_F_USE_ORIG_FWMARK)
<span class="p_chunk">@@ -1347,6 +1350,8 @@</span> <span class="p_context"> ip6ip6_tnl_xmit(struct sk_buff *skb, struct net_device *dev)</span>
 	if (iptunnel_handle_offloads(skb, SKB_GSO_IPXIP6))
 		return -1;
 
<span class="p_add">+	dsfield = INET_ECN_encapsulate(dsfield, ipv6_get_dsfield(ipv6h));</span>
<span class="p_add">+</span>
 	skb_set_inner_ipproto(skb, IPPROTO_IPV6);
 
 	err = ip6_tnl_xmit(skb, dev, dsfield, &amp;fl6, encap_limit, &amp;mtu,
<span class="p_header">diff --git a/net/ipv6/output_core.c b/net/ipv6/output_core.c</span>
<span class="p_header">index cd4252346a32..e9065b8d3af8 100644</span>
<span class="p_header">--- a/net/ipv6/output_core.c</span>
<span class="p_header">+++ b/net/ipv6/output_core.c</span>
<span class="p_chunk">@@ -79,14 +79,13 @@</span> <span class="p_context"> EXPORT_SYMBOL(ipv6_select_ident);</span>
 int ip6_find_1stfragopt(struct sk_buff *skb, u8 **nexthdr)
 {
 	u16 offset = sizeof(struct ipv6hdr);
<span class="p_del">-	struct ipv6_opt_hdr *exthdr =</span>
<span class="p_del">-				(struct ipv6_opt_hdr *)(ipv6_hdr(skb) + 1);</span>
 	unsigned int packet_len = skb_tail_pointer(skb) -
 		skb_network_header(skb);
 	int found_rhdr = 0;
 	*nexthdr = &amp;ipv6_hdr(skb)-&gt;nexthdr;
 
<span class="p_del">-	while (offset + 1 &lt;= packet_len) {</span>
<span class="p_add">+	while (offset &lt;= packet_len) {</span>
<span class="p_add">+		struct ipv6_opt_hdr *exthdr;</span>
 
 		switch (**nexthdr) {
 
<span class="p_chunk">@@ -107,13 +106,16 @@</span> <span class="p_context"> int ip6_find_1stfragopt(struct sk_buff *skb, u8 **nexthdr)</span>
 			return offset;
 		}
 
<span class="p_del">-		offset += ipv6_optlen(exthdr);</span>
<span class="p_del">-		*nexthdr = &amp;exthdr-&gt;nexthdr;</span>
<span class="p_add">+		if (offset + sizeof(struct ipv6_opt_hdr) &gt; packet_len)</span>
<span class="p_add">+			return -EINVAL;</span>
<span class="p_add">+</span>
 		exthdr = (struct ipv6_opt_hdr *)(skb_network_header(skb) +
 						 offset);
<span class="p_add">+		offset += ipv6_optlen(exthdr);</span>
<span class="p_add">+		*nexthdr = &amp;exthdr-&gt;nexthdr;</span>
 	}
 
<span class="p_del">-	return offset;</span>
<span class="p_add">+	return -EINVAL;</span>
 }
 EXPORT_SYMBOL(ip6_find_1stfragopt);
 
<span class="p_header">diff --git a/net/ipv6/tcp_ipv6.c b/net/ipv6/tcp_ipv6.c</span>
<span class="p_header">index 4c4afdca41ff..ff5f87641651 100644</span>
<span class="p_header">--- a/net/ipv6/tcp_ipv6.c</span>
<span class="p_header">+++ b/net/ipv6/tcp_ipv6.c</span>
<span class="p_chunk">@@ -1070,6 +1070,7 @@</span> <span class="p_context"> static struct sock *tcp_v6_syn_recv_sock(const struct sock *sk, struct sk_buff *</span>
 		newtp-&gt;af_specific = &amp;tcp_sock_ipv6_mapped_specific;
 #endif
 
<span class="p_add">+		newnp-&gt;ipv6_mc_list = NULL;</span>
 		newnp-&gt;ipv6_ac_list = NULL;
 		newnp-&gt;ipv6_fl_list = NULL;
 		newnp-&gt;pktoptions  = NULL;
<span class="p_chunk">@@ -1139,6 +1140,7 @@</span> <span class="p_context"> static struct sock *tcp_v6_syn_recv_sock(const struct sock *sk, struct sk_buff *</span>
 	   First: no IPv4 options.
 	 */
 	newinet-&gt;inet_opt = NULL;
<span class="p_add">+	newnp-&gt;ipv6_mc_list = NULL;</span>
 	newnp-&gt;ipv6_ac_list = NULL;
 	newnp-&gt;ipv6_fl_list = NULL;
 
<span class="p_header">diff --git a/net/ipv6/udp_offload.c b/net/ipv6/udp_offload.c</span>
<span class="p_header">index ac858c480f2f..a2267f80febb 100644</span>
<span class="p_header">--- a/net/ipv6/udp_offload.c</span>
<span class="p_header">+++ b/net/ipv6/udp_offload.c</span>
<span class="p_chunk">@@ -29,6 +29,7 @@</span> <span class="p_context"> static struct sk_buff *udp6_ufo_fragment(struct sk_buff *skb,</span>
 	u8 frag_hdr_sz = sizeof(struct frag_hdr);
 	__wsum csum;
 	int tnl_hlen;
<span class="p_add">+	int err;</span>
 
 	mss = skb_shinfo(skb)-&gt;gso_size;
 	if (unlikely(skb-&gt;len &lt;= mss))
<span class="p_chunk">@@ -90,7 +91,10 @@</span> <span class="p_context"> static struct sk_buff *udp6_ufo_fragment(struct sk_buff *skb,</span>
 		/* Find the unfragmentable header and shift it left by frag_hdr_sz
 		 * bytes to insert fragment header.
 		 */
<span class="p_del">-		unfrag_ip6hlen = ip6_find_1stfragopt(skb, &amp;prevhdr);</span>
<span class="p_add">+		err = ip6_find_1stfragopt(skb, &amp;prevhdr);</span>
<span class="p_add">+		if (err &lt; 0)</span>
<span class="p_add">+			return ERR_PTR(err);</span>
<span class="p_add">+		unfrag_ip6hlen = err;</span>
 		nexthdr = *prevhdr;
 		*prevhdr = NEXTHDR_FRAGMENT;
 		unfrag_len = (skb_network_header(skb) - skb_mac_header(skb)) +
<span class="p_header">diff --git a/net/packet/af_packet.c b/net/packet/af_packet.c</span>
<span class="p_header">index ea81ccf3c7d6..b2d8e8c23e46 100644</span>
<span class="p_header">--- a/net/packet/af_packet.c</span>
<span class="p_header">+++ b/net/packet/af_packet.c</span>
<span class="p_chunk">@@ -2614,13 +2614,6 @@</span> <span class="p_context"> static int tpacket_snd(struct packet_sock *po, struct msghdr *msg)</span>
 		dev = dev_get_by_index(sock_net(&amp;po-&gt;sk), saddr-&gt;sll_ifindex);
 	}
 
<span class="p_del">-	sockc.tsflags = po-&gt;sk.sk_tsflags;</span>
<span class="p_del">-	if (msg-&gt;msg_controllen) {</span>
<span class="p_del">-		err = sock_cmsg_send(&amp;po-&gt;sk, msg, &amp;sockc);</span>
<span class="p_del">-		if (unlikely(err))</span>
<span class="p_del">-			goto out;</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
 	err = -ENXIO;
 	if (unlikely(dev == NULL))
 		goto out;
<span class="p_chunk">@@ -2628,6 +2621,13 @@</span> <span class="p_context"> static int tpacket_snd(struct packet_sock *po, struct msghdr *msg)</span>
 	if (unlikely(!(dev-&gt;flags &amp; IFF_UP)))
 		goto out_put;
 
<span class="p_add">+	sockc.tsflags = po-&gt;sk.sk_tsflags;</span>
<span class="p_add">+	if (msg-&gt;msg_controllen) {</span>
<span class="p_add">+		err = sock_cmsg_send(&amp;po-&gt;sk, msg, &amp;sockc);</span>
<span class="p_add">+		if (unlikely(err))</span>
<span class="p_add">+			goto out_put;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
 	if (po-&gt;sk.sk_socket-&gt;type == SOCK_RAW)
 		reserve = dev-&gt;hard_header_len;
 	size_max = po-&gt;tx_ring.frame_size
<span class="p_header">diff --git a/net/sctp/input.c b/net/sctp/input.c</span>
<span class="p_header">index 0e06a278d2a9..ba9ad32fc447 100644</span>
<span class="p_header">--- a/net/sctp/input.c</span>
<span class="p_header">+++ b/net/sctp/input.c</span>
<span class="p_chunk">@@ -473,15 +473,14 @@</span> <span class="p_context"> struct sock *sctp_err_lookup(struct net *net, int family, struct sk_buff *skb,</span>
 			     struct sctp_association **app,
 			     struct sctp_transport **tpp)
 {
<span class="p_add">+	struct sctp_init_chunk *chunkhdr, _chunkhdr;</span>
 	union sctp_addr saddr;
 	union sctp_addr daddr;
 	struct sctp_af *af;
 	struct sock *sk = NULL;
 	struct sctp_association *asoc;
 	struct sctp_transport *transport = NULL;
<span class="p_del">-	struct sctp_init_chunk *chunkhdr;</span>
 	__u32 vtag = ntohl(sctphdr-&gt;vtag);
<span class="p_del">-	int len = skb-&gt;len - ((void *)sctphdr - (void *)skb-&gt;data);</span>
 
 	*app = NULL; *tpp = NULL;
 
<span class="p_chunk">@@ -516,13 +515,16 @@</span> <span class="p_context"> struct sock *sctp_err_lookup(struct net *net, int family, struct sk_buff *skb,</span>
 	 * discard the packet.
 	 */
 	if (vtag == 0) {
<span class="p_del">-		chunkhdr = (void *)sctphdr + sizeof(struct sctphdr);</span>
<span class="p_del">-		if (len &lt; sizeof(struct sctphdr) + sizeof(sctp_chunkhdr_t)</span>
<span class="p_del">-			  + sizeof(__be32) ||</span>
<span class="p_add">+		/* chunk header + first 4 octects of init header */</span>
<span class="p_add">+		chunkhdr = skb_header_pointer(skb, skb_transport_offset(skb) +</span>
<span class="p_add">+					      sizeof(struct sctphdr),</span>
<span class="p_add">+					      sizeof(struct sctp_chunkhdr) +</span>
<span class="p_add">+					      sizeof(__be32), &amp;_chunkhdr);</span>
<span class="p_add">+		if (!chunkhdr ||</span>
 		    chunkhdr-&gt;chunk_hdr.type != SCTP_CID_INIT ||
<span class="p_del">-		    ntohl(chunkhdr-&gt;init_hdr.init_tag) != asoc-&gt;c.my_vtag) {</span>
<span class="p_add">+		    ntohl(chunkhdr-&gt;init_hdr.init_tag) != asoc-&gt;c.my_vtag)</span>
 			goto out;
<span class="p_del">-		}</span>
<span class="p_add">+</span>
 	} else if (vtag != asoc-&gt;c.peer_vtag) {
 		goto out;
 	}
<span class="p_header">diff --git a/net/sctp/ipv6.c b/net/sctp/ipv6.c</span>
<span class="p_header">index 961ee59f696a..f5b45b8b8b16 100644</span>
<span class="p_header">--- a/net/sctp/ipv6.c</span>
<span class="p_header">+++ b/net/sctp/ipv6.c</span>
<span class="p_chunk">@@ -240,12 +240,10 @@</span> <span class="p_context"> static void sctp_v6_get_dst(struct sctp_transport *t, union sctp_addr *saddr,</span>
 	struct sctp_bind_addr *bp;
 	struct ipv6_pinfo *np = inet6_sk(sk);
 	struct sctp_sockaddr_entry *laddr;
<span class="p_del">-	union sctp_addr *baddr = NULL;</span>
 	union sctp_addr *daddr = &amp;t-&gt;ipaddr;
 	union sctp_addr dst_saddr;
 	struct in6_addr *final_p, final;
 	__u8 matchlen = 0;
<span class="p_del">-	__u8 bmatchlen;</span>
 	sctp_scope_t scope;
 
 	memset(fl6, 0, sizeof(struct flowi6));
<span class="p_chunk">@@ -312,23 +310,37 @@</span> <span class="p_context"> static void sctp_v6_get_dst(struct sctp_transport *t, union sctp_addr *saddr,</span>
 	 */
 	rcu_read_lock();
 	list_for_each_entry_rcu(laddr, &amp;bp-&gt;address_list, list) {
<span class="p_del">-		if (!laddr-&gt;valid)</span>
<span class="p_add">+		struct dst_entry *bdst;</span>
<span class="p_add">+		__u8 bmatchlen;</span>
<span class="p_add">+</span>
<span class="p_add">+		if (!laddr-&gt;valid ||</span>
<span class="p_add">+		    laddr-&gt;state != SCTP_ADDR_SRC ||</span>
<span class="p_add">+		    laddr-&gt;a.sa.sa_family != AF_INET6 ||</span>
<span class="p_add">+		    scope &gt; sctp_scope(&amp;laddr-&gt;a))</span>
 			continue;
<span class="p_del">-		if ((laddr-&gt;state == SCTP_ADDR_SRC) &amp;&amp;</span>
<span class="p_del">-		    (laddr-&gt;a.sa.sa_family == AF_INET6) &amp;&amp;</span>
<span class="p_del">-		    (scope &lt;= sctp_scope(&amp;laddr-&gt;a))) {</span>
<span class="p_del">-			bmatchlen = sctp_v6_addr_match_len(daddr, &amp;laddr-&gt;a);</span>
<span class="p_del">-			if (!baddr || (matchlen &lt; bmatchlen)) {</span>
<span class="p_del">-				baddr = &amp;laddr-&gt;a;</span>
<span class="p_del">-				matchlen = bmatchlen;</span>
<span class="p_del">-			}</span>
<span class="p_del">-		}</span>
<span class="p_del">-	}</span>
<span class="p_del">-	if (baddr) {</span>
<span class="p_del">-		fl6-&gt;saddr = baddr-&gt;v6.sin6_addr;</span>
<span class="p_del">-		fl6-&gt;fl6_sport = baddr-&gt;v6.sin6_port;</span>
<span class="p_add">+</span>
<span class="p_add">+		fl6-&gt;saddr = laddr-&gt;a.v6.sin6_addr;</span>
<span class="p_add">+		fl6-&gt;fl6_sport = laddr-&gt;a.v6.sin6_port;</span>
 		final_p = fl6_update_dst(fl6, rcu_dereference(np-&gt;opt), &amp;final);
<span class="p_del">-		dst = ip6_dst_lookup_flow(sk, fl6, final_p);</span>
<span class="p_add">+		bdst = ip6_dst_lookup_flow(sk, fl6, final_p);</span>
<span class="p_add">+</span>
<span class="p_add">+		if (!IS_ERR(bdst) &amp;&amp;</span>
<span class="p_add">+		    ipv6_chk_addr(dev_net(bdst-&gt;dev),</span>
<span class="p_add">+				  &amp;laddr-&gt;a.v6.sin6_addr, bdst-&gt;dev, 1)) {</span>
<span class="p_add">+			if (!IS_ERR_OR_NULL(dst))</span>
<span class="p_add">+				dst_release(dst);</span>
<span class="p_add">+			dst = bdst;</span>
<span class="p_add">+			break;</span>
<span class="p_add">+		}</span>
<span class="p_add">+</span>
<span class="p_add">+		bmatchlen = sctp_v6_addr_match_len(daddr, &amp;laddr-&gt;a);</span>
<span class="p_add">+		if (matchlen &gt; bmatchlen)</span>
<span class="p_add">+			continue;</span>
<span class="p_add">+</span>
<span class="p_add">+		if (!IS_ERR_OR_NULL(dst))</span>
<span class="p_add">+			dst_release(dst);</span>
<span class="p_add">+		dst = bdst;</span>
<span class="p_add">+		matchlen = bmatchlen;</span>
 	}
 	rcu_read_unlock();
 
<span class="p_chunk">@@ -665,6 +677,9 @@</span> <span class="p_context"> static struct sock *sctp_v6_create_accept_sk(struct sock *sk,</span>
 	newnp = inet6_sk(newsk);
 
 	memcpy(newnp, np, sizeof(struct ipv6_pinfo));
<span class="p_add">+	newnp-&gt;ipv6_mc_list = NULL;</span>
<span class="p_add">+	newnp-&gt;ipv6_ac_list = NULL;</span>
<span class="p_add">+	newnp-&gt;ipv6_fl_list = NULL;</span>
 
 	rcu_read_lock();
 	opt = rcu_dereference(np-&gt;opt);
<span class="p_header">diff --git a/net/smc/Kconfig b/net/smc/Kconfig</span>
<span class="p_header">index c717ef0896aa..33954852f3f8 100644</span>
<span class="p_header">--- a/net/smc/Kconfig</span>
<span class="p_header">+++ b/net/smc/Kconfig</span>
<span class="p_chunk">@@ -8,6 +8,10 @@</span> <span class="p_context"> config SMC</span>
 	  The Linux implementation of the SMC-R solution is designed as
 	  a separate socket family SMC.
 
<span class="p_add">+	  Warning: SMC will expose all memory for remote reads and writes</span>
<span class="p_add">+	  once a connection is established.  Don&#39;t enable this option except</span>
<span class="p_add">+	  for tightly controlled lab environment.</span>
<span class="p_add">+</span>
 	  Select this option if you want to run SMC socket applications
 
 config SMC_DIAG
<span class="p_header">diff --git a/net/smc/smc_clc.c b/net/smc/smc_clc.c</span>
<span class="p_header">index e41f594a1e1d..03ec058d18df 100644</span>
<span class="p_header">--- a/net/smc/smc_clc.c</span>
<span class="p_header">+++ b/net/smc/smc_clc.c</span>
<span class="p_chunk">@@ -204,7 +204,7 @@</span> <span class="p_context"> int smc_clc_send_confirm(struct smc_sock *smc)</span>
 	memcpy(&amp;cclc.lcl.mac, &amp;link-&gt;smcibdev-&gt;mac[link-&gt;ibport - 1], ETH_ALEN);
 	hton24(cclc.qpn, link-&gt;roce_qp-&gt;qp_num);
 	cclc.rmb_rkey =
<span class="p_del">-		htonl(conn-&gt;rmb_desc-&gt;mr_rx[SMC_SINGLE_LINK]-&gt;rkey);</span>
<span class="p_add">+		htonl(conn-&gt;rmb_desc-&gt;rkey[SMC_SINGLE_LINK]);</span>
 	cclc.conn_idx = 1; /* for now: 1 RMB = 1 RMBE */
 	cclc.rmbe_alert_token = htonl(conn-&gt;alert_token_local);
 	cclc.qp_mtu = min(link-&gt;path_mtu, link-&gt;peer_mtu);
<span class="p_chunk">@@ -256,7 +256,7 @@</span> <span class="p_context"> int smc_clc_send_accept(struct smc_sock *new_smc, int srv_first_contact)</span>
 	memcpy(&amp;aclc.lcl.mac, link-&gt;smcibdev-&gt;mac[link-&gt;ibport - 1], ETH_ALEN);
 	hton24(aclc.qpn, link-&gt;roce_qp-&gt;qp_num);
 	aclc.rmb_rkey =
<span class="p_del">-		htonl(conn-&gt;rmb_desc-&gt;mr_rx[SMC_SINGLE_LINK]-&gt;rkey);</span>
<span class="p_add">+		htonl(conn-&gt;rmb_desc-&gt;rkey[SMC_SINGLE_LINK]);</span>
 	aclc.conn_idx = 1;			/* as long as 1 RMB = 1 RMBE */
 	aclc.rmbe_alert_token = htonl(conn-&gt;alert_token_local);
 	aclc.qp_mtu = link-&gt;path_mtu;
<span class="p_header">diff --git a/net/smc/smc_core.c b/net/smc/smc_core.c</span>
<span class="p_header">index 0eac633fb354..88cbb8a22d4a 100644</span>
<span class="p_header">--- a/net/smc/smc_core.c</span>
<span class="p_header">+++ b/net/smc/smc_core.c</span>
<span class="p_chunk">@@ -613,19 +613,8 @@</span> <span class="p_context"> int smc_rmb_create(struct smc_sock *smc)</span>
 			rmb_desc = NULL;
 			continue; /* if mapping failed, try smaller one */
 		}
<span class="p_del">-		rc = smc_ib_get_memory_region(lgr-&gt;lnk[SMC_SINGLE_LINK].roce_pd,</span>
<span class="p_del">-					      IB_ACCESS_REMOTE_WRITE |</span>
<span class="p_del">-					      IB_ACCESS_LOCAL_WRITE,</span>
<span class="p_del">-					     &amp;rmb_desc-&gt;mr_rx[SMC_SINGLE_LINK]);</span>
<span class="p_del">-		if (rc) {</span>
<span class="p_del">-			smc_ib_buf_unmap(lgr-&gt;lnk[SMC_SINGLE_LINK].smcibdev,</span>
<span class="p_del">-					 tmp_bufsize, rmb_desc,</span>
<span class="p_del">-					 DMA_FROM_DEVICE);</span>
<span class="p_del">-			kfree(rmb_desc-&gt;cpu_addr);</span>
<span class="p_del">-			kfree(rmb_desc);</span>
<span class="p_del">-			rmb_desc = NULL;</span>
<span class="p_del">-			continue;</span>
<span class="p_del">-		}</span>
<span class="p_add">+		rmb_desc-&gt;rkey[SMC_SINGLE_LINK] =</span>
<span class="p_add">+			lgr-&gt;lnk[SMC_SINGLE_LINK].roce_pd-&gt;unsafe_global_rkey;</span>
 		rmb_desc-&gt;used = 1;
 		write_lock_bh(&amp;lgr-&gt;rmbs_lock);
 		list_add(&amp;rmb_desc-&gt;list,
<span class="p_chunk">@@ -668,6 +657,7 @@</span> <span class="p_context"> int smc_rmb_rtoken_handling(struct smc_connection *conn,</span>
 
 	for (i = 0; i &lt; SMC_RMBS_PER_LGR_MAX; i++) {
 		if ((lgr-&gt;rtokens[i][SMC_SINGLE_LINK].rkey == rkey) &amp;&amp;
<span class="p_add">+		    (lgr-&gt;rtokens[i][SMC_SINGLE_LINK].dma_addr == dma_addr) &amp;&amp;</span>
 		    test_bit(i, lgr-&gt;rtokens_used_mask)) {
 			conn-&gt;rtoken_idx = i;
 			return 0;
<span class="p_header">diff --git a/net/smc/smc_core.h b/net/smc/smc_core.h</span>
<span class="p_header">index 27eb38056a27..b013cb43a327 100644</span>
<span class="p_header">--- a/net/smc/smc_core.h</span>
<span class="p_header">+++ b/net/smc/smc_core.h</span>
<span class="p_chunk">@@ -93,7 +93,7 @@</span> <span class="p_context"> struct smc_buf_desc {</span>
 	u64			dma_addr[SMC_LINKS_PER_LGR_MAX];
 						/* mapped address of buffer */
 	void			*cpu_addr;	/* virtual address of buffer */
<span class="p_del">-	struct ib_mr		*mr_rx[SMC_LINKS_PER_LGR_MAX];</span>
<span class="p_add">+	u32			rkey[SMC_LINKS_PER_LGR_MAX];</span>
 						/* for rmb only:
 						 * rkey provided to peer
 						 */
<span class="p_header">diff --git a/net/smc/smc_ib.c b/net/smc/smc_ib.c</span>
<span class="p_header">index e6743c008ac5..51e5f0124f31 100644</span>
<span class="p_header">--- a/net/smc/smc_ib.c</span>
<span class="p_header">+++ b/net/smc/smc_ib.c</span>
<span class="p_chunk">@@ -37,24 +37,6 @@</span> <span class="p_context"> u8 local_systemid[SMC_SYSTEMID_LEN] = SMC_LOCAL_SYSTEMID_RESET;	/* unique system</span>
 								 * identifier
 								 */
 
<span class="p_del">-int smc_ib_get_memory_region(struct ib_pd *pd, int access_flags,</span>
<span class="p_del">-			     struct ib_mr **mr)</span>
<span class="p_del">-{</span>
<span class="p_del">-	int rc;</span>
<span class="p_del">-</span>
<span class="p_del">-	if (*mr)</span>
<span class="p_del">-		return 0; /* already done */</span>
<span class="p_del">-</span>
<span class="p_del">-	/* obtain unique key -</span>
<span class="p_del">-	 * next invocation of get_dma_mr returns a different key!</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	*mr = pd-&gt;device-&gt;get_dma_mr(pd, access_flags);</span>
<span class="p_del">-	rc = PTR_ERR_OR_ZERO(*mr);</span>
<span class="p_del">-	if (IS_ERR(*mr))</span>
<span class="p_del">-		*mr = NULL;</span>
<span class="p_del">-	return rc;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
 static int smc_ib_modify_qp_init(struct smc_link *lnk)
 {
 	struct ib_qp_attr qp_attr;
<span class="p_chunk">@@ -213,7 +195,8 @@</span> <span class="p_context"> int smc_ib_create_protection_domain(struct smc_link *lnk)</span>
 {
 	int rc;
 
<span class="p_del">-	lnk-&gt;roce_pd = ib_alloc_pd(lnk-&gt;smcibdev-&gt;ibdev, 0);</span>
<span class="p_add">+	lnk-&gt;roce_pd = ib_alloc_pd(lnk-&gt;smcibdev-&gt;ibdev,</span>
<span class="p_add">+				   IB_PD_UNSAFE_GLOBAL_RKEY);</span>
 	rc = PTR_ERR_OR_ZERO(lnk-&gt;roce_pd);
 	if (IS_ERR(lnk-&gt;roce_pd))
 		lnk-&gt;roce_pd = NULL;
<span class="p_header">diff --git a/net/smc/smc_ib.h b/net/smc/smc_ib.h</span>
<span class="p_header">index a95f74bb5569..cde21263287c 100644</span>
<span class="p_header">--- a/net/smc/smc_ib.h</span>
<span class="p_header">+++ b/net/smc/smc_ib.h</span>
<span class="p_chunk">@@ -60,8 +60,6 @@</span> <span class="p_context"> void smc_ib_dealloc_protection_domain(struct smc_link *lnk);</span>
 int smc_ib_create_protection_domain(struct smc_link *lnk);
 void smc_ib_destroy_queue_pair(struct smc_link *lnk);
 int smc_ib_create_queue_pair(struct smc_link *lnk);
<span class="p_del">-int smc_ib_get_memory_region(struct ib_pd *pd, int access_flags,</span>
<span class="p_del">-			     struct ib_mr **mr);</span>
 int smc_ib_ready_link(struct smc_link *lnk);
 int smc_ib_modify_qp_rts(struct smc_link *lnk);
 int smc_ib_modify_qp_reset(struct smc_link *lnk);
<span class="p_header">diff --git a/net/tipc/socket.c b/net/tipc/socket.c</span>
<span class="p_header">index bdce99f9407a..599c69bca8b9 100644</span>
<span class="p_header">--- a/net/tipc/socket.c</span>
<span class="p_header">+++ b/net/tipc/socket.c</span>
<span class="p_chunk">@@ -361,25 +361,25 @@</span> <span class="p_context"> static int tipc_sk_sock_err(struct socket *sock, long *timeout)</span>
 	return 0;
 }
 
<span class="p_del">-#define tipc_wait_for_cond(sock_, timeout_, condition_)			\</span>
<span class="p_del">-({								        \</span>
<span class="p_del">-	int rc_ = 0;							\</span>
<span class="p_del">-	int done_ = 0;							\</span>
<span class="p_del">-									\</span>
<span class="p_del">-	while (!(condition_) &amp;&amp; !done_) {				\</span>
<span class="p_del">-		struct sock *sk_ = sock-&gt;sk;				\</span>
<span class="p_del">-		DEFINE_WAIT_FUNC(wait_, woken_wake_function);		\</span>
<span class="p_del">-									\</span>
<span class="p_del">-		rc_ = tipc_sk_sock_err(sock_, timeout_);		\</span>
<span class="p_del">-		if (rc_)						\</span>
<span class="p_del">-			break;						\</span>
<span class="p_del">-		prepare_to_wait(sk_sleep(sk_), &amp;wait_,			\</span>
<span class="p_del">-				TASK_INTERRUPTIBLE);			\</span>
<span class="p_del">-		done_ = sk_wait_event(sk_, timeout_,			\</span>
<span class="p_del">-				      (condition_), &amp;wait_);		\</span>
<span class="p_del">-		remove_wait_queue(sk_sleep(sk_), &amp;wait_);		\</span>
<span class="p_del">-	}								\</span>
<span class="p_del">-	rc_;								\</span>
<span class="p_add">+#define tipc_wait_for_cond(sock_, timeo_, condition_)			       \</span>
<span class="p_add">+({                                                                             \</span>
<span class="p_add">+	struct sock *sk_;						       \</span>
<span class="p_add">+	int rc_;							       \</span>
<span class="p_add">+									       \</span>
<span class="p_add">+	while ((rc_ = !(condition_))) {					       \</span>
<span class="p_add">+		DEFINE_WAIT_FUNC(wait_, woken_wake_function);	               \</span>
<span class="p_add">+		sk_ = (sock_)-&gt;sk;					       \</span>
<span class="p_add">+		rc_ = tipc_sk_sock_err((sock_), timeo_);		       \</span>
<span class="p_add">+		if (rc_)						       \</span>
<span class="p_add">+			break;						       \</span>
<span class="p_add">+		prepare_to_wait(sk_sleep(sk_), &amp;wait_, TASK_INTERRUPTIBLE);    \</span>
<span class="p_add">+		release_sock(sk_);					       \</span>
<span class="p_add">+		*(timeo_) = wait_woken(&amp;wait_, TASK_INTERRUPTIBLE, *(timeo_)); \</span>
<span class="p_add">+		sched_annotate_sleep();				               \</span>
<span class="p_add">+		lock_sock(sk_);						       \</span>
<span class="p_add">+		remove_wait_queue(sk_sleep(sk_), &amp;wait_);		       \</span>
<span class="p_add">+	}								       \</span>
<span class="p_add">+	rc_;								       \</span>
 })
 
 /**
<span class="p_header">diff --git a/sound/pci/hda/patch_realtek.c b/sound/pci/hda/patch_realtek.c</span>
<span class="p_header">index 299835d1fbaa..1aa21d7e7245 100644</span>
<span class="p_header">--- a/sound/pci/hda/patch_realtek.c</span>
<span class="p_header">+++ b/sound/pci/hda/patch_realtek.c</span>
<span class="p_chunk">@@ -6276,8 +6276,11 @@</span> <span class="p_context"> static int patch_alc269(struct hda_codec *codec)</span>
 		break;
 	case 0x10ec0225:
 	case 0x10ec0295:
<span class="p_add">+		spec-&gt;codec_variant = ALC269_TYPE_ALC225;</span>
<span class="p_add">+		break;</span>
 	case 0x10ec0299:
 		spec-&gt;codec_variant = ALC269_TYPE_ALC225;
<span class="p_add">+		spec-&gt;gen.mixer_nid = 0; /* no loopback on ALC299 */</span>
 		break;
 	case 0x10ec0234:
 	case 0x10ec0274:
<span class="p_header">diff --git a/sound/pci/hda/patch_sigmatel.c b/sound/pci/hda/patch_sigmatel.c</span>
<span class="p_header">index faa3d38bac0b..6cefdf6c0b75 100644</span>
<span class="p_header">--- a/sound/pci/hda/patch_sigmatel.c</span>
<span class="p_header">+++ b/sound/pci/hda/patch_sigmatel.c</span>
<span class="p_chunk">@@ -1559,6 +1559,8 @@</span> <span class="p_context"> static const struct snd_pci_quirk stac9200_fixup_tbl[] = {</span>
 		      &quot;Dell Inspiron 1501&quot;, STAC_9200_DELL_M26),
 	SND_PCI_QUIRK(PCI_VENDOR_ID_DELL, 0x01f6,
 		      &quot;unknown Dell&quot;, STAC_9200_DELL_M26),
<span class="p_add">+	SND_PCI_QUIRK(PCI_VENDOR_ID_DELL, 0x0201,</span>
<span class="p_add">+		      &quot;Dell Latitude D430&quot;, STAC_9200_DELL_M22),</span>
 	/* Panasonic */
 	SND_PCI_QUIRK(0x10f7, 0x8338, &quot;Panasonic CF-74&quot;, STAC_9200_PANASONIC),
 	/* Gateway machines needs EAPD to be set on resume */
<span class="p_header">diff --git a/sound/usb/mixer_us16x08.c b/sound/usb/mixer_us16x08.c</span>
<span class="p_header">index dc48eedea92e..442d8f7998e3 100644</span>
<span class="p_header">--- a/sound/usb/mixer_us16x08.c</span>
<span class="p_header">+++ b/sound/usb/mixer_us16x08.c</span>
<span class="p_chunk">@@ -698,12 +698,12 @@</span> <span class="p_context"> static int snd_us16x08_meter_get(struct snd_kcontrol *kcontrol,</span>
 	struct snd_usb_audio *chip = elem-&gt;head.mixer-&gt;chip;
 	struct snd_us16x08_meter_store *store = elem-&gt;private_data;
 	u8 meter_urb[64];
<span class="p_del">-	char tmp[sizeof(mix_init_msg2)] = {0};</span>
<span class="p_add">+	char tmp[max(sizeof(mix_init_msg1), sizeof(mix_init_msg2))];</span>
 
 	switch (kcontrol-&gt;private_value) {
 	case 0:
<span class="p_del">-		snd_us16x08_send_urb(chip, (char *)mix_init_msg1,</span>
<span class="p_del">-				     sizeof(mix_init_msg1));</span>
<span class="p_add">+		memcpy(tmp, mix_init_msg1, sizeof(mix_init_msg1));</span>
<span class="p_add">+		snd_us16x08_send_urb(chip, tmp, 4);</span>
 		snd_us16x08_recv_urb(chip, meter_urb,
 			sizeof(meter_urb));
 		kcontrol-&gt;private_value++;
<span class="p_chunk">@@ -721,7 +721,7 @@</span> <span class="p_context"> static int snd_us16x08_meter_get(struct snd_kcontrol *kcontrol,</span>
 	case 3:
 		memcpy(tmp, mix_init_msg2, sizeof(mix_init_msg2));
 		tmp[2] = snd_get_meter_comp_index(store);
<span class="p_del">-		snd_us16x08_send_urb(chip, tmp, sizeof(mix_init_msg2));</span>
<span class="p_add">+		snd_us16x08_send_urb(chip, tmp, 10);</span>
 		snd_us16x08_recv_urb(chip, meter_urb,
 			sizeof(meter_urb));
 		kcontrol-&gt;private_value = 0;
<span class="p_chunk">@@ -1135,7 +1135,7 @@</span> <span class="p_context"> static const struct snd_us16x08_control_params eq_controls[] = {</span>
 		.control_id = SND_US16X08_ID_EQLOWMIDWIDTH,
 		.type = USB_MIXER_U8,
 		.num_channels = 16,
<span class="p_del">-		.name = &quot;EQ MidQLow Q&quot;,</span>
<span class="p_add">+		.name = &quot;EQ MidLow Q&quot;,</span>
 	},
 	{ /* EQ mid high gain */
 		.kcontrol_new = &amp;snd_us16x08_eq_gain_ctl,

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



