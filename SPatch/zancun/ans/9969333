
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>[PATCHv2] mm: Account pud page tables - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    [PATCHv2] mm: Account pud page tables</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=40781">Kirill A. Shutemov</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>Sept. 25, 2017, 7:39 a.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;20170925073913.22628-1-kirill.shutemov@linux.intel.com&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/9969333/mbox/"
   >mbox</a>
|
   <a href="/patch/9969333/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/9969333/">/patch/9969333/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
	[172.30.200.125])
	by pdx-korg-patchwork.web.codeaurora.org (Postfix) with ESMTP id
	2237A60365 for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Mon, 25 Sep 2017 07:40:35 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 12F9128B70
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Mon, 25 Sep 2017 07:40:35 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id CFD4D28B3F; Mon, 25 Sep 2017 07:40:34 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-6.9 required=2.0 tests=BAYES_00,RCVD_IN_DNSWL_HI
	autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 20D8928B30
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Mon, 25 Sep 2017 07:40:31 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S933864AbdIYHjk (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Mon, 25 Sep 2017 03:39:40 -0400
Received: from mga03.intel.com ([134.134.136.65]:15817 &quot;EHLO mga03.intel.com&quot;
	rhost-flags-OK-OK-OK-OK) by vger.kernel.org with ESMTP
	id S932909AbdIYHji (ORCPT &lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Mon, 25 Sep 2017 03:39:38 -0400
Received: from orsmga002.jf.intel.com ([10.7.209.21])
	by orsmga103.jf.intel.com with ESMTP/TLS/DHE-RSA-AES256-GCM-SHA384;
	25 Sep 2017 00:39:37 -0700
X-ExtLoop1: 1
X-IronPort-AV: E=Sophos;i=&quot;5.42,435,1500966000&quot;; d=&quot;scan&#39;208&quot;;a=&quot;139030379&quot;
Received: from black.fi.intel.com ([10.237.72.28])
	by orsmga002.jf.intel.com with ESMTP; 25 Sep 2017 00:39:22 -0700
Received: by black.fi.intel.com (Postfix, from userid 1000)
	id 27137B3; Mon, 25 Sep 2017 10:39:21 +0300 (EEST)
From: &quot;Kirill A. Shutemov&quot; &lt;kirill.shutemov@linux.intel.com&gt;
To: Andrew Morton &lt;akpm@linux-foundation.org&gt;
Cc: linux-mm@kvack.org, linux-kernel@vger.kernel.org,
	&quot;Kirill A. Shutemov&quot; &lt;kirill.shutemov@linux.intel.com&gt;,
	Michal Hocko &lt;mhocko@suse.com&gt;, Vlastimil Babka &lt;vbabka@suse.cz&gt;
Subject: [PATCHv2] mm: Account pud page tables
Date: Mon, 25 Sep 2017 10:39:13 +0300
Message-Id: &lt;20170925073913.22628-1-kirill.shutemov@linux.intel.com&gt;
X-Mailer: git-send-email 2.14.1
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=40781">Kirill A. Shutemov</a> - Sept. 25, 2017, 7:39 a.m.</div>
<pre class="content">
On machine with 5-level paging support a process can allocate
significant amount of memory and stay unnoticed by oom-killer and
memory cgroup. The trick is to allocate a lot of PUD page tables.
We don&#39;t account PUD page tables, only PMD and PTE.

We already addressed the same issue for PMD page tables, see
dc6c9a35b66b (&quot;mm: account pmd page tables to the process&quot;).
Introduction 5-level paging bring the same issue for PUD page tables.

The patch expands accounting to PUD level.
<span class="signed-off-by">
Signed-off-by: Kirill A. Shutemov &lt;kirill.shutemov@linux.intel.com&gt;</span>
Cc: Michal Hocko &lt;mhocko@suse.com&gt;
Cc: Vlastimil Babka &lt;vbabka@suse.cz&gt;
---
 Documentation/sysctl/vm.txt   |  8 ++++----
 arch/powerpc/mm/hugetlbpage.c |  1 +
 arch/sparc/mm/hugetlbpage.c   |  1 +
 fs/proc/task_mmu.c            |  5 ++++-
 include/linux/mm.h            | 34 ++++++++++++++++++++++++++++++++--
 include/linux/mm_types.h      |  3 +++
 kernel/fork.c                 |  4 ++++
 mm/debug.c                    |  6 ++++--
 mm/memory.c                   | 15 +++++++++------
 mm/oom_kill.c                 |  8 +++++---
 10 files changed, 67 insertions(+), 18 deletions(-)
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=137061">Michal Hocko</a> - Sept. 25, 2017, 11:54 a.m.</div>
<pre class="content">
On Mon 25-09-17 10:39:13, Kirill A. Shutemov wrote:
<span class="quote">&gt; On machine with 5-level paging support a process can allocate</span>
<span class="quote">&gt; significant amount of memory and stay unnoticed by oom-killer and</span>
<span class="quote">&gt; memory cgroup. The trick is to allocate a lot of PUD page tables.</span>
<span class="quote">&gt; We don&#39;t account PUD page tables, only PMD and PTE.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; We already addressed the same issue for PMD page tables, see</span>
<span class="quote">&gt; dc6c9a35b66b (&quot;mm: account pmd page tables to the process&quot;).</span>
<span class="quote">&gt; Introduction 5-level paging bring the same issue for PUD page tables.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; The patch expands accounting to PUD level.</span>

OK, we definitely need this or something like that but I really do not
like how much code we actually need for each pte level for accounting.
Do we really need to distinguish each level? Do we have any arch that
would use a different number of pages to back pte/pmd/pud?
<span class="quote">
&gt; Signed-off-by: Kirill A. Shutemov &lt;kirill.shutemov@linux.intel.com&gt;</span>
<span class="quote">&gt; Cc: Michal Hocko &lt;mhocko@suse.com&gt;</span>
<span class="quote">&gt; Cc: Vlastimil Babka &lt;vbabka@suse.cz&gt;</span>
<span class="quote">&gt; ---</span>
<span class="quote">&gt;  Documentation/sysctl/vm.txt   |  8 ++++----</span>
<span class="quote">&gt;  arch/powerpc/mm/hugetlbpage.c |  1 +</span>
<span class="quote">&gt;  arch/sparc/mm/hugetlbpage.c   |  1 +</span>
<span class="quote">&gt;  fs/proc/task_mmu.c            |  5 ++++-</span>
<span class="quote">&gt;  include/linux/mm.h            | 34 ++++++++++++++++++++++++++++++++--</span>
<span class="quote">&gt;  include/linux/mm_types.h      |  3 +++</span>
<span class="quote">&gt;  kernel/fork.c                 |  4 ++++</span>
<span class="quote">&gt;  mm/debug.c                    |  6 ++++--</span>
<span class="quote">&gt;  mm/memory.c                   | 15 +++++++++------</span>
<span class="quote">&gt;  mm/oom_kill.c                 |  8 +++++---</span>
<span class="quote">&gt;  10 files changed, 67 insertions(+), 18 deletions(-)</span>
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=874">Kirill A. Shutemov</a> - Sept. 25, 2017, 1:07 p.m.</div>
<pre class="content">
On Mon, Sep 25, 2017 at 01:54:30PM +0200, Michal Hocko wrote:
<span class="quote">&gt; On Mon 25-09-17 10:39:13, Kirill A. Shutemov wrote:</span>
<span class="quote">&gt; &gt; On machine with 5-level paging support a process can allocate</span>
<span class="quote">&gt; &gt; significant amount of memory and stay unnoticed by oom-killer and</span>
<span class="quote">&gt; &gt; memory cgroup. The trick is to allocate a lot of PUD page tables.</span>
<span class="quote">&gt; &gt; We don&#39;t account PUD page tables, only PMD and PTE.</span>
<span class="quote">&gt; &gt; </span>
<span class="quote">&gt; &gt; We already addressed the same issue for PMD page tables, see</span>
<span class="quote">&gt; &gt; dc6c9a35b66b (&quot;mm: account pmd page tables to the process&quot;).</span>
<span class="quote">&gt; &gt; Introduction 5-level paging bring the same issue for PUD page tables.</span>
<span class="quote">&gt; &gt; </span>
<span class="quote">&gt; &gt; The patch expands accounting to PUD level.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; OK, we definitely need this or something like that but I really do not</span>
<span class="quote">&gt; like how much code we actually need for each pte level for accounting.</span>
<span class="quote">&gt; Do we really need to distinguish each level? Do we have any arch that</span>
<span class="quote">&gt; would use a different number of pages to back pte/pmd/pud?</span>

Looks like we actually do. At least on mips. See PMD_ORDER/PUD_ORDER.
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=137061">Michal Hocko</a> - Sept. 25, 2017, 1:53 p.m.</div>
<pre class="content">
On Mon 25-09-17 16:07:15, Kirill A. Shutemov wrote:
<span class="quote">&gt; On Mon, Sep 25, 2017 at 01:54:30PM +0200, Michal Hocko wrote:</span>
<span class="quote">&gt; &gt; On Mon 25-09-17 10:39:13, Kirill A. Shutemov wrote:</span>
<span class="quote">&gt; &gt; &gt; On machine with 5-level paging support a process can allocate</span>
<span class="quote">&gt; &gt; &gt; significant amount of memory and stay unnoticed by oom-killer and</span>
<span class="quote">&gt; &gt; &gt; memory cgroup. The trick is to allocate a lot of PUD page tables.</span>
<span class="quote">&gt; &gt; &gt; We don&#39;t account PUD page tables, only PMD and PTE.</span>
<span class="quote">&gt; &gt; &gt; </span>
<span class="quote">&gt; &gt; &gt; We already addressed the same issue for PMD page tables, see</span>
<span class="quote">&gt; &gt; &gt; dc6c9a35b66b (&quot;mm: account pmd page tables to the process&quot;).</span>
<span class="quote">&gt; &gt; &gt; Introduction 5-level paging bring the same issue for PUD page tables.</span>
<span class="quote">&gt; &gt; &gt; </span>
<span class="quote">&gt; &gt; &gt; The patch expands accounting to PUD level.</span>
<span class="quote">&gt; &gt; </span>
<span class="quote">&gt; &gt; OK, we definitely need this or something like that but I really do not</span>
<span class="quote">&gt; &gt; like how much code we actually need for each pte level for accounting.</span>
<span class="quote">&gt; &gt; Do we really need to distinguish each level? Do we have any arch that</span>
<span class="quote">&gt; &gt; would use a different number of pages to back pte/pmd/pud?</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Looks like we actually do. At least on mips. See PMD_ORDER/PUD_ORDER.</span>

Hmm, but then oom_badness does consider them a single page which is
wrong. I haven&#39;t checked other users. Anyway even if we&#39;ve had different
sizes why cannot we deal with this in callers. They know which level of
page table they allocate/free, no?
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=874">Kirill A. Shutemov</a> - Sept. 26, 2017, 9:43 a.m.</div>
<pre class="content">
On Mon, Sep 25, 2017 at 03:53:05PM +0200, Michal Hocko wrote:
<span class="quote">&gt; On Mon 25-09-17 16:07:15, Kirill A. Shutemov wrote:</span>
<span class="quote">&gt; &gt; On Mon, Sep 25, 2017 at 01:54:30PM +0200, Michal Hocko wrote:</span>
<span class="quote">&gt; &gt; &gt; On Mon 25-09-17 10:39:13, Kirill A. Shutemov wrote:</span>
<span class="quote">&gt; &gt; &gt; &gt; On machine with 5-level paging support a process can allocate</span>
<span class="quote">&gt; &gt; &gt; &gt; significant amount of memory and stay unnoticed by oom-killer and</span>
<span class="quote">&gt; &gt; &gt; &gt; memory cgroup. The trick is to allocate a lot of PUD page tables.</span>
<span class="quote">&gt; &gt; &gt; &gt; We don&#39;t account PUD page tables, only PMD and PTE.</span>
<span class="quote">&gt; &gt; &gt; &gt; </span>
<span class="quote">&gt; &gt; &gt; &gt; We already addressed the same issue for PMD page tables, see</span>
<span class="quote">&gt; &gt; &gt; &gt; dc6c9a35b66b (&quot;mm: account pmd page tables to the process&quot;).</span>
<span class="quote">&gt; &gt; &gt; &gt; Introduction 5-level paging bring the same issue for PUD page tables.</span>
<span class="quote">&gt; &gt; &gt; &gt; </span>
<span class="quote">&gt; &gt; &gt; &gt; The patch expands accounting to PUD level.</span>
<span class="quote">&gt; &gt; &gt; </span>
<span class="quote">&gt; &gt; &gt; OK, we definitely need this or something like that but I really do not</span>
<span class="quote">&gt; &gt; &gt; like how much code we actually need for each pte level for accounting.</span>
<span class="quote">&gt; &gt; &gt; Do we really need to distinguish each level? Do we have any arch that</span>
<span class="quote">&gt; &gt; &gt; would use a different number of pages to back pte/pmd/pud?</span>
<span class="quote">&gt; &gt; </span>
<span class="quote">&gt; &gt; Looks like we actually do. At least on mips. See PMD_ORDER/PUD_ORDER.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Hmm, but then oom_badness does consider them a single page which is</span>
<span class="quote">&gt; wrong. I haven&#39;t checked other users. Anyway even if we&#39;ve had different</span>
<span class="quote">&gt; sizes why cannot we deal with this in callers. They know which level of</span>
<span class="quote">&gt; page table they allocate/free, no?</span>

So do you want to see single counter for all page table levels?
Do we have anybody who relies on VmPTE/VmPMD now?
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=137061">Michal Hocko</a> - Sept. 26, 2017, 10:14 a.m.</div>
<pre class="content">
On Tue 26-09-17 12:43:44, Kirill A. Shutemov wrote:
<span class="quote">&gt; On Mon, Sep 25, 2017 at 03:53:05PM +0200, Michal Hocko wrote:</span>
<span class="quote">&gt; &gt; On Mon 25-09-17 16:07:15, Kirill A. Shutemov wrote:</span>
<span class="quote">&gt; &gt; &gt; On Mon, Sep 25, 2017 at 01:54:30PM +0200, Michal Hocko wrote:</span>
<span class="quote">&gt; &gt; &gt; &gt; On Mon 25-09-17 10:39:13, Kirill A. Shutemov wrote:</span>
<span class="quote">&gt; &gt; &gt; &gt; &gt; On machine with 5-level paging support a process can allocate</span>
<span class="quote">&gt; &gt; &gt; &gt; &gt; significant amount of memory and stay unnoticed by oom-killer and</span>
<span class="quote">&gt; &gt; &gt; &gt; &gt; memory cgroup. The trick is to allocate a lot of PUD page tables.</span>
<span class="quote">&gt; &gt; &gt; &gt; &gt; We don&#39;t account PUD page tables, only PMD and PTE.</span>
<span class="quote">&gt; &gt; &gt; &gt; &gt; </span>
<span class="quote">&gt; &gt; &gt; &gt; &gt; We already addressed the same issue for PMD page tables, see</span>
<span class="quote">&gt; &gt; &gt; &gt; &gt; dc6c9a35b66b (&quot;mm: account pmd page tables to the process&quot;).</span>
<span class="quote">&gt; &gt; &gt; &gt; &gt; Introduction 5-level paging bring the same issue for PUD page tables.</span>
<span class="quote">&gt; &gt; &gt; &gt; &gt; </span>
<span class="quote">&gt; &gt; &gt; &gt; &gt; The patch expands accounting to PUD level.</span>
<span class="quote">&gt; &gt; &gt; &gt; </span>
<span class="quote">&gt; &gt; &gt; &gt; OK, we definitely need this or something like that but I really do not</span>
<span class="quote">&gt; &gt; &gt; &gt; like how much code we actually need for each pte level for accounting.</span>
<span class="quote">&gt; &gt; &gt; &gt; Do we really need to distinguish each level? Do we have any arch that</span>
<span class="quote">&gt; &gt; &gt; &gt; would use a different number of pages to back pte/pmd/pud?</span>
<span class="quote">&gt; &gt; &gt; </span>
<span class="quote">&gt; &gt; &gt; Looks like we actually do. At least on mips. See PMD_ORDER/PUD_ORDER.</span>
<span class="quote">&gt; &gt; </span>
<span class="quote">&gt; &gt; Hmm, but then oom_badness does consider them a single page which is</span>
<span class="quote">&gt; &gt; wrong. I haven&#39;t checked other users. Anyway even if we&#39;ve had different</span>
<span class="quote">&gt; &gt; sizes why cannot we deal with this in callers. They know which level of</span>
<span class="quote">&gt; &gt; page table they allocate/free, no?</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; So do you want to see single counter for all page table levels?</span>

I think it would make the code easier to maintain and follow. As a
follow up for this patch which I am willing to ack.
<span class="quote">
&gt; Do we have anybody who relies on VmPTE/VmPMD now?</span>

No idea. I would just account everything to the pte level. If somebody
complains we can revert that part. But the value has been exported since
dc6c9a35b66b (&quot;mm: account pmd page tables to the process&quot;) and I
suspect you have done so just to keep it in sync the existing VmPTE
without an explicit usecase in mind, right?
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=137061">Michal Hocko</a> - Sept. 26, 2017, 10:17 a.m.</div>
<pre class="content">
On Mon 25-09-17 10:39:13, Kirill A. Shutemov wrote:
<span class="quote">&gt; On machine with 5-level paging support a process can allocate</span>
<span class="quote">&gt; significant amount of memory and stay unnoticed by oom-killer and</span>
<span class="quote">&gt; memory cgroup. The trick is to allocate a lot of PUD page tables.</span>
<span class="quote">&gt; We don&#39;t account PUD page tables, only PMD and PTE.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; We already addressed the same issue for PMD page tables, see</span>
<span class="quote">&gt; dc6c9a35b66b (&quot;mm: account pmd page tables to the process&quot;).</span>
<span class="quote">&gt; Introduction 5-level paging bring the same issue for PUD page tables.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; The patch expands accounting to PUD level.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Signed-off-by: Kirill A. Shutemov &lt;kirill.shutemov@linux.intel.com&gt;</span>
<span class="quote">&gt; Cc: Michal Hocko &lt;mhocko@suse.com&gt;</span>
<span class="quote">&gt; Cc: Vlastimil Babka &lt;vbabka@suse.cz&gt;</span>

So just for the reference. You can assume my
<span class="acked-by">Acked-by: Michal Hocko &lt;mhocko@suse.com&gt;</span>

it seems that no arch has PUD_ORDER &gt; 0 so the oom part works correctly.
As mentioned in other email I think we should actually simplify the
whole thing and use a single counter for all pte levels. This will
remove some code and make this whole thing less error prone.
<span class="quote">
&gt; ---</span>
<span class="quote">&gt;  Documentation/sysctl/vm.txt   |  8 ++++----</span>
<span class="quote">&gt;  arch/powerpc/mm/hugetlbpage.c |  1 +</span>
<span class="quote">&gt;  arch/sparc/mm/hugetlbpage.c   |  1 +</span>
<span class="quote">&gt;  fs/proc/task_mmu.c            |  5 ++++-</span>
<span class="quote">&gt;  include/linux/mm.h            | 34 ++++++++++++++++++++++++++++++++--</span>
<span class="quote">&gt;  include/linux/mm_types.h      |  3 +++</span>
<span class="quote">&gt;  kernel/fork.c                 |  4 ++++</span>
<span class="quote">&gt;  mm/debug.c                    |  6 ++++--</span>
<span class="quote">&gt;  mm/memory.c                   | 15 +++++++++------</span>
<span class="quote">&gt;  mm/oom_kill.c                 |  8 +++++---</span>
<span class="quote">&gt;  10 files changed, 67 insertions(+), 18 deletions(-)</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; diff --git a/Documentation/sysctl/vm.txt b/Documentation/sysctl/vm.txt</span>
<span class="quote">&gt; index 9baf66a9ef4e..2717b6f2d706 100644</span>
<span class="quote">&gt; --- a/Documentation/sysctl/vm.txt</span>
<span class="quote">&gt; +++ b/Documentation/sysctl/vm.txt</span>
<span class="quote">&gt; @@ -622,10 +622,10 @@ oom_dump_tasks</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  Enables a system-wide task dump (excluding kernel threads) to be produced</span>
<span class="quote">&gt;  when the kernel performs an OOM-killing and includes such information as</span>
<span class="quote">&gt; -pid, uid, tgid, vm size, rss, nr_ptes, nr_pmds, swapents, oom_score_adj</span>
<span class="quote">&gt; -score, and name.  This is helpful to determine why the OOM killer was</span>
<span class="quote">&gt; -invoked, to identify the rogue task that caused it, and to determine why</span>
<span class="quote">&gt; -the OOM killer chose the task it did to kill.</span>
<span class="quote">&gt; +pid, uid, tgid, vm size, rss, nr_ptes, nr_pmds, nr_puds, swapents,</span>
<span class="quote">&gt; +oom_score_adj score, and name.  This is helpful to determine why the OOM</span>
<span class="quote">&gt; +killer was invoked, to identify the rogue task that caused it, and to</span>
<span class="quote">&gt; +determine why the OOM killer chose the task it did to kill.</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  If this is set to zero, this information is suppressed.  On very</span>
<span class="quote">&gt;  large systems with thousands of tasks it may not be feasible to dump</span>
<span class="quote">&gt; diff --git a/arch/powerpc/mm/hugetlbpage.c b/arch/powerpc/mm/hugetlbpage.c</span>
<span class="quote">&gt; index 1571a498a33f..a9b9083c5e49 100644</span>
<span class="quote">&gt; --- a/arch/powerpc/mm/hugetlbpage.c</span>
<span class="quote">&gt; +++ b/arch/powerpc/mm/hugetlbpage.c</span>
<span class="quote">&gt; @@ -433,6 +433,7 @@ static void hugetlb_free_pud_range(struct mmu_gather *tlb, pgd_t *pgd,</span>
<span class="quote">&gt;  	pud = pud_offset(pgd, start);</span>
<span class="quote">&gt;  	pgd_clear(pgd);</span>
<span class="quote">&gt;  	pud_free_tlb(tlb, pud, start);</span>
<span class="quote">&gt; +	mm_dec_nr_puds(tlb-&gt;mm);</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  /*</span>
<span class="quote">&gt; diff --git a/arch/sparc/mm/hugetlbpage.c b/arch/sparc/mm/hugetlbpage.c</span>
<span class="quote">&gt; index bcd8cdbc377f..fd0d85808828 100644</span>
<span class="quote">&gt; --- a/arch/sparc/mm/hugetlbpage.c</span>
<span class="quote">&gt; +++ b/arch/sparc/mm/hugetlbpage.c</span>
<span class="quote">&gt; @@ -471,6 +471,7 @@ static void hugetlb_free_pud_range(struct mmu_gather *tlb, pgd_t *pgd,</span>
<span class="quote">&gt;  	pud = pud_offset(pgd, start);</span>
<span class="quote">&gt;  	pgd_clear(pgd);</span>
<span class="quote">&gt;  	pud_free_tlb(tlb, pud, start);</span>
<span class="quote">&gt; +	mm_dec_nr_puds(tlb-&gt;mm);</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  void hugetlb_free_pgd_range(struct mmu_gather *tlb,</span>
<span class="quote">&gt; diff --git a/fs/proc/task_mmu.c b/fs/proc/task_mmu.c</span>
<span class="quote">&gt; index 5589b4bd4b85..0bf9e423aa99 100644</span>
<span class="quote">&gt; --- a/fs/proc/task_mmu.c</span>
<span class="quote">&gt; +++ b/fs/proc/task_mmu.c</span>
<span class="quote">&gt; @@ -25,7 +25,7 @@</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  void task_mem(struct seq_file *m, struct mm_struct *mm)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt; -	unsigned long text, lib, swap, ptes, pmds, anon, file, shmem;</span>
<span class="quote">&gt; +	unsigned long text, lib, swap, ptes, pmds, puds, anon, file, shmem;</span>
<span class="quote">&gt;  	unsigned long hiwater_vm, total_vm, hiwater_rss, total_rss;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	anon = get_mm_counter(mm, MM_ANONPAGES);</span>
<span class="quote">&gt; @@ -51,6 +51,7 @@ void task_mem(struct seq_file *m, struct mm_struct *mm)</span>
<span class="quote">&gt;  	swap = get_mm_counter(mm, MM_SWAPENTS);</span>
<span class="quote">&gt;  	ptes = PTRS_PER_PTE * sizeof(pte_t) * atomic_long_read(&amp;mm-&gt;nr_ptes);</span>
<span class="quote">&gt;  	pmds = PTRS_PER_PMD * sizeof(pmd_t) * mm_nr_pmds(mm);</span>
<span class="quote">&gt; +	puds = PTRS_PER_PUD * sizeof(pmd_t) * mm_nr_puds(mm);</span>
<span class="quote">&gt;  	seq_printf(m,</span>
<span class="quote">&gt;  		&quot;VmPeak:\t%8lu kB\n&quot;</span>
<span class="quote">&gt;  		&quot;VmSize:\t%8lu kB\n&quot;</span>
<span class="quote">&gt; @@ -67,6 +68,7 @@ void task_mem(struct seq_file *m, struct mm_struct *mm)</span>
<span class="quote">&gt;  		&quot;VmLib:\t%8lu kB\n&quot;</span>
<span class="quote">&gt;  		&quot;VmPTE:\t%8lu kB\n&quot;</span>
<span class="quote">&gt;  		&quot;VmPMD:\t%8lu kB\n&quot;</span>
<span class="quote">&gt; +		&quot;VmPUD:\t%8lu kB\n&quot;</span>
<span class="quote">&gt;  		&quot;VmSwap:\t%8lu kB\n&quot;,</span>
<span class="quote">&gt;  		hiwater_vm &lt;&lt; (PAGE_SHIFT-10),</span>
<span class="quote">&gt;  		total_vm &lt;&lt; (PAGE_SHIFT-10),</span>
<span class="quote">&gt; @@ -81,6 +83,7 @@ void task_mem(struct seq_file *m, struct mm_struct *mm)</span>
<span class="quote">&gt;  		mm-&gt;stack_vm &lt;&lt; (PAGE_SHIFT-10), text, lib,</span>
<span class="quote">&gt;  		ptes &gt;&gt; 10,</span>
<span class="quote">&gt;  		pmds &gt;&gt; 10,</span>
<span class="quote">&gt; +		puds &gt;&gt; 10,</span>
<span class="quote">&gt;  		swap &lt;&lt; (PAGE_SHIFT-10));</span>
<span class="quote">&gt;  	hugetlb_report_usage(m, mm);</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt; diff --git a/include/linux/mm.h b/include/linux/mm.h</span>
<span class="quote">&gt; index f8c10d336e42..c5eb8c609599 100644</span>
<span class="quote">&gt; --- a/include/linux/mm.h</span>
<span class="quote">&gt; +++ b/include/linux/mm.h</span>
<span class="quote">&gt; @@ -1604,8 +1604,38 @@ static inline int __pud_alloc(struct mm_struct *mm, p4d_t *p4d,</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	return 0;</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +static inline unsigned long mm_nr_puds(const struct mm_struct *mm)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	return 0;</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +static inline void mm_nr_puds_init(struct mm_struct *mm) {}</span>
<span class="quote">&gt; +static inline void mm_inc_nr_puds(struct mm_struct *mm) {}</span>
<span class="quote">&gt; +static inline void mm_dec_nr_puds(struct mm_struct *mm) {}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt;  #else</span>
<span class="quote">&gt;  int __pud_alloc(struct mm_struct *mm, p4d_t *p4d, unsigned long address);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +static inline void mm_nr_puds_init(struct mm_struct *mm)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	atomic_long_set(&amp;mm-&gt;nr_puds, 0);</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +static inline unsigned long mm_nr_puds(const struct mm_struct *mm)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	return atomic_long_read(&amp;mm-&gt;nr_puds);</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +static inline void mm_inc_nr_puds(struct mm_struct *mm)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	atomic_long_inc(&amp;mm-&gt;nr_puds);</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +static inline void mm_dec_nr_puds(struct mm_struct *mm)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	atomic_long_dec(&amp;mm-&gt;nr_puds);</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt;  #endif</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  #if defined(__PAGETABLE_PMD_FOLDED) || !defined(CONFIG_MMU)</span>
<span class="quote">&gt; @@ -1617,7 +1647,7 @@ static inline int __pmd_alloc(struct mm_struct *mm, pud_t *pud,</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  static inline void mm_nr_pmds_init(struct mm_struct *mm) {}</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; -static inline unsigned long mm_nr_pmds(struct mm_struct *mm)</span>
<span class="quote">&gt; +static inline unsigned long mm_nr_pmds(const struct mm_struct *mm)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	return 0;</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt; @@ -1633,7 +1663,7 @@ static inline void mm_nr_pmds_init(struct mm_struct *mm)</span>
<span class="quote">&gt;  	atomic_long_set(&amp;mm-&gt;nr_pmds, 0);</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; -static inline unsigned long mm_nr_pmds(struct mm_struct *mm)</span>
<span class="quote">&gt; +static inline unsigned long mm_nr_pmds(const struct mm_struct *mm)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	return atomic_long_read(&amp;mm-&gt;nr_pmds);</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt; diff --git a/include/linux/mm_types.h b/include/linux/mm_types.h</span>
<span class="quote">&gt; index 46f4ecf5479a..6c8c2bb9e5a1 100644</span>
<span class="quote">&gt; --- a/include/linux/mm_types.h</span>
<span class="quote">&gt; +++ b/include/linux/mm_types.h</span>
<span class="quote">&gt; @@ -401,6 +401,9 @@ struct mm_struct {</span>
<span class="quote">&gt;  	atomic_long_t nr_ptes;			/* PTE page table pages */</span>
<span class="quote">&gt;  #if CONFIG_PGTABLE_LEVELS &gt; 2</span>
<span class="quote">&gt;  	atomic_long_t nr_pmds;			/* PMD page table pages */</span>
<span class="quote">&gt; +#endif</span>
<span class="quote">&gt; +#if CONFIG_PGTABLE_LEVELS &gt; 3</span>
<span class="quote">&gt; +	atomic_long_t nr_puds;			/* PUD page table pages */</span>
<span class="quote">&gt;  #endif</span>
<span class="quote">&gt;  	int map_count;				/* number of VMAs */</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; diff --git a/kernel/fork.c b/kernel/fork.c</span>
<span class="quote">&gt; index 10646182440f..5624918154db 100644</span>
<span class="quote">&gt; --- a/kernel/fork.c</span>
<span class="quote">&gt; +++ b/kernel/fork.c</span>
<span class="quote">&gt; @@ -815,6 +815,7 @@ static struct mm_struct *mm_init(struct mm_struct *mm, struct task_struct *p,</span>
<span class="quote">&gt;  	mm-&gt;core_state = NULL;</span>
<span class="quote">&gt;  	atomic_long_set(&amp;mm-&gt;nr_ptes, 0);</span>
<span class="quote">&gt;  	mm_nr_pmds_init(mm);</span>
<span class="quote">&gt; +	mm_nr_puds_init(mm);</span>
<span class="quote">&gt;  	mm-&gt;map_count = 0;</span>
<span class="quote">&gt;  	mm-&gt;locked_vm = 0;</span>
<span class="quote">&gt;  	mm-&gt;pinned_vm = 0;</span>
<span class="quote">&gt; @@ -874,6 +875,9 @@ static void check_mm(struct mm_struct *mm)</span>
<span class="quote">&gt;  	if (mm_nr_pmds(mm))</span>
<span class="quote">&gt;  		pr_alert(&quot;BUG: non-zero nr_pmds on freeing mm: %ld\n&quot;,</span>
<span class="quote">&gt;  				mm_nr_pmds(mm));</span>
<span class="quote">&gt; +	if (mm_nr_puds(mm))</span>
<span class="quote">&gt; +		pr_alert(&quot;BUG: non-zero nr_puds on freeing mm: %ld\n&quot;,</span>
<span class="quote">&gt; +				mm_nr_puds(mm));</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  #if defined(CONFIG_TRANSPARENT_HUGEPAGE) &amp;&amp; !USE_SPLIT_PMD_PTLOCKS</span>
<span class="quote">&gt;  	VM_BUG_ON_MM(mm-&gt;pmd_huge_pte, mm);</span>
<span class="quote">&gt; diff --git a/mm/debug.c b/mm/debug.c</span>
<span class="quote">&gt; index 5715448ab0b5..afccb2565269 100644</span>
<span class="quote">&gt; --- a/mm/debug.c</span>
<span class="quote">&gt; +++ b/mm/debug.c</span>
<span class="quote">&gt; @@ -104,7 +104,8 @@ void dump_mm(const struct mm_struct *mm)</span>
<span class="quote">&gt;  		&quot;get_unmapped_area %p\n&quot;</span>
<span class="quote">&gt;  #endif</span>
<span class="quote">&gt;  		&quot;mmap_base %lu mmap_legacy_base %lu highest_vm_end %lu\n&quot;</span>
<span class="quote">&gt; -		&quot;pgd %p mm_users %d mm_count %d nr_ptes %lu nr_pmds %lu map_count %d\n&quot;</span>
<span class="quote">&gt; +		&quot;pgd %p mm_users %d mm_count %d\n&quot;</span>
<span class="quote">&gt; +		&quot;nr_ptes %lu nr_pmds %lu nr_puds %lu map_count %d\n&quot;</span>
<span class="quote">&gt;  		&quot;hiwater_rss %lx hiwater_vm %lx total_vm %lx locked_vm %lx\n&quot;</span>
<span class="quote">&gt;  		&quot;pinned_vm %lx data_vm %lx exec_vm %lx stack_vm %lx\n&quot;</span>
<span class="quote">&gt;  		&quot;start_code %lx end_code %lx start_data %lx end_data %lx\n&quot;</span>
<span class="quote">&gt; @@ -135,7 +136,8 @@ void dump_mm(const struct mm_struct *mm)</span>
<span class="quote">&gt;  		mm-&gt;pgd, atomic_read(&amp;mm-&gt;mm_users),</span>
<span class="quote">&gt;  		atomic_read(&amp;mm-&gt;mm_count),</span>
<span class="quote">&gt;  		atomic_long_read((atomic_long_t *)&amp;mm-&gt;nr_ptes),</span>
<span class="quote">&gt; -		mm_nr_pmds((struct mm_struct *)mm),</span>
<span class="quote">&gt; +		mm_nr_pmds(mm),</span>
<span class="quote">&gt; +		mm_nr_puds(mm),</span>
<span class="quote">&gt;  		mm-&gt;map_count,</span>
<span class="quote">&gt;  		mm-&gt;hiwater_rss, mm-&gt;hiwater_vm, mm-&gt;total_vm, mm-&gt;locked_vm,</span>
<span class="quote">&gt;  		mm-&gt;pinned_vm, mm-&gt;data_vm, mm-&gt;exec_vm, mm-&gt;stack_vm,</span>
<span class="quote">&gt; diff --git a/mm/memory.c b/mm/memory.c</span>
<span class="quote">&gt; index ec4e15494901..8f49fdafac56 100644</span>
<span class="quote">&gt; --- a/mm/memory.c</span>
<span class="quote">&gt; +++ b/mm/memory.c</span>
<span class="quote">&gt; @@ -506,6 +506,7 @@ static inline void free_pud_range(struct mmu_gather *tlb, p4d_t *p4d,</span>
<span class="quote">&gt;  	pud = pud_offset(p4d, start);</span>
<span class="quote">&gt;  	p4d_clear(p4d);</span>
<span class="quote">&gt;  	pud_free_tlb(tlb, pud, start);</span>
<span class="quote">&gt; +	mm_dec_nr_puds(tlb-&gt;mm);</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  static inline void free_p4d_range(struct mmu_gather *tlb, pgd_t *pgd,</span>
<span class="quote">&gt; @@ -4124,15 +4125,17 @@ int __pud_alloc(struct mm_struct *mm, p4d_t *p4d, unsigned long address)</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	spin_lock(&amp;mm-&gt;page_table_lock);</span>
<span class="quote">&gt;  #ifndef __ARCH_HAS_5LEVEL_HACK</span>
<span class="quote">&gt; -	if (p4d_present(*p4d))		/* Another has populated it */</span>
<span class="quote">&gt; -		pud_free(mm, new);</span>
<span class="quote">&gt; -	else</span>
<span class="quote">&gt; +	if (!p4d_present(*p4d)) {</span>
<span class="quote">&gt; +		mm_inc_nr_puds(mm);</span>
<span class="quote">&gt;  		p4d_populate(mm, p4d, new);</span>
<span class="quote">&gt; -#else</span>
<span class="quote">&gt; -	if (pgd_present(*p4d))		/* Another has populated it */</span>
<span class="quote">&gt; +	} else	/* Another has populated it */</span>
<span class="quote">&gt;  		pud_free(mm, new);</span>
<span class="quote">&gt; -	else</span>
<span class="quote">&gt; +#else</span>
<span class="quote">&gt; +	if (!pgd_present(*pud)) {</span>
<span class="quote">&gt; +		mm_inc_nr_puds(mm);</span>
<span class="quote">&gt;  		pgd_populate(mm, p4d, new);</span>
<span class="quote">&gt; +	} else	/* Another has populated it */</span>
<span class="quote">&gt; +		pud_free(mm, new);</span>
<span class="quote">&gt;  #endif /* __ARCH_HAS_5LEVEL_HACK */</span>
<span class="quote">&gt;  	spin_unlock(&amp;mm-&gt;page_table_lock);</span>
<span class="quote">&gt;  	return 0;</span>
<span class="quote">&gt; diff --git a/mm/oom_kill.c b/mm/oom_kill.c</span>
<span class="quote">&gt; index 99736e026712..4bee6968885d 100644</span>
<span class="quote">&gt; --- a/mm/oom_kill.c</span>
<span class="quote">&gt; +++ b/mm/oom_kill.c</span>
<span class="quote">&gt; @@ -200,7 +200,8 @@ unsigned long oom_badness(struct task_struct *p, struct mem_cgroup *memcg,</span>
<span class="quote">&gt;  	 * task&#39;s rss, pagetable and swap space use.</span>
<span class="quote">&gt;  	 */</span>
<span class="quote">&gt;  	points = get_mm_rss(p-&gt;mm) + get_mm_counter(p-&gt;mm, MM_SWAPENTS) +</span>
<span class="quote">&gt; -		atomic_long_read(&amp;p-&gt;mm-&gt;nr_ptes) + mm_nr_pmds(p-&gt;mm);</span>
<span class="quote">&gt; +		atomic_long_read(&amp;p-&gt;mm-&gt;nr_ptes) + mm_nr_pmds(p-&gt;mm) +</span>
<span class="quote">&gt; +		mm_nr_puds(p-&gt;mm);</span>
<span class="quote">&gt;  	task_unlock(p);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	/*</span>
<span class="quote">&gt; @@ -376,7 +377,7 @@ static void dump_tasks(struct mem_cgroup *memcg, const nodemask_t *nodemask)</span>
<span class="quote">&gt;  	struct task_struct *p;</span>
<span class="quote">&gt;  	struct task_struct *task;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; -	pr_info(&quot;[ pid ]   uid  tgid total_vm      rss nr_ptes nr_pmds swapents oom_score_adj name\n&quot;);</span>
<span class="quote">&gt; +	pr_info(&quot;[ pid ]   uid  tgid total_vm      rss nr_ptes nr_pmds nr_puds swapents oom_score_adj name\n&quot;);</span>
<span class="quote">&gt;  	rcu_read_lock();</span>
<span class="quote">&gt;  	for_each_process(p) {</span>
<span class="quote">&gt;  		if (oom_unkillable_task(p, memcg, nodemask))</span>
<span class="quote">&gt; @@ -392,11 +393,12 @@ static void dump_tasks(struct mem_cgroup *memcg, const nodemask_t *nodemask)</span>
<span class="quote">&gt;  			continue;</span>
<span class="quote">&gt;  		}</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; -		pr_info(&quot;[%5d] %5d %5d %8lu %8lu %7ld %7ld %8lu         %5hd %s\n&quot;,</span>
<span class="quote">&gt; +		pr_info(&quot;[%5d] %5d %5d %8lu %8lu %7ld %7ld %7ld %8lu         %5hd %s\n&quot;,</span>
<span class="quote">&gt;  			task-&gt;pid, from_kuid(&amp;init_user_ns, task_uid(task)),</span>
<span class="quote">&gt;  			task-&gt;tgid, task-&gt;mm-&gt;total_vm, get_mm_rss(task-&gt;mm),</span>
<span class="quote">&gt;  			atomic_long_read(&amp;task-&gt;mm-&gt;nr_ptes),</span>
<span class="quote">&gt;  			mm_nr_pmds(task-&gt;mm),</span>
<span class="quote">&gt; +			mm_nr_puds(task-&gt;mm),</span>
<span class="quote">&gt;  			get_mm_counter(task-&gt;mm, MM_SWAPENTS),</span>
<span class="quote">&gt;  			task-&gt;signal-&gt;oom_score_adj, task-&gt;comm);</span>
<span class="quote">&gt;  		task_unlock(task);</span>
<span class="quote">&gt; -- </span>
<span class="quote">&gt; 2.14.1</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; --</span>
<span class="quote">&gt; To unsubscribe, send a message with &#39;unsubscribe linux-mm&#39; in</span>
<span class="quote">&gt; the body to majordomo@kvack.org.  For more info on Linux MM,</span>
<span class="quote">&gt; see: http://www.linux-mm.org/ .</span>
<span class="quote">&gt; Don&#39;t email: &lt;a href=mailto:&quot;dont@kvack.org&quot;&gt; email@kvack.org &lt;/a&gt;</span>
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=143191">kbuild test robot</a> - Oct. 1, 2017, 12:38 a.m.</div>
<pre class="content">
Hi Kirill,

[auto build test ERROR on linus/master]
[also build test ERROR on v4.14-rc2]
[cannot apply to next-20170929]
[if your patch is applied to the wrong git tree, please drop us a note to help improve the system]

url:    https://github.com/0day-ci/linux/commits/Kirill-A-Shutemov/mm-Account-pud-page-tables/20170926-031536
config: microblaze-nommu_defconfig (attached as .config)
compiler: microblaze-linux-gcc (GCC) 6.2.0
reproduce:
        wget https://raw.githubusercontent.com/intel/lkp-tests/master/sbin/make.cross -O ~/bin/make.cross
        chmod +x ~/bin/make.cross
        # save the attached .config to linux build tree
        make.cross ARCH=microblaze 

All errors (new ones prefixed by &gt;&gt;):

   In file included from arch/microblaze/include/uapi/asm/byteorder.h:7:0,
                    from include/asm-generic/bitops/le.h:5,
                    from include/asm-generic/bitops.h:34,
                    from ./arch/microblaze/include/generated/asm/bitops.h:1,
                    from include/linux/bitops.h:37,
                    from include/linux/kernel.h:10,
                    from include/asm-generic/bug.h:15,
                    from ./arch/microblaze/include/generated/asm/bug.h:1,
                    from include/linux/bug.h:4,
                    from include/linux/page-flags.h:9,
                    from kernel/bounds.c:9:
   include/linux/byteorder/big_endian.h:7:2: warning: #warning inconsistent configuration, needs CONFIG_CPU_BIG_ENDIAN [-Wcpp]
    #warning inconsistent configuration, needs CONFIG_CPU_BIG_ENDIAN
     ^~~~~~~
   In file included from arch/microblaze/include/uapi/asm/byteorder.h:7:0,
                    from include/asm-generic/bitops/le.h:5,
                    from include/asm-generic/bitops.h:34,
                    from ./arch/microblaze/include/generated/asm/bitops.h:1,
                    from include/linux/bitops.h:37,
                    from include/linux/kernel.h:10,
                    from include/linux/list.h:8,
                    from include/linux/rculist.h:9,
                    from include/linux/pid.h:4,
                    from include/linux/sched.h:13,
                    from arch/microblaze/kernel/asm-offsets.c:13:
   include/linux/byteorder/big_endian.h:7:2: warning: #warning inconsistent configuration, needs CONFIG_CPU_BIG_ENDIAN [-Wcpp]
    #warning inconsistent configuration, needs CONFIG_CPU_BIG_ENDIAN
     ^~~~~~~
   In file included from arch/microblaze/include/asm/io.h:17:0,
                    from include/linux/io.h:25,
                    from include/linux/irq.h:24,
                    from include/asm-generic/hardirq.h:12,
                    from ./arch/microblaze/include/generated/asm/hardirq.h:1,
                    from include/linux/hardirq.h:8,
                    from include/linux/interrupt.h:12,
                    from include/linux/kernel_stat.h:8,
                    from arch/microblaze/kernel/asm-offsets.c:14:
   include/linux/mm.h: In function &#39;mm_nr_puds_init&#39;:
<span class="quote">&gt;&gt; include/linux/mm.h:1622:21: error: &#39;struct mm_struct&#39; has no member named &#39;nr_puds&#39;; did you mean &#39;nr_ptes&#39;?</span>
     atomic_long_set(&amp;mm-&gt;nr_puds, 0);
                        ^~
   include/linux/mm.h: In function &#39;mm_nr_puds&#39;:
<span class="quote">&gt;&gt; include/linux/mm.h:1627:29: error: &#39;const struct mm_struct&#39; has no member named &#39;nr_puds&#39;; did you mean &#39;nr_ptes&#39;?</span>
     return atomic_long_read(&amp;mm-&gt;nr_puds);
                                ^~
   include/linux/mm.h: In function &#39;mm_inc_nr_puds&#39;:
   include/linux/mm.h:1632:21: error: &#39;struct mm_struct&#39; has no member named &#39;nr_puds&#39;; did you mean &#39;nr_ptes&#39;?
     atomic_long_inc(&amp;mm-&gt;nr_puds);
                        ^~
   include/linux/mm.h: In function &#39;mm_dec_nr_puds&#39;:
   include/linux/mm.h:1637:21: error: &#39;struct mm_struct&#39; has no member named &#39;nr_puds&#39;; did you mean &#39;nr_ptes&#39;?
     atomic_long_dec(&amp;mm-&gt;nr_puds);
                        ^~
   make[2]: *** [arch/microblaze/kernel/asm-offsets.s] Error 1
   make[2]: Target &#39;__build&#39; not remade because of errors.
   make[1]: *** [prepare0] Error 2
   make[1]: Target &#39;prepare&#39; not remade because of errors.
   make: *** [sub-make] Error 2

vim +1622 include/linux/mm.h

  1619	
  1620	static inline void mm_nr_puds_init(struct mm_struct *mm)
  1621	{
<span class="quote">&gt; 1622		atomic_long_set(&amp;mm-&gt;nr_puds, 0);</span>
  1623	}
  1624	
  1625	static inline unsigned long mm_nr_puds(const struct mm_struct *mm)
  1626	{
<span class="quote">&gt; 1627		return atomic_long_read(&amp;mm-&gt;nr_puds);</span>
  1628	}
  1629	

---
0-DAY kernel test infrastructure                Open Source Technology Center
https://lists.01.org/pipermail/kbuild-all                   Intel Corporation
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=143191">kbuild test robot</a> - Oct. 1, 2017, 1:03 a.m.</div>
<pre class="content">
Hi Kirill,

[auto build test ERROR on linus/master]
[also build test ERROR on v4.14-rc2]
[cannot apply to next-20170929]
[if your patch is applied to the wrong git tree, please drop us a note to help improve the system]

url:    https://github.com/0day-ci/linux/commits/Kirill-A-Shutemov/mm-Account-pud-page-tables/20170926-031536
config: powerpc-powernv_defconfig (attached as .config)
compiler: powerpc64-linux-gnu-gcc (Debian 6.1.1-9) 6.1.1 20160705
reproduce:
        wget https://raw.githubusercontent.com/intel/lkp-tests/master/sbin/make.cross -O ~/bin/make.cross
        chmod +x ~/bin/make.cross
        # save the attached .config to linux build tree
        make.cross ARCH=powerpc 

All errors (new ones prefixed by &gt;&gt;):

   mm/memory.c: In function &#39;__pud_alloc&#39;:
<span class="quote">&gt;&gt; mm/memory.c:4134:20: error: &#39;pud&#39; undeclared (first use in this function)</span>
     if (!pgd_present(*pud)) {
                       ^~~
   mm/memory.c:4134:20: note: each undeclared identifier is reported only once for each function it appears in

vim +/pud +4134 mm/memory.c

  4112	
  4113	#ifndef __PAGETABLE_PUD_FOLDED
  4114	/*
  4115	 * Allocate page upper directory.
  4116	 * We&#39;ve already handled the fast-path in-line.
  4117	 */
  4118	int __pud_alloc(struct mm_struct *mm, p4d_t *p4d, unsigned long address)
  4119	{
  4120		pud_t *new = pud_alloc_one(mm, address);
  4121		if (!new)
  4122			return -ENOMEM;
  4123	
  4124		smp_wmb(); /* See comment in __pte_alloc */
  4125	
  4126		spin_lock(&amp;mm-&gt;page_table_lock);
  4127	#ifndef __ARCH_HAS_5LEVEL_HACK
  4128		if (!p4d_present(*p4d)) {
  4129			mm_inc_nr_puds(mm);
  4130			p4d_populate(mm, p4d, new);
  4131		} else	/* Another has populated it */
  4132			pud_free(mm, new);
  4133	#else
<span class="quote">&gt; 4134		if (!pgd_present(*pud)) {</span>
  4135			mm_inc_nr_puds(mm);
  4136			pgd_populate(mm, p4d, new);
  4137		} else	/* Another has populated it */
  4138			pud_free(mm, new);
  4139	#endif /* __ARCH_HAS_5LEVEL_HACK */
  4140		spin_unlock(&amp;mm-&gt;page_table_lock);
  4141		return 0;
  4142	}
  4143	#endif /* __PAGETABLE_PUD_FOLDED */
  4144	

---
0-DAY kernel test infrastructure                Open Source Technology Center
https://lists.01.org/pipermail/kbuild-all                   Intel Corporation
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/Documentation/sysctl/vm.txt b/Documentation/sysctl/vm.txt</span>
<span class="p_header">index 9baf66a9ef4e..2717b6f2d706 100644</span>
<span class="p_header">--- a/Documentation/sysctl/vm.txt</span>
<span class="p_header">+++ b/Documentation/sysctl/vm.txt</span>
<span class="p_chunk">@@ -622,10 +622,10 @@</span> <span class="p_context"> oom_dump_tasks</span>
 
 Enables a system-wide task dump (excluding kernel threads) to be produced
 when the kernel performs an OOM-killing and includes such information as
<span class="p_del">-pid, uid, tgid, vm size, rss, nr_ptes, nr_pmds, swapents, oom_score_adj</span>
<span class="p_del">-score, and name.  This is helpful to determine why the OOM killer was</span>
<span class="p_del">-invoked, to identify the rogue task that caused it, and to determine why</span>
<span class="p_del">-the OOM killer chose the task it did to kill.</span>
<span class="p_add">+pid, uid, tgid, vm size, rss, nr_ptes, nr_pmds, nr_puds, swapents,</span>
<span class="p_add">+oom_score_adj score, and name.  This is helpful to determine why the OOM</span>
<span class="p_add">+killer was invoked, to identify the rogue task that caused it, and to</span>
<span class="p_add">+determine why the OOM killer chose the task it did to kill.</span>
 
 If this is set to zero, this information is suppressed.  On very
 large systems with thousands of tasks it may not be feasible to dump
<span class="p_header">diff --git a/arch/powerpc/mm/hugetlbpage.c b/arch/powerpc/mm/hugetlbpage.c</span>
<span class="p_header">index 1571a498a33f..a9b9083c5e49 100644</span>
<span class="p_header">--- a/arch/powerpc/mm/hugetlbpage.c</span>
<span class="p_header">+++ b/arch/powerpc/mm/hugetlbpage.c</span>
<span class="p_chunk">@@ -433,6 +433,7 @@</span> <span class="p_context"> static void hugetlb_free_pud_range(struct mmu_gather *tlb, pgd_t *pgd,</span>
 	pud = pud_offset(pgd, start);
 	pgd_clear(pgd);
 	pud_free_tlb(tlb, pud, start);
<span class="p_add">+	mm_dec_nr_puds(tlb-&gt;mm);</span>
 }
 
 /*
<span class="p_header">diff --git a/arch/sparc/mm/hugetlbpage.c b/arch/sparc/mm/hugetlbpage.c</span>
<span class="p_header">index bcd8cdbc377f..fd0d85808828 100644</span>
<span class="p_header">--- a/arch/sparc/mm/hugetlbpage.c</span>
<span class="p_header">+++ b/arch/sparc/mm/hugetlbpage.c</span>
<span class="p_chunk">@@ -471,6 +471,7 @@</span> <span class="p_context"> static void hugetlb_free_pud_range(struct mmu_gather *tlb, pgd_t *pgd,</span>
 	pud = pud_offset(pgd, start);
 	pgd_clear(pgd);
 	pud_free_tlb(tlb, pud, start);
<span class="p_add">+	mm_dec_nr_puds(tlb-&gt;mm);</span>
 }
 
 void hugetlb_free_pgd_range(struct mmu_gather *tlb,
<span class="p_header">diff --git a/fs/proc/task_mmu.c b/fs/proc/task_mmu.c</span>
<span class="p_header">index 5589b4bd4b85..0bf9e423aa99 100644</span>
<span class="p_header">--- a/fs/proc/task_mmu.c</span>
<span class="p_header">+++ b/fs/proc/task_mmu.c</span>
<span class="p_chunk">@@ -25,7 +25,7 @@</span> <span class="p_context"></span>
 
 void task_mem(struct seq_file *m, struct mm_struct *mm)
 {
<span class="p_del">-	unsigned long text, lib, swap, ptes, pmds, anon, file, shmem;</span>
<span class="p_add">+	unsigned long text, lib, swap, ptes, pmds, puds, anon, file, shmem;</span>
 	unsigned long hiwater_vm, total_vm, hiwater_rss, total_rss;
 
 	anon = get_mm_counter(mm, MM_ANONPAGES);
<span class="p_chunk">@@ -51,6 +51,7 @@</span> <span class="p_context"> void task_mem(struct seq_file *m, struct mm_struct *mm)</span>
 	swap = get_mm_counter(mm, MM_SWAPENTS);
 	ptes = PTRS_PER_PTE * sizeof(pte_t) * atomic_long_read(&amp;mm-&gt;nr_ptes);
 	pmds = PTRS_PER_PMD * sizeof(pmd_t) * mm_nr_pmds(mm);
<span class="p_add">+	puds = PTRS_PER_PUD * sizeof(pmd_t) * mm_nr_puds(mm);</span>
 	seq_printf(m,
 		&quot;VmPeak:\t%8lu kB\n&quot;
 		&quot;VmSize:\t%8lu kB\n&quot;
<span class="p_chunk">@@ -67,6 +68,7 @@</span> <span class="p_context"> void task_mem(struct seq_file *m, struct mm_struct *mm)</span>
 		&quot;VmLib:\t%8lu kB\n&quot;
 		&quot;VmPTE:\t%8lu kB\n&quot;
 		&quot;VmPMD:\t%8lu kB\n&quot;
<span class="p_add">+		&quot;VmPUD:\t%8lu kB\n&quot;</span>
 		&quot;VmSwap:\t%8lu kB\n&quot;,
 		hiwater_vm &lt;&lt; (PAGE_SHIFT-10),
 		total_vm &lt;&lt; (PAGE_SHIFT-10),
<span class="p_chunk">@@ -81,6 +83,7 @@</span> <span class="p_context"> void task_mem(struct seq_file *m, struct mm_struct *mm)</span>
 		mm-&gt;stack_vm &lt;&lt; (PAGE_SHIFT-10), text, lib,
 		ptes &gt;&gt; 10,
 		pmds &gt;&gt; 10,
<span class="p_add">+		puds &gt;&gt; 10,</span>
 		swap &lt;&lt; (PAGE_SHIFT-10));
 	hugetlb_report_usage(m, mm);
 }
<span class="p_header">diff --git a/include/linux/mm.h b/include/linux/mm.h</span>
<span class="p_header">index f8c10d336e42..c5eb8c609599 100644</span>
<span class="p_header">--- a/include/linux/mm.h</span>
<span class="p_header">+++ b/include/linux/mm.h</span>
<span class="p_chunk">@@ -1604,8 +1604,38 @@</span> <span class="p_context"> static inline int __pud_alloc(struct mm_struct *mm, p4d_t *p4d,</span>
 {
 	return 0;
 }
<span class="p_add">+</span>
<span class="p_add">+static inline unsigned long mm_nr_puds(const struct mm_struct *mm)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return 0;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline void mm_nr_puds_init(struct mm_struct *mm) {}</span>
<span class="p_add">+static inline void mm_inc_nr_puds(struct mm_struct *mm) {}</span>
<span class="p_add">+static inline void mm_dec_nr_puds(struct mm_struct *mm) {}</span>
<span class="p_add">+</span>
 #else
 int __pud_alloc(struct mm_struct *mm, p4d_t *p4d, unsigned long address);
<span class="p_add">+</span>
<span class="p_add">+static inline void mm_nr_puds_init(struct mm_struct *mm)</span>
<span class="p_add">+{</span>
<span class="p_add">+	atomic_long_set(&amp;mm-&gt;nr_puds, 0);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline unsigned long mm_nr_puds(const struct mm_struct *mm)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return atomic_long_read(&amp;mm-&gt;nr_puds);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline void mm_inc_nr_puds(struct mm_struct *mm)</span>
<span class="p_add">+{</span>
<span class="p_add">+	atomic_long_inc(&amp;mm-&gt;nr_puds);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline void mm_dec_nr_puds(struct mm_struct *mm)</span>
<span class="p_add">+{</span>
<span class="p_add">+	atomic_long_dec(&amp;mm-&gt;nr_puds);</span>
<span class="p_add">+}</span>
 #endif
 
 #if defined(__PAGETABLE_PMD_FOLDED) || !defined(CONFIG_MMU)
<span class="p_chunk">@@ -1617,7 +1647,7 @@</span> <span class="p_context"> static inline int __pmd_alloc(struct mm_struct *mm, pud_t *pud,</span>
 
 static inline void mm_nr_pmds_init(struct mm_struct *mm) {}
 
<span class="p_del">-static inline unsigned long mm_nr_pmds(struct mm_struct *mm)</span>
<span class="p_add">+static inline unsigned long mm_nr_pmds(const struct mm_struct *mm)</span>
 {
 	return 0;
 }
<span class="p_chunk">@@ -1633,7 +1663,7 @@</span> <span class="p_context"> static inline void mm_nr_pmds_init(struct mm_struct *mm)</span>
 	atomic_long_set(&amp;mm-&gt;nr_pmds, 0);
 }
 
<span class="p_del">-static inline unsigned long mm_nr_pmds(struct mm_struct *mm)</span>
<span class="p_add">+static inline unsigned long mm_nr_pmds(const struct mm_struct *mm)</span>
 {
 	return atomic_long_read(&amp;mm-&gt;nr_pmds);
 }
<span class="p_header">diff --git a/include/linux/mm_types.h b/include/linux/mm_types.h</span>
<span class="p_header">index 46f4ecf5479a..6c8c2bb9e5a1 100644</span>
<span class="p_header">--- a/include/linux/mm_types.h</span>
<span class="p_header">+++ b/include/linux/mm_types.h</span>
<span class="p_chunk">@@ -401,6 +401,9 @@</span> <span class="p_context"> struct mm_struct {</span>
 	atomic_long_t nr_ptes;			/* PTE page table pages */
 #if CONFIG_PGTABLE_LEVELS &gt; 2
 	atomic_long_t nr_pmds;			/* PMD page table pages */
<span class="p_add">+#endif</span>
<span class="p_add">+#if CONFIG_PGTABLE_LEVELS &gt; 3</span>
<span class="p_add">+	atomic_long_t nr_puds;			/* PUD page table pages */</span>
 #endif
 	int map_count;				/* number of VMAs */
 
<span class="p_header">diff --git a/kernel/fork.c b/kernel/fork.c</span>
<span class="p_header">index 10646182440f..5624918154db 100644</span>
<span class="p_header">--- a/kernel/fork.c</span>
<span class="p_header">+++ b/kernel/fork.c</span>
<span class="p_chunk">@@ -815,6 +815,7 @@</span> <span class="p_context"> static struct mm_struct *mm_init(struct mm_struct *mm, struct task_struct *p,</span>
 	mm-&gt;core_state = NULL;
 	atomic_long_set(&amp;mm-&gt;nr_ptes, 0);
 	mm_nr_pmds_init(mm);
<span class="p_add">+	mm_nr_puds_init(mm);</span>
 	mm-&gt;map_count = 0;
 	mm-&gt;locked_vm = 0;
 	mm-&gt;pinned_vm = 0;
<span class="p_chunk">@@ -874,6 +875,9 @@</span> <span class="p_context"> static void check_mm(struct mm_struct *mm)</span>
 	if (mm_nr_pmds(mm))
 		pr_alert(&quot;BUG: non-zero nr_pmds on freeing mm: %ld\n&quot;,
 				mm_nr_pmds(mm));
<span class="p_add">+	if (mm_nr_puds(mm))</span>
<span class="p_add">+		pr_alert(&quot;BUG: non-zero nr_puds on freeing mm: %ld\n&quot;,</span>
<span class="p_add">+				mm_nr_puds(mm));</span>
 
 #if defined(CONFIG_TRANSPARENT_HUGEPAGE) &amp;&amp; !USE_SPLIT_PMD_PTLOCKS
 	VM_BUG_ON_MM(mm-&gt;pmd_huge_pte, mm);
<span class="p_header">diff --git a/mm/debug.c b/mm/debug.c</span>
<span class="p_header">index 5715448ab0b5..afccb2565269 100644</span>
<span class="p_header">--- a/mm/debug.c</span>
<span class="p_header">+++ b/mm/debug.c</span>
<span class="p_chunk">@@ -104,7 +104,8 @@</span> <span class="p_context"> void dump_mm(const struct mm_struct *mm)</span>
 		&quot;get_unmapped_area %p\n&quot;
 #endif
 		&quot;mmap_base %lu mmap_legacy_base %lu highest_vm_end %lu\n&quot;
<span class="p_del">-		&quot;pgd %p mm_users %d mm_count %d nr_ptes %lu nr_pmds %lu map_count %d\n&quot;</span>
<span class="p_add">+		&quot;pgd %p mm_users %d mm_count %d\n&quot;</span>
<span class="p_add">+		&quot;nr_ptes %lu nr_pmds %lu nr_puds %lu map_count %d\n&quot;</span>
 		&quot;hiwater_rss %lx hiwater_vm %lx total_vm %lx locked_vm %lx\n&quot;
 		&quot;pinned_vm %lx data_vm %lx exec_vm %lx stack_vm %lx\n&quot;
 		&quot;start_code %lx end_code %lx start_data %lx end_data %lx\n&quot;
<span class="p_chunk">@@ -135,7 +136,8 @@</span> <span class="p_context"> void dump_mm(const struct mm_struct *mm)</span>
 		mm-&gt;pgd, atomic_read(&amp;mm-&gt;mm_users),
 		atomic_read(&amp;mm-&gt;mm_count),
 		atomic_long_read((atomic_long_t *)&amp;mm-&gt;nr_ptes),
<span class="p_del">-		mm_nr_pmds((struct mm_struct *)mm),</span>
<span class="p_add">+		mm_nr_pmds(mm),</span>
<span class="p_add">+		mm_nr_puds(mm),</span>
 		mm-&gt;map_count,
 		mm-&gt;hiwater_rss, mm-&gt;hiwater_vm, mm-&gt;total_vm, mm-&gt;locked_vm,
 		mm-&gt;pinned_vm, mm-&gt;data_vm, mm-&gt;exec_vm, mm-&gt;stack_vm,
<span class="p_header">diff --git a/mm/memory.c b/mm/memory.c</span>
<span class="p_header">index ec4e15494901..8f49fdafac56 100644</span>
<span class="p_header">--- a/mm/memory.c</span>
<span class="p_header">+++ b/mm/memory.c</span>
<span class="p_chunk">@@ -506,6 +506,7 @@</span> <span class="p_context"> static inline void free_pud_range(struct mmu_gather *tlb, p4d_t *p4d,</span>
 	pud = pud_offset(p4d, start);
 	p4d_clear(p4d);
 	pud_free_tlb(tlb, pud, start);
<span class="p_add">+	mm_dec_nr_puds(tlb-&gt;mm);</span>
 }
 
 static inline void free_p4d_range(struct mmu_gather *tlb, pgd_t *pgd,
<span class="p_chunk">@@ -4124,15 +4125,17 @@</span> <span class="p_context"> int __pud_alloc(struct mm_struct *mm, p4d_t *p4d, unsigned long address)</span>
 
 	spin_lock(&amp;mm-&gt;page_table_lock);
 #ifndef __ARCH_HAS_5LEVEL_HACK
<span class="p_del">-	if (p4d_present(*p4d))		/* Another has populated it */</span>
<span class="p_del">-		pud_free(mm, new);</span>
<span class="p_del">-	else</span>
<span class="p_add">+	if (!p4d_present(*p4d)) {</span>
<span class="p_add">+		mm_inc_nr_puds(mm);</span>
 		p4d_populate(mm, p4d, new);
<span class="p_del">-#else</span>
<span class="p_del">-	if (pgd_present(*p4d))		/* Another has populated it */</span>
<span class="p_add">+	} else	/* Another has populated it */</span>
 		pud_free(mm, new);
<span class="p_del">-	else</span>
<span class="p_add">+#else</span>
<span class="p_add">+	if (!pgd_present(*pud)) {</span>
<span class="p_add">+		mm_inc_nr_puds(mm);</span>
 		pgd_populate(mm, p4d, new);
<span class="p_add">+	} else	/* Another has populated it */</span>
<span class="p_add">+		pud_free(mm, new);</span>
 #endif /* __ARCH_HAS_5LEVEL_HACK */
 	spin_unlock(&amp;mm-&gt;page_table_lock);
 	return 0;
<span class="p_header">diff --git a/mm/oom_kill.c b/mm/oom_kill.c</span>
<span class="p_header">index 99736e026712..4bee6968885d 100644</span>
<span class="p_header">--- a/mm/oom_kill.c</span>
<span class="p_header">+++ b/mm/oom_kill.c</span>
<span class="p_chunk">@@ -200,7 +200,8 @@</span> <span class="p_context"> unsigned long oom_badness(struct task_struct *p, struct mem_cgroup *memcg,</span>
 	 * task&#39;s rss, pagetable and swap space use.
 	 */
 	points = get_mm_rss(p-&gt;mm) + get_mm_counter(p-&gt;mm, MM_SWAPENTS) +
<span class="p_del">-		atomic_long_read(&amp;p-&gt;mm-&gt;nr_ptes) + mm_nr_pmds(p-&gt;mm);</span>
<span class="p_add">+		atomic_long_read(&amp;p-&gt;mm-&gt;nr_ptes) + mm_nr_pmds(p-&gt;mm) +</span>
<span class="p_add">+		mm_nr_puds(p-&gt;mm);</span>
 	task_unlock(p);
 
 	/*
<span class="p_chunk">@@ -376,7 +377,7 @@</span> <span class="p_context"> static void dump_tasks(struct mem_cgroup *memcg, const nodemask_t *nodemask)</span>
 	struct task_struct *p;
 	struct task_struct *task;
 
<span class="p_del">-	pr_info(&quot;[ pid ]   uid  tgid total_vm      rss nr_ptes nr_pmds swapents oom_score_adj name\n&quot;);</span>
<span class="p_add">+	pr_info(&quot;[ pid ]   uid  tgid total_vm      rss nr_ptes nr_pmds nr_puds swapents oom_score_adj name\n&quot;);</span>
 	rcu_read_lock();
 	for_each_process(p) {
 		if (oom_unkillable_task(p, memcg, nodemask))
<span class="p_chunk">@@ -392,11 +393,12 @@</span> <span class="p_context"> static void dump_tasks(struct mem_cgroup *memcg, const nodemask_t *nodemask)</span>
 			continue;
 		}
 
<span class="p_del">-		pr_info(&quot;[%5d] %5d %5d %8lu %8lu %7ld %7ld %8lu         %5hd %s\n&quot;,</span>
<span class="p_add">+		pr_info(&quot;[%5d] %5d %5d %8lu %8lu %7ld %7ld %7ld %8lu         %5hd %s\n&quot;,</span>
 			task-&gt;pid, from_kuid(&amp;init_user_ns, task_uid(task)),
 			task-&gt;tgid, task-&gt;mm-&gt;total_vm, get_mm_rss(task-&gt;mm),
 			atomic_long_read(&amp;task-&gt;mm-&gt;nr_ptes),
 			mm_nr_pmds(task-&gt;mm),
<span class="p_add">+			mm_nr_puds(task-&gt;mm),</span>
 			get_mm_counter(task-&gt;mm, MM_SWAPENTS),
 			task-&gt;signal-&gt;oom_score_adj, task-&gt;comm);
 		task_unlock(task);

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



