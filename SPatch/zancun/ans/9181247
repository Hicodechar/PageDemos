
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>[v3] Linux VM workaround for Knights Landing A/D leak - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    [v3] Linux VM workaround for Knights Landing A/D leak</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=115261">lukasz.anaczkowski@intel.com</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>June 16, 2016, 3:14 p.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;1466090042-30908-1-git-send-email-lukasz.anaczkowski@intel.com&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/9181247/mbox/"
   >mbox</a>
|
   <a href="/patch/9181247/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/9181247/">/patch/9181247/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
	[172.30.200.125])
	by pdx-korg-patchwork.web.codeaurora.org (Postfix) with ESMTP id
	B57116075D for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Thu, 16 Jun 2016 15:15:13 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id A53D02835E
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Thu, 16 Jun 2016 15:15:13 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id 9A22C28372; Thu, 16 Jun 2016 15:15:13 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-6.9 required=2.0 tests=BAYES_00,RCVD_IN_DNSWL_HI
	autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id C76752835E
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Thu, 16 Jun 2016 15:15:12 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1755084AbcFPPPF (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Thu, 16 Jun 2016 11:15:05 -0400
Received: from mga02.intel.com ([134.134.136.20]:63769 &quot;EHLO mga02.intel.com&quot;
	rhost-flags-OK-OK-OK-OK) by vger.kernel.org with ESMTP
	id S1754245AbcFPPO7 (ORCPT &lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Thu, 16 Jun 2016 11:14:59 -0400
Received: from fmsmga001.fm.intel.com ([10.253.24.23])
	by orsmga101.jf.intel.com with ESMTP; 16 Jun 2016 08:14:24 -0700
X-ExtLoop1: 1
X-IronPort-AV: E=Sophos;i=&quot;5.26,480,1459839600&quot;; d=&quot;scan&#39;208&quot;;a=&quot;988847744&quot;
Received: from gklab-125-033.igk.intel.com ([10.91.125.33])
	by fmsmga001.fm.intel.com with ESMTP; 16 Jun 2016 08:14:22 -0700
From: Lukasz Anaczkowski &lt;lukasz.anaczkowski@intel.com&gt;
To: hpa@zytor.com, mingo@redhat.com, tglx@linutronix.de,
	dave.hansen@linux.intel.com, ak@linux.intel.com,
	kirill.shutemov@linux.intel.com, mhocko@suse.com,
	akpm@linux-foundation.org, linux-kernel@vger.kernel.org,
	linux-mm@kvack.org
Cc: lukasz.anaczkowski@intel.com, harish.srinivasappa@intel.com,
	lukasz.odzioba@intel.com, grzegorz.andrejczuk@intel.com,
	lukasz.daniluk@intel.com
Subject: [PATCH v3] Linux VM workaround for Knights Landing A/D leak
Date: Thu, 16 Jun 2016 17:14:02 +0200
Message-Id: &lt;1466090042-30908-1-git-send-email-lukasz.anaczkowski@intel.com&gt;
X-Mailer: git-send-email 1.8.3.1
In-Reply-To: &lt;1465923672-14232-1-git-send-email-lukasz.anaczkowski@intel.com&gt;
References: &lt;1465923672-14232-1-git-send-email-lukasz.anaczkowski@intel.com&gt;
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=115261">lukasz.anaczkowski@intel.com</a> - June 16, 2016, 3:14 p.m.</div>
<pre class="content">
<span class="from">From: Andi Kleen &lt;ak@linux.intel.com&gt;</span>

Knights Landing has an issue that a thread setting A or D bits
may not do so atomically against checking the present bit.
A thread which is going to page fault may still set those
bits, even though the present bit was already atomically cleared.

This implies that when the kernel clears present atomically,
some time later the supposed to be zero entry could be corrupted
with stray A or D bits.

Since the PTE could be already used for storing a swap index,
or a NUMA migration index, this cannot be tolerated. Most
of the time the kernel detects the problem, but in some
rare cases it may not.

This patch enforces that the page unmap path in vmscan/direct reclaim
always flushes other CPUs after clearing each page, and also
clears the PTE again after the flush. A new memory barrier may be
required, but this code is at least consistent with all
the existing uses in the kernel. If we decide that we need a new
barrier, it can added at the same time as the rest of the tree.

For reclaim this brings the performance back to before Mel&#39;s
flushing changes, but for unmap it disables batching.

This makes sure any leaked A/D bits are immediately cleared before the entry
is used for something else.

Any parallel faults that check for entry is zero may loop,
but they should eventually recover after the entry is written.

Also other users may spin in the page table lock until we
&quot;fixed&quot; the PTE. This is ensured by always taking the page table lock
even for the swap cache case. Previously this was only done
on architectures with non atomic PTE accesses (such as 32bit PTE),
but now it is also done when this bug workaround is active.

I audited apply_pte_range and other users of arch_enter_lazy...
and they seem to all not clear the present bit.

Right now the extra flush is done in the low level
architecture code, while the higher level code still
does batched TLB flush. This means there is always one extra
unnecessary TLB flush now. As a followon optimization
this could be avoided by telling the callers that
the flush already happenend.

The official erratum will be posted hopefully by the end of July&#39;16.

v3 (Lukasz Anaczkowski):
    () Improved documentation
    () Removed unnecessary declaration and call to fix_pte_leak from hugetlb.h
    () Moved fix_pte_leak() definition from tlb.c to intel.c
    () Replaced boot_cpu_has_bug() with static_cpu_has_bug()
    () pr_info_once instead of pr_info
    () Fix applies only to 64-bit kernels as Knights Landing does not
       support 32-bit kernels

v2 (Lukasz Anaczkowski):
    () added call to smp_mb__after_atomic() to synchornize with
       switch_mm, based on Nadav&#39;s comment
    () fixed compilation breakage
<span class="signed-off-by">
Signed-off-by: Andi Kleen &lt;ak@linux.intel.com&gt;</span>
<span class="signed-off-by">Signed-off-by: Lukasz Anaczkowski &lt;lukasz.anaczkowski@intel.com&gt;</span>
---
 arch/x86/include/asm/cpufeatures.h |  1 +
 arch/x86/include/asm/pgtable.h     | 10 ++++++++++
 arch/x86/include/asm/pgtable_64.h  | 16 +++++++++++++++
 arch/x86/kernel/cpu/intel.c        | 41 ++++++++++++++++++++++++++++++++++++++
 include/linux/mm.h                 |  4 ++++
 mm/memory.c                        |  3 ++-
 6 files changed, 74 insertions(+), 1 deletion(-)
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=55071">Nadav Amit</a> - June 16, 2016, 4:43 p.m.</div>
<pre class="content">
Lukasz Anaczkowski &lt;lukasz.anaczkowski@intel.com&gt; wrote:
<span class="quote">
&gt; From: Andi Kleen &lt;ak@linux.intel.com&gt;</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; +void fix_pte_leak(struct mm_struct *mm, unsigned long addr, pte_t *ptep)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	if (cpumask_any_but(mm_cpumask(mm), smp_processor_id()) &lt; nr_cpu_ids) {</span>
<span class="quote">&gt; +		trace_tlb_flush(TLB_LOCAL_SHOOTDOWN, TLB_FLUSH_ALL);</span>
This tracing seems incorrect since you don’t perform a local flush.
I don’t think you need any tracing - native_flush_tlb_others will do it for you.
<span class="quote">
&gt; +		flush_tlb_others(mm_cpumask(mm), mm, addr,</span>
<span class="quote">&gt; +				 addr + PAGE_SIZE);</span>
<span class="quote">&gt; +		mb();</span>
Why do you need the memory barrier?

Regards,
Nadav
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=64071">Dave Hansen</a> - June 16, 2016, 8:23 p.m.</div>
<pre class="content">
On 06/16/2016 08:14 AM, Lukasz Anaczkowski wrote:
<span class="quote">&gt; For reclaim this brings the performance back to before Mel&#39;s</span>
<span class="quote">&gt; flushing changes, but for unmap it disables batching.</span>

This turns out to be pretty catastrophic for unmap.  In a workload that
uses, say 200 hardware threads and alloc/frees() a few MB/sec, this ends
up costing hundreds of thousands of extra received IPIs.  10MB=~2500
ptes, and at with 200 threads, that&#39;s 250,000 IPIs received just to free
10MB of memory.

The initial testing we did on this was on a *bunch* of threads all doing
alloc/free.  But this is bottlenecked on other things, like mmap_sem
being held for write.

The scenario that we really needed to test here was on lots of threads
doing processing and 1 thread doing alloc/free.
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/arch/x86/include/asm/cpufeatures.h b/arch/x86/include/asm/cpufeatures.h</span>
<span class="p_header">index 4a41348..2c48011 100644</span>
<span class="p_header">--- a/arch/x86/include/asm/cpufeatures.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/cpufeatures.h</span>
<span class="p_chunk">@@ -303,6 +303,7 @@</span> <span class="p_context"></span>
 #define X86_BUG_SYSRET_SS_ATTRS	X86_BUG(8) /* SYSRET doesn&#39;t fix up SS attrs */
 #define X86_BUG_NULL_SEG	X86_BUG(9) /* Nulling a selector preserves the base */
 #define X86_BUG_SWAPGS_FENCE	X86_BUG(10) /* SWAPGS without input dep on GS */
<span class="p_add">+#define X86_BUG_PTE_LEAK        X86_BUG(11) /* PTE may leak A/D bits after clear */</span>
 
 
 #ifdef CONFIG_X86_32
<span class="p_header">diff --git a/arch/x86/include/asm/pgtable.h b/arch/x86/include/asm/pgtable.h</span>
<span class="p_header">index 1a27396..14abcb3 100644</span>
<span class="p_header">--- a/arch/x86/include/asm/pgtable.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/pgtable.h</span>
<span class="p_chunk">@@ -794,11 +794,21 @@</span> <span class="p_context"> extern int ptep_test_and_clear_young(struct vm_area_struct *vma,</span>
 extern int ptep_clear_flush_young(struct vm_area_struct *vma,
 				  unsigned long address, pte_t *ptep);
 
<span class="p_add">+#if defined(CONFIG_X86_64) &amp;&amp; defined(CONFIG_CPU_SUP_INTEL)</span>
<span class="p_add">+extern void fix_pte_leak(struct mm_struct *mm, unsigned long addr,</span>
<span class="p_add">+			 pte_t *ptep);</span>
<span class="p_add">+#else</span>
<span class="p_add">+static inline void fix_pte_leak(struct mm_struct *mm, unsigned long addr,</span>
<span class="p_add">+				pte_t *ptep) {}</span>
<span class="p_add">+#endif</span>
<span class="p_add">+</span>
 #define __HAVE_ARCH_PTEP_GET_AND_CLEAR
 static inline pte_t ptep_get_and_clear(struct mm_struct *mm, unsigned long addr,
 				       pte_t *ptep)
 {
 	pte_t pte = native_ptep_get_and_clear(ptep);
<span class="p_add">+	if (static_cpu_has_bug(X86_BUG_PTE_LEAK))</span>
<span class="p_add">+		fix_pte_leak(mm, addr, ptep);</span>
 	pte_update(mm, addr, ptep);
 	return pte;
 }
<span class="p_header">diff --git a/arch/x86/include/asm/pgtable_64.h b/arch/x86/include/asm/pgtable_64.h</span>
<span class="p_header">index 2ee7811..be7d63c 100644</span>
<span class="p_header">--- a/arch/x86/include/asm/pgtable_64.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/pgtable_64.h</span>
<span class="p_chunk">@@ -178,6 +178,22 @@</span> <span class="p_context"> extern void cleanup_highmap(void);</span>
 extern void init_extra_mapping_uc(unsigned long phys, unsigned long size);
 extern void init_extra_mapping_wb(unsigned long phys, unsigned long size);
 
<span class="p_add">+/*</span>
<span class="p_add">+ * Intel Xeon Phi x200 codenamed Knights Landing has an issue that a thread</span>
<span class="p_add">+ * setting A or D bits may not do so atomically against checking the present</span>
<span class="p_add">+ * bit. A thread which is going to page fault may still set those</span>
<span class="p_add">+ * bits, even though the present bit was already atomically cleared.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * This implies that when the kernel clears present atomically,</span>
<span class="p_add">+ * some time later the supposed to be zero entry could be corrupted</span>
<span class="p_add">+ * with stray A or D bits.</span>
<span class="p_add">+ */</span>
<span class="p_add">+#define ARCH_HAS_NEEDS_SWAP_PTL 1</span>
<span class="p_add">+static inline bool arch_needs_swap_ptl(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+       return static_cpu_has_bug(X86_BUG_PTE_LEAK);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 #endif /* !__ASSEMBLY__ */
 
 #endif /* _ASM_X86_PGTABLE_64_H */
<span class="p_header">diff --git a/arch/x86/kernel/cpu/intel.c b/arch/x86/kernel/cpu/intel.c</span>
<span class="p_header">index 6e2ffbe..b5f5bab 100644</span>
<span class="p_header">--- a/arch/x86/kernel/cpu/intel.c</span>
<span class="p_header">+++ b/arch/x86/kernel/cpu/intel.c</span>
<span class="p_chunk">@@ -7,12 +7,17 @@</span> <span class="p_context"></span>
 #include &lt;linux/thread_info.h&gt;
 #include &lt;linux/module.h&gt;
 #include &lt;linux/uaccess.h&gt;
<span class="p_add">+#include &lt;linux/mm_types.h&gt;</span>
 
 #include &lt;asm/cpufeature.h&gt;
 #include &lt;asm/pgtable.h&gt;
 #include &lt;asm/msr.h&gt;
 #include &lt;asm/bugs.h&gt;
 #include &lt;asm/cpu.h&gt;
<span class="p_add">+#include &lt;asm/intel-family.h&gt;</span>
<span class="p_add">+#include &lt;asm/tlbflush.h&gt;</span>
<span class="p_add">+</span>
<span class="p_add">+#include &lt;trace/events/tlb.h&gt;</span>
 
 #ifdef CONFIG_X86_64
 #include &lt;linux/topology.h&gt;
<span class="p_chunk">@@ -60,6 +65,35 @@</span> <span class="p_context"> void check_mpx_erratum(struct cpuinfo_x86 *c)</span>
 	}
 }
 
<span class="p_add">+#ifdef CONFIG_X86_64</span>
<span class="p_add">+/*</span>
<span class="p_add">+ * Knights Landing has an issue that a thread setting A or D bits</span>
<span class="p_add">+ * may not do so atomically against checking the present bit.</span>
<span class="p_add">+ * A thread which is going to page fault may still set those</span>
<span class="p_add">+ * bits, even though the present bit was already atomically cleared.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * Entering here, the current CPU just cleared the PTE.  But,</span>
<span class="p_add">+ * another thread may have raced and set the A or D bits, or be</span>
<span class="p_add">+ * _about_ to set the bits.  Shooting their TLB entry down will</span>
<span class="p_add">+ * ensure they see the cleared PTE and will not set A or D and</span>
<span class="p_add">+ * won&#39;t corrupt swap entries.</span>
<span class="p_add">+ */</span>
<span class="p_add">+void fix_pte_leak(struct mm_struct *mm, unsigned long addr, pte_t *ptep)</span>
<span class="p_add">+{</span>
<span class="p_add">+	if (cpumask_any_but(mm_cpumask(mm), smp_processor_id()) &lt; nr_cpu_ids) {</span>
<span class="p_add">+		trace_tlb_flush(TLB_LOCAL_SHOOTDOWN, TLB_FLUSH_ALL);</span>
<span class="p_add">+		flush_tlb_others(mm_cpumask(mm), mm, addr,</span>
<span class="p_add">+				 addr + PAGE_SIZE);</span>
<span class="p_add">+		mb();</span>
<span class="p_add">+		/*</span>
<span class="p_add">+		 * Clear the PTE one more time, in case the other thread set A/D</span>
<span class="p_add">+		 * before we sent the TLB flush.</span>
<span class="p_add">+		 */</span>
<span class="p_add">+		set_pte(ptep, __pte(0));</span>
<span class="p_add">+	}</span>
<span class="p_add">+}</span>
<span class="p_add">+#endif</span>
<span class="p_add">+</span>
 static void early_init_intel(struct cpuinfo_x86 *c)
 {
 	u64 misc_enable;
<span class="p_chunk">@@ -181,6 +215,13 @@</span> <span class="p_context"> static void early_init_intel(struct cpuinfo_x86 *c)</span>
 		}
 	}
 
<span class="p_add">+#ifdef CONFIG_X86_64</span>
<span class="p_add">+	if (c-&gt;x86_model == INTEL_FAM6_XEON_PHI_KNL) {</span>
<span class="p_add">+		pr_info_once(&quot;x86/intel: Enabling PTE leaking workaround\n&quot;);</span>
<span class="p_add">+		set_cpu_bug(c, X86_BUG_PTE_LEAK);</span>
<span class="p_add">+	}</span>
<span class="p_add">+#endif</span>
<span class="p_add">+</span>
 	/*
 	 * Intel Quark Core DevMan_001.pdf section 6.4.11
 	 * &quot;The operating system also is required to invalidate (i.e., flush)
<span class="p_header">diff --git a/include/linux/mm.h b/include/linux/mm.h</span>
<span class="p_header">index 5df5feb..5c80fe09 100644</span>
<span class="p_header">--- a/include/linux/mm.h</span>
<span class="p_header">+++ b/include/linux/mm.h</span>
<span class="p_chunk">@@ -2404,6 +2404,10 @@</span> <span class="p_context"> static inline bool debug_guardpage_enabled(void) { return false; }</span>
 static inline bool page_is_guard(struct page *page) { return false; }
 #endif /* CONFIG_DEBUG_PAGEALLOC */
 
<span class="p_add">+#ifndef ARCH_HAS_NEEDS_SWAP_PTL</span>
<span class="p_add">+static inline bool arch_needs_swap_ptl(void) { return false; }</span>
<span class="p_add">+#endif</span>
<span class="p_add">+</span>
 #if MAX_NUMNODES &gt; 1
 void __init setup_nr_node_ids(void);
 #else
<span class="p_header">diff --git a/mm/memory.c b/mm/memory.c</span>
<span class="p_header">index 15322b7..0d6ef39 100644</span>
<span class="p_header">--- a/mm/memory.c</span>
<span class="p_header">+++ b/mm/memory.c</span>
<span class="p_chunk">@@ -1960,7 +1960,8 @@</span> <span class="p_context"> static inline int pte_unmap_same(struct mm_struct *mm, pmd_t *pmd,</span>
 {
 	int same = 1;
 #if defined(CONFIG_SMP) || defined(CONFIG_PREEMPT)
<span class="p_del">-	if (sizeof(pte_t) &gt; sizeof(unsigned long)) {</span>
<span class="p_add">+	if (arch_needs_swap_ptl() ||</span>
<span class="p_add">+	    sizeof(pte_t) &gt; sizeof(unsigned long)) {</span>
 		spinlock_t *ptl = pte_lockptr(mm, pmd);
 		spin_lock(ptl);
 		same = pte_same(*page_table, orig_pte);

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



