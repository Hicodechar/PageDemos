
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>[01/11] Initialize the mapping of KASan shadow memory - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    [01/11] Initialize the mapping of KASan shadow memory</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=176771">Abbott Liu</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>Oct. 11, 2017, 8:22 a.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;20171011082227.20546-2-liuwenliang@huawei.com&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/9998977/mbox/"
   >mbox</a>
|
   <a href="/patch/9998977/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/9998977/">/patch/9998977/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
	[172.30.200.125])
	by pdx-korg-patchwork.web.codeaurora.org (Postfix) with ESMTP id
	38BC86037F for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Wed, 11 Oct 2017 08:34:39 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 22BE31FFAD
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Wed, 11 Oct 2017 08:34:39 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id 16DD52623C; Wed, 11 Oct 2017 08:34:39 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-6.9 required=2.0 tests=BAYES_00,RCVD_IN_DNSWL_HI
	autolearn=unavailable version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 180771FFAD
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Wed, 11 Oct 2017 08:34:38 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1757369AbdJKIef (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Wed, 11 Oct 2017 04:34:35 -0400
Received: from szxga05-in.huawei.com ([45.249.212.191]:7557 &quot;EHLO
	szxga05-in.huawei.com&quot; rhost-flags-OK-OK-OK-OK) by vger.kernel.org
	with ESMTP id S1756774AbdJKI2H (ORCPT
	&lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Wed, 11 Oct 2017 04:28:07 -0400
Received: from 172.30.72.59 (EHLO DGGEMS414-HUB.china.huawei.com)
	([172.30.72.59])
	by dggrg05-dlp.huawei.com (MOS 4.4.6-GA FastPath queued)
	with ESMTP id DIX64444; Wed, 11 Oct 2017 16:24:34 +0800 (CST)
Received: from linux.huawei.com (10.67.54.198) by
	DGGEMS414-HUB.china.huawei.com (10.3.19.214) with Microsoft SMTP
	Server id 14.3.301.0; Wed, 11 Oct 2017 16:22:43 +0800
From: Abbott Liu &lt;liuwenliang@huawei.com&gt;
To: &lt;linux@armlinux.org.uk&gt;, &lt;aryabinin@virtuozzo.com&gt;,
	&lt;liuwenliang@huawei.com&gt;, &lt;afzal.mohd.ma@gmail.com&gt;,
	&lt;f.fainelli@gmail.com&gt;, &lt;labbott@redhat.com&gt;,
	&lt;kirill.shutemov@linux.intel.com&gt;, &lt;mhocko@suse.com&gt;,
	&lt;cdall@linaro.org&gt;, &lt;marc.zyngier@arm.com&gt;,
	&lt;catalin.marinas@arm.com&gt;, &lt;akpm@linux-foundation.org&gt;,
	&lt;mawilcox@microsoft.com&gt;, &lt;tglx@linutronix.de&gt;,
	&lt;thgarnie@google.com&gt;, &lt;keescook@chromium.org&gt;, &lt;arnd@arndb.de&gt;,
	&lt;vladimir.murzin@arm.com&gt;, &lt;tixy@linaro.org&gt;,
	&lt;ard.biesheuvel@linaro.org&gt;, &lt;robin.murphy@arm.com&gt;,
	&lt;mingo@kernel.org&gt;, &lt;grygorii.strashko@linaro.org&gt;
CC: &lt;glider@google.com&gt;, &lt;dvyukov@google.com&gt;, &lt;opendmb@gmail.com&gt;,
	&lt;linux-arm-kernel@lists.infradead.org&gt;,
	&lt;linux-kernel@vger.kernel.org&gt;, &lt;kasan-dev@googlegroups.com&gt;,
	&lt;linux-mm@kvack.org&gt;, &lt;jiazhenghua@huawei.com&gt;,
	&lt;dylix.dailei@huawei.com&gt;, &lt;zengweilin@huawei.com&gt;,
	&lt;heshaoliang@huawei.com&gt;
Subject: [PATCH 01/11] Initialize the mapping of KASan shadow memory
Date: Wed, 11 Oct 2017 16:22:17 +0800
Message-ID: &lt;20171011082227.20546-2-liuwenliang@huawei.com&gt;
X-Mailer: git-send-email 2.9.0
In-Reply-To: &lt;20171011082227.20546-1-liuwenliang@huawei.com&gt;
References: &lt;20171011082227.20546-1-liuwenliang@huawei.com&gt;
MIME-Version: 1.0
Content-Type: text/plain
X-Originating-IP: [10.67.54.198]
X-CFilter-Loop: Reflected
X-Mirapoint-Virus-RAPID-Raw: score=unknown(0),
	refid=str=0001.0A020205.59DDD542.00DD, ss=1, re=0.000, recu=0.000,
	reip=0.000, cl=1, cld=1, fgs=0, ip=0.0.0.0,
	so=2014-11-16 11:51:01, dmn=2013-03-21 17:37:32
X-Mirapoint-Loop-Id: 8a4cea6d5aacd90d74f9dd847a498925
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=176771">Abbott Liu</a> - Oct. 11, 2017, 8:22 a.m.</div>
<pre class="content">
<span class="from">From: Andrey Ryabinin &lt;a.ryabinin@samsung.com&gt;</span>

This patch initializes KASan shadow region&#39;s page table and memory.
There are two stage for KASan initializing:
1. At early boot stage the whole shadow region is mapped to just
   one physical page (kasan_zero_page). It&#39;s finished by the function
   kasan_early_init which is called by __mmap_switched(arch/arm/kernel/
   head-common.S)

2. After the calling of paging_init, we use kasan_zero_page as zero
   shadow for some memory that KASan don&#39;t need to track, and we alloc
   new shadow space for the other memory that KASan need to track. These
   issues are finished by the function kasan_init which is call by setup_arch.

Cc: Andrey Ryabinin &lt;a.ryabinin@samsung.com&gt;
<span class="signed-off-by">Signed-off-by: Abbott Liu &lt;liuwenliang@huawei.com&gt;</span>
---
 arch/arm/include/asm/kasan.h       |  20 +++
 arch/arm/include/asm/pgalloc.h     |   5 +-
 arch/arm/include/asm/pgtable.h     |   1 +
 arch/arm/include/asm/proc-fns.h    |  33 +++++
 arch/arm/include/asm/thread_info.h |   4 +
 arch/arm/kernel/head-common.S      |   4 +
 arch/arm/kernel/setup.c            |   2 +
 arch/arm/mm/Makefile               |   5 +
 arch/arm/mm/kasan_init.c           | 257 +++++++++++++++++++++++++++++++++++++
 mm/kasan/kasan.c                   |   2 +-
 10 files changed, 331 insertions(+), 2 deletions(-)
 create mode 100644 arch/arm/include/asm/kasan.h
 create mode 100644 arch/arm/mm/kasan_init.c
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=4640">Florian Fainelli</a> - Oct. 11, 2017, 7:39 p.m.</div>
<pre class="content">
On 10/11/2017 01:22 AM, Abbott Liu wrote:
<span class="quote">&gt; From: Andrey Ryabinin &lt;a.ryabinin@samsung.com&gt;</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; This patch initializes KASan shadow region&#39;s page table and memory.</span>
<span class="quote">&gt; There are two stage for KASan initializing:</span>
<span class="quote">&gt; 1. At early boot stage the whole shadow region is mapped to just</span>
<span class="quote">&gt;    one physical page (kasan_zero_page). It&#39;s finished by the function</span>
<span class="quote">&gt;    kasan_early_init which is called by __mmap_switched(arch/arm/kernel/</span>
<span class="quote">&gt;    head-common.S)</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; 2. After the calling of paging_init, we use kasan_zero_page as zero</span>
<span class="quote">&gt;    shadow for some memory that KASan don&#39;t need to track, and we alloc</span>
<span class="quote">&gt;    new shadow space for the other memory that KASan need to track. These</span>
<span class="quote">&gt;    issues are finished by the function kasan_init which is call by setup_arch.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Cc: Andrey Ryabinin &lt;a.ryabinin@samsung.com&gt;</span>
<span class="quote">&gt; Signed-off-by: Abbott Liu &lt;liuwenliang@huawei.com&gt;</span>
<span class="quote">&gt; ---</span>

[snip]

				\
<span class="quote">&gt; @@ -140,6 +149,30 @@ extern void cpu_resume(void);</span>
<span class="quote">&gt;  		pg &amp;= ~0x3fff;				\</span>
<span class="quote">&gt;  		(pgd_t *)phys_to_virt(pg);		\</span>
<span class="quote">&gt;  	})</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +#define cpu_set_ttbr(nr, val)					\</span>
<span class="quote">&gt; +	do {							\</span>
<span class="quote">&gt; +		u64 ttbr = val;					\</span>
<span class="quote">&gt; +		__asm__(&quot;mcr	p15, 0, %0, c2, c0, 0&quot;		\</span>
<span class="quote">&gt; +			: : &quot;r&quot; (ttbr));			\</span>
<span class="quote">&gt; +	} while (0)</span>

nr seems to be unused here?
<span class="quote">
&gt; +</span>
<span class="quote">&gt; +#define cpu_get_ttbr(nr)					\</span>
<span class="quote">&gt; +	({							\</span>
<span class="quote">&gt; +		unsigned long ttbr;				\</span>
<span class="quote">&gt; +		__asm__(&quot;mrc	p15, 0, %0, c2, c0, 0&quot;		\</span>
<span class="quote">&gt; +			: &quot;=r&quot; (ttbr));				\</span>
<span class="quote">&gt; +		ttbr;						\</span>
<span class="quote">&gt; +	})</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +#define cpu_set_ttbr0(val)					\</span>
<span class="quote">&gt; +	do {							\</span>
<span class="quote">&gt; +		u64 ttbr = val;					\</span>
<span class="quote">&gt; +		__asm__(&quot;mcr	p15, 0, %0, c2, c0, 0&quot;		\</span>
<span class="quote">&gt; +			: : &quot;r&quot; (ttbr));			\</span>
<span class="quote">&gt; +	} while (0)</span>
<span class="quote">&gt; +</span>

Why is not cpu_set_ttbr0() not using cpu_set_ttbr()?
<span class="quote">
&gt; +</span>
<span class="quote">&gt;  #endif</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  #else	/*!CONFIG_MMU */</span>
<span class="quote">&gt; diff --git a/arch/arm/include/asm/thread_info.h b/arch/arm/include/asm/thread_info.h</span>
<span class="quote">&gt; index 1d468b5..52c4858 100644</span>
<span class="quote">&gt; --- a/arch/arm/include/asm/thread_info.h</span>
<span class="quote">&gt; +++ b/arch/arm/include/asm/thread_info.h</span>
<span class="quote">&gt; @@ -16,7 +16,11 @@</span>
<span class="quote">&gt;  #include &lt;asm/fpstate.h&gt;</span>
<span class="quote">&gt;  #include &lt;asm/page.h&gt;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; +#ifdef CONFIG_KASAN</span>
<span class="quote">&gt; +#define THREAD_SIZE_ORDER       2</span>
<span class="quote">&gt; +#else</span>
<span class="quote">&gt;  #define THREAD_SIZE_ORDER	1</span>
<span class="quote">&gt; +#endif</span>
<span class="quote">&gt;  #define THREAD_SIZE		(PAGE_SIZE &lt;&lt; THREAD_SIZE_ORDER)</span>
<span class="quote">&gt;  #define THREAD_START_SP		(THREAD_SIZE - 8)</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; diff --git a/arch/arm/kernel/head-common.S b/arch/arm/kernel/head-common.S</span>
<span class="quote">&gt; index 8733012..c17f4a2 100644</span>
<span class="quote">&gt; --- a/arch/arm/kernel/head-common.S</span>
<span class="quote">&gt; +++ b/arch/arm/kernel/head-common.S</span>
<span class="quote">&gt; @@ -101,7 +101,11 @@ __mmap_switched:</span>
<span class="quote">&gt;  	str	r2, [r6]			@ Save atags pointer</span>
<span class="quote">&gt;  	cmp	r7, #0</span>
<span class="quote">&gt;  	strne	r0, [r7]			@ Save control register values</span>
<span class="quote">&gt; +#ifdef CONFIG_KASAN</span>
<span class="quote">&gt; +	b	kasan_early_init</span>
<span class="quote">&gt; +#else</span>
<span class="quote">&gt;  	b	start_kernel</span>
<span class="quote">&gt; +#endif</span>

Please don&#39;t make this &quot;exclusive&quot; just conditionally call
kasan_early_init(), remove the call to start_kernel from
kasan_early_init and keep the call to start_kernel here.
<span class="quote">
&gt;  ENDPROC(__mmap_switched)</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	.align	2</span>

[snip]
<span class="quote">
&gt; +void __init kasan_early_init(void)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	struct proc_info_list *list;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	/*</span>
<span class="quote">&gt; +	 * locate processor in the list of supported processor</span>
<span class="quote">&gt; +	 * types.  The linker builds this table for us from the</span>
<span class="quote">&gt; +	 * entries in arch/arm/mm/proc-*.S</span>
<span class="quote">&gt; +	 */</span>
<span class="quote">&gt; +	list = lookup_processor_type(read_cpuid_id());</span>
<span class="quote">&gt; +	if (list) {</span>
<span class="quote">&gt; +#ifdef MULTI_CPU</span>
<span class="quote">&gt; +		processor = *list-&gt;proc;</span>
<span class="quote">&gt; +#endif</span>
<span class="quote">&gt; +	}</span>

I could not quite spot in your patch series when do you need this
information?
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=166571">Russell King - ARM Linux</a> - Oct. 11, 2017, 9:41 p.m.</div>
<pre class="content">
On Wed, Oct 11, 2017 at 12:39:39PM -0700, Florian Fainelli wrote:
<span class="quote">&gt; On 10/11/2017 01:22 AM, Abbott Liu wrote:</span>
<span class="quote">&gt; &gt; diff --git a/arch/arm/kernel/head-common.S b/arch/arm/kernel/head-common.S</span>
<span class="quote">&gt; &gt; index 8733012..c17f4a2 100644</span>
<span class="quote">&gt; &gt; --- a/arch/arm/kernel/head-common.S</span>
<span class="quote">&gt; &gt; +++ b/arch/arm/kernel/head-common.S</span>
<span class="quote">&gt; &gt; @@ -101,7 +101,11 @@ __mmap_switched:</span>
<span class="quote">&gt; &gt;  	str	r2, [r6]			@ Save atags pointer</span>
<span class="quote">&gt; &gt;  	cmp	r7, #0</span>
<span class="quote">&gt; &gt;  	strne	r0, [r7]			@ Save control register values</span>
<span class="quote">&gt; &gt; +#ifdef CONFIG_KASAN</span>
<span class="quote">&gt; &gt; +	b	kasan_early_init</span>
<span class="quote">&gt; &gt; +#else</span>
<span class="quote">&gt; &gt;  	b	start_kernel</span>
<span class="quote">&gt; &gt; +#endif</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Please don&#39;t make this &quot;exclusive&quot; just conditionally call</span>
<span class="quote">&gt; kasan_early_init(), remove the call to start_kernel from</span>
<span class="quote">&gt; kasan_early_init and keep the call to start_kernel here.</span>

iow:

#ifdef CONFIG_KASAN
	bl	kasan_early_init
#endif
	b	start_kernel

This has the advantage that we don&#39;t leave any stack frame from
kasan_early_init() on the init task stack.
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=51621">Dmitry Osipenko</a> - Oct. 11, 2017, 11:42 p.m.</div>
<pre class="content">
On 11.10.2017 11:22, Abbott Liu wrote:
<span class="quote">&gt; From: Andrey Ryabinin &lt;a.ryabinin@samsung.com&gt;</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; This patch initializes KASan shadow region&#39;s page table and memory.</span>
<span class="quote">&gt; There are two stage for KASan initializing:</span>
<span class="quote">&gt; 1. At early boot stage the whole shadow region is mapped to just</span>
<span class="quote">&gt;    one physical page (kasan_zero_page). It&#39;s finished by the function</span>
<span class="quote">&gt;    kasan_early_init which is called by __mmap_switched(arch/arm/kernel/</span>
<span class="quote">&gt;    head-common.S)</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; 2. After the calling of paging_init, we use kasan_zero_page as zero</span>
<span class="quote">&gt;    shadow for some memory that KASan don&#39;t need to track, and we alloc</span>
<span class="quote">&gt;    new shadow space for the other memory that KASan need to track. These</span>
<span class="quote">&gt;    issues are finished by the function kasan_init which is call by setup_arch.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Cc: Andrey Ryabinin &lt;a.ryabinin@samsung.com&gt;</span>
<span class="quote">&gt; Signed-off-by: Abbott Liu &lt;liuwenliang@huawei.com&gt;</span>
<span class="quote">&gt; ---</span>
<span class="quote">&gt;  arch/arm/include/asm/kasan.h       |  20 +++</span>
<span class="quote">&gt;  arch/arm/include/asm/pgalloc.h     |   5 +-</span>
<span class="quote">&gt;  arch/arm/include/asm/pgtable.h     |   1 +</span>
<span class="quote">&gt;  arch/arm/include/asm/proc-fns.h    |  33 +++++</span>
<span class="quote">&gt;  arch/arm/include/asm/thread_info.h |   4 +</span>
<span class="quote">&gt;  arch/arm/kernel/head-common.S      |   4 +</span>
<span class="quote">&gt;  arch/arm/kernel/setup.c            |   2 +</span>
<span class="quote">&gt;  arch/arm/mm/Makefile               |   5 +</span>
<span class="quote">&gt;  arch/arm/mm/kasan_init.c           | 257 +++++++++++++++++++++++++++++++++++++</span>
<span class="quote">&gt;  mm/kasan/kasan.c                   |   2 +-</span>
<span class="quote">&gt;  10 files changed, 331 insertions(+), 2 deletions(-)</span>
<span class="quote">&gt;  create mode 100644 arch/arm/include/asm/kasan.h</span>
<span class="quote">&gt;  create mode 100644 arch/arm/mm/kasan_init.c</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; diff --git a/arch/arm/include/asm/kasan.h b/arch/arm/include/asm/kasan.h</span>
<span class="quote">&gt; new file mode 100644</span>
<span class="quote">&gt; index 0000000..90ee60c</span>
<span class="quote">&gt; --- /dev/null</span>
<span class="quote">&gt; +++ b/arch/arm/include/asm/kasan.h</span>
<span class="quote">&gt; @@ -0,0 +1,20 @@</span>
<span class="quote">&gt; +#ifndef __ASM_KASAN_H</span>
<span class="quote">&gt; +#define __ASM_KASAN_H</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +#ifdef CONFIG_KASAN</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +#include &lt;asm/kasan_def.h&gt;</span>
<span class="quote">&gt; +/*</span>
<span class="quote">&gt; + * Compiler uses shadow offset assuming that addresses start</span>
<span class="quote">&gt; + * from 0. Kernel addresses don&#39;t start from 0, so shadow</span>
<span class="quote">&gt; + * for kernel really starts from &#39;compiler&#39;s shadow offset&#39; +</span>
<span class="quote">&gt; + * (&#39;kernel address space start&#39; &gt;&gt; KASAN_SHADOW_SCALE_SHIFT)</span>
<span class="quote">&gt; + */</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +extern void kasan_init(void);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +#else</span>
<span class="quote">&gt; +static inline void kasan_init(void) { }</span>
<span class="quote">&gt; +#endif</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +#endif</span>
<span class="quote">&gt; diff --git a/arch/arm/include/asm/pgalloc.h b/arch/arm/include/asm/pgalloc.h</span>
<span class="quote">&gt; index b2902a5..10cee6a 100644</span>
<span class="quote">&gt; --- a/arch/arm/include/asm/pgalloc.h</span>
<span class="quote">&gt; +++ b/arch/arm/include/asm/pgalloc.h</span>
<span class="quote">&gt; @@ -50,8 +50,11 @@ static inline void pud_populate(struct mm_struct *mm, pud_t *pud, pmd_t *pmd)</span>
<span class="quote">&gt;   */</span>
<span class="quote">&gt;  #define pmd_alloc_one(mm,addr)		({ BUG(); ((pmd_t *)2); })</span>
<span class="quote">&gt;  #define pmd_free(mm, pmd)		do { } while (0)</span>
<span class="quote">&gt; +#ifndef CONFIG_KASAN</span>
<span class="quote">&gt;  #define pud_populate(mm,pmd,pte)	BUG()</span>
<span class="quote">&gt; -</span>
<span class="quote">&gt; +#else</span>
<span class="quote">&gt; +#define pud_populate(mm,pmd,pte)	do { } while (0)</span>
<span class="quote">&gt; +#endif</span>
<span class="quote">&gt;  #endif	/* CONFIG_ARM_LPAE */</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  extern pgd_t *pgd_alloc(struct mm_struct *mm);</span>
<span class="quote">&gt; diff --git a/arch/arm/include/asm/pgtable.h b/arch/arm/include/asm/pgtable.h</span>
<span class="quote">&gt; index 1c46238..fdf343f 100644</span>
<span class="quote">&gt; --- a/arch/arm/include/asm/pgtable.h</span>
<span class="quote">&gt; +++ b/arch/arm/include/asm/pgtable.h</span>
<span class="quote">&gt; @@ -97,6 +97,7 @@ extern pgprot_t		pgprot_s2_device;</span>
<span class="quote">&gt;  #define PAGE_READONLY		_MOD_PROT(pgprot_user, L_PTE_USER | L_PTE_RDONLY | L_PTE_XN)</span>
<span class="quote">&gt;  #define PAGE_READONLY_EXEC	_MOD_PROT(pgprot_user, L_PTE_USER | L_PTE_RDONLY)</span>
<span class="quote">&gt;  #define PAGE_KERNEL		_MOD_PROT(pgprot_kernel, L_PTE_XN)</span>
<span class="quote">&gt; +#define PAGE_KERNEL_RO		_MOD_PROT(pgprot_kernel, L_PTE_XN | L_PTE_RDONLY)</span>
<span class="quote">&gt;  #define PAGE_KERNEL_EXEC	pgprot_kernel</span>
<span class="quote">&gt;  #define PAGE_HYP		_MOD_PROT(pgprot_kernel, L_PTE_HYP | L_PTE_XN)</span>
<span class="quote">&gt;  #define PAGE_HYP_EXEC		_MOD_PROT(pgprot_kernel, L_PTE_HYP | L_PTE_RDONLY)</span>
<span class="quote">&gt; diff --git a/arch/arm/include/asm/proc-fns.h b/arch/arm/include/asm/proc-fns.h</span>
<span class="quote">&gt; index f2e1af4..6e26714 100644</span>
<span class="quote">&gt; --- a/arch/arm/include/asm/proc-fns.h</span>
<span class="quote">&gt; +++ b/arch/arm/include/asm/proc-fns.h</span>
<span class="quote">&gt; @@ -131,6 +131,15 @@ extern void cpu_resume(void);</span>
<span class="quote">&gt;  		pg &amp;= ~(PTRS_PER_PGD*sizeof(pgd_t)-1);	\</span>
<span class="quote">&gt;  		(pgd_t *)phys_to_virt(pg);		\</span>
<span class="quote">&gt;  	})</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +#define cpu_set_ttbr0(val)					\</span>
<span class="quote">&gt; +	do {							\</span>
<span class="quote">&gt; +		u64 ttbr = val;					\</span>
<span class="quote">&gt; +		__asm__(&quot;mcrr	p15, 0, %Q0, %R0, c2&quot;		\</span>
<span class="quote">&gt; +			: : &quot;r&quot; (ttbr));	\</span>
<span class="quote">&gt; +	} while (0)</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt;  #else</span>
<span class="quote">&gt;  #define cpu_get_pgd()	\</span>
<span class="quote">&gt;  	({						\</span>
<span class="quote">&gt; @@ -140,6 +149,30 @@ extern void cpu_resume(void);</span>
<span class="quote">&gt;  		pg &amp;= ~0x3fff;				\</span>
<span class="quote">&gt;  		(pgd_t *)phys_to_virt(pg);		\</span>
<span class="quote">&gt;  	})</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +#define cpu_set_ttbr(nr, val)					\</span>
<span class="quote">&gt; +	do {							\</span>
<span class="quote">&gt; +		u64 ttbr = val;					\</span>
<span class="quote">&gt; +		__asm__(&quot;mcr	p15, 0, %0, c2, c0, 0&quot;		\</span>
<span class="quote">&gt; +			: : &quot;r&quot; (ttbr));			\</span>
<span class="quote">&gt; +	} while (0)</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +#define cpu_get_ttbr(nr)					\</span>
<span class="quote">&gt; +	({							\</span>
<span class="quote">&gt; +		unsigned long ttbr;				\</span>
<span class="quote">&gt; +		__asm__(&quot;mrc	p15, 0, %0, c2, c0, 0&quot;		\</span>
<span class="quote">&gt; +			: &quot;=r&quot; (ttbr));				\</span>
<span class="quote">&gt; +		ttbr;						\</span>
<span class="quote">&gt; +	})</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +#define cpu_set_ttbr0(val)					\</span>
<span class="quote">&gt; +	do {							\</span>
<span class="quote">&gt; +		u64 ttbr = val;					\</span>
<span class="quote">&gt; +		__asm__(&quot;mcr	p15, 0, %0, c2, c0, 0&quot;		\</span>
<span class="quote">&gt; +			: : &quot;r&quot; (ttbr));			\</span>
<span class="quote">&gt; +	} while (0)</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt;  #endif</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  #else	/*!CONFIG_MMU */</span>
<span class="quote">&gt; diff --git a/arch/arm/include/asm/thread_info.h b/arch/arm/include/asm/thread_info.h</span>
<span class="quote">&gt; index 1d468b5..52c4858 100644</span>
<span class="quote">&gt; --- a/arch/arm/include/asm/thread_info.h</span>
<span class="quote">&gt; +++ b/arch/arm/include/asm/thread_info.h</span>
<span class="quote">&gt; @@ -16,7 +16,11 @@</span>
<span class="quote">&gt;  #include &lt;asm/fpstate.h&gt;</span>
<span class="quote">&gt;  #include &lt;asm/page.h&gt;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; +#ifdef CONFIG_KASAN</span>
<span class="quote">&gt; +#define THREAD_SIZE_ORDER       2</span>
<span class="quote">&gt; +#else</span>
<span class="quote">&gt;  #define THREAD_SIZE_ORDER	1</span>
<span class="quote">&gt; +#endif</span>
<span class="quote">&gt;  #define THREAD_SIZE		(PAGE_SIZE &lt;&lt; THREAD_SIZE_ORDER)</span>
<span class="quote">&gt;  #define THREAD_START_SP		(THREAD_SIZE - 8)</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; diff --git a/arch/arm/kernel/head-common.S b/arch/arm/kernel/head-common.S</span>
<span class="quote">&gt; index 8733012..c17f4a2 100644</span>
<span class="quote">&gt; --- a/arch/arm/kernel/head-common.S</span>
<span class="quote">&gt; +++ b/arch/arm/kernel/head-common.S</span>
<span class="quote">&gt; @@ -101,7 +101,11 @@ __mmap_switched:</span>
<span class="quote">&gt;  	str	r2, [r6]			@ Save atags pointer</span>
<span class="quote">&gt;  	cmp	r7, #0</span>
<span class="quote">&gt;  	strne	r0, [r7]			@ Save control register values</span>
<span class="quote">&gt; +#ifdef CONFIG_KASAN</span>
<span class="quote">&gt; +	b	kasan_early_init</span>
<span class="quote">&gt; +#else</span>
<span class="quote">&gt;  	b	start_kernel</span>
<span class="quote">&gt; +#endif</span>
<span class="quote">&gt;  ENDPROC(__mmap_switched)</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	.align	2</span>
<span class="quote">&gt; diff --git a/arch/arm/kernel/setup.c b/arch/arm/kernel/setup.c</span>
<span class="quote">&gt; index 8e9a3e4..985d9a3 100644</span>
<span class="quote">&gt; --- a/arch/arm/kernel/setup.c</span>
<span class="quote">&gt; +++ b/arch/arm/kernel/setup.c</span>
<span class="quote">&gt; @@ -62,6 +62,7 @@</span>
<span class="quote">&gt;  #include &lt;asm/unwind.h&gt;</span>
<span class="quote">&gt;  #include &lt;asm/memblock.h&gt;</span>
<span class="quote">&gt;  #include &lt;asm/virt.h&gt;</span>
<span class="quote">&gt; +#include &lt;asm/kasan.h&gt;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  #include &quot;atags.h&quot;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; @@ -1108,6 +1109,7 @@ void __init setup_arch(char **cmdline_p)</span>
<span class="quote">&gt;  	early_ioremap_reset();</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	paging_init(mdesc);</span>
<span class="quote">&gt; +	kasan_init();</span>
<span class="quote">&gt;  	request_standard_resources(mdesc);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	if (mdesc-&gt;restart)</span>
<span class="quote">&gt; diff --git a/arch/arm/mm/Makefile b/arch/arm/mm/Makefile</span>
<span class="quote">&gt; index 950d19b..498c316 100644</span>
<span class="quote">&gt; --- a/arch/arm/mm/Makefile</span>
<span class="quote">&gt; +++ b/arch/arm/mm/Makefile</span>
<span class="quote">&gt; @@ -106,4 +106,9 @@ obj-$(CONFIG_CACHE_L2X0)	+= cache-l2x0.o l2c-l2x0-resume.o</span>
<span class="quote">&gt;  obj-$(CONFIG_CACHE_L2X0_PMU)	+= cache-l2x0-pmu.o</span>
<span class="quote">&gt;  obj-$(CONFIG_CACHE_XSC3L2)	+= cache-xsc3l2.o</span>
<span class="quote">&gt;  obj-$(CONFIG_CACHE_TAUROS2)	+= cache-tauros2.o</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +KASAN_SANITIZE_kasan_init.o    := n</span>
<span class="quote">&gt; +obj-$(CONFIG_KASAN)            += kasan_init.o</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt;  obj-$(CONFIG_CACHE_UNIPHIER)	+= cache-uniphier.o</span>
<span class="quote">&gt; diff --git a/arch/arm/mm/kasan_init.c b/arch/arm/mm/kasan_init.c</span>
<span class="quote">&gt; new file mode 100644</span>
<span class="quote">&gt; index 0000000..2bf0782</span>
<span class="quote">&gt; --- /dev/null</span>
<span class="quote">&gt; +++ b/arch/arm/mm/kasan_init.c</span>
<span class="quote">&gt; @@ -0,0 +1,257 @@</span>
<span class="quote">&gt; +#include &lt;linux/bootmem.h&gt;</span>
<span class="quote">&gt; +#include &lt;linux/kasan.h&gt;</span>
<span class="quote">&gt; +#include &lt;linux/kernel.h&gt;</span>
<span class="quote">&gt; +#include &lt;linux/memblock.h&gt;</span>
<span class="quote">&gt; +#include &lt;linux/start_kernel.h&gt;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +#include &lt;asm/cputype.h&gt;</span>
<span class="quote">&gt; +#include &lt;asm/highmem.h&gt;</span>
<span class="quote">&gt; +#include &lt;asm/mach/map.h&gt;</span>
<span class="quote">&gt; +#include &lt;asm/memory.h&gt;</span>
<span class="quote">&gt; +#include &lt;asm/page.h&gt;</span>
<span class="quote">&gt; +#include &lt;asm/pgalloc.h&gt;</span>
<span class="quote">&gt; +#include &lt;asm/pgtable.h&gt;</span>
<span class="quote">&gt; +#include &lt;asm/procinfo.h&gt;</span>
<span class="quote">&gt; +#include &lt;asm/proc-fns.h&gt;</span>
<span class="quote">&gt; +#include &lt;asm/tlbflush.h&gt;</span>
<span class="quote">&gt; +#include &lt;asm/cp15.h&gt;</span>
<span class="quote">&gt; +#include &lt;linux/sched/task.h&gt;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +#include &quot;mm.h&quot;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +static pgd_t tmp_page_table[PTRS_PER_PGD] __initdata __aligned(1ULL &lt;&lt; 14);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +pmd_t tmp_pmd_table[PTRS_PER_PMD] __page_aligned_bss;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +static __init void *kasan_alloc_block(size_t size, int node)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	return memblock_virt_alloc_try_nid(size, size, __pa(MAX_DMA_ADDRESS),</span>
<span class="quote">&gt; +					BOOTMEM_ALLOC_ACCESSIBLE, node);</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +static void __init kasan_early_pmd_populate(unsigned long start, unsigned long end, pud_t *pud)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	unsigned long addr;</span>
<span class="quote">&gt; +	unsigned long next;</span>
<span class="quote">&gt; +	pmd_t *pmd;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	pmd = pmd_offset(pud, start);</span>
<span class="quote">&gt; +	for (addr = start; addr &lt; end;) {</span>
<span class="quote">&gt; +		pmd_populate_kernel(&amp;init_mm, pmd, kasan_zero_pte);</span>
<span class="quote">&gt; +		next = pmd_addr_end(addr, end);</span>
<span class="quote">&gt; +		addr = next;</span>
<span class="quote">&gt; +		flush_pmd_entry(pmd);</span>
<span class="quote">&gt; +		pmd++;</span>
<span class="quote">&gt; +	}</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +static void __init kasan_early_pud_populate(unsigned long start, unsigned long end, pgd_t *pgd)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	unsigned long addr;</span>
<span class="quote">&gt; +	unsigned long next;</span>
<span class="quote">&gt; +	pud_t *pud;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	pud = pud_offset(pgd, start);</span>
<span class="quote">&gt; +	for (addr = start; addr &lt; end;) {</span>
<span class="quote">&gt; +		next = pud_addr_end(addr, end);</span>
<span class="quote">&gt; +		kasan_early_pmd_populate(addr, next, pud);</span>
<span class="quote">&gt; +		addr = next;</span>
<span class="quote">&gt; +		pud++;</span>
<span class="quote">&gt; +	}</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +void __init kasan_map_early_shadow(pgd_t *pgdp)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	int i;</span>
<span class="quote">&gt; +	unsigned long start = KASAN_SHADOW_START;</span>
<span class="quote">&gt; +	unsigned long end = KASAN_SHADOW_END;</span>
<span class="quote">&gt; +	unsigned long addr;</span>
<span class="quote">&gt; +	unsigned long next;</span>
<span class="quote">&gt; +	pgd_t *pgd;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	for (i = 0; i &lt; PTRS_PER_PTE; i++)</span>
<span class="quote">&gt; +		set_pte_at(&amp;init_mm, KASAN_SHADOW_START + i*PAGE_SIZE,</span>
<span class="quote">&gt; +			&amp;kasan_zero_pte[i], pfn_pte(</span>
<span class="quote">&gt; +				virt_to_pfn(kasan_zero_page),</span>
<span class="quote">&gt; +				__pgprot(_L_PTE_DEFAULT | L_PTE_DIRTY | L_PTE_XN)));</span>

Shouldn&#39;t all __pgprot&#39;s contain L_PTE_MT_WRITETHROUGH ?

[...]
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=28962">Marc Zyngier</a> - Oct. 12, 2017, 7:58 a.m.</div>
<pre class="content">
On 11/10/17 09:22, Abbott Liu wrote:
<span class="quote">&gt; From: Andrey Ryabinin &lt;a.ryabinin@samsung.com&gt;</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; This patch initializes KASan shadow region&#39;s page table and memory.</span>
<span class="quote">&gt; There are two stage for KASan initializing:</span>
<span class="quote">&gt; 1. At early boot stage the whole shadow region is mapped to just</span>
<span class="quote">&gt;    one physical page (kasan_zero_page). It&#39;s finished by the function</span>
<span class="quote">&gt;    kasan_early_init which is called by __mmap_switched(arch/arm/kernel/</span>
<span class="quote">&gt;    head-common.S)</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; 2. After the calling of paging_init, we use kasan_zero_page as zero</span>
<span class="quote">&gt;    shadow for some memory that KASan don&#39;t need to track, and we alloc</span>
<span class="quote">&gt;    new shadow space for the other memory that KASan need to track. These</span>
<span class="quote">&gt;    issues are finished by the function kasan_init which is call by setup_arch.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Cc: Andrey Ryabinin &lt;a.ryabinin@samsung.com&gt;</span>
<span class="quote">&gt; Signed-off-by: Abbott Liu &lt;liuwenliang@huawei.com&gt;</span>
<span class="quote">&gt; ---</span>
<span class="quote">&gt;  arch/arm/include/asm/kasan.h       |  20 +++</span>
<span class="quote">&gt;  arch/arm/include/asm/pgalloc.h     |   5 +-</span>
<span class="quote">&gt;  arch/arm/include/asm/pgtable.h     |   1 +</span>
<span class="quote">&gt;  arch/arm/include/asm/proc-fns.h    |  33 +++++</span>
<span class="quote">&gt;  arch/arm/include/asm/thread_info.h |   4 +</span>
<span class="quote">&gt;  arch/arm/kernel/head-common.S      |   4 +</span>
<span class="quote">&gt;  arch/arm/kernel/setup.c            |   2 +</span>
<span class="quote">&gt;  arch/arm/mm/Makefile               |   5 +</span>
<span class="quote">&gt;  arch/arm/mm/kasan_init.c           | 257 +++++++++++++++++++++++++++++++++++++</span>
<span class="quote">&gt;  mm/kasan/kasan.c                   |   2 +-</span>
<span class="quote">&gt;  10 files changed, 331 insertions(+), 2 deletions(-)</span>
<span class="quote">&gt;  create mode 100644 arch/arm/include/asm/kasan.h</span>
<span class="quote">&gt;  create mode 100644 arch/arm/mm/kasan_init.c</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; diff --git a/arch/arm/include/asm/kasan.h b/arch/arm/include/asm/kasan.h</span>
<span class="quote">&gt; new file mode 100644</span>
<span class="quote">&gt; index 0000000..90ee60c</span>
<span class="quote">&gt; --- /dev/null</span>
<span class="quote">&gt; +++ b/arch/arm/include/asm/kasan.h</span>
<span class="quote">&gt; @@ -0,0 +1,20 @@</span>
<span class="quote">&gt; +#ifndef __ASM_KASAN_H</span>
<span class="quote">&gt; +#define __ASM_KASAN_H</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +#ifdef CONFIG_KASAN</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +#include &lt;asm/kasan_def.h&gt;</span>
<span class="quote">&gt; +/*</span>
<span class="quote">&gt; + * Compiler uses shadow offset assuming that addresses start</span>
<span class="quote">&gt; + * from 0. Kernel addresses don&#39;t start from 0, so shadow</span>
<span class="quote">&gt; + * for kernel really starts from &#39;compiler&#39;s shadow offset&#39; +</span>
<span class="quote">&gt; + * (&#39;kernel address space start&#39; &gt;&gt; KASAN_SHADOW_SCALE_SHIFT)</span>
<span class="quote">&gt; + */</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +extern void kasan_init(void);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +#else</span>
<span class="quote">&gt; +static inline void kasan_init(void) { }</span>
<span class="quote">&gt; +#endif</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +#endif</span>
<span class="quote">&gt; diff --git a/arch/arm/include/asm/pgalloc.h b/arch/arm/include/asm/pgalloc.h</span>
<span class="quote">&gt; index b2902a5..10cee6a 100644</span>
<span class="quote">&gt; --- a/arch/arm/include/asm/pgalloc.h</span>
<span class="quote">&gt; +++ b/arch/arm/include/asm/pgalloc.h</span>
<span class="quote">&gt; @@ -50,8 +50,11 @@ static inline void pud_populate(struct mm_struct *mm, pud_t *pud, pmd_t *pmd)</span>
<span class="quote">&gt;   */</span>
<span class="quote">&gt;  #define pmd_alloc_one(mm,addr)		({ BUG(); ((pmd_t *)2); })</span>
<span class="quote">&gt;  #define pmd_free(mm, pmd)		do { } while (0)</span>
<span class="quote">&gt; +#ifndef CONFIG_KASAN</span>
<span class="quote">&gt;  #define pud_populate(mm,pmd,pte)	BUG()</span>
<span class="quote">&gt; -</span>
<span class="quote">&gt; +#else</span>
<span class="quote">&gt; +#define pud_populate(mm,pmd,pte)	do { } while (0)</span>
<span class="quote">&gt; +#endif</span>
<span class="quote">&gt;  #endif	/* CONFIG_ARM_LPAE */</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  extern pgd_t *pgd_alloc(struct mm_struct *mm);</span>
<span class="quote">&gt; diff --git a/arch/arm/include/asm/pgtable.h b/arch/arm/include/asm/pgtable.h</span>
<span class="quote">&gt; index 1c46238..fdf343f 100644</span>
<span class="quote">&gt; --- a/arch/arm/include/asm/pgtable.h</span>
<span class="quote">&gt; +++ b/arch/arm/include/asm/pgtable.h</span>
<span class="quote">&gt; @@ -97,6 +97,7 @@ extern pgprot_t		pgprot_s2_device;</span>
<span class="quote">&gt;  #define PAGE_READONLY		_MOD_PROT(pgprot_user, L_PTE_USER | L_PTE_RDONLY | L_PTE_XN)</span>
<span class="quote">&gt;  #define PAGE_READONLY_EXEC	_MOD_PROT(pgprot_user, L_PTE_USER | L_PTE_RDONLY)</span>
<span class="quote">&gt;  #define PAGE_KERNEL		_MOD_PROT(pgprot_kernel, L_PTE_XN)</span>
<span class="quote">&gt; +#define PAGE_KERNEL_RO		_MOD_PROT(pgprot_kernel, L_PTE_XN | L_PTE_RDONLY)</span>
<span class="quote">&gt;  #define PAGE_KERNEL_EXEC	pgprot_kernel</span>
<span class="quote">&gt;  #define PAGE_HYP		_MOD_PROT(pgprot_kernel, L_PTE_HYP | L_PTE_XN)</span>
<span class="quote">&gt;  #define PAGE_HYP_EXEC		_MOD_PROT(pgprot_kernel, L_PTE_HYP | L_PTE_RDONLY)</span>
<span class="quote">&gt; diff --git a/arch/arm/include/asm/proc-fns.h b/arch/arm/include/asm/proc-fns.h</span>
<span class="quote">&gt; index f2e1af4..6e26714 100644</span>
<span class="quote">&gt; --- a/arch/arm/include/asm/proc-fns.h</span>
<span class="quote">&gt; +++ b/arch/arm/include/asm/proc-fns.h</span>
<span class="quote">&gt; @@ -131,6 +131,15 @@ extern void cpu_resume(void);</span>
<span class="quote">&gt;  		pg &amp;= ~(PTRS_PER_PGD*sizeof(pgd_t)-1);	\</span>
<span class="quote">&gt;  		(pgd_t *)phys_to_virt(pg);		\</span>
<span class="quote">&gt;  	})</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +#define cpu_set_ttbr0(val)					\</span>
<span class="quote">&gt; +	do {							\</span>
<span class="quote">&gt; +		u64 ttbr = val;					\</span>
<span class="quote">&gt; +		__asm__(&quot;mcrr	p15, 0, %Q0, %R0, c2&quot;		\</span>
<span class="quote">&gt; +			: : &quot;r&quot; (ttbr));	\</span>
<span class="quote">&gt; +	} while (0)</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt;  #else</span>
<span class="quote">&gt;  #define cpu_get_pgd()	\</span>
<span class="quote">&gt;  	({						\</span>
<span class="quote">&gt; @@ -140,6 +149,30 @@ extern void cpu_resume(void);</span>
<span class="quote">&gt;  		pg &amp;= ~0x3fff;				\</span>
<span class="quote">&gt;  		(pgd_t *)phys_to_virt(pg);		\</span>
<span class="quote">&gt;  	})</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +#define cpu_set_ttbr(nr, val)					\</span>
<span class="quote">&gt; +	do {							\</span>
<span class="quote">&gt; +		u64 ttbr = val;					\</span>
<span class="quote">&gt; +		__asm__(&quot;mcr	p15, 0, %0, c2, c0, 0&quot;		\</span>
<span class="quote">&gt; +			: : &quot;r&quot; (ttbr));			\</span>
<span class="quote">&gt; +	} while (0)</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +#define cpu_get_ttbr(nr)					\</span>
<span class="quote">&gt; +	({							\</span>
<span class="quote">&gt; +		unsigned long ttbr;				\</span>
<span class="quote">&gt; +		__asm__(&quot;mrc	p15, 0, %0, c2, c0, 0&quot;		\</span>
<span class="quote">&gt; +			: &quot;=r&quot; (ttbr));				\</span>
<span class="quote">&gt; +		ttbr;						\</span>
<span class="quote">&gt; +	})</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +#define cpu_set_ttbr0(val)					\</span>
<span class="quote">&gt; +	do {							\</span>
<span class="quote">&gt; +		u64 ttbr = val;					\</span>
<span class="quote">&gt; +		__asm__(&quot;mcr	p15, 0, %0, c2, c0, 0&quot;		\</span>
<span class="quote">&gt; +			: : &quot;r&quot; (ttbr));			\</span>
<span class="quote">&gt; +	} while (0)</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +</span>

You could instead lift and extend the definitions provided in kvm_hyp.h,
and use the read_sysreg/write_sysreg helpers defined in cp15.h.

Thanks,

	M.
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=176771">Abbott Liu</a> - Oct. 17, 2017, 1:28 p.m.</div>
<pre class="content">
2017.10.12  05:42 AM  Russell King - ARM Linux [mailto:linux@armlinux.org.uk] wrote:
<span class="quote">
&gt;&gt; Please don&#39;t make this &quot;exclusive&quot; just conditionally call </span>
<span class="quote">&gt;&gt; kasan_early_init(), remove the call to start_kernel from </span>
<span class="quote">&gt;&gt; kasan_early_init and keep the call to start_kernel here.</span>
<span class="quote">&gt;iow:</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;#ifdef CONFIG_KASAN</span>
<span class="quote">&gt;	bl	kasan_early_init</span>
<span class="quote">&gt;#endif</span>
<span class="quote">&gt;	b	start_kernel</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;This has the advantage that we don&#39;t leave any stack frame from</span>
<span class="quote">&gt;kasan_early_init() on the init task stack.</span>

Thanks for your review.  I tested your opinion and it work well.
I agree with you that it is better to use follow code
#ifdef CONFIG_KASAN
	bl	kasan_early_init
#endif
	b	start_kernel

than :
#ifdef CONFIG_KASAN
	bl	kasan_early_init
#else
	b	start_kernel
#endif
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=166571">Russell King - ARM Linux</a> - Oct. 19, 2017, 11:09 a.m.</div>
<pre class="content">
On Wed, Oct 11, 2017 at 04:22:17PM +0800, Abbott Liu wrote:
<span class="quote">&gt; diff --git a/arch/arm/include/asm/pgalloc.h b/arch/arm/include/asm/pgalloc.h</span>
<span class="quote">&gt; index b2902a5..10cee6a 100644</span>
<span class="quote">&gt; --- a/arch/arm/include/asm/pgalloc.h</span>
<span class="quote">&gt; +++ b/arch/arm/include/asm/pgalloc.h</span>
<span class="quote">&gt; @@ -50,8 +50,11 @@ static inline void pud_populate(struct mm_struct *mm, pud_t *pud, pmd_t *pmd)</span>
<span class="quote">&gt;   */</span>
<span class="quote">&gt;  #define pmd_alloc_one(mm,addr)		({ BUG(); ((pmd_t *)2); })</span>
<span class="quote">&gt;  #define pmd_free(mm, pmd)		do { } while (0)</span>
<span class="quote">&gt; +#ifndef CONFIG_KASAN</span>
<span class="quote">&gt;  #define pud_populate(mm,pmd,pte)	BUG()</span>
<span class="quote">&gt; -</span>
<span class="quote">&gt; +#else</span>
<span class="quote">&gt; +#define pud_populate(mm,pmd,pte)	do { } while (0)</span>
<span class="quote">&gt; +#endif</span>

Please explain this change - we don&#39;t have a &quot;pud&quot; as far as the rest of
the Linux MM layer is concerned, so why do we need it for kasan?

I suspect it comes from the way we wrap up the page tables - where ARM
does it one way (because it has to) vs the subsequently merged method
which is completely upside down to what ARMs doing, and therefore is
totally incompatible and impossible to fit in with our way.
<span class="quote">
&gt; diff --git a/arch/arm/include/asm/proc-fns.h b/arch/arm/include/asm/proc-fns.h</span>
<span class="quote">&gt; index f2e1af4..6e26714 100644</span>
<span class="quote">&gt; --- a/arch/arm/include/asm/proc-fns.h</span>
<span class="quote">&gt; +++ b/arch/arm/include/asm/proc-fns.h</span>
<span class="quote">&gt; @@ -131,6 +131,15 @@ extern void cpu_resume(void);</span>
<span class="quote">&gt;  		pg &amp;= ~(PTRS_PER_PGD*sizeof(pgd_t)-1);	\</span>
<span class="quote">&gt;  		(pgd_t *)phys_to_virt(pg);		\</span>
<span class="quote">&gt;  	})</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +#define cpu_set_ttbr0(val)					\</span>
<span class="quote">&gt; +	do {							\</span>
<span class="quote">&gt; +		u64 ttbr = val;					\</span>
<span class="quote">&gt; +		__asm__(&quot;mcrr	p15, 0, %Q0, %R0, c2&quot;		\</span>
<span class="quote">&gt; +			: : &quot;r&quot; (ttbr));	\</span>
<span class="quote">&gt; +	} while (0)</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt;  #else</span>
<span class="quote">&gt;  #define cpu_get_pgd()	\</span>
<span class="quote">&gt;  	({						\</span>
<span class="quote">&gt; @@ -140,6 +149,30 @@ extern void cpu_resume(void);</span>
<span class="quote">&gt;  		pg &amp;= ~0x3fff;				\</span>
<span class="quote">&gt;  		(pgd_t *)phys_to_virt(pg);		\</span>
<span class="quote">&gt;  	})</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +#define cpu_set_ttbr(nr, val)					\</span>
<span class="quote">&gt; +	do {							\</span>
<span class="quote">&gt; +		u64 ttbr = val;					\</span>
<span class="quote">&gt; +		__asm__(&quot;mcr	p15, 0, %0, c2, c0, 0&quot;		\</span>
<span class="quote">&gt; +			: : &quot;r&quot; (ttbr));			\</span>
<span class="quote">&gt; +	} while (0)</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +#define cpu_get_ttbr(nr)					\</span>
<span class="quote">&gt; +	({							\</span>
<span class="quote">&gt; +		unsigned long ttbr;				\</span>
<span class="quote">&gt; +		__asm__(&quot;mrc	p15, 0, %0, c2, c0, 0&quot;		\</span>
<span class="quote">&gt; +			: &quot;=r&quot; (ttbr));				\</span>
<span class="quote">&gt; +		ttbr;						\</span>
<span class="quote">&gt; +	})</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +#define cpu_set_ttbr0(val)					\</span>
<span class="quote">&gt; +	do {							\</span>
<span class="quote">&gt; +		u64 ttbr = val;					\</span>
<span class="quote">&gt; +		__asm__(&quot;mcr	p15, 0, %0, c2, c0, 0&quot;		\</span>
<span class="quote">&gt; +			: : &quot;r&quot; (ttbr));			\</span>
<span class="quote">&gt; +	} while (0)</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt;  #endif</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  #else	/*!CONFIG_MMU */</span>
<span class="quote">&gt; diff --git a/arch/arm/include/asm/thread_info.h b/arch/arm/include/asm/thread_info.h</span>
<span class="quote">&gt; index 1d468b5..52c4858 100644</span>
<span class="quote">&gt; --- a/arch/arm/include/asm/thread_info.h</span>
<span class="quote">&gt; +++ b/arch/arm/include/asm/thread_info.h</span>
<span class="quote">&gt; @@ -16,7 +16,11 @@</span>
<span class="quote">&gt;  #include &lt;asm/fpstate.h&gt;</span>
<span class="quote">&gt;  #include &lt;asm/page.h&gt;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; +#ifdef CONFIG_KASAN</span>
<span class="quote">&gt; +#define THREAD_SIZE_ORDER       2</span>
<span class="quote">&gt; +#else</span>
<span class="quote">&gt;  #define THREAD_SIZE_ORDER	1</span>
<span class="quote">&gt; +#endif</span>
<span class="quote">&gt;  #define THREAD_SIZE		(PAGE_SIZE &lt;&lt; THREAD_SIZE_ORDER)</span>
<span class="quote">&gt;  #define THREAD_START_SP		(THREAD_SIZE - 8)</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; diff --git a/arch/arm/kernel/head-common.S b/arch/arm/kernel/head-common.S</span>
<span class="quote">&gt; index 8733012..c17f4a2 100644</span>
<span class="quote">&gt; --- a/arch/arm/kernel/head-common.S</span>
<span class="quote">&gt; +++ b/arch/arm/kernel/head-common.S</span>
<span class="quote">&gt; @@ -101,7 +101,11 @@ __mmap_switched:</span>
<span class="quote">&gt;  	str	r2, [r6]			@ Save atags pointer</span>
<span class="quote">&gt;  	cmp	r7, #0</span>
<span class="quote">&gt;  	strne	r0, [r7]			@ Save control register values</span>
<span class="quote">&gt; +#ifdef CONFIG_KASAN</span>
<span class="quote">&gt; +	b	kasan_early_init</span>
<span class="quote">&gt; +#else</span>
<span class="quote">&gt;  	b	start_kernel</span>
<span class="quote">&gt; +#endif</span>
<span class="quote">&gt;  ENDPROC(__mmap_switched)</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	.align	2</span>
<span class="quote">&gt; diff --git a/arch/arm/kernel/setup.c b/arch/arm/kernel/setup.c</span>
<span class="quote">&gt; index 8e9a3e4..985d9a3 100644</span>
<span class="quote">&gt; --- a/arch/arm/kernel/setup.c</span>
<span class="quote">&gt; +++ b/arch/arm/kernel/setup.c</span>
<span class="quote">&gt; @@ -62,6 +62,7 @@</span>
<span class="quote">&gt;  #include &lt;asm/unwind.h&gt;</span>
<span class="quote">&gt;  #include &lt;asm/memblock.h&gt;</span>
<span class="quote">&gt;  #include &lt;asm/virt.h&gt;</span>
<span class="quote">&gt; +#include &lt;asm/kasan.h&gt;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  #include &quot;atags.h&quot;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; @@ -1108,6 +1109,7 @@ void __init setup_arch(char **cmdline_p)</span>
<span class="quote">&gt;  	early_ioremap_reset();</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	paging_init(mdesc);</span>
<span class="quote">&gt; +	kasan_init();</span>
<span class="quote">&gt;  	request_standard_resources(mdesc);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	if (mdesc-&gt;restart)</span>
<span class="quote">&gt; diff --git a/arch/arm/mm/Makefile b/arch/arm/mm/Makefile</span>
<span class="quote">&gt; index 950d19b..498c316 100644</span>
<span class="quote">&gt; --- a/arch/arm/mm/Makefile</span>
<span class="quote">&gt; +++ b/arch/arm/mm/Makefile</span>
<span class="quote">&gt; @@ -106,4 +106,9 @@ obj-$(CONFIG_CACHE_L2X0)	+= cache-l2x0.o l2c-l2x0-resume.o</span>
<span class="quote">&gt;  obj-$(CONFIG_CACHE_L2X0_PMU)	+= cache-l2x0-pmu.o</span>
<span class="quote">&gt;  obj-$(CONFIG_CACHE_XSC3L2)	+= cache-xsc3l2.o</span>
<span class="quote">&gt;  obj-$(CONFIG_CACHE_TAUROS2)	+= cache-tauros2.o</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +KASAN_SANITIZE_kasan_init.o    := n</span>
<span class="quote">&gt; +obj-$(CONFIG_KASAN)            += kasan_init.o</span>

Why is this placed in the middle of the cache object listing?
<span class="quote">
&gt; +</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt;  obj-$(CONFIG_CACHE_UNIPHIER)	+= cache-uniphier.o</span>
<span class="quote">&gt; diff --git a/arch/arm/mm/kasan_init.c b/arch/arm/mm/kasan_init.c</span>
<span class="quote">&gt; new file mode 100644</span>
<span class="quote">&gt; index 0000000..2bf0782</span>
<span class="quote">&gt; --- /dev/null</span>
<span class="quote">&gt; +++ b/arch/arm/mm/kasan_init.c</span>
<span class="quote">&gt; @@ -0,0 +1,257 @@</span>
<span class="quote">&gt; +#include &lt;linux/bootmem.h&gt;</span>
<span class="quote">&gt; +#include &lt;linux/kasan.h&gt;</span>
<span class="quote">&gt; +#include &lt;linux/kernel.h&gt;</span>
<span class="quote">&gt; +#include &lt;linux/memblock.h&gt;</span>
<span class="quote">&gt; +#include &lt;linux/start_kernel.h&gt;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +#include &lt;asm/cputype.h&gt;</span>
<span class="quote">&gt; +#include &lt;asm/highmem.h&gt;</span>
<span class="quote">&gt; +#include &lt;asm/mach/map.h&gt;</span>
<span class="quote">&gt; +#include &lt;asm/memory.h&gt;</span>
<span class="quote">&gt; +#include &lt;asm/page.h&gt;</span>
<span class="quote">&gt; +#include &lt;asm/pgalloc.h&gt;</span>
<span class="quote">&gt; +#include &lt;asm/pgtable.h&gt;</span>
<span class="quote">&gt; +#include &lt;asm/procinfo.h&gt;</span>
<span class="quote">&gt; +#include &lt;asm/proc-fns.h&gt;</span>
<span class="quote">&gt; +#include &lt;asm/tlbflush.h&gt;</span>
<span class="quote">&gt; +#include &lt;asm/cp15.h&gt;</span>
<span class="quote">&gt; +#include &lt;linux/sched/task.h&gt;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +#include &quot;mm.h&quot;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +static pgd_t tmp_page_table[PTRS_PER_PGD] __initdata __aligned(1ULL &lt;&lt; 14);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +pmd_t tmp_pmd_table[PTRS_PER_PMD] __page_aligned_bss;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +static __init void *kasan_alloc_block(size_t size, int node)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	return memblock_virt_alloc_try_nid(size, size, __pa(MAX_DMA_ADDRESS),</span>
<span class="quote">&gt; +					BOOTMEM_ALLOC_ACCESSIBLE, node);</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +static void __init kasan_early_pmd_populate(unsigned long start, unsigned long end, pud_t *pud)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	unsigned long addr;</span>
<span class="quote">&gt; +	unsigned long next;</span>
<span class="quote">&gt; +	pmd_t *pmd;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	pmd = pmd_offset(pud, start);</span>
<span class="quote">&gt; +	for (addr = start; addr &lt; end;) {</span>
<span class="quote">&gt; +		pmd_populate_kernel(&amp;init_mm, pmd, kasan_zero_pte);</span>
<span class="quote">&gt; +		next = pmd_addr_end(addr, end);</span>
<span class="quote">&gt; +		addr = next;</span>
<span class="quote">&gt; +		flush_pmd_entry(pmd);</span>
<span class="quote">&gt; +		pmd++;</span>
<span class="quote">&gt; +	}</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +static void __init kasan_early_pud_populate(unsigned long start, unsigned long end, pgd_t *pgd)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	unsigned long addr;</span>
<span class="quote">&gt; +	unsigned long next;</span>
<span class="quote">&gt; +	pud_t *pud;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	pud = pud_offset(pgd, start);</span>
<span class="quote">&gt; +	for (addr = start; addr &lt; end;) {</span>
<span class="quote">&gt; +		next = pud_addr_end(addr, end);</span>
<span class="quote">&gt; +		kasan_early_pmd_populate(addr, next, pud);</span>
<span class="quote">&gt; +		addr = next;</span>
<span class="quote">&gt; +		pud++;</span>
<span class="quote">&gt; +	}</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +void __init kasan_map_early_shadow(pgd_t *pgdp)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	int i;</span>
<span class="quote">&gt; +	unsigned long start = KASAN_SHADOW_START;</span>
<span class="quote">&gt; +	unsigned long end = KASAN_SHADOW_END;</span>
<span class="quote">&gt; +	unsigned long addr;</span>
<span class="quote">&gt; +	unsigned long next;</span>
<span class="quote">&gt; +	pgd_t *pgd;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	for (i = 0; i &lt; PTRS_PER_PTE; i++)</span>
<span class="quote">&gt; +		set_pte_at(&amp;init_mm, KASAN_SHADOW_START + i*PAGE_SIZE,</span>
<span class="quote">&gt; +			&amp;kasan_zero_pte[i], pfn_pte(</span>
<span class="quote">&gt; +				virt_to_pfn(kasan_zero_page),</span>
<span class="quote">&gt; +				__pgprot(_L_PTE_DEFAULT | L_PTE_DIRTY | L_PTE_XN)));</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	pgd = pgd_offset_k(start);</span>
<span class="quote">&gt; +	for (addr = start; addr &lt; end;) {</span>
<span class="quote">&gt; +		next = pgd_addr_end(addr, end);</span>
<span class="quote">&gt; +		kasan_early_pud_populate(addr, next, pgd);</span>
<span class="quote">&gt; +		addr = next;</span>
<span class="quote">&gt; +		pgd++;</span>
<span class="quote">&gt; +	}</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +extern struct proc_info_list *lookup_processor_type(unsigned int);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +void __init kasan_early_init(void)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	struct proc_info_list *list;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	/*</span>
<span class="quote">&gt; +	 * locate processor in the list of supported processor</span>
<span class="quote">&gt; +	 * types.  The linker builds this table for us from the</span>
<span class="quote">&gt; +	 * entries in arch/arm/mm/proc-*.S</span>
<span class="quote">&gt; +	 */</span>
<span class="quote">&gt; +	list = lookup_processor_type(read_cpuid_id());</span>
<span class="quote">&gt; +	if (list) {</span>
<span class="quote">&gt; +#ifdef MULTI_CPU</span>
<span class="quote">&gt; +		processor = *list-&gt;proc;</span>
<span class="quote">&gt; +#endif</span>
<span class="quote">&gt; +	}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	BUILD_BUG_ON(KASAN_SHADOW_OFFSET != KASAN_SHADOW_END - (1UL &lt;&lt; 29));</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	kasan_map_early_shadow(swapper_pg_dir);</span>
<span class="quote">&gt; +	start_kernel();</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +static void __init clear_pgds(unsigned long start,</span>
<span class="quote">&gt; +			unsigned long end)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	for (; start &amp;&amp; start &lt; end; start += PMD_SIZE)</span>
<span class="quote">&gt; +		pmd_clear(pmd_off_k(start));</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +pte_t * __meminit kasan_pte_populate(pmd_t *pmd, unsigned long addr, int node)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	pte_t *pte = pte_offset_kernel(pmd, addr);</span>
<span class="quote">&gt; +	if (pte_none(*pte)) {</span>
<span class="quote">&gt; +		pte_t entry;</span>
<span class="quote">&gt; +		void *p = kasan_alloc_block(PAGE_SIZE, node);</span>
<span class="quote">&gt; +		if (!p)</span>
<span class="quote">&gt; +			return NULL;</span>
<span class="quote">&gt; +		entry = pfn_pte(virt_to_pfn(p), __pgprot(_L_PTE_DEFAULT | L_PTE_DIRTY | L_PTE_XN));</span>
<span class="quote">&gt; +		set_pte_at(&amp;init_mm, addr, pte, entry);</span>
<span class="quote">&gt; +	}</span>
<span class="quote">&gt; +	return pte;</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +pmd_t * __meminit kasan_pmd_populate(pud_t *pud, unsigned long addr, int node)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	pmd_t *pmd = pmd_offset(pud, addr);</span>
<span class="quote">&gt; +	if (pmd_none(*pmd)) {</span>
<span class="quote">&gt; +		void *p = kasan_alloc_block(PAGE_SIZE, node);</span>
<span class="quote">&gt; +		if (!p)</span>
<span class="quote">&gt; +			return NULL;</span>
<span class="quote">&gt; +		pmd_populate_kernel(&amp;init_mm, pmd, p);</span>
<span class="quote">&gt; +	}</span>
<span class="quote">&gt; +	return pmd;</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +pud_t * __meminit kasan_pud_populate(pgd_t *pgd, unsigned long addr, int node)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	pud_t *pud = pud_offset(pgd, addr);</span>
<span class="quote">&gt; +	if (pud_none(*pud)) {</span>
<span class="quote">&gt; +		void *p = kasan_alloc_block(PAGE_SIZE, node);</span>
<span class="quote">&gt; +		if (!p)</span>
<span class="quote">&gt; +			return NULL;</span>
<span class="quote">&gt; +		pr_err(&quot;populating pud addr %lx\n&quot;, addr);</span>
<span class="quote">&gt; +		pud_populate(&amp;init_mm, pud, p);</span>
<span class="quote">&gt; +	}</span>
<span class="quote">&gt; +	return pud;</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +pgd_t * __meminit kasan_pgd_populate(unsigned long addr, int node)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	pgd_t *pgd = pgd_offset_k(addr);</span>
<span class="quote">&gt; +	if (pgd_none(*pgd)) {</span>
<span class="quote">&gt; +		void *p = kasan_alloc_block(PAGE_SIZE, node);</span>
<span class="quote">&gt; +		if (!p)</span>
<span class="quote">&gt; +			return NULL;</span>
<span class="quote">&gt; +		pgd_populate(&amp;init_mm, pgd, p);</span>
<span class="quote">&gt; +	}</span>
<span class="quote">&gt; +	return pgd;</span>
<span class="quote">&gt; +}</span>

This all looks wrong - you are aware that on non-LPAE platforms, there
is only a _two_ level page table - the top level page table is 16K in
size, and each _individual_ lower level page table is actually 1024
bytes, but we do some special handling in the kernel to combine two
together.  It looks to me that you allocate memory for each Linux-
abstracted page table level whether the hardware needs it or not.

Is there any reason why the pre-existing &quot;create_mapping()&quot; function
can&#39;t be used, and you&#39;ve had to rewrite that code here?
<span class="quote">
&gt; +</span>
<span class="quote">&gt; +static int __init create_mapping(unsigned long start, unsigned long end, int node)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	unsigned long addr = start;</span>
<span class="quote">&gt; +	pgd_t *pgd;</span>
<span class="quote">&gt; +	pud_t *pud;</span>
<span class="quote">&gt; +	pmd_t *pmd;</span>
<span class="quote">&gt; +	pte_t *pte;</span>

A blank line would help between the auto variables and the code of the
function.
<span class="quote">
&gt; +	pr_info(&quot;populating shadow for %lx, %lx\n&quot;, start, end);</span>

Blank line here too please.
<span class="quote">
&gt; +	for (; addr &lt; end; addr += PAGE_SIZE) {</span>
<span class="quote">&gt; +		pgd = kasan_pgd_populate(addr, node);</span>
<span class="quote">&gt; +		if (!pgd)</span>
<span class="quote">&gt; +			return -ENOMEM;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +		pud = kasan_pud_populate(pgd, addr, node);</span>
<span class="quote">&gt; +		if (!pud)</span>
<span class="quote">&gt; +			return -ENOMEM;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +		pmd = kasan_pmd_populate(pud, addr, node);</span>
<span class="quote">&gt; +		if (!pmd)</span>
<span class="quote">&gt; +			return -ENOMEM;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +		pte = kasan_pte_populate(pmd, addr, node);</span>
<span class="quote">&gt; +		if (!pte)</span>
<span class="quote">&gt; +			return -ENOMEM;</span>
<span class="quote">&gt; +	}</span>
<span class="quote">&gt; +	return 0;</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +void __init kasan_init(void)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	struct memblock_region *reg;</span>
<span class="quote">&gt; +	u64 orig_ttbr0;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	orig_ttbr0 = cpu_get_ttbr(0);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +#ifdef CONFIG_ARM_LPAE</span>
<span class="quote">&gt; +	memcpy(tmp_pmd_table, pgd_page_vaddr(*pgd_offset_k(KASAN_SHADOW_START)), sizeof(tmp_pmd_table));</span>
<span class="quote">&gt; +	memcpy(tmp_page_table, swapper_pg_dir, sizeof(tmp_page_table));</span>
<span class="quote">&gt; +	set_pgd(&amp;tmp_page_table[pgd_index(KASAN_SHADOW_START)], __pgd(__pa(tmp_pmd_table) | PMD_TYPE_TABLE | L_PGD_SWAPPER));</span>
<span class="quote">&gt; +	cpu_set_ttbr0(__pa(tmp_page_table));</span>
<span class="quote">&gt; +#else</span>
<span class="quote">&gt; +	memcpy(tmp_page_table, swapper_pg_dir, sizeof(tmp_page_table));</span>
<span class="quote">&gt; +	cpu_set_ttbr0(__pa(tmp_page_table));</span>
<span class="quote">&gt; +#endif</span>
<span class="quote">&gt; +	flush_cache_all();</span>
<span class="quote">&gt; +	local_flush_bp_all();</span>
<span class="quote">&gt; +	local_flush_tlb_all();</span>

What are you trying to achieve with all this complexity?  Some comments
might be useful, especially for those of us who don&#39;t know the internals
of kasan.
<span class="quote">
&gt; +</span>
<span class="quote">&gt; +	clear_pgds(KASAN_SHADOW_START, KASAN_SHADOW_END);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	kasan_populate_zero_shadow(</span>
<span class="quote">&gt; +		kasan_mem_to_shadow((void *)KASAN_SHADOW_START),</span>
<span class="quote">&gt; +		kasan_mem_to_shadow((void *)KASAN_SHADOW_END));</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	kasan_populate_zero_shadow(kasan_mem_to_shadow((void *)VMALLOC_START),</span>
<span class="quote">&gt; +				kasan_mem_to_shadow((void *)-1UL) + 1);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	for_each_memblock(memory, reg) {</span>
<span class="quote">&gt; +		void *start = __va(reg-&gt;base);</span>
<span class="quote">&gt; +		void *end = __va(reg-&gt;base + reg-&gt;size);</span>

Isn&#39;t this going to complain if the translation macro debugging is enabled?
<span class="quote">
&gt; +</span>
<span class="quote">&gt; +		if (reg-&gt;base + reg-&gt;size &gt; arm_lowmem_limit)</span>
<span class="quote">&gt; +			end = __va(arm_lowmem_limit);</span>
<span class="quote">&gt; +		if (start &gt;= end)</span>
<span class="quote">&gt; +			break;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +		create_mapping((unsigned long)kasan_mem_to_shadow(start),</span>
<span class="quote">&gt; +			(unsigned long)kasan_mem_to_shadow(end),</span>
<span class="quote">&gt; +			NUMA_NO_NODE);</span>
<span class="quote">&gt; +	}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	/*1.the module&#39;s global variable is in MODULES_VADDR ~ MODULES_END,so we need mapping.</span>
<span class="quote">&gt; +	  *2.PKMAP_BASE ~ PKMAP_BASE+PMD_SIZE&#39;s shadow and MODULES_VADDR ~ MODULES_END&#39;s shadow</span>
<span class="quote">&gt; +	  *  is in the same PMD_SIZE, so we cant use kasan_populate_zero_shadow.</span>
<span class="quote">&gt; +	  *</span>
<span class="quote">&gt; +	  **/</span>
<span class="quote">&gt; +	create_mapping((unsigned long)kasan_mem_to_shadow((void *)MODULES_VADDR),</span>
<span class="quote">&gt; +		(unsigned long)kasan_mem_to_shadow((void *)(PKMAP_BASE+PMD_SIZE)),</span>
<span class="quote">&gt; +		NUMA_NO_NODE);</span>
<span class="quote">&gt; +	cpu_set_ttbr0(orig_ttbr0);</span>
<span class="quote">&gt; +	flush_cache_all();</span>
<span class="quote">&gt; +	local_flush_bp_all();</span>
<span class="quote">&gt; +	local_flush_tlb_all();</span>
<span class="quote">&gt; +	memset(kasan_zero_page, 0, PAGE_SIZE);</span>
<span class="quote">&gt; +	pr_info(&quot;Kernel address sanitizer initialized\n&quot;);</span>
<span class="quote">&gt; +	init_task.kasan_depth = 0;</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; diff --git a/mm/kasan/kasan.c b/mm/kasan/kasan.c</span>
<span class="quote">&gt; index 6f319fb..12749da 100644</span>
<span class="quote">&gt; --- a/mm/kasan/kasan.c</span>
<span class="quote">&gt; +++ b/mm/kasan/kasan.c</span>
<span class="quote">&gt; @@ -358,7 +358,7 @@ void kasan_cache_create(struct kmem_cache *cache, size_t *size,</span>
<span class="quote">&gt;  	if (redzone_adjust &gt; 0)</span>
<span class="quote">&gt;  		*size += redzone_adjust;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; -	*size = min(KMALLOC_MAX_SIZE, max(*size, cache-&gt;object_size +</span>
<span class="quote">&gt; +	*size = min((size_t)KMALLOC_MAX_SIZE, max(*size, cache-&gt;object_size +</span>
<span class="quote">&gt;  					optimal_redzone(cache-&gt;object_size)));</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	/*</span>
<span class="quote">&gt; -- </span>
<span class="quote">&gt; 2.9.0</span>
<span class="quote">&gt;</span>
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=166571">Russell King - ARM Linux</a> - Oct. 19, 2017, 12:01 p.m.</div>
<pre class="content">
On Thu, Oct 12, 2017 at 02:42:49AM +0300, Dmitry Osipenko wrote:
<span class="quote">&gt; On 11.10.2017 11:22, Abbott Liu wrote:</span>
<span class="quote">&gt; &gt; +void __init kasan_map_early_shadow(pgd_t *pgdp)</span>
<span class="quote">&gt; &gt; +{</span>
<span class="quote">&gt; &gt; +	int i;</span>
<span class="quote">&gt; &gt; +	unsigned long start = KASAN_SHADOW_START;</span>
<span class="quote">&gt; &gt; +	unsigned long end = KASAN_SHADOW_END;</span>
<span class="quote">&gt; &gt; +	unsigned long addr;</span>
<span class="quote">&gt; &gt; +	unsigned long next;</span>
<span class="quote">&gt; &gt; +	pgd_t *pgd;</span>
<span class="quote">&gt; &gt; +</span>
<span class="quote">&gt; &gt; +	for (i = 0; i &lt; PTRS_PER_PTE; i++)</span>
<span class="quote">&gt; &gt; +		set_pte_at(&amp;init_mm, KASAN_SHADOW_START + i*PAGE_SIZE,</span>
<span class="quote">&gt; &gt; +			&amp;kasan_zero_pte[i], pfn_pte(</span>
<span class="quote">&gt; &gt; +				virt_to_pfn(kasan_zero_page),</span>
<span class="quote">&gt; &gt; +				__pgprot(_L_PTE_DEFAULT | L_PTE_DIRTY | L_PTE_XN)));</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Shouldn&#39;t all __pgprot&#39;s contain L_PTE_MT_WRITETHROUGH ?</span>

One of the architecture restrictions is that the cache attributes of
all aliases should match (but there is a specific workaround that
permits this, provided that the dis-similar mappings aren&#39;t accessed
without certain intervening instructions.)

Why should it be L_PTE_MT_WRITETHROUGH, and not the same cache
attributes as the lowmem mapping?
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=176771">Abbott Liu</a> - Feb. 24, 2018, 2:28 p.m.</div>
<pre class="content">
On Oct 19, 2017 at 19:09, Russell King - ARM Linux [mailto:linux@armlinux.org.uk] wrote:
<span class="quote">&gt;On Wed, Oct 11, 2017 at 04:22:17PM +0800, Abbott Liu wrote:</span>
<span class="quote">&gt;&gt; +#else</span>
<span class="quote">&gt;&gt; +#define pud_populate(mm,pmd,pte)	do { } while (0)</span>
<span class="quote">&gt;&gt; +#endif</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;Please explain this change - we don&#39;t have a &quot;pud&quot; as far as the rest of</span>
<span class="quote">&gt;the Linux MM layer is concerned, so why do we need it for kasan?</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;I suspect it comes from the way we wrap up the page tables - where ARM</span>
<span class="quote">&gt;does it one way (because it has to) vs the subsequently merged method</span>
<span class="quote">&gt;which is completely upside down to what ARMs doing, and therefore is</span>
<span class="quote">&gt;totally incompatible and impossible to fit in with our way.</span>

We will use pud_polulate in kasan_populate_zero_shadow function.
....
<span class="quote">&gt;&gt;  obj-$(CONFIG_CACHE_TAUROS2)	+= cache-tauros2.o</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +KASAN_SANITIZE_kasan_init.o    := n</span>
<span class="quote">&gt;&gt; +obj-$(CONFIG_KASAN)            += kasan_init.o</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;Why is this placed in the middle of the cache object listing?</span>

Sorry, I will place this at the end of the arch/arm/mm/Makefile.
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt;  obj-$(CONFIG_CACHE_UNIPHIER)	+= cache-uniphier.o</span>
...
<span class="quote">
&gt;&gt; +pgd_t * __meminit kasan_pgd_populate(unsigned long addr, int node)</span>
<span class="quote">&gt;&gt; +{</span>
<span class="quote">&gt;&gt; +	pgd_t *pgd = pgd_offset_k(addr);</span>
<span class="quote">&gt;&gt; +	if (pgd_none(*pgd)) {</span>
<span class="quote">&gt;&gt; +		void *p = kasan_alloc_block(PAGE_SIZE, node);</span>
<span class="quote">&gt;&gt; +		if (!p)</span>
<span class="quote">&gt;&gt; +			return NULL;</span>
<span class="quote">&gt;&gt; +		pgd_populate(&amp;init_mm, pgd, p);</span>
<span class="quote">&gt;&gt; +	}</span>
<span class="quote">&gt;&gt; +	return pgd;</span>
<span class="quote">&gt;&gt; +}</span>
<span class="quote">
&gt;This all looks wrong - you are aware that on non-LPAE platforms, there</span>
<span class="quote">&gt;is only a _two_ level page table - the top level page table is 16K in</span>
<span class="quote">&gt;size, and each _individual_ lower level page table is actually 1024</span>
<span class="quote">&gt;bytes, but we do some special handling in the kernel to combine two</span>
<span class="quote">&gt;together.  It looks to me that you allocate memory for each Linux-</span>
<span class="quote">&gt;abstracted page table level whether the hardware needs it or not.</span>

You are right. If non-LPAE platform check if(pgd_none(*pgd)) true,
void *p = kasan_alloc_block(PAGE_SIZE, node) alloc space is not enough.
But the the function kasan_pgd_populate only used in :
Kasan_init-&gt; create_mapping-&gt; kasan_pgd_populate , so when non-LPAE platform
the if (pgd_none(*pgd)) always false.
But I also think change those code is much better :
if (IS_ENABLED(CONFIG_ARM_LPAE)) {
   p = kasan_alloc_block(PAGE_SIZE, node);
} else {
   /* non-LPAE need 16K for first level pagetabe*/
   p = kasan_alloc_block(PAGE_SIZE*4, node);
}
<span class="quote">
&gt;Is there any reason why the pre-existing &quot;create_mapping()&quot; function</span>
<span class="quote">&gt;can&#39;t be used, and you&#39;ve had to rewrite that code here?</span>

Two reason:
1) Here create_mapping can dynamic alloc phys memory space for mapping to virtual space 
Which from start to end, but the create_mapping in arch/arm/mm/mmu.c can&#39;t.
2) for LPAE, create_mapping need alloc pgd which we need use virtual space below 0xc0000000,
 here create_mapping can alloc pgd, but create_mapping in arch/arm/mm/mmu.c can&#39;t.
<span class="quote">
&gt;&gt; +</span>
<span class="quote">&gt;&gt; +static int __init create_mapping(unsigned long start, unsigned long end, int node)</span>
<span class="quote">&gt;&gt; +{</span>
<span class="quote">&gt;&gt; +	unsigned long addr = start;</span>
<span class="quote">&gt;&gt; +	pgd_t *pgd;</span>
<span class="quote">&gt;&gt; +	pud_t *pud;</span>
<span class="quote">&gt;&gt; +	pmd_t *pmd;</span>
<span class="quote">&gt;&gt; +	pte_t *pte;</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;A blank line would help between the auto variables and the code of the</span>
<span class="quote">&gt;function.</span>

Ok, I will add blank line in new version.
<span class="quote">&gt;&gt; +	pr_info(&quot;populating shadow for %lx, %lx\n&quot;, start, end);</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;Blank line here too please.</span>

Ok, I will add blank line in new version.
<span class="quote">
&gt;&gt; +	for (; addr &lt; end; addr += PAGE_SIZE) {</span>
<span class="quote">&gt;&gt; +		pgd = kasan_pgd_populate(addr, node);</span>
<span class="quote">&gt;&gt; +		if (!pgd)</span>
<span class="quote">&gt;&gt; +			return -ENOMEM;</span>
...
<span class="quote">&gt;&gt; +void __init kasan_init(void)</span>
<span class="quote">&gt;&gt; +{</span>
<span class="quote">&gt;&gt; +	struct memblock_region *reg;</span>
<span class="quote">&gt;&gt; +	u64 orig_ttbr0;</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +	orig_ttbr0 = cpu_get_ttbr(0);</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +#ifdef CONFIG_ARM_LPAE</span>
<span class="quote">&gt;&gt; +	memcpy(tmp_pmd_table, pgd_page_vaddr(*pgd_offset_k(KASAN_SHADOW_START)), sizeof(tmp_pmd_table));</span>
<span class="quote">&gt;&gt; +	memcpy(tmp_page_table, swapper_pg_dir, sizeof(tmp_page_table));</span>
<span class="quote">&gt;&gt; +	set_pgd(&amp;tmp_page_table[pgd_index(KASAN_SHADOW_START)], __pgd(__pa(tmp_pmd_table) | PMD_TYPE_TABLE | L_PGD_SWAPPER));</span>
<span class="quote">&gt;&gt; +	cpu_set_ttbr0(__pa(tmp_page_table));</span>
<span class="quote">&gt;&gt; +#else</span>
<span class="quote">&gt;&gt; +	memcpy(tmp_page_table, swapper_pg_dir, sizeof(tmp_page_table));</span>
<span class="quote">&gt;&gt; +	cpu_set_ttbr0(__pa(tmp_page_table));</span>
<span class="quote">&gt;&gt; +#endif</span>
<span class="quote">&gt;&gt; +	flush_cache_all();</span>
<span class="quote">&gt;&gt; +	local_flush_bp_all();</span>
<span class="quote">&gt;&gt; +	local_flush_tlb_all();</span>
<span class="quote">
&gt;What are you trying to achieve with all this complexity?  Some comments</span>
<span class="quote">&gt;might be useful, especially for those of us who don&#39;t know the internals</span>
<span class="quote">&gt;of kasan.</span>
OK, I will add some comments in kasan_init function in new version.
...
<span class="quote">&gt;&gt; +	for_each_memblock(memory, reg) {</span>
<span class="quote">&gt;&gt; +		void *start = __va(reg-&gt;base);</span>
<span class="quote">&gt;&gt; +		void *end = __va(reg-&gt;base + reg-&gt;size);</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;Isn&#39;t this going to complain if the translation macro debugging is enabled?</span>

Sorry, I don&#39;t what is the translation macro. Can you tell me.
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/arch/arm/include/asm/kasan.h b/arch/arm/include/asm/kasan.h</span>
new file mode 100644
<span class="p_header">index 0000000..90ee60c</span>
<span class="p_header">--- /dev/null</span>
<span class="p_header">+++ b/arch/arm/include/asm/kasan.h</span>
<span class="p_chunk">@@ -0,0 +1,20 @@</span> <span class="p_context"></span>
<span class="p_add">+#ifndef __ASM_KASAN_H</span>
<span class="p_add">+#define __ASM_KASAN_H</span>
<span class="p_add">+</span>
<span class="p_add">+#ifdef CONFIG_KASAN</span>
<span class="p_add">+</span>
<span class="p_add">+#include &lt;asm/kasan_def.h&gt;</span>
<span class="p_add">+/*</span>
<span class="p_add">+ * Compiler uses shadow offset assuming that addresses start</span>
<span class="p_add">+ * from 0. Kernel addresses don&#39;t start from 0, so shadow</span>
<span class="p_add">+ * for kernel really starts from &#39;compiler&#39;s shadow offset&#39; +</span>
<span class="p_add">+ * (&#39;kernel address space start&#39; &gt;&gt; KASAN_SHADOW_SCALE_SHIFT)</span>
<span class="p_add">+ */</span>
<span class="p_add">+</span>
<span class="p_add">+extern void kasan_init(void);</span>
<span class="p_add">+</span>
<span class="p_add">+#else</span>
<span class="p_add">+static inline void kasan_init(void) { }</span>
<span class="p_add">+#endif</span>
<span class="p_add">+</span>
<span class="p_add">+#endif</span>
<span class="p_header">diff --git a/arch/arm/include/asm/pgalloc.h b/arch/arm/include/asm/pgalloc.h</span>
<span class="p_header">index b2902a5..10cee6a 100644</span>
<span class="p_header">--- a/arch/arm/include/asm/pgalloc.h</span>
<span class="p_header">+++ b/arch/arm/include/asm/pgalloc.h</span>
<span class="p_chunk">@@ -50,8 +50,11 @@</span> <span class="p_context"> static inline void pud_populate(struct mm_struct *mm, pud_t *pud, pmd_t *pmd)</span>
  */
 #define pmd_alloc_one(mm,addr)		({ BUG(); ((pmd_t *)2); })
 #define pmd_free(mm, pmd)		do { } while (0)
<span class="p_add">+#ifndef CONFIG_KASAN</span>
 #define pud_populate(mm,pmd,pte)	BUG()
<span class="p_del">-</span>
<span class="p_add">+#else</span>
<span class="p_add">+#define pud_populate(mm,pmd,pte)	do { } while (0)</span>
<span class="p_add">+#endif</span>
 #endif	/* CONFIG_ARM_LPAE */
 
 extern pgd_t *pgd_alloc(struct mm_struct *mm);
<span class="p_header">diff --git a/arch/arm/include/asm/pgtable.h b/arch/arm/include/asm/pgtable.h</span>
<span class="p_header">index 1c46238..fdf343f 100644</span>
<span class="p_header">--- a/arch/arm/include/asm/pgtable.h</span>
<span class="p_header">+++ b/arch/arm/include/asm/pgtable.h</span>
<span class="p_chunk">@@ -97,6 +97,7 @@</span> <span class="p_context"> extern pgprot_t		pgprot_s2_device;</span>
 #define PAGE_READONLY		_MOD_PROT(pgprot_user, L_PTE_USER | L_PTE_RDONLY | L_PTE_XN)
 #define PAGE_READONLY_EXEC	_MOD_PROT(pgprot_user, L_PTE_USER | L_PTE_RDONLY)
 #define PAGE_KERNEL		_MOD_PROT(pgprot_kernel, L_PTE_XN)
<span class="p_add">+#define PAGE_KERNEL_RO		_MOD_PROT(pgprot_kernel, L_PTE_XN | L_PTE_RDONLY)</span>
 #define PAGE_KERNEL_EXEC	pgprot_kernel
 #define PAGE_HYP		_MOD_PROT(pgprot_kernel, L_PTE_HYP | L_PTE_XN)
 #define PAGE_HYP_EXEC		_MOD_PROT(pgprot_kernel, L_PTE_HYP | L_PTE_RDONLY)
<span class="p_header">diff --git a/arch/arm/include/asm/proc-fns.h b/arch/arm/include/asm/proc-fns.h</span>
<span class="p_header">index f2e1af4..6e26714 100644</span>
<span class="p_header">--- a/arch/arm/include/asm/proc-fns.h</span>
<span class="p_header">+++ b/arch/arm/include/asm/proc-fns.h</span>
<span class="p_chunk">@@ -131,6 +131,15 @@</span> <span class="p_context"> extern void cpu_resume(void);</span>
 		pg &amp;= ~(PTRS_PER_PGD*sizeof(pgd_t)-1);	\
 		(pgd_t *)phys_to_virt(pg);		\
 	})
<span class="p_add">+</span>
<span class="p_add">+#define cpu_set_ttbr0(val)					\</span>
<span class="p_add">+	do {							\</span>
<span class="p_add">+		u64 ttbr = val;					\</span>
<span class="p_add">+		__asm__(&quot;mcrr	p15, 0, %Q0, %R0, c2&quot;		\</span>
<span class="p_add">+			: : &quot;r&quot; (ttbr));	\</span>
<span class="p_add">+	} while (0)</span>
<span class="p_add">+</span>
<span class="p_add">+</span>
 #else
 #define cpu_get_pgd()	\
 	({						\
<span class="p_chunk">@@ -140,6 +149,30 @@</span> <span class="p_context"> extern void cpu_resume(void);</span>
 		pg &amp;= ~0x3fff;				\
 		(pgd_t *)phys_to_virt(pg);		\
 	})
<span class="p_add">+</span>
<span class="p_add">+#define cpu_set_ttbr(nr, val)					\</span>
<span class="p_add">+	do {							\</span>
<span class="p_add">+		u64 ttbr = val;					\</span>
<span class="p_add">+		__asm__(&quot;mcr	p15, 0, %0, c2, c0, 0&quot;		\</span>
<span class="p_add">+			: : &quot;r&quot; (ttbr));			\</span>
<span class="p_add">+	} while (0)</span>
<span class="p_add">+</span>
<span class="p_add">+#define cpu_get_ttbr(nr)					\</span>
<span class="p_add">+	({							\</span>
<span class="p_add">+		unsigned long ttbr;				\</span>
<span class="p_add">+		__asm__(&quot;mrc	p15, 0, %0, c2, c0, 0&quot;		\</span>
<span class="p_add">+			: &quot;=r&quot; (ttbr));				\</span>
<span class="p_add">+		ttbr;						\</span>
<span class="p_add">+	})</span>
<span class="p_add">+</span>
<span class="p_add">+#define cpu_set_ttbr0(val)					\</span>
<span class="p_add">+	do {							\</span>
<span class="p_add">+		u64 ttbr = val;					\</span>
<span class="p_add">+		__asm__(&quot;mcr	p15, 0, %0, c2, c0, 0&quot;		\</span>
<span class="p_add">+			: : &quot;r&quot; (ttbr));			\</span>
<span class="p_add">+	} while (0)</span>
<span class="p_add">+</span>
<span class="p_add">+</span>
 #endif
 
 #else	/*!CONFIG_MMU */
<span class="p_header">diff --git a/arch/arm/include/asm/thread_info.h b/arch/arm/include/asm/thread_info.h</span>
<span class="p_header">index 1d468b5..52c4858 100644</span>
<span class="p_header">--- a/arch/arm/include/asm/thread_info.h</span>
<span class="p_header">+++ b/arch/arm/include/asm/thread_info.h</span>
<span class="p_chunk">@@ -16,7 +16,11 @@</span> <span class="p_context"></span>
 #include &lt;asm/fpstate.h&gt;
 #include &lt;asm/page.h&gt;
 
<span class="p_add">+#ifdef CONFIG_KASAN</span>
<span class="p_add">+#define THREAD_SIZE_ORDER       2</span>
<span class="p_add">+#else</span>
 #define THREAD_SIZE_ORDER	1
<span class="p_add">+#endif</span>
 #define THREAD_SIZE		(PAGE_SIZE &lt;&lt; THREAD_SIZE_ORDER)
 #define THREAD_START_SP		(THREAD_SIZE - 8)
 
<span class="p_header">diff --git a/arch/arm/kernel/head-common.S b/arch/arm/kernel/head-common.S</span>
<span class="p_header">index 8733012..c17f4a2 100644</span>
<span class="p_header">--- a/arch/arm/kernel/head-common.S</span>
<span class="p_header">+++ b/arch/arm/kernel/head-common.S</span>
<span class="p_chunk">@@ -101,7 +101,11 @@</span> <span class="p_context"> __mmap_switched:</span>
 	str	r2, [r6]			@ Save atags pointer
 	cmp	r7, #0
 	strne	r0, [r7]			@ Save control register values
<span class="p_add">+#ifdef CONFIG_KASAN</span>
<span class="p_add">+	b	kasan_early_init</span>
<span class="p_add">+#else</span>
 	b	start_kernel
<span class="p_add">+#endif</span>
 ENDPROC(__mmap_switched)
 
 	.align	2
<span class="p_header">diff --git a/arch/arm/kernel/setup.c b/arch/arm/kernel/setup.c</span>
<span class="p_header">index 8e9a3e4..985d9a3 100644</span>
<span class="p_header">--- a/arch/arm/kernel/setup.c</span>
<span class="p_header">+++ b/arch/arm/kernel/setup.c</span>
<span class="p_chunk">@@ -62,6 +62,7 @@</span> <span class="p_context"></span>
 #include &lt;asm/unwind.h&gt;
 #include &lt;asm/memblock.h&gt;
 #include &lt;asm/virt.h&gt;
<span class="p_add">+#include &lt;asm/kasan.h&gt;</span>
 
 #include &quot;atags.h&quot;
 
<span class="p_chunk">@@ -1108,6 +1109,7 @@</span> <span class="p_context"> void __init setup_arch(char **cmdline_p)</span>
 	early_ioremap_reset();
 
 	paging_init(mdesc);
<span class="p_add">+	kasan_init();</span>
 	request_standard_resources(mdesc);
 
 	if (mdesc-&gt;restart)
<span class="p_header">diff --git a/arch/arm/mm/Makefile b/arch/arm/mm/Makefile</span>
<span class="p_header">index 950d19b..498c316 100644</span>
<span class="p_header">--- a/arch/arm/mm/Makefile</span>
<span class="p_header">+++ b/arch/arm/mm/Makefile</span>
<span class="p_chunk">@@ -106,4 +106,9 @@</span> <span class="p_context"> obj-$(CONFIG_CACHE_L2X0)	+= cache-l2x0.o l2c-l2x0-resume.o</span>
 obj-$(CONFIG_CACHE_L2X0_PMU)	+= cache-l2x0-pmu.o
 obj-$(CONFIG_CACHE_XSC3L2)	+= cache-xsc3l2.o
 obj-$(CONFIG_CACHE_TAUROS2)	+= cache-tauros2.o
<span class="p_add">+</span>
<span class="p_add">+KASAN_SANITIZE_kasan_init.o    := n</span>
<span class="p_add">+obj-$(CONFIG_KASAN)            += kasan_init.o</span>
<span class="p_add">+</span>
<span class="p_add">+</span>
 obj-$(CONFIG_CACHE_UNIPHIER)	+= cache-uniphier.o
<span class="p_header">diff --git a/arch/arm/mm/kasan_init.c b/arch/arm/mm/kasan_init.c</span>
new file mode 100644
<span class="p_header">index 0000000..2bf0782</span>
<span class="p_header">--- /dev/null</span>
<span class="p_header">+++ b/arch/arm/mm/kasan_init.c</span>
<span class="p_chunk">@@ -0,0 +1,257 @@</span> <span class="p_context"></span>
<span class="p_add">+#include &lt;linux/bootmem.h&gt;</span>
<span class="p_add">+#include &lt;linux/kasan.h&gt;</span>
<span class="p_add">+#include &lt;linux/kernel.h&gt;</span>
<span class="p_add">+#include &lt;linux/memblock.h&gt;</span>
<span class="p_add">+#include &lt;linux/start_kernel.h&gt;</span>
<span class="p_add">+</span>
<span class="p_add">+#include &lt;asm/cputype.h&gt;</span>
<span class="p_add">+#include &lt;asm/highmem.h&gt;</span>
<span class="p_add">+#include &lt;asm/mach/map.h&gt;</span>
<span class="p_add">+#include &lt;asm/memory.h&gt;</span>
<span class="p_add">+#include &lt;asm/page.h&gt;</span>
<span class="p_add">+#include &lt;asm/pgalloc.h&gt;</span>
<span class="p_add">+#include &lt;asm/pgtable.h&gt;</span>
<span class="p_add">+#include &lt;asm/procinfo.h&gt;</span>
<span class="p_add">+#include &lt;asm/proc-fns.h&gt;</span>
<span class="p_add">+#include &lt;asm/tlbflush.h&gt;</span>
<span class="p_add">+#include &lt;asm/cp15.h&gt;</span>
<span class="p_add">+#include &lt;linux/sched/task.h&gt;</span>
<span class="p_add">+</span>
<span class="p_add">+#include &quot;mm.h&quot;</span>
<span class="p_add">+</span>
<span class="p_add">+static pgd_t tmp_page_table[PTRS_PER_PGD] __initdata __aligned(1ULL &lt;&lt; 14);</span>
<span class="p_add">+</span>
<span class="p_add">+pmd_t tmp_pmd_table[PTRS_PER_PMD] __page_aligned_bss;</span>
<span class="p_add">+</span>
<span class="p_add">+static __init void *kasan_alloc_block(size_t size, int node)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return memblock_virt_alloc_try_nid(size, size, __pa(MAX_DMA_ADDRESS),</span>
<span class="p_add">+					BOOTMEM_ALLOC_ACCESSIBLE, node);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static void __init kasan_early_pmd_populate(unsigned long start, unsigned long end, pud_t *pud)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long addr;</span>
<span class="p_add">+	unsigned long next;</span>
<span class="p_add">+	pmd_t *pmd;</span>
<span class="p_add">+</span>
<span class="p_add">+	pmd = pmd_offset(pud, start);</span>
<span class="p_add">+	for (addr = start; addr &lt; end;) {</span>
<span class="p_add">+		pmd_populate_kernel(&amp;init_mm, pmd, kasan_zero_pte);</span>
<span class="p_add">+		next = pmd_addr_end(addr, end);</span>
<span class="p_add">+		addr = next;</span>
<span class="p_add">+		flush_pmd_entry(pmd);</span>
<span class="p_add">+		pmd++;</span>
<span class="p_add">+	}</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static void __init kasan_early_pud_populate(unsigned long start, unsigned long end, pgd_t *pgd)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long addr;</span>
<span class="p_add">+	unsigned long next;</span>
<span class="p_add">+	pud_t *pud;</span>
<span class="p_add">+</span>
<span class="p_add">+	pud = pud_offset(pgd, start);</span>
<span class="p_add">+	for (addr = start; addr &lt; end;) {</span>
<span class="p_add">+		next = pud_addr_end(addr, end);</span>
<span class="p_add">+		kasan_early_pmd_populate(addr, next, pud);</span>
<span class="p_add">+		addr = next;</span>
<span class="p_add">+		pud++;</span>
<span class="p_add">+	}</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void __init kasan_map_early_shadow(pgd_t *pgdp)</span>
<span class="p_add">+{</span>
<span class="p_add">+	int i;</span>
<span class="p_add">+	unsigned long start = KASAN_SHADOW_START;</span>
<span class="p_add">+	unsigned long end = KASAN_SHADOW_END;</span>
<span class="p_add">+	unsigned long addr;</span>
<span class="p_add">+	unsigned long next;</span>
<span class="p_add">+	pgd_t *pgd;</span>
<span class="p_add">+</span>
<span class="p_add">+	for (i = 0; i &lt; PTRS_PER_PTE; i++)</span>
<span class="p_add">+		set_pte_at(&amp;init_mm, KASAN_SHADOW_START + i*PAGE_SIZE,</span>
<span class="p_add">+			&amp;kasan_zero_pte[i], pfn_pte(</span>
<span class="p_add">+				virt_to_pfn(kasan_zero_page),</span>
<span class="p_add">+				__pgprot(_L_PTE_DEFAULT | L_PTE_DIRTY | L_PTE_XN)));</span>
<span class="p_add">+</span>
<span class="p_add">+	pgd = pgd_offset_k(start);</span>
<span class="p_add">+	for (addr = start; addr &lt; end;) {</span>
<span class="p_add">+		next = pgd_addr_end(addr, end);</span>
<span class="p_add">+		kasan_early_pud_populate(addr, next, pgd);</span>
<span class="p_add">+		addr = next;</span>
<span class="p_add">+		pgd++;</span>
<span class="p_add">+	}</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+extern struct proc_info_list *lookup_processor_type(unsigned int);</span>
<span class="p_add">+</span>
<span class="p_add">+void __init kasan_early_init(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct proc_info_list *list;</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * locate processor in the list of supported processor</span>
<span class="p_add">+	 * types.  The linker builds this table for us from the</span>
<span class="p_add">+	 * entries in arch/arm/mm/proc-*.S</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	list = lookup_processor_type(read_cpuid_id());</span>
<span class="p_add">+	if (list) {</span>
<span class="p_add">+#ifdef MULTI_CPU</span>
<span class="p_add">+		processor = *list-&gt;proc;</span>
<span class="p_add">+#endif</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	BUILD_BUG_ON(KASAN_SHADOW_OFFSET != KASAN_SHADOW_END - (1UL &lt;&lt; 29));</span>
<span class="p_add">+</span>
<span class="p_add">+</span>
<span class="p_add">+	kasan_map_early_shadow(swapper_pg_dir);</span>
<span class="p_add">+	start_kernel();</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static void __init clear_pgds(unsigned long start,</span>
<span class="p_add">+			unsigned long end)</span>
<span class="p_add">+{</span>
<span class="p_add">+	for (; start &amp;&amp; start &lt; end; start += PMD_SIZE)</span>
<span class="p_add">+		pmd_clear(pmd_off_k(start));</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+pte_t * __meminit kasan_pte_populate(pmd_t *pmd, unsigned long addr, int node)</span>
<span class="p_add">+{</span>
<span class="p_add">+	pte_t *pte = pte_offset_kernel(pmd, addr);</span>
<span class="p_add">+	if (pte_none(*pte)) {</span>
<span class="p_add">+		pte_t entry;</span>
<span class="p_add">+		void *p = kasan_alloc_block(PAGE_SIZE, node);</span>
<span class="p_add">+		if (!p)</span>
<span class="p_add">+			return NULL;</span>
<span class="p_add">+		entry = pfn_pte(virt_to_pfn(p), __pgprot(_L_PTE_DEFAULT | L_PTE_DIRTY | L_PTE_XN));</span>
<span class="p_add">+		set_pte_at(&amp;init_mm, addr, pte, entry);</span>
<span class="p_add">+	}</span>
<span class="p_add">+	return pte;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+pmd_t * __meminit kasan_pmd_populate(pud_t *pud, unsigned long addr, int node)</span>
<span class="p_add">+{</span>
<span class="p_add">+	pmd_t *pmd = pmd_offset(pud, addr);</span>
<span class="p_add">+	if (pmd_none(*pmd)) {</span>
<span class="p_add">+		void *p = kasan_alloc_block(PAGE_SIZE, node);</span>
<span class="p_add">+		if (!p)</span>
<span class="p_add">+			return NULL;</span>
<span class="p_add">+		pmd_populate_kernel(&amp;init_mm, pmd, p);</span>
<span class="p_add">+	}</span>
<span class="p_add">+	return pmd;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+pud_t * __meminit kasan_pud_populate(pgd_t *pgd, unsigned long addr, int node)</span>
<span class="p_add">+{</span>
<span class="p_add">+	pud_t *pud = pud_offset(pgd, addr);</span>
<span class="p_add">+	if (pud_none(*pud)) {</span>
<span class="p_add">+		void *p = kasan_alloc_block(PAGE_SIZE, node);</span>
<span class="p_add">+		if (!p)</span>
<span class="p_add">+			return NULL;</span>
<span class="p_add">+		pr_err(&quot;populating pud addr %lx\n&quot;, addr);</span>
<span class="p_add">+		pud_populate(&amp;init_mm, pud, p);</span>
<span class="p_add">+	}</span>
<span class="p_add">+	return pud;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+pgd_t * __meminit kasan_pgd_populate(unsigned long addr, int node)</span>
<span class="p_add">+{</span>
<span class="p_add">+	pgd_t *pgd = pgd_offset_k(addr);</span>
<span class="p_add">+	if (pgd_none(*pgd)) {</span>
<span class="p_add">+		void *p = kasan_alloc_block(PAGE_SIZE, node);</span>
<span class="p_add">+		if (!p)</span>
<span class="p_add">+			return NULL;</span>
<span class="p_add">+		pgd_populate(&amp;init_mm, pgd, p);</span>
<span class="p_add">+	}</span>
<span class="p_add">+	return pgd;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static int __init create_mapping(unsigned long start, unsigned long end, int node)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long addr = start;</span>
<span class="p_add">+	pgd_t *pgd;</span>
<span class="p_add">+	pud_t *pud;</span>
<span class="p_add">+	pmd_t *pmd;</span>
<span class="p_add">+	pte_t *pte;</span>
<span class="p_add">+	pr_info(&quot;populating shadow for %lx, %lx\n&quot;, start, end);</span>
<span class="p_add">+	for (; addr &lt; end; addr += PAGE_SIZE) {</span>
<span class="p_add">+		pgd = kasan_pgd_populate(addr, node);</span>
<span class="p_add">+		if (!pgd)</span>
<span class="p_add">+			return -ENOMEM;</span>
<span class="p_add">+</span>
<span class="p_add">+		pud = kasan_pud_populate(pgd, addr, node);</span>
<span class="p_add">+		if (!pud)</span>
<span class="p_add">+			return -ENOMEM;</span>
<span class="p_add">+</span>
<span class="p_add">+		pmd = kasan_pmd_populate(pud, addr, node);</span>
<span class="p_add">+		if (!pmd)</span>
<span class="p_add">+			return -ENOMEM;</span>
<span class="p_add">+</span>
<span class="p_add">+		pte = kasan_pte_populate(pmd, addr, node);</span>
<span class="p_add">+		if (!pte)</span>
<span class="p_add">+			return -ENOMEM;</span>
<span class="p_add">+	}</span>
<span class="p_add">+	return 0;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+</span>
<span class="p_add">+void __init kasan_init(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct memblock_region *reg;</span>
<span class="p_add">+	u64 orig_ttbr0;</span>
<span class="p_add">+</span>
<span class="p_add">+	orig_ttbr0 = cpu_get_ttbr(0);</span>
<span class="p_add">+</span>
<span class="p_add">+#ifdef CONFIG_ARM_LPAE</span>
<span class="p_add">+	memcpy(tmp_pmd_table, pgd_page_vaddr(*pgd_offset_k(KASAN_SHADOW_START)), sizeof(tmp_pmd_table));</span>
<span class="p_add">+	memcpy(tmp_page_table, swapper_pg_dir, sizeof(tmp_page_table));</span>
<span class="p_add">+	set_pgd(&amp;tmp_page_table[pgd_index(KASAN_SHADOW_START)], __pgd(__pa(tmp_pmd_table) | PMD_TYPE_TABLE | L_PGD_SWAPPER));</span>
<span class="p_add">+	cpu_set_ttbr0(__pa(tmp_page_table));</span>
<span class="p_add">+#else</span>
<span class="p_add">+	memcpy(tmp_page_table, swapper_pg_dir, sizeof(tmp_page_table));</span>
<span class="p_add">+	cpu_set_ttbr0(__pa(tmp_page_table));</span>
<span class="p_add">+#endif</span>
<span class="p_add">+	flush_cache_all();</span>
<span class="p_add">+	local_flush_bp_all();</span>
<span class="p_add">+	local_flush_tlb_all();</span>
<span class="p_add">+</span>
<span class="p_add">+	clear_pgds(KASAN_SHADOW_START, KASAN_SHADOW_END);</span>
<span class="p_add">+</span>
<span class="p_add">+	kasan_populate_zero_shadow(</span>
<span class="p_add">+		kasan_mem_to_shadow((void *)KASAN_SHADOW_START),</span>
<span class="p_add">+		kasan_mem_to_shadow((void *)KASAN_SHADOW_END));</span>
<span class="p_add">+</span>
<span class="p_add">+	kasan_populate_zero_shadow(kasan_mem_to_shadow((void *)VMALLOC_START),</span>
<span class="p_add">+				kasan_mem_to_shadow((void *)-1UL) + 1);</span>
<span class="p_add">+</span>
<span class="p_add">+	for_each_memblock(memory, reg) {</span>
<span class="p_add">+		void *start = __va(reg-&gt;base);</span>
<span class="p_add">+		void *end = __va(reg-&gt;base + reg-&gt;size);</span>
<span class="p_add">+</span>
<span class="p_add">+		if (reg-&gt;base + reg-&gt;size &gt; arm_lowmem_limit)</span>
<span class="p_add">+			end = __va(arm_lowmem_limit);</span>
<span class="p_add">+		if (start &gt;= end)</span>
<span class="p_add">+			break;</span>
<span class="p_add">+</span>
<span class="p_add">+		create_mapping((unsigned long)kasan_mem_to_shadow(start),</span>
<span class="p_add">+			(unsigned long)kasan_mem_to_shadow(end),</span>
<span class="p_add">+			NUMA_NO_NODE);</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	/*1.the module&#39;s global variable is in MODULES_VADDR ~ MODULES_END,so we need mapping.</span>
<span class="p_add">+	  *2.PKMAP_BASE ~ PKMAP_BASE+PMD_SIZE&#39;s shadow and MODULES_VADDR ~ MODULES_END&#39;s shadow</span>
<span class="p_add">+	  *  is in the same PMD_SIZE, so we cant use kasan_populate_zero_shadow.</span>
<span class="p_add">+	  *</span>
<span class="p_add">+	  **/</span>
<span class="p_add">+	create_mapping((unsigned long)kasan_mem_to_shadow((void *)MODULES_VADDR),</span>
<span class="p_add">+		(unsigned long)kasan_mem_to_shadow((void *)(PKMAP_BASE+PMD_SIZE)),</span>
<span class="p_add">+		NUMA_NO_NODE);</span>
<span class="p_add">+	cpu_set_ttbr0(orig_ttbr0);</span>
<span class="p_add">+	flush_cache_all();</span>
<span class="p_add">+	local_flush_bp_all();</span>
<span class="p_add">+	local_flush_tlb_all();</span>
<span class="p_add">+	memset(kasan_zero_page, 0, PAGE_SIZE);</span>
<span class="p_add">+	pr_info(&quot;Kernel address sanitizer initialized\n&quot;);</span>
<span class="p_add">+	init_task.kasan_depth = 0;</span>
<span class="p_add">+}</span>
<span class="p_header">diff --git a/mm/kasan/kasan.c b/mm/kasan/kasan.c</span>
<span class="p_header">index 6f319fb..12749da 100644</span>
<span class="p_header">--- a/mm/kasan/kasan.c</span>
<span class="p_header">+++ b/mm/kasan/kasan.c</span>
<span class="p_chunk">@@ -358,7 +358,7 @@</span> <span class="p_context"> void kasan_cache_create(struct kmem_cache *cache, size_t *size,</span>
 	if (redzone_adjust &gt; 0)
 		*size += redzone_adjust;
 
<span class="p_del">-	*size = min(KMALLOC_MAX_SIZE, max(*size, cache-&gt;object_size +</span>
<span class="p_add">+	*size = min((size_t)KMALLOC_MAX_SIZE, max(*size, cache-&gt;object_size +</span>
 					optimal_redzone(cache-&gt;object_size)));
 
 	/*

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



