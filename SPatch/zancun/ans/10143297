
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>[4.4,19/37] kaiser: load_new_mm_cr3() let SWITCH_USER_CR3 flush user - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    [4.4,19/37] kaiser: load_new_mm_cr3() let SWITCH_USER_CR3 flush user</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=37061">gregkh@linuxfoundation.org</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>Jan. 3, 2018, 8:11 p.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;20180103195057.835156819@linuxfoundation.org&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/10143297/mbox/"
   >mbox</a>
|
   <a href="/patch/10143297/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/10143297/">/patch/10143297/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
	[172.30.200.125])
	by pdx-korg-patchwork.web.codeaurora.org (Postfix) with ESMTP id
	0AD2E6034B for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Wed,  3 Jan 2018 20:31:48 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id F3B0B2930D
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Wed,  3 Jan 2018 20:31:47 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id E8AA52930B; Wed,  3 Jan 2018 20:31:47 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-6.9 required=2.0 tests=BAYES_00,RCVD_IN_DNSWL_HI
	autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id C2E782930B
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Wed,  3 Jan 2018 20:31:46 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1751950AbeACUbn (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Wed, 3 Jan 2018 15:31:43 -0500
Received: from mail.linuxfoundation.org ([140.211.169.12]:60924 &quot;EHLO
	mail.linuxfoundation.org&quot; rhost-flags-OK-OK-OK-OK) by vger.kernel.org
	with ESMTP id S1751762AbeACUMS (ORCPT
	&lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Wed, 3 Jan 2018 15:12:18 -0500
Received: from localhost (LFbn-1-12258-90.w90-92.abo.wanadoo.fr
	[90.92.71.90])
	by mail.linuxfoundation.org (Postfix) with ESMTPSA id DEA7689F;
	Wed,  3 Jan 2018 20:12:17 +0000 (UTC)
From: Greg Kroah-Hartman &lt;gregkh@linuxfoundation.org&gt;
To: linux-kernel@vger.kernel.org
Cc: Greg Kroah-Hartman &lt;gregkh@linuxfoundation.org&gt;,
	stable@vger.kernel.org, Hugh Dickins &lt;hughd@google.com&gt;,
	Jiri Kosina &lt;jkosina@suse.cz&gt;
Subject: [PATCH 4.4 19/37] kaiser: load_new_mm_cr3() let SWITCH_USER_CR3
	flush user
Date: Wed,  3 Jan 2018 21:11:25 +0100
Message-Id: &lt;20180103195057.835156819@linuxfoundation.org&gt;
X-Mailer: git-send-email 2.15.1
In-Reply-To: &lt;20180103195056.837404126@linuxfoundation.org&gt;
References: &lt;20180103195056.837404126@linuxfoundation.org&gt;
User-Agent: quilt/0.65
MIME-Version: 1.0
Content-Type: text/plain; charset=UTF-8
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=37061">gregkh@linuxfoundation.org</a> - Jan. 3, 2018, 8:11 p.m.</div>
<pre class="content">
4.4-stable review patch.  If anyone has any objections, please let me know.

------------------
<span class="from">
From: Hugh Dickins &lt;hughd@google.com&gt;</span>


We have many machines (Westmere, Sandybridge, Ivybridge) supporting
PCID but not INVPCID: on these load_new_mm_cr3() simply crashed.

Flushing user context inside load_new_mm_cr3() without the use of
invpcid is difficult: momentarily switch from kernel to user context
and back to do so?  I&#39;m not sure whether that can be safely done at
all, and would risk polluting user context with kernel internals,
and kernel context with stale user externals.

Instead, follow the hint in the comment that was there: change
X86_CR3_PCID_USER_VAR to be a per-cpu variable, then load_new_mm_cr3()
can leave a note in it, for SWITCH_USER_CR3 on return to userspace to
flush user context TLB, instead of default X86_CR3_PCID_USER_NOFLUSH.

Which works well enough that there&#39;s no need to do it this way only
when invpcid is unsupported: it&#39;s a good alternative to invpcid here.
But there&#39;s a couple of inlines in asm/tlbflush.h that need to do the
same trick, so it&#39;s best to localize all this per-cpu business in
mm/kaiser.c: moving that part of the initialization from setup_pcid()
to kaiser_setup_pcid(); with kaiser_flush_tlb_on_return_to_user() the
function for noting an X86_CR3_PCID_USER_FLUSH.  And let&#39;s keep a
KAISER_SHADOW_PGD_OFFSET in there, to avoid the extra OR on exit.

I did try to make the feature tests in asm/tlbflush.h more consistent
with each other: there seem to be far too many ways of performing such
tests, and I don&#39;t have a good grasp of their differences.  At first
I converted them all to be static_cpu_has(): but that proved to be a
mistake, as the comment in __native_flush_tlb_single() hints; so then
I reversed and made them all this_cpu_has().  Probably all gratuitous
change, but that&#39;s the way it&#39;s working at present.

I am slightly bothered by the way non-per-cpu X86_CR3_PCID_KERN_VAR
gets re-initialized by each cpu (before and after these changes):
no problem when (as usual) all cpus on a machine have the same
features, but in principle incorrect.  However, my experiment
to per-cpu-ify that one did not end well...
<span class="signed-off-by">
Signed-off-by: Hugh Dickins &lt;hughd@google.com&gt;</span>
<span class="acked-by">Acked-by: Jiri Kosina &lt;jkosina@suse.cz&gt;</span>
<span class="signed-off-by">Signed-off-by: Greg Kroah-Hartman &lt;gregkh@linuxfoundation.org&gt;</span>
---
 arch/x86/include/asm/kaiser.h   |   18 +++++++-----
 arch/x86/include/asm/tlbflush.h |   58 +++++++++++++++++++++++++++-------------
 arch/x86/kernel/cpu/common.c    |   22 ---------------
 arch/x86/mm/kaiser.c            |   50 ++++++++++++++++++++++++++++++----
 arch/x86/mm/tlb.c               |   46 ++++++++++++-------------------
 5 files changed, 114 insertions(+), 80 deletions(-)
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">--- a/arch/x86/include/asm/kaiser.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/kaiser.h</span>
<span class="p_chunk">@@ -32,13 +32,12 @@</span> <span class="p_context"> movq \reg, %cr3</span>
 .macro _SWITCH_TO_USER_CR3 reg
 movq %cr3, \reg
 andq $(~(X86_CR3_PCID_ASID_MASK | KAISER_SHADOW_PGD_OFFSET)), \reg
<span class="p_del">-/*</span>
<span class="p_del">- * This can obviously be one instruction by putting the</span>
<span class="p_del">- * KAISER_SHADOW_PGD_OFFSET bit in the X86_CR3_PCID_USER_VAR.</span>
<span class="p_del">- * But, just leave it now for simplicity.</span>
<span class="p_del">- */</span>
<span class="p_del">-orq  X86_CR3_PCID_USER_VAR, \reg</span>
<span class="p_del">-orq  $(KAISER_SHADOW_PGD_OFFSET), \reg</span>
<span class="p_add">+orq  PER_CPU_VAR(X86_CR3_PCID_USER_VAR), \reg</span>
<span class="p_add">+js   9f</span>
<span class="p_add">+// FLUSH this time, reset to NOFLUSH for next time</span>
<span class="p_add">+// But if nopcid?  Consider using 0x80 for user pcid?</span>
<span class="p_add">+movb $(0x80), PER_CPU_VAR(X86_CR3_PCID_USER_VAR+7)</span>
<span class="p_add">+9:</span>
 movq \reg, %cr3
 .endm
 
<span class="p_chunk">@@ -90,6 +89,11 @@</span> <span class="p_context"> movq PER_CPU_VAR(unsafe_stack_register_b</span>
 */
 DECLARE_PER_CPU_USER_MAPPED(unsigned long, unsafe_stack_register_backup);
 
<span class="p_add">+extern unsigned long X86_CR3_PCID_KERN_VAR;</span>
<span class="p_add">+DECLARE_PER_CPU(unsigned long, X86_CR3_PCID_USER_VAR);</span>
<span class="p_add">+</span>
<span class="p_add">+extern char __per_cpu_user_mapped_start[], __per_cpu_user_mapped_end[];</span>
<span class="p_add">+</span>
 /**
  *  kaiser_add_mapping - map a virtual memory part to the shadow (user) mapping
  *  @addr: the start address of the range
<span class="p_header">--- a/arch/x86/include/asm/tlbflush.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/tlbflush.h</span>
<span class="p_chunk">@@ -12,6 +12,7 @@</span> <span class="p_context"> static inline void __invpcid(unsigned lo</span>
 			     unsigned long type)
 {
 	struct { u64 d[2]; } desc = { { pcid, addr } };
<span class="p_add">+</span>
 	/*
 	 * The memory clobber is because the whole point is to invalidate
 	 * stale TLB entries and, especially if we&#39;re flushing global
<span class="p_chunk">@@ -130,27 +131,42 @@</span> <span class="p_context"> static inline void cr4_set_bits_and_upda</span>
 	cr4_set_bits(mask);
 }
 
<span class="p_add">+/*</span>
<span class="p_add">+ * Declare a couple of kaiser interfaces here for convenience,</span>
<span class="p_add">+ * to avoid the need for asm/kaiser.h in unexpected places.</span>
<span class="p_add">+ */</span>
<span class="p_add">+#ifdef CONFIG_KAISER</span>
<span class="p_add">+extern void kaiser_setup_pcid(void);</span>
<span class="p_add">+extern void kaiser_flush_tlb_on_return_to_user(void);</span>
<span class="p_add">+#else</span>
<span class="p_add">+static inline void kaiser_setup_pcid(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+}</span>
<span class="p_add">+static inline void kaiser_flush_tlb_on_return_to_user(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+}</span>
<span class="p_add">+#endif</span>
<span class="p_add">+</span>
 static inline void __native_flush_tlb(void)
 {
<span class="p_del">-	if (!cpu_feature_enabled(X86_FEATURE_INVPCID)) {</span>
<span class="p_del">-	 	/*</span>
<span class="p_del">-		 * If current-&gt;mm == NULL then we borrow a mm which may change during a</span>
<span class="p_del">-		 * task switch and therefore we must not be preempted while we write CR3</span>
<span class="p_del">-		 * back:</span>
<span class="p_add">+	if (this_cpu_has(X86_FEATURE_INVPCID)) {</span>
<span class="p_add">+		/*</span>
<span class="p_add">+		 * Note, this works with CR4.PCIDE=0 or 1.</span>
 		 */
<span class="p_del">-		preempt_disable();</span>
<span class="p_del">-		native_write_cr3(native_read_cr3());</span>
<span class="p_del">-		preempt_enable();</span>
<span class="p_add">+		invpcid_flush_all_nonglobals();</span>
 		return;
 	}
<span class="p_add">+</span>
 	/*
<span class="p_del">-	 * We are no longer using globals with KAISER, so a</span>
<span class="p_del">-	 * &quot;nonglobals&quot; flush would work too. But, this is more</span>
<span class="p_del">-	 * conservative.</span>
<span class="p_del">-	 *</span>
<span class="p_del">-	 * Note, this works with CR4.PCIDE=0 or 1.</span>
<span class="p_add">+	 * If current-&gt;mm == NULL then we borrow a mm which may change during a</span>
<span class="p_add">+	 * task switch and therefore we must not be preempted while we write CR3</span>
<span class="p_add">+	 * back:</span>
 	 */
<span class="p_del">-	invpcid_flush_all();</span>
<span class="p_add">+	preempt_disable();</span>
<span class="p_add">+	if (this_cpu_has(X86_FEATURE_PCID))</span>
<span class="p_add">+		kaiser_flush_tlb_on_return_to_user();</span>
<span class="p_add">+	native_write_cr3(native_read_cr3());</span>
<span class="p_add">+	preempt_enable();</span>
 }
 
 static inline void __native_flush_tlb_global_irq_disabled(void)
<span class="p_chunk">@@ -166,9 +182,13 @@</span> <span class="p_context"> static inline void __native_flush_tlb_gl</span>
 
 static inline void __native_flush_tlb_global(void)
 {
<span class="p_add">+#ifdef CONFIG_KAISER</span>
<span class="p_add">+	/* Globals are not used at all */</span>
<span class="p_add">+	__native_flush_tlb();</span>
<span class="p_add">+#else</span>
 	unsigned long flags;
 
<span class="p_del">-	if (static_cpu_has(X86_FEATURE_INVPCID)) {</span>
<span class="p_add">+	if (this_cpu_has(X86_FEATURE_INVPCID)) {</span>
 		/*
 		 * Using INVPCID is considerably faster than a pair of writes
 		 * to CR4 sandwiched inside an IRQ flag save/restore.
<span class="p_chunk">@@ -185,10 +205,9 @@</span> <span class="p_context"> static inline void __native_flush_tlb_gl</span>
 	 * be called from deep inside debugging code.)
 	 */
 	raw_local_irq_save(flags);
<span class="p_del">-</span>
 	__native_flush_tlb_global_irq_disabled();
<span class="p_del">-</span>
 	raw_local_irq_restore(flags);
<span class="p_add">+#endif</span>
 }
 
 static inline void __native_flush_tlb_single(unsigned long addr)
<span class="p_chunk">@@ -199,9 +218,12 @@</span> <span class="p_context"> static inline void __native_flush_tlb_si</span>
 	 *
 	 * The ASIDs used below are hard-coded.  But, we must not
 	 * call invpcid(type=1/2) before CR4.PCIDE=1.  Just call
<span class="p_del">-	 * invpcid in the case we are called early.</span>
<span class="p_add">+	 * invlpg in the case we are called early.</span>
 	 */
<span class="p_add">+</span>
 	if (!this_cpu_has(X86_FEATURE_INVPCID_SINGLE)) {
<span class="p_add">+		if (this_cpu_has(X86_FEATURE_PCID))</span>
<span class="p_add">+			kaiser_flush_tlb_on_return_to_user();</span>
 		asm volatile(&quot;invlpg (%0)&quot; ::&quot;r&quot; (addr) : &quot;memory&quot;);
 		return;
 	}
<span class="p_header">--- a/arch/x86/kernel/cpu/common.c</span>
<span class="p_header">+++ b/arch/x86/kernel/cpu/common.c</span>
<span class="p_chunk">@@ -321,33 +321,12 @@</span> <span class="p_context"> static __always_inline void setup_smap(s</span>
 	}
 }
 
<span class="p_del">-/*</span>
<span class="p_del">- * These can have bit 63 set, so we can not just use a plain &quot;or&quot;</span>
<span class="p_del">- * instruction to get their value or&#39;d into CR3.  It would take</span>
<span class="p_del">- * another register.  So, we use a memory reference to these</span>
<span class="p_del">- * instead.</span>
<span class="p_del">- *</span>
<span class="p_del">- * This is also handy because systems that do not support</span>
<span class="p_del">- * PCIDs just end up or&#39;ing a 0 into their CR3, which does</span>
<span class="p_del">- * no harm.</span>
<span class="p_del">- */</span>
<span class="p_del">-__aligned(PAGE_SIZE) unsigned long X86_CR3_PCID_KERN_VAR = 0;</span>
<span class="p_del">-__aligned(PAGE_SIZE) unsigned long X86_CR3_PCID_USER_VAR = 0;</span>
<span class="p_del">-</span>
 static void setup_pcid(struct cpuinfo_x86 *c)
 {
 	if (cpu_has(c, X86_FEATURE_PCID)) {
 		if (cpu_has(c, X86_FEATURE_PGE)) {
 			cr4_set_bits(X86_CR4_PCIDE);
 			/*
<span class="p_del">-			 * These variables are used by the entry/exit</span>
<span class="p_del">-			 * code to change PCIDs.</span>
<span class="p_del">-			 */</span>
<span class="p_del">-#ifdef CONFIG_KAISER</span>
<span class="p_del">-			X86_CR3_PCID_KERN_VAR = X86_CR3_PCID_KERN_NOFLUSH;</span>
<span class="p_del">-			X86_CR3_PCID_USER_VAR = X86_CR3_PCID_USER_NOFLUSH;</span>
<span class="p_del">-#endif</span>
<span class="p_del">-			/*</span>
 			 * INVPCID has two &quot;groups&quot; of types:
 			 * 1/2: Invalidate an individual address
 			 * 3/4: Invalidate all contexts
<span class="p_chunk">@@ -372,6 +351,7 @@</span> <span class="p_context"> static void setup_pcid(struct cpuinfo_x8</span>
 			clear_cpu_cap(c, X86_FEATURE_PCID);
 		}
 	}
<span class="p_add">+	kaiser_setup_pcid();</span>
 }
 
 /*
<span class="p_header">--- a/arch/x86/mm/kaiser.c</span>
<span class="p_header">+++ b/arch/x86/mm/kaiser.c</span>
<span class="p_chunk">@@ -12,12 +12,26 @@</span> <span class="p_context"></span>
 #include &lt;linux/ftrace.h&gt;
 
 #include &lt;asm/kaiser.h&gt;
<span class="p_add">+#include &lt;asm/tlbflush.h&gt;	/* to verify its kaiser declarations */</span>
 #include &lt;asm/pgtable.h&gt;
 #include &lt;asm/pgalloc.h&gt;
 #include &lt;asm/desc.h&gt;
<span class="p_add">+</span>
 #ifdef CONFIG_KAISER
<span class="p_add">+__visible</span>
<span class="p_add">+DEFINE_PER_CPU_USER_MAPPED(unsigned long, unsafe_stack_register_backup);</span>
<span class="p_add">+</span>
<span class="p_add">+/*</span>
<span class="p_add">+ * These can have bit 63 set, so we can not just use a plain &quot;or&quot;</span>
<span class="p_add">+ * instruction to get their value or&#39;d into CR3.  It would take</span>
<span class="p_add">+ * another register.  So, we use a memory reference to these instead.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * This is also handy because systems that do not support PCIDs</span>
<span class="p_add">+ * just end up or&#39;ing a 0 into their CR3, which does no harm.</span>
<span class="p_add">+ */</span>
<span class="p_add">+__aligned(PAGE_SIZE) unsigned long X86_CR3_PCID_KERN_VAR;</span>
<span class="p_add">+DEFINE_PER_CPU(unsigned long, X86_CR3_PCID_USER_VAR);</span>
 
<span class="p_del">-__visible DEFINE_PER_CPU_USER_MAPPED(unsigned long, unsafe_stack_register_backup);</span>
 /*
  * At runtime, the only things we map are some things for CPU
  * hotplug, and stacks for new processes.  No two CPUs will ever
<span class="p_chunk">@@ -239,9 +253,6 @@</span> <span class="p_context"> static void __init kaiser_init_all_pgds(</span>
 	WARN_ON(__ret);							\
 } while (0)
 
<span class="p_del">-extern char __per_cpu_user_mapped_start[], __per_cpu_user_mapped_end[];</span>
<span class="p_del">-extern unsigned long X86_CR3_PCID_KERN_VAR;</span>
<span class="p_del">-extern unsigned long X86_CR3_PCID_USER_VAR;</span>
 /*
  * If anything in here fails, we will likely die on one of the
  * first kernel-&gt;user transitions and init will die.  But, we
<span class="p_chunk">@@ -295,8 +306,6 @@</span> <span class="p_context"> void __init kaiser_init(void)</span>
 
 	kaiser_add_user_map_early(&amp;X86_CR3_PCID_KERN_VAR, PAGE_SIZE,
 				  __PAGE_KERNEL);
<span class="p_del">-	kaiser_add_user_map_early(&amp;X86_CR3_PCID_USER_VAR, PAGE_SIZE,</span>
<span class="p_del">-				  __PAGE_KERNEL);</span>
 }
 
 /* Add a mapping to the shadow mapping, and synchronize the mappings */
<span class="p_chunk">@@ -361,4 +370,33 @@</span> <span class="p_context"> pgd_t kaiser_set_shadow_pgd(pgd_t *pgdp,</span>
 	}
 	return pgd;
 }
<span class="p_add">+</span>
<span class="p_add">+void kaiser_setup_pcid(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long kern_cr3 = 0;</span>
<span class="p_add">+	unsigned long user_cr3 = KAISER_SHADOW_PGD_OFFSET;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (this_cpu_has(X86_FEATURE_PCID)) {</span>
<span class="p_add">+		kern_cr3 |= X86_CR3_PCID_KERN_NOFLUSH;</span>
<span class="p_add">+		user_cr3 |= X86_CR3_PCID_USER_NOFLUSH;</span>
<span class="p_add">+	}</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * These variables are used by the entry/exit</span>
<span class="p_add">+	 * code to change PCID and pgd and TLB flushing.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	X86_CR3_PCID_KERN_VAR = kern_cr3;</span>
<span class="p_add">+	this_cpu_write(X86_CR3_PCID_USER_VAR, user_cr3);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+/*</span>
<span class="p_add">+ * Make a note that this cpu will need to flush USER tlb on return to user.</span>
<span class="p_add">+ * Caller checks whether this_cpu_has(X86_FEATURE_PCID) before calling:</span>
<span class="p_add">+ * if cpu does not, then the NOFLUSH bit will never have been set.</span>
<span class="p_add">+ */</span>
<span class="p_add">+void kaiser_flush_tlb_on_return_to_user(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	this_cpu_write(X86_CR3_PCID_USER_VAR,</span>
<span class="p_add">+			X86_CR3_PCID_USER_FLUSH | KAISER_SHADOW_PGD_OFFSET);</span>
<span class="p_add">+}</span>
<span class="p_add">+EXPORT_SYMBOL(kaiser_flush_tlb_on_return_to_user);</span>
 #endif /* CONFIG_KAISER */
<span class="p_header">--- a/arch/x86/mm/tlb.c</span>
<span class="p_header">+++ b/arch/x86/mm/tlb.c</span>
<span class="p_chunk">@@ -6,13 +6,14 @@</span> <span class="p_context"></span>
 #include &lt;linux/interrupt.h&gt;
 #include &lt;linux/module.h&gt;
 #include &lt;linux/cpu.h&gt;
<span class="p_add">+#include &lt;linux/debugfs.h&gt;</span>
 
 #include &lt;asm/tlbflush.h&gt;
 #include &lt;asm/mmu_context.h&gt;
 #include &lt;asm/cache.h&gt;
 #include &lt;asm/apic.h&gt;
 #include &lt;asm/uv/uv.h&gt;
<span class="p_del">-#include &lt;linux/debugfs.h&gt;</span>
<span class="p_add">+#include &lt;asm/kaiser.h&gt;</span>
 
 /*
  *	TLB flushing, formerly SMP-only
<span class="p_chunk">@@ -38,34 +39,23 @@</span> <span class="p_context"> static void load_new_mm_cr3(pgd_t *pgdir</span>
 {
 	unsigned long new_mm_cr3 = __pa(pgdir);
 
<span class="p_del">-	/*</span>
<span class="p_del">-	 * KAISER, plus PCIDs needs some extra work here.  But,</span>
<span class="p_del">-	 * if either of features is not present, we need no</span>
<span class="p_del">-	 * PCIDs here and just do a normal, full TLB flush with</span>
<span class="p_del">-	 * the write_cr3()</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	if (!IS_ENABLED(CONFIG_KAISER) ||</span>
<span class="p_del">-	    !cpu_feature_enabled(X86_FEATURE_PCID))</span>
<span class="p_del">-		goto out_set_cr3;</span>
<span class="p_del">-	/*</span>
<span class="p_del">-	 * We reuse the same PCID for different tasks, so we must</span>
<span class="p_del">-	 * flush all the entires for the PCID out when we change</span>
<span class="p_del">-	 * tasks.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	new_mm_cr3 = X86_CR3_PCID_KERN_FLUSH | __pa(pgdir);</span>
<span class="p_del">-</span>
<span class="p_del">-	/*</span>
<span class="p_del">-	 * The flush from load_cr3() may leave old TLB entries</span>
<span class="p_del">-	 * for userspace in place.  We must flush that context</span>
<span class="p_del">-	 * separately.  We can theoretically delay doing this</span>
<span class="p_del">-	 * until we actually load up the userspace CR3, but</span>
<span class="p_del">-	 * that&#39;s a bit tricky.  We have to have the &quot;need to</span>
<span class="p_del">-	 * flush userspace PCID&quot; bit per-cpu and check it in the</span>
<span class="p_del">-	 * exit-to-userspace paths.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	invpcid_flush_single_context(X86_CR3_PCID_ASID_USER);</span>
<span class="p_add">+#ifdef CONFIG_KAISER</span>
<span class="p_add">+	if (this_cpu_has(X86_FEATURE_PCID)) {</span>
<span class="p_add">+		/*</span>
<span class="p_add">+		 * We reuse the same PCID for different tasks, so we must</span>
<span class="p_add">+		 * flush all the entries for the PCID out when we change tasks.</span>
<span class="p_add">+		 * Flush KERN below, flush USER when returning to userspace in</span>
<span class="p_add">+		 * kaiser&#39;s SWITCH_USER_CR3 (_SWITCH_TO_USER_CR3) macro.</span>
<span class="p_add">+		 *</span>
<span class="p_add">+		 * invpcid_flush_single_context(X86_CR3_PCID_ASID_USER) could</span>
<span class="p_add">+		 * do it here, but can only be used if X86_FEATURE_INVPCID is</span>
<span class="p_add">+		 * available - and many machines support pcid without invpcid.</span>
<span class="p_add">+		 */</span>
<span class="p_add">+		new_mm_cr3 |= X86_CR3_PCID_KERN_FLUSH;</span>
<span class="p_add">+		kaiser_flush_tlb_on_return_to_user();</span>
<span class="p_add">+	}</span>
<span class="p_add">+#endif /* CONFIG_KAISER */</span>
 
<span class="p_del">-out_set_cr3:</span>
 	/*
 	 * Caution: many callers of this function expect
 	 * that load_cr3() is serializing and orders TLB

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



