
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>[v5] mm, sysctl: make NUMA stats configurable - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    [v5] mm, sysctl: make NUMA stats configurable</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=175911">Kemi Wang</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>Oct. 18, 2017, 1:42 a.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;1508290927-8518-1-git-send-email-kemi.wang@intel.com&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/10013325/mbox/"
   >mbox</a>
|
   <a href="/patch/10013325/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/10013325/">/patch/10013325/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
	[172.30.200.125])
	by pdx-korg-patchwork.web.codeaurora.org (Postfix) with ESMTP id
	E4780600CC for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Wed, 18 Oct 2017 01:43:57 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id D628728A80
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Wed, 18 Oct 2017 01:43:57 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id CAED728A82; Wed, 18 Oct 2017 01:43:57 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-6.9 required=2.0 tests=BAYES_00,RCVD_IN_DNSWL_HI
	autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 908B828A80
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Wed, 18 Oct 2017 01:43:56 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1762305AbdJRBny (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Tue, 17 Oct 2017 21:43:54 -0400
Received: from mga11.intel.com ([192.55.52.93]:55652 &quot;EHLO mga11.intel.com&quot;
	rhost-flags-OK-OK-OK-OK) by vger.kernel.org with ESMTP
	id S1761475AbdJRBnw (ORCPT &lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Tue, 17 Oct 2017 21:43:52 -0400
Received: from fmsmga003.fm.intel.com ([10.253.24.29])
	by fmsmga102.fm.intel.com with ESMTP/TLS/DHE-RSA-AES256-GCM-SHA384;
	17 Oct 2017 18:43:51 -0700
X-ExtLoop1: 1
X-IronPort-AV: E=Sophos;i=&quot;5.43,393,1503385200&quot;; d=&quot;scan&#39;208&quot;;a=&quot;910935530&quot;
Received: from kemi-desktop.sh.intel.com ([10.239.13.103])
	by FMSMGA003.fm.intel.com with ESMTP; 17 Oct 2017 18:43:47 -0700
From: Kemi Wang &lt;kemi.wang@intel.com&gt;
To: &quot;Luis R . Rodriguez&quot; &lt;mcgrof@kernel.org&gt;,
	Kees Cook &lt;keescook@chromium.org&gt;,
	Andrew Morton &lt;akpm@linux-foundation.org&gt;,
	Jonathan Corbet &lt;corbet@lwn.net&gt;, Michal Hocko &lt;mhocko@suse.com&gt;,
	Mel Gorman &lt;mgorman@techsingularity.net&gt;,
	Johannes Weiner &lt;hannes@cmpxchg.org&gt;, Christopher Lameter &lt;cl@linux.com&gt;,
	Sebastian Andrzej Siewior &lt;bigeasy@linutronix.de&gt;,
	Vlastimil Babka &lt;vbabka@suse.cz&gt;,
	Andrey Ryabinin &lt;aryabinin@virtuozzo.com&gt;
Cc: Dave &lt;dave.hansen@linux.intel.com&gt;, Tim Chen &lt;tim.c.chen@intel.com&gt;,
	Andi Kleen &lt;andi.kleen@intel.com&gt;,
	Jesper Dangaard Brouer &lt;brouer@redhat.com&gt;,
	Ying Huang &lt;ying.huang@intel.com&gt;,
	Aaron Lu &lt;aaron.lu@intel.com&gt;, Kemi Wang &lt;kemi.wang@intel.com&gt;,
	Proc sysctl &lt;linux-fsdevel@vger.kernel.org&gt;,
	Linux MM &lt;linux-mm@kvack.org&gt;,
	Linux Kernel &lt;linux-kernel@vger.kernel.org&gt;,
	Linux API &lt;linux-api@vger.kernel.org&gt;
Subject: [PATCH v5] mm, sysctl: make NUMA stats configurable
Date: Wed, 18 Oct 2017 09:42:07 +0800
Message-Id: &lt;1508290927-8518-1-git-send-email-kemi.wang@intel.com&gt;
X-Mailer: git-send-email 2.7.4
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=175911">Kemi Wang</a> - Oct. 18, 2017, 1:42 a.m.</div>
<pre class="content">
This is the second step which introduces a tunable interface that allow
numa stats configurable for optimizing zone_statistics(), as suggested by
Dave Hansen and Ying Huang.
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=72672">Vlastimil Babka</a> - Oct. 18, 2017, 6:30 a.m.</div>
<pre class="content">
On 10/18/2017 03:42 AM, Kemi Wang wrote:
<span class="quote">&gt; This is the second step which introduces a tunable interface that allow</span>
<span class="quote">&gt; numa stats configurable for optimizing zone_statistics(), as suggested by</span>
<span class="quote">&gt; Dave Hansen and Ying Huang.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; =========================================================================</span>
<span class="quote">&gt; When page allocation performance becomes a bottleneck and you can tolerate</span>
<span class="quote">&gt; some possible tool breakage and decreased numa counter precision, you can</span>
<span class="quote">&gt; do:</span>
<span class="quote">&gt; 	echo 0 &gt; /proc/sys/vm/numa_stat</span>
<span class="quote">&gt; In this case, numa counter update is ignored. We can see about</span>
<span class="quote">&gt; *4.8%*(185-&gt;176) drop of cpu cycles per single page allocation and reclaim</span>
<span class="quote">&gt; on Jesper&#39;s page_bench01 (single thread) and *8.1%*(343-&gt;315) drop of cpu</span>
<span class="quote">&gt; cycles per single page allocation and reclaim on Jesper&#39;s page_bench03 (88</span>
<span class="quote">&gt; threads) running on a 2-Socket Broadwell-based server (88 threads, 126G</span>
<span class="quote">&gt; memory).</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Benchmark link provided by Jesper D Brouer(increase loop times to</span>
<span class="quote">&gt; 10000000):</span>
<span class="quote">&gt; https://github.com/netoptimizer/prototype-kernel/tree/master/kernel/mm/</span>
<span class="quote">&gt; bench</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; =========================================================================</span>
<span class="quote">&gt; When page allocation performance is not a bottleneck and you want all</span>
<span class="quote">&gt; tooling to work, you can do:</span>
<span class="quote">&gt; 	echo 1 &gt; /proc/sys/vm/numa_stat</span>
<span class="quote">&gt; This is system default setting.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Many thanks to Michal Hocko, Dave Hansen, Ying Huang and Vlastimil Babka</span>
<span class="quote">&gt; for comments to help improve the original patch.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; ChangeLog:</span>
<span class="quote">&gt;   V4-&gt;V5</span>
<span class="quote">&gt;   a) Scope vm_numa_stat_lock into the sysctl handler function, as suggested</span>
<span class="quote">&gt;   by Michal Hocko;</span>
<span class="quote">&gt;   b) Only allow 0/1 value when setting a value to numa_stat at userspace,</span>
<span class="quote">&gt;   that would keep the possibility for add auto mode in future (e.g. 2 for</span>
<span class="quote">&gt;   auto mode), as suggested by Michal Hocko.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt;   V3-&gt;V4</span>
<span class="quote">&gt;   a) Get rid of auto mode of numa stats, and may add it back if necessary,</span>
<span class="quote">&gt;   as alignment before;</span>
<span class="quote">&gt;   b) Skip NUMA_INTERLEAVE_HIT counter update when numa stats is disabled,</span>
<span class="quote">&gt;   as reported by Andrey Ryabinin. See commit &quot;de55c8b2519&quot; for details</span>
<span class="quote">&gt;   c) Remove extern declaration for those clear_numa_ function, and make</span>
<span class="quote">&gt;   them static in vmstat.c, as suggested by Vlastimil Babka.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt;   V2-&gt;V3:</span>
<span class="quote">&gt;   a) Propose a better way to use jump label to eliminate the overhead of</span>
<span class="quote">&gt;   branch selection in zone_statistics(), as inspired by Ying Huang;</span>
<span class="quote">&gt;   b) Add a paragraph in commit log to describe the way for branch target</span>
<span class="quote">&gt;   selection;</span>
<span class="quote">&gt;   c) Use a more descriptive name numa_stats_mode instead of vmstat_mode,</span>
<span class="quote">&gt;   and change the description accordingly, as suggested by Michal Hocko;</span>
<span class="quote">&gt;   d) Make this functionality NUMA-specific via ifdef</span>
<span class="quote">&gt; </span>
<span class="quote">&gt;   V1-&gt;V2:</span>
<span class="quote">&gt;   a) Merge to one patch;</span>
<span class="quote">&gt;   b) Use jump label to eliminate the overhead of branch selection;</span>
<span class="quote">&gt;   c) Add a single-time log message at boot time to help tell users what</span>
<span class="quote">&gt;   happened.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Reported-by: Jesper Dangaard Brouer &lt;brouer@redhat.com&gt;</span>
<span class="quote">&gt; Suggested-by: Dave Hansen &lt;dave.hansen@intel.com&gt;</span>
<span class="quote">&gt; Suggested-by: Ying Huang &lt;ying.huang@intel.com&gt;</span>
<span class="quote">&gt; Signed-off-by: Kemi Wang &lt;kemi.wang@intel.com&gt;</span>
<span class="acked-by">
Acked-by: Vlastimil Babka &lt;vbabka@suse.cz&gt;</span>
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=137061">Michal Hocko</a> - Oct. 19, 2017, 7:51 a.m.</div>
<pre class="content">
On Wed 18-10-17 09:42:07, Kemi Wang wrote:
<span class="quote">&gt; This is the second step which introduces a tunable interface that allow</span>
<span class="quote">&gt; numa stats configurable for optimizing zone_statistics(), as suggested by</span>
<span class="quote">&gt; Dave Hansen and Ying Huang.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; =========================================================================</span>
<span class="quote">&gt; When page allocation performance becomes a bottleneck and you can tolerate</span>
<span class="quote">&gt; some possible tool breakage and decreased numa counter precision, you can</span>
<span class="quote">&gt; do:</span>
<span class="quote">&gt; 	echo 0 &gt; /proc/sys/vm/numa_stat</span>
<span class="quote">&gt; In this case, numa counter update is ignored. We can see about</span>
<span class="quote">&gt; *4.8%*(185-&gt;176) drop of cpu cycles per single page allocation and reclaim</span>
<span class="quote">&gt; on Jesper&#39;s page_bench01 (single thread) and *8.1%*(343-&gt;315) drop of cpu</span>
<span class="quote">&gt; cycles per single page allocation and reclaim on Jesper&#39;s page_bench03 (88</span>
<span class="quote">&gt; threads) running on a 2-Socket Broadwell-based server (88 threads, 126G</span>
<span class="quote">&gt; memory).</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Benchmark link provided by Jesper D Brouer(increase loop times to</span>
<span class="quote">&gt; 10000000):</span>
<span class="quote">&gt; https://github.com/netoptimizer/prototype-kernel/tree/master/kernel/mm/</span>
<span class="quote">&gt; bench</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; =========================================================================</span>
<span class="quote">&gt; When page allocation performance is not a bottleneck and you want all</span>
<span class="quote">&gt; tooling to work, you can do:</span>
<span class="quote">&gt; 	echo 1 &gt; /proc/sys/vm/numa_stat</span>
<span class="quote">&gt; This is system default setting.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Many thanks to Michal Hocko, Dave Hansen, Ying Huang and Vlastimil Babka</span>
<span class="quote">&gt; for comments to help improve the original patch.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; ChangeLog:</span>
<span class="quote">&gt;   V4-&gt;V5</span>
<span class="quote">&gt;   a) Scope vm_numa_stat_lock into the sysctl handler function, as suggested</span>
<span class="quote">&gt;   by Michal Hocko;</span>
<span class="quote">&gt;   b) Only allow 0/1 value when setting a value to numa_stat at userspace,</span>
<span class="quote">&gt;   that would keep the possibility for add auto mode in future (e.g. 2 for</span>
<span class="quote">&gt;   auto mode), as suggested by Michal Hocko.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt;   V3-&gt;V4</span>
<span class="quote">&gt;   a) Get rid of auto mode of numa stats, and may add it back if necessary,</span>
<span class="quote">&gt;   as alignment before;</span>
<span class="quote">&gt;   b) Skip NUMA_INTERLEAVE_HIT counter update when numa stats is disabled,</span>
<span class="quote">&gt;   as reported by Andrey Ryabinin. See commit &quot;de55c8b2519&quot; for details</span>
<span class="quote">&gt;   c) Remove extern declaration for those clear_numa_ function, and make</span>
<span class="quote">&gt;   them static in vmstat.c, as suggested by Vlastimil Babka.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt;   V2-&gt;V3:</span>
<span class="quote">&gt;   a) Propose a better way to use jump label to eliminate the overhead of</span>
<span class="quote">&gt;   branch selection in zone_statistics(), as inspired by Ying Huang;</span>
<span class="quote">&gt;   b) Add a paragraph in commit log to describe the way for branch target</span>
<span class="quote">&gt;   selection;</span>
<span class="quote">&gt;   c) Use a more descriptive name numa_stats_mode instead of vmstat_mode,</span>
<span class="quote">&gt;   and change the description accordingly, as suggested by Michal Hocko;</span>
<span class="quote">&gt;   d) Make this functionality NUMA-specific via ifdef</span>
<span class="quote">&gt; </span>
<span class="quote">&gt;   V1-&gt;V2:</span>
<span class="quote">&gt;   a) Merge to one patch;</span>
<span class="quote">&gt;   b) Use jump label to eliminate the overhead of branch selection;</span>
<span class="quote">&gt;   c) Add a single-time log message at boot time to help tell users what</span>
<span class="quote">&gt;   happened.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Reported-by: Jesper Dangaard Brouer &lt;brouer@redhat.com&gt;</span>
<span class="quote">&gt; Suggested-by: Dave Hansen &lt;dave.hansen@intel.com&gt;</span>
<span class="quote">&gt; Suggested-by: Ying Huang &lt;ying.huang@intel.com&gt;</span>
<span class="quote">&gt; Signed-off-by: Kemi Wang &lt;kemi.wang@intel.com&gt;</span>
<span class="acked-by">
Acked-by: Michal Hocko &lt;mhocko@suse.com&gt;</span>

Thanks!
<span class="quote">
&gt; ---</span>
<span class="quote">&gt;  Documentation/sysctl/vm.txt | 16 +++++++++++</span>
<span class="quote">&gt;  include/linux/vmstat.h      | 10 +++++++</span>
<span class="quote">&gt;  kernel/sysctl.c             |  9 ++++++</span>
<span class="quote">&gt;  mm/mempolicy.c              |  3 ++</span>
<span class="quote">&gt;  mm/page_alloc.c             |  6 ++++</span>
<span class="quote">&gt;  mm/vmstat.c                 | 70 +++++++++++++++++++++++++++++++++++++++++++++</span>
<span class="quote">&gt;  6 files changed, 114 insertions(+)</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; diff --git a/Documentation/sysctl/vm.txt b/Documentation/sysctl/vm.txt</span>
<span class="quote">&gt; index 9baf66a..f65c5c7 100644</span>
<span class="quote">&gt; --- a/Documentation/sysctl/vm.txt</span>
<span class="quote">&gt; +++ b/Documentation/sysctl/vm.txt</span>
<span class="quote">&gt; @@ -58,6 +58,7 @@ Currently, these files are in /proc/sys/vm:</span>
<span class="quote">&gt;  - percpu_pagelist_fraction</span>
<span class="quote">&gt;  - stat_interval</span>
<span class="quote">&gt;  - stat_refresh</span>
<span class="quote">&gt; +- numa_stat</span>
<span class="quote">&gt;  - swappiness</span>
<span class="quote">&gt;  - user_reserve_kbytes</span>
<span class="quote">&gt;  - vfs_cache_pressure</span>
<span class="quote">&gt; @@ -792,6 +793,21 @@ with no ill effects: errors and warnings on these stats are suppressed.)</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  ==============================================================</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; +numa_stat</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +This interface allows runtime configuration of numa statistics.</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +When page allocation performance becomes a bottleneck and you can tolerate</span>
<span class="quote">&gt; +some possible tool breakage and decreased numa counter precision, you can</span>
<span class="quote">&gt; +do:</span>
<span class="quote">&gt; +	echo 0 &gt; /proc/sys/vm/numa_stat</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +When page allocation performance is not a bottleneck and you want all</span>
<span class="quote">&gt; +tooling to work, you can do:</span>
<span class="quote">&gt; +	echo 1 &gt; /proc/sys/vm/numa_stat</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +==============================================================</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt;  swappiness</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  This control is used to define how aggressive the kernel will swap</span>
<span class="quote">&gt; diff --git a/include/linux/vmstat.h b/include/linux/vmstat.h</span>
<span class="quote">&gt; index ade7cb5..c605c94 100644</span>
<span class="quote">&gt; --- a/include/linux/vmstat.h</span>
<span class="quote">&gt; +++ b/include/linux/vmstat.h</span>
<span class="quote">&gt; @@ -6,9 +6,19 @@</span>
<span class="quote">&gt;  #include &lt;linux/mmzone.h&gt;</span>
<span class="quote">&gt;  #include &lt;linux/vm_event_item.h&gt;</span>
<span class="quote">&gt;  #include &lt;linux/atomic.h&gt;</span>
<span class="quote">&gt; +#include &lt;linux/static_key.h&gt;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  extern int sysctl_stat_interval;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; +#ifdef CONFIG_NUMA</span>
<span class="quote">&gt; +#define ENABLE_NUMA_STAT   1</span>
<span class="quote">&gt; +#define DISABLE_NUMA_STAT   0</span>
<span class="quote">&gt; +extern int sysctl_vm_numa_stat;</span>
<span class="quote">&gt; +DECLARE_STATIC_KEY_TRUE(vm_numa_stat_key);</span>
<span class="quote">&gt; +extern int sysctl_vm_numa_stat_handler(struct ctl_table *table,</span>
<span class="quote">&gt; +		int write, void __user *buffer, size_t *length, loff_t *ppos);</span>
<span class="quote">&gt; +#endif</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt;  #ifdef CONFIG_VM_EVENT_COUNTERS</span>
<span class="quote">&gt;  /*</span>
<span class="quote">&gt;   * Light weight per cpu counter implementation.</span>
<span class="quote">&gt; diff --git a/kernel/sysctl.c b/kernel/sysctl.c</span>
<span class="quote">&gt; index d9c31bc..8f272db 100644</span>
<span class="quote">&gt; --- a/kernel/sysctl.c</span>
<span class="quote">&gt; +++ b/kernel/sysctl.c</span>
<span class="quote">&gt; @@ -1371,6 +1371,15 @@ static struct ctl_table vm_table[] = {</span>
<span class="quote">&gt;  		.mode           = 0644,</span>
<span class="quote">&gt;  		.proc_handler   = &amp;hugetlb_mempolicy_sysctl_handler,</span>
<span class="quote">&gt;  	},</span>
<span class="quote">&gt; +	{</span>
<span class="quote">&gt; +		.procname		= &quot;numa_stat&quot;,</span>
<span class="quote">&gt; +		.data			= &amp;sysctl_vm_numa_stat,</span>
<span class="quote">&gt; +		.maxlen			= sizeof(int),</span>
<span class="quote">&gt; +		.mode			= 0644,</span>
<span class="quote">&gt; +		.proc_handler	= sysctl_vm_numa_stat_handler,</span>
<span class="quote">&gt; +		.extra1			= &amp;zero,</span>
<span class="quote">&gt; +		.extra2			= &amp;one,</span>
<span class="quote">&gt; +	},</span>
<span class="quote">&gt;  #endif</span>
<span class="quote">&gt;  	 {</span>
<span class="quote">&gt;  		.procname	= &quot;hugetlb_shm_group&quot;,</span>
<span class="quote">&gt; diff --git a/mm/mempolicy.c b/mm/mempolicy.c</span>
<span class="quote">&gt; index a2af6d5..78344cf 100644</span>
<span class="quote">&gt; --- a/mm/mempolicy.c</span>
<span class="quote">&gt; +++ b/mm/mempolicy.c</span>
<span class="quote">&gt; @@ -1920,6 +1920,9 @@ static struct page *alloc_page_interleave(gfp_t gfp, unsigned order,</span>
<span class="quote">&gt;  	struct page *page;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	page = __alloc_pages(gfp, order, nid);</span>
<span class="quote">&gt; +	/* skip NUMA_INTERLEAVE_HIT counter update if numa stats is disabled */</span>
<span class="quote">&gt; +	if (!static_branch_likely(&amp;vm_numa_stat_key))</span>
<span class="quote">&gt; +		return page;</span>
<span class="quote">&gt;  	if (page &amp;&amp; page_to_nid(page) == nid) {</span>
<span class="quote">&gt;  		preempt_disable();</span>
<span class="quote">&gt;  		__inc_numa_state(page_zone(page), NUMA_INTERLEAVE_HIT);</span>
<span class="quote">&gt; diff --git a/mm/page_alloc.c b/mm/page_alloc.c</span>
<span class="quote">&gt; index 77e4d3c..7bdb4f7 100644</span>
<span class="quote">&gt; --- a/mm/page_alloc.c</span>
<span class="quote">&gt; +++ b/mm/page_alloc.c</span>
<span class="quote">&gt; @@ -83,6 +83,8 @@ DEFINE_PER_CPU(int, numa_node);</span>
<span class="quote">&gt;  EXPORT_PER_CPU_SYMBOL(numa_node);</span>
<span class="quote">&gt;  #endif</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; +DEFINE_STATIC_KEY_TRUE(vm_numa_stat_key);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt;  #ifdef CONFIG_HAVE_MEMORYLESS_NODES</span>
<span class="quote">&gt;  /*</span>
<span class="quote">&gt;   * N.B., Do NOT reference the &#39;_numa_mem_&#39; per cpu variable directly.</span>
<span class="quote">&gt; @@ -2743,6 +2745,10 @@ static inline void zone_statistics(struct zone *preferred_zone, struct zone *z)</span>
<span class="quote">&gt;  #ifdef CONFIG_NUMA</span>
<span class="quote">&gt;  	enum numa_stat_item local_stat = NUMA_LOCAL;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; +	/* skip numa counters update if numa stats is disabled */</span>
<span class="quote">&gt; +	if (!static_branch_likely(&amp;vm_numa_stat_key))</span>
<span class="quote">&gt; +		return;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt;  	if (z-&gt;node != numa_node_id())</span>
<span class="quote">&gt;  		local_stat = NUMA_OTHER;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; diff --git a/mm/vmstat.c b/mm/vmstat.c</span>
<span class="quote">&gt; index 4bb13e7..1faf30d 100644</span>
<span class="quote">&gt; --- a/mm/vmstat.c</span>
<span class="quote">&gt; +++ b/mm/vmstat.c</span>
<span class="quote">&gt; @@ -32,6 +32,76 @@</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  #define NUMA_STATS_THRESHOLD (U16_MAX - 2)</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; +#ifdef CONFIG_NUMA</span>
<span class="quote">&gt; +int sysctl_vm_numa_stat = ENABLE_NUMA_STAT;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +/* zero numa counters within a zone */</span>
<span class="quote">&gt; +static void zero_zone_numa_counters(struct zone *zone)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	int item, cpu;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	for (item = 0; item &lt; NR_VM_NUMA_STAT_ITEMS; item++) {</span>
<span class="quote">&gt; +		atomic_long_set(&amp;zone-&gt;vm_numa_stat[item], 0);</span>
<span class="quote">&gt; +		for_each_online_cpu(cpu)</span>
<span class="quote">&gt; +			per_cpu_ptr(zone-&gt;pageset, cpu)-&gt;vm_numa_stat_diff[item]</span>
<span class="quote">&gt; +						= 0;</span>
<span class="quote">&gt; +	}</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +/* zero numa counters of all the populated zones */</span>
<span class="quote">&gt; +static void zero_zones_numa_counters(void)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	struct zone *zone;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	for_each_populated_zone(zone)</span>
<span class="quote">&gt; +		zero_zone_numa_counters(zone);</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +/* zero global numa counters */</span>
<span class="quote">&gt; +static void zero_global_numa_counters(void)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	int item;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	for (item = 0; item &lt; NR_VM_NUMA_STAT_ITEMS; item++)</span>
<span class="quote">&gt; +		atomic_long_set(&amp;vm_numa_stat[item], 0);</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +static void invalid_numa_statistics(void)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	zero_zones_numa_counters();</span>
<span class="quote">&gt; +	zero_global_numa_counters();</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +int sysctl_vm_numa_stat_handler(struct ctl_table *table, int write,</span>
<span class="quote">&gt; +		void __user *buffer, size_t *length, loff_t *ppos)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	int ret, oldval;</span>
<span class="quote">&gt; +	DEFINE_MUTEX(vm_numa_stat_lock);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	mutex_lock(&amp;vm_numa_stat_lock);</span>
<span class="quote">&gt; +	if (write)</span>
<span class="quote">&gt; +		oldval = sysctl_vm_numa_stat;</span>
<span class="quote">&gt; +	ret = proc_dointvec_minmax(table, write, buffer, length, ppos);</span>
<span class="quote">&gt; +	if (ret || !write)</span>
<span class="quote">&gt; +		goto out;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	if (oldval == sysctl_vm_numa_stat)</span>
<span class="quote">&gt; +		goto out;</span>
<span class="quote">&gt; +	else if (sysctl_vm_numa_stat == ENABLE_NUMA_STAT) {</span>
<span class="quote">&gt; +		static_branch_enable(&amp;vm_numa_stat_key);</span>
<span class="quote">&gt; +		pr_info(&quot;enable numa statistics\n&quot;);</span>
<span class="quote">&gt; +	} else {</span>
<span class="quote">&gt; +		static_branch_disable(&amp;vm_numa_stat_key);</span>
<span class="quote">&gt; +		invalid_numa_statistics();</span>
<span class="quote">&gt; +		pr_info(&quot;disable numa statistics, and clear numa counters\n&quot;);</span>
<span class="quote">&gt; +	}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +out:</span>
<span class="quote">&gt; +	mutex_unlock(&amp;vm_numa_stat_lock);</span>
<span class="quote">&gt; +	return ret;</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +#endif</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt;  #ifdef CONFIG_VM_EVENT_COUNTERS</span>
<span class="quote">&gt;  DEFINE_PER_CPU(struct vm_event_state, vm_event_states) = {{0}};</span>
<span class="quote">&gt;  EXPORT_PER_CPU_SYMBOL(vm_event_states);</span>
<span class="quote">&gt; -- </span>
<span class="quote">&gt; 2.7.4</span>
<span class="quote">&gt;</span>
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
=========================================================================
When page allocation performance becomes a bottleneck and you can tolerate
some possible tool breakage and decreased numa counter precision, you can
do:
	echo 0 &gt; /proc/sys/vm/numa_stat
In this case, numa counter update is ignored. We can see about
*4.8%*(185-&gt;176) drop of cpu cycles per single page allocation and reclaim
on Jesper&#39;s page_bench01 (single thread) and *8.1%*(343-&gt;315) drop of cpu
cycles per single page allocation and reclaim on Jesper&#39;s page_bench03 (88
threads) running on a 2-Socket Broadwell-based server (88 threads, 126G
memory).

Benchmark link provided by Jesper D Brouer(increase loop times to
10000000):
https://github.com/netoptimizer/prototype-kernel/tree/master/kernel/mm/
bench

=========================================================================
When page allocation performance is not a bottleneck and you want all
tooling to work, you can do:
	echo 1 &gt; /proc/sys/vm/numa_stat
This is system default setting.

Many thanks to Michal Hocko, Dave Hansen, Ying Huang and Vlastimil Babka
for comments to help improve the original patch.

ChangeLog:
  V4-&gt;V5
  a) Scope vm_numa_stat_lock into the sysctl handler function, as suggested
  by Michal Hocko;
  b) Only allow 0/1 value when setting a value to numa_stat at userspace,
  that would keep the possibility for add auto mode in future (e.g. 2 for
  auto mode), as suggested by Michal Hocko.

  V3-&gt;V4
  a) Get rid of auto mode of numa stats, and may add it back if necessary,
  as alignment before;
  b) Skip NUMA_INTERLEAVE_HIT counter update when numa stats is disabled,
  as reported by Andrey Ryabinin. See commit &quot;de55c8b2519&quot; for details
  c) Remove extern declaration for those clear_numa_ function, and make
  them static in vmstat.c, as suggested by Vlastimil Babka.

  V2-&gt;V3:
  a) Propose a better way to use jump label to eliminate the overhead of
  branch selection in zone_statistics(), as inspired by Ying Huang;
  b) Add a paragraph in commit log to describe the way for branch target
  selection;
  c) Use a more descriptive name numa_stats_mode instead of vmstat_mode,
  and change the description accordingly, as suggested by Michal Hocko;
  d) Make this functionality NUMA-specific via ifdef

  V1-&gt;V2:
  a) Merge to one patch;
  b) Use jump label to eliminate the overhead of branch selection;
  c) Add a single-time log message at boot time to help tell users what
  happened.

Reported-by: Jesper Dangaard Brouer &lt;brouer@redhat.com&gt;
Suggested-by: Dave Hansen &lt;dave.hansen@intel.com&gt;
Suggested-by: Ying Huang &lt;ying.huang@intel.com&gt;
Signed-off-by: Kemi Wang &lt;kemi.wang@intel.com&gt;
<span class="p_del">---</span>
 Documentation/sysctl/vm.txt | 16 +++++++++++
 include/linux/vmstat.h      | 10 +++++++
 kernel/sysctl.c             |  9 ++++++
 mm/mempolicy.c              |  3 ++
 mm/page_alloc.c             |  6 ++++
 mm/vmstat.c                 | 70 +++++++++++++++++++++++++++++++++++++++++++++
 6 files changed, 114 insertions(+)

<span class="p_header">diff --git a/Documentation/sysctl/vm.txt b/Documentation/sysctl/vm.txt</span>
<span class="p_header">index 9baf66a..f65c5c7 100644</span>
<span class="p_header">--- a/Documentation/sysctl/vm.txt</span>
<span class="p_header">+++ b/Documentation/sysctl/vm.txt</span>
<span class="p_chunk">@@ -58,6 +58,7 @@</span> <span class="p_context"> Currently, these files are in /proc/sys/vm:</span>
 - percpu_pagelist_fraction
 - stat_interval
 - stat_refresh
<span class="p_add">+- numa_stat</span>
 - swappiness
 - user_reserve_kbytes
 - vfs_cache_pressure
<span class="p_chunk">@@ -792,6 +793,21 @@</span> <span class="p_context"> with no ill effects: errors and warnings on these stats are suppressed.)</span>
 
 ==============================================================
 
<span class="p_add">+numa_stat</span>
<span class="p_add">+</span>
<span class="p_add">+This interface allows runtime configuration of numa statistics.</span>
<span class="p_add">+</span>
<span class="p_add">+When page allocation performance becomes a bottleneck and you can tolerate</span>
<span class="p_add">+some possible tool breakage and decreased numa counter precision, you can</span>
<span class="p_add">+do:</span>
<span class="p_add">+	echo 0 &gt; /proc/sys/vm/numa_stat</span>
<span class="p_add">+</span>
<span class="p_add">+When page allocation performance is not a bottleneck and you want all</span>
<span class="p_add">+tooling to work, you can do:</span>
<span class="p_add">+	echo 1 &gt; /proc/sys/vm/numa_stat</span>
<span class="p_add">+</span>
<span class="p_add">+==============================================================</span>
<span class="p_add">+</span>
 swappiness
 
 This control is used to define how aggressive the kernel will swap
<span class="p_header">diff --git a/include/linux/vmstat.h b/include/linux/vmstat.h</span>
<span class="p_header">index ade7cb5..c605c94 100644</span>
<span class="p_header">--- a/include/linux/vmstat.h</span>
<span class="p_header">+++ b/include/linux/vmstat.h</span>
<span class="p_chunk">@@ -6,9 +6,19 @@</span> <span class="p_context"></span>
 #include &lt;linux/mmzone.h&gt;
 #include &lt;linux/vm_event_item.h&gt;
 #include &lt;linux/atomic.h&gt;
<span class="p_add">+#include &lt;linux/static_key.h&gt;</span>
 
 extern int sysctl_stat_interval;
 
<span class="p_add">+#ifdef CONFIG_NUMA</span>
<span class="p_add">+#define ENABLE_NUMA_STAT   1</span>
<span class="p_add">+#define DISABLE_NUMA_STAT   0</span>
<span class="p_add">+extern int sysctl_vm_numa_stat;</span>
<span class="p_add">+DECLARE_STATIC_KEY_TRUE(vm_numa_stat_key);</span>
<span class="p_add">+extern int sysctl_vm_numa_stat_handler(struct ctl_table *table,</span>
<span class="p_add">+		int write, void __user *buffer, size_t *length, loff_t *ppos);</span>
<span class="p_add">+#endif</span>
<span class="p_add">+</span>
 #ifdef CONFIG_VM_EVENT_COUNTERS
 /*
  * Light weight per cpu counter implementation.
<span class="p_header">diff --git a/kernel/sysctl.c b/kernel/sysctl.c</span>
<span class="p_header">index d9c31bc..8f272db 100644</span>
<span class="p_header">--- a/kernel/sysctl.c</span>
<span class="p_header">+++ b/kernel/sysctl.c</span>
<span class="p_chunk">@@ -1371,6 +1371,15 @@</span> <span class="p_context"> static struct ctl_table vm_table[] = {</span>
 		.mode           = 0644,
 		.proc_handler   = &amp;hugetlb_mempolicy_sysctl_handler,
 	},
<span class="p_add">+	{</span>
<span class="p_add">+		.procname		= &quot;numa_stat&quot;,</span>
<span class="p_add">+		.data			= &amp;sysctl_vm_numa_stat,</span>
<span class="p_add">+		.maxlen			= sizeof(int),</span>
<span class="p_add">+		.mode			= 0644,</span>
<span class="p_add">+		.proc_handler	= sysctl_vm_numa_stat_handler,</span>
<span class="p_add">+		.extra1			= &amp;zero,</span>
<span class="p_add">+		.extra2			= &amp;one,</span>
<span class="p_add">+	},</span>
 #endif
 	 {
 		.procname	= &quot;hugetlb_shm_group&quot;,
<span class="p_header">diff --git a/mm/mempolicy.c b/mm/mempolicy.c</span>
<span class="p_header">index a2af6d5..78344cf 100644</span>
<span class="p_header">--- a/mm/mempolicy.c</span>
<span class="p_header">+++ b/mm/mempolicy.c</span>
<span class="p_chunk">@@ -1920,6 +1920,9 @@</span> <span class="p_context"> static struct page *alloc_page_interleave(gfp_t gfp, unsigned order,</span>
 	struct page *page;
 
 	page = __alloc_pages(gfp, order, nid);
<span class="p_add">+	/* skip NUMA_INTERLEAVE_HIT counter update if numa stats is disabled */</span>
<span class="p_add">+	if (!static_branch_likely(&amp;vm_numa_stat_key))</span>
<span class="p_add">+		return page;</span>
 	if (page &amp;&amp; page_to_nid(page) == nid) {
 		preempt_disable();
 		__inc_numa_state(page_zone(page), NUMA_INTERLEAVE_HIT);
<span class="p_header">diff --git a/mm/page_alloc.c b/mm/page_alloc.c</span>
<span class="p_header">index 77e4d3c..7bdb4f7 100644</span>
<span class="p_header">--- a/mm/page_alloc.c</span>
<span class="p_header">+++ b/mm/page_alloc.c</span>
<span class="p_chunk">@@ -83,6 +83,8 @@</span> <span class="p_context"> DEFINE_PER_CPU(int, numa_node);</span>
 EXPORT_PER_CPU_SYMBOL(numa_node);
 #endif
 
<span class="p_add">+DEFINE_STATIC_KEY_TRUE(vm_numa_stat_key);</span>
<span class="p_add">+</span>
 #ifdef CONFIG_HAVE_MEMORYLESS_NODES
 /*
  * N.B., Do NOT reference the &#39;_numa_mem_&#39; per cpu variable directly.
<span class="p_chunk">@@ -2743,6 +2745,10 @@</span> <span class="p_context"> static inline void zone_statistics(struct zone *preferred_zone, struct zone *z)</span>
 #ifdef CONFIG_NUMA
 	enum numa_stat_item local_stat = NUMA_LOCAL;
 
<span class="p_add">+	/* skip numa counters update if numa stats is disabled */</span>
<span class="p_add">+	if (!static_branch_likely(&amp;vm_numa_stat_key))</span>
<span class="p_add">+		return;</span>
<span class="p_add">+</span>
 	if (z-&gt;node != numa_node_id())
 		local_stat = NUMA_OTHER;
 
<span class="p_header">diff --git a/mm/vmstat.c b/mm/vmstat.c</span>
<span class="p_header">index 4bb13e7..1faf30d 100644</span>
<span class="p_header">--- a/mm/vmstat.c</span>
<span class="p_header">+++ b/mm/vmstat.c</span>
<span class="p_chunk">@@ -32,6 +32,76 @@</span> <span class="p_context"></span>
 
 #define NUMA_STATS_THRESHOLD (U16_MAX - 2)
 
<span class="p_add">+#ifdef CONFIG_NUMA</span>
<span class="p_add">+int sysctl_vm_numa_stat = ENABLE_NUMA_STAT;</span>
<span class="p_add">+</span>
<span class="p_add">+/* zero numa counters within a zone */</span>
<span class="p_add">+static void zero_zone_numa_counters(struct zone *zone)</span>
<span class="p_add">+{</span>
<span class="p_add">+	int item, cpu;</span>
<span class="p_add">+</span>
<span class="p_add">+	for (item = 0; item &lt; NR_VM_NUMA_STAT_ITEMS; item++) {</span>
<span class="p_add">+		atomic_long_set(&amp;zone-&gt;vm_numa_stat[item], 0);</span>
<span class="p_add">+		for_each_online_cpu(cpu)</span>
<span class="p_add">+			per_cpu_ptr(zone-&gt;pageset, cpu)-&gt;vm_numa_stat_diff[item]</span>
<span class="p_add">+						= 0;</span>
<span class="p_add">+	}</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+/* zero numa counters of all the populated zones */</span>
<span class="p_add">+static void zero_zones_numa_counters(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct zone *zone;</span>
<span class="p_add">+</span>
<span class="p_add">+	for_each_populated_zone(zone)</span>
<span class="p_add">+		zero_zone_numa_counters(zone);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+/* zero global numa counters */</span>
<span class="p_add">+static void zero_global_numa_counters(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	int item;</span>
<span class="p_add">+</span>
<span class="p_add">+	for (item = 0; item &lt; NR_VM_NUMA_STAT_ITEMS; item++)</span>
<span class="p_add">+		atomic_long_set(&amp;vm_numa_stat[item], 0);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static void invalid_numa_statistics(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	zero_zones_numa_counters();</span>
<span class="p_add">+	zero_global_numa_counters();</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+int sysctl_vm_numa_stat_handler(struct ctl_table *table, int write,</span>
<span class="p_add">+		void __user *buffer, size_t *length, loff_t *ppos)</span>
<span class="p_add">+{</span>
<span class="p_add">+	int ret, oldval;</span>
<span class="p_add">+	DEFINE_MUTEX(vm_numa_stat_lock);</span>
<span class="p_add">+</span>
<span class="p_add">+	mutex_lock(&amp;vm_numa_stat_lock);</span>
<span class="p_add">+	if (write)</span>
<span class="p_add">+		oldval = sysctl_vm_numa_stat;</span>
<span class="p_add">+	ret = proc_dointvec_minmax(table, write, buffer, length, ppos);</span>
<span class="p_add">+	if (ret || !write)</span>
<span class="p_add">+		goto out;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (oldval == sysctl_vm_numa_stat)</span>
<span class="p_add">+		goto out;</span>
<span class="p_add">+	else if (sysctl_vm_numa_stat == ENABLE_NUMA_STAT) {</span>
<span class="p_add">+		static_branch_enable(&amp;vm_numa_stat_key);</span>
<span class="p_add">+		pr_info(&quot;enable numa statistics\n&quot;);</span>
<span class="p_add">+	} else {</span>
<span class="p_add">+		static_branch_disable(&amp;vm_numa_stat_key);</span>
<span class="p_add">+		invalid_numa_statistics();</span>
<span class="p_add">+		pr_info(&quot;disable numa statistics, and clear numa counters\n&quot;);</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+out:</span>
<span class="p_add">+	mutex_unlock(&amp;vm_numa_stat_lock);</span>
<span class="p_add">+	return ret;</span>
<span class="p_add">+}</span>
<span class="p_add">+#endif</span>
<span class="p_add">+</span>
 #ifdef CONFIG_VM_EVENT_COUNTERS
 DEFINE_PER_CPU(struct vm_event_state, vm_event_states) = {{0}};
 EXPORT_PER_CPU_SYMBOL(vm_event_states);

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



