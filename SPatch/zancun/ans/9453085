
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>proc: mm: export PTE sizes directly in smaps (v3) - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    proc: mm: export PTE sizes directly in smaps (v3)</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=2302">Dave Hansen</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>Nov. 29, 2016, 8:17 p.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;20161129201703.CE9D5054@viggo.jf.intel.com&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/9453085/mbox/"
   >mbox</a>
|
   <a href="/patch/9453085/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/9453085/">/patch/9453085/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
	[172.30.200.125])
	by pdx-korg-patchwork.web.codeaurora.org (Postfix) with ESMTP id
	1FC0F6071C for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Tue, 29 Nov 2016 20:17:23 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 11E162787C
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Tue, 29 Nov 2016 20:17:23 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id 039BB283BC; Tue, 29 Nov 2016 20:17:23 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-6.9 required=2.0 tests=BAYES_00,RCVD_IN_DNSWL_HI
	autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 68BAF2787C
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Tue, 29 Nov 2016 20:17:21 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S933809AbcK2URQ (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Tue, 29 Nov 2016 15:17:16 -0500
Received: from mga03.intel.com ([134.134.136.65]:22023 &quot;EHLO mga03.intel.com&quot;
	rhost-flags-OK-OK-OK-OK) by vger.kernel.org with ESMTP
	id S933758AbcK2URF (ORCPT &lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Tue, 29 Nov 2016 15:17:05 -0500
Received: from fmsmga005.fm.intel.com ([10.253.24.32])
	by orsmga103.jf.intel.com with ESMTP; 29 Nov 2016 12:17:04 -0800
X-ExtLoop1: 1
X-IronPort-AV: E=Sophos;i=&quot;5.31,570,1473145200&quot;; d=&quot;scan&#39;208&quot;;a=&quot;37050303&quot;
Received: from viggo.jf.intel.com (HELO localhost.localdomain)
	([10.54.39.121])
	by fmsmga005.fm.intel.com with ESMTP; 29 Nov 2016 12:17:04 -0800
Subject: [PATCH] proc: mm: export PTE sizes directly in smaps (v3)
To: linux-kernel@vger.kernel.org
Cc: Dave Hansen &lt;dave@sr71.net&gt;, hch@lst.de, akpm@linux-foundation.org,
	dan.j.williams@intel.com, khandual@linux.vnet.ibm.com,
	vbabka@suse.cz, linux-mm@kvack.org, linux-arch@vger.kernel.org
From: Dave Hansen &lt;dave@sr71.net&gt;
Date: Tue, 29 Nov 2016 12:17:03 -0800
Message-Id: &lt;20161129201703.CE9D5054@viggo.jf.intel.com&gt;
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=2302">Dave Hansen</a> - Nov. 29, 2016, 8:17 p.m.</div>
<pre class="content">
Andrew, you can drop proc-mm-export-pte-sizes-directly-in-smaps-v2.patch,
and replace it with this.

Changes from v2:
 * Do not assume (wrongly) that smaps_hugetlb_range() always uses
   PUDs.  (Thanks for pointing this out, Vlastimil).  Also handle
   hstates that are not exactly at PMD/PUD sizes.

Changes from v1:
 * Do one &#39;Pte&#39; line per pte size instead of mashing on one line
 * Use PMD_SIZE for pmds instead of PAGE_SIZE, whoops
 * Wrote some Documentation/

--

/proc/$pid/smaps has a number of fields that are intended to imply the
kinds of PTEs used to map memory.  &quot;AnonHugePages&quot; obviously tells you
how many PMDs are being used.  &quot;MMUPageSize&quot; along with the &quot;Hugetlb&quot;
fields tells you how many PTEs you have for a huge page.

The current mechanisms work fine when we have one or two page sizes.
But, they start to get a bit muddled when we mix page sizes inside
one VMA.  For instance, the DAX folks were proposing adding a set of
fields like:

	DevicePages:
	DeviceHugePages:
	DeviceGiganticPages:
	DeviceGinormousPages:

to unmuddle things when page sizes get mixed.  That&#39;s fine, but
it does require userspace know the mapping from our various
arbitrary names to hardware page sizes on each architecture and
kernel configuration.  That seems rather suboptimal.

What folks really want is to know how much memory is mapped with
each page size.  How about we just do *that* instead?

Patch attached.  Seems harmless enough.  Seems to compile on a
bunch of random architectures.  Makes smaps look like this:

Private_Hugetlb:       0 kB
Swap:                  0 kB
SwapPss:               0 kB
KernelPageSize:        4 kB
MMUPageSize:           4 kB
Locked:                0 kB
Ptes@4kB:	      32 kB
Ptes@2MB:	    2048 kB

The format I used here should be unlikely to break smaps parsers
unless they&#39;re looking for &quot;kB&quot; and now match the &#39;Ptes@4kB&#39; instead
of the one at the end of the line.

Note: hugetlbfs PTEs are unusual.  We can have more than one &quot;pte_t&quot;
for each hugetlbfs &quot;page&quot;.  arm64 has this configuration, and probably
others.  The code should now handle when an hstate&#39;s size is not equal
to one of the page table entry sizes.  For instance, it assumes that
hstates between PMD_SIZE and PUD_SIZE are made up of multiple PMDs
and prints them as such.

I&#39;ve tested this on x86 with normal 4k ptes, anonymous huge pages,
1G hugetlbfs and 2M hugetlbfs pages.

1. I&#39;d like to thank Dan Williams for showing me a mirror as I
   complained about the bozo that introduced &#39;AnonHugePages&#39;.

Cc: Christoph Hellwig &lt;hch@lst.de&gt;
Cc: Andrew Morton &lt;akpm@linux-foundation.org&gt;
Cc: Dan Williams &lt;dan.j.williams@intel.com&gt;
Cc: Anshuman Khandual &lt;khandual@linux.vnet.ibm.com&gt;
Cc: Vlastimil Babka &lt;vbabka@suse.cz&gt;
Cc: linux-mm@kvack.org
Cc: linux-arch@vger.kernel.org

---

 b/Documentation/filesystems/proc.txt |    6 +
 b/fs/proc/task_mmu.c                 |  106 ++++++++++++++++++++++++++++++++++-
 b/mm/hugetlb.c                       |   11 +++
 3 files changed, 121 insertions(+), 2 deletions(-)
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=72672">Vlastimil Babka</a> - Dec. 1, 2016, 12:21 p.m.</div>
<pre class="content">
On 11/29/2016 09:17 PM, Dave Hansen wrote:
<span class="quote">&gt; Andrew, you can drop proc-mm-export-pte-sizes-directly-in-smaps-v2.patch,</span>
<span class="quote">&gt; and replace it with this.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; Changes from v2:</span>
<span class="quote">&gt;  * Do not assume (wrongly) that smaps_hugetlb_range() always uses</span>
<span class="quote">&gt;    PUDs.  (Thanks for pointing this out, Vlastimil).  Also handle</span>
<span class="quote">&gt;    hstates that are not exactly at PMD/PUD sizes.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; Changes from v1:</span>
<span class="quote">&gt;  * Do one &#39;Pte&#39; line per pte size instead of mashing on one line</span>
<span class="quote">&gt;  * Use PMD_SIZE for pmds instead of PAGE_SIZE, whoops</span>
<span class="quote">&gt;  * Wrote some Documentation/</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; --</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; /proc/$pid/smaps has a number of fields that are intended to imply the</span>
<span class="quote">&gt; kinds of PTEs used to map memory.  &quot;AnonHugePages&quot; obviously tells you</span>
<span class="quote">&gt; how many PMDs are being used.  &quot;MMUPageSize&quot; along with the &quot;Hugetlb&quot;</span>
<span class="quote">&gt; fields tells you how many PTEs you have for a huge page.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; The current mechanisms work fine when we have one or two page sizes.</span>
<span class="quote">&gt; But, they start to get a bit muddled when we mix page sizes inside</span>
<span class="quote">&gt; one VMA.  For instance, the DAX folks were proposing adding a set of</span>
<span class="quote">&gt; fields like:</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; 	DevicePages:</span>
<span class="quote">&gt; 	DeviceHugePages:</span>
<span class="quote">&gt; 	DeviceGiganticPages:</span>
<span class="quote">&gt; 	DeviceGinormousPages:</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; to unmuddle things when page sizes get mixed.  That&#39;s fine, but</span>
<span class="quote">&gt; it does require userspace know the mapping from our various</span>
<span class="quote">&gt; arbitrary names to hardware page sizes on each architecture and</span>
<span class="quote">&gt; kernel configuration.  That seems rather suboptimal.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; What folks really want is to know how much memory is mapped with</span>
<span class="quote">&gt; each page size.  How about we just do *that* instead?</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; Patch attached.  Seems harmless enough.  Seems to compile on a</span>
<span class="quote">&gt; bunch of random architectures.  Makes smaps look like this:</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; Private_Hugetlb:       0 kB</span>
<span class="quote">&gt; Swap:                  0 kB</span>
<span class="quote">&gt; SwapPss:               0 kB</span>
<span class="quote">&gt; KernelPageSize:        4 kB</span>
<span class="quote">&gt; MMUPageSize:           4 kB</span>
<span class="quote">&gt; Locked:                0 kB</span>
<span class="quote">&gt; Ptes@4kB:	      32 kB</span>
<span class="quote">&gt; Ptes@2MB:	    2048 kB</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; The format I used here should be unlikely to break smaps parsers</span>
<span class="quote">&gt; unless they&#39;re looking for &quot;kB&quot; and now match the &#39;Ptes@4kB&#39; instead</span>
<span class="quote">&gt; of the one at the end of the line.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; Note: hugetlbfs PTEs are unusual.  We can have more than one &quot;pte_t&quot;</span>
<span class="quote">&gt; for each hugetlbfs &quot;page&quot;.  arm64 has this configuration, and probably</span>
<span class="quote">&gt; others.  The code should now handle when an hstate&#39;s size is not equal</span>
<span class="quote">&gt; to one of the page table entry sizes.  For instance, it assumes that</span>
<span class="quote">&gt; hstates between PMD_SIZE and PUD_SIZE are made up of multiple PMDs</span>
<span class="quote">&gt; and prints them as such.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; I&#39;ve tested this on x86 with normal 4k ptes, anonymous huge pages,</span>
<span class="quote">&gt; 1G hugetlbfs and 2M hugetlbfs pages.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; 1. I&#39;d like to thank Dan Williams for showing me a mirror as I</span>
<span class="quote">&gt;    complained about the bozo that introduced &#39;AnonHugePages&#39;.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; Cc: Christoph Hellwig &lt;hch@lst.de&gt;</span>
<span class="quote">&gt; Cc: Andrew Morton &lt;akpm@linux-foundation.org&gt;</span>
<span class="quote">&gt; Cc: Dan Williams &lt;dan.j.williams@intel.com&gt;</span>
<span class="quote">&gt; Cc: Anshuman Khandual &lt;khandual@linux.vnet.ibm.com&gt;</span>
<span class="quote">&gt; Cc: Vlastimil Babka &lt;vbabka@suse.cz&gt;</span>
<span class="quote">&gt; Cc: linux-mm@kvack.org</span>
<span class="quote">&gt; Cc: linux-arch@vger.kernel.org</span>
<span class="acked-by">
Acked-by: Vlastimil Babka &lt;vbabka@suse.cz&gt;</span>
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=3211">Andy Shevchenko</a> - Dec. 1, 2016, 2:50 p.m.</div>
<pre class="content">
On Tue, Nov 29, 2016 at 10:17 PM, Dave Hansen &lt;dave@sr71.net&gt; wrote:
<span class="quote">&gt;</span>
<span class="quote">&gt; Andrew, you can drop proc-mm-export-pte-sizes-directly-in-smaps-v2.patch,</span>
<span class="quote">&gt; and replace it with this.</span>

You added a warning and it immediately appears:


[    0.402603] ------------[ cut here ]------------
[    0.402844] WARNING: CPU: 0 PID: 1 at
/home/andy/prj/linux-netboot/mm/hugetlb.c:2918
hugetlb_add_hstate+0x143/0
x14b
[    0.403042] Modules linked in:
[    0.403233] CPU: 0 PID: 1 Comm: swapper Not tainted
4.9.0-rc7-next-20161201+ #1
[    0.403499] Call Trace:
[    0.403677]  dump_stack+0x16/0x1d
[    0.404081]  __warn+0xd1/0xf0
[    0.404289]  ? hugetlb_add_hstate+0x143/0x14b
[    0.404491]  warn_slowpath_null+0x25/0x30
[    0.404695]  hugetlb_add_hstate+0x143/0x14b
[    0.404908]  hugetlb_init+0x79/0x3af
[    0.405249]  ? wake_up_process+0xf/0x20
[    0.405450]  ? kcompactd_run+0x50/0x90
[    0.405638]  ? compact_zone+0x7c0/0x7c0
[    0.405842]  ? hugetlb_add_hstate+0x14b/0x14b
[    0.406082]  do_one_initcall+0x2f/0x160
[    0.406286]  ? repair_env_string+0x12/0x54
[    0.406482]  ? parse_args+0x2a1/0x5a0
[    0.406684]  ? __dquot_free_space+0xa0/0x2d0
[    0.406892]  ? kernel_init_freeable+0xe4/0x18a
[    0.407088]  kernel_init_freeable+0x107/0x18a
[    0.407303]  ? rest_init+0x60/0x60
[    0.407496]  kernel_init+0xb/0x100
[    0.407703]  ? schedule_tail_wrapper+0x9/0x10
[    0.408099]  ret_from_fork+0x19/0x30
[    0.408302] ---[ end trace 601ba77b9b62b9d7 ]---
[    0.408481] HugeTLB registered 4 MB page size, pre-allocated 0 pages


Quark SoC here.

Besides that see below.
<span class="quote">
&gt; +/*</span>
<span class="quote">&gt; + * What units should we use for a given number?  We want</span>
<span class="quote">&gt; + * 2048 to be 2k, so we return &#39;k&#39;.  1048576 should be</span>
<span class="quote">&gt; + * 1M, so we return &#39;M&#39;.</span>
<span class="quote">&gt; + */</span>
<span class="quote">&gt; +static char size_unit(unsigned long long nr)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +       /*</span>
<span class="quote">&gt; +        * This &#39; &#39; might look a bit goofy in the output.  But, why</span>
<span class="quote">&gt; +        * bother doing anything.  Do we even have a &lt;1k page size?</span>
<span class="quote">&gt; +        */</span>
<span class="quote">&gt; +       if (nr &lt; (1ULL&lt;&lt;10))</span>
<span class="quote">&gt; +               return &#39; &#39;;</span>
<span class="quote">&gt; +       if (nr &lt; (1ULL&lt;&lt;20))</span>
<span class="quote">&gt; +               return &#39;k&#39;;</span>
<span class="quote">&gt; +       if (nr &lt; (1ULL&lt;&lt;30))</span>
<span class="quote">&gt; +               return &#39;M&#39;;</span>
<span class="quote">&gt; +       if (nr &lt; (1ULL&lt;&lt;40))</span>
<span class="quote">&gt; +               return &#39;G&#39;;</span>
<span class="quote">&gt; +       if (nr &lt; (1ULL&lt;&lt;50))</span>
<span class="quote">&gt; +               return &#39;T&#39;;</span>
<span class="quote">&gt; +       if (nr &lt; (1ULL&lt;&lt;60))</span>
<span class="quote">&gt; +               return &#39;P&#39;;</span>
<span class="quote">&gt; +       return &#39;E&#39;;</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +/*</span>
<span class="quote">&gt; + * How should we shift down a a given number to scale it</span>
<span class="quote">&gt; + * with the units we are printing it as? 2048 to be 2k,</span>
<span class="quote">&gt; + * so we want it shifted down by 10.  1048576 should be</span>
<span class="quote">&gt; + * 1M, so we want it shifted down by 20.</span>
<span class="quote">&gt; + */</span>
<span class="quote">&gt; +static int size_shift(unsigned long long nr)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +       if (nr &lt; (1ULL&lt;&lt;10))</span>
<span class="quote">&gt; +               return 0;</span>
<span class="quote">&gt; +       if (nr &lt; (1ULL&lt;&lt;20))</span>
<span class="quote">&gt; +               return 10;</span>
<span class="quote">&gt; +       if (nr &lt; (1ULL&lt;&lt;30))</span>
<span class="quote">&gt; +               return 20;</span>
<span class="quote">&gt; +       if (nr &lt; (1ULL&lt;&lt;40))</span>
<span class="quote">&gt; +               return 30;</span>
<span class="quote">&gt; +       if (nr &lt; (1ULL&lt;&lt;50))</span>
<span class="quote">&gt; +               return 40;</span>
<span class="quote">&gt; +       if (nr &lt; (1ULL&lt;&lt;60))</span>
<span class="quote">&gt; +               return 50;</span>
<span class="quote">&gt; +       return 60;</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>

New copy of string_get_size() ?

Something similar was discussed for EFI stuff like half a year ago?
<span class="quote">
&gt; +static void show_one_smap_pte(struct seq_file *m, unsigned long bytes_rss,</span>
<span class="quote">&gt; +               unsigned long pte_size)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +       seq_printf(m, &quot;Ptes@%ld%cB:     %8lu kB\n&quot;,</span>
<span class="quote">&gt; +                       pte_size &gt;&gt; size_shift(pte_size),</span>
<span class="quote">&gt; +                       size_unit(pte_size),</span>
<span class="quote">&gt; +                       bytes_rss &gt;&gt; 10);</span>
<span class="quote">&gt; +}</span>
<span class="quote">

&gt; +       /*</span>
<span class="quote">&gt; +        * PGD_SIZE isn&#39;t widely made available by architecures,</span>
<span class="quote">&gt; +        * so use PUD_SIZE*PTRS_PER_PUD as a substitute.</span>
<span class="quote">&gt; +        *</span>
<span class="quote">&gt; +        * Check for sizes that might be mapped by a PGD.  There</span>
<span class="quote">&gt; +        * are none of these known today, but be on the lookout.</span>
<span class="quote">&gt; +        * If this trips, we will need to update the mss-&gt;rss_*</span>
<span class="quote">&gt; +        * code in fs/proc/task_mmu.c.</span>
<span class="quote">&gt; +        */</span>
<span class="quote">&gt; +       WARN_ON_ONCE((PAGE_SIZE &lt;&lt; order) &gt;= PUD_SIZE * PTRS_PER_PUD);</span>

This what I got.
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=1141">Aneesh Kumar K.V</a> - Dec. 2, 2016, 3:43 p.m.</div>
<pre class="content">
Dave Hansen &lt;dave@sr71.net&gt; writes:
<span class="quote">
&gt; Andrew, you can drop proc-mm-export-pte-sizes-directly-in-smaps-v2.patch,</span>
<span class="quote">&gt; and replace it with this.</span>
<span class="quote">&gt;</span>
.....
<span class="quote">
&gt; diff -puN mm/hugetlb.c~smaps-pte-sizes mm/hugetlb.c</span>
<span class="quote">&gt; --- a/mm/hugetlb.c~smaps-pte-sizes	2016-11-28 14:21:37.555519365 -0800</span>
<span class="quote">&gt; +++ b/mm/hugetlb.c	2016-11-28 14:28:49.186234688 -0800</span>
<span class="quote">&gt; @@ -2763,6 +2763,17 @@ void __init hugetlb_add_hstate(unsigned</span>
<span class="quote">&gt;  					huge_page_size(h)/1024);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	parsed_hstate = h;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	/*</span>
<span class="quote">&gt; +	 * PGD_SIZE isn&#39;t widely made available by architecures,</span>
<span class="quote">&gt; +	 * so use PUD_SIZE*PTRS_PER_PUD as a substitute.</span>
<span class="quote">&gt; +	 *</span>
<span class="quote">&gt; +	 * Check for sizes that might be mapped by a PGD.  There</span>
<span class="quote">&gt; +	 * are none of these known today, but be on the lookout.</span>
<span class="quote">&gt; +	 * If this trips, we will need to update the mss-&gt;rss_*</span>
<span class="quote">&gt; +	 * code in fs/proc/task_mmu.c.</span>
<span class="quote">&gt; +	 */</span>
<span class="quote">&gt; +	WARN_ON_ONCE((PAGE_SIZE &lt;&lt; order) &gt;= PUD_SIZE * PTRS_PER_PUD);</span>
<span class="quote">&gt;  }</span>

This will trip for ppc64 16GB hugepage.

For ppc64 we have the 16G at pgd level.

-aneesh
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=1141">Aneesh Kumar K.V</a> - Dec. 2, 2016, 4:14 p.m.</div>
<pre class="content">
Dave Hansen &lt;dave@sr71.net&gt; writes:
<span class="quote">
  
&gt;  #ifdef CONFIG_HUGETLB_PAGE</span>
<span class="quote">&gt; +/*</span>
<span class="quote">&gt; + * Most architectures have a 1:1 mapping of PTEs to hugetlb page</span>
<span class="quote">&gt; + * sizes, but there are some outliers like arm64 that use</span>
<span class="quote">&gt; + * multiple hardware PTEs to make a hugetlb &quot;page&quot;.  Do not</span>
<span class="quote">&gt; + * assume that all &#39;hpage_size&#39;s are not exactly at a page table</span>
<span class="quote">&gt; + * size boundary.  Instead, accept arbitrary &#39;hpage_size&#39;s and</span>
<span class="quote">&gt; + * assume they are made up of the next-smallest size.  We do not</span>
<span class="quote">&gt; + * handle PGD-sized hpages and hugetlb_add_hstate() will WARN()</span>
<span class="quote">&gt; + * if it sees one.</span>
<span class="quote">&gt; + *</span>
<span class="quote">&gt; + * Note also that the page walker code only calls us once per</span>
<span class="quote">&gt; + * huge &#39;struct page&#39;, *not* once per PTE in the page tables.</span>
<span class="quote">&gt; + */</span>
<span class="quote">&gt; +static void smaps_hugetlb_present_hpage(struct mem_size_stats *mss,</span>
<span class="quote">&gt; +					unsigned long hpage_size)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	if (hpage_size &gt;= PUD_SIZE)</span>
<span class="quote">&gt; +		mss-&gt;rss_pud += hpage_size;</span>
<span class="quote">&gt; +	else if (hpage_size &gt;= PMD_SIZE)</span>
<span class="quote">&gt; +		mss-&gt;rss_pmd += hpage_size;</span>
<span class="quote">&gt; +	else</span>
<span class="quote">&gt; +		mss-&gt;rss_pte += hpage_size;</span>
<span class="quote">&gt; +}</span>

some powerpc platforms have multiple page table entries mapping the same
hugepage and on other, we have a page table entry pointing to something
called hugepaeg directory mapping a set of hugepage. So I am not sure
the above will work for all those ?

Also do we derive pte@&lt;size value&gt; correctly there ?

-aneesh
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=2302">Dave Hansen</a> - Dec. 9, 2016, 11:10 p.m.</div>
<pre class="content">
On 12/01/2016 06:50 AM, Andy Shevchenko wrote:
<span class="quote">&gt;&gt; &gt; +static int size_shift(unsigned long long nr)</span>
<span class="quote">&gt;&gt; &gt; +{</span>
<span class="quote">&gt;&gt; &gt; +       if (nr &lt; (1ULL&lt;&lt;10))</span>
<span class="quote">&gt;&gt; &gt; +               return 0;</span>
<span class="quote">&gt;&gt; &gt; +       if (nr &lt; (1ULL&lt;&lt;20))</span>
<span class="quote">&gt;&gt; &gt; +               return 10;</span>
<span class="quote">&gt;&gt; &gt; +       if (nr &lt; (1ULL&lt;&lt;30))</span>
<span class="quote">&gt;&gt; &gt; +               return 20;</span>
<span class="quote">&gt;&gt; &gt; +       if (nr &lt; (1ULL&lt;&lt;40))</span>
<span class="quote">&gt;&gt; &gt; +               return 30;</span>
<span class="quote">&gt;&gt; &gt; +       if (nr &lt; (1ULL&lt;&lt;50))</span>
<span class="quote">&gt;&gt; &gt; +               return 40;</span>
<span class="quote">&gt;&gt; &gt; +       if (nr &lt; (1ULL&lt;&lt;60))</span>
<span class="quote">&gt;&gt; &gt; +               return 50;</span>
<span class="quote">&gt;&gt; &gt; +       return 60;</span>
<span class="quote">&gt;&gt; &gt; +}</span>
<span class="quote">&gt;&gt; &gt; +</span>
<span class="quote">&gt; New copy of string_get_size() ?</span>

Not really.  That prints to a buffer, so we&#39;ll need to allocate stack
space for a buffer, which we also have to size properly.  We also want
to be consistent with other parts of smaps that mean kB==1024 bytes, so
we want string_get_size()&#39;s STRING_UNITS_10 strings, but
STRING_UNITS_2&#39;s divisor.

Also, guaranteeing that we have a power-of-2 &#39;block size&#39; lets us cheat
and do things much faster than using real division.  Not that it
matters, but we could do it thousands of times for a large smaps file.

Being defined locally, this stuff also gets inlined pretty aggressively.

Given all that, I&#39;m not sure I want to modify string_get_size() to do
exactly what we need here.
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff -puN fs/proc/task_mmu.c~smaps-pte-sizes fs/proc/task_mmu.c</span>
<span class="p_header">--- a/fs/proc/task_mmu.c~smaps-pte-sizes	2016-11-28 08:48:10.899054714 -0800</span>
<span class="p_header">+++ b/fs/proc/task_mmu.c	2016-11-29 10:31:55.259790185 -0800</span>
<span class="p_chunk">@@ -445,6 +445,9 @@</span> <span class="p_context"> struct mem_size_stats {</span>
 	unsigned long swap;
 	unsigned long shared_hugetlb;
 	unsigned long private_hugetlb;
<span class="p_add">+	unsigned long rss_pte;</span>
<span class="p_add">+	unsigned long rss_pmd;</span>
<span class="p_add">+	unsigned long rss_pud;</span>
 	u64 pss;
 	u64 swap_pss;
 	bool check_shmem_swap;
<span class="p_chunk">@@ -519,6 +522,7 @@</span> <span class="p_context"> static void smaps_pte_entry(pte_t *pte,</span>
 
 	if (pte_present(*pte)) {
 		page = vm_normal_page(vma, addr, *pte);
<span class="p_add">+		mss-&gt;rss_pte += PAGE_SIZE;</span>
 	} else if (is_swap_pte(*pte)) {
 		swp_entry_t swpent = pte_to_swp_entry(*pte);
 
<span class="p_chunk">@@ -578,6 +582,7 @@</span> <span class="p_context"> static void smaps_pmd_entry(pmd_t *pmd,</span>
 		/* pass */;
 	else
 		VM_BUG_ON_PAGE(1, page);
<span class="p_add">+	mss-&gt;rss_pmd += PMD_SIZE;</span>
 	smaps_account(mss, page, true, pmd_young(*pmd), pmd_dirty(*pmd));
 }
 #else
<span class="p_chunk">@@ -684,6 +689,30 @@</span> <span class="p_context"> static void show_smap_vma_flags(struct s</span>
 }
 
 #ifdef CONFIG_HUGETLB_PAGE
<span class="p_add">+/*</span>
<span class="p_add">+ * Most architectures have a 1:1 mapping of PTEs to hugetlb page</span>
<span class="p_add">+ * sizes, but there are some outliers like arm64 that use</span>
<span class="p_add">+ * multiple hardware PTEs to make a hugetlb &quot;page&quot;.  Do not</span>
<span class="p_add">+ * assume that all &#39;hpage_size&#39;s are not exactly at a page table</span>
<span class="p_add">+ * size boundary.  Instead, accept arbitrary &#39;hpage_size&#39;s and</span>
<span class="p_add">+ * assume they are made up of the next-smallest size.  We do not</span>
<span class="p_add">+ * handle PGD-sized hpages and hugetlb_add_hstate() will WARN()</span>
<span class="p_add">+ * if it sees one.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * Note also that the page walker code only calls us once per</span>
<span class="p_add">+ * huge &#39;struct page&#39;, *not* once per PTE in the page tables.</span>
<span class="p_add">+ */</span>
<span class="p_add">+static void smaps_hugetlb_present_hpage(struct mem_size_stats *mss,</span>
<span class="p_add">+					unsigned long hpage_size)</span>
<span class="p_add">+{</span>
<span class="p_add">+	if (hpage_size &gt;= PUD_SIZE)</span>
<span class="p_add">+		mss-&gt;rss_pud += hpage_size;</span>
<span class="p_add">+	else if (hpage_size &gt;= PMD_SIZE)</span>
<span class="p_add">+		mss-&gt;rss_pmd += hpage_size;</span>
<span class="p_add">+	else</span>
<span class="p_add">+		mss-&gt;rss_pte += hpage_size;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static int smaps_hugetlb_range(pte_t *pte, unsigned long hmask,
 				 unsigned long addr, unsigned long end,
 				 struct mm_walk *walk)
<span class="p_chunk">@@ -702,11 +731,14 @@</span> <span class="p_context"> static int smaps_hugetlb_range(pte_t *pt</span>
 	}
 	if (page) {
 		int mapcount = page_mapcount(page);
<span class="p_add">+		unsigned long hpage_size = huge_page_size(hstate_vma(vma));</span>
<span class="p_add">+</span>
<span class="p_add">+		smaps_hugetlb_present_hpage(mss, hpage_size);</span>
 
 		if (mapcount &gt;= 2)
<span class="p_del">-			mss-&gt;shared_hugetlb += huge_page_size(hstate_vma(vma));</span>
<span class="p_add">+			mss-&gt;shared_hugetlb += hpage_size;</span>
 		else
<span class="p_del">-			mss-&gt;private_hugetlb += huge_page_size(hstate_vma(vma));</span>
<span class="p_add">+			mss-&gt;private_hugetlb += hpage_size;</span>
 	}
 	return 0;
 }
<span class="p_chunk">@@ -716,6 +748,75 @@</span> <span class="p_context"> void __weak arch_show_smap(struct seq_fi</span>
 {
 }
 
<span class="p_add">+/*</span>
<span class="p_add">+ * What units should we use for a given number?  We want</span>
<span class="p_add">+ * 2048 to be 2k, so we return &#39;k&#39;.  1048576 should be</span>
<span class="p_add">+ * 1M, so we return &#39;M&#39;.</span>
<span class="p_add">+ */</span>
<span class="p_add">+static char size_unit(unsigned long long nr)</span>
<span class="p_add">+{</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * This &#39; &#39; might look a bit goofy in the output.  But, why</span>
<span class="p_add">+	 * bother doing anything.  Do we even have a &lt;1k page size?</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	if (nr &lt; (1ULL&lt;&lt;10))</span>
<span class="p_add">+		return &#39; &#39;;</span>
<span class="p_add">+	if (nr &lt; (1ULL&lt;&lt;20))</span>
<span class="p_add">+		return &#39;k&#39;;</span>
<span class="p_add">+	if (nr &lt; (1ULL&lt;&lt;30))</span>
<span class="p_add">+		return &#39;M&#39;;</span>
<span class="p_add">+	if (nr &lt; (1ULL&lt;&lt;40))</span>
<span class="p_add">+		return &#39;G&#39;;</span>
<span class="p_add">+	if (nr &lt; (1ULL&lt;&lt;50))</span>
<span class="p_add">+		return &#39;T&#39;;</span>
<span class="p_add">+	if (nr &lt; (1ULL&lt;&lt;60))</span>
<span class="p_add">+		return &#39;P&#39;;</span>
<span class="p_add">+	return &#39;E&#39;;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+/*</span>
<span class="p_add">+ * How should we shift down a a given number to scale it</span>
<span class="p_add">+ * with the units we are printing it as? 2048 to be 2k,</span>
<span class="p_add">+ * so we want it shifted down by 10.  1048576 should be</span>
<span class="p_add">+ * 1M, so we want it shifted down by 20.</span>
<span class="p_add">+ */</span>
<span class="p_add">+static int size_shift(unsigned long long nr)</span>
<span class="p_add">+{</span>
<span class="p_add">+	if (nr &lt; (1ULL&lt;&lt;10))</span>
<span class="p_add">+		return 0;</span>
<span class="p_add">+	if (nr &lt; (1ULL&lt;&lt;20))</span>
<span class="p_add">+		return 10;</span>
<span class="p_add">+	if (nr &lt; (1ULL&lt;&lt;30))</span>
<span class="p_add">+		return 20;</span>
<span class="p_add">+	if (nr &lt; (1ULL&lt;&lt;40))</span>
<span class="p_add">+		return 30;</span>
<span class="p_add">+	if (nr &lt; (1ULL&lt;&lt;50))</span>
<span class="p_add">+		return 40;</span>
<span class="p_add">+	if (nr &lt; (1ULL&lt;&lt;60))</span>
<span class="p_add">+		return 50;</span>
<span class="p_add">+	return 60;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static void show_one_smap_pte(struct seq_file *m, unsigned long bytes_rss,</span>
<span class="p_add">+		unsigned long pte_size)</span>
<span class="p_add">+{</span>
<span class="p_add">+	seq_printf(m, &quot;Ptes@%ld%cB:	%8lu kB\n&quot;,</span>
<span class="p_add">+			pte_size &gt;&gt; size_shift(pte_size),</span>
<span class="p_add">+			size_unit(pte_size),</span>
<span class="p_add">+			bytes_rss &gt;&gt; 10);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static void show_smap_ptes(struct seq_file *m, struct mem_size_stats *mss)</span>
<span class="p_add">+{</span>
<span class="p_add">+	/* Only print the entries for page sizes present in the VMA */</span>
<span class="p_add">+	if (mss-&gt;rss_pte)</span>
<span class="p_add">+		show_one_smap_pte(m, mss-&gt;rss_pte, PAGE_SIZE);</span>
<span class="p_add">+	if (mss-&gt;rss_pmd)</span>
<span class="p_add">+		show_one_smap_pte(m, mss-&gt;rss_pmd, PMD_SIZE);</span>
<span class="p_add">+	if (mss-&gt;rss_pud)</span>
<span class="p_add">+		show_one_smap_pte(m, mss-&gt;rss_pud, PUD_SIZE);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static int show_smap(struct seq_file *m, void *v, int is_pid)
 {
 	struct vm_area_struct *vma = v;
<span class="p_chunk">@@ -799,6 +900,7 @@</span> <span class="p_context"> static int show_smap(struct seq_file *m,</span>
 		   (vma-&gt;vm_flags &amp; VM_LOCKED) ?
 			(unsigned long)(mss.pss &gt;&gt; (10 + PSS_SHIFT)) : 0);
 
<span class="p_add">+	show_smap_ptes(m, &amp;mss);</span>
 	arch_show_smap(m, vma);
 	show_smap_vma_flags(m, vma);
 	m_cache_vma(m, vma);
<span class="p_header">diff -puN Documentation/filesystems/proc.txt~smaps-pte-sizes Documentation/filesystems/proc.txt</span>
<span class="p_header">--- a/Documentation/filesystems/proc.txt~smaps-pte-sizes	2016-11-28 08:48:10.903054895 -0800</span>
<span class="p_header">+++ b/Documentation/filesystems/proc.txt	2016-11-28 08:48:10.909055167 -0800</span>
<span class="p_chunk">@@ -418,6 +418,9 @@</span> <span class="p_context"> SwapPss:               0 kB</span>
 KernelPageSize:        4 kB
 MMUPageSize:           4 kB
 Locked:                0 kB
<span class="p_add">+Ptes@4kB:	       4 kB</span>
<span class="p_add">+Ptes@2MB:	    8192 kB</span>
<span class="p_add">+</span>
 VmFlags: rd ex mr mw me dw
 
 the first of these lines shows the same information as is displayed for the
<span class="p_chunk">@@ -450,6 +453,9 @@</span> <span class="p_context"> replaced by copy-on-write) part of the u</span>
 &quot;SwapPss&quot; shows proportional swap share of this mapping. Unlike &quot;Swap&quot;, this
 does not take into account swapped out page of underlying shmem objects.
 &quot;Locked&quot; indicates whether the mapping is locked in memory or not.
<span class="p_add">+&quot;Ptes@...&quot; lines show how many page table entries are currently in place and</span>
<span class="p_add">+pointing to memory.  There is an entry for each size present in the hardware</span>
<span class="p_add">+page tables for this mapping.</span>
 
 &quot;VmFlags&quot; field deserves a separate description. This member represents the kernel
 flags associated with the particular virtual memory area in two letter encoded
<span class="p_header">diff -puN mm/hugetlb.c~smaps-pte-sizes mm/hugetlb.c</span>
<span class="p_header">--- a/mm/hugetlb.c~smaps-pte-sizes	2016-11-28 14:21:37.555519365 -0800</span>
<span class="p_header">+++ b/mm/hugetlb.c	2016-11-28 14:28:49.186234688 -0800</span>
<span class="p_chunk">@@ -2763,6 +2763,17 @@</span> <span class="p_context"> void __init hugetlb_add_hstate(unsigned</span>
 					huge_page_size(h)/1024);
 
 	parsed_hstate = h;
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * PGD_SIZE isn&#39;t widely made available by architecures,</span>
<span class="p_add">+	 * so use PUD_SIZE*PTRS_PER_PUD as a substitute.</span>
<span class="p_add">+	 *</span>
<span class="p_add">+	 * Check for sizes that might be mapped by a PGD.  There</span>
<span class="p_add">+	 * are none of these known today, but be on the lookout.</span>
<span class="p_add">+	 * If this trips, we will need to update the mss-&gt;rss_*</span>
<span class="p_add">+	 * code in fs/proc/task_mmu.c.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	WARN_ON_ONCE((PAGE_SIZE &lt;&lt; order) &gt;= PUD_SIZE * PTRS_PER_PUD);</span>
 }
 
 static int __init hugetlb_nrpages_setup(char *s)

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



