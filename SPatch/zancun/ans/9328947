
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>[v3,2/2] iommu/exynos: Add proper runtime pm support - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    [v3,2/2] iommu/exynos: Add proper runtime pm support</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=2061">Marek Szyprowski</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>Sept. 13, 2016, 12:49 p.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;1473770941-8337-3-git-send-email-m.szyprowski@samsung.com&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/9328947/mbox/"
   >mbox</a>
|
   <a href="/patch/9328947/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/9328947/">/patch/9328947/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
	[172.30.200.125])
	by pdx-korg-patchwork.web.codeaurora.org (Postfix) with ESMTP id
	8C6116077F for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Tue, 13 Sep 2016 12:49:40 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 8012929427
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Tue, 13 Sep 2016 12:49:40 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id 74A252944B; Tue, 13 Sep 2016 12:49:40 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-6.9 required=2.0 tests=BAYES_00,RCVD_IN_DNSWL_HI
	autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 30F982944A
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Tue, 13 Sep 2016 12:49:38 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1756000AbcIMMtg (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Tue, 13 Sep 2016 08:49:36 -0400
Received: from mailout3.w1.samsung.com ([210.118.77.13]:46378 &quot;EHLO
	mailout3.w1.samsung.com&quot; rhost-flags-OK-OK-OK-OK) by vger.kernel.org
	with ESMTP id S1751488AbcIMMtX (ORCPT
	&lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Tue, 13 Sep 2016 08:49:23 -0400
Received: from eucas1p1.samsung.com (unknown [182.198.249.206])
	by mailout3.w1.samsung.com
	(Oracle Communications Messaging Server 7.0.5.31.0 64bit (built May 5
	2014))
	with ESMTP id &lt;0ODG00LGC0Y8LI00@mailout3.w1.samsung.com&gt;; Tue,
	13 Sep 2016 13:49:21 +0100 (BST)
Received: from eusmges1.samsung.com (unknown [203.254.199.239])
	by     eucas1p1.samsung.com (KnoxPortal) with ESMTP id
	20160913124919eucas1p1ad997b218de485d4d4f1bf0ac7c687de~z4uEPZeFf2669126691eucas1p1r;
	Tue, 13 Sep 2016 12:49:19 +0000 (GMT)
Received: from eucas1p1.samsung.com ( [182.198.249.206])
	by eusmges1.samsung.com (EUCPMTA) with SMTP id 3A.95.23383.FC5F7D75;
	Tue, 13     Sep 2016 13:49:19 +0100 (BST)
Received: from eusmgms1.samsung.com (unknown [182.198.249.179])
	by     eucas1p2.samsung.com (KnoxPortal) with ESMTP id
	20160913124918eucas1p29f49efbb142d416215482c29b53daff8~z4uDlZqpN1319313193eucas1p2X;
	Tue, 13 Sep 2016 12:49:18 +0000 (GMT)
X-AuditID: cbfec7ef-f79e76d000005b57-aa-57d7f5cfd039
Received: from eusync4.samsung.com ( [203.254.199.214])
	by eusmgms1.samsung.com (EUCPMTA) with SMTP id 62.AF.07726.0A5F7D75;
	Tue, 13     Sep 2016 13:48:32 +0100 (BST)
Received: from AMDC2765.digital.local ([106.116.147.25])
	by eusync4.samsung.com (Oracle Communications Messaging Server
	7.0.5.31.0 64bit  (built May  5 2014))
	with ESMTPA id &lt;0ODG00I0K0Y0D650@eusync4.samsung.com&gt;; Tue,
	13 Sep 2016 13:49:18 +0100 (BST)
From: Marek Szyprowski &lt;m.szyprowski@samsung.com&gt;
To: linux-pm@vger.kernel.org, linux-kernel@vger.kernel.org,
	iommu@lists.linux-foundation.org, linux-samsung-soc@vger.kernel.org
Cc: Marek Szyprowski &lt;m.szyprowski@samsung.com&gt;,
	Joerg Roedel &lt;joro@8bytes.org&gt;,
	Inki Dae &lt;inki.dae@samsung.com&gt;, Kukjin Kim &lt;kgene@kernel.org&gt;,
	Krzysztof Kozlowski &lt;k.kozlowski@samsung.com&gt;,
	Bartlomiej Zolnierkiewicz &lt;b.zolnierkie@samsung.com&gt;,
	&quot;Rafael J. Wysocki&quot; &lt;rjw@rjwysocki.net&gt;, Mark Brown &lt;broonie@kernel.org&gt;,
	&quot;Luis R. Rodriguez&quot; &lt;mcgrof@kernel.org&gt;,
	Greg Kroah-Hartman &lt;gregkh@linuxfoundation.org&gt;,
	Tomeu Vizoso &lt;tomeu.vizoso@collabora.com&gt;,
	Lukas Wunner &lt;lukas@wunner.de&gt;, Kevin Hilman &lt;khilman@kernel.org&gt;
Subject: [PATCH v3 2/2] iommu/exynos: Add proper runtime pm support
Date: Tue, 13 Sep 2016 14:49:01 +0200
Message-id: &lt;1473770941-8337-3-git-send-email-m.szyprowski@samsung.com&gt;
X-Mailer: git-send-email 1.9.1
In-reply-to: &lt;1473770941-8337-1-git-send-email-m.szyprowski@samsung.com&gt;
X-Brightmail-Tracker: H4sIAAAAAAAAAzWSbUhTYRTHfe7u7u5Gk+sUffA1VvaipA768IQWSZaXDOyDMEowV17UUieb
	ivolU/NlmRMtvWDpwmViyvIlEUOd07RluqamQliYzqRpQtqHyiy3q99+h/M///85cEiepILv
	TaZmZDGqDEWalBDhPaO/Jk9Yfs7Jw+wfQ1EHa+Cjh4vLBCpqMhCo+nMVjnSD4ai8/oUA2Vdl
	SLtk5yFb1xKGpvseEWjz/ghArGUAQ6tffVD7yIIAzVfZAHo3PsVHle1TxFk3enmoAaN7F/SA
	7mwtJ+jBx20Cumb+GaC7P5TidGV3K6A3O/1ptrSHf1l4VRSRxKSl5jCq0DOJopSdcis/cywx
	d2KlBC8A1lgNEJKQOgn1i4UCjj3h+08GQgNEpIRqBrB51Y5zxSaA271v8f2JDcMbvoOdqn/6
	vYkCDP4xDjutCEoGNesaZ8ODugPgVpkecxQ86gEOtWwL5lC5U+fgROMK4WCcCoTbxbW7tiQp
	pqKhsf4ml+YPzaM1zjQhRcOZLTNw+EBqVgDvrdUChx5SfrDTyOP0UXBQY9/b1B1+G+veu80X
	lpcNYRxrASy8G8wxC+DkupjjcDg8ZnVm8ShXWN1Tx+PsxbCsRMJJaNjYWLFnHwltrwb43PH1
	APbXLQmqgK8OuLQCDyZbnZ7MqGUhakW6OjsjOeSGMr0T7P7I+M7YRi+wFcWZAEUC6QFxwfNZ
	uYSvyFHnpZsAJHlSD3Hwjzm5RJykyMtnVMprquw0Rm0CPiQu9RL362bkEipZkcXcYphMRrXf
	xUihdwEIqCyO6Xu58tSuPdSk85Ne8T9y2Jo6bcEr46JbbruVdSlLMySm3PqhqoYvrsZ837XY
	PGV7i3n9QlZhUELAEhsdxi4Glpw+iGs6dF7H27SY+yHt+S2JiznyqKclxjM+6OKxBKFPQoCy
	Ne3v71OvnxDfWVtzhOxSvCX1epR1hqWluDpFIQviqdSK/yGP6J4fAwAA
X-Brightmail-Tracker: H4sIAAAAAAAAA+NgFlrDIsWRmVeSWpSXmKPExsVy+t/xa7oLvl4PNzj6Tt1i44z1rBZTHz5h
	s2hevJ7NYtL9CSwWC/ZbW3TO3sBu8fqFoUX/49fMFk83P2ayuLxrDpvF594jjBYzzu9jsnjx
	XNpi7ZG77BY3JjxltDhz+hKrRd/aS2wOgh5PDs5j8thxdwmjx6ZVnWwe++euYfeYfGM5o8eW
	q+0sHn1bVjF6fN4k5zGjfRtrAGeUm01GamJKapFCal5yfkpmXrqtUmiIm66FkkJeYm6qrVKE
	rm9IkJJCWWJOKZBnZIAGHJwD3IOV9O0S3DL+dV5kLTieUHH2WRtLA+NF/y5GTg4JAROJ9+tP
	sELYYhIX7q1n62Lk4hASWMIo8ej2cxaQhJBAE5PEyiMCIDabgKFE19susCIRgUZGiW1bJ7KD
	OMwC01gkpnR3gXUICzhLnJ3/jA3EZhFQlfjTMg1oBQcHr4C7xIHZWRDb5CROHpsMtplTwEPi
	ypeTjBDL3CU2/LvHOoGRdwEjwypGkdTS4tz03GJDveLE3OLSvHS95PzcTYzAmNp27OfmHYyX
	NgYfYhTgYFTi4W1YfS1ciDWxrLgy9xCjBAezkgiv9qfr4UK8KYmVValF+fFFpTmpxYcYTYFu
	msgsJZqcD4z3vJJ4QxNDc0tDI2MLC3MjIyVx3pIPV8KFBNITS1KzU1MLUotg+pg4OKUaGKtC
	+hsLd64o7Yi+9mSu96pSJcMVBo/deKyyfz+y6Hzs137Kf3lLicCNG7ffKqZzlisz9suuWbT5
	nObUd+Z83ioZEotM1tkJS5yo7+YvNjmmV1T3e/IswR91u+t2zfHi8zKezbfN88a6I+bh+/ZE
	/5Ow2n5yy9TletcW3T/RMln0sE96/VqmG0osxRmJhlrMRcWJAMnq2Te/AgAA
X-MTR: 20000000000000000@CPGS
X-CMS-MailID: 20160913124918eucas1p29f49efbb142d416215482c29b53daff8
X-Msg-Generator: CA
X-Sender-IP: 182.198.249.179
X-Local-Sender: =?UTF-8?B?TWFyZWsgU3p5cHJvd3NraRtTUlBPTC1LZXJuZWwgKFRQKRs=?=
	=?UTF-8?B?7IK87ISx7KCE7J6QG1NlbmlvciBTb2Z0d2FyZSBFbmdpbmVlcg==?=
X-Global-Sender: =?UTF-8?B?TWFyZWsgU3p5cHJvd3NraRtTUlBPTC1LZXJuZWwgKFRQKRtT?=
	=?UTF-8?B?YW1zdW5nIEVsZWN0cm9uaWNzG1NlbmlvciBTb2Z0d2FyZSBFbmdpbmVlcg==?=
X-Sender-Code: =?UTF-8?B?QzEwG0VIURtDMTBDRDAyQ0QwMjczOTI=?=
CMS-TYPE: 201P
X-HopCount: 7
X-CMS-RootMailID: 20160913124918eucas1p29f49efbb142d416215482c29b53daff8
X-RootMTR: 20160913124918eucas1p29f49efbb142d416215482c29b53daff8
References: &lt;1473770941-8337-1-git-send-email-m.szyprowski@samsung.com&gt;
	&lt;CGME20160913124918eucas1p29f49efbb142d416215482c29b53daff8@eucas1p2.samsung.com&gt;
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=2061">Marek Szyprowski</a> - Sept. 13, 2016, 12:49 p.m.</div>
<pre class="content">
This patch uses recently introduced device links to track the runtime pm
state of the master&#39;s device. This way each SYSMMU controller is runtime
activated when its master&#39;s device is active and can save/restore its state
instead of being enabled all the time. This way SYSMMU controllers no
longer prevents respective power domains to be turned off when master&#39;s
device is not used.
<span class="signed-off-by">
Signed-off-by: Marek Szyprowski &lt;m.szyprowski@samsung.com&gt;</span>
---
 drivers/iommu/exynos-iommu.c | 225 ++++++++++++++++++-------------------------
 1 file changed, 94 insertions(+), 131 deletions(-)
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=45281">Ulf Hansson</a> - Sept. 13, 2016, 2:20 p.m.</div>
<pre class="content">
On 13 September 2016 at 14:49, Marek Szyprowski
&lt;m.szyprowski@samsung.com&gt; wrote:
<span class="quote">&gt; This patch uses recently introduced device links to track the runtime pm</span>
<span class="quote">&gt; state of the master&#39;s device. This way each SYSMMU controller is runtime</span>
<span class="quote">&gt; activated when its master&#39;s device is active and can save/restore its state</span>
<span class="quote">&gt; instead of being enabled all the time. This way SYSMMU controllers no</span>
<span class="quote">&gt; longer prevents respective power domains to be turned off when master&#39;s</span>
<span class="quote">&gt; device is not used.</span>

Apologize for not reviewing earlier and if you find my
questions/suggestions being silly. You may ignore them, if you don&#39;t
think they deserves a proper answer. :-)

I am not so familiar with the IOMMU subsystem, but I am wondering
whether the issue you are solving, is similar to what can be observed
for DMA and serial drivers. And of course also for other IOMMU
drivers.

In general the DMA/serial drivers requires to use the
pm_runtime_irq_safe() option, to be able to easily deploy runtime PM
support (of course there are some other workarounds as well).

As we know, using the pm_runtime_irq_safe() option comes with some
limitations, such as the runtime PM callbacks is not allowed to sleep.
For a PM domain (genpd) that is attached to the device, this also
means it must not be powered off.

To solve this problem, I was thinking we could convert to use the
asynchronous pm_runtime_get() API, when trying to runtime resume the
device from atomic contexts.

Of course when it turns out that the device isn&#39;t yet runtime resumed
immediately after calling pm_runtime_get(), the request needs to be
put on a request queue to be managed shortly after instead. Doing it
like this, would remove the need to use the pm_runtime_irq_safe()
option.

I realize that such change needs to be implemented in common code for
IOMMU drivers, if at all possible.

Anyway, I hope you at least get the idea and I just wanted to mention
that I have been exploring this option for DMA and serial drivers.

Kind regards
Uffe
<span class="quote">
&gt;</span>
<span class="quote">&gt; Signed-off-by: Marek Szyprowski &lt;m.szyprowski@samsung.com&gt;</span>
<span class="quote">&gt; ---</span>
<span class="quote">&gt;  drivers/iommu/exynos-iommu.c | 225 ++++++++++++++++++-------------------------</span>
<span class="quote">&gt;  1 file changed, 94 insertions(+), 131 deletions(-)</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; diff --git a/drivers/iommu/exynos-iommu.c b/drivers/iommu/exynos-iommu.c</span>
<span class="quote">&gt; index b0fa4d432e71..34717a0b1902 100644</span>
<span class="quote">&gt; --- a/drivers/iommu/exynos-iommu.c</span>
<span class="quote">&gt; +++ b/drivers/iommu/exynos-iommu.c</span>
<span class="quote">&gt; @@ -206,6 +206,7 @@ static const struct sysmmu_fault_info sysmmu_v5_faults[] = {</span>
<span class="quote">&gt;  struct exynos_iommu_owner {</span>
<span class="quote">&gt;         struct list_head controllers;   /* list of sysmmu_drvdata.owner_node */</span>
<span class="quote">&gt;         struct iommu_domain *domain;    /* domain this device is attached */</span>
<span class="quote">&gt; +       struct mutex rpm_lock;          /* for runtime pm of all sysmmus */</span>
<span class="quote">&gt;  };</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;  /*</span>
<span class="quote">&gt; @@ -237,8 +238,8 @@ struct sysmmu_drvdata {</span>
<span class="quote">&gt;         struct clk *aclk;               /* SYSMMU&#39;s aclk clock */</span>
<span class="quote">&gt;         struct clk *pclk;               /* SYSMMU&#39;s pclk clock */</span>
<span class="quote">&gt;         struct clk *clk_master;         /* master&#39;s device clock */</span>
<span class="quote">&gt; -       int activations;                /* number of calls to sysmmu_enable */</span>
<span class="quote">&gt;         spinlock_t lock;                /* lock for modyfying state */</span>
<span class="quote">&gt; +       int active;                     /* current status */</span>
<span class="quote">&gt;         struct exynos_iommu_domain *domain; /* domain we belong to */</span>
<span class="quote">&gt;         struct list_head domain_node;   /* node for domain clients list */</span>
<span class="quote">&gt;         struct list_head owner_node;    /* node for owner controllers list */</span>
<span class="quote">&gt; @@ -251,25 +252,6 @@ static struct exynos_iommu_domain *to_exynos_domain(struct iommu_domain *dom)</span>
<span class="quote">&gt;         return container_of(dom, struct exynos_iommu_domain, domain);</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; -static bool set_sysmmu_active(struct sysmmu_drvdata *data)</span>
<span class="quote">&gt; -{</span>
<span class="quote">&gt; -       /* return true if the System MMU was not active previously</span>
<span class="quote">&gt; -          and it needs to be initialized */</span>
<span class="quote">&gt; -       return ++data-&gt;activations == 1;</span>
<span class="quote">&gt; -}</span>
<span class="quote">&gt; -</span>
<span class="quote">&gt; -static bool set_sysmmu_inactive(struct sysmmu_drvdata *data)</span>
<span class="quote">&gt; -{</span>
<span class="quote">&gt; -       /* return true if the System MMU is needed to be disabled */</span>
<span class="quote">&gt; -       BUG_ON(data-&gt;activations &lt; 1);</span>
<span class="quote">&gt; -       return --data-&gt;activations == 0;</span>
<span class="quote">&gt; -}</span>
<span class="quote">&gt; -</span>
<span class="quote">&gt; -static bool is_sysmmu_active(struct sysmmu_drvdata *data)</span>
<span class="quote">&gt; -{</span>
<span class="quote">&gt; -       return data-&gt;activations &gt; 0;</span>
<span class="quote">&gt; -}</span>
<span class="quote">&gt; -</span>
<span class="quote">&gt;  static void sysmmu_unblock(struct sysmmu_drvdata *data)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;         writel(CTRL_ENABLE, data-&gt;sfrbase + REG_MMU_CTRL);</span>
<span class="quote">&gt; @@ -389,7 +371,7 @@ static irqreturn_t exynos_sysmmu_irq(int irq, void *dev_id)</span>
<span class="quote">&gt;         unsigned short reg_status, reg_clear;</span>
<span class="quote">&gt;         int ret = -ENOSYS;</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; -       WARN_ON(!is_sysmmu_active(data));</span>
<span class="quote">&gt; +       WARN_ON(!data-&gt;active);</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;         if (MMU_MAJ_VER(data-&gt;version) &lt; 5) {</span>
<span class="quote">&gt;                 reg_status = REG_INT_STATUS;</span>
<span class="quote">&gt; @@ -435,40 +417,19 @@ static irqreturn_t exynos_sysmmu_irq(int irq, void *dev_id)</span>
<span class="quote">&gt;         return IRQ_HANDLED;</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; -static void __sysmmu_disable_nocount(struct sysmmu_drvdata *data)</span>
<span class="quote">&gt; +static void __sysmmu_disable(struct sysmmu_drvdata *data)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt; +       unsigned long flags;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt;         clk_enable(data-&gt;clk_master);</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; +       spin_lock_irqsave(&amp;data-&gt;lock, flags);</span>
<span class="quote">&gt;         writel(CTRL_DISABLE, data-&gt;sfrbase + REG_MMU_CTRL);</span>
<span class="quote">&gt;         writel(0, data-&gt;sfrbase + REG_MMU_CFG);</span>
<span class="quote">&gt; -</span>
<span class="quote">&gt; -       __sysmmu_disable_clocks(data);</span>
<span class="quote">&gt; -}</span>
<span class="quote">&gt; -</span>
<span class="quote">&gt; -static bool __sysmmu_disable(struct sysmmu_drvdata *data)</span>
<span class="quote">&gt; -{</span>
<span class="quote">&gt; -       bool disabled;</span>
<span class="quote">&gt; -       unsigned long flags;</span>
<span class="quote">&gt; -</span>
<span class="quote">&gt; -       spin_lock_irqsave(&amp;data-&gt;lock, flags);</span>
<span class="quote">&gt; -</span>
<span class="quote">&gt; -       disabled = set_sysmmu_inactive(data);</span>
<span class="quote">&gt; -</span>
<span class="quote">&gt; -       if (disabled) {</span>
<span class="quote">&gt; -               data-&gt;pgtable = 0;</span>
<span class="quote">&gt; -               data-&gt;domain = NULL;</span>
<span class="quote">&gt; -</span>
<span class="quote">&gt; -               __sysmmu_disable_nocount(data);</span>
<span class="quote">&gt; -</span>
<span class="quote">&gt; -               dev_dbg(data-&gt;sysmmu, &quot;Disabled\n&quot;);</span>
<span class="quote">&gt; -       } else  {</span>
<span class="quote">&gt; -               dev_dbg(data-&gt;sysmmu, &quot;%d times left to disable\n&quot;,</span>
<span class="quote">&gt; -                                       data-&gt;activations);</span>
<span class="quote">&gt; -       }</span>
<span class="quote">&gt; -</span>
<span class="quote">&gt; +       data-&gt;active = false;</span>
<span class="quote">&gt;         spin_unlock_irqrestore(&amp;data-&gt;lock, flags);</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; -       return disabled;</span>
<span class="quote">&gt; +       __sysmmu_disable_clocks(data);</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;  static void __sysmmu_init_config(struct sysmmu_drvdata *data)</span>
<span class="quote">&gt; @@ -485,17 +446,19 @@ static void __sysmmu_init_config(struct sysmmu_drvdata *data)</span>
<span class="quote">&gt;         writel(cfg, data-&gt;sfrbase + REG_MMU_CFG);</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; -static void __sysmmu_enable_nocount(struct sysmmu_drvdata *data)</span>
<span class="quote">&gt; +static void __sysmmu_enable(struct sysmmu_drvdata *data)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt; +       unsigned long flags;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt;         __sysmmu_enable_clocks(data);</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; +       spin_lock_irqsave(&amp;data-&gt;lock, flags);</span>
<span class="quote">&gt;         writel(CTRL_BLOCK, data-&gt;sfrbase + REG_MMU_CTRL);</span>
<span class="quote">&gt; -</span>
<span class="quote">&gt;         __sysmmu_init_config(data);</span>
<span class="quote">&gt; -</span>
<span class="quote">&gt;         __sysmmu_set_ptbase(data, data-&gt;pgtable);</span>
<span class="quote">&gt; -</span>
<span class="quote">&gt;         writel(CTRL_ENABLE, data-&gt;sfrbase + REG_MMU_CTRL);</span>
<span class="quote">&gt; +       data-&gt;active = true;</span>
<span class="quote">&gt; +       spin_unlock_irqrestore(&amp;data-&gt;lock, flags);</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;         /*</span>
<span class="quote">&gt;          * SYSMMU driver keeps master&#39;s clock enabled only for the short</span>
<span class="quote">&gt; @@ -506,48 +469,18 @@ static void __sysmmu_enable_nocount(struct sysmmu_drvdata *data)</span>
<span class="quote">&gt;         clk_disable(data-&gt;clk_master);</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; -static int __sysmmu_enable(struct sysmmu_drvdata *data, phys_addr_t pgtable,</span>
<span class="quote">&gt; -                          struct exynos_iommu_domain *domain)</span>
<span class="quote">&gt; -{</span>
<span class="quote">&gt; -       int ret = 0;</span>
<span class="quote">&gt; -       unsigned long flags;</span>
<span class="quote">&gt; -</span>
<span class="quote">&gt; -       spin_lock_irqsave(&amp;data-&gt;lock, flags);</span>
<span class="quote">&gt; -       if (set_sysmmu_active(data)) {</span>
<span class="quote">&gt; -               data-&gt;pgtable = pgtable;</span>
<span class="quote">&gt; -               data-&gt;domain = domain;</span>
<span class="quote">&gt; -</span>
<span class="quote">&gt; -               __sysmmu_enable_nocount(data);</span>
<span class="quote">&gt; -</span>
<span class="quote">&gt; -               dev_dbg(data-&gt;sysmmu, &quot;Enabled\n&quot;);</span>
<span class="quote">&gt; -       } else {</span>
<span class="quote">&gt; -               ret = (pgtable == data-&gt;pgtable) ? 1 : -EBUSY;</span>
<span class="quote">&gt; -</span>
<span class="quote">&gt; -               dev_dbg(data-&gt;sysmmu, &quot;already enabled\n&quot;);</span>
<span class="quote">&gt; -       }</span>
<span class="quote">&gt; -</span>
<span class="quote">&gt; -       if (WARN_ON(ret &lt; 0))</span>
<span class="quote">&gt; -               set_sysmmu_inactive(data); /* decrement count */</span>
<span class="quote">&gt; -</span>
<span class="quote">&gt; -       spin_unlock_irqrestore(&amp;data-&gt;lock, flags);</span>
<span class="quote">&gt; -</span>
<span class="quote">&gt; -       return ret;</span>
<span class="quote">&gt; -}</span>
<span class="quote">&gt; -</span>
<span class="quote">&gt;  static void sysmmu_tlb_invalidate_flpdcache(struct sysmmu_drvdata *data,</span>
<span class="quote">&gt;                                             sysmmu_iova_t iova)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;         unsigned long flags;</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; -</span>
<span class="quote">&gt;         spin_lock_irqsave(&amp;data-&gt;lock, flags);</span>
<span class="quote">&gt; -       if (is_sysmmu_active(data) &amp;&amp; data-&gt;version &gt;= MAKE_MMU_VER(3, 3)) {</span>
<span class="quote">&gt; +       if (data-&gt;active &amp;&amp; data-&gt;version &gt;= MAKE_MMU_VER(3, 3)) {</span>
<span class="quote">&gt;                 clk_enable(data-&gt;clk_master);</span>
<span class="quote">&gt;                 __sysmmu_tlb_invalidate_entry(data, iova, 1);</span>
<span class="quote">&gt;                 clk_disable(data-&gt;clk_master);</span>
<span class="quote">&gt;         }</span>
<span class="quote">&gt;         spin_unlock_irqrestore(&amp;data-&gt;lock, flags);</span>
<span class="quote">&gt; -</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;  static void sysmmu_tlb_invalidate_entry(struct sysmmu_drvdata *data,</span>
<span class="quote">&gt; @@ -556,7 +489,7 @@ static void sysmmu_tlb_invalidate_entry(struct sysmmu_drvdata *data,</span>
<span class="quote">&gt;         unsigned long flags;</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;         spin_lock_irqsave(&amp;data-&gt;lock, flags);</span>
<span class="quote">&gt; -       if (is_sysmmu_active(data)) {</span>
<span class="quote">&gt; +       if (data-&gt;active) {</span>
<span class="quote">&gt;                 unsigned int num_inv = 1;</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;                 clk_enable(data-&gt;clk_master);</span>
<span class="quote">&gt; @@ -657,40 +590,55 @@ static int __init exynos_sysmmu_probe(struct platform_device *pdev)</span>
<span class="quote">&gt;         }</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;         pm_runtime_enable(dev);</span>
<span class="quote">&gt; -</span>
<span class="quote">&gt;         of_iommu_set_ops(dev-&gt;of_node, &amp;exynos_iommu_ops);</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;         return 0;</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; -#ifdef CONFIG_PM_SLEEP</span>
<span class="quote">&gt;  static int exynos_sysmmu_suspend(struct device *dev)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;         struct sysmmu_drvdata *data = dev_get_drvdata(dev);</span>
<span class="quote">&gt; +       struct exynos_iommu_owner *owner;</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; -       dev_dbg(dev, &quot;suspend\n&quot;);</span>
<span class="quote">&gt; -       if (is_sysmmu_active(data)) {</span>
<span class="quote">&gt; -               __sysmmu_disable_nocount(data);</span>
<span class="quote">&gt; -               pm_runtime_put(dev);</span>
<span class="quote">&gt; +       if (!data-&gt;master)</span>
<span class="quote">&gt; +               return 0;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +       owner = data-&gt;master-&gt;archdata.iommu;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +       mutex_lock(&amp;owner-&gt;rpm_lock);</span>
<span class="quote">&gt; +       if (data-&gt;domain) {</span>
<span class="quote">&gt; +               dev_dbg(data-&gt;sysmmu, &quot;saving state\n&quot;);</span>
<span class="quote">&gt; +               __sysmmu_disable(data);</span>
<span class="quote">&gt;         }</span>
<span class="quote">&gt; +       mutex_unlock(&amp;owner-&gt;rpm_lock);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt;         return 0;</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;  static int exynos_sysmmu_resume(struct device *dev)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;         struct sysmmu_drvdata *data = dev_get_drvdata(dev);</span>
<span class="quote">&gt; +       struct exynos_iommu_owner *owner;</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; -       dev_dbg(dev, &quot;resume\n&quot;);</span>
<span class="quote">&gt; -       if (is_sysmmu_active(data)) {</span>
<span class="quote">&gt; -               pm_runtime_get_sync(dev);</span>
<span class="quote">&gt; -               __sysmmu_enable_nocount(data);</span>
<span class="quote">&gt; +       if (!data-&gt;master)</span>
<span class="quote">&gt; +               return 0;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +       owner = data-&gt;master-&gt;archdata.iommu;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +       mutex_lock(&amp;owner-&gt;rpm_lock);</span>
<span class="quote">&gt; +       if (data-&gt;domain) {</span>
<span class="quote">&gt; +               dev_dbg(data-&gt;sysmmu, &quot;restoring state\n&quot;);</span>
<span class="quote">&gt; +               __sysmmu_enable(data);</span>
<span class="quote">&gt;         }</span>
<span class="quote">&gt; +       mutex_unlock(&amp;owner-&gt;rpm_lock);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt;         return 0;</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt; -#endif</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;  static const struct dev_pm_ops sysmmu_pm_ops = {</span>
<span class="quote">&gt; -       SET_LATE_SYSTEM_SLEEP_PM_OPS(exynos_sysmmu_suspend, exynos_sysmmu_resume)</span>
<span class="quote">&gt; +       SET_RUNTIME_PM_OPS(exynos_sysmmu_suspend, exynos_sysmmu_resume, NULL)</span>
<span class="quote">&gt; +       SET_LATE_SYSTEM_SLEEP_PM_OPS(pm_runtime_force_suspend,</span>
<span class="quote">&gt; +                                    pm_runtime_force_resume)</span>
<span class="quote">&gt;  };</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;  static const struct of_device_id sysmmu_of_match[] __initconst = {</span>
<span class="quote">&gt; @@ -794,9 +742,12 @@ static void exynos_iommu_domain_free(struct iommu_domain *iommu_domain)</span>
<span class="quote">&gt;         spin_lock_irqsave(&amp;domain-&gt;lock, flags);</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;         list_for_each_entry_safe(data, next, &amp;domain-&gt;clients, domain_node) {</span>
<span class="quote">&gt; -               if (__sysmmu_disable(data))</span>
<span class="quote">&gt; -                       data-&gt;master = NULL;</span>
<span class="quote">&gt; +               spin_lock(&amp;data-&gt;lock);</span>
<span class="quote">&gt; +               __sysmmu_disable(data);</span>
<span class="quote">&gt; +               data-&gt;pgtable = 0;</span>
<span class="quote">&gt; +               data-&gt;domain = NULL;</span>
<span class="quote">&gt;                 list_del_init(&amp;data-&gt;domain_node);</span>
<span class="quote">&gt; +               spin_unlock(&amp;data-&gt;lock);</span>
<span class="quote">&gt;         }</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;         spin_unlock_irqrestore(&amp;domain-&gt;lock, flags);</span>
<span class="quote">&gt; @@ -830,31 +781,32 @@ static void exynos_iommu_detach_device(struct iommu_domain *iommu_domain,</span>
<span class="quote">&gt;         phys_addr_t pagetable = virt_to_phys(domain-&gt;pgtable);</span>
<span class="quote">&gt;         struct sysmmu_drvdata *data, *next;</span>
<span class="quote">&gt;         unsigned long flags;</span>
<span class="quote">&gt; -       bool found = false;</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;         if (!has_sysmmu(dev) || owner-&gt;domain != iommu_domain)</span>
<span class="quote">&gt;                 return;</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; +       mutex_lock(&amp;owner-&gt;rpm_lock);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +       list_for_each_entry(data, &amp;owner-&gt;controllers, owner_node) {</span>
<span class="quote">&gt; +               if (pm_runtime_active(data-&gt;sysmmu))</span>
<span class="quote">&gt; +                       __sysmmu_disable(data);</span>
<span class="quote">&gt; +       }</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt;         spin_lock_irqsave(&amp;domain-&gt;lock, flags);</span>
<span class="quote">&gt;         list_for_each_entry_safe(data, next, &amp;domain-&gt;clients, domain_node) {</span>
<span class="quote">&gt; -               if (data-&gt;master == dev) {</span>
<span class="quote">&gt; -                       if (__sysmmu_disable(data)) {</span>
<span class="quote">&gt; -                               data-&gt;master = NULL;</span>
<span class="quote">&gt; -                               list_del_init(&amp;data-&gt;domain_node);</span>
<span class="quote">&gt; -                       }</span>
<span class="quote">&gt; -                       pm_runtime_put(data-&gt;sysmmu);</span>
<span class="quote">&gt; -                       found = true;</span>
<span class="quote">&gt; -               }</span>
<span class="quote">&gt; +               spin_lock(&amp;data-&gt;lock);</span>
<span class="quote">&gt; +               data-&gt;pgtable = 0;</span>
<span class="quote">&gt; +               data-&gt;domain = NULL;</span>
<span class="quote">&gt; +               list_del_init(&amp;data-&gt;domain_node);</span>
<span class="quote">&gt; +               spin_unlock(&amp;data-&gt;lock);</span>
<span class="quote">&gt;         }</span>
<span class="quote">&gt; +       owner-&gt;domain = NULL;</span>
<span class="quote">&gt;         spin_unlock_irqrestore(&amp;domain-&gt;lock, flags);</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; -       owner-&gt;domain = NULL;</span>
<span class="quote">&gt; +       mutex_unlock(&amp;owner-&gt;rpm_lock);</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; -       if (found)</span>
<span class="quote">&gt; -               dev_dbg(dev, &quot;%s: Detached IOMMU with pgtable %pa\n&quot;,</span>
<span class="quote">&gt; -                                       __func__, &amp;pagetable);</span>
<span class="quote">&gt; -       else</span>
<span class="quote">&gt; -               dev_err(dev, &quot;%s: No IOMMU is attached\n&quot;, __func__);</span>
<span class="quote">&gt; +       dev_dbg(dev, &quot;%s: Detached IOMMU with pgtable %pa\n&quot;, __func__,</span>
<span class="quote">&gt; +               &amp;pagetable);</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;  static int exynos_iommu_attach_device(struct iommu_domain *iommu_domain,</span>
<span class="quote">&gt; @@ -865,7 +817,6 @@ static int exynos_iommu_attach_device(struct iommu_domain *iommu_domain,</span>
<span class="quote">&gt;         struct sysmmu_drvdata *data;</span>
<span class="quote">&gt;         phys_addr_t pagetable = virt_to_phys(domain-&gt;pgtable);</span>
<span class="quote">&gt;         unsigned long flags;</span>
<span class="quote">&gt; -       int ret = -ENODEV;</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;         if (!has_sysmmu(dev))</span>
<span class="quote">&gt;                 return -ENODEV;</span>
<span class="quote">&gt; @@ -873,29 +824,30 @@ static int exynos_iommu_attach_device(struct iommu_domain *iommu_domain,</span>
<span class="quote">&gt;         if (owner-&gt;domain)</span>
<span class="quote">&gt;                 exynos_iommu_detach_device(owner-&gt;domain, dev);</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; +       mutex_lock(&amp;owner-&gt;rpm_lock);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +       spin_lock_irqsave(&amp;domain-&gt;lock, flags);</span>
<span class="quote">&gt;         list_for_each_entry(data, &amp;owner-&gt;controllers, owner_node) {</span>
<span class="quote">&gt; -               pm_runtime_get_sync(data-&gt;sysmmu);</span>
<span class="quote">&gt; -               ret = __sysmmu_enable(data, pagetable, domain);</span>
<span class="quote">&gt; -               if (ret &gt;= 0) {</span>
<span class="quote">&gt; -                       data-&gt;master = dev;</span>
<span class="quote">&gt; -</span>
<span class="quote">&gt; -                       spin_lock_irqsave(&amp;domain-&gt;lock, flags);</span>
<span class="quote">&gt; -                       list_add_tail(&amp;data-&gt;domain_node, &amp;domain-&gt;clients);</span>
<span class="quote">&gt; -                       spin_unlock_irqrestore(&amp;domain-&gt;lock, flags);</span>
<span class="quote">&gt; -               }</span>
<span class="quote">&gt; +               spin_lock(&amp;data-&gt;lock);</span>
<span class="quote">&gt; +               data-&gt;pgtable = pagetable;</span>
<span class="quote">&gt; +               data-&gt;domain = domain;</span>
<span class="quote">&gt; +               list_add_tail(&amp;data-&gt;domain_node, &amp;domain-&gt;clients);</span>
<span class="quote">&gt; +               spin_unlock(&amp;data-&gt;lock);</span>
<span class="quote">&gt;         }</span>
<span class="quote">&gt; +       owner-&gt;domain = iommu_domain;</span>
<span class="quote">&gt; +       spin_unlock_irqrestore(&amp;domain-&gt;lock, flags);</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; -       if (ret &lt; 0) {</span>
<span class="quote">&gt; -               dev_err(dev, &quot;%s: Failed to attach IOMMU with pgtable %pa\n&quot;,</span>
<span class="quote">&gt; -                                       __func__, &amp;pagetable);</span>
<span class="quote">&gt; -               return ret;</span>
<span class="quote">&gt; +       list_for_each_entry(data, &amp;owner-&gt;controllers, owner_node) {</span>
<span class="quote">&gt; +               if (pm_runtime_active(data-&gt;sysmmu))</span>
<span class="quote">&gt; +                       __sysmmu_enable(data);</span>
<span class="quote">&gt;         }</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; -       owner-&gt;domain = iommu_domain;</span>
<span class="quote">&gt; -       dev_dbg(dev, &quot;%s: Attached IOMMU with pgtable %pa %s\n&quot;,</span>
<span class="quote">&gt; -               __func__, &amp;pagetable, (ret == 0) ? &quot;&quot; : &quot;, again&quot;);</span>
<span class="quote">&gt; +       mutex_unlock(&amp;owner-&gt;rpm_lock);</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; -       return ret;</span>
<span class="quote">&gt; +       dev_dbg(dev, &quot;%s: Attached IOMMU with pgtable %pa\n&quot;, __func__,</span>
<span class="quote">&gt; +               &amp;pagetable);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +       return 0;</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;  static sysmmu_pte_t *alloc_lv2entry(struct exynos_iommu_domain *domain,</span>
<span class="quote">&gt; @@ -1266,10 +1218,21 @@ static int exynos_iommu_of_xlate(struct device *dev,</span>
<span class="quote">&gt;                         return -ENOMEM;</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;                 INIT_LIST_HEAD(&amp;owner-&gt;controllers);</span>
<span class="quote">&gt; +               mutex_init(&amp;owner-&gt;rpm_lock);</span>
<span class="quote">&gt;                 dev-&gt;archdata.iommu = owner;</span>
<span class="quote">&gt;         }</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;         list_add_tail(&amp;data-&gt;owner_node, &amp;owner-&gt;controllers);</span>
<span class="quote">&gt; +       data-&gt;master = dev;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +       /*</span>
<span class="quote">&gt; +        * SYSMMU will be runtime enabled via device link (dependency) to its</span>
<span class="quote">&gt; +        * master device, so there are no direct calls to pm_runtime_get/put</span>
<span class="quote">&gt; +        * in this driver.</span>
<span class="quote">&gt; +        */</span>
<span class="quote">&gt; +       device_link_add(dev, data-&gt;sysmmu, DEVICE_LINK_AVAILABLE,</span>
<span class="quote">&gt; +                       DEVICE_LINK_PERSISTENT | DEVICE_LINK_PM_RUNTIME);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt;         return 0;</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; --</span>
<span class="quote">&gt; 1.9.1</span>
<span class="quote">&gt;</span>
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=143191">kbuild test robot</a> - Sept. 13, 2016, 2:35 p.m.</div>
<pre class="content">
Hi Marek,

[auto build test ERROR on iommu/next]
[also build test ERROR on v4.8-rc6 next-20160913]
[if your patch is applied to the wrong git tree, please drop us a note to help improve the system]
[Suggest to use git(&gt;=2.9.0) format-patch --base=&lt;commit&gt; (or --base=auto for convenience) to record what (public, well-known) commit your patch series was built on]
[Check https://git-scm.com/docs/git-format-patch for more information]

url:    https://github.com/0day-ci/linux/commits/Marek-Szyprowski/Exynos-IOMMU-proper-runtime-PM-support-use-device-dependencies/20160913-205434
base:   https://git.kernel.org/pub/scm/linux/kernel/git/joro/iommu.git next
config: arm-allmodconfig (attached as .config)
compiler: arm-linux-gnueabi-gcc (Debian 5.4.0-6) 5.4.0 20160609
reproduce:
        wget https://git.kernel.org/cgit/linux/kernel/git/wfg/lkp-tests.git/plain/sbin/make.cross -O ~/bin/make.cross
        chmod +x ~/bin/make.cross
        # save the attached .config to linux build tree
        make.cross ARCH=arm 

All errors (new ones prefixed by &gt;&gt;):

   drivers/iommu/exynos-iommu.c: In function &#39;exynos_iommu_of_xlate&#39;:
<span class="quote">&gt;&gt; drivers/iommu/exynos-iommu.c:1232:2: error: implicit declaration of function &#39;device_link_add&#39; [-Werror=implicit-function-declaration]</span>
     device_link_add(dev, data-&gt;sysmmu, DEVICE_LINK_AVAILABLE,
     ^
<span class="quote">&gt;&gt; drivers/iommu/exynos-iommu.c:1232:37: error: &#39;DEVICE_LINK_AVAILABLE&#39; undeclared (first use in this function)</span>
     device_link_add(dev, data-&gt;sysmmu, DEVICE_LINK_AVAILABLE,
                                        ^
   drivers/iommu/exynos-iommu.c:1232:37: note: each undeclared identifier is reported only once for each function it appears in
<span class="quote">&gt;&gt; drivers/iommu/exynos-iommu.c:1233:4: error: &#39;DEVICE_LINK_PERSISTENT&#39; undeclared (first use in this function)</span>
       DEVICE_LINK_PERSISTENT | DEVICE_LINK_PM_RUNTIME);
       ^
<span class="quote">&gt;&gt; drivers/iommu/exynos-iommu.c:1233:29: error: &#39;DEVICE_LINK_PM_RUNTIME&#39; undeclared (first use in this function)</span>
       DEVICE_LINK_PERSISTENT | DEVICE_LINK_PM_RUNTIME);
                                ^
   cc1: some warnings being treated as errors

vim +/device_link_add +1232 drivers/iommu/exynos-iommu.c

  1226	
  1227		/*
  1228		 * SYSMMU will be runtime enabled via device link (dependency) to its
  1229		 * master device, so there are no direct calls to pm_runtime_get/put
  1230		 * in this driver.
  1231		 */
<span class="quote">&gt; 1232		device_link_add(dev, data-&gt;sysmmu, DEVICE_LINK_AVAILABLE,</span>
<span class="quote">&gt; 1233				DEVICE_LINK_PERSISTENT | DEVICE_LINK_PM_RUNTIME);</span>
  1234	
  1235		return 0;
  1236	}

---
0-DAY kernel test infrastructure                Open Source Technology Center
https://lists.01.org/pipermail/kbuild-all                   Intel Corporation
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=2061">Marek Szyprowski</a> - Sept. 14, 2016, 7:11 a.m.</div>
<pre class="content">
Hi Ulf,

On 2016-09-13 16:20, Ulf Hansson wrote:
<span class="quote">&gt; On 13 September 2016 at 14:49, Marek Szyprowski</span>
<span class="quote">&gt; &lt;m.szyprowski@samsung.com&gt; wrote:</span>
<span class="quote">&gt;&gt; This patch uses recently introduced device links to track the runtime pm</span>
<span class="quote">&gt;&gt; state of the master&#39;s device. This way each SYSMMU controller is runtime</span>
<span class="quote">&gt;&gt; activated when its master&#39;s device is active and can save/restore its state</span>
<span class="quote">&gt;&gt; instead of being enabled all the time. This way SYSMMU controllers no</span>
<span class="quote">&gt;&gt; longer prevents respective power domains to be turned off when master&#39;s</span>
<span class="quote">&gt;&gt; device is not used.</span>
<span class="quote">&gt; Apologize for not reviewing earlier and if you find my</span>
<span class="quote">&gt; questions/suggestions being silly. You may ignore them, if you don&#39;t</span>
<span class="quote">&gt; think they deserves a proper answer. :-)</span>

No problem. There are no silly questions, but there might be some silly
answers ;)
<span class="quote">
&gt; I am not so familiar with the IOMMU subsystem, but I am wondering</span>
<span class="quote">&gt; whether the issue you are solving, is similar to what can be observed</span>
<span class="quote">&gt; for DMA and serial drivers. And of course also for other IOMMU</span>
<span class="quote">&gt; drivers.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; In general the DMA/serial drivers requires to use the</span>
<span class="quote">&gt; pm_runtime_irq_safe() option, to be able to easily deploy runtime PM</span>
<span class="quote">&gt; support (of course there are some other workarounds as well).</span>

There are some similarities between IOMMU and DMA engine devices (serial
drivers are imho completely different case). Both hw blocks do their work
on behalf of some other hardware block, which I will call master device.
DMA engine performs some DMA transaction on master&#39;s device request, while
IOMMU usually sits between system memory and master&#39;s device memory
interface, remapping addresses of each DMA transaction according to its
configuration and provided mapping tables (master device has some kind
of internal DMA controller and performs DMA transactions on their own).
IOMMU is usually used for a) mapping physically discontinuous memory into
contiguous DMA addresses and b) isolating devices, so they can access
only memory, which is dedicated or allocated for them.

DMA engine devices provide explicit API for their master&#39;s device drivers,
while IOMMU drivers are usually hidden behind DMA-mapping API (for most
use cases, although it would be possible for master&#39;s device driver to
call IOMMU API directly and some GPU/DRM drivers do that).

However from runtime pm perspective the DMA engine and IOMMU devices are
a bit different.

DMA engine drivers have well defined start and end of operation (queuing
dma request and irq from hw about having it finished). During that time
the device has to be runtime active all the time. The problem with using
current implementation of runtime pm is the fact that both start and end
of operation can be triggered from atomic context, what is not really
suitable for runtime pm. So the problem is mainly about API
incompatibility and lack of something like dma_engine_prepare()/unprepare()
(as an analogy to clocks api).

In case of IOMMU the main problem is determining weather IOMMU controller
has to be activated. There is no calls in IOMMU and DMA-mapping API, which
would bracket all DMA transactions performed by the master device. Someone
proposed to keep IOMMU runtime active when there exist at least one
mapping created by the IOMMU/DMA-mapping layers. This however does not
cover all the cases. In case of our IOMMU, when it is disabled or runtime
suspended, it enters &quot;pass-thought&quot; mode, so master device can still
perform DMA operations with identity mappings (so DMA address equals to
physical memory address). Till now Exynos IOMMU called pm_runtime_get()
on attaching to the iommu domain (what happens during initialization of
dma-mapping structures for given master device) and kept it active all
the time.

This patch series tries to address Exynos IOMMU runtime pm issue by forcing
IOMMU controller to follow runtime pm status of its master device. This way
we ensure that anytime when master&#39;s device is runtime activated, the iommu
will be also active and master device won&#39;t be able to bypass during its
DMA transactions mappings created by the IOMMU layer.

Quite long answer, but I hope I managed to give you a bit more background
on this topic.
<span class="quote">
&gt; As we know, using the pm_runtime_irq_safe() option comes with some</span>
<span class="quote">&gt; limitations, such as the runtime PM callbacks is not allowed to sleep.</span>
<span class="quote">&gt; For a PM domain (genpd) that is attached to the device, this also</span>
<span class="quote">&gt; means it must not be powered off.</span>

Right, if possible I would like to avoid using pm_runtime_irq_safe()
option, because it is really impractical.
<span class="quote">
&gt; To solve this problem, I was thinking we could convert to use the</span>
<span class="quote">&gt; asynchronous pm_runtime_get() API, when trying to runtime resume the</span>
<span class="quote">&gt; device from atomic contexts.</span>

I&#39;m not sure if this will work for DMA engine devices. If I understand
correctly some client&#39;s of DMA engine device might rely on the DMA
engine being configured and operational after queuing a request and
they might lock up if the DMA engine device activation if postponed
because of async runtime pm activation.
<span class="quote">
&gt; Of course when it turns out that the device isn&#39;t yet runtime resumed</span>
<span class="quote">&gt; immediately after calling pm_runtime_get(), the request needs to be</span>
<span class="quote">&gt; put on a request queue to be managed shortly after instead. Doing it</span>
<span class="quote">&gt; like this, would remove the need to use the pm_runtime_irq_safe()</span>
<span class="quote">&gt; option.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; I realize that such change needs to be implemented in common code for</span>
<span class="quote">&gt; IOMMU drivers, if at all possible.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; Anyway, I hope you at least get the idea and I just wanted to mention</span>
<span class="quote">&gt; that I have been exploring this option for DMA and serial drivers.</span>

I also have runtime pm for serial driver on my todo list, but it doesn&#39;t
have high priority. The other runtime pm integration subsystem that I
want to work on first is pinctrl. It is needed to fully support Exynos
5433 SoCs, because registers of some audio related pins are in the audio
power domain, what now prevent us from enabling support for audio power
domain.

Best regards
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=45281">Ulf Hansson</a> - Sept. 14, 2016, 10:28 a.m.</div>
<pre class="content">
[...]
<span class="quote">
&gt;</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; There are some similarities between IOMMU and DMA engine devices (serial</span>
<span class="quote">&gt; drivers are imho completely different case). Both hw blocks do their work</span>
<span class="quote">&gt; on behalf of some other hardware block, which I will call master device.</span>
<span class="quote">&gt; DMA engine performs some DMA transaction on master&#39;s device request, while</span>
<span class="quote">&gt; IOMMU usually sits between system memory and master&#39;s device memory</span>
<span class="quote">&gt; interface, remapping addresses of each DMA transaction according to its</span>
<span class="quote">&gt; configuration and provided mapping tables (master device has some kind</span>
<span class="quote">&gt; of internal DMA controller and performs DMA transactions on their own).</span>
<span class="quote">&gt; IOMMU is usually used for a) mapping physically discontinuous memory into</span>
<span class="quote">&gt; contiguous DMA addresses and b) isolating devices, so they can access</span>
<span class="quote">&gt; only memory, which is dedicated or allocated for them.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; DMA engine devices provide explicit API for their master&#39;s device drivers,</span>
<span class="quote">&gt; while IOMMU drivers are usually hidden behind DMA-mapping API (for most</span>
<span class="quote">&gt; use cases, although it would be possible for master&#39;s device driver to</span>
<span class="quote">&gt; call IOMMU API directly and some GPU/DRM drivers do that).</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; However from runtime pm perspective the DMA engine and IOMMU devices are</span>
<span class="quote">&gt; a bit different.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; DMA engine drivers have well defined start and end of operation (queuing</span>
<span class="quote">&gt; dma request and irq from hw about having it finished). During that time</span>
<span class="quote">&gt; the device has to be runtime active all the time. The problem with using</span>
<span class="quote">&gt; current implementation of runtime pm is the fact that both start and end</span>
<span class="quote">&gt; of operation can be triggered from atomic context, what is not really</span>
<span class="quote">&gt; suitable for runtime pm. So the problem is mainly about API</span>
<span class="quote">&gt; incompatibility and lack of something like dma_engine_prepare()/unprepare()</span>
<span class="quote">&gt; (as an analogy to clocks api).</span>

That&#39;s also a viable option. Although, DMA clients would then need to
invoke such APIs from non-atomic contexts. Typically that would be
from client driver&#39;s runtime PM callbacks.

Me personally would rather avoid such solution, as it would sprinkle
lots of drivers to deal with this. Although, perhaps this is the only
option that actually works.
<span class="quote">
&gt;</span>
<span class="quote">&gt; In case of IOMMU the main problem is determining weather IOMMU controller</span>
<span class="quote">&gt; has to be activated. There is no calls in IOMMU and DMA-mapping API, which</span>
<span class="quote">&gt; would bracket all DMA transactions performed by the master device. Someone</span>
<span class="quote">&gt; proposed to keep IOMMU runtime active when there exist at least one</span>
<span class="quote">&gt; mapping created by the IOMMU/DMA-mapping layers. This however does not</span>
<span class="quote">&gt; cover all the cases. In case of our IOMMU, when it is disabled or runtime</span>
<span class="quote">&gt; suspended, it enters &quot;pass-thought&quot; mode, so master device can still</span>
<span class="quote">&gt; perform DMA operations with identity mappings (so DMA address equals to</span>
<span class="quote">&gt; physical memory address). Till now Exynos IOMMU called pm_runtime_get()</span>
<span class="quote">&gt; on attaching to the iommu domain (what happens during initialization of</span>
<span class="quote">&gt; dma-mapping structures for given master device) and kept it active all</span>
<span class="quote">&gt; the time.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; This patch series tries to address Exynos IOMMU runtime pm issue by forcing</span>
<span class="quote">&gt; IOMMU controller to follow runtime pm status of its master device. This way</span>
<span class="quote">&gt; we ensure that anytime when master&#39;s device is runtime activated, the iommu</span>
<span class="quote">&gt; will be also active and master device won&#39;t be able to bypass during its</span>
<span class="quote">&gt; DMA transactions mappings created by the IOMMU layer.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; Quite long answer, but I hope I managed to give you a bit more background</span>
<span class="quote">&gt; on this topic.</span>

Yes, indeed. Thank you for taking the time to respond!
<span class="quote">
&gt;</span>
<span class="quote">&gt;&gt; As we know, using the pm_runtime_irq_safe() option comes with some</span>
<span class="quote">&gt;&gt; limitations, such as the runtime PM callbacks is not allowed to sleep.</span>
<span class="quote">&gt;&gt; For a PM domain (genpd) that is attached to the device, this also</span>
<span class="quote">&gt;&gt; means it must not be powered off.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; Right, if possible I would like to avoid using pm_runtime_irq_safe()</span>
<span class="quote">&gt; option, because it is really impractical.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;&gt; To solve this problem, I was thinking we could convert to use the</span>
<span class="quote">&gt;&gt; asynchronous pm_runtime_get() API, when trying to runtime resume the</span>
<span class="quote">&gt;&gt; device from atomic contexts.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; I&#39;m not sure if this will work for DMA engine devices. If I understand</span>
<span class="quote">&gt; correctly some client&#39;s of DMA engine device might rely on the DMA</span>
<span class="quote">&gt; engine being configured and operational after queuing a request and</span>
<span class="quote">&gt; they might lock up if the DMA engine device activation if postponed</span>
<span class="quote">&gt; because of async runtime pm activation.</span>

I didn&#39;t know about this. If you have an example from the top of your
head, could you perhaps point me to it?

[...]

Kind regards
Uffe
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=2061">Marek Szyprowski</a> - Sept. 14, 2016, 10:50 a.m.</div>
<pre class="content">
Hi Ulf,


On 2016-09-14 12:28, Ulf Hansson wrote:
<span class="quote">&gt; [...]</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;&gt; There are some similarities between IOMMU and DMA engine devices (serial</span>
<span class="quote">&gt;&gt; drivers are imho completely different case). Both hw blocks do their work</span>
<span class="quote">&gt;&gt; on behalf of some other hardware block, which I will call master device.</span>
<span class="quote">&gt;&gt; DMA engine performs some DMA transaction on master&#39;s device request, while</span>
<span class="quote">&gt;&gt; IOMMU usually sits between system memory and master&#39;s device memory</span>
<span class="quote">&gt;&gt; interface, remapping addresses of each DMA transaction according to its</span>
<span class="quote">&gt;&gt; configuration and provided mapping tables (master device has some kind</span>
<span class="quote">&gt;&gt; of internal DMA controller and performs DMA transactions on their own).</span>
<span class="quote">&gt;&gt; IOMMU is usually used for a) mapping physically discontinuous memory into</span>
<span class="quote">&gt;&gt; contiguous DMA addresses and b) isolating devices, so they can access</span>
<span class="quote">&gt;&gt; only memory, which is dedicated or allocated for them.</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; DMA engine devices provide explicit API for their master&#39;s device drivers,</span>
<span class="quote">&gt;&gt; while IOMMU drivers are usually hidden behind DMA-mapping API (for most</span>
<span class="quote">&gt;&gt; use cases, although it would be possible for master&#39;s device driver to</span>
<span class="quote">&gt;&gt; call IOMMU API directly and some GPU/DRM drivers do that).</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; However from runtime pm perspective the DMA engine and IOMMU devices are</span>
<span class="quote">&gt;&gt; a bit different.</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; DMA engine drivers have well defined start and end of operation (queuing</span>
<span class="quote">&gt;&gt; dma request and irq from hw about having it finished). During that time</span>
<span class="quote">&gt;&gt; the device has to be runtime active all the time. The problem with using</span>
<span class="quote">&gt;&gt; current implementation of runtime pm is the fact that both start and end</span>
<span class="quote">&gt;&gt; of operation can be triggered from atomic context, what is not really</span>
<span class="quote">&gt;&gt; suitable for runtime pm. So the problem is mainly about API</span>
<span class="quote">&gt;&gt; incompatibility and lack of something like dma_engine_prepare()/unprepare()</span>
<span class="quote">&gt;&gt; (as an analogy to clocks api).</span>
<span class="quote">&gt; That&#39;s also a viable option. Although, DMA clients would then need to</span>
<span class="quote">&gt; invoke such APIs from non-atomic contexts. Typically that would be</span>
<span class="quote">&gt; from client driver&#39;s runtime PM callbacks.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; Me personally would rather avoid such solution, as it would sprinkle</span>
<span class="quote">&gt; lots of drivers to deal with this. Although, perhaps this is the only</span>
<span class="quote">&gt; option that actually works.</span>

One might also introduce optional functions and notify DMA engine core with
some flag that the client driver wants to use them or not. If not core will
prepare dma engine on initialization. This is not really nice from the API
clearness perspective, but it would allow to have some time for transition
to the new approach till all clients gets updated.
<span class="quote">
&gt;&gt; In case of IOMMU the main problem is determining weather IOMMU controller</span>
<span class="quote">&gt;&gt; has to be activated. There is no calls in IOMMU and DMA-mapping API, which</span>
<span class="quote">&gt;&gt; would bracket all DMA transactions performed by the master device. Someone</span>
<span class="quote">&gt;&gt; proposed to keep IOMMU runtime active when there exist at least one</span>
<span class="quote">&gt;&gt; mapping created by the IOMMU/DMA-mapping layers. This however does not</span>
<span class="quote">&gt;&gt; cover all the cases. In case of our IOMMU, when it is disabled or runtime</span>
<span class="quote">&gt;&gt; suspended, it enters &quot;pass-thought&quot; mode, so master device can still</span>
<span class="quote">&gt;&gt; perform DMA operations with identity mappings (so DMA address equals to</span>
<span class="quote">&gt;&gt; physical memory address). Till now Exynos IOMMU called pm_runtime_get()</span>
<span class="quote">&gt;&gt; on attaching to the iommu domain (what happens during initialization of</span>
<span class="quote">&gt;&gt; dma-mapping structures for given master device) and kept it active all</span>
<span class="quote">&gt;&gt; the time.</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; This patch series tries to address Exynos IOMMU runtime pm issue by forcing</span>
<span class="quote">&gt;&gt; IOMMU controller to follow runtime pm status of its master device. This way</span>
<span class="quote">&gt;&gt; we ensure that anytime when master&#39;s device is runtime activated, the iommu</span>
<span class="quote">&gt;&gt; will be also active and master device won&#39;t be able to bypass during its</span>
<span class="quote">&gt;&gt; DMA transactions mappings created by the IOMMU layer.</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; Quite long answer, but I hope I managed to give you a bit more background</span>
<span class="quote">&gt;&gt; on this topic.</span>
<span class="quote">&gt; Yes, indeed. Thank you for taking the time to respond!</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;&gt;&gt; As we know, using the pm_runtime_irq_safe() option comes with some</span>
<span class="quote">&gt;&gt;&gt; limitations, such as the runtime PM callbacks is not allowed to sleep.</span>
<span class="quote">&gt;&gt;&gt; For a PM domain (genpd) that is attached to the device, this also</span>
<span class="quote">&gt;&gt;&gt; means it must not be powered off.</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; Right, if possible I would like to avoid using pm_runtime_irq_safe()</span>
<span class="quote">&gt;&gt; option, because it is really impractical.</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt; To solve this problem, I was thinking we could convert to use the</span>
<span class="quote">&gt;&gt;&gt; asynchronous pm_runtime_get() API, when trying to runtime resume the</span>
<span class="quote">&gt;&gt;&gt; device from atomic contexts.</span>
<span class="quote">&gt;&gt; I&#39;m not sure if this will work for DMA engine devices. If I understand</span>
<span class="quote">&gt;&gt; correctly some client&#39;s of DMA engine device might rely on the DMA</span>
<span class="quote">&gt;&gt; engine being configured and operational after queuing a request and</span>
<span class="quote">&gt;&gt; they might lock up if the DMA engine device activation if postponed</span>
<span class="quote">&gt;&gt; because of async runtime pm activation.</span>
<span class="quote">&gt; I didn&#39;t know about this. If you have an example from the top of your</span>
<span class="quote">&gt; head, could you perhaps point me to it?</span>

No, I don&#39;t have any example. This is just my fear that there might be some
hardware which works this way. I can imagine a driver, which queue dma 
engine
request and then triggers &#39;start&#39; command to its hw block. HW blocks usually
uses some additional signal lines for DMA, so the HW block might check 
if all
needed signals from DMA engine HW are ready. If not it will fail to start
avoid lockup of starting without DMA engine HW being ready.

However I don&#39;t have much experience with DMA engine and drivers. I only
helped in adding DMA engine support to Samsung UART driver and in the
hardware manual there is information about additional lines between DMA
controller and UART module, which are used in the DMA mode.

Best regards
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=45281">Ulf Hansson</a> - Sept. 14, 2016, 11:54 a.m.</div>
<pre class="content">
[...]
<span class="quote">
&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt;&gt; To solve this problem, I was thinking we could convert to use the</span>
<span class="quote">&gt;&gt;&gt;&gt; asynchronous pm_runtime_get() API, when trying to runtime resume the</span>
<span class="quote">&gt;&gt;&gt;&gt; device from atomic contexts.</span>
<span class="quote">&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt; I&#39;m not sure if this will work for DMA engine devices. If I understand</span>
<span class="quote">&gt;&gt;&gt; correctly some client&#39;s of DMA engine device might rely on the DMA</span>
<span class="quote">&gt;&gt;&gt; engine being configured and operational after queuing a request and</span>
<span class="quote">&gt;&gt;&gt; they might lock up if the DMA engine device activation if postponed</span>
<span class="quote">&gt;&gt;&gt; because of async runtime pm activation.</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; I didn&#39;t know about this. If you have an example from the top of your</span>
<span class="quote">&gt;&gt; head, could you perhaps point me to it?</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; No, I don&#39;t have any example. This is just my fear that there might be some</span>
<span class="quote">&gt; hardware which works this way. I can imagine a driver, which queue dma</span>
<span class="quote">&gt; engine</span>
<span class="quote">&gt; request and then triggers &#39;start&#39; command to its hw block. HW blocks usually</span>
<span class="quote">&gt; uses some additional signal lines for DMA, so the HW block might check if</span>
<span class="quote">&gt; all</span>
<span class="quote">&gt; needed signals from DMA engine HW are ready. If not it will fail to start</span>
<span class="quote">&gt; avoid lockup of starting without DMA engine HW being ready.</span>

Well, I think this reasoning makes lots of sense! Clearly we wouldn&#39;t
be able to guarantee that there&#39;s isn&#39;t a glitch in an undefined HW
behaviour.

I will drop my suggested approach and try out another one.
<span class="quote">
&gt;</span>
<span class="quote">&gt; However I don&#39;t have much experience with DMA engine and drivers. I only</span>
<span class="quote">&gt; helped in adding DMA engine support to Samsung UART driver and in the</span>
<span class="quote">&gt; hardware manual there is information about additional lines between DMA</span>
<span class="quote">&gt; controller and UART module, which are used in the DMA mode.</span>

Thanks for sharing your experience!

Now, I should allow you to get back to the original review! :-)

Kind regards
Uffe
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/drivers/iommu/exynos-iommu.c b/drivers/iommu/exynos-iommu.c</span>
<span class="p_header">index b0fa4d432e71..34717a0b1902 100644</span>
<span class="p_header">--- a/drivers/iommu/exynos-iommu.c</span>
<span class="p_header">+++ b/drivers/iommu/exynos-iommu.c</span>
<span class="p_chunk">@@ -206,6 +206,7 @@</span> <span class="p_context"> static const struct sysmmu_fault_info sysmmu_v5_faults[] = {</span>
 struct exynos_iommu_owner {
 	struct list_head controllers;	/* list of sysmmu_drvdata.owner_node */
 	struct iommu_domain *domain;	/* domain this device is attached */
<span class="p_add">+	struct mutex rpm_lock;		/* for runtime pm of all sysmmus */</span>
 };
 
 /*
<span class="p_chunk">@@ -237,8 +238,8 @@</span> <span class="p_context"> struct sysmmu_drvdata {</span>
 	struct clk *aclk;		/* SYSMMU&#39;s aclk clock */
 	struct clk *pclk;		/* SYSMMU&#39;s pclk clock */
 	struct clk *clk_master;		/* master&#39;s device clock */
<span class="p_del">-	int activations;		/* number of calls to sysmmu_enable */</span>
 	spinlock_t lock;		/* lock for modyfying state */
<span class="p_add">+	int active;			/* current status */</span>
 	struct exynos_iommu_domain *domain; /* domain we belong to */
 	struct list_head domain_node;	/* node for domain clients list */
 	struct list_head owner_node;	/* node for owner controllers list */
<span class="p_chunk">@@ -251,25 +252,6 @@</span> <span class="p_context"> static struct exynos_iommu_domain *to_exynos_domain(struct iommu_domain *dom)</span>
 	return container_of(dom, struct exynos_iommu_domain, domain);
 }
 
<span class="p_del">-static bool set_sysmmu_active(struct sysmmu_drvdata *data)</span>
<span class="p_del">-{</span>
<span class="p_del">-	/* return true if the System MMU was not active previously</span>
<span class="p_del">-	   and it needs to be initialized */</span>
<span class="p_del">-	return ++data-&gt;activations == 1;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static bool set_sysmmu_inactive(struct sysmmu_drvdata *data)</span>
<span class="p_del">-{</span>
<span class="p_del">-	/* return true if the System MMU is needed to be disabled */</span>
<span class="p_del">-	BUG_ON(data-&gt;activations &lt; 1);</span>
<span class="p_del">-	return --data-&gt;activations == 0;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static bool is_sysmmu_active(struct sysmmu_drvdata *data)</span>
<span class="p_del">-{</span>
<span class="p_del">-	return data-&gt;activations &gt; 0;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
 static void sysmmu_unblock(struct sysmmu_drvdata *data)
 {
 	writel(CTRL_ENABLE, data-&gt;sfrbase + REG_MMU_CTRL);
<span class="p_chunk">@@ -389,7 +371,7 @@</span> <span class="p_context"> static irqreturn_t exynos_sysmmu_irq(int irq, void *dev_id)</span>
 	unsigned short reg_status, reg_clear;
 	int ret = -ENOSYS;
 
<span class="p_del">-	WARN_ON(!is_sysmmu_active(data));</span>
<span class="p_add">+	WARN_ON(!data-&gt;active);</span>
 
 	if (MMU_MAJ_VER(data-&gt;version) &lt; 5) {
 		reg_status = REG_INT_STATUS;
<span class="p_chunk">@@ -435,40 +417,19 @@</span> <span class="p_context"> static irqreturn_t exynos_sysmmu_irq(int irq, void *dev_id)</span>
 	return IRQ_HANDLED;
 }
 
<span class="p_del">-static void __sysmmu_disable_nocount(struct sysmmu_drvdata *data)</span>
<span class="p_add">+static void __sysmmu_disable(struct sysmmu_drvdata *data)</span>
 {
<span class="p_add">+	unsigned long flags;</span>
<span class="p_add">+</span>
 	clk_enable(data-&gt;clk_master);
 
<span class="p_add">+	spin_lock_irqsave(&amp;data-&gt;lock, flags);</span>
 	writel(CTRL_DISABLE, data-&gt;sfrbase + REG_MMU_CTRL);
 	writel(0, data-&gt;sfrbase + REG_MMU_CFG);
<span class="p_del">-</span>
<span class="p_del">-	__sysmmu_disable_clocks(data);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static bool __sysmmu_disable(struct sysmmu_drvdata *data)</span>
<span class="p_del">-{</span>
<span class="p_del">-	bool disabled;</span>
<span class="p_del">-	unsigned long flags;</span>
<span class="p_del">-</span>
<span class="p_del">-	spin_lock_irqsave(&amp;data-&gt;lock, flags);</span>
<span class="p_del">-</span>
<span class="p_del">-	disabled = set_sysmmu_inactive(data);</span>
<span class="p_del">-</span>
<span class="p_del">-	if (disabled) {</span>
<span class="p_del">-		data-&gt;pgtable = 0;</span>
<span class="p_del">-		data-&gt;domain = NULL;</span>
<span class="p_del">-</span>
<span class="p_del">-		__sysmmu_disable_nocount(data);</span>
<span class="p_del">-</span>
<span class="p_del">-		dev_dbg(data-&gt;sysmmu, &quot;Disabled\n&quot;);</span>
<span class="p_del">-	} else  {</span>
<span class="p_del">-		dev_dbg(data-&gt;sysmmu, &quot;%d times left to disable\n&quot;,</span>
<span class="p_del">-					data-&gt;activations);</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_add">+	data-&gt;active = false;</span>
 	spin_unlock_irqrestore(&amp;data-&gt;lock, flags);
 
<span class="p_del">-	return disabled;</span>
<span class="p_add">+	__sysmmu_disable_clocks(data);</span>
 }
 
 static void __sysmmu_init_config(struct sysmmu_drvdata *data)
<span class="p_chunk">@@ -485,17 +446,19 @@</span> <span class="p_context"> static void __sysmmu_init_config(struct sysmmu_drvdata *data)</span>
 	writel(cfg, data-&gt;sfrbase + REG_MMU_CFG);
 }
 
<span class="p_del">-static void __sysmmu_enable_nocount(struct sysmmu_drvdata *data)</span>
<span class="p_add">+static void __sysmmu_enable(struct sysmmu_drvdata *data)</span>
 {
<span class="p_add">+	unsigned long flags;</span>
<span class="p_add">+</span>
 	__sysmmu_enable_clocks(data);
 
<span class="p_add">+	spin_lock_irqsave(&amp;data-&gt;lock, flags);</span>
 	writel(CTRL_BLOCK, data-&gt;sfrbase + REG_MMU_CTRL);
<span class="p_del">-</span>
 	__sysmmu_init_config(data);
<span class="p_del">-</span>
 	__sysmmu_set_ptbase(data, data-&gt;pgtable);
<span class="p_del">-</span>
 	writel(CTRL_ENABLE, data-&gt;sfrbase + REG_MMU_CTRL);
<span class="p_add">+	data-&gt;active = true;</span>
<span class="p_add">+	spin_unlock_irqrestore(&amp;data-&gt;lock, flags);</span>
 
 	/*
 	 * SYSMMU driver keeps master&#39;s clock enabled only for the short
<span class="p_chunk">@@ -506,48 +469,18 @@</span> <span class="p_context"> static void __sysmmu_enable_nocount(struct sysmmu_drvdata *data)</span>
 	clk_disable(data-&gt;clk_master);
 }
 
<span class="p_del">-static int __sysmmu_enable(struct sysmmu_drvdata *data, phys_addr_t pgtable,</span>
<span class="p_del">-			   struct exynos_iommu_domain *domain)</span>
<span class="p_del">-{</span>
<span class="p_del">-	int ret = 0;</span>
<span class="p_del">-	unsigned long flags;</span>
<span class="p_del">-</span>
<span class="p_del">-	spin_lock_irqsave(&amp;data-&gt;lock, flags);</span>
<span class="p_del">-	if (set_sysmmu_active(data)) {</span>
<span class="p_del">-		data-&gt;pgtable = pgtable;</span>
<span class="p_del">-		data-&gt;domain = domain;</span>
<span class="p_del">-</span>
<span class="p_del">-		__sysmmu_enable_nocount(data);</span>
<span class="p_del">-</span>
<span class="p_del">-		dev_dbg(data-&gt;sysmmu, &quot;Enabled\n&quot;);</span>
<span class="p_del">-	} else {</span>
<span class="p_del">-		ret = (pgtable == data-&gt;pgtable) ? 1 : -EBUSY;</span>
<span class="p_del">-</span>
<span class="p_del">-		dev_dbg(data-&gt;sysmmu, &quot;already enabled\n&quot;);</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">-	if (WARN_ON(ret &lt; 0))</span>
<span class="p_del">-		set_sysmmu_inactive(data); /* decrement count */</span>
<span class="p_del">-</span>
<span class="p_del">-	spin_unlock_irqrestore(&amp;data-&gt;lock, flags);</span>
<span class="p_del">-</span>
<span class="p_del">-	return ret;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
 static void sysmmu_tlb_invalidate_flpdcache(struct sysmmu_drvdata *data,
 					    sysmmu_iova_t iova)
 {
 	unsigned long flags;
 
<span class="p_del">-</span>
 	spin_lock_irqsave(&amp;data-&gt;lock, flags);
<span class="p_del">-	if (is_sysmmu_active(data) &amp;&amp; data-&gt;version &gt;= MAKE_MMU_VER(3, 3)) {</span>
<span class="p_add">+	if (data-&gt;active &amp;&amp; data-&gt;version &gt;= MAKE_MMU_VER(3, 3)) {</span>
 		clk_enable(data-&gt;clk_master);
 		__sysmmu_tlb_invalidate_entry(data, iova, 1);
 		clk_disable(data-&gt;clk_master);
 	}
 	spin_unlock_irqrestore(&amp;data-&gt;lock, flags);
<span class="p_del">-</span>
 }
 
 static void sysmmu_tlb_invalidate_entry(struct sysmmu_drvdata *data,
<span class="p_chunk">@@ -556,7 +489,7 @@</span> <span class="p_context"> static void sysmmu_tlb_invalidate_entry(struct sysmmu_drvdata *data,</span>
 	unsigned long flags;
 
 	spin_lock_irqsave(&amp;data-&gt;lock, flags);
<span class="p_del">-	if (is_sysmmu_active(data)) {</span>
<span class="p_add">+	if (data-&gt;active) {</span>
 		unsigned int num_inv = 1;
 
 		clk_enable(data-&gt;clk_master);
<span class="p_chunk">@@ -657,40 +590,55 @@</span> <span class="p_context"> static int __init exynos_sysmmu_probe(struct platform_device *pdev)</span>
 	}
 
 	pm_runtime_enable(dev);
<span class="p_del">-</span>
 	of_iommu_set_ops(dev-&gt;of_node, &amp;exynos_iommu_ops);
 
 	return 0;
 }
 
<span class="p_del">-#ifdef CONFIG_PM_SLEEP</span>
 static int exynos_sysmmu_suspend(struct device *dev)
 {
 	struct sysmmu_drvdata *data = dev_get_drvdata(dev);
<span class="p_add">+	struct exynos_iommu_owner *owner;</span>
 
<span class="p_del">-	dev_dbg(dev, &quot;suspend\n&quot;);</span>
<span class="p_del">-	if (is_sysmmu_active(data)) {</span>
<span class="p_del">-		__sysmmu_disable_nocount(data);</span>
<span class="p_del">-		pm_runtime_put(dev);</span>
<span class="p_add">+	if (!data-&gt;master)</span>
<span class="p_add">+		return 0;</span>
<span class="p_add">+</span>
<span class="p_add">+	owner = data-&gt;master-&gt;archdata.iommu;</span>
<span class="p_add">+</span>
<span class="p_add">+	mutex_lock(&amp;owner-&gt;rpm_lock);</span>
<span class="p_add">+	if (data-&gt;domain) {</span>
<span class="p_add">+		dev_dbg(data-&gt;sysmmu, &quot;saving state\n&quot;);</span>
<span class="p_add">+		__sysmmu_disable(data);</span>
 	}
<span class="p_add">+	mutex_unlock(&amp;owner-&gt;rpm_lock);</span>
<span class="p_add">+</span>
 	return 0;
 }
 
 static int exynos_sysmmu_resume(struct device *dev)
 {
 	struct sysmmu_drvdata *data = dev_get_drvdata(dev);
<span class="p_add">+	struct exynos_iommu_owner *owner;</span>
 
<span class="p_del">-	dev_dbg(dev, &quot;resume\n&quot;);</span>
<span class="p_del">-	if (is_sysmmu_active(data)) {</span>
<span class="p_del">-		pm_runtime_get_sync(dev);</span>
<span class="p_del">-		__sysmmu_enable_nocount(data);</span>
<span class="p_add">+	if (!data-&gt;master)</span>
<span class="p_add">+		return 0;</span>
<span class="p_add">+</span>
<span class="p_add">+	owner = data-&gt;master-&gt;archdata.iommu;</span>
<span class="p_add">+</span>
<span class="p_add">+	mutex_lock(&amp;owner-&gt;rpm_lock);</span>
<span class="p_add">+	if (data-&gt;domain) {</span>
<span class="p_add">+		dev_dbg(data-&gt;sysmmu, &quot;restoring state\n&quot;);</span>
<span class="p_add">+		__sysmmu_enable(data);</span>
 	}
<span class="p_add">+	mutex_unlock(&amp;owner-&gt;rpm_lock);</span>
<span class="p_add">+</span>
 	return 0;
 }
<span class="p_del">-#endif</span>
 
 static const struct dev_pm_ops sysmmu_pm_ops = {
<span class="p_del">-	SET_LATE_SYSTEM_SLEEP_PM_OPS(exynos_sysmmu_suspend, exynos_sysmmu_resume)</span>
<span class="p_add">+	SET_RUNTIME_PM_OPS(exynos_sysmmu_suspend, exynos_sysmmu_resume, NULL)</span>
<span class="p_add">+	SET_LATE_SYSTEM_SLEEP_PM_OPS(pm_runtime_force_suspend,</span>
<span class="p_add">+				     pm_runtime_force_resume)</span>
 };
 
 static const struct of_device_id sysmmu_of_match[] __initconst = {
<span class="p_chunk">@@ -794,9 +742,12 @@</span> <span class="p_context"> static void exynos_iommu_domain_free(struct iommu_domain *iommu_domain)</span>
 	spin_lock_irqsave(&amp;domain-&gt;lock, flags);
 
 	list_for_each_entry_safe(data, next, &amp;domain-&gt;clients, domain_node) {
<span class="p_del">-		if (__sysmmu_disable(data))</span>
<span class="p_del">-			data-&gt;master = NULL;</span>
<span class="p_add">+		spin_lock(&amp;data-&gt;lock);</span>
<span class="p_add">+		__sysmmu_disable(data);</span>
<span class="p_add">+		data-&gt;pgtable = 0;</span>
<span class="p_add">+		data-&gt;domain = NULL;</span>
 		list_del_init(&amp;data-&gt;domain_node);
<span class="p_add">+		spin_unlock(&amp;data-&gt;lock);</span>
 	}
 
 	spin_unlock_irqrestore(&amp;domain-&gt;lock, flags);
<span class="p_chunk">@@ -830,31 +781,32 @@</span> <span class="p_context"> static void exynos_iommu_detach_device(struct iommu_domain *iommu_domain,</span>
 	phys_addr_t pagetable = virt_to_phys(domain-&gt;pgtable);
 	struct sysmmu_drvdata *data, *next;
 	unsigned long flags;
<span class="p_del">-	bool found = false;</span>
 
 	if (!has_sysmmu(dev) || owner-&gt;domain != iommu_domain)
 		return;
 
<span class="p_add">+	mutex_lock(&amp;owner-&gt;rpm_lock);</span>
<span class="p_add">+</span>
<span class="p_add">+	list_for_each_entry(data, &amp;owner-&gt;controllers, owner_node) {</span>
<span class="p_add">+		if (pm_runtime_active(data-&gt;sysmmu))</span>
<span class="p_add">+			__sysmmu_disable(data);</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
 	spin_lock_irqsave(&amp;domain-&gt;lock, flags);
 	list_for_each_entry_safe(data, next, &amp;domain-&gt;clients, domain_node) {
<span class="p_del">-		if (data-&gt;master == dev) {</span>
<span class="p_del">-			if (__sysmmu_disable(data)) {</span>
<span class="p_del">-				data-&gt;master = NULL;</span>
<span class="p_del">-				list_del_init(&amp;data-&gt;domain_node);</span>
<span class="p_del">-			}</span>
<span class="p_del">-			pm_runtime_put(data-&gt;sysmmu);</span>
<span class="p_del">-			found = true;</span>
<span class="p_del">-		}</span>
<span class="p_add">+		spin_lock(&amp;data-&gt;lock);</span>
<span class="p_add">+		data-&gt;pgtable = 0;</span>
<span class="p_add">+		data-&gt;domain = NULL;</span>
<span class="p_add">+		list_del_init(&amp;data-&gt;domain_node);</span>
<span class="p_add">+		spin_unlock(&amp;data-&gt;lock);</span>
 	}
<span class="p_add">+	owner-&gt;domain = NULL;</span>
 	spin_unlock_irqrestore(&amp;domain-&gt;lock, flags);
 
<span class="p_del">-	owner-&gt;domain = NULL;</span>
<span class="p_add">+	mutex_unlock(&amp;owner-&gt;rpm_lock);</span>
 
<span class="p_del">-	if (found)</span>
<span class="p_del">-		dev_dbg(dev, &quot;%s: Detached IOMMU with pgtable %pa\n&quot;,</span>
<span class="p_del">-					__func__, &amp;pagetable);</span>
<span class="p_del">-	else</span>
<span class="p_del">-		dev_err(dev, &quot;%s: No IOMMU is attached\n&quot;, __func__);</span>
<span class="p_add">+	dev_dbg(dev, &quot;%s: Detached IOMMU with pgtable %pa\n&quot;, __func__,</span>
<span class="p_add">+		&amp;pagetable);</span>
 }
 
 static int exynos_iommu_attach_device(struct iommu_domain *iommu_domain,
<span class="p_chunk">@@ -865,7 +817,6 @@</span> <span class="p_context"> static int exynos_iommu_attach_device(struct iommu_domain *iommu_domain,</span>
 	struct sysmmu_drvdata *data;
 	phys_addr_t pagetable = virt_to_phys(domain-&gt;pgtable);
 	unsigned long flags;
<span class="p_del">-	int ret = -ENODEV;</span>
 
 	if (!has_sysmmu(dev))
 		return -ENODEV;
<span class="p_chunk">@@ -873,29 +824,30 @@</span> <span class="p_context"> static int exynos_iommu_attach_device(struct iommu_domain *iommu_domain,</span>
 	if (owner-&gt;domain)
 		exynos_iommu_detach_device(owner-&gt;domain, dev);
 
<span class="p_add">+	mutex_lock(&amp;owner-&gt;rpm_lock);</span>
<span class="p_add">+</span>
<span class="p_add">+	spin_lock_irqsave(&amp;domain-&gt;lock, flags);</span>
 	list_for_each_entry(data, &amp;owner-&gt;controllers, owner_node) {
<span class="p_del">-		pm_runtime_get_sync(data-&gt;sysmmu);</span>
<span class="p_del">-		ret = __sysmmu_enable(data, pagetable, domain);</span>
<span class="p_del">-		if (ret &gt;= 0) {</span>
<span class="p_del">-			data-&gt;master = dev;</span>
<span class="p_del">-</span>
<span class="p_del">-			spin_lock_irqsave(&amp;domain-&gt;lock, flags);</span>
<span class="p_del">-			list_add_tail(&amp;data-&gt;domain_node, &amp;domain-&gt;clients);</span>
<span class="p_del">-			spin_unlock_irqrestore(&amp;domain-&gt;lock, flags);</span>
<span class="p_del">-		}</span>
<span class="p_add">+		spin_lock(&amp;data-&gt;lock);</span>
<span class="p_add">+		data-&gt;pgtable = pagetable;</span>
<span class="p_add">+		data-&gt;domain = domain;</span>
<span class="p_add">+		list_add_tail(&amp;data-&gt;domain_node, &amp;domain-&gt;clients);</span>
<span class="p_add">+		spin_unlock(&amp;data-&gt;lock);</span>
 	}
<span class="p_add">+	owner-&gt;domain = iommu_domain;</span>
<span class="p_add">+	spin_unlock_irqrestore(&amp;domain-&gt;lock, flags);</span>
 
<span class="p_del">-	if (ret &lt; 0) {</span>
<span class="p_del">-		dev_err(dev, &quot;%s: Failed to attach IOMMU with pgtable %pa\n&quot;,</span>
<span class="p_del">-					__func__, &amp;pagetable);</span>
<span class="p_del">-		return ret;</span>
<span class="p_add">+	list_for_each_entry(data, &amp;owner-&gt;controllers, owner_node) {</span>
<span class="p_add">+		if (pm_runtime_active(data-&gt;sysmmu))</span>
<span class="p_add">+			__sysmmu_enable(data);</span>
 	}
 
<span class="p_del">-	owner-&gt;domain = iommu_domain;</span>
<span class="p_del">-	dev_dbg(dev, &quot;%s: Attached IOMMU with pgtable %pa %s\n&quot;,</span>
<span class="p_del">-		__func__, &amp;pagetable, (ret == 0) ? &quot;&quot; : &quot;, again&quot;);</span>
<span class="p_add">+	mutex_unlock(&amp;owner-&gt;rpm_lock);</span>
 
<span class="p_del">-	return ret;</span>
<span class="p_add">+	dev_dbg(dev, &quot;%s: Attached IOMMU with pgtable %pa\n&quot;, __func__,</span>
<span class="p_add">+		&amp;pagetable);</span>
<span class="p_add">+</span>
<span class="p_add">+	return 0;</span>
 }
 
 static sysmmu_pte_t *alloc_lv2entry(struct exynos_iommu_domain *domain,
<span class="p_chunk">@@ -1266,10 +1218,21 @@</span> <span class="p_context"> static int exynos_iommu_of_xlate(struct device *dev,</span>
 			return -ENOMEM;
 
 		INIT_LIST_HEAD(&amp;owner-&gt;controllers);
<span class="p_add">+		mutex_init(&amp;owner-&gt;rpm_lock);</span>
 		dev-&gt;archdata.iommu = owner;
 	}
 
 	list_add_tail(&amp;data-&gt;owner_node, &amp;owner-&gt;controllers);
<span class="p_add">+	data-&gt;master = dev;</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * SYSMMU will be runtime enabled via device link (dependency) to its</span>
<span class="p_add">+	 * master device, so there are no direct calls to pm_runtime_get/put</span>
<span class="p_add">+	 * in this driver.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	device_link_add(dev, data-&gt;sysmmu, DEVICE_LINK_AVAILABLE,</span>
<span class="p_add">+			DEVICE_LINK_PERSISTENT | DEVICE_LINK_PM_RUNTIME);</span>
<span class="p_add">+</span>
 	return 0;
 }
 

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



