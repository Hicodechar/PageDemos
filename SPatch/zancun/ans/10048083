
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>Linux 4.13.12 - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    Linux 4.13.12</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=37061">gregkh@linuxfoundation.org</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>Nov. 8, 2017, 9:28 a.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;20171108092847.GB23630@kroah.com&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/10048083/mbox/"
   >mbox</a>
|
   <a href="/patch/10048083/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/10048083/">/patch/10048083/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
	[172.30.200.125])
	by pdx-korg-patchwork.web.codeaurora.org (Postfix) with ESMTP id
	D324F6032D for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Wed,  8 Nov 2017 09:29:26 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id C26D52A4E5
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Wed,  8 Nov 2017 09:29:26 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id B5C902A4F0; Wed,  8 Nov 2017 09:29:26 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-6.9 required=2.0 tests=BAYES_00,RCVD_IN_DNSWL_HI
	autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 445B82A4E5
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Wed,  8 Nov 2017 09:29:24 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1752044AbdKHJ3U (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Wed, 8 Nov 2017 04:29:20 -0500
Received: from mail.linuxfoundation.org ([140.211.169.12]:46930 &quot;EHLO
	mail.linuxfoundation.org&quot; rhost-flags-OK-OK-OK-OK) by vger.kernel.org
	with ESMTP id S1752009AbdKHJ2r (ORCPT
	&lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Wed, 8 Nov 2017 04:28:47 -0500
Received: from localhost (unknown [185.156.173.27])
	by mail.linuxfoundation.org (Postfix) with ESMTPSA id ACE50A7A;
	Wed,  8 Nov 2017 09:28:45 +0000 (UTC)
Date: Wed, 8 Nov 2017 10:28:47 +0100
From: Greg KH &lt;gregkh@linuxfoundation.org&gt;
To: linux-kernel@vger.kernel.org, Andrew Morton &lt;akpm@linux-foundation.org&gt;,
	torvalds@linux-foundation.org, stable@vger.kernel.org
Cc: lwn@lwn.net, Jiri Slaby &lt;jslaby@suse.cz&gt;
Subject: Re: Linux 4.13.12
Message-ID: &lt;20171108092847.GB23630@kroah.com&gt;
References: &lt;20171108092843.GA23630@kroah.com&gt;
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Disposition: inline
In-Reply-To: &lt;20171108092843.GA23630@kroah.com&gt;
User-Agent: Mutt/1.9.1 (2017-09-22)
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=37061">gregkh@linuxfoundation.org</a> - Nov. 8, 2017, 9:28 a.m.</div>
<pre class="content">

</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/Makefile b/Makefile</span>
<span class="p_header">index 8280953c8a45..a7c847f495b0 100644</span>
<span class="p_header">--- a/Makefile</span>
<span class="p_header">+++ b/Makefile</span>
<span class="p_chunk">@@ -1,6 +1,6 @@</span> <span class="p_context"></span>
 VERSION = 4
 PATCHLEVEL = 13
<span class="p_del">-SUBLEVEL = 11</span>
<span class="p_add">+SUBLEVEL = 12</span>
 EXTRAVERSION =
 NAME = Fearless Coyote
 
<span class="p_header">diff --git a/arch/arm/boot/dts/armada-375.dtsi b/arch/arm/boot/dts/armada-375.dtsi</span>
<span class="p_header">index 50c5e8417802..10b99530280a 100644</span>
<span class="p_header">--- a/arch/arm/boot/dts/armada-375.dtsi</span>
<span class="p_header">+++ b/arch/arm/boot/dts/armada-375.dtsi</span>
<span class="p_chunk">@@ -178,9 +178,9 @@</span> <span class="p_context"></span>
 				reg = &lt;0x8000 0x1000&gt;;
 				cache-unified;
 				cache-level = &lt;2&gt;;
<span class="p_del">-				arm,double-linefill-incr = &lt;1&gt;;</span>
<span class="p_add">+				arm,double-linefill-incr = &lt;0&gt;;</span>
 				arm,double-linefill-wrap = &lt;0&gt;;
<span class="p_del">-				arm,double-linefill = &lt;1&gt;;</span>
<span class="p_add">+				arm,double-linefill = &lt;0&gt;;</span>
 				prefetch-data = &lt;1&gt;;
 			};
 
<span class="p_header">diff --git a/arch/arm/boot/dts/armada-38x.dtsi b/arch/arm/boot/dts/armada-38x.dtsi</span>
<span class="p_header">index af31f5d6c0e5..c3448622e79e 100644</span>
<span class="p_header">--- a/arch/arm/boot/dts/armada-38x.dtsi</span>
<span class="p_header">+++ b/arch/arm/boot/dts/armada-38x.dtsi</span>
<span class="p_chunk">@@ -143,9 +143,9 @@</span> <span class="p_context"></span>
 				reg = &lt;0x8000 0x1000&gt;;
 				cache-unified;
 				cache-level = &lt;2&gt;;
<span class="p_del">-				arm,double-linefill-incr = &lt;1&gt;;</span>
<span class="p_add">+				arm,double-linefill-incr = &lt;0&gt;;</span>
 				arm,double-linefill-wrap = &lt;0&gt;;
<span class="p_del">-				arm,double-linefill = &lt;1&gt;;</span>
<span class="p_add">+				arm,double-linefill = &lt;0&gt;;</span>
 				prefetch-data = &lt;1&gt;;
 			};
 
<span class="p_header">diff --git a/arch/arm/boot/dts/armada-39x.dtsi b/arch/arm/boot/dts/armada-39x.dtsi</span>
<span class="p_header">index 60fbfd5907c7..55d02641d930 100644</span>
<span class="p_header">--- a/arch/arm/boot/dts/armada-39x.dtsi</span>
<span class="p_header">+++ b/arch/arm/boot/dts/armada-39x.dtsi</span>
<span class="p_chunk">@@ -111,9 +111,9 @@</span> <span class="p_context"></span>
 				reg = &lt;0x8000 0x1000&gt;;
 				cache-unified;
 				cache-level = &lt;2&gt;;
<span class="p_del">-				arm,double-linefill-incr = &lt;1&gt;;</span>
<span class="p_add">+				arm,double-linefill-incr = &lt;0&gt;;</span>
 				arm,double-linefill-wrap = &lt;0&gt;;
<span class="p_del">-				arm,double-linefill = &lt;1&gt;;</span>
<span class="p_add">+				arm,double-linefill = &lt;0&gt;;</span>
 				prefetch-data = &lt;1&gt;;
 			};
 
<span class="p_header">diff --git a/arch/arm/include/asm/Kbuild b/arch/arm/include/asm/Kbuild</span>
<span class="p_header">index 721ab5ecfb9b..0f2c8a2a8131 100644</span>
<span class="p_header">--- a/arch/arm/include/asm/Kbuild</span>
<span class="p_header">+++ b/arch/arm/include/asm/Kbuild</span>
<span class="p_chunk">@@ -20,7 +20,6 @@</span> <span class="p_context"> generic-y += simd.h</span>
 generic-y += sizes.h
 generic-y += timex.h
 generic-y += trace_clock.h
<span class="p_del">-generic-y += unaligned.h</span>
 
 generated-y += mach-types.h
 generated-y += unistd-nr.h
<span class="p_header">diff --git a/arch/arm/include/asm/unaligned.h b/arch/arm/include/asm/unaligned.h</span>
new file mode 100644
<span class="p_header">index 000000000000..ab905ffcf193</span>
<span class="p_header">--- /dev/null</span>
<span class="p_header">+++ b/arch/arm/include/asm/unaligned.h</span>
<span class="p_chunk">@@ -0,0 +1,27 @@</span> <span class="p_context"></span>
<span class="p_add">+#ifndef __ASM_ARM_UNALIGNED_H</span>
<span class="p_add">+#define __ASM_ARM_UNALIGNED_H</span>
<span class="p_add">+</span>
<span class="p_add">+/*</span>
<span class="p_add">+ * We generally want to set CONFIG_HAVE_EFFICIENT_UNALIGNED_ACCESS on ARMv6+,</span>
<span class="p_add">+ * but we don&#39;t want to use linux/unaligned/access_ok.h since that can lead</span>
<span class="p_add">+ * to traps on unaligned stm/ldm or strd/ldrd.</span>
<span class="p_add">+ */</span>
<span class="p_add">+#include &lt;asm/byteorder.h&gt;</span>
<span class="p_add">+</span>
<span class="p_add">+#if defined(__LITTLE_ENDIAN)</span>
<span class="p_add">+# include &lt;linux/unaligned/le_struct.h&gt;</span>
<span class="p_add">+# include &lt;linux/unaligned/be_byteshift.h&gt;</span>
<span class="p_add">+# include &lt;linux/unaligned/generic.h&gt;</span>
<span class="p_add">+# define get_unaligned	__get_unaligned_le</span>
<span class="p_add">+# define put_unaligned	__put_unaligned_le</span>
<span class="p_add">+#elif defined(__BIG_ENDIAN)</span>
<span class="p_add">+# include &lt;linux/unaligned/be_struct.h&gt;</span>
<span class="p_add">+# include &lt;linux/unaligned/le_byteshift.h&gt;</span>
<span class="p_add">+# include &lt;linux/unaligned/generic.h&gt;</span>
<span class="p_add">+# define get_unaligned	__get_unaligned_be</span>
<span class="p_add">+# define put_unaligned	__put_unaligned_be</span>
<span class="p_add">+#else</span>
<span class="p_add">+# error need to define endianess</span>
<span class="p_add">+#endif</span>
<span class="p_add">+</span>
<span class="p_add">+#endif /* __ASM_ARM_UNALIGNED_H */</span>
<span class="p_header">diff --git a/arch/arm/kvm/emulate.c b/arch/arm/kvm/emulate.c</span>
<span class="p_header">index 0064b86a2c87..30a13647c54c 100644</span>
<span class="p_header">--- a/arch/arm/kvm/emulate.c</span>
<span class="p_header">+++ b/arch/arm/kvm/emulate.c</span>
<span class="p_chunk">@@ -227,7 +227,7 @@</span> <span class="p_context"> void kvm_inject_undefined(struct kvm_vcpu *vcpu)</span>
 	u32 return_offset = (is_thumb) ? 2 : 4;
 
 	kvm_update_psr(vcpu, UND_MODE);
<span class="p_del">-	*vcpu_reg(vcpu, 14) = *vcpu_pc(vcpu) - return_offset;</span>
<span class="p_add">+	*vcpu_reg(vcpu, 14) = *vcpu_pc(vcpu) + return_offset;</span>
 
 	/* Branch to exception vector */
 	*vcpu_pc(vcpu) = exc_vector_base(vcpu) + vect_offset;
<span class="p_chunk">@@ -239,10 +239,8 @@</span> <span class="p_context"> void kvm_inject_undefined(struct kvm_vcpu *vcpu)</span>
  */
 static void inject_abt(struct kvm_vcpu *vcpu, bool is_pabt, unsigned long addr)
 {
<span class="p_del">-	unsigned long cpsr = *vcpu_cpsr(vcpu);</span>
<span class="p_del">-	bool is_thumb = (cpsr &amp; PSR_T_BIT);</span>
 	u32 vect_offset;
<span class="p_del">-	u32 return_offset = (is_thumb) ? 4 : 0;</span>
<span class="p_add">+	u32 return_offset = (is_pabt) ? 4 : 8;</span>
 	bool is_lpae;
 
 	kvm_update_psr(vcpu, ABT_MODE);
<span class="p_header">diff --git a/arch/arm/kvm/hyp/Makefile b/arch/arm/kvm/hyp/Makefile</span>
<span class="p_header">index 8679405b0b2b..92eab1d51785 100644</span>
<span class="p_header">--- a/arch/arm/kvm/hyp/Makefile</span>
<span class="p_header">+++ b/arch/arm/kvm/hyp/Makefile</span>
<span class="p_chunk">@@ -2,7 +2,7 @@</span> <span class="p_context"></span>
 # Makefile for Kernel-based Virtual Machine module, HYP part
 #
 
<span class="p_del">-ccflags-y += -fno-stack-protector</span>
<span class="p_add">+ccflags-y += -fno-stack-protector -DDISABLE_BRANCH_PROFILING</span>
 
 KVM=../../../../virt/kvm
 
<span class="p_header">diff --git a/arch/arm64/kernel/traps.c b/arch/arm64/kernel/traps.c</span>
<span class="p_header">index 8a62648848e5..c99ffd8dce27 100644</span>
<span class="p_header">--- a/arch/arm64/kernel/traps.c</span>
<span class="p_header">+++ b/arch/arm64/kernel/traps.c</span>
<span class="p_chunk">@@ -116,7 +116,7 @@</span> <span class="p_context"> static void __dump_instr(const char *lvl, struct pt_regs *regs)</span>
 	for (i = -4; i &lt; 1; i++) {
 		unsigned int val, bad;
 
<span class="p_del">-		bad = __get_user(val, &amp;((u32 *)addr)[i]);</span>
<span class="p_add">+		bad = get_user(val, &amp;((u32 *)addr)[i]);</span>
 
 		if (!bad)
 			p += sprintf(p, i == 0 ? &quot;(%08x) &quot; : &quot;%08x &quot;, val);
<span class="p_header">diff --git a/arch/arm64/kvm/hyp/Makefile b/arch/arm64/kvm/hyp/Makefile</span>
<span class="p_header">index 14c4e3b14bcb..48b03547a969 100644</span>
<span class="p_header">--- a/arch/arm64/kvm/hyp/Makefile</span>
<span class="p_header">+++ b/arch/arm64/kvm/hyp/Makefile</span>
<span class="p_chunk">@@ -2,7 +2,7 @@</span> <span class="p_context"></span>
 # Makefile for Kernel-based Virtual Machine module, HYP part
 #
 
<span class="p_del">-ccflags-y += -fno-stack-protector</span>
<span class="p_add">+ccflags-y += -fno-stack-protector -DDISABLE_BRANCH_PROFILING</span>
 
 KVM=../../../../virt/kvm
 
<span class="p_header">diff --git a/arch/arm64/kvm/inject_fault.c b/arch/arm64/kvm/inject_fault.c</span>
<span class="p_header">index da6a8cfa54a0..3556715a774e 100644</span>
<span class="p_header">--- a/arch/arm64/kvm/inject_fault.c</span>
<span class="p_header">+++ b/arch/arm64/kvm/inject_fault.c</span>
<span class="p_chunk">@@ -33,12 +33,26 @@</span> <span class="p_context"></span>
 #define LOWER_EL_AArch64_VECTOR		0x400
 #define LOWER_EL_AArch32_VECTOR		0x600
 
<span class="p_add">+/*</span>
<span class="p_add">+ * Table taken from ARMv8 ARM DDI0487B-B, table G1-10.</span>
<span class="p_add">+ */</span>
<span class="p_add">+static const u8 return_offsets[8][2] = {</span>
<span class="p_add">+	[0] = { 0, 0 },		/* Reset, unused */</span>
<span class="p_add">+	[1] = { 4, 2 },		/* Undefined */</span>
<span class="p_add">+	[2] = { 0, 0 },		/* SVC, unused */</span>
<span class="p_add">+	[3] = { 4, 4 },		/* Prefetch abort */</span>
<span class="p_add">+	[4] = { 8, 8 },		/* Data abort */</span>
<span class="p_add">+	[5] = { 0, 0 },		/* HVC, unused */</span>
<span class="p_add">+	[6] = { 4, 4 },		/* IRQ, unused */</span>
<span class="p_add">+	[7] = { 4, 4 },		/* FIQ, unused */</span>
<span class="p_add">+};</span>
<span class="p_add">+</span>
 static void prepare_fault32(struct kvm_vcpu *vcpu, u32 mode, u32 vect_offset)
 {
 	unsigned long cpsr;
 	unsigned long new_spsr_value = *vcpu_cpsr(vcpu);
 	bool is_thumb = (new_spsr_value &amp; COMPAT_PSR_T_BIT);
<span class="p_del">-	u32 return_offset = (is_thumb) ? 4 : 0;</span>
<span class="p_add">+	u32 return_offset = return_offsets[vect_offset &gt;&gt; 2][is_thumb];</span>
 	u32 sctlr = vcpu_cp15(vcpu, c1_SCTLR);
 
 	cpsr = mode | COMPAT_PSR_I_BIT;
<span class="p_header">diff --git a/arch/mips/kernel/smp-cmp.c b/arch/mips/kernel/smp-cmp.c</span>
<span class="p_header">index 76923349b4fe..797da807916f 100644</span>
<span class="p_header">--- a/arch/mips/kernel/smp-cmp.c</span>
<span class="p_header">+++ b/arch/mips/kernel/smp-cmp.c</span>
<span class="p_chunk">@@ -19,7 +19,7 @@</span> <span class="p_context"></span>
 #undef DEBUG
 
 #include &lt;linux/kernel.h&gt;
<span class="p_del">-#include &lt;linux/sched.h&gt;</span>
<span class="p_add">+#include &lt;linux/sched/task_stack.h&gt;</span>
 #include &lt;linux/smp.h&gt;
 #include &lt;linux/cpumask.h&gt;
 #include &lt;linux/interrupt.h&gt;
<span class="p_header">diff --git a/arch/mips/kernel/smp.c b/arch/mips/kernel/smp.c</span>
<span class="p_header">index 6bace7695788..20d7bc5f0eb5 100644</span>
<span class="p_header">--- a/arch/mips/kernel/smp.c</span>
<span class="p_header">+++ b/arch/mips/kernel/smp.c</span>
<span class="p_chunk">@@ -66,6 +66,7 @@</span> <span class="p_context"> EXPORT_SYMBOL(cpu_sibling_map);</span>
 cpumask_t cpu_core_map[NR_CPUS] __read_mostly;
 EXPORT_SYMBOL(cpu_core_map);
 
<span class="p_add">+static DECLARE_COMPLETION(cpu_starting);</span>
 static DECLARE_COMPLETION(cpu_running);
 
 /*
<span class="p_chunk">@@ -376,6 +377,12 @@</span> <span class="p_context"> asmlinkage void start_secondary(void)</span>
 	cpumask_set_cpu(cpu, &amp;cpu_coherent_mask);
 	notify_cpu_starting(cpu);
 
<span class="p_add">+	/* Notify boot CPU that we&#39;re starting &amp; ready to sync counters */</span>
<span class="p_add">+	complete(&amp;cpu_starting);</span>
<span class="p_add">+</span>
<span class="p_add">+	synchronise_count_slave(cpu);</span>
<span class="p_add">+</span>
<span class="p_add">+	/* The CPU is running and counters synchronised, now mark it online */</span>
 	set_cpu_online(cpu, true);
 
 	set_cpu_sibling_map(cpu);
<span class="p_chunk">@@ -383,8 +390,11 @@</span> <span class="p_context"> asmlinkage void start_secondary(void)</span>
 
 	calculate_cpu_foreign_map();
 
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Notify boot CPU that we&#39;re up &amp; online and it can safely return</span>
<span class="p_add">+	 * from __cpu_up</span>
<span class="p_add">+	 */</span>
 	complete(&amp;cpu_running);
<span class="p_del">-	synchronise_count_slave(cpu);</span>
 
 	/*
 	 * irq will be enabled in -&gt;smp_finish(), enabling it too early
<span class="p_chunk">@@ -443,17 +453,17 @@</span> <span class="p_context"> int __cpu_up(unsigned int cpu, struct task_struct *tidle)</span>
 {
 	mp_ops-&gt;boot_secondary(cpu, tidle);
 
<span class="p_del">-	/*</span>
<span class="p_del">-	 * We must check for timeout here, as the CPU will not be marked</span>
<span class="p_del">-	 * online until the counters are synchronised.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	if (!wait_for_completion_timeout(&amp;cpu_running,</span>
<span class="p_add">+	/* Wait for CPU to start and be ready to sync counters */</span>
<span class="p_add">+	if (!wait_for_completion_timeout(&amp;cpu_starting,</span>
 					 msecs_to_jiffies(1000))) {
 		pr_crit(&quot;CPU%u: failed to start\n&quot;, cpu);
 		return -EIO;
 	}
 
 	synchronise_count_master(cpu);
<span class="p_add">+</span>
<span class="p_add">+	/* Wait for CPU to finish startup &amp; mark itself online before return */</span>
<span class="p_add">+	wait_for_completion(&amp;cpu_running);</span>
 	return 0;
 }
 
<span class="p_header">diff --git a/arch/mips/mm/uasm-micromips.c b/arch/mips/mm/uasm-micromips.c</span>
<span class="p_header">index c28ff53c8da0..cdb5a191b9d5 100644</span>
<span class="p_header">--- a/arch/mips/mm/uasm-micromips.c</span>
<span class="p_header">+++ b/arch/mips/mm/uasm-micromips.c</span>
<span class="p_chunk">@@ -80,7 +80,7 @@</span> <span class="p_context"> static const struct insn const insn_table_MM[insn_invalid] = {</span>
 	[insn_jr]	= {M(mm_pool32a_op, 0, 0, 0, mm_jalr_op, mm_pool32axf_op), RS},
 	[insn_lb]	= {M(mm_lb32_op, 0, 0, 0, 0, 0), RT | RS | SIMM},
 	[insn_ld]	= {0, 0},
<span class="p_del">-	[insn_lh]	= {M(mm_lh32_op, 0, 0, 0, 0, 0), RS | RS | SIMM},</span>
<span class="p_add">+	[insn_lh]	= {M(mm_lh32_op, 0, 0, 0, 0, 0), RT | RS | SIMM},</span>
 	[insn_ll]	= {M(mm_pool32c_op, 0, 0, (mm_ll_func &lt;&lt; 1), 0, 0), RS | RT | SIMM},
 	[insn_lld]	= {0, 0},
 	[insn_lui]	= {M(mm_pool32i_op, mm_lui_op, 0, 0, 0, 0), RS | SIMM},
<span class="p_header">diff --git a/arch/mips/net/ebpf_jit.c b/arch/mips/net/ebpf_jit.c</span>
<span class="p_header">index 401776f92288..e45f05cc510d 100644</span>
<span class="p_header">--- a/arch/mips/net/ebpf_jit.c</span>
<span class="p_header">+++ b/arch/mips/net/ebpf_jit.c</span>
<span class="p_chunk">@@ -1485,7 +1485,7 @@</span> <span class="p_context"> static int build_one_insn(const struct bpf_insn *insn, struct jit_ctx *ctx,</span>
 		}
 		src = ebpf_to_mips_reg(ctx, insn, src_reg_no_fp);
 		if (src &lt; 0)
<span class="p_del">-			return dst;</span>
<span class="p_add">+			return src;</span>
 		if (BPF_MODE(insn-&gt;code) == BPF_XADD) {
 			switch (BPF_SIZE(insn-&gt;code)) {
 			case BPF_W:
<span class="p_header">diff --git a/arch/powerpc/include/asm/code-patching.h b/arch/powerpc/include/asm/code-patching.h</span>
<span class="p_header">index 5482928eea1b..abef812de7f8 100644</span>
<span class="p_header">--- a/arch/powerpc/include/asm/code-patching.h</span>
<span class="p_header">+++ b/arch/powerpc/include/asm/code-patching.h</span>
<span class="p_chunk">@@ -83,16 +83,8 @@</span> <span class="p_context"> static inline unsigned long ppc_function_entry(void *func)</span>
 	 * On PPC64 ABIv1 the function pointer actually points to the
 	 * function&#39;s descriptor. The first entry in the descriptor is the
 	 * address of the function text.
<span class="p_del">-	 *</span>
<span class="p_del">-	 * However, we may also receive pointer to an assembly symbol. To</span>
<span class="p_del">-	 * detect that, we first check if the function pointer we receive</span>
<span class="p_del">-	 * already points to kernel/module text and we only dereference it</span>
<span class="p_del">-	 * if it doesn&#39;t.</span>
 	 */
<span class="p_del">-	if (kernel_text_address((unsigned long)func))</span>
<span class="p_del">-		return (unsigned long)func;</span>
<span class="p_del">-	else</span>
<span class="p_del">-		return ((func_descr_t *)func)-&gt;entry;</span>
<span class="p_add">+	return ((func_descr_t *)func)-&gt;entry;</span>
 #else
 	return (unsigned long)func;
 #endif
<span class="p_header">diff --git a/arch/powerpc/kernel/kprobes.c b/arch/powerpc/kernel/kprobes.c</span>
<span class="p_header">index 367494dc67d9..bebc3007a793 100644</span>
<span class="p_header">--- a/arch/powerpc/kernel/kprobes.c</span>
<span class="p_header">+++ b/arch/powerpc/kernel/kprobes.c</span>
<span class="p_chunk">@@ -600,7 +600,12 @@</span> <span class="p_context"> NOKPROBE_SYMBOL(kprobe_fault_handler);</span>
 
 unsigned long arch_deref_entry_point(void *entry)
 {
<span class="p_del">-	return ppc_global_function_entry(entry);</span>
<span class="p_add">+#ifdef PPC64_ELF_ABI_v1</span>
<span class="p_add">+	if (!kernel_text_address((unsigned long)entry))</span>
<span class="p_add">+		return ppc_global_function_entry(entry);</span>
<span class="p_add">+	else</span>
<span class="p_add">+#endif</span>
<span class="p_add">+		return (unsigned long)entry;</span>
 }
 NOKPROBE_SYMBOL(arch_deref_entry_point);
 
<span class="p_header">diff --git a/arch/x86/kernel/cpu/Makefile b/arch/x86/kernel/cpu/Makefile</span>
<span class="p_header">index cdf82492b770..836877e2da22 100644</span>
<span class="p_header">--- a/arch/x86/kernel/cpu/Makefile</span>
<span class="p_header">+++ b/arch/x86/kernel/cpu/Makefile</span>
<span class="p_chunk">@@ -21,7 +21,7 @@</span> <span class="p_context"> obj-y			+= common.o</span>
 obj-y			+= rdrand.o
 obj-y			+= match.o
 obj-y			+= bugs.o
<span class="p_del">-obj-$(CONFIG_CPU_FREQ)	+= aperfmperf.o</span>
<span class="p_add">+obj-y			+= aperfmperf.o</span>
 
 obj-$(CONFIG_PROC_FS)	+= proc.o
 obj-$(CONFIG_X86_FEATURE_NAMES) += capflags.o powerflags.o
<span class="p_header">diff --git a/arch/x86/kernel/cpu/aperfmperf.c b/arch/x86/kernel/cpu/aperfmperf.c</span>
<span class="p_header">index 0ee83321a313..957813e0180d 100644</span>
<span class="p_header">--- a/arch/x86/kernel/cpu/aperfmperf.c</span>
<span class="p_header">+++ b/arch/x86/kernel/cpu/aperfmperf.c</span>
<span class="p_chunk">@@ -42,10 +42,6 @@</span> <span class="p_context"> static void aperfmperf_snapshot_khz(void *dummy)</span>
 	s64 time_delta = ktime_ms_delta(now, s-&gt;time);
 	unsigned long flags;
 
<span class="p_del">-	/* Don&#39;t bother re-computing within the cache threshold time. */</span>
<span class="p_del">-	if (time_delta &lt; APERFMPERF_CACHE_THRESHOLD_MS)</span>
<span class="p_del">-		return;</span>
<span class="p_del">-</span>
 	local_irq_save(flags);
 	rdmsrl(MSR_IA32_APERF, aperf);
 	rdmsrl(MSR_IA32_MPERF, mperf);
<span class="p_chunk">@@ -74,6 +70,7 @@</span> <span class="p_context"> static void aperfmperf_snapshot_khz(void *dummy)</span>
 
 unsigned int arch_freq_get_on_cpu(int cpu)
 {
<span class="p_add">+	s64 time_delta;</span>
 	unsigned int khz;
 
 	if (!cpu_khz)
<span class="p_chunk">@@ -82,6 +79,12 @@</span> <span class="p_context"> unsigned int arch_freq_get_on_cpu(int cpu)</span>
 	if (!static_cpu_has(X86_FEATURE_APERFMPERF))
 		return 0;
 
<span class="p_add">+	/* Don&#39;t bother re-computing within the cache threshold time. */</span>
<span class="p_add">+	time_delta = ktime_ms_delta(ktime_get(), per_cpu(samples.time, cpu));</span>
<span class="p_add">+	khz = per_cpu(samples.khz, cpu);</span>
<span class="p_add">+	if (khz &amp;&amp; time_delta &lt; APERFMPERF_CACHE_THRESHOLD_MS)</span>
<span class="p_add">+		return khz;</span>
<span class="p_add">+</span>
 	smp_call_function_single(cpu, aperfmperf_snapshot_khz, NULL, 1);
 	khz = per_cpu(samples.khz, cpu);
 	if (khz)
<span class="p_header">diff --git a/arch/x86/kernel/cpu/mcheck/dev-mcelog.c b/arch/x86/kernel/cpu/mcheck/dev-mcelog.c</span>
<span class="p_header">index 10cec43aac38..7f85b76f43bc 100644</span>
<span class="p_header">--- a/arch/x86/kernel/cpu/mcheck/dev-mcelog.c</span>
<span class="p_header">+++ b/arch/x86/kernel/cpu/mcheck/dev-mcelog.c</span>
<span class="p_chunk">@@ -24,14 +24,6 @@</span> <span class="p_context"> static DEFINE_MUTEX(mce_chrdev_read_mutex);</span>
 static char mce_helper[128];
 static char *mce_helper_argv[2] = { mce_helper, NULL };
 
<span class="p_del">-#define mce_log_get_idx_check(p) \</span>
<span class="p_del">-({ \</span>
<span class="p_del">-	RCU_LOCKDEP_WARN(!rcu_read_lock_sched_held() &amp;&amp; \</span>
<span class="p_del">-			 !lockdep_is_held(&amp;mce_chrdev_read_mutex), \</span>
<span class="p_del">-			 &quot;suspicious mce_log_get_idx_check() usage&quot;); \</span>
<span class="p_del">-	smp_load_acquire(&amp;(p)); \</span>
<span class="p_del">-})</span>
<span class="p_del">-</span>
 /*
  * Lockless MCE logging infrastructure.
  * This avoids deadlocks on printk locks without having to break locks. Also
<span class="p_chunk">@@ -53,43 +45,32 @@</span> <span class="p_context"> static int dev_mce_log(struct notifier_block *nb, unsigned long val,</span>
 				void *data)
 {
 	struct mce *mce = (struct mce *)data;
<span class="p_del">-	unsigned int next, entry;</span>
<span class="p_del">-</span>
<span class="p_del">-	wmb();</span>
<span class="p_del">-	for (;;) {</span>
<span class="p_del">-		entry = mce_log_get_idx_check(mcelog.next);</span>
<span class="p_del">-		for (;;) {</span>
<span class="p_del">-</span>
<span class="p_del">-			/*</span>
<span class="p_del">-			 * When the buffer fills up discard new entries.</span>
<span class="p_del">-			 * Assume that the earlier errors are the more</span>
<span class="p_del">-			 * interesting ones:</span>
<span class="p_del">-			 */</span>
<span class="p_del">-			if (entry &gt;= MCE_LOG_LEN) {</span>
<span class="p_del">-				set_bit(MCE_OVERFLOW,</span>
<span class="p_del">-					(unsigned long *)&amp;mcelog.flags);</span>
<span class="p_del">-				return NOTIFY_OK;</span>
<span class="p_del">-			}</span>
<span class="p_del">-			/* Old left over entry. Skip: */</span>
<span class="p_del">-			if (mcelog.entry[entry].finished) {</span>
<span class="p_del">-				entry++;</span>
<span class="p_del">-				continue;</span>
<span class="p_del">-			}</span>
<span class="p_del">-			break;</span>
<span class="p_del">-		}</span>
<span class="p_del">-		smp_rmb();</span>
<span class="p_del">-		next = entry + 1;</span>
<span class="p_del">-		if (cmpxchg(&amp;mcelog.next, entry, next) == entry)</span>
<span class="p_del">-			break;</span>
<span class="p_add">+	unsigned int entry;</span>
<span class="p_add">+</span>
<span class="p_add">+	mutex_lock(&amp;mce_chrdev_read_mutex);</span>
<span class="p_add">+</span>
<span class="p_add">+	entry = mcelog.next;</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * When the buffer fills up discard new entries. Assume that the</span>
<span class="p_add">+	 * earlier errors are the more interesting ones:</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	if (entry &gt;= MCE_LOG_LEN) {</span>
<span class="p_add">+		set_bit(MCE_OVERFLOW, (unsigned long *)&amp;mcelog.flags);</span>
<span class="p_add">+		goto unlock;</span>
 	}
<span class="p_add">+</span>
<span class="p_add">+	mcelog.next = entry + 1;</span>
<span class="p_add">+</span>
 	memcpy(mcelog.entry + entry, mce, sizeof(struct mce));
<span class="p_del">-	wmb();</span>
 	mcelog.entry[entry].finished = 1;
<span class="p_del">-	wmb();</span>
 
 	/* wake processes polling /dev/mcelog */
 	wake_up_interruptible(&amp;mce_chrdev_wait);
 
<span class="p_add">+unlock:</span>
<span class="p_add">+	mutex_unlock(&amp;mce_chrdev_read_mutex);</span>
<span class="p_add">+</span>
 	return NOTIFY_OK;
 }
 
<span class="p_chunk">@@ -177,13 +158,6 @@</span> <span class="p_context"> static int mce_chrdev_release(struct inode *inode, struct file *file)</span>
 	return 0;
 }
 
<span class="p_del">-static void collect_tscs(void *data)</span>
<span class="p_del">-{</span>
<span class="p_del">-	unsigned long *cpu_tsc = (unsigned long *)data;</span>
<span class="p_del">-</span>
<span class="p_del">-	cpu_tsc[smp_processor_id()] = rdtsc();</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
 static int mce_apei_read_done;
 
 /* Collect MCE record of previous boot in persistent storage via APEI ERST. */
<span class="p_chunk">@@ -231,14 +205,9 @@</span> <span class="p_context"> static ssize_t mce_chrdev_read(struct file *filp, char __user *ubuf,</span>
 				size_t usize, loff_t *off)
 {
 	char __user *buf = ubuf;
<span class="p_del">-	unsigned long *cpu_tsc;</span>
<span class="p_del">-	unsigned prev, next;</span>
<span class="p_add">+	unsigned next;</span>
 	int i, err;
 
<span class="p_del">-	cpu_tsc = kmalloc(nr_cpu_ids * sizeof(long), GFP_KERNEL);</span>
<span class="p_del">-	if (!cpu_tsc)</span>
<span class="p_del">-		return -ENOMEM;</span>
<span class="p_del">-</span>
 	mutex_lock(&amp;mce_chrdev_read_mutex);
 
 	if (!mce_apei_read_done) {
<span class="p_chunk">@@ -247,65 +216,29 @@</span> <span class="p_context"> static ssize_t mce_chrdev_read(struct file *filp, char __user *ubuf,</span>
 			goto out;
 	}
 
<span class="p_del">-	next = mce_log_get_idx_check(mcelog.next);</span>
<span class="p_del">-</span>
 	/* Only supports full reads right now */
 	err = -EINVAL;
 	if (*off != 0 || usize &lt; MCE_LOG_LEN*sizeof(struct mce))
 		goto out;
 
<span class="p_add">+	next = mcelog.next;</span>
 	err = 0;
<span class="p_del">-	prev = 0;</span>
<span class="p_del">-	do {</span>
<span class="p_del">-		for (i = prev; i &lt; next; i++) {</span>
<span class="p_del">-			unsigned long start = jiffies;</span>
<span class="p_del">-			struct mce *m = &amp;mcelog.entry[i];</span>
<span class="p_del">-</span>
<span class="p_del">-			while (!m-&gt;finished) {</span>
<span class="p_del">-				if (time_after_eq(jiffies, start + 2)) {</span>
<span class="p_del">-					memset(m, 0, sizeof(*m));</span>
<span class="p_del">-					goto timeout;</span>
<span class="p_del">-				}</span>
<span class="p_del">-				cpu_relax();</span>
<span class="p_del">-			}</span>
<span class="p_del">-			smp_rmb();</span>
<span class="p_del">-			err |= copy_to_user(buf, m, sizeof(*m));</span>
<span class="p_del">-			buf += sizeof(*m);</span>
<span class="p_del">-timeout:</span>
<span class="p_del">-			;</span>
<span class="p_del">-		}</span>
<span class="p_del">-</span>
<span class="p_del">-		memset(mcelog.entry + prev, 0,</span>
<span class="p_del">-		       (next - prev) * sizeof(struct mce));</span>
<span class="p_del">-		prev = next;</span>
<span class="p_del">-		next = cmpxchg(&amp;mcelog.next, prev, 0);</span>
<span class="p_del">-	} while (next != prev);</span>
<span class="p_del">-</span>
<span class="p_del">-	synchronize_sched();</span>
 
<span class="p_del">-	/*</span>
<span class="p_del">-	 * Collect entries that were still getting written before the</span>
<span class="p_del">-	 * synchronize.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	on_each_cpu(collect_tscs, cpu_tsc, 1);</span>
<span class="p_del">-</span>
<span class="p_del">-	for (i = next; i &lt; MCE_LOG_LEN; i++) {</span>
<span class="p_add">+	for (i = 0; i &lt; next; i++) {</span>
 		struct mce *m = &amp;mcelog.entry[i];
 
<span class="p_del">-		if (m-&gt;finished &amp;&amp; m-&gt;tsc &lt; cpu_tsc[m-&gt;cpu]) {</span>
<span class="p_del">-			err |= copy_to_user(buf, m, sizeof(*m));</span>
<span class="p_del">-			smp_rmb();</span>
<span class="p_del">-			buf += sizeof(*m);</span>
<span class="p_del">-			memset(m, 0, sizeof(*m));</span>
<span class="p_del">-		}</span>
<span class="p_add">+		err |= copy_to_user(buf, m, sizeof(*m));</span>
<span class="p_add">+		buf += sizeof(*m);</span>
 	}
 
<span class="p_add">+	memset(mcelog.entry, 0, next * sizeof(struct mce));</span>
<span class="p_add">+	mcelog.next = 0;</span>
<span class="p_add">+</span>
 	if (err)
 		err = -EFAULT;
 
 out:
 	mutex_unlock(&amp;mce_chrdev_read_mutex);
<span class="p_del">-	kfree(cpu_tsc);</span>
 
 	return err ? err : buf - ubuf;
 }
<span class="p_header">diff --git a/arch/x86/kernel/cpu/proc.c b/arch/x86/kernel/cpu/proc.c</span>
<span class="p_header">index 218f79825b3c..510e69596278 100644</span>
<span class="p_header">--- a/arch/x86/kernel/cpu/proc.c</span>
<span class="p_header">+++ b/arch/x86/kernel/cpu/proc.c</span>
<span class="p_chunk">@@ -2,6 +2,7 @@</span> <span class="p_context"></span>
 #include &lt;linux/timex.h&gt;
 #include &lt;linux/string.h&gt;
 #include &lt;linux/seq_file.h&gt;
<span class="p_add">+#include &lt;linux/cpufreq.h&gt;</span>
 
 /*
  *	Get CPU information for use by the procfs.
<span class="p_chunk">@@ -75,9 +76,16 @@</span> <span class="p_context"> static int show_cpuinfo(struct seq_file *m, void *v)</span>
 	if (c-&gt;microcode)
 		seq_printf(m, &quot;microcode\t: 0x%x\n&quot;, c-&gt;microcode);
 
<span class="p_del">-	if (cpu_has(c, X86_FEATURE_TSC))</span>
<span class="p_add">+	if (cpu_has(c, X86_FEATURE_TSC)) {</span>
<span class="p_add">+		unsigned int freq = arch_freq_get_on_cpu(cpu);</span>
<span class="p_add">+</span>
<span class="p_add">+		if (!freq)</span>
<span class="p_add">+			freq = cpufreq_quick_get(cpu);</span>
<span class="p_add">+		if (!freq)</span>
<span class="p_add">+			freq = cpu_khz;</span>
 		seq_printf(m, &quot;cpu MHz\t\t: %u.%03u\n&quot;,
<span class="p_del">-			   cpu_khz / 1000, (cpu_khz % 1000));</span>
<span class="p_add">+			   freq / 1000, (freq % 1000));</span>
<span class="p_add">+	}</span>
 
 	/* Cache size */
 	if (c-&gt;x86_cache_size &gt;= 0)
<span class="p_header">diff --git a/drivers/block/virtio_blk.c b/drivers/block/virtio_blk.c</span>
<span class="p_header">index d3d5523862c2..b49952b5a189 100644</span>
<span class="p_header">--- a/drivers/block/virtio_blk.c</span>
<span class="p_header">+++ b/drivers/block/virtio_blk.c</span>
<span class="p_chunk">@@ -593,10 +593,22 @@</span> <span class="p_context"> static int virtblk_map_queues(struct blk_mq_tag_set *set)</span>
 	return blk_mq_virtio_map_queues(set, vblk-&gt;vdev, 0);
 }
 
<span class="p_add">+#ifdef CONFIG_VIRTIO_BLK_SCSI</span>
<span class="p_add">+static void virtblk_initialize_rq(struct request *req)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct virtblk_req *vbr = blk_mq_rq_to_pdu(req);</span>
<span class="p_add">+</span>
<span class="p_add">+	scsi_req_init(&amp;vbr-&gt;sreq);</span>
<span class="p_add">+}</span>
<span class="p_add">+#endif</span>
<span class="p_add">+</span>
 static const struct blk_mq_ops virtio_mq_ops = {
 	.queue_rq	= virtio_queue_rq,
 	.complete	= virtblk_request_done,
 	.init_request	= virtblk_init_request,
<span class="p_add">+#ifdef CONFIG_VIRTIO_BLK_SCSI</span>
<span class="p_add">+	.initialize_rq_fn = virtblk_initialize_rq,</span>
<span class="p_add">+#endif</span>
 	.map_queues	= virtblk_map_queues,
 };
 
<span class="p_header">diff --git a/drivers/gpu/drm/amd/amdgpu/uvd_v6_0.c b/drivers/gpu/drm/amd/amdgpu/uvd_v6_0.c</span>
<span class="p_header">index 31db356476f8..1086cf86354f 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/amd/amdgpu/uvd_v6_0.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/amd/amdgpu/uvd_v6_0.c</span>
<span class="p_chunk">@@ -93,6 +93,10 @@</span> <span class="p_context"> static int uvd_v6_0_early_init(void *handle)</span>
 {
 	struct amdgpu_device *adev = (struct amdgpu_device *)handle;
 
<span class="p_add">+	if (!(adev-&gt;flags &amp; AMD_IS_APU) &amp;&amp;</span>
<span class="p_add">+	    (RREG32_SMC(ixCC_HARVEST_FUSES) &amp; CC_HARVEST_FUSES__UVD_DISABLE_MASK))</span>
<span class="p_add">+		return -ENOENT;</span>
<span class="p_add">+</span>
 	uvd_v6_0_set_ring_funcs(adev);
 	uvd_v6_0_set_irq_funcs(adev);
 
<span class="p_header">diff --git a/drivers/gpu/drm/amd/amdgpu/vce_v3_0.c b/drivers/gpu/drm/amd/amdgpu/vce_v3_0.c</span>
<span class="p_header">index 90332f55cfba..cf81065e3c5a 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/amd/amdgpu/vce_v3_0.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/amd/amdgpu/vce_v3_0.c</span>
<span class="p_chunk">@@ -365,15 +365,10 @@</span> <span class="p_context"> static unsigned vce_v3_0_get_harvest_config(struct amdgpu_device *adev)</span>
 {
 	u32 tmp;
 
<span class="p_del">-	/* Fiji, Stoney, Polaris10, Polaris11, Polaris12 are single pipe */</span>
 	if ((adev-&gt;asic_type == CHIP_FIJI) ||
<span class="p_del">-	    (adev-&gt;asic_type == CHIP_STONEY) ||</span>
<span class="p_del">-	    (adev-&gt;asic_type == CHIP_POLARIS10) ||</span>
<span class="p_del">-	    (adev-&gt;asic_type == CHIP_POLARIS11) ||</span>
<span class="p_del">-	    (adev-&gt;asic_type == CHIP_POLARIS12))</span>
<span class="p_add">+	    (adev-&gt;asic_type == CHIP_STONEY))</span>
 		return AMDGPU_VCE_HARVEST_VCE1;
 
<span class="p_del">-	/* Tonga and CZ are dual or single pipe */</span>
 	if (adev-&gt;flags &amp; AMD_IS_APU)
 		tmp = (RREG32_SMC(ixVCE_HARVEST_FUSE_MACRO__ADDRESS) &amp;
 		       VCE_HARVEST_FUSE_MACRO__MASK) &gt;&gt;
<span class="p_chunk">@@ -391,6 +386,11 @@</span> <span class="p_context"> static unsigned vce_v3_0_get_harvest_config(struct amdgpu_device *adev)</span>
 	case 3:
 		return AMDGPU_VCE_HARVEST_VCE0 | AMDGPU_VCE_HARVEST_VCE1;
 	default:
<span class="p_add">+		if ((adev-&gt;asic_type == CHIP_POLARIS10) ||</span>
<span class="p_add">+		    (adev-&gt;asic_type == CHIP_POLARIS11) ||</span>
<span class="p_add">+		    (adev-&gt;asic_type == CHIP_POLARIS12))</span>
<span class="p_add">+			return AMDGPU_VCE_HARVEST_VCE1;</span>
<span class="p_add">+</span>
 		return 0;
 	}
 }
<span class="p_header">diff --git a/drivers/gpu/drm/i915/intel_dp.c b/drivers/gpu/drm/i915/intel_dp.c</span>
<span class="p_header">index 61c313e21a91..169843de91cb 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/i915/intel_dp.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/i915/intel_dp.c</span>
<span class="p_chunk">@@ -3687,9 +3687,16 @@</span> <span class="p_context"> intel_edp_init_dpcd(struct intel_dp *intel_dp)</span>
 
 	}
 
<span class="p_del">-	/* Read the eDP Display control capabilities registers */</span>
<span class="p_del">-	if ((intel_dp-&gt;dpcd[DP_EDP_CONFIGURATION_CAP] &amp; DP_DPCD_DISPLAY_CONTROL_CAPABLE) &amp;&amp;</span>
<span class="p_del">-	    drm_dp_dpcd_read(&amp;intel_dp-&gt;aux, DP_EDP_DPCD_REV,</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Read the eDP display control registers.</span>
<span class="p_add">+	 *</span>
<span class="p_add">+	 * Do this independent of DP_DPCD_DISPLAY_CONTROL_CAPABLE bit in</span>
<span class="p_add">+	 * DP_EDP_CONFIGURATION_CAP, because some buggy displays do not have it</span>
<span class="p_add">+	 * set, but require eDP 1.4+ detection (e.g. for supported link rates</span>
<span class="p_add">+	 * method). The display control registers should read zero if they&#39;re</span>
<span class="p_add">+	 * not supported anyway.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	if (drm_dp_dpcd_read(&amp;intel_dp-&gt;aux, DP_EDP_DPCD_REV,</span>
 			     intel_dp-&gt;edp_dpcd, sizeof(intel_dp-&gt;edp_dpcd)) ==
 			     sizeof(intel_dp-&gt;edp_dpcd))
 		DRM_DEBUG_KMS(&quot;EDP DPCD : %*ph\n&quot;, (int) sizeof(intel_dp-&gt;edp_dpcd),
<span class="p_header">diff --git a/drivers/gpu/drm/i915/intel_drv.h b/drivers/gpu/drm/i915/intel_drv.h</span>
<span class="p_header">index d93efb49a2e2..954e9454625e 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/i915/intel_drv.h</span>
<span class="p_header">+++ b/drivers/gpu/drm/i915/intel_drv.h</span>
<span class="p_chunk">@@ -495,7 +495,6 @@</span> <span class="p_context"> struct intel_crtc_scaler_state {</span>
 
 struct intel_pipe_wm {
 	struct intel_wm_level wm[5];
<span class="p_del">-	struct intel_wm_level raw_wm[5];</span>
 	uint32_t linetime;
 	bool fbc_wm_enabled;
 	bool pipe_enabled;
<span class="p_header">diff --git a/drivers/gpu/drm/i915/intel_pm.c b/drivers/gpu/drm/i915/intel_pm.c</span>
<span class="p_header">index 40b224b44d1b..1427cec843b9 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/i915/intel_pm.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/i915/intel_pm.c</span>
<span class="p_chunk">@@ -2696,9 +2696,9 @@</span> <span class="p_context"> static void ilk_compute_wm_level(const struct drm_i915_private *dev_priv,</span>
 				 const struct intel_crtc *intel_crtc,
 				 int level,
 				 struct intel_crtc_state *cstate,
<span class="p_del">-				 struct intel_plane_state *pristate,</span>
<span class="p_del">-				 struct intel_plane_state *sprstate,</span>
<span class="p_del">-				 struct intel_plane_state *curstate,</span>
<span class="p_add">+				 const struct intel_plane_state *pristate,</span>
<span class="p_add">+				 const struct intel_plane_state *sprstate,</span>
<span class="p_add">+				 const struct intel_plane_state *curstate,</span>
 				 struct intel_wm_level *result)
 {
 	uint16_t pri_latency = dev_priv-&gt;wm.pri_latency[level];
<span class="p_chunk">@@ -3016,28 +3016,24 @@</span> <span class="p_context"> static int ilk_compute_pipe_wm(struct intel_crtc_state *cstate)</span>
 	struct intel_pipe_wm *pipe_wm;
 	struct drm_device *dev = state-&gt;dev;
 	const struct drm_i915_private *dev_priv = to_i915(dev);
<span class="p_del">-	struct intel_plane *intel_plane;</span>
<span class="p_del">-	struct intel_plane_state *pristate = NULL;</span>
<span class="p_del">-	struct intel_plane_state *sprstate = NULL;</span>
<span class="p_del">-	struct intel_plane_state *curstate = NULL;</span>
<span class="p_add">+	struct drm_plane *plane;</span>
<span class="p_add">+	const struct drm_plane_state *plane_state;</span>
<span class="p_add">+	const struct intel_plane_state *pristate = NULL;</span>
<span class="p_add">+	const struct intel_plane_state *sprstate = NULL;</span>
<span class="p_add">+	const struct intel_plane_state *curstate = NULL;</span>
 	int level, max_level = ilk_wm_max_level(dev_priv), usable_level;
 	struct ilk_wm_maximums max;
 
 	pipe_wm = &amp;cstate-&gt;wm.ilk.optimal;
 
<span class="p_del">-	for_each_intel_plane_on_crtc(dev, intel_crtc, intel_plane) {</span>
<span class="p_del">-		struct intel_plane_state *ps;</span>
<span class="p_del">-</span>
<span class="p_del">-		ps = intel_atomic_get_existing_plane_state(state,</span>
<span class="p_del">-							   intel_plane);</span>
<span class="p_del">-		if (!ps)</span>
<span class="p_del">-			continue;</span>
<span class="p_add">+	drm_atomic_crtc_state_for_each_plane_state(plane, plane_state, &amp;cstate-&gt;base) {</span>
<span class="p_add">+		const struct intel_plane_state *ps = to_intel_plane_state(plane_state);</span>
 
<span class="p_del">-		if (intel_plane-&gt;base.type == DRM_PLANE_TYPE_PRIMARY)</span>
<span class="p_add">+		if (plane-&gt;type == DRM_PLANE_TYPE_PRIMARY)</span>
 			pristate = ps;
<span class="p_del">-		else if (intel_plane-&gt;base.type == DRM_PLANE_TYPE_OVERLAY)</span>
<span class="p_add">+		else if (plane-&gt;type == DRM_PLANE_TYPE_OVERLAY)</span>
 			sprstate = ps;
<span class="p_del">-		else if (intel_plane-&gt;base.type == DRM_PLANE_TYPE_CURSOR)</span>
<span class="p_add">+		else if (plane-&gt;type == DRM_PLANE_TYPE_CURSOR)</span>
 			curstate = ps;
 	}
 
<span class="p_chunk">@@ -3059,11 +3055,9 @@</span> <span class="p_context"> static int ilk_compute_pipe_wm(struct intel_crtc_state *cstate)</span>
 	if (pipe_wm-&gt;sprites_scaled)
 		usable_level = 0;
 
<span class="p_del">-	ilk_compute_wm_level(dev_priv, intel_crtc, 0, cstate,</span>
<span class="p_del">-			     pristate, sprstate, curstate, &amp;pipe_wm-&gt;raw_wm[0]);</span>
<span class="p_del">-</span>
 	memset(&amp;pipe_wm-&gt;wm, 0, sizeof(pipe_wm-&gt;wm));
<span class="p_del">-	pipe_wm-&gt;wm[0] = pipe_wm-&gt;raw_wm[0];</span>
<span class="p_add">+	ilk_compute_wm_level(dev_priv, intel_crtc, 0, cstate,</span>
<span class="p_add">+			     pristate, sprstate, curstate, &amp;pipe_wm-&gt;wm[0]);</span>
 
 	if (IS_HASWELL(dev_priv) || IS_BROADWELL(dev_priv))
 		pipe_wm-&gt;linetime = hsw_compute_linetime_wm(cstate);
<span class="p_chunk">@@ -3073,8 +3067,8 @@</span> <span class="p_context"> static int ilk_compute_pipe_wm(struct intel_crtc_state *cstate)</span>
 
 	ilk_compute_wm_reg_maximums(dev_priv, 1, &amp;max);
 
<span class="p_del">-	for (level = 1; level &lt;= max_level; level++) {</span>
<span class="p_del">-		struct intel_wm_level *wm = &amp;pipe_wm-&gt;raw_wm[level];</span>
<span class="p_add">+	for (level = 1; level &lt;= usable_level; level++) {</span>
<span class="p_add">+		struct intel_wm_level *wm = &amp;pipe_wm-&gt;wm[level];</span>
 
 		ilk_compute_wm_level(dev_priv, intel_crtc, level, cstate,
 				     pristate, sprstate, curstate, wm);
<span class="p_chunk">@@ -3084,13 +3078,10 @@</span> <span class="p_context"> static int ilk_compute_pipe_wm(struct intel_crtc_state *cstate)</span>
 		 * register maximums since such watermarks are
 		 * always invalid.
 		 */
<span class="p_del">-		if (level &gt; usable_level)</span>
<span class="p_del">-			continue;</span>
<span class="p_del">-</span>
<span class="p_del">-		if (ilk_validate_wm_level(level, &amp;max, wm))</span>
<span class="p_del">-			pipe_wm-&gt;wm[level] = *wm;</span>
<span class="p_del">-		else</span>
<span class="p_del">-			usable_level = level;</span>
<span class="p_add">+		if (!ilk_validate_wm_level(level, &amp;max, wm)) {</span>
<span class="p_add">+			memset(wm, 0, sizeof(*wm));</span>
<span class="p_add">+			break;</span>
<span class="p_add">+		}</span>
 	}
 
 	return 0;
<span class="p_header">diff --git a/drivers/irqchip/irq-mvebu-gicp.c b/drivers/irqchip/irq-mvebu-gicp.c</span>
<span class="p_header">index b283fc90be1e..17a4a7b6cdbb 100644</span>
<span class="p_header">--- a/drivers/irqchip/irq-mvebu-gicp.c</span>
<span class="p_header">+++ b/drivers/irqchip/irq-mvebu-gicp.c</span>
<span class="p_chunk">@@ -194,6 +194,7 @@</span> <span class="p_context"> static int mvebu_gicp_probe(struct platform_device *pdev)</span>
 		return -ENOMEM;
 
 	gicp-&gt;dev = &amp;pdev-&gt;dev;
<span class="p_add">+	spin_lock_init(&amp;gicp-&gt;spi_lock);</span>
 
 	gicp-&gt;res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
 	if (!gicp-&gt;res)
<span class="p_header">diff --git a/fs/cifs/dir.c b/fs/cifs/dir.c</span>
<span class="p_header">index e702d48bd023..81ba6e0d88d8 100644</span>
<span class="p_header">--- a/fs/cifs/dir.c</span>
<span class="p_header">+++ b/fs/cifs/dir.c</span>
<span class="p_chunk">@@ -204,7 +204,8 @@</span> <span class="p_context"> check_name(struct dentry *direntry, struct cifs_tcon *tcon)</span>
 	struct cifs_sb_info *cifs_sb = CIFS_SB(direntry-&gt;d_sb);
 	int i;
 
<span class="p_del">-	if (unlikely(direntry-&gt;d_name.len &gt;</span>
<span class="p_add">+	if (unlikely(tcon-&gt;fsAttrInfo.MaxPathNameComponentLength &amp;&amp;</span>
<span class="p_add">+		     direntry-&gt;d_name.len &gt;</span>
 		     le32_to_cpu(tcon-&gt;fsAttrInfo.MaxPathNameComponentLength)))
 		return -ENAMETOOLONG;
 
<span class="p_chunk">@@ -520,7 +521,7 @@</span> <span class="p_context"> cifs_atomic_open(struct inode *inode, struct dentry *direntry,</span>
 
 	rc = check_name(direntry, tcon);
 	if (rc)
<span class="p_del">-		goto out_free_xid;</span>
<span class="p_add">+		goto out;</span>
 
 	server = tcon-&gt;ses-&gt;server;
 
<span class="p_header">diff --git a/fs/hugetlbfs/inode.c b/fs/hugetlbfs/inode.c</span>
<span class="p_header">index 28d2753be094..a9e3b26e1b72 100644</span>
<span class="p_header">--- a/fs/hugetlbfs/inode.c</span>
<span class="p_header">+++ b/fs/hugetlbfs/inode.c</span>
<span class="p_chunk">@@ -855,9 +855,12 @@</span> <span class="p_context"> static int hugetlbfs_error_remove_page(struct address_space *mapping,</span>
 				struct page *page)
 {
 	struct inode *inode = mapping-&gt;host;
<span class="p_add">+	pgoff_t index = page-&gt;index;</span>
 
 	remove_huge_page(page);
<span class="p_del">-	hugetlb_fix_reserve_counts(inode);</span>
<span class="p_add">+	if (unlikely(hugetlb_unreserve_pages(inode, index, index + 1, 1)))</span>
<span class="p_add">+		hugetlb_fix_reserve_counts(inode);</span>
<span class="p_add">+</span>
 	return 0;
 }
 
<span class="p_header">diff --git a/fs/ocfs2/alloc.c b/fs/ocfs2/alloc.c</span>
<span class="p_header">index fb15a96df0b6..386aecce881d 100644</span>
<span class="p_header">--- a/fs/ocfs2/alloc.c</span>
<span class="p_header">+++ b/fs/ocfs2/alloc.c</span>
<span class="p_chunk">@@ -7310,13 +7310,24 @@</span> <span class="p_context"> int ocfs2_truncate_inline(struct inode *inode, struct buffer_head *di_bh,</span>
 
 static int ocfs2_trim_extent(struct super_block *sb,
 			     struct ocfs2_group_desc *gd,
<span class="p_del">-			     u32 start, u32 count)</span>
<span class="p_add">+			     u64 group, u32 start, u32 count)</span>
 {
 	u64 discard, bcount;
<span class="p_add">+	struct ocfs2_super *osb = OCFS2_SB(sb);</span>
 
 	bcount = ocfs2_clusters_to_blocks(sb, count);
<span class="p_del">-	discard = le64_to_cpu(gd-&gt;bg_blkno) +</span>
<span class="p_del">-			ocfs2_clusters_to_blocks(sb, start);</span>
<span class="p_add">+	discard = ocfs2_clusters_to_blocks(sb, start);</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * For the first cluster group, the gd-&gt;bg_blkno is not at the start</span>
<span class="p_add">+	 * of the group, but at an offset from the start. If we add it while</span>
<span class="p_add">+	 * calculating discard for first group, we will wrongly start fstrim a</span>
<span class="p_add">+	 * few blocks after the desried start block and the range can cross</span>
<span class="p_add">+	 * over into the next cluster group. So, add it only if this is not</span>
<span class="p_add">+	 * the first cluster group.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	if (group != osb-&gt;first_cluster_group_blkno)</span>
<span class="p_add">+		discard += le64_to_cpu(gd-&gt;bg_blkno);</span>
 
 	trace_ocfs2_trim_extent(sb, (unsigned long long)discard, bcount);
 
<span class="p_chunk">@@ -7324,7 +7335,7 @@</span> <span class="p_context"> static int ocfs2_trim_extent(struct super_block *sb,</span>
 }
 
 static int ocfs2_trim_group(struct super_block *sb,
<span class="p_del">-			    struct ocfs2_group_desc *gd,</span>
<span class="p_add">+			    struct ocfs2_group_desc *gd, u64 group,</span>
 			    u32 start, u32 max, u32 minbits)
 {
 	int ret = 0, count = 0, next;
<span class="p_chunk">@@ -7343,7 +7354,7 @@</span> <span class="p_context"> static int ocfs2_trim_group(struct super_block *sb,</span>
 		next = ocfs2_find_next_bit(bitmap, max, start);
 
 		if ((next - start) &gt;= minbits) {
<span class="p_del">-			ret = ocfs2_trim_extent(sb, gd,</span>
<span class="p_add">+			ret = ocfs2_trim_extent(sb, gd, group,</span>
 						start, next - start);
 			if (ret &lt; 0) {
 				mlog_errno(ret);
<span class="p_chunk">@@ -7441,7 +7452,8 @@</span> <span class="p_context"> int ocfs2_trim_fs(struct super_block *sb, struct fstrim_range *range)</span>
 		}
 
 		gd = (struct ocfs2_group_desc *)gd_bh-&gt;b_data;
<span class="p_del">-		cnt = ocfs2_trim_group(sb, gd, first_bit, last_bit, minlen);</span>
<span class="p_add">+		cnt = ocfs2_trim_group(sb, gd, group,</span>
<span class="p_add">+				       first_bit, last_bit, minlen);</span>
 		brelse(gd_bh);
 		gd_bh = NULL;
 		if (cnt &lt; 0) {
<span class="p_header">diff --git a/include/linux/swap.h b/include/linux/swap.h</span>
<span class="p_header">index d83d28e53e62..a615eda102ae 100644</span>
<span class="p_header">--- a/include/linux/swap.h</span>
<span class="p_header">+++ b/include/linux/swap.h</span>
<span class="p_chunk">@@ -246,6 +246,10 @@</span> <span class="p_context"> struct swap_info_struct {</span>
 					 * both locks need hold, hold swap_lock
 					 * first.
 					 */
<span class="p_add">+	spinlock_t cont_lock;		/*</span>
<span class="p_add">+					 * protect swap count continuation page</span>
<span class="p_add">+					 * list.</span>
<span class="p_add">+					 */</span>
 	struct work_struct discard_work; /* discard worker */
 	struct swap_cluster_list discard_clusters; /* discard clusters list */
 };
<span class="p_header">diff --git a/kernel/events/core.c b/kernel/events/core.c</span>
<span class="p_header">index 7242a6e1ec76..95bbe99e4e6c 100644</span>
<span class="p_header">--- a/kernel/events/core.c</span>
<span class="p_header">+++ b/kernel/events/core.c</span>
<span class="p_chunk">@@ -901,9 +901,11 @@</span> <span class="p_context"> list_update_cgroup_event(struct perf_event *event,</span>
 	cpuctx_entry = &amp;cpuctx-&gt;cgrp_cpuctx_entry;
 	/* cpuctx-&gt;cgrp is NULL unless a cgroup event is active in this CPU .*/
 	if (add) {
<span class="p_add">+		struct perf_cgroup *cgrp = perf_cgroup_from_task(current, ctx);</span>
<span class="p_add">+</span>
 		list_add(cpuctx_entry, this_cpu_ptr(&amp;cgrp_cpuctx_list));
<span class="p_del">-		if (perf_cgroup_from_task(current, ctx) == event-&gt;cgrp)</span>
<span class="p_del">-			cpuctx-&gt;cgrp = event-&gt;cgrp;</span>
<span class="p_add">+		if (cgroup_is_descendant(cgrp-&gt;css.cgroup, event-&gt;cgrp-&gt;css.cgroup))</span>
<span class="p_add">+			cpuctx-&gt;cgrp = cgrp;</span>
 	} else {
 		list_del(cpuctx_entry);
 		cpuctx-&gt;cgrp = NULL;
<span class="p_header">diff --git a/kernel/futex.c b/kernel/futex.c</span>
<span class="p_header">index bf57ab12ffe8..a6639b346373 100644</span>
<span class="p_header">--- a/kernel/futex.c</span>
<span class="p_header">+++ b/kernel/futex.c</span>
<span class="p_chunk">@@ -901,11 +901,27 @@</span> <span class="p_context"> void exit_pi_state_list(struct task_struct *curr)</span>
 	 */
 	raw_spin_lock_irq(&amp;curr-&gt;pi_lock);
 	while (!list_empty(head)) {
<span class="p_del">-</span>
 		next = head-&gt;next;
 		pi_state = list_entry(next, struct futex_pi_state, list);
 		key = pi_state-&gt;key;
 		hb = hash_futex(&amp;key);
<span class="p_add">+</span>
<span class="p_add">+		/*</span>
<span class="p_add">+		 * We can race against put_pi_state() removing itself from the</span>
<span class="p_add">+		 * list (a waiter going away). put_pi_state() will first</span>
<span class="p_add">+		 * decrement the reference count and then modify the list, so</span>
<span class="p_add">+		 * its possible to see the list entry but fail this reference</span>
<span class="p_add">+		 * acquire.</span>
<span class="p_add">+		 *</span>
<span class="p_add">+		 * In that case; drop the locks to let put_pi_state() make</span>
<span class="p_add">+		 * progress and retry the loop.</span>
<span class="p_add">+		 */</span>
<span class="p_add">+		if (!atomic_inc_not_zero(&amp;pi_state-&gt;refcount)) {</span>
<span class="p_add">+			raw_spin_unlock_irq(&amp;curr-&gt;pi_lock);</span>
<span class="p_add">+			cpu_relax();</span>
<span class="p_add">+			raw_spin_lock_irq(&amp;curr-&gt;pi_lock);</span>
<span class="p_add">+			continue;</span>
<span class="p_add">+		}</span>
 		raw_spin_unlock_irq(&amp;curr-&gt;pi_lock);
 
 		spin_lock(&amp;hb-&gt;lock);
<span class="p_chunk">@@ -916,8 +932,10 @@</span> <span class="p_context"> void exit_pi_state_list(struct task_struct *curr)</span>
 		 * task still owns the PI-state:
 		 */
 		if (head-&gt;next != next) {
<span class="p_add">+			/* retain curr-&gt;pi_lock for the loop invariant */</span>
 			raw_spin_unlock(&amp;pi_state-&gt;pi_mutex.wait_lock);
 			spin_unlock(&amp;hb-&gt;lock);
<span class="p_add">+			put_pi_state(pi_state);</span>
 			continue;
 		}
 
<span class="p_chunk">@@ -925,9 +943,8 @@</span> <span class="p_context"> void exit_pi_state_list(struct task_struct *curr)</span>
 		WARN_ON(list_empty(&amp;pi_state-&gt;list));
 		list_del_init(&amp;pi_state-&gt;list);
 		pi_state-&gt;owner = NULL;
<span class="p_del">-		raw_spin_unlock(&amp;curr-&gt;pi_lock);</span>
 
<span class="p_del">-		get_pi_state(pi_state);</span>
<span class="p_add">+		raw_spin_unlock(&amp;curr-&gt;pi_lock);</span>
 		raw_spin_unlock_irq(&amp;pi_state-&gt;pi_mutex.wait_lock);
 		spin_unlock(&amp;hb-&gt;lock);
 
<span class="p_header">diff --git a/lib/asn1_decoder.c b/lib/asn1_decoder.c</span>
<span class="p_header">index 0bd8a611eb83..fef5d2e114be 100644</span>
<span class="p_header">--- a/lib/asn1_decoder.c</span>
<span class="p_header">+++ b/lib/asn1_decoder.c</span>
<span class="p_chunk">@@ -284,6 +284,9 @@</span> <span class="p_context"> int asn1_ber_decoder(const struct asn1_decoder *decoder,</span>
 				if (unlikely(len &gt; datalen - dp))
 					goto data_overrun_error;
 			}
<span class="p_add">+		} else {</span>
<span class="p_add">+			if (unlikely(len &gt; datalen - dp))</span>
<span class="p_add">+				goto data_overrun_error;</span>
 		}
 
 		if (flags &amp; FLAG_CONS) {
<span class="p_header">diff --git a/mm/hugetlb.c b/mm/hugetlb.c</span>
<span class="p_header">index 31e207cb399b..011725849f52 100644</span>
<span class="p_header">--- a/mm/hugetlb.c</span>
<span class="p_header">+++ b/mm/hugetlb.c</span>
<span class="p_chunk">@@ -3977,6 +3977,9 @@</span> <span class="p_context"> int hugetlb_mcopy_atomic_pte(struct mm_struct *dst_mm,</span>
 			    unsigned long src_addr,
 			    struct page **pagep)
 {
<span class="p_add">+	struct address_space *mapping;</span>
<span class="p_add">+	pgoff_t idx;</span>
<span class="p_add">+	unsigned long size;</span>
 	int vm_shared = dst_vma-&gt;vm_flags &amp; VM_SHARED;
 	struct hstate *h = hstate_vma(dst_vma);
 	pte_t _dst_pte;
<span class="p_chunk">@@ -4014,13 +4017,24 @@</span> <span class="p_context"> int hugetlb_mcopy_atomic_pte(struct mm_struct *dst_mm,</span>
 	__SetPageUptodate(page);
 	set_page_huge_active(page);
 
<span class="p_add">+	mapping = dst_vma-&gt;vm_file-&gt;f_mapping;</span>
<span class="p_add">+	idx = vma_hugecache_offset(h, dst_vma, dst_addr);</span>
<span class="p_add">+</span>
 	/*
 	 * If shared, add to page cache
 	 */
 	if (vm_shared) {
<span class="p_del">-		struct address_space *mapping = dst_vma-&gt;vm_file-&gt;f_mapping;</span>
<span class="p_del">-		pgoff_t idx = vma_hugecache_offset(h, dst_vma, dst_addr);</span>
<span class="p_add">+		size = i_size_read(mapping-&gt;host) &gt;&gt; huge_page_shift(h);</span>
<span class="p_add">+		ret = -EFAULT;</span>
<span class="p_add">+		if (idx &gt;= size)</span>
<span class="p_add">+			goto out_release_nounlock;</span>
 
<span class="p_add">+		/*</span>
<span class="p_add">+		 * Serialization between remove_inode_hugepages() and</span>
<span class="p_add">+		 * huge_add_to_page_cache() below happens through the</span>
<span class="p_add">+		 * hugetlb_fault_mutex_table that here must be hold by</span>
<span class="p_add">+		 * the caller.</span>
<span class="p_add">+		 */</span>
 		ret = huge_add_to_page_cache(page, mapping, idx);
 		if (ret)
 			goto out_release_nounlock;
<span class="p_chunk">@@ -4029,6 +4043,20 @@</span> <span class="p_context"> int hugetlb_mcopy_atomic_pte(struct mm_struct *dst_mm,</span>
 	ptl = huge_pte_lockptr(h, dst_mm, dst_pte);
 	spin_lock(ptl);
 
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Recheck the i_size after holding PT lock to make sure not</span>
<span class="p_add">+	 * to leave any page mapped (as page_mapped()) beyond the end</span>
<span class="p_add">+	 * of the i_size (remove_inode_hugepages() is strict about</span>
<span class="p_add">+	 * enforcing that). If we bail out here, we&#39;ll also leave a</span>
<span class="p_add">+	 * page in the radix tree in the vm_shared case beyond the end</span>
<span class="p_add">+	 * of the i_size, but remove_inode_hugepages() will take care</span>
<span class="p_add">+	 * of it as soon as we drop the hugetlb_fault_mutex_table.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	size = i_size_read(mapping-&gt;host) &gt;&gt; huge_page_shift(h);</span>
<span class="p_add">+	ret = -EFAULT;</span>
<span class="p_add">+	if (idx &gt;= size)</span>
<span class="p_add">+		goto out_release_unlock;</span>
<span class="p_add">+</span>
 	ret = -EEXIST;
 	if (!huge_pte_none(huge_ptep_get(dst_pte)))
 		goto out_release_unlock;
<span class="p_header">diff --git a/mm/swapfile.c b/mm/swapfile.c</span>
<span class="p_header">index a8952b6563c6..3191465b0ccf 100644</span>
<span class="p_header">--- a/mm/swapfile.c</span>
<span class="p_header">+++ b/mm/swapfile.c</span>
<span class="p_chunk">@@ -2635,6 +2635,7 @@</span> <span class="p_context"> static struct swap_info_struct *alloc_swap_info(void)</span>
 	p-&gt;flags = SWP_USED;
 	spin_unlock(&amp;swap_lock);
 	spin_lock_init(&amp;p-&gt;lock);
<span class="p_add">+	spin_lock_init(&amp;p-&gt;cont_lock);</span>
 
 	return p;
 }
<span class="p_chunk">@@ -3307,6 +3308,7 @@</span> <span class="p_context"> int add_swap_count_continuation(swp_entry_t entry, gfp_t gfp_mask)</span>
 	head = vmalloc_to_page(si-&gt;swap_map + offset);
 	offset &amp;= ~PAGE_MASK;
 
<span class="p_add">+	spin_lock(&amp;si-&gt;cont_lock);</span>
 	/*
 	 * Page allocation does not initialize the page&#39;s lru field,
 	 * but it does always reset its private field.
<span class="p_chunk">@@ -3326,7 +3328,7 @@</span> <span class="p_context"> int add_swap_count_continuation(swp_entry_t entry, gfp_t gfp_mask)</span>
 		 * a continuation page, free our allocation and use this one.
 		 */
 		if (!(count &amp; COUNT_CONTINUED))
<span class="p_del">-			goto out;</span>
<span class="p_add">+			goto out_unlock_cont;</span>
 
 		map = kmap_atomic(list_page) + offset;
 		count = *map;
<span class="p_chunk">@@ -3337,11 +3339,13 @@</span> <span class="p_context"> int add_swap_count_continuation(swp_entry_t entry, gfp_t gfp_mask)</span>
 		 * free our allocation and use this one.
 		 */
 		if ((count &amp; ~COUNT_CONTINUED) != SWAP_CONT_MAX)
<span class="p_del">-			goto out;</span>
<span class="p_add">+			goto out_unlock_cont;</span>
 	}
 
 	list_add_tail(&amp;page-&gt;lru, &amp;head-&gt;lru);
 	page = NULL;			/* now it&#39;s attached, don&#39;t free it */
<span class="p_add">+out_unlock_cont:</span>
<span class="p_add">+	spin_unlock(&amp;si-&gt;cont_lock);</span>
 out:
 	unlock_cluster(ci);
 	spin_unlock(&amp;si-&gt;lock);
<span class="p_chunk">@@ -3366,6 +3370,7 @@</span> <span class="p_context"> static bool swap_count_continued(struct swap_info_struct *si,</span>
 	struct page *head;
 	struct page *page;
 	unsigned char *map;
<span class="p_add">+	bool ret;</span>
 
 	head = vmalloc_to_page(si-&gt;swap_map + offset);
 	if (page_private(head) != SWP_CONTINUED) {
<span class="p_chunk">@@ -3373,6 +3378,7 @@</span> <span class="p_context"> static bool swap_count_continued(struct swap_info_struct *si,</span>
 		return false;		/* need to add count continuation */
 	}
 
<span class="p_add">+	spin_lock(&amp;si-&gt;cont_lock);</span>
 	offset &amp;= ~PAGE_MASK;
 	page = list_entry(head-&gt;lru.next, struct page, lru);
 	map = kmap_atomic(page) + offset;
<span class="p_chunk">@@ -3393,8 +3399,10 @@</span> <span class="p_context"> static bool swap_count_continued(struct swap_info_struct *si,</span>
 		if (*map == SWAP_CONT_MAX) {
 			kunmap_atomic(map);
 			page = list_entry(page-&gt;lru.next, struct page, lru);
<span class="p_del">-			if (page == head)</span>
<span class="p_del">-				return false;	/* add count continuation */</span>
<span class="p_add">+			if (page == head) {</span>
<span class="p_add">+				ret = false;	/* add count continuation */</span>
<span class="p_add">+				goto out;</span>
<span class="p_add">+			}</span>
 			map = kmap_atomic(page) + offset;
 init_map:		*map = 0;		/* we didn&#39;t zero the page */
 		}
<span class="p_chunk">@@ -3407,7 +3415,7 @@</span> <span class="p_context"> init_map:		*map = 0;		/* we didn&#39;t zero the page */</span>
 			kunmap_atomic(map);
 			page = list_entry(page-&gt;lru.prev, struct page, lru);
 		}
<span class="p_del">-		return true;			/* incremented */</span>
<span class="p_add">+		ret = true;			/* incremented */</span>
 
 	} else {				/* decrementing */
 		/*
<span class="p_chunk">@@ -3433,8 +3441,11 @@</span> <span class="p_context"> init_map:		*map = 0;		/* we didn&#39;t zero the page */</span>
 			kunmap_atomic(map);
 			page = list_entry(page-&gt;lru.prev, struct page, lru);
 		}
<span class="p_del">-		return count == COUNT_CONTINUED;</span>
<span class="p_add">+		ret = count == COUNT_CONTINUED;</span>
 	}
<span class="p_add">+out:</span>
<span class="p_add">+	spin_unlock(&amp;si-&gt;cont_lock);</span>
<span class="p_add">+	return ret;</span>
 }
 
 /*
<span class="p_header">diff --git a/security/keys/keyring.c b/security/keys/keyring.c</span>
<span class="p_header">index 06173b091a74..c04032302a25 100644</span>
<span class="p_header">--- a/security/keys/keyring.c</span>
<span class="p_header">+++ b/security/keys/keyring.c</span>
<span class="p_chunk">@@ -459,34 +459,33 @@</span> <span class="p_context"> static long keyring_read(const struct key *keyring,</span>
 			 char __user *buffer, size_t buflen)
 {
 	struct keyring_read_iterator_context ctx;
<span class="p_del">-	unsigned long nr_keys;</span>
<span class="p_del">-	int ret;</span>
<span class="p_add">+	long ret;</span>
 
 	kenter(&quot;{%d},,%zu&quot;, key_serial(keyring), buflen);
 
 	if (buflen &amp; (sizeof(key_serial_t) - 1))
 		return -EINVAL;
 
<span class="p_del">-	nr_keys = keyring-&gt;keys.nr_leaves_on_tree;</span>
<span class="p_del">-	if (nr_keys == 0)</span>
<span class="p_del">-		return 0;</span>
<span class="p_del">-</span>
<span class="p_del">-	/* Calculate how much data we could return */</span>
<span class="p_del">-	if (!buffer || !buflen)</span>
<span class="p_del">-		return nr_keys * sizeof(key_serial_t);</span>
<span class="p_del">-</span>
<span class="p_del">-	/* Copy the IDs of the subscribed keys into the buffer */</span>
<span class="p_del">-	ctx.buffer = (key_serial_t __user *)buffer;</span>
<span class="p_del">-	ctx.buflen = buflen;</span>
<span class="p_del">-	ctx.count = 0;</span>
<span class="p_del">-	ret = assoc_array_iterate(&amp;keyring-&gt;keys, keyring_read_iterator, &amp;ctx);</span>
<span class="p_del">-	if (ret &lt; 0) {</span>
<span class="p_del">-		kleave(&quot; = %d [iterate]&quot;, ret);</span>
<span class="p_del">-		return ret;</span>
<span class="p_add">+	/* Copy as many key IDs as fit into the buffer */</span>
<span class="p_add">+	if (buffer &amp;&amp; buflen) {</span>
<span class="p_add">+		ctx.buffer = (key_serial_t __user *)buffer;</span>
<span class="p_add">+		ctx.buflen = buflen;</span>
<span class="p_add">+		ctx.count = 0;</span>
<span class="p_add">+		ret = assoc_array_iterate(&amp;keyring-&gt;keys,</span>
<span class="p_add">+					  keyring_read_iterator, &amp;ctx);</span>
<span class="p_add">+		if (ret &lt; 0) {</span>
<span class="p_add">+			kleave(&quot; = %ld [iterate]&quot;, ret);</span>
<span class="p_add">+			return ret;</span>
<span class="p_add">+		}</span>
 	}
 
<span class="p_del">-	kleave(&quot; = %zu [ok]&quot;, ctx.count);</span>
<span class="p_del">-	return ctx.count;</span>
<span class="p_add">+	/* Return the size of the buffer needed */</span>
<span class="p_add">+	ret = keyring-&gt;keys.nr_leaves_on_tree * sizeof(key_serial_t);</span>
<span class="p_add">+	if (ret &lt;= buflen)</span>
<span class="p_add">+		kleave(&quot;= %ld [ok]&quot;, ret);</span>
<span class="p_add">+	else</span>
<span class="p_add">+		kleave(&quot;= %ld [buffer too small]&quot;, ret);</span>
<span class="p_add">+	return ret;</span>
 }
 
 /*
<span class="p_header">diff --git a/security/keys/trusted.c b/security/keys/trusted.c</span>
<span class="p_header">index bd85315cbfeb..98aa89ff7bfd 100644</span>
<span class="p_header">--- a/security/keys/trusted.c</span>
<span class="p_header">+++ b/security/keys/trusted.c</span>
<span class="p_chunk">@@ -1147,20 +1147,21 @@</span> <span class="p_context"> static long trusted_read(const struct key *key, char __user *buffer,</span>
 	p = dereference_key_locked(key);
 	if (!p)
 		return -EINVAL;
<span class="p_del">-	if (!buffer || buflen &lt;= 0)</span>
<span class="p_del">-		return 2 * p-&gt;blob_len;</span>
<span class="p_del">-	ascii_buf = kmalloc(2 * p-&gt;blob_len, GFP_KERNEL);</span>
<span class="p_del">-	if (!ascii_buf)</span>
<span class="p_del">-		return -ENOMEM;</span>
 
<span class="p_del">-	bufp = ascii_buf;</span>
<span class="p_del">-	for (i = 0; i &lt; p-&gt;blob_len; i++)</span>
<span class="p_del">-		bufp = hex_byte_pack(bufp, p-&gt;blob[i]);</span>
<span class="p_del">-	if ((copy_to_user(buffer, ascii_buf, 2 * p-&gt;blob_len)) != 0) {</span>
<span class="p_add">+	if (buffer &amp;&amp; buflen &gt;= 2 * p-&gt;blob_len) {</span>
<span class="p_add">+		ascii_buf = kmalloc(2 * p-&gt;blob_len, GFP_KERNEL);</span>
<span class="p_add">+		if (!ascii_buf)</span>
<span class="p_add">+			return -ENOMEM;</span>
<span class="p_add">+</span>
<span class="p_add">+		bufp = ascii_buf;</span>
<span class="p_add">+		for (i = 0; i &lt; p-&gt;blob_len; i++)</span>
<span class="p_add">+			bufp = hex_byte_pack(bufp, p-&gt;blob[i]);</span>
<span class="p_add">+		if (copy_to_user(buffer, ascii_buf, 2 * p-&gt;blob_len) != 0) {</span>
<span class="p_add">+			kzfree(ascii_buf);</span>
<span class="p_add">+			return -EFAULT;</span>
<span class="p_add">+		}</span>
 		kzfree(ascii_buf);
<span class="p_del">-		return -EFAULT;</span>
 	}
<span class="p_del">-	kzfree(ascii_buf);</span>
 	return 2 * p-&gt;blob_len;
 }
 
<span class="p_header">diff --git a/sound/core/seq/seq_clientmgr.c b/sound/core/seq/seq_clientmgr.c</span>
<span class="p_header">index 6c9cba2166d9..d10c780dfd54 100644</span>
<span class="p_header">--- a/sound/core/seq/seq_clientmgr.c</span>
<span class="p_header">+++ b/sound/core/seq/seq_clientmgr.c</span>
<span class="p_chunk">@@ -663,7 +663,7 @@</span> <span class="p_context"> static int deliver_to_subscribers(struct snd_seq_client *client,</span>
 	if (atomic)
 		read_lock(&amp;grp-&gt;list_lock);
 	else
<span class="p_del">-		down_read(&amp;grp-&gt;list_mutex);</span>
<span class="p_add">+		down_read_nested(&amp;grp-&gt;list_mutex, hop);</span>
 	list_for_each_entry(subs, &amp;grp-&gt;list_head, src_list) {
 		/* both ports ready? */
 		if (atomic_read(&amp;subs-&gt;ref_count) != 2)
<span class="p_header">diff --git a/sound/core/timer_compat.c b/sound/core/timer_compat.c</span>
<span class="p_header">index 6a437eb66115..59127b6ef39e 100644</span>
<span class="p_header">--- a/sound/core/timer_compat.c</span>
<span class="p_header">+++ b/sound/core/timer_compat.c</span>
<span class="p_chunk">@@ -133,7 +133,8 @@</span> <span class="p_context"> enum {</span>
 #endif /* CONFIG_X86_X32 */
 };
 
<span class="p_del">-static long snd_timer_user_ioctl_compat(struct file *file, unsigned int cmd, unsigned long arg)</span>
<span class="p_add">+static long __snd_timer_user_ioctl_compat(struct file *file, unsigned int cmd,</span>
<span class="p_add">+					  unsigned long arg)</span>
 {
 	void __user *argp = compat_ptr(arg);
 
<span class="p_chunk">@@ -153,7 +154,7 @@</span> <span class="p_context"> static long snd_timer_user_ioctl_compat(struct file *file, unsigned int cmd, uns</span>
 	case SNDRV_TIMER_IOCTL_PAUSE:
 	case SNDRV_TIMER_IOCTL_PAUSE_OLD:
 	case SNDRV_TIMER_IOCTL_NEXT_DEVICE:
<span class="p_del">-		return snd_timer_user_ioctl(file, cmd, (unsigned long)argp);</span>
<span class="p_add">+		return __snd_timer_user_ioctl(file, cmd, (unsigned long)argp);</span>
 	case SNDRV_TIMER_IOCTL_GPARAMS32:
 		return snd_timer_user_gparams_compat(file, argp);
 	case SNDRV_TIMER_IOCTL_INFO32:
<span class="p_chunk">@@ -167,3 +168,15 @@</span> <span class="p_context"> static long snd_timer_user_ioctl_compat(struct file *file, unsigned int cmd, uns</span>
 	}
 	return -ENOIOCTLCMD;
 }
<span class="p_add">+</span>
<span class="p_add">+static long snd_timer_user_ioctl_compat(struct file *file, unsigned int cmd,</span>
<span class="p_add">+					unsigned long arg)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct snd_timer_user *tu = file-&gt;private_data;</span>
<span class="p_add">+	long ret;</span>
<span class="p_add">+</span>
<span class="p_add">+	mutex_lock(&amp;tu-&gt;ioctl_lock);</span>
<span class="p_add">+	ret = __snd_timer_user_ioctl_compat(file, cmd, arg);</span>
<span class="p_add">+	mutex_unlock(&amp;tu-&gt;ioctl_lock);</span>
<span class="p_add">+	return ret;</span>
<span class="p_add">+}</span>
<span class="p_header">diff --git a/sound/soc/codecs/adau17x1.c b/sound/soc/codecs/adau17x1.c</span>
<span class="p_header">index 2c1bd2763864..6758f789b712 100644</span>
<span class="p_header">--- a/sound/soc/codecs/adau17x1.c</span>
<span class="p_header">+++ b/sound/soc/codecs/adau17x1.c</span>
<span class="p_chunk">@@ -90,6 +90,27 @@</span> <span class="p_context"> static int adau17x1_pll_event(struct snd_soc_dapm_widget *w,</span>
 	return 0;
 }
 
<span class="p_add">+static int adau17x1_adc_fixup(struct snd_soc_dapm_widget *w,</span>
<span class="p_add">+	struct snd_kcontrol *kcontrol, int event)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct snd_soc_codec *codec = snd_soc_dapm_to_codec(w-&gt;dapm);</span>
<span class="p_add">+	struct adau *adau = snd_soc_codec_get_drvdata(codec);</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * If we are capturing, toggle the ADOSR bit in Converter Control 0 to</span>
<span class="p_add">+	 * avoid losing SNR (workaround from ADI). This must be done after</span>
<span class="p_add">+	 * the ADC(s) have been enabled. According to the data sheet, it is</span>
<span class="p_add">+	 * normally illegal to set this bit when the sampling rate is 96 kHz,</span>
<span class="p_add">+	 * but according to ADI it is acceptable for this workaround.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	regmap_update_bits(adau-&gt;regmap, ADAU17X1_CONVERTER0,</span>
<span class="p_add">+		ADAU17X1_CONVERTER0_ADOSR, ADAU17X1_CONVERTER0_ADOSR);</span>
<span class="p_add">+	regmap_update_bits(adau-&gt;regmap, ADAU17X1_CONVERTER0,</span>
<span class="p_add">+		ADAU17X1_CONVERTER0_ADOSR, 0);</span>
<span class="p_add">+</span>
<span class="p_add">+	return 0;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static const char * const adau17x1_mono_stereo_text[] = {
 	&quot;Stereo&quot;,
 	&quot;Mono Left Channel (L+R)&quot;,
<span class="p_chunk">@@ -121,7 +142,8 @@</span> <span class="p_context"> static const struct snd_soc_dapm_widget adau17x1_dapm_widgets[] = {</span>
 	SND_SOC_DAPM_MUX(&quot;Right DAC Mode Mux&quot;, SND_SOC_NOPM, 0, 0,
 		&amp;adau17x1_dac_mode_mux),
 
<span class="p_del">-	SND_SOC_DAPM_ADC(&quot;Left Decimator&quot;, NULL, ADAU17X1_ADC_CONTROL, 0, 0),</span>
<span class="p_add">+	SND_SOC_DAPM_ADC_E(&quot;Left Decimator&quot;, NULL, ADAU17X1_ADC_CONTROL, 0, 0,</span>
<span class="p_add">+			   adau17x1_adc_fixup, SND_SOC_DAPM_POST_PMU),</span>
 	SND_SOC_DAPM_ADC(&quot;Right Decimator&quot;, NULL, ADAU17X1_ADC_CONTROL, 1, 0),
 	SND_SOC_DAPM_DAC(&quot;Left DAC&quot;, NULL, ADAU17X1_DAC_CONTROL0, 0, 0),
 	SND_SOC_DAPM_DAC(&quot;Right DAC&quot;, NULL, ADAU17X1_DAC_CONTROL0, 1, 0),
<span class="p_header">diff --git a/sound/soc/codecs/adau17x1.h b/sound/soc/codecs/adau17x1.h</span>
<span class="p_header">index bf04b7efee40..db350035fad7 100644</span>
<span class="p_header">--- a/sound/soc/codecs/adau17x1.h</span>
<span class="p_header">+++ b/sound/soc/codecs/adau17x1.h</span>
<span class="p_chunk">@@ -129,5 +129,7 @@</span> <span class="p_context"> bool adau17x1_has_dsp(struct adau *adau);</span>
 
 #define ADAU17X1_CONVERTER0_CONVSR_MASK		0x7
 
<span class="p_add">+#define ADAU17X1_CONVERTER0_ADOSR		BIT(3)</span>
<span class="p_add">+</span>
 
 #endif
<span class="p_header">diff --git a/virt/kvm/arm/vgic/vgic-its.c b/virt/kvm/arm/vgic/vgic-its.c</span>
<span class="p_header">index aa6b68db80b4..b606f1643fe5 100644</span>
<span class="p_header">--- a/virt/kvm/arm/vgic/vgic-its.c</span>
<span class="p_header">+++ b/virt/kvm/arm/vgic/vgic-its.c</span>
<span class="p_chunk">@@ -1803,37 +1803,33 @@</span> <span class="p_context"> typedef int (*entry_fn_t)(struct vgic_its *its, u32 id, void *entry,</span>
 static int scan_its_table(struct vgic_its *its, gpa_t base, int size, int esz,
 			  int start_id, entry_fn_t fn, void *opaque)
 {
<span class="p_del">-	void *entry = kzalloc(esz, GFP_KERNEL);</span>
 	struct kvm *kvm = its-&gt;dev-&gt;kvm;
 	unsigned long len = size;
 	int id = start_id;
 	gpa_t gpa = base;
<span class="p_add">+	char entry[esz];</span>
 	int ret;
 
<span class="p_add">+	memset(entry, 0, esz);</span>
<span class="p_add">+</span>
 	while (len &gt; 0) {
 		int next_offset;
 		size_t byte_offset;
 
 		ret = kvm_read_guest(kvm, gpa, entry, esz);
 		if (ret)
<span class="p_del">-			goto out;</span>
<span class="p_add">+			return ret;</span>
 
 		next_offset = fn(its, id, entry, opaque);
<span class="p_del">-		if (next_offset &lt;= 0) {</span>
<span class="p_del">-			ret = next_offset;</span>
<span class="p_del">-			goto out;</span>
<span class="p_del">-		}</span>
<span class="p_add">+		if (next_offset &lt;= 0)</span>
<span class="p_add">+			return next_offset;</span>
 
 		byte_offset = next_offset * esz;
 		id += next_offset;
 		gpa += byte_offset;
 		len -= byte_offset;
 	}
<span class="p_del">-	ret =  1;</span>
<span class="p_del">-</span>
<span class="p_del">-out:</span>
<span class="p_del">-	kfree(entry);</span>
<span class="p_del">-	return ret;</span>
<span class="p_add">+	return 1;</span>
 }
 
 /**

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



