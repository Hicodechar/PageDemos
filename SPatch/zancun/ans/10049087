
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>[22/30] x86, pcid, kaiser: allow flushing for future ASID switches - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    [22/30] x86, pcid, kaiser: allow flushing for future ASID switches</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=64071">Dave Hansen</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>Nov. 8, 2017, 7:47 p.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;20171108194728.4D8F87B6@viggo.jf.intel.com&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/10049087/mbox/"
   >mbox</a>
|
   <a href="/patch/10049087/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/10049087/">/patch/10049087/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
	[172.30.200.125])
	by pdx-korg-patchwork.web.codeaurora.org (Postfix) with ESMTP id
	6BB17603FA for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Wed,  8 Nov 2017 19:47:48 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 5BDA529364
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Wed,  8 Nov 2017 19:47:48 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id 50BB4294DB; Wed,  8 Nov 2017 19:47:48 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-6.9 required=2.0 tests=BAYES_00,RCVD_IN_DNSWL_HI
	autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 1824229364
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Wed,  8 Nov 2017 19:47:47 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1752891AbdKHTrp (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Wed, 8 Nov 2017 14:47:45 -0500
Received: from mga06.intel.com ([134.134.136.31]:37804 &quot;EHLO mga06.intel.com&quot;
	rhost-flags-OK-OK-OK-OK) by vger.kernel.org with ESMTP
	id S1752810AbdKHTrj (ORCPT &lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Wed, 8 Nov 2017 14:47:39 -0500
Received: from fmsmga006.fm.intel.com ([10.253.24.20])
	by orsmga104.jf.intel.com with ESMTP; 08 Nov 2017 11:47:39 -0800
X-ExtLoop1: 1
X-IronPort-AV: E=Sophos;i=&quot;5.44,365,1505804400&quot;; d=&quot;scan&#39;208&quot;;a=&quot;173893918&quot;
Received: from viggo.jf.intel.com (HELO localhost.localdomain)
	([10.54.39.119])
	by fmsmga006.fm.intel.com with ESMTP; 08 Nov 2017 11:47:38 -0800
Subject: [PATCH 22/30] x86, pcid,
	kaiser: allow flushing for future ASID switches
To: linux-kernel@vger.kernel.org
Cc: linux-mm@kvack.org, dave.hansen@linux.intel.com,
	moritz.lipp@iaik.tugraz.at, daniel.gruss@iaik.tugraz.at,
	michael.schwarz@iaik.tugraz.at, richard.fellner@student.tugraz.at,
	luto@kernel.org, torvalds@linux-foundation.org,
	keescook@google.com, hughd@google.com, x86@kernel.org
From: Dave Hansen &lt;dave.hansen@linux.intel.com&gt;
Date: Wed, 08 Nov 2017 11:47:28 -0800
References: &lt;20171108194646.907A1942@viggo.jf.intel.com&gt;
In-Reply-To: &lt;20171108194646.907A1942@viggo.jf.intel.com&gt;
Message-Id: &lt;20171108194728.4D8F87B6@viggo.jf.intel.com&gt;
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=64071">Dave Hansen</a> - Nov. 8, 2017, 7:47 p.m.</div>
<pre class="content">
<span class="from">From: Dave Hansen &lt;dave.hansen@linux.intel.com&gt;</span>

If we change the page tables in such a way that we need an
invalidation of all contexts (aka. PCIDs / ASIDs) we can
actively invalidate them by:
 1. INVPCID for each PCID (works for single pages too).
 2. Load CR3 with each PCID without the NOFLUSH bit set
 3. Load CR3 with the NOFLUSH bit set for each and do
    INVLPG for each address.

But, none of these are really feasible since we have ~6 ASIDs (12 with
KAISER) at the time that we need to do an invalidation.  So, we just
invalidate the *current* context and then mark the cpu_tlbstate
_quickly_.

Then, at the next context-switch, we notice that we had
&#39;all_other_ctxs_invalid&#39; marked, and go invalidate all of the
cpu_tlbstate.ctxs[] entries.

This ensures that any future context switches will do a full flush
of the TLB so they pick up the changes.
<span class="signed-off-by">
Signed-off-by: Dave Hansen &lt;dave.hansen@linux.intel.com&gt;</span>
Cc: Moritz Lipp &lt;moritz.lipp@iaik.tugraz.at&gt;
Cc: Daniel Gruss &lt;daniel.gruss@iaik.tugraz.at&gt;
Cc: Michael Schwarz &lt;michael.schwarz@iaik.tugraz.at&gt;
Cc: Richard Fellner &lt;richard.fellner@student.tugraz.at&gt;
Cc: Andy Lutomirski &lt;luto@kernel.org&gt;
Cc: Linus Torvalds &lt;torvalds@linux-foundation.org&gt;
Cc: Kees Cook &lt;keescook@google.com&gt;
Cc: Hugh Dickins &lt;hughd@google.com&gt;
Cc: x86@kernel.org
---

 b/arch/x86/include/asm/tlbflush.h |   47 +++++++++++++++++++++++++++++---------
 b/arch/x86/mm/tlb.c               |   35 ++++++++++++++++++++++++++++
 2 files changed, 72 insertions(+), 10 deletions(-)
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=137">Peter Zijlstra</a> - Nov. 10, 2017, 12:25 p.m.</div>
<pre class="content">
On Wed, Nov 08, 2017 at 11:47:28AM -0800, Dave Hansen wrote:
<span class="quote">&gt; +/*</span>
<span class="quote">&gt; + * We get here when we do something requiring a TLB invalidation</span>
<span class="quote">&gt; + * but could not go invalidate all of the contexts.  We do the</span>
<span class="quote">&gt; + * necessary invalidation by clearing out the &#39;ctx_id&#39; which</span>
<span class="quote">&gt; + * forces a TLB flush when the context is loaded.</span>
<span class="quote">&gt; + */</span>
<span class="quote">&gt; +void clear_non_loaded_ctxs(void)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	u16 asid;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	/*</span>
<span class="quote">&gt; +	 * This is only expected to be set if we have disabled</span>
<span class="quote">&gt; +	 * kernel _PAGE_GLOBAL pages.</span>
<span class="quote">&gt; +	 */</span>
<span class="quote">&gt; +        if (IS_ENABLED(CONFIG_X86_GLOBAL_PAGES)) {</span>
<span class="quote">&gt; +		WARN_ON_ONCE(1);</span>
<span class="quote">&gt; +                return;</span>
<span class="quote">&gt; +	}</span>

Whitespace damage..
<span class="quote">
&gt; +</span>
<span class="quote">&gt; +	for (asid = 0; asid &lt; TLB_NR_DYN_ASIDS; asid++) {</span>
<span class="quote">&gt; +		/* Do not need to flush the current asid */</span>
<span class="quote">&gt; +		if (asid == this_cpu_read(cpu_tlbstate.loaded_mm_asid))</span>
<span class="quote">&gt; +			continue;</span>
<span class="quote">&gt; +		/*</span>
<span class="quote">&gt; +		 * Make sure the next time we go to switch to</span>
<span class="quote">&gt; +		 * this asid, we do a flush:</span>
<span class="quote">&gt; +		 */</span>
<span class="quote">&gt; +		this_cpu_write(cpu_tlbstate.ctxs[asid].ctx_id, 0);</span>
<span class="quote">&gt; +	}</span>
<span class="quote">&gt; +	this_cpu_write(cpu_tlbstate.all_other_ctxs_invalid, false);</span>
<span class="quote">&gt; +}</span>
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff -puN arch/x86/include/asm/tlbflush.h~kaiser-pcid-pre-clear-pcid-cache arch/x86/include/asm/tlbflush.h</span>
<span class="p_header">--- a/arch/x86/include/asm/tlbflush.h~kaiser-pcid-pre-clear-pcid-cache	2017-11-08 10:45:37.846681374 -0800</span>
<span class="p_header">+++ b/arch/x86/include/asm/tlbflush.h	2017-11-08 10:45:37.852681374 -0800</span>
<span class="p_chunk">@@ -183,6 +183,17 @@</span> <span class="p_context"> struct tlb_state {</span>
 	bool is_lazy;
 
 	/*
<span class="p_add">+	 * If set we changed the page tables in such a way that we</span>
<span class="p_add">+	 * needed an invalidation of all contexts (aka. PCIDs / ASIDs).</span>
<span class="p_add">+	 * This tells us to go invalidate all the non-loaded ctxs[]</span>
<span class="p_add">+	 * on the next context switch.</span>
<span class="p_add">+	 *</span>
<span class="p_add">+	 * The current ctx was kept up-to-date as it ran and does not</span>
<span class="p_add">+	 * need to be invalidated.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	bool all_other_ctxs_invalid;</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
 	 * Access to this CR4 shadow and to H/W CR4 is protected by
 	 * disabling interrupts when modifying either one.
 	 */
<span class="p_chunk">@@ -259,6 +270,19 @@</span> <span class="p_context"> static inline unsigned long cr4_read_sha</span>
 	return this_cpu_read(cpu_tlbstate.cr4);
 }
 
<span class="p_add">+static inline void tlb_flush_shared_nonglobals(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * With global pages, all of the shared kenel page tables</span>
<span class="p_add">+	 * are set as _PAGE_GLOBAL.  We have no shared nonglobals</span>
<span class="p_add">+	 * and nothing to do here.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	if (IS_ENABLED(CONFIG_X86_GLOBAL_PAGES))</span>
<span class="p_add">+		return;</span>
<span class="p_add">+</span>
<span class="p_add">+	this_cpu_write(cpu_tlbstate.all_other_ctxs_invalid, true);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 /*
  * Save some of cr4 feature set we&#39;re using (e.g.  Pentium 4MB
  * enable and PPro Global page enable), so that any CPU&#39;s that boot
<span class="p_chunk">@@ -288,6 +312,10 @@</span> <span class="p_context"> static inline void __native_flush_tlb(vo</span>
 	preempt_disable();
 	native_write_cr3(__native_read_cr3());
 	preempt_enable();
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Does not need tlb_flush_shared_nonglobals() since the CR3 write</span>
<span class="p_add">+	 * without PCIDs flushes all non-globals.</span>
<span class="p_add">+	 */</span>
 }
 
 static inline void __native_flush_tlb_global_irq_disabled(void)
<span class="p_chunk">@@ -346,24 +374,23 @@</span> <span class="p_context"> static inline void __native_flush_tlb_si</span>
 
 static inline void __flush_tlb_all(void)
 {
<span class="p_del">-	if (boot_cpu_has(X86_FEATURE_PGE))</span>
<span class="p_add">+	if (boot_cpu_has(X86_FEATURE_PGE)) {</span>
 		__flush_tlb_global();
<span class="p_del">-	else</span>
<span class="p_add">+	} else {</span>
 		__flush_tlb();
<span class="p_del">-</span>
<span class="p_del">-	/*</span>
<span class="p_del">-	 * Note: if we somehow had PCID but not PGE, then this wouldn&#39;t work --</span>
<span class="p_del">-	 * we&#39;d end up flushing kernel translations for the current ASID but</span>
<span class="p_del">-	 * we might fail to flush kernel translations for other cached ASIDs.</span>
<span class="p_del">-	 *</span>
<span class="p_del">-	 * To avoid this issue, we force PCID off if PGE is off.</span>
<span class="p_del">-	 */</span>
<span class="p_add">+		tlb_flush_shared_nonglobals();</span>
<span class="p_add">+	}</span>
 }
 
 static inline void __flush_tlb_one(unsigned long addr)
 {
 	count_vm_tlb_event(NR_TLB_LOCAL_FLUSH_ONE);
 	__flush_tlb_single(addr);
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Invalidate other address spaces inaccessible to single-page</span>
<span class="p_add">+	 * invalidation:</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	tlb_flush_shared_nonglobals();</span>
 }
 
 #define TLB_FLUSH_ALL	-1UL
<span class="p_header">diff -puN arch/x86/mm/tlb.c~kaiser-pcid-pre-clear-pcid-cache arch/x86/mm/tlb.c</span>
<span class="p_header">--- a/arch/x86/mm/tlb.c~kaiser-pcid-pre-clear-pcid-cache	2017-11-08 10:45:37.848681374 -0800</span>
<span class="p_header">+++ b/arch/x86/mm/tlb.c	2017-11-08 10:45:37.852681374 -0800</span>
<span class="p_chunk">@@ -28,6 +28,38 @@</span> <span class="p_context"></span>
  *	Implement flush IPI by CALL_FUNCTION_VECTOR, Alex Shi
  */
 
<span class="p_add">+/*</span>
<span class="p_add">+ * We get here when we do something requiring a TLB invalidation</span>
<span class="p_add">+ * but could not go invalidate all of the contexts.  We do the</span>
<span class="p_add">+ * necessary invalidation by clearing out the &#39;ctx_id&#39; which</span>
<span class="p_add">+ * forces a TLB flush when the context is loaded.</span>
<span class="p_add">+ */</span>
<span class="p_add">+void clear_non_loaded_ctxs(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	u16 asid;</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * This is only expected to be set if we have disabled</span>
<span class="p_add">+	 * kernel _PAGE_GLOBAL pages.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+        if (IS_ENABLED(CONFIG_X86_GLOBAL_PAGES)) {</span>
<span class="p_add">+		WARN_ON_ONCE(1);</span>
<span class="p_add">+                return;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	for (asid = 0; asid &lt; TLB_NR_DYN_ASIDS; asid++) {</span>
<span class="p_add">+		/* Do not need to flush the current asid */</span>
<span class="p_add">+		if (asid == this_cpu_read(cpu_tlbstate.loaded_mm_asid))</span>
<span class="p_add">+			continue;</span>
<span class="p_add">+		/*</span>
<span class="p_add">+		 * Make sure the next time we go to switch to</span>
<span class="p_add">+		 * this asid, we do a flush:</span>
<span class="p_add">+		 */</span>
<span class="p_add">+		this_cpu_write(cpu_tlbstate.ctxs[asid].ctx_id, 0);</span>
<span class="p_add">+	}</span>
<span class="p_add">+	this_cpu_write(cpu_tlbstate.all_other_ctxs_invalid, false);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 atomic64_t last_mm_ctx_id = ATOMIC64_INIT(1);
 
 
<span class="p_chunk">@@ -42,6 +74,9 @@</span> <span class="p_context"> static void choose_new_asid(struct mm_st</span>
 		return;
 	}
 
<span class="p_add">+	if (this_cpu_read(cpu_tlbstate.all_other_ctxs_invalid))</span>
<span class="p_add">+		clear_non_loaded_ctxs();</span>
<span class="p_add">+</span>
 	for (asid = 0; asid &lt; TLB_NR_DYN_ASIDS; asid++) {
 		if (this_cpu_read(cpu_tlbstate.ctxs[asid].ctx_id) !=
 		    next-&gt;context.ctx_id)

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



