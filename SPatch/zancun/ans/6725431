
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>Linux 3.14.47 - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    Linux 3.14.47</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=37061">gregkh@linuxfoundation.org</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>July 6, 2015, 3:30 p.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;20150706153019.GB20673@kroah.com&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/6725431/mbox/"
   >mbox</a>
|
   <a href="/patch/6725431/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/6725431/">/patch/6725431/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
X-Original-To: patchwork-LKML@patchwork.kernel.org
Delivered-To: patchwork-parsemail@patchwork1.web.kernel.org
Received: from mail.kernel.org (mail.kernel.org [198.145.29.136])
	by patchwork1.web.kernel.org (Postfix) with ESMTP id F0B079F38C
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Mon,  6 Jul 2015 15:30:48 +0000 (UTC)
Received: from mail.kernel.org (localhost [127.0.0.1])
	by mail.kernel.org (Postfix) with ESMTP id E986B206D4
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Mon,  6 Jul 2015 15:30:45 +0000 (UTC)
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.kernel.org (Postfix) with ESMTP id 92BE1206BA
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Mon,  6 Jul 2015 15:30:42 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1753713AbbGFPa2 (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Mon, 6 Jul 2015 11:30:28 -0400
Received: from mail.linuxfoundation.org ([140.211.169.12]:54126 &quot;EHLO
	mail.linuxfoundation.org&quot; rhost-flags-OK-OK-OK-OK) by vger.kernel.org
	with ESMTP id S1753639AbbGFPaU (ORCPT
	&lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Mon, 6 Jul 2015 11:30:20 -0400
Received: from localhost (c-50-170-35-168.hsd1.wa.comcast.net
	[50.170.35.168])
	by mail.linuxfoundation.org (Postfix) with ESMTPSA id 07864B19;
	Mon,  6 Jul 2015 15:30:20 +0000 (UTC)
Date: Mon, 6 Jul 2015 08:30:19 -0700
From: Greg KH &lt;gregkh@linuxfoundation.org&gt;
To: linux-kernel@vger.kernel.org, Andrew Morton &lt;akpm@linux-foundation.org&gt;,
	torvalds@linux-foundation.org, stable@vger.kernel.org
Cc: lwn@lwn.net, Jiri Slaby &lt;jslaby@suse.cz&gt;
Subject: Re: Linux 3.14.47
Message-ID: &lt;20150706153019.GB20673@kroah.com&gt;
References: &lt;20150706153009.GA20673@kroah.com&gt;
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Disposition: inline
In-Reply-To: &lt;20150706153009.GA20673@kroah.com&gt;
User-Agent: Mutt/1.5.23+89 (0255b37be491) (2014-03-12)
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Spam-Status: No, score=-7.6 required=5.0 tests=BAYES_00, RCVD_IN_DNSWL_HI, 
	RP_MATCHES_RCVD,
	UNPARSEABLE_RELAY autolearn=unavailable version=3.3.1
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on mail.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=37061">gregkh@linuxfoundation.org</a> - July 6, 2015, 3:30 p.m.</div>
<pre class="content">
--
To unsubscribe from this list: send the line &quot;unsubscribe linux-kernel&quot; in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
Please read the FAQ at  http://www.tux.org/lkml/
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/Documentation/virtual/kvm/api.txt b/Documentation/virtual/kvm/api.txt</span>
<span class="p_header">index 6cd63a9010fb..bc6d61773ee2 100644</span>
<span class="p_header">--- a/Documentation/virtual/kvm/api.txt</span>
<span class="p_header">+++ b/Documentation/virtual/kvm/api.txt</span>
<span class="p_chunk">@@ -2344,7 +2344,8 @@</span> <span class="p_context"> should be created before this ioctl is invoked.</span>
 
 Possible features:
 	- KVM_ARM_VCPU_POWER_OFF: Starts the CPU in a power-off state.
<span class="p_del">-	  Depends on KVM_CAP_ARM_PSCI.</span>
<span class="p_add">+	  Depends on KVM_CAP_ARM_PSCI.  If not set, the CPU will be powered on</span>
<span class="p_add">+	  and execute guest code when KVM_RUN is called.</span>
 	- KVM_ARM_VCPU_EL1_32BIT: Starts the CPU in a 32bit mode.
 	  Depends on KVM_CAP_ARM_EL1_32BIT (arm64 only).
 
<span class="p_header">diff --git a/Makefile b/Makefile</span>
<span class="p_header">index def39fdd9df4..f9041e6d4d19 100644</span>
<span class="p_header">--- a/Makefile</span>
<span class="p_header">+++ b/Makefile</span>
<span class="p_chunk">@@ -1,6 +1,6 @@</span> <span class="p_context"></span>
 VERSION = 3
 PATCHLEVEL = 14
<span class="p_del">-SUBLEVEL = 46</span>
<span class="p_add">+SUBLEVEL = 47</span>
 EXTRAVERSION =
 NAME = Remembering Coco
 
<span class="p_header">diff --git a/arch/arm/include/asm/kvm_emulate.h b/arch/arm/include/asm/kvm_emulate.h</span>
<span class="p_header">index 0fa90c962ac8..853e2becad18 100644</span>
<span class="p_header">--- a/arch/arm/include/asm/kvm_emulate.h</span>
<span class="p_header">+++ b/arch/arm/include/asm/kvm_emulate.h</span>
<span class="p_chunk">@@ -33,6 +33,11 @@</span> <span class="p_context"> void kvm_inject_undefined(struct kvm_vcpu *vcpu);</span>
 void kvm_inject_dabt(struct kvm_vcpu *vcpu, unsigned long addr);
 void kvm_inject_pabt(struct kvm_vcpu *vcpu, unsigned long addr);
 
<span class="p_add">+static inline void vcpu_reset_hcr(struct kvm_vcpu *vcpu)</span>
<span class="p_add">+{</span>
<span class="p_add">+	vcpu-&gt;arch.hcr = HCR_GUEST_MASK;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static inline bool vcpu_mode_is_32bit(struct kvm_vcpu *vcpu)
 {
 	return 1;
<span class="p_header">diff --git a/arch/arm/include/asm/kvm_mmu.h b/arch/arm/include/asm/kvm_mmu.h</span>
<span class="p_header">index 0cbdb8ed71cf..9f7923193cda 100644</span>
<span class="p_header">--- a/arch/arm/include/asm/kvm_mmu.h</span>
<span class="p_header">+++ b/arch/arm/include/asm/kvm_mmu.h</span>
<span class="p_chunk">@@ -47,6 +47,7 @@</span> <span class="p_context"> int create_hyp_io_mappings(void *from, void *to, phys_addr_t);</span>
 void free_boot_hyp_pgd(void);
 void free_hyp_pgds(void);
 
<span class="p_add">+void stage2_unmap_vm(struct kvm *kvm);</span>
 int kvm_alloc_stage2_pgd(struct kvm *kvm);
 void kvm_free_stage2_pgd(struct kvm *kvm);
 int kvm_phys_addr_ioremap(struct kvm *kvm, phys_addr_t guest_ipa,
<span class="p_chunk">@@ -78,17 +79,6 @@</span> <span class="p_context"> static inline void kvm_set_pte(pte_t *pte, pte_t new_pte)</span>
 	flush_pmd_entry(pte);
 }
 
<span class="p_del">-static inline bool kvm_is_write_fault(unsigned long hsr)</span>
<span class="p_del">-{</span>
<span class="p_del">-	unsigned long hsr_ec = hsr &gt;&gt; HSR_EC_SHIFT;</span>
<span class="p_del">-	if (hsr_ec == HSR_EC_IABT)</span>
<span class="p_del">-		return false;</span>
<span class="p_del">-	else if ((hsr &amp; HSR_ISV) &amp;&amp; !(hsr &amp; HSR_WNR))</span>
<span class="p_del">-		return false;</span>
<span class="p_del">-	else</span>
<span class="p_del">-		return true;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
 static inline void kvm_clean_pgd(pgd_t *pgd)
 {
 	clean_dcache_area(pgd, PTRS_PER_S2_PGD * sizeof(pgd_t));
<span class="p_header">diff --git a/arch/arm/kvm/arm.c b/arch/arm/kvm/arm.c</span>
<span class="p_header">index df6e75e47ae0..2e74a617147d 100644</span>
<span class="p_header">--- a/arch/arm/kvm/arm.c</span>
<span class="p_header">+++ b/arch/arm/kvm/arm.c</span>
<span class="p_chunk">@@ -220,6 +220,11 @@</span> <span class="p_context"> struct kvm_vcpu *kvm_arch_vcpu_create(struct kvm *kvm, unsigned int id)</span>
 	int err;
 	struct kvm_vcpu *vcpu;
 
<span class="p_add">+	if (irqchip_in_kernel(kvm) &amp;&amp; vgic_initialized(kvm)) {</span>
<span class="p_add">+		err = -EBUSY;</span>
<span class="p_add">+		goto out;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
 	vcpu = kmem_cache_zalloc(kvm_vcpu_cache, GFP_KERNEL);
 	if (!vcpu) {
 		err = -ENOMEM;
<span class="p_chunk">@@ -427,9 +432,9 @@</span> <span class="p_context"> static void update_vttbr(struct kvm *kvm)</span>
 
 	/* update vttbr to be used with the new vmid */
 	pgd_phys = virt_to_phys(kvm-&gt;arch.pgd);
<span class="p_add">+	BUG_ON(pgd_phys &amp; ~VTTBR_BADDR_MASK);</span>
 	vmid = ((u64)(kvm-&gt;arch.vmid) &lt;&lt; VTTBR_VMID_SHIFT) &amp; VTTBR_VMID_MASK;
<span class="p_del">-	kvm-&gt;arch.vttbr = pgd_phys &amp; VTTBR_BADDR_MASK;</span>
<span class="p_del">-	kvm-&gt;arch.vttbr |= vmid;</span>
<span class="p_add">+	kvm-&gt;arch.vttbr = pgd_phys | vmid;</span>
 
 	spin_unlock(&amp;kvm_vmid_lock);
 }
<span class="p_chunk">@@ -676,10 +681,21 @@</span> <span class="p_context"> static int kvm_arch_vcpu_ioctl_vcpu_init(struct kvm_vcpu *vcpu,</span>
 		return ret;
 
 	/*
<span class="p_add">+	 * Ensure a rebooted VM will fault in RAM pages and detect if the</span>
<span class="p_add">+	 * guest MMU is turned off and flush the caches as needed.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	if (vcpu-&gt;arch.has_run_once)</span>
<span class="p_add">+		stage2_unmap_vm(vcpu-&gt;kvm);</span>
<span class="p_add">+</span>
<span class="p_add">+	vcpu_reset_hcr(vcpu);</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
 	 * Handle the &quot;start in power-off&quot; case by marking the VCPU as paused.
 	 */
<span class="p_del">-	if (__test_and_clear_bit(KVM_ARM_VCPU_POWER_OFF, vcpu-&gt;arch.features))</span>
<span class="p_add">+	if (test_bit(KVM_ARM_VCPU_POWER_OFF, vcpu-&gt;arch.features))</span>
 		vcpu-&gt;arch.pause = true;
<span class="p_add">+	else</span>
<span class="p_add">+		vcpu-&gt;arch.pause = false;</span>
 
 	return 0;
 }
<span class="p_chunk">@@ -825,7 +841,8 @@</span> <span class="p_context"> static int hyp_init_cpu_notify(struct notifier_block *self,</span>
 	switch (action) {
 	case CPU_STARTING:
 	case CPU_STARTING_FROZEN:
<span class="p_del">-		cpu_init_hyp_mode(NULL);</span>
<span class="p_add">+		if (__hyp_get_vectors() == hyp_default_vectors)</span>
<span class="p_add">+			cpu_init_hyp_mode(NULL);</span>
 		break;
 	}
 
<span class="p_header">diff --git a/arch/arm/kvm/guest.c b/arch/arm/kvm/guest.c</span>
<span class="p_header">index b23a59c1c522..2786eae10c0d 100644</span>
<span class="p_header">--- a/arch/arm/kvm/guest.c</span>
<span class="p_header">+++ b/arch/arm/kvm/guest.c</span>
<span class="p_chunk">@@ -38,7 +38,6 @@</span> <span class="p_context"> struct kvm_stats_debugfs_item debugfs_entries[] = {</span>
 
 int kvm_arch_vcpu_setup(struct kvm_vcpu *vcpu)
 {
<span class="p_del">-	vcpu-&gt;arch.hcr = HCR_GUEST_MASK;</span>
 	return 0;
 }
 
<span class="p_header">diff --git a/arch/arm/kvm/mmu.c b/arch/arm/kvm/mmu.c</span>
<span class="p_header">index 70ed2c1f57b0..524b4b57f650 100644</span>
<span class="p_header">--- a/arch/arm/kvm/mmu.c</span>
<span class="p_header">+++ b/arch/arm/kvm/mmu.c</span>
<span class="p_chunk">@@ -197,7 +197,8 @@</span> <span class="p_context"> static void unmap_range(struct kvm *kvm, pgd_t *pgdp,</span>
 	pgd = pgdp + pgd_index(addr);
 	do {
 		next = kvm_pgd_addr_end(addr, end);
<span class="p_del">-		unmap_puds(kvm, pgd, addr, next);</span>
<span class="p_add">+		if (!pgd_none(*pgd))</span>
<span class="p_add">+			unmap_puds(kvm, pgd, addr, next);</span>
 	} while (pgd++, addr = next, addr != end);
 }
 
<span class="p_chunk">@@ -555,6 +556,71 @@</span> <span class="p_context"> static void unmap_stage2_range(struct kvm *kvm, phys_addr_t start, u64 size)</span>
 	unmap_range(kvm, kvm-&gt;arch.pgd, start, size);
 }
 
<span class="p_add">+static void stage2_unmap_memslot(struct kvm *kvm,</span>
<span class="p_add">+				 struct kvm_memory_slot *memslot)</span>
<span class="p_add">+{</span>
<span class="p_add">+	hva_t hva = memslot-&gt;userspace_addr;</span>
<span class="p_add">+	phys_addr_t addr = memslot-&gt;base_gfn &lt;&lt; PAGE_SHIFT;</span>
<span class="p_add">+	phys_addr_t size = PAGE_SIZE * memslot-&gt;npages;</span>
<span class="p_add">+	hva_t reg_end = hva + size;</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * A memory region could potentially cover multiple VMAs, and any holes</span>
<span class="p_add">+	 * between them, so iterate over all of them to find out if we should</span>
<span class="p_add">+	 * unmap any of them.</span>
<span class="p_add">+	 *</span>
<span class="p_add">+	 *     +--------------------------------------------+</span>
<span class="p_add">+	 * +---------------+----------------+   +----------------+</span>
<span class="p_add">+	 * |   : VMA 1     |      VMA 2     |   |    VMA 3  :    |</span>
<span class="p_add">+	 * +---------------+----------------+   +----------------+</span>
<span class="p_add">+	 *     |               memory region                |</span>
<span class="p_add">+	 *     +--------------------------------------------+</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	do {</span>
<span class="p_add">+		struct vm_area_struct *vma = find_vma(current-&gt;mm, hva);</span>
<span class="p_add">+		hva_t vm_start, vm_end;</span>
<span class="p_add">+</span>
<span class="p_add">+		if (!vma || vma-&gt;vm_start &gt;= reg_end)</span>
<span class="p_add">+			break;</span>
<span class="p_add">+</span>
<span class="p_add">+		/*</span>
<span class="p_add">+		 * Take the intersection of this VMA with the memory region</span>
<span class="p_add">+		 */</span>
<span class="p_add">+		vm_start = max(hva, vma-&gt;vm_start);</span>
<span class="p_add">+		vm_end = min(reg_end, vma-&gt;vm_end);</span>
<span class="p_add">+</span>
<span class="p_add">+		if (!(vma-&gt;vm_flags &amp; VM_PFNMAP)) {</span>
<span class="p_add">+			gpa_t gpa = addr + (vm_start - memslot-&gt;userspace_addr);</span>
<span class="p_add">+			unmap_stage2_range(kvm, gpa, vm_end - vm_start);</span>
<span class="p_add">+		}</span>
<span class="p_add">+		hva = vm_end;</span>
<span class="p_add">+	} while (hva &lt; reg_end);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+/**</span>
<span class="p_add">+ * stage2_unmap_vm - Unmap Stage-2 RAM mappings</span>
<span class="p_add">+ * @kvm: The struct kvm pointer</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * Go through the memregions and unmap any reguler RAM</span>
<span class="p_add">+ * backing memory already mapped to the VM.</span>
<span class="p_add">+ */</span>
<span class="p_add">+void stage2_unmap_vm(struct kvm *kvm)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct kvm_memslots *slots;</span>
<span class="p_add">+	struct kvm_memory_slot *memslot;</span>
<span class="p_add">+	int idx;</span>
<span class="p_add">+</span>
<span class="p_add">+	idx = srcu_read_lock(&amp;kvm-&gt;srcu);</span>
<span class="p_add">+	spin_lock(&amp;kvm-&gt;mmu_lock);</span>
<span class="p_add">+</span>
<span class="p_add">+	slots = kvm_memslots(kvm);</span>
<span class="p_add">+	kvm_for_each_memslot(memslot, slots)</span>
<span class="p_add">+		stage2_unmap_memslot(kvm, memslot);</span>
<span class="p_add">+</span>
<span class="p_add">+	spin_unlock(&amp;kvm-&gt;mmu_lock);</span>
<span class="p_add">+	srcu_read_unlock(&amp;kvm-&gt;srcu, idx);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 /**
  * kvm_free_stage2_pgd - free all stage-2 tables
  * @kvm:	The KVM struct pointer for the VM.
<span class="p_chunk">@@ -746,6 +812,19 @@</span> <span class="p_context"> static bool transparent_hugepage_adjust(pfn_t *pfnp, phys_addr_t *ipap)</span>
 	return false;
 }
 
<span class="p_add">+static bool kvm_is_write_fault(struct kvm_vcpu *vcpu)</span>
<span class="p_add">+{</span>
<span class="p_add">+	if (kvm_vcpu_trap_is_iabt(vcpu))</span>
<span class="p_add">+		return false;</span>
<span class="p_add">+</span>
<span class="p_add">+	return kvm_vcpu_dabt_iswrite(vcpu);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static bool kvm_is_device_pfn(unsigned long pfn)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return !pfn_valid(pfn);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static int user_mem_abort(struct kvm_vcpu *vcpu, phys_addr_t fault_ipa,
 			  struct kvm_memory_slot *memslot,
 			  unsigned long fault_status)
<span class="p_chunk">@@ -761,7 +840,7 @@</span> <span class="p_context"> static int user_mem_abort(struct kvm_vcpu *vcpu, phys_addr_t fault_ipa,</span>
 	pfn_t pfn;
 	pgprot_t mem_type = PAGE_S2;
 
<span class="p_del">-	write_fault = kvm_is_write_fault(kvm_vcpu_get_hsr(vcpu));</span>
<span class="p_add">+	write_fault = kvm_is_write_fault(vcpu);</span>
 	if (fault_status == FSC_PERM &amp;&amp; !write_fault) {
 		kvm_err(&quot;Unexpected L2 read permission error\n&quot;);
 		return -EFAULT;
<span class="p_chunk">@@ -770,6 +849,12 @@</span> <span class="p_context"> static int user_mem_abort(struct kvm_vcpu *vcpu, phys_addr_t fault_ipa,</span>
 	/* Let&#39;s check if we will get back a huge page backed by hugetlbfs */
 	down_read(&amp;current-&gt;mm-&gt;mmap_sem);
 	vma = find_vma_intersection(current-&gt;mm, hva, hva + 1);
<span class="p_add">+	if (unlikely(!vma)) {</span>
<span class="p_add">+		kvm_err(&quot;Failed to find VMA for hva 0x%lx\n&quot;, hva);</span>
<span class="p_add">+		up_read(&amp;current-&gt;mm-&gt;mmap_sem);</span>
<span class="p_add">+		return -EFAULT;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
 	if (is_vm_hugetlb_page(vma)) {
 		hugetlb = true;
 		gfn = (fault_ipa &amp; PMD_MASK) &gt;&gt; PAGE_SHIFT;
<span class="p_chunk">@@ -810,7 +895,7 @@</span> <span class="p_context"> static int user_mem_abort(struct kvm_vcpu *vcpu, phys_addr_t fault_ipa,</span>
 	if (is_error_pfn(pfn))
 		return -EFAULT;
 
<span class="p_del">-	if (kvm_is_mmio_pfn(pfn))</span>
<span class="p_add">+	if (kvm_is_device_pfn(pfn))</span>
 		mem_type = PAGE_S2_DEVICE;
 
 	spin_lock(&amp;kvm-&gt;mmu_lock);
<span class="p_chunk">@@ -836,7 +921,7 @@</span> <span class="p_context"> static int user_mem_abort(struct kvm_vcpu *vcpu, phys_addr_t fault_ipa,</span>
 		}
 		coherent_cache_guest_page(vcpu, hva, PAGE_SIZE);
 		ret = stage2_set_pte(kvm, memcache, fault_ipa, &amp;new_pte,
<span class="p_del">-				     mem_type == PAGE_S2_DEVICE);</span>
<span class="p_add">+			pgprot_val(mem_type) == pgprot_val(PAGE_S2_DEVICE));</span>
 	}
 
 
<span class="p_chunk">@@ -912,6 +997,9 @@</span> <span class="p_context"> int kvm_handle_guest_abort(struct kvm_vcpu *vcpu, struct kvm_run *run)</span>
 
 	memslot = gfn_to_memslot(vcpu-&gt;kvm, gfn);
 
<span class="p_add">+	/* Userspace should not be able to register out-of-bounds IPAs */</span>
<span class="p_add">+	VM_BUG_ON(fault_ipa &gt;= KVM_PHYS_SIZE);</span>
<span class="p_add">+</span>
 	ret = user_mem_abort(vcpu, fault_ipa, memslot, fault_status);
 	if (ret == 0)
 		ret = 1;
<span class="p_chunk">@@ -1136,6 +1224,14 @@</span> <span class="p_context"> int kvm_arch_prepare_memory_region(struct kvm *kvm,</span>
 				   struct kvm_userspace_memory_region *mem,
 				   enum kvm_mr_change change)
 {
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Prevent userspace from creating a memory region outside of the IPA</span>
<span class="p_add">+	 * space addressable by the KVM guest IPA space.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	if (memslot-&gt;base_gfn + memslot-&gt;npages &gt;=</span>
<span class="p_add">+	    (KVM_PHYS_SIZE &gt;&gt; PAGE_SHIFT))</span>
<span class="p_add">+		return -EFAULT;</span>
<span class="p_add">+</span>
 	return 0;
 }
 
<span class="p_header">diff --git a/arch/arm/mach-dove/board-dt.c b/arch/arm/mach-dove/board-dt.c</span>
<span class="p_header">index 49fa9abd09da..7a7a09a5d5ff 100644</span>
<span class="p_header">--- a/arch/arm/mach-dove/board-dt.c</span>
<span class="p_header">+++ b/arch/arm/mach-dove/board-dt.c</span>
<span class="p_chunk">@@ -26,7 +26,7 @@</span> <span class="p_context"> static void __init dove_dt_init(void)</span>
 #ifdef CONFIG_CACHE_TAUROS2
 	tauros2_init(0);
 #endif
<span class="p_del">-	BUG_ON(mvebu_mbus_dt_init());</span>
<span class="p_add">+	BUG_ON(mvebu_mbus_dt_init(false));</span>
 	of_platform_populate(NULL, of_default_bus_match_table, NULL, NULL);
 }
 
<span class="p_header">diff --git a/arch/arm/mach-imx/clk-imx6q.c b/arch/arm/mach-imx/clk-imx6q.c</span>
<span class="p_header">index 01a5765a8b26..b509556f6cfd 100644</span>
<span class="p_header">--- a/arch/arm/mach-imx/clk-imx6q.c</span>
<span class="p_header">+++ b/arch/arm/mach-imx/clk-imx6q.c</span>
<span class="p_chunk">@@ -406,7 +406,7 @@</span> <span class="p_context"> static void __init imx6q_clocks_init(struct device_node *ccm_node)</span>
 	clk[gpmi_io]      = imx_clk_gate2(&quot;gpmi_io&quot;,       &quot;enfc&quot;,              base + 0x78, 28);
 	clk[gpmi_apb]     = imx_clk_gate2(&quot;gpmi_apb&quot;,      &quot;usdhc3&quot;,            base + 0x78, 30);
 	clk[rom]          = imx_clk_gate2(&quot;rom&quot;,           &quot;ahb&quot;,               base + 0x7c, 0);
<span class="p_del">-	clk[sata]         = imx_clk_gate2(&quot;sata&quot;,          &quot;ipg&quot;,               base + 0x7c, 4);</span>
<span class="p_add">+	clk[sata]         = imx_clk_gate2(&quot;sata&quot;,          &quot;ahb&quot;,               base + 0x7c, 4);</span>
 	clk[sdma]         = imx_clk_gate2(&quot;sdma&quot;,          &quot;ahb&quot;,               base + 0x7c, 6);
 	clk[spba]         = imx_clk_gate2(&quot;spba&quot;,          &quot;ipg&quot;,               base + 0x7c, 12);
 	clk[spdif]        = imx_clk_gate2(&quot;spdif&quot;,         &quot;spdif_podf&quot;,    	base + 0x7c, 14);
<span class="p_header">diff --git a/arch/arm/mach-kirkwood/board-dt.c b/arch/arm/mach-kirkwood/board-dt.c</span>
<span class="p_header">index 78188159484d..79e629da1c92 100644</span>
<span class="p_header">--- a/arch/arm/mach-kirkwood/board-dt.c</span>
<span class="p_header">+++ b/arch/arm/mach-kirkwood/board-dt.c</span>
<span class="p_chunk">@@ -116,7 +116,7 @@</span> <span class="p_context"> static void __init kirkwood_dt_init(void)</span>
 	 */
 	writel(readl(CPU_CONFIG) &amp; ~CPU_CONFIG_ERROR_PROP, CPU_CONFIG);
 
<span class="p_del">-	BUG_ON(mvebu_mbus_dt_init());</span>
<span class="p_add">+	BUG_ON(mvebu_mbus_dt_init(false));</span>
 
 	kirkwood_l2_init();
 
<span class="p_header">diff --git a/arch/arm/mach-mvebu/armada-370-xp.c b/arch/arm/mach-mvebu/armada-370-xp.c</span>
<span class="p_header">index f6c9d1d85c14..79c3766a56fd 100644</span>
<span class="p_header">--- a/arch/arm/mach-mvebu/armada-370-xp.c</span>
<span class="p_header">+++ b/arch/arm/mach-mvebu/armada-370-xp.c</span>
<span class="p_chunk">@@ -41,7 +41,7 @@</span> <span class="p_context"> static void __init armada_370_xp_timer_and_clk_init(void)</span>
 	of_clk_init(NULL);
 	clocksource_of_init();
 	coherency_init();
<span class="p_del">-	BUG_ON(mvebu_mbus_dt_init());</span>
<span class="p_add">+	BUG_ON(mvebu_mbus_dt_init(coherency_available()));</span>
 #ifdef CONFIG_CACHE_L2X0
 	l2x0_of_init(0, ~0UL);
 #endif
<span class="p_header">diff --git a/arch/arm/mach-mvebu/coherency.c b/arch/arm/mach-mvebu/coherency.c</span>
<span class="p_header">index c295c10f9217..49bad4d66fa2 100644</span>
<span class="p_header">--- a/arch/arm/mach-mvebu/coherency.c</span>
<span class="p_header">+++ b/arch/arm/mach-mvebu/coherency.c</span>
<span class="p_chunk">@@ -121,6 +121,20 @@</span> <span class="p_context"> static struct notifier_block mvebu_hwcc_platform_nb = {</span>
 	.notifier_call = mvebu_hwcc_platform_notifier,
 };
 
<span class="p_add">+/*</span>
<span class="p_add">+ * Keep track of whether we have IO hardware coherency enabled or not.</span>
<span class="p_add">+ * On Armada 370&#39;s we will not be using it for example. We need to make</span>
<span class="p_add">+ * that available [through coherency_available()] so the mbus controller</span>
<span class="p_add">+ * doesn&#39;t enable the IO coherency bit in the attribute bits of the</span>
<span class="p_add">+ * chip selects.</span>
<span class="p_add">+ */</span>
<span class="p_add">+static int coherency_enabled;</span>
<span class="p_add">+</span>
<span class="p_add">+int coherency_available(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return coherency_enabled;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 int __init coherency_init(void)
 {
 	struct device_node *np;
<span class="p_chunk">@@ -164,6 +178,7 @@</span> <span class="p_context"> int __init coherency_init(void)</span>
 		coherency_base = of_iomap(np, 0);
 		coherency_cpu_base = of_iomap(np, 1);
 		set_cpu_coherent(cpu_logical_map(smp_processor_id()), 0);
<span class="p_add">+		coherency_enabled = 1;</span>
 		of_node_put(np);
 	}
 
<span class="p_header">diff --git a/arch/arm/mach-mvebu/coherency.h b/arch/arm/mach-mvebu/coherency.h</span>
<span class="p_header">index 760226c41353..63e18c64a8e3 100644</span>
<span class="p_header">--- a/arch/arm/mach-mvebu/coherency.h</span>
<span class="p_header">+++ b/arch/arm/mach-mvebu/coherency.h</span>
<span class="p_chunk">@@ -17,6 +17,7 @@</span> <span class="p_context"></span>
 extern unsigned long coherency_phys_base;
 
 int set_cpu_coherent(unsigned int cpu_id, int smp_group_id);
<span class="p_add">+int coherency_available(void);</span>
 int coherency_init(void);
 
 #endif	/* __MACH_370_XP_COHERENCY_H */
<span class="p_header">diff --git a/arch/arm64/include/asm/kvm_arm.h b/arch/arm64/include/asm/kvm_arm.h</span>
<span class="p_header">index 00fbaa75dc7b..ea68925a4480 100644</span>
<span class="p_header">--- a/arch/arm64/include/asm/kvm_arm.h</span>
<span class="p_header">+++ b/arch/arm64/include/asm/kvm_arm.h</span>
<span class="p_chunk">@@ -18,6 +18,7 @@</span> <span class="p_context"></span>
 #ifndef __ARM64_KVM_ARM_H__
 #define __ARM64_KVM_ARM_H__
 
<span class="p_add">+#include &lt;asm/memory.h&gt;</span>
 #include &lt;asm/types.h&gt;
 
 /* Hyp Configuration Register (HCR) bits */
<span class="p_chunk">@@ -122,6 +123,17 @@</span> <span class="p_context"></span>
 #define VTCR_EL2_T0SZ_MASK	0x3f
 #define VTCR_EL2_T0SZ_40B	24
 
<span class="p_add">+/*</span>
<span class="p_add">+ * We configure the Stage-2 page tables to always restrict the IPA space to be</span>
<span class="p_add">+ * 40 bits wide (T0SZ = 24).  Systems with a PARange smaller than 40 bits are</span>
<span class="p_add">+ * not known to exist and will break with this configuration.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * Note that when using 4K pages, we concatenate two first level page tables</span>
<span class="p_add">+ * together.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * The magic numbers used for VTTBR_X in this patch can be found in Tables</span>
<span class="p_add">+ * D4-23 and D4-25 in ARM DDI 0487A.b.</span>
<span class="p_add">+ */</span>
 #ifdef CONFIG_ARM64_64K_PAGES
 /*
  * Stage2 translation configuration:
<span class="p_chunk">@@ -151,9 +163,9 @@</span> <span class="p_context"></span>
 #endif
 
 #define VTTBR_BADDR_SHIFT (VTTBR_X - 1)
<span class="p_del">-#define VTTBR_BADDR_MASK  (((1LLU &lt;&lt; (40 - VTTBR_X)) - 1) &lt;&lt; VTTBR_BADDR_SHIFT)</span>
<span class="p_del">-#define VTTBR_VMID_SHIFT  (48LLU)</span>
<span class="p_del">-#define VTTBR_VMID_MASK	  (0xffLLU &lt;&lt; VTTBR_VMID_SHIFT)</span>
<span class="p_add">+#define VTTBR_BADDR_MASK  (((UL(1) &lt;&lt; (PHYS_MASK_SHIFT - VTTBR_X)) - 1) &lt;&lt; VTTBR_BADDR_SHIFT)</span>
<span class="p_add">+#define VTTBR_VMID_SHIFT  (UL(48))</span>
<span class="p_add">+#define VTTBR_VMID_MASK	  (UL(0xFF) &lt;&lt; VTTBR_VMID_SHIFT)</span>
 
 /* Hyp System Trap Register */
 #define HSTR_EL2_TTEE	(1 &lt;&lt; 16)
<span class="p_chunk">@@ -176,13 +188,13 @@</span> <span class="p_context"></span>
 
 /* Exception Syndrome Register (ESR) bits */
 #define ESR_EL2_EC_SHIFT	(26)
<span class="p_del">-#define ESR_EL2_EC		(0x3fU &lt;&lt; ESR_EL2_EC_SHIFT)</span>
<span class="p_del">-#define ESR_EL2_IL		(1U &lt;&lt; 25)</span>
<span class="p_add">+#define ESR_EL2_EC		(UL(0x3f) &lt;&lt; ESR_EL2_EC_SHIFT)</span>
<span class="p_add">+#define ESR_EL2_IL		(UL(1) &lt;&lt; 25)</span>
 #define ESR_EL2_ISS		(ESR_EL2_IL - 1)
 #define ESR_EL2_ISV_SHIFT	(24)
<span class="p_del">-#define ESR_EL2_ISV		(1U &lt;&lt; ESR_EL2_ISV_SHIFT)</span>
<span class="p_add">+#define ESR_EL2_ISV		(UL(1) &lt;&lt; ESR_EL2_ISV_SHIFT)</span>
 #define ESR_EL2_SAS_SHIFT	(22)
<span class="p_del">-#define ESR_EL2_SAS		(3U &lt;&lt; ESR_EL2_SAS_SHIFT)</span>
<span class="p_add">+#define ESR_EL2_SAS		(UL(3) &lt;&lt; ESR_EL2_SAS_SHIFT)</span>
 #define ESR_EL2_SSE		(1 &lt;&lt; 21)
 #define ESR_EL2_SRT_SHIFT	(16)
 #define ESR_EL2_SRT_MASK	(0x1f &lt;&lt; ESR_EL2_SRT_SHIFT)
<span class="p_chunk">@@ -196,16 +208,16 @@</span> <span class="p_context"></span>
 #define ESR_EL2_FSC_TYPE	(0x3c)
 
 #define ESR_EL2_CV_SHIFT	(24)
<span class="p_del">-#define ESR_EL2_CV		(1U &lt;&lt; ESR_EL2_CV_SHIFT)</span>
<span class="p_add">+#define ESR_EL2_CV		(UL(1) &lt;&lt; ESR_EL2_CV_SHIFT)</span>
 #define ESR_EL2_COND_SHIFT	(20)
<span class="p_del">-#define ESR_EL2_COND		(0xfU &lt;&lt; ESR_EL2_COND_SHIFT)</span>
<span class="p_add">+#define ESR_EL2_COND		(UL(0xf) &lt;&lt; ESR_EL2_COND_SHIFT)</span>
 
 
 #define FSC_FAULT	(0x04)
 #define FSC_PERM	(0x0c)
 
 /* Hyp Prefetch Fault Address Register (HPFAR/HDFAR) */
<span class="p_del">-#define HPFAR_MASK	(~0xFUL)</span>
<span class="p_add">+#define HPFAR_MASK	(~UL(0xf))</span>
 
 #define ESR_EL2_EC_UNKNOWN	(0x00)
 #define ESR_EL2_EC_WFI		(0x01)
<span class="p_header">diff --git a/arch/arm64/include/asm/kvm_emulate.h b/arch/arm64/include/asm/kvm_emulate.h</span>
<span class="p_header">index dd8ecfc3f995..681cb9080100 100644</span>
<span class="p_header">--- a/arch/arm64/include/asm/kvm_emulate.h</span>
<span class="p_header">+++ b/arch/arm64/include/asm/kvm_emulate.h</span>
<span class="p_chunk">@@ -38,6 +38,11 @@</span> <span class="p_context"> void kvm_inject_undefined(struct kvm_vcpu *vcpu);</span>
 void kvm_inject_dabt(struct kvm_vcpu *vcpu, unsigned long addr);
 void kvm_inject_pabt(struct kvm_vcpu *vcpu, unsigned long addr);
 
<span class="p_add">+static inline void vcpu_reset_hcr(struct kvm_vcpu *vcpu)</span>
<span class="p_add">+{</span>
<span class="p_add">+	vcpu-&gt;arch.hcr_el2 = HCR_GUEST_FLAGS;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static inline unsigned long *vcpu_pc(const struct kvm_vcpu *vcpu)
 {
 	return (unsigned long *)&amp;vcpu_gp_regs(vcpu)-&gt;regs.pc;
<span class="p_header">diff --git a/arch/arm64/include/asm/kvm_mmu.h b/arch/arm64/include/asm/kvm_mmu.h</span>
<span class="p_header">index 8e138c7c53ac..0d51874c838f 100644</span>
<span class="p_header">--- a/arch/arm64/include/asm/kvm_mmu.h</span>
<span class="p_header">+++ b/arch/arm64/include/asm/kvm_mmu.h</span>
<span class="p_chunk">@@ -59,10 +59,9 @@</span> <span class="p_context"></span>
 #define KERN_TO_HYP(kva)	((unsigned long)kva - PAGE_OFFSET + HYP_PAGE_OFFSET)
 
 /*
<span class="p_del">- * Align KVM with the kernel&#39;s view of physical memory. Should be</span>
<span class="p_del">- * 40bit IPA, with PGD being 8kB aligned in the 4KB page configuration.</span>
<span class="p_add">+ * We currently only support a 40bit IPA.</span>
  */
<span class="p_del">-#define KVM_PHYS_SHIFT	PHYS_MASK_SHIFT</span>
<span class="p_add">+#define KVM_PHYS_SHIFT	(40)</span>
 #define KVM_PHYS_SIZE	(1UL &lt;&lt; KVM_PHYS_SHIFT)
 #define KVM_PHYS_MASK	(KVM_PHYS_SIZE - 1UL)
 
<span class="p_chunk">@@ -75,6 +74,7 @@</span> <span class="p_context"> int create_hyp_io_mappings(void *from, void *to, phys_addr_t);</span>
 void free_boot_hyp_pgd(void);
 void free_hyp_pgds(void);
 
<span class="p_add">+void stage2_unmap_vm(struct kvm *kvm);</span>
 int kvm_alloc_stage2_pgd(struct kvm *kvm);
 void kvm_free_stage2_pgd(struct kvm *kvm);
 int kvm_phys_addr_ioremap(struct kvm *kvm, phys_addr_t guest_ipa,
<span class="p_chunk">@@ -93,19 +93,6 @@</span> <span class="p_context"> void kvm_clear_hyp_idmap(void);</span>
 #define	kvm_set_pte(ptep, pte)		set_pte(ptep, pte)
 #define	kvm_set_pmd(pmdp, pmd)		set_pmd(pmdp, pmd)
 
<span class="p_del">-static inline bool kvm_is_write_fault(unsigned long esr)</span>
<span class="p_del">-{</span>
<span class="p_del">-	unsigned long esr_ec = esr &gt;&gt; ESR_EL2_EC_SHIFT;</span>
<span class="p_del">-</span>
<span class="p_del">-	if (esr_ec == ESR_EL2_EC_IABT)</span>
<span class="p_del">-		return false;</span>
<span class="p_del">-</span>
<span class="p_del">-	if ((esr &amp; ESR_EL2_ISV) &amp;&amp; !(esr &amp; ESR_EL2_WNR))</span>
<span class="p_del">-		return false;</span>
<span class="p_del">-</span>
<span class="p_del">-	return true;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
 static inline void kvm_clean_pgd(pgd_t *pgd) {}
 static inline void kvm_clean_pmd_entry(pmd_t *pmd) {}
 static inline void kvm_clean_pte(pte_t *pte) {}
<span class="p_header">diff --git a/arch/arm64/kvm/guest.c b/arch/arm64/kvm/guest.c</span>
<span class="p_header">index 08745578d54d..a8d81fa8c527 100644</span>
<span class="p_header">--- a/arch/arm64/kvm/guest.c</span>
<span class="p_header">+++ b/arch/arm64/kvm/guest.c</span>
<span class="p_chunk">@@ -38,7 +38,6 @@</span> <span class="p_context"> struct kvm_stats_debugfs_item debugfs_entries[] = {</span>
 
 int kvm_arch_vcpu_setup(struct kvm_vcpu *vcpu)
 {
<span class="p_del">-	vcpu-&gt;arch.hcr_el2 = HCR_GUEST_FLAGS;</span>
 	return 0;
 }
 
<span class="p_header">diff --git a/arch/arm64/mm/dma-mapping.c b/arch/arm64/mm/dma-mapping.c</span>
<span class="p_header">index 3974881388bb..b76159a153a5 100644</span>
<span class="p_header">--- a/arch/arm64/mm/dma-mapping.c</span>
<span class="p_header">+++ b/arch/arm64/mm/dma-mapping.c</span>
<span class="p_chunk">@@ -54,8 +54,7 @@</span> <span class="p_context"> static void *arm64_swiotlb_alloc_coherent(struct device *dev, size_t size,</span>
 
 		*dma_handle = phys_to_dma(dev, page_to_phys(page));
 		addr = page_address(page);
<span class="p_del">-		if (flags &amp; __GFP_ZERO)</span>
<span class="p_del">-			memset(addr, 0, size);</span>
<span class="p_add">+		memset(addr, 0, size);</span>
 		return addr;
 	} else {
 		return swiotlb_alloc_coherent(dev, size, dma_handle, flags);
<span class="p_header">diff --git a/arch/x86/Kconfig b/arch/x86/Kconfig</span>
<span class="p_header">index 2f645c90e4d8..5dab54accc56 100644</span>
<span class="p_header">--- a/arch/x86/Kconfig</span>
<span class="p_header">+++ b/arch/x86/Kconfig</span>
<span class="p_chunk">@@ -160,7 +160,7 @@</span> <span class="p_context"> config SBUS</span>
 
 config NEED_DMA_MAP_STATE
 	def_bool y
<span class="p_del">-	depends on X86_64 || INTEL_IOMMU || DMA_API_DEBUG</span>
<span class="p_add">+	depends on X86_64 || INTEL_IOMMU || DMA_API_DEBUG || SWIOTLB</span>
 
 config NEED_SG_DMA_LENGTH
 	def_bool y
<span class="p_header">diff --git a/arch/x86/kernel/cpu/microcode/intel_early.c b/arch/x86/kernel/cpu/microcode/intel_early.c</span>
<span class="p_header">index 18f739129e72..43a07bf48dea 100644</span>
<span class="p_header">--- a/arch/x86/kernel/cpu/microcode/intel_early.c</span>
<span class="p_header">+++ b/arch/x86/kernel/cpu/microcode/intel_early.c</span>
<span class="p_chunk">@@ -321,7 +321,7 @@</span> <span class="p_context"> get_matching_model_microcode(int cpu, unsigned long start,</span>
 	unsigned int mc_saved_count = mc_saved_data-&gt;mc_saved_count;
 	int i;
 
<span class="p_del">-	while (leftover) {</span>
<span class="p_add">+	while (leftover &amp;&amp; mc_saved_count &lt; ARRAY_SIZE(mc_saved_tmp)) {</span>
 		mc_header = (struct microcode_header_intel *)ucode_ptr;
 
 		mc_size = get_totalsize(mc_header);
<span class="p_header">diff --git a/arch/x86/kernel/kprobes/core.c b/arch/x86/kernel/kprobes/core.c</span>
<span class="p_header">index a1f5b1866cbe..490fee15fea5 100644</span>
<span class="p_header">--- a/arch/x86/kernel/kprobes/core.c</span>
<span class="p_header">+++ b/arch/x86/kernel/kprobes/core.c</span>
<span class="p_chunk">@@ -326,13 +326,16 @@</span> <span class="p_context"> int __kprobes __copy_instruction(u8 *dest, u8 *src)</span>
 {
 	struct insn insn;
 	kprobe_opcode_t buf[MAX_INSN_SIZE];
<span class="p_add">+	int length;</span>
 
 	kernel_insn_init(&amp;insn, (void *)recover_probed_instruction(buf, (unsigned long)src));
 	insn_get_length(&amp;insn);
<span class="p_add">+	length = insn.length;</span>
<span class="p_add">+</span>
 	/* Another subsystem puts a breakpoint, failed to recover */
 	if (insn.opcode.bytes[0] == BREAKPOINT_INSTRUCTION)
 		return 0;
<span class="p_del">-	memcpy(dest, insn.kaddr, insn.length);</span>
<span class="p_add">+	memcpy(dest, insn.kaddr, length);</span>
 
 #ifdef CONFIG_X86_64
 	if (insn_rip_relative(&amp;insn)) {
<span class="p_chunk">@@ -362,7 +365,7 @@</span> <span class="p_context"> int __kprobes __copy_instruction(u8 *dest, u8 *src)</span>
 		*(s32 *) disp = (s32) newdisp;
 	}
 #endif
<span class="p_del">-	return insn.length;</span>
<span class="p_add">+	return length;</span>
 }
 
 static int __kprobes arch_copy_kprobe(struct kprobe *p)
<span class="p_header">diff --git a/arch/x86/kvm/svm.c b/arch/x86/kvm/svm.c</span>
<span class="p_header">index 9643eda60a52..074633411ea8 100644</span>
<span class="p_header">--- a/arch/x86/kvm/svm.c</span>
<span class="p_header">+++ b/arch/x86/kvm/svm.c</span>
<span class="p_chunk">@@ -495,8 +495,10 @@</span> <span class="p_context"> static void skip_emulated_instruction(struct kvm_vcpu *vcpu)</span>
 {
 	struct vcpu_svm *svm = to_svm(vcpu);
 
<span class="p_del">-	if (svm-&gt;vmcb-&gt;control.next_rip != 0)</span>
<span class="p_add">+	if (svm-&gt;vmcb-&gt;control.next_rip != 0) {</span>
<span class="p_add">+		WARN_ON(!static_cpu_has(X86_FEATURE_NRIPS));</span>
 		svm-&gt;next_rip = svm-&gt;vmcb-&gt;control.next_rip;
<span class="p_add">+	}</span>
 
 	if (!svm-&gt;next_rip) {
 		if (emulate_instruction(vcpu, EMULTYPE_SKIP) !=
<span class="p_chunk">@@ -4246,7 +4248,9 @@</span> <span class="p_context"> static int svm_check_intercept(struct kvm_vcpu *vcpu,</span>
 		break;
 	}
 
<span class="p_del">-	vmcb-&gt;control.next_rip  = info-&gt;next_rip;</span>
<span class="p_add">+	/* TODO: Advertise NRIPS to guest hypervisor unconditionally */</span>
<span class="p_add">+	if (static_cpu_has(X86_FEATURE_NRIPS))</span>
<span class="p_add">+		vmcb-&gt;control.next_rip  = info-&gt;next_rip;</span>
 	vmcb-&gt;control.exit_code = icpt_info.exit_code;
 	vmexit = nested_svm_exit_handled(svm);
 
<span class="p_header">diff --git a/drivers/bus/mvebu-mbus.c b/drivers/bus/mvebu-mbus.c</span>
<span class="p_header">index e990deed2d33..1aa0130a63d5 100644</span>
<span class="p_header">--- a/drivers/bus/mvebu-mbus.c</span>
<span class="p_header">+++ b/drivers/bus/mvebu-mbus.c</span>
<span class="p_chunk">@@ -701,7 +701,6 @@</span> <span class="p_context"> static int __init mvebu_mbus_common_init(struct mvebu_mbus_state *mbus,</span>
 					 phys_addr_t sdramwins_phys_base,
 					 size_t sdramwins_size)
 {
<span class="p_del">-	struct device_node *np;</span>
 	int win;
 
 	mbus-&gt;mbuswins_base = ioremap(mbuswins_phys_base, mbuswins_size);
<span class="p_chunk">@@ -714,12 +713,6 @@</span> <span class="p_context"> static int __init mvebu_mbus_common_init(struct mvebu_mbus_state *mbus,</span>
 		return -ENOMEM;
 	}
 
<span class="p_del">-	np = of_find_compatible_node(NULL, NULL, &quot;marvell,coherency-fabric&quot;);</span>
<span class="p_del">-	if (np) {</span>
<span class="p_del">-		mbus-&gt;hw_io_coherency = 1;</span>
<span class="p_del">-		of_node_put(np);</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
 	for (win = 0; win &lt; mbus-&gt;soc-&gt;num_wins; win++)
 		mvebu_mbus_disable_window(mbus, win);
 
<span class="p_chunk">@@ -889,7 +882,7 @@</span> <span class="p_context"> static void __init mvebu_mbus_get_pcie_resources(struct device_node *np,</span>
 	}
 }
 
<span class="p_del">-int __init mvebu_mbus_dt_init(void)</span>
<span class="p_add">+int __init mvebu_mbus_dt_init(bool is_coherent)</span>
 {
 	struct resource mbuswins_res, sdramwins_res;
 	struct device_node *np, *controller;
<span class="p_chunk">@@ -928,6 +921,8 @@</span> <span class="p_context"> int __init mvebu_mbus_dt_init(void)</span>
 		return -EINVAL;
 	}
 
<span class="p_add">+	mbus_state.hw_io_coherency = is_coherent;</span>
<span class="p_add">+</span>
 	/* Get optional pcie-{mem,io}-aperture properties */
 	mvebu_mbus_get_pcie_resources(np, &amp;mbus_state.pcie_mem_aperture,
 					  &amp;mbus_state.pcie_io_aperture);
<span class="p_header">diff --git a/drivers/edac/sb_edac.c b/drivers/edac/sb_edac.c</span>
<span class="p_header">index c611bcc01f7e..3e623ab5e315 100644</span>
<span class="p_header">--- a/drivers/edac/sb_edac.c</span>
<span class="p_header">+++ b/drivers/edac/sb_edac.c</span>
<span class="p_chunk">@@ -765,7 +765,7 @@</span> <span class="p_context"> static void get_memory_layout(const struct mem_ctl_info *mci)</span>
 	u32 reg;
 	u64 limit, prv = 0;
 	u64 tmp_mb;
<span class="p_del">-	u32 mb, kb;</span>
<span class="p_add">+	u32 gb, mb;</span>
 	u32 rir_way;
 
 	/*
<span class="p_chunk">@@ -775,15 +775,17 @@</span> <span class="p_context"> static void get_memory_layout(const struct mem_ctl_info *mci)</span>
 	pvt-&gt;tolm = pvt-&gt;info.get_tolm(pvt);
 	tmp_mb = (1 + pvt-&gt;tolm) &gt;&gt; 20;
 
<span class="p_del">-	mb = div_u64_rem(tmp_mb, 1000, &amp;kb);</span>
<span class="p_del">-	edac_dbg(0, &quot;TOLM: %u.%03u GB (0x%016Lx)\n&quot;, mb, kb, (u64)pvt-&gt;tolm);</span>
<span class="p_add">+	gb = div_u64_rem(tmp_mb, 1024, &amp;mb);</span>
<span class="p_add">+	edac_dbg(0, &quot;TOLM: %u.%03u GB (0x%016Lx)\n&quot;,</span>
<span class="p_add">+		gb, (mb*1000)/1024, (u64)pvt-&gt;tolm);</span>
 
 	/* Address range is already 45:25 */
 	pvt-&gt;tohm = pvt-&gt;info.get_tohm(pvt);
 	tmp_mb = (1 + pvt-&gt;tohm) &gt;&gt; 20;
 
<span class="p_del">-	mb = div_u64_rem(tmp_mb, 1000, &amp;kb);</span>
<span class="p_del">-	edac_dbg(0, &quot;TOHM: %u.%03u GB (0x%016Lx)\n&quot;, mb, kb, (u64)pvt-&gt;tohm);</span>
<span class="p_add">+	gb = div_u64_rem(tmp_mb, 1024, &amp;mb);</span>
<span class="p_add">+	edac_dbg(0, &quot;TOHM: %u.%03u GB (0x%016Lx)\n&quot;,</span>
<span class="p_add">+		gb, (mb*1000)/1024, (u64)pvt-&gt;tohm);</span>
 
 	/*
 	 * Step 2) Get SAD range and SAD Interleave list
<span class="p_chunk">@@ -805,11 +807,11 @@</span> <span class="p_context"> static void get_memory_layout(const struct mem_ctl_info *mci)</span>
 			break;
 
 		tmp_mb = (limit + 1) &gt;&gt; 20;
<span class="p_del">-		mb = div_u64_rem(tmp_mb, 1000, &amp;kb);</span>
<span class="p_add">+		gb = div_u64_rem(tmp_mb, 1024, &amp;mb);</span>
 		edac_dbg(0, &quot;SAD#%d %s up to %u.%03u GB (0x%016Lx) Interleave: %s reg=0x%08x\n&quot;,
 			 n_sads,
 			 get_dram_attr(reg),
<span class="p_del">-			 mb, kb,</span>
<span class="p_add">+			 gb, (mb*1000)/1024,</span>
 			 ((u64)tmp_mb) &lt;&lt; 20L,
 			 INTERLEAVE_MODE(reg) ? &quot;8:6&quot; : &quot;[8:6]XOR[18:16]&quot;,
 			 reg);
<span class="p_chunk">@@ -840,9 +842,9 @@</span> <span class="p_context"> static void get_memory_layout(const struct mem_ctl_info *mci)</span>
 			break;
 		tmp_mb = (limit + 1) &gt;&gt; 20;
 
<span class="p_del">-		mb = div_u64_rem(tmp_mb, 1000, &amp;kb);</span>
<span class="p_add">+		gb = div_u64_rem(tmp_mb, 1024, &amp;mb);</span>
 		edac_dbg(0, &quot;TAD#%d: up to %u.%03u GB (0x%016Lx), socket interleave %d, memory interleave %d, TGT: %d, %d, %d, %d, reg=0x%08x\n&quot;,
<span class="p_del">-			 n_tads, mb, kb,</span>
<span class="p_add">+			 n_tads, gb, (mb*1000)/1024,</span>
 			 ((u64)tmp_mb) &lt;&lt; 20L,
 			 (u32)TAD_SOCK(reg),
 			 (u32)TAD_CH(reg),
<span class="p_chunk">@@ -865,10 +867,10 @@</span> <span class="p_context"> static void get_memory_layout(const struct mem_ctl_info *mci)</span>
 					      tad_ch_nilv_offset[j],
 					      &amp;reg);
 			tmp_mb = TAD_OFFSET(reg) &gt;&gt; 20;
<span class="p_del">-			mb = div_u64_rem(tmp_mb, 1000, &amp;kb);</span>
<span class="p_add">+			gb = div_u64_rem(tmp_mb, 1024, &amp;mb);</span>
 			edac_dbg(0, &quot;TAD CH#%d, offset #%d: %u.%03u GB (0x%016Lx), reg=0x%08x\n&quot;,
 				 i, j,
<span class="p_del">-				 mb, kb,</span>
<span class="p_add">+				 gb, (mb*1000)/1024,</span>
 				 ((u64)tmp_mb) &lt;&lt; 20L,
 				 reg);
 		}
<span class="p_chunk">@@ -890,10 +892,10 @@</span> <span class="p_context"> static void get_memory_layout(const struct mem_ctl_info *mci)</span>
 
 			tmp_mb = RIR_LIMIT(reg) &gt;&gt; 20;
 			rir_way = 1 &lt;&lt; RIR_WAY(reg);
<span class="p_del">-			mb = div_u64_rem(tmp_mb, 1000, &amp;kb);</span>
<span class="p_add">+			gb = div_u64_rem(tmp_mb, 1024, &amp;mb);</span>
 			edac_dbg(0, &quot;CH#%d RIR#%d, limit: %u.%03u GB (0x%016Lx), way: %d, reg=0x%08x\n&quot;,
 				 i, j,
<span class="p_del">-				 mb, kb,</span>
<span class="p_add">+				 gb, (mb*1000)/1024,</span>
 				 ((u64)tmp_mb) &lt;&lt; 20L,
 				 rir_way,
 				 reg);
<span class="p_chunk">@@ -904,10 +906,10 @@</span> <span class="p_context"> static void get_memory_layout(const struct mem_ctl_info *mci)</span>
 						      &amp;reg);
 				tmp_mb = RIR_OFFSET(reg) &lt;&lt; 6;
 
<span class="p_del">-				mb = div_u64_rem(tmp_mb, 1000, &amp;kb);</span>
<span class="p_add">+				gb = div_u64_rem(tmp_mb, 1024, &amp;mb);</span>
 				edac_dbg(0, &quot;CH#%d RIR#%d INTL#%d, offset %u.%03u GB (0x%016Lx), tgt: %d, reg=0x%08x\n&quot;,
 					 i, j, k,
<span class="p_del">-					 mb, kb,</span>
<span class="p_add">+					 gb, (mb*1000)/1024,</span>
 					 ((u64)tmp_mb) &lt;&lt; 20L,
 					 (u32)RIR_RNK_TGT(reg),
 					 reg);
<span class="p_chunk">@@ -945,7 +947,7 @@</span> <span class="p_context"> static int get_memory_error_data(struct mem_ctl_info *mci,</span>
 	u8			ch_way, sck_way, pkg, sad_ha = 0;
 	u32			tad_offset;
 	u32			rir_way;
<span class="p_del">-	u32			mb, kb;</span>
<span class="p_add">+	u32			mb, gb;</span>
 	u64			ch_addr, offset, limit = 0, prv = 0;
 
 
<span class="p_chunk">@@ -1183,10 +1185,10 @@</span> <span class="p_context"> static int get_memory_error_data(struct mem_ctl_info *mci,</span>
 			continue;
 
 		limit = RIR_LIMIT(reg);
<span class="p_del">-		mb = div_u64_rem(limit &gt;&gt; 20, 1000, &amp;kb);</span>
<span class="p_add">+		gb = div_u64_rem(limit &gt;&gt; 20, 1024, &amp;mb);</span>
 		edac_dbg(0, &quot;RIR#%d, limit: %u.%03u GB (0x%016Lx), way: %d\n&quot;,
 			 n_rir,
<span class="p_del">-			 mb, kb,</span>
<span class="p_add">+			 gb, (mb*1000)/1024,</span>
 			 limit,
 			 1 &lt;&lt; RIR_WAY(reg));
 		if  (ch_addr &lt;= limit)
<span class="p_header">diff --git a/drivers/net/ethernet/mellanox/mlx4/en_tx.c b/drivers/net/ethernet/mellanox/mlx4/en_tx.c</span>
<span class="p_header">index 019a04a31384..a467261b10b9 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/mellanox/mlx4/en_tx.c</span>
<span class="p_header">+++ b/drivers/net/ethernet/mellanox/mlx4/en_tx.c</span>
<span class="p_chunk">@@ -810,8 +810,11 @@</span> <span class="p_context"> netdev_tx_t mlx4_en_xmit(struct sk_buff *skb, struct net_device *dev)</span>
 	tx_desc-&gt;ctrl.fence_size = (real_size / 16) &amp; 0x3f;
 	tx_desc-&gt;ctrl.srcrb_flags = priv-&gt;ctrl_flags;
 	if (likely(skb-&gt;ip_summed == CHECKSUM_PARTIAL)) {
<span class="p_del">-		tx_desc-&gt;ctrl.srcrb_flags |= cpu_to_be32(MLX4_WQE_CTRL_IP_CSUM |</span>
<span class="p_del">-							 MLX4_WQE_CTRL_TCP_UDP_CSUM);</span>
<span class="p_add">+		if (!skb-&gt;encapsulation)</span>
<span class="p_add">+			tx_desc-&gt;ctrl.srcrb_flags |= cpu_to_be32(MLX4_WQE_CTRL_IP_CSUM |</span>
<span class="p_add">+								 MLX4_WQE_CTRL_TCP_UDP_CSUM);</span>
<span class="p_add">+		else</span>
<span class="p_add">+			tx_desc-&gt;ctrl.srcrb_flags |= cpu_to_be32(MLX4_WQE_CTRL_IP_CSUM);</span>
 		ring-&gt;tx_csum++;
 	}
 
<span class="p_header">diff --git a/drivers/scsi/hpsa.c b/drivers/scsi/hpsa.c</span>
<span class="p_header">index 528bff5ec91f..85d370e1ca79 100644</span>
<span class="p_header">--- a/drivers/scsi/hpsa.c</span>
<span class="p_header">+++ b/drivers/scsi/hpsa.c</span>
<span class="p_chunk">@@ -3984,10 +3984,6 @@</span> <span class="p_context"> static int hpsa_kdump_hard_reset_controller(struct pci_dev *pdev)</span>
 
 	/* Save the PCI command register */
 	pci_read_config_word(pdev, 4, &amp;command_register);
<span class="p_del">-	/* Turn the board off.  This is so that later pci_restore_state()</span>
<span class="p_del">-	 * won&#39;t turn the board on before the rest of config space is ready.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	pci_disable_device(pdev);</span>
 	pci_save_state(pdev);
 
 	/* find the first memory BAR, so we can find the cfg table */
<span class="p_chunk">@@ -4035,11 +4031,6 @@</span> <span class="p_context"> static int hpsa_kdump_hard_reset_controller(struct pci_dev *pdev)</span>
 		goto unmap_cfgtable;
 
 	pci_restore_state(pdev);
<span class="p_del">-	rc = pci_enable_device(pdev);</span>
<span class="p_del">-	if (rc) {</span>
<span class="p_del">-		dev_warn(&amp;pdev-&gt;dev, &quot;failed to enable device.\n&quot;);</span>
<span class="p_del">-		goto unmap_cfgtable;</span>
<span class="p_del">-	}</span>
 	pci_write_config_word(pdev, 4, command_register);
 
 	/* Some devices (notably the HP Smart Array 5i Controller)
<span class="p_chunk">@@ -4525,6 +4516,23 @@</span> <span class="p_context"> static int hpsa_init_reset_devices(struct pci_dev *pdev)</span>
 	if (!reset_devices)
 		return 0;
 
<span class="p_add">+	/* kdump kernel is loading, we don&#39;t know in which state is</span>
<span class="p_add">+	 * the pci interface. The dev-&gt;enable_cnt is equal zero</span>
<span class="p_add">+	 * so we call enable+disable, wait a while and switch it on.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	rc = pci_enable_device(pdev);</span>
<span class="p_add">+	if (rc) {</span>
<span class="p_add">+		dev_warn(&amp;pdev-&gt;dev, &quot;Failed to enable PCI device\n&quot;);</span>
<span class="p_add">+		return -ENODEV;</span>
<span class="p_add">+	}</span>
<span class="p_add">+	pci_disable_device(pdev);</span>
<span class="p_add">+	msleep(260);			/* a randomly chosen number */</span>
<span class="p_add">+	rc = pci_enable_device(pdev);</span>
<span class="p_add">+	if (rc) {</span>
<span class="p_add">+		dev_warn(&amp;pdev-&gt;dev, &quot;failed to enable device.\n&quot;);</span>
<span class="p_add">+		return -ENODEV;</span>
<span class="p_add">+	}</span>
<span class="p_add">+	pci_set_master(pdev);</span>
 	/* Reset the controller with a PCI power-cycle or via doorbell */
 	rc = hpsa_kdump_hard_reset_controller(pdev);
 
<span class="p_chunk">@@ -4533,10 +4541,11 @@</span> <span class="p_context"> static int hpsa_init_reset_devices(struct pci_dev *pdev)</span>
 	 * &quot;performant mode&quot;.  Or, it might be 640x, which can&#39;t reset
 	 * due to concerns about shared bbwc between 6402/6404 pair.
 	 */
<span class="p_del">-	if (rc == -ENOTSUPP)</span>
<span class="p_del">-		return rc; /* just try to do the kdump anyhow. */</span>
<span class="p_del">-	if (rc)</span>
<span class="p_del">-		return -ENODEV;</span>
<span class="p_add">+	if (rc) {</span>
<span class="p_add">+		if (rc != -ENOTSUPP) /* just try to do the kdump anyhow. */</span>
<span class="p_add">+			rc = -ENODEV;</span>
<span class="p_add">+		goto out_disable;</span>
<span class="p_add">+	}</span>
 
 	/* Now try to get the controller to respond to a no-op */
 	dev_warn(&amp;pdev-&gt;dev, &quot;Waiting for controller to respond to no-op\n&quot;);
<span class="p_chunk">@@ -4547,7 +4556,11 @@</span> <span class="p_context"> static int hpsa_init_reset_devices(struct pci_dev *pdev)</span>
 			dev_warn(&amp;pdev-&gt;dev, &quot;no-op failed%s\n&quot;,
 					(i &lt; 11 ? &quot;; re-trying&quot; : &quot;&quot;));
 	}
<span class="p_del">-	return 0;</span>
<span class="p_add">+</span>
<span class="p_add">+out_disable:</span>
<span class="p_add">+</span>
<span class="p_add">+	pci_disable_device(pdev);</span>
<span class="p_add">+	return rc;</span>
 }
 
 static int hpsa_allocate_cmd_pool(struct ctlr_info *h)
<span class="p_chunk">@@ -4690,6 +4703,7 @@</span> <span class="p_context"> static void hpsa_undo_allocations_after_kdump_soft_reset(struct ctlr_info *h)</span>
 		iounmap(h-&gt;transtable);
 	if (h-&gt;cfgtable)
 		iounmap(h-&gt;cfgtable);
<span class="p_add">+	pci_disable_device(h-&gt;pdev);</span>
 	pci_release_regions(h-&gt;pdev);
 	kfree(h);
 }
<span class="p_header">diff --git a/fs/btrfs/ctree.c b/fs/btrfs/ctree.c</span>
<span class="p_header">index 93de3ba994e7..f8ffee4562d3 100644</span>
<span class="p_header">--- a/fs/btrfs/ctree.c</span>
<span class="p_header">+++ b/fs/btrfs/ctree.c</span>
<span class="p_chunk">@@ -2963,7 +2963,7 @@</span> <span class="p_context"> done:</span>
 	 */
 	if (!p-&gt;leave_spinning)
 		btrfs_set_path_blocking(p);
<span class="p_del">-	if (ret &lt; 0)</span>
<span class="p_add">+	if (ret &lt; 0 &amp;&amp; !p-&gt;skip_release_on_error)</span>
 		btrfs_release_path(p);
 	return ret;
 }
<span class="p_header">diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h</span>
<span class="p_header">index d3511cc17091..3b39eb4cb309 100644</span>
<span class="p_header">--- a/fs/btrfs/ctree.h</span>
<span class="p_header">+++ b/fs/btrfs/ctree.h</span>
<span class="p_chunk">@@ -608,6 +608,7 @@</span> <span class="p_context"> struct btrfs_path {</span>
 	unsigned int skip_locking:1;
 	unsigned int leave_spinning:1;
 	unsigned int search_commit_root:1;
<span class="p_add">+	unsigned int skip_release_on_error:1;</span>
 };
 
 /*
<span class="p_chunk">@@ -3609,6 +3610,10 @@</span> <span class="p_context"> struct btrfs_dir_item *btrfs_lookup_xattr(struct btrfs_trans_handle *trans,</span>
 int verify_dir_item(struct btrfs_root *root,
 		    struct extent_buffer *leaf,
 		    struct btrfs_dir_item *dir_item);
<span class="p_add">+struct btrfs_dir_item *btrfs_match_dir_item_name(struct btrfs_root *root,</span>
<span class="p_add">+						 struct btrfs_path *path,</span>
<span class="p_add">+						 const char *name,</span>
<span class="p_add">+						 int name_len);</span>
 
 /* orphan.c */
 int btrfs_insert_orphan_item(struct btrfs_trans_handle *trans,
<span class="p_header">diff --git a/fs/btrfs/dir-item.c b/fs/btrfs/dir-item.c</span>
<span class="p_header">index a0691df5dcea..9521a93b5303 100644</span>
<span class="p_header">--- a/fs/btrfs/dir-item.c</span>
<span class="p_header">+++ b/fs/btrfs/dir-item.c</span>
<span class="p_chunk">@@ -21,10 +21,6 @@</span> <span class="p_context"></span>
 #include &quot;hash.h&quot;
 #include &quot;transaction.h&quot;
 
<span class="p_del">-static struct btrfs_dir_item *btrfs_match_dir_item_name(struct btrfs_root *root,</span>
<span class="p_del">-			      struct btrfs_path *path,</span>
<span class="p_del">-			      const char *name, int name_len);</span>
<span class="p_del">-</span>
 /*
  * insert a name into a directory, doing overflow properly if there is a hash
  * collision.  data_size indicates how big the item inserted should be.  On
<span class="p_chunk">@@ -383,9 +379,9 @@</span> <span class="p_context"> struct btrfs_dir_item *btrfs_lookup_xattr(struct btrfs_trans_handle *trans,</span>
  * this walks through all the entries in a dir item and finds one
  * for a specific name.
  */
<span class="p_del">-static struct btrfs_dir_item *btrfs_match_dir_item_name(struct btrfs_root *root,</span>
<span class="p_del">-			      struct btrfs_path *path,</span>
<span class="p_del">-			      const char *name, int name_len)</span>
<span class="p_add">+struct btrfs_dir_item *btrfs_match_dir_item_name(struct btrfs_root *root,</span>
<span class="p_add">+						 struct btrfs_path *path,</span>
<span class="p_add">+						 const char *name, int name_len)</span>
 {
 	struct btrfs_dir_item *dir_item;
 	unsigned long name_ptr;
<span class="p_header">diff --git a/fs/btrfs/xattr.c b/fs/btrfs/xattr.c</span>
<span class="p_header">index 488e987c3374..618e86ceede7 100644</span>
<span class="p_header">--- a/fs/btrfs/xattr.c</span>
<span class="p_header">+++ b/fs/btrfs/xattr.c</span>
<span class="p_chunk">@@ -29,6 +29,7 @@</span> <span class="p_context"></span>
 #include &quot;xattr.h&quot;
 #include &quot;disk-io.h&quot;
 #include &quot;props.h&quot;
<span class="p_add">+#include &quot;locking.h&quot;</span>
 
 
 ssize_t __btrfs_getxattr(struct inode *inode, const char *name,
<span class="p_chunk">@@ -91,7 +92,7 @@</span> <span class="p_context"> static int do_setxattr(struct btrfs_trans_handle *trans,</span>
 		       struct inode *inode, const char *name,
 		       const void *value, size_t size, int flags)
 {
<span class="p_del">-	struct btrfs_dir_item *di;</span>
<span class="p_add">+	struct btrfs_dir_item *di = NULL;</span>
 	struct btrfs_root *root = BTRFS_I(inode)-&gt;root;
 	struct btrfs_path *path;
 	size_t name_len = strlen(name);
<span class="p_chunk">@@ -103,84 +104,119 @@</span> <span class="p_context"> static int do_setxattr(struct btrfs_trans_handle *trans,</span>
 	path = btrfs_alloc_path();
 	if (!path)
 		return -ENOMEM;
<span class="p_add">+	path-&gt;skip_release_on_error = 1;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (!value) {</span>
<span class="p_add">+		di = btrfs_lookup_xattr(trans, root, path, btrfs_ino(inode),</span>
<span class="p_add">+					name, name_len, -1);</span>
<span class="p_add">+		if (!di &amp;&amp; (flags &amp; XATTR_REPLACE))</span>
<span class="p_add">+			ret = -ENODATA;</span>
<span class="p_add">+		else if (di)</span>
<span class="p_add">+			ret = btrfs_delete_one_dir_name(trans, root, path, di);</span>
<span class="p_add">+		goto out;</span>
<span class="p_add">+	}</span>
 
<span class="p_add">+	/*</span>
<span class="p_add">+	 * For a replace we can&#39;t just do the insert blindly.</span>
<span class="p_add">+	 * Do a lookup first (read-only btrfs_search_slot), and return if xattr</span>
<span class="p_add">+	 * doesn&#39;t exist. If it exists, fall down below to the insert/replace</span>
<span class="p_add">+	 * path - we can&#39;t race with a concurrent xattr delete, because the VFS</span>
<span class="p_add">+	 * locks the inode&#39;s i_mutex before calling setxattr or removexattr.</span>
<span class="p_add">+	 */</span>
 	if (flags &amp; XATTR_REPLACE) {
<span class="p_del">-		di = btrfs_lookup_xattr(trans, root, path, btrfs_ino(inode), name,</span>
<span class="p_del">-					name_len, -1);</span>
<span class="p_del">-		if (IS_ERR(di)) {</span>
<span class="p_del">-			ret = PTR_ERR(di);</span>
<span class="p_del">-			goto out;</span>
<span class="p_del">-		} else if (!di) {</span>
<span class="p_add">+		ASSERT(mutex_is_locked(&amp;inode-&gt;i_mutex));</span>
<span class="p_add">+		di = btrfs_lookup_xattr(NULL, root, path, btrfs_ino(inode),</span>
<span class="p_add">+					name, name_len, 0);</span>
<span class="p_add">+		if (!di) {</span>
 			ret = -ENODATA;
 			goto out;
 		}
<span class="p_del">-		ret = btrfs_delete_one_dir_name(trans, root, path, di);</span>
<span class="p_del">-		if (ret)</span>
<span class="p_del">-			goto out;</span>
 		btrfs_release_path(path);
<span class="p_add">+		di = NULL;</span>
<span class="p_add">+	}</span>
 
<span class="p_add">+	ret = btrfs_insert_xattr_item(trans, root, path, btrfs_ino(inode),</span>
<span class="p_add">+				      name, name_len, value, size);</span>
<span class="p_add">+	if (ret == -EOVERFLOW) {</span>
 		/*
<span class="p_del">-		 * remove the attribute</span>
<span class="p_add">+		 * We have an existing item in a leaf, split_leaf couldn&#39;t</span>
<span class="p_add">+		 * expand it. That item might have or not a dir_item that</span>
<span class="p_add">+		 * matches our target xattr, so lets check.</span>
 		 */
<span class="p_del">-		if (!value)</span>
<span class="p_del">-			goto out;</span>
<span class="p_del">-	} else {</span>
<span class="p_del">-		di = btrfs_lookup_xattr(NULL, root, path, btrfs_ino(inode),</span>
<span class="p_del">-					name, name_len, 0);</span>
<span class="p_del">-		if (IS_ERR(di)) {</span>
<span class="p_del">-			ret = PTR_ERR(di);</span>
<span class="p_add">+		ret = 0;</span>
<span class="p_add">+		btrfs_assert_tree_locked(path-&gt;nodes[0]);</span>
<span class="p_add">+		di = btrfs_match_dir_item_name(root, path, name, name_len);</span>
<span class="p_add">+		if (!di &amp;&amp; !(flags &amp; XATTR_REPLACE)) {</span>
<span class="p_add">+			ret = -ENOSPC;</span>
 			goto out;
 		}
<span class="p_del">-		if (!di &amp;&amp; !value)</span>
<span class="p_del">-			goto out;</span>
<span class="p_del">-		btrfs_release_path(path);</span>
<span class="p_add">+	} else if (ret == -EEXIST) {</span>
<span class="p_add">+		ret = 0;</span>
<span class="p_add">+		di = btrfs_match_dir_item_name(root, path, name, name_len);</span>
<span class="p_add">+		ASSERT(di); /* logic error */</span>
<span class="p_add">+	} else if (ret) {</span>
<span class="p_add">+		goto out;</span>
 	}
 
<span class="p_del">-again:</span>
<span class="p_del">-	ret = btrfs_insert_xattr_item(trans, root, path, btrfs_ino(inode),</span>
<span class="p_del">-				      name, name_len, value, size);</span>
<span class="p_del">-	/*</span>
<span class="p_del">-	 * If we&#39;re setting an xattr to a new value but the new value is say</span>
<span class="p_del">-	 * exactly BTRFS_MAX_XATTR_SIZE, we could end up with EOVERFLOW getting</span>
<span class="p_del">-	 * back from split_leaf.  This is because it thinks we&#39;ll be extending</span>
<span class="p_del">-	 * the existing item size, but we&#39;re asking for enough space to add the</span>
<span class="p_del">-	 * item itself.  So if we get EOVERFLOW just set ret to EEXIST and let</span>
<span class="p_del">-	 * the rest of the function figure it out.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	if (ret == -EOVERFLOW)</span>
<span class="p_add">+	if (di &amp;&amp; (flags &amp; XATTR_CREATE)) {</span>
 		ret = -EEXIST;
<span class="p_add">+		goto out;</span>
<span class="p_add">+	}</span>
 
<span class="p_del">-	if (ret == -EEXIST) {</span>
<span class="p_del">-		if (flags &amp; XATTR_CREATE)</span>
<span class="p_del">-			goto out;</span>
<span class="p_add">+	if (di) {</span>
 		/*
<span class="p_del">-		 * We can&#39;t use the path we already have since we won&#39;t have the</span>
<span class="p_del">-		 * proper locking for a delete, so release the path and</span>
<span class="p_del">-		 * re-lookup to delete the thing.</span>
<span class="p_add">+		 * We&#39;re doing a replace, and it must be atomic, that is, at</span>
<span class="p_add">+		 * any point in time we have either the old or the new xattr</span>
<span class="p_add">+		 * value in the tree. We don&#39;t want readers (getxattr and</span>
<span class="p_add">+		 * listxattrs) to miss a value, this is specially important</span>
<span class="p_add">+		 * for ACLs.</span>
 		 */
<span class="p_del">-		btrfs_release_path(path);</span>
<span class="p_del">-		di = btrfs_lookup_xattr(trans, root, path, btrfs_ino(inode),</span>
<span class="p_del">-					name, name_len, -1);</span>
<span class="p_del">-		if (IS_ERR(di)) {</span>
<span class="p_del">-			ret = PTR_ERR(di);</span>
<span class="p_del">-			goto out;</span>
<span class="p_del">-		} else if (!di) {</span>
<span class="p_del">-			/* Shouldn&#39;t happen but just in case... */</span>
<span class="p_del">-			btrfs_release_path(path);</span>
<span class="p_del">-			goto again;</span>
<span class="p_add">+		const int slot = path-&gt;slots[0];</span>
<span class="p_add">+		struct extent_buffer *leaf = path-&gt;nodes[0];</span>
<span class="p_add">+		const u16 old_data_len = btrfs_dir_data_len(leaf, di);</span>
<span class="p_add">+		const u32 item_size = btrfs_item_size_nr(leaf, slot);</span>
<span class="p_add">+		const u32 data_size = sizeof(*di) + name_len + size;</span>
<span class="p_add">+		struct btrfs_item *item;</span>
<span class="p_add">+		unsigned long data_ptr;</span>
<span class="p_add">+		char *ptr;</span>
<span class="p_add">+</span>
<span class="p_add">+		if (size &gt; old_data_len) {</span>
<span class="p_add">+			if (btrfs_leaf_free_space(root, leaf) &lt;</span>
<span class="p_add">+			    (size - old_data_len)) {</span>
<span class="p_add">+				ret = -ENOSPC;</span>
<span class="p_add">+				goto out;</span>
<span class="p_add">+			}</span>
 		}
 
<span class="p_del">-		ret = btrfs_delete_one_dir_name(trans, root, path, di);</span>
<span class="p_del">-		if (ret)</span>
<span class="p_del">-			goto out;</span>
<span class="p_add">+		if (old_data_len + name_len + sizeof(*di) == item_size) {</span>
<span class="p_add">+			/* No other xattrs packed in the same leaf item. */</span>
<span class="p_add">+			if (size &gt; old_data_len)</span>
<span class="p_add">+				btrfs_extend_item(root, path,</span>
<span class="p_add">+						  size - old_data_len);</span>
<span class="p_add">+			else if (size &lt; old_data_len)</span>
<span class="p_add">+				btrfs_truncate_item(root, path, data_size, 1);</span>
<span class="p_add">+		} else {</span>
<span class="p_add">+			/* There are other xattrs packed in the same item. */</span>
<span class="p_add">+			ret = btrfs_delete_one_dir_name(trans, root, path, di);</span>
<span class="p_add">+			if (ret)</span>
<span class="p_add">+				goto out;</span>
<span class="p_add">+			btrfs_extend_item(root, path, data_size);</span>
<span class="p_add">+		}</span>
 
<span class="p_add">+		item = btrfs_item_nr(slot);</span>
<span class="p_add">+		ptr = btrfs_item_ptr(leaf, slot, char);</span>
<span class="p_add">+		ptr += btrfs_item_size(leaf, item) - data_size;</span>
<span class="p_add">+		di = (struct btrfs_dir_item *)ptr;</span>
<span class="p_add">+		btrfs_set_dir_data_len(leaf, di, size);</span>
<span class="p_add">+		data_ptr = ((unsigned long)(di + 1)) + name_len;</span>
<span class="p_add">+		write_extent_buffer(leaf, value, data_ptr, size);</span>
<span class="p_add">+		btrfs_mark_buffer_dirty(leaf);</span>
<span class="p_add">+	} else {</span>
 		/*
<span class="p_del">-		 * We have a value to set, so go back and try to insert it now.</span>
<span class="p_add">+		 * Insert, and we had space for the xattr, so path-&gt;slots[0] is</span>
<span class="p_add">+		 * where our xattr dir_item is and btrfs_insert_xattr_item()</span>
<span class="p_add">+		 * filled it.</span>
 		 */
<span class="p_del">-		if (value) {</span>
<span class="p_del">-			btrfs_release_path(path);</span>
<span class="p_del">-			goto again;</span>
<span class="p_del">-		}</span>
 	}
 out:
 	btrfs_free_path(path);
<span class="p_header">diff --git a/fs/ocfs2/file.c b/fs/ocfs2/file.c</span>
<span class="p_header">index 7fe30f655aa5..35f54bc96519 100644</span>
<span class="p_header">--- a/fs/ocfs2/file.c</span>
<span class="p_header">+++ b/fs/ocfs2/file.c</span>
<span class="p_chunk">@@ -2478,9 +2478,7 @@</span> <span class="p_context"> static ssize_t ocfs2_file_splice_write(struct pipe_inode_info *pipe,</span>
 	struct address_space *mapping = out-&gt;f_mapping;
 	struct inode *inode = mapping-&gt;host;
 	struct splice_desc sd = {
<span class="p_del">-		.total_len = len,</span>
 		.flags = flags,
<span class="p_del">-		.pos = *ppos,</span>
 		.u.file = out,
 	};
 
<span class="p_chunk">@@ -2490,6 +2488,12 @@</span> <span class="p_context"> static ssize_t ocfs2_file_splice_write(struct pipe_inode_info *pipe,</span>
 			out-&gt;f_path.dentry-&gt;d_name.len,
 			out-&gt;f_path.dentry-&gt;d_name.name, len);
 
<span class="p_add">+	ret = generic_write_checks(out, ppos, &amp;len, 0);</span>
<span class="p_add">+	if (ret)</span>
<span class="p_add">+		return ret;</span>
<span class="p_add">+	sd.total_len = len;</span>
<span class="p_add">+	sd.pos = *ppos;</span>
<span class="p_add">+</span>
 	pipe_lock(pipe);
 
 	splice_from_pipe_begin(&amp;sd);
<span class="p_header">diff --git a/fs/splice.c b/fs/splice.c</span>
<span class="p_header">index 12028fa41def..f345d53f94da 100644</span>
<span class="p_header">--- a/fs/splice.c</span>
<span class="p_header">+++ b/fs/splice.c</span>
<span class="p_chunk">@@ -1012,13 +1012,17 @@</span> <span class="p_context"> generic_file_splice_write(struct pipe_inode_info *pipe, struct file *out,</span>
 	struct address_space *mapping = out-&gt;f_mapping;
 	struct inode *inode = mapping-&gt;host;
 	struct splice_desc sd = {
<span class="p_del">-		.total_len = len,</span>
 		.flags = flags,
<span class="p_del">-		.pos = *ppos,</span>
 		.u.file = out,
 	};
 	ssize_t ret;
 
<span class="p_add">+	ret = generic_write_checks(out, ppos, &amp;len, S_ISBLK(inode-&gt;i_mode));</span>
<span class="p_add">+	if (ret)</span>
<span class="p_add">+		return ret;</span>
<span class="p_add">+	sd.total_len = len;</span>
<span class="p_add">+	sd.pos = *ppos;</span>
<span class="p_add">+</span>
 	pipe_lock(pipe);
 
 	splice_from_pipe_begin(&amp;sd);
<span class="p_header">diff --git a/include/linux/mbus.h b/include/linux/mbus.h</span>
<span class="p_header">index 345b8c53b897..550c88fb0267 100644</span>
<span class="p_header">--- a/include/linux/mbus.h</span>
<span class="p_header">+++ b/include/linux/mbus.h</span>
<span class="p_chunk">@@ -73,6 +73,6 @@</span> <span class="p_context"> int mvebu_mbus_del_window(phys_addr_t base, size_t size);</span>
 int mvebu_mbus_init(const char *soc, phys_addr_t mbus_phys_base,
 		    size_t mbus_size, phys_addr_t sdram_phys_base,
 		    size_t sdram_size);
<span class="p_del">-int mvebu_mbus_dt_init(void);</span>
<span class="p_add">+int mvebu_mbus_dt_init(bool is_coherent);</span>
 
 #endif /* __LINUX_MBUS_H */
<span class="p_header">diff --git a/net/netfilter/nf_tables_api.c b/net/netfilter/nf_tables_api.c</span>
<span class="p_header">index c68e5e0628df..99de2409f731 100644</span>
<span class="p_header">--- a/net/netfilter/nf_tables_api.c</span>
<span class="p_header">+++ b/net/netfilter/nf_tables_api.c</span>
<span class="p_chunk">@@ -855,7 +855,10 @@</span> <span class="p_context"> static int nf_tables_newchain(struct sock *nlsk, struct sk_buff *skb,</span>
 
 	if (nla[NFTA_CHAIN_POLICY]) {
 		if ((chain != NULL &amp;&amp;
<span class="p_del">-		    !(chain-&gt;flags &amp; NFT_BASE_CHAIN)) ||</span>
<span class="p_add">+		    !(chain-&gt;flags &amp; NFT_BASE_CHAIN)))</span>
<span class="p_add">+			return -EOPNOTSUPP;</span>
<span class="p_add">+</span>
<span class="p_add">+		if (chain == NULL &amp;&amp;</span>
 		    nla[NFTA_CHAIN_HOOK] == NULL)
 			return -EOPNOTSUPP;
 
<span class="p_header">diff --git a/net/netfilter/nfnetlink_cthelper.c b/net/netfilter/nfnetlink_cthelper.c</span>
<span class="p_header">index 9e287cb56a04..54330fb5efaf 100644</span>
<span class="p_header">--- a/net/netfilter/nfnetlink_cthelper.c</span>
<span class="p_header">+++ b/net/netfilter/nfnetlink_cthelper.c</span>
<span class="p_chunk">@@ -77,6 +77,9 @@</span> <span class="p_context"> nfnl_cthelper_parse_tuple(struct nf_conntrack_tuple *tuple,</span>
 	if (!tb[NFCTH_TUPLE_L3PROTONUM] || !tb[NFCTH_TUPLE_L4PROTONUM])
 		return -EINVAL;
 
<span class="p_add">+	/* Not all fields are initialized so first zero the tuple */</span>
<span class="p_add">+	memset(tuple, 0, sizeof(struct nf_conntrack_tuple));</span>
<span class="p_add">+</span>
 	tuple-&gt;src.l3num = ntohs(nla_get_be16(tb[NFCTH_TUPLE_L3PROTONUM]));
 	tuple-&gt;dst.protonum = nla_get_u8(tb[NFCTH_TUPLE_L4PROTONUM]);
 
<span class="p_chunk">@@ -86,7 +89,7 @@</span> <span class="p_context"> nfnl_cthelper_parse_tuple(struct nf_conntrack_tuple *tuple,</span>
 static int
 nfnl_cthelper_from_nlattr(struct nlattr *attr, struct nf_conn *ct)
 {
<span class="p_del">-	const struct nf_conn_help *help = nfct_help(ct);</span>
<span class="p_add">+	struct nf_conn_help *help = nfct_help(ct);</span>
 
 	if (attr == NULL)
 		return -EINVAL;
<span class="p_chunk">@@ -94,7 +97,7 @@</span> <span class="p_context"> nfnl_cthelper_from_nlattr(struct nlattr *attr, struct nf_conn *ct)</span>
 	if (help-&gt;helper-&gt;data_len == 0)
 		return -EINVAL;
 
<span class="p_del">-	memcpy(&amp;help-&gt;data, nla_data(attr), help-&gt;helper-&gt;data_len);</span>
<span class="p_add">+	memcpy(help-&gt;data, nla_data(attr), help-&gt;helper-&gt;data_len);</span>
 	return 0;
 }
 
<span class="p_header">diff --git a/net/netfilter/nft_compat.c b/net/netfilter/nft_compat.c</span>
<span class="p_header">index 7350723aeb15..969589590814 100644</span>
<span class="p_header">--- a/net/netfilter/nft_compat.c</span>
<span class="p_header">+++ b/net/netfilter/nft_compat.c</span>
<span class="p_chunk">@@ -82,6 +82,9 @@</span> <span class="p_context"> nft_target_set_tgchk_param(struct xt_tgchk_param *par,</span>
 		entry-&gt;e4.ip.invflags = inv ? IPT_INV_PROTO : 0;
 		break;
 	case AF_INET6:
<span class="p_add">+		if (proto)</span>
<span class="p_add">+			entry-&gt;e6.ipv6.flags |= IP6T_F_PROTO;</span>
<span class="p_add">+</span>
 		entry-&gt;e6.ipv6.proto = proto;
 		entry-&gt;e6.ipv6.invflags = inv ? IP6T_INV_PROTO : 0;
 		break;
<span class="p_chunk">@@ -313,6 +316,9 @@</span> <span class="p_context"> nft_match_set_mtchk_param(struct xt_mtchk_param *par, const struct nft_ctx *ctx,</span>
 		entry-&gt;e4.ip.invflags = inv ? IPT_INV_PROTO : 0;
 		break;
 	case AF_INET6:
<span class="p_add">+		if (proto)</span>
<span class="p_add">+			entry-&gt;e6.ipv6.flags |= IP6T_F_PROTO;</span>
<span class="p_add">+</span>
 		entry-&gt;e6.ipv6.proto = proto;
 		entry-&gt;e6.ipv6.invflags = inv ? IP6T_INV_PROTO : 0;
 		break;
<span class="p_header">diff --git a/virt/kvm/arm/vgic.c b/virt/kvm/arm/vgic.c</span>
<span class="p_header">index 1316e558db64..c324a52bb407 100644</span>
<span class="p_header">--- a/virt/kvm/arm/vgic.c</span>
<span class="p_header">+++ b/virt/kvm/arm/vgic.c</span>
<span class="p_chunk">@@ -674,7 +674,7 @@</span> <span class="p_context"> static bool read_set_clear_sgi_pend_reg(struct kvm_vcpu *vcpu,</span>
 {
 	struct vgic_dist *dist = &amp;vcpu-&gt;kvm-&gt;arch.vgic;
 	int sgi;
<span class="p_del">-	int min_sgi = (offset &amp; ~0x3) * 4;</span>
<span class="p_add">+	int min_sgi = (offset &amp; ~0x3);</span>
 	int max_sgi = min_sgi + 3;
 	int vcpu_id = vcpu-&gt;vcpu_id;
 	u32 reg = 0;
<span class="p_chunk">@@ -695,7 +695,7 @@</span> <span class="p_context"> static bool write_set_clear_sgi_pend_reg(struct kvm_vcpu *vcpu,</span>
 {
 	struct vgic_dist *dist = &amp;vcpu-&gt;kvm-&gt;arch.vgic;
 	int sgi;
<span class="p_del">-	int min_sgi = (offset &amp; ~0x3) * 4;</span>
<span class="p_add">+	int min_sgi = (offset &amp; ~0x3);</span>
 	int max_sgi = min_sgi + 3;
 	int vcpu_id = vcpu-&gt;vcpu_id;
 	u32 reg;
<span class="p_chunk">@@ -1387,7 +1387,8 @@</span> <span class="p_context"> out:</span>
 int kvm_vgic_inject_irq(struct kvm *kvm, int cpuid, unsigned int irq_num,
 			bool level)
 {
<span class="p_del">-	if (vgic_update_irq_state(kvm, cpuid, irq_num, level))</span>
<span class="p_add">+	if (likely(vgic_initialized(kvm)) &amp;&amp;</span>
<span class="p_add">+	    vgic_update_irq_state(kvm, cpuid, irq_num, level))</span>
 		vgic_kick_vcpus(kvm);
 
 	return 0;
<span class="p_chunk">@@ -1610,7 +1611,7 @@</span> <span class="p_context"> out:</span>
 
 int kvm_vgic_create(struct kvm *kvm)
 {
<span class="p_del">-	int i, vcpu_lock_idx = -1, ret = 0;</span>
<span class="p_add">+	int i, vcpu_lock_idx = -1, ret;</span>
 	struct kvm_vcpu *vcpu;
 
 	mutex_lock(&amp;kvm-&gt;lock);
<span class="p_chunk">@@ -1625,6 +1626,7 @@</span> <span class="p_context"> int kvm_vgic_create(struct kvm *kvm)</span>
 	 * vcpu-&gt;mutex.  By grabbing the vcpu-&gt;mutex of all VCPUs we ensure
 	 * that no other VCPUs are run while we create the vgic.
 	 */
<span class="p_add">+	ret = -EBUSY;</span>
 	kvm_for_each_vcpu(i, vcpu, kvm) {
 		if (!mutex_trylock(&amp;vcpu-&gt;mutex))
 			goto out_unlock;
<span class="p_chunk">@@ -1632,11 +1634,10 @@</span> <span class="p_context"> int kvm_vgic_create(struct kvm *kvm)</span>
 	}
 
 	kvm_for_each_vcpu(i, vcpu, kvm) {
<span class="p_del">-		if (vcpu-&gt;arch.has_run_once) {</span>
<span class="p_del">-			ret = -EBUSY;</span>
<span class="p_add">+		if (vcpu-&gt;arch.has_run_once)</span>
 			goto out_unlock;
<span class="p_del">-		}</span>
 	}
<span class="p_add">+	ret = 0;</span>
 
 	spin_lock_init(&amp;kvm-&gt;arch.vgic.lock);
 	kvm-&gt;arch.vgic.vctrl_base = vgic_vctrl_base;

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



