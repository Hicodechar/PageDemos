
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>[v4,09/10] hugetlbfs: add hugetlbfs_fallocate() - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    [v4,09/10] hugetlbfs: add hugetlbfs_fallocate()</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=124511">Mike Kravetz</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>July 21, 2015, 6:09 p.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;1437502184-14269-10-git-send-email-mike.kravetz@oracle.com&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/6837521/mbox/"
   >mbox</a>
|
   <a href="/patch/6837521/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/6837521/">/patch/6837521/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
X-Original-To: patchwork-LKML@patchwork.kernel.org
Delivered-To: patchwork-parsemail@patchwork1.web.kernel.org
Received: from mail.kernel.org (mail.kernel.org [198.145.29.136])
	by patchwork1.web.kernel.org (Postfix) with ESMTP id 8F8B99F358
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Tue, 21 Jul 2015 18:13:39 +0000 (UTC)
Received: from mail.kernel.org (localhost [127.0.0.1])
	by mail.kernel.org (Postfix) with ESMTP id 854B8206B2
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Tue, 21 Jul 2015 18:13:38 +0000 (UTC)
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.kernel.org (Postfix) with ESMTP id 486EB206A0
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Tue, 21 Jul 2015 18:13:37 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S933780AbbGUSN1 (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Tue, 21 Jul 2015 14:13:27 -0400
Received: from aserp1040.oracle.com ([141.146.126.69]:28751 &quot;EHLO
	aserp1040.oracle.com&quot; rhost-flags-OK-OK-OK-OK) by vger.kernel.org
	with ESMTP id S933447AbbGUSL1 (ORCPT
	&lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Tue, 21 Jul 2015 14:11:27 -0400
Received: from aserv0021.oracle.com (aserv0021.oracle.com [141.146.126.233])
	by aserp1040.oracle.com (Sentrion-MTA-4.3.2/Sentrion-MTA-4.3.2)
	with ESMTP id t6LIAQtW023420
	(version=TLSv1 cipher=DHE-RSA-AES256-SHA bits=256 verify=OK);
	Tue, 21 Jul 2015 18:10:26 GMT
Received: from userv0121.oracle.com (userv0121.oracle.com [156.151.31.72])
	by aserv0021.oracle.com (8.13.8/8.13.8) with ESMTP id t6LIAQnQ004854
	(version=TLSv1/SSLv3 cipher=DHE-RSA-AES256-SHA bits=256 verify=FAIL); 
	Tue, 21 Jul 2015 18:10:26 GMT
Received: from abhmp0017.oracle.com (abhmp0017.oracle.com [141.146.116.23])
	by userv0121.oracle.com (8.13.8/8.13.8) with ESMTP id
	t6LIAPhA003524; Tue, 21 Jul 2015 18:10:25 GMT
Received: from monkey.oracle.com (/50.53.81.168)
	by default (Oracle Beehive Gateway v4.0)
	with ESMTP ; Tue, 21 Jul 2015 11:10:25 -0700
From: Mike Kravetz &lt;mike.kravetz@oracle.com&gt;
To: linux-mm@kvack.org, linux-kernel@vger.kernel.org,
	linux-api@vger.kernel.org
Cc: Dave Hansen &lt;dave.hansen@linux.intel.com&gt;,
	Naoya Horiguchi &lt;n-horiguchi@ah.jp.nec.com&gt;,
	David Rientjes &lt;rientjes@google.com&gt;, Hugh Dickins &lt;hughd@google.com&gt;,
	Davidlohr Bueso &lt;dave@stgolabs.net&gt;,
	Aneesh Kumar &lt;aneesh.kumar@linux.vnet.ibm.com&gt;,
	Hillf Danton &lt;hillf.zj@alibaba-inc.com&gt;,
	Christoph Hellwig &lt;hch@infradead.org&gt;,
	Andrew Morton &lt;akpm@linux-foundation.org&gt;, Michal Hocko &lt;mhocko@suse.cz&gt;,
	Mike Kravetz &lt;mike.kravetz@oracle.com&gt;
Subject: [PATCH v4 09/10] hugetlbfs: add hugetlbfs_fallocate()
Date: Tue, 21 Jul 2015 11:09:43 -0700
Message-Id: &lt;1437502184-14269-10-git-send-email-mike.kravetz@oracle.com&gt;
X-Mailer: git-send-email 2.1.0
In-Reply-To: &lt;1437502184-14269-1-git-send-email-mike.kravetz@oracle.com&gt;
References: &lt;1437502184-14269-1-git-send-email-mike.kravetz@oracle.com&gt;
X-Source-IP: aserv0021.oracle.com [141.146.126.233]
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Spam-Status: No, score=-8.1 required=5.0 tests=BAYES_00, RCVD_IN_DNSWL_HI, 
	RP_MATCHES_RCVD,
	UNPARSEABLE_RELAY autolearn=unavailable version=3.3.1
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on mail.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=124511">Mike Kravetz</a> - July 21, 2015, 6:09 p.m.</div>
<pre class="content">
This is based on the shmem version, but it has diverged quite
a bit.  We have no swap to worry about, nor the new file sealing.
Add synchronication via the fault mutex table to coordinate
page faults,  fallocate allocation and fallocate hole punch.

What this allows us to do is move physical memory in and out of
a hugetlbfs file without having it mapped.  This also gives us
the ability to support MADV_REMOVE since it is currently
implemented using fallocate().  MADV_REMOVE lets madvise() remove
pages from the middle of a hugetlbfs file, which wasn&#39;t possible
before.

hugetlbfs fallocate only operates on whole huge pages.

Based-on code-by: Dave Hansen &lt;dave.hansen@linux.intel.com&gt;
<span class="signed-off-by">Signed-off-by: Mike Kravetz &lt;mike.kravetz@oracle.com&gt;</span>
---
 fs/hugetlbfs/inode.c    | 158 +++++++++++++++++++++++++++++++++++++++++++++++-
 include/linux/hugetlb.h |   3 +
 mm/hugetlb.c            |   2 +-
 3 files changed, 161 insertions(+), 2 deletions(-)
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=41">Andrew Morton</a> - July 22, 2015, 10:03 p.m.</div>
<pre class="content">
On Tue, 21 Jul 2015 11:09:43 -0700 Mike Kravetz &lt;mike.kravetz@oracle.com&gt; wrote:
<span class="quote">
&gt; This is based on the shmem version, but it has diverged quite</span>
<span class="quote">&gt; a bit.  We have no swap to worry about, nor the new file sealing.</span>
<span class="quote">&gt; Add synchronication via the fault mutex table to coordinate</span>
<span class="quote">&gt; page faults,  fallocate allocation and fallocate hole punch.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; What this allows us to do is move physical memory in and out of</span>
<span class="quote">&gt; a hugetlbfs file without having it mapped.  This also gives us</span>
<span class="quote">&gt; the ability to support MADV_REMOVE since it is currently</span>
<span class="quote">&gt; implemented using fallocate().  MADV_REMOVE lets madvise() remove</span>
<span class="quote">&gt; pages from the middle of a hugetlbfs file, which wasn&#39;t possible</span>
<span class="quote">&gt; before.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; hugetlbfs fallocate only operates on whole huge pages.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; ...</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; +static long hugetlbfs_fallocate(struct file *file, int mode, loff_t offset,</span>
<span class="quote">&gt; +				loff_t len)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	struct inode *inode = file_inode(file);</span>
<span class="quote">&gt; +	struct address_space *mapping = inode-&gt;i_mapping;</span>
<span class="quote">&gt; +	struct hstate *h = hstate_inode(inode);</span>
<span class="quote">&gt; +	struct vm_area_struct pseudo_vma;</span>
<span class="quote">&gt; +	struct mm_struct *mm = current-&gt;mm;</span>
<span class="quote">&gt; +	loff_t hpage_size = huge_page_size(h);</span>
<span class="quote">&gt; +	unsigned long hpage_shift = huge_page_shift(h);</span>
<span class="quote">&gt; +	pgoff_t start, index, end;</span>
<span class="quote">&gt; +	int error;</span>
<span class="quote">&gt; +	u32 hash;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	if (mode &amp; ~(FALLOC_FL_KEEP_SIZE | FALLOC_FL_PUNCH_HOLE))</span>
<span class="quote">&gt; +		return -EOPNOTSUPP;</span>

EOPNOTSUPP is a networking thing.  It&#39;s inappropriate here.

The problem is that if this error is ever returned to userspace, the
user will be sitting looking at &quot;Operation not supported on transport
endpoint&quot; and wondering what went wrong in the networking stack.
<span class="quote">
&gt; +	if (mode &amp; FALLOC_FL_PUNCH_HOLE)</span>
<span class="quote">&gt; +		return hugetlbfs_punch_hole(inode, offset, len);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	/*</span>
<span class="quote">&gt; +	 * Default preallocate case.</span>
<span class="quote">&gt; +	 * For this range, start is rounded down and end is rounded up</span>
<span class="quote">&gt; +	 * as well as being converted to page offsets.</span>
<span class="quote">&gt; +	 */</span>
<span class="quote">&gt; +	start = offset &gt;&gt; hpage_shift;</span>
<span class="quote">&gt; +	end = (offset + len + hpage_size - 1) &gt;&gt; hpage_shift;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	mutex_lock(&amp;inode-&gt;i_mutex);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	/* We need to check rlimit even when FALLOC_FL_KEEP_SIZE */</span>
<span class="quote">&gt; +	error = inode_newsize_ok(inode, offset + len);</span>
<span class="quote">&gt; +	if (error)</span>
<span class="quote">&gt; +		goto out;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	/*</span>
<span class="quote">&gt; +	 * Initialize a pseudo vma that just contains the policy used</span>
<span class="quote">&gt; +	 * when allocating the huge pages.  The actual policy field</span>
<span class="quote">&gt; +	 * (vm_policy) is determined based on the index in the loop below.</span>
<span class="quote">&gt; +	 */</span>
<span class="quote">&gt; +	memset(&amp;pseudo_vma, 0, sizeof(struct vm_area_struct));</span>
<span class="quote">&gt; +	pseudo_vma.vm_flags = (VM_HUGETLB | VM_MAYSHARE | VM_SHARED);</span>
<span class="quote">&gt; +	pseudo_vma.vm_file = file;</span>

triviata: we could have just done

	struct vm_area_struct pseudo_vma = {
		.vm_flags = ...
		.vm_file = file;
	};
<span class="quote">
&gt; +	for (index = start; index &lt; end; index++) {</span>
<span class="quote">&gt; +		/*</span>
<span class="quote">&gt; +		 * This is supposed to be the vaddr where the page is being</span>
<span class="quote">&gt; +		 * faulted in, but we have no vaddr here.</span>
<span class="quote">&gt; +		 */</span>
<span class="quote">&gt; +		struct page *page;</span>
<span class="quote">&gt; +		unsigned long addr;</span>
<span class="quote">&gt; +		int avoid_reserve = 0;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +		cond_resched();</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +		/*</span>
<span class="quote">&gt; +		 * fallocate(2) manpage permits EINTR; we may have been</span>
<span class="quote">&gt; +		 * interrupted because we are using up too much memory.</span>
<span class="quote">&gt; +		 */</span>
<span class="quote">&gt; +		if (signal_pending(current)) {</span>
<span class="quote">&gt; +			error = -EINTR;</span>
<span class="quote">&gt; +			break;</span>
<span class="quote">&gt; +		}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +		/* Get policy based on index */</span>
<span class="quote">&gt; +		pseudo_vma.vm_policy =</span>
<span class="quote">&gt; +			mpol_shared_policy_lookup(&amp;HUGETLBFS_I(inode)-&gt;policy,</span>
<span class="quote">&gt; +							index);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +		/* addr is the offset within the file (zero based) */</span>

So use loff_t?
<span class="quote">
&gt; +		addr = index * hpage_size;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +		/* mutex taken here, fault path and hole punch */</span>
<span class="quote">&gt; +		hash = hugetlb_fault_mutex_hash(h, mm, &amp;pseudo_vma, mapping,</span>
<span class="quote">&gt; +						index, addr);</span>
<span class="quote">&gt; +		mutex_lock(&amp;hugetlb_fault_mutex_table[hash]);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +		/* See if already present in mapping to avoid alloc/free */</span>
<span class="quote">&gt; +		page = find_get_page(mapping, index);</span>
<span class="quote">&gt; +		if (page) {</span>
<span class="quote">&gt; +			put_page(page);</span>
<span class="quote">&gt; +			mutex_unlock(&amp;hugetlb_fault_mutex_table[hash]);</span>
<span class="quote">&gt; +			mpol_cond_put(pseudo_vma.vm_policy);</span>
<span class="quote">&gt; +			continue;</span>
<span class="quote">&gt; +		}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +		/* Allocate page and add to page cache */</span>
<span class="quote">&gt; +		page = alloc_huge_page(&amp;pseudo_vma, addr, avoid_reserve);</span>
<span class="quote">&gt; +		mpol_cond_put(pseudo_vma.vm_policy);</span>
<span class="quote">&gt; +		if (IS_ERR(page)) {</span>
<span class="quote">&gt; +			mutex_unlock(&amp;hugetlb_fault_mutex_table[hash]);</span>
<span class="quote">&gt; +			error = PTR_ERR(page);</span>
<span class="quote">&gt; +			goto out;</span>
<span class="quote">&gt; +		}</span>
<span class="quote">&gt; +		clear_huge_page(page, addr, pages_per_huge_page(h));</span>
<span class="quote">&gt; +		__SetPageUptodate(page);</span>
<span class="quote">&gt; +		error = huge_add_to_page_cache(page, mapping, index);</span>
<span class="quote">&gt; +		if (unlikely(error)) {</span>
<span class="quote">&gt; +			put_page(page);</span>
<span class="quote">&gt; +			mutex_unlock(&amp;hugetlb_fault_mutex_table[hash]);</span>
<span class="quote">&gt; +			goto out;</span>
<span class="quote">&gt; +		}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +		mutex_unlock(&amp;hugetlb_fault_mutex_table[hash]);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +		/*</span>
<span class="quote">&gt; +		 * page_put due to reference from alloc_huge_page()</span>
<span class="quote">&gt; +		 * unlock_page because locked by add_to_page_cache()</span>
<span class="quote">&gt; +		 */</span>
<span class="quote">&gt; +		put_page(page);</span>
<span class="quote">&gt; +		unlock_page(page);</span>
<span class="quote">&gt; +	}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	if (!(mode &amp; FALLOC_FL_KEEP_SIZE) &amp;&amp; offset + len &gt; inode-&gt;i_size)</span>
<span class="quote">&gt; +		i_size_write(inode, offset + len);</span>
<span class="quote">&gt; +	inode-&gt;i_ctime = CURRENT_TIME;</span>
<span class="quote">&gt; +	spin_lock(&amp;inode-&gt;i_lock);</span>
<span class="quote">&gt; +	inode-&gt;i_private = NULL;</span>
<span class="quote">&gt; +	spin_unlock(&amp;inode-&gt;i_lock);</span>
<span class="quote">&gt; +out:</span>
<span class="quote">&gt; +	mutex_unlock(&amp;inode-&gt;i_mutex);</span>
<span class="quote">&gt; +	return error;</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; ...</span>
<span class="quote">&gt;</span>

--
To unsubscribe from this list: send the line &quot;unsubscribe linux-kernel&quot; in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
Please read the FAQ at  http://www.tux.org/lkml/
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=124511">Mike Kravetz</a> - July 22, 2015, 10:23 p.m.</div>
<pre class="content">
On 07/22/2015 03:03 PM, Andrew Morton wrote:
<span class="quote">&gt; On Tue, 21 Jul 2015 11:09:43 -0700 Mike Kravetz &lt;mike.kravetz@oracle.com&gt; wrote:</span>
...
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +	if (mode &amp; ~(FALLOC_FL_KEEP_SIZE | FALLOC_FL_PUNCH_HOLE))</span>
<span class="quote">&gt;&gt; +		return -EOPNOTSUPP;</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; EOPNOTSUPP is a networking thing.  It&#39;s inappropriate here.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; The problem is that if this error is ever returned to userspace, the</span>
<span class="quote">&gt; user will be sitting looking at &quot;Operation not supported on transport</span>
<span class="quote">&gt; endpoint&quot; and wondering what went wrong in the networking stack.</span>

Trying to follow FALLOCATE(2) man page:

&quot;EOPNOTSUPP
	The filesystem containing the file referred to by  fd  does  not
	support  this  operation;  or  the  mode is not supported by the
	filesystem containing the file referred to by fd.&quot;
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=41">Andrew Morton</a> - July 22, 2015, 10:30 p.m.</div>
<pre class="content">
On Wed, 22 Jul 2015 15:23:42 -0700 Mike Kravetz &lt;mike.kravetz@oracle.com&gt; wrote:
<span class="quote">
&gt; On 07/22/2015 03:03 PM, Andrew Morton wrote:</span>
<span class="quote">&gt; &gt; On Tue, 21 Jul 2015 11:09:43 -0700 Mike Kravetz &lt;mike.kravetz@oracle.com&gt; wrote:</span>
<span class="quote">&gt; ...</span>
<span class="quote">&gt; &gt;&gt; +</span>
<span class="quote">&gt; &gt;&gt; +	if (mode &amp; ~(FALLOC_FL_KEEP_SIZE | FALLOC_FL_PUNCH_HOLE))</span>
<span class="quote">&gt; &gt;&gt; +		return -EOPNOTSUPP;</span>
<span class="quote">&gt; &gt;</span>
<span class="quote">&gt; &gt; EOPNOTSUPP is a networking thing.  It&#39;s inappropriate here.</span>
<span class="quote">&gt; &gt;</span>
<span class="quote">&gt; &gt; The problem is that if this error is ever returned to userspace, the</span>
<span class="quote">&gt; &gt; user will be sitting looking at &quot;Operation not supported on transport</span>
<span class="quote">&gt; &gt; endpoint&quot; and wondering what went wrong in the networking stack.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Trying to follow FALLOCATE(2) man page:</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; &quot;EOPNOTSUPP</span>
<span class="quote">&gt; 	The filesystem containing the file referred to by  fd  does  not</span>
<span class="quote">&gt; 	support  this  operation;  or  the  mode is not supported by the</span>
<span class="quote">&gt; 	filesystem containing the file referred to by fd.&quot;</span>
<span class="quote">&gt; </span>

Sigh.
--
To unsubscribe from this list: send the line &quot;unsubscribe linux-kernel&quot; in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
Please read the FAQ at  http://www.tux.org/lkml/
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/fs/hugetlbfs/inode.c b/fs/hugetlbfs/inode.c</span>
<span class="p_header">index a974e4b..6e565a4 100644</span>
<span class="p_header">--- a/fs/hugetlbfs/inode.c</span>
<span class="p_header">+++ b/fs/hugetlbfs/inode.c</span>
<span class="p_chunk">@@ -12,6 +12,7 @@</span> <span class="p_context"></span>
 #include &lt;linux/thread_info.h&gt;
 #include &lt;asm/current.h&gt;
 #include &lt;linux/sched.h&gt;		/* remove ASAP */
<span class="p_add">+#include &lt;linux/falloc.h&gt;</span>
 #include &lt;linux/fs.h&gt;
 #include &lt;linux/mount.h&gt;
 #include &lt;linux/file.h&gt;
<span class="p_chunk">@@ -479,6 +480,160 @@</span> <span class="p_context"> static int hugetlb_vmtruncate(struct inode *inode, loff_t offset)</span>
 	return 0;
 }
 
<span class="p_add">+static long hugetlbfs_punch_hole(struct inode *inode, loff_t offset, loff_t len)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct hstate *h = hstate_inode(inode);</span>
<span class="p_add">+	loff_t hpage_size = huge_page_size(h);</span>
<span class="p_add">+	loff_t hole_start, hole_end;</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * For hole punch round up the beginning offset of the hole and</span>
<span class="p_add">+	 * round down the end.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	hole_start = round_up(offset, hpage_size);</span>
<span class="p_add">+	hole_end = round_down(offset + len, hpage_size);</span>
<span class="p_add">+</span>
<span class="p_add">+	if (hole_end &gt; hole_start) {</span>
<span class="p_add">+		struct address_space *mapping = inode-&gt;i_mapping;</span>
<span class="p_add">+</span>
<span class="p_add">+		mutex_lock(&amp;inode-&gt;i_mutex);</span>
<span class="p_add">+		i_mmap_lock_write(mapping);</span>
<span class="p_add">+		if (!RB_EMPTY_ROOT(&amp;mapping-&gt;i_mmap))</span>
<span class="p_add">+			hugetlb_vmdelete_list(&amp;mapping-&gt;i_mmap,</span>
<span class="p_add">+						hole_start &gt;&gt; PAGE_SHIFT,</span>
<span class="p_add">+						hole_end  &gt;&gt; PAGE_SHIFT);</span>
<span class="p_add">+		i_mmap_unlock_write(mapping);</span>
<span class="p_add">+		remove_inode_hugepages(inode, hole_start, hole_end);</span>
<span class="p_add">+		mutex_unlock(&amp;inode-&gt;i_mutex);</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	return 0;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static long hugetlbfs_fallocate(struct file *file, int mode, loff_t offset,</span>
<span class="p_add">+				loff_t len)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct inode *inode = file_inode(file);</span>
<span class="p_add">+	struct address_space *mapping = inode-&gt;i_mapping;</span>
<span class="p_add">+	struct hstate *h = hstate_inode(inode);</span>
<span class="p_add">+	struct vm_area_struct pseudo_vma;</span>
<span class="p_add">+	struct mm_struct *mm = current-&gt;mm;</span>
<span class="p_add">+	loff_t hpage_size = huge_page_size(h);</span>
<span class="p_add">+	unsigned long hpage_shift = huge_page_shift(h);</span>
<span class="p_add">+	pgoff_t start, index, end;</span>
<span class="p_add">+	int error;</span>
<span class="p_add">+	u32 hash;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (mode &amp; ~(FALLOC_FL_KEEP_SIZE | FALLOC_FL_PUNCH_HOLE))</span>
<span class="p_add">+		return -EOPNOTSUPP;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (mode &amp; FALLOC_FL_PUNCH_HOLE)</span>
<span class="p_add">+		return hugetlbfs_punch_hole(inode, offset, len);</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Default preallocate case.</span>
<span class="p_add">+	 * For this range, start is rounded down and end is rounded up</span>
<span class="p_add">+	 * as well as being converted to page offsets.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	start = offset &gt;&gt; hpage_shift;</span>
<span class="p_add">+	end = (offset + len + hpage_size - 1) &gt;&gt; hpage_shift;</span>
<span class="p_add">+</span>
<span class="p_add">+	mutex_lock(&amp;inode-&gt;i_mutex);</span>
<span class="p_add">+</span>
<span class="p_add">+	/* We need to check rlimit even when FALLOC_FL_KEEP_SIZE */</span>
<span class="p_add">+	error = inode_newsize_ok(inode, offset + len);</span>
<span class="p_add">+	if (error)</span>
<span class="p_add">+		goto out;</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Initialize a pseudo vma that just contains the policy used</span>
<span class="p_add">+	 * when allocating the huge pages.  The actual policy field</span>
<span class="p_add">+	 * (vm_policy) is determined based on the index in the loop below.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	memset(&amp;pseudo_vma, 0, sizeof(struct vm_area_struct));</span>
<span class="p_add">+	pseudo_vma.vm_flags = (VM_HUGETLB | VM_MAYSHARE | VM_SHARED);</span>
<span class="p_add">+	pseudo_vma.vm_file = file;</span>
<span class="p_add">+</span>
<span class="p_add">+	for (index = start; index &lt; end; index++) {</span>
<span class="p_add">+		/*</span>
<span class="p_add">+		 * This is supposed to be the vaddr where the page is being</span>
<span class="p_add">+		 * faulted in, but we have no vaddr here.</span>
<span class="p_add">+		 */</span>
<span class="p_add">+		struct page *page;</span>
<span class="p_add">+		unsigned long addr;</span>
<span class="p_add">+		int avoid_reserve = 0;</span>
<span class="p_add">+</span>
<span class="p_add">+		cond_resched();</span>
<span class="p_add">+</span>
<span class="p_add">+		/*</span>
<span class="p_add">+		 * fallocate(2) manpage permits EINTR; we may have been</span>
<span class="p_add">+		 * interrupted because we are using up too much memory.</span>
<span class="p_add">+		 */</span>
<span class="p_add">+		if (signal_pending(current)) {</span>
<span class="p_add">+			error = -EINTR;</span>
<span class="p_add">+			break;</span>
<span class="p_add">+		}</span>
<span class="p_add">+</span>
<span class="p_add">+		/* Get policy based on index */</span>
<span class="p_add">+		pseudo_vma.vm_policy =</span>
<span class="p_add">+			mpol_shared_policy_lookup(&amp;HUGETLBFS_I(inode)-&gt;policy,</span>
<span class="p_add">+							index);</span>
<span class="p_add">+</span>
<span class="p_add">+		/* addr is the offset within the file (zero based) */</span>
<span class="p_add">+		addr = index * hpage_size;</span>
<span class="p_add">+</span>
<span class="p_add">+		/* mutex taken here, fault path and hole punch */</span>
<span class="p_add">+		hash = hugetlb_fault_mutex_hash(h, mm, &amp;pseudo_vma, mapping,</span>
<span class="p_add">+						index, addr);</span>
<span class="p_add">+		mutex_lock(&amp;hugetlb_fault_mutex_table[hash]);</span>
<span class="p_add">+</span>
<span class="p_add">+		/* See if already present in mapping to avoid alloc/free */</span>
<span class="p_add">+		page = find_get_page(mapping, index);</span>
<span class="p_add">+		if (page) {</span>
<span class="p_add">+			put_page(page);</span>
<span class="p_add">+			mutex_unlock(&amp;hugetlb_fault_mutex_table[hash]);</span>
<span class="p_add">+			mpol_cond_put(pseudo_vma.vm_policy);</span>
<span class="p_add">+			continue;</span>
<span class="p_add">+		}</span>
<span class="p_add">+</span>
<span class="p_add">+		/* Allocate page and add to page cache */</span>
<span class="p_add">+		page = alloc_huge_page(&amp;pseudo_vma, addr, avoid_reserve);</span>
<span class="p_add">+		mpol_cond_put(pseudo_vma.vm_policy);</span>
<span class="p_add">+		if (IS_ERR(page)) {</span>
<span class="p_add">+			mutex_unlock(&amp;hugetlb_fault_mutex_table[hash]);</span>
<span class="p_add">+			error = PTR_ERR(page);</span>
<span class="p_add">+			goto out;</span>
<span class="p_add">+		}</span>
<span class="p_add">+		clear_huge_page(page, addr, pages_per_huge_page(h));</span>
<span class="p_add">+		__SetPageUptodate(page);</span>
<span class="p_add">+		error = huge_add_to_page_cache(page, mapping, index);</span>
<span class="p_add">+		if (unlikely(error)) {</span>
<span class="p_add">+			put_page(page);</span>
<span class="p_add">+			mutex_unlock(&amp;hugetlb_fault_mutex_table[hash]);</span>
<span class="p_add">+			goto out;</span>
<span class="p_add">+		}</span>
<span class="p_add">+</span>
<span class="p_add">+		mutex_unlock(&amp;hugetlb_fault_mutex_table[hash]);</span>
<span class="p_add">+</span>
<span class="p_add">+		/*</span>
<span class="p_add">+		 * page_put due to reference from alloc_huge_page()</span>
<span class="p_add">+		 * unlock_page because locked by add_to_page_cache()</span>
<span class="p_add">+		 */</span>
<span class="p_add">+		put_page(page);</span>
<span class="p_add">+		unlock_page(page);</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	if (!(mode &amp; FALLOC_FL_KEEP_SIZE) &amp;&amp; offset + len &gt; inode-&gt;i_size)</span>
<span class="p_add">+		i_size_write(inode, offset + len);</span>
<span class="p_add">+	inode-&gt;i_ctime = CURRENT_TIME;</span>
<span class="p_add">+	spin_lock(&amp;inode-&gt;i_lock);</span>
<span class="p_add">+	inode-&gt;i_private = NULL;</span>
<span class="p_add">+	spin_unlock(&amp;inode-&gt;i_lock);</span>
<span class="p_add">+out:</span>
<span class="p_add">+	mutex_unlock(&amp;inode-&gt;i_mutex);</span>
<span class="p_add">+	return error;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static int hugetlbfs_setattr(struct dentry *dentry, struct iattr *attr)
 {
 	struct inode *inode = d_inode(dentry);
<span class="p_chunk">@@ -790,7 +945,8 @@</span> <span class="p_context"> const struct file_operations hugetlbfs_file_operations = {</span>
 	.mmap			= hugetlbfs_file_mmap,
 	.fsync			= noop_fsync,
 	.get_unmapped_area	= hugetlb_get_unmapped_area,
<span class="p_del">-	.llseek		= default_llseek,</span>
<span class="p_add">+	.llseek			= default_llseek,</span>
<span class="p_add">+	.fallocate		= hugetlbfs_fallocate,</span>
 };
 
 static const struct inode_operations hugetlbfs_dir_inode_operations = {
<span class="p_header">diff --git a/include/linux/hugetlb.h b/include/linux/hugetlb.h</span>
<span class="p_header">index 657ef26..386dcbf 100644</span>
<span class="p_header">--- a/include/linux/hugetlb.h</span>
<span class="p_header">+++ b/include/linux/hugetlb.h</span>
<span class="p_chunk">@@ -330,6 +330,8 @@</span> <span class="p_context"> struct huge_bootmem_page {</span>
 #endif
 };
 
<span class="p_add">+struct page *alloc_huge_page(struct vm_area_struct *vma,</span>
<span class="p_add">+				unsigned long addr, int avoid_reserve);</span>
 struct page *alloc_huge_page_node(struct hstate *h, int nid);
 struct page *alloc_huge_page_noerr(struct vm_area_struct *vma,
 				unsigned long addr, int avoid_reserve);
<span class="p_chunk">@@ -483,6 +485,7 @@</span> <span class="p_context"> static inline spinlock_t *huge_pte_lockptr(struct hstate *h,</span>
 
 #else	/* CONFIG_HUGETLB_PAGE */
 struct hstate {};
<span class="p_add">+#define alloc_huge_page(v, a, r) NULL</span>
 #define alloc_huge_page_node(h, nid) NULL
 #define alloc_huge_page_noerr(v, a, r) NULL
 #define alloc_bootmem_huge_page(h) NULL
<span class="p_header">diff --git a/mm/hugetlb.c b/mm/hugetlb.c</span>
<span class="p_header">index 9812785..e9acf24 100644</span>
<span class="p_header">--- a/mm/hugetlb.c</span>
<span class="p_header">+++ b/mm/hugetlb.c</span>
<span class="p_chunk">@@ -1729,7 +1729,7 @@</span> <span class="p_context"> static void vma_end_reservation(struct hstate *h,</span>
 	(void)__vma_reservation_common(h, vma, addr, VMA_END_RESV);
 }
 
<span class="p_del">-static struct page *alloc_huge_page(struct vm_area_struct *vma,</span>
<span class="p_add">+struct page *alloc_huge_page(struct vm_area_struct *vma,</span>
 				    unsigned long addr, int avoid_reserve)
 {
 	struct hugepage_subpool *spool = subpool_vma(vma);

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



