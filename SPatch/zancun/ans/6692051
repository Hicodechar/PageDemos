
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>Linux 3.14.46 - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    Linux 3.14.46</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=37061">gregkh@linuxfoundation.org</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>June 29, 2015, 8:46 p.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;20150629204606.GB19372@kroah.com&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/6692051/mbox/"
   >mbox</a>
|
   <a href="/patch/6692051/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/6692051/">/patch/6692051/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
X-Original-To: patchwork-LKML@patchwork.kernel.org
Delivered-To: patchwork-parsemail@patchwork2.web.kernel.org
Received: from mail.kernel.org (mail.kernel.org [198.145.29.136])
	by patchwork2.web.kernel.org (Postfix) with ESMTP id 5CD64C05AC
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Mon, 29 Jun 2015 20:46:37 +0000 (UTC)
Received: from mail.kernel.org (localhost [127.0.0.1])
	by mail.kernel.org (Postfix) with ESMTP id 53BF9205F9
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Mon, 29 Jun 2015 20:46:35 +0000 (UTC)
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.kernel.org (Postfix) with ESMTP id 269E1205FD
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Mon, 29 Jun 2015 20:46:33 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1753573AbbF2Uq2 (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Mon, 29 Jun 2015 16:46:28 -0400
Received: from mail.linuxfoundation.org ([140.211.169.12]:50717 &quot;EHLO
	mail.linuxfoundation.org&quot; rhost-flags-OK-OK-OK-OK) by vger.kernel.org
	with ESMTP id S1753996AbbF2UqI (ORCPT
	&lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Mon, 29 Jun 2015 16:46:08 -0400
Received: from localhost (c-50-170-35-168.hsd1.wa.comcast.net
	[50.170.35.168])
	by mail.linuxfoundation.org (Postfix) with ESMTPSA id 2841FBC2;
	Mon, 29 Jun 2015 20:46:07 +0000 (UTC)
Date: Mon, 29 Jun 2015 13:46:06 -0700
From: Greg KH &lt;gregkh@linuxfoundation.org&gt;
To: linux-kernel@vger.kernel.org, Andrew Morton &lt;akpm@linux-foundation.org&gt;,
	torvalds@linux-foundation.org, stable@vger.kernel.org
Cc: lwn@lwn.net, Jiri Slaby &lt;jslaby@suse.cz&gt;
Subject: Re: Linux 3.14.46
Message-ID: &lt;20150629204606.GB19372@kroah.com&gt;
References: &lt;20150629204558.GA19372@kroah.com&gt;
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Disposition: inline
In-Reply-To: &lt;20150629204558.GA19372@kroah.com&gt;
User-Agent: Mutt/1.5.23+89 (0255b37be491) (2014-03-12)
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Spam-Status: No, score=-7.5 required=5.0 tests=BAYES_00, RCVD_IN_DNSWL_HI, 
	RP_MATCHES_RCVD,
	UNPARSEABLE_RELAY autolearn=unavailable version=3.3.1
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on mail.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=37061">gregkh@linuxfoundation.org</a> - June 29, 2015, 8:46 p.m.</div>
<pre class="content">
--
To unsubscribe from this list: send the line &quot;unsubscribe linux-kernel&quot; in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
Please read the FAQ at  http://www.tux.org/lkml/
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/Makefile b/Makefile</span>
<span class="p_header">index c92186c3efd7..def39fdd9df4 100644</span>
<span class="p_header">--- a/Makefile</span>
<span class="p_header">+++ b/Makefile</span>
<span class="p_chunk">@@ -1,6 +1,6 @@</span> <span class="p_context"></span>
 VERSION = 3
 PATCHLEVEL = 14
<span class="p_del">-SUBLEVEL = 45</span>
<span class="p_add">+SUBLEVEL = 46</span>
 EXTRAVERSION =
 NAME = Remembering Coco
 
<span class="p_header">diff --git a/arch/arm/include/asm/kvm_host.h b/arch/arm/include/asm/kvm_host.h</span>
<span class="p_header">index 09af14999c9b..530f56e19931 100644</span>
<span class="p_header">--- a/arch/arm/include/asm/kvm_host.h</span>
<span class="p_header">+++ b/arch/arm/include/asm/kvm_host.h</span>
<span class="p_chunk">@@ -42,7 +42,7 @@</span> <span class="p_context"></span>
 
 struct kvm_vcpu;
 u32 *kvm_vcpu_reg(struct kvm_vcpu *vcpu, u8 reg_num, u32 mode);
<span class="p_del">-int kvm_target_cpu(void);</span>
<span class="p_add">+int __attribute_const__ kvm_target_cpu(void);</span>
 int kvm_reset_vcpu(struct kvm_vcpu *vcpu);
 void kvm_reset_coprocs(struct kvm_vcpu *vcpu);
 
<span class="p_header">diff --git a/arch/arm/include/asm/kvm_mmu.h b/arch/arm/include/asm/kvm_mmu.h</span>
<span class="p_header">index 7b362bc9c09a..0cbdb8ed71cf 100644</span>
<span class="p_header">--- a/arch/arm/include/asm/kvm_mmu.h</span>
<span class="p_header">+++ b/arch/arm/include/asm/kvm_mmu.h</span>
<span class="p_chunk">@@ -127,6 +127,18 @@</span> <span class="p_context"> static inline void kvm_set_s2pmd_writable(pmd_t *pmd)</span>
 	(__boundary - 1 &lt; (end) - 1)? __boundary: (end);		\
 })
 
<span class="p_add">+static inline bool kvm_page_empty(void *ptr)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct page *ptr_page = virt_to_page(ptr);</span>
<span class="p_add">+	return page_count(ptr_page) == 1;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+</span>
<span class="p_add">+#define kvm_pte_table_empty(ptep) kvm_page_empty(ptep)</span>
<span class="p_add">+#define kvm_pmd_table_empty(pmdp) kvm_page_empty(pmdp)</span>
<span class="p_add">+#define kvm_pud_table_empty(pudp) (0)</span>
<span class="p_add">+</span>
<span class="p_add">+</span>
 struct kvm;
 
 #define kvm_flush_dcache_to_poc(a,l)	__cpuc_flush_dcache_area((a), (l))
<span class="p_header">diff --git a/arch/arm/kernel/hyp-stub.S b/arch/arm/kernel/hyp-stub.S</span>
<span class="p_header">index 797b1a6a4906..7e666cfda634 100644</span>
<span class="p_header">--- a/arch/arm/kernel/hyp-stub.S</span>
<span class="p_header">+++ b/arch/arm/kernel/hyp-stub.S</span>
<span class="p_chunk">@@ -134,9 +134,7 @@</span> <span class="p_context"> ENTRY(__hyp_stub_install_secondary)</span>
 	mcr	p15, 4, r7, c1, c1, 3	@ HSTR
 
 THUMB(	orr	r7, #(1 &lt;&lt; 30)	)	@ HSCTLR.TE
<span class="p_del">-#ifdef CONFIG_CPU_BIG_ENDIAN</span>
<span class="p_del">-	orr	r7, #(1 &lt;&lt; 9)		@ HSCTLR.EE</span>
<span class="p_del">-#endif</span>
<span class="p_add">+ARM_BE8(orr	r7, r7, #(1 &lt;&lt; 25))     @ HSCTLR.EE</span>
 	mcr	p15, 4, r7, c1, c0, 0	@ HSCTLR
 
 	mrc	p15, 4, r7, c1, c1, 1	@ HDCR
<span class="p_header">diff --git a/arch/arm/kvm/arm.c b/arch/arm/kvm/arm.c</span>
<span class="p_header">index bd18bb8b2770..df6e75e47ae0 100644</span>
<span class="p_header">--- a/arch/arm/kvm/arm.c</span>
<span class="p_header">+++ b/arch/arm/kvm/arm.c</span>
<span class="p_chunk">@@ -82,7 +82,7 @@</span> <span class="p_context"> struct kvm_vcpu *kvm_arm_get_running_vcpu(void)</span>
 /**
  * kvm_arm_get_running_vcpus - get the per-CPU array of currently running vcpus.
  */
<span class="p_del">-struct kvm_vcpu __percpu **kvm_get_running_vcpus(void)</span>
<span class="p_add">+struct kvm_vcpu * __percpu *kvm_get_running_vcpus(void)</span>
 {
 	return &amp;kvm_arm_running_vcpu;
 }
<span class="p_chunk">@@ -155,16 +155,6 @@</span> <span class="p_context"> int kvm_arch_vcpu_fault(struct kvm_vcpu *vcpu, struct vm_fault *vmf)</span>
 	return VM_FAULT_SIGBUS;
 }
 
<span class="p_del">-void kvm_arch_free_memslot(struct kvm *kvm, struct kvm_memory_slot *free,</span>
<span class="p_del">-			   struct kvm_memory_slot *dont)</span>
<span class="p_del">-{</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-int kvm_arch_create_memslot(struct kvm *kvm, struct kvm_memory_slot *slot,</span>
<span class="p_del">-			    unsigned long npages)</span>
<span class="p_del">-{</span>
<span class="p_del">-	return 0;</span>
<span class="p_del">-}</span>
 
 /**
  * kvm_arch_destroy_vm - destroy the VM data structure
<span class="p_chunk">@@ -224,33 +214,6 @@</span> <span class="p_context"> long kvm_arch_dev_ioctl(struct file *filp,</span>
 	return -EINVAL;
 }
 
<span class="p_del">-void kvm_arch_memslots_updated(struct kvm *kvm)</span>
<span class="p_del">-{</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-int kvm_arch_prepare_memory_region(struct kvm *kvm,</span>
<span class="p_del">-				   struct kvm_memory_slot *memslot,</span>
<span class="p_del">-				   struct kvm_userspace_memory_region *mem,</span>
<span class="p_del">-				   enum kvm_mr_change change)</span>
<span class="p_del">-{</span>
<span class="p_del">-	return 0;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-void kvm_arch_commit_memory_region(struct kvm *kvm,</span>
<span class="p_del">-				   struct kvm_userspace_memory_region *mem,</span>
<span class="p_del">-				   const struct kvm_memory_slot *old,</span>
<span class="p_del">-				   enum kvm_mr_change change)</span>
<span class="p_del">-{</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-void kvm_arch_flush_shadow_all(struct kvm *kvm)</span>
<span class="p_del">-{</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-void kvm_arch_flush_shadow_memslot(struct kvm *kvm,</span>
<span class="p_del">-				   struct kvm_memory_slot *slot)</span>
<span class="p_del">-{</span>
<span class="p_del">-}</span>
 
 struct kvm_vcpu *kvm_arch_vcpu_create(struct kvm *kvm, unsigned int id)
 {
<span class="p_header">diff --git a/arch/arm/kvm/coproc.c b/arch/arm/kvm/coproc.c</span>
<span class="p_header">index c58a35116f63..7c732908f1df 100644</span>
<span class="p_header">--- a/arch/arm/kvm/coproc.c</span>
<span class="p_header">+++ b/arch/arm/kvm/coproc.c</span>
<span class="p_chunk">@@ -742,7 +742,7 @@</span> <span class="p_context"> static bool is_valid_cache(u32 val)</span>
 	u32 level, ctype;
 
 	if (val &gt;= CSSELR_MAX)
<span class="p_del">-		return -ENOENT;</span>
<span class="p_add">+		return false;</span>
 
 	/* Bottom bit is Instruction or Data bit.  Next 3 bits are level. */
         level = (val &gt;&gt; 1);
<span class="p_header">diff --git a/arch/arm/kvm/mmu.c b/arch/arm/kvm/mmu.c</span>
<span class="p_header">index c93ef38f9cb0..70ed2c1f57b0 100644</span>
<span class="p_header">--- a/arch/arm/kvm/mmu.c</span>
<span class="p_header">+++ b/arch/arm/kvm/mmu.c</span>
<span class="p_chunk">@@ -90,103 +90,115 @@</span> <span class="p_context"> static void *mmu_memory_cache_alloc(struct kvm_mmu_memory_cache *mc)</span>
 	return p;
 }
 
<span class="p_del">-static bool page_empty(void *ptr)</span>
<span class="p_add">+static void clear_pgd_entry(struct kvm *kvm, pgd_t *pgd, phys_addr_t addr)</span>
 {
<span class="p_del">-	struct page *ptr_page = virt_to_page(ptr);</span>
<span class="p_del">-	return page_count(ptr_page) == 1;</span>
<span class="p_add">+	pud_t *pud_table __maybe_unused = pud_offset(pgd, 0);</span>
<span class="p_add">+	pgd_clear(pgd);</span>
<span class="p_add">+	kvm_tlb_flush_vmid_ipa(kvm, addr);</span>
<span class="p_add">+	pud_free(NULL, pud_table);</span>
<span class="p_add">+	put_page(virt_to_page(pgd));</span>
 }
 
 static void clear_pud_entry(struct kvm *kvm, pud_t *pud, phys_addr_t addr)
 {
<span class="p_del">-	if (pud_huge(*pud)) {</span>
<span class="p_del">-		pud_clear(pud);</span>
<span class="p_del">-		kvm_tlb_flush_vmid_ipa(kvm, addr);</span>
<span class="p_del">-	} else {</span>
<span class="p_del">-		pmd_t *pmd_table = pmd_offset(pud, 0);</span>
<span class="p_del">-		pud_clear(pud);</span>
<span class="p_del">-		kvm_tlb_flush_vmid_ipa(kvm, addr);</span>
<span class="p_del">-		pmd_free(NULL, pmd_table);</span>
<span class="p_del">-	}</span>
<span class="p_add">+	pmd_t *pmd_table = pmd_offset(pud, 0);</span>
<span class="p_add">+	VM_BUG_ON(pud_huge(*pud));</span>
<span class="p_add">+	pud_clear(pud);</span>
<span class="p_add">+	kvm_tlb_flush_vmid_ipa(kvm, addr);</span>
<span class="p_add">+	pmd_free(NULL, pmd_table);</span>
 	put_page(virt_to_page(pud));
 }
 
 static void clear_pmd_entry(struct kvm *kvm, pmd_t *pmd, phys_addr_t addr)
 {
<span class="p_del">-	if (kvm_pmd_huge(*pmd)) {</span>
<span class="p_del">-		pmd_clear(pmd);</span>
<span class="p_del">-		kvm_tlb_flush_vmid_ipa(kvm, addr);</span>
<span class="p_del">-	} else {</span>
<span class="p_del">-		pte_t *pte_table = pte_offset_kernel(pmd, 0);</span>
<span class="p_del">-		pmd_clear(pmd);</span>
<span class="p_del">-		kvm_tlb_flush_vmid_ipa(kvm, addr);</span>
<span class="p_del">-		pte_free_kernel(NULL, pte_table);</span>
<span class="p_del">-	}</span>
<span class="p_add">+	pte_t *pte_table = pte_offset_kernel(pmd, 0);</span>
<span class="p_add">+	VM_BUG_ON(kvm_pmd_huge(*pmd));</span>
<span class="p_add">+	pmd_clear(pmd);</span>
<span class="p_add">+	kvm_tlb_flush_vmid_ipa(kvm, addr);</span>
<span class="p_add">+	pte_free_kernel(NULL, pte_table);</span>
 	put_page(virt_to_page(pmd));
 }
 
<span class="p_del">-static void clear_pte_entry(struct kvm *kvm, pte_t *pte, phys_addr_t addr)</span>
<span class="p_add">+static void unmap_ptes(struct kvm *kvm, pmd_t *pmd,</span>
<span class="p_add">+		      phys_addr_t addr, phys_addr_t end)</span>
 {
<span class="p_del">-	if (pte_present(*pte)) {</span>
<span class="p_del">-		kvm_set_pte(pte, __pte(0));</span>
<span class="p_del">-		put_page(virt_to_page(pte));</span>
<span class="p_del">-		kvm_tlb_flush_vmid_ipa(kvm, addr);</span>
<span class="p_add">+	phys_addr_t start_addr = addr;</span>
<span class="p_add">+	pte_t *pte, *start_pte;</span>
<span class="p_add">+</span>
<span class="p_add">+	start_pte = pte = pte_offset_kernel(pmd, addr);</span>
<span class="p_add">+	do {</span>
<span class="p_add">+		if (!pte_none(*pte)) {</span>
<span class="p_add">+			kvm_set_pte(pte, __pte(0));</span>
<span class="p_add">+			put_page(virt_to_page(pte));</span>
<span class="p_add">+			kvm_tlb_flush_vmid_ipa(kvm, addr);</span>
<span class="p_add">+		}</span>
<span class="p_add">+	} while (pte++, addr += PAGE_SIZE, addr != end);</span>
<span class="p_add">+</span>
<span class="p_add">+	if (kvm_pte_table_empty(start_pte))</span>
<span class="p_add">+		clear_pmd_entry(kvm, pmd, start_addr);</span>
 	}
<span class="p_del">-}</span>
 
<span class="p_del">-static void unmap_range(struct kvm *kvm, pgd_t *pgdp,</span>
<span class="p_del">-			unsigned long long start, u64 size)</span>
<span class="p_add">+static void unmap_pmds(struct kvm *kvm, pud_t *pud,</span>
<span class="p_add">+		      phys_addr_t addr, phys_addr_t end)</span>
 {
<span class="p_del">-	pgd_t *pgd;</span>
<span class="p_del">-	pud_t *pud;</span>
<span class="p_del">-	pmd_t *pmd;</span>
<span class="p_del">-	pte_t *pte;</span>
<span class="p_del">-	unsigned long long addr = start, end = start + size;</span>
<span class="p_del">-	u64 next;</span>
<span class="p_del">-</span>
<span class="p_del">-	while (addr &lt; end) {</span>
<span class="p_del">-		pgd = pgdp + pgd_index(addr);</span>
<span class="p_del">-		pud = pud_offset(pgd, addr);</span>
<span class="p_del">-		if (pud_none(*pud)) {</span>
<span class="p_del">-			addr = kvm_pud_addr_end(addr, end);</span>
<span class="p_del">-			continue;</span>
<span class="p_del">-		}</span>
<span class="p_add">+	phys_addr_t next, start_addr = addr;</span>
<span class="p_add">+	pmd_t *pmd, *start_pmd;</span>
 
<span class="p_del">-		if (pud_huge(*pud)) {</span>
<span class="p_del">-			/*</span>
<span class="p_del">-			 * If we are dealing with a huge pud, just clear it and</span>
<span class="p_del">-			 * move on.</span>
<span class="p_del">-			 */</span>
<span class="p_del">-			clear_pud_entry(kvm, pud, addr);</span>
<span class="p_del">-			addr = kvm_pud_addr_end(addr, end);</span>
<span class="p_del">-			continue;</span>
<span class="p_add">+	start_pmd = pmd = pmd_offset(pud, addr);</span>
<span class="p_add">+	do {</span>
<span class="p_add">+		next = kvm_pmd_addr_end(addr, end);</span>
<span class="p_add">+		if (!pmd_none(*pmd)) {</span>
<span class="p_add">+			if (kvm_pmd_huge(*pmd)) {</span>
<span class="p_add">+				pmd_clear(pmd);</span>
<span class="p_add">+				kvm_tlb_flush_vmid_ipa(kvm, addr);</span>
<span class="p_add">+				put_page(virt_to_page(pmd));</span>
<span class="p_add">+			} else {</span>
<span class="p_add">+				unmap_ptes(kvm, pmd, addr, next);</span>
<span class="p_add">+			}</span>
 		}
<span class="p_add">+	} while (pmd++, addr = next, addr != end);</span>
 
<span class="p_del">-		pmd = pmd_offset(pud, addr);</span>
<span class="p_del">-		if (pmd_none(*pmd)) {</span>
<span class="p_del">-			addr = kvm_pmd_addr_end(addr, end);</span>
<span class="p_del">-			continue;</span>
<span class="p_del">-		}</span>
<span class="p_add">+	if (kvm_pmd_table_empty(start_pmd))</span>
<span class="p_add">+		clear_pud_entry(kvm, pud, start_addr);</span>
<span class="p_add">+}</span>
 
<span class="p_del">-		if (!kvm_pmd_huge(*pmd)) {</span>
<span class="p_del">-			pte = pte_offset_kernel(pmd, addr);</span>
<span class="p_del">-			clear_pte_entry(kvm, pte, addr);</span>
<span class="p_del">-			next = addr + PAGE_SIZE;</span>
<span class="p_del">-		}</span>
<span class="p_add">+static void unmap_puds(struct kvm *kvm, pgd_t *pgd,</span>
<span class="p_add">+		      phys_addr_t addr, phys_addr_t end)</span>
<span class="p_add">+{</span>
<span class="p_add">+	phys_addr_t next, start_addr = addr;</span>
<span class="p_add">+	pud_t *pud, *start_pud;</span>
 
<span class="p_del">-		/*</span>
<span class="p_del">-		 * If the pmd entry is to be cleared, walk back up the ladder</span>
<span class="p_del">-		 */</span>
<span class="p_del">-		if (kvm_pmd_huge(*pmd) || page_empty(pte)) {</span>
<span class="p_del">-			clear_pmd_entry(kvm, pmd, addr);</span>
<span class="p_del">-			next = kvm_pmd_addr_end(addr, end);</span>
<span class="p_del">-			if (page_empty(pmd) &amp;&amp; !page_empty(pud)) {</span>
<span class="p_del">-				clear_pud_entry(kvm, pud, addr);</span>
<span class="p_del">-				next = kvm_pud_addr_end(addr, end);</span>
<span class="p_add">+	start_pud = pud = pud_offset(pgd, addr);</span>
<span class="p_add">+	do {</span>
<span class="p_add">+		next = kvm_pud_addr_end(addr, end);</span>
<span class="p_add">+		if (!pud_none(*pud)) {</span>
<span class="p_add">+			if (pud_huge(*pud)) {</span>
<span class="p_add">+				pud_clear(pud);</span>
<span class="p_add">+				kvm_tlb_flush_vmid_ipa(kvm, addr);</span>
<span class="p_add">+				put_page(virt_to_page(pud));</span>
<span class="p_add">+			} else {</span>
<span class="p_add">+				unmap_pmds(kvm, pud, addr, next);</span>
 			}
 		}
<span class="p_add">+	} while (pud++, addr = next, addr != end);</span>
 
<span class="p_del">-		addr = next;</span>
<span class="p_del">-	}</span>
<span class="p_add">+	if (kvm_pud_table_empty(start_pud))</span>
<span class="p_add">+		clear_pgd_entry(kvm, pgd, start_addr);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+</span>
<span class="p_add">+static void unmap_range(struct kvm *kvm, pgd_t *pgdp,</span>
<span class="p_add">+		       phys_addr_t start, u64 size)</span>
<span class="p_add">+{</span>
<span class="p_add">+	pgd_t *pgd;</span>
<span class="p_add">+	phys_addr_t addr = start, end = start + size;</span>
<span class="p_add">+	phys_addr_t next;</span>
<span class="p_add">+</span>
<span class="p_add">+	pgd = pgdp + pgd_index(addr);</span>
<span class="p_add">+	do {</span>
<span class="p_add">+		next = kvm_pgd_addr_end(addr, end);</span>
<span class="p_add">+		unmap_puds(kvm, pgd, addr, next);</span>
<span class="p_add">+	} while (pgd++, addr = next, addr != end);</span>
 }
 
 static void stage2_flush_ptes(struct kvm *kvm, pmd_t *pmd,
<span class="p_chunk">@@ -747,6 +759,7 @@</span> <span class="p_context"> static int user_mem_abort(struct kvm_vcpu *vcpu, phys_addr_t fault_ipa,</span>
 	struct kvm_mmu_memory_cache *memcache = &amp;vcpu-&gt;arch.mmu_page_cache;
 	struct vm_area_struct *vma;
 	pfn_t pfn;
<span class="p_add">+	pgprot_t mem_type = PAGE_S2;</span>
 
 	write_fault = kvm_is_write_fault(kvm_vcpu_get_hsr(vcpu));
 	if (fault_status == FSC_PERM &amp;&amp; !write_fault) {
<span class="p_chunk">@@ -797,6 +810,9 @@</span> <span class="p_context"> static int user_mem_abort(struct kvm_vcpu *vcpu, phys_addr_t fault_ipa,</span>
 	if (is_error_pfn(pfn))
 		return -EFAULT;
 
<span class="p_add">+	if (kvm_is_mmio_pfn(pfn))</span>
<span class="p_add">+		mem_type = PAGE_S2_DEVICE;</span>
<span class="p_add">+</span>
 	spin_lock(&amp;kvm-&gt;mmu_lock);
 	if (mmu_notifier_retry(kvm, mmu_seq))
 		goto out_unlock;
<span class="p_chunk">@@ -804,7 +820,7 @@</span> <span class="p_context"> static int user_mem_abort(struct kvm_vcpu *vcpu, phys_addr_t fault_ipa,</span>
 		hugetlb = transparent_hugepage_adjust(&amp;pfn, &amp;fault_ipa);
 
 	if (hugetlb) {
<span class="p_del">-		pmd_t new_pmd = pfn_pmd(pfn, PAGE_S2);</span>
<span class="p_add">+		pmd_t new_pmd = pfn_pmd(pfn, mem_type);</span>
 		new_pmd = pmd_mkhuge(new_pmd);
 		if (writable) {
 			kvm_set_s2pmd_writable(&amp;new_pmd);
<span class="p_chunk">@@ -813,13 +829,14 @@</span> <span class="p_context"> static int user_mem_abort(struct kvm_vcpu *vcpu, phys_addr_t fault_ipa,</span>
 		coherent_cache_guest_page(vcpu, hva &amp; PMD_MASK, PMD_SIZE);
 		ret = stage2_set_pmd_huge(kvm, memcache, fault_ipa, &amp;new_pmd);
 	} else {
<span class="p_del">-		pte_t new_pte = pfn_pte(pfn, PAGE_S2);</span>
<span class="p_add">+		pte_t new_pte = pfn_pte(pfn, mem_type);</span>
 		if (writable) {
 			kvm_set_s2pte_writable(&amp;new_pte);
 			kvm_set_pfn_dirty(pfn);
 		}
 		coherent_cache_guest_page(vcpu, hva, PAGE_SIZE);
<span class="p_del">-		ret = stage2_set_pte(kvm, memcache, fault_ipa, &amp;new_pte, false);</span>
<span class="p_add">+		ret = stage2_set_pte(kvm, memcache, fault_ipa, &amp;new_pte,</span>
<span class="p_add">+				     mem_type == PAGE_S2_DEVICE);</span>
 	}
 
 
<span class="p_chunk">@@ -1099,3 +1116,49 @@</span> <span class="p_context"> out:</span>
 	free_hyp_pgds();
 	return err;
 }
<span class="p_add">+</span>
<span class="p_add">+void kvm_arch_commit_memory_region(struct kvm *kvm,</span>
<span class="p_add">+				   struct kvm_userspace_memory_region *mem,</span>
<span class="p_add">+				   const struct kvm_memory_slot *old,</span>
<span class="p_add">+				   enum kvm_mr_change change)</span>
<span class="p_add">+{</span>
<span class="p_add">+	gpa_t gpa = old-&gt;base_gfn &lt;&lt; PAGE_SHIFT;</span>
<span class="p_add">+	phys_addr_t size = old-&gt;npages &lt;&lt; PAGE_SHIFT;</span>
<span class="p_add">+	if (change == KVM_MR_DELETE || change == KVM_MR_MOVE) {</span>
<span class="p_add">+		spin_lock(&amp;kvm-&gt;mmu_lock);</span>
<span class="p_add">+		unmap_stage2_range(kvm, gpa, size);</span>
<span class="p_add">+		spin_unlock(&amp;kvm-&gt;mmu_lock);</span>
<span class="p_add">+	}</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+int kvm_arch_prepare_memory_region(struct kvm *kvm,</span>
<span class="p_add">+				   struct kvm_memory_slot *memslot,</span>
<span class="p_add">+				   struct kvm_userspace_memory_region *mem,</span>
<span class="p_add">+				   enum kvm_mr_change change)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return 0;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void kvm_arch_free_memslot(struct kvm *kvm, struct kvm_memory_slot *free,</span>
<span class="p_add">+			   struct kvm_memory_slot *dont)</span>
<span class="p_add">+{</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+int kvm_arch_create_memslot(struct kvm *kvm, struct kvm_memory_slot *slot,</span>
<span class="p_add">+			    unsigned long npages)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return 0;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void kvm_arch_memslots_updated(struct kvm *kvm)</span>
<span class="p_add">+{</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void kvm_arch_flush_shadow_all(struct kvm *kvm)</span>
<span class="p_add">+{</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void kvm_arch_flush_shadow_memslot(struct kvm *kvm,</span>
<span class="p_add">+				   struct kvm_memory_slot *slot)</span>
<span class="p_add">+{</span>
<span class="p_add">+}</span>
<span class="p_header">diff --git a/arch/arm64/include/asm/kvm_host.h b/arch/arm64/include/asm/kvm_host.h</span>
<span class="p_header">index 0a1d69751562..3fb0946d963a 100644</span>
<span class="p_header">--- a/arch/arm64/include/asm/kvm_host.h</span>
<span class="p_header">+++ b/arch/arm64/include/asm/kvm_host.h</span>
<span class="p_chunk">@@ -42,7 +42,7 @@</span> <span class="p_context"></span>
 #define KVM_VCPU_MAX_FEATURES 2
 
 struct kvm_vcpu;
<span class="p_del">-int kvm_target_cpu(void);</span>
<span class="p_add">+int __attribute_const__ kvm_target_cpu(void);</span>
 int kvm_reset_vcpu(struct kvm_vcpu *vcpu);
 int kvm_arch_dev_ioctl_check_extension(long ext);
 
<span class="p_chunk">@@ -177,7 +177,7 @@</span> <span class="p_context"> static inline int kvm_test_age_hva(struct kvm *kvm, unsigned long hva)</span>
 }
 
 struct kvm_vcpu *kvm_arm_get_running_vcpu(void);
<span class="p_del">-struct kvm_vcpu __percpu **kvm_get_running_vcpus(void);</span>
<span class="p_add">+struct kvm_vcpu * __percpu *kvm_get_running_vcpus(void);</span>
 
 u64 kvm_call_hyp(void *hypfn, ...);
 
<span class="p_header">diff --git a/arch/arm64/include/asm/kvm_mmu.h b/arch/arm64/include/asm/kvm_mmu.h</span>
<span class="p_header">index 7d29847a893b..8e138c7c53ac 100644</span>
<span class="p_header">--- a/arch/arm64/include/asm/kvm_mmu.h</span>
<span class="p_header">+++ b/arch/arm64/include/asm/kvm_mmu.h</span>
<span class="p_chunk">@@ -125,6 +125,21 @@</span> <span class="p_context"> static inline void kvm_set_s2pmd_writable(pmd_t *pmd)</span>
 #define kvm_pud_addr_end(addr, end)	pud_addr_end(addr, end)
 #define kvm_pmd_addr_end(addr, end)	pmd_addr_end(addr, end)
 
<span class="p_add">+static inline bool kvm_page_empty(void *ptr)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct page *ptr_page = virt_to_page(ptr);</span>
<span class="p_add">+	return page_count(ptr_page) == 1;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+#define kvm_pte_table_empty(ptep) kvm_page_empty(ptep)</span>
<span class="p_add">+#ifndef CONFIG_ARM64_64K_PAGES</span>
<span class="p_add">+#define kvm_pmd_table_empty(pmdp) kvm_page_empty(pmdp)</span>
<span class="p_add">+#else</span>
<span class="p_add">+#define kvm_pmd_table_empty(pmdp) (0)</span>
<span class="p_add">+#endif</span>
<span class="p_add">+#define kvm_pud_table_empty(pudp) (0)</span>
<span class="p_add">+</span>
<span class="p_add">+</span>
 struct kvm;
 
 #define kvm_flush_dcache_to_poc(a,l)	__flush_dcache_area((a), (l))
<span class="p_header">diff --git a/arch/arm64/kvm/hyp.S b/arch/arm64/kvm/hyp.S</span>
<span class="p_header">index b0d1512acf08..5dfc8331c385 100644</span>
<span class="p_header">--- a/arch/arm64/kvm/hyp.S</span>
<span class="p_header">+++ b/arch/arm64/kvm/hyp.S</span>
<span class="p_chunk">@@ -830,7 +830,7 @@</span> <span class="p_context"> el1_trap:</span>
 	mrs	x2, far_el2
 
 2:	mrs	x0, tpidr_el2
<span class="p_del">-	str	x1, [x0, #VCPU_ESR_EL2]</span>
<span class="p_add">+	str	w1, [x0, #VCPU_ESR_EL2]</span>
 	str	x2, [x0, #VCPU_FAR_EL2]
 	str	x3, [x0, #VCPU_HPFAR_EL2]
 
<span class="p_header">diff --git a/arch/arm64/kvm/sys_regs.c b/arch/arm64/kvm/sys_regs.c</span>
<span class="p_header">index 03244582bc55..7691b2563d27 100644</span>
<span class="p_header">--- a/arch/arm64/kvm/sys_regs.c</span>
<span class="p_header">+++ b/arch/arm64/kvm/sys_regs.c</span>
<span class="p_chunk">@@ -836,7 +836,7 @@</span> <span class="p_context"> static bool is_valid_cache(u32 val)</span>
 	u32 level, ctype;
 
 	if (val &gt;= CSSELR_MAX)
<span class="p_del">-		return -ENOENT;</span>
<span class="p_add">+		return false;</span>
 
 	/* Bottom bit is Instruction or Data bit.  Next 3 bits are level. */
 	level = (val &gt;&gt; 1);
<span class="p_chunk">@@ -962,7 +962,7 @@</span> <span class="p_context"> static unsigned int num_demux_regs(void)</span>
 
 static int write_demux_regids(u64 __user *uindices)
 {
<span class="p_del">-	u64 val = KVM_REG_ARM | KVM_REG_SIZE_U32 | KVM_REG_ARM_DEMUX;</span>
<span class="p_add">+	u64 val = KVM_REG_ARM64 | KVM_REG_SIZE_U32 | KVM_REG_ARM_DEMUX;</span>
 	unsigned int i;
 
 	val |= KVM_REG_ARM_DEMUX_ID_CCSIDR;
<span class="p_header">diff --git a/drivers/bluetooth/ath3k.c b/drivers/bluetooth/ath3k.c</span>
<span class="p_header">index 26b03e1254ef..8ff2b3ca7ee9 100644</span>
<span class="p_header">--- a/drivers/bluetooth/ath3k.c</span>
<span class="p_header">+++ b/drivers/bluetooth/ath3k.c</span>
<span class="p_chunk">@@ -79,6 +79,7 @@</span> <span class="p_context"> static const struct usb_device_id ath3k_table[] = {</span>
 	{ USB_DEVICE(0x0489, 0xe057) },
 	{ USB_DEVICE(0x0489, 0xe056) },
 	{ USB_DEVICE(0x0489, 0xe05f) },
<span class="p_add">+	{ USB_DEVICE(0x0489, 0xe076) },</span>
 	{ USB_DEVICE(0x0489, 0xe078) },
 	{ USB_DEVICE(0x04c5, 0x1330) },
 	{ USB_DEVICE(0x04CA, 0x3004) },
<span class="p_chunk">@@ -109,6 +110,7 @@</span> <span class="p_context"> static const struct usb_device_id ath3k_table[] = {</span>
 	{ USB_DEVICE(0x13d3, 0x3402) },
 	{ USB_DEVICE(0x13d3, 0x3408) },
 	{ USB_DEVICE(0x13d3, 0x3432) },
<span class="p_add">+	{ USB_DEVICE(0x13d3, 0x3474) },</span>
 
 	/* Atheros AR5BBU12 with sflash firmware */
 	{ USB_DEVICE(0x0489, 0xE02C) },
<span class="p_chunk">@@ -133,6 +135,7 @@</span> <span class="p_context"> static const struct usb_device_id ath3k_blist_tbl[] = {</span>
 	{ USB_DEVICE(0x0489, 0xe056), .driver_info = BTUSB_ATH3012 },
 	{ USB_DEVICE(0x0489, 0xe057), .driver_info = BTUSB_ATH3012 },
 	{ USB_DEVICE(0x0489, 0xe05f), .driver_info = BTUSB_ATH3012 },
<span class="p_add">+	{ USB_DEVICE(0x0489, 0xe076), .driver_info = BTUSB_ATH3012 },</span>
 	{ USB_DEVICE(0x0489, 0xe078), .driver_info = BTUSB_ATH3012 },
 	{ USB_DEVICE(0x04c5, 0x1330), .driver_info = BTUSB_ATH3012 },
 	{ USB_DEVICE(0x04ca, 0x3004), .driver_info = BTUSB_ATH3012 },
<span class="p_chunk">@@ -163,6 +166,7 @@</span> <span class="p_context"> static const struct usb_device_id ath3k_blist_tbl[] = {</span>
 	{ USB_DEVICE(0x13d3, 0x3402), .driver_info = BTUSB_ATH3012 },
 	{ USB_DEVICE(0x13d3, 0x3408), .driver_info = BTUSB_ATH3012 },
 	{ USB_DEVICE(0x13d3, 0x3432), .driver_info = BTUSB_ATH3012 },
<span class="p_add">+	{ USB_DEVICE(0x13d3, 0x3474), .driver_info = BTUSB_ATH3012 },</span>
 
 	/* Atheros AR5BBU22 with sflash firmware */
 	{ USB_DEVICE(0x0489, 0xE036), .driver_info = BTUSB_ATH3012 },
<span class="p_header">diff --git a/drivers/bluetooth/btusb.c b/drivers/bluetooth/btusb.c</span>
<span class="p_header">index 9eb1669962ef..c0e7a9aa97a4 100644</span>
<span class="p_header">--- a/drivers/bluetooth/btusb.c</span>
<span class="p_header">+++ b/drivers/bluetooth/btusb.c</span>
<span class="p_chunk">@@ -157,6 +157,7 @@</span> <span class="p_context"> static const struct usb_device_id blacklist_table[] = {</span>
 	{ USB_DEVICE(0x0489, 0xe056), .driver_info = BTUSB_ATH3012 },
 	{ USB_DEVICE(0x0489, 0xe057), .driver_info = BTUSB_ATH3012 },
 	{ USB_DEVICE(0x0489, 0xe05f), .driver_info = BTUSB_ATH3012 },
<span class="p_add">+	{ USB_DEVICE(0x0489, 0xe076), .driver_info = BTUSB_ATH3012 },</span>
 	{ USB_DEVICE(0x0489, 0xe078), .driver_info = BTUSB_ATH3012 },
 	{ USB_DEVICE(0x04c5, 0x1330), .driver_info = BTUSB_ATH3012 },
 	{ USB_DEVICE(0x04ca, 0x3004), .driver_info = BTUSB_ATH3012 },
<span class="p_chunk">@@ -187,6 +188,7 @@</span> <span class="p_context"> static const struct usb_device_id blacklist_table[] = {</span>
 	{ USB_DEVICE(0x13d3, 0x3402), .driver_info = BTUSB_ATH3012 },
 	{ USB_DEVICE(0x13d3, 0x3408), .driver_info = BTUSB_ATH3012 },
 	{ USB_DEVICE(0x13d3, 0x3432), .driver_info = BTUSB_ATH3012 },
<span class="p_add">+	{ USB_DEVICE(0x13d3, 0x3474), .driver_info = BTUSB_ATH3012 },</span>
 
 	/* Atheros AR5BBU12 with sflash firmware */
 	{ USB_DEVICE(0x0489, 0xe02c), .driver_info = BTUSB_IGNORE },
<span class="p_header">diff --git a/drivers/crypto/caam/caamrng.c b/drivers/crypto/caam/caamrng.c</span>
<span class="p_header">index 28486b19fc36..ae6dae8ef7ab 100644</span>
<span class="p_header">--- a/drivers/crypto/caam/caamrng.c</span>
<span class="p_header">+++ b/drivers/crypto/caam/caamrng.c</span>
<span class="p_chunk">@@ -56,7 +56,7 @@</span> <span class="p_context"></span>
 
 /* Buffer, its dma address and lock */
 struct buf_data {
<span class="p_del">-	u8 buf[RN_BUF_SIZE];</span>
<span class="p_add">+	u8 buf[RN_BUF_SIZE] ____cacheline_aligned;</span>
 	dma_addr_t addr;
 	struct completion filled;
 	u32 hw_desc[DESC_JOB_O_LEN];
<span class="p_header">diff --git a/drivers/gpu/drm/mgag200/mgag200_mode.c b/drivers/gpu/drm/mgag200/mgag200_mode.c</span>
<span class="p_header">index 968374776db9..f2511a03e3e9 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/mgag200/mgag200_mode.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/mgag200/mgag200_mode.c</span>
<span class="p_chunk">@@ -1529,6 +1529,11 @@</span> <span class="p_context"> static int mga_vga_mode_valid(struct drm_connector *connector,</span>
 		return MODE_BANDWIDTH;
 	}
 
<span class="p_add">+	if ((mode-&gt;hdisplay % 8) != 0 || (mode-&gt;hsync_start % 8) != 0 ||</span>
<span class="p_add">+	    (mode-&gt;hsync_end % 8) != 0 || (mode-&gt;htotal % 8) != 0) {</span>
<span class="p_add">+		return MODE_H_ILLEGAL;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
 	if (mode-&gt;crtc_hdisplay &gt; 2048 || mode-&gt;crtc_hsync_start &gt; 4096 ||
 	    mode-&gt;crtc_hsync_end &gt; 4096 || mode-&gt;crtc_htotal &gt; 4096 ||
 	    mode-&gt;crtc_vdisplay &gt; 2048 || mode-&gt;crtc_vsync_start &gt; 4096 ||
<span class="p_header">diff --git a/drivers/scsi/lpfc/lpfc_sli.c b/drivers/scsi/lpfc/lpfc_sli.c</span>
<span class="p_header">index 8f580fda443f..ce211328bc1c 100644</span>
<span class="p_header">--- a/drivers/scsi/lpfc/lpfc_sli.c</span>
<span class="p_header">+++ b/drivers/scsi/lpfc/lpfc_sli.c</span>
<span class="p_chunk">@@ -265,6 +265,16 @@</span> <span class="p_context"> lpfc_sli4_eq_get(struct lpfc_queue *q)</span>
 		return NULL;
 
 	q-&gt;hba_index = idx;
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * insert barrier for instruction interlock : data from the hardware</span>
<span class="p_add">+	 * must have the valid bit checked before it can be copied and acted</span>
<span class="p_add">+	 * upon. Given what was seen in lpfc_sli4_cq_get() of speculative</span>
<span class="p_add">+	 * instructions allowing action on content before valid bit checked,</span>
<span class="p_add">+	 * add barrier here as well. May not be needed as &quot;content&quot; is a</span>
<span class="p_add">+	 * single 32-bit entity here (vs multi word structure for cq&#39;s).</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	mb();</span>
 	return eqe;
 }
 
<span class="p_chunk">@@ -370,6 +380,17 @@</span> <span class="p_context"> lpfc_sli4_cq_get(struct lpfc_queue *q)</span>
 
 	cqe = q-&gt;qe[q-&gt;hba_index].cqe;
 	q-&gt;hba_index = idx;
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * insert barrier for instruction interlock : data from the hardware</span>
<span class="p_add">+	 * must have the valid bit checked before it can be copied and acted</span>
<span class="p_add">+	 * upon. Speculative instructions were allowing a bcopy at the start</span>
<span class="p_add">+	 * of lpfc_sli4_fp_handle_wcqe(), which is called immediately</span>
<span class="p_add">+	 * after our return, to copy data before the valid bit check above</span>
<span class="p_add">+	 * was done. As such, some of the copied data was stale. The barrier</span>
<span class="p_add">+	 * ensures the check is before any data is copied.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	mb();</span>
 	return cqe;
 }
 
<span class="p_header">diff --git a/fs/pipe.c b/fs/pipe.c</span>
<span class="p_header">index 78fd0d0788db..46f1ab264a4c 100644</span>
<span class="p_header">--- a/fs/pipe.c</span>
<span class="p_header">+++ b/fs/pipe.c</span>
<span class="p_chunk">@@ -117,25 +117,27 @@</span> <span class="p_context"> void pipe_wait(struct pipe_inode_info *pipe)</span>
 }
 
 static int
<span class="p_del">-pipe_iov_copy_from_user(void *to, struct iovec *iov, unsigned long len,</span>
<span class="p_del">-			int atomic)</span>
<span class="p_add">+pipe_iov_copy_from_user(void *addr, int *offset, struct iovec *iov,</span>
<span class="p_add">+			size_t *remaining, int atomic)</span>
 {
 	unsigned long copy;
 
<span class="p_del">-	while (len &gt; 0) {</span>
<span class="p_add">+	while (*remaining &gt; 0) {</span>
 		while (!iov-&gt;iov_len)
 			iov++;
<span class="p_del">-		copy = min_t(unsigned long, len, iov-&gt;iov_len);</span>
<span class="p_add">+		copy = min_t(unsigned long, *remaining, iov-&gt;iov_len);</span>
 
 		if (atomic) {
<span class="p_del">-			if (__copy_from_user_inatomic(to, iov-&gt;iov_base, copy))</span>
<span class="p_add">+			if (__copy_from_user_inatomic(addr + *offset,</span>
<span class="p_add">+						      iov-&gt;iov_base, copy))</span>
 				return -EFAULT;
 		} else {
<span class="p_del">-			if (copy_from_user(to, iov-&gt;iov_base, copy))</span>
<span class="p_add">+			if (copy_from_user(addr + *offset,</span>
<span class="p_add">+					   iov-&gt;iov_base, copy))</span>
 				return -EFAULT;
 		}
<span class="p_del">-		to += copy;</span>
<span class="p_del">-		len -= copy;</span>
<span class="p_add">+		*offset += copy;</span>
<span class="p_add">+		*remaining -= copy;</span>
 		iov-&gt;iov_base += copy;
 		iov-&gt;iov_len -= copy;
 	}
<span class="p_chunk">@@ -143,25 +145,27 @@</span> <span class="p_context"> pipe_iov_copy_from_user(void *to, struct iovec *iov, unsigned long len,</span>
 }
 
 static int
<span class="p_del">-pipe_iov_copy_to_user(struct iovec *iov, const void *from, unsigned long len,</span>
<span class="p_del">-		      int atomic)</span>
<span class="p_add">+pipe_iov_copy_to_user(struct iovec *iov, void *addr, int *offset,</span>
<span class="p_add">+		      size_t *remaining, int atomic)</span>
 {
 	unsigned long copy;
 
<span class="p_del">-	while (len &gt; 0) {</span>
<span class="p_add">+	while (*remaining &gt; 0) {</span>
 		while (!iov-&gt;iov_len)
 			iov++;
<span class="p_del">-		copy = min_t(unsigned long, len, iov-&gt;iov_len);</span>
<span class="p_add">+		copy = min_t(unsigned long, *remaining, iov-&gt;iov_len);</span>
 
 		if (atomic) {
<span class="p_del">-			if (__copy_to_user_inatomic(iov-&gt;iov_base, from, copy))</span>
<span class="p_add">+			if (__copy_to_user_inatomic(iov-&gt;iov_base,</span>
<span class="p_add">+						    addr + *offset, copy))</span>
 				return -EFAULT;
 		} else {
<span class="p_del">-			if (copy_to_user(iov-&gt;iov_base, from, copy))</span>
<span class="p_add">+			if (copy_to_user(iov-&gt;iov_base,</span>
<span class="p_add">+					 addr + *offset, copy))</span>
 				return -EFAULT;
 		}
<span class="p_del">-		from += copy;</span>
<span class="p_del">-		len -= copy;</span>
<span class="p_add">+		*offset += copy;</span>
<span class="p_add">+		*remaining -= copy;</span>
 		iov-&gt;iov_base += copy;
 		iov-&gt;iov_len -= copy;
 	}
<span class="p_chunk">@@ -395,7 +399,7 @@</span> <span class="p_context"> pipe_read(struct kiocb *iocb, const struct iovec *_iov,</span>
 			struct pipe_buffer *buf = pipe-&gt;bufs + curbuf;
 			const struct pipe_buf_operations *ops = buf-&gt;ops;
 			void *addr;
<span class="p_del">-			size_t chars = buf-&gt;len;</span>
<span class="p_add">+			size_t chars = buf-&gt;len, remaining;</span>
 			int error, atomic;
 
 			if (chars &gt; total_len)
<span class="p_chunk">@@ -409,9 +413,11 @@</span> <span class="p_context"> pipe_read(struct kiocb *iocb, const struct iovec *_iov,</span>
 			}
 
 			atomic = !iov_fault_in_pages_write(iov, chars);
<span class="p_add">+			remaining = chars;</span>
 redo:
 			addr = ops-&gt;map(pipe, buf, atomic);
<span class="p_del">-			error = pipe_iov_copy_to_user(iov, addr + buf-&gt;offset, chars, atomic);</span>
<span class="p_add">+			error = pipe_iov_copy_to_user(iov, addr, &amp;buf-&gt;offset,</span>
<span class="p_add">+						      &amp;remaining, atomic);</span>
 			ops-&gt;unmap(pipe, buf, addr);
 			if (unlikely(error)) {
 				/*
<span class="p_chunk">@@ -426,7 +432,6 @@</span> <span class="p_context"> redo:</span>
 				break;
 			}
 			ret += chars;
<span class="p_del">-			buf-&gt;offset += chars;</span>
 			buf-&gt;len -= chars;
 
 			/* Was it a packet buffer? Clean up and exit */
<span class="p_chunk">@@ -531,6 +536,7 @@</span> <span class="p_context"> pipe_write(struct kiocb *iocb, const struct iovec *_iov,</span>
 		if (ops-&gt;can_merge &amp;&amp; offset + chars &lt;= PAGE_SIZE) {
 			int error, atomic = 1;
 			void *addr;
<span class="p_add">+			size_t remaining = chars;</span>
 
 			error = ops-&gt;confirm(pipe, buf);
 			if (error)
<span class="p_chunk">@@ -539,8 +545,8 @@</span> <span class="p_context"> pipe_write(struct kiocb *iocb, const struct iovec *_iov,</span>
 			iov_fault_in_pages_read(iov, chars);
 redo1:
 			addr = ops-&gt;map(pipe, buf, atomic);
<span class="p_del">-			error = pipe_iov_copy_from_user(offset + addr, iov,</span>
<span class="p_del">-							chars, atomic);</span>
<span class="p_add">+			error = pipe_iov_copy_from_user(addr, &amp;offset, iov,</span>
<span class="p_add">+							&amp;remaining, atomic);</span>
 			ops-&gt;unmap(pipe, buf, addr);
 			ret = error;
 			do_wakeup = 1;
<span class="p_chunk">@@ -575,6 +581,8 @@</span> <span class="p_context"> redo1:</span>
 			struct page *page = pipe-&gt;tmp_page;
 			char *src;
 			int error, atomic = 1;
<span class="p_add">+			int offset = 0;</span>
<span class="p_add">+			size_t remaining;</span>
 
 			if (!page) {
 				page = alloc_page(GFP_HIGHUSER);
<span class="p_chunk">@@ -595,14 +603,15 @@</span> <span class="p_context"> redo1:</span>
 				chars = total_len;
 
 			iov_fault_in_pages_read(iov, chars);
<span class="p_add">+			remaining = chars;</span>
 redo2:
 			if (atomic)
 				src = kmap_atomic(page);
 			else
 				src = kmap(page);
 
<span class="p_del">-			error = pipe_iov_copy_from_user(src, iov, chars,</span>
<span class="p_del">-							atomic);</span>
<span class="p_add">+			error = pipe_iov_copy_from_user(src, &amp;offset, iov,</span>
<span class="p_add">+							&amp;remaining, atomic);</span>
 			if (atomic)
 				kunmap_atomic(src);
 			else
<span class="p_header">diff --git a/kernel/trace/trace_events_filter.c b/kernel/trace/trace_events_filter.c</span>
<span class="p_header">index 8a8631926a07..cb347e85f75e 100644</span>
<span class="p_header">--- a/kernel/trace/trace_events_filter.c</span>
<span class="p_header">+++ b/kernel/trace/trace_events_filter.c</span>
<span class="p_chunk">@@ -1399,19 +1399,24 @@</span> <span class="p_context"> static int check_preds(struct filter_parse_state *ps)</span>
 {
 	int n_normal_preds = 0, n_logical_preds = 0;
 	struct postfix_elt *elt;
<span class="p_add">+	int cnt = 0;</span>
 
 	list_for_each_entry(elt, &amp;ps-&gt;postfix, list) {
<span class="p_del">-		if (elt-&gt;op == OP_NONE)</span>
<span class="p_add">+		if (elt-&gt;op == OP_NONE) {</span>
<span class="p_add">+			cnt++;</span>
 			continue;
<span class="p_add">+		}</span>
 
<span class="p_add">+		cnt--;</span>
 		if (elt-&gt;op == OP_AND || elt-&gt;op == OP_OR) {
 			n_logical_preds++;
 			continue;
 		}
 		n_normal_preds++;
<span class="p_add">+		WARN_ON_ONCE(cnt &lt; 0);</span>
 	}
 
<span class="p_del">-	if (!n_normal_preds || n_logical_preds &gt;= n_normal_preds) {</span>
<span class="p_add">+	if (cnt != 1 || !n_normal_preds || n_logical_preds &gt;= n_normal_preds) {</span>
 		parse_error(ps, FILT_ERR_INVALID_FILTER, 0);
 		return -EINVAL;
 	}
<span class="p_header">diff --git a/virt/kvm/arm/vgic.c b/virt/kvm/arm/vgic.c</span>
<span class="p_header">index 4eec2d436109..1316e558db64 100644</span>
<span class="p_header">--- a/virt/kvm/arm/vgic.c</span>
<span class="p_header">+++ b/virt/kvm/arm/vgic.c</span>
<span class="p_chunk">@@ -1654,7 +1654,7 @@</span> <span class="p_context"> out:</span>
 	return ret;
 }
 
<span class="p_del">-static bool vgic_ioaddr_overlap(struct kvm *kvm)</span>
<span class="p_add">+static int vgic_ioaddr_overlap(struct kvm *kvm)</span>
 {
 	phys_addr_t dist = kvm-&gt;arch.vgic.vgic_dist_base;
 	phys_addr_t cpu = kvm-&gt;arch.vgic.vgic_cpu_base;

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



