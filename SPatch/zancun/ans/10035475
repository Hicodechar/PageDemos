
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>[21/23] x86, pcid, kaiser: allow flushing for future ASID switches - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    [21/23] x86, pcid, kaiser: allow flushing for future ASID switches</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=64071">Dave Hansen</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>Oct. 31, 2017, 10:32 p.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;20171031223224.B9F5D5CA@viggo.jf.intel.com&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/10035475/mbox/"
   >mbox</a>
|
   <a href="/patch/10035475/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/10035475/">/patch/10035475/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
	[172.30.200.125])
	by pdx-korg-patchwork.web.codeaurora.org (Postfix) with ESMTP id
	1B5B560327 for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Tue, 31 Oct 2017 22:32:34 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 0F78E28B14
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Tue, 31 Oct 2017 22:32:34 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id 0454228B21; Tue, 31 Oct 2017 22:32:34 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-6.9 required=2.0 tests=BAYES_00,RCVD_IN_DNSWL_HI
	autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 4C61728B14
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Tue, 31 Oct 2017 22:32:33 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S933106AbdJaWca (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Tue, 31 Oct 2017 18:32:30 -0400
Received: from mga03.intel.com ([134.134.136.65]:41229 &quot;EHLO mga03.intel.com&quot;
	rhost-flags-OK-OK-OK-OK) by vger.kernel.org with ESMTP
	id S933079AbdJaWcZ (ORCPT &lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Tue, 31 Oct 2017 18:32:25 -0400
Received: from orsmga004.jf.intel.com ([10.7.209.38])
	by orsmga103.jf.intel.com with ESMTP/TLS/DHE-RSA-AES256-GCM-SHA384;
	31 Oct 2017 15:32:24 -0700
X-ExtLoop1: 1
X-IronPort-AV: E=Sophos;i=&quot;5.44,326,1505804400&quot;; d=&quot;scan&#39;208&quot;;a=&quot;144445953&quot;
Received: from viggo.jf.intel.com (HELO localhost.localdomain)
	([10.54.39.20])
	by orsmga004.jf.intel.com with ESMTP; 31 Oct 2017 15:32:24 -0700
Subject: [PATCH 21/23] x86, pcid,
	kaiser: allow flushing for future ASID switches
To: linux-kernel@vger.kernel.org
Cc: linux-mm@kvack.org, dave.hansen@linux.intel.com,
	moritz.lipp@iaik.tugraz.at, daniel.gruss@iaik.tugraz.at,
	michael.schwarz@iaik.tugraz.at, luto@kernel.org,
	torvalds@linux-foundation.org, keescook@google.com,
	hughd@google.com, x86@kernel.org
From: Dave Hansen &lt;dave.hansen@linux.intel.com&gt;
Date: Tue, 31 Oct 2017 15:32:24 -0700
References: &lt;20171031223146.6B47C861@viggo.jf.intel.com&gt;
In-Reply-To: &lt;20171031223146.6B47C861@viggo.jf.intel.com&gt;
Message-Id: &lt;20171031223224.B9F5D5CA@viggo.jf.intel.com&gt;
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=64071">Dave Hansen</a> - Oct. 31, 2017, 10:32 p.m.</div>
<pre class="content">
If we change the page tables in such a way that we need an
invalidation of all contexts (aka. PCIDs / ASIDs) we can
actively invalidate them by:
 1. INVPCID for each PCID (works for single pages too).
 2. Load CR3 with each PCID without the NOFLUSH bit set
 3. Load CR3 with the NOFLUSH bit set for each and do
    INVLPG for each address.

But, none of these are really feasible since we have ~6 ASIDs (12 with
KAISER) at the time that we need to do an invalidation.  So, we just
invalidate the *current* context and then mark the cpu_tlbstate
_quickly_.

Then, at the next context-switch, we notice that we had
&#39;all_other_ctxs_invalid&#39; marked, and go invalidate all of the
cpu_tlbstate.ctxs[] entries.

This ensures that any futuee context switches will do a full flush
of the TLB so they pick up the changes.
<span class="signed-off-by">
Signed-off-by: Dave Hansen &lt;dave.hansen@linux.intel.com&gt;</span>
Cc: Moritz Lipp &lt;moritz.lipp@iaik.tugraz.at&gt;
Cc: Daniel Gruss &lt;daniel.gruss@iaik.tugraz.at&gt;
Cc: Michael Schwarz &lt;michael.schwarz@iaik.tugraz.at&gt;
Cc: Andy Lutomirski &lt;luto@kernel.org&gt;
Cc: Linus Torvalds &lt;torvalds@linux-foundation.org&gt;
Cc: Kees Cook &lt;keescook@google.com&gt;
Cc: Hugh Dickins &lt;hughd@google.com&gt;
Cc: x86@kernel.org
---

 b/arch/x86/include/asm/tlbflush.h |   47 +++++++++++++++++++++++++++++---------
 b/arch/x86/mm/tlb.c               |   35 ++++++++++++++++++++++++++++
 2 files changed, 72 insertions(+), 10 deletions(-)
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=125831">Andrew Lutomirski</a> - Nov. 1, 2017, 8:03 a.m.</div>
<pre class="content">
On Tue, Oct 31, 2017 at 3:32 PM, Dave Hansen
&lt;dave.hansen@linux.intel.com&gt; wrote:
<span class="quote">&gt;</span>
<span class="quote">&gt; If we change the page tables in such a way that we need an</span>
<span class="quote">&gt; invalidation of all contexts (aka. PCIDs / ASIDs) we can</span>
<span class="quote">&gt; actively invalidate them by:</span>
<span class="quote">&gt;  1. INVPCID for each PCID (works for single pages too).</span>
<span class="quote">&gt;  2. Load CR3 with each PCID without the NOFLUSH bit set</span>
<span class="quote">&gt;  3. Load CR3 with the NOFLUSH bit set for each and do</span>
<span class="quote">&gt;     INVLPG for each address.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; But, none of these are really feasible since we have ~6 ASIDs (12 with</span>
<span class="quote">&gt; KAISER) at the time that we need to do an invalidation.  So, we just</span>
<span class="quote">&gt; invalidate the *current* context and then mark the cpu_tlbstate</span>
<span class="quote">&gt; _quickly_.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; Then, at the next context-switch, we notice that we had</span>
<span class="quote">&gt; &#39;all_other_ctxs_invalid&#39; marked, and go invalidate all of the</span>
<span class="quote">&gt; cpu_tlbstate.ctxs[] entries.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; This ensures that any futuee context switches will do a full flush</span>
<span class="quote">&gt; of the TLB so they pick up the changes.</span>

I&#39;m convuced.  What was wrong with the old code?  I guess I just don&#39;t
see what the problem is that is solved by this patch.
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=64071">Dave Hansen</a> - Nov. 1, 2017, 2:17 p.m.</div>
<pre class="content">
On 11/01/2017 01:03 AM, Andy Lutomirski wrote:
<span class="quote">&gt;&gt; This ensures that any futuee context switches will do a full flush</span>
<span class="quote">&gt;&gt; of the TLB so they pick up the changes.</span>
<span class="quote">&gt; I&#39;m convuced.  What was wrong with the old code?  I guess I just don&#39;t</span>
<span class="quote">&gt; see what the problem is that is solved by this patch.</span>

Instead of flushing *now* with INVPCID, this lets us flush *later* with
CR3.  It just hijacks the code that you already have that flushes CR3
when loading a new ASID by making all ASIDs look new in the future.

We have to load CR3 anyway, so we might as well just do this flush then.
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=125831">Andrew Lutomirski</a> - Nov. 1, 2017, 8:31 p.m.</div>
<pre class="content">
On Wed, Nov 1, 2017 at 7:17 AM, Dave Hansen &lt;dave.hansen@linux.intel.com&gt; wrote:
<span class="quote">&gt; On 11/01/2017 01:03 AM, Andy Lutomirski wrote:</span>
<span class="quote">&gt;&gt;&gt; This ensures that any futuee context switches will do a full flush</span>
<span class="quote">&gt;&gt;&gt; of the TLB so they pick up the changes.</span>
<span class="quote">&gt;&gt; I&#39;m convuced.  What was wrong with the old code?  I guess I just don&#39;t</span>
<span class="quote">&gt;&gt; see what the problem is that is solved by this patch.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; Instead of flushing *now* with INVPCID, this lets us flush *later* with</span>
<span class="quote">&gt; CR3.  It just hijacks the code that you already have that flushes CR3</span>
<span class="quote">&gt; when loading a new ASID by making all ASIDs look new in the future.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; We have to load CR3 anyway, so we might as well just do this flush then.</span>

Would it make more sense to put it in flush_tlb_func_common() instead?

Also, I don&#39;t understand what clear_non_loaded_ctxs() is trying to do.
It looks like it&#39;s invalidating all the other logical address spaces.
And I don&#39;t see why you want a all_other_ctxs_invalid variable.  Isn&#39;t
the goal to mark a single ASID as needing a *user* flush the next time
we switch to user mode using that ASID?  Your code seems like it&#39;s
going to flush a lot of *kernel* PCIDs.

Can you explain the overall logic?
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=64071">Dave Hansen</a> - Nov. 1, 2017, 8:59 p.m.</div>
<pre class="content">
On 11/01/2017 01:31 PM, Andy Lutomirski wrote:
<span class="quote">&gt; On Wed, Nov 1, 2017 at 7:17 AM, Dave Hansen &lt;dave.hansen@linux.intel.com&gt; wrote:</span>
<span class="quote">&gt;&gt; On 11/01/2017 01:03 AM, Andy Lutomirski wrote:</span>
<span class="quote">&gt;&gt;&gt;&gt; This ensures that any futuee context switches will do a full flush</span>
<span class="quote">&gt;&gt;&gt;&gt; of the TLB so they pick up the changes.</span>
<span class="quote">&gt;&gt;&gt; I&#39;m convuced.  What was wrong with the old code?  I guess I just don&#39;t</span>
<span class="quote">&gt;&gt;&gt; see what the problem is that is solved by this patch.</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; Instead of flushing *now* with INVPCID, this lets us flush *later* with</span>
<span class="quote">&gt;&gt; CR3.  It just hijacks the code that you already have that flushes CR3</span>
<span class="quote">&gt;&gt; when loading a new ASID by making all ASIDs look new in the future.</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; We have to load CR3 anyway, so we might as well just do this flush then.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Would it make more sense to put it in flush_tlb_func_common() instead?</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Also, I don&#39;t understand what clear_non_loaded_ctxs() is trying to do.</span>
<span class="quote">&gt; It looks like it&#39;s invalidating all the other logical address spaces.</span>
<span class="quote">&gt; And I don&#39;t see why you want a all_other_ctxs_invalid variable.  Isn&#39;t</span>
<span class="quote">&gt; the goal to mark a single ASID as needing a *user* flush the next time</span>
<span class="quote">&gt; we switch to user mode using that ASID?  Your code seems like it&#39;s</span>
<span class="quote">&gt; going to flush a lot of *kernel* PCIDs.</span>

The point of the whole thing is to (relatively) efficiently flush
*kernel* TLB entries in *other* address spaces.  I did it way down in
the TLB handling functions because not everybody goes through
flush_tlb_func_common() to flush kernel addresses.

I used the variable instead of just invalidating the contexts directly
because I hooked into the __flush_tlb_single() path and it&#39;s used in
loops like this:

	for (addr = start; addr &lt; end; addr++)
		__flush_tlb_single()

I didn&#39;t want to add a loop that effectively does:

	for (addr = start; addr &lt; end; addr++)
		__flush_tlb_single();
		for (i = 0; i &lt; TLB_NR_DYN_ASIDS; i++)
			this_cpu_write(cpu_tlbstate.ctxs[i].ctx_id, 0);

Even with just 6 ASIDS it seemed a little silly.  It would get _very_
silly if we ever decided to grow TLB_NR_DYN_ASIDS.
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=125831">Andrew Lutomirski</a> - Nov. 1, 2017, 9:04 p.m.</div>
<pre class="content">
On Wed, Nov 1, 2017 at 1:59 PM, Dave Hansen &lt;dave.hansen@linux.intel.com&gt; wrote:
<span class="quote">&gt; On 11/01/2017 01:31 PM, Andy Lutomirski wrote:</span>
<span class="quote">&gt;&gt; On Wed, Nov 1, 2017 at 7:17 AM, Dave Hansen &lt;dave.hansen@linux.intel.com&gt; wrote:</span>
<span class="quote">&gt;&gt;&gt; On 11/01/2017 01:03 AM, Andy Lutomirski wrote:</span>
<span class="quote">&gt;&gt;&gt;&gt;&gt; This ensures that any futuee context switches will do a full flush</span>
<span class="quote">&gt;&gt;&gt;&gt;&gt; of the TLB so they pick up the changes.</span>
<span class="quote">&gt;&gt;&gt;&gt; I&#39;m convuced.  What was wrong with the old code?  I guess I just don&#39;t</span>
<span class="quote">&gt;&gt;&gt;&gt; see what the problem is that is solved by this patch.</span>
<span class="quote">&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt; Instead of flushing *now* with INVPCID, this lets us flush *later* with</span>
<span class="quote">&gt;&gt;&gt; CR3.  It just hijacks the code that you already have that flushes CR3</span>
<span class="quote">&gt;&gt;&gt; when loading a new ASID by making all ASIDs look new in the future.</span>
<span class="quote">&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt; We have to load CR3 anyway, so we might as well just do this flush then.</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; Would it make more sense to put it in flush_tlb_func_common() instead?</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; Also, I don&#39;t understand what clear_non_loaded_ctxs() is trying to do.</span>
<span class="quote">&gt;&gt; It looks like it&#39;s invalidating all the other logical address spaces.</span>
<span class="quote">&gt;&gt; And I don&#39;t see why you want a all_other_ctxs_invalid variable.  Isn&#39;t</span>
<span class="quote">&gt;&gt; the goal to mark a single ASID as needing a *user* flush the next time</span>
<span class="quote">&gt;&gt; we switch to user mode using that ASID?  Your code seems like it&#39;s</span>
<span class="quote">&gt;&gt; going to flush a lot of *kernel* PCIDs.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; The point of the whole thing is to (relatively) efficiently flush</span>
<span class="quote">&gt; *kernel* TLB entries in *other* address spaces.</span>

Aha!  That wasn&#39;t at all clear to me from the changelog.  Can I make a
totally different suggestion?  Add a new function
__flush_tlb_one_kernel() and use it for kernel addresses.  That
function should just do __flush_tlb_all() if KAISER is on.  Then make
sure that there are no performance-critical looks that call
__flush_tlb_one_kernel() in KAISER mode.  The approach you&#39;re using is
quite expensive, and I suspect that just going a global flush may
actually be faster.  It&#39;s certainly a lot simpler.

Optionally add a warning to __flush_tlb_one() if the address is a
kernel address to help notice any missed conversions.  Or just rename
it to __flush_tlb_one_user().

--Andy
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=64071">Dave Hansen</a> - Nov. 1, 2017, 9:06 p.m.</div>
<pre class="content">
On 11/01/2017 02:04 PM, Andy Lutomirski wrote:
<span class="quote">&gt; Aha!  That wasn&#39;t at all clear to me from the changelog.  Can I make a</span>
<span class="quote">&gt; totally different suggestion?  Add a new function</span>
<span class="quote">&gt; __flush_tlb_one_kernel() and use it for kernel addresses. </span>

I&#39;ll look into this.
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff -puN arch/x86/include/asm/tlbflush.h~kaiser-pcid-pre-clear-pcid-cache arch/x86/include/asm/tlbflush.h</span>
<span class="p_header">--- a/arch/x86/include/asm/tlbflush.h~kaiser-pcid-pre-clear-pcid-cache	2017-10-31 15:04:00.268582170 -0700</span>
<span class="p_header">+++ b/arch/x86/include/asm/tlbflush.h	2017-10-31 15:04:00.275582500 -0700</span>
<span class="p_chunk">@@ -183,6 +183,17 @@</span> <span class="p_context"> struct tlb_state {</span>
 	bool is_lazy;
 
 	/*
<span class="p_add">+	 * If set we changed the page tables in such a way that we</span>
<span class="p_add">+	 * needed an invalidation of all contexts (aka. PCIDs / ASIDs).</span>
<span class="p_add">+	 * This tells us to go invalidate all the non-loaded ctxs[]</span>
<span class="p_add">+	 * on the next context switch.</span>
<span class="p_add">+	 *</span>
<span class="p_add">+	 * The current ctx was kept up-to-date as it ran and does not</span>
<span class="p_add">+	 * need to be invalidated.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	bool all_other_ctxs_invalid;</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
 	 * Access to this CR4 shadow and to H/W CR4 is protected by
 	 * disabling interrupts when modifying either one.
 	 */
<span class="p_chunk">@@ -259,6 +270,19 @@</span> <span class="p_context"> static inline unsigned long cr4_read_sha</span>
 	return this_cpu_read(cpu_tlbstate.cr4);
 }
 
<span class="p_add">+static inline void tlb_flush_shared_nonglobals(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * With global pages, all of the shared kenel page tables</span>
<span class="p_add">+	 * are set as _PAGE_GLOBAL.  We have no shared nonglobals</span>
<span class="p_add">+	 * and nothing to do here.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	if (IS_ENABLED(CONFIG_X86_GLOBAL_PAGES))</span>
<span class="p_add">+		return;</span>
<span class="p_add">+</span>
<span class="p_add">+	this_cpu_write(cpu_tlbstate.all_other_ctxs_invalid, true);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 /*
  * Save some of cr4 feature set we&#39;re using (e.g.  Pentium 4MB
  * enable and PPro Global page enable), so that any CPU&#39;s that boot
<span class="p_chunk">@@ -288,6 +312,10 @@</span> <span class="p_context"> static inline void __native_flush_tlb(vo</span>
 	preempt_disable();
 	native_write_cr3(__native_read_cr3());
 	preempt_enable();
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Does not need tlb_flush_shared_nonglobals() since the CR3 write</span>
<span class="p_add">+	 * without PCIDs flushes all non-globals.</span>
<span class="p_add">+	 */</span>
 }
 
 static inline void __native_flush_tlb_global_irq_disabled(void)
<span class="p_chunk">@@ -346,24 +374,23 @@</span> <span class="p_context"> static inline void __native_flush_tlb_si</span>
 
 static inline void __flush_tlb_all(void)
 {
<span class="p_del">-	if (boot_cpu_has(X86_FEATURE_PGE))</span>
<span class="p_add">+	if (boot_cpu_has(X86_FEATURE_PGE)) {</span>
 		__flush_tlb_global();
<span class="p_del">-	else</span>
<span class="p_add">+	} else {</span>
 		__flush_tlb();
<span class="p_del">-</span>
<span class="p_del">-	/*</span>
<span class="p_del">-	 * Note: if we somehow had PCID but not PGE, then this wouldn&#39;t work --</span>
<span class="p_del">-	 * we&#39;d end up flushing kernel translations for the current ASID but</span>
<span class="p_del">-	 * we might fail to flush kernel translations for other cached ASIDs.</span>
<span class="p_del">-	 *</span>
<span class="p_del">-	 * To avoid this issue, we force PCID off if PGE is off.</span>
<span class="p_del">-	 */</span>
<span class="p_add">+		tlb_flush_shared_nonglobals();</span>
<span class="p_add">+	}</span>
 }
 
 static inline void __flush_tlb_one(unsigned long addr)
 {
 	count_vm_tlb_event(NR_TLB_LOCAL_FLUSH_ONE);
 	__flush_tlb_single(addr);
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Invalidate other address spaces inaccessible to single-page</span>
<span class="p_add">+	 * invalidation:</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	tlb_flush_shared_nonglobals();</span>
 }
 
 #define TLB_FLUSH_ALL	-1UL
<span class="p_header">diff -puN arch/x86/mm/tlb.c~kaiser-pcid-pre-clear-pcid-cache arch/x86/mm/tlb.c</span>
<span class="p_header">--- a/arch/x86/mm/tlb.c~kaiser-pcid-pre-clear-pcid-cache	2017-10-31 15:04:00.271582311 -0700</span>
<span class="p_header">+++ b/arch/x86/mm/tlb.c	2017-10-31 15:04:00.275582500 -0700</span>
<span class="p_chunk">@@ -28,6 +28,38 @@</span> <span class="p_context"></span>
  *	Implement flush IPI by CALL_FUNCTION_VECTOR, Alex Shi
  */
 
<span class="p_add">+/*</span>
<span class="p_add">+ * We get here when we do something requiring a TLB invalidation</span>
<span class="p_add">+ * but could not go invalidate all of the contexts.  We do the</span>
<span class="p_add">+ * necessary invalidation by clearing out the &#39;ctx_id&#39; which</span>
<span class="p_add">+ * forces a TLB flush when the context is loaded.</span>
<span class="p_add">+ */</span>
<span class="p_add">+void clear_non_loaded_ctxs(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	u16 asid;</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * This is only expected to be set if we have disabled</span>
<span class="p_add">+	 * kernel _PAGE_GLOBAL pages.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+        if (IS_ENABLED(CONFIG_X86_GLOBAL_PAGES)) {</span>
<span class="p_add">+		WARN_ON_ONCE(1);</span>
<span class="p_add">+                return;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	for (asid = 0; asid &lt; TLB_NR_DYN_ASIDS; asid++) {</span>
<span class="p_add">+		/* Do not need to flush the current asid */</span>
<span class="p_add">+		if (asid == this_cpu_read(cpu_tlbstate.loaded_mm_asid))</span>
<span class="p_add">+			continue;</span>
<span class="p_add">+		/*</span>
<span class="p_add">+		 * Make sure the next time we go to switch to</span>
<span class="p_add">+		 * this asid, we do a flush:</span>
<span class="p_add">+		 */</span>
<span class="p_add">+		this_cpu_write(cpu_tlbstate.ctxs[asid].ctx_id, 0);</span>
<span class="p_add">+	}</span>
<span class="p_add">+	this_cpu_write(cpu_tlbstate.all_other_ctxs_invalid, false);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 atomic64_t last_mm_ctx_id = ATOMIC64_INIT(1);
 
 
<span class="p_chunk">@@ -42,6 +74,9 @@</span> <span class="p_context"> static void choose_new_asid(struct mm_st</span>
 		return;
 	}
 
<span class="p_add">+	if (this_cpu_read(cpu_tlbstate.all_other_ctxs_invalid))</span>
<span class="p_add">+		clear_non_loaded_ctxs();</span>
<span class="p_add">+</span>
 	for (asid = 0; asid &lt; TLB_NR_DYN_ASIDS; asid++) {
 		if (this_cpu_read(cpu_tlbstate.ctxs[asid].ctx_id) !=
 		    next-&gt;context.ctx_id)

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



