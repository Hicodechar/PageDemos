
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>[15/25] mm: Move most file-based accounting to the node - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    [15/25] mm: Move most file-based accounting to the node</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=24451">Mel Gorman</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>June 8, 2015, 1:56 p.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;1433771791-30567-16-git-send-email-mgorman@suse.de&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/6565661/mbox/"
   >mbox</a>
|
   <a href="/patch/6565661/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/6565661/">/patch/6565661/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
X-Original-To: patchwork-LKML@patchwork.kernel.org
Delivered-To: patchwork-parsemail@patchwork1.web.kernel.org
Received: from mail.kernel.org (mail.kernel.org [198.145.29.136])
	by patchwork1.web.kernel.org (Postfix) with ESMTP id 4D0369F2F4
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Mon,  8 Jun 2015 14:00:07 +0000 (UTC)
Received: from mail.kernel.org (localhost [127.0.0.1])
	by mail.kernel.org (Postfix) with ESMTP id 1CEA7203EB
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Mon,  8 Jun 2015 14:00:05 +0000 (UTC)
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.kernel.org (Postfix) with ESMTP id B14B8203C0
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Mon,  8 Jun 2015 14:00:02 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S932941AbbFHN7y (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Mon, 8 Jun 2015 09:59:54 -0400
Received: from cantor2.suse.de ([195.135.220.15]:52397 &quot;EHLO mx2.suse.de&quot;
	rhost-flags-OK-OK-OK-OK) by vger.kernel.org with ESMTP
	id S932572AbbFHN5K (ORCPT &lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Mon, 8 Jun 2015 09:57:10 -0400
X-Virus-Scanned: by amavisd-new at test-mx.suse.de
Received: from relay1.suse.de (charybdis-ext.suse.de [195.135.220.254])
	by mx2.suse.de (Postfix) with ESMTP id 5FD18ADC0;
	Mon,  8 Jun 2015 13:56:58 +0000 (UTC)
From: Mel Gorman &lt;mgorman@suse.de&gt;
To: Linux-MM &lt;linux-mm@kvack.org&gt;
Cc: Rik van Riel &lt;riel@redhat.com&gt;, Johannes Weiner &lt;hannes@cmpxchg.org&gt;,
	Michal Hocko &lt;mhocko@suse.cz&gt;,
	LKML &lt;linux-kernel@vger.kernel.org&gt;, Mel Gorman &lt;mgorman@suse.de&gt;
Subject: [PATCH 15/25] mm: Move most file-based accounting to the node
Date: Mon,  8 Jun 2015 14:56:21 +0100
Message-Id: &lt;1433771791-30567-16-git-send-email-mgorman@suse.de&gt;
X-Mailer: git-send-email 2.3.5
In-Reply-To: &lt;1433771791-30567-1-git-send-email-mgorman@suse.de&gt;
References: &lt;1433771791-30567-1-git-send-email-mgorman@suse.de&gt;
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Spam-Status: No, score=-6.9 required=5.0 tests=BAYES_00, RCVD_IN_DNSWL_HI, 
	T_RP_MATCHES_RCVD,
	UNPARSEABLE_RELAY autolearn=unavailable version=3.3.1
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on mail.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=24451">Mel Gorman</a> - June 8, 2015, 1:56 p.m.</div>
<pre class="content">
There are now a number of accounting oddities such as mapped file pages
being accounted for on the node while the total number of file pages are
accounted on the zone. This can be coped with to some extent but it&#39;s
confusing so this patch moves the relevant file-based accounted.
<span class="signed-off-by">
Signed-off-by: Mel Gorman &lt;mgorman@suse.de&gt;</span>
---
 arch/s390/appldata/appldata_mem.c         |  2 +-
 arch/tile/mm/pgtable.c                    |  8 +++----
 drivers/base/node.c                       | 12 +++++-----
 drivers/staging/android/lowmemorykiller.c |  4 ++--
 fs/fs-writeback.c                         |  8 +++----
 fs/fuse/file.c                            |  8 +++----
 fs/nfs/internal.h                         |  2 +-
 fs/nfs/write.c                            |  2 +-
 fs/proc/meminfo.c                         | 10 ++++----
 include/linux/mmzone.h                    | 12 +++++-----
 include/trace/events/writeback.h          |  6 ++---
 mm/filemap.c                              | 12 +++++-----
 mm/migrate.c                              |  8 +++----
 mm/mmap.c                                 |  4 ++--
 mm/nommu.c                                |  4 ++--
 mm/page-writeback.c                       | 38 ++++++++++++-------------------
 mm/page_alloc.c                           | 34 +++++++++++++--------------
 mm/shmem.c                                | 12 +++++-----
 mm/swap_state.c                           |  4 ++--
 mm/truncate.c                             |  2 +-
 mm/vmscan.c                               | 16 ++++++-------
 mm/vmstat.c                               | 12 +++++-----
 22 files changed, 106 insertions(+), 114 deletions(-)
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/arch/s390/appldata/appldata_mem.c b/arch/s390/appldata/appldata_mem.c</span>
<span class="p_header">index edcf2a706942..598df5708501 100644</span>
<span class="p_header">--- a/arch/s390/appldata/appldata_mem.c</span>
<span class="p_header">+++ b/arch/s390/appldata/appldata_mem.c</span>
<span class="p_chunk">@@ -102,7 +102,7 @@</span> <span class="p_context"> static void appldata_get_mem_data(void *data)</span>
 	mem_data-&gt;totalhigh = P2K(val.totalhigh);
 	mem_data-&gt;freehigh  = P2K(val.freehigh);
 	mem_data-&gt;bufferram = P2K(val.bufferram);
<span class="p_del">-	mem_data-&gt;cached    = P2K(global_page_state(NR_FILE_PAGES)</span>
<span class="p_add">+	mem_data-&gt;cached    = P2K(global_node_page_state(NR_FILE_PAGES)</span>
 				- val.bufferram);
 
 	si_swapinfo(&amp;val);
<span class="p_header">diff --git a/arch/tile/mm/pgtable.c b/arch/tile/mm/pgtable.c</span>
<span class="p_header">index 2e784e84bd6f..dad42acd0f84 100644</span>
<span class="p_header">--- a/arch/tile/mm/pgtable.c</span>
<span class="p_header">+++ b/arch/tile/mm/pgtable.c</span>
<span class="p_chunk">@@ -49,16 +49,16 @@</span> <span class="p_context"> void show_mem(unsigned int filter)</span>
 		global_node_page_state(NR_ACTIVE_FILE)),
 	       (global_node_page_state(NR_INACTIVE_ANON) +
 		global_node_page_state(NR_INACTIVE_FILE)),
<span class="p_del">-	       global_page_state(NR_FILE_DIRTY),</span>
<span class="p_del">-	       global_page_state(NR_WRITEBACK),</span>
<span class="p_del">-	       global_page_state(NR_UNSTABLE_NFS),</span>
<span class="p_add">+	       global_node_page_state(NR_FILE_DIRTY),</span>
<span class="p_add">+	       global_node_page_state(NR_WRITEBACK),</span>
<span class="p_add">+	       global_node_page_state(NR_UNSTABLE_NFS),</span>
 	       global_page_state(NR_FREE_PAGES),
 	       (global_page_state(NR_SLAB_RECLAIMABLE) +
 		global_page_state(NR_SLAB_UNRECLAIMABLE)),
 	       global_node_page_state(NR_FILE_MAPPED),
 	       global_page_state(NR_PAGETABLE),
 	       global_page_state(NR_BOUNCE),
<span class="p_del">-	       global_page_state(NR_FILE_PAGES),</span>
<span class="p_add">+	       global_node_page_state(NR_FILE_PAGES),</span>
 	       get_nr_swap_pages());
 
 	for_each_zone(zone) {
<span class="p_header">diff --git a/drivers/base/node.c b/drivers/base/node.c</span>
<span class="p_header">index 4a83f3c9891a..552271e46578 100644</span>
<span class="p_header">--- a/drivers/base/node.c</span>
<span class="p_header">+++ b/drivers/base/node.c</span>
<span class="p_chunk">@@ -116,18 +116,18 @@</span> <span class="p_context"> static ssize_t node_read_meminfo(struct device *dev,</span>
 		       &quot;Node %d AnonHugePages:  %8lu kB\n&quot;
 #endif
 			,
<span class="p_del">-		       nid, K(sum_zone_node_page_state(nid, NR_FILE_DIRTY)),</span>
<span class="p_del">-		       nid, K(sum_zone_node_page_state(nid, NR_WRITEBACK)),</span>
<span class="p_del">-		       nid, K(sum_zone_node_page_state(nid, NR_FILE_PAGES)),</span>
<span class="p_add">+		       nid, K(node_page_state(pgdat, NR_FILE_DIRTY)),</span>
<span class="p_add">+		       nid, K(node_page_state(pgdat, NR_WRITEBACK)),</span>
<span class="p_add">+		       nid, K(node_page_state(pgdat, NR_FILE_PAGES)),</span>
 		       nid, K(node_page_state(pgdat, NR_FILE_MAPPED)),
<span class="p_del">-		       nid, K(node_page_state(pgdat, NR_ANON_PAGES)),</span>
<span class="p_add">+		       nid, K(node_page_state(pgdat, NR_ANON_MAPPED)),</span>
 		       nid, K(i.sharedram),
 		       nid, sum_zone_node_page_state(nid, NR_KERNEL_STACK) *
 				THREAD_SIZE / 1024,
 		       nid, K(sum_zone_node_page_state(nid, NR_PAGETABLE)),
<span class="p_del">-		       nid, K(sum_zone_node_page_state(nid, NR_UNSTABLE_NFS)),</span>
<span class="p_add">+		       nid, K(node_page_state(pgdat, NR_UNSTABLE_NFS)),</span>
 		       nid, K(sum_zone_node_page_state(nid, NR_BOUNCE)),
<span class="p_del">-		       nid, K(sum_zone_node_page_state(nid, NR_WRITEBACK_TEMP)),</span>
<span class="p_add">+		       nid, K(node_page_state(pgdat, NR_WRITEBACK_TEMP)),</span>
 		       nid, K(sum_zone_node_page_state(nid, NR_SLAB_RECLAIMABLE) +
 				sum_zone_node_page_state(nid, NR_SLAB_UNRECLAIMABLE)),
 		       nid, K(sum_zone_node_page_state(nid, NR_SLAB_RECLAIMABLE)),
<span class="p_header">diff --git a/drivers/staging/android/lowmemorykiller.c b/drivers/staging/android/lowmemorykiller.c</span>
<span class="p_header">index 6463d9278229..e3aca64b6aca 100644</span>
<span class="p_header">--- a/drivers/staging/android/lowmemorykiller.c</span>
<span class="p_header">+++ b/drivers/staging/android/lowmemorykiller.c</span>
<span class="p_chunk">@@ -87,8 +87,8 @@</span> <span class="p_context"> static unsigned long lowmem_scan(struct shrinker *s, struct shrink_control *sc)</span>
 	short selected_oom_score_adj;
 	int array_size = ARRAY_SIZE(lowmem_adj);
 	int other_free = global_page_state(NR_FREE_PAGES) - totalreserve_pages;
<span class="p_del">-	int other_file = global_page_state(NR_FILE_PAGES) -</span>
<span class="p_del">-						global_page_state(NR_SHMEM) -</span>
<span class="p_add">+	int other_file = global_node_page_state(NR_FILE_PAGES) -</span>
<span class="p_add">+						global_node_page_state(NR_SHMEM) -</span>
 						total_swapcache_pages();
 
 	if (lowmem_adj_size &lt; array_size)
<span class="p_header">diff --git a/fs/fs-writeback.c b/fs/fs-writeback.c</span>
<span class="p_header">index 32a8bbd7a9ad..813d4ee67a03 100644</span>
<span class="p_header">--- a/fs/fs-writeback.c</span>
<span class="p_header">+++ b/fs/fs-writeback.c</span>
<span class="p_chunk">@@ -836,8 +836,8 @@</span> <span class="p_context"> static bool over_bground_thresh(struct backing_dev_info *bdi)</span>
 
 	global_dirty_limits(&amp;background_thresh, &amp;dirty_thresh);
 
<span class="p_del">-	if (global_page_state(NR_FILE_DIRTY) +</span>
<span class="p_del">-	    global_page_state(NR_UNSTABLE_NFS) &gt; background_thresh)</span>
<span class="p_add">+	if (global_node_page_state(NR_FILE_DIRTY) +</span>
<span class="p_add">+	    global_node_page_state(NR_UNSTABLE_NFS) &gt; background_thresh)</span>
 		return true;
 
 	if (bdi_stat(bdi, BDI_RECLAIMABLE) &gt;
<span class="p_chunk">@@ -991,8 +991,8 @@</span> <span class="p_context"> get_next_work_item(struct backing_dev_info *bdi)</span>
  */
 static unsigned long get_nr_dirty_pages(void)
 {
<span class="p_del">-	return global_page_state(NR_FILE_DIRTY) +</span>
<span class="p_del">-		global_page_state(NR_UNSTABLE_NFS) +</span>
<span class="p_add">+	return global_node_page_state(NR_FILE_DIRTY) +</span>
<span class="p_add">+		global_node_page_state(NR_UNSTABLE_NFS) +</span>
 		get_nr_dirty_inodes();
 }
 
<span class="p_header">diff --git a/fs/fuse/file.c b/fs/fuse/file.c</span>
<span class="p_header">index c01ec3bdcfd8..bcb58dfe2dd3 100644</span>
<span class="p_header">--- a/fs/fuse/file.c</span>
<span class="p_header">+++ b/fs/fuse/file.c</span>
<span class="p_chunk">@@ -1470,7 +1470,7 @@</span> <span class="p_context"> static void fuse_writepage_finish(struct fuse_conn *fc, struct fuse_req *req)</span>
 	list_del(&amp;req-&gt;writepages_entry);
 	for (i = 0; i &lt; req-&gt;num_pages; i++) {
 		dec_bdi_stat(bdi, BDI_WRITEBACK);
<span class="p_del">-		dec_zone_page_state(req-&gt;pages[i], NR_WRITEBACK_TEMP);</span>
<span class="p_add">+		dec_node_page_state(req-&gt;pages[i], NR_WRITEBACK_TEMP);</span>
 		bdi_writeout_inc(bdi);
 	}
 	wake_up(&amp;fi-&gt;page_waitq);
<span class="p_chunk">@@ -1659,7 +1659,7 @@</span> <span class="p_context"> static int fuse_writepage_locked(struct page *page)</span>
 	req-&gt;inode = inode;
 
 	inc_bdi_stat(inode_to_bdi(inode), BDI_WRITEBACK);
<span class="p_del">-	inc_zone_page_state(tmp_page, NR_WRITEBACK_TEMP);</span>
<span class="p_add">+	inc_node_page_state(tmp_page, NR_WRITEBACK_TEMP);</span>
 
 	spin_lock(&amp;fc-&gt;lock);
 	list_add(&amp;req-&gt;writepages_entry, &amp;fi-&gt;writepages);
<span class="p_chunk">@@ -1774,7 +1774,7 @@</span> <span class="p_context"> static bool fuse_writepage_in_flight(struct fuse_req *new_req,</span>
 		spin_unlock(&amp;fc-&gt;lock);
 
 		dec_bdi_stat(bdi, BDI_WRITEBACK);
<span class="p_del">-		dec_zone_page_state(page, NR_WRITEBACK_TEMP);</span>
<span class="p_add">+		dec_node_page_state(page, NR_WRITEBACK_TEMP);</span>
 		bdi_writeout_inc(bdi);
 		fuse_writepage_free(fc, new_req);
 		fuse_request_free(new_req);
<span class="p_chunk">@@ -1873,7 +1873,7 @@</span> <span class="p_context"> static int fuse_writepages_fill(struct page *page,</span>
 	req-&gt;page_descs[req-&gt;num_pages].length = PAGE_SIZE;
 
 	inc_bdi_stat(inode_to_bdi(inode), BDI_WRITEBACK);
<span class="p_del">-	inc_zone_page_state(tmp_page, NR_WRITEBACK_TEMP);</span>
<span class="p_add">+	inc_node_page_state(tmp_page, NR_WRITEBACK_TEMP);</span>
 
 	err = 0;
 	if (is_writeback &amp;&amp; fuse_writepage_in_flight(req, page)) {
<span class="p_header">diff --git a/fs/nfs/internal.h b/fs/nfs/internal.h</span>
<span class="p_header">index 9e6475bc5ba2..1200f9dba3f8 100644</span>
<span class="p_header">--- a/fs/nfs/internal.h</span>
<span class="p_header">+++ b/fs/nfs/internal.h</span>
<span class="p_chunk">@@ -606,7 +606,7 @@</span> <span class="p_context"> void nfs_mark_page_unstable(struct page *page)</span>
 {
 	struct inode *inode = page_file_mapping(page)-&gt;host;
 
<span class="p_del">-	inc_zone_page_state(page, NR_UNSTABLE_NFS);</span>
<span class="p_add">+	inc_node_page_state(page, NR_UNSTABLE_NFS);</span>
 	inc_bdi_stat(inode_to_bdi(inode), BDI_RECLAIMABLE);
 	 __mark_inode_dirty(inode, I_DIRTY_DATASYNC);
 }
<span class="p_header">diff --git a/fs/nfs/write.c b/fs/nfs/write.c</span>
<span class="p_header">index 849ed784d6ac..ee1d2a51e86e 100644</span>
<span class="p_header">--- a/fs/nfs/write.c</span>
<span class="p_header">+++ b/fs/nfs/write.c</span>
<span class="p_chunk">@@ -852,7 +852,7 @@</span> <span class="p_context"> nfs_mark_request_commit(struct nfs_page *req, struct pnfs_layout_segment *lseg,</span>
 static void
 nfs_clear_page_commit(struct page *page)
 {
<span class="p_del">-	dec_zone_page_state(page, NR_UNSTABLE_NFS);</span>
<span class="p_add">+	dec_node_page_state(page, NR_UNSTABLE_NFS);</span>
 	dec_bdi_stat(inode_to_bdi(page_file_mapping(page)-&gt;host), BDI_RECLAIMABLE);
 }
 
<span class="p_header">diff --git a/fs/proc/meminfo.c b/fs/proc/meminfo.c</span>
<span class="p_header">index 2072876cce7c..dc9fde883db4 100644</span>
<span class="p_header">--- a/fs/proc/meminfo.c</span>
<span class="p_header">+++ b/fs/proc/meminfo.c</span>
<span class="p_chunk">@@ -44,7 +44,7 @@</span> <span class="p_context"> static int meminfo_proc_show(struct seq_file *m, void *v)</span>
 	si_swapinfo(&amp;i);
 	committed = percpu_counter_read_positive(&amp;vm_committed_as);
 
<span class="p_del">-	cached = global_page_state(NR_FILE_PAGES) -</span>
<span class="p_add">+	cached = global_node_page_state(NR_FILE_PAGES) -</span>
 			total_swapcache_pages() - i.bufferram;
 	if (cached &lt; 0)
 		cached = 0;
<span class="p_chunk">@@ -171,8 +171,8 @@</span> <span class="p_context"> static int meminfo_proc_show(struct seq_file *m, void *v)</span>
 #endif
 		K(i.totalswap),
 		K(i.freeswap),
<span class="p_del">-		K(global_page_state(NR_FILE_DIRTY)),</span>
<span class="p_del">-		K(global_page_state(NR_WRITEBACK)),</span>
<span class="p_add">+		K(global_node_page_state(NR_FILE_DIRTY)),</span>
<span class="p_add">+		K(global_node_page_state(NR_WRITEBACK)),</span>
 		K(global_node_page_state(NR_ANON_MAPPED)),
 		K(global_node_page_state(NR_FILE_MAPPED)),
 		K(i.sharedram),
<span class="p_chunk">@@ -185,9 +185,9 @@</span> <span class="p_context"> static int meminfo_proc_show(struct seq_file *m, void *v)</span>
 #ifdef CONFIG_QUICKLIST
 		K(quicklist_total_size()),
 #endif
<span class="p_del">-		K(global_page_state(NR_UNSTABLE_NFS)),</span>
<span class="p_add">+		K(global_node_page_state(NR_UNSTABLE_NFS)),</span>
 		K(global_page_state(NR_BOUNCE)),
<span class="p_del">-		K(global_page_state(NR_WRITEBACK_TEMP)),</span>
<span class="p_add">+		K(global_node_page_state(NR_WRITEBACK_TEMP)),</span>
 		K(vm_commit_limit()),
 		K(committed),
 		(unsigned long)VMALLOC_TOTAL &gt;&gt; 10,
<span class="p_header">diff --git a/include/linux/mmzone.h b/include/linux/mmzone.h</span>
<span class="p_header">index 4406f855d58e..34050b012409 100644</span>
<span class="p_header">--- a/include/linux/mmzone.h</span>
<span class="p_header">+++ b/include/linux/mmzone.h</span>
<span class="p_chunk">@@ -116,20 +116,14 @@</span> <span class="p_context"> enum zone_stat_item {</span>
 	NR_FREE_PAGES,
 	NR_ALLOC_BATCH,
 	NR_MLOCK,		/* mlock()ed pages found and moved off LRU */
<span class="p_del">-	NR_FILE_PAGES,</span>
<span class="p_del">-	NR_FILE_DIRTY,</span>
<span class="p_del">-	NR_WRITEBACK,</span>
 	NR_SLAB_RECLAIMABLE,
 	NR_SLAB_UNRECLAIMABLE,
 	NR_PAGETABLE,		/* used for pagetables */
 	NR_KERNEL_STACK,
 	/* Second 128 byte cacheline */
<span class="p_del">-	NR_UNSTABLE_NFS,	/* NFS unstable pages */</span>
 	NR_BOUNCE,
 	NR_VMSCAN_WRITE,
 	NR_VMSCAN_IMMEDIATE,	/* Prioritise for reclaim when writeback ends */
<span class="p_del">-	NR_WRITEBACK_TEMP,	/* Writeback using temporary buffers */</span>
<span class="p_del">-	NR_SHMEM,		/* shmem pages (included tmpfs/GEM pages) */</span>
 	NR_DIRTIED,		/* page dirtyings since bootup */
 	NR_WRITTEN,		/* page writings since bootup */
 #ifdef CONFIG_NUMA
<span class="p_chunk">@@ -160,6 +154,12 @@</span> <span class="p_context"> enum node_stat_item {</span>
 	NR_ANON_MAPPED,	/* Mapped anonymous pages */
 	NR_FILE_MAPPED,	/* pagecache pages mapped into pagetables.
 			   only modified from process context */
<span class="p_add">+	NR_FILE_PAGES,</span>
<span class="p_add">+	NR_FILE_DIRTY,</span>
<span class="p_add">+	NR_WRITEBACK,</span>
<span class="p_add">+	NR_WRITEBACK_TEMP,	/* Writeback using temporary buffers */</span>
<span class="p_add">+	NR_SHMEM,		/* shmem pages (included tmpfs/GEM pages) */</span>
<span class="p_add">+	NR_UNSTABLE_NFS,	/* NFS unstable pages */</span>
 	NR_VM_NODE_STAT_ITEMS
 };
 
<span class="p_header">diff --git a/include/trace/events/writeback.h b/include/trace/events/writeback.h</span>
<span class="p_header">index 5a14ead59696..e1f38ea62129 100644</span>
<span class="p_header">--- a/include/trace/events/writeback.h</span>
<span class="p_header">+++ b/include/trace/events/writeback.h</span>
<span class="p_chunk">@@ -337,9 +337,9 @@</span> <span class="p_context"> TRACE_EVENT(global_dirty_state,</span>
 	),
 
 	TP_fast_assign(
<span class="p_del">-		__entry-&gt;nr_dirty	= global_page_state(NR_FILE_DIRTY);</span>
<span class="p_del">-		__entry-&gt;nr_writeback	= global_page_state(NR_WRITEBACK);</span>
<span class="p_del">-		__entry-&gt;nr_unstable	= global_page_state(NR_UNSTABLE_NFS);</span>
<span class="p_add">+		__entry-&gt;nr_dirty	= global_node_page_state(NR_FILE_DIRTY);</span>
<span class="p_add">+		__entry-&gt;nr_writeback	= global_node_page_state(NR_WRITEBACK);</span>
<span class="p_add">+		__entry-&gt;nr_unstable	= global_node_page_state(NR_UNSTABLE_NFS);</span>
 		__entry-&gt;nr_dirtied	= global_page_state(NR_DIRTIED);
 		__entry-&gt;nr_written	= global_page_state(NR_WRITTEN);
 		__entry-&gt;background_thresh = background_thresh;
<span class="p_header">diff --git a/mm/filemap.c b/mm/filemap.c</span>
<span class="p_header">index 12a47ccd8565..43cb39b5c24a 100644</span>
<span class="p_header">--- a/mm/filemap.c</span>
<span class="p_header">+++ b/mm/filemap.c</span>
<span class="p_chunk">@@ -197,9 +197,9 @@</span> <span class="p_context"> void __delete_from_page_cache(struct page *page, void *shadow)</span>
 	page-&gt;mapping = NULL;
 	/* Leave page-&gt;index set: truncation lookup relies upon it */
 
<span class="p_del">-	__dec_zone_page_state(page, NR_FILE_PAGES);</span>
<span class="p_add">+	__dec_node_page_state(page, NR_FILE_PAGES);</span>
 	if (PageSwapBacked(page))
<span class="p_del">-		__dec_zone_page_state(page, NR_SHMEM);</span>
<span class="p_add">+		__dec_node_page_state(page, NR_SHMEM);</span>
 	BUG_ON(page_mapped(page));
 
 	/*
<span class="p_chunk">@@ -210,7 +210,7 @@</span> <span class="p_context"> void __delete_from_page_cache(struct page *page, void *shadow)</span>
 	 * having removed the page entirely.
 	 */
 	if (PageDirty(page) &amp;&amp; mapping_cap_account_dirty(mapping)) {
<span class="p_del">-		dec_zone_page_state(page, NR_FILE_DIRTY);</span>
<span class="p_add">+		dec_node_page_state(page, NR_FILE_DIRTY);</span>
 		dec_bdi_stat(inode_to_bdi(mapping-&gt;host), BDI_RECLAIMABLE);
 	}
 }
<span class="p_chunk">@@ -485,9 +485,9 @@</span> <span class="p_context"> int replace_page_cache_page(struct page *old, struct page *new, gfp_t gfp_mask)</span>
 		error = radix_tree_insert(&amp;mapping-&gt;page_tree, offset, new);
 		BUG_ON(error);
 		mapping-&gt;nrpages++;
<span class="p_del">-		__inc_zone_page_state(new, NR_FILE_PAGES);</span>
<span class="p_add">+		__inc_node_page_state(new, NR_FILE_PAGES);</span>
 		if (PageSwapBacked(new))
<span class="p_del">-			__inc_zone_page_state(new, NR_SHMEM);</span>
<span class="p_add">+			__inc_node_page_state(new, NR_SHMEM);</span>
 		spin_unlock_irq(&amp;mapping-&gt;tree_lock);
 		mem_cgroup_migrate(old, new, true);
 		radix_tree_preload_end();
<span class="p_chunk">@@ -577,7 +577,7 @@</span> <span class="p_context"> static int __add_to_page_cache_locked(struct page *page,</span>
 	radix_tree_preload_end();
 	if (unlikely(error))
 		goto err_insert;
<span class="p_del">-	__inc_zone_page_state(page, NR_FILE_PAGES);</span>
<span class="p_add">+	__inc_node_page_state(page, NR_FILE_PAGES);</span>
 	spin_unlock_irq(&amp;mapping-&gt;tree_lock);
 	if (!huge)
 		mem_cgroup_commit_charge(page, memcg, false);
<span class="p_header">diff --git a/mm/migrate.c b/mm/migrate.c</span>
<span class="p_header">index 4a50bb7c06a6..ad58e7e33b1f 100644</span>
<span class="p_header">--- a/mm/migrate.c</span>
<span class="p_header">+++ b/mm/migrate.c</span>
<span class="p_chunk">@@ -379,11 +379,11 @@</span> <span class="p_context"> int migrate_page_move_mapping(struct address_space *mapping,</span>
 	 * via NR_FILE_PAGES and NR_ANON_MAPPED if they
 	 * are mapped to swap space.
 	 */
<span class="p_del">-	__dec_zone_page_state(page, NR_FILE_PAGES);</span>
<span class="p_del">-	__inc_zone_page_state(newpage, NR_FILE_PAGES);</span>
<span class="p_add">+	__dec_node_page_state(page, NR_FILE_PAGES);</span>
<span class="p_add">+	__inc_node_page_state(newpage, NR_FILE_PAGES);</span>
 	if (!PageSwapCache(page) &amp;&amp; PageSwapBacked(page)) {
<span class="p_del">-		__dec_zone_page_state(page, NR_SHMEM);</span>
<span class="p_del">-		__inc_zone_page_state(newpage, NR_SHMEM);</span>
<span class="p_add">+		__dec_node_page_state(page, NR_SHMEM);</span>
<span class="p_add">+		__inc_node_page_state(newpage, NR_SHMEM);</span>
 	}
 	spin_unlock_irq(&amp;mapping-&gt;tree_lock);
 
<span class="p_header">diff --git a/mm/mmap.c b/mm/mmap.c</span>
<span class="p_header">index 9ec50a368634..be87d208fd25 100644</span>
<span class="p_header">--- a/mm/mmap.c</span>
<span class="p_header">+++ b/mm/mmap.c</span>
<span class="p_chunk">@@ -168,7 +168,7 @@</span> <span class="p_context"> int __vm_enough_memory(struct mm_struct *mm, long pages, int cap_sys_admin)</span>
 
 	if (sysctl_overcommit_memory == OVERCOMMIT_GUESS) {
 		free = global_page_state(NR_FREE_PAGES);
<span class="p_del">-		free += global_page_state(NR_FILE_PAGES);</span>
<span class="p_add">+		free += global_node_page_state(NR_FILE_PAGES);</span>
 
 		/*
 		 * shmem pages shouldn&#39;t be counted as free in this
<span class="p_chunk">@@ -176,7 +176,7 @@</span> <span class="p_context"> int __vm_enough_memory(struct mm_struct *mm, long pages, int cap_sys_admin)</span>
 		 * that won&#39;t affect the overall amount of available
 		 * memory in the system.
 		 */
<span class="p_del">-		free -= global_page_state(NR_SHMEM);</span>
<span class="p_add">+		free -= global_node_page_state(NR_SHMEM);</span>
 
 		free += get_nr_swap_pages();
 
<span class="p_header">diff --git a/mm/nommu.c b/mm/nommu.c</span>
<span class="p_header">index 3fba2dc97c44..b036f23080e0 100644</span>
<span class="p_header">--- a/mm/nommu.c</span>
<span class="p_header">+++ b/mm/nommu.c</span>
<span class="p_chunk">@@ -1930,7 +1930,7 @@</span> <span class="p_context"> int __vm_enough_memory(struct mm_struct *mm, long pages, int cap_sys_admin)</span>
 
 	if (sysctl_overcommit_memory == OVERCOMMIT_GUESS) {
 		free = global_page_state(NR_FREE_PAGES);
<span class="p_del">-		free += global_page_state(NR_FILE_PAGES);</span>
<span class="p_add">+		free += global_node_page_state(NR_FILE_PAGES);</span>
 
 		/*
 		 * shmem pages shouldn&#39;t be counted as free in this
<span class="p_chunk">@@ -1938,7 +1938,7 @@</span> <span class="p_context"> int __vm_enough_memory(struct mm_struct *mm, long pages, int cap_sys_admin)</span>
 		 * that won&#39;t affect the overall amount of available
 		 * memory in the system.
 		 */
<span class="p_del">-		free -= global_page_state(NR_SHMEM);</span>
<span class="p_add">+		free -= global_node_page_state(NR_SHMEM);</span>
 
 		free += get_nr_swap_pages();
 
<span class="p_header">diff --git a/mm/page-writeback.c b/mm/page-writeback.c</span>
<span class="p_header">index 88e346f36f79..ad1ee405d970 100644</span>
<span class="p_header">--- a/mm/page-writeback.c</span>
<span class="p_header">+++ b/mm/page-writeback.c</span>
<span class="p_chunk">@@ -320,20 +320,12 @@</span> <span class="p_context"> static unsigned long node_dirty_limit(struct pglist_data *pgdat)</span>
  */
 bool node_dirty_ok(struct pglist_data *pgdat)
 {
<span class="p_del">-	int z;</span>
 	unsigned long limit = node_dirty_limit(pgdat);
 	unsigned long nr_pages = 0;
 
<span class="p_del">-	for (z = 0; z &lt; MAX_NR_ZONES; z++) {</span>
<span class="p_del">-		struct zone *zone = pgdat-&gt;node_zones + z;</span>
<span class="p_del">-</span>
<span class="p_del">-		if (!populated_zone(zone))</span>
<span class="p_del">-			continue;</span>
<span class="p_del">-</span>
<span class="p_del">-		nr_pages += zone_page_state(zone, NR_FILE_DIRTY);</span>
<span class="p_del">-		nr_pages += zone_page_state(zone, NR_UNSTABLE_NFS);</span>
<span class="p_del">-		nr_pages += zone_page_state(zone, NR_WRITEBACK);</span>
<span class="p_del">-	}</span>
<span class="p_add">+	nr_pages += node_page_state(pgdat, NR_FILE_DIRTY);</span>
<span class="p_add">+	nr_pages += node_page_state(pgdat, NR_UNSTABLE_NFS);</span>
<span class="p_add">+	nr_pages += node_page_state(pgdat, NR_WRITEBACK);</span>
 
 	return nr_pages &lt;= limit;
 }
<span class="p_chunk">@@ -1381,9 +1373,9 @@</span> <span class="p_context"> static void balance_dirty_pages(struct address_space *mapping,</span>
 		 * written to the server&#39;s write cache, but has not yet
 		 * been flushed to permanent storage.
 		 */
<span class="p_del">-		nr_reclaimable = global_page_state(NR_FILE_DIRTY) +</span>
<span class="p_del">-					global_page_state(NR_UNSTABLE_NFS);</span>
<span class="p_del">-		nr_dirty = nr_reclaimable + global_page_state(NR_WRITEBACK);</span>
<span class="p_add">+		nr_reclaimable = global_node_page_state(NR_FILE_DIRTY) +</span>
<span class="p_add">+					global_node_page_state(NR_UNSTABLE_NFS);</span>
<span class="p_add">+		nr_dirty = nr_reclaimable + global_node_page_state(NR_WRITEBACK);</span>
 
 		global_dirty_limits(&amp;background_thresh, &amp;dirty_thresh);
 
<span class="p_chunk">@@ -1645,8 +1637,8 @@</span> <span class="p_context"> void throttle_vm_writeout(gfp_t gfp_mask)</span>
                  */
                 dirty_thresh += dirty_thresh / 10;      /* wheeee... */
 
<span class="p_del">-                if (global_page_state(NR_UNSTABLE_NFS) +</span>
<span class="p_del">-			global_page_state(NR_WRITEBACK) &lt;= dirty_thresh)</span>
<span class="p_add">+                if (global_node_page_state(NR_UNSTABLE_NFS) +</span>
<span class="p_add">+			global_node_page_state(NR_WRITEBACK) &lt;= dirty_thresh)</span>
                         	break;
                 congestion_wait(BLK_RW_ASYNC, HZ/10);
 
<span class="p_chunk">@@ -1674,8 +1666,8 @@</span> <span class="p_context"> int dirty_writeback_centisecs_handler(struct ctl_table *table, int write,</span>
 void laptop_mode_timer_fn(unsigned long data)
 {
 	struct request_queue *q = (struct request_queue *)data;
<span class="p_del">-	int nr_pages = global_page_state(NR_FILE_DIRTY) +</span>
<span class="p_del">-		global_page_state(NR_UNSTABLE_NFS);</span>
<span class="p_add">+	int nr_pages = global_node_page_state(NR_FILE_DIRTY) +</span>
<span class="p_add">+		global_node_page_state(NR_UNSTABLE_NFS);</span>
 
 	/*
 	 * We want to write everything out, not just down to the dirty
<span class="p_chunk">@@ -2108,8 +2100,8 @@</span> <span class="p_context"> void account_page_dirtied(struct page *page, struct address_space *mapping)</span>
 	if (mapping_cap_account_dirty(mapping)) {
 		struct backing_dev_info *bdi = inode_to_bdi(mapping-&gt;host);
 
<span class="p_del">-		__inc_zone_page_state(page, NR_FILE_DIRTY);</span>
<span class="p_del">-		__inc_zone_page_state(page, NR_DIRTIED);</span>
<span class="p_add">+		__inc_node_page_state(page, NR_FILE_DIRTY);</span>
<span class="p_add">+		__inc_node_page_state(page, NR_DIRTIED);</span>
 		__inc_bdi_stat(bdi, BDI_RECLAIMABLE);
 		__inc_bdi_stat(bdi, BDI_DIRTIED);
 		task_io_account_write(PAGE_CACHE_SIZE);
<span class="p_chunk">@@ -2311,7 +2303,7 @@</span> <span class="p_context"> int clear_page_dirty_for_io(struct page *page)</span>
 		 * exclusion.
 		 */
 		if (TestClearPageDirty(page)) {
<span class="p_del">-			dec_zone_page_state(page, NR_FILE_DIRTY);</span>
<span class="p_add">+			dec_node_page_state(page, NR_FILE_DIRTY);</span>
 			dec_bdi_stat(inode_to_bdi(mapping-&gt;host),
 					BDI_RECLAIMABLE);
 			return 1;
<span class="p_chunk">@@ -2350,7 +2342,7 @@</span> <span class="p_context"> int test_clear_page_writeback(struct page *page)</span>
 	}
 	if (ret) {
 		mem_cgroup_dec_page_stat(memcg, MEM_CGROUP_STAT_WRITEBACK);
<span class="p_del">-		dec_zone_page_state(page, NR_WRITEBACK);</span>
<span class="p_add">+		dec_node_page_state(page, NR_WRITEBACK);</span>
 		inc_zone_page_state(page, NR_WRITTEN);
 	}
 	mem_cgroup_end_page_stat(memcg);
<span class="p_chunk">@@ -2391,7 +2383,7 @@</span> <span class="p_context"> int __test_set_page_writeback(struct page *page, bool keep_write)</span>
 	}
 	if (!ret) {
 		mem_cgroup_inc_page_stat(memcg, MEM_CGROUP_STAT_WRITEBACK);
<span class="p_del">-		inc_zone_page_state(page, NR_WRITEBACK);</span>
<span class="p_add">+		inc_node_page_state(page, NR_WRITEBACK);</span>
 	}
 	mem_cgroup_end_page_stat(memcg);
 	return ret;
<span class="p_header">diff --git a/mm/page_alloc.c b/mm/page_alloc.c</span>
<span class="p_header">index f5a376056ece..2ca5da938972 100644</span>
<span class="p_header">--- a/mm/page_alloc.c</span>
<span class="p_header">+++ b/mm/page_alloc.c</span>
<span class="p_chunk">@@ -3118,7 +3118,7 @@</span> <span class="p_context"> static inline void show_node(struct zone *zone)</span>
 void si_meminfo(struct sysinfo *val)
 {
 	val-&gt;totalram = totalram_pages;
<span class="p_del">-	val-&gt;sharedram = global_page_state(NR_SHMEM);</span>
<span class="p_add">+	val-&gt;sharedram = global_node_page_state(NR_SHMEM);</span>
 	val-&gt;freeram = global_page_state(NR_FREE_PAGES);
 	val-&gt;bufferram = nr_blockdev_pages();
 	val-&gt;totalhigh = totalhigh_pages;
<span class="p_chunk">@@ -3138,7 +3138,7 @@</span> <span class="p_context"> void si_meminfo_node(struct sysinfo *val, int nid)</span>
 	for (zone_type = 0; zone_type &lt; MAX_NR_ZONES; zone_type++)
 		managed_pages += pgdat-&gt;node_zones[zone_type].managed_pages;
 	val-&gt;totalram = managed_pages;
<span class="p_del">-	val-&gt;sharedram = sum_zone_node_page_state(nid, NR_SHMEM);</span>
<span class="p_add">+	val-&gt;sharedram = node_page_state(pgdat, NR_SHMEM);</span>
 	val-&gt;freeram = sum_zone_node_page_state(nid, NR_FREE_PAGES);
 #ifdef CONFIG_HIGHMEM
 	val-&gt;totalhigh = pgdat-&gt;node_zones[ZONE_HIGHMEM].managed_pages;
<span class="p_chunk">@@ -3245,14 +3245,14 @@</span> <span class="p_context"> void show_free_areas(unsigned int filter)</span>
 		global_node_page_state(NR_INACTIVE_FILE),
 		global_node_page_state(NR_ISOLATED_FILE),
 		global_node_page_state(NR_UNEVICTABLE),
<span class="p_del">-		global_page_state(NR_FILE_DIRTY),</span>
<span class="p_del">-		global_page_state(NR_WRITEBACK),</span>
<span class="p_del">-		global_page_state(NR_UNSTABLE_NFS),</span>
<span class="p_add">+		global_node_page_state(NR_FILE_DIRTY),</span>
<span class="p_add">+		global_node_page_state(NR_WRITEBACK),</span>
<span class="p_add">+		global_node_page_state(NR_UNSTABLE_NFS),</span>
 		global_page_state(NR_FREE_PAGES),
 		global_page_state(NR_SLAB_RECLAIMABLE),
 		global_page_state(NR_SLAB_UNRECLAIMABLE),
 		global_node_page_state(NR_FILE_MAPPED),
<span class="p_del">-		global_page_state(NR_SHMEM),</span>
<span class="p_add">+		global_node_page_state(NR_SHMEM),</span>
 		global_page_state(NR_PAGETABLE),
 		global_page_state(NR_BOUNCE),
 		global_page_state(NR_FREE_CMA_PAGES));
<span class="p_chunk">@@ -3267,6 +3267,11 @@</span> <span class="p_context"> void show_free_areas(unsigned int filter)</span>
 			&quot; isolated(anon):%lukB&quot;
 			&quot; isolated(file):%lukB&quot;
 			&quot; mapped:%lukB&quot;
<span class="p_add">+			&quot; dirty:%lukB&quot;</span>
<span class="p_add">+			&quot; writeback:%lukB&quot;</span>
<span class="p_add">+			&quot; shmem:%lukB&quot;</span>
<span class="p_add">+			&quot; writeback_tmp:%lukB&quot;</span>
<span class="p_add">+			&quot; unstable:%lukB&quot;</span>
 			&quot; all_unreclaimable? %s&quot;
 			&quot;\n&quot;,
 			pgdat-&gt;node_id,
<span class="p_chunk">@@ -3278,6 +3283,11 @@</span> <span class="p_context"> void show_free_areas(unsigned int filter)</span>
 			K(node_page_state(pgdat, NR_ISOLATED_ANON)),
 			K(node_page_state(pgdat, NR_ISOLATED_FILE)),
 			K(node_page_state(pgdat, NR_FILE_MAPPED)),
<span class="p_add">+			K(node_page_state(pgdat, NR_FILE_DIRTY)),</span>
<span class="p_add">+			K(node_page_state(pgdat, NR_WRITEBACK)),</span>
<span class="p_add">+			K(node_page_state(pgdat, NR_SHMEM)),</span>
<span class="p_add">+			K(node_page_state(pgdat, NR_WRITEBACK_TEMP)),</span>
<span class="p_add">+			K(node_page_state(pgdat, NR_UNSTABLE_NFS)),</span>
 			!pgdat_reclaimable(pgdat) ? &quot;yes&quot; : &quot;no&quot;);
 	}
 
<span class="p_chunk">@@ -3295,17 +3305,12 @@</span> <span class="p_context"> void show_free_areas(unsigned int filter)</span>
 			&quot; present:%lukB&quot;
 			&quot; managed:%lukB&quot;
 			&quot; mlocked:%lukB&quot;
<span class="p_del">-			&quot; dirty:%lukB&quot;</span>
<span class="p_del">-			&quot; writeback:%lukB&quot;</span>
<span class="p_del">-			&quot; shmem:%lukB&quot;</span>
 			&quot; slab_reclaimable:%lukB&quot;
 			&quot; slab_unreclaimable:%lukB&quot;
 			&quot; kernel_stack:%lukB&quot;
 			&quot; pagetables:%lukB&quot;
<span class="p_del">-			&quot; unstable:%lukB&quot;</span>
 			&quot; bounce:%lukB&quot;
 			&quot; free_cma:%lukB&quot;
<span class="p_del">-			&quot; writeback_tmp:%lukB&quot;</span>
 			&quot; node_pages_scanned:%lu&quot;
 			&quot;\n&quot;,
 			zone-&gt;name,
<span class="p_chunk">@@ -3316,18 +3321,13 @@</span> <span class="p_context"> void show_free_areas(unsigned int filter)</span>
 			K(zone-&gt;present_pages),
 			K(zone-&gt;managed_pages),
 			K(zone_page_state(zone, NR_MLOCK)),
<span class="p_del">-			K(zone_page_state(zone, NR_FILE_DIRTY)),</span>
<span class="p_del">-			K(zone_page_state(zone, NR_WRITEBACK)),</span>
<span class="p_del">-			K(zone_page_state(zone, NR_SHMEM)),</span>
 			K(zone_page_state(zone, NR_SLAB_RECLAIMABLE)),
 			K(zone_page_state(zone, NR_SLAB_UNRECLAIMABLE)),
 			zone_page_state(zone, NR_KERNEL_STACK) *
 				THREAD_SIZE / 1024,
 			K(zone_page_state(zone, NR_PAGETABLE)),
<span class="p_del">-			K(zone_page_state(zone, NR_UNSTABLE_NFS)),</span>
 			K(zone_page_state(zone, NR_BOUNCE)),
 			K(zone_page_state(zone, NR_FREE_CMA_PAGES)),
<span class="p_del">-			K(zone_page_state(zone, NR_WRITEBACK_TEMP)),</span>
 			K(node_page_state(zone-&gt;zone_pgdat, NR_PAGES_SCANNED)));
 		printk(&quot;lowmem_reserve[]:&quot;);
 		for (i = 0; i &lt; MAX_NR_ZONES; i++)
<span class="p_chunk">@@ -3369,7 +3369,7 @@</span> <span class="p_context"> void show_free_areas(unsigned int filter)</span>
 
 	hugetlb_show_meminfo();
 
<span class="p_del">-	printk(&quot;%ld total pagecache pages\n&quot;, global_page_state(NR_FILE_PAGES));</span>
<span class="p_add">+	printk(&quot;%ld total pagecache pages\n&quot;, global_node_page_state(NR_FILE_PAGES));</span>
 
 	show_swap_cache_info();
 }
<span class="p_header">diff --git a/mm/shmem.c b/mm/shmem.c</span>
<span class="p_header">index cf2d0ca010bc..8f73a97599a6 100644</span>
<span class="p_header">--- a/mm/shmem.c</span>
<span class="p_header">+++ b/mm/shmem.c</span>
<span class="p_chunk">@@ -310,8 +310,8 @@</span> <span class="p_context"> static int shmem_add_to_page_cache(struct page *page,</span>
 								 page);
 	if (!error) {
 		mapping-&gt;nrpages++;
<span class="p_del">-		__inc_zone_page_state(page, NR_FILE_PAGES);</span>
<span class="p_del">-		__inc_zone_page_state(page, NR_SHMEM);</span>
<span class="p_add">+		__inc_node_page_state(page, NR_FILE_PAGES);</span>
<span class="p_add">+		__inc_node_page_state(page, NR_SHMEM);</span>
 		spin_unlock_irq(&amp;mapping-&gt;tree_lock);
 	} else {
 		page-&gt;mapping = NULL;
<span class="p_chunk">@@ -333,8 +333,8 @@</span> <span class="p_context"> static void shmem_delete_from_page_cache(struct page *page, void *radswap)</span>
 	error = shmem_radix_tree_replace(mapping, page-&gt;index, page, radswap);
 	page-&gt;mapping = NULL;
 	mapping-&gt;nrpages--;
<span class="p_del">-	__dec_zone_page_state(page, NR_FILE_PAGES);</span>
<span class="p_del">-	__dec_zone_page_state(page, NR_SHMEM);</span>
<span class="p_add">+	__dec_node_page_state(page, NR_FILE_PAGES);</span>
<span class="p_add">+	__dec_node_page_state(page, NR_SHMEM);</span>
 	spin_unlock_irq(&amp;mapping-&gt;tree_lock);
 	page_cache_release(page);
 	BUG_ON(error);
<span class="p_chunk">@@ -995,8 +995,8 @@</span> <span class="p_context"> static int shmem_replace_page(struct page **pagep, gfp_t gfp,</span>
 	error = shmem_radix_tree_replace(swap_mapping, swap_index, oldpage,
 								   newpage);
 	if (!error) {
<span class="p_del">-		__inc_zone_page_state(newpage, NR_FILE_PAGES);</span>
<span class="p_del">-		__dec_zone_page_state(oldpage, NR_FILE_PAGES);</span>
<span class="p_add">+		__inc_node_page_state(newpage, NR_FILE_PAGES);</span>
<span class="p_add">+		__dec_node_page_state(oldpage, NR_FILE_PAGES);</span>
 	}
 	spin_unlock_irq(&amp;swap_mapping-&gt;tree_lock);
 
<span class="p_header">diff --git a/mm/swap_state.c b/mm/swap_state.c</span>
<span class="p_header">index 405923f77334..caa8ebca3996 100644</span>
<span class="p_header">--- a/mm/swap_state.c</span>
<span class="p_header">+++ b/mm/swap_state.c</span>
<span class="p_chunk">@@ -95,7 +95,7 @@</span> <span class="p_context"> int __add_to_swap_cache(struct page *page, swp_entry_t entry)</span>
 					entry.val, page);
 	if (likely(!error)) {
 		address_space-&gt;nrpages++;
<span class="p_del">-		__inc_zone_page_state(page, NR_FILE_PAGES);</span>
<span class="p_add">+		__inc_node_page_state(page, NR_FILE_PAGES);</span>
 		INC_CACHE_INFO(add_total);
 	}
 	spin_unlock_irq(&amp;address_space-&gt;tree_lock);
<span class="p_chunk">@@ -147,7 +147,7 @@</span> <span class="p_context"> void __delete_from_swap_cache(struct page *page)</span>
 	set_page_private(page, 0);
 	ClearPageSwapCache(page);
 	address_space-&gt;nrpages--;
<span class="p_del">-	__dec_zone_page_state(page, NR_FILE_PAGES);</span>
<span class="p_add">+	__dec_node_page_state(page, NR_FILE_PAGES);</span>
 	INC_CACHE_INFO(del_total);
 }
 
<span class="p_header">diff --git a/mm/truncate.c b/mm/truncate.c</span>
<span class="p_header">index ddec5a5966d7..77393b97d9ac 100644</span>
<span class="p_header">--- a/mm/truncate.c</span>
<span class="p_header">+++ b/mm/truncate.c</span>
<span class="p_chunk">@@ -111,7 +111,7 @@</span> <span class="p_context"> void cancel_dirty_page(struct page *page, unsigned int account_size)</span>
 	if (TestClearPageDirty(page)) {
 		struct address_space *mapping = page-&gt;mapping;
 		if (mapping &amp;&amp; mapping_cap_account_dirty(mapping)) {
<span class="p_del">-			dec_zone_page_state(page, NR_FILE_DIRTY);</span>
<span class="p_add">+			dec_node_page_state(page, NR_FILE_DIRTY);</span>
 			dec_bdi_stat(inode_to_bdi(mapping-&gt;host),
 					BDI_RECLAIMABLE);
 			if (account_size)
<span class="p_header">diff --git a/mm/vmscan.c b/mm/vmscan.c</span>
<span class="p_header">index 1391fd15a7ec..2a3050d7dc95 100644</span>
<span class="p_header">--- a/mm/vmscan.c</span>
<span class="p_header">+++ b/mm/vmscan.c</span>
<span class="p_chunk">@@ -3547,11 +3547,11 @@</span> <span class="p_context"> int sysctl_min_unmapped_ratio = 1;</span>
  */
 int sysctl_min_slab_ratio = 5;
 
<span class="p_del">-static inline unsigned long zone_unmapped_file_pages(struct zone *zone)</span>
<span class="p_add">+static inline unsigned long node_unmapped_file_pages(struct pglist_data *pgdat)</span>
 {
<span class="p_del">-	unsigned long file_mapped = node_page_state(zone-&gt;zone_pgdat, NR_FILE_MAPPED);</span>
<span class="p_del">-	unsigned long file_lru = node_page_state(zone-&gt;zone_pgdat, NR_INACTIVE_FILE) +</span>
<span class="p_del">-		node_page_state(zone-&gt;zone_pgdat, NR_ACTIVE_FILE);</span>
<span class="p_add">+	unsigned long file_mapped = node_page_state(pgdat, NR_FILE_MAPPED);</span>
<span class="p_add">+	unsigned long file_lru = node_page_state(pgdat, NR_INACTIVE_FILE) +</span>
<span class="p_add">+		node_page_state(pgdat, NR_ACTIVE_FILE);</span>
 
 	/*
 	 * It&#39;s possible for there to be more file mapped pages than
<span class="p_chunk">@@ -3570,17 +3570,17 @@</span> <span class="p_context"> static long zone_pagecache_reclaimable(struct zone *zone)</span>
 	/*
 	 * If RECLAIM_SWAP is set, then all file pages are considered
 	 * potentially reclaimable. Otherwise, we have to worry about
<span class="p_del">-	 * pages like swapcache and zone_unmapped_file_pages() provides</span>
<span class="p_add">+	 * pages like swapcache and node_unmapped_file_pages() provides</span>
 	 * a better estimate
 	 */
 	if (zone_reclaim_mode &amp; RECLAIM_SWAP)
<span class="p_del">-		nr_pagecache_reclaimable = zone_page_state(zone, NR_FILE_PAGES);</span>
<span class="p_add">+		nr_pagecache_reclaimable = node_page_state(zone-&gt;zone_pgdat, NR_FILE_PAGES);</span>
 	else
<span class="p_del">-		nr_pagecache_reclaimable = zone_unmapped_file_pages(zone);</span>
<span class="p_add">+		nr_pagecache_reclaimable = node_unmapped_file_pages(zone-&gt;zone_pgdat);</span>
 
 	/* If we can&#39;t clean pages, remove dirty pages from consideration */
 	if (!(zone_reclaim_mode &amp; RECLAIM_WRITE))
<span class="p_del">-		delta += zone_page_state(zone, NR_FILE_DIRTY);</span>
<span class="p_add">+		delta += node_page_state(zone-&gt;zone_pgdat, NR_FILE_DIRTY);</span>
 
 	/* Watch for any possible underflows due to delta */
 	if (unlikely(delta &gt; nr_pagecache_reclaimable))
<span class="p_header">diff --git a/mm/vmstat.c b/mm/vmstat.c</span>
<span class="p_header">index 4aa4fb09d078..4a9f73c4140b 100644</span>
<span class="p_header">--- a/mm/vmstat.c</span>
<span class="p_header">+++ b/mm/vmstat.c</span>
<span class="p_chunk">@@ -895,19 +895,13 @@</span> <span class="p_context"> const char * const vmstat_text[] = {</span>
 	&quot;nr_free_pages&quot;,
 	&quot;nr_alloc_batch&quot;,
 	&quot;nr_mlock&quot;,
<span class="p_del">-	&quot;nr_file_pages&quot;,</span>
<span class="p_del">-	&quot;nr_dirty&quot;,</span>
<span class="p_del">-	&quot;nr_writeback&quot;,</span>
 	&quot;nr_slab_reclaimable&quot;,
 	&quot;nr_slab_unreclaimable&quot;,
 	&quot;nr_page_table_pages&quot;,
 	&quot;nr_kernel_stack&quot;,
<span class="p_del">-	&quot;nr_unstable&quot;,</span>
 	&quot;nr_bounce&quot;,
 	&quot;nr_vmscan_write&quot;,
 	&quot;nr_vmscan_immediate_reclaim&quot;,
<span class="p_del">-	&quot;nr_writeback_temp&quot;,</span>
<span class="p_del">-	&quot;nr_shmem&quot;,</span>
 	&quot;nr_dirtied&quot;,
 	&quot;nr_written&quot;,
 
<span class="p_chunk">@@ -936,6 +930,12 @@</span> <span class="p_context"> const char * const vmstat_text[] = {</span>
 	&quot;workingset_nodereclaim&quot;,
 	&quot;nr_anon_pages&quot;,
 	&quot;nr_mapped&quot;,
<span class="p_add">+	&quot;nr_file_pages&quot;,</span>
<span class="p_add">+	&quot;nr_dirty&quot;,</span>
<span class="p_add">+	&quot;nr_writeback&quot;,</span>
<span class="p_add">+	&quot;nr_writeback_temp&quot;,</span>
<span class="p_add">+	&quot;nr_shmem&quot;,</span>
<span class="p_add">+	&quot;nr_unstable&quot;,</span>
 
 	/* enum writeback_stat_item counters */
 	&quot;nr_dirty_threshold&quot;,

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



