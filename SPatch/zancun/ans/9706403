
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>[GIT,PULL] x86/cpu changes for v4.12 - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    [GIT,PULL] x86/cpu changes for v4.12</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=35552">Ingo Molnar</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>May 1, 2017, 11:06 a.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;20170501110639.2c3vb7hdqld5i4uk@gmail.com&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/9706403/mbox/"
   >mbox</a>
|
   <a href="/patch/9706403/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/9706403/">/patch/9706403/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
	[172.30.200.125])
	by pdx-korg-patchwork.web.codeaurora.org (Postfix) with ESMTP id
	466826020B for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Mon,  1 May 2017 11:07:42 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 2788E23B23
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Mon,  1 May 2017 11:07:42 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id 17CDB27C0B; Mon,  1 May 2017 11:07:42 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-6.3 required=2.0 tests=BAYES_00,DKIM_SIGNED,
	RCVD_IN_DNSWL_HI, RCVD_IN_SORBS_SPAM,
	T_DKIM_INVALID autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 58CDD23B23
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Mon,  1 May 2017 11:07:38 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S377143AbdEALGv (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Mon, 1 May 2017 07:06:51 -0400
Received: from mail-wm0-f67.google.com ([74.125.82.67]:36524 &quot;EHLO
	mail-wm0-f67.google.com&quot; rhost-flags-OK-OK-OK-OK) by vger.kernel.org
	with ESMTP id S377118AbdEALGo (ORCPT
	&lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Mon, 1 May 2017 07:06:44 -0400
Received: by mail-wm0-f67.google.com with SMTP id u65so22878168wmu.3
	for &lt;linux-kernel@vger.kernel.org&gt;;
	Mon, 01 May 2017 04:06:43 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
	d=gmail.com; s=20161025;
	h=sender:date:from:to:cc:subject:message-id:mime-version
	:content-disposition:user-agent;
	bh=jPdhMwDSMEulDlkRYio4mg5w2nQcHln/vxecfNyDj1g=;
	b=Ab5Vx70hKo3B9Z278aDlnFAPb6n1WX0cNKQXEML1d1TJ7gzq0yQS4MeZPTIzzdntRZ
	gIqgQDlEMc9QpKDvvIirg4JRYJLx1yG/dIYCzeO2dW2Q9m1XDJFyR1BJfxdPUo0n2PAA
	9A8/mwsm2qlPAkkEiIpgCow507K6Mk9JNPgHMJgmyXDDNpAHJDo0SIff0Ydbqbin04OP
	xyNhnceZ+YydB/SGd6vKNqnvitaMCLuzldTAbqhMlaXKcbh2p8Q/lRlgMjLb0Vlh6eVt
	7JL6aLcqF1vywkNBkEOJ+bUTGouBzLQusI/XE5JN2Jj9vfC1xA/vRWTZ7FxaaIpvxI6R
	+wwQ==
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
	d=1e100.net; s=20161025;
	h=x-gm-message-state:sender:date:from:to:cc:subject:message-id
	:mime-version:content-disposition:user-agent;
	bh=jPdhMwDSMEulDlkRYio4mg5w2nQcHln/vxecfNyDj1g=;
	b=VZNB6rCxCP6uc6PCJdVxvIwcLvBsEPk1ofSuOURBvJu7r29N5aoDePy702dbqG0JRQ
	MDAIdnhmfihxIgyi6B2LZj9joqY/dfQtVUzh14Ol9PMVi6vieU3FC51IHute8Nl4jkab
	L3jG5lYdjsSWGvF7ht3m/K1UPprDbvzA4S1zm9UmaZXgBL4+8krShRuqso2wWJ0A6kdm
	cU+Os4TZ4fPiznntlnjF/XHh89cF8u71ppl6ld5TIkMg4ULq9o7eWXuAjnCOQY3VLiOQ
	yaza4OSVwUscSZTDwzXrpHXxsCiIN8S0WTgsVBM/7AeXi5milKce4hJj/VsAZLwo1LW2
	OaPA==
X-Gm-Message-State: AN3rC/57l/wmY+Vv5wN5n/tFQUw6EsA5X+EfOWzFyCaO2Ui59MIfpImz
	czNCIg9ED39JDgw5
X-Received: by 10.28.151.213 with SMTP id z204mr181026wmd.48.1493636802047; 
	Mon, 01 May 2017 04:06:42 -0700 (PDT)
Received: from gmail.com (2E8B0CD5.catv.pool.telekom.hu. [46.139.12.213])
	by smtp.gmail.com with ESMTPSA id
	y60sm10984854wrb.39.2017.05.01.04.06.40
	(version=TLS1_2 cipher=ECDHE-RSA-CHACHA20-POLY1305 bits=256/256);
	Mon, 01 May 2017 04:06:41 -0700 (PDT)
Date: Mon, 1 May 2017 13:06:39 +0200
From: Ingo Molnar &lt;mingo@kernel.org&gt;
To: Linus Torvalds &lt;torvalds@linux-foundation.org&gt;
Cc: linux-kernel@vger.kernel.org, Thomas Gleixner &lt;tglx@linutronix.de&gt;,
	&quot;H. Peter Anvin&quot; &lt;hpa@zytor.com&gt;,
	Peter Zijlstra &lt;a.p.zijlstra@chello.nl&gt;,
	Andrew Morton &lt;akpm@linux-foundation.org&gt;
Subject: [GIT PULL] x86/cpu changes for v4.12
Message-ID: &lt;20170501110639.2c3vb7hdqld5i4uk@gmail.com&gt;
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Disposition: inline
User-Agent: NeoMutt/20170113 (1.7.2)
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=35552">Ingo Molnar</a> - May 1, 2017, 11:06 a.m.</div>
<pre class="content">
Linus,

Please pull the latest x86-cpu-for-linus git tree from:

   git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip.git x86-cpu-for-linus

   # HEAD: 4797b7dfdfcf457075c36743d71e2b0feeaaa20f x86/intel_rdt: Return error for incorrect resource names in schemata

The biggest changes are an extension of the Intel RDT code to extend it with Intel 
Memory Bandwidth Allocation CPU support: MBA allows bandwidth allocation between 
cores, while CBM (already upstream) allows CPU cache partitioning.

There&#39;s also misc smaller fixes and updates.

 Thanks,

	Ingo

------------------&gt;
Andy Shevchenko (1):
      x86/cpu: Keep model defines sorted by model number

Jiri Olsa (1):
      x86/intel_rdt: Add cpus_list rdtgroup file

Mathias Krause (2):
      x86/cpu: Drop unneded members of struct cpuinfo_x86
      x86/cpu: Drop wp_works_ok member of struct cpuinfo_x86

Thomas Gleixner (6):
      x86/intel_rdt: Cleanup kernel-doc
      x86/intel_rdt: Init padding only if a device exists
      x86/intel_rdt: Organize code properly
      x86/intel_rdt: Move CBM specific data into a struct
      x86/intel_rdt: Add resource specific msr update function
      x86/intel_rdt: Get rid of anon union

Tony Luck (1):
      x86/intel_rdt: Implement &quot;update&quot; mode when writing schemata file

Vikas Shivappa (12):
      x86/intel_rdt: Update schemata read to show data in tabular format
      Documentation, x86: Intel Memory bandwidth allocation
      x86/intel_rdt: Cleanup namespace to support multiple resource types
      x86/intel_rdt/mba: Memory bandwith allocation feature detect
      x86/intel_rdt/mba: Add primary support for Memory Bandwidth Allocation (MBA)
      x86/intel_rdt: Make information files resource specific
      x86/intel_rdt/mba: Add info directory files for Memory Bandwidth Allocation
      x86/intel_rdt: Make schemata file parsers resource specific
      x86/intel_rdt/mba: Add schemata file support for MBA
      x86/intel_rdt: Fix padding when resource is enabled via mount
      x86/intel_rdt: Trim whitespace while parsing schemata input
      x86/intel_rdt: Return error for incorrect resource names in schemata


 Documentation/x86/intel_rdt_ui.txt       | 124 +++++++++--
 arch/x86/include/asm/cpufeatures.h       |   2 +
 arch/x86/include/asm/intel-family.h      |   6 +-
 arch/x86/include/asm/intel_rdt.h         | 157 +++++++++-----
 arch/x86/include/asm/processor.h         |  11 +-
 arch/x86/kernel/cpu/intel_rdt.c          | 350 ++++++++++++++++++++++---------
 arch/x86/kernel/cpu/intel_rdt_rdtgroup.c | 125 +++++++++--
 arch/x86/kernel/cpu/intel_rdt_schemata.c | 181 +++++++++-------
 arch/x86/kernel/cpu/proc.c               |   5 +-
 arch/x86/kernel/cpu/scattered.c          |   1 +
 arch/x86/kernel/setup.c                  |  11 +-
 arch/x86/mm/init_32.c                    |   9 +-
 arch/x86/xen/enlighten.c                 |   1 -
 13 files changed, 707 insertions(+), 276 deletions(-)
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/Documentation/x86/intel_rdt_ui.txt b/Documentation/x86/intel_rdt_ui.txt</span>
<span class="p_header">index 51cf6fa5591f..0f6d8477b66c 100644</span>
<span class="p_header">--- a/Documentation/x86/intel_rdt_ui.txt</span>
<span class="p_header">+++ b/Documentation/x86/intel_rdt_ui.txt</span>
<span class="p_chunk">@@ -4,6 +4,7 @@</span> <span class="p_context"> Copyright (C) 2016 Intel Corporation</span>
 
 Fenghua Yu &lt;fenghua.yu@intel.com&gt;
 Tony Luck &lt;tony.luck@intel.com&gt;
<span class="p_add">+Vikas Shivappa &lt;vikas.shivappa@intel.com&gt;</span>
 
 This feature is enabled by the CONFIG_INTEL_RDT_A Kconfig and the
 X86 /proc/cpuinfo flag bits &quot;rdt&quot;, &quot;cat_l3&quot; and &quot;cdp_l3&quot;.
<span class="p_chunk">@@ -22,19 +23,34 @@</span> <span class="p_context"> Info directory</span>
 
 The &#39;info&#39; directory contains information about the enabled
 resources. Each resource has its own subdirectory. The subdirectory
<span class="p_del">-names reflect the resource names. Each subdirectory contains the</span>
<span class="p_del">-following files:</span>
<span class="p_add">+names reflect the resource names.</span>
<span class="p_add">+Cache resource(L3/L2)  subdirectory contains the following files:</span>
 
<span class="p_del">-&quot;num_closids&quot;:  The number of CLOSIDs which are valid for this</span>
<span class="p_del">-	        resource. The kernel uses the smallest number of</span>
<span class="p_del">-		CLOSIDs of all enabled resources as limit.</span>
<span class="p_add">+&quot;num_closids&quot;:  	The number of CLOSIDs which are valid for this</span>
<span class="p_add">+			resource. The kernel uses the smallest number of</span>
<span class="p_add">+			CLOSIDs of all enabled resources as limit.</span>
 
<span class="p_del">-&quot;cbm_mask&quot;:     The bitmask which is valid for this resource. This</span>
<span class="p_del">-		mask is equivalent to 100%.</span>
<span class="p_add">+&quot;cbm_mask&quot;:     	The bitmask which is valid for this resource.</span>
<span class="p_add">+			This mask is equivalent to 100%.</span>
 
<span class="p_del">-&quot;min_cbm_bits&quot;: The minimum number of consecutive bits which must be</span>
<span class="p_del">-		set when writing a mask.</span>
<span class="p_add">+&quot;min_cbm_bits&quot;: 	The minimum number of consecutive bits which</span>
<span class="p_add">+			must be set when writing a mask.</span>
 
<span class="p_add">+Memory bandwitdh(MB) subdirectory contains the following files:</span>
<span class="p_add">+</span>
<span class="p_add">+&quot;min_bandwidth&quot;:	The minimum memory bandwidth percentage which</span>
<span class="p_add">+			user can request.</span>
<span class="p_add">+</span>
<span class="p_add">+&quot;bandwidth_gran&quot;:	The granularity in which the memory bandwidth</span>
<span class="p_add">+			percentage is allocated. The allocated</span>
<span class="p_add">+			b/w percentage is rounded off to the next</span>
<span class="p_add">+			control step available on the hardware. The</span>
<span class="p_add">+			available bandwidth control steps are:</span>
<span class="p_add">+			min_bandwidth + N * bandwidth_gran.</span>
<span class="p_add">+</span>
<span class="p_add">+&quot;delay_linear&quot;: 	Indicates if the delay scale is linear or</span>
<span class="p_add">+			non-linear. This field is purely informational</span>
<span class="p_add">+			only.</span>
 
 Resource groups
 ---------------
<span class="p_chunk">@@ -59,6 +75,9 @@</span> <span class="p_context"> command, and removed using &quot;rmdir(1)&quot;.</span>
 	given to the default (root) group. You cannot remove CPUs
 	from the default group.
 
<span class="p_add">+&quot;cpus_list&quot;: One or more CPU ranges of logical CPUs assigned to this</span>
<span class="p_add">+	     group. Same rules apply like for the &quot;cpus&quot; file.</span>
<span class="p_add">+</span>
 &quot;schemata&quot;: A list of all the resources available to this group.
 	Each resource has its own line and format - see below for
 	details.
<span class="p_chunk">@@ -107,6 +126,22 @@</span> <span class="p_context"> and 0xA are not.  On a system with a 20-bit mask each bit represents 5%</span>
 of the capacity of the cache. You could partition the cache into four
 equal parts with masks: 0x1f, 0x3e0, 0x7c00, 0xf8000.
 
<span class="p_add">+Memory bandwidth(b/w) percentage</span>
<span class="p_add">+--------------------------------</span>
<span class="p_add">+For Memory b/w resource, user controls the resource by indicating the</span>
<span class="p_add">+percentage of total memory b/w.</span>
<span class="p_add">+</span>
<span class="p_add">+The minimum bandwidth percentage value for each cpu model is predefined</span>
<span class="p_add">+and can be looked up through &quot;info/MB/min_bandwidth&quot;. The bandwidth</span>
<span class="p_add">+granularity that is allocated is also dependent on the cpu model and can</span>
<span class="p_add">+be looked up at &quot;info/MB/bandwidth_gran&quot;. The available bandwidth</span>
<span class="p_add">+control steps are: min_bw + N * bw_gran. Intermediate values are rounded</span>
<span class="p_add">+to the next control step available on the hardware.</span>
<span class="p_add">+</span>
<span class="p_add">+The bandwidth throttling is a core specific mechanism on some of Intel</span>
<span class="p_add">+SKUs. Using a high bandwidth and a low bandwidth setting on two threads</span>
<span class="p_add">+sharing a core will result in both threads being throttled to use the</span>
<span class="p_add">+low bandwidth.</span>
 
 L3 details (code and data prioritization disabled)
 --------------------------------------------------
<span class="p_chunk">@@ -129,16 +164,38 @@</span> <span class="p_context"> L2 cache does not support code and data prioritization, so the</span>
 
 	L2:&lt;cache_id0&gt;=&lt;cbm&gt;;&lt;cache_id1&gt;=&lt;cbm&gt;;...
 
<span class="p_add">+Memory b/w Allocation details</span>
<span class="p_add">+-----------------------------</span>
<span class="p_add">+</span>
<span class="p_add">+Memory b/w domain is L3 cache.</span>
<span class="p_add">+</span>
<span class="p_add">+	MB:&lt;cache_id0&gt;=bandwidth0;&lt;cache_id1&gt;=bandwidth1;...</span>
<span class="p_add">+</span>
<span class="p_add">+Reading/writing the schemata file</span>
<span class="p_add">+---------------------------------</span>
<span class="p_add">+Reading the schemata file will show the state of all resources</span>
<span class="p_add">+on all domains. When writing you only need to specify those values</span>
<span class="p_add">+which you wish to change.  E.g.</span>
<span class="p_add">+</span>
<span class="p_add">+# cat schemata</span>
<span class="p_add">+L3DATA:0=fffff;1=fffff;2=fffff;3=fffff</span>
<span class="p_add">+L3CODE:0=fffff;1=fffff;2=fffff;3=fffff</span>
<span class="p_add">+# echo &quot;L3DATA:2=3c0;&quot; &gt; schemata</span>
<span class="p_add">+# cat schemata</span>
<span class="p_add">+L3DATA:0=fffff;1=fffff;2=3c0;3=fffff</span>
<span class="p_add">+L3CODE:0=fffff;1=fffff;2=fffff;3=fffff</span>
<span class="p_add">+</span>
 Example 1
 ---------
 On a two socket machine (one L3 cache per socket) with just four bits
<span class="p_del">-for cache bit masks</span>
<span class="p_add">+for cache bit masks, minimum b/w of 10% with a memory bandwidth</span>
<span class="p_add">+granularity of 10%</span>
 
 # mount -t resctrl resctrl /sys/fs/resctrl
 # cd /sys/fs/resctrl
 # mkdir p0 p1
<span class="p_del">-# echo &quot;L3:0=3;1=c&quot; &gt; /sys/fs/resctrl/p0/schemata</span>
<span class="p_del">-# echo &quot;L3:0=3;1=3&quot; &gt; /sys/fs/resctrl/p1/schemata</span>
<span class="p_add">+# echo &quot;L3:0=3;1=c\nMB:0=50;1=50&quot; &gt; /sys/fs/resctrl/p0/schemata</span>
<span class="p_add">+# echo &quot;L3:0=3;1=3\nMB:0=50;1=50&quot; &gt; /sys/fs/resctrl/p1/schemata</span>
 
 The default resource group is unmodified, so we have access to all parts
 of all caches (its schemata file reads &quot;L3:0=f;1=f&quot;).
<span class="p_chunk">@@ -147,6 +204,14 @@</span> <span class="p_context"> Tasks that are under the control of group &quot;p0&quot; may only allocate from the</span>
 &quot;lower&quot; 50% on cache ID 0, and the &quot;upper&quot; 50% of cache ID 1.
 Tasks in group &quot;p1&quot; use the &quot;lower&quot; 50% of cache on both sockets.
 
<span class="p_add">+Similarly, tasks that are under the control of group &quot;p0&quot; may use a</span>
<span class="p_add">+maximum memory b/w of 50% on socket0 and 50% on socket 1.</span>
<span class="p_add">+Tasks in group &quot;p1&quot; may also use 50% memory b/w on both sockets.</span>
<span class="p_add">+Note that unlike cache masks, memory b/w cannot specify whether these</span>
<span class="p_add">+allocations can overlap or not. The allocations specifies the maximum</span>
<span class="p_add">+b/w that the group may be able to use and the system admin can configure</span>
<span class="p_add">+the b/w accordingly.</span>
<span class="p_add">+</span>
 Example 2
 ---------
 Again two sockets, but this time with a more realistic 20-bit mask.
<span class="p_chunk">@@ -160,9 +225,10 @@</span> <span class="p_context"> of L3 cache on socket 0.</span>
 # cd /sys/fs/resctrl
 
 First we reset the schemata for the default group so that the &quot;upper&quot;
<span class="p_del">-50% of the L3 cache on socket 0 cannot be used by ordinary tasks:</span>
<span class="p_add">+50% of the L3 cache on socket 0 and 50% of memory b/w cannot be used by</span>
<span class="p_add">+ordinary tasks:</span>
 
<span class="p_del">-# echo &quot;L3:0=3ff;1=fffff&quot; &gt; schemata</span>
<span class="p_add">+# echo &quot;L3:0=3ff;1=fffff\nMB:0=50;1=100&quot; &gt; schemata</span>
 
 Next we make a resource group for our first real time task and give
 it access to the &quot;top&quot; 25% of the cache on socket 0.
<span class="p_chunk">@@ -185,6 +251,20 @@</span> <span class="p_context"> processors tasks run on.</span>
 # echo 5678 &gt; p1/tasks
 # taskset -cp 2 5678
 
<span class="p_add">+For the same 2 socket system with memory b/w resource and CAT L3 the</span>
<span class="p_add">+schemata would look like(Assume min_bandwidth 10 and bandwidth_gran is</span>
<span class="p_add">+10):</span>
<span class="p_add">+</span>
<span class="p_add">+For our first real time task this would request 20% memory b/w on socket</span>
<span class="p_add">+0.</span>
<span class="p_add">+</span>
<span class="p_add">+# echo -e &quot;L3:0=f8000;1=fffff\nMB:0=20;1=100&quot; &gt; p0/schemata</span>
<span class="p_add">+</span>
<span class="p_add">+For our second real time task this would request an other 20% memory b/w</span>
<span class="p_add">+on socket 0.</span>
<span class="p_add">+</span>
<span class="p_add">+# echo -e &quot;L3:0=f8000;1=fffff\nMB:0=20;1=100&quot; &gt; p0/schemata</span>
<span class="p_add">+</span>
 Example 3
 ---------
 
<span class="p_chunk">@@ -198,18 +278,22 @@</span> <span class="p_context"> the tasks.</span>
 # cd /sys/fs/resctrl
 
 First we reset the schemata for the default group so that the &quot;upper&quot;
<span class="p_del">-50% of the L3 cache on socket 0 cannot be used by ordinary tasks:</span>
<span class="p_add">+50% of the L3 cache on socket 0, and 50% of memory bandwidth on socket 0</span>
<span class="p_add">+cannot be used by ordinary tasks:</span>
 
<span class="p_del">-# echo &quot;L3:0=3ff&quot; &gt; schemata</span>
<span class="p_add">+# echo &quot;L3:0=3ff\nMB:0=50&quot; &gt; schemata</span>
 
<span class="p_del">-Next we make a resource group for our real time cores and give</span>
<span class="p_del">-it access to the &quot;top&quot; 50% of the cache on socket 0.</span>
<span class="p_add">+Next we make a resource group for our real time cores and give it access</span>
<span class="p_add">+to the &quot;top&quot; 50% of the cache on socket 0 and 50% of memory bandwidth on</span>
<span class="p_add">+socket 0.</span>
 
 # mkdir p0
<span class="p_del">-# echo &quot;L3:0=ffc00;&quot; &gt; p0/schemata</span>
<span class="p_add">+# echo &quot;L3:0=ffc00\nMB:0=50&quot; &gt; p0/schemata</span>
 
 Finally we move core 4-7 over to the new group and make sure that the
<span class="p_del">-kernel and the tasks running there get 50% of the cache.</span>
<span class="p_add">+kernel and the tasks running there get 50% of the cache. They should</span>
<span class="p_add">+also get 50% of memory bandwidth assuming that the cores 4-7 are SMT</span>
<span class="p_add">+siblings and only the real time threads are scheduled on the cores 4-7.</span>
 
 # echo C0 &gt; p0/cpus
 
<span class="p_header">diff --git a/arch/x86/include/asm/cpufeatures.h b/arch/x86/include/asm/cpufeatures.h</span>
<span class="p_header">index b04bb6dfed7f..25d7f528bd96 100644</span>
<span class="p_header">--- a/arch/x86/include/asm/cpufeatures.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/cpufeatures.h</span>
<span class="p_chunk">@@ -201,6 +201,8 @@</span> <span class="p_context"></span>
 #define X86_FEATURE_AVX512_4VNNIW (7*32+16) /* AVX-512 Neural Network Instructions */
 #define X86_FEATURE_AVX512_4FMAPS (7*32+17) /* AVX-512 Multiply Accumulation Single precision */
 
<span class="p_add">+#define X86_FEATURE_MBA         ( 7*32+18) /* Memory Bandwidth Allocation */</span>
<span class="p_add">+</span>
 /* Virtualization flags: Linux defined, word 8 */
 #define X86_FEATURE_TPR_SHADOW  ( 8*32+ 0) /* Intel TPR Shadow */
 #define X86_FEATURE_VNMI        ( 8*32+ 1) /* Intel Virtual NMI */
<span class="p_header">diff --git a/arch/x86/include/asm/intel-family.h b/arch/x86/include/asm/intel-family.h</span>
<span class="p_header">index 9814db42b790..75b748a1deb8 100644</span>
<span class="p_header">--- a/arch/x86/include/asm/intel-family.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/intel-family.h</span>
<span class="p_chunk">@@ -12,6 +12,7 @@</span> <span class="p_context"></span>
  */
 
 #define INTEL_FAM6_CORE_YONAH		0x0E
<span class="p_add">+</span>
 #define INTEL_FAM6_CORE2_MEROM		0x0F
 #define INTEL_FAM6_CORE2_MEROM_L	0x16
 #define INTEL_FAM6_CORE2_PENRYN		0x17
<span class="p_chunk">@@ -21,6 +22,7 @@</span> <span class="p_context"></span>
 #define INTEL_FAM6_NEHALEM_G		0x1F /* Auburndale / Havendale */
 #define INTEL_FAM6_NEHALEM_EP		0x1A
 #define INTEL_FAM6_NEHALEM_EX		0x2E
<span class="p_add">+</span>
 #define INTEL_FAM6_WESTMERE		0x25
 #define INTEL_FAM6_WESTMERE_EP		0x2C
 #define INTEL_FAM6_WESTMERE_EX		0x2F
<span class="p_chunk">@@ -36,9 +38,9 @@</span> <span class="p_context"></span>
 #define INTEL_FAM6_HASWELL_GT3E		0x46
 
 #define INTEL_FAM6_BROADWELL_CORE	0x3D
<span class="p_del">-#define INTEL_FAM6_BROADWELL_XEON_D	0x56</span>
 #define INTEL_FAM6_BROADWELL_GT3E	0x47
 #define INTEL_FAM6_BROADWELL_X		0x4F
<span class="p_add">+#define INTEL_FAM6_BROADWELL_XEON_D	0x56</span>
 
 #define INTEL_FAM6_SKYLAKE_MOBILE	0x4E
 #define INTEL_FAM6_SKYLAKE_DESKTOP	0x5E
<span class="p_chunk">@@ -59,8 +61,8 @@</span> <span class="p_context"></span>
 #define INTEL_FAM6_ATOM_MERRIFIELD	0x4A /* Tangier */
 #define INTEL_FAM6_ATOM_MOOREFIELD	0x5A /* Anniedale */
 #define INTEL_FAM6_ATOM_GOLDMONT	0x5C
<span class="p_del">-#define INTEL_FAM6_ATOM_GEMINI_LAKE	0x7A</span>
 #define INTEL_FAM6_ATOM_DENVERTON	0x5F /* Goldmont Microserver */
<span class="p_add">+#define INTEL_FAM6_ATOM_GEMINI_LAKE	0x7A</span>
 
 /* Xeon Phi */
 
<span class="p_header">diff --git a/arch/x86/include/asm/intel_rdt.h b/arch/x86/include/asm/intel_rdt.h</span>
<span class="p_header">index 0d64397cee58..597dc4995678 100644</span>
<span class="p_header">--- a/arch/x86/include/asm/intel_rdt.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/intel_rdt.h</span>
<span class="p_chunk">@@ -12,6 +12,7 @@</span> <span class="p_context"></span>
 #define IA32_L3_QOS_CFG		0xc81
 #define IA32_L3_CBM_BASE	0xc90
 #define IA32_L2_CBM_BASE	0xd10
<span class="p_add">+#define IA32_MBA_THRTL_BASE	0xd50</span>
 
 #define L3_QOS_CDP_ENABLE	0x01ULL
 
<span class="p_chunk">@@ -37,23 +38,30 @@</span> <span class="p_context"> struct rdtgroup {</span>
 /* rdtgroup.flags */
 #define	RDT_DELETED		1
 
<span class="p_add">+/* rftype.flags */</span>
<span class="p_add">+#define RFTYPE_FLAGS_CPUS_LIST	1</span>
<span class="p_add">+</span>
 /* List of all resource groups */
 extern struct list_head rdt_all_groups;
 
<span class="p_add">+extern int max_name_width, max_data_width;</span>
<span class="p_add">+</span>
 int __init rdtgroup_init(void);
 
 /**
  * struct rftype - describe each file in the resctrl file system
<span class="p_del">- * @name: file name</span>
<span class="p_del">- * @mode: access mode</span>
<span class="p_del">- * @kf_ops: operations</span>
<span class="p_del">- * @seq_show: show content of the file</span>
<span class="p_del">- * @write: write to the file</span>
<span class="p_add">+ * @name:	File name</span>
<span class="p_add">+ * @mode:	Access mode</span>
<span class="p_add">+ * @kf_ops:	File operations</span>
<span class="p_add">+ * @flags:	File specific RFTYPE_FLAGS_* flags</span>
<span class="p_add">+ * @seq_show:	Show content of the file</span>
<span class="p_add">+ * @write:	Write to the file</span>
  */
 struct rftype {
 	char			*name;
 	umode_t			mode;
 	struct kernfs_ops	*kf_ops;
<span class="p_add">+	unsigned long		flags;</span>
 
 	int (*seq_show)(struct kernfs_open_file *of,
 			struct seq_file *sf, void *v);
<span class="p_chunk">@@ -67,54 +75,21 @@</span> <span class="p_context"> struct rftype {</span>
 };
 
 /**
<span class="p_del">- * struct rdt_resource - attributes of an RDT resource</span>
<span class="p_del">- * @enabled:			Is this feature enabled on this machine</span>
<span class="p_del">- * @capable:			Is this feature available on this machine</span>
<span class="p_del">- * @name:			Name to use in &quot;schemata&quot; file</span>
<span class="p_del">- * @num_closid:			Number of CLOSIDs available</span>
<span class="p_del">- * @max_cbm:			Largest Cache Bit Mask allowed</span>
<span class="p_del">- * @min_cbm_bits:		Minimum number of consecutive bits to be set</span>
<span class="p_del">- *				in a cache bit mask</span>
<span class="p_del">- * @domains:			All domains for this resource</span>
<span class="p_del">- * @num_domains:		Number of domains active</span>
<span class="p_del">- * @msr_base:			Base MSR address for CBMs</span>
<span class="p_del">- * @tmp_cbms:			Scratch space when updating schemata</span>
<span class="p_del">- * @num_tmp_cbms:		Number of CBMs in tmp_cbms</span>
<span class="p_del">- * @cache_level:		Which cache level defines scope of this domain</span>
<span class="p_del">- * @cbm_idx_multi:		Multiplier of CBM index</span>
<span class="p_del">- * @cbm_idx_offset:		Offset of CBM index. CBM index is computed by:</span>
<span class="p_del">- *				closid * cbm_idx_multi + cbm_idx_offset</span>
<span class="p_del">- */</span>
<span class="p_del">-struct rdt_resource {</span>
<span class="p_del">-	bool			enabled;</span>
<span class="p_del">-	bool			capable;</span>
<span class="p_del">-	char			*name;</span>
<span class="p_del">-	int			num_closid;</span>
<span class="p_del">-	int			cbm_len;</span>
<span class="p_del">-	int			min_cbm_bits;</span>
<span class="p_del">-	u32			max_cbm;</span>
<span class="p_del">-	struct list_head	domains;</span>
<span class="p_del">-	int			num_domains;</span>
<span class="p_del">-	int			msr_base;</span>
<span class="p_del">-	u32			*tmp_cbms;</span>
<span class="p_del">-	int			num_tmp_cbms;</span>
<span class="p_del">-	int			cache_level;</span>
<span class="p_del">-	int			cbm_idx_multi;</span>
<span class="p_del">-	int			cbm_idx_offset;</span>
<span class="p_del">-};</span>
<span class="p_del">-</span>
<span class="p_del">-/**</span>
  * struct rdt_domain - group of cpus sharing an RDT resource
  * @list:	all instances of this resource
  * @id:		unique id for this instance
  * @cpu_mask:	which cpus share this resource
<span class="p_del">- * @cbm:	array of cache bit masks (indexed by CLOSID)</span>
<span class="p_add">+ * @ctrl_val:	array of cache or mem ctrl values (indexed by CLOSID)</span>
<span class="p_add">+ * @new_ctrl:	new ctrl value to be loaded</span>
<span class="p_add">+ * @have_new_ctrl: did user provide new_ctrl for this domain</span>
  */
 struct rdt_domain {
 	struct list_head	list;
 	int			id;
 	struct cpumask		cpu_mask;
<span class="p_del">-	u32			*cbm;</span>
<span class="p_add">+	u32			*ctrl_val;</span>
<span class="p_add">+	u32			new_ctrl;</span>
<span class="p_add">+	bool			have_new_ctrl;</span>
 };
 
 /**
<span class="p_chunk">@@ -129,6 +104,83 @@</span> <span class="p_context"> struct msr_param {</span>
 	int			high;
 };
 
<span class="p_add">+/**</span>
<span class="p_add">+ * struct rdt_cache - Cache allocation related data</span>
<span class="p_add">+ * @cbm_len:		Length of the cache bit mask</span>
<span class="p_add">+ * @min_cbm_bits:	Minimum number of consecutive bits to be set</span>
<span class="p_add">+ * @cbm_idx_mult:	Multiplier of CBM index</span>
<span class="p_add">+ * @cbm_idx_offset:	Offset of CBM index. CBM index is computed by:</span>
<span class="p_add">+ *			closid * cbm_idx_multi + cbm_idx_offset</span>
<span class="p_add">+ *			in a cache bit mask</span>
<span class="p_add">+ */</span>
<span class="p_add">+struct rdt_cache {</span>
<span class="p_add">+	unsigned int	cbm_len;</span>
<span class="p_add">+	unsigned int	min_cbm_bits;</span>
<span class="p_add">+	unsigned int	cbm_idx_mult;</span>
<span class="p_add">+	unsigned int	cbm_idx_offset;</span>
<span class="p_add">+};</span>
<span class="p_add">+</span>
<span class="p_add">+/**</span>
<span class="p_add">+ * struct rdt_membw - Memory bandwidth allocation related data</span>
<span class="p_add">+ * @max_delay:		Max throttle delay. Delay is the hardware</span>
<span class="p_add">+ *			representation for memory bandwidth.</span>
<span class="p_add">+ * @min_bw:		Minimum memory bandwidth percentage user can request</span>
<span class="p_add">+ * @bw_gran:		Granularity at which the memory bandwidth is allocated</span>
<span class="p_add">+ * @delay_linear:	True if memory B/W delay is in linear scale</span>
<span class="p_add">+ * @mb_map:		Mapping of memory B/W percentage to memory B/W delay</span>
<span class="p_add">+ */</span>
<span class="p_add">+struct rdt_membw {</span>
<span class="p_add">+	u32		max_delay;</span>
<span class="p_add">+	u32		min_bw;</span>
<span class="p_add">+	u32		bw_gran;</span>
<span class="p_add">+	u32		delay_linear;</span>
<span class="p_add">+	u32		*mb_map;</span>
<span class="p_add">+};</span>
<span class="p_add">+</span>
<span class="p_add">+/**</span>
<span class="p_add">+ * struct rdt_resource - attributes of an RDT resource</span>
<span class="p_add">+ * @enabled:		Is this feature enabled on this machine</span>
<span class="p_add">+ * @capable:		Is this feature available on this machine</span>
<span class="p_add">+ * @name:		Name to use in &quot;schemata&quot; file</span>
<span class="p_add">+ * @num_closid:		Number of CLOSIDs available</span>
<span class="p_add">+ * @cache_level:	Which cache level defines scope of this resource</span>
<span class="p_add">+ * @default_ctrl:	Specifies default cache cbm or memory B/W percent.</span>
<span class="p_add">+ * @msr_base:		Base MSR address for CBMs</span>
<span class="p_add">+ * @msr_update:		Function pointer to update QOS MSRs</span>
<span class="p_add">+ * @data_width:		Character width of data when displaying</span>
<span class="p_add">+ * @domains:		All domains for this resource</span>
<span class="p_add">+ * @cache:		Cache allocation related data</span>
<span class="p_add">+ * @info_files:		resctrl info files for the resource</span>
<span class="p_add">+ * @nr_info_files:	Number of info files</span>
<span class="p_add">+ * @format_str:		Per resource format string to show domain value</span>
<span class="p_add">+ * @parse_ctrlval:	Per resource function pointer to parse control values</span>
<span class="p_add">+ */</span>
<span class="p_add">+struct rdt_resource {</span>
<span class="p_add">+	bool			enabled;</span>
<span class="p_add">+	bool			capable;</span>
<span class="p_add">+	char			*name;</span>
<span class="p_add">+	int			num_closid;</span>
<span class="p_add">+	int			cache_level;</span>
<span class="p_add">+	u32			default_ctrl;</span>
<span class="p_add">+	unsigned int		msr_base;</span>
<span class="p_add">+	void (*msr_update)	(struct rdt_domain *d, struct msr_param *m,</span>
<span class="p_add">+				 struct rdt_resource *r);</span>
<span class="p_add">+	int			data_width;</span>
<span class="p_add">+	struct list_head	domains;</span>
<span class="p_add">+	struct rdt_cache	cache;</span>
<span class="p_add">+	struct rdt_membw	membw;</span>
<span class="p_add">+	struct rftype		*info_files;</span>
<span class="p_add">+	int			nr_info_files;</span>
<span class="p_add">+	const char		*format_str;</span>
<span class="p_add">+	int (*parse_ctrlval)	(char *buf, struct rdt_resource *r,</span>
<span class="p_add">+				 struct rdt_domain *d);</span>
<span class="p_add">+};</span>
<span class="p_add">+</span>
<span class="p_add">+void rdt_get_cache_infofile(struct rdt_resource *r);</span>
<span class="p_add">+void rdt_get_mba_infofile(struct rdt_resource *r);</span>
<span class="p_add">+int parse_cbm(char *buf, struct rdt_resource *r, struct rdt_domain *d);</span>
<span class="p_add">+int parse_bw(char *buf, struct rdt_resource *r,  struct rdt_domain *d);</span>
<span class="p_add">+</span>
 extern struct mutex rdtgroup_mutex;
 
 extern struct rdt_resource rdt_resources_all[];
<span class="p_chunk">@@ -142,6 +194,7 @@</span> <span class="p_context"> enum {</span>
 	RDT_RESOURCE_L3DATA,
 	RDT_RESOURCE_L3CODE,
 	RDT_RESOURCE_L2,
<span class="p_add">+	RDT_RESOURCE_MBA,</span>
 
 	/* Must be the last */
 	RDT_NUM_RESOURCES,
<span class="p_chunk">@@ -149,7 +202,7 @@</span> <span class="p_context"> enum {</span>
 
 #define for_each_capable_rdt_resource(r)				      \
 	for (r = rdt_resources_all; r &lt; rdt_resources_all + RDT_NUM_RESOURCES;\
<span class="p_del">-	     r++) 							      \</span>
<span class="p_add">+	     r++)							      \</span>
 		if (r-&gt;capable)
 
 #define for_each_enabled_rdt_resource(r)				      \
<span class="p_chunk">@@ -165,8 +218,16 @@</span> <span class="p_context"> union cpuid_0x10_1_eax {</span>
 	unsigned int full;
 };
 
<span class="p_del">-/* CPUID.(EAX=10H, ECX=ResID=1).EDX */</span>
<span class="p_del">-union cpuid_0x10_1_edx {</span>
<span class="p_add">+/* CPUID.(EAX=10H, ECX=ResID=3).EAX */</span>
<span class="p_add">+union cpuid_0x10_3_eax {</span>
<span class="p_add">+	struct {</span>
<span class="p_add">+		unsigned int max_delay:12;</span>
<span class="p_add">+	} split;</span>
<span class="p_add">+	unsigned int full;</span>
<span class="p_add">+};</span>
<span class="p_add">+</span>
<span class="p_add">+/* CPUID.(EAX=10H, ECX=ResID).EDX */</span>
<span class="p_add">+union cpuid_0x10_x_edx {</span>
 	struct {
 		unsigned int cos_max:16;
 	} split;
<span class="p_chunk">@@ -175,7 +236,7 @@</span> <span class="p_context"> union cpuid_0x10_1_edx {</span>
 
 DECLARE_PER_CPU_READ_MOSTLY(int, cpu_closid);
 
<span class="p_del">-void rdt_cbm_update(void *arg);</span>
<span class="p_add">+void rdt_ctrl_update(void *arg);</span>
 struct rdtgroup *rdtgroup_kn_lock_live(struct kernfs_node *kn);
 void rdtgroup_kn_unlock(struct kernfs_node *kn);
 ssize_t rdtgroup_schemata_write(struct kernfs_open_file *of,
<span class="p_header">diff --git a/arch/x86/include/asm/processor.h b/arch/x86/include/asm/processor.h</span>
<span class="p_header">index f385eca5407a..4aa93b560a2b 100644</span>
<span class="p_header">--- a/arch/x86/include/asm/processor.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/processor.h</span>
<span class="p_chunk">@@ -80,7 +80,7 @@</span> <span class="p_context"> extern u16 __read_mostly tlb_lld_1g[NR_INFO];</span>
 
 /*
  *  CPU type and hardware bug flags. Kept separately for each CPU.
<span class="p_del">- *  Members of this structure are referenced in head.S, so think twice</span>
<span class="p_add">+ *  Members of this structure are referenced in head_32.S, so think twice</span>
  *  before touching them. [mj]
  */
 
<span class="p_chunk">@@ -89,14 +89,7 @@</span> <span class="p_context"> struct cpuinfo_x86 {</span>
 	__u8			x86_vendor;	/* CPU vendor */
 	__u8			x86_model;
 	__u8			x86_mask;
<span class="p_del">-#ifdef CONFIG_X86_32</span>
<span class="p_del">-	char			wp_works_ok;	/* It doesn&#39;t on 386&#39;s */</span>
<span class="p_del">-</span>
<span class="p_del">-	/* Problems on some 486Dx4&#39;s and old 386&#39;s: */</span>
<span class="p_del">-	char			rfu;</span>
<span class="p_del">-	char			pad0;</span>
<span class="p_del">-	char			pad1;</span>
<span class="p_del">-#else</span>
<span class="p_add">+#ifdef CONFIG_X86_64</span>
 	/* Number of 4K pages in DTLB/ITLB combined(in pages): */
 	int			x86_tlbsize;
 #endif
<span class="p_header">diff --git a/arch/x86/kernel/cpu/intel_rdt.c b/arch/x86/kernel/cpu/intel_rdt.c</span>
<span class="p_header">index 5a533fefefa0..5b366462f579 100644</span>
<span class="p_header">--- a/arch/x86/kernel/cpu/intel_rdt.c</span>
<span class="p_header">+++ b/arch/x86/kernel/cpu/intel_rdt.c</span>
<span class="p_chunk">@@ -32,55 +32,98 @@</span> <span class="p_context"></span>
 #include &lt;asm/intel-family.h&gt;
 #include &lt;asm/intel_rdt.h&gt;
 
<span class="p_add">+#define MAX_MBA_BW	100u</span>
<span class="p_add">+#define MBA_IS_LINEAR	0x4</span>
<span class="p_add">+</span>
 /* Mutex to protect rdtgroup access. */
 DEFINE_MUTEX(rdtgroup_mutex);
 
 DEFINE_PER_CPU_READ_MOSTLY(int, cpu_closid);
 
<span class="p_add">+/*</span>
<span class="p_add">+ * Used to store the max resource name width and max resource data width</span>
<span class="p_add">+ * to display the schemata in a tabular format</span>
<span class="p_add">+ */</span>
<span class="p_add">+int max_name_width, max_data_width;</span>
<span class="p_add">+</span>
<span class="p_add">+static void</span>
<span class="p_add">+mba_wrmsr(struct rdt_domain *d, struct msr_param *m, struct rdt_resource *r);</span>
<span class="p_add">+static void</span>
<span class="p_add">+cat_wrmsr(struct rdt_domain *d, struct msr_param *m, struct rdt_resource *r);</span>
<span class="p_add">+</span>
 #define domain_init(id) LIST_HEAD_INIT(rdt_resources_all[id].domains)
 
 struct rdt_resource rdt_resources_all[] = {
 	{
<span class="p_del">-		.name		= &quot;L3&quot;,</span>
<span class="p_del">-		.domains	= domain_init(RDT_RESOURCE_L3),</span>
<span class="p_del">-		.msr_base	= IA32_L3_CBM_BASE,</span>
<span class="p_del">-		.min_cbm_bits	= 1,</span>
<span class="p_del">-		.cache_level	= 3,</span>
<span class="p_del">-		.cbm_idx_multi	= 1,</span>
<span class="p_del">-		.cbm_idx_offset	= 0</span>
<span class="p_add">+		.name			= &quot;L3&quot;,</span>
<span class="p_add">+		.domains		= domain_init(RDT_RESOURCE_L3),</span>
<span class="p_add">+		.msr_base		= IA32_L3_CBM_BASE,</span>
<span class="p_add">+		.msr_update		= cat_wrmsr,</span>
<span class="p_add">+		.cache_level		= 3,</span>
<span class="p_add">+		.cache = {</span>
<span class="p_add">+			.min_cbm_bits	= 1,</span>
<span class="p_add">+			.cbm_idx_mult	= 1,</span>
<span class="p_add">+			.cbm_idx_offset	= 0,</span>
<span class="p_add">+		},</span>
<span class="p_add">+		.parse_ctrlval		= parse_cbm,</span>
<span class="p_add">+		.format_str		= &quot;%d=%0*x&quot;,</span>
<span class="p_add">+	},</span>
<span class="p_add">+	{</span>
<span class="p_add">+		.name			= &quot;L3DATA&quot;,</span>
<span class="p_add">+		.domains		= domain_init(RDT_RESOURCE_L3DATA),</span>
<span class="p_add">+		.msr_base		= IA32_L3_CBM_BASE,</span>
<span class="p_add">+		.msr_update		= cat_wrmsr,</span>
<span class="p_add">+		.cache_level		= 3,</span>
<span class="p_add">+		.cache = {</span>
<span class="p_add">+			.min_cbm_bits	= 1,</span>
<span class="p_add">+			.cbm_idx_mult	= 2,</span>
<span class="p_add">+			.cbm_idx_offset	= 0,</span>
<span class="p_add">+		},</span>
<span class="p_add">+		.parse_ctrlval		= parse_cbm,</span>
<span class="p_add">+		.format_str		= &quot;%d=%0*x&quot;,</span>
 	},
 	{
<span class="p_del">-		.name		= &quot;L3DATA&quot;,</span>
<span class="p_del">-		.domains	= domain_init(RDT_RESOURCE_L3DATA),</span>
<span class="p_del">-		.msr_base	= IA32_L3_CBM_BASE,</span>
<span class="p_del">-		.min_cbm_bits	= 1,</span>
<span class="p_del">-		.cache_level	= 3,</span>
<span class="p_del">-		.cbm_idx_multi	= 2,</span>
<span class="p_del">-		.cbm_idx_offset	= 0</span>
<span class="p_add">+		.name			= &quot;L3CODE&quot;,</span>
<span class="p_add">+		.domains		= domain_init(RDT_RESOURCE_L3CODE),</span>
<span class="p_add">+		.msr_base		= IA32_L3_CBM_BASE,</span>
<span class="p_add">+		.msr_update		= cat_wrmsr,</span>
<span class="p_add">+		.cache_level		= 3,</span>
<span class="p_add">+		.cache = {</span>
<span class="p_add">+			.min_cbm_bits	= 1,</span>
<span class="p_add">+			.cbm_idx_mult	= 2,</span>
<span class="p_add">+			.cbm_idx_offset	= 1,</span>
<span class="p_add">+		},</span>
<span class="p_add">+		.parse_ctrlval		= parse_cbm,</span>
<span class="p_add">+		.format_str		= &quot;%d=%0*x&quot;,</span>
 	},
 	{
<span class="p_del">-		.name		= &quot;L3CODE&quot;,</span>
<span class="p_del">-		.domains	= domain_init(RDT_RESOURCE_L3CODE),</span>
<span class="p_del">-		.msr_base	= IA32_L3_CBM_BASE,</span>
<span class="p_del">-		.min_cbm_bits	= 1,</span>
<span class="p_del">-		.cache_level	= 3,</span>
<span class="p_del">-		.cbm_idx_multi	= 2,</span>
<span class="p_del">-		.cbm_idx_offset	= 1</span>
<span class="p_add">+		.name			= &quot;L2&quot;,</span>
<span class="p_add">+		.domains		= domain_init(RDT_RESOURCE_L2),</span>
<span class="p_add">+		.msr_base		= IA32_L2_CBM_BASE,</span>
<span class="p_add">+		.msr_update		= cat_wrmsr,</span>
<span class="p_add">+		.cache_level		= 2,</span>
<span class="p_add">+		.cache = {</span>
<span class="p_add">+			.min_cbm_bits	= 1,</span>
<span class="p_add">+			.cbm_idx_mult	= 1,</span>
<span class="p_add">+			.cbm_idx_offset	= 0,</span>
<span class="p_add">+		},</span>
<span class="p_add">+		.parse_ctrlval		= parse_cbm,</span>
<span class="p_add">+		.format_str		= &quot;%d=%0*x&quot;,</span>
 	},
 	{
<span class="p_del">-		.name		= &quot;L2&quot;,</span>
<span class="p_del">-		.domains	= domain_init(RDT_RESOURCE_L2),</span>
<span class="p_del">-		.msr_base	= IA32_L2_CBM_BASE,</span>
<span class="p_del">-		.min_cbm_bits	= 1,</span>
<span class="p_del">-		.cache_level	= 2,</span>
<span class="p_del">-		.cbm_idx_multi	= 1,</span>
<span class="p_del">-		.cbm_idx_offset	= 0</span>
<span class="p_add">+		.name			= &quot;MB&quot;,</span>
<span class="p_add">+		.domains		= domain_init(RDT_RESOURCE_MBA),</span>
<span class="p_add">+		.msr_base		= IA32_MBA_THRTL_BASE,</span>
<span class="p_add">+		.msr_update		= mba_wrmsr,</span>
<span class="p_add">+		.cache_level		= 3,</span>
<span class="p_add">+		.parse_ctrlval		= parse_bw,</span>
<span class="p_add">+		.format_str		= &quot;%d=%*d&quot;,</span>
 	},
 };
 
<span class="p_del">-static int cbm_idx(struct rdt_resource *r, int closid)</span>
<span class="p_add">+static unsigned int cbm_idx(struct rdt_resource *r, unsigned int closid)</span>
 {
<span class="p_del">-	return closid * r-&gt;cbm_idx_multi + r-&gt;cbm_idx_offset;</span>
<span class="p_add">+	return closid * r-&gt;cache.cbm_idx_mult + r-&gt;cache.cbm_idx_offset;</span>
 }
 
 /*
<span class="p_chunk">@@ -118,9 +161,9 @@</span> <span class="p_context"> static inline bool cache_alloc_hsw_probe(void)</span>
 			return false;
 
 		r-&gt;num_closid = 4;
<span class="p_del">-		r-&gt;cbm_len = 20;</span>
<span class="p_del">-		r-&gt;max_cbm = max_cbm;</span>
<span class="p_del">-		r-&gt;min_cbm_bits = 2;</span>
<span class="p_add">+		r-&gt;default_ctrl = max_cbm;</span>
<span class="p_add">+		r-&gt;cache.cbm_len = 20;</span>
<span class="p_add">+		r-&gt;cache.min_cbm_bits = 2;</span>
 		r-&gt;capable = true;
 		r-&gt;enabled = true;
 
<span class="p_chunk">@@ -130,16 +173,66 @@</span> <span class="p_context"> static inline bool cache_alloc_hsw_probe(void)</span>
 	return false;
 }
 
<span class="p_del">-static void rdt_get_config(int idx, struct rdt_resource *r)</span>
<span class="p_add">+/*</span>
<span class="p_add">+ * rdt_get_mb_table() - get a mapping of bandwidth(b/w) percentage values</span>
<span class="p_add">+ * exposed to user interface and the h/w understandable delay values.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * The non-linear delay values have the granularity of power of two</span>
<span class="p_add">+ * and also the h/w does not guarantee a curve for configured delay</span>
<span class="p_add">+ * values vs. actual b/w enforced.</span>
<span class="p_add">+ * Hence we need a mapping that is pre calibrated so the user can</span>
<span class="p_add">+ * express the memory b/w as a percentage value.</span>
<span class="p_add">+ */</span>
<span class="p_add">+static inline bool rdt_get_mb_table(struct rdt_resource *r)</span>
<span class="p_add">+{</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * There are no Intel SKUs as of now to support non-linear delay.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	pr_info(&quot;MBA b/w map not implemented for cpu:%d, model:%d&quot;,</span>
<span class="p_add">+		boot_cpu_data.x86, boot_cpu_data.x86_model);</span>
<span class="p_add">+</span>
<span class="p_add">+	return false;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static bool rdt_get_mem_config(struct rdt_resource *r)</span>
<span class="p_add">+{</span>
<span class="p_add">+	union cpuid_0x10_3_eax eax;</span>
<span class="p_add">+	union cpuid_0x10_x_edx edx;</span>
<span class="p_add">+	u32 ebx, ecx;</span>
<span class="p_add">+</span>
<span class="p_add">+	cpuid_count(0x00000010, 3, &amp;eax.full, &amp;ebx, &amp;ecx, &amp;edx.full);</span>
<span class="p_add">+	r-&gt;num_closid = edx.split.cos_max + 1;</span>
<span class="p_add">+	r-&gt;membw.max_delay = eax.split.max_delay + 1;</span>
<span class="p_add">+	r-&gt;default_ctrl = MAX_MBA_BW;</span>
<span class="p_add">+	if (ecx &amp; MBA_IS_LINEAR) {</span>
<span class="p_add">+		r-&gt;membw.delay_linear = true;</span>
<span class="p_add">+		r-&gt;membw.min_bw = MAX_MBA_BW - r-&gt;membw.max_delay;</span>
<span class="p_add">+		r-&gt;membw.bw_gran = MAX_MBA_BW - r-&gt;membw.max_delay;</span>
<span class="p_add">+	} else {</span>
<span class="p_add">+		if (!rdt_get_mb_table(r))</span>
<span class="p_add">+			return false;</span>
<span class="p_add">+	}</span>
<span class="p_add">+	r-&gt;data_width = 3;</span>
<span class="p_add">+	rdt_get_mba_infofile(r);</span>
<span class="p_add">+</span>
<span class="p_add">+	r-&gt;capable = true;</span>
<span class="p_add">+	r-&gt;enabled = true;</span>
<span class="p_add">+</span>
<span class="p_add">+	return true;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static void rdt_get_cache_config(int idx, struct rdt_resource *r)</span>
 {
 	union cpuid_0x10_1_eax eax;
<span class="p_del">-	union cpuid_0x10_1_edx edx;</span>
<span class="p_add">+	union cpuid_0x10_x_edx edx;</span>
 	u32 ebx, ecx;
 
 	cpuid_count(0x00000010, idx, &amp;eax.full, &amp;ebx, &amp;ecx, &amp;edx.full);
 	r-&gt;num_closid = edx.split.cos_max + 1;
<span class="p_del">-	r-&gt;cbm_len = eax.split.cbm_len + 1;</span>
<span class="p_del">-	r-&gt;max_cbm = BIT_MASK(eax.split.cbm_len + 1) - 1;</span>
<span class="p_add">+	r-&gt;cache.cbm_len = eax.split.cbm_len + 1;</span>
<span class="p_add">+	r-&gt;default_ctrl = BIT_MASK(eax.split.cbm_len + 1) - 1;</span>
<span class="p_add">+	r-&gt;data_width = (r-&gt;cache.cbm_len + 3) / 4;</span>
<span class="p_add">+	rdt_get_cache_infofile(r);</span>
 	r-&gt;capable = true;
 	r-&gt;enabled = true;
 }
<span class="p_chunk">@@ -150,8 +243,9 @@</span> <span class="p_context"> static void rdt_get_cdp_l3_config(int type)</span>
 	struct rdt_resource *r = &amp;rdt_resources_all[type];
 
 	r-&gt;num_closid = r_l3-&gt;num_closid / 2;
<span class="p_del">-	r-&gt;cbm_len = r_l3-&gt;cbm_len;</span>
<span class="p_del">-	r-&gt;max_cbm = r_l3-&gt;max_cbm;</span>
<span class="p_add">+	r-&gt;cache.cbm_len = r_l3-&gt;cache.cbm_len;</span>
<span class="p_add">+	r-&gt;default_ctrl = r_l3-&gt;default_ctrl;</span>
<span class="p_add">+	r-&gt;data_width = (r-&gt;cache.cbm_len + 3) / 4;</span>
 	r-&gt;capable = true;
 	/*
 	 * By default, CDP is disabled. CDP can be enabled by mount parameter
<span class="p_chunk">@@ -160,33 +254,6 @@</span> <span class="p_context"> static void rdt_get_cdp_l3_config(int type)</span>
 	r-&gt;enabled = false;
 }
 
<span class="p_del">-static inline bool get_rdt_resources(void)</span>
<span class="p_del">-{</span>
<span class="p_del">-	bool ret = false;</span>
<span class="p_del">-</span>
<span class="p_del">-	if (cache_alloc_hsw_probe())</span>
<span class="p_del">-		return true;</span>
<span class="p_del">-</span>
<span class="p_del">-	if (!boot_cpu_has(X86_FEATURE_RDT_A))</span>
<span class="p_del">-		return false;</span>
<span class="p_del">-</span>
<span class="p_del">-	if (boot_cpu_has(X86_FEATURE_CAT_L3)) {</span>
<span class="p_del">-		rdt_get_config(1, &amp;rdt_resources_all[RDT_RESOURCE_L3]);</span>
<span class="p_del">-		if (boot_cpu_has(X86_FEATURE_CDP_L3)) {</span>
<span class="p_del">-			rdt_get_cdp_l3_config(RDT_RESOURCE_L3DATA);</span>
<span class="p_del">-			rdt_get_cdp_l3_config(RDT_RESOURCE_L3CODE);</span>
<span class="p_del">-		}</span>
<span class="p_del">-		ret = true;</span>
<span class="p_del">-	}</span>
<span class="p_del">-	if (boot_cpu_has(X86_FEATURE_CAT_L2)) {</span>
<span class="p_del">-		/* CPUID 0x10.2 fields are same format at 0x10.1 */</span>
<span class="p_del">-		rdt_get_config(2, &amp;rdt_resources_all[RDT_RESOURCE_L2]);</span>
<span class="p_del">-		ret = true;</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">-	return ret;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
 static int get_cache_id(int cpu, int level)
 {
 	struct cpu_cacheinfo *ci = get_cpu_cacheinfo(cpu);
<span class="p_chunk">@@ -200,29 +267,55 @@</span> <span class="p_context"> static int get_cache_id(int cpu, int level)</span>
 	return -1;
 }
 
<span class="p_del">-void rdt_cbm_update(void *arg)</span>
<span class="p_add">+/*</span>
<span class="p_add">+ * Map the memory b/w percentage value to delay values</span>
<span class="p_add">+ * that can be written to QOS_MSRs.</span>
<span class="p_add">+ * There are currently no SKUs which support non linear delay values.</span>
<span class="p_add">+ */</span>
<span class="p_add">+static u32 delay_bw_map(unsigned long bw, struct rdt_resource *r)</span>
 {
<span class="p_del">-	struct msr_param *m = (struct msr_param *)arg;</span>
<span class="p_add">+	if (r-&gt;membw.delay_linear)</span>
<span class="p_add">+		return MAX_MBA_BW - bw;</span>
<span class="p_add">+</span>
<span class="p_add">+	pr_warn_once(&quot;Non Linear delay-bw map not supported but queried\n&quot;);</span>
<span class="p_add">+	return r-&gt;default_ctrl;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static void</span>
<span class="p_add">+mba_wrmsr(struct rdt_domain *d, struct msr_param *m, struct rdt_resource *r)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned int i;</span>
<span class="p_add">+</span>
<span class="p_add">+	/*  Write the delay values for mba. */</span>
<span class="p_add">+	for (i = m-&gt;low; i &lt; m-&gt;high; i++)</span>
<span class="p_add">+		wrmsrl(r-&gt;msr_base + i, delay_bw_map(d-&gt;ctrl_val[i], r));</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static void</span>
<span class="p_add">+cat_wrmsr(struct rdt_domain *d, struct msr_param *m, struct rdt_resource *r)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned int i;</span>
<span class="p_add">+</span>
<span class="p_add">+	for (i = m-&gt;low; i &lt; m-&gt;high; i++)</span>
<span class="p_add">+		wrmsrl(r-&gt;msr_base + cbm_idx(r, i), d-&gt;ctrl_val[i]);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void rdt_ctrl_update(void *arg)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct msr_param *m = arg;</span>
 	struct rdt_resource *r = m-&gt;res;
<span class="p_del">-	int i, cpu = smp_processor_id();</span>
<span class="p_add">+	int cpu = smp_processor_id();</span>
 	struct rdt_domain *d;
 
 	list_for_each_entry(d, &amp;r-&gt;domains, list) {
 		/* Find the domain that contains this CPU */
<span class="p_del">-		if (cpumask_test_cpu(cpu, &amp;d-&gt;cpu_mask))</span>
<span class="p_del">-			goto found;</span>
<span class="p_add">+		if (cpumask_test_cpu(cpu, &amp;d-&gt;cpu_mask)) {</span>
<span class="p_add">+			r-&gt;msr_update(d, m, r);</span>
<span class="p_add">+			return;</span>
<span class="p_add">+		}</span>
 	}
<span class="p_del">-	pr_info_once(&quot;cpu %d not found in any domain for resource %s\n&quot;,</span>
<span class="p_add">+	pr_warn_once(&quot;cpu %d not found in any domain for resource %s\n&quot;,</span>
 		     cpu, r-&gt;name);
<span class="p_del">-</span>
<span class="p_del">-	return;</span>
<span class="p_del">-</span>
<span class="p_del">-found:</span>
<span class="p_del">-	for (i = m-&gt;low; i &lt; m-&gt;high; i++) {</span>
<span class="p_del">-		int idx = cbm_idx(r, i);</span>
<span class="p_del">-</span>
<span class="p_del">-		wrmsrl(r-&gt;msr_base + idx, d-&gt;cbm[i]);</span>
<span class="p_del">-	}</span>
 }
 
 /*
<span class="p_chunk">@@ -258,6 +351,32 @@</span> <span class="p_context"> static struct rdt_domain *rdt_find_domain(struct rdt_resource *r, int id,</span>
 	return NULL;
 }
 
<span class="p_add">+static int domain_setup_ctrlval(struct rdt_resource *r, struct rdt_domain *d)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct msr_param m;</span>
<span class="p_add">+	u32 *dc;</span>
<span class="p_add">+	int i;</span>
<span class="p_add">+</span>
<span class="p_add">+	dc = kmalloc_array(r-&gt;num_closid, sizeof(*d-&gt;ctrl_val), GFP_KERNEL);</span>
<span class="p_add">+	if (!dc)</span>
<span class="p_add">+		return -ENOMEM;</span>
<span class="p_add">+</span>
<span class="p_add">+	d-&gt;ctrl_val = dc;</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Initialize the Control MSRs to having no control.</span>
<span class="p_add">+	 * For Cache Allocation: Set all bits in cbm</span>
<span class="p_add">+	 * For Memory Allocation: Set b/w requested to 100</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	for (i = 0; i &lt; r-&gt;num_closid; i++, dc++)</span>
<span class="p_add">+		*dc = r-&gt;default_ctrl;</span>
<span class="p_add">+</span>
<span class="p_add">+	m.low = 0;</span>
<span class="p_add">+	m.high = r-&gt;num_closid;</span>
<span class="p_add">+	r-&gt;msr_update(d, &amp;m, r);</span>
<span class="p_add">+	return 0;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 /*
  * domain_add_cpu - Add a cpu to a resource&#39;s domain list.
  *
<span class="p_chunk">@@ -273,7 +392,7 @@</span> <span class="p_context"> static struct rdt_domain *rdt_find_domain(struct rdt_resource *r, int id,</span>
  */
 static void domain_add_cpu(int cpu, struct rdt_resource *r)
 {
<span class="p_del">-	int i, id = get_cache_id(cpu, r-&gt;cache_level);</span>
<span class="p_add">+	int id = get_cache_id(cpu, r-&gt;cache_level);</span>
 	struct list_head *add_pos = NULL;
 	struct rdt_domain *d;
 
<span class="p_chunk">@@ -294,22 +413,13 @@</span> <span class="p_context"> static void domain_add_cpu(int cpu, struct rdt_resource *r)</span>
 
 	d-&gt;id = id;
 
<span class="p_del">-	d-&gt;cbm = kmalloc_array(r-&gt;num_closid, sizeof(*d-&gt;cbm), GFP_KERNEL);</span>
<span class="p_del">-	if (!d-&gt;cbm) {</span>
<span class="p_add">+	if (domain_setup_ctrlval(r, d)) {</span>
 		kfree(d);
 		return;
 	}
 
<span class="p_del">-	for (i = 0; i &lt; r-&gt;num_closid; i++) {</span>
<span class="p_del">-		int idx = cbm_idx(r, i);</span>
<span class="p_del">-</span>
<span class="p_del">-		d-&gt;cbm[i] = r-&gt;max_cbm;</span>
<span class="p_del">-		wrmsrl(r-&gt;msr_base + idx, d-&gt;cbm[i]);</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
 	cpumask_set_cpu(cpu, &amp;d-&gt;cpu_mask);
 	list_add_tail(&amp;d-&gt;list, add_pos);
<span class="p_del">-	r-&gt;num_domains++;</span>
 }
 
 static void domain_remove_cpu(int cpu, struct rdt_resource *r)
<span class="p_chunk">@@ -325,8 +435,7 @@</span> <span class="p_context"> static void domain_remove_cpu(int cpu, struct rdt_resource *r)</span>
 
 	cpumask_clear_cpu(cpu, &amp;d-&gt;cpu_mask);
 	if (cpumask_empty(&amp;d-&gt;cpu_mask)) {
<span class="p_del">-		r-&gt;num_domains--;</span>
<span class="p_del">-		kfree(d-&gt;cbm);</span>
<span class="p_add">+		kfree(d-&gt;ctrl_val);</span>
 		list_del(&amp;d-&gt;list);
 		kfree(d);
 	}
<span class="p_chunk">@@ -374,6 +483,57 @@</span> <span class="p_context"> static int intel_rdt_offline_cpu(unsigned int cpu)</span>
 	return 0;
 }
 
<span class="p_add">+/*</span>
<span class="p_add">+ * Choose a width for the resource name and resource data based on the</span>
<span class="p_add">+ * resource that has widest name and cbm.</span>
<span class="p_add">+ */</span>
<span class="p_add">+static __init void rdt_init_padding(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct rdt_resource *r;</span>
<span class="p_add">+	int cl;</span>
<span class="p_add">+</span>
<span class="p_add">+	for_each_capable_rdt_resource(r) {</span>
<span class="p_add">+		cl = strlen(r-&gt;name);</span>
<span class="p_add">+		if (cl &gt; max_name_width)</span>
<span class="p_add">+			max_name_width = cl;</span>
<span class="p_add">+</span>
<span class="p_add">+		if (r-&gt;data_width &gt; max_data_width)</span>
<span class="p_add">+			max_data_width = r-&gt;data_width;</span>
<span class="p_add">+	}</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static __init bool get_rdt_resources(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	bool ret = false;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (cache_alloc_hsw_probe())</span>
<span class="p_add">+		return true;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (!boot_cpu_has(X86_FEATURE_RDT_A))</span>
<span class="p_add">+		return false;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (boot_cpu_has(X86_FEATURE_CAT_L3)) {</span>
<span class="p_add">+		rdt_get_cache_config(1, &amp;rdt_resources_all[RDT_RESOURCE_L3]);</span>
<span class="p_add">+		if (boot_cpu_has(X86_FEATURE_CDP_L3)) {</span>
<span class="p_add">+			rdt_get_cdp_l3_config(RDT_RESOURCE_L3DATA);</span>
<span class="p_add">+			rdt_get_cdp_l3_config(RDT_RESOURCE_L3CODE);</span>
<span class="p_add">+		}</span>
<span class="p_add">+		ret = true;</span>
<span class="p_add">+	}</span>
<span class="p_add">+	if (boot_cpu_has(X86_FEATURE_CAT_L2)) {</span>
<span class="p_add">+		/* CPUID 0x10.2 fields are same format at 0x10.1 */</span>
<span class="p_add">+		rdt_get_cache_config(2, &amp;rdt_resources_all[RDT_RESOURCE_L2]);</span>
<span class="p_add">+		ret = true;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	if (boot_cpu_has(X86_FEATURE_MBA)) {</span>
<span class="p_add">+		if (rdt_get_mem_config(&amp;rdt_resources_all[RDT_RESOURCE_MBA]))</span>
<span class="p_add">+			ret = true;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	return ret;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static int __init intel_rdt_late_init(void)
 {
 	struct rdt_resource *r;
<span class="p_chunk">@@ -382,6 +542,8 @@</span> <span class="p_context"> static int __init intel_rdt_late_init(void)</span>
 	if (!get_rdt_resources())
 		return -ENODEV;
 
<span class="p_add">+	rdt_init_padding();</span>
<span class="p_add">+</span>
 	state = cpuhp_setup_state(CPUHP_AP_ONLINE_DYN,
 				  &quot;x86/rdt/cat:online:&quot;,
 				  intel_rdt_online_cpu, intel_rdt_offline_cpu);
<span class="p_header">diff --git a/arch/x86/kernel/cpu/intel_rdt_rdtgroup.c b/arch/x86/kernel/cpu/intel_rdt_rdtgroup.c</span>
<span class="p_header">index 9ac2a5cdd9c2..f5af0cc7eb0d 100644</span>
<span class="p_header">--- a/arch/x86/kernel/cpu/intel_rdt_rdtgroup.c</span>
<span class="p_header">+++ b/arch/x86/kernel/cpu/intel_rdt_rdtgroup.c</span>
<span class="p_chunk">@@ -174,6 +174,13 @@</span> <span class="p_context"> static struct kernfs_ops rdtgroup_kf_single_ops = {</span>
 	.seq_show		= rdtgroup_seqfile_show,
 };
 
<span class="p_add">+static bool is_cpu_list(struct kernfs_open_file *of)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct rftype *rft = of-&gt;kn-&gt;priv;</span>
<span class="p_add">+</span>
<span class="p_add">+	return rft-&gt;flags &amp; RFTYPE_FLAGS_CPUS_LIST;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static int rdtgroup_cpus_show(struct kernfs_open_file *of,
 			      struct seq_file *s, void *v)
 {
<span class="p_chunk">@@ -182,10 +189,12 @@</span> <span class="p_context"> static int rdtgroup_cpus_show(struct kernfs_open_file *of,</span>
 
 	rdtgrp = rdtgroup_kn_lock_live(of-&gt;kn);
 
<span class="p_del">-	if (rdtgrp)</span>
<span class="p_del">-		seq_printf(s, &quot;%*pb\n&quot;, cpumask_pr_args(&amp;rdtgrp-&gt;cpu_mask));</span>
<span class="p_del">-	else</span>
<span class="p_add">+	if (rdtgrp) {</span>
<span class="p_add">+		seq_printf(s, is_cpu_list(of) ? &quot;%*pbl\n&quot; : &quot;%*pb\n&quot;,</span>
<span class="p_add">+			   cpumask_pr_args(&amp;rdtgrp-&gt;cpu_mask));</span>
<span class="p_add">+	} else {</span>
 		ret = -ENOENT;
<span class="p_add">+	}</span>
 	rdtgroup_kn_unlock(of-&gt;kn);
 
 	return ret;
<span class="p_chunk">@@ -252,7 +261,11 @@</span> <span class="p_context"> static ssize_t rdtgroup_cpus_write(struct kernfs_open_file *of,</span>
 		goto unlock;
 	}
 
<span class="p_del">-	ret = cpumask_parse(buf, newmask);</span>
<span class="p_add">+	if (is_cpu_list(of))</span>
<span class="p_add">+		ret = cpulist_parse(buf, newmask);</span>
<span class="p_add">+	else</span>
<span class="p_add">+		ret = cpumask_parse(buf, newmask);</span>
<span class="p_add">+</span>
 	if (ret)
 		goto unlock;
 
<span class="p_chunk">@@ -473,6 +486,14 @@</span> <span class="p_context"> static struct rftype rdtgroup_base_files[] = {</span>
 		.seq_show	= rdtgroup_cpus_show,
 	},
 	{
<span class="p_add">+		.name		= &quot;cpus_list&quot;,</span>
<span class="p_add">+		.mode		= 0644,</span>
<span class="p_add">+		.kf_ops		= &amp;rdtgroup_kf_single_ops,</span>
<span class="p_add">+		.write		= rdtgroup_cpus_write,</span>
<span class="p_add">+		.seq_show	= rdtgroup_cpus_show,</span>
<span class="p_add">+		.flags		= RFTYPE_FLAGS_CPUS_LIST,</span>
<span class="p_add">+	},</span>
<span class="p_add">+	{</span>
 		.name		= &quot;tasks&quot;,
 		.mode		= 0644,
 		.kf_ops		= &amp;rdtgroup_kf_single_ops,
<span class="p_chunk">@@ -494,32 +515,56 @@</span> <span class="p_context"> static int rdt_num_closids_show(struct kernfs_open_file *of,</span>
 	struct rdt_resource *r = of-&gt;kn-&gt;parent-&gt;priv;
 
 	seq_printf(seq, &quot;%d\n&quot;, r-&gt;num_closid);
<span class="p_add">+	return 0;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static int rdt_default_ctrl_show(struct kernfs_open_file *of,</span>
<span class="p_add">+			     struct seq_file *seq, void *v)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct rdt_resource *r = of-&gt;kn-&gt;parent-&gt;priv;</span>
 
<span class="p_add">+	seq_printf(seq, &quot;%x\n&quot;, r-&gt;default_ctrl);</span>
 	return 0;
 }
 
<span class="p_del">-static int rdt_cbm_mask_show(struct kernfs_open_file *of,</span>
<span class="p_add">+static int rdt_min_cbm_bits_show(struct kernfs_open_file *of,</span>
 			     struct seq_file *seq, void *v)
 {
 	struct rdt_resource *r = of-&gt;kn-&gt;parent-&gt;priv;
 
<span class="p_del">-	seq_printf(seq, &quot;%x\n&quot;, r-&gt;max_cbm);</span>
<span class="p_add">+	seq_printf(seq, &quot;%u\n&quot;, r-&gt;cache.min_cbm_bits);</span>
<span class="p_add">+	return 0;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static int rdt_min_bw_show(struct kernfs_open_file *of,</span>
<span class="p_add">+			     struct seq_file *seq, void *v)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct rdt_resource *r = of-&gt;kn-&gt;parent-&gt;priv;</span>
 
<span class="p_add">+	seq_printf(seq, &quot;%u\n&quot;, r-&gt;membw.min_bw);</span>
 	return 0;
 }
 
<span class="p_del">-static int rdt_min_cbm_bits_show(struct kernfs_open_file *of,</span>
<span class="p_add">+static int rdt_bw_gran_show(struct kernfs_open_file *of,</span>
 			     struct seq_file *seq, void *v)
 {
 	struct rdt_resource *r = of-&gt;kn-&gt;parent-&gt;priv;
 
<span class="p_del">-	seq_printf(seq, &quot;%d\n&quot;, r-&gt;min_cbm_bits);</span>
<span class="p_add">+	seq_printf(seq, &quot;%u\n&quot;, r-&gt;membw.bw_gran);</span>
<span class="p_add">+	return 0;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static int rdt_delay_linear_show(struct kernfs_open_file *of,</span>
<span class="p_add">+			     struct seq_file *seq, void *v)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct rdt_resource *r = of-&gt;kn-&gt;parent-&gt;priv;</span>
 
<span class="p_add">+	seq_printf(seq, &quot;%u\n&quot;, r-&gt;membw.delay_linear);</span>
 	return 0;
 }
 
 /* rdtgroup information files for one cache resource. */
<span class="p_del">-static struct rftype res_info_files[] = {</span>
<span class="p_add">+static struct rftype res_cache_info_files[] = {</span>
 	{
 		.name		= &quot;num_closids&quot;,
 		.mode		= 0444,
<span class="p_chunk">@@ -530,7 +575,7 @@</span> <span class="p_context"> static struct rftype res_info_files[] = {</span>
 		.name		= &quot;cbm_mask&quot;,
 		.mode		= 0444,
 		.kf_ops		= &amp;rdtgroup_kf_single_ops,
<span class="p_del">-		.seq_show	= rdt_cbm_mask_show,</span>
<span class="p_add">+		.seq_show	= rdt_default_ctrl_show,</span>
 	},
 	{
 		.name		= &quot;min_cbm_bits&quot;,
<span class="p_chunk">@@ -540,11 +585,52 @@</span> <span class="p_context"> static struct rftype res_info_files[] = {</span>
 	},
 };
 
<span class="p_add">+/* rdtgroup information files for memory bandwidth. */</span>
<span class="p_add">+static struct rftype res_mba_info_files[] = {</span>
<span class="p_add">+	{</span>
<span class="p_add">+		.name		= &quot;num_closids&quot;,</span>
<span class="p_add">+		.mode		= 0444,</span>
<span class="p_add">+		.kf_ops		= &amp;rdtgroup_kf_single_ops,</span>
<span class="p_add">+		.seq_show	= rdt_num_closids_show,</span>
<span class="p_add">+	},</span>
<span class="p_add">+	{</span>
<span class="p_add">+		.name		= &quot;min_bandwidth&quot;,</span>
<span class="p_add">+		.mode		= 0444,</span>
<span class="p_add">+		.kf_ops		= &amp;rdtgroup_kf_single_ops,</span>
<span class="p_add">+		.seq_show	= rdt_min_bw_show,</span>
<span class="p_add">+	},</span>
<span class="p_add">+	{</span>
<span class="p_add">+		.name		= &quot;bandwidth_gran&quot;,</span>
<span class="p_add">+		.mode		= 0444,</span>
<span class="p_add">+		.kf_ops		= &amp;rdtgroup_kf_single_ops,</span>
<span class="p_add">+		.seq_show	= rdt_bw_gran_show,</span>
<span class="p_add">+	},</span>
<span class="p_add">+	{</span>
<span class="p_add">+		.name		= &quot;delay_linear&quot;,</span>
<span class="p_add">+		.mode		= 0444,</span>
<span class="p_add">+		.kf_ops		= &amp;rdtgroup_kf_single_ops,</span>
<span class="p_add">+		.seq_show	= rdt_delay_linear_show,</span>
<span class="p_add">+	},</span>
<span class="p_add">+};</span>
<span class="p_add">+</span>
<span class="p_add">+void rdt_get_mba_infofile(struct rdt_resource *r)</span>
<span class="p_add">+{</span>
<span class="p_add">+	r-&gt;info_files = res_mba_info_files;</span>
<span class="p_add">+	r-&gt;nr_info_files = ARRAY_SIZE(res_mba_info_files);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void rdt_get_cache_infofile(struct rdt_resource *r)</span>
<span class="p_add">+{</span>
<span class="p_add">+	r-&gt;info_files = res_cache_info_files;</span>
<span class="p_add">+	r-&gt;nr_info_files = ARRAY_SIZE(res_cache_info_files);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static int rdtgroup_create_info_dir(struct kernfs_node *parent_kn)
 {
 	struct kernfs_node *kn_subdir;
<span class="p_add">+	struct rftype *res_info_files;</span>
 	struct rdt_resource *r;
<span class="p_del">-	int ret;</span>
<span class="p_add">+	int ret, len;</span>
 
 	/* create the directory */
 	kn_info = kernfs_create_dir(parent_kn, &quot;info&quot;, parent_kn-&gt;mode, NULL);
<span class="p_chunk">@@ -563,8 +649,11 @@</span> <span class="p_context"> static int rdtgroup_create_info_dir(struct kernfs_node *parent_kn)</span>
 		ret = rdtgroup_kn_set_ugid(kn_subdir);
 		if (ret)
 			goto out_destroy;
<span class="p_del">-		ret = rdtgroup_add_files(kn_subdir, res_info_files,</span>
<span class="p_del">-					 ARRAY_SIZE(res_info_files));</span>
<span class="p_add">+</span>
<span class="p_add">+		res_info_files = r-&gt;info_files;</span>
<span class="p_add">+		len = r-&gt;nr_info_files;</span>
<span class="p_add">+</span>
<span class="p_add">+		ret = rdtgroup_add_files(kn_subdir, res_info_files, len);</span>
 		if (ret)
 			goto out_destroy;
 		kernfs_activate(kn_subdir);
<span class="p_chunk">@@ -780,7 +869,7 @@</span> <span class="p_context"> static struct dentry *rdt_mount(struct file_system_type *fs_type,</span>
 	return dentry;
 }
 
<span class="p_del">-static int reset_all_cbms(struct rdt_resource *r)</span>
<span class="p_add">+static int reset_all_ctrls(struct rdt_resource *r)</span>
 {
 	struct msr_param msr_param;
 	cpumask_var_t cpu_mask;
<span class="p_chunk">@@ -803,14 +892,14 @@</span> <span class="p_context"> static int reset_all_cbms(struct rdt_resource *r)</span>
 		cpumask_set_cpu(cpumask_any(&amp;d-&gt;cpu_mask), cpu_mask);
 
 		for (i = 0; i &lt; r-&gt;num_closid; i++)
<span class="p_del">-			d-&gt;cbm[i] = r-&gt;max_cbm;</span>
<span class="p_add">+			d-&gt;ctrl_val[i] = r-&gt;default_ctrl;</span>
 	}
 	cpu = get_cpu();
 	/* Update CBM on this cpu if it&#39;s in cpu_mask. */
 	if (cpumask_test_cpu(cpu, cpu_mask))
<span class="p_del">-		rdt_cbm_update(&amp;msr_param);</span>
<span class="p_add">+		rdt_ctrl_update(&amp;msr_param);</span>
 	/* Update CBM on all other cpus in cpu_mask. */
<span class="p_del">-	smp_call_function_many(cpu_mask, rdt_cbm_update, &amp;msr_param, 1);</span>
<span class="p_add">+	smp_call_function_many(cpu_mask, rdt_ctrl_update, &amp;msr_param, 1);</span>
 	put_cpu();
 
 	free_cpumask_var(cpu_mask);
<span class="p_chunk">@@ -896,7 +985,7 @@</span> <span class="p_context"> static void rdt_kill_sb(struct super_block *sb)</span>
 
 	/*Put everything back to default values. */
 	for_each_enabled_rdt_resource(r)
<span class="p_del">-		reset_all_cbms(r);</span>
<span class="p_add">+		reset_all_ctrls(r);</span>
 	cdp_disable();
 	rmdir_all_sub();
 	static_branch_disable(&amp;rdt_enable_key);
<span class="p_header">diff --git a/arch/x86/kernel/cpu/intel_rdt_schemata.c b/arch/x86/kernel/cpu/intel_rdt_schemata.c</span>
<span class="p_header">index badd2b31a560..406d7a6532f9 100644</span>
<span class="p_header">--- a/arch/x86/kernel/cpu/intel_rdt_schemata.c</span>
<span class="p_header">+++ b/arch/x86/kernel/cpu/intel_rdt_schemata.c</span>
<span class="p_chunk">@@ -29,26 +29,77 @@</span> <span class="p_context"></span>
 #include &lt;asm/intel_rdt.h&gt;
 
 /*
<span class="p_add">+ * Check whether MBA bandwidth percentage value is correct. The value is</span>
<span class="p_add">+ * checked against the minimum and max bandwidth values specified by the</span>
<span class="p_add">+ * hardware. The allocated bandwidth percentage is rounded to the next</span>
<span class="p_add">+ * control step available on the hardware.</span>
<span class="p_add">+ */</span>
<span class="p_add">+static bool bw_validate(char *buf, unsigned long *data, struct rdt_resource *r)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long bw;</span>
<span class="p_add">+	int ret;</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Only linear delay values is supported for current Intel SKUs.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	if (!r-&gt;membw.delay_linear)</span>
<span class="p_add">+		return false;</span>
<span class="p_add">+</span>
<span class="p_add">+	ret = kstrtoul(buf, 10, &amp;bw);</span>
<span class="p_add">+	if (ret)</span>
<span class="p_add">+		return false;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (bw &lt; r-&gt;membw.min_bw || bw &gt; r-&gt;default_ctrl)</span>
<span class="p_add">+		return false;</span>
<span class="p_add">+</span>
<span class="p_add">+	*data = roundup(bw, (unsigned long)r-&gt;membw.bw_gran);</span>
<span class="p_add">+	return true;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+int parse_bw(char *buf, struct rdt_resource *r, struct rdt_domain *d)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long data;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (d-&gt;have_new_ctrl)</span>
<span class="p_add">+		return -EINVAL;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (!bw_validate(buf, &amp;data, r))</span>
<span class="p_add">+		return -EINVAL;</span>
<span class="p_add">+	d-&gt;new_ctrl = data;</span>
<span class="p_add">+	d-&gt;have_new_ctrl = true;</span>
<span class="p_add">+</span>
<span class="p_add">+	return 0;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+/*</span>
  * Check whether a cache bit mask is valid. The SDM says:
  *	Please note that all (and only) contiguous &#39;1&#39; combinations
  *	are allowed (e.g. FFFFH, 0FF0H, 003CH, etc.).
  * Additionally Haswell requires at least two bits set.
  */
<span class="p_del">-static bool cbm_validate(unsigned long var, struct rdt_resource *r)</span>
<span class="p_add">+static bool cbm_validate(char *buf, unsigned long *data, struct rdt_resource *r)</span>
 {
<span class="p_del">-	unsigned long first_bit, zero_bit;</span>
<span class="p_add">+	unsigned long first_bit, zero_bit, val;</span>
<span class="p_add">+	unsigned int cbm_len = r-&gt;cache.cbm_len;</span>
<span class="p_add">+	int ret;</span>
<span class="p_add">+</span>
<span class="p_add">+	ret = kstrtoul(buf, 16, &amp;val);</span>
<span class="p_add">+	if (ret)</span>
<span class="p_add">+		return false;</span>
 
<span class="p_del">-	if (var == 0 || var &gt; r-&gt;max_cbm)</span>
<span class="p_add">+	if (val == 0 || val &gt; r-&gt;default_ctrl)</span>
 		return false;
 
<span class="p_del">-	first_bit = find_first_bit(&amp;var, r-&gt;cbm_len);</span>
<span class="p_del">-	zero_bit = find_next_zero_bit(&amp;var, r-&gt;cbm_len, first_bit);</span>
<span class="p_add">+	first_bit = find_first_bit(&amp;val, cbm_len);</span>
<span class="p_add">+	zero_bit = find_next_zero_bit(&amp;val, cbm_len, first_bit);</span>
 
<span class="p_del">-	if (find_next_bit(&amp;var, r-&gt;cbm_len, zero_bit) &lt; r-&gt;cbm_len)</span>
<span class="p_add">+	if (find_next_bit(&amp;val, cbm_len, zero_bit) &lt; cbm_len)</span>
 		return false;
 
<span class="p_del">-	if ((zero_bit - first_bit) &lt; r-&gt;min_cbm_bits)</span>
<span class="p_add">+	if ((zero_bit - first_bit) &lt; r-&gt;cache.min_cbm_bits)</span>
 		return false;
<span class="p_add">+</span>
<span class="p_add">+	*data = val;</span>
 	return true;
 }
 
<span class="p_chunk">@@ -56,17 +107,17 @@</span> <span class="p_context"> static bool cbm_validate(unsigned long var, struct rdt_resource *r)</span>
  * Read one cache bit mask (hex). Check that it is valid for the current
  * resource type.
  */
<span class="p_del">-static int parse_cbm(char *buf, struct rdt_resource *r)</span>
<span class="p_add">+int parse_cbm(char *buf, struct rdt_resource *r, struct rdt_domain *d)</span>
 {
 	unsigned long data;
<span class="p_del">-	int ret;</span>
 
<span class="p_del">-	ret = kstrtoul(buf, 16, &amp;data);</span>
<span class="p_del">-	if (ret)</span>
<span class="p_del">-		return ret;</span>
<span class="p_del">-	if (!cbm_validate(data, r))</span>
<span class="p_add">+	if (d-&gt;have_new_ctrl)</span>
 		return -EINVAL;
<span class="p_del">-	r-&gt;tmp_cbms[r-&gt;num_tmp_cbms++] = data;</span>
<span class="p_add">+</span>
<span class="p_add">+	if(!cbm_validate(buf, &amp;data, r))</span>
<span class="p_add">+		return -EINVAL;</span>
<span class="p_add">+	d-&gt;new_ctrl = data;</span>
<span class="p_add">+	d-&gt;have_new_ctrl = true;</span>
 
 	return 0;
 }
<span class="p_chunk">@@ -74,8 +125,8 @@</span> <span class="p_context"> static int parse_cbm(char *buf, struct rdt_resource *r)</span>
 /*
  * For each domain in this resource we expect to find a series of:
  *	id=mask
<span class="p_del">- * separated by &quot;;&quot;. The &quot;id&quot; is in decimal, and must appear in the</span>
<span class="p_del">- * right order.</span>
<span class="p_add">+ * separated by &quot;;&quot;. The &quot;id&quot; is in decimal, and must match one of</span>
<span class="p_add">+ * the &quot;id&quot;s for this resource.</span>
  */
 static int parse_line(char *line, struct rdt_resource *r)
 {
<span class="p_chunk">@@ -83,21 +134,22 @@</span> <span class="p_context"> static int parse_line(char *line, struct rdt_resource *r)</span>
 	struct rdt_domain *d;
 	unsigned long dom_id;
 
<span class="p_add">+next:</span>
<span class="p_add">+	if (!line || line[0] == &#39;\0&#39;)</span>
<span class="p_add">+		return 0;</span>
<span class="p_add">+	dom = strsep(&amp;line, &quot;;&quot;);</span>
<span class="p_add">+	id = strsep(&amp;dom, &quot;=&quot;);</span>
<span class="p_add">+	if (!dom || kstrtoul(id, 10, &amp;dom_id))</span>
<span class="p_add">+		return -EINVAL;</span>
<span class="p_add">+	dom = strim(dom);</span>
 	list_for_each_entry(d, &amp;r-&gt;domains, list) {
<span class="p_del">-		dom = strsep(&amp;line, &quot;;&quot;);</span>
<span class="p_del">-		if (!dom)</span>
<span class="p_del">-			return -EINVAL;</span>
<span class="p_del">-		id = strsep(&amp;dom, &quot;=&quot;);</span>
<span class="p_del">-		if (kstrtoul(id, 10, &amp;dom_id) || dom_id != d-&gt;id)</span>
<span class="p_del">-			return -EINVAL;</span>
<span class="p_del">-		if (parse_cbm(dom, r))</span>
<span class="p_del">-			return -EINVAL;</span>
<span class="p_add">+		if (d-&gt;id == dom_id) {</span>
<span class="p_add">+			if (r-&gt;parse_ctrlval(dom, r, d))</span>
<span class="p_add">+				return -EINVAL;</span>
<span class="p_add">+			goto next;</span>
<span class="p_add">+		}</span>
 	}
<span class="p_del">-</span>
<span class="p_del">-	/* Any garbage at the end of the line? */</span>
<span class="p_del">-	if (line &amp;&amp; line[0])</span>
<span class="p_del">-		return -EINVAL;</span>
<span class="p_del">-	return 0;</span>
<span class="p_add">+	return -EINVAL;</span>
 }
 
 static int update_domains(struct rdt_resource *r, int closid)
<span class="p_chunk">@@ -105,7 +157,7 @@</span> <span class="p_context"> static int update_domains(struct rdt_resource *r, int closid)</span>
 	struct msr_param msr_param;
 	cpumask_var_t cpu_mask;
 	struct rdt_domain *d;
<span class="p_del">-	int cpu, idx = 0;</span>
<span class="p_add">+	int cpu;</span>
 
 	if (!zalloc_cpumask_var(&amp;cpu_mask, GFP_KERNEL))
 		return -ENOMEM;
<span class="p_chunk">@@ -115,30 +167,46 @@</span> <span class="p_context"> static int update_domains(struct rdt_resource *r, int closid)</span>
 	msr_param.res = r;
 
 	list_for_each_entry(d, &amp;r-&gt;domains, list) {
<span class="p_del">-		cpumask_set_cpu(cpumask_any(&amp;d-&gt;cpu_mask), cpu_mask);</span>
<span class="p_del">-		d-&gt;cbm[msr_param.low] = r-&gt;tmp_cbms[idx++];</span>
<span class="p_add">+		if (d-&gt;have_new_ctrl &amp;&amp; d-&gt;new_ctrl != d-&gt;ctrl_val[closid]) {</span>
<span class="p_add">+			cpumask_set_cpu(cpumask_any(&amp;d-&gt;cpu_mask), cpu_mask);</span>
<span class="p_add">+			d-&gt;ctrl_val[closid] = d-&gt;new_ctrl;</span>
<span class="p_add">+		}</span>
 	}
<span class="p_add">+	if (cpumask_empty(cpu_mask))</span>
<span class="p_add">+		goto done;</span>
 	cpu = get_cpu();
 	/* Update CBM on this cpu if it&#39;s in cpu_mask. */
 	if (cpumask_test_cpu(cpu, cpu_mask))
<span class="p_del">-		rdt_cbm_update(&amp;msr_param);</span>
<span class="p_add">+		rdt_ctrl_update(&amp;msr_param);</span>
 	/* Update CBM on other cpus. */
<span class="p_del">-	smp_call_function_many(cpu_mask, rdt_cbm_update, &amp;msr_param, 1);</span>
<span class="p_add">+	smp_call_function_many(cpu_mask, rdt_ctrl_update, &amp;msr_param, 1);</span>
 	put_cpu();
 
<span class="p_add">+done:</span>
 	free_cpumask_var(cpu_mask);
 
 	return 0;
 }
 
<span class="p_add">+static int rdtgroup_parse_resource(char *resname, char *tok, int closid)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct rdt_resource *r;</span>
<span class="p_add">+</span>
<span class="p_add">+	for_each_enabled_rdt_resource(r) {</span>
<span class="p_add">+		if (!strcmp(resname, r-&gt;name) &amp;&amp; closid &lt; r-&gt;num_closid)</span>
<span class="p_add">+			return parse_line(tok, r);</span>
<span class="p_add">+	}</span>
<span class="p_add">+	return -EINVAL;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 ssize_t rdtgroup_schemata_write(struct kernfs_open_file *of,
 				char *buf, size_t nbytes, loff_t off)
 {
 	struct rdtgroup *rdtgrp;
<span class="p_add">+	struct rdt_domain *dom;</span>
 	struct rdt_resource *r;
 	char *tok, *resname;
 	int closid, ret = 0;
<span class="p_del">-	u32 *l3_cbms = NULL;</span>
 
 	/* Valid input requires a trailing newline */
 	if (nbytes == 0 || buf[nbytes - 1] != &#39;\n&#39;)
<span class="p_chunk">@@ -153,44 +221,20 @@</span> <span class="p_context"> ssize_t rdtgroup_schemata_write(struct kernfs_open_file *of,</span>
 
 	closid = rdtgrp-&gt;closid;
 
<span class="p_del">-	/* get scratch space to save all the masks while we validate input */</span>
 	for_each_enabled_rdt_resource(r) {
<span class="p_del">-		r-&gt;tmp_cbms = kcalloc(r-&gt;num_domains, sizeof(*l3_cbms),</span>
<span class="p_del">-				      GFP_KERNEL);</span>
<span class="p_del">-		if (!r-&gt;tmp_cbms) {</span>
<span class="p_del">-			ret = -ENOMEM;</span>
<span class="p_del">-			goto out;</span>
<span class="p_del">-		}</span>
<span class="p_del">-		r-&gt;num_tmp_cbms = 0;</span>
<span class="p_add">+		list_for_each_entry(dom, &amp;r-&gt;domains, list)</span>
<span class="p_add">+			dom-&gt;have_new_ctrl = false;</span>
 	}
 
 	while ((tok = strsep(&amp;buf, &quot;\n&quot;)) != NULL) {
<span class="p_del">-		resname = strsep(&amp;tok, &quot;:&quot;);</span>
<span class="p_add">+		resname = strim(strsep(&amp;tok, &quot;:&quot;));</span>
 		if (!tok) {
 			ret = -EINVAL;
 			goto out;
 		}
<span class="p_del">-		for_each_enabled_rdt_resource(r) {</span>
<span class="p_del">-			if (!strcmp(resname, r-&gt;name) &amp;&amp;</span>
<span class="p_del">-			    closid &lt; r-&gt;num_closid) {</span>
<span class="p_del">-				ret = parse_line(tok, r);</span>
<span class="p_del">-				if (ret)</span>
<span class="p_del">-					goto out;</span>
<span class="p_del">-				break;</span>
<span class="p_del">-			}</span>
<span class="p_del">-		}</span>
<span class="p_del">-		if (!r-&gt;name) {</span>
<span class="p_del">-			ret = -EINVAL;</span>
<span class="p_del">-			goto out;</span>
<span class="p_del">-		}</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">-	/* Did the parser find all the masks we need? */</span>
<span class="p_del">-	for_each_enabled_rdt_resource(r) {</span>
<span class="p_del">-		if (r-&gt;num_tmp_cbms != r-&gt;num_domains) {</span>
<span class="p_del">-			ret = -EINVAL;</span>
<span class="p_add">+		ret = rdtgroup_parse_resource(resname, tok, closid);</span>
<span class="p_add">+		if (ret)</span>
 			goto out;
<span class="p_del">-		}</span>
 	}
 
 	for_each_enabled_rdt_resource(r) {
<span class="p_chunk">@@ -200,10 +244,6 @@</span> <span class="p_context"> ssize_t rdtgroup_schemata_write(struct kernfs_open_file *of,</span>
 	}
 
 out:
<span class="p_del">-	for_each_enabled_rdt_resource(r) {</span>
<span class="p_del">-		kfree(r-&gt;tmp_cbms);</span>
<span class="p_del">-		r-&gt;tmp_cbms = NULL;</span>
<span class="p_del">-	}</span>
 	rdtgroup_kn_unlock(of-&gt;kn);
 	return ret ?: nbytes;
 }
<span class="p_chunk">@@ -213,11 +253,12 @@</span> <span class="p_context"> static void show_doms(struct seq_file *s, struct rdt_resource *r, int closid)</span>
 	struct rdt_domain *dom;
 	bool sep = false;
 
<span class="p_del">-	seq_printf(s, &quot;%s:&quot;, r-&gt;name);</span>
<span class="p_add">+	seq_printf(s, &quot;%*s:&quot;, max_name_width, r-&gt;name);</span>
 	list_for_each_entry(dom, &amp;r-&gt;domains, list) {
 		if (sep)
 			seq_puts(s, &quot;;&quot;);
<span class="p_del">-		seq_printf(s, &quot;%d=%x&quot;, dom-&gt;id, dom-&gt;cbm[closid]);</span>
<span class="p_add">+		seq_printf(s, r-&gt;format_str, dom-&gt;id, max_data_width,</span>
<span class="p_add">+			   dom-&gt;ctrl_val[closid]);</span>
 		sep = true;
 	}
 	seq_puts(s, &quot;\n&quot;);
<span class="p_header">diff --git a/arch/x86/kernel/cpu/proc.c b/arch/x86/kernel/cpu/proc.c</span>
<span class="p_header">index 18ca99f2798b..6df621ae62a7 100644</span>
<span class="p_header">--- a/arch/x86/kernel/cpu/proc.c</span>
<span class="p_header">+++ b/arch/x86/kernel/cpu/proc.c</span>
<span class="p_chunk">@@ -31,14 +31,13 @@</span> <span class="p_context"> static void show_cpuinfo_misc(struct seq_file *m, struct cpuinfo_x86 *c)</span>
 		   &quot;fpu\t\t: %s\n&quot;
 		   &quot;fpu_exception\t: %s\n&quot;
 		   &quot;cpuid level\t: %d\n&quot;
<span class="p_del">-		   &quot;wp\t\t: %s\n&quot;,</span>
<span class="p_add">+		   &quot;wp\t\t: yes\n&quot;,</span>
 		   static_cpu_has_bug(X86_BUG_FDIV) ? &quot;yes&quot; : &quot;no&quot;,
 		   static_cpu_has_bug(X86_BUG_F00F) ? &quot;yes&quot; : &quot;no&quot;,
 		   static_cpu_has_bug(X86_BUG_COMA) ? &quot;yes&quot; : &quot;no&quot;,
 		   static_cpu_has(X86_FEATURE_FPU) ? &quot;yes&quot; : &quot;no&quot;,
 		   static_cpu_has(X86_FEATURE_FPU) ? &quot;yes&quot; : &quot;no&quot;,
<span class="p_del">-		   c-&gt;cpuid_level,</span>
<span class="p_del">-		   c-&gt;wp_works_ok ? &quot;yes&quot; : &quot;no&quot;);</span>
<span class="p_add">+		   c-&gt;cpuid_level);</span>
 }
 #else
 static void show_cpuinfo_misc(struct seq_file *m, struct cpuinfo_x86 *c)
<span class="p_header">diff --git a/arch/x86/kernel/cpu/scattered.c b/arch/x86/kernel/cpu/scattered.c</span>
<span class="p_header">index d9794060fe22..23c23508c012 100644</span>
<span class="p_header">--- a/arch/x86/kernel/cpu/scattered.c</span>
<span class="p_header">+++ b/arch/x86/kernel/cpu/scattered.c</span>
<span class="p_chunk">@@ -27,6 +27,7 @@</span> <span class="p_context"> static const struct cpuid_bit cpuid_bits[] = {</span>
 	{ X86_FEATURE_CAT_L3,		CPUID_EBX,  1, 0x00000010, 0 },
 	{ X86_FEATURE_CAT_L2,		CPUID_EBX,  2, 0x00000010, 0 },
 	{ X86_FEATURE_CDP_L3,		CPUID_ECX,  2, 0x00000010, 1 },
<span class="p_add">+	{ X86_FEATURE_MBA,		CPUID_EBX,  3, 0x00000010, 0 },</span>
 	{ X86_FEATURE_HW_PSTATE,	CPUID_EDX,  7, 0x80000007, 0 },
 	{ X86_FEATURE_CPB,		CPUID_EDX,  9, 0x80000007, 0 },
 	{ X86_FEATURE_PROC_FEEDBACK,    CPUID_EDX, 11, 0x80000007, 0 },
<span class="p_header">diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c</span>
<span class="p_header">index 4bf0c8926a1c..7cd7bbefd418 100644</span>
<span class="p_header">--- a/arch/x86/kernel/setup.c</span>
<span class="p_header">+++ b/arch/x86/kernel/setup.c</span>
<span class="p_chunk">@@ -173,14 +173,11 @@</span> <span class="p_context"> static struct resource bss_resource = {</span>
 
 
 #ifdef CONFIG_X86_32
<span class="p_del">-/* cpu data as detected by the assembly code in head.S */</span>
<span class="p_del">-struct cpuinfo_x86 new_cpu_data = {</span>
<span class="p_del">-	.wp_works_ok = -1,</span>
<span class="p_del">-};</span>
<span class="p_add">+/* cpu data as detected by the assembly code in head_32.S */</span>
<span class="p_add">+struct cpuinfo_x86 new_cpu_data;</span>
<span class="p_add">+</span>
 /* common cpu data for all cpus */
<span class="p_del">-struct cpuinfo_x86 boot_cpu_data __read_mostly = {</span>
<span class="p_del">-	.wp_works_ok = -1,</span>
<span class="p_del">-};</span>
<span class="p_add">+struct cpuinfo_x86 boot_cpu_data __read_mostly;</span>
 EXPORT_SYMBOL(boot_cpu_data);
 
 unsigned int def_to_bigsmp;
<span class="p_header">diff --git a/arch/x86/mm/init_32.c b/arch/x86/mm/init_32.c</span>
<span class="p_header">index 2b4b53e6793f..4dddfaf6569a 100644</span>
<span class="p_header">--- a/arch/x86/mm/init_32.c</span>
<span class="p_header">+++ b/arch/x86/mm/init_32.c</span>
<span class="p_chunk">@@ -716,15 +716,17 @@</span> <span class="p_context"> void __init paging_init(void)</span>
  */
 static void __init test_wp_bit(void)
 {
<span class="p_add">+	int wp_works_ok;</span>
<span class="p_add">+</span>
 	printk(KERN_INFO
   &quot;Checking if this processor honours the WP bit even in supervisor mode...&quot;);
 
 	/* Any page-aligned address will do, the test is non-destructive */
 	__set_fixmap(FIX_WP_TEST, __pa(&amp;swapper_pg_dir), PAGE_KERNEL_RO);
<span class="p_del">-	boot_cpu_data.wp_works_ok = do_test_wp_bit();</span>
<span class="p_add">+	wp_works_ok = do_test_wp_bit();</span>
 	clear_fixmap(FIX_WP_TEST);
 
<span class="p_del">-	if (!boot_cpu_data.wp_works_ok) {</span>
<span class="p_add">+	if (!wp_works_ok) {</span>
 		printk(KERN_CONT &quot;No.\n&quot;);
 		panic(&quot;Linux doesn&#39;t support CPUs with broken WP.&quot;);
 	} else {
<span class="p_chunk">@@ -811,8 +813,7 @@</span> <span class="p_context"> void __init mem_init(void)</span>
 	BUG_ON(VMALLOC_START				&gt;= VMALLOC_END);
 	BUG_ON((unsigned long)high_memory		&gt; VMALLOC_START);
 
<span class="p_del">-	if (boot_cpu_data.wp_works_ok &lt; 0)</span>
<span class="p_del">-		test_wp_bit();</span>
<span class="p_add">+	test_wp_bit();</span>
 }
 
 #ifdef CONFIG_MEMORY_HOTPLUG
<span class="p_header">diff --git a/arch/x86/xen/enlighten.c b/arch/x86/xen/enlighten.c</span>
<span class="p_header">index ec1d5c46e58f..bc3dab5d47ca 100644</span>
<span class="p_header">--- a/arch/x86/xen/enlighten.c</span>
<span class="p_header">+++ b/arch/x86/xen/enlighten.c</span>
<span class="p_chunk">@@ -1595,7 +1595,6 @@</span> <span class="p_context"> asmlinkage __visible void __init xen_start_kernel(void)</span>
 	/* set up basic CPUID stuff */
 	cpu_detect(&amp;new_cpu_data);
 	set_cpu_cap(&amp;new_cpu_data, X86_FEATURE_FPU);
<span class="p_del">-	new_cpu_data.wp_works_ok = 1;</span>
 	new_cpu_data.x86_capability[CPUID_1_EDX] = cpuid_edx(1);
 #endif
 

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



