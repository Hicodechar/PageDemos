
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>[RFC,03/10] x86/mm: Make the batched unmap TLB flush API more generic - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    [RFC,03/10] x86/mm: Make the batched unmap TLB flush API more generic</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=125831">Andrew Lutomirski</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>May 7, 2017, 12:38 p.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;983c5ee661d8fe8a70c596c4e77076d11ce3f80a.1494160201.git.luto@kernel.org&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/9715541/mbox/"
   >mbox</a>
|
   <a href="/patch/9715541/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/9715541/">/patch/9715541/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
	[172.30.200.125])
	by pdx-korg-patchwork.web.codeaurora.org (Postfix) with ESMTP id
	1A86C60380 for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Sun,  7 May 2017 22:07:02 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 0B711200F5
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Sun,  7 May 2017 22:07:02 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id F38B426C9B; Sun,  7 May 2017 22:07:01 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-6.9 required=2.0 tests=BAYES_00,RCVD_IN_DNSWL_HI
	autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 59BE1200F5
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Sun,  7 May 2017 22:07:01 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1757274AbdEGWG5 (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Sun, 7 May 2017 18:06:57 -0400
Received: from mail.kernel.org ([198.145.29.136]:51068 &quot;EHLO mail.kernel.org&quot;
	rhost-flags-OK-OK-OK-OK) by vger.kernel.org with ESMTP
	id S1757103AbdEGWGW (ORCPT &lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Sun, 7 May 2017 18:06:22 -0400
Received: from mail.kernel.org (localhost [127.0.0.1])
	by mail.kernel.org (Postfix) with ESMTP id AEB4C203B4;
	Sun,  7 May 2017 12:38:59 +0000 (UTC)
Received: from localhost (118-171-175-29.dynamic-ip.hinet.net
	[118.171.175.29])
	(using TLSv1.2 with cipher ECDHE-RSA-AES256-GCM-SHA384 (256/256
	bits)) (No client certificate requested)
	by mail.kernel.org (Postfix) with ESMTPSA id 7BDD6203AE;
	Sun,  7 May 2017 12:38:57 +0000 (UTC)
From: Andy Lutomirski &lt;luto@kernel.org&gt;
To: X86 ML &lt;x86@kernel.org&gt;
Cc: &quot;linux-kernel@vger.kernel.org&quot; &lt;linux-kernel@vger.kernel.org&gt;,
	Borislav Petkov &lt;bpetkov@suse.de&gt;,
	Linus Torvalds &lt;torvalds@linux-foundation.org&gt;,
	Andrew Morton &lt;akpm@linux-foundation.org&gt;, Mel Gorman &lt;mgorman@suse.de&gt;,
	&quot;linux-mm@kvack.org&quot; &lt;linux-mm@kvack.org&gt;,
	Andy Lutomirski &lt;luto@kernel.org&gt;, Rik van Riel &lt;riel@redhat.com&gt;,
	Dave Hansen &lt;dave.hansen@intel.com&gt;,
	Nadav Amit &lt;namit@vmware.com&gt;, Michal Hocko &lt;mhocko@suse.com&gt;,
	Sasha Levin &lt;sasha.levin@oracle.com&gt;
Subject: [RFC 03/10] x86/mm: Make the batched unmap TLB flush API more
	generic
Date: Sun,  7 May 2017 05:38:32 -0700
Message-Id: &lt;983c5ee661d8fe8a70c596c4e77076d11ce3f80a.1494160201.git.luto@kernel.org&gt;
X-Mailer: git-send-email 2.9.3
In-Reply-To: &lt;cover.1494160201.git.luto@kernel.org&gt;
References: &lt;cover.1494160201.git.luto@kernel.org&gt;
In-Reply-To: &lt;cover.1494160201.git.luto@kernel.org&gt;
References: &lt;cover.1494160201.git.luto@kernel.org&gt;
X-Virus-Scanned: ClamAV using ClamSMTP
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=125831">Andrew Lutomirski</a> - May 7, 2017, 12:38 p.m.</div>
<pre class="content">
try_to_unmap_flush() used to open-code a rather x86-centric flush
sequence: local_flush_tlb() + flush_tlb_others().  Rearrange the
code so that the arch (only x86 for now) provides
arch_tlbbatch_add_mm() and arch_tlbbatch_flush() and the core code
calls those functions instead.

I&#39;ll want this for x86 because, to enable address space ids, I can&#39;t
support the flush_tlb_others() mode used by exising
try_to_unmap_flush() implementation with good performance.  I can
support the new API fairly easily, though.

I imagine that other architectures may be in a similar position.
Architectures with strong remote flush primitives (arm64?) may have
even worse performance problems with flush_tlb_others() the way that
try_to_unmap_flush() uses it.

Cc: Mel Gorman &lt;mgorman@suse.de&gt;
Cc: Rik van Riel &lt;riel@redhat.com&gt;
Cc: Dave Hansen &lt;dave.hansen@intel.com&gt;
Cc: Nadav Amit &lt;namit@vmware.com&gt;
Cc: Michal Hocko &lt;mhocko@suse.com&gt;
Cc: Sasha Levin &lt;sasha.levin@oracle.com&gt;
Cc: Andrew Morton &lt;akpm@linux-foundation.org&gt;
<span class="signed-off-by">Signed-off-by: Andy Lutomirski &lt;luto@kernel.org&gt;</span>
---
 arch/x86/include/asm/tlbbatch.h | 16 ++++++++++++++++
 arch/x86/include/asm/tlbflush.h |  8 ++++++++
 arch/x86/mm/tlb.c               | 17 +++++++++++++++++
 include/linux/mm_types_task.h   | 15 +++++++++++----
 mm/rmap.c                       | 15 +--------------
 5 files changed, 53 insertions(+), 18 deletions(-)
 create mode 100644 arch/x86/include/asm/tlbbatch.h
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=65121">Dave Hansen</a> - May 8, 2017, 3:34 p.m.</div>
<pre class="content">
On 05/07/2017 05:38 AM, Andy Lutomirski wrote:
<span class="quote">&gt; diff --git a/mm/rmap.c b/mm/rmap.c</span>
<span class="quote">&gt; index f6838015810f..2e568c82f477 100644</span>
<span class="quote">&gt; --- a/mm/rmap.c</span>
<span class="quote">&gt; +++ b/mm/rmap.c</span>
<span class="quote">&gt; @@ -579,25 +579,12 @@ void page_unlock_anon_vma_read(struct anon_vma *anon_vma)</span>
<span class="quote">&gt;  void try_to_unmap_flush(void)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	struct tlbflush_unmap_batch *tlb_ubc = &amp;current-&gt;tlb_ubc;</span>
<span class="quote">&gt; -	int cpu;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	if (!tlb_ubc-&gt;flush_required)</span>
<span class="quote">&gt;  		return;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; -	cpu = get_cpu();</span>
<span class="quote">&gt; -</span>
<span class="quote">&gt; -	if (cpumask_test_cpu(cpu, &amp;tlb_ubc-&gt;cpumask)) {</span>
<span class="quote">&gt; -		count_vm_tlb_event(NR_TLB_LOCAL_FLUSH_ALL);</span>
<span class="quote">&gt; -		local_flush_tlb();</span>
<span class="quote">&gt; -		trace_tlb_flush(TLB_LOCAL_SHOOTDOWN, TLB_FLUSH_ALL);</span>
<span class="quote">&gt; -	}</span>
<span class="quote">&gt; -</span>
<span class="quote">&gt; -	if (cpumask_any_but(&amp;tlb_ubc-&gt;cpumask, cpu) &lt; nr_cpu_ids)</span>
<span class="quote">&gt; -		flush_tlb_others(&amp;tlb_ubc-&gt;cpumask, NULL, 0, TLB_FLUSH_ALL);</span>
<span class="quote">&gt; -	cpumask_clear(&amp;tlb_ubc-&gt;cpumask);</span>
<span class="quote">&gt;  	tlb_ubc-&gt;flush_required = false;</span>
<span class="quote">&gt;  	tlb_ubc-&gt;writable = false;</span>
<span class="quote">&gt; -	put_cpu();</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  /* Flush iff there are potentially writable TLB entries that can race with IO */</span>
<span class="quote">&gt; @@ -613,7 +600,7 @@ static void set_tlb_ubc_flush_pending(struct mm_struct *mm, bool writable)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	struct tlbflush_unmap_batch *tlb_ubc = &amp;current-&gt;tlb_ubc;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; -	cpumask_or(&amp;tlb_ubc-&gt;cpumask, &amp;tlb_ubc-&gt;cpumask, mm_cpumask(mm));</span>
<span class="quote">&gt; +	arch_tlbbatch_add_mm(&amp;tlb_ubc-&gt;arch, mm);</span>
<span class="quote">&gt;  	tlb_ubc-&gt;flush_required = true;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	/*</span>

Looking at this patch in isolation, how can this be safe?  It removes
TLB flushes from the generic code.  Do other patches in the series fix
this up?
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=125831">Andrew Lutomirski</a> - May 9, 2017, 1:02 p.m.</div>
<pre class="content">
On Mon, May 8, 2017 at 8:34 AM, Dave Hansen &lt;dave.hansen@intel.com&gt; wrote:
<span class="quote">&gt; On 05/07/2017 05:38 AM, Andy Lutomirski wrote:</span>
<span class="quote">&gt;&gt; diff --git a/mm/rmap.c b/mm/rmap.c</span>
<span class="quote">&gt;&gt; index f6838015810f..2e568c82f477 100644</span>
<span class="quote">&gt;&gt; --- a/mm/rmap.c</span>
<span class="quote">&gt;&gt; +++ b/mm/rmap.c</span>
<span class="quote">&gt;&gt; @@ -579,25 +579,12 @@ void page_unlock_anon_vma_read(struct anon_vma *anon_vma)</span>
<span class="quote">&gt;&gt;  void try_to_unmap_flush(void)</span>
<span class="quote">&gt;&gt;  {</span>
<span class="quote">&gt;&gt;       struct tlbflush_unmap_batch *tlb_ubc = &amp;current-&gt;tlb_ubc;</span>
<span class="quote">&gt;&gt; -     int cpu;</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt;       if (!tlb_ubc-&gt;flush_required)</span>
<span class="quote">&gt;&gt;               return;</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; -     cpu = get_cpu();</span>
<span class="quote">&gt;&gt; -</span>
<span class="quote">&gt;&gt; -     if (cpumask_test_cpu(cpu, &amp;tlb_ubc-&gt;cpumask)) {</span>
<span class="quote">&gt;&gt; -             count_vm_tlb_event(NR_TLB_LOCAL_FLUSH_ALL);</span>
<span class="quote">&gt;&gt; -             local_flush_tlb();</span>
<span class="quote">&gt;&gt; -             trace_tlb_flush(TLB_LOCAL_SHOOTDOWN, TLB_FLUSH_ALL);</span>
<span class="quote">&gt;&gt; -     }</span>
<span class="quote">&gt;&gt; -</span>
<span class="quote">&gt;&gt; -     if (cpumask_any_but(&amp;tlb_ubc-&gt;cpumask, cpu) &lt; nr_cpu_ids)</span>
<span class="quote">&gt;&gt; -             flush_tlb_others(&amp;tlb_ubc-&gt;cpumask, NULL, 0, TLB_FLUSH_ALL);</span>
<span class="quote">&gt;&gt; -     cpumask_clear(&amp;tlb_ubc-&gt;cpumask);</span>
<span class="quote">&gt;&gt;       tlb_ubc-&gt;flush_required = false;</span>
<span class="quote">&gt;&gt;       tlb_ubc-&gt;writable = false;</span>
<span class="quote">&gt;&gt; -     put_cpu();</span>
<span class="quote">&gt;&gt;  }</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt;  /* Flush iff there are potentially writable TLB entries that can race with IO */</span>
<span class="quote">&gt;&gt; @@ -613,7 +600,7 @@ static void set_tlb_ubc_flush_pending(struct mm_struct *mm, bool writable)</span>
<span class="quote">&gt;&gt;  {</span>
<span class="quote">&gt;&gt;       struct tlbflush_unmap_batch *tlb_ubc = &amp;current-&gt;tlb_ubc;</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; -     cpumask_or(&amp;tlb_ubc-&gt;cpumask, &amp;tlb_ubc-&gt;cpumask, mm_cpumask(mm));</span>
<span class="quote">&gt;&gt; +     arch_tlbbatch_add_mm(&amp;tlb_ubc-&gt;arch, mm);</span>
<span class="quote">&gt;&gt;       tlb_ubc-&gt;flush_required = true;</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt;       /*</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; Looking at this patch in isolation, how can this be safe?  It removes</span>
<span class="quote">&gt; TLB flushes from the generic code.  Do other patches in the series fix</span>
<span class="quote">&gt; this up?</span>

Hmm?  Unless I totally screwed this up, this patch just moves the
flushes around -- it shouldn&#39;t remove any flushes.
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=24451">Mel Gorman</a> - May 9, 2017, 2:39 p.m.</div>
<pre class="content">
On Tue, May 09, 2017 at 06:02:49AM -0700, Andrew Lutomirski wrote:
<span class="quote">&gt; On Mon, May 8, 2017 at 8:34 AM, Dave Hansen &lt;dave.hansen@intel.com&gt; wrote:</span>
<span class="quote">&gt; &gt; On 05/07/2017 05:38 AM, Andy Lutomirski wrote:</span>
<span class="quote">&gt; &gt;&gt; diff --git a/mm/rmap.c b/mm/rmap.c</span>
<span class="quote">&gt; &gt;&gt; index f6838015810f..2e568c82f477 100644</span>
<span class="quote">&gt; &gt;&gt; --- a/mm/rmap.c</span>
<span class="quote">&gt; &gt;&gt; +++ b/mm/rmap.c</span>
<span class="quote">&gt; &gt;&gt; @@ -579,25 +579,12 @@ void page_unlock_anon_vma_read(struct anon_vma *anon_vma)</span>
<span class="quote">&gt; &gt;&gt;  void try_to_unmap_flush(void)</span>
<span class="quote">&gt; &gt;&gt;  {</span>
<span class="quote">&gt; &gt;&gt;       struct tlbflush_unmap_batch *tlb_ubc = &amp;current-&gt;tlb_ubc;</span>
<span class="quote">&gt; &gt;&gt; -     int cpu;</span>
<span class="quote">&gt; &gt;&gt;</span>
<span class="quote">&gt; &gt;&gt;       if (!tlb_ubc-&gt;flush_required)</span>
<span class="quote">&gt; &gt;&gt;               return;</span>
<span class="quote">&gt; &gt;&gt;</span>
<span class="quote">&gt; &gt;&gt; -     cpu = get_cpu();</span>
<span class="quote">&gt; &gt;&gt; -</span>
<span class="quote">&gt; &gt;&gt; -     if (cpumask_test_cpu(cpu, &amp;tlb_ubc-&gt;cpumask)) {</span>
<span class="quote">&gt; &gt;&gt; -             count_vm_tlb_event(NR_TLB_LOCAL_FLUSH_ALL);</span>
<span class="quote">&gt; &gt;&gt; -             local_flush_tlb();</span>
<span class="quote">&gt; &gt;&gt; -             trace_tlb_flush(TLB_LOCAL_SHOOTDOWN, TLB_FLUSH_ALL);</span>
<span class="quote">&gt; &gt;&gt; -     }</span>
<span class="quote">&gt; &gt;&gt; -</span>
<span class="quote">&gt; &gt;&gt; -     if (cpumask_any_but(&amp;tlb_ubc-&gt;cpumask, cpu) &lt; nr_cpu_ids)</span>
<span class="quote">&gt; &gt;&gt; -             flush_tlb_others(&amp;tlb_ubc-&gt;cpumask, NULL, 0, TLB_FLUSH_ALL);</span>
<span class="quote">&gt; &gt;&gt; -     cpumask_clear(&amp;tlb_ubc-&gt;cpumask);</span>
<span class="quote">&gt; &gt;&gt;       tlb_ubc-&gt;flush_required = false;</span>
<span class="quote">&gt; &gt;&gt;       tlb_ubc-&gt;writable = false;</span>
<span class="quote">&gt; &gt;&gt; -     put_cpu();</span>
<span class="quote">&gt; &gt;&gt;  }</span>
<span class="quote">&gt; &gt;&gt;</span>
<span class="quote">&gt; &gt;&gt;  /* Flush iff there are potentially writable TLB entries that can race with IO */</span>
<span class="quote">&gt; &gt;&gt; @@ -613,7 +600,7 @@ static void set_tlb_ubc_flush_pending(struct mm_struct *mm, bool writable)</span>
<span class="quote">&gt; &gt;&gt;  {</span>
<span class="quote">&gt; &gt;&gt;       struct tlbflush_unmap_batch *tlb_ubc = &amp;current-&gt;tlb_ubc;</span>
<span class="quote">&gt; &gt;&gt;</span>
<span class="quote">&gt; &gt;&gt; -     cpumask_or(&amp;tlb_ubc-&gt;cpumask, &amp;tlb_ubc-&gt;cpumask, mm_cpumask(mm));</span>
<span class="quote">&gt; &gt;&gt; +     arch_tlbbatch_add_mm(&amp;tlb_ubc-&gt;arch, mm);</span>
<span class="quote">&gt; &gt;&gt;       tlb_ubc-&gt;flush_required = true;</span>
<span class="quote">&gt; &gt;&gt;</span>
<span class="quote">&gt; &gt;&gt;       /*</span>
<span class="quote">&gt; &gt;</span>
<span class="quote">&gt; &gt; Looking at this patch in isolation, how can this be safe?  It removes</span>
<span class="quote">&gt; &gt; TLB flushes from the generic code.  Do other patches in the series fix</span>
<span class="quote">&gt; &gt; this up?</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Hmm?  Unless I totally screwed this up, this patch just moves the</span>
<span class="quote">&gt; flushes around -- it shouldn&#39;t remove any flushes.</span>

I think he&#39;s asking when or how arch_tlbbatch_flush gets called because
it doesn&#39;t happen in try_to_unmap_flush().
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=65121">Dave Hansen</a> - May 9, 2017, 5:13 p.m.</div>
<pre class="content">
On 05/09/2017 06:02 AM, Andy Lutomirski wrote:
<span class="quote">&gt; On Mon, May 8, 2017 at 8:34 AM, Dave Hansen &lt;dave.hansen@intel.com&gt; wrote:</span>
<span class="quote">&gt;&gt; On 05/07/2017 05:38 AM, Andy Lutomirski wrote:</span>
<span class="quote">&gt;&gt;&gt; diff --git a/mm/rmap.c b/mm/rmap.c</span>
<span class="quote">&gt;&gt;&gt; index f6838015810f..2e568c82f477 100644</span>
<span class="quote">&gt;&gt;&gt; --- a/mm/rmap.c</span>
<span class="quote">&gt;&gt;&gt; +++ b/mm/rmap.c</span>
<span class="quote">&gt;&gt;&gt; @@ -579,25 +579,12 @@ void page_unlock_anon_vma_read(struct anon_vma *anon_vma)</span>
<span class="quote">&gt;&gt;&gt;  void try_to_unmap_flush(void)</span>
<span class="quote">&gt;&gt;&gt;  {</span>
<span class="quote">&gt;&gt;&gt;       struct tlbflush_unmap_batch *tlb_ubc = &amp;current-&gt;tlb_ubc;</span>
<span class="quote">&gt;&gt;&gt; -     int cpu;</span>
<span class="quote">&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt;       if (!tlb_ubc-&gt;flush_required)</span>
<span class="quote">&gt;&gt;&gt;               return;</span>
<span class="quote">&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt; -     cpu = get_cpu();</span>
<span class="quote">&gt;&gt;&gt; -</span>
<span class="quote">&gt;&gt;&gt; -     if (cpumask_test_cpu(cpu, &amp;tlb_ubc-&gt;cpumask)) {</span>
<span class="quote">&gt;&gt;&gt; -             count_vm_tlb_event(NR_TLB_LOCAL_FLUSH_ALL);</span>
<span class="quote">&gt;&gt;&gt; -             local_flush_tlb();</span>
<span class="quote">&gt;&gt;&gt; -             trace_tlb_flush(TLB_LOCAL_SHOOTDOWN, TLB_FLUSH_ALL);</span>
<span class="quote">&gt;&gt;&gt; -     }</span>
<span class="quote">&gt;&gt;&gt; -</span>
<span class="quote">&gt;&gt;&gt; -     if (cpumask_any_but(&amp;tlb_ubc-&gt;cpumask, cpu) &lt; nr_cpu_ids)</span>
<span class="quote">&gt;&gt;&gt; -             flush_tlb_others(&amp;tlb_ubc-&gt;cpumask, NULL, 0, TLB_FLUSH_ALL);</span>
<span class="quote">&gt;&gt;&gt; -     cpumask_clear(&amp;tlb_ubc-&gt;cpumask);</span>
<span class="quote">&gt;&gt;&gt;       tlb_ubc-&gt;flush_required = false;</span>
<span class="quote">&gt;&gt;&gt;       tlb_ubc-&gt;writable = false;</span>
<span class="quote">&gt;&gt;&gt; -     put_cpu();</span>
<span class="quote">&gt;&gt;&gt;  }</span>
<span class="quote">&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt;  /* Flush iff there are potentially writable TLB entries that can race with IO */</span>
<span class="quote">&gt;&gt;&gt; @@ -613,7 +600,7 @@ static void set_tlb_ubc_flush_pending(struct mm_struct *mm, bool writable)</span>
<span class="quote">&gt;&gt;&gt;  {</span>
<span class="quote">&gt;&gt;&gt;       struct tlbflush_unmap_batch *tlb_ubc = &amp;current-&gt;tlb_ubc;</span>
<span class="quote">&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt; -     cpumask_or(&amp;tlb_ubc-&gt;cpumask, &amp;tlb_ubc-&gt;cpumask, mm_cpumask(mm));</span>
<span class="quote">&gt;&gt;&gt; +     arch_tlbbatch_add_mm(&amp;tlb_ubc-&gt;arch, mm);</span>
<span class="quote">&gt;&gt;&gt;       tlb_ubc-&gt;flush_required = true;</span>
<span class="quote">&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt;       /*</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; Looking at this patch in isolation, how can this be safe?  It removes</span>
<span class="quote">&gt;&gt; TLB flushes from the generic code.  Do other patches in the series fix</span>
<span class="quote">&gt;&gt; this up?</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Hmm?  Unless I totally screwed this up, this patch just moves the</span>
<span class="quote">&gt; flushes around -- it shouldn&#39;t remove any flushes.</span>

This takes a flush out of try_to_unmap_flush().  It adds code for
arch_tlbbatch_flush(), but not *calls* to arch_tlbbatch_flush() that I
can see.

I actually don&#39;t see _any_ in the whole series in a quick grepping.  Am
I just missing them?
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=125831">Andrew Lutomirski</a> - May 9, 2017, 10:54 p.m.</div>
<pre class="content">
On Tue, May 9, 2017 at 10:13 AM, Dave Hansen &lt;dave.hansen@intel.com&gt; wrote:
<span class="quote">&gt; On 05/09/2017 06:02 AM, Andy Lutomirski wrote:</span>
<span class="quote">&gt;&gt; On Mon, May 8, 2017 at 8:34 AM, Dave Hansen &lt;dave.hansen@intel.com&gt; wrote:</span>
<span class="quote">&gt;&gt;&gt; On 05/07/2017 05:38 AM, Andy Lutomirski wrote:</span>
<span class="quote">&gt;&gt;&gt;&gt; diff --git a/mm/rmap.c b/mm/rmap.c</span>
<span class="quote">&gt;&gt;&gt;&gt; index f6838015810f..2e568c82f477 100644</span>
<span class="quote">&gt;&gt;&gt;&gt; --- a/mm/rmap.c</span>
<span class="quote">&gt;&gt;&gt;&gt; +++ b/mm/rmap.c</span>
<span class="quote">&gt;&gt;&gt;&gt; @@ -579,25 +579,12 @@ void page_unlock_anon_vma_read(struct anon_vma *anon_vma)</span>
<span class="quote">&gt;&gt;&gt;&gt;  void try_to_unmap_flush(void)</span>
<span class="quote">&gt;&gt;&gt;&gt;  {</span>
<span class="quote">&gt;&gt;&gt;&gt;       struct tlbflush_unmap_batch *tlb_ubc = &amp;current-&gt;tlb_ubc;</span>
<span class="quote">&gt;&gt;&gt;&gt; -     int cpu;</span>
<span class="quote">&gt;&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt;&gt;       if (!tlb_ubc-&gt;flush_required)</span>
<span class="quote">&gt;&gt;&gt;&gt;               return;</span>
<span class="quote">&gt;&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt;&gt; -     cpu = get_cpu();</span>
<span class="quote">&gt;&gt;&gt;&gt; -</span>
<span class="quote">&gt;&gt;&gt;&gt; -     if (cpumask_test_cpu(cpu, &amp;tlb_ubc-&gt;cpumask)) {</span>
<span class="quote">&gt;&gt;&gt;&gt; -             count_vm_tlb_event(NR_TLB_LOCAL_FLUSH_ALL);</span>
<span class="quote">&gt;&gt;&gt;&gt; -             local_flush_tlb();</span>
<span class="quote">&gt;&gt;&gt;&gt; -             trace_tlb_flush(TLB_LOCAL_SHOOTDOWN, TLB_FLUSH_ALL);</span>
<span class="quote">&gt;&gt;&gt;&gt; -     }</span>
<span class="quote">&gt;&gt;&gt;&gt; -</span>
<span class="quote">&gt;&gt;&gt;&gt; -     if (cpumask_any_but(&amp;tlb_ubc-&gt;cpumask, cpu) &lt; nr_cpu_ids)</span>
<span class="quote">&gt;&gt;&gt;&gt; -             flush_tlb_others(&amp;tlb_ubc-&gt;cpumask, NULL, 0, TLB_FLUSH_ALL);</span>
<span class="quote">&gt;&gt;&gt;&gt; -     cpumask_clear(&amp;tlb_ubc-&gt;cpumask);</span>
<span class="quote">&gt;&gt;&gt;&gt;       tlb_ubc-&gt;flush_required = false;</span>
<span class="quote">&gt;&gt;&gt;&gt;       tlb_ubc-&gt;writable = false;</span>
<span class="quote">&gt;&gt;&gt;&gt; -     put_cpu();</span>
<span class="quote">&gt;&gt;&gt;&gt;  }</span>
<span class="quote">&gt;&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt;&gt;  /* Flush iff there are potentially writable TLB entries that can race with IO */</span>
<span class="quote">&gt;&gt;&gt;&gt; @@ -613,7 +600,7 @@ static void set_tlb_ubc_flush_pending(struct mm_struct *mm, bool writable)</span>
<span class="quote">&gt;&gt;&gt;&gt;  {</span>
<span class="quote">&gt;&gt;&gt;&gt;       struct tlbflush_unmap_batch *tlb_ubc = &amp;current-&gt;tlb_ubc;</span>
<span class="quote">&gt;&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt;&gt; -     cpumask_or(&amp;tlb_ubc-&gt;cpumask, &amp;tlb_ubc-&gt;cpumask, mm_cpumask(mm));</span>
<span class="quote">&gt;&gt;&gt;&gt; +     arch_tlbbatch_add_mm(&amp;tlb_ubc-&gt;arch, mm);</span>
<span class="quote">&gt;&gt;&gt;&gt;       tlb_ubc-&gt;flush_required = true;</span>
<span class="quote">&gt;&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt;&gt;       /*</span>
<span class="quote">&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt; Looking at this patch in isolation, how can this be safe?  It removes</span>
<span class="quote">&gt;&gt;&gt; TLB flushes from the generic code.  Do other patches in the series fix</span>
<span class="quote">&gt;&gt;&gt; this up?</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; Hmm?  Unless I totally screwed this up, this patch just moves the</span>
<span class="quote">&gt;&gt; flushes around -- it shouldn&#39;t remove any flushes.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; This takes a flush out of try_to_unmap_flush().  It adds code for</span>
<span class="quote">&gt; arch_tlbbatch_flush(), but not *calls* to arch_tlbbatch_flush() that I</span>
<span class="quote">&gt; can see.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; I actually don&#39;t see _any_ in the whole series in a quick grepping.  Am</span>
<span class="quote">&gt; I just missing them?</span>

Oops!  I must have stared at that function for so long that I started
seeing the invisible call.  I&#39;ll fix that.
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/arch/x86/include/asm/tlbbatch.h b/arch/x86/include/asm/tlbbatch.h</span>
new file mode 100644
<span class="p_header">index 000000000000..01a6de16fb96</span>
<span class="p_header">--- /dev/null</span>
<span class="p_header">+++ b/arch/x86/include/asm/tlbbatch.h</span>
<span class="p_chunk">@@ -0,0 +1,16 @@</span> <span class="p_context"></span>
<span class="p_add">+#ifndef _ARCH_X86_TLBBATCH_H</span>
<span class="p_add">+#define _ARCH_X86_TLBBATCH_H</span>
<span class="p_add">+</span>
<span class="p_add">+#include &lt;linux/cpumask.h&gt;</span>
<span class="p_add">+</span>
<span class="p_add">+#ifdef CONFIG_SMP</span>
<span class="p_add">+struct arch_tlbflush_unmap_batch {</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Each bit set is a CPU that potentially has a TLB entry for one of</span>
<span class="p_add">+	 * the PFNs being flushed..</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	struct cpumask cpumask;</span>
<span class="p_add">+};</span>
<span class="p_add">+#endif</span>
<span class="p_add">+</span>
<span class="p_add">+#endif /* _ARCH_X86_TLBBATCH_H */</span>
<span class="p_header">diff --git a/arch/x86/include/asm/tlbflush.h b/arch/x86/include/asm/tlbflush.h</span>
<span class="p_header">index 5ed64cdaf536..df71e3f2fe4d 100644</span>
<span class="p_header">--- a/arch/x86/include/asm/tlbflush.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/tlbflush.h</span>
<span class="p_chunk">@@ -329,6 +329,14 @@</span> <span class="p_context"> static inline void reset_lazy_tlbstate(void)</span>
 	this_cpu_write(cpu_tlbstate.active_mm, &amp;init_mm);
 }
 
<span class="p_add">+static inline void arch_tlbbatch_add_mm(struct arch_tlbflush_unmap_batch *batch,</span>
<span class="p_add">+					struct mm_struct *mm)</span>
<span class="p_add">+{</span>
<span class="p_add">+	cpumask_or(&amp;batch-&gt;cpumask, &amp;batch-&gt;cpumask, mm_cpumask(mm));</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+extern void arch_tlbbatch_flush(struct arch_tlbflush_unmap_batch *batch);</span>
<span class="p_add">+</span>
 #endif	/* SMP */
 
 #ifndef CONFIG_PARAVIRT
<span class="p_header">diff --git a/arch/x86/mm/tlb.c b/arch/x86/mm/tlb.c</span>
<span class="p_header">index 4d303864b310..743e4c6b4529 100644</span>
<span class="p_header">--- a/arch/x86/mm/tlb.c</span>
<span class="p_header">+++ b/arch/x86/mm/tlb.c</span>
<span class="p_chunk">@@ -395,6 +395,23 @@</span> <span class="p_context"> void flush_tlb_kernel_range(unsigned long start, unsigned long end)</span>
 	}
 }
 
<span class="p_add">+void arch_tlbbatch_flush(struct arch_tlbflush_unmap_batch *batch)</span>
<span class="p_add">+{</span>
<span class="p_add">+	int cpu = get_cpu();</span>
<span class="p_add">+</span>
<span class="p_add">+	if (cpumask_test_cpu(cpu, &amp;batch-&gt;cpumask)) {</span>
<span class="p_add">+		count_vm_tlb_event(NR_TLB_LOCAL_FLUSH_ALL);</span>
<span class="p_add">+		local_flush_tlb();</span>
<span class="p_add">+		trace_tlb_flush(TLB_LOCAL_SHOOTDOWN, TLB_FLUSH_ALL);</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	if (cpumask_any_but(&amp;batch-&gt;cpumask, cpu) &lt; nr_cpu_ids)</span>
<span class="p_add">+		flush_tlb_others(&amp;batch-&gt;cpumask, NULL, 0, TLB_FLUSH_ALL);</span>
<span class="p_add">+	cpumask_clear(&amp;batch-&gt;cpumask);</span>
<span class="p_add">+</span>
<span class="p_add">+	put_cpu();</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static ssize_t tlbflush_read_file(struct file *file, char __user *user_buf,
 			     size_t count, loff_t *ppos)
 {
<span class="p_header">diff --git a/include/linux/mm_types_task.h b/include/linux/mm_types_task.h</span>
<span class="p_header">index 136dfdf63ba1..fc412fbd80bd 100644</span>
<span class="p_header">--- a/include/linux/mm_types_task.h</span>
<span class="p_header">+++ b/include/linux/mm_types_task.h</span>
<span class="p_chunk">@@ -14,6 +14,10 @@</span> <span class="p_context"></span>
 
 #include &lt;asm/page.h&gt;
 
<span class="p_add">+#ifdef CONFIG_ARCH_WANT_BATCHED_UNMAP_TLB_FLUSH</span>
<span class="p_add">+#include &lt;asm/tlbbatch.h&gt;</span>
<span class="p_add">+#endif</span>
<span class="p_add">+</span>
 #define USE_SPLIT_PTE_PTLOCKS	(NR_CPUS &gt;= CONFIG_SPLIT_PTLOCK_CPUS)
 #define USE_SPLIT_PMD_PTLOCKS	(USE_SPLIT_PTE_PTLOCKS &amp;&amp; \
 		IS_ENABLED(CONFIG_ARCH_ENABLE_SPLIT_PMD_PTLOCK))
<span class="p_chunk">@@ -67,12 +71,15 @@</span> <span class="p_context"> struct page_frag {</span>
 struct tlbflush_unmap_batch {
 #ifdef CONFIG_ARCH_WANT_BATCHED_UNMAP_TLB_FLUSH
 	/*
<span class="p_del">-	 * Each bit set is a CPU that potentially has a TLB entry for one of</span>
<span class="p_del">-	 * the PFNs being flushed. See set_tlb_ubc_flush_pending().</span>
<span class="p_add">+	 * The arch code makes the following promise: generic code can modify a</span>
<span class="p_add">+	 * PTE, then call arch_tlbbatch_add_mm() (which internally provides all</span>
<span class="p_add">+	 * needed barriers), then call arch_tlbbatch_flush(), and the entries</span>
<span class="p_add">+	 * will be flushed on all CPUs by the time that arch_tlbbatch_flush()</span>
<span class="p_add">+	 * returns.</span>
 	 */
<span class="p_del">-	struct cpumask cpumask;</span>
<span class="p_add">+	struct arch_tlbflush_unmap_batch arch;</span>
 
<span class="p_del">-	/* True if any bit in cpumask is set */</span>
<span class="p_add">+	/* True if a flush is needed. */</span>
 	bool flush_required;
 
 	/*
<span class="p_header">diff --git a/mm/rmap.c b/mm/rmap.c</span>
<span class="p_header">index f6838015810f..2e568c82f477 100644</span>
<span class="p_header">--- a/mm/rmap.c</span>
<span class="p_header">+++ b/mm/rmap.c</span>
<span class="p_chunk">@@ -579,25 +579,12 @@</span> <span class="p_context"> void page_unlock_anon_vma_read(struct anon_vma *anon_vma)</span>
 void try_to_unmap_flush(void)
 {
 	struct tlbflush_unmap_batch *tlb_ubc = &amp;current-&gt;tlb_ubc;
<span class="p_del">-	int cpu;</span>
 
 	if (!tlb_ubc-&gt;flush_required)
 		return;
 
<span class="p_del">-	cpu = get_cpu();</span>
<span class="p_del">-</span>
<span class="p_del">-	if (cpumask_test_cpu(cpu, &amp;tlb_ubc-&gt;cpumask)) {</span>
<span class="p_del">-		count_vm_tlb_event(NR_TLB_LOCAL_FLUSH_ALL);</span>
<span class="p_del">-		local_flush_tlb();</span>
<span class="p_del">-		trace_tlb_flush(TLB_LOCAL_SHOOTDOWN, TLB_FLUSH_ALL);</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">-	if (cpumask_any_but(&amp;tlb_ubc-&gt;cpumask, cpu) &lt; nr_cpu_ids)</span>
<span class="p_del">-		flush_tlb_others(&amp;tlb_ubc-&gt;cpumask, NULL, 0, TLB_FLUSH_ALL);</span>
<span class="p_del">-	cpumask_clear(&amp;tlb_ubc-&gt;cpumask);</span>
 	tlb_ubc-&gt;flush_required = false;
 	tlb_ubc-&gt;writable = false;
<span class="p_del">-	put_cpu();</span>
 }
 
 /* Flush iff there are potentially writable TLB entries that can race with IO */
<span class="p_chunk">@@ -613,7 +600,7 @@</span> <span class="p_context"> static void set_tlb_ubc_flush_pending(struct mm_struct *mm, bool writable)</span>
 {
 	struct tlbflush_unmap_batch *tlb_ubc = &amp;current-&gt;tlb_ubc;
 
<span class="p_del">-	cpumask_or(&amp;tlb_ubc-&gt;cpumask, &amp;tlb_ubc-&gt;cpumask, mm_cpumask(mm));</span>
<span class="p_add">+	arch_tlbbatch_add_mm(&amp;tlb_ubc-&gt;arch, mm);</span>
 	tlb_ubc-&gt;flush_required = true;
 
 	/*

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



