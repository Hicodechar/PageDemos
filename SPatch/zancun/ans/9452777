
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>block,blkcg: use __GFP_NOWARN for best-effort allocations in blkcg - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    block,blkcg: use __GFP_NOWARN for best-effort allocations in blkcg</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=137061">Michal Hocko</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>Nov. 29, 2016, 5:13 p.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;20161129171333.GE9796@dhcp22.suse.cz&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/9452777/mbox/"
   >mbox</a>
|
   <a href="/patch/9452777/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/9452777/">/patch/9452777/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
	[172.30.200.125])
	by pdx-korg-patchwork.web.codeaurora.org (Postfix) with ESMTP id
	4B1706071C for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Tue, 29 Nov 2016 17:14:00 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 3A23128391
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Tue, 29 Nov 2016 17:14:00 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id 2EB2E283ED; Tue, 29 Nov 2016 17:14:00 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-6.9 required=2.0 tests=BAYES_00,RCVD_IN_DNSWL_HI
	autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id F09C928391
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Tue, 29 Nov 2016 17:13:58 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1756538AbcK2RNv (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Tue, 29 Nov 2016 12:13:51 -0500
Received: from mail-wm0-f68.google.com ([74.125.82.68]:33064 &quot;EHLO
	mail-wm0-f68.google.com&quot; rhost-flags-OK-OK-OK-OK) by vger.kernel.org
	with ESMTP id S1752159AbcK2RNl (ORCPT
	&lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Tue, 29 Nov 2016 12:13:41 -0500
Received: by mail-wm0-f68.google.com with SMTP id u144so25370189wmu.0
	for &lt;linux-kernel@vger.kernel.org&gt;;
	Tue, 29 Nov 2016 09:13:40 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
	d=1e100.net; s=20130820;
	h=x-gm-message-state:date:from:to:cc:subject:message-id:references
	:mime-version:content-disposition:in-reply-to:user-agent;
	bh=W8YGpL5RXN6CLcItfclilPtvPhBMNins7CbZs8CzuhY=;
	b=K1IJRz/Pltipda5V1Ym+aQDVQ+dk409iRVHqMSdCoNXu2bYtYD7e0esWjvZCYkYqd/
	TQtbtaeTMbZZItz3W1YWW9EGzktRePVhTv2fK+E+jxq+Pvg8v+o8wA3zhqLfz9p6MXCf
	2fhsryMMHj8lVewmKdAToOSYoa3suYl7C/jfnq/mhyAUwUQMq0RsR/1tzp0f/IXYUjst
	NYQo4jJ1HAp1FkttlZX6IHUXMNRkb0z0CF5PPJB+/M7Sfas0Aey55iNd3FivKbHg4UdF
	ytgjI/IBw2+MA5PKeS2zCls2/nWb8UxC6WdeFY+v6mCqYxAJ5bo2oZPPD7J3XSkqVCti
	u7YQ==
X-Gm-Message-State: AKaTC017JYOoA6cR2u7b4+lu1cQdfSHZ9Euic1VoWWYWalxSGlbf0K8dOs2ETqCq1IhL9w==
X-Received: by 10.28.169.4 with SMTP id s4mr23995955wme.65.1480439614719;
	Tue, 29 Nov 2016 09:13:34 -0800 (PST)
Received: from localhost (ip-94-113-214-7.net.upcbroadband.cz.
	[94.113.214.7]) by smtp.gmail.com with ESMTPSA id
	d8sm3764853wmi.21.2016.11.29.09.13.33
	(version=TLS1_2 cipher=ECDHE-RSA-CHACHA20-POLY1305 bits=256/256);
	Tue, 29 Nov 2016 09:13:33 -0800 (PST)
Date: Tue, 29 Nov 2016 18:13:33 +0100
From: Michal Hocko &lt;mhocko@kernel.org&gt;
To: Vlastimil Babka &lt;vbabka@suse.cz&gt;
Cc: Tejun Heo &lt;tj@kernel.org&gt;,
	Linus Torvalds &lt;torvalds@linux-foundation.org&gt;,
	Jens Axboe &lt;axboe@kernel.dk&gt;, linux-mm &lt;linux-mm@kvack.org&gt;,
	LKML &lt;linux-kernel@vger.kernel.org&gt;,
	Joonsoo Kim &lt;iamjoonsoo.kim@lge.com&gt;, Marc MERLIN &lt;marc@merlins.org&gt;
Subject: Re: [PATCH] block,blkcg: use __GFP_NOWARN for best-effort
	allocations in blkcg
Message-ID: &lt;20161129171333.GE9796@dhcp22.suse.cz&gt;
References: &lt;20161121215639.GF13371@merlins.org&gt;
	&lt;20161121230332.GA3767@htj.duckdns.org&gt;
	&lt;7189b1f6-98c3-9a36-83c1-79f2ff4099af@suse.cz&gt;
	&lt;20161122164822.GA5459@htj.duckdns.org&gt;
	&lt;CA+55aFwEik1Q-D0d4pRTNq672RS2eHpT2ULzGfttaSWW69Tajw@mail.gmail.com&gt;
	&lt;3e8eeadb-8dde-2313-f6e3-ef7763832104@suse.cz&gt;
	&lt;20161128171907.GA14754@htj.duckdns.org&gt;
	&lt;20161129072507.GA31671@dhcp22.suse.cz&gt;
	&lt;20161129163807.GB19454@htj.duckdns.org&gt;
	&lt;d50f16b5-296f-9c30-b61a-288aaef49e7e@suse.cz&gt;
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Disposition: inline
In-Reply-To: &lt;d50f16b5-296f-9c30-b61a-288aaef49e7e@suse.cz&gt;
User-Agent: Mutt/1.6.0 (2016-04-01)
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=137061">Michal Hocko</a> - Nov. 29, 2016, 5:13 p.m.</div>
<pre class="content">
On Tue 29-11-16 17:57:08, Vlastimil Babka wrote:
<span class="quote">&gt; On 11/29/2016 05:38 PM, Tejun Heo wrote:</span>
<span class="quote">&gt; &gt; On Tue, Nov 29, 2016 at 08:25:07AM +0100, Michal Hocko wrote:</span>
<span class="quote">&gt; &gt; &gt; --- a/include/linux/gfp.h</span>
<span class="quote">&gt; &gt; &gt; +++ b/include/linux/gfp.h</span>
<span class="quote">&gt; &gt; &gt; @@ -246,7 +246,7 @@ struct vm_area_struct;</span>
<span class="quote">&gt; &gt; &gt;  #define GFP_ATOMIC	(__GFP_HIGH|__GFP_ATOMIC|__GFP_KSWAPD_RECLAIM)</span>
<span class="quote">&gt; &gt; &gt;  #define GFP_KERNEL	(__GFP_RECLAIM | __GFP_IO | __GFP_FS)</span>
<span class="quote">&gt; &gt; &gt;  #define GFP_KERNEL_ACCOUNT (GFP_KERNEL | __GFP_ACCOUNT)</span>
<span class="quote">&gt; &gt; &gt; -#define GFP_NOWAIT	(__GFP_KSWAPD_RECLAIM)</span>
<span class="quote">&gt; &gt; &gt; +#define GFP_NOWAIT	(__GFP_KSWAPD_RECLAIM|__GFP_NOWARN)</span>
<span class="quote">&gt; &gt; &gt;  #define GFP_NOIO	(__GFP_RECLAIM)</span>
<span class="quote">&gt; &gt; &gt;  #define GFP_NOFS	(__GFP_RECLAIM | __GFP_IO)</span>
<span class="quote">&gt; &gt; &gt;  #define GFP_TEMPORARY	(__GFP_RECLAIM | __GFP_IO | __GFP_FS | \</span>
<span class="quote">&gt; &gt; &gt; </span>
<span class="quote">&gt; &gt; &gt; this will not catch users who are doing gfp &amp; ~__GFP_DIRECT_RECLAIM but</span>
<span class="quote">&gt; &gt; &gt; I would rather not make warn_alloc() even more cluttered with checks.</span>
<span class="quote">&gt; &gt; </span>
<span class="quote">&gt; &gt; Yeah, FWIW, looks good to me.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Me too. Just don&#39;t forget to update the comment describing GFP_NOWAIT and</span>
<span class="quote">&gt; check the existing users if duplicite __GFP_NOWARN can be removed, and if</span>
<span class="quote">&gt; they really want to be doing GFP_NOWAIT and not GFP_ATOMIC.</span>

How does this look like?
---
From c6635f7fedec1fc475da0a4be32ea360560cde18 Mon Sep 17 00:00:00 2001
<span class="from">From: Michal Hocko &lt;mhocko@suse.com&gt;</span>
Date: Tue, 29 Nov 2016 18:04:00 +0100
Subject: [PATCH] mm: do not warn about allocation failures for GFP_NOWAIT

Historically we didn&#39;t have a distinction between atomic allocation
requests and those which just do not want to sleep for other (e.g.
performance optimization reasons). After d0164adc89f6 (&quot;mm, page_alloc:
distinguish between being unable to sleep, unwilling to sleep and
avoiding waking kswapd&quot;) this distinction is clear.

Nevertheless we still have quite some GFP_NOWAIT requests without
__GFP_NOWARN so the system log will contain scary and rarely useful
allocation failure splats. Those allocations are to be expected to fail
under a memory pressure (especially when the kswapd doesn&#39;t catch up
with the load). GFP_ATOMIC is different in this regards because it
allows an access to part of the memory reserves which sould make it much
less likely to fail and actual reports could help to tune the system
better - e.g. by increasing the amount of memory reserves for a better
performance. This is not true for GFP_NOWAIT though.

This patch simply makes __GFP_NOWARN implicit to all GFP_NOWAIT requests
to silent them all. Those which used the explicit NOWARN were removed.

Suggested-by: Vlastimil Babka &lt;vbabka@suse.cz&gt;
<span class="signed-off-by">Signed-off-by: Michal Hocko &lt;mhocko@suse.com&gt;</span>
---
 arch/arm/include/asm/tlb.h      | 2 +-
 arch/ia64/include/asm/tlb.h     | 2 +-
 arch/s390/mm/pgalloc.c          | 2 +-
 drivers/dma-buf/reservation.c   | 3 +--
 drivers/md/bcache/bset.c        | 3 +--
 drivers/md/bcache/btree.c       | 2 +-
 fs/fs-writeback.c               | 2 +-
 include/linux/gfp.h             | 5 +++--
 kernel/events/uprobes.c         | 2 +-
 mm/memory.c                     | 4 ++--
 mm/rmap.c                       | 2 +-
 net/ipv4/tcp_cdg.c              | 2 +-
 net/sunrpc/sched.c              | 2 +-
 net/sunrpc/xprt.c               | 2 +-
 net/sunrpc/xprtrdma/transport.c | 2 +-
 virt/kvm/async_pf.c             | 2 +-
 16 files changed, 19 insertions(+), 20 deletions(-)
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=77">Linus Torvalds</a> - Nov. 29, 2016, 5:17 p.m.</div>
<pre class="content">
On Tue, Nov 29, 2016 at 9:13 AM, Michal Hocko &lt;mhocko@kernel.org&gt; wrote:
<span class="quote">&gt; How does this look like?</span>

No.

I *really* want people to write out that &quot;I am ok with the allocation failing&quot;.

It&#39;s not an &quot;inconvenience&quot;. It&#39;s a sign that you are competent and
that you know it will fail, and that you can handle it.

If you don&#39;t show that you know that, we warn about it.

And no, &quot;GFP_NOWAIT&quot; does *not* mean &quot;I have a good fallback&quot;.

             Linus
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=137061">Michal Hocko</a> - Nov. 29, 2016, 5:28 p.m.</div>
<pre class="content">
On Tue 29-11-16 09:17:37, Linus Torvalds wrote:
<span class="quote">&gt; On Tue, Nov 29, 2016 at 9:13 AM, Michal Hocko &lt;mhocko@kernel.org&gt; wrote:</span>
<span class="quote">&gt; &gt; How does this look like?</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; No.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; I *really* want people to write out that &quot;I am ok with the allocation failing&quot;.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; It&#39;s not an &quot;inconvenience&quot;. It&#39;s a sign that you are competent and</span>
<span class="quote">&gt; that you know it will fail, and that you can handle it.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; If you don&#39;t show that you know that, we warn about it.</span>

How does this warning help those who are watching the logs? What are
they supposed to do about it? Unlike GFP_ATOMIC there is no tuning you
can possibly do.

From my experience people tend to report those and worry about them
(quite often confusing them with the real OOM) and we usually only can
explain that this is nothing to worry about... And so then we sprinkle
GFP_NOWARN all over the place as we hit those. Is this really what we
want?
<span class="quote">
&gt; And no, &quot;GFP_NOWAIT&quot; does *not* mean &quot;I have a good fallback&quot;.</span>

I am confused, how can anybody _rely_ on GFP_NOWAIT to succeed?
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=77">Linus Torvalds</a> - Nov. 29, 2016, 5:48 p.m.</div>
<pre class="content">
On Tue, Nov 29, 2016 at 9:28 AM, Michal Hocko &lt;mhocko@kernel.org&gt; wrote:
<span class="quote">&gt; How does this warning help those who are watching the logs? What are</span>
<span class="quote">&gt; they supposed to do about it? Unlike GFP_ATOMIC there is no tuning you</span>
<span class="quote">&gt; can possibly do.</span>

You can report it and it will get fixed.

It&#39;s not about tuning. It&#39;s about people like Tejun who made changes
and didn&#39;t do them right.

In other words, exactly the patch that this whole thread started with.

Except that because of the idiotic arguments about the *obvious*
patch, the patch gets delayed and not applied.

The whole __GFP_NOWARN thing is not some kind of newfangled thing that
suddenly became a problem. It&#39;s been there for decades. Why are you
arguing for stupidly removing it now?
<span class="quote">
&gt; I am confused, how can anybody _rely_ on GFP_NOWAIT to succeed?</span>

You can&#39;t (except perhaps during bootup).

BUT YOU HAVE TO HAVE A FALLBACK, AND SHOW THAT YOU ARE *AWARE* THAT
YOU CAN&quot;T RELY ON IT.

Christ. What&#39;s so hard to understand about this?

And no, GFP_NOWAIT is not special. Higher orders have the exact same
issue. And they too need that __GFP_NOWARN to show that &quot;yes, I know,
and yes, I have a fallback strategy&quot;.

Because that warning shows real bugs. Seriously. We had fix for this
pending for 4.10 already (nfsd just blithely assuming it can do big
allocations).

So stop the idiotic arguments. The whole point is that lots of people
don&#39;t think about allocations failing (and NOWAIT and friends do not
change that ONE WHIT), and __GFP_NOWARN is there exactly to show that
you thought about them.

The warning _has_ been useful. We&#39;re not hiding it by default, because
that makes the whole warning pointless.

Really.

                Linus
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/arch/arm/include/asm/tlb.h b/arch/arm/include/asm/tlb.h</span>
<span class="p_header">index 1e25cd80589e..5b173836df23 100644</span>
<span class="p_header">--- a/arch/arm/include/asm/tlb.h</span>
<span class="p_header">+++ b/arch/arm/include/asm/tlb.h</span>
<span class="p_chunk">@@ -117,7 +117,7 @@</span> <span class="p_context"> static inline void tlb_add_flush(struct mmu_gather *tlb, unsigned long addr)</span>
 
 static inline void __tlb_alloc_page(struct mmu_gather *tlb)
 {
<span class="p_del">-	unsigned long addr = __get_free_pages(GFP_NOWAIT | __GFP_NOWARN, 0);</span>
<span class="p_add">+	unsigned long addr = __get_free_pages(GFP_NOWAIT, 0);</span>
 
 	if (addr) {
 		tlb-&gt;pages = (void *)addr;
<span class="p_header">diff --git a/arch/ia64/include/asm/tlb.h b/arch/ia64/include/asm/tlb.h</span>
<span class="p_header">index 77e541cf0e5d..7dfabd37c993 100644</span>
<span class="p_header">--- a/arch/ia64/include/asm/tlb.h</span>
<span class="p_header">+++ b/arch/ia64/include/asm/tlb.h</span>
<span class="p_chunk">@@ -158,7 +158,7 @@</span> <span class="p_context"> ia64_tlb_flush_mmu (struct mmu_gather *tlb, unsigned long start, unsigned long e</span>
 
 static inline void __tlb_alloc_page(struct mmu_gather *tlb)
 {
<span class="p_del">-	unsigned long addr = __get_free_pages(GFP_NOWAIT | __GFP_NOWARN, 0);</span>
<span class="p_add">+	unsigned long addr = __get_free_pages(GFP_NOWAIT, 0);</span>
 
 	if (addr) {
 		tlb-&gt;pages = (void *)addr;
<span class="p_header">diff --git a/arch/s390/mm/pgalloc.c b/arch/s390/mm/pgalloc.c</span>
<span class="p_header">index 995f78532cc2..1e5adc76f7dd 100644</span>
<span class="p_header">--- a/arch/s390/mm/pgalloc.c</span>
<span class="p_header">+++ b/arch/s390/mm/pgalloc.c</span>
<span class="p_chunk">@@ -340,7 +340,7 @@</span> <span class="p_context"> void tlb_remove_table(struct mmu_gather *tlb, void *table)</span>
 	tlb-&gt;mm-&gt;context.flush_mm = 1;
 	if (*batch == NULL) {
 		*batch = (struct mmu_table_batch *)
<span class="p_del">-			__get_free_page(GFP_NOWAIT | __GFP_NOWARN);</span>
<span class="p_add">+			__get_free_page(GFP_NOWAIT);</span>
 		if (*batch == NULL) {
 			__tlb_flush_mm_lazy(tlb-&gt;mm);
 			tlb_remove_table_one(table);
<span class="p_header">diff --git a/drivers/dma-buf/reservation.c b/drivers/dma-buf/reservation.c</span>
<span class="p_header">index 9566a62ad8e3..2715258ef1db 100644</span>
<span class="p_header">--- a/drivers/dma-buf/reservation.c</span>
<span class="p_header">+++ b/drivers/dma-buf/reservation.c</span>
<span class="p_chunk">@@ -298,8 +298,7 @@</span> <span class="p_context"> int reservation_object_get_fences_rcu(struct reservation_object *obj,</span>
 			struct fence **nshared;
 			size_t sz = sizeof(*shared) * fobj-&gt;shared_max;
 
<span class="p_del">-			nshared = krealloc(shared, sz,</span>
<span class="p_del">-					   GFP_NOWAIT | __GFP_NOWARN);</span>
<span class="p_add">+			nshared = krealloc(shared, sz, GFP_NOWAIT);</span>
 			if (!nshared) {
 				rcu_read_unlock();
 				nshared = krealloc(shared, sz, GFP_KERNEL);
<span class="p_header">diff --git a/drivers/md/bcache/bset.c b/drivers/md/bcache/bset.c</span>
<span class="p_header">index 646fe85261c1..0a9b6a91f5b9 100644</span>
<span class="p_header">--- a/drivers/md/bcache/bset.c</span>
<span class="p_header">+++ b/drivers/md/bcache/bset.c</span>
<span class="p_chunk">@@ -1182,8 +1182,7 @@</span> <span class="p_context"> static void __btree_sort(struct btree_keys *b, struct btree_iter *iter,</span>
 {
 	uint64_t start_time;
 	bool used_mempool = false;
<span class="p_del">-	struct bset *out = (void *) __get_free_pages(__GFP_NOWARN|GFP_NOWAIT,</span>
<span class="p_del">-						     order);</span>
<span class="p_add">+	struct bset *out = (void *) __get_free_pages(GFP_NOWAIT, order);</span>
 	if (!out) {
 		struct page *outp;
 
<span class="p_header">diff --git a/drivers/md/bcache/btree.c b/drivers/md/bcache/btree.c</span>
<span class="p_header">index 76f7534d1dd1..54355099dd14 100644</span>
<span class="p_header">--- a/drivers/md/bcache/btree.c</span>
<span class="p_header">+++ b/drivers/md/bcache/btree.c</span>
<span class="p_chunk">@@ -419,7 +419,7 @@</span> <span class="p_context"> static void do_btree_node_write(struct btree *b)</span>
 	SET_PTR_OFFSET(&amp;k.key, 0, PTR_OFFSET(&amp;k.key, 0) +
 		       bset_sector_offset(&amp;b-&gt;keys, i));
 
<span class="p_del">-	if (!bio_alloc_pages(b-&gt;bio, __GFP_NOWARN|GFP_NOWAIT)) {</span>
<span class="p_add">+	if (!bio_alloc_pages(b-&gt;bio, GFP_NOWAIT)) {</span>
 		int j;
 		struct bio_vec *bv;
 		void *base = (void *) ((unsigned long) i &amp; ~(PAGE_SIZE - 1));
<span class="p_header">diff --git a/fs/fs-writeback.c b/fs/fs-writeback.c</span>
<span class="p_header">index 05713a5da083..ae46eebd56be 100644</span>
<span class="p_header">--- a/fs/fs-writeback.c</span>
<span class="p_header">+++ b/fs/fs-writeback.c</span>
<span class="p_chunk">@@ -932,7 +932,7 @@</span> <span class="p_context"> void wb_start_writeback(struct bdi_writeback *wb, long nr_pages,</span>
 	 * wakeup the thread for old dirty data writeback
 	 */
 	work = kzalloc(sizeof(*work),
<span class="p_del">-		       GFP_NOWAIT | __GFP_NOMEMALLOC | __GFP_NOWARN);</span>
<span class="p_add">+		       GFP_NOWAIT | __GFP_NOMEMALLOC);</span>
 	if (!work) {
 		trace_writeback_nowork(wb);
 		wb_wakeup(wb);
<span class="p_header">diff --git a/include/linux/gfp.h b/include/linux/gfp.h</span>
<span class="p_header">index f8041f9de31e..2579a9abbc38 100644</span>
<span class="p_header">--- a/include/linux/gfp.h</span>
<span class="p_header">+++ b/include/linux/gfp.h</span>
<span class="p_chunk">@@ -205,7 +205,8 @@</span> <span class="p_context"> struct vm_area_struct;</span>
  *   accounted to kmemcg.
  *
  * GFP_NOWAIT is for kernel allocations that should not stall for direct
<span class="p_del">- *   reclaim, start physical IO or use any filesystem callback.</span>
<span class="p_add">+ *   reclaim, start physical IO or use any filesystem callback. These are</span>
<span class="p_add">+ *   quite likely to fail under memory pressure.</span>
  *
  * GFP_NOIO will use direct reclaim to discard clean pages or slab pages
  *   that do not require the starting of any physical IO.
<span class="p_chunk">@@ -246,7 +247,7 @@</span> <span class="p_context"> struct vm_area_struct;</span>
 #define GFP_ATOMIC	(__GFP_HIGH|__GFP_ATOMIC|__GFP_KSWAPD_RECLAIM)
 #define GFP_KERNEL	(__GFP_RECLAIM | __GFP_IO | __GFP_FS)
 #define GFP_KERNEL_ACCOUNT (GFP_KERNEL | __GFP_ACCOUNT)
<span class="p_del">-#define GFP_NOWAIT	(__GFP_KSWAPD_RECLAIM)</span>
<span class="p_add">+#define GFP_NOWAIT	(__GFP_KSWAPD_RECLAIM | __GFP_NOWARN)</span>
 #define GFP_NOIO	(__GFP_RECLAIM)
 #define GFP_NOFS	(__GFP_RECLAIM | __GFP_IO)
 #define GFP_TEMPORARY	(__GFP_RECLAIM | __GFP_IO | __GFP_FS | \
<span class="p_header">diff --git a/kernel/events/uprobes.c b/kernel/events/uprobes.c</span>
<span class="p_header">index 19417719fde7..3013df303461 100644</span>
<span class="p_header">--- a/kernel/events/uprobes.c</span>
<span class="p_header">+++ b/kernel/events/uprobes.c</span>
<span class="p_chunk">@@ -732,7 +732,7 @@</span> <span class="p_context"> build_map_info(struct address_space *mapping, loff_t offset, bool is_register)</span>
 			 * reclaim. This is optimistic, no harm done if it fails.
 			 */
 			prev = kmalloc(sizeof(struct map_info),
<span class="p_del">-					GFP_NOWAIT | __GFP_NOMEMALLOC | __GFP_NOWARN);</span>
<span class="p_add">+					GFP_NOWAIT | __GFP_NOMEMALLOC);</span>
 			if (prev)
 				prev-&gt;next = NULL;
 		}
<span class="p_header">diff --git a/mm/memory.c b/mm/memory.c</span>
<span class="p_header">index 840adc6e05d6..13fa563e90e1 100644</span>
<span class="p_header">--- a/mm/memory.c</span>
<span class="p_header">+++ b/mm/memory.c</span>
<span class="p_chunk">@@ -197,7 +197,7 @@</span> <span class="p_context"> static bool tlb_next_batch(struct mmu_gather *tlb)</span>
 	if (tlb-&gt;batch_count == MAX_GATHER_BATCH_COUNT)
 		return false;
 
<span class="p_del">-	batch = (void *)__get_free_pages(GFP_NOWAIT | __GFP_NOWARN, 0);</span>
<span class="p_add">+	batch = (void *)__get_free_pages(GFP_NOWAIT, 0);</span>
 	if (!batch)
 		return false;
 
<span class="p_chunk">@@ -383,7 +383,7 @@</span> <span class="p_context"> void tlb_remove_table(struct mmu_gather *tlb, void *table)</span>
 	}
 
 	if (*batch == NULL) {
<span class="p_del">-		*batch = (struct mmu_table_batch *)__get_free_page(GFP_NOWAIT | __GFP_NOWARN);</span>
<span class="p_add">+		*batch = (struct mmu_table_batch *)__get_free_page(GFP_NOWAIT);</span>
 		if (*batch == NULL) {
 			tlb_remove_table_one(table);
 			return;
<span class="p_header">diff --git a/mm/rmap.c b/mm/rmap.c</span>
<span class="p_header">index 1ef36404e7b2..004abc7c2cff 100644</span>
<span class="p_header">--- a/mm/rmap.c</span>
<span class="p_header">+++ b/mm/rmap.c</span>
<span class="p_chunk">@@ -263,7 +263,7 @@</span> <span class="p_context"> int anon_vma_clone(struct vm_area_struct *dst, struct vm_area_struct *src)</span>
 	list_for_each_entry_reverse(pavc, &amp;src-&gt;anon_vma_chain, same_vma) {
 		struct anon_vma *anon_vma;
 
<span class="p_del">-		avc = anon_vma_chain_alloc(GFP_NOWAIT | __GFP_NOWARN);</span>
<span class="p_add">+		avc = anon_vma_chain_alloc(GFP_NOWAIT);</span>
 		if (unlikely(!avc)) {
 			unlock_anon_vma_root(root);
 			root = NULL;
<span class="p_header">diff --git a/net/ipv4/tcp_cdg.c b/net/ipv4/tcp_cdg.c</span>
<span class="p_header">index 03725b294286..e2621acc54e8 100644</span>
<span class="p_header">--- a/net/ipv4/tcp_cdg.c</span>
<span class="p_header">+++ b/net/ipv4/tcp_cdg.c</span>
<span class="p_chunk">@@ -385,7 +385,7 @@</span> <span class="p_context"> static void tcp_cdg_init(struct sock *sk)</span>
 	/* We silently fall back to window = 1 if allocation fails. */
 	if (window &gt; 1)
 		ca-&gt;gradients = kcalloc(window, sizeof(ca-&gt;gradients[0]),
<span class="p_del">-					GFP_NOWAIT | __GFP_NOWARN);</span>
<span class="p_add">+					GFP_NOWAIT);</span>
 	ca-&gt;rtt_seq = tp-&gt;snd_nxt;
 	ca-&gt;shadow_wnd = tp-&gt;snd_cwnd;
 }
<span class="p_header">diff --git a/net/sunrpc/sched.c b/net/sunrpc/sched.c</span>
<span class="p_header">index 9ae588511aaf..791fd3fe4995 100644</span>
<span class="p_header">--- a/net/sunrpc/sched.c</span>
<span class="p_header">+++ b/net/sunrpc/sched.c</span>
<span class="p_chunk">@@ -871,7 +871,7 @@</span> <span class="p_context"> void *rpc_malloc(struct rpc_task *task, size_t size)</span>
 	gfp_t gfp = GFP_NOIO | __GFP_NOWARN;
 
 	if (RPC_IS_SWAPPER(task))
<span class="p_del">-		gfp = __GFP_MEMALLOC | GFP_NOWAIT | __GFP_NOWARN;</span>
<span class="p_add">+		gfp = __GFP_MEMALLOC | GFP_NOWAIT;</span>
 
 	size += sizeof(struct rpc_buffer);
 	if (size &lt;= RPC_BUFFER_MAXSIZE)
<span class="p_header">diff --git a/net/sunrpc/xprt.c b/net/sunrpc/xprt.c</span>
<span class="p_header">index ea244b29138b..3a4e13282f4e 100644</span>
<span class="p_header">--- a/net/sunrpc/xprt.c</span>
<span class="p_header">+++ b/net/sunrpc/xprt.c</span>
<span class="p_chunk">@@ -1081,7 +1081,7 @@</span> <span class="p_context"> void xprt_alloc_slot(struct rpc_xprt *xprt, struct rpc_task *task)</span>
 		list_del(&amp;req-&gt;rq_list);
 		goto out_init_req;
 	}
<span class="p_del">-	req = xprt_dynamic_alloc_slot(xprt, GFP_NOWAIT|__GFP_NOWARN);</span>
<span class="p_add">+	req = xprt_dynamic_alloc_slot(xprt, GFP_NOWAIT);</span>
 	if (!IS_ERR(req))
 		goto out_init_req;
 	switch (PTR_ERR(req)) {
<span class="p_header">diff --git a/net/sunrpc/xprtrdma/transport.c b/net/sunrpc/xprtrdma/transport.c</span>
<span class="p_header">index 81f0e879f019..c22ed3b7bf61 100644</span>
<span class="p_header">--- a/net/sunrpc/xprtrdma/transport.c</span>
<span class="p_header">+++ b/net/sunrpc/xprtrdma/transport.c</span>
<span class="p_chunk">@@ -502,7 +502,7 @@</span> <span class="p_context"> xprt_rdma_allocate(struct rpc_task *task, size_t size)</span>
 
 	flags = RPCRDMA_DEF_GFP;
 	if (RPC_IS_SWAPPER(task))
<span class="p_del">-		flags = __GFP_MEMALLOC | GFP_NOWAIT | __GFP_NOWARN;</span>
<span class="p_add">+		flags = __GFP_MEMALLOC | GFP_NOWAIT;</span>
 
 	if (req-&gt;rl_rdmabuf == NULL)
 		goto out_rdmabuf;
<span class="p_header">diff --git a/virt/kvm/async_pf.c b/virt/kvm/async_pf.c</span>
<span class="p_header">index 8035cc1eb955..99209775818f 100644</span>
<span class="p_header">--- a/virt/kvm/async_pf.c</span>
<span class="p_header">+++ b/virt/kvm/async_pf.c</span>
<span class="p_chunk">@@ -179,7 +179,7 @@</span> <span class="p_context"> int kvm_setup_async_pf(struct kvm_vcpu *vcpu, gva_t gva, unsigned long hva,</span>
 	 * do alloc nowait since if we are going to sleep anyway we
 	 * may as well sleep faulting in page
 	 */
<span class="p_del">-	work = kmem_cache_zalloc(async_pf_cache, GFP_NOWAIT | __GFP_NOWARN);</span>
<span class="p_add">+	work = kmem_cache_zalloc(async_pf_cache, GFP_NOWAIT);</span>
 	if (!work)
 		return 0;
 

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



