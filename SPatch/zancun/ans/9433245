
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>proc: mm: export PTE sizes directly in smaps (v2) - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    proc: mm: export PTE sizes directly in smaps (v2)</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=2302">Dave Hansen</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>Nov. 17, 2016, 12:28 a.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;20161117002851.C7BACB98@viggo.jf.intel.com&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/9433245/mbox/"
   >mbox</a>
|
   <a href="/patch/9433245/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/9433245/">/patch/9433245/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
	[172.30.200.125])
	by pdx-korg-patchwork.web.codeaurora.org (Postfix) with ESMTP id
	B60A76021C for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Thu, 17 Nov 2016 00:29:17 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id A6CA129198
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Thu, 17 Nov 2016 00:29:17 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id 9B59C291AF; Thu, 17 Nov 2016 00:29:17 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-6.9 required=2.0 tests=BAYES_00,RCVD_IN_DNSWL_HI
	autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id D04FE29198
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Thu, 17 Nov 2016 00:29:16 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S937085AbcKQA3B (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Wed, 16 Nov 2016 19:29:01 -0500
Received: from mga14.intel.com ([192.55.52.115]:20909 &quot;EHLO mga14.intel.com&quot;
	rhost-flags-OK-OK-OK-OK) by vger.kernel.org with ESMTP
	id S932212AbcKQA26 (ORCPT &lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Wed, 16 Nov 2016 19:28:58 -0500
Received: from orsmga004.jf.intel.com ([10.7.209.38])
	by fmsmga103.fm.intel.com with ESMTP; 16 Nov 2016 16:28:52 -0800
X-ExtLoop1: 1
X-IronPort-AV: E=Sophos;i=&quot;5.31,650,1473145200&quot;; d=&quot;scan&#39;208&quot;;a=&quot;31728750&quot;
Received: from viggo.jf.intel.com (HELO localhost.localdomain)
	([10.54.39.121])
	by orsmga004.jf.intel.com with ESMTP; 16 Nov 2016 16:28:52 -0800
Subject: [PATCH] proc: mm: export PTE sizes directly in smaps (v2)
To: linux-kernel@vger.kernel.org
Cc: Dave Hansen &lt;dave@sr71.net&gt;, hch@lst.de, akpm@linux-foundation.org,
	dan.j.williams@intel.com, khandual@linux.vnet.ibm.com, linux-mm@kvack.org
From: Dave Hansen &lt;dave@sr71.net&gt;
Date: Wed, 16 Nov 2016 16:28:51 -0800
Message-Id: &lt;20161117002851.C7BACB98@viggo.jf.intel.com&gt;
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=2302">Dave Hansen</a> - Nov. 17, 2016, 12:28 a.m.</div>
<pre class="content">
Changes from v1:
 * Do one &#39;Pte&#39; line per pte size instead of mashing on one line
 * Use PMD_SIZE for pmds instead of PAGE_SIZE, whoops
 * Wrote some Documentation/

--

/proc/$pid/smaps has a number of fields that are intended to imply the
kinds of PTEs used to map memory.  &quot;AnonHugePages&quot; obviously tells you
how many PMDs are being used.  &quot;MMUPageSize&quot; along with the &quot;Hugetlb&quot;
fields tells you how many PTEs you have for a huge page.

The current mechanisms work fine when we have one or two page sizes.
But, they start to get a bit muddled when we mix page sizes inside
one VMA.  For instance, the DAX folks were proposing adding a set of
fields like:

	DevicePages:
	DeviceHugePages:
	DeviceGiganticPages:
	DeviceGinormousPages:

to unmuddle things when page sizes get mixed.  That&#39;s fine, but
it does require userspace know the mapping from our various
arbitrary names to hardware page sizes on each architecture and
kernel configuration.  That seems rather suboptimal.

What folks really want is to know how much memory is mapped with
each page size.  How about we just do *that*?

Patch attached.  Seems harmless enough.  Seems to compile on a
bunch of random architectures.  Makes smaps look like this:

Private_Hugetlb:       0 kB
Swap:                  0 kB
SwapPss:               0 kB
KernelPageSize:        4 kB
MMUPageSize:           4 kB
Locked:                0 kB
Ptes@4kB:	      32 kB
Ptes@2MB:	    2048 kB

The format I used here should be unlikely to break smaps parsers
unless they&#39;re looking for &quot;kB&quot; and now match the &#39;Ptes@4kB&#39; instead
of the one at the end of the line.

1. I&#39;d like to thank Dan Williams for showing me a mirror as I
   complained about the bozo that introduced &#39;AnonHugePages&#39;.

Cc: Christoph Hellwig &lt;hch@lst.de&gt;
Cc: Andrew Morton &lt;akpm@linux-foundation.org&gt;
Cc: Dan Williams &lt;dan.j.williams@intel.com&gt;
Cc: Anshuman Khandual &lt;khandual@linux.vnet.ibm.com&gt;
Cc: linux-mm@kvack.org

---

 b/Documentation/filesystems/proc.txt |    6 ++
 b/fs/proc/task_mmu.c                 |   81 ++++++++++++++++++++++++++++++++++-
 2 files changed, 85 insertions(+), 2 deletions(-)
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=72672">Vlastimil Babka</a> - Nov. 24, 2016, 2:22 p.m.</div>
<pre class="content">
On 11/17/2016 01:28 AM, Dave Hansen wrote:
<span class="quote">&gt; Changes from v1:</span>
<span class="quote">&gt;  * Do one &#39;Pte&#39; line per pte size instead of mashing on one line</span>
<span class="quote">&gt;  * Use PMD_SIZE for pmds instead of PAGE_SIZE, whoops</span>
<span class="quote">&gt;  * Wrote some Documentation/</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; --</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; /proc/$pid/smaps has a number of fields that are intended to imply the</span>
<span class="quote">&gt; kinds of PTEs used to map memory.  &quot;AnonHugePages&quot; obviously tells you</span>
<span class="quote">&gt; how many PMDs are being used.  &quot;MMUPageSize&quot; along with the &quot;Hugetlb&quot;</span>
<span class="quote">&gt; fields tells you how many PTEs you have for a huge page.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; The current mechanisms work fine when we have one or two page sizes.</span>
<span class="quote">&gt; But, they start to get a bit muddled when we mix page sizes inside</span>
<span class="quote">&gt; one VMA.  For instance, the DAX folks were proposing adding a set of</span>
<span class="quote">&gt; fields like:</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; 	DevicePages:</span>
<span class="quote">&gt; 	DeviceHugePages:</span>
<span class="quote">&gt; 	DeviceGiganticPages:</span>
<span class="quote">&gt; 	DeviceGinormousPages:</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; to unmuddle things when page sizes get mixed.  That&#39;s fine, but</span>
<span class="quote">&gt; it does require userspace know the mapping from our various</span>
<span class="quote">&gt; arbitrary names to hardware page sizes on each architecture and</span>
<span class="quote">&gt; kernel configuration.  That seems rather suboptimal.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; What folks really want is to know how much memory is mapped with</span>
<span class="quote">&gt; each page size.  How about we just do *that*?</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; Patch attached.  Seems harmless enough.  Seems to compile on a</span>
<span class="quote">&gt; bunch of random architectures.  Makes smaps look like this:</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; Private_Hugetlb:       0 kB</span>
<span class="quote">&gt; Swap:                  0 kB</span>
<span class="quote">&gt; SwapPss:               0 kB</span>
<span class="quote">&gt; KernelPageSize:        4 kB</span>
<span class="quote">&gt; MMUPageSize:           4 kB</span>
<span class="quote">&gt; Locked:                0 kB</span>
<span class="quote">&gt; Ptes@4kB:	      32 kB</span>
<span class="quote">&gt; Ptes@2MB:	    2048 kB</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; The format I used here should be unlikely to break smaps parsers</span>
<span class="quote">&gt; unless they&#39;re looking for &quot;kB&quot; and now match the &#39;Ptes@4kB&#39; instead</span>
<span class="quote">&gt; of the one at the end of the line.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; 1. I&#39;d like to thank Dan Williams for showing me a mirror as I</span>
<span class="quote">&gt;    complained about the bozo that introduced &#39;AnonHugePages&#39;.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; Cc: Christoph Hellwig &lt;hch@lst.de&gt;</span>
<span class="quote">&gt; Cc: Andrew Morton &lt;akpm@linux-foundation.org&gt;</span>
<span class="quote">&gt; Cc: Dan Williams &lt;dan.j.williams@intel.com&gt;</span>
<span class="quote">&gt; Cc: Anshuman Khandual &lt;khandual@linux.vnet.ibm.com&gt;</span>
<span class="quote">&gt; Cc: linux-mm@kvack.org</span>

Hmm, why not, I guess. But are HugeTLBs handled correctly?
<span class="quote">
&gt; @@ -702,11 +707,13 @@ static int smaps_hugetlb_range(pte_t *pt</span>
<span class="quote">&gt;  	}</span>
<span class="quote">&gt;  	if (page) {</span>
<span class="quote">&gt;  		int mapcount = page_mapcount(page);</span>
<span class="quote">&gt; +		unsigned long hpage_size = huge_page_size(hstate_vma(vma));</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; +		mss-&gt;rss_pud += hpage_size;</span>

This hardcoded pud doesn&#39;t look right, doesn&#39;t the pmd/pud depend on 
hpage_size?
<span class="quote">
&gt;  		if (mapcount &gt;= 2)</span>
<span class="quote">&gt; -			mss-&gt;shared_hugetlb += huge_page_size(hstate_vma(vma));</span>
<span class="quote">&gt; +			mss-&gt;shared_hugetlb += hpage_size;</span>
<span class="quote">&gt;  		else</span>
<span class="quote">&gt; -			mss-&gt;private_hugetlb += huge_page_size(hstate_vma(vma));</span>
<span class="quote">&gt; +			mss-&gt;private_hugetlb += hpage_size;</span>
<span class="quote">&gt;  	}</span>
<span class="quote">&gt;  	return 0;</span>
<span class="quote">&gt;  }</span>
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=36302">Anshuman Khandual</a> - Nov. 25, 2016, 4 a.m.</div>
<pre class="content">
On 11/17/2016 05:58 AM, Dave Hansen wrote:
<span class="quote">&gt; Changes from v1:</span>
<span class="quote">&gt;  * Do one &#39;Pte&#39; line per pte size instead of mashing on one line</span>
<span class="quote">&gt;  * Use PMD_SIZE for pmds instead of PAGE_SIZE, whoops</span>
<span class="quote">&gt;  * Wrote some Documentation/</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; --</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; /proc/$pid/smaps has a number of fields that are intended to imply the</span>
<span class="quote">&gt; kinds of PTEs used to map memory.  &quot;AnonHugePages&quot; obviously tells you</span>
<span class="quote">&gt; how many PMDs are being used.  &quot;MMUPageSize&quot; along with the &quot;Hugetlb&quot;</span>
<span class="quote">&gt; fields tells you how many PTEs you have for a huge page.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; The current mechanisms work fine when we have one or two page sizes.</span>
<span class="quote">&gt; But, they start to get a bit muddled when we mix page sizes inside</span>
<span class="quote">&gt; one VMA.  For instance, the DAX folks were proposing adding a set of</span>
<span class="quote">&gt; fields like:</span>

So DAX is only case which creates this scenario of multi page sizes in
the same VMA ? Is there any cases other than DAX mapping ?
<span class="quote">
&gt; </span>
<span class="quote">&gt; 	DevicePages:</span>
<span class="quote">&gt; 	DeviceHugePages:</span>
<span class="quote">&gt; 	DeviceGiganticPages:</span>
<span class="quote">&gt; 	DeviceGinormousPages:</span>

I guess these are the page sizes supported at PTE, PMD, PUD, PGD level.
Are all these page sizes supported right now or we are just creating
place holder for future.
<span class="quote">
&gt; </span>
<span class="quote">&gt; to unmuddle things when page sizes get mixed.  That&#39;s fine, but</span>
<span class="quote">&gt; it does require userspace know the mapping from our various</span>
<span class="quote">&gt; arbitrary names to hardware page sizes on each architecture and</span>
<span class="quote">&gt; kernel configuration.  That seems rather suboptimal.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; What folks really want is to know how much memory is mapped with</span>
<span class="quote">&gt; each page size.  How about we just do *that*?</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Patch attached.  Seems harmless enough.  Seems to compile on a</span>
<span class="quote">&gt; bunch of random architectures.  Makes smaps look like this:</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Private_Hugetlb:       0 kB</span>
<span class="quote">&gt; Swap:                  0 kB</span>
<span class="quote">&gt; SwapPss:               0 kB</span>
<span class="quote">&gt; KernelPageSize:        4 kB</span>
<span class="quote">&gt; MMUPageSize:           4 kB</span>
<span class="quote">&gt; Locked:                0 kB</span>
<span class="quote">&gt; Ptes@4kB:	      32 kB</span>
<span class="quote">&gt; Ptes@2MB:	    2048 kB</span>

So in the left column we are explicitly indicating the size of the PTE
and expect the user to figure out where it can really be either at PTE,
PMD, PUD etc. Thats little bit different that &#39;AnonHugePages&#39; or the
Shared_HugeTLB/Private_HugeTLB pages which we know are the the PMD/PUD
level.
<span class="quote">
&gt; </span>
<span class="quote">&gt; The format I used here should be unlikely to break smaps parsers</span>
<span class="quote">&gt; unless they&#39;re looking for &quot;kB&quot; and now match the &#39;Ptes@4kB&#39; instead</span>
<span class="quote">&gt; of the one at the end of the line.</span>

Right. So you are dropping the idea to introduce these fields as you
mentioned before for DAX mappings.

 	DevicePages:
 	DeviceHugePages:
 	DeviceGiganticPages:
 	DeviceGinormousPages:
<span class="quote">

&gt; </span>
<span class="quote">&gt; 1. I&#39;d like to thank Dan Williams for showing me a mirror as I</span>
<span class="quote">&gt;    complained about the bozo that introduced &#39;AnonHugePages&#39;.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Cc: Christoph Hellwig &lt;hch@lst.de&gt;</span>
<span class="quote">&gt; Cc: Andrew Morton &lt;akpm@linux-foundation.org&gt;</span>
<span class="quote">&gt; Cc: Dan Williams &lt;dan.j.williams@intel.com&gt;</span>
<span class="quote">&gt; Cc: Anshuman Khandual &lt;khandual@linux.vnet.ibm.com&gt;</span>
<span class="quote">&gt; Cc: linux-mm@kvack.org</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; ---</span>
<span class="quote">&gt; </span>
<span class="quote">&gt;  b/Documentation/filesystems/proc.txt |    6 ++</span>
<span class="quote">&gt;  b/fs/proc/task_mmu.c                 |   81 ++++++++++++++++++++++++++++++++++-</span>
<span class="quote">&gt;  2 files changed, 85 insertions(+), 2 deletions(-)</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; diff -puN fs/proc/task_mmu.c~smaps-pte-sizes fs/proc/task_mmu.c</span>
<span class="quote">&gt; --- a/fs/proc/task_mmu.c~smaps-pte-sizes	2016-11-16 15:43:56.756991084 -0800</span>
<span class="quote">&gt; +++ b/fs/proc/task_mmu.c	2016-11-16 16:19:47.354789912 -0800</span>
<span class="quote">&gt; @@ -445,6 +445,9 @@ struct mem_size_stats {</span>
<span class="quote">&gt;  	unsigned long swap;</span>
<span class="quote">&gt;  	unsigned long shared_hugetlb;</span>
<span class="quote">&gt;  	unsigned long private_hugetlb;</span>
<span class="quote">&gt; +	unsigned long rss_pte;</span>
<span class="quote">&gt; +	unsigned long rss_pmd;</span>
<span class="quote">&gt; +	unsigned long rss_pud;</span>
<span class="quote">&gt;  	u64 pss;</span>
<span class="quote">&gt;  	u64 swap_pss;</span>
<span class="quote">&gt;  	bool check_shmem_swap;</span>
<span class="quote">&gt; @@ -519,6 +522,7 @@ static void smaps_pte_entry(pte_t *pte,</span>
<span class="quote">&gt; </span>
<span class="quote">&gt;  	if (pte_present(*pte)) {</span>
<span class="quote">&gt;  		page = vm_normal_page(vma, addr, *pte);</span>
<span class="quote">&gt; +		mss-&gt;rss_pte += PAGE_SIZE;</span>
<span class="quote">&gt;  	} else if (is_swap_pte(*pte)) {</span>
<span class="quote">&gt;  		swp_entry_t swpent = pte_to_swp_entry(*pte);</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; @@ -578,6 +582,7 @@ static void smaps_pmd_entry(pmd_t *pmd,</span>
<span class="quote">&gt;  		/* pass */;</span>
<span class="quote">&gt;  	else</span>
<span class="quote">&gt;  		VM_BUG_ON_PAGE(1, page);</span>
<span class="quote">&gt; +	mss-&gt;rss_pmd += PMD_SIZE;</span>
<span class="quote">&gt;  	smaps_account(mss, page, true, pmd_young(*pmd), pmd_dirty(*pmd));</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;  #else</span>
<span class="quote">&gt; @@ -702,11 +707,13 @@ static int smaps_hugetlb_range(pte_t *pt</span>
<span class="quote">&gt;  	}</span>
<span class="quote">&gt;  	if (page) {</span>
<span class="quote">&gt;  		int mapcount = page_mapcount(page);</span>
<span class="quote">&gt; +		unsigned long hpage_size = huge_page_size(hstate_vma(vma));</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; +		mss-&gt;rss_pud += hpage_size;</span>
<span class="quote">&gt;  		if (mapcount &gt;= 2)</span>
<span class="quote">&gt; -			mss-&gt;shared_hugetlb += huge_page_size(hstate_vma(vma));</span>
<span class="quote">&gt; +			mss-&gt;shared_hugetlb += hpage_size;</span>
<span class="quote">&gt;  		else</span>
<span class="quote">&gt; -			mss-&gt;private_hugetlb += huge_page_size(hstate_vma(vma));</span>
<span class="quote">&gt; +			mss-&gt;private_hugetlb += hpage_size;</span>
<span class="quote">&gt;  	}</span>
<span class="quote">&gt;  	return 0;</span>

Hmm, is this related to these new changes ? The replacement of &#39;hpage_size&#39;
instead of huge_page_size(hstate_vma(vma)) can be done in a separate patch.
<span class="quote">
&gt;  }</span>
<span class="quote">&gt; @@ -716,6 +723,75 @@ void __weak arch_show_smap(struct seq_fi</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; +/*</span>
<span class="quote">&gt; + * What units should we use for a given number?  We want</span>
<span class="quote">&gt; + * 2048 to be 2k, so we return &#39;k&#39;.  1048576 should be</span>
<span class="quote">&gt; + * 1M, so we return &#39;M&#39;.</span>
<span class="quote">&gt; + */</span>
<span class="quote">&gt; +static char size_unit(unsigned long long nr)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	/*</span>
<span class="quote">&gt; +	 * This &#39; &#39; might look a bit goofy in the output.  But, why</span>
<span class="quote">&gt; +	 * bother doing anything.  Do we even have a &lt;1k page size?</span>
<span class="quote">&gt; +	 */</span>
<span class="quote">&gt; +	if (nr &lt; (1ULL&lt;&lt;10))</span>
<span class="quote">&gt; +		return &#39; &#39;;</span>
<span class="quote">&gt; +	if (nr &lt; (1ULL&lt;&lt;20))</span>
<span class="quote">&gt; +		return &#39;k&#39;;</span>
<span class="quote">&gt; +	if (nr &lt; (1ULL&lt;&lt;30))</span>
<span class="quote">&gt; +		return &#39;M&#39;;</span>
<span class="quote">&gt; +	if (nr &lt; (1ULL&lt;&lt;40))</span>
<span class="quote">&gt; +		return &#39;G&#39;;</span>
<span class="quote">&gt; +	if (nr &lt; (1ULL&lt;&lt;50))</span>
<span class="quote">&gt; +		return &#39;T&#39;;</span>
<span class="quote">&gt; +	if (nr &lt; (1ULL&lt;&lt;60))</span>
<span class="quote">&gt; +		return &#39;P&#39;;</span>
<span class="quote">&gt; +	return &#39;E&#39;;</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +/*</span>
<span class="quote">&gt; + * How should we shift down a a given number to scale it</span>
<span class="quote">&gt; + * with the units we are printing it as? 2048 to be 2k,</span>
<span class="quote">&gt; + * so we want it shifted down by 10.  1048576 should be</span>
<span class="quote">&gt; + * 1M, so we want it shifted down by 20.</span>
<span class="quote">&gt; + */</span>
<span class="quote">&gt; +static int size_shift(unsigned long long nr)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	if (nr &lt; (1ULL&lt;&lt;10))</span>
<span class="quote">&gt; +		return 0;</span>
<span class="quote">&gt; +	if (nr &lt; (1ULL&lt;&lt;20))</span>
<span class="quote">&gt; +		return 10;</span>
<span class="quote">&gt; +	if (nr &lt; (1ULL&lt;&lt;30))</span>
<span class="quote">&gt; +		return 20;</span>
<span class="quote">&gt; +	if (nr &lt; (1ULL&lt;&lt;40))</span>
<span class="quote">&gt; +		return 30;</span>
<span class="quote">&gt; +	if (nr &lt; (1ULL&lt;&lt;50))</span>
<span class="quote">&gt; +		return 40;</span>
<span class="quote">&gt; +	if (nr &lt; (1ULL&lt;&lt;60))</span>
<span class="quote">&gt; +		return 50;</span>
<span class="quote">&gt; +	return 60;</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +static void show_one_smap_pte(struct seq_file *m, unsigned long bytes_rss,</span>
<span class="quote">&gt; +		unsigned long pte_size)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	seq_printf(m, &quot;Ptes@%ld%cB:	%8lu kB\n&quot;,</span>
<span class="quote">&gt; +			pte_size &gt;&gt; size_shift(pte_size),</span>
<span class="quote">&gt; +			size_unit(pte_size),</span>
<span class="quote">&gt; +			bytes_rss &gt;&gt; 10);</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +static void show_smap_ptes(struct seq_file *m, struct mem_size_stats *mss)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	/* Only print the entries for page sizes present in the VMA */</span>
<span class="quote">&gt; +	if (mss-&gt;rss_pte)</span>
<span class="quote">&gt; +		show_one_smap_pte(m, mss-&gt;rss_pte, PAGE_SIZE);</span>
<span class="quote">&gt; +	if (mss-&gt;rss_pmd)</span>
<span class="quote">&gt; +		show_one_smap_pte(m, mss-&gt;rss_pmd, PMD_SIZE);</span>
<span class="quote">&gt; +	if (mss-&gt;rss_pud)</span>
<span class="quote">&gt; +		show_one_smap_pte(m, mss-&gt;rss_pud, PUD_SIZE);</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt;  static int show_smap(struct seq_file *m, void *v, int is_pid)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	struct vm_area_struct *vma = v;</span>
<span class="quote">&gt; @@ -799,6 +875,7 @@ static int show_smap(struct seq_file *m,</span>
<span class="quote">&gt;  		   (vma-&gt;vm_flags &amp; VM_LOCKED) ?</span>
<span class="quote">&gt;  			(unsigned long)(mss.pss &gt;&gt; (10 + PSS_SHIFT)) : 0);</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; +	show_smap_ptes(m, &amp;mss);</span>
<span class="quote">&gt;  	arch_show_smap(m, vma);</span>
<span class="quote">&gt;  	show_smap_vma_flags(m, vma);</span>
<span class="quote">&gt;  	m_cache_vma(m, vma);</span>
<span class="quote">&gt; diff -puN Documentation/filesystems/proc.txt~smaps-pte-sizes Documentation/filesystems/proc.txt</span>
<span class="quote">&gt; --- a/Documentation/filesystems/proc.txt~smaps-pte-sizes	2016-11-16 16:10:48.707307044 -0800</span>
<span class="quote">&gt; +++ b/Documentation/filesystems/proc.txt	2016-11-16 16:10:52.172464547 -0800</span>
<span class="quote">&gt; @@ -418,6 +418,9 @@ SwapPss:               0 kB</span>
<span class="quote">&gt;  KernelPageSize:        4 kB</span>
<span class="quote">&gt;  MMUPageSize:           4 kB</span>
<span class="quote">&gt;  Locked:                0 kB</span>
<span class="quote">&gt; +Ptes@4kB:	       4 kB</span>
<span class="quote">&gt; +Ptes@2MB:	    8192 kB</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt;  VmFlags: rd ex mr mw me dw</span>
<span class="quote">&gt; </span>
<span class="quote">&gt;  the first of these lines shows the same information as is displayed for the</span>
<span class="quote">&gt; @@ -450,6 +453,9 @@ replaced by copy-on-write) part of the u</span>
<span class="quote">&gt;  &quot;SwapPss&quot; shows proportional swap share of this mapping. Unlike &quot;Swap&quot;, this</span>
<span class="quote">&gt;  does not take into account swapped out page of underlying shmem objects.</span>
<span class="quote">&gt;  &quot;Locked&quot; indicates whether the mapping is locked in memory or not.</span>
<span class="quote">&gt; +&quot;Ptes@...&quot; lines show how many page table entries are currently in place and</span>
<span class="quote">&gt; +pointing to memory.  There is an entry for each size present in the hardware</span>
<span class="quote">&gt; +page tables for this mapping.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt;  &quot;VmFlags&quot; field deserves a separate description. This member represents the kernel</span>
<span class="quote">&gt;  flags associated with the particular virtual memory area in two letter encoded</span>
<span class="quote">&gt; _</span>
<span class="quote">&gt;</span>
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=2302">Dave Hansen</a> - Nov. 28, 2016, 4:52 p.m.</div>
<pre class="content">
On 11/24/2016 06:22 AM, Vlastimil Babka wrote:
<span class="quote">&gt; On 11/17/2016 01:28 AM, Dave Hansen wrote:</span>
<span class="quote">&gt;&gt; @@ -702,11 +707,13 @@ static int smaps_hugetlb_range(pte_t *pt</span>
<span class="quote">&gt;&gt;      }</span>
<span class="quote">&gt;&gt;      if (page) {</span>
<span class="quote">&gt;&gt;          int mapcount = page_mapcount(page);</span>
<span class="quote">&gt;&gt; +        unsigned long hpage_size = huge_page_size(hstate_vma(vma));</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; +        mss-&gt;rss_pud += hpage_size;</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; This hardcoded pud doesn&#39;t look right, doesn&#39;t the pmd/pud depend on</span>
<span class="quote">&gt; hpage_size?</span>

Urg, nope.  Thanks for noticing that!  I think we&#39;ll need something
along the lines of:

                if (hpage_size == PUD_SIZE)
                        mss-&gt;rss_pud += PUD_SIZE;
                else if (hpage_size == PMD_SIZE)
                        mss-&gt;rss_pmd += PMD_SIZE;

I&#39;ll respin and resend.
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=2302">Dave Hansen</a> - Nov. 28, 2016, 5 p.m.</div>
<pre class="content">
On 11/24/2016 08:00 PM, Anshuman Khandual wrote:
...
<span class="quote">&gt;&gt; The current mechanisms work fine when we have one or two page sizes.</span>
<span class="quote">&gt;&gt; But, they start to get a bit muddled when we mix page sizes inside</span>
<span class="quote">&gt;&gt; one VMA.  For instance, the DAX folks were proposing adding a set of</span>
<span class="quote">&gt;&gt; fields like:</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; So DAX is only case which creates this scenario of multi page sizes in</span>
<span class="quote">&gt; the same VMA ? Is there any cases other than DAX mapping ?</span>

Both file and anonymous huge pages.  No other ones in the core VM that I
can think of.
<span class="quote">
&gt;&gt; 	DevicePages:</span>
<span class="quote">&gt;&gt; 	DeviceHugePages:</span>
<span class="quote">&gt;&gt; 	DeviceGiganticPages:</span>
<span class="quote">&gt;&gt; 	DeviceGinormousPages:</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; I guess these are the page sizes supported at PTE, PMD, PUD, PGD level.</span>
<span class="quote">&gt; Are all these page sizes supported right now or we are just creating</span>
<span class="quote">&gt; place holder for future.</span>

I know there are patches for PUD level support in DAX, but I don&#39;t think
they&#39;re merged yet.  There is definitely *not* support for PGD level
since we don&#39;t have such support in hardware on x86 as far as I know.
<span class="quote">
&gt;&gt; SwapPss:               0 kB</span>
<span class="quote">&gt;&gt; KernelPageSize:        4 kB</span>
<span class="quote">&gt;&gt; MMUPageSize:           4 kB</span>
<span class="quote">&gt;&gt; Locked:                0 kB</span>
<span class="quote">&gt;&gt; Ptes@4kB:	      32 kB</span>
<span class="quote">&gt;&gt; Ptes@2MB:	    2048 kB</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; So in the left column we are explicitly indicating the size of the PTE</span>
<span class="quote">&gt; and expect the user to figure out where it can really be either at PTE,</span>
<span class="quote">&gt; PMD, PUD etc. Thats little bit different that &#39;AnonHugePages&#39; or the</span>
<span class="quote">&gt; Shared_HugeTLB/Private_HugeTLB pages which we know are the the PMD/PUD</span>
<span class="quote">&gt; level.</span>

Yeah, it&#39;s a little different from what we have.
<span class="quote">
&gt;&gt; The format I used here should be unlikely to break smaps parsers</span>
<span class="quote">&gt;&gt; unless they&#39;re looking for &quot;kB&quot; and now match the &#39;Ptes@4kB&#39; instead</span>
<span class="quote">&gt;&gt; of the one at the end of the line.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Right. So you are dropping the idea to introduce these fields as you</span>
<span class="quote">&gt; mentioned before for DAX mappings.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt;  	DevicePages:</span>
<span class="quote">&gt;  	DeviceHugePages:</span>
<span class="quote">&gt;  	DeviceGiganticPages:</span>
<span class="quote">&gt;  	DeviceGinormousPages:</span>

Right.  We don&#39;t need those if we have this patch.
<span class="quote">
&gt;&gt;  	if (page) {</span>
<span class="quote">&gt;&gt;  		int mapcount = page_mapcount(page);</span>
<span class="quote">&gt;&gt; +		unsigned long hpage_size = huge_page_size(hstate_vma(vma));</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; +		mss-&gt;rss_pud += hpage_size;</span>
<span class="quote">&gt;&gt;  		if (mapcount &gt;= 2)</span>
<span class="quote">&gt;&gt; -			mss-&gt;shared_hugetlb += huge_page_size(hstate_vma(vma));</span>
<span class="quote">&gt;&gt; +			mss-&gt;shared_hugetlb += hpage_size;</span>
<span class="quote">&gt;&gt;  		else</span>
<span class="quote">&gt;&gt; -			mss-&gt;private_hugetlb += huge_page_size(hstate_vma(vma));</span>
<span class="quote">&gt;&gt; +			mss-&gt;private_hugetlb += hpage_size;</span>
<span class="quote">&gt;&gt;  	}</span>
<span class="quote">&gt;&gt;  	return 0;</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Hmm, is this related to these new changes ? The replacement of &#39;hpage_size&#39;</span>
<span class="quote">&gt; instead of huge_page_size(hstate_vma(vma)) can be done in a separate patch.</span>

Yes, this is theoretically unrelated, but I&#39;m not breaking this 3-line
change up into a different patch unless there&#39;s a pretty good reason reason.
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=72672">Vlastimil Babka</a> - Nov. 28, 2016, 9:07 p.m.</div>
<pre class="content">
On 11/28/2016 05:52 PM, Dave Hansen wrote:
<span class="quote">&gt; On 11/24/2016 06:22 AM, Vlastimil Babka wrote:</span>
<span class="quote">&gt;&gt; On 11/17/2016 01:28 AM, Dave Hansen wrote:</span>
<span class="quote">&gt;&gt;&gt; @@ -702,11 +707,13 @@ static int smaps_hugetlb_range(pte_t *pt</span>
<span class="quote">&gt;&gt;&gt;      }</span>
<span class="quote">&gt;&gt;&gt;      if (page) {</span>
<span class="quote">&gt;&gt;&gt;          int mapcount = page_mapcount(page);</span>
<span class="quote">&gt;&gt;&gt; +        unsigned long hpage_size = huge_page_size(hstate_vma(vma));</span>
<span class="quote">&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt; +        mss-&gt;rss_pud += hpage_size;</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; This hardcoded pud doesn&#39;t look right, doesn&#39;t the pmd/pud depend on</span>
<span class="quote">&gt;&gt; hpage_size?</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Urg, nope.  Thanks for noticing that!  I think we&#39;ll need something</span>
<span class="quote">&gt; along the lines of:</span>
<span class="quote">&gt; </span>
<span class="quote">&gt;                 if (hpage_size == PUD_SIZE)</span>
<span class="quote">&gt;                         mss-&gt;rss_pud += PUD_SIZE;</span>
<span class="quote">&gt;                 else if (hpage_size == PMD_SIZE)</span>
<span class="quote">&gt;                         mss-&gt;rss_pmd += PMD_SIZE;</span>

Sounds better, although I wonder whether there are some weird arches
supporting hugepage sizes that don&#39;t match page table levels. I recall
that e.g. MIPS could do arbitrary size, but dunno if the kernel supports
that...
<span class="quote">
&gt; I&#39;ll respin and resend.</span>
<span class="quote">&gt;</span>
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=2302">Dave Hansen</a> - Nov. 28, 2016, 9:39 p.m.</div>
<pre class="content">
... cc&#39;ing the arm64 maintainers

On 11/28/2016 01:07 PM, Vlastimil Babka wrote:
<span class="quote">&gt; On 11/28/2016 05:52 PM, Dave Hansen wrote:</span>
<span class="quote">&gt;&gt; On 11/24/2016 06:22 AM, Vlastimil Babka wrote:</span>
<span class="quote">&gt;&gt;&gt; On 11/17/2016 01:28 AM, Dave Hansen wrote:</span>
<span class="quote">&gt;&gt;&gt;&gt; @@ -702,11 +707,13 @@ static int smaps_hugetlb_range(pte_t *pt</span>
<span class="quote">&gt;&gt;&gt;&gt;      }</span>
<span class="quote">&gt;&gt;&gt;&gt;      if (page) {</span>
<span class="quote">&gt;&gt;&gt;&gt;          int mapcount = page_mapcount(page);</span>
<span class="quote">&gt;&gt;&gt;&gt; +        unsigned long hpage_size = huge_page_size(hstate_vma(vma));</span>
<span class="quote">&gt;&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt;&gt; +        mss-&gt;rss_pud += hpage_size;</span>
<span class="quote">&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt; This hardcoded pud doesn&#39;t look right, doesn&#39;t the pmd/pud depend on</span>
<span class="quote">&gt;&gt;&gt; hpage_size?</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; Urg, nope.  Thanks for noticing that!  I think we&#39;ll need something</span>
<span class="quote">&gt;&gt; along the lines of:</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt;                 if (hpage_size == PUD_SIZE)</span>
<span class="quote">&gt;&gt;                         mss-&gt;rss_pud += PUD_SIZE;</span>
<span class="quote">&gt;&gt;                 else if (hpage_size == PMD_SIZE)</span>
<span class="quote">&gt;&gt;                         mss-&gt;rss_pmd += PMD_SIZE;</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Sounds better, although I wonder whether there are some weird arches</span>
<span class="quote">&gt; supporting hugepage sizes that don&#39;t match page table levels. I recall</span>
<span class="quote">&gt; that e.g. MIPS could do arbitrary size, but dunno if the kernel supports</span>
<span class="quote">&gt; that...</span>

arm64 seems to have pretty arbitrary sizes, and seems to be able to
build them out of multiple hardware PTE sizes.  I think I can fix my
code to handle those:

                if (hpage_size &gt;= PGD_SIZE)
                        mss-&gt;rss_pgd += PGD_SIZE;
                else if (hpage_size &gt;= PUD_SIZE)
                        mss-&gt;rss_pud += PUD_SIZE;
                else if (hpage_size &gt;= PMD_SIZE)
                        mss-&gt;rss_pmd += PMD_SIZE;
                else
                        mss-&gt;rss_pte += PAGE_SIZE;

But, I *think* that means that smaps_hugetlb_range() is *currently*
broken for these intermediate arm64 sizes.  The code does:

                if (mapcount &gt;= 2)
                        mss-&gt;shared_hugetlb += hpage_size;
                else
                        mss-&gt;private_hugetlb += hpage_size;

So I *think* if we may count a hugetlbfs arm64 CONT_PTES page multiple
times, and account hpage_size for *each* of the CONT_PTES.  That would
artificially inflate the smaps output for those pages.

Will / Catalin, is there something I&#39;m missing?
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=72672">Vlastimil Babka</a> - Nov. 29, 2016, 8:01 a.m.</div>
<pre class="content">
On 11/28/2016 10:39 PM, Dave Hansen wrote:
<span class="quote">&gt; ... cc&#39;ing the arm64 maintainers</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; On 11/28/2016 01:07 PM, Vlastimil Babka wrote:</span>
<span class="quote">&gt;&gt; On 11/28/2016 05:52 PM, Dave Hansen wrote:</span>
<span class="quote">&gt;&gt;&gt; On 11/24/2016 06:22 AM, Vlastimil Babka wrote:</span>
<span class="quote">&gt;&gt;&gt;&gt; On 11/17/2016 01:28 AM, Dave Hansen wrote:</span>
<span class="quote">&gt;&gt;&gt;&gt;&gt; @@ -702,11 +707,13 @@ static int smaps_hugetlb_range(pte_t *pt</span>
<span class="quote">&gt;&gt;&gt;&gt;&gt;      }</span>
<span class="quote">&gt;&gt;&gt;&gt;&gt;      if (page) {</span>
<span class="quote">&gt;&gt;&gt;&gt;&gt;          int mapcount = page_mapcount(page);</span>
<span class="quote">&gt;&gt;&gt;&gt;&gt; +        unsigned long hpage_size = huge_page_size(hstate_vma(vma));</span>
<span class="quote">&gt;&gt;&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt;&gt;&gt; +        mss-&gt;rss_pud += hpage_size;</span>
<span class="quote">&gt;&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt;&gt; This hardcoded pud doesn&#39;t look right, doesn&#39;t the pmd/pud depend on</span>
<span class="quote">&gt;&gt;&gt;&gt; hpage_size?</span>
<span class="quote">&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt; Urg, nope.  Thanks for noticing that!  I think we&#39;ll need something</span>
<span class="quote">&gt;&gt;&gt; along the lines of:</span>
<span class="quote">&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt;                 if (hpage_size == PUD_SIZE)</span>
<span class="quote">&gt;&gt;&gt;                         mss-&gt;rss_pud += PUD_SIZE;</span>
<span class="quote">&gt;&gt;&gt;                 else if (hpage_size == PMD_SIZE)</span>
<span class="quote">&gt;&gt;&gt;                         mss-&gt;rss_pmd += PMD_SIZE;</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; Sounds better, although I wonder whether there are some weird arches</span>
<span class="quote">&gt;&gt; supporting hugepage sizes that don&#39;t match page table levels. I recall</span>
<span class="quote">&gt;&gt; that e.g. MIPS could do arbitrary size, but dunno if the kernel supports</span>
<span class="quote">&gt;&gt; that...</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; arm64 seems to have pretty arbitrary sizes, and seems to be able to</span>
<span class="quote">&gt; build them out of multiple hardware PTE sizes.  I think I can fix my</span>
<span class="quote">&gt; code to handle those:</span>
<span class="quote">&gt; </span>
<span class="quote">&gt;                 if (hpage_size &gt;= PGD_SIZE)</span>
<span class="quote">&gt;                         mss-&gt;rss_pgd += PGD_SIZE;</span>
<span class="quote">&gt;                 else if (hpage_size &gt;= PUD_SIZE)</span>
<span class="quote">&gt;                         mss-&gt;rss_pud += PUD_SIZE;</span>
<span class="quote">&gt;                 else if (hpage_size &gt;= PMD_SIZE)</span>
<span class="quote">&gt;                         mss-&gt;rss_pmd += PMD_SIZE;</span>
<span class="quote">&gt;                 else</span>
<span class="quote">&gt;                         mss-&gt;rss_pte += PAGE_SIZE;</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; But, I *think* that means that smaps_hugetlb_range() is *currently*</span>
<span class="quote">&gt; broken for these intermediate arm64 sizes.  The code does:</span>
<span class="quote">&gt; </span>
<span class="quote">&gt;                 if (mapcount &gt;= 2)</span>
<span class="quote">&gt;                         mss-&gt;shared_hugetlb += hpage_size;</span>
<span class="quote">&gt;                 else</span>
<span class="quote">&gt;                         mss-&gt;private_hugetlb += hpage_size;</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; So I *think* if we may count a hugetlbfs arm64 CONT_PTES page multiple</span>
<span class="quote">&gt; times, and account hpage_size for *each* of the CONT_PTES.  That would</span>
<span class="quote">&gt; artificially inflate the smaps output for those pages.</span>

Hmm IIUC walk_hugetlb_range() will call the smaps_hugetlb_range()
callback once per hugepage, not once per &quot;pte&quot;, no? See
hugetlb_entry_end(). In that case the current code should be OK and
yours would undercount?
<span class="quote">
&gt; Will / Catalin, is there something I&#39;m missing?</span>
<span class="quote">&gt;</span>
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=352">Catalin Marinas</a> - Nov. 29, 2016, 3:07 p.m.</div>
<pre class="content">
On Mon, Nov 28, 2016 at 01:39:49PM -0800, Dave Hansen wrote:
<span class="quote">&gt; On 11/28/2016 01:07 PM, Vlastimil Babka wrote:</span>
<span class="quote">&gt; &gt; On 11/28/2016 05:52 PM, Dave Hansen wrote:</span>
<span class="quote">&gt; &gt;&gt; On 11/24/2016 06:22 AM, Vlastimil Babka wrote:</span>
<span class="quote">&gt; &gt;&gt;&gt; On 11/17/2016 01:28 AM, Dave Hansen wrote:</span>
<span class="quote">&gt; &gt;&gt;&gt;&gt; @@ -702,11 +707,13 @@ static int smaps_hugetlb_range(pte_t *pt</span>
<span class="quote">&gt; &gt;&gt;&gt;&gt;      }</span>
<span class="quote">&gt; &gt;&gt;&gt;&gt;      if (page) {</span>
<span class="quote">&gt; &gt;&gt;&gt;&gt;          int mapcount = page_mapcount(page);</span>
<span class="quote">&gt; &gt;&gt;&gt;&gt; +        unsigned long hpage_size = huge_page_size(hstate_vma(vma));</span>
<span class="quote">&gt; &gt;&gt;&gt;&gt;</span>
<span class="quote">&gt; &gt;&gt;&gt;&gt; +        mss-&gt;rss_pud += hpage_size;</span>
<span class="quote">&gt; &gt;&gt;&gt;</span>
<span class="quote">&gt; &gt;&gt;&gt; This hardcoded pud doesn&#39;t look right, doesn&#39;t the pmd/pud depend on</span>
<span class="quote">&gt; &gt;&gt;&gt; hpage_size?</span>
<span class="quote">&gt; &gt;&gt;</span>
<span class="quote">&gt; &gt;&gt; Urg, nope.  Thanks for noticing that!  I think we&#39;ll need something</span>
<span class="quote">&gt; &gt;&gt; along the lines of:</span>
<span class="quote">&gt; &gt;&gt;</span>
<span class="quote">&gt; &gt;&gt;                 if (hpage_size == PUD_SIZE)</span>
<span class="quote">&gt; &gt;&gt;                         mss-&gt;rss_pud += PUD_SIZE;</span>
<span class="quote">&gt; &gt;&gt;                 else if (hpage_size == PMD_SIZE)</span>
<span class="quote">&gt; &gt;&gt;                         mss-&gt;rss_pmd += PMD_SIZE;</span>
<span class="quote">&gt; &gt; </span>
<span class="quote">&gt; &gt; Sounds better, although I wonder whether there are some weird arches</span>
<span class="quote">&gt; &gt; supporting hugepage sizes that don&#39;t match page table levels. I recall</span>
<span class="quote">&gt; &gt; that e.g. MIPS could do arbitrary size, but dunno if the kernel supports</span>
<span class="quote">&gt; &gt; that...</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; arm64 seems to have pretty arbitrary sizes, and seems to be able to</span>
<span class="quote">&gt; build them out of multiple hardware PTE sizes.  I think I can fix my</span>
<span class="quote">&gt; code to handle those:</span>
<span class="quote">&gt; </span>
<span class="quote">&gt;                 if (hpage_size &gt;= PGD_SIZE)</span>
<span class="quote">&gt;                         mss-&gt;rss_pgd += PGD_SIZE;</span>
<span class="quote">&gt;                 else if (hpage_size &gt;= PUD_SIZE)</span>
<span class="quote">&gt;                         mss-&gt;rss_pud += PUD_SIZE;</span>
<span class="quote">&gt;                 else if (hpage_size &gt;= PMD_SIZE)</span>
<span class="quote">&gt;                         mss-&gt;rss_pmd += PMD_SIZE;</span>
<span class="quote">&gt;                 else</span>
<span class="quote">&gt;                         mss-&gt;rss_pte += PAGE_SIZE;</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; But, I *think* that means that smaps_hugetlb_range() is *currently*</span>
<span class="quote">&gt; broken for these intermediate arm64 sizes.  The code does:</span>
<span class="quote">&gt; </span>
<span class="quote">&gt;                 if (mapcount &gt;= 2)</span>
<span class="quote">&gt;                         mss-&gt;shared_hugetlb += hpage_size;</span>
<span class="quote">&gt;                 else</span>
<span class="quote">&gt;                         mss-&gt;private_hugetlb += hpage_size;</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; So I *think* if we may count a hugetlbfs arm64 CONT_PTES page multiple</span>
<span class="quote">&gt; times, and account hpage_size for *each* of the CONT_PTES.  That would</span>
<span class="quote">&gt; artificially inflate the smaps output for those pages.</span>

I don&#39;t think it would count them multiple times. As Vlastimil
mentioned, huge_page_size() would return (CONT_PTES * PAGE_SIZE) in such
case, so walk_hugetlb_range() skips the intermediate ptes. In general,
we try to keep the contiguous pte/pmd support visible only to the arm64
hugetlb code and hidden to the core code.
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff -puN fs/proc/task_mmu.c~smaps-pte-sizes fs/proc/task_mmu.c</span>
<span class="p_header">--- a/fs/proc/task_mmu.c~smaps-pte-sizes	2016-11-16 15:43:56.756991084 -0800</span>
<span class="p_header">+++ b/fs/proc/task_mmu.c	2016-11-16 16:19:47.354789912 -0800</span>
<span class="p_chunk">@@ -445,6 +445,9 @@</span> <span class="p_context"> struct mem_size_stats {</span>
 	unsigned long swap;
 	unsigned long shared_hugetlb;
 	unsigned long private_hugetlb;
<span class="p_add">+	unsigned long rss_pte;</span>
<span class="p_add">+	unsigned long rss_pmd;</span>
<span class="p_add">+	unsigned long rss_pud;</span>
 	u64 pss;
 	u64 swap_pss;
 	bool check_shmem_swap;
<span class="p_chunk">@@ -519,6 +522,7 @@</span> <span class="p_context"> static void smaps_pte_entry(pte_t *pte,</span>
 
 	if (pte_present(*pte)) {
 		page = vm_normal_page(vma, addr, *pte);
<span class="p_add">+		mss-&gt;rss_pte += PAGE_SIZE;</span>
 	} else if (is_swap_pte(*pte)) {
 		swp_entry_t swpent = pte_to_swp_entry(*pte);
 
<span class="p_chunk">@@ -578,6 +582,7 @@</span> <span class="p_context"> static void smaps_pmd_entry(pmd_t *pmd,</span>
 		/* pass */;
 	else
 		VM_BUG_ON_PAGE(1, page);
<span class="p_add">+	mss-&gt;rss_pmd += PMD_SIZE;</span>
 	smaps_account(mss, page, true, pmd_young(*pmd), pmd_dirty(*pmd));
 }
 #else
<span class="p_chunk">@@ -702,11 +707,13 @@</span> <span class="p_context"> static int smaps_hugetlb_range(pte_t *pt</span>
 	}
 	if (page) {
 		int mapcount = page_mapcount(page);
<span class="p_add">+		unsigned long hpage_size = huge_page_size(hstate_vma(vma));</span>
 
<span class="p_add">+		mss-&gt;rss_pud += hpage_size;</span>
 		if (mapcount &gt;= 2)
<span class="p_del">-			mss-&gt;shared_hugetlb += huge_page_size(hstate_vma(vma));</span>
<span class="p_add">+			mss-&gt;shared_hugetlb += hpage_size;</span>
 		else
<span class="p_del">-			mss-&gt;private_hugetlb += huge_page_size(hstate_vma(vma));</span>
<span class="p_add">+			mss-&gt;private_hugetlb += hpage_size;</span>
 	}
 	return 0;
 }
<span class="p_chunk">@@ -716,6 +723,75 @@</span> <span class="p_context"> void __weak arch_show_smap(struct seq_fi</span>
 {
 }
 
<span class="p_add">+/*</span>
<span class="p_add">+ * What units should we use for a given number?  We want</span>
<span class="p_add">+ * 2048 to be 2k, so we return &#39;k&#39;.  1048576 should be</span>
<span class="p_add">+ * 1M, so we return &#39;M&#39;.</span>
<span class="p_add">+ */</span>
<span class="p_add">+static char size_unit(unsigned long long nr)</span>
<span class="p_add">+{</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * This &#39; &#39; might look a bit goofy in the output.  But, why</span>
<span class="p_add">+	 * bother doing anything.  Do we even have a &lt;1k page size?</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	if (nr &lt; (1ULL&lt;&lt;10))</span>
<span class="p_add">+		return &#39; &#39;;</span>
<span class="p_add">+	if (nr &lt; (1ULL&lt;&lt;20))</span>
<span class="p_add">+		return &#39;k&#39;;</span>
<span class="p_add">+	if (nr &lt; (1ULL&lt;&lt;30))</span>
<span class="p_add">+		return &#39;M&#39;;</span>
<span class="p_add">+	if (nr &lt; (1ULL&lt;&lt;40))</span>
<span class="p_add">+		return &#39;G&#39;;</span>
<span class="p_add">+	if (nr &lt; (1ULL&lt;&lt;50))</span>
<span class="p_add">+		return &#39;T&#39;;</span>
<span class="p_add">+	if (nr &lt; (1ULL&lt;&lt;60))</span>
<span class="p_add">+		return &#39;P&#39;;</span>
<span class="p_add">+	return &#39;E&#39;;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+/*</span>
<span class="p_add">+ * How should we shift down a a given number to scale it</span>
<span class="p_add">+ * with the units we are printing it as? 2048 to be 2k,</span>
<span class="p_add">+ * so we want it shifted down by 10.  1048576 should be</span>
<span class="p_add">+ * 1M, so we want it shifted down by 20.</span>
<span class="p_add">+ */</span>
<span class="p_add">+static int size_shift(unsigned long long nr)</span>
<span class="p_add">+{</span>
<span class="p_add">+	if (nr &lt; (1ULL&lt;&lt;10))</span>
<span class="p_add">+		return 0;</span>
<span class="p_add">+	if (nr &lt; (1ULL&lt;&lt;20))</span>
<span class="p_add">+		return 10;</span>
<span class="p_add">+	if (nr &lt; (1ULL&lt;&lt;30))</span>
<span class="p_add">+		return 20;</span>
<span class="p_add">+	if (nr &lt; (1ULL&lt;&lt;40))</span>
<span class="p_add">+		return 30;</span>
<span class="p_add">+	if (nr &lt; (1ULL&lt;&lt;50))</span>
<span class="p_add">+		return 40;</span>
<span class="p_add">+	if (nr &lt; (1ULL&lt;&lt;60))</span>
<span class="p_add">+		return 50;</span>
<span class="p_add">+	return 60;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static void show_one_smap_pte(struct seq_file *m, unsigned long bytes_rss,</span>
<span class="p_add">+		unsigned long pte_size)</span>
<span class="p_add">+{</span>
<span class="p_add">+	seq_printf(m, &quot;Ptes@%ld%cB:	%8lu kB\n&quot;,</span>
<span class="p_add">+			pte_size &gt;&gt; size_shift(pte_size),</span>
<span class="p_add">+			size_unit(pte_size),</span>
<span class="p_add">+			bytes_rss &gt;&gt; 10);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static void show_smap_ptes(struct seq_file *m, struct mem_size_stats *mss)</span>
<span class="p_add">+{</span>
<span class="p_add">+	/* Only print the entries for page sizes present in the VMA */</span>
<span class="p_add">+	if (mss-&gt;rss_pte)</span>
<span class="p_add">+		show_one_smap_pte(m, mss-&gt;rss_pte, PAGE_SIZE);</span>
<span class="p_add">+	if (mss-&gt;rss_pmd)</span>
<span class="p_add">+		show_one_smap_pte(m, mss-&gt;rss_pmd, PMD_SIZE);</span>
<span class="p_add">+	if (mss-&gt;rss_pud)</span>
<span class="p_add">+		show_one_smap_pte(m, mss-&gt;rss_pud, PUD_SIZE);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static int show_smap(struct seq_file *m, void *v, int is_pid)
 {
 	struct vm_area_struct *vma = v;
<span class="p_chunk">@@ -799,6 +875,7 @@</span> <span class="p_context"> static int show_smap(struct seq_file *m,</span>
 		   (vma-&gt;vm_flags &amp; VM_LOCKED) ?
 			(unsigned long)(mss.pss &gt;&gt; (10 + PSS_SHIFT)) : 0);
 
<span class="p_add">+	show_smap_ptes(m, &amp;mss);</span>
 	arch_show_smap(m, vma);
 	show_smap_vma_flags(m, vma);
 	m_cache_vma(m, vma);
<span class="p_header">diff -puN Documentation/filesystems/proc.txt~smaps-pte-sizes Documentation/filesystems/proc.txt</span>
<span class="p_header">--- a/Documentation/filesystems/proc.txt~smaps-pte-sizes	2016-11-16 16:10:48.707307044 -0800</span>
<span class="p_header">+++ b/Documentation/filesystems/proc.txt	2016-11-16 16:10:52.172464547 -0800</span>
<span class="p_chunk">@@ -418,6 +418,9 @@</span> <span class="p_context"> SwapPss:               0 kB</span>
 KernelPageSize:        4 kB
 MMUPageSize:           4 kB
 Locked:                0 kB
<span class="p_add">+Ptes@4kB:	       4 kB</span>
<span class="p_add">+Ptes@2MB:	    8192 kB</span>
<span class="p_add">+</span>
 VmFlags: rd ex mr mw me dw
 
 the first of these lines shows the same information as is displayed for the
<span class="p_chunk">@@ -450,6 +453,9 @@</span> <span class="p_context"> replaced by copy-on-write) part of the u</span>
 &quot;SwapPss&quot; shows proportional swap share of this mapping. Unlike &quot;Swap&quot;, this
 does not take into account swapped out page of underlying shmem objects.
 &quot;Locked&quot; indicates whether the mapping is locked in memory or not.
<span class="p_add">+&quot;Ptes@...&quot; lines show how many page table entries are currently in place and</span>
<span class="p_add">+pointing to memory.  There is an entry for each size present in the hardware</span>
<span class="p_add">+page tables for this mapping.</span>
 
 &quot;VmFlags&quot; field deserves a separate description. This member represents the kernel
 flags associated with the particular virtual memory area in two letter encoded

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



