
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>[v2,2/7] mm: vmscan: pass memcg to get_scan_count() - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    [v2,2/7] mm: vmscan: pass memcg to get_scan_count()</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=143531">Vladimir Davydov</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>Dec. 17, 2015, 12:29 p.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;daacf7e0dbe2ba11ed44facc36ac2fed3546ffe0.1450352792.git.vdavydov@virtuozzo.com&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/7872821/mbox/"
   >mbox</a>
|
   <a href="/patch/7872821/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/7872821/">/patch/7872821/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
X-Original-To: patchwork-LKML@patchwork.kernel.org
Delivered-To: patchwork-parsemail@patchwork1.web.kernel.org
Received: from mail.kernel.org (mail.kernel.org [198.145.29.136])
	by patchwork1.web.kernel.org (Postfix) with ESMTP id 2D3539F32E
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Thu, 17 Dec 2015 12:30:38 +0000 (UTC)
Received: from mail.kernel.org (localhost [127.0.0.1])
	by mail.kernel.org (Postfix) with ESMTP id 3D85E20392
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Thu, 17 Dec 2015 12:30:37 +0000 (UTC)
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.kernel.org (Postfix) with ESMTP id 4665B20219
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Thu, 17 Dec 2015 12:30:36 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S966710AbbLQMa3 (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Thu, 17 Dec 2015 07:30:29 -0500
Received: from relay.parallels.com ([195.214.232.42]:53909 &quot;EHLO
	relay.parallels.com&quot; rhost-flags-OK-OK-OK-OK) by vger.kernel.org
	with ESMTP id S1753462AbbLQMa0 (ORCPT
	&lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Thu, 17 Dec 2015 07:30:26 -0500
Received: from [10.67.48.55] (helo=mail.parallels.net)
	by relay.parallels.com with esmtps
	(TLSv1.2:ECDHE-RSA-AES256-SHA384:256) (Exim 4.86)
	(envelope-from &lt;VDavydov@odin.com&gt;)
	id 1a9XhQ-00071b-HX; Thu, 17 Dec 2015 15:30:24 +0300
Received: from odin.com (10.30.4.177) by MSK-EXCH1.sw.swsoft.com
	(10.67.48.55) with Microsoft SMTP Server (TLS) id 15.0.1130.7;
	Thu, 17 Dec 2015 13:30:17 +0100
From: Vladimir Davydov &lt;vdavydov@virtuozzo.com&gt;
To: Andrew Morton &lt;akpm@linux-foundation.org&gt;
CC: Johannes Weiner &lt;hannes@cmpxchg.org&gt;,
	Michal Hocko &lt;mhocko@kernel.org&gt;, &lt;linux-mm@kvack.org&gt;,
	&lt;cgroups@vger.kernel.org&gt;, &lt;linux-kernel@vger.kernel.org&gt;
Subject: [PATCH v2 2/7] mm: vmscan: pass memcg to get_scan_count()
Date: Thu, 17 Dec 2015 15:29:55 +0300
Message-ID: &lt;daacf7e0dbe2ba11ed44facc36ac2fed3546ffe0.1450352792.git.vdavydov@virtuozzo.com&gt;
X-Mailer: git-send-email 2.1.4
In-Reply-To: &lt;cover.1450352791.git.vdavydov@virtuozzo.com&gt;
References: &lt;cover.1450352791.git.vdavydov@virtuozzo.com&gt;
MIME-Version: 1.0
Content-Type: text/plain
X-ClientProxiedBy: US-EXCH2.sw.swsoft.com (10.255.249.46) To
	MSK-EXCH1.sw.swsoft.com (10.67.48.55)
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Spam-Status: No, score=-6.9 required=5.0 tests=BAYES_00, RCVD_IN_DNSWL_HI, 
	T_RP_MATCHES_RCVD,
	UNPARSEABLE_RELAY autolearn=unavailable version=3.3.1
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on mail.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=143531">Vladimir Davydov</a> - Dec. 17, 2015, 12:29 p.m.</div>
<pre class="content">
memcg will come in handy in get_scan_count(). It can already be used for
getting swappiness immediately in get_scan_count() instead of passing it
around. The following patches will add more memcg-related values, which
will be used there.
<span class="signed-off-by">
Signed-off-by: Vladimir Davydov &lt;vdavydov@virtuozzo.com&gt;</span>
<span class="acked-by">Acked-by: Johannes Weiner &lt;hannes@cmpxchg.org&gt;</span>
---
 mm/vmscan.c | 20 ++++++++------------
 1 file changed, 8 insertions(+), 12 deletions(-)
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=137061">Michal Hocko</a> - Jan. 13, 2016, 4:47 p.m.</div>
<pre class="content">
On Thu 17-12-15 15:29:55, Vladimir Davydov wrote:
<span class="quote">&gt; memcg will come in handy in get_scan_count(). It can already be used for</span>
<span class="quote">&gt; getting swappiness immediately in get_scan_count() instead of passing it</span>
<span class="quote">&gt; around. The following patches will add more memcg-related values, which</span>
<span class="quote">&gt; will be used there.</span>

OK, the down side would be that every user (even outside of memcg
proper) has to be aware that the memcg might be NULL but this makes
the code a bit easier so...
<span class="quote">
&gt; Signed-off-by: Vladimir Davydov &lt;vdavydov@virtuozzo.com&gt;</span>
<span class="quote">&gt; Acked-by: Johannes Weiner &lt;hannes@cmpxchg.org&gt;</span>
<span class="acked-by">
Acked-by: Michal Hocko &lt;mhocko@suse.com&gt;</span>
<span class="quote">
&gt; ---</span>
<span class="quote">&gt;  mm/vmscan.c | 20 ++++++++------------</span>
<span class="quote">&gt;  1 file changed, 8 insertions(+), 12 deletions(-)</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; diff --git a/mm/vmscan.c b/mm/vmscan.c</span>
<span class="quote">&gt; index bb01b04154ad..acc6bff84e26 100644</span>
<span class="quote">&gt; --- a/mm/vmscan.c</span>
<span class="quote">&gt; +++ b/mm/vmscan.c</span>
<span class="quote">&gt; @@ -1957,10 +1957,11 @@ enum scan_balance {</span>
<span class="quote">&gt;   * nr[0] = anon inactive pages to scan; nr[1] = anon active pages to scan</span>
<span class="quote">&gt;   * nr[2] = file inactive pages to scan; nr[3] = file active pages to scan</span>
<span class="quote">&gt;   */</span>
<span class="quote">&gt; -static void get_scan_count(struct lruvec *lruvec, int swappiness,</span>
<span class="quote">&gt; +static void get_scan_count(struct lruvec *lruvec, struct mem_cgroup *memcg,</span>
<span class="quote">&gt;  			   struct scan_control *sc, unsigned long *nr,</span>
<span class="quote">&gt;  			   unsigned long *lru_pages)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt; +	int swappiness = mem_cgroup_swappiness(memcg);</span>
<span class="quote">&gt;  	struct zone_reclaim_stat *reclaim_stat = &amp;lruvec-&gt;reclaim_stat;</span>
<span class="quote">&gt;  	u64 fraction[2];</span>
<span class="quote">&gt;  	u64 denominator = 0;	/* gcc */</span>
<span class="quote">&gt; @@ -2184,9 +2185,10 @@ static inline void init_tlb_ubc(void)</span>
<span class="quote">&gt;  /*</span>
<span class="quote">&gt;   * This is a basic per-zone page freer.  Used by both kswapd and direct reclaim.</span>
<span class="quote">&gt;   */</span>
<span class="quote">&gt; -static void shrink_lruvec(struct lruvec *lruvec, int swappiness,</span>
<span class="quote">&gt; -			  struct scan_control *sc, unsigned long *lru_pages)</span>
<span class="quote">&gt; +static void shrink_zone_memcg(struct zone *zone, struct mem_cgroup *memcg,</span>
<span class="quote">&gt; +			      struct scan_control *sc, unsigned long *lru_pages)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt; +	struct lruvec *lruvec = mem_cgroup_zone_lruvec(zone, memcg);</span>
<span class="quote">&gt;  	unsigned long nr[NR_LRU_LISTS];</span>
<span class="quote">&gt;  	unsigned long targets[NR_LRU_LISTS];</span>
<span class="quote">&gt;  	unsigned long nr_to_scan;</span>
<span class="quote">&gt; @@ -2196,7 +2198,7 @@ static void shrink_lruvec(struct lruvec *lruvec, int swappiness,</span>
<span class="quote">&gt;  	struct blk_plug plug;</span>
<span class="quote">&gt;  	bool scan_adjusted;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; -	get_scan_count(lruvec, swappiness, sc, nr, lru_pages);</span>
<span class="quote">&gt; +	get_scan_count(lruvec, memcg, sc, nr, lru_pages);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	/* Record the original scan target for proportional adjustments later */</span>
<span class="quote">&gt;  	memcpy(targets, nr, sizeof(nr));</span>
<span class="quote">&gt; @@ -2400,8 +2402,6 @@ static bool shrink_zone(struct zone *zone, struct scan_control *sc,</span>
<span class="quote">&gt;  			unsigned long lru_pages;</span>
<span class="quote">&gt;  			unsigned long reclaimed;</span>
<span class="quote">&gt;  			unsigned long scanned;</span>
<span class="quote">&gt; -			struct lruvec *lruvec;</span>
<span class="quote">&gt; -			int swappiness;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  			if (mem_cgroup_low(root, memcg)) {</span>
<span class="quote">&gt;  				if (!sc-&gt;may_thrash)</span>
<span class="quote">&gt; @@ -2409,12 +2409,10 @@ static bool shrink_zone(struct zone *zone, struct scan_control *sc,</span>
<span class="quote">&gt;  				mem_cgroup_events(memcg, MEMCG_LOW, 1);</span>
<span class="quote">&gt;  			}</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; -			lruvec = mem_cgroup_zone_lruvec(zone, memcg);</span>
<span class="quote">&gt; -			swappiness = mem_cgroup_swappiness(memcg);</span>
<span class="quote">&gt;  			reclaimed = sc-&gt;nr_reclaimed;</span>
<span class="quote">&gt;  			scanned = sc-&gt;nr_scanned;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; -			shrink_lruvec(lruvec, swappiness, sc, &amp;lru_pages);</span>
<span class="quote">&gt; +			shrink_zone_memcg(zone, memcg, sc, &amp;lru_pages);</span>
<span class="quote">&gt;  			zone_lru_pages += lru_pages;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  			if (memcg &amp;&amp; is_classzone)</span>
<span class="quote">&gt; @@ -2884,8 +2882,6 @@ unsigned long mem_cgroup_shrink_node_zone(struct mem_cgroup *memcg,</span>
<span class="quote">&gt;  		.may_unmap = 1,</span>
<span class="quote">&gt;  		.may_swap = !noswap,</span>
<span class="quote">&gt;  	};</span>
<span class="quote">&gt; -	struct lruvec *lruvec = mem_cgroup_zone_lruvec(zone, memcg);</span>
<span class="quote">&gt; -	int swappiness = mem_cgroup_swappiness(memcg);</span>
<span class="quote">&gt;  	unsigned long lru_pages;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	sc.gfp_mask = (gfp_mask &amp; GFP_RECLAIM_MASK) |</span>
<span class="quote">&gt; @@ -2902,7 +2898,7 @@ unsigned long mem_cgroup_shrink_node_zone(struct mem_cgroup *memcg,</span>
<span class="quote">&gt;  	 * will pick up pages from other mem cgroup&#39;s as well. We hack</span>
<span class="quote">&gt;  	 * the priority and make it zero.</span>
<span class="quote">&gt;  	 */</span>
<span class="quote">&gt; -	shrink_lruvec(lruvec, swappiness, &amp;sc, &amp;lru_pages);</span>
<span class="quote">&gt; +	shrink_zone_memcg(zone, memcg, &amp;sc, &amp;lru_pages);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	trace_mm_vmscan_memcg_softlimit_reclaim_end(sc.nr_reclaimed);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; -- </span>
<span class="quote">&gt; 2.1.4</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; --</span>
<span class="quote">&gt; To unsubscribe, send a message with &#39;unsubscribe linux-mm&#39; in</span>
<span class="quote">&gt; the body to majordomo@kvack.org.  For more info on Linux MM,</span>
<span class="quote">&gt; see: http://www.linux-mm.org/ .</span>
<span class="quote">&gt; Don&#39;t email: &lt;a href=mailto:&quot;dont@kvack.org&quot;&gt; email@kvack.org &lt;/a&gt;</span>
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/mm/vmscan.c b/mm/vmscan.c</span>
<span class="p_header">index bb01b04154ad..acc6bff84e26 100644</span>
<span class="p_header">--- a/mm/vmscan.c</span>
<span class="p_header">+++ b/mm/vmscan.c</span>
<span class="p_chunk">@@ -1957,10 +1957,11 @@</span> <span class="p_context"> enum scan_balance {</span>
  * nr[0] = anon inactive pages to scan; nr[1] = anon active pages to scan
  * nr[2] = file inactive pages to scan; nr[3] = file active pages to scan
  */
<span class="p_del">-static void get_scan_count(struct lruvec *lruvec, int swappiness,</span>
<span class="p_add">+static void get_scan_count(struct lruvec *lruvec, struct mem_cgroup *memcg,</span>
 			   struct scan_control *sc, unsigned long *nr,
 			   unsigned long *lru_pages)
 {
<span class="p_add">+	int swappiness = mem_cgroup_swappiness(memcg);</span>
 	struct zone_reclaim_stat *reclaim_stat = &amp;lruvec-&gt;reclaim_stat;
 	u64 fraction[2];
 	u64 denominator = 0;	/* gcc */
<span class="p_chunk">@@ -2184,9 +2185,10 @@</span> <span class="p_context"> static inline void init_tlb_ubc(void)</span>
 /*
  * This is a basic per-zone page freer.  Used by both kswapd and direct reclaim.
  */
<span class="p_del">-static void shrink_lruvec(struct lruvec *lruvec, int swappiness,</span>
<span class="p_del">-			  struct scan_control *sc, unsigned long *lru_pages)</span>
<span class="p_add">+static void shrink_zone_memcg(struct zone *zone, struct mem_cgroup *memcg,</span>
<span class="p_add">+			      struct scan_control *sc, unsigned long *lru_pages)</span>
 {
<span class="p_add">+	struct lruvec *lruvec = mem_cgroup_zone_lruvec(zone, memcg);</span>
 	unsigned long nr[NR_LRU_LISTS];
 	unsigned long targets[NR_LRU_LISTS];
 	unsigned long nr_to_scan;
<span class="p_chunk">@@ -2196,7 +2198,7 @@</span> <span class="p_context"> static void shrink_lruvec(struct lruvec *lruvec, int swappiness,</span>
 	struct blk_plug plug;
 	bool scan_adjusted;
 
<span class="p_del">-	get_scan_count(lruvec, swappiness, sc, nr, lru_pages);</span>
<span class="p_add">+	get_scan_count(lruvec, memcg, sc, nr, lru_pages);</span>
 
 	/* Record the original scan target for proportional adjustments later */
 	memcpy(targets, nr, sizeof(nr));
<span class="p_chunk">@@ -2400,8 +2402,6 @@</span> <span class="p_context"> static bool shrink_zone(struct zone *zone, struct scan_control *sc,</span>
 			unsigned long lru_pages;
 			unsigned long reclaimed;
 			unsigned long scanned;
<span class="p_del">-			struct lruvec *lruvec;</span>
<span class="p_del">-			int swappiness;</span>
 
 			if (mem_cgroup_low(root, memcg)) {
 				if (!sc-&gt;may_thrash)
<span class="p_chunk">@@ -2409,12 +2409,10 @@</span> <span class="p_context"> static bool shrink_zone(struct zone *zone, struct scan_control *sc,</span>
 				mem_cgroup_events(memcg, MEMCG_LOW, 1);
 			}
 
<span class="p_del">-			lruvec = mem_cgroup_zone_lruvec(zone, memcg);</span>
<span class="p_del">-			swappiness = mem_cgroup_swappiness(memcg);</span>
 			reclaimed = sc-&gt;nr_reclaimed;
 			scanned = sc-&gt;nr_scanned;
 
<span class="p_del">-			shrink_lruvec(lruvec, swappiness, sc, &amp;lru_pages);</span>
<span class="p_add">+			shrink_zone_memcg(zone, memcg, sc, &amp;lru_pages);</span>
 			zone_lru_pages += lru_pages;
 
 			if (memcg &amp;&amp; is_classzone)
<span class="p_chunk">@@ -2884,8 +2882,6 @@</span> <span class="p_context"> unsigned long mem_cgroup_shrink_node_zone(struct mem_cgroup *memcg,</span>
 		.may_unmap = 1,
 		.may_swap = !noswap,
 	};
<span class="p_del">-	struct lruvec *lruvec = mem_cgroup_zone_lruvec(zone, memcg);</span>
<span class="p_del">-	int swappiness = mem_cgroup_swappiness(memcg);</span>
 	unsigned long lru_pages;
 
 	sc.gfp_mask = (gfp_mask &amp; GFP_RECLAIM_MASK) |
<span class="p_chunk">@@ -2902,7 +2898,7 @@</span> <span class="p_context"> unsigned long mem_cgroup_shrink_node_zone(struct mem_cgroup *memcg,</span>
 	 * will pick up pages from other mem cgroup&#39;s as well. We hack
 	 * the priority and make it zero.
 	 */
<span class="p_del">-	shrink_lruvec(lruvec, swappiness, &amp;sc, &amp;lru_pages);</span>
<span class="p_add">+	shrink_zone_memcg(zone, memcg, &amp;sc, &amp;lru_pages);</span>
 
 	trace_mm_vmscan_memcg_softlimit_reclaim_end(sc.nr_reclaimed);
 

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



