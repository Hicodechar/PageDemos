
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>[RFC,4/4] dma-mapping: Constify dma_attrs - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    [RFC,4/4] dma-mapping: Constify dma_attrs</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=72608">Krzysztof Kozlowski</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>May 24, 2016, 6:28 a.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;1464071290-15948-5-git-send-email-k.kozlowski@samsung.com&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/9132833/mbox/"
   >mbox</a>
|
   <a href="/patch/9132833/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/9132833/">/patch/9132833/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
	[172.30.200.125])
	by pdx-korg-patchwork.web.codeaurora.org (Postfix) with ESMTP id
	EDA486075E for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Tue, 24 May 2016 06:28:53 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id E33D32823B
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Tue, 24 May 2016 06:28:53 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id D7A0C2824F; Tue, 24 May 2016 06:28:53 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-6.9 required=2.0 tests=BAYES_00,RCVD_IN_DNSWL_HI
	autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 1562A2823B
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Tue, 24 May 2016 06:28:52 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1754084AbcEXG23 (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Tue, 24 May 2016 02:28:29 -0400
Received: from mailout3.w1.samsung.com ([210.118.77.13]:20353 &quot;EHLO
	mailout3.w1.samsung.com&quot; rhost-flags-OK-OK-OK-OK) by vger.kernel.org
	with ESMTP id S1753840AbcEXG2Z (ORCPT
	&lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Tue, 24 May 2016 02:28:25 -0400
Received: from eucpsbgm1.samsung.com (unknown [203.254.199.244])
	by mailout3.w1.samsung.com
	(Oracle Communications Messaging Server 7.0.5.31.0 64bit (built May 5
	2014)) with ESMTP id &lt;0O7O008I34N8HX90@mailout3.w1.samsung.com&gt; for
	linux-kernel@vger.kernel.org; Tue, 24 May 2016 07:28:21 +0100 (BST)
X-AuditID: cbfec7f4-f796c6d000001486-2a-5743f4848b37
Received: from eusync4.samsung.com ( [203.254.199.214])
	by eucpsbgm1.samsung.com (EUCPMTA) with SMTP id 55.83.05254.484F3475;
	Tue, 24 May 2016 07:28:20 +0100 (BST)
Received: from AMDC2174.DIGITAL.local ([106.120.53.17])
	by eusync4.samsung.com (Oracle Communications Messaging Server
	7.0.5.31.0 64bit (built May  5 2014))
	with ESMTPA id &lt;0O7O00BQ04N2WW40@eusync4.samsung.com&gt;; Tue,
	24 May 2016 07:28:20 +0100 (BST)
From: Krzysztof Kozlowski &lt;k.kozlowski@samsung.com&gt;
To: Russell King &lt;linux@armlinux.org.uk&gt;,
	Stefano Stabellini &lt;sstabellini@kernel.org&gt;,
	Catalin Marinas &lt;catalin.marinas@arm.com&gt;,
	Will Deacon &lt;will.deacon@arm.com&gt;, Joerg Roedel &lt;joro@8bytes.org&gt;,
	Konrad Rzeszutek Wilk &lt;konrad.wilk@oracle.com&gt;,
	Andrew Morton &lt;akpm@linux-foundation.org&gt;,
	Marek Szyprowski &lt;m.szyprowski@samsung.com&gt;,
	linux-arm-kernel@lists.infradead.org, linux-kernel@vger.kernel.org,
	xen-devel@lists.xenproject.org, iommu@lists.linux-foundation.org
Cc: Krzysztof Kozlowski &lt;k.kozlowski@samsung.com&gt;,
	Bartlomiej Zolnierkiewicz &lt;b.zolnierkie@samsung.com&gt;
Subject: [RFC 4/4] dma-mapping: Constify dma_attrs
Date: Tue, 24 May 2016 08:28:10 +0200
Message-id: &lt;1464071290-15948-5-git-send-email-k.kozlowski@samsung.com&gt;
X-Mailer: git-send-email 1.9.1
In-reply-to: &lt;1464071290-15948-1-git-send-email-k.kozlowski@samsung.com&gt;
References: &lt;1464071290-15948-1-git-send-email-k.kozlowski@samsung.com&gt;
X-Brightmail-Tracker: H4sIAAAAAAAAA+NgFrrELMWRmVeSWpSXmKPExsVy+t/xa7otX5zDDTZu0rWYs34Nm8XGGetZ
	Ld4v62G0WLDf2qJz9gZ2i9cvDC2WLX7KaLHp8TVWi8u75rBZHJq6l9Fi7ZG77Bar18VbvPx4
	gsXi+5bJTA58Hk8OzmPyWDNvDaPH5WsXmT02repk8zgx4zeLx+Yl9R6Tbyxn9Dj84QqLx8en
	t1g8+rasYvT4vEkugDuKyyYlNSezLLVI3y6BK+PXoZNsBbsnMlW8+PSMvYFx3i3GLkYODgkB
	E4mrj3i7GDmBTDGJC/fWs3UxcnEICSxllPi5ZzsTSEJIoJFJYtXNEBCbTcBYYvPyJWBFIgIP
	mSXOzPrLApJgFsiU6Nw7lx3EFhYwkjg24QgbiM0ioCrRNOEBM4jNK+Au0ft1CxPENjmJk8cm
	s4LYnAIeEo2nD7BALHOXmDb7IvsERt4FjAyrGEVTS5MLipPScw31ihNzi0vz0vWS83M3MUJC
	+ssOxsXHrA4xCnAwKvHwBuQ7hwuxJpYVV+YeYpTgYFYS4V1+HSjEm5JYWZValB9fVJqTWnyI
	UZqDRUmcd+6u9yFCAumJJanZqakFqUUwWSYOTqkGxvWfQz/d4LCZ9fHWlssSbFfu/Jp6Z7kN
	b/vW2DeTHntNFfz679tSgSM1Cx87/y0rflFY9k637svVFW4rWWX9n5/f1nAjb2kQG+frgP1L
	AqZqWa/esmNPU53f/itX2Tr3/vorx8j3d6LOw6nqTHM73uzUONI/6+JLE/HcFinFhg+Mv99/
	VnBu3V2sxFKckWioxVxUnAgALWq/j2UCAAA=
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=72608">Krzysztof Kozlowski</a> - May 24, 2016, 6:28 a.m.</div>
<pre class="content">
Pointer to dma_attrs passed to all dma-mapping implementations can point
to const data. This brings some benefits:
 - const-safeness,
 - is a direct indication that ownership of memory is not transferred to
   called functions so it can be safely allocated on the stack (which is
   a pattern already used).

Please have in mind that this is RFC, not finished yet. Only ARM and
ARM64 are fixed. However other API users also have to be converted which
is quite intrusive. I would rather avoid it until the overall approach
is accepted.
<span class="signed-off-by">
Signed-off-by: Krzysztof Kozlowski &lt;k.kozlowski@samsung.com&gt;</span>
---
 arch/arm/include/asm/dma-mapping.h | 12 ++++----
 arch/arm/mm/dma-mapping.c          | 61 +++++++++++++++++++++-----------------
 arch/arm/xen/mm.c                  |  4 +--
 arch/arm64/mm/dma-mapping.c        | 47 +++++++++++++++--------------
 drivers/iommu/dma-iommu.c          |  6 ++--
 include/linux/dma-iommu.h          |  6 ++--
 include/linux/dma-mapping.h        | 34 +++++++++++----------
 include/linux/swiotlb.h            |  9 +++---
 lib/dma-noop.c                     |  9 +++---
 lib/swiotlb.c                      |  9 +++---
 10 files changed, 104 insertions(+), 93 deletions(-)
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/arch/arm/include/asm/dma-mapping.h b/arch/arm/include/asm/dma-mapping.h</span>
<span class="p_header">index a83570f10124..07202beed663 100644</span>
<span class="p_header">--- a/arch/arm/include/asm/dma-mapping.h</span>
<span class="p_header">+++ b/arch/arm/include/asm/dma-mapping.h</span>
<span class="p_chunk">@@ -174,7 +174,7 @@</span> <span class="p_context"> static inline void dma_mark_clean(void *addr, size_t size) { }</span>
  * to be the device-viewed address.
  */
 extern void *arm_dma_alloc(struct device *dev, size_t size, dma_addr_t *handle,
<span class="p_del">-			   gfp_t gfp, struct dma_attrs *attrs);</span>
<span class="p_add">+			   gfp_t gfp, const struct dma_attrs *attrs);</span>
 
 /**
  * arm_dma_free - free memory allocated by arm_dma_alloc
<span class="p_chunk">@@ -191,7 +191,7 @@</span> <span class="p_context"> extern void *arm_dma_alloc(struct device *dev, size_t size, dma_addr_t *handle,</span>
  * during and after this call executing are illegal.
  */
 extern void arm_dma_free(struct device *dev, size_t size, void *cpu_addr,
<span class="p_del">-			 dma_addr_t handle, struct dma_attrs *attrs);</span>
<span class="p_add">+			 dma_addr_t handle, const struct dma_attrs *attrs);</span>
 
 /**
  * arm_dma_mmap - map a coherent DMA allocation into user space
<span class="p_chunk">@@ -208,7 +208,7 @@</span> <span class="p_context"> extern void arm_dma_free(struct device *dev, size_t size, void *cpu_addr,</span>
  */
 extern int arm_dma_mmap(struct device *dev, struct vm_area_struct *vma,
 			void *cpu_addr, dma_addr_t dma_addr, size_t size,
<span class="p_del">-			struct dma_attrs *attrs);</span>
<span class="p_add">+			const struct dma_attrs *attrs);</span>
 
 /*
  * This can be called during early boot to increase the size of the atomic
<span class="p_chunk">@@ -262,16 +262,16 @@</span> <span class="p_context"> extern void dmabounce_unregister_dev(struct device *);</span>
  * The scatter list versions of the above methods.
  */
 extern int arm_dma_map_sg(struct device *, struct scatterlist *, int,
<span class="p_del">-		enum dma_data_direction, struct dma_attrs *attrs);</span>
<span class="p_add">+		enum dma_data_direction, const struct dma_attrs *attrs);</span>
 extern void arm_dma_unmap_sg(struct device *, struct scatterlist *, int,
<span class="p_del">-		enum dma_data_direction, struct dma_attrs *attrs);</span>
<span class="p_add">+		enum dma_data_direction, const struct dma_attrs *attrs);</span>
 extern void arm_dma_sync_sg_for_cpu(struct device *, struct scatterlist *, int,
 		enum dma_data_direction);
 extern void arm_dma_sync_sg_for_device(struct device *, struct scatterlist *, int,
 		enum dma_data_direction);
 extern int arm_dma_get_sgtable(struct device *dev, struct sg_table *sgt,
 		void *cpu_addr, dma_addr_t dma_addr, size_t size,
<span class="p_del">-		struct dma_attrs *attrs);</span>
<span class="p_add">+		const struct dma_attrs *attrs);</span>
 
 #endif /* __KERNEL__ */
 #endif
<span class="p_header">diff --git a/arch/arm/mm/dma-mapping.c b/arch/arm/mm/dma-mapping.c</span>
<span class="p_header">index 4abc50952451..245954e7e343 100644</span>
<span class="p_header">--- a/arch/arm/mm/dma-mapping.c</span>
<span class="p_header">+++ b/arch/arm/mm/dma-mapping.c</span>
<span class="p_chunk">@@ -124,7 +124,7 @@</span> <span class="p_context"> static void __dma_page_dev_to_cpu(struct page *, unsigned long,</span>
  */
 static dma_addr_t arm_dma_map_page(struct device *dev, struct page *page,
 	     unsigned long offset, size_t size, enum dma_data_direction dir,
<span class="p_del">-	     struct dma_attrs *attrs)</span>
<span class="p_add">+	     const struct dma_attrs *attrs)</span>
 {
 	if (!dma_get_attr(DMA_ATTR_SKIP_CPU_SYNC, attrs))
 		__dma_page_cpu_to_dev(page, offset, size, dir);
<span class="p_chunk">@@ -133,7 +133,7 @@</span> <span class="p_context"> static dma_addr_t arm_dma_map_page(struct device *dev, struct page *page,</span>
 
 static dma_addr_t arm_coherent_dma_map_page(struct device *dev, struct page *page,
 	     unsigned long offset, size_t size, enum dma_data_direction dir,
<span class="p_del">-	     struct dma_attrs *attrs)</span>
<span class="p_add">+	     const struct dma_attrs *attrs)</span>
 {
 	return pfn_to_dma(dev, page_to_pfn(page)) + offset;
 }
<span class="p_chunk">@@ -154,7 +154,7 @@</span> <span class="p_context"> static dma_addr_t arm_coherent_dma_map_page(struct device *dev, struct page *pag</span>
  */
 static void arm_dma_unmap_page(struct device *dev, dma_addr_t handle,
 		size_t size, enum dma_data_direction dir,
<span class="p_del">-		struct dma_attrs *attrs)</span>
<span class="p_add">+		const struct dma_attrs *attrs)</span>
 {
 	if (!dma_get_attr(DMA_ATTR_SKIP_CPU_SYNC, attrs))
 		__dma_page_dev_to_cpu(pfn_to_page(dma_to_pfn(dev, handle)),
<span class="p_chunk">@@ -194,12 +194,13 @@</span> <span class="p_context"> struct dma_map_ops arm_dma_ops = {</span>
 EXPORT_SYMBOL(arm_dma_ops);
 
 static void *arm_coherent_dma_alloc(struct device *dev, size_t size,
<span class="p_del">-	dma_addr_t *handle, gfp_t gfp, struct dma_attrs *attrs);</span>
<span class="p_add">+	dma_addr_t *handle, gfp_t gfp, const struct dma_attrs *attrs);</span>
 static void arm_coherent_dma_free(struct device *dev, size_t size, void *cpu_addr,
<span class="p_del">-				  dma_addr_t handle, struct dma_attrs *attrs);</span>
<span class="p_add">+				  dma_addr_t handle,</span>
<span class="p_add">+				  const struct dma_attrs *attrs);</span>
 static int arm_coherent_dma_mmap(struct device *dev, struct vm_area_struct *vma,
 		 void *cpu_addr, dma_addr_t dma_addr, size_t size,
<span class="p_del">-		 struct dma_attrs *attrs);</span>
<span class="p_add">+		 const struct dma_attrs *attrs);</span>
 
 struct dma_map_ops arm_coherent_dma_ops = {
 	.alloc			= arm_coherent_dma_alloc,
<span class="p_chunk">@@ -814,7 +815,7 @@</span> <span class="p_context"> static void *__dma_alloc(struct device *dev, size_t size, dma_addr_t *handle,</span>
  * virtual and bus address for that space.
  */
 void *arm_dma_alloc(struct device *dev, size_t size, dma_addr_t *handle,
<span class="p_del">-		    gfp_t gfp, struct dma_attrs *attrs)</span>
<span class="p_add">+		    gfp_t gfp, const struct dma_attrs *attrs)</span>
 {
 	pgprot_t prot = __get_dma_pgprot(attrs, PAGE_KERNEL);
 
<span class="p_chunk">@@ -823,7 +824,7 @@</span> <span class="p_context"> void *arm_dma_alloc(struct device *dev, size_t size, dma_addr_t *handle,</span>
 }
 
 static void *arm_coherent_dma_alloc(struct device *dev, size_t size,
<span class="p_del">-	dma_addr_t *handle, gfp_t gfp, struct dma_attrs *attrs)</span>
<span class="p_add">+	dma_addr_t *handle, gfp_t gfp, const struct dma_attrs *attrs)</span>
 {
 	return __dma_alloc(dev, size, handle, gfp, PAGE_KERNEL, true,
 			   attrs, __builtin_return_address(0));
<span class="p_chunk">@@ -831,7 +832,7 @@</span> <span class="p_context"> static void *arm_coherent_dma_alloc(struct device *dev, size_t size,</span>
 
 static int __arm_dma_mmap(struct device *dev, struct vm_area_struct *vma,
 		 void *cpu_addr, dma_addr_t dma_addr, size_t size,
<span class="p_del">-		 struct dma_attrs *attrs)</span>
<span class="p_add">+		 const struct dma_attrs *attrs)</span>
 {
 	int ret = -ENXIO;
 #ifdef CONFIG_MMU
<span class="p_chunk">@@ -859,14 +860,14 @@</span> <span class="p_context"> static int __arm_dma_mmap(struct device *dev, struct vm_area_struct *vma,</span>
  */
 static int arm_coherent_dma_mmap(struct device *dev, struct vm_area_struct *vma,
 		 void *cpu_addr, dma_addr_t dma_addr, size_t size,
<span class="p_del">-		 struct dma_attrs *attrs)</span>
<span class="p_add">+		 const struct dma_attrs *attrs)</span>
 {
 	return __arm_dma_mmap(dev, vma, cpu_addr, dma_addr, size, attrs);
 }
 
 int arm_dma_mmap(struct device *dev, struct vm_area_struct *vma,
 		 void *cpu_addr, dma_addr_t dma_addr, size_t size,
<span class="p_del">-		 struct dma_attrs *attrs)</span>
<span class="p_add">+		 const struct dma_attrs *attrs)</span>
 {
 #ifdef CONFIG_MMU
 	vma-&gt;vm_page_prot = __get_dma_pgprot(attrs, vma-&gt;vm_page_prot);
<span class="p_chunk">@@ -900,20 +901,20 @@</span> <span class="p_context"> static void __arm_dma_free(struct device *dev, size_t size, void *cpu_addr,</span>
 }
 
 void arm_dma_free(struct device *dev, size_t size, void *cpu_addr,
<span class="p_del">-		  dma_addr_t handle, struct dma_attrs *attrs)</span>
<span class="p_add">+		  dma_addr_t handle, const struct dma_attrs *attrs)</span>
 {
 	__arm_dma_free(dev, size, cpu_addr, handle, attrs, false);
 }
 
 static void arm_coherent_dma_free(struct device *dev, size_t size, void *cpu_addr,
<span class="p_del">-				  dma_addr_t handle, struct dma_attrs *attrs)</span>
<span class="p_add">+				  dma_addr_t handle, const struct dma_attrs *attrs)</span>
 {
 	__arm_dma_free(dev, size, cpu_addr, handle, attrs, true);
 }
 
 int arm_dma_get_sgtable(struct device *dev, struct sg_table *sgt,
 		 void *cpu_addr, dma_addr_t handle, size_t size,
<span class="p_del">-		 struct dma_attrs *attrs)</span>
<span class="p_add">+		 const struct dma_attrs *attrs)</span>
 {
 	struct page *page = pfn_to_page(dma_to_pfn(dev, handle));
 	int ret;
<span class="p_chunk">@@ -1046,7 +1047,7 @@</span> <span class="p_context"> static void __dma_page_dev_to_cpu(struct page *page, unsigned long off,</span>
  * here.
  */
 int arm_dma_map_sg(struct device *dev, struct scatterlist *sg, int nents,
<span class="p_del">-		enum dma_data_direction dir, struct dma_attrs *attrs)</span>
<span class="p_add">+		enum dma_data_direction dir, const struct dma_attrs *attrs)</span>
 {
 	struct dma_map_ops *ops = get_dma_ops(dev);
 	struct scatterlist *s;
<span class="p_chunk">@@ -1080,7 +1081,7 @@</span> <span class="p_context"> int arm_dma_map_sg(struct device *dev, struct scatterlist *sg, int nents,</span>
  * rules concerning calls here are the same as for dma_unmap_single().
  */
 void arm_dma_unmap_sg(struct device *dev, struct scatterlist *sg, int nents,
<span class="p_del">-		enum dma_data_direction dir, struct dma_attrs *attrs)</span>
<span class="p_add">+		enum dma_data_direction dir, const struct dma_attrs *attrs)</span>
 {
 	struct dma_map_ops *ops = get_dma_ops(dev);
 	struct scatterlist *s;
<span class="p_chunk">@@ -1486,7 +1487,7 @@</span> <span class="p_context"> static void __iommu_free_atomic(struct device *dev, void *cpu_addr,</span>
 }
 
 static void *arm_iommu_alloc_attrs(struct device *dev, size_t size,
<span class="p_del">-	    dma_addr_t *handle, gfp_t gfp, struct dma_attrs *attrs)</span>
<span class="p_add">+	    dma_addr_t *handle, gfp_t gfp, const struct dma_attrs *attrs)</span>
 {
 	pgprot_t prot = __get_dma_pgprot(attrs, PAGE_KERNEL);
 	struct page **pages;
<span class="p_chunk">@@ -1534,7 +1535,7 @@</span> <span class="p_context"> err_buffer:</span>
 
 static int arm_iommu_mmap_attrs(struct device *dev, struct vm_area_struct *vma,
 		    void *cpu_addr, dma_addr_t dma_addr, size_t size,
<span class="p_del">-		    struct dma_attrs *attrs)</span>
<span class="p_add">+		    const struct dma_attrs *attrs)</span>
 {
 	unsigned long uaddr = vma-&gt;vm_start;
 	unsigned long usize = vma-&gt;vm_end - vma-&gt;vm_start;
<span class="p_chunk">@@ -1570,7 +1571,7 @@</span> <span class="p_context"> static int arm_iommu_mmap_attrs(struct device *dev, struct vm_area_struct *vma,</span>
  * Must not be called with IRQs disabled.
  */
 void arm_iommu_free_attrs(struct device *dev, size_t size, void *cpu_addr,
<span class="p_del">-			  dma_addr_t handle, struct dma_attrs *attrs)</span>
<span class="p_add">+			  dma_addr_t handle, const struct dma_attrs *attrs)</span>
 {
 	struct page **pages;
 	size = PAGE_ALIGN(size);
<span class="p_chunk">@@ -1597,7 +1598,7 @@</span> <span class="p_context"> void arm_iommu_free_attrs(struct device *dev, size_t size, void *cpu_addr,</span>
 
 static int arm_iommu_get_sgtable(struct device *dev, struct sg_table *sgt,
 				 void *cpu_addr, dma_addr_t dma_addr,
<span class="p_del">-				 size_t size, struct dma_attrs *attrs)</span>
<span class="p_add">+				 size_t size, const struct dma_attrs *attrs)</span>
 {
 	unsigned int count = PAGE_ALIGN(size) &gt;&gt; PAGE_SHIFT;
 	struct page **pages = __iommu_get_pages(cpu_addr, attrs);
<span class="p_chunk">@@ -1736,7 +1737,8 @@</span> <span class="p_context"> bad_mapping:</span>
  * obtained via sg_dma_{address,length}.
  */
 int arm_coherent_iommu_map_sg(struct device *dev, struct scatterlist *sg,
<span class="p_del">-		int nents, enum dma_data_direction dir, struct dma_attrs *attrs)</span>
<span class="p_add">+		int nents, enum dma_data_direction dir,</span>
<span class="p_add">+		const struct dma_attrs *attrs)</span>
 {
 	return __iommu_map_sg(dev, sg, nents, dir, attrs, true);
 }
<span class="p_chunk">@@ -1754,7 +1756,8 @@</span> <span class="p_context"> int arm_coherent_iommu_map_sg(struct device *dev, struct scatterlist *sg,</span>
  * sg_dma_{address,length}.
  */
 int arm_iommu_map_sg(struct device *dev, struct scatterlist *sg,
<span class="p_del">-		int nents, enum dma_data_direction dir, struct dma_attrs *attrs)</span>
<span class="p_add">+		int nents, enum dma_data_direction dir,</span>
<span class="p_add">+		const struct dma_attrs *attrs)</span>
 {
 	return __iommu_map_sg(dev, sg, nents, dir, attrs, false);
 }
<span class="p_chunk">@@ -1788,7 +1791,8 @@</span> <span class="p_context"> static void __iommu_unmap_sg(struct device *dev, struct scatterlist *sg,</span>
  * rules concerning calls here are the same as for dma_unmap_single().
  */
 void arm_coherent_iommu_unmap_sg(struct device *dev, struct scatterlist *sg,
<span class="p_del">-		int nents, enum dma_data_direction dir, struct dma_attrs *attrs)</span>
<span class="p_add">+		int nents, enum dma_data_direction dir,</span>
<span class="p_add">+		const struct dma_attrs *attrs)</span>
 {
 	__iommu_unmap_sg(dev, sg, nents, dir, attrs, true);
 }
<span class="p_chunk">@@ -1804,7 +1808,8 @@</span> <span class="p_context"> void arm_coherent_iommu_unmap_sg(struct device *dev, struct scatterlist *sg,</span>
  * rules concerning calls here are the same as for dma_unmap_single().
  */
 void arm_iommu_unmap_sg(struct device *dev, struct scatterlist *sg, int nents,
<span class="p_del">-			enum dma_data_direction dir, struct dma_attrs *attrs)</span>
<span class="p_add">+			enum dma_data_direction dir,</span>
<span class="p_add">+			const struct dma_attrs *attrs)</span>
 {
 	__iommu_unmap_sg(dev, sg, nents, dir, attrs, false);
 }
<span class="p_chunk">@@ -1857,7 +1862,7 @@</span> <span class="p_context"> void arm_iommu_sync_sg_for_device(struct device *dev, struct scatterlist *sg,</span>
  */
 static dma_addr_t arm_coherent_iommu_map_page(struct device *dev, struct page *page,
 	     unsigned long offset, size_t size, enum dma_data_direction dir,
<span class="p_del">-	     struct dma_attrs *attrs)</span>
<span class="p_add">+	     const struct dma_attrs *attrs)</span>
 {
 	struct dma_iommu_mapping *mapping = to_dma_iommu_mapping(dev);
 	dma_addr_t dma_addr;
<span class="p_chunk">@@ -1891,7 +1896,7 @@</span> <span class="p_context"> fail:</span>
  */
 static dma_addr_t arm_iommu_map_page(struct device *dev, struct page *page,
 	     unsigned long offset, size_t size, enum dma_data_direction dir,
<span class="p_del">-	     struct dma_attrs *attrs)</span>
<span class="p_add">+	     const struct dma_attrs *attrs)</span>
 {
 	if (!dma_get_attr(DMA_ATTR_SKIP_CPU_SYNC, attrs))
 		__dma_page_cpu_to_dev(page, offset, size, dir);
<span class="p_chunk">@@ -1910,7 +1915,7 @@</span> <span class="p_context"> static dma_addr_t arm_iommu_map_page(struct device *dev, struct page *page,</span>
  */
 static void arm_coherent_iommu_unmap_page(struct device *dev, dma_addr_t handle,
 		size_t size, enum dma_data_direction dir,
<span class="p_del">-		struct dma_attrs *attrs)</span>
<span class="p_add">+		const struct dma_attrs *attrs)</span>
 {
 	struct dma_iommu_mapping *mapping = to_dma_iommu_mapping(dev);
 	dma_addr_t iova = handle &amp; PAGE_MASK;
<span class="p_chunk">@@ -1935,7 +1940,7 @@</span> <span class="p_context"> static void arm_coherent_iommu_unmap_page(struct device *dev, dma_addr_t handle,</span>
  */
 static void arm_iommu_unmap_page(struct device *dev, dma_addr_t handle,
 		size_t size, enum dma_data_direction dir,
<span class="p_del">-		struct dma_attrs *attrs)</span>
<span class="p_add">+		const struct dma_attrs *attrs)</span>
 {
 	struct dma_iommu_mapping *mapping = to_dma_iommu_mapping(dev);
 	dma_addr_t iova = handle &amp; PAGE_MASK;
<span class="p_header">diff --git a/arch/arm/xen/mm.c b/arch/arm/xen/mm.c</span>
<span class="p_header">index c5f9a9e3d1f3..0af2fbbc25be 100644</span>
<span class="p_header">--- a/arch/arm/xen/mm.c</span>
<span class="p_header">+++ b/arch/arm/xen/mm.c</span>
<span class="p_chunk">@@ -98,7 +98,7 @@</span> <span class="p_context"> static void __xen_dma_page_cpu_to_dev(struct device *hwdev, dma_addr_t handle,</span>
 
 void __xen_dma_map_page(struct device *hwdev, struct page *page,
 	     dma_addr_t dev_addr, unsigned long offset, size_t size,
<span class="p_del">-	     enum dma_data_direction dir, struct dma_attrs *attrs)</span>
<span class="p_add">+	     enum dma_data_direction dir, const struct dma_attrs *attrs)</span>
 {
 	if (is_device_dma_coherent(hwdev))
 		return;
<span class="p_chunk">@@ -110,7 +110,7 @@</span> <span class="p_context"> void __xen_dma_map_page(struct device *hwdev, struct page *page,</span>
 
 void __xen_dma_unmap_page(struct device *hwdev, dma_addr_t handle,
 		size_t size, enum dma_data_direction dir,
<span class="p_del">-		struct dma_attrs *attrs)</span>
<span class="p_add">+		const struct dma_attrs *attrs)</span>
 
 {
 	if (is_device_dma_coherent(hwdev))
<span class="p_header">diff --git a/arch/arm64/mm/dma-mapping.c b/arch/arm64/mm/dma-mapping.c</span>
<span class="p_header">index 0ef620a34c4e..9f6c6b12db30 100644</span>
<span class="p_header">--- a/arch/arm64/mm/dma-mapping.c</span>
<span class="p_header">+++ b/arch/arm64/mm/dma-mapping.c</span>
<span class="p_chunk">@@ -137,7 +137,7 @@</span> <span class="p_context"> static void __dma_free_coherent(struct device *dev, size_t size,</span>
 
 static void *__dma_alloc(struct device *dev, size_t size,
 			 dma_addr_t *dma_handle, gfp_t flags,
<span class="p_del">-			 struct dma_attrs *attrs)</span>
<span class="p_add">+			 const struct dma_attrs *attrs)</span>
 {
 	struct page *page;
 	void *ptr, *coherent_ptr;
<span class="p_chunk">@@ -185,7 +185,7 @@</span> <span class="p_context"> no_mem:</span>
 
 static void __dma_free(struct device *dev, size_t size,
 		       void *vaddr, dma_addr_t dma_handle,
<span class="p_del">-		       struct dma_attrs *attrs)</span>
<span class="p_add">+		       const struct dma_attrs *attrs)</span>
 {
 	void *swiotlb_addr = phys_to_virt(dma_to_phys(dev, dma_handle));
 
<span class="p_chunk">@@ -202,7 +202,7 @@</span> <span class="p_context"> static void __dma_free(struct device *dev, size_t size,</span>
 static dma_addr_t __swiotlb_map_page(struct device *dev, struct page *page,
 				     unsigned long offset, size_t size,
 				     enum dma_data_direction dir,
<span class="p_del">-				     struct dma_attrs *attrs)</span>
<span class="p_add">+				     const struct dma_attrs *attrs)</span>
 {
 	dma_addr_t dev_addr;
 
<span class="p_chunk">@@ -216,7 +216,7 @@</span> <span class="p_context"> static dma_addr_t __swiotlb_map_page(struct device *dev, struct page *page,</span>
 
 static void __swiotlb_unmap_page(struct device *dev, dma_addr_t dev_addr,
 				 size_t size, enum dma_data_direction dir,
<span class="p_del">-				 struct dma_attrs *attrs)</span>
<span class="p_add">+				 const struct dma_attrs *attrs)</span>
 {
 	if (!is_device_dma_coherent(dev))
 		__dma_unmap_area(phys_to_virt(dma_to_phys(dev, dev_addr)), size, dir);
<span class="p_chunk">@@ -225,7 +225,7 @@</span> <span class="p_context"> static void __swiotlb_unmap_page(struct device *dev, dma_addr_t dev_addr,</span>
 
 static int __swiotlb_map_sg_attrs(struct device *dev, struct scatterlist *sgl,
 				  int nelems, enum dma_data_direction dir,
<span class="p_del">-				  struct dma_attrs *attrs)</span>
<span class="p_add">+				  const struct dma_attrs *attrs)</span>
 {
 	struct scatterlist *sg;
 	int i, ret;
<span class="p_chunk">@@ -242,7 +242,7 @@</span> <span class="p_context"> static int __swiotlb_map_sg_attrs(struct device *dev, struct scatterlist *sgl,</span>
 static void __swiotlb_unmap_sg_attrs(struct device *dev,
 				     struct scatterlist *sgl, int nelems,
 				     enum dma_data_direction dir,
<span class="p_del">-				     struct dma_attrs *attrs)</span>
<span class="p_add">+				     const struct dma_attrs *attrs)</span>
 {
 	struct scatterlist *sg;
 	int i;
<span class="p_chunk">@@ -303,7 +303,7 @@</span> <span class="p_context"> static void __swiotlb_sync_sg_for_device(struct device *dev,</span>
 static int __swiotlb_mmap(struct device *dev,
 			  struct vm_area_struct *vma,
 			  void *cpu_addr, dma_addr_t dma_addr, size_t size,
<span class="p_del">-			  struct dma_attrs *attrs)</span>
<span class="p_add">+			  const struct dma_attrs *attrs)</span>
 {
 	int ret = -ENXIO;
 	unsigned long nr_vma_pages = (vma-&gt;vm_end - vma-&gt;vm_start) &gt;&gt;
<span class="p_chunk">@@ -330,7 +330,7 @@</span> <span class="p_context"> static int __swiotlb_mmap(struct device *dev,</span>
 
 static int __swiotlb_get_sgtable(struct device *dev, struct sg_table *sgt,
 				 void *cpu_addr, dma_addr_t handle, size_t size,
<span class="p_del">-				 struct dma_attrs *attrs)</span>
<span class="p_add">+				 const struct dma_attrs *attrs)</span>
 {
 	int ret = sg_alloc_table(sgt, 1, GFP_KERNEL);
 
<span class="p_chunk">@@ -425,21 +425,21 @@</span> <span class="p_context"> out:</span>
 
 static void *__dummy_alloc(struct device *dev, size_t size,
 			   dma_addr_t *dma_handle, gfp_t flags,
<span class="p_del">-			   struct dma_attrs *attrs)</span>
<span class="p_add">+			   const struct dma_attrs *attrs)</span>
 {
 	return NULL;
 }
 
 static void __dummy_free(struct device *dev, size_t size,
 			 void *vaddr, dma_addr_t dma_handle,
<span class="p_del">-			 struct dma_attrs *attrs)</span>
<span class="p_add">+			 const struct dma_attrs *attrs)</span>
 {
 }
 
 static int __dummy_mmap(struct device *dev,
 			struct vm_area_struct *vma,
 			void *cpu_addr, dma_addr_t dma_addr, size_t size,
<span class="p_del">-			struct dma_attrs *attrs)</span>
<span class="p_add">+			const struct dma_attrs *attrs)</span>
 {
 	return -ENXIO;
 }
<span class="p_chunk">@@ -447,20 +447,20 @@</span> <span class="p_context"> static int __dummy_mmap(struct device *dev,</span>
 static dma_addr_t __dummy_map_page(struct device *dev, struct page *page,
 				   unsigned long offset, size_t size,
 				   enum dma_data_direction dir,
<span class="p_del">-				   struct dma_attrs *attrs)</span>
<span class="p_add">+				   const struct dma_attrs *attrs)</span>
 {
 	return DMA_ERROR_CODE;
 }
 
 static void __dummy_unmap_page(struct device *dev, dma_addr_t dev_addr,
 			       size_t size, enum dma_data_direction dir,
<span class="p_del">-			       struct dma_attrs *attrs)</span>
<span class="p_add">+			       const struct dma_attrs *attrs)</span>
 {
 }
 
 static int __dummy_map_sg(struct device *dev, struct scatterlist *sgl,
 			  int nelems, enum dma_data_direction dir,
<span class="p_del">-			  struct dma_attrs *attrs)</span>
<span class="p_add">+			  const struct dma_attrs *attrs)</span>
 {
 	return 0;
 }
<span class="p_chunk">@@ -468,7 +468,7 @@</span> <span class="p_context"> static int __dummy_map_sg(struct device *dev, struct scatterlist *sgl,</span>
 static void __dummy_unmap_sg(struct device *dev,
 			     struct scatterlist *sgl, int nelems,
 			     enum dma_data_direction dir,
<span class="p_del">-			     struct dma_attrs *attrs)</span>
<span class="p_add">+			     const struct dma_attrs *attrs)</span>
 {
 }
 
<span class="p_chunk">@@ -540,7 +540,7 @@</span> <span class="p_context"> static void flush_page(struct device *dev, const void *virt, phys_addr_t phys)</span>
 
 static void *__iommu_alloc_attrs(struct device *dev, size_t size,
 				 dma_addr_t *handle, gfp_t gfp,
<span class="p_del">-				 struct dma_attrs *attrs)</span>
<span class="p_add">+				 const struct dma_attrs *attrs)</span>
 {
 	bool coherent = is_device_dma_coherent(dev);
 	int ioprot = dma_direction_to_prot(DMA_BIDIRECTIONAL, coherent);
<span class="p_chunk">@@ -600,7 +600,8 @@</span> <span class="p_context"> static void *__iommu_alloc_attrs(struct device *dev, size_t size,</span>
 }
 
 static void __iommu_free_attrs(struct device *dev, size_t size, void *cpu_addr,
<span class="p_del">-			       dma_addr_t handle, struct dma_attrs *attrs)</span>
<span class="p_add">+			       dma_addr_t handle,</span>
<span class="p_add">+			       const struct dma_attrs *attrs)</span>
 {
 	size_t iosize = size;
 
<span class="p_chunk">@@ -633,7 +634,7 @@</span> <span class="p_context"> static void __iommu_free_attrs(struct device *dev, size_t size, void *cpu_addr,</span>
 
 static int __iommu_mmap_attrs(struct device *dev, struct vm_area_struct *vma,
 			      void *cpu_addr, dma_addr_t dma_addr, size_t size,
<span class="p_del">-			      struct dma_attrs *attrs)</span>
<span class="p_add">+			      const struct dma_attrs *attrs)</span>
 {
 	struct vm_struct *area;
 	int ret;
<span class="p_chunk">@@ -653,7 +654,7 @@</span> <span class="p_context"> static int __iommu_mmap_attrs(struct device *dev, struct vm_area_struct *vma,</span>
 
 static int __iommu_get_sgtable(struct device *dev, struct sg_table *sgt,
 			       void *cpu_addr, dma_addr_t dma_addr,
<span class="p_del">-			       size_t size, struct dma_attrs *attrs)</span>
<span class="p_add">+			       size_t size, const struct dma_attrs *attrs)</span>
 {
 	unsigned int count = PAGE_ALIGN(size) &gt;&gt; PAGE_SHIFT;
 	struct vm_struct *area = find_vm_area(cpu_addr);
<span class="p_chunk">@@ -694,7 +695,7 @@</span> <span class="p_context"> static void __iommu_sync_single_for_device(struct device *dev,</span>
 static dma_addr_t __iommu_map_page(struct device *dev, struct page *page,
 				   unsigned long offset, size_t size,
 				   enum dma_data_direction dir,
<span class="p_del">-				   struct dma_attrs *attrs)</span>
<span class="p_add">+				   const struct dma_attrs *attrs)</span>
 {
 	bool coherent = is_device_dma_coherent(dev);
 	int prot = dma_direction_to_prot(dir, coherent);
<span class="p_chunk">@@ -709,7 +710,7 @@</span> <span class="p_context"> static dma_addr_t __iommu_map_page(struct device *dev, struct page *page,</span>
 
 static void __iommu_unmap_page(struct device *dev, dma_addr_t dev_addr,
 			       size_t size, enum dma_data_direction dir,
<span class="p_del">-			       struct dma_attrs *attrs)</span>
<span class="p_add">+			       const struct dma_attrs *attrs)</span>
 {
 	if (!dma_get_attr(DMA_ATTR_SKIP_CPU_SYNC, attrs))
 		__iommu_sync_single_for_cpu(dev, dev_addr, size, dir);
<span class="p_chunk">@@ -747,7 +748,7 @@</span> <span class="p_context"> static void __iommu_sync_sg_for_device(struct device *dev,</span>
 
 static int __iommu_map_sg_attrs(struct device *dev, struct scatterlist *sgl,
 				int nelems, enum dma_data_direction dir,
<span class="p_del">-				struct dma_attrs *attrs)</span>
<span class="p_add">+				const struct dma_attrs *attrs)</span>
 {
 	bool coherent = is_device_dma_coherent(dev);
 
<span class="p_chunk">@@ -761,7 +762,7 @@</span> <span class="p_context"> static int __iommu_map_sg_attrs(struct device *dev, struct scatterlist *sgl,</span>
 static void __iommu_unmap_sg_attrs(struct device *dev,
 				   struct scatterlist *sgl, int nelems,
 				   enum dma_data_direction dir,
<span class="p_del">-				   struct dma_attrs *attrs)</span>
<span class="p_add">+				   const struct dma_attrs *attrs)</span>
 {
 	if (!dma_get_attr(DMA_ATTR_SKIP_CPU_SYNC, attrs))
 		__iommu_sync_sg_for_cpu(dev, sgl, nelems, dir);
<span class="p_header">diff --git a/drivers/iommu/dma-iommu.c b/drivers/iommu/dma-iommu.c</span>
<span class="p_header">index ea5a9ebf0f78..69eb1fdce971 100644</span>
<span class="p_header">--- a/drivers/iommu/dma-iommu.c</span>
<span class="p_header">+++ b/drivers/iommu/dma-iommu.c</span>
<span class="p_chunk">@@ -286,7 +286,7 @@</span> <span class="p_context"> void iommu_dma_free(struct device *dev, struct page **pages, size_t size,</span>
  *	   or NULL on failure.
  */
 struct page **iommu_dma_alloc(struct device *dev, size_t size, gfp_t gfp,
<span class="p_del">-		struct dma_attrs *attrs, int prot, dma_addr_t *handle,</span>
<span class="p_add">+		const struct dma_attrs *attrs, int prot, dma_addr_t *handle,</span>
 		void (*flush_page)(struct device *, const void *, phys_addr_t))
 {
 	struct iommu_domain *domain = iommu_get_domain_for_dev(dev);
<span class="p_chunk">@@ -400,7 +400,7 @@</span> <span class="p_context"> dma_addr_t iommu_dma_map_page(struct device *dev, struct page *page,</span>
 }
 
 void iommu_dma_unmap_page(struct device *dev, dma_addr_t handle, size_t size,
<span class="p_del">-		enum dma_data_direction dir, struct dma_attrs *attrs)</span>
<span class="p_add">+		enum dma_data_direction dir, const struct dma_attrs *attrs)</span>
 {
 	__iommu_dma_unmap(iommu_get_domain_for_dev(dev), handle);
 }
<span class="p_chunk">@@ -560,7 +560,7 @@</span> <span class="p_context"> out_restore_sg:</span>
 }
 
 void iommu_dma_unmap_sg(struct device *dev, struct scatterlist *sg, int nents,
<span class="p_del">-		enum dma_data_direction dir, struct dma_attrs *attrs)</span>
<span class="p_add">+		enum dma_data_direction dir, const struct dma_attrs *attrs)</span>
 {
 	/*
 	 * The scatterlist segments are mapped into a single
<span class="p_header">diff --git a/include/linux/dma-iommu.h b/include/linux/dma-iommu.h</span>
<span class="p_header">index 8443bbb5c071..797b47bc6dae 100644</span>
<span class="p_header">--- a/include/linux/dma-iommu.h</span>
<span class="p_header">+++ b/include/linux/dma-iommu.h</span>
<span class="p_chunk">@@ -39,7 +39,7 @@</span> <span class="p_context"> int dma_direction_to_prot(enum dma_data_direction dir, bool coherent);</span>
  * the arch code to take care of attributes and cache maintenance
  */
 struct page **iommu_dma_alloc(struct device *dev, size_t size, gfp_t gfp,
<span class="p_del">-		struct dma_attrs *attrs, int prot, dma_addr_t *handle,</span>
<span class="p_add">+		const struct dma_attrs *attrs, int prot, dma_addr_t *handle,</span>
 		void (*flush_page)(struct device *, const void *, phys_addr_t));
 void iommu_dma_free(struct device *dev, struct page **pages, size_t size,
 		dma_addr_t *handle);
<span class="p_chunk">@@ -56,9 +56,9 @@</span> <span class="p_context"> int iommu_dma_map_sg(struct device *dev, struct scatterlist *sg,</span>
  * directly as DMA mapping callbacks for simplicity
  */
 void iommu_dma_unmap_page(struct device *dev, dma_addr_t handle, size_t size,
<span class="p_del">-		enum dma_data_direction dir, struct dma_attrs *attrs);</span>
<span class="p_add">+		enum dma_data_direction dir, const struct dma_attrs *attrs);</span>
 void iommu_dma_unmap_sg(struct device *dev, struct scatterlist *sg, int nents,
<span class="p_del">-		enum dma_data_direction dir, struct dma_attrs *attrs);</span>
<span class="p_add">+		enum dma_data_direction dir, const struct dma_attrs *attrs);</span>
 int iommu_dma_supported(struct device *dev, u64 mask);
 int iommu_dma_mapping_error(struct device *dev, dma_addr_t dma_addr);
 
<span class="p_header">diff --git a/include/linux/dma-mapping.h b/include/linux/dma-mapping.h</span>
<span class="p_header">index 71c1b215ef66..c8b339436dfa 100644</span>
<span class="p_header">--- a/include/linux/dma-mapping.h</span>
<span class="p_header">+++ b/include/linux/dma-mapping.h</span>
<span class="p_chunk">@@ -21,34 +21,35 @@</span> <span class="p_context"></span>
 struct dma_map_ops {
 	void* (*alloc)(struct device *dev, size_t size,
 				dma_addr_t *dma_handle, gfp_t gfp,
<span class="p_del">-				struct dma_attrs *attrs);</span>
<span class="p_add">+				const struct dma_attrs *attrs);</span>
 	void (*free)(struct device *dev, size_t size,
 			      void *vaddr, dma_addr_t dma_handle,
<span class="p_del">-			      struct dma_attrs *attrs);</span>
<span class="p_add">+			      const struct dma_attrs *attrs);</span>
 	int (*mmap)(struct device *, struct vm_area_struct *,
<span class="p_del">-			  void *, dma_addr_t, size_t, struct dma_attrs *attrs);</span>
<span class="p_add">+			  void *, dma_addr_t, size_t,</span>
<span class="p_add">+			  const struct dma_attrs *attrs);</span>
 
 	int (*get_sgtable)(struct device *dev, struct sg_table *sgt, void *,
<span class="p_del">-			   dma_addr_t, size_t, struct dma_attrs *attrs);</span>
<span class="p_add">+			   dma_addr_t, size_t, const struct dma_attrs *attrs);</span>
 
 	dma_addr_t (*map_page)(struct device *dev, struct page *page,
 			       unsigned long offset, size_t size,
 			       enum dma_data_direction dir,
<span class="p_del">-			       struct dma_attrs *attrs);</span>
<span class="p_add">+			       const struct dma_attrs *attrs);</span>
 	void (*unmap_page)(struct device *dev, dma_addr_t dma_handle,
 			   size_t size, enum dma_data_direction dir,
<span class="p_del">-			   struct dma_attrs *attrs);</span>
<span class="p_add">+			   const struct dma_attrs *attrs);</span>
 	/*
 	 * map_sg returns 0 on error and a value &gt; 0 on success.
 	 * It should never return a value &lt; 0.
 	 */
 	int (*map_sg)(struct device *dev, struct scatterlist *sg,
 		      int nents, enum dma_data_direction dir,
<span class="p_del">-		      struct dma_attrs *attrs);</span>
<span class="p_add">+		      const struct dma_attrs *attrs);</span>
 	void (*unmap_sg)(struct device *dev,
 			 struct scatterlist *sg, int nents,
 			 enum dma_data_direction dir,
<span class="p_del">-			 struct dma_attrs *attrs);</span>
<span class="p_add">+			 const struct dma_attrs *attrs);</span>
 	void (*sync_single_for_cpu)(struct device *dev,
 				    dma_addr_t dma_handle, size_t size,
 				    enum dma_data_direction dir);
<span class="p_chunk">@@ -123,7 +124,7 @@</span> <span class="p_context"> static inline struct dma_map_ops *get_dma_ops(struct device *dev)</span>
 static inline dma_addr_t dma_map_single_attrs(struct device *dev, void *ptr,
 					      size_t size,
 					      enum dma_data_direction dir,
<span class="p_del">-					      struct dma_attrs *attrs)</span>
<span class="p_add">+					      const struct dma_attrs *attrs)</span>
 {
 	struct dma_map_ops *ops = get_dma_ops(dev);
 	dma_addr_t addr;
<span class="p_chunk">@@ -142,7 +143,7 @@</span> <span class="p_context"> static inline dma_addr_t dma_map_single_attrs(struct device *dev, void *ptr,</span>
 static inline void dma_unmap_single_attrs(struct device *dev, dma_addr_t addr,
 					  size_t size,
 					  enum dma_data_direction dir,
<span class="p_del">-					  struct dma_attrs *attrs)</span>
<span class="p_add">+					  const struct dma_attrs *attrs)</span>
 {
 	struct dma_map_ops *ops = get_dma_ops(dev);
 
<span class="p_chunk">@@ -158,7 +159,7 @@</span> <span class="p_context"> static inline void dma_unmap_single_attrs(struct device *dev, dma_addr_t addr,</span>
  */
 static inline int dma_map_sg_attrs(struct device *dev, struct scatterlist *sg,
 				   int nents, enum dma_data_direction dir,
<span class="p_del">-				   struct dma_attrs *attrs)</span>
<span class="p_add">+				   const struct dma_attrs *attrs)</span>
 {
 	struct dma_map_ops *ops = get_dma_ops(dev);
 	int i, ents;
<span class="p_chunk">@@ -176,7 +177,7 @@</span> <span class="p_context"> static inline int dma_map_sg_attrs(struct device *dev, struct scatterlist *sg,</span>
 
 static inline void dma_unmap_sg_attrs(struct device *dev, struct scatterlist *sg,
 				      int nents, enum dma_data_direction dir,
<span class="p_del">-				      struct dma_attrs *attrs)</span>
<span class="p_add">+				      const struct dma_attrs *attrs)</span>
 {
 	struct dma_map_ops *ops = get_dma_ops(dev);
 
<span class="p_chunk">@@ -321,7 +322,7 @@</span> <span class="p_context"> void dma_common_free_remap(void *cpu_addr, size_t size, unsigned long vm_flags);</span>
  */
 static inline int
 dma_mmap_attrs(struct device *dev, struct vm_area_struct *vma, void *cpu_addr,
<span class="p_del">-	       dma_addr_t dma_addr, size_t size, struct dma_attrs *attrs)</span>
<span class="p_add">+	       dma_addr_t dma_addr, size_t size, const struct dma_attrs *attrs)</span>
 {
 	struct dma_map_ops *ops = get_dma_ops(dev);
 	BUG_ON(!ops);
<span class="p_chunk">@@ -338,7 +339,8 @@</span> <span class="p_context"> dma_common_get_sgtable(struct device *dev, struct sg_table *sgt,</span>
 
 static inline int
 dma_get_sgtable_attrs(struct device *dev, struct sg_table *sgt, void *cpu_addr,
<span class="p_del">-		      dma_addr_t dma_addr, size_t size, struct dma_attrs *attrs)</span>
<span class="p_add">+		      dma_addr_t dma_addr, size_t size,</span>
<span class="p_add">+		      const struct dma_attrs *attrs)</span>
 {
 	struct dma_map_ops *ops = get_dma_ops(dev);
 	BUG_ON(!ops);
<span class="p_chunk">@@ -356,7 +358,7 @@</span> <span class="p_context"> dma_get_sgtable_attrs(struct device *dev, struct sg_table *sgt, void *cpu_addr,</span>
 
 static inline void *dma_alloc_attrs(struct device *dev, size_t size,
 				       dma_addr_t *dma_handle, gfp_t flag,
<span class="p_del">-				       struct dma_attrs *attrs)</span>
<span class="p_add">+				       const struct dma_attrs *attrs)</span>
 {
 	struct dma_map_ops *ops = get_dma_ops(dev);
 	void *cpu_addr;
<span class="p_chunk">@@ -378,7 +380,7 @@</span> <span class="p_context"> static inline void *dma_alloc_attrs(struct device *dev, size_t size,</span>
 
 static inline void dma_free_attrs(struct device *dev, size_t size,
 				     void *cpu_addr, dma_addr_t dma_handle,
<span class="p_del">-				     struct dma_attrs *attrs)</span>
<span class="p_add">+				     const struct dma_attrs *attrs)</span>
 {
 	struct dma_map_ops *ops = get_dma_ops(dev);
 
<span class="p_header">diff --git a/include/linux/swiotlb.h b/include/linux/swiotlb.h</span>
<span class="p_header">index 017fced60242..0ff87d75982b 100644</span>
<span class="p_header">--- a/include/linux/swiotlb.h</span>
<span class="p_header">+++ b/include/linux/swiotlb.h</span>
<span class="p_chunk">@@ -68,10 +68,10 @@</span> <span class="p_context"> swiotlb_free_coherent(struct device *hwdev, size_t size,</span>
 extern dma_addr_t swiotlb_map_page(struct device *dev, struct page *page,
 				   unsigned long offset, size_t size,
 				   enum dma_data_direction dir,
<span class="p_del">-				   struct dma_attrs *attrs);</span>
<span class="p_add">+				   const struct dma_attrs *attrs);</span>
 extern void swiotlb_unmap_page(struct device *hwdev, dma_addr_t dev_addr,
 			       size_t size, enum dma_data_direction dir,
<span class="p_del">-			       struct dma_attrs *attrs);</span>
<span class="p_add">+			       const struct dma_attrs *attrs);</span>
 
 extern int
 swiotlb_map_sg(struct device *hwdev, struct scatterlist *sg, int nents,
<span class="p_chunk">@@ -83,12 +83,13 @@</span> <span class="p_context"> swiotlb_unmap_sg(struct device *hwdev, struct scatterlist *sg, int nents,</span>
 
 extern int
 swiotlb_map_sg_attrs(struct device *hwdev, struct scatterlist *sgl, int nelems,
<span class="p_del">-		     enum dma_data_direction dir, struct dma_attrs *attrs);</span>
<span class="p_add">+		     enum dma_data_direction dir,</span>
<span class="p_add">+		     const struct dma_attrs *attrs);</span>
 
 extern void
 swiotlb_unmap_sg_attrs(struct device *hwdev, struct scatterlist *sgl,
 		       int nelems, enum dma_data_direction dir,
<span class="p_del">-		       struct dma_attrs *attrs);</span>
<span class="p_add">+		       const struct dma_attrs *attrs);</span>
 
 extern void
 swiotlb_sync_single_for_cpu(struct device *hwdev, dma_addr_t dev_addr,
<span class="p_header">diff --git a/lib/dma-noop.c b/lib/dma-noop.c</span>
<span class="p_header">index 72145646857e..22e44fc26eba 100644</span>
<span class="p_header">--- a/lib/dma-noop.c</span>
<span class="p_header">+++ b/lib/dma-noop.c</span>
<span class="p_chunk">@@ -10,7 +10,7 @@</span> <span class="p_context"></span>
 
 static void *dma_noop_alloc(struct device *dev, size_t size,
 			    dma_addr_t *dma_handle, gfp_t gfp,
<span class="p_del">-			    struct dma_attrs *attrs)</span>
<span class="p_add">+			    const struct dma_attrs *attrs)</span>
 {
 	void *ret;
 
<span class="p_chunk">@@ -22,7 +22,7 @@</span> <span class="p_context"> static void *dma_noop_alloc(struct device *dev, size_t size,</span>
 
 static void dma_noop_free(struct device *dev, size_t size,
 			  void *cpu_addr, dma_addr_t dma_addr,
<span class="p_del">-			  struct dma_attrs *attrs)</span>
<span class="p_add">+			  const struct dma_attrs *attrs)</span>
 {
 	free_pages((unsigned long)cpu_addr, get_order(size));
 }
<span class="p_chunk">@@ -30,13 +30,14 @@</span> <span class="p_context"> static void dma_noop_free(struct device *dev, size_t size,</span>
 static dma_addr_t dma_noop_map_page(struct device *dev, struct page *page,
 				      unsigned long offset, size_t size,
 				      enum dma_data_direction dir,
<span class="p_del">-				      struct dma_attrs *attrs)</span>
<span class="p_add">+				      const struct dma_attrs *attrs)</span>
 {
 	return page_to_phys(page) + offset;
 }
 
 static int dma_noop_map_sg(struct device *dev, struct scatterlist *sgl, int nents,
<span class="p_del">-			     enum dma_data_direction dir, struct dma_attrs *attrs)</span>
<span class="p_add">+			     enum dma_data_direction dir,</span>
<span class="p_add">+			     const struct dma_attrs *attrs)</span>
 {
 	int i;
 	struct scatterlist *sg;
<span class="p_header">diff --git a/lib/swiotlb.c b/lib/swiotlb.c</span>
<span class="p_header">index 76f29ecba8f4..f881405d0b17 100644</span>
<span class="p_header">--- a/lib/swiotlb.c</span>
<span class="p_header">+++ b/lib/swiotlb.c</span>
<span class="p_chunk">@@ -738,7 +738,7 @@</span> <span class="p_context"> swiotlb_full(struct device *dev, size_t size, enum dma_data_direction dir,</span>
 dma_addr_t swiotlb_map_page(struct device *dev, struct page *page,
 			    unsigned long offset, size_t size,
 			    enum dma_data_direction dir,
<span class="p_del">-			    struct dma_attrs *attrs)</span>
<span class="p_add">+			    const struct dma_attrs *attrs)</span>
 {
 	phys_addr_t map, phys = page_to_phys(page) + offset;
 	dma_addr_t dev_addr = phys_to_dma(dev, phys);
<span class="p_chunk">@@ -807,7 +807,7 @@</span> <span class="p_context"> static void unmap_single(struct device *hwdev, dma_addr_t dev_addr,</span>
 
 void swiotlb_unmap_page(struct device *hwdev, dma_addr_t dev_addr,
 			size_t size, enum dma_data_direction dir,
<span class="p_del">-			struct dma_attrs *attrs)</span>
<span class="p_add">+			const struct dma_attrs *attrs)</span>
 {
 	unmap_single(hwdev, dev_addr, size, dir);
 }
<span class="p_chunk">@@ -877,7 +877,7 @@</span> <span class="p_context"> EXPORT_SYMBOL(swiotlb_sync_single_for_device);</span>
  */
 int
 swiotlb_map_sg_attrs(struct device *hwdev, struct scatterlist *sgl, int nelems,
<span class="p_del">-		     enum dma_data_direction dir, struct dma_attrs *attrs)</span>
<span class="p_add">+		     enum dma_data_direction dir, const struct dma_attrs *attrs)</span>
 {
 	struct scatterlist *sg;
 	int i;
<span class="p_chunk">@@ -924,7 +924,8 @@</span> <span class="p_context"> EXPORT_SYMBOL(swiotlb_map_sg);</span>
  */
 void
 swiotlb_unmap_sg_attrs(struct device *hwdev, struct scatterlist *sgl,
<span class="p_del">-		       int nelems, enum dma_data_direction dir, struct dma_attrs *attrs)</span>
<span class="p_add">+		       int nelems, enum dma_data_direction dir,</span>
<span class="p_add">+		       const struct dma_attrs *attrs)</span>
 {
 	struct scatterlist *sg;
 	int i;

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



