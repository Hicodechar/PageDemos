
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>mm: kill kmemcheck again - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    mm: kill kmemcheck again</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=169497">Levin, Alexander</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>Sept. 27, 2017, 11:27 a.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;20170927112723.16862-1-alexander.levin@verizon.com&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/9973827/mbox/"
   >mbox</a>
|
   <a href="/patch/9973827/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/9973827/">/patch/9973827/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
	[172.30.200.125])
	by pdx-korg-patchwork.web.codeaurora.org (Postfix) with ESMTP id
	696A660365 for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Wed, 27 Sep 2017 11:28:36 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 4662D28897
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Wed, 27 Sep 2017 11:28:36 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id 39E872889C; Wed, 27 Sep 2017 11:28:36 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-7.0 required=2.0 tests=BAYES_00,DKIM_SIGNED,
	DKIM_VALID, DKIM_VALID_AU,
	RCVD_IN_DNSWL_HI autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 7053528897
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Wed, 27 Sep 2017 11:28:29 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1752691AbdI0L20 (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Wed, 27 Sep 2017 07:28:26 -0400
Received: from omzsmtpe03.verizonbusiness.com ([199.249.25.208]:33285 &quot;EHLO
	omzsmtpe03.verizonbusiness.com&quot; rhost-flags-OK-OK-OK-OK)
	by vger.kernel.org with ESMTP id S1751840AbdI0L2T (ORCPT
	&lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Wed, 27 Sep 2017 07:28:19 -0400
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/simple;
	d=verizon.com; i=@verizon.com; q=dns/txt; s=corp;
	t=1506511699; x=1538047699;
	h=from:cc:to:subject:date:message-id:
	content-transfer-encoding:mime-version;
	bh=P/9R+sqZJTluPmNTKaTphJgByRE0m6iI8zr4NeFgAJ0=;
	b=fnpAGK49oRfJbpaO24XhjmpdMFFKrmfdel5BtU5bqH65SZ7KLnrcIWzO
	tSaik6A9ucDlT4NstFMDjClkBkApeqA3piYiQYJNYaihBoVHAQkfEHg+x
	SRHhRaFhHhxAZHZd4QuM+YQxTDFuW6DsSPoupbkjzDqHNu6TXrq2vFjQh U=;
Received: from unknown (HELO fldsmtpi01.verizon.com) ([166.68.71.143])
	by omzsmtpe03.verizonbusiness.com with ESMTP;
	27 Sep 2017 11:28:17 +0000
From: &quot;Levin, Alexander (Sasha Levin)&quot; &lt;alexander.levin@verizon.com&gt;
Cc: &quot;linux-kernel@vger.kernel.org&quot; &lt;linux-kernel@vger.kernel.org&gt;,
	&quot;Levin, Alexander (Sasha Levin)&quot; &lt;alexander.levin@verizon.com&gt;,
	Steven Rostedt &lt;rostedt@goodmis.org&gt;,
	&quot;David S . Miller&quot; &lt;davem@davemloft.net&gt;
Received: from rogue-10-255-192-101.rogue.vzwcorp.com (HELO
	apollo.verizonwireless.com) ([10.255.192.101])
	by fldsmtpi01.verizon.com with ESMTP/TLS/DHE-RSA-AES256-SHA;
	27 Sep 2017 11:27:51 +0000
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/simple;
	d=verizon.com; i=@verizon.com; q=dns/txt; s=corp;
	t=1506511672; x=1538047672;
	h=from:to:cc:subject:date:message-id:
	content-transfer-encoding:mime-version;
	bh=P/9R+sqZJTluPmNTKaTphJgByRE0m6iI8zr4NeFgAJ0=;
	b=fI0FKxgPhwfR9MlwUVjIV9O3wkeLC/U6U3xNcV17KqXlLF552BRxVtqk
	PNfcc9eNFHbWbzsmWMM2htwdpggElp3JMI8NHzXFAs7CD+DxCS3uJfafI
	TlIKe3yRL16c5BOBWW+07Ndy2n6OZxEyjlmjN15fPWEJLQiE4mTk3ZHD1 4=;
Received: from viking.odc.vzwcorp.com (HELO mercury.verizonwireless.com)
	([10.255.240.26])
	by apollo.verizonwireless.com with ESMTP/TLS/DHE-RSA-AES256-SHA;
	27 Sep 2017 07:27:51 -0400
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/simple;
	d=verizon.com; i=@verizon.com; q=dns/txt; s=corp;
	t=1506511671; x=1538047671;
	h=from:to:cc:subject:date:message-id:
	content-transfer-encoding:mime-version;
	bh=P/9R+sqZJTluPmNTKaTphJgByRE0m6iI8zr4NeFgAJ0=;
	b=c2Qnj9aK4CHIkvbSoVGx8Zqc5ipWIzNerrGy60Gc3qI6KrDfVIgqid1f
	VrnqBZssoEppufKTjKtRPTGAUt+j5i8BWmNe1AHt+iGoenGQS6cfreXYY
	PM89dCbB+0iwHcLtV92N1njq4jqeqUR1bhV59n5dO/8ZW8P8w0I1MOP3M k=;
X-Host: viking.odc.vzwcorp.com
Received: from casac1exh002.uswin.ad.vzwcorp.com ([10.11.218.44])
	by mercury.verizonwireless.com with ESMTP/TLS/AES128-SHA256;
	27 Sep 2017 11:27:49 +0000
Received: from scwexch24apd.uswin.ad.vzwcorp.com (153.114.130.43) by
	CASAC1EXH002.uswin.ad.vzwcorp.com (10.11.218.44) with Microsoft SMTP
	Server (TLS) id 14.3.248.2; Wed, 27 Sep 2017 04:27:49 -0700
Received: from OMZP1LUMXCA13.uswin.ad.vzwcorp.com (144.8.22.188) by
	scwexch24apd.uswin.ad.vzwcorp.com (153.114.130.43) with Microsoft
	SMTP Server (TLS) id 15.0.1263.5; Wed, 27 Sep 2017 04:27:48 -0700
Received: from OMZP1LUMXCA17.uswin.ad.vzwcorp.com (144.8.22.195) by
	OMZP1LUMXCA13.uswin.ad.vzwcorp.com (144.8.22.188) with Microsoft SMTP
	Server (TLS) id 15.0.1263.5; Wed, 27 Sep 2017 06:27:40 -0500
Received: from OMZP1LUMXCA17.uswin.ad.vzwcorp.com ([144.8.22.195]) by
	OMZP1LUMXCA17.uswin.ad.vzwcorp.com ([144.8.22.195]) with mapi id
	15.00.1263.000; Wed, 27 Sep 2017 06:27:40 -0500
To: &quot;akpm@linux-foundation.org&quot; &lt;akpm@linux-foundation.org&gt;
Subject: [PATCH] mm: kill kmemcheck again
Thread-Topic: [PATCH] mm: kill kmemcheck again
Thread-Index: AQHTN4OgmY+PcZ5HDEK4HOmFCwQFLA==
Date: Wed, 27 Sep 2017 11:27:40 +0000
Message-ID: &lt;20170927112723.16862-1-alexander.levin@verizon.com&gt;
Accept-Language: en-US
Content-Language: en-US
X-MS-Has-Attach: 
X-MS-TNEF-Correlator: 
x-ms-exchange-messagesentrepresentingtype: 1
x-ms-exchange-transport-fromentityheader: Hosted
x-originating-ip: [10.144.60.250]
Content-Type: text/plain; charset=&quot;iso-8859-1&quot;
Content-Transfer-Encoding: quoted-printable
MIME-Version: 1.0
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=169497">Levin, Alexander</a> - Sept. 27, 2017, 11:27 a.m.</div>
<pre class="content">
2 Years ago I proposed to kill kmemcheck:
<span class="quote">
&gt; As discussed on LSF/MM, kill kmemcheck.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; KASan is a replacement that is able to work without the limitation of</span>
<span class="quote">&gt; kmemcheck (single CPU, slow). KASan is already upstream.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; We are also not aware of any users of kmemcheck (or users who don&#39;t consider</span>
<span class="quote">&gt; KASan as a suitable replacement).</span>

The only objection was that since KASAN wasn&#39;t supported by all GCC
versions provided by distros at that time we should hold off for 2
years, and try again.

Now that 2 years have passed, and all distros provide gcc that supports
KASAN, kill kmemcheck again for the very same reasons.

Cc: Steven Rostedt (VMware) &lt;rostedt@goodmis.org&gt;
Cc: David S. Miller &lt;davem@davemloft.net&gt;
<span class="signed-off-by">Signed-off-by: Sasha Levin &lt;alexander.levin@verizon.com&gt;</span>
---
 Documentation/admin-guide/kernel-parameters.txt |   7 -
 Documentation/dev-tools/index.rst               |   1 -
 Documentation/dev-tools/kmemcheck.rst           | 733 ------------------------
 MAINTAINERS                                     |  10 -
 arch/arm/include/asm/dma-iommu.h                |   1 -
 arch/arm/include/asm/pgalloc.h                  |   2 +-
 arch/arm64/include/asm/pgalloc.h                |   2 +-
 arch/openrisc/include/asm/dma-mapping.h         |   1 -
 arch/powerpc/include/asm/pgalloc.h              |   2 +-
 arch/sh/kernel/dwarf.c                          |   4 +-
 arch/sh/kernel/process.c                        |   2 +-
 arch/sparc/mm/init_64.c                         |   4 +-
 arch/unicore32/include/asm/pgalloc.h            |   2 +-
 arch/x86/Kconfig                                |   3 +-
 arch/x86/Makefile                               |   5 -
 arch/x86/include/asm/dma-mapping.h              |   1 -
 arch/x86/include/asm/kmemcheck.h                |  42 --
 arch/x86/include/asm/pgtable.h                  |   5 -
 arch/x86/include/asm/pgtable_types.h            |  13 -
 arch/x86/include/asm/string_32.h                |   9 -
 arch/x86/include/asm/string_64.h                |   8 -
 arch/x86/include/asm/xor.h                      |   4 +-
 arch/x86/kernel/cpu/intel.c                     |  15 -
 arch/x86/kernel/espfix_64.c                     |   2 +-
 arch/x86/kernel/traps.c                         |   5 -
 arch/x86/mm/Makefile                            |   2 -
 arch/x86/mm/fault.c                             |   6 -
 arch/x86/mm/init.c                              |   8 +-
 arch/x86/mm/init_64.c                           |   2 +-
 arch/x86/mm/kmemcheck/Makefile                  |   1 -
 arch/x86/mm/kmemcheck/error.c                   | 227 --------
 arch/x86/mm/kmemcheck/error.h                   |  15 -
 arch/x86/mm/kmemcheck/kmemcheck.c               | 658 ---------------------
 arch/x86/mm/kmemcheck/opcode.c                  | 106 ----
 arch/x86/mm/kmemcheck/opcode.h                  |   9 -
 arch/x86/mm/kmemcheck/pte.c                     |  22 -
 arch/x86/mm/kmemcheck/pte.h                     |  10 -
 arch/x86/mm/kmemcheck/selftest.c                |  70 ---
 arch/x86/mm/kmemcheck/selftest.h                |   6 -
 arch/x86/mm/kmemcheck/shadow.c                  | 173 ------
 arch/x86/mm/kmemcheck/shadow.h                  |  18 -
 arch/x86/mm/pageattr.c                          |  10 +-
 arch/x86/mm/pgtable.c                           |   2 +-
 arch/x86/platform/efi/efi_64.c                  |   2 +-
 crypto/xor.c                                    |   7 +-
 drivers/char/random.c                           |   1 -
 drivers/misc/c2port/core.c                      |   2 -
 fs/dcache.c                                     |   2 -
 include/linux/c2port.h                          |   4 -
 include/linux/dma-mapping.h                     |   8 +-
 include/linux/filter.h                          |   2 -
 include/linux/gfp.h                             |   9 -
 include/linux/interrupt.h                       |  15 -
 include/linux/kmemcheck.h                       | 171 ------
 include/linux/mm_types.h                        |   8 -
 include/linux/net.h                             |   3 -
 include/linux/ring_buffer.h                     |   3 -
 include/linux/skbuff.h                          |   3 -
 include/linux/slab.h                            |   6 -
 include/linux/thread_info.h                     |   5 +-
 include/net/inet_sock.h                         |   3 -
 include/net/inet_timewait_sock.h                |   3 -
 include/net/sock.h                              |   2 -
 include/trace/events/mmflags.h                  |   1 -
 init/do_mounts.c                                |   3 +-
 init/main.c                                     |   1 -
 kernel/bpf/core.c                               |   6 -
 kernel/fork.c                                   |  12 +-
 kernel/locking/lockdep.c                        |   3 -
 kernel/signal.c                                 |   3 +-
 kernel/softirq.c                                |  10 -
 kernel/sysctl.c                                 |  10 -
 kernel/trace/ring_buffer.c                      |   3 -
 lib/Kconfig.debug                               |   6 +-
 lib/Kconfig.kmemcheck                           |  94 ---
 mm/Kconfig.debug                                |   1 -
 mm/Makefile                                     |   2 -
 mm/kmemcheck.c                                  | 125 ----
 mm/kmemleak.c                                   |   9 -
 mm/page_alloc.c                                 |  14 -
 mm/slab.c                                       |  16 +-
 mm/slab.h                                       |   7 +-
 mm/slab_common.c                                |   2 +-
 mm/slub.c                                       |  31 +-
 net/core/skbuff.c                               |   5 -
 net/core/sock.c                                 |   2 -
 net/ipv4/inet_timewait_sock.c                   |   3 -
 net/ipv4/tcp_input.c                            |   1 -
 net/socket.c                                    |   1 -
 scripts/kernel-doc                              |   2 -
 tools/include/linux/kmemcheck.h                 |   8 -
 tools/perf/builtin-kmem.c                       |   1 -
 92 files changed, 44 insertions(+), 2825 deletions(-)
 delete mode 100644 Documentation/dev-tools/kmemcheck.rst
 delete mode 100644 arch/x86/include/asm/kmemcheck.h
 delete mode 100644 arch/x86/mm/kmemcheck/Makefile
 delete mode 100644 arch/x86/mm/kmemcheck/error.c
 delete mode 100644 arch/x86/mm/kmemcheck/error.h
 delete mode 100644 arch/x86/mm/kmemcheck/kmemcheck.c
 delete mode 100644 arch/x86/mm/kmemcheck/opcode.c
 delete mode 100644 arch/x86/mm/kmemcheck/opcode.h
 delete mode 100644 arch/x86/mm/kmemcheck/pte.c
 delete mode 100644 arch/x86/mm/kmemcheck/pte.h
 delete mode 100644 arch/x86/mm/kmemcheck/selftest.c
 delete mode 100644 arch/x86/mm/kmemcheck/selftest.h
 delete mode 100644 arch/x86/mm/kmemcheck/shadow.c
 delete mode 100644 arch/x86/mm/kmemcheck/shadow.h
 delete mode 100644 include/linux/kmemcheck.h
 delete mode 100644 lib/Kconfig.kmemcheck
 delete mode 100644 mm/kmemcheck.c
 delete mode 100644 tools/include/linux/kmemcheck.h
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=169497">Levin, Alexander</a> - Sept. 27, 2017, 11:32 a.m.</div>
<pre class="content">
I stupidly forgot to Cc Pekka and Vegard, now Cc&#39;ed.

On Wed, Sep 27, 2017 at 11:27:40AM +0000, Levin, Alexander (Sasha Levin) wrote:
<span class="quote">&gt;2 Years ago I proposed to kill kmemcheck:</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;&gt; As discussed on LSF/MM, kill kmemcheck.</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; KASan is a replacement that is able to work without the limitation of</span>
<span class="quote">&gt;&gt; kmemcheck (single CPU, slow). KASan is already upstream.</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; We are also not aware of any users of kmemcheck (or users who don&#39;t consider</span>
<span class="quote">&gt;&gt; KASan as a suitable replacement).</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;The only objection was that since KASAN wasn&#39;t supported by all GCC</span>
<span class="quote">&gt;versions provided by distros at that time we should hold off for 2</span>
<span class="quote">&gt;years, and try again.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;Now that 2 years have passed, and all distros provide gcc that supports</span>
<span class="quote">&gt;KASAN, kill kmemcheck again for the very same reasons.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;Cc: Steven Rostedt (VMware) &lt;rostedt@goodmis.org&gt;</span>
<span class="quote">&gt;Cc: David S. Miller &lt;davem@davemloft.net&gt;</span>
<span class="quote">&gt;Signed-off-by: Sasha Levin &lt;alexander.levin@verizon.com&gt;</span>
<span class="quote">&gt;---</span>
<span class="quote">&gt; Documentation/admin-guide/kernel-parameters.txt |   7 -</span>
<span class="quote">&gt; Documentation/dev-tools/index.rst               |   1 -</span>
<span class="quote">&gt; Documentation/dev-tools/kmemcheck.rst           | 733 ------------------------</span>
<span class="quote">&gt; MAINTAINERS                                     |  10 -</span>
<span class="quote">&gt; arch/arm/include/asm/dma-iommu.h                |   1 -</span>
<span class="quote">&gt; arch/arm/include/asm/pgalloc.h                  |   2 +-</span>
<span class="quote">&gt; arch/arm64/include/asm/pgalloc.h                |   2 +-</span>
<span class="quote">&gt; arch/openrisc/include/asm/dma-mapping.h         |   1 -</span>
<span class="quote">&gt; arch/powerpc/include/asm/pgalloc.h              |   2 +-</span>
<span class="quote">&gt; arch/sh/kernel/dwarf.c                          |   4 +-</span>
<span class="quote">&gt; arch/sh/kernel/process.c                        |   2 +-</span>
<span class="quote">&gt; arch/sparc/mm/init_64.c                         |   4 +-</span>
<span class="quote">&gt; arch/unicore32/include/asm/pgalloc.h            |   2 +-</span>
<span class="quote">&gt; arch/x86/Kconfig                                |   3 +-</span>
<span class="quote">&gt; arch/x86/Makefile                               |   5 -</span>
<span class="quote">&gt; arch/x86/include/asm/dma-mapping.h              |   1 -</span>
<span class="quote">&gt; arch/x86/include/asm/kmemcheck.h                |  42 --</span>
<span class="quote">&gt; arch/x86/include/asm/pgtable.h                  |   5 -</span>
<span class="quote">&gt; arch/x86/include/asm/pgtable_types.h            |  13 -</span>
<span class="quote">&gt; arch/x86/include/asm/string_32.h                |   9 -</span>
<span class="quote">&gt; arch/x86/include/asm/string_64.h                |   8 -</span>
<span class="quote">&gt; arch/x86/include/asm/xor.h                      |   4 +-</span>
<span class="quote">&gt; arch/x86/kernel/cpu/intel.c                     |  15 -</span>
<span class="quote">&gt; arch/x86/kernel/espfix_64.c                     |   2 +-</span>
<span class="quote">&gt; arch/x86/kernel/traps.c                         |   5 -</span>
<span class="quote">&gt; arch/x86/mm/Makefile                            |   2 -</span>
<span class="quote">&gt; arch/x86/mm/fault.c                             |   6 -</span>
<span class="quote">&gt; arch/x86/mm/init.c                              |   8 +-</span>
<span class="quote">&gt; arch/x86/mm/init_64.c                           |   2 +-</span>
<span class="quote">&gt; arch/x86/mm/kmemcheck/Makefile                  |   1 -</span>
<span class="quote">&gt; arch/x86/mm/kmemcheck/error.c                   | 227 --------</span>
<span class="quote">&gt; arch/x86/mm/kmemcheck/error.h                   |  15 -</span>
<span class="quote">&gt; arch/x86/mm/kmemcheck/kmemcheck.c               | 658 ---------------------</span>
<span class="quote">&gt; arch/x86/mm/kmemcheck/opcode.c                  | 106 ----</span>
<span class="quote">&gt; arch/x86/mm/kmemcheck/opcode.h                  |   9 -</span>
<span class="quote">&gt; arch/x86/mm/kmemcheck/pte.c                     |  22 -</span>
<span class="quote">&gt; arch/x86/mm/kmemcheck/pte.h                     |  10 -</span>
<span class="quote">&gt; arch/x86/mm/kmemcheck/selftest.c                |  70 ---</span>
<span class="quote">&gt; arch/x86/mm/kmemcheck/selftest.h                |   6 -</span>
<span class="quote">&gt; arch/x86/mm/kmemcheck/shadow.c                  | 173 ------</span>
<span class="quote">&gt; arch/x86/mm/kmemcheck/shadow.h                  |  18 -</span>
<span class="quote">&gt; arch/x86/mm/pageattr.c                          |  10 +-</span>
<span class="quote">&gt; arch/x86/mm/pgtable.c                           |   2 +-</span>
<span class="quote">&gt; arch/x86/platform/efi/efi_64.c                  |   2 +-</span>
<span class="quote">&gt; crypto/xor.c                                    |   7 +-</span>
<span class="quote">&gt; drivers/char/random.c                           |   1 -</span>
<span class="quote">&gt; drivers/misc/c2port/core.c                      |   2 -</span>
<span class="quote">&gt; fs/dcache.c                                     |   2 -</span>
<span class="quote">&gt; include/linux/c2port.h                          |   4 -</span>
<span class="quote">&gt; include/linux/dma-mapping.h                     |   8 +-</span>
<span class="quote">&gt; include/linux/filter.h                          |   2 -</span>
<span class="quote">&gt; include/linux/gfp.h                             |   9 -</span>
<span class="quote">&gt; include/linux/interrupt.h                       |  15 -</span>
<span class="quote">&gt; include/linux/kmemcheck.h                       | 171 ------</span>
<span class="quote">&gt; include/linux/mm_types.h                        |   8 -</span>
<span class="quote">&gt; include/linux/net.h                             |   3 -</span>
<span class="quote">&gt; include/linux/ring_buffer.h                     |   3 -</span>
<span class="quote">&gt; include/linux/skbuff.h                          |   3 -</span>
<span class="quote">&gt; include/linux/slab.h                            |   6 -</span>
<span class="quote">&gt; include/linux/thread_info.h                     |   5 +-</span>
<span class="quote">&gt; include/net/inet_sock.h                         |   3 -</span>
<span class="quote">&gt; include/net/inet_timewait_sock.h                |   3 -</span>
<span class="quote">&gt; include/net/sock.h                              |   2 -</span>
<span class="quote">&gt; include/trace/events/mmflags.h                  |   1 -</span>
<span class="quote">&gt; init/do_mounts.c                                |   3 +-</span>
<span class="quote">&gt; init/main.c                                     |   1 -</span>
<span class="quote">&gt; kernel/bpf/core.c                               |   6 -</span>
<span class="quote">&gt; kernel/fork.c                                   |  12 +-</span>
<span class="quote">&gt; kernel/locking/lockdep.c                        |   3 -</span>
<span class="quote">&gt; kernel/signal.c                                 |   3 +-</span>
<span class="quote">&gt; kernel/softirq.c                                |  10 -</span>
<span class="quote">&gt; kernel/sysctl.c                                 |  10 -</span>
<span class="quote">&gt; kernel/trace/ring_buffer.c                      |   3 -</span>
<span class="quote">&gt; lib/Kconfig.debug                               |   6 +-</span>
<span class="quote">&gt; lib/Kconfig.kmemcheck                           |  94 ---</span>
<span class="quote">&gt; mm/Kconfig.debug                                |   1 -</span>
<span class="quote">&gt; mm/Makefile                                     |   2 -</span>
<span class="quote">&gt; mm/kmemcheck.c                                  | 125 ----</span>
<span class="quote">&gt; mm/kmemleak.c                                   |   9 -</span>
<span class="quote">&gt; mm/page_alloc.c                                 |  14 -</span>
<span class="quote">&gt; mm/slab.c                                       |  16 +-</span>
<span class="quote">&gt; mm/slab.h                                       |   7 +-</span>
<span class="quote">&gt; mm/slab_common.c                                |   2 +-</span>
<span class="quote">&gt; mm/slub.c                                       |  31 +-</span>
<span class="quote">&gt; net/core/skbuff.c                               |   5 -</span>
<span class="quote">&gt; net/core/sock.c                                 |   2 -</span>
<span class="quote">&gt; net/ipv4/inet_timewait_sock.c                   |   3 -</span>
<span class="quote">&gt; net/ipv4/tcp_input.c                            |   1 -</span>
<span class="quote">&gt; net/socket.c                                    |   1 -</span>
<span class="quote">&gt; scripts/kernel-doc                              |   2 -</span>
<span class="quote">&gt; tools/include/linux/kmemcheck.h                 |   8 -</span>
<span class="quote">&gt; tools/perf/builtin-kmem.c                       |   1 -</span>
<span class="quote">&gt; 92 files changed, 44 insertions(+), 2825 deletions(-)</span>
<span class="quote">&gt; delete mode 100644 Documentation/dev-tools/kmemcheck.rst</span>
<span class="quote">&gt; delete mode 100644 arch/x86/include/asm/kmemcheck.h</span>
<span class="quote">&gt; delete mode 100644 arch/x86/mm/kmemcheck/Makefile</span>
<span class="quote">&gt; delete mode 100644 arch/x86/mm/kmemcheck/error.c</span>
<span class="quote">&gt; delete mode 100644 arch/x86/mm/kmemcheck/error.h</span>
<span class="quote">&gt; delete mode 100644 arch/x86/mm/kmemcheck/kmemcheck.c</span>
<span class="quote">&gt; delete mode 100644 arch/x86/mm/kmemcheck/opcode.c</span>
<span class="quote">&gt; delete mode 100644 arch/x86/mm/kmemcheck/opcode.h</span>
<span class="quote">&gt; delete mode 100644 arch/x86/mm/kmemcheck/pte.c</span>
<span class="quote">&gt; delete mode 100644 arch/x86/mm/kmemcheck/pte.h</span>
<span class="quote">&gt; delete mode 100644 arch/x86/mm/kmemcheck/selftest.c</span>
<span class="quote">&gt; delete mode 100644 arch/x86/mm/kmemcheck/selftest.h</span>
<span class="quote">&gt; delete mode 100644 arch/x86/mm/kmemcheck/shadow.c</span>
<span class="quote">&gt; delete mode 100644 arch/x86/mm/kmemcheck/shadow.h</span>
<span class="quote">&gt; delete mode 100644 include/linux/kmemcheck.h</span>
<span class="quote">&gt; delete mode 100644 lib/Kconfig.kmemcheck</span>
<span class="quote">&gt; delete mode 100644 mm/kmemcheck.c</span>
<span class="quote">&gt; delete mode 100644 tools/include/linux/kmemcheck.h</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;diff --git a/Documentation/admin-guide/kernel-parameters.txt b/Documentation/admin-guide/kernel-parameters.txt</span>
<span class="quote">&gt;index 05496622b4ef..5e1e0e7ebee3 100644</span>
<span class="quote">&gt;--- a/Documentation/admin-guide/kernel-parameters.txt</span>
<span class="quote">&gt;+++ b/Documentation/admin-guide/kernel-parameters.txt</span>
<span class="quote">&gt;@@ -1841,13 +1841,6 @@</span>
<span class="quote">&gt; 			Built with CONFIG_DEBUG_KMEMLEAK_DEFAULT_OFF=y,</span>
<span class="quote">&gt; 			the default is off.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;-	kmemcheck=	[X86] Boot-time kmemcheck enable/disable/one-shot mode</span>
<span class="quote">&gt;-			Valid arguments: 0, 1, 2</span>
<span class="quote">&gt;-			kmemcheck=0 (disabled)</span>
<span class="quote">&gt;-			kmemcheck=1 (enabled)</span>
<span class="quote">&gt;-			kmemcheck=2 (one-shot mode)</span>
<span class="quote">&gt;-			Default: 2 (one-shot mode)</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt; 	kvm.ignore_msrs=[KVM] Ignore guest accesses to unhandled MSRs.</span>
<span class="quote">&gt; 			Default is 0 (don&#39;t ignore, but inject #GP)</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;diff --git a/Documentation/dev-tools/index.rst b/Documentation/dev-tools/index.rst</span>
<span class="quote">&gt;index a81787cd47d7..e313925fb0fa 100644</span>
<span class="quote">&gt;--- a/Documentation/dev-tools/index.rst</span>
<span class="quote">&gt;+++ b/Documentation/dev-tools/index.rst</span>
<span class="quote">&gt;@@ -21,7 +21,6 @@ whole; patches welcome!</span>
<span class="quote">&gt;    kasan</span>
<span class="quote">&gt;    ubsan</span>
<span class="quote">&gt;    kmemleak</span>
<span class="quote">&gt;-   kmemcheck</span>
<span class="quote">&gt;    gdb-kernel-debugging</span>
<span class="quote">&gt;    kgdb</span>
<span class="quote">&gt;    kselftest</span>
<span class="quote">&gt;diff --git a/Documentation/dev-tools/kmemcheck.rst b/Documentation/dev-tools/kmemcheck.rst</span>
<span class="quote">&gt;deleted file mode 100644</span>
<span class="quote">&gt;index 7f3d1985de74..000000000000</span>
<span class="quote">&gt;--- a/Documentation/dev-tools/kmemcheck.rst</span>
<span class="quote">&gt;+++ /dev/null</span>
<span class="quote">&gt;@@ -1,733 +0,0 @@</span>
<span class="quote">&gt;-Getting started with kmemcheck</span>
<span class="quote">&gt;-==============================</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-Vegard Nossum &lt;vegardno@ifi.uio.no&gt;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-Introduction</span>
<span class="quote">&gt;-------------</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-kmemcheck is a debugging feature for the Linux Kernel. More specifically, it</span>
<span class="quote">&gt;-is a dynamic checker that detects and warns about some uses of uninitialized</span>
<span class="quote">&gt;-memory.</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-Userspace programmers might be familiar with Valgrind&#39;s memcheck. The main</span>
<span class="quote">&gt;-difference between memcheck and kmemcheck is that memcheck works for userspace</span>
<span class="quote">&gt;-programs only, and kmemcheck works for the kernel only. The implementations</span>
<span class="quote">&gt;-are of course vastly different. Because of this, kmemcheck is not as accurate</span>
<span class="quote">&gt;-as memcheck, but it turns out to be good enough in practice to discover real</span>
<span class="quote">&gt;-programmer errors that the compiler is not able to find through static</span>
<span class="quote">&gt;-analysis.</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-Enabling kmemcheck on a kernel will probably slow it down to the extent that</span>
<span class="quote">&gt;-the machine will not be usable for normal workloads such as e.g. an</span>
<span class="quote">&gt;-interactive desktop. kmemcheck will also cause the kernel to use about twice</span>
<span class="quote">&gt;-as much memory as normal. For this reason, kmemcheck is strictly a debugging</span>
<span class="quote">&gt;-feature.</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-Downloading</span>
<span class="quote">&gt;------------</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-As of version 2.6.31-rc1, kmemcheck is included in the mainline kernel.</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-Configuring and compiling</span>
<span class="quote">&gt;--------------------------</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-kmemcheck only works for the x86 (both 32- and 64-bit) platform. A number of</span>
<span class="quote">&gt;-configuration variables must have specific settings in order for the kmemcheck</span>
<span class="quote">&gt;-menu to even appear in &quot;menuconfig&quot;. These are:</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-- ``CONFIG_CC_OPTIMIZE_FOR_SIZE=n``</span>
<span class="quote">&gt;-	This option is located under &quot;General setup&quot; / &quot;Optimize for size&quot;.</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	Without this, gcc will use certain optimizations that usually lead to</span>
<span class="quote">&gt;-	false positive warnings from kmemcheck. An example of this is a 16-bit</span>
<span class="quote">&gt;-	field in a struct, where gcc may load 32 bits, then discard the upper</span>
<span class="quote">&gt;-	16 bits. kmemcheck sees only the 32-bit load, and may trigger a</span>
<span class="quote">&gt;-	warning for the upper 16 bits (if they&#39;re uninitialized).</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-- ``CONFIG_SLAB=y`` or ``CONFIG_SLUB=y``</span>
<span class="quote">&gt;-	This option is located under &quot;General setup&quot; / &quot;Choose SLAB</span>
<span class="quote">&gt;-	allocator&quot;.</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-- ``CONFIG_FUNCTION_TRACER=n``</span>
<span class="quote">&gt;-	This option is located under &quot;Kernel hacking&quot; / &quot;Tracers&quot; / &quot;Kernel</span>
<span class="quote">&gt;-	Function Tracer&quot;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	When function tracing is compiled in, gcc emits a call to another</span>
<span class="quote">&gt;-	function at the beginning of every function. This means that when the</span>
<span class="quote">&gt;-	page fault handler is called, the ftrace framework will be called</span>
<span class="quote">&gt;-	before kmemcheck has had a chance to handle the fault. If ftrace then</span>
<span class="quote">&gt;-	modifies memory that was tracked by kmemcheck, the result is an</span>
<span class="quote">&gt;-	endless recursive page fault.</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-- ``CONFIG_DEBUG_PAGEALLOC=n``</span>
<span class="quote">&gt;-	This option is located under &quot;Kernel hacking&quot; / &quot;Memory Debugging&quot;</span>
<span class="quote">&gt;-	/ &quot;Debug page memory allocations&quot;.</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-In addition, I highly recommend turning on ``CONFIG_DEBUG_INFO=y``. This is also</span>
<span class="quote">&gt;-located under &quot;Kernel hacking&quot;. With this, you will be able to get line number</span>
<span class="quote">&gt;-information from the kmemcheck warnings, which is extremely valuable in</span>
<span class="quote">&gt;-debugging a problem. This option is not mandatory, however, because it slows</span>
<span class="quote">&gt;-down the compilation process and produces a much bigger kernel image.</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-Now the kmemcheck menu should be visible (under &quot;Kernel hacking&quot; / &quot;Memory</span>
<span class="quote">&gt;-Debugging&quot; / &quot;kmemcheck: trap use of uninitialized memory&quot;). Here follows</span>
<span class="quote">&gt;-a description of the kmemcheck configuration variables:</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-- ``CONFIG_KMEMCHECK``</span>
<span class="quote">&gt;-	This must be enabled in order to use kmemcheck at all...</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-- ``CONFIG_KMEMCHECK_``[``DISABLED`` | ``ENABLED`` | ``ONESHOT``]``_BY_DEFAULT``</span>
<span class="quote">&gt;-	This option controls the status of kmemcheck at boot-time. &quot;Enabled&quot;</span>
<span class="quote">&gt;-	will enable kmemcheck right from the start, &quot;disabled&quot; will boot the</span>
<span class="quote">&gt;-	kernel as normal (but with the kmemcheck code compiled in, so it can</span>
<span class="quote">&gt;-	be enabled at run-time after the kernel has booted), and &quot;one-shot&quot; is</span>
<span class="quote">&gt;-	a special mode which will turn kmemcheck off automatically after</span>
<span class="quote">&gt;-	detecting the first use of uninitialized memory.</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	If you are using kmemcheck to actively debug a problem, then you</span>
<span class="quote">&gt;-	probably want to choose &quot;enabled&quot; here.</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	The one-shot mode is mostly useful in automated test setups because it</span>
<span class="quote">&gt;-	can prevent floods of warnings and increase the chances of the machine</span>
<span class="quote">&gt;-	surviving in case something is really wrong. In other cases, the one-</span>
<span class="quote">&gt;-	shot mode could actually be counter-productive because it would turn</span>
<span class="quote">&gt;-	itself off at the very first error -- in the case of a false positive</span>
<span class="quote">&gt;-	too -- and this would come in the way of debugging the specific</span>
<span class="quote">&gt;-	problem you were interested in.</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	If you would like to use your kernel as normal, but with a chance to</span>
<span class="quote">&gt;-	enable kmemcheck in case of some problem, it might be a good idea to</span>
<span class="quote">&gt;-	choose &quot;disabled&quot; here. When kmemcheck is disabled, most of the run-</span>
<span class="quote">&gt;-	time overhead is not incurred, and the kernel will be almost as fast</span>
<span class="quote">&gt;-	as normal.</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-- ``CONFIG_KMEMCHECK_QUEUE_SIZE``</span>
<span class="quote">&gt;-	Select the maximum number of error reports to store in an internal</span>
<span class="quote">&gt;-	(fixed-size) buffer. Since errors can occur virtually anywhere and in</span>
<span class="quote">&gt;-	any context, we need a temporary storage area which is guaranteed not</span>
<span class="quote">&gt;-	to generate any other page faults when accessed. The queue will be</span>
<span class="quote">&gt;-	emptied as soon as a tasklet may be scheduled. If the queue is full,</span>
<span class="quote">&gt;-	new error reports will be lost.</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	The default value of 64 is probably fine. If some code produces more</span>
<span class="quote">&gt;-	than 64 errors within an irqs-off section, then the code is likely to</span>
<span class="quote">&gt;-	produce many, many more, too, and these additional reports seldom give</span>
<span class="quote">&gt;-	any more information (the first report is usually the most valuable</span>
<span class="quote">&gt;-	anyway).</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	This number might have to be adjusted if you are not using serial</span>
<span class="quote">&gt;-	console or similar to capture the kernel log. If you are using the</span>
<span class="quote">&gt;-	&quot;dmesg&quot; command to save the log, then getting a lot of kmemcheck</span>
<span class="quote">&gt;-	warnings might overflow the kernel log itself, and the earlier reports</span>
<span class="quote">&gt;-	will get lost in that way instead. Try setting this to 10 or so on</span>
<span class="quote">&gt;-	such a setup.</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-- ``CONFIG_KMEMCHECK_SHADOW_COPY_SHIFT``</span>
<span class="quote">&gt;-	Select the number of shadow bytes to save along with each entry of the</span>
<span class="quote">&gt;-	error-report queue. These bytes indicate what parts of an allocation</span>
<span class="quote">&gt;-	are initialized, uninitialized, etc. and will be displayed when an</span>
<span class="quote">&gt;-	error is detected to help the debugging of a particular problem.</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	The number entered here is actually the logarithm of the number of</span>
<span class="quote">&gt;-	bytes that will be saved. So if you pick for example 5 here, kmemcheck</span>
<span class="quote">&gt;-	will save 2^5 = 32 bytes.</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	The default value should be fine for debugging most problems. It also</span>
<span class="quote">&gt;-	fits nicely within 80 columns.</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-- ``CONFIG_KMEMCHECK_PARTIAL_OK``</span>
<span class="quote">&gt;-	This option (when enabled) works around certain GCC optimizations that</span>
<span class="quote">&gt;-	produce 32-bit reads from 16-bit variables where the upper 16 bits are</span>
<span class="quote">&gt;-	thrown away afterwards.</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	The default value (enabled) is recommended. This may of course hide</span>
<span class="quote">&gt;-	some real errors, but disabling it would probably produce a lot of</span>
<span class="quote">&gt;-	false positives.</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-- ``CONFIG_KMEMCHECK_BITOPS_OK``</span>
<span class="quote">&gt;-	This option silences warnings that would be generated for bit-field</span>
<span class="quote">&gt;-	accesses where not all the bits are initialized at the same time. This</span>
<span class="quote">&gt;-	may also hide some real bugs.</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	This option is probably obsolete, or it should be replaced with</span>
<span class="quote">&gt;-	the kmemcheck-/bitfield-annotations for the code in question. The</span>
<span class="quote">&gt;-	default value is therefore fine.</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-Now compile the kernel as usual.</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-How to use</span>
<span class="quote">&gt;-----------</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-Booting</span>
<span class="quote">&gt;-~~~~~~~</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-First some information about the command-line options. There is only one</span>
<span class="quote">&gt;-option specific to kmemcheck, and this is called &quot;kmemcheck&quot;. It can be used</span>
<span class="quote">&gt;-to override the default mode as chosen by the ``CONFIG_KMEMCHECK_*_BY_DEFAULT``</span>
<span class="quote">&gt;-option. Its possible settings are:</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-- ``kmemcheck=0`` (disabled)</span>
<span class="quote">&gt;-- ``kmemcheck=1`` (enabled)</span>
<span class="quote">&gt;-- ``kmemcheck=2`` (one-shot mode)</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-If SLUB debugging has been enabled in the kernel, it may take precedence over</span>
<span class="quote">&gt;-kmemcheck in such a way that the slab caches which are under SLUB debugging</span>
<span class="quote">&gt;-will not be tracked by kmemcheck. In order to ensure that this doesn&#39;t happen</span>
<span class="quote">&gt;-(even though it shouldn&#39;t by default), use SLUB&#39;s boot option ``slub_debug``,</span>
<span class="quote">&gt;-like this: ``slub_debug=-``</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-In fact, this option may also be used for fine-grained control over SLUB vs.</span>
<span class="quote">&gt;-kmemcheck. For example, if the command line includes</span>
<span class="quote">&gt;-``kmemcheck=1 slub_debug=,dentry``, then SLUB debugging will be used only</span>
<span class="quote">&gt;-for the &quot;dentry&quot; slab cache, and with kmemcheck tracking all the other</span>
<span class="quote">&gt;-caches. This is advanced usage, however, and is not generally recommended.</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-Run-time enable/disable</span>
<span class="quote">&gt;-~~~~~~~~~~~~~~~~~~~~~~~</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-When the kernel has booted, it is possible to enable or disable kmemcheck at</span>
<span class="quote">&gt;-run-time. WARNING: This feature is still experimental and may cause false</span>
<span class="quote">&gt;-positive warnings to appear. Therefore, try not to use this. If you find that</span>
<span class="quote">&gt;-it doesn&#39;t work properly (e.g. you see an unreasonable amount of warnings), I</span>
<span class="quote">&gt;-will be happy to take bug reports.</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-Use the file ``/proc/sys/kernel/kmemcheck`` for this purpose, e.g.::</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	$ echo 0 &gt; /proc/sys/kernel/kmemcheck # disables kmemcheck</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-The numbers are the same as for the ``kmemcheck=`` command-line option.</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-Debugging</span>
<span class="quote">&gt;-~~~~~~~~~</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-A typical report will look something like this::</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-    WARNING: kmemcheck: Caught 32-bit read from uninitialized memory (ffff88003e4a2024)</span>
<span class="quote">&gt;-    80000000000000000000000000000000000000000088ffff0000000000000000</span>
<span class="quote">&gt;-     i i i i u u u u i i i i i i i i u u u u u u u u u u u u u u u u</span>
<span class="quote">&gt;-             ^</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-    Pid: 1856, comm: ntpdate Not tainted 2.6.29-rc5 #264 945P-A</span>
<span class="quote">&gt;-    RIP: 0010:[&lt;ffffffff8104ede8&gt;]  [&lt;ffffffff8104ede8&gt;] __dequeue_signal+0xc8/0x190</span>
<span class="quote">&gt;-    RSP: 0018:ffff88003cdf7d98  EFLAGS: 00210002</span>
<span class="quote">&gt;-    RAX: 0000000000000030 RBX: ffff88003d4ea968 RCX: 0000000000000009</span>
<span class="quote">&gt;-    RDX: ffff88003e5d6018 RSI: ffff88003e5d6024 RDI: ffff88003cdf7e84</span>
<span class="quote">&gt;-    RBP: ffff88003cdf7db8 R08: ffff88003e5d6000 R09: 0000000000000000</span>
<span class="quote">&gt;-    R10: 0000000000000080 R11: 0000000000000000 R12: 000000000000000e</span>
<span class="quote">&gt;-    R13: ffff88003cdf7e78 R14: ffff88003d530710 R15: ffff88003d5a98c8</span>
<span class="quote">&gt;-    FS:  0000000000000000(0000) GS:ffff880001982000(0063) knlGS:00000</span>
<span class="quote">&gt;-    CS:  0010 DS: 002b ES: 002b CR0: 0000000080050033</span>
<span class="quote">&gt;-    CR2: ffff88003f806ea0 CR3: 000000003c036000 CR4: 00000000000006a0</span>
<span class="quote">&gt;-    DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000</span>
<span class="quote">&gt;-    DR3: 0000000000000000 DR6: 00000000ffff4ff0 DR7: 0000000000000400</span>
<span class="quote">&gt;-     [&lt;ffffffff8104f04e&gt;] dequeue_signal+0x8e/0x170</span>
<span class="quote">&gt;-     [&lt;ffffffff81050bd8&gt;] get_signal_to_deliver+0x98/0x390</span>
<span class="quote">&gt;-     [&lt;ffffffff8100b87d&gt;] do_notify_resume+0xad/0x7d0</span>
<span class="quote">&gt;-     [&lt;ffffffff8100c7b5&gt;] int_signal+0x12/0x17</span>
<span class="quote">&gt;-     [&lt;ffffffffffffffff&gt;] 0xffffffffffffffff</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-The single most valuable information in this report is the RIP (or EIP on 32-</span>
<span class="quote">&gt;-bit) value. This will help us pinpoint exactly which instruction that caused</span>
<span class="quote">&gt;-the warning.</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-If your kernel was compiled with ``CONFIG_DEBUG_INFO=y``, then all we have to do</span>
<span class="quote">&gt;-is give this address to the addr2line program, like this::</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	$ addr2line -e vmlinux -i ffffffff8104ede8</span>
<span class="quote">&gt;-	arch/x86/include/asm/string_64.h:12</span>
<span class="quote">&gt;-	include/asm-generic/siginfo.h:287</span>
<span class="quote">&gt;-	kernel/signal.c:380</span>
<span class="quote">&gt;-	kernel/signal.c:410</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-The &quot;``-e vmlinux``&quot; tells addr2line which file to look in. **IMPORTANT:**</span>
<span class="quote">&gt;-This must be the vmlinux of the kernel that produced the warning in the</span>
<span class="quote">&gt;-first place! If not, the line number information will almost certainly be</span>
<span class="quote">&gt;-wrong.</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-The &quot;``-i``&quot; tells addr2line to also print the line numbers of inlined</span>
<span class="quote">&gt;-functions.  In this case, the flag was very important, because otherwise,</span>
<span class="quote">&gt;-it would only have printed the first line, which is just a call to</span>
<span class="quote">&gt;-``memcpy()``, which could be called from a thousand places in the kernel, and</span>
<span class="quote">&gt;-is therefore not very useful.  These inlined functions would not show up in</span>
<span class="quote">&gt;-the stack trace above, simply because the kernel doesn&#39;t load the extra</span>
<span class="quote">&gt;-debugging information. This technique can of course be used with ordinary</span>
<span class="quote">&gt;-kernel oopses as well.</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-In this case, it&#39;s the caller of ``memcpy()`` that is interesting, and it can be</span>
<span class="quote">&gt;-found in ``include/asm-generic/siginfo.h``, line 287::</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-    281 static inline void copy_siginfo(struct siginfo *to, struct siginfo *from)</span>
<span class="quote">&gt;-    282 {</span>
<span class="quote">&gt;-    283         if (from-&gt;si_code &lt; 0)</span>
<span class="quote">&gt;-    284                 memcpy(to, from, sizeof(*to));</span>
<span class="quote">&gt;-    285         else</span>
<span class="quote">&gt;-    286                 /* _sigchld is currently the largest know union member */</span>
<span class="quote">&gt;-    287                 memcpy(to, from, __ARCH_SI_PREAMBLE_SIZE + sizeof(from-&gt;_sifields._sigchld));</span>
<span class="quote">&gt;-    288 }</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-Since this was a read (kmemcheck usually warns about reads only, though it can</span>
<span class="quote">&gt;-warn about writes to unallocated or freed memory as well), it was probably the</span>
<span class="quote">&gt;-&quot;from&quot; argument which contained some uninitialized bytes. Following the chain</span>
<span class="quote">&gt;-of calls, we move upwards to see where &quot;from&quot; was allocated or initialized,</span>
<span class="quote">&gt;-``kernel/signal.c``, line 380::</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-    359 static void collect_signal(int sig, struct sigpending *list, siginfo_t *info)</span>
<span class="quote">&gt;-    360 {</span>
<span class="quote">&gt;-    ...</span>
<span class="quote">&gt;-    367         list_for_each_entry(q, &amp;list-&gt;list, list) {</span>
<span class="quote">&gt;-    368                 if (q-&gt;info.si_signo == sig) {</span>
<span class="quote">&gt;-    369                         if (first)</span>
<span class="quote">&gt;-    370                                 goto still_pending;</span>
<span class="quote">&gt;-    371                         first = q;</span>
<span class="quote">&gt;-    ...</span>
<span class="quote">&gt;-    377         if (first) {</span>
<span class="quote">&gt;-    378 still_pending:</span>
<span class="quote">&gt;-    379                 list_del_init(&amp;first-&gt;list);</span>
<span class="quote">&gt;-    380                 copy_siginfo(info, &amp;first-&gt;info);</span>
<span class="quote">&gt;-    381                 __sigqueue_free(first);</span>
<span class="quote">&gt;-    ...</span>
<span class="quote">&gt;-    392         }</span>
<span class="quote">&gt;-    393 }</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-Here, it is ``&amp;first-&gt;info`` that is being passed on to ``copy_siginfo()``. The</span>
<span class="quote">&gt;-variable ``first`` was found on a list -- passed in as the second argument to</span>
<span class="quote">&gt;-``collect_signal()``. We  continue our journey through the stack, to figure out</span>
<span class="quote">&gt;-where the item on &quot;list&quot; was allocated or initialized. We move to line 410::</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-    395 static int __dequeue_signal(struct sigpending *pending, sigset_t *mask,</span>
<span class="quote">&gt;-    396                         siginfo_t *info)</span>
<span class="quote">&gt;-    397 {</span>
<span class="quote">&gt;-    ...</span>
<span class="quote">&gt;-    410                 collect_signal(sig, pending, info);</span>
<span class="quote">&gt;-    ...</span>
<span class="quote">&gt;-    414 }</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-Now we need to follow the ``pending`` pointer, since that is being passed on to</span>
<span class="quote">&gt;-``collect_signal()`` as ``list``. At this point, we&#39;ve run out of lines from the</span>
<span class="quote">&gt;-&quot;addr2line&quot; output. Not to worry, we just paste the next addresses from the</span>
<span class="quote">&gt;-kmemcheck stack dump, i.e.::</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-     [&lt;ffffffff8104f04e&gt;] dequeue_signal+0x8e/0x170</span>
<span class="quote">&gt;-     [&lt;ffffffff81050bd8&gt;] get_signal_to_deliver+0x98/0x390</span>
<span class="quote">&gt;-     [&lt;ffffffff8100b87d&gt;] do_notify_resume+0xad/0x7d0</span>
<span class="quote">&gt;-     [&lt;ffffffff8100c7b5&gt;] int_signal+0x12/0x17</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	$ addr2line -e vmlinux -i ffffffff8104f04e ffffffff81050bd8 \</span>
<span class="quote">&gt;-		ffffffff8100b87d ffffffff8100c7b5</span>
<span class="quote">&gt;-	kernel/signal.c:446</span>
<span class="quote">&gt;-	kernel/signal.c:1806</span>
<span class="quote">&gt;-	arch/x86/kernel/signal.c:805</span>
<span class="quote">&gt;-	arch/x86/kernel/signal.c:871</span>
<span class="quote">&gt;-	arch/x86/kernel/entry_64.S:694</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-Remember that since these addresses were found on the stack and not as the</span>
<span class="quote">&gt;-RIP value, they actually point to the _next_ instruction (they are return</span>
<span class="quote">&gt;-addresses). This becomes obvious when we look at the code for line 446::</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-    422 int dequeue_signal(struct task_struct *tsk, sigset_t *mask, siginfo_t *info)</span>
<span class="quote">&gt;-    423 {</span>
<span class="quote">&gt;-    ...</span>
<span class="quote">&gt;-    431                 signr = __dequeue_signal(&amp;tsk-&gt;signal-&gt;shared_pending,</span>
<span class="quote">&gt;-    432						 mask, info);</span>
<span class="quote">&gt;-    433			/*</span>
<span class="quote">&gt;-    434			 * itimer signal ?</span>
<span class="quote">&gt;-    435			 *</span>
<span class="quote">&gt;-    436			 * itimers are process shared and we restart periodic</span>
<span class="quote">&gt;-    437			 * itimers in the signal delivery path to prevent DoS</span>
<span class="quote">&gt;-    438			 * attacks in the high resolution timer case. This is</span>
<span class="quote">&gt;-    439			 * compliant with the old way of self restarting</span>
<span class="quote">&gt;-    440			 * itimers, as the SIGALRM is a legacy signal and only</span>
<span class="quote">&gt;-    441			 * queued once. Changing the restart behaviour to</span>
<span class="quote">&gt;-    442			 * restart the timer in the signal dequeue path is</span>
<span class="quote">&gt;-    443			 * reducing the timer noise on heavy loaded !highres</span>
<span class="quote">&gt;-    444			 * systems too.</span>
<span class="quote">&gt;-    445			 */</span>
<span class="quote">&gt;-    446			if (unlikely(signr == SIGALRM)) {</span>
<span class="quote">&gt;-    ...</span>
<span class="quote">&gt;-    489 }</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-So instead of looking at 446, we should be looking at 431, which is the line</span>
<span class="quote">&gt;-that executes just before 446. Here we see that what we are looking for is</span>
<span class="quote">&gt;-``&amp;tsk-&gt;signal-&gt;shared_pending``.</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-Our next task is now to figure out which function that puts items on this</span>
<span class="quote">&gt;-``shared_pending`` list. A crude, but efficient tool, is ``git grep``::</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	$ git grep -n &#39;shared_pending&#39; kernel/</span>
<span class="quote">&gt;-	...</span>
<span class="quote">&gt;-	kernel/signal.c:828:	pending = group ? &amp;t-&gt;signal-&gt;shared_pending : &amp;t-&gt;pending;</span>
<span class="quote">&gt;-	kernel/signal.c:1339:	pending = group ? &amp;t-&gt;signal-&gt;shared_pending : &amp;t-&gt;pending;</span>
<span class="quote">&gt;-	...</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-There were more results, but none of them were related to list operations,</span>
<span class="quote">&gt;-and these were the only assignments. We inspect the line numbers more closely</span>
<span class="quote">&gt;-and find that this is indeed where items are being added to the list::</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-    816 static int send_signal(int sig, struct siginfo *info, struct task_struct *t,</span>
<span class="quote">&gt;-    817				int group)</span>
<span class="quote">&gt;-    818 {</span>
<span class="quote">&gt;-    ...</span>
<span class="quote">&gt;-    828		pending = group ? &amp;t-&gt;signal-&gt;shared_pending : &amp;t-&gt;pending;</span>
<span class="quote">&gt;-    ...</span>
<span class="quote">&gt;-    851		q = __sigqueue_alloc(t, GFP_ATOMIC, (sig &lt; SIGRTMIN &amp;&amp;</span>
<span class="quote">&gt;-    852						     (is_si_special(info) ||</span>
<span class="quote">&gt;-    853						      info-&gt;si_code &gt;= 0)));</span>
<span class="quote">&gt;-    854		if (q) {</span>
<span class="quote">&gt;-    855			list_add_tail(&amp;q-&gt;list, &amp;pending-&gt;list);</span>
<span class="quote">&gt;-    ...</span>
<span class="quote">&gt;-    890 }</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-and::</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-    1309 int send_sigqueue(struct sigqueue *q, struct task_struct *t, int group)</span>
<span class="quote">&gt;-    1310 {</span>
<span class="quote">&gt;-    ....</span>
<span class="quote">&gt;-    1339	 pending = group ? &amp;t-&gt;signal-&gt;shared_pending : &amp;t-&gt;pending;</span>
<span class="quote">&gt;-    1340	 list_add_tail(&amp;q-&gt;list, &amp;pending-&gt;list);</span>
<span class="quote">&gt;-    ....</span>
<span class="quote">&gt;-    1347 }</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-In the first case, the list element we are looking for, ``q``, is being</span>
<span class="quote">&gt;-returned from the function ``__sigqueue_alloc()``, which looks like an</span>
<span class="quote">&gt;-allocation function.  Let&#39;s take a look at it::</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-    187 static struct sigqueue *__sigqueue_alloc(struct task_struct *t, gfp_t flags,</span>
<span class="quote">&gt;-    188						 int override_rlimit)</span>
<span class="quote">&gt;-    189 {</span>
<span class="quote">&gt;-    190		struct sigqueue *q = NULL;</span>
<span class="quote">&gt;-    191		struct user_struct *user;</span>
<span class="quote">&gt;-    192</span>
<span class="quote">&gt;-    193		/*</span>
<span class="quote">&gt;-    194		 * We won&#39;t get problems with the target&#39;s UID changing under us</span>
<span class="quote">&gt;-    195		 * because changing it requires RCU be used, and if t != current, the</span>
<span class="quote">&gt;-    196		 * caller must be holding the RCU readlock (by way of a spinlock) and</span>
<span class="quote">&gt;-    197		 * we use RCU protection here</span>
<span class="quote">&gt;-    198		 */</span>
<span class="quote">&gt;-    199		user = get_uid(__task_cred(t)-&gt;user);</span>
<span class="quote">&gt;-    200		atomic_inc(&amp;user-&gt;sigpending);</span>
<span class="quote">&gt;-    201		if (override_rlimit ||</span>
<span class="quote">&gt;-    202		    atomic_read(&amp;user-&gt;sigpending) &lt;=</span>
<span class="quote">&gt;-    203				t-&gt;signal-&gt;rlim[RLIMIT_SIGPENDING].rlim_cur)</span>
<span class="quote">&gt;-    204			q = kmem_cache_alloc(sigqueue_cachep, flags);</span>
<span class="quote">&gt;-    205		if (unlikely(q == NULL)) {</span>
<span class="quote">&gt;-    206			atomic_dec(&amp;user-&gt;sigpending);</span>
<span class="quote">&gt;-    207			free_uid(user);</span>
<span class="quote">&gt;-    208		} else {</span>
<span class="quote">&gt;-    209			INIT_LIST_HEAD(&amp;q-&gt;list);</span>
<span class="quote">&gt;-    210			q-&gt;flags = 0;</span>
<span class="quote">&gt;-    211			q-&gt;user = user;</span>
<span class="quote">&gt;-    212		}</span>
<span class="quote">&gt;-    213</span>
<span class="quote">&gt;-    214		return q;</span>
<span class="quote">&gt;-    215 }</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-We see that this function initializes ``q-&gt;list``, ``q-&gt;flags``, and</span>
<span class="quote">&gt;-``q-&gt;user``. It seems that now is the time to look at the definition of</span>
<span class="quote">&gt;-``struct sigqueue``, e.g.::</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-    14 struct sigqueue {</span>
<span class="quote">&gt;-    15	       struct list_head list;</span>
<span class="quote">&gt;-    16	       int flags;</span>
<span class="quote">&gt;-    17	       siginfo_t info;</span>
<span class="quote">&gt;-    18	       struct user_struct *user;</span>
<span class="quote">&gt;-    19 };</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-And, you might remember, it was a ``memcpy()`` on ``&amp;first-&gt;info`` that</span>
<span class="quote">&gt;-caused the warning, so this makes perfect sense. It also seems reasonable</span>
<span class="quote">&gt;-to assume that it is the caller of ``__sigqueue_alloc()`` that has the</span>
<span class="quote">&gt;-responsibility of filling out (initializing) this member.</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-But just which fields of the struct were uninitialized? Let&#39;s look at</span>
<span class="quote">&gt;-kmemcheck&#39;s report again::</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-    WARNING: kmemcheck: Caught 32-bit read from uninitialized memory (ffff88003e4a2024)</span>
<span class="quote">&gt;-    80000000000000000000000000000000000000000088ffff0000000000000000</span>
<span class="quote">&gt;-     i i i i u u u u i i i i i i i i u u u u u u u u u u u u u u u u</span>
<span class="quote">&gt;-	     ^</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-These first two lines are the memory dump of the memory object itself, and</span>
<span class="quote">&gt;-the shadow bytemap, respectively. The memory object itself is in this case</span>
<span class="quote">&gt;-``&amp;first-&gt;info``. Just beware that the start of this dump is NOT the start</span>
<span class="quote">&gt;-of the object itself! The position of the caret (^) corresponds with the</span>
<span class="quote">&gt;-address of the read (ffff88003e4a2024).</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-The shadow bytemap dump legend is as follows:</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-- i: initialized</span>
<span class="quote">&gt;-- u: uninitialized</span>
<span class="quote">&gt;-- a: unallocated (memory has been allocated by the slab layer, but has not</span>
<span class="quote">&gt;-  yet been handed off to anybody)</span>
<span class="quote">&gt;-- f: freed (memory has been allocated by the slab layer, but has been freed</span>
<span class="quote">&gt;-  by the previous owner)</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-In order to figure out where (relative to the start of the object) the</span>
<span class="quote">&gt;-uninitialized memory was located, we have to look at the disassembly. For</span>
<span class="quote">&gt;-that, we&#39;ll need the RIP address again::</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-    RIP: 0010:[&lt;ffffffff8104ede8&gt;]  [&lt;ffffffff8104ede8&gt;] __dequeue_signal+0xc8/0x190</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	$ objdump -d --no-show-raw-insn vmlinux | grep -C 8 ffffffff8104ede8:</span>
<span class="quote">&gt;-	ffffffff8104edc8:	mov    %r8,0x8(%r8)</span>
<span class="quote">&gt;-	ffffffff8104edcc:	test   %r10d,%r10d</span>
<span class="quote">&gt;-	ffffffff8104edcf:	js     ffffffff8104ee88 &lt;__dequeue_signal+0x168&gt;</span>
<span class="quote">&gt;-	ffffffff8104edd5:	mov    %rax,%rdx</span>
<span class="quote">&gt;-	ffffffff8104edd8:	mov    $0xc,%ecx</span>
<span class="quote">&gt;-	ffffffff8104eddd:	mov    %r13,%rdi</span>
<span class="quote">&gt;-	ffffffff8104ede0:	mov    $0x30,%eax</span>
<span class="quote">&gt;-	ffffffff8104ede5:	mov    %rdx,%rsi</span>
<span class="quote">&gt;-	ffffffff8104ede8:	rep movsl %ds:(%rsi),%es:(%rdi)</span>
<span class="quote">&gt;-	ffffffff8104edea:	test   $0x2,%al</span>
<span class="quote">&gt;-	ffffffff8104edec:	je     ffffffff8104edf0 &lt;__dequeue_signal+0xd0&gt;</span>
<span class="quote">&gt;-	ffffffff8104edee:	movsw  %ds:(%rsi),%es:(%rdi)</span>
<span class="quote">&gt;-	ffffffff8104edf0:	test   $0x1,%al</span>
<span class="quote">&gt;-	ffffffff8104edf2:	je     ffffffff8104edf5 &lt;__dequeue_signal+0xd5&gt;</span>
<span class="quote">&gt;-	ffffffff8104edf4:	movsb  %ds:(%rsi),%es:(%rdi)</span>
<span class="quote">&gt;-	ffffffff8104edf5:	mov    %r8,%rdi</span>
<span class="quote">&gt;-	ffffffff8104edf8:	callq  ffffffff8104de60 &lt;__sigqueue_free&gt;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-As expected, it&#39;s the &quot;``rep movsl``&quot; instruction from the ``memcpy()``</span>
<span class="quote">&gt;-that causes the warning. We know about ``REP MOVSL`` that it uses the register</span>
<span class="quote">&gt;-``RCX`` to count the number of remaining iterations. By taking a look at the</span>
<span class="quote">&gt;-register dump again (from the kmemcheck report), we can figure out how many</span>
<span class="quote">&gt;-bytes were left to copy::</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-    RAX: 0000000000000030 RBX: ffff88003d4ea968 RCX: 0000000000000009</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-By looking at the disassembly, we also see that ``%ecx`` is being loaded</span>
<span class="quote">&gt;-with the value ``$0xc`` just before (ffffffff8104edd8), so we are very</span>
<span class="quote">&gt;-lucky. Keep in mind that this is the number of iterations, not bytes. And</span>
<span class="quote">&gt;-since this is a &quot;long&quot; operation, we need to multiply by 4 to get the</span>
<span class="quote">&gt;-number of bytes. So this means that the uninitialized value was encountered</span>
<span class="quote">&gt;-at 4 * (0xc - 0x9) = 12 bytes from the start of the object.</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-We can now try to figure out which field of the &quot;``struct siginfo``&quot; that</span>
<span class="quote">&gt;-was not initialized. This is the beginning of the struct::</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-    40 typedef struct siginfo {</span>
<span class="quote">&gt;-    41	       int si_signo;</span>
<span class="quote">&gt;-    42	       int si_errno;</span>
<span class="quote">&gt;-    43	       int si_code;</span>
<span class="quote">&gt;-    44</span>
<span class="quote">&gt;-    45	       union {</span>
<span class="quote">&gt;-    ..</span>
<span class="quote">&gt;-    92	       } _sifields;</span>
<span class="quote">&gt;-    93 } siginfo_t;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-On 64-bit, the int is 4 bytes long, so it must the union member that has</span>
<span class="quote">&gt;-not been initialized. We can verify this using gdb::</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	$ gdb vmlinux</span>
<span class="quote">&gt;-	...</span>
<span class="quote">&gt;-	(gdb) p &amp;((struct siginfo *) 0)-&gt;_sifields</span>
<span class="quote">&gt;-	$1 = (union {...} *) 0x10</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-Actually, it seems that the union member is located at offset 0x10 -- which</span>
<span class="quote">&gt;-means that gcc has inserted 4 bytes of padding between the members ``si_code``</span>
<span class="quote">&gt;-and ``_sifields``. We can now get a fuller picture of the memory dump::</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-		 _----------------------------=&gt; si_code</span>
<span class="quote">&gt;-		/	 _--------------------=&gt; (padding)</span>
<span class="quote">&gt;-	       |	/	 _------------=&gt; _sifields(._kill._pid)</span>
<span class="quote">&gt;-	       |       |	/	 _----=&gt; _sifields(._kill._uid)</span>
<span class="quote">&gt;-	       |       |       |	/</span>
<span class="quote">&gt;-	-------|-------|-------|-------|</span>
<span class="quote">&gt;-	80000000000000000000000000000000000000000088ffff0000000000000000</span>
<span class="quote">&gt;-	 i i i i u u u u i i i i i i i i u u u u u u u u u u u u u u u u</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-This allows us to realize another important fact: ``si_code`` contains the</span>
<span class="quote">&gt;-value 0x80. Remember that x86 is little endian, so the first 4 bytes</span>
<span class="quote">&gt;-&quot;80000000&quot; are really the number 0x00000080. With a bit of research, we</span>
<span class="quote">&gt;-find that this is actually the constant ``SI_KERNEL`` defined in</span>
<span class="quote">&gt;-``include/asm-generic/siginfo.h``::</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-    144 #define SI_KERNEL	0x80		/* sent by the kernel from somewhere	 */</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-This macro is used in exactly one place in the x86 kernel: In ``send_signal()``</span>
<span class="quote">&gt;-in ``kernel/signal.c``::</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-    816 static int send_signal(int sig, struct siginfo *info, struct task_struct *t,</span>
<span class="quote">&gt;-    817				int group)</span>
<span class="quote">&gt;-    818 {</span>
<span class="quote">&gt;-    ...</span>
<span class="quote">&gt;-    828		pending = group ? &amp;t-&gt;signal-&gt;shared_pending : &amp;t-&gt;pending;</span>
<span class="quote">&gt;-    ...</span>
<span class="quote">&gt;-    851		q = __sigqueue_alloc(t, GFP_ATOMIC, (sig &lt; SIGRTMIN &amp;&amp;</span>
<span class="quote">&gt;-    852						     (is_si_special(info) ||</span>
<span class="quote">&gt;-    853						      info-&gt;si_code &gt;= 0)));</span>
<span class="quote">&gt;-    854		if (q) {</span>
<span class="quote">&gt;-    855			list_add_tail(&amp;q-&gt;list, &amp;pending-&gt;list);</span>
<span class="quote">&gt;-    856			switch ((unsigned long) info) {</span>
<span class="quote">&gt;-    ...</span>
<span class="quote">&gt;-    865			case (unsigned long) SEND_SIG_PRIV:</span>
<span class="quote">&gt;-    866				q-&gt;info.si_signo = sig;</span>
<span class="quote">&gt;-    867				q-&gt;info.si_errno = 0;</span>
<span class="quote">&gt;-    868				q-&gt;info.si_code = SI_KERNEL;</span>
<span class="quote">&gt;-    869				q-&gt;info.si_pid = 0;</span>
<span class="quote">&gt;-    870				q-&gt;info.si_uid = 0;</span>
<span class="quote">&gt;-    871				break;</span>
<span class="quote">&gt;-    ...</span>
<span class="quote">&gt;-    890 }</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-Not only does this match with the ``.si_code`` member, it also matches the place</span>
<span class="quote">&gt;-we found earlier when looking for where siginfo_t objects are enqueued on the</span>
<span class="quote">&gt;-``shared_pending`` list.</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-So to sum up: It seems that it is the padding introduced by the compiler</span>
<span class="quote">&gt;-between two struct fields that is uninitialized, and this gets reported when</span>
<span class="quote">&gt;-we do a ``memcpy()`` on the struct. This means that we have identified a false</span>
<span class="quote">&gt;-positive warning.</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-Normally, kmemcheck will not report uninitialized accesses in ``memcpy()`` calls</span>
<span class="quote">&gt;-when both the source and destination addresses are tracked. (Instead, we copy</span>
<span class="quote">&gt;-the shadow bytemap as well). In this case, the destination address clearly</span>
<span class="quote">&gt;-was not tracked. We can dig a little deeper into the stack trace from above::</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	arch/x86/kernel/signal.c:805</span>
<span class="quote">&gt;-	arch/x86/kernel/signal.c:871</span>
<span class="quote">&gt;-	arch/x86/kernel/entry_64.S:694</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-And we clearly see that the destination siginfo object is located on the</span>
<span class="quote">&gt;-stack::</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-    782 static void do_signal(struct pt_regs *regs)</span>
<span class="quote">&gt;-    783 {</span>
<span class="quote">&gt;-    784		struct k_sigaction ka;</span>
<span class="quote">&gt;-    785		siginfo_t info;</span>
<span class="quote">&gt;-    ...</span>
<span class="quote">&gt;-    804		signr = get_signal_to_deliver(&amp;info, &amp;ka, regs, NULL);</span>
<span class="quote">&gt;-    ...</span>
<span class="quote">&gt;-    854 }</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-And this ``&amp;info`` is what eventually gets passed to ``copy_siginfo()`` as the</span>
<span class="quote">&gt;-destination argument.</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-Now, even though we didn&#39;t find an actual error here, the example is still a</span>
<span class="quote">&gt;-good one, because it shows how one would go about to find out what the report</span>
<span class="quote">&gt;-was all about.</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-Annotating false positives</span>
<span class="quote">&gt;-~~~~~~~~~~~~~~~~~~~~~~~~~~</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-There are a few different ways to make annotations in the source code that</span>
<span class="quote">&gt;-will keep kmemcheck from checking and reporting certain allocations. Here</span>
<span class="quote">&gt;-they are:</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-- ``__GFP_NOTRACK_FALSE_POSITIVE``</span>
<span class="quote">&gt;-	This flag can be passed to ``kmalloc()`` or ``kmem_cache_alloc()``</span>
<span class="quote">&gt;-	(therefore also to other functions that end up calling one of</span>
<span class="quote">&gt;-	these) to indicate that the allocation should not be tracked</span>
<span class="quote">&gt;-	because it would lead to a false positive report. This is a &quot;big</span>
<span class="quote">&gt;-	hammer&quot; way of silencing kmemcheck; after all, even if the false</span>
<span class="quote">&gt;-	positive pertains to particular field in a struct, for example, we</span>
<span class="quote">&gt;-	will now lose the ability to find (real) errors in other parts of</span>
<span class="quote">&gt;-	the same struct.</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	Example::</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	    /* No warnings will ever trigger on accessing any part of x */</span>
<span class="quote">&gt;-	    x = kmalloc(sizeof *x, GFP_KERNEL | __GFP_NOTRACK_FALSE_POSITIVE);</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-- ``kmemcheck_bitfield_begin(name)``/``kmemcheck_bitfield_end(name)`` and</span>
<span class="quote">&gt;-	``kmemcheck_annotate_bitfield(ptr, name)``</span>
<span class="quote">&gt;-	The first two of these three macros can be used inside struct</span>
<span class="quote">&gt;-	definitions to signal, respectively, the beginning and end of a</span>
<span class="quote">&gt;-	bitfield. Additionally, this will assign the bitfield a name, which</span>
<span class="quote">&gt;-	is given as an argument to the macros.</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	Having used these markers, one can later use</span>
<span class="quote">&gt;-	kmemcheck_annotate_bitfield() at the point of allocation, to indicate</span>
<span class="quote">&gt;-	which parts of the allocation is part of a bitfield.</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	Example::</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	    struct foo {</span>
<span class="quote">&gt;-		int x;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-		kmemcheck_bitfield_begin(flags);</span>
<span class="quote">&gt;-		int flag_a:1;</span>
<span class="quote">&gt;-		int flag_b:1;</span>
<span class="quote">&gt;-		kmemcheck_bitfield_end(flags);</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-		int y;</span>
<span class="quote">&gt;-	    };</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	    struct foo *x = kmalloc(sizeof *x);</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	    /* No warnings will trigger on accessing the bitfield of x */</span>
<span class="quote">&gt;-	    kmemcheck_annotate_bitfield(x, flags);</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	Note that ``kmemcheck_annotate_bitfield()`` can be used even before the</span>
<span class="quote">&gt;-	return value of ``kmalloc()`` is checked -- in other words, passing NULL</span>
<span class="quote">&gt;-	as the first argument is legal (and will do nothing).</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-Reporting errors</span>
<span class="quote">&gt;-----------------</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-As we have seen, kmemcheck will produce false positive reports. Therefore, it</span>
<span class="quote">&gt;-is not very wise to blindly post kmemcheck warnings to mailing lists and</span>
<span class="quote">&gt;-maintainers. Instead, I encourage maintainers and developers to find errors</span>
<span class="quote">&gt;-in their own code. If you get a warning, you can try to work around it, try</span>
<span class="quote">&gt;-to figure out if it&#39;s a real error or not, or simply ignore it. Most</span>
<span class="quote">&gt;-developers know their own code and will quickly and efficiently determine the</span>
<span class="quote">&gt;-root cause of a kmemcheck report. This is therefore also the most efficient</span>
<span class="quote">&gt;-way to work with kmemcheck.</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-That said, we (the kmemcheck maintainers) will always be on the lookout for</span>
<span class="quote">&gt;-false positives that we can annotate and silence. So whatever you find,</span>
<span class="quote">&gt;-please drop us a note privately! Kernel configs and steps to reproduce (if</span>
<span class="quote">&gt;-available) are of course a great help too.</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-Happy hacking!</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-Technical description</span>
<span class="quote">&gt;----------------------</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-kmemcheck works by marking memory pages non-present. This means that whenever</span>
<span class="quote">&gt;-somebody attempts to access the page, a page fault is generated. The page</span>
<span class="quote">&gt;-fault handler notices that the page was in fact only hidden, and so it calls</span>
<span class="quote">&gt;-on the kmemcheck code to make further investigations.</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-When the investigations are completed, kmemcheck &quot;shows&quot; the page by marking</span>
<span class="quote">&gt;-it present (as it would be under normal circumstances). This way, the</span>
<span class="quote">&gt;-interrupted code can continue as usual.</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-But after the instruction has been executed, we should hide the page again, so</span>
<span class="quote">&gt;-that we can catch the next access too! Now kmemcheck makes use of a debugging</span>
<span class="quote">&gt;-feature of the processor, namely single-stepping. When the processor has</span>
<span class="quote">&gt;-finished the one instruction that generated the memory access, a debug</span>
<span class="quote">&gt;-exception is raised. From here, we simply hide the page again and continue</span>
<span class="quote">&gt;-execution, this time with the single-stepping feature turned off.</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-kmemcheck requires some assistance from the memory allocator in order to work.</span>
<span class="quote">&gt;-The memory allocator needs to</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-  1. Tell kmemcheck about newly allocated pages and pages that are about to</span>
<span class="quote">&gt;-     be freed. This allows kmemcheck to set up and tear down the shadow memory</span>
<span class="quote">&gt;-     for the pages in question. The shadow memory stores the status of each</span>
<span class="quote">&gt;-     byte in the allocation proper, e.g. whether it is initialized or</span>
<span class="quote">&gt;-     uninitialized.</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-  2. Tell kmemcheck which parts of memory should be marked uninitialized.</span>
<span class="quote">&gt;-     There are actually a few more states, such as &quot;not yet allocated&quot; and</span>
<span class="quote">&gt;-     &quot;recently freed&quot;.</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-If a slab cache is set up using the SLAB_NOTRACK flag, it will never return</span>
<span class="quote">&gt;-memory that can take page faults because of kmemcheck.</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-If a slab cache is NOT set up using the SLAB_NOTRACK flag, callers can still</span>
<span class="quote">&gt;-request memory with the __GFP_NOTRACK or __GFP_NOTRACK_FALSE_POSITIVE flags.</span>
<span class="quote">&gt;-This does not prevent the page faults from occurring, however, but marks the</span>
<span class="quote">&gt;-object in question as being initialized so that no warnings will ever be</span>
<span class="quote">&gt;-produced for this object.</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-Currently, the SLAB and SLUB allocators are supported by kmemcheck.</span>
<span class="quote">&gt;diff --git a/MAINTAINERS b/MAINTAINERS</span>
<span class="quote">&gt;index 6671f375f7fc..74eee2abeeb5 100644</span>
<span class="quote">&gt;--- a/MAINTAINERS</span>
<span class="quote">&gt;+++ b/MAINTAINERS</span>
<span class="quote">&gt;@@ -7669,16 +7669,6 @@ F:	include/linux/kdb.h</span>
<span class="quote">&gt; F:	include/linux/kgdb.h</span>
<span class="quote">&gt; F:	kernel/debug/</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;-KMEMCHECK</span>
<span class="quote">&gt;-M:	Vegard Nossum &lt;vegardno@ifi.uio.no&gt;</span>
<span class="quote">&gt;-M:	Pekka Enberg &lt;penberg@kernel.org&gt;</span>
<span class="quote">&gt;-S:	Maintained</span>
<span class="quote">&gt;-F:	Documentation/dev-tools/kmemcheck.rst</span>
<span class="quote">&gt;-F:	arch/x86/include/asm/kmemcheck.h</span>
<span class="quote">&gt;-F:	arch/x86/mm/kmemcheck/</span>
<span class="quote">&gt;-F:	include/linux/kmemcheck.h</span>
<span class="quote">&gt;-F:	mm/kmemcheck.c</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt; KMEMLEAK</span>
<span class="quote">&gt; M:	Catalin Marinas &lt;catalin.marinas@arm.com&gt;</span>
<span class="quote">&gt; S:	Maintained</span>
<span class="quote">&gt;diff --git a/arch/arm/include/asm/dma-iommu.h b/arch/arm/include/asm/dma-iommu.h</span>
<span class="quote">&gt;index c090ec675eac..5ad676f2de22 100644</span>
<span class="quote">&gt;--- a/arch/arm/include/asm/dma-iommu.h</span>
<span class="quote">&gt;+++ b/arch/arm/include/asm/dma-iommu.h</span>
<span class="quote">&gt;@@ -6,7 +6,6 @@</span>
<span class="quote">&gt; #include &lt;linux/mm_types.h&gt;</span>
<span class="quote">&gt; #include &lt;linux/scatterlist.h&gt;</span>
<span class="quote">&gt; #include &lt;linux/dma-debug.h&gt;</span>
<span class="quote">&gt;-#include &lt;linux/kmemcheck.h&gt;</span>
<span class="quote">&gt; #include &lt;linux/kref.h&gt;</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; #define ARM_MAPPING_ERROR		(~(dma_addr_t)0x0)</span>
<span class="quote">&gt;diff --git a/arch/arm/include/asm/pgalloc.h b/arch/arm/include/asm/pgalloc.h</span>
<span class="quote">&gt;index b2902a5cd780..2d7344f0e208 100644</span>
<span class="quote">&gt;--- a/arch/arm/include/asm/pgalloc.h</span>
<span class="quote">&gt;+++ b/arch/arm/include/asm/pgalloc.h</span>
<span class="quote">&gt;@@ -57,7 +57,7 @@ static inline void pud_populate(struct mm_struct *mm, pud_t *pud, pmd_t *pmd)</span>
<span class="quote">&gt; extern pgd_t *pgd_alloc(struct mm_struct *mm);</span>
<span class="quote">&gt; extern void pgd_free(struct mm_struct *mm, pgd_t *pgd);</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;-#define PGALLOC_GFP	(GFP_KERNEL | __GFP_NOTRACK | __GFP_ZERO)</span>
<span class="quote">&gt;+#define PGALLOC_GFP	(GFP_KERNEL | __GFP_ZERO)</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; static inline void clean_pte_table(pte_t *pte)</span>
<span class="quote">&gt; {</span>
<span class="quote">&gt;diff --git a/arch/arm64/include/asm/pgalloc.h b/arch/arm64/include/asm/pgalloc.h</span>
<span class="quote">&gt;index d25f4f137c2a..5ca6a573a701 100644</span>
<span class="quote">&gt;--- a/arch/arm64/include/asm/pgalloc.h</span>
<span class="quote">&gt;+++ b/arch/arm64/include/asm/pgalloc.h</span>
<span class="quote">&gt;@@ -26,7 +26,7 @@</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; #define check_pgt_cache()		do { } while (0)</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;-#define PGALLOC_GFP	(GFP_KERNEL | __GFP_NOTRACK | __GFP_ZERO)</span>
<span class="quote">&gt;+#define PGALLOC_GFP	(GFP_KERNEL | __GFP_ZERO)</span>
<span class="quote">&gt; #define PGD_SIZE	(PTRS_PER_PGD * sizeof(pgd_t))</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; #if CONFIG_PGTABLE_LEVELS &gt; 2</span>
<span class="quote">&gt;diff --git a/arch/openrisc/include/asm/dma-mapping.h b/arch/openrisc/include/asm/dma-mapping.h</span>
<span class="quote">&gt;index f41bd3cb76d9..e212a1f0b6d2 100644</span>
<span class="quote">&gt;--- a/arch/openrisc/include/asm/dma-mapping.h</span>
<span class="quote">&gt;+++ b/arch/openrisc/include/asm/dma-mapping.h</span>
<span class="quote">&gt;@@ -23,7 +23,6 @@</span>
<span class="quote">&gt;  */</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; #include &lt;linux/dma-debug.h&gt;</span>
<span class="quote">&gt;-#include &lt;linux/kmemcheck.h&gt;</span>
<span class="quote">&gt; #include &lt;linux/dma-mapping.h&gt;</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; extern const struct dma_map_ops or1k_dma_map_ops;</span>
<span class="quote">&gt;diff --git a/arch/powerpc/include/asm/pgalloc.h b/arch/powerpc/include/asm/pgalloc.h</span>
<span class="quote">&gt;index 45ae1212ab8a..bb01297b617a 100644</span>
<span class="quote">&gt;--- a/arch/powerpc/include/asm/pgalloc.h</span>
<span class="quote">&gt;+++ b/arch/powerpc/include/asm/pgalloc.h</span>
<span class="quote">&gt;@@ -17,7 +17,7 @@ static inline gfp_t pgtable_gfp_flags(struct mm_struct *mm, gfp_t gfp)</span>
<span class="quote">&gt; }</span>
<span class="quote">&gt; #endif /* MODULE */</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;-#define PGALLOC_GFP (GFP_KERNEL | __GFP_NOTRACK | __GFP_ZERO)</span>
<span class="quote">&gt;+#define PGALLOC_GFP (GFP_KERNEL | __GFP_ZERO)</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; #ifdef CONFIG_PPC_BOOK3S</span>
<span class="quote">&gt; #include &lt;asm/book3s/pgalloc.h&gt;</span>
<span class="quote">&gt;diff --git a/arch/sh/kernel/dwarf.c b/arch/sh/kernel/dwarf.c</span>
<span class="quote">&gt;index e1d751ae2498..1a2526676a87 100644</span>
<span class="quote">&gt;--- a/arch/sh/kernel/dwarf.c</span>
<span class="quote">&gt;+++ b/arch/sh/kernel/dwarf.c</span>
<span class="quote">&gt;@@ -1172,11 +1172,11 @@ static int __init dwarf_unwinder_init(void)</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; 	dwarf_frame_cachep = kmem_cache_create(&quot;dwarf_frames&quot;,</span>
<span class="quote">&gt; 			sizeof(struct dwarf_frame), 0,</span>
<span class="quote">&gt;-			SLAB_PANIC | SLAB_HWCACHE_ALIGN | SLAB_NOTRACK, NULL);</span>
<span class="quote">&gt;+			SLAB_PANIC | SLAB_HWCACHE_ALIGN, NULL);</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; 	dwarf_reg_cachep = kmem_cache_create(&quot;dwarf_regs&quot;,</span>
<span class="quote">&gt; 			sizeof(struct dwarf_reg), 0,</span>
<span class="quote">&gt;-			SLAB_PANIC | SLAB_HWCACHE_ALIGN | SLAB_NOTRACK, NULL);</span>
<span class="quote">&gt;+			SLAB_PANIC | SLAB_HWCACHE_ALIGN, NULL);</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; 	dwarf_frame_pool = mempool_create_slab_pool(DWARF_FRAME_MIN_REQ,</span>
<span class="quote">&gt; 						    dwarf_frame_cachep);</span>
<span class="quote">&gt;diff --git a/arch/sh/kernel/process.c b/arch/sh/kernel/process.c</span>
<span class="quote">&gt;index f8a695a223dd..ded55e7461f8 100644</span>
<span class="quote">&gt;--- a/arch/sh/kernel/process.c</span>
<span class="quote">&gt;+++ b/arch/sh/kernel/process.c</span>
<span class="quote">&gt;@@ -58,7 +58,7 @@ void arch_task_cache_init(void)</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; 	task_xstate_cachep = kmem_cache_create(&quot;task_xstate&quot;, xstate_size,</span>
<span class="quote">&gt; 					       __alignof__(union thread_xstate),</span>
<span class="quote">&gt;-					       SLAB_PANIC | SLAB_NOTRACK, NULL);</span>
<span class="quote">&gt;+					       SLAB_PANIC, NULL);</span>
<span class="quote">&gt; }</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; #ifdef CONFIG_SH_FPU_EMU</span>
<span class="quote">&gt;diff --git a/arch/sparc/mm/init_64.c b/arch/sparc/mm/init_64.c</span>
<span class="quote">&gt;index b2ba410b26f4..78f79004be2c 100644</span>
<span class="quote">&gt;--- a/arch/sparc/mm/init_64.c</span>
<span class="quote">&gt;+++ b/arch/sparc/mm/init_64.c</span>
<span class="quote">&gt;@@ -2926,7 +2926,7 @@ void __flush_tlb_all(void)</span>
<span class="quote">&gt; pte_t *pte_alloc_one_kernel(struct mm_struct *mm,</span>
<span class="quote">&gt; 			    unsigned long address)</span>
<span class="quote">&gt; {</span>
<span class="quote">&gt;-	struct page *page = alloc_page(GFP_KERNEL | __GFP_NOTRACK | __GFP_ZERO);</span>
<span class="quote">&gt;+	struct page *page = alloc_page(GFP_KERNEL | __GFP_ZERO);</span>
<span class="quote">&gt; 	pte_t *pte = NULL;</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; 	if (page)</span>
<span class="quote">&gt;@@ -2938,7 +2938,7 @@ pte_t *pte_alloc_one_kernel(struct mm_struct *mm,</span>
<span class="quote">&gt; pgtable_t pte_alloc_one(struct mm_struct *mm,</span>
<span class="quote">&gt; 			unsigned long address)</span>
<span class="quote">&gt; {</span>
<span class="quote">&gt;-	struct page *page = alloc_page(GFP_KERNEL | __GFP_NOTRACK | __GFP_ZERO);</span>
<span class="quote">&gt;+	struct page *page = alloc_page(GFP_KERNEL | __GFP_ZERO);</span>
<span class="quote">&gt; 	if (!page)</span>
<span class="quote">&gt; 		return NULL;</span>
<span class="quote">&gt; 	if (!pgtable_page_ctor(page)) {</span>
<span class="quote">&gt;diff --git a/arch/unicore32/include/asm/pgalloc.h b/arch/unicore32/include/asm/pgalloc.h</span>
<span class="quote">&gt;index 26775793c204..f0fdb268f8f2 100644</span>
<span class="quote">&gt;--- a/arch/unicore32/include/asm/pgalloc.h</span>
<span class="quote">&gt;+++ b/arch/unicore32/include/asm/pgalloc.h</span>
<span class="quote">&gt;@@ -28,7 +28,7 @@ extern void free_pgd_slow(struct mm_struct *mm, pgd_t *pgd);</span>
<span class="quote">&gt; #define pgd_alloc(mm)			get_pgd_slow(mm)</span>
<span class="quote">&gt; #define pgd_free(mm, pgd)		free_pgd_slow(mm, pgd)</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;-#define PGALLOC_GFP	(GFP_KERNEL | __GFP_NOTRACK | __GFP_ZERO)</span>
<span class="quote">&gt;+#define PGALLOC_GFP	(GFP_KERNEL | __GFP_ZERO)</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; /*</span>
<span class="quote">&gt;  * Allocate one PTE table.</span>
<span class="quote">&gt;diff --git a/arch/x86/Kconfig b/arch/x86/Kconfig</span>
<span class="quote">&gt;index 971feac13506..f2b6484a0b36 100644</span>
<span class="quote">&gt;--- a/arch/x86/Kconfig</span>
<span class="quote">&gt;+++ b/arch/x86/Kconfig</span>
<span class="quote">&gt;@@ -109,7 +109,6 @@ config X86</span>
<span class="quote">&gt; 	select HAVE_ARCH_JUMP_LABEL</span>
<span class="quote">&gt; 	select HAVE_ARCH_KASAN			if X86_64 &amp;&amp; SPARSEMEM_VMEMMAP</span>
<span class="quote">&gt; 	select HAVE_ARCH_KGDB</span>
<span class="quote">&gt;-	select HAVE_ARCH_KMEMCHECK</span>
<span class="quote">&gt; 	select HAVE_ARCH_MMAP_RND_BITS		if MMU</span>
<span class="quote">&gt; 	select HAVE_ARCH_MMAP_RND_COMPAT_BITS	if MMU &amp;&amp; COMPAT</span>
<span class="quote">&gt; 	select HAVE_ARCH_COMPAT_MMAP_BASES	if MMU &amp;&amp; COMPAT</span>
<span class="quote">&gt;@@ -1428,7 +1427,7 @@ config ARCH_DMA_ADDR_T_64BIT</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; config X86_DIRECT_GBPAGES</span>
<span class="quote">&gt; 	def_bool y</span>
<span class="quote">&gt;-	depends on X86_64 &amp;&amp; !DEBUG_PAGEALLOC &amp;&amp; !KMEMCHECK</span>
<span class="quote">&gt;+	depends on X86_64 &amp;&amp; !DEBUG_PAGEALLOC</span>
<span class="quote">&gt; 	---help---</span>
<span class="quote">&gt; 	  Certain kernel features effectively disable kernel</span>
<span class="quote">&gt; 	  linear 1 GB mappings (even if the CPU otherwise</span>
<span class="quote">&gt;diff --git a/arch/x86/Makefile b/arch/x86/Makefile</span>
<span class="quote">&gt;index 6276572259c8..559eb0a282fd 100644</span>
<span class="quote">&gt;--- a/arch/x86/Makefile</span>
<span class="quote">&gt;+++ b/arch/x86/Makefile</span>
<span class="quote">&gt;@@ -157,11 +157,6 @@ ifdef CONFIG_X86_X32</span>
<span class="quote">&gt; endif</span>
<span class="quote">&gt; export CONFIG_X86_X32_ABI</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;-# Don&#39;t unroll struct assignments with kmemcheck enabled</span>
<span class="quote">&gt;-ifeq ($(CONFIG_KMEMCHECK),y)</span>
<span class="quote">&gt;-	KBUILD_CFLAGS += $(call cc-option,-fno-builtin-memcpy)</span>
<span class="quote">&gt;-endif</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt; #</span>
<span class="quote">&gt; # If the function graph tracer is used with mcount instead of fentry,</span>
<span class="quote">&gt; # &#39;-maccumulate-outgoing-args&#39; is needed to prevent a GCC bug</span>
<span class="quote">&gt;diff --git a/arch/x86/include/asm/dma-mapping.h b/arch/x86/include/asm/dma-mapping.h</span>
<span class="quote">&gt;index 1387dafdba2d..bd974c04c9aa 100644</span>
<span class="quote">&gt;--- a/arch/x86/include/asm/dma-mapping.h</span>
<span class="quote">&gt;+++ b/arch/x86/include/asm/dma-mapping.h</span>
<span class="quote">&gt;@@ -6,7 +6,6 @@</span>
<span class="quote">&gt;  * Documentation/DMA-API.txt for documentation.</span>
<span class="quote">&gt;  */</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;-#include &lt;linux/kmemcheck.h&gt;</span>
<span class="quote">&gt; #include &lt;linux/scatterlist.h&gt;</span>
<span class="quote">&gt; #include &lt;linux/dma-debug.h&gt;</span>
<span class="quote">&gt; #include &lt;asm/io.h&gt;</span>
<span class="quote">&gt;diff --git a/arch/x86/include/asm/kmemcheck.h b/arch/x86/include/asm/kmemcheck.h</span>
<span class="quote">&gt;deleted file mode 100644</span>
<span class="quote">&gt;index ed01518f297e..000000000000</span>
<span class="quote">&gt;--- a/arch/x86/include/asm/kmemcheck.h</span>
<span class="quote">&gt;+++ /dev/null</span>
<span class="quote">&gt;@@ -1,42 +0,0 @@</span>
<span class="quote">&gt;-#ifndef ASM_X86_KMEMCHECK_H</span>
<span class="quote">&gt;-#define ASM_X86_KMEMCHECK_H</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-#include &lt;linux/types.h&gt;</span>
<span class="quote">&gt;-#include &lt;asm/ptrace.h&gt;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-#ifdef CONFIG_KMEMCHECK</span>
<span class="quote">&gt;-bool kmemcheck_active(struct pt_regs *regs);</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-void kmemcheck_show(struct pt_regs *regs);</span>
<span class="quote">&gt;-void kmemcheck_hide(struct pt_regs *regs);</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-bool kmemcheck_fault(struct pt_regs *regs,</span>
<span class="quote">&gt;-	unsigned long address, unsigned long error_code);</span>
<span class="quote">&gt;-bool kmemcheck_trap(struct pt_regs *regs);</span>
<span class="quote">&gt;-#else</span>
<span class="quote">&gt;-static inline bool kmemcheck_active(struct pt_regs *regs)</span>
<span class="quote">&gt;-{</span>
<span class="quote">&gt;-	return false;</span>
<span class="quote">&gt;-}</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-static inline void kmemcheck_show(struct pt_regs *regs)</span>
<span class="quote">&gt;-{</span>
<span class="quote">&gt;-}</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-static inline void kmemcheck_hide(struct pt_regs *regs)</span>
<span class="quote">&gt;-{</span>
<span class="quote">&gt;-}</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-static inline bool kmemcheck_fault(struct pt_regs *regs,</span>
<span class="quote">&gt;-	unsigned long address, unsigned long error_code)</span>
<span class="quote">&gt;-{</span>
<span class="quote">&gt;-	return false;</span>
<span class="quote">&gt;-}</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-static inline bool kmemcheck_trap(struct pt_regs *regs)</span>
<span class="quote">&gt;-{</span>
<span class="quote">&gt;-	return false;</span>
<span class="quote">&gt;-}</span>
<span class="quote">&gt;-#endif /* CONFIG_KMEMCHECK */</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-#endif</span>
<span class="quote">&gt;diff --git a/arch/x86/include/asm/pgtable.h b/arch/x86/include/asm/pgtable.h</span>
<span class="quote">&gt;index b714934512b3..d110e38893d1 100644</span>
<span class="quote">&gt;--- a/arch/x86/include/asm/pgtable.h</span>
<span class="quote">&gt;+++ b/arch/x86/include/asm/pgtable.h</span>
<span class="quote">&gt;@@ -666,11 +666,6 @@ static inline bool pte_accessible(struct mm_struct *mm, pte_t a)</span>
<span class="quote">&gt; 	return false;</span>
<span class="quote">&gt; }</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;-static inline int pte_hidden(pte_t pte)</span>
<span class="quote">&gt;-{</span>
<span class="quote">&gt;-	return pte_flags(pte) &amp; _PAGE_HIDDEN;</span>
<span class="quote">&gt;-}</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt; static inline int pmd_present(pmd_t pmd)</span>
<span class="quote">&gt; {</span>
<span class="quote">&gt; 	/*</span>
<span class="quote">&gt;diff --git a/arch/x86/include/asm/pgtable_types.h b/arch/x86/include/asm/pgtable_types.h</span>
<span class="quote">&gt;index f1492473f10e..27e230dec7a4 100644</span>
<span class="quote">&gt;--- a/arch/x86/include/asm/pgtable_types.h</span>
<span class="quote">&gt;+++ b/arch/x86/include/asm/pgtable_types.h</span>
<span class="quote">&gt;@@ -31,7 +31,6 @@</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; #define _PAGE_BIT_SPECIAL	_PAGE_BIT_SOFTW1</span>
<span class="quote">&gt; #define _PAGE_BIT_CPA_TEST	_PAGE_BIT_SOFTW1</span>
<span class="quote">&gt;-#define _PAGE_BIT_HIDDEN	_PAGE_BIT_SOFTW3 /* hidden by kmemcheck */</span>
<span class="quote">&gt; #define _PAGE_BIT_SOFT_DIRTY	_PAGE_BIT_SOFTW3 /* software dirty tracking */</span>
<span class="quote">&gt; #define _PAGE_BIT_DEVMAP	_PAGE_BIT_SOFTW4</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;@@ -78,18 +77,6 @@</span>
<span class="quote">&gt; #define _PAGE_KNL_ERRATUM_MASK 0</span>
<span class="quote">&gt; #endif</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;-#ifdef CONFIG_KMEMCHECK</span>
<span class="quote">&gt;-#define _PAGE_HIDDEN	(_AT(pteval_t, 1) &lt;&lt; _PAGE_BIT_HIDDEN)</span>
<span class="quote">&gt;-#else</span>
<span class="quote">&gt;-#define _PAGE_HIDDEN	(_AT(pteval_t, 0))</span>
<span class="quote">&gt;-#endif</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-/*</span>
<span class="quote">&gt;- * The same hidden bit is used by kmemcheck, but since kmemcheck</span>
<span class="quote">&gt;- * works on kernel pages while soft-dirty engine on user space,</span>
<span class="quote">&gt;- * they do not conflict with each other.</span>
<span class="quote">&gt;- */</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt; #ifdef CONFIG_MEM_SOFT_DIRTY</span>
<span class="quote">&gt; #define _PAGE_SOFT_DIRTY	(_AT(pteval_t, 1) &lt;&lt; _PAGE_BIT_SOFT_DIRTY)</span>
<span class="quote">&gt; #else</span>
<span class="quote">&gt;diff --git a/arch/x86/include/asm/string_32.h b/arch/x86/include/asm/string_32.h</span>
<span class="quote">&gt;index e371e7229042..00a4429ac12c 100644</span>
<span class="quote">&gt;--- a/arch/x86/include/asm/string_32.h</span>
<span class="quote">&gt;+++ b/arch/x86/include/asm/string_32.h</span>
<span class="quote">&gt;@@ -178,8 +178,6 @@ static inline void *__memcpy3d(void *to, const void *from, size_t len)</span>
<span class="quote">&gt;  *	No 3D Now!</span>
<span class="quote">&gt;  */</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;-#ifndef CONFIG_KMEMCHECK</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt; #if (__GNUC__ &gt;= 4)</span>
<span class="quote">&gt; #define memcpy(t, f, n) __builtin_memcpy(t, f, n)</span>
<span class="quote">&gt; #else</span>
<span class="quote">&gt;@@ -188,13 +186,6 @@ static inline void *__memcpy3d(void *to, const void *from, size_t len)</span>
<span class="quote">&gt; 	 ? __constant_memcpy((t), (f), (n))	\</span>
<span class="quote">&gt; 	 : __memcpy((t), (f), (n)))</span>
<span class="quote">&gt; #endif</span>
<span class="quote">&gt;-#else</span>
<span class="quote">&gt;-/*</span>
<span class="quote">&gt;- * kmemcheck becomes very happy if we use the REP instructions unconditionally,</span>
<span class="quote">&gt;- * because it means that we know both memory operands in advance.</span>
<span class="quote">&gt;- */</span>
<span class="quote">&gt;-#define memcpy(t, f, n) __memcpy((t), (f), (n))</span>
<span class="quote">&gt;-#endif</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; #endif</span>
<span class="quote">&gt; #endif /* !CONFIG_FORTIFY_SOURCE */</span>
<span class="quote">&gt;diff --git a/arch/x86/include/asm/string_64.h b/arch/x86/include/asm/string_64.h</span>
<span class="quote">&gt;index f372a70a523f..08071875881d 100644</span>
<span class="quote">&gt;--- a/arch/x86/include/asm/string_64.h</span>
<span class="quote">&gt;+++ b/arch/x86/include/asm/string_64.h</span>
<span class="quote">&gt;@@ -32,7 +32,6 @@ extern void *memcpy(void *to, const void *from, size_t len);</span>
<span class="quote">&gt; extern void *__memcpy(void *to, const void *from, size_t len);</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; #ifndef CONFIG_FORTIFY_SOURCE</span>
<span class="quote">&gt;-#ifndef CONFIG_KMEMCHECK</span>
<span class="quote">&gt; #if (__GNUC__ == 4 &amp;&amp; __GNUC_MINOR__ &lt; 3) || __GNUC__ &lt; 4</span>
<span class="quote">&gt; #define memcpy(dst, src, len)					\</span>
<span class="quote">&gt; ({								\</span>
<span class="quote">&gt;@@ -45,13 +44,6 @@ extern void *__memcpy(void *to, const void *from, size_t len);</span>
<span class="quote">&gt; 	__ret;							\</span>
<span class="quote">&gt; })</span>
<span class="quote">&gt; #endif</span>
<span class="quote">&gt;-#else</span>
<span class="quote">&gt;-/*</span>
<span class="quote">&gt;- * kmemcheck becomes very happy if we use the REP instructions unconditionally,</span>
<span class="quote">&gt;- * because it means that we know both memory operands in advance.</span>
<span class="quote">&gt;- */</span>
<span class="quote">&gt;-#define memcpy(dst, src, len) __inline_memcpy((dst), (src), (len))</span>
<span class="quote">&gt;-#endif</span>
<span class="quote">&gt; #endif /* !CONFIG_FORTIFY_SOURCE */</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; #define __HAVE_ARCH_MEMSET</span>
<span class="quote">&gt;diff --git a/arch/x86/include/asm/xor.h b/arch/x86/include/asm/xor.h</span>
<span class="quote">&gt;index 1f5c5161ead6..3d58e95fe74c 100644</span>
<span class="quote">&gt;--- a/arch/x86/include/asm/xor.h</span>
<span class="quote">&gt;+++ b/arch/x86/include/asm/xor.h</span>
<span class="quote">&gt;@@ -1,7 +1,5 @@</span>
<span class="quote">&gt;-#ifdef CONFIG_KMEMCHECK</span>
<span class="quote">&gt;-/* kmemcheck doesn&#39;t handle MMX/SSE/SSE2 instructions */</span>
<span class="quote">&gt; # include &lt;asm-generic/xor.h&gt;</span>
<span class="quote">&gt;-#elif !defined(_ASM_X86_XOR_H)</span>
<span class="quote">&gt;+#if !defined(_ASM_X86_XOR_H)</span>
<span class="quote">&gt; #define _ASM_X86_XOR_H</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; /*</span>
<span class="quote">&gt;diff --git a/arch/x86/kernel/cpu/intel.c b/arch/x86/kernel/cpu/intel.c</span>
<span class="quote">&gt;index dfa90a3a5145..873ca226d0ce 100644</span>
<span class="quote">&gt;--- a/arch/x86/kernel/cpu/intel.c</span>
<span class="quote">&gt;+++ b/arch/x86/kernel/cpu/intel.c</span>
<span class="quote">&gt;@@ -186,21 +186,6 @@ static void early_init_intel(struct cpuinfo_x86 *c)</span>
<span class="quote">&gt; 	if (c-&gt;x86 == 6 &amp;&amp; c-&gt;x86_model &lt; 15)</span>
<span class="quote">&gt; 		clear_cpu_cap(c, X86_FEATURE_PAT);</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;-#ifdef CONFIG_KMEMCHECK</span>
<span class="quote">&gt;-	/*</span>
<span class="quote">&gt;-	 * P4s have a &quot;fast strings&quot; feature which causes single-</span>
<span class="quote">&gt;-	 * stepping REP instructions to only generate a #DB on</span>
<span class="quote">&gt;-	 * cache-line boundaries.</span>
<span class="quote">&gt;-	 *</span>
<span class="quote">&gt;-	 * Ingo Molnar reported a Pentium D (model 6) and a Xeon</span>
<span class="quote">&gt;-	 * (model 2) with the same problem.</span>
<span class="quote">&gt;-	 */</span>
<span class="quote">&gt;-	if (c-&gt;x86 == 15)</span>
<span class="quote">&gt;-		if (msr_clear_bit(MSR_IA32_MISC_ENABLE,</span>
<span class="quote">&gt;-				  MSR_IA32_MISC_ENABLE_FAST_STRING_BIT) &gt; 0)</span>
<span class="quote">&gt;-			pr_info(&quot;kmemcheck: Disabling fast string operations\n&quot;);</span>
<span class="quote">&gt;-#endif</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt; 	/*</span>
<span class="quote">&gt; 	 * If fast string is not enabled in IA32_MISC_ENABLE for any reason,</span>
<span class="quote">&gt; 	 * clear the fast string and enhanced fast string CPU capabilities.</span>
<span class="quote">&gt;diff --git a/arch/x86/kernel/espfix_64.c b/arch/x86/kernel/espfix_64.c</span>
<span class="quote">&gt;index 9c4e7ba6870c..cbded50ee601 100644</span>
<span class="quote">&gt;--- a/arch/x86/kernel/espfix_64.c</span>
<span class="quote">&gt;+++ b/arch/x86/kernel/espfix_64.c</span>
<span class="quote">&gt;@@ -57,7 +57,7 @@</span>
<span class="quote">&gt; # error &quot;Need more virtual address space for the ESPFIX hack&quot;</span>
<span class="quote">&gt; #endif</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;-#define PGALLOC_GFP (GFP_KERNEL | __GFP_NOTRACK | __GFP_ZERO)</span>
<span class="quote">&gt;+#define PGALLOC_GFP (GFP_KERNEL | __GFP_ZERO)</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; /* This contains the *bottom* address of the espfix stack */</span>
<span class="quote">&gt; DEFINE_PER_CPU_READ_MOSTLY(unsigned long, espfix_stack);</span>
<span class="quote">&gt;diff --git a/arch/x86/kernel/traps.c b/arch/x86/kernel/traps.c</span>
<span class="quote">&gt;index 34ea3651362e..869e6e0612f5 100644</span>
<span class="quote">&gt;--- a/arch/x86/kernel/traps.c</span>
<span class="quote">&gt;+++ b/arch/x86/kernel/traps.c</span>
<span class="quote">&gt;@@ -42,7 +42,6 @@</span>
<span class="quote">&gt; #include &lt;linux/edac.h&gt;</span>
<span class="quote">&gt; #endif</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;-#include &lt;asm/kmemcheck.h&gt;</span>
<span class="quote">&gt; #include &lt;asm/stacktrace.h&gt;</span>
<span class="quote">&gt; #include &lt;asm/processor.h&gt;</span>
<span class="quote">&gt; #include &lt;asm/debugreg.h&gt;</span>
<span class="quote">&gt;@@ -740,10 +739,6 @@ dotraplinkage void do_debug(struct pt_regs *regs, long error_code)</span>
<span class="quote">&gt; 	if (!dr6 &amp;&amp; user_mode(regs))</span>
<span class="quote">&gt; 		user_icebp = 1;</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;-	/* Catch kmemcheck conditions! */</span>
<span class="quote">&gt;-	if ((dr6 &amp; DR_STEP) &amp;&amp; kmemcheck_trap(regs))</span>
<span class="quote">&gt;-		goto exit;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt; 	/* Store the virtualized DR6 value */</span>
<span class="quote">&gt; 	tsk-&gt;thread.debugreg6 = dr6;</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;diff --git a/arch/x86/mm/Makefile b/arch/x86/mm/Makefile</span>
<span class="quote">&gt;index 72bf8c01c6e3..08042cf4a1db 100644</span>
<span class="quote">&gt;--- a/arch/x86/mm/Makefile</span>
<span class="quote">&gt;+++ b/arch/x86/mm/Makefile</span>
<span class="quote">&gt;@@ -21,8 +21,6 @@ obj-$(CONFIG_X86_PTDUMP)	+= debug_pagetables.o</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; obj-$(CONFIG_HIGHMEM)		+= highmem_32.o</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;-obj-$(CONFIG_KMEMCHECK)		+= kmemcheck/</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt; KASAN_SANITIZE_kasan_init_$(BITS).o := n</span>
<span class="quote">&gt; obj-$(CONFIG_KASAN)		+= kasan_init_$(BITS).o</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;diff --git a/arch/x86/mm/fault.c b/arch/x86/mm/fault.c</span>
<span class="quote">&gt;index 39567b5c33da..5452f2a55586 100644</span>
<span class="quote">&gt;--- a/arch/x86/mm/fault.c</span>
<span class="quote">&gt;+++ b/arch/x86/mm/fault.c</span>
<span class="quote">&gt;@@ -19,7 +19,6 @@</span>
<span class="quote">&gt; #include &lt;asm/cpufeature.h&gt;		/* boot_cpu_has, ...		*/</span>
<span class="quote">&gt; #include &lt;asm/traps.h&gt;			/* dotraplinkage, ...		*/</span>
<span class="quote">&gt; #include &lt;asm/pgalloc.h&gt;		/* pgd_*(), ...			*/</span>
<span class="quote">&gt;-#include &lt;asm/kmemcheck.h&gt;		/* kmemcheck_*(), ...		*/</span>
<span class="quote">&gt; #include &lt;asm/fixmap.h&gt;			/* VSYSCALL_ADDR		*/</span>
<span class="quote">&gt; #include &lt;asm/vsyscall.h&gt;		/* emulate_vsyscall		*/</span>
<span class="quote">&gt; #include &lt;asm/vm86.h&gt;			/* struct vm86			*/</span>
<span class="quote">&gt;@@ -1275,8 +1274,6 @@ __do_page_fault(struct pt_regs *regs, unsigned long error_code,</span>
<span class="quote">&gt; 	 * Detect and handle instructions that would cause a page fault for</span>
<span class="quote">&gt; 	 * both a tracked kernel page and a userspace page.</span>
<span class="quote">&gt; 	 */</span>
<span class="quote">&gt;-	if (kmemcheck_active(regs))</span>
<span class="quote">&gt;-		kmemcheck_hide(regs);</span>
<span class="quote">&gt; 	prefetchw(&amp;mm-&gt;mmap_sem);</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; 	if (unlikely(kmmio_fault(regs, address)))</span>
<span class="quote">&gt;@@ -1299,9 +1296,6 @@ __do_page_fault(struct pt_regs *regs, unsigned long error_code,</span>
<span class="quote">&gt; 		if (!(error_code &amp; (PF_RSVD | PF_USER | PF_PROT))) {</span>
<span class="quote">&gt; 			if (vmalloc_fault(address) &gt;= 0)</span>
<span class="quote">&gt; 				return;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-			if (kmemcheck_fault(regs, address, error_code))</span>
<span class="quote">&gt;-				return;</span>
<span class="quote">&gt; 		}</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; 		/* Can handle a stale RO-&gt;RW TLB: */</span>
<span class="quote">&gt;diff --git a/arch/x86/mm/init.c b/arch/x86/mm/init.c</span>
<span class="quote">&gt;index af5c1ed21d43..8b3fd7e8eb50 100644</span>
<span class="quote">&gt;--- a/arch/x86/mm/init.c</span>
<span class="quote">&gt;+++ b/arch/x86/mm/init.c</span>
<span class="quote">&gt;@@ -92,8 +92,7 @@ __ref void *alloc_low_pages(unsigned int num)</span>
<span class="quote">&gt; 		unsigned int order;</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; 		order = get_order((unsigned long)num &lt;&lt; PAGE_SHIFT);</span>
<span class="quote">&gt;-		return (void *)__get_free_pages(GFP_ATOMIC | __GFP_NOTRACK |</span>
<span class="quote">&gt;-						__GFP_ZERO, order);</span>
<span class="quote">&gt;+		return (void *)__get_free_pages(GFP_ATOMIC | __GFP_ZERO, order);</span>
<span class="quote">&gt; 	}</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; 	if ((pgt_buf_end + num) &gt; pgt_buf_top || !can_use_brk_pgt) {</span>
<span class="quote">&gt;@@ -164,12 +163,11 @@ static int page_size_mask;</span>
<span class="quote">&gt; static void __init probe_page_size_mask(void)</span>
<span class="quote">&gt; {</span>
<span class="quote">&gt; 	/*</span>
<span class="quote">&gt;-	 * For CONFIG_KMEMCHECK or pagealloc debugging, identity mapping will</span>
<span class="quote">&gt;-	 * use small pages.</span>
<span class="quote">&gt;+	 * For pagealloc debugging, identity mapping will use small pages.</span>
<span class="quote">&gt; 	 * This will simplify cpa(), which otherwise needs to support splitting</span>
<span class="quote">&gt; 	 * large pages into small in interrupt context, etc.</span>
<span class="quote">&gt; 	 */</span>
<span class="quote">&gt;-	if (boot_cpu_has(X86_FEATURE_PSE) &amp;&amp; !debug_pagealloc_enabled() &amp;&amp; !IS_ENABLED(CONFIG_KMEMCHECK))</span>
<span class="quote">&gt;+	if (boot_cpu_has(X86_FEATURE_PSE) &amp;&amp; !debug_pagealloc_enabled())</span>
<span class="quote">&gt; 		page_size_mask |= 1 &lt;&lt; PG_LEVEL_2M;</span>
<span class="quote">&gt; 	else</span>
<span class="quote">&gt; 		direct_gbpages = 0;</span>
<span class="quote">&gt;diff --git a/arch/x86/mm/init_64.c b/arch/x86/mm/init_64.c</span>
<span class="quote">&gt;index 048fbe8fc274..3f7ca42d1e22 100644</span>
<span class="quote">&gt;--- a/arch/x86/mm/init_64.c</span>
<span class="quote">&gt;+++ b/arch/x86/mm/init_64.c</span>
<span class="quote">&gt;@@ -184,7 +184,7 @@ static __ref void *spp_getpage(void)</span>
<span class="quote">&gt; 	void *ptr;</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; 	if (after_bootmem)</span>
<span class="quote">&gt;-		ptr = (void *) get_zeroed_page(GFP_ATOMIC | __GFP_NOTRACK);</span>
<span class="quote">&gt;+		ptr = (void *) get_zeroed_page(GFP_ATOMIC);</span>
<span class="quote">&gt; 	else</span>
<span class="quote">&gt; 		ptr = alloc_bootmem_pages(PAGE_SIZE);</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;diff --git a/arch/x86/mm/kmemcheck/Makefile b/arch/x86/mm/kmemcheck/Makefile</span>
<span class="quote">&gt;deleted file mode 100644</span>
<span class="quote">&gt;index 520b3bce4095..000000000000</span>
<span class="quote">&gt;--- a/arch/x86/mm/kmemcheck/Makefile</span>
<span class="quote">&gt;+++ /dev/null</span>
<span class="quote">&gt;@@ -1 +0,0 @@</span>
<span class="quote">&gt;-obj-y := error.o kmemcheck.o opcode.o pte.o selftest.o shadow.o</span>
<span class="quote">&gt;diff --git a/arch/x86/mm/kmemcheck/error.c b/arch/x86/mm/kmemcheck/error.c</span>
<span class="quote">&gt;deleted file mode 100644</span>
<span class="quote">&gt;index dab41876cdd5..000000000000</span>
<span class="quote">&gt;--- a/arch/x86/mm/kmemcheck/error.c</span>
<span class="quote">&gt;+++ /dev/null</span>
<span class="quote">&gt;@@ -1,227 +0,0 @@</span>
<span class="quote">&gt;-#include &lt;linux/interrupt.h&gt;</span>
<span class="quote">&gt;-#include &lt;linux/kdebug.h&gt;</span>
<span class="quote">&gt;-#include &lt;linux/kmemcheck.h&gt;</span>
<span class="quote">&gt;-#include &lt;linux/kernel.h&gt;</span>
<span class="quote">&gt;-#include &lt;linux/types.h&gt;</span>
<span class="quote">&gt;-#include &lt;linux/ptrace.h&gt;</span>
<span class="quote">&gt;-#include &lt;linux/stacktrace.h&gt;</span>
<span class="quote">&gt;-#include &lt;linux/string.h&gt;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-#include &quot;error.h&quot;</span>
<span class="quote">&gt;-#include &quot;shadow.h&quot;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-enum kmemcheck_error_type {</span>
<span class="quote">&gt;-	KMEMCHECK_ERROR_INVALID_ACCESS,</span>
<span class="quote">&gt;-	KMEMCHECK_ERROR_BUG,</span>
<span class="quote">&gt;-};</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-#define SHADOW_COPY_SIZE (1 &lt;&lt; CONFIG_KMEMCHECK_SHADOW_COPY_SHIFT)</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-struct kmemcheck_error {</span>
<span class="quote">&gt;-	enum kmemcheck_error_type type;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	union {</span>
<span class="quote">&gt;-		/* KMEMCHECK_ERROR_INVALID_ACCESS */</span>
<span class="quote">&gt;-		struct {</span>
<span class="quote">&gt;-			/* Kind of access that caused the error */</span>
<span class="quote">&gt;-			enum kmemcheck_shadow state;</span>
<span class="quote">&gt;-			/* Address and size of the erroneous read */</span>
<span class="quote">&gt;-			unsigned long	address;</span>
<span class="quote">&gt;-			unsigned int	size;</span>
<span class="quote">&gt;-		};</span>
<span class="quote">&gt;-	};</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	struct pt_regs		regs;</span>
<span class="quote">&gt;-	struct stack_trace	trace;</span>
<span class="quote">&gt;-	unsigned long		trace_entries[32];</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	/* We compress it to a char. */</span>
<span class="quote">&gt;-	unsigned char		shadow_copy[SHADOW_COPY_SIZE];</span>
<span class="quote">&gt;-	unsigned char		memory_copy[SHADOW_COPY_SIZE];</span>
<span class="quote">&gt;-};</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-/*</span>
<span class="quote">&gt;- * Create a ring queue of errors to output. We can&#39;t call printk() directly</span>
<span class="quote">&gt;- * from the kmemcheck traps, since this may call the console drivers and</span>
<span class="quote">&gt;- * result in a recursive fault.</span>
<span class="quote">&gt;- */</span>
<span class="quote">&gt;-static struct kmemcheck_error error_fifo[CONFIG_KMEMCHECK_QUEUE_SIZE];</span>
<span class="quote">&gt;-static unsigned int error_count;</span>
<span class="quote">&gt;-static unsigned int error_rd;</span>
<span class="quote">&gt;-static unsigned int error_wr;</span>
<span class="quote">&gt;-static unsigned int error_missed_count;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-static struct kmemcheck_error *error_next_wr(void)</span>
<span class="quote">&gt;-{</span>
<span class="quote">&gt;-	struct kmemcheck_error *e;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	if (error_count == ARRAY_SIZE(error_fifo)) {</span>
<span class="quote">&gt;-		++error_missed_count;</span>
<span class="quote">&gt;-		return NULL;</span>
<span class="quote">&gt;-	}</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	e = &amp;error_fifo[error_wr];</span>
<span class="quote">&gt;-	if (++error_wr == ARRAY_SIZE(error_fifo))</span>
<span class="quote">&gt;-		error_wr = 0;</span>
<span class="quote">&gt;-	++error_count;</span>
<span class="quote">&gt;-	return e;</span>
<span class="quote">&gt;-}</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-static struct kmemcheck_error *error_next_rd(void)</span>
<span class="quote">&gt;-{</span>
<span class="quote">&gt;-	struct kmemcheck_error *e;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	if (error_count == 0)</span>
<span class="quote">&gt;-		return NULL;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	e = &amp;error_fifo[error_rd];</span>
<span class="quote">&gt;-	if (++error_rd == ARRAY_SIZE(error_fifo))</span>
<span class="quote">&gt;-		error_rd = 0;</span>
<span class="quote">&gt;-	--error_count;</span>
<span class="quote">&gt;-	return e;</span>
<span class="quote">&gt;-}</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-void kmemcheck_error_recall(void)</span>
<span class="quote">&gt;-{</span>
<span class="quote">&gt;-	static const char *desc[] = {</span>
<span class="quote">&gt;-		[KMEMCHECK_SHADOW_UNALLOCATED]		= &quot;unallocated&quot;,</span>
<span class="quote">&gt;-		[KMEMCHECK_SHADOW_UNINITIALIZED]	= &quot;uninitialized&quot;,</span>
<span class="quote">&gt;-		[KMEMCHECK_SHADOW_INITIALIZED]		= &quot;initialized&quot;,</span>
<span class="quote">&gt;-		[KMEMCHECK_SHADOW_FREED]		= &quot;freed&quot;,</span>
<span class="quote">&gt;-	};</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	static const char short_desc[] = {</span>
<span class="quote">&gt;-		[KMEMCHECK_SHADOW_UNALLOCATED]		= &#39;a&#39;,</span>
<span class="quote">&gt;-		[KMEMCHECK_SHADOW_UNINITIALIZED]	= &#39;u&#39;,</span>
<span class="quote">&gt;-		[KMEMCHECK_SHADOW_INITIALIZED]		= &#39;i&#39;,</span>
<span class="quote">&gt;-		[KMEMCHECK_SHADOW_FREED]		= &#39;f&#39;,</span>
<span class="quote">&gt;-	};</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	struct kmemcheck_error *e;</span>
<span class="quote">&gt;-	unsigned int i;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	e = error_next_rd();</span>
<span class="quote">&gt;-	if (!e)</span>
<span class="quote">&gt;-		return;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	switch (e-&gt;type) {</span>
<span class="quote">&gt;-	case KMEMCHECK_ERROR_INVALID_ACCESS:</span>
<span class="quote">&gt;-		printk(KERN_WARNING &quot;WARNING: kmemcheck: Caught %d-bit read from %s memory (%p)\n&quot;,</span>
<span class="quote">&gt;-			8 * e-&gt;size, e-&gt;state &lt; ARRAY_SIZE(desc) ?</span>
<span class="quote">&gt;-				desc[e-&gt;state] : &quot;(invalid shadow state)&quot;,</span>
<span class="quote">&gt;-			(void *) e-&gt;address);</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-		printk(KERN_WARNING);</span>
<span class="quote">&gt;-		for (i = 0; i &lt; SHADOW_COPY_SIZE; ++i)</span>
<span class="quote">&gt;-			printk(KERN_CONT &quot;%02x&quot;, e-&gt;memory_copy[i]);</span>
<span class="quote">&gt;-		printk(KERN_CONT &quot;\n&quot;);</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-		printk(KERN_WARNING);</span>
<span class="quote">&gt;-		for (i = 0; i &lt; SHADOW_COPY_SIZE; ++i) {</span>
<span class="quote">&gt;-			if (e-&gt;shadow_copy[i] &lt; ARRAY_SIZE(short_desc))</span>
<span class="quote">&gt;-				printk(KERN_CONT &quot; %c&quot;, short_desc[e-&gt;shadow_copy[i]]);</span>
<span class="quote">&gt;-			else</span>
<span class="quote">&gt;-				printk(KERN_CONT &quot; ?&quot;);</span>
<span class="quote">&gt;-		}</span>
<span class="quote">&gt;-		printk(KERN_CONT &quot;\n&quot;);</span>
<span class="quote">&gt;-		printk(KERN_WARNING &quot;%*c\n&quot;, 2 + 2</span>
<span class="quote">&gt;-			* (int) (e-&gt;address &amp; (SHADOW_COPY_SIZE - 1)), &#39;^&#39;);</span>
<span class="quote">&gt;-		break;</span>
<span class="quote">&gt;-	case KMEMCHECK_ERROR_BUG:</span>
<span class="quote">&gt;-		printk(KERN_EMERG &quot;ERROR: kmemcheck: Fatal error\n&quot;);</span>
<span class="quote">&gt;-		break;</span>
<span class="quote">&gt;-	}</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	__show_regs(&amp;e-&gt;regs, 1);</span>
<span class="quote">&gt;-	print_stack_trace(&amp;e-&gt;trace, 0);</span>
<span class="quote">&gt;-}</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-static void do_wakeup(unsigned long data)</span>
<span class="quote">&gt;-{</span>
<span class="quote">&gt;-	while (error_count &gt; 0)</span>
<span class="quote">&gt;-		kmemcheck_error_recall();</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	if (error_missed_count &gt; 0) {</span>
<span class="quote">&gt;-		printk(KERN_WARNING &quot;kmemcheck: Lost %d error reports because &quot;</span>
<span class="quote">&gt;-			&quot;the queue was too small\n&quot;, error_missed_count);</span>
<span class="quote">&gt;-		error_missed_count = 0;</span>
<span class="quote">&gt;-	}</span>
<span class="quote">&gt;-}</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-static DECLARE_TASKLET(kmemcheck_tasklet, &amp;do_wakeup, 0);</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-/*</span>
<span class="quote">&gt;- * Save the context of an error report.</span>
<span class="quote">&gt;- */</span>
<span class="quote">&gt;-void kmemcheck_error_save(enum kmemcheck_shadow state,</span>
<span class="quote">&gt;-	unsigned long address, unsigned int size, struct pt_regs *regs)</span>
<span class="quote">&gt;-{</span>
<span class="quote">&gt;-	static unsigned long prev_ip;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	struct kmemcheck_error *e;</span>
<span class="quote">&gt;-	void *shadow_copy;</span>
<span class="quote">&gt;-	void *memory_copy;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	/* Don&#39;t report several adjacent errors from the same EIP. */</span>
<span class="quote">&gt;-	if (regs-&gt;ip == prev_ip)</span>
<span class="quote">&gt;-		return;</span>
<span class="quote">&gt;-	prev_ip = regs-&gt;ip;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	e = error_next_wr();</span>
<span class="quote">&gt;-	if (!e)</span>
<span class="quote">&gt;-		return;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	e-&gt;type = KMEMCHECK_ERROR_INVALID_ACCESS;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	e-&gt;state = state;</span>
<span class="quote">&gt;-	e-&gt;address = address;</span>
<span class="quote">&gt;-	e-&gt;size = size;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	/* Save regs */</span>
<span class="quote">&gt;-	memcpy(&amp;e-&gt;regs, regs, sizeof(*regs));</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	/* Save stack trace */</span>
<span class="quote">&gt;-	e-&gt;trace.nr_entries = 0;</span>
<span class="quote">&gt;-	e-&gt;trace.entries = e-&gt;trace_entries;</span>
<span class="quote">&gt;-	e-&gt;trace.max_entries = ARRAY_SIZE(e-&gt;trace_entries);</span>
<span class="quote">&gt;-	e-&gt;trace.skip = 0;</span>
<span class="quote">&gt;-	save_stack_trace_regs(regs, &amp;e-&gt;trace);</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	/* Round address down to nearest 16 bytes */</span>
<span class="quote">&gt;-	shadow_copy = kmemcheck_shadow_lookup(address</span>
<span class="quote">&gt;-		&amp; ~(SHADOW_COPY_SIZE - 1));</span>
<span class="quote">&gt;-	BUG_ON(!shadow_copy);</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	memcpy(e-&gt;shadow_copy, shadow_copy, SHADOW_COPY_SIZE);</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	kmemcheck_show_addr(address);</span>
<span class="quote">&gt;-	memory_copy = (void *) (address &amp; ~(SHADOW_COPY_SIZE - 1));</span>
<span class="quote">&gt;-	memcpy(e-&gt;memory_copy, memory_copy, SHADOW_COPY_SIZE);</span>
<span class="quote">&gt;-	kmemcheck_hide_addr(address);</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	tasklet_hi_schedule_first(&amp;kmemcheck_tasklet);</span>
<span class="quote">&gt;-}</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-/*</span>
<span class="quote">&gt;- * Save the context of a kmemcheck bug.</span>
<span class="quote">&gt;- */</span>
<span class="quote">&gt;-void kmemcheck_error_save_bug(struct pt_regs *regs)</span>
<span class="quote">&gt;-{</span>
<span class="quote">&gt;-	struct kmemcheck_error *e;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	e = error_next_wr();</span>
<span class="quote">&gt;-	if (!e)</span>
<span class="quote">&gt;-		return;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	e-&gt;type = KMEMCHECK_ERROR_BUG;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	memcpy(&amp;e-&gt;regs, regs, sizeof(*regs));</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	e-&gt;trace.nr_entries = 0;</span>
<span class="quote">&gt;-	e-&gt;trace.entries = e-&gt;trace_entries;</span>
<span class="quote">&gt;-	e-&gt;trace.max_entries = ARRAY_SIZE(e-&gt;trace_entries);</span>
<span class="quote">&gt;-	e-&gt;trace.skip = 1;</span>
<span class="quote">&gt;-	save_stack_trace(&amp;e-&gt;trace);</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	tasklet_hi_schedule_first(&amp;kmemcheck_tasklet);</span>
<span class="quote">&gt;-}</span>
<span class="quote">&gt;diff --git a/arch/x86/mm/kmemcheck/error.h b/arch/x86/mm/kmemcheck/error.h</span>
<span class="quote">&gt;deleted file mode 100644</span>
<span class="quote">&gt;index 0efc2e8d0a20..000000000000</span>
<span class="quote">&gt;--- a/arch/x86/mm/kmemcheck/error.h</span>
<span class="quote">&gt;+++ /dev/null</span>
<span class="quote">&gt;@@ -1,15 +0,0 @@</span>
<span class="quote">&gt;-#ifndef ARCH__X86__MM__KMEMCHECK__ERROR_H</span>
<span class="quote">&gt;-#define ARCH__X86__MM__KMEMCHECK__ERROR_H</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-#include &lt;linux/ptrace.h&gt;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-#include &quot;shadow.h&quot;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-void kmemcheck_error_save(enum kmemcheck_shadow state,</span>
<span class="quote">&gt;-	unsigned long address, unsigned int size, struct pt_regs *regs);</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-void kmemcheck_error_save_bug(struct pt_regs *regs);</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-void kmemcheck_error_recall(void);</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-#endif</span>
<span class="quote">&gt;diff --git a/arch/x86/mm/kmemcheck/kmemcheck.c b/arch/x86/mm/kmemcheck/kmemcheck.c</span>
<span class="quote">&gt;deleted file mode 100644</span>
<span class="quote">&gt;index 4515bae36bbe..000000000000</span>
<span class="quote">&gt;--- a/arch/x86/mm/kmemcheck/kmemcheck.c</span>
<span class="quote">&gt;+++ /dev/null</span>
<span class="quote">&gt;@@ -1,658 +0,0 @@</span>
<span class="quote">&gt;-/**</span>
<span class="quote">&gt;- * kmemcheck - a heavyweight memory checker for the linux kernel</span>
<span class="quote">&gt;- * Copyright (C) 2007, 2008  Vegard Nossum &lt;vegardno@ifi.uio.no&gt;</span>
<span class="quote">&gt;- * (With a lot of help from Ingo Molnar and Pekka Enberg.)</span>
<span class="quote">&gt;- *</span>
<span class="quote">&gt;- * This program is free software; you can redistribute it and/or modify</span>
<span class="quote">&gt;- * it under the terms of the GNU General Public License (version 2) as</span>
<span class="quote">&gt;- * published by the Free Software Foundation.</span>
<span class="quote">&gt;- */</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-#include &lt;linux/init.h&gt;</span>
<span class="quote">&gt;-#include &lt;linux/interrupt.h&gt;</span>
<span class="quote">&gt;-#include &lt;linux/kallsyms.h&gt;</span>
<span class="quote">&gt;-#include &lt;linux/kernel.h&gt;</span>
<span class="quote">&gt;-#include &lt;linux/kmemcheck.h&gt;</span>
<span class="quote">&gt;-#include &lt;linux/mm.h&gt;</span>
<span class="quote">&gt;-#include &lt;linux/page-flags.h&gt;</span>
<span class="quote">&gt;-#include &lt;linux/percpu.h&gt;</span>
<span class="quote">&gt;-#include &lt;linux/ptrace.h&gt;</span>
<span class="quote">&gt;-#include &lt;linux/string.h&gt;</span>
<span class="quote">&gt;-#include &lt;linux/types.h&gt;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-#include &lt;asm/cacheflush.h&gt;</span>
<span class="quote">&gt;-#include &lt;asm/kmemcheck.h&gt;</span>
<span class="quote">&gt;-#include &lt;asm/pgtable.h&gt;</span>
<span class="quote">&gt;-#include &lt;asm/tlbflush.h&gt;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-#include &quot;error.h&quot;</span>
<span class="quote">&gt;-#include &quot;opcode.h&quot;</span>
<span class="quote">&gt;-#include &quot;pte.h&quot;</span>
<span class="quote">&gt;-#include &quot;selftest.h&quot;</span>
<span class="quote">&gt;-#include &quot;shadow.h&quot;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-#ifdef CONFIG_KMEMCHECK_DISABLED_BY_DEFAULT</span>
<span class="quote">&gt;-#  define KMEMCHECK_ENABLED 0</span>
<span class="quote">&gt;-#endif</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-#ifdef CONFIG_KMEMCHECK_ENABLED_BY_DEFAULT</span>
<span class="quote">&gt;-#  define KMEMCHECK_ENABLED 1</span>
<span class="quote">&gt;-#endif</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-#ifdef CONFIG_KMEMCHECK_ONESHOT_BY_DEFAULT</span>
<span class="quote">&gt;-#  define KMEMCHECK_ENABLED 2</span>
<span class="quote">&gt;-#endif</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-int kmemcheck_enabled = KMEMCHECK_ENABLED;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-int __init kmemcheck_init(void)</span>
<span class="quote">&gt;-{</span>
<span class="quote">&gt;-#ifdef CONFIG_SMP</span>
<span class="quote">&gt;-	/*</span>
<span class="quote">&gt;-	 * Limit SMP to use a single CPU. We rely on the fact that this code</span>
<span class="quote">&gt;-	 * runs before SMP is set up.</span>
<span class="quote">&gt;-	 */</span>
<span class="quote">&gt;-	if (setup_max_cpus &gt; 1) {</span>
<span class="quote">&gt;-		printk(KERN_INFO</span>
<span class="quote">&gt;-			&quot;kmemcheck: Limiting number of CPUs to 1.\n&quot;);</span>
<span class="quote">&gt;-		setup_max_cpus = 1;</span>
<span class="quote">&gt;-	}</span>
<span class="quote">&gt;-#endif</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	if (!kmemcheck_selftest()) {</span>
<span class="quote">&gt;-		printk(KERN_INFO &quot;kmemcheck: self-tests failed; disabling\n&quot;);</span>
<span class="quote">&gt;-		kmemcheck_enabled = 0;</span>
<span class="quote">&gt;-		return -EINVAL;</span>
<span class="quote">&gt;-	}</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	printk(KERN_INFO &quot;kmemcheck: Initialized\n&quot;);</span>
<span class="quote">&gt;-	return 0;</span>
<span class="quote">&gt;-}</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-early_initcall(kmemcheck_init);</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-/*</span>
<span class="quote">&gt;- * We need to parse the kmemcheck= option before any memory is allocated.</span>
<span class="quote">&gt;- */</span>
<span class="quote">&gt;-static int __init param_kmemcheck(char *str)</span>
<span class="quote">&gt;-{</span>
<span class="quote">&gt;-	int val;</span>
<span class="quote">&gt;-	int ret;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	if (!str)</span>
<span class="quote">&gt;-		return -EINVAL;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	ret = kstrtoint(str, 0, &amp;val);</span>
<span class="quote">&gt;-	if (ret)</span>
<span class="quote">&gt;-		return ret;</span>
<span class="quote">&gt;-	kmemcheck_enabled = val;</span>
<span class="quote">&gt;-	return 0;</span>
<span class="quote">&gt;-}</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-early_param(&quot;kmemcheck&quot;, param_kmemcheck);</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-int kmemcheck_show_addr(unsigned long address)</span>
<span class="quote">&gt;-{</span>
<span class="quote">&gt;-	pte_t *pte;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	pte = kmemcheck_pte_lookup(address);</span>
<span class="quote">&gt;-	if (!pte)</span>
<span class="quote">&gt;-		return 0;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	set_pte(pte, __pte(pte_val(*pte) | _PAGE_PRESENT));</span>
<span class="quote">&gt;-	__flush_tlb_one(address);</span>
<span class="quote">&gt;-	return 1;</span>
<span class="quote">&gt;-}</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-int kmemcheck_hide_addr(unsigned long address)</span>
<span class="quote">&gt;-{</span>
<span class="quote">&gt;-	pte_t *pte;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	pte = kmemcheck_pte_lookup(address);</span>
<span class="quote">&gt;-	if (!pte)</span>
<span class="quote">&gt;-		return 0;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	set_pte(pte, __pte(pte_val(*pte) &amp; ~_PAGE_PRESENT));</span>
<span class="quote">&gt;-	__flush_tlb_one(address);</span>
<span class="quote">&gt;-	return 1;</span>
<span class="quote">&gt;-}</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-struct kmemcheck_context {</span>
<span class="quote">&gt;-	bool busy;</span>
<span class="quote">&gt;-	int balance;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	/*</span>
<span class="quote">&gt;-	 * There can be at most two memory operands to an instruction, but</span>
<span class="quote">&gt;-	 * each address can cross a page boundary -- so we may need up to</span>
<span class="quote">&gt;-	 * four addresses that must be hidden/revealed for each fault.</span>
<span class="quote">&gt;-	 */</span>
<span class="quote">&gt;-	unsigned long addr[4];</span>
<span class="quote">&gt;-	unsigned long n_addrs;</span>
<span class="quote">&gt;-	unsigned long flags;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	/* Data size of the instruction that caused a fault. */</span>
<span class="quote">&gt;-	unsigned int size;</span>
<span class="quote">&gt;-};</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-static DEFINE_PER_CPU(struct kmemcheck_context, kmemcheck_context);</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-bool kmemcheck_active(struct pt_regs *regs)</span>
<span class="quote">&gt;-{</span>
<span class="quote">&gt;-	struct kmemcheck_context *data = this_cpu_ptr(&amp;kmemcheck_context);</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	return data-&gt;balance &gt; 0;</span>
<span class="quote">&gt;-}</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-/* Save an address that needs to be shown/hidden */</span>
<span class="quote">&gt;-static void kmemcheck_save_addr(unsigned long addr)</span>
<span class="quote">&gt;-{</span>
<span class="quote">&gt;-	struct kmemcheck_context *data = this_cpu_ptr(&amp;kmemcheck_context);</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	BUG_ON(data-&gt;n_addrs &gt;= ARRAY_SIZE(data-&gt;addr));</span>
<span class="quote">&gt;-	data-&gt;addr[data-&gt;n_addrs++] = addr;</span>
<span class="quote">&gt;-}</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-static unsigned int kmemcheck_show_all(void)</span>
<span class="quote">&gt;-{</span>
<span class="quote">&gt;-	struct kmemcheck_context *data = this_cpu_ptr(&amp;kmemcheck_context);</span>
<span class="quote">&gt;-	unsigned int i;</span>
<span class="quote">&gt;-	unsigned int n;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	n = 0;</span>
<span class="quote">&gt;-	for (i = 0; i &lt; data-&gt;n_addrs; ++i)</span>
<span class="quote">&gt;-		n += kmemcheck_show_addr(data-&gt;addr[i]);</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	return n;</span>
<span class="quote">&gt;-}</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-static unsigned int kmemcheck_hide_all(void)</span>
<span class="quote">&gt;-{</span>
<span class="quote">&gt;-	struct kmemcheck_context *data = this_cpu_ptr(&amp;kmemcheck_context);</span>
<span class="quote">&gt;-	unsigned int i;</span>
<span class="quote">&gt;-	unsigned int n;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	n = 0;</span>
<span class="quote">&gt;-	for (i = 0; i &lt; data-&gt;n_addrs; ++i)</span>
<span class="quote">&gt;-		n += kmemcheck_hide_addr(data-&gt;addr[i]);</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	return n;</span>
<span class="quote">&gt;-}</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-/*</span>
<span class="quote">&gt;- * Called from the #PF handler.</span>
<span class="quote">&gt;- */</span>
<span class="quote">&gt;-void kmemcheck_show(struct pt_regs *regs)</span>
<span class="quote">&gt;-{</span>
<span class="quote">&gt;-	struct kmemcheck_context *data = this_cpu_ptr(&amp;kmemcheck_context);</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	BUG_ON(!irqs_disabled());</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	if (unlikely(data-&gt;balance != 0)) {</span>
<span class="quote">&gt;-		kmemcheck_show_all();</span>
<span class="quote">&gt;-		kmemcheck_error_save_bug(regs);</span>
<span class="quote">&gt;-		data-&gt;balance = 0;</span>
<span class="quote">&gt;-		return;</span>
<span class="quote">&gt;-	}</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	/*</span>
<span class="quote">&gt;-	 * None of the addresses actually belonged to kmemcheck. Note that</span>
<span class="quote">&gt;-	 * this is not an error.</span>
<span class="quote">&gt;-	 */</span>
<span class="quote">&gt;-	if (kmemcheck_show_all() == 0)</span>
<span class="quote">&gt;-		return;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	++data-&gt;balance;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	/*</span>
<span class="quote">&gt;-	 * The IF needs to be cleared as well, so that the faulting</span>
<span class="quote">&gt;-	 * instruction can run &quot;uninterrupted&quot;. Otherwise, we might take</span>
<span class="quote">&gt;-	 * an interrupt and start executing that before we&#39;ve had a chance</span>
<span class="quote">&gt;-	 * to hide the page again.</span>
<span class="quote">&gt;-	 *</span>
<span class="quote">&gt;-	 * NOTE: In the rare case of multiple faults, we must not override</span>
<span class="quote">&gt;-	 * the original flags:</span>
<span class="quote">&gt;-	 */</span>
<span class="quote">&gt;-	if (!(regs-&gt;flags &amp; X86_EFLAGS_TF))</span>
<span class="quote">&gt;-		data-&gt;flags = regs-&gt;flags;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	regs-&gt;flags |= X86_EFLAGS_TF;</span>
<span class="quote">&gt;-	regs-&gt;flags &amp;= ~X86_EFLAGS_IF;</span>
<span class="quote">&gt;-}</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-/*</span>
<span class="quote">&gt;- * Called from the #DB handler.</span>
<span class="quote">&gt;- */</span>
<span class="quote">&gt;-void kmemcheck_hide(struct pt_regs *regs)</span>
<span class="quote">&gt;-{</span>
<span class="quote">&gt;-	struct kmemcheck_context *data = this_cpu_ptr(&amp;kmemcheck_context);</span>
<span class="quote">&gt;-	int n;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	BUG_ON(!irqs_disabled());</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	if (unlikely(data-&gt;balance != 1)) {</span>
<span class="quote">&gt;-		kmemcheck_show_all();</span>
<span class="quote">&gt;-		kmemcheck_error_save_bug(regs);</span>
<span class="quote">&gt;-		data-&gt;n_addrs = 0;</span>
<span class="quote">&gt;-		data-&gt;balance = 0;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-		if (!(data-&gt;flags &amp; X86_EFLAGS_TF))</span>
<span class="quote">&gt;-			regs-&gt;flags &amp;= ~X86_EFLAGS_TF;</span>
<span class="quote">&gt;-		if (data-&gt;flags &amp; X86_EFLAGS_IF)</span>
<span class="quote">&gt;-			regs-&gt;flags |= X86_EFLAGS_IF;</span>
<span class="quote">&gt;-		return;</span>
<span class="quote">&gt;-	}</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	if (kmemcheck_enabled)</span>
<span class="quote">&gt;-		n = kmemcheck_hide_all();</span>
<span class="quote">&gt;-	else</span>
<span class="quote">&gt;-		n = kmemcheck_show_all();</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	if (n == 0)</span>
<span class="quote">&gt;-		return;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	--data-&gt;balance;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	data-&gt;n_addrs = 0;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	if (!(data-&gt;flags &amp; X86_EFLAGS_TF))</span>
<span class="quote">&gt;-		regs-&gt;flags &amp;= ~X86_EFLAGS_TF;</span>
<span class="quote">&gt;-	if (data-&gt;flags &amp; X86_EFLAGS_IF)</span>
<span class="quote">&gt;-		regs-&gt;flags |= X86_EFLAGS_IF;</span>
<span class="quote">&gt;-}</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-void kmemcheck_show_pages(struct page *p, unsigned int n)</span>
<span class="quote">&gt;-{</span>
<span class="quote">&gt;-	unsigned int i;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	for (i = 0; i &lt; n; ++i) {</span>
<span class="quote">&gt;-		unsigned long address;</span>
<span class="quote">&gt;-		pte_t *pte;</span>
<span class="quote">&gt;-		unsigned int level;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-		address = (unsigned long) page_address(&amp;p[i]);</span>
<span class="quote">&gt;-		pte = lookup_address(address, &amp;level);</span>
<span class="quote">&gt;-		BUG_ON(!pte);</span>
<span class="quote">&gt;-		BUG_ON(level != PG_LEVEL_4K);</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-		set_pte(pte, __pte(pte_val(*pte) | _PAGE_PRESENT));</span>
<span class="quote">&gt;-		set_pte(pte, __pte(pte_val(*pte) &amp; ~_PAGE_HIDDEN));</span>
<span class="quote">&gt;-		__flush_tlb_one(address);</span>
<span class="quote">&gt;-	}</span>
<span class="quote">&gt;-}</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-bool kmemcheck_page_is_tracked(struct page *p)</span>
<span class="quote">&gt;-{</span>
<span class="quote">&gt;-	/* This will also check the &quot;hidden&quot; flag of the PTE. */</span>
<span class="quote">&gt;-	return kmemcheck_pte_lookup((unsigned long) page_address(p));</span>
<span class="quote">&gt;-}</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-void kmemcheck_hide_pages(struct page *p, unsigned int n)</span>
<span class="quote">&gt;-{</span>
<span class="quote">&gt;-	unsigned int i;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	for (i = 0; i &lt; n; ++i) {</span>
<span class="quote">&gt;-		unsigned long address;</span>
<span class="quote">&gt;-		pte_t *pte;</span>
<span class="quote">&gt;-		unsigned int level;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-		address = (unsigned long) page_address(&amp;p[i]);</span>
<span class="quote">&gt;-		pte = lookup_address(address, &amp;level);</span>
<span class="quote">&gt;-		BUG_ON(!pte);</span>
<span class="quote">&gt;-		BUG_ON(level != PG_LEVEL_4K);</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-		set_pte(pte, __pte(pte_val(*pte) &amp; ~_PAGE_PRESENT));</span>
<span class="quote">&gt;-		set_pte(pte, __pte(pte_val(*pte) | _PAGE_HIDDEN));</span>
<span class="quote">&gt;-		__flush_tlb_one(address);</span>
<span class="quote">&gt;-	}</span>
<span class="quote">&gt;-}</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-/* Access may NOT cross page boundary */</span>
<span class="quote">&gt;-static void kmemcheck_read_strict(struct pt_regs *regs,</span>
<span class="quote">&gt;-	unsigned long addr, unsigned int size)</span>
<span class="quote">&gt;-{</span>
<span class="quote">&gt;-	void *shadow;</span>
<span class="quote">&gt;-	enum kmemcheck_shadow status;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	shadow = kmemcheck_shadow_lookup(addr);</span>
<span class="quote">&gt;-	if (!shadow)</span>
<span class="quote">&gt;-		return;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	kmemcheck_save_addr(addr);</span>
<span class="quote">&gt;-	status = kmemcheck_shadow_test(shadow, size);</span>
<span class="quote">&gt;-	if (status == KMEMCHECK_SHADOW_INITIALIZED)</span>
<span class="quote">&gt;-		return;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	if (kmemcheck_enabled)</span>
<span class="quote">&gt;-		kmemcheck_error_save(status, addr, size, regs);</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	if (kmemcheck_enabled == 2)</span>
<span class="quote">&gt;-		kmemcheck_enabled = 0;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	/* Don&#39;t warn about it again. */</span>
<span class="quote">&gt;-	kmemcheck_shadow_set(shadow, size);</span>
<span class="quote">&gt;-}</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-bool kmemcheck_is_obj_initialized(unsigned long addr, size_t size)</span>
<span class="quote">&gt;-{</span>
<span class="quote">&gt;-	enum kmemcheck_shadow status;</span>
<span class="quote">&gt;-	void *shadow;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	shadow = kmemcheck_shadow_lookup(addr);</span>
<span class="quote">&gt;-	if (!shadow)</span>
<span class="quote">&gt;-		return true;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	status = kmemcheck_shadow_test_all(shadow, size);</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	return status == KMEMCHECK_SHADOW_INITIALIZED;</span>
<span class="quote">&gt;-}</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-/* Access may cross page boundary */</span>
<span class="quote">&gt;-static void kmemcheck_read(struct pt_regs *regs,</span>
<span class="quote">&gt;-	unsigned long addr, unsigned int size)</span>
<span class="quote">&gt;-{</span>
<span class="quote">&gt;-	unsigned long page = addr &amp; PAGE_MASK;</span>
<span class="quote">&gt;-	unsigned long next_addr = addr + size - 1;</span>
<span class="quote">&gt;-	unsigned long next_page = next_addr &amp; PAGE_MASK;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	if (likely(page == next_page)) {</span>
<span class="quote">&gt;-		kmemcheck_read_strict(regs, addr, size);</span>
<span class="quote">&gt;-		return;</span>
<span class="quote">&gt;-	}</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	/*</span>
<span class="quote">&gt;-	 * What we do is basically to split the access across the</span>
<span class="quote">&gt;-	 * two pages and handle each part separately. Yes, this means</span>
<span class="quote">&gt;-	 * that we may now see reads that are 3 + 5 bytes, for</span>
<span class="quote">&gt;-	 * example (and if both are uninitialized, there will be two</span>
<span class="quote">&gt;-	 * reports), but it makes the code a lot simpler.</span>
<span class="quote">&gt;-	 */</span>
<span class="quote">&gt;-	kmemcheck_read_strict(regs, addr, next_page - addr);</span>
<span class="quote">&gt;-	kmemcheck_read_strict(regs, next_page, next_addr - next_page);</span>
<span class="quote">&gt;-}</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-static void kmemcheck_write_strict(struct pt_regs *regs,</span>
<span class="quote">&gt;-	unsigned long addr, unsigned int size)</span>
<span class="quote">&gt;-{</span>
<span class="quote">&gt;-	void *shadow;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	shadow = kmemcheck_shadow_lookup(addr);</span>
<span class="quote">&gt;-	if (!shadow)</span>
<span class="quote">&gt;-		return;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	kmemcheck_save_addr(addr);</span>
<span class="quote">&gt;-	kmemcheck_shadow_set(shadow, size);</span>
<span class="quote">&gt;-}</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-static void kmemcheck_write(struct pt_regs *regs,</span>
<span class="quote">&gt;-	unsigned long addr, unsigned int size)</span>
<span class="quote">&gt;-{</span>
<span class="quote">&gt;-	unsigned long page = addr &amp; PAGE_MASK;</span>
<span class="quote">&gt;-	unsigned long next_addr = addr + size - 1;</span>
<span class="quote">&gt;-	unsigned long next_page = next_addr &amp; PAGE_MASK;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	if (likely(page == next_page)) {</span>
<span class="quote">&gt;-		kmemcheck_write_strict(regs, addr, size);</span>
<span class="quote">&gt;-		return;</span>
<span class="quote">&gt;-	}</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	/* See comment in kmemcheck_read(). */</span>
<span class="quote">&gt;-	kmemcheck_write_strict(regs, addr, next_page - addr);</span>
<span class="quote">&gt;-	kmemcheck_write_strict(regs, next_page, next_addr - next_page);</span>
<span class="quote">&gt;-}</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-/*</span>
<span class="quote">&gt;- * Copying is hard. We have two addresses, each of which may be split across</span>
<span class="quote">&gt;- * a page (and each page will have different shadow addresses).</span>
<span class="quote">&gt;- */</span>
<span class="quote">&gt;-static void kmemcheck_copy(struct pt_regs *regs,</span>
<span class="quote">&gt;-	unsigned long src_addr, unsigned long dst_addr, unsigned int size)</span>
<span class="quote">&gt;-{</span>
<span class="quote">&gt;-	uint8_t shadow[8];</span>
<span class="quote">&gt;-	enum kmemcheck_shadow status;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	unsigned long page;</span>
<span class="quote">&gt;-	unsigned long next_addr;</span>
<span class="quote">&gt;-	unsigned long next_page;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	uint8_t *x;</span>
<span class="quote">&gt;-	unsigned int i;</span>
<span class="quote">&gt;-	unsigned int n;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	BUG_ON(size &gt; sizeof(shadow));</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	page = src_addr &amp; PAGE_MASK;</span>
<span class="quote">&gt;-	next_addr = src_addr + size - 1;</span>
<span class="quote">&gt;-	next_page = next_addr &amp; PAGE_MASK;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	if (likely(page == next_page)) {</span>
<span class="quote">&gt;-		/* Same page */</span>
<span class="quote">&gt;-		x = kmemcheck_shadow_lookup(src_addr);</span>
<span class="quote">&gt;-		if (x) {</span>
<span class="quote">&gt;-			kmemcheck_save_addr(src_addr);</span>
<span class="quote">&gt;-			for (i = 0; i &lt; size; ++i)</span>
<span class="quote">&gt;-				shadow[i] = x[i];</span>
<span class="quote">&gt;-		} else {</span>
<span class="quote">&gt;-			for (i = 0; i &lt; size; ++i)</span>
<span class="quote">&gt;-				shadow[i] = KMEMCHECK_SHADOW_INITIALIZED;</span>
<span class="quote">&gt;-		}</span>
<span class="quote">&gt;-	} else {</span>
<span class="quote">&gt;-		n = next_page - src_addr;</span>
<span class="quote">&gt;-		BUG_ON(n &gt; sizeof(shadow));</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-		/* First page */</span>
<span class="quote">&gt;-		x = kmemcheck_shadow_lookup(src_addr);</span>
<span class="quote">&gt;-		if (x) {</span>
<span class="quote">&gt;-			kmemcheck_save_addr(src_addr);</span>
<span class="quote">&gt;-			for (i = 0; i &lt; n; ++i)</span>
<span class="quote">&gt;-				shadow[i] = x[i];</span>
<span class="quote">&gt;-		} else {</span>
<span class="quote">&gt;-			/* Not tracked */</span>
<span class="quote">&gt;-			for (i = 0; i &lt; n; ++i)</span>
<span class="quote">&gt;-				shadow[i] = KMEMCHECK_SHADOW_INITIALIZED;</span>
<span class="quote">&gt;-		}</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-		/* Second page */</span>
<span class="quote">&gt;-		x = kmemcheck_shadow_lookup(next_page);</span>
<span class="quote">&gt;-		if (x) {</span>
<span class="quote">&gt;-			kmemcheck_save_addr(next_page);</span>
<span class="quote">&gt;-			for (i = n; i &lt; size; ++i)</span>
<span class="quote">&gt;-				shadow[i] = x[i - n];</span>
<span class="quote">&gt;-		} else {</span>
<span class="quote">&gt;-			/* Not tracked */</span>
<span class="quote">&gt;-			for (i = n; i &lt; size; ++i)</span>
<span class="quote">&gt;-				shadow[i] = KMEMCHECK_SHADOW_INITIALIZED;</span>
<span class="quote">&gt;-		}</span>
<span class="quote">&gt;-	}</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	page = dst_addr &amp; PAGE_MASK;</span>
<span class="quote">&gt;-	next_addr = dst_addr + size - 1;</span>
<span class="quote">&gt;-	next_page = next_addr &amp; PAGE_MASK;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	if (likely(page == next_page)) {</span>
<span class="quote">&gt;-		/* Same page */</span>
<span class="quote">&gt;-		x = kmemcheck_shadow_lookup(dst_addr);</span>
<span class="quote">&gt;-		if (x) {</span>
<span class="quote">&gt;-			kmemcheck_save_addr(dst_addr);</span>
<span class="quote">&gt;-			for (i = 0; i &lt; size; ++i) {</span>
<span class="quote">&gt;-				x[i] = shadow[i];</span>
<span class="quote">&gt;-				shadow[i] = KMEMCHECK_SHADOW_INITIALIZED;</span>
<span class="quote">&gt;-			}</span>
<span class="quote">&gt;-		}</span>
<span class="quote">&gt;-	} else {</span>
<span class="quote">&gt;-		n = next_page - dst_addr;</span>
<span class="quote">&gt;-		BUG_ON(n &gt; sizeof(shadow));</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-		/* First page */</span>
<span class="quote">&gt;-		x = kmemcheck_shadow_lookup(dst_addr);</span>
<span class="quote">&gt;-		if (x) {</span>
<span class="quote">&gt;-			kmemcheck_save_addr(dst_addr);</span>
<span class="quote">&gt;-			for (i = 0; i &lt; n; ++i) {</span>
<span class="quote">&gt;-				x[i] = shadow[i];</span>
<span class="quote">&gt;-				shadow[i] = KMEMCHECK_SHADOW_INITIALIZED;</span>
<span class="quote">&gt;-			}</span>
<span class="quote">&gt;-		}</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-		/* Second page */</span>
<span class="quote">&gt;-		x = kmemcheck_shadow_lookup(next_page);</span>
<span class="quote">&gt;-		if (x) {</span>
<span class="quote">&gt;-			kmemcheck_save_addr(next_page);</span>
<span class="quote">&gt;-			for (i = n; i &lt; size; ++i) {</span>
<span class="quote">&gt;-				x[i - n] = shadow[i];</span>
<span class="quote">&gt;-				shadow[i] = KMEMCHECK_SHADOW_INITIALIZED;</span>
<span class="quote">&gt;-			}</span>
<span class="quote">&gt;-		}</span>
<span class="quote">&gt;-	}</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	status = kmemcheck_shadow_test(shadow, size);</span>
<span class="quote">&gt;-	if (status == KMEMCHECK_SHADOW_INITIALIZED)</span>
<span class="quote">&gt;-		return;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	if (kmemcheck_enabled)</span>
<span class="quote">&gt;-		kmemcheck_error_save(status, src_addr, size, regs);</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	if (kmemcheck_enabled == 2)</span>
<span class="quote">&gt;-		kmemcheck_enabled = 0;</span>
<span class="quote">&gt;-}</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-enum kmemcheck_method {</span>
<span class="quote">&gt;-	KMEMCHECK_READ,</span>
<span class="quote">&gt;-	KMEMCHECK_WRITE,</span>
<span class="quote">&gt;-};</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-static void kmemcheck_access(struct pt_regs *regs,</span>
<span class="quote">&gt;-	unsigned long fallback_address, enum kmemcheck_method fallback_method)</span>
<span class="quote">&gt;-{</span>
<span class="quote">&gt;-	const uint8_t *insn;</span>
<span class="quote">&gt;-	const uint8_t *insn_primary;</span>
<span class="quote">&gt;-	unsigned int size;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	struct kmemcheck_context *data = this_cpu_ptr(&amp;kmemcheck_context);</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	/* Recursive fault -- ouch. */</span>
<span class="quote">&gt;-	if (data-&gt;busy) {</span>
<span class="quote">&gt;-		kmemcheck_show_addr(fallback_address);</span>
<span class="quote">&gt;-		kmemcheck_error_save_bug(regs);</span>
<span class="quote">&gt;-		return;</span>
<span class="quote">&gt;-	}</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	data-&gt;busy = true;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	insn = (const uint8_t *) regs-&gt;ip;</span>
<span class="quote">&gt;-	insn_primary = kmemcheck_opcode_get_primary(insn);</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	kmemcheck_opcode_decode(insn, &amp;size);</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	switch (insn_primary[0]) {</span>
<span class="quote">&gt;-#ifdef CONFIG_KMEMCHECK_BITOPS_OK</span>
<span class="quote">&gt;-		/* AND, OR, XOR */</span>
<span class="quote">&gt;-		/*</span>
<span class="quote">&gt;-		 * Unfortunately, these instructions have to be excluded from</span>
<span class="quote">&gt;-		 * our regular checking since they access only some (and not</span>
<span class="quote">&gt;-		 * all) bits. This clears out &quot;bogus&quot; bitfield-access warnings.</span>
<span class="quote">&gt;-		 */</span>
<span class="quote">&gt;-	case 0x80:</span>
<span class="quote">&gt;-	case 0x81:</span>
<span class="quote">&gt;-	case 0x82:</span>
<span class="quote">&gt;-	case 0x83:</span>
<span class="quote">&gt;-		switch ((insn_primary[1] &gt;&gt; 3) &amp; 7) {</span>
<span class="quote">&gt;-			/* OR */</span>
<span class="quote">&gt;-		case 1:</span>
<span class="quote">&gt;-			/* AND */</span>
<span class="quote">&gt;-		case 4:</span>
<span class="quote">&gt;-			/* XOR */</span>
<span class="quote">&gt;-		case 6:</span>
<span class="quote">&gt;-			kmemcheck_write(regs, fallback_address, size);</span>
<span class="quote">&gt;-			goto out;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-			/* ADD */</span>
<span class="quote">&gt;-		case 0:</span>
<span class="quote">&gt;-			/* ADC */</span>
<span class="quote">&gt;-		case 2:</span>
<span class="quote">&gt;-			/* SBB */</span>
<span class="quote">&gt;-		case 3:</span>
<span class="quote">&gt;-			/* SUB */</span>
<span class="quote">&gt;-		case 5:</span>
<span class="quote">&gt;-			/* CMP */</span>
<span class="quote">&gt;-		case 7:</span>
<span class="quote">&gt;-			break;</span>
<span class="quote">&gt;-		}</span>
<span class="quote">&gt;-		break;</span>
<span class="quote">&gt;-#endif</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-		/* MOVS, MOVSB, MOVSW, MOVSD */</span>
<span class="quote">&gt;-	case 0xa4:</span>
<span class="quote">&gt;-	case 0xa5:</span>
<span class="quote">&gt;-		/*</span>
<span class="quote">&gt;-		 * These instructions are special because they take two</span>
<span class="quote">&gt;-		 * addresses, but we only get one page fault.</span>
<span class="quote">&gt;-		 */</span>
<span class="quote">&gt;-		kmemcheck_copy(regs, regs-&gt;si, regs-&gt;di, size);</span>
<span class="quote">&gt;-		goto out;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-		/* CMPS, CMPSB, CMPSW, CMPSD */</span>
<span class="quote">&gt;-	case 0xa6:</span>
<span class="quote">&gt;-	case 0xa7:</span>
<span class="quote">&gt;-		kmemcheck_read(regs, regs-&gt;si, size);</span>
<span class="quote">&gt;-		kmemcheck_read(regs, regs-&gt;di, size);</span>
<span class="quote">&gt;-		goto out;</span>
<span class="quote">&gt;-	}</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	/*</span>
<span class="quote">&gt;-	 * If the opcode isn&#39;t special in any way, we use the data from the</span>
<span class="quote">&gt;-	 * page fault handler to determine the address and type of memory</span>
<span class="quote">&gt;-	 * access.</span>
<span class="quote">&gt;-	 */</span>
<span class="quote">&gt;-	switch (fallback_method) {</span>
<span class="quote">&gt;-	case KMEMCHECK_READ:</span>
<span class="quote">&gt;-		kmemcheck_read(regs, fallback_address, size);</span>
<span class="quote">&gt;-		goto out;</span>
<span class="quote">&gt;-	case KMEMCHECK_WRITE:</span>
<span class="quote">&gt;-		kmemcheck_write(regs, fallback_address, size);</span>
<span class="quote">&gt;-		goto out;</span>
<span class="quote">&gt;-	}</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-out:</span>
<span class="quote">&gt;-	data-&gt;busy = false;</span>
<span class="quote">&gt;-}</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-bool kmemcheck_fault(struct pt_regs *regs, unsigned long address,</span>
<span class="quote">&gt;-	unsigned long error_code)</span>
<span class="quote">&gt;-{</span>
<span class="quote">&gt;-	pte_t *pte;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	/*</span>
<span class="quote">&gt;-	 * XXX: Is it safe to assume that memory accesses from virtual 86</span>
<span class="quote">&gt;-	 * mode or non-kernel code segments will _never_ access kernel</span>
<span class="quote">&gt;-	 * memory (e.g. tracked pages)? For now, we need this to avoid</span>
<span class="quote">&gt;-	 * invoking kmemcheck for PnP BIOS calls.</span>
<span class="quote">&gt;-	 */</span>
<span class="quote">&gt;-	if (regs-&gt;flags &amp; X86_VM_MASK)</span>
<span class="quote">&gt;-		return false;</span>
<span class="quote">&gt;-	if (regs-&gt;cs != __KERNEL_CS)</span>
<span class="quote">&gt;-		return false;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	pte = kmemcheck_pte_lookup(address);</span>
<span class="quote">&gt;-	if (!pte)</span>
<span class="quote">&gt;-		return false;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	WARN_ON_ONCE(in_nmi());</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	if (error_code &amp; 2)</span>
<span class="quote">&gt;-		kmemcheck_access(regs, address, KMEMCHECK_WRITE);</span>
<span class="quote">&gt;-	else</span>
<span class="quote">&gt;-		kmemcheck_access(regs, address, KMEMCHECK_READ);</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	kmemcheck_show(regs);</span>
<span class="quote">&gt;-	return true;</span>
<span class="quote">&gt;-}</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-bool kmemcheck_trap(struct pt_regs *regs)</span>
<span class="quote">&gt;-{</span>
<span class="quote">&gt;-	if (!kmemcheck_active(regs))</span>
<span class="quote">&gt;-		return false;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	/* We&#39;re done. */</span>
<span class="quote">&gt;-	kmemcheck_hide(regs);</span>
<span class="quote">&gt;-	return true;</span>
<span class="quote">&gt;-}</span>
<span class="quote">&gt;diff --git a/arch/x86/mm/kmemcheck/opcode.c b/arch/x86/mm/kmemcheck/opcode.c</span>
<span class="quote">&gt;deleted file mode 100644</span>
<span class="quote">&gt;index 324aa3f07237..000000000000</span>
<span class="quote">&gt;--- a/arch/x86/mm/kmemcheck/opcode.c</span>
<span class="quote">&gt;+++ /dev/null</span>
<span class="quote">&gt;@@ -1,106 +0,0 @@</span>
<span class="quote">&gt;-#include &lt;linux/types.h&gt;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-#include &quot;opcode.h&quot;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-static bool opcode_is_prefix(uint8_t b)</span>
<span class="quote">&gt;-{</span>
<span class="quote">&gt;-	return</span>
<span class="quote">&gt;-		/* Group 1 */</span>
<span class="quote">&gt;-		b == 0xf0 || b == 0xf2 || b == 0xf3</span>
<span class="quote">&gt;-		/* Group 2 */</span>
<span class="quote">&gt;-		|| b == 0x2e || b == 0x36 || b == 0x3e || b == 0x26</span>
<span class="quote">&gt;-		|| b == 0x64 || b == 0x65</span>
<span class="quote">&gt;-		/* Group 3 */</span>
<span class="quote">&gt;-		|| b == 0x66</span>
<span class="quote">&gt;-		/* Group 4 */</span>
<span class="quote">&gt;-		|| b == 0x67;</span>
<span class="quote">&gt;-}</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-#ifdef CONFIG_X86_64</span>
<span class="quote">&gt;-static bool opcode_is_rex_prefix(uint8_t b)</span>
<span class="quote">&gt;-{</span>
<span class="quote">&gt;-	return (b &amp; 0xf0) == 0x40;</span>
<span class="quote">&gt;-}</span>
<span class="quote">&gt;-#else</span>
<span class="quote">&gt;-static bool opcode_is_rex_prefix(uint8_t b)</span>
<span class="quote">&gt;-{</span>
<span class="quote">&gt;-	return false;</span>
<span class="quote">&gt;-}</span>
<span class="quote">&gt;-#endif</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-#define REX_W (1 &lt;&lt; 3)</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-/*</span>
<span class="quote">&gt;- * This is a VERY crude opcode decoder. We only need to find the size of the</span>
<span class="quote">&gt;- * load/store that caused our #PF and this should work for all the opcodes</span>
<span class="quote">&gt;- * that we care about. Moreover, the ones who invented this instruction set</span>
<span class="quote">&gt;- * should be shot.</span>
<span class="quote">&gt;- */</span>
<span class="quote">&gt;-void kmemcheck_opcode_decode(const uint8_t *op, unsigned int *size)</span>
<span class="quote">&gt;-{</span>
<span class="quote">&gt;-	/* Default operand size */</span>
<span class="quote">&gt;-	int operand_size_override = 4;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	/* prefixes */</span>
<span class="quote">&gt;-	for (; opcode_is_prefix(*op); ++op) {</span>
<span class="quote">&gt;-		if (*op == 0x66)</span>
<span class="quote">&gt;-			operand_size_override = 2;</span>
<span class="quote">&gt;-	}</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	/* REX prefix */</span>
<span class="quote">&gt;-	if (opcode_is_rex_prefix(*op)) {</span>
<span class="quote">&gt;-		uint8_t rex = *op;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-		++op;</span>
<span class="quote">&gt;-		if (rex &amp; REX_W) {</span>
<span class="quote">&gt;-			switch (*op) {</span>
<span class="quote">&gt;-			case 0x63:</span>
<span class="quote">&gt;-				*size = 4;</span>
<span class="quote">&gt;-				return;</span>
<span class="quote">&gt;-			case 0x0f:</span>
<span class="quote">&gt;-				++op;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-				switch (*op) {</span>
<span class="quote">&gt;-				case 0xb6:</span>
<span class="quote">&gt;-				case 0xbe:</span>
<span class="quote">&gt;-					*size = 1;</span>
<span class="quote">&gt;-					return;</span>
<span class="quote">&gt;-				case 0xb7:</span>
<span class="quote">&gt;-				case 0xbf:</span>
<span class="quote">&gt;-					*size = 2;</span>
<span class="quote">&gt;-					return;</span>
<span class="quote">&gt;-				}</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-				break;</span>
<span class="quote">&gt;-			}</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-			*size = 8;</span>
<span class="quote">&gt;-			return;</span>
<span class="quote">&gt;-		}</span>
<span class="quote">&gt;-	}</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	/* escape opcode */</span>
<span class="quote">&gt;-	if (*op == 0x0f) {</span>
<span class="quote">&gt;-		++op;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-		/*</span>
<span class="quote">&gt;-		 * This is move with zero-extend and sign-extend, respectively;</span>
<span class="quote">&gt;-		 * we don&#39;t have to think about 0xb6/0xbe, because this is</span>
<span class="quote">&gt;-		 * already handled in the conditional below.</span>
<span class="quote">&gt;-		 */</span>
<span class="quote">&gt;-		if (*op == 0xb7 || *op == 0xbf)</span>
<span class="quote">&gt;-			operand_size_override = 2;</span>
<span class="quote">&gt;-	}</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	*size = (*op &amp; 1) ? operand_size_override : 1;</span>
<span class="quote">&gt;-}</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-const uint8_t *kmemcheck_opcode_get_primary(const uint8_t *op)</span>
<span class="quote">&gt;-{</span>
<span class="quote">&gt;-	/* skip prefixes */</span>
<span class="quote">&gt;-	while (opcode_is_prefix(*op))</span>
<span class="quote">&gt;-		++op;</span>
<span class="quote">&gt;-	if (opcode_is_rex_prefix(*op))</span>
<span class="quote">&gt;-		++op;</span>
<span class="quote">&gt;-	return op;</span>
<span class="quote">&gt;-}</span>
<span class="quote">&gt;diff --git a/arch/x86/mm/kmemcheck/opcode.h b/arch/x86/mm/kmemcheck/opcode.h</span>
<span class="quote">&gt;deleted file mode 100644</span>
<span class="quote">&gt;index 6956aad66b5b..000000000000</span>
<span class="quote">&gt;--- a/arch/x86/mm/kmemcheck/opcode.h</span>
<span class="quote">&gt;+++ /dev/null</span>
<span class="quote">&gt;@@ -1,9 +0,0 @@</span>
<span class="quote">&gt;-#ifndef ARCH__X86__MM__KMEMCHECK__OPCODE_H</span>
<span class="quote">&gt;-#define ARCH__X86__MM__KMEMCHECK__OPCODE_H</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-#include &lt;linux/types.h&gt;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-void kmemcheck_opcode_decode(const uint8_t *op, unsigned int *size);</span>
<span class="quote">&gt;-const uint8_t *kmemcheck_opcode_get_primary(const uint8_t *op);</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-#endif</span>
<span class="quote">&gt;diff --git a/arch/x86/mm/kmemcheck/pte.c b/arch/x86/mm/kmemcheck/pte.c</span>
<span class="quote">&gt;deleted file mode 100644</span>
<span class="quote">&gt;index 4ead26eeaf96..000000000000</span>
<span class="quote">&gt;--- a/arch/x86/mm/kmemcheck/pte.c</span>
<span class="quote">&gt;+++ /dev/null</span>
<span class="quote">&gt;@@ -1,22 +0,0 @@</span>
<span class="quote">&gt;-#include &lt;linux/mm.h&gt;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-#include &lt;asm/pgtable.h&gt;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-#include &quot;pte.h&quot;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-pte_t *kmemcheck_pte_lookup(unsigned long address)</span>
<span class="quote">&gt;-{</span>
<span class="quote">&gt;-	pte_t *pte;</span>
<span class="quote">&gt;-	unsigned int level;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	pte = lookup_address(address, &amp;level);</span>
<span class="quote">&gt;-	if (!pte)</span>
<span class="quote">&gt;-		return NULL;</span>
<span class="quote">&gt;-	if (level != PG_LEVEL_4K)</span>
<span class="quote">&gt;-		return NULL;</span>
<span class="quote">&gt;-	if (!pte_hidden(*pte))</span>
<span class="quote">&gt;-		return NULL;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	return pte;</span>
<span class="quote">&gt;-}</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;diff --git a/arch/x86/mm/kmemcheck/pte.h b/arch/x86/mm/kmemcheck/pte.h</span>
<span class="quote">&gt;deleted file mode 100644</span>
<span class="quote">&gt;index 9f5966456492..000000000000</span>
<span class="quote">&gt;--- a/arch/x86/mm/kmemcheck/pte.h</span>
<span class="quote">&gt;+++ /dev/null</span>
<span class="quote">&gt;@@ -1,10 +0,0 @@</span>
<span class="quote">&gt;-#ifndef ARCH__X86__MM__KMEMCHECK__PTE_H</span>
<span class="quote">&gt;-#define ARCH__X86__MM__KMEMCHECK__PTE_H</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-#include &lt;linux/mm.h&gt;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-#include &lt;asm/pgtable.h&gt;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-pte_t *kmemcheck_pte_lookup(unsigned long address);</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-#endif</span>
<span class="quote">&gt;diff --git a/arch/x86/mm/kmemcheck/selftest.c b/arch/x86/mm/kmemcheck/selftest.c</span>
<span class="quote">&gt;deleted file mode 100644</span>
<span class="quote">&gt;index aef7140c0063..000000000000</span>
<span class="quote">&gt;--- a/arch/x86/mm/kmemcheck/selftest.c</span>
<span class="quote">&gt;+++ /dev/null</span>
<span class="quote">&gt;@@ -1,70 +0,0 @@</span>
<span class="quote">&gt;-#include &lt;linux/bug.h&gt;</span>
<span class="quote">&gt;-#include &lt;linux/kernel.h&gt;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-#include &quot;opcode.h&quot;</span>
<span class="quote">&gt;-#include &quot;selftest.h&quot;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-struct selftest_opcode {</span>
<span class="quote">&gt;-	unsigned int expected_size;</span>
<span class="quote">&gt;-	const uint8_t *insn;</span>
<span class="quote">&gt;-	const char *desc;</span>
<span class="quote">&gt;-};</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-static const struct selftest_opcode selftest_opcodes[] = {</span>
<span class="quote">&gt;-	/* REP MOVS */</span>
<span class="quote">&gt;-	{1, &quot;\xf3\xa4&quot;, 		&quot;rep movsb &lt;mem8&gt;, &lt;mem8&gt;&quot;},</span>
<span class="quote">&gt;-	{4, &quot;\xf3\xa5&quot;,			&quot;rep movsl &lt;mem32&gt;, &lt;mem32&gt;&quot;},</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	/* MOVZX / MOVZXD */</span>
<span class="quote">&gt;-	{1, &quot;\x66\x0f\xb6\x51\xf8&quot;,	&quot;movzwq &lt;mem8&gt;, &lt;reg16&gt;&quot;},</span>
<span class="quote">&gt;-	{1, &quot;\x0f\xb6\x51\xf8&quot;,		&quot;movzwq &lt;mem8&gt;, &lt;reg32&gt;&quot;},</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	/* MOVSX / MOVSXD */</span>
<span class="quote">&gt;-	{1, &quot;\x66\x0f\xbe\x51\xf8&quot;,	&quot;movswq &lt;mem8&gt;, &lt;reg16&gt;&quot;},</span>
<span class="quote">&gt;-	{1, &quot;\x0f\xbe\x51\xf8&quot;,		&quot;movswq &lt;mem8&gt;, &lt;reg32&gt;&quot;},</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-#ifdef CONFIG_X86_64</span>
<span class="quote">&gt;-	/* MOVZX / MOVZXD */</span>
<span class="quote">&gt;-	{1, &quot;\x49\x0f\xb6\x51\xf8&quot;,	&quot;movzbq &lt;mem8&gt;, &lt;reg64&gt;&quot;},</span>
<span class="quote">&gt;-	{2, &quot;\x49\x0f\xb7\x51\xf8&quot;,	&quot;movzbq &lt;mem16&gt;, &lt;reg64&gt;&quot;},</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	/* MOVSX / MOVSXD */</span>
<span class="quote">&gt;-	{1, &quot;\x49\x0f\xbe\x51\xf8&quot;,	&quot;movsbq &lt;mem8&gt;, &lt;reg64&gt;&quot;},</span>
<span class="quote">&gt;-	{2, &quot;\x49\x0f\xbf\x51\xf8&quot;,	&quot;movsbq &lt;mem16&gt;, &lt;reg64&gt;&quot;},</span>
<span class="quote">&gt;-	{4, &quot;\x49\x63\x51\xf8&quot;,		&quot;movslq &lt;mem32&gt;, &lt;reg64&gt;&quot;},</span>
<span class="quote">&gt;-#endif</span>
<span class="quote">&gt;-};</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-static bool selftest_opcode_one(const struct selftest_opcode *op)</span>
<span class="quote">&gt;-{</span>
<span class="quote">&gt;-	unsigned size;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	kmemcheck_opcode_decode(op-&gt;insn, &amp;size);</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	if (size == op-&gt;expected_size)</span>
<span class="quote">&gt;-		return true;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	printk(KERN_WARNING &quot;kmemcheck: opcode %s: expected size %d, got %d\n&quot;,</span>
<span class="quote">&gt;-		op-&gt;desc, op-&gt;expected_size, size);</span>
<span class="quote">&gt;-	return false;</span>
<span class="quote">&gt;-}</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-static bool selftest_opcodes_all(void)</span>
<span class="quote">&gt;-{</span>
<span class="quote">&gt;-	bool pass = true;</span>
<span class="quote">&gt;-	unsigned int i;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	for (i = 0; i &lt; ARRAY_SIZE(selftest_opcodes); ++i)</span>
<span class="quote">&gt;-		pass = pass &amp;&amp; selftest_opcode_one(&amp;selftest_opcodes[i]);</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	return pass;</span>
<span class="quote">&gt;-}</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-bool kmemcheck_selftest(void)</span>
<span class="quote">&gt;-{</span>
<span class="quote">&gt;-	bool pass = true;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	pass = pass &amp;&amp; selftest_opcodes_all();</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	return pass;</span>
<span class="quote">&gt;-}</span>
<span class="quote">&gt;diff --git a/arch/x86/mm/kmemcheck/selftest.h b/arch/x86/mm/kmemcheck/selftest.h</span>
<span class="quote">&gt;deleted file mode 100644</span>
<span class="quote">&gt;index 8fed4fe11f95..000000000000</span>
<span class="quote">&gt;--- a/arch/x86/mm/kmemcheck/selftest.h</span>
<span class="quote">&gt;+++ /dev/null</span>
<span class="quote">&gt;@@ -1,6 +0,0 @@</span>
<span class="quote">&gt;-#ifndef ARCH_X86_MM_KMEMCHECK_SELFTEST_H</span>
<span class="quote">&gt;-#define ARCH_X86_MM_KMEMCHECK_SELFTEST_H</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-bool kmemcheck_selftest(void);</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-#endif</span>
<span class="quote">&gt;diff --git a/arch/x86/mm/kmemcheck/shadow.c b/arch/x86/mm/kmemcheck/shadow.c</span>
<span class="quote">&gt;deleted file mode 100644</span>
<span class="quote">&gt;index c2638a7d2c10..000000000000</span>
<span class="quote">&gt;--- a/arch/x86/mm/kmemcheck/shadow.c</span>
<span class="quote">&gt;+++ /dev/null</span>
<span class="quote">&gt;@@ -1,173 +0,0 @@</span>
<span class="quote">&gt;-#include &lt;linux/kmemcheck.h&gt;</span>
<span class="quote">&gt;-#include &lt;linux/export.h&gt;</span>
<span class="quote">&gt;-#include &lt;linux/mm.h&gt;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-#include &lt;asm/page.h&gt;</span>
<span class="quote">&gt;-#include &lt;asm/pgtable.h&gt;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-#include &quot;pte.h&quot;</span>
<span class="quote">&gt;-#include &quot;shadow.h&quot;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-/*</span>
<span class="quote">&gt;- * Return the shadow address for the given address. Returns NULL if the</span>
<span class="quote">&gt;- * address is not tracked.</span>
<span class="quote">&gt;- *</span>
<span class="quote">&gt;- * We need to be extremely careful not to follow any invalid pointers,</span>
<span class="quote">&gt;- * because this function can be called for *any* possible address.</span>
<span class="quote">&gt;- */</span>
<span class="quote">&gt;-void *kmemcheck_shadow_lookup(unsigned long address)</span>
<span class="quote">&gt;-{</span>
<span class="quote">&gt;-	pte_t *pte;</span>
<span class="quote">&gt;-	struct page *page;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	if (!virt_addr_valid(address))</span>
<span class="quote">&gt;-		return NULL;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	pte = kmemcheck_pte_lookup(address);</span>
<span class="quote">&gt;-	if (!pte)</span>
<span class="quote">&gt;-		return NULL;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	page = virt_to_page(address);</span>
<span class="quote">&gt;-	if (!page-&gt;shadow)</span>
<span class="quote">&gt;-		return NULL;</span>
<span class="quote">&gt;-	return page-&gt;shadow + (address &amp; (PAGE_SIZE - 1));</span>
<span class="quote">&gt;-}</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-static void mark_shadow(void *address, unsigned int n,</span>
<span class="quote">&gt;-	enum kmemcheck_shadow status)</span>
<span class="quote">&gt;-{</span>
<span class="quote">&gt;-	unsigned long addr = (unsigned long) address;</span>
<span class="quote">&gt;-	unsigned long last_addr = addr + n - 1;</span>
<span class="quote">&gt;-	unsigned long page = addr &amp; PAGE_MASK;</span>
<span class="quote">&gt;-	unsigned long last_page = last_addr &amp; PAGE_MASK;</span>
<span class="quote">&gt;-	unsigned int first_n;</span>
<span class="quote">&gt;-	void *shadow;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	/* If the memory range crosses a page boundary, stop there. */</span>
<span class="quote">&gt;-	if (page == last_page)</span>
<span class="quote">&gt;-		first_n = n;</span>
<span class="quote">&gt;-	else</span>
<span class="quote">&gt;-		first_n = page + PAGE_SIZE - addr;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	shadow = kmemcheck_shadow_lookup(addr);</span>
<span class="quote">&gt;-	if (shadow)</span>
<span class="quote">&gt;-		memset(shadow, status, first_n);</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	addr += first_n;</span>
<span class="quote">&gt;-	n -= first_n;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	/* Do full-page memset()s. */</span>
<span class="quote">&gt;-	while (n &gt;= PAGE_SIZE) {</span>
<span class="quote">&gt;-		shadow = kmemcheck_shadow_lookup(addr);</span>
<span class="quote">&gt;-		if (shadow)</span>
<span class="quote">&gt;-			memset(shadow, status, PAGE_SIZE);</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-		addr += PAGE_SIZE;</span>
<span class="quote">&gt;-		n -= PAGE_SIZE;</span>
<span class="quote">&gt;-	}</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	/* Do the remaining page, if any. */</span>
<span class="quote">&gt;-	if (n &gt; 0) {</span>
<span class="quote">&gt;-		shadow = kmemcheck_shadow_lookup(addr);</span>
<span class="quote">&gt;-		if (shadow)</span>
<span class="quote">&gt;-			memset(shadow, status, n);</span>
<span class="quote">&gt;-	}</span>
<span class="quote">&gt;-}</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-void kmemcheck_mark_unallocated(void *address, unsigned int n)</span>
<span class="quote">&gt;-{</span>
<span class="quote">&gt;-	mark_shadow(address, n, KMEMCHECK_SHADOW_UNALLOCATED);</span>
<span class="quote">&gt;-}</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-void kmemcheck_mark_uninitialized(void *address, unsigned int n)</span>
<span class="quote">&gt;-{</span>
<span class="quote">&gt;-	mark_shadow(address, n, KMEMCHECK_SHADOW_UNINITIALIZED);</span>
<span class="quote">&gt;-}</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-/*</span>
<span class="quote">&gt;- * Fill the shadow memory of the given address such that the memory at that</span>
<span class="quote">&gt;- * address is marked as being initialized.</span>
<span class="quote">&gt;- */</span>
<span class="quote">&gt;-void kmemcheck_mark_initialized(void *address, unsigned int n)</span>
<span class="quote">&gt;-{</span>
<span class="quote">&gt;-	mark_shadow(address, n, KMEMCHECK_SHADOW_INITIALIZED);</span>
<span class="quote">&gt;-}</span>
<span class="quote">&gt;-EXPORT_SYMBOL_GPL(kmemcheck_mark_initialized);</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-void kmemcheck_mark_freed(void *address, unsigned int n)</span>
<span class="quote">&gt;-{</span>
<span class="quote">&gt;-	mark_shadow(address, n, KMEMCHECK_SHADOW_FREED);</span>
<span class="quote">&gt;-}</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-void kmemcheck_mark_unallocated_pages(struct page *p, unsigned int n)</span>
<span class="quote">&gt;-{</span>
<span class="quote">&gt;-	unsigned int i;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	for (i = 0; i &lt; n; ++i)</span>
<span class="quote">&gt;-		kmemcheck_mark_unallocated(page_address(&amp;p[i]), PAGE_SIZE);</span>
<span class="quote">&gt;-}</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-void kmemcheck_mark_uninitialized_pages(struct page *p, unsigned int n)</span>
<span class="quote">&gt;-{</span>
<span class="quote">&gt;-	unsigned int i;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	for (i = 0; i &lt; n; ++i)</span>
<span class="quote">&gt;-		kmemcheck_mark_uninitialized(page_address(&amp;p[i]), PAGE_SIZE);</span>
<span class="quote">&gt;-}</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-void kmemcheck_mark_initialized_pages(struct page *p, unsigned int n)</span>
<span class="quote">&gt;-{</span>
<span class="quote">&gt;-	unsigned int i;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	for (i = 0; i &lt; n; ++i)</span>
<span class="quote">&gt;-		kmemcheck_mark_initialized(page_address(&amp;p[i]), PAGE_SIZE);</span>
<span class="quote">&gt;-}</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-enum kmemcheck_shadow kmemcheck_shadow_test(void *shadow, unsigned int size)</span>
<span class="quote">&gt;-{</span>
<span class="quote">&gt;-#ifdef CONFIG_KMEMCHECK_PARTIAL_OK</span>
<span class="quote">&gt;-	uint8_t *x;</span>
<span class="quote">&gt;-	unsigned int i;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	x = shadow;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	/*</span>
<span class="quote">&gt;-	 * Make sure _some_ bytes are initialized. Gcc frequently generates</span>
<span class="quote">&gt;-	 * code to access neighboring bytes.</span>
<span class="quote">&gt;-	 */</span>
<span class="quote">&gt;-	for (i = 0; i &lt; size; ++i) {</span>
<span class="quote">&gt;-		if (x[i] == KMEMCHECK_SHADOW_INITIALIZED)</span>
<span class="quote">&gt;-			return x[i];</span>
<span class="quote">&gt;-	}</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	return x[0];</span>
<span class="quote">&gt;-#else</span>
<span class="quote">&gt;-	return kmemcheck_shadow_test_all(shadow, size);</span>
<span class="quote">&gt;-#endif</span>
<span class="quote">&gt;-}</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-enum kmemcheck_shadow kmemcheck_shadow_test_all(void *shadow, unsigned int size)</span>
<span class="quote">&gt;-{</span>
<span class="quote">&gt;-	uint8_t *x;</span>
<span class="quote">&gt;-	unsigned int i;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	x = shadow;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	/* All bytes must be initialized. */</span>
<span class="quote">&gt;-	for (i = 0; i &lt; size; ++i) {</span>
<span class="quote">&gt;-		if (x[i] != KMEMCHECK_SHADOW_INITIALIZED)</span>
<span class="quote">&gt;-			return x[i];</span>
<span class="quote">&gt;-	}</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	return x[0];</span>
<span class="quote">&gt;-}</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-void kmemcheck_shadow_set(void *shadow, unsigned int size)</span>
<span class="quote">&gt;-{</span>
<span class="quote">&gt;-	uint8_t *x;</span>
<span class="quote">&gt;-	unsigned int i;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	x = shadow;</span>
<span class="quote">&gt;-	for (i = 0; i &lt; size; ++i)</span>
<span class="quote">&gt;-		x[i] = KMEMCHECK_SHADOW_INITIALIZED;</span>
<span class="quote">&gt;-}</span>
<span class="quote">&gt;diff --git a/arch/x86/mm/kmemcheck/shadow.h b/arch/x86/mm/kmemcheck/shadow.h</span>
<span class="quote">&gt;deleted file mode 100644</span>
<span class="quote">&gt;index ff0b2f70fbcb..000000000000</span>
<span class="quote">&gt;--- a/arch/x86/mm/kmemcheck/shadow.h</span>
<span class="quote">&gt;+++ /dev/null</span>
<span class="quote">&gt;@@ -1,18 +0,0 @@</span>
<span class="quote">&gt;-#ifndef ARCH__X86__MM__KMEMCHECK__SHADOW_H</span>
<span class="quote">&gt;-#define ARCH__X86__MM__KMEMCHECK__SHADOW_H</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-enum kmemcheck_shadow {</span>
<span class="quote">&gt;-	KMEMCHECK_SHADOW_UNALLOCATED,</span>
<span class="quote">&gt;-	KMEMCHECK_SHADOW_UNINITIALIZED,</span>
<span class="quote">&gt;-	KMEMCHECK_SHADOW_INITIALIZED,</span>
<span class="quote">&gt;-	KMEMCHECK_SHADOW_FREED,</span>
<span class="quote">&gt;-};</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-void *kmemcheck_shadow_lookup(unsigned long address);</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-enum kmemcheck_shadow kmemcheck_shadow_test(void *shadow, unsigned int size);</span>
<span class="quote">&gt;-enum kmemcheck_shadow kmemcheck_shadow_test_all(void *shadow,</span>
<span class="quote">&gt;-						unsigned int size);</span>
<span class="quote">&gt;-void kmemcheck_shadow_set(void *shadow, unsigned int size);</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-#endif</span>
<span class="quote">&gt;diff --git a/arch/x86/mm/pageattr.c b/arch/x86/mm/pageattr.c</span>
<span class="quote">&gt;index dfb7d657cf43..3ed9a08885c5 100644</span>
<span class="quote">&gt;--- a/arch/x86/mm/pageattr.c</span>
<span class="quote">&gt;+++ b/arch/x86/mm/pageattr.c</span>
<span class="quote">&gt;@@ -753,7 +753,7 @@ static int split_large_page(struct cpa_data *cpa, pte_t *kpte,</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; 	if (!debug_pagealloc_enabled())</span>
<span class="quote">&gt; 		spin_unlock(&amp;cpa_lock);</span>
<span class="quote">&gt;-	base = alloc_pages(GFP_KERNEL | __GFP_NOTRACK, 0);</span>
<span class="quote">&gt;+	base = alloc_pages(GFP_KERNEL, 0);</span>
<span class="quote">&gt; 	if (!debug_pagealloc_enabled())</span>
<span class="quote">&gt; 		spin_lock(&amp;cpa_lock);</span>
<span class="quote">&gt; 	if (!base)</span>
<span class="quote">&gt;@@ -904,7 +904,7 @@ static void unmap_pud_range(p4d_t *p4d, unsigned long start, unsigned long end)</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; static int alloc_pte_page(pmd_t *pmd)</span>
<span class="quote">&gt; {</span>
<span class="quote">&gt;-	pte_t *pte = (pte_t *)get_zeroed_page(GFP_KERNEL | __GFP_NOTRACK);</span>
<span class="quote">&gt;+	pte_t *pte = (pte_t *)get_zeroed_page(GFP_KERNEL);</span>
<span class="quote">&gt; 	if (!pte)</span>
<span class="quote">&gt; 		return -1;</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;@@ -914,7 +914,7 @@ static int alloc_pte_page(pmd_t *pmd)</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; static int alloc_pmd_page(pud_t *pud)</span>
<span class="quote">&gt; {</span>
<span class="quote">&gt;-	pmd_t *pmd = (pmd_t *)get_zeroed_page(GFP_KERNEL | __GFP_NOTRACK);</span>
<span class="quote">&gt;+	pmd_t *pmd = (pmd_t *)get_zeroed_page(GFP_KERNEL);</span>
<span class="quote">&gt; 	if (!pmd)</span>
<span class="quote">&gt; 		return -1;</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;@@ -1120,7 +1120,7 @@ static int populate_pgd(struct cpa_data *cpa, unsigned long addr)</span>
<span class="quote">&gt; 	pgd_entry = cpa-&gt;pgd + pgd_index(addr);</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; 	if (pgd_none(*pgd_entry)) {</span>
<span class="quote">&gt;-		p4d = (p4d_t *)get_zeroed_page(GFP_KERNEL | __GFP_NOTRACK);</span>
<span class="quote">&gt;+		p4d = (p4d_t *)get_zeroed_page(GFP_KERNEL);</span>
<span class="quote">&gt; 		if (!p4d)</span>
<span class="quote">&gt; 			return -1;</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;@@ -1132,7 +1132,7 @@ static int populate_pgd(struct cpa_data *cpa, unsigned long addr)</span>
<span class="quote">&gt; 	 */</span>
<span class="quote">&gt; 	p4d = p4d_offset(pgd_entry, addr);</span>
<span class="quote">&gt; 	if (p4d_none(*p4d)) {</span>
<span class="quote">&gt;-		pud = (pud_t *)get_zeroed_page(GFP_KERNEL | __GFP_NOTRACK);</span>
<span class="quote">&gt;+		pud = (pud_t *)get_zeroed_page(GFP_KERNEL);</span>
<span class="quote">&gt; 		if (!pud)</span>
<span class="quote">&gt; 			return -1;</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;diff --git a/arch/x86/mm/pgtable.c b/arch/x86/mm/pgtable.c</span>
<span class="quote">&gt;index b372f3442bbf..dc686d2fc59a 100644</span>
<span class="quote">&gt;--- a/arch/x86/mm/pgtable.c</span>
<span class="quote">&gt;+++ b/arch/x86/mm/pgtable.c</span>
<span class="quote">&gt;@@ -6,7 +6,7 @@</span>
<span class="quote">&gt; #include &lt;asm/fixmap.h&gt;</span>
<span class="quote">&gt; #include &lt;asm/mtrr.h&gt;</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;-#define PGALLOC_GFP (GFP_KERNEL_ACCOUNT | __GFP_NOTRACK | __GFP_ZERO)</span>
<span class="quote">&gt;+#define PGALLOC_GFP (GFP_KERNEL_ACCOUNT | __GFP_ZERO)</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; #ifdef CONFIG_HIGHPTE</span>
<span class="quote">&gt; #define PGALLOC_USER_GFP __GFP_HIGHMEM</span>
<span class="quote">&gt;diff --git a/arch/x86/platform/efi/efi_64.c b/arch/x86/platform/efi/efi_64.c</span>
<span class="quote">&gt;index 12e83888e5b9..fe3aebb87468 100644</span>
<span class="quote">&gt;--- a/arch/x86/platform/efi/efi_64.c</span>
<span class="quote">&gt;+++ b/arch/x86/platform/efi/efi_64.c</span>
<span class="quote">&gt;@@ -205,7 +205,7 @@ int __init efi_alloc_page_tables(void)</span>
<span class="quote">&gt; 	if (efi_enabled(EFI_OLD_MEMMAP))</span>
<span class="quote">&gt; 		return 0;</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;-	gfp_mask = GFP_KERNEL | __GFP_NOTRACK | __GFP_ZERO;</span>
<span class="quote">&gt;+	gfp_mask = GFP_KERNEL | __GFP_ZERO;</span>
<span class="quote">&gt; 	efi_pgd = (pgd_t *)__get_free_page(gfp_mask);</span>
<span class="quote">&gt; 	if (!efi_pgd)</span>
<span class="quote">&gt; 		return -ENOMEM;</span>
<span class="quote">&gt;diff --git a/crypto/xor.c b/crypto/xor.c</span>
<span class="quote">&gt;index 263af9fb45ea..bce9fe7af40a 100644</span>
<span class="quote">&gt;--- a/crypto/xor.c</span>
<span class="quote">&gt;+++ b/crypto/xor.c</span>
<span class="quote">&gt;@@ -122,12 +122,7 @@ calibrate_xor_blocks(void)</span>
<span class="quote">&gt; 		goto out;</span>
<span class="quote">&gt; 	}</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;-	/*</span>
<span class="quote">&gt;-	 * Note: Since the memory is not actually used for _anything_ but to</span>
<span class="quote">&gt;-	 * test the XOR speed, we don&#39;t really want kmemcheck to warn about</span>
<span class="quote">&gt;-	 * reading uninitialized bytes here.</span>
<span class="quote">&gt;-	 */</span>
<span class="quote">&gt;-	b1 = (void *) __get_free_pages(GFP_KERNEL | __GFP_NOTRACK, 2);</span>
<span class="quote">&gt;+	b1 = (void *) __get_free_pages(GFP_KERNEL, 2);</span>
<span class="quote">&gt; 	if (!b1) {</span>
<span class="quote">&gt; 		printk(KERN_WARNING &quot;xor: Yikes!  No memory available.\n&quot;);</span>
<span class="quote">&gt; 		return -ENOMEM;</span>
<span class="quote">&gt;diff --git a/drivers/char/random.c b/drivers/char/random.c</span>
<span class="quote">&gt;index 8ad92707e45f..ea0115cf5fc0 100644</span>
<span class="quote">&gt;--- a/drivers/char/random.c</span>
<span class="quote">&gt;+++ b/drivers/char/random.c</span>
<span class="quote">&gt;@@ -259,7 +259,6 @@</span>
<span class="quote">&gt; #include &lt;linux/cryptohash.h&gt;</span>
<span class="quote">&gt; #include &lt;linux/fips.h&gt;</span>
<span class="quote">&gt; #include &lt;linux/ptrace.h&gt;</span>
<span class="quote">&gt;-#include &lt;linux/kmemcheck.h&gt;</span>
<span class="quote">&gt; #include &lt;linux/workqueue.h&gt;</span>
<span class="quote">&gt; #include &lt;linux/irq.h&gt;</span>
<span class="quote">&gt; #include &lt;linux/syscalls.h&gt;</span>
<span class="quote">&gt;diff --git a/drivers/misc/c2port/core.c b/drivers/misc/c2port/core.c</span>
<span class="quote">&gt;index 1922cb8f6b88..1c5b7aec13d4 100644</span>
<span class="quote">&gt;--- a/drivers/misc/c2port/core.c</span>
<span class="quote">&gt;+++ b/drivers/misc/c2port/core.c</span>
<span class="quote">&gt;@@ -15,7 +15,6 @@</span>
<span class="quote">&gt; #include &lt;linux/errno.h&gt;</span>
<span class="quote">&gt; #include &lt;linux/err.h&gt;</span>
<span class="quote">&gt; #include &lt;linux/kernel.h&gt;</span>
<span class="quote">&gt;-#include &lt;linux/kmemcheck.h&gt;</span>
<span class="quote">&gt; #include &lt;linux/ctype.h&gt;</span>
<span class="quote">&gt; #include &lt;linux/delay.h&gt;</span>
<span class="quote">&gt; #include &lt;linux/idr.h&gt;</span>
<span class="quote">&gt;@@ -904,7 +903,6 @@ struct c2port_device *c2port_device_register(char *name,</span>
<span class="quote">&gt; 		return ERR_PTR(-EINVAL);</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; 	c2dev = kmalloc(sizeof(struct c2port_device), GFP_KERNEL);</span>
<span class="quote">&gt;-	kmemcheck_annotate_bitfield(c2dev, flags);</span>
<span class="quote">&gt; 	if (unlikely(!c2dev))</span>
<span class="quote">&gt; 		return ERR_PTR(-ENOMEM);</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;diff --git a/fs/dcache.c b/fs/dcache.c</span>
<span class="quote">&gt;index f90141387f01..96f3af133ee6 100644</span>
<span class="quote">&gt;--- a/fs/dcache.c</span>
<span class="quote">&gt;+++ b/fs/dcache.c</span>
<span class="quote">&gt;@@ -2705,8 +2705,6 @@ static void swap_names(struct dentry *dentry, struct dentry *target)</span>
<span class="quote">&gt; 			 */</span>
<span class="quote">&gt; 			unsigned int i;</span>
<span class="quote">&gt; 			BUILD_BUG_ON(!IS_ALIGNED(DNAME_INLINE_LEN, sizeof(long)));</span>
<span class="quote">&gt;-			kmemcheck_mark_initialized(dentry-&gt;d_iname, DNAME_INLINE_LEN);</span>
<span class="quote">&gt;-			kmemcheck_mark_initialized(target-&gt;d_iname, DNAME_INLINE_LEN);</span>
<span class="quote">&gt; 			for (i = 0; i &lt; DNAME_INLINE_LEN / sizeof(long); i++) {</span>
<span class="quote">&gt; 				swap(((long *) &amp;dentry-&gt;d_iname)[i],</span>
<span class="quote">&gt; 				     ((long *) &amp;target-&gt;d_iname)[i]);</span>
<span class="quote">&gt;diff --git a/include/linux/c2port.h b/include/linux/c2port.h</span>
<span class="quote">&gt;index 4efabcb51347..f2736348ca26 100644</span>
<span class="quote">&gt;--- a/include/linux/c2port.h</span>
<span class="quote">&gt;+++ b/include/linux/c2port.h</span>
<span class="quote">&gt;@@ -9,8 +9,6 @@</span>
<span class="quote">&gt;  * the Free Software Foundation</span>
<span class="quote">&gt;  */</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;-#include &lt;linux/kmemcheck.h&gt;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt; #define C2PORT_NAME_LEN			32</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; struct device;</span>
<span class="quote">&gt;@@ -22,10 +20,8 @@ struct device;</span>
<span class="quote">&gt; /* Main struct */</span>
<span class="quote">&gt; struct c2port_ops;</span>
<span class="quote">&gt; struct c2port_device {</span>
<span class="quote">&gt;-	kmemcheck_bitfield_begin(flags);</span>
<span class="quote">&gt; 	unsigned int access:1;</span>
<span class="quote">&gt; 	unsigned int flash_access:1;</span>
<span class="quote">&gt;-	kmemcheck_bitfield_end(flags);</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; 	int id;</span>
<span class="quote">&gt; 	char name[C2PORT_NAME_LEN];</span>
<span class="quote">&gt;diff --git a/include/linux/dma-mapping.h b/include/linux/dma-mapping.h</span>
<span class="quote">&gt;index 29ce9815da87..2911389bc147 100644</span>
<span class="quote">&gt;--- a/include/linux/dma-mapping.h</span>
<span class="quote">&gt;+++ b/include/linux/dma-mapping.h</span>
<span class="quote">&gt;@@ -8,7 +8,6 @@</span>
<span class="quote">&gt; #include &lt;linux/dma-debug.h&gt;</span>
<span class="quote">&gt; #include &lt;linux/dma-direction.h&gt;</span>
<span class="quote">&gt; #include &lt;linux/scatterlist.h&gt;</span>
<span class="quote">&gt;-#include &lt;linux/kmemcheck.h&gt;</span>
<span class="quote">&gt; #include &lt;linux/bug.h&gt;</span>
<span class="quote">&gt; #include &lt;linux/mem_encrypt.h&gt;</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;@@ -229,7 +228,6 @@ static inline dma_addr_t dma_map_single_attrs(struct device *dev, void *ptr,</span>
<span class="quote">&gt; 	const struct dma_map_ops *ops = get_dma_ops(dev);</span>
<span class="quote">&gt; 	dma_addr_t addr;</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;-	kmemcheck_mark_initialized(ptr, size);</span>
<span class="quote">&gt; 	BUG_ON(!valid_dma_direction(dir));</span>
<span class="quote">&gt; 	addr = ops-&gt;map_page(dev, virt_to_page(ptr),</span>
<span class="quote">&gt; 			     offset_in_page(ptr), size,</span>
<span class="quote">&gt;@@ -262,11 +260,8 @@ static inline int dma_map_sg_attrs(struct device *dev, struct scatterlist *sg,</span>
<span class="quote">&gt; 				   unsigned long attrs)</span>
<span class="quote">&gt; {</span>
<span class="quote">&gt; 	const struct dma_map_ops *ops = get_dma_ops(dev);</span>
<span class="quote">&gt;-	int i, ents;</span>
<span class="quote">&gt;-	struct scatterlist *s;</span>
<span class="quote">&gt;+	int ents;</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;-	for_each_sg(sg, s, nents, i)</span>
<span class="quote">&gt;-		kmemcheck_mark_initialized(sg_virt(s), s-&gt;length);</span>
<span class="quote">&gt; 	BUG_ON(!valid_dma_direction(dir));</span>
<span class="quote">&gt; 	ents = ops-&gt;map_sg(dev, sg, nents, dir, attrs);</span>
<span class="quote">&gt; 	BUG_ON(ents &lt; 0);</span>
<span class="quote">&gt;@@ -296,7 +291,6 @@ static inline dma_addr_t dma_map_page_attrs(struct device *dev,</span>
<span class="quote">&gt; 	const struct dma_map_ops *ops = get_dma_ops(dev);</span>
<span class="quote">&gt; 	dma_addr_t addr;</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;-	kmemcheck_mark_initialized(page_address(page) + offset, size);</span>
<span class="quote">&gt; 	BUG_ON(!valid_dma_direction(dir));</span>
<span class="quote">&gt; 	addr = ops-&gt;map_page(dev, page, offset, size, dir, attrs);</span>
<span class="quote">&gt; 	debug_dma_map_page(dev, page, offset, size, dir, addr, false);</span>
<span class="quote">&gt;diff --git a/include/linux/filter.h b/include/linux/filter.h</span>
<span class="quote">&gt;index d29e58fde364..9a0022cd70c6 100644</span>
<span class="quote">&gt;--- a/include/linux/filter.h</span>
<span class="quote">&gt;+++ b/include/linux/filter.h</span>
<span class="quote">&gt;@@ -453,13 +453,11 @@ struct bpf_binary_header {</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; struct bpf_prog {</span>
<span class="quote">&gt; 	u16			pages;		/* Number of allocated pages */</span>
<span class="quote">&gt;-	kmemcheck_bitfield_begin(meta);</span>
<span class="quote">&gt; 	u16			jited:1,	/* Is our filter JIT&#39;ed? */</span>
<span class="quote">&gt; 				locked:1,	/* Program image locked? */</span>
<span class="quote">&gt; 				gpl_compatible:1, /* Is filter GPL compatible? */</span>
<span class="quote">&gt; 				cb_access:1,	/* Is control block accessed? */</span>
<span class="quote">&gt; 				dst_needed:1;	/* Do we need dst entry? */</span>
<span class="quote">&gt;-	kmemcheck_bitfield_end(meta);</span>
<span class="quote">&gt; 	enum bpf_prog_type	type;		/* Type of BPF program */</span>
<span class="quote">&gt; 	u32			len;		/* Number of filter blocks */</span>
<span class="quote">&gt; 	u32			jited_len;	/* Size of jited insns in bytes */</span>
<span class="quote">&gt;diff --git a/include/linux/gfp.h b/include/linux/gfp.h</span>
<span class="quote">&gt;index f780718b7391..3427fb8d936a 100644</span>
<span class="quote">&gt;--- a/include/linux/gfp.h</span>
<span class="quote">&gt;+++ b/include/linux/gfp.h</span>
<span class="quote">&gt;@@ -36,7 +36,6 @@ struct vm_area_struct;</span>
<span class="quote">&gt; #define ___GFP_THISNODE		0x40000u</span>
<span class="quote">&gt; #define ___GFP_ATOMIC		0x80000u</span>
<span class="quote">&gt; #define ___GFP_ACCOUNT		0x100000u</span>
<span class="quote">&gt;-#define ___GFP_NOTRACK		0x200000u</span>
<span class="quote">&gt; #define ___GFP_DIRECT_RECLAIM	0x400000u</span>
<span class="quote">&gt; #define ___GFP_WRITE		0x800000u</span>
<span class="quote">&gt; #define ___GFP_KSWAPD_RECLAIM	0x1000000u</span>
<span class="quote">&gt;@@ -200,19 +199,11 @@ struct vm_area_struct;</span>
<span class="quote">&gt;  * __GFP_COMP address compound page metadata.</span>
<span class="quote">&gt;  *</span>
<span class="quote">&gt;  * __GFP_ZERO returns a zeroed page on success.</span>
<span class="quote">&gt;- *</span>
<span class="quote">&gt;- * __GFP_NOTRACK avoids tracking with kmemcheck.</span>
<span class="quote">&gt;- *</span>
<span class="quote">&gt;- * __GFP_NOTRACK_FALSE_POSITIVE is an alias of __GFP_NOTRACK. It&#39;s a means of</span>
<span class="quote">&gt;- *   distinguishing in the source between false positives and allocations that</span>
<span class="quote">&gt;- *   cannot be supported (e.g. page tables).</span>
<span class="quote">&gt;  */</span>
<span class="quote">&gt; #define __GFP_COLD	((__force gfp_t)___GFP_COLD)</span>
<span class="quote">&gt; #define __GFP_NOWARN	((__force gfp_t)___GFP_NOWARN)</span>
<span class="quote">&gt; #define __GFP_COMP	((__force gfp_t)___GFP_COMP)</span>
<span class="quote">&gt; #define __GFP_ZERO	((__force gfp_t)___GFP_ZERO)</span>
<span class="quote">&gt;-#define __GFP_NOTRACK	((__force gfp_t)___GFP_NOTRACK)</span>
<span class="quote">&gt;-#define __GFP_NOTRACK_FALSE_POSITIVE (__GFP_NOTRACK)</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; /* Disable lockdep for GFP context tracking */</span>
<span class="quote">&gt; #define __GFP_NOLOCKDEP ((__force gfp_t)___GFP_NOLOCKDEP)</span>
<span class="quote">&gt;diff --git a/include/linux/interrupt.h b/include/linux/interrupt.h</span>
<span class="quote">&gt;index 59ba11661b6e..0cca55dd19ba 100644</span>
<span class="quote">&gt;--- a/include/linux/interrupt.h</span>
<span class="quote">&gt;+++ b/include/linux/interrupt.h</span>
<span class="quote">&gt;@@ -593,21 +593,6 @@ static inline void tasklet_hi_schedule(struct tasklet_struct *t)</span>
<span class="quote">&gt; 		__tasklet_hi_schedule(t);</span>
<span class="quote">&gt; }</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;-extern void __tasklet_hi_schedule_first(struct tasklet_struct *t);</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-/*</span>
<span class="quote">&gt;- * This version avoids touching any other tasklets. Needed for kmemcheck</span>
<span class="quote">&gt;- * in order not to take any page faults while enqueueing this tasklet;</span>
<span class="quote">&gt;- * consider VERY carefully whether you really need this or</span>
<span class="quote">&gt;- * tasklet_hi_schedule()...</span>
<span class="quote">&gt;- */</span>
<span class="quote">&gt;-static inline void tasklet_hi_schedule_first(struct tasklet_struct *t)</span>
<span class="quote">&gt;-{</span>
<span class="quote">&gt;-	if (!test_and_set_bit(TASKLET_STATE_SCHED, &amp;t-&gt;state))</span>
<span class="quote">&gt;-		__tasklet_hi_schedule_first(t);</span>
<span class="quote">&gt;-}</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt; static inline void tasklet_disable_nosync(struct tasklet_struct *t)</span>
<span class="quote">&gt; {</span>
<span class="quote">&gt; 	atomic_inc(&amp;t-&gt;count);</span>
<span class="quote">&gt;diff --git a/include/linux/kmemcheck.h b/include/linux/kmemcheck.h</span>
<span class="quote">&gt;deleted file mode 100644</span>
<span class="quote">&gt;index 39f8453239f7..000000000000</span>
<span class="quote">&gt;--- a/include/linux/kmemcheck.h</span>
<span class="quote">&gt;+++ /dev/null</span>
<span class="quote">&gt;@@ -1,171 +0,0 @@</span>
<span class="quote">&gt;-#ifndef LINUX_KMEMCHECK_H</span>
<span class="quote">&gt;-#define LINUX_KMEMCHECK_H</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-#include &lt;linux/mm_types.h&gt;</span>
<span class="quote">&gt;-#include &lt;linux/types.h&gt;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-#ifdef CONFIG_KMEMCHECK</span>
<span class="quote">&gt;-extern int kmemcheck_enabled;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-/* The slab-related functions. */</span>
<span class="quote">&gt;-void kmemcheck_alloc_shadow(struct page *page, int order, gfp_t flags, int node);</span>
<span class="quote">&gt;-void kmemcheck_free_shadow(struct page *page, int order);</span>
<span class="quote">&gt;-void kmemcheck_slab_alloc(struct kmem_cache *s, gfp_t gfpflags, void *object,</span>
<span class="quote">&gt;-			  size_t size);</span>
<span class="quote">&gt;-void kmemcheck_slab_free(struct kmem_cache *s, void *object, size_t size);</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-void kmemcheck_pagealloc_alloc(struct page *p, unsigned int order,</span>
<span class="quote">&gt;-			       gfp_t gfpflags);</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-void kmemcheck_show_pages(struct page *p, unsigned int n);</span>
<span class="quote">&gt;-void kmemcheck_hide_pages(struct page *p, unsigned int n);</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-bool kmemcheck_page_is_tracked(struct page *p);</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-void kmemcheck_mark_unallocated(void *address, unsigned int n);</span>
<span class="quote">&gt;-void kmemcheck_mark_uninitialized(void *address, unsigned int n);</span>
<span class="quote">&gt;-void kmemcheck_mark_initialized(void *address, unsigned int n);</span>
<span class="quote">&gt;-void kmemcheck_mark_freed(void *address, unsigned int n);</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-void kmemcheck_mark_unallocated_pages(struct page *p, unsigned int n);</span>
<span class="quote">&gt;-void kmemcheck_mark_uninitialized_pages(struct page *p, unsigned int n);</span>
<span class="quote">&gt;-void kmemcheck_mark_initialized_pages(struct page *p, unsigned int n);</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-int kmemcheck_show_addr(unsigned long address);</span>
<span class="quote">&gt;-int kmemcheck_hide_addr(unsigned long address);</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-bool kmemcheck_is_obj_initialized(unsigned long addr, size_t size);</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-/*</span>
<span class="quote">&gt;- * Bitfield annotations</span>
<span class="quote">&gt;- *</span>
<span class="quote">&gt;- * How to use: If you have a struct using bitfields, for example</span>
<span class="quote">&gt;- *</span>
<span class="quote">&gt;- *     struct a {</span>
<span class="quote">&gt;- *             int x:8, y:8;</span>
<span class="quote">&gt;- *     };</span>
<span class="quote">&gt;- *</span>
<span class="quote">&gt;- * then this should be rewritten as</span>
<span class="quote">&gt;- *</span>
<span class="quote">&gt;- *     struct a {</span>
<span class="quote">&gt;- *             kmemcheck_bitfield_begin(flags);</span>
<span class="quote">&gt;- *             int x:8, y:8;</span>
<span class="quote">&gt;- *             kmemcheck_bitfield_end(flags);</span>
<span class="quote">&gt;- *     };</span>
<span class="quote">&gt;- *</span>
<span class="quote">&gt;- * Now the &quot;flags_begin&quot; and &quot;flags_end&quot; members may be used to refer to the</span>
<span class="quote">&gt;- * beginning and end, respectively, of the bitfield (and things like</span>
<span class="quote">&gt;- * &amp;x.flags_begin is allowed). As soon as the struct is allocated, the bit-</span>
<span class="quote">&gt;- * fields should be annotated:</span>
<span class="quote">&gt;- *</span>
<span class="quote">&gt;- *     struct a *a = kmalloc(sizeof(struct a), GFP_KERNEL);</span>
<span class="quote">&gt;- *     kmemcheck_annotate_bitfield(a, flags);</span>
<span class="quote">&gt;- */</span>
<span class="quote">&gt;-#define kmemcheck_bitfield_begin(name)	\</span>
<span class="quote">&gt;-	int name##_begin[0];</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-#define kmemcheck_bitfield_end(name)	\</span>
<span class="quote">&gt;-	int name##_end[0];</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-#define kmemcheck_annotate_bitfield(ptr, name)				\</span>
<span class="quote">&gt;-	do {								\</span>
<span class="quote">&gt;-		int _n;							\</span>
<span class="quote">&gt;-									\</span>
<span class="quote">&gt;-		if (!ptr)						\</span>
<span class="quote">&gt;-			break;						\</span>
<span class="quote">&gt;-									\</span>
<span class="quote">&gt;-		_n = (long) &amp;((ptr)-&gt;name##_end)			\</span>
<span class="quote">&gt;-			- (long) &amp;((ptr)-&gt;name##_begin);		\</span>
<span class="quote">&gt;-		BUILD_BUG_ON(_n &lt; 0);					\</span>
<span class="quote">&gt;-									\</span>
<span class="quote">&gt;-		kmemcheck_mark_initialized(&amp;((ptr)-&gt;name##_begin), _n);	\</span>
<span class="quote">&gt;-	} while (0)</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-#define kmemcheck_annotate_variable(var)				\</span>
<span class="quote">&gt;-	do {								\</span>
<span class="quote">&gt;-		kmemcheck_mark_initialized(&amp;(var), sizeof(var));	\</span>
<span class="quote">&gt;-	} while (0)							\</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-#else</span>
<span class="quote">&gt;-#define kmemcheck_enabled 0</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-static inline void</span>
<span class="quote">&gt;-kmemcheck_alloc_shadow(struct page *page, int order, gfp_t flags, int node)</span>
<span class="quote">&gt;-{</span>
<span class="quote">&gt;-}</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-static inline void</span>
<span class="quote">&gt;-kmemcheck_free_shadow(struct page *page, int order)</span>
<span class="quote">&gt;-{</span>
<span class="quote">&gt;-}</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-static inline void</span>
<span class="quote">&gt;-kmemcheck_slab_alloc(struct kmem_cache *s, gfp_t gfpflags, void *object,</span>
<span class="quote">&gt;-		     size_t size)</span>
<span class="quote">&gt;-{</span>
<span class="quote">&gt;-}</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-static inline void kmemcheck_slab_free(struct kmem_cache *s, void *object,</span>
<span class="quote">&gt;-				       size_t size)</span>
<span class="quote">&gt;-{</span>
<span class="quote">&gt;-}</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-static inline void kmemcheck_pagealloc_alloc(struct page *p,</span>
<span class="quote">&gt;-	unsigned int order, gfp_t gfpflags)</span>
<span class="quote">&gt;-{</span>
<span class="quote">&gt;-}</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-static inline bool kmemcheck_page_is_tracked(struct page *p)</span>
<span class="quote">&gt;-{</span>
<span class="quote">&gt;-	return false;</span>
<span class="quote">&gt;-}</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-static inline void kmemcheck_mark_unallocated(void *address, unsigned int n)</span>
<span class="quote">&gt;-{</span>
<span class="quote">&gt;-}</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-static inline void kmemcheck_mark_uninitialized(void *address, unsigned int n)</span>
<span class="quote">&gt;-{</span>
<span class="quote">&gt;-}</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-static inline void kmemcheck_mark_initialized(void *address, unsigned int n)</span>
<span class="quote">&gt;-{</span>
<span class="quote">&gt;-}</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-static inline void kmemcheck_mark_freed(void *address, unsigned int n)</span>
<span class="quote">&gt;-{</span>
<span class="quote">&gt;-}</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-static inline void kmemcheck_mark_unallocated_pages(struct page *p,</span>
<span class="quote">&gt;-						    unsigned int n)</span>
<span class="quote">&gt;-{</span>
<span class="quote">&gt;-}</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-static inline void kmemcheck_mark_uninitialized_pages(struct page *p,</span>
<span class="quote">&gt;-						      unsigned int n)</span>
<span class="quote">&gt;-{</span>
<span class="quote">&gt;-}</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-static inline void kmemcheck_mark_initialized_pages(struct page *p,</span>
<span class="quote">&gt;-						    unsigned int n)</span>
<span class="quote">&gt;-{</span>
<span class="quote">&gt;-}</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-static inline bool kmemcheck_is_obj_initialized(unsigned long addr, size_t size)</span>
<span class="quote">&gt;-{</span>
<span class="quote">&gt;-	return true;</span>
<span class="quote">&gt;-}</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-#define kmemcheck_bitfield_begin(name)</span>
<span class="quote">&gt;-#define kmemcheck_bitfield_end(name)</span>
<span class="quote">&gt;-#define kmemcheck_annotate_bitfield(ptr, name)	\</span>
<span class="quote">&gt;-	do {					\</span>
<span class="quote">&gt;-	} while (0)</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-#define kmemcheck_annotate_variable(var)	\</span>
<span class="quote">&gt;-	do {					\</span>
<span class="quote">&gt;-	} while (0)</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-#endif /* CONFIG_KMEMCHECK */</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-#endif /* LINUX_KMEMCHECK_H */</span>
<span class="quote">&gt;diff --git a/include/linux/mm_types.h b/include/linux/mm_types.h</span>
<span class="quote">&gt;index 46f4ecf5479a..804d0e754ab0 100644</span>
<span class="quote">&gt;--- a/include/linux/mm_types.h</span>
<span class="quote">&gt;+++ b/include/linux/mm_types.h</span>
<span class="quote">&gt;@@ -206,14 +206,6 @@ struct page {</span>
<span class="quote">&gt; 					   not kmapped, ie. highmem) */</span>
<span class="quote">&gt; #endif /* WANT_PAGE_VIRTUAL */</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;-#ifdef CONFIG_KMEMCHECK</span>
<span class="quote">&gt;-	/*</span>
<span class="quote">&gt;-	 * kmemcheck wants to track the status of each byte in a page; this</span>
<span class="quote">&gt;-	 * is a pointer to such a status block. NULL if not tracked.</span>
<span class="quote">&gt;-	 */</span>
<span class="quote">&gt;-	void *shadow;</span>
<span class="quote">&gt;-#endif</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt; #ifdef LAST_CPUPID_NOT_IN_PAGE_FLAGS</span>
<span class="quote">&gt; 	int _last_cpupid;</span>
<span class="quote">&gt; #endif</span>
<span class="quote">&gt;diff --git a/include/linux/net.h b/include/linux/net.h</span>
<span class="quote">&gt;index d97d80d7fdf8..caeb159abda5 100644</span>
<span class="quote">&gt;--- a/include/linux/net.h</span>
<span class="quote">&gt;+++ b/include/linux/net.h</span>
<span class="quote">&gt;@@ -22,7 +22,6 @@</span>
<span class="quote">&gt; #include &lt;linux/random.h&gt;</span>
<span class="quote">&gt; #include &lt;linux/wait.h&gt;</span>
<span class="quote">&gt; #include &lt;linux/fcntl.h&gt;	/* For O_CLOEXEC and O_NONBLOCK */</span>
<span class="quote">&gt;-#include &lt;linux/kmemcheck.h&gt;</span>
<span class="quote">&gt; #include &lt;linux/rcupdate.h&gt;</span>
<span class="quote">&gt; #include &lt;linux/once.h&gt;</span>
<span class="quote">&gt; #include &lt;linux/fs.h&gt;</span>
<span class="quote">&gt;@@ -111,9 +110,7 @@ struct socket_wq {</span>
<span class="quote">&gt; struct socket {</span>
<span class="quote">&gt; 	socket_state		state;</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;-	kmemcheck_bitfield_begin(type);</span>
<span class="quote">&gt; 	short			type;</span>
<span class="quote">&gt;-	kmemcheck_bitfield_end(type);</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; 	unsigned long		flags;</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;diff --git a/include/linux/ring_buffer.h b/include/linux/ring_buffer.h</span>
<span class="quote">&gt;index ee9b461af095..8c0c6d236c49 100644</span>
<span class="quote">&gt;--- a/include/linux/ring_buffer.h</span>
<span class="quote">&gt;+++ b/include/linux/ring_buffer.h</span>
<span class="quote">&gt;@@ -1,7 +1,6 @@</span>
<span class="quote">&gt; #ifndef _LINUX_RING_BUFFER_H</span>
<span class="quote">&gt; #define _LINUX_RING_BUFFER_H</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;-#include &lt;linux/kmemcheck.h&gt;</span>
<span class="quote">&gt; #include &lt;linux/mm.h&gt;</span>
<span class="quote">&gt; #include &lt;linux/seq_file.h&gt;</span>
<span class="quote">&gt; #include &lt;linux/poll.h&gt;</span>
<span class="quote">&gt;@@ -13,9 +12,7 @@ struct ring_buffer_iter;</span>
<span class="quote">&gt;  * Don&#39;t refer to this struct directly, use functions below.</span>
<span class="quote">&gt;  */</span>
<span class="quote">&gt; struct ring_buffer_event {</span>
<span class="quote">&gt;-	kmemcheck_bitfield_begin(bitfield);</span>
<span class="quote">&gt; 	u32		type_len:5, time_delta:27;</span>
<span class="quote">&gt;-	kmemcheck_bitfield_end(bitfield);</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; 	u32		array[];</span>
<span class="quote">&gt; };</span>
<span class="quote">&gt;diff --git a/include/linux/skbuff.h b/include/linux/skbuff.h</span>
<span class="quote">&gt;index 72299ef00061..ac4041af7f37 100644</span>
<span class="quote">&gt;--- a/include/linux/skbuff.h</span>
<span class="quote">&gt;+++ b/include/linux/skbuff.h</span>
<span class="quote">&gt;@@ -15,7 +15,6 @@</span>
<span class="quote">&gt; #define _LINUX_SKBUFF_H</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; #include &lt;linux/kernel.h&gt;</span>
<span class="quote">&gt;-#include &lt;linux/kmemcheck.h&gt;</span>
<span class="quote">&gt; #include &lt;linux/compiler.h&gt;</span>
<span class="quote">&gt; #include &lt;linux/time.h&gt;</span>
<span class="quote">&gt; #include &lt;linux/bug.h&gt;</span>
<span class="quote">&gt;@@ -704,7 +703,6 @@ struct sk_buff {</span>
<span class="quote">&gt; 	/* Following fields are _not_ copied in __copy_skb_header()</span>
<span class="quote">&gt; 	 * Note that queue_mapping is here mostly to fill a hole.</span>
<span class="quote">&gt; 	 */</span>
<span class="quote">&gt;-	kmemcheck_bitfield_begin(flags1);</span>
<span class="quote">&gt; 	__u16			queue_mapping;</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; /* if you move cloned around you also must adapt those constants */</span>
<span class="quote">&gt;@@ -723,7 +721,6 @@ struct sk_buff {</span>
<span class="quote">&gt; 				head_frag:1,</span>
<span class="quote">&gt; 				xmit_more:1,</span>
<span class="quote">&gt; 				__unused:1; /* one bit hole */</span>
<span class="quote">&gt;-	kmemcheck_bitfield_end(flags1);</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; 	/* fields enclosed in headers_start/headers_end are copied</span>
<span class="quote">&gt; 	 * using a single memcpy() in __copy_skb_header()</span>
<span class="quote">&gt;diff --git a/include/linux/slab.h b/include/linux/slab.h</span>
<span class="quote">&gt;index 41473df6dfb0..f35c640687a0 100644</span>
<span class="quote">&gt;--- a/include/linux/slab.h</span>
<span class="quote">&gt;+++ b/include/linux/slab.h</span>
<span class="quote">&gt;@@ -77,12 +77,6 @@</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; #define SLAB_NOLEAKTRACE	0x00800000UL	/* Avoid kmemleak tracing */</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;-/* Don&#39;t track use of uninitialized memory */</span>
<span class="quote">&gt;-#ifdef CONFIG_KMEMCHECK</span>
<span class="quote">&gt;-# define SLAB_NOTRACK		0x01000000UL</span>
<span class="quote">&gt;-#else</span>
<span class="quote">&gt;-# define SLAB_NOTRACK		0x00000000UL</span>
<span class="quote">&gt;-#endif</span>
<span class="quote">&gt; #ifdef CONFIG_FAILSLAB</span>
<span class="quote">&gt; # define SLAB_FAILSLAB		0x02000000UL	/* Fault injection mark */</span>
<span class="quote">&gt; #else</span>
<span class="quote">&gt;diff --git a/include/linux/thread_info.h b/include/linux/thread_info.h</span>
<span class="quote">&gt;index 905d769d8ddc..c1deb611b5bb 100644</span>
<span class="quote">&gt;--- a/include/linux/thread_info.h</span>
<span class="quote">&gt;+++ b/include/linux/thread_info.h</span>
<span class="quote">&gt;@@ -43,10 +43,9 @@ enum {</span>
<span class="quote">&gt; #endif</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; #ifdef CONFIG_DEBUG_STACK_USAGE</span>
<span class="quote">&gt;-# define THREADINFO_GFP		(GFP_KERNEL_ACCOUNT | __GFP_NOTRACK | \</span>
<span class="quote">&gt;-				 __GFP_ZERO)</span>
<span class="quote">&gt;+# define THREADINFO_GFP		(GFP_KERNEL_ACCOUNT | __GFP_ZERO)</span>
<span class="quote">&gt; #else</span>
<span class="quote">&gt;-# define THREADINFO_GFP		(GFP_KERNEL_ACCOUNT | __GFP_NOTRACK)</span>
<span class="quote">&gt;+# define THREADINFO_GFP		(GFP_KERNEL_ACCOUNT)</span>
<span class="quote">&gt; #endif</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; /*</span>
<span class="quote">&gt;diff --git a/include/net/inet_sock.h b/include/net/inet_sock.h</span>
<span class="quote">&gt;index aa95053dfc78..21c3e4d73b88 100644</span>
<span class="quote">&gt;--- a/include/net/inet_sock.h</span>
<span class="quote">&gt;+++ b/include/net/inet_sock.h</span>
<span class="quote">&gt;@@ -17,7 +17,6 @@</span>
<span class="quote">&gt; #define _INET_SOCK_H</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; #include &lt;linux/bitops.h&gt;</span>
<span class="quote">&gt;-#include &lt;linux/kmemcheck.h&gt;</span>
<span class="quote">&gt; #include &lt;linux/string.h&gt;</span>
<span class="quote">&gt; #include &lt;linux/types.h&gt;</span>
<span class="quote">&gt; #include &lt;linux/jhash.h&gt;</span>
<span class="quote">&gt;@@ -84,7 +83,6 @@ struct inet_request_sock {</span>
<span class="quote">&gt; #define ireq_state		req.__req_common.skc_state</span>
<span class="quote">&gt; #define ireq_family		req.__req_common.skc_family</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;-	kmemcheck_bitfield_begin(flags);</span>
<span class="quote">&gt; 	u16			snd_wscale : 4,</span>
<span class="quote">&gt; 				rcv_wscale : 4,</span>
<span class="quote">&gt; 				tstamp_ok  : 1,</span>
<span class="quote">&gt;@@ -93,7 +91,6 @@ struct inet_request_sock {</span>
<span class="quote">&gt; 				ecn_ok	   : 1,</span>
<span class="quote">&gt; 				acked	   : 1,</span>
<span class="quote">&gt; 				no_srccheck: 1;</span>
<span class="quote">&gt;-	kmemcheck_bitfield_end(flags);</span>
<span class="quote">&gt; 	u32                     ir_mark;</span>
<span class="quote">&gt; 	union {</span>
<span class="quote">&gt; 		struct ip_options_rcu	*opt;</span>
<span class="quote">&gt;diff --git a/include/net/inet_timewait_sock.h b/include/net/inet_timewait_sock.h</span>
<span class="quote">&gt;index 6a75d67a30fd..48977ba510d6 100644</span>
<span class="quote">&gt;--- a/include/net/inet_timewait_sock.h</span>
<span class="quote">&gt;+++ b/include/net/inet_timewait_sock.h</span>
<span class="quote">&gt;@@ -16,7 +16,6 @@</span>
<span class="quote">&gt; #define _INET_TIMEWAIT_SOCK_</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;-#include &lt;linux/kmemcheck.h&gt;</span>
<span class="quote">&gt; #include &lt;linux/list.h&gt;</span>
<span class="quote">&gt; #include &lt;linux/timer.h&gt;</span>
<span class="quote">&gt; #include &lt;linux/types.h&gt;</span>
<span class="quote">&gt;@@ -69,14 +68,12 @@ struct inet_timewait_sock {</span>
<span class="quote">&gt; 	/* Socket demultiplex comparisons on incoming packets. */</span>
<span class="quote">&gt; 	/* these three are in inet_sock */</span>
<span class="quote">&gt; 	__be16			tw_sport;</span>
<span class="quote">&gt;-	kmemcheck_bitfield_begin(flags);</span>
<span class="quote">&gt; 	/* And these are ours. */</span>
<span class="quote">&gt; 	unsigned int		tw_kill		: 1,</span>
<span class="quote">&gt; 				tw_transparent  : 1,</span>
<span class="quote">&gt; 				tw_flowlabel	: 20,</span>
<span class="quote">&gt; 				tw_pad		: 2,	/* 2 bits hole */</span>
<span class="quote">&gt; 				tw_tos		: 8;</span>
<span class="quote">&gt;-	kmemcheck_bitfield_end(flags);</span>
<span class="quote">&gt; 	struct timer_list	tw_timer;</span>
<span class="quote">&gt; 	struct inet_bind_bucket	*tw_tb;</span>
<span class="quote">&gt; };</span>
<span class="quote">&gt;diff --git a/include/net/sock.h b/include/net/sock.h</span>
<span class="quote">&gt;index a6b9a8d1a6df..167c687ebdb1 100644</span>
<span class="quote">&gt;--- a/include/net/sock.h</span>
<span class="quote">&gt;+++ b/include/net/sock.h</span>
<span class="quote">&gt;@@ -436,7 +436,6 @@ struct sock {</span>
<span class="quote">&gt; #define SK_FL_TYPE_MASK    0xffff0000</span>
<span class="quote">&gt; #endif</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;-	kmemcheck_bitfield_begin(flags);</span>
<span class="quote">&gt; 	unsigned int		sk_padding : 1,</span>
<span class="quote">&gt; 				sk_kern_sock : 1,</span>
<span class="quote">&gt; 				sk_no_check_tx : 1,</span>
<span class="quote">&gt;@@ -445,7 +444,6 @@ struct sock {</span>
<span class="quote">&gt; 				sk_protocol  : 8,</span>
<span class="quote">&gt; 				sk_type      : 16;</span>
<span class="quote">&gt; #define SK_PROTOCOL_MAX U8_MAX</span>
<span class="quote">&gt;-	kmemcheck_bitfield_end(flags);</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; 	u16			sk_gso_max_segs;</span>
<span class="quote">&gt; 	unsigned long	        sk_lingertime;</span>
<span class="quote">&gt;diff --git a/include/trace/events/mmflags.h b/include/trace/events/mmflags.h</span>
<span class="quote">&gt;index fec6291a6703..937d5d54d1b9 100644</span>
<span class="quote">&gt;--- a/include/trace/events/mmflags.h</span>
<span class="quote">&gt;+++ b/include/trace/events/mmflags.h</span>
<span class="quote">&gt;@@ -45,7 +45,6 @@</span>
<span class="quote">&gt; 	{(unsigned long)__GFP_RECLAIMABLE,	&quot;__GFP_RECLAIMABLE&quot;},	\</span>
<span class="quote">&gt; 	{(unsigned long)__GFP_MOVABLE,		&quot;__GFP_MOVABLE&quot;},	\</span>
<span class="quote">&gt; 	{(unsigned long)__GFP_ACCOUNT,		&quot;__GFP_ACCOUNT&quot;},	\</span>
<span class="quote">&gt;-	{(unsigned long)__GFP_NOTRACK,		&quot;__GFP_NOTRACK&quot;},	\</span>
<span class="quote">&gt; 	{(unsigned long)__GFP_WRITE,		&quot;__GFP_WRITE&quot;},		\</span>
<span class="quote">&gt; 	{(unsigned long)__GFP_RECLAIM,		&quot;__GFP_RECLAIM&quot;},	\</span>
<span class="quote">&gt; 	{(unsigned long)__GFP_DIRECT_RECLAIM,	&quot;__GFP_DIRECT_RECLAIM&quot;},\</span>
<span class="quote">&gt;diff --git a/init/do_mounts.c b/init/do_mounts.c</span>
<span class="quote">&gt;index f6d4dd764a52..7cf4f6dafd5f 100644</span>
<span class="quote">&gt;--- a/init/do_mounts.c</span>
<span class="quote">&gt;+++ b/init/do_mounts.c</span>
<span class="quote">&gt;@@ -380,8 +380,7 @@ static int __init do_mount_root(char *name, char *fs, int flags, void *data)</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; void __init mount_block_root(char *name, int flags)</span>
<span class="quote">&gt; {</span>
<span class="quote">&gt;-	struct page *page = alloc_page(GFP_KERNEL |</span>
<span class="quote">&gt;-					__GFP_NOTRACK_FALSE_POSITIVE);</span>
<span class="quote">&gt;+	struct page *page = alloc_page(GFP_KERNEL);</span>
<span class="quote">&gt; 	char *fs_names = page_address(page);</span>
<span class="quote">&gt; 	char *p;</span>
<span class="quote">&gt; #ifdef CONFIG_BLOCK</span>
<span class="quote">&gt;diff --git a/init/main.c b/init/main.c</span>
<span class="quote">&gt;index 0ee9c6866ada..0e4d39c2ec82 100644</span>
<span class="quote">&gt;--- a/init/main.c</span>
<span class="quote">&gt;+++ b/init/main.c</span>
<span class="quote">&gt;@@ -69,7 +69,6 @@</span>
<span class="quote">&gt; #include &lt;linux/kgdb.h&gt;</span>
<span class="quote">&gt; #include &lt;linux/ftrace.h&gt;</span>
<span class="quote">&gt; #include &lt;linux/async.h&gt;</span>
<span class="quote">&gt;-#include &lt;linux/kmemcheck.h&gt;</span>
<span class="quote">&gt; #include &lt;linux/sfi.h&gt;</span>
<span class="quote">&gt; #include &lt;linux/shmem_fs.h&gt;</span>
<span class="quote">&gt; #include &lt;linux/slab.h&gt;</span>
<span class="quote">&gt;diff --git a/kernel/bpf/core.c b/kernel/bpf/core.c</span>
<span class="quote">&gt;index 917cc04a0a94..29af29befbd1 100644</span>
<span class="quote">&gt;--- a/kernel/bpf/core.c</span>
<span class="quote">&gt;+++ b/kernel/bpf/core.c</span>
<span class="quote">&gt;@@ -85,8 +85,6 @@ struct bpf_prog *bpf_prog_alloc(unsigned int size, gfp_t gfp_extra_flags)</span>
<span class="quote">&gt; 	if (fp == NULL)</span>
<span class="quote">&gt; 		return NULL;</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;-	kmemcheck_annotate_bitfield(fp, meta);</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt; 	aux = kzalloc(sizeof(*aux), GFP_KERNEL | gfp_extra_flags);</span>
<span class="quote">&gt; 	if (aux == NULL) {</span>
<span class="quote">&gt; 		vfree(fp);</span>
<span class="quote">&gt;@@ -127,8 +125,6 @@ struct bpf_prog *bpf_prog_realloc(struct bpf_prog *fp_old, unsigned int size,</span>
<span class="quote">&gt; 	if (fp == NULL) {</span>
<span class="quote">&gt; 		__bpf_prog_uncharge(fp_old-&gt;aux-&gt;user, delta);</span>
<span class="quote">&gt; 	} else {</span>
<span class="quote">&gt;-		kmemcheck_annotate_bitfield(fp, meta);</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt; 		memcpy(fp, fp_old, fp_old-&gt;pages * PAGE_SIZE);</span>
<span class="quote">&gt; 		fp-&gt;pages = pages;</span>
<span class="quote">&gt; 		fp-&gt;aux-&gt;prog = fp;</span>
<span class="quote">&gt;@@ -662,8 +658,6 @@ static struct bpf_prog *bpf_prog_clone_create(struct bpf_prog *fp_other,</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; 	fp = __vmalloc(fp_other-&gt;pages * PAGE_SIZE, gfp_flags, PAGE_KERNEL);</span>
<span class="quote">&gt; 	if (fp != NULL) {</span>
<span class="quote">&gt;-		kmemcheck_annotate_bitfield(fp, meta);</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt; 		/* aux-&gt;prog still points to the fp_other one, so</span>
<span class="quote">&gt; 		 * when promoting the clone to the real program,</span>
<span class="quote">&gt; 		 * this still needs to be adapted.</span>
<span class="quote">&gt;diff --git a/kernel/fork.c b/kernel/fork.c</span>
<span class="quote">&gt;index 10646182440f..07fdb44af7b8 100644</span>
<span class="quote">&gt;--- a/kernel/fork.c</span>
<span class="quote">&gt;+++ b/kernel/fork.c</span>
<span class="quote">&gt;@@ -465,7 +465,7 @@ void __init fork_init(void)</span>
<span class="quote">&gt; 	/* create a slab on which task_structs can be allocated */</span>
<span class="quote">&gt; 	task_struct_cachep = kmem_cache_create(&quot;task_struct&quot;,</span>
<span class="quote">&gt; 			arch_task_struct_size, align,</span>
<span class="quote">&gt;-			SLAB_PANIC|SLAB_NOTRACK|SLAB_ACCOUNT, NULL);</span>
<span class="quote">&gt;+			SLAB_PANIC|SLAB_ACCOUNT, NULL);</span>
<span class="quote">&gt; #endif</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; 	/* do the arch specific task caches init */</span>
<span class="quote">&gt;@@ -2187,18 +2187,18 @@ void __init proc_caches_init(void)</span>
<span class="quote">&gt; 	sighand_cachep = kmem_cache_create(&quot;sighand_cache&quot;,</span>
<span class="quote">&gt; 			sizeof(struct sighand_struct), 0,</span>
<span class="quote">&gt; 			SLAB_HWCACHE_ALIGN|SLAB_PANIC|SLAB_TYPESAFE_BY_RCU|</span>
<span class="quote">&gt;-			SLAB_NOTRACK|SLAB_ACCOUNT, sighand_ctor);</span>
<span class="quote">&gt;+			SLAB_ACCOUNT, sighand_ctor);</span>
<span class="quote">&gt; 	signal_cachep = kmem_cache_create(&quot;signal_cache&quot;,</span>
<span class="quote">&gt; 			sizeof(struct signal_struct), 0,</span>
<span class="quote">&gt;-			SLAB_HWCACHE_ALIGN|SLAB_PANIC|SLAB_NOTRACK|SLAB_ACCOUNT,</span>
<span class="quote">&gt;+			SLAB_HWCACHE_ALIGN|SLAB_PANIC|SLAB_ACCOUNT,</span>
<span class="quote">&gt; 			NULL);</span>
<span class="quote">&gt; 	files_cachep = kmem_cache_create(&quot;files_cache&quot;,</span>
<span class="quote">&gt; 			sizeof(struct files_struct), 0,</span>
<span class="quote">&gt;-			SLAB_HWCACHE_ALIGN|SLAB_PANIC|SLAB_NOTRACK|SLAB_ACCOUNT,</span>
<span class="quote">&gt;+			SLAB_HWCACHE_ALIGN|SLAB_PANIC|SLAB_ACCOUNT,</span>
<span class="quote">&gt; 			NULL);</span>
<span class="quote">&gt; 	fs_cachep = kmem_cache_create(&quot;fs_cache&quot;,</span>
<span class="quote">&gt; 			sizeof(struct fs_struct), 0,</span>
<span class="quote">&gt;-			SLAB_HWCACHE_ALIGN|SLAB_PANIC|SLAB_NOTRACK|SLAB_ACCOUNT,</span>
<span class="quote">&gt;+			SLAB_HWCACHE_ALIGN|SLAB_PANIC|SLAB_ACCOUNT,</span>
<span class="quote">&gt; 			NULL);</span>
<span class="quote">&gt; 	/*</span>
<span class="quote">&gt; 	 * FIXME! The &quot;sizeof(struct mm_struct)&quot; currently includes the</span>
<span class="quote">&gt;@@ -2209,7 +2209,7 @@ void __init proc_caches_init(void)</span>
<span class="quote">&gt; 	 */</span>
<span class="quote">&gt; 	mm_cachep = kmem_cache_create(&quot;mm_struct&quot;,</span>
<span class="quote">&gt; 			sizeof(struct mm_struct), ARCH_MIN_MMSTRUCT_ALIGN,</span>
<span class="quote">&gt;-			SLAB_HWCACHE_ALIGN|SLAB_PANIC|SLAB_NOTRACK|SLAB_ACCOUNT,</span>
<span class="quote">&gt;+			SLAB_HWCACHE_ALIGN|SLAB_PANIC|SLAB_ACCOUNT,</span>
<span class="quote">&gt; 			NULL);</span>
<span class="quote">&gt; 	vm_area_cachep = KMEM_CACHE(vm_area_struct, SLAB_PANIC|SLAB_ACCOUNT);</span>
<span class="quote">&gt; 	mmap_init();</span>
<span class="quote">&gt;diff --git a/kernel/locking/lockdep.c b/kernel/locking/lockdep.c</span>
<span class="quote">&gt;index 44c8d0d17170..a616140f3a2a 100644</span>
<span class="quote">&gt;--- a/kernel/locking/lockdep.c</span>
<span class="quote">&gt;+++ b/kernel/locking/lockdep.c</span>
<span class="quote">&gt;@@ -47,7 +47,6 @@</span>
<span class="quote">&gt; #include &lt;linux/stringify.h&gt;</span>
<span class="quote">&gt; #include &lt;linux/bitops.h&gt;</span>
<span class="quote">&gt; #include &lt;linux/gfp.h&gt;</span>
<span class="quote">&gt;-#include &lt;linux/kmemcheck.h&gt;</span>
<span class="quote">&gt; #include &lt;linux/random.h&gt;</span>
<span class="quote">&gt; #include &lt;linux/jhash.h&gt;</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;@@ -3233,8 +3232,6 @@ static void __lockdep_init_map(struct lockdep_map *lock, const char *name,</span>
<span class="quote">&gt; {</span>
<span class="quote">&gt; 	int i;</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;-	kmemcheck_mark_initialized(lock, sizeof(*lock));</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt; 	for (i = 0; i &lt; NR_LOCKDEP_CACHING_CLASSES; i++)</span>
<span class="quote">&gt; 		lock-&gt;class_cache[i] = NULL;</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;diff --git a/kernel/signal.c b/kernel/signal.c</span>
<span class="quote">&gt;index 800a18f77732..8da9a7ff52fc 100644</span>
<span class="quote">&gt;--- a/kernel/signal.c</span>
<span class="quote">&gt;+++ b/kernel/signal.c</span>
<span class="quote">&gt;@@ -1036,8 +1036,7 @@ static int __send_signal(int sig, struct siginfo *info, struct task_struct *t,</span>
<span class="quote">&gt; 	else</span>
<span class="quote">&gt; 		override_rlimit = 0;</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;-	q = __sigqueue_alloc(sig, t, GFP_ATOMIC | __GFP_NOTRACK_FALSE_POSITIVE,</span>
<span class="quote">&gt;-		override_rlimit);</span>
<span class="quote">&gt;+	q = __sigqueue_alloc(sig, t, GFP_ATOMIC, override_rlimit);</span>
<span class="quote">&gt; 	if (q) {</span>
<span class="quote">&gt; 		list_add_tail(&amp;q-&gt;list, &amp;pending-&gt;list);</span>
<span class="quote">&gt; 		switch ((unsigned long) info) {</span>
<span class="quote">&gt;diff --git a/kernel/softirq.c b/kernel/softirq.c</span>
<span class="quote">&gt;index 4e09821f9d9e..e89c3b0cff6d 100644</span>
<span class="quote">&gt;--- a/kernel/softirq.c</span>
<span class="quote">&gt;+++ b/kernel/softirq.c</span>
<span class="quote">&gt;@@ -486,16 +486,6 @@ void __tasklet_hi_schedule(struct tasklet_struct *t)</span>
<span class="quote">&gt; }</span>
<span class="quote">&gt; EXPORT_SYMBOL(__tasklet_hi_schedule);</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;-void __tasklet_hi_schedule_first(struct tasklet_struct *t)</span>
<span class="quote">&gt;-{</span>
<span class="quote">&gt;-	BUG_ON(!irqs_disabled());</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	t-&gt;next = __this_cpu_read(tasklet_hi_vec.head);</span>
<span class="quote">&gt;-	__this_cpu_write(tasklet_hi_vec.head, t);</span>
<span class="quote">&gt;-	__raise_softirq_irqoff(HI_SOFTIRQ);</span>
<span class="quote">&gt;-}</span>
<span class="quote">&gt;-EXPORT_SYMBOL(__tasklet_hi_schedule_first);</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt; static __latent_entropy void tasklet_action(struct softirq_action *a)</span>
<span class="quote">&gt; {</span>
<span class="quote">&gt; 	struct tasklet_struct *list;</span>
<span class="quote">&gt;diff --git a/kernel/sysctl.c b/kernel/sysctl.c</span>
<span class="quote">&gt;index 6648fbbb8157..9a9691a76d61 100644</span>
<span class="quote">&gt;--- a/kernel/sysctl.c</span>
<span class="quote">&gt;+++ b/kernel/sysctl.c</span>
<span class="quote">&gt;@@ -30,7 +30,6 @@</span>
<span class="quote">&gt; #include &lt;linux/proc_fs.h&gt;</span>
<span class="quote">&gt; #include &lt;linux/security.h&gt;</span>
<span class="quote">&gt; #include &lt;linux/ctype.h&gt;</span>
<span class="quote">&gt;-#include &lt;linux/kmemcheck.h&gt;</span>
<span class="quote">&gt; #include &lt;linux/kmemleak.h&gt;</span>
<span class="quote">&gt; #include &lt;linux/fs.h&gt;</span>
<span class="quote">&gt; #include &lt;linux/init.h&gt;</span>
<span class="quote">&gt;@@ -1177,15 +1176,6 @@ static struct ctl_table kern_table[] = {</span>
<span class="quote">&gt; 		.extra2		= &amp;one_thousand,</span>
<span class="quote">&gt; 	},</span>
<span class="quote">&gt; #endif</span>
<span class="quote">&gt;-#ifdef CONFIG_KMEMCHECK</span>
<span class="quote">&gt;-	{</span>
<span class="quote">&gt;-		.procname	= &quot;kmemcheck&quot;,</span>
<span class="quote">&gt;-		.data		= &amp;kmemcheck_enabled,</span>
<span class="quote">&gt;-		.maxlen		= sizeof(int),</span>
<span class="quote">&gt;-		.mode		= 0644,</span>
<span class="quote">&gt;-		.proc_handler	= proc_dointvec,</span>
<span class="quote">&gt;-	},</span>
<span class="quote">&gt;-#endif</span>
<span class="quote">&gt; 	{</span>
<span class="quote">&gt; 		.procname	= &quot;panic_on_warn&quot;,</span>
<span class="quote">&gt; 		.data		= &amp;panic_on_warn,</span>
<span class="quote">&gt;diff --git a/kernel/trace/ring_buffer.c b/kernel/trace/ring_buffer.c</span>
<span class="quote">&gt;index 81279c6602ff..7e97e75afc6a 100644</span>
<span class="quote">&gt;--- a/kernel/trace/ring_buffer.c</span>
<span class="quote">&gt;+++ b/kernel/trace/ring_buffer.c</span>
<span class="quote">&gt;@@ -13,7 +13,6 @@</span>
<span class="quote">&gt; #include &lt;linux/uaccess.h&gt;</span>
<span class="quote">&gt; #include &lt;linux/hardirq.h&gt;</span>
<span class="quote">&gt; #include &lt;linux/kthread.h&gt;	/* for self test */</span>
<span class="quote">&gt;-#include &lt;linux/kmemcheck.h&gt;</span>
<span class="quote">&gt; #include &lt;linux/module.h&gt;</span>
<span class="quote">&gt; #include &lt;linux/percpu.h&gt;</span>
<span class="quote">&gt; #include &lt;linux/mutex.h&gt;</span>
<span class="quote">&gt;@@ -2055,7 +2054,6 @@ rb_reset_tail(struct ring_buffer_per_cpu *cpu_buffer,</span>
<span class="quote">&gt; 	}</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; 	event = __rb_page_index(tail_page, tail);</span>
<span class="quote">&gt;-	kmemcheck_annotate_bitfield(event, bitfield);</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; 	/* account for padding bytes */</span>
<span class="quote">&gt; 	local_add(BUF_PAGE_SIZE - tail, &amp;cpu_buffer-&gt;entries_bytes);</span>
<span class="quote">&gt;@@ -2686,7 +2684,6 @@ __rb_reserve_next(struct ring_buffer_per_cpu *cpu_buffer,</span>
<span class="quote">&gt; 	/* We reserved something on the buffer */</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; 	event = __rb_page_index(tail_page, tail);</span>
<span class="quote">&gt;-	kmemcheck_annotate_bitfield(event, bitfield);</span>
<span class="quote">&gt; 	rb_update_event(cpu_buffer, event, info);</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; 	local_inc(&amp;tail_page-&gt;entries);</span>
<span class="quote">&gt;diff --git a/lib/Kconfig.debug b/lib/Kconfig.debug</span>
<span class="quote">&gt;index 2689b7c50c52..d4051fcafa4e 100644</span>
<span class="quote">&gt;--- a/lib/Kconfig.debug</span>
<span class="quote">&gt;+++ b/lib/Kconfig.debug</span>
<span class="quote">&gt;@@ -504,7 +504,7 @@ config DEBUG_OBJECTS_ENABLE_DEFAULT</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; config DEBUG_SLAB</span>
<span class="quote">&gt; 	bool &quot;Debug slab memory allocations&quot;</span>
<span class="quote">&gt;-	depends on DEBUG_KERNEL &amp;&amp; SLAB &amp;&amp; !KMEMCHECK</span>
<span class="quote">&gt;+	depends on DEBUG_KERNEL &amp;&amp; SLAB</span>
<span class="quote">&gt; 	help</span>
<span class="quote">&gt; 	  Say Y here to have the kernel do limited verification on memory</span>
<span class="quote">&gt; 	  allocation as well as poisoning memory on free to catch use of freed</span>
<span class="quote">&gt;@@ -516,7 +516,7 @@ config DEBUG_SLAB_LEAK</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; config SLUB_DEBUG_ON</span>
<span class="quote">&gt; 	bool &quot;SLUB debugging on by default&quot;</span>
<span class="quote">&gt;-	depends on SLUB &amp;&amp; SLUB_DEBUG &amp;&amp; !KMEMCHECK</span>
<span class="quote">&gt;+	depends on SLUB &amp;&amp; SLUB_DEBUG</span>
<span class="quote">&gt; 	default n</span>
<span class="quote">&gt; 	help</span>
<span class="quote">&gt; 	  Boot with debugging on by default. SLUB boots by default with</span>
<span class="quote">&gt;@@ -730,8 +730,6 @@ config DEBUG_STACKOVERFLOW</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; 	  If in doubt, say &quot;N&quot;.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;-source &quot;lib/Kconfig.kmemcheck&quot;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt; source &quot;lib/Kconfig.kasan&quot;</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; endmenu # &quot;Memory Debugging&quot;</span>
<span class="quote">&gt;diff --git a/lib/Kconfig.kmemcheck b/lib/Kconfig.kmemcheck</span>
<span class="quote">&gt;deleted file mode 100644</span>
<span class="quote">&gt;index 846e039a86b4..000000000000</span>
<span class="quote">&gt;--- a/lib/Kconfig.kmemcheck</span>
<span class="quote">&gt;+++ /dev/null</span>
<span class="quote">&gt;@@ -1,94 +0,0 @@</span>
<span class="quote">&gt;-config HAVE_ARCH_KMEMCHECK</span>
<span class="quote">&gt;-	bool</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-if HAVE_ARCH_KMEMCHECK</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-menuconfig KMEMCHECK</span>
<span class="quote">&gt;-	bool &quot;kmemcheck: trap use of uninitialized memory&quot;</span>
<span class="quote">&gt;-	depends on DEBUG_KERNEL</span>
<span class="quote">&gt;-	depends on !X86_USE_3DNOW</span>
<span class="quote">&gt;-	depends on SLUB || SLAB</span>
<span class="quote">&gt;-	depends on !CC_OPTIMIZE_FOR_SIZE</span>
<span class="quote">&gt;-	depends on !FUNCTION_TRACER</span>
<span class="quote">&gt;-	select FRAME_POINTER</span>
<span class="quote">&gt;-	select STACKTRACE</span>
<span class="quote">&gt;-	default n</span>
<span class="quote">&gt;-	help</span>
<span class="quote">&gt;-	  This option enables tracing of dynamically allocated kernel memory</span>
<span class="quote">&gt;-	  to see if memory is used before it has been given an initial value.</span>
<span class="quote">&gt;-	  Be aware that this requires half of your memory for bookkeeping and</span>
<span class="quote">&gt;-	  will insert extra code at *every* read and write to tracked memory</span>
<span class="quote">&gt;-	  thus slow down the kernel code (but user code is unaffected).</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	  The kernel may be started with kmemcheck=0 or kmemcheck=1 to disable</span>
<span class="quote">&gt;-	  or enable kmemcheck at boot-time. If the kernel is started with</span>
<span class="quote">&gt;-	  kmemcheck=0, the large memory and CPU overhead is not incurred.</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-choice</span>
<span class="quote">&gt;-	prompt &quot;kmemcheck: default mode at boot&quot;</span>
<span class="quote">&gt;-	depends on KMEMCHECK</span>
<span class="quote">&gt;-	default KMEMCHECK_ONESHOT_BY_DEFAULT</span>
<span class="quote">&gt;-	help</span>
<span class="quote">&gt;-	  This option controls the default behaviour of kmemcheck when the</span>
<span class="quote">&gt;-	  kernel boots and no kmemcheck= parameter is given.</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-config KMEMCHECK_DISABLED_BY_DEFAULT</span>
<span class="quote">&gt;-	bool &quot;disabled&quot;</span>
<span class="quote">&gt;-	depends on KMEMCHECK</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-config KMEMCHECK_ENABLED_BY_DEFAULT</span>
<span class="quote">&gt;-	bool &quot;enabled&quot;</span>
<span class="quote">&gt;-	depends on KMEMCHECK</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-config KMEMCHECK_ONESHOT_BY_DEFAULT</span>
<span class="quote">&gt;-	bool &quot;one-shot&quot;</span>
<span class="quote">&gt;-	depends on KMEMCHECK</span>
<span class="quote">&gt;-	help</span>
<span class="quote">&gt;-	  In one-shot mode, only the first error detected is reported before</span>
<span class="quote">&gt;-	  kmemcheck is disabled.</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-endchoice</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-config KMEMCHECK_QUEUE_SIZE</span>
<span class="quote">&gt;-	int &quot;kmemcheck: error queue size&quot;</span>
<span class="quote">&gt;-	depends on KMEMCHECK</span>
<span class="quote">&gt;-	default 64</span>
<span class="quote">&gt;-	help</span>
<span class="quote">&gt;-	  Select the maximum number of errors to store in the queue. Since</span>
<span class="quote">&gt;-	  errors can occur virtually anywhere and in any context, we need a</span>
<span class="quote">&gt;-	  temporary storage area which is guarantueed not to generate any</span>
<span class="quote">&gt;-	  other faults. The queue will be emptied as soon as a tasklet may</span>
<span class="quote">&gt;-	  be scheduled. If the queue is full, new error reports will be</span>
<span class="quote">&gt;-	  lost.</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-config KMEMCHECK_SHADOW_COPY_SHIFT</span>
<span class="quote">&gt;-	int &quot;kmemcheck: shadow copy size (5 =&gt; 32 bytes, 6 =&gt; 64 bytes)&quot;</span>
<span class="quote">&gt;-	depends on KMEMCHECK</span>
<span class="quote">&gt;-	range 2 8</span>
<span class="quote">&gt;-	default 5</span>
<span class="quote">&gt;-	help</span>
<span class="quote">&gt;-	  Select the number of shadow bytes to save along with each entry of</span>
<span class="quote">&gt;-	  the queue. These bytes indicate what parts of an allocation are</span>
<span class="quote">&gt;-	  initialized, uninitialized, etc. and will be displayed when an</span>
<span class="quote">&gt;-	  error is detected to help the debugging of a particular problem.</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-config KMEMCHECK_PARTIAL_OK</span>
<span class="quote">&gt;-	bool &quot;kmemcheck: allow partially uninitialized memory&quot;</span>
<span class="quote">&gt;-	depends on KMEMCHECK</span>
<span class="quote">&gt;-	default y</span>
<span class="quote">&gt;-	help</span>
<span class="quote">&gt;-	  This option works around certain GCC optimizations that produce</span>
<span class="quote">&gt;-	  32-bit reads from 16-bit variables where the upper 16 bits are</span>
<span class="quote">&gt;-	  thrown away afterwards. This may of course also hide some real</span>
<span class="quote">&gt;-	  bugs.</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-config KMEMCHECK_BITOPS_OK</span>
<span class="quote">&gt;-	bool &quot;kmemcheck: allow bit-field manipulation&quot;</span>
<span class="quote">&gt;-	depends on KMEMCHECK</span>
<span class="quote">&gt;-	default n</span>
<span class="quote">&gt;-	help</span>
<span class="quote">&gt;-	  This option silences warnings that would be generated for bit-field</span>
<span class="quote">&gt;-	  accesses where not all the bits are initialized at the same time.</span>
<span class="quote">&gt;-	  This may also hide some real bugs.</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-endif</span>
<span class="quote">&gt;diff --git a/mm/Kconfig.debug b/mm/Kconfig.debug</span>
<span class="quote">&gt;index 5b0adf1435de..e5e606ee5f71 100644</span>
<span class="quote">&gt;--- a/mm/Kconfig.debug</span>
<span class="quote">&gt;+++ b/mm/Kconfig.debug</span>
<span class="quote">&gt;@@ -11,7 +11,6 @@ config DEBUG_PAGEALLOC</span>
<span class="quote">&gt; 	bool &quot;Debug page memory allocations&quot;</span>
<span class="quote">&gt; 	depends on DEBUG_KERNEL</span>
<span class="quote">&gt; 	depends on !HIBERNATION || ARCH_SUPPORTS_DEBUG_PAGEALLOC &amp;&amp; !PPC &amp;&amp; !SPARC</span>
<span class="quote">&gt;-	depends on !KMEMCHECK</span>
<span class="quote">&gt; 	select PAGE_EXTENSION</span>
<span class="quote">&gt; 	select PAGE_POISONING if !ARCH_SUPPORTS_DEBUG_PAGEALLOC</span>
<span class="quote">&gt; 	---help---</span>
<span class="quote">&gt;diff --git a/mm/Makefile b/mm/Makefile</span>
<span class="quote">&gt;index e3ac3aeb533b..cdec8105457c 100644</span>
<span class="quote">&gt;--- a/mm/Makefile</span>
<span class="quote">&gt;+++ b/mm/Makefile</span>
<span class="quote">&gt;@@ -16,7 +16,6 @@ KCOV_INSTRUMENT_slub.o := n</span>
<span class="quote">&gt; KCOV_INSTRUMENT_page_alloc.o := n</span>
<span class="quote">&gt; KCOV_INSTRUMENT_debug-pagealloc.o := n</span>
<span class="quote">&gt; KCOV_INSTRUMENT_kmemleak.o := n</span>
<span class="quote">&gt;-KCOV_INSTRUMENT_kmemcheck.o := n</span>
<span class="quote">&gt; KCOV_INSTRUMENT_memcontrol.o := n</span>
<span class="quote">&gt; KCOV_INSTRUMENT_mmzone.o := n</span>
<span class="quote">&gt; KCOV_INSTRUMENT_vmstat.o := n</span>
<span class="quote">&gt;@@ -69,7 +68,6 @@ obj-$(CONFIG_KSM) += ksm.o</span>
<span class="quote">&gt; obj-$(CONFIG_PAGE_POISONING) += page_poison.o</span>
<span class="quote">&gt; obj-$(CONFIG_SLAB) += slab.o</span>
<span class="quote">&gt; obj-$(CONFIG_SLUB) += slub.o</span>
<span class="quote">&gt;-obj-$(CONFIG_KMEMCHECK) += kmemcheck.o</span>
<span class="quote">&gt; obj-$(CONFIG_KASAN)	+= kasan/</span>
<span class="quote">&gt; obj-$(CONFIG_FAILSLAB) += failslab.o</span>
<span class="quote">&gt; obj-$(CONFIG_MEMORY_HOTPLUG) += memory_hotplug.o</span>
<span class="quote">&gt;diff --git a/mm/kmemcheck.c b/mm/kmemcheck.c</span>
<span class="quote">&gt;deleted file mode 100644</span>
<span class="quote">&gt;index 2d5959c5f7c5..000000000000</span>
<span class="quote">&gt;--- a/mm/kmemcheck.c</span>
<span class="quote">&gt;+++ /dev/null</span>
<span class="quote">&gt;@@ -1,125 +0,0 @@</span>
<span class="quote">&gt;-#include &lt;linux/gfp.h&gt;</span>
<span class="quote">&gt;-#include &lt;linux/mm_types.h&gt;</span>
<span class="quote">&gt;-#include &lt;linux/mm.h&gt;</span>
<span class="quote">&gt;-#include &lt;linux/slab.h&gt;</span>
<span class="quote">&gt;-#include &quot;slab.h&quot;</span>
<span class="quote">&gt;-#include &lt;linux/kmemcheck.h&gt;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-void kmemcheck_alloc_shadow(struct page *page, int order, gfp_t flags, int node)</span>
<span class="quote">&gt;-{</span>
<span class="quote">&gt;-	struct page *shadow;</span>
<span class="quote">&gt;-	int pages;</span>
<span class="quote">&gt;-	int i;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	pages = 1 &lt;&lt; order;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	/*</span>
<span class="quote">&gt;-	 * With kmemcheck enabled, we need to allocate a memory area for the</span>
<span class="quote">&gt;-	 * shadow bits as well.</span>
<span class="quote">&gt;-	 */</span>
<span class="quote">&gt;-	shadow = alloc_pages_node(node, flags | __GFP_NOTRACK, order);</span>
<span class="quote">&gt;-	if (!shadow) {</span>
<span class="quote">&gt;-		if (printk_ratelimit())</span>
<span class="quote">&gt;-			pr_err(&quot;kmemcheck: failed to allocate shadow bitmap\n&quot;);</span>
<span class="quote">&gt;-		return;</span>
<span class="quote">&gt;-	}</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	for(i = 0; i &lt; pages; ++i)</span>
<span class="quote">&gt;-		page[i].shadow = page_address(&amp;shadow[i]);</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	/*</span>
<span class="quote">&gt;-	 * Mark it as non-present for the MMU so that our accesses to</span>
<span class="quote">&gt;-	 * this memory will trigger a page fault and let us analyze</span>
<span class="quote">&gt;-	 * the memory accesses.</span>
<span class="quote">&gt;-	 */</span>
<span class="quote">&gt;-	kmemcheck_hide_pages(page, pages);</span>
<span class="quote">&gt;-}</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-void kmemcheck_free_shadow(struct page *page, int order)</span>
<span class="quote">&gt;-{</span>
<span class="quote">&gt;-	struct page *shadow;</span>
<span class="quote">&gt;-	int pages;</span>
<span class="quote">&gt;-	int i;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	if (!kmemcheck_page_is_tracked(page))</span>
<span class="quote">&gt;-		return;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	pages = 1 &lt;&lt; order;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	kmemcheck_show_pages(page, pages);</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	shadow = virt_to_page(page[0].shadow);</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	for(i = 0; i &lt; pages; ++i)</span>
<span class="quote">&gt;-		page[i].shadow = NULL;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	__free_pages(shadow, order);</span>
<span class="quote">&gt;-}</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-void kmemcheck_slab_alloc(struct kmem_cache *s, gfp_t gfpflags, void *object,</span>
<span class="quote">&gt;-			  size_t size)</span>
<span class="quote">&gt;-{</span>
<span class="quote">&gt;-	if (unlikely(!object)) /* Skip object if allocation failed */</span>
<span class="quote">&gt;-		return;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	/*</span>
<span class="quote">&gt;-	 * Has already been memset(), which initializes the shadow for us</span>
<span class="quote">&gt;-	 * as well.</span>
<span class="quote">&gt;-	 */</span>
<span class="quote">&gt;-	if (gfpflags &amp; __GFP_ZERO)</span>
<span class="quote">&gt;-		return;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	/* No need to initialize the shadow of a non-tracked slab. */</span>
<span class="quote">&gt;-	if (s-&gt;flags &amp; SLAB_NOTRACK)</span>
<span class="quote">&gt;-		return;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	if (!kmemcheck_enabled || gfpflags &amp; __GFP_NOTRACK) {</span>
<span class="quote">&gt;-		/*</span>
<span class="quote">&gt;-		 * Allow notracked objects to be allocated from</span>
<span class="quote">&gt;-		 * tracked caches. Note however that these objects</span>
<span class="quote">&gt;-		 * will still get page faults on access, they just</span>
<span class="quote">&gt;-		 * won&#39;t ever be flagged as uninitialized. If page</span>
<span class="quote">&gt;-		 * faults are not acceptable, the slab cache itself</span>
<span class="quote">&gt;-		 * should be marked NOTRACK.</span>
<span class="quote">&gt;-		 */</span>
<span class="quote">&gt;-		kmemcheck_mark_initialized(object, size);</span>
<span class="quote">&gt;-	} else if (!s-&gt;ctor) {</span>
<span class="quote">&gt;-		/*</span>
<span class="quote">&gt;-		 * New objects should be marked uninitialized before</span>
<span class="quote">&gt;-		 * they&#39;re returned to the called.</span>
<span class="quote">&gt;-		 */</span>
<span class="quote">&gt;-		kmemcheck_mark_uninitialized(object, size);</span>
<span class="quote">&gt;-	}</span>
<span class="quote">&gt;-}</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-void kmemcheck_slab_free(struct kmem_cache *s, void *object, size_t size)</span>
<span class="quote">&gt;-{</span>
<span class="quote">&gt;-	/* TODO: RCU freeing is unsupported for now; hide false positives. */</span>
<span class="quote">&gt;-	if (!s-&gt;ctor &amp;&amp; !(s-&gt;flags &amp; SLAB_TYPESAFE_BY_RCU))</span>
<span class="quote">&gt;-		kmemcheck_mark_freed(object, size);</span>
<span class="quote">&gt;-}</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-void kmemcheck_pagealloc_alloc(struct page *page, unsigned int order,</span>
<span class="quote">&gt;-			       gfp_t gfpflags)</span>
<span class="quote">&gt;-{</span>
<span class="quote">&gt;-	int pages;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	if (gfpflags &amp; (__GFP_HIGHMEM | __GFP_NOTRACK))</span>
<span class="quote">&gt;-		return;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	pages = 1 &lt;&lt; order;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	/*</span>
<span class="quote">&gt;-	 * NOTE: We choose to track GFP_ZERO pages too; in fact, they</span>
<span class="quote">&gt;-	 * can become uninitialized by copying uninitialized memory</span>
<span class="quote">&gt;-	 * into them.</span>
<span class="quote">&gt;-	 */</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	/* XXX: Can use zone-&gt;node for node? */</span>
<span class="quote">&gt;-	kmemcheck_alloc_shadow(page, order, gfpflags, -1);</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-	if (gfpflags &amp; __GFP_ZERO)</span>
<span class="quote">&gt;-		kmemcheck_mark_initialized_pages(page, pages);</span>
<span class="quote">&gt;-	else</span>
<span class="quote">&gt;-		kmemcheck_mark_uninitialized_pages(page, pages);</span>
<span class="quote">&gt;-}</span>
<span class="quote">&gt;diff --git a/mm/kmemleak.c b/mm/kmemleak.c</span>
<span class="quote">&gt;index 7780cd83a495..a74d878f06c3 100644</span>
<span class="quote">&gt;--- a/mm/kmemleak.c</span>
<span class="quote">&gt;+++ b/mm/kmemleak.c</span>
<span class="quote">&gt;@@ -110,7 +110,6 @@</span>
<span class="quote">&gt; #include &lt;linux/atomic.h&gt;</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; #include &lt;linux/kasan.h&gt;</span>
<span class="quote">&gt;-#include &lt;linux/kmemcheck.h&gt;</span>
<span class="quote">&gt; #include &lt;linux/kmemleak.h&gt;</span>
<span class="quote">&gt; #include &lt;linux/memory_hotplug.h&gt;</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;@@ -1238,9 +1237,6 @@ static bool update_checksum(struct kmemleak_object *object)</span>
<span class="quote">&gt; {</span>
<span class="quote">&gt; 	u32 old_csum = object-&gt;checksum;</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;-	if (!kmemcheck_is_obj_initialized(object-&gt;pointer, object-&gt;size))</span>
<span class="quote">&gt;-		return false;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt; 	kasan_disable_current();</span>
<span class="quote">&gt; 	object-&gt;checksum = crc32(0, (void *)object-&gt;pointer, object-&gt;size);</span>
<span class="quote">&gt; 	kasan_enable_current();</span>
<span class="quote">&gt;@@ -1314,11 +1310,6 @@ static void scan_block(void *_start, void *_end,</span>
<span class="quote">&gt; 		if (scan_should_stop())</span>
<span class="quote">&gt; 			break;</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;-		/* don&#39;t scan uninitialized memory */</span>
<span class="quote">&gt;-		if (!kmemcheck_is_obj_initialized((unsigned long)ptr,</span>
<span class="quote">&gt;-						  BYTES_PER_POINTER))</span>
<span class="quote">&gt;-			continue;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt; 		kasan_disable_current();</span>
<span class="quote">&gt; 		pointer = *ptr;</span>
<span class="quote">&gt; 		kasan_enable_current();</span>
<span class="quote">&gt;diff --git a/mm/page_alloc.c b/mm/page_alloc.c</span>
<span class="quote">&gt;index c841af88836a..606c398d409f 100644</span>
<span class="quote">&gt;--- a/mm/page_alloc.c</span>
<span class="quote">&gt;+++ b/mm/page_alloc.c</span>
<span class="quote">&gt;@@ -24,7 +24,6 @@</span>
<span class="quote">&gt; #include &lt;linux/memblock.h&gt;</span>
<span class="quote">&gt; #include &lt;linux/compiler.h&gt;</span>
<span class="quote">&gt; #include &lt;linux/kernel.h&gt;</span>
<span class="quote">&gt;-#include &lt;linux/kmemcheck.h&gt;</span>
<span class="quote">&gt; #include &lt;linux/kasan.h&gt;</span>
<span class="quote">&gt; #include &lt;linux/module.h&gt;</span>
<span class="quote">&gt; #include &lt;linux/suspend.h&gt;</span>
<span class="quote">&gt;@@ -1013,7 +1012,6 @@ static __always_inline bool free_pages_prepare(struct page *page,</span>
<span class="quote">&gt; 	VM_BUG_ON_PAGE(PageTail(page), page);</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; 	trace_mm_page_free(page, order);</span>
<span class="quote">&gt;-	kmemcheck_free_shadow(page, order);</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; 	/*</span>
<span class="quote">&gt; 	 * Check tail pages before head page information is cleared to</span>
<span class="quote">&gt;@@ -2669,15 +2667,6 @@ void split_page(struct page *page, unsigned int order)</span>
<span class="quote">&gt; 	VM_BUG_ON_PAGE(PageCompound(page), page);</span>
<span class="quote">&gt; 	VM_BUG_ON_PAGE(!page_count(page), page);</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;-#ifdef CONFIG_KMEMCHECK</span>
<span class="quote">&gt;-	/*</span>
<span class="quote">&gt;-	 * Split shadow pages too, because free(page[0]) would</span>
<span class="quote">&gt;-	 * otherwise free the whole shadow.</span>
<span class="quote">&gt;-	 */</span>
<span class="quote">&gt;-	if (kmemcheck_page_is_tracked(page))</span>
<span class="quote">&gt;-		split_page(virt_to_page(page[0].shadow), order);</span>
<span class="quote">&gt;-#endif</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt; 	for (i = 1; i &lt; (1 &lt;&lt; order); i++)</span>
<span class="quote">&gt; 		set_page_refcounted(page + i);</span>
<span class="quote">&gt; 	split_page_owner(page, order);</span>
<span class="quote">&gt;@@ -4223,9 +4212,6 @@ __alloc_pages_nodemask(gfp_t gfp_mask, unsigned int order, int preferred_nid,</span>
<span class="quote">&gt; 		page = NULL;</span>
<span class="quote">&gt; 	}</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;-	if (kmemcheck_enabled &amp;&amp; page)</span>
<span class="quote">&gt;-		kmemcheck_pagealloc_alloc(page, order, gfp_mask);</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt; 	trace_mm_page_alloc(page, order, alloc_mask, ac.migratetype);</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; 	return page;</span>
<span class="quote">&gt;diff --git a/mm/slab.c b/mm/slab.c</span>
<span class="quote">&gt;index 04dec48c3ed7..5f91bd387e2e 100644</span>
<span class="quote">&gt;--- a/mm/slab.c</span>
<span class="quote">&gt;+++ b/mm/slab.c</span>
<span class="quote">&gt;@@ -113,7 +113,6 @@</span>
<span class="quote">&gt; #include	&lt;linux/rtmutex.h&gt;</span>
<span class="quote">&gt; #include	&lt;linux/reciprocal_div.h&gt;</span>
<span class="quote">&gt; #include	&lt;linux/debugobjects.h&gt;</span>
<span class="quote">&gt;-#include	&lt;linux/kmemcheck.h&gt;</span>
<span class="quote">&gt; #include	&lt;linux/memory.h&gt;</span>
<span class="quote">&gt; #include	&lt;linux/prefetch.h&gt;</span>
<span class="quote">&gt; #include	&lt;linux/sched/task_stack.h&gt;</span>
<span class="quote">&gt;@@ -1412,7 +1411,7 @@ static struct page *kmem_getpages(struct kmem_cache *cachep, gfp_t flags,</span>
<span class="quote">&gt; 	if (cachep-&gt;flags &amp; SLAB_RECLAIM_ACCOUNT)</span>
<span class="quote">&gt; 		flags |= __GFP_RECLAIMABLE;</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;-	page = __alloc_pages_node(nodeid, flags | __GFP_NOTRACK, cachep-&gt;gfporder);</span>
<span class="quote">&gt;+	page = __alloc_pages_node(nodeid, flags, cachep-&gt;gfporder);</span>
<span class="quote">&gt; 	if (!page) {</span>
<span class="quote">&gt; 		slab_out_of_memory(cachep, flags, nodeid);</span>
<span class="quote">&gt; 		return NULL;</span>
<span class="quote">&gt;@@ -1434,15 +1433,6 @@ static struct page *kmem_getpages(struct kmem_cache *cachep, gfp_t flags,</span>
<span class="quote">&gt; 	if (sk_memalloc_socks() &amp;&amp; page_is_pfmemalloc(page))</span>
<span class="quote">&gt; 		SetPageSlabPfmemalloc(page);</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;-	if (kmemcheck_enabled &amp;&amp; !(cachep-&gt;flags &amp; SLAB_NOTRACK)) {</span>
<span class="quote">&gt;-		kmemcheck_alloc_shadow(page, cachep-&gt;gfporder, flags, nodeid);</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-		if (cachep-&gt;ctor)</span>
<span class="quote">&gt;-			kmemcheck_mark_uninitialized_pages(page, nr_pages);</span>
<span class="quote">&gt;-		else</span>
<span class="quote">&gt;-			kmemcheck_mark_unallocated_pages(page, nr_pages);</span>
<span class="quote">&gt;-	}</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt; 	return page;</span>
<span class="quote">&gt; }</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;@@ -1454,8 +1444,6 @@ static void kmem_freepages(struct kmem_cache *cachep, struct page *page)</span>
<span class="quote">&gt; 	int order = cachep-&gt;gfporder;</span>
<span class="quote">&gt; 	unsigned long nr_freed = (1 &lt;&lt; order);</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;-	kmemcheck_free_shadow(page, order);</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt; 	if (cachep-&gt;flags &amp; SLAB_RECLAIM_ACCOUNT)</span>
<span class="quote">&gt; 		mod_lruvec_page_state(page, NR_SLAB_RECLAIMABLE, -nr_freed);</span>
<span class="quote">&gt; 	else</span>
<span class="quote">&gt;@@ -3515,8 +3503,6 @@ void ___cache_free(struct kmem_cache *cachep, void *objp,</span>
<span class="quote">&gt; 	kmemleak_free_recursive(objp, cachep-&gt;flags);</span>
<span class="quote">&gt; 	objp = cache_free_debugcheck(cachep, objp, caller);</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;-	kmemcheck_slab_free(cachep, objp, cachep-&gt;object_size);</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt; 	/*</span>
<span class="quote">&gt; 	 * Skip calling cache_free_alien() when the platform is not numa.</span>
<span class="quote">&gt; 	 * This will avoid cache misses that happen while accessing slabp (which</span>
<span class="quote">&gt;diff --git a/mm/slab.h b/mm/slab.h</span>
<span class="quote">&gt;index 073362816acc..8ff05e5b592a 100644</span>
<span class="quote">&gt;--- a/mm/slab.h</span>
<span class="quote">&gt;+++ b/mm/slab.h</span>
<span class="quote">&gt;@@ -39,7 +39,6 @@ struct kmem_cache {</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; #include &lt;linux/memcontrol.h&gt;</span>
<span class="quote">&gt; #include &lt;linux/fault-inject.h&gt;</span>
<span class="quote">&gt;-#include &lt;linux/kmemcheck.h&gt;</span>
<span class="quote">&gt; #include &lt;linux/kasan.h&gt;</span>
<span class="quote">&gt; #include &lt;linux/kmemleak.h&gt;</span>
<span class="quote">&gt; #include &lt;linux/random.h&gt;</span>
<span class="quote">&gt;@@ -141,10 +140,10 @@ static inline unsigned long kmem_cache_flags(unsigned long object_size,</span>
<span class="quote">&gt; #if defined(CONFIG_SLAB)</span>
<span class="quote">&gt; #define SLAB_CACHE_FLAGS (SLAB_MEM_SPREAD | SLAB_NOLEAKTRACE | \</span>
<span class="quote">&gt; 			  SLAB_RECLAIM_ACCOUNT | SLAB_TEMPORARY | \</span>
<span class="quote">&gt;-			  SLAB_NOTRACK | SLAB_ACCOUNT)</span>
<span class="quote">&gt;+			  SLAB_ACCOUNT)</span>
<span class="quote">&gt; #elif defined(CONFIG_SLUB)</span>
<span class="quote">&gt; #define SLAB_CACHE_FLAGS (SLAB_NOLEAKTRACE | SLAB_RECLAIM_ACCOUNT | \</span>
<span class="quote">&gt;-			  SLAB_TEMPORARY | SLAB_NOTRACK | SLAB_ACCOUNT)</span>
<span class="quote">&gt;+			  SLAB_TEMPORARY | SLAB_ACCOUNT)</span>
<span class="quote">&gt; #else</span>
<span class="quote">&gt; #define SLAB_CACHE_FLAGS (0)</span>
<span class="quote">&gt; #endif</span>
<span class="quote">&gt;@@ -163,7 +162,6 @@ static inline unsigned long kmem_cache_flags(unsigned long object_size,</span>
<span class="quote">&gt; 			      SLAB_NOLEAKTRACE | \</span>
<span class="quote">&gt; 			      SLAB_RECLAIM_ACCOUNT | \</span>
<span class="quote">&gt; 			      SLAB_TEMPORARY | \</span>
<span class="quote">&gt;-			      SLAB_NOTRACK | \</span>
<span class="quote">&gt; 			      SLAB_ACCOUNT)</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; int __kmem_cache_shutdown(struct kmem_cache *);</span>
<span class="quote">&gt;@@ -438,7 +436,6 @@ static inline void slab_post_alloc_hook(struct kmem_cache *s, gfp_t flags,</span>
<span class="quote">&gt; 	for (i = 0; i &lt; size; i++) {</span>
<span class="quote">&gt; 		void *object = p[i];</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;-		kmemcheck_slab_alloc(s, flags, object, slab_ksize(s));</span>
<span class="quote">&gt; 		kmemleak_alloc_recursive(object, s-&gt;object_size, 1,</span>
<span class="quote">&gt; 					 s-&gt;flags, flags);</span>
<span class="quote">&gt; 		kasan_slab_alloc(s, object, flags);</span>
<span class="quote">&gt;diff --git a/mm/slab_common.c b/mm/slab_common.c</span>
<span class="quote">&gt;index 904a83be82de..a79c202eedca 100644</span>
<span class="quote">&gt;--- a/mm/slab_common.c</span>
<span class="quote">&gt;+++ b/mm/slab_common.c</span>
<span class="quote">&gt;@@ -43,7 +43,7 @@ static DECLARE_WORK(slab_caches_to_rcu_destroy_work,</span>
<span class="quote">&gt; 		SLAB_FAILSLAB | SLAB_KASAN)</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; #define SLAB_MERGE_SAME (SLAB_RECLAIM_ACCOUNT | SLAB_CACHE_DMA | \</span>
<span class="quote">&gt;-			 SLAB_NOTRACK | SLAB_ACCOUNT)</span>
<span class="quote">&gt;+			 SLAB_ACCOUNT)</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; /*</span>
<span class="quote">&gt;  * Merge control. If this is set then no merging of slab caches will occur.</span>
<span class="quote">&gt;diff --git a/mm/slub.c b/mm/slub.c</span>
<span class="quote">&gt;index 163352c537ab..acaffdb0050e 100644</span>
<span class="quote">&gt;--- a/mm/slub.c</span>
<span class="quote">&gt;+++ b/mm/slub.c</span>
<span class="quote">&gt;@@ -21,7 +21,6 @@</span>
<span class="quote">&gt; #include &lt;linux/notifier.h&gt;</span>
<span class="quote">&gt; #include &lt;linux/seq_file.h&gt;</span>
<span class="quote">&gt; #include &lt;linux/kasan.h&gt;</span>
<span class="quote">&gt;-#include &lt;linux/kmemcheck.h&gt;</span>
<span class="quote">&gt; #include &lt;linux/cpu.h&gt;</span>
<span class="quote">&gt; #include &lt;linux/cpuset.h&gt;</span>
<span class="quote">&gt; #include &lt;linux/mempolicy.h&gt;</span>
<span class="quote">&gt;@@ -1369,12 +1368,11 @@ static inline void *slab_free_hook(struct kmem_cache *s, void *x)</span>
<span class="quote">&gt; 	 * So in order to make the debug calls that expect irqs to be</span>
<span class="quote">&gt; 	 * disabled we need to disable interrupts temporarily.</span>
<span class="quote">&gt; 	 */</span>
<span class="quote">&gt;-#if defined(CONFIG_KMEMCHECK) || defined(CONFIG_LOCKDEP)</span>
<span class="quote">&gt;+#if defined(CONFIG_LOCKDEP)</span>
<span class="quote">&gt; 	{</span>
<span class="quote">&gt; 		unsigned long flags;</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; 		local_irq_save(flags);</span>
<span class="quote">&gt;-		kmemcheck_slab_free(s, x, s-&gt;object_size);</span>
<span class="quote">&gt; 		debug_check_no_locks_freed(x, s-&gt;object_size);</span>
<span class="quote">&gt; 		local_irq_restore(flags);</span>
<span class="quote">&gt; 	}</span>
<span class="quote">&gt;@@ -1398,8 +1396,7 @@ static inline void slab_free_freelist_hook(struct kmem_cache *s,</span>
<span class="quote">&gt;  * Compiler cannot detect this function can be removed if slab_free_hook()</span>
<span class="quote">&gt;  * evaluates to nothing.  Thus, catch all relevant config debug options here.</span>
<span class="quote">&gt;  */</span>
<span class="quote">&gt;-#if defined(CONFIG_KMEMCHECK) ||		\</span>
<span class="quote">&gt;-	defined(CONFIG_LOCKDEP)	||		\</span>
<span class="quote">&gt;+#if defined(CONFIG_LOCKDEP)	||		\</span>
<span class="quote">&gt; 	defined(CONFIG_DEBUG_KMEMLEAK) ||	\</span>
<span class="quote">&gt; 	defined(CONFIG_DEBUG_OBJECTS_FREE) ||	\</span>
<span class="quote">&gt; 	defined(CONFIG_KASAN)</span>
<span class="quote">&gt;@@ -1435,8 +1432,6 @@ static inline struct page *alloc_slab_page(struct kmem_cache *s,</span>
<span class="quote">&gt; 	struct page *page;</span>
<span class="quote">&gt; 	int order = oo_order(oo);</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;-	flags |= __GFP_NOTRACK;</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt; 	if (node == NUMA_NO_NODE)</span>
<span class="quote">&gt; 		page = alloc_pages(flags, order);</span>
<span class="quote">&gt; 	else</span>
<span class="quote">&gt;@@ -1595,22 +1590,6 @@ static struct page *allocate_slab(struct kmem_cache *s, gfp_t flags, int node)</span>
<span class="quote">&gt; 		stat(s, ORDER_FALLBACK);</span>
<span class="quote">&gt; 	}</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;-	if (kmemcheck_enabled &amp;&amp;</span>
<span class="quote">&gt;-	    !(s-&gt;flags &amp; (SLAB_NOTRACK | DEBUG_DEFAULT_FLAGS))) {</span>
<span class="quote">&gt;-		int pages = 1 &lt;&lt; oo_order(oo);</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-		kmemcheck_alloc_shadow(page, oo_order(oo), alloc_gfp, node);</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-		/*</span>
<span class="quote">&gt;-		 * Objects from caches that have a constructor don&#39;t get</span>
<span class="quote">&gt;-		 * cleared when they&#39;re allocated, so we need to do it here.</span>
<span class="quote">&gt;-		 */</span>
<span class="quote">&gt;-		if (s-&gt;ctor)</span>
<span class="quote">&gt;-			kmemcheck_mark_uninitialized_pages(page, pages);</span>
<span class="quote">&gt;-		else</span>
<span class="quote">&gt;-			kmemcheck_mark_unallocated_pages(page, pages);</span>
<span class="quote">&gt;-	}</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt; 	page-&gt;objects = oo_objects(oo);</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; 	order = compound_order(page);</span>
<span class="quote">&gt;@@ -1686,8 +1665,6 @@ static void __free_slab(struct kmem_cache *s, struct page *page)</span>
<span class="quote">&gt; 			check_object(s, page, p, SLUB_RED_INACTIVE);</span>
<span class="quote">&gt; 	}</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;-	kmemcheck_free_shadow(page, compound_order(page));</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt; 	mod_lruvec_page_state(page,</span>
<span class="quote">&gt; 		(s-&gt;flags &amp; SLAB_RECLAIM_ACCOUNT) ?</span>
<span class="quote">&gt; 		NR_SLAB_RECLAIMABLE : NR_SLAB_UNRECLAIMABLE,</span>
<span class="quote">&gt;@@ -3791,7 +3768,7 @@ static void *kmalloc_large_node(size_t size, gfp_t flags, int node)</span>
<span class="quote">&gt; 	struct page *page;</span>
<span class="quote">&gt; 	void *ptr = NULL;</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;-	flags |= __GFP_COMP | __GFP_NOTRACK;</span>
<span class="quote">&gt;+	flags |= __GFP_COMP;</span>
<span class="quote">&gt; 	page = alloc_pages_node(node, flags, get_order(size));</span>
<span class="quote">&gt; 	if (page)</span>
<span class="quote">&gt; 		ptr = page_address(page);</span>
<span class="quote">&gt;@@ -5654,8 +5631,6 @@ static char *create_unique_id(struct kmem_cache *s)</span>
<span class="quote">&gt; 		*p++ = &#39;a&#39;;</span>
<span class="quote">&gt; 	if (s-&gt;flags &amp; SLAB_CONSISTENCY_CHECKS)</span>
<span class="quote">&gt; 		*p++ = &#39;F&#39;;</span>
<span class="quote">&gt;-	if (!(s-&gt;flags &amp; SLAB_NOTRACK))</span>
<span class="quote">&gt;-		*p++ = &#39;t&#39;;</span>
<span class="quote">&gt; 	if (s-&gt;flags &amp; SLAB_ACCOUNT)</span>
<span class="quote">&gt; 		*p++ = &#39;A&#39;;</span>
<span class="quote">&gt; 	if (p != name + 1)</span>
<span class="quote">&gt;diff --git a/net/core/skbuff.c b/net/core/skbuff.c</span>
<span class="quote">&gt;index 16982de649b9..382d6155cd2e 100644</span>
<span class="quote">&gt;--- a/net/core/skbuff.c</span>
<span class="quote">&gt;+++ b/net/core/skbuff.c</span>
<span class="quote">&gt;@@ -41,7 +41,6 @@</span>
<span class="quote">&gt; #include &lt;linux/module.h&gt;</span>
<span class="quote">&gt; #include &lt;linux/types.h&gt;</span>
<span class="quote">&gt; #include &lt;linux/kernel.h&gt;</span>
<span class="quote">&gt;-#include &lt;linux/kmemcheck.h&gt;</span>
<span class="quote">&gt; #include &lt;linux/mm.h&gt;</span>
<span class="quote">&gt; #include &lt;linux/interrupt.h&gt;</span>
<span class="quote">&gt; #include &lt;linux/in.h&gt;</span>
<span class="quote">&gt;@@ -234,14 +233,12 @@ struct sk_buff *__alloc_skb(unsigned int size, gfp_t gfp_mask,</span>
<span class="quote">&gt; 	shinfo = skb_shinfo(skb);</span>
<span class="quote">&gt; 	memset(shinfo, 0, offsetof(struct skb_shared_info, dataref));</span>
<span class="quote">&gt; 	atomic_set(&amp;shinfo-&gt;dataref, 1);</span>
<span class="quote">&gt;-	kmemcheck_annotate_variable(shinfo-&gt;destructor_arg);</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; 	if (flags &amp; SKB_ALLOC_FCLONE) {</span>
<span class="quote">&gt; 		struct sk_buff_fclones *fclones;</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; 		fclones = container_of(skb, struct sk_buff_fclones, skb1);</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;-		kmemcheck_annotate_bitfield(&amp;fclones-&gt;skb2, flags1);</span>
<span class="quote">&gt; 		skb-&gt;fclone = SKB_FCLONE_ORIG;</span>
<span class="quote">&gt; 		refcount_set(&amp;fclones-&gt;fclone_ref, 1);</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;@@ -301,7 +298,6 @@ struct sk_buff *__build_skb(void *data, unsigned int frag_size)</span>
<span class="quote">&gt; 	shinfo = skb_shinfo(skb);</span>
<span class="quote">&gt; 	memset(shinfo, 0, offsetof(struct skb_shared_info, dataref));</span>
<span class="quote">&gt; 	atomic_set(&amp;shinfo-&gt;dataref, 1);</span>
<span class="quote">&gt;-	kmemcheck_annotate_variable(shinfo-&gt;destructor_arg);</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; 	return skb;</span>
<span class="quote">&gt; }</span>
<span class="quote">&gt;@@ -1279,7 +1275,6 @@ struct sk_buff *skb_clone(struct sk_buff *skb, gfp_t gfp_mask)</span>
<span class="quote">&gt; 		if (!n)</span>
<span class="quote">&gt; 			return NULL;</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;-		kmemcheck_annotate_bitfield(n, flags1);</span>
<span class="quote">&gt; 		n-&gt;fclone = SKB_FCLONE_UNAVAILABLE;</span>
<span class="quote">&gt; 	}</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;diff --git a/net/core/sock.c b/net/core/sock.c</span>
<span class="quote">&gt;index 9b7b6bbb2a23..f358370b4a2e 100644</span>
<span class="quote">&gt;--- a/net/core/sock.c</span>
<span class="quote">&gt;+++ b/net/core/sock.c</span>
<span class="quote">&gt;@@ -1469,8 +1469,6 @@ static struct sock *sk_prot_alloc(struct proto *prot, gfp_t priority,</span>
<span class="quote">&gt; 		sk = kmalloc(prot-&gt;obj_size, priority);</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; 	if (sk != NULL) {</span>
<span class="quote">&gt;-		kmemcheck_annotate_bitfield(sk, flags);</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt; 		if (security_sk_alloc(sk, family, priority))</span>
<span class="quote">&gt; 			goto out_free;</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;diff --git a/net/ipv4/inet_timewait_sock.c b/net/ipv4/inet_timewait_sock.c</span>
<span class="quote">&gt;index 5b039159e67a..d451b9f19b59 100644</span>
<span class="quote">&gt;--- a/net/ipv4/inet_timewait_sock.c</span>
<span class="quote">&gt;+++ b/net/ipv4/inet_timewait_sock.c</span>
<span class="quote">&gt;@@ -9,7 +9,6 @@</span>
<span class="quote">&gt;  */</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; #include &lt;linux/kernel.h&gt;</span>
<span class="quote">&gt;-#include &lt;linux/kmemcheck.h&gt;</span>
<span class="quote">&gt; #include &lt;linux/slab.h&gt;</span>
<span class="quote">&gt; #include &lt;linux/module.h&gt;</span>
<span class="quote">&gt; #include &lt;net/inet_hashtables.h&gt;</span>
<span class="quote">&gt;@@ -167,8 +166,6 @@ struct inet_timewait_sock *inet_twsk_alloc(const struct sock *sk,</span>
<span class="quote">&gt; 	if (tw) {</span>
<span class="quote">&gt; 		const struct inet_sock *inet = inet_sk(sk);</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;-		kmemcheck_annotate_bitfield(tw, flags);</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt; 		tw-&gt;tw_dr	    = dr;</span>
<span class="quote">&gt; 		/* Give us an identity. */</span>
<span class="quote">&gt; 		tw-&gt;tw_daddr	    = inet-&gt;inet_daddr;</span>
<span class="quote">&gt;diff --git a/net/ipv4/tcp_input.c b/net/ipv4/tcp_input.c</span>
<span class="quote">&gt;index c5d7656beeee..4d2e31273a25 100644</span>
<span class="quote">&gt;--- a/net/ipv4/tcp_input.c</span>
<span class="quote">&gt;+++ b/net/ipv4/tcp_input.c</span>
<span class="quote">&gt;@@ -6195,7 +6195,6 @@ struct request_sock *inet_reqsk_alloc(const struct request_sock_ops *ops,</span>
<span class="quote">&gt; 	if (req) {</span>
<span class="quote">&gt; 		struct inet_request_sock *ireq = inet_rsk(req);</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;-		kmemcheck_annotate_bitfield(ireq, flags);</span>
<span class="quote">&gt; 		ireq-&gt;opt = NULL;</span>
<span class="quote">&gt; #if IS_ENABLED(CONFIG_IPV6)</span>
<span class="quote">&gt; 		ireq-&gt;pktopts = NULL;</span>
<span class="quote">&gt;diff --git a/net/socket.c b/net/socket.c</span>
<span class="quote">&gt;index c729625eb5d3..42d8e9c9ccd5 100644</span>
<span class="quote">&gt;--- a/net/socket.c</span>
<span class="quote">&gt;+++ b/net/socket.c</span>
<span class="quote">&gt;@@ -568,7 +568,6 @@ struct socket *sock_alloc(void)</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; 	sock = SOCKET_I(inode);</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;-	kmemcheck_annotate_bitfield(sock, type);</span>
<span class="quote">&gt; 	inode-&gt;i_ino = get_next_ino();</span>
<span class="quote">&gt; 	inode-&gt;i_mode = S_IFSOCK | S_IRWXUGO;</span>
<span class="quote">&gt; 	inode-&gt;i_uid = current_fsuid();</span>
<span class="quote">&gt;diff --git a/scripts/kernel-doc b/scripts/kernel-doc</span>
<span class="quote">&gt;index 9d3eafea58f0..8323ff9dec71 100755</span>
<span class="quote">&gt;--- a/scripts/kernel-doc</span>
<span class="quote">&gt;+++ b/scripts/kernel-doc</span>
<span class="quote">&gt;@@ -2182,8 +2182,6 @@ sub dump_struct($$) {</span>
<span class="quote">&gt; 	# strip comments:</span>
<span class="quote">&gt; 	$members =~ s/\/\*.*?\*\///gos;</span>
<span class="quote">&gt; 	$nested =~ s/\/\*.*?\*\///gos;</span>
<span class="quote">&gt;-	# strip kmemcheck_bitfield_{begin,end}.*;</span>
<span class="quote">&gt;-	$members =~ s/kmemcheck_bitfield_.*?;//gos;</span>
<span class="quote">&gt; 	# strip attributes</span>
<span class="quote">&gt; 	$members =~ s/__attribute__\s*\(\([a-z,_\*\s\(\)]*\)\)//i;</span>
<span class="quote">&gt; 	$members =~ s/__aligned\s*\([^;]*\)//gos;</span>
<span class="quote">&gt;diff --git a/tools/include/linux/kmemcheck.h b/tools/include/linux/kmemcheck.h</span>
<span class="quote">&gt;deleted file mode 100644</span>
<span class="quote">&gt;index 94d598bc6abe..000000000000</span>
<span class="quote">&gt;--- a/tools/include/linux/kmemcheck.h</span>
<span class="quote">&gt;+++ /dev/null</span>
<span class="quote">&gt;@@ -1,8 +0,0 @@</span>
<span class="quote">&gt;-#ifndef _LIBLOCKDEP_LINUX_KMEMCHECK_H_</span>
<span class="quote">&gt;-#define _LIBLOCKDEP_LINUX_KMEMCHECK_H_</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-static inline void kmemcheck_mark_initialized(void *address, unsigned int n)</span>
<span class="quote">&gt;-{</span>
<span class="quote">&gt;-}</span>
<span class="quote">&gt;-</span>
<span class="quote">&gt;-#endif</span>
<span class="quote">&gt;diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c</span>
<span class="quote">&gt;index 24ee68ecdd42..988c4732fe5d 100644</span>
<span class="quote">&gt;--- a/tools/perf/builtin-kmem.c</span>
<span class="quote">&gt;+++ b/tools/perf/builtin-kmem.c</span>
<span class="quote">&gt;@@ -654,7 +654,6 @@ static const struct {</span>
<span class="quote">&gt; 	{ &quot;__GFP_RECLAIMABLE&quot;,		&quot;RC&quot; },</span>
<span class="quote">&gt; 	{ &quot;__GFP_MOVABLE&quot;,		&quot;M&quot; },</span>
<span class="quote">&gt; 	{ &quot;__GFP_ACCOUNT&quot;,		&quot;AC&quot; },</span>
<span class="quote">&gt;-	{ &quot;__GFP_NOTRACK&quot;,		&quot;NT&quot; },</span>
<span class="quote">&gt; 	{ &quot;__GFP_WRITE&quot;,		&quot;WR&quot; },</span>
<span class="quote">&gt; 	{ &quot;__GFP_RECLAIM&quot;,		&quot;R&quot; },</span>
<span class="quote">&gt; 	{ &quot;__GFP_DIRECT_RECLAIM&quot;,	&quot;DR&quot; },</span>
<span class="quote">&gt;-- </span>
<span class="quote">&gt;2.11.0</span>
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=137061">Michal Hocko</a> - Sept. 27, 2017, 3:02 p.m.</div>
<pre class="content">
On Wed 27-09-17 11:27:40, Sasha Levin wrote:
<span class="quote">&gt; 2 Years ago I proposed to kill kmemcheck:</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; &gt; As discussed on LSF/MM, kill kmemcheck.</span>
<span class="quote">&gt; &gt;</span>
<span class="quote">&gt; &gt; KASan is a replacement that is able to work without the limitation of</span>
<span class="quote">&gt; &gt; kmemcheck (single CPU, slow). KASan is already upstream.</span>
<span class="quote">&gt; &gt;</span>
<span class="quote">&gt; &gt; We are also not aware of any users of kmemcheck (or users who don&#39;t consider</span>
<span class="quote">&gt; &gt; KASan as a suitable replacement).</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; The only objection was that since KASAN wasn&#39;t supported by all GCC</span>
<span class="quote">&gt; versions provided by distros at that time we should hold off for 2</span>
<span class="quote">&gt; years, and try again.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Now that 2 years have passed, and all distros provide gcc that supports</span>
<span class="quote">&gt; KASAN, kill kmemcheck again for the very same reasons.</span>

This is just too large to review manually. How have you generated the
patch?

My compile test batery failed for i386 allyesconfig for some reason
which is not entirely clear to me (see attached).  I have applied on top
of dc972a67cc54585bd83ad811c4e9b6ab3dcd427e and that one compiles fine.
<span class="quote">
&gt; Cc: Steven Rostedt (VMware) &lt;rostedt@goodmis.org&gt;</span>
<span class="quote">&gt; Cc: David S. Miller &lt;davem@davemloft.net&gt;</span>
<span class="quote">&gt; Signed-off-by: Sasha Levin &lt;alexander.levin@verizon.com&gt;</span>

Anyway I fully support this removal. It is a lot of rarely used code and
KASAN is much more usable.
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=169497">Levin, Alexander</a> - Sept. 27, 2017, 3:24 p.m.</div>
<pre class="content">
On Wed, Sep 27, 2017 at 05:02:07PM +0200, Michal Hocko wrote:
<span class="quote">&gt;This is just too large to review manually. How have you generated the</span>
<span class="quote">&gt;patch?</span>

Manualy. Note that most of it (~95%) is the result of &#39;rm arch/x86/mm/kmemcheck&#39;.

Otherwise, I just removed all uses of __GFP_NOWARN/SLAB_NOWARN, and calls to
various annotations throughout the code.

I&#39;m not sure about i386 breakage, will take a look, doesn&#39;t seem to be too obvious.
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=156">Eric W. Biederman</a> - Sept. 27, 2017, 5:36 p.m.</div>
<pre class="content">
&quot;Levin, Alexander (Sasha Levin)&quot; &lt;alexander.levin@verizon.com&gt; writes:
<span class="quote">
&gt; On Wed, Sep 27, 2017 at 05:02:07PM +0200, Michal Hocko wrote:</span>
<span class="quote">&gt;&gt;This is just too large to review manually. How have you generated the</span>
<span class="quote">&gt;&gt;patch?</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; Manualy. Note that most of it (~95%) is the result of &#39;rm arch/x86/mm/kmemcheck&#39;.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; Otherwise, I just removed all uses of __GFP_NOWARN/SLAB_NOWARN, and calls to</span>
<span class="quote">&gt; various annotations throughout the code.</span>

Do you mean GFP_NOTRACK? GFP_NOWARN has a different meaning.
<span class="quote">
&gt; I&#39;m not sure about i386 breakage, will take a look, doesn&#39;t seem to be too obvious.</span>

Eric
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=169497">Levin, Alexander</a> - Sept. 27, 2017, 10:01 p.m.</div>
<pre class="content">
On Wed, Sep 27, 2017 at 12:36:27PM -0500, Eric W. Biederman wrote:
<span class="quote">&gt;&quot;Levin, Alexander (Sasha Levin)&quot; &lt;alexander.levin@verizon.com&gt; writes:</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;&gt; On Wed, Sep 27, 2017 at 05:02:07PM +0200, Michal Hocko wrote:</span>
<span class="quote">&gt;&gt;&gt;This is just too large to review manually. How have you generated the</span>
<span class="quote">&gt;&gt;&gt;patch?</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; Manualy. Note that most of it (~95%) is the result of &#39;rm arch/x86/mm/kmemcheck&#39;.</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; Otherwise, I just removed all uses of __GFP_NOWARN/SLAB_NOWARN, and calls to</span>
<span class="quote">&gt;&gt; various annotations throughout the code.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;Do you mean GFP_NOTRACK? GFP_NOWARN has a different meaning.</span>

uh, yes, thanks Eric!

__GFP_NOTRACK and SLAB_NOTRACK.
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=310">Steven Rostedt</a> - Sept. 30, 2017, 9:48 a.m.</div>
<pre class="content">
On Wed, 27 Sep 2017 17:02:07 +0200
Michal Hocko &lt;mhocko@kernel.org&gt; wrote:
<span class="quote">
&gt; &gt; Now that 2 years have passed, and all distros provide gcc that supports</span>
<span class="quote">&gt; &gt; KASAN, kill kmemcheck again for the very same reasons.  </span>
<span class="quote">&gt; </span>
<span class="quote">&gt; This is just too large to review manually. How have you generated the</span>
<span class="quote">&gt; patch?</span>

I agree. This needs to be taken out piece by piece, not in one go,
where there could be unexpected fallout.
<span class="quote">
&gt; </span>
<span class="quote">&gt; My compile test batery failed for i386 allyesconfig for some reason</span>
<span class="quote">&gt; which is not entirely clear to me (see attached).  I have applied on top</span>
<span class="quote">&gt; of dc972a67cc54585bd83ad811c4e9b6ab3dcd427e and that one compiles fine.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; &gt; Cc: Steven Rostedt (VMware) &lt;rostedt@goodmis.org&gt;</span>
<span class="quote">&gt; &gt; Cc: David S. Miller &lt;davem@davemloft.net&gt;</span>
<span class="quote">&gt; &gt; Signed-off-by: Sasha Levin &lt;alexander.levin@verizon.com&gt;  </span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Anyway I fully support this removal. It is a lot of rarely used code and</span>
<span class="quote">&gt; KASAN is much more usable.</span>

Now that my default compilers support KASAN, I&#39;m fine with this removal.

-- Steve
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/Documentation/admin-guide/kernel-parameters.txt b/Documentation/admin-guide/kernel-parameters.txt</span>
<span class="p_header">index 05496622b4ef..5e1e0e7ebee3 100644</span>
<span class="p_header">--- a/Documentation/admin-guide/kernel-parameters.txt</span>
<span class="p_header">+++ b/Documentation/admin-guide/kernel-parameters.txt</span>
<span class="p_chunk">@@ -1841,13 +1841,6 @@</span> <span class="p_context"></span>
 			Built with CONFIG_DEBUG_KMEMLEAK_DEFAULT_OFF=y,
 			the default is off.
 
<span class="p_del">-	kmemcheck=	[X86] Boot-time kmemcheck enable/disable/one-shot mode</span>
<span class="p_del">-			Valid arguments: 0, 1, 2</span>
<span class="p_del">-			kmemcheck=0 (disabled)</span>
<span class="p_del">-			kmemcheck=1 (enabled)</span>
<span class="p_del">-			kmemcheck=2 (one-shot mode)</span>
<span class="p_del">-			Default: 2 (one-shot mode)</span>
<span class="p_del">-</span>
 	kvm.ignore_msrs=[KVM] Ignore guest accesses to unhandled MSRs.
 			Default is 0 (don&#39;t ignore, but inject #GP)
 
<span class="p_header">diff --git a/Documentation/dev-tools/index.rst b/Documentation/dev-tools/index.rst</span>
<span class="p_header">index a81787cd47d7..e313925fb0fa 100644</span>
<span class="p_header">--- a/Documentation/dev-tools/index.rst</span>
<span class="p_header">+++ b/Documentation/dev-tools/index.rst</span>
<span class="p_chunk">@@ -21,7 +21,6 @@</span> <span class="p_context"> whole; patches welcome!</span>
    kasan
    ubsan
    kmemleak
<span class="p_del">-   kmemcheck</span>
    gdb-kernel-debugging
    kgdb
    kselftest
<span class="p_header">diff --git a/Documentation/dev-tools/kmemcheck.rst b/Documentation/dev-tools/kmemcheck.rst</span>
deleted file mode 100644
<span class="p_header">index 7f3d1985de74..000000000000</span>
<span class="p_header">--- a/Documentation/dev-tools/kmemcheck.rst</span>
<span class="p_header">+++ /dev/null</span>
<span class="p_chunk">@@ -1,733 +0,0 @@</span> <span class="p_context"></span>
<span class="p_del">-Getting started with kmemcheck</span>
<span class="p_del">-==============================</span>
<span class="p_del">-</span>
<span class="p_del">-Vegard Nossum &lt;vegardno@ifi.uio.no&gt;</span>
<span class="p_del">-</span>
<span class="p_del">-</span>
<span class="p_del">-Introduction</span>
<span class="p_del">-------------</span>
<span class="p_del">-</span>
<span class="p_del">-kmemcheck is a debugging feature for the Linux Kernel. More specifically, it</span>
<span class="p_del">-is a dynamic checker that detects and warns about some uses of uninitialized</span>
<span class="p_del">-memory.</span>
<span class="p_del">-</span>
<span class="p_del">-Userspace programmers might be familiar with Valgrind&#39;s memcheck. The main</span>
<span class="p_del">-difference between memcheck and kmemcheck is that memcheck works for userspace</span>
<span class="p_del">-programs only, and kmemcheck works for the kernel only. The implementations</span>
<span class="p_del">-are of course vastly different. Because of this, kmemcheck is not as accurate</span>
<span class="p_del">-as memcheck, but it turns out to be good enough in practice to discover real</span>
<span class="p_del">-programmer errors that the compiler is not able to find through static</span>
<span class="p_del">-analysis.</span>
<span class="p_del">-</span>
<span class="p_del">-Enabling kmemcheck on a kernel will probably slow it down to the extent that</span>
<span class="p_del">-the machine will not be usable for normal workloads such as e.g. an</span>
<span class="p_del">-interactive desktop. kmemcheck will also cause the kernel to use about twice</span>
<span class="p_del">-as much memory as normal. For this reason, kmemcheck is strictly a debugging</span>
<span class="p_del">-feature.</span>
<span class="p_del">-</span>
<span class="p_del">-</span>
<span class="p_del">-Downloading</span>
<span class="p_del">------------</span>
<span class="p_del">-</span>
<span class="p_del">-As of version 2.6.31-rc1, kmemcheck is included in the mainline kernel.</span>
<span class="p_del">-</span>
<span class="p_del">-</span>
<span class="p_del">-Configuring and compiling</span>
<span class="p_del">--------------------------</span>
<span class="p_del">-</span>
<span class="p_del">-kmemcheck only works for the x86 (both 32- and 64-bit) platform. A number of</span>
<span class="p_del">-configuration variables must have specific settings in order for the kmemcheck</span>
<span class="p_del">-menu to even appear in &quot;menuconfig&quot;. These are:</span>
<span class="p_del">-</span>
<span class="p_del">-- ``CONFIG_CC_OPTIMIZE_FOR_SIZE=n``</span>
<span class="p_del">-	This option is located under &quot;General setup&quot; / &quot;Optimize for size&quot;.</span>
<span class="p_del">-</span>
<span class="p_del">-	Without this, gcc will use certain optimizations that usually lead to</span>
<span class="p_del">-	false positive warnings from kmemcheck. An example of this is a 16-bit</span>
<span class="p_del">-	field in a struct, where gcc may load 32 bits, then discard the upper</span>
<span class="p_del">-	16 bits. kmemcheck sees only the 32-bit load, and may trigger a</span>
<span class="p_del">-	warning for the upper 16 bits (if they&#39;re uninitialized).</span>
<span class="p_del">-</span>
<span class="p_del">-- ``CONFIG_SLAB=y`` or ``CONFIG_SLUB=y``</span>
<span class="p_del">-	This option is located under &quot;General setup&quot; / &quot;Choose SLAB</span>
<span class="p_del">-	allocator&quot;.</span>
<span class="p_del">-</span>
<span class="p_del">-- ``CONFIG_FUNCTION_TRACER=n``</span>
<span class="p_del">-	This option is located under &quot;Kernel hacking&quot; / &quot;Tracers&quot; / &quot;Kernel</span>
<span class="p_del">-	Function Tracer&quot;</span>
<span class="p_del">-</span>
<span class="p_del">-	When function tracing is compiled in, gcc emits a call to another</span>
<span class="p_del">-	function at the beginning of every function. This means that when the</span>
<span class="p_del">-	page fault handler is called, the ftrace framework will be called</span>
<span class="p_del">-	before kmemcheck has had a chance to handle the fault. If ftrace then</span>
<span class="p_del">-	modifies memory that was tracked by kmemcheck, the result is an</span>
<span class="p_del">-	endless recursive page fault.</span>
<span class="p_del">-</span>
<span class="p_del">-- ``CONFIG_DEBUG_PAGEALLOC=n``</span>
<span class="p_del">-	This option is located under &quot;Kernel hacking&quot; / &quot;Memory Debugging&quot;</span>
<span class="p_del">-	/ &quot;Debug page memory allocations&quot;.</span>
<span class="p_del">-</span>
<span class="p_del">-In addition, I highly recommend turning on ``CONFIG_DEBUG_INFO=y``. This is also</span>
<span class="p_del">-located under &quot;Kernel hacking&quot;. With this, you will be able to get line number</span>
<span class="p_del">-information from the kmemcheck warnings, which is extremely valuable in</span>
<span class="p_del">-debugging a problem. This option is not mandatory, however, because it slows</span>
<span class="p_del">-down the compilation process and produces a much bigger kernel image.</span>
<span class="p_del">-</span>
<span class="p_del">-Now the kmemcheck menu should be visible (under &quot;Kernel hacking&quot; / &quot;Memory</span>
<span class="p_del">-Debugging&quot; / &quot;kmemcheck: trap use of uninitialized memory&quot;). Here follows</span>
<span class="p_del">-a description of the kmemcheck configuration variables:</span>
<span class="p_del">-</span>
<span class="p_del">-- ``CONFIG_KMEMCHECK``</span>
<span class="p_del">-	This must be enabled in order to use kmemcheck at all...</span>
<span class="p_del">-</span>
<span class="p_del">-- ``CONFIG_KMEMCHECK_``[``DISABLED`` | ``ENABLED`` | ``ONESHOT``]``_BY_DEFAULT``</span>
<span class="p_del">-	This option controls the status of kmemcheck at boot-time. &quot;Enabled&quot;</span>
<span class="p_del">-	will enable kmemcheck right from the start, &quot;disabled&quot; will boot the</span>
<span class="p_del">-	kernel as normal (but with the kmemcheck code compiled in, so it can</span>
<span class="p_del">-	be enabled at run-time after the kernel has booted), and &quot;one-shot&quot; is</span>
<span class="p_del">-	a special mode which will turn kmemcheck off automatically after</span>
<span class="p_del">-	detecting the first use of uninitialized memory.</span>
<span class="p_del">-</span>
<span class="p_del">-	If you are using kmemcheck to actively debug a problem, then you</span>
<span class="p_del">-	probably want to choose &quot;enabled&quot; here.</span>
<span class="p_del">-</span>
<span class="p_del">-	The one-shot mode is mostly useful in automated test setups because it</span>
<span class="p_del">-	can prevent floods of warnings and increase the chances of the machine</span>
<span class="p_del">-	surviving in case something is really wrong. In other cases, the one-</span>
<span class="p_del">-	shot mode could actually be counter-productive because it would turn</span>
<span class="p_del">-	itself off at the very first error -- in the case of a false positive</span>
<span class="p_del">-	too -- and this would come in the way of debugging the specific</span>
<span class="p_del">-	problem you were interested in.</span>
<span class="p_del">-</span>
<span class="p_del">-	If you would like to use your kernel as normal, but with a chance to</span>
<span class="p_del">-	enable kmemcheck in case of some problem, it might be a good idea to</span>
<span class="p_del">-	choose &quot;disabled&quot; here. When kmemcheck is disabled, most of the run-</span>
<span class="p_del">-	time overhead is not incurred, and the kernel will be almost as fast</span>
<span class="p_del">-	as normal.</span>
<span class="p_del">-</span>
<span class="p_del">-- ``CONFIG_KMEMCHECK_QUEUE_SIZE``</span>
<span class="p_del">-	Select the maximum number of error reports to store in an internal</span>
<span class="p_del">-	(fixed-size) buffer. Since errors can occur virtually anywhere and in</span>
<span class="p_del">-	any context, we need a temporary storage area which is guaranteed not</span>
<span class="p_del">-	to generate any other page faults when accessed. The queue will be</span>
<span class="p_del">-	emptied as soon as a tasklet may be scheduled. If the queue is full,</span>
<span class="p_del">-	new error reports will be lost.</span>
<span class="p_del">-</span>
<span class="p_del">-	The default value of 64 is probably fine. If some code produces more</span>
<span class="p_del">-	than 64 errors within an irqs-off section, then the code is likely to</span>
<span class="p_del">-	produce many, many more, too, and these additional reports seldom give</span>
<span class="p_del">-	any more information (the first report is usually the most valuable</span>
<span class="p_del">-	anyway).</span>
<span class="p_del">-</span>
<span class="p_del">-	This number might have to be adjusted if you are not using serial</span>
<span class="p_del">-	console or similar to capture the kernel log. If you are using the</span>
<span class="p_del">-	&quot;dmesg&quot; command to save the log, then getting a lot of kmemcheck</span>
<span class="p_del">-	warnings might overflow the kernel log itself, and the earlier reports</span>
<span class="p_del">-	will get lost in that way instead. Try setting this to 10 or so on</span>
<span class="p_del">-	such a setup.</span>
<span class="p_del">-</span>
<span class="p_del">-- ``CONFIG_KMEMCHECK_SHADOW_COPY_SHIFT``</span>
<span class="p_del">-	Select the number of shadow bytes to save along with each entry of the</span>
<span class="p_del">-	error-report queue. These bytes indicate what parts of an allocation</span>
<span class="p_del">-	are initialized, uninitialized, etc. and will be displayed when an</span>
<span class="p_del">-	error is detected to help the debugging of a particular problem.</span>
<span class="p_del">-</span>
<span class="p_del">-	The number entered here is actually the logarithm of the number of</span>
<span class="p_del">-	bytes that will be saved. So if you pick for example 5 here, kmemcheck</span>
<span class="p_del">-	will save 2^5 = 32 bytes.</span>
<span class="p_del">-</span>
<span class="p_del">-	The default value should be fine for debugging most problems. It also</span>
<span class="p_del">-	fits nicely within 80 columns.</span>
<span class="p_del">-</span>
<span class="p_del">-- ``CONFIG_KMEMCHECK_PARTIAL_OK``</span>
<span class="p_del">-	This option (when enabled) works around certain GCC optimizations that</span>
<span class="p_del">-	produce 32-bit reads from 16-bit variables where the upper 16 bits are</span>
<span class="p_del">-	thrown away afterwards.</span>
<span class="p_del">-</span>
<span class="p_del">-	The default value (enabled) is recommended. This may of course hide</span>
<span class="p_del">-	some real errors, but disabling it would probably produce a lot of</span>
<span class="p_del">-	false positives.</span>
<span class="p_del">-</span>
<span class="p_del">-- ``CONFIG_KMEMCHECK_BITOPS_OK``</span>
<span class="p_del">-	This option silences warnings that would be generated for bit-field</span>
<span class="p_del">-	accesses where not all the bits are initialized at the same time. This</span>
<span class="p_del">-	may also hide some real bugs.</span>
<span class="p_del">-</span>
<span class="p_del">-	This option is probably obsolete, or it should be replaced with</span>
<span class="p_del">-	the kmemcheck-/bitfield-annotations for the code in question. The</span>
<span class="p_del">-	default value is therefore fine.</span>
<span class="p_del">-</span>
<span class="p_del">-Now compile the kernel as usual.</span>
<span class="p_del">-</span>
<span class="p_del">-</span>
<span class="p_del">-How to use</span>
<span class="p_del">-----------</span>
<span class="p_del">-</span>
<span class="p_del">-Booting</span>
<span class="p_del">-~~~~~~~</span>
<span class="p_del">-</span>
<span class="p_del">-First some information about the command-line options. There is only one</span>
<span class="p_del">-option specific to kmemcheck, and this is called &quot;kmemcheck&quot;. It can be used</span>
<span class="p_del">-to override the default mode as chosen by the ``CONFIG_KMEMCHECK_*_BY_DEFAULT``</span>
<span class="p_del">-option. Its possible settings are:</span>
<span class="p_del">-</span>
<span class="p_del">-- ``kmemcheck=0`` (disabled)</span>
<span class="p_del">-- ``kmemcheck=1`` (enabled)</span>
<span class="p_del">-- ``kmemcheck=2`` (one-shot mode)</span>
<span class="p_del">-</span>
<span class="p_del">-If SLUB debugging has been enabled in the kernel, it may take precedence over</span>
<span class="p_del">-kmemcheck in such a way that the slab caches which are under SLUB debugging</span>
<span class="p_del">-will not be tracked by kmemcheck. In order to ensure that this doesn&#39;t happen</span>
<span class="p_del">-(even though it shouldn&#39;t by default), use SLUB&#39;s boot option ``slub_debug``,</span>
<span class="p_del">-like this: ``slub_debug=-``</span>
<span class="p_del">-</span>
<span class="p_del">-In fact, this option may also be used for fine-grained control over SLUB vs.</span>
<span class="p_del">-kmemcheck. For example, if the command line includes</span>
<span class="p_del">-``kmemcheck=1 slub_debug=,dentry``, then SLUB debugging will be used only</span>
<span class="p_del">-for the &quot;dentry&quot; slab cache, and with kmemcheck tracking all the other</span>
<span class="p_del">-caches. This is advanced usage, however, and is not generally recommended.</span>
<span class="p_del">-</span>
<span class="p_del">-</span>
<span class="p_del">-Run-time enable/disable</span>
<span class="p_del">-~~~~~~~~~~~~~~~~~~~~~~~</span>
<span class="p_del">-</span>
<span class="p_del">-When the kernel has booted, it is possible to enable or disable kmemcheck at</span>
<span class="p_del">-run-time. WARNING: This feature is still experimental and may cause false</span>
<span class="p_del">-positive warnings to appear. Therefore, try not to use this. If you find that</span>
<span class="p_del">-it doesn&#39;t work properly (e.g. you see an unreasonable amount of warnings), I</span>
<span class="p_del">-will be happy to take bug reports.</span>
<span class="p_del">-</span>
<span class="p_del">-Use the file ``/proc/sys/kernel/kmemcheck`` for this purpose, e.g.::</span>
<span class="p_del">-</span>
<span class="p_del">-	$ echo 0 &gt; /proc/sys/kernel/kmemcheck # disables kmemcheck</span>
<span class="p_del">-</span>
<span class="p_del">-The numbers are the same as for the ``kmemcheck=`` command-line option.</span>
<span class="p_del">-</span>
<span class="p_del">-</span>
<span class="p_del">-Debugging</span>
<span class="p_del">-~~~~~~~~~</span>
<span class="p_del">-</span>
<span class="p_del">-A typical report will look something like this::</span>
<span class="p_del">-</span>
<span class="p_del">-    WARNING: kmemcheck: Caught 32-bit read from uninitialized memory (ffff88003e4a2024)</span>
<span class="p_del">-    80000000000000000000000000000000000000000088ffff0000000000000000</span>
<span class="p_del">-     i i i i u u u u i i i i i i i i u u u u u u u u u u u u u u u u</span>
<span class="p_del">-             ^</span>
<span class="p_del">-</span>
<span class="p_del">-    Pid: 1856, comm: ntpdate Not tainted 2.6.29-rc5 #264 945P-A</span>
<span class="p_del">-    RIP: 0010:[&lt;ffffffff8104ede8&gt;]  [&lt;ffffffff8104ede8&gt;] __dequeue_signal+0xc8/0x190</span>
<span class="p_del">-    RSP: 0018:ffff88003cdf7d98  EFLAGS: 00210002</span>
<span class="p_del">-    RAX: 0000000000000030 RBX: ffff88003d4ea968 RCX: 0000000000000009</span>
<span class="p_del">-    RDX: ffff88003e5d6018 RSI: ffff88003e5d6024 RDI: ffff88003cdf7e84</span>
<span class="p_del">-    RBP: ffff88003cdf7db8 R08: ffff88003e5d6000 R09: 0000000000000000</span>
<span class="p_del">-    R10: 0000000000000080 R11: 0000000000000000 R12: 000000000000000e</span>
<span class="p_del">-    R13: ffff88003cdf7e78 R14: ffff88003d530710 R15: ffff88003d5a98c8</span>
<span class="p_del">-    FS:  0000000000000000(0000) GS:ffff880001982000(0063) knlGS:00000</span>
<span class="p_del">-    CS:  0010 DS: 002b ES: 002b CR0: 0000000080050033</span>
<span class="p_del">-    CR2: ffff88003f806ea0 CR3: 000000003c036000 CR4: 00000000000006a0</span>
<span class="p_del">-    DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000</span>
<span class="p_del">-    DR3: 0000000000000000 DR6: 00000000ffff4ff0 DR7: 0000000000000400</span>
<span class="p_del">-     [&lt;ffffffff8104f04e&gt;] dequeue_signal+0x8e/0x170</span>
<span class="p_del">-     [&lt;ffffffff81050bd8&gt;] get_signal_to_deliver+0x98/0x390</span>
<span class="p_del">-     [&lt;ffffffff8100b87d&gt;] do_notify_resume+0xad/0x7d0</span>
<span class="p_del">-     [&lt;ffffffff8100c7b5&gt;] int_signal+0x12/0x17</span>
<span class="p_del">-     [&lt;ffffffffffffffff&gt;] 0xffffffffffffffff</span>
<span class="p_del">-</span>
<span class="p_del">-The single most valuable information in this report is the RIP (or EIP on 32-</span>
<span class="p_del">-bit) value. This will help us pinpoint exactly which instruction that caused</span>
<span class="p_del">-the warning.</span>
<span class="p_del">-</span>
<span class="p_del">-If your kernel was compiled with ``CONFIG_DEBUG_INFO=y``, then all we have to do</span>
<span class="p_del">-is give this address to the addr2line program, like this::</span>
<span class="p_del">-</span>
<span class="p_del">-	$ addr2line -e vmlinux -i ffffffff8104ede8</span>
<span class="p_del">-	arch/x86/include/asm/string_64.h:12</span>
<span class="p_del">-	include/asm-generic/siginfo.h:287</span>
<span class="p_del">-	kernel/signal.c:380</span>
<span class="p_del">-	kernel/signal.c:410</span>
<span class="p_del">-</span>
<span class="p_del">-The &quot;``-e vmlinux``&quot; tells addr2line which file to look in. **IMPORTANT:**</span>
<span class="p_del">-This must be the vmlinux of the kernel that produced the warning in the</span>
<span class="p_del">-first place! If not, the line number information will almost certainly be</span>
<span class="p_del">-wrong.</span>
<span class="p_del">-</span>
<span class="p_del">-The &quot;``-i``&quot; tells addr2line to also print the line numbers of inlined</span>
<span class="p_del">-functions.  In this case, the flag was very important, because otherwise,</span>
<span class="p_del">-it would only have printed the first line, which is just a call to</span>
<span class="p_del">-``memcpy()``, which could be called from a thousand places in the kernel, and</span>
<span class="p_del">-is therefore not very useful.  These inlined functions would not show up in</span>
<span class="p_del">-the stack trace above, simply because the kernel doesn&#39;t load the extra</span>
<span class="p_del">-debugging information. This technique can of course be used with ordinary</span>
<span class="p_del">-kernel oopses as well.</span>
<span class="p_del">-</span>
<span class="p_del">-In this case, it&#39;s the caller of ``memcpy()`` that is interesting, and it can be</span>
<span class="p_del">-found in ``include/asm-generic/siginfo.h``, line 287::</span>
<span class="p_del">-</span>
<span class="p_del">-    281 static inline void copy_siginfo(struct siginfo *to, struct siginfo *from)</span>
<span class="p_del">-    282 {</span>
<span class="p_del">-    283         if (from-&gt;si_code &lt; 0)</span>
<span class="p_del">-    284                 memcpy(to, from, sizeof(*to));</span>
<span class="p_del">-    285         else</span>
<span class="p_del">-    286                 /* _sigchld is currently the largest know union member */</span>
<span class="p_del">-    287                 memcpy(to, from, __ARCH_SI_PREAMBLE_SIZE + sizeof(from-&gt;_sifields._sigchld));</span>
<span class="p_del">-    288 }</span>
<span class="p_del">-</span>
<span class="p_del">-Since this was a read (kmemcheck usually warns about reads only, though it can</span>
<span class="p_del">-warn about writes to unallocated or freed memory as well), it was probably the</span>
<span class="p_del">-&quot;from&quot; argument which contained some uninitialized bytes. Following the chain</span>
<span class="p_del">-of calls, we move upwards to see where &quot;from&quot; was allocated or initialized,</span>
<span class="p_del">-``kernel/signal.c``, line 380::</span>
<span class="p_del">-</span>
<span class="p_del">-    359 static void collect_signal(int sig, struct sigpending *list, siginfo_t *info)</span>
<span class="p_del">-    360 {</span>
<span class="p_del">-    ...</span>
<span class="p_del">-    367         list_for_each_entry(q, &amp;list-&gt;list, list) {</span>
<span class="p_del">-    368                 if (q-&gt;info.si_signo == sig) {</span>
<span class="p_del">-    369                         if (first)</span>
<span class="p_del">-    370                                 goto still_pending;</span>
<span class="p_del">-    371                         first = q;</span>
<span class="p_del">-    ...</span>
<span class="p_del">-    377         if (first) {</span>
<span class="p_del">-    378 still_pending:</span>
<span class="p_del">-    379                 list_del_init(&amp;first-&gt;list);</span>
<span class="p_del">-    380                 copy_siginfo(info, &amp;first-&gt;info);</span>
<span class="p_del">-    381                 __sigqueue_free(first);</span>
<span class="p_del">-    ...</span>
<span class="p_del">-    392         }</span>
<span class="p_del">-    393 }</span>
<span class="p_del">-</span>
<span class="p_del">-Here, it is ``&amp;first-&gt;info`` that is being passed on to ``copy_siginfo()``. The</span>
<span class="p_del">-variable ``first`` was found on a list -- passed in as the second argument to</span>
<span class="p_del">-``collect_signal()``. We  continue our journey through the stack, to figure out</span>
<span class="p_del">-where the item on &quot;list&quot; was allocated or initialized. We move to line 410::</span>
<span class="p_del">-</span>
<span class="p_del">-    395 static int __dequeue_signal(struct sigpending *pending, sigset_t *mask,</span>
<span class="p_del">-    396                         siginfo_t *info)</span>
<span class="p_del">-    397 {</span>
<span class="p_del">-    ...</span>
<span class="p_del">-    410                 collect_signal(sig, pending, info);</span>
<span class="p_del">-    ...</span>
<span class="p_del">-    414 }</span>
<span class="p_del">-</span>
<span class="p_del">-Now we need to follow the ``pending`` pointer, since that is being passed on to</span>
<span class="p_del">-``collect_signal()`` as ``list``. At this point, we&#39;ve run out of lines from the</span>
<span class="p_del">-&quot;addr2line&quot; output. Not to worry, we just paste the next addresses from the</span>
<span class="p_del">-kmemcheck stack dump, i.e.::</span>
<span class="p_del">-</span>
<span class="p_del">-     [&lt;ffffffff8104f04e&gt;] dequeue_signal+0x8e/0x170</span>
<span class="p_del">-     [&lt;ffffffff81050bd8&gt;] get_signal_to_deliver+0x98/0x390</span>
<span class="p_del">-     [&lt;ffffffff8100b87d&gt;] do_notify_resume+0xad/0x7d0</span>
<span class="p_del">-     [&lt;ffffffff8100c7b5&gt;] int_signal+0x12/0x17</span>
<span class="p_del">-</span>
<span class="p_del">-	$ addr2line -e vmlinux -i ffffffff8104f04e ffffffff81050bd8 \</span>
<span class="p_del">-		ffffffff8100b87d ffffffff8100c7b5</span>
<span class="p_del">-	kernel/signal.c:446</span>
<span class="p_del">-	kernel/signal.c:1806</span>
<span class="p_del">-	arch/x86/kernel/signal.c:805</span>
<span class="p_del">-	arch/x86/kernel/signal.c:871</span>
<span class="p_del">-	arch/x86/kernel/entry_64.S:694</span>
<span class="p_del">-</span>
<span class="p_del">-Remember that since these addresses were found on the stack and not as the</span>
<span class="p_del">-RIP value, they actually point to the _next_ instruction (they are return</span>
<span class="p_del">-addresses). This becomes obvious when we look at the code for line 446::</span>
<span class="p_del">-</span>
<span class="p_del">-    422 int dequeue_signal(struct task_struct *tsk, sigset_t *mask, siginfo_t *info)</span>
<span class="p_del">-    423 {</span>
<span class="p_del">-    ...</span>
<span class="p_del">-    431                 signr = __dequeue_signal(&amp;tsk-&gt;signal-&gt;shared_pending,</span>
<span class="p_del">-    432						 mask, info);</span>
<span class="p_del">-    433			/*</span>
<span class="p_del">-    434			 * itimer signal ?</span>
<span class="p_del">-    435			 *</span>
<span class="p_del">-    436			 * itimers are process shared and we restart periodic</span>
<span class="p_del">-    437			 * itimers in the signal delivery path to prevent DoS</span>
<span class="p_del">-    438			 * attacks in the high resolution timer case. This is</span>
<span class="p_del">-    439			 * compliant with the old way of self restarting</span>
<span class="p_del">-    440			 * itimers, as the SIGALRM is a legacy signal and only</span>
<span class="p_del">-    441			 * queued once. Changing the restart behaviour to</span>
<span class="p_del">-    442			 * restart the timer in the signal dequeue path is</span>
<span class="p_del">-    443			 * reducing the timer noise on heavy loaded !highres</span>
<span class="p_del">-    444			 * systems too.</span>
<span class="p_del">-    445			 */</span>
<span class="p_del">-    446			if (unlikely(signr == SIGALRM)) {</span>
<span class="p_del">-    ...</span>
<span class="p_del">-    489 }</span>
<span class="p_del">-</span>
<span class="p_del">-So instead of looking at 446, we should be looking at 431, which is the line</span>
<span class="p_del">-that executes just before 446. Here we see that what we are looking for is</span>
<span class="p_del">-``&amp;tsk-&gt;signal-&gt;shared_pending``.</span>
<span class="p_del">-</span>
<span class="p_del">-Our next task is now to figure out which function that puts items on this</span>
<span class="p_del">-``shared_pending`` list. A crude, but efficient tool, is ``git grep``::</span>
<span class="p_del">-</span>
<span class="p_del">-	$ git grep -n &#39;shared_pending&#39; kernel/</span>
<span class="p_del">-	...</span>
<span class="p_del">-	kernel/signal.c:828:	pending = group ? &amp;t-&gt;signal-&gt;shared_pending : &amp;t-&gt;pending;</span>
<span class="p_del">-	kernel/signal.c:1339:	pending = group ? &amp;t-&gt;signal-&gt;shared_pending : &amp;t-&gt;pending;</span>
<span class="p_del">-	...</span>
<span class="p_del">-</span>
<span class="p_del">-There were more results, but none of them were related to list operations,</span>
<span class="p_del">-and these were the only assignments. We inspect the line numbers more closely</span>
<span class="p_del">-and find that this is indeed where items are being added to the list::</span>
<span class="p_del">-</span>
<span class="p_del">-    816 static int send_signal(int sig, struct siginfo *info, struct task_struct *t,</span>
<span class="p_del">-    817				int group)</span>
<span class="p_del">-    818 {</span>
<span class="p_del">-    ...</span>
<span class="p_del">-    828		pending = group ? &amp;t-&gt;signal-&gt;shared_pending : &amp;t-&gt;pending;</span>
<span class="p_del">-    ...</span>
<span class="p_del">-    851		q = __sigqueue_alloc(t, GFP_ATOMIC, (sig &lt; SIGRTMIN &amp;&amp;</span>
<span class="p_del">-    852						     (is_si_special(info) ||</span>
<span class="p_del">-    853						      info-&gt;si_code &gt;= 0)));</span>
<span class="p_del">-    854		if (q) {</span>
<span class="p_del">-    855			list_add_tail(&amp;q-&gt;list, &amp;pending-&gt;list);</span>
<span class="p_del">-    ...</span>
<span class="p_del">-    890 }</span>
<span class="p_del">-</span>
<span class="p_del">-and::</span>
<span class="p_del">-</span>
<span class="p_del">-    1309 int send_sigqueue(struct sigqueue *q, struct task_struct *t, int group)</span>
<span class="p_del">-    1310 {</span>
<span class="p_del">-    ....</span>
<span class="p_del">-    1339	 pending = group ? &amp;t-&gt;signal-&gt;shared_pending : &amp;t-&gt;pending;</span>
<span class="p_del">-    1340	 list_add_tail(&amp;q-&gt;list, &amp;pending-&gt;list);</span>
<span class="p_del">-    ....</span>
<span class="p_del">-    1347 }</span>
<span class="p_del">-</span>
<span class="p_del">-In the first case, the list element we are looking for, ``q``, is being</span>
<span class="p_del">-returned from the function ``__sigqueue_alloc()``, which looks like an</span>
<span class="p_del">-allocation function.  Let&#39;s take a look at it::</span>
<span class="p_del">-</span>
<span class="p_del">-    187 static struct sigqueue *__sigqueue_alloc(struct task_struct *t, gfp_t flags,</span>
<span class="p_del">-    188						 int override_rlimit)</span>
<span class="p_del">-    189 {</span>
<span class="p_del">-    190		struct sigqueue *q = NULL;</span>
<span class="p_del">-    191		struct user_struct *user;</span>
<span class="p_del">-    192</span>
<span class="p_del">-    193		/*</span>
<span class="p_del">-    194		 * We won&#39;t get problems with the target&#39;s UID changing under us</span>
<span class="p_del">-    195		 * because changing it requires RCU be used, and if t != current, the</span>
<span class="p_del">-    196		 * caller must be holding the RCU readlock (by way of a spinlock) and</span>
<span class="p_del">-    197		 * we use RCU protection here</span>
<span class="p_del">-    198		 */</span>
<span class="p_del">-    199		user = get_uid(__task_cred(t)-&gt;user);</span>
<span class="p_del">-    200		atomic_inc(&amp;user-&gt;sigpending);</span>
<span class="p_del">-    201		if (override_rlimit ||</span>
<span class="p_del">-    202		    atomic_read(&amp;user-&gt;sigpending) &lt;=</span>
<span class="p_del">-    203				t-&gt;signal-&gt;rlim[RLIMIT_SIGPENDING].rlim_cur)</span>
<span class="p_del">-    204			q = kmem_cache_alloc(sigqueue_cachep, flags);</span>
<span class="p_del">-    205		if (unlikely(q == NULL)) {</span>
<span class="p_del">-    206			atomic_dec(&amp;user-&gt;sigpending);</span>
<span class="p_del">-    207			free_uid(user);</span>
<span class="p_del">-    208		} else {</span>
<span class="p_del">-    209			INIT_LIST_HEAD(&amp;q-&gt;list);</span>
<span class="p_del">-    210			q-&gt;flags = 0;</span>
<span class="p_del">-    211			q-&gt;user = user;</span>
<span class="p_del">-    212		}</span>
<span class="p_del">-    213</span>
<span class="p_del">-    214		return q;</span>
<span class="p_del">-    215 }</span>
<span class="p_del">-</span>
<span class="p_del">-We see that this function initializes ``q-&gt;list``, ``q-&gt;flags``, and</span>
<span class="p_del">-``q-&gt;user``. It seems that now is the time to look at the definition of</span>
<span class="p_del">-``struct sigqueue``, e.g.::</span>
<span class="p_del">-</span>
<span class="p_del">-    14 struct sigqueue {</span>
<span class="p_del">-    15	       struct list_head list;</span>
<span class="p_del">-    16	       int flags;</span>
<span class="p_del">-    17	       siginfo_t info;</span>
<span class="p_del">-    18	       struct user_struct *user;</span>
<span class="p_del">-    19 };</span>
<span class="p_del">-</span>
<span class="p_del">-And, you might remember, it was a ``memcpy()`` on ``&amp;first-&gt;info`` that</span>
<span class="p_del">-caused the warning, so this makes perfect sense. It also seems reasonable</span>
<span class="p_del">-to assume that it is the caller of ``__sigqueue_alloc()`` that has the</span>
<span class="p_del">-responsibility of filling out (initializing) this member.</span>
<span class="p_del">-</span>
<span class="p_del">-But just which fields of the struct were uninitialized? Let&#39;s look at</span>
<span class="p_del">-kmemcheck&#39;s report again::</span>
<span class="p_del">-</span>
<span class="p_del">-    WARNING: kmemcheck: Caught 32-bit read from uninitialized memory (ffff88003e4a2024)</span>
<span class="p_del">-    80000000000000000000000000000000000000000088ffff0000000000000000</span>
<span class="p_del">-     i i i i u u u u i i i i i i i i u u u u u u u u u u u u u u u u</span>
<span class="p_del">-	     ^</span>
<span class="p_del">-</span>
<span class="p_del">-These first two lines are the memory dump of the memory object itself, and</span>
<span class="p_del">-the shadow bytemap, respectively. The memory object itself is in this case</span>
<span class="p_del">-``&amp;first-&gt;info``. Just beware that the start of this dump is NOT the start</span>
<span class="p_del">-of the object itself! The position of the caret (^) corresponds with the</span>
<span class="p_del">-address of the read (ffff88003e4a2024).</span>
<span class="p_del">-</span>
<span class="p_del">-The shadow bytemap dump legend is as follows:</span>
<span class="p_del">-</span>
<span class="p_del">-- i: initialized</span>
<span class="p_del">-- u: uninitialized</span>
<span class="p_del">-- a: unallocated (memory has been allocated by the slab layer, but has not</span>
<span class="p_del">-  yet been handed off to anybody)</span>
<span class="p_del">-- f: freed (memory has been allocated by the slab layer, but has been freed</span>
<span class="p_del">-  by the previous owner)</span>
<span class="p_del">-</span>
<span class="p_del">-In order to figure out where (relative to the start of the object) the</span>
<span class="p_del">-uninitialized memory was located, we have to look at the disassembly. For</span>
<span class="p_del">-that, we&#39;ll need the RIP address again::</span>
<span class="p_del">-</span>
<span class="p_del">-    RIP: 0010:[&lt;ffffffff8104ede8&gt;]  [&lt;ffffffff8104ede8&gt;] __dequeue_signal+0xc8/0x190</span>
<span class="p_del">-</span>
<span class="p_del">-	$ objdump -d --no-show-raw-insn vmlinux | grep -C 8 ffffffff8104ede8:</span>
<span class="p_del">-	ffffffff8104edc8:	mov    %r8,0x8(%r8)</span>
<span class="p_del">-	ffffffff8104edcc:	test   %r10d,%r10d</span>
<span class="p_del">-	ffffffff8104edcf:	js     ffffffff8104ee88 &lt;__dequeue_signal+0x168&gt;</span>
<span class="p_del">-	ffffffff8104edd5:	mov    %rax,%rdx</span>
<span class="p_del">-	ffffffff8104edd8:	mov    $0xc,%ecx</span>
<span class="p_del">-	ffffffff8104eddd:	mov    %r13,%rdi</span>
<span class="p_del">-	ffffffff8104ede0:	mov    $0x30,%eax</span>
<span class="p_del">-	ffffffff8104ede5:	mov    %rdx,%rsi</span>
<span class="p_del">-	ffffffff8104ede8:	rep movsl %ds:(%rsi),%es:(%rdi)</span>
<span class="p_del">-	ffffffff8104edea:	test   $0x2,%al</span>
<span class="p_del">-	ffffffff8104edec:	je     ffffffff8104edf0 &lt;__dequeue_signal+0xd0&gt;</span>
<span class="p_del">-	ffffffff8104edee:	movsw  %ds:(%rsi),%es:(%rdi)</span>
<span class="p_del">-	ffffffff8104edf0:	test   $0x1,%al</span>
<span class="p_del">-	ffffffff8104edf2:	je     ffffffff8104edf5 &lt;__dequeue_signal+0xd5&gt;</span>
<span class="p_del">-	ffffffff8104edf4:	movsb  %ds:(%rsi),%es:(%rdi)</span>
<span class="p_del">-	ffffffff8104edf5:	mov    %r8,%rdi</span>
<span class="p_del">-	ffffffff8104edf8:	callq  ffffffff8104de60 &lt;__sigqueue_free&gt;</span>
<span class="p_del">-</span>
<span class="p_del">-As expected, it&#39;s the &quot;``rep movsl``&quot; instruction from the ``memcpy()``</span>
<span class="p_del">-that causes the warning. We know about ``REP MOVSL`` that it uses the register</span>
<span class="p_del">-``RCX`` to count the number of remaining iterations. By taking a look at the</span>
<span class="p_del">-register dump again (from the kmemcheck report), we can figure out how many</span>
<span class="p_del">-bytes were left to copy::</span>
<span class="p_del">-</span>
<span class="p_del">-    RAX: 0000000000000030 RBX: ffff88003d4ea968 RCX: 0000000000000009</span>
<span class="p_del">-</span>
<span class="p_del">-By looking at the disassembly, we also see that ``%ecx`` is being loaded</span>
<span class="p_del">-with the value ``$0xc`` just before (ffffffff8104edd8), so we are very</span>
<span class="p_del">-lucky. Keep in mind that this is the number of iterations, not bytes. And</span>
<span class="p_del">-since this is a &quot;long&quot; operation, we need to multiply by 4 to get the</span>
<span class="p_del">-number of bytes. So this means that the uninitialized value was encountered</span>
<span class="p_del">-at 4 * (0xc - 0x9) = 12 bytes from the start of the object.</span>
<span class="p_del">-</span>
<span class="p_del">-We can now try to figure out which field of the &quot;``struct siginfo``&quot; that</span>
<span class="p_del">-was not initialized. This is the beginning of the struct::</span>
<span class="p_del">-</span>
<span class="p_del">-    40 typedef struct siginfo {</span>
<span class="p_del">-    41	       int si_signo;</span>
<span class="p_del">-    42	       int si_errno;</span>
<span class="p_del">-    43	       int si_code;</span>
<span class="p_del">-    44</span>
<span class="p_del">-    45	       union {</span>
<span class="p_del">-    ..</span>
<span class="p_del">-    92	       } _sifields;</span>
<span class="p_del">-    93 } siginfo_t;</span>
<span class="p_del">-</span>
<span class="p_del">-On 64-bit, the int is 4 bytes long, so it must the union member that has</span>
<span class="p_del">-not been initialized. We can verify this using gdb::</span>
<span class="p_del">-</span>
<span class="p_del">-	$ gdb vmlinux</span>
<span class="p_del">-	...</span>
<span class="p_del">-	(gdb) p &amp;((struct siginfo *) 0)-&gt;_sifields</span>
<span class="p_del">-	$1 = (union {...} *) 0x10</span>
<span class="p_del">-</span>
<span class="p_del">-Actually, it seems that the union member is located at offset 0x10 -- which</span>
<span class="p_del">-means that gcc has inserted 4 bytes of padding between the members ``si_code``</span>
<span class="p_del">-and ``_sifields``. We can now get a fuller picture of the memory dump::</span>
<span class="p_del">-</span>
<span class="p_del">-		 _----------------------------=&gt; si_code</span>
<span class="p_del">-		/	 _--------------------=&gt; (padding)</span>
<span class="p_del">-	       |	/	 _------------=&gt; _sifields(._kill._pid)</span>
<span class="p_del">-	       |       |	/	 _----=&gt; _sifields(._kill._uid)</span>
<span class="p_del">-	       |       |       |	/</span>
<span class="p_del">-	-------|-------|-------|-------|</span>
<span class="p_del">-	80000000000000000000000000000000000000000088ffff0000000000000000</span>
<span class="p_del">-	 i i i i u u u u i i i i i i i i u u u u u u u u u u u u u u u u</span>
<span class="p_del">-</span>
<span class="p_del">-This allows us to realize another important fact: ``si_code`` contains the</span>
<span class="p_del">-value 0x80. Remember that x86 is little endian, so the first 4 bytes</span>
<span class="p_del">-&quot;80000000&quot; are really the number 0x00000080. With a bit of research, we</span>
<span class="p_del">-find that this is actually the constant ``SI_KERNEL`` defined in</span>
<span class="p_del">-``include/asm-generic/siginfo.h``::</span>
<span class="p_del">-</span>
<span class="p_del">-    144 #define SI_KERNEL	0x80		/* sent by the kernel from somewhere	 */</span>
<span class="p_del">-</span>
<span class="p_del">-This macro is used in exactly one place in the x86 kernel: In ``send_signal()``</span>
<span class="p_del">-in ``kernel/signal.c``::</span>
<span class="p_del">-</span>
<span class="p_del">-    816 static int send_signal(int sig, struct siginfo *info, struct task_struct *t,</span>
<span class="p_del">-    817				int group)</span>
<span class="p_del">-    818 {</span>
<span class="p_del">-    ...</span>
<span class="p_del">-    828		pending = group ? &amp;t-&gt;signal-&gt;shared_pending : &amp;t-&gt;pending;</span>
<span class="p_del">-    ...</span>
<span class="p_del">-    851		q = __sigqueue_alloc(t, GFP_ATOMIC, (sig &lt; SIGRTMIN &amp;&amp;</span>
<span class="p_del">-    852						     (is_si_special(info) ||</span>
<span class="p_del">-    853						      info-&gt;si_code &gt;= 0)));</span>
<span class="p_del">-    854		if (q) {</span>
<span class="p_del">-    855			list_add_tail(&amp;q-&gt;list, &amp;pending-&gt;list);</span>
<span class="p_del">-    856			switch ((unsigned long) info) {</span>
<span class="p_del">-    ...</span>
<span class="p_del">-    865			case (unsigned long) SEND_SIG_PRIV:</span>
<span class="p_del">-    866				q-&gt;info.si_signo = sig;</span>
<span class="p_del">-    867				q-&gt;info.si_errno = 0;</span>
<span class="p_del">-    868				q-&gt;info.si_code = SI_KERNEL;</span>
<span class="p_del">-    869				q-&gt;info.si_pid = 0;</span>
<span class="p_del">-    870				q-&gt;info.si_uid = 0;</span>
<span class="p_del">-    871				break;</span>
<span class="p_del">-    ...</span>
<span class="p_del">-    890 }</span>
<span class="p_del">-</span>
<span class="p_del">-Not only does this match with the ``.si_code`` member, it also matches the place</span>
<span class="p_del">-we found earlier when looking for where siginfo_t objects are enqueued on the</span>
<span class="p_del">-``shared_pending`` list.</span>
<span class="p_del">-</span>
<span class="p_del">-So to sum up: It seems that it is the padding introduced by the compiler</span>
<span class="p_del">-between two struct fields that is uninitialized, and this gets reported when</span>
<span class="p_del">-we do a ``memcpy()`` on the struct. This means that we have identified a false</span>
<span class="p_del">-positive warning.</span>
<span class="p_del">-</span>
<span class="p_del">-Normally, kmemcheck will not report uninitialized accesses in ``memcpy()`` calls</span>
<span class="p_del">-when both the source and destination addresses are tracked. (Instead, we copy</span>
<span class="p_del">-the shadow bytemap as well). In this case, the destination address clearly</span>
<span class="p_del">-was not tracked. We can dig a little deeper into the stack trace from above::</span>
<span class="p_del">-</span>
<span class="p_del">-	arch/x86/kernel/signal.c:805</span>
<span class="p_del">-	arch/x86/kernel/signal.c:871</span>
<span class="p_del">-	arch/x86/kernel/entry_64.S:694</span>
<span class="p_del">-</span>
<span class="p_del">-And we clearly see that the destination siginfo object is located on the</span>
<span class="p_del">-stack::</span>
<span class="p_del">-</span>
<span class="p_del">-    782 static void do_signal(struct pt_regs *regs)</span>
<span class="p_del">-    783 {</span>
<span class="p_del">-    784		struct k_sigaction ka;</span>
<span class="p_del">-    785		siginfo_t info;</span>
<span class="p_del">-    ...</span>
<span class="p_del">-    804		signr = get_signal_to_deliver(&amp;info, &amp;ka, regs, NULL);</span>
<span class="p_del">-    ...</span>
<span class="p_del">-    854 }</span>
<span class="p_del">-</span>
<span class="p_del">-And this ``&amp;info`` is what eventually gets passed to ``copy_siginfo()`` as the</span>
<span class="p_del">-destination argument.</span>
<span class="p_del">-</span>
<span class="p_del">-Now, even though we didn&#39;t find an actual error here, the example is still a</span>
<span class="p_del">-good one, because it shows how one would go about to find out what the report</span>
<span class="p_del">-was all about.</span>
<span class="p_del">-</span>
<span class="p_del">-</span>
<span class="p_del">-Annotating false positives</span>
<span class="p_del">-~~~~~~~~~~~~~~~~~~~~~~~~~~</span>
<span class="p_del">-</span>
<span class="p_del">-There are a few different ways to make annotations in the source code that</span>
<span class="p_del">-will keep kmemcheck from checking and reporting certain allocations. Here</span>
<span class="p_del">-they are:</span>
<span class="p_del">-</span>
<span class="p_del">-- ``__GFP_NOTRACK_FALSE_POSITIVE``</span>
<span class="p_del">-	This flag can be passed to ``kmalloc()`` or ``kmem_cache_alloc()``</span>
<span class="p_del">-	(therefore also to other functions that end up calling one of</span>
<span class="p_del">-	these) to indicate that the allocation should not be tracked</span>
<span class="p_del">-	because it would lead to a false positive report. This is a &quot;big</span>
<span class="p_del">-	hammer&quot; way of silencing kmemcheck; after all, even if the false</span>
<span class="p_del">-	positive pertains to particular field in a struct, for example, we</span>
<span class="p_del">-	will now lose the ability to find (real) errors in other parts of</span>
<span class="p_del">-	the same struct.</span>
<span class="p_del">-</span>
<span class="p_del">-	Example::</span>
<span class="p_del">-</span>
<span class="p_del">-	    /* No warnings will ever trigger on accessing any part of x */</span>
<span class="p_del">-	    x = kmalloc(sizeof *x, GFP_KERNEL | __GFP_NOTRACK_FALSE_POSITIVE);</span>
<span class="p_del">-</span>
<span class="p_del">-- ``kmemcheck_bitfield_begin(name)``/``kmemcheck_bitfield_end(name)`` and</span>
<span class="p_del">-	``kmemcheck_annotate_bitfield(ptr, name)``</span>
<span class="p_del">-	The first two of these three macros can be used inside struct</span>
<span class="p_del">-	definitions to signal, respectively, the beginning and end of a</span>
<span class="p_del">-	bitfield. Additionally, this will assign the bitfield a name, which</span>
<span class="p_del">-	is given as an argument to the macros.</span>
<span class="p_del">-</span>
<span class="p_del">-	Having used these markers, one can later use</span>
<span class="p_del">-	kmemcheck_annotate_bitfield() at the point of allocation, to indicate</span>
<span class="p_del">-	which parts of the allocation is part of a bitfield.</span>
<span class="p_del">-</span>
<span class="p_del">-	Example::</span>
<span class="p_del">-</span>
<span class="p_del">-	    struct foo {</span>
<span class="p_del">-		int x;</span>
<span class="p_del">-</span>
<span class="p_del">-		kmemcheck_bitfield_begin(flags);</span>
<span class="p_del">-		int flag_a:1;</span>
<span class="p_del">-		int flag_b:1;</span>
<span class="p_del">-		kmemcheck_bitfield_end(flags);</span>
<span class="p_del">-</span>
<span class="p_del">-		int y;</span>
<span class="p_del">-	    };</span>
<span class="p_del">-</span>
<span class="p_del">-	    struct foo *x = kmalloc(sizeof *x);</span>
<span class="p_del">-</span>
<span class="p_del">-	    /* No warnings will trigger on accessing the bitfield of x */</span>
<span class="p_del">-	    kmemcheck_annotate_bitfield(x, flags);</span>
<span class="p_del">-</span>
<span class="p_del">-	Note that ``kmemcheck_annotate_bitfield()`` can be used even before the</span>
<span class="p_del">-	return value of ``kmalloc()`` is checked -- in other words, passing NULL</span>
<span class="p_del">-	as the first argument is legal (and will do nothing).</span>
<span class="p_del">-</span>
<span class="p_del">-</span>
<span class="p_del">-Reporting errors</span>
<span class="p_del">-----------------</span>
<span class="p_del">-</span>
<span class="p_del">-As we have seen, kmemcheck will produce false positive reports. Therefore, it</span>
<span class="p_del">-is not very wise to blindly post kmemcheck warnings to mailing lists and</span>
<span class="p_del">-maintainers. Instead, I encourage maintainers and developers to find errors</span>
<span class="p_del">-in their own code. If you get a warning, you can try to work around it, try</span>
<span class="p_del">-to figure out if it&#39;s a real error or not, or simply ignore it. Most</span>
<span class="p_del">-developers know their own code and will quickly and efficiently determine the</span>
<span class="p_del">-root cause of a kmemcheck report. This is therefore also the most efficient</span>
<span class="p_del">-way to work with kmemcheck.</span>
<span class="p_del">-</span>
<span class="p_del">-That said, we (the kmemcheck maintainers) will always be on the lookout for</span>
<span class="p_del">-false positives that we can annotate and silence. So whatever you find,</span>
<span class="p_del">-please drop us a note privately! Kernel configs and steps to reproduce (if</span>
<span class="p_del">-available) are of course a great help too.</span>
<span class="p_del">-</span>
<span class="p_del">-Happy hacking!</span>
<span class="p_del">-</span>
<span class="p_del">-</span>
<span class="p_del">-Technical description</span>
<span class="p_del">----------------------</span>
<span class="p_del">-</span>
<span class="p_del">-kmemcheck works by marking memory pages non-present. This means that whenever</span>
<span class="p_del">-somebody attempts to access the page, a page fault is generated. The page</span>
<span class="p_del">-fault handler notices that the page was in fact only hidden, and so it calls</span>
<span class="p_del">-on the kmemcheck code to make further investigations.</span>
<span class="p_del">-</span>
<span class="p_del">-When the investigations are completed, kmemcheck &quot;shows&quot; the page by marking</span>
<span class="p_del">-it present (as it would be under normal circumstances). This way, the</span>
<span class="p_del">-interrupted code can continue as usual.</span>
<span class="p_del">-</span>
<span class="p_del">-But after the instruction has been executed, we should hide the page again, so</span>
<span class="p_del">-that we can catch the next access too! Now kmemcheck makes use of a debugging</span>
<span class="p_del">-feature of the processor, namely single-stepping. When the processor has</span>
<span class="p_del">-finished the one instruction that generated the memory access, a debug</span>
<span class="p_del">-exception is raised. From here, we simply hide the page again and continue</span>
<span class="p_del">-execution, this time with the single-stepping feature turned off.</span>
<span class="p_del">-</span>
<span class="p_del">-kmemcheck requires some assistance from the memory allocator in order to work.</span>
<span class="p_del">-The memory allocator needs to</span>
<span class="p_del">-</span>
<span class="p_del">-  1. Tell kmemcheck about newly allocated pages and pages that are about to</span>
<span class="p_del">-     be freed. This allows kmemcheck to set up and tear down the shadow memory</span>
<span class="p_del">-     for the pages in question. The shadow memory stores the status of each</span>
<span class="p_del">-     byte in the allocation proper, e.g. whether it is initialized or</span>
<span class="p_del">-     uninitialized.</span>
<span class="p_del">-</span>
<span class="p_del">-  2. Tell kmemcheck which parts of memory should be marked uninitialized.</span>
<span class="p_del">-     There are actually a few more states, such as &quot;not yet allocated&quot; and</span>
<span class="p_del">-     &quot;recently freed&quot;.</span>
<span class="p_del">-</span>
<span class="p_del">-If a slab cache is set up using the SLAB_NOTRACK flag, it will never return</span>
<span class="p_del">-memory that can take page faults because of kmemcheck.</span>
<span class="p_del">-</span>
<span class="p_del">-If a slab cache is NOT set up using the SLAB_NOTRACK flag, callers can still</span>
<span class="p_del">-request memory with the __GFP_NOTRACK or __GFP_NOTRACK_FALSE_POSITIVE flags.</span>
<span class="p_del">-This does not prevent the page faults from occurring, however, but marks the</span>
<span class="p_del">-object in question as being initialized so that no warnings will ever be</span>
<span class="p_del">-produced for this object.</span>
<span class="p_del">-</span>
<span class="p_del">-Currently, the SLAB and SLUB allocators are supported by kmemcheck.</span>
<span class="p_header">diff --git a/MAINTAINERS b/MAINTAINERS</span>
<span class="p_header">index 6671f375f7fc..74eee2abeeb5 100644</span>
<span class="p_header">--- a/MAINTAINERS</span>
<span class="p_header">+++ b/MAINTAINERS</span>
<span class="p_chunk">@@ -7669,16 +7669,6 @@</span> <span class="p_context"> F:	include/linux/kdb.h</span>
 F:	include/linux/kgdb.h
 F:	kernel/debug/
 
<span class="p_del">-KMEMCHECK</span>
<span class="p_del">-M:	Vegard Nossum &lt;vegardno@ifi.uio.no&gt;</span>
<span class="p_del">-M:	Pekka Enberg &lt;penberg@kernel.org&gt;</span>
<span class="p_del">-S:	Maintained</span>
<span class="p_del">-F:	Documentation/dev-tools/kmemcheck.rst</span>
<span class="p_del">-F:	arch/x86/include/asm/kmemcheck.h</span>
<span class="p_del">-F:	arch/x86/mm/kmemcheck/</span>
<span class="p_del">-F:	include/linux/kmemcheck.h</span>
<span class="p_del">-F:	mm/kmemcheck.c</span>
<span class="p_del">-</span>
 KMEMLEAK
 M:	Catalin Marinas &lt;catalin.marinas@arm.com&gt;
 S:	Maintained
<span class="p_header">diff --git a/arch/arm/include/asm/dma-iommu.h b/arch/arm/include/asm/dma-iommu.h</span>
<span class="p_header">index c090ec675eac..5ad676f2de22 100644</span>
<span class="p_header">--- a/arch/arm/include/asm/dma-iommu.h</span>
<span class="p_header">+++ b/arch/arm/include/asm/dma-iommu.h</span>
<span class="p_chunk">@@ -6,7 +6,6 @@</span> <span class="p_context"></span>
 #include &lt;linux/mm_types.h&gt;
 #include &lt;linux/scatterlist.h&gt;
 #include &lt;linux/dma-debug.h&gt;
<span class="p_del">-#include &lt;linux/kmemcheck.h&gt;</span>
 #include &lt;linux/kref.h&gt;
 
 #define ARM_MAPPING_ERROR		(~(dma_addr_t)0x0)
<span class="p_header">diff --git a/arch/arm/include/asm/pgalloc.h b/arch/arm/include/asm/pgalloc.h</span>
<span class="p_header">index b2902a5cd780..2d7344f0e208 100644</span>
<span class="p_header">--- a/arch/arm/include/asm/pgalloc.h</span>
<span class="p_header">+++ b/arch/arm/include/asm/pgalloc.h</span>
<span class="p_chunk">@@ -57,7 +57,7 @@</span> <span class="p_context"> static inline void pud_populate(struct mm_struct *mm, pud_t *pud, pmd_t *pmd)</span>
 extern pgd_t *pgd_alloc(struct mm_struct *mm);
 extern void pgd_free(struct mm_struct *mm, pgd_t *pgd);
 
<span class="p_del">-#define PGALLOC_GFP	(GFP_KERNEL | __GFP_NOTRACK | __GFP_ZERO)</span>
<span class="p_add">+#define PGALLOC_GFP	(GFP_KERNEL | __GFP_ZERO)</span>
 
 static inline void clean_pte_table(pte_t *pte)
 {
<span class="p_header">diff --git a/arch/arm64/include/asm/pgalloc.h b/arch/arm64/include/asm/pgalloc.h</span>
<span class="p_header">index d25f4f137c2a..5ca6a573a701 100644</span>
<span class="p_header">--- a/arch/arm64/include/asm/pgalloc.h</span>
<span class="p_header">+++ b/arch/arm64/include/asm/pgalloc.h</span>
<span class="p_chunk">@@ -26,7 +26,7 @@</span> <span class="p_context"></span>
 
 #define check_pgt_cache()		do { } while (0)
 
<span class="p_del">-#define PGALLOC_GFP	(GFP_KERNEL | __GFP_NOTRACK | __GFP_ZERO)</span>
<span class="p_add">+#define PGALLOC_GFP	(GFP_KERNEL | __GFP_ZERO)</span>
 #define PGD_SIZE	(PTRS_PER_PGD * sizeof(pgd_t))
 
 #if CONFIG_PGTABLE_LEVELS &gt; 2
<span class="p_header">diff --git a/arch/openrisc/include/asm/dma-mapping.h b/arch/openrisc/include/asm/dma-mapping.h</span>
<span class="p_header">index f41bd3cb76d9..e212a1f0b6d2 100644</span>
<span class="p_header">--- a/arch/openrisc/include/asm/dma-mapping.h</span>
<span class="p_header">+++ b/arch/openrisc/include/asm/dma-mapping.h</span>
<span class="p_chunk">@@ -23,7 +23,6 @@</span> <span class="p_context"></span>
  */
 
 #include &lt;linux/dma-debug.h&gt;
<span class="p_del">-#include &lt;linux/kmemcheck.h&gt;</span>
 #include &lt;linux/dma-mapping.h&gt;
 
 extern const struct dma_map_ops or1k_dma_map_ops;
<span class="p_header">diff --git a/arch/powerpc/include/asm/pgalloc.h b/arch/powerpc/include/asm/pgalloc.h</span>
<span class="p_header">index 45ae1212ab8a..bb01297b617a 100644</span>
<span class="p_header">--- a/arch/powerpc/include/asm/pgalloc.h</span>
<span class="p_header">+++ b/arch/powerpc/include/asm/pgalloc.h</span>
<span class="p_chunk">@@ -17,7 +17,7 @@</span> <span class="p_context"> static inline gfp_t pgtable_gfp_flags(struct mm_struct *mm, gfp_t gfp)</span>
 }
 #endif /* MODULE */
 
<span class="p_del">-#define PGALLOC_GFP (GFP_KERNEL | __GFP_NOTRACK | __GFP_ZERO)</span>
<span class="p_add">+#define PGALLOC_GFP (GFP_KERNEL | __GFP_ZERO)</span>
 
 #ifdef CONFIG_PPC_BOOK3S
 #include &lt;asm/book3s/pgalloc.h&gt;
<span class="p_header">diff --git a/arch/sh/kernel/dwarf.c b/arch/sh/kernel/dwarf.c</span>
<span class="p_header">index e1d751ae2498..1a2526676a87 100644</span>
<span class="p_header">--- a/arch/sh/kernel/dwarf.c</span>
<span class="p_header">+++ b/arch/sh/kernel/dwarf.c</span>
<span class="p_chunk">@@ -1172,11 +1172,11 @@</span> <span class="p_context"> static int __init dwarf_unwinder_init(void)</span>
 
 	dwarf_frame_cachep = kmem_cache_create(&quot;dwarf_frames&quot;,
 			sizeof(struct dwarf_frame), 0,
<span class="p_del">-			SLAB_PANIC | SLAB_HWCACHE_ALIGN | SLAB_NOTRACK, NULL);</span>
<span class="p_add">+			SLAB_PANIC | SLAB_HWCACHE_ALIGN, NULL);</span>
 
 	dwarf_reg_cachep = kmem_cache_create(&quot;dwarf_regs&quot;,
 			sizeof(struct dwarf_reg), 0,
<span class="p_del">-			SLAB_PANIC | SLAB_HWCACHE_ALIGN | SLAB_NOTRACK, NULL);</span>
<span class="p_add">+			SLAB_PANIC | SLAB_HWCACHE_ALIGN, NULL);</span>
 
 	dwarf_frame_pool = mempool_create_slab_pool(DWARF_FRAME_MIN_REQ,
 						    dwarf_frame_cachep);
<span class="p_header">diff --git a/arch/sh/kernel/process.c b/arch/sh/kernel/process.c</span>
<span class="p_header">index f8a695a223dd..ded55e7461f8 100644</span>
<span class="p_header">--- a/arch/sh/kernel/process.c</span>
<span class="p_header">+++ b/arch/sh/kernel/process.c</span>
<span class="p_chunk">@@ -58,7 +58,7 @@</span> <span class="p_context"> void arch_task_cache_init(void)</span>
 
 	task_xstate_cachep = kmem_cache_create(&quot;task_xstate&quot;, xstate_size,
 					       __alignof__(union thread_xstate),
<span class="p_del">-					       SLAB_PANIC | SLAB_NOTRACK, NULL);</span>
<span class="p_add">+					       SLAB_PANIC, NULL);</span>
 }
 
 #ifdef CONFIG_SH_FPU_EMU
<span class="p_header">diff --git a/arch/sparc/mm/init_64.c b/arch/sparc/mm/init_64.c</span>
<span class="p_header">index b2ba410b26f4..78f79004be2c 100644</span>
<span class="p_header">--- a/arch/sparc/mm/init_64.c</span>
<span class="p_header">+++ b/arch/sparc/mm/init_64.c</span>
<span class="p_chunk">@@ -2926,7 +2926,7 @@</span> <span class="p_context"> void __flush_tlb_all(void)</span>
 pte_t *pte_alloc_one_kernel(struct mm_struct *mm,
 			    unsigned long address)
 {
<span class="p_del">-	struct page *page = alloc_page(GFP_KERNEL | __GFP_NOTRACK | __GFP_ZERO);</span>
<span class="p_add">+	struct page *page = alloc_page(GFP_KERNEL | __GFP_ZERO);</span>
 	pte_t *pte = NULL;
 
 	if (page)
<span class="p_chunk">@@ -2938,7 +2938,7 @@</span> <span class="p_context"> pte_t *pte_alloc_one_kernel(struct mm_struct *mm,</span>
 pgtable_t pte_alloc_one(struct mm_struct *mm,
 			unsigned long address)
 {
<span class="p_del">-	struct page *page = alloc_page(GFP_KERNEL | __GFP_NOTRACK | __GFP_ZERO);</span>
<span class="p_add">+	struct page *page = alloc_page(GFP_KERNEL | __GFP_ZERO);</span>
 	if (!page)
 		return NULL;
 	if (!pgtable_page_ctor(page)) {
<span class="p_header">diff --git a/arch/unicore32/include/asm/pgalloc.h b/arch/unicore32/include/asm/pgalloc.h</span>
<span class="p_header">index 26775793c204..f0fdb268f8f2 100644</span>
<span class="p_header">--- a/arch/unicore32/include/asm/pgalloc.h</span>
<span class="p_header">+++ b/arch/unicore32/include/asm/pgalloc.h</span>
<span class="p_chunk">@@ -28,7 +28,7 @@</span> <span class="p_context"> extern void free_pgd_slow(struct mm_struct *mm, pgd_t *pgd);</span>
 #define pgd_alloc(mm)			get_pgd_slow(mm)
 #define pgd_free(mm, pgd)		free_pgd_slow(mm, pgd)
 
<span class="p_del">-#define PGALLOC_GFP	(GFP_KERNEL | __GFP_NOTRACK | __GFP_ZERO)</span>
<span class="p_add">+#define PGALLOC_GFP	(GFP_KERNEL | __GFP_ZERO)</span>
 
 /*
  * Allocate one PTE table.
<span class="p_header">diff --git a/arch/x86/Kconfig b/arch/x86/Kconfig</span>
<span class="p_header">index 971feac13506..f2b6484a0b36 100644</span>
<span class="p_header">--- a/arch/x86/Kconfig</span>
<span class="p_header">+++ b/arch/x86/Kconfig</span>
<span class="p_chunk">@@ -109,7 +109,6 @@</span> <span class="p_context"> config X86</span>
 	select HAVE_ARCH_JUMP_LABEL
 	select HAVE_ARCH_KASAN			if X86_64 &amp;&amp; SPARSEMEM_VMEMMAP
 	select HAVE_ARCH_KGDB
<span class="p_del">-	select HAVE_ARCH_KMEMCHECK</span>
 	select HAVE_ARCH_MMAP_RND_BITS		if MMU
 	select HAVE_ARCH_MMAP_RND_COMPAT_BITS	if MMU &amp;&amp; COMPAT
 	select HAVE_ARCH_COMPAT_MMAP_BASES	if MMU &amp;&amp; COMPAT
<span class="p_chunk">@@ -1428,7 +1427,7 @@</span> <span class="p_context"> config ARCH_DMA_ADDR_T_64BIT</span>
 
 config X86_DIRECT_GBPAGES
 	def_bool y
<span class="p_del">-	depends on X86_64 &amp;&amp; !DEBUG_PAGEALLOC &amp;&amp; !KMEMCHECK</span>
<span class="p_add">+	depends on X86_64 &amp;&amp; !DEBUG_PAGEALLOC</span>
 	---help---
 	  Certain kernel features effectively disable kernel
 	  linear 1 GB mappings (even if the CPU otherwise
<span class="p_header">diff --git a/arch/x86/Makefile b/arch/x86/Makefile</span>
<span class="p_header">index 6276572259c8..559eb0a282fd 100644</span>
<span class="p_header">--- a/arch/x86/Makefile</span>
<span class="p_header">+++ b/arch/x86/Makefile</span>
<span class="p_chunk">@@ -157,11 +157,6 @@</span> <span class="p_context"> ifdef CONFIG_X86_X32</span>
 endif
 export CONFIG_X86_X32_ABI
 
<span class="p_del">-# Don&#39;t unroll struct assignments with kmemcheck enabled</span>
<span class="p_del">-ifeq ($(CONFIG_KMEMCHECK),y)</span>
<span class="p_del">-	KBUILD_CFLAGS += $(call cc-option,-fno-builtin-memcpy)</span>
<span class="p_del">-endif</span>
<span class="p_del">-</span>
 #
 # If the function graph tracer is used with mcount instead of fentry,
 # &#39;-maccumulate-outgoing-args&#39; is needed to prevent a GCC bug
<span class="p_header">diff --git a/arch/x86/include/asm/dma-mapping.h b/arch/x86/include/asm/dma-mapping.h</span>
<span class="p_header">index 1387dafdba2d..bd974c04c9aa 100644</span>
<span class="p_header">--- a/arch/x86/include/asm/dma-mapping.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/dma-mapping.h</span>
<span class="p_chunk">@@ -6,7 +6,6 @@</span> <span class="p_context"></span>
  * Documentation/DMA-API.txt for documentation.
  */
 
<span class="p_del">-#include &lt;linux/kmemcheck.h&gt;</span>
 #include &lt;linux/scatterlist.h&gt;
 #include &lt;linux/dma-debug.h&gt;
 #include &lt;asm/io.h&gt;
<span class="p_header">diff --git a/arch/x86/include/asm/kmemcheck.h b/arch/x86/include/asm/kmemcheck.h</span>
deleted file mode 100644
<span class="p_header">index ed01518f297e..000000000000</span>
<span class="p_header">--- a/arch/x86/include/asm/kmemcheck.h</span>
<span class="p_header">+++ /dev/null</span>
<span class="p_chunk">@@ -1,42 +0,0 @@</span> <span class="p_context"></span>
<span class="p_del">-#ifndef ASM_X86_KMEMCHECK_H</span>
<span class="p_del">-#define ASM_X86_KMEMCHECK_H</span>
<span class="p_del">-</span>
<span class="p_del">-#include &lt;linux/types.h&gt;</span>
<span class="p_del">-#include &lt;asm/ptrace.h&gt;</span>
<span class="p_del">-</span>
<span class="p_del">-#ifdef CONFIG_KMEMCHECK</span>
<span class="p_del">-bool kmemcheck_active(struct pt_regs *regs);</span>
<span class="p_del">-</span>
<span class="p_del">-void kmemcheck_show(struct pt_regs *regs);</span>
<span class="p_del">-void kmemcheck_hide(struct pt_regs *regs);</span>
<span class="p_del">-</span>
<span class="p_del">-bool kmemcheck_fault(struct pt_regs *regs,</span>
<span class="p_del">-	unsigned long address, unsigned long error_code);</span>
<span class="p_del">-bool kmemcheck_trap(struct pt_regs *regs);</span>
<span class="p_del">-#else</span>
<span class="p_del">-static inline bool kmemcheck_active(struct pt_regs *regs)</span>
<span class="p_del">-{</span>
<span class="p_del">-	return false;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static inline void kmemcheck_show(struct pt_regs *regs)</span>
<span class="p_del">-{</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static inline void kmemcheck_hide(struct pt_regs *regs)</span>
<span class="p_del">-{</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static inline bool kmemcheck_fault(struct pt_regs *regs,</span>
<span class="p_del">-	unsigned long address, unsigned long error_code)</span>
<span class="p_del">-{</span>
<span class="p_del">-	return false;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static inline bool kmemcheck_trap(struct pt_regs *regs)</span>
<span class="p_del">-{</span>
<span class="p_del">-	return false;</span>
<span class="p_del">-}</span>
<span class="p_del">-#endif /* CONFIG_KMEMCHECK */</span>
<span class="p_del">-</span>
<span class="p_del">-#endif</span>
<span class="p_header">diff --git a/arch/x86/include/asm/pgtable.h b/arch/x86/include/asm/pgtable.h</span>
<span class="p_header">index b714934512b3..d110e38893d1 100644</span>
<span class="p_header">--- a/arch/x86/include/asm/pgtable.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/pgtable.h</span>
<span class="p_chunk">@@ -666,11 +666,6 @@</span> <span class="p_context"> static inline bool pte_accessible(struct mm_struct *mm, pte_t a)</span>
 	return false;
 }
 
<span class="p_del">-static inline int pte_hidden(pte_t pte)</span>
<span class="p_del">-{</span>
<span class="p_del">-	return pte_flags(pte) &amp; _PAGE_HIDDEN;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
 static inline int pmd_present(pmd_t pmd)
 {
 	/*
<span class="p_header">diff --git a/arch/x86/include/asm/pgtable_types.h b/arch/x86/include/asm/pgtable_types.h</span>
<span class="p_header">index f1492473f10e..27e230dec7a4 100644</span>
<span class="p_header">--- a/arch/x86/include/asm/pgtable_types.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/pgtable_types.h</span>
<span class="p_chunk">@@ -31,7 +31,6 @@</span> <span class="p_context"></span>
 
 #define _PAGE_BIT_SPECIAL	_PAGE_BIT_SOFTW1
 #define _PAGE_BIT_CPA_TEST	_PAGE_BIT_SOFTW1
<span class="p_del">-#define _PAGE_BIT_HIDDEN	_PAGE_BIT_SOFTW3 /* hidden by kmemcheck */</span>
 #define _PAGE_BIT_SOFT_DIRTY	_PAGE_BIT_SOFTW3 /* software dirty tracking */
 #define _PAGE_BIT_DEVMAP	_PAGE_BIT_SOFTW4
 
<span class="p_chunk">@@ -78,18 +77,6 @@</span> <span class="p_context"></span>
 #define _PAGE_KNL_ERRATUM_MASK 0
 #endif
 
<span class="p_del">-#ifdef CONFIG_KMEMCHECK</span>
<span class="p_del">-#define _PAGE_HIDDEN	(_AT(pteval_t, 1) &lt;&lt; _PAGE_BIT_HIDDEN)</span>
<span class="p_del">-#else</span>
<span class="p_del">-#define _PAGE_HIDDEN	(_AT(pteval_t, 0))</span>
<span class="p_del">-#endif</span>
<span class="p_del">-</span>
<span class="p_del">-/*</span>
<span class="p_del">- * The same hidden bit is used by kmemcheck, but since kmemcheck</span>
<span class="p_del">- * works on kernel pages while soft-dirty engine on user space,</span>
<span class="p_del">- * they do not conflict with each other.</span>
<span class="p_del">- */</span>
<span class="p_del">-</span>
 #ifdef CONFIG_MEM_SOFT_DIRTY
 #define _PAGE_SOFT_DIRTY	(_AT(pteval_t, 1) &lt;&lt; _PAGE_BIT_SOFT_DIRTY)
 #else
<span class="p_header">diff --git a/arch/x86/include/asm/string_32.h b/arch/x86/include/asm/string_32.h</span>
<span class="p_header">index e371e7229042..00a4429ac12c 100644</span>
<span class="p_header">--- a/arch/x86/include/asm/string_32.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/string_32.h</span>
<span class="p_chunk">@@ -178,8 +178,6 @@</span> <span class="p_context"> static inline void *__memcpy3d(void *to, const void *from, size_t len)</span>
  *	No 3D Now!
  */
 
<span class="p_del">-#ifndef CONFIG_KMEMCHECK</span>
<span class="p_del">-</span>
 #if (__GNUC__ &gt;= 4)
 #define memcpy(t, f, n) __builtin_memcpy(t, f, n)
 #else
<span class="p_chunk">@@ -188,13 +186,6 @@</span> <span class="p_context"> static inline void *__memcpy3d(void *to, const void *from, size_t len)</span>
 	 ? __constant_memcpy((t), (f), (n))	\
 	 : __memcpy((t), (f), (n)))
 #endif
<span class="p_del">-#else</span>
<span class="p_del">-/*</span>
<span class="p_del">- * kmemcheck becomes very happy if we use the REP instructions unconditionally,</span>
<span class="p_del">- * because it means that we know both memory operands in advance.</span>
<span class="p_del">- */</span>
<span class="p_del">-#define memcpy(t, f, n) __memcpy((t), (f), (n))</span>
<span class="p_del">-#endif</span>
 
 #endif
 #endif /* !CONFIG_FORTIFY_SOURCE */
<span class="p_header">diff --git a/arch/x86/include/asm/string_64.h b/arch/x86/include/asm/string_64.h</span>
<span class="p_header">index f372a70a523f..08071875881d 100644</span>
<span class="p_header">--- a/arch/x86/include/asm/string_64.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/string_64.h</span>
<span class="p_chunk">@@ -32,7 +32,6 @@</span> <span class="p_context"> extern void *memcpy(void *to, const void *from, size_t len);</span>
 extern void *__memcpy(void *to, const void *from, size_t len);
 
 #ifndef CONFIG_FORTIFY_SOURCE
<span class="p_del">-#ifndef CONFIG_KMEMCHECK</span>
 #if (__GNUC__ == 4 &amp;&amp; __GNUC_MINOR__ &lt; 3) || __GNUC__ &lt; 4
 #define memcpy(dst, src, len)					\
 ({								\
<span class="p_chunk">@@ -45,13 +44,6 @@</span> <span class="p_context"> extern void *__memcpy(void *to, const void *from, size_t len);</span>
 	__ret;							\
 })
 #endif
<span class="p_del">-#else</span>
<span class="p_del">-/*</span>
<span class="p_del">- * kmemcheck becomes very happy if we use the REP instructions unconditionally,</span>
<span class="p_del">- * because it means that we know both memory operands in advance.</span>
<span class="p_del">- */</span>
<span class="p_del">-#define memcpy(dst, src, len) __inline_memcpy((dst), (src), (len))</span>
<span class="p_del">-#endif</span>
 #endif /* !CONFIG_FORTIFY_SOURCE */
 
 #define __HAVE_ARCH_MEMSET
<span class="p_header">diff --git a/arch/x86/include/asm/xor.h b/arch/x86/include/asm/xor.h</span>
<span class="p_header">index 1f5c5161ead6..3d58e95fe74c 100644</span>
<span class="p_header">--- a/arch/x86/include/asm/xor.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/xor.h</span>
<span class="p_chunk">@@ -1,7 +1,5 @@</span> <span class="p_context"></span>
<span class="p_del">-#ifdef CONFIG_KMEMCHECK</span>
<span class="p_del">-/* kmemcheck doesn&#39;t handle MMX/SSE/SSE2 instructions */</span>
 # include &lt;asm-generic/xor.h&gt;
<span class="p_del">-#elif !defined(_ASM_X86_XOR_H)</span>
<span class="p_add">+#if !defined(_ASM_X86_XOR_H)</span>
 #define _ASM_X86_XOR_H
 
 /*
<span class="p_header">diff --git a/arch/x86/kernel/cpu/intel.c b/arch/x86/kernel/cpu/intel.c</span>
<span class="p_header">index dfa90a3a5145..873ca226d0ce 100644</span>
<span class="p_header">--- a/arch/x86/kernel/cpu/intel.c</span>
<span class="p_header">+++ b/arch/x86/kernel/cpu/intel.c</span>
<span class="p_chunk">@@ -186,21 +186,6 @@</span> <span class="p_context"> static void early_init_intel(struct cpuinfo_x86 *c)</span>
 	if (c-&gt;x86 == 6 &amp;&amp; c-&gt;x86_model &lt; 15)
 		clear_cpu_cap(c, X86_FEATURE_PAT);
 
<span class="p_del">-#ifdef CONFIG_KMEMCHECK</span>
<span class="p_del">-	/*</span>
<span class="p_del">-	 * P4s have a &quot;fast strings&quot; feature which causes single-</span>
<span class="p_del">-	 * stepping REP instructions to only generate a #DB on</span>
<span class="p_del">-	 * cache-line boundaries.</span>
<span class="p_del">-	 *</span>
<span class="p_del">-	 * Ingo Molnar reported a Pentium D (model 6) and a Xeon</span>
<span class="p_del">-	 * (model 2) with the same problem.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	if (c-&gt;x86 == 15)</span>
<span class="p_del">-		if (msr_clear_bit(MSR_IA32_MISC_ENABLE,</span>
<span class="p_del">-				  MSR_IA32_MISC_ENABLE_FAST_STRING_BIT) &gt; 0)</span>
<span class="p_del">-			pr_info(&quot;kmemcheck: Disabling fast string operations\n&quot;);</span>
<span class="p_del">-#endif</span>
<span class="p_del">-</span>
 	/*
 	 * If fast string is not enabled in IA32_MISC_ENABLE for any reason,
 	 * clear the fast string and enhanced fast string CPU capabilities.
<span class="p_header">diff --git a/arch/x86/kernel/espfix_64.c b/arch/x86/kernel/espfix_64.c</span>
<span class="p_header">index 9c4e7ba6870c..cbded50ee601 100644</span>
<span class="p_header">--- a/arch/x86/kernel/espfix_64.c</span>
<span class="p_header">+++ b/arch/x86/kernel/espfix_64.c</span>
<span class="p_chunk">@@ -57,7 +57,7 @@</span> <span class="p_context"></span>
 # error &quot;Need more virtual address space for the ESPFIX hack&quot;
 #endif
 
<span class="p_del">-#define PGALLOC_GFP (GFP_KERNEL | __GFP_NOTRACK | __GFP_ZERO)</span>
<span class="p_add">+#define PGALLOC_GFP (GFP_KERNEL | __GFP_ZERO)</span>
 
 /* This contains the *bottom* address of the espfix stack */
 DEFINE_PER_CPU_READ_MOSTLY(unsigned long, espfix_stack);
<span class="p_header">diff --git a/arch/x86/kernel/traps.c b/arch/x86/kernel/traps.c</span>
<span class="p_header">index 34ea3651362e..869e6e0612f5 100644</span>
<span class="p_header">--- a/arch/x86/kernel/traps.c</span>
<span class="p_header">+++ b/arch/x86/kernel/traps.c</span>
<span class="p_chunk">@@ -42,7 +42,6 @@</span> <span class="p_context"></span>
 #include &lt;linux/edac.h&gt;
 #endif
 
<span class="p_del">-#include &lt;asm/kmemcheck.h&gt;</span>
 #include &lt;asm/stacktrace.h&gt;
 #include &lt;asm/processor.h&gt;
 #include &lt;asm/debugreg.h&gt;
<span class="p_chunk">@@ -740,10 +739,6 @@</span> <span class="p_context"> dotraplinkage void do_debug(struct pt_regs *regs, long error_code)</span>
 	if (!dr6 &amp;&amp; user_mode(regs))
 		user_icebp = 1;
 
<span class="p_del">-	/* Catch kmemcheck conditions! */</span>
<span class="p_del">-	if ((dr6 &amp; DR_STEP) &amp;&amp; kmemcheck_trap(regs))</span>
<span class="p_del">-		goto exit;</span>
<span class="p_del">-</span>
 	/* Store the virtualized DR6 value */
 	tsk-&gt;thread.debugreg6 = dr6;
 
<span class="p_header">diff --git a/arch/x86/mm/Makefile b/arch/x86/mm/Makefile</span>
<span class="p_header">index 72bf8c01c6e3..08042cf4a1db 100644</span>
<span class="p_header">--- a/arch/x86/mm/Makefile</span>
<span class="p_header">+++ b/arch/x86/mm/Makefile</span>
<span class="p_chunk">@@ -21,8 +21,6 @@</span> <span class="p_context"> obj-$(CONFIG_X86_PTDUMP)	+= debug_pagetables.o</span>
 
 obj-$(CONFIG_HIGHMEM)		+= highmem_32.o
 
<span class="p_del">-obj-$(CONFIG_KMEMCHECK)		+= kmemcheck/</span>
<span class="p_del">-</span>
 KASAN_SANITIZE_kasan_init_$(BITS).o := n
 obj-$(CONFIG_KASAN)		+= kasan_init_$(BITS).o
 
<span class="p_header">diff --git a/arch/x86/mm/fault.c b/arch/x86/mm/fault.c</span>
<span class="p_header">index 39567b5c33da..5452f2a55586 100644</span>
<span class="p_header">--- a/arch/x86/mm/fault.c</span>
<span class="p_header">+++ b/arch/x86/mm/fault.c</span>
<span class="p_chunk">@@ -19,7 +19,6 @@</span> <span class="p_context"></span>
 #include &lt;asm/cpufeature.h&gt;		/* boot_cpu_has, ...		*/
 #include &lt;asm/traps.h&gt;			/* dotraplinkage, ...		*/
 #include &lt;asm/pgalloc.h&gt;		/* pgd_*(), ...			*/
<span class="p_del">-#include &lt;asm/kmemcheck.h&gt;		/* kmemcheck_*(), ...		*/</span>
 #include &lt;asm/fixmap.h&gt;			/* VSYSCALL_ADDR		*/
 #include &lt;asm/vsyscall.h&gt;		/* emulate_vsyscall		*/
 #include &lt;asm/vm86.h&gt;			/* struct vm86			*/
<span class="p_chunk">@@ -1275,8 +1274,6 @@</span> <span class="p_context"> __do_page_fault(struct pt_regs *regs, unsigned long error_code,</span>
 	 * Detect and handle instructions that would cause a page fault for
 	 * both a tracked kernel page and a userspace page.
 	 */
<span class="p_del">-	if (kmemcheck_active(regs))</span>
<span class="p_del">-		kmemcheck_hide(regs);</span>
 	prefetchw(&amp;mm-&gt;mmap_sem);
 
 	if (unlikely(kmmio_fault(regs, address)))
<span class="p_chunk">@@ -1299,9 +1296,6 @@</span> <span class="p_context"> __do_page_fault(struct pt_regs *regs, unsigned long error_code,</span>
 		if (!(error_code &amp; (PF_RSVD | PF_USER | PF_PROT))) {
 			if (vmalloc_fault(address) &gt;= 0)
 				return;
<span class="p_del">-</span>
<span class="p_del">-			if (kmemcheck_fault(regs, address, error_code))</span>
<span class="p_del">-				return;</span>
 		}
 
 		/* Can handle a stale RO-&gt;RW TLB: */
<span class="p_header">diff --git a/arch/x86/mm/init.c b/arch/x86/mm/init.c</span>
<span class="p_header">index af5c1ed21d43..8b3fd7e8eb50 100644</span>
<span class="p_header">--- a/arch/x86/mm/init.c</span>
<span class="p_header">+++ b/arch/x86/mm/init.c</span>
<span class="p_chunk">@@ -92,8 +92,7 @@</span> <span class="p_context"> __ref void *alloc_low_pages(unsigned int num)</span>
 		unsigned int order;
 
 		order = get_order((unsigned long)num &lt;&lt; PAGE_SHIFT);
<span class="p_del">-		return (void *)__get_free_pages(GFP_ATOMIC | __GFP_NOTRACK |</span>
<span class="p_del">-						__GFP_ZERO, order);</span>
<span class="p_add">+		return (void *)__get_free_pages(GFP_ATOMIC | __GFP_ZERO, order);</span>
 	}
 
 	if ((pgt_buf_end + num) &gt; pgt_buf_top || !can_use_brk_pgt) {
<span class="p_chunk">@@ -164,12 +163,11 @@</span> <span class="p_context"> static int page_size_mask;</span>
 static void __init probe_page_size_mask(void)
 {
 	/*
<span class="p_del">-	 * For CONFIG_KMEMCHECK or pagealloc debugging, identity mapping will</span>
<span class="p_del">-	 * use small pages.</span>
<span class="p_add">+	 * For pagealloc debugging, identity mapping will use small pages.</span>
 	 * This will simplify cpa(), which otherwise needs to support splitting
 	 * large pages into small in interrupt context, etc.
 	 */
<span class="p_del">-	if (boot_cpu_has(X86_FEATURE_PSE) &amp;&amp; !debug_pagealloc_enabled() &amp;&amp; !IS_ENABLED(CONFIG_KMEMCHECK))</span>
<span class="p_add">+	if (boot_cpu_has(X86_FEATURE_PSE) &amp;&amp; !debug_pagealloc_enabled())</span>
 		page_size_mask |= 1 &lt;&lt; PG_LEVEL_2M;
 	else
 		direct_gbpages = 0;
<span class="p_header">diff --git a/arch/x86/mm/init_64.c b/arch/x86/mm/init_64.c</span>
<span class="p_header">index 048fbe8fc274..3f7ca42d1e22 100644</span>
<span class="p_header">--- a/arch/x86/mm/init_64.c</span>
<span class="p_header">+++ b/arch/x86/mm/init_64.c</span>
<span class="p_chunk">@@ -184,7 +184,7 @@</span> <span class="p_context"> static __ref void *spp_getpage(void)</span>
 	void *ptr;
 
 	if (after_bootmem)
<span class="p_del">-		ptr = (void *) get_zeroed_page(GFP_ATOMIC | __GFP_NOTRACK);</span>
<span class="p_add">+		ptr = (void *) get_zeroed_page(GFP_ATOMIC);</span>
 	else
 		ptr = alloc_bootmem_pages(PAGE_SIZE);
 
<span class="p_header">diff --git a/arch/x86/mm/kmemcheck/Makefile b/arch/x86/mm/kmemcheck/Makefile</span>
deleted file mode 100644
<span class="p_header">index 520b3bce4095..000000000000</span>
<span class="p_header">--- a/arch/x86/mm/kmemcheck/Makefile</span>
<span class="p_header">+++ /dev/null</span>
<span class="p_chunk">@@ -1 +0,0 @@</span> <span class="p_context"></span>
<span class="p_del">-obj-y := error.o kmemcheck.o opcode.o pte.o selftest.o shadow.o</span>
<span class="p_header">diff --git a/arch/x86/mm/kmemcheck/error.c b/arch/x86/mm/kmemcheck/error.c</span>
deleted file mode 100644
<span class="p_header">index dab41876cdd5..000000000000</span>
<span class="p_header">--- a/arch/x86/mm/kmemcheck/error.c</span>
<span class="p_header">+++ /dev/null</span>
<span class="p_chunk">@@ -1,227 +0,0 @@</span> <span class="p_context"></span>
<span class="p_del">-#include &lt;linux/interrupt.h&gt;</span>
<span class="p_del">-#include &lt;linux/kdebug.h&gt;</span>
<span class="p_del">-#include &lt;linux/kmemcheck.h&gt;</span>
<span class="p_del">-#include &lt;linux/kernel.h&gt;</span>
<span class="p_del">-#include &lt;linux/types.h&gt;</span>
<span class="p_del">-#include &lt;linux/ptrace.h&gt;</span>
<span class="p_del">-#include &lt;linux/stacktrace.h&gt;</span>
<span class="p_del">-#include &lt;linux/string.h&gt;</span>
<span class="p_del">-</span>
<span class="p_del">-#include &quot;error.h&quot;</span>
<span class="p_del">-#include &quot;shadow.h&quot;</span>
<span class="p_del">-</span>
<span class="p_del">-enum kmemcheck_error_type {</span>
<span class="p_del">-	KMEMCHECK_ERROR_INVALID_ACCESS,</span>
<span class="p_del">-	KMEMCHECK_ERROR_BUG,</span>
<span class="p_del">-};</span>
<span class="p_del">-</span>
<span class="p_del">-#define SHADOW_COPY_SIZE (1 &lt;&lt; CONFIG_KMEMCHECK_SHADOW_COPY_SHIFT)</span>
<span class="p_del">-</span>
<span class="p_del">-struct kmemcheck_error {</span>
<span class="p_del">-	enum kmemcheck_error_type type;</span>
<span class="p_del">-</span>
<span class="p_del">-	union {</span>
<span class="p_del">-		/* KMEMCHECK_ERROR_INVALID_ACCESS */</span>
<span class="p_del">-		struct {</span>
<span class="p_del">-			/* Kind of access that caused the error */</span>
<span class="p_del">-			enum kmemcheck_shadow state;</span>
<span class="p_del">-			/* Address and size of the erroneous read */</span>
<span class="p_del">-			unsigned long	address;</span>
<span class="p_del">-			unsigned int	size;</span>
<span class="p_del">-		};</span>
<span class="p_del">-	};</span>
<span class="p_del">-</span>
<span class="p_del">-	struct pt_regs		regs;</span>
<span class="p_del">-	struct stack_trace	trace;</span>
<span class="p_del">-	unsigned long		trace_entries[32];</span>
<span class="p_del">-</span>
<span class="p_del">-	/* We compress it to a char. */</span>
<span class="p_del">-	unsigned char		shadow_copy[SHADOW_COPY_SIZE];</span>
<span class="p_del">-	unsigned char		memory_copy[SHADOW_COPY_SIZE];</span>
<span class="p_del">-};</span>
<span class="p_del">-</span>
<span class="p_del">-/*</span>
<span class="p_del">- * Create a ring queue of errors to output. We can&#39;t call printk() directly</span>
<span class="p_del">- * from the kmemcheck traps, since this may call the console drivers and</span>
<span class="p_del">- * result in a recursive fault.</span>
<span class="p_del">- */</span>
<span class="p_del">-static struct kmemcheck_error error_fifo[CONFIG_KMEMCHECK_QUEUE_SIZE];</span>
<span class="p_del">-static unsigned int error_count;</span>
<span class="p_del">-static unsigned int error_rd;</span>
<span class="p_del">-static unsigned int error_wr;</span>
<span class="p_del">-static unsigned int error_missed_count;</span>
<span class="p_del">-</span>
<span class="p_del">-static struct kmemcheck_error *error_next_wr(void)</span>
<span class="p_del">-{</span>
<span class="p_del">-	struct kmemcheck_error *e;</span>
<span class="p_del">-</span>
<span class="p_del">-	if (error_count == ARRAY_SIZE(error_fifo)) {</span>
<span class="p_del">-		++error_missed_count;</span>
<span class="p_del">-		return NULL;</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">-	e = &amp;error_fifo[error_wr];</span>
<span class="p_del">-	if (++error_wr == ARRAY_SIZE(error_fifo))</span>
<span class="p_del">-		error_wr = 0;</span>
<span class="p_del">-	++error_count;</span>
<span class="p_del">-	return e;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static struct kmemcheck_error *error_next_rd(void)</span>
<span class="p_del">-{</span>
<span class="p_del">-	struct kmemcheck_error *e;</span>
<span class="p_del">-</span>
<span class="p_del">-	if (error_count == 0)</span>
<span class="p_del">-		return NULL;</span>
<span class="p_del">-</span>
<span class="p_del">-	e = &amp;error_fifo[error_rd];</span>
<span class="p_del">-	if (++error_rd == ARRAY_SIZE(error_fifo))</span>
<span class="p_del">-		error_rd = 0;</span>
<span class="p_del">-	--error_count;</span>
<span class="p_del">-	return e;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-void kmemcheck_error_recall(void)</span>
<span class="p_del">-{</span>
<span class="p_del">-	static const char *desc[] = {</span>
<span class="p_del">-		[KMEMCHECK_SHADOW_UNALLOCATED]		= &quot;unallocated&quot;,</span>
<span class="p_del">-		[KMEMCHECK_SHADOW_UNINITIALIZED]	= &quot;uninitialized&quot;,</span>
<span class="p_del">-		[KMEMCHECK_SHADOW_INITIALIZED]		= &quot;initialized&quot;,</span>
<span class="p_del">-		[KMEMCHECK_SHADOW_FREED]		= &quot;freed&quot;,</span>
<span class="p_del">-	};</span>
<span class="p_del">-</span>
<span class="p_del">-	static const char short_desc[] = {</span>
<span class="p_del">-		[KMEMCHECK_SHADOW_UNALLOCATED]		= &#39;a&#39;,</span>
<span class="p_del">-		[KMEMCHECK_SHADOW_UNINITIALIZED]	= &#39;u&#39;,</span>
<span class="p_del">-		[KMEMCHECK_SHADOW_INITIALIZED]		= &#39;i&#39;,</span>
<span class="p_del">-		[KMEMCHECK_SHADOW_FREED]		= &#39;f&#39;,</span>
<span class="p_del">-	};</span>
<span class="p_del">-</span>
<span class="p_del">-	struct kmemcheck_error *e;</span>
<span class="p_del">-	unsigned int i;</span>
<span class="p_del">-</span>
<span class="p_del">-	e = error_next_rd();</span>
<span class="p_del">-	if (!e)</span>
<span class="p_del">-		return;</span>
<span class="p_del">-</span>
<span class="p_del">-	switch (e-&gt;type) {</span>
<span class="p_del">-	case KMEMCHECK_ERROR_INVALID_ACCESS:</span>
<span class="p_del">-		printk(KERN_WARNING &quot;WARNING: kmemcheck: Caught %d-bit read from %s memory (%p)\n&quot;,</span>
<span class="p_del">-			8 * e-&gt;size, e-&gt;state &lt; ARRAY_SIZE(desc) ?</span>
<span class="p_del">-				desc[e-&gt;state] : &quot;(invalid shadow state)&quot;,</span>
<span class="p_del">-			(void *) e-&gt;address);</span>
<span class="p_del">-</span>
<span class="p_del">-		printk(KERN_WARNING);</span>
<span class="p_del">-		for (i = 0; i &lt; SHADOW_COPY_SIZE; ++i)</span>
<span class="p_del">-			printk(KERN_CONT &quot;%02x&quot;, e-&gt;memory_copy[i]);</span>
<span class="p_del">-		printk(KERN_CONT &quot;\n&quot;);</span>
<span class="p_del">-</span>
<span class="p_del">-		printk(KERN_WARNING);</span>
<span class="p_del">-		for (i = 0; i &lt; SHADOW_COPY_SIZE; ++i) {</span>
<span class="p_del">-			if (e-&gt;shadow_copy[i] &lt; ARRAY_SIZE(short_desc))</span>
<span class="p_del">-				printk(KERN_CONT &quot; %c&quot;, short_desc[e-&gt;shadow_copy[i]]);</span>
<span class="p_del">-			else</span>
<span class="p_del">-				printk(KERN_CONT &quot; ?&quot;);</span>
<span class="p_del">-		}</span>
<span class="p_del">-		printk(KERN_CONT &quot;\n&quot;);</span>
<span class="p_del">-		printk(KERN_WARNING &quot;%*c\n&quot;, 2 + 2</span>
<span class="p_del">-			* (int) (e-&gt;address &amp; (SHADOW_COPY_SIZE - 1)), &#39;^&#39;);</span>
<span class="p_del">-		break;</span>
<span class="p_del">-	case KMEMCHECK_ERROR_BUG:</span>
<span class="p_del">-		printk(KERN_EMERG &quot;ERROR: kmemcheck: Fatal error\n&quot;);</span>
<span class="p_del">-		break;</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">-	__show_regs(&amp;e-&gt;regs, 1);</span>
<span class="p_del">-	print_stack_trace(&amp;e-&gt;trace, 0);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static void do_wakeup(unsigned long data)</span>
<span class="p_del">-{</span>
<span class="p_del">-	while (error_count &gt; 0)</span>
<span class="p_del">-		kmemcheck_error_recall();</span>
<span class="p_del">-</span>
<span class="p_del">-	if (error_missed_count &gt; 0) {</span>
<span class="p_del">-		printk(KERN_WARNING &quot;kmemcheck: Lost %d error reports because &quot;</span>
<span class="p_del">-			&quot;the queue was too small\n&quot;, error_missed_count);</span>
<span class="p_del">-		error_missed_count = 0;</span>
<span class="p_del">-	}</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static DECLARE_TASKLET(kmemcheck_tasklet, &amp;do_wakeup, 0);</span>
<span class="p_del">-</span>
<span class="p_del">-/*</span>
<span class="p_del">- * Save the context of an error report.</span>
<span class="p_del">- */</span>
<span class="p_del">-void kmemcheck_error_save(enum kmemcheck_shadow state,</span>
<span class="p_del">-	unsigned long address, unsigned int size, struct pt_regs *regs)</span>
<span class="p_del">-{</span>
<span class="p_del">-	static unsigned long prev_ip;</span>
<span class="p_del">-</span>
<span class="p_del">-	struct kmemcheck_error *e;</span>
<span class="p_del">-	void *shadow_copy;</span>
<span class="p_del">-	void *memory_copy;</span>
<span class="p_del">-</span>
<span class="p_del">-	/* Don&#39;t report several adjacent errors from the same EIP. */</span>
<span class="p_del">-	if (regs-&gt;ip == prev_ip)</span>
<span class="p_del">-		return;</span>
<span class="p_del">-	prev_ip = regs-&gt;ip;</span>
<span class="p_del">-</span>
<span class="p_del">-	e = error_next_wr();</span>
<span class="p_del">-	if (!e)</span>
<span class="p_del">-		return;</span>
<span class="p_del">-</span>
<span class="p_del">-	e-&gt;type = KMEMCHECK_ERROR_INVALID_ACCESS;</span>
<span class="p_del">-</span>
<span class="p_del">-	e-&gt;state = state;</span>
<span class="p_del">-	e-&gt;address = address;</span>
<span class="p_del">-	e-&gt;size = size;</span>
<span class="p_del">-</span>
<span class="p_del">-	/* Save regs */</span>
<span class="p_del">-	memcpy(&amp;e-&gt;regs, regs, sizeof(*regs));</span>
<span class="p_del">-</span>
<span class="p_del">-	/* Save stack trace */</span>
<span class="p_del">-	e-&gt;trace.nr_entries = 0;</span>
<span class="p_del">-	e-&gt;trace.entries = e-&gt;trace_entries;</span>
<span class="p_del">-	e-&gt;trace.max_entries = ARRAY_SIZE(e-&gt;trace_entries);</span>
<span class="p_del">-	e-&gt;trace.skip = 0;</span>
<span class="p_del">-	save_stack_trace_regs(regs, &amp;e-&gt;trace);</span>
<span class="p_del">-</span>
<span class="p_del">-	/* Round address down to nearest 16 bytes */</span>
<span class="p_del">-	shadow_copy = kmemcheck_shadow_lookup(address</span>
<span class="p_del">-		&amp; ~(SHADOW_COPY_SIZE - 1));</span>
<span class="p_del">-	BUG_ON(!shadow_copy);</span>
<span class="p_del">-</span>
<span class="p_del">-	memcpy(e-&gt;shadow_copy, shadow_copy, SHADOW_COPY_SIZE);</span>
<span class="p_del">-</span>
<span class="p_del">-	kmemcheck_show_addr(address);</span>
<span class="p_del">-	memory_copy = (void *) (address &amp; ~(SHADOW_COPY_SIZE - 1));</span>
<span class="p_del">-	memcpy(e-&gt;memory_copy, memory_copy, SHADOW_COPY_SIZE);</span>
<span class="p_del">-	kmemcheck_hide_addr(address);</span>
<span class="p_del">-</span>
<span class="p_del">-	tasklet_hi_schedule_first(&amp;kmemcheck_tasklet);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-/*</span>
<span class="p_del">- * Save the context of a kmemcheck bug.</span>
<span class="p_del">- */</span>
<span class="p_del">-void kmemcheck_error_save_bug(struct pt_regs *regs)</span>
<span class="p_del">-{</span>
<span class="p_del">-	struct kmemcheck_error *e;</span>
<span class="p_del">-</span>
<span class="p_del">-	e = error_next_wr();</span>
<span class="p_del">-	if (!e)</span>
<span class="p_del">-		return;</span>
<span class="p_del">-</span>
<span class="p_del">-	e-&gt;type = KMEMCHECK_ERROR_BUG;</span>
<span class="p_del">-</span>
<span class="p_del">-	memcpy(&amp;e-&gt;regs, regs, sizeof(*regs));</span>
<span class="p_del">-</span>
<span class="p_del">-	e-&gt;trace.nr_entries = 0;</span>
<span class="p_del">-	e-&gt;trace.entries = e-&gt;trace_entries;</span>
<span class="p_del">-	e-&gt;trace.max_entries = ARRAY_SIZE(e-&gt;trace_entries);</span>
<span class="p_del">-	e-&gt;trace.skip = 1;</span>
<span class="p_del">-	save_stack_trace(&amp;e-&gt;trace);</span>
<span class="p_del">-</span>
<span class="p_del">-	tasklet_hi_schedule_first(&amp;kmemcheck_tasklet);</span>
<span class="p_del">-}</span>
<span class="p_header">diff --git a/arch/x86/mm/kmemcheck/error.h b/arch/x86/mm/kmemcheck/error.h</span>
deleted file mode 100644
<span class="p_header">index 0efc2e8d0a20..000000000000</span>
<span class="p_header">--- a/arch/x86/mm/kmemcheck/error.h</span>
<span class="p_header">+++ /dev/null</span>
<span class="p_chunk">@@ -1,15 +0,0 @@</span> <span class="p_context"></span>
<span class="p_del">-#ifndef ARCH__X86__MM__KMEMCHECK__ERROR_H</span>
<span class="p_del">-#define ARCH__X86__MM__KMEMCHECK__ERROR_H</span>
<span class="p_del">-</span>
<span class="p_del">-#include &lt;linux/ptrace.h&gt;</span>
<span class="p_del">-</span>
<span class="p_del">-#include &quot;shadow.h&quot;</span>
<span class="p_del">-</span>
<span class="p_del">-void kmemcheck_error_save(enum kmemcheck_shadow state,</span>
<span class="p_del">-	unsigned long address, unsigned int size, struct pt_regs *regs);</span>
<span class="p_del">-</span>
<span class="p_del">-void kmemcheck_error_save_bug(struct pt_regs *regs);</span>
<span class="p_del">-</span>
<span class="p_del">-void kmemcheck_error_recall(void);</span>
<span class="p_del">-</span>
<span class="p_del">-#endif</span>
<span class="p_header">diff --git a/arch/x86/mm/kmemcheck/kmemcheck.c b/arch/x86/mm/kmemcheck/kmemcheck.c</span>
deleted file mode 100644
<span class="p_header">index 4515bae36bbe..000000000000</span>
<span class="p_header">--- a/arch/x86/mm/kmemcheck/kmemcheck.c</span>
<span class="p_header">+++ /dev/null</span>
<span class="p_chunk">@@ -1,658 +0,0 @@</span> <span class="p_context"></span>
<span class="p_del">-/**</span>
<span class="p_del">- * kmemcheck - a heavyweight memory checker for the linux kernel</span>
<span class="p_del">- * Copyright (C) 2007, 2008  Vegard Nossum &lt;vegardno@ifi.uio.no&gt;</span>
<span class="p_del">- * (With a lot of help from Ingo Molnar and Pekka Enberg.)</span>
<span class="p_del">- *</span>
<span class="p_del">- * This program is free software; you can redistribute it and/or modify</span>
<span class="p_del">- * it under the terms of the GNU General Public License (version 2) as</span>
<span class="p_del">- * published by the Free Software Foundation.</span>
<span class="p_del">- */</span>
<span class="p_del">-</span>
<span class="p_del">-#include &lt;linux/init.h&gt;</span>
<span class="p_del">-#include &lt;linux/interrupt.h&gt;</span>
<span class="p_del">-#include &lt;linux/kallsyms.h&gt;</span>
<span class="p_del">-#include &lt;linux/kernel.h&gt;</span>
<span class="p_del">-#include &lt;linux/kmemcheck.h&gt;</span>
<span class="p_del">-#include &lt;linux/mm.h&gt;</span>
<span class="p_del">-#include &lt;linux/page-flags.h&gt;</span>
<span class="p_del">-#include &lt;linux/percpu.h&gt;</span>
<span class="p_del">-#include &lt;linux/ptrace.h&gt;</span>
<span class="p_del">-#include &lt;linux/string.h&gt;</span>
<span class="p_del">-#include &lt;linux/types.h&gt;</span>
<span class="p_del">-</span>
<span class="p_del">-#include &lt;asm/cacheflush.h&gt;</span>
<span class="p_del">-#include &lt;asm/kmemcheck.h&gt;</span>
<span class="p_del">-#include &lt;asm/pgtable.h&gt;</span>
<span class="p_del">-#include &lt;asm/tlbflush.h&gt;</span>
<span class="p_del">-</span>
<span class="p_del">-#include &quot;error.h&quot;</span>
<span class="p_del">-#include &quot;opcode.h&quot;</span>
<span class="p_del">-#include &quot;pte.h&quot;</span>
<span class="p_del">-#include &quot;selftest.h&quot;</span>
<span class="p_del">-#include &quot;shadow.h&quot;</span>
<span class="p_del">-</span>
<span class="p_del">-</span>
<span class="p_del">-#ifdef CONFIG_KMEMCHECK_DISABLED_BY_DEFAULT</span>
<span class="p_del">-#  define KMEMCHECK_ENABLED 0</span>
<span class="p_del">-#endif</span>
<span class="p_del">-</span>
<span class="p_del">-#ifdef CONFIG_KMEMCHECK_ENABLED_BY_DEFAULT</span>
<span class="p_del">-#  define KMEMCHECK_ENABLED 1</span>
<span class="p_del">-#endif</span>
<span class="p_del">-</span>
<span class="p_del">-#ifdef CONFIG_KMEMCHECK_ONESHOT_BY_DEFAULT</span>
<span class="p_del">-#  define KMEMCHECK_ENABLED 2</span>
<span class="p_del">-#endif</span>
<span class="p_del">-</span>
<span class="p_del">-int kmemcheck_enabled = KMEMCHECK_ENABLED;</span>
<span class="p_del">-</span>
<span class="p_del">-int __init kmemcheck_init(void)</span>
<span class="p_del">-{</span>
<span class="p_del">-#ifdef CONFIG_SMP</span>
<span class="p_del">-	/*</span>
<span class="p_del">-	 * Limit SMP to use a single CPU. We rely on the fact that this code</span>
<span class="p_del">-	 * runs before SMP is set up.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	if (setup_max_cpus &gt; 1) {</span>
<span class="p_del">-		printk(KERN_INFO</span>
<span class="p_del">-			&quot;kmemcheck: Limiting number of CPUs to 1.\n&quot;);</span>
<span class="p_del">-		setup_max_cpus = 1;</span>
<span class="p_del">-	}</span>
<span class="p_del">-#endif</span>
<span class="p_del">-</span>
<span class="p_del">-	if (!kmemcheck_selftest()) {</span>
<span class="p_del">-		printk(KERN_INFO &quot;kmemcheck: self-tests failed; disabling\n&quot;);</span>
<span class="p_del">-		kmemcheck_enabled = 0;</span>
<span class="p_del">-		return -EINVAL;</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">-	printk(KERN_INFO &quot;kmemcheck: Initialized\n&quot;);</span>
<span class="p_del">-	return 0;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-early_initcall(kmemcheck_init);</span>
<span class="p_del">-</span>
<span class="p_del">-/*</span>
<span class="p_del">- * We need to parse the kmemcheck= option before any memory is allocated.</span>
<span class="p_del">- */</span>
<span class="p_del">-static int __init param_kmemcheck(char *str)</span>
<span class="p_del">-{</span>
<span class="p_del">-	int val;</span>
<span class="p_del">-	int ret;</span>
<span class="p_del">-</span>
<span class="p_del">-	if (!str)</span>
<span class="p_del">-		return -EINVAL;</span>
<span class="p_del">-</span>
<span class="p_del">-	ret = kstrtoint(str, 0, &amp;val);</span>
<span class="p_del">-	if (ret)</span>
<span class="p_del">-		return ret;</span>
<span class="p_del">-	kmemcheck_enabled = val;</span>
<span class="p_del">-	return 0;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-early_param(&quot;kmemcheck&quot;, param_kmemcheck);</span>
<span class="p_del">-</span>
<span class="p_del">-int kmemcheck_show_addr(unsigned long address)</span>
<span class="p_del">-{</span>
<span class="p_del">-	pte_t *pte;</span>
<span class="p_del">-</span>
<span class="p_del">-	pte = kmemcheck_pte_lookup(address);</span>
<span class="p_del">-	if (!pte)</span>
<span class="p_del">-		return 0;</span>
<span class="p_del">-</span>
<span class="p_del">-	set_pte(pte, __pte(pte_val(*pte) | _PAGE_PRESENT));</span>
<span class="p_del">-	__flush_tlb_one(address);</span>
<span class="p_del">-	return 1;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-int kmemcheck_hide_addr(unsigned long address)</span>
<span class="p_del">-{</span>
<span class="p_del">-	pte_t *pte;</span>
<span class="p_del">-</span>
<span class="p_del">-	pte = kmemcheck_pte_lookup(address);</span>
<span class="p_del">-	if (!pte)</span>
<span class="p_del">-		return 0;</span>
<span class="p_del">-</span>
<span class="p_del">-	set_pte(pte, __pte(pte_val(*pte) &amp; ~_PAGE_PRESENT));</span>
<span class="p_del">-	__flush_tlb_one(address);</span>
<span class="p_del">-	return 1;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-struct kmemcheck_context {</span>
<span class="p_del">-	bool busy;</span>
<span class="p_del">-	int balance;</span>
<span class="p_del">-</span>
<span class="p_del">-	/*</span>
<span class="p_del">-	 * There can be at most two memory operands to an instruction, but</span>
<span class="p_del">-	 * each address can cross a page boundary -- so we may need up to</span>
<span class="p_del">-	 * four addresses that must be hidden/revealed for each fault.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	unsigned long addr[4];</span>
<span class="p_del">-	unsigned long n_addrs;</span>
<span class="p_del">-	unsigned long flags;</span>
<span class="p_del">-</span>
<span class="p_del">-	/* Data size of the instruction that caused a fault. */</span>
<span class="p_del">-	unsigned int size;</span>
<span class="p_del">-};</span>
<span class="p_del">-</span>
<span class="p_del">-static DEFINE_PER_CPU(struct kmemcheck_context, kmemcheck_context);</span>
<span class="p_del">-</span>
<span class="p_del">-bool kmemcheck_active(struct pt_regs *regs)</span>
<span class="p_del">-{</span>
<span class="p_del">-	struct kmemcheck_context *data = this_cpu_ptr(&amp;kmemcheck_context);</span>
<span class="p_del">-</span>
<span class="p_del">-	return data-&gt;balance &gt; 0;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-/* Save an address that needs to be shown/hidden */</span>
<span class="p_del">-static void kmemcheck_save_addr(unsigned long addr)</span>
<span class="p_del">-{</span>
<span class="p_del">-	struct kmemcheck_context *data = this_cpu_ptr(&amp;kmemcheck_context);</span>
<span class="p_del">-</span>
<span class="p_del">-	BUG_ON(data-&gt;n_addrs &gt;= ARRAY_SIZE(data-&gt;addr));</span>
<span class="p_del">-	data-&gt;addr[data-&gt;n_addrs++] = addr;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static unsigned int kmemcheck_show_all(void)</span>
<span class="p_del">-{</span>
<span class="p_del">-	struct kmemcheck_context *data = this_cpu_ptr(&amp;kmemcheck_context);</span>
<span class="p_del">-	unsigned int i;</span>
<span class="p_del">-	unsigned int n;</span>
<span class="p_del">-</span>
<span class="p_del">-	n = 0;</span>
<span class="p_del">-	for (i = 0; i &lt; data-&gt;n_addrs; ++i)</span>
<span class="p_del">-		n += kmemcheck_show_addr(data-&gt;addr[i]);</span>
<span class="p_del">-</span>
<span class="p_del">-	return n;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static unsigned int kmemcheck_hide_all(void)</span>
<span class="p_del">-{</span>
<span class="p_del">-	struct kmemcheck_context *data = this_cpu_ptr(&amp;kmemcheck_context);</span>
<span class="p_del">-	unsigned int i;</span>
<span class="p_del">-	unsigned int n;</span>
<span class="p_del">-</span>
<span class="p_del">-	n = 0;</span>
<span class="p_del">-	for (i = 0; i &lt; data-&gt;n_addrs; ++i)</span>
<span class="p_del">-		n += kmemcheck_hide_addr(data-&gt;addr[i]);</span>
<span class="p_del">-</span>
<span class="p_del">-	return n;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-/*</span>
<span class="p_del">- * Called from the #PF handler.</span>
<span class="p_del">- */</span>
<span class="p_del">-void kmemcheck_show(struct pt_regs *regs)</span>
<span class="p_del">-{</span>
<span class="p_del">-	struct kmemcheck_context *data = this_cpu_ptr(&amp;kmemcheck_context);</span>
<span class="p_del">-</span>
<span class="p_del">-	BUG_ON(!irqs_disabled());</span>
<span class="p_del">-</span>
<span class="p_del">-	if (unlikely(data-&gt;balance != 0)) {</span>
<span class="p_del">-		kmemcheck_show_all();</span>
<span class="p_del">-		kmemcheck_error_save_bug(regs);</span>
<span class="p_del">-		data-&gt;balance = 0;</span>
<span class="p_del">-		return;</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">-	/*</span>
<span class="p_del">-	 * None of the addresses actually belonged to kmemcheck. Note that</span>
<span class="p_del">-	 * this is not an error.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	if (kmemcheck_show_all() == 0)</span>
<span class="p_del">-		return;</span>
<span class="p_del">-</span>
<span class="p_del">-	++data-&gt;balance;</span>
<span class="p_del">-</span>
<span class="p_del">-	/*</span>
<span class="p_del">-	 * The IF needs to be cleared as well, so that the faulting</span>
<span class="p_del">-	 * instruction can run &quot;uninterrupted&quot;. Otherwise, we might take</span>
<span class="p_del">-	 * an interrupt and start executing that before we&#39;ve had a chance</span>
<span class="p_del">-	 * to hide the page again.</span>
<span class="p_del">-	 *</span>
<span class="p_del">-	 * NOTE: In the rare case of multiple faults, we must not override</span>
<span class="p_del">-	 * the original flags:</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	if (!(regs-&gt;flags &amp; X86_EFLAGS_TF))</span>
<span class="p_del">-		data-&gt;flags = regs-&gt;flags;</span>
<span class="p_del">-</span>
<span class="p_del">-	regs-&gt;flags |= X86_EFLAGS_TF;</span>
<span class="p_del">-	regs-&gt;flags &amp;= ~X86_EFLAGS_IF;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-/*</span>
<span class="p_del">- * Called from the #DB handler.</span>
<span class="p_del">- */</span>
<span class="p_del">-void kmemcheck_hide(struct pt_regs *regs)</span>
<span class="p_del">-{</span>
<span class="p_del">-	struct kmemcheck_context *data = this_cpu_ptr(&amp;kmemcheck_context);</span>
<span class="p_del">-	int n;</span>
<span class="p_del">-</span>
<span class="p_del">-	BUG_ON(!irqs_disabled());</span>
<span class="p_del">-</span>
<span class="p_del">-	if (unlikely(data-&gt;balance != 1)) {</span>
<span class="p_del">-		kmemcheck_show_all();</span>
<span class="p_del">-		kmemcheck_error_save_bug(regs);</span>
<span class="p_del">-		data-&gt;n_addrs = 0;</span>
<span class="p_del">-		data-&gt;balance = 0;</span>
<span class="p_del">-</span>
<span class="p_del">-		if (!(data-&gt;flags &amp; X86_EFLAGS_TF))</span>
<span class="p_del">-			regs-&gt;flags &amp;= ~X86_EFLAGS_TF;</span>
<span class="p_del">-		if (data-&gt;flags &amp; X86_EFLAGS_IF)</span>
<span class="p_del">-			regs-&gt;flags |= X86_EFLAGS_IF;</span>
<span class="p_del">-		return;</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">-	if (kmemcheck_enabled)</span>
<span class="p_del">-		n = kmemcheck_hide_all();</span>
<span class="p_del">-	else</span>
<span class="p_del">-		n = kmemcheck_show_all();</span>
<span class="p_del">-</span>
<span class="p_del">-	if (n == 0)</span>
<span class="p_del">-		return;</span>
<span class="p_del">-</span>
<span class="p_del">-	--data-&gt;balance;</span>
<span class="p_del">-</span>
<span class="p_del">-	data-&gt;n_addrs = 0;</span>
<span class="p_del">-</span>
<span class="p_del">-	if (!(data-&gt;flags &amp; X86_EFLAGS_TF))</span>
<span class="p_del">-		regs-&gt;flags &amp;= ~X86_EFLAGS_TF;</span>
<span class="p_del">-	if (data-&gt;flags &amp; X86_EFLAGS_IF)</span>
<span class="p_del">-		regs-&gt;flags |= X86_EFLAGS_IF;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-void kmemcheck_show_pages(struct page *p, unsigned int n)</span>
<span class="p_del">-{</span>
<span class="p_del">-	unsigned int i;</span>
<span class="p_del">-</span>
<span class="p_del">-	for (i = 0; i &lt; n; ++i) {</span>
<span class="p_del">-		unsigned long address;</span>
<span class="p_del">-		pte_t *pte;</span>
<span class="p_del">-		unsigned int level;</span>
<span class="p_del">-</span>
<span class="p_del">-		address = (unsigned long) page_address(&amp;p[i]);</span>
<span class="p_del">-		pte = lookup_address(address, &amp;level);</span>
<span class="p_del">-		BUG_ON(!pte);</span>
<span class="p_del">-		BUG_ON(level != PG_LEVEL_4K);</span>
<span class="p_del">-</span>
<span class="p_del">-		set_pte(pte, __pte(pte_val(*pte) | _PAGE_PRESENT));</span>
<span class="p_del">-		set_pte(pte, __pte(pte_val(*pte) &amp; ~_PAGE_HIDDEN));</span>
<span class="p_del">-		__flush_tlb_one(address);</span>
<span class="p_del">-	}</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-bool kmemcheck_page_is_tracked(struct page *p)</span>
<span class="p_del">-{</span>
<span class="p_del">-	/* This will also check the &quot;hidden&quot; flag of the PTE. */</span>
<span class="p_del">-	return kmemcheck_pte_lookup((unsigned long) page_address(p));</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-void kmemcheck_hide_pages(struct page *p, unsigned int n)</span>
<span class="p_del">-{</span>
<span class="p_del">-	unsigned int i;</span>
<span class="p_del">-</span>
<span class="p_del">-	for (i = 0; i &lt; n; ++i) {</span>
<span class="p_del">-		unsigned long address;</span>
<span class="p_del">-		pte_t *pte;</span>
<span class="p_del">-		unsigned int level;</span>
<span class="p_del">-</span>
<span class="p_del">-		address = (unsigned long) page_address(&amp;p[i]);</span>
<span class="p_del">-		pte = lookup_address(address, &amp;level);</span>
<span class="p_del">-		BUG_ON(!pte);</span>
<span class="p_del">-		BUG_ON(level != PG_LEVEL_4K);</span>
<span class="p_del">-</span>
<span class="p_del">-		set_pte(pte, __pte(pte_val(*pte) &amp; ~_PAGE_PRESENT));</span>
<span class="p_del">-		set_pte(pte, __pte(pte_val(*pte) | _PAGE_HIDDEN));</span>
<span class="p_del">-		__flush_tlb_one(address);</span>
<span class="p_del">-	}</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-/* Access may NOT cross page boundary */</span>
<span class="p_del">-static void kmemcheck_read_strict(struct pt_regs *regs,</span>
<span class="p_del">-	unsigned long addr, unsigned int size)</span>
<span class="p_del">-{</span>
<span class="p_del">-	void *shadow;</span>
<span class="p_del">-	enum kmemcheck_shadow status;</span>
<span class="p_del">-</span>
<span class="p_del">-	shadow = kmemcheck_shadow_lookup(addr);</span>
<span class="p_del">-	if (!shadow)</span>
<span class="p_del">-		return;</span>
<span class="p_del">-</span>
<span class="p_del">-	kmemcheck_save_addr(addr);</span>
<span class="p_del">-	status = kmemcheck_shadow_test(shadow, size);</span>
<span class="p_del">-	if (status == KMEMCHECK_SHADOW_INITIALIZED)</span>
<span class="p_del">-		return;</span>
<span class="p_del">-</span>
<span class="p_del">-	if (kmemcheck_enabled)</span>
<span class="p_del">-		kmemcheck_error_save(status, addr, size, regs);</span>
<span class="p_del">-</span>
<span class="p_del">-	if (kmemcheck_enabled == 2)</span>
<span class="p_del">-		kmemcheck_enabled = 0;</span>
<span class="p_del">-</span>
<span class="p_del">-	/* Don&#39;t warn about it again. */</span>
<span class="p_del">-	kmemcheck_shadow_set(shadow, size);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-bool kmemcheck_is_obj_initialized(unsigned long addr, size_t size)</span>
<span class="p_del">-{</span>
<span class="p_del">-	enum kmemcheck_shadow status;</span>
<span class="p_del">-	void *shadow;</span>
<span class="p_del">-</span>
<span class="p_del">-	shadow = kmemcheck_shadow_lookup(addr);</span>
<span class="p_del">-	if (!shadow)</span>
<span class="p_del">-		return true;</span>
<span class="p_del">-</span>
<span class="p_del">-	status = kmemcheck_shadow_test_all(shadow, size);</span>
<span class="p_del">-</span>
<span class="p_del">-	return status == KMEMCHECK_SHADOW_INITIALIZED;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-/* Access may cross page boundary */</span>
<span class="p_del">-static void kmemcheck_read(struct pt_regs *regs,</span>
<span class="p_del">-	unsigned long addr, unsigned int size)</span>
<span class="p_del">-{</span>
<span class="p_del">-	unsigned long page = addr &amp; PAGE_MASK;</span>
<span class="p_del">-	unsigned long next_addr = addr + size - 1;</span>
<span class="p_del">-	unsigned long next_page = next_addr &amp; PAGE_MASK;</span>
<span class="p_del">-</span>
<span class="p_del">-	if (likely(page == next_page)) {</span>
<span class="p_del">-		kmemcheck_read_strict(regs, addr, size);</span>
<span class="p_del">-		return;</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">-	/*</span>
<span class="p_del">-	 * What we do is basically to split the access across the</span>
<span class="p_del">-	 * two pages and handle each part separately. Yes, this means</span>
<span class="p_del">-	 * that we may now see reads that are 3 + 5 bytes, for</span>
<span class="p_del">-	 * example (and if both are uninitialized, there will be two</span>
<span class="p_del">-	 * reports), but it makes the code a lot simpler.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	kmemcheck_read_strict(regs, addr, next_page - addr);</span>
<span class="p_del">-	kmemcheck_read_strict(regs, next_page, next_addr - next_page);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static void kmemcheck_write_strict(struct pt_regs *regs,</span>
<span class="p_del">-	unsigned long addr, unsigned int size)</span>
<span class="p_del">-{</span>
<span class="p_del">-	void *shadow;</span>
<span class="p_del">-</span>
<span class="p_del">-	shadow = kmemcheck_shadow_lookup(addr);</span>
<span class="p_del">-	if (!shadow)</span>
<span class="p_del">-		return;</span>
<span class="p_del">-</span>
<span class="p_del">-	kmemcheck_save_addr(addr);</span>
<span class="p_del">-	kmemcheck_shadow_set(shadow, size);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static void kmemcheck_write(struct pt_regs *regs,</span>
<span class="p_del">-	unsigned long addr, unsigned int size)</span>
<span class="p_del">-{</span>
<span class="p_del">-	unsigned long page = addr &amp; PAGE_MASK;</span>
<span class="p_del">-	unsigned long next_addr = addr + size - 1;</span>
<span class="p_del">-	unsigned long next_page = next_addr &amp; PAGE_MASK;</span>
<span class="p_del">-</span>
<span class="p_del">-	if (likely(page == next_page)) {</span>
<span class="p_del">-		kmemcheck_write_strict(regs, addr, size);</span>
<span class="p_del">-		return;</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">-	/* See comment in kmemcheck_read(). */</span>
<span class="p_del">-	kmemcheck_write_strict(regs, addr, next_page - addr);</span>
<span class="p_del">-	kmemcheck_write_strict(regs, next_page, next_addr - next_page);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-/*</span>
<span class="p_del">- * Copying is hard. We have two addresses, each of which may be split across</span>
<span class="p_del">- * a page (and each page will have different shadow addresses).</span>
<span class="p_del">- */</span>
<span class="p_del">-static void kmemcheck_copy(struct pt_regs *regs,</span>
<span class="p_del">-	unsigned long src_addr, unsigned long dst_addr, unsigned int size)</span>
<span class="p_del">-{</span>
<span class="p_del">-	uint8_t shadow[8];</span>
<span class="p_del">-	enum kmemcheck_shadow status;</span>
<span class="p_del">-</span>
<span class="p_del">-	unsigned long page;</span>
<span class="p_del">-	unsigned long next_addr;</span>
<span class="p_del">-	unsigned long next_page;</span>
<span class="p_del">-</span>
<span class="p_del">-	uint8_t *x;</span>
<span class="p_del">-	unsigned int i;</span>
<span class="p_del">-	unsigned int n;</span>
<span class="p_del">-</span>
<span class="p_del">-	BUG_ON(size &gt; sizeof(shadow));</span>
<span class="p_del">-</span>
<span class="p_del">-	page = src_addr &amp; PAGE_MASK;</span>
<span class="p_del">-	next_addr = src_addr + size - 1;</span>
<span class="p_del">-	next_page = next_addr &amp; PAGE_MASK;</span>
<span class="p_del">-</span>
<span class="p_del">-	if (likely(page == next_page)) {</span>
<span class="p_del">-		/* Same page */</span>
<span class="p_del">-		x = kmemcheck_shadow_lookup(src_addr);</span>
<span class="p_del">-		if (x) {</span>
<span class="p_del">-			kmemcheck_save_addr(src_addr);</span>
<span class="p_del">-			for (i = 0; i &lt; size; ++i)</span>
<span class="p_del">-				shadow[i] = x[i];</span>
<span class="p_del">-		} else {</span>
<span class="p_del">-			for (i = 0; i &lt; size; ++i)</span>
<span class="p_del">-				shadow[i] = KMEMCHECK_SHADOW_INITIALIZED;</span>
<span class="p_del">-		}</span>
<span class="p_del">-	} else {</span>
<span class="p_del">-		n = next_page - src_addr;</span>
<span class="p_del">-		BUG_ON(n &gt; sizeof(shadow));</span>
<span class="p_del">-</span>
<span class="p_del">-		/* First page */</span>
<span class="p_del">-		x = kmemcheck_shadow_lookup(src_addr);</span>
<span class="p_del">-		if (x) {</span>
<span class="p_del">-			kmemcheck_save_addr(src_addr);</span>
<span class="p_del">-			for (i = 0; i &lt; n; ++i)</span>
<span class="p_del">-				shadow[i] = x[i];</span>
<span class="p_del">-		} else {</span>
<span class="p_del">-			/* Not tracked */</span>
<span class="p_del">-			for (i = 0; i &lt; n; ++i)</span>
<span class="p_del">-				shadow[i] = KMEMCHECK_SHADOW_INITIALIZED;</span>
<span class="p_del">-		}</span>
<span class="p_del">-</span>
<span class="p_del">-		/* Second page */</span>
<span class="p_del">-		x = kmemcheck_shadow_lookup(next_page);</span>
<span class="p_del">-		if (x) {</span>
<span class="p_del">-			kmemcheck_save_addr(next_page);</span>
<span class="p_del">-			for (i = n; i &lt; size; ++i)</span>
<span class="p_del">-				shadow[i] = x[i - n];</span>
<span class="p_del">-		} else {</span>
<span class="p_del">-			/* Not tracked */</span>
<span class="p_del">-			for (i = n; i &lt; size; ++i)</span>
<span class="p_del">-				shadow[i] = KMEMCHECK_SHADOW_INITIALIZED;</span>
<span class="p_del">-		}</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">-	page = dst_addr &amp; PAGE_MASK;</span>
<span class="p_del">-	next_addr = dst_addr + size - 1;</span>
<span class="p_del">-	next_page = next_addr &amp; PAGE_MASK;</span>
<span class="p_del">-</span>
<span class="p_del">-	if (likely(page == next_page)) {</span>
<span class="p_del">-		/* Same page */</span>
<span class="p_del">-		x = kmemcheck_shadow_lookup(dst_addr);</span>
<span class="p_del">-		if (x) {</span>
<span class="p_del">-			kmemcheck_save_addr(dst_addr);</span>
<span class="p_del">-			for (i = 0; i &lt; size; ++i) {</span>
<span class="p_del">-				x[i] = shadow[i];</span>
<span class="p_del">-				shadow[i] = KMEMCHECK_SHADOW_INITIALIZED;</span>
<span class="p_del">-			}</span>
<span class="p_del">-		}</span>
<span class="p_del">-	} else {</span>
<span class="p_del">-		n = next_page - dst_addr;</span>
<span class="p_del">-		BUG_ON(n &gt; sizeof(shadow));</span>
<span class="p_del">-</span>
<span class="p_del">-		/* First page */</span>
<span class="p_del">-		x = kmemcheck_shadow_lookup(dst_addr);</span>
<span class="p_del">-		if (x) {</span>
<span class="p_del">-			kmemcheck_save_addr(dst_addr);</span>
<span class="p_del">-			for (i = 0; i &lt; n; ++i) {</span>
<span class="p_del">-				x[i] = shadow[i];</span>
<span class="p_del">-				shadow[i] = KMEMCHECK_SHADOW_INITIALIZED;</span>
<span class="p_del">-			}</span>
<span class="p_del">-		}</span>
<span class="p_del">-</span>
<span class="p_del">-		/* Second page */</span>
<span class="p_del">-		x = kmemcheck_shadow_lookup(next_page);</span>
<span class="p_del">-		if (x) {</span>
<span class="p_del">-			kmemcheck_save_addr(next_page);</span>
<span class="p_del">-			for (i = n; i &lt; size; ++i) {</span>
<span class="p_del">-				x[i - n] = shadow[i];</span>
<span class="p_del">-				shadow[i] = KMEMCHECK_SHADOW_INITIALIZED;</span>
<span class="p_del">-			}</span>
<span class="p_del">-		}</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">-	status = kmemcheck_shadow_test(shadow, size);</span>
<span class="p_del">-	if (status == KMEMCHECK_SHADOW_INITIALIZED)</span>
<span class="p_del">-		return;</span>
<span class="p_del">-</span>
<span class="p_del">-	if (kmemcheck_enabled)</span>
<span class="p_del">-		kmemcheck_error_save(status, src_addr, size, regs);</span>
<span class="p_del">-</span>
<span class="p_del">-	if (kmemcheck_enabled == 2)</span>
<span class="p_del">-		kmemcheck_enabled = 0;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-enum kmemcheck_method {</span>
<span class="p_del">-	KMEMCHECK_READ,</span>
<span class="p_del">-	KMEMCHECK_WRITE,</span>
<span class="p_del">-};</span>
<span class="p_del">-</span>
<span class="p_del">-static void kmemcheck_access(struct pt_regs *regs,</span>
<span class="p_del">-	unsigned long fallback_address, enum kmemcheck_method fallback_method)</span>
<span class="p_del">-{</span>
<span class="p_del">-	const uint8_t *insn;</span>
<span class="p_del">-	const uint8_t *insn_primary;</span>
<span class="p_del">-	unsigned int size;</span>
<span class="p_del">-</span>
<span class="p_del">-	struct kmemcheck_context *data = this_cpu_ptr(&amp;kmemcheck_context);</span>
<span class="p_del">-</span>
<span class="p_del">-	/* Recursive fault -- ouch. */</span>
<span class="p_del">-	if (data-&gt;busy) {</span>
<span class="p_del">-		kmemcheck_show_addr(fallback_address);</span>
<span class="p_del">-		kmemcheck_error_save_bug(regs);</span>
<span class="p_del">-		return;</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">-	data-&gt;busy = true;</span>
<span class="p_del">-</span>
<span class="p_del">-	insn = (const uint8_t *) regs-&gt;ip;</span>
<span class="p_del">-	insn_primary = kmemcheck_opcode_get_primary(insn);</span>
<span class="p_del">-</span>
<span class="p_del">-	kmemcheck_opcode_decode(insn, &amp;size);</span>
<span class="p_del">-</span>
<span class="p_del">-	switch (insn_primary[0]) {</span>
<span class="p_del">-#ifdef CONFIG_KMEMCHECK_BITOPS_OK</span>
<span class="p_del">-		/* AND, OR, XOR */</span>
<span class="p_del">-		/*</span>
<span class="p_del">-		 * Unfortunately, these instructions have to be excluded from</span>
<span class="p_del">-		 * our regular checking since they access only some (and not</span>
<span class="p_del">-		 * all) bits. This clears out &quot;bogus&quot; bitfield-access warnings.</span>
<span class="p_del">-		 */</span>
<span class="p_del">-	case 0x80:</span>
<span class="p_del">-	case 0x81:</span>
<span class="p_del">-	case 0x82:</span>
<span class="p_del">-	case 0x83:</span>
<span class="p_del">-		switch ((insn_primary[1] &gt;&gt; 3) &amp; 7) {</span>
<span class="p_del">-			/* OR */</span>
<span class="p_del">-		case 1:</span>
<span class="p_del">-			/* AND */</span>
<span class="p_del">-		case 4:</span>
<span class="p_del">-			/* XOR */</span>
<span class="p_del">-		case 6:</span>
<span class="p_del">-			kmemcheck_write(regs, fallback_address, size);</span>
<span class="p_del">-			goto out;</span>
<span class="p_del">-</span>
<span class="p_del">-			/* ADD */</span>
<span class="p_del">-		case 0:</span>
<span class="p_del">-			/* ADC */</span>
<span class="p_del">-		case 2:</span>
<span class="p_del">-			/* SBB */</span>
<span class="p_del">-		case 3:</span>
<span class="p_del">-			/* SUB */</span>
<span class="p_del">-		case 5:</span>
<span class="p_del">-			/* CMP */</span>
<span class="p_del">-		case 7:</span>
<span class="p_del">-			break;</span>
<span class="p_del">-		}</span>
<span class="p_del">-		break;</span>
<span class="p_del">-#endif</span>
<span class="p_del">-</span>
<span class="p_del">-		/* MOVS, MOVSB, MOVSW, MOVSD */</span>
<span class="p_del">-	case 0xa4:</span>
<span class="p_del">-	case 0xa5:</span>
<span class="p_del">-		/*</span>
<span class="p_del">-		 * These instructions are special because they take two</span>
<span class="p_del">-		 * addresses, but we only get one page fault.</span>
<span class="p_del">-		 */</span>
<span class="p_del">-		kmemcheck_copy(regs, regs-&gt;si, regs-&gt;di, size);</span>
<span class="p_del">-		goto out;</span>
<span class="p_del">-</span>
<span class="p_del">-		/* CMPS, CMPSB, CMPSW, CMPSD */</span>
<span class="p_del">-	case 0xa6:</span>
<span class="p_del">-	case 0xa7:</span>
<span class="p_del">-		kmemcheck_read(regs, regs-&gt;si, size);</span>
<span class="p_del">-		kmemcheck_read(regs, regs-&gt;di, size);</span>
<span class="p_del">-		goto out;</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">-	/*</span>
<span class="p_del">-	 * If the opcode isn&#39;t special in any way, we use the data from the</span>
<span class="p_del">-	 * page fault handler to determine the address and type of memory</span>
<span class="p_del">-	 * access.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	switch (fallback_method) {</span>
<span class="p_del">-	case KMEMCHECK_READ:</span>
<span class="p_del">-		kmemcheck_read(regs, fallback_address, size);</span>
<span class="p_del">-		goto out;</span>
<span class="p_del">-	case KMEMCHECK_WRITE:</span>
<span class="p_del">-		kmemcheck_write(regs, fallback_address, size);</span>
<span class="p_del">-		goto out;</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">-out:</span>
<span class="p_del">-	data-&gt;busy = false;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-bool kmemcheck_fault(struct pt_regs *regs, unsigned long address,</span>
<span class="p_del">-	unsigned long error_code)</span>
<span class="p_del">-{</span>
<span class="p_del">-	pte_t *pte;</span>
<span class="p_del">-</span>
<span class="p_del">-	/*</span>
<span class="p_del">-	 * XXX: Is it safe to assume that memory accesses from virtual 86</span>
<span class="p_del">-	 * mode or non-kernel code segments will _never_ access kernel</span>
<span class="p_del">-	 * memory (e.g. tracked pages)? For now, we need this to avoid</span>
<span class="p_del">-	 * invoking kmemcheck for PnP BIOS calls.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	if (regs-&gt;flags &amp; X86_VM_MASK)</span>
<span class="p_del">-		return false;</span>
<span class="p_del">-	if (regs-&gt;cs != __KERNEL_CS)</span>
<span class="p_del">-		return false;</span>
<span class="p_del">-</span>
<span class="p_del">-	pte = kmemcheck_pte_lookup(address);</span>
<span class="p_del">-	if (!pte)</span>
<span class="p_del">-		return false;</span>
<span class="p_del">-</span>
<span class="p_del">-	WARN_ON_ONCE(in_nmi());</span>
<span class="p_del">-</span>
<span class="p_del">-	if (error_code &amp; 2)</span>
<span class="p_del">-		kmemcheck_access(regs, address, KMEMCHECK_WRITE);</span>
<span class="p_del">-	else</span>
<span class="p_del">-		kmemcheck_access(regs, address, KMEMCHECK_READ);</span>
<span class="p_del">-</span>
<span class="p_del">-	kmemcheck_show(regs);</span>
<span class="p_del">-	return true;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-bool kmemcheck_trap(struct pt_regs *regs)</span>
<span class="p_del">-{</span>
<span class="p_del">-	if (!kmemcheck_active(regs))</span>
<span class="p_del">-		return false;</span>
<span class="p_del">-</span>
<span class="p_del">-	/* We&#39;re done. */</span>
<span class="p_del">-	kmemcheck_hide(regs);</span>
<span class="p_del">-	return true;</span>
<span class="p_del">-}</span>
<span class="p_header">diff --git a/arch/x86/mm/kmemcheck/opcode.c b/arch/x86/mm/kmemcheck/opcode.c</span>
deleted file mode 100644
<span class="p_header">index 324aa3f07237..000000000000</span>
<span class="p_header">--- a/arch/x86/mm/kmemcheck/opcode.c</span>
<span class="p_header">+++ /dev/null</span>
<span class="p_chunk">@@ -1,106 +0,0 @@</span> <span class="p_context"></span>
<span class="p_del">-#include &lt;linux/types.h&gt;</span>
<span class="p_del">-</span>
<span class="p_del">-#include &quot;opcode.h&quot;</span>
<span class="p_del">-</span>
<span class="p_del">-static bool opcode_is_prefix(uint8_t b)</span>
<span class="p_del">-{</span>
<span class="p_del">-	return</span>
<span class="p_del">-		/* Group 1 */</span>
<span class="p_del">-		b == 0xf0 || b == 0xf2 || b == 0xf3</span>
<span class="p_del">-		/* Group 2 */</span>
<span class="p_del">-		|| b == 0x2e || b == 0x36 || b == 0x3e || b == 0x26</span>
<span class="p_del">-		|| b == 0x64 || b == 0x65</span>
<span class="p_del">-		/* Group 3 */</span>
<span class="p_del">-		|| b == 0x66</span>
<span class="p_del">-		/* Group 4 */</span>
<span class="p_del">-		|| b == 0x67;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-#ifdef CONFIG_X86_64</span>
<span class="p_del">-static bool opcode_is_rex_prefix(uint8_t b)</span>
<span class="p_del">-{</span>
<span class="p_del">-	return (b &amp; 0xf0) == 0x40;</span>
<span class="p_del">-}</span>
<span class="p_del">-#else</span>
<span class="p_del">-static bool opcode_is_rex_prefix(uint8_t b)</span>
<span class="p_del">-{</span>
<span class="p_del">-	return false;</span>
<span class="p_del">-}</span>
<span class="p_del">-#endif</span>
<span class="p_del">-</span>
<span class="p_del">-#define REX_W (1 &lt;&lt; 3)</span>
<span class="p_del">-</span>
<span class="p_del">-/*</span>
<span class="p_del">- * This is a VERY crude opcode decoder. We only need to find the size of the</span>
<span class="p_del">- * load/store that caused our #PF and this should work for all the opcodes</span>
<span class="p_del">- * that we care about. Moreover, the ones who invented this instruction set</span>
<span class="p_del">- * should be shot.</span>
<span class="p_del">- */</span>
<span class="p_del">-void kmemcheck_opcode_decode(const uint8_t *op, unsigned int *size)</span>
<span class="p_del">-{</span>
<span class="p_del">-	/* Default operand size */</span>
<span class="p_del">-	int operand_size_override = 4;</span>
<span class="p_del">-</span>
<span class="p_del">-	/* prefixes */</span>
<span class="p_del">-	for (; opcode_is_prefix(*op); ++op) {</span>
<span class="p_del">-		if (*op == 0x66)</span>
<span class="p_del">-			operand_size_override = 2;</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">-	/* REX prefix */</span>
<span class="p_del">-	if (opcode_is_rex_prefix(*op)) {</span>
<span class="p_del">-		uint8_t rex = *op;</span>
<span class="p_del">-</span>
<span class="p_del">-		++op;</span>
<span class="p_del">-		if (rex &amp; REX_W) {</span>
<span class="p_del">-			switch (*op) {</span>
<span class="p_del">-			case 0x63:</span>
<span class="p_del">-				*size = 4;</span>
<span class="p_del">-				return;</span>
<span class="p_del">-			case 0x0f:</span>
<span class="p_del">-				++op;</span>
<span class="p_del">-</span>
<span class="p_del">-				switch (*op) {</span>
<span class="p_del">-				case 0xb6:</span>
<span class="p_del">-				case 0xbe:</span>
<span class="p_del">-					*size = 1;</span>
<span class="p_del">-					return;</span>
<span class="p_del">-				case 0xb7:</span>
<span class="p_del">-				case 0xbf:</span>
<span class="p_del">-					*size = 2;</span>
<span class="p_del">-					return;</span>
<span class="p_del">-				}</span>
<span class="p_del">-</span>
<span class="p_del">-				break;</span>
<span class="p_del">-			}</span>
<span class="p_del">-</span>
<span class="p_del">-			*size = 8;</span>
<span class="p_del">-			return;</span>
<span class="p_del">-		}</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">-	/* escape opcode */</span>
<span class="p_del">-	if (*op == 0x0f) {</span>
<span class="p_del">-		++op;</span>
<span class="p_del">-</span>
<span class="p_del">-		/*</span>
<span class="p_del">-		 * This is move with zero-extend and sign-extend, respectively;</span>
<span class="p_del">-		 * we don&#39;t have to think about 0xb6/0xbe, because this is</span>
<span class="p_del">-		 * already handled in the conditional below.</span>
<span class="p_del">-		 */</span>
<span class="p_del">-		if (*op == 0xb7 || *op == 0xbf)</span>
<span class="p_del">-			operand_size_override = 2;</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">-	*size = (*op &amp; 1) ? operand_size_override : 1;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-const uint8_t *kmemcheck_opcode_get_primary(const uint8_t *op)</span>
<span class="p_del">-{</span>
<span class="p_del">-	/* skip prefixes */</span>
<span class="p_del">-	while (opcode_is_prefix(*op))</span>
<span class="p_del">-		++op;</span>
<span class="p_del">-	if (opcode_is_rex_prefix(*op))</span>
<span class="p_del">-		++op;</span>
<span class="p_del">-	return op;</span>
<span class="p_del">-}</span>
<span class="p_header">diff --git a/arch/x86/mm/kmemcheck/opcode.h b/arch/x86/mm/kmemcheck/opcode.h</span>
deleted file mode 100644
<span class="p_header">index 6956aad66b5b..000000000000</span>
<span class="p_header">--- a/arch/x86/mm/kmemcheck/opcode.h</span>
<span class="p_header">+++ /dev/null</span>
<span class="p_chunk">@@ -1,9 +0,0 @@</span> <span class="p_context"></span>
<span class="p_del">-#ifndef ARCH__X86__MM__KMEMCHECK__OPCODE_H</span>
<span class="p_del">-#define ARCH__X86__MM__KMEMCHECK__OPCODE_H</span>
<span class="p_del">-</span>
<span class="p_del">-#include &lt;linux/types.h&gt;</span>
<span class="p_del">-</span>
<span class="p_del">-void kmemcheck_opcode_decode(const uint8_t *op, unsigned int *size);</span>
<span class="p_del">-const uint8_t *kmemcheck_opcode_get_primary(const uint8_t *op);</span>
<span class="p_del">-</span>
<span class="p_del">-#endif</span>
<span class="p_header">diff --git a/arch/x86/mm/kmemcheck/pte.c b/arch/x86/mm/kmemcheck/pte.c</span>
deleted file mode 100644
<span class="p_header">index 4ead26eeaf96..000000000000</span>
<span class="p_header">--- a/arch/x86/mm/kmemcheck/pte.c</span>
<span class="p_header">+++ /dev/null</span>
<span class="p_chunk">@@ -1,22 +0,0 @@</span> <span class="p_context"></span>
<span class="p_del">-#include &lt;linux/mm.h&gt;</span>
<span class="p_del">-</span>
<span class="p_del">-#include &lt;asm/pgtable.h&gt;</span>
<span class="p_del">-</span>
<span class="p_del">-#include &quot;pte.h&quot;</span>
<span class="p_del">-</span>
<span class="p_del">-pte_t *kmemcheck_pte_lookup(unsigned long address)</span>
<span class="p_del">-{</span>
<span class="p_del">-	pte_t *pte;</span>
<span class="p_del">-	unsigned int level;</span>
<span class="p_del">-</span>
<span class="p_del">-	pte = lookup_address(address, &amp;level);</span>
<span class="p_del">-	if (!pte)</span>
<span class="p_del">-		return NULL;</span>
<span class="p_del">-	if (level != PG_LEVEL_4K)</span>
<span class="p_del">-		return NULL;</span>
<span class="p_del">-	if (!pte_hidden(*pte))</span>
<span class="p_del">-		return NULL;</span>
<span class="p_del">-</span>
<span class="p_del">-	return pte;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_header">diff --git a/arch/x86/mm/kmemcheck/pte.h b/arch/x86/mm/kmemcheck/pte.h</span>
deleted file mode 100644
<span class="p_header">index 9f5966456492..000000000000</span>
<span class="p_header">--- a/arch/x86/mm/kmemcheck/pte.h</span>
<span class="p_header">+++ /dev/null</span>
<span class="p_chunk">@@ -1,10 +0,0 @@</span> <span class="p_context"></span>
<span class="p_del">-#ifndef ARCH__X86__MM__KMEMCHECK__PTE_H</span>
<span class="p_del">-#define ARCH__X86__MM__KMEMCHECK__PTE_H</span>
<span class="p_del">-</span>
<span class="p_del">-#include &lt;linux/mm.h&gt;</span>
<span class="p_del">-</span>
<span class="p_del">-#include &lt;asm/pgtable.h&gt;</span>
<span class="p_del">-</span>
<span class="p_del">-pte_t *kmemcheck_pte_lookup(unsigned long address);</span>
<span class="p_del">-</span>
<span class="p_del">-#endif</span>
<span class="p_header">diff --git a/arch/x86/mm/kmemcheck/selftest.c b/arch/x86/mm/kmemcheck/selftest.c</span>
deleted file mode 100644
<span class="p_header">index aef7140c0063..000000000000</span>
<span class="p_header">--- a/arch/x86/mm/kmemcheck/selftest.c</span>
<span class="p_header">+++ /dev/null</span>
<span class="p_chunk">@@ -1,70 +0,0 @@</span> <span class="p_context"></span>
<span class="p_del">-#include &lt;linux/bug.h&gt;</span>
<span class="p_del">-#include &lt;linux/kernel.h&gt;</span>
<span class="p_del">-</span>
<span class="p_del">-#include &quot;opcode.h&quot;</span>
<span class="p_del">-#include &quot;selftest.h&quot;</span>
<span class="p_del">-</span>
<span class="p_del">-struct selftest_opcode {</span>
<span class="p_del">-	unsigned int expected_size;</span>
<span class="p_del">-	const uint8_t *insn;</span>
<span class="p_del">-	const char *desc;</span>
<span class="p_del">-};</span>
<span class="p_del">-</span>
<span class="p_del">-static const struct selftest_opcode selftest_opcodes[] = {</span>
<span class="p_del">-	/* REP MOVS */</span>
<span class="p_del">-	{1, &quot;\xf3\xa4&quot;, 		&quot;rep movsb &lt;mem8&gt;, &lt;mem8&gt;&quot;},</span>
<span class="p_del">-	{4, &quot;\xf3\xa5&quot;,			&quot;rep movsl &lt;mem32&gt;, &lt;mem32&gt;&quot;},</span>
<span class="p_del">-</span>
<span class="p_del">-	/* MOVZX / MOVZXD */</span>
<span class="p_del">-	{1, &quot;\x66\x0f\xb6\x51\xf8&quot;,	&quot;movzwq &lt;mem8&gt;, &lt;reg16&gt;&quot;},</span>
<span class="p_del">-	{1, &quot;\x0f\xb6\x51\xf8&quot;,		&quot;movzwq &lt;mem8&gt;, &lt;reg32&gt;&quot;},</span>
<span class="p_del">-</span>
<span class="p_del">-	/* MOVSX / MOVSXD */</span>
<span class="p_del">-	{1, &quot;\x66\x0f\xbe\x51\xf8&quot;,	&quot;movswq &lt;mem8&gt;, &lt;reg16&gt;&quot;},</span>
<span class="p_del">-	{1, &quot;\x0f\xbe\x51\xf8&quot;,		&quot;movswq &lt;mem8&gt;, &lt;reg32&gt;&quot;},</span>
<span class="p_del">-</span>
<span class="p_del">-#ifdef CONFIG_X86_64</span>
<span class="p_del">-	/* MOVZX / MOVZXD */</span>
<span class="p_del">-	{1, &quot;\x49\x0f\xb6\x51\xf8&quot;,	&quot;movzbq &lt;mem8&gt;, &lt;reg64&gt;&quot;},</span>
<span class="p_del">-	{2, &quot;\x49\x0f\xb7\x51\xf8&quot;,	&quot;movzbq &lt;mem16&gt;, &lt;reg64&gt;&quot;},</span>
<span class="p_del">-</span>
<span class="p_del">-	/* MOVSX / MOVSXD */</span>
<span class="p_del">-	{1, &quot;\x49\x0f\xbe\x51\xf8&quot;,	&quot;movsbq &lt;mem8&gt;, &lt;reg64&gt;&quot;},</span>
<span class="p_del">-	{2, &quot;\x49\x0f\xbf\x51\xf8&quot;,	&quot;movsbq &lt;mem16&gt;, &lt;reg64&gt;&quot;},</span>
<span class="p_del">-	{4, &quot;\x49\x63\x51\xf8&quot;,		&quot;movslq &lt;mem32&gt;, &lt;reg64&gt;&quot;},</span>
<span class="p_del">-#endif</span>
<span class="p_del">-};</span>
<span class="p_del">-</span>
<span class="p_del">-static bool selftest_opcode_one(const struct selftest_opcode *op)</span>
<span class="p_del">-{</span>
<span class="p_del">-	unsigned size;</span>
<span class="p_del">-</span>
<span class="p_del">-	kmemcheck_opcode_decode(op-&gt;insn, &amp;size);</span>
<span class="p_del">-</span>
<span class="p_del">-	if (size == op-&gt;expected_size)</span>
<span class="p_del">-		return true;</span>
<span class="p_del">-</span>
<span class="p_del">-	printk(KERN_WARNING &quot;kmemcheck: opcode %s: expected size %d, got %d\n&quot;,</span>
<span class="p_del">-		op-&gt;desc, op-&gt;expected_size, size);</span>
<span class="p_del">-	return false;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static bool selftest_opcodes_all(void)</span>
<span class="p_del">-{</span>
<span class="p_del">-	bool pass = true;</span>
<span class="p_del">-	unsigned int i;</span>
<span class="p_del">-</span>
<span class="p_del">-	for (i = 0; i &lt; ARRAY_SIZE(selftest_opcodes); ++i)</span>
<span class="p_del">-		pass = pass &amp;&amp; selftest_opcode_one(&amp;selftest_opcodes[i]);</span>
<span class="p_del">-</span>
<span class="p_del">-	return pass;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-bool kmemcheck_selftest(void)</span>
<span class="p_del">-{</span>
<span class="p_del">-	bool pass = true;</span>
<span class="p_del">-</span>
<span class="p_del">-	pass = pass &amp;&amp; selftest_opcodes_all();</span>
<span class="p_del">-</span>
<span class="p_del">-	return pass;</span>
<span class="p_del">-}</span>
<span class="p_header">diff --git a/arch/x86/mm/kmemcheck/selftest.h b/arch/x86/mm/kmemcheck/selftest.h</span>
deleted file mode 100644
<span class="p_header">index 8fed4fe11f95..000000000000</span>
<span class="p_header">--- a/arch/x86/mm/kmemcheck/selftest.h</span>
<span class="p_header">+++ /dev/null</span>
<span class="p_chunk">@@ -1,6 +0,0 @@</span> <span class="p_context"></span>
<span class="p_del">-#ifndef ARCH_X86_MM_KMEMCHECK_SELFTEST_H</span>
<span class="p_del">-#define ARCH_X86_MM_KMEMCHECK_SELFTEST_H</span>
<span class="p_del">-</span>
<span class="p_del">-bool kmemcheck_selftest(void);</span>
<span class="p_del">-</span>
<span class="p_del">-#endif</span>
<span class="p_header">diff --git a/arch/x86/mm/kmemcheck/shadow.c b/arch/x86/mm/kmemcheck/shadow.c</span>
deleted file mode 100644
<span class="p_header">index c2638a7d2c10..000000000000</span>
<span class="p_header">--- a/arch/x86/mm/kmemcheck/shadow.c</span>
<span class="p_header">+++ /dev/null</span>
<span class="p_chunk">@@ -1,173 +0,0 @@</span> <span class="p_context"></span>
<span class="p_del">-#include &lt;linux/kmemcheck.h&gt;</span>
<span class="p_del">-#include &lt;linux/export.h&gt;</span>
<span class="p_del">-#include &lt;linux/mm.h&gt;</span>
<span class="p_del">-</span>
<span class="p_del">-#include &lt;asm/page.h&gt;</span>
<span class="p_del">-#include &lt;asm/pgtable.h&gt;</span>
<span class="p_del">-</span>
<span class="p_del">-#include &quot;pte.h&quot;</span>
<span class="p_del">-#include &quot;shadow.h&quot;</span>
<span class="p_del">-</span>
<span class="p_del">-/*</span>
<span class="p_del">- * Return the shadow address for the given address. Returns NULL if the</span>
<span class="p_del">- * address is not tracked.</span>
<span class="p_del">- *</span>
<span class="p_del">- * We need to be extremely careful not to follow any invalid pointers,</span>
<span class="p_del">- * because this function can be called for *any* possible address.</span>
<span class="p_del">- */</span>
<span class="p_del">-void *kmemcheck_shadow_lookup(unsigned long address)</span>
<span class="p_del">-{</span>
<span class="p_del">-	pte_t *pte;</span>
<span class="p_del">-	struct page *page;</span>
<span class="p_del">-</span>
<span class="p_del">-	if (!virt_addr_valid(address))</span>
<span class="p_del">-		return NULL;</span>
<span class="p_del">-</span>
<span class="p_del">-	pte = kmemcheck_pte_lookup(address);</span>
<span class="p_del">-	if (!pte)</span>
<span class="p_del">-		return NULL;</span>
<span class="p_del">-</span>
<span class="p_del">-	page = virt_to_page(address);</span>
<span class="p_del">-	if (!page-&gt;shadow)</span>
<span class="p_del">-		return NULL;</span>
<span class="p_del">-	return page-&gt;shadow + (address &amp; (PAGE_SIZE - 1));</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static void mark_shadow(void *address, unsigned int n,</span>
<span class="p_del">-	enum kmemcheck_shadow status)</span>
<span class="p_del">-{</span>
<span class="p_del">-	unsigned long addr = (unsigned long) address;</span>
<span class="p_del">-	unsigned long last_addr = addr + n - 1;</span>
<span class="p_del">-	unsigned long page = addr &amp; PAGE_MASK;</span>
<span class="p_del">-	unsigned long last_page = last_addr &amp; PAGE_MASK;</span>
<span class="p_del">-	unsigned int first_n;</span>
<span class="p_del">-	void *shadow;</span>
<span class="p_del">-</span>
<span class="p_del">-	/* If the memory range crosses a page boundary, stop there. */</span>
<span class="p_del">-	if (page == last_page)</span>
<span class="p_del">-		first_n = n;</span>
<span class="p_del">-	else</span>
<span class="p_del">-		first_n = page + PAGE_SIZE - addr;</span>
<span class="p_del">-</span>
<span class="p_del">-	shadow = kmemcheck_shadow_lookup(addr);</span>
<span class="p_del">-	if (shadow)</span>
<span class="p_del">-		memset(shadow, status, first_n);</span>
<span class="p_del">-</span>
<span class="p_del">-	addr += first_n;</span>
<span class="p_del">-	n -= first_n;</span>
<span class="p_del">-</span>
<span class="p_del">-	/* Do full-page memset()s. */</span>
<span class="p_del">-	while (n &gt;= PAGE_SIZE) {</span>
<span class="p_del">-		shadow = kmemcheck_shadow_lookup(addr);</span>
<span class="p_del">-		if (shadow)</span>
<span class="p_del">-			memset(shadow, status, PAGE_SIZE);</span>
<span class="p_del">-</span>
<span class="p_del">-		addr += PAGE_SIZE;</span>
<span class="p_del">-		n -= PAGE_SIZE;</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">-	/* Do the remaining page, if any. */</span>
<span class="p_del">-	if (n &gt; 0) {</span>
<span class="p_del">-		shadow = kmemcheck_shadow_lookup(addr);</span>
<span class="p_del">-		if (shadow)</span>
<span class="p_del">-			memset(shadow, status, n);</span>
<span class="p_del">-	}</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-void kmemcheck_mark_unallocated(void *address, unsigned int n)</span>
<span class="p_del">-{</span>
<span class="p_del">-	mark_shadow(address, n, KMEMCHECK_SHADOW_UNALLOCATED);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-void kmemcheck_mark_uninitialized(void *address, unsigned int n)</span>
<span class="p_del">-{</span>
<span class="p_del">-	mark_shadow(address, n, KMEMCHECK_SHADOW_UNINITIALIZED);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-/*</span>
<span class="p_del">- * Fill the shadow memory of the given address such that the memory at that</span>
<span class="p_del">- * address is marked as being initialized.</span>
<span class="p_del">- */</span>
<span class="p_del">-void kmemcheck_mark_initialized(void *address, unsigned int n)</span>
<span class="p_del">-{</span>
<span class="p_del">-	mark_shadow(address, n, KMEMCHECK_SHADOW_INITIALIZED);</span>
<span class="p_del">-}</span>
<span class="p_del">-EXPORT_SYMBOL_GPL(kmemcheck_mark_initialized);</span>
<span class="p_del">-</span>
<span class="p_del">-void kmemcheck_mark_freed(void *address, unsigned int n)</span>
<span class="p_del">-{</span>
<span class="p_del">-	mark_shadow(address, n, KMEMCHECK_SHADOW_FREED);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-void kmemcheck_mark_unallocated_pages(struct page *p, unsigned int n)</span>
<span class="p_del">-{</span>
<span class="p_del">-	unsigned int i;</span>
<span class="p_del">-</span>
<span class="p_del">-	for (i = 0; i &lt; n; ++i)</span>
<span class="p_del">-		kmemcheck_mark_unallocated(page_address(&amp;p[i]), PAGE_SIZE);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-void kmemcheck_mark_uninitialized_pages(struct page *p, unsigned int n)</span>
<span class="p_del">-{</span>
<span class="p_del">-	unsigned int i;</span>
<span class="p_del">-</span>
<span class="p_del">-	for (i = 0; i &lt; n; ++i)</span>
<span class="p_del">-		kmemcheck_mark_uninitialized(page_address(&amp;p[i]), PAGE_SIZE);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-void kmemcheck_mark_initialized_pages(struct page *p, unsigned int n)</span>
<span class="p_del">-{</span>
<span class="p_del">-	unsigned int i;</span>
<span class="p_del">-</span>
<span class="p_del">-	for (i = 0; i &lt; n; ++i)</span>
<span class="p_del">-		kmemcheck_mark_initialized(page_address(&amp;p[i]), PAGE_SIZE);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-enum kmemcheck_shadow kmemcheck_shadow_test(void *shadow, unsigned int size)</span>
<span class="p_del">-{</span>
<span class="p_del">-#ifdef CONFIG_KMEMCHECK_PARTIAL_OK</span>
<span class="p_del">-	uint8_t *x;</span>
<span class="p_del">-	unsigned int i;</span>
<span class="p_del">-</span>
<span class="p_del">-	x = shadow;</span>
<span class="p_del">-</span>
<span class="p_del">-	/*</span>
<span class="p_del">-	 * Make sure _some_ bytes are initialized. Gcc frequently generates</span>
<span class="p_del">-	 * code to access neighboring bytes.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	for (i = 0; i &lt; size; ++i) {</span>
<span class="p_del">-		if (x[i] == KMEMCHECK_SHADOW_INITIALIZED)</span>
<span class="p_del">-			return x[i];</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">-	return x[0];</span>
<span class="p_del">-#else</span>
<span class="p_del">-	return kmemcheck_shadow_test_all(shadow, size);</span>
<span class="p_del">-#endif</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-enum kmemcheck_shadow kmemcheck_shadow_test_all(void *shadow, unsigned int size)</span>
<span class="p_del">-{</span>
<span class="p_del">-	uint8_t *x;</span>
<span class="p_del">-	unsigned int i;</span>
<span class="p_del">-</span>
<span class="p_del">-	x = shadow;</span>
<span class="p_del">-</span>
<span class="p_del">-	/* All bytes must be initialized. */</span>
<span class="p_del">-	for (i = 0; i &lt; size; ++i) {</span>
<span class="p_del">-		if (x[i] != KMEMCHECK_SHADOW_INITIALIZED)</span>
<span class="p_del">-			return x[i];</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">-	return x[0];</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-void kmemcheck_shadow_set(void *shadow, unsigned int size)</span>
<span class="p_del">-{</span>
<span class="p_del">-	uint8_t *x;</span>
<span class="p_del">-	unsigned int i;</span>
<span class="p_del">-</span>
<span class="p_del">-	x = shadow;</span>
<span class="p_del">-	for (i = 0; i &lt; size; ++i)</span>
<span class="p_del">-		x[i] = KMEMCHECK_SHADOW_INITIALIZED;</span>
<span class="p_del">-}</span>
<span class="p_header">diff --git a/arch/x86/mm/kmemcheck/shadow.h b/arch/x86/mm/kmemcheck/shadow.h</span>
deleted file mode 100644
<span class="p_header">index ff0b2f70fbcb..000000000000</span>
<span class="p_header">--- a/arch/x86/mm/kmemcheck/shadow.h</span>
<span class="p_header">+++ /dev/null</span>
<span class="p_chunk">@@ -1,18 +0,0 @@</span> <span class="p_context"></span>
<span class="p_del">-#ifndef ARCH__X86__MM__KMEMCHECK__SHADOW_H</span>
<span class="p_del">-#define ARCH__X86__MM__KMEMCHECK__SHADOW_H</span>
<span class="p_del">-</span>
<span class="p_del">-enum kmemcheck_shadow {</span>
<span class="p_del">-	KMEMCHECK_SHADOW_UNALLOCATED,</span>
<span class="p_del">-	KMEMCHECK_SHADOW_UNINITIALIZED,</span>
<span class="p_del">-	KMEMCHECK_SHADOW_INITIALIZED,</span>
<span class="p_del">-	KMEMCHECK_SHADOW_FREED,</span>
<span class="p_del">-};</span>
<span class="p_del">-</span>
<span class="p_del">-void *kmemcheck_shadow_lookup(unsigned long address);</span>
<span class="p_del">-</span>
<span class="p_del">-enum kmemcheck_shadow kmemcheck_shadow_test(void *shadow, unsigned int size);</span>
<span class="p_del">-enum kmemcheck_shadow kmemcheck_shadow_test_all(void *shadow,</span>
<span class="p_del">-						unsigned int size);</span>
<span class="p_del">-void kmemcheck_shadow_set(void *shadow, unsigned int size);</span>
<span class="p_del">-</span>
<span class="p_del">-#endif</span>
<span class="p_header">diff --git a/arch/x86/mm/pageattr.c b/arch/x86/mm/pageattr.c</span>
<span class="p_header">index dfb7d657cf43..3ed9a08885c5 100644</span>
<span class="p_header">--- a/arch/x86/mm/pageattr.c</span>
<span class="p_header">+++ b/arch/x86/mm/pageattr.c</span>
<span class="p_chunk">@@ -753,7 +753,7 @@</span> <span class="p_context"> static int split_large_page(struct cpa_data *cpa, pte_t *kpte,</span>
 
 	if (!debug_pagealloc_enabled())
 		spin_unlock(&amp;cpa_lock);
<span class="p_del">-	base = alloc_pages(GFP_KERNEL | __GFP_NOTRACK, 0);</span>
<span class="p_add">+	base = alloc_pages(GFP_KERNEL, 0);</span>
 	if (!debug_pagealloc_enabled())
 		spin_lock(&amp;cpa_lock);
 	if (!base)
<span class="p_chunk">@@ -904,7 +904,7 @@</span> <span class="p_context"> static void unmap_pud_range(p4d_t *p4d, unsigned long start, unsigned long end)</span>
 
 static int alloc_pte_page(pmd_t *pmd)
 {
<span class="p_del">-	pte_t *pte = (pte_t *)get_zeroed_page(GFP_KERNEL | __GFP_NOTRACK);</span>
<span class="p_add">+	pte_t *pte = (pte_t *)get_zeroed_page(GFP_KERNEL);</span>
 	if (!pte)
 		return -1;
 
<span class="p_chunk">@@ -914,7 +914,7 @@</span> <span class="p_context"> static int alloc_pte_page(pmd_t *pmd)</span>
 
 static int alloc_pmd_page(pud_t *pud)
 {
<span class="p_del">-	pmd_t *pmd = (pmd_t *)get_zeroed_page(GFP_KERNEL | __GFP_NOTRACK);</span>
<span class="p_add">+	pmd_t *pmd = (pmd_t *)get_zeroed_page(GFP_KERNEL);</span>
 	if (!pmd)
 		return -1;
 
<span class="p_chunk">@@ -1120,7 +1120,7 @@</span> <span class="p_context"> static int populate_pgd(struct cpa_data *cpa, unsigned long addr)</span>
 	pgd_entry = cpa-&gt;pgd + pgd_index(addr);
 
 	if (pgd_none(*pgd_entry)) {
<span class="p_del">-		p4d = (p4d_t *)get_zeroed_page(GFP_KERNEL | __GFP_NOTRACK);</span>
<span class="p_add">+		p4d = (p4d_t *)get_zeroed_page(GFP_KERNEL);</span>
 		if (!p4d)
 			return -1;
 
<span class="p_chunk">@@ -1132,7 +1132,7 @@</span> <span class="p_context"> static int populate_pgd(struct cpa_data *cpa, unsigned long addr)</span>
 	 */
 	p4d = p4d_offset(pgd_entry, addr);
 	if (p4d_none(*p4d)) {
<span class="p_del">-		pud = (pud_t *)get_zeroed_page(GFP_KERNEL | __GFP_NOTRACK);</span>
<span class="p_add">+		pud = (pud_t *)get_zeroed_page(GFP_KERNEL);</span>
 		if (!pud)
 			return -1;
 
<span class="p_header">diff --git a/arch/x86/mm/pgtable.c b/arch/x86/mm/pgtable.c</span>
<span class="p_header">index b372f3442bbf..dc686d2fc59a 100644</span>
<span class="p_header">--- a/arch/x86/mm/pgtable.c</span>
<span class="p_header">+++ b/arch/x86/mm/pgtable.c</span>
<span class="p_chunk">@@ -6,7 +6,7 @@</span> <span class="p_context"></span>
 #include &lt;asm/fixmap.h&gt;
 #include &lt;asm/mtrr.h&gt;
 
<span class="p_del">-#define PGALLOC_GFP (GFP_KERNEL_ACCOUNT | __GFP_NOTRACK | __GFP_ZERO)</span>
<span class="p_add">+#define PGALLOC_GFP (GFP_KERNEL_ACCOUNT | __GFP_ZERO)</span>
 
 #ifdef CONFIG_HIGHPTE
 #define PGALLOC_USER_GFP __GFP_HIGHMEM
<span class="p_header">diff --git a/arch/x86/platform/efi/efi_64.c b/arch/x86/platform/efi/efi_64.c</span>
<span class="p_header">index 12e83888e5b9..fe3aebb87468 100644</span>
<span class="p_header">--- a/arch/x86/platform/efi/efi_64.c</span>
<span class="p_header">+++ b/arch/x86/platform/efi/efi_64.c</span>
<span class="p_chunk">@@ -205,7 +205,7 @@</span> <span class="p_context"> int __init efi_alloc_page_tables(void)</span>
 	if (efi_enabled(EFI_OLD_MEMMAP))
 		return 0;
 
<span class="p_del">-	gfp_mask = GFP_KERNEL | __GFP_NOTRACK | __GFP_ZERO;</span>
<span class="p_add">+	gfp_mask = GFP_KERNEL | __GFP_ZERO;</span>
 	efi_pgd = (pgd_t *)__get_free_page(gfp_mask);
 	if (!efi_pgd)
 		return -ENOMEM;
<span class="p_header">diff --git a/crypto/xor.c b/crypto/xor.c</span>
<span class="p_header">index 263af9fb45ea..bce9fe7af40a 100644</span>
<span class="p_header">--- a/crypto/xor.c</span>
<span class="p_header">+++ b/crypto/xor.c</span>
<span class="p_chunk">@@ -122,12 +122,7 @@</span> <span class="p_context"> calibrate_xor_blocks(void)</span>
 		goto out;
 	}
 
<span class="p_del">-	/*</span>
<span class="p_del">-	 * Note: Since the memory is not actually used for _anything_ but to</span>
<span class="p_del">-	 * test the XOR speed, we don&#39;t really want kmemcheck to warn about</span>
<span class="p_del">-	 * reading uninitialized bytes here.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	b1 = (void *) __get_free_pages(GFP_KERNEL | __GFP_NOTRACK, 2);</span>
<span class="p_add">+	b1 = (void *) __get_free_pages(GFP_KERNEL, 2);</span>
 	if (!b1) {
 		printk(KERN_WARNING &quot;xor: Yikes!  No memory available.\n&quot;);
 		return -ENOMEM;
<span class="p_header">diff --git a/drivers/char/random.c b/drivers/char/random.c</span>
<span class="p_header">index 8ad92707e45f..ea0115cf5fc0 100644</span>
<span class="p_header">--- a/drivers/char/random.c</span>
<span class="p_header">+++ b/drivers/char/random.c</span>
<span class="p_chunk">@@ -259,7 +259,6 @@</span> <span class="p_context"></span>
 #include &lt;linux/cryptohash.h&gt;
 #include &lt;linux/fips.h&gt;
 #include &lt;linux/ptrace.h&gt;
<span class="p_del">-#include &lt;linux/kmemcheck.h&gt;</span>
 #include &lt;linux/workqueue.h&gt;
 #include &lt;linux/irq.h&gt;
 #include &lt;linux/syscalls.h&gt;
<span class="p_header">diff --git a/drivers/misc/c2port/core.c b/drivers/misc/c2port/core.c</span>
<span class="p_header">index 1922cb8f6b88..1c5b7aec13d4 100644</span>
<span class="p_header">--- a/drivers/misc/c2port/core.c</span>
<span class="p_header">+++ b/drivers/misc/c2port/core.c</span>
<span class="p_chunk">@@ -15,7 +15,6 @@</span> <span class="p_context"></span>
 #include &lt;linux/errno.h&gt;
 #include &lt;linux/err.h&gt;
 #include &lt;linux/kernel.h&gt;
<span class="p_del">-#include &lt;linux/kmemcheck.h&gt;</span>
 #include &lt;linux/ctype.h&gt;
 #include &lt;linux/delay.h&gt;
 #include &lt;linux/idr.h&gt;
<span class="p_chunk">@@ -904,7 +903,6 @@</span> <span class="p_context"> struct c2port_device *c2port_device_register(char *name,</span>
 		return ERR_PTR(-EINVAL);
 
 	c2dev = kmalloc(sizeof(struct c2port_device), GFP_KERNEL);
<span class="p_del">-	kmemcheck_annotate_bitfield(c2dev, flags);</span>
 	if (unlikely(!c2dev))
 		return ERR_PTR(-ENOMEM);
 
<span class="p_header">diff --git a/fs/dcache.c b/fs/dcache.c</span>
<span class="p_header">index f90141387f01..96f3af133ee6 100644</span>
<span class="p_header">--- a/fs/dcache.c</span>
<span class="p_header">+++ b/fs/dcache.c</span>
<span class="p_chunk">@@ -2705,8 +2705,6 @@</span> <span class="p_context"> static void swap_names(struct dentry *dentry, struct dentry *target)</span>
 			 */
 			unsigned int i;
 			BUILD_BUG_ON(!IS_ALIGNED(DNAME_INLINE_LEN, sizeof(long)));
<span class="p_del">-			kmemcheck_mark_initialized(dentry-&gt;d_iname, DNAME_INLINE_LEN);</span>
<span class="p_del">-			kmemcheck_mark_initialized(target-&gt;d_iname, DNAME_INLINE_LEN);</span>
 			for (i = 0; i &lt; DNAME_INLINE_LEN / sizeof(long); i++) {
 				swap(((long *) &amp;dentry-&gt;d_iname)[i],
 				     ((long *) &amp;target-&gt;d_iname)[i]);
<span class="p_header">diff --git a/include/linux/c2port.h b/include/linux/c2port.h</span>
<span class="p_header">index 4efabcb51347..f2736348ca26 100644</span>
<span class="p_header">--- a/include/linux/c2port.h</span>
<span class="p_header">+++ b/include/linux/c2port.h</span>
<span class="p_chunk">@@ -9,8 +9,6 @@</span> <span class="p_context"></span>
  * the Free Software Foundation
  */
 
<span class="p_del">-#include &lt;linux/kmemcheck.h&gt;</span>
<span class="p_del">-</span>
 #define C2PORT_NAME_LEN			32
 
 struct device;
<span class="p_chunk">@@ -22,10 +20,8 @@</span> <span class="p_context"> struct device;</span>
 /* Main struct */
 struct c2port_ops;
 struct c2port_device {
<span class="p_del">-	kmemcheck_bitfield_begin(flags);</span>
 	unsigned int access:1;
 	unsigned int flash_access:1;
<span class="p_del">-	kmemcheck_bitfield_end(flags);</span>
 
 	int id;
 	char name[C2PORT_NAME_LEN];
<span class="p_header">diff --git a/include/linux/dma-mapping.h b/include/linux/dma-mapping.h</span>
<span class="p_header">index 29ce9815da87..2911389bc147 100644</span>
<span class="p_header">--- a/include/linux/dma-mapping.h</span>
<span class="p_header">+++ b/include/linux/dma-mapping.h</span>
<span class="p_chunk">@@ -8,7 +8,6 @@</span> <span class="p_context"></span>
 #include &lt;linux/dma-debug.h&gt;
 #include &lt;linux/dma-direction.h&gt;
 #include &lt;linux/scatterlist.h&gt;
<span class="p_del">-#include &lt;linux/kmemcheck.h&gt;</span>
 #include &lt;linux/bug.h&gt;
 #include &lt;linux/mem_encrypt.h&gt;
 
<span class="p_chunk">@@ -229,7 +228,6 @@</span> <span class="p_context"> static inline dma_addr_t dma_map_single_attrs(struct device *dev, void *ptr,</span>
 	const struct dma_map_ops *ops = get_dma_ops(dev);
 	dma_addr_t addr;
 
<span class="p_del">-	kmemcheck_mark_initialized(ptr, size);</span>
 	BUG_ON(!valid_dma_direction(dir));
 	addr = ops-&gt;map_page(dev, virt_to_page(ptr),
 			     offset_in_page(ptr), size,
<span class="p_chunk">@@ -262,11 +260,8 @@</span> <span class="p_context"> static inline int dma_map_sg_attrs(struct device *dev, struct scatterlist *sg,</span>
 				   unsigned long attrs)
 {
 	const struct dma_map_ops *ops = get_dma_ops(dev);
<span class="p_del">-	int i, ents;</span>
<span class="p_del">-	struct scatterlist *s;</span>
<span class="p_add">+	int ents;</span>
 
<span class="p_del">-	for_each_sg(sg, s, nents, i)</span>
<span class="p_del">-		kmemcheck_mark_initialized(sg_virt(s), s-&gt;length);</span>
 	BUG_ON(!valid_dma_direction(dir));
 	ents = ops-&gt;map_sg(dev, sg, nents, dir, attrs);
 	BUG_ON(ents &lt; 0);
<span class="p_chunk">@@ -296,7 +291,6 @@</span> <span class="p_context"> static inline dma_addr_t dma_map_page_attrs(struct device *dev,</span>
 	const struct dma_map_ops *ops = get_dma_ops(dev);
 	dma_addr_t addr;
 
<span class="p_del">-	kmemcheck_mark_initialized(page_address(page) + offset, size);</span>
 	BUG_ON(!valid_dma_direction(dir));
 	addr = ops-&gt;map_page(dev, page, offset, size, dir, attrs);
 	debug_dma_map_page(dev, page, offset, size, dir, addr, false);
<span class="p_header">diff --git a/include/linux/filter.h b/include/linux/filter.h</span>
<span class="p_header">index d29e58fde364..9a0022cd70c6 100644</span>
<span class="p_header">--- a/include/linux/filter.h</span>
<span class="p_header">+++ b/include/linux/filter.h</span>
<span class="p_chunk">@@ -453,13 +453,11 @@</span> <span class="p_context"> struct bpf_binary_header {</span>
 
 struct bpf_prog {
 	u16			pages;		/* Number of allocated pages */
<span class="p_del">-	kmemcheck_bitfield_begin(meta);</span>
 	u16			jited:1,	/* Is our filter JIT&#39;ed? */
 				locked:1,	/* Program image locked? */
 				gpl_compatible:1, /* Is filter GPL compatible? */
 				cb_access:1,	/* Is control block accessed? */
 				dst_needed:1;	/* Do we need dst entry? */
<span class="p_del">-	kmemcheck_bitfield_end(meta);</span>
 	enum bpf_prog_type	type;		/* Type of BPF program */
 	u32			len;		/* Number of filter blocks */
 	u32			jited_len;	/* Size of jited insns in bytes */
<span class="p_header">diff --git a/include/linux/gfp.h b/include/linux/gfp.h</span>
<span class="p_header">index f780718b7391..3427fb8d936a 100644</span>
<span class="p_header">--- a/include/linux/gfp.h</span>
<span class="p_header">+++ b/include/linux/gfp.h</span>
<span class="p_chunk">@@ -36,7 +36,6 @@</span> <span class="p_context"> struct vm_area_struct;</span>
 #define ___GFP_THISNODE		0x40000u
 #define ___GFP_ATOMIC		0x80000u
 #define ___GFP_ACCOUNT		0x100000u
<span class="p_del">-#define ___GFP_NOTRACK		0x200000u</span>
 #define ___GFP_DIRECT_RECLAIM	0x400000u
 #define ___GFP_WRITE		0x800000u
 #define ___GFP_KSWAPD_RECLAIM	0x1000000u
<span class="p_chunk">@@ -200,19 +199,11 @@</span> <span class="p_context"> struct vm_area_struct;</span>
  * __GFP_COMP address compound page metadata.
  *
  * __GFP_ZERO returns a zeroed page on success.
<span class="p_del">- *</span>
<span class="p_del">- * __GFP_NOTRACK avoids tracking with kmemcheck.</span>
<span class="p_del">- *</span>
<span class="p_del">- * __GFP_NOTRACK_FALSE_POSITIVE is an alias of __GFP_NOTRACK. It&#39;s a means of</span>
<span class="p_del">- *   distinguishing in the source between false positives and allocations that</span>
<span class="p_del">- *   cannot be supported (e.g. page tables).</span>
  */
 #define __GFP_COLD	((__force gfp_t)___GFP_COLD)
 #define __GFP_NOWARN	((__force gfp_t)___GFP_NOWARN)
 #define __GFP_COMP	((__force gfp_t)___GFP_COMP)
 #define __GFP_ZERO	((__force gfp_t)___GFP_ZERO)
<span class="p_del">-#define __GFP_NOTRACK	((__force gfp_t)___GFP_NOTRACK)</span>
<span class="p_del">-#define __GFP_NOTRACK_FALSE_POSITIVE (__GFP_NOTRACK)</span>
 
 /* Disable lockdep for GFP context tracking */
 #define __GFP_NOLOCKDEP ((__force gfp_t)___GFP_NOLOCKDEP)
<span class="p_header">diff --git a/include/linux/interrupt.h b/include/linux/interrupt.h</span>
<span class="p_header">index 59ba11661b6e..0cca55dd19ba 100644</span>
<span class="p_header">--- a/include/linux/interrupt.h</span>
<span class="p_header">+++ b/include/linux/interrupt.h</span>
<span class="p_chunk">@@ -593,21 +593,6 @@</span> <span class="p_context"> static inline void tasklet_hi_schedule(struct tasklet_struct *t)</span>
 		__tasklet_hi_schedule(t);
 }
 
<span class="p_del">-extern void __tasklet_hi_schedule_first(struct tasklet_struct *t);</span>
<span class="p_del">-</span>
<span class="p_del">-/*</span>
<span class="p_del">- * This version avoids touching any other tasklets. Needed for kmemcheck</span>
<span class="p_del">- * in order not to take any page faults while enqueueing this tasklet;</span>
<span class="p_del">- * consider VERY carefully whether you really need this or</span>
<span class="p_del">- * tasklet_hi_schedule()...</span>
<span class="p_del">- */</span>
<span class="p_del">-static inline void tasklet_hi_schedule_first(struct tasklet_struct *t)</span>
<span class="p_del">-{</span>
<span class="p_del">-	if (!test_and_set_bit(TASKLET_STATE_SCHED, &amp;t-&gt;state))</span>
<span class="p_del">-		__tasklet_hi_schedule_first(t);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-</span>
 static inline void tasklet_disable_nosync(struct tasklet_struct *t)
 {
 	atomic_inc(&amp;t-&gt;count);
<span class="p_header">diff --git a/include/linux/kmemcheck.h b/include/linux/kmemcheck.h</span>
deleted file mode 100644
<span class="p_header">index 39f8453239f7..000000000000</span>
<span class="p_header">--- a/include/linux/kmemcheck.h</span>
<span class="p_header">+++ /dev/null</span>
<span class="p_chunk">@@ -1,171 +0,0 @@</span> <span class="p_context"></span>
<span class="p_del">-#ifndef LINUX_KMEMCHECK_H</span>
<span class="p_del">-#define LINUX_KMEMCHECK_H</span>
<span class="p_del">-</span>
<span class="p_del">-#include &lt;linux/mm_types.h&gt;</span>
<span class="p_del">-#include &lt;linux/types.h&gt;</span>
<span class="p_del">-</span>
<span class="p_del">-#ifdef CONFIG_KMEMCHECK</span>
<span class="p_del">-extern int kmemcheck_enabled;</span>
<span class="p_del">-</span>
<span class="p_del">-/* The slab-related functions. */</span>
<span class="p_del">-void kmemcheck_alloc_shadow(struct page *page, int order, gfp_t flags, int node);</span>
<span class="p_del">-void kmemcheck_free_shadow(struct page *page, int order);</span>
<span class="p_del">-void kmemcheck_slab_alloc(struct kmem_cache *s, gfp_t gfpflags, void *object,</span>
<span class="p_del">-			  size_t size);</span>
<span class="p_del">-void kmemcheck_slab_free(struct kmem_cache *s, void *object, size_t size);</span>
<span class="p_del">-</span>
<span class="p_del">-void kmemcheck_pagealloc_alloc(struct page *p, unsigned int order,</span>
<span class="p_del">-			       gfp_t gfpflags);</span>
<span class="p_del">-</span>
<span class="p_del">-void kmemcheck_show_pages(struct page *p, unsigned int n);</span>
<span class="p_del">-void kmemcheck_hide_pages(struct page *p, unsigned int n);</span>
<span class="p_del">-</span>
<span class="p_del">-bool kmemcheck_page_is_tracked(struct page *p);</span>
<span class="p_del">-</span>
<span class="p_del">-void kmemcheck_mark_unallocated(void *address, unsigned int n);</span>
<span class="p_del">-void kmemcheck_mark_uninitialized(void *address, unsigned int n);</span>
<span class="p_del">-void kmemcheck_mark_initialized(void *address, unsigned int n);</span>
<span class="p_del">-void kmemcheck_mark_freed(void *address, unsigned int n);</span>
<span class="p_del">-</span>
<span class="p_del">-void kmemcheck_mark_unallocated_pages(struct page *p, unsigned int n);</span>
<span class="p_del">-void kmemcheck_mark_uninitialized_pages(struct page *p, unsigned int n);</span>
<span class="p_del">-void kmemcheck_mark_initialized_pages(struct page *p, unsigned int n);</span>
<span class="p_del">-</span>
<span class="p_del">-int kmemcheck_show_addr(unsigned long address);</span>
<span class="p_del">-int kmemcheck_hide_addr(unsigned long address);</span>
<span class="p_del">-</span>
<span class="p_del">-bool kmemcheck_is_obj_initialized(unsigned long addr, size_t size);</span>
<span class="p_del">-</span>
<span class="p_del">-/*</span>
<span class="p_del">- * Bitfield annotations</span>
<span class="p_del">- *</span>
<span class="p_del">- * How to use: If you have a struct using bitfields, for example</span>
<span class="p_del">- *</span>
<span class="p_del">- *     struct a {</span>
<span class="p_del">- *             int x:8, y:8;</span>
<span class="p_del">- *     };</span>
<span class="p_del">- *</span>
<span class="p_del">- * then this should be rewritten as</span>
<span class="p_del">- *</span>
<span class="p_del">- *     struct a {</span>
<span class="p_del">- *             kmemcheck_bitfield_begin(flags);</span>
<span class="p_del">- *             int x:8, y:8;</span>
<span class="p_del">- *             kmemcheck_bitfield_end(flags);</span>
<span class="p_del">- *     };</span>
<span class="p_del">- *</span>
<span class="p_del">- * Now the &quot;flags_begin&quot; and &quot;flags_end&quot; members may be used to refer to the</span>
<span class="p_del">- * beginning and end, respectively, of the bitfield (and things like</span>
<span class="p_del">- * &amp;x.flags_begin is allowed). As soon as the struct is allocated, the bit-</span>
<span class="p_del">- * fields should be annotated:</span>
<span class="p_del">- *</span>
<span class="p_del">- *     struct a *a = kmalloc(sizeof(struct a), GFP_KERNEL);</span>
<span class="p_del">- *     kmemcheck_annotate_bitfield(a, flags);</span>
<span class="p_del">- */</span>
<span class="p_del">-#define kmemcheck_bitfield_begin(name)	\</span>
<span class="p_del">-	int name##_begin[0];</span>
<span class="p_del">-</span>
<span class="p_del">-#define kmemcheck_bitfield_end(name)	\</span>
<span class="p_del">-	int name##_end[0];</span>
<span class="p_del">-</span>
<span class="p_del">-#define kmemcheck_annotate_bitfield(ptr, name)				\</span>
<span class="p_del">-	do {								\</span>
<span class="p_del">-		int _n;							\</span>
<span class="p_del">-									\</span>
<span class="p_del">-		if (!ptr)						\</span>
<span class="p_del">-			break;						\</span>
<span class="p_del">-									\</span>
<span class="p_del">-		_n = (long) &amp;((ptr)-&gt;name##_end)			\</span>
<span class="p_del">-			- (long) &amp;((ptr)-&gt;name##_begin);		\</span>
<span class="p_del">-		BUILD_BUG_ON(_n &lt; 0);					\</span>
<span class="p_del">-									\</span>
<span class="p_del">-		kmemcheck_mark_initialized(&amp;((ptr)-&gt;name##_begin), _n);	\</span>
<span class="p_del">-	} while (0)</span>
<span class="p_del">-</span>
<span class="p_del">-#define kmemcheck_annotate_variable(var)				\</span>
<span class="p_del">-	do {								\</span>
<span class="p_del">-		kmemcheck_mark_initialized(&amp;(var), sizeof(var));	\</span>
<span class="p_del">-	} while (0)							\</span>
<span class="p_del">-</span>
<span class="p_del">-#else</span>
<span class="p_del">-#define kmemcheck_enabled 0</span>
<span class="p_del">-</span>
<span class="p_del">-static inline void</span>
<span class="p_del">-kmemcheck_alloc_shadow(struct page *page, int order, gfp_t flags, int node)</span>
<span class="p_del">-{</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static inline void</span>
<span class="p_del">-kmemcheck_free_shadow(struct page *page, int order)</span>
<span class="p_del">-{</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static inline void</span>
<span class="p_del">-kmemcheck_slab_alloc(struct kmem_cache *s, gfp_t gfpflags, void *object,</span>
<span class="p_del">-		     size_t size)</span>
<span class="p_del">-{</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static inline void kmemcheck_slab_free(struct kmem_cache *s, void *object,</span>
<span class="p_del">-				       size_t size)</span>
<span class="p_del">-{</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static inline void kmemcheck_pagealloc_alloc(struct page *p,</span>
<span class="p_del">-	unsigned int order, gfp_t gfpflags)</span>
<span class="p_del">-{</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static inline bool kmemcheck_page_is_tracked(struct page *p)</span>
<span class="p_del">-{</span>
<span class="p_del">-	return false;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static inline void kmemcheck_mark_unallocated(void *address, unsigned int n)</span>
<span class="p_del">-{</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static inline void kmemcheck_mark_uninitialized(void *address, unsigned int n)</span>
<span class="p_del">-{</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static inline void kmemcheck_mark_initialized(void *address, unsigned int n)</span>
<span class="p_del">-{</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static inline void kmemcheck_mark_freed(void *address, unsigned int n)</span>
<span class="p_del">-{</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static inline void kmemcheck_mark_unallocated_pages(struct page *p,</span>
<span class="p_del">-						    unsigned int n)</span>
<span class="p_del">-{</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static inline void kmemcheck_mark_uninitialized_pages(struct page *p,</span>
<span class="p_del">-						      unsigned int n)</span>
<span class="p_del">-{</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static inline void kmemcheck_mark_initialized_pages(struct page *p,</span>
<span class="p_del">-						    unsigned int n)</span>
<span class="p_del">-{</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static inline bool kmemcheck_is_obj_initialized(unsigned long addr, size_t size)</span>
<span class="p_del">-{</span>
<span class="p_del">-	return true;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-#define kmemcheck_bitfield_begin(name)</span>
<span class="p_del">-#define kmemcheck_bitfield_end(name)</span>
<span class="p_del">-#define kmemcheck_annotate_bitfield(ptr, name)	\</span>
<span class="p_del">-	do {					\</span>
<span class="p_del">-	} while (0)</span>
<span class="p_del">-</span>
<span class="p_del">-#define kmemcheck_annotate_variable(var)	\</span>
<span class="p_del">-	do {					\</span>
<span class="p_del">-	} while (0)</span>
<span class="p_del">-</span>
<span class="p_del">-#endif /* CONFIG_KMEMCHECK */</span>
<span class="p_del">-</span>
<span class="p_del">-#endif /* LINUX_KMEMCHECK_H */</span>
<span class="p_header">diff --git a/include/linux/mm_types.h b/include/linux/mm_types.h</span>
<span class="p_header">index 46f4ecf5479a..804d0e754ab0 100644</span>
<span class="p_header">--- a/include/linux/mm_types.h</span>
<span class="p_header">+++ b/include/linux/mm_types.h</span>
<span class="p_chunk">@@ -206,14 +206,6 @@</span> <span class="p_context"> struct page {</span>
 					   not kmapped, ie. highmem) */
 #endif /* WANT_PAGE_VIRTUAL */
 
<span class="p_del">-#ifdef CONFIG_KMEMCHECK</span>
<span class="p_del">-	/*</span>
<span class="p_del">-	 * kmemcheck wants to track the status of each byte in a page; this</span>
<span class="p_del">-	 * is a pointer to such a status block. NULL if not tracked.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	void *shadow;</span>
<span class="p_del">-#endif</span>
<span class="p_del">-</span>
 #ifdef LAST_CPUPID_NOT_IN_PAGE_FLAGS
 	int _last_cpupid;
 #endif
<span class="p_header">diff --git a/include/linux/net.h b/include/linux/net.h</span>
<span class="p_header">index d97d80d7fdf8..caeb159abda5 100644</span>
<span class="p_header">--- a/include/linux/net.h</span>
<span class="p_header">+++ b/include/linux/net.h</span>
<span class="p_chunk">@@ -22,7 +22,6 @@</span> <span class="p_context"></span>
 #include &lt;linux/random.h&gt;
 #include &lt;linux/wait.h&gt;
 #include &lt;linux/fcntl.h&gt;	/* For O_CLOEXEC and O_NONBLOCK */
<span class="p_del">-#include &lt;linux/kmemcheck.h&gt;</span>
 #include &lt;linux/rcupdate.h&gt;
 #include &lt;linux/once.h&gt;
 #include &lt;linux/fs.h&gt;
<span class="p_chunk">@@ -111,9 +110,7 @@</span> <span class="p_context"> struct socket_wq {</span>
 struct socket {
 	socket_state		state;
 
<span class="p_del">-	kmemcheck_bitfield_begin(type);</span>
 	short			type;
<span class="p_del">-	kmemcheck_bitfield_end(type);</span>
 
 	unsigned long		flags;
 
<span class="p_header">diff --git a/include/linux/ring_buffer.h b/include/linux/ring_buffer.h</span>
<span class="p_header">index ee9b461af095..8c0c6d236c49 100644</span>
<span class="p_header">--- a/include/linux/ring_buffer.h</span>
<span class="p_header">+++ b/include/linux/ring_buffer.h</span>
<span class="p_chunk">@@ -1,7 +1,6 @@</span> <span class="p_context"></span>
 #ifndef _LINUX_RING_BUFFER_H
 #define _LINUX_RING_BUFFER_H
 
<span class="p_del">-#include &lt;linux/kmemcheck.h&gt;</span>
 #include &lt;linux/mm.h&gt;
 #include &lt;linux/seq_file.h&gt;
 #include &lt;linux/poll.h&gt;
<span class="p_chunk">@@ -13,9 +12,7 @@</span> <span class="p_context"> struct ring_buffer_iter;</span>
  * Don&#39;t refer to this struct directly, use functions below.
  */
 struct ring_buffer_event {
<span class="p_del">-	kmemcheck_bitfield_begin(bitfield);</span>
 	u32		type_len:5, time_delta:27;
<span class="p_del">-	kmemcheck_bitfield_end(bitfield);</span>
 
 	u32		array[];
 };
<span class="p_header">diff --git a/include/linux/skbuff.h b/include/linux/skbuff.h</span>
<span class="p_header">index 72299ef00061..ac4041af7f37 100644</span>
<span class="p_header">--- a/include/linux/skbuff.h</span>
<span class="p_header">+++ b/include/linux/skbuff.h</span>
<span class="p_chunk">@@ -15,7 +15,6 @@</span> <span class="p_context"></span>
 #define _LINUX_SKBUFF_H
 
 #include &lt;linux/kernel.h&gt;
<span class="p_del">-#include &lt;linux/kmemcheck.h&gt;</span>
 #include &lt;linux/compiler.h&gt;
 #include &lt;linux/time.h&gt;
 #include &lt;linux/bug.h&gt;
<span class="p_chunk">@@ -704,7 +703,6 @@</span> <span class="p_context"> struct sk_buff {</span>
 	/* Following fields are _not_ copied in __copy_skb_header()
 	 * Note that queue_mapping is here mostly to fill a hole.
 	 */
<span class="p_del">-	kmemcheck_bitfield_begin(flags1);</span>
 	__u16			queue_mapping;
 
 /* if you move cloned around you also must adapt those constants */
<span class="p_chunk">@@ -723,7 +721,6 @@</span> <span class="p_context"> struct sk_buff {</span>
 				head_frag:1,
 				xmit_more:1,
 				__unused:1; /* one bit hole */
<span class="p_del">-	kmemcheck_bitfield_end(flags1);</span>
 
 	/* fields enclosed in headers_start/headers_end are copied
 	 * using a single memcpy() in __copy_skb_header()
<span class="p_header">diff --git a/include/linux/slab.h b/include/linux/slab.h</span>
<span class="p_header">index 41473df6dfb0..f35c640687a0 100644</span>
<span class="p_header">--- a/include/linux/slab.h</span>
<span class="p_header">+++ b/include/linux/slab.h</span>
<span class="p_chunk">@@ -77,12 +77,6 @@</span> <span class="p_context"></span>
 
 #define SLAB_NOLEAKTRACE	0x00800000UL	/* Avoid kmemleak tracing */
 
<span class="p_del">-/* Don&#39;t track use of uninitialized memory */</span>
<span class="p_del">-#ifdef CONFIG_KMEMCHECK</span>
<span class="p_del">-# define SLAB_NOTRACK		0x01000000UL</span>
<span class="p_del">-#else</span>
<span class="p_del">-# define SLAB_NOTRACK		0x00000000UL</span>
<span class="p_del">-#endif</span>
 #ifdef CONFIG_FAILSLAB
 # define SLAB_FAILSLAB		0x02000000UL	/* Fault injection mark */
 #else
<span class="p_header">diff --git a/include/linux/thread_info.h b/include/linux/thread_info.h</span>
<span class="p_header">index 905d769d8ddc..c1deb611b5bb 100644</span>
<span class="p_header">--- a/include/linux/thread_info.h</span>
<span class="p_header">+++ b/include/linux/thread_info.h</span>
<span class="p_chunk">@@ -43,10 +43,9 @@</span> <span class="p_context"> enum {</span>
 #endif
 
 #ifdef CONFIG_DEBUG_STACK_USAGE
<span class="p_del">-# define THREADINFO_GFP		(GFP_KERNEL_ACCOUNT | __GFP_NOTRACK | \</span>
<span class="p_del">-				 __GFP_ZERO)</span>
<span class="p_add">+# define THREADINFO_GFP		(GFP_KERNEL_ACCOUNT | __GFP_ZERO)</span>
 #else
<span class="p_del">-# define THREADINFO_GFP		(GFP_KERNEL_ACCOUNT | __GFP_NOTRACK)</span>
<span class="p_add">+# define THREADINFO_GFP		(GFP_KERNEL_ACCOUNT)</span>
 #endif
 
 /*
<span class="p_header">diff --git a/include/net/inet_sock.h b/include/net/inet_sock.h</span>
<span class="p_header">index aa95053dfc78..21c3e4d73b88 100644</span>
<span class="p_header">--- a/include/net/inet_sock.h</span>
<span class="p_header">+++ b/include/net/inet_sock.h</span>
<span class="p_chunk">@@ -17,7 +17,6 @@</span> <span class="p_context"></span>
 #define _INET_SOCK_H
 
 #include &lt;linux/bitops.h&gt;
<span class="p_del">-#include &lt;linux/kmemcheck.h&gt;</span>
 #include &lt;linux/string.h&gt;
 #include &lt;linux/types.h&gt;
 #include &lt;linux/jhash.h&gt;
<span class="p_chunk">@@ -84,7 +83,6 @@</span> <span class="p_context"> struct inet_request_sock {</span>
 #define ireq_state		req.__req_common.skc_state
 #define ireq_family		req.__req_common.skc_family
 
<span class="p_del">-	kmemcheck_bitfield_begin(flags);</span>
 	u16			snd_wscale : 4,
 				rcv_wscale : 4,
 				tstamp_ok  : 1,
<span class="p_chunk">@@ -93,7 +91,6 @@</span> <span class="p_context"> struct inet_request_sock {</span>
 				ecn_ok	   : 1,
 				acked	   : 1,
 				no_srccheck: 1;
<span class="p_del">-	kmemcheck_bitfield_end(flags);</span>
 	u32                     ir_mark;
 	union {
 		struct ip_options_rcu	*opt;
<span class="p_header">diff --git a/include/net/inet_timewait_sock.h b/include/net/inet_timewait_sock.h</span>
<span class="p_header">index 6a75d67a30fd..48977ba510d6 100644</span>
<span class="p_header">--- a/include/net/inet_timewait_sock.h</span>
<span class="p_header">+++ b/include/net/inet_timewait_sock.h</span>
<span class="p_chunk">@@ -16,7 +16,6 @@</span> <span class="p_context"></span>
 #define _INET_TIMEWAIT_SOCK_
 
 
<span class="p_del">-#include &lt;linux/kmemcheck.h&gt;</span>
 #include &lt;linux/list.h&gt;
 #include &lt;linux/timer.h&gt;
 #include &lt;linux/types.h&gt;
<span class="p_chunk">@@ -69,14 +68,12 @@</span> <span class="p_context"> struct inet_timewait_sock {</span>
 	/* Socket demultiplex comparisons on incoming packets. */
 	/* these three are in inet_sock */
 	__be16			tw_sport;
<span class="p_del">-	kmemcheck_bitfield_begin(flags);</span>
 	/* And these are ours. */
 	unsigned int		tw_kill		: 1,
 				tw_transparent  : 1,
 				tw_flowlabel	: 20,
 				tw_pad		: 2,	/* 2 bits hole */
 				tw_tos		: 8;
<span class="p_del">-	kmemcheck_bitfield_end(flags);</span>
 	struct timer_list	tw_timer;
 	struct inet_bind_bucket	*tw_tb;
 };
<span class="p_header">diff --git a/include/net/sock.h b/include/net/sock.h</span>
<span class="p_header">index a6b9a8d1a6df..167c687ebdb1 100644</span>
<span class="p_header">--- a/include/net/sock.h</span>
<span class="p_header">+++ b/include/net/sock.h</span>
<span class="p_chunk">@@ -436,7 +436,6 @@</span> <span class="p_context"> struct sock {</span>
 #define SK_FL_TYPE_MASK    0xffff0000
 #endif
 
<span class="p_del">-	kmemcheck_bitfield_begin(flags);</span>
 	unsigned int		sk_padding : 1,
 				sk_kern_sock : 1,
 				sk_no_check_tx : 1,
<span class="p_chunk">@@ -445,7 +444,6 @@</span> <span class="p_context"> struct sock {</span>
 				sk_protocol  : 8,
 				sk_type      : 16;
 #define SK_PROTOCOL_MAX U8_MAX
<span class="p_del">-	kmemcheck_bitfield_end(flags);</span>
 
 	u16			sk_gso_max_segs;
 	unsigned long	        sk_lingertime;
<span class="p_header">diff --git a/include/trace/events/mmflags.h b/include/trace/events/mmflags.h</span>
<span class="p_header">index fec6291a6703..937d5d54d1b9 100644</span>
<span class="p_header">--- a/include/trace/events/mmflags.h</span>
<span class="p_header">+++ b/include/trace/events/mmflags.h</span>
<span class="p_chunk">@@ -45,7 +45,6 @@</span> <span class="p_context"></span>
 	{(unsigned long)__GFP_RECLAIMABLE,	&quot;__GFP_RECLAIMABLE&quot;},	\
 	{(unsigned long)__GFP_MOVABLE,		&quot;__GFP_MOVABLE&quot;},	\
 	{(unsigned long)__GFP_ACCOUNT,		&quot;__GFP_ACCOUNT&quot;},	\
<span class="p_del">-	{(unsigned long)__GFP_NOTRACK,		&quot;__GFP_NOTRACK&quot;},	\</span>
 	{(unsigned long)__GFP_WRITE,		&quot;__GFP_WRITE&quot;},		\
 	{(unsigned long)__GFP_RECLAIM,		&quot;__GFP_RECLAIM&quot;},	\
 	{(unsigned long)__GFP_DIRECT_RECLAIM,	&quot;__GFP_DIRECT_RECLAIM&quot;},\
<span class="p_header">diff --git a/init/do_mounts.c b/init/do_mounts.c</span>
<span class="p_header">index f6d4dd764a52..7cf4f6dafd5f 100644</span>
<span class="p_header">--- a/init/do_mounts.c</span>
<span class="p_header">+++ b/init/do_mounts.c</span>
<span class="p_chunk">@@ -380,8 +380,7 @@</span> <span class="p_context"> static int __init do_mount_root(char *name, char *fs, int flags, void *data)</span>
 
 void __init mount_block_root(char *name, int flags)
 {
<span class="p_del">-	struct page *page = alloc_page(GFP_KERNEL |</span>
<span class="p_del">-					__GFP_NOTRACK_FALSE_POSITIVE);</span>
<span class="p_add">+	struct page *page = alloc_page(GFP_KERNEL);</span>
 	char *fs_names = page_address(page);
 	char *p;
 #ifdef CONFIG_BLOCK
<span class="p_header">diff --git a/init/main.c b/init/main.c</span>
<span class="p_header">index 0ee9c6866ada..0e4d39c2ec82 100644</span>
<span class="p_header">--- a/init/main.c</span>
<span class="p_header">+++ b/init/main.c</span>
<span class="p_chunk">@@ -69,7 +69,6 @@</span> <span class="p_context"></span>
 #include &lt;linux/kgdb.h&gt;
 #include &lt;linux/ftrace.h&gt;
 #include &lt;linux/async.h&gt;
<span class="p_del">-#include &lt;linux/kmemcheck.h&gt;</span>
 #include &lt;linux/sfi.h&gt;
 #include &lt;linux/shmem_fs.h&gt;
 #include &lt;linux/slab.h&gt;
<span class="p_header">diff --git a/kernel/bpf/core.c b/kernel/bpf/core.c</span>
<span class="p_header">index 917cc04a0a94..29af29befbd1 100644</span>
<span class="p_header">--- a/kernel/bpf/core.c</span>
<span class="p_header">+++ b/kernel/bpf/core.c</span>
<span class="p_chunk">@@ -85,8 +85,6 @@</span> <span class="p_context"> struct bpf_prog *bpf_prog_alloc(unsigned int size, gfp_t gfp_extra_flags)</span>
 	if (fp == NULL)
 		return NULL;
 
<span class="p_del">-	kmemcheck_annotate_bitfield(fp, meta);</span>
<span class="p_del">-</span>
 	aux = kzalloc(sizeof(*aux), GFP_KERNEL | gfp_extra_flags);
 	if (aux == NULL) {
 		vfree(fp);
<span class="p_chunk">@@ -127,8 +125,6 @@</span> <span class="p_context"> struct bpf_prog *bpf_prog_realloc(struct bpf_prog *fp_old, unsigned int size,</span>
 	if (fp == NULL) {
 		__bpf_prog_uncharge(fp_old-&gt;aux-&gt;user, delta);
 	} else {
<span class="p_del">-		kmemcheck_annotate_bitfield(fp, meta);</span>
<span class="p_del">-</span>
 		memcpy(fp, fp_old, fp_old-&gt;pages * PAGE_SIZE);
 		fp-&gt;pages = pages;
 		fp-&gt;aux-&gt;prog = fp;
<span class="p_chunk">@@ -662,8 +658,6 @@</span> <span class="p_context"> static struct bpf_prog *bpf_prog_clone_create(struct bpf_prog *fp_other,</span>
 
 	fp = __vmalloc(fp_other-&gt;pages * PAGE_SIZE, gfp_flags, PAGE_KERNEL);
 	if (fp != NULL) {
<span class="p_del">-		kmemcheck_annotate_bitfield(fp, meta);</span>
<span class="p_del">-</span>
 		/* aux-&gt;prog still points to the fp_other one, so
 		 * when promoting the clone to the real program,
 		 * this still needs to be adapted.
<span class="p_header">diff --git a/kernel/fork.c b/kernel/fork.c</span>
<span class="p_header">index 10646182440f..07fdb44af7b8 100644</span>
<span class="p_header">--- a/kernel/fork.c</span>
<span class="p_header">+++ b/kernel/fork.c</span>
<span class="p_chunk">@@ -465,7 +465,7 @@</span> <span class="p_context"> void __init fork_init(void)</span>
 	/* create a slab on which task_structs can be allocated */
 	task_struct_cachep = kmem_cache_create(&quot;task_struct&quot;,
 			arch_task_struct_size, align,
<span class="p_del">-			SLAB_PANIC|SLAB_NOTRACK|SLAB_ACCOUNT, NULL);</span>
<span class="p_add">+			SLAB_PANIC|SLAB_ACCOUNT, NULL);</span>
 #endif
 
 	/* do the arch specific task caches init */
<span class="p_chunk">@@ -2187,18 +2187,18 @@</span> <span class="p_context"> void __init proc_caches_init(void)</span>
 	sighand_cachep = kmem_cache_create(&quot;sighand_cache&quot;,
 			sizeof(struct sighand_struct), 0,
 			SLAB_HWCACHE_ALIGN|SLAB_PANIC|SLAB_TYPESAFE_BY_RCU|
<span class="p_del">-			SLAB_NOTRACK|SLAB_ACCOUNT, sighand_ctor);</span>
<span class="p_add">+			SLAB_ACCOUNT, sighand_ctor);</span>
 	signal_cachep = kmem_cache_create(&quot;signal_cache&quot;,
 			sizeof(struct signal_struct), 0,
<span class="p_del">-			SLAB_HWCACHE_ALIGN|SLAB_PANIC|SLAB_NOTRACK|SLAB_ACCOUNT,</span>
<span class="p_add">+			SLAB_HWCACHE_ALIGN|SLAB_PANIC|SLAB_ACCOUNT,</span>
 			NULL);
 	files_cachep = kmem_cache_create(&quot;files_cache&quot;,
 			sizeof(struct files_struct), 0,
<span class="p_del">-			SLAB_HWCACHE_ALIGN|SLAB_PANIC|SLAB_NOTRACK|SLAB_ACCOUNT,</span>
<span class="p_add">+			SLAB_HWCACHE_ALIGN|SLAB_PANIC|SLAB_ACCOUNT,</span>
 			NULL);
 	fs_cachep = kmem_cache_create(&quot;fs_cache&quot;,
 			sizeof(struct fs_struct), 0,
<span class="p_del">-			SLAB_HWCACHE_ALIGN|SLAB_PANIC|SLAB_NOTRACK|SLAB_ACCOUNT,</span>
<span class="p_add">+			SLAB_HWCACHE_ALIGN|SLAB_PANIC|SLAB_ACCOUNT,</span>
 			NULL);
 	/*
 	 * FIXME! The &quot;sizeof(struct mm_struct)&quot; currently includes the
<span class="p_chunk">@@ -2209,7 +2209,7 @@</span> <span class="p_context"> void __init proc_caches_init(void)</span>
 	 */
 	mm_cachep = kmem_cache_create(&quot;mm_struct&quot;,
 			sizeof(struct mm_struct), ARCH_MIN_MMSTRUCT_ALIGN,
<span class="p_del">-			SLAB_HWCACHE_ALIGN|SLAB_PANIC|SLAB_NOTRACK|SLAB_ACCOUNT,</span>
<span class="p_add">+			SLAB_HWCACHE_ALIGN|SLAB_PANIC|SLAB_ACCOUNT,</span>
 			NULL);
 	vm_area_cachep = KMEM_CACHE(vm_area_struct, SLAB_PANIC|SLAB_ACCOUNT);
 	mmap_init();
<span class="p_header">diff --git a/kernel/locking/lockdep.c b/kernel/locking/lockdep.c</span>
<span class="p_header">index 44c8d0d17170..a616140f3a2a 100644</span>
<span class="p_header">--- a/kernel/locking/lockdep.c</span>
<span class="p_header">+++ b/kernel/locking/lockdep.c</span>
<span class="p_chunk">@@ -47,7 +47,6 @@</span> <span class="p_context"></span>
 #include &lt;linux/stringify.h&gt;
 #include &lt;linux/bitops.h&gt;
 #include &lt;linux/gfp.h&gt;
<span class="p_del">-#include &lt;linux/kmemcheck.h&gt;</span>
 #include &lt;linux/random.h&gt;
 #include &lt;linux/jhash.h&gt;
 
<span class="p_chunk">@@ -3233,8 +3232,6 @@</span> <span class="p_context"> static void __lockdep_init_map(struct lockdep_map *lock, const char *name,</span>
 {
 	int i;
 
<span class="p_del">-	kmemcheck_mark_initialized(lock, sizeof(*lock));</span>
<span class="p_del">-</span>
 	for (i = 0; i &lt; NR_LOCKDEP_CACHING_CLASSES; i++)
 		lock-&gt;class_cache[i] = NULL;
 
<span class="p_header">diff --git a/kernel/signal.c b/kernel/signal.c</span>
<span class="p_header">index 800a18f77732..8da9a7ff52fc 100644</span>
<span class="p_header">--- a/kernel/signal.c</span>
<span class="p_header">+++ b/kernel/signal.c</span>
<span class="p_chunk">@@ -1036,8 +1036,7 @@</span> <span class="p_context"> static int __send_signal(int sig, struct siginfo *info, struct task_struct *t,</span>
 	else
 		override_rlimit = 0;
 
<span class="p_del">-	q = __sigqueue_alloc(sig, t, GFP_ATOMIC | __GFP_NOTRACK_FALSE_POSITIVE,</span>
<span class="p_del">-		override_rlimit);</span>
<span class="p_add">+	q = __sigqueue_alloc(sig, t, GFP_ATOMIC, override_rlimit);</span>
 	if (q) {
 		list_add_tail(&amp;q-&gt;list, &amp;pending-&gt;list);
 		switch ((unsigned long) info) {
<span class="p_header">diff --git a/kernel/softirq.c b/kernel/softirq.c</span>
<span class="p_header">index 4e09821f9d9e..e89c3b0cff6d 100644</span>
<span class="p_header">--- a/kernel/softirq.c</span>
<span class="p_header">+++ b/kernel/softirq.c</span>
<span class="p_chunk">@@ -486,16 +486,6 @@</span> <span class="p_context"> void __tasklet_hi_schedule(struct tasklet_struct *t)</span>
 }
 EXPORT_SYMBOL(__tasklet_hi_schedule);
 
<span class="p_del">-void __tasklet_hi_schedule_first(struct tasklet_struct *t)</span>
<span class="p_del">-{</span>
<span class="p_del">-	BUG_ON(!irqs_disabled());</span>
<span class="p_del">-</span>
<span class="p_del">-	t-&gt;next = __this_cpu_read(tasklet_hi_vec.head);</span>
<span class="p_del">-	__this_cpu_write(tasklet_hi_vec.head, t);</span>
<span class="p_del">-	__raise_softirq_irqoff(HI_SOFTIRQ);</span>
<span class="p_del">-}</span>
<span class="p_del">-EXPORT_SYMBOL(__tasklet_hi_schedule_first);</span>
<span class="p_del">-</span>
 static __latent_entropy void tasklet_action(struct softirq_action *a)
 {
 	struct tasklet_struct *list;
<span class="p_header">diff --git a/kernel/sysctl.c b/kernel/sysctl.c</span>
<span class="p_header">index 6648fbbb8157..9a9691a76d61 100644</span>
<span class="p_header">--- a/kernel/sysctl.c</span>
<span class="p_header">+++ b/kernel/sysctl.c</span>
<span class="p_chunk">@@ -30,7 +30,6 @@</span> <span class="p_context"></span>
 #include &lt;linux/proc_fs.h&gt;
 #include &lt;linux/security.h&gt;
 #include &lt;linux/ctype.h&gt;
<span class="p_del">-#include &lt;linux/kmemcheck.h&gt;</span>
 #include &lt;linux/kmemleak.h&gt;
 #include &lt;linux/fs.h&gt;
 #include &lt;linux/init.h&gt;
<span class="p_chunk">@@ -1177,15 +1176,6 @@</span> <span class="p_context"> static struct ctl_table kern_table[] = {</span>
 		.extra2		= &amp;one_thousand,
 	},
 #endif
<span class="p_del">-#ifdef CONFIG_KMEMCHECK</span>
<span class="p_del">-	{</span>
<span class="p_del">-		.procname	= &quot;kmemcheck&quot;,</span>
<span class="p_del">-		.data		= &amp;kmemcheck_enabled,</span>
<span class="p_del">-		.maxlen		= sizeof(int),</span>
<span class="p_del">-		.mode		= 0644,</span>
<span class="p_del">-		.proc_handler	= proc_dointvec,</span>
<span class="p_del">-	},</span>
<span class="p_del">-#endif</span>
 	{
 		.procname	= &quot;panic_on_warn&quot;,
 		.data		= &amp;panic_on_warn,
<span class="p_header">diff --git a/kernel/trace/ring_buffer.c b/kernel/trace/ring_buffer.c</span>
<span class="p_header">index 81279c6602ff..7e97e75afc6a 100644</span>
<span class="p_header">--- a/kernel/trace/ring_buffer.c</span>
<span class="p_header">+++ b/kernel/trace/ring_buffer.c</span>
<span class="p_chunk">@@ -13,7 +13,6 @@</span> <span class="p_context"></span>
 #include &lt;linux/uaccess.h&gt;
 #include &lt;linux/hardirq.h&gt;
 #include &lt;linux/kthread.h&gt;	/* for self test */
<span class="p_del">-#include &lt;linux/kmemcheck.h&gt;</span>
 #include &lt;linux/module.h&gt;
 #include &lt;linux/percpu.h&gt;
 #include &lt;linux/mutex.h&gt;
<span class="p_chunk">@@ -2055,7 +2054,6 @@</span> <span class="p_context"> rb_reset_tail(struct ring_buffer_per_cpu *cpu_buffer,</span>
 	}
 
 	event = __rb_page_index(tail_page, tail);
<span class="p_del">-	kmemcheck_annotate_bitfield(event, bitfield);</span>
 
 	/* account for padding bytes */
 	local_add(BUF_PAGE_SIZE - tail, &amp;cpu_buffer-&gt;entries_bytes);
<span class="p_chunk">@@ -2686,7 +2684,6 @@</span> <span class="p_context"> __rb_reserve_next(struct ring_buffer_per_cpu *cpu_buffer,</span>
 	/* We reserved something on the buffer */
 
 	event = __rb_page_index(tail_page, tail);
<span class="p_del">-	kmemcheck_annotate_bitfield(event, bitfield);</span>
 	rb_update_event(cpu_buffer, event, info);
 
 	local_inc(&amp;tail_page-&gt;entries);
<span class="p_header">diff --git a/lib/Kconfig.debug b/lib/Kconfig.debug</span>
<span class="p_header">index 2689b7c50c52..d4051fcafa4e 100644</span>
<span class="p_header">--- a/lib/Kconfig.debug</span>
<span class="p_header">+++ b/lib/Kconfig.debug</span>
<span class="p_chunk">@@ -504,7 +504,7 @@</span> <span class="p_context"> config DEBUG_OBJECTS_ENABLE_DEFAULT</span>
 
 config DEBUG_SLAB
 	bool &quot;Debug slab memory allocations&quot;
<span class="p_del">-	depends on DEBUG_KERNEL &amp;&amp; SLAB &amp;&amp; !KMEMCHECK</span>
<span class="p_add">+	depends on DEBUG_KERNEL &amp;&amp; SLAB</span>
 	help
 	  Say Y here to have the kernel do limited verification on memory
 	  allocation as well as poisoning memory on free to catch use of freed
<span class="p_chunk">@@ -516,7 +516,7 @@</span> <span class="p_context"> config DEBUG_SLAB_LEAK</span>
 
 config SLUB_DEBUG_ON
 	bool &quot;SLUB debugging on by default&quot;
<span class="p_del">-	depends on SLUB &amp;&amp; SLUB_DEBUG &amp;&amp; !KMEMCHECK</span>
<span class="p_add">+	depends on SLUB &amp;&amp; SLUB_DEBUG</span>
 	default n
 	help
 	  Boot with debugging on by default. SLUB boots by default with
<span class="p_chunk">@@ -730,8 +730,6 @@</span> <span class="p_context"> config DEBUG_STACKOVERFLOW</span>
 
 	  If in doubt, say &quot;N&quot;.
 
<span class="p_del">-source &quot;lib/Kconfig.kmemcheck&quot;</span>
<span class="p_del">-</span>
 source &quot;lib/Kconfig.kasan&quot;
 
 endmenu # &quot;Memory Debugging&quot;
<span class="p_header">diff --git a/lib/Kconfig.kmemcheck b/lib/Kconfig.kmemcheck</span>
deleted file mode 100644
<span class="p_header">index 846e039a86b4..000000000000</span>
<span class="p_header">--- a/lib/Kconfig.kmemcheck</span>
<span class="p_header">+++ /dev/null</span>
<span class="p_chunk">@@ -1,94 +0,0 @@</span> <span class="p_context"></span>
<span class="p_del">-config HAVE_ARCH_KMEMCHECK</span>
<span class="p_del">-	bool</span>
<span class="p_del">-</span>
<span class="p_del">-if HAVE_ARCH_KMEMCHECK</span>
<span class="p_del">-</span>
<span class="p_del">-menuconfig KMEMCHECK</span>
<span class="p_del">-	bool &quot;kmemcheck: trap use of uninitialized memory&quot;</span>
<span class="p_del">-	depends on DEBUG_KERNEL</span>
<span class="p_del">-	depends on !X86_USE_3DNOW</span>
<span class="p_del">-	depends on SLUB || SLAB</span>
<span class="p_del">-	depends on !CC_OPTIMIZE_FOR_SIZE</span>
<span class="p_del">-	depends on !FUNCTION_TRACER</span>
<span class="p_del">-	select FRAME_POINTER</span>
<span class="p_del">-	select STACKTRACE</span>
<span class="p_del">-	default n</span>
<span class="p_del">-	help</span>
<span class="p_del">-	  This option enables tracing of dynamically allocated kernel memory</span>
<span class="p_del">-	  to see if memory is used before it has been given an initial value.</span>
<span class="p_del">-	  Be aware that this requires half of your memory for bookkeeping and</span>
<span class="p_del">-	  will insert extra code at *every* read and write to tracked memory</span>
<span class="p_del">-	  thus slow down the kernel code (but user code is unaffected).</span>
<span class="p_del">-</span>
<span class="p_del">-	  The kernel may be started with kmemcheck=0 or kmemcheck=1 to disable</span>
<span class="p_del">-	  or enable kmemcheck at boot-time. If the kernel is started with</span>
<span class="p_del">-	  kmemcheck=0, the large memory and CPU overhead is not incurred.</span>
<span class="p_del">-</span>
<span class="p_del">-choice</span>
<span class="p_del">-	prompt &quot;kmemcheck: default mode at boot&quot;</span>
<span class="p_del">-	depends on KMEMCHECK</span>
<span class="p_del">-	default KMEMCHECK_ONESHOT_BY_DEFAULT</span>
<span class="p_del">-	help</span>
<span class="p_del">-	  This option controls the default behaviour of kmemcheck when the</span>
<span class="p_del">-	  kernel boots and no kmemcheck= parameter is given.</span>
<span class="p_del">-</span>
<span class="p_del">-config KMEMCHECK_DISABLED_BY_DEFAULT</span>
<span class="p_del">-	bool &quot;disabled&quot;</span>
<span class="p_del">-	depends on KMEMCHECK</span>
<span class="p_del">-</span>
<span class="p_del">-config KMEMCHECK_ENABLED_BY_DEFAULT</span>
<span class="p_del">-	bool &quot;enabled&quot;</span>
<span class="p_del">-	depends on KMEMCHECK</span>
<span class="p_del">-</span>
<span class="p_del">-config KMEMCHECK_ONESHOT_BY_DEFAULT</span>
<span class="p_del">-	bool &quot;one-shot&quot;</span>
<span class="p_del">-	depends on KMEMCHECK</span>
<span class="p_del">-	help</span>
<span class="p_del">-	  In one-shot mode, only the first error detected is reported before</span>
<span class="p_del">-	  kmemcheck is disabled.</span>
<span class="p_del">-</span>
<span class="p_del">-endchoice</span>
<span class="p_del">-</span>
<span class="p_del">-config KMEMCHECK_QUEUE_SIZE</span>
<span class="p_del">-	int &quot;kmemcheck: error queue size&quot;</span>
<span class="p_del">-	depends on KMEMCHECK</span>
<span class="p_del">-	default 64</span>
<span class="p_del">-	help</span>
<span class="p_del">-	  Select the maximum number of errors to store in the queue. Since</span>
<span class="p_del">-	  errors can occur virtually anywhere and in any context, we need a</span>
<span class="p_del">-	  temporary storage area which is guarantueed not to generate any</span>
<span class="p_del">-	  other faults. The queue will be emptied as soon as a tasklet may</span>
<span class="p_del">-	  be scheduled. If the queue is full, new error reports will be</span>
<span class="p_del">-	  lost.</span>
<span class="p_del">-</span>
<span class="p_del">-config KMEMCHECK_SHADOW_COPY_SHIFT</span>
<span class="p_del">-	int &quot;kmemcheck: shadow copy size (5 =&gt; 32 bytes, 6 =&gt; 64 bytes)&quot;</span>
<span class="p_del">-	depends on KMEMCHECK</span>
<span class="p_del">-	range 2 8</span>
<span class="p_del">-	default 5</span>
<span class="p_del">-	help</span>
<span class="p_del">-	  Select the number of shadow bytes to save along with each entry of</span>
<span class="p_del">-	  the queue. These bytes indicate what parts of an allocation are</span>
<span class="p_del">-	  initialized, uninitialized, etc. and will be displayed when an</span>
<span class="p_del">-	  error is detected to help the debugging of a particular problem.</span>
<span class="p_del">-</span>
<span class="p_del">-config KMEMCHECK_PARTIAL_OK</span>
<span class="p_del">-	bool &quot;kmemcheck: allow partially uninitialized memory&quot;</span>
<span class="p_del">-	depends on KMEMCHECK</span>
<span class="p_del">-	default y</span>
<span class="p_del">-	help</span>
<span class="p_del">-	  This option works around certain GCC optimizations that produce</span>
<span class="p_del">-	  32-bit reads from 16-bit variables where the upper 16 bits are</span>
<span class="p_del">-	  thrown away afterwards. This may of course also hide some real</span>
<span class="p_del">-	  bugs.</span>
<span class="p_del">-</span>
<span class="p_del">-config KMEMCHECK_BITOPS_OK</span>
<span class="p_del">-	bool &quot;kmemcheck: allow bit-field manipulation&quot;</span>
<span class="p_del">-	depends on KMEMCHECK</span>
<span class="p_del">-	default n</span>
<span class="p_del">-	help</span>
<span class="p_del">-	  This option silences warnings that would be generated for bit-field</span>
<span class="p_del">-	  accesses where not all the bits are initialized at the same time.</span>
<span class="p_del">-	  This may also hide some real bugs.</span>
<span class="p_del">-</span>
<span class="p_del">-endif</span>
<span class="p_header">diff --git a/mm/Kconfig.debug b/mm/Kconfig.debug</span>
<span class="p_header">index 5b0adf1435de..e5e606ee5f71 100644</span>
<span class="p_header">--- a/mm/Kconfig.debug</span>
<span class="p_header">+++ b/mm/Kconfig.debug</span>
<span class="p_chunk">@@ -11,7 +11,6 @@</span> <span class="p_context"> config DEBUG_PAGEALLOC</span>
 	bool &quot;Debug page memory allocations&quot;
 	depends on DEBUG_KERNEL
 	depends on !HIBERNATION || ARCH_SUPPORTS_DEBUG_PAGEALLOC &amp;&amp; !PPC &amp;&amp; !SPARC
<span class="p_del">-	depends on !KMEMCHECK</span>
 	select PAGE_EXTENSION
 	select PAGE_POISONING if !ARCH_SUPPORTS_DEBUG_PAGEALLOC
 	---help---
<span class="p_header">diff --git a/mm/Makefile b/mm/Makefile</span>
<span class="p_header">index e3ac3aeb533b..cdec8105457c 100644</span>
<span class="p_header">--- a/mm/Makefile</span>
<span class="p_header">+++ b/mm/Makefile</span>
<span class="p_chunk">@@ -16,7 +16,6 @@</span> <span class="p_context"> KCOV_INSTRUMENT_slub.o := n</span>
 KCOV_INSTRUMENT_page_alloc.o := n
 KCOV_INSTRUMENT_debug-pagealloc.o := n
 KCOV_INSTRUMENT_kmemleak.o := n
<span class="p_del">-KCOV_INSTRUMENT_kmemcheck.o := n</span>
 KCOV_INSTRUMENT_memcontrol.o := n
 KCOV_INSTRUMENT_mmzone.o := n
 KCOV_INSTRUMENT_vmstat.o := n
<span class="p_chunk">@@ -69,7 +68,6 @@</span> <span class="p_context"> obj-$(CONFIG_KSM) += ksm.o</span>
 obj-$(CONFIG_PAGE_POISONING) += page_poison.o
 obj-$(CONFIG_SLAB) += slab.o
 obj-$(CONFIG_SLUB) += slub.o
<span class="p_del">-obj-$(CONFIG_KMEMCHECK) += kmemcheck.o</span>
 obj-$(CONFIG_KASAN)	+= kasan/
 obj-$(CONFIG_FAILSLAB) += failslab.o
 obj-$(CONFIG_MEMORY_HOTPLUG) += memory_hotplug.o
<span class="p_header">diff --git a/mm/kmemcheck.c b/mm/kmemcheck.c</span>
deleted file mode 100644
<span class="p_header">index 2d5959c5f7c5..000000000000</span>
<span class="p_header">--- a/mm/kmemcheck.c</span>
<span class="p_header">+++ /dev/null</span>
<span class="p_chunk">@@ -1,125 +0,0 @@</span> <span class="p_context"></span>
<span class="p_del">-#include &lt;linux/gfp.h&gt;</span>
<span class="p_del">-#include &lt;linux/mm_types.h&gt;</span>
<span class="p_del">-#include &lt;linux/mm.h&gt;</span>
<span class="p_del">-#include &lt;linux/slab.h&gt;</span>
<span class="p_del">-#include &quot;slab.h&quot;</span>
<span class="p_del">-#include &lt;linux/kmemcheck.h&gt;</span>
<span class="p_del">-</span>
<span class="p_del">-void kmemcheck_alloc_shadow(struct page *page, int order, gfp_t flags, int node)</span>
<span class="p_del">-{</span>
<span class="p_del">-	struct page *shadow;</span>
<span class="p_del">-	int pages;</span>
<span class="p_del">-	int i;</span>
<span class="p_del">-</span>
<span class="p_del">-	pages = 1 &lt;&lt; order;</span>
<span class="p_del">-</span>
<span class="p_del">-	/*</span>
<span class="p_del">-	 * With kmemcheck enabled, we need to allocate a memory area for the</span>
<span class="p_del">-	 * shadow bits as well.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	shadow = alloc_pages_node(node, flags | __GFP_NOTRACK, order);</span>
<span class="p_del">-	if (!shadow) {</span>
<span class="p_del">-		if (printk_ratelimit())</span>
<span class="p_del">-			pr_err(&quot;kmemcheck: failed to allocate shadow bitmap\n&quot;);</span>
<span class="p_del">-		return;</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">-	for(i = 0; i &lt; pages; ++i)</span>
<span class="p_del">-		page[i].shadow = page_address(&amp;shadow[i]);</span>
<span class="p_del">-</span>
<span class="p_del">-	/*</span>
<span class="p_del">-	 * Mark it as non-present for the MMU so that our accesses to</span>
<span class="p_del">-	 * this memory will trigger a page fault and let us analyze</span>
<span class="p_del">-	 * the memory accesses.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	kmemcheck_hide_pages(page, pages);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-void kmemcheck_free_shadow(struct page *page, int order)</span>
<span class="p_del">-{</span>
<span class="p_del">-	struct page *shadow;</span>
<span class="p_del">-	int pages;</span>
<span class="p_del">-	int i;</span>
<span class="p_del">-</span>
<span class="p_del">-	if (!kmemcheck_page_is_tracked(page))</span>
<span class="p_del">-		return;</span>
<span class="p_del">-</span>
<span class="p_del">-	pages = 1 &lt;&lt; order;</span>
<span class="p_del">-</span>
<span class="p_del">-	kmemcheck_show_pages(page, pages);</span>
<span class="p_del">-</span>
<span class="p_del">-	shadow = virt_to_page(page[0].shadow);</span>
<span class="p_del">-</span>
<span class="p_del">-	for(i = 0; i &lt; pages; ++i)</span>
<span class="p_del">-		page[i].shadow = NULL;</span>
<span class="p_del">-</span>
<span class="p_del">-	__free_pages(shadow, order);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-void kmemcheck_slab_alloc(struct kmem_cache *s, gfp_t gfpflags, void *object,</span>
<span class="p_del">-			  size_t size)</span>
<span class="p_del">-{</span>
<span class="p_del">-	if (unlikely(!object)) /* Skip object if allocation failed */</span>
<span class="p_del">-		return;</span>
<span class="p_del">-</span>
<span class="p_del">-	/*</span>
<span class="p_del">-	 * Has already been memset(), which initializes the shadow for us</span>
<span class="p_del">-	 * as well.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	if (gfpflags &amp; __GFP_ZERO)</span>
<span class="p_del">-		return;</span>
<span class="p_del">-</span>
<span class="p_del">-	/* No need to initialize the shadow of a non-tracked slab. */</span>
<span class="p_del">-	if (s-&gt;flags &amp; SLAB_NOTRACK)</span>
<span class="p_del">-		return;</span>
<span class="p_del">-</span>
<span class="p_del">-	if (!kmemcheck_enabled || gfpflags &amp; __GFP_NOTRACK) {</span>
<span class="p_del">-		/*</span>
<span class="p_del">-		 * Allow notracked objects to be allocated from</span>
<span class="p_del">-		 * tracked caches. Note however that these objects</span>
<span class="p_del">-		 * will still get page faults on access, they just</span>
<span class="p_del">-		 * won&#39;t ever be flagged as uninitialized. If page</span>
<span class="p_del">-		 * faults are not acceptable, the slab cache itself</span>
<span class="p_del">-		 * should be marked NOTRACK.</span>
<span class="p_del">-		 */</span>
<span class="p_del">-		kmemcheck_mark_initialized(object, size);</span>
<span class="p_del">-	} else if (!s-&gt;ctor) {</span>
<span class="p_del">-		/*</span>
<span class="p_del">-		 * New objects should be marked uninitialized before</span>
<span class="p_del">-		 * they&#39;re returned to the called.</span>
<span class="p_del">-		 */</span>
<span class="p_del">-		kmemcheck_mark_uninitialized(object, size);</span>
<span class="p_del">-	}</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-void kmemcheck_slab_free(struct kmem_cache *s, void *object, size_t size)</span>
<span class="p_del">-{</span>
<span class="p_del">-	/* TODO: RCU freeing is unsupported for now; hide false positives. */</span>
<span class="p_del">-	if (!s-&gt;ctor &amp;&amp; !(s-&gt;flags &amp; SLAB_TYPESAFE_BY_RCU))</span>
<span class="p_del">-		kmemcheck_mark_freed(object, size);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-void kmemcheck_pagealloc_alloc(struct page *page, unsigned int order,</span>
<span class="p_del">-			       gfp_t gfpflags)</span>
<span class="p_del">-{</span>
<span class="p_del">-	int pages;</span>
<span class="p_del">-</span>
<span class="p_del">-	if (gfpflags &amp; (__GFP_HIGHMEM | __GFP_NOTRACK))</span>
<span class="p_del">-		return;</span>
<span class="p_del">-</span>
<span class="p_del">-	pages = 1 &lt;&lt; order;</span>
<span class="p_del">-</span>
<span class="p_del">-	/*</span>
<span class="p_del">-	 * NOTE: We choose to track GFP_ZERO pages too; in fact, they</span>
<span class="p_del">-	 * can become uninitialized by copying uninitialized memory</span>
<span class="p_del">-	 * into them.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-</span>
<span class="p_del">-	/* XXX: Can use zone-&gt;node for node? */</span>
<span class="p_del">-	kmemcheck_alloc_shadow(page, order, gfpflags, -1);</span>
<span class="p_del">-</span>
<span class="p_del">-	if (gfpflags &amp; __GFP_ZERO)</span>
<span class="p_del">-		kmemcheck_mark_initialized_pages(page, pages);</span>
<span class="p_del">-	else</span>
<span class="p_del">-		kmemcheck_mark_uninitialized_pages(page, pages);</span>
<span class="p_del">-}</span>
<span class="p_header">diff --git a/mm/kmemleak.c b/mm/kmemleak.c</span>
<span class="p_header">index 7780cd83a495..a74d878f06c3 100644</span>
<span class="p_header">--- a/mm/kmemleak.c</span>
<span class="p_header">+++ b/mm/kmemleak.c</span>
<span class="p_chunk">@@ -110,7 +110,6 @@</span> <span class="p_context"></span>
 #include &lt;linux/atomic.h&gt;
 
 #include &lt;linux/kasan.h&gt;
<span class="p_del">-#include &lt;linux/kmemcheck.h&gt;</span>
 #include &lt;linux/kmemleak.h&gt;
 #include &lt;linux/memory_hotplug.h&gt;
 
<span class="p_chunk">@@ -1238,9 +1237,6 @@</span> <span class="p_context"> static bool update_checksum(struct kmemleak_object *object)</span>
 {
 	u32 old_csum = object-&gt;checksum;
 
<span class="p_del">-	if (!kmemcheck_is_obj_initialized(object-&gt;pointer, object-&gt;size))</span>
<span class="p_del">-		return false;</span>
<span class="p_del">-</span>
 	kasan_disable_current();
 	object-&gt;checksum = crc32(0, (void *)object-&gt;pointer, object-&gt;size);
 	kasan_enable_current();
<span class="p_chunk">@@ -1314,11 +1310,6 @@</span> <span class="p_context"> static void scan_block(void *_start, void *_end,</span>
 		if (scan_should_stop())
 			break;
 
<span class="p_del">-		/* don&#39;t scan uninitialized memory */</span>
<span class="p_del">-		if (!kmemcheck_is_obj_initialized((unsigned long)ptr,</span>
<span class="p_del">-						  BYTES_PER_POINTER))</span>
<span class="p_del">-			continue;</span>
<span class="p_del">-</span>
 		kasan_disable_current();
 		pointer = *ptr;
 		kasan_enable_current();
<span class="p_header">diff --git a/mm/page_alloc.c b/mm/page_alloc.c</span>
<span class="p_header">index c841af88836a..606c398d409f 100644</span>
<span class="p_header">--- a/mm/page_alloc.c</span>
<span class="p_header">+++ b/mm/page_alloc.c</span>
<span class="p_chunk">@@ -24,7 +24,6 @@</span> <span class="p_context"></span>
 #include &lt;linux/memblock.h&gt;
 #include &lt;linux/compiler.h&gt;
 #include &lt;linux/kernel.h&gt;
<span class="p_del">-#include &lt;linux/kmemcheck.h&gt;</span>
 #include &lt;linux/kasan.h&gt;
 #include &lt;linux/module.h&gt;
 #include &lt;linux/suspend.h&gt;
<span class="p_chunk">@@ -1013,7 +1012,6 @@</span> <span class="p_context"> static __always_inline bool free_pages_prepare(struct page *page,</span>
 	VM_BUG_ON_PAGE(PageTail(page), page);
 
 	trace_mm_page_free(page, order);
<span class="p_del">-	kmemcheck_free_shadow(page, order);</span>
 
 	/*
 	 * Check tail pages before head page information is cleared to
<span class="p_chunk">@@ -2669,15 +2667,6 @@</span> <span class="p_context"> void split_page(struct page *page, unsigned int order)</span>
 	VM_BUG_ON_PAGE(PageCompound(page), page);
 	VM_BUG_ON_PAGE(!page_count(page), page);
 
<span class="p_del">-#ifdef CONFIG_KMEMCHECK</span>
<span class="p_del">-	/*</span>
<span class="p_del">-	 * Split shadow pages too, because free(page[0]) would</span>
<span class="p_del">-	 * otherwise free the whole shadow.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	if (kmemcheck_page_is_tracked(page))</span>
<span class="p_del">-		split_page(virt_to_page(page[0].shadow), order);</span>
<span class="p_del">-#endif</span>
<span class="p_del">-</span>
 	for (i = 1; i &lt; (1 &lt;&lt; order); i++)
 		set_page_refcounted(page + i);
 	split_page_owner(page, order);
<span class="p_chunk">@@ -4223,9 +4212,6 @@</span> <span class="p_context"> __alloc_pages_nodemask(gfp_t gfp_mask, unsigned int order, int preferred_nid,</span>
 		page = NULL;
 	}
 
<span class="p_del">-	if (kmemcheck_enabled &amp;&amp; page)</span>
<span class="p_del">-		kmemcheck_pagealloc_alloc(page, order, gfp_mask);</span>
<span class="p_del">-</span>
 	trace_mm_page_alloc(page, order, alloc_mask, ac.migratetype);
 
 	return page;
<span class="p_header">diff --git a/mm/slab.c b/mm/slab.c</span>
<span class="p_header">index 04dec48c3ed7..5f91bd387e2e 100644</span>
<span class="p_header">--- a/mm/slab.c</span>
<span class="p_header">+++ b/mm/slab.c</span>
<span class="p_chunk">@@ -113,7 +113,6 @@</span> <span class="p_context"></span>
 #include	&lt;linux/rtmutex.h&gt;
 #include	&lt;linux/reciprocal_div.h&gt;
 #include	&lt;linux/debugobjects.h&gt;
<span class="p_del">-#include	&lt;linux/kmemcheck.h&gt;</span>
 #include	&lt;linux/memory.h&gt;
 #include	&lt;linux/prefetch.h&gt;
 #include	&lt;linux/sched/task_stack.h&gt;
<span class="p_chunk">@@ -1412,7 +1411,7 @@</span> <span class="p_context"> static struct page *kmem_getpages(struct kmem_cache *cachep, gfp_t flags,</span>
 	if (cachep-&gt;flags &amp; SLAB_RECLAIM_ACCOUNT)
 		flags |= __GFP_RECLAIMABLE;
 
<span class="p_del">-	page = __alloc_pages_node(nodeid, flags | __GFP_NOTRACK, cachep-&gt;gfporder);</span>
<span class="p_add">+	page = __alloc_pages_node(nodeid, flags, cachep-&gt;gfporder);</span>
 	if (!page) {
 		slab_out_of_memory(cachep, flags, nodeid);
 		return NULL;
<span class="p_chunk">@@ -1434,15 +1433,6 @@</span> <span class="p_context"> static struct page *kmem_getpages(struct kmem_cache *cachep, gfp_t flags,</span>
 	if (sk_memalloc_socks() &amp;&amp; page_is_pfmemalloc(page))
 		SetPageSlabPfmemalloc(page);
 
<span class="p_del">-	if (kmemcheck_enabled &amp;&amp; !(cachep-&gt;flags &amp; SLAB_NOTRACK)) {</span>
<span class="p_del">-		kmemcheck_alloc_shadow(page, cachep-&gt;gfporder, flags, nodeid);</span>
<span class="p_del">-</span>
<span class="p_del">-		if (cachep-&gt;ctor)</span>
<span class="p_del">-			kmemcheck_mark_uninitialized_pages(page, nr_pages);</span>
<span class="p_del">-		else</span>
<span class="p_del">-			kmemcheck_mark_unallocated_pages(page, nr_pages);</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
 	return page;
 }
 
<span class="p_chunk">@@ -1454,8 +1444,6 @@</span> <span class="p_context"> static void kmem_freepages(struct kmem_cache *cachep, struct page *page)</span>
 	int order = cachep-&gt;gfporder;
 	unsigned long nr_freed = (1 &lt;&lt; order);
 
<span class="p_del">-	kmemcheck_free_shadow(page, order);</span>
<span class="p_del">-</span>
 	if (cachep-&gt;flags &amp; SLAB_RECLAIM_ACCOUNT)
 		mod_lruvec_page_state(page, NR_SLAB_RECLAIMABLE, -nr_freed);
 	else
<span class="p_chunk">@@ -3515,8 +3503,6 @@</span> <span class="p_context"> void ___cache_free(struct kmem_cache *cachep, void *objp,</span>
 	kmemleak_free_recursive(objp, cachep-&gt;flags);
 	objp = cache_free_debugcheck(cachep, objp, caller);
 
<span class="p_del">-	kmemcheck_slab_free(cachep, objp, cachep-&gt;object_size);</span>
<span class="p_del">-</span>
 	/*
 	 * Skip calling cache_free_alien() when the platform is not numa.
 	 * This will avoid cache misses that happen while accessing slabp (which
<span class="p_header">diff --git a/mm/slab.h b/mm/slab.h</span>
<span class="p_header">index 073362816acc..8ff05e5b592a 100644</span>
<span class="p_header">--- a/mm/slab.h</span>
<span class="p_header">+++ b/mm/slab.h</span>
<span class="p_chunk">@@ -39,7 +39,6 @@</span> <span class="p_context"> struct kmem_cache {</span>
 
 #include &lt;linux/memcontrol.h&gt;
 #include &lt;linux/fault-inject.h&gt;
<span class="p_del">-#include &lt;linux/kmemcheck.h&gt;</span>
 #include &lt;linux/kasan.h&gt;
 #include &lt;linux/kmemleak.h&gt;
 #include &lt;linux/random.h&gt;
<span class="p_chunk">@@ -141,10 +140,10 @@</span> <span class="p_context"> static inline unsigned long kmem_cache_flags(unsigned long object_size,</span>
 #if defined(CONFIG_SLAB)
 #define SLAB_CACHE_FLAGS (SLAB_MEM_SPREAD | SLAB_NOLEAKTRACE | \
 			  SLAB_RECLAIM_ACCOUNT | SLAB_TEMPORARY | \
<span class="p_del">-			  SLAB_NOTRACK | SLAB_ACCOUNT)</span>
<span class="p_add">+			  SLAB_ACCOUNT)</span>
 #elif defined(CONFIG_SLUB)
 #define SLAB_CACHE_FLAGS (SLAB_NOLEAKTRACE | SLAB_RECLAIM_ACCOUNT | \
<span class="p_del">-			  SLAB_TEMPORARY | SLAB_NOTRACK | SLAB_ACCOUNT)</span>
<span class="p_add">+			  SLAB_TEMPORARY | SLAB_ACCOUNT)</span>
 #else
 #define SLAB_CACHE_FLAGS (0)
 #endif
<span class="p_chunk">@@ -163,7 +162,6 @@</span> <span class="p_context"> static inline unsigned long kmem_cache_flags(unsigned long object_size,</span>
 			      SLAB_NOLEAKTRACE | \
 			      SLAB_RECLAIM_ACCOUNT | \
 			      SLAB_TEMPORARY | \
<span class="p_del">-			      SLAB_NOTRACK | \</span>
 			      SLAB_ACCOUNT)
 
 int __kmem_cache_shutdown(struct kmem_cache *);
<span class="p_chunk">@@ -438,7 +436,6 @@</span> <span class="p_context"> static inline void slab_post_alloc_hook(struct kmem_cache *s, gfp_t flags,</span>
 	for (i = 0; i &lt; size; i++) {
 		void *object = p[i];
 
<span class="p_del">-		kmemcheck_slab_alloc(s, flags, object, slab_ksize(s));</span>
 		kmemleak_alloc_recursive(object, s-&gt;object_size, 1,
 					 s-&gt;flags, flags);
 		kasan_slab_alloc(s, object, flags);
<span class="p_header">diff --git a/mm/slab_common.c b/mm/slab_common.c</span>
<span class="p_header">index 904a83be82de..a79c202eedca 100644</span>
<span class="p_header">--- a/mm/slab_common.c</span>
<span class="p_header">+++ b/mm/slab_common.c</span>
<span class="p_chunk">@@ -43,7 +43,7 @@</span> <span class="p_context"> static DECLARE_WORK(slab_caches_to_rcu_destroy_work,</span>
 		SLAB_FAILSLAB | SLAB_KASAN)
 
 #define SLAB_MERGE_SAME (SLAB_RECLAIM_ACCOUNT | SLAB_CACHE_DMA | \
<span class="p_del">-			 SLAB_NOTRACK | SLAB_ACCOUNT)</span>
<span class="p_add">+			 SLAB_ACCOUNT)</span>
 
 /*
  * Merge control. If this is set then no merging of slab caches will occur.
<span class="p_header">diff --git a/mm/slub.c b/mm/slub.c</span>
<span class="p_header">index 163352c537ab..acaffdb0050e 100644</span>
<span class="p_header">--- a/mm/slub.c</span>
<span class="p_header">+++ b/mm/slub.c</span>
<span class="p_chunk">@@ -21,7 +21,6 @@</span> <span class="p_context"></span>
 #include &lt;linux/notifier.h&gt;
 #include &lt;linux/seq_file.h&gt;
 #include &lt;linux/kasan.h&gt;
<span class="p_del">-#include &lt;linux/kmemcheck.h&gt;</span>
 #include &lt;linux/cpu.h&gt;
 #include &lt;linux/cpuset.h&gt;
 #include &lt;linux/mempolicy.h&gt;
<span class="p_chunk">@@ -1369,12 +1368,11 @@</span> <span class="p_context"> static inline void *slab_free_hook(struct kmem_cache *s, void *x)</span>
 	 * So in order to make the debug calls that expect irqs to be
 	 * disabled we need to disable interrupts temporarily.
 	 */
<span class="p_del">-#if defined(CONFIG_KMEMCHECK) || defined(CONFIG_LOCKDEP)</span>
<span class="p_add">+#if defined(CONFIG_LOCKDEP)</span>
 	{
 		unsigned long flags;
 
 		local_irq_save(flags);
<span class="p_del">-		kmemcheck_slab_free(s, x, s-&gt;object_size);</span>
 		debug_check_no_locks_freed(x, s-&gt;object_size);
 		local_irq_restore(flags);
 	}
<span class="p_chunk">@@ -1398,8 +1396,7 @@</span> <span class="p_context"> static inline void slab_free_freelist_hook(struct kmem_cache *s,</span>
  * Compiler cannot detect this function can be removed if slab_free_hook()
  * evaluates to nothing.  Thus, catch all relevant config debug options here.
  */
<span class="p_del">-#if defined(CONFIG_KMEMCHECK) ||		\</span>
<span class="p_del">-	defined(CONFIG_LOCKDEP)	||		\</span>
<span class="p_add">+#if defined(CONFIG_LOCKDEP)	||		\</span>
 	defined(CONFIG_DEBUG_KMEMLEAK) ||	\
 	defined(CONFIG_DEBUG_OBJECTS_FREE) ||	\
 	defined(CONFIG_KASAN)
<span class="p_chunk">@@ -1435,8 +1432,6 @@</span> <span class="p_context"> static inline struct page *alloc_slab_page(struct kmem_cache *s,</span>
 	struct page *page;
 	int order = oo_order(oo);
 
<span class="p_del">-	flags |= __GFP_NOTRACK;</span>
<span class="p_del">-</span>
 	if (node == NUMA_NO_NODE)
 		page = alloc_pages(flags, order);
 	else
<span class="p_chunk">@@ -1595,22 +1590,6 @@</span> <span class="p_context"> static struct page *allocate_slab(struct kmem_cache *s, gfp_t flags, int node)</span>
 		stat(s, ORDER_FALLBACK);
 	}
 
<span class="p_del">-	if (kmemcheck_enabled &amp;&amp;</span>
<span class="p_del">-	    !(s-&gt;flags &amp; (SLAB_NOTRACK | DEBUG_DEFAULT_FLAGS))) {</span>
<span class="p_del">-		int pages = 1 &lt;&lt; oo_order(oo);</span>
<span class="p_del">-</span>
<span class="p_del">-		kmemcheck_alloc_shadow(page, oo_order(oo), alloc_gfp, node);</span>
<span class="p_del">-</span>
<span class="p_del">-		/*</span>
<span class="p_del">-		 * Objects from caches that have a constructor don&#39;t get</span>
<span class="p_del">-		 * cleared when they&#39;re allocated, so we need to do it here.</span>
<span class="p_del">-		 */</span>
<span class="p_del">-		if (s-&gt;ctor)</span>
<span class="p_del">-			kmemcheck_mark_uninitialized_pages(page, pages);</span>
<span class="p_del">-		else</span>
<span class="p_del">-			kmemcheck_mark_unallocated_pages(page, pages);</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
 	page-&gt;objects = oo_objects(oo);
 
 	order = compound_order(page);
<span class="p_chunk">@@ -1686,8 +1665,6 @@</span> <span class="p_context"> static void __free_slab(struct kmem_cache *s, struct page *page)</span>
 			check_object(s, page, p, SLUB_RED_INACTIVE);
 	}
 
<span class="p_del">-	kmemcheck_free_shadow(page, compound_order(page));</span>
<span class="p_del">-</span>
 	mod_lruvec_page_state(page,
 		(s-&gt;flags &amp; SLAB_RECLAIM_ACCOUNT) ?
 		NR_SLAB_RECLAIMABLE : NR_SLAB_UNRECLAIMABLE,
<span class="p_chunk">@@ -3791,7 +3768,7 @@</span> <span class="p_context"> static void *kmalloc_large_node(size_t size, gfp_t flags, int node)</span>
 	struct page *page;
 	void *ptr = NULL;
 
<span class="p_del">-	flags |= __GFP_COMP | __GFP_NOTRACK;</span>
<span class="p_add">+	flags |= __GFP_COMP;</span>
 	page = alloc_pages_node(node, flags, get_order(size));
 	if (page)
 		ptr = page_address(page);
<span class="p_chunk">@@ -5654,8 +5631,6 @@</span> <span class="p_context"> static char *create_unique_id(struct kmem_cache *s)</span>
 		*p++ = &#39;a&#39;;
 	if (s-&gt;flags &amp; SLAB_CONSISTENCY_CHECKS)
 		*p++ = &#39;F&#39;;
<span class="p_del">-	if (!(s-&gt;flags &amp; SLAB_NOTRACK))</span>
<span class="p_del">-		*p++ = &#39;t&#39;;</span>
 	if (s-&gt;flags &amp; SLAB_ACCOUNT)
 		*p++ = &#39;A&#39;;
 	if (p != name + 1)
<span class="p_header">diff --git a/net/core/skbuff.c b/net/core/skbuff.c</span>
<span class="p_header">index 16982de649b9..382d6155cd2e 100644</span>
<span class="p_header">--- a/net/core/skbuff.c</span>
<span class="p_header">+++ b/net/core/skbuff.c</span>
<span class="p_chunk">@@ -41,7 +41,6 @@</span> <span class="p_context"></span>
 #include &lt;linux/module.h&gt;
 #include &lt;linux/types.h&gt;
 #include &lt;linux/kernel.h&gt;
<span class="p_del">-#include &lt;linux/kmemcheck.h&gt;</span>
 #include &lt;linux/mm.h&gt;
 #include &lt;linux/interrupt.h&gt;
 #include &lt;linux/in.h&gt;
<span class="p_chunk">@@ -234,14 +233,12 @@</span> <span class="p_context"> struct sk_buff *__alloc_skb(unsigned int size, gfp_t gfp_mask,</span>
 	shinfo = skb_shinfo(skb);
 	memset(shinfo, 0, offsetof(struct skb_shared_info, dataref));
 	atomic_set(&amp;shinfo-&gt;dataref, 1);
<span class="p_del">-	kmemcheck_annotate_variable(shinfo-&gt;destructor_arg);</span>
 
 	if (flags &amp; SKB_ALLOC_FCLONE) {
 		struct sk_buff_fclones *fclones;
 
 		fclones = container_of(skb, struct sk_buff_fclones, skb1);
 
<span class="p_del">-		kmemcheck_annotate_bitfield(&amp;fclones-&gt;skb2, flags1);</span>
 		skb-&gt;fclone = SKB_FCLONE_ORIG;
 		refcount_set(&amp;fclones-&gt;fclone_ref, 1);
 
<span class="p_chunk">@@ -301,7 +298,6 @@</span> <span class="p_context"> struct sk_buff *__build_skb(void *data, unsigned int frag_size)</span>
 	shinfo = skb_shinfo(skb);
 	memset(shinfo, 0, offsetof(struct skb_shared_info, dataref));
 	atomic_set(&amp;shinfo-&gt;dataref, 1);
<span class="p_del">-	kmemcheck_annotate_variable(shinfo-&gt;destructor_arg);</span>
 
 	return skb;
 }
<span class="p_chunk">@@ -1279,7 +1275,6 @@</span> <span class="p_context"> struct sk_buff *skb_clone(struct sk_buff *skb, gfp_t gfp_mask)</span>
 		if (!n)
 			return NULL;
 
<span class="p_del">-		kmemcheck_annotate_bitfield(n, flags1);</span>
 		n-&gt;fclone = SKB_FCLONE_UNAVAILABLE;
 	}
 
<span class="p_header">diff --git a/net/core/sock.c b/net/core/sock.c</span>
<span class="p_header">index 9b7b6bbb2a23..f358370b4a2e 100644</span>
<span class="p_header">--- a/net/core/sock.c</span>
<span class="p_header">+++ b/net/core/sock.c</span>
<span class="p_chunk">@@ -1469,8 +1469,6 @@</span> <span class="p_context"> static struct sock *sk_prot_alloc(struct proto *prot, gfp_t priority,</span>
 		sk = kmalloc(prot-&gt;obj_size, priority);
 
 	if (sk != NULL) {
<span class="p_del">-		kmemcheck_annotate_bitfield(sk, flags);</span>
<span class="p_del">-</span>
 		if (security_sk_alloc(sk, family, priority))
 			goto out_free;
 
<span class="p_header">diff --git a/net/ipv4/inet_timewait_sock.c b/net/ipv4/inet_timewait_sock.c</span>
<span class="p_header">index 5b039159e67a..d451b9f19b59 100644</span>
<span class="p_header">--- a/net/ipv4/inet_timewait_sock.c</span>
<span class="p_header">+++ b/net/ipv4/inet_timewait_sock.c</span>
<span class="p_chunk">@@ -9,7 +9,6 @@</span> <span class="p_context"></span>
  */
 
 #include &lt;linux/kernel.h&gt;
<span class="p_del">-#include &lt;linux/kmemcheck.h&gt;</span>
 #include &lt;linux/slab.h&gt;
 #include &lt;linux/module.h&gt;
 #include &lt;net/inet_hashtables.h&gt;
<span class="p_chunk">@@ -167,8 +166,6 @@</span> <span class="p_context"> struct inet_timewait_sock *inet_twsk_alloc(const struct sock *sk,</span>
 	if (tw) {
 		const struct inet_sock *inet = inet_sk(sk);
 
<span class="p_del">-		kmemcheck_annotate_bitfield(tw, flags);</span>
<span class="p_del">-</span>
 		tw-&gt;tw_dr	    = dr;
 		/* Give us an identity. */
 		tw-&gt;tw_daddr	    = inet-&gt;inet_daddr;
<span class="p_header">diff --git a/net/ipv4/tcp_input.c b/net/ipv4/tcp_input.c</span>
<span class="p_header">index c5d7656beeee..4d2e31273a25 100644</span>
<span class="p_header">--- a/net/ipv4/tcp_input.c</span>
<span class="p_header">+++ b/net/ipv4/tcp_input.c</span>
<span class="p_chunk">@@ -6195,7 +6195,6 @@</span> <span class="p_context"> struct request_sock *inet_reqsk_alloc(const struct request_sock_ops *ops,</span>
 	if (req) {
 		struct inet_request_sock *ireq = inet_rsk(req);
 
<span class="p_del">-		kmemcheck_annotate_bitfield(ireq, flags);</span>
 		ireq-&gt;opt = NULL;
 #if IS_ENABLED(CONFIG_IPV6)
 		ireq-&gt;pktopts = NULL;
<span class="p_header">diff --git a/net/socket.c b/net/socket.c</span>
<span class="p_header">index c729625eb5d3..42d8e9c9ccd5 100644</span>
<span class="p_header">--- a/net/socket.c</span>
<span class="p_header">+++ b/net/socket.c</span>
<span class="p_chunk">@@ -568,7 +568,6 @@</span> <span class="p_context"> struct socket *sock_alloc(void)</span>
 
 	sock = SOCKET_I(inode);
 
<span class="p_del">-	kmemcheck_annotate_bitfield(sock, type);</span>
 	inode-&gt;i_ino = get_next_ino();
 	inode-&gt;i_mode = S_IFSOCK | S_IRWXUGO;
 	inode-&gt;i_uid = current_fsuid();
<span class="p_header">diff --git a/scripts/kernel-doc b/scripts/kernel-doc</span>
<span class="p_header">index 9d3eafea58f0..8323ff9dec71 100755</span>
<span class="p_header">--- a/scripts/kernel-doc</span>
<span class="p_header">+++ b/scripts/kernel-doc</span>
<span class="p_chunk">@@ -2182,8 +2182,6 @@</span> <span class="p_context"> sub dump_struct($$) {</span>
 	# strip comments:
 	$members =~ s/\/\*.*?\*\///gos;
 	$nested =~ s/\/\*.*?\*\///gos;
<span class="p_del">-	# strip kmemcheck_bitfield_{begin,end}.*;</span>
<span class="p_del">-	$members =~ s/kmemcheck_bitfield_.*?;//gos;</span>
 	# strip attributes
 	$members =~ s/__attribute__\s*\(\([a-z,_\*\s\(\)]*\)\)//i;
 	$members =~ s/__aligned\s*\([^;]*\)//gos;
<span class="p_header">diff --git a/tools/include/linux/kmemcheck.h b/tools/include/linux/kmemcheck.h</span>
deleted file mode 100644
<span class="p_header">index 94d598bc6abe..000000000000</span>
<span class="p_header">--- a/tools/include/linux/kmemcheck.h</span>
<span class="p_header">+++ /dev/null</span>
<span class="p_chunk">@@ -1,8 +0,0 @@</span> <span class="p_context"></span>
<span class="p_del">-#ifndef _LIBLOCKDEP_LINUX_KMEMCHECK_H_</span>
<span class="p_del">-#define _LIBLOCKDEP_LINUX_KMEMCHECK_H_</span>
<span class="p_del">-</span>
<span class="p_del">-static inline void kmemcheck_mark_initialized(void *address, unsigned int n)</span>
<span class="p_del">-{</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-#endif</span>
<span class="p_header">diff --git a/tools/perf/builtin-kmem.c b/tools/perf/builtin-kmem.c</span>
<span class="p_header">index 24ee68ecdd42..988c4732fe5d 100644</span>
<span class="p_header">--- a/tools/perf/builtin-kmem.c</span>
<span class="p_header">+++ b/tools/perf/builtin-kmem.c</span>
<span class="p_chunk">@@ -654,7 +654,6 @@</span> <span class="p_context"> static const struct {</span>
 	{ &quot;__GFP_RECLAIMABLE&quot;,		&quot;RC&quot; },
 	{ &quot;__GFP_MOVABLE&quot;,		&quot;M&quot; },
 	{ &quot;__GFP_ACCOUNT&quot;,		&quot;AC&quot; },
<span class="p_del">-	{ &quot;__GFP_NOTRACK&quot;,		&quot;NT&quot; },</span>
 	{ &quot;__GFP_WRITE&quot;,		&quot;WR&quot; },
 	{ &quot;__GFP_RECLAIM&quot;,		&quot;R&quot; },
 	{ &quot;__GFP_DIRECT_RECLAIM&quot;,	&quot;DR&quot; },

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



