
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>[RFC,v2] Add /proc/pid/smaps_rollup - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    [RFC,v2] Add /proc/pid/smaps_rollup</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=175813">Daniel Colascione</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>Aug. 10, 2017, 12:15 a.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;20170810001557.147285-1-dancol@google.com&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/9892455/mbox/"
   >mbox</a>
|
   <a href="/patch/9892455/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/9892455/">/patch/9892455/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
	[172.30.200.125])
	by pdx-korg-patchwork.web.codeaurora.org (Postfix) with ESMTP id
	2CE59601EB for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Thu, 10 Aug 2017 00:16:46 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 048672896D
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Thu, 10 Aug 2017 00:16:46 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id ED3AC289EB; Thu, 10 Aug 2017 00:16:45 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-6.5 required=2.0 tests=BAYES_00,DKIM_SIGNED,
	DKIM_VALID,DKIM_VALID_AU,RCVD_IN_DNSWL_HI,RCVD_IN_SORBS_SPAM
	autolearn=unavailable version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 173592896D
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Thu, 10 Aug 2017 00:16:45 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1752486AbdHJAQi (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Wed, 9 Aug 2017 20:16:38 -0400
Received: from mail-pg0-f50.google.com ([74.125.83.50]:35899 &quot;EHLO
	mail-pg0-f50.google.com&quot; rhost-flags-OK-OK-OK-OK) by vger.kernel.org
	with ESMTP id S1752332AbdHJAQg (ORCPT
	&lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Wed, 9 Aug 2017 20:16:36 -0400
Received: by mail-pg0-f50.google.com with SMTP id v77so34203648pgb.3
	for &lt;linux-kernel@vger.kernel.org&gt;;
	Wed, 09 Aug 2017 17:16:36 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
	d=google.com; s=20161025;
	h=from:to:cc:subject:date:message-id:in-reply-to:references;
	bh=UM2AmphGTYNQjb6eIUfmFDkZ2OI6NUvPlhl5ubXGI/Q=;
	b=Vagjw6c81V2yG0Vnvrk54omTmEd0KEvYxBX1AErC9BIfAyTWcVLJY7gmJBcXdaAisO
	z4qhu6yuVvUF43NQnBmRJoNYyVlZ3celu823oNW02iSRU0NKhxLhIFYqPc7XbhQFh6Yx
	sh2pNgmTL9JB72/yB9MM3SVXS+EFH7BtmIegAbq/c3izWK/XK/3ZQRTIlbUsiH5HZ1VF
	lmHG9vpqLRPqW3wCgMW0xqrsoWwdsrSAD55znbB8qfVTpvQHA05dZEPoHCXY0myqSGxr
	iTJd6rFtfR1Tu9v+1EEF6zW7yRpzJ1NawwVz0hAOaBwcQgnbRA32Z6TVxP4b/jY44geq
	rwuQ==
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
	d=1e100.net; s=20161025;
	h=x-gm-message-state:from:to:cc:subject:date:message-id:in-reply-to
	:references;
	bh=UM2AmphGTYNQjb6eIUfmFDkZ2OI6NUvPlhl5ubXGI/Q=;
	b=dvXDM5PXj8RtXYElLY7TMx133smq25Zoi3Xfi3nZrvUIp8HJ0NIsV4JMBYWyCjbZ44
	e2QdK3w050QBP2zDsAAre4NvCcuyAkfj0ORTGKlrw/3D8KdP6Vq3QOAT8551t9LTJ3xI
	u8WYPtKmnGb+QpWVMhq39KI8TgAI90A37rAcrzPuS3Es4yrT+IuEhCLZCbHdpBGdTs8G
	UW2Gwcm1f/7aUJHkvwc3eDgCe7+qvW3q+er1/BulXRZIHex+KtYPAWgC55WKC0siLFZX
	XATEMG4mJxf0sGUEf2CUpiQLyGUXbgksGTRNuBMdR0aFnQ80LBrl5BiCfTEnnUlQivoE
	Zpgw==
X-Gm-Message-State: AHYfb5g2Nwh9g6J5ibFlxF09WDURS8d4mGNKyG3dLIn/j0KIhJrG51gN
	dUBPRRwEVbyLMkCoSWlfmQ==
X-Received: by 10.99.139.66 with SMTP id j63mr9450404pge.266.1502324195374; 
	Wed, 09 Aug 2017 17:16:35 -0700 (PDT)
Received: from poke.sea.corp.google.com ([100.100.214.22])
	by smtp.gmail.com with ESMTPSA id
	k185sm8194355pgc.31.2017.08.09.17.16.34
	(version=TLS1_2 cipher=ECDHE-RSA-AES128-SHA bits=128/128);
	Wed, 09 Aug 2017 17:16:34 -0700 (PDT)
From: Daniel Colascione &lt;dancol@google.com&gt;
To: linux-kernel@vger.kernel.org, timmurray@google.com,
	joelaf@google.com, viro@zeniv.linux.org.uk,
	linux-fsdevel@vger.kernel.org, linux-mm@kvack.org
Cc: Daniel Colascione &lt;dancol@google.com&gt;
Subject: [PATCH RFC v2] Add /proc/pid/smaps_rollup
Date: Wed,  9 Aug 2017 17:15:57 -0700
Message-Id: &lt;20170810001557.147285-1-dancol@google.com&gt;
X-Mailer: git-send-email 2.14.0.434.g98096fd7a8-goog
In-Reply-To: &lt;20170808132554.141143-1-dancol@google.com&gt;
References: &lt;20170808132554.141143-1-dancol@google.com&gt;
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=175813">Daniel Colascione</a> - Aug. 10, 2017, 12:15 a.m.</div>
<pre class="content">
/proc/pid/smaps_rollup is a new proc file that improves the
performance of user programs that determine aggregate memory
statistics (e.g., total PSS) of a process.

Android regularly &quot;samples&quot; the memory usage of various processes in
order to balance its memory pool sizes. This sampling process involves
opening /proc/pid/smaps and summing certain fields. For very large
processes, sampling memory use this way can take several hundred
milliseconds, due mostly to the overhead of the seq_printf calls in
task_mmu.c.

smaps_rollup improves the situation. It contains most of the fields of
/proc/pid/smaps, but instead of a set of fields for each VMA,
smaps_rollup instead contains one synthetic smaps-format entry
representing the whole process. In the single smaps_rollup synthetic
entry, each field is the summation of the corresponding field in all
of the real-smaps VMAs. Using a common format for smaps_rollup and
smaps allows userspace parsers to repurpose parsers meant for use with
non-rollup smaps for smaps_rollup, and it allows userspace to switch
between smaps_rollup and smaps at runtime (say, based on the
availability of smaps_rollup in a given kernel) with minimal fuss.

By using smaps_rollup instead of smaps, a caller can avoid the
significant overhead of formatting, reading, and parsing each of a
large process&#39;s potentially very numerous memory mappings. For
sampling system_server&#39;s PSS in Android, we measured a 12x speedup,
representing a savings of several hundred milliseconds.

One alternative to a new per-process proc file would have been
including PSS information in /proc/pid/status. We considered this
option but thought that PSS would be too expensive (by a few orders of
magnitude) to collect relative to what&#39;s already emitted as part of
/proc/pid/status, and slowing every user of /proc/pid/status for the
sake of readers that happen to want PSS feels wrong.

The code itself works by reusing the existing VMA-walking framework we
use for regular smaps generation and keeping the mem_size_stats
structure around between VMA walks instead of using a fresh one for
each VMA.  In this way, summation happens automatically.  We let
seq_file walk over the VMAs just as it does for regular smaps and just
emit nothing to the seq_file until we hit the last VMA.

Patch changelog:

v2: Fix typo in commit message
    Add ABI documentation as requested by gregkh
<span class="signed-off-by">
Signed-off-by: Daniel Colascione &lt;dancol@google.com&gt;</span>
---
 Documentation/ABI/testing/procfs-smaps_rollup |  34 +++++
 fs/proc/base.c                                |   2 +
 fs/proc/internal.h                            |   3 +
 fs/proc/task_mmu.c                            | 196 ++++++++++++++++++--------
 4 files changed, 173 insertions(+), 62 deletions(-)
 create mode 100644 Documentation/ABI/testing/procfs-smaps_rollup
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=52131">Randy Dunlap</a> - Aug. 10, 2017, 1:24 a.m.</div>
<pre class="content">
On 08/09/2017 05:15 PM, Daniel Colascione wrote:
<span class="quote">&gt; </span>
<span class="quote">&gt; diff --git a/Documentation/ABI/testing/procfs-smaps_rollup b/Documentation/ABI/testing/procfs-smaps_rollup</span>
<span class="quote">&gt; new file mode 100644</span>
<span class="quote">&gt; index 000000000000..fd5a3699edf1</span>
<span class="quote">&gt; --- /dev/null</span>
<span class="quote">&gt; +++ b/Documentation/ABI/testing/procfs-smaps_rollup</span>
<span class="quote">&gt; @@ -0,0 +1,34 @@</span>
<span class="quote">&gt; +What:		/proc/pid/smaps_Rollup</span>

        		          smaps_rollup

\although I would prefer smaps_summary. whatever.
<span class="quote">
&gt; +Date:		August 2017</span>
<span class="quote">&gt; +Contact:	Daniel Colascione &lt;dancol@google.com&gt;</span>
<span class="quote">&gt; +Description:</span>
<span class="quote">&gt; +		This file provides pre-summed memory information for a</span>
<span class="quote">&gt; +		process.  The format is identical to /proc/pid/smaps,</span>
<span class="quote">&gt; +		except instead of an entry for each VMA in a process,</span>
<span class="quote">&gt; +		smaps_rollup has a single entry (tagged &quot;[rollup]&quot;)</span>
<span class="quote">&gt; +		for which each field is the sum of the corresponding</span>
<span class="quote">&gt; +		fields from all the maps in /proc/pid/smaps.</span>
<span class="quote">&gt; +		For more details, see the procfs man page.</span>
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=36811">Minchan Kim</a> - Aug. 10, 2017, 4:38 a.m.</div>
<pre class="content">
On Wed, Aug 09, 2017 at 05:15:57PM -0700, Daniel Colascione wrote:
<span class="quote">&gt; /proc/pid/smaps_rollup is a new proc file that improves the</span>
<span class="quote">&gt; performance of user programs that determine aggregate memory</span>
<span class="quote">&gt; statistics (e.g., total PSS) of a process.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Android regularly &quot;samples&quot; the memory usage of various processes in</span>
<span class="quote">&gt; order to balance its memory pool sizes. This sampling process involves</span>
<span class="quote">&gt; opening /proc/pid/smaps and summing certain fields. For very large</span>
<span class="quote">&gt; processes, sampling memory use this way can take several hundred</span>
<span class="quote">&gt; milliseconds, due mostly to the overhead of the seq_printf calls in</span>
<span class="quote">&gt; task_mmu.c.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; smaps_rollup improves the situation. It contains most of the fields of</span>
<span class="quote">&gt; /proc/pid/smaps, but instead of a set of fields for each VMA,</span>
<span class="quote">&gt; smaps_rollup instead contains one synthetic smaps-format entry</span>
<span class="quote">&gt; representing the whole process. In the single smaps_rollup synthetic</span>
<span class="quote">&gt; entry, each field is the summation of the corresponding field in all</span>
<span class="quote">&gt; of the real-smaps VMAs. Using a common format for smaps_rollup and</span>
<span class="quote">&gt; smaps allows userspace parsers to repurpose parsers meant for use with</span>
<span class="quote">&gt; non-rollup smaps for smaps_rollup, and it allows userspace to switch</span>
<span class="quote">&gt; between smaps_rollup and smaps at runtime (say, based on the</span>
<span class="quote">&gt; availability of smaps_rollup in a given kernel) with minimal fuss.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; By using smaps_rollup instead of smaps, a caller can avoid the</span>
<span class="quote">&gt; significant overhead of formatting, reading, and parsing each of a</span>
<span class="quote">&gt; large process&#39;s potentially very numerous memory mappings. For</span>
<span class="quote">&gt; sampling system_server&#39;s PSS in Android, we measured a 12x speedup,</span>
<span class="quote">&gt; representing a savings of several hundred milliseconds.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; One alternative to a new per-process proc file would have been</span>
<span class="quote">&gt; including PSS information in /proc/pid/status. We considered this</span>
<span class="quote">&gt; option but thought that PSS would be too expensive (by a few orders of</span>
<span class="quote">&gt; magnitude) to collect relative to what&#39;s already emitted as part of</span>
<span class="quote">&gt; /proc/pid/status, and slowing every user of /proc/pid/status for the</span>
<span class="quote">&gt; sake of readers that happen to want PSS feels wrong.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; The code itself works by reusing the existing VMA-walking framework we</span>
<span class="quote">&gt; use for regular smaps generation and keeping the mem_size_stats</span>
<span class="quote">&gt; structure around between VMA walks instead of using a fresh one for</span>
<span class="quote">&gt; each VMA.  In this way, summation happens automatically.  We let</span>
<span class="quote">&gt; seq_file walk over the VMAs just as it does for regular smaps and just</span>
<span class="quote">&gt; emit nothing to the seq_file until we hit the last VMA.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Patch changelog:</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; v2: Fix typo in commit message</span>
<span class="quote">&gt;     Add ABI documentation as requested by gregkh</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Signed-off-by: Daniel Colascione &lt;dancol@google.com&gt;</span>

I love this.

FYI, there was trial but got failed at that time so in this time,
https://marc.info/?l=linux-kernel&amp;m=147310650003277&amp;w=2
http://www.mail-archive.com/linux-kernel@vger.kernel.org/msg1229163.html

I really hope we merge this patch.
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=137061">Michal Hocko</a> - Aug. 10, 2017, 8:46 a.m.</div>
<pre class="content">
[CC linux-api - the patch was posted here
http://lkml.kernel.org/r/20170810001557.147285-1-dancol@google.com]

On Thu 10-08-17 13:38:31, Minchan Kim wrote:
<span class="quote">&gt; On Wed, Aug 09, 2017 at 05:15:57PM -0700, Daniel Colascione wrote:</span>
<span class="quote">&gt; &gt; /proc/pid/smaps_rollup is a new proc file that improves the</span>
<span class="quote">&gt; &gt; performance of user programs that determine aggregate memory</span>
<span class="quote">&gt; &gt; statistics (e.g., total PSS) of a process.</span>
<span class="quote">&gt; &gt; </span>
<span class="quote">&gt; &gt; Android regularly &quot;samples&quot; the memory usage of various processes in</span>
<span class="quote">&gt; &gt; order to balance its memory pool sizes. This sampling process involves</span>
<span class="quote">&gt; &gt; opening /proc/pid/smaps and summing certain fields. For very large</span>
<span class="quote">&gt; &gt; processes, sampling memory use this way can take several hundred</span>
<span class="quote">&gt; &gt; milliseconds, due mostly to the overhead of the seq_printf calls in</span>
<span class="quote">&gt; &gt; task_mmu.c.</span>

Have you tried to reduce that overhead? E.g. by replacing seq_printf by
something more simple
http://lkml.kernel.org/r/20160817130320.GC20703@dhcp22.suse.cz?
How often you you need to read this information?
<span class="quote">
&gt; &gt; smaps_rollup improves the situation. It contains most of the fields of</span>
<span class="quote">&gt; &gt; /proc/pid/smaps, but instead of a set of fields for each VMA,</span>
<span class="quote">&gt; &gt; smaps_rollup instead contains one synthetic smaps-format entry</span>
<span class="quote">&gt; &gt; representing the whole process. In the single smaps_rollup synthetic</span>
<span class="quote">&gt; &gt; entry, each field is the summation of the corresponding field in all</span>
<span class="quote">&gt; &gt; of the real-smaps VMAs. Using a common format for smaps_rollup and</span>
<span class="quote">&gt; &gt; smaps allows userspace parsers to repurpose parsers meant for use with</span>
<span class="quote">&gt; &gt; non-rollup smaps for smaps_rollup, and it allows userspace to switch</span>
<span class="quote">&gt; &gt; between smaps_rollup and smaps at runtime (say, based on the</span>
<span class="quote">&gt; &gt; availability of smaps_rollup in a given kernel) with minimal fuss.</span>
<span class="quote">&gt; &gt; </span>
<span class="quote">&gt; &gt; By using smaps_rollup instead of smaps, a caller can avoid the</span>
<span class="quote">&gt; &gt; significant overhead of formatting, reading, and parsing each of a</span>
<span class="quote">&gt; &gt; large process&#39;s potentially very numerous memory mappings. For</span>
<span class="quote">&gt; &gt; sampling system_server&#39;s PSS in Android, we measured a 12x speedup,</span>
<span class="quote">&gt; &gt; representing a savings of several hundred milliseconds.</span>

By a large process you mean a process with many VMAs right? How many
vmas are we talking about?
<span class="quote">
&gt; &gt; One alternative to a new per-process proc file would have been</span>
<span class="quote">&gt; &gt; including PSS information in /proc/pid/status. We considered this</span>
<span class="quote">&gt; &gt; option but thought that PSS would be too expensive (by a few orders of</span>
<span class="quote">&gt; &gt; magnitude) to collect relative to what&#39;s already emitted as part of</span>
<span class="quote">&gt; &gt; /proc/pid/status, and slowing every user of /proc/pid/status for the</span>
<span class="quote">&gt; &gt; sake of readers that happen to want PSS feels wrong.</span>
<span class="quote">&gt; &gt; </span>
<span class="quote">&gt; &gt; The code itself works by reusing the existing VMA-walking framework we</span>
<span class="quote">&gt; &gt; use for regular smaps generation and keeping the mem_size_stats</span>
<span class="quote">&gt; &gt; structure around between VMA walks instead of using a fresh one for</span>
<span class="quote">&gt; &gt; each VMA.  In this way, summation happens automatically.  We let</span>
<span class="quote">&gt; &gt; seq_file walk over the VMAs just as it does for regular smaps and just</span>
<span class="quote">&gt; &gt; emit nothing to the seq_file until we hit the last VMA.</span>
<span class="quote">&gt; &gt; </span>
<span class="quote">&gt; &gt; Patch changelog:</span>
<span class="quote">&gt; &gt; </span>
<span class="quote">&gt; &gt; v2: Fix typo in commit message</span>
<span class="quote">&gt; &gt;     Add ABI documentation as requested by gregkh</span>
<span class="quote">&gt; &gt; </span>
<span class="quote">&gt; &gt; Signed-off-by: Daniel Colascione &lt;dancol@google.com&gt;</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; I love this.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; FYI, there was trial but got failed at that time so in this time,</span>
<span class="quote">&gt; https://marc.info/?l=linux-kernel&amp;m=147310650003277&amp;w=2</span>
<span class="quote">&gt; http://www.mail-archive.com/linux-kernel@vger.kernel.org/msg1229163.html</span>

Yes I really disliked the previous attempt and this one is not all that
better. The primary unanswered question back then was a relevant
usecase. Back then it was argued [1] that PSS was useful for userspace
OOM handling but arguments were rather dubious. Follow up questions [2]
shown that the useage of PSS was very workload specific. Minchan has
noted some usecase as well but not very specific either.

So let&#39;s start with a clear use case description. Then let&#39;s make it
clear that even optimizing the current implementation is not sufficient
to meat goals and only then try to add one more user visible API which
we will have to maintain for ever.

[1] http://lkml.kernel.org/r/CAPz6YkW3Ph4mi++qY4cJiQ1PwhnxLr5=E4oCHjf5nYJHMhRcew@mail.gmail.com
[2] http://lkml.kernel.org/r/20160819075910.GB32619@dhcp22.suse.cz
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=175813">Daniel Colascione</a> - Aug. 10, 2017, 10:23 a.m.</div>
<pre class="content">
Thanks for taking a look at the patch!

On Thu, Aug 10 2017, Michal Hocko wrote:
<span class="quote">&gt; [CC linux-api - the patch was posted here</span>
<span class="quote">&gt; http://lkml.kernel.org/r/20170810001557.147285-1-dancol@google.com]</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; On Thu 10-08-17 13:38:31, Minchan Kim wrote:</span>
<span class="quote">&gt;&gt; On Wed, Aug 09, 2017 at 05:15:57PM -0700, Daniel Colascione wrote:</span>
<span class="quote">&gt;&gt; &gt; /proc/pid/smaps_rollup is a new proc file that improves the</span>
<span class="quote">&gt;&gt; &gt; performance of user programs that determine aggregate memory</span>
<span class="quote">&gt;&gt; &gt; statistics (e.g., total PSS) of a process.</span>
<span class="quote">&gt;&gt; &gt; </span>
<span class="quote">&gt;&gt; &gt; Android regularly &quot;samples&quot; the memory usage of various processes in</span>
<span class="quote">&gt;&gt; &gt; order to balance its memory pool sizes. This sampling process involves</span>
<span class="quote">&gt;&gt; &gt; opening /proc/pid/smaps and summing certain fields. For very large</span>
<span class="quote">&gt;&gt; &gt; processes, sampling memory use this way can take several hundred</span>
<span class="quote">&gt;&gt; &gt; milliseconds, due mostly to the overhead of the seq_printf calls in</span>
<span class="quote">&gt;&gt; &gt; task_mmu.c.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; Have you tried to reduce that overhead? E.g. by replacing seq_printf by</span>
<span class="quote">&gt; something more simple</span>
<span class="quote">&gt; http://lkml.kernel.org/r/20160817130320.GC20703@dhcp22.suse.cz?</span>

I haven&#39;t tried that yet, but if I&#39;m reading that thread correctly, it
looks like using more efficient printing primitives gives us a 7%
speedup. The smaps_rollup patch gives us a much bigger speedup while
reusing almost all the smaps code, so it seems easier and simpler than a
bunch of incremental improvements to smaps. And even an efficient smaps
would have to push 2MB through seq_file for the 3000-VMA process case.
<span class="quote">
&gt; How often you you need to read this information?</span>

It varies depending on how often processes change state.  We sample a
short time (tens of seconds) after processes change state (e.g., enters
foreground) and every few minutes thereafter. We&#39;re particularly
concerned from an energy perspective about needlessly burning CPU on
background samples.
<span class="quote">
&gt;&gt; &gt; smaps_rollup improves the situation. It contains most of the fields of</span>
<span class="quote">&gt;&gt; &gt; /proc/pid/smaps, but instead of a set of fields for each VMA,</span>
<span class="quote">&gt;&gt; &gt; smaps_rollup instead contains one synthetic smaps-format entry</span>
<span class="quote">&gt;&gt; &gt; representing the whole process. In the single smaps_rollup synthetic</span>
<span class="quote">&gt;&gt; &gt; entry, each field is the summation of the corresponding field in all</span>
<span class="quote">&gt;&gt; &gt; of the real-smaps VMAs. Using a common format for smaps_rollup and</span>
<span class="quote">&gt;&gt; &gt; smaps allows userspace parsers to repurpose parsers meant for use with</span>
<span class="quote">&gt;&gt; &gt; non-rollup smaps for smaps_rollup, and it allows userspace to switch</span>
<span class="quote">&gt;&gt; &gt; between smaps_rollup and smaps at runtime (say, based on the</span>
<span class="quote">&gt;&gt; &gt; availability of smaps_rollup in a given kernel) with minimal fuss.</span>
<span class="quote">&gt;&gt; &gt; </span>
<span class="quote">&gt;&gt; &gt; By using smaps_rollup instead of smaps, a caller can avoid the</span>
<span class="quote">&gt;&gt; &gt; significant overhead of formatting, reading, and parsing each of a</span>
<span class="quote">&gt;&gt; &gt; large process&#39;s potentially very numerous memory mappings. For</span>
<span class="quote">&gt;&gt; &gt; sampling system_server&#39;s PSS in Android, we measured a 12x speedup,</span>
<span class="quote">&gt;&gt; &gt; representing a savings of several hundred milliseconds.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; By a large process you mean a process with many VMAs right? How many</span>
<span class="quote">&gt; vmas are we talking about?</span>

Yes: ~3000 VMAs is one I&#39;d consider large in this context.
<span class="quote">
&gt;&gt; &gt; One alternative to a new per-process proc file would have been</span>
<span class="quote">&gt;&gt; &gt; including PSS information in /proc/pid/status. We considered this</span>
<span class="quote">&gt;&gt; &gt; option but thought that PSS would be too expensive (by a few orders of</span>
<span class="quote">&gt;&gt; &gt; magnitude) to collect relative to what&#39;s already emitted as part of</span>
<span class="quote">&gt;&gt; &gt; /proc/pid/status, and slowing every user of /proc/pid/status for the</span>
<span class="quote">&gt;&gt; &gt; sake of readers that happen to want PSS feels wrong.</span>
<span class="quote">&gt;&gt; &gt; </span>
<span class="quote">&gt;&gt; &gt; The code itself works by reusing the existing VMA-walking framework we</span>
<span class="quote">&gt;&gt; &gt; use for regular smaps generation and keeping the mem_size_stats</span>
<span class="quote">&gt;&gt; &gt; structure around between VMA walks instead of using a fresh one for</span>
<span class="quote">&gt;&gt; &gt; each VMA.  In this way, summation happens automatically.  We let</span>
<span class="quote">&gt;&gt; &gt; seq_file walk over the VMAs just as it does for regular smaps and just</span>
<span class="quote">&gt;&gt; &gt; emit nothing to the seq_file until we hit the last VMA.</span>
<span class="quote">&gt;&gt; &gt; </span>
<span class="quote">&gt;&gt; &gt; Patch changelog:</span>
<span class="quote">&gt;&gt; &gt; </span>
<span class="quote">&gt;&gt; &gt; v2: Fix typo in commit message</span>
<span class="quote">&gt;&gt; &gt;     Add ABI documentation as requested by gregkh</span>
<span class="quote">&gt;&gt; &gt; </span>
<span class="quote">&gt;&gt; &gt; Signed-off-by: Daniel Colascione &lt;dancol@google.com&gt;</span>
<span class="quote">&gt;&gt; </span>
<span class="quote">&gt;&gt; I love this.</span>
<span class="quote">&gt;&gt; </span>
<span class="quote">&gt;&gt; FYI, there was trial but got failed at that time so in this time,</span>
<span class="quote">&gt;&gt; https://marc.info/?l=linux-kernel&amp;m=147310650003277&amp;w=2</span>
<span class="quote">&gt;&gt; http://www.mail-archive.com/linux-kernel@vger.kernel.org/msg1229163.html</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; Yes I really disliked the previous attempt and this one is not all that</span>
<span class="quote">&gt; better. The primary unanswered question back then was a relevant</span>
<span class="quote">&gt; usecase. Back then it was argued [1] that PSS was useful for userspace</span>
<span class="quote">&gt; OOM handling but arguments were rather dubious. Follow up questions [2]</span>
<span class="quote">&gt; shown that the useage of PSS was very workload specific. Minchan has</span>
<span class="quote">&gt; noted some usecase as well but not very specific either.</span>

Anyway, I see what you mean about PSS being iffy for user-space OOM
processing (because PSS doesn&#39;t tell you how much memory you get back in
exchange for killing a given process at a particular moment). We&#39;re not
using it like that.

Instead, we&#39;re using the PSS samples we collect asynchronously for
system-management tasks like fine-tuning oom_adj_score, memory use
tracking for debugging, application-level memory-use attribution, and
deciding whether we want to kill large processes during system idle
maintenance windows. Android has been using PSS for these purposes for a
long time; as the average process VMA count has increased and and
devices become more efficiency-conscious, PSS-collection inefficiency
has started to matter more. IMHO, it&#39;d be a lot safer to optimize the
existing PSS-collection model, which has been fine-tuned over the years,
instead of changing the memory tracking approach entirely to work around
smaps-generation inefficiency.

The existence of an independent attempt to add this functionality
suggests that it might be generally useful too.
<span class="quote">
&gt; So let&#39;s start with a clear use case description. Then let&#39;s make it</span>
<span class="quote">&gt; clear that even optimizing the current implementation is not sufficient</span>
<span class="quote">&gt; to meat goals and only then try to add one more user visible API which</span>
<span class="quote">&gt; we will have to maintain for ever.</span>

Adding a new API shouldn&#39;t be anyone&#39;s first choice, but the efficiency
wins are hard to ignore. We can cut ~2MB of smaps data to a few KB this
way. I&#39;m definitely open to other ideas for getting similar wins, but
right now, I&#39;d like to explore approaches that let us keep using the
existing PSS metric.

Thanks again!
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=137061">Michal Hocko</a> - Aug. 10, 2017, 10:58 a.m.</div>
<pre class="content">
On Thu 10-08-17 03:23:23, Daniel Colascione wrote:
<span class="quote">&gt; Thanks for taking a look at the patch!</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; On Thu, Aug 10 2017, Michal Hocko wrote:</span>
<span class="quote">&gt; &gt; [CC linux-api - the patch was posted here</span>
<span class="quote">&gt; &gt; http://lkml.kernel.org/r/20170810001557.147285-1-dancol@google.com]</span>
<span class="quote">&gt; &gt;</span>
<span class="quote">&gt; &gt; On Thu 10-08-17 13:38:31, Minchan Kim wrote:</span>
<span class="quote">&gt; &gt;&gt; On Wed, Aug 09, 2017 at 05:15:57PM -0700, Daniel Colascione wrote:</span>
<span class="quote">&gt; &gt;&gt; &gt; /proc/pid/smaps_rollup is a new proc file that improves the</span>
<span class="quote">&gt; &gt;&gt; &gt; performance of user programs that determine aggregate memory</span>
<span class="quote">&gt; &gt;&gt; &gt; statistics (e.g., total PSS) of a process.</span>
<span class="quote">&gt; &gt;&gt; &gt; </span>
<span class="quote">&gt; &gt;&gt; &gt; Android regularly &quot;samples&quot; the memory usage of various processes in</span>
<span class="quote">&gt; &gt;&gt; &gt; order to balance its memory pool sizes. This sampling process involves</span>
<span class="quote">&gt; &gt;&gt; &gt; opening /proc/pid/smaps and summing certain fields. For very large</span>
<span class="quote">&gt; &gt;&gt; &gt; processes, sampling memory use this way can take several hundred</span>
<span class="quote">&gt; &gt;&gt; &gt; milliseconds, due mostly to the overhead of the seq_printf calls in</span>
<span class="quote">&gt; &gt;&gt; &gt; task_mmu.c.</span>
<span class="quote">&gt; &gt;</span>
<span class="quote">&gt; &gt; Have you tried to reduce that overhead? E.g. by replacing seq_printf by</span>
<span class="quote">&gt; &gt; something more simple</span>
<span class="quote">&gt; &gt; http://lkml.kernel.org/r/20160817130320.GC20703@dhcp22.suse.cz?</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; I haven&#39;t tried that yet, but if I&#39;m reading that thread correctly, it</span>
<span class="quote">&gt; looks like using more efficient printing primitives gives us a 7%</span>
<span class="quote">&gt; speedup. The smaps_rollup patch gives us a much bigger speedup while</span>
<span class="quote">&gt; reusing almost all the smaps code, so it seems easier and simpler than a</span>
<span class="quote">&gt; bunch of incremental improvements to smaps. And even an efficient smaps</span>
<span class="quote">&gt; would have to push 2MB through seq_file for the 3000-VMA process case.</span>

The thing is that more users would benefit from a more efficient
/proc/pid/smaps call. Maybe we can use some caching tricks etc...  We
should make sure that existing options should be attempted before a new
user visible interface is added. It is kind of sad that the real work
(pte walk) is less expensive than formating the output and copying it to
the userspace...
<span class="quote">
&gt; &gt; How often you you need to read this information?</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; It varies depending on how often processes change state.  We sample a</span>
<span class="quote">&gt; short time (tens of seconds) after processes change state (e.g., enters</span>
<span class="quote">&gt; foreground) and every few minutes thereafter. We&#39;re particularly</span>
<span class="quote">&gt; concerned from an energy perspective about needlessly burning CPU on</span>
<span class="quote">&gt; background samples.</span>

Please make sure this is documented in the patch along with some numbers
ideally.

[...]
<span class="quote">
&gt; &gt;&gt; FYI, there was trial but got failed at that time so in this time,</span>
<span class="quote">&gt; &gt;&gt; https://marc.info/?l=linux-kernel&amp;m=147310650003277&amp;w=2</span>
<span class="quote">&gt; &gt;&gt; http://www.mail-archive.com/linux-kernel@vger.kernel.org/msg1229163.html</span>
<span class="quote">&gt; &gt;</span>
<span class="quote">&gt; &gt; Yes I really disliked the previous attempt and this one is not all that</span>
<span class="quote">&gt; &gt; better. The primary unanswered question back then was a relevant</span>
<span class="quote">&gt; &gt; usecase. Back then it was argued [1] that PSS was useful for userspace</span>
<span class="quote">&gt; &gt; OOM handling but arguments were rather dubious. Follow up questions [2]</span>
<span class="quote">&gt; &gt; shown that the useage of PSS was very workload specific. Minchan has</span>
<span class="quote">&gt; &gt; noted some usecase as well but not very specific either.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Anyway, I see what you mean about PSS being iffy for user-space OOM</span>
<span class="quote">&gt; processing (because PSS doesn&#39;t tell you how much memory you get back in</span>
<span class="quote">&gt; exchange for killing a given process at a particular moment). We&#39;re not</span>
<span class="quote">&gt; using it like that.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Instead, we&#39;re using the PSS samples we collect asynchronously for</span>
<span class="quote">&gt; system-management tasks like fine-tuning oom_adj_score, memory use</span>
<span class="quote">&gt; tracking for debugging, application-level memory-use attribution, and</span>
<span class="quote">&gt; deciding whether we want to kill large processes during system idle</span>
<span class="quote">&gt; maintenance windows. Android has been using PSS for these purposes for a</span>
<span class="quote">&gt; long time; as the average process VMA count has increased and and</span>
<span class="quote">&gt; devices become more efficiency-conscious, PSS-collection inefficiency</span>
<span class="quote">&gt; has started to matter more. IMHO, it&#39;d be a lot safer to optimize the</span>
<span class="quote">&gt; existing PSS-collection model, which has been fine-tuned over the years,</span>
<span class="quote">&gt; instead of changing the memory tracking approach entirely to work around</span>
<span class="quote">&gt; smaps-generation inefficiency.</span>

This is really vague. Please be more specific.
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=26032">Sonny Rao</a> - Aug. 10, 2017, 6:56 p.m.</div>
<pre class="content">
On Thu, Aug 10, 2017 at 3:58 AM, Michal Hocko &lt;mhocko@kernel.org&gt; wrote:
<span class="quote">&gt; On Thu 10-08-17 03:23:23, Daniel Colascione wrote:</span>
<span class="quote">&gt;&gt; Thanks for taking a look at the patch!</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; On Thu, Aug 10 2017, Michal Hocko wrote:</span>
<span class="quote">&gt;&gt; &gt; [CC linux-api - the patch was posted here</span>
<span class="quote">&gt;&gt; &gt; http://lkml.kernel.org/r/20170810001557.147285-1-dancol@google.com]</span>
<span class="quote">&gt;&gt; &gt;</span>
<span class="quote">&gt;&gt; &gt; On Thu 10-08-17 13:38:31, Minchan Kim wrote:</span>
<span class="quote">&gt;&gt; &gt;&gt; On Wed, Aug 09, 2017 at 05:15:57PM -0700, Daniel Colascione wrote:</span>
<span class="quote">&gt;&gt; &gt;&gt; &gt; /proc/pid/smaps_rollup is a new proc file that improves the</span>
<span class="quote">&gt;&gt; &gt;&gt; &gt; performance of user programs that determine aggregate memory</span>
<span class="quote">&gt;&gt; &gt;&gt; &gt; statistics (e.g., total PSS) of a process.</span>
<span class="quote">&gt;&gt; &gt;&gt; &gt;</span>
<span class="quote">&gt;&gt; &gt;&gt; &gt; Android regularly &quot;samples&quot; the memory usage of various processes in</span>
<span class="quote">&gt;&gt; &gt;&gt; &gt; order to balance its memory pool sizes. This sampling process involves</span>
<span class="quote">&gt;&gt; &gt;&gt; &gt; opening /proc/pid/smaps and summing certain fields. For very large</span>
<span class="quote">&gt;&gt; &gt;&gt; &gt; processes, sampling memory use this way can take several hundred</span>
<span class="quote">&gt;&gt; &gt;&gt; &gt; milliseconds, due mostly to the overhead of the seq_printf calls in</span>
<span class="quote">&gt;&gt; &gt;&gt; &gt; task_mmu.c.</span>
<span class="quote">&gt;&gt; &gt;</span>
<span class="quote">&gt;&gt; &gt; Have you tried to reduce that overhead? E.g. by replacing seq_printf by</span>
<span class="quote">&gt;&gt; &gt; something more simple</span>
<span class="quote">&gt;&gt; &gt; http://lkml.kernel.org/r/20160817130320.GC20703@dhcp22.suse.cz?</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; I haven&#39;t tried that yet, but if I&#39;m reading that thread correctly, it</span>
<span class="quote">&gt;&gt; looks like using more efficient printing primitives gives us a 7%</span>
<span class="quote">&gt;&gt; speedup. The smaps_rollup patch gives us a much bigger speedup while</span>
<span class="quote">&gt;&gt; reusing almost all the smaps code, so it seems easier and simpler than a</span>
<span class="quote">&gt;&gt; bunch of incremental improvements to smaps. And even an efficient smaps</span>
<span class="quote">&gt;&gt; would have to push 2MB through seq_file for the 3000-VMA process case.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; The thing is that more users would benefit from a more efficient</span>
<span class="quote">&gt; /proc/pid/smaps call. Maybe we can use some caching tricks etc...  We</span>
<span class="quote">&gt; should make sure that existing options should be attempted before a new</span>
<span class="quote">&gt; user visible interface is added. It is kind of sad that the real work</span>
<span class="quote">&gt; (pte walk) is less expensive than formating the output and copying it to</span>
<span class="quote">&gt; the userspace...</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;&gt; &gt; How often you you need to read this information?</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; It varies depending on how often processes change state.  We sample a</span>
<span class="quote">&gt;&gt; short time (tens of seconds) after processes change state (e.g., enters</span>
<span class="quote">&gt;&gt; foreground) and every few minutes thereafter. We&#39;re particularly</span>
<span class="quote">&gt;&gt; concerned from an energy perspective about needlessly burning CPU on</span>
<span class="quote">&gt;&gt; background samples.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; Please make sure this is documented in the patch along with some numbers</span>
<span class="quote">&gt; ideally.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; [...]</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;&gt; &gt;&gt; FYI, there was trial but got failed at that time so in this time,</span>
<span class="quote">&gt;&gt; &gt;&gt; https://marc.info/?l=linux-kernel&amp;m=147310650003277&amp;w=2</span>
<span class="quote">&gt;&gt; &gt;&gt; http://www.mail-archive.com/linux-kernel@vger.kernel.org/msg1229163.html</span>
<span class="quote">&gt;&gt; &gt;</span>
<span class="quote">&gt;&gt; &gt; Yes I really disliked the previous attempt and this one is not all that</span>
<span class="quote">&gt;&gt; &gt; better. The primary unanswered question back then was a relevant</span>
<span class="quote">&gt;&gt; &gt; usecase. Back then it was argued [1] that PSS was useful for userspace</span>
<span class="quote">&gt;&gt; &gt; OOM handling but arguments were rather dubious. Follow up questions [2]</span>
<span class="quote">&gt;&gt; &gt; shown that the useage of PSS was very workload specific. Minchan has</span>
<span class="quote">&gt;&gt; &gt; noted some usecase as well but not very specific either.</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; Anyway, I see what you mean about PSS being iffy for user-space OOM</span>
<span class="quote">&gt;&gt; processing (because PSS doesn&#39;t tell you how much memory you get back in</span>
<span class="quote">&gt;&gt; exchange for killing a given process at a particular moment). We&#39;re not</span>
<span class="quote">&gt;&gt; using it like that.</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; Instead, we&#39;re using the PSS samples we collect asynchronously for</span>
<span class="quote">&gt;&gt; system-management tasks like fine-tuning oom_adj_score, memory use</span>
<span class="quote">&gt;&gt; tracking for debugging, application-level memory-use attribution, and</span>
<span class="quote">&gt;&gt; deciding whether we want to kill large processes during system idle</span>
<span class="quote">&gt;&gt; maintenance windows. Android has been using PSS for these purposes for a</span>
<span class="quote">&gt;&gt; long time; as the average process VMA count has increased and and</span>
<span class="quote">&gt;&gt; devices become more efficiency-conscious, PSS-collection inefficiency</span>
<span class="quote">&gt;&gt; has started to matter more. IMHO, it&#39;d be a lot safer to optimize the</span>
<span class="quote">&gt;&gt; existing PSS-collection model, which has been fine-tuned over the years,</span>
<span class="quote">&gt;&gt; instead of changing the memory tracking approach entirely to work around</span>
<span class="quote">&gt;&gt; smaps-generation inefficiency.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; This is really vague. Please be more specific.</span>

I actually think this is really similar to the Chrome OS use case --
we need to do proper accounting of memory from user space, and we need
something more accurate than what we have now (usually RSS) to figure
it out.  I&#39;m not sure what is vague about that statement?

PSS is not perfect but in closed systems where we have some knowledge
about what is being shared amongst process, PSS is much better than
RSS and readily available.  So, I disagree that this is a dubious
usage -- if there&#39;s a better metric for making this kind of decision,
please share it.

Also I realized there&#39;s another argument for presenting this
information outside of smaps which is that we expose far less
information about a process and it&#39;s address space via something like
this, so it&#39;s much better for isolation to have a separate file with
different permissions.  Right now the process in charge of accounting
for memory usage also gains knowledge about each process&#39;s address
space which is unnecessary.

IMHO, the fact that multiple folks have independently asked for this
seems like an argument that something like this is needed.
<span class="quote">

&gt; --</span>
<span class="quote">&gt; Michal Hocko</span>
<span class="quote">&gt; SUSE Labs</span>
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=173077">Tim Murray</a> - Aug. 10, 2017, 7:17 p.m.</div>
<pre class="content">
I&#39;ve looked into this a fair bit on the Android side, so I can provide
some context. There are two main reasons why Android gathers PSS
information:

1. Android devices can show the user the amount of memory used per
application via the settings app. This is a less important use case.
2. We log PSS to help identify leaks in applications. We have found an
enormous number of bugs (in the Android platform, in Google&#39;s own
apps, and in third-party applications) using this data.

To do this, system_server (the main process in Android userspace) will
sample the PSS of a process three seconds after it changes state (for
example, app is launched and becomes the foreground application) and
about every ten minutes after that. The net result is that PSS
collection is regularly running on at least one process in the system
(usually a few times a minute while the screen is on, less when screen
is off due to suspend). PSS of a process is an incredibly useful stat
to track, and we aren&#39;t going to get rid of it. We&#39;ve looked at some
very hacky approaches using RSS (&quot;take the RSS of the target process,
subtract the RSS of the zygote process that is the parent of all
Android apps&quot;) to reduce the accounting time, but it regularly
overestimated the memory used by 20+ percent. Accordingly, I don&#39;t
think that there&#39;s a good alternative to using PSS.

We started looking into PSS collection performance after we noticed
random frequency spikes while a phone&#39;s screen was off; occasionally,
one of the CPU clusters would ramp to a high frequency because there
was 200-300ms of constant CPU work from a single thread in the main
Android userspace process. The work causing the spike (which is
reasonable governor behavior given the amount of CPU time needed) was
always PSS collection. As a result, Android is burning more power than
we should be on PSS collection.

The other issue (and why I&#39;m less sure about improving smaps as a
long-term solution) is that the number of VMAs per process has
increased significantly from release to release. After trying to
figure out why we were seeing these 200-300ms PSS collection times on
Android O but had not noticed it in previous versions, we found that
the number of VMAs in the main system process increased by 50% from
Android N to Android O (from ~1800 to ~2700) and varying increases in
every userspace process. Android M to N also had an increase in the
number of VMAs, although not as much. I&#39;m not sure why this is
increasing so much over time, but thinking about ASLR and ways to make
ASLR better, I expect that this will continue to increase going
forward. I would not be surprised if we hit 5000 VMAs on the main
Android process (system_server) by 2020.

If we assume that the number of VMAs is going to increase over time,
then doing anything we can do to reduce the overhead of each VMA
during PSS collection seems like the right way to go, and that means
outputting an aggregate statistic (to avoid whatever overhead there is
per line in writing smaps and in reading each line from userspace).

Also, Dan sent me some numbers from his benchmark measuring PSS on
system_server (the big Android process) using smaps vs smaps_rollup:

using smaps:
iterations:1000 pid:1163 pss:220023808
 0m29.46s real 0m08.28s user 0m20.98s system

using smaps_rollup:
iterations:1000 pid:1163 pss:220702720
 0m04.39s real 0m00.03s user 0m04.31s system

On Thu, Aug 10, 2017 at 11:56 AM, Sonny Rao &lt;sonnyrao@chromium.org&gt; wrote:
<span class="quote">&gt; On Thu, Aug 10, 2017 at 3:58 AM, Michal Hocko &lt;mhocko@kernel.org&gt; wrote:</span>
<span class="quote">&gt;&gt; On Thu 10-08-17 03:23:23, Daniel Colascione wrote:</span>
<span class="quote">&gt;&gt;&gt; Thanks for taking a look at the patch!</span>
<span class="quote">&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt; On Thu, Aug 10 2017, Michal Hocko wrote:</span>
<span class="quote">&gt;&gt;&gt; &gt; [CC linux-api - the patch was posted here</span>
<span class="quote">&gt;&gt;&gt; &gt; http://lkml.kernel.org/r/20170810001557.147285-1-dancol@google.com]</span>
<span class="quote">&gt;&gt;&gt; &gt;</span>
<span class="quote">&gt;&gt;&gt; &gt; On Thu 10-08-17 13:38:31, Minchan Kim wrote:</span>
<span class="quote">&gt;&gt;&gt; &gt;&gt; On Wed, Aug 09, 2017 at 05:15:57PM -0700, Daniel Colascione wrote:</span>
<span class="quote">&gt;&gt;&gt; &gt;&gt; &gt; /proc/pid/smaps_rollup is a new proc file that improves the</span>
<span class="quote">&gt;&gt;&gt; &gt;&gt; &gt; performance of user programs that determine aggregate memory</span>
<span class="quote">&gt;&gt;&gt; &gt;&gt; &gt; statistics (e.g., total PSS) of a process.</span>
<span class="quote">&gt;&gt;&gt; &gt;&gt; &gt;</span>
<span class="quote">&gt;&gt;&gt; &gt;&gt; &gt; Android regularly &quot;samples&quot; the memory usage of various processes in</span>
<span class="quote">&gt;&gt;&gt; &gt;&gt; &gt; order to balance its memory pool sizes. This sampling process involves</span>
<span class="quote">&gt;&gt;&gt; &gt;&gt; &gt; opening /proc/pid/smaps and summing certain fields. For very large</span>
<span class="quote">&gt;&gt;&gt; &gt;&gt; &gt; processes, sampling memory use this way can take several hundred</span>
<span class="quote">&gt;&gt;&gt; &gt;&gt; &gt; milliseconds, due mostly to the overhead of the seq_printf calls in</span>
<span class="quote">&gt;&gt;&gt; &gt;&gt; &gt; task_mmu.c.</span>
<span class="quote">&gt;&gt;&gt; &gt;</span>
<span class="quote">&gt;&gt;&gt; &gt; Have you tried to reduce that overhead? E.g. by replacing seq_printf by</span>
<span class="quote">&gt;&gt;&gt; &gt; something more simple</span>
<span class="quote">&gt;&gt;&gt; &gt; http://lkml.kernel.org/r/20160817130320.GC20703@dhcp22.suse.cz?</span>
<span class="quote">&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt; I haven&#39;t tried that yet, but if I&#39;m reading that thread correctly, it</span>
<span class="quote">&gt;&gt;&gt; looks like using more efficient printing primitives gives us a 7%</span>
<span class="quote">&gt;&gt;&gt; speedup. The smaps_rollup patch gives us a much bigger speedup while</span>
<span class="quote">&gt;&gt;&gt; reusing almost all the smaps code, so it seems easier and simpler than a</span>
<span class="quote">&gt;&gt;&gt; bunch of incremental improvements to smaps. And even an efficient smaps</span>
<span class="quote">&gt;&gt;&gt; would have to push 2MB through seq_file for the 3000-VMA process case.</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; The thing is that more users would benefit from a more efficient</span>
<span class="quote">&gt;&gt; /proc/pid/smaps call. Maybe we can use some caching tricks etc...  We</span>
<span class="quote">&gt;&gt; should make sure that existing options should be attempted before a new</span>
<span class="quote">&gt;&gt; user visible interface is added. It is kind of sad that the real work</span>
<span class="quote">&gt;&gt; (pte walk) is less expensive than formating the output and copying it to</span>
<span class="quote">&gt;&gt; the userspace...</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt; &gt; How often you you need to read this information?</span>
<span class="quote">&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt; It varies depending on how often processes change state.  We sample a</span>
<span class="quote">&gt;&gt;&gt; short time (tens of seconds) after processes change state (e.g., enters</span>
<span class="quote">&gt;&gt;&gt; foreground) and every few minutes thereafter. We&#39;re particularly</span>
<span class="quote">&gt;&gt;&gt; concerned from an energy perspective about needlessly burning CPU on</span>
<span class="quote">&gt;&gt;&gt; background samples.</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; Please make sure this is documented in the patch along with some numbers</span>
<span class="quote">&gt;&gt; ideally.</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; [...]</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt; &gt;&gt; FYI, there was trial but got failed at that time so in this time,</span>
<span class="quote">&gt;&gt;&gt; &gt;&gt; https://marc.info/?l=linux-kernel&amp;m=147310650003277&amp;w=2</span>
<span class="quote">&gt;&gt;&gt; &gt;&gt; http://www.mail-archive.com/linux-kernel@vger.kernel.org/msg1229163.html</span>
<span class="quote">&gt;&gt;&gt; &gt;</span>
<span class="quote">&gt;&gt;&gt; &gt; Yes I really disliked the previous attempt and this one is not all that</span>
<span class="quote">&gt;&gt;&gt; &gt; better. The primary unanswered question back then was a relevant</span>
<span class="quote">&gt;&gt;&gt; &gt; usecase. Back then it was argued [1] that PSS was useful for userspace</span>
<span class="quote">&gt;&gt;&gt; &gt; OOM handling but arguments were rather dubious. Follow up questions [2]</span>
<span class="quote">&gt;&gt;&gt; &gt; shown that the useage of PSS was very workload specific. Minchan has</span>
<span class="quote">&gt;&gt;&gt; &gt; noted some usecase as well but not very specific either.</span>
<span class="quote">&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt; Anyway, I see what you mean about PSS being iffy for user-space OOM</span>
<span class="quote">&gt;&gt;&gt; processing (because PSS doesn&#39;t tell you how much memory you get back in</span>
<span class="quote">&gt;&gt;&gt; exchange for killing a given process at a particular moment). We&#39;re not</span>
<span class="quote">&gt;&gt;&gt; using it like that.</span>
<span class="quote">&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt; Instead, we&#39;re using the PSS samples we collect asynchronously for</span>
<span class="quote">&gt;&gt;&gt; system-management tasks like fine-tuning oom_adj_score, memory use</span>
<span class="quote">&gt;&gt;&gt; tracking for debugging, application-level memory-use attribution, and</span>
<span class="quote">&gt;&gt;&gt; deciding whether we want to kill large processes during system idle</span>
<span class="quote">&gt;&gt;&gt; maintenance windows. Android has been using PSS for these purposes for a</span>
<span class="quote">&gt;&gt;&gt; long time; as the average process VMA count has increased and and</span>
<span class="quote">&gt;&gt;&gt; devices become more efficiency-conscious, PSS-collection inefficiency</span>
<span class="quote">&gt;&gt;&gt; has started to matter more. IMHO, it&#39;d be a lot safer to optimize the</span>
<span class="quote">&gt;&gt;&gt; existing PSS-collection model, which has been fine-tuned over the years,</span>
<span class="quote">&gt;&gt;&gt; instead of changing the memory tracking approach entirely to work around</span>
<span class="quote">&gt;&gt;&gt; smaps-generation inefficiency.</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; This is really vague. Please be more specific.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; I actually think this is really similar to the Chrome OS use case --</span>
<span class="quote">&gt; we need to do proper accounting of memory from user space, and we need</span>
<span class="quote">&gt; something more accurate than what we have now (usually RSS) to figure</span>
<span class="quote">&gt; it out.  I&#39;m not sure what is vague about that statement?</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; PSS is not perfect but in closed systems where we have some knowledge</span>
<span class="quote">&gt; about what is being shared amongst process, PSS is much better than</span>
<span class="quote">&gt; RSS and readily available.  So, I disagree that this is a dubious</span>
<span class="quote">&gt; usage -- if there&#39;s a better metric for making this kind of decision,</span>
<span class="quote">&gt; please share it.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; Also I realized there&#39;s another argument for presenting this</span>
<span class="quote">&gt; information outside of smaps which is that we expose far less</span>
<span class="quote">&gt; information about a process and it&#39;s address space via something like</span>
<span class="quote">&gt; this, so it&#39;s much better for isolation to have a separate file with</span>
<span class="quote">&gt; different permissions.  Right now the process in charge of accounting</span>
<span class="quote">&gt; for memory usage also gains knowledge about each process&#39;s address</span>
<span class="quote">&gt; space which is unnecessary.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; IMHO, the fact that multiple folks have independently asked for this</span>
<span class="quote">&gt; seems like an argument that something like this is needed.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;&gt; --</span>
<span class="quote">&gt;&gt; Michal Hocko</span>
<span class="quote">&gt;&gt; SUSE Labs</span>
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=137061">Michal Hocko</a> - Aug. 24, 2017, 8:55 a.m.</div>
<pre class="content">
Sorry for a late reply

On Thu 10-08-17 12:17:07, Tim Murray wrote:
<span class="quote">&gt; I&#39;ve looked into this a fair bit on the Android side, so I can provide</span>
<span class="quote">&gt; some context. There are two main reasons why Android gathers PSS</span>
<span class="quote">&gt; information:</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; 1. Android devices can show the user the amount of memory used per</span>
<span class="quote">&gt; application via the settings app. This is a less important use case.</span>

yes
<span class="quote">
&gt; 2. We log PSS to help identify leaks in applications. We have found an</span>
<span class="quote">&gt; enormous number of bugs (in the Android platform, in Google&#39;s own</span>
<span class="quote">&gt; apps, and in third-party applications) using this data.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; To do this, system_server (the main process in Android userspace) will</span>
<span class="quote">&gt; sample the PSS of a process three seconds after it changes state (for</span>
<span class="quote">&gt; example, app is launched and becomes the foreground application) and</span>
<span class="quote">&gt; about every ten minutes after that. The net result is that PSS</span>
<span class="quote">&gt; collection is regularly running on at least one process in the system</span>
<span class="quote">&gt; (usually a few times a minute while the screen is on, less when screen</span>
<span class="quote">&gt; is off due to suspend). PSS of a process is an incredibly useful stat</span>
<span class="quote">&gt; to track, and we aren&#39;t going to get rid of it. We&#39;ve looked at some</span>
<span class="quote">&gt; very hacky approaches using RSS (&quot;take the RSS of the target process,</span>
<span class="quote">&gt; subtract the RSS of the zygote process that is the parent of all</span>
<span class="quote">&gt; Android apps&quot;) to reduce the accounting time, but it regularly</span>
<span class="quote">&gt; overestimated the memory used by 20+ percent. Accordingly, I don&#39;t</span>
<span class="quote">&gt; think that there&#39;s a good alternative to using PSS.</span>

Even if the RSS overestimates this shouldn&#39;t hide a memory leak, no?
<span class="quote">
&gt; We started looking into PSS collection performance after we noticed</span>
<span class="quote">&gt; random frequency spikes while a phone&#39;s screen was off; occasionally,</span>
<span class="quote">&gt; one of the CPU clusters would ramp to a high frequency because there</span>
<span class="quote">&gt; was 200-300ms of constant CPU work from a single thread in the main</span>
<span class="quote">&gt; Android userspace process. The work causing the spike (which is</span>
<span class="quote">&gt; reasonable governor behavior given the amount of CPU time needed) was</span>
<span class="quote">&gt; always PSS collection. As a result, Android is burning more power than</span>
<span class="quote">&gt; we should be on PSS collection.</span>

Yes, this really sucks but we are revolving around the same point. It
really sucks that we burn so much time just copying the output to the
userspace when the real stuff (vma walk and pte walk) has to be done
anyway. AFAIR I could reduce the overhead by using more appropriate
seq_* functions but maybe we can do even better.
<span class="quote">
&gt; The other issue (and why I&#39;m less sure about improving smaps as a</span>
<span class="quote">&gt; long-term solution) is that the number of VMAs per process has</span>
<span class="quote">&gt; increased significantly from release to release. After trying to</span>
<span class="quote">&gt; figure out why we were seeing these 200-300ms PSS collection times on</span>
<span class="quote">&gt; Android O but had not noticed it in previous versions, we found that</span>
<span class="quote">&gt; the number of VMAs in the main system process increased by 50% from</span>
<span class="quote">&gt; Android N to Android O (from ~1800 to ~2700) and varying increases in</span>
<span class="quote">&gt; every userspace process. Android M to N also had an increase in the</span>
<span class="quote">&gt; number of VMAs, although not as much. I&#39;m not sure why this is</span>
<span class="quote">&gt; increasing so much over time, but thinking about ASLR and ways to make</span>
<span class="quote">&gt; ASLR better, I expect that this will continue to increase going</span>
<span class="quote">&gt; forward. I would not be surprised if we hit 5000 VMAs on the main</span>
<span class="quote">&gt; Android process (system_server) by 2020.</span>

The thing is, however, that the larger amount of VMAs will also mean
more work on the kernel side. The data collection has to be done anyway.
<span class="quote"> 
&gt; If we assume that the number of VMAs is going to increase over time,</span>
<span class="quote">&gt; then doing anything we can do to reduce the overhead of each VMA</span>
<span class="quote">&gt; during PSS collection seems like the right way to go, and that means</span>
<span class="quote">&gt; outputting an aggregate statistic (to avoid whatever overhead there is</span>
<span class="quote">&gt; per line in writing smaps and in reading each line from userspace).</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Also, Dan sent me some numbers from his benchmark measuring PSS on</span>
<span class="quote">&gt; system_server (the big Android process) using smaps vs smaps_rollup:</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; using smaps:</span>
<span class="quote">&gt; iterations:1000 pid:1163 pss:220023808</span>
<span class="quote">&gt;  0m29.46s real 0m08.28s user 0m20.98s system</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; using smaps_rollup:</span>
<span class="quote">&gt; iterations:1000 pid:1163 pss:220702720</span>
<span class="quote">&gt;  0m04.39s real 0m00.03s user 0m04.31s system</span>

I would assume we would do all we can to reduce this kernel-&gt;user
overhead first before considering a new user visible file. I haven&#39;t
seen any attempts except from the low hanging fruid I have tried.
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=41">Andrew Morton</a> - Aug. 25, 2017, 9:16 p.m.</div>
<pre class="content">
On Thu, 24 Aug 2017 10:55:53 +0200 Michal Hocko &lt;mhocko@kernel.org&gt; wrote:
<span class="quote">
&gt; &gt; If we assume that the number of VMAs is going to increase over time,</span>
<span class="quote">&gt; &gt; then doing anything we can do to reduce the overhead of each VMA</span>
<span class="quote">&gt; &gt; during PSS collection seems like the right way to go, and that means</span>
<span class="quote">&gt; &gt; outputting an aggregate statistic (to avoid whatever overhead there is</span>
<span class="quote">&gt; &gt; per line in writing smaps and in reading each line from userspace).</span>
<span class="quote">&gt; &gt; </span>
<span class="quote">&gt; &gt; Also, Dan sent me some numbers from his benchmark measuring PSS on</span>
<span class="quote">&gt; &gt; system_server (the big Android process) using smaps vs smaps_rollup:</span>
<span class="quote">&gt; &gt; </span>
<span class="quote">&gt; &gt; using smaps:</span>
<span class="quote">&gt; &gt; iterations:1000 pid:1163 pss:220023808</span>
<span class="quote">&gt; &gt;  0m29.46s real 0m08.28s user 0m20.98s system</span>
<span class="quote">&gt; &gt; </span>
<span class="quote">&gt; &gt; using smaps_rollup:</span>
<span class="quote">&gt; &gt; iterations:1000 pid:1163 pss:220702720</span>
<span class="quote">&gt; &gt;  0m04.39s real 0m00.03s user 0m04.31s system</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; I would assume we would do all we can to reduce this kernel-&gt;user</span>
<span class="quote">&gt; overhead first before considering a new user visible file. I haven&#39;t</span>
<span class="quote">&gt; seen any attempts except from the low hanging fruid I have tried.</span>

It&#39;s hard to believe that we&#39;ll get anything like a 5x speedup via
optimization of the existing code?
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=137061">Michal Hocko</a> - Aug. 28, 2017, 11:30 a.m.</div>
<pre class="content">
On Fri 25-08-17 14:16:37, Andrew Morton wrote:
<span class="quote">&gt; On Thu, 24 Aug 2017 10:55:53 +0200 Michal Hocko &lt;mhocko@kernel.org&gt; wrote:</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; &gt; &gt; If we assume that the number of VMAs is going to increase over time,</span>
<span class="quote">&gt; &gt; &gt; then doing anything we can do to reduce the overhead of each VMA</span>
<span class="quote">&gt; &gt; &gt; during PSS collection seems like the right way to go, and that means</span>
<span class="quote">&gt; &gt; &gt; outputting an aggregate statistic (to avoid whatever overhead there is</span>
<span class="quote">&gt; &gt; &gt; per line in writing smaps and in reading each line from userspace).</span>
<span class="quote">&gt; &gt; &gt; </span>
<span class="quote">&gt; &gt; &gt; Also, Dan sent me some numbers from his benchmark measuring PSS on</span>
<span class="quote">&gt; &gt; &gt; system_server (the big Android process) using smaps vs smaps_rollup:</span>
<span class="quote">&gt; &gt; &gt; </span>
<span class="quote">&gt; &gt; &gt; using smaps:</span>
<span class="quote">&gt; &gt; &gt; iterations:1000 pid:1163 pss:220023808</span>
<span class="quote">&gt; &gt; &gt;  0m29.46s real 0m08.28s user 0m20.98s system</span>
<span class="quote">&gt; &gt; &gt; </span>
<span class="quote">&gt; &gt; &gt; using smaps_rollup:</span>
<span class="quote">&gt; &gt; &gt; iterations:1000 pid:1163 pss:220702720</span>
<span class="quote">&gt; &gt; &gt;  0m04.39s real 0m00.03s user 0m04.31s system</span>
<span class="quote">&gt; &gt; </span>
<span class="quote">&gt; &gt; I would assume we would do all we can to reduce this kernel-&gt;user</span>
<span class="quote">&gt; &gt; overhead first before considering a new user visible file. I haven&#39;t</span>
<span class="quote">&gt; &gt; seen any attempts except from the low hanging fruid I have tried.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; It&#39;s hard to believe that we&#39;ll get anything like a 5x speedup via</span>
<span class="quote">&gt; optimization of the existing code?</span>

Maybe we will not get that much of a boost but having misleading numbers
really quick is not something we should aim for. Just try to think what
the cumulative numbers actually mean. How can you even consider
cumulative PSS when you have no idea about mappings that were
considered?
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/Documentation/ABI/testing/procfs-smaps_rollup b/Documentation/ABI/testing/procfs-smaps_rollup</span>
new file mode 100644
<span class="p_header">index 000000000000..fd5a3699edf1</span>
<span class="p_header">--- /dev/null</span>
<span class="p_header">+++ b/Documentation/ABI/testing/procfs-smaps_rollup</span>
<span class="p_chunk">@@ -0,0 +1,34 @@</span> <span class="p_context"></span>
<span class="p_add">+What:		/proc/pid/smaps_Rollup</span>
<span class="p_add">+Date:		August 2017</span>
<span class="p_add">+Contact:	Daniel Colascione &lt;dancol@google.com&gt;</span>
<span class="p_add">+Description:</span>
<span class="p_add">+		This file provides pre-summed memory information for a</span>
<span class="p_add">+		process.  The format is identical to /proc/pid/smaps,</span>
<span class="p_add">+		except instead of an entry for each VMA in a process,</span>
<span class="p_add">+		smaps_rollup has a single entry (tagged &quot;[rollup]&quot;)</span>
<span class="p_add">+		for which each field is the sum of the corresponding</span>
<span class="p_add">+		fields from all the maps in /proc/pid/smaps.</span>
<span class="p_add">+		For more details, see the procfs man page.</span>
<span class="p_add">+</span>
<span class="p_add">+		Typical output looks like this:</span>
<span class="p_add">+</span>
<span class="p_add">+		00100000-ff709000 ---p 00000000 00:00 0		 [rollup]</span>
<span class="p_add">+		Rss:		     884 kB</span>
<span class="p_add">+		Pss:		     385 kB</span>
<span class="p_add">+		Shared_Clean:	     696 kB</span>
<span class="p_add">+		Shared_Dirty:	       0 kB</span>
<span class="p_add">+		Private_Clean:	     120 kB</span>
<span class="p_add">+		Private_Dirty:	      68 kB</span>
<span class="p_add">+		Referenced:	     884 kB</span>
<span class="p_add">+		Anonymous:	      68 kB</span>
<span class="p_add">+		LazyFree:	       0 kB</span>
<span class="p_add">+		AnonHugePages:	       0 kB</span>
<span class="p_add">+		ShmemPmdMapped:	       0 kB</span>
<span class="p_add">+		Shared_Hugetlb:	       0 kB</span>
<span class="p_add">+		Private_Hugetlb:       0 kB</span>
<span class="p_add">+		Swap:		       0 kB</span>
<span class="p_add">+		SwapPss:	       0 kB</span>
<span class="p_add">+		Locked:		     385 kB</span>
<span class="p_add">+</span>
<span class="p_add">+</span>
<span class="p_add">+		</span>
<span class="p_header">diff --git a/fs/proc/base.c b/fs/proc/base.c</span>
<span class="p_header">index 719c2e943ea1..a9587b9cace5 100644</span>
<span class="p_header">--- a/fs/proc/base.c</span>
<span class="p_header">+++ b/fs/proc/base.c</span>
<span class="p_chunk">@@ -2930,6 +2930,7 @@</span> <span class="p_context"> static const struct pid_entry tgid_base_stuff[] = {</span>
 #ifdef CONFIG_PROC_PAGE_MONITOR
 	REG(&quot;clear_refs&quot;, S_IWUSR, proc_clear_refs_operations),
 	REG(&quot;smaps&quot;,      S_IRUGO, proc_pid_smaps_operations),
<span class="p_add">+	REG(&quot;smaps_rollup&quot;, S_IRUGO, proc_pid_smaps_rollup_operations),</span>
 	REG(&quot;pagemap&quot;,    S_IRUSR, proc_pagemap_operations),
 #endif
 #ifdef CONFIG_SECURITY
<span class="p_chunk">@@ -3323,6 +3324,7 @@</span> <span class="p_context"> static const struct pid_entry tid_base_stuff[] = {</span>
 #ifdef CONFIG_PROC_PAGE_MONITOR
 	REG(&quot;clear_refs&quot;, S_IWUSR, proc_clear_refs_operations),
 	REG(&quot;smaps&quot;,     S_IRUGO, proc_tid_smaps_operations),
<span class="p_add">+	REG(&quot;smaps_rollup&quot;, S_IRUGO, proc_pid_smaps_rollup_operations),</span>
 	REG(&quot;pagemap&quot;,    S_IRUSR, proc_pagemap_operations),
 #endif
 #ifdef CONFIG_SECURITY
<span class="p_header">diff --git a/fs/proc/internal.h b/fs/proc/internal.h</span>
<span class="p_header">index aa2b89071630..2cbfcd32e884 100644</span>
<span class="p_header">--- a/fs/proc/internal.h</span>
<span class="p_header">+++ b/fs/proc/internal.h</span>
<span class="p_chunk">@@ -269,10 +269,12 @@</span> <span class="p_context"> extern int proc_remount(struct super_block *, int *, char *);</span>
 /*
  * task_[no]mmu.c
  */
<span class="p_add">+struct mem_size_stats;</span>
 struct proc_maps_private {
 	struct inode *inode;
 	struct task_struct *task;
 	struct mm_struct *mm;
<span class="p_add">+	struct mem_size_stats *rollup;</span>
 #ifdef CONFIG_MMU
 	struct vm_area_struct *tail_vma;
 #endif
<span class="p_chunk">@@ -288,6 +290,7 @@</span> <span class="p_context"> extern const struct file_operations proc_tid_maps_operations;</span>
 extern const struct file_operations proc_pid_numa_maps_operations;
 extern const struct file_operations proc_tid_numa_maps_operations;
 extern const struct file_operations proc_pid_smaps_operations;
<span class="p_add">+extern const struct file_operations proc_pid_smaps_rollup_operations;</span>
 extern const struct file_operations proc_tid_smaps_operations;
 extern const struct file_operations proc_clear_refs_operations;
 extern const struct file_operations proc_pagemap_operations;
<span class="p_header">diff --git a/fs/proc/task_mmu.c b/fs/proc/task_mmu.c</span>
<span class="p_header">index b836fd61ed87..02b55df7291c 100644</span>
<span class="p_header">--- a/fs/proc/task_mmu.c</span>
<span class="p_header">+++ b/fs/proc/task_mmu.c</span>
<span class="p_chunk">@@ -252,6 +252,7 @@</span> <span class="p_context"> static int proc_map_release(struct inode *inode, struct file *file)</span>
 	if (priv-&gt;mm)
 		mmdrop(priv-&gt;mm);
 
<span class="p_add">+	kfree(priv-&gt;rollup);</span>
 	return seq_release_private(inode, file);
 }
 
<span class="p_chunk">@@ -278,6 +279,23 @@</span> <span class="p_context"> static int is_stack(struct proc_maps_private *priv,</span>
 		vma-&gt;vm_end &gt;= vma-&gt;vm_mm-&gt;start_stack;
 }
 
<span class="p_add">+static void show_vma_header_prefix(struct seq_file *m,</span>
<span class="p_add">+				   unsigned long start, unsigned long end,</span>
<span class="p_add">+				   vm_flags_t flags, unsigned long long pgoff,</span>
<span class="p_add">+				   dev_t dev, unsigned long ino)</span>
<span class="p_add">+{</span>
<span class="p_add">+	seq_setwidth(m, 25 + sizeof(void *) * 6 - 1);</span>
<span class="p_add">+	seq_printf(m, &quot;%08lx-%08lx %c%c%c%c %08llx %02x:%02x %lu &quot;,</span>
<span class="p_add">+		   start,</span>
<span class="p_add">+		   end,</span>
<span class="p_add">+		   flags &amp; VM_READ ? &#39;r&#39; : &#39;-&#39;,</span>
<span class="p_add">+		   flags &amp; VM_WRITE ? &#39;w&#39; : &#39;-&#39;,</span>
<span class="p_add">+		   flags &amp; VM_EXEC ? &#39;x&#39; : &#39;-&#39;,</span>
<span class="p_add">+		   flags &amp; VM_MAYSHARE ? &#39;s&#39; : &#39;p&#39;,</span>
<span class="p_add">+		   pgoff,</span>
<span class="p_add">+		   MAJOR(dev), MINOR(dev), ino);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static void
 show_map_vma(struct seq_file *m, struct vm_area_struct *vma, int is_pid)
 {
<span class="p_chunk">@@ -300,17 +318,7 @@</span> <span class="p_context"> show_map_vma(struct seq_file *m, struct vm_area_struct *vma, int is_pid)</span>
 
 	start = vma-&gt;vm_start;
 	end = vma-&gt;vm_end;
<span class="p_del">-</span>
<span class="p_del">-	seq_setwidth(m, 25 + sizeof(void *) * 6 - 1);</span>
<span class="p_del">-	seq_printf(m, &quot;%08lx-%08lx %c%c%c%c %08llx %02x:%02x %lu &quot;,</span>
<span class="p_del">-			start,</span>
<span class="p_del">-			end,</span>
<span class="p_del">-			flags &amp; VM_READ ? &#39;r&#39; : &#39;-&#39;,</span>
<span class="p_del">-			flags &amp; VM_WRITE ? &#39;w&#39; : &#39;-&#39;,</span>
<span class="p_del">-			flags &amp; VM_EXEC ? &#39;x&#39; : &#39;-&#39;,</span>
<span class="p_del">-			flags &amp; VM_MAYSHARE ? &#39;s&#39; : &#39;p&#39;,</span>
<span class="p_del">-			pgoff,</span>
<span class="p_del">-			MAJOR(dev), MINOR(dev), ino);</span>
<span class="p_add">+	show_vma_header_prefix(m, start, end, flags, pgoff, dev, ino);</span>
 
 	/*
 	 * Print the dentry name for named mappings, and a
<span class="p_chunk">@@ -429,6 +437,7 @@</span> <span class="p_context"> const struct file_operations proc_tid_maps_operations = {</span>
 
 #ifdef CONFIG_PROC_PAGE_MONITOR
 struct mem_size_stats {
<span class="p_add">+	bool first;</span>
 	unsigned long resident;
 	unsigned long shared_clean;
 	unsigned long shared_dirty;
<span class="p_chunk">@@ -442,7 +451,9 @@</span> <span class="p_context"> struct mem_size_stats {</span>
 	unsigned long swap;
 	unsigned long shared_hugetlb;
 	unsigned long private_hugetlb;
<span class="p_add">+	unsigned long first_vma_start;</span>
 	u64 pss;
<span class="p_add">+	u64 pss_locked;</span>
 	u64 swap_pss;
 	bool check_shmem_swap;
 };
<span class="p_chunk">@@ -718,18 +729,36 @@</span> <span class="p_context"> void __weak arch_show_smap(struct seq_file *m, struct vm_area_struct *vma)</span>
 
 static int show_smap(struct seq_file *m, void *v, int is_pid)
 {
<span class="p_add">+	struct proc_maps_private *priv = m-&gt;private;</span>
 	struct vm_area_struct *vma = v;
<span class="p_del">-	struct mem_size_stats mss;</span>
<span class="p_add">+	struct mem_size_stats mss_stack;</span>
<span class="p_add">+	struct mem_size_stats *mss;</span>
 	struct mm_walk smaps_walk = {
 		.pmd_entry = smaps_pte_range,
 #ifdef CONFIG_HUGETLB_PAGE
 		.hugetlb_entry = smaps_hugetlb_range,
 #endif
 		.mm = vma-&gt;vm_mm,
<span class="p_del">-		.private = &amp;mss,</span>
 	};
<span class="p_add">+	int ret = 0;</span>
<span class="p_add">+	bool rollup_mode;</span>
<span class="p_add">+	bool last_vma;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (priv-&gt;rollup) {</span>
<span class="p_add">+		rollup_mode = true;</span>
<span class="p_add">+		mss = priv-&gt;rollup;</span>
<span class="p_add">+		if (mss-&gt;first) {</span>
<span class="p_add">+			mss-&gt;first_vma_start = vma-&gt;vm_start;</span>
<span class="p_add">+			mss-&gt;first = false;</span>
<span class="p_add">+		}</span>
<span class="p_add">+		last_vma = !m_next_vma(priv, vma);</span>
<span class="p_add">+	} else {</span>
<span class="p_add">+		rollup_mode = false;</span>
<span class="p_add">+		memset(&amp;mss_stack, 0, sizeof(mss_stack));</span>
<span class="p_add">+		mss = &amp;mss_stack;</span>
<span class="p_add">+	}</span>
 
<span class="p_del">-	memset(&amp;mss, 0, sizeof mss);</span>
<span class="p_add">+	smaps_walk.private = mss;</span>
 
 #ifdef CONFIG_SHMEM
 	if (vma-&gt;vm_file &amp;&amp; shmem_mapping(vma-&gt;vm_file-&gt;f_mapping)) {
<span class="p_chunk">@@ -747,9 +776,9 @@</span> <span class="p_context"> static int show_smap(struct seq_file *m, void *v, int is_pid)</span>
 
 		if (!shmem_swapped || (vma-&gt;vm_flags &amp; VM_SHARED) ||
 					!(vma-&gt;vm_flags &amp; VM_WRITE)) {
<span class="p_del">-			mss.swap = shmem_swapped;</span>
<span class="p_add">+			mss-&gt;swap = shmem_swapped;</span>
 		} else {
<span class="p_del">-			mss.check_shmem_swap = true;</span>
<span class="p_add">+			mss-&gt;check_shmem_swap = true;</span>
 			smaps_walk.pte_hole = smaps_pte_hole;
 		}
 	}
<span class="p_chunk">@@ -757,54 +786,71 @@</span> <span class="p_context"> static int show_smap(struct seq_file *m, void *v, int is_pid)</span>
 
 	/* mmap_sem is held in m_start */
 	walk_page_vma(vma, &amp;smaps_walk);
<span class="p_add">+	if (vma-&gt;vm_flags &amp; VM_LOCKED)</span>
<span class="p_add">+		mss-&gt;pss_locked += mss-&gt;pss;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (!rollup_mode) {</span>
<span class="p_add">+		show_map_vma(m, vma, is_pid);</span>
<span class="p_add">+	} else if (last_vma) {</span>
<span class="p_add">+		show_vma_header_prefix(</span>
<span class="p_add">+			m, mss-&gt;first_vma_start, vma-&gt;vm_end, 0, 0, 0, 0);</span>
<span class="p_add">+		seq_pad(m, &#39; &#39;);</span>
<span class="p_add">+		seq_puts(m, &quot;[rollup]\n&quot;);</span>
<span class="p_add">+	} else {</span>
<span class="p_add">+		ret = SEQ_SKIP;</span>
<span class="p_add">+	}</span>
 
<span class="p_del">-	show_map_vma(m, vma, is_pid);</span>
<span class="p_del">-</span>
<span class="p_del">-	seq_printf(m,</span>
<span class="p_del">-		   &quot;Size:           %8lu kB\n&quot;</span>
<span class="p_del">-		   &quot;Rss:            %8lu kB\n&quot;</span>
<span class="p_del">-		   &quot;Pss:            %8lu kB\n&quot;</span>
<span class="p_del">-		   &quot;Shared_Clean:   %8lu kB\n&quot;</span>
<span class="p_del">-		   &quot;Shared_Dirty:   %8lu kB\n&quot;</span>
<span class="p_del">-		   &quot;Private_Clean:  %8lu kB\n&quot;</span>
<span class="p_del">-		   &quot;Private_Dirty:  %8lu kB\n&quot;</span>
<span class="p_del">-		   &quot;Referenced:     %8lu kB\n&quot;</span>
<span class="p_del">-		   &quot;Anonymous:      %8lu kB\n&quot;</span>
<span class="p_del">-		   &quot;LazyFree:       %8lu kB\n&quot;</span>
<span class="p_del">-		   &quot;AnonHugePages:  %8lu kB\n&quot;</span>
<span class="p_del">-		   &quot;ShmemPmdMapped: %8lu kB\n&quot;</span>
<span class="p_del">-		   &quot;Shared_Hugetlb: %8lu kB\n&quot;</span>
<span class="p_del">-		   &quot;Private_Hugetlb: %7lu kB\n&quot;</span>
<span class="p_del">-		   &quot;Swap:           %8lu kB\n&quot;</span>
<span class="p_del">-		   &quot;SwapPss:        %8lu kB\n&quot;</span>
<span class="p_del">-		   &quot;KernelPageSize: %8lu kB\n&quot;</span>
<span class="p_del">-		   &quot;MMUPageSize:    %8lu kB\n&quot;</span>
<span class="p_del">-		   &quot;Locked:         %8lu kB\n&quot;,</span>
<span class="p_del">-		   (vma-&gt;vm_end - vma-&gt;vm_start) &gt;&gt; 10,</span>
<span class="p_del">-		   mss.resident &gt;&gt; 10,</span>
<span class="p_del">-		   (unsigned long)(mss.pss &gt;&gt; (10 + PSS_SHIFT)),</span>
<span class="p_del">-		   mss.shared_clean  &gt;&gt; 10,</span>
<span class="p_del">-		   mss.shared_dirty  &gt;&gt; 10,</span>
<span class="p_del">-		   mss.private_clean &gt;&gt; 10,</span>
<span class="p_del">-		   mss.private_dirty &gt;&gt; 10,</span>
<span class="p_del">-		   mss.referenced &gt;&gt; 10,</span>
<span class="p_del">-		   mss.anonymous &gt;&gt; 10,</span>
<span class="p_del">-		   mss.lazyfree &gt;&gt; 10,</span>
<span class="p_del">-		   mss.anonymous_thp &gt;&gt; 10,</span>
<span class="p_del">-		   mss.shmem_thp &gt;&gt; 10,</span>
<span class="p_del">-		   mss.shared_hugetlb &gt;&gt; 10,</span>
<span class="p_del">-		   mss.private_hugetlb &gt;&gt; 10,</span>
<span class="p_del">-		   mss.swap &gt;&gt; 10,</span>
<span class="p_del">-		   (unsigned long)(mss.swap_pss &gt;&gt; (10 + PSS_SHIFT)),</span>
<span class="p_del">-		   vma_kernel_pagesize(vma) &gt;&gt; 10,</span>
<span class="p_del">-		   vma_mmu_pagesize(vma) &gt;&gt; 10,</span>
<span class="p_del">-		   (vma-&gt;vm_flags &amp; VM_LOCKED) ?</span>
<span class="p_del">-			(unsigned long)(mss.pss &gt;&gt; (10 + PSS_SHIFT)) : 0);</span>
<span class="p_del">-</span>
<span class="p_del">-	arch_show_smap(m, vma);</span>
<span class="p_del">-	show_smap_vma_flags(m, vma);</span>
<span class="p_add">+	if (!rollup_mode)</span>
<span class="p_add">+		seq_printf(m,</span>
<span class="p_add">+			   &quot;Size:           %8lu kB\n&quot;</span>
<span class="p_add">+			   &quot;KernelPageSize: %8lu kB\n&quot;</span>
<span class="p_add">+			   &quot;MMUPageSize:    %8lu kB\n&quot;,</span>
<span class="p_add">+			   (vma-&gt;vm_end - vma-&gt;vm_start) &gt;&gt; 10,</span>
<span class="p_add">+			   vma_kernel_pagesize(vma) &gt;&gt; 10,</span>
<span class="p_add">+			   vma_mmu_pagesize(vma) &gt;&gt; 10);</span>
<span class="p_add">+</span>
<span class="p_add">+</span>
<span class="p_add">+	if (!rollup_mode || last_vma)</span>
<span class="p_add">+		seq_printf(m,</span>
<span class="p_add">+			   &quot;Rss:            %8lu kB\n&quot;</span>
<span class="p_add">+			   &quot;Pss:            %8lu kB\n&quot;</span>
<span class="p_add">+			   &quot;Shared_Clean:   %8lu kB\n&quot;</span>
<span class="p_add">+			   &quot;Shared_Dirty:   %8lu kB\n&quot;</span>
<span class="p_add">+			   &quot;Private_Clean:  %8lu kB\n&quot;</span>
<span class="p_add">+			   &quot;Private_Dirty:  %8lu kB\n&quot;</span>
<span class="p_add">+			   &quot;Referenced:     %8lu kB\n&quot;</span>
<span class="p_add">+			   &quot;Anonymous:      %8lu kB\n&quot;</span>
<span class="p_add">+			   &quot;LazyFree:       %8lu kB\n&quot;</span>
<span class="p_add">+			   &quot;AnonHugePages:  %8lu kB\n&quot;</span>
<span class="p_add">+			   &quot;ShmemPmdMapped: %8lu kB\n&quot;</span>
<span class="p_add">+			   &quot;Shared_Hugetlb: %8lu kB\n&quot;</span>
<span class="p_add">+			   &quot;Private_Hugetlb: %7lu kB\n&quot;</span>
<span class="p_add">+			   &quot;Swap:           %8lu kB\n&quot;</span>
<span class="p_add">+			   &quot;SwapPss:        %8lu kB\n&quot;</span>
<span class="p_add">+			   &quot;Locked:         %8lu kB\n&quot;,</span>
<span class="p_add">+			   mss-&gt;resident &gt;&gt; 10,</span>
<span class="p_add">+			   (unsigned long)(mss-&gt;pss &gt;&gt; (10 + PSS_SHIFT)),</span>
<span class="p_add">+			   mss-&gt;shared_clean  &gt;&gt; 10,</span>
<span class="p_add">+			   mss-&gt;shared_dirty  &gt;&gt; 10,</span>
<span class="p_add">+			   mss-&gt;private_clean &gt;&gt; 10,</span>
<span class="p_add">+			   mss-&gt;private_dirty &gt;&gt; 10,</span>
<span class="p_add">+			   mss-&gt;referenced &gt;&gt; 10,</span>
<span class="p_add">+			   mss-&gt;anonymous &gt;&gt; 10,</span>
<span class="p_add">+			   mss-&gt;lazyfree &gt;&gt; 10,</span>
<span class="p_add">+			   mss-&gt;anonymous_thp &gt;&gt; 10,</span>
<span class="p_add">+			   mss-&gt;shmem_thp &gt;&gt; 10,</span>
<span class="p_add">+			   mss-&gt;shared_hugetlb &gt;&gt; 10,</span>
<span class="p_add">+			   mss-&gt;private_hugetlb &gt;&gt; 10,</span>
<span class="p_add">+			   mss-&gt;swap &gt;&gt; 10,</span>
<span class="p_add">+			   (unsigned long)(mss-&gt;swap_pss &gt;&gt; (10 + PSS_SHIFT)),</span>
<span class="p_add">+			   (unsigned long)(mss-&gt;pss &gt;&gt; (10 + PSS_SHIFT)));</span>
<span class="p_add">+</span>
<span class="p_add">+	if (!rollup_mode) {</span>
<span class="p_add">+		arch_show_smap(m, vma);</span>
<span class="p_add">+		show_smap_vma_flags(m, vma);</span>
<span class="p_add">+	}</span>
 	m_cache_vma(m, vma);
<span class="p_del">-	return 0;</span>
<span class="p_add">+	return ret;</span>
 }
 
 static int show_pid_smap(struct seq_file *m, void *v)
<span class="p_chunk">@@ -836,6 +882,25 @@</span> <span class="p_context"> static int pid_smaps_open(struct inode *inode, struct file *file)</span>
 	return do_maps_open(inode, file, &amp;proc_pid_smaps_op);
 }
 
<span class="p_add">+static int pid_smaps_rollup_open(struct inode *inode, struct file *file)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct seq_file *seq;</span>
<span class="p_add">+	struct proc_maps_private *priv;</span>
<span class="p_add">+	int ret = do_maps_open(inode, file, &amp;proc_pid_smaps_op);</span>
<span class="p_add">+</span>
<span class="p_add">+	if (ret &lt; 0)</span>
<span class="p_add">+		return ret;</span>
<span class="p_add">+	seq = file-&gt;private_data;</span>
<span class="p_add">+	priv = seq-&gt;private;</span>
<span class="p_add">+	priv-&gt;rollup = kzalloc(sizeof(*priv-&gt;rollup), GFP_KERNEL);</span>
<span class="p_add">+	if (!priv-&gt;rollup) {</span>
<span class="p_add">+		proc_map_release(inode, file);</span>
<span class="p_add">+		return -ENOMEM;</span>
<span class="p_add">+	}</span>
<span class="p_add">+	priv-&gt;rollup-&gt;first = true;</span>
<span class="p_add">+	return 0;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static int tid_smaps_open(struct inode *inode, struct file *file)
 {
 	return do_maps_open(inode, file, &amp;proc_tid_smaps_op);
<span class="p_chunk">@@ -848,6 +913,13 @@</span> <span class="p_context"> const struct file_operations proc_pid_smaps_operations = {</span>
 	.release	= proc_map_release,
 };
 
<span class="p_add">+const struct file_operations proc_pid_smaps_rollup_operations = {</span>
<span class="p_add">+	.open		= pid_smaps_rollup_open,</span>
<span class="p_add">+	.read		= seq_read,</span>
<span class="p_add">+	.llseek		= seq_lseek,</span>
<span class="p_add">+	.release	= proc_map_release,</span>
<span class="p_add">+};</span>
<span class="p_add">+</span>
 const struct file_operations proc_tid_smaps_operations = {
 	.open		= tid_smaps_open,
 	.read		= seq_read,

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



