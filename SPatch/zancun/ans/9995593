
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>[v15,7/7] drm/i915/gvt: Dmabuf support for GVT-g - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    [v15,7/7] drm/i915/gvt: Dmabuf support for GVT-g</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=174253">Tina Zhang</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>Oct. 10, 2017, 9:50 a.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;1507629007-3183-8-git-send-email-tina.zhang@intel.com&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/9995593/mbox/"
   >mbox</a>
|
   <a href="/patch/9995593/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/9995593/">/patch/9995593/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
	[172.30.200.125])
	by pdx-korg-patchwork.web.codeaurora.org (Postfix) with ESMTP id
	2FA4860216 for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Tue, 10 Oct 2017 09:55:58 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 149B127F98
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Tue, 10 Oct 2017 09:55:58 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id 0943D28450; Tue, 10 Oct 2017 09:55:58 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-6.9 required=2.0 tests=BAYES_00,RCVD_IN_DNSWL_HI
	autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 7409727F98
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Tue, 10 Oct 2017 09:55:56 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S932212AbdJJJzz (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Tue, 10 Oct 2017 05:55:55 -0400
Received: from mga05.intel.com ([192.55.52.43]:45399 &quot;EHLO mga05.intel.com&quot;
	rhost-flags-OK-OK-OK-OK) by vger.kernel.org with ESMTP
	id S932101AbdJJJzw (ORCPT &lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Tue, 10 Oct 2017 05:55:52 -0400
Received: from fmsmga005.fm.intel.com ([10.253.24.32])
	by fmsmga105.fm.intel.com with ESMTP; 10 Oct 2017 02:55:51 -0700
X-ExtLoop1: 1
X-IronPort-AV: E=Sophos;i=&quot;5.42,504,1500966000&quot;; d=&quot;scan&#39;208&quot;;a=&quot;160920408&quot;
Received: from tinazhang-linux-1.bj.intel.com ([10.238.158.80])
	by fmsmga005.fm.intel.com with ESMTP; 10 Oct 2017 02:55:48 -0700
From: Tina Zhang &lt;tina.zhang@intel.com&gt;
To: alex.williamson@redhat.com, kraxel@redhat.com,
	chris@chris-wilson.co.uk, zhenyuw@linux.intel.com,
	zhiyuan.lv@intel.com, zhi.a.wang@intel.com, kevin.tian@intel.com,
	daniel@ffwll.ch, kwankhede@nvidia.com
Cc: Tina Zhang &lt;tina.zhang@intel.com&gt;, intel-gfx@lists.freedesktop.org,
	intel-gvt-dev@lists.freedesktop.org, linux-kernel@vger.kernel.org,
	Daniel Vetter &lt;daniel.vetter@ffwll.ch&gt;
Subject: [PATCH v15 7/7] drm/i915/gvt: Dmabuf support for GVT-g
Date: Tue, 10 Oct 2017 17:50:07 +0800
Message-Id: &lt;1507629007-3183-8-git-send-email-tina.zhang@intel.com&gt;
X-Mailer: git-send-email 2.7.4
In-Reply-To: &lt;1507629007-3183-1-git-send-email-tina.zhang@intel.com&gt;
References: &lt;1507629007-3183-1-git-send-email-tina.zhang@intel.com&gt;
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=174253">Tina Zhang</a> - Oct. 10, 2017, 9:50 a.m.</div>
<pre class="content">
This patch introduces a guest&#39;s framebuffer sharing mechanism based on
dma-buf subsystem. With this sharing mechanism, guest&#39;s framebuffer can
be shared between guest VM and host.

v15:
- Add VFIO_DEVICE_GET_GFX_DMABUF ABI. (Gerd)
- Add intel_vgpu_dmabuf_cleanup() to clean up the vGPU&#39;s dmabuf. (Gerd)

v14:
- add PROBE, DMABUF and REGION flags. (Alex)

v12:
- refine the lifecycle of dmabuf.

v9:
- remove dma-buf management. (Alex)
- track the dma-buf create and release in kernel mode. (Gerd) (Daniel)

v8:
- refine the dma-buf ioctl definition.(Alex)
- add a lock to protect the dmabuf list. (Alex)

v7:
- release dma-buf related allocations in dma-buf&#39;s associated release
  function. (Alex)
- refine ioctl interface for querying plane info or create dma-buf.
  (Alex)

v6:
- align the dma-buf life cycle with the vfio device. (Alex)
- add the dma-buf related operations in a separate patch. (Gerd)
- i915 related changes. (Chris)

v5:
- fix bug while checking whether the gem obj is gvt&#39;s dma-buf when user
  change caching mode or domains. Add a helper function to do it.
  (Xiaoguang)
- add definition for the query plane and create dma-buf. (Xiaoguang)

v4:
- fix bug while checking whether the gem obj is gvt&#39;s dma-buf when set
  caching mode or doamins. (Xiaoguang)

v3:
- declare a new flag I915_GEM_OBJECT_IS_GVT_DMABUF in drm_i915_gem_object
  to represent the gem obj for gvt&#39;s dma-buf. The tiling mode, caching
  mode and domains can not be changed for this kind of gem object. (Alex)
- change dma-buf related information to be more generic. So other vendor
  can use the same interface. (Alex)

v2:
- create a management fd for dma-buf operations. (Alex)
- alloc gem object&#39;s backing storage in gem obj&#39;s get_pages() callback.
  (Chris)
<span class="signed-off-by">
Signed-off-by: Tina Zhang &lt;tina.zhang@intel.com&gt;</span>
Cc: Alex Williamson &lt;alex.williamson@redhat.com&gt;
Cc: Chris Wilson &lt;chris@chris-wilson.co.uk&gt;
Cc: Daniel Vetter &lt;daniel.vetter@ffwll.ch&gt;
Cc: Gerd Hoffmann &lt;kraxel@redhat.com&gt;
---
 drivers/gpu/drm/i915/gvt/Makefile      |   2 +-
 drivers/gpu/drm/i915/gvt/dmabuf.c      | 513 +++++++++++++++++++++++++++++++++
 drivers/gpu/drm/i915/gvt/dmabuf.h      |  65 +++++
 drivers/gpu/drm/i915/gvt/gvt.c         |   2 +
 drivers/gpu/drm/i915/gvt/gvt.h         |  11 +
 drivers/gpu/drm/i915/gvt/hypercall.h   |   2 +
 drivers/gpu/drm/i915/gvt/kvmgt.c       |  60 ++++
 drivers/gpu/drm/i915/gvt/mpt.h         |  30 ++
 drivers/gpu/drm/i915/gvt/vgpu.c        |   5 +-
 drivers/gpu/drm/i915/i915_gem_object.h |   2 +
 10 files changed, 690 insertions(+), 2 deletions(-)
 create mode 100644 drivers/gpu/drm/i915/gvt/dmabuf.c
 create mode 100644 drivers/gpu/drm/i915/gvt/dmabuf.h
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/drivers/gpu/drm/i915/gvt/Makefile b/drivers/gpu/drm/i915/gvt/Makefile</span>
<span class="p_header">index 019d596..18f43cb 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/i915/gvt/Makefile</span>
<span class="p_header">+++ b/drivers/gpu/drm/i915/gvt/Makefile</span>
<span class="p_chunk">@@ -2,7 +2,7 @@</span> <span class="p_context"> GVT_DIR := gvt</span>
 GVT_SOURCE := gvt.o aperture_gm.o handlers.o vgpu.o trace_points.o firmware.o \
 	interrupt.o gtt.o cfg_space.o opregion.o mmio.o display.o edid.o \
 	execlist.o scheduler.o sched_policy.o render.o cmd_parser.o \
<span class="p_del">-	fb_decoder.o</span>
<span class="p_add">+	fb_decoder.o dmabuf.o</span>
 
 ccflags-y				+= -I$(src) -I$(src)/$(GVT_DIR)
 i915-y					+= $(addprefix $(GVT_DIR)/, $(GVT_SOURCE))
<span class="p_header">diff --git a/drivers/gpu/drm/i915/gvt/dmabuf.c b/drivers/gpu/drm/i915/gvt/dmabuf.c</span>
new file mode 100644
<span class="p_header">index 0000000..e97b3c7</span>
<span class="p_header">--- /dev/null</span>
<span class="p_header">+++ b/drivers/gpu/drm/i915/gvt/dmabuf.c</span>
<span class="p_chunk">@@ -0,0 +1,513 @@</span> <span class="p_context"></span>
<span class="p_add">+/*</span>
<span class="p_add">+ * Copyright 2017 Intel Corporation. All rights reserved.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * Permission is hereby granted, free of charge, to any person obtaining a</span>
<span class="p_add">+ * copy of this software and associated documentation files (the &quot;Software&quot;),</span>
<span class="p_add">+ * to deal in the Software without restriction, including without limitation</span>
<span class="p_add">+ * the rights to use, copy, modify, merge, publish, distribute, sublicense,</span>
<span class="p_add">+ * and/or sell copies of the Software, and to permit persons to whom the</span>
<span class="p_add">+ * Software is furnished to do so, subject to the following conditions:</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * The above copyright notice and this permission notice (including the next</span>
<span class="p_add">+ * paragraph) shall be included in all copies or substantial portions of the</span>
<span class="p_add">+ * Software.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * THE SOFTWARE IS PROVIDED &quot;AS IS&quot;, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR</span>
<span class="p_add">+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,</span>
<span class="p_add">+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL</span>
<span class="p_add">+ * THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER</span>
<span class="p_add">+ * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING</span>
<span class="p_add">+ * FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER</span>
<span class="p_add">+ * DEALINGS IN THE SOFTWARE.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * Authors:</span>
<span class="p_add">+ *    Zhiyuan Lv &lt;zhiyuan.lv@intel.com&gt;</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * Contributors:</span>
<span class="p_add">+ *    Xiaoguang Chen</span>
<span class="p_add">+ *    Tina Zhang &lt;tina.zhang@intel.com&gt;</span>
<span class="p_add">+ */</span>
<span class="p_add">+</span>
<span class="p_add">+#include &lt;linux/dma-buf.h&gt;</span>
<span class="p_add">+#include &lt;drm/drmP.h&gt;</span>
<span class="p_add">+#include &lt;linux/vfio.h&gt;</span>
<span class="p_add">+</span>
<span class="p_add">+#include &quot;i915_drv.h&quot;</span>
<span class="p_add">+#include &quot;gvt.h&quot;</span>
<span class="p_add">+</span>
<span class="p_add">+#define GEN8_DECODE_PTE(pte) (pte &amp; GENMASK_ULL(63, 12))</span>
<span class="p_add">+</span>
<span class="p_add">+static struct sg_table *vgpu_gem_get_pages(</span>
<span class="p_add">+		struct drm_i915_gem_object *obj)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct drm_i915_private *dev_priv = to_i915(obj-&gt;base.dev);</span>
<span class="p_add">+	struct sg_table *st;</span>
<span class="p_add">+	struct scatterlist *sg;</span>
<span class="p_add">+	int i, ret;</span>
<span class="p_add">+	gen8_pte_t __iomem *gtt_entries;</span>
<span class="p_add">+	struct intel_vgpu_fb_info *fb_info;</span>
<span class="p_add">+</span>
<span class="p_add">+	fb_info = (struct intel_vgpu_fb_info *)obj-&gt;gvt_info;</span>
<span class="p_add">+	if (WARN_ON(!fb_info))</span>
<span class="p_add">+		return ERR_PTR(-ENODEV);</span>
<span class="p_add">+</span>
<span class="p_add">+	st = kmalloc(sizeof(*st), GFP_KERNEL);</span>
<span class="p_add">+	if (unlikely(!st))</span>
<span class="p_add">+		return ERR_PTR(-ENOMEM);</span>
<span class="p_add">+</span>
<span class="p_add">+	ret = sg_alloc_table(st, fb_info-&gt;size, GFP_KERNEL);</span>
<span class="p_add">+	if (ret) {</span>
<span class="p_add">+		kfree(st);</span>
<span class="p_add">+		return ERR_PTR(ret);</span>
<span class="p_add">+	}</span>
<span class="p_add">+	gtt_entries = (gen8_pte_t __iomem *)dev_priv-&gt;ggtt.gsm +</span>
<span class="p_add">+		(fb_info-&gt;start &gt;&gt; PAGE_SHIFT);</span>
<span class="p_add">+	for_each_sg(st-&gt;sgl, sg, fb_info-&gt;size, i) {</span>
<span class="p_add">+		sg-&gt;offset = 0;</span>
<span class="p_add">+		sg-&gt;length = PAGE_SIZE;</span>
<span class="p_add">+		sg_dma_address(sg) =</span>
<span class="p_add">+			GEN8_DECODE_PTE(readq(&amp;gtt_entries[i]));</span>
<span class="p_add">+		sg_dma_len(sg) = PAGE_SIZE;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	return st;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static void vgpu_gem_put_pages(struct drm_i915_gem_object *obj,</span>
<span class="p_add">+		struct sg_table *pages)</span>
<span class="p_add">+{</span>
<span class="p_add">+	sg_free_table(pages);</span>
<span class="p_add">+	kfree(pages);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static void dmabuf_gem_object_free(struct kref *kref)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct intel_vgpu_dmabuf_obj *obj =</span>
<span class="p_add">+		container_of(kref, struct intel_vgpu_dmabuf_obj, kref);</span>
<span class="p_add">+	struct intel_vgpu *vgpu = obj-&gt;vgpu;</span>
<span class="p_add">+	struct list_head *pos;</span>
<span class="p_add">+</span>
<span class="p_add">+	struct intel_vgpu_dmabuf_obj *dmabuf_obj;</span>
<span class="p_add">+</span>
<span class="p_add">+	list_for_each(pos, &amp;vgpu-&gt;dmabuf_obj_list_head) {</span>
<span class="p_add">+		dmabuf_obj = container_of(pos, struct intel_vgpu_dmabuf_obj,</span>
<span class="p_add">+						list);</span>
<span class="p_add">+		if (dmabuf_obj == obj) {</span>
<span class="p_add">+			idr_remove(&amp;vgpu-&gt;object_idr, dmabuf_obj-&gt;dmabuf_id);</span>
<span class="p_add">+			kfree(dmabuf_obj-&gt;info);</span>
<span class="p_add">+			kfree(dmabuf_obj);</span>
<span class="p_add">+			list_del(pos);</span>
<span class="p_add">+			break;</span>
<span class="p_add">+		}</span>
<span class="p_add">+	}</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+</span>
<span class="p_add">+static inline void dmabuf_obj_get(struct intel_vgpu_dmabuf_obj *obj)</span>
<span class="p_add">+{</span>
<span class="p_add">+	kref_get(&amp;obj-&gt;kref);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline void dmabuf_obj_put(struct intel_vgpu_dmabuf_obj *obj)</span>
<span class="p_add">+{</span>
<span class="p_add">+	kref_put(&amp;obj-&gt;kref, dmabuf_gem_object_free);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static void vgpu_gem_release(struct drm_i915_gem_object *gem_obj)</span>
<span class="p_add">+{</span>
<span class="p_add">+</span>
<span class="p_add">+	struct intel_vgpu_fb_info *fb_info = gem_obj-&gt;gvt_info;</span>
<span class="p_add">+	struct intel_vgpu_dmabuf_obj *obj = fb_info-&gt;obj;</span>
<span class="p_add">+	struct intel_vgpu *vgpu = obj-&gt;vgpu;</span>
<span class="p_add">+</span>
<span class="p_add">+	mutex_lock(&amp;vgpu-&gt;dmabuf_lock);</span>
<span class="p_add">+	gem_obj-&gt;base.dma_buf = NULL;</span>
<span class="p_add">+	dmabuf_obj_put(obj);</span>
<span class="p_add">+	intel_gvt_hypervisor_put_vfio_device(vgpu);</span>
<span class="p_add">+	mutex_unlock(&amp;vgpu-&gt;dmabuf_lock);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static const struct drm_i915_gem_object_ops intel_vgpu_gem_ops = {</span>
<span class="p_add">+	.flags = I915_GEM_OBJECT_IS_PROXY,</span>
<span class="p_add">+	.get_pages = vgpu_gem_get_pages,</span>
<span class="p_add">+	.put_pages = vgpu_gem_put_pages,</span>
<span class="p_add">+	.release = vgpu_gem_release,</span>
<span class="p_add">+};</span>
<span class="p_add">+</span>
<span class="p_add">+static struct drm_i915_gem_object *vgpu_create_gem(struct drm_device *dev,</span>
<span class="p_add">+		struct intel_vgpu_fb_info *info)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct drm_i915_private *dev_priv = to_i915(dev);</span>
<span class="p_add">+	struct drm_i915_gem_object *obj;</span>
<span class="p_add">+</span>
<span class="p_add">+	obj = i915_gem_object_alloc(dev_priv);</span>
<span class="p_add">+	if (obj == NULL)</span>
<span class="p_add">+		return NULL;</span>
<span class="p_add">+</span>
<span class="p_add">+	drm_gem_private_object_init(dev, &amp;obj-&gt;base,</span>
<span class="p_add">+		info-&gt;size &lt;&lt; PAGE_SHIFT);</span>
<span class="p_add">+	i915_gem_object_init(obj, &amp;intel_vgpu_gem_ops);</span>
<span class="p_add">+</span>
<span class="p_add">+	obj-&gt;base.read_domains = I915_GEM_DOMAIN_GTT;</span>
<span class="p_add">+	obj-&gt;base.write_domain = 0;</span>
<span class="p_add">+	if (IS_SKYLAKE(dev_priv)) {</span>
<span class="p_add">+		unsigned int tiling_mode = 0;</span>
<span class="p_add">+		unsigned int stride = 0;</span>
<span class="p_add">+</span>
<span class="p_add">+		switch (info-&gt;drm_format_mod &lt;&lt; 10) {</span>
<span class="p_add">+		case PLANE_CTL_TILED_LINEAR:</span>
<span class="p_add">+			tiling_mode = I915_TILING_NONE;</span>
<span class="p_add">+			break;</span>
<span class="p_add">+		case PLANE_CTL_TILED_X:</span>
<span class="p_add">+			tiling_mode = I915_TILING_X;</span>
<span class="p_add">+			stride = info-&gt;stride;</span>
<span class="p_add">+			break;</span>
<span class="p_add">+		case PLANE_CTL_TILED_Y:</span>
<span class="p_add">+			tiling_mode = I915_TILING_Y;</span>
<span class="p_add">+			stride = info-&gt;stride;</span>
<span class="p_add">+			break;</span>
<span class="p_add">+		default:</span>
<span class="p_add">+			gvt_dbg_core(&quot;not supported tiling mode\n&quot;);</span>
<span class="p_add">+		}</span>
<span class="p_add">+		obj-&gt;tiling_and_stride = tiling_mode | stride;</span>
<span class="p_add">+	} else {</span>
<span class="p_add">+		obj-&gt;tiling_and_stride = info-&gt;drm_format_mod ?</span>
<span class="p_add">+					I915_TILING_X : 0;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	return obj;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static int vgpu_get_plane_info(struct drm_device *dev,</span>
<span class="p_add">+		struct intel_vgpu *vgpu,</span>
<span class="p_add">+		struct intel_vgpu_fb_info *info,</span>
<span class="p_add">+		int plane_id)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct drm_i915_private *dev_priv = to_i915(dev);</span>
<span class="p_add">+	struct intel_vgpu_primary_plane_format p;</span>
<span class="p_add">+	struct intel_vgpu_cursor_plane_format c;</span>
<span class="p_add">+	int ret;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (plane_id == DRM_PLANE_TYPE_PRIMARY) {</span>
<span class="p_add">+		ret = intel_vgpu_decode_primary_plane(vgpu, &amp;p);</span>
<span class="p_add">+		if (ret)</span>
<span class="p_add">+			return ret;</span>
<span class="p_add">+		info-&gt;start = p.base;</span>
<span class="p_add">+		info-&gt;start_gpa = p.base_gpa;</span>
<span class="p_add">+		info-&gt;width = p.width;</span>
<span class="p_add">+		info-&gt;height = p.height;</span>
<span class="p_add">+		info-&gt;stride = p.stride;</span>
<span class="p_add">+		info-&gt;drm_format = p.drm_format;</span>
<span class="p_add">+		info-&gt;drm_format_mod = p.tiled;</span>
<span class="p_add">+		info-&gt;size = (((p.stride * p.height * p.bpp) / 8) +</span>
<span class="p_add">+				(PAGE_SIZE - 1)) &gt;&gt; PAGE_SHIFT;</span>
<span class="p_add">+	} else if (plane_id == DRM_PLANE_TYPE_CURSOR) {</span>
<span class="p_add">+		ret = intel_vgpu_decode_cursor_plane(vgpu, &amp;c);</span>
<span class="p_add">+		if (ret)</span>
<span class="p_add">+			return ret;</span>
<span class="p_add">+		info-&gt;start = c.base;</span>
<span class="p_add">+		info-&gt;start_gpa = c.base_gpa;</span>
<span class="p_add">+		info-&gt;width = c.width;</span>
<span class="p_add">+		info-&gt;height = c.height;</span>
<span class="p_add">+		info-&gt;stride = c.width * (c.bpp / 8);</span>
<span class="p_add">+		info-&gt;drm_format = c.drm_format;</span>
<span class="p_add">+		info-&gt;drm_format_mod = 0;</span>
<span class="p_add">+		info-&gt;x_pos = c.x_pos;</span>
<span class="p_add">+		info-&gt;y_pos = c.y_pos;</span>
<span class="p_add">+		info-&gt;size = (((info-&gt;stride * c.height * c.bpp) / 8)</span>
<span class="p_add">+				+ (PAGE_SIZE - 1)) &gt;&gt; PAGE_SHIFT;</span>
<span class="p_add">+	} else {</span>
<span class="p_add">+		gvt_vgpu_err(&quot;invalid plane id:%d\n&quot;, plane_id);</span>
<span class="p_add">+		return -EINVAL;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	if (info-&gt;size == 0) {</span>
<span class="p_add">+		gvt_vgpu_err(&quot;fb size is zero\n&quot;);</span>
<span class="p_add">+		return -EINVAL;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	if (info-&gt;start &amp; (PAGE_SIZE - 1)) {</span>
<span class="p_add">+		gvt_vgpu_err(&quot;Not aligned fb address:0x%llx\n&quot;, info-&gt;start);</span>
<span class="p_add">+		return -EFAULT;</span>
<span class="p_add">+	}</span>
<span class="p_add">+	if (((info-&gt;start &gt;&gt; PAGE_SHIFT) + info-&gt;size) &gt;</span>
<span class="p_add">+		ggtt_total_entries(&amp;dev_priv-&gt;ggtt)) {</span>
<span class="p_add">+		gvt_vgpu_err(&quot;Invalid GTT offset or size\n&quot;);</span>
<span class="p_add">+		return -EFAULT;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	if (!intel_gvt_ggtt_validate_range(vgpu, info-&gt;start, info-&gt;size)) {</span>
<span class="p_add">+		gvt_vgpu_err(&quot;invalid gma addr\n&quot;);</span>
<span class="p_add">+		return -EFAULT;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	return 0;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static struct intel_vgpu_dmabuf_obj *</span>
<span class="p_add">+pick_dmabuf_by_info(struct intel_vgpu *vgpu,</span>
<span class="p_add">+		    struct intel_vgpu_fb_info *latest_info)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct list_head *pos;</span>
<span class="p_add">+	struct intel_vgpu_fb_info *fb_info;</span>
<span class="p_add">+	struct intel_vgpu_dmabuf_obj *dmabuf_obj = NULL;</span>
<span class="p_add">+	struct intel_vgpu_dmabuf_obj *ret = NULL;</span>
<span class="p_add">+</span>
<span class="p_add">+	list_for_each(pos, &amp;vgpu-&gt;dmabuf_obj_list_head) {</span>
<span class="p_add">+		dmabuf_obj = container_of(pos, struct intel_vgpu_dmabuf_obj,</span>
<span class="p_add">+						list);</span>
<span class="p_add">+		if ((dmabuf_obj == NULL) ||</span>
<span class="p_add">+		    (dmabuf_obj-&gt;info == NULL))</span>
<span class="p_add">+			continue;</span>
<span class="p_add">+</span>
<span class="p_add">+		fb_info = (struct intel_vgpu_fb_info *)dmabuf_obj-&gt;info;</span>
<span class="p_add">+		if ((fb_info-&gt;start == latest_info-&gt;start) &amp;&amp;</span>
<span class="p_add">+		    (fb_info-&gt;start_gpa == latest_info-&gt;start_gpa) &amp;&amp;</span>
<span class="p_add">+		    (fb_info-&gt;size == latest_info-&gt;size) &amp;&amp;</span>
<span class="p_add">+		    (fb_info-&gt;drm_format_mod == latest_info-&gt;drm_format_mod) &amp;&amp;</span>
<span class="p_add">+		    (fb_info-&gt;drm_format == latest_info-&gt;drm_format) &amp;&amp;</span>
<span class="p_add">+		    (fb_info-&gt;width == latest_info-&gt;width) &amp;&amp;</span>
<span class="p_add">+		    (fb_info-&gt;height == latest_info-&gt;height)) {</span>
<span class="p_add">+			ret = dmabuf_obj;</span>
<span class="p_add">+			break;</span>
<span class="p_add">+		}</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	return ret;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static struct intel_vgpu_dmabuf_obj *</span>
<span class="p_add">+pick_dmabuf_by_num(struct intel_vgpu *vgpu, u32 id)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct list_head *pos;</span>
<span class="p_add">+	struct intel_vgpu_dmabuf_obj *dmabuf_obj = NULL;</span>
<span class="p_add">+	struct intel_vgpu_dmabuf_obj *ret = NULL;</span>
<span class="p_add">+</span>
<span class="p_add">+	list_for_each(pos, &amp;vgpu-&gt;dmabuf_obj_list_head) {</span>
<span class="p_add">+		dmabuf_obj = container_of(pos, struct intel_vgpu_dmabuf_obj,</span>
<span class="p_add">+						list);</span>
<span class="p_add">+		if (!dmabuf_obj)</span>
<span class="p_add">+			continue;</span>
<span class="p_add">+</span>
<span class="p_add">+		if (dmabuf_obj-&gt;dmabuf_id == id) {</span>
<span class="p_add">+			ret = dmabuf_obj;</span>
<span class="p_add">+			break;</span>
<span class="p_add">+		}</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	return ret;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static void update_fb_info(struct vfio_device_gfx_plane_info *gvt_dmabuf,</span>
<span class="p_add">+		      struct intel_vgpu_fb_info *fb_info)</span>
<span class="p_add">+{</span>
<span class="p_add">+	gvt_dmabuf-&gt;drm_format = fb_info-&gt;drm_format;</span>
<span class="p_add">+	gvt_dmabuf-&gt;width = fb_info-&gt;width;</span>
<span class="p_add">+	gvt_dmabuf-&gt;height = fb_info-&gt;height;</span>
<span class="p_add">+	gvt_dmabuf-&gt;stride = fb_info-&gt;stride;</span>
<span class="p_add">+	gvt_dmabuf-&gt;size = fb_info-&gt;size;</span>
<span class="p_add">+	gvt_dmabuf-&gt;x_pos = fb_info-&gt;x_pos;</span>
<span class="p_add">+	gvt_dmabuf-&gt;y_pos = fb_info-&gt;y_pos;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+int intel_vgpu_query_plane(struct intel_vgpu *vgpu, void *args)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct drm_device *dev = &amp;vgpu-&gt;gvt-&gt;dev_priv-&gt;drm;</span>
<span class="p_add">+	struct vfio_device_gfx_plane_info *gfx_plane_info = args;</span>
<span class="p_add">+	struct intel_vgpu_dmabuf_obj *dmabuf_obj;</span>
<span class="p_add">+	struct intel_vgpu_fb_info fb_info;</span>
<span class="p_add">+	int ret = 0;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (gfx_plane_info-&gt;flags == (VFIO_GFX_PLANE_TYPE_DMABUF |</span>
<span class="p_add">+				       VFIO_GFX_PLANE_TYPE_PROBE))</span>
<span class="p_add">+		return ret;</span>
<span class="p_add">+	else if ((gfx_plane_info-&gt;flags &amp; ~VFIO_GFX_PLANE_TYPE_DMABUF) ||</span>
<span class="p_add">+			(!gfx_plane_info-&gt;flags))</span>
<span class="p_add">+		return -EINVAL;</span>
<span class="p_add">+</span>
<span class="p_add">+	ret = vgpu_get_plane_info(dev, vgpu, &amp;fb_info,</span>
<span class="p_add">+					gfx_plane_info-&gt;drm_plane_type);</span>
<span class="p_add">+	if (ret != 0)</span>
<span class="p_add">+		goto out;</span>
<span class="p_add">+</span>
<span class="p_add">+	mutex_lock(&amp;vgpu-&gt;dmabuf_lock);</span>
<span class="p_add">+	/* If exists, pick up the exposed dmabuf_obj */</span>
<span class="p_add">+	dmabuf_obj = pick_dmabuf_by_info(vgpu, &amp;fb_info);</span>
<span class="p_add">+	if (dmabuf_obj) {</span>
<span class="p_add">+		update_fb_info(gfx_plane_info, &amp;fb_info);</span>
<span class="p_add">+		gfx_plane_info-&gt;dmabuf_id = dmabuf_obj-&gt;dmabuf_id;</span>
<span class="p_add">+</span>
<span class="p_add">+		/* This buffer may be released between query_plane ioctl and</span>
<span class="p_add">+		 * get_dmabuf ioctl. Add the refcount to make sure it won&#39;t</span>
<span class="p_add">+		 * be released between the two ioctls.</span>
<span class="p_add">+		 */</span>
<span class="p_add">+		if (!dmabuf_obj-&gt;initref) {</span>
<span class="p_add">+			dmabuf_obj-&gt;initref = true;</span>
<span class="p_add">+			dmabuf_obj_get(dmabuf_obj);</span>
<span class="p_add">+		}</span>
<span class="p_add">+		ret = 0;</span>
<span class="p_add">+		gvt_dbg_dpy(&quot;vgpu%d: re-use dmabuf_obj ref %d, id %d\n&quot;,</span>
<span class="p_add">+			    vgpu-&gt;id, kref_read(&amp;dmabuf_obj-&gt;kref),</span>
<span class="p_add">+			    gfx_plane_info-&gt;dmabuf_id);</span>
<span class="p_add">+		mutex_unlock(&amp;vgpu-&gt;dmabuf_lock);</span>
<span class="p_add">+		goto out;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	mutex_unlock(&amp;vgpu-&gt;dmabuf_lock);</span>
<span class="p_add">+</span>
<span class="p_add">+	/* Need to allocate a new one*/</span>
<span class="p_add">+	dmabuf_obj = kmalloc(sizeof(struct intel_vgpu_dmabuf_obj), GFP_KERNEL);</span>
<span class="p_add">+	if (unlikely(!dmabuf_obj)) {</span>
<span class="p_add">+		gvt_vgpu_err(&quot;alloc dmabuf_obj failed\n&quot;);</span>
<span class="p_add">+		ret = -ENOMEM;</span>
<span class="p_add">+		goto out;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	dmabuf_obj-&gt;info = kmalloc(sizeof(struct intel_vgpu_fb_info),</span>
<span class="p_add">+				   GFP_KERNEL);</span>
<span class="p_add">+	if (unlikely(!dmabuf_obj-&gt;info)) {</span>
<span class="p_add">+		gvt_vgpu_err(&quot;allocate intel vgpu fb info failed\n&quot;);</span>
<span class="p_add">+		ret = -ENOMEM;</span>
<span class="p_add">+		goto out_free_dmabuf;</span>
<span class="p_add">+	}</span>
<span class="p_add">+	memcpy(dmabuf_obj-&gt;info, &amp;fb_info, sizeof(struct intel_vgpu_fb_info));</span>
<span class="p_add">+</span>
<span class="p_add">+	((struct intel_vgpu_fb_info *)dmabuf_obj-&gt;info)-&gt;obj = dmabuf_obj;</span>
<span class="p_add">+</span>
<span class="p_add">+	dmabuf_obj-&gt;vgpu = vgpu;</span>
<span class="p_add">+</span>
<span class="p_add">+	ret = idr_alloc(&amp;vgpu-&gt;object_idr, dmabuf_obj, 1, 0, GFP_NOWAIT);</span>
<span class="p_add">+	if (ret &lt; 0)</span>
<span class="p_add">+		goto out_free_info;</span>
<span class="p_add">+	gfx_plane_info-&gt;dmabuf_id = ret;</span>
<span class="p_add">+	dmabuf_obj-&gt;dmabuf_id = ret;</span>
<span class="p_add">+</span>
<span class="p_add">+	dmabuf_obj-&gt;initref = true;</span>
<span class="p_add">+</span>
<span class="p_add">+	kref_init(&amp;dmabuf_obj-&gt;kref);</span>
<span class="p_add">+</span>
<span class="p_add">+	mutex_lock(&amp;vgpu-&gt;dmabuf_lock);</span>
<span class="p_add">+	if (intel_gvt_hypervisor_get_vfio_device(vgpu)) {</span>
<span class="p_add">+		gvt_vgpu_err(&quot;get vfio device failed\n&quot;);</span>
<span class="p_add">+		mutex_unlock(&amp;vgpu-&gt;dmabuf_lock);</span>
<span class="p_add">+		goto out_free_info;</span>
<span class="p_add">+	}</span>
<span class="p_add">+	mutex_unlock(&amp;vgpu-&gt;dmabuf_lock);</span>
<span class="p_add">+</span>
<span class="p_add">+	update_fb_info(gfx_plane_info, &amp;fb_info);</span>
<span class="p_add">+</span>
<span class="p_add">+	INIT_LIST_HEAD(&amp;dmabuf_obj-&gt;list);</span>
<span class="p_add">+	mutex_lock(&amp;vgpu-&gt;dmabuf_lock);</span>
<span class="p_add">+	list_add_tail(&amp;dmabuf_obj-&gt;list, &amp;vgpu-&gt;dmabuf_obj_list_head);</span>
<span class="p_add">+	mutex_unlock(&amp;vgpu-&gt;dmabuf_lock);</span>
<span class="p_add">+</span>
<span class="p_add">+	gvt_dbg_dpy(&quot;vgpu%d: %s new dmabuf_obj ref %d, id %d\n&quot;, vgpu-&gt;id,</span>
<span class="p_add">+		    __func__, kref_read(&amp;dmabuf_obj-&gt;kref), ret);</span>
<span class="p_add">+</span>
<span class="p_add">+	return 0;</span>
<span class="p_add">+</span>
<span class="p_add">+out_free_info:</span>
<span class="p_add">+	kfree(dmabuf_obj-&gt;info);</span>
<span class="p_add">+out_free_dmabuf:</span>
<span class="p_add">+	kfree(dmabuf_obj);</span>
<span class="p_add">+out:</span>
<span class="p_add">+	/* ENODEV means plane isn&#39;t ready, which might be a normal case. */</span>
<span class="p_add">+	return (ret == -ENODEV) ? 0 : ret;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+/* To associate an exposed dmabuf with the dmabuf_obj */</span>
<span class="p_add">+int intel_vgpu_get_dmabuf(struct intel_vgpu *vgpu, void *args)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct drm_device *dev = &amp;vgpu-&gt;gvt-&gt;dev_priv-&gt;drm;</span>
<span class="p_add">+	struct vfio_device_gfx_dmabuf_fd *gvt_dmabuf_fd = args;</span>
<span class="p_add">+	struct intel_vgpu_dmabuf_obj *dmabuf_obj;</span>
<span class="p_add">+	struct drm_i915_gem_object *obj;</span>
<span class="p_add">+	struct dma_buf *dmabuf;</span>
<span class="p_add">+	int ret = 0;</span>
<span class="p_add">+</span>
<span class="p_add">+	mutex_lock(&amp;vgpu-&gt;dmabuf_lock);</span>
<span class="p_add">+</span>
<span class="p_add">+	dmabuf_obj = pick_dmabuf_by_num(vgpu, gvt_dmabuf_fd-&gt;dmabuf_id);</span>
<span class="p_add">+	if (dmabuf_obj == NULL) {</span>
<span class="p_add">+		gvt_vgpu_err(&quot;invalid dmabuf id:%d\n&quot;,</span>
<span class="p_add">+			     gvt_dmabuf_fd-&gt;dmabuf_id);</span>
<span class="p_add">+		ret = -EINVAL;</span>
<span class="p_add">+		goto out;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	obj = vgpu_create_gem(dev, dmabuf_obj-&gt;info);</span>
<span class="p_add">+	if (obj == NULL) {</span>
<span class="p_add">+		gvt_vgpu_err(&quot;create gvt gem obj failed:%d\n&quot;, vgpu-&gt;id);</span>
<span class="p_add">+		ret = -ENOMEM;</span>
<span class="p_add">+		goto out;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	obj-&gt;gvt_info = dmabuf_obj-&gt;info;</span>
<span class="p_add">+</span>
<span class="p_add">+	dmabuf = i915_gem_prime_export(dev, &amp;obj-&gt;base, DRM_CLOEXEC | DRM_RDWR);</span>
<span class="p_add">+	if (IS_ERR(dmabuf)) {</span>
<span class="p_add">+		gvt_vgpu_err(&quot;export dma-buf failed\n&quot;);</span>
<span class="p_add">+		ret = PTR_ERR(dmabuf);</span>
<span class="p_add">+		goto out_free_gem;</span>
<span class="p_add">+	}</span>
<span class="p_add">+	obj-&gt;base.dma_buf = dmabuf;</span>
<span class="p_add">+</span>
<span class="p_add">+	i915_gem_object_put(obj);</span>
<span class="p_add">+</span>
<span class="p_add">+	ret = dma_buf_fd(dmabuf, DRM_CLOEXEC | DRM_RDWR);</span>
<span class="p_add">+	if (ret &lt; 0) {</span>
<span class="p_add">+		gvt_vgpu_err(&quot;create dma-buf fd failed ret:%d\n&quot;, ret);</span>
<span class="p_add">+		goto out_free_dmabuf;</span>
<span class="p_add">+	}</span>
<span class="p_add">+	gvt_dmabuf_fd-&gt;dmabuf_fd = ret;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (intel_gvt_hypervisor_get_vfio_device(vgpu)) {</span>
<span class="p_add">+		gvt_vgpu_err(&quot;get vfio device failed\n&quot;);</span>
<span class="p_add">+		put_unused_fd(ret);</span>
<span class="p_add">+		goto out_free_dmabuf;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	dmabuf_obj_get(dmabuf_obj);</span>
<span class="p_add">+</span>
<span class="p_add">+	if (dmabuf_obj-&gt;initref) {</span>
<span class="p_add">+		dmabuf_obj-&gt;initref = false;</span>
<span class="p_add">+		dmabuf_obj_put(dmabuf_obj);</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	mutex_unlock(&amp;vgpu-&gt;dmabuf_lock);</span>
<span class="p_add">+</span>
<span class="p_add">+	gvt_dbg_dpy(&quot;vgpu%d: dmabuf:%d, dmabuf ref %d, fd:%d\n&quot;</span>
<span class="p_add">+		    &quot;        file count: %ld, GEM ref: %d\n&quot;,</span>
<span class="p_add">+		    vgpu-&gt;id, dmabuf_obj-&gt;dmabuf_id,</span>
<span class="p_add">+		    kref_read(&amp;dmabuf_obj-&gt;kref),</span>
<span class="p_add">+		    gvt_dmabuf_fd-&gt;dmabuf_fd,</span>
<span class="p_add">+		    file_count(dmabuf-&gt;file),</span>
<span class="p_add">+		    kref_read(&amp;obj-&gt;base.refcount));</span>
<span class="p_add">+</span>
<span class="p_add">+	return 0;</span>
<span class="p_add">+</span>
<span class="p_add">+out_free_dmabuf:</span>
<span class="p_add">+	dma_buf_put(dmabuf);</span>
<span class="p_add">+out_free_gem:</span>
<span class="p_add">+	i915_gem_object_put(obj);</span>
<span class="p_add">+out:</span>
<span class="p_add">+	mutex_unlock(&amp;vgpu-&gt;dmabuf_lock);</span>
<span class="p_add">+	return ret;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void intel_vgpu_dmabuf_cleanup(struct intel_vgpu *vgpu)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct list_head *pos, *n;</span>
<span class="p_add">+	struct intel_vgpu_dmabuf_obj *dmabuf_obj;</span>
<span class="p_add">+</span>
<span class="p_add">+	mutex_lock(&amp;vgpu-&gt;dmabuf_lock);</span>
<span class="p_add">+	list_for_each_safe(pos, n, &amp;vgpu-&gt;dmabuf_obj_list_head) {</span>
<span class="p_add">+		dmabuf_obj = container_of(pos, struct intel_vgpu_dmabuf_obj,</span>
<span class="p_add">+						list);</span>
<span class="p_add">+		if (dmabuf_obj-&gt;initref) {</span>
<span class="p_add">+			dmabuf_obj-&gt;initref = false;</span>
<span class="p_add">+			dmabuf_obj_put(dmabuf_obj);</span>
<span class="p_add">+		}</span>
<span class="p_add">+	}</span>
<span class="p_add">+	mutex_unlock(&amp;vgpu-&gt;dmabuf_lock);</span>
<span class="p_add">+}</span>
<span class="p_header">diff --git a/drivers/gpu/drm/i915/gvt/dmabuf.h b/drivers/gpu/drm/i915/gvt/dmabuf.h</span>
new file mode 100644
<span class="p_header">index 0000000..d02c76c</span>
<span class="p_header">--- /dev/null</span>
<span class="p_header">+++ b/drivers/gpu/drm/i915/gvt/dmabuf.h</span>
<span class="p_chunk">@@ -0,0 +1,65 @@</span> <span class="p_context"></span>
<span class="p_add">+/*</span>
<span class="p_add">+ * Copyright(c) 2017 Intel Corporation. All rights reserved.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * Permission is hereby granted, free of charge, to any person obtaining a</span>
<span class="p_add">+ * copy of this software and associated documentation files (the &quot;Software&quot;),</span>
<span class="p_add">+ * to deal in the Software without restriction, including without limitation</span>
<span class="p_add">+ * the rights to use, copy, modify, merge, publish, distribute, sublicense,</span>
<span class="p_add">+ * and/or sell copies of the Software, and to permit persons to whom the</span>
<span class="p_add">+ * Software is furnished to do so, subject to the following conditions:</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * The above copyright notice and this permission notice (including the next</span>
<span class="p_add">+ * paragraph) shall be included in all copies or substantial portions of the</span>
<span class="p_add">+ * Software.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * THE SOFTWARE IS PROVIDED &quot;AS IS&quot;, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR</span>
<span class="p_add">+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,</span>
<span class="p_add">+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL</span>
<span class="p_add">+ * THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER</span>
<span class="p_add">+ * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,</span>
<span class="p_add">+ * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE</span>
<span class="p_add">+ * SOFTWARE.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * Authors:</span>
<span class="p_add">+ *    Zhiyuan Lv &lt;zhiyuan.lv@intel.com&gt;</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * Contributors:</span>
<span class="p_add">+ *    Xiaoguang Chen</span>
<span class="p_add">+ *    Tina Zhang &lt;tina.zhang@intel.com&gt;</span>
<span class="p_add">+ */</span>
<span class="p_add">+</span>
<span class="p_add">+#ifndef _GVT_DMABUF_H_</span>
<span class="p_add">+#define _GVT_DMABUF_H_</span>
<span class="p_add">+#include &lt;linux/vfio.h&gt;</span>
<span class="p_add">+</span>
<span class="p_add">+struct intel_vgpu_fb_info {</span>
<span class="p_add">+	__u64 start;</span>
<span class="p_add">+	__u64 start_gpa;</span>
<span class="p_add">+	__u64 drm_format_mod;</span>
<span class="p_add">+	__u32 drm_format;	/* drm format of plane */</span>
<span class="p_add">+	__u32 width;	/* width of plane */</span>
<span class="p_add">+	__u32 height;	/* height of plane */</span>
<span class="p_add">+	__u32 stride;	/* stride of plane */</span>
<span class="p_add">+	__u32 size;	/* size of plane in bytes, align on page */</span>
<span class="p_add">+	__u32 x_pos;	/* horizontal position of cursor plane */</span>
<span class="p_add">+	__u32 y_pos;	/* vertical position of cursor plane */</span>
<span class="p_add">+	struct intel_vgpu_dmabuf_obj *obj;</span>
<span class="p_add">+};</span>
<span class="p_add">+</span>
<span class="p_add">+/**</span>
<span class="p_add">+ * struct intel_vgpu_dmabuf_obj- Intel vGPU device buffer object</span>
<span class="p_add">+ */</span>
<span class="p_add">+struct intel_vgpu_dmabuf_obj {</span>
<span class="p_add">+	struct intel_vgpu *vgpu;</span>
<span class="p_add">+	struct intel_vgpu_fb_info *info;</span>
<span class="p_add">+	__u32 dmabuf_id;</span>
<span class="p_add">+	struct kref kref;</span>
<span class="p_add">+	bool initref;</span>
<span class="p_add">+	struct list_head list;</span>
<span class="p_add">+};</span>
<span class="p_add">+</span>
<span class="p_add">+int intel_vgpu_query_plane(struct intel_vgpu *vgpu, void *args);</span>
<span class="p_add">+int intel_vgpu_get_dmabuf(struct intel_vgpu *vgpu, void *args);</span>
<span class="p_add">+void intel_vgpu_dmabuf_cleanup(struct intel_vgpu *vgpu);</span>
<span class="p_add">+</span>
<span class="p_add">+#endif</span>
<span class="p_header">diff --git a/drivers/gpu/drm/i915/gvt/gvt.c b/drivers/gpu/drm/i915/gvt/gvt.c</span>
<span class="p_header">index c27c683..bc7264f 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/i915/gvt/gvt.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/i915/gvt/gvt.c</span>
<span class="p_chunk">@@ -54,6 +54,8 @@</span> <span class="p_context"> static const struct intel_gvt_ops intel_gvt_ops = {</span>
 	.vgpu_reset = intel_gvt_reset_vgpu,
 	.vgpu_activate = intel_gvt_activate_vgpu,
 	.vgpu_deactivate = intel_gvt_deactivate_vgpu,
<span class="p_add">+	.vgpu_query_plane = intel_vgpu_query_plane,</span>
<span class="p_add">+	.vgpu_get_dmabuf = intel_vgpu_get_dmabuf,</span>
 };
 
 /**
<span class="p_header">diff --git a/drivers/gpu/drm/i915/gvt/gvt.h b/drivers/gpu/drm/i915/gvt/gvt.h</span>
<span class="p_header">index 0f562ee..e67367e 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/i915/gvt/gvt.h</span>
<span class="p_header">+++ b/drivers/gpu/drm/i915/gvt/gvt.h</span>
<span class="p_chunk">@@ -47,6 +47,7 @@</span> <span class="p_context"></span>
 #include &quot;render.h&quot;
 #include &quot;cmd_parser.h&quot;
 #include &quot;fb_decoder.h&quot;
<span class="p_add">+#include &quot;dmabuf.h&quot;</span>
 
 #define GVT_MAX_VGPU 8
 
<span class="p_chunk">@@ -183,8 +184,16 @@</span> <span class="p_context"> struct intel_vgpu {</span>
 		struct kvm *kvm;
 		struct work_struct release_work;
 		atomic_t released;
<span class="p_add">+		struct vfio_device *vfio_device;</span>
 	} vdev;
 #endif
<span class="p_add">+</span>
<span class="p_add">+	struct list_head dmabuf_obj_list_head;</span>
<span class="p_add">+	struct mutex dmabuf_lock;</span>
<span class="p_add">+	struct idr object_idr;</span>
<span class="p_add">+</span>
<span class="p_add">+	struct completion vblank_done;</span>
<span class="p_add">+</span>
 };
 
 struct intel_gvt_gm {
<span class="p_chunk">@@ -500,6 +509,8 @@</span> <span class="p_context"> struct intel_gvt_ops {</span>
 	void (*vgpu_reset)(struct intel_vgpu *);
 	void (*vgpu_activate)(struct intel_vgpu *);
 	void (*vgpu_deactivate)(struct intel_vgpu *);
<span class="p_add">+	int (*vgpu_query_plane)(struct intel_vgpu *vgpu, void *);</span>
<span class="p_add">+	int (*vgpu_get_dmabuf)(struct intel_vgpu *vgpu, void *);</span>
 };
 
 
<span class="p_header">diff --git a/drivers/gpu/drm/i915/gvt/hypercall.h b/drivers/gpu/drm/i915/gvt/hypercall.h</span>
<span class="p_header">index 32c345c..a1bd82f 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/i915/gvt/hypercall.h</span>
<span class="p_header">+++ b/drivers/gpu/drm/i915/gvt/hypercall.h</span>
<span class="p_chunk">@@ -56,6 +56,8 @@</span> <span class="p_context"> struct intel_gvt_mpt {</span>
 	int (*set_trap_area)(unsigned long handle, u64 start, u64 end,
 			     bool map);
 	int (*set_opregion)(void *vgpu);
<span class="p_add">+	int (*get_vfio_device)(void *vgpu);</span>
<span class="p_add">+	void (*put_vfio_device)(void *vgpu);</span>
 };
 
 extern struct intel_gvt_mpt xengt_mpt;
<span class="p_header">diff --git a/drivers/gpu/drm/i915/gvt/kvmgt.c b/drivers/gpu/drm/i915/gvt/kvmgt.c</span>
<span class="p_header">index 6b0a330..d249054 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/i915/gvt/kvmgt.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/i915/gvt/kvmgt.c</span>
<span class="p_chunk">@@ -492,10 +492,23 @@</span> <span class="p_context"> static int intel_vgpu_register_reg(struct intel_vgpu *vgpu,</span>
 	vgpu-&gt;vdev.region[vgpu-&gt;vdev.num_regions].flags = flags;
 	vgpu-&gt;vdev.region[vgpu-&gt;vdev.num_regions].data = data;
 	vgpu-&gt;vdev.num_regions++;
<span class="p_add">+	return 0;</span>
<span class="p_add">+}</span>
 
<span class="p_add">+static int kvmgt_get_vfio_device(void *p_vgpu)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct intel_vgpu *vgpu = (struct intel_vgpu *)p_vgpu;</span>
<span class="p_add">+</span>
<span class="p_add">+	vgpu-&gt;vdev.vfio_device = vfio_device_get_from_dev(</span>
<span class="p_add">+		mdev_dev(vgpu-&gt;vdev.mdev));</span>
<span class="p_add">+	if (!vgpu-&gt;vdev.vfio_device) {</span>
<span class="p_add">+		gvt_vgpu_err(&quot;failed to get vfio device\n&quot;);</span>
<span class="p_add">+		return -ENODEV;</span>
<span class="p_add">+	}</span>
 	return 0;
 }
 
<span class="p_add">+</span>
 static int kvmgt_set_opregion(void *p_vgpu)
 {
 	struct intel_vgpu *vgpu = (struct intel_vgpu *)p_vgpu;
<span class="p_chunk">@@ -527,6 +540,14 @@</span> <span class="p_context"> static int kvmgt_set_opregion(void *p_vgpu)</span>
 	return ret;
 }
 
<span class="p_add">+static void kvmgt_put_vfio_device(void *vgpu)</span>
<span class="p_add">+{</span>
<span class="p_add">+	if (WARN_ON(!((struct intel_vgpu *)vgpu)-&gt;vdev.vfio_device))</span>
<span class="p_add">+		return;</span>
<span class="p_add">+</span>
<span class="p_add">+	vfio_device_put(((struct intel_vgpu *)vgpu)-&gt;vdev.vfio_device);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static int intel_vgpu_create(struct kobject *kobj, struct mdev_device *mdev)
 {
 	struct intel_vgpu *vgpu = NULL;
<span class="p_chunk">@@ -1253,6 +1274,40 @@</span> <span class="p_context"> static long intel_vgpu_ioctl(struct mdev_device *mdev, unsigned int cmd,</span>
 	} else if (cmd == VFIO_DEVICE_RESET) {
 		intel_gvt_ops-&gt;vgpu_reset(vgpu);
 		return 0;
<span class="p_add">+	} else if (cmd == VFIO_DEVICE_QUERY_GFX_PLANE) {</span>
<span class="p_add">+		struct vfio_device_gfx_plane_info dmabuf;</span>
<span class="p_add">+		int ret = 0;</span>
<span class="p_add">+</span>
<span class="p_add">+		minsz = offsetofend(struct vfio_device_gfx_plane_info,</span>
<span class="p_add">+				    dmabuf_id);</span>
<span class="p_add">+		if (copy_from_user(&amp;dmabuf, (void __user *)arg, minsz))</span>
<span class="p_add">+			return -EFAULT;</span>
<span class="p_add">+		if (dmabuf.argsz &lt; minsz)</span>
<span class="p_add">+			return -EINVAL;</span>
<span class="p_add">+</span>
<span class="p_add">+		ret = intel_gvt_ops-&gt;vgpu_query_plane(vgpu, &amp;dmabuf);</span>
<span class="p_add">+		if (ret != 0)</span>
<span class="p_add">+			return ret;</span>
<span class="p_add">+</span>
<span class="p_add">+		return copy_to_user((void __user *)arg, &amp;dmabuf, minsz) ?</span>
<span class="p_add">+								-EFAULT : 0;</span>
<span class="p_add">+	} else if (cmd == VFIO_DEVICE_GET_GFX_DMABUF) {</span>
<span class="p_add">+		struct vfio_device_gfx_dmabuf_fd dmabuf_fd;</span>
<span class="p_add">+		int ret = 0;</span>
<span class="p_add">+</span>
<span class="p_add">+		minsz = offsetofend(struct vfio_device_gfx_dmabuf_fd,</span>
<span class="p_add">+				    dmabuf_fd);</span>
<span class="p_add">+		if (copy_from_user(&amp;dmabuf_fd, (void __user *)arg, minsz))</span>
<span class="p_add">+			return -EFAULT;</span>
<span class="p_add">+		if (dmabuf_fd.argsz &lt; minsz)</span>
<span class="p_add">+			return -EINVAL;</span>
<span class="p_add">+</span>
<span class="p_add">+		ret = intel_gvt_ops-&gt;vgpu_get_dmabuf(vgpu, &amp;dmabuf_fd);</span>
<span class="p_add">+		if (ret != 0)</span>
<span class="p_add">+			return ret;</span>
<span class="p_add">+</span>
<span class="p_add">+		return copy_to_user((void __user *)arg, &amp;dmabuf_fd, minsz) ?</span>
<span class="p_add">+								-EFAULT : 0;</span>
 	}
 
 	return 0;
<span class="p_chunk">@@ -1475,6 +1530,9 @@</span> <span class="p_context"> static int kvmgt_guest_init(struct mdev_device *mdev)</span>
 	kvmgt_protect_table_init(info);
 	gvt_cache_init(vgpu);
 
<span class="p_add">+	mutex_init(&amp;vgpu-&gt;dmabuf_lock);</span>
<span class="p_add">+	init_completion(&amp;vgpu-&gt;vblank_done);</span>
<span class="p_add">+</span>
 	info-&gt;track_node.track_write = kvmgt_page_track_write;
 	info-&gt;track_node.track_flush_slot = kvmgt_page_track_flush_slot;
 	kvm_page_track_register_notifier(kvm, &amp;info-&gt;track_node);
<span class="p_chunk">@@ -1616,6 +1674,8 @@</span> <span class="p_context"> struct intel_gvt_mpt kvmgt_mpt = {</span>
 	.write_gpa = kvmgt_write_gpa,
 	.gfn_to_mfn = kvmgt_gfn_to_pfn,
 	.set_opregion = kvmgt_set_opregion,
<span class="p_add">+	.get_vfio_device = kvmgt_get_vfio_device,</span>
<span class="p_add">+	.put_vfio_device = kvmgt_put_vfio_device,</span>
 };
 EXPORT_SYMBOL_GPL(kvmgt_mpt);
 
<span class="p_header">diff --git a/drivers/gpu/drm/i915/gvt/mpt.h b/drivers/gpu/drm/i915/gvt/mpt.h</span>
<span class="p_header">index 9e73f2e..86443ff 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/i915/gvt/mpt.h</span>
<span class="p_header">+++ b/drivers/gpu/drm/i915/gvt/mpt.h</span>
<span class="p_chunk">@@ -307,4 +307,34 @@</span> <span class="p_context"> static inline int intel_gvt_hypervisor_set_opregion(struct intel_vgpu *vgpu)</span>
 	return intel_gvt_host.mpt-&gt;set_opregion(vgpu);
 }
 
<span class="p_add">+/**</span>
<span class="p_add">+ * intel_gvt_hypervisor_get_vfio_device - increase vfio device ref count</span>
<span class="p_add">+ * @vgpu: a vGPU</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * Returns:</span>
<span class="p_add">+ * Zero on success, negative error code if failed.</span>
<span class="p_add">+ */</span>
<span class="p_add">+static inline int intel_gvt_hypervisor_get_vfio_device(struct intel_vgpu *vgpu)</span>
<span class="p_add">+{</span>
<span class="p_add">+	if (!intel_gvt_host.mpt-&gt;get_vfio_device)</span>
<span class="p_add">+		return 0;</span>
<span class="p_add">+</span>
<span class="p_add">+	return intel_gvt_host.mpt-&gt;get_vfio_device(vgpu);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+/**</span>
<span class="p_add">+ * intel_gvt_hypervisor_put_vfio_device - decrease vfio device ref count</span>
<span class="p_add">+ * @vgpu: a vGPU</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * Returns:</span>
<span class="p_add">+ * Zero on success, negative error code if failed.</span>
<span class="p_add">+ */</span>
<span class="p_add">+static inline void intel_gvt_hypervisor_put_vfio_device(struct intel_vgpu *vgpu)</span>
<span class="p_add">+{</span>
<span class="p_add">+	if (!intel_gvt_host.mpt-&gt;put_vfio_device)</span>
<span class="p_add">+		return;</span>
<span class="p_add">+</span>
<span class="p_add">+	intel_gvt_host.mpt-&gt;put_vfio_device(vgpu);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 #endif /* _GVT_MPT_H_ */
<span class="p_header">diff --git a/drivers/gpu/drm/i915/gvt/vgpu.c b/drivers/gpu/drm/i915/gvt/vgpu.c</span>
<span class="p_header">index bcbf535..326c8c7 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/i915/gvt/vgpu.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/i915/gvt/vgpu.c</span>
<span class="p_chunk">@@ -232,6 +232,7 @@</span> <span class="p_context"> void intel_gvt_deactivate_vgpu(struct intel_vgpu *vgpu)</span>
 	}
 
 	intel_vgpu_stop_schedule(vgpu);
<span class="p_add">+	intel_vgpu_dmabuf_cleanup(vgpu);</span>
 
 	mutex_unlock(&amp;gvt-&gt;lock);
 }
<span class="p_chunk">@@ -261,6 +262,7 @@</span> <span class="p_context"> void intel_gvt_destroy_vgpu(struct intel_vgpu *vgpu)</span>
 	intel_gvt_hypervisor_detach_vgpu(vgpu);
 	intel_vgpu_free_resource(vgpu);
 	intel_vgpu_clean_mmio(vgpu);
<span class="p_add">+	intel_vgpu_dmabuf_cleanup(vgpu);</span>
 	vfree(vgpu);
 
 	intel_gvt_update_vgpu_types(gvt);
<span class="p_chunk">@@ -346,7 +348,8 @@</span> <span class="p_context"> static struct intel_vgpu *__intel_gvt_create_vgpu(struct intel_gvt *gvt,</span>
 	vgpu-&gt;gvt = gvt;
 	vgpu-&gt;sched_ctl.weight = param-&gt;weight;
 	bitmap_zero(vgpu-&gt;tlb_handle_pending, I915_NUM_ENGINES);
<span class="p_del">-</span>
<span class="p_add">+	INIT_LIST_HEAD(&amp;vgpu-&gt;dmabuf_obj_list_head);</span>
<span class="p_add">+	idr_init(&amp;vgpu-&gt;object_idr);</span>
 	intel_vgpu_init_cfg_space(vgpu, param-&gt;primary);
 
 	ret = intel_vgpu_init_mmio(vgpu);
<span class="p_header">diff --git a/drivers/gpu/drm/i915/i915_gem_object.h b/drivers/gpu/drm/i915/i915_gem_object.h</span>
<span class="p_header">index f3b382a..c91e336 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/i915/i915_gem_object.h</span>
<span class="p_header">+++ b/drivers/gpu/drm/i915/i915_gem_object.h</span>
<span class="p_chunk">@@ -199,6 +199,8 @@</span> <span class="p_context"> struct drm_i915_gem_object {</span>
 		} userptr;
 
 		unsigned long scratch;
<span class="p_add">+</span>
<span class="p_add">+		void *gvt_info;</span>
 	};
 
 	/** for phys allocated objects */

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



