
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>[RFC,v4,18/28] x86: DMA support for memory encryption - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    [RFC,v4,18/28] x86: DMA support for memory encryption</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=80801">Tom Lendacky</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>Feb. 16, 2017, 3:46 p.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;20170216154604.19244.69522.stgit@tlendack-t1.amdoffice.net&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/9577543/mbox/"
   >mbox</a>
|
   <a href="/patch/9577543/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/9577543/">/patch/9577543/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
	[172.30.200.125])
	by pdx-korg-patchwork.web.codeaurora.org (Postfix) with ESMTP id
	740C660244 for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Thu, 16 Feb 2017 15:46:33 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 6484F2861B
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Thu, 16 Feb 2017 15:46:33 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id 58E6E2861D; Thu, 16 Feb 2017 15:46:33 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-6.9 required=2.0 tests=BAYES_00,DKIM_SIGNED,
	DKIM_VALID,RCVD_IN_DNSWL_HI autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 4F96F2861B
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Thu, 16 Feb 2017 15:46:32 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S932799AbdBPPqa (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Thu, 16 Feb 2017 10:46:30 -0500
Received: from mail-co1nam03on0081.outbound.protection.outlook.com
	([104.47.40.81]:16416
	&quot;EHLO NAM03-CO1-obe.outbound.protection.outlook.com&quot;
	rhost-flags-OK-OK-OK-FAIL) by vger.kernel.org with ESMTP
	id S932454AbdBPPqW (ORCPT &lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Thu, 16 Feb 2017 10:46:22 -0500
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
	d=amdcloud.onmicrosoft.com; s=selector1-amd-com;
	h=From:Date:Subject:Message-ID:Content-Type:MIME-Version;
	bh=jeusKACVvSgLyQnrMOjCMWl7AvaUfS1sHGfoqkbrM3c=;
	b=yFFfji/E6/2i9y6rP56Zd+rFyVwYj4bwDELH4FkyoaYnpNjAeOHEVN2tAP+nzrE2qdepu7OVIlMT64DQ7p2FJySzglGfekSet423Wn5Nb7HtRO/dVv6Keg/hcboMh88fJxmGV98o5rzIpkLWJfB80OCDVu6rMI7jFT/JJclW0sE=
Authentication-Results: spf=none (sender IP is )
	smtp.mailfrom=Thomas.Lendacky@amd.com; 
Received: from tlendack-t1.amdoffice.net (165.204.77.1) by
	DM5PR12MB1148.namprd12.prod.outlook.com (10.168.236.143) with
	Microsoft SMTP Server (version=TLS1_2,
	cipher=TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA384_P384) id
	15.1.888.16; Thu, 16 Feb 2017 15:46:08 +0000
From: Tom Lendacky &lt;thomas.lendacky@amd.com&gt;
Subject: [RFC PATCH v4 18/28] x86: DMA support for memory encryption
To: &lt;linux-arch@vger.kernel.org&gt;, &lt;linux-efi@vger.kernel.org&gt;,
	&lt;kvm@vger.kernel.org&gt;, &lt;linux-doc@vger.kernel.org&gt;,
	&lt;x86@kernel.org&gt;, &lt;linux-kernel@vger.kernel.org&gt;,
	&lt;kasan-dev@googlegroups.com&gt;, &lt;linux-mm@kvack.org&gt;,
	&lt;iommu@lists.linux-foundation.org&gt;
CC: Rik van Riel &lt;riel@redhat.com&gt;,
	Radim =?utf-8?b?S3LEjW3DocWZ?= &lt;rkrcmar@redhat.com&gt;,
	Toshimitsu Kani &lt;toshi.kani@hpe.com&gt;, Arnd Bergmann &lt;arnd@arndb.de&gt;,
	Jonathan Corbet &lt;corbet@lwn.net&gt;,
	Matt Fleming &lt;matt@codeblueprint.co.uk&gt;,
	&quot;Michael S. Tsirkin&quot; &lt;mst@redhat.com&gt;, Joerg Roedel &lt;joro@8bytes.org&gt;,
	Konrad Rzeszutek Wilk &lt;konrad.wilk@oracle.com&gt;,
	Paolo Bonzini &lt;pbonzini@redhat.com&gt;,
	Brijesh Singh &lt;brijesh.singh@amd.com&gt;, Ingo Molnar &lt;mingo@redhat.com&gt;,
	Alexander Potapenko &lt;glider@google.com&gt;,
	Andy Lutomirski &lt;luto@kernel.org&gt;,
	&quot;H. Peter Anvin&quot; &lt;hpa@zytor.com&gt;, Borislav Petkov &lt;bp@alien8.de&gt;,
	Andrey Ryabinin &lt;aryabinin@virtuozzo.com&gt;,
	Thomas Gleixner &lt;tglx@linutronix.de&gt;,
	Larry Woodman &lt;lwoodman@redhat.com&gt;, Dmitry Vyukov &lt;dvyukov@google.com&gt;
Date: Thu, 16 Feb 2017 09:46:04 -0600
Message-ID: &lt;20170216154604.19244.69522.stgit@tlendack-t1.amdoffice.net&gt;
In-Reply-To: &lt;20170216154158.19244.66630.stgit@tlendack-t1.amdoffice.net&gt;
References: &lt;20170216154158.19244.66630.stgit@tlendack-t1.amdoffice.net&gt;
User-Agent: StGit/0.17.1-dirty
MIME-Version: 1.0
Content-Type: text/plain; charset=&quot;utf-8&quot;
Content-Transfer-Encoding: 7bit
X-Originating-IP: [165.204.77.1]
X-ClientProxiedBy: MWHPR21CA0023.namprd21.prod.outlook.com (10.173.47.33) To
	DM5PR12MB1148.namprd12.prod.outlook.com (10.168.236.143)
X-MS-Office365-Filtering-Correlation-Id: 5eec0880-73b5-43ad-ff52-08d45682eec2
X-MS-Office365-Filtering-HT: Tenant
X-Microsoft-Antispam: UriScan:; BCL:0; PCL:0; RULEID:(22001)(48565401081);
	SRVR:DM5PR12MB1148; 
X-Microsoft-Exchange-Diagnostics: 1; DM5PR12MB1148;
	3:nHo4Fo6avJxrvZBgTMucst5Ed+URHs3Io4r7Ffd7DhHG+8yohiMROpBd8KZ62O0yz5W+u/98zcSJLli/jpVo6fq7DZzSf68Fo6zEU+DHA23eWvITWLX5cJPa8zukcLifa3GIHGOkDaTPGKf7NfJmDy1FlaCElphkYY3yttxaxAau308gAyDwLDlFAsbJqGn9BWP89/YfEUOMC5VNNSgYpKlhoAgrUa6eYpSzYOW6OmoKGMKH4z7jRrbu6J8vR59/Ilzk4Xt8qKzJSkBIVqy5HfP8G1SffD4V/Q5CCahR8DU=;
	25:g8Kjl41HWgyXMnWirW492Ug8IW8qwwLg7QIkGq3wriiUWneNdqZV6Z/Cy37AZiUz7wy5PiqBQg1Osjzf0QYpUOlR9lCxgKFgJnYo1ng3l2E7MPEvfzhTQz2/RDPKHImCF92DGfI9LsCthbkeCeshV+pCzbyC4DNkWrkxofbGrCTSXGTtgHMZC+BGyRb+HA4M9h2zATz+zPTauQaorss5IcLOwMeABSEVwmLMVNjMQdqgazp3IRDHlIj9SlTttzMUNStzUxRFTNcTuSM/C4yk5beSUg50oTsd0Mz98xEmizhGPTxRKNPJ3QkABgLW2U6PbNihcSYpeOpln0OYJ4EJD30ecFkGgCo0lwtNWV8XvO9HTAyU57xqoXNupO0klaF4yK7TQdwfQBygc5Vhdo55KezchnNob024n9lDegKPQl4ryyg2J5YOJeQSTaR/n6+GiHCpPF04W5L3locESTYChw==
X-Microsoft-Exchange-Diagnostics: 1; DM5PR12MB1148;
	31:uZ1WrFy6cmP/aZoKlrWPoPtxvDxRFkAhkYNFErDbm3WLI6riDJNdftYNqJ/7ZOJcA1GHay50CCMGFQFLrb4BFaGZbasMUoC22L/jScNB2x/R0V8QOlqf1g+vIUi7pbUjKIurudiuhRrjMMX+KXK14dC1KZYBnJBiK8atEPgM6tjJD2zUyBkCOh6PjAEWssnZ+tVqnjNDgeXF/yxWYM6nVM4wZmrg6RnBUMwk1x1BNdo=;
	20:Voa8kHvDrqD/dpK7sUQw26f08nf+kimCnlGqofGHyvLazsME9gIN+2IyvCq/DcrEYSSMrRaZ8YG8Aj4u6sjGZ6C0L/Do+k38RDCXBp6iO/DT+7aLZC5MdBA7SpDtRNfAtmXco/a6eMVSKLxu+2qYMX9iR7sErCU8aIeJV6MFZXYvZyNRBmJ3FTHB/cxVjNiZC8W3XpXgNlR5Oc/pung1Jp4ZAYiGFLjqpi4gBjTK4g91W+XK9yMqGDn85M0YQMsNUXdyanD7N27Eahy5Zwt4PTg5B1BRCAhP1OHg3+mHMw7oZ1o+Y3EUFW+xie5yBqsmofHU7aJzRHwsVyuwiAaDTAfIlpRZZzfe9LGgTpUp/dB1oSoFEPGdRXP39frD8l1/wqd5t3jJnVKMTbe+rbFNY+ExObQKmVnB9qIOv6yrqWpTPUutSlVwNIE6wZtTkF3NaxAYw4WTA5xY7h8i+5acsHwCsghVVP7LkylZpNWP2vSBqD0XQnjmsHTWKDRvbWrD
X-Microsoft-Antispam-PRVS: &lt;DM5PR12MB114861449615D9E5C13B5995EC5A0@DM5PR12MB1148.namprd12.prod.outlook.com&gt;
X-Exchange-Antispam-Report-Test: UriScan:(767451399110);
X-Exchange-Antispam-Report-CFA-Test: BCL:0; PCL:0;
	RULEID:(6040375)(601004)(2401047)(5005006)(8121501046)(10201501046)(3002001)(6055026)(6041248)(20161123564025)(20161123562025)(20161123555025)(20161123558025)(20161123560025)(6072148);
	SRVR:DM5PR12MB1148; BCL:0; PCL:0; RULEID:; SRVR:DM5PR12MB1148;
X-Microsoft-Exchange-Diagnostics: 1; DM5PR12MB1148;
	4:ueDgRfNcBsEILlP3qCcOHUVfzYurKujITNrFB19rSamUKEUwH6+jn5zGO4jYGcLQkCDJ3rRAWQ9e9m8j/M3VUPXaYlftlildnUN9CSGy3uDNDsDHmHj1s8MMM7jWHH0fLuI4PPVWVunostVkOsUu9AopdkZvTb1PSII3SsWs/SCbyCAJPly91bZyidg1EgH9r8yDi/g6zOUJxGVHKATUNos8DjEwbKAQH+DzNMtam7aMUlU1TknQhjN8RUqknuuFHCyztpK47X65FSlw21oOLUMQwW4cWyzIewhP6LMweG9BO7DuUjb232WAGDRMWAMZOi6tb1SEfrSZimL4/stYqvaAiRpAmuEN1Db6Uu2I6fFAjOxQ9vLwdrIXqzw+/AJkQojj8tBCKkvTvCQMvJFYWI7FRoPuRzUqQ9KROXc92NSuR5TyBCZhvAcRYcV2QwsHFtcBW2DqNZAXYccxZqtoDGh0ra0Y9rkBF7Q4ZYcOL5rFoikWrTsvXZZp7yUqvPKr9m3peRMHRRZkcIkPNvOV6OToZnoNiiDEqnT+tp/u16QQJyejNnLRZQ2BLH5581Dn4zfjDoT9/xrIx3zvZzwkqveiEaryErxO5Uy7pQE/QqsV/pibiMlEDMmOOWdeOtzN5f3lp6VatslPRT8dCUZHck8JARbmy7mvcTTlT1+NovU=
X-Forefront-PRVS: 0220D4B98D
X-Forefront-Antispam-Report: SFV:NSPM;
	SFS:(10009020)(4630300001)(6009001)(7916002)(39860400002)(39410400002)(39450400003)(39850400002)(39840400002)(199003)(189002)(50466002)(2201001)(103116003)(66066001)(33646002)(53936002)(86362001)(23676002)(7416002)(105586002)(106356001)(69596002)(6506006)(50986999)(389900003)(92566002)(97746001)(81166006)(68736007)(81156014)(8676002)(25786008)(101416001)(1076002)(54356999)(47776003)(42186005)(7736002)(305945005)(189998001)(6666003)(83506001)(230700001)(3846002)(4326007)(2906002)(53416004)(5660300001)(54906002)(9686003)(4001350100001)(76176999)(2950100002)(55016002)(6116002)(97736004)(38730400002)(71626007)(217873001);
	DIR:OUT; SFP:1101; SCL:1; SRVR:DM5PR12MB1148;
	H:tlendack-t1.amdoffice.net; FPR:; SPF:None; PTR:InfoNoRecords;
	A:1; MX:1; LANG:en; 
Received-SPF: None (protection.outlook.com: amd.com does not designate
	permitted sender hosts)
X-Microsoft-Exchange-Diagnostics: =?utf-8?B?MTtETTVQUjEyTUIxMTQ4OzIzOlVXTzM5YnRHQUEzUGd5YnhHU2I1d1paYThk?=
	=?utf-8?B?T1dIUFNieldHOXRHUHFmZDVoOEt5Uy9jbWNmYkNWVFVSdFdCcnIzS0VMS1Fs?=
	=?utf-8?B?UDQxZStqSmZWRmQ3WnVUMFBTdlFVVnVGSFhRVHZVdDEyM3I0K2E3U2J2N2xV?=
	=?utf-8?B?Tm9wTjVGRUFZNnd6blloUjJrTmJjcHdNK3pDYm1LZFpaNWhIUjBTRElLREdU?=
	=?utf-8?B?WVYzdlpMZG1QMTlvV1p5QmNnSCtFN0xxVEhBbER5UnNua2VZb1pRQ1RpOXRo?=
	=?utf-8?B?bmppWnpxL01RYTZnZWRsbzJPU2JqUnNsRVA5NU4xOVNEc1hEekhjeTVoZzB6?=
	=?utf-8?B?QlJMM0xOczgwMTBJa0hyUjJwNjhrQy8wR2NueDM2bG56UDZUaWMwZUxZT2ln?=
	=?utf-8?B?NTk4cXRHK3NVUlMrVFZjSGpYeDVBSDE3K1NBOXZRbkc5SXdPTTZqUlk0V01x?=
	=?utf-8?B?dHhadittNHBhb05uWFRFeXlGZjhHMHowVGxxR3lUSXV6dDB5Ui9nVUtiWFM4?=
	=?utf-8?B?Y0lhV1BFcU1CY3V4NnBaS1pybWJXcE5oZE0wTDgyZHFhWWxVUmsxMWNSVkV2?=
	=?utf-8?B?ckNvOE5CYVdqMlh0a3g4ZHc4NWJXRlNhZDZ6QkM4RCt4S3dwcFE0TnZ3bS9E?=
	=?utf-8?B?TEZZQVRMSG9WeEZQeEVaYjNxaDRCOHdvcDBLeG13TDNuWjB6S3hkUHJrd2FK?=
	=?utf-8?B?S3RlMDFJWW1yeXhoa2liOHU3NnUwOXVpNHhScGJuM0pST01xN0JEWnRwalM1?=
	=?utf-8?B?dnRPb0xXQ3FMRFFtQTJCUE8rdVdURmNCdStRZGRCWEgvWGFzK1JVK0EydG1P?=
	=?utf-8?B?NE9SQVI0QkZCeXJWNlNvMnBuRnlweURxQ28rajQ5RHV2czBxdXNkTGV0OW4w?=
	=?utf-8?B?dENTL05mNmZTZStLMjVDeXNYcHR6NmdFVmJDTHpZR0dVY25WTmlVYklZK0d5?=
	=?utf-8?B?MUdPR1JVOFJtKytnbVc3QTBPSG9yb2JQYWJUM3hydXR0YXg2aXliLy8yTE4r?=
	=?utf-8?B?NkI4aXhGRzdCNEFvK0E5cC9wRktpTWxBZTF0cVVOMHF5ZGk2OTRJNmVPRWlq?=
	=?utf-8?B?N2d1bGdLbWd1RUhHeThUMkNSZWJUdVRQWXhsNkh1WlkwUEczc1JrMzFOTk9h?=
	=?utf-8?B?SWV0YkxKbk1qSFJmZ0pkUXh6bmhqSHBzMzN1Z2lRQ3hYWC9oc0xyaHhqeHVj?=
	=?utf-8?B?WEV4Mzd4RU5XRy9LMklHU2lEMmZFTGd6NE9uYlJCaDNtQUpDUDBQdU1CcUFR?=
	=?utf-8?B?aUdMVy96S0lxYUkvblBDYm84TlZwbHc4ZXRWZ1BidUFoVDJtbnhEUlQyTGsz?=
	=?utf-8?B?VUdOaFNPTDBnYkVtbzByZHZqelZ0bFdTQzN3eU5ZTkdOL2Zvb0pqN3c0QVZR?=
	=?utf-8?B?eWF4eEVOOWJuMjM4bHlNWFVNQVRCbmhDZDIvNjdOWXVhRlR3R1NrS2F4L1g4?=
	=?utf-8?B?MFhEM3RMbGtydUNMMFV1VTAzZEtDTndJZC9CRUZycnNLcEdDUG5lRi84VVdj?=
	=?utf-8?B?NGxUQU02MVh4ZnhuM2FJN0xPZ3o1SzhHQ3dHVStnZWt5b2dDcm9keG50Tk1o?=
	=?utf-8?B?VVBEY3R4bG9CZGwyc0dnQXJYQVg4TmFrcWo5Rnkycnc1SnlCRWM1OXpLWEls?=
	=?utf-8?B?OEEzcUk2K3pwRWVxV1FBWmlXRHZpRWQ5Ykdxa3dNQm05L01WK3E4dmhXMTRx?=
	=?utf-8?B?eDJLUTZRcTJ3Y010NGJIMEpmTlZzRVpKMGJTU2NDbzhmWHFnU3BERXhpek1z?=
	=?utf-8?B?RHVIRlo2WGVHM1JKeWM2cmVGYXdVTVppU01DT3RONmxOakFsaFk3TW5pU1pt?=
	=?utf-8?B?ZkVBOERqVUJvRUFVU0F3L1ZzUHpwQ0RuMVNKSUFJOEZ4ekVCWGJTL01lNVh6?=
	=?utf-8?B?bzRQTDgwYkdzdXdvSjlKa2tVK2dzNnc5b0hacjZiQS9NZDR2bTdGdVUwd2dT?=
	=?utf-8?B?YWNkYlpUNXBBPT0=?=
X-Microsoft-Exchange-Diagnostics: 1; DM5PR12MB1148;
	6:IJ1SrWU3Xw4I8h/bPVrixDfUnfJKYTwNj5FD5Ddpzer+AAl37C+5vj7X1w4ye7pivKf+HFSHgmRq2iwTG/2CZ74kwnDkK3vervj834nkLjJQLN1VKh6xfpqzZsWDhi34hZdRmlhRXGkBu/pfjn7wDC+2zrK8ulaU1FNxG4KaczjhIG/omFiHmNZCIC9f0qW+stvOESodGKDSyq3L3CQfP8xEFIKD0efYre2i1/Kl+d27m9pFqzIU+B+qGcT+GtpvPVhqasM4Bc7qRl1MByoRUtpBxeEdqKfGLoB+WDR3XXuwLRA8uXssVd/8/6/kOPdrroTsNfnCj+CQMmLP04ZBanPTH2/Y+RZBlXHczAW75OagzwofZMiWJZy6IAEdtmLjNRyNJtZJzJSzLtLnjkl3bHSkLWSvkqctZmki2JU1/so=;
	5:tghDEj8xc1Dd9iHn0raBPCK9DQx0HjUWUkS9e9kEX7+CJctpDV/OH7rekDDospoxucMnagvlszvowYVjvYcB25MTSQq4dw29gU7I7OZBLI6mnTWAj+ntvkRlW2RAqaBjbG5YVy9dDFdYlawzj5ZvOQ==;
	24:+OFDoLkkeJk/iv8vJwh4AOWHWqdCck3vJYbeogDl/lt3xqfZawrPEidJKwD8PCg/Tn0rI5HS+Gv2GCmYm4P0qJvTeYfF3rVs/eLLI38M1Nw=
SpamDiagnosticOutput: 1:99
SpamDiagnosticMetadata: NSPM
X-Microsoft-Exchange-Diagnostics: 1; DM5PR12MB1148;
	7:CNyPemjIot0c9oFH2YGwE9MMFUZ770E1FP04tIBpqxl18eCTrUCAJBknty5L00n1vqd1djAPis1BFhD2S2z9dPVB97gy46q7cn2TmhcbgqiTEZS28Rti/LPoJD99dXSSibZ7/OqdkIWL3M9yJ3MgFh7hhiJUVloL4f5PAOGsoEddDrJjP9USBSoMqxr/QqR1KgHS52INwK5e1nAL2OOimhgq7ixLcUuKjxiFj5/AROw54NmWWDEJmfm3fycswXTaluVokGGI31hLntxXqnxZ8DR3v/J5LIPX0wbv2dzHhiOjoB8hz6nglTVgq73Uw99DmcHajSdI3wmUYDm6B/QfNQ==;
	20:8/B3ob4swhOYRqRkKekYPA3D5UD4nlWhV2qdhrmq9F4AVPTQaMGjL0WtsdaOX6aqd6JFg+wf/qqNtNOPtFOXqqvrVY2v5PgOoOoUQOkkfy+X1FFUmf2CxSNc1RC+zYD0VGGcJYKkIYYuQvQvinPxpm1rOTTyguAkVW66ygK/LayCJUZYcaVg1uReZhivz2K4+7Ww1wmB/7sL8eAYw3398LqeOgOxzFKEmdMBwRciXdCKbvyjOLJX4Omvea2iXbXT
X-OriginatorOrg: amd.com
X-MS-Exchange-CrossTenant-OriginalArrivalTime: 16 Feb 2017 15:46:08.8472
	(UTC)
X-MS-Exchange-CrossTenant-FromEntityHeader: Hosted
X-MS-Exchange-Transport-CrossTenantHeadersStamped: DM5PR12MB1148
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=80801">Tom Lendacky</a> - Feb. 16, 2017, 3:46 p.m.</div>
<pre class="content">
Since DMA addresses will effectively look like 48-bit addresses when the
memory encryption mask is set, SWIOTLB is needed if the DMA mask of the
device performing the DMA does not support 48-bits. SWIOTLB will be
initialized to create decrypted bounce buffers for use by these devices.
<span class="signed-off-by">
Signed-off-by: Tom Lendacky &lt;thomas.lendacky@amd.com&gt;</span>
---
 arch/x86/include/asm/dma-mapping.h |    5 ++-
 arch/x86/include/asm/mem_encrypt.h |    5 +++
 arch/x86/kernel/pci-dma.c          |   11 +++++--
 arch/x86/kernel/pci-nommu.c        |    2 +
 arch/x86/kernel/pci-swiotlb.c      |    8 ++++-
 arch/x86/mm/mem_encrypt.c          |   22 ++++++++++++++
 include/linux/swiotlb.h            |    1 +
 init/main.c                        |   13 ++++++++
 lib/swiotlb.c                      |   56 +++++++++++++++++++++++++++++++-----
 9 files changed, 106 insertions(+), 17 deletions(-)
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=7500">Borislav Petkov</a> - Feb. 25, 2017, 5:10 p.m.</div>
<pre class="content">
On Thu, Feb 16, 2017 at 09:46:04AM -0600, Tom Lendacky wrote:
<span class="quote">&gt; Since DMA addresses will effectively look like 48-bit addresses when the</span>
<span class="quote">&gt; memory encryption mask is set, SWIOTLB is needed if the DMA mask of the</span>
<span class="quote">&gt; device performing the DMA does not support 48-bits. SWIOTLB will be</span>
<span class="quote">&gt; initialized to create decrypted bounce buffers for use by these devices.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Signed-off-by: Tom Lendacky &lt;thomas.lendacky@amd.com&gt;</span>
<span class="quote">&gt; ---</span>

Just nitpicks below...
<span class="quote">
&gt; diff --git a/arch/x86/mm/mem_encrypt.c b/arch/x86/mm/mem_encrypt.c</span>
<span class="quote">&gt; index ec548e9..a46bcf4 100644</span>
<span class="quote">&gt; --- a/arch/x86/mm/mem_encrypt.c</span>
<span class="quote">&gt; +++ b/arch/x86/mm/mem_encrypt.c</span>
<span class="quote">&gt; @@ -13,11 +13,14 @@</span>
<span class="quote">&gt;  #include &lt;linux/linkage.h&gt;</span>
<span class="quote">&gt;  #include &lt;linux/init.h&gt;</span>
<span class="quote">&gt;  #include &lt;linux/mm.h&gt;</span>
<span class="quote">&gt; +#include &lt;linux/dma-mapping.h&gt;</span>
<span class="quote">&gt; +#include &lt;linux/swiotlb.h&gt;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  #include &lt;asm/tlbflush.h&gt;</span>
<span class="quote">&gt;  #include &lt;asm/fixmap.h&gt;</span>
<span class="quote">&gt;  #include &lt;asm/setup.h&gt;</span>
<span class="quote">&gt;  #include &lt;asm/bootparam.h&gt;</span>
<span class="quote">&gt; +#include &lt;asm/cacheflush.h&gt;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  extern pmdval_t early_pmd_flags;</span>
<span class="quote">&gt;  int __init __early_make_pgtable(unsigned long, pmdval_t);</span>
<span class="quote">&gt; @@ -192,3 +195,22 @@ void __init sme_early_init(void)</span>
<span class="quote">&gt;  	for (i = 0; i &lt; ARRAY_SIZE(protection_map); i++)</span>
<span class="quote">&gt;  		protection_map[i] = pgprot_encrypted(protection_map[i]);</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +/* Architecture __weak replacement functions */</span>
<span class="quote">&gt; +void __init mem_encrypt_init(void)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	if (!sme_me_mask)</span>

	    !sme_active()

no?

Unless we&#39;re going to be switching SME dynamically at run time?
<span class="quote">
&gt; +		return;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	/* Call into SWIOTLB to update the SWIOTLB DMA buffers */</span>
<span class="quote">&gt; +	swiotlb_update_mem_attributes();</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +void swiotlb_set_mem_attributes(void *vaddr, unsigned long size)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	WARN(PAGE_ALIGN(size) != size,</span>
<span class="quote">&gt; +	     &quot;size is not page aligned (%#lx)\n&quot;, size);</span>

&quot;page-aligned&quot; I guess.
<span class="quote">
&gt; +</span>
<span class="quote">&gt; +	/* Make the SWIOTLB buffer area decrypted */</span>
<span class="quote">&gt; +	set_memory_decrypted((unsigned long)vaddr, size &gt;&gt; PAGE_SHIFT);</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; diff --git a/include/linux/swiotlb.h b/include/linux/swiotlb.h</span>
<span class="quote">&gt; index 4ee479f..15e7160 100644</span>
<span class="quote">&gt; --- a/include/linux/swiotlb.h</span>
<span class="quote">&gt; +++ b/include/linux/swiotlb.h</span>
<span class="quote">&gt; @@ -35,6 +35,7 @@ enum swiotlb_force {</span>
<span class="quote">&gt;  extern unsigned long swiotlb_nr_tbl(void);</span>
<span class="quote">&gt;  unsigned long swiotlb_size_or_default(void);</span>
<span class="quote">&gt;  extern int swiotlb_late_init_with_tbl(char *tlb, unsigned long nslabs);</span>
<span class="quote">&gt; +extern void __init swiotlb_update_mem_attributes(void);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  /*</span>
<span class="quote">&gt;   * Enumeration for sync targets</span>
<span class="quote">&gt; diff --git a/init/main.c b/init/main.c</span>
<span class="quote">&gt; index 8222caa..ba13f8f 100644</span>
<span class="quote">&gt; --- a/init/main.c</span>
<span class="quote">&gt; +++ b/init/main.c</span>
<span class="quote">&gt; @@ -466,6 +466,10 @@ void __init __weak thread_stack_cache_init(void)</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;  #endif</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; +void __init __weak mem_encrypt_init(void)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt;  /*</span>
<span class="quote">&gt;   * Set up kernel memory allocators</span>
<span class="quote">&gt;   */</span>
<span class="quote">&gt; @@ -614,6 +618,15 @@ asmlinkage __visible void __init start_kernel(void)</span>
<span class="quote">&gt;  	 */</span>
<span class="quote">&gt;  	locking_selftest();</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; +	/*</span>
<span class="quote">&gt; +	 * This needs to be called before any devices perform DMA</span>
<span class="quote">&gt; +	 * operations that might use the swiotlb bounce buffers.</span>

					 SWIOTLB
<span class="quote">
&gt; +	 * This call will mark the bounce buffers as decrypted so</span>
<span class="quote">&gt; +	 * that their usage will not cause &quot;plain-text&quot; data to be</span>
<span class="quote">&gt; +	 * decrypted when accessed.</span>
<span class="quote">&gt; +	 */</span>
<span class="quote">&gt; +	mem_encrypt_init();</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt;  #ifdef CONFIG_BLK_DEV_INITRD</span>
<span class="quote">&gt;  	if (initrd_start &amp;&amp; !initrd_below_start_ok &amp;&amp;</span>
<span class="quote">&gt;  	    page_to_pfn(virt_to_page((void *)initrd_start)) &lt; min_low_pfn) {</span>
<span class="quote">&gt; diff --git a/lib/swiotlb.c b/lib/swiotlb.c</span>
<span class="quote">&gt; index a8d74a7..c463067 100644</span>
<span class="quote">&gt; --- a/lib/swiotlb.c</span>
<span class="quote">&gt; +++ b/lib/swiotlb.c</span>
<span class="quote">&gt; @@ -30,6 +30,7 @@</span>
<span class="quote">&gt;  #include &lt;linux/highmem.h&gt;</span>
<span class="quote">&gt;  #include &lt;linux/gfp.h&gt;</span>
<span class="quote">&gt;  #include &lt;linux/scatterlist.h&gt;</span>
<span class="quote">&gt; +#include &lt;linux/mem_encrypt.h&gt;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  #include &lt;asm/io.h&gt;</span>
<span class="quote">&gt;  #include &lt;asm/dma.h&gt;</span>
<span class="quote">&gt; @@ -155,6 +156,17 @@ unsigned long swiotlb_size_or_default(void)</span>
<span class="quote">&gt;  	return size ? size : (IO_TLB_DEFAULT_SIZE);</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; +void __weak swiotlb_set_mem_attributes(void *vaddr, unsigned long size)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +/* For swiotlb, clear memory encryption mask from dma addresses */</span>
<span class="quote">&gt; +static dma_addr_t swiotlb_phys_to_dma(struct device *hwdev,</span>
<span class="quote">&gt; +				      phys_addr_t address)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	return phys_to_dma(hwdev, address) &amp; ~sme_me_mask;</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt;  /* Note that this doesn&#39;t work with highmem page */</span>
<span class="quote">&gt;  static dma_addr_t swiotlb_virt_to_bus(struct device *hwdev,</span>
<span class="quote">&gt;  				      volatile void *address)</span>
<span class="quote">&gt; @@ -183,6 +195,31 @@ void swiotlb_print_info(void)</span>
<span class="quote">&gt;  	       bytes &gt;&gt; 20, vstart, vend - 1);</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; +/*</span>
<span class="quote">&gt; + * Early SWIOTLB allocation may be to early to allow an architecture to</span>

				      too
<span class="quote">
&gt; + * perform the desired operations.  This function allows the architecture to</span>
<span class="quote">&gt; + * call SWIOTLB when the operations are possible.  This function needs to be</span>

s/This function/It/
<span class="quote">
&gt; + * called before the SWIOTLB memory is used.</span>
<span class="quote">&gt; + */</span>
<span class="quote">&gt; +void __init swiotlb_update_mem_attributes(void)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	void *vaddr;</span>
<span class="quote">&gt; +	unsigned long bytes;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	if (no_iotlb_memory || late_alloc)</span>
<span class="quote">&gt; +		return;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	vaddr = phys_to_virt(io_tlb_start);</span>
<span class="quote">&gt; +	bytes = PAGE_ALIGN(io_tlb_nslabs &lt;&lt; IO_TLB_SHIFT);</span>
<span class="quote">&gt; +	swiotlb_set_mem_attributes(vaddr, bytes);</span>
<span class="quote">&gt; +	memset(vaddr, 0, bytes);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	vaddr = phys_to_virt(io_tlb_overflow_buffer);</span>
<span class="quote">&gt; +	bytes = PAGE_ALIGN(io_tlb_overflow);</span>
<span class="quote">&gt; +	swiotlb_set_mem_attributes(vaddr, bytes);</span>
<span class="quote">&gt; +	memset(vaddr, 0, bytes);</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt;  int __init swiotlb_init_with_tbl(char *tlb, unsigned long nslabs, int verbose)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	void *v_overflow_buffer;</span>
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=80801">Tom Lendacky</a> - March 6, 2017, 5:47 p.m.</div>
<pre class="content">
On 2/25/2017 11:10 AM, Borislav Petkov wrote:
<span class="quote">&gt; On Thu, Feb 16, 2017 at 09:46:04AM -0600, Tom Lendacky wrote:</span>
<span class="quote">&gt;&gt; Since DMA addresses will effectively look like 48-bit addresses when the</span>
<span class="quote">&gt;&gt; memory encryption mask is set, SWIOTLB is needed if the DMA mask of the</span>
<span class="quote">&gt;&gt; device performing the DMA does not support 48-bits. SWIOTLB will be</span>
<span class="quote">&gt;&gt; initialized to create decrypted bounce buffers for use by these devices.</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; Signed-off-by: Tom Lendacky &lt;thomas.lendacky@amd.com&gt;</span>
<span class="quote">&gt;&gt; ---</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; Just nitpicks below...</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;&gt; diff --git a/arch/x86/mm/mem_encrypt.c b/arch/x86/mm/mem_encrypt.c</span>
<span class="quote">&gt;&gt; index ec548e9..a46bcf4 100644</span>
<span class="quote">&gt;&gt; --- a/arch/x86/mm/mem_encrypt.c</span>
<span class="quote">&gt;&gt; +++ b/arch/x86/mm/mem_encrypt.c</span>
<span class="quote">&gt;&gt; @@ -13,11 +13,14 @@</span>
<span class="quote">&gt;&gt;  #include &lt;linux/linkage.h&gt;</span>
<span class="quote">&gt;&gt;  #include &lt;linux/init.h&gt;</span>
<span class="quote">&gt;&gt;  #include &lt;linux/mm.h&gt;</span>
<span class="quote">&gt;&gt; +#include &lt;linux/dma-mapping.h&gt;</span>
<span class="quote">&gt;&gt; +#include &lt;linux/swiotlb.h&gt;</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt;  #include &lt;asm/tlbflush.h&gt;</span>
<span class="quote">&gt;&gt;  #include &lt;asm/fixmap.h&gt;</span>
<span class="quote">&gt;&gt;  #include &lt;asm/setup.h&gt;</span>
<span class="quote">&gt;&gt;  #include &lt;asm/bootparam.h&gt;</span>
<span class="quote">&gt;&gt; +#include &lt;asm/cacheflush.h&gt;</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt;  extern pmdval_t early_pmd_flags;</span>
<span class="quote">&gt;&gt;  int __init __early_make_pgtable(unsigned long, pmdval_t);</span>
<span class="quote">&gt;&gt; @@ -192,3 +195,22 @@ void __init sme_early_init(void)</span>
<span class="quote">&gt;&gt;  	for (i = 0; i &lt; ARRAY_SIZE(protection_map); i++)</span>
<span class="quote">&gt;&gt;  		protection_map[i] = pgprot_encrypted(protection_map[i]);</span>
<span class="quote">&gt;&gt;  }</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +/* Architecture __weak replacement functions */</span>
<span class="quote">&gt;&gt; +void __init mem_encrypt_init(void)</span>
<span class="quote">&gt;&gt; +{</span>
<span class="quote">&gt;&gt; +	if (!sme_me_mask)</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; 	    !sme_active()</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; no?</span>

I was probably looking ahead to SEV on this one. Basically if the
sme_me_mask is non-zero we will want to make SWIOTLB decrypted.
<span class="quote">
&gt;</span>
<span class="quote">&gt; Unless we&#39;re going to be switching SME dynamically at run time?</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;&gt; +		return;</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +	/* Call into SWIOTLB to update the SWIOTLB DMA buffers */</span>
<span class="quote">&gt;&gt; +	swiotlb_update_mem_attributes();</span>
<span class="quote">&gt;&gt; +}</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +void swiotlb_set_mem_attributes(void *vaddr, unsigned long size)</span>
<span class="quote">&gt;&gt; +{</span>
<span class="quote">&gt;&gt; +	WARN(PAGE_ALIGN(size) != size,</span>
<span class="quote">&gt;&gt; +	     &quot;size is not page aligned (%#lx)\n&quot;, size);</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; &quot;page-aligned&quot; I guess.</span>

Ok.
<span class="quote">
&gt;</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +	/* Make the SWIOTLB buffer area decrypted */</span>
<span class="quote">&gt;&gt; +	set_memory_decrypted((unsigned long)vaddr, size &gt;&gt; PAGE_SHIFT);</span>
<span class="quote">&gt;&gt; +}</span>
<span class="quote">&gt;&gt; diff --git a/include/linux/swiotlb.h b/include/linux/swiotlb.h</span>
<span class="quote">&gt;&gt; index 4ee479f..15e7160 100644</span>
<span class="quote">&gt;&gt; --- a/include/linux/swiotlb.h</span>
<span class="quote">&gt;&gt; +++ b/include/linux/swiotlb.h</span>
<span class="quote">&gt;&gt; @@ -35,6 +35,7 @@ enum swiotlb_force {</span>
<span class="quote">&gt;&gt;  extern unsigned long swiotlb_nr_tbl(void);</span>
<span class="quote">&gt;&gt;  unsigned long swiotlb_size_or_default(void);</span>
<span class="quote">&gt;&gt;  extern int swiotlb_late_init_with_tbl(char *tlb, unsigned long nslabs);</span>
<span class="quote">&gt;&gt; +extern void __init swiotlb_update_mem_attributes(void);</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt;  /*</span>
<span class="quote">&gt;&gt;   * Enumeration for sync targets</span>
<span class="quote">&gt;&gt; diff --git a/init/main.c b/init/main.c</span>
<span class="quote">&gt;&gt; index 8222caa..ba13f8f 100644</span>
<span class="quote">&gt;&gt; --- a/init/main.c</span>
<span class="quote">&gt;&gt; +++ b/init/main.c</span>
<span class="quote">&gt;&gt; @@ -466,6 +466,10 @@ void __init __weak thread_stack_cache_init(void)</span>
<span class="quote">&gt;&gt;  }</span>
<span class="quote">&gt;&gt;  #endif</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; +void __init __weak mem_encrypt_init(void)</span>
<span class="quote">&gt;&gt; +{</span>
<span class="quote">&gt;&gt; +}</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt;  /*</span>
<span class="quote">&gt;&gt;   * Set up kernel memory allocators</span>
<span class="quote">&gt;&gt;   */</span>
<span class="quote">&gt;&gt; @@ -614,6 +618,15 @@ asmlinkage __visible void __init start_kernel(void)</span>
<span class="quote">&gt;&gt;  	 */</span>
<span class="quote">&gt;&gt;  	locking_selftest();</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; +	/*</span>
<span class="quote">&gt;&gt; +	 * This needs to be called before any devices perform DMA</span>
<span class="quote">&gt;&gt; +	 * operations that might use the swiotlb bounce buffers.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; 					 SWIOTLB</span>

Ok.
<span class="quote">
&gt;</span>
<span class="quote">&gt;&gt; +	 * This call will mark the bounce buffers as decrypted so</span>
<span class="quote">&gt;&gt; +	 * that their usage will not cause &quot;plain-text&quot; data to be</span>
<span class="quote">&gt;&gt; +	 * decrypted when accessed.</span>
<span class="quote">&gt;&gt; +	 */</span>
<span class="quote">&gt;&gt; +	mem_encrypt_init();</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt;  #ifdef CONFIG_BLK_DEV_INITRD</span>
<span class="quote">&gt;&gt;  	if (initrd_start &amp;&amp; !initrd_below_start_ok &amp;&amp;</span>
<span class="quote">&gt;&gt;  	    page_to_pfn(virt_to_page((void *)initrd_start)) &lt; min_low_pfn) {</span>
<span class="quote">&gt;&gt; diff --git a/lib/swiotlb.c b/lib/swiotlb.c</span>
<span class="quote">&gt;&gt; index a8d74a7..c463067 100644</span>
<span class="quote">&gt;&gt; --- a/lib/swiotlb.c</span>
<span class="quote">&gt;&gt; +++ b/lib/swiotlb.c</span>
<span class="quote">&gt;&gt; @@ -30,6 +30,7 @@</span>
<span class="quote">&gt;&gt;  #include &lt;linux/highmem.h&gt;</span>
<span class="quote">&gt;&gt;  #include &lt;linux/gfp.h&gt;</span>
<span class="quote">&gt;&gt;  #include &lt;linux/scatterlist.h&gt;</span>
<span class="quote">&gt;&gt; +#include &lt;linux/mem_encrypt.h&gt;</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt;  #include &lt;asm/io.h&gt;</span>
<span class="quote">&gt;&gt;  #include &lt;asm/dma.h&gt;</span>
<span class="quote">&gt;&gt; @@ -155,6 +156,17 @@ unsigned long swiotlb_size_or_default(void)</span>
<span class="quote">&gt;&gt;  	return size ? size : (IO_TLB_DEFAULT_SIZE);</span>
<span class="quote">&gt;&gt;  }</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; +void __weak swiotlb_set_mem_attributes(void *vaddr, unsigned long size)</span>
<span class="quote">&gt;&gt; +{</span>
<span class="quote">&gt;&gt; +}</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +/* For swiotlb, clear memory encryption mask from dma addresses */</span>
<span class="quote">&gt;&gt; +static dma_addr_t swiotlb_phys_to_dma(struct device *hwdev,</span>
<span class="quote">&gt;&gt; +				      phys_addr_t address)</span>
<span class="quote">&gt;&gt; +{</span>
<span class="quote">&gt;&gt; +	return phys_to_dma(hwdev, address) &amp; ~sme_me_mask;</span>
<span class="quote">&gt;&gt; +}</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt;  /* Note that this doesn&#39;t work with highmem page */</span>
<span class="quote">&gt;&gt;  static dma_addr_t swiotlb_virt_to_bus(struct device *hwdev,</span>
<span class="quote">&gt;&gt;  				      volatile void *address)</span>
<span class="quote">&gt;&gt; @@ -183,6 +195,31 @@ void swiotlb_print_info(void)</span>
<span class="quote">&gt;&gt;  	       bytes &gt;&gt; 20, vstart, vend - 1);</span>
<span class="quote">&gt;&gt;  }</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; +/*</span>
<span class="quote">&gt;&gt; + * Early SWIOTLB allocation may be to early to allow an architecture to</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; 				      too</span>

Yup.
<span class="quote">
&gt;</span>
<span class="quote">&gt;&gt; + * perform the desired operations.  This function allows the architecture to</span>
<span class="quote">&gt;&gt; + * call SWIOTLB when the operations are possible.  This function needs to be</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; s/This function/It/</span>

Ok.

Thanks,
Tom
<span class="quote">
&gt;</span>
<span class="quote">&gt;&gt; + * called before the SWIOTLB memory is used.</span>
<span class="quote">&gt;&gt; + */</span>
<span class="quote">&gt;&gt; +void __init swiotlb_update_mem_attributes(void)</span>
<span class="quote">&gt;&gt; +{</span>
<span class="quote">&gt;&gt; +	void *vaddr;</span>
<span class="quote">&gt;&gt; +	unsigned long bytes;</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +	if (no_iotlb_memory || late_alloc)</span>
<span class="quote">&gt;&gt; +		return;</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +	vaddr = phys_to_virt(io_tlb_start);</span>
<span class="quote">&gt;&gt; +	bytes = PAGE_ALIGN(io_tlb_nslabs &lt;&lt; IO_TLB_SHIFT);</span>
<span class="quote">&gt;&gt; +	swiotlb_set_mem_attributes(vaddr, bytes);</span>
<span class="quote">&gt;&gt; +	memset(vaddr, 0, bytes);</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +	vaddr = phys_to_virt(io_tlb_overflow_buffer);</span>
<span class="quote">&gt;&gt; +	bytes = PAGE_ALIGN(io_tlb_overflow);</span>
<span class="quote">&gt;&gt; +	swiotlb_set_mem_attributes(vaddr, bytes);</span>
<span class="quote">&gt;&gt; +	memset(vaddr, 0, bytes);</span>
<span class="quote">&gt;&gt; +}</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt;  int __init swiotlb_init_with_tbl(char *tlb, unsigned long nslabs, int verbose)</span>
<span class="quote">&gt;&gt;  {</span>
<span class="quote">&gt;&gt;  	void *v_overflow_buffer;</span>
<span class="quote">&gt;</span>
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/arch/x86/include/asm/dma-mapping.h b/arch/x86/include/asm/dma-mapping.h</span>
<span class="p_header">index 4446162..c9cdcae 100644</span>
<span class="p_header">--- a/arch/x86/include/asm/dma-mapping.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/dma-mapping.h</span>
<span class="p_chunk">@@ -12,6 +12,7 @@</span> <span class="p_context"></span>
 #include &lt;asm/io.h&gt;
 #include &lt;asm/swiotlb.h&gt;
 #include &lt;linux/dma-contiguous.h&gt;
<span class="p_add">+#include &lt;asm/mem_encrypt.h&gt;</span>
 
 #ifdef CONFIG_ISA
 # define ISA_DMA_BIT_MASK DMA_BIT_MASK(24)
<span class="p_chunk">@@ -69,12 +70,12 @@</span> <span class="p_context"> static inline bool dma_capable(struct device *dev, dma_addr_t addr, size_t size)</span>
 
 static inline dma_addr_t phys_to_dma(struct device *dev, phys_addr_t paddr)
 {
<span class="p_del">-	return paddr;</span>
<span class="p_add">+	return paddr | sme_me_mask;</span>
 }
 
 static inline phys_addr_t dma_to_phys(struct device *dev, dma_addr_t daddr)
 {
<span class="p_del">-	return daddr;</span>
<span class="p_add">+	return daddr &amp; ~sme_me_mask;</span>
 }
 #endif /* CONFIG_X86_DMA_REMAP */
 
<span class="p_header">diff --git a/arch/x86/include/asm/mem_encrypt.h b/arch/x86/include/asm/mem_encrypt.h</span>
<span class="p_header">index e2b7364..87e816f 100644</span>
<span class="p_header">--- a/arch/x86/include/asm/mem_encrypt.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/mem_encrypt.h</span>
<span class="p_chunk">@@ -36,6 +36,11 @@</span> <span class="p_context"> void __init sme_early_decrypt(resource_size_t paddr,</span>
 
 void __init sme_early_init(void);
 
<span class="p_add">+/* Architecture __weak replacement functions */</span>
<span class="p_add">+void __init mem_encrypt_init(void);</span>
<span class="p_add">+</span>
<span class="p_add">+void swiotlb_set_mem_attributes(void *vaddr, unsigned long size);</span>
<span class="p_add">+</span>
 #define __sme_pa(x)		(__pa((x)) | sme_me_mask)
 #define __sme_pa_nodebug(x)	(__pa_nodebug((x)) | sme_me_mask)
 
<span class="p_header">diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c</span>
<span class="p_header">index d30c377..0ce28df 100644</span>
<span class="p_header">--- a/arch/x86/kernel/pci-dma.c</span>
<span class="p_header">+++ b/arch/x86/kernel/pci-dma.c</span>
<span class="p_chunk">@@ -92,9 +92,12 @@</span> <span class="p_context"> void *dma_generic_alloc_coherent(struct device *dev, size_t size,</span>
 	/* CMA can be used only in the context which permits sleeping */
 	if (gfpflags_allow_blocking(flag)) {
 		page = dma_alloc_from_contiguous(dev, count, get_order(size));
<span class="p_del">-		if (page &amp;&amp; page_to_phys(page) + size &gt; dma_mask) {</span>
<span class="p_del">-			dma_release_from_contiguous(dev, page, count);</span>
<span class="p_del">-			page = NULL;</span>
<span class="p_add">+		if (page) {</span>
<span class="p_add">+			addr = phys_to_dma(dev, page_to_phys(page));</span>
<span class="p_add">+			if (addr + size &gt; dma_mask) {</span>
<span class="p_add">+				dma_release_from_contiguous(dev, page, count);</span>
<span class="p_add">+				page = NULL;</span>
<span class="p_add">+			}</span>
 		}
 	}
 	/* fallback */
<span class="p_chunk">@@ -103,7 +106,7 @@</span> <span class="p_context"> void *dma_generic_alloc_coherent(struct device *dev, size_t size,</span>
 	if (!page)
 		return NULL;
 
<span class="p_del">-	addr = page_to_phys(page);</span>
<span class="p_add">+	addr = phys_to_dma(dev, page_to_phys(page));</span>
 	if (addr + size &gt; dma_mask) {
 		__free_pages(page, get_order(size));
 
<span class="p_header">diff --git a/arch/x86/kernel/pci-nommu.c b/arch/x86/kernel/pci-nommu.c</span>
<span class="p_header">index 00e71ce..922c10d 100644</span>
<span class="p_header">--- a/arch/x86/kernel/pci-nommu.c</span>
<span class="p_header">+++ b/arch/x86/kernel/pci-nommu.c</span>
<span class="p_chunk">@@ -30,7 +30,7 @@</span> <span class="p_context"> static dma_addr_t nommu_map_page(struct device *dev, struct page *page,</span>
 				 enum dma_data_direction dir,
 				 unsigned long attrs)
 {
<span class="p_del">-	dma_addr_t bus = page_to_phys(page) + offset;</span>
<span class="p_add">+	dma_addr_t bus = phys_to_dma(dev, page_to_phys(page)) + offset;</span>
 	WARN_ON(size == 0);
 	if (!check_addr(&quot;map_single&quot;, dev, bus, size))
 		return DMA_ERROR_CODE;
<span class="p_header">diff --git a/arch/x86/kernel/pci-swiotlb.c b/arch/x86/kernel/pci-swiotlb.c</span>
<span class="p_header">index 410efb2..a0677a9 100644</span>
<span class="p_header">--- a/arch/x86/kernel/pci-swiotlb.c</span>
<span class="p_header">+++ b/arch/x86/kernel/pci-swiotlb.c</span>
<span class="p_chunk">@@ -12,6 +12,8 @@</span> <span class="p_context"></span>
 #include &lt;asm/dma.h&gt;
 #include &lt;asm/xen/swiotlb-xen.h&gt;
 #include &lt;asm/iommu_table.h&gt;
<span class="p_add">+#include &lt;asm/mem_encrypt.h&gt;</span>
<span class="p_add">+</span>
 int swiotlb __read_mostly;
 
 void *x86_swiotlb_alloc_coherent(struct device *hwdev, size_t size,
<span class="p_chunk">@@ -64,11 +66,13 @@</span> <span class="p_context"> void x86_swiotlb_free_coherent(struct device *dev, size_t size,</span>
  * pci_swiotlb_detect_override - set swiotlb to 1 if necessary
  *
  * This returns non-zero if we are forced to use swiotlb (by the boot
<span class="p_del">- * option).</span>
<span class="p_add">+ * option). If memory encryption is enabled then swiotlb will be set</span>
<span class="p_add">+ * to 1 so that bounce buffers are allocated and used for devices that</span>
<span class="p_add">+ * do not support the addressing range required for the encryption mask.</span>
  */
 int __init pci_swiotlb_detect_override(void)
 {
<span class="p_del">-	if (swiotlb_force == SWIOTLB_FORCE)</span>
<span class="p_add">+	if ((swiotlb_force == SWIOTLB_FORCE) || sme_active())</span>
 		swiotlb = 1;
 
 	return swiotlb;
<span class="p_header">diff --git a/arch/x86/mm/mem_encrypt.c b/arch/x86/mm/mem_encrypt.c</span>
<span class="p_header">index ec548e9..a46bcf4 100644</span>
<span class="p_header">--- a/arch/x86/mm/mem_encrypt.c</span>
<span class="p_header">+++ b/arch/x86/mm/mem_encrypt.c</span>
<span class="p_chunk">@@ -13,11 +13,14 @@</span> <span class="p_context"></span>
 #include &lt;linux/linkage.h&gt;
 #include &lt;linux/init.h&gt;
 #include &lt;linux/mm.h&gt;
<span class="p_add">+#include &lt;linux/dma-mapping.h&gt;</span>
<span class="p_add">+#include &lt;linux/swiotlb.h&gt;</span>
 
 #include &lt;asm/tlbflush.h&gt;
 #include &lt;asm/fixmap.h&gt;
 #include &lt;asm/setup.h&gt;
 #include &lt;asm/bootparam.h&gt;
<span class="p_add">+#include &lt;asm/cacheflush.h&gt;</span>
 
 extern pmdval_t early_pmd_flags;
 int __init __early_make_pgtable(unsigned long, pmdval_t);
<span class="p_chunk">@@ -192,3 +195,22 @@</span> <span class="p_context"> void __init sme_early_init(void)</span>
 	for (i = 0; i &lt; ARRAY_SIZE(protection_map); i++)
 		protection_map[i] = pgprot_encrypted(protection_map[i]);
 }
<span class="p_add">+</span>
<span class="p_add">+/* Architecture __weak replacement functions */</span>
<span class="p_add">+void __init mem_encrypt_init(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	if (!sme_me_mask)</span>
<span class="p_add">+		return;</span>
<span class="p_add">+</span>
<span class="p_add">+	/* Call into SWIOTLB to update the SWIOTLB DMA buffers */</span>
<span class="p_add">+	swiotlb_update_mem_attributes();</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void swiotlb_set_mem_attributes(void *vaddr, unsigned long size)</span>
<span class="p_add">+{</span>
<span class="p_add">+	WARN(PAGE_ALIGN(size) != size,</span>
<span class="p_add">+	     &quot;size is not page aligned (%#lx)\n&quot;, size);</span>
<span class="p_add">+</span>
<span class="p_add">+	/* Make the SWIOTLB buffer area decrypted */</span>
<span class="p_add">+	set_memory_decrypted((unsigned long)vaddr, size &gt;&gt; PAGE_SHIFT);</span>
<span class="p_add">+}</span>
<span class="p_header">diff --git a/include/linux/swiotlb.h b/include/linux/swiotlb.h</span>
<span class="p_header">index 4ee479f..15e7160 100644</span>
<span class="p_header">--- a/include/linux/swiotlb.h</span>
<span class="p_header">+++ b/include/linux/swiotlb.h</span>
<span class="p_chunk">@@ -35,6 +35,7 @@</span> <span class="p_context"> enum swiotlb_force {</span>
 extern unsigned long swiotlb_nr_tbl(void);
 unsigned long swiotlb_size_or_default(void);
 extern int swiotlb_late_init_with_tbl(char *tlb, unsigned long nslabs);
<span class="p_add">+extern void __init swiotlb_update_mem_attributes(void);</span>
 
 /*
  * Enumeration for sync targets
<span class="p_header">diff --git a/init/main.c b/init/main.c</span>
<span class="p_header">index 8222caa..ba13f8f 100644</span>
<span class="p_header">--- a/init/main.c</span>
<span class="p_header">+++ b/init/main.c</span>
<span class="p_chunk">@@ -466,6 +466,10 @@</span> <span class="p_context"> void __init __weak thread_stack_cache_init(void)</span>
 }
 #endif
 
<span class="p_add">+void __init __weak mem_encrypt_init(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 /*
  * Set up kernel memory allocators
  */
<span class="p_chunk">@@ -614,6 +618,15 @@</span> <span class="p_context"> asmlinkage __visible void __init start_kernel(void)</span>
 	 */
 	locking_selftest();
 
<span class="p_add">+	/*</span>
<span class="p_add">+	 * This needs to be called before any devices perform DMA</span>
<span class="p_add">+	 * operations that might use the swiotlb bounce buffers.</span>
<span class="p_add">+	 * This call will mark the bounce buffers as decrypted so</span>
<span class="p_add">+	 * that their usage will not cause &quot;plain-text&quot; data to be</span>
<span class="p_add">+	 * decrypted when accessed.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	mem_encrypt_init();</span>
<span class="p_add">+</span>
 #ifdef CONFIG_BLK_DEV_INITRD
 	if (initrd_start &amp;&amp; !initrd_below_start_ok &amp;&amp;
 	    page_to_pfn(virt_to_page((void *)initrd_start)) &lt; min_low_pfn) {
<span class="p_header">diff --git a/lib/swiotlb.c b/lib/swiotlb.c</span>
<span class="p_header">index a8d74a7..c463067 100644</span>
<span class="p_header">--- a/lib/swiotlb.c</span>
<span class="p_header">+++ b/lib/swiotlb.c</span>
<span class="p_chunk">@@ -30,6 +30,7 @@</span> <span class="p_context"></span>
 #include &lt;linux/highmem.h&gt;
 #include &lt;linux/gfp.h&gt;
 #include &lt;linux/scatterlist.h&gt;
<span class="p_add">+#include &lt;linux/mem_encrypt.h&gt;</span>
 
 #include &lt;asm/io.h&gt;
 #include &lt;asm/dma.h&gt;
<span class="p_chunk">@@ -155,6 +156,17 @@</span> <span class="p_context"> unsigned long swiotlb_size_or_default(void)</span>
 	return size ? size : (IO_TLB_DEFAULT_SIZE);
 }
 
<span class="p_add">+void __weak swiotlb_set_mem_attributes(void *vaddr, unsigned long size)</span>
<span class="p_add">+{</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+/* For swiotlb, clear memory encryption mask from dma addresses */</span>
<span class="p_add">+static dma_addr_t swiotlb_phys_to_dma(struct device *hwdev,</span>
<span class="p_add">+				      phys_addr_t address)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return phys_to_dma(hwdev, address) &amp; ~sme_me_mask;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 /* Note that this doesn&#39;t work with highmem page */
 static dma_addr_t swiotlb_virt_to_bus(struct device *hwdev,
 				      volatile void *address)
<span class="p_chunk">@@ -183,6 +195,31 @@</span> <span class="p_context"> void swiotlb_print_info(void)</span>
 	       bytes &gt;&gt; 20, vstart, vend - 1);
 }
 
<span class="p_add">+/*</span>
<span class="p_add">+ * Early SWIOTLB allocation may be to early to allow an architecture to</span>
<span class="p_add">+ * perform the desired operations.  This function allows the architecture to</span>
<span class="p_add">+ * call SWIOTLB when the operations are possible.  This function needs to be</span>
<span class="p_add">+ * called before the SWIOTLB memory is used.</span>
<span class="p_add">+ */</span>
<span class="p_add">+void __init swiotlb_update_mem_attributes(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	void *vaddr;</span>
<span class="p_add">+	unsigned long bytes;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (no_iotlb_memory || late_alloc)</span>
<span class="p_add">+		return;</span>
<span class="p_add">+</span>
<span class="p_add">+	vaddr = phys_to_virt(io_tlb_start);</span>
<span class="p_add">+	bytes = PAGE_ALIGN(io_tlb_nslabs &lt;&lt; IO_TLB_SHIFT);</span>
<span class="p_add">+	swiotlb_set_mem_attributes(vaddr, bytes);</span>
<span class="p_add">+	memset(vaddr, 0, bytes);</span>
<span class="p_add">+</span>
<span class="p_add">+	vaddr = phys_to_virt(io_tlb_overflow_buffer);</span>
<span class="p_add">+	bytes = PAGE_ALIGN(io_tlb_overflow);</span>
<span class="p_add">+	swiotlb_set_mem_attributes(vaddr, bytes);</span>
<span class="p_add">+	memset(vaddr, 0, bytes);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 int __init swiotlb_init_with_tbl(char *tlb, unsigned long nslabs, int verbose)
 {
 	void *v_overflow_buffer;
<span class="p_chunk">@@ -320,6 +357,7 @@</span> <span class="p_context"> int __init swiotlb_init_with_tbl(char *tlb, unsigned long nslabs, int verbose)</span>
 	io_tlb_start = virt_to_phys(tlb);
 	io_tlb_end = io_tlb_start + bytes;
 
<span class="p_add">+	swiotlb_set_mem_attributes(tlb, bytes);</span>
 	memset(tlb, 0, bytes);
 
 	/*
<span class="p_chunk">@@ -330,6 +368,8 @@</span> <span class="p_context"> int __init swiotlb_init_with_tbl(char *tlb, unsigned long nslabs, int verbose)</span>
 	if (!v_overflow_buffer)
 		goto cleanup2;
 
<span class="p_add">+	swiotlb_set_mem_attributes(v_overflow_buffer, io_tlb_overflow);</span>
<span class="p_add">+	memset(v_overflow_buffer, 0, io_tlb_overflow);</span>
 	io_tlb_overflow_buffer = virt_to_phys(v_overflow_buffer);
 
 	/*
<span class="p_chunk">@@ -581,7 +621,7 @@</span> <span class="p_context"> phys_addr_t swiotlb_tbl_map_single(struct device *hwdev,</span>
 		return SWIOTLB_MAP_ERROR;
 	}
 
<span class="p_del">-	start_dma_addr = phys_to_dma(hwdev, io_tlb_start);</span>
<span class="p_add">+	start_dma_addr = swiotlb_phys_to_dma(hwdev, io_tlb_start);</span>
 	return swiotlb_tbl_map_single(hwdev, start_dma_addr, phys, size,
 				      dir, attrs);
 }
<span class="p_chunk">@@ -702,7 +742,7 @@</span> <span class="p_context"> void swiotlb_tbl_sync_single(struct device *hwdev, phys_addr_t tlb_addr,</span>
 			goto err_warn;
 
 		ret = phys_to_virt(paddr);
<span class="p_del">-		dev_addr = phys_to_dma(hwdev, paddr);</span>
<span class="p_add">+		dev_addr = swiotlb_phys_to_dma(hwdev, paddr);</span>
 
 		/* Confirm address can be DMA&#39;d by device */
 		if (dev_addr + size - 1 &gt; dma_mask) {
<span class="p_chunk">@@ -812,10 +852,10 @@</span> <span class="p_context"> dma_addr_t swiotlb_map_page(struct device *dev, struct page *page,</span>
 	map = map_single(dev, phys, size, dir, attrs);
 	if (map == SWIOTLB_MAP_ERROR) {
 		swiotlb_full(dev, size, dir, 1);
<span class="p_del">-		return phys_to_dma(dev, io_tlb_overflow_buffer);</span>
<span class="p_add">+		return swiotlb_phys_to_dma(dev, io_tlb_overflow_buffer);</span>
 	}
 
<span class="p_del">-	dev_addr = phys_to_dma(dev, map);</span>
<span class="p_add">+	dev_addr = swiotlb_phys_to_dma(dev, map);</span>
 
 	/* Ensure that the address returned is DMA&#39;ble */
 	if (dma_capable(dev, dev_addr, size))
<span class="p_chunk">@@ -824,7 +864,7 @@</span> <span class="p_context"> dma_addr_t swiotlb_map_page(struct device *dev, struct page *page,</span>
 	attrs |= DMA_ATTR_SKIP_CPU_SYNC;
 	swiotlb_tbl_unmap_single(dev, map, size, dir, attrs);
 
<span class="p_del">-	return phys_to_dma(dev, io_tlb_overflow_buffer);</span>
<span class="p_add">+	return swiotlb_phys_to_dma(dev, io_tlb_overflow_buffer);</span>
 }
 EXPORT_SYMBOL_GPL(swiotlb_map_page);
 
<span class="p_chunk">@@ -958,7 +998,7 @@</span> <span class="p_context"> void swiotlb_unmap_page(struct device *hwdev, dma_addr_t dev_addr,</span>
 				sg_dma_len(sgl) = 0;
 				return 0;
 			}
<span class="p_del">-			sg-&gt;dma_address = phys_to_dma(hwdev, map);</span>
<span class="p_add">+			sg-&gt;dma_address = swiotlb_phys_to_dma(hwdev, map);</span>
 		} else
 			sg-&gt;dma_address = dev_addr;
 		sg_dma_len(sg) = sg-&gt;length;
<span class="p_chunk">@@ -1026,7 +1066,7 @@</span> <span class="p_context"> void swiotlb_unmap_page(struct device *hwdev, dma_addr_t dev_addr,</span>
 int
 swiotlb_dma_mapping_error(struct device *hwdev, dma_addr_t dma_addr)
 {
<span class="p_del">-	return (dma_addr == phys_to_dma(hwdev, io_tlb_overflow_buffer));</span>
<span class="p_add">+	return (dma_addr == swiotlb_phys_to_dma(hwdev, io_tlb_overflow_buffer));</span>
 }
 EXPORT_SYMBOL(swiotlb_dma_mapping_error);
 
<span class="p_chunk">@@ -1039,6 +1079,6 @@</span> <span class="p_context"> void swiotlb_unmap_page(struct device *hwdev, dma_addr_t dev_addr,</span>
 int
 swiotlb_dma_supported(struct device *hwdev, u64 mask)
 {
<span class="p_del">-	return phys_to_dma(hwdev, io_tlb_end - 1) &lt;= mask;</span>
<span class="p_add">+	return swiotlb_phys_to_dma(hwdev, io_tlb_end - 1) &lt;= mask;</span>
 }
 EXPORT_SYMBOL(swiotlb_dma_supported);

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



