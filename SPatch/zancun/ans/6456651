
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>[RFC,v3,09/10] hugetlbfs: add hugetlbfs_fallocate() - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    [RFC,v3,09/10] hugetlbfs: add hugetlbfs_fallocate()</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=124511">Mike Kravetz</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>May 21, 2015, 3:47 p.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;1432223264-4414-10-git-send-email-mike.kravetz@oracle.com&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/6456651/mbox/"
   >mbox</a>
|
   <a href="/patch/6456651/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/6456651/">/patch/6456651/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
X-Original-To: patchwork-LKML@patchwork.kernel.org
Delivered-To: patchwork-parsemail@patchwork2.web.kernel.org
Received: from mail.kernel.org (mail.kernel.org [198.145.29.136])
	by patchwork2.web.kernel.org (Postfix) with ESMTP id 91380C0020
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Thu, 21 May 2015 15:50:26 +0000 (UTC)
Received: from mail.kernel.org (localhost [127.0.0.1])
	by mail.kernel.org (Postfix) with ESMTP id 7781920443
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Thu, 21 May 2015 15:50:25 +0000 (UTC)
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.kernel.org (Postfix) with ESMTP id 2E46A20457
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Thu, 21 May 2015 15:50:24 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S964787AbbEUPuP (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Thu, 21 May 2015 11:50:15 -0400
Received: from aserp1040.oracle.com ([141.146.126.69]:31843 &quot;EHLO
	aserp1040.oracle.com&quot; rhost-flags-OK-OK-OK-OK) by vger.kernel.org
	with ESMTP id S1756561AbbEUPuK (ORCPT
	&lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Thu, 21 May 2015 11:50:10 -0400
Received: from userv0021.oracle.com (userv0021.oracle.com [156.151.31.71])
	by aserp1040.oracle.com (Sentrion-MTA-4.3.2/Sentrion-MTA-4.3.2) with
	ESMTP id t4LFmVoW020419
	(version=TLSv1 cipher=DHE-RSA-AES256-SHA bits=256 verify=OK);
	Thu, 21 May 2015 15:48:32 GMT
Received: from aserv0121.oracle.com (aserv0121.oracle.com [141.146.126.235])
	by userv0021.oracle.com (8.13.8/8.13.8) with ESMTP id
	t4LFmVf7014995
	(version=TLSv1/SSLv3 cipher=DHE-RSA-AES256-SHA bits=256 verify=FAIL); 
	Thu, 21 May 2015 15:48:31 GMT
Received: from abhmp0018.oracle.com (abhmp0018.oracle.com [141.146.116.24])
	by aserv0121.oracle.com (8.13.8/8.13.8) with ESMTP id
	t4LFmVCo017838; Thu, 21 May 2015 15:48:31 GMT
Received: from monkey.oracle.com (/50.53.81.168)
	by default (Oracle Beehive Gateway v4.0)
	with ESMTP ; Thu, 21 May 2015 08:48:30 -0700
From: Mike Kravetz &lt;mike.kravetz@oracle.com&gt;
To: linux-mm@kvack.org, linux-kernel@vger.kernel.org
Cc: Dave Hansen &lt;dave.hansen@linux.intel.com&gt;,
	Naoya Horiguchi &lt;n-horiguchi@ah.jp.nec.com&gt;,
	David Rientjes &lt;rientjes@google.com&gt;, Hugh Dickins &lt;hughd@google.com&gt;,
	Davidlohr Bueso &lt;dave@stgolabs.net&gt;,
	Aneesh Kumar &lt;aneesh.kumar@linux.vnet.ibm.com&gt;,
	Hillf Danton &lt;hillf.zj@alibaba-inc.com&gt;,
	Christoph Hellwig &lt;hch@infradead.org&gt;,
	Mike Kravetz &lt;mike.kravetz@oracle.com&gt;
Subject: [RFC v3 PATCH 09/10] hugetlbfs: add hugetlbfs_fallocate()
Date: Thu, 21 May 2015 08:47:43 -0700
Message-Id: &lt;1432223264-4414-10-git-send-email-mike.kravetz@oracle.com&gt;
X-Mailer: git-send-email 2.1.0
In-Reply-To: &lt;1432223264-4414-1-git-send-email-mike.kravetz@oracle.com&gt;
References: &lt;1432223264-4414-1-git-send-email-mike.kravetz@oracle.com&gt;
X-Source-IP: userv0021.oracle.com [156.151.31.71]
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Spam-Status: No, score=-6.9 required=5.0 tests=BAYES_00, RCVD_IN_DNSWL_HI, 
	T_RP_MATCHES_RCVD,
	UNPARSEABLE_RELAY autolearn=unavailable version=3.3.1
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on mail.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=124511">Mike Kravetz</a> - May 21, 2015, 3:47 p.m.</div>
<pre class="content">
This is based on the shmem version, but it has diverged quite
a bit.  We have no swap to worry about, nor the new file sealing.
Add synchronication via the fault mutex table to coordinate
page faults,  fallocate allocation and fallocate hole punch.

What this allows us to do is move physical memory in and out of
a hugetlbfs file without having it mapped.  This also gives us
the ability to support MADV_REMOVE since it is currently
implemented using fallocate().  MADV_REMOVE lets madvise() remove
pages from the middle of a hugetlbfs file, which wasn&#39;t possible
before.

hugetlbfs fallocate only operates on whole huge pages.

Based-on code-by: Dave Hansen &lt;dave.hansen@linux.intel.com&gt;
<span class="signed-off-by">Signed-off-by: Mike Kravetz &lt;mike.kravetz@oracle.com&gt;</span>
---
 fs/hugetlbfs/inode.c    | 169 +++++++++++++++++++++++++++++++++++++++++++++++-
 include/linux/hugetlb.h |   3 +
 mm/hugetlb.c            |   2 +-
 3 files changed, 172 insertions(+), 2 deletions(-)
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=4407">Naoya Horiguchi</a> - May 26, 2015, 6:54 a.m.</div>
<pre class="content">
On Thu, May 21, 2015 at 08:47:43AM -0700, Mike Kravetz wrote:
<span class="quote">&gt; This is based on the shmem version, but it has diverged quite</span>
<span class="quote">&gt; a bit.  We have no swap to worry about, nor the new file sealing.</span>
<span class="quote">&gt; Add synchronication via the fault mutex table to coordinate</span>
<span class="quote">&gt; page faults,  fallocate allocation and fallocate hole punch.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; What this allows us to do is move physical memory in and out of</span>
<span class="quote">&gt; a hugetlbfs file without having it mapped.  This also gives us</span>
<span class="quote">&gt; the ability to support MADV_REMOVE since it is currently</span>
<span class="quote">&gt; implemented using fallocate().  MADV_REMOVE lets madvise() remove</span>
<span class="quote">&gt; pages from the middle of a hugetlbfs file, which wasn&#39;t possible</span>
<span class="quote">&gt; before.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; hugetlbfs fallocate only operates on whole huge pages.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Based-on code-by: Dave Hansen &lt;dave.hansen@linux.intel.com&gt;</span>
<span class="quote">&gt; Signed-off-by: Mike Kravetz &lt;mike.kravetz@oracle.com&gt;</span>

This patch changes the behavior of user API, so please update manpage of
fallocate(2).
<span class="quote">
&gt; ---</span>
<span class="quote">&gt;  fs/hugetlbfs/inode.c    | 169 +++++++++++++++++++++++++++++++++++++++++++++++-</span>
<span class="quote">&gt;  include/linux/hugetlb.h |   3 +</span>
<span class="quote">&gt;  mm/hugetlb.c            |   2 +-</span>
<span class="quote">&gt;  3 files changed, 172 insertions(+), 2 deletions(-)</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; diff --git a/fs/hugetlbfs/inode.c b/fs/hugetlbfs/inode.c</span>
<span class="quote">&gt; index dfa88a5..4b1535f 100644</span>
<span class="quote">&gt; --- a/fs/hugetlbfs/inode.c</span>
<span class="quote">&gt; +++ b/fs/hugetlbfs/inode.c</span>
<span class="quote">&gt; @@ -12,6 +12,7 @@</span>
<span class="quote">&gt;  #include &lt;linux/thread_info.h&gt;</span>
<span class="quote">&gt;  #include &lt;asm/current.h&gt;</span>
<span class="quote">&gt;  #include &lt;linux/sched.h&gt;		/* remove ASAP */</span>
<span class="quote">&gt; +#include &lt;linux/falloc.h&gt;</span>
<span class="quote">&gt;  #include &lt;linux/fs.h&gt;</span>
<span class="quote">&gt;  #include &lt;linux/mount.h&gt;</span>
<span class="quote">&gt;  #include &lt;linux/file.h&gt;</span>
<span class="quote">&gt; @@ -493,6 +494,171 @@ static int hugetlb_vmtruncate(struct inode *inode, loff_t offset)</span>
<span class="quote">&gt;  	return 0;</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; +static long hugetlbfs_punch_hole(struct inode *inode, loff_t offset, loff_t len)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	struct hstate *h = hstate_inode(inode);</span>
<span class="quote">&gt; +	unsigned long hpage_size = huge_page_size(h);</span>
<span class="quote">&gt; +	loff_t hole_start, hole_end;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	/*</span>
<span class="quote">&gt; +	 * For hole punch round up the beginning offset of the hole and</span>
<span class="quote">&gt; +	 * round down the end.</span>
<span class="quote">&gt; +	 */</span>
<span class="quote">&gt; +	hole_start = (offset + hpage_size - 1) &amp; huge_page_mask(h);</span>
<span class="quote">&gt; +	hole_end = (offset + len) &amp; huge_page_mask(h);</span>

We have round_up/round_up macro, so please use them here.
Then, it&#39;s self-descriptive, so you don&#39;t have to write comment.
<span class="quote">
&gt; +</span>
<span class="quote">&gt; +	if ((u64)hole_end &gt; (u64)hole_start) {</span>

Why is this casting to u64 necessary?
<span class="quote">
&gt; +		struct address_space *mapping = inode-&gt;i_mapping;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +		mutex_lock(&amp;inode-&gt;i_mutex);</span>
<span class="quote">&gt; +		i_mmap_lock_write(mapping);</span>
<span class="quote">&gt; +		if (!RB_EMPTY_ROOT(&amp;mapping-&gt;i_mmap))</span>
<span class="quote">&gt; +			hugetlb_vmdelete_list(&amp;mapping-&gt;i_mmap,</span>
<span class="quote">&gt; +						hole_start &gt;&gt; PAGE_SHIFT,</span>
<span class="quote">&gt; +						hole_end  &gt;&gt; PAGE_SHIFT);</span>
<span class="quote">&gt; +		i_mmap_unlock_write(mapping);</span>
<span class="quote">&gt; +		remove_inode_hugepages(inode, hole_start, hole_end);</span>
<span class="quote">&gt; +		mutex_unlock(&amp;inode-&gt;i_mutex);</span>
<span class="quote">&gt; +	}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	return 0;</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +static long hugetlbfs_fallocate(struct file *file, int mode, loff_t offset,</span>
<span class="quote">&gt; +				loff_t len)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	struct inode *inode = file_inode(file);</span>
<span class="quote">&gt; +	struct address_space *mapping = inode-&gt;i_mapping;</span>
<span class="quote">&gt; +	struct hstate *h = hstate_inode(inode);</span>
<span class="quote">&gt; +	struct vm_area_struct pseudo_vma;</span>
<span class="quote">&gt; +	unsigned long hpage_size = huge_page_size(h);</span>
<span class="quote">&gt; +	unsigned long hpage_shift = huge_page_shift(h);</span>
<span class="quote">&gt; +	pgoff_t start, index, end;</span>
<span class="quote">&gt; +	int error;</span>
<span class="quote">&gt; +	u32 hash;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	if (mode &amp; ~(FALLOC_FL_KEEP_SIZE | FALLOC_FL_PUNCH_HOLE))</span>
<span class="quote">&gt; +		return -EOPNOTSUPP;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	if (mode &amp; FALLOC_FL_PUNCH_HOLE)</span>
<span class="quote">&gt; +		return hugetlbfs_punch_hole(inode, offset, len);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	/*</span>
<span class="quote">&gt; +	 * Default preallocate case.</span>
<span class="quote">&gt; +	 * For this range, start is rounded down and end is rounded up.</span>
<span class="quote">&gt; +	 */</span>
<span class="quote">&gt; +	start = offset &gt;&gt; hpage_shift;</span>
<span class="quote">&gt; +	end = (offset + len + hpage_size - 1) &gt;&gt; hpage_shift;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	mutex_lock(&amp;inode-&gt;i_mutex);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	/* We need to check rlimit even when FALLOC_FL_KEEP_SIZE */</span>
<span class="quote">&gt; +	error = inode_newsize_ok(inode, offset + len);</span>
<span class="quote">&gt; +	if (error)</span>
<span class="quote">&gt; +		goto out;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	/*</span>
<span class="quote">&gt; +	 * Initialize a pseudo vma that just contains the policy used</span>
<span class="quote">&gt; +	 * when allocating the huge pages.  The actual policy field</span>
<span class="quote">&gt; +	 * (vm_policy) is determined based on the index in the loop below.</span>
<span class="quote">&gt; +	 */</span>
<span class="quote">&gt; +	memset(&amp;pseudo_vma, 0, sizeof(struct vm_area_struct));</span>
<span class="quote">&gt; +	pseudo_vma.vm_start = 0;</span>
<span class="quote">&gt; +	pseudo_vma.vm_flags |= (VM_HUGETLB | VM_MAYSHARE | VM_SHARED);</span>

Maybe &#39;|&#39; isn&#39;t necessary.
<span class="quote">
&gt; +	pseudo_vma.vm_file = file;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	for (index = start; index &lt; end; index++) {</span>
<span class="quote">&gt; +		/*</span>
<span class="quote">&gt; +		 * This is supposed to be the vaddr where the page is being</span>
<span class="quote">&gt; +		 * faulted in, but we have no vaddr here.</span>
<span class="quote">&gt; +		 */</span>
<span class="quote">&gt; +		struct page *page;</span>
<span class="quote">&gt; +		unsigned long addr;</span>
<span class="quote">&gt; +		int avoid_reserve = 0;</span>

avoid_reserve is referred only once and never changed, so no need to use
the variable?
<span class="quote">
&gt; +</span>
<span class="quote">&gt; +		cond_resched();</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +		/*</span>
<span class="quote">&gt; +		 * fallocate(2) manpage permits EINTR; we may have been</span>
<span class="quote">&gt; +		 * interrupted because we are using up too much memory.</span>
<span class="quote">&gt; +		 */</span>
<span class="quote">&gt; +		if (signal_pending(current)) {</span>
<span class="quote">&gt; +			error = -EINTR;</span>
<span class="quote">&gt; +			break;</span>
<span class="quote">&gt; +		}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +		/* Get policy based on index */</span>
<span class="quote">&gt; +		pseudo_vma.vm_policy =</span>
<span class="quote">&gt; +			mpol_shared_policy_lookup(&amp;HUGETLBFS_I(inode)-&gt;policy,</span>
<span class="quote">&gt; +							index);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +		/* addr is the offset within the file (zero based) */</span>
<span class="quote">&gt; +		addr = index * hpage_size;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +		/* mutex taken here, fault path and hole punch */</span>
<span class="quote">&gt; +		hash = hugetlb_fault_mutex_shared_hash(mapping, index);</span>
<span class="quote">&gt; +		hugetlb_fault_mutex_lock(hash);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +		/* see if page already exists to avoid alloc/free */</span>
<span class="quote">&gt; +		page = find_get_page(mapping, index);</span>
<span class="quote">&gt; +		if (page) {</span>
<span class="quote">&gt; +			put_page(page);</span>
<span class="quote">&gt; +			hugetlb_fault_mutex_unlock(hash);</span>

Don&#39;t you need mpol_cond_put() here?
<span class="quote">
&gt; +			continue;</span>
<span class="quote">&gt; +		}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +		page = alloc_huge_page(&amp;pseudo_vma, addr, avoid_reserve);</span>
<span class="quote">&gt; +		mpol_cond_put(pseudo_vma.vm_policy);</span>
<span class="quote">&gt; +		if (IS_ERR(page)) {</span>
<span class="quote">&gt; +			hugetlb_fault_mutex_unlock(hash);</span>
<span class="quote">&gt; +			error = PTR_ERR(page);</span>
<span class="quote">&gt; +			goto out;</span>
<span class="quote">&gt; +		}</span>
<span class="quote">&gt; +		clear_huge_page(page, addr, pages_per_huge_page(h));</span>
<span class="quote">&gt; +		__SetPageUptodate(page);</span>

Note that recently I added page_huge_active() to mark activeness of hugepages,
so when you rebased to v4.1-rc1+, please insert set_page_huge_active(page) here.
<span class="quote">
&gt; +		error = huge_add_to_page_cache(page, mapping, index);</span>
<span class="quote">&gt; +		if (error) {</span>
<span class="quote">&gt; +			/*</span>
<span class="quote">&gt; +			 * An entry already exists in the cache.  This implies</span>
<span class="quote">&gt; +			 * a region also existed in the reserve map at the time</span>
<span class="quote">&gt; +			 * the page was allocated above.  Therefore, no use</span>
<span class="quote">&gt; +			 * count was added to the subpool for the page.  Before</span>
<span class="quote">&gt; +			 * freeing the page, clear the subpool reference so</span>
<span class="quote">&gt; +			 * that the count is not decremented.</span>
<span class="quote">&gt; +			 */</span>
<span class="quote">&gt; +			set_page_private(page, 0);/* clear spool reference */</span>

This looks unclear to me. Which &quot;count&quot; do you refer to in the comment
&quot;no use count was added to the subpool&quot; or &quot;the count is not decremented&quot;?
I guess spool-&gt;used_hpages or spool-&gt;rsv_hpages, but alloc_huge_page() above
should call hugepage_subpool_get_pages(), so it&#39;s accounted, right?
Could you write comments more specifically?

Thanks,
Naoya Horiguchi
<span class="quote">
&gt; +			put_page(page);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +			hugetlb_fault_mutex_unlock(hash);</span>
<span class="quote">&gt; +			/* Keep going if we see an -EEXIST */</span>
<span class="quote">&gt; +			if (error == -EEXIST) {</span>
<span class="quote">&gt; +				error = 0;	/* do not return to user */</span>
<span class="quote">&gt; +				continue;</span>
<span class="quote">&gt; +			} else</span>
<span class="quote">&gt; +				goto out;</span>
<span class="quote">&gt; +		}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +		hugetlb_fault_mutex_unlock(hash);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +		/*</span>
<span class="quote">&gt; +		 * page_put due to reference from alloc_huge_page()</span>
<span class="quote">&gt; +		 * unlock_page because locked by add_to_page_cache()</span>
<span class="quote">&gt; +		 */</span>
<span class="quote">&gt; +		put_page(page);</span>
<span class="quote">&gt; +		unlock_page(page);</span>
<span class="quote">&gt; +	}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	if (!(mode &amp; FALLOC_FL_KEEP_SIZE) &amp;&amp; offset + len &gt; inode-&gt;i_size)</span>
<span class="quote">&gt; +		i_size_write(inode, offset + len);</span>
<span class="quote">&gt; +	inode-&gt;i_ctime = CURRENT_TIME;</span>
<span class="quote">&gt; +	spin_lock(&amp;inode-&gt;i_lock);</span>
<span class="quote">&gt; +	inode-&gt;i_private = NULL;</span>
<span class="quote">&gt; +	spin_unlock(&amp;inode-&gt;i_lock);</span>
<span class="quote">&gt; +out:</span>
<span class="quote">&gt; +	mutex_unlock(&amp;inode-&gt;i_mutex);</span>
<span class="quote">&gt; +	return error;</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt;  static int hugetlbfs_setattr(struct dentry *dentry, struct iattr *attr)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	struct inode *inode = dentry-&gt;d_inode;</span>
<span class="quote">&gt; @@ -804,7 +970,8 @@ const struct file_operations hugetlbfs_file_operations = {</span>
<span class="quote">&gt;  	.mmap			= hugetlbfs_file_mmap,</span>
<span class="quote">&gt;  	.fsync			= noop_fsync,</span>
<span class="quote">&gt;  	.get_unmapped_area	= hugetlb_get_unmapped_area,</span>
<span class="quote">&gt; -	.llseek		= default_llseek,</span>
<span class="quote">&gt; +	.llseek			= default_llseek,</span>
<span class="quote">&gt; +	.fallocate		= hugetlbfs_fallocate,</span>
<span class="quote">&gt;  };</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  static const struct inode_operations hugetlbfs_dir_inode_operations = {</span>
<span class="quote">&gt; diff --git a/include/linux/hugetlb.h b/include/linux/hugetlb.h</span>
<span class="quote">&gt; index 934f339..fa36b7a 100644</span>
<span class="quote">&gt; --- a/include/linux/hugetlb.h</span>
<span class="quote">&gt; +++ b/include/linux/hugetlb.h</span>
<span class="quote">&gt; @@ -327,6 +327,8 @@ struct huge_bootmem_page {</span>
<span class="quote">&gt;  #endif</span>
<span class="quote">&gt;  };</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; +struct page *alloc_huge_page(struct vm_area_struct *vma,</span>
<span class="quote">&gt; +				unsigned long addr, int avoid_reserve);</span>
<span class="quote">&gt;  struct page *alloc_huge_page_node(struct hstate *h, int nid);</span>
<span class="quote">&gt;  struct page *alloc_huge_page_noerr(struct vm_area_struct *vma,</span>
<span class="quote">&gt;  				unsigned long addr, int avoid_reserve);</span>
<span class="quote">&gt; @@ -481,6 +483,7 @@ static inline bool hugepages_supported(void)</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  #else	/* CONFIG_HUGETLB_PAGE */</span>
<span class="quote">&gt;  struct hstate {};</span>
<span class="quote">&gt; +#define alloc_huge_page(v, a, r) NULL</span>
<span class="quote">&gt;  #define alloc_huge_page_node(h, nid) NULL</span>
<span class="quote">&gt;  #define alloc_huge_page_noerr(v, a, r) NULL</span>
<span class="quote">&gt;  #define alloc_bootmem_huge_page(h) NULL</span>
<span class="quote">&gt; diff --git a/mm/hugetlb.c b/mm/hugetlb.c</span>
<span class="quote">&gt; index 94c6154..1e95038 100644</span>
<span class="quote">&gt; --- a/mm/hugetlb.c</span>
<span class="quote">&gt; +++ b/mm/hugetlb.c</span>
<span class="quote">&gt; @@ -1444,7 +1444,7 @@ static long vma_commit_reservation(struct hstate *h,</span>
<span class="quote">&gt;  /* Forward declaration */</span>
<span class="quote">&gt;  static int hugetlb_acct_memory(struct hstate *h, long delta);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; -static struct page *alloc_huge_page(struct vm_area_struct *vma,</span>
<span class="quote">&gt; +struct page *alloc_huge_page(struct vm_area_struct *vma,</span>
<span class="quote">&gt;  				    unsigned long addr, int avoid_reserve)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	struct hugepage_subpool *spool = subpool_vma(vma);</span>
<span class="quote">&gt; -- </span>
<span class="quote">&gt; 2.1.0</span>
<span class="quote">&gt; --</span>
To unsubscribe from this list: send the line &quot;unsubscribe linux-kernel&quot; in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
Please read the FAQ at  http://www.tux.org/lkml/
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=124511">Mike Kravetz</a> - May 26, 2015, 5:53 p.m.</div>
<pre class="content">
On 05/25/2015 11:54 PM, Naoya Horiguchi wrote:
<span class="quote">&gt; On Thu, May 21, 2015 at 08:47:43AM -0700, Mike Kravetz wrote:</span>
<span class="quote">&gt;&gt; This is based on the shmem version, but it has diverged quite</span>
<span class="quote">&gt;&gt; a bit.  We have no swap to worry about, nor the new file sealing.</span>
<span class="quote">&gt;&gt; Add synchronication via the fault mutex table to coordinate</span>
<span class="quote">&gt;&gt; page faults,  fallocate allocation and fallocate hole punch.</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; What this allows us to do is move physical memory in and out of</span>
<span class="quote">&gt;&gt; a hugetlbfs file without having it mapped.  This also gives us</span>
<span class="quote">&gt;&gt; the ability to support MADV_REMOVE since it is currently</span>
<span class="quote">&gt;&gt; implemented using fallocate().  MADV_REMOVE lets madvise() remove</span>
<span class="quote">&gt;&gt; pages from the middle of a hugetlbfs file, which wasn&#39;t possible</span>
<span class="quote">&gt;&gt; before.</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; hugetlbfs fallocate only operates on whole huge pages.</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; Based-on code-by: Dave Hansen &lt;dave.hansen@linux.intel.com&gt;</span>
<span class="quote">&gt;&gt; Signed-off-by: Mike Kravetz &lt;mike.kravetz@oracle.com&gt;</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; This patch changes the behavior of user API, so please update manpage of</span>
<span class="quote">&gt; fallocate(2).</span>

Will do.

Unfortunately, I believe hugetlbfs does not follow the man page
for ftruncate.  So, I will look to get that updated as well.
<span class="quote">
&gt;&gt; ---</span>
<span class="quote">&gt;&gt;   fs/hugetlbfs/inode.c    | 169 +++++++++++++++++++++++++++++++++++++++++++++++-</span>
<span class="quote">&gt;&gt;   include/linux/hugetlb.h |   3 +</span>
<span class="quote">&gt;&gt;   mm/hugetlb.c            |   2 +-</span>
<span class="quote">&gt;&gt;   3 files changed, 172 insertions(+), 2 deletions(-)</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; diff --git a/fs/hugetlbfs/inode.c b/fs/hugetlbfs/inode.c</span>
<span class="quote">&gt;&gt; index dfa88a5..4b1535f 100644</span>
<span class="quote">&gt;&gt; --- a/fs/hugetlbfs/inode.c</span>
<span class="quote">&gt;&gt; +++ b/fs/hugetlbfs/inode.c</span>
<span class="quote">&gt;&gt; @@ -12,6 +12,7 @@</span>
<span class="quote">&gt;&gt;   #include &lt;linux/thread_info.h&gt;</span>
<span class="quote">&gt;&gt;   #include &lt;asm/current.h&gt;</span>
<span class="quote">&gt;&gt;   #include &lt;linux/sched.h&gt;		/* remove ASAP */</span>
<span class="quote">&gt;&gt; +#include &lt;linux/falloc.h&gt;</span>
<span class="quote">&gt;&gt;   #include &lt;linux/fs.h&gt;</span>
<span class="quote">&gt;&gt;   #include &lt;linux/mount.h&gt;</span>
<span class="quote">&gt;&gt;   #include &lt;linux/file.h&gt;</span>
<span class="quote">&gt;&gt; @@ -493,6 +494,171 @@ static int hugetlb_vmtruncate(struct inode *inode, loff_t offset)</span>
<span class="quote">&gt;&gt;   	return 0;</span>
<span class="quote">&gt;&gt;   }</span>
<span class="quote">&gt;&gt;   </span>
<span class="quote">&gt;&gt; +static long hugetlbfs_punch_hole(struct inode *inode, loff_t offset, loff_t len)</span>
<span class="quote">&gt;&gt; +{</span>
<span class="quote">&gt;&gt; +	struct hstate *h = hstate_inode(inode);</span>
<span class="quote">&gt;&gt; +	unsigned long hpage_size = huge_page_size(h);</span>
<span class="quote">&gt;&gt; +	loff_t hole_start, hole_end;</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +	/*</span>
<span class="quote">&gt;&gt; +	 * For hole punch round up the beginning offset of the hole and</span>
<span class="quote">&gt;&gt; +	 * round down the end.</span>
<span class="quote">&gt;&gt; +	 */</span>
<span class="quote">&gt;&gt; +	hole_start = (offset + hpage_size - 1) &amp; huge_page_mask(h);</span>
<span class="quote">&gt;&gt; +	hole_end = (offset + len) &amp; huge_page_mask(h);</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; We have round_up/round_up macro, so please use them here.</span>
<span class="quote">&gt; Then, it&#39;s self-descriptive, so you don&#39;t have to write comment.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +	if ((u64)hole_end &gt; (u64)hole_start) {</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Why is this casting to u64 necessary?</span>

It is not necessary.  I will remove it.
<span class="quote">
&gt;&gt; +		struct address_space *mapping = inode-&gt;i_mapping;</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +		mutex_lock(&amp;inode-&gt;i_mutex);</span>
<span class="quote">&gt;&gt; +		i_mmap_lock_write(mapping);</span>
<span class="quote">&gt;&gt; +		if (!RB_EMPTY_ROOT(&amp;mapping-&gt;i_mmap))</span>
<span class="quote">&gt;&gt; +			hugetlb_vmdelete_list(&amp;mapping-&gt;i_mmap,</span>
<span class="quote">&gt;&gt; +						hole_start &gt;&gt; PAGE_SHIFT,</span>
<span class="quote">&gt;&gt; +						hole_end  &gt;&gt; PAGE_SHIFT);</span>
<span class="quote">&gt;&gt; +		i_mmap_unlock_write(mapping);</span>
<span class="quote">&gt;&gt; +		remove_inode_hugepages(inode, hole_start, hole_end);</span>
<span class="quote">&gt;&gt; +		mutex_unlock(&amp;inode-&gt;i_mutex);</span>
<span class="quote">&gt;&gt; +	}</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +	return 0;</span>
<span class="quote">&gt;&gt; +}</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +static long hugetlbfs_fallocate(struct file *file, int mode, loff_t offset,</span>
<span class="quote">&gt;&gt; +				loff_t len)</span>
<span class="quote">&gt;&gt; +{</span>
<span class="quote">&gt;&gt; +	struct inode *inode = file_inode(file);</span>
<span class="quote">&gt;&gt; +	struct address_space *mapping = inode-&gt;i_mapping;</span>
<span class="quote">&gt;&gt; +	struct hstate *h = hstate_inode(inode);</span>
<span class="quote">&gt;&gt; +	struct vm_area_struct pseudo_vma;</span>
<span class="quote">&gt;&gt; +	unsigned long hpage_size = huge_page_size(h);</span>
<span class="quote">&gt;&gt; +	unsigned long hpage_shift = huge_page_shift(h);</span>
<span class="quote">&gt;&gt; +	pgoff_t start, index, end;</span>
<span class="quote">&gt;&gt; +	int error;</span>
<span class="quote">&gt;&gt; +	u32 hash;</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +	if (mode &amp; ~(FALLOC_FL_KEEP_SIZE | FALLOC_FL_PUNCH_HOLE))</span>
<span class="quote">&gt;&gt; +		return -EOPNOTSUPP;</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +	if (mode &amp; FALLOC_FL_PUNCH_HOLE)</span>
<span class="quote">&gt;&gt; +		return hugetlbfs_punch_hole(inode, offset, len);</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +	/*</span>
<span class="quote">&gt;&gt; +	 * Default preallocate case.</span>
<span class="quote">&gt;&gt; +	 * For this range, start is rounded down and end is rounded up.</span>
<span class="quote">&gt;&gt; +	 */</span>
<span class="quote">&gt;&gt; +	start = offset &gt;&gt; hpage_shift;</span>
<span class="quote">&gt;&gt; +	end = (offset + len + hpage_size - 1) &gt;&gt; hpage_shift;</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +	mutex_lock(&amp;inode-&gt;i_mutex);</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +	/* We need to check rlimit even when FALLOC_FL_KEEP_SIZE */</span>
<span class="quote">&gt;&gt; +	error = inode_newsize_ok(inode, offset + len);</span>
<span class="quote">&gt;&gt; +	if (error)</span>
<span class="quote">&gt;&gt; +		goto out;</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +	/*</span>
<span class="quote">&gt;&gt; +	 * Initialize a pseudo vma that just contains the policy used</span>
<span class="quote">&gt;&gt; +	 * when allocating the huge pages.  The actual policy field</span>
<span class="quote">&gt;&gt; +	 * (vm_policy) is determined based on the index in the loop below.</span>
<span class="quote">&gt;&gt; +	 */</span>
<span class="quote">&gt;&gt; +	memset(&amp;pseudo_vma, 0, sizeof(struct vm_area_struct));</span>
<span class="quote">&gt;&gt; +	pseudo_vma.vm_start = 0;</span>
<span class="quote">&gt;&gt; +	pseudo_vma.vm_flags |= (VM_HUGETLB | VM_MAYSHARE | VM_SHARED);</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Maybe &#39;|&#39; isn&#39;t necessary.</span>

No, it is not necessary.  I will remove.
<span class="quote">
&gt;&gt; +	pseudo_vma.vm_file = file;</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +	for (index = start; index &lt; end; index++) {</span>
<span class="quote">&gt;&gt; +		/*</span>
<span class="quote">&gt;&gt; +		 * This is supposed to be the vaddr where the page is being</span>
<span class="quote">&gt;&gt; +		 * faulted in, but we have no vaddr here.</span>
<span class="quote">&gt;&gt; +		 */</span>
<span class="quote">&gt;&gt; +		struct page *page;</span>
<span class="quote">&gt;&gt; +		unsigned long addr;</span>
<span class="quote">&gt;&gt; +		int avoid_reserve = 0;</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; avoid_reserve is referred only once and never changed, so no need to use</span>
<span class="quote">&gt; the variable?</span>

It is not necessary.  I will remove it.
<span class="quote">
&gt;&gt; +</span>
<span class="quote">&gt;&gt; +		cond_resched();</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +		/*</span>
<span class="quote">&gt;&gt; +		 * fallocate(2) manpage permits EINTR; we may have been</span>
<span class="quote">&gt;&gt; +		 * interrupted because we are using up too much memory.</span>
<span class="quote">&gt;&gt; +		 */</span>
<span class="quote">&gt;&gt; +		if (signal_pending(current)) {</span>
<span class="quote">&gt;&gt; +			error = -EINTR;</span>
<span class="quote">&gt;&gt; +			break;</span>
<span class="quote">&gt;&gt; +		}</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +		/* Get policy based on index */</span>
<span class="quote">&gt;&gt; +		pseudo_vma.vm_policy =</span>
<span class="quote">&gt;&gt; +			mpol_shared_policy_lookup(&amp;HUGETLBFS_I(inode)-&gt;policy,</span>
<span class="quote">&gt;&gt; +							index);</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +		/* addr is the offset within the file (zero based) */</span>
<span class="quote">&gt;&gt; +		addr = index * hpage_size;</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +		/* mutex taken here, fault path and hole punch */</span>
<span class="quote">&gt;&gt; +		hash = hugetlb_fault_mutex_shared_hash(mapping, index);</span>
<span class="quote">&gt;&gt; +		hugetlb_fault_mutex_lock(hash);</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +		/* see if page already exists to avoid alloc/free */</span>
<span class="quote">&gt;&gt; +		page = find_get_page(mapping, index);</span>
<span class="quote">&gt;&gt; +		if (page) {</span>
<span class="quote">&gt;&gt; +			put_page(page);</span>
<span class="quote">&gt;&gt; +			hugetlb_fault_mutex_unlock(hash);</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Don&#39;t you need mpol_cond_put() here?</span>

Yes.  Thank you, I will add it.
<span class="quote">
&gt;&gt; +			continue;</span>
<span class="quote">&gt;&gt; +		}</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +		page = alloc_huge_page(&amp;pseudo_vma, addr, avoid_reserve);</span>
<span class="quote">&gt;&gt; +		mpol_cond_put(pseudo_vma.vm_policy);</span>
<span class="quote">&gt;&gt; +		if (IS_ERR(page)) {</span>
<span class="quote">&gt;&gt; +			hugetlb_fault_mutex_unlock(hash);</span>
<span class="quote">&gt;&gt; +			error = PTR_ERR(page);</span>
<span class="quote">&gt;&gt; +			goto out;</span>
<span class="quote">&gt;&gt; +		}</span>
<span class="quote">&gt;&gt; +		clear_huge_page(page, addr, pages_per_huge_page(h));</span>
<span class="quote">&gt;&gt; +		__SetPageUptodate(page);</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Note that recently I added page_huge_active() to mark activeness of hugepages,</span>
<span class="quote">&gt; so when you rebased to v4.1-rc1+, please insert set_page_huge_active(page) here.</span>
<span class="quote">&gt; </span>

Yes, I noticed your change.
<span class="quote">
&gt;&gt; +		error = huge_add_to_page_cache(page, mapping, index);</span>
<span class="quote">&gt;&gt; +		if (error) {</span>
<span class="quote">&gt;&gt; +			/*</span>
<span class="quote">&gt;&gt; +			 * An entry already exists in the cache.  This implies</span>
<span class="quote">&gt;&gt; +			 * a region also existed in the reserve map at the time</span>
<span class="quote">&gt;&gt; +			 * the page was allocated above.  Therefore, no use</span>
<span class="quote">&gt;&gt; +			 * count was added to the subpool for the page.  Before</span>
<span class="quote">&gt;&gt; +			 * freeing the page, clear the subpool reference so</span>
<span class="quote">&gt;&gt; +			 * that the count is not decremented.</span>
<span class="quote">&gt;&gt; +			 */</span>
<span class="quote">&gt;&gt; +			set_page_private(page, 0);/* clear spool reference */</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; This looks unclear to me. Which &quot;count&quot; do you refer to in the comment</span>
<span class="quote">&gt; &quot;no use count was added to the subpool&quot; or &quot;the count is not decremented&quot;?</span>
<span class="quote">&gt; I guess spool-&gt;used_hpages or spool-&gt;rsv_hpages, but alloc_huge_page() above</span>
<span class="quote">&gt; should call hugepage_subpool_get_pages(), so it&#39;s accounted, right?</span>
<span class="quote">&gt; Could you write comments more specifically?</span>

Yes, this is confusing.  As I am reexamining the code, I see that
it is incorrect.  This code may not be necessary.  It was there to
handle a race with page faults.  The code now uses the hugetlb fault
mutex table to synchronize with page faults.  I will do some more
work here and expect this confusing code to go away.

Thank you for your comments,
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/fs/hugetlbfs/inode.c b/fs/hugetlbfs/inode.c</span>
<span class="p_header">index dfa88a5..4b1535f 100644</span>
<span class="p_header">--- a/fs/hugetlbfs/inode.c</span>
<span class="p_header">+++ b/fs/hugetlbfs/inode.c</span>
<span class="p_chunk">@@ -12,6 +12,7 @@</span> <span class="p_context"></span>
 #include &lt;linux/thread_info.h&gt;
 #include &lt;asm/current.h&gt;
 #include &lt;linux/sched.h&gt;		/* remove ASAP */
<span class="p_add">+#include &lt;linux/falloc.h&gt;</span>
 #include &lt;linux/fs.h&gt;
 #include &lt;linux/mount.h&gt;
 #include &lt;linux/file.h&gt;
<span class="p_chunk">@@ -493,6 +494,171 @@</span> <span class="p_context"> static int hugetlb_vmtruncate(struct inode *inode, loff_t offset)</span>
 	return 0;
 }
 
<span class="p_add">+static long hugetlbfs_punch_hole(struct inode *inode, loff_t offset, loff_t len)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct hstate *h = hstate_inode(inode);</span>
<span class="p_add">+	unsigned long hpage_size = huge_page_size(h);</span>
<span class="p_add">+	loff_t hole_start, hole_end;</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * For hole punch round up the beginning offset of the hole and</span>
<span class="p_add">+	 * round down the end.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	hole_start = (offset + hpage_size - 1) &amp; huge_page_mask(h);</span>
<span class="p_add">+	hole_end = (offset + len) &amp; huge_page_mask(h);</span>
<span class="p_add">+</span>
<span class="p_add">+	if ((u64)hole_end &gt; (u64)hole_start) {</span>
<span class="p_add">+		struct address_space *mapping = inode-&gt;i_mapping;</span>
<span class="p_add">+</span>
<span class="p_add">+		mutex_lock(&amp;inode-&gt;i_mutex);</span>
<span class="p_add">+		i_mmap_lock_write(mapping);</span>
<span class="p_add">+		if (!RB_EMPTY_ROOT(&amp;mapping-&gt;i_mmap))</span>
<span class="p_add">+			hugetlb_vmdelete_list(&amp;mapping-&gt;i_mmap,</span>
<span class="p_add">+						hole_start &gt;&gt; PAGE_SHIFT,</span>
<span class="p_add">+						hole_end  &gt;&gt; PAGE_SHIFT);</span>
<span class="p_add">+		i_mmap_unlock_write(mapping);</span>
<span class="p_add">+		remove_inode_hugepages(inode, hole_start, hole_end);</span>
<span class="p_add">+		mutex_unlock(&amp;inode-&gt;i_mutex);</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	return 0;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static long hugetlbfs_fallocate(struct file *file, int mode, loff_t offset,</span>
<span class="p_add">+				loff_t len)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct inode *inode = file_inode(file);</span>
<span class="p_add">+	struct address_space *mapping = inode-&gt;i_mapping;</span>
<span class="p_add">+	struct hstate *h = hstate_inode(inode);</span>
<span class="p_add">+	struct vm_area_struct pseudo_vma;</span>
<span class="p_add">+	unsigned long hpage_size = huge_page_size(h);</span>
<span class="p_add">+	unsigned long hpage_shift = huge_page_shift(h);</span>
<span class="p_add">+	pgoff_t start, index, end;</span>
<span class="p_add">+	int error;</span>
<span class="p_add">+	u32 hash;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (mode &amp; ~(FALLOC_FL_KEEP_SIZE | FALLOC_FL_PUNCH_HOLE))</span>
<span class="p_add">+		return -EOPNOTSUPP;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (mode &amp; FALLOC_FL_PUNCH_HOLE)</span>
<span class="p_add">+		return hugetlbfs_punch_hole(inode, offset, len);</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Default preallocate case.</span>
<span class="p_add">+	 * For this range, start is rounded down and end is rounded up.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	start = offset &gt;&gt; hpage_shift;</span>
<span class="p_add">+	end = (offset + len + hpage_size - 1) &gt;&gt; hpage_shift;</span>
<span class="p_add">+</span>
<span class="p_add">+	mutex_lock(&amp;inode-&gt;i_mutex);</span>
<span class="p_add">+</span>
<span class="p_add">+	/* We need to check rlimit even when FALLOC_FL_KEEP_SIZE */</span>
<span class="p_add">+	error = inode_newsize_ok(inode, offset + len);</span>
<span class="p_add">+	if (error)</span>
<span class="p_add">+		goto out;</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Initialize a pseudo vma that just contains the policy used</span>
<span class="p_add">+	 * when allocating the huge pages.  The actual policy field</span>
<span class="p_add">+	 * (vm_policy) is determined based on the index in the loop below.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	memset(&amp;pseudo_vma, 0, sizeof(struct vm_area_struct));</span>
<span class="p_add">+	pseudo_vma.vm_start = 0;</span>
<span class="p_add">+	pseudo_vma.vm_flags |= (VM_HUGETLB | VM_MAYSHARE | VM_SHARED);</span>
<span class="p_add">+	pseudo_vma.vm_file = file;</span>
<span class="p_add">+</span>
<span class="p_add">+	for (index = start; index &lt; end; index++) {</span>
<span class="p_add">+		/*</span>
<span class="p_add">+		 * This is supposed to be the vaddr where the page is being</span>
<span class="p_add">+		 * faulted in, but we have no vaddr here.</span>
<span class="p_add">+		 */</span>
<span class="p_add">+		struct page *page;</span>
<span class="p_add">+		unsigned long addr;</span>
<span class="p_add">+		int avoid_reserve = 0;</span>
<span class="p_add">+</span>
<span class="p_add">+		cond_resched();</span>
<span class="p_add">+</span>
<span class="p_add">+		/*</span>
<span class="p_add">+		 * fallocate(2) manpage permits EINTR; we may have been</span>
<span class="p_add">+		 * interrupted because we are using up too much memory.</span>
<span class="p_add">+		 */</span>
<span class="p_add">+		if (signal_pending(current)) {</span>
<span class="p_add">+			error = -EINTR;</span>
<span class="p_add">+			break;</span>
<span class="p_add">+		}</span>
<span class="p_add">+</span>
<span class="p_add">+		/* Get policy based on index */</span>
<span class="p_add">+		pseudo_vma.vm_policy =</span>
<span class="p_add">+			mpol_shared_policy_lookup(&amp;HUGETLBFS_I(inode)-&gt;policy,</span>
<span class="p_add">+							index);</span>
<span class="p_add">+</span>
<span class="p_add">+		/* addr is the offset within the file (zero based) */</span>
<span class="p_add">+		addr = index * hpage_size;</span>
<span class="p_add">+</span>
<span class="p_add">+		/* mutex taken here, fault path and hole punch */</span>
<span class="p_add">+		hash = hugetlb_fault_mutex_shared_hash(mapping, index);</span>
<span class="p_add">+		hugetlb_fault_mutex_lock(hash);</span>
<span class="p_add">+</span>
<span class="p_add">+		/* see if page already exists to avoid alloc/free */</span>
<span class="p_add">+		page = find_get_page(mapping, index);</span>
<span class="p_add">+		if (page) {</span>
<span class="p_add">+			put_page(page);</span>
<span class="p_add">+			hugetlb_fault_mutex_unlock(hash);</span>
<span class="p_add">+			continue;</span>
<span class="p_add">+		}</span>
<span class="p_add">+</span>
<span class="p_add">+		page = alloc_huge_page(&amp;pseudo_vma, addr, avoid_reserve);</span>
<span class="p_add">+		mpol_cond_put(pseudo_vma.vm_policy);</span>
<span class="p_add">+		if (IS_ERR(page)) {</span>
<span class="p_add">+			hugetlb_fault_mutex_unlock(hash);</span>
<span class="p_add">+			error = PTR_ERR(page);</span>
<span class="p_add">+			goto out;</span>
<span class="p_add">+		}</span>
<span class="p_add">+		clear_huge_page(page, addr, pages_per_huge_page(h));</span>
<span class="p_add">+		__SetPageUptodate(page);</span>
<span class="p_add">+		error = huge_add_to_page_cache(page, mapping, index);</span>
<span class="p_add">+		if (error) {</span>
<span class="p_add">+			/*</span>
<span class="p_add">+			 * An entry already exists in the cache.  This implies</span>
<span class="p_add">+			 * a region also existed in the reserve map at the time</span>
<span class="p_add">+			 * the page was allocated above.  Therefore, no use</span>
<span class="p_add">+			 * count was added to the subpool for the page.  Before</span>
<span class="p_add">+			 * freeing the page, clear the subpool reference so</span>
<span class="p_add">+			 * that the count is not decremented.</span>
<span class="p_add">+			 */</span>
<span class="p_add">+			set_page_private(page, 0);/* clear spool reference */</span>
<span class="p_add">+			put_page(page);</span>
<span class="p_add">+</span>
<span class="p_add">+			hugetlb_fault_mutex_unlock(hash);</span>
<span class="p_add">+			/* Keep going if we see an -EEXIST */</span>
<span class="p_add">+			if (error == -EEXIST) {</span>
<span class="p_add">+				error = 0;	/* do not return to user */</span>
<span class="p_add">+				continue;</span>
<span class="p_add">+			} else</span>
<span class="p_add">+				goto out;</span>
<span class="p_add">+		}</span>
<span class="p_add">+</span>
<span class="p_add">+		hugetlb_fault_mutex_unlock(hash);</span>
<span class="p_add">+</span>
<span class="p_add">+		/*</span>
<span class="p_add">+		 * page_put due to reference from alloc_huge_page()</span>
<span class="p_add">+		 * unlock_page because locked by add_to_page_cache()</span>
<span class="p_add">+		 */</span>
<span class="p_add">+		put_page(page);</span>
<span class="p_add">+		unlock_page(page);</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	if (!(mode &amp; FALLOC_FL_KEEP_SIZE) &amp;&amp; offset + len &gt; inode-&gt;i_size)</span>
<span class="p_add">+		i_size_write(inode, offset + len);</span>
<span class="p_add">+	inode-&gt;i_ctime = CURRENT_TIME;</span>
<span class="p_add">+	spin_lock(&amp;inode-&gt;i_lock);</span>
<span class="p_add">+	inode-&gt;i_private = NULL;</span>
<span class="p_add">+	spin_unlock(&amp;inode-&gt;i_lock);</span>
<span class="p_add">+out:</span>
<span class="p_add">+	mutex_unlock(&amp;inode-&gt;i_mutex);</span>
<span class="p_add">+	return error;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static int hugetlbfs_setattr(struct dentry *dentry, struct iattr *attr)
 {
 	struct inode *inode = dentry-&gt;d_inode;
<span class="p_chunk">@@ -804,7 +970,8 @@</span> <span class="p_context"> const struct file_operations hugetlbfs_file_operations = {</span>
 	.mmap			= hugetlbfs_file_mmap,
 	.fsync			= noop_fsync,
 	.get_unmapped_area	= hugetlb_get_unmapped_area,
<span class="p_del">-	.llseek		= default_llseek,</span>
<span class="p_add">+	.llseek			= default_llseek,</span>
<span class="p_add">+	.fallocate		= hugetlbfs_fallocate,</span>
 };
 
 static const struct inode_operations hugetlbfs_dir_inode_operations = {
<span class="p_header">diff --git a/include/linux/hugetlb.h b/include/linux/hugetlb.h</span>
<span class="p_header">index 934f339..fa36b7a 100644</span>
<span class="p_header">--- a/include/linux/hugetlb.h</span>
<span class="p_header">+++ b/include/linux/hugetlb.h</span>
<span class="p_chunk">@@ -327,6 +327,8 @@</span> <span class="p_context"> struct huge_bootmem_page {</span>
 #endif
 };
 
<span class="p_add">+struct page *alloc_huge_page(struct vm_area_struct *vma,</span>
<span class="p_add">+				unsigned long addr, int avoid_reserve);</span>
 struct page *alloc_huge_page_node(struct hstate *h, int nid);
 struct page *alloc_huge_page_noerr(struct vm_area_struct *vma,
 				unsigned long addr, int avoid_reserve);
<span class="p_chunk">@@ -481,6 +483,7 @@</span> <span class="p_context"> static inline bool hugepages_supported(void)</span>
 
 #else	/* CONFIG_HUGETLB_PAGE */
 struct hstate {};
<span class="p_add">+#define alloc_huge_page(v, a, r) NULL</span>
 #define alloc_huge_page_node(h, nid) NULL
 #define alloc_huge_page_noerr(v, a, r) NULL
 #define alloc_bootmem_huge_page(h) NULL
<span class="p_header">diff --git a/mm/hugetlb.c b/mm/hugetlb.c</span>
<span class="p_header">index 94c6154..1e95038 100644</span>
<span class="p_header">--- a/mm/hugetlb.c</span>
<span class="p_header">+++ b/mm/hugetlb.c</span>
<span class="p_chunk">@@ -1444,7 +1444,7 @@</span> <span class="p_context"> static long vma_commit_reservation(struct hstate *h,</span>
 /* Forward declaration */
 static int hugetlb_acct_memory(struct hstate *h, long delta);
 
<span class="p_del">-static struct page *alloc_huge_page(struct vm_area_struct *vma,</span>
<span class="p_add">+struct page *alloc_huge_page(struct vm_area_struct *vma,</span>
 				    unsigned long addr, int avoid_reserve)
 {
 	struct hugepage_subpool *spool = subpool_vma(vma);

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



