
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>[RFC,v3,03/10] mm/hugetlb: add region_del() to delete a specific range of entries - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    [RFC,v3,03/10] mm/hugetlb: add region_del() to delete a specific range of entries</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=124511">Mike Kravetz</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>May 21, 2015, 3:47 p.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;1432223264-4414-4-git-send-email-mike.kravetz@oracle.com&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/6456641/mbox/"
   >mbox</a>
|
   <a href="/patch/6456641/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/6456641/">/patch/6456641/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
X-Original-To: patchwork-LKML@patchwork.kernel.org
Delivered-To: patchwork-parsemail@patchwork2.web.kernel.org
Received: from mail.kernel.org (mail.kernel.org [198.145.29.136])
	by patchwork2.web.kernel.org (Postfix) with ESMTP id 11721C0020
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Thu, 21 May 2015 15:50:24 +0000 (UTC)
Received: from mail.kernel.org (localhost [127.0.0.1])
	by mail.kernel.org (Postfix) with ESMTP id 1AD8E20443
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Thu, 21 May 2015 15:50:23 +0000 (UTC)
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.kernel.org (Postfix) with ESMTP id DB8E220457
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Thu, 21 May 2015 15:50:21 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1756560AbbEUPt4 (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Thu, 21 May 2015 11:49:56 -0400
Received: from aserp1040.oracle.com ([141.146.126.69]:31637 &quot;EHLO
	aserp1040.oracle.com&quot; rhost-flags-OK-OK-OK-OK) by vger.kernel.org
	with ESMTP id S1756512AbbEUPtv (ORCPT
	&lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Thu, 21 May 2015 11:49:51 -0400
Received: from aserv0021.oracle.com (aserv0021.oracle.com [141.146.126.233])
	by aserp1040.oracle.com (Sentrion-MTA-4.3.2/Sentrion-MTA-4.3.2)
	with ESMTP id t4LFmDAx020106
	(version=TLSv1 cipher=DHE-RSA-AES256-SHA bits=256 verify=OK);
	Thu, 21 May 2015 15:48:13 GMT
Received: from aserv0122.oracle.com (aserv0122.oracle.com [141.146.126.236])
	by aserv0021.oracle.com (8.13.8/8.13.8) with ESMTP id
	t4LFmDRk010992
	(version=TLSv1/SSLv3 cipher=DHE-RSA-AES256-SHA bits=256 verify=FAIL); 
	Thu, 21 May 2015 15:48:13 GMT
Received: from abhmp0018.oracle.com (abhmp0018.oracle.com [141.146.116.24])
	by aserv0122.oracle.com (8.13.8/8.13.8) with ESMTP id
	t4LFmDdX025139; Thu, 21 May 2015 15:48:13 GMT
Received: from monkey.oracle.com (/50.53.81.168)
	by default (Oracle Beehive Gateway v4.0)
	with ESMTP ; Thu, 21 May 2015 08:48:13 -0700
From: Mike Kravetz &lt;mike.kravetz@oracle.com&gt;
To: linux-mm@kvack.org, linux-kernel@vger.kernel.org
Cc: Dave Hansen &lt;dave.hansen@linux.intel.com&gt;,
	Naoya Horiguchi &lt;n-horiguchi@ah.jp.nec.com&gt;,
	David Rientjes &lt;rientjes@google.com&gt;, Hugh Dickins &lt;hughd@google.com&gt;,
	Davidlohr Bueso &lt;dave@stgolabs.net&gt;,
	Aneesh Kumar &lt;aneesh.kumar@linux.vnet.ibm.com&gt;,
	Hillf Danton &lt;hillf.zj@alibaba-inc.com&gt;,
	Christoph Hellwig &lt;hch@infradead.org&gt;,
	Mike Kravetz &lt;mike.kravetz@oracle.com&gt;
Subject: [RFC v3 PATCH 03/10] mm/hugetlb: add region_del() to delete a
	specific range of entries
Date: Thu, 21 May 2015 08:47:37 -0700
Message-Id: &lt;1432223264-4414-4-git-send-email-mike.kravetz@oracle.com&gt;
X-Mailer: git-send-email 2.1.0
In-Reply-To: &lt;1432223264-4414-1-git-send-email-mike.kravetz@oracle.com&gt;
References: &lt;1432223264-4414-1-git-send-email-mike.kravetz@oracle.com&gt;
X-Source-IP: aserv0021.oracle.com [141.146.126.233]
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Spam-Status: No, score=-6.9 required=5.0 tests=BAYES_00, RCVD_IN_DNSWL_HI, 
	T_RP_MATCHES_RCVD,
	UNPARSEABLE_RELAY autolearn=unavailable version=3.3.1
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on mail.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=124511">Mike Kravetz</a> - May 21, 2015, 3:47 p.m.</div>
<pre class="content">
fallocate hole punch will want to remove a specific range of pages.
The existing region_truncate() routine deletes all region/reserve
map entries after a specified offset.  region_del() will provide
this same functionality if the end of region is specified as -1.
Hence, region_del() can replace region_truncate().

Unlike region_truncate(), region_del() can return an error in the
rare case where it can not allocate memory for a region descriptor.
This ONLY happens in the case where an existing region must be split.
Current callers passing -1 as end of range will never experience
this error and do not need to deal with error handling.  Future
callers of region_del() (such as fallocate hole punch) will need to
handle this error.  A routine hugetlb_fix_reserve_counts() is added
to assist in cleaning up if fallocate hole punch experiences this
type of error in region_del().
<span class="signed-off-by">
Signed-off-by: Mike Kravetz &lt;mike.kravetz@oracle.com&gt;</span>
---
 include/linux/hugetlb.h |  1 +
 mm/hugetlb.c            | 99 ++++++++++++++++++++++++++++++++++++++-----------
 2 files changed, 79 insertions(+), 21 deletions(-)
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=4407">Naoya Horiguchi</a> - May 22, 2015, 6:21 a.m.</div>
<pre class="content">
On Thu, May 21, 2015 at 08:47:37AM -0700, Mike Kravetz wrote:
<span class="quote">&gt; fallocate hole punch will want to remove a specific range of pages.</span>
<span class="quote">&gt; The existing region_truncate() routine deletes all region/reserve</span>
<span class="quote">&gt; map entries after a specified offset.  region_del() will provide</span>
<span class="quote">&gt; this same functionality if the end of region is specified as -1.</span>
<span class="quote">&gt; Hence, region_del() can replace region_truncate().</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Unlike region_truncate(), region_del() can return an error in the</span>
<span class="quote">&gt; rare case where it can not allocate memory for a region descriptor.</span>
<span class="quote">&gt; This ONLY happens in the case where an existing region must be split.</span>
<span class="quote">&gt; Current callers passing -1 as end of range will never experience</span>
<span class="quote">&gt; this error and do not need to deal with error handling.  Future</span>
<span class="quote">&gt; callers of region_del() (such as fallocate hole punch) will need to</span>
<span class="quote">&gt; handle this error.  A routine hugetlb_fix_reserve_counts() is added</span>
<span class="quote">&gt; to assist in cleaning up if fallocate hole punch experiences this</span>
<span class="quote">&gt; type of error in region_del().</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Signed-off-by: Mike Kravetz &lt;mike.kravetz@oracle.com&gt;</span>
<span class="quote">&gt; ---</span>
<span class="quote">&gt;  include/linux/hugetlb.h |  1 +</span>
<span class="quote">&gt;  mm/hugetlb.c            | 99 ++++++++++++++++++++++++++++++++++++++-----------</span>
<span class="quote">&gt;  2 files changed, 79 insertions(+), 21 deletions(-)</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; diff --git a/include/linux/hugetlb.h b/include/linux/hugetlb.h</span>
<span class="quote">&gt; index 7b57850..fd337f2 100644</span>
<span class="quote">&gt; --- a/include/linux/hugetlb.h</span>
<span class="quote">&gt; +++ b/include/linux/hugetlb.h</span>
<span class="quote">&gt; @@ -81,6 +81,7 @@ bool isolate_huge_page(struct page *page, struct list_head *list);</span>
<span class="quote">&gt;  void putback_active_hugepage(struct page *page);</span>
<span class="quote">&gt;  bool is_hugepage_active(struct page *page);</span>
<span class="quote">&gt;  void free_huge_page(struct page *page);</span>
<span class="quote">&gt; +void hugetlb_fix_reserve_counts(struct inode *inode, bool restore_reserve);</span>

This function is used in patch 6/10 for the first time,
so is it better to move the definition to that patch?
(this temporarily introduces &quot;defined but not used&quot; warning...)
<span class="quote">
&gt;  #ifdef CONFIG_ARCH_WANT_HUGE_PMD_SHARE</span>
<span class="quote">&gt;  pte_t *huge_pmd_share(struct mm_struct *mm, unsigned long addr, pud_t *pud);</span>
<span class="quote">&gt; diff --git a/mm/hugetlb.c b/mm/hugetlb.c</span>
<span class="quote">&gt; index 63f6d43..620cc9e 100644</span>
<span class="quote">&gt; --- a/mm/hugetlb.c</span>
<span class="quote">&gt; +++ b/mm/hugetlb.c</span>
<span class="quote">&gt; @@ -261,38 +261,74 @@ out_nrg:</span>
<span class="quote">&gt;  	return chg;</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; -static long region_truncate(struct resv_map *resv, long end)</span>
<span class="quote">&gt; +static long region_del(struct resv_map *resv, long f, long t)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	struct list_head *head = &amp;resv-&gt;regions;</span>
<span class="quote">&gt;  	struct file_region *rg, *trg;</span>
<span class="quote">&gt; +	struct file_region *nrg = NULL;</span>
<span class="quote">&gt;  	long chg = 0;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; +	/*</span>
<span class="quote">&gt; +	 * Locate segments we overlap and etiher split, remove or</span>
<span class="quote">&gt; +	 * trim the existing regions.  The end of region (t) == -1</span>
<span class="quote">&gt; +	 * indicates all remaining regions.  Special case t == -1 as</span>
<span class="quote">&gt; +	 * all comparisons are signed.  Also, when t == -1 it is not</span>
<span class="quote">&gt; +	 * possible to return an error (-ENOMEM) as this only happens</span>
<span class="quote">&gt; +	 * when splitting a region.  Callers take advantage of this</span>
<span class="quote">&gt; +	 * when calling with -1.</span>
<span class="quote">&gt; +	 */</span>
<span class="quote">&gt; +	if (t == -1)</span>
<span class="quote">&gt; +		t = LONG_MAX;</span>
<span class="quote">&gt; +retry:</span>
<span class="quote">&gt;  	spin_lock(&amp;resv-&gt;lock);</span>
<span class="quote">&gt; -	/* Locate the region we are either in or before. */</span>
<span class="quote">&gt; -	list_for_each_entry(rg, head, link)</span>
<span class="quote">&gt; -		if (end &lt;= rg-&gt;to)</span>
<span class="quote">&gt; +	list_for_each_entry_safe(rg, trg, head, link) {</span>
<span class="quote">&gt; +		if (rg-&gt;to &lt;= f)</span>
<span class="quote">&gt; +			continue;</span>
<span class="quote">&gt; +		if (rg-&gt;from &gt;= t)</span>
<span class="quote">&gt;  			break;</span>
<span class="quote">&gt; -	if (&amp;rg-&gt;link == head)</span>
<span class="quote">&gt; -		goto out;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; -	/* If we are in the middle of a region then adjust it. */</span>
<span class="quote">&gt; -	if (end &gt; rg-&gt;from) {</span>
<span class="quote">&gt; -		chg = rg-&gt;to - end;</span>
<span class="quote">&gt; -		rg-&gt;to = end;</span>
<span class="quote">&gt; -		rg = list_entry(rg-&gt;link.next, typeof(*rg), link);</span>
<span class="quote">&gt; -	}</span>
<span class="quote">&gt; +		if (f &gt; rg-&gt;from &amp;&amp; t &lt; rg-&gt;to) { /* must split region */</span>
<span class="quote">&gt; +			if (!nrg) {</span>
<span class="quote">&gt; +				spin_unlock(&amp;resv-&gt;lock);</span>
<span class="quote">&gt; +				nrg = kmalloc(sizeof(*nrg), GFP_KERNEL);</span>
<span class="quote">&gt; +				if (!nrg)</span>
<span class="quote">&gt; +					return -ENOMEM;</span>
<span class="quote">&gt; +				goto retry;</span>
<span class="quote">&gt; +			}</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; -	/* Drop any remaining regions. */</span>
<span class="quote">&gt; -	list_for_each_entry_safe(rg, trg, rg-&gt;link.prev, link) {</span>
<span class="quote">&gt; -		if (&amp;rg-&gt;link == head)</span>
<span class="quote">&gt; +			chg += t - f;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +			/* new entry for end of split region */</span>
<span class="quote">&gt; +			nrg-&gt;from = t;</span>
<span class="quote">&gt; +			nrg-&gt;to = rg-&gt;to;</span>
<span class="quote">&gt; +			INIT_LIST_HEAD(&amp;nrg-&gt;link);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +			/* original entry is trimmed */</span>
<span class="quote">&gt; +			rg-&gt;to = f;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +			list_add(&amp;nrg-&gt;link, &amp;rg-&gt;link);</span>
<span class="quote">&gt; +			nrg = NULL;</span>
<span class="quote">&gt;  			break;</span>
<span class="quote">&gt; -		chg += rg-&gt;to - rg-&gt;from;</span>
<span class="quote">&gt; -		list_del(&amp;rg-&gt;link);</span>
<span class="quote">&gt; -		kfree(rg);</span>
<span class="quote">&gt; +		}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +		if (f &lt;= rg-&gt;from &amp;&amp; t &gt;= rg-&gt;to) { /* remove entire region */</span>
<span class="quote">&gt; +			chg += rg-&gt;to - rg-&gt;from;</span>
<span class="quote">&gt; +			list_del(&amp;rg-&gt;link);</span>
<span class="quote">&gt; +			kfree(rg);</span>
<span class="quote">&gt; +			continue;</span>
<span class="quote">&gt; +		}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +		if (f &lt;= rg-&gt;from) {	/* trim beginning of region */</span>
<span class="quote">&gt; +			chg += t - rg-&gt;from;</span>
<span class="quote">&gt; +			rg-&gt;from = t;</span>
<span class="quote">&gt; +		} else {		/* trim end of region */</span>
<span class="quote">&gt; +			chg += rg-&gt;to - f;</span>
<span class="quote">&gt; +			rg-&gt;to = f;</span>

Is it better to put &quot;break&quot; here?

Thanks,
Naoya Horiguchi
<span class="quote">
&gt; +		}</span>
<span class="quote">&gt;  	}</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; -out:</span>
<span class="quote">&gt;  	spin_unlock(&amp;resv-&gt;lock);</span>
<span class="quote">&gt; +	kfree(nrg);</span>
<span class="quote">&gt;  	return chg;</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; @@ -324,6 +360,27 @@ static long region_count(struct resv_map *resv, long f, long t)</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  /*</span>
<span class="quote">&gt; + * A rare out of memory error was encountered which prevented removal of</span>
<span class="quote">&gt; + * the reserve map region for a page.  The huge page itself was free&#39;&#39;ed</span>
<span class="quote">&gt; + * and removed from the page cache.  This routine will adjust the global</span>
<span class="quote">&gt; + * reserve count if needed, and the subpool usage count.  By incrementing</span>
<span class="quote">&gt; + * these counts, the reserve map entry which could not be deleted will</span>
<span class="quote">&gt; + * appear as a &quot;reserved&quot; entry instead of simply dangling with incorrect</span>
<span class="quote">&gt; + * counts.</span>
<span class="quote">&gt; + */</span>
<span class="quote">&gt; +void hugetlb_fix_reserve_counts(struct inode *inode, bool restore_reserve)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	struct hugepage_subpool *spool = subpool_inode(inode);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	if (restore_reserve) {</span>
<span class="quote">&gt; +		struct hstate *h = hstate_inode(inode);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +		h-&gt;resv_huge_pages++;</span>
<span class="quote">&gt; +	}</span>
<span class="quote">&gt; +	hugepage_subpool_get_pages(spool, 1);</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +/*</span>
<span class="quote">&gt;   * Convert the address within this vma to the page offset within</span>
<span class="quote">&gt;   * the mapping, in pagecache page units; huge pages here.</span>
<span class="quote">&gt;   */</span>
<span class="quote">&gt; @@ -427,7 +484,7 @@ void resv_map_release(struct kref *ref)</span>
<span class="quote">&gt;  	struct resv_map *resv_map = container_of(ref, struct resv_map, refs);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	/* Clear out any active regions before we release the map. */</span>
<span class="quote">&gt; -	region_truncate(resv_map, 0);</span>
<span class="quote">&gt; +	region_del(resv_map, 0, -1);</span>
<span class="quote">&gt;  	kfree(resv_map);</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; @@ -3558,7 +3615,7 @@ void hugetlb_unreserve_pages(struct inode *inode, long offset, long freed)</span>
<span class="quote">&gt;  	struct hugepage_subpool *spool = subpool_inode(inode);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	if (resv_map)</span>
<span class="quote">&gt; -		chg = region_truncate(resv_map, offset);</span>
<span class="quote">&gt; +		chg = region_del(resv_map, offset, -1);</span>
<span class="quote">&gt;  	spin_lock(&amp;inode-&gt;i_lock);</span>
<span class="quote">&gt;  	inode-&gt;i_blocks -= (blocks_per_huge_page(h) * freed);</span>
<span class="quote">&gt;  	spin_unlock(&amp;inode-&gt;i_lock);</span>
<span class="quote">&gt; -- </span>
<span class="quote">&gt; 2.1.0</span>
<span class="quote">&gt; --</span>
To unsubscribe from this list: send the line &quot;unsubscribe linux-kernel&quot; in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
Please read the FAQ at  http://www.tux.org/lkml/
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=124511">Mike Kravetz</a> - May 22, 2015, 4:48 p.m.</div>
<pre class="content">
On 05/21/2015 11:21 PM, Naoya Horiguchi wrote:
<span class="quote">&gt; On Thu, May 21, 2015 at 08:47:37AM -0700, Mike Kravetz wrote:</span>
<span class="quote">&gt;&gt; fallocate hole punch will want to remove a specific range of pages.</span>
<span class="quote">&gt;&gt; The existing region_truncate() routine deletes all region/reserve</span>
<span class="quote">&gt;&gt; map entries after a specified offset.  region_del() will provide</span>
<span class="quote">&gt;&gt; this same functionality if the end of region is specified as -1.</span>
<span class="quote">&gt;&gt; Hence, region_del() can replace region_truncate().</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; Unlike region_truncate(), region_del() can return an error in the</span>
<span class="quote">&gt;&gt; rare case where it can not allocate memory for a region descriptor.</span>
<span class="quote">&gt;&gt; This ONLY happens in the case where an existing region must be split.</span>
<span class="quote">&gt;&gt; Current callers passing -1 as end of range will never experience</span>
<span class="quote">&gt;&gt; this error and do not need to deal with error handling.  Future</span>
<span class="quote">&gt;&gt; callers of region_del() (such as fallocate hole punch) will need to</span>
<span class="quote">&gt;&gt; handle this error.  A routine hugetlb_fix_reserve_counts() is added</span>
<span class="quote">&gt;&gt; to assist in cleaning up if fallocate hole punch experiences this</span>
<span class="quote">&gt;&gt; type of error in region_del().</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; Signed-off-by: Mike Kravetz &lt;mike.kravetz@oracle.com&gt;</span>
<span class="quote">&gt;&gt; ---</span>
<span class="quote">&gt;&gt;   include/linux/hugetlb.h |  1 +</span>
<span class="quote">&gt;&gt;   mm/hugetlb.c            | 99 ++++++++++++++++++++++++++++++++++++++-----------</span>
<span class="quote">&gt;&gt;   2 files changed, 79 insertions(+), 21 deletions(-)</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; diff --git a/include/linux/hugetlb.h b/include/linux/hugetlb.h</span>
<span class="quote">&gt;&gt; index 7b57850..fd337f2 100644</span>
<span class="quote">&gt;&gt; --- a/include/linux/hugetlb.h</span>
<span class="quote">&gt;&gt; +++ b/include/linux/hugetlb.h</span>
<span class="quote">&gt;&gt; @@ -81,6 +81,7 @@ bool isolate_huge_page(struct page *page, struct list_head *list);</span>
<span class="quote">&gt;&gt;   void putback_active_hugepage(struct page *page);</span>
<span class="quote">&gt;&gt;   bool is_hugepage_active(struct page *page);</span>
<span class="quote">&gt;&gt;   void free_huge_page(struct page *page);</span>
<span class="quote">&gt;&gt; +void hugetlb_fix_reserve_counts(struct inode *inode, bool restore_reserve);</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; This function is used in patch 6/10 for the first time,</span>
<span class="quote">&gt; so is it better to move the definition to that patch?</span>
<span class="quote">&gt; (this temporarily introduces &quot;defined but not used&quot; warning...)</span>

Yes, I do think it would be better to move it to patch 6.  The existing
callers/users of region_del() will never encounter an error return value.
As you mention, it is only the new use case in patch 6/10 that needs
to deal with the error.  So, it makes sense to move it there.
<span class="quote">
&gt;&gt;   #ifdef CONFIG_ARCH_WANT_HUGE_PMD_SHARE</span>
<span class="quote">&gt;&gt;   pte_t *huge_pmd_share(struct mm_struct *mm, unsigned long addr, pud_t *pud);</span>
<span class="quote">&gt;&gt; diff --git a/mm/hugetlb.c b/mm/hugetlb.c</span>
<span class="quote">&gt;&gt; index 63f6d43..620cc9e 100644</span>
<span class="quote">&gt;&gt; --- a/mm/hugetlb.c</span>
<span class="quote">&gt;&gt; +++ b/mm/hugetlb.c</span>
<span class="quote">&gt;&gt; @@ -261,38 +261,74 @@ out_nrg:</span>
<span class="quote">&gt;&gt;   	return chg;</span>
<span class="quote">&gt;&gt;   }</span>
<span class="quote">&gt;&gt;   </span>
<span class="quote">&gt;&gt; -static long region_truncate(struct resv_map *resv, long end)</span>
<span class="quote">&gt;&gt; +static long region_del(struct resv_map *resv, long f, long t)</span>
<span class="quote">&gt;&gt;   {</span>
<span class="quote">&gt;&gt;   	struct list_head *head = &amp;resv-&gt;regions;</span>
<span class="quote">&gt;&gt;   	struct file_region *rg, *trg;</span>
<span class="quote">&gt;&gt; +	struct file_region *nrg = NULL;</span>
<span class="quote">&gt;&gt;   	long chg = 0;</span>
<span class="quote">&gt;&gt;   </span>
<span class="quote">&gt;&gt; +	/*</span>
<span class="quote">&gt;&gt; +	 * Locate segments we overlap and etiher split, remove or</span>
<span class="quote">&gt;&gt; +	 * trim the existing regions.  The end of region (t) == -1</span>
<span class="quote">&gt;&gt; +	 * indicates all remaining regions.  Special case t == -1 as</span>
<span class="quote">&gt;&gt; +	 * all comparisons are signed.  Also, when t == -1 it is not</span>
<span class="quote">&gt;&gt; +	 * possible to return an error (-ENOMEM) as this only happens</span>
<span class="quote">&gt;&gt; +	 * when splitting a region.  Callers take advantage of this</span>
<span class="quote">&gt;&gt; +	 * when calling with -1.</span>
<span class="quote">&gt;&gt; +	 */</span>
<span class="quote">&gt;&gt; +	if (t == -1)</span>
<span class="quote">&gt;&gt; +		t = LONG_MAX;</span>
<span class="quote">&gt;&gt; +retry:</span>
<span class="quote">&gt;&gt;   	spin_lock(&amp;resv-&gt;lock);</span>
<span class="quote">&gt;&gt; -	/* Locate the region we are either in or before. */</span>
<span class="quote">&gt;&gt; -	list_for_each_entry(rg, head, link)</span>
<span class="quote">&gt;&gt; -		if (end &lt;= rg-&gt;to)</span>
<span class="quote">&gt;&gt; +	list_for_each_entry_safe(rg, trg, head, link) {</span>
<span class="quote">&gt;&gt; +		if (rg-&gt;to &lt;= f)</span>
<span class="quote">&gt;&gt; +			continue;</span>
<span class="quote">&gt;&gt; +		if (rg-&gt;from &gt;= t)</span>
<span class="quote">&gt;&gt;   			break;</span>
<span class="quote">&gt;&gt; -	if (&amp;rg-&gt;link == head)</span>
<span class="quote">&gt;&gt; -		goto out;</span>
<span class="quote">&gt;&gt;   </span>
<span class="quote">&gt;&gt; -	/* If we are in the middle of a region then adjust it. */</span>
<span class="quote">&gt;&gt; -	if (end &gt; rg-&gt;from) {</span>
<span class="quote">&gt;&gt; -		chg = rg-&gt;to - end;</span>
<span class="quote">&gt;&gt; -		rg-&gt;to = end;</span>
<span class="quote">&gt;&gt; -		rg = list_entry(rg-&gt;link.next, typeof(*rg), link);</span>
<span class="quote">&gt;&gt; -	}</span>
<span class="quote">&gt;&gt; +		if (f &gt; rg-&gt;from &amp;&amp; t &lt; rg-&gt;to) { /* must split region */</span>
<span class="quote">&gt;&gt; +			if (!nrg) {</span>
<span class="quote">&gt;&gt; +				spin_unlock(&amp;resv-&gt;lock);</span>
<span class="quote">&gt;&gt; +				nrg = kmalloc(sizeof(*nrg), GFP_KERNEL);</span>
<span class="quote">&gt;&gt; +				if (!nrg)</span>
<span class="quote">&gt;&gt; +					return -ENOMEM;</span>
<span class="quote">&gt;&gt; +				goto retry;</span>
<span class="quote">&gt;&gt; +			}</span>
<span class="quote">&gt;&gt;   </span>
<span class="quote">&gt;&gt; -	/* Drop any remaining regions. */</span>
<span class="quote">&gt;&gt; -	list_for_each_entry_safe(rg, trg, rg-&gt;link.prev, link) {</span>
<span class="quote">&gt;&gt; -		if (&amp;rg-&gt;link == head)</span>
<span class="quote">&gt;&gt; +			chg += t - f;</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +			/* new entry for end of split region */</span>
<span class="quote">&gt;&gt; +			nrg-&gt;from = t;</span>
<span class="quote">&gt;&gt; +			nrg-&gt;to = rg-&gt;to;</span>
<span class="quote">&gt;&gt; +			INIT_LIST_HEAD(&amp;nrg-&gt;link);</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +			/* original entry is trimmed */</span>
<span class="quote">&gt;&gt; +			rg-&gt;to = f;</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +			list_add(&amp;nrg-&gt;link, &amp;rg-&gt;link);</span>
<span class="quote">&gt;&gt; +			nrg = NULL;</span>
<span class="quote">&gt;&gt;   			break;</span>
<span class="quote">&gt;&gt; -		chg += rg-&gt;to - rg-&gt;from;</span>
<span class="quote">&gt;&gt; -		list_del(&amp;rg-&gt;link);</span>
<span class="quote">&gt;&gt; -		kfree(rg);</span>
<span class="quote">&gt;&gt; +		}</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +		if (f &lt;= rg-&gt;from &amp;&amp; t &gt;= rg-&gt;to) { /* remove entire region */</span>
<span class="quote">&gt;&gt; +			chg += rg-&gt;to - rg-&gt;from;</span>
<span class="quote">&gt;&gt; +			list_del(&amp;rg-&gt;link);</span>
<span class="quote">&gt;&gt; +			kfree(rg);</span>
<span class="quote">&gt;&gt; +			continue;</span>
<span class="quote">&gt;&gt; +		}</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +		if (f &lt;= rg-&gt;from) {	/* trim beginning of region */</span>
<span class="quote">&gt;&gt; +			chg += t - rg-&gt;from;</span>
<span class="quote">&gt;&gt; +			rg-&gt;from = t;</span>
<span class="quote">&gt;&gt; +		} else {		/* trim end of region */</span>
<span class="quote">&gt;&gt; +			chg += rg-&gt;to - f;</span>
<span class="quote">&gt;&gt; +			rg-&gt;to = f;</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Is it better to put &quot;break&quot; here?</span>

Yes, I think a break would be appropriate.  At this point we know the
range to be deleted will not intersect any other regions in the map.
So, the break is appropriate as we do not need to examine the remaining
regions.

I&#39;ll add these change as well as more documentation for region_del in
the next version of this patch set.
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/include/linux/hugetlb.h b/include/linux/hugetlb.h</span>
<span class="p_header">index 7b57850..fd337f2 100644</span>
<span class="p_header">--- a/include/linux/hugetlb.h</span>
<span class="p_header">+++ b/include/linux/hugetlb.h</span>
<span class="p_chunk">@@ -81,6 +81,7 @@</span> <span class="p_context"> bool isolate_huge_page(struct page *page, struct list_head *list);</span>
 void putback_active_hugepage(struct page *page);
 bool is_hugepage_active(struct page *page);
 void free_huge_page(struct page *page);
<span class="p_add">+void hugetlb_fix_reserve_counts(struct inode *inode, bool restore_reserve);</span>
 
 #ifdef CONFIG_ARCH_WANT_HUGE_PMD_SHARE
 pte_t *huge_pmd_share(struct mm_struct *mm, unsigned long addr, pud_t *pud);
<span class="p_header">diff --git a/mm/hugetlb.c b/mm/hugetlb.c</span>
<span class="p_header">index 63f6d43..620cc9e 100644</span>
<span class="p_header">--- a/mm/hugetlb.c</span>
<span class="p_header">+++ b/mm/hugetlb.c</span>
<span class="p_chunk">@@ -261,38 +261,74 @@</span> <span class="p_context"> out_nrg:</span>
 	return chg;
 }
 
<span class="p_del">-static long region_truncate(struct resv_map *resv, long end)</span>
<span class="p_add">+static long region_del(struct resv_map *resv, long f, long t)</span>
 {
 	struct list_head *head = &amp;resv-&gt;regions;
 	struct file_region *rg, *trg;
<span class="p_add">+	struct file_region *nrg = NULL;</span>
 	long chg = 0;
 
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Locate segments we overlap and etiher split, remove or</span>
<span class="p_add">+	 * trim the existing regions.  The end of region (t) == -1</span>
<span class="p_add">+	 * indicates all remaining regions.  Special case t == -1 as</span>
<span class="p_add">+	 * all comparisons are signed.  Also, when t == -1 it is not</span>
<span class="p_add">+	 * possible to return an error (-ENOMEM) as this only happens</span>
<span class="p_add">+	 * when splitting a region.  Callers take advantage of this</span>
<span class="p_add">+	 * when calling with -1.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	if (t == -1)</span>
<span class="p_add">+		t = LONG_MAX;</span>
<span class="p_add">+retry:</span>
 	spin_lock(&amp;resv-&gt;lock);
<span class="p_del">-	/* Locate the region we are either in or before. */</span>
<span class="p_del">-	list_for_each_entry(rg, head, link)</span>
<span class="p_del">-		if (end &lt;= rg-&gt;to)</span>
<span class="p_add">+	list_for_each_entry_safe(rg, trg, head, link) {</span>
<span class="p_add">+		if (rg-&gt;to &lt;= f)</span>
<span class="p_add">+			continue;</span>
<span class="p_add">+		if (rg-&gt;from &gt;= t)</span>
 			break;
<span class="p_del">-	if (&amp;rg-&gt;link == head)</span>
<span class="p_del">-		goto out;</span>
 
<span class="p_del">-	/* If we are in the middle of a region then adjust it. */</span>
<span class="p_del">-	if (end &gt; rg-&gt;from) {</span>
<span class="p_del">-		chg = rg-&gt;to - end;</span>
<span class="p_del">-		rg-&gt;to = end;</span>
<span class="p_del">-		rg = list_entry(rg-&gt;link.next, typeof(*rg), link);</span>
<span class="p_del">-	}</span>
<span class="p_add">+		if (f &gt; rg-&gt;from &amp;&amp; t &lt; rg-&gt;to) { /* must split region */</span>
<span class="p_add">+			if (!nrg) {</span>
<span class="p_add">+				spin_unlock(&amp;resv-&gt;lock);</span>
<span class="p_add">+				nrg = kmalloc(sizeof(*nrg), GFP_KERNEL);</span>
<span class="p_add">+				if (!nrg)</span>
<span class="p_add">+					return -ENOMEM;</span>
<span class="p_add">+				goto retry;</span>
<span class="p_add">+			}</span>
 
<span class="p_del">-	/* Drop any remaining regions. */</span>
<span class="p_del">-	list_for_each_entry_safe(rg, trg, rg-&gt;link.prev, link) {</span>
<span class="p_del">-		if (&amp;rg-&gt;link == head)</span>
<span class="p_add">+			chg += t - f;</span>
<span class="p_add">+</span>
<span class="p_add">+			/* new entry for end of split region */</span>
<span class="p_add">+			nrg-&gt;from = t;</span>
<span class="p_add">+			nrg-&gt;to = rg-&gt;to;</span>
<span class="p_add">+			INIT_LIST_HEAD(&amp;nrg-&gt;link);</span>
<span class="p_add">+</span>
<span class="p_add">+			/* original entry is trimmed */</span>
<span class="p_add">+			rg-&gt;to = f;</span>
<span class="p_add">+</span>
<span class="p_add">+			list_add(&amp;nrg-&gt;link, &amp;rg-&gt;link);</span>
<span class="p_add">+			nrg = NULL;</span>
 			break;
<span class="p_del">-		chg += rg-&gt;to - rg-&gt;from;</span>
<span class="p_del">-		list_del(&amp;rg-&gt;link);</span>
<span class="p_del">-		kfree(rg);</span>
<span class="p_add">+		}</span>
<span class="p_add">+</span>
<span class="p_add">+		if (f &lt;= rg-&gt;from &amp;&amp; t &gt;= rg-&gt;to) { /* remove entire region */</span>
<span class="p_add">+			chg += rg-&gt;to - rg-&gt;from;</span>
<span class="p_add">+			list_del(&amp;rg-&gt;link);</span>
<span class="p_add">+			kfree(rg);</span>
<span class="p_add">+			continue;</span>
<span class="p_add">+		}</span>
<span class="p_add">+</span>
<span class="p_add">+		if (f &lt;= rg-&gt;from) {	/* trim beginning of region */</span>
<span class="p_add">+			chg += t - rg-&gt;from;</span>
<span class="p_add">+			rg-&gt;from = t;</span>
<span class="p_add">+		} else {		/* trim end of region */</span>
<span class="p_add">+			chg += rg-&gt;to - f;</span>
<span class="p_add">+			rg-&gt;to = f;</span>
<span class="p_add">+		}</span>
 	}
 
<span class="p_del">-out:</span>
 	spin_unlock(&amp;resv-&gt;lock);
<span class="p_add">+	kfree(nrg);</span>
 	return chg;
 }
 
<span class="p_chunk">@@ -324,6 +360,27 @@</span> <span class="p_context"> static long region_count(struct resv_map *resv, long f, long t)</span>
 }
 
 /*
<span class="p_add">+ * A rare out of memory error was encountered which prevented removal of</span>
<span class="p_add">+ * the reserve map region for a page.  The huge page itself was free&#39;&#39;ed</span>
<span class="p_add">+ * and removed from the page cache.  This routine will adjust the global</span>
<span class="p_add">+ * reserve count if needed, and the subpool usage count.  By incrementing</span>
<span class="p_add">+ * these counts, the reserve map entry which could not be deleted will</span>
<span class="p_add">+ * appear as a &quot;reserved&quot; entry instead of simply dangling with incorrect</span>
<span class="p_add">+ * counts.</span>
<span class="p_add">+ */</span>
<span class="p_add">+void hugetlb_fix_reserve_counts(struct inode *inode, bool restore_reserve)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct hugepage_subpool *spool = subpool_inode(inode);</span>
<span class="p_add">+</span>
<span class="p_add">+	if (restore_reserve) {</span>
<span class="p_add">+		struct hstate *h = hstate_inode(inode);</span>
<span class="p_add">+</span>
<span class="p_add">+		h-&gt;resv_huge_pages++;</span>
<span class="p_add">+	}</span>
<span class="p_add">+	hugepage_subpool_get_pages(spool, 1);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+/*</span>
  * Convert the address within this vma to the page offset within
  * the mapping, in pagecache page units; huge pages here.
  */
<span class="p_chunk">@@ -427,7 +484,7 @@</span> <span class="p_context"> void resv_map_release(struct kref *ref)</span>
 	struct resv_map *resv_map = container_of(ref, struct resv_map, refs);
 
 	/* Clear out any active regions before we release the map. */
<span class="p_del">-	region_truncate(resv_map, 0);</span>
<span class="p_add">+	region_del(resv_map, 0, -1);</span>
 	kfree(resv_map);
 }
 
<span class="p_chunk">@@ -3558,7 +3615,7 @@</span> <span class="p_context"> void hugetlb_unreserve_pages(struct inode *inode, long offset, long freed)</span>
 	struct hugepage_subpool *spool = subpool_inode(inode);
 
 	if (resv_map)
<span class="p_del">-		chg = region_truncate(resv_map, offset);</span>
<span class="p_add">+		chg = region_del(resv_map, offset, -1);</span>
 	spin_lock(&amp;inode-&gt;i_lock);
 	inode-&gt;i_blocks -= (blocks_per_huge_page(h) * freed);
 	spin_unlock(&amp;inode-&gt;i_lock);

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



