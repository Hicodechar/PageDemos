
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>[RFC,6/6] mm: MADV_FREE refactoring - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    [RFC,6/6] mm: MADV_FREE refactoring</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=36811">Minchan Kim</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>June 3, 2015, 6:15 a.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;1433312145-19386-7-git-send-email-minchan@kernel.org&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/6532381/mbox/"
   >mbox</a>
|
   <a href="/patch/6532381/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/6532381/">/patch/6532381/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
X-Original-To: patchwork-LKML@patchwork.kernel.org
Delivered-To: patchwork-parsemail@patchwork1.web.kernel.org
Received: from mail.kernel.org (mail.kernel.org [198.145.29.136])
	by patchwork1.web.kernel.org (Postfix) with ESMTP id CBCB99F1CC
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Wed,  3 Jun 2015 06:17:40 +0000 (UTC)
Received: from mail.kernel.org (localhost [127.0.0.1])
	by mail.kernel.org (Postfix) with ESMTP id 8116D206A9
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Wed,  3 Jun 2015 06:17:39 +0000 (UTC)
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.kernel.org (Postfix) with ESMTP id 00386206AC
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Wed,  3 Jun 2015 06:17:37 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1753386AbbFCGRb (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Wed, 3 Jun 2015 02:17:31 -0400
Received: from lgeamrelo02.lge.com ([156.147.1.126]:56245 &quot;EHLO
	lgeamrelo02.lge.com&quot; rhost-flags-OK-OK-OK-OK) by vger.kernel.org
	with ESMTP id S1753114AbbFCGPy (ORCPT
	&lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Wed, 3 Jun 2015 02:15:54 -0400
Received: from unknown (HELO localhost.localdomain) (10.177.222.143)
	by 156.147.1.126 with ESMTP; 3 Jun 2015 15:15:51 +0900
X-Original-SENDERIP: 10.177.222.143
X-Original-MAILFROM: minchan@kernel.org
From: Minchan Kim &lt;minchan@kernel.org&gt;
To: Andrew Morton &lt;akpm@linux-foundation.org&gt;
Cc: Hugh Dickins &lt;hughd@google.com&gt;, Rik van Riel &lt;riel@redhat.com&gt;,
	Mel Gorman &lt;mgorman@suse.de&gt;, Michal Hocko &lt;mhocko@suse.cz&gt;,
	Johannes Weiner &lt;hannes@cmpxchg.org&gt;, linux-mm@kvack.org,
	linux-kernel@vger.kernel.org, Minchan Kim &lt;minchan@kernel.org&gt;
Subject: [RFC 6/6] mm: MADV_FREE refactoring
Date: Wed,  3 Jun 2015 15:15:45 +0900
Message-Id: &lt;1433312145-19386-7-git-send-email-minchan@kernel.org&gt;
X-Mailer: git-send-email 1.9.1
In-Reply-To: &lt;1433312145-19386-1-git-send-email-minchan@kernel.org&gt;
References: &lt;1433312145-19386-1-git-send-email-minchan@kernel.org&gt;
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Spam-Status: No, score=-6.9 required=5.0 tests=BAYES_00, RCVD_IN_DNSWL_HI, 
	T_RP_MATCHES_RCVD,
	UNPARSEABLE_RELAY autolearn=unavailable version=3.3.1
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on mail.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=36811">Minchan Kim</a> - June 3, 2015, 6:15 a.m.</div>
<pre class="content">
This patch does some clean up.

Firstly, it removes unnecessary PageSwapCache and ClearPageDirty
in madvise_fre_pte_range. The reason I did in there is to prevent
wrong discarding by non-dirty marked page table entries of
anonymous pages.
However, eariler patches in this patchset removed dependency
between MADV_FREE and PG_dirty and took care of anonymous page&#39;s
dirty bit in page table so there is no reason to add such logics
in fast path now.

Secondly, this patch removes freeable check in page_referenced.
It was pointess because we could decide freeable in try_to_unmap_one
with just pte_dirty. If it is judged by freeable page(ie, page table
doesn&#39;t have dirty bit), just doesn&#39;t store swap location of the pte
(ie, nuke the page table entry ). Otherwise, we could store swap
location on pte so that the page should be swapped-out.

This patch introduces SWAP_DISCARD which represents the passed page
should be discarded instead of swapping.
It is set if page is no mapped at any page table and there is
no swap slot for the page. If so, shrink_page_list does ClearPageDirty
for skipping pageout and then VM reclaims it.
<span class="signed-off-by">
Signed-off-by: Minchan Kim &lt;minchan@kernel.org&gt;</span>
---
 include/linux/rmap.h |  9 ++----
 mm/madvise.c         | 13 ---------
 mm/rmap.c            | 78 +++++++++++++++++++++++++---------------------------
 mm/vmscan.c          | 62 ++++++++++++++---------------------------
 4 files changed, 62 insertions(+), 100 deletions(-)
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/include/linux/rmap.h b/include/linux/rmap.h</span>
<span class="p_header">index bf36b6e644c4..352c72074e69 100644</span>
<span class="p_header">--- a/include/linux/rmap.h</span>
<span class="p_header">+++ b/include/linux/rmap.h</span>
<span class="p_chunk">@@ -184,8 +184,7 @@</span> <span class="p_context"> static inline void page_dup_rmap(struct page *page)</span>
  * Called from mm/vmscan.c to handle paging out
  */
 int page_referenced(struct page *, int is_locked,
<span class="p_del">-			struct mem_cgroup *memcg, unsigned long *vm_flags,</span>
<span class="p_del">-			int *is_pte_dirty);</span>
<span class="p_add">+			struct mem_cgroup *memcg, unsigned long *vm_flags);</span>
 
 #define TTU_ACTION(x) ((x) &amp; TTU_ACTION_MASK)
 
<span class="p_chunk">@@ -262,12 +261,9 @@</span> <span class="p_context"> int rmap_walk(struct page *page, struct rmap_walk_control *rwc);</span>
 
 static inline int page_referenced(struct page *page, int is_locked,
 				  struct mem_cgroup *memcg,
<span class="p_del">-				  unsigned long *vm_flags,</span>
<span class="p_del">-				  int *is_pte_dirty)</span>
<span class="p_add">+				  unsigned long *vm_flags)</span>
 {
 	*vm_flags = 0;
<span class="p_del">-	if (is_pte_dirty)</span>
<span class="p_del">-		*is_pte_dirty = 0;</span>
 	return 0;
 }
 
<span class="p_chunk">@@ -288,5 +284,6 @@</span> <span class="p_context"> static inline int page_mkclean(struct page *page)</span>
 #define SWAP_AGAIN	1
 #define SWAP_FAIL	2
 #define SWAP_MLOCK	3
<span class="p_add">+#define SWAP_DISCARD	4</span>
 
 #endif	/* _LINUX_RMAP_H */
<span class="p_header">diff --git a/mm/madvise.c b/mm/madvise.c</span>
<span class="p_header">index d215ea949630..68446e8ea6f6 100644</span>
<span class="p_header">--- a/mm/madvise.c</span>
<span class="p_header">+++ b/mm/madvise.c</span>
<span class="p_chunk">@@ -317,19 +317,6 @@</span> <span class="p_context"> static int madvise_free_pte_range(pmd_t *pmd, unsigned long addr,</span>
 		if (!page)
 			continue;
 
<span class="p_del">-		if (PageSwapCache(page)) {</span>
<span class="p_del">-			if (!trylock_page(page))</span>
<span class="p_del">-				continue;</span>
<span class="p_del">-</span>
<span class="p_del">-			if (!try_to_free_swap(page)) {</span>
<span class="p_del">-				unlock_page(page);</span>
<span class="p_del">-				continue;</span>
<span class="p_del">-			}</span>
<span class="p_del">-</span>
<span class="p_del">-			ClearPageDirty(page);</span>
<span class="p_del">-			unlock_page(page);</span>
<span class="p_del">-		}</span>
<span class="p_del">-</span>
 		/*
 		 * Some of architecture(ex, PPC) don&#39;t update TLB
 		 * with set_pte_at and tlb_remove_tlb_entry so for
<span class="p_header">diff --git a/mm/rmap.c b/mm/rmap.c</span>
<span class="p_header">index a2e4f64c392e..aa4a5174bc69 100644</span>
<span class="p_header">--- a/mm/rmap.c</span>
<span class="p_header">+++ b/mm/rmap.c</span>
<span class="p_chunk">@@ -712,7 +712,6 @@</span> <span class="p_context"> int page_mapped_in_vma(struct page *page, struct vm_area_struct *vma)</span>
 }
 
 struct page_referenced_arg {
<span class="p_del">-	int dirtied;</span>
 	int mapcount;
 	int referenced;
 	unsigned long vm_flags;
<span class="p_chunk">@@ -727,7 +726,6 @@</span> <span class="p_context"> static int page_referenced_one(struct page *page, struct vm_area_struct *vma,</span>
 	struct mm_struct *mm = vma-&gt;vm_mm;
 	spinlock_t *ptl;
 	int referenced = 0;
<span class="p_del">-	int dirty = 0;</span>
 	struct page_referenced_arg *pra = arg;
 
 	if (unlikely(PageTransHuge(page))) {
<span class="p_chunk">@@ -752,14 +750,6 @@</span> <span class="p_context"> static int page_referenced_one(struct page *page, struct vm_area_struct *vma,</span>
 		if (pmdp_clear_flush_young_notify(vma, address, pmd))
 			referenced++;
 
<span class="p_del">-		/*</span>
<span class="p_del">-		 * Use pmd_freeable instead of raw pmd_dirty because in some</span>
<span class="p_del">-		 * of architecture, pmd_dirty is not defined unless</span>
<span class="p_del">-		 * CONFIG_TRANSPARENT_HUGEPAGE is enabled</span>
<span class="p_del">-		 */</span>
<span class="p_del">-		if (!pmd_freeable(*pmd))</span>
<span class="p_del">-			dirty++;</span>
<span class="p_del">-</span>
 		spin_unlock(ptl);
 	} else {
 		pte_t *pte;
<span class="p_chunk">@@ -790,9 +780,6 @@</span> <span class="p_context"> static int page_referenced_one(struct page *page, struct vm_area_struct *vma,</span>
 				referenced++;
 		}
 
<span class="p_del">-		if (pte_dirty(*pte))</span>
<span class="p_del">-			dirty++;</span>
<span class="p_del">-</span>
 		pte_unmap_unlock(pte, ptl);
 	}
 
<span class="p_chunk">@@ -801,9 +788,6 @@</span> <span class="p_context"> static int page_referenced_one(struct page *page, struct vm_area_struct *vma,</span>
 		pra-&gt;vm_flags |= vma-&gt;vm_flags;
 	}
 
<span class="p_del">-	if (dirty)</span>
<span class="p_del">-		pra-&gt;dirtied++;</span>
<span class="p_del">-</span>
 	pra-&gt;mapcount--;
 	if (!pra-&gt;mapcount)
 		return SWAP_SUCCESS; /* To break the loop */
<span class="p_chunk">@@ -828,7 +812,6 @@</span> <span class="p_context"> static bool invalid_page_referenced_vma(struct vm_area_struct *vma, void *arg)</span>
  * @is_locked: caller holds lock on the page
  * @memcg: target memory cgroup
  * @vm_flags: collect encountered vma-&gt;vm_flags who actually referenced the page
<span class="p_del">- * @is_pte_dirty: ptes which have marked dirty bit - used for lazyfree page</span>
  *
  * Quick test_and_clear_referenced for all mappings to a page,
  * returns the number of ptes which referenced the page.
<span class="p_chunk">@@ -836,8 +819,7 @@</span> <span class="p_context"> static bool invalid_page_referenced_vma(struct vm_area_struct *vma, void *arg)</span>
 int page_referenced(struct page *page,
 		    int is_locked,
 		    struct mem_cgroup *memcg,
<span class="p_del">-		    unsigned long *vm_flags,</span>
<span class="p_del">-		    int *is_pte_dirty)</span>
<span class="p_add">+		    unsigned long *vm_flags)</span>
 {
 	int ret;
 	int we_locked = 0;
<span class="p_chunk">@@ -852,8 +834,6 @@</span> <span class="p_context"> int page_referenced(struct page *page,</span>
 	};
 
 	*vm_flags = 0;
<span class="p_del">-	if (is_pte_dirty)</span>
<span class="p_del">-		*is_pte_dirty = 0;</span>
 
 	if (!page_mapped(page))
 		return 0;
<span class="p_chunk">@@ -882,9 +862,6 @@</span> <span class="p_context"> int page_referenced(struct page *page,</span>
 	if (we_locked)
 		unlock_page(page);
 
<span class="p_del">-	if (is_pte_dirty)</span>
<span class="p_del">-		*is_pte_dirty = pra.dirtied;</span>
<span class="p_del">-</span>
 	return pra.referenced;
 }
 
<span class="p_chunk">@@ -1206,8 +1183,13 @@</span> <span class="p_context"> void page_remove_rmap(struct page *page)</span>
 	 */
 }
 
<span class="p_add">+struct rmap_arg {</span>
<span class="p_add">+	enum ttu_flags flags;</span>
<span class="p_add">+	int discard;</span>
<span class="p_add">+};</span>
<span class="p_add">+</span>
 /*
<span class="p_del">- * @arg: enum ttu_flags will be passed to this argument</span>
<span class="p_add">+ * @arg: struct rmap_arg will be passed to this argument</span>
  */
 static int try_to_unmap_one(struct page *page, struct vm_area_struct *vma,
 		     unsigned long address, void *arg)
<span class="p_chunk">@@ -1217,7 +1199,8 @@</span> <span class="p_context"> static int try_to_unmap_one(struct page *page, struct vm_area_struct *vma,</span>
 	pte_t pteval;
 	spinlock_t *ptl;
 	int ret = SWAP_AGAIN;
<span class="p_del">-	enum ttu_flags flags = (enum ttu_flags)arg;</span>
<span class="p_add">+	struct rmap_arg *rmap_arg = (struct rmap_arg *)arg;</span>
<span class="p_add">+	enum ttu_flags flags = rmap_arg-&gt;flags;</span>
 	int dirty = 0;
 
 	pte = page_check_address(page, mm, address, &amp;ptl, 0);
<span class="p_chunk">@@ -1278,17 +1261,11 @@</span> <span class="p_context"> static int try_to_unmap_one(struct page *page, struct vm_area_struct *vma,</span>
 		swp_entry_t entry = { .val = page_private(page) };
 		pte_t swp_pte;
 
<span class="p_del">-		if (flags &amp; TTU_FREE) {</span>
<span class="p_del">-			VM_BUG_ON_PAGE(PageSwapCache(page), page);</span>
<span class="p_del">-			if (!dirty) {</span>
<span class="p_del">-				/* It&#39;s a freeable page by MADV_FREE */</span>
<span class="p_del">-				dec_mm_counter(mm, MM_ANONPAGES);</span>
<span class="p_del">-				goto discard;</span>
<span class="p_del">-			} else {</span>
<span class="p_del">-				set_pte_at(mm, address, pte, pteval);</span>
<span class="p_del">-				ret = SWAP_FAIL;</span>
<span class="p_del">-				goto out_unmap;</span>
<span class="p_del">-			}</span>
<span class="p_add">+		if (flags &amp; TTU_FREE &amp;&amp; !dirty) {</span>
<span class="p_add">+			/* It&#39;s a freeable page by MADV_FREE */</span>
<span class="p_add">+			dec_mm_counter(mm, MM_ANONPAGES);</span>
<span class="p_add">+			rmap_arg-&gt;discard++;</span>
<span class="p_add">+			goto discard;</span>
 		}
 
 		if (PageSwapCache(page)) {
<span class="p_chunk">@@ -1405,15 +1382,23 @@</span> <span class="p_context"> static int page_not_mapped(struct page *page)</span>
 int try_to_unmap(struct page *page, enum ttu_flags flags)
 {
 	int ret;
<span class="p_add">+	int mapcount;</span>
<span class="p_add">+	struct rmap_arg rmap_arg = {</span>
<span class="p_add">+		.flags = flags,</span>
<span class="p_add">+	};</span>
<span class="p_add">+</span>
 	struct rmap_walk_control rwc = {
 		.rmap_one = try_to_unmap_one,
<span class="p_del">-		.arg = (void *)flags,</span>
<span class="p_add">+		.arg = (void *)&amp;rmap_arg,</span>
 		.done = page_not_mapped,
 		.anon_lock = page_lock_anon_vma_read,
 	};
 
 	VM_BUG_ON_PAGE(!PageHuge(page) &amp;&amp; PageTransHuge(page), page);
 
<span class="p_add">+	if (flags &amp; TTU_FREE)</span>
<span class="p_add">+		mapcount = page_mapcount(page);</span>
<span class="p_add">+</span>
 	/*
 	 * During exec, a temporary VMA is setup and later moved.
 	 * The VMA is moved under the anon_vma lock but not the
<span class="p_chunk">@@ -1427,8 +1412,21 @@</span> <span class="p_context"> int try_to_unmap(struct page *page, enum ttu_flags flags)</span>
 
 	ret = rmap_walk(page, &amp;rwc);
 
<span class="p_del">-	if (ret != SWAP_MLOCK &amp;&amp; !page_mapped(page))</span>
<span class="p_del">-		ret = SWAP_SUCCESS;</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * The mapcount would be zero if some process frees @page in parallel.</span>
<span class="p_add">+	 * In this case, we shouldn&#39;t count it as SWAP_DISCARD. Otherwise,</span>
<span class="p_add">+	 * people can see increased pglazyfreed via vmstat even though there</span>
<span class="p_add">+	 * is no process called MADV_FREE.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	if (ret != SWAP_MLOCK &amp;&amp; !page_mapped(page)) {</span>
<span class="p_add">+		if ((flags &amp; TTU_FREE) &amp;&amp; mapcount &amp;&amp;</span>
<span class="p_add">+			mapcount == rmap_arg.discard &amp;&amp;</span>
<span class="p_add">+				!page_swapcount(page))</span>
<span class="p_add">+			ret = SWAP_DISCARD;</span>
<span class="p_add">+		else</span>
<span class="p_add">+			ret = SWAP_SUCCESS;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
 	return ret;
 }
 
<span class="p_header">diff --git a/mm/vmscan.c b/mm/vmscan.c</span>
<span class="p_header">index c5fbb7c64deb..4ab599810c8d 100644</span>
<span class="p_header">--- a/mm/vmscan.c</span>
<span class="p_header">+++ b/mm/vmscan.c</span>
<span class="p_chunk">@@ -754,17 +754,15 @@</span> <span class="p_context"> enum page_references {</span>
 };
 
 static enum page_references page_check_references(struct page *page,
<span class="p_del">-						  struct scan_control *sc,</span>
<span class="p_del">-						  bool *freeable)</span>
<span class="p_add">+						  struct scan_control *sc)</span>
 {
 	int referenced_ptes, referenced_page;
 	unsigned long vm_flags;
<span class="p_del">-	int pte_dirty;</span>
 
 	VM_BUG_ON_PAGE(!PageLocked(page), page);
 
 	referenced_ptes = page_referenced(page, 1, sc-&gt;target_mem_cgroup,
<span class="p_del">-					  &amp;vm_flags, &amp;pte_dirty);</span>
<span class="p_add">+					  &amp;vm_flags);</span>
 	referenced_page = TestClearPageReferenced(page);
 
 	/*
<span class="p_chunk">@@ -805,9 +803,6 @@</span> <span class="p_context"> static enum page_references page_check_references(struct page *page,</span>
 		return PAGEREF_KEEP;
 	}
 
<span class="p_del">-	if (PageAnon(page) &amp;&amp; !pte_dirty &amp;&amp; !PageSwapCache(page))</span>
<span class="p_del">-		*freeable = true;</span>
<span class="p_del">-</span>
 	/* Reclaim if clean, defer dirty pages to writeback */
 	if (referenced_page &amp;&amp; !PageSwapBacked(page))
 		return PAGEREF_RECLAIM_CLEAN;
<span class="p_chunk">@@ -876,7 +871,8 @@</span> <span class="p_context"> static unsigned long shrink_page_list(struct list_head *page_list,</span>
 		int may_enter_fs;
 		enum page_references references = PAGEREF_RECLAIM_CLEAN;
 		bool dirty, writeback;
<span class="p_del">-		bool freeable = false;</span>
<span class="p_add">+		int unmap_ret = SWAP_AGAIN;</span>
<span class="p_add">+		enum ttu_flags tmp_ttu_flags = ttu_flags;</span>
 
 		cond_resched();
 
<span class="p_chunk">@@ -1000,8 +996,7 @@</span> <span class="p_context"> static unsigned long shrink_page_list(struct list_head *page_list,</span>
 		}
 
 		if (!force_reclaim)
<span class="p_del">-			references = page_check_references(page, sc,</span>
<span class="p_del">-							&amp;freeable);</span>
<span class="p_add">+			references = page_check_references(page, sc);</span>
 
 		switch (references) {
 		case PAGEREF_ACTIVATE:
<span class="p_chunk">@@ -1013,12 +1008,13 @@</span> <span class="p_context"> static unsigned long shrink_page_list(struct list_head *page_list,</span>
 			; /* try to reclaim the page below */
 		}
 
<span class="p_del">-		/*</span>
<span class="p_del">-		 * Anonymous process memory has backing store?</span>
<span class="p_del">-		 * Try to allocate it some swap space here.</span>
<span class="p_del">-		 */</span>
<span class="p_del">-		if (PageAnon(page) &amp;&amp; !PageSwapCache(page)) {</span>
<span class="p_del">-			if (!freeable) {</span>
<span class="p_add">+		if (PageAnon(page)) {</span>
<span class="p_add">+			tmp_ttu_flags |= TTU_FREE;</span>
<span class="p_add">+			/*</span>
<span class="p_add">+			 * Anonymous process memory has backing store?</span>
<span class="p_add">+			 * Try to allocate it some swap space here.</span>
<span class="p_add">+			 */</span>
<span class="p_add">+			if (!PageSwapCache(page)) {</span>
 				if (!(sc-&gt;gfp_mask &amp; __GFP_IO))
 					goto keep_locked;
 				if (!add_to_swap(page, page_list))
<span class="p_chunk">@@ -1026,44 +1022,26 @@</span> <span class="p_context"> static unsigned long shrink_page_list(struct list_head *page_list,</span>
 				may_enter_fs = 1;
 				/* Adding to swap updated mapping */
 				mapping = page_mapping(page);
<span class="p_del">-			} else {</span>
<span class="p_del">-				if (likely(!PageTransHuge(page)))</span>
<span class="p_del">-					goto unmap;</span>
<span class="p_del">-				/* try_to_unmap isn&#39;t aware of THP page */</span>
<span class="p_del">-				if (unlikely(split_huge_page_to_list(page,</span>
<span class="p_del">-								page_list)))</span>
<span class="p_del">-					goto keep_locked;</span>
 			}
 		}
<span class="p_del">-unmap:</span>
<span class="p_add">+</span>
 		/*
 		 * The page is mapped into the page tables of one or more
 		 * processes. Try to unmap it here.
 		 */
<span class="p_del">-		if (page_mapped(page) &amp;&amp; (mapping || freeable)) {</span>
<span class="p_del">-			switch (try_to_unmap(page,</span>
<span class="p_del">-				freeable ? TTU_FREE : ttu_flags)) {</span>
<span class="p_add">+		if (page_mapped(page) &amp;&amp; mapping) {</span>
<span class="p_add">+			switch (unmap_ret = try_to_unmap(page, tmp_ttu_flags)) {</span>
 			case SWAP_FAIL:
 				goto activate_locked;
 			case SWAP_AGAIN:
 				goto keep_locked;
 			case SWAP_MLOCK:
 				goto cull_mlocked;
<span class="p_add">+			case SWAP_DISCARD:</span>
<span class="p_add">+				ClearPageDirty(page);</span>
 			case SWAP_SUCCESS:
<span class="p_add">+				break;</span>
 				/* try to free the page below */
<span class="p_del">-				if (!freeable)</span>
<span class="p_del">-					break;</span>
<span class="p_del">-				/*</span>
<span class="p_del">-				 * Freeable anon page doesn&#39;t have mapping</span>
<span class="p_del">-				 * due to skipping of swapcache so we free</span>
<span class="p_del">-				 * page in here rather than __remove_mapping.</span>
<span class="p_del">-				 */</span>
<span class="p_del">-				VM_BUG_ON_PAGE(PageSwapCache(page), page);</span>
<span class="p_del">-				if (!page_freeze_refs(page, 1))</span>
<span class="p_del">-					goto keep_locked;</span>
<span class="p_del">-				__ClearPageLocked(page);</span>
<span class="p_del">-				count_vm_event(PGLAZYFREED);</span>
<span class="p_del">-				goto free_it;</span>
 			}
 		}
 
<span class="p_chunk">@@ -1175,6 +1153,8 @@</span> <span class="p_context"> unmap:</span>
 		 */
 		__ClearPageLocked(page);
 free_it:
<span class="p_add">+		if (unmap_ret == SWAP_DISCARD)</span>
<span class="p_add">+			count_vm_event(PGLAZYFREED);</span>
 		nr_reclaimed++;
 
 		/*
<span class="p_chunk">@@ -1820,7 +1800,7 @@</span> <span class="p_context"> static void shrink_active_list(unsigned long nr_to_scan,</span>
 		}
 
 		if (page_referenced(page, 0, sc-&gt;target_mem_cgroup,
<span class="p_del">-				    &amp;vm_flags, NULL)) {</span>
<span class="p_add">+				    &amp;vm_flags)) {</span>
 			nr_rotated += hpage_nr_pages(page);
 			/*
 			 * Identify referenced, file-backed active pages and

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



