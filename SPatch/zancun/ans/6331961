
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>[3.2,034/221] mm/hugetlb: fix getting refcount 0 page in hugetlb_fault() - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    [3.2,034/221] mm/hugetlb: fix getting refcount 0 page in hugetlb_fault()</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=131">Ben Hutchings</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>May 5, 2015, 1:16 a.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;lsq.1430788599.805190013@decadent.org.uk&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/6331961/mbox/"
   >mbox</a>
|
   <a href="/patch/6331961/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/6331961/">/patch/6331961/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
X-Original-To: patchwork-LKML@patchwork.kernel.org
Delivered-To: patchwork-parsemail@patchwork1.web.kernel.org
Received: from mail.kernel.org (mail.kernel.org [198.145.29.136])
	by patchwork1.web.kernel.org (Postfix) with ESMTP id 13FBA9F1C2
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Tue,  5 May 2015 01:50:01 +0000 (UTC)
Received: from mail.kernel.org (localhost [127.0.0.1])
	by mail.kernel.org (Postfix) with ESMTP id EE0E12028D
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Tue,  5 May 2015 01:49:59 +0000 (UTC)
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.kernel.org (Postfix) with ESMTP id D6CD320270
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Tue,  5 May 2015 01:49:58 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S932444AbbEEBtr (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Mon, 4 May 2015 21:49:47 -0400
Received: from shadbolt.e.decadent.org.uk ([88.96.1.126]:51830 &quot;EHLO
	shadbolt.e.decadent.org.uk&quot; rhost-flags-OK-OK-OK-OK)
	by vger.kernel.org with ESMTP id S932350AbbEEBsh (ORCPT
	&lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Mon, 4 May 2015 21:48:37 -0400
Received: from deadeye.wl.decadent.org.uk ([192.168.4.249] helo=deadeye)
	by shadbolt.decadent.org.uk with esmtps
	(TLS1.2:ECDHE_RSA_AES_128_GCM_SHA256:128) (Exim 4.84)
	(envelope-from &lt;ben@decadent.org.uk&gt;)
	id 1YpRYl-0003Eq-58; Tue, 05 May 2015 02:22:07 +0100
Received: from ben by deadeye with local (Exim 4.85)
	(envelope-from &lt;ben@decadent.org.uk&gt;)
	id 1YpRYR-0004Ii-U3; Tue, 05 May 2015 02:21:47 +0100
Content-Type: text/plain; charset=&quot;UTF-8&quot;
Content-Disposition: inline
Content-Transfer-Encoding: 8bit
MIME-Version: 1.0
From: Ben Hutchings &lt;ben@decadent.org.uk&gt;
To: linux-kernel@vger.kernel.org, stable@vger.kernel.org
CC: akpm@linux-foundation.org, &quot;Lee Schermerhorn&quot; &lt;lee.schermerhorn@hp.com&gt;,
	&quot;David Rientjes&quot; &lt;rientjes@google.com&gt;,
	&quot;Mel Gorman&quot; &lt;mel@csn.ul.ie&gt;, &quot;Rik van Riel&quot; &lt;riel@redhat.com&gt;,
	&quot;James Hogan&quot; &lt;james.hogan@imgtec.com&gt;,
	&quot;Naoya Horiguchi&quot; &lt;n-horiguchi@ah.jp.nec.com&gt;,
	&quot;Andrea Arcangeli&quot; &lt;aarcange@redhat.com&gt;,
	&quot;Steve Capper&quot; &lt;steve.capper@linaro.org&gt;,
	&quot;Nishanth Aravamudan&quot; &lt;nacc@linux.vnet.ibm.com&gt;,
	&quot;Hugh Dickins&quot; &lt;hughd@google.com&gt;,
	&quot;Johannes Weiner&quot; &lt;hannes@cmpxchg.org&gt;,
	&quot;Luiz Capitulino&quot; &lt;lcapitulino@redhat.com&gt;,
	&quot;Michal Hocko&quot; &lt;mhocko@suse.cz&gt;,
	&quot;Linus Torvalds&quot; &lt;torvalds@linux-foundation.org&gt;
Date: Tue, 05 May 2015 02:16:39 +0100
Message-ID: &lt;lsq.1430788599.805190013@decadent.org.uk&gt;
X-Mailer: LinuxStableQueue (scripts by bwh)
Subject: [PATCH 3.2 034/221] mm/hugetlb: fix getting refcount 0 page in
	hugetlb_fault()
In-Reply-To: &lt;lsq.1430788598.234880031@decadent.org.uk&gt;
X-SA-Exim-Connect-IP: 192.168.4.249
X-SA-Exim-Mail-From: ben@decadent.org.uk
X-SA-Exim-Scanned: No (on shadbolt.decadent.org.uk);
	SAEximRunCond expanded to false
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Spam-Status: No, score=-6.9 required=5.0 tests=BAYES_00, RCVD_IN_DNSWL_HI, 
	T_RP_MATCHES_RCVD,
	UNPARSEABLE_RELAY autolearn=unavailable version=3.3.1
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on mail.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=131">Ben Hutchings</a> - May 5, 2015, 1:16 a.m.</div>
<pre class="content">
3.2.69-rc1 review patch.  If anyone has any objections, please let me know.

------------------
<span class="from">
From: Naoya Horiguchi &lt;n-horiguchi@ah.jp.nec.com&gt;</span>

commit 0f792cf949a0be506c2aa8bfac0605746b146dda upstream.

When running the test which causes the race as shown in the previous patch,
we can hit the BUG &quot;get_page() on refcount 0 page&quot; in hugetlb_fault().

This race happens when pte turns into migration entry just after the first
check of is_hugetlb_entry_migration() in hugetlb_fault() passed with false.
To fix this, we need to check pte_present() again after huge_ptep_get().

This patch also reorders taking ptl and doing pte_page(), because
pte_page() should be done in ptl.  Due to this reordering, we need use
trylock_page() in page != pagecache_page case to respect locking order.

Fixes: 66aebce747ea (&quot;hugetlb: fix race condition in hugetlb_fault()&quot;)
<span class="signed-off-by">Signed-off-by: Naoya Horiguchi &lt;n-horiguchi@ah.jp.nec.com&gt;</span>
Cc: Hugh Dickins &lt;hughd@google.com&gt;
Cc: James Hogan &lt;james.hogan@imgtec.com&gt;
Cc: David Rientjes &lt;rientjes@google.com&gt;
Cc: Mel Gorman &lt;mel@csn.ul.ie&gt;
Cc: Johannes Weiner &lt;hannes@cmpxchg.org&gt;
Cc: Michal Hocko &lt;mhocko@suse.cz&gt;
Cc: Rik van Riel &lt;riel@redhat.com&gt;
Cc: Andrea Arcangeli &lt;aarcange@redhat.com&gt;
Cc: Luiz Capitulino &lt;lcapitulino@redhat.com&gt;
Cc: Nishanth Aravamudan &lt;nacc@linux.vnet.ibm.com&gt;
Cc: Lee Schermerhorn &lt;lee.schermerhorn@hp.com&gt;
Cc: Steve Capper &lt;steve.capper@linaro.org&gt;
<span class="signed-off-by">Signed-off-by: Andrew Morton &lt;akpm@linux-foundation.org&gt;</span>
<span class="signed-off-by">Signed-off-by: Linus Torvalds &lt;torvalds@linux-foundation.org&gt;</span>
[bwh: Backported to 3.2:
 - Adjust context
 - Error label is named &#39;out_page_table_lock&#39; not &#39;out_ptl&#39;]
<span class="signed-off-by">Signed-off-by: Ben Hutchings &lt;ben@decadent.org.uk&gt;</span>
---
 mm/hugetlb.c | 52 ++++++++++++++++++++++++++++++++++++----------------
 1 file changed, 36 insertions(+), 16 deletions(-)


--
To unsubscribe from this list: send the line &quot;unsubscribe linux-kernel&quot; in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
Please read the FAQ at  http://www.tux.org/lkml/
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">--- a/mm/hugetlb.c</span>
<span class="p_header">+++ b/mm/hugetlb.c</span>
<span class="p_chunk">@@ -2798,6 +2798,7 @@</span> <span class="p_context"> int hugetlb_fault(struct mm_struct *mm,</span>
 	struct page *pagecache_page = NULL;
 	static DEFINE_MUTEX(hugetlb_instantiation_mutex);
 	struct hstate *h = hstate_vma(vma);
<span class="p_add">+	int need_wait_lock = 0;</span>
 
 	ptep = huge_pte_offset(mm, address);
 	if (ptep) {
<span class="p_chunk">@@ -2829,6 +2830,16 @@</span> <span class="p_context"> int hugetlb_fault(struct mm_struct *mm,</span>
 	ret = 0;
 
 	/*
<span class="p_add">+	 * entry could be a migration/hwpoison entry at this point, so this</span>
<span class="p_add">+	 * check prevents the kernel from going below assuming that we have</span>
<span class="p_add">+	 * a active hugepage in pagecache. This goto expects the 2nd page fault,</span>
<span class="p_add">+	 * and is_hugetlb_entry_(migration|hwpoisoned) check will properly</span>
<span class="p_add">+	 * handle it.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	if (!pte_present(entry))</span>
<span class="p_add">+		goto out_mutex;</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
 	 * If we are going to COW the mapping later, we examine the pending
 	 * reservations for this page now. This will ensure that any
 	 * allocations necessary to record that reservation occur outside the
<span class="p_chunk">@@ -2847,29 +2858,30 @@</span> <span class="p_context"> int hugetlb_fault(struct mm_struct *mm,</span>
 								vma, address);
 	}
 
<span class="p_add">+	spin_lock(&amp;mm-&gt;page_table_lock);</span>
<span class="p_add">+	/* Check for a racing update before calling hugetlb_cow */</span>
<span class="p_add">+	if (unlikely(!pte_same(entry, huge_ptep_get(ptep))))</span>
<span class="p_add">+		goto out_page_table_lock;</span>
<span class="p_add">+</span>
 	/*
 	 * hugetlb_cow() requires page locks of pte_page(entry) and
 	 * pagecache_page, so here we need take the former one
 	 * when page != pagecache_page or !pagecache_page.
<span class="p_del">-	 * Note that locking order is always pagecache_page -&gt; page,</span>
<span class="p_del">-	 * so no worry about deadlock.</span>
 	 */
 	page = pte_page(entry);
<span class="p_del">-	get_page(page);</span>
 	if (page != pagecache_page)
<span class="p_del">-		lock_page(page);</span>
<span class="p_del">-</span>
<span class="p_del">-	spin_lock(&amp;mm-&gt;page_table_lock);</span>
<span class="p_del">-	/* Check for a racing update before calling hugetlb_cow */</span>
<span class="p_del">-	if (unlikely(!pte_same(entry, huge_ptep_get(ptep))))</span>
<span class="p_del">-		goto out_page_table_lock;</span>
<span class="p_add">+		if (!trylock_page(page)) {</span>
<span class="p_add">+			need_wait_lock = 1;</span>
<span class="p_add">+			goto out_page_table_lock;</span>
<span class="p_add">+		}</span>
 
<span class="p_add">+	get_page(page);</span>
 
 	if (flags &amp; FAULT_FLAG_WRITE) {
 		if (!pte_write(entry)) {
 			ret = hugetlb_cow(mm, vma, address, ptep, entry,
 							pagecache_page);
<span class="p_del">-			goto out_page_table_lock;</span>
<span class="p_add">+			goto out_put_page;</span>
 		}
 		entry = pte_mkdirty(entry);
 	}
<span class="p_chunk">@@ -2877,7 +2889,10 @@</span> <span class="p_context"> int hugetlb_fault(struct mm_struct *mm,</span>
 	if (huge_ptep_set_access_flags(vma, address, ptep, entry,
 						flags &amp; FAULT_FLAG_WRITE))
 		update_mmu_cache(vma, address, ptep);
<span class="p_del">-</span>
<span class="p_add">+out_put_page:</span>
<span class="p_add">+	if (page != pagecache_page)</span>
<span class="p_add">+		unlock_page(page);</span>
<span class="p_add">+	put_page(page);</span>
 out_page_table_lock:
 	spin_unlock(&amp;mm-&gt;page_table_lock);
 
<span class="p_chunk">@@ -2885,13 +2900,18 @@</span> <span class="p_context"> out_page_table_lock:</span>
 		unlock_page(pagecache_page);
 		put_page(pagecache_page);
 	}
<span class="p_del">-	if (page != pagecache_page)</span>
<span class="p_del">-		unlock_page(page);</span>
<span class="p_del">-	put_page(page);</span>
<span class="p_del">-</span>
 out_mutex:
 	mutex_unlock(&amp;hugetlb_instantiation_mutex);
 
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Generally it&#39;s safe to hold refcount during waiting page lock. But</span>
<span class="p_add">+	 * here we just wait to defer the next page fault to avoid busy loop and</span>
<span class="p_add">+	 * the page is not used after unlocked before returning from the current</span>
<span class="p_add">+	 * page fault. So we are safe from accessing freed page, even if we wait</span>
<span class="p_add">+	 * here without taking refcount.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	if (need_wait_lock)</span>
<span class="p_add">+		wait_on_page_locked(page);</span>
 	return ret;
 }
 

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



