
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>[4/8] mm: free swp_entry in madvise_free - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    [4/8] mm: free swp_entry in madvise_free</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=36811">Minchan Kim</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>Oct. 30, 2015, 7:01 a.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;1446188504-28023-5-git-send-email-minchan@kernel.org&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/7524861/mbox/"
   >mbox</a>
|
   <a href="/patch/7524861/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/7524861/">/patch/7524861/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
X-Original-To: patchwork-LKML@patchwork.kernel.org
Delivered-To: patchwork-parsemail@patchwork1.web.kernel.org
Received: from mail.kernel.org (mail.kernel.org [198.145.29.136])
	by patchwork1.web.kernel.org (Postfix) with ESMTP id 2EFB99F2F7
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Fri, 30 Oct 2015 07:01:36 +0000 (UTC)
Received: from mail.kernel.org (localhost [127.0.0.1])
	by mail.kernel.org (Postfix) with ESMTP id 5F7F32061E
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Fri, 30 Oct 2015 07:01:35 +0000 (UTC)
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.kernel.org (Postfix) with ESMTP id 6C534206EE
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Fri, 30 Oct 2015 07:01:34 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1758862AbbJ3HB1 (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Fri, 30 Oct 2015 03:01:27 -0400
Received: from LGEAMRELO11.lge.com ([156.147.23.51]:32983 &quot;EHLO
	lgeamrelo11.lge.com&quot; rhost-flags-OK-OK-OK-OK) by vger.kernel.org
	with ESMTP id S1758804AbbJ3HBU (ORCPT
	&lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Fri, 30 Oct 2015 03:01:20 -0400
Received: from unknown (HELO lgemrelse7q.lge.com) (156.147.1.151)
	by 156.147.23.51 with ESMTP; 30 Oct 2015 16:01:18 +0900
X-Original-SENDERIP: 156.147.1.151
X-Original-MAILFROM: minchan@kernel.org
Received: from unknown (HELO localhost.localdomain) (10.177.223.161)
	by 156.147.1.151 with ESMTP; 30 Oct 2015 16:01:17 +0900
X-Original-SENDERIP: 10.177.223.161
X-Original-MAILFROM: minchan@kernel.org
From: Minchan Kim &lt;minchan@kernel.org&gt;
To: Andrew Morton &lt;akpm@linux-foundation.org&gt;
Cc: linux-kernel@vger.kernel.org, linux-mm@kvack.org,
	Michael Kerrisk &lt;mtk.manpages@gmail.com&gt;,
	linux-api@vger.kernel.org, Hugh Dickins &lt;hughd@google.com&gt;,
	Johannes Weiner &lt;hannes@cmpxchg.org&gt;,
	zhangyanfei@cn.fujitsu.com, Rik van Riel &lt;riel@redhat.com&gt;,
	Mel Gorman &lt;mgorman@suse.de&gt;,
	KOSAKI Motohiro &lt;kosaki.motohiro@jp.fujitsu.com&gt;,
	Jason Evans &lt;je@fb.com&gt;, Daniel Micay &lt;danielmicay@gmail.com&gt;,
	&quot;Kirill A. Shutemov&quot; &lt;kirill@shutemov.name&gt;,
	Michal Hocko &lt;mhocko@suse.cz&gt;, yalin.wang2010@gmail.com,
	Shaohua Li &lt;shli@kernel.org&gt;, Minchan Kim &lt;minchan@kernel.org&gt;
Subject: [PATCH 4/8] mm: free swp_entry in madvise_free
Date: Fri, 30 Oct 2015 16:01:40 +0900
Message-Id: &lt;1446188504-28023-5-git-send-email-minchan@kernel.org&gt;
X-Mailer: git-send-email 1.9.1
In-Reply-To: &lt;1446188504-28023-1-git-send-email-minchan@kernel.org&gt;
References: &lt;1446188504-28023-1-git-send-email-minchan@kernel.org&gt;
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Spam-Status: No, score=-7.9 required=5.0 tests=BAYES_00, RCVD_IN_DNSWL_HI, 
	RP_MATCHES_RCVD,
	UNPARSEABLE_RELAY autolearn=unavailable version=3.3.1
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on mail.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=36811">Minchan Kim</a> - Oct. 30, 2015, 7:01 a.m.</div>
<pre class="content">
When I test below piece of code with 12 processes(ie, 512M * 12 = 6G
consume) on my (3G ram + 12 cpu + 8G swap, the madvise_free is siginficat
slower (ie, 2x times) than madvise_dontneed.

loop = 5;
mmap(512M);
while (loop--) {
        memset(512M);
        madvise(MADV_FREE or MADV_DONTNEED);
}

The reason is lots of swapin.

1) dontneed: 1,612 swapin
2) madvfree: 879,585 swapin

If we find hinted pages were already swapped out when syscall is called,
it&#39;s pointless to keep the swapped-out pages in pte.
Instead, let&#39;s free the cold page because swapin is more expensive
than (alloc page + zeroing).

With this patch, it reduced swapin from 879,585 to 1,878 so elapsed time

1) dontneed: 6.10user 233.50system 0:50.44elapsed
2) madvfree: 6.03user 401.17system 1:30.67elapsed
2) madvfree + below patch: 6.70user 339.14system 1:04.45elapsed
<span class="acked-by">
Acked-by: Hugh Dickins &lt;hughd@google.com&gt;</span>
<span class="signed-off-by">Signed-off-by: Minchan Kim &lt;minchan@kernel.org&gt;</span>
---
 mm/madvise.c | 26 +++++++++++++++++++++++++-
 1 file changed, 25 insertions(+), 1 deletion(-)
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=137061">Michal Hocko</a> - Oct. 30, 2015, 12:28 p.m.</div>
<pre class="content">
On Fri 30-10-15 16:01:40, Minchan Kim wrote:
<span class="quote">&gt; When I test below piece of code with 12 processes(ie, 512M * 12 = 6G</span>
<span class="quote">&gt; consume) on my (3G ram + 12 cpu + 8G swap, the madvise_free is siginficat</span>
<span class="quote">&gt; slower (ie, 2x times) than madvise_dontneed.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; loop = 5;</span>
<span class="quote">&gt; mmap(512M);</span>
<span class="quote">&gt; while (loop--) {</span>
<span class="quote">&gt;         memset(512M);</span>
<span class="quote">&gt;         madvise(MADV_FREE or MADV_DONTNEED);</span>
<span class="quote">&gt; }</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; The reason is lots of swapin.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; 1) dontneed: 1,612 swapin</span>
<span class="quote">&gt; 2) madvfree: 879,585 swapin</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; If we find hinted pages were already swapped out when syscall is called,</span>
<span class="quote">&gt; it&#39;s pointless to keep the swapped-out pages in pte.</span>
<span class="quote">&gt; Instead, let&#39;s free the cold page because swapin is more expensive</span>
<span class="quote">&gt; than (alloc page + zeroing).</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; With this patch, it reduced swapin from 879,585 to 1,878 so elapsed time</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; 1) dontneed: 6.10user 233.50system 0:50.44elapsed</span>
<span class="quote">&gt; 2) madvfree: 6.03user 401.17system 1:30.67elapsed</span>
<span class="quote">&gt; 2) madvfree + below patch: 6.70user 339.14system 1:04.45elapsed</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Acked-by: Hugh Dickins &lt;hughd@google.com&gt;</span>
<span class="quote">&gt; Signed-off-by: Minchan Kim &lt;minchan@kernel.org&gt;</span>

Yes this makes a lot of sense.
<span class="acked-by">
Acked-by: Michal Hocko &lt;mhocko@suse.com&gt;</span>

One nit below.
<span class="quote">
&gt; ---</span>
<span class="quote">&gt;  mm/madvise.c | 26 +++++++++++++++++++++++++-</span>
<span class="quote">&gt;  1 file changed, 25 insertions(+), 1 deletion(-)</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; diff --git a/mm/madvise.c b/mm/madvise.c</span>
<span class="quote">&gt; index 640311704e31..663bd9fa0ae0 100644</span>
<span class="quote">&gt; --- a/mm/madvise.c</span>
<span class="quote">&gt; +++ b/mm/madvise.c</span>
<span class="quote">&gt; @@ -270,6 +270,8 @@ static int madvise_free_pte_range(pmd_t *pmd, unsigned long addr,</span>
<span class="quote">&gt;  	spinlock_t *ptl;</span>
<span class="quote">&gt;  	pte_t *pte, ptent;</span>
<span class="quote">&gt;  	struct page *page;</span>
<span class="quote">&gt; +	swp_entry_t entry;</span>

This could go into !pte_present if block
<span class="quote">
&gt; +	int nr_swap = 0;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	split_huge_page_pmd(vma, addr, pmd);</span>
<span class="quote">&gt;  	if (pmd_trans_unstable(pmd))</span>
<span class="quote">&gt; @@ -280,8 +282,22 @@ static int madvise_free_pte_range(pmd_t *pmd, unsigned long addr,</span>
<span class="quote">&gt;  	for (; addr != end; pte++, addr += PAGE_SIZE) {</span>
<span class="quote">&gt;  		ptent = *pte;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; -		if (!pte_present(ptent))</span>
<span class="quote">&gt; +		if (pte_none(ptent))</span>
<span class="quote">&gt;  			continue;</span>
<span class="quote">&gt; +		/*</span>
<span class="quote">&gt; +		 * If the pte has swp_entry, just clear page table to</span>
<span class="quote">&gt; +		 * prevent swap-in which is more expensive rather than</span>
<span class="quote">&gt; +		 * (page allocation + zeroing).</span>
<span class="quote">&gt; +		 */</span>
<span class="quote">&gt; +		if (!pte_present(ptent)) {</span>
<span class="quote">&gt; +			entry = pte_to_swp_entry(ptent);</span>
<span class="quote">&gt; +			if (non_swap_entry(entry))</span>
<span class="quote">&gt; +				continue;</span>
<span class="quote">&gt; +			nr_swap--;</span>
<span class="quote">&gt; +			free_swap_and_cache(entry);</span>
<span class="quote">&gt; +			pte_clear_not_present_full(mm, addr, pte, tlb-&gt;fullmm);</span>
<span class="quote">&gt; +			continue;</span>
<span class="quote">&gt; +		}</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  		page = vm_normal_page(vma, addr, ptent);</span>
<span class="quote">&gt;  		if (!page)</span>
<span class="quote">&gt; @@ -313,6 +329,14 @@ static int madvise_free_pte_range(pmd_t *pmd, unsigned long addr,</span>
<span class="quote">&gt;  		set_pte_at(mm, addr, pte, ptent);</span>
<span class="quote">&gt;  		tlb_remove_tlb_entry(tlb, pte, addr);</span>
<span class="quote">&gt;  	}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	if (nr_swap) {</span>
<span class="quote">&gt; +		if (current-&gt;mm == mm)</span>
<span class="quote">&gt; +			sync_mm_rss(mm);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +		add_mm_counter(mm, MM_SWAPENTS, nr_swap);</span>
<span class="quote">&gt; +	}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt;  	arch_leave_lazy_mmu_mode();</span>
<span class="quote">&gt;  	pte_unmap_unlock(pte - 1, ptl);</span>
<span class="quote">&gt;  	cond_resched();</span>
<span class="quote">&gt; -- </span>
<span class="quote">&gt; 1.9.1</span>
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=36811">Minchan Kim</a> - Nov. 3, 2015, 12:53 a.m.</div>
<pre class="content">
On Fri, Oct 30, 2015 at 01:28:14PM +0100, Michal Hocko wrote:
<span class="quote">&gt; On Fri 30-10-15 16:01:40, Minchan Kim wrote:</span>
<span class="quote">&gt; &gt; When I test below piece of code with 12 processes(ie, 512M * 12 = 6G</span>
<span class="quote">&gt; &gt; consume) on my (3G ram + 12 cpu + 8G swap, the madvise_free is siginficat</span>
<span class="quote">&gt; &gt; slower (ie, 2x times) than madvise_dontneed.</span>
<span class="quote">&gt; &gt; </span>
<span class="quote">&gt; &gt; loop = 5;</span>
<span class="quote">&gt; &gt; mmap(512M);</span>
<span class="quote">&gt; &gt; while (loop--) {</span>
<span class="quote">&gt; &gt;         memset(512M);</span>
<span class="quote">&gt; &gt;         madvise(MADV_FREE or MADV_DONTNEED);</span>
<span class="quote">&gt; &gt; }</span>
<span class="quote">&gt; &gt; </span>
<span class="quote">&gt; &gt; The reason is lots of swapin.</span>
<span class="quote">&gt; &gt; </span>
<span class="quote">&gt; &gt; 1) dontneed: 1,612 swapin</span>
<span class="quote">&gt; &gt; 2) madvfree: 879,585 swapin</span>
<span class="quote">&gt; &gt; </span>
<span class="quote">&gt; &gt; If we find hinted pages were already swapped out when syscall is called,</span>
<span class="quote">&gt; &gt; it&#39;s pointless to keep the swapped-out pages in pte.</span>
<span class="quote">&gt; &gt; Instead, let&#39;s free the cold page because swapin is more expensive</span>
<span class="quote">&gt; &gt; than (alloc page + zeroing).</span>
<span class="quote">&gt; &gt; </span>
<span class="quote">&gt; &gt; With this patch, it reduced swapin from 879,585 to 1,878 so elapsed time</span>
<span class="quote">&gt; &gt; </span>
<span class="quote">&gt; &gt; 1) dontneed: 6.10user 233.50system 0:50.44elapsed</span>
<span class="quote">&gt; &gt; 2) madvfree: 6.03user 401.17system 1:30.67elapsed</span>
<span class="quote">&gt; &gt; 2) madvfree + below patch: 6.70user 339.14system 1:04.45elapsed</span>
<span class="quote">&gt; &gt; </span>
<span class="quote">&gt; &gt; Acked-by: Hugh Dickins &lt;hughd@google.com&gt;</span>
<span class="quote">&gt; &gt; Signed-off-by: Minchan Kim &lt;minchan@kernel.org&gt;</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Yes this makes a lot of sense.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Acked-by: Michal Hocko &lt;mhocko@suse.com&gt;</span>

Thanks!
<span class="quote">
&gt; </span>
<span class="quote">&gt; One nit below.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; &gt; ---</span>
<span class="quote">&gt; &gt;  mm/madvise.c | 26 +++++++++++++++++++++++++-</span>
<span class="quote">&gt; &gt;  1 file changed, 25 insertions(+), 1 deletion(-)</span>
<span class="quote">&gt; &gt; </span>
<span class="quote">&gt; &gt; diff --git a/mm/madvise.c b/mm/madvise.c</span>
<span class="quote">&gt; &gt; index 640311704e31..663bd9fa0ae0 100644</span>
<span class="quote">&gt; &gt; --- a/mm/madvise.c</span>
<span class="quote">&gt; &gt; +++ b/mm/madvise.c</span>
<span class="quote">&gt; &gt; @@ -270,6 +270,8 @@ static int madvise_free_pte_range(pmd_t *pmd, unsigned long addr,</span>
<span class="quote">&gt; &gt;  	spinlock_t *ptl;</span>
<span class="quote">&gt; &gt;  	pte_t *pte, ptent;</span>
<span class="quote">&gt; &gt;  	struct page *page;</span>
<span class="quote">&gt; &gt; +	swp_entry_t entry;</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; This could go into !pte_present if block</span>

Sure, I fixed.
--
To unsubscribe from this list: send the line &quot;unsubscribe linux-kernel&quot; in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
Please read the FAQ at  http://www.tux.org/lkml/
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/mm/madvise.c b/mm/madvise.c</span>
<span class="p_header">index 640311704e31..663bd9fa0ae0 100644</span>
<span class="p_header">--- a/mm/madvise.c</span>
<span class="p_header">+++ b/mm/madvise.c</span>
<span class="p_chunk">@@ -270,6 +270,8 @@</span> <span class="p_context"> static int madvise_free_pte_range(pmd_t *pmd, unsigned long addr,</span>
 	spinlock_t *ptl;
 	pte_t *pte, ptent;
 	struct page *page;
<span class="p_add">+	swp_entry_t entry;</span>
<span class="p_add">+	int nr_swap = 0;</span>
 
 	split_huge_page_pmd(vma, addr, pmd);
 	if (pmd_trans_unstable(pmd))
<span class="p_chunk">@@ -280,8 +282,22 @@</span> <span class="p_context"> static int madvise_free_pte_range(pmd_t *pmd, unsigned long addr,</span>
 	for (; addr != end; pte++, addr += PAGE_SIZE) {
 		ptent = *pte;
 
<span class="p_del">-		if (!pte_present(ptent))</span>
<span class="p_add">+		if (pte_none(ptent))</span>
 			continue;
<span class="p_add">+		/*</span>
<span class="p_add">+		 * If the pte has swp_entry, just clear page table to</span>
<span class="p_add">+		 * prevent swap-in which is more expensive rather than</span>
<span class="p_add">+		 * (page allocation + zeroing).</span>
<span class="p_add">+		 */</span>
<span class="p_add">+		if (!pte_present(ptent)) {</span>
<span class="p_add">+			entry = pte_to_swp_entry(ptent);</span>
<span class="p_add">+			if (non_swap_entry(entry))</span>
<span class="p_add">+				continue;</span>
<span class="p_add">+			nr_swap--;</span>
<span class="p_add">+			free_swap_and_cache(entry);</span>
<span class="p_add">+			pte_clear_not_present_full(mm, addr, pte, tlb-&gt;fullmm);</span>
<span class="p_add">+			continue;</span>
<span class="p_add">+		}</span>
 
 		page = vm_normal_page(vma, addr, ptent);
 		if (!page)
<span class="p_chunk">@@ -313,6 +329,14 @@</span> <span class="p_context"> static int madvise_free_pte_range(pmd_t *pmd, unsigned long addr,</span>
 		set_pte_at(mm, addr, pte, ptent);
 		tlb_remove_tlb_entry(tlb, pte, addr);
 	}
<span class="p_add">+</span>
<span class="p_add">+	if (nr_swap) {</span>
<span class="p_add">+		if (current-&gt;mm == mm)</span>
<span class="p_add">+			sync_mm_rss(mm);</span>
<span class="p_add">+</span>
<span class="p_add">+		add_mm_counter(mm, MM_SWAPENTS, nr_swap);</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
 	arch_leave_lazy_mmu_mode();
 	pte_unmap_unlock(pte - 1, ptl);
 	cond_resched();

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



