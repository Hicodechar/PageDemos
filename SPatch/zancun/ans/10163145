
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>[v6,09/36] nds32: MMU initialization - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    [v6,09/36] nds32: MMU initialization</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=171217">Greentime Hu</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>Jan. 15, 2018, 5:53 a.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;f27b75af63adeb7f543151fdc248dceea85ef0c4.1515766253.git.green.hu@gmail.com&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/10163145/mbox/"
   >mbox</a>
|
   <a href="/patch/10163145/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/10163145/">/patch/10163145/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
	[172.30.200.125])
	by pdx-korg-patchwork.web.codeaurora.org (Postfix) with ESMTP id
	1385560245 for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Mon, 15 Jan 2018 06:07:13 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id E7D52288E0
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Mon, 15 Jan 2018 06:07:12 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id DC55E288ED; Mon, 15 Jan 2018 06:07:12 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-7.0 required=2.0 tests=BAYES_00,DKIM_SIGNED,
	DKIM_VALID, DKIM_VALID_AU, FREEMAIL_FROM,
	RCVD_IN_DNSWL_HI autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id C3C14288E0
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Mon, 15 Jan 2018 06:07:11 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S932660AbeAOFyz (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Mon, 15 Jan 2018 00:54:55 -0500
Received: from mail-pf0-f196.google.com ([209.85.192.196]:34910 &quot;EHLO
	mail-pf0-f196.google.com&quot; rhost-flags-OK-OK-OK-OK) by vger.kernel.org
	with ESMTP id S932450AbeAOFyt (ORCPT
	&lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Mon, 15 Jan 2018 00:54:49 -0500
Received: by mail-pf0-f196.google.com with SMTP id t12so7559404pfg.2;
	Sun, 14 Jan 2018 21:54:48 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
	d=gmail.com; s=20161025;
	h=from:to:cc:subject:date:message-id:in-reply-to:references
	:in-reply-to:references;
	bh=u0H+EQoSba3OVoj86LaIvNgdH4NdyHmaYFfL/UFwrG0=;
	b=VQfHHQNf/JLInInQF4+aqh2Ls+HwbeVhj9k8pV4TBNCltqrGzjS3cANaGyzgoNQVru
	JIhOurJpE44rorYu6sx1Yn1XFImNnBSc+6ku605ZQIgIqDCvwlA96FjeIz12xjybfrWW
	TVUOg+XYCQsVyuVEiRUkPzP7x/rZanB01TrB4zlITNR9myNlhd4Uh3QtY+EIPO2/2/kt
	O1PYTPhFRZqBD9bUGFf5uMPTyu977EH5yrwKHYsypLQ89D+F5WW3AkXzxfnapUwGN+Af
	fe0BD0IuEY0O0Twkf8APXgS0tshkd/v9dcAn3A1zZSqTvk9+o8qP6cpLDVpHU30XFH8y
	q2zQ==
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
	d=1e100.net; s=20161025;
	h=x-gm-message-state:from:to:cc:subject:date:message-id:in-reply-to
	:references:in-reply-to:references;
	bh=u0H+EQoSba3OVoj86LaIvNgdH4NdyHmaYFfL/UFwrG0=;
	b=ZFi2TjFSmEUTC7UhQn4roKB6AjIsuhK3Qp2pFjxRlP/EZi9yhFcu5AUaVuz/UvD0qp
	wX77p4iTihQGU25k9H9WgN/ITXwa8DFfCMvhH1HqW9L/JlTB94gaVJL0trhjMkngXJXB
	SOZenEES7mqU8SNW5sOWRIFLf8tCNrIih233IH0EjVuV2+XDOF7CDF5kJTMBozerBSA9
	Q5CIUDAhrJSKayXrwDfTrSO4jWiwOJPQFkT00Op0AzKxpfk3nAiUThNyv7pWj3gJKpmV
	kq4Rvt8yUZewlqEfriAnVHcMaNeYSYfpzxBkCIazRwDdKZxE06W+Jv986cG6OQ9ShpPE
	R51w==
X-Gm-Message-State: AKwxytco5uEzfYjgN5itKWfOCYTYxGuQqeGHGvM3fztvi//RQabBOG9I
	JT5nu+y3gFHfhkNC430nSaQ=
X-Google-Smtp-Source: ACJfBou2q1xn6bZIOcNnYaHslXCugQGMG/Xig3qyOnchls7xWgiVwjhy4pAXsPtbpHMvlrzr3ImhCw==
X-Received: by 10.99.55.5 with SMTP id e5mr1178311pga.237.1515995688010;
	Sun, 14 Jan 2018 21:54:48 -0800 (PST)
Received: from app09.andestech.com ([118.163.51.199])
	by smtp.gmail.com with ESMTPSA id
	h13sm49614291pfi.40.2018.01.14.21.54.43
	(version=TLS1_2 cipher=ECDHE-RSA-AES128-GCM-SHA256 bits=128/128);
	Sun, 14 Jan 2018 21:54:47 -0800 (PST)
From: Greentime Hu &lt;green.hu@gmail.com&gt;
To: greentime@andestech.com, linux-kernel@vger.kernel.org,
	arnd@arndb.de, linux-arch@vger.kernel.org, tglx@linutronix.de,
	jason@lakedaemon.net, marc.zyngier@arm.com, robh+dt@kernel.org,
	netdev@vger.kernel.org, deanbo422@gmail.com,
	devicetree@vger.kernel.org, viro@zeniv.linux.org.uk,
	dhowells@redhat.com, will.deacon@arm.com,
	daniel.lezcano@linaro.org, linux-serial@vger.kernel.org,
	geert.uytterhoeven@gmail.com, linus.walleij@linaro.org,
	mark.rutland@arm.com, greg@kroah.com, ren_guo@c-sky.com,
	rdunlap@infradead.org, davem@davemloft.net, jonas@southpole.se,
	stefan.kristiansson@saunalahti.fi, shorne@gmail.com
Cc: green.hu@gmail.com, Vincent Chen &lt;vincentc@andestech.com&gt;
Subject: [PATCH v6 09/36] nds32: MMU initialization
Date: Mon, 15 Jan 2018 13:53:17 +0800
Message-Id: &lt;f27b75af63adeb7f543151fdc248dceea85ef0c4.1515766253.git.green.hu@gmail.com&gt;
X-Mailer: git-send-email 1.7.9.5
In-Reply-To: &lt;cover.1515766253.git.green.hu@gmail.com&gt;
References: &lt;cover.1515766253.git.green.hu@gmail.com&gt;
In-Reply-To: &lt;cover.1515766253.git.green.hu@gmail.com&gt;
References: &lt;cover.1515766253.git.green.hu@gmail.com&gt;
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=171217">Greentime Hu</a> - Jan. 15, 2018, 5:53 a.m.</div>
<pre class="content">
<span class="from">From: Greentime Hu &lt;greentime@andestech.com&gt;</span>

This patch includes memory initializations and highmem supporting.
<span class="signed-off-by">
Signed-off-by: Vincent Chen &lt;vincentc@andestech.com&gt;</span>
<span class="signed-off-by">Signed-off-by: Greentime Hu &lt;greentime@andestech.com&gt;</span>
---
 arch/nds32/mm/highmem.c  |   79 +++++++++++++
 arch/nds32/mm/init.c     |  277 ++++++++++++++++++++++++++++++++++++++++++++++
 arch/nds32/mm/mm-nds32.c |   90 +++++++++++++++
 3 files changed, 446 insertions(+)
 create mode 100644 arch/nds32/mm/highmem.c
 create mode 100644 arch/nds32/mm/init.c
 create mode 100644 arch/nds32/mm/mm-nds32.c
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=176">Arnd Bergmann</a> - Jan. 18, 2018, 10:16 a.m.</div>
<pre class="content">
On Mon, Jan 15, 2018 at 6:53 AM, Greentime Hu &lt;green.hu@gmail.com&gt; wrote:
<span class="quote">&gt; From: Greentime Hu &lt;greentime@andestech.com&gt;</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; This patch includes memory initializations and highmem supporting.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; Signed-off-by: Vincent Chen &lt;vincentc@andestech.com&gt;</span>
<span class="quote">&gt; Signed-off-by: Greentime Hu &lt;greentime@andestech.com&gt;</span>
<span class="acked-by">
Acked-by: Arnd Bergmann &lt;arnd@arndb.de&gt;</span>
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/arch/nds32/mm/highmem.c b/arch/nds32/mm/highmem.c</span>
new file mode 100644
<span class="p_header">index 0000000..e17cb8a</span>
<span class="p_header">--- /dev/null</span>
<span class="p_header">+++ b/arch/nds32/mm/highmem.c</span>
<span class="p_chunk">@@ -0,0 +1,79 @@</span> <span class="p_context"></span>
<span class="p_add">+// SPDX-License-Identifier: GPL-2.0</span>
<span class="p_add">+// Copyright (C) 2005-2017 Andes Technology Corporation</span>
<span class="p_add">+</span>
<span class="p_add">+#include &lt;linux/export.h&gt;</span>
<span class="p_add">+#include &lt;linux/highmem.h&gt;</span>
<span class="p_add">+#include &lt;linux/sched.h&gt;</span>
<span class="p_add">+#include &lt;linux/smp.h&gt;</span>
<span class="p_add">+#include &lt;linux/interrupt.h&gt;</span>
<span class="p_add">+#include &lt;linux/bootmem.h&gt;</span>
<span class="p_add">+#include &lt;asm/fixmap.h&gt;</span>
<span class="p_add">+#include &lt;asm/tlbflush.h&gt;</span>
<span class="p_add">+</span>
<span class="p_add">+void *kmap(struct page *page)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long vaddr;</span>
<span class="p_add">+	might_sleep();</span>
<span class="p_add">+	if (!PageHighMem(page))</span>
<span class="p_add">+		return page_address(page);</span>
<span class="p_add">+	vaddr = (unsigned long)kmap_high(page);</span>
<span class="p_add">+	return (void *)vaddr;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+EXPORT_SYMBOL(kmap);</span>
<span class="p_add">+</span>
<span class="p_add">+void kunmap(struct page *page)</span>
<span class="p_add">+{</span>
<span class="p_add">+	BUG_ON(in_interrupt());</span>
<span class="p_add">+	if (!PageHighMem(page))</span>
<span class="p_add">+		return;</span>
<span class="p_add">+	kunmap_high(page);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+EXPORT_SYMBOL(kunmap);</span>
<span class="p_add">+</span>
<span class="p_add">+void *kmap_atomic(struct page *page)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned int idx;</span>
<span class="p_add">+	unsigned long vaddr, pte;</span>
<span class="p_add">+	int type;</span>
<span class="p_add">+	pte_t *ptep;</span>
<span class="p_add">+</span>
<span class="p_add">+	preempt_disable();</span>
<span class="p_add">+	pagefault_disable();</span>
<span class="p_add">+	if (!PageHighMem(page))</span>
<span class="p_add">+		return page_address(page);</span>
<span class="p_add">+</span>
<span class="p_add">+	type = kmap_atomic_idx_push();</span>
<span class="p_add">+</span>
<span class="p_add">+	idx = type + KM_TYPE_NR * smp_processor_id();</span>
<span class="p_add">+	vaddr = __fix_to_virt(FIX_KMAP_BEGIN + idx);</span>
<span class="p_add">+	pte = (page_to_pfn(page) &lt;&lt; PAGE_SHIFT) | (PAGE_KERNEL);</span>
<span class="p_add">+	ptep = pte_offset_kernel(pmd_off_k(vaddr), vaddr);</span>
<span class="p_add">+	set_pte(ptep, pte);</span>
<span class="p_add">+</span>
<span class="p_add">+	__nds32__tlbop_inv(vaddr);</span>
<span class="p_add">+	__nds32__mtsr_dsb(vaddr, NDS32_SR_TLB_VPN);</span>
<span class="p_add">+	__nds32__tlbop_rwr(pte);</span>
<span class="p_add">+	__nds32__isb();</span>
<span class="p_add">+	return (void *)vaddr;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+EXPORT_SYMBOL(kmap_atomic);</span>
<span class="p_add">+</span>
<span class="p_add">+void __kunmap_atomic(void *kvaddr)</span>
<span class="p_add">+{</span>
<span class="p_add">+	if (kvaddr &gt;= (void *)FIXADDR_START) {</span>
<span class="p_add">+		unsigned long vaddr = (unsigned long)kvaddr;</span>
<span class="p_add">+		pte_t *ptep;</span>
<span class="p_add">+		kmap_atomic_idx_pop();</span>
<span class="p_add">+		__nds32__tlbop_inv(vaddr);</span>
<span class="p_add">+		__nds32__isb();</span>
<span class="p_add">+		ptep = pte_offset_kernel(pmd_off_k(vaddr), vaddr);</span>
<span class="p_add">+		set_pte(ptep, 0);</span>
<span class="p_add">+	}</span>
<span class="p_add">+	pagefault_enable();</span>
<span class="p_add">+	preempt_enable();</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+EXPORT_SYMBOL(__kunmap_atomic);</span>
<span class="p_header">diff --git a/arch/nds32/mm/init.c b/arch/nds32/mm/init.c</span>
new file mode 100644
<span class="p_header">index 0000000..93ee016</span>
<span class="p_header">--- /dev/null</span>
<span class="p_header">+++ b/arch/nds32/mm/init.c</span>
<span class="p_chunk">@@ -0,0 +1,277 @@</span> <span class="p_context"></span>
<span class="p_add">+// SPDX-License-Identifier: GPL-2.0</span>
<span class="p_add">+// Copyright (C) 1995-2005 Russell King</span>
<span class="p_add">+// Copyright (C) 2012 ARM Ltd.</span>
<span class="p_add">+// Copyright (C) 2013-2017 Andes Technology Corporation</span>
<span class="p_add">+</span>
<span class="p_add">+#include &lt;linux/kernel.h&gt;</span>
<span class="p_add">+#include &lt;linux/errno.h&gt;</span>
<span class="p_add">+#include &lt;linux/swap.h&gt;</span>
<span class="p_add">+#include &lt;linux/init.h&gt;</span>
<span class="p_add">+#include &lt;linux/bootmem.h&gt;</span>
<span class="p_add">+#include &lt;linux/mman.h&gt;</span>
<span class="p_add">+#include &lt;linux/nodemask.h&gt;</span>
<span class="p_add">+#include &lt;linux/initrd.h&gt;</span>
<span class="p_add">+#include &lt;linux/highmem.h&gt;</span>
<span class="p_add">+#include &lt;linux/memblock.h&gt;</span>
<span class="p_add">+</span>
<span class="p_add">+#include &lt;asm/sections.h&gt;</span>
<span class="p_add">+#include &lt;asm/setup.h&gt;</span>
<span class="p_add">+#include &lt;asm/tlb.h&gt;</span>
<span class="p_add">+#include &lt;asm/page.h&gt;</span>
<span class="p_add">+</span>
<span class="p_add">+DEFINE_PER_CPU(struct mmu_gather, mmu_gathers);</span>
<span class="p_add">+DEFINE_SPINLOCK(anon_alias_lock);</span>
<span class="p_add">+extern pgd_t swapper_pg_dir[PTRS_PER_PGD];</span>
<span class="p_add">+extern unsigned long phys_initrd_start;</span>
<span class="p_add">+extern unsigned long phys_initrd_size;</span>
<span class="p_add">+</span>
<span class="p_add">+/*</span>
<span class="p_add">+ * empty_zero_page is a special page that is used for</span>
<span class="p_add">+ * zero-initialized data and COW.</span>
<span class="p_add">+ */</span>
<span class="p_add">+struct page *empty_zero_page;</span>
<span class="p_add">+</span>
<span class="p_add">+static void __init zone_sizes_init(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long zones_size[MAX_NR_ZONES];</span>
<span class="p_add">+</span>
<span class="p_add">+	/* Clear the zone sizes */</span>
<span class="p_add">+	memset(zones_size, 0, sizeof(zones_size));</span>
<span class="p_add">+</span>
<span class="p_add">+	zones_size[ZONE_NORMAL] = max_low_pfn;</span>
<span class="p_add">+#ifdef CONFIG_HIGHMEM</span>
<span class="p_add">+	zones_size[ZONE_HIGHMEM] = max_pfn;</span>
<span class="p_add">+#endif</span>
<span class="p_add">+	free_area_init(zones_size);</span>
<span class="p_add">+</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+/*</span>
<span class="p_add">+ * Map all physical memory under high_memory into kernel&#39;s address space.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * This is explicitly coded for two-level page tables, so if you need</span>
<span class="p_add">+ * something else then this needs to change.</span>
<span class="p_add">+ */</span>
<span class="p_add">+static void __init map_ram(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long v, p, e;</span>
<span class="p_add">+	pgd_t *pge;</span>
<span class="p_add">+	pud_t *pue;</span>
<span class="p_add">+	pmd_t *pme;</span>
<span class="p_add">+	pte_t *pte;</span>
<span class="p_add">+	/* These mark extents of read-only kernel pages...</span>
<span class="p_add">+	 * ...from vmlinux.lds.S</span>
<span class="p_add">+	 */</span>
<span class="p_add">+</span>
<span class="p_add">+	p = (u32) memblock_start_of_DRAM() &amp; PAGE_MASK;</span>
<span class="p_add">+	e = min((u32) memblock_end_of_DRAM(), (u32) __pa(high_memory));</span>
<span class="p_add">+</span>
<span class="p_add">+	v = (u32) __va(p);</span>
<span class="p_add">+	pge = pgd_offset_k(v);</span>
<span class="p_add">+</span>
<span class="p_add">+	while (p &lt; e) {</span>
<span class="p_add">+		int j;</span>
<span class="p_add">+		pue = pud_offset(pge, v);</span>
<span class="p_add">+		pme = pmd_offset(pue, v);</span>
<span class="p_add">+</span>
<span class="p_add">+		if ((u32) pue != (u32) pge || (u32) pme != (u32) pge) {</span>
<span class="p_add">+			panic(&quot;%s: Kernel hardcoded for &quot;</span>
<span class="p_add">+			      &quot;two-level page tables&quot;, __func__);</span>
<span class="p_add">+		}</span>
<span class="p_add">+</span>
<span class="p_add">+		/* Alloc one page for holding PTE&#39;s... */</span>
<span class="p_add">+		pte = (pte_t *) __va(memblock_alloc(PAGE_SIZE, PAGE_SIZE));</span>
<span class="p_add">+		memset(pte, 0, PAGE_SIZE);</span>
<span class="p_add">+		set_pmd(pme, __pmd(__pa(pte) + _PAGE_KERNEL_TABLE));</span>
<span class="p_add">+</span>
<span class="p_add">+		/* Fill the newly allocated page with PTE&#39;S */</span>
<span class="p_add">+		for (j = 0; p &lt; e &amp;&amp; j &lt; PTRS_PER_PTE;</span>
<span class="p_add">+		     v += PAGE_SIZE, p += PAGE_SIZE, j++, pte++) {</span>
<span class="p_add">+			/* Create mapping between p and v. */</span>
<span class="p_add">+			/* TODO: more fine grant for page access permission */</span>
<span class="p_add">+			set_pte(pte, __pte(p + pgprot_val(PAGE_KERNEL)));</span>
<span class="p_add">+		}</span>
<span class="p_add">+</span>
<span class="p_add">+		pge++;</span>
<span class="p_add">+	}</span>
<span class="p_add">+}</span>
<span class="p_add">+static pmd_t *fixmap_pmd_p;</span>
<span class="p_add">+static void __init fixedrange_init(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long vaddr;</span>
<span class="p_add">+	pgd_t *pgd;</span>
<span class="p_add">+	pud_t *pud;</span>
<span class="p_add">+	pmd_t *pmd;</span>
<span class="p_add">+#ifdef CONFIG_HIGHMEM</span>
<span class="p_add">+	pte_t *pte;</span>
<span class="p_add">+#endif /* CONFIG_HIGHMEM */</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Fixed mappings:</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	vaddr = __fix_to_virt(__end_of_fixed_addresses - 1);</span>
<span class="p_add">+	pgd = swapper_pg_dir + pgd_index(vaddr);</span>
<span class="p_add">+	pud = pud_offset(pgd, vaddr);</span>
<span class="p_add">+	pmd = pmd_offset(pud, vaddr);</span>
<span class="p_add">+	fixmap_pmd_p = (pmd_t *) __va(memblock_alloc(PAGE_SIZE, PAGE_SIZE));</span>
<span class="p_add">+	memset(fixmap_pmd_p, 0, PAGE_SIZE);</span>
<span class="p_add">+	set_pmd(pmd, __pmd(__pa(fixmap_pmd_p) + _PAGE_KERNEL_TABLE));</span>
<span class="p_add">+</span>
<span class="p_add">+#ifdef CONFIG_HIGHMEM</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Permanent kmaps:</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	vaddr = PKMAP_BASE;</span>
<span class="p_add">+</span>
<span class="p_add">+	pgd = swapper_pg_dir + pgd_index(vaddr);</span>
<span class="p_add">+	pud = pud_offset(pgd, vaddr);</span>
<span class="p_add">+	pmd = pmd_offset(pud, vaddr);</span>
<span class="p_add">+	pte = (pte_t *) __va(memblock_alloc(PAGE_SIZE, PAGE_SIZE));</span>
<span class="p_add">+	memset(pte, 0, PAGE_SIZE);</span>
<span class="p_add">+	set_pmd(pmd, __pmd(__pa(pte) + _PAGE_KERNEL_TABLE));</span>
<span class="p_add">+	pkmap_page_table = pte;</span>
<span class="p_add">+#endif /* CONFIG_HIGHMEM */</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+/*</span>
<span class="p_add">+ * paging_init() sets up the page tables, initialises the zone memory</span>
<span class="p_add">+ * maps, and sets up the zero page, bad page and bad page tables.</span>
<span class="p_add">+ */</span>
<span class="p_add">+void __init paging_init(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	int i;</span>
<span class="p_add">+	void *zero_page;</span>
<span class="p_add">+</span>
<span class="p_add">+	pr_info(&quot;Setting up paging and PTEs.\n&quot;);</span>
<span class="p_add">+	/* clear out the init_mm.pgd that will contain the kernel&#39;s mappings */</span>
<span class="p_add">+	for (i = 0; i &lt; PTRS_PER_PGD; i++)</span>
<span class="p_add">+		swapper_pg_dir[i] = __pgd(1);</span>
<span class="p_add">+</span>
<span class="p_add">+	map_ram();</span>
<span class="p_add">+</span>
<span class="p_add">+	fixedrange_init();</span>
<span class="p_add">+</span>
<span class="p_add">+	/* allocate space for empty_zero_page */</span>
<span class="p_add">+	zero_page = __va(memblock_alloc(PAGE_SIZE, PAGE_SIZE));</span>
<span class="p_add">+	memset(zero_page, 0, PAGE_SIZE);</span>
<span class="p_add">+	zone_sizes_init();</span>
<span class="p_add">+</span>
<span class="p_add">+	empty_zero_page = virt_to_page(zero_page);</span>
<span class="p_add">+	flush_dcache_page(empty_zero_page);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline void __init free_highmem(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+#ifdef CONFIG_HIGHMEM</span>
<span class="p_add">+	unsigned long pfn;</span>
<span class="p_add">+	for (pfn = PFN_UP(__pa(high_memory)); pfn &lt; max_pfn; pfn++) {</span>
<span class="p_add">+		phys_addr_t paddr = (phys_addr_t) pfn &lt;&lt; PAGE_SHIFT;</span>
<span class="p_add">+		if (!memblock_is_reserved(paddr))</span>
<span class="p_add">+			free_highmem_page(pfn_to_page(pfn));</span>
<span class="p_add">+	}</span>
<span class="p_add">+#endif</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static void __init set_max_mapnr_init(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	max_mapnr = max_pfn;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+/*</span>
<span class="p_add">+ * mem_init() marks the free areas in the mem_map and tells us how much</span>
<span class="p_add">+ * memory is free.  This is done after various parts of the system have</span>
<span class="p_add">+ * claimed their memory after the kernel image.</span>
<span class="p_add">+ */</span>
<span class="p_add">+void __init mem_init(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	phys_addr_t memory_start = memblock_start_of_DRAM();</span>
<span class="p_add">+	BUG_ON(!mem_map);</span>
<span class="p_add">+	set_max_mapnr_init();</span>
<span class="p_add">+</span>
<span class="p_add">+	free_highmem();</span>
<span class="p_add">+</span>
<span class="p_add">+	/* this will put all low memory onto the freelists */</span>
<span class="p_add">+	free_all_bootmem();</span>
<span class="p_add">+	mem_init_print_info(NULL);</span>
<span class="p_add">+</span>
<span class="p_add">+	pr_info(&quot;virtual kernel memory layout:\n&quot;</span>
<span class="p_add">+		&quot;    fixmap  : 0x%08lx - 0x%08lx   (%4ld kB)\n&quot;</span>
<span class="p_add">+#ifdef CONFIG_HIGHMEM</span>
<span class="p_add">+		&quot;    pkmap   : 0x%08lx - 0x%08lx   (%4ld kB)\n&quot;</span>
<span class="p_add">+#endif</span>
<span class="p_add">+		&quot;    consist : 0x%08lx - 0x%08lx   (%4ld MB)\n&quot;</span>
<span class="p_add">+		&quot;    vmalloc : 0x%08lx - 0x%08lx   (%4ld MB)\n&quot;</span>
<span class="p_add">+		&quot;    lowmem  : 0x%08lx - 0x%08lx   (%4ld MB)\n&quot;</span>
<span class="p_add">+		&quot;      .init : 0x%08lx - 0x%08lx   (%4ld kB)\n&quot;</span>
<span class="p_add">+		&quot;      .data : 0x%08lx - 0x%08lx   (%4ld kB)\n&quot;</span>
<span class="p_add">+		&quot;      .text : 0x%08lx - 0x%08lx   (%4ld kB)\n&quot;,</span>
<span class="p_add">+		FIXADDR_START, FIXADDR_TOP, (FIXADDR_TOP - FIXADDR_START) &gt;&gt; 10,</span>
<span class="p_add">+#ifdef CONFIG_HIGHMEM</span>
<span class="p_add">+		PKMAP_BASE, PKMAP_BASE + LAST_PKMAP * PAGE_SIZE,</span>
<span class="p_add">+		(LAST_PKMAP * PAGE_SIZE) &gt;&gt; 10,</span>
<span class="p_add">+#endif</span>
<span class="p_add">+		CONSISTENT_BASE, CONSISTENT_END,</span>
<span class="p_add">+		((CONSISTENT_END) - (CONSISTENT_BASE)) &gt;&gt; 20, VMALLOC_START,</span>
<span class="p_add">+		(unsigned long)VMALLOC_END, (VMALLOC_END - VMALLOC_START) &gt;&gt; 20,</span>
<span class="p_add">+		(unsigned long)__va(memory_start), (unsigned long)high_memory,</span>
<span class="p_add">+		((unsigned long)high_memory -</span>
<span class="p_add">+		 (unsigned long)__va(memory_start)) &gt;&gt; 20,</span>
<span class="p_add">+		(unsigned long)&amp;__init_begin, (unsigned long)&amp;__init_end,</span>
<span class="p_add">+		((unsigned long)&amp;__init_end -</span>
<span class="p_add">+		 (unsigned long)&amp;__init_begin) &gt;&gt; 10, (unsigned long)&amp;_etext,</span>
<span class="p_add">+		(unsigned long)&amp;_edata,</span>
<span class="p_add">+		((unsigned long)&amp;_edata - (unsigned long)&amp;_etext) &gt;&gt; 10,</span>
<span class="p_add">+		(unsigned long)&amp;_text, (unsigned long)&amp;_etext,</span>
<span class="p_add">+		((unsigned long)&amp;_etext - (unsigned long)&amp;_text) &gt;&gt; 10);</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Check boundaries twice: Some fundamental inconsistencies can</span>
<span class="p_add">+	 * be detected at build time already.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+#ifdef CONFIG_HIGHMEM</span>
<span class="p_add">+	BUILD_BUG_ON(PKMAP_BASE + LAST_PKMAP * PAGE_SIZE &gt; FIXADDR_START);</span>
<span class="p_add">+	BUILD_BUG_ON((CONSISTENT_END) &gt; PKMAP_BASE);</span>
<span class="p_add">+#endif</span>
<span class="p_add">+	BUILD_BUG_ON(VMALLOC_END &gt; CONSISTENT_BASE);</span>
<span class="p_add">+	BUILD_BUG_ON(VMALLOC_START &gt;= VMALLOC_END);</span>
<span class="p_add">+</span>
<span class="p_add">+#ifdef CONFIG_HIGHMEM</span>
<span class="p_add">+	BUG_ON(PKMAP_BASE + LAST_PKMAP * PAGE_SIZE &gt; FIXADDR_START);</span>
<span class="p_add">+	BUG_ON(CONSISTENT_END &gt; PKMAP_BASE);</span>
<span class="p_add">+#endif</span>
<span class="p_add">+	BUG_ON(VMALLOC_END &gt; CONSISTENT_BASE);</span>
<span class="p_add">+	BUG_ON(VMALLOC_START &gt;= VMALLOC_END);</span>
<span class="p_add">+	BUG_ON((unsigned long)high_memory &gt; VMALLOC_START);</span>
<span class="p_add">+</span>
<span class="p_add">+	return;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void free_initmem(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	free_initmem_default(-1);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+#ifdef CONFIG_BLK_DEV_INITRD</span>
<span class="p_add">+void free_initrd_mem(unsigned long start, unsigned long end)</span>
<span class="p_add">+{</span>
<span class="p_add">+	free_reserved_area((void *)start, (void *)end, -1, &quot;initrd&quot;);</span>
<span class="p_add">+}</span>
<span class="p_add">+#endif</span>
<span class="p_add">+</span>
<span class="p_add">+void __set_fixmap(enum fixed_addresses idx,</span>
<span class="p_add">+			       phys_addr_t phys, pgprot_t flags)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long addr = __fix_to_virt(idx);</span>
<span class="p_add">+	pte_t *pte;</span>
<span class="p_add">+</span>
<span class="p_add">+	BUG_ON(idx &lt;= FIX_HOLE || idx &gt;= __end_of_fixed_addresses);</span>
<span class="p_add">+</span>
<span class="p_add">+	pte = (pte_t *)&amp;fixmap_pmd_p[pte_index(addr)];;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (pgprot_val(flags)) {</span>
<span class="p_add">+		set_pte(pte, pfn_pte(phys &gt;&gt; PAGE_SHIFT, flags));</span>
<span class="p_add">+	} else {</span>
<span class="p_add">+		pte_clear(&amp;init_mm, addr, pte);</span>
<span class="p_add">+		flush_tlb_kernel_range(addr, addr + PAGE_SIZE);</span>
<span class="p_add">+	}</span>
<span class="p_add">+}</span>
<span class="p_header">diff --git a/arch/nds32/mm/mm-nds32.c b/arch/nds32/mm/mm-nds32.c</span>
new file mode 100644
<span class="p_header">index 0000000..7f7d4b36</span>
<span class="p_header">--- /dev/null</span>
<span class="p_header">+++ b/arch/nds32/mm/mm-nds32.c</span>
<span class="p_chunk">@@ -0,0 +1,90 @@</span> <span class="p_context"></span>
<span class="p_add">+// SPDX-License-Identifier: GPL-2.0</span>
<span class="p_add">+// Copyright (C) 2005-2017 Andes Technology Corporation</span>
<span class="p_add">+</span>
<span class="p_add">+#include &lt;linux/init_task.h&gt;</span>
<span class="p_add">+#include &lt;asm/pgalloc.h&gt;</span>
<span class="p_add">+</span>
<span class="p_add">+#define FIRST_KERNEL_PGD_NR	(USER_PTRS_PER_PGD)</span>
<span class="p_add">+</span>
<span class="p_add">+/*</span>
<span class="p_add">+ * need to get a page for level 1</span>
<span class="p_add">+ */</span>
<span class="p_add">+</span>
<span class="p_add">+pgd_t *pgd_alloc(struct mm_struct *mm)</span>
<span class="p_add">+{</span>
<span class="p_add">+	pgd_t *new_pgd, *init_pgd;</span>
<span class="p_add">+	int i;</span>
<span class="p_add">+</span>
<span class="p_add">+	new_pgd = (pgd_t *) __get_free_pages(GFP_KERNEL, 0);</span>
<span class="p_add">+	if (!new_pgd)</span>
<span class="p_add">+		return NULL;</span>
<span class="p_add">+	for (i = 0; i &lt; PTRS_PER_PGD; i++) {</span>
<span class="p_add">+		(*new_pgd) = 1;</span>
<span class="p_add">+		new_pgd++;</span>
<span class="p_add">+	}</span>
<span class="p_add">+	new_pgd -= PTRS_PER_PGD;</span>
<span class="p_add">+</span>
<span class="p_add">+	init_pgd = pgd_offset_k(0);</span>
<span class="p_add">+</span>
<span class="p_add">+	memcpy(new_pgd + FIRST_KERNEL_PGD_NR, init_pgd + FIRST_KERNEL_PGD_NR,</span>
<span class="p_add">+	       (PTRS_PER_PGD - FIRST_KERNEL_PGD_NR) * sizeof(pgd_t));</span>
<span class="p_add">+</span>
<span class="p_add">+	cpu_dcache_wb_range((unsigned long)new_pgd,</span>
<span class="p_add">+			    (unsigned long)new_pgd +</span>
<span class="p_add">+			    PTRS_PER_PGD * sizeof(pgd_t));</span>
<span class="p_add">+	inc_zone_page_state(virt_to_page((unsigned long *)new_pgd),</span>
<span class="p_add">+			    NR_PAGETABLE);</span>
<span class="p_add">+</span>
<span class="p_add">+	return new_pgd;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void pgd_free(struct mm_struct *mm, pgd_t * pgd)</span>
<span class="p_add">+{</span>
<span class="p_add">+	pmd_t *pmd;</span>
<span class="p_add">+	struct page *pte;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (!pgd)</span>
<span class="p_add">+		return;</span>
<span class="p_add">+</span>
<span class="p_add">+	pmd = (pmd_t *) pgd;</span>
<span class="p_add">+	if (pmd_none(*pmd))</span>
<span class="p_add">+		goto free;</span>
<span class="p_add">+	if (pmd_bad(*pmd)) {</span>
<span class="p_add">+		pmd_ERROR(*pmd);</span>
<span class="p_add">+		pmd_clear(pmd);</span>
<span class="p_add">+		goto free;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	pte = pmd_page(*pmd);</span>
<span class="p_add">+	pmd_clear(pmd);</span>
<span class="p_add">+	dec_zone_page_state(virt_to_page((unsigned long *)pgd), NR_PAGETABLE);</span>
<span class="p_add">+	pte_free(mm, pte);</span>
<span class="p_add">+	atomic_long_dec(&amp;mm-&gt;nr_ptes);</span>
<span class="p_add">+	pmd_free(mm, pmd);</span>
<span class="p_add">+free:</span>
<span class="p_add">+	free_pages((unsigned long)pgd, 0);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+/*</span>
<span class="p_add">+ * In order to soft-boot, we need to insert a 1:1 mapping in place of</span>
<span class="p_add">+ * the user-mode pages.  This will then ensure that we have predictable</span>
<span class="p_add">+ * results when turning the mmu off</span>
<span class="p_add">+ */</span>
<span class="p_add">+void setup_mm_for_reboot(char mode)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long pmdval;</span>
<span class="p_add">+	pgd_t *pgd;</span>
<span class="p_add">+	pmd_t *pmd;</span>
<span class="p_add">+	int i;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (current-&gt;mm &amp;&amp; current-&gt;mm-&gt;pgd)</span>
<span class="p_add">+		pgd = current-&gt;mm-&gt;pgd;</span>
<span class="p_add">+	else</span>
<span class="p_add">+		pgd = init_mm.pgd;</span>
<span class="p_add">+</span>
<span class="p_add">+	for (i = 0; i &lt; USER_PTRS_PER_PGD; i++) {</span>
<span class="p_add">+		pmdval = (i &lt;&lt; PGDIR_SHIFT);</span>
<span class="p_add">+		pmd = pmd_offset(pgd + i, i &lt;&lt; PGDIR_SHIFT);</span>
<span class="p_add">+		set_pmd(pmd, __pmd(pmdval));</span>
<span class="p_add">+	}</span>
<span class="p_add">+}</span>

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



