
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>KVM: arm/arm64: Check pagesize when allocating a hugepage at Stage 2 - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    KVM: arm/arm64: Check pagesize when allocating a hugepage at Stage 2</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=58591">Punit Agrawal</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>Jan. 4, 2018, 6:24 p.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;20180104182433.3790-1-punit.agrawal@arm.com&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/10145339/mbox/"
   >mbox</a>
|
   <a href="/patch/10145339/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/10145339/">/patch/10145339/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
	[172.30.200.125])
	by pdx-korg-patchwork.web.codeaurora.org (Postfix) with ESMTP id
	E29E560594 for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Thu,  4 Jan 2018 18:24:53 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id D5B172877B
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Thu,  4 Jan 2018 18:24:53 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id C8F4628830; Thu,  4 Jan 2018 18:24:53 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-6.9 required=2.0 tests=BAYES_00,RCVD_IN_DNSWL_HI
	autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 57B472877B
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Thu,  4 Jan 2018 18:24:53 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1752506AbeADSYt (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Thu, 4 Jan 2018 13:24:49 -0500
Received: from usa-sjc-mx-foss1.foss.arm.com ([217.140.101.70]:36258 &quot;EHLO
	foss.arm.com&quot; rhost-flags-OK-OK-OK-OK) by vger.kernel.org with ESMTP
	id S1750924AbeADSYp (ORCPT &lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Thu, 4 Jan 2018 13:24:45 -0500
Received: from usa-sjc-imap-foss1.foss.arm.com (unknown [10.72.51.249])
	by usa-sjc-mx-foss1.foss.arm.com (Postfix) with ESMTP id C90DC1529;
	Thu,  4 Jan 2018 10:24:44 -0800 (PST)
Received: from localhost (e105922-lin.cambridge.arm.com [10.1.207.29])
	by usa-sjc-imap-foss1.foss.arm.com (Postfix) with ESMTPSA id
	494AF3F24A; Thu,  4 Jan 2018 10:24:44 -0800 (PST)
From: Punit Agrawal &lt;punit.agrawal@arm.com&gt;
To: kvmarm@lists.cs.columbia.edu
Cc: Punit Agrawal &lt;punit.agrawal@arm.com&gt;, linux-kernel@vger.kernel.org,
	Christoffer Dall &lt;christoffer.dall@linaro.org&gt;,
	Marc Zyngier &lt;marc.zyngier@arm.com&gt;
Subject: [PATCH] KVM: arm/arm64: Check pagesize when allocating a hugepage
	at Stage 2
Date: Thu,  4 Jan 2018 18:24:33 +0000
Message-Id: &lt;20180104182433.3790-1-punit.agrawal@arm.com&gt;
X-Mailer: git-send-email 2.15.1
X-ARM-No-Footer: FoSSMail
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=58591">Punit Agrawal</a> - Jan. 4, 2018, 6:24 p.m.</div>
<pre class="content">
KVM only supports PMD hugepages at stage 2 but doesn&#39;t actually check
that the provided hugepage memory pagesize is PMD_SIZE before populating
stage 2 entries.

In cases where the backing hugepage size is smaller than PMD_SIZE (such
as when using contiguous hugepages), KVM can end up creating stage 2
mappings that extend beyond the supplied memory.

Fix this by checking for the pagesize of userspace vma before creating
PMD hugepage at stage 2.

Fixes: ad361f093c1e31d (&quot;KVM: ARM: Support hugetlbfs backed huge pages&quot;)
<span class="signed-off-by">Signed-off-by: Punit Agrawal &lt;punit.agrawal@arm.com&gt;</span>
Cc: Christoffer Dall &lt;christoffer.dall@linaro.org&gt;
Cc: Marc Zyngier &lt;marc.zyngier@arm.com&gt;
---
 virt/kvm/arm/mmu.c | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=68151">Christoffer Dall</a> - Jan. 11, 2018, 12:15 p.m.</div>
<pre class="content">
On Thu, Jan 04, 2018 at 06:24:33PM +0000, Punit Agrawal wrote:
<span class="quote">&gt; KVM only supports PMD hugepages at stage 2 but doesn&#39;t actually check</span>
<span class="quote">&gt; that the provided hugepage memory pagesize is PMD_SIZE before populating</span>
<span class="quote">&gt; stage 2 entries.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; In cases where the backing hugepage size is smaller than PMD_SIZE (such</span>
<span class="quote">&gt; as when using contiguous hugepages),</span>

what are contiguous hugepages and how are they created vs. a normal
hugetlbfs?  Is this a kernel config thing, or how does it work?
<span class="quote">
&gt; KVM can end up creating stage 2</span>
<span class="quote">&gt; mappings that extend beyond the supplied memory.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Fix this by checking for the pagesize of userspace vma before creating</span>
<span class="quote">&gt; PMD hugepage at stage 2.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Fixes: ad361f093c1e31d (&quot;KVM: ARM: Support hugetlbfs backed huge pages&quot;)</span>
<span class="quote">&gt; Signed-off-by: Punit Agrawal &lt;punit.agrawal@arm.com&gt;</span>
<span class="quote">&gt; Cc: Christoffer Dall &lt;christoffer.dall@linaro.org&gt;</span>
<span class="quote">&gt; Cc: Marc Zyngier &lt;marc.zyngier@arm.com&gt;</span>
<span class="quote">&gt; ---</span>
<span class="quote">&gt;  virt/kvm/arm/mmu.c | 2 +-</span>
<span class="quote">&gt;  1 file changed, 1 insertion(+), 1 deletion(-)</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; diff --git a/virt/kvm/arm/mmu.c b/virt/kvm/arm/mmu.c</span>
<span class="quote">&gt; index b4b69c2d1012..9dea96380339 100644</span>
<span class="quote">&gt; --- a/virt/kvm/arm/mmu.c</span>
<span class="quote">&gt; +++ b/virt/kvm/arm/mmu.c</span>
<span class="quote">&gt; @@ -1310,7 +1310,7 @@ static int user_mem_abort(struct kvm_vcpu *vcpu, phys_addr_t fault_ipa,</span>
<span class="quote">&gt;  		return -EFAULT;</span>
<span class="quote">&gt;  	}</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; -	if (is_vm_hugetlb_page(vma) &amp;&amp; !logging_active) {</span>
<span class="quote">&gt; +	if (vma_kernel_pagesize(vma) == PMD_SIZE &amp;&amp; !logging_active) {</span>

Don&#39;t we need to also fix this in kvm_send_hwpoison_signal?

(which probably implies this will then need a backport without that for
older stable kernels.  Has this been an issue from the start or did we
add contiguous hugepage support at some point?)
<span class="quote">
&gt;  		hugetlb = true;</span>
<span class="quote">&gt;  		gfn = (fault_ipa &amp; PMD_MASK) &gt;&gt; PAGE_SHIFT;</span>
<span class="quote">&gt;  	} else {</span>
<span class="quote">&gt; -- </span>
<span class="quote">&gt; 2.15.1</span>
<span class="quote">&gt; </span>

Thanks,
-Christoffer
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=58591">Punit Agrawal</a> - Jan. 11, 2018, 1:01 p.m.</div>
<pre class="content">
Christoffer Dall &lt;christoffer.dall@linaro.org&gt; writes:
<span class="quote">
&gt; On Thu, Jan 04, 2018 at 06:24:33PM +0000, Punit Agrawal wrote:</span>
<span class="quote">&gt;&gt; KVM only supports PMD hugepages at stage 2 but doesn&#39;t actually check</span>
<span class="quote">&gt;&gt; that the provided hugepage memory pagesize is PMD_SIZE before populating</span>
<span class="quote">&gt;&gt; stage 2 entries.</span>
<span class="quote">&gt;&gt; </span>
<span class="quote">&gt;&gt; In cases where the backing hugepage size is smaller than PMD_SIZE (such</span>
<span class="quote">&gt;&gt; as when using contiguous hugepages),</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; what are contiguous hugepages and how are they created vs. a normal</span>
<span class="quote">&gt; hugetlbfs?  Is this a kernel config thing, or how does it work?</span>

Contiguous hugepages use the &quot;Contiguous&quot; bit (bit 52) in the page table
entry (pte), to mark successive entries as forming a block mapping.

The number of successive ptes that can be combined depend on the granule
size. E.g., for 4KB granule, 16 last-level ptes can form a 64KB
hugepage. or 16 adjacent PMD entries can form a 32MB hugepage.

There&#39;s no difference in instantiating contiguous hugepages vs normal
hugepages from a user&#39;s perspective other than passing in the
appropriate hugepage size.

There is no explicit config for contiguous hugepages - instead the
architectural helper to setup &quot;hugepagesz&quot; (see setup_hugepagesz() in
arch/arm64/mm/hugetlbpage.c&quot;) dictates the supported sizes.

Contiguous hugepage support has been enabled/disabled a few times for
arm64 - the latest of which is 5cd028b9d90403b (&quot;arm64: Re-enable
support for contiguous hugepages&quot;).
<span class="quote">
&gt;</span>
<span class="quote">&gt;&gt; KVM can end up creating stage 2</span>
<span class="quote">&gt;&gt; mappings that extend beyond the supplied memory.</span>
<span class="quote">&gt;&gt; </span>
<span class="quote">&gt;&gt; Fix this by checking for the pagesize of userspace vma before creating</span>
<span class="quote">&gt;&gt; PMD hugepage at stage 2.</span>
<span class="quote">&gt;&gt; </span>
<span class="quote">&gt;&gt; Fixes: ad361f093c1e31d (&quot;KVM: ARM: Support hugetlbfs backed huge pages&quot;)</span>
<span class="quote">&gt;&gt; Signed-off-by: Punit Agrawal &lt;punit.agrawal@arm.com&gt;</span>
<span class="quote">&gt;&gt; Cc: Christoffer Dall &lt;christoffer.dall@linaro.org&gt;</span>
<span class="quote">&gt;&gt; Cc: Marc Zyngier &lt;marc.zyngier@arm.com&gt;</span>
<span class="quote">&gt;&gt; ---</span>
<span class="quote">&gt;&gt;  virt/kvm/arm/mmu.c | 2 +-</span>
<span class="quote">&gt;&gt;  1 file changed, 1 insertion(+), 1 deletion(-)</span>
<span class="quote">&gt;&gt; </span>
<span class="quote">&gt;&gt; diff --git a/virt/kvm/arm/mmu.c b/virt/kvm/arm/mmu.c</span>
<span class="quote">&gt;&gt; index b4b69c2d1012..9dea96380339 100644</span>
<span class="quote">&gt;&gt; --- a/virt/kvm/arm/mmu.c</span>
<span class="quote">&gt;&gt; +++ b/virt/kvm/arm/mmu.c</span>
<span class="quote">&gt;&gt; @@ -1310,7 +1310,7 @@ static int user_mem_abort(struct kvm_vcpu *vcpu, phys_addr_t fault_ipa,</span>
<span class="quote">&gt;&gt;  		return -EFAULT;</span>
<span class="quote">&gt;&gt;  	}</span>
<span class="quote">&gt;&gt;  </span>
<span class="quote">&gt;&gt; -	if (is_vm_hugetlb_page(vma) &amp;&amp; !logging_active) {</span>
<span class="quote">&gt;&gt; +	if (vma_kernel_pagesize(vma) == PMD_SIZE &amp;&amp; !logging_active) {</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; Don&#39;t we need to also fix this in kvm_send_hwpoison_signal?</span>

I think we are OK here as the signal is delivered to userspace using the
hva and the lsb_shift is derived from the vma as well, i.e., stage 2 is
not involved here.

Does that make sense?
<span class="quote">
&gt;</span>
<span class="quote">&gt; (which probably implies this will then need a backport without that for</span>
<span class="quote">&gt; older stable kernels.  Has this been an issue from the start or did we</span>
<span class="quote">&gt; add contiguous hugepage support at some point?)</span>

I think kvm was missed out in the first (and subsequent) enabling of
contiguous hugepage support. The functionality didn&#39;t start out broken
initially.

Note that applying the fix as far back as it applies isn&#39;t harmful
though.

Thanks,
Punit
<span class="quote">
&gt;</span>
<span class="quote">&gt;&gt;  		hugetlb = true;</span>
<span class="quote">&gt;&gt;  		gfn = (fault_ipa &amp; PMD_MASK) &gt;&gt; PAGE_SHIFT;</span>
<span class="quote">&gt;&gt;  	} else {</span>
<span class="quote">&gt;&gt; -- </span>
<span class="quote">&gt;&gt; 2.15.1</span>
<span class="quote">&gt;&gt; </span>
<span class="quote">&gt;</span>
<span class="quote">&gt; Thanks,</span>
<span class="quote">&gt; -Christoffer</span>
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=68151">Christoffer Dall</a> - Jan. 11, 2018, 1:49 p.m.</div>
<pre class="content">
On Thu, Jan 11, 2018 at 01:01:07PM +0000, Punit Agrawal wrote:
<span class="quote">&gt; Christoffer Dall &lt;christoffer.dall@linaro.org&gt; writes:</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; &gt; On Thu, Jan 04, 2018 at 06:24:33PM +0000, Punit Agrawal wrote:</span>
<span class="quote">&gt; &gt;&gt; KVM only supports PMD hugepages at stage 2 but doesn&#39;t actually check</span>
<span class="quote">&gt; &gt;&gt; that the provided hugepage memory pagesize is PMD_SIZE before populating</span>
<span class="quote">&gt; &gt;&gt; stage 2 entries.</span>
<span class="quote">&gt; &gt;&gt; </span>
<span class="quote">&gt; &gt;&gt; In cases where the backing hugepage size is smaller than PMD_SIZE (such</span>
<span class="quote">&gt; &gt;&gt; as when using contiguous hugepages),</span>
<span class="quote">&gt; &gt;</span>
<span class="quote">&gt; &gt; what are contiguous hugepages and how are they created vs. a normal</span>
<span class="quote">&gt; &gt; hugetlbfs?  Is this a kernel config thing, or how does it work?</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Contiguous hugepages use the &quot;Contiguous&quot; bit (bit 52) in the page table</span>
<span class="quote">&gt; entry (pte), to mark successive entries as forming a block mapping.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; The number of successive ptes that can be combined depend on the granule</span>
<span class="quote">&gt; size. E.g., for 4KB granule, 16 last-level ptes can form a 64KB</span>
<span class="quote">&gt; hugepage. or 16 adjacent PMD entries can form a 32MB hugepage.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; There&#39;s no difference in instantiating contiguous hugepages vs normal</span>
<span class="quote">&gt; hugepages from a user&#39;s perspective other than passing in the</span>
<span class="quote">&gt; appropriate hugepage size.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; There is no explicit config for contiguous hugepages - instead the</span>
<span class="quote">&gt; architectural helper to setup &quot;hugepagesz&quot; (see setup_hugepagesz() in</span>
<span class="quote">&gt; arch/arm64/mm/hugetlbpage.c&quot;) dictates the supported sizes.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Contiguous hugepage support has been enabled/disabled a few times for</span>
<span class="quote">&gt; arm64 - the latest of which is 5cd028b9d90403b (&quot;arm64: Re-enable</span>
<span class="quote">&gt; support for contiguous hugepages&quot;).</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; &gt;</span>
<span class="quote">&gt; &gt;&gt; KVM can end up creating stage 2</span>
<span class="quote">&gt; &gt;&gt; mappings that extend beyond the supplied memory.</span>
<span class="quote">&gt; &gt;&gt; </span>
<span class="quote">&gt; &gt;&gt; Fix this by checking for the pagesize of userspace vma before creating</span>
<span class="quote">&gt; &gt;&gt; PMD hugepage at stage 2.</span>
<span class="quote">&gt; &gt;&gt; </span>
<span class="quote">&gt; &gt;&gt; Fixes: ad361f093c1e31d (&quot;KVM: ARM: Support hugetlbfs backed huge pages&quot;)</span>
<span class="quote">&gt; &gt;&gt; Signed-off-by: Punit Agrawal &lt;punit.agrawal@arm.com&gt;</span>
<span class="quote">&gt; &gt;&gt; Cc: Christoffer Dall &lt;christoffer.dall@linaro.org&gt;</span>
<span class="quote">&gt; &gt;&gt; Cc: Marc Zyngier &lt;marc.zyngier@arm.com&gt;</span>
<span class="quote">&gt; &gt;&gt; ---</span>
<span class="quote">&gt; &gt;&gt;  virt/kvm/arm/mmu.c | 2 +-</span>
<span class="quote">&gt; &gt;&gt;  1 file changed, 1 insertion(+), 1 deletion(-)</span>
<span class="quote">&gt; &gt;&gt; </span>
<span class="quote">&gt; &gt;&gt; diff --git a/virt/kvm/arm/mmu.c b/virt/kvm/arm/mmu.c</span>
<span class="quote">&gt; &gt;&gt; index b4b69c2d1012..9dea96380339 100644</span>
<span class="quote">&gt; &gt;&gt; --- a/virt/kvm/arm/mmu.c</span>
<span class="quote">&gt; &gt;&gt; +++ b/virt/kvm/arm/mmu.c</span>
<span class="quote">&gt; &gt;&gt; @@ -1310,7 +1310,7 @@ static int user_mem_abort(struct kvm_vcpu *vcpu, phys_addr_t fault_ipa,</span>
<span class="quote">&gt; &gt;&gt;  		return -EFAULT;</span>
<span class="quote">&gt; &gt;&gt;  	}</span>
<span class="quote">&gt; &gt;&gt;  </span>
<span class="quote">&gt; &gt;&gt; -	if (is_vm_hugetlb_page(vma) &amp;&amp; !logging_active) {</span>
<span class="quote">&gt; &gt;&gt; +	if (vma_kernel_pagesize(vma) == PMD_SIZE &amp;&amp; !logging_active) {</span>
<span class="quote">&gt; &gt;</span>
<span class="quote">&gt; &gt; Don&#39;t we need to also fix this in kvm_send_hwpoison_signal?</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; I think we are OK here as the signal is delivered to userspace using the</span>
<span class="quote">&gt; hva and the lsb_shift is derived from the vma as well, i.e., stage 2 is</span>
<span class="quote">&gt; not involved here.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Does that make sense?</span>
<span class="quote">&gt; </span>

Yes, you&#39;re right.
<span class="quote">
&gt; &gt;</span>
<span class="quote">&gt; &gt; (which probably implies this will then need a backport without that for</span>
<span class="quote">&gt; &gt; older stable kernels.  Has this been an issue from the start or did we</span>
<span class="quote">&gt; &gt; add contiguous hugepage support at some point?)</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; I think kvm was missed out in the first (and subsequent) enabling of</span>
<span class="quote">&gt; contiguous hugepage support. The functionality didn&#39;t start out broken</span>
<span class="quote">&gt; initially.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Note that applying the fix as far back as it applies isn&#39;t harmful</span>
<span class="quote">&gt; though.</span>
<span class="quote">&gt; </span>

It&#39;s a bit misleading to have the &quot;Fixes: ad361f093c1e31d&quot; tag, in that
it may have people running old kernels think this could be affecting
their workloads.  I know it&#39;s unlikely, but still.  Shouldn&#39;t the tag be
Fixes 66b3923a1a0f &quot;arm64: hugetlb: add support for PTE contiguous bit&quot;
?

That would make it a
Cc: &lt;stable@vger.kernel.org&gt; # v4.5+

Thanks,
-Christoffer
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=58591">Punit Agrawal</a> - Jan. 11, 2018, 2:23 p.m.</div>
<pre class="content">
Christoffer Dall &lt;christoffer.dall@linaro.org&gt; writes:
<span class="quote">
&gt; On Thu, Jan 11, 2018 at 01:01:07PM +0000, Punit Agrawal wrote:</span>
<span class="quote">&gt;&gt; Christoffer Dall &lt;christoffer.dall@linaro.org&gt; writes:</span>
<span class="quote">&gt;&gt; </span>
<span class="quote">&gt;&gt; &gt; On Thu, Jan 04, 2018 at 06:24:33PM +0000, Punit Agrawal wrote:</span>
<span class="quote">&gt;&gt; &gt;&gt; KVM only supports PMD hugepages at stage 2 but doesn&#39;t actually check</span>
<span class="quote">&gt;&gt; &gt;&gt; that the provided hugepage memory pagesize is PMD_SIZE before populating</span>
<span class="quote">&gt;&gt; &gt;&gt; stage 2 entries.</span>
<span class="quote">&gt;&gt; &gt;&gt; </span>
<span class="quote">&gt;&gt; &gt;&gt; In cases where the backing hugepage size is smaller than PMD_SIZE (such</span>
<span class="quote">&gt;&gt; &gt;&gt; as when using contiguous hugepages),</span>
<span class="quote">&gt;&gt; &gt;</span>
<span class="quote">&gt;&gt; &gt; what are contiguous hugepages and how are they created vs. a normal</span>
<span class="quote">&gt;&gt; &gt; hugetlbfs?  Is this a kernel config thing, or how does it work?</span>
<span class="quote">&gt;&gt; </span>
<span class="quote">&gt;&gt; Contiguous hugepages use the &quot;Contiguous&quot; bit (bit 52) in the page table</span>
<span class="quote">&gt;&gt; entry (pte), to mark successive entries as forming a block mapping.</span>
<span class="quote">&gt;&gt; </span>
<span class="quote">&gt;&gt; The number of successive ptes that can be combined depend on the granule</span>
<span class="quote">&gt;&gt; size. E.g., for 4KB granule, 16 last-level ptes can form a 64KB</span>
<span class="quote">&gt;&gt; hugepage. or 16 adjacent PMD entries can form a 32MB hugepage.</span>
<span class="quote">&gt;&gt; </span>
<span class="quote">&gt;&gt; There&#39;s no difference in instantiating contiguous hugepages vs normal</span>
<span class="quote">&gt;&gt; hugepages from a user&#39;s perspective other than passing in the</span>
<span class="quote">&gt;&gt; appropriate hugepage size.</span>
<span class="quote">&gt;&gt; </span>
<span class="quote">&gt;&gt; There is no explicit config for contiguous hugepages - instead the</span>
<span class="quote">&gt;&gt; architectural helper to setup &quot;hugepagesz&quot; (see setup_hugepagesz() in</span>
<span class="quote">&gt;&gt; arch/arm64/mm/hugetlbpage.c&quot;) dictates the supported sizes.</span>
<span class="quote">&gt;&gt; </span>
<span class="quote">&gt;&gt; Contiguous hugepage support has been enabled/disabled a few times for</span>
<span class="quote">&gt;&gt; arm64 - the latest of which is 5cd028b9d90403b (&quot;arm64: Re-enable</span>
<span class="quote">&gt;&gt; support for contiguous hugepages&quot;).</span>
<span class="quote">&gt;&gt; </span>
<span class="quote">&gt;&gt; &gt;</span>
<span class="quote">&gt;&gt; &gt;&gt; KVM can end up creating stage 2</span>
<span class="quote">&gt;&gt; &gt;&gt; mappings that extend beyond the supplied memory.</span>
<span class="quote">&gt;&gt; &gt;&gt; </span>
<span class="quote">&gt;&gt; &gt;&gt; Fix this by checking for the pagesize of userspace vma before creating</span>
<span class="quote">&gt;&gt; &gt;&gt; PMD hugepage at stage 2.</span>
<span class="quote">&gt;&gt; &gt;&gt; </span>
<span class="quote">&gt;&gt; &gt;&gt; Fixes: ad361f093c1e31d (&quot;KVM: ARM: Support hugetlbfs backed huge pages&quot;)</span>
<span class="quote">&gt;&gt; &gt;&gt; Signed-off-by: Punit Agrawal &lt;punit.agrawal@arm.com&gt;</span>
<span class="quote">&gt;&gt; &gt;&gt; Cc: Christoffer Dall &lt;christoffer.dall@linaro.org&gt;</span>
<span class="quote">&gt;&gt; &gt;&gt; Cc: Marc Zyngier &lt;marc.zyngier@arm.com&gt;</span>
<span class="quote">&gt;&gt; &gt;&gt; ---</span>
<span class="quote">&gt;&gt; &gt;&gt;  virt/kvm/arm/mmu.c | 2 +-</span>
<span class="quote">&gt;&gt; &gt;&gt;  1 file changed, 1 insertion(+), 1 deletion(-)</span>
<span class="quote">&gt;&gt; &gt;&gt; </span>
<span class="quote">&gt;&gt; &gt;&gt; diff --git a/virt/kvm/arm/mmu.c b/virt/kvm/arm/mmu.c</span>
<span class="quote">&gt;&gt; &gt;&gt; index b4b69c2d1012..9dea96380339 100644</span>
<span class="quote">&gt;&gt; &gt;&gt; --- a/virt/kvm/arm/mmu.c</span>
<span class="quote">&gt;&gt; &gt;&gt; +++ b/virt/kvm/arm/mmu.c</span>
<span class="quote">&gt;&gt; &gt;&gt; @@ -1310,7 +1310,7 @@ static int user_mem_abort(struct kvm_vcpu *vcpu, phys_addr_t fault_ipa,</span>
<span class="quote">&gt;&gt; &gt;&gt;  		return -EFAULT;</span>
<span class="quote">&gt;&gt; &gt;&gt;  	}</span>
<span class="quote">&gt;&gt; &gt;&gt;  </span>
<span class="quote">&gt;&gt; &gt;&gt; -	if (is_vm_hugetlb_page(vma) &amp;&amp; !logging_active) {</span>
<span class="quote">&gt;&gt; &gt;&gt; +	if (vma_kernel_pagesize(vma) == PMD_SIZE &amp;&amp; !logging_active) {</span>
<span class="quote">&gt;&gt; &gt;</span>
<span class="quote">&gt;&gt; &gt; Don&#39;t we need to also fix this in kvm_send_hwpoison_signal?</span>
<span class="quote">&gt;&gt; </span>
<span class="quote">&gt;&gt; I think we are OK here as the signal is delivered to userspace using the</span>
<span class="quote">&gt;&gt; hva and the lsb_shift is derived from the vma as well, i.e., stage 2 is</span>
<span class="quote">&gt;&gt; not involved here.</span>
<span class="quote">&gt;&gt; </span>
<span class="quote">&gt;&gt; Does that make sense?</span>
<span class="quote">&gt;&gt; </span>
<span class="quote">&gt;</span>
<span class="quote">&gt; Yes, you&#39;re right.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;&gt; &gt;</span>
<span class="quote">&gt;&gt; &gt; (which probably implies this will then need a backport without that for</span>
<span class="quote">&gt;&gt; &gt; older stable kernels.  Has this been an issue from the start or did we</span>
<span class="quote">&gt;&gt; &gt; add contiguous hugepage support at some point?)</span>
<span class="quote">&gt;&gt; </span>
<span class="quote">&gt;&gt; I think kvm was missed out in the first (and subsequent) enabling of</span>
<span class="quote">&gt;&gt; contiguous hugepage support. The functionality didn&#39;t start out broken</span>
<span class="quote">&gt;&gt; initially.</span>
<span class="quote">&gt;&gt; </span>
<span class="quote">&gt;&gt; Note that applying the fix as far back as it applies isn&#39;t harmful</span>
<span class="quote">&gt;&gt; though.</span>
<span class="quote">&gt;&gt; </span>
<span class="quote">&gt;</span>
<span class="quote">&gt; It&#39;s a bit misleading to have the &quot;Fixes: ad361f093c1e31d&quot; tag, in that</span>
<span class="quote">&gt; it may have people running old kernels think this could be affecting</span>
<span class="quote">&gt; their workloads.  I know it&#39;s unlikely, but still.  Shouldn&#39;t the tag be</span>
<span class="quote">&gt; Fixes 66b3923a1a0f &quot;arm64: hugetlb: add support for PTE contiguous bit&quot;</span>
<span class="quote">&gt; ?</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; That would make it a</span>
<span class="quote">&gt; Cc: &lt;stable@vger.kernel.org&gt; # v4.5+</span>
<span class="quote">&gt;</span>

Agreed. Makes sense to go only as far back as it really matters.

Can you fix it up when applying? Or I can send a patch with an update as
well.

Thanks,
Punit
<span class="quote">
&gt; Thanks,</span>
<span class="quote">&gt; -Christoffer</span>
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=68151">Christoffer Dall</a> - Jan. 11, 2018, 2:25 p.m.</div>
<pre class="content">
On Thu, Jan 11, 2018 at 3:23 PM, Punit Agrawal &lt;punit.agrawal@arm.com&gt; wrote:
<span class="quote">&gt; Christoffer Dall &lt;christoffer.dall@linaro.org&gt; writes:</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;&gt; On Thu, Jan 11, 2018 at 01:01:07PM +0000, Punit Agrawal wrote:</span>
<span class="quote">&gt;&gt;&gt; Christoffer Dall &lt;christoffer.dall@linaro.org&gt; writes:</span>
<span class="quote">&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt; &gt; On Thu, Jan 04, 2018 at 06:24:33PM +0000, Punit Agrawal wrote:</span>
<span class="quote">&gt;&gt;&gt; &gt;&gt; KVM only supports PMD hugepages at stage 2 but doesn&#39;t actually check</span>
<span class="quote">&gt;&gt;&gt; &gt;&gt; that the provided hugepage memory pagesize is PMD_SIZE before populating</span>
<span class="quote">&gt;&gt;&gt; &gt;&gt; stage 2 entries.</span>
<span class="quote">&gt;&gt;&gt; &gt;&gt;</span>
<span class="quote">&gt;&gt;&gt; &gt;&gt; In cases where the backing hugepage size is smaller than PMD_SIZE (such</span>
<span class="quote">&gt;&gt;&gt; &gt;&gt; as when using contiguous hugepages),</span>
<span class="quote">&gt;&gt;&gt; &gt;</span>
<span class="quote">&gt;&gt;&gt; &gt; what are contiguous hugepages and how are they created vs. a normal</span>
<span class="quote">&gt;&gt;&gt; &gt; hugetlbfs?  Is this a kernel config thing, or how does it work?</span>
<span class="quote">&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt; Contiguous hugepages use the &quot;Contiguous&quot; bit (bit 52) in the page table</span>
<span class="quote">&gt;&gt;&gt; entry (pte), to mark successive entries as forming a block mapping.</span>
<span class="quote">&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt; The number of successive ptes that can be combined depend on the granule</span>
<span class="quote">&gt;&gt;&gt; size. E.g., for 4KB granule, 16 last-level ptes can form a 64KB</span>
<span class="quote">&gt;&gt;&gt; hugepage. or 16 adjacent PMD entries can form a 32MB hugepage.</span>
<span class="quote">&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt; There&#39;s no difference in instantiating contiguous hugepages vs normal</span>
<span class="quote">&gt;&gt;&gt; hugepages from a user&#39;s perspective other than passing in the</span>
<span class="quote">&gt;&gt;&gt; appropriate hugepage size.</span>
<span class="quote">&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt; There is no explicit config for contiguous hugepages - instead the</span>
<span class="quote">&gt;&gt;&gt; architectural helper to setup &quot;hugepagesz&quot; (see setup_hugepagesz() in</span>
<span class="quote">&gt;&gt;&gt; arch/arm64/mm/hugetlbpage.c&quot;) dictates the supported sizes.</span>
<span class="quote">&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt; Contiguous hugepage support has been enabled/disabled a few times for</span>
<span class="quote">&gt;&gt;&gt; arm64 - the latest of which is 5cd028b9d90403b (&quot;arm64: Re-enable</span>
<span class="quote">&gt;&gt;&gt; support for contiguous hugepages&quot;).</span>
<span class="quote">&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt; &gt;</span>
<span class="quote">&gt;&gt;&gt; &gt;&gt; KVM can end up creating stage 2</span>
<span class="quote">&gt;&gt;&gt; &gt;&gt; mappings that extend beyond the supplied memory.</span>
<span class="quote">&gt;&gt;&gt; &gt;&gt;</span>
<span class="quote">&gt;&gt;&gt; &gt;&gt; Fix this by checking for the pagesize of userspace vma before creating</span>
<span class="quote">&gt;&gt;&gt; &gt;&gt; PMD hugepage at stage 2.</span>
<span class="quote">&gt;&gt;&gt; &gt;&gt;</span>
<span class="quote">&gt;&gt;&gt; &gt;&gt; Fixes: ad361f093c1e31d (&quot;KVM: ARM: Support hugetlbfs backed huge pages&quot;)</span>
<span class="quote">&gt;&gt;&gt; &gt;&gt; Signed-off-by: Punit Agrawal &lt;punit.agrawal@arm.com&gt;</span>
<span class="quote">&gt;&gt;&gt; &gt;&gt; Cc: Christoffer Dall &lt;christoffer.dall@linaro.org&gt;</span>
<span class="quote">&gt;&gt;&gt; &gt;&gt; Cc: Marc Zyngier &lt;marc.zyngier@arm.com&gt;</span>
<span class="quote">&gt;&gt;&gt; &gt;&gt; ---</span>
<span class="quote">&gt;&gt;&gt; &gt;&gt;  virt/kvm/arm/mmu.c | 2 +-</span>
<span class="quote">&gt;&gt;&gt; &gt;&gt;  1 file changed, 1 insertion(+), 1 deletion(-)</span>
<span class="quote">&gt;&gt;&gt; &gt;&gt;</span>
<span class="quote">&gt;&gt;&gt; &gt;&gt; diff --git a/virt/kvm/arm/mmu.c b/virt/kvm/arm/mmu.c</span>
<span class="quote">&gt;&gt;&gt; &gt;&gt; index b4b69c2d1012..9dea96380339 100644</span>
<span class="quote">&gt;&gt;&gt; &gt;&gt; --- a/virt/kvm/arm/mmu.c</span>
<span class="quote">&gt;&gt;&gt; &gt;&gt; +++ b/virt/kvm/arm/mmu.c</span>
<span class="quote">&gt;&gt;&gt; &gt;&gt; @@ -1310,7 +1310,7 @@ static int user_mem_abort(struct kvm_vcpu *vcpu, phys_addr_t fault_ipa,</span>
<span class="quote">&gt;&gt;&gt; &gt;&gt;           return -EFAULT;</span>
<span class="quote">&gt;&gt;&gt; &gt;&gt;   }</span>
<span class="quote">&gt;&gt;&gt; &gt;&gt;</span>
<span class="quote">&gt;&gt;&gt; &gt;&gt; - if (is_vm_hugetlb_page(vma) &amp;&amp; !logging_active) {</span>
<span class="quote">&gt;&gt;&gt; &gt;&gt; + if (vma_kernel_pagesize(vma) == PMD_SIZE &amp;&amp; !logging_active) {</span>
<span class="quote">&gt;&gt;&gt; &gt;</span>
<span class="quote">&gt;&gt;&gt; &gt; Don&#39;t we need to also fix this in kvm_send_hwpoison_signal?</span>
<span class="quote">&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt; I think we are OK here as the signal is delivered to userspace using the</span>
<span class="quote">&gt;&gt;&gt; hva and the lsb_shift is derived from the vma as well, i.e., stage 2 is</span>
<span class="quote">&gt;&gt;&gt; not involved here.</span>
<span class="quote">&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt; Does that make sense?</span>
<span class="quote">&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; Yes, you&#39;re right.</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt; &gt;</span>
<span class="quote">&gt;&gt;&gt; &gt; (which probably implies this will then need a backport without that for</span>
<span class="quote">&gt;&gt;&gt; &gt; older stable kernels.  Has this been an issue from the start or did we</span>
<span class="quote">&gt;&gt;&gt; &gt; add contiguous hugepage support at some point?)</span>
<span class="quote">&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt; I think kvm was missed out in the first (and subsequent) enabling of</span>
<span class="quote">&gt;&gt;&gt; contiguous hugepage support. The functionality didn&#39;t start out broken</span>
<span class="quote">&gt;&gt;&gt; initially.</span>
<span class="quote">&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt; Note that applying the fix as far back as it applies isn&#39;t harmful</span>
<span class="quote">&gt;&gt;&gt; though.</span>
<span class="quote">&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; It&#39;s a bit misleading to have the &quot;Fixes: ad361f093c1e31d&quot; tag, in that</span>
<span class="quote">&gt;&gt; it may have people running old kernels think this could be affecting</span>
<span class="quote">&gt;&gt; their workloads.  I know it&#39;s unlikely, but still.  Shouldn&#39;t the tag be</span>
<span class="quote">&gt;&gt; Fixes 66b3923a1a0f &quot;arm64: hugetlb: add support for PTE contiguous bit&quot;</span>
<span class="quote">&gt;&gt; ?</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; That would make it a</span>
<span class="quote">&gt;&gt; Cc: &lt;stable@vger.kernel.org&gt; # v4.5+</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; Agreed. Makes sense to go only as far back as it really matters.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; Can you fix it up when applying? Or I can send a patch with an update as</span>
<span class="quote">&gt; well.</span>
<span class="quote">&gt;</span>

I&#39;ll fix it up.

Thanks,
-Christoffer
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/virt/kvm/arm/mmu.c b/virt/kvm/arm/mmu.c</span>
<span class="p_header">index b4b69c2d1012..9dea96380339 100644</span>
<span class="p_header">--- a/virt/kvm/arm/mmu.c</span>
<span class="p_header">+++ b/virt/kvm/arm/mmu.c</span>
<span class="p_chunk">@@ -1310,7 +1310,7 @@</span> <span class="p_context"> static int user_mem_abort(struct kvm_vcpu *vcpu, phys_addr_t fault_ipa,</span>
 		return -EFAULT;
 	}
 
<span class="p_del">-	if (is_vm_hugetlb_page(vma) &amp;&amp; !logging_active) {</span>
<span class="p_add">+	if (vma_kernel_pagesize(vma) == PMD_SIZE &amp;&amp; !logging_active) {</span>
 		hugetlb = true;
 		gfn = (fault_ipa &amp; PMD_MASK) &gt;&gt; PAGE_SHIFT;
 	} else {

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



