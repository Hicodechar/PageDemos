
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>[GIT,pull] x86 updates for 4.2 - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    [GIT,pull] x86 updates for 4.2</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=107">Thomas Gleixner</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>July 12, 2015, 6:35 a.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;alpine.DEB.2.11.1507120823500.20072@nanos&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/6771751/mbox/"
   >mbox</a>
|
   <a href="/patch/6771751/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/6771751/">/patch/6771751/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
X-Original-To: patchwork-LKML@patchwork.kernel.org
Delivered-To: patchwork-parsemail@patchwork1.web.kernel.org
Received: from mail.kernel.org (mail.kernel.org [198.145.29.136])
	by patchwork1.web.kernel.org (Postfix) with ESMTP id E0E349F380
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Sun, 12 Jul 2015 06:35:50 +0000 (UTC)
Received: from mail.kernel.org (localhost [127.0.0.1])
	by mail.kernel.org (Postfix) with ESMTP id 7522520619
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Sun, 12 Jul 2015 06:35:49 +0000 (UTC)
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.kernel.org (Postfix) with ESMTP id 9D44C20617
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Sun, 12 Jul 2015 06:35:47 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1751331AbbGLGfm (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Sun, 12 Jul 2015 02:35:42 -0400
Received: from www.linutronix.de ([62.245.132.108]:50445 &quot;EHLO
	Galois.linutronix.de&quot; rhost-flags-OK-OK-OK-OK) by vger.kernel.org
	with ESMTP id S1750759AbbGLGfk (ORCPT
	&lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Sun, 12 Jul 2015 02:35:40 -0400
Received: from localhost ([127.0.0.1]) by Galois.linutronix.de with esmtps
	(TLS1.0:DHE_RSA_AES_256_CBC_SHA1:256) (Exim 4.80)
	(envelope-from &lt;tglx@linutronix.de&gt;)
	id 1ZEArR-0002VC-Jl; Sun, 12 Jul 2015 08:35:37 +0200
Date: Sun, 12 Jul 2015 08:35:31 +0200 (CEST)
From: Thomas Gleixner &lt;tglx@linutronix.de&gt;
To: Linus Torvalds &lt;torvalds@linux-foundation.org&gt;
cc: LKML &lt;linux-kernel@vger.kernel.org&gt;,
	Andrew Morton &lt;akpm@linux-foundation.org&gt;,
	Ingo Molnar &lt;mingo@kernel.org&gt;, &quot;H. Peter Anvin&quot; &lt;hpa@zytor.com&gt;
Subject: [GIT pull] x86 updates for 4.2
Message-ID: &lt;alpine.DEB.2.11.1507120823500.20072@nanos&gt;
User-Agent: Alpine 2.11 (DEB 23 2013-08-11)
MIME-Version: 1.0
Content-Type: MULTIPART/MIXED; BOUNDARY=&quot;8323329-834831086-1436682932=:20072&quot;
X-Linutronix-Spam-Score: -1.0
X-Linutronix-Spam-Level: -
X-Linutronix-Spam-Status: No , -1.0 points, 5.0 required, ALL_TRUSTED=-1,
	SHORTCIRCUIT=-0.0001
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Spam-Status: No, score=-8.3 required=5.0 tests=BAYES_00, RCVD_IN_DNSWL_HI, 
	RP_MATCHES_RCVD, T_TVD_MIME_EPI,
	UNPARSEABLE_RELAY autolearn=unavailable version=3.3.1
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on mail.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=107">Thomas Gleixner</a> - July 12, 2015, 6:35 a.m.</div>
<pre class="content">
Linus,

please pull the latest x86-urgent-for-linus git tree from:

   git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip.git x86-urgent-for-linus

This updates contains:

  - The high latency PIT detection fix, which slipped through the
    cracks for rc1

  - A regression fix for the early printk mechanism

  - The x86 part to plug irq/vector related hotplug races

  - Move the allocation of the espfix pages on cpu hotplug to non
    atomic context. The current code triggers a might_sleep() warning.

  - A series of KASAN fixes addressing boot crashes and usability

  - A trivial typo fix for Kconfig help text

Thanks,

	tglx

------------------&gt;
Adrian Hunter (1):
      x86/tsc: Let high latency PIT fail fast in quick_pit_calibrate()

Alexander Popov (1):
      x86/kasan: Fix KASAN shadow region page tables

Andrey Ryabinin (5):
      x86/init: Clear &#39;init_level4_pgt&#39; earlier
      x86/kasan: Flush TLBs after switching CR3
      x86/kasan: Fix boot crash on AMD processors
      x86/kasan: Add message about KASAN being initialized
      x86/kasan: Move KASAN_SHADOW_OFFSET to the arch Kconfig

Steven Rostedt (1):
      x86/earlyprintk: Allow early_printk() to use console style parameters like &#39;115200n8&#39;

SÃ©bastien Hinderer (1):
      x86/kconfig: Fix typo in the CONFIG_CMDLINE_BOOL help text

Thomas Gleixner (3):
      x86/irq: Plug irq vector hotplug race
      x86/irq: Use proper locking in check_irq_vectors_for_cpu_disable()
      x86/irq: Retrieve irq data after locking irq_desc

Zhu Guihua (2):
      x86/espfix: Add &#39;cpu&#39; parameter to init_espfix_ap()
      x86/espfix: Init espfix on the boot CPU side


 arch/x86/Kconfig               |  7 ++++++-
 arch/x86/include/asm/espfix.h  |  2 +-
 arch/x86/include/asm/kasan.h   |  8 ++-----
 arch/x86/kernel/apic/vector.c  | 10 ++-------
 arch/x86/kernel/early_printk.c |  4 +++-
 arch/x86/kernel/espfix_64.c    | 28 ++++++++++++++-----------
 arch/x86/kernel/head64.c       | 10 ++++-----
 arch/x86/kernel/head_64.S      | 29 --------------------------
 arch/x86/kernel/irq.c          | 20 ++++++++++++++++--
 arch/x86/kernel/smpboot.c      | 27 +++++++++++-------------
 arch/x86/kernel/tsc.c          | 11 +++++++++-
 arch/x86/mm/kasan_init_64.c    | 47 +++++++++++++++++++++++++++++++++++++-----
 lib/Kconfig.kasan              |  4 ----
 13 files changed, 116 insertions(+), 91 deletions(-)
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/arch/x86/Kconfig b/arch/x86/Kconfig</span>
<span class="p_header">index 55bced17dc95..3dbb7e7909ca 100644</span>
<span class="p_header">--- a/arch/x86/Kconfig</span>
<span class="p_header">+++ b/arch/x86/Kconfig</span>
<span class="p_chunk">@@ -254,6 +254,11 @@</span> <span class="p_context"> config ARCH_SUPPORTS_OPTIMIZED_INLINING</span>
 config ARCH_SUPPORTS_DEBUG_PAGEALLOC
 	def_bool y
 
<span class="p_add">+config KASAN_SHADOW_OFFSET</span>
<span class="p_add">+	hex</span>
<span class="p_add">+	depends on KASAN</span>
<span class="p_add">+	default 0xdffffc0000000000</span>
<span class="p_add">+</span>
 config HAVE_INTEL_TXT
 	def_bool y
 	depends on INTEL_IOMMU &amp;&amp; ACPI
<span class="p_chunk">@@ -2015,7 +2020,7 @@</span> <span class="p_context"> config CMDLINE_BOOL</span>
 
 	  To compile command line arguments into the kernel,
 	  set this option to &#39;Y&#39;, then fill in the
<span class="p_del">-	  the boot arguments in CONFIG_CMDLINE.</span>
<span class="p_add">+	  boot arguments in CONFIG_CMDLINE.</span>
 
 	  Systems with fully functional boot loaders (i.e. non-embedded)
 	  should leave this option set to &#39;N&#39;.
<span class="p_header">diff --git a/arch/x86/include/asm/espfix.h b/arch/x86/include/asm/espfix.h</span>
<span class="p_header">index 99efebb2f69d..ca3ce9ab9385 100644</span>
<span class="p_header">--- a/arch/x86/include/asm/espfix.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/espfix.h</span>
<span class="p_chunk">@@ -9,7 +9,7 @@</span> <span class="p_context"> DECLARE_PER_CPU_READ_MOSTLY(unsigned long, espfix_stack);</span>
 DECLARE_PER_CPU_READ_MOSTLY(unsigned long, espfix_waddr);
 
 extern void init_espfix_bsp(void);
<span class="p_del">-extern void init_espfix_ap(void);</span>
<span class="p_add">+extern void init_espfix_ap(int cpu);</span>
 
 #endif /* CONFIG_X86_64 */
 
<span class="p_header">diff --git a/arch/x86/include/asm/kasan.h b/arch/x86/include/asm/kasan.h</span>
<span class="p_header">index 8b22422fbad8..74a2a8dc9908 100644</span>
<span class="p_header">--- a/arch/x86/include/asm/kasan.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/kasan.h</span>
<span class="p_chunk">@@ -14,15 +14,11 @@</span> <span class="p_context"></span>
 
 #ifndef __ASSEMBLY__
 
<span class="p_del">-extern pte_t kasan_zero_pte[];</span>
<span class="p_del">-extern pte_t kasan_zero_pmd[];</span>
<span class="p_del">-extern pte_t kasan_zero_pud[];</span>
<span class="p_del">-</span>
 #ifdef CONFIG_KASAN
<span class="p_del">-void __init kasan_map_early_shadow(pgd_t *pgd);</span>
<span class="p_add">+void __init kasan_early_init(void);</span>
 void __init kasan_init(void);
 #else
<span class="p_del">-static inline void kasan_map_early_shadow(pgd_t *pgd) { }</span>
<span class="p_add">+static inline void kasan_early_init(void) { }</span>
 static inline void kasan_init(void) { }
 #endif
 
<span class="p_header">diff --git a/arch/x86/kernel/apic/vector.c b/arch/x86/kernel/apic/vector.c</span>
<span class="p_header">index 28eba2d38b15..f813261d9740 100644</span>
<span class="p_header">--- a/arch/x86/kernel/apic/vector.c</span>
<span class="p_header">+++ b/arch/x86/kernel/apic/vector.c</span>
<span class="p_chunk">@@ -409,12 +409,6 @@</span> <span class="p_context"> static void __setup_vector_irq(int cpu)</span>
 	int irq, vector;
 	struct apic_chip_data *data;
 
<span class="p_del">-	/*</span>
<span class="p_del">-	 * vector_lock will make sure that we don&#39;t run into irq vector</span>
<span class="p_del">-	 * assignments that might be happening on another cpu in parallel,</span>
<span class="p_del">-	 * while we setup our initial vector to irq mappings.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	raw_spin_lock(&amp;vector_lock);</span>
 	/* Mark the inuse vectors */
 	for_each_active_irq(irq) {
 		data = apic_chip_data(irq_get_irq_data(irq));
<span class="p_chunk">@@ -436,16 +430,16 @@</span> <span class="p_context"> static void __setup_vector_irq(int cpu)</span>
 		if (!cpumask_test_cpu(cpu, data-&gt;domain))
 			per_cpu(vector_irq, cpu)[vector] = VECTOR_UNDEFINED;
 	}
<span class="p_del">-	raw_spin_unlock(&amp;vector_lock);</span>
 }
 
 /*
<span class="p_del">- * Setup the vector to irq mappings.</span>
<span class="p_add">+ * Setup the vector to irq mappings. Must be called with vector_lock held.</span>
  */
 void setup_vector_irq(int cpu)
 {
 	int irq;
 
<span class="p_add">+	lockdep_assert_held(&amp;vector_lock);</span>
 	/*
 	 * On most of the platforms, legacy PIC delivers the interrupts on the
 	 * boot cpu. But there are certain platforms where PIC interrupts are
<span class="p_header">diff --git a/arch/x86/kernel/early_printk.c b/arch/x86/kernel/early_printk.c</span>
<span class="p_header">index 89427d8d4fc5..eec40f595ab9 100644</span>
<span class="p_header">--- a/arch/x86/kernel/early_printk.c</span>
<span class="p_header">+++ b/arch/x86/kernel/early_printk.c</span>
<span class="p_chunk">@@ -175,7 +175,9 @@</span> <span class="p_context"> static __init void early_serial_init(char *s)</span>
 	}
 
 	if (*s) {
<span class="p_del">-		if (kstrtoul(s, 0, &amp;baud) &lt; 0 || baud == 0)</span>
<span class="p_add">+		baud = simple_strtoull(s, &amp;e, 0);</span>
<span class="p_add">+</span>
<span class="p_add">+		if (baud == 0 || s == e)</span>
 			baud = DEFAULT_BAUD;
 	}
 
<span class="p_header">diff --git a/arch/x86/kernel/espfix_64.c b/arch/x86/kernel/espfix_64.c</span>
<span class="p_header">index f5d0730e7b08..ce95676abd60 100644</span>
<span class="p_header">--- a/arch/x86/kernel/espfix_64.c</span>
<span class="p_header">+++ b/arch/x86/kernel/espfix_64.c</span>
<span class="p_chunk">@@ -131,25 +131,24 @@</span> <span class="p_context"> void __init init_espfix_bsp(void)</span>
 	init_espfix_random();
 
 	/* The rest is the same as for any other processor */
<span class="p_del">-	init_espfix_ap();</span>
<span class="p_add">+	init_espfix_ap(0);</span>
 }
 
<span class="p_del">-void init_espfix_ap(void)</span>
<span class="p_add">+void init_espfix_ap(int cpu)</span>
 {
<span class="p_del">-	unsigned int cpu, page;</span>
<span class="p_add">+	unsigned int page;</span>
 	unsigned long addr;
 	pud_t pud, *pud_p;
 	pmd_t pmd, *pmd_p;
 	pte_t pte, *pte_p;
<span class="p_del">-	int n;</span>
<span class="p_add">+	int n, node;</span>
 	void *stack_page;
 	pteval_t ptemask;
 
 	/* We only have to do this once... */
<span class="p_del">-	if (likely(this_cpu_read(espfix_stack)))</span>
<span class="p_add">+	if (likely(per_cpu(espfix_stack, cpu)))</span>
 		return;		/* Already initialized */
 
<span class="p_del">-	cpu = smp_processor_id();</span>
 	addr = espfix_base_addr(cpu);
 	page = cpu/ESPFIX_STACKS_PER_PAGE;
 
<span class="p_chunk">@@ -165,12 +164,15 @@</span> <span class="p_context"> void init_espfix_ap(void)</span>
 	if (stack_page)
 		goto unlock_done;
 
<span class="p_add">+	node = cpu_to_node(cpu);</span>
 	ptemask = __supported_pte_mask;
 
 	pud_p = &amp;espfix_pud_page[pud_index(addr)];
 	pud = *pud_p;
 	if (!pud_present(pud)) {
<span class="p_del">-		pmd_p = (pmd_t *)__get_free_page(PGALLOC_GFP);</span>
<span class="p_add">+		struct page *page = alloc_pages_node(node, PGALLOC_GFP, 0);</span>
<span class="p_add">+</span>
<span class="p_add">+		pmd_p = (pmd_t *)page_address(page);</span>
 		pud = __pud(__pa(pmd_p) | (PGTABLE_PROT &amp; ptemask));
 		paravirt_alloc_pmd(&amp;init_mm, __pa(pmd_p) &gt;&gt; PAGE_SHIFT);
 		for (n = 0; n &lt; ESPFIX_PUD_CLONES; n++)
<span class="p_chunk">@@ -180,7 +182,9 @@</span> <span class="p_context"> void init_espfix_ap(void)</span>
 	pmd_p = pmd_offset(&amp;pud, addr);
 	pmd = *pmd_p;
 	if (!pmd_present(pmd)) {
<span class="p_del">-		pte_p = (pte_t *)__get_free_page(PGALLOC_GFP);</span>
<span class="p_add">+		struct page *page = alloc_pages_node(node, PGALLOC_GFP, 0);</span>
<span class="p_add">+</span>
<span class="p_add">+		pte_p = (pte_t *)page_address(page);</span>
 		pmd = __pmd(__pa(pte_p) | (PGTABLE_PROT &amp; ptemask));
 		paravirt_alloc_pte(&amp;init_mm, __pa(pte_p) &gt;&gt; PAGE_SHIFT);
 		for (n = 0; n &lt; ESPFIX_PMD_CLONES; n++)
<span class="p_chunk">@@ -188,7 +192,7 @@</span> <span class="p_context"> void init_espfix_ap(void)</span>
 	}
 
 	pte_p = pte_offset_kernel(&amp;pmd, addr);
<span class="p_del">-	stack_page = (void *)__get_free_page(GFP_KERNEL);</span>
<span class="p_add">+	stack_page = page_address(alloc_pages_node(node, GFP_KERNEL, 0));</span>
 	pte = __pte(__pa(stack_page) | (__PAGE_KERNEL_RO &amp; ptemask));
 	for (n = 0; n &lt; ESPFIX_PTE_CLONES; n++)
 		set_pte(&amp;pte_p[n*PTE_STRIDE], pte);
<span class="p_chunk">@@ -199,7 +203,7 @@</span> <span class="p_context"> void init_espfix_ap(void)</span>
 unlock_done:
 	mutex_unlock(&amp;espfix_init_mutex);
 done:
<span class="p_del">-	this_cpu_write(espfix_stack, addr);</span>
<span class="p_del">-	this_cpu_write(espfix_waddr, (unsigned long)stack_page</span>
<span class="p_del">-		       + (addr &amp; ~PAGE_MASK));</span>
<span class="p_add">+	per_cpu(espfix_stack, cpu) = addr;</span>
<span class="p_add">+	per_cpu(espfix_waddr, cpu) = (unsigned long)stack_page</span>
<span class="p_add">+				      + (addr &amp; ~PAGE_MASK);</span>
 }
<span class="p_header">diff --git a/arch/x86/kernel/head64.c b/arch/x86/kernel/head64.c</span>
<span class="p_header">index 5a4668136e98..f129a9af6357 100644</span>
<span class="p_header">--- a/arch/x86/kernel/head64.c</span>
<span class="p_header">+++ b/arch/x86/kernel/head64.c</span>
<span class="p_chunk">@@ -161,11 +161,12 @@</span> <span class="p_context"> asmlinkage __visible void __init x86_64_start_kernel(char * real_mode_data)</span>
 	/* Kill off the identity-map trampoline */
 	reset_early_page_tables();
 
<span class="p_del">-	kasan_map_early_shadow(early_level4_pgt);</span>
<span class="p_del">-</span>
<span class="p_del">-	/* clear bss before set_intr_gate with early_idt_handler */</span>
 	clear_bss();
 
<span class="p_add">+	clear_page(init_level4_pgt);</span>
<span class="p_add">+</span>
<span class="p_add">+	kasan_early_init();</span>
<span class="p_add">+</span>
 	for (i = 0; i &lt; NUM_EXCEPTION_VECTORS; i++)
 		set_intr_gate(i, early_idt_handler_array[i]);
 	load_idt((const struct desc_ptr *)&amp;idt_descr);
<span class="p_chunk">@@ -177,12 +178,9 @@</span> <span class="p_context"> asmlinkage __visible void __init x86_64_start_kernel(char * real_mode_data)</span>
 	 */
 	load_ucode_bsp();
 
<span class="p_del">-	clear_page(init_level4_pgt);</span>
 	/* set init_level4_pgt kernel high mapping*/
 	init_level4_pgt[511] = early_level4_pgt[511];
 
<span class="p_del">-	kasan_map_early_shadow(init_level4_pgt);</span>
<span class="p_del">-</span>
 	x86_64_start_reservations(real_mode_data);
 }
 
<span class="p_header">diff --git a/arch/x86/kernel/head_64.S b/arch/x86/kernel/head_64.S</span>
<span class="p_header">index e5c27f729a38..1d40ca8a73f2 100644</span>
<span class="p_header">--- a/arch/x86/kernel/head_64.S</span>
<span class="p_header">+++ b/arch/x86/kernel/head_64.S</span>
<span class="p_chunk">@@ -516,38 +516,9 @@</span> <span class="p_context"> ENTRY(phys_base)</span>
 	/* This must match the first entry in level2_kernel_pgt */
 	.quad   0x0000000000000000
 
<span class="p_del">-#ifdef CONFIG_KASAN</span>
<span class="p_del">-#define FILL(VAL, COUNT)				\</span>
<span class="p_del">-	.rept (COUNT) ;					\</span>
<span class="p_del">-	.quad	(VAL) ;					\</span>
<span class="p_del">-	.endr</span>
<span class="p_del">-</span>
<span class="p_del">-NEXT_PAGE(kasan_zero_pte)</span>
<span class="p_del">-	FILL(kasan_zero_page - __START_KERNEL_map + _KERNPG_TABLE, 512)</span>
<span class="p_del">-NEXT_PAGE(kasan_zero_pmd)</span>
<span class="p_del">-	FILL(kasan_zero_pte - __START_KERNEL_map + _KERNPG_TABLE, 512)</span>
<span class="p_del">-NEXT_PAGE(kasan_zero_pud)</span>
<span class="p_del">-	FILL(kasan_zero_pmd - __START_KERNEL_map + _KERNPG_TABLE, 512)</span>
<span class="p_del">-</span>
<span class="p_del">-#undef FILL</span>
<span class="p_del">-#endif</span>
<span class="p_del">-</span>
<span class="p_del">-</span>
 #include &quot;../../x86/xen/xen-head.S&quot;
 	
 	__PAGE_ALIGNED_BSS
 NEXT_PAGE(empty_zero_page)
 	.skip PAGE_SIZE
 
<span class="p_del">-#ifdef CONFIG_KASAN</span>
<span class="p_del">-/*</span>
<span class="p_del">- * This page used as early shadow. We don&#39;t use empty_zero_page</span>
<span class="p_del">- * at early stages, stack instrumentation could write some garbage</span>
<span class="p_del">- * to this page.</span>
<span class="p_del">- * Latter we reuse it as zero shadow for large ranges of memory</span>
<span class="p_del">- * that allowed to access, but not instrumented by kasan</span>
<span class="p_del">- * (vmalloc/vmemmap ...).</span>
<span class="p_del">- */</span>
<span class="p_del">-NEXT_PAGE(kasan_zero_page)</span>
<span class="p_del">-	.skip PAGE_SIZE</span>
<span class="p_del">-#endif</span>
<span class="p_header">diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c</span>
<span class="p_header">index 88b366487b0e..c7dfe1be784e 100644</span>
<span class="p_header">--- a/arch/x86/kernel/irq.c</span>
<span class="p_header">+++ b/arch/x86/kernel/irq.c</span>
<span class="p_chunk">@@ -347,14 +347,22 @@</span> <span class="p_context"> int check_irq_vectors_for_cpu_disable(void)</span>
 			if (!desc)
 				continue;
 
<span class="p_add">+			/*</span>
<span class="p_add">+			 * Protect against concurrent action removal,</span>
<span class="p_add">+			 * affinity changes etc.</span>
<span class="p_add">+			 */</span>
<span class="p_add">+			raw_spin_lock(&amp;desc-&gt;lock);</span>
 			data = irq_desc_get_irq_data(desc);
 			cpumask_copy(&amp;affinity_new, data-&gt;affinity);
 			cpumask_clear_cpu(this_cpu, &amp;affinity_new);
 
 			/* Do not count inactive or per-cpu irqs. */
<span class="p_del">-			if (!irq_has_action(irq) || irqd_is_per_cpu(data))</span>
<span class="p_add">+			if (!irq_has_action(irq) || irqd_is_per_cpu(data)) {</span>
<span class="p_add">+				raw_spin_unlock(&amp;desc-&gt;lock);</span>
 				continue;
<span class="p_add">+			}</span>
 
<span class="p_add">+			raw_spin_unlock(&amp;desc-&gt;lock);</span>
 			/*
 			 * A single irq may be mapped to multiple
 			 * cpu&#39;s vector_irq[] (for example IOAPIC cluster
<span class="p_chunk">@@ -385,6 +393,9 @@</span> <span class="p_context"> int check_irq_vectors_for_cpu_disable(void)</span>
 		 * vector. If the vector is marked in the used vectors
 		 * bitmap or an irq is assigned to it, we don&#39;t count
 		 * it as available.
<span class="p_add">+		 *</span>
<span class="p_add">+		 * As this is an inaccurate snapshot anyway, we can do</span>
<span class="p_add">+		 * this w/o holding vector_lock.</span>
 		 */
 		for (vector = FIRST_EXTERNAL_VECTOR;
 		     vector &lt; first_system_vector; vector++) {
<span class="p_chunk">@@ -486,6 +497,11 @@</span> <span class="p_context"> void fixup_irqs(void)</span>
 	 */
 	mdelay(1);
 
<span class="p_add">+	/*</span>
<span class="p_add">+	 * We can walk the vector array of this cpu without holding</span>
<span class="p_add">+	 * vector_lock because the cpu is already marked !online, so</span>
<span class="p_add">+	 * nothing else will touch it.</span>
<span class="p_add">+	 */</span>
 	for (vector = FIRST_EXTERNAL_VECTOR; vector &lt; NR_VECTORS; vector++) {
 		unsigned int irr;
 
<span class="p_chunk">@@ -497,9 +513,9 @@</span> <span class="p_context"> void fixup_irqs(void)</span>
 			irq = __this_cpu_read(vector_irq[vector]);
 
 			desc = irq_to_desc(irq);
<span class="p_add">+			raw_spin_lock(&amp;desc-&gt;lock);</span>
 			data = irq_desc_get_irq_data(desc);
 			chip = irq_data_get_irq_chip(data);
<span class="p_del">-			raw_spin_lock(&amp;desc-&gt;lock);</span>
 			if (chip-&gt;irq_retrigger) {
 				chip-&gt;irq_retrigger(data);
 				__this_cpu_write(vector_irq[vector], VECTOR_RETRIGGERED);
<span class="p_header">diff --git a/arch/x86/kernel/smpboot.c b/arch/x86/kernel/smpboot.c</span>
<span class="p_header">index 8add66b22f33..d3010aa79daf 100644</span>
<span class="p_header">--- a/arch/x86/kernel/smpboot.c</span>
<span class="p_header">+++ b/arch/x86/kernel/smpboot.c</span>
<span class="p_chunk">@@ -171,11 +171,6 @@</span> <span class="p_context"> static void smp_callin(void)</span>
 	apic_ap_setup();
 
 	/*
<span class="p_del">-	 * Need to setup vector mappings before we enable interrupts.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	setup_vector_irq(smp_processor_id());</span>
<span class="p_del">-</span>
<span class="p_del">-	/*</span>
 	 * Save our processor parameters. Note: this information
 	 * is needed for clock calibration.
 	 */
<span class="p_chunk">@@ -239,18 +234,13 @@</span> <span class="p_context"> static void notrace start_secondary(void *unused)</span>
 	check_tsc_sync_target();
 
 	/*
<span class="p_del">-	 * Enable the espfix hack for this CPU</span>
<span class="p_del">-	 */</span>
<span class="p_del">-#ifdef CONFIG_X86_ESPFIX64</span>
<span class="p_del">-	init_espfix_ap();</span>
<span class="p_del">-#endif</span>
<span class="p_del">-</span>
<span class="p_del">-	/*</span>
<span class="p_del">-	 * We need to hold vector_lock so there the set of online cpus</span>
<span class="p_del">-	 * does not change while we are assigning vectors to cpus.  Holding</span>
<span class="p_del">-	 * this lock ensures we don&#39;t half assign or remove an irq from a cpu.</span>
<span class="p_add">+	 * Lock vector_lock and initialize the vectors on this cpu</span>
<span class="p_add">+	 * before setting the cpu online. We must set it online with</span>
<span class="p_add">+	 * vector_lock held to prevent a concurrent setup/teardown</span>
<span class="p_add">+	 * from seeing a half valid vector space.</span>
 	 */
 	lock_vector_lock();
<span class="p_add">+	setup_vector_irq(smp_processor_id());</span>
 	set_cpu_online(smp_processor_id(), true);
 	unlock_vector_lock();
 	cpu_set_state_online(smp_processor_id());
<span class="p_chunk">@@ -854,6 +844,13 @@</span> <span class="p_context"> static int do_boot_cpu(int apicid, int cpu, struct task_struct *idle)</span>
 	initial_code = (unsigned long)start_secondary;
 	stack_start  = idle-&gt;thread.sp;
 
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Enable the espfix hack for this CPU</span>
<span class="p_add">+	*/</span>
<span class="p_add">+#ifdef CONFIG_X86_ESPFIX64</span>
<span class="p_add">+	init_espfix_ap(cpu);</span>
<span class="p_add">+#endif</span>
<span class="p_add">+</span>
 	/* So we see what&#39;s up */
 	announce_cpu(cpu, apicid);
 
<span class="p_header">diff --git a/arch/x86/kernel/tsc.c b/arch/x86/kernel/tsc.c</span>
<span class="p_header">index 505449700e0c..7437b41f6a47 100644</span>
<span class="p_header">--- a/arch/x86/kernel/tsc.c</span>
<span class="p_header">+++ b/arch/x86/kernel/tsc.c</span>
<span class="p_chunk">@@ -598,10 +598,19 @@</span> <span class="p_context"> static unsigned long quick_pit_calibrate(void)</span>
 			if (!pit_expect_msb(0xff-i, &amp;delta, &amp;d2))
 				break;
 
<span class="p_add">+			delta -= tsc;</span>
<span class="p_add">+</span>
<span class="p_add">+			/*</span>
<span class="p_add">+			 * Extrapolate the error and fail fast if the error will</span>
<span class="p_add">+			 * never be below 500 ppm.</span>
<span class="p_add">+			 */</span>
<span class="p_add">+			if (i == 1 &amp;&amp;</span>
<span class="p_add">+			    d1 + d2 &gt;= (delta * MAX_QUICK_PIT_ITERATIONS) &gt;&gt; 11)</span>
<span class="p_add">+				return 0;</span>
<span class="p_add">+</span>
 			/*
 			 * Iterate until the error is less than 500 ppm
 			 */
<span class="p_del">-			delta -= tsc;</span>
 			if (d1+d2 &gt;= delta &gt;&gt; 11)
 				continue;
 
<span class="p_header">diff --git a/arch/x86/mm/kasan_init_64.c b/arch/x86/mm/kasan_init_64.c</span>
<span class="p_header">index 4860906c6b9f..e1840f3db5b5 100644</span>
<span class="p_header">--- a/arch/x86/mm/kasan_init_64.c</span>
<span class="p_header">+++ b/arch/x86/mm/kasan_init_64.c</span>
<span class="p_chunk">@@ -1,3 +1,4 @@</span> <span class="p_context"></span>
<span class="p_add">+#define pr_fmt(fmt) &quot;kasan: &quot; fmt</span>
 #include &lt;linux/bootmem.h&gt;
 #include &lt;linux/kasan.h&gt;
 #include &lt;linux/kdebug.h&gt;
<span class="p_chunk">@@ -11,7 +12,19 @@</span> <span class="p_context"></span>
 extern pgd_t early_level4_pgt[PTRS_PER_PGD];
 extern struct range pfn_mapped[E820_X_MAX];
 
<span class="p_del">-extern unsigned char kasan_zero_page[PAGE_SIZE];</span>
<span class="p_add">+static pud_t kasan_zero_pud[PTRS_PER_PUD] __page_aligned_bss;</span>
<span class="p_add">+static pmd_t kasan_zero_pmd[PTRS_PER_PMD] __page_aligned_bss;</span>
<span class="p_add">+static pte_t kasan_zero_pte[PTRS_PER_PTE] __page_aligned_bss;</span>
<span class="p_add">+</span>
<span class="p_add">+/*</span>
<span class="p_add">+ * This page used as early shadow. We don&#39;t use empty_zero_page</span>
<span class="p_add">+ * at early stages, stack instrumentation could write some garbage</span>
<span class="p_add">+ * to this page.</span>
<span class="p_add">+ * Latter we reuse it as zero shadow for large ranges of memory</span>
<span class="p_add">+ * that allowed to access, but not instrumented by kasan</span>
<span class="p_add">+ * (vmalloc/vmemmap ...).</span>
<span class="p_add">+ */</span>
<span class="p_add">+static unsigned char kasan_zero_page[PAGE_SIZE] __page_aligned_bss;</span>
 
 static int __init map_range(struct range *range)
 {
<span class="p_chunk">@@ -36,7 +49,7 @@</span> <span class="p_context"> static void __init clear_pgds(unsigned long start,</span>
 		pgd_clear(pgd_offset_k(start));
 }
 
<span class="p_del">-void __init kasan_map_early_shadow(pgd_t *pgd)</span>
<span class="p_add">+static void __init kasan_map_early_shadow(pgd_t *pgd)</span>
 {
 	int i;
 	unsigned long start = KASAN_SHADOW_START;
<span class="p_chunk">@@ -73,7 +86,7 @@</span> <span class="p_context"> static int __init zero_pmd_populate(pud_t *pud, unsigned long addr,</span>
 	while (IS_ALIGNED(addr, PMD_SIZE) &amp;&amp; addr + PMD_SIZE &lt;= end) {
 		WARN_ON(!pmd_none(*pmd));
 		set_pmd(pmd, __pmd(__pa_nodebug(kasan_zero_pte)
<span class="p_del">-					| __PAGE_KERNEL_RO));</span>
<span class="p_add">+					| _KERNPG_TABLE));</span>
 		addr += PMD_SIZE;
 		pmd = pmd_offset(pud, addr);
 	}
<span class="p_chunk">@@ -99,7 +112,7 @@</span> <span class="p_context"> static int __init zero_pud_populate(pgd_t *pgd, unsigned long addr,</span>
 	while (IS_ALIGNED(addr, PUD_SIZE) &amp;&amp; addr + PUD_SIZE &lt;= end) {
 		WARN_ON(!pud_none(*pud));
 		set_pud(pud, __pud(__pa_nodebug(kasan_zero_pmd)
<span class="p_del">-					| __PAGE_KERNEL_RO));</span>
<span class="p_add">+					| _KERNPG_TABLE));</span>
 		addr += PUD_SIZE;
 		pud = pud_offset(pgd, addr);
 	}
<span class="p_chunk">@@ -124,7 +137,7 @@</span> <span class="p_context"> static int __init zero_pgd_populate(unsigned long addr, unsigned long end)</span>
 	while (IS_ALIGNED(addr, PGDIR_SIZE) &amp;&amp; addr + PGDIR_SIZE &lt;= end) {
 		WARN_ON(!pgd_none(*pgd));
 		set_pgd(pgd, __pgd(__pa_nodebug(kasan_zero_pud)
<span class="p_del">-					| __PAGE_KERNEL_RO));</span>
<span class="p_add">+					| _KERNPG_TABLE));</span>
 		addr += PGDIR_SIZE;
 		pgd = pgd_offset_k(addr);
 	}
<span class="p_chunk">@@ -166,6 +179,26 @@</span> <span class="p_context"> static struct notifier_block kasan_die_notifier = {</span>
 };
 #endif
 
<span class="p_add">+void __init kasan_early_init(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	int i;</span>
<span class="p_add">+	pteval_t pte_val = __pa_nodebug(kasan_zero_page) | __PAGE_KERNEL;</span>
<span class="p_add">+	pmdval_t pmd_val = __pa_nodebug(kasan_zero_pte) | _KERNPG_TABLE;</span>
<span class="p_add">+	pudval_t pud_val = __pa_nodebug(kasan_zero_pmd) | _KERNPG_TABLE;</span>
<span class="p_add">+</span>
<span class="p_add">+	for (i = 0; i &lt; PTRS_PER_PTE; i++)</span>
<span class="p_add">+		kasan_zero_pte[i] = __pte(pte_val);</span>
<span class="p_add">+</span>
<span class="p_add">+	for (i = 0; i &lt; PTRS_PER_PMD; i++)</span>
<span class="p_add">+		kasan_zero_pmd[i] = __pmd(pmd_val);</span>
<span class="p_add">+</span>
<span class="p_add">+	for (i = 0; i &lt; PTRS_PER_PUD; i++)</span>
<span class="p_add">+		kasan_zero_pud[i] = __pud(pud_val);</span>
<span class="p_add">+</span>
<span class="p_add">+	kasan_map_early_shadow(early_level4_pgt);</span>
<span class="p_add">+	kasan_map_early_shadow(init_level4_pgt);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 void __init kasan_init(void)
 {
 	int i;
<span class="p_chunk">@@ -176,6 +209,7 @@</span> <span class="p_context"> void __init kasan_init(void)</span>
 
 	memcpy(early_level4_pgt, init_level4_pgt, sizeof(early_level4_pgt));
 	load_cr3(early_level4_pgt);
<span class="p_add">+	__flush_tlb_all();</span>
 
 	clear_pgds(KASAN_SHADOW_START, KASAN_SHADOW_END);
 
<span class="p_chunk">@@ -202,5 +236,8 @@</span> <span class="p_context"> void __init kasan_init(void)</span>
 	memset(kasan_zero_page, 0, PAGE_SIZE);
 
 	load_cr3(init_level4_pgt);
<span class="p_add">+	__flush_tlb_all();</span>
 	init_task.kasan_depth = 0;
<span class="p_add">+</span>
<span class="p_add">+	pr_info(&quot;Kernel address sanitizer initialized\n&quot;);</span>
 }
<span class="p_header">diff --git a/lib/Kconfig.kasan b/lib/Kconfig.kasan</span>
<span class="p_header">index 777eda7d1ab4..39f24d6721e5 100644</span>
<span class="p_header">--- a/lib/Kconfig.kasan</span>
<span class="p_header">+++ b/lib/Kconfig.kasan</span>
<span class="p_chunk">@@ -18,10 +18,6 @@</span> <span class="p_context"> config KASAN</span>
 	  For better error detection enable CONFIG_STACKTRACE,
 	  and add slub_debug=U to boot cmdline.
 
<span class="p_del">-config KASAN_SHADOW_OFFSET</span>
<span class="p_del">-	hex</span>
<span class="p_del">-	default 0xdffffc0000000000 if X86_64</span>
<span class="p_del">-</span>
 choice
 	prompt &quot;Instrumentation type&quot;
 	depends on KASAN

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



