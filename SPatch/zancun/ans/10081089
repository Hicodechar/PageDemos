
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>[15/24] x86/mm: Allow flushing for future ASID switches - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    [15/24] x86/mm: Allow flushing for future ASID switches</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=137">Peter Zijlstra</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>Nov. 28, 2017, 8:45 p.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;20171128204551.2fcg6yhtxfsogvrc@hirez.programming.kicks-ass.net&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/10081089/mbox/"
   >mbox</a>
|
   <a href="/patch/10081089/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/10081089/">/patch/10081089/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
	[172.30.200.125])
	by pdx-korg-patchwork.web.codeaurora.org (Postfix) with ESMTP id
	0391760353 for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Tue, 28 Nov 2017 20:46:07 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id F00961FF1E
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Tue, 28 Nov 2017 20:46:06 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id DEF292969F; Tue, 28 Nov 2017 20:46:06 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-6.8 required=2.0 tests=BAYES_00,DKIM_SIGNED,
	RCVD_IN_DNSWL_HI,T_DKIM_INVALID autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 6939E1FF1E
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Tue, 28 Nov 2017 20:46:05 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S932180AbdK1UqB (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Tue, 28 Nov 2017 15:46:01 -0500
Received: from bombadil.infradead.org ([65.50.211.133]:40300 &quot;EHLO
	bombadil.infradead.org&quot; rhost-flags-OK-OK-OK-OK) by vger.kernel.org
	with ESMTP id S1753284AbdK1Up6 (ORCPT
	&lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Tue, 28 Nov 2017 15:45:58 -0500
DKIM-Signature: v=1; a=rsa-sha256; q=dns/txt; c=relaxed/relaxed;
	d=infradead.org; s=bombadil.20170209;
	h=In-Reply-To:Content-Type:MIME-Version
	:References:Message-ID:Subject:Cc:To:From:Date:Sender:Reply-To:
	Content-Transfer-Encoding:Content-ID:Content-Description:Resent-Date:
	Resent-From:Resent-Sender:Resent-To:Resent-Cc:Resent-Message-ID:List-Id:
	List-Help:List-Unsubscribe:List-Subscribe:List-Post:List-Owner:List-Archive;
	bh=ozBeZlmpjYeW+esM5wzZtSydS3088YcHJXLDUCuLRh4=;
	b=D4D9jR6VEs4rsmcpOA8h8XIaJ
	jLrolHy2sby9GyPd6pIgW9JZ5Wb42Rix0zd3tUX2CHAwfLJ7+KSvdH1hemKEYaoU6s5HrHVjoB9XC
	7clm8CgrYYBTRcHh9oCwxamPvILVw7+ie04stCeJIPy7IQ5YDFXQNuJXdmtMPTOLhB5QtiGM30Lb2
	cKsi8t2Qm9KY51F8PRLJjkfoF1BQ5Qdktszav7o4T6RQyqvHkddRffKW80wIdowLkNopHmfLSS27g
	8xqHpvhWjAuid55rI/CCTvycN+qHVpoi7l+WYlcuH9PllQetPSalYTByFA0sy3H7NWrYvXX+OBTzJ
	+ff5wp2sQ==;
Received: from j217100.upc-j.chello.nl ([24.132.217.100]
	helo=hirez.programming.kicks-ass.net)
	by bombadil.infradead.org with esmtpsa (Exim 4.87 #1 (Red Hat Linux))
	id 1eJmlN-0001qC-EB; Tue, 28 Nov 2017 20:45:53 +0000
Received: by hirez.programming.kicks-ass.net (Postfix, from userid 1000)
	id AD41820321DB8; Tue, 28 Nov 2017 21:45:51 +0100 (CET)
Date: Tue, 28 Nov 2017 21:45:51 +0100
From: Peter Zijlstra &lt;peterz@infradead.org&gt;
To: Andy Lutomirski &lt;luto@amacapital.net&gt;
Cc: Dave Hansen &lt;dave.hansen@linux.intel.com&gt;,
	Ingo Molnar &lt;mingo@kernel.org&gt;,
	&quot;linux-kernel@vger.kernel.org&quot; &lt;linux-kernel@vger.kernel.org&gt;,
	Thomas Gleixner &lt;tglx@linutronix.de&gt;,
	&quot;H . Peter Anvin&quot; &lt;hpa@zytor.com&gt;, Borislav Petkov &lt;bp@alien8.de&gt;,
	Linus Torvalds &lt;torvalds@linux-foundation.org&gt;
Subject: Re: [PATCH 15/24] x86/mm: Allow flushing for future ASID switches
Message-ID: &lt;20171128204551.2fcg6yhtxfsogvrc@hirez.programming.kicks-ass.net&gt;
References: &lt;20171127104923.14378-1-mingo@kernel.org&gt;
	&lt;20171127104923.14378-16-mingo@kernel.org&gt;
	&lt;CALCETrUFfpDLEP78K9V4GsbHWS5=M6k8ndv0p+R0ud0=xxbaMg@mail.gmail.com&gt;
	&lt;20171128163908.e3gj6zgq6kcbdlxe@hirez.programming.kicks-ass.net&gt;
	&lt;1c9a32ed-e754-9d91-98f7-b72c07b2c0dc@linux.intel.com&gt;
	&lt;20171128190505.pqip2v2ewb3isjhd@hirez.programming.kicks-ass.net&gt;
	&lt;CALCETrW3hgNJoP9sMWXBmYiRKten1CJNY6AgCxv1wQdcBfd8pQ@mail.gmail.com&gt;
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Disposition: inline
In-Reply-To: &lt;CALCETrW3hgNJoP9sMWXBmYiRKten1CJNY6AgCxv1wQdcBfd8pQ@mail.gmail.com&gt;
User-Agent: NeoMutt/20170609 (1.8.3)
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=137">Peter Zijlstra</a> - Nov. 28, 2017, 8:45 p.m.</div>
<pre class="content">
On Tue, Nov 28, 2017 at 12:34:17PM -0800, Andy Lutomirski wrote:
<span class="quote">&gt; I think it should be fine.  A very old version of the patches had that</span>
<span class="quote">&gt; problem, but, in -tip, the nmi RESTORE_CR3 is in the fancy</span>
<span class="quote">&gt; recursion-protected region, and the stack is okay.  The idea is that</span>
<span class="quote">&gt; we&#39;re already on the old (possibly user) CR3 before we do the crazy</span>
<span class="quote">&gt; recursion-checking bits.  But that&#39;s fine, since all that&#39;s accessed</span>
<span class="quote">&gt; there is the IST stack, and that&#39;s in the cpu_entry_area and thus safe</span>
<span class="quote">&gt; regardless of CR3.</span>

Turns out there&#39;s a gob of spare registers to be had on RESTORE_CR3, we
do POP_EXTRA_REGS right after both call-sites. So I just picked
something from there.
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/arch/x86/entry/calling.h b/arch/x86/entry/calling.h</span>
<span class="p_header">index 07fa7fdd7b68..9617b7c642db 100644</span>
<span class="p_header">--- a/arch/x86/entry/calling.h</span>
<span class="p_header">+++ b/arch/x86/entry/calling.h</span>
<span class="p_chunk">@@ -4,6 +4,7 @@</span> <span class="p_context"></span>
 #include &lt;asm/cpufeatures.h&gt;
 #include &lt;asm/page_types.h&gt;
 #include &lt;asm/pgtable_types.h&gt;
<span class="p_add">+#include &lt;asm/percpu.h&gt;</span>
 
 /*
 
<span class="p_chunk">@@ -220,15 +221,29 @@</span> <span class="p_context"> For 32-bit we have the following conventions - kernel is built with</span>
 .macro SWITCH_TO_USER_CR3 scratch_reg:req
 	STATIC_JUMP_IF_FALSE .Lend_\@, kaiser_enabled_key, def=1
 	mov	%cr3, \scratch_reg
<span class="p_del">-	ADJUST_USER_CR3 \scratch_reg</span>
<span class="p_add">+	push	\scratch_reg</span>
<span class="p_add">+	andq	$(0x7FF), \scratch_reg</span>
<span class="p_add">+	bt	\scratch_reg, PER_CPU_VAR(__asid_flush)</span>
<span class="p_add">+	jnc	.Lnoflush_\@</span>
<span class="p_add">+</span>
<span class="p_add">+	btr	\scratch_reg, PER_CPU_VAR(__asid_flush)</span>
<span class="p_add">+	pop	\scratch_reg</span>
<span class="p_add">+	jmp	.Ldo_\@</span>
<span class="p_add">+</span>
<span class="p_add">+.Lnoflush_\@:</span>
<span class="p_add">+	pop	\scratch_reg</span>
<span class="p_add">+	ALTERNATIVE &quot;&quot;, &quot;bts $63, \scratch_reg&quot;, X86_FEATURE_PCID</span>
<span class="p_add">+</span>
<span class="p_add">+.Ldo_\@:</span>
<span class="p_add">+	orq     $(KAISER_SWITCH_MASK), \scratch_reg</span>
 	mov	\scratch_reg, %cr3
 .Lend_\@:
 .endm
 
 .macro SAVE_AND_SWITCH_TO_KERNEL_CR3 scratch_reg:req save_reg:req
 	STATIC_JUMP_IF_FALSE .Ldone_\@, kaiser_enabled_key, def=1
<span class="p_del">-	movq	%cr3, %r\scratch_reg</span>
<span class="p_del">-	movq	%r\scratch_reg, \save_reg</span>
<span class="p_add">+	movq	%cr3, \scratch_reg</span>
<span class="p_add">+	movq	\scratch_reg, \save_reg</span>
 	/*
 	 * Is the &quot;switch mask&quot; all zero?  That means that both of
 	 * these are zero:
<span class="p_chunk">@@ -239,17 +254,42 @@</span> <span class="p_context"> For 32-bit we have the following conventions - kernel is built with</span>
 	 *
 	 * That indicates a kernel CR3 value, not user/shadow.
 	 */
<span class="p_del">-	testq	$(KAISER_SWITCH_MASK), %r\scratch_reg</span>
<span class="p_add">+	testq	$(KAISER_SWITCH_MASK), \scratch_reg</span>
 	jz	.Ldone_\@
 
<span class="p_del">-	ADJUST_KERNEL_CR3 %r\scratch_reg</span>
<span class="p_del">-	movq	%r\scratch_reg, %cr3</span>
<span class="p_add">+	ADJUST_KERNEL_CR3 \scratch_reg</span>
<span class="p_add">+	movq	\scratch_reg, %cr3</span>
 
 .Ldone_\@:
 .endm
 
<span class="p_del">-.macro RESTORE_CR3 save_reg:req</span>
<span class="p_add">+.macro RESTORE_CR3 scratch_reg:req save_reg:req</span>
 	STATIC_JUMP_IF_FALSE .Lend_\@, kaiser_enabled_key, def=1
<span class="p_add">+</span>
<span class="p_add">+	/* ASID bit 11 is for USER */</span>
<span class="p_add">+	bt	$11, \save_reg</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * KERNEL pages can always resume with NOFLUSH as we do</span>
<span class="p_add">+	 * explicit flushes.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	jnc	.Lnoflush_\@</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Check if there&#39;s a pending flush for the USER ASID we&#39;re</span>
<span class="p_add">+	 * about to set.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	movq	\save_reg, \scratch_reg</span>
<span class="p_add">+	andq	$(0x7FF), \scratch_reg</span>
<span class="p_add">+	bt	\scratch_reg, PER_CPU_VAR(__asid_flush)</span>
<span class="p_add">+	jnc	.Lnoflush_\@</span>
<span class="p_add">+</span>
<span class="p_add">+	btr	\scratch_reg, PER_CPU_VAR(__asid_flush)</span>
<span class="p_add">+	jmp	.Ldo_\@</span>
<span class="p_add">+</span>
<span class="p_add">+.Lnoflush_\@:</span>
<span class="p_add">+	ALTERNATIVE &quot;&quot;, &quot;bts $63, \save_reg&quot;, X86_FEATURE_PCID</span>
<span class="p_add">+</span>
<span class="p_add">+.Ldo_\@:</span>
 	/*
 	 * The CR3 write could be avoided when not changing its value,
 	 * but would require a CR3 read *and* a scratch register.
<span class="p_chunk">@@ -266,7 +306,7 @@</span> <span class="p_context"> For 32-bit we have the following conventions - kernel is built with</span>
 .endm
 .macro SAVE_AND_SWITCH_TO_KERNEL_CR3 scratch_reg:req save_reg:req
 .endm
<span class="p_del">-.macro RESTORE_CR3 save_reg:req</span>
<span class="p_add">+.macro RESTORE_CR3 scratch_reg:req save_reg:req</span>
 .endm
 
 #endif
<span class="p_header">diff --git a/arch/x86/entry/entry_64.S b/arch/x86/entry/entry_64.S</span>
<span class="p_header">index df0152bee8a8..39233c58f14a 100644</span>
<span class="p_header">--- a/arch/x86/entry/entry_64.S</span>
<span class="p_header">+++ b/arch/x86/entry/entry_64.S</span>
<span class="p_chunk">@@ -1257,7 +1254,7 @@</span> <span class="p_context"> ENTRY(paranoid_entry)</span>
 	xorl	%ebx, %ebx
 
 1:
<span class="p_del">-	SAVE_AND_SWITCH_TO_KERNEL_CR3 scratch_reg=ax save_reg=%r14</span>
<span class="p_add">+	SAVE_AND_SWITCH_TO_KERNEL_CR3 scratch_reg=%rax save_reg=%r14</span>
 
 	ret
 END(paranoid_entry)
<span class="p_chunk">@@ -1281,7 +1278,7 @@</span> <span class="p_context"> ENTRY(paranoid_exit)</span>
 	testl	%ebx, %ebx			/* swapgs needed? */
 	jnz	.Lparanoid_exit_no_swapgs
 	TRACE_IRQS_IRETQ
<span class="p_del">-	RESTORE_CR3	save_reg=%r14</span>
<span class="p_add">+	RESTORE_CR3	scratch_reg=%rbx save_reg=%r14</span>
 	SWAPGS_UNSAFE_STACK
 	jmp	.Lparanoid_exit_restore
 .Lparanoid_exit_no_swapgs:
<span class="p_chunk">@@ -1723,7 +1720,7 @@</span> <span class="p_context"> end_repeat_nmi:</span>
 	movq	$-1, %rsi
 	call	do_nmi
 
<span class="p_del">-	RESTORE_CR3 save_reg=%r14</span>
<span class="p_add">+	RESTORE_CR3 scratch_reg=%r15 save_reg=%r14</span>
 
 	testl	%ebx, %ebx			/* swapgs needed? */
 	jnz	nmi_restore
<span class="p_header">diff --git a/arch/x86/include/asm/tlbflush.h b/arch/x86/include/asm/tlbflush.h</span>
<span class="p_header">index 27eb7e8c5e84..1fb137da4c9f 100644</span>
<span class="p_header">--- a/arch/x86/include/asm/tlbflush.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/tlbflush.h</span>
<span class="p_chunk">@@ -9,6 +9,7 @@</span> <span class="p_context"></span>
 #include &lt;asm/cpufeature.h&gt;
 #include &lt;asm/special_insns.h&gt;
 #include &lt;asm/smp.h&gt;
<span class="p_add">+#include &lt;asm/kaiser.h&gt;</span>
 
 static inline void __invpcid(unsigned long pcid, unsigned long addr,
 			     unsigned long type)
<span class="p_chunk">@@ -347,9 +348,33 @@</span> <span class="p_context"> static inline void cr4_set_bits_and_update_boot(unsigned long mask)</span>
 
 extern void initialize_tlbstate_and_flush(void);
 
<span class="p_add">+DECLARE_PER_CPU(unsigned long, __asid_flush);</span>
<span class="p_add">+</span>
<span class="p_add">+/*</span>
<span class="p_add">+ * Given an asid, flush the corresponding KAISER user ASID.</span>
<span class="p_add">+ */</span>
<span class="p_add">+static inline void flush_user_asid(u16 asid)</span>
<span class="p_add">+{</span>
<span class="p_add">+	/* There is no user ASID if KAISER is off */</span>
<span class="p_add">+	if (!IS_ENABLED(CONFIG_KAISER))</span>
<span class="p_add">+		return;</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * We only have a single ASID if PCID is off and the CR3</span>
<span class="p_add">+	 * write will have flushed it.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	if (!cpu_feature_enabled(X86_FEATURE_PCID))</span>
<span class="p_add">+		return;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (!kaiser_enabled)</span>
<span class="p_add">+		return;</span>
<span class="p_add">+</span>
<span class="p_add">+	__set_bit(kern_asid(asid), this_cpu_ptr(&amp;__asid_flush));</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static inline void __native_flush_tlb(void)
 {
 	if (!cpu_feature_enabled(X86_FEATURE_INVPCID)) {
<span class="p_add">+#if 0</span>
 		/*
 		 * native_write_cr3() only clears the current PCID if
 		 * CR4 has X86_CR4_PCIDE set.  In other words, this does
<span class="p_chunk">@@ -358,9 +383,10 @@</span> <span class="p_context"> static inline void __native_flush_tlb(void)</span>
 		 * With KAISER and PCIDs, the means that we did not
 		 * flush the user PCID.  Warn if it gets called.
 		 */
<span class="p_del">-		if (IS_ENABLED(CONFIG_KAISER))</span>
<span class="p_del">-			WARN_ON_ONCE(this_cpu_read(cpu_tlbstate.cr4) &amp;</span>
<span class="p_del">-				     X86_CR4_PCIDE);</span>
<span class="p_add">+		if (IS_ENABLED(CONFIG_KAISER) &amp;&amp; kaiser_enabled)</span>
<span class="p_add">+			WARN_ON_ONCE(this_cpu_read(cpu_tlbstate.cr4) &amp; X86_CR4_PCIDE);</span>
<span class="p_add">+#endif</span>
<span class="p_add">+		flush_user_asid(this_cpu_read(cpu_tlbstate.loaded_mm_asid));</span>
 		/*
 		 * If current-&gt;mm == NULL then we borrow a mm
 		 * which may change during a task switch and
<span class="p_chunk">@@ -435,6 +461,8 @@</span> <span class="p_context"> static inline void __native_flush_tlb_single(unsigned long addr)</span>
 	 * early.
 	 */
 	if (!this_cpu_has(X86_FEATURE_INVPCID_SINGLE)) {
<span class="p_add">+		flush_user_asid(loaded_mm_asid);</span>
<span class="p_add">+</span>
 		asm volatile(&quot;invlpg (%0)&quot; ::&quot;r&quot; (addr) : &quot;memory&quot;);
 		return;
 	}
<span class="p_header">diff --git a/arch/x86/mm/init.c b/arch/x86/mm/init.c</span>
<span class="p_header">index 72f115178d14..2dcd01615772 100644</span>
<span class="p_header">--- a/arch/x86/mm/init.c</span>
<span class="p_header">+++ b/arch/x86/mm/init.c</span>
<span class="p_chunk">@@ -218,11 +218,13 @@</span> <span class="p_context"> static void setup_pcid(void)</span>
 		 * INVPCID.  Just avoid using PCIDs at all if we
 		 * have KAISER and do not have INVPCID.
 		 */
<span class="p_add">+#if 0</span>
 		if (!IS_ENABLED(CONFIG_X86_GLOBAL_PAGES) &amp;&amp;
<span class="p_del">-		    !boot_cpu_has(X86_FEATURE_INVPCID)) {</span>
<span class="p_add">+		    kaiser_enabled &amp;&amp; !boot_cpu_has(X86_FEATURE_INVPCID)) {</span>
 			setup_clear_cpu_cap(X86_FEATURE_PCID);
 			return;
 		}
<span class="p_add">+#endif</span>
 		/*
 		 * This can&#39;t be cr4_set_bits_and_update_boot() --
 		 * the trampoline code can&#39;t handle CR4.PCIDE and
<span class="p_header">diff --git a/arch/x86/mm/tlb.c b/arch/x86/mm/tlb.c</span>
<span class="p_header">index f75b6eb47a6d..4ed1d0dfd54f 100644</span>
<span class="p_header">--- a/arch/x86/mm/tlb.c</span>
<span class="p_header">+++ b/arch/x86/mm/tlb.c</span>
<span class="p_chunk">@@ -100,55 +100,14 @@</span> <span class="p_context"> static void choose_new_asid(struct mm_struct *next, u64 next_tlb_gen,</span>
 	*need_flush = true;
 }
 
<span class="p_del">-/*</span>
<span class="p_del">- * Given a kernel asid, flush the corresponding KAISER</span>
<span class="p_del">- * user ASID.</span>
<span class="p_del">- */</span>
<span class="p_del">-static void flush_user_asid(pgd_t *pgd, u16 kern_asid)</span>
<span class="p_del">-{</span>
<span class="p_del">-	/* There is no user ASID if KAISER is off */</span>
<span class="p_del">-	if (!IS_ENABLED(CONFIG_KAISER))</span>
<span class="p_del">-		return;</span>
<span class="p_del">-	/*</span>
<span class="p_del">-	 * We only have a single ASID if PCID is off and the CR3</span>
<span class="p_del">-	 * write will have flushed it.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	if (!cpu_feature_enabled(X86_FEATURE_PCID))</span>
<span class="p_del">-		return;</span>
<span class="p_del">-	/*</span>
<span class="p_del">-	 * With PCIDs enabled, write_cr3() only flushes TLB</span>
<span class="p_del">-	 * entries for the current (kernel) ASID.  This leaves</span>
<span class="p_del">-	 * old TLB entries for the user ASID in place and we must</span>
<span class="p_del">-	 * flush that context separately.  We can theoretically</span>
<span class="p_del">-	 * delay doing this until we actually load up the</span>
<span class="p_del">-	 * userspace CR3, but do it here for simplicity.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	if (cpu_feature_enabled(X86_FEATURE_INVPCID)) {</span>
<span class="p_del">-		invpcid_flush_single_context(user_asid(kern_asid));</span>
<span class="p_del">-	} else {</span>
<span class="p_del">-		/*</span>
<span class="p_del">-		 * On systems with PCIDs, but no INVPCID, the only</span>
<span class="p_del">-		 * way to flush a PCID is a CR3 write.  Note that</span>
<span class="p_del">-		 * we use the kernel page tables with the *user*</span>
<span class="p_del">-		 * ASID here.</span>
<span class="p_del">-		 */</span>
<span class="p_del">-		unsigned long user_asid_flush_cr3;</span>
<span class="p_del">-		user_asid_flush_cr3 = build_cr3(pgd, user_asid(kern_asid));</span>
<span class="p_del">-		write_cr3(user_asid_flush_cr3);</span>
<span class="p_del">-		/*</span>
<span class="p_del">-		 * We do not use PCIDs with KAISER unless we also</span>
<span class="p_del">-		 * have INVPCID.  Getting here is unexpected.</span>
<span class="p_del">-		 */</span>
<span class="p_del">-		WARN_ON_ONCE(1);</span>
<span class="p_del">-	}</span>
<span class="p_del">-}</span>
<span class="p_add">+__visible DEFINE_PER_CPU(unsigned long, __asid_flush);</span>
 
 static void load_new_mm_cr3(pgd_t *pgdir, u16 new_asid, bool need_flush)
 {
 	unsigned long new_mm_cr3;
 
 	if (need_flush) {
<span class="p_del">-		flush_user_asid(pgdir, new_asid);</span>
<span class="p_add">+		flush_user_asid(new_asid);</span>
 		new_mm_cr3 = build_cr3(pgdir, new_asid);
 	} else {
 		new_mm_cr3 = build_cr3_noflush(pgdir, new_asid);

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



