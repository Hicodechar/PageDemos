
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>Linux 4.9.53 - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    Linux 4.9.53</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=37061">gregkh@linuxfoundation.org</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>Oct. 5, 2017, 8:13 a.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;20171005081313.GB30247@kroah.com&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/9986515/mbox/"
   >mbox</a>
|
   <a href="/patch/9986515/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/9986515/">/patch/9986515/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
	[172.30.200.125])
	by pdx-korg-patchwork.web.codeaurora.org (Postfix) with ESMTP id
	0C9A6602B8 for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Thu,  5 Oct 2017 08:13:33 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id E038928C60
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Thu,  5 Oct 2017 08:13:32 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id D4B4D28C66; Thu,  5 Oct 2017 08:13:32 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-6.9 required=2.0 tests=BAYES_00,RCVD_IN_DNSWL_HI
	autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id D048528C60
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Thu,  5 Oct 2017 08:13:28 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1751587AbdJEINX (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Thu, 5 Oct 2017 04:13:23 -0400
Received: from mail.linuxfoundation.org ([140.211.169.12]:37574 &quot;EHLO
	mail.linuxfoundation.org&quot; rhost-flags-OK-OK-OK-OK) by vger.kernel.org
	with ESMTP id S1751314AbdJEING (ORCPT
	&lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Thu, 5 Oct 2017 04:13:06 -0400
Received: from localhost (LFbn-1-12253-150.w90-92.abo.wanadoo.fr
	[90.92.67.150])
	by mail.linuxfoundation.org (Postfix) with ESMTPSA id 874084A6;
	Thu,  5 Oct 2017 08:13:04 +0000 (UTC)
Date: Thu, 5 Oct 2017 10:13:13 +0200
From: Greg KH &lt;gregkh@linuxfoundation.org&gt;
To: linux-kernel@vger.kernel.org, Andrew Morton &lt;akpm@linux-foundation.org&gt;,
	torvalds@linux-foundation.org, stable@vger.kernel.org
Cc: lwn@lwn.net, Jiri Slaby &lt;jslaby@suse.cz&gt;
Subject: Re: Linux 4.9.53
Message-ID: &lt;20171005081313.GB30247@kroah.com&gt;
References: &lt;20171005081307.GA30247@kroah.com&gt;
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Disposition: inline
In-Reply-To: &lt;20171005081307.GA30247@kroah.com&gt;
User-Agent: Mutt/1.9.1 (2017-09-22)
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=37061">gregkh@linuxfoundation.org</a> - Oct. 5, 2017, 8:13 a.m.</div>
<pre class="content">

</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/Makefile b/Makefile</span>
<span class="p_header">index c53de1e38c6a..98e3be659b21 100644</span>
<span class="p_header">--- a/Makefile</span>
<span class="p_header">+++ b/Makefile</span>
<span class="p_chunk">@@ -1,6 +1,6 @@</span> <span class="p_context"></span>
 VERSION = 4
 PATCHLEVEL = 9
<span class="p_del">-SUBLEVEL = 52</span>
<span class="p_add">+SUBLEVEL = 53</span>
 EXTRAVERSION =
 NAME = Roaring Lionus
 
<span class="p_header">diff --git a/arch/arm/xen/mm.c b/arch/arm/xen/mm.c</span>
<span class="p_header">index d062f08f5020..4b24964a520a 100644</span>
<span class="p_header">--- a/arch/arm/xen/mm.c</span>
<span class="p_header">+++ b/arch/arm/xen/mm.c</span>
<span class="p_chunk">@@ -199,6 +199,7 @@</span> <span class="p_context"> static struct dma_map_ops xen_swiotlb_dma_ops = {</span>
 	.unmap_page = xen_swiotlb_unmap_page,
 	.dma_supported = xen_swiotlb_dma_supported,
 	.set_dma_mask = xen_swiotlb_set_dma_mask,
<span class="p_add">+	.mmap = xen_swiotlb_dma_mmap,</span>
 };
 
 int __init xen_mm_init(void)
<span class="p_header">diff --git a/arch/arm64/kernel/head.S b/arch/arm64/kernel/head.S</span>
<span class="p_header">index 332e33193ccf..539bebc1222f 100644</span>
<span class="p_header">--- a/arch/arm64/kernel/head.S</span>
<span class="p_header">+++ b/arch/arm64/kernel/head.S</span>
<span class="p_chunk">@@ -486,6 +486,7 @@</span> <span class="p_context"> ENTRY(kimage_vaddr)</span>
  * booted in EL1 or EL2 respectively.
  */
 ENTRY(el2_setup)
<span class="p_add">+	msr	SPsel, #1			// We want to use SP_EL{1,2}</span>
 	mrs	x0, CurrentEL
 	cmp	x0, #CurrentEL_EL2
 	b.ne	1f
<span class="p_header">diff --git a/arch/arm64/mm/fault.c b/arch/arm64/mm/fault.c</span>
<span class="p_header">index fec5b1ce97f8..403fe9e57135 100644</span>
<span class="p_header">--- a/arch/arm64/mm/fault.c</span>
<span class="p_header">+++ b/arch/arm64/mm/fault.c</span>
<span class="p_chunk">@@ -509,7 +509,7 @@</span> <span class="p_context"> static const struct fault_info fault_info[] = {</span>
 	{ do_translation_fault,	SIGSEGV, SEGV_MAPERR,	&quot;level 0 translation fault&quot;	},
 	{ do_translation_fault,	SIGSEGV, SEGV_MAPERR,	&quot;level 1 translation fault&quot;	},
 	{ do_translation_fault,	SIGSEGV, SEGV_MAPERR,	&quot;level 2 translation fault&quot;	},
<span class="p_del">-	{ do_page_fault,	SIGSEGV, SEGV_MAPERR,	&quot;level 3 translation fault&quot;	},</span>
<span class="p_add">+	{ do_translation_fault,	SIGSEGV, SEGV_MAPERR,	&quot;level 3 translation fault&quot;	},</span>
 	{ do_bad,		SIGBUS,  0,		&quot;unknown 8&quot;			},
 	{ do_page_fault,	SIGSEGV, SEGV_ACCERR,	&quot;level 1 access flag fault&quot;	},
 	{ do_page_fault,	SIGSEGV, SEGV_ACCERR,	&quot;level 2 access flag fault&quot;	},
<span class="p_header">diff --git a/arch/powerpc/kernel/entry_64.S b/arch/powerpc/kernel/entry_64.S</span>
<span class="p_header">index 767ef6d68c9e..caa659671599 100644</span>
<span class="p_header">--- a/arch/powerpc/kernel/entry_64.S</span>
<span class="p_header">+++ b/arch/powerpc/kernel/entry_64.S</span>
<span class="p_chunk">@@ -1235,10 +1235,14 @@</span> <span class="p_context"> _GLOBAL(ftrace_caller)</span>
 	stdu	r1,-SWITCH_FRAME_SIZE(r1)
 
 	/* Save all gprs to pt_regs */
<span class="p_del">-	SAVE_8GPRS(0,r1)</span>
<span class="p_del">-	SAVE_8GPRS(8,r1)</span>
<span class="p_del">-	SAVE_8GPRS(16,r1)</span>
<span class="p_del">-	SAVE_8GPRS(24,r1)</span>
<span class="p_add">+	SAVE_GPR(0, r1)</span>
<span class="p_add">+	SAVE_10GPRS(2, r1)</span>
<span class="p_add">+	SAVE_10GPRS(12, r1)</span>
<span class="p_add">+	SAVE_10GPRS(22, r1)</span>
<span class="p_add">+</span>
<span class="p_add">+	/* Save previous stack pointer (r1) */</span>
<span class="p_add">+	addi	r8, r1, SWITCH_FRAME_SIZE</span>
<span class="p_add">+	std	r8, GPR1(r1)</span>
 
 	/* Load special regs for save below */
 	mfmsr   r8
<span class="p_chunk">@@ -1292,10 +1296,10 @@</span> <span class="p_context"> ftrace_call:</span>
 #endif
 
 	/* Restore gprs */
<span class="p_del">-	REST_8GPRS(0,r1)</span>
<span class="p_del">-	REST_8GPRS(8,r1)</span>
<span class="p_del">-	REST_8GPRS(16,r1)</span>
<span class="p_del">-	REST_8GPRS(24,r1)</span>
<span class="p_add">+	REST_GPR(0,r1)</span>
<span class="p_add">+	REST_10GPRS(2,r1)</span>
<span class="p_add">+	REST_10GPRS(12,r1)</span>
<span class="p_add">+	REST_10GPRS(22,r1)</span>
 
 	/* Restore callee&#39;s TOC */
 	ld	r2, 24(r1)
<span class="p_header">diff --git a/arch/powerpc/kernel/ptrace.c b/arch/powerpc/kernel/ptrace.c</span>
<span class="p_header">index dcbb9144c16d..d97370866a5f 100644</span>
<span class="p_header">--- a/arch/powerpc/kernel/ptrace.c</span>
<span class="p_header">+++ b/arch/powerpc/kernel/ptrace.c</span>
<span class="p_chunk">@@ -131,7 +131,7 @@</span> <span class="p_context"> static void flush_tmregs_to_thread(struct task_struct *tsk)</span>
 	 * in the appropriate thread structures from live.
 	 */
 
<span class="p_del">-	if (tsk != current)</span>
<span class="p_add">+	if ((!cpu_has_feature(CPU_FTR_TM)) || (tsk != current))</span>
 		return;
 
 	if (MSR_TM_SUSPENDED(mfmsr())) {
<span class="p_header">diff --git a/arch/powerpc/kvm/book3s_64_vio.c b/arch/powerpc/kvm/book3s_64_vio.c</span>
<span class="p_header">index c379ff5a4438..da2a7eccb10a 100644</span>
<span class="p_header">--- a/arch/powerpc/kvm/book3s_64_vio.c</span>
<span class="p_header">+++ b/arch/powerpc/kvm/book3s_64_vio.c</span>
<span class="p_chunk">@@ -129,8 +129,11 @@</span> <span class="p_context"> static int kvm_spapr_tce_mmap(struct file *file, struct vm_area_struct *vma)</span>
 static int kvm_spapr_tce_release(struct inode *inode, struct file *filp)
 {
 	struct kvmppc_spapr_tce_table *stt = filp-&gt;private_data;
<span class="p_add">+	struct kvm *kvm = stt-&gt;kvm;</span>
 
<span class="p_add">+	mutex_lock(&amp;kvm-&gt;lock);</span>
 	list_del_rcu(&amp;stt-&gt;list);
<span class="p_add">+	mutex_unlock(&amp;kvm-&gt;lock);</span>
 
 	kvm_put_kvm(stt-&gt;kvm);
 
<span class="p_chunk">@@ -150,6 +153,7 @@</span> <span class="p_context"> long kvm_vm_ioctl_create_spapr_tce(struct kvm *kvm,</span>
 				   struct kvm_create_spapr_tce_64 *args)
 {
 	struct kvmppc_spapr_tce_table *stt = NULL;
<span class="p_add">+	struct kvmppc_spapr_tce_table *siter;</span>
 	unsigned long npages, size;
 	int ret = -ENOMEM;
 	int i;
<span class="p_chunk">@@ -157,24 +161,16 @@</span> <span class="p_context"> long kvm_vm_ioctl_create_spapr_tce(struct kvm *kvm,</span>
 	if (!args-&gt;size)
 		return -EINVAL;
 
<span class="p_del">-	/* Check this LIOBN hasn&#39;t been previously allocated */</span>
<span class="p_del">-	list_for_each_entry(stt, &amp;kvm-&gt;arch.spapr_tce_tables, list) {</span>
<span class="p_del">-		if (stt-&gt;liobn == args-&gt;liobn)</span>
<span class="p_del">-			return -EBUSY;</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
 	size = args-&gt;size;
 	npages = kvmppc_tce_pages(size);
 	ret = kvmppc_account_memlimit(kvmppc_stt_pages(npages), true);
<span class="p_del">-	if (ret) {</span>
<span class="p_del">-		stt = NULL;</span>
<span class="p_del">-		goto fail;</span>
<span class="p_del">-	}</span>
<span class="p_add">+	if (ret)</span>
<span class="p_add">+		return ret;</span>
 
 	stt = kzalloc(sizeof(*stt) + npages * sizeof(struct page *),
 		      GFP_KERNEL);
 	if (!stt)
<span class="p_del">-		goto fail;</span>
<span class="p_add">+		goto fail_acct;</span>
 
 	stt-&gt;liobn = args-&gt;liobn;
 	stt-&gt;page_shift = args-&gt;page_shift;
<span class="p_chunk">@@ -188,24 +184,39 @@</span> <span class="p_context"> long kvm_vm_ioctl_create_spapr_tce(struct kvm *kvm,</span>
 			goto fail;
 	}
 
<span class="p_del">-	kvm_get_kvm(kvm);</span>
<span class="p_del">-</span>
 	mutex_lock(&amp;kvm-&gt;lock);
<span class="p_del">-	list_add_rcu(&amp;stt-&gt;list, &amp;kvm-&gt;arch.spapr_tce_tables);</span>
<span class="p_add">+</span>
<span class="p_add">+	/* Check this LIOBN hasn&#39;t been previously allocated */</span>
<span class="p_add">+	ret = 0;</span>
<span class="p_add">+	list_for_each_entry(siter, &amp;kvm-&gt;arch.spapr_tce_tables, list) {</span>
<span class="p_add">+		if (siter-&gt;liobn == args-&gt;liobn) {</span>
<span class="p_add">+			ret = -EBUSY;</span>
<span class="p_add">+			break;</span>
<span class="p_add">+		}</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	if (!ret)</span>
<span class="p_add">+		ret = anon_inode_getfd(&quot;kvm-spapr-tce&quot;, &amp;kvm_spapr_tce_fops,</span>
<span class="p_add">+				       stt, O_RDWR | O_CLOEXEC);</span>
<span class="p_add">+</span>
<span class="p_add">+	if (ret &gt;= 0) {</span>
<span class="p_add">+		list_add_rcu(&amp;stt-&gt;list, &amp;kvm-&gt;arch.spapr_tce_tables);</span>
<span class="p_add">+		kvm_get_kvm(kvm);</span>
<span class="p_add">+	}</span>
 
 	mutex_unlock(&amp;kvm-&gt;lock);
 
<span class="p_del">-	return anon_inode_getfd(&quot;kvm-spapr-tce&quot;, &amp;kvm_spapr_tce_fops,</span>
<span class="p_del">-				stt, O_RDWR | O_CLOEXEC);</span>
<span class="p_add">+	if (ret &gt;= 0)</span>
<span class="p_add">+		return ret;</span>
 
<span class="p_del">-fail:</span>
<span class="p_del">-	if (stt) {</span>
<span class="p_del">-		for (i = 0; i &lt; npages; i++)</span>
<span class="p_del">-			if (stt-&gt;pages[i])</span>
<span class="p_del">-				__free_page(stt-&gt;pages[i]);</span>
<span class="p_add">+ fail:</span>
<span class="p_add">+	for (i = 0; i &lt; npages; i++)</span>
<span class="p_add">+		if (stt-&gt;pages[i])</span>
<span class="p_add">+			__free_page(stt-&gt;pages[i]);</span>
 
<span class="p_del">-		kfree(stt);</span>
<span class="p_del">-	}</span>
<span class="p_add">+	kfree(stt);</span>
<span class="p_add">+ fail_acct:</span>
<span class="p_add">+	kvmppc_account_memlimit(kvmppc_stt_pages(npages), false);</span>
 	return ret;
 }
 
<span class="p_header">diff --git a/arch/powerpc/platforms/pseries/mobility.c b/arch/powerpc/platforms/pseries/mobility.c</span>
<span class="p_header">index a560a98bcf3b..6a5e7467445c 100644</span>
<span class="p_header">--- a/arch/powerpc/platforms/pseries/mobility.c</span>
<span class="p_header">+++ b/arch/powerpc/platforms/pseries/mobility.c</span>
<span class="p_chunk">@@ -225,8 +225,10 @@</span> <span class="p_context"> static int add_dt_node(__be32 parent_phandle, __be32 drc_index)</span>
 		return -ENOENT;
 
 	dn = dlpar_configure_connector(drc_index, parent_dn);
<span class="p_del">-	if (!dn)</span>
<span class="p_add">+	if (!dn) {</span>
<span class="p_add">+		of_node_put(parent_dn);</span>
 		return -ENOENT;
<span class="p_add">+	}</span>
 
 	rc = dlpar_attach_node(dn);
 	if (rc)
<span class="p_header">diff --git a/arch/s390/mm/gup.c b/arch/s390/mm/gup.c</span>
<span class="p_header">index 18d4107e10ee..97fc449a7470 100644</span>
<span class="p_header">--- a/arch/s390/mm/gup.c</span>
<span class="p_header">+++ b/arch/s390/mm/gup.c</span>
<span class="p_chunk">@@ -56,13 +56,12 @@</span> <span class="p_context"> static inline int gup_pte_range(pmd_t *pmdp, pmd_t pmd, unsigned long addr,</span>
 static inline int gup_huge_pmd(pmd_t *pmdp, pmd_t pmd, unsigned long addr,
 		unsigned long end, int write, struct page **pages, int *nr)
 {
<span class="p_del">-	unsigned long mask, result;</span>
 	struct page *head, *page;
<span class="p_add">+	unsigned long mask;</span>
 	int refs;
 
<span class="p_del">-	result = write ? 0 : _SEGMENT_ENTRY_PROTECT;</span>
<span class="p_del">-	mask = result | _SEGMENT_ENTRY_INVALID;</span>
<span class="p_del">-	if ((pmd_val(pmd) &amp; mask) != result)</span>
<span class="p_add">+	mask = (write ? _SEGMENT_ENTRY_PROTECT : 0) | _SEGMENT_ENTRY_INVALID;</span>
<span class="p_add">+	if ((pmd_val(pmd) &amp; mask) != 0)</span>
 		return 0;
 	VM_BUG_ON(!pfn_valid(pmd_val(pmd) &gt;&gt; PAGE_SHIFT));
 
<span class="p_header">diff --git a/arch/x86/kernel/fpu/regset.c b/arch/x86/kernel/fpu/regset.c</span>
<span class="p_header">index c114b132d121..7052d9a65fe9 100644</span>
<span class="p_header">--- a/arch/x86/kernel/fpu/regset.c</span>
<span class="p_header">+++ b/arch/x86/kernel/fpu/regset.c</span>
<span class="p_chunk">@@ -130,11 +130,16 @@</span> <span class="p_context"> int xstateregs_set(struct task_struct *target, const struct user_regset *regset,</span>
 
 	fpu__activate_fpstate_write(fpu);
 
<span class="p_del">-	if (boot_cpu_has(X86_FEATURE_XSAVES))</span>
<span class="p_add">+	if (boot_cpu_has(X86_FEATURE_XSAVES)) {</span>
 		ret = copyin_to_xsaves(kbuf, ubuf, xsave);
<span class="p_del">-	else</span>
<span class="p_add">+	} else {</span>
 		ret = user_regset_copyin(&amp;pos, &amp;count, &amp;kbuf, &amp;ubuf, xsave, 0, -1);
 
<span class="p_add">+		/* xcomp_bv must be 0 when using uncompacted format */</span>
<span class="p_add">+		if (!ret &amp;&amp; xsave-&gt;header.xcomp_bv)</span>
<span class="p_add">+			ret = -EINVAL;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
 	/*
 	 * In case of failure, mark all states as init:
 	 */
<span class="p_header">diff --git a/arch/x86/kernel/fpu/signal.c b/arch/x86/kernel/fpu/signal.c</span>
<span class="p_header">index a184c210efba..3ec0d2d64601 100644</span>
<span class="p_header">--- a/arch/x86/kernel/fpu/signal.c</span>
<span class="p_header">+++ b/arch/x86/kernel/fpu/signal.c</span>
<span class="p_chunk">@@ -329,6 +329,10 @@</span> <span class="p_context"> static int __fpu__restore_sig(void __user *buf, void __user *buf_fx, int size)</span>
 		} else {
 			err = __copy_from_user(&amp;fpu-&gt;state.xsave,
 					       buf_fx, state_size);
<span class="p_add">+</span>
<span class="p_add">+			/* xcomp_bv must be 0 when using uncompacted format */</span>
<span class="p_add">+			if (!err &amp;&amp; state_size &gt; offsetof(struct xregs_state, header) &amp;&amp; fpu-&gt;state.xsave.header.xcomp_bv)</span>
<span class="p_add">+				err = -EINVAL;</span>
 		}
 
 		if (err || __copy_from_user(&amp;env, buf, sizeof(env))) {
<span class="p_header">diff --git a/arch/x86/kernel/kvm.c b/arch/x86/kernel/kvm.c</span>
<span class="p_header">index 55ffd9dc2258..77f17cbfe271 100644</span>
<span class="p_header">--- a/arch/x86/kernel/kvm.c</span>
<span class="p_header">+++ b/arch/x86/kernel/kvm.c</span>
<span class="p_chunk">@@ -141,7 +141,8 @@</span> <span class="p_context"> void kvm_async_pf_task_wait(u32 token)</span>
 
 	n.token = token;
 	n.cpu = smp_processor_id();
<span class="p_del">-	n.halted = is_idle_task(current) || preempt_count() &gt; 1;</span>
<span class="p_add">+	n.halted = is_idle_task(current) || preempt_count() &gt; 1 ||</span>
<span class="p_add">+		   rcu_preempt_depth();</span>
 	init_swait_queue_head(&amp;n.wq);
 	hlist_add_head(&amp;n.link, &amp;b-&gt;list);
 	raw_spin_unlock(&amp;b-&gt;lock);
<span class="p_header">diff --git a/arch/x86/kvm/vmx.c b/arch/x86/kvm/vmx.c</span>
<span class="p_header">index 3dc6d8017ce9..fb49212d25df 100644</span>
<span class="p_header">--- a/arch/x86/kvm/vmx.c</span>
<span class="p_header">+++ b/arch/x86/kvm/vmx.c</span>
<span class="p_chunk">@@ -2167,46 +2167,44 @@</span> <span class="p_context"> static void vmx_vcpu_pi_load(struct kvm_vcpu *vcpu, int cpu)</span>
 	struct pi_desc old, new;
 	unsigned int dest;
 
<span class="p_del">-	if (!kvm_arch_has_assigned_device(vcpu-&gt;kvm) ||</span>
<span class="p_del">-		!irq_remapping_cap(IRQ_POSTING_CAP)  ||</span>
<span class="p_del">-		!kvm_vcpu_apicv_active(vcpu))</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * In case of hot-plug or hot-unplug, we may have to undo</span>
<span class="p_add">+	 * vmx_vcpu_pi_put even if there is no assigned device.  And we</span>
<span class="p_add">+	 * always keep PI.NDST up to date for simplicity: it makes the</span>
<span class="p_add">+	 * code easier, and CPU migration is not a fast path.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	if (!pi_test_sn(pi_desc) &amp;&amp; vcpu-&gt;cpu == cpu)</span>
<span class="p_add">+		return;</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * First handle the simple case where no cmpxchg is necessary; just</span>
<span class="p_add">+	 * allow posting non-urgent interrupts.</span>
<span class="p_add">+	 *</span>
<span class="p_add">+	 * If the &#39;nv&#39; field is POSTED_INTR_WAKEUP_VECTOR, do not change</span>
<span class="p_add">+	 * PI.NDST: pi_post_block will do it for us and the wakeup_handler</span>
<span class="p_add">+	 * expects the VCPU to be on the blocked_vcpu_list that matches</span>
<span class="p_add">+	 * PI.NDST.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	if (pi_desc-&gt;nv == POSTED_INTR_WAKEUP_VECTOR ||</span>
<span class="p_add">+	    vcpu-&gt;cpu == cpu) {</span>
<span class="p_add">+		pi_clear_sn(pi_desc);</span>
 		return;
<span class="p_add">+	}</span>
 
<span class="p_add">+	/* The full case.  */</span>
 	do {
 		old.control = new.control = pi_desc-&gt;control;
 
<span class="p_del">-		/*</span>
<span class="p_del">-		 * If &#39;nv&#39; field is POSTED_INTR_WAKEUP_VECTOR, there</span>
<span class="p_del">-		 * are two possible cases:</span>
<span class="p_del">-		 * 1. After running &#39;pre_block&#39;, context switch</span>
<span class="p_del">-		 *    happened. For this case, &#39;sn&#39; was set in</span>
<span class="p_del">-		 *    vmx_vcpu_put(), so we need to clear it here.</span>
<span class="p_del">-		 * 2. After running &#39;pre_block&#39;, we were blocked,</span>
<span class="p_del">-		 *    and woken up by some other guy. For this case,</span>
<span class="p_del">-		 *    we don&#39;t need to do anything, &#39;pi_post_block&#39;</span>
<span class="p_del">-		 *    will do everything for us. However, we cannot</span>
<span class="p_del">-		 *    check whether it is case #1 or case #2 here</span>
<span class="p_del">-		 *    (maybe, not needed), so we also clear sn here,</span>
<span class="p_del">-		 *    I think it is not a big deal.</span>
<span class="p_del">-		 */</span>
<span class="p_del">-		if (pi_desc-&gt;nv != POSTED_INTR_WAKEUP_VECTOR) {</span>
<span class="p_del">-			if (vcpu-&gt;cpu != cpu) {</span>
<span class="p_del">-				dest = cpu_physical_id(cpu);</span>
<span class="p_del">-</span>
<span class="p_del">-				if (x2apic_enabled())</span>
<span class="p_del">-					new.ndst = dest;</span>
<span class="p_del">-				else</span>
<span class="p_del">-					new.ndst = (dest &lt;&lt; 8) &amp; 0xFF00;</span>
<span class="p_del">-			}</span>
<span class="p_add">+		dest = cpu_physical_id(cpu);</span>
 
<span class="p_del">-			/* set &#39;NV&#39; to &#39;notification vector&#39; */</span>
<span class="p_del">-			new.nv = POSTED_INTR_VECTOR;</span>
<span class="p_del">-		}</span>
<span class="p_add">+		if (x2apic_enabled())</span>
<span class="p_add">+			new.ndst = dest;</span>
<span class="p_add">+		else</span>
<span class="p_add">+			new.ndst = (dest &lt;&lt; 8) &amp; 0xFF00;</span>
 
<span class="p_del">-		/* Allow posting non-urgent interrupts */</span>
 		new.sn = 0;
<span class="p_del">-	} while (cmpxchg(&amp;pi_desc-&gt;control, old.control,</span>
<span class="p_del">-			new.control) != old.control);</span>
<span class="p_add">+	} while (cmpxchg64(&amp;pi_desc-&gt;control, old.control,</span>
<span class="p_add">+			   new.control) != old.control);</span>
 }
 
 static void decache_tsc_multiplier(struct vcpu_vmx *vmx)
<span class="p_chunk">@@ -4761,21 +4759,30 @@</span> <span class="p_context"> static inline bool kvm_vcpu_trigger_posted_interrupt(struct kvm_vcpu *vcpu)</span>
 {
 #ifdef CONFIG_SMP
 	if (vcpu-&gt;mode == IN_GUEST_MODE) {
<span class="p_del">-		struct vcpu_vmx *vmx = to_vmx(vcpu);</span>
<span class="p_del">-</span>
 		/*
<span class="p_del">-		 * Currently, we don&#39;t support urgent interrupt,</span>
<span class="p_del">-		 * all interrupts are recognized as non-urgent</span>
<span class="p_del">-		 * interrupt, so we cannot post interrupts when</span>
<span class="p_del">-		 * &#39;SN&#39; is set.</span>
<span class="p_add">+		 * The vector of interrupt to be delivered to vcpu had</span>
<span class="p_add">+		 * been set in PIR before this function.</span>
 		 *
<span class="p_del">-		 * If the vcpu is in guest mode, it means it is</span>
<span class="p_del">-		 * running instead of being scheduled out and</span>
<span class="p_del">-		 * waiting in the run queue, and that&#39;s the only</span>
<span class="p_del">-		 * case when &#39;SN&#39; is set currently, warning if</span>
<span class="p_del">-		 * &#39;SN&#39; is set.</span>
<span class="p_add">+		 * Following cases will be reached in this block, and</span>
<span class="p_add">+		 * we always send a notification event in all cases as</span>
<span class="p_add">+		 * explained below.</span>
<span class="p_add">+		 *</span>
<span class="p_add">+		 * Case 1: vcpu keeps in non-root mode. Sending a</span>
<span class="p_add">+		 * notification event posts the interrupt to vcpu.</span>
<span class="p_add">+		 *</span>
<span class="p_add">+		 * Case 2: vcpu exits to root mode and is still</span>
<span class="p_add">+		 * runnable. PIR will be synced to vIRR before the</span>
<span class="p_add">+		 * next vcpu entry. Sending a notification event in</span>
<span class="p_add">+		 * this case has no effect, as vcpu is not in root</span>
<span class="p_add">+		 * mode.</span>
<span class="p_add">+		 *</span>
<span class="p_add">+		 * Case 3: vcpu exits to root mode and is blocked.</span>
<span class="p_add">+		 * vcpu_block() has already synced PIR to vIRR and</span>
<span class="p_add">+		 * never blocks vcpu if vIRR is not cleared. Therefore,</span>
<span class="p_add">+		 * a blocked vcpu here does not wait for any requested</span>
<span class="p_add">+		 * interrupts in PIR, and sending a notification event</span>
<span class="p_add">+		 * which has no effect is safe here.</span>
 		 */
<span class="p_del">-		WARN_ON_ONCE(pi_test_sn(&amp;vmx-&gt;pi_desc));</span>
 
 		apic-&gt;send_IPI_mask(get_cpu_mask(vcpu-&gt;cpu),
 				POSTED_INTR_VECTOR);
<span class="p_chunk">@@ -9187,6 +9194,13 @@</span> <span class="p_context"> static struct kvm_vcpu *vmx_create_vcpu(struct kvm *kvm, unsigned int id)</span>
 
 	vmx-&gt;msr_ia32_feature_control_valid_bits = FEATURE_CONTROL_LOCKED;
 
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Enforce invariant: pi_desc.nv is always either POSTED_INTR_VECTOR</span>
<span class="p_add">+	 * or POSTED_INTR_WAKEUP_VECTOR.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	vmx-&gt;pi_desc.nv = POSTED_INTR_VECTOR;</span>
<span class="p_add">+	vmx-&gt;pi_desc.sn = 1;</span>
<span class="p_add">+</span>
 	return &amp;vmx-&gt;vcpu;
 
 free_vmcs:
<span class="p_chunk">@@ -9996,6 +10010,11 @@</span> <span class="p_context"> static void prepare_vmcs02(struct kvm_vcpu *vcpu, struct vmcs12 *vmcs12)</span>
 		vmcs_write64(VIRTUAL_APIC_PAGE_ADDR,
 				page_to_phys(vmx-&gt;nested.virtual_apic_page));
 		vmcs_write32(TPR_THRESHOLD, vmcs12-&gt;tpr_threshold);
<span class="p_add">+	} else {</span>
<span class="p_add">+#ifdef CONFIG_X86_64</span>
<span class="p_add">+		exec_control |= CPU_BASED_CR8_LOAD_EXITING |</span>
<span class="p_add">+				CPU_BASED_CR8_STORE_EXITING;</span>
<span class="p_add">+#endif</span>
 	}
 
 	if (cpu_has_vmx_msr_bitmap() &amp;&amp;
<span class="p_chunk">@@ -11000,6 +11019,37 @@</span> <span class="p_context"> static void vmx_enable_log_dirty_pt_masked(struct kvm *kvm,</span>
 	kvm_mmu_clear_dirty_pt_masked(kvm, memslot, offset, mask);
 }
 
<span class="p_add">+static void __pi_post_block(struct kvm_vcpu *vcpu)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct pi_desc *pi_desc = vcpu_to_pi_desc(vcpu);</span>
<span class="p_add">+	struct pi_desc old, new;</span>
<span class="p_add">+	unsigned int dest;</span>
<span class="p_add">+</span>
<span class="p_add">+	do {</span>
<span class="p_add">+		old.control = new.control = pi_desc-&gt;control;</span>
<span class="p_add">+		WARN(old.nv != POSTED_INTR_WAKEUP_VECTOR,</span>
<span class="p_add">+		     &quot;Wakeup handler not enabled while the VCPU is blocked\n&quot;);</span>
<span class="p_add">+</span>
<span class="p_add">+		dest = cpu_physical_id(vcpu-&gt;cpu);</span>
<span class="p_add">+</span>
<span class="p_add">+		if (x2apic_enabled())</span>
<span class="p_add">+			new.ndst = dest;</span>
<span class="p_add">+		else</span>
<span class="p_add">+			new.ndst = (dest &lt;&lt; 8) &amp; 0xFF00;</span>
<span class="p_add">+</span>
<span class="p_add">+		/* set &#39;NV&#39; to &#39;notification vector&#39; */</span>
<span class="p_add">+		new.nv = POSTED_INTR_VECTOR;</span>
<span class="p_add">+	} while (cmpxchg64(&amp;pi_desc-&gt;control, old.control,</span>
<span class="p_add">+			   new.control) != old.control);</span>
<span class="p_add">+</span>
<span class="p_add">+	if (!WARN_ON_ONCE(vcpu-&gt;pre_pcpu == -1)) {</span>
<span class="p_add">+		spin_lock(&amp;per_cpu(blocked_vcpu_on_cpu_lock, vcpu-&gt;pre_pcpu));</span>
<span class="p_add">+		list_del(&amp;vcpu-&gt;blocked_vcpu_list);</span>
<span class="p_add">+		spin_unlock(&amp;per_cpu(blocked_vcpu_on_cpu_lock, vcpu-&gt;pre_pcpu));</span>
<span class="p_add">+		vcpu-&gt;pre_pcpu = -1;</span>
<span class="p_add">+	}</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 /*
  * This routine does the following things for vCPU which is going
  * to be blocked if VT-d PI is enabled.
<span class="p_chunk">@@ -11015,7 +11065,6 @@</span> <span class="p_context"> static void vmx_enable_log_dirty_pt_masked(struct kvm *kvm,</span>
  */
 static int pi_pre_block(struct kvm_vcpu *vcpu)
 {
<span class="p_del">-	unsigned long flags;</span>
 	unsigned int dest;
 	struct pi_desc old, new;
 	struct pi_desc *pi_desc = vcpu_to_pi_desc(vcpu);
<span class="p_chunk">@@ -11025,34 +11074,20 @@</span> <span class="p_context"> static int pi_pre_block(struct kvm_vcpu *vcpu)</span>
 		!kvm_vcpu_apicv_active(vcpu))
 		return 0;
 
<span class="p_del">-	vcpu-&gt;pre_pcpu = vcpu-&gt;cpu;</span>
<span class="p_del">-	spin_lock_irqsave(&amp;per_cpu(blocked_vcpu_on_cpu_lock,</span>
<span class="p_del">-			  vcpu-&gt;pre_pcpu), flags);</span>
<span class="p_del">-	list_add_tail(&amp;vcpu-&gt;blocked_vcpu_list,</span>
<span class="p_del">-		      &amp;per_cpu(blocked_vcpu_on_cpu,</span>
<span class="p_del">-		      vcpu-&gt;pre_pcpu));</span>
<span class="p_del">-	spin_unlock_irqrestore(&amp;per_cpu(blocked_vcpu_on_cpu_lock,</span>
<span class="p_del">-			       vcpu-&gt;pre_pcpu), flags);</span>
<span class="p_add">+	WARN_ON(irqs_disabled());</span>
<span class="p_add">+	local_irq_disable();</span>
<span class="p_add">+	if (!WARN_ON_ONCE(vcpu-&gt;pre_pcpu != -1)) {</span>
<span class="p_add">+		vcpu-&gt;pre_pcpu = vcpu-&gt;cpu;</span>
<span class="p_add">+		spin_lock(&amp;per_cpu(blocked_vcpu_on_cpu_lock, vcpu-&gt;pre_pcpu));</span>
<span class="p_add">+		list_add_tail(&amp;vcpu-&gt;blocked_vcpu_list,</span>
<span class="p_add">+			      &amp;per_cpu(blocked_vcpu_on_cpu,</span>
<span class="p_add">+				       vcpu-&gt;pre_pcpu));</span>
<span class="p_add">+		spin_unlock(&amp;per_cpu(blocked_vcpu_on_cpu_lock, vcpu-&gt;pre_pcpu));</span>
<span class="p_add">+	}</span>
 
 	do {
 		old.control = new.control = pi_desc-&gt;control;
 
<span class="p_del">-		/*</span>
<span class="p_del">-		 * We should not block the vCPU if</span>
<span class="p_del">-		 * an interrupt is posted for it.</span>
<span class="p_del">-		 */</span>
<span class="p_del">-		if (pi_test_on(pi_desc) == 1) {</span>
<span class="p_del">-			spin_lock_irqsave(&amp;per_cpu(blocked_vcpu_on_cpu_lock,</span>
<span class="p_del">-					  vcpu-&gt;pre_pcpu), flags);</span>
<span class="p_del">-			list_del(&amp;vcpu-&gt;blocked_vcpu_list);</span>
<span class="p_del">-			spin_unlock_irqrestore(</span>
<span class="p_del">-					&amp;per_cpu(blocked_vcpu_on_cpu_lock,</span>
<span class="p_del">-					vcpu-&gt;pre_pcpu), flags);</span>
<span class="p_del">-			vcpu-&gt;pre_pcpu = -1;</span>
<span class="p_del">-</span>
<span class="p_del">-			return 1;</span>
<span class="p_del">-		}</span>
<span class="p_del">-</span>
 		WARN((pi_desc-&gt;sn == 1),
 		     &quot;Warning: SN field of posted-interrupts &quot;
 		     &quot;is set before blocking\n&quot;);
<span class="p_chunk">@@ -11074,10 +11109,15 @@</span> <span class="p_context"> static int pi_pre_block(struct kvm_vcpu *vcpu)</span>
 
 		/* set &#39;NV&#39; to &#39;wakeup vector&#39; */
 		new.nv = POSTED_INTR_WAKEUP_VECTOR;
<span class="p_del">-	} while (cmpxchg(&amp;pi_desc-&gt;control, old.control,</span>
<span class="p_del">-			new.control) != old.control);</span>
<span class="p_add">+	} while (cmpxchg64(&amp;pi_desc-&gt;control, old.control,</span>
<span class="p_add">+			   new.control) != old.control);</span>
 
<span class="p_del">-	return 0;</span>
<span class="p_add">+	/* We should not block the vCPU if an interrupt is posted for it.  */</span>
<span class="p_add">+	if (pi_test_on(pi_desc) == 1)</span>
<span class="p_add">+		__pi_post_block(vcpu);</span>
<span class="p_add">+</span>
<span class="p_add">+	local_irq_enable();</span>
<span class="p_add">+	return (vcpu-&gt;pre_pcpu == -1);</span>
 }
 
 static int vmx_pre_block(struct kvm_vcpu *vcpu)
<span class="p_chunk">@@ -11093,44 +11133,13 @@</span> <span class="p_context"> static int vmx_pre_block(struct kvm_vcpu *vcpu)</span>
 
 static void pi_post_block(struct kvm_vcpu *vcpu)
 {
<span class="p_del">-	struct pi_desc *pi_desc = vcpu_to_pi_desc(vcpu);</span>
<span class="p_del">-	struct pi_desc old, new;</span>
<span class="p_del">-	unsigned int dest;</span>
<span class="p_del">-	unsigned long flags;</span>
<span class="p_del">-</span>
<span class="p_del">-	if (!kvm_arch_has_assigned_device(vcpu-&gt;kvm) ||</span>
<span class="p_del">-		!irq_remapping_cap(IRQ_POSTING_CAP)  ||</span>
<span class="p_del">-		!kvm_vcpu_apicv_active(vcpu))</span>
<span class="p_add">+	if (vcpu-&gt;pre_pcpu == -1)</span>
 		return;
 
<span class="p_del">-	do {</span>
<span class="p_del">-		old.control = new.control = pi_desc-&gt;control;</span>
<span class="p_del">-</span>
<span class="p_del">-		dest = cpu_physical_id(vcpu-&gt;cpu);</span>
<span class="p_del">-</span>
<span class="p_del">-		if (x2apic_enabled())</span>
<span class="p_del">-			new.ndst = dest;</span>
<span class="p_del">-		else</span>
<span class="p_del">-			new.ndst = (dest &lt;&lt; 8) &amp; 0xFF00;</span>
<span class="p_del">-</span>
<span class="p_del">-		/* Allow posting non-urgent interrupts */</span>
<span class="p_del">-		new.sn = 0;</span>
<span class="p_del">-</span>
<span class="p_del">-		/* set &#39;NV&#39; to &#39;notification vector&#39; */</span>
<span class="p_del">-		new.nv = POSTED_INTR_VECTOR;</span>
<span class="p_del">-	} while (cmpxchg(&amp;pi_desc-&gt;control, old.control,</span>
<span class="p_del">-			new.control) != old.control);</span>
<span class="p_del">-</span>
<span class="p_del">-	if(vcpu-&gt;pre_pcpu != -1) {</span>
<span class="p_del">-		spin_lock_irqsave(</span>
<span class="p_del">-			&amp;per_cpu(blocked_vcpu_on_cpu_lock,</span>
<span class="p_del">-			vcpu-&gt;pre_pcpu), flags);</span>
<span class="p_del">-		list_del(&amp;vcpu-&gt;blocked_vcpu_list);</span>
<span class="p_del">-		spin_unlock_irqrestore(</span>
<span class="p_del">-			&amp;per_cpu(blocked_vcpu_on_cpu_lock,</span>
<span class="p_del">-			vcpu-&gt;pre_pcpu), flags);</span>
<span class="p_del">-		vcpu-&gt;pre_pcpu = -1;</span>
<span class="p_del">-	}</span>
<span class="p_add">+	WARN_ON(irqs_disabled());</span>
<span class="p_add">+	local_irq_disable();</span>
<span class="p_add">+	__pi_post_block(vcpu);</span>
<span class="p_add">+	local_irq_enable();</span>
 }
 
 static void vmx_post_block(struct kvm_vcpu *vcpu)
<span class="p_chunk">@@ -11158,7 +11167,7 @@</span> <span class="p_context"> static int vmx_update_pi_irte(struct kvm *kvm, unsigned int host_irq,</span>
 	struct kvm_lapic_irq irq;
 	struct kvm_vcpu *vcpu;
 	struct vcpu_data vcpu_info;
<span class="p_del">-	int idx, ret = -EINVAL;</span>
<span class="p_add">+	int idx, ret = 0;</span>
 
 	if (!kvm_arch_has_assigned_device(kvm) ||
 		!irq_remapping_cap(IRQ_POSTING_CAP) ||
<span class="p_chunk">@@ -11167,7 +11176,12 @@</span> <span class="p_context"> static int vmx_update_pi_irte(struct kvm *kvm, unsigned int host_irq,</span>
 
 	idx = srcu_read_lock(&amp;kvm-&gt;irq_srcu);
 	irq_rt = srcu_dereference(kvm-&gt;irq_routing, &amp;kvm-&gt;irq_srcu);
<span class="p_del">-	BUG_ON(guest_irq &gt;= irq_rt-&gt;nr_rt_entries);</span>
<span class="p_add">+	if (guest_irq &gt;= irq_rt-&gt;nr_rt_entries ||</span>
<span class="p_add">+	    hlist_empty(&amp;irq_rt-&gt;map[guest_irq])) {</span>
<span class="p_add">+		pr_warn_once(&quot;no route for guest_irq %u/%u (broken user space?)\n&quot;,</span>
<span class="p_add">+			     guest_irq, irq_rt-&gt;nr_rt_entries);</span>
<span class="p_add">+		goto out;</span>
<span class="p_add">+	}</span>
 
 	hlist_for_each_entry(e, &amp;irq_rt-&gt;map[guest_irq], link) {
 		if (e-&gt;type != KVM_IRQ_ROUTING_MSI)
<span class="p_chunk">@@ -11210,12 +11224,8 @@</span> <span class="p_context"> static int vmx_update_pi_irte(struct kvm *kvm, unsigned int host_irq,</span>
 
 		if (set)
 			ret = irq_set_vcpu_affinity(host_irq, &amp;vcpu_info);
<span class="p_del">-		else {</span>
<span class="p_del">-			/* suppress notification event before unposting */</span>
<span class="p_del">-			pi_set_sn(vcpu_to_pi_desc(vcpu));</span>
<span class="p_add">+		else</span>
 			ret = irq_set_vcpu_affinity(host_irq, NULL);
<span class="p_del">-			pi_clear_sn(vcpu_to_pi_desc(vcpu));</span>
<span class="p_del">-		}</span>
 
 		if (ret &lt; 0) {
 			printk(KERN_INFO &quot;%s: failed to update PI IRTE\n&quot;,
<span class="p_header">diff --git a/arch/x86/mm/fault.c b/arch/x86/mm/fault.c</span>
<span class="p_header">index 9f72ca3b2669..1dd796025472 100644</span>
<span class="p_header">--- a/arch/x86/mm/fault.c</span>
<span class="p_header">+++ b/arch/x86/mm/fault.c</span>
<span class="p_chunk">@@ -191,8 +191,7 @@</span> <span class="p_context"> is_prefetch(struct pt_regs *regs, unsigned long error_code, unsigned long addr)</span>
  * 6. T1   : reaches here, sees vma_pkey(vma)=5, when we really
  *	     faulted on a pte with its pkey=4.
  */
<span class="p_del">-static void fill_sig_info_pkey(int si_code, siginfo_t *info,</span>
<span class="p_del">-		struct vm_area_struct *vma)</span>
<span class="p_add">+static void fill_sig_info_pkey(int si_code, siginfo_t *info, u32 *pkey)</span>
 {
 	/* This is effectively an #ifdef */
 	if (!boot_cpu_has(X86_FEATURE_OSPKE))
<span class="p_chunk">@@ -208,7 +207,7 @@</span> <span class="p_context"> static void fill_sig_info_pkey(int si_code, siginfo_t *info,</span>
 	 * valid VMA, so we should never reach this without a
 	 * valid VMA.
 	 */
<span class="p_del">-	if (!vma) {</span>
<span class="p_add">+	if (!pkey) {</span>
 		WARN_ONCE(1, &quot;PKU fault with no VMA passed in&quot;);
 		info-&gt;si_pkey = 0;
 		return;
<span class="p_chunk">@@ -218,13 +217,12 @@</span> <span class="p_context"> static void fill_sig_info_pkey(int si_code, siginfo_t *info,</span>
 	 * absolutely guranteed to be 100% accurate because of
 	 * the race explained above.
 	 */
<span class="p_del">-	info-&gt;si_pkey = vma_pkey(vma);</span>
<span class="p_add">+	info-&gt;si_pkey = *pkey;</span>
 }
 
 static void
 force_sig_info_fault(int si_signo, int si_code, unsigned long address,
<span class="p_del">-		     struct task_struct *tsk, struct vm_area_struct *vma,</span>
<span class="p_del">-		     int fault)</span>
<span class="p_add">+		     struct task_struct *tsk, u32 *pkey, int fault)</span>
 {
 	unsigned lsb = 0;
 	siginfo_t info;
<span class="p_chunk">@@ -239,7 +237,7 @@</span> <span class="p_context"> force_sig_info_fault(int si_signo, int si_code, unsigned long address,</span>
 		lsb = PAGE_SHIFT;
 	info.si_addr_lsb = lsb;
 
<span class="p_del">-	fill_sig_info_pkey(si_code, &amp;info, vma);</span>
<span class="p_add">+	fill_sig_info_pkey(si_code, &amp;info, pkey);</span>
 
 	force_sig_info(si_signo, &amp;info, tsk);
 }
<span class="p_chunk">@@ -718,8 +716,6 @@</span> <span class="p_context"> no_context(struct pt_regs *regs, unsigned long error_code,</span>
 	struct task_struct *tsk = current;
 	unsigned long flags;
 	int sig;
<span class="p_del">-	/* No context means no VMA to pass down */</span>
<span class="p_del">-	struct vm_area_struct *vma = NULL;</span>
 
 	/* Are we prepared to handle this kernel fault? */
 	if (fixup_exception(regs, X86_TRAP_PF)) {
<span class="p_chunk">@@ -744,7 +740,7 @@</span> <span class="p_context"> no_context(struct pt_regs *regs, unsigned long error_code,</span>
 
 			/* XXX: hwpoison faults will set the wrong code. */
 			force_sig_info_fault(signal, si_code, address,
<span class="p_del">-					     tsk, vma, 0);</span>
<span class="p_add">+					     tsk, NULL, 0);</span>
 		}
 
 		/*
<span class="p_chunk">@@ -853,8 +849,7 @@</span> <span class="p_context"> show_signal_msg(struct pt_regs *regs, unsigned long error_code,</span>
 
 static void
 __bad_area_nosemaphore(struct pt_regs *regs, unsigned long error_code,
<span class="p_del">-		       unsigned long address, struct vm_area_struct *vma,</span>
<span class="p_del">-		       int si_code)</span>
<span class="p_add">+		       unsigned long address, u32 *pkey, int si_code)</span>
 {
 	struct task_struct *tsk = current;
 
<span class="p_chunk">@@ -902,7 +897,7 @@</span> <span class="p_context"> __bad_area_nosemaphore(struct pt_regs *regs, unsigned long error_code,</span>
 		tsk-&gt;thread.error_code	= error_code;
 		tsk-&gt;thread.trap_nr	= X86_TRAP_PF;
 
<span class="p_del">-		force_sig_info_fault(SIGSEGV, si_code, address, tsk, vma, 0);</span>
<span class="p_add">+		force_sig_info_fault(SIGSEGV, si_code, address, tsk, pkey, 0);</span>
 
 		return;
 	}
<span class="p_chunk">@@ -915,9 +910,9 @@</span> <span class="p_context"> __bad_area_nosemaphore(struct pt_regs *regs, unsigned long error_code,</span>
 
 static noinline void
 bad_area_nosemaphore(struct pt_regs *regs, unsigned long error_code,
<span class="p_del">-		     unsigned long address, struct vm_area_struct *vma)</span>
<span class="p_add">+		     unsigned long address, u32 *pkey)</span>
 {
<span class="p_del">-	__bad_area_nosemaphore(regs, error_code, address, vma, SEGV_MAPERR);</span>
<span class="p_add">+	__bad_area_nosemaphore(regs, error_code, address, pkey, SEGV_MAPERR);</span>
 }
 
 static void
<span class="p_chunk">@@ -925,6 +920,10 @@</span> <span class="p_context"> __bad_area(struct pt_regs *regs, unsigned long error_code,</span>
 	   unsigned long address,  struct vm_area_struct *vma, int si_code)
 {
 	struct mm_struct *mm = current-&gt;mm;
<span class="p_add">+	u32 pkey;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (vma)</span>
<span class="p_add">+		pkey = vma_pkey(vma);</span>
 
 	/*
 	 * Something tried to access memory that isn&#39;t in our memory map..
<span class="p_chunk">@@ -932,7 +931,8 @@</span> <span class="p_context"> __bad_area(struct pt_regs *regs, unsigned long error_code,</span>
 	 */
 	up_read(&amp;mm-&gt;mmap_sem);
 
<span class="p_del">-	__bad_area_nosemaphore(regs, error_code, address, vma, si_code);</span>
<span class="p_add">+	__bad_area_nosemaphore(regs, error_code, address,</span>
<span class="p_add">+			       (vma) ? &amp;pkey : NULL, si_code);</span>
 }
 
 static noinline void
<span class="p_chunk">@@ -975,7 +975,7 @@</span> <span class="p_context"> bad_area_access_error(struct pt_regs *regs, unsigned long error_code,</span>
 
 static void
 do_sigbus(struct pt_regs *regs, unsigned long error_code, unsigned long address,
<span class="p_del">-	  struct vm_area_struct *vma, unsigned int fault)</span>
<span class="p_add">+	  u32 *pkey, unsigned int fault)</span>
 {
 	struct task_struct *tsk = current;
 	int code = BUS_ADRERR;
<span class="p_chunk">@@ -1002,13 +1002,12 @@</span> <span class="p_context"> do_sigbus(struct pt_regs *regs, unsigned long error_code, unsigned long address,</span>
 		code = BUS_MCEERR_AR;
 	}
 #endif
<span class="p_del">-	force_sig_info_fault(SIGBUS, code, address, tsk, vma, fault);</span>
<span class="p_add">+	force_sig_info_fault(SIGBUS, code, address, tsk, pkey, fault);</span>
 }
 
 static noinline void
 mm_fault_error(struct pt_regs *regs, unsigned long error_code,
<span class="p_del">-	       unsigned long address, struct vm_area_struct *vma,</span>
<span class="p_del">-	       unsigned int fault)</span>
<span class="p_add">+	       unsigned long address, u32 *pkey, unsigned int fault)</span>
 {
 	if (fatal_signal_pending(current) &amp;&amp; !(error_code &amp; PF_USER)) {
 		no_context(regs, error_code, address, 0, 0);
<span class="p_chunk">@@ -1032,9 +1031,9 @@</span> <span class="p_context"> mm_fault_error(struct pt_regs *regs, unsigned long error_code,</span>
 	} else {
 		if (fault &amp; (VM_FAULT_SIGBUS|VM_FAULT_HWPOISON|
 			     VM_FAULT_HWPOISON_LARGE))
<span class="p_del">-			do_sigbus(regs, error_code, address, vma, fault);</span>
<span class="p_add">+			do_sigbus(regs, error_code, address, pkey, fault);</span>
 		else if (fault &amp; VM_FAULT_SIGSEGV)
<span class="p_del">-			bad_area_nosemaphore(regs, error_code, address, vma);</span>
<span class="p_add">+			bad_area_nosemaphore(regs, error_code, address, pkey);</span>
 		else
 			BUG();
 	}
<span class="p_chunk">@@ -1220,6 +1219,7 @@</span> <span class="p_context"> __do_page_fault(struct pt_regs *regs, unsigned long error_code,</span>
 	struct mm_struct *mm;
 	int fault, major = 0;
 	unsigned int flags = FAULT_FLAG_ALLOW_RETRY | FAULT_FLAG_KILLABLE;
<span class="p_add">+	u32 pkey;</span>
 
 	tsk = current;
 	mm = tsk-&gt;mm;
<span class="p_chunk">@@ -1420,9 +1420,10 @@</span> <span class="p_context"> __do_page_fault(struct pt_regs *regs, unsigned long error_code,</span>
 		return;
 	}
 
<span class="p_add">+	pkey = vma_pkey(vma);</span>
 	up_read(&amp;mm-&gt;mmap_sem);
 	if (unlikely(fault &amp; VM_FAULT_ERROR)) {
<span class="p_del">-		mm_fault_error(regs, error_code, address, vma, fault);</span>
<span class="p_add">+		mm_fault_error(regs, error_code, address, &amp;pkey, fault);</span>
 		return;
 	}
 
<span class="p_header">diff --git a/block/bsg-lib.c b/block/bsg-lib.c</span>
<span class="p_header">index 650f427d915b..341b8d858e67 100644</span>
<span class="p_header">--- a/block/bsg-lib.c</span>
<span class="p_header">+++ b/block/bsg-lib.c</span>
<span class="p_chunk">@@ -147,7 +147,6 @@</span> <span class="p_context"> static int bsg_create_job(struct device *dev, struct request *req)</span>
 failjob_rls_rqst_payload:
 	kfree(job-&gt;request_payload.sg_list);
 failjob_rls_job:
<span class="p_del">-	kfree(job);</span>
 	return -ENOMEM;
 }
 
<span class="p_header">diff --git a/crypto/drbg.c b/crypto/drbg.c</span>
<span class="p_header">index 8cac3d31a5f8..942ddff68408 100644</span>
<span class="p_header">--- a/crypto/drbg.c</span>
<span class="p_header">+++ b/crypto/drbg.c</span>
<span class="p_chunk">@@ -1133,10 +1133,10 @@</span> <span class="p_context"> static inline void drbg_dealloc_state(struct drbg_state *drbg)</span>
 {
 	if (!drbg)
 		return;
<span class="p_del">-	kzfree(drbg-&gt;V);</span>
<span class="p_del">-	drbg-&gt;Vbuf = NULL;</span>
<span class="p_del">-	kzfree(drbg-&gt;C);</span>
<span class="p_del">-	drbg-&gt;Cbuf = NULL;</span>
<span class="p_add">+	kzfree(drbg-&gt;Vbuf);</span>
<span class="p_add">+	drbg-&gt;V = NULL;</span>
<span class="p_add">+	kzfree(drbg-&gt;Cbuf);</span>
<span class="p_add">+	drbg-&gt;C = NULL;</span>
 	kzfree(drbg-&gt;scratchpadbuf);
 	drbg-&gt;scratchpadbuf = NULL;
 	drbg-&gt;reseed_ctr = 0;
<span class="p_header">diff --git a/drivers/base/power/main.c b/drivers/base/power/main.c</span>
<span class="p_header">index 2932a5bd892f..dfffba39f723 100644</span>
<span class="p_header">--- a/drivers/base/power/main.c</span>
<span class="p_header">+++ b/drivers/base/power/main.c</span>
<span class="p_chunk">@@ -1757,10 +1757,13 @@</span> <span class="p_context"> void device_pm_check_callbacks(struct device *dev)</span>
 {
 	spin_lock_irq(&amp;dev-&gt;power.lock);
 	dev-&gt;power.no_pm_callbacks =
<span class="p_del">-		(!dev-&gt;bus || pm_ops_is_empty(dev-&gt;bus-&gt;pm)) &amp;&amp;</span>
<span class="p_del">-		(!dev-&gt;class || pm_ops_is_empty(dev-&gt;class-&gt;pm)) &amp;&amp;</span>
<span class="p_add">+		(!dev-&gt;bus || (pm_ops_is_empty(dev-&gt;bus-&gt;pm) &amp;&amp;</span>
<span class="p_add">+		 !dev-&gt;bus-&gt;suspend &amp;&amp; !dev-&gt;bus-&gt;resume)) &amp;&amp;</span>
<span class="p_add">+		(!dev-&gt;class || (pm_ops_is_empty(dev-&gt;class-&gt;pm) &amp;&amp;</span>
<span class="p_add">+		 !dev-&gt;class-&gt;suspend &amp;&amp; !dev-&gt;class-&gt;resume)) &amp;&amp;</span>
 		(!dev-&gt;type || pm_ops_is_empty(dev-&gt;type-&gt;pm)) &amp;&amp;
 		(!dev-&gt;pm_domain || pm_ops_is_empty(&amp;dev-&gt;pm_domain-&gt;ops)) &amp;&amp;
<span class="p_del">-		(!dev-&gt;driver || pm_ops_is_empty(dev-&gt;driver-&gt;pm));</span>
<span class="p_add">+		(!dev-&gt;driver || (pm_ops_is_empty(dev-&gt;driver-&gt;pm) &amp;&amp;</span>
<span class="p_add">+		 !dev-&gt;driver-&gt;suspend &amp;&amp; !dev-&gt;driver-&gt;resume));</span>
 	spin_unlock_irq(&amp;dev-&gt;power.lock);
 }
<span class="p_header">diff --git a/drivers/crypto/talitos.c b/drivers/crypto/talitos.c</span>
<span class="p_header">index 571de2f284cf..e2d323fa2437 100644</span>
<span class="p_header">--- a/drivers/crypto/talitos.c</span>
<span class="p_header">+++ b/drivers/crypto/talitos.c</span>
<span class="p_chunk">@@ -1756,9 +1756,9 @@</span> <span class="p_context"> static int common_nonsnoop_hash(struct talitos_edesc *edesc,</span>
 		req_ctx-&gt;swinit = 0;
 	} else {
 		desc-&gt;ptr[1] = zero_entry;
<span class="p_del">-		/* Indicate next op is not the first. */</span>
<span class="p_del">-		req_ctx-&gt;first = 0;</span>
 	}
<span class="p_add">+	/* Indicate next op is not the first. */</span>
<span class="p_add">+	req_ctx-&gt;first = 0;</span>
 
 	/* HMAC key */
 	if (ctx-&gt;keylen)
<span class="p_chunk">@@ -1769,7 +1769,7 @@</span> <span class="p_context"> static int common_nonsnoop_hash(struct talitos_edesc *edesc,</span>
 
 	sg_count = edesc-&gt;src_nents ?: 1;
 	if (is_sec1 &amp;&amp; sg_count &gt; 1)
<span class="p_del">-		sg_copy_to_buffer(areq-&gt;src, sg_count, edesc-&gt;buf, length);</span>
<span class="p_add">+		sg_copy_to_buffer(req_ctx-&gt;psrc, sg_count, edesc-&gt;buf, length);</span>
 	else
 		sg_count = dma_map_sg(dev, req_ctx-&gt;psrc, sg_count,
 				      DMA_TO_DEVICE);
<span class="p_chunk">@@ -3057,7 +3057,8 @@</span> <span class="p_context"> static struct talitos_crypto_alg *talitos_alg_alloc(struct device *dev,</span>
 		t_alg-&gt;algt.alg.hash.final = ahash_final;
 		t_alg-&gt;algt.alg.hash.finup = ahash_finup;
 		t_alg-&gt;algt.alg.hash.digest = ahash_digest;
<span class="p_del">-		t_alg-&gt;algt.alg.hash.setkey = ahash_setkey;</span>
<span class="p_add">+		if (!strncmp(alg-&gt;cra_name, &quot;hmac&quot;, 4))</span>
<span class="p_add">+			t_alg-&gt;algt.alg.hash.setkey = ahash_setkey;</span>
 		t_alg-&gt;algt.alg.hash.import = ahash_import;
 		t_alg-&gt;algt.alg.hash.export = ahash_export;
 
<span class="p_header">diff --git a/drivers/gpu/drm/etnaviv/etnaviv_gem.c b/drivers/gpu/drm/etnaviv/etnaviv_gem.c</span>
<span class="p_header">index 0370b842d9cc..82dd57d4843c 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/etnaviv/etnaviv_gem.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/etnaviv/etnaviv_gem.c</span>
<span class="p_chunk">@@ -549,12 +549,15 @@</span> <span class="p_context"> static const struct etnaviv_gem_ops etnaviv_gem_shmem_ops = {</span>
 void etnaviv_gem_free_object(struct drm_gem_object *obj)
 {
 	struct etnaviv_gem_object *etnaviv_obj = to_etnaviv_bo(obj);
<span class="p_add">+	struct etnaviv_drm_private *priv = obj-&gt;dev-&gt;dev_private;</span>
 	struct etnaviv_vram_mapping *mapping, *tmp;
 
 	/* object should not be active */
 	WARN_ON(is_active(etnaviv_obj));
 
<span class="p_add">+	mutex_lock(&amp;priv-&gt;gem_lock);</span>
 	list_del(&amp;etnaviv_obj-&gt;gem_node);
<span class="p_add">+	mutex_unlock(&amp;priv-&gt;gem_lock);</span>
 
 	list_for_each_entry_safe(mapping, tmp, &amp;etnaviv_obj-&gt;vram_list,
 				 obj_node) {
<span class="p_header">diff --git a/drivers/gpu/drm/radeon/radeon_device.c b/drivers/gpu/drm/radeon/radeon_device.c</span>
<span class="p_header">index 3b21ca5a6c81..82b01123c386 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/radeon/radeon_device.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/radeon/radeon_device.c</span>
<span class="p_chunk">@@ -1674,7 +1674,7 @@</span> <span class="p_context"> int radeon_suspend_kms(struct drm_device *dev, bool suspend,</span>
 	radeon_agp_suspend(rdev);
 
 	pci_save_state(dev-&gt;pdev);
<span class="p_del">-	if (freeze &amp;&amp; rdev-&gt;family &gt;= CHIP_CEDAR) {</span>
<span class="p_add">+	if (freeze &amp;&amp; rdev-&gt;family &gt;= CHIP_CEDAR &amp;&amp; !(rdev-&gt;flags &amp; RADEON_IS_IGP)) {</span>
 		rdev-&gt;asic-&gt;asic_reset(rdev, true);
 		pci_restore_state(dev-&gt;pdev);
 	} else if (suspend) {
<span class="p_header">diff --git a/drivers/infiniband/hw/cxgb4/cm.c b/drivers/infiniband/hw/cxgb4/cm.c</span>
<span class="p_header">index 9398143d7c5e..6512a555f7f8 100644</span>
<span class="p_header">--- a/drivers/infiniband/hw/cxgb4/cm.c</span>
<span class="p_header">+++ b/drivers/infiniband/hw/cxgb4/cm.c</span>
<span class="p_chunk">@@ -2577,9 +2577,9 @@</span> <span class="p_context"> static int pass_accept_req(struct c4iw_dev *dev, struct sk_buff *skb)</span>
 	c4iw_put_ep(&amp;child_ep-&gt;com);
 reject:
 	reject_cr(dev, hwtid, skb);
<span class="p_add">+out:</span>
 	if (parent_ep)
 		c4iw_put_ep(&amp;parent_ep-&gt;com);
<span class="p_del">-out:</span>
 	return 0;
 }
 
<span class="p_chunk">@@ -3441,7 +3441,7 @@</span> <span class="p_context"> int c4iw_create_listen(struct iw_cm_id *cm_id, int backlog)</span>
 		cm_id-&gt;provider_data = ep;
 		goto out;
 	}
<span class="p_del">-</span>
<span class="p_add">+	remove_handle(ep-&gt;com.dev, &amp;ep-&gt;com.dev-&gt;stid_idr, ep-&gt;stid);</span>
 	cxgb4_free_stid(ep-&gt;com.dev-&gt;rdev.lldi.tids, ep-&gt;stid,
 			ep-&gt;com.local_addr.ss_family);
 fail2:
<span class="p_header">diff --git a/drivers/md/raid5.c b/drivers/md/raid5.c</span>
<span class="p_header">index 549b4afd12e1..7aea0221530c 100644</span>
<span class="p_header">--- a/drivers/md/raid5.c</span>
<span class="p_header">+++ b/drivers/md/raid5.c</span>
<span class="p_chunk">@@ -829,6 +829,14 @@</span> <span class="p_context"> static void stripe_add_to_batch_list(struct r5conf *conf, struct stripe_head *sh</span>
 			spin_unlock(&amp;head-&gt;batch_head-&gt;batch_lock);
 			goto unlock_out;
 		}
<span class="p_add">+		/*</span>
<span class="p_add">+		 * We must assign batch_head of this stripe within the</span>
<span class="p_add">+		 * batch_lock, otherwise clear_batch_ready of batch head</span>
<span class="p_add">+		 * stripe could clear BATCH_READY bit of this stripe and</span>
<span class="p_add">+		 * this stripe-&gt;batch_head doesn&#39;t get assigned, which</span>
<span class="p_add">+		 * could confuse clear_batch_ready for this stripe</span>
<span class="p_add">+		 */</span>
<span class="p_add">+		sh-&gt;batch_head = head-&gt;batch_head;</span>
 
 		/*
 		 * at this point, head&#39;s BATCH_READY could be cleared, but we
<span class="p_chunk">@@ -836,8 +844,6 @@</span> <span class="p_context"> static void stripe_add_to_batch_list(struct r5conf *conf, struct stripe_head *sh</span>
 		 */
 		list_add(&amp;sh-&gt;batch_list, &amp;head-&gt;batch_list);
 		spin_unlock(&amp;head-&gt;batch_head-&gt;batch_lock);
<span class="p_del">-</span>
<span class="p_del">-		sh-&gt;batch_head = head-&gt;batch_head;</span>
 	} else {
 		head-&gt;batch_head = head;
 		sh-&gt;batch_head = head-&gt;batch_head;
<span class="p_chunk">@@ -4277,7 +4283,8 @@</span> <span class="p_context"> static void break_stripe_batch_list(struct stripe_head *head_sh,</span>
 
 		set_mask_bits(&amp;sh-&gt;state, ~(STRIPE_EXPAND_SYNC_FLAGS |
 					    (1 &lt;&lt; STRIPE_PREREAD_ACTIVE) |
<span class="p_del">-					    (1 &lt;&lt; STRIPE_DEGRADED)),</span>
<span class="p_add">+					    (1 &lt;&lt; STRIPE_DEGRADED) |</span>
<span class="p_add">+					    (1 &lt;&lt; STRIPE_ON_UNPLUG_LIST)),</span>
 			      head_sh-&gt;state &amp; (1 &lt;&lt; STRIPE_INSYNC));
 
 		sh-&gt;check_state = head_sh-&gt;check_state;
<span class="p_header">diff --git a/drivers/misc/cxl/api.c b/drivers/misc/cxl/api.c</span>
<span class="p_header">index 2e5233b60971..ae856161faa9 100644</span>
<span class="p_header">--- a/drivers/misc/cxl/api.c</span>
<span class="p_header">+++ b/drivers/misc/cxl/api.c</span>
<span class="p_chunk">@@ -244,6 +244,10 @@</span> <span class="p_context"> int cxl_start_context(struct cxl_context *ctx, u64 wed,</span>
 		ctx-&gt;real_mode = false;
 	}
 
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Increment driver use count. Enables global TLBIs for hash</span>
<span class="p_add">+	 * and callbacks to handle the segment table</span>
<span class="p_add">+	 */</span>
 	cxl_ctx_get();
 
 	if ((rc = cxl_ops-&gt;attach_process(ctx, kernel, wed, 0))) {
<span class="p_header">diff --git a/drivers/misc/cxl/file.c b/drivers/misc/cxl/file.c</span>
<span class="p_header">index afa211397048..d3e009438991 100644</span>
<span class="p_header">--- a/drivers/misc/cxl/file.c</span>
<span class="p_header">+++ b/drivers/misc/cxl/file.c</span>
<span class="p_chunk">@@ -91,7 +91,6 @@</span> <span class="p_context"> static int __afu_open(struct inode *inode, struct file *file, bool master)</span>
 
 	pr_devel(&quot;afu_open pe: %i\n&quot;, ctx-&gt;pe);
 	file-&gt;private_data = ctx;
<span class="p_del">-	cxl_ctx_get();</span>
 
 	/* indicate success */
 	rc = 0;
<span class="p_chunk">@@ -213,6 +212,12 @@</span> <span class="p_context"> static long afu_ioctl_start_work(struct cxl_context *ctx,</span>
 	ctx-&gt;glpid = get_task_pid(current-&gt;group_leader, PIDTYPE_PID);
 
 
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Increment driver use count. Enables global TLBIs for hash</span>
<span class="p_add">+	 * and callbacks to handle the segment table</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	cxl_ctx_get();</span>
<span class="p_add">+</span>
 	trace_cxl_attach(ctx, work.work_element_descriptor, work.num_interrupts, amr);
 
 	if ((rc = cxl_ops-&gt;attach_process(ctx, false, work.work_element_descriptor,
<span class="p_chunk">@@ -222,6 +227,7 @@</span> <span class="p_context"> static long afu_ioctl_start_work(struct cxl_context *ctx,</span>
 		put_pid(ctx-&gt;glpid);
 		put_pid(ctx-&gt;pid);
 		ctx-&gt;glpid = ctx-&gt;pid = NULL;
<span class="p_add">+		cxl_ctx_put();</span>
 		goto out;
 	}
 
<span class="p_header">diff --git a/drivers/net/wireless/mac80211_hwsim.c b/drivers/net/wireless/mac80211_hwsim.c</span>
<span class="p_header">index 0fd7d7ed07ce..c06932c5ecdb 100644</span>
<span class="p_header">--- a/drivers/net/wireless/mac80211_hwsim.c</span>
<span class="p_header">+++ b/drivers/net/wireless/mac80211_hwsim.c</span>
<span class="p_chunk">@@ -1357,8 +1357,6 @@</span> <span class="p_context"> static void mac80211_hwsim_tx(struct ieee80211_hw *hw,</span>
 				       txi-&gt;control.rates,
 				       ARRAY_SIZE(txi-&gt;control.rates));
 
<span class="p_del">-	txi-&gt;rate_driver_data[0] = channel;</span>
<span class="p_del">-</span>
 	if (skb-&gt;len &gt;= 24 + 8 &amp;&amp;
 	    ieee80211_is_probe_resp(hdr-&gt;frame_control)) {
 		/* fake header transmission time */
<span class="p_header">diff --git a/drivers/pci/pci-sysfs.c b/drivers/pci/pci-sysfs.c</span>
<span class="p_header">index 1b0786555394..f9f4d1c18eb2 100644</span>
<span class="p_header">--- a/drivers/pci/pci-sysfs.c</span>
<span class="p_header">+++ b/drivers/pci/pci-sysfs.c</span>
<span class="p_chunk">@@ -527,7 +527,7 @@</span> <span class="p_context"> static ssize_t driver_override_store(struct device *dev,</span>
 				     const char *buf, size_t count)
 {
 	struct pci_dev *pdev = to_pci_dev(dev);
<span class="p_del">-	char *driver_override, *old = pdev-&gt;driver_override, *cp;</span>
<span class="p_add">+	char *driver_override, *old, *cp;</span>
 
 	/* We need to keep extra room for a newline */
 	if (count &gt;= (PAGE_SIZE - 1))
<span class="p_chunk">@@ -541,12 +541,15 @@</span> <span class="p_context"> static ssize_t driver_override_store(struct device *dev,</span>
 	if (cp)
 		*cp = &#39;\0&#39;;
 
<span class="p_add">+	device_lock(dev);</span>
<span class="p_add">+	old = pdev-&gt;driver_override;</span>
 	if (strlen(driver_override)) {
 		pdev-&gt;driver_override = driver_override;
 	} else {
 		kfree(driver_override);
 		pdev-&gt;driver_override = NULL;
 	}
<span class="p_add">+	device_unlock(dev);</span>
 
 	kfree(old);
 
<span class="p_chunk">@@ -557,8 +560,12 @@</span> <span class="p_context"> static ssize_t driver_override_show(struct device *dev,</span>
 				    struct device_attribute *attr, char *buf)
 {
 	struct pci_dev *pdev = to_pci_dev(dev);
<span class="p_add">+	ssize_t len;</span>
 
<span class="p_del">-	return snprintf(buf, PAGE_SIZE, &quot;%s\n&quot;, pdev-&gt;driver_override);</span>
<span class="p_add">+	device_lock(dev);</span>
<span class="p_add">+	len = snprintf(buf, PAGE_SIZE, &quot;%s\n&quot;, pdev-&gt;driver_override);</span>
<span class="p_add">+	device_unlock(dev);</span>
<span class="p_add">+	return len;</span>
 }
 static DEVICE_ATTR_RW(driver_override);
 
<span class="p_header">diff --git a/drivers/scsi/scsi_transport_iscsi.c b/drivers/scsi/scsi_transport_iscsi.c</span>
<span class="p_header">index 42bca619f854..c39551b32e94 100644</span>
<span class="p_header">--- a/drivers/scsi/scsi_transport_iscsi.c</span>
<span class="p_header">+++ b/drivers/scsi/scsi_transport_iscsi.c</span>
<span class="p_chunk">@@ -3696,7 +3696,7 @@</span> <span class="p_context"> iscsi_if_rx(struct sk_buff *skb)</span>
 		uint32_t group;
 
 		nlh = nlmsg_hdr(skb);
<span class="p_del">-		if (nlh-&gt;nlmsg_len &lt; sizeof(*nlh) ||</span>
<span class="p_add">+		if (nlh-&gt;nlmsg_len &lt; sizeof(*nlh) + sizeof(*ev) ||</span>
 		    skb-&gt;len &lt; nlh-&gt;nlmsg_len) {
 			break;
 		}
<span class="p_header">diff --git a/drivers/video/fbdev/aty/atyfb_base.c b/drivers/video/fbdev/aty/atyfb_base.c</span>
<span class="p_header">index 11026e726b68..81367cf0af77 100644</span>
<span class="p_header">--- a/drivers/video/fbdev/aty/atyfb_base.c</span>
<span class="p_header">+++ b/drivers/video/fbdev/aty/atyfb_base.c</span>
<span class="p_chunk">@@ -1861,7 +1861,7 @@</span> <span class="p_context"> static int atyfb_ioctl(struct fb_info *info, u_int cmd, u_long arg)</span>
 #if defined(DEBUG) &amp;&amp; defined(CONFIG_FB_ATY_CT)
 	case ATYIO_CLKR:
 		if (M64_HAS(INTEGRATED)) {
<span class="p_del">-			struct atyclk clk;</span>
<span class="p_add">+			struct atyclk clk = { 0 };</span>
 			union aty_pll *pll = &amp;par-&gt;pll;
 			u32 dsp_config = pll-&gt;ct.dsp_config;
 			u32 dsp_on_off = pll-&gt;ct.dsp_on_off;
<span class="p_header">diff --git a/drivers/xen/swiotlb-xen.c b/drivers/xen/swiotlb-xen.c</span>
<span class="p_header">index 679f79f68182..b68ced5a6331 100644</span>
<span class="p_header">--- a/drivers/xen/swiotlb-xen.c</span>
<span class="p_header">+++ b/drivers/xen/swiotlb-xen.c</span>
<span class="p_chunk">@@ -680,3 +680,22 @@</span> <span class="p_context"> xen_swiotlb_set_dma_mask(struct device *dev, u64 dma_mask)</span>
 	return 0;
 }
 EXPORT_SYMBOL_GPL(xen_swiotlb_set_dma_mask);
<span class="p_add">+</span>
<span class="p_add">+/*</span>
<span class="p_add">+ * Create userspace mapping for the DMA-coherent memory.</span>
<span class="p_add">+ * This function should be called with the pages from the current domain only,</span>
<span class="p_add">+ * passing pages mapped from other domains would lead to memory corruption.</span>
<span class="p_add">+ */</span>
<span class="p_add">+int</span>
<span class="p_add">+xen_swiotlb_dma_mmap(struct device *dev, struct vm_area_struct *vma,</span>
<span class="p_add">+		     void *cpu_addr, dma_addr_t dma_addr, size_t size,</span>
<span class="p_add">+		     unsigned long attrs)</span>
<span class="p_add">+{</span>
<span class="p_add">+#if defined(CONFIG_ARM) || defined(CONFIG_ARM64)</span>
<span class="p_add">+	if (__generic_dma_ops(dev)-&gt;mmap)</span>
<span class="p_add">+		return __generic_dma_ops(dev)-&gt;mmap(dev, vma, cpu_addr,</span>
<span class="p_add">+						    dma_addr, size, attrs);</span>
<span class="p_add">+#endif</span>
<span class="p_add">+	return dma_common_mmap(dev, vma, cpu_addr, dma_addr, size);</span>
<span class="p_add">+}</span>
<span class="p_add">+EXPORT_SYMBOL_GPL(xen_swiotlb_dma_mmap);</span>
<span class="p_header">diff --git a/fs/btrfs/ioctl.c b/fs/btrfs/ioctl.c</span>
<span class="p_header">index 1782804f6c26..0fe346c4bd28 100644</span>
<span class="p_header">--- a/fs/btrfs/ioctl.c</span>
<span class="p_header">+++ b/fs/btrfs/ioctl.c</span>
<span class="p_chunk">@@ -3052,7 +3052,7 @@</span> <span class="p_context"> static int btrfs_cmp_data_prepare(struct inode *src, u64 loff,</span>
 out:
 	if (ret)
 		btrfs_cmp_data_free(cmp);
<span class="p_del">-	return 0;</span>
<span class="p_add">+	return ret;</span>
 }
 
 static int btrfs_cmp_data(struct inode *src, u64 loff, struct inode *dst,
<span class="p_chunk">@@ -4082,6 +4082,10 @@</span> <span class="p_context"> static long btrfs_ioctl_default_subvol(struct file *file, void __user *argp)</span>
 		ret = PTR_ERR(new_root);
 		goto out;
 	}
<span class="p_add">+	if (!is_fstree(new_root-&gt;objectid)) {</span>
<span class="p_add">+		ret = -ENOENT;</span>
<span class="p_add">+		goto out;</span>
<span class="p_add">+	}</span>
 
 	path = btrfs_alloc_path();
 	if (!path) {
<span class="p_header">diff --git a/fs/btrfs/relocation.c b/fs/btrfs/relocation.c</span>
<span class="p_header">index 2cf5e142675e..04c61bcf62e5 100644</span>
<span class="p_header">--- a/fs/btrfs/relocation.c</span>
<span class="p_header">+++ b/fs/btrfs/relocation.c</span>
<span class="p_chunk">@@ -2367,11 +2367,11 @@</span> <span class="p_context"> void free_reloc_roots(struct list_head *list)</span>
 	while (!list_empty(list)) {
 		reloc_root = list_entry(list-&gt;next, struct btrfs_root,
 					root_list);
<span class="p_add">+		__del_reloc_root(reloc_root);</span>
 		free_extent_buffer(reloc_root-&gt;node);
 		free_extent_buffer(reloc_root-&gt;commit_root);
 		reloc_root-&gt;node = NULL;
 		reloc_root-&gt;commit_root = NULL;
<span class="p_del">-		__del_reloc_root(reloc_root);</span>
 	}
 }
 
<span class="p_header">diff --git a/fs/cifs/cifsfs.c b/fs/cifs/cifsfs.c</span>
<span class="p_header">index c0c253005b76..87658f63b374 100644</span>
<span class="p_header">--- a/fs/cifs/cifsfs.c</span>
<span class="p_header">+++ b/fs/cifs/cifsfs.c</span>
<span class="p_chunk">@@ -1360,7 +1360,7 @@</span> <span class="p_context"> exit_cifs(void)</span>
 	exit_cifs_idmap();
 #endif
 #ifdef CONFIG_CIFS_UPCALL
<span class="p_del">-	unregister_key_type(&amp;cifs_spnego_key_type);</span>
<span class="p_add">+	exit_cifs_spnego();</span>
 #endif
 	cifs_destroy_request_bufs();
 	cifs_destroy_mids();
<span class="p_header">diff --git a/fs/cifs/connect.c b/fs/cifs/connect.c</span>
<span class="p_header">index 1a545695f547..f6712b6128d8 100644</span>
<span class="p_header">--- a/fs/cifs/connect.c</span>
<span class="p_header">+++ b/fs/cifs/connect.c</span>
<span class="p_chunk">@@ -4071,6 +4071,14 @@</span> <span class="p_context"> cifs_setup_session(const unsigned int xid, struct cifs_ses *ses,</span>
 	cifs_dbg(FYI, &quot;Security Mode: 0x%x Capabilities: 0x%x TimeAdjust: %d\n&quot;,
 		 server-&gt;sec_mode, server-&gt;capabilities, server-&gt;timeAdj);
 
<span class="p_add">+	if (ses-&gt;auth_key.response) {</span>
<span class="p_add">+		cifs_dbg(VFS, &quot;Free previous auth_key.response = %p\n&quot;,</span>
<span class="p_add">+			 ses-&gt;auth_key.response);</span>
<span class="p_add">+		kfree(ses-&gt;auth_key.response);</span>
<span class="p_add">+		ses-&gt;auth_key.response = NULL;</span>
<span class="p_add">+		ses-&gt;auth_key.len = 0;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
 	if (server-&gt;ops-&gt;sess_setup)
 		rc = server-&gt;ops-&gt;sess_setup(xid, ses, nls_info);
 
<span class="p_header">diff --git a/fs/cifs/file.c b/fs/cifs/file.c</span>
<span class="p_header">index 3925758f6dde..cf192f9ce254 100644</span>
<span class="p_header">--- a/fs/cifs/file.c</span>
<span class="p_header">+++ b/fs/cifs/file.c</span>
<span class="p_chunk">@@ -224,6 +224,13 @@</span> <span class="p_context"> cifs_nt_open(char *full_path, struct inode *inode, struct cifs_sb_info *cifs_sb,</span>
 	if (backup_cred(cifs_sb))
 		create_options |= CREATE_OPEN_BACKUP_INTENT;
 
<span class="p_add">+	/* O_SYNC also has bit for O_DSYNC so following check picks up either */</span>
<span class="p_add">+	if (f_flags &amp; O_SYNC)</span>
<span class="p_add">+		create_options |= CREATE_WRITE_THROUGH;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (f_flags &amp; O_DIRECT)</span>
<span class="p_add">+		create_options |= CREATE_NO_BUFFER;</span>
<span class="p_add">+</span>
 	oparms.tcon = tcon;
 	oparms.cifs_sb = cifs_sb;
 	oparms.desired_access = desired_access;
<span class="p_header">diff --git a/fs/cifs/smb2pdu.c b/fs/cifs/smb2pdu.c</span>
<span class="p_header">index 0437e5fdba56..69b610ad3fdc 100644</span>
<span class="p_header">--- a/fs/cifs/smb2pdu.c</span>
<span class="p_header">+++ b/fs/cifs/smb2pdu.c</span>
<span class="p_chunk">@@ -366,7 +366,7 @@</span> <span class="p_context"> assemble_neg_contexts(struct smb2_negotiate_req *req)</span>
 	build_encrypt_ctxt((struct smb2_encryption_neg_context *)pneg_ctxt);
 	req-&gt;NegotiateContextOffset = cpu_to_le32(OFFSET_OF_NEG_CONTEXT);
 	req-&gt;NegotiateContextCount = cpu_to_le16(2);
<span class="p_del">-	inc_rfc1001_len(req, 4 + sizeof(struct smb2_preauth_neg_context) + 2</span>
<span class="p_add">+	inc_rfc1001_len(req, 4 + sizeof(struct smb2_preauth_neg_context)</span>
 			+ sizeof(struct smb2_encryption_neg_context)); /* calculate hash */
 }
 #else
<span class="p_chunk">@@ -531,15 +531,22 @@</span> <span class="p_context"> int smb3_validate_negotiate(const unsigned int xid, struct cifs_tcon *tcon)</span>
 
 	/*
 	 * validation ioctl must be signed, so no point sending this if we
<span class="p_del">-	 * can not sign it.  We could eventually change this to selectively</span>
<span class="p_add">+	 * can not sign it (ie are not known user).  Even if signing is not</span>
<span class="p_add">+	 * required (enabled but not negotiated), in those cases we selectively</span>
 	 * sign just this, the first and only signed request on a connection.
<span class="p_del">-	 * This is good enough for now since a user who wants better security</span>
<span class="p_del">-	 * would also enable signing on the mount. Having validation of</span>
<span class="p_del">-	 * negotiate info for signed connections helps reduce attack vectors</span>
<span class="p_add">+	 * Having validation of negotiate info  helps reduce attack vectors.</span>
 	 */
<span class="p_del">-	if (tcon-&gt;ses-&gt;server-&gt;sign == false)</span>
<span class="p_add">+	if (tcon-&gt;ses-&gt;session_flags &amp; SMB2_SESSION_FLAG_IS_GUEST)</span>
 		return 0; /* validation requires signing */
 
<span class="p_add">+	if (tcon-&gt;ses-&gt;user_name == NULL) {</span>
<span class="p_add">+		cifs_dbg(FYI, &quot;Can&#39;t validate negotiate: null user mount\n&quot;);</span>
<span class="p_add">+		return 0; /* validation requires signing */</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	if (tcon-&gt;ses-&gt;session_flags &amp; SMB2_SESSION_FLAG_IS_NULL)</span>
<span class="p_add">+		cifs_dbg(VFS, &quot;Unexpected null user (anonymous) auth flag sent by server\n&quot;);</span>
<span class="p_add">+</span>
 	vneg_inbuf.Capabilities =
 			cpu_to_le32(tcon-&gt;ses-&gt;server-&gt;vals-&gt;req_capabilities);
 	memcpy(vneg_inbuf.Guid, tcon-&gt;ses-&gt;server-&gt;client_guid,
<span class="p_chunk">@@ -1010,6 +1017,8 @@</span> <span class="p_context"> SMB2_sess_setup(const unsigned int xid, struct cifs_ses *ses,</span>
 	while (sess_data-&gt;func)
 		sess_data-&gt;func(sess_data);
 
<span class="p_add">+	if ((ses-&gt;session_flags &amp; SMB2_SESSION_FLAG_IS_GUEST) &amp;&amp; (ses-&gt;sign))</span>
<span class="p_add">+		cifs_dbg(VFS, &quot;signing requested but authenticated as guest\n&quot;);</span>
 	rc = sess_data-&gt;result;
 out:
 	kfree(sess_data);
<span class="p_header">diff --git a/fs/gfs2/glock.c b/fs/gfs2/glock.c</span>
<span class="p_header">index 7bff6f46f5da..f7cae1629c6c 100644</span>
<span class="p_header">--- a/fs/gfs2/glock.c</span>
<span class="p_header">+++ b/fs/gfs2/glock.c</span>
<span class="p_chunk">@@ -1836,13 +1836,9 @@</span> <span class="p_context"> static void *gfs2_glock_seq_start(struct seq_file *seq, loff_t *pos)</span>
 {
 	struct gfs2_glock_iter *gi = seq-&gt;private;
 	loff_t n = *pos;
<span class="p_del">-	int ret;</span>
<span class="p_del">-</span>
<span class="p_del">-	if (gi-&gt;last_pos &lt;= *pos)</span>
<span class="p_del">-		n = (*pos - gi-&gt;last_pos);</span>
 
<span class="p_del">-	ret = rhashtable_walk_start(&amp;gi-&gt;hti);</span>
<span class="p_del">-	if (ret)</span>
<span class="p_add">+	rhashtable_walk_enter(&amp;gl_hash_table, &amp;gi-&gt;hti);</span>
<span class="p_add">+	if (rhashtable_walk_start(&amp;gi-&gt;hti) != 0)</span>
 		return NULL;
 
 	do {
<span class="p_chunk">@@ -1850,6 +1846,7 @@</span> <span class="p_context"> static void *gfs2_glock_seq_start(struct seq_file *seq, loff_t *pos)</span>
 	} while (gi-&gt;gl &amp;&amp; n--);
 
 	gi-&gt;last_pos = *pos;
<span class="p_add">+</span>
 	return gi-&gt;gl;
 }
 
<span class="p_chunk">@@ -1861,6 +1858,7 @@</span> <span class="p_context"> static void *gfs2_glock_seq_next(struct seq_file *seq, void *iter_ptr,</span>
 	(*pos)++;
 	gi-&gt;last_pos = *pos;
 	gfs2_glock_iter_next(gi);
<span class="p_add">+</span>
 	return gi-&gt;gl;
 }
 
<span class="p_chunk">@@ -1870,6 +1868,7 @@</span> <span class="p_context"> static void gfs2_glock_seq_stop(struct seq_file *seq, void *iter_ptr)</span>
 
 	gi-&gt;gl = NULL;
 	rhashtable_walk_stop(&amp;gi-&gt;hti);
<span class="p_add">+	rhashtable_walk_exit(&amp;gi-&gt;hti);</span>
 }
 
 static int gfs2_glock_seq_show(struct seq_file *seq, void *iter_ptr)
<span class="p_chunk">@@ -1932,12 +1931,10 @@</span> <span class="p_context"> static int gfs2_glocks_open(struct inode *inode, struct file *file)</span>
 		struct gfs2_glock_iter *gi = seq-&gt;private;
 
 		gi-&gt;sdp = inode-&gt;i_private;
<span class="p_del">-		gi-&gt;last_pos = 0;</span>
 		seq-&gt;buf = kmalloc(GFS2_SEQ_GOODSIZE, GFP_KERNEL | __GFP_NOWARN);
 		if (seq-&gt;buf)
 			seq-&gt;size = GFS2_SEQ_GOODSIZE;
 		gi-&gt;gl = NULL;
<span class="p_del">-		ret = rhashtable_walk_init(&amp;gl_hash_table, &amp;gi-&gt;hti, GFP_KERNEL);</span>
 	}
 	return ret;
 }
<span class="p_chunk">@@ -1948,7 +1945,6 @@</span> <span class="p_context"> static int gfs2_glocks_release(struct inode *inode, struct file *file)</span>
 	struct gfs2_glock_iter *gi = seq-&gt;private;
 
 	gi-&gt;gl = NULL;
<span class="p_del">-	rhashtable_walk_exit(&amp;gi-&gt;hti);</span>
 	return seq_release_private(inode, file);
 }
 
<span class="p_chunk">@@ -1960,12 +1956,10 @@</span> <span class="p_context"> static int gfs2_glstats_open(struct inode *inode, struct file *file)</span>
 		struct seq_file *seq = file-&gt;private_data;
 		struct gfs2_glock_iter *gi = seq-&gt;private;
 		gi-&gt;sdp = inode-&gt;i_private;
<span class="p_del">-		gi-&gt;last_pos = 0;</span>
 		seq-&gt;buf = kmalloc(GFS2_SEQ_GOODSIZE, GFP_KERNEL | __GFP_NOWARN);
 		if (seq-&gt;buf)
 			seq-&gt;size = GFS2_SEQ_GOODSIZE;
 		gi-&gt;gl = NULL;
<span class="p_del">-		ret = rhashtable_walk_init(&amp;gl_hash_table, &amp;gi-&gt;hti, GFP_KERNEL);</span>
 	}
 	return ret;
 }
<span class="p_header">diff --git a/fs/proc/array.c b/fs/proc/array.c</span>
<span class="p_header">index 81818adb8e9e..c932ec454625 100644</span>
<span class="p_header">--- a/fs/proc/array.c</span>
<span class="p_header">+++ b/fs/proc/array.c</span>
<span class="p_chunk">@@ -60,6 +60,7 @@</span> <span class="p_context"></span>
 #include &lt;linux/tty.h&gt;
 #include &lt;linux/string.h&gt;
 #include &lt;linux/mman.h&gt;
<span class="p_add">+#include &lt;linux/sched.h&gt;</span>
 #include &lt;linux/proc_fs.h&gt;
 #include &lt;linux/ioport.h&gt;
 #include &lt;linux/uaccess.h&gt;
<span class="p_chunk">@@ -416,7 +417,15 @@</span> <span class="p_context"> static int do_task_stat(struct seq_file *m, struct pid_namespace *ns,</span>
 		 * esp and eip are intentionally zeroed out.  There is no
 		 * non-racy way to read them without freezing the task.
 		 * Programs that need reliable values can use ptrace(2).
<span class="p_add">+		 *</span>
<span class="p_add">+		 * The only exception is if the task is core dumping because</span>
<span class="p_add">+		 * a program is not able to use ptrace(2) in that case. It is</span>
<span class="p_add">+		 * safe because the task has stopped executing permanently.</span>
 		 */
<span class="p_add">+		if (permitted &amp;&amp; (task-&gt;flags &amp; PF_DUMPCORE)) {</span>
<span class="p_add">+			eip = KSTK_EIP(task);</span>
<span class="p_add">+			esp = KSTK_ESP(task);</span>
<span class="p_add">+		}</span>
 	}
 
 	get_task_comm(tcomm, task);
<span class="p_header">diff --git a/fs/read_write.c b/fs/read_write.c</span>
<span class="p_header">index e479e24dcd4c..09a8757efd34 100644</span>
<span class="p_header">--- a/fs/read_write.c</span>
<span class="p_header">+++ b/fs/read_write.c</span>
<span class="p_chunk">@@ -114,7 +114,7 @@</span> <span class="p_context"> generic_file_llseek_size(struct file *file, loff_t offset, int whence,</span>
 		 * In the generic case the entire file is data, so as long as
 		 * offset isn&#39;t at the end of the file then the offset is data.
 		 */
<span class="p_del">-		if (offset &gt;= eof)</span>
<span class="p_add">+		if ((unsigned long long)offset &gt;= eof)</span>
 			return -ENXIO;
 		break;
 	case SEEK_HOLE:
<span class="p_chunk">@@ -122,7 +122,7 @@</span> <span class="p_context"> generic_file_llseek_size(struct file *file, loff_t offset, int whence,</span>
 		 * There is a virtual hole at the end of the file, so as long as
 		 * offset isn&#39;t i_size or larger, return i_size.
 		 */
<span class="p_del">-		if (offset &gt;= eof)</span>
<span class="p_add">+		if ((unsigned long long)offset &gt;= eof)</span>
 			return -ENXIO;
 		offset = eof;
 		break;
<span class="p_header">diff --git a/fs/xfs/xfs_ioctl.c b/fs/xfs/xfs_ioctl.c</span>
<span class="p_header">index bce2e260f55e..6c95812120eb 100644</span>
<span class="p_header">--- a/fs/xfs/xfs_ioctl.c</span>
<span class="p_header">+++ b/fs/xfs/xfs_ioctl.c</span>
<span class="p_chunk">@@ -1085,6 +1085,7 @@</span> <span class="p_context"> xfs_ioctl_setattr_dax_invalidate(</span>
 	int			*join_flags)
 {
 	struct inode		*inode = VFS_I(ip);
<span class="p_add">+	struct super_block	*sb = inode-&gt;i_sb;</span>
 	int			error;
 
 	*join_flags = 0;
<span class="p_chunk">@@ -1097,7 +1098,7 @@</span> <span class="p_context"> xfs_ioctl_setattr_dax_invalidate(</span>
 	if (fa-&gt;fsx_xflags &amp; FS_XFLAG_DAX) {
 		if (!(S_ISREG(inode-&gt;i_mode) || S_ISDIR(inode-&gt;i_mode)))
 			return -EINVAL;
<span class="p_del">-		if (ip-&gt;i_mount-&gt;m_sb.sb_blocksize != PAGE_SIZE)</span>
<span class="p_add">+		if (bdev_dax_supported(sb, sb-&gt;s_blocksize) &lt; 0)</span>
 			return -EINVAL;
 	}
 
<span class="p_header">diff --git a/include/linux/key.h b/include/linux/key.h</span>
<span class="p_header">index 722914798f37..6a544726903e 100644</span>
<span class="p_header">--- a/include/linux/key.h</span>
<span class="p_header">+++ b/include/linux/key.h</span>
<span class="p_chunk">@@ -176,6 +176,7 @@</span> <span class="p_context"> struct key {</span>
 #define KEY_FLAG_BUILTIN	8	/* set if key is built in to the kernel */
 #define KEY_FLAG_ROOT_CAN_INVAL	9	/* set if key can be invalidated by root without permission */
 #define KEY_FLAG_KEEP		10	/* set if key should not be removed */
<span class="p_add">+#define KEY_FLAG_UID_KEYRING	11	/* set if key is a user or user session keyring */</span>
 
 	/* the key type and key description string
 	 * - the desc is used to match a key against search criteria
<span class="p_chunk">@@ -235,6 +236,7 @@</span> <span class="p_context"> extern struct key *key_alloc(struct key_type *type,</span>
 #define KEY_ALLOC_NOT_IN_QUOTA		0x0002	/* not in quota */
 #define KEY_ALLOC_BUILT_IN		0x0004	/* Key is built into kernel */
 #define KEY_ALLOC_BYPASS_RESTRICTION	0x0008	/* Override the check on restricted keyrings */
<span class="p_add">+#define KEY_ALLOC_UID_KEYRING		0x0010	/* allocating a user or user session keyring */</span>
 
 extern void key_revoke(struct key *key);
 extern void key_invalidate(struct key *key);
<span class="p_header">diff --git a/include/net/mac80211.h b/include/net/mac80211.h</span>
<span class="p_header">index e2dba93e374f..2c7d876e2a1a 100644</span>
<span class="p_header">--- a/include/net/mac80211.h</span>
<span class="p_header">+++ b/include/net/mac80211.h</span>
<span class="p_chunk">@@ -902,21 +902,10 @@</span> <span class="p_context"> struct ieee80211_tx_info {</span>
 				unsigned long jiffies;
 			};
 			/* NB: vif can be NULL for injected frames */
<span class="p_del">-			union {</span>
<span class="p_del">-				/* NB: vif can be NULL for injected frames */</span>
<span class="p_del">-				struct ieee80211_vif *vif;</span>
<span class="p_del">-</span>
<span class="p_del">-				/* When packets are enqueued on txq it&#39;s easy</span>
<span class="p_del">-				 * to re-construct the vif pointer. There&#39;s no</span>
<span class="p_del">-				 * more space in tx_info so it can be used to</span>
<span class="p_del">-				 * store the necessary enqueue time for packet</span>
<span class="p_del">-				 * sojourn time computation.</span>
<span class="p_del">-				 */</span>
<span class="p_del">-				codel_time_t enqueue_time;</span>
<span class="p_del">-			};</span>
<span class="p_add">+			struct ieee80211_vif *vif;</span>
 			struct ieee80211_key_conf *hw_key;
 			u32 flags;
<span class="p_del">-			/* 4 bytes free */</span>
<span class="p_add">+			codel_time_t enqueue_time;</span>
 		} control;
 		struct {
 			u64 cookie;
<span class="p_header">diff --git a/include/xen/swiotlb-xen.h b/include/xen/swiotlb-xen.h</span>
<span class="p_header">index 7c35e279d1e3..683057f79dca 100644</span>
<span class="p_header">--- a/include/xen/swiotlb-xen.h</span>
<span class="p_header">+++ b/include/xen/swiotlb-xen.h</span>
<span class="p_chunk">@@ -58,4 +58,9 @@</span> <span class="p_context"> xen_swiotlb_dma_supported(struct device *hwdev, u64 mask);</span>
 
 extern int
 xen_swiotlb_set_dma_mask(struct device *dev, u64 dma_mask);
<span class="p_add">+</span>
<span class="p_add">+extern int</span>
<span class="p_add">+xen_swiotlb_dma_mmap(struct device *dev, struct vm_area_struct *vma,</span>
<span class="p_add">+		     void *cpu_addr, dma_addr_t dma_addr, size_t size,</span>
<span class="p_add">+		     unsigned long attrs);</span>
 #endif /* __LINUX_SWIOTLB_XEN_H */
<span class="p_header">diff --git a/kernel/irq/irqdesc.c b/kernel/irq/irqdesc.c</span>
<span class="p_header">index 00bb0aeea1d0..77977f55dff7 100644</span>
<span class="p_header">--- a/kernel/irq/irqdesc.c</span>
<span class="p_header">+++ b/kernel/irq/irqdesc.c</span>
<span class="p_chunk">@@ -405,10 +405,8 @@</span> <span class="p_context"> static void free_desc(unsigned int irq)</span>
 	 * The sysfs entry must be serialized against a concurrent
 	 * irq_sysfs_init() as well.
 	 */
<span class="p_del">-	mutex_lock(&amp;sparse_irq_lock);</span>
 	kobject_del(&amp;desc-&gt;kobj);
 	delete_irq_desc(irq);
<span class="p_del">-	mutex_unlock(&amp;sparse_irq_lock);</span>
 
 	/*
 	 * We free the descriptor, masks and stat fields via RCU. That
<span class="p_chunk">@@ -446,20 +444,15 @@</span> <span class="p_context"> static int alloc_descs(unsigned int start, unsigned int cnt, int node,</span>
 		desc = alloc_desc(start + i, node, flags, mask, owner);
 		if (!desc)
 			goto err;
<span class="p_del">-		mutex_lock(&amp;sparse_irq_lock);</span>
 		irq_insert_desc(start + i, desc);
 		irq_sysfs_add(start + i, desc);
<span class="p_del">-		mutex_unlock(&amp;sparse_irq_lock);</span>
 	}
<span class="p_add">+	bitmap_set(allocated_irqs, start, cnt);</span>
 	return start;
 
 err:
 	for (i--; i &gt;= 0; i--)
 		free_desc(start + i);
<span class="p_del">-</span>
<span class="p_del">-	mutex_lock(&amp;sparse_irq_lock);</span>
<span class="p_del">-	bitmap_clear(allocated_irqs, start, cnt);</span>
<span class="p_del">-	mutex_unlock(&amp;sparse_irq_lock);</span>
 	return -ENOMEM;
 }
 
<span class="p_chunk">@@ -558,6 +551,7 @@</span> <span class="p_context"> static inline int alloc_descs(unsigned int start, unsigned int cnt, int node,</span>
 
 		desc-&gt;owner = owner;
 	}
<span class="p_add">+	bitmap_set(allocated_irqs, start, cnt);</span>
 	return start;
 }
 
<span class="p_chunk">@@ -653,10 +647,10 @@</span> <span class="p_context"> void irq_free_descs(unsigned int from, unsigned int cnt)</span>
 	if (from &gt;= nr_irqs || (from + cnt) &gt; nr_irqs)
 		return;
 
<span class="p_add">+	mutex_lock(&amp;sparse_irq_lock);</span>
 	for (i = 0; i &lt; cnt; i++)
 		free_desc(from + i);
 
<span class="p_del">-	mutex_lock(&amp;sparse_irq_lock);</span>
 	bitmap_clear(allocated_irqs, from, cnt);
 	mutex_unlock(&amp;sparse_irq_lock);
 }
<span class="p_chunk">@@ -703,19 +697,15 @@</span> <span class="p_context"> __irq_alloc_descs(int irq, unsigned int from, unsigned int cnt, int node,</span>
 					   from, cnt, 0);
 	ret = -EEXIST;
 	if (irq &gt;=0 &amp;&amp; start != irq)
<span class="p_del">-		goto err;</span>
<span class="p_add">+		goto unlock;</span>
 
 	if (start + cnt &gt; nr_irqs) {
 		ret = irq_expand_nr_irqs(start + cnt);
 		if (ret)
<span class="p_del">-			goto err;</span>
<span class="p_add">+			goto unlock;</span>
 	}
<span class="p_del">-</span>
<span class="p_del">-	bitmap_set(allocated_irqs, start, cnt);</span>
<span class="p_del">-	mutex_unlock(&amp;sparse_irq_lock);</span>
<span class="p_del">-	return alloc_descs(start, cnt, node, affinity, owner);</span>
<span class="p_del">-</span>
<span class="p_del">-err:</span>
<span class="p_add">+	ret = alloc_descs(start, cnt, node, affinity, owner);</span>
<span class="p_add">+unlock:</span>
 	mutex_unlock(&amp;sparse_irq_lock);
 	return ret;
 }
<span class="p_header">diff --git a/kernel/seccomp.c b/kernel/seccomp.c</span>
<span class="p_header">index 0db7c8a2afe2..af182a6df25b 100644</span>
<span class="p_header">--- a/kernel/seccomp.c</span>
<span class="p_header">+++ b/kernel/seccomp.c</span>
<span class="p_chunk">@@ -457,14 +457,19 @@</span> <span class="p_context"> static long seccomp_attach_filter(unsigned int flags,</span>
 	return 0;
 }
 
<span class="p_add">+void __get_seccomp_filter(struct seccomp_filter *filter)</span>
<span class="p_add">+{</span>
<span class="p_add">+	/* Reference count is bounded by the number of total processes. */</span>
<span class="p_add">+	atomic_inc(&amp;filter-&gt;usage);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 /* get_seccomp_filter - increments the reference count of the filter on @tsk */
 void get_seccomp_filter(struct task_struct *tsk)
 {
 	struct seccomp_filter *orig = tsk-&gt;seccomp.filter;
 	if (!orig)
 		return;
<span class="p_del">-	/* Reference count is bounded by the number of total processes. */</span>
<span class="p_del">-	atomic_inc(&amp;orig-&gt;usage);</span>
<span class="p_add">+	__get_seccomp_filter(orig);</span>
 }
 
 static inline void seccomp_filter_free(struct seccomp_filter *filter)
<span class="p_chunk">@@ -475,10 +480,8 @@</span> <span class="p_context"> static inline void seccomp_filter_free(struct seccomp_filter *filter)</span>
 	}
 }
 
<span class="p_del">-/* put_seccomp_filter - decrements the ref count of tsk-&gt;seccomp.filter */</span>
<span class="p_del">-void put_seccomp_filter(struct task_struct *tsk)</span>
<span class="p_add">+static void __put_seccomp_filter(struct seccomp_filter *orig)</span>
 {
<span class="p_del">-	struct seccomp_filter *orig = tsk-&gt;seccomp.filter;</span>
 	/* Clean up single-reference branches iteratively. */
 	while (orig &amp;&amp; atomic_dec_and_test(&amp;orig-&gt;usage)) {
 		struct seccomp_filter *freeme = orig;
<span class="p_chunk">@@ -487,6 +490,12 @@</span> <span class="p_context"> void put_seccomp_filter(struct task_struct *tsk)</span>
 	}
 }
 
<span class="p_add">+/* put_seccomp_filter - decrements the ref count of tsk-&gt;seccomp.filter */</span>
<span class="p_add">+void put_seccomp_filter(struct task_struct *tsk)</span>
<span class="p_add">+{</span>
<span class="p_add">+	__put_seccomp_filter(tsk-&gt;seccomp.filter);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 /**
  * seccomp_send_sigsys - signals the task to allow in-process syscall emulation
  * @syscall: syscall number to send to userland
<span class="p_chunk">@@ -892,13 +901,13 @@</span> <span class="p_context"> long seccomp_get_filter(struct task_struct *task, unsigned long filter_off,</span>
 	if (!data)
 		goto out;
 
<span class="p_del">-	get_seccomp_filter(task);</span>
<span class="p_add">+	__get_seccomp_filter(filter);</span>
 	spin_unlock_irq(&amp;task-&gt;sighand-&gt;siglock);
 
 	if (copy_to_user(data, fprog-&gt;filter, bpf_classic_proglen(fprog)))
 		ret = -EFAULT;
 
<span class="p_del">-	put_seccomp_filter(task);</span>
<span class="p_add">+	__put_seccomp_filter(filter);</span>
 	return ret;
 
 out:
<span class="p_header">diff --git a/kernel/sysctl.c b/kernel/sysctl.c</span>
<span class="p_header">index 265e0d0216e3..24d603d29512 100644</span>
<span class="p_header">--- a/kernel/sysctl.c</span>
<span class="p_header">+++ b/kernel/sysctl.c</span>
<span class="p_chunk">@@ -1189,6 +1189,8 @@</span> <span class="p_context"> static struct ctl_table kern_table[] = {</span>
 		.maxlen		= sizeof(unsigned int),
 		.mode		= 0644,
 		.proc_handler	= timer_migration_handler,
<span class="p_add">+		.extra1		= &amp;zero,</span>
<span class="p_add">+		.extra2		= &amp;one,</span>
 	},
 #endif
 #ifdef CONFIG_BPF_SYSCALL
<span class="p_header">diff --git a/kernel/time/timer.c b/kernel/time/timer.c</span>
<span class="p_header">index df445cde8a1e..7d670362891a 100644</span>
<span class="p_header">--- a/kernel/time/timer.c</span>
<span class="p_header">+++ b/kernel/time/timer.c</span>
<span class="p_chunk">@@ -240,7 +240,7 @@</span> <span class="p_context"> int timer_migration_handler(struct ctl_table *table, int write,</span>
 	int ret;
 
 	mutex_lock(&amp;mutex);
<span class="p_del">-	ret = proc_dointvec(table, write, buffer, lenp, ppos);</span>
<span class="p_add">+	ret = proc_dointvec_minmax(table, write, buffer, lenp, ppos);</span>
 	if (!ret &amp;&amp; write)
 		timers_update_migration(false);
 	mutex_unlock(&amp;mutex);
<span class="p_header">diff --git a/kernel/trace/trace.c b/kernel/trace/trace.c</span>
<span class="p_header">index f95bf81529f5..c1e50cc0d7b0 100644</span>
<span class="p_header">--- a/kernel/trace/trace.c</span>
<span class="p_header">+++ b/kernel/trace/trace.c</span>
<span class="p_chunk">@@ -3569,11 +3569,17 @@</span> <span class="p_context"> static int tracing_open(struct inode *inode, struct file *file)</span>
 	/* If this file was open for write, then erase contents */
 	if ((file-&gt;f_mode &amp; FMODE_WRITE) &amp;&amp; (file-&gt;f_flags &amp; O_TRUNC)) {
 		int cpu = tracing_get_cpu(inode);
<span class="p_add">+		struct trace_buffer *trace_buf = &amp;tr-&gt;trace_buffer;</span>
<span class="p_add">+</span>
<span class="p_add">+#ifdef CONFIG_TRACER_MAX_TRACE</span>
<span class="p_add">+		if (tr-&gt;current_trace-&gt;print_max)</span>
<span class="p_add">+			trace_buf = &amp;tr-&gt;max_buffer;</span>
<span class="p_add">+#endif</span>
 
 		if (cpu == RING_BUFFER_ALL_CPUS)
<span class="p_del">-			tracing_reset_online_cpus(&amp;tr-&gt;trace_buffer);</span>
<span class="p_add">+			tracing_reset_online_cpus(trace_buf);</span>
 		else
<span class="p_del">-			tracing_reset(&amp;tr-&gt;trace_buffer, cpu);</span>
<span class="p_add">+			tracing_reset(trace_buf, cpu);</span>
 	}
 
 	if (file-&gt;f_mode &amp; FMODE_READ) {
<span class="p_chunk">@@ -5128,7 +5134,7 @@</span> <span class="p_context"> static int tracing_wait_pipe(struct file *filp)</span>
 		 *
 		 * iter-&gt;pos will be 0 if we haven&#39;t read anything.
 		 */
<span class="p_del">-		if (!tracing_is_on() &amp;&amp; iter-&gt;pos)</span>
<span class="p_add">+		if (!tracer_tracing_is_on(iter-&gt;tr) &amp;&amp; iter-&gt;pos)</span>
 			break;
 
 		mutex_unlock(&amp;iter-&gt;mutex);
<span class="p_header">diff --git a/net/mac80211/iface.c b/net/mac80211/iface.c</span>
<span class="p_header">index 37bec0f864b7..a7aa54f45e19 100644</span>
<span class="p_header">--- a/net/mac80211/iface.c</span>
<span class="p_header">+++ b/net/mac80211/iface.c</span>
<span class="p_chunk">@@ -791,6 +791,7 @@</span> <span class="p_context"> static int ieee80211_open(struct net_device *dev)</span>
 static void ieee80211_do_stop(struct ieee80211_sub_if_data *sdata,
 			      bool going_down)
 {
<span class="p_add">+	struct ieee80211_sub_if_data *txq_sdata = sdata;</span>
 	struct ieee80211_local *local = sdata-&gt;local;
 	struct fq *fq = &amp;local-&gt;fq;
 	unsigned long flags;
<span class="p_chunk">@@ -931,6 +932,9 @@</span> <span class="p_context"> static void ieee80211_do_stop(struct ieee80211_sub_if_data *sdata,</span>
 
 	switch (sdata-&gt;vif.type) {
 	case NL80211_IFTYPE_AP_VLAN:
<span class="p_add">+		txq_sdata = container_of(sdata-&gt;bss,</span>
<span class="p_add">+					 struct ieee80211_sub_if_data, u.ap);</span>
<span class="p_add">+</span>
 		mutex_lock(&amp;local-&gt;mtx);
 		list_del(&amp;sdata-&gt;u.vlan.list);
 		mutex_unlock(&amp;local-&gt;mtx);
<span class="p_chunk">@@ -1001,8 +1005,17 @@</span> <span class="p_context"> static void ieee80211_do_stop(struct ieee80211_sub_if_data *sdata,</span>
 	}
 	spin_unlock_irqrestore(&amp;local-&gt;queue_stop_reason_lock, flags);
 
<span class="p_del">-	if (sdata-&gt;vif.txq) {</span>
<span class="p_del">-		struct txq_info *txqi = to_txq_info(sdata-&gt;vif.txq);</span>
<span class="p_add">+	if (txq_sdata-&gt;vif.txq) {</span>
<span class="p_add">+		struct txq_info *txqi = to_txq_info(txq_sdata-&gt;vif.txq);</span>
<span class="p_add">+</span>
<span class="p_add">+		/*</span>
<span class="p_add">+		 * FIXME FIXME</span>
<span class="p_add">+		 *</span>
<span class="p_add">+		 * We really shouldn&#39;t purge the *entire* txqi since that</span>
<span class="p_add">+		 * contains frames for the other AP_VLANs (and possibly</span>
<span class="p_add">+		 * the AP itself) as well, but there&#39;s no API in FQ now</span>
<span class="p_add">+		 * to be able to filter.</span>
<span class="p_add">+		 */</span>
 
 		spin_lock_bh(&amp;fq-&gt;lock);
 		ieee80211_txq_purge(local, txqi);
<span class="p_header">diff --git a/net/mac80211/offchannel.c b/net/mac80211/offchannel.c</span>
<span class="p_header">index eede5c6db8d5..30bba53c2992 100644</span>
<span class="p_header">--- a/net/mac80211/offchannel.c</span>
<span class="p_header">+++ b/net/mac80211/offchannel.c</span>
<span class="p_chunk">@@ -707,6 +707,8 @@</span> <span class="p_context"> static int ieee80211_cancel_roc(struct ieee80211_local *local,</span>
 	if (!cookie)
 		return -ENOENT;
 
<span class="p_add">+	flush_work(&amp;local-&gt;hw_roc_start);</span>
<span class="p_add">+</span>
 	mutex_lock(&amp;local-&gt;mtx);
 	list_for_each_entry_safe(roc, tmp, &amp;local-&gt;roc_list, list) {
 		if (!mgmt_tx &amp;&amp; roc-&gt;cookie != cookie)
<span class="p_header">diff --git a/net/mac80211/tx.c b/net/mac80211/tx.c</span>
<span class="p_header">index dd190ff3daea..274c564bd9af 100644</span>
<span class="p_header">--- a/net/mac80211/tx.c</span>
<span class="p_header">+++ b/net/mac80211/tx.c</span>
<span class="p_chunk">@@ -1277,11 +1277,6 @@</span> <span class="p_context"> static void ieee80211_set_skb_enqueue_time(struct sk_buff *skb)</span>
 	IEEE80211_SKB_CB(skb)-&gt;control.enqueue_time = codel_get_time();
 }
 
<span class="p_del">-static void ieee80211_set_skb_vif(struct sk_buff *skb, struct txq_info *txqi)</span>
<span class="p_del">-{</span>
<span class="p_del">-	IEEE80211_SKB_CB(skb)-&gt;control.vif = txqi-&gt;txq.vif;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
 static u32 codel_skb_len_func(const struct sk_buff *skb)
 {
 	return skb-&gt;len;
<span class="p_chunk">@@ -3388,6 +3383,7 @@</span> <span class="p_context"> struct sk_buff *ieee80211_tx_dequeue(struct ieee80211_hw *hw,</span>
 	struct ieee80211_tx_info *info;
 	struct ieee80211_tx_data tx;
 	ieee80211_tx_result r;
<span class="p_add">+	struct ieee80211_vif *vif;</span>
 
 	spin_lock_bh(&amp;fq-&gt;lock);
 
<span class="p_chunk">@@ -3404,8 +3400,6 @@</span> <span class="p_context"> struct sk_buff *ieee80211_tx_dequeue(struct ieee80211_hw *hw,</span>
 	if (!skb)
 		goto out;
 
<span class="p_del">-	ieee80211_set_skb_vif(skb, txqi);</span>
<span class="p_del">-</span>
 	hdr = (struct ieee80211_hdr *)skb-&gt;data;
 	info = IEEE80211_SKB_CB(skb);
 
<span class="p_chunk">@@ -3462,6 +3456,34 @@</span> <span class="p_context"> struct sk_buff *ieee80211_tx_dequeue(struct ieee80211_hw *hw,</span>
 		}
 	}
 
<span class="p_add">+	switch (tx.sdata-&gt;vif.type) {</span>
<span class="p_add">+	case NL80211_IFTYPE_MONITOR:</span>
<span class="p_add">+		if (tx.sdata-&gt;u.mntr.flags &amp; MONITOR_FLAG_ACTIVE) {</span>
<span class="p_add">+			vif = &amp;tx.sdata-&gt;vif;</span>
<span class="p_add">+			break;</span>
<span class="p_add">+		}</span>
<span class="p_add">+		tx.sdata = rcu_dereference(local-&gt;monitor_sdata);</span>
<span class="p_add">+		if (tx.sdata) {</span>
<span class="p_add">+			vif = &amp;tx.sdata-&gt;vif;</span>
<span class="p_add">+			info-&gt;hw_queue =</span>
<span class="p_add">+				vif-&gt;hw_queue[skb_get_queue_mapping(skb)];</span>
<span class="p_add">+		} else if (ieee80211_hw_check(&amp;local-&gt;hw, QUEUE_CONTROL)) {</span>
<span class="p_add">+			ieee80211_free_txskb(&amp;local-&gt;hw, skb);</span>
<span class="p_add">+			goto begin;</span>
<span class="p_add">+		} else {</span>
<span class="p_add">+			vif = NULL;</span>
<span class="p_add">+		}</span>
<span class="p_add">+		break;</span>
<span class="p_add">+	case NL80211_IFTYPE_AP_VLAN:</span>
<span class="p_add">+		tx.sdata = container_of(tx.sdata-&gt;bss,</span>
<span class="p_add">+					struct ieee80211_sub_if_data, u.ap);</span>
<span class="p_add">+		/* fall through */</span>
<span class="p_add">+	default:</span>
<span class="p_add">+		vif = &amp;tx.sdata-&gt;vif;</span>
<span class="p_add">+		break;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	IEEE80211_SKB_CB(skb)-&gt;control.vif = vif;</span>
 out:
 	spin_unlock_bh(&amp;fq-&gt;lock);
 
<span class="p_header">diff --git a/net/wireless/nl80211.c b/net/wireless/nl80211.c</span>
<span class="p_header">index e9e9bc5c8773..ece0fbc08607 100644</span>
<span class="p_header">--- a/net/wireless/nl80211.c</span>
<span class="p_header">+++ b/net/wireless/nl80211.c</span>
<span class="p_chunk">@@ -10385,6 +10385,9 @@</span> <span class="p_context"> static int nl80211_set_rekey_data(struct sk_buff *skb, struct genl_info *info)</span>
 	if (err)
 		return err;
 
<span class="p_add">+	if (!tb[NL80211_REKEY_DATA_REPLAY_CTR] || !tb[NL80211_REKEY_DATA_KEK] ||</span>
<span class="p_add">+	    !tb[NL80211_REKEY_DATA_KCK])</span>
<span class="p_add">+		return -EINVAL;</span>
 	if (nla_len(tb[NL80211_REKEY_DATA_REPLAY_CTR]) != NL80211_REPLAY_CTR_LEN)
 		return -ERANGE;
 	if (nla_len(tb[NL80211_REKEY_DATA_KEK]) != NL80211_KEK_LEN)
<span class="p_header">diff --git a/security/keys/Kconfig b/security/keys/Kconfig</span>
<span class="p_header">index d942c7c2bc0a..e0a39781b10f 100644</span>
<span class="p_header">--- a/security/keys/Kconfig</span>
<span class="p_header">+++ b/security/keys/Kconfig</span>
<span class="p_chunk">@@ -41,10 +41,8 @@</span> <span class="p_context"> config BIG_KEYS</span>
 	bool &quot;Large payload keys&quot;
 	depends on KEYS
 	depends on TMPFS
<span class="p_del">-	depends on (CRYPTO_ANSI_CPRNG = y || CRYPTO_DRBG = y)</span>
 	select CRYPTO_AES
<span class="p_del">-	select CRYPTO_ECB</span>
<span class="p_del">-	select CRYPTO_RNG</span>
<span class="p_add">+	select CRYPTO_GCM</span>
 	help
 	  This option provides support for holding large keys within the kernel
 	  (for example Kerberos ticket caches).  The data may be stored out to
<span class="p_header">diff --git a/security/keys/big_key.c b/security/keys/big_key.c</span>
<span class="p_header">index 835c1ab30d01..47c6dcab1a8e 100644</span>
<span class="p_header">--- a/security/keys/big_key.c</span>
<span class="p_header">+++ b/security/keys/big_key.c</span>
<span class="p_chunk">@@ -1,5 +1,6 @@</span> <span class="p_context"></span>
 /* Large capacity key type
  *
<span class="p_add">+ * Copyright (C) 2017 Jason A. Donenfeld &lt;Jason@zx2c4.com&gt;. All Rights Reserved.</span>
  * Copyright (C) 2013 Red Hat, Inc. All Rights Reserved.
  * Written by David Howells (dhowells@redhat.com)
  *
<span class="p_chunk">@@ -16,10 +17,10 @@</span> <span class="p_context"></span>
 #include &lt;linux/shmem_fs.h&gt;
 #include &lt;linux/err.h&gt;
 #include &lt;linux/scatterlist.h&gt;
<span class="p_add">+#include &lt;linux/random.h&gt;</span>
 #include &lt;keys/user-type.h&gt;
 #include &lt;keys/big_key-type.h&gt;
<span class="p_del">-#include &lt;crypto/rng.h&gt;</span>
<span class="p_del">-#include &lt;crypto/skcipher.h&gt;</span>
<span class="p_add">+#include &lt;crypto/aead.h&gt;</span>
 
 /*
  * Layout of key payload words.
<span class="p_chunk">@@ -49,7 +50,12 @@</span> <span class="p_context"> enum big_key_op {</span>
 /*
  * Key size for big_key data encryption
  */
<span class="p_del">-#define ENC_KEY_SIZE	16</span>
<span class="p_add">+#define ENC_KEY_SIZE 32</span>
<span class="p_add">+</span>
<span class="p_add">+/*</span>
<span class="p_add">+ * Authentication tag length</span>
<span class="p_add">+ */</span>
<span class="p_add">+#define ENC_AUTHTAG_SIZE 16</span>
 
 /*
  * big_key defined keys take an arbitrary string as the description and an
<span class="p_chunk">@@ -64,57 +70,62 @@</span> <span class="p_context"> struct key_type key_type_big_key = {</span>
 	.destroy		= big_key_destroy,
 	.describe		= big_key_describe,
 	.read			= big_key_read,
<span class="p_add">+	/* no -&gt;update(); don&#39;t add it without changing big_key_crypt() nonce */</span>
 };
 
 /*
<span class="p_del">- * Crypto names for big_key data encryption</span>
<span class="p_add">+ * Crypto names for big_key data authenticated encryption</span>
  */
<span class="p_del">-static const char big_key_rng_name[] = &quot;stdrng&quot;;</span>
<span class="p_del">-static const char big_key_alg_name[] = &quot;ecb(aes)&quot;;</span>
<span class="p_add">+static const char big_key_alg_name[] = &quot;gcm(aes)&quot;;</span>
 
 /*
<span class="p_del">- * Crypto algorithms for big_key data encryption</span>
<span class="p_add">+ * Crypto algorithms for big_key data authenticated encryption</span>
  */
<span class="p_del">-static struct crypto_rng *big_key_rng;</span>
<span class="p_del">-static struct crypto_skcipher *big_key_skcipher;</span>
<span class="p_add">+static struct crypto_aead *big_key_aead;</span>
 
 /*
<span class="p_del">- * Generate random key to encrypt big_key data</span>
<span class="p_add">+ * Since changing the key affects the entire object, we need a mutex.</span>
  */
<span class="p_del">-static inline int big_key_gen_enckey(u8 *key)</span>
<span class="p_del">-{</span>
<span class="p_del">-	return crypto_rng_get_bytes(big_key_rng, key, ENC_KEY_SIZE);</span>
<span class="p_del">-}</span>
<span class="p_add">+static DEFINE_MUTEX(big_key_aead_lock);</span>
 
 /*
  * Encrypt/decrypt big_key data
  */
 static int big_key_crypt(enum big_key_op op, u8 *data, size_t datalen, u8 *key)
 {
<span class="p_del">-	int ret = -EINVAL;</span>
<span class="p_add">+	int ret;</span>
 	struct scatterlist sgio;
<span class="p_del">-	SKCIPHER_REQUEST_ON_STACK(req, big_key_skcipher);</span>
<span class="p_del">-</span>
<span class="p_del">-	if (crypto_skcipher_setkey(big_key_skcipher, key, ENC_KEY_SIZE)) {</span>
<span class="p_add">+	struct aead_request *aead_req;</span>
<span class="p_add">+	/* We always use a zero nonce. The reason we can get away with this is</span>
<span class="p_add">+	 * because we&#39;re using a different randomly generated key for every</span>
<span class="p_add">+	 * different encryption. Notably, too, key_type_big_key doesn&#39;t define</span>
<span class="p_add">+	 * an .update function, so there&#39;s no chance we&#39;ll wind up reusing the</span>
<span class="p_add">+	 * key to encrypt updated data. Simply put: one key, one encryption.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	u8 zero_nonce[crypto_aead_ivsize(big_key_aead)];</span>
<span class="p_add">+</span>
<span class="p_add">+	aead_req = aead_request_alloc(big_key_aead, GFP_KERNEL);</span>
<span class="p_add">+	if (!aead_req)</span>
<span class="p_add">+		return -ENOMEM;</span>
<span class="p_add">+</span>
<span class="p_add">+	memset(zero_nonce, 0, sizeof(zero_nonce));</span>
<span class="p_add">+	sg_init_one(&amp;sgio, data, datalen + (op == BIG_KEY_ENC ? ENC_AUTHTAG_SIZE : 0));</span>
<span class="p_add">+	aead_request_set_crypt(aead_req, &amp;sgio, &amp;sgio, datalen, zero_nonce);</span>
<span class="p_add">+	aead_request_set_callback(aead_req, CRYPTO_TFM_REQ_MAY_SLEEP, NULL, NULL);</span>
<span class="p_add">+	aead_request_set_ad(aead_req, 0);</span>
<span class="p_add">+</span>
<span class="p_add">+	mutex_lock(&amp;big_key_aead_lock);</span>
<span class="p_add">+	if (crypto_aead_setkey(big_key_aead, key, ENC_KEY_SIZE)) {</span>
 		ret = -EAGAIN;
 		goto error;
 	}
<span class="p_del">-</span>
<span class="p_del">-	skcipher_request_set_tfm(req, big_key_skcipher);</span>
<span class="p_del">-	skcipher_request_set_callback(req, CRYPTO_TFM_REQ_MAY_SLEEP,</span>
<span class="p_del">-				      NULL, NULL);</span>
<span class="p_del">-</span>
<span class="p_del">-	sg_init_one(&amp;sgio, data, datalen);</span>
<span class="p_del">-	skcipher_request_set_crypt(req, &amp;sgio, &amp;sgio, datalen, NULL);</span>
<span class="p_del">-</span>
 	if (op == BIG_KEY_ENC)
<span class="p_del">-		ret = crypto_skcipher_encrypt(req);</span>
<span class="p_add">+		ret = crypto_aead_encrypt(aead_req);</span>
 	else
<span class="p_del">-		ret = crypto_skcipher_decrypt(req);</span>
<span class="p_del">-</span>
<span class="p_del">-	skcipher_request_zero(req);</span>
<span class="p_del">-</span>
<span class="p_add">+		ret = crypto_aead_decrypt(aead_req);</span>
 error:
<span class="p_add">+	mutex_unlock(&amp;big_key_aead_lock);</span>
<span class="p_add">+	aead_request_free(aead_req);</span>
 	return ret;
 }
 
<span class="p_chunk">@@ -146,15 +157,13 @@</span> <span class="p_context"> int big_key_preparse(struct key_preparsed_payload *prep)</span>
 		 *
 		 * File content is stored encrypted with randomly generated key.
 		 */
<span class="p_del">-		size_t enclen = ALIGN(datalen, crypto_skcipher_blocksize(big_key_skcipher));</span>
<span class="p_add">+		size_t enclen = datalen + ENC_AUTHTAG_SIZE;</span>
 
<span class="p_del">-		/* prepare aligned data to encrypt */</span>
 		data = kmalloc(enclen, GFP_KERNEL);
 		if (!data)
 			return -ENOMEM;
 
 		memcpy(data, prep-&gt;data, datalen);
<span class="p_del">-		memset(data + datalen, 0x00, enclen - datalen);</span>
 
 		/* generate random key */
 		enckey = kmalloc(ENC_KEY_SIZE, GFP_KERNEL);
<span class="p_chunk">@@ -162,13 +171,10 @@</span> <span class="p_context"> int big_key_preparse(struct key_preparsed_payload *prep)</span>
 			ret = -ENOMEM;
 			goto error;
 		}
<span class="p_del">-</span>
<span class="p_del">-		ret = big_key_gen_enckey(enckey);</span>
<span class="p_del">-		if (ret)</span>
<span class="p_del">-			goto err_enckey;</span>
<span class="p_add">+		get_random_bytes(enckey, ENC_KEY_SIZE);</span>
 
 		/* encrypt aligned data */
<span class="p_del">-		ret = big_key_crypt(BIG_KEY_ENC, data, enclen, enckey);</span>
<span class="p_add">+		ret = big_key_crypt(BIG_KEY_ENC, data, datalen, enckey);</span>
 		if (ret)
 			goto err_enckey;
 
<span class="p_chunk">@@ -194,7 +200,7 @@</span> <span class="p_context"> int big_key_preparse(struct key_preparsed_payload *prep)</span>
 		*path = file-&gt;f_path;
 		path_get(path);
 		fput(file);
<span class="p_del">-		kfree(data);</span>
<span class="p_add">+		kzfree(data);</span>
 	} else {
 		/* Just store the data in a buffer */
 		void *data = kmalloc(datalen, GFP_KERNEL);
<span class="p_chunk">@@ -210,9 +216,9 @@</span> <span class="p_context"> int big_key_preparse(struct key_preparsed_payload *prep)</span>
 err_fput:
 	fput(file);
 err_enckey:
<span class="p_del">-	kfree(enckey);</span>
<span class="p_add">+	kzfree(enckey);</span>
 error:
<span class="p_del">-	kfree(data);</span>
<span class="p_add">+	kzfree(data);</span>
 	return ret;
 }
 
<span class="p_chunk">@@ -226,7 +232,7 @@</span> <span class="p_context"> void big_key_free_preparse(struct key_preparsed_payload *prep)</span>
 
 		path_put(path);
 	}
<span class="p_del">-	kfree(prep-&gt;payload.data[big_key_data]);</span>
<span class="p_add">+	kzfree(prep-&gt;payload.data[big_key_data]);</span>
 }
 
 /*
<span class="p_chunk">@@ -258,7 +264,7 @@</span> <span class="p_context"> void big_key_destroy(struct key *key)</span>
 		path-&gt;mnt = NULL;
 		path-&gt;dentry = NULL;
 	}
<span class="p_del">-	kfree(key-&gt;payload.data[big_key_data]);</span>
<span class="p_add">+	kzfree(key-&gt;payload.data[big_key_data]);</span>
 	key-&gt;payload.data[big_key_data] = NULL;
 }
 
<span class="p_chunk">@@ -294,7 +300,7 @@</span> <span class="p_context"> long big_key_read(const struct key *key, char __user *buffer, size_t buflen)</span>
 		struct file *file;
 		u8 *data;
 		u8 *enckey = (u8 *)key-&gt;payload.data[big_key_data];
<span class="p_del">-		size_t enclen = ALIGN(datalen, crypto_skcipher_blocksize(big_key_skcipher));</span>
<span class="p_add">+		size_t enclen = datalen + ENC_AUTHTAG_SIZE;</span>
 
 		data = kmalloc(enclen, GFP_KERNEL);
 		if (!data)
<span class="p_chunk">@@ -326,7 +332,7 @@</span> <span class="p_context"> long big_key_read(const struct key *key, char __user *buffer, size_t buflen)</span>
 err_fput:
 		fput(file);
 error:
<span class="p_del">-		kfree(data);</span>
<span class="p_add">+		kzfree(data);</span>
 	} else {
 		ret = datalen;
 		if (copy_to_user(buffer, key-&gt;payload.data[big_key_data],
<span class="p_chunk">@@ -342,47 +348,31 @@</span> <span class="p_context"> long big_key_read(const struct key *key, char __user *buffer, size_t buflen)</span>
  */
 static int __init big_key_init(void)
 {
<span class="p_del">-	struct crypto_skcipher *cipher;</span>
<span class="p_del">-	struct crypto_rng *rng;</span>
 	int ret;
 
<span class="p_del">-	rng = crypto_alloc_rng(big_key_rng_name, 0, 0);</span>
<span class="p_del">-	if (IS_ERR(rng)) {</span>
<span class="p_del">-		pr_err(&quot;Can&#39;t alloc rng: %ld\n&quot;, PTR_ERR(rng));</span>
<span class="p_del">-		return PTR_ERR(rng);</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">-	big_key_rng = rng;</span>
<span class="p_del">-</span>
<span class="p_del">-	/* seed RNG */</span>
<span class="p_del">-	ret = crypto_rng_reset(rng, NULL, crypto_rng_seedsize(rng));</span>
<span class="p_del">-	if (ret) {</span>
<span class="p_del">-		pr_err(&quot;Can&#39;t reset rng: %d\n&quot;, ret);</span>
<span class="p_del">-		goto error_rng;</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
 	/* init block cipher */
<span class="p_del">-	cipher = crypto_alloc_skcipher(big_key_alg_name, 0, CRYPTO_ALG_ASYNC);</span>
<span class="p_del">-	if (IS_ERR(cipher)) {</span>
<span class="p_del">-		ret = PTR_ERR(cipher);</span>
<span class="p_add">+	big_key_aead = crypto_alloc_aead(big_key_alg_name, 0, CRYPTO_ALG_ASYNC);</span>
<span class="p_add">+	if (IS_ERR(big_key_aead)) {</span>
<span class="p_add">+		ret = PTR_ERR(big_key_aead);</span>
 		pr_err(&quot;Can&#39;t alloc crypto: %d\n&quot;, ret);
<span class="p_del">-		goto error_rng;</span>
<span class="p_add">+		return ret;</span>
<span class="p_add">+	}</span>
<span class="p_add">+	ret = crypto_aead_setauthsize(big_key_aead, ENC_AUTHTAG_SIZE);</span>
<span class="p_add">+	if (ret &lt; 0) {</span>
<span class="p_add">+		pr_err(&quot;Can&#39;t set crypto auth tag len: %d\n&quot;, ret);</span>
<span class="p_add">+		goto free_aead;</span>
 	}
<span class="p_del">-</span>
<span class="p_del">-	big_key_skcipher = cipher;</span>
 
 	ret = register_key_type(&amp;key_type_big_key);
 	if (ret &lt; 0) {
 		pr_err(&quot;Can&#39;t register type: %d\n&quot;, ret);
<span class="p_del">-		goto error_cipher;</span>
<span class="p_add">+		goto free_aead;</span>
 	}
 
 	return 0;
 
<span class="p_del">-error_cipher:</span>
<span class="p_del">-	crypto_free_skcipher(big_key_skcipher);</span>
<span class="p_del">-error_rng:</span>
<span class="p_del">-	crypto_free_rng(big_key_rng);</span>
<span class="p_add">+free_aead:</span>
<span class="p_add">+	crypto_free_aead(big_key_aead);</span>
 	return ret;
 }
 
<span class="p_header">diff --git a/security/keys/internal.h b/security/keys/internal.h</span>
<span class="p_header">index a705a7d92ad7..fb0c65049c19 100644</span>
<span class="p_header">--- a/security/keys/internal.h</span>
<span class="p_header">+++ b/security/keys/internal.h</span>
<span class="p_chunk">@@ -137,7 +137,7 @@</span> <span class="p_context"> extern key_ref_t keyring_search_aux(key_ref_t keyring_ref,</span>
 extern key_ref_t search_my_process_keyrings(struct keyring_search_context *ctx);
 extern key_ref_t search_process_keyrings(struct keyring_search_context *ctx);
 
<span class="p_del">-extern struct key *find_keyring_by_name(const char *name, bool skip_perm_check);</span>
<span class="p_add">+extern struct key *find_keyring_by_name(const char *name, bool uid_keyring);</span>
 
 extern int install_user_keyrings(void);
 extern int install_thread_keyring_to_cred(struct cred *);
<span class="p_header">diff --git a/security/keys/key.c b/security/keys/key.c</span>
<span class="p_header">index 2f4ce35ae2aa..135e1eb7e468 100644</span>
<span class="p_header">--- a/security/keys/key.c</span>
<span class="p_header">+++ b/security/keys/key.c</span>
<span class="p_chunk">@@ -301,6 +301,8 @@</span> <span class="p_context"> struct key *key_alloc(struct key_type *type, const char *desc,</span>
 		key-&gt;flags |= 1 &lt;&lt; KEY_FLAG_IN_QUOTA;
 	if (flags &amp; KEY_ALLOC_BUILT_IN)
 		key-&gt;flags |= 1 &lt;&lt; KEY_FLAG_BUILTIN;
<span class="p_add">+	if (flags &amp; KEY_ALLOC_UID_KEYRING)</span>
<span class="p_add">+		key-&gt;flags |= 1 &lt;&lt; KEY_FLAG_UID_KEYRING;</span>
 
 #ifdef KEY_DEBUGGING
 	key-&gt;magic = KEY_DEBUG_MAGIC;
<span class="p_header">diff --git a/security/keys/keyctl.c b/security/keys/keyctl.c</span>
<span class="p_header">index ada12c3e3ac4..1302cb398346 100644</span>
<span class="p_header">--- a/security/keys/keyctl.c</span>
<span class="p_header">+++ b/security/keys/keyctl.c</span>
<span class="p_chunk">@@ -766,6 +766,11 @@</span> <span class="p_context"> long keyctl_read_key(key_serial_t keyid, char __user *buffer, size_t buflen)</span>
 
 	key = key_ref_to_ptr(key_ref);
 
<span class="p_add">+	if (test_bit(KEY_FLAG_NEGATIVE, &amp;key-&gt;flags)) {</span>
<span class="p_add">+		ret = -ENOKEY;</span>
<span class="p_add">+		goto error2;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
 	/* see if we can read it directly */
 	ret = key_permission(key_ref, KEY_NEED_READ);
 	if (ret == 0)
<span class="p_header">diff --git a/security/keys/keyring.c b/security/keys/keyring.c</span>
<span class="p_header">index c91e4e0cea08..a86d0ae1773c 100644</span>
<span class="p_header">--- a/security/keys/keyring.c</span>
<span class="p_header">+++ b/security/keys/keyring.c</span>
<span class="p_chunk">@@ -416,7 +416,7 @@</span> <span class="p_context"> static void keyring_describe(const struct key *keyring, struct seq_file *m)</span>
 }
 
 struct keyring_read_iterator_context {
<span class="p_del">-	size_t			qty;</span>
<span class="p_add">+	size_t			buflen;</span>
 	size_t			count;
 	key_serial_t __user	*buffer;
 };
<span class="p_chunk">@@ -428,9 +428,9 @@</span> <span class="p_context"> static int keyring_read_iterator(const void *object, void *data)</span>
 	int ret;
 
 	kenter(&quot;{%s,%d},,{%zu/%zu}&quot;,
<span class="p_del">-	       key-&gt;type-&gt;name, key-&gt;serial, ctx-&gt;count, ctx-&gt;qty);</span>
<span class="p_add">+	       key-&gt;type-&gt;name, key-&gt;serial, ctx-&gt;count, ctx-&gt;buflen);</span>
 
<span class="p_del">-	if (ctx-&gt;count &gt;= ctx-&gt;qty)</span>
<span class="p_add">+	if (ctx-&gt;count &gt;= ctx-&gt;buflen)</span>
 		return 1;
 
 	ret = put_user(key-&gt;serial, ctx-&gt;buffer);
<span class="p_chunk">@@ -465,16 +465,12 @@</span> <span class="p_context"> static long keyring_read(const struct key *keyring,</span>
 		return 0;
 
 	/* Calculate how much data we could return */
<span class="p_del">-	ctx.qty = nr_keys * sizeof(key_serial_t);</span>
<span class="p_del">-</span>
 	if (!buffer || !buflen)
<span class="p_del">-		return ctx.qty;</span>
<span class="p_del">-</span>
<span class="p_del">-	if (buflen &gt; ctx.qty)</span>
<span class="p_del">-		ctx.qty = buflen;</span>
<span class="p_add">+		return nr_keys * sizeof(key_serial_t);</span>
 
 	/* Copy the IDs of the subscribed keys into the buffer */
 	ctx.buffer = (key_serial_t __user *)buffer;
<span class="p_add">+	ctx.buflen = buflen;</span>
 	ctx.count = 0;
 	ret = assoc_array_iterate(&amp;keyring-&gt;keys, keyring_read_iterator, &amp;ctx);
 	if (ret &lt; 0) {
<span class="p_chunk">@@ -989,15 +985,15 @@</span> <span class="p_context"> key_ref_t find_key_to_update(key_ref_t keyring_ref,</span>
 /*
  * Find a keyring with the specified name.
  *
<span class="p_del">- * All named keyrings in the current user namespace are searched, provided they</span>
<span class="p_del">- * grant Search permission directly to the caller (unless this check is</span>
<span class="p_del">- * skipped).  Keyrings whose usage points have reached zero or who have been</span>
<span class="p_del">- * revoked are skipped.</span>
<span class="p_add">+ * Only keyrings that have nonzero refcount, are not revoked, and are owned by a</span>
<span class="p_add">+ * user in the current user namespace are considered.  If @uid_keyring is %true,</span>
<span class="p_add">+ * the keyring additionally must have been allocated as a user or user session</span>
<span class="p_add">+ * keyring; otherwise, it must grant Search permission directly to the caller.</span>
  *
  * Returns a pointer to the keyring with the keyring&#39;s refcount having being
  * incremented on success.  -ENOKEY is returned if a key could not be found.
  */
<span class="p_del">-struct key *find_keyring_by_name(const char *name, bool skip_perm_check)</span>
<span class="p_add">+struct key *find_keyring_by_name(const char *name, bool uid_keyring)</span>
 {
 	struct key *keyring;
 	int bucket;
<span class="p_chunk">@@ -1025,10 +1021,15 @@</span> <span class="p_context"> struct key *find_keyring_by_name(const char *name, bool skip_perm_check)</span>
 			if (strcmp(keyring-&gt;description, name) != 0)
 				continue;
 
<span class="p_del">-			if (!skip_perm_check &amp;&amp;</span>
<span class="p_del">-			    key_permission(make_key_ref(keyring, 0),</span>
<span class="p_del">-					   KEY_NEED_SEARCH) &lt; 0)</span>
<span class="p_del">-				continue;</span>
<span class="p_add">+			if (uid_keyring) {</span>
<span class="p_add">+				if (!test_bit(KEY_FLAG_UID_KEYRING,</span>
<span class="p_add">+					      &amp;keyring-&gt;flags))</span>
<span class="p_add">+					continue;</span>
<span class="p_add">+			} else {</span>
<span class="p_add">+				if (key_permission(make_key_ref(keyring, 0),</span>
<span class="p_add">+						   KEY_NEED_SEARCH) &lt; 0)</span>
<span class="p_add">+					continue;</span>
<span class="p_add">+			}</span>
 
 			/* we&#39;ve got a match but we might end up racing with
 			 * key_cleanup() if the keyring is currently &#39;dead&#39;
<span class="p_header">diff --git a/security/keys/process_keys.c b/security/keys/process_keys.c</span>
<span class="p_header">index 45536c677b05..ce45c78cf0a2 100644</span>
<span class="p_header">--- a/security/keys/process_keys.c</span>
<span class="p_header">+++ b/security/keys/process_keys.c</span>
<span class="p_chunk">@@ -76,7 +76,8 @@</span> <span class="p_context"> int install_user_keyrings(void)</span>
 		if (IS_ERR(uid_keyring)) {
 			uid_keyring = keyring_alloc(buf, user-&gt;uid, INVALID_GID,
 						    cred, user_keyring_perm,
<span class="p_del">-						    KEY_ALLOC_IN_QUOTA,</span>
<span class="p_add">+						    KEY_ALLOC_UID_KEYRING |</span>
<span class="p_add">+							KEY_ALLOC_IN_QUOTA,</span>
 						    NULL, NULL);
 			if (IS_ERR(uid_keyring)) {
 				ret = PTR_ERR(uid_keyring);
<span class="p_chunk">@@ -93,7 +94,8 @@</span> <span class="p_context"> int install_user_keyrings(void)</span>
 			session_keyring =
 				keyring_alloc(buf, user-&gt;uid, INVALID_GID,
 					      cred, user_keyring_perm,
<span class="p_del">-					      KEY_ALLOC_IN_QUOTA,</span>
<span class="p_add">+					      KEY_ALLOC_UID_KEYRING |</span>
<span class="p_add">+						  KEY_ALLOC_IN_QUOTA,</span>
 					      NULL, NULL);
 			if (IS_ERR(session_keyring)) {
 				ret = PTR_ERR(session_keyring);
<span class="p_header">diff --git a/tools/testing/selftests/seccomp/seccomp_bpf.c b/tools/testing/selftests/seccomp/seccomp_bpf.c</span>
<span class="p_header">index 03f1fa495d74..cbb0564c0ec4 100644</span>
<span class="p_header">--- a/tools/testing/selftests/seccomp/seccomp_bpf.c</span>
<span class="p_header">+++ b/tools/testing/selftests/seccomp/seccomp_bpf.c</span>
<span class="p_chunk">@@ -6,10 +6,18 @@</span> <span class="p_context"></span>
  */
 
 #include &lt;sys/types.h&gt;
<span class="p_del">-#include &lt;asm/siginfo.h&gt;</span>
<span class="p_del">-#define __have_siginfo_t 1</span>
<span class="p_del">-#define __have_sigval_t 1</span>
<span class="p_del">-#define __have_sigevent_t 1</span>
<span class="p_add">+</span>
<span class="p_add">+/*</span>
<span class="p_add">+ * glibc 2.26 and later have SIGSYS in siginfo_t. Before that,</span>
<span class="p_add">+ * we need to use the kernel&#39;s siginfo.h file and trick glibc</span>
<span class="p_add">+ * into accepting it.</span>
<span class="p_add">+ */</span>
<span class="p_add">+#if !__GLIBC_PREREQ(2, 26)</span>
<span class="p_add">+# include &lt;asm/siginfo.h&gt;</span>
<span class="p_add">+# define __have_siginfo_t 1</span>
<span class="p_add">+# define __have_sigval_t 1</span>
<span class="p_add">+# define __have_sigevent_t 1</span>
<span class="p_add">+#endif</span>
 
 #include &lt;errno.h&gt;
 #include &lt;linux/filter.h&gt;
<span class="p_chunk">@@ -676,7 +684,7 @@</span> <span class="p_context"> TEST_F_SIGNAL(TRAP, ign, SIGSYS)</span>
 	syscall(__NR_getpid);
 }
 
<span class="p_del">-static struct siginfo TRAP_info;</span>
<span class="p_add">+static siginfo_t TRAP_info;</span>
 static volatile int TRAP_nr;
 static void TRAP_action(int nr, siginfo_t *info, void *void_context)
 {

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



