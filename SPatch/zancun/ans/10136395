
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>[16/67] powerpc: rename dma_direct_ to dma_nommu_ - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    [16/67] powerpc: rename dma_direct_ to dma_nommu_</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=99">Christoph Hellwig</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>Dec. 29, 2017, 8:18 a.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;20171229081911.2802-17-hch@lst.de&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/10136395/mbox/"
   >mbox</a>
|
   <a href="/patch/10136395/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/10136395/">/patch/10136395/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
	[172.30.200.125])
	by pdx-korg-patchwork.web.codeaurora.org (Postfix) with ESMTP id
	A5D7D603FA for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Fri, 29 Dec 2017 08:20:52 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 92C232D8CD
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Fri, 29 Dec 2017 08:20:52 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id 874A02D8E5; Fri, 29 Dec 2017 08:20:52 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-6.8 required=2.0 tests=BAYES_00,DKIM_SIGNED,
	RCVD_IN_DNSWL_HI,T_DKIM_INVALID autolearn=unavailable version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 5D7812D8CD
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Fri, 29 Dec 2017 08:20:51 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1755949AbdL2IUl (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Fri, 29 Dec 2017 03:20:41 -0500
Received: from bombadil.infradead.org ([65.50.211.133]:46540 &quot;EHLO
	bombadil.infradead.org&quot; rhost-flags-OK-OK-OK-OK) by vger.kernel.org
	with ESMTP id S1755856AbdL2IUh (ORCPT
	&lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Fri, 29 Dec 2017 03:20:37 -0500
DKIM-Signature: v=1; a=rsa-sha256; q=dns/txt; c=relaxed/relaxed;
	d=infradead.org; s=bombadil.20170209;
	h=References:In-Reply-To:Message-Id:
	Date:Subject:Cc:To:From:Sender:Reply-To:MIME-Version:Content-Type:
	Content-Transfer-Encoding:Content-ID:Content-Description:Resent-Date:
	Resent-From:Resent-Sender:Resent-To:Resent-Cc:Resent-Message-ID:List-Id:
	List-Help:List-Unsubscribe:List-Subscribe:List-Post:List-Owner:List-Archive;
	bh=arz+MLVaSKwBFdRfjgT6rraF1jFk1nlDpf1Kj2En7AE=;
	b=o83nzpwprXt4I8JsXurx6RVQ8
	YdFmlEC8i4rYWqNULqT+lPzYytiu/DInJXF6rNSBwWmj4mBfYIChIPHcFWbCOCdjJ50vYUPaphlLN
	Oae1T3eKgAiG/iRyJ/oZeLVCy8CUt0zNDIMNc/VxZQwJ76a+QCRIvd4G9zIPiM5MeIOs5VqRbdirI
	xUKSfqp3PSdtVUSh50KaqMa3M/YolVyN+TMIeTsN/AFQDFK4pkRoHavnUv5FMouZ0Tn4l3YUq+acY
	vwWl15pXW7Q01+AEb59aDTeZiUWwhZr1TtRZyV3xukSiOMSgEQnfpVLt0kXO+LQXxGNOMw88tIoU7
	iPDrH442A==;
Received: from 77.117.237.29.wireless.dyn.drei.com ([77.117.237.29]
	helo=localhost)
	by bombadil.infradead.org with esmtpsa (Exim 4.89 #1 (Red Hat Linux))
	id 1eUpu0-0000t1-7m; Fri, 29 Dec 2017 08:20:29 +0000
From: Christoph Hellwig &lt;hch@lst.de&gt;
To: iommu@lists.linux-foundation.org
Cc: linux-alpha@vger.kernel.org, linux-snps-arc@lists.infradead.org,
	linux-arm-kernel@lists.infradead.org,
	adi-buildroot-devel@lists.sourceforge.net,
	linux-c6x-dev@linux-c6x.org, linux-cris-kernel@axis.com,
	linux-hexagon@vger.kernel.org, linux-ia64@vger.kernel.org,
	linux-m68k@lists.linux-m68k.org, linux-metag@vger.kernel.org,
	Michal Simek &lt;monstr@monstr.eu&gt;, linux-mips@linux-mips.org,
	linux-parisc@vger.kernel.org, linuxppc-dev@lists.ozlabs.org,
	patches@groups.riscv.org, linux-s390@vger.kernel.org,
	linux-sh@vger.kernel.org, sparclinux@vger.kernel.org,
	Guan Xuetao &lt;gxt@mprc.pku.edu.cn&gt;, x86@kernel.org,
	linux-arch@vger.kernel.org, linux-kernel@vger.kernel.org
Subject: [PATCH 16/67] powerpc: rename dma_direct_ to dma_nommu_
Date: Fri, 29 Dec 2017 09:18:20 +0100
Message-Id: &lt;20171229081911.2802-17-hch@lst.de&gt;
X-Mailer: git-send-email 2.14.2
In-Reply-To: &lt;20171229081911.2802-1-hch@lst.de&gt;
References: &lt;20171229081911.2802-1-hch@lst.de&gt;
X-SRS-Rewrite: SMTP reverse-path rewritten from &lt;hch@infradead.org&gt; by
	bombadil.infradead.org. See http://www.infradead.org/rpr.html
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=99">Christoph Hellwig</a> - Dec. 29, 2017, 8:18 a.m.</div>
<pre class="content">
We want to use the dma_direct_ namespace for a generic implementation,
so rename powerpc to the second best choice: dma_nommu_.
<span class="signed-off-by">
Signed-off-by: Christoph Hellwig &lt;hch@lst.de&gt;</span>
---
 arch/powerpc/include/asm/dma-mapping.h    |  8 ++--
 arch/powerpc/kernel/dma-iommu.c           |  2 +-
 arch/powerpc/kernel/dma-swiotlb.c         |  6 +--
 arch/powerpc/kernel/dma.c                 | 68 +++++++++++++++----------------
 arch/powerpc/kernel/pci-common.c          |  2 +-
 arch/powerpc/kernel/setup-common.c        |  2 +-
 arch/powerpc/platforms/cell/iommu.c       | 28 ++++++-------
 arch/powerpc/platforms/pasemi/iommu.c     |  2 +-
 arch/powerpc/platforms/pasemi/setup.c     |  2 +-
 arch/powerpc/platforms/powernv/pci-ioda.c |  4 +-
 arch/powerpc/platforms/pseries/iommu.c    |  2 +-
 arch/powerpc/platforms/pseries/vio.c      |  2 +-
 arch/powerpc/sysdev/dart_iommu.c          |  4 +-
 arch/powerpc/sysdev/fsl_pci.c             |  2 +-
 drivers/misc/cxl/vphb.c                   |  2 +-
 15 files changed, 68 insertions(+), 68 deletions(-)
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=81661">Michael Ellerman</a> - Jan. 2, 2018, 9:45 a.m.</div>
<pre class="content">
Christoph Hellwig &lt;hch@lst.de&gt; writes:
<span class="quote">
&gt; We want to use the dma_direct_ namespace for a generic implementation,</span>
<span class="quote">&gt; so rename powerpc to the second best choice: dma_nommu_.</span>

I&#39;m not a fan of &quot;nommu&quot;. Some of the users of direct ops *are* using an
IOMMU, they&#39;re just setting up a 1:1 mapping once at init time, rather
than mapping dynamically.

Though I don&#39;t have a good idea for a better name, maybe &quot;1to1&quot;,
&quot;linear&quot;, &quot;premapped&quot; ?

cheers
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=70">Geert Uytterhoeven</a> - Jan. 2, 2018, 10:22 a.m.</div>
<pre class="content">
On Tue, Jan 2, 2018 at 10:45 AM, Michael Ellerman &lt;mpe@ellerman.id.au&gt; wrote:
<span class="quote">&gt; Christoph Hellwig &lt;hch@lst.de&gt; writes:</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;&gt; We want to use the dma_direct_ namespace for a generic implementation,</span>
<span class="quote">&gt;&gt; so rename powerpc to the second best choice: dma_nommu_.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; I&#39;m not a fan of &quot;nommu&quot;. Some of the users of direct ops *are* using an</span>
<span class="quote">&gt; IOMMU, they&#39;re just setting up a 1:1 mapping once at init time, rather</span>
<span class="quote">&gt; than mapping dynamically.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; Though I don&#39;t have a good idea for a better name, maybe &quot;1to1&quot;,</span>
<span class="quote">&gt; &quot;linear&quot;, &quot;premapped&quot; ?</span>

&quot;identity&quot;?

Gr{oetje,eeting}s,

                        Geert

--
Geert Uytterhoeven -- There&#39;s lots of Linux beyond ia32 -- geert@linux-m68k.org

In personal conversations with technical people, I call myself a hacker. But
when I&#39;m talking to journalists I just say &quot;programmer&quot; or something like that.
                                -- Linus Torvalds
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=81661">Michael Ellerman</a> - Jan. 3, 2018, 6:24 a.m.</div>
<pre class="content">
Geert Uytterhoeven &lt;geert@linux-m68k.org&gt; writes:
<span class="quote">
&gt; On Tue, Jan 2, 2018 at 10:45 AM, Michael Ellerman &lt;mpe@ellerman.id.au&gt; wrote:</span>
<span class="quote">&gt;&gt; Christoph Hellwig &lt;hch@lst.de&gt; writes:</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt; We want to use the dma_direct_ namespace for a generic implementation,</span>
<span class="quote">&gt;&gt;&gt; so rename powerpc to the second best choice: dma_nommu_.</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; I&#39;m not a fan of &quot;nommu&quot;. Some of the users of direct ops *are* using an</span>
<span class="quote">&gt;&gt; IOMMU, they&#39;re just setting up a 1:1 mapping once at init time, rather</span>
<span class="quote">&gt;&gt; than mapping dynamically.</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; Though I don&#39;t have a good idea for a better name, maybe &quot;1to1&quot;,</span>
<span class="quote">&gt;&gt; &quot;linear&quot;, &quot;premapped&quot; ?</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; &quot;identity&quot;?</span>

I think that would be wrong, but thanks for trying to help :)

The address on the device side is sometimes (often?) offset from the CPU
address. So eg. the device can DMA to RAM address 0x0 using address
0x800000000000000.

Identity would imply 0 == 0 etc.

I think &quot;bijective&quot; is the correct term, but that&#39;s probably a bit
esoteric.

cheers
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=70">Geert Uytterhoeven</a> - Jan. 3, 2018, 7:49 a.m.</div>
<pre class="content">
Hi Michael,

On Wed, Jan 3, 2018 at 7:24 AM, Michael Ellerman &lt;mpe@ellerman.id.au&gt; wrote:
<span class="quote">&gt; Geert Uytterhoeven &lt;geert@linux-m68k.org&gt; writes:</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;&gt; On Tue, Jan 2, 2018 at 10:45 AM, Michael Ellerman &lt;mpe@ellerman.id.au&gt; wrote:</span>
<span class="quote">&gt;&gt;&gt; Christoph Hellwig &lt;hch@lst.de&gt; writes:</span>
<span class="quote">&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt;&gt; We want to use the dma_direct_ namespace for a generic implementation,</span>
<span class="quote">&gt;&gt;&gt;&gt; so rename powerpc to the second best choice: dma_nommu_.</span>
<span class="quote">&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt; I&#39;m not a fan of &quot;nommu&quot;. Some of the users of direct ops *are* using an</span>
<span class="quote">&gt;&gt;&gt; IOMMU, they&#39;re just setting up a 1:1 mapping once at init time, rather</span>
<span class="quote">&gt;&gt;&gt; than mapping dynamically.</span>
<span class="quote">&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt; Though I don&#39;t have a good idea for a better name, maybe &quot;1to1&quot;,</span>
<span class="quote">&gt;&gt;&gt; &quot;linear&quot;, &quot;premapped&quot; ?</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; &quot;identity&quot;?</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; I think that would be wrong, but thanks for trying to help :)</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; The address on the device side is sometimes (often?) offset from the CPU</span>
<span class="quote">&gt; address. So eg. the device can DMA to RAM address 0x0 using address</span>
<span class="quote">&gt; 0x800000000000000.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; Identity would imply 0 == 0 etc.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; I think &quot;bijective&quot; is the correct term, but that&#39;s probably a bit</span>
<span class="quote">&gt; esoteric.</span>

OK, didn&#39;t know about the offset.
Then &quot;linear&quot; is what we tend to use, right?

Gr{oetje,eeting}s,

                        Geert

--
Geert Uytterhoeven -- There&#39;s lots of Linux beyond ia32 -- geert@linux-m68k.org

In personal conversations with technical people, I call myself a hacker. But
when I&#39;m talking to journalists I just say &quot;programmer&quot; or something like that.
                                -- Linus Torvalds
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=545">Julian Calaby</a> - Jan. 3, 2018, 8:19 a.m.</div>
<pre class="content">
Hi All,

On Wed, Jan 3, 2018 at 6:49 PM, Geert Uytterhoeven &lt;geert@linux-m68k.org&gt; wrote:
<span class="quote">&gt; Hi Michael,</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; On Wed, Jan 3, 2018 at 7:24 AM, Michael Ellerman &lt;mpe@ellerman.id.au&gt; wrote:</span>
<span class="quote">&gt;&gt; Geert Uytterhoeven &lt;geert@linux-m68k.org&gt; writes:</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt; On Tue, Jan 2, 2018 at 10:45 AM, Michael Ellerman &lt;mpe@ellerman.id.au&gt; wrote:</span>
<span class="quote">&gt;&gt;&gt;&gt; Christoph Hellwig &lt;hch@lst.de&gt; writes:</span>
<span class="quote">&gt;&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt;&gt;&gt; We want to use the dma_direct_ namespace for a generic implementation,</span>
<span class="quote">&gt;&gt;&gt;&gt;&gt; so rename powerpc to the second best choice: dma_nommu_.</span>
<span class="quote">&gt;&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt;&gt; I&#39;m not a fan of &quot;nommu&quot;. Some of the users of direct ops *are* using an</span>
<span class="quote">&gt;&gt;&gt;&gt; IOMMU, they&#39;re just setting up a 1:1 mapping once at init time, rather</span>
<span class="quote">&gt;&gt;&gt;&gt; than mapping dynamically.</span>
<span class="quote">&gt;&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt;&gt; Though I don&#39;t have a good idea for a better name, maybe &quot;1to1&quot;,</span>
<span class="quote">&gt;&gt;&gt;&gt; &quot;linear&quot;, &quot;premapped&quot; ?</span>
<span class="quote">&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt; &quot;identity&quot;?</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; I think that would be wrong, but thanks for trying to help :)</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; The address on the device side is sometimes (often?) offset from the CPU</span>
<span class="quote">&gt;&gt; address. So eg. the device can DMA to RAM address 0x0 using address</span>
<span class="quote">&gt;&gt; 0x800000000000000.</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; Identity would imply 0 == 0 etc.</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; I think &quot;bijective&quot; is the correct term, but that&#39;s probably a bit</span>
<span class="quote">&gt;&gt; esoteric.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; OK, didn&#39;t know about the offset.</span>
<span class="quote">&gt; Then &quot;linear&quot; is what we tend to use, right?</span>

If this is indeed a linear mapping, can we just remove this and
replace it with the new &quot;generic&quot; mapping being introduced by this
patchset?

Thanks,
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=99">Christoph Hellwig</a> - Jan. 4, 2018, 8:48 a.m.</div>
<pre class="content">
On Wed, Jan 03, 2018 at 07:19:46PM +1100, Julian Calaby wrote:
<span class="quote">&gt; If this is indeed a linear mapping, can we just remove this and</span>
<span class="quote">&gt; replace it with the new &quot;generic&quot; mapping being introduced by this</span>
<span class="quote">&gt; patchset?</span>

That is the long-term plan.  But as the powerpc one includes support
for non-coherent DMA it will have to wait for the next batch.
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=99">Christoph Hellwig</a> - Jan. 4, 2018, 8:49 a.m.</div>
<pre class="content">
On Tue, Jan 02, 2018 at 08:45:30PM +1100, Michael Ellerman wrote:
<span class="quote">&gt; Christoph Hellwig &lt;hch@lst.de&gt; writes:</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; &gt; We want to use the dma_direct_ namespace for a generic implementation,</span>
<span class="quote">&gt; &gt; so rename powerpc to the second best choice: dma_nommu_.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; I&#39;m not a fan of &quot;nommu&quot;. Some of the users of direct ops *are* using an</span>
<span class="quote">&gt; IOMMU, they&#39;re just setting up a 1:1 mapping once at init time, rather</span>
<span class="quote">&gt; than mapping dynamically.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Though I don&#39;t have a good idea for a better name, maybe &quot;1to1&quot;,</span>
<span class="quote">&gt; &quot;linear&quot;, &quot;premapped&quot; ?</span>

It seems like a nice counter part to the dma_iommu_ops used just about
anywhere else in ppc.

But I&#39;ll happily take any maintainer bike shed decision for the next
series.  Remember that in a merge window or two it will hopefully
go away in favor of the new generic dma_direct ops.
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=99">Christoph Hellwig</a> - Jan. 9, 2018, 3:38 p.m.</div>
<pre class="content">
On Thu, Jan 04, 2018 at 09:49:30AM +0100, Christoph Hellwig wrote:
<span class="quote">&gt; On Tue, Jan 02, 2018 at 08:45:30PM +1100, Michael Ellerman wrote:</span>
<span class="quote">&gt; &gt; Christoph Hellwig &lt;hch@lst.de&gt; writes:</span>
<span class="quote">&gt; &gt; </span>
<span class="quote">&gt; &gt; &gt; We want to use the dma_direct_ namespace for a generic implementation,</span>
<span class="quote">&gt; &gt; &gt; so rename powerpc to the second best choice: dma_nommu_.</span>
<span class="quote">&gt; &gt; </span>
<span class="quote">&gt; &gt; I&#39;m not a fan of &quot;nommu&quot;. Some of the users of direct ops *are* using an</span>
<span class="quote">&gt; &gt; IOMMU, they&#39;re just setting up a 1:1 mapping once at init time, rather</span>
<span class="quote">&gt; &gt; than mapping dynamically.</span>
<span class="quote">&gt; &gt; </span>
<span class="quote">&gt; &gt; Though I don&#39;t have a good idea for a better name, maybe &quot;1to1&quot;,</span>
<span class="quote">&gt; &gt; &quot;linear&quot;, &quot;premapped&quot; ?</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; It seems like a nice counter part to the dma_iommu_ops used just about</span>
<span class="quote">&gt; anywhere else in ppc.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; But I&#39;ll happily take any maintainer bike shed decision for the next</span>
<span class="quote">&gt; series.  Remember that in a merge window or two it will hopefully</span>
<span class="quote">&gt; go away in favor of the new generic dma_direct ops.</span>

Michael, please suggest what name you want for the next iteration,
I don&#39;t want to hold up the series on a naming bikeshed.
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/arch/powerpc/include/asm/dma-mapping.h b/arch/powerpc/include/asm/dma-mapping.h</span>
<span class="p_header">index f6ab51205a85..8fa394520af6 100644</span>
<span class="p_header">--- a/arch/powerpc/include/asm/dma-mapping.h</span>
<span class="p_header">+++ b/arch/powerpc/include/asm/dma-mapping.h</span>
<span class="p_chunk">@@ -19,13 +19,13 @@</span> <span class="p_context"></span>
 #include &lt;asm/swiotlb.h&gt;
 
 /* Some dma direct funcs must be visible for use in other dma_ops */
<span class="p_del">-extern void *__dma_direct_alloc_coherent(struct device *dev, size_t size,</span>
<span class="p_add">+extern void *__dma_nommu_alloc_coherent(struct device *dev, size_t size,</span>
 					 dma_addr_t *dma_handle, gfp_t flag,
 					 unsigned long attrs);
<span class="p_del">-extern void __dma_direct_free_coherent(struct device *dev, size_t size,</span>
<span class="p_add">+extern void __dma_nommu_free_coherent(struct device *dev, size_t size,</span>
 				       void *vaddr, dma_addr_t dma_handle,
 				       unsigned long attrs);
<span class="p_del">-extern int dma_direct_mmap_coherent(struct device *dev,</span>
<span class="p_add">+extern int dma_nommu_mmap_coherent(struct device *dev,</span>
 				    struct vm_area_struct *vma,
 				    void *cpu_addr, dma_addr_t handle,
 				    size_t size, unsigned long attrs);
<span class="p_chunk">@@ -73,7 +73,7 @@</span> <span class="p_context"> static inline unsigned long device_to_mask(struct device *dev)</span>
 #ifdef CONFIG_PPC64
 extern struct dma_map_ops dma_iommu_ops;
 #endif
<span class="p_del">-extern const struct dma_map_ops dma_direct_ops;</span>
<span class="p_add">+extern const struct dma_map_ops dma_nommu_ops;</span>
 
 static inline const struct dma_map_ops *get_arch_dma_ops(struct bus_type *bus)
 {
<span class="p_header">diff --git a/arch/powerpc/kernel/dma-iommu.c b/arch/powerpc/kernel/dma-iommu.c</span>
<span class="p_header">index 66f33e7f8d40..f9fe2080ceb9 100644</span>
<span class="p_header">--- a/arch/powerpc/kernel/dma-iommu.c</span>
<span class="p_header">+++ b/arch/powerpc/kernel/dma-iommu.c</span>
<span class="p_chunk">@@ -114,7 +114,7 @@</span> <span class="p_context"> int dma_iommu_mapping_error(struct device *dev, dma_addr_t dma_addr)</span>
 struct dma_map_ops dma_iommu_ops = {
 	.alloc			= dma_iommu_alloc_coherent,
 	.free			= dma_iommu_free_coherent,
<span class="p_del">-	.mmap			= dma_direct_mmap_coherent,</span>
<span class="p_add">+	.mmap			= dma_nommu_mmap_coherent,</span>
 	.map_sg			= dma_iommu_map_sg,
 	.unmap_sg		= dma_iommu_unmap_sg,
 	.dma_supported		= dma_iommu_dma_supported,
<span class="p_header">diff --git a/arch/powerpc/kernel/dma-swiotlb.c b/arch/powerpc/kernel/dma-swiotlb.c</span>
<span class="p_header">index d0ea7860e02b..f1e99b9cee97 100644</span>
<span class="p_header">--- a/arch/powerpc/kernel/dma-swiotlb.c</span>
<span class="p_header">+++ b/arch/powerpc/kernel/dma-swiotlb.c</span>
<span class="p_chunk">@@ -47,9 +47,9 @@</span> <span class="p_context"> static u64 swiotlb_powerpc_get_required(struct device *dev)</span>
  * for everything else.
  */
 const struct dma_map_ops swiotlb_dma_ops = {
<span class="p_del">-	.alloc = __dma_direct_alloc_coherent,</span>
<span class="p_del">-	.free = __dma_direct_free_coherent,</span>
<span class="p_del">-	.mmap = dma_direct_mmap_coherent,</span>
<span class="p_add">+	.alloc = __dma_nommu_alloc_coherent,</span>
<span class="p_add">+	.free = __dma_nommu_free_coherent,</span>
<span class="p_add">+	.mmap = dma_nommu_mmap_coherent,</span>
 	.map_sg = swiotlb_map_sg_attrs,
 	.unmap_sg = swiotlb_unmap_sg_attrs,
 	.dma_supported = swiotlb_dma_supported,
<span class="p_header">diff --git a/arch/powerpc/kernel/dma.c b/arch/powerpc/kernel/dma.c</span>
<span class="p_header">index df0e7bb97ab5..5d49da094a93 100644</span>
<span class="p_header">--- a/arch/powerpc/kernel/dma.c</span>
<span class="p_header">+++ b/arch/powerpc/kernel/dma.c</span>
<span class="p_chunk">@@ -40,7 +40,7 @@</span> <span class="p_context"> static u64 __maybe_unused get_pfn_limit(struct device *dev)</span>
 	return pfn;
 }
 
<span class="p_del">-static int dma_direct_dma_supported(struct device *dev, u64 mask)</span>
<span class="p_add">+static int dma_nommu_dma_supported(struct device *dev, u64 mask)</span>
 {
 #ifdef CONFIG_PPC64
 	u64 limit = get_dma_offset(dev) + (memblock_end_of_DRAM() - 1);
<span class="p_chunk">@@ -62,7 +62,7 @@</span> <span class="p_context"> static int dma_direct_dma_supported(struct device *dev, u64 mask)</span>
 #endif
 }
 
<span class="p_del">-void *__dma_direct_alloc_coherent(struct device *dev, size_t size,</span>
<span class="p_add">+void *__dma_nommu_alloc_coherent(struct device *dev, size_t size,</span>
 				  dma_addr_t *dma_handle, gfp_t flag,
 				  unsigned long attrs)
 {
<span class="p_chunk">@@ -119,7 +119,7 @@</span> <span class="p_context"> void *__dma_direct_alloc_coherent(struct device *dev, size_t size,</span>
 #endif
 }
 
<span class="p_del">-void __dma_direct_free_coherent(struct device *dev, size_t size,</span>
<span class="p_add">+void __dma_nommu_free_coherent(struct device *dev, size_t size,</span>
 				void *vaddr, dma_addr_t dma_handle,
 				unsigned long attrs)
 {
<span class="p_chunk">@@ -130,7 +130,7 @@</span> <span class="p_context"> void __dma_direct_free_coherent(struct device *dev, size_t size,</span>
 #endif
 }
 
<span class="p_del">-static void *dma_direct_alloc_coherent(struct device *dev, size_t size,</span>
<span class="p_add">+static void *dma_nommu_alloc_coherent(struct device *dev, size_t size,</span>
 				       dma_addr_t *dma_handle, gfp_t flag,
 				       unsigned long attrs)
 {
<span class="p_chunk">@@ -139,8 +139,8 @@</span> <span class="p_context"> static void *dma_direct_alloc_coherent(struct device *dev, size_t size,</span>
 	/* The coherent mask may be smaller than the real mask, check if
 	 * we can really use the direct ops
 	 */
<span class="p_del">-	if (dma_direct_dma_supported(dev, dev-&gt;coherent_dma_mask))</span>
<span class="p_del">-		return __dma_direct_alloc_coherent(dev, size, dma_handle,</span>
<span class="p_add">+	if (dma_nommu_dma_supported(dev, dev-&gt;coherent_dma_mask))</span>
<span class="p_add">+		return __dma_nommu_alloc_coherent(dev, size, dma_handle,</span>
 						   flag, attrs);
 
 	/* Ok we can&#39;t ... do we have an iommu ? If not, fail */
<span class="p_chunk">@@ -154,15 +154,15 @@</span> <span class="p_context"> static void *dma_direct_alloc_coherent(struct device *dev, size_t size,</span>
 				    dev_to_node(dev));
 }
 
<span class="p_del">-static void dma_direct_free_coherent(struct device *dev, size_t size,</span>
<span class="p_add">+static void dma_nommu_free_coherent(struct device *dev, size_t size,</span>
 				     void *vaddr, dma_addr_t dma_handle,
 				     unsigned long attrs)
 {
 	struct iommu_table *iommu;
 
<span class="p_del">-	/* See comments in dma_direct_alloc_coherent() */</span>
<span class="p_del">-	if (dma_direct_dma_supported(dev, dev-&gt;coherent_dma_mask))</span>
<span class="p_del">-		return __dma_direct_free_coherent(dev, size, vaddr, dma_handle,</span>
<span class="p_add">+	/* See comments in dma_nommu_alloc_coherent() */</span>
<span class="p_add">+	if (dma_nommu_dma_supported(dev, dev-&gt;coherent_dma_mask))</span>
<span class="p_add">+		return __dma_nommu_free_coherent(dev, size, vaddr, dma_handle,</span>
 						  attrs);
 	/* Maybe we used an iommu ... */
 	iommu = get_iommu_table_base(dev);
<span class="p_chunk">@@ -175,7 +175,7 @@</span> <span class="p_context"> static void dma_direct_free_coherent(struct device *dev, size_t size,</span>
 	iommu_free_coherent(iommu, size, vaddr, dma_handle);
 }
 
<span class="p_del">-int dma_direct_mmap_coherent(struct device *dev, struct vm_area_struct *vma,</span>
<span class="p_add">+int dma_nommu_mmap_coherent(struct device *dev, struct vm_area_struct *vma,</span>
 			     void *cpu_addr, dma_addr_t handle, size_t size,
 			     unsigned long attrs)
 {
<span class="p_chunk">@@ -193,7 +193,7 @@</span> <span class="p_context"> int dma_direct_mmap_coherent(struct device *dev, struct vm_area_struct *vma,</span>
 			       vma-&gt;vm_page_prot);
 }
 
<span class="p_del">-static int dma_direct_map_sg(struct device *dev, struct scatterlist *sgl,</span>
<span class="p_add">+static int dma_nommu_map_sg(struct device *dev, struct scatterlist *sgl,</span>
 			     int nents, enum dma_data_direction direction,
 			     unsigned long attrs)
 {
<span class="p_chunk">@@ -213,13 +213,13 @@</span> <span class="p_context"> static int dma_direct_map_sg(struct device *dev, struct scatterlist *sgl,</span>
 	return nents;
 }
 
<span class="p_del">-static void dma_direct_unmap_sg(struct device *dev, struct scatterlist *sg,</span>
<span class="p_add">+static void dma_nommu_unmap_sg(struct device *dev, struct scatterlist *sg,</span>
 				int nents, enum dma_data_direction direction,
 				unsigned long attrs)
 {
 }
 
<span class="p_del">-static u64 dma_direct_get_required_mask(struct device *dev)</span>
<span class="p_add">+static u64 dma_nommu_get_required_mask(struct device *dev)</span>
 {
 	u64 end, mask;
 
<span class="p_chunk">@@ -231,7 +231,7 @@</span> <span class="p_context"> static u64 dma_direct_get_required_mask(struct device *dev)</span>
 	return mask;
 }
 
<span class="p_del">-static inline dma_addr_t dma_direct_map_page(struct device *dev,</span>
<span class="p_add">+static inline dma_addr_t dma_nommu_map_page(struct device *dev,</span>
 					     struct page *page,
 					     unsigned long offset,
 					     size_t size,
<span class="p_chunk">@@ -246,7 +246,7 @@</span> <span class="p_context"> static inline dma_addr_t dma_direct_map_page(struct device *dev,</span>
 	return page_to_phys(page) + offset + get_dma_offset(dev);
 }
 
<span class="p_del">-static inline void dma_direct_unmap_page(struct device *dev,</span>
<span class="p_add">+static inline void dma_nommu_unmap_page(struct device *dev,</span>
 					 dma_addr_t dma_address,
 					 size_t size,
 					 enum dma_data_direction direction,
<span class="p_chunk">@@ -255,7 +255,7 @@</span> <span class="p_context"> static inline void dma_direct_unmap_page(struct device *dev,</span>
 }
 
 #ifdef CONFIG_NOT_COHERENT_CACHE
<span class="p_del">-static inline void dma_direct_sync_sg(struct device *dev,</span>
<span class="p_add">+static inline void dma_nommu_sync_sg(struct device *dev,</span>
 		struct scatterlist *sgl, int nents,
 		enum dma_data_direction direction)
 {
<span class="p_chunk">@@ -266,7 +266,7 @@</span> <span class="p_context"> static inline void dma_direct_sync_sg(struct device *dev,</span>
 		__dma_sync_page(sg_page(sg), sg-&gt;offset, sg-&gt;length, direction);
 }
 
<span class="p_del">-static inline void dma_direct_sync_single(struct device *dev,</span>
<span class="p_add">+static inline void dma_nommu_sync_single(struct device *dev,</span>
 					  dma_addr_t dma_handle, size_t size,
 					  enum dma_data_direction direction)
 {
<span class="p_chunk">@@ -274,25 +274,25 @@</span> <span class="p_context"> static inline void dma_direct_sync_single(struct device *dev,</span>
 }
 #endif
 
<span class="p_del">-const struct dma_map_ops dma_direct_ops = {</span>
<span class="p_del">-	.alloc				= dma_direct_alloc_coherent,</span>
<span class="p_del">-	.free				= dma_direct_free_coherent,</span>
<span class="p_del">-	.mmap				= dma_direct_mmap_coherent,</span>
<span class="p_del">-	.map_sg				= dma_direct_map_sg,</span>
<span class="p_del">-	.unmap_sg			= dma_direct_unmap_sg,</span>
<span class="p_del">-	.dma_supported			= dma_direct_dma_supported,</span>
<span class="p_del">-	.map_page			= dma_direct_map_page,</span>
<span class="p_del">-	.unmap_page			= dma_direct_unmap_page,</span>
<span class="p_del">-	.get_required_mask		= dma_direct_get_required_mask,</span>
<span class="p_add">+const struct dma_map_ops dma_nommu_ops = {</span>
<span class="p_add">+	.alloc				= dma_nommu_alloc_coherent,</span>
<span class="p_add">+	.free				= dma_nommu_free_coherent,</span>
<span class="p_add">+	.mmap				= dma_nommu_mmap_coherent,</span>
<span class="p_add">+	.map_sg				= dma_nommu_map_sg,</span>
<span class="p_add">+	.unmap_sg			= dma_nommu_unmap_sg,</span>
<span class="p_add">+	.dma_supported			= dma_nommu_dma_supported,</span>
<span class="p_add">+	.map_page			= dma_nommu_map_page,</span>
<span class="p_add">+	.unmap_page			= dma_nommu_unmap_page,</span>
<span class="p_add">+	.get_required_mask		= dma_nommu_get_required_mask,</span>
 #ifdef CONFIG_NOT_COHERENT_CACHE
<span class="p_del">-	.sync_single_for_cpu 		= dma_direct_sync_single,</span>
<span class="p_del">-	.sync_single_for_device 	= dma_direct_sync_single,</span>
<span class="p_del">-	.sync_sg_for_cpu 		= dma_direct_sync_sg,</span>
<span class="p_del">-	.sync_sg_for_device 		= dma_direct_sync_sg,</span>
<span class="p_add">+	.sync_single_for_cpu 		= dma_nommu_sync_single,</span>
<span class="p_add">+	.sync_single_for_device 	= dma_nommu_sync_single,</span>
<span class="p_add">+	.sync_sg_for_cpu 		= dma_nommu_sync_sg,</span>
<span class="p_add">+	.sync_sg_for_device 		= dma_nommu_sync_sg,</span>
 #endif
 	.is_phys			= true,
 };
<span class="p_del">-EXPORT_SYMBOL(dma_direct_ops);</span>
<span class="p_add">+EXPORT_SYMBOL(dma_nommu_ops);</span>
 
 int dma_set_coherent_mask(struct device *dev, u64 mask)
 {
<span class="p_chunk">@@ -303,7 +303,7 @@</span> <span class="p_context"> int dma_set_coherent_mask(struct device *dev, u64 mask)</span>
 		 * is no dma_op-&gt;set_coherent_mask() so we have to do
 		 * things the hard way:
 		 */
<span class="p_del">-		if (get_dma_ops(dev) != &amp;dma_direct_ops ||</span>
<span class="p_add">+		if (get_dma_ops(dev) != &amp;dma_nommu_ops ||</span>
 		    get_iommu_table_base(dev) == NULL ||
 		    !dma_iommu_dma_supported(dev, mask))
 			return -EIO;
<span class="p_header">diff --git a/arch/powerpc/kernel/pci-common.c b/arch/powerpc/kernel/pci-common.c</span>
<span class="p_header">index 0ac7aa346c69..590f4d0a6cb1 100644</span>
<span class="p_header">--- a/arch/powerpc/kernel/pci-common.c</span>
<span class="p_header">+++ b/arch/powerpc/kernel/pci-common.c</span>
<span class="p_chunk">@@ -60,7 +60,7 @@</span> <span class="p_context"> resource_size_t isa_mem_base;</span>
 EXPORT_SYMBOL(isa_mem_base);
 
 
<span class="p_del">-static const struct dma_map_ops *pci_dma_ops = &amp;dma_direct_ops;</span>
<span class="p_add">+static const struct dma_map_ops *pci_dma_ops = &amp;dma_nommu_ops;</span>
 
 void set_pci_dma_ops(const struct dma_map_ops *dma_ops)
 {
<span class="p_header">diff --git a/arch/powerpc/kernel/setup-common.c b/arch/powerpc/kernel/setup-common.c</span>
<span class="p_header">index 9d213542a48b..9b89df1e71ab 100644</span>
<span class="p_header">--- a/arch/powerpc/kernel/setup-common.c</span>
<span class="p_header">+++ b/arch/powerpc/kernel/setup-common.c</span>
<span class="p_chunk">@@ -791,7 +791,7 @@</span> <span class="p_context"> void arch_setup_pdev_archdata(struct platform_device *pdev)</span>
 {
 	pdev-&gt;archdata.dma_mask = DMA_BIT_MASK(32);
 	pdev-&gt;dev.dma_mask = &amp;pdev-&gt;archdata.dma_mask;
<span class="p_del">- 	set_dma_ops(&amp;pdev-&gt;dev, &amp;dma_direct_ops);</span>
<span class="p_add">+ 	set_dma_ops(&amp;pdev-&gt;dev, &amp;dma_nommu_ops);</span>
 }
 
 static __init void print_system_info(void)
<span class="p_header">diff --git a/arch/powerpc/platforms/cell/iommu.c b/arch/powerpc/platforms/cell/iommu.c</span>
<span class="p_header">index 4b91ad08eefd..12352a58072a 100644</span>
<span class="p_header">--- a/arch/powerpc/platforms/cell/iommu.c</span>
<span class="p_header">+++ b/arch/powerpc/platforms/cell/iommu.c</span>
<span class="p_chunk">@@ -541,7 +541,7 @@</span> <span class="p_context"> static struct cbe_iommu *cell_iommu_for_node(int nid)</span>
 	return NULL;
 }
 
<span class="p_del">-static unsigned long cell_dma_direct_offset;</span>
<span class="p_add">+static unsigned long cell_dma_nommu_offset;</span>
 
 static unsigned long dma_iommu_fixed_base;
 
<span class="p_chunk">@@ -580,7 +580,7 @@</span> <span class="p_context"> static void *dma_fixed_alloc_coherent(struct device *dev, size_t size,</span>
 					    device_to_mask(dev), flag,
 					    dev_to_node(dev));
 	else
<span class="p_del">-		return dma_direct_ops.alloc(dev, size, dma_handle, flag,</span>
<span class="p_add">+		return dma_nommu_ops.alloc(dev, size, dma_handle, flag,</span>
 					    attrs);
 }
 
<span class="p_chunk">@@ -592,7 +592,7 @@</span> <span class="p_context"> static void dma_fixed_free_coherent(struct device *dev, size_t size,</span>
 		iommu_free_coherent(cell_get_iommu_table(dev), size, vaddr,
 				    dma_handle);
 	else
<span class="p_del">-		dma_direct_ops.free(dev, size, vaddr, dma_handle, attrs);</span>
<span class="p_add">+		dma_nommu_ops.free(dev, size, vaddr, dma_handle, attrs);</span>
 }
 
 static dma_addr_t dma_fixed_map_page(struct device *dev, struct page *page,
<span class="p_chunk">@@ -601,7 +601,7 @@</span> <span class="p_context"> static dma_addr_t dma_fixed_map_page(struct device *dev, struct page *page,</span>
 				     unsigned long attrs)
 {
 	if (iommu_fixed_is_weak == (attrs &amp; DMA_ATTR_WEAK_ORDERING))
<span class="p_del">-		return dma_direct_ops.map_page(dev, page, offset, size,</span>
<span class="p_add">+		return dma_nommu_ops.map_page(dev, page, offset, size,</span>
 					       direction, attrs);
 	else
 		return iommu_map_page(dev, cell_get_iommu_table(dev), page,
<span class="p_chunk">@@ -614,7 +614,7 @@</span> <span class="p_context"> static void dma_fixed_unmap_page(struct device *dev, dma_addr_t dma_addr,</span>
 				 unsigned long attrs)
 {
 	if (iommu_fixed_is_weak == (attrs &amp; DMA_ATTR_WEAK_ORDERING))
<span class="p_del">-		dma_direct_ops.unmap_page(dev, dma_addr, size, direction,</span>
<span class="p_add">+		dma_nommu_ops.unmap_page(dev, dma_addr, size, direction,</span>
 					  attrs);
 	else
 		iommu_unmap_page(cell_get_iommu_table(dev), dma_addr, size,
<span class="p_chunk">@@ -626,7 +626,7 @@</span> <span class="p_context"> static int dma_fixed_map_sg(struct device *dev, struct scatterlist *sg,</span>
 			   unsigned long attrs)
 {
 	if (iommu_fixed_is_weak == (attrs &amp; DMA_ATTR_WEAK_ORDERING))
<span class="p_del">-		return dma_direct_ops.map_sg(dev, sg, nents, direction, attrs);</span>
<span class="p_add">+		return dma_nommu_ops.map_sg(dev, sg, nents, direction, attrs);</span>
 	else
 		return ppc_iommu_map_sg(dev, cell_get_iommu_table(dev), sg,
 					nents, device_to_mask(dev),
<span class="p_chunk">@@ -638,7 +638,7 @@</span> <span class="p_context"> static void dma_fixed_unmap_sg(struct device *dev, struct scatterlist *sg,</span>
 			       unsigned long attrs)
 {
 	if (iommu_fixed_is_weak == (attrs &amp; DMA_ATTR_WEAK_ORDERING))
<span class="p_del">-		dma_direct_ops.unmap_sg(dev, sg, nents, direction, attrs);</span>
<span class="p_add">+		dma_nommu_ops.unmap_sg(dev, sg, nents, direction, attrs);</span>
 	else
 		ppc_iommu_unmap_sg(cell_get_iommu_table(dev), sg, nents,
 				   direction, attrs);
<span class="p_chunk">@@ -661,8 +661,8 @@</span> <span class="p_context"> static void cell_dma_dev_setup(struct device *dev)</span>
 {
 	if (get_pci_dma_ops() == &amp;dma_iommu_ops)
 		set_iommu_table_base(dev, cell_get_iommu_table(dev));
<span class="p_del">-	else if (get_pci_dma_ops() == &amp;dma_direct_ops)</span>
<span class="p_del">-		set_dma_offset(dev, cell_dma_direct_offset);</span>
<span class="p_add">+	else if (get_pci_dma_ops() == &amp;dma_nommu_ops)</span>
<span class="p_add">+		set_dma_offset(dev, cell_dma_nommu_offset);</span>
 	else
 		BUG();
 }
<span class="p_chunk">@@ -810,14 +810,14 @@</span> <span class="p_context"> static int __init cell_iommu_init_disabled(void)</span>
 	unsigned long base = 0, size;
 
 	/* When no iommu is present, we use direct DMA ops */
<span class="p_del">-	set_pci_dma_ops(&amp;dma_direct_ops);</span>
<span class="p_add">+	set_pci_dma_ops(&amp;dma_nommu_ops);</span>
 
 	/* First make sure all IOC translation is turned off */
 	cell_disable_iommus();
 
 	/* If we have no Axon, we set up the spider DMA magic offset */
 	if (of_find_node_by_name(NULL, &quot;axon&quot;) == NULL)
<span class="p_del">-		cell_dma_direct_offset = SPIDER_DMA_OFFSET;</span>
<span class="p_add">+		cell_dma_nommu_offset = SPIDER_DMA_OFFSET;</span>
 
 	/* Now we need to check to see where the memory is mapped
 	 * in PCI space. We assume that all busses use the same dma
<span class="p_chunk">@@ -851,13 +851,13 @@</span> <span class="p_context"> static int __init cell_iommu_init_disabled(void)</span>
 		return -ENODEV;
 	}
 
<span class="p_del">-	cell_dma_direct_offset += base;</span>
<span class="p_add">+	cell_dma_nommu_offset += base;</span>
 
<span class="p_del">-	if (cell_dma_direct_offset != 0)</span>
<span class="p_add">+	if (cell_dma_nommu_offset != 0)</span>
 		cell_pci_controller_ops.dma_dev_setup = cell_pci_dma_dev_setup;
 
 	printk(&quot;iommu: disabled, direct DMA offset is 0x%lx\n&quot;,
<span class="p_del">-	       cell_dma_direct_offset);</span>
<span class="p_add">+	       cell_dma_nommu_offset);</span>
 
 	return 0;
 }
<span class="p_header">diff --git a/arch/powerpc/platforms/pasemi/iommu.c b/arch/powerpc/platforms/pasemi/iommu.c</span>
<span class="p_header">index 7fec04de27fc..78b80cbd9768 100644</span>
<span class="p_header">--- a/arch/powerpc/platforms/pasemi/iommu.c</span>
<span class="p_header">+++ b/arch/powerpc/platforms/pasemi/iommu.c</span>
<span class="p_chunk">@@ -186,7 +186,7 @@</span> <span class="p_context"> static void pci_dma_dev_setup_pasemi(struct pci_dev *dev)</span>
 	 */
 	if (dev-&gt;vendor == 0x1959 &amp;&amp; dev-&gt;device == 0xa007 &amp;&amp;
 	    !firmware_has_feature(FW_FEATURE_LPAR)) {
<span class="p_del">-		dev-&gt;dev.dma_ops = &amp;dma_direct_ops;</span>
<span class="p_add">+		dev-&gt;dev.dma_ops = &amp;dma_nommu_ops;</span>
 		/*
 		 * Set the coherent DMA mask to prevent the iommu
 		 * being used unnecessarily
<span class="p_header">diff --git a/arch/powerpc/platforms/pasemi/setup.c b/arch/powerpc/platforms/pasemi/setup.c</span>
<span class="p_header">index c4a3e93dc324..d0b8ae53660d 100644</span>
<span class="p_header">--- a/arch/powerpc/platforms/pasemi/setup.c</span>
<span class="p_header">+++ b/arch/powerpc/platforms/pasemi/setup.c</span>
<span class="p_chunk">@@ -363,7 +363,7 @@</span> <span class="p_context"> static int pcmcia_notify(struct notifier_block *nb, unsigned long action,</span>
 		return 0;
 
 	/* We use the direct ops for localbus */
<span class="p_del">-	dev-&gt;dma_ops = &amp;dma_direct_ops;</span>
<span class="p_add">+	dev-&gt;dma_ops = &amp;dma_nommu_ops;</span>
 
 	return 0;
 }
<span class="p_header">diff --git a/arch/powerpc/platforms/powernv/pci-ioda.c b/arch/powerpc/platforms/powernv/pci-ioda.c</span>
<span class="p_header">index 749055553064..9582aeb1fe4c 100644</span>
<span class="p_header">--- a/arch/powerpc/platforms/powernv/pci-ioda.c</span>
<span class="p_header">+++ b/arch/powerpc/platforms/powernv/pci-ioda.c</span>
<span class="p_chunk">@@ -1850,7 +1850,7 @@</span> <span class="p_context"> static int pnv_pci_ioda_dma_set_mask(struct pci_dev *pdev, u64 dma_mask)</span>
 
 	if (bypass) {
 		dev_info(&amp;pdev-&gt;dev, &quot;Using 64-bit DMA iommu bypass\n&quot;);
<span class="p_del">-		set_dma_ops(&amp;pdev-&gt;dev, &amp;dma_direct_ops);</span>
<span class="p_add">+		set_dma_ops(&amp;pdev-&gt;dev, &amp;dma_nommu_ops);</span>
 	} else {
 		/*
 		 * If the device can&#39;t set the TCE bypass bit but still wants
<span class="p_chunk">@@ -1868,7 +1868,7 @@</span> <span class="p_context"> static int pnv_pci_ioda_dma_set_mask(struct pci_dev *pdev, u64 dma_mask)</span>
 				return rc;
 			/* 4GB offset bypasses 32-bit space */
 			set_dma_offset(&amp;pdev-&gt;dev, (1ULL &lt;&lt; 32));
<span class="p_del">-			set_dma_ops(&amp;pdev-&gt;dev, &amp;dma_direct_ops);</span>
<span class="p_add">+			set_dma_ops(&amp;pdev-&gt;dev, &amp;dma_nommu_ops);</span>
 		} else if (dma_mask &gt;&gt; 32 &amp;&amp; dma_mask != DMA_BIT_MASK(64)) {
 			/*
 			 * Fail the request if a DMA mask between 32 and 64 bits
<span class="p_header">diff --git a/arch/powerpc/platforms/pseries/iommu.c b/arch/powerpc/platforms/pseries/iommu.c</span>
<span class="p_header">index 69921f72e2da..eaa11334fc8c 100644</span>
<span class="p_header">--- a/arch/powerpc/platforms/pseries/iommu.c</span>
<span class="p_header">+++ b/arch/powerpc/platforms/pseries/iommu.c</span>
<span class="p_chunk">@@ -1231,7 +1231,7 @@</span> <span class="p_context"> static int dma_set_mask_pSeriesLP(struct device *dev, u64 dma_mask)</span>
 			if (dma_offset != 0) {
 				dev_info(dev, &quot;Using 64-bit direct DMA at offset %llx\n&quot;, dma_offset);
 				set_dma_offset(dev, dma_offset);
<span class="p_del">-				set_dma_ops(dev, &amp;dma_direct_ops);</span>
<span class="p_add">+				set_dma_ops(dev, &amp;dma_nommu_ops);</span>
 				ddw_enabled = true;
 			}
 		}
<span class="p_header">diff --git a/arch/powerpc/platforms/pseries/vio.c b/arch/powerpc/platforms/pseries/vio.c</span>
<span class="p_header">index d86938260a86..49e04ec19238 100644</span>
<span class="p_header">--- a/arch/powerpc/platforms/pseries/vio.c</span>
<span class="p_header">+++ b/arch/powerpc/platforms/pseries/vio.c</span>
<span class="p_chunk">@@ -618,7 +618,7 @@</span> <span class="p_context"> static u64 vio_dma_get_required_mask(struct device *dev)</span>
 static const struct dma_map_ops vio_dma_mapping_ops = {
 	.alloc             = vio_dma_iommu_alloc_coherent,
 	.free              = vio_dma_iommu_free_coherent,
<span class="p_del">-	.mmap		   = dma_direct_mmap_coherent,</span>
<span class="p_add">+	.mmap		   = dma_nommu_mmap_coherent,</span>
 	.map_sg            = vio_dma_iommu_map_sg,
 	.unmap_sg          = vio_dma_iommu_unmap_sg,
 	.map_page          = vio_dma_iommu_map_page,
<span class="p_header">diff --git a/arch/powerpc/sysdev/dart_iommu.c b/arch/powerpc/sysdev/dart_iommu.c</span>
<span class="p_header">index 3573d54b2770..a6198d4f0f03 100644</span>
<span class="p_header">--- a/arch/powerpc/sysdev/dart_iommu.c</span>
<span class="p_header">+++ b/arch/powerpc/sysdev/dart_iommu.c</span>
<span class="p_chunk">@@ -402,7 +402,7 @@</span> <span class="p_context"> static int dart_dma_set_mask(struct device *dev, u64 dma_mask)</span>
 	 */
 	if (dart_device_on_pcie(dev) &amp;&amp; dma_mask &gt;= DMA_BIT_MASK(40)) {
 		dev_info(dev, &quot;Using 64-bit DMA iommu bypass\n&quot;);
<span class="p_del">-		set_dma_ops(dev, &amp;dma_direct_ops);</span>
<span class="p_add">+		set_dma_ops(dev, &amp;dma_nommu_ops);</span>
 	} else {
 		dev_info(dev, &quot;Using 32-bit DMA via iommu\n&quot;);
 		set_dma_ops(dev, &amp;dma_iommu_ops);
<span class="p_chunk">@@ -446,7 +446,7 @@</span> <span class="p_context"> void __init iommu_init_early_dart(struct pci_controller_ops *controller_ops)</span>
 	controller_ops-&gt;dma_bus_setup = NULL;
 
 	/* Setup pci_dma ops */
<span class="p_del">-	set_pci_dma_ops(&amp;dma_direct_ops);</span>
<span class="p_add">+	set_pci_dma_ops(&amp;dma_nommu_ops);</span>
 }
 
 #ifdef CONFIG_PM
<span class="p_header">diff --git a/arch/powerpc/sysdev/fsl_pci.c b/arch/powerpc/sysdev/fsl_pci.c</span>
<span class="p_header">index 22d98057f773..e4d0133bbeeb 100644</span>
<span class="p_header">--- a/arch/powerpc/sysdev/fsl_pci.c</span>
<span class="p_header">+++ b/arch/powerpc/sysdev/fsl_pci.c</span>
<span class="p_chunk">@@ -135,7 +135,7 @@</span> <span class="p_context"> static int fsl_pci_dma_set_mask(struct device *dev, u64 dma_mask)</span>
 	 * mapping that allows addressing any RAM address from across PCI.
 	 */
 	if (dev_is_pci(dev) &amp;&amp; dma_mask &gt;= pci64_dma_offset * 2 - 1) {
<span class="p_del">-		set_dma_ops(dev, &amp;dma_direct_ops);</span>
<span class="p_add">+		set_dma_ops(dev, &amp;dma_nommu_ops);</span>
 		set_dma_offset(dev, pci64_dma_offset);
 	}
 
<span class="p_header">diff --git a/drivers/misc/cxl/vphb.c b/drivers/misc/cxl/vphb.c</span>
<span class="p_header">index 512a4897dbf6..7fd0bdc1436a 100644</span>
<span class="p_header">--- a/drivers/misc/cxl/vphb.c</span>
<span class="p_header">+++ b/drivers/misc/cxl/vphb.c</span>
<span class="p_chunk">@@ -54,7 +54,7 @@</span> <span class="p_context"> static bool cxl_pci_enable_device_hook(struct pci_dev *dev)</span>
 		return false;
 	}
 
<span class="p_del">-	set_dma_ops(&amp;dev-&gt;dev, &amp;dma_direct_ops);</span>
<span class="p_add">+	set_dma_ops(&amp;dev-&gt;dev, &amp;dma_nommu_ops);</span>
 	set_dma_offset(&amp;dev-&gt;dev, PAGE_OFFSET);
 
 	return _cxl_pci_associate_default_context(dev, afu);

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



