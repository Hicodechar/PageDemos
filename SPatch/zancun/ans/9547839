
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>[v4,4/9] arm64: KVM: Handle trappable TLB instructions - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    [v4,4/9] arm64: KVM: Handle trappable TLB instructions</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=58591">Punit Agrawal</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>Jan. 31, 2017, 5:16 p.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;20170131171630.26898-5-punit.agrawal@arm.com&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/9547839/mbox/"
   >mbox</a>
|
   <a href="/patch/9547839/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/9547839/">/patch/9547839/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
	[172.30.200.125])
	by pdx-korg-patchwork.web.codeaurora.org (Postfix) with ESMTP id
	40A3A6016C for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Tue, 31 Jan 2017 17:19:50 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 336D2283EF
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Tue, 31 Jan 2017 17:19:50 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id 280AE28409; Tue, 31 Jan 2017 17:19:50 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-6.9 required=2.0 tests=BAYES_00,RCVD_IN_DNSWL_HI
	autolearn=unavailable version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 7FDCB283EF
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Tue, 31 Jan 2017 17:19:49 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1751884AbdAaRTq (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Tue, 31 Jan 2017 12:19:46 -0500
Received: from foss.arm.com ([217.140.101.70]:42750 &quot;EHLO foss.arm.com&quot;
	rhost-flags-OK-OK-OK-OK) by vger.kernel.org with ESMTP
	id S1750869AbdAaRSY (ORCPT &lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Tue, 31 Jan 2017 12:18:24 -0500
Received: from usa-sjc-imap-foss1.foss.arm.com (unknown [10.72.51.249])
	by usa-sjc-mx-foss1.foss.arm.com (Postfix) with ESMTP id 6CFAC15B2;
	Tue, 31 Jan 2017 09:17:29 -0800 (PST)
Received: from localhost (e105922-lin.cambridge.arm.com [10.1.195.25])
	by usa-sjc-imap-foss1.foss.arm.com (Postfix) with ESMTPSA id
	3F5943F24D; Tue, 31 Jan 2017 09:17:29 -0800 (PST)
From: Punit Agrawal &lt;punit.agrawal@arm.com&gt;
To: kvmarm@lists.cs.columbia.edu, linux-arm-kernel@lists.infradead.org
Cc: Punit Agrawal &lt;punit.agrawal@arm.com&gt;,
	linux-kernel@vger.kernel.org, kvm@vger.kernel.org,
	Christoffer Dall &lt;christoffer.dall@linaro.org&gt;,
	Marc Zyngier &lt;marc.zyngier@arm.com&gt;, Will Deacon &lt;will.deacon@arm.com&gt;,
	Mark Rutland &lt;mark.rutland@arm.com&gt;
Subject: [PATCH v4 4/9] arm64: KVM: Handle trappable TLB instructions
Date: Tue, 31 Jan 2017 17:16:25 +0000
Message-Id: &lt;20170131171630.26898-5-punit.agrawal@arm.com&gt;
X-Mailer: git-send-email 2.11.0
In-Reply-To: &lt;20170131171630.26898-1-punit.agrawal@arm.com&gt;
References: &lt;20170131171630.26898-1-punit.agrawal@arm.com&gt;
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=58591">Punit Agrawal</a> - Jan. 31, 2017, 5:16 p.m.</div>
<pre class="content">
The ARMv8 architecture allows trapping of TLB maintenane instructions
from EL0/EL1 to higher exception levels. On encountering a trappable TLB
instruction in a guest, an exception is taken to EL2.

Add support to handle emulating the TLB instructions. Also track the
number of emulated operations.
<span class="signed-off-by">
Signed-off-by: Punit Agrawal &lt;punit.agrawal@arm.com&gt;</span>
Cc: Christoffer Dall &lt;christoffer.dall@linaro.org&gt;
Cc: Marc Zyngier &lt;marc.zyngier@arm.com&gt;
---
 arch/arm64/include/asm/kvm_asm.h  |  2 +
 arch/arm64/include/asm/kvm_host.h |  1 +
 arch/arm64/kvm/hyp/tlb.c          | 75 +++++++++++++++++++++++++++++++++++
 arch/arm64/kvm/sys_regs.c         | 83 +++++++++++++++++++++++++++++++++++++++
 4 files changed, 161 insertions(+)
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/arch/arm64/include/asm/kvm_asm.h b/arch/arm64/include/asm/kvm_asm.h</span>
<span class="p_header">index ec3553eb9349..8b695785d454 100644</span>
<span class="p_header">--- a/arch/arm64/include/asm/kvm_asm.h</span>
<span class="p_header">+++ b/arch/arm64/include/asm/kvm_asm.h</span>
<span class="p_chunk">@@ -55,6 +55,8 @@</span> <span class="p_context"> extern void __kvm_flush_vm_context(void);</span>
 extern void __kvm_tlb_flush_vmid_ipa(struct kvm *kvm, phys_addr_t ipa);
 extern void __kvm_tlb_flush_vmid(struct kvm *kvm);
 extern void __kvm_tlb_flush_local_vmid(struct kvm_vcpu *vcpu);
<span class="p_add">+extern void __kvm_emulate_tlb_invalidate(struct kvm *kvm, u32 opcode,</span>
<span class="p_add">+					 u64 regval);</span>
 
 extern int __kvm_vcpu_run(struct kvm_vcpu *vcpu);
 
<span class="p_header">diff --git a/arch/arm64/include/asm/kvm_host.h b/arch/arm64/include/asm/kvm_host.h</span>
<span class="p_header">index e5050388e062..1e83b707f14c 100644</span>
<span class="p_header">--- a/arch/arm64/include/asm/kvm_host.h</span>
<span class="p_header">+++ b/arch/arm64/include/asm/kvm_host.h</span>
<span class="p_chunk">@@ -307,6 +307,7 @@</span> <span class="p_context"> struct kvm_vcpu_stat {</span>
 	u64 mmio_exit_user;
 	u64 mmio_exit_kernel;
 	u64 exits;
<span class="p_add">+	u64 tlb_invalidate;</span>
 };
 
 int kvm_vcpu_preferred_target(struct kvm_vcpu_init *init);
<span class="p_header">diff --git a/arch/arm64/kvm/hyp/tlb.c b/arch/arm64/kvm/hyp/tlb.c</span>
<span class="p_header">index b2cfbedea582..c14237858d75 100644</span>
<span class="p_header">--- a/arch/arm64/kvm/hyp/tlb.c</span>
<span class="p_header">+++ b/arch/arm64/kvm/hyp/tlb.c</span>
<span class="p_chunk">@@ -86,3 +86,78 @@</span> <span class="p_context"> void __hyp_text __kvm_flush_vm_context(void)</span>
 	__tlbi(alle1is);
 	__flush_icache_all(); /* contains a dsb(ish) */
 }
<span class="p_add">+</span>
<span class="p_add">+/* Intentionally empty functions */</span>
<span class="p_add">+static void __hyp_text __switch_to_hyp_role_nvhe(void) { }</span>
<span class="p_add">+static void __hyp_text __switch_to_host_role_nvhe(void) { }</span>
<span class="p_add">+</span>
<span class="p_add">+static void __hyp_text __switch_to_hyp_role_vhe(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	u64 hcr = read_sysreg(hcr_el2);</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * When VHE is enabled and HCR_EL2.TGE=1, EL1&amp;0 TLB operations</span>
<span class="p_add">+	 * apply to EL2&amp;0 translation regime. As we prepare to emulate</span>
<span class="p_add">+	 * guest TLB operation clear HCR_TGE to target TLB operations</span>
<span class="p_add">+	 * to EL1&amp;0 (guest).</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	hcr &amp;= ~HCR_TGE;</span>
<span class="p_add">+	write_sysreg(hcr, hcr_el2);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static void __hyp_text __switch_to_host_role_vhe(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	u64 hcr = read_sysreg(hcr_el2);</span>
<span class="p_add">+</span>
<span class="p_add">+	hcr |= HCR_TGE;</span>
<span class="p_add">+	write_sysreg(hcr, hcr_el2);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static hyp_alternate_select(__switch_to_hyp_role,</span>
<span class="p_add">+			    __switch_to_hyp_role_nvhe,</span>
<span class="p_add">+			    __switch_to_hyp_role_vhe,</span>
<span class="p_add">+			    ARM64_HAS_VIRT_HOST_EXTN);</span>
<span class="p_add">+</span>
<span class="p_add">+static hyp_alternate_select(__switch_to_host_role,</span>
<span class="p_add">+			    __switch_to_host_role_nvhe,</span>
<span class="p_add">+			    __switch_to_host_role_vhe,</span>
<span class="p_add">+			    ARM64_HAS_VIRT_HOST_EXTN);</span>
<span class="p_add">+</span>
<span class="p_add">+static void __hyp_text __switch_to_guest_regime(struct kvm *kvm)</span>
<span class="p_add">+{</span>
<span class="p_add">+	write_sysreg(kvm-&gt;arch.vttbr, vttbr_el2);</span>
<span class="p_add">+	__switch_to_hyp_role();</span>
<span class="p_add">+	isb();</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static void __hyp_text __switch_to_host_regime(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	__switch_to_host_role();</span>
<span class="p_add">+	write_sysreg(0, vttbr_el2);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void __hyp_text</span>
<span class="p_add">+__kvm_emulate_tlb_invalidate(struct kvm *kvm, u32 opcode, u64 regval)</span>
<span class="p_add">+{</span>
<span class="p_add">+	kvm = kern_hyp_va(kvm);</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Switch to the guest before performing any TLB operations to</span>
<span class="p_add">+	 * target the appropriate VMID</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	__switch_to_guest_regime(kvm);</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 *  TLB maintenance operations are broadcast to</span>
<span class="p_add">+	 *  inner-shareable domain when HCR_FB is set (default for</span>
<span class="p_add">+	 *  KVM).</span>
<span class="p_add">+	 *</span>
<span class="p_add">+	 *  Nuke all Stage 1 TLB entries for the VM. This will kill</span>
<span class="p_add">+	 *  performance but it&#39;s always safe to do as we don&#39;t leave</span>
<span class="p_add">+	 *  behind any strays in the TLB</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	__tlbi(vmalle1is);</span>
<span class="p_add">+	isb();</span>
<span class="p_add">+</span>
<span class="p_add">+	__switch_to_host_regime();</span>
<span class="p_add">+}</span>
<span class="p_header">diff --git a/arch/arm64/kvm/sys_regs.c b/arch/arm64/kvm/sys_regs.c</span>
<span class="p_header">index 87e7e6608cd8..12ff8cf9f18a 100644</span>
<span class="p_header">--- a/arch/arm64/kvm/sys_regs.c</span>
<span class="p_header">+++ b/arch/arm64/kvm/sys_regs.c</span>
<span class="p_chunk">@@ -791,6 +791,20 @@</span> <span class="p_context"> static bool access_pmuserenr(struct kvm_vcpu *vcpu, struct sys_reg_params *p,</span>
 	return true;
 }
 
<span class="p_add">+static bool emulate_tlb_invalidate(struct kvm_vcpu *vcpu,</span>
<span class="p_add">+				   struct sys_reg_params *p,</span>
<span class="p_add">+				   const struct sys_reg_desc *r)</span>
<span class="p_add">+{</span>
<span class="p_add">+	u32 opcode = sys_reg(p-&gt;Op0, p-&gt;Op1, p-&gt;CRn, p-&gt;CRm, p-&gt;Op2);</span>
<span class="p_add">+</span>
<span class="p_add">+	kvm_call_hyp(__kvm_emulate_tlb_invalidate,</span>
<span class="p_add">+		     vcpu-&gt;kvm, opcode, p-&gt;regval);</span>
<span class="p_add">+	trace_kvm_tlb_invalidate(*vcpu_pc(vcpu), opcode);</span>
<span class="p_add">+	++vcpu-&gt;stat.tlb_invalidate;</span>
<span class="p_add">+</span>
<span class="p_add">+	return true;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 /* Silly macro to expand the DBG{BCR,BVR,WVR,WCR}n_EL1 registers in one go */
 #define DBG_BCR_BVR_WCR_WVR_EL1(n)					\
 	/* DBGBVRn_EL1 */						\
<span class="p_chunk">@@ -842,6 +856,35 @@</span> <span class="p_context"> static const struct sys_reg_desc sys_reg_descs[] = {</span>
 	{ Op0(0b01), Op1(0b000), CRn(0b0111), CRm(0b1110), Op2(0b010),
 	  access_dcsw },
 
<span class="p_add">+	/*</span>
<span class="p_add">+	 * ARMv8 ARM: Table C5-4 TLB maintenance instructions</span>
<span class="p_add">+	 * (Ref: ARMv8 ARM C5.1 version: ARM DDI 0487A.j)</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	/* TLBI VMALLE1IS */</span>
<span class="p_add">+	{ Op0(1), Op1(0), CRn(8), CRm(3), Op2(0), emulate_tlb_invalidate },</span>
<span class="p_add">+	/* TLBI VAE1IS */</span>
<span class="p_add">+	{ Op0(1), Op1(0), CRn(8), CRm(3), Op2(1), emulate_tlb_invalidate },</span>
<span class="p_add">+	/* TLBI ASIDE1IS */</span>
<span class="p_add">+	{ Op0(1), Op1(0), CRn(8), CRm(3), Op2(2), emulate_tlb_invalidate },</span>
<span class="p_add">+	/* TLBI VAAE1IS */</span>
<span class="p_add">+	{ Op0(1), Op1(0), CRn(8), CRm(3), Op2(3), emulate_tlb_invalidate },</span>
<span class="p_add">+	/* TLBI VALE1IS */</span>
<span class="p_add">+	{ Op0(1), Op1(0), CRn(8), CRm(3), Op2(5), emulate_tlb_invalidate },</span>
<span class="p_add">+	/* TLBI VAALE1IS */</span>
<span class="p_add">+	{ Op0(1), Op1(0), CRn(8), CRm(3), Op2(7), emulate_tlb_invalidate },</span>
<span class="p_add">+	/* TLBI VMALLE1 */</span>
<span class="p_add">+	{ Op0(1), Op1(0), CRn(8), CRm(7), Op2(0), emulate_tlb_invalidate },</span>
<span class="p_add">+	/* TLBI VAE1 */</span>
<span class="p_add">+	{ Op0(1), Op1(0), CRn(8), CRm(7), Op2(1), emulate_tlb_invalidate },</span>
<span class="p_add">+	/* TLBI ASIDE1 */</span>
<span class="p_add">+	{ Op0(1), Op1(0), CRn(8), CRm(7), Op2(2), emulate_tlb_invalidate },</span>
<span class="p_add">+	/* TLBI VAAE1 */</span>
<span class="p_add">+	{ Op0(1), Op1(0), CRn(8), CRm(7), Op2(3), emulate_tlb_invalidate },</span>
<span class="p_add">+	/* TLBI VALE1 */</span>
<span class="p_add">+	{ Op0(1), Op1(0), CRn(8), CRm(7), Op2(5), emulate_tlb_invalidate },</span>
<span class="p_add">+	/* TLBI VAALE1 */</span>
<span class="p_add">+	{ Op0(1), Op1(0), CRn(8), CRm(7), Op2(7), emulate_tlb_invalidate },</span>
<span class="p_add">+</span>
 	DBG_BCR_BVR_WCR_WVR_EL1(0),
 	DBG_BCR_BVR_WCR_WVR_EL1(1),
 	/* MDCCINT_EL1 */
<span class="p_chunk">@@ -1330,6 +1373,46 @@</span> <span class="p_context"> static const struct sys_reg_desc cp15_regs[] = {</span>
 	{ Op1( 0), CRn( 7), CRm(10), Op2( 2), access_dcsw },
 	{ Op1( 0), CRn( 7), CRm(14), Op2( 2), access_dcsw },
 
<span class="p_add">+	/*</span>
<span class="p_add">+	 * TLB operations</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	/* TLBIALLIS */</span>
<span class="p_add">+	{ Op1( 0), CRn( 8), CRm( 3), Op2( 0), emulate_tlb_invalidate},</span>
<span class="p_add">+	/* TLBIMVAIS */</span>
<span class="p_add">+	{ Op1( 0), CRn( 8), CRm( 3), Op2( 1), emulate_tlb_invalidate},</span>
<span class="p_add">+	/* TLBIASIDIS */</span>
<span class="p_add">+	{ Op1( 0), CRn( 8), CRm( 3), Op2( 2), emulate_tlb_invalidate},</span>
<span class="p_add">+	/* TLBIMVAAIS */</span>
<span class="p_add">+	{ Op1( 0), CRn( 8), CRm( 3), Op2( 3), emulate_tlb_invalidate},</span>
<span class="p_add">+	/* TLBIMVALIS */</span>
<span class="p_add">+	{ Op1( 0), CRn( 8), CRm( 3), Op2( 5), emulate_tlb_invalidate},</span>
<span class="p_add">+	/* TLBIMVAALIS */</span>
<span class="p_add">+	{ Op1( 0), CRn( 8), CRm( 3), Op2( 7), emulate_tlb_invalidate},</span>
<span class="p_add">+	/* ITLBIALL */</span>
<span class="p_add">+	{ Op1( 0), CRn( 8), CRm( 5), Op2( 0), emulate_tlb_invalidate},</span>
<span class="p_add">+	/* ITLBIMVA */</span>
<span class="p_add">+	{ Op1( 0), CRn( 8), CRm( 5), Op2( 1), emulate_tlb_invalidate},</span>
<span class="p_add">+	/* ITLBIASID */</span>
<span class="p_add">+	{ Op1( 0), CRn( 8), CRm( 5), Op2( 2), emulate_tlb_invalidate},</span>
<span class="p_add">+	/* DTLBIALL */</span>
<span class="p_add">+	{ Op1( 0), CRn( 8), CRm( 6), Op2( 0), emulate_tlb_invalidate},</span>
<span class="p_add">+	/* DTLBIMVA */</span>
<span class="p_add">+	{ Op1( 0), CRn( 8), CRm( 6), Op2( 1), emulate_tlb_invalidate},</span>
<span class="p_add">+	/* DTLBIASID */</span>
<span class="p_add">+	{ Op1( 0), CRn( 8), CRm( 6), Op2( 2), emulate_tlb_invalidate},</span>
<span class="p_add">+	/* TLBIALL */</span>
<span class="p_add">+	{ Op1( 0), CRn( 8), CRm( 7), Op2( 0), emulate_tlb_invalidate},</span>
<span class="p_add">+	/* TLBIMVA */</span>
<span class="p_add">+	{ Op1( 0), CRn( 8), CRm( 7), Op2( 1), emulate_tlb_invalidate},</span>
<span class="p_add">+	/* TLBIASID */</span>
<span class="p_add">+	{ Op1( 0), CRn( 8), CRm( 7), Op2( 2), emulate_tlb_invalidate},</span>
<span class="p_add">+	/* TLBIMVAA */</span>
<span class="p_add">+	{ Op1( 0), CRn( 8), CRm( 7), Op2( 3), emulate_tlb_invalidate},</span>
<span class="p_add">+	/* TLBIMVAL */</span>
<span class="p_add">+	{ Op1( 0), CRn( 8), CRm( 7), Op2( 5), emulate_tlb_invalidate},</span>
<span class="p_add">+	/* TLBIMVAAL */</span>
<span class="p_add">+	{ Op1( 0), CRn( 8), CRm( 7), Op2( 7), emulate_tlb_invalidate},</span>
<span class="p_add">+</span>
 	/* PMU */
 	{ Op1( 0), CRn( 9), CRm(12), Op2( 0), access_pmcr },
 	{ Op1( 0), CRn( 9), CRm(12), Op2( 1), access_pmcnten },

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



