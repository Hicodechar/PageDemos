
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>Multiple oom_reaper BUGs: unmap_page_range racing with exit_mmap - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    Multiple oom_reaper BUGs: unmap_page_range racing with exit_mmap</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=28">Tetsuo Handa</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>Dec. 6, 2017, 11:37 a.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;201712062037.DAF90168.SVFQOJFMOOtHLF@I-love.SAKURA.ne.jp&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/10095661/mbox/"
   >mbox</a>
|
   <a href="/patch/10095661/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/10095661/">/patch/10095661/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
	[172.30.200.125])
	by pdx-korg-patchwork.web.codeaurora.org (Postfix) with ESMTP id
	70E0D60327 for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Wed,  6 Dec 2017 11:37:30 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 62B802983B
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Wed,  6 Dec 2017 11:37:30 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id 5630729CC4; Wed,  6 Dec 2017 11:37:30 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-6.9 required=2.0 tests=BAYES_00,RCVD_IN_DNSWL_HI
	autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 337052983B
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Wed,  6 Dec 2017 11:37:29 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1752119AbdLFLh0 (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Wed, 6 Dec 2017 06:37:26 -0500
Received: from www262.sakura.ne.jp ([202.181.97.72]:32525 &quot;EHLO
	www262.sakura.ne.jp&quot; rhost-flags-OK-OK-OK-OK) by vger.kernel.org
	with ESMTP id S1751894AbdLFLhV (ORCPT
	&lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Wed, 6 Dec 2017 06:37:21 -0500
Received: from fsav401.sakura.ne.jp (fsav401.sakura.ne.jp [133.242.250.100])
	by www262.sakura.ne.jp (8.14.5/8.14.5) with ESMTP id
	vB6Bb5O5035408; Wed, 6 Dec 2017 20:37:05 +0900 (JST)
	(envelope-from penguin-kernel@I-love.SAKURA.ne.jp)
Received: from www262.sakura.ne.jp (202.181.97.72) by fsav401.sakura.ne.jp
	(F-Secure/fsigk_smtp/530/fsav401.sakura.ne.jp); 
	Wed, 06 Dec 2017 20:37:05 +0900 (JST)
X-Virus-Status: clean(F-Secure/fsigk_smtp/530/fsav401.sakura.ne.jp)
Received: from AQUA (softbank126094099187.bbtec.net [126.94.99.187])
	(authenticated bits=0)
	by www262.sakura.ne.jp (8.14.5/8.14.5) with ESMTP id vB6Bb5w4035402; 
	Wed, 6 Dec 2017 20:37:05 +0900 (JST)
	(envelope-from penguin-kernel@I-love.SAKURA.ne.jp)
To: rientjes@google.com
Cc: akpm@linux-foundation.org, mhocko@suse.com, aarcange@redhat.com,
	linux-kernel@vger.kernel.org, linux-mm@kvack.org
Subject: Re: Multiple oom_reaper BUGs: unmap_page_range racing with exit_mmap
From: Tetsuo Handa &lt;penguin-kernel@I-love.SAKURA.ne.jp&gt;
References: &lt;alpine.DEB.2.10.1712051824050.91099@chino.kir.corp.google.com&gt;
	&lt;alpine.DEB.2.10.1712051857450.98120@chino.kir.corp.google.com&gt;
	&lt;201712060328.vB63SrDK069830@www262.sakura.ne.jp&gt;
	&lt;alpine.DEB.2.10.1712052323170.119719@chino.kir.corp.google.com&gt;
In-Reply-To: &lt;alpine.DEB.2.10.1712052323170.119719@chino.kir.corp.google.com&gt;
Message-Id: &lt;201712062037.DAF90168.SVFQOJFMOOtHLF@I-love.SAKURA.ne.jp&gt;
X-Mailer: Winbiff [Version 2.51 PL2]
X-Accept-Language: ja,en,zh
Date: Wed, 6 Dec 2017 20:37:06 +0900
Mime-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=28">Tetsuo Handa</a> - Dec. 6, 2017, 11:37 a.m.</div>
<pre class="content">
David Rientjes wrote:
<span class="quote">&gt; On Wed, 6 Dec 2017, Tetsuo Handa wrote:</span>
<span class="quote">&gt; &gt; Also, I don&#39;t know what exit_mmap() is doing but I think that there is a</span>
<span class="quote">&gt; &gt; possibility that the OOM reaper tries to reclaim mlocked pages as soon as</span>
<span class="quote">&gt; &gt; exit_mmap() cleared VM_LOCKED flag by calling munlock_vma_pages_all().</span>
<span class="quote">&gt; &gt; </span>
<span class="quote">&gt; &gt; 	if (mm-&gt;locked_vm) {</span>
<span class="quote">&gt; &gt; 		vma = mm-&gt;mmap;</span>
<span class="quote">&gt; &gt; 		while (vma) {</span>
<span class="quote">&gt; &gt; 			if (vma-&gt;vm_flags &amp; VM_LOCKED)</span>
<span class="quote">&gt; &gt; 				munlock_vma_pages_all(vma);</span>
<span class="quote">&gt; &gt; 			vma = vma-&gt;vm_next;</span>
<span class="quote">&gt; &gt; 		}</span>
<span class="quote">&gt; &gt; 	}</span>
<span class="quote">&gt; &gt; </span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Yes, that looks possible as well, although the problem I have reported can </span>
<span class="quote">&gt; happen with or without mlock.  Did you find this by code inspection or </span>
<span class="quote">&gt; have you experienced runtime problems with it?</span>

By code inspection.
<span class="quote">
&gt; </span>
<span class="quote">&gt; I think this argues to do MMF_REAPING-style behavior at the beginning of </span>
<span class="quote">&gt; exit_mmap() and avoid reaping all together once we have reached that </span>
<span class="quote">&gt; point.  There are no more users of the mm and we are in the process of </span>
<span class="quote">&gt; tearing it down, I&#39;m not sure that the oom reaper should be in the </span>
<span class="quote">&gt; business with trying to interfere with that.  Or are there actual bug </span>
<span class="quote">&gt; reports where an oom victim gets wedged while in exit_mmap() prior to </span>
<span class="quote">&gt; releasing its memory?</span>

If our assumption is that the OOM reaper can reclaim majority of OOM
victim&#39;s memory via victim&#39;s -&gt;signal-&gt;oom_mm, what will be wrong with
simply reverting 212925802454672e (&quot;mm: oom: let oom_reap_task and
exit_mmap run concurrently&quot;) and replace mmgrab()/mmdrop_async() with
mmget()/mmput_async() so that the OOM reaper no longer need to worry
about tricky __mmput() behavior (like shown below) ?

----------
 kernel/fork.c |   17 ++++++++++++-----
 mm/mmap.c     |   17 -----------------
 mm/oom_kill.c |   21 +++++++--------------
 3 files changed, 19 insertions(+), 36 deletions(-)

----------
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/kernel/fork.c b/kernel/fork.c</span>
<span class="p_header">index 432eadf..018a857 100644</span>
<span class="p_header">--- a/kernel/fork.c</span>
<span class="p_header">+++ b/kernel/fork.c</span>
<span class="p_chunk">@@ -394,12 +394,18 @@</span> <span class="p_context"> static inline void free_signal_struct(struct signal_struct *sig)</span>
 {
 	taskstats_tgid_free(sig);
 	sched_autogroup_exit(sig);
<span class="p_del">-	/*</span>
<span class="p_del">-	 * __mmdrop is not safe to call from softirq context on x86 due to</span>
<span class="p_del">-	 * pgd_dtor so postpone it to the async context</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	if (sig-&gt;oom_mm)</span>
<span class="p_add">+	if (sig-&gt;oom_mm) {</span>
<span class="p_add">+#ifdef CONFIG_MMU</span>
<span class="p_add">+		mmput_async(sig-&gt;oom_mm);</span>
<span class="p_add">+#else</span>
<span class="p_add">+		/*</span>
<span class="p_add">+		 * There might be archtectures where calling __mmdrop() from</span>
<span class="p_add">+		 * softirq context is not safe. Thus, postpone it to the async</span>
<span class="p_add">+		 * context.</span>
<span class="p_add">+		 */</span>
 		mmdrop_async(sig-&gt;oom_mm);
<span class="p_add">+#endif</span>
<span class="p_add">+	}</span>
 	kmem_cache_free(signal_cachep, sig);
 }
 
<span class="p_chunk">@@ -931,6 +937,7 @@</span> <span class="p_context"> static inline void __mmput(struct mm_struct *mm)</span>
 	}
 	if (mm-&gt;binfmt)
 		module_put(mm-&gt;binfmt-&gt;module);
<span class="p_add">+	set_bit(MMF_OOM_SKIP, &amp;mm-&gt;flags);</span>
 	mmdrop(mm);
 }
 
<span class="p_header">diff --git a/mm/mmap.c b/mm/mmap.c</span>
<span class="p_header">index a4d5468..fafaf06 100644</span>
<span class="p_header">--- a/mm/mmap.c</span>
<span class="p_header">+++ b/mm/mmap.c</span>
<span class="p_chunk">@@ -3019,23 +3019,6 @@</span> <span class="p_context"> void exit_mmap(struct mm_struct *mm)</span>
 	/* Use -1 here to ensure all VMAs in the mm are unmapped */
 	unmap_vmas(&amp;tlb, vma, 0, -1);
 
<span class="p_del">-	set_bit(MMF_OOM_SKIP, &amp;mm-&gt;flags);</span>
<span class="p_del">-	if (unlikely(tsk_is_oom_victim(current))) {</span>
<span class="p_del">-		/*</span>
<span class="p_del">-		 * Wait for oom_reap_task() to stop working on this</span>
<span class="p_del">-		 * mm. Because MMF_OOM_SKIP is already set before</span>
<span class="p_del">-		 * calling down_read(), oom_reap_task() will not run</span>
<span class="p_del">-		 * on this &quot;mm&quot; post up_write().</span>
<span class="p_del">-		 *</span>
<span class="p_del">-		 * tsk_is_oom_victim() cannot be set from under us</span>
<span class="p_del">-		 * either because current-&gt;mm is already set to NULL</span>
<span class="p_del">-		 * under task_lock before calling mmput and oom_mm is</span>
<span class="p_del">-		 * set not NULL by the OOM killer only if current-&gt;mm</span>
<span class="p_del">-		 * is found not NULL while holding the task_lock.</span>
<span class="p_del">-		 */</span>
<span class="p_del">-		down_write(&amp;mm-&gt;mmap_sem);</span>
<span class="p_del">-		up_write(&amp;mm-&gt;mmap_sem);</span>
<span class="p_del">-	}</span>
 	free_pgtables(&amp;tlb, vma, FIRST_USER_ADDRESS, USER_PGTABLES_CEILING);
 	tlb_finish_mmu(&amp;tlb, 0, -1);
 
<span class="p_header">diff --git a/mm/oom_kill.c b/mm/oom_kill.c</span>
<span class="p_header">index c957be3..eb2a005 100644</span>
<span class="p_header">--- a/mm/oom_kill.c</span>
<span class="p_header">+++ b/mm/oom_kill.c</span>
<span class="p_chunk">@@ -528,18 +528,6 @@</span> <span class="p_context"> static bool __oom_reap_task_mm(struct task_struct *tsk, struct mm_struct *mm)</span>
 		goto unlock_oom;
 	}
 
<span class="p_del">-	/*</span>
<span class="p_del">-	 * MMF_OOM_SKIP is set by exit_mmap when the OOM reaper can&#39;t</span>
<span class="p_del">-	 * work on the mm anymore. The check for MMF_OOM_SKIP must run</span>
<span class="p_del">-	 * under mmap_sem for reading because it serializes against the</span>
<span class="p_del">-	 * down_write();up_write() cycle in exit_mmap().</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	if (test_bit(MMF_OOM_SKIP, &amp;mm-&gt;flags)) {</span>
<span class="p_del">-		up_read(&amp;mm-&gt;mmap_sem);</span>
<span class="p_del">-		trace_skip_task_reaping(tsk-&gt;pid);</span>
<span class="p_del">-		goto unlock_oom;</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
 	trace_start_task_reaping(tsk-&gt;pid);
 
 	/*
<span class="p_chunk">@@ -683,8 +671,13 @@</span> <span class="p_context"> static void mark_oom_victim(struct task_struct *tsk)</span>
 		return;
 
 	/* oom_mm is bound to the signal struct life time. */
<span class="p_del">-	if (!cmpxchg(&amp;tsk-&gt;signal-&gt;oom_mm, NULL, mm))</span>
<span class="p_del">-		mmgrab(tsk-&gt;signal-&gt;oom_mm);</span>
<span class="p_add">+	if (!cmpxchg(&amp;tsk-&gt;signal-&gt;oom_mm, NULL, mm)) {</span>
<span class="p_add">+#ifdef CONFIG_MMU</span>
<span class="p_add">+		mmget(mm);</span>
<span class="p_add">+#else</span>
<span class="p_add">+		mmgrab(mm);</span>
<span class="p_add">+#endif</span>
<span class="p_add">+	}</span>
 
 	/*
 	 * Make sure that the task is woken up from uninterruptible sleep
<span class="p_del">----------</span>

If holding the address space when there are so many victim&#39;s mm waiting for
the OOM reaper to reclaim is considered dangerous, I think we can try direct
OOM reaping (like untested patch shown below) in order to reclaim first-blocked
first-reaped basis (and also serve as a mitigation for race caused by removing
oom_lock from the OOM reaper).

<span class="p_del">----------</span>
 include/linux/mm_types.h |   3 ++
 include/linux/sched.h    |   3 --
 mm/oom_kill.c            | 132 ++++++++++++++---------------------------------
 3 files changed, 43 insertions(+), 95 deletions(-)

<span class="p_header">diff --git a/include/linux/mm_types.h b/include/linux/mm_types.h</span>
<span class="p_header">index cfd0ac4..068119b 100644</span>
<span class="p_header">--- a/include/linux/mm_types.h</span>
<span class="p_header">+++ b/include/linux/mm_types.h</span>
<span class="p_chunk">@@ -501,6 +501,9 @@</span> <span class="p_context"> struct mm_struct {</span>
 	atomic_long_t hugetlb_usage;
 #endif
 	struct work_struct async_put_work;
<span class="p_add">+#ifdef CONFIG_MMU</span>
<span class="p_add">+	unsigned long oom_reap_started;</span>
<span class="p_add">+#endif</span>
 
 #if IS_ENABLED(CONFIG_HMM)
 	/* HMM needs to track a few things per mm */
<span class="p_header">diff --git a/include/linux/sched.h b/include/linux/sched.h</span>
<span class="p_header">index a2709d2..d63b599 100644</span>
<span class="p_header">--- a/include/linux/sched.h</span>
<span class="p_header">+++ b/include/linux/sched.h</span>
<span class="p_chunk">@@ -1081,9 +1081,6 @@</span> <span class="p_context"> struct task_struct {</span>
 	unsigned long			task_state_change;
 #endif
 	int				pagefault_disabled;
<span class="p_del">-#ifdef CONFIG_MMU</span>
<span class="p_del">-	struct task_struct		*oom_reaper_list;</span>
<span class="p_del">-#endif</span>
 #ifdef CONFIG_VMAP_STACK
 	struct vm_struct		*stack_vm_area;
 #endif
<span class="p_header">diff --git a/mm/oom_kill.c b/mm/oom_kill.c</span>
<span class="p_header">index 3b0d0fe..a9f8bae 100644</span>
<span class="p_header">--- a/mm/oom_kill.c</span>
<span class="p_header">+++ b/mm/oom_kill.c</span>
<span class="p_chunk">@@ -309,9 +309,14 @@</span> <span class="p_context"> static enum oom_constraint constrained_alloc(struct oom_control *oc)</span>
 	return CONSTRAINT_NONE;
 }
 
<span class="p_add">+#ifdef CONFIG_MMU</span>
<span class="p_add">+static void oom_reap_task_mm(struct task_struct *tsk, struct mm_struct *mm);</span>
<span class="p_add">+#endif</span>
<span class="p_add">+</span>
 static int oom_evaluate_task(struct task_struct *task, void *arg)
 {
 	struct oom_control *oc = arg;
<span class="p_add">+	struct mm_struct *mm;</span>
 	unsigned long points;
 
 	if (oom_unkillable_task(task, NULL, oc-&gt;nodemask))
<span class="p_chunk">@@ -324,7 +329,8 @@</span> <span class="p_context"> static int oom_evaluate_task(struct task_struct *task, void *arg)</span>
 	 * any memory is quite low.
 	 */
 	if (!is_sysrq_oom(oc) &amp;&amp; tsk_is_oom_victim(task)) {
<span class="p_del">-		if (test_bit(MMF_OOM_SKIP, &amp;task-&gt;signal-&gt;oom_mm-&gt;flags))</span>
<span class="p_add">+		mm = task-&gt;signal-&gt;oom_mm;</span>
<span class="p_add">+		if (test_bit(MMF_OOM_SKIP, &amp;mm-&gt;flags))</span>
 			goto next;
 		goto abort;
 	}
<span class="p_chunk">@@ -357,6 +363,15 @@</span> <span class="p_context"> static int oom_evaluate_task(struct task_struct *task, void *arg)</span>
 	if (oc-&gt;chosen)
 		put_task_struct(oc-&gt;chosen);
 	oc-&gt;chosen = (void *)-1UL;
<span class="p_add">+#ifdef CONFIG_MMU</span>
<span class="p_add">+	get_task_struct(task);</span>
<span class="p_add">+	if (!is_memcg_oom(oc))</span>
<span class="p_add">+		rcu_read_unlock();</span>
<span class="p_add">+	oom_reap_task_mm(task, mm);</span>
<span class="p_add">+	put_task_struct(task);</span>
<span class="p_add">+	if (!is_memcg_oom(oc))</span>
<span class="p_add">+		rcu_read_lock();</span>
<span class="p_add">+#endif</span>
 	return 1;
 }
 
<span class="p_chunk">@@ -474,23 +489,14 @@</span> <span class="p_context"> bool process_shares_mm(struct task_struct *p, struct mm_struct *mm)</span>
 	return false;
 }
 
<span class="p_del">-</span>
 #ifdef CONFIG_MMU
<span class="p_del">-/*</span>
<span class="p_del">- * OOM Reaper kernel thread which tries to reap the memory used by the OOM</span>
<span class="p_del">- * victim (if that is possible) to help the OOM killer to move on.</span>
<span class="p_del">- */</span>
<span class="p_del">-static struct task_struct *oom_reaper_th;</span>
<span class="p_del">-static DECLARE_WAIT_QUEUE_HEAD(oom_reaper_wait);</span>
<span class="p_del">-static struct task_struct *oom_reaper_list;</span>
<span class="p_del">-static DEFINE_SPINLOCK(oom_reaper_lock);</span>
<span class="p_del">-</span>
 static bool __oom_reap_task_mm(struct task_struct *tsk, struct mm_struct *mm)
 {
 	struct mmu_gather tlb;
 	struct vm_area_struct *vma;
 	bool ret = true;
 
<span class="p_add">+	trace_wake_reaper(tsk-&gt;pid);</span>
 	if (!down_read_trylock(&amp;mm-&gt;mmap_sem)) {
 		ret = false;
 		trace_skip_task_reaping(tsk-&gt;pid);
<span class="p_chunk">@@ -507,8 +513,8 @@</span> <span class="p_context"> static bool __oom_reap_task_mm(struct task_struct *tsk, struct mm_struct *mm)</span>
 	 * mmu_notifier_invalidate_range_{start,end} around unmap_page_range
 	 */
 	if (mm_has_notifiers(mm)) {
<span class="p_add">+		ret = false;</span>
 		up_read(&amp;mm-&gt;mmap_sem);
<span class="p_del">-		schedule_timeout_idle(HZ);</span>
 		goto unlock_oom;
 	}
 
<span class="p_chunk">@@ -567,82 +573,22 @@</span> <span class="p_context"> static bool __oom_reap_task_mm(struct task_struct *tsk, struct mm_struct *mm)</span>
 	return ret;
 }
 
<span class="p_del">-#define MAX_OOM_REAP_RETRIES 10</span>
<span class="p_del">-static void oom_reap_task(struct task_struct *tsk)</span>
<span class="p_del">-{</span>
<span class="p_del">-	int attempts = 0;</span>
<span class="p_del">-	struct mm_struct *mm = tsk-&gt;signal-&gt;oom_mm;</span>
<span class="p_del">-</span>
<span class="p_del">-	/* Retry the down_read_trylock(mmap_sem) a few times */</span>
<span class="p_del">-	while (attempts++ &lt; MAX_OOM_REAP_RETRIES &amp;&amp; !__oom_reap_task_mm(tsk, mm))</span>
<span class="p_del">-		schedule_timeout_idle(HZ/10);</span>
<span class="p_del">-</span>
<span class="p_del">-	if (attempts &lt;= MAX_OOM_REAP_RETRIES)</span>
<span class="p_del">-		goto done;</span>
<span class="p_del">-</span>
<span class="p_del">-</span>
<span class="p_del">-	pr_info(&quot;oom_reaper: unable to reap pid:%d (%s)\n&quot;,</span>
<span class="p_del">-		task_pid_nr(tsk), tsk-&gt;comm);</span>
<span class="p_del">-	debug_show_all_locks();</span>
<span class="p_del">-</span>
<span class="p_del">-done:</span>
<span class="p_del">-	tsk-&gt;oom_reaper_list = NULL;</span>
<span class="p_del">-</span>
<span class="p_del">-	/*</span>
<span class="p_del">-	 * Hide this mm from OOM killer because it has been either reaped or</span>
<span class="p_del">-	 * somebody can&#39;t call up_write(mmap_sem).</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	set_bit(MMF_OOM_SKIP, &amp;mm-&gt;flags);</span>
<span class="p_del">-</span>
<span class="p_del">-	/* Drop a reference taken by wake_oom_reaper */</span>
<span class="p_del">-	put_task_struct(tsk);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static int oom_reaper(void *unused)</span>
<span class="p_add">+static void oom_reap_task_mm(struct task_struct *tsk, struct mm_struct *mm)</span>
 {
<span class="p_del">-	while (true) {</span>
<span class="p_del">-		struct task_struct *tsk = NULL;</span>
<span class="p_del">-</span>
<span class="p_del">-		wait_event_freezable(oom_reaper_wait, oom_reaper_list != NULL);</span>
<span class="p_del">-		spin_lock(&amp;oom_reaper_lock);</span>
<span class="p_del">-		if (oom_reaper_list != NULL) {</span>
<span class="p_del">-			tsk = oom_reaper_list;</span>
<span class="p_del">-			oom_reaper_list = tsk-&gt;oom_reaper_list;</span>
<span class="p_add">+	if (__oom_reap_task_mm(tsk, mm))</span>
<span class="p_add">+		/* Hide this mm from OOM killer because we reaped it. */</span>
<span class="p_add">+		set_bit(MMF_OOM_SKIP, &amp;mm-&gt;flags);</span>
<span class="p_add">+	else if (!mm-&gt;oom_reap_started)</span>
<span class="p_add">+		mm-&gt;oom_reap_started = jiffies;</span>
<span class="p_add">+	else if (time_after(jiffies, mm-&gt;oom_reap_started + HZ)) {</span>
<span class="p_add">+		if (!mm_has_notifiers(mm)) {</span>
<span class="p_add">+			pr_info(&quot;oom_reaper: unable to reap pid:%d (%s)\n&quot;,</span>
<span class="p_add">+				task_pid_nr(tsk), tsk-&gt;comm);</span>
<span class="p_add">+			debug_show_all_locks();</span>
 		}
<span class="p_del">-		spin_unlock(&amp;oom_reaper_lock);</span>
<span class="p_del">-</span>
<span class="p_del">-		if (tsk)</span>
<span class="p_del">-			oom_reap_task(tsk);</span>
<span class="p_add">+		/* Hide this mm from OOM killer because we can&#39;t reap. */</span>
<span class="p_add">+		set_bit(MMF_OOM_SKIP, &amp;mm-&gt;flags);</span>
 	}
<span class="p_del">-</span>
<span class="p_del">-	return 0;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static void wake_oom_reaper(struct task_struct *tsk)</span>
<span class="p_del">-{</span>
<span class="p_del">-	/* tsk is already queued? */</span>
<span class="p_del">-	if (tsk == oom_reaper_list || tsk-&gt;oom_reaper_list)</span>
<span class="p_del">-		return;</span>
<span class="p_del">-</span>
<span class="p_del">-	get_task_struct(tsk);</span>
<span class="p_del">-</span>
<span class="p_del">-	spin_lock(&amp;oom_reaper_lock);</span>
<span class="p_del">-	tsk-&gt;oom_reaper_list = oom_reaper_list;</span>
<span class="p_del">-	oom_reaper_list = tsk;</span>
<span class="p_del">-	spin_unlock(&amp;oom_reaper_lock);</span>
<span class="p_del">-	trace_wake_reaper(tsk-&gt;pid);</span>
<span class="p_del">-	wake_up(&amp;oom_reaper_wait);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static int __init oom_init(void)</span>
<span class="p_del">-{</span>
<span class="p_del">-	oom_reaper_th = kthread_run(oom_reaper, NULL, &quot;oom_reaper&quot;);</span>
<span class="p_del">-	return 0;</span>
<span class="p_del">-}</span>
<span class="p_del">-subsys_initcall(oom_init)</span>
<span class="p_del">-#else</span>
<span class="p_del">-static inline void wake_oom_reaper(struct task_struct *tsk)</span>
<span class="p_del">-{</span>
 }
 #endif /* CONFIG_MMU */
 
<span class="p_chunk">@@ -825,7 +771,6 @@</span> <span class="p_context"> static void oom_kill_process(struct oom_control *oc, const char *message)</span>
 	unsigned int victim_points = 0;
 	static DEFINE_RATELIMIT_STATE(oom_rs, DEFAULT_RATELIMIT_INTERVAL,
 					      DEFAULT_RATELIMIT_BURST);
<span class="p_del">-	bool can_oom_reap = true;</span>
 
 	/*
 	 * If the task is already exiting, don&#39;t alarm the sysadmin or kill
<span class="p_chunk">@@ -835,7 +780,6 @@</span> <span class="p_context"> static void oom_kill_process(struct oom_control *oc, const char *message)</span>
 	task_lock(p);
 	if (task_will_free_mem(p)) {
 		mark_oom_victim(p);
<span class="p_del">-		wake_oom_reaper(p);</span>
 		task_unlock(p);
 		put_task_struct(p);
 		return;
<span class="p_chunk">@@ -924,7 +868,6 @@</span> <span class="p_context"> static void oom_kill_process(struct oom_control *oc, const char *message)</span>
 		if (same_thread_group(p, victim))
 			continue;
 		if (is_global_init(p)) {
<span class="p_del">-			can_oom_reap = false;</span>
 			set_bit(MMF_OOM_SKIP, &amp;mm-&gt;flags);
 			pr_info(&quot;oom killer %d (%s) has mm pinned by %d (%s)\n&quot;,
 					task_pid_nr(victim), victim-&gt;comm,
<span class="p_chunk">@@ -941,9 +884,15 @@</span> <span class="p_context"> static void oom_kill_process(struct oom_control *oc, const char *message)</span>
 	}
 	rcu_read_unlock();
 
<span class="p_del">-	if (can_oom_reap)</span>
<span class="p_del">-		wake_oom_reaper(victim);</span>
<span class="p_del">-</span>
<span class="p_add">+#ifdef CONFIG_MMU</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * sysctl_oom_kill_allocating_task case could get stuck because</span>
<span class="p_add">+	 * select_bad_process() which calls oom_reap_task_mm() is not called.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	if (sysctl_oom_kill_allocating_task &amp;&amp;</span>
<span class="p_add">+	    !test_bit(MMF_OOM_SKIP, &amp;mm-&gt;flags))</span>
<span class="p_add">+		oom_reap_task_mm(victim, mm);</span>
<span class="p_add">+#endif</span>
 	mmdrop(mm);
 	put_task_struct(victim);
 }
<span class="p_chunk">@@ -1019,7 +968,6 @@</span> <span class="p_context"> bool out_of_memory(struct oom_control *oc)</span>
 	 */
 	if (task_will_free_mem(current)) {
 		mark_oom_victim(current);
<span class="p_del">-		wake_oom_reaper(current);</span>
 		return true;
 	}
 

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



