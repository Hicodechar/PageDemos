
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>Linux 4.14.3 - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    Linux 4.14.3</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=37061">gregkh@linuxfoundation.org</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>Nov. 30, 2017, 8:59 a.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;20171130085910.GB2391@kroah.com&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/10084425/mbox/"
   >mbox</a>
|
   <a href="/patch/10084425/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/10084425/">/patch/10084425/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
	[172.30.200.125])
	by pdx-korg-patchwork.web.codeaurora.org (Postfix) with ESMTP id
	84370602B9 for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Thu, 30 Nov 2017 08:59:56 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 23B0629F04
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Thu, 30 Nov 2017 08:59:56 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id 1500B29F08; Thu, 30 Nov 2017 08:59:56 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-6.9 required=2.0 tests=BAYES_00,RCVD_IN_DNSWL_HI
	autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 5D6D229F04
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Thu, 30 Nov 2017 08:59:42 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1752380AbdK3I7i (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Thu, 30 Nov 2017 03:59:38 -0500
Received: from mail.linuxfoundation.org ([140.211.169.12]:54968 &quot;EHLO
	mail.linuxfoundation.org&quot; rhost-flags-OK-OK-OK-OK) by vger.kernel.org
	with ESMTP id S1752089AbdK3I7H (ORCPT
	&lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Thu, 30 Nov 2017 03:59:07 -0500
Received: from localhost (cpc92304-cmbg19-2-0-cust157.5-4.cable.virginm.net
	[82.24.196.158])
	by mail.linuxfoundation.org (Postfix) with ESMTPSA id 528E9927;
	Thu, 30 Nov 2017 08:59:05 +0000 (UTC)
Date: Thu, 30 Nov 2017 08:59:10 +0000
From: Greg KH &lt;gregkh@linuxfoundation.org&gt;
To: linux-kernel@vger.kernel.org, Andrew Morton &lt;akpm@linux-foundation.org&gt;,
	torvalds@linux-foundation.org, stable@vger.kernel.org
Cc: lwn@lwn.net, Jiri Slaby &lt;jslaby@suse.cz&gt;
Subject: Re: Linux 4.14.3
Message-ID: &lt;20171130085910.GB2391@kroah.com&gt;
References: &lt;20171130085906.GA2391@kroah.com&gt;
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Disposition: inline
In-Reply-To: &lt;20171130085906.GA2391@kroah.com&gt;
User-Agent: Mutt/1.9.1 (2017-09-22)
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=37061">gregkh@linuxfoundation.org</a> - Nov. 30, 2017, 8:59 a.m.</div>
<pre class="content">

</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/Makefile b/Makefile</span>
<span class="p_header">index 75d89dc2b94a..ede4de0d8634 100644</span>
<span class="p_header">--- a/Makefile</span>
<span class="p_header">+++ b/Makefile</span>
<span class="p_chunk">@@ -1,7 +1,7 @@</span> <span class="p_context"></span>
 # SPDX-License-Identifier: GPL-2.0
 VERSION = 4
 PATCHLEVEL = 14
<span class="p_del">-SUBLEVEL = 2</span>
<span class="p_add">+SUBLEVEL = 3</span>
 EXTRAVERSION =
 NAME = Petit Gorille
 
<span class="p_header">diff --git a/arch/arm/mm/dump.c b/arch/arm/mm/dump.c</span>
<span class="p_header">index 35ff45470dbf..fc3b44028cfb 100644</span>
<span class="p_header">--- a/arch/arm/mm/dump.c</span>
<span class="p_header">+++ b/arch/arm/mm/dump.c</span>
<span class="p_chunk">@@ -129,8 +129,8 @@</span> <span class="p_context"> static const struct prot_bits section_bits[] = {</span>
 		.val	= PMD_SECT_USER,
 		.set	= &quot;USR&quot;,
 	}, {
<span class="p_del">-		.mask	= L_PMD_SECT_RDONLY,</span>
<span class="p_del">-		.val	= L_PMD_SECT_RDONLY,</span>
<span class="p_add">+		.mask	= L_PMD_SECT_RDONLY | PMD_SECT_AP2,</span>
<span class="p_add">+		.val	= L_PMD_SECT_RDONLY | PMD_SECT_AP2,</span>
 		.set	= &quot;ro&quot;,
 		.clear	= &quot;RW&quot;,
 #elif __LINUX_ARM_ARCH__ &gt;= 6
<span class="p_header">diff --git a/arch/arm/mm/init.c b/arch/arm/mm/init.c</span>
<span class="p_header">index ad80548325fe..0f6d1537f330 100644</span>
<span class="p_header">--- a/arch/arm/mm/init.c</span>
<span class="p_header">+++ b/arch/arm/mm/init.c</span>
<span class="p_chunk">@@ -639,8 +639,8 @@</span> <span class="p_context"> static struct section_perm ro_perms[] = {</span>
 		.start  = (unsigned long)_stext,
 		.end    = (unsigned long)__init_begin,
 #ifdef CONFIG_ARM_LPAE
<span class="p_del">-		.mask   = ~L_PMD_SECT_RDONLY,</span>
<span class="p_del">-		.prot   = L_PMD_SECT_RDONLY,</span>
<span class="p_add">+		.mask   = ~(L_PMD_SECT_RDONLY | PMD_SECT_AP2),</span>
<span class="p_add">+		.prot   = L_PMD_SECT_RDONLY | PMD_SECT_AP2,</span>
 #else
 		.mask   = ~(PMD_SECT_APX | PMD_SECT_AP_WRITE),
 		.prot   = PMD_SECT_APX | PMD_SECT_AP_WRITE,
<span class="p_header">diff --git a/arch/arm64/boot/dts/amlogic/meson-gxl.dtsi b/arch/arm64/boot/dts/amlogic/meson-gxl.dtsi</span>
<span class="p_header">index d8dd3298b15c..fb8d76a17bc5 100644</span>
<span class="p_header">--- a/arch/arm64/boot/dts/amlogic/meson-gxl.dtsi</span>
<span class="p_header">+++ b/arch/arm64/boot/dts/amlogic/meson-gxl.dtsi</span>
<span class="p_chunk">@@ -49,6 +49,14 @@</span> <span class="p_context"></span>
 
 / {
 	compatible = &quot;amlogic,meson-gxl&quot;;
<span class="p_add">+</span>
<span class="p_add">+	reserved-memory {</span>
<span class="p_add">+		/* Alternate 3 MiB reserved for ARM Trusted Firmware (BL31) */</span>
<span class="p_add">+		secmon_reserved_alt: secmon@05000000 {</span>
<span class="p_add">+			reg = &lt;0x0 0x05000000 0x0 0x300000&gt;;</span>
<span class="p_add">+			no-map;</span>
<span class="p_add">+		};</span>
<span class="p_add">+	};</span>
 };
 
 &amp;ethmac {
<span class="p_header">diff --git a/arch/arm64/include/asm/pgtable.h b/arch/arm64/include/asm/pgtable.h</span>
<span class="p_header">index b46e54c2399b..c9530b5b5ca8 100644</span>
<span class="p_header">--- a/arch/arm64/include/asm/pgtable.h</span>
<span class="p_header">+++ b/arch/arm64/include/asm/pgtable.h</span>
<span class="p_chunk">@@ -98,6 +98,8 @@</span> <span class="p_context"> extern unsigned long empty_zero_page[PAGE_SIZE / sizeof(unsigned long)];</span>
 	((pte_val(pte) &amp; (PTE_VALID | PTE_USER | PTE_UXN)) == (PTE_VALID | PTE_UXN))
 #define pte_valid_young(pte) \
 	((pte_val(pte) &amp; (PTE_VALID | PTE_AF)) == (PTE_VALID | PTE_AF))
<span class="p_add">+#define pte_valid_user(pte) \</span>
<span class="p_add">+	((pte_val(pte) &amp; (PTE_VALID | PTE_USER)) == (PTE_VALID | PTE_USER))</span>
 
 /*
  * Could the pte be present in the TLB? We must check mm_tlb_flush_pending
<span class="p_chunk">@@ -107,6 +109,18 @@</span> <span class="p_context"> extern unsigned long empty_zero_page[PAGE_SIZE / sizeof(unsigned long)];</span>
 #define pte_accessible(mm, pte)	\
 	(mm_tlb_flush_pending(mm) ? pte_present(pte) : pte_valid_young(pte))
 
<span class="p_add">+/*</span>
<span class="p_add">+ * p??_access_permitted() is true for valid user mappings (subject to the</span>
<span class="p_add">+ * write permission check) other than user execute-only which do not have the</span>
<span class="p_add">+ * PTE_USER bit set. PROT_NONE mappings do not have the PTE_VALID bit set.</span>
<span class="p_add">+ */</span>
<span class="p_add">+#define pte_access_permitted(pte, write) \</span>
<span class="p_add">+	(pte_valid_user(pte) &amp;&amp; (!(write) || pte_write(pte)))</span>
<span class="p_add">+#define pmd_access_permitted(pmd, write) \</span>
<span class="p_add">+	(pte_access_permitted(pmd_pte(pmd), (write)))</span>
<span class="p_add">+#define pud_access_permitted(pud, write) \</span>
<span class="p_add">+	(pte_access_permitted(pud_pte(pud), (write)))</span>
<span class="p_add">+</span>
 static inline pte_t clear_pte_bit(pte_t pte, pgprot_t prot)
 {
 	pte_val(pte) &amp;= ~pgprot_val(prot);
<span class="p_header">diff --git a/arch/mips/Kconfig b/arch/mips/Kconfig</span>
<span class="p_header">index 5d3284d20678..c3d798b44030 100644</span>
<span class="p_header">--- a/arch/mips/Kconfig</span>
<span class="p_header">+++ b/arch/mips/Kconfig</span>
<span class="p_chunk">@@ -65,7 +65,7 @@</span> <span class="p_context"> config MIPS</span>
 	select HAVE_PERF_EVENTS
 	select HAVE_REGS_AND_STACK_ACCESS_API
 	select HAVE_SYSCALL_TRACEPOINTS
<span class="p_del">-	select HAVE_VIRT_CPU_ACCOUNTING_GEN</span>
<span class="p_add">+	select HAVE_VIRT_CPU_ACCOUNTING_GEN if 64BIT || !SMP</span>
 	select IRQ_FORCED_THREADING
 	select MODULES_USE_ELF_RELA if MODULES &amp;&amp; 64BIT
 	select MODULES_USE_ELF_REL if MODULES
<span class="p_header">diff --git a/arch/mips/bcm47xx/leds.c b/arch/mips/bcm47xx/leds.c</span>
<span class="p_header">index d4f2407a42c6..8307a8a02667 100644</span>
<span class="p_header">--- a/arch/mips/bcm47xx/leds.c</span>
<span class="p_header">+++ b/arch/mips/bcm47xx/leds.c</span>
<span class="p_chunk">@@ -331,7 +331,7 @@</span> <span class="p_context"> bcm47xx_leds_linksys_wrt54g3gv2[] __initconst = {</span>
 /* Verified on: WRT54GS V1.0 */
 static const struct gpio_led
 bcm47xx_leds_linksys_wrt54g_type_0101[] __initconst = {
<span class="p_del">-	BCM47XX_GPIO_LED(0, &quot;green&quot;, &quot;wlan&quot;, 0, LEDS_GPIO_DEFSTATE_OFF),</span>
<span class="p_add">+	BCM47XX_GPIO_LED(0, &quot;green&quot;, &quot;wlan&quot;, 1, LEDS_GPIO_DEFSTATE_OFF),</span>
 	BCM47XX_GPIO_LED(1, &quot;green&quot;, &quot;power&quot;, 0, LEDS_GPIO_DEFSTATE_ON),
 	BCM47XX_GPIO_LED(7, &quot;green&quot;, &quot;dmz&quot;, 1, LEDS_GPIO_DEFSTATE_OFF),
 };
<span class="p_header">diff --git a/arch/mips/boot/dts/brcm/Makefile b/arch/mips/boot/dts/brcm/Makefile</span>
<span class="p_header">index 9e09cc4556b3..398994312361 100644</span>
<span class="p_header">--- a/arch/mips/boot/dts/brcm/Makefile</span>
<span class="p_header">+++ b/arch/mips/boot/dts/brcm/Makefile</span>
<span class="p_chunk">@@ -23,7 +23,6 @@</span> <span class="p_context"> dtb-$(CONFIG_DT_NONE) += \</span>
 	bcm63268-comtrend-vr-3032u.dtb \
 	bcm93384wvg.dtb \
 	bcm93384wvg_viper.dtb \
<span class="p_del">-	bcm96358nb4ser.dtb \</span>
 	bcm96368mvwg.dtb \
 	bcm9ejtagprb.dtb \
 	bcm97125cbmb.dtb \
<span class="p_header">diff --git a/arch/mips/include/asm/asmmacro.h b/arch/mips/include/asm/asmmacro.h</span>
<span class="p_header">index 83054f79f72a..feb069cbf44e 100644</span>
<span class="p_header">--- a/arch/mips/include/asm/asmmacro.h</span>
<span class="p_header">+++ b/arch/mips/include/asm/asmmacro.h</span>
<span class="p_chunk">@@ -19,6 +19,9 @@</span> <span class="p_context"></span>
 #include &lt;asm/asmmacro-64.h&gt;
 #endif
 
<span class="p_add">+/* preprocessor replaces the fp in &quot;.set fp=64&quot; with $30 otherwise */</span>
<span class="p_add">+#undef fp</span>
<span class="p_add">+</span>
 /*
  * Helper macros for generating raw instruction encodings.
  */
<span class="p_chunk">@@ -105,6 +108,7 @@</span> <span class="p_context"></span>
 	.macro	fpu_save_16odd thread
 	.set	push
 	.set	mips64r2
<span class="p_add">+	.set	fp=64</span>
 	SET_HARDFLOAT
 	sdc1	$f1,  THREAD_FPR1(\thread)
 	sdc1	$f3,  THREAD_FPR3(\thread)
<span class="p_chunk">@@ -126,8 +130,8 @@</span> <span class="p_context"></span>
 	.endm
 
 	.macro	fpu_save_double thread status tmp
<span class="p_del">-#if defined(CONFIG_64BIT) || defined(CONFIG_CPU_MIPS32_R2) || \</span>
<span class="p_del">-		defined(CONFIG_CPU_MIPS32_R6)</span>
<span class="p_add">+#if defined(CONFIG_64BIT) || defined(CONFIG_CPU_MIPSR2) || \</span>
<span class="p_add">+		defined(CONFIG_CPU_MIPSR6)</span>
 	sll	\tmp, \status, 5
 	bgez	\tmp, 10f
 	fpu_save_16odd \thread
<span class="p_chunk">@@ -163,6 +167,7 @@</span> <span class="p_context"></span>
 	.macro	fpu_restore_16odd thread
 	.set	push
 	.set	mips64r2
<span class="p_add">+	.set	fp=64</span>
 	SET_HARDFLOAT
 	ldc1	$f1,  THREAD_FPR1(\thread)
 	ldc1	$f3,  THREAD_FPR3(\thread)
<span class="p_chunk">@@ -184,8 +189,8 @@</span> <span class="p_context"></span>
 	.endm
 
 	.macro	fpu_restore_double thread status tmp
<span class="p_del">-#if defined(CONFIG_64BIT) || defined(CONFIG_CPU_MIPS32_R2) || \</span>
<span class="p_del">-		defined(CONFIG_CPU_MIPS32_R6)</span>
<span class="p_add">+#if defined(CONFIG_64BIT) || defined(CONFIG_CPU_MIPSR2) || \</span>
<span class="p_add">+		defined(CONFIG_CPU_MIPSR6)</span>
 	sll	\tmp, \status, 5
 	bgez	\tmp, 10f				# 16 register mode?
 
<span class="p_chunk">@@ -234,9 +239,6 @@</span> <span class="p_context"></span>
 	.endm
 
 #ifdef TOOLCHAIN_SUPPORTS_MSA
<span class="p_del">-/* preprocessor replaces the fp in &quot;.set fp=64&quot; with $30 otherwise */</span>
<span class="p_del">-#undef fp</span>
<span class="p_del">-</span>
 	.macro	_cfcmsa	rd, cs
 	.set	push
 	.set	mips32r2
<span class="p_header">diff --git a/arch/mips/include/asm/cmpxchg.h b/arch/mips/include/asm/cmpxchg.h</span>
<span class="p_header">index 7e25c5cc353a..89e9fb7976fe 100644</span>
<span class="p_header">--- a/arch/mips/include/asm/cmpxchg.h</span>
<span class="p_header">+++ b/arch/mips/include/asm/cmpxchg.h</span>
<span class="p_chunk">@@ -204,8 +204,10 @@</span> <span class="p_context"> static inline unsigned long __cmpxchg(volatile void *ptr, unsigned long old,</span>
 #else
 #include &lt;asm-generic/cmpxchg-local.h&gt;
 #define cmpxchg64_local(ptr, o, n) __cmpxchg64_local_generic((ptr), (o), (n))
<span class="p_add">+#ifndef CONFIG_SMP</span>
 #define cmpxchg64(ptr, o, n) cmpxchg64_local((ptr), (o), (n))
 #endif
<span class="p_add">+#endif</span>
 
 #undef __scbeqz
 
<span class="p_header">diff --git a/arch/mips/kernel/ptrace.c b/arch/mips/kernel/ptrace.c</span>
<span class="p_header">index 1395654cfc8d..5a09c2901a76 100644</span>
<span class="p_header">--- a/arch/mips/kernel/ptrace.c</span>
<span class="p_header">+++ b/arch/mips/kernel/ptrace.c</span>
<span class="p_chunk">@@ -618,6 +618,19 @@</span> <span class="p_context"> static const struct user_regset_view user_mips64_view = {</span>
 	.n		= ARRAY_SIZE(mips64_regsets),
 };
 
<span class="p_add">+#ifdef CONFIG_MIPS32_N32</span>
<span class="p_add">+</span>
<span class="p_add">+static const struct user_regset_view user_mipsn32_view = {</span>
<span class="p_add">+	.name		= &quot;mipsn32&quot;,</span>
<span class="p_add">+	.e_flags	= EF_MIPS_ABI2,</span>
<span class="p_add">+	.e_machine	= ELF_ARCH,</span>
<span class="p_add">+	.ei_osabi	= ELF_OSABI,</span>
<span class="p_add">+	.regsets	= mips64_regsets,</span>
<span class="p_add">+	.n		= ARRAY_SIZE(mips64_regsets),</span>
<span class="p_add">+};</span>
<span class="p_add">+</span>
<span class="p_add">+#endif /* CONFIG_MIPS32_N32 */</span>
<span class="p_add">+</span>
 #endif /* CONFIG_64BIT */
 
 const struct user_regset_view *task_user_regset_view(struct task_struct *task)
<span class="p_chunk">@@ -628,6 +641,10 @@</span> <span class="p_context"> const struct user_regset_view *task_user_regset_view(struct task_struct *task)</span>
 #ifdef CONFIG_MIPS32_O32
 	if (test_tsk_thread_flag(task, TIF_32BIT_REGS))
 		return &amp;user_mips_view;
<span class="p_add">+#endif</span>
<span class="p_add">+#ifdef CONFIG_MIPS32_N32</span>
<span class="p_add">+	if (test_tsk_thread_flag(task, TIF_32BIT_ADDR))</span>
<span class="p_add">+		return &amp;user_mipsn32_view;</span>
 #endif
 	return &amp;user_mips64_view;
 #endif
<span class="p_header">diff --git a/arch/mips/kernel/r4k_fpu.S b/arch/mips/kernel/r4k_fpu.S</span>
<span class="p_header">index 0a83b1708b3c..8e3a6020c613 100644</span>
<span class="p_header">--- a/arch/mips/kernel/r4k_fpu.S</span>
<span class="p_header">+++ b/arch/mips/kernel/r4k_fpu.S</span>
<span class="p_chunk">@@ -40,8 +40,8 @@</span> <span class="p_context"></span>
  */
 LEAF(_save_fp)
 EXPORT_SYMBOL(_save_fp)
<span class="p_del">-#if defined(CONFIG_64BIT) || defined(CONFIG_CPU_MIPS32_R2) || \</span>
<span class="p_del">-		defined(CONFIG_CPU_MIPS32_R6)</span>
<span class="p_add">+#if defined(CONFIG_64BIT) || defined(CONFIG_CPU_MIPSR2) || \</span>
<span class="p_add">+		defined(CONFIG_CPU_MIPSR6)</span>
 	mfc0	t0, CP0_STATUS
 #endif
 	fpu_save_double a0 t0 t1		# clobbers t1
<span class="p_chunk">@@ -52,8 +52,8 @@</span> <span class="p_context"> EXPORT_SYMBOL(_save_fp)</span>
  * Restore a thread&#39;s fp context.
  */
 LEAF(_restore_fp)
<span class="p_del">-#if defined(CONFIG_64BIT) || defined(CONFIG_CPU_MIPS32_R2) || \</span>
<span class="p_del">-		defined(CONFIG_CPU_MIPS32_R6)</span>
<span class="p_add">+#if defined(CONFIG_64BIT) || defined(CONFIG_CPU_MIPSR2) || \</span>
<span class="p_add">+		defined(CONFIG_CPU_MIPSR6)</span>
 	mfc0	t0, CP0_STATUS
 #endif
 	fpu_restore_double a0 t0 t1		# clobbers t1
<span class="p_chunk">@@ -246,11 +246,11 @@</span> <span class="p_context"> LEAF(_save_fp_context)</span>
 	cfc1	t1, fcr31
 	.set	pop
 
<span class="p_del">-#if defined(CONFIG_64BIT) || defined(CONFIG_CPU_MIPS32_R2) || \</span>
<span class="p_del">-		defined(CONFIG_CPU_MIPS32_R6)</span>
<span class="p_add">+#if defined(CONFIG_64BIT) || defined(CONFIG_CPU_MIPSR2) || \</span>
<span class="p_add">+		defined(CONFIG_CPU_MIPSR6)</span>
 	.set	push
 	SET_HARDFLOAT
<span class="p_del">-#ifdef CONFIG_CPU_MIPS32_R2</span>
<span class="p_add">+#ifdef CONFIG_CPU_MIPSR2</span>
 	.set	mips32r2
 	.set	fp=64
 	mfc0	t0, CP0_STATUS
<span class="p_chunk">@@ -314,11 +314,11 @@</span> <span class="p_context"> LEAF(_save_fp_context)</span>
 LEAF(_restore_fp_context)
 	EX	lw t1, 0(a1)
 
<span class="p_del">-#if defined(CONFIG_64BIT) || defined(CONFIG_CPU_MIPS32_R2)  || \</span>
<span class="p_del">-		defined(CONFIG_CPU_MIPS32_R6)</span>
<span class="p_add">+#if defined(CONFIG_64BIT) || defined(CONFIG_CPU_MIPSR2)  || \</span>
<span class="p_add">+		defined(CONFIG_CPU_MIPSR6)</span>
 	.set	push
 	SET_HARDFLOAT
<span class="p_del">-#ifdef CONFIG_CPU_MIPS32_R2</span>
<span class="p_add">+#ifdef CONFIG_CPU_MIPSR2</span>
 	.set	mips32r2
 	.set	fp=64
 	mfc0	t0, CP0_STATUS
<span class="p_header">diff --git a/arch/mips/math-emu/cp1emu.c b/arch/mips/math-emu/cp1emu.c</span>
<span class="p_header">index 16d9ef5a78c5..6f57212f5659 100644</span>
<span class="p_header">--- a/arch/mips/math-emu/cp1emu.c</span>
<span class="p_header">+++ b/arch/mips/math-emu/cp1emu.c</span>
<span class="p_chunk">@@ -1795,7 +1795,7 @@</span> <span class="p_context"> static int fpu_emu(struct pt_regs *xcp, struct mips_fpu_struct *ctx,</span>
 			SPFROMREG(fs, MIPSInst_FS(ir));
 			SPFROMREG(fd, MIPSInst_FD(ir));
 			rv.s = ieee754sp_maddf(fd, fs, ft);
<span class="p_del">-			break;</span>
<span class="p_add">+			goto copcsr;</span>
 		}
 
 		case fmsubf_op: {
<span class="p_chunk">@@ -1809,7 +1809,7 @@</span> <span class="p_context"> static int fpu_emu(struct pt_regs *xcp, struct mips_fpu_struct *ctx,</span>
 			SPFROMREG(fs, MIPSInst_FS(ir));
 			SPFROMREG(fd, MIPSInst_FD(ir));
 			rv.s = ieee754sp_msubf(fd, fs, ft);
<span class="p_del">-			break;</span>
<span class="p_add">+			goto copcsr;</span>
 		}
 
 		case frint_op: {
<span class="p_chunk">@@ -1834,7 +1834,7 @@</span> <span class="p_context"> static int fpu_emu(struct pt_regs *xcp, struct mips_fpu_struct *ctx,</span>
 			SPFROMREG(fs, MIPSInst_FS(ir));
 			rv.w = ieee754sp_2008class(fs);
 			rfmt = w_fmt;
<span class="p_del">-			break;</span>
<span class="p_add">+			goto copcsr;</span>
 		}
 
 		case fmin_op: {
<span class="p_chunk">@@ -1847,7 +1847,7 @@</span> <span class="p_context"> static int fpu_emu(struct pt_regs *xcp, struct mips_fpu_struct *ctx,</span>
 			SPFROMREG(ft, MIPSInst_FT(ir));
 			SPFROMREG(fs, MIPSInst_FS(ir));
 			rv.s = ieee754sp_fmin(fs, ft);
<span class="p_del">-			break;</span>
<span class="p_add">+			goto copcsr;</span>
 		}
 
 		case fmina_op: {
<span class="p_chunk">@@ -1860,7 +1860,7 @@</span> <span class="p_context"> static int fpu_emu(struct pt_regs *xcp, struct mips_fpu_struct *ctx,</span>
 			SPFROMREG(ft, MIPSInst_FT(ir));
 			SPFROMREG(fs, MIPSInst_FS(ir));
 			rv.s = ieee754sp_fmina(fs, ft);
<span class="p_del">-			break;</span>
<span class="p_add">+			goto copcsr;</span>
 		}
 
 		case fmax_op: {
<span class="p_chunk">@@ -1873,7 +1873,7 @@</span> <span class="p_context"> static int fpu_emu(struct pt_regs *xcp, struct mips_fpu_struct *ctx,</span>
 			SPFROMREG(ft, MIPSInst_FT(ir));
 			SPFROMREG(fs, MIPSInst_FS(ir));
 			rv.s = ieee754sp_fmax(fs, ft);
<span class="p_del">-			break;</span>
<span class="p_add">+			goto copcsr;</span>
 		}
 
 		case fmaxa_op: {
<span class="p_chunk">@@ -1886,7 +1886,7 @@</span> <span class="p_context"> static int fpu_emu(struct pt_regs *xcp, struct mips_fpu_struct *ctx,</span>
 			SPFROMREG(ft, MIPSInst_FT(ir));
 			SPFROMREG(fs, MIPSInst_FS(ir));
 			rv.s = ieee754sp_fmaxa(fs, ft);
<span class="p_del">-			break;</span>
<span class="p_add">+			goto copcsr;</span>
 		}
 
 		case fabs_op:
<span class="p_chunk">@@ -2165,7 +2165,7 @@</span> <span class="p_context"> static int fpu_emu(struct pt_regs *xcp, struct mips_fpu_struct *ctx,</span>
 			DPFROMREG(fs, MIPSInst_FS(ir));
 			DPFROMREG(fd, MIPSInst_FD(ir));
 			rv.d = ieee754dp_maddf(fd, fs, ft);
<span class="p_del">-			break;</span>
<span class="p_add">+			goto copcsr;</span>
 		}
 
 		case fmsubf_op: {
<span class="p_chunk">@@ -2179,7 +2179,7 @@</span> <span class="p_context"> static int fpu_emu(struct pt_regs *xcp, struct mips_fpu_struct *ctx,</span>
 			DPFROMREG(fs, MIPSInst_FS(ir));
 			DPFROMREG(fd, MIPSInst_FD(ir));
 			rv.d = ieee754dp_msubf(fd, fs, ft);
<span class="p_del">-			break;</span>
<span class="p_add">+			goto copcsr;</span>
 		}
 
 		case frint_op: {
<span class="p_chunk">@@ -2204,7 +2204,7 @@</span> <span class="p_context"> static int fpu_emu(struct pt_regs *xcp, struct mips_fpu_struct *ctx,</span>
 			DPFROMREG(fs, MIPSInst_FS(ir));
 			rv.l = ieee754dp_2008class(fs);
 			rfmt = l_fmt;
<span class="p_del">-			break;</span>
<span class="p_add">+			goto copcsr;</span>
 		}
 
 		case fmin_op: {
<span class="p_chunk">@@ -2217,7 +2217,7 @@</span> <span class="p_context"> static int fpu_emu(struct pt_regs *xcp, struct mips_fpu_struct *ctx,</span>
 			DPFROMREG(ft, MIPSInst_FT(ir));
 			DPFROMREG(fs, MIPSInst_FS(ir));
 			rv.d = ieee754dp_fmin(fs, ft);
<span class="p_del">-			break;</span>
<span class="p_add">+			goto copcsr;</span>
 		}
 
 		case fmina_op: {
<span class="p_chunk">@@ -2230,7 +2230,7 @@</span> <span class="p_context"> static int fpu_emu(struct pt_regs *xcp, struct mips_fpu_struct *ctx,</span>
 			DPFROMREG(ft, MIPSInst_FT(ir));
 			DPFROMREG(fs, MIPSInst_FS(ir));
 			rv.d = ieee754dp_fmina(fs, ft);
<span class="p_del">-			break;</span>
<span class="p_add">+			goto copcsr;</span>
 		}
 
 		case fmax_op: {
<span class="p_chunk">@@ -2243,7 +2243,7 @@</span> <span class="p_context"> static int fpu_emu(struct pt_regs *xcp, struct mips_fpu_struct *ctx,</span>
 			DPFROMREG(ft, MIPSInst_FT(ir));
 			DPFROMREG(fs, MIPSInst_FS(ir));
 			rv.d = ieee754dp_fmax(fs, ft);
<span class="p_del">-			break;</span>
<span class="p_add">+			goto copcsr;</span>
 		}
 
 		case fmaxa_op: {
<span class="p_chunk">@@ -2256,7 +2256,7 @@</span> <span class="p_context"> static int fpu_emu(struct pt_regs *xcp, struct mips_fpu_struct *ctx,</span>
 			DPFROMREG(ft, MIPSInst_FT(ir));
 			DPFROMREG(fs, MIPSInst_FS(ir));
 			rv.d = ieee754dp_fmaxa(fs, ft);
<span class="p_del">-			break;</span>
<span class="p_add">+			goto copcsr;</span>
 		}
 
 		case fabs_op:
<span class="p_header">diff --git a/arch/mips/pci/pci-mt7620.c b/arch/mips/pci/pci-mt7620.c</span>
<span class="p_header">index 90fba9bf98da..27ac00c36bc0 100644</span>
<span class="p_header">--- a/arch/mips/pci/pci-mt7620.c</span>
<span class="p_header">+++ b/arch/mips/pci/pci-mt7620.c</span>
<span class="p_chunk">@@ -121,7 +121,7 @@</span> <span class="p_context"> static int wait_pciephy_busy(void)</span>
 		else
 			break;
 		if (retry++ &gt; WAITRETRY_MAX) {
<span class="p_del">-			printk(KERN_WARN &quot;PCIE-PHY retry failed.\n&quot;);</span>
<span class="p_add">+			pr_warn(&quot;PCIE-PHY retry failed.\n&quot;);</span>
 			return -1;
 		}
 	}
<span class="p_header">diff --git a/arch/mips/ralink/mt7620.c b/arch/mips/ralink/mt7620.c</span>
<span class="p_header">index 9be8b08ae46b..41b71c4352c2 100644</span>
<span class="p_header">--- a/arch/mips/ralink/mt7620.c</span>
<span class="p_header">+++ b/arch/mips/ralink/mt7620.c</span>
<span class="p_chunk">@@ -145,8 +145,8 @@</span> <span class="p_context"> static struct rt2880_pmx_func i2c_grp_mt7628[] = {</span>
 	FUNC(&quot;i2c&quot;, 0, 4, 2),
 };
 
<span class="p_del">-static struct rt2880_pmx_func refclk_grp_mt7628[] = { FUNC(&quot;reclk&quot;, 0, 36, 1) };</span>
<span class="p_del">-static struct rt2880_pmx_func perst_grp_mt7628[] = { FUNC(&quot;perst&quot;, 0, 37, 1) };</span>
<span class="p_add">+static struct rt2880_pmx_func refclk_grp_mt7628[] = { FUNC(&quot;refclk&quot;, 0, 37, 1) };</span>
<span class="p_add">+static struct rt2880_pmx_func perst_grp_mt7628[] = { FUNC(&quot;perst&quot;, 0, 36, 1) };</span>
 static struct rt2880_pmx_func wdt_grp_mt7628[] = { FUNC(&quot;wdt&quot;, 0, 38, 1) };
 static struct rt2880_pmx_func spi_grp_mt7628[] = { FUNC(&quot;spi&quot;, 0, 7, 4) };
 
<span class="p_header">diff --git a/arch/parisc/kernel/syscall.S b/arch/parisc/kernel/syscall.S</span>
<span class="p_header">index 41e60a9c7db2..e775f80ae28c 100644</span>
<span class="p_header">--- a/arch/parisc/kernel/syscall.S</span>
<span class="p_header">+++ b/arch/parisc/kernel/syscall.S</span>
<span class="p_chunk">@@ -690,15 +690,15 @@</span> <span class="p_context"> cas_action:</span>
 	/* ELF32 Process entry path */
 lws_compare_and_swap_2:
 #ifdef CONFIG_64BIT
<span class="p_del">-	/* Clip the input registers */</span>
<span class="p_add">+	/* Clip the input registers. We don&#39;t need to clip %r23 as we</span>
<span class="p_add">+	   only use it for word operations */</span>
 	depdi	0, 31, 32, %r26
 	depdi	0, 31, 32, %r25
 	depdi	0, 31, 32, %r24
<span class="p_del">-	depdi	0, 31, 32, %r23</span>
 #endif
 
 	/* Check the validity of the size pointer */
<span class="p_del">-	subi,&gt;&gt;= 4, %r23, %r0</span>
<span class="p_add">+	subi,&gt;&gt;= 3, %r23, %r0</span>
 	b,n	lws_exit_nosys
 
 	/* Jump to the functions which will load the old and new values into
<span class="p_header">diff --git a/arch/powerpc/kernel/exceptions-64s.S b/arch/powerpc/kernel/exceptions-64s.S</span>
<span class="p_header">index 1c80bd292e48..06598142d755 100644</span>
<span class="p_header">--- a/arch/powerpc/kernel/exceptions-64s.S</span>
<span class="p_header">+++ b/arch/powerpc/kernel/exceptions-64s.S</span>
<span class="p_chunk">@@ -542,7 +542,7 @@</span> <span class="p_context"> EXC_COMMON_BEGIN(instruction_access_common)</span>
 	RECONCILE_IRQ_STATE(r10, r11)
 	ld	r12,_MSR(r1)
 	ld	r3,_NIP(r1)
<span class="p_del">-	andis.	r4,r12,DSISR_BAD_FAULT_64S@h</span>
<span class="p_add">+	andis.	r4,r12,DSISR_SRR1_MATCH_64S@h</span>
 	li	r5,0x400
 	std	r3,_DAR(r1)
 	std	r4,_DSISR(r1)
<span class="p_header">diff --git a/arch/powerpc/kernel/signal.c b/arch/powerpc/kernel/signal.c</span>
<span class="p_header">index e9436c5e1e09..3d7539b90010 100644</span>
<span class="p_header">--- a/arch/powerpc/kernel/signal.c</span>
<span class="p_header">+++ b/arch/powerpc/kernel/signal.c</span>
<span class="p_chunk">@@ -103,7 +103,7 @@</span> <span class="p_context"> static void check_syscall_restart(struct pt_regs *regs, struct k_sigaction *ka,</span>
 static void do_signal(struct task_struct *tsk)
 {
 	sigset_t *oldset = sigmask_to_save();
<span class="p_del">-	struct ksignal ksig;</span>
<span class="p_add">+	struct ksignal ksig = { .sig = 0 };</span>
 	int ret;
 	int is32 = is_32bit_task();
 
<span class="p_header">diff --git a/arch/powerpc/kvm/book3s_hv_builtin.c b/arch/powerpc/kvm/book3s_hv_builtin.c</span>
<span class="p_header">index 90644db9d38e..8e0cf8f186df 100644</span>
<span class="p_header">--- a/arch/powerpc/kvm/book3s_hv_builtin.c</span>
<span class="p_header">+++ b/arch/powerpc/kvm/book3s_hv_builtin.c</span>
<span class="p_chunk">@@ -529,6 +529,8 @@</span> <span class="p_context"> static inline bool is_rm(void)</span>
 
 unsigned long kvmppc_rm_h_xirr(struct kvm_vcpu *vcpu)
 {
<span class="p_add">+	if (!kvmppc_xics_enabled(vcpu))</span>
<span class="p_add">+		return H_TOO_HARD;</span>
 	if (xive_enabled()) {
 		if (is_rm())
 			return xive_rm_h_xirr(vcpu);
<span class="p_chunk">@@ -541,6 +543,8 @@</span> <span class="p_context"> unsigned long kvmppc_rm_h_xirr(struct kvm_vcpu *vcpu)</span>
 
 unsigned long kvmppc_rm_h_xirr_x(struct kvm_vcpu *vcpu)
 {
<span class="p_add">+	if (!kvmppc_xics_enabled(vcpu))</span>
<span class="p_add">+		return H_TOO_HARD;</span>
 	vcpu-&gt;arch.gpr[5] = get_tb();
 	if (xive_enabled()) {
 		if (is_rm())
<span class="p_chunk">@@ -554,6 +558,8 @@</span> <span class="p_context"> unsigned long kvmppc_rm_h_xirr_x(struct kvm_vcpu *vcpu)</span>
 
 unsigned long kvmppc_rm_h_ipoll(struct kvm_vcpu *vcpu, unsigned long server)
 {
<span class="p_add">+	if (!kvmppc_xics_enabled(vcpu))</span>
<span class="p_add">+		return H_TOO_HARD;</span>
 	if (xive_enabled()) {
 		if (is_rm())
 			return xive_rm_h_ipoll(vcpu, server);
<span class="p_chunk">@@ -567,6 +573,8 @@</span> <span class="p_context"> unsigned long kvmppc_rm_h_ipoll(struct kvm_vcpu *vcpu, unsigned long server)</span>
 int kvmppc_rm_h_ipi(struct kvm_vcpu *vcpu, unsigned long server,
 		    unsigned long mfrr)
 {
<span class="p_add">+	if (!kvmppc_xics_enabled(vcpu))</span>
<span class="p_add">+		return H_TOO_HARD;</span>
 	if (xive_enabled()) {
 		if (is_rm())
 			return xive_rm_h_ipi(vcpu, server, mfrr);
<span class="p_chunk">@@ -579,6 +587,8 @@</span> <span class="p_context"> int kvmppc_rm_h_ipi(struct kvm_vcpu *vcpu, unsigned long server,</span>
 
 int kvmppc_rm_h_cppr(struct kvm_vcpu *vcpu, unsigned long cppr)
 {
<span class="p_add">+	if (!kvmppc_xics_enabled(vcpu))</span>
<span class="p_add">+		return H_TOO_HARD;</span>
 	if (xive_enabled()) {
 		if (is_rm())
 			return xive_rm_h_cppr(vcpu, cppr);
<span class="p_chunk">@@ -591,6 +601,8 @@</span> <span class="p_context"> int kvmppc_rm_h_cppr(struct kvm_vcpu *vcpu, unsigned long cppr)</span>
 
 int kvmppc_rm_h_eoi(struct kvm_vcpu *vcpu, unsigned long xirr)
 {
<span class="p_add">+	if (!kvmppc_xics_enabled(vcpu))</span>
<span class="p_add">+		return H_TOO_HARD;</span>
 	if (xive_enabled()) {
 		if (is_rm())
 			return xive_rm_h_eoi(vcpu, xirr);
<span class="p_header">diff --git a/arch/powerpc/lib/code-patching.c b/arch/powerpc/lib/code-patching.c</span>
<span class="p_header">index c9de03e0c1f1..d469224c4ada 100644</span>
<span class="p_header">--- a/arch/powerpc/lib/code-patching.c</span>
<span class="p_header">+++ b/arch/powerpc/lib/code-patching.c</span>
<span class="p_chunk">@@ -21,6 +21,7 @@</span> <span class="p_context"></span>
 #include &lt;asm/tlbflush.h&gt;
 #include &lt;asm/page.h&gt;
 #include &lt;asm/code-patching.h&gt;
<span class="p_add">+#include &lt;asm/setup.h&gt;</span>
 
 static int __patch_instruction(unsigned int *addr, unsigned int instr)
 {
<span class="p_chunk">@@ -146,11 +147,8 @@</span> <span class="p_context"> int patch_instruction(unsigned int *addr, unsigned int instr)</span>
 	 * During early early boot patch_instruction is called
 	 * when text_poke_area is not ready, but we still need
 	 * to allow patching. We just do the plain old patching
<span class="p_del">-	 * We use slab_is_available and per cpu read * via this_cpu_read</span>
<span class="p_del">-	 * of text_poke_area. Per-CPU areas might not be up early</span>
<span class="p_del">-	 * this can create problems with just using this_cpu_read()</span>
 	 */
<span class="p_del">-	if (!slab_is_available() || !this_cpu_read(text_poke_area))</span>
<span class="p_add">+	if (!this_cpu_read(*PTRRELOC(&amp;text_poke_area)))</span>
 		return __patch_instruction(addr, instr);
 
 	local_irq_save(flags);
<span class="p_header">diff --git a/arch/powerpc/mm/hugetlbpage-radix.c b/arch/powerpc/mm/hugetlbpage-radix.c</span>
<span class="p_header">index 558e9d3891bf..bd022d16745c 100644</span>
<span class="p_header">--- a/arch/powerpc/mm/hugetlbpage-radix.c</span>
<span class="p_header">+++ b/arch/powerpc/mm/hugetlbpage-radix.c</span>
<span class="p_chunk">@@ -49,17 +49,28 @@</span> <span class="p_context"> radix__hugetlb_get_unmapped_area(struct file *file, unsigned long addr,</span>
 	struct mm_struct *mm = current-&gt;mm;
 	struct vm_area_struct *vma;
 	struct hstate *h = hstate_file(file);
<span class="p_add">+	int fixed = (flags &amp; MAP_FIXED);</span>
<span class="p_add">+	unsigned long high_limit;</span>
 	struct vm_unmapped_area_info info;
 
<span class="p_del">-	if (unlikely(addr &gt; mm-&gt;context.addr_limit &amp;&amp; addr &lt; TASK_SIZE))</span>
<span class="p_del">-		mm-&gt;context.addr_limit = TASK_SIZE;</span>
<span class="p_add">+	high_limit = DEFAULT_MAP_WINDOW;</span>
<span class="p_add">+	if (addr &gt;= high_limit || (fixed &amp;&amp; (addr + len &gt; high_limit)))</span>
<span class="p_add">+		high_limit = TASK_SIZE;</span>
 
 	if (len &amp; ~huge_page_mask(h))
 		return -EINVAL;
<span class="p_del">-	if (len &gt; mm-&gt;task_size)</span>
<span class="p_add">+	if (len &gt; high_limit)</span>
 		return -ENOMEM;
<span class="p_add">+	if (fixed) {</span>
<span class="p_add">+		if (addr &gt; high_limit - len)</span>
<span class="p_add">+			return -ENOMEM;</span>
<span class="p_add">+	}</span>
 
<span class="p_del">-	if (flags &amp; MAP_FIXED) {</span>
<span class="p_add">+	if (unlikely(addr &gt; mm-&gt;context.addr_limit &amp;&amp;</span>
<span class="p_add">+		     mm-&gt;context.addr_limit != TASK_SIZE))</span>
<span class="p_add">+		mm-&gt;context.addr_limit = TASK_SIZE;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (fixed) {</span>
 		if (prepare_hugepage_range(file, addr, len))
 			return -EINVAL;
 		return addr;
<span class="p_chunk">@@ -68,7 +79,7 @@</span> <span class="p_context"> radix__hugetlb_get_unmapped_area(struct file *file, unsigned long addr,</span>
 	if (addr) {
 		addr = ALIGN(addr, huge_page_size(h));
 		vma = find_vma(mm, addr);
<span class="p_del">-		if (mm-&gt;task_size - len &gt;= addr &amp;&amp;</span>
<span class="p_add">+		if (high_limit - len &gt;= addr &amp;&amp;</span>
 		    (!vma || addr + len &lt;= vm_start_gap(vma)))
 			return addr;
 	}
<span class="p_chunk">@@ -79,12 +90,9 @@</span> <span class="p_context"> radix__hugetlb_get_unmapped_area(struct file *file, unsigned long addr,</span>
 	info.flags = VM_UNMAPPED_AREA_TOPDOWN;
 	info.length = len;
 	info.low_limit = PAGE_SIZE;
<span class="p_del">-	info.high_limit = current-&gt;mm-&gt;mmap_base;</span>
<span class="p_add">+	info.high_limit = mm-&gt;mmap_base + (high_limit - DEFAULT_MAP_WINDOW);</span>
 	info.align_mask = PAGE_MASK &amp; ~huge_page_mask(h);
 	info.align_offset = 0;
 
<span class="p_del">-	if (addr &gt; DEFAULT_MAP_WINDOW)</span>
<span class="p_del">-		info.high_limit += mm-&gt;context.addr_limit - DEFAULT_MAP_WINDOW;</span>
<span class="p_del">-</span>
 	return vm_unmapped_area(&amp;info);
 }
<span class="p_header">diff --git a/arch/powerpc/mm/mmap.c b/arch/powerpc/mm/mmap.c</span>
<span class="p_header">index 5d78b193fec4..6d476a7b5611 100644</span>
<span class="p_header">--- a/arch/powerpc/mm/mmap.c</span>
<span class="p_header">+++ b/arch/powerpc/mm/mmap.c</span>
<span class="p_chunk">@@ -106,22 +106,32 @@</span> <span class="p_context"> radix__arch_get_unmapped_area(struct file *filp, unsigned long addr,</span>
 {
 	struct mm_struct *mm = current-&gt;mm;
 	struct vm_area_struct *vma;
<span class="p_add">+	int fixed = (flags &amp; MAP_FIXED);</span>
<span class="p_add">+	unsigned long high_limit;</span>
 	struct vm_unmapped_area_info info;
 
<span class="p_add">+	high_limit = DEFAULT_MAP_WINDOW;</span>
<span class="p_add">+	if (addr &gt;= high_limit || (fixed &amp;&amp; (addr + len &gt; high_limit)))</span>
<span class="p_add">+		high_limit = TASK_SIZE;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (len &gt; high_limit)</span>
<span class="p_add">+		return -ENOMEM;</span>
<span class="p_add">+	if (fixed) {</span>
<span class="p_add">+		if (addr &gt; high_limit - len)</span>
<span class="p_add">+			return -ENOMEM;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
 	if (unlikely(addr &gt; mm-&gt;context.addr_limit &amp;&amp;
 		     mm-&gt;context.addr_limit != TASK_SIZE))
 		mm-&gt;context.addr_limit = TASK_SIZE;
 
<span class="p_del">-	if (len &gt; mm-&gt;task_size - mmap_min_addr)</span>
<span class="p_del">-		return -ENOMEM;</span>
<span class="p_del">-</span>
<span class="p_del">-	if (flags &amp; MAP_FIXED)</span>
<span class="p_add">+	if (fixed)</span>
 		return addr;
 
 	if (addr) {
 		addr = PAGE_ALIGN(addr);
 		vma = find_vma(mm, addr);
<span class="p_del">-		if (mm-&gt;task_size - len &gt;= addr &amp;&amp; addr &gt;= mmap_min_addr &amp;&amp;</span>
<span class="p_add">+		if (high_limit - len &gt;= addr &amp;&amp; addr &gt;= mmap_min_addr &amp;&amp;</span>
 		    (!vma || addr + len &lt;= vm_start_gap(vma)))
 			return addr;
 	}
<span class="p_chunk">@@ -129,13 +139,9 @@</span> <span class="p_context"> radix__arch_get_unmapped_area(struct file *filp, unsigned long addr,</span>
 	info.flags = 0;
 	info.length = len;
 	info.low_limit = mm-&gt;mmap_base;
<span class="p_add">+	info.high_limit = high_limit;</span>
 	info.align_mask = 0;
 
<span class="p_del">-	if (unlikely(addr &gt; DEFAULT_MAP_WINDOW))</span>
<span class="p_del">-		info.high_limit = mm-&gt;context.addr_limit;</span>
<span class="p_del">-	else</span>
<span class="p_del">-		info.high_limit = DEFAULT_MAP_WINDOW;</span>
<span class="p_del">-</span>
 	return vm_unmapped_area(&amp;info);
 }
 
<span class="p_chunk">@@ -149,37 +155,42 @@</span> <span class="p_context"> radix__arch_get_unmapped_area_topdown(struct file *filp,</span>
 	struct vm_area_struct *vma;
 	struct mm_struct *mm = current-&gt;mm;
 	unsigned long addr = addr0;
<span class="p_add">+	int fixed = (flags &amp; MAP_FIXED);</span>
<span class="p_add">+	unsigned long high_limit;</span>
 	struct vm_unmapped_area_info info;
 
<span class="p_add">+	high_limit = DEFAULT_MAP_WINDOW;</span>
<span class="p_add">+	if (addr &gt;= high_limit || (fixed &amp;&amp; (addr + len &gt; high_limit)))</span>
<span class="p_add">+		high_limit = TASK_SIZE;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (len &gt; high_limit)</span>
<span class="p_add">+		return -ENOMEM;</span>
<span class="p_add">+	if (fixed) {</span>
<span class="p_add">+		if (addr &gt; high_limit - len)</span>
<span class="p_add">+			return -ENOMEM;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
 	if (unlikely(addr &gt; mm-&gt;context.addr_limit &amp;&amp;
 		     mm-&gt;context.addr_limit != TASK_SIZE))
 		mm-&gt;context.addr_limit = TASK_SIZE;
 
<span class="p_del">-	/* requested length too big for entire address space */</span>
<span class="p_del">-	if (len &gt; mm-&gt;task_size - mmap_min_addr)</span>
<span class="p_del">-		return -ENOMEM;</span>
<span class="p_del">-</span>
<span class="p_del">-	if (flags &amp; MAP_FIXED)</span>
<span class="p_add">+	if (fixed)</span>
 		return addr;
 
<span class="p_del">-	/* requesting a specific address */</span>
 	if (addr) {
 		addr = PAGE_ALIGN(addr);
 		vma = find_vma(mm, addr);
<span class="p_del">-		if (mm-&gt;task_size - len &gt;= addr &amp;&amp; addr &gt;= mmap_min_addr &amp;&amp;</span>
<span class="p_del">-				(!vma || addr + len &lt;= vm_start_gap(vma)))</span>
<span class="p_add">+		if (high_limit - len &gt;= addr &amp;&amp; addr &gt;= mmap_min_addr &amp;&amp;</span>
<span class="p_add">+		    (!vma || addr + len &lt;= vm_start_gap(vma)))</span>
 			return addr;
 	}
 
 	info.flags = VM_UNMAPPED_AREA_TOPDOWN;
 	info.length = len;
 	info.low_limit = max(PAGE_SIZE, mmap_min_addr);
<span class="p_del">-	info.high_limit = mm-&gt;mmap_base;</span>
<span class="p_add">+	info.high_limit = mm-&gt;mmap_base + (high_limit - DEFAULT_MAP_WINDOW);</span>
 	info.align_mask = 0;
 
<span class="p_del">-	if (addr &gt; DEFAULT_MAP_WINDOW)</span>
<span class="p_del">-		info.high_limit += mm-&gt;context.addr_limit - DEFAULT_MAP_WINDOW;</span>
<span class="p_del">-</span>
 	addr = vm_unmapped_area(&amp;info);
 	if (!(addr &amp; ~PAGE_MASK))
 		return addr;
<span class="p_header">diff --git a/arch/powerpc/mm/mmu_context_book3s64.c b/arch/powerpc/mm/mmu_context_book3s64.c</span>
<span class="p_header">index 05e15386d4cb..b94fb62e60fd 100644</span>
<span class="p_header">--- a/arch/powerpc/mm/mmu_context_book3s64.c</span>
<span class="p_header">+++ b/arch/powerpc/mm/mmu_context_book3s64.c</span>
<span class="p_chunk">@@ -93,11 +93,11 @@</span> <span class="p_context"> static int hash__init_new_context(struct mm_struct *mm)</span>
 		return index;
 
 	/*
<span class="p_del">-	 * We do switch_slb() early in fork, even before we setup the</span>
<span class="p_del">-	 * mm-&gt;context.addr_limit. Default to max task size so that we copy the</span>
<span class="p_del">-	 * default values to paca which will help us to handle slb miss early.</span>
<span class="p_add">+	 * In the case of exec, use the default limit,</span>
<span class="p_add">+	 * otherwise inherit it from the mm we are duplicating.</span>
 	 */
<span class="p_del">-	mm-&gt;context.addr_limit = DEFAULT_MAP_WINDOW_USER64;</span>
<span class="p_add">+	if (!mm-&gt;context.addr_limit)</span>
<span class="p_add">+		mm-&gt;context.addr_limit = DEFAULT_MAP_WINDOW_USER64;</span>
 
 	/*
 	 * The old code would re-promote on fork, we don&#39;t do that when using
<span class="p_header">diff --git a/arch/powerpc/mm/pgtable-radix.c b/arch/powerpc/mm/pgtable-radix.c</span>
<span class="p_header">index 39c252b54d16..cfbbee941a76 100644</span>
<span class="p_header">--- a/arch/powerpc/mm/pgtable-radix.c</span>
<span class="p_header">+++ b/arch/powerpc/mm/pgtable-radix.c</span>
<span class="p_chunk">@@ -169,6 +169,16 @@</span> <span class="p_context"> void radix__mark_rodata_ro(void)</span>
 {
 	unsigned long start, end;
 
<span class="p_add">+	/*</span>
<span class="p_add">+	 * mark_rodata_ro() will mark itself as !writable at some point.</span>
<span class="p_add">+	 * Due to DD1 workaround in radix__pte_update(), we&#39;ll end up with</span>
<span class="p_add">+	 * an invalid pte and the system will crash quite severly.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	if (cpu_has_feature(CPU_FTR_POWER9_DD1)) {</span>
<span class="p_add">+		pr_warn(&quot;Warning: Unable to mark rodata read only on P9 DD1\n&quot;);</span>
<span class="p_add">+		return;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
 	start = (unsigned long)_stext;
 	end = (unsigned long)__init_begin;
 
<span class="p_header">diff --git a/arch/powerpc/mm/slice.c b/arch/powerpc/mm/slice.c</span>
<span class="p_header">index 45f6740dd407..a4f93699194b 100644</span>
<span class="p_header">--- a/arch/powerpc/mm/slice.c</span>
<span class="p_header">+++ b/arch/powerpc/mm/slice.c</span>
<span class="p_chunk">@@ -96,7 +96,7 @@</span> <span class="p_context"> static int slice_area_is_free(struct mm_struct *mm, unsigned long addr,</span>
 {
 	struct vm_area_struct *vma;
 
<span class="p_del">-	if ((mm-&gt;task_size - len) &lt; addr)</span>
<span class="p_add">+	if ((mm-&gt;context.addr_limit - len) &lt; addr)</span>
 		return 0;
 	vma = find_vma(mm, addr);
 	return (!vma || (addr + len) &lt;= vm_start_gap(vma));
<span class="p_chunk">@@ -133,7 +133,7 @@</span> <span class="p_context"> static void slice_mask_for_free(struct mm_struct *mm, struct slice_mask *ret)</span>
 		if (!slice_low_has_vma(mm, i))
 			ret-&gt;low_slices |= 1u &lt;&lt; i;
 
<span class="p_del">-	if (mm-&gt;task_size &lt;= SLICE_LOW_TOP)</span>
<span class="p_add">+	if (mm-&gt;context.addr_limit &lt;= SLICE_LOW_TOP)</span>
 		return;
 
 	for (i = 0; i &lt; GET_HIGH_SLICE_INDEX(mm-&gt;context.addr_limit); i++)
<span class="p_chunk">@@ -412,25 +412,31 @@</span> <span class="p_context"> unsigned long slice_get_unmapped_area(unsigned long addr, unsigned long len,</span>
 	struct slice_mask compat_mask;
 	int fixed = (flags &amp; MAP_FIXED);
 	int pshift = max_t(int, mmu_psize_defs[psize].shift, PAGE_SHIFT);
<span class="p_add">+	unsigned long page_size = 1UL &lt;&lt; pshift;</span>
 	struct mm_struct *mm = current-&gt;mm;
 	unsigned long newaddr;
 	unsigned long high_limit;
 
<span class="p_del">-	/*</span>
<span class="p_del">-	 * Check if we need to expland slice area.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	if (unlikely(addr &gt; mm-&gt;context.addr_limit &amp;&amp;</span>
<span class="p_del">-		     mm-&gt;context.addr_limit != TASK_SIZE)) {</span>
<span class="p_del">-		mm-&gt;context.addr_limit = TASK_SIZE;</span>
<span class="p_add">+	high_limit = DEFAULT_MAP_WINDOW;</span>
<span class="p_add">+	if (addr &gt;= high_limit || (fixed &amp;&amp; (addr + len &gt; high_limit)))</span>
<span class="p_add">+		high_limit = TASK_SIZE;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (len &gt; high_limit)</span>
<span class="p_add">+		return -ENOMEM;</span>
<span class="p_add">+	if (len &amp; (page_size - 1))</span>
<span class="p_add">+		return -EINVAL;</span>
<span class="p_add">+	if (fixed) {</span>
<span class="p_add">+		if (addr &amp; (page_size - 1))</span>
<span class="p_add">+			return -EINVAL;</span>
<span class="p_add">+		if (addr &gt; high_limit - len)</span>
<span class="p_add">+			return -ENOMEM;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	if (high_limit &gt; mm-&gt;context.addr_limit) {</span>
<span class="p_add">+		mm-&gt;context.addr_limit = high_limit;</span>
 		on_each_cpu(slice_flush_segments, mm, 1);
 	}
<span class="p_del">-	/*</span>
<span class="p_del">-	 * This mmap request can allocate upt to 512TB</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	if (addr &gt; DEFAULT_MAP_WINDOW)</span>
<span class="p_del">-		high_limit = mm-&gt;context.addr_limit;</span>
<span class="p_del">-	else</span>
<span class="p_del">-		high_limit = DEFAULT_MAP_WINDOW;</span>
<span class="p_add">+</span>
 	/*
 	 * init different masks
 	 */
<span class="p_chunk">@@ -446,27 +452,19 @@</span> <span class="p_context"> unsigned long slice_get_unmapped_area(unsigned long addr, unsigned long len,</span>
 
 	/* Sanity checks */
 	BUG_ON(mm-&gt;task_size == 0);
<span class="p_add">+	BUG_ON(mm-&gt;context.addr_limit == 0);</span>
 	VM_BUG_ON(radix_enabled());
 
 	slice_dbg(&quot;slice_get_unmapped_area(mm=%p, psize=%d...\n&quot;, mm, psize);
 	slice_dbg(&quot; addr=%lx, len=%lx, flags=%lx, topdown=%d\n&quot;,
 		  addr, len, flags, topdown);
 
<span class="p_del">-	if (len &gt; mm-&gt;task_size)</span>
<span class="p_del">-		return -ENOMEM;</span>
<span class="p_del">-	if (len &amp; ((1ul &lt;&lt; pshift) - 1))</span>
<span class="p_del">-		return -EINVAL;</span>
<span class="p_del">-	if (fixed &amp;&amp; (addr &amp; ((1ul &lt;&lt; pshift) - 1)))</span>
<span class="p_del">-		return -EINVAL;</span>
<span class="p_del">-	if (fixed &amp;&amp; addr &gt; (mm-&gt;task_size - len))</span>
<span class="p_del">-		return -ENOMEM;</span>
<span class="p_del">-</span>
 	/* If hint, make sure it matches our alignment restrictions */
 	if (!fixed &amp;&amp; addr) {
<span class="p_del">-		addr = _ALIGN_UP(addr, 1ul &lt;&lt; pshift);</span>
<span class="p_add">+		addr = _ALIGN_UP(addr, page_size);</span>
 		slice_dbg(&quot; aligned addr=%lx\n&quot;, addr);
 		/* Ignore hint if it&#39;s too large or overlaps a VMA */
<span class="p_del">-		if (addr &gt; mm-&gt;task_size - len ||</span>
<span class="p_add">+		if (addr &gt; high_limit - len ||</span>
 		    !slice_area_is_free(mm, addr, len))
 			addr = 0;
 	}
<span class="p_header">diff --git a/arch/powerpc/perf/imc-pmu.c b/arch/powerpc/perf/imc-pmu.c</span>
<span class="p_header">index 36344117c680..cf64e16f92c2 100644</span>
<span class="p_header">--- a/arch/powerpc/perf/imc-pmu.c</span>
<span class="p_header">+++ b/arch/powerpc/perf/imc-pmu.c</span>
<span class="p_chunk">@@ -467,7 +467,7 @@</span> <span class="p_context"> static int nest_imc_event_init(struct perf_event *event)</span>
 	 * Nest HW counter memory resides in a per-chip reserve-memory (HOMER).
 	 * Get the base memory addresss for this cpu.
 	 */
<span class="p_del">-	chip_id = topology_physical_package_id(event-&gt;cpu);</span>
<span class="p_add">+	chip_id = cpu_to_chip_id(event-&gt;cpu);</span>
 	pcni = pmu-&gt;mem_info;
 	do {
 		if (pcni-&gt;id == chip_id) {
<span class="p_chunk">@@ -524,19 +524,19 @@</span> <span class="p_context"> static int nest_imc_event_init(struct perf_event *event)</span>
  */
 static int core_imc_mem_init(int cpu, int size)
 {
<span class="p_del">-	int phys_id, rc = 0, core_id = (cpu / threads_per_core);</span>
<span class="p_add">+	int nid, rc = 0, core_id = (cpu / threads_per_core);</span>
 	struct imc_mem_info *mem_info;
 
 	/*
 	 * alloc_pages_node() will allocate memory for core in the
 	 * local node only.
 	 */
<span class="p_del">-	phys_id = topology_physical_package_id(cpu);</span>
<span class="p_add">+	nid = cpu_to_node(cpu);</span>
 	mem_info = &amp;core_imc_pmu-&gt;mem_info[core_id];
 	mem_info-&gt;id = core_id;
 
 	/* We need only vbase for core counters */
<span class="p_del">-	mem_info-&gt;vbase = page_address(alloc_pages_node(phys_id,</span>
<span class="p_add">+	mem_info-&gt;vbase = page_address(alloc_pages_node(nid,</span>
 					  GFP_KERNEL | __GFP_ZERO | __GFP_THISNODE |
 					  __GFP_NOWARN, get_order(size)));
 	if (!mem_info-&gt;vbase)
<span class="p_chunk">@@ -797,14 +797,14 @@</span> <span class="p_context"> static int core_imc_event_init(struct perf_event *event)</span>
 static int thread_imc_mem_alloc(int cpu_id, int size)
 {
 	u64 ldbar_value, *local_mem = per_cpu(thread_imc_mem, cpu_id);
<span class="p_del">-	int phys_id = topology_physical_package_id(cpu_id);</span>
<span class="p_add">+	int nid = cpu_to_node(cpu_id);</span>
 
 	if (!local_mem) {
 		/*
 		 * This case could happen only once at start, since we dont
 		 * free the memory in cpu offline path.
 		 */
<span class="p_del">-		local_mem = page_address(alloc_pages_node(phys_id,</span>
<span class="p_add">+		local_mem = page_address(alloc_pages_node(nid,</span>
 				  GFP_KERNEL | __GFP_ZERO | __GFP_THISNODE |
 				  __GFP_NOWARN, get_order(size)));
 		if (!local_mem)
<span class="p_header">diff --git a/arch/s390/include/asm/switch_to.h b/arch/s390/include/asm/switch_to.h</span>
<span class="p_header">index c21fe1d57c00..ec7b476c1ac5 100644</span>
<span class="p_header">--- a/arch/s390/include/asm/switch_to.h</span>
<span class="p_header">+++ b/arch/s390/include/asm/switch_to.h</span>
<span class="p_chunk">@@ -37,8 +37,8 @@</span> <span class="p_context"> static inline void restore_access_regs(unsigned int *acrs)</span>
 		save_ri_cb(prev-&gt;thread.ri_cb);				\
 		save_gs_cb(prev-&gt;thread.gs_cb);				\
 	}								\
<span class="p_add">+	update_cr_regs(next);						\</span>
 	if (next-&gt;mm) {							\
<span class="p_del">-		update_cr_regs(next);					\</span>
 		set_cpu_flag(CIF_FPU);					\
 		restore_access_regs(&amp;next-&gt;thread.acrs[0]);		\
 		restore_ri_cb(next-&gt;thread.ri_cb, prev-&gt;thread.ri_cb);	\
<span class="p_header">diff --git a/arch/s390/kernel/dis.c b/arch/s390/kernel/dis.c</span>
<span class="p_header">index f7e82302a71e..2394557653d5 100644</span>
<span class="p_header">--- a/arch/s390/kernel/dis.c</span>
<span class="p_header">+++ b/arch/s390/kernel/dis.c</span>
<span class="p_chunk">@@ -1548,6 +1548,7 @@</span> <span class="p_context"> static struct s390_insn opcode_e7[] = {</span>
 	{ &quot;vfsq&quot;, 0xce, INSTR_VRR_VV000MM },
 	{ &quot;vfs&quot;, 0xe2, INSTR_VRR_VVV00MM },
 	{ &quot;vftci&quot;, 0x4a, INSTR_VRI_VVIMM },
<span class="p_add">+	{ &quot;&quot;, 0, INSTR_INVALID }</span>
 };
 
 static struct s390_insn opcode_eb[] = {
<span class="p_chunk">@@ -1953,7 +1954,7 @@</span> <span class="p_context"> void show_code(struct pt_regs *regs)</span>
 {
 	char *mode = user_mode(regs) ? &quot;User&quot; : &quot;Krnl&quot;;
 	unsigned char code[64];
<span class="p_del">-	char buffer[64], *ptr;</span>
<span class="p_add">+	char buffer[128], *ptr;</span>
 	mm_segment_t old_fs;
 	unsigned long addr;
 	int start, end, opsize, hops, i;
<span class="p_chunk">@@ -2016,7 +2017,7 @@</span> <span class="p_context"> void show_code(struct pt_regs *regs)</span>
 		start += opsize;
 		pr_cont(&quot;%s&quot;, buffer);
 		ptr = buffer;
<span class="p_del">-		ptr += sprintf(ptr, &quot;\n          &quot;);</span>
<span class="p_add">+		ptr += sprintf(ptr, &quot;\n\t  &quot;);</span>
 		hops++;
 	}
 	pr_cont(&quot;\n&quot;);
<span class="p_header">diff --git a/arch/s390/kernel/early.c b/arch/s390/kernel/early.c</span>
<span class="p_header">index b945448b9eae..f7b280f0ab16 100644</span>
<span class="p_header">--- a/arch/s390/kernel/early.c</span>
<span class="p_header">+++ b/arch/s390/kernel/early.c</span>
<span class="p_chunk">@@ -375,8 +375,10 @@</span> <span class="p_context"> static __init void detect_machine_facilities(void)</span>
 		S390_lowcore.machine_flags |= MACHINE_FLAG_IDTE;
 	if (test_facility(40))
 		S390_lowcore.machine_flags |= MACHINE_FLAG_LPP;
<span class="p_del">-	if (test_facility(50) &amp;&amp; test_facility(73))</span>
<span class="p_add">+	if (test_facility(50) &amp;&amp; test_facility(73)) {</span>
 		S390_lowcore.machine_flags |= MACHINE_FLAG_TE;
<span class="p_add">+		__ctl_set_bit(0, 55);</span>
<span class="p_add">+	}</span>
 	if (test_facility(51))
 		S390_lowcore.machine_flags |= MACHINE_FLAG_TLB_LC;
 	if (test_facility(129)) {
<span class="p_header">diff --git a/arch/s390/kernel/guarded_storage.c b/arch/s390/kernel/guarded_storage.c</span>
<span class="p_header">index bff39b66c9ff..9ee794e14f33 100644</span>
<span class="p_header">--- a/arch/s390/kernel/guarded_storage.c</span>
<span class="p_header">+++ b/arch/s390/kernel/guarded_storage.c</span>
<span class="p_chunk">@@ -14,9 +14,11 @@</span> <span class="p_context"></span>
 
 void exit_thread_gs(void)
 {
<span class="p_add">+	preempt_disable();</span>
 	kfree(current-&gt;thread.gs_cb);
 	kfree(current-&gt;thread.gs_bc_cb);
 	current-&gt;thread.gs_cb = current-&gt;thread.gs_bc_cb = NULL;
<span class="p_add">+	preempt_enable();</span>
 }
 
 static int gs_enable(void)
<span class="p_header">diff --git a/arch/s390/kernel/machine_kexec.c b/arch/s390/kernel/machine_kexec.c</span>
<span class="p_header">index b0ba2c26b45e..d6f7782e75c9 100644</span>
<span class="p_header">--- a/arch/s390/kernel/machine_kexec.c</span>
<span class="p_header">+++ b/arch/s390/kernel/machine_kexec.c</span>
<span class="p_chunk">@@ -269,6 +269,7 @@</span> <span class="p_context"> static void __do_machine_kexec(void *data)</span>
 	s390_reset_system();
 	data_mover = (relocate_kernel_t) page_to_phys(image-&gt;control_code_page);
 
<span class="p_add">+	__arch_local_irq_stnsm(0xfb); /* disable DAT - avoid no-execute */</span>
 	/* Call the moving routine */
 	(*data_mover)(&amp;image-&gt;head, image-&gt;start);
 
<span class="p_header">diff --git a/arch/s390/kernel/process.c b/arch/s390/kernel/process.c</span>
<span class="p_header">index a4a84fb08046..203b7cd7c348 100644</span>
<span class="p_header">--- a/arch/s390/kernel/process.c</span>
<span class="p_header">+++ b/arch/s390/kernel/process.c</span>
<span class="p_chunk">@@ -100,6 +100,7 @@</span> <span class="p_context"> int copy_thread_tls(unsigned long clone_flags, unsigned long new_stackp,</span>
 	memset(&amp;p-&gt;thread.per_user, 0, sizeof(p-&gt;thread.per_user));
 	memset(&amp;p-&gt;thread.per_event, 0, sizeof(p-&gt;thread.per_event));
 	clear_tsk_thread_flag(p, TIF_SINGLE_STEP);
<span class="p_add">+	p-&gt;thread.per_flags = 0;</span>
 	/* Initialize per thread user and system timer values */
 	p-&gt;thread.user_timer = 0;
 	p-&gt;thread.guest_timer = 0;
<span class="p_header">diff --git a/arch/s390/kernel/relocate_kernel.S b/arch/s390/kernel/relocate_kernel.S</span>
<span class="p_header">index ca37e5d5b40c..9c2c96da23d0 100644</span>
<span class="p_header">--- a/arch/s390/kernel/relocate_kernel.S</span>
<span class="p_header">+++ b/arch/s390/kernel/relocate_kernel.S</span>
<span class="p_chunk">@@ -29,7 +29,6 @@</span> <span class="p_context"></span>
 ENTRY(relocate_kernel)
 		basr	%r13,0		# base address
 	.base:
<span class="p_del">-		stnsm	sys_msk-.base(%r13),0xfb	# disable DAT</span>
 		stctg	%c0,%c15,ctlregs-.base(%r13)
 		stmg	%r0,%r15,gprregs-.base(%r13)
 		lghi	%r0,3
<span class="p_chunk">@@ -103,8 +102,6 @@</span> <span class="p_context"> ENTRY(relocate_kernel)</span>
 		.align	8
 	load_psw:
 		.long	0x00080000,0x80000000
<span class="p_del">-	sys_msk:</span>
<span class="p_del">-		.quad	0</span>
 	ctlregs:
 		.rept	16
 		.quad	0
<span class="p_header">diff --git a/arch/s390/kernel/runtime_instr.c b/arch/s390/kernel/runtime_instr.c</span>
<span class="p_header">index 32aefb215e59..d85c64821a6b 100644</span>
<span class="p_header">--- a/arch/s390/kernel/runtime_instr.c</span>
<span class="p_header">+++ b/arch/s390/kernel/runtime_instr.c</span>
<span class="p_chunk">@@ -50,11 +50,13 @@</span> <span class="p_context"> void exit_thread_runtime_instr(void)</span>
 {
 	struct task_struct *task = current;
 
<span class="p_add">+	preempt_disable();</span>
 	if (!task-&gt;thread.ri_cb)
 		return;
 	disable_runtime_instr();
 	kfree(task-&gt;thread.ri_cb);
 	task-&gt;thread.ri_cb = NULL;
<span class="p_add">+	preempt_enable();</span>
 }
 
 SYSCALL_DEFINE1(s390_runtime_instr, int, command)
<span class="p_chunk">@@ -65,9 +67,7 @@</span> <span class="p_context"> SYSCALL_DEFINE1(s390_runtime_instr, int, command)</span>
 		return -EOPNOTSUPP;
 
 	if (command == S390_RUNTIME_INSTR_STOP) {
<span class="p_del">-		preempt_disable();</span>
 		exit_thread_runtime_instr();
<span class="p_del">-		preempt_enable();</span>
 		return 0;
 	}
 
<span class="p_header">diff --git a/arch/x86/entry/entry_64.S b/arch/x86/entry/entry_64.S</span>
<span class="p_header">index bcfc5668dcb2..518d9286b3d1 100644</span>
<span class="p_header">--- a/arch/x86/entry/entry_64.S</span>
<span class="p_header">+++ b/arch/x86/entry/entry_64.S</span>
<span class="p_chunk">@@ -51,15 +51,19 @@</span> <span class="p_context"> ENTRY(native_usergs_sysret64)</span>
 END(native_usergs_sysret64)
 #endif /* CONFIG_PARAVIRT */
 
<span class="p_del">-.macro TRACE_IRQS_IRETQ</span>
<span class="p_add">+.macro TRACE_IRQS_FLAGS flags:req</span>
 #ifdef CONFIG_TRACE_IRQFLAGS
<span class="p_del">-	bt	$9, EFLAGS(%rsp)		/* interrupts off? */</span>
<span class="p_add">+	bt	$9, \flags		/* interrupts off? */</span>
 	jnc	1f
 	TRACE_IRQS_ON
 1:
 #endif
 .endm
 
<span class="p_add">+.macro TRACE_IRQS_IRETQ</span>
<span class="p_add">+	TRACE_IRQS_FLAGS EFLAGS(%rsp)</span>
<span class="p_add">+.endm</span>
<span class="p_add">+</span>
 /*
  * When dynamic function tracer is enabled it will add a breakpoint
  * to all locations that it is about to modify, sync CPUs, update
<span class="p_chunk">@@ -148,8 +152,6 @@</span> <span class="p_context"> ENTRY(entry_SYSCALL_64)</span>
 	movq	%rsp, PER_CPU_VAR(rsp_scratch)
 	movq	PER_CPU_VAR(cpu_current_top_of_stack), %rsp
 
<span class="p_del">-	TRACE_IRQS_OFF</span>
<span class="p_del">-</span>
 	/* Construct struct pt_regs on stack */
 	pushq	$__USER_DS			/* pt_regs-&gt;ss */
 	pushq	PER_CPU_VAR(rsp_scratch)	/* pt_regs-&gt;sp */
<span class="p_chunk">@@ -170,6 +172,8 @@</span> <span class="p_context"> GLOBAL(entry_SYSCALL_64_after_hwframe)</span>
 	sub	$(6*8), %rsp			/* pt_regs-&gt;bp, bx, r12-15 not saved */
 	UNWIND_HINT_REGS extra=0
 
<span class="p_add">+	TRACE_IRQS_OFF</span>
<span class="p_add">+</span>
 	/*
 	 * If we need to do entry work or if we guess we&#39;ll need to do
 	 * exit work, go straight to the slow path.
<span class="p_chunk">@@ -923,11 +927,13 @@</span> <span class="p_context"> ENTRY(native_load_gs_index)</span>
 	FRAME_BEGIN
 	pushfq
 	DISABLE_INTERRUPTS(CLBR_ANY &amp; ~CLBR_RDI)
<span class="p_add">+	TRACE_IRQS_OFF</span>
 	SWAPGS
 .Lgs_change:
 	movl	%edi, %gs
 2:	ALTERNATIVE &quot;&quot;, &quot;mfence&quot;, X86_BUG_SWAPGS_FENCE
 	SWAPGS
<span class="p_add">+	TRACE_IRQS_FLAGS (%rsp)</span>
 	popfq
 	FRAME_END
 	ret
<span class="p_header">diff --git a/arch/x86/events/intel/core.c b/arch/x86/events/intel/core.c</span>
<span class="p_header">index 9fb9a1f1e47b..f94855000d4e 100644</span>
<span class="p_header">--- a/arch/x86/events/intel/core.c</span>
<span class="p_header">+++ b/arch/x86/events/intel/core.c</span>
<span class="p_chunk">@@ -3730,6 +3730,19 @@</span> <span class="p_context"> EVENT_ATTR_STR(cycles-t,	cycles_t,	&quot;event=0x3c,in_tx=1&quot;);</span>
 EVENT_ATTR_STR(cycles-ct,	cycles_ct,	&quot;event=0x3c,in_tx=1,in_tx_cp=1&quot;);
 
 static struct attribute *hsw_events_attrs[] = {
<span class="p_add">+	EVENT_PTR(mem_ld_hsw),</span>
<span class="p_add">+	EVENT_PTR(mem_st_hsw),</span>
<span class="p_add">+	EVENT_PTR(td_slots_issued),</span>
<span class="p_add">+	EVENT_PTR(td_slots_retired),</span>
<span class="p_add">+	EVENT_PTR(td_fetch_bubbles),</span>
<span class="p_add">+	EVENT_PTR(td_total_slots),</span>
<span class="p_add">+	EVENT_PTR(td_total_slots_scale),</span>
<span class="p_add">+	EVENT_PTR(td_recovery_bubbles),</span>
<span class="p_add">+	EVENT_PTR(td_recovery_bubbles_scale),</span>
<span class="p_add">+	NULL</span>
<span class="p_add">+};</span>
<span class="p_add">+</span>
<span class="p_add">+static struct attribute *hsw_tsx_events_attrs[] = {</span>
 	EVENT_PTR(tx_start),
 	EVENT_PTR(tx_commit),
 	EVENT_PTR(tx_abort),
<span class="p_chunk">@@ -3742,18 +3755,16 @@</span> <span class="p_context"> static struct attribute *hsw_events_attrs[] = {</span>
 	EVENT_PTR(el_conflict),
 	EVENT_PTR(cycles_t),
 	EVENT_PTR(cycles_ct),
<span class="p_del">-	EVENT_PTR(mem_ld_hsw),</span>
<span class="p_del">-	EVENT_PTR(mem_st_hsw),</span>
<span class="p_del">-	EVENT_PTR(td_slots_issued),</span>
<span class="p_del">-	EVENT_PTR(td_slots_retired),</span>
<span class="p_del">-	EVENT_PTR(td_fetch_bubbles),</span>
<span class="p_del">-	EVENT_PTR(td_total_slots),</span>
<span class="p_del">-	EVENT_PTR(td_total_slots_scale),</span>
<span class="p_del">-	EVENT_PTR(td_recovery_bubbles),</span>
<span class="p_del">-	EVENT_PTR(td_recovery_bubbles_scale),</span>
 	NULL
 };
 
<span class="p_add">+static __init struct attribute **get_hsw_events_attrs(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return boot_cpu_has(X86_FEATURE_RTM) ?</span>
<span class="p_add">+		merge_attr(hsw_events_attrs, hsw_tsx_events_attrs) :</span>
<span class="p_add">+		hsw_events_attrs;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static ssize_t freeze_on_smi_show(struct device *cdev,
 				  struct device_attribute *attr,
 				  char *buf)
<span class="p_chunk">@@ -4182,7 +4193,7 @@</span> <span class="p_context"> __init int intel_pmu_init(void)</span>
 
 		x86_pmu.hw_config = hsw_hw_config;
 		x86_pmu.get_event_constraints = hsw_get_event_constraints;
<span class="p_del">-		x86_pmu.cpu_events = hsw_events_attrs;</span>
<span class="p_add">+		x86_pmu.cpu_events = get_hsw_events_attrs();</span>
 		x86_pmu.lbr_double_abort = true;
 		extra_attr = boot_cpu_has(X86_FEATURE_RTM) ?
 			hsw_format_attr : nhm_format_attr;
<span class="p_chunk">@@ -4221,7 +4232,7 @@</span> <span class="p_context"> __init int intel_pmu_init(void)</span>
 
 		x86_pmu.hw_config = hsw_hw_config;
 		x86_pmu.get_event_constraints = hsw_get_event_constraints;
<span class="p_del">-		x86_pmu.cpu_events = hsw_events_attrs;</span>
<span class="p_add">+		x86_pmu.cpu_events = get_hsw_events_attrs();</span>
 		x86_pmu.limit_period = bdw_limit_period;
 		extra_attr = boot_cpu_has(X86_FEATURE_RTM) ?
 			hsw_format_attr : nhm_format_attr;
<span class="p_chunk">@@ -4279,7 +4290,7 @@</span> <span class="p_context"> __init int intel_pmu_init(void)</span>
 		extra_attr = boot_cpu_has(X86_FEATURE_RTM) ?
 			hsw_format_attr : nhm_format_attr;
 		extra_attr = merge_attr(extra_attr, skl_format_attr);
<span class="p_del">-		x86_pmu.cpu_events = hsw_events_attrs;</span>
<span class="p_add">+		x86_pmu.cpu_events = get_hsw_events_attrs();</span>
 		intel_pmu_pebs_data_source_skl(
 			boot_cpu_data.x86_model == INTEL_FAM6_SKYLAKE_X);
 		pr_cont(&quot;Skylake events, &quot;);
<span class="p_header">diff --git a/arch/x86/kernel/mpparse.c b/arch/x86/kernel/mpparse.c</span>
<span class="p_header">index 410c5dadcee3..3a4b12809ab5 100644</span>
<span class="p_header">--- a/arch/x86/kernel/mpparse.c</span>
<span class="p_header">+++ b/arch/x86/kernel/mpparse.c</span>
<span class="p_chunk">@@ -431,6 +431,7 @@</span> <span class="p_context"> static inline void __init construct_default_ISA_mptable(int mpc_default_type)</span>
 }
 
 static unsigned long mpf_base;
<span class="p_add">+static bool mpf_found;</span>
 
 static unsigned long __init get_mpc_size(unsigned long physptr)
 {
<span class="p_chunk">@@ -504,7 +505,7 @@</span> <span class="p_context"> void __init default_get_smp_config(unsigned int early)</span>
 	if (!smp_found_config)
 		return;
 
<span class="p_del">-	if (!mpf_base)</span>
<span class="p_add">+	if (!mpf_found)</span>
 		return;
 
 	if (acpi_lapic &amp;&amp; early)
<span class="p_chunk">@@ -593,6 +594,7 @@</span> <span class="p_context"> static int __init smp_scan_config(unsigned long base, unsigned long length)</span>
 			smp_found_config = 1;
 #endif
 			mpf_base = base;
<span class="p_add">+			mpf_found = true;</span>
 
 			pr_info(&quot;found SMP MP-table at [mem %#010lx-%#010lx] mapped at [%p]\n&quot;,
 				base, base + sizeof(*mpf) - 1, mpf);
<span class="p_chunk">@@ -858,7 +860,7 @@</span> <span class="p_context"> static int __init update_mp_table(void)</span>
 	if (!enable_update_mptable)
 		return 0;
 
<span class="p_del">-	if (!mpf_base)</span>
<span class="p_add">+	if (!mpf_found)</span>
 		return 0;
 
 	mpf = early_memremap(mpf_base, sizeof(*mpf));
<span class="p_header">diff --git a/arch/x86/kvm/svm.c b/arch/x86/kvm/svm.c</span>
<span class="p_header">index 0e68f0b3cbf7..ca209a4a7834 100644</span>
<span class="p_header">--- a/arch/x86/kvm/svm.c</span>
<span class="p_header">+++ b/arch/x86/kvm/svm.c</span>
<span class="p_chunk">@@ -3657,6 +3657,13 @@</span> <span class="p_context"> static int svm_set_msr(struct kvm_vcpu *vcpu, struct msr_data *msr)</span>
 	u32 ecx = msr-&gt;index;
 	u64 data = msr-&gt;data;
 	switch (ecx) {
<span class="p_add">+	case MSR_IA32_CR_PAT:</span>
<span class="p_add">+		if (!kvm_mtrr_valid(vcpu, MSR_IA32_CR_PAT, data))</span>
<span class="p_add">+			return 1;</span>
<span class="p_add">+		vcpu-&gt;arch.pat = data;</span>
<span class="p_add">+		svm-&gt;vmcb-&gt;save.g_pat = data;</span>
<span class="p_add">+		mark_dirty(svm-&gt;vmcb, VMCB_NPT);</span>
<span class="p_add">+		break;</span>
 	case MSR_IA32_TSC:
 		kvm_write_tsc(vcpu, msr);
 		break;
<span class="p_header">diff --git a/arch/x86/kvm/vmx.c b/arch/x86/kvm/vmx.c</span>
<span class="p_header">index a6f4f095f8f4..21cad7068cbf 100644</span>
<span class="p_header">--- a/arch/x86/kvm/vmx.c</span>
<span class="p_header">+++ b/arch/x86/kvm/vmx.c</span>
<span class="p_chunk">@@ -202,6 +202,10 @@</span> <span class="p_context"> struct loaded_vmcs {</span>
 	bool nmi_known_unmasked;
 	unsigned long vmcs_host_cr3;	/* May not match real cr3 */
 	unsigned long vmcs_host_cr4;	/* May not match real cr4 */
<span class="p_add">+	/* Support for vnmi-less CPUs */</span>
<span class="p_add">+	int soft_vnmi_blocked;</span>
<span class="p_add">+	ktime_t entry_time;</span>
<span class="p_add">+	s64 vnmi_blocked_time;</span>
 	struct list_head loaded_vmcss_on_cpu_link;
 };
 
<span class="p_chunk">@@ -1286,6 +1290,11 @@</span> <span class="p_context"> static inline bool cpu_has_vmx_invpcid(void)</span>
 		SECONDARY_EXEC_ENABLE_INVPCID;
 }
 
<span class="p_add">+static inline bool cpu_has_virtual_nmis(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return vmcs_config.pin_based_exec_ctrl &amp; PIN_BASED_VIRTUAL_NMIS;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static inline bool cpu_has_vmx_wbinvd_exit(void)
 {
 	return vmcs_config.cpu_based_2nd_exec_ctrl &amp;
<span class="p_chunk">@@ -1343,11 +1352,6 @@</span> <span class="p_context"> static inline bool nested_cpu_has2(struct vmcs12 *vmcs12, u32 bit)</span>
 		(vmcs12-&gt;secondary_vm_exec_control &amp; bit);
 }
 
<span class="p_del">-static inline bool nested_cpu_has_virtual_nmis(struct vmcs12 *vmcs12)</span>
<span class="p_del">-{</span>
<span class="p_del">-	return vmcs12-&gt;pin_based_vm_exec_control &amp; PIN_BASED_VIRTUAL_NMIS;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
 static inline bool nested_cpu_has_preemption_timer(struct vmcs12 *vmcs12)
 {
 	return vmcs12-&gt;pin_based_vm_exec_control &amp;
<span class="p_chunk">@@ -3699,9 +3703,9 @@</span> <span class="p_context"> static __init int setup_vmcs_config(struct vmcs_config *vmcs_conf)</span>
 				&amp;_vmexit_control) &lt; 0)
 		return -EIO;
 
<span class="p_del">-	min = PIN_BASED_EXT_INTR_MASK | PIN_BASED_NMI_EXITING |</span>
<span class="p_del">-		PIN_BASED_VIRTUAL_NMIS;</span>
<span class="p_del">-	opt = PIN_BASED_POSTED_INTR | PIN_BASED_VMX_PREEMPTION_TIMER;</span>
<span class="p_add">+	min = PIN_BASED_EXT_INTR_MASK | PIN_BASED_NMI_EXITING;</span>
<span class="p_add">+	opt = PIN_BASED_VIRTUAL_NMIS | PIN_BASED_POSTED_INTR |</span>
<span class="p_add">+		 PIN_BASED_VMX_PREEMPTION_TIMER;</span>
 	if (adjust_vmx_controls(min, opt, MSR_IA32_VMX_PINBASED_CTLS,
 				&amp;_pin_based_exec_control) &lt; 0)
 		return -EIO;
<span class="p_chunk">@@ -5667,7 +5671,8 @@</span> <span class="p_context"> static void enable_irq_window(struct kvm_vcpu *vcpu)</span>
 
 static void enable_nmi_window(struct kvm_vcpu *vcpu)
 {
<span class="p_del">-	if (vmcs_read32(GUEST_INTERRUPTIBILITY_INFO) &amp; GUEST_INTR_STATE_STI) {</span>
<span class="p_add">+	if (!cpu_has_virtual_nmis() ||</span>
<span class="p_add">+	    vmcs_read32(GUEST_INTERRUPTIBILITY_INFO) &amp; GUEST_INTR_STATE_STI) {</span>
 		enable_irq_window(vcpu);
 		return;
 	}
<span class="p_chunk">@@ -5707,6 +5712,19 @@</span> <span class="p_context"> static void vmx_inject_nmi(struct kvm_vcpu *vcpu)</span>
 {
 	struct vcpu_vmx *vmx = to_vmx(vcpu);
 
<span class="p_add">+	if (!cpu_has_virtual_nmis()) {</span>
<span class="p_add">+		/*</span>
<span class="p_add">+		 * Tracking the NMI-blocked state in software is built upon</span>
<span class="p_add">+		 * finding the next open IRQ window. This, in turn, depends on</span>
<span class="p_add">+		 * well-behaving guests: They have to keep IRQs disabled at</span>
<span class="p_add">+		 * least as long as the NMI handler runs. Otherwise we may</span>
<span class="p_add">+		 * cause NMI nesting, maybe breaking the guest. But as this is</span>
<span class="p_add">+		 * highly unlikely, we can live with the residual risk.</span>
<span class="p_add">+		 */</span>
<span class="p_add">+		vmx-&gt;loaded_vmcs-&gt;soft_vnmi_blocked = 1;</span>
<span class="p_add">+		vmx-&gt;loaded_vmcs-&gt;vnmi_blocked_time = 0;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
 	++vcpu-&gt;stat.nmi_injections;
 	vmx-&gt;loaded_vmcs-&gt;nmi_known_unmasked = false;
 
<span class="p_chunk">@@ -5725,6 +5743,8 @@</span> <span class="p_context"> static bool vmx_get_nmi_mask(struct kvm_vcpu *vcpu)</span>
 	struct vcpu_vmx *vmx = to_vmx(vcpu);
 	bool masked;
 
<span class="p_add">+	if (!cpu_has_virtual_nmis())</span>
<span class="p_add">+		return vmx-&gt;loaded_vmcs-&gt;soft_vnmi_blocked;</span>
 	if (vmx-&gt;loaded_vmcs-&gt;nmi_known_unmasked)
 		return false;
 	masked = vmcs_read32(GUEST_INTERRUPTIBILITY_INFO) &amp; GUEST_INTR_STATE_NMI;
<span class="p_chunk">@@ -5736,13 +5756,20 @@</span> <span class="p_context"> static void vmx_set_nmi_mask(struct kvm_vcpu *vcpu, bool masked)</span>
 {
 	struct vcpu_vmx *vmx = to_vmx(vcpu);
 
<span class="p_del">-	vmx-&gt;loaded_vmcs-&gt;nmi_known_unmasked = !masked;</span>
<span class="p_del">-	if (masked)</span>
<span class="p_del">-		vmcs_set_bits(GUEST_INTERRUPTIBILITY_INFO,</span>
<span class="p_del">-			      GUEST_INTR_STATE_NMI);</span>
<span class="p_del">-	else</span>
<span class="p_del">-		vmcs_clear_bits(GUEST_INTERRUPTIBILITY_INFO,</span>
<span class="p_del">-				GUEST_INTR_STATE_NMI);</span>
<span class="p_add">+	if (!cpu_has_virtual_nmis()) {</span>
<span class="p_add">+		if (vmx-&gt;loaded_vmcs-&gt;soft_vnmi_blocked != masked) {</span>
<span class="p_add">+			vmx-&gt;loaded_vmcs-&gt;soft_vnmi_blocked = masked;</span>
<span class="p_add">+			vmx-&gt;loaded_vmcs-&gt;vnmi_blocked_time = 0;</span>
<span class="p_add">+		}</span>
<span class="p_add">+	} else {</span>
<span class="p_add">+		vmx-&gt;loaded_vmcs-&gt;nmi_known_unmasked = !masked;</span>
<span class="p_add">+		if (masked)</span>
<span class="p_add">+			vmcs_set_bits(GUEST_INTERRUPTIBILITY_INFO,</span>
<span class="p_add">+				      GUEST_INTR_STATE_NMI);</span>
<span class="p_add">+		else</span>
<span class="p_add">+			vmcs_clear_bits(GUEST_INTERRUPTIBILITY_INFO,</span>
<span class="p_add">+					GUEST_INTR_STATE_NMI);</span>
<span class="p_add">+	}</span>
 }
 
 static int vmx_nmi_allowed(struct kvm_vcpu *vcpu)
<span class="p_chunk">@@ -5750,6 +5777,10 @@</span> <span class="p_context"> static int vmx_nmi_allowed(struct kvm_vcpu *vcpu)</span>
 	if (to_vmx(vcpu)-&gt;nested.nested_run_pending)
 		return 0;
 
<span class="p_add">+	if (!cpu_has_virtual_nmis() &amp;&amp;</span>
<span class="p_add">+	    to_vmx(vcpu)-&gt;loaded_vmcs-&gt;soft_vnmi_blocked)</span>
<span class="p_add">+		return 0;</span>
<span class="p_add">+</span>
 	return	!(vmcs_read32(GUEST_INTERRUPTIBILITY_INFO) &amp;
 		  (GUEST_INTR_STATE_MOV_SS | GUEST_INTR_STATE_STI
 		   | GUEST_INTR_STATE_NMI));
<span class="p_chunk">@@ -6478,6 +6509,7 @@</span> <span class="p_context"> static int handle_ept_violation(struct kvm_vcpu *vcpu)</span>
 	 * AAK134, BY25.
 	 */
 	if (!(to_vmx(vcpu)-&gt;idt_vectoring_info &amp; VECTORING_INFO_VALID_MASK) &amp;&amp;
<span class="p_add">+			cpu_has_virtual_nmis() &amp;&amp;</span>
 			(exit_qualification &amp; INTR_INFO_UNBLOCK_NMI))
 		vmcs_set_bits(GUEST_INTERRUPTIBILITY_INFO, GUEST_INTR_STATE_NMI);
 
<span class="p_chunk">@@ -6961,7 +6993,7 @@</span> <span class="p_context"> static struct loaded_vmcs *nested_get_current_vmcs02(struct vcpu_vmx *vmx)</span>
 	}
 
 	/* Create a new VMCS */
<span class="p_del">-	item = kmalloc(sizeof(struct vmcs02_list), GFP_KERNEL);</span>
<span class="p_add">+	item = kzalloc(sizeof(struct vmcs02_list), GFP_KERNEL);</span>
 	if (!item)
 		return NULL;
 	item-&gt;vmcs02.vmcs = alloc_vmcs();
<span class="p_chunk">@@ -7978,6 +8010,7 @@</span> <span class="p_context"> static int handle_pml_full(struct kvm_vcpu *vcpu)</span>
 	 * &quot;blocked by NMI&quot; bit has to be set before next VM entry.
 	 */
 	if (!(to_vmx(vcpu)-&gt;idt_vectoring_info &amp; VECTORING_INFO_VALID_MASK) &amp;&amp;
<span class="p_add">+			cpu_has_virtual_nmis() &amp;&amp;</span>
 			(exit_qualification &amp; INTR_INFO_UNBLOCK_NMI))
 		vmcs_set_bits(GUEST_INTERRUPTIBILITY_INFO,
 				GUEST_INTR_STATE_NMI);
<span class="p_chunk">@@ -8822,6 +8855,25 @@</span> <span class="p_context"> static int vmx_handle_exit(struct kvm_vcpu *vcpu)</span>
 		return 0;
 	}
 
<span class="p_add">+	if (unlikely(!cpu_has_virtual_nmis() &amp;&amp;</span>
<span class="p_add">+		     vmx-&gt;loaded_vmcs-&gt;soft_vnmi_blocked)) {</span>
<span class="p_add">+		if (vmx_interrupt_allowed(vcpu)) {</span>
<span class="p_add">+			vmx-&gt;loaded_vmcs-&gt;soft_vnmi_blocked = 0;</span>
<span class="p_add">+		} else if (vmx-&gt;loaded_vmcs-&gt;vnmi_blocked_time &gt; 1000000000LL &amp;&amp;</span>
<span class="p_add">+			   vcpu-&gt;arch.nmi_pending) {</span>
<span class="p_add">+			/*</span>
<span class="p_add">+			 * This CPU don&#39;t support us in finding the end of an</span>
<span class="p_add">+			 * NMI-blocked window if the guest runs with IRQs</span>
<span class="p_add">+			 * disabled. So we pull the trigger after 1 s of</span>
<span class="p_add">+			 * futile waiting, but inform the user about this.</span>
<span class="p_add">+			 */</span>
<span class="p_add">+			printk(KERN_WARNING &quot;%s: Breaking out of NMI-blocked &quot;</span>
<span class="p_add">+			       &quot;state on VCPU %d after 1 s timeout\n&quot;,</span>
<span class="p_add">+			       __func__, vcpu-&gt;vcpu_id);</span>
<span class="p_add">+			vmx-&gt;loaded_vmcs-&gt;soft_vnmi_blocked = 0;</span>
<span class="p_add">+		}</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
 	if (exit_reason &lt; kvm_vmx_max_exit_handlers
 	    &amp;&amp; kvm_vmx_exit_handlers[exit_reason])
 		return kvm_vmx_exit_handlers[exit_reason](vcpu);
<span class="p_chunk">@@ -9104,33 +9156,38 @@</span> <span class="p_context"> static void vmx_recover_nmi_blocking(struct vcpu_vmx *vmx)</span>
 
 	idtv_info_valid = vmx-&gt;idt_vectoring_info &amp; VECTORING_INFO_VALID_MASK;
 
<span class="p_del">-	if (vmx-&gt;loaded_vmcs-&gt;nmi_known_unmasked)</span>
<span class="p_del">-		return;</span>
<span class="p_del">-	/*</span>
<span class="p_del">-	 * Can&#39;t use vmx-&gt;exit_intr_info since we&#39;re not sure what</span>
<span class="p_del">-	 * the exit reason is.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	exit_intr_info = vmcs_read32(VM_EXIT_INTR_INFO);</span>
<span class="p_del">-	unblock_nmi = (exit_intr_info &amp; INTR_INFO_UNBLOCK_NMI) != 0;</span>
<span class="p_del">-	vector = exit_intr_info &amp; INTR_INFO_VECTOR_MASK;</span>
<span class="p_del">-	/*</span>
<span class="p_del">-	 * SDM 3: 27.7.1.2 (September 2008)</span>
<span class="p_del">-	 * Re-set bit &quot;block by NMI&quot; before VM entry if vmexit caused by</span>
<span class="p_del">-	 * a guest IRET fault.</span>
<span class="p_del">-	 * SDM 3: 23.2.2 (September 2008)</span>
<span class="p_del">-	 * Bit 12 is undefined in any of the following cases:</span>
<span class="p_del">-	 *  If the VM exit sets the valid bit in the IDT-vectoring</span>
<span class="p_del">-	 *   information field.</span>
<span class="p_del">-	 *  If the VM exit is due to a double fault.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	if ((exit_intr_info &amp; INTR_INFO_VALID_MASK) &amp;&amp; unblock_nmi &amp;&amp;</span>
<span class="p_del">-	    vector != DF_VECTOR &amp;&amp; !idtv_info_valid)</span>
<span class="p_del">-		vmcs_set_bits(GUEST_INTERRUPTIBILITY_INFO,</span>
<span class="p_del">-			      GUEST_INTR_STATE_NMI);</span>
<span class="p_del">-	else</span>
<span class="p_del">-		vmx-&gt;loaded_vmcs-&gt;nmi_known_unmasked =</span>
<span class="p_del">-			!(vmcs_read32(GUEST_INTERRUPTIBILITY_INFO)</span>
<span class="p_del">-			  &amp; GUEST_INTR_STATE_NMI);</span>
<span class="p_add">+	if (cpu_has_virtual_nmis()) {</span>
<span class="p_add">+		if (vmx-&gt;loaded_vmcs-&gt;nmi_known_unmasked)</span>
<span class="p_add">+			return;</span>
<span class="p_add">+		/*</span>
<span class="p_add">+		 * Can&#39;t use vmx-&gt;exit_intr_info since we&#39;re not sure what</span>
<span class="p_add">+		 * the exit reason is.</span>
<span class="p_add">+		 */</span>
<span class="p_add">+		exit_intr_info = vmcs_read32(VM_EXIT_INTR_INFO);</span>
<span class="p_add">+		unblock_nmi = (exit_intr_info &amp; INTR_INFO_UNBLOCK_NMI) != 0;</span>
<span class="p_add">+		vector = exit_intr_info &amp; INTR_INFO_VECTOR_MASK;</span>
<span class="p_add">+		/*</span>
<span class="p_add">+		 * SDM 3: 27.7.1.2 (September 2008)</span>
<span class="p_add">+		 * Re-set bit &quot;block by NMI&quot; before VM entry if vmexit caused by</span>
<span class="p_add">+		 * a guest IRET fault.</span>
<span class="p_add">+		 * SDM 3: 23.2.2 (September 2008)</span>
<span class="p_add">+		 * Bit 12 is undefined in any of the following cases:</span>
<span class="p_add">+		 *  If the VM exit sets the valid bit in the IDT-vectoring</span>
<span class="p_add">+		 *   information field.</span>
<span class="p_add">+		 *  If the VM exit is due to a double fault.</span>
<span class="p_add">+		 */</span>
<span class="p_add">+		if ((exit_intr_info &amp; INTR_INFO_VALID_MASK) &amp;&amp; unblock_nmi &amp;&amp;</span>
<span class="p_add">+		    vector != DF_VECTOR &amp;&amp; !idtv_info_valid)</span>
<span class="p_add">+			vmcs_set_bits(GUEST_INTERRUPTIBILITY_INFO,</span>
<span class="p_add">+				      GUEST_INTR_STATE_NMI);</span>
<span class="p_add">+		else</span>
<span class="p_add">+			vmx-&gt;loaded_vmcs-&gt;nmi_known_unmasked =</span>
<span class="p_add">+				!(vmcs_read32(GUEST_INTERRUPTIBILITY_INFO)</span>
<span class="p_add">+				  &amp; GUEST_INTR_STATE_NMI);</span>
<span class="p_add">+	} else if (unlikely(vmx-&gt;loaded_vmcs-&gt;soft_vnmi_blocked))</span>
<span class="p_add">+		vmx-&gt;loaded_vmcs-&gt;vnmi_blocked_time +=</span>
<span class="p_add">+			ktime_to_ns(ktime_sub(ktime_get(),</span>
<span class="p_add">+					      vmx-&gt;loaded_vmcs-&gt;entry_time));</span>
 }
 
 static void __vmx_complete_interrupts(struct kvm_vcpu *vcpu,
<span class="p_chunk">@@ -9247,6 +9304,11 @@</span> <span class="p_context"> static void __noclone vmx_vcpu_run(struct kvm_vcpu *vcpu)</span>
 	struct vcpu_vmx *vmx = to_vmx(vcpu);
 	unsigned long debugctlmsr, cr3, cr4;
 
<span class="p_add">+	/* Record the guest&#39;s net vcpu time for enforced NMI injections. */</span>
<span class="p_add">+	if (unlikely(!cpu_has_virtual_nmis() &amp;&amp;</span>
<span class="p_add">+		     vmx-&gt;loaded_vmcs-&gt;soft_vnmi_blocked))</span>
<span class="p_add">+		vmx-&gt;loaded_vmcs-&gt;entry_time = ktime_get();</span>
<span class="p_add">+</span>
 	/* Don&#39;t enter VMX if guest state is invalid, let the exit handler
 	   start emulation until we arrive back to a valid state */
 	if (vmx-&gt;emulation_required)
<span class="p_chunk">@@ -11325,6 +11387,8 @@</span> <span class="p_context"> static void load_vmcs12_host_state(struct kvm_vcpu *vcpu,</span>
 	vmcs_writel(GUEST_SYSENTER_EIP, vmcs12-&gt;host_ia32_sysenter_eip);
 	vmcs_writel(GUEST_IDTR_BASE, vmcs12-&gt;host_idtr_base);
 	vmcs_writel(GUEST_GDTR_BASE, vmcs12-&gt;host_gdtr_base);
<span class="p_add">+	vmcs_write32(GUEST_IDTR_LIMIT, 0xFFFF);</span>
<span class="p_add">+	vmcs_write32(GUEST_GDTR_LIMIT, 0xFFFF);</span>
 
 	/* If not VM_EXIT_CLEAR_BNDCFGS, the L2 value propagates to L1.  */
 	if (vmcs12-&gt;vm_exit_controls &amp; VM_EXIT_CLEAR_BNDCFGS)
<span class="p_header">diff --git a/arch/x86/lib/x86-opcode-map.txt b/arch/x86/lib/x86-opcode-map.txt</span>
<span class="p_header">index 12e377184ee4..c4d55919fac1 100644</span>
<span class="p_header">--- a/arch/x86/lib/x86-opcode-map.txt</span>
<span class="p_header">+++ b/arch/x86/lib/x86-opcode-map.txt</span>
<span class="p_chunk">@@ -896,7 +896,7 @@</span> <span class="p_context"> EndTable</span>
 
 GrpTable: Grp3_1
 0: TEST Eb,Ib
<span class="p_del">-1:</span>
<span class="p_add">+1: TEST Eb,Ib</span>
 2: NOT Eb
 3: NEG Eb
 4: MUL AL,Eb
<span class="p_header">diff --git a/block/blk-core.c b/block/blk-core.c</span>
<span class="p_header">index 048be4aa6024..33ee583cfe45 100644</span>
<span class="p_header">--- a/block/blk-core.c</span>
<span class="p_header">+++ b/block/blk-core.c</span>
<span class="p_chunk">@@ -333,6 +333,7 @@</span> <span class="p_context"> EXPORT_SYMBOL(blk_stop_queue);</span>
 void blk_sync_queue(struct request_queue *q)
 {
 	del_timer_sync(&amp;q-&gt;timeout);
<span class="p_add">+	cancel_work_sync(&amp;q-&gt;timeout_work);</span>
 
 	if (q-&gt;mq_ops) {
 		struct blk_mq_hw_ctx *hctx;
<span class="p_chunk">@@ -844,6 +845,7 @@</span> <span class="p_context"> struct request_queue *blk_alloc_queue_node(gfp_t gfp_mask, int node_id)</span>
 	setup_timer(&amp;q-&gt;backing_dev_info-&gt;laptop_mode_wb_timer,
 		    laptop_mode_timer_fn, (unsigned long) q);
 	setup_timer(&amp;q-&gt;timeout, blk_rq_timed_out_timer, (unsigned long) q);
<span class="p_add">+	INIT_WORK(&amp;q-&gt;timeout_work, NULL);</span>
 	INIT_LIST_HEAD(&amp;q-&gt;queue_head);
 	INIT_LIST_HEAD(&amp;q-&gt;timeout_list);
 	INIT_LIST_HEAD(&amp;q-&gt;icq_list);
<span class="p_header">diff --git a/block/blk-timeout.c b/block/blk-timeout.c</span>
<span class="p_header">index 17ec83bb0900..6427be7ac363 100644</span>
<span class="p_header">--- a/block/blk-timeout.c</span>
<span class="p_header">+++ b/block/blk-timeout.c</span>
<span class="p_chunk">@@ -134,8 +134,6 @@</span> <span class="p_context"> void blk_timeout_work(struct work_struct *work)</span>
 	struct request *rq, *tmp;
 	int next_set = 0;
 
<span class="p_del">-	if (blk_queue_enter(q, true))</span>
<span class="p_del">-		return;</span>
 	spin_lock_irqsave(q-&gt;queue_lock, flags);
 
 	list_for_each_entry_safe(rq, tmp, &amp;q-&gt;timeout_list, timeout_list)
<span class="p_chunk">@@ -145,7 +143,6 @@</span> <span class="p_context"> void blk_timeout_work(struct work_struct *work)</span>
 		mod_timer(&amp;q-&gt;timeout, round_jiffies_up(next));
 
 	spin_unlock_irqrestore(q-&gt;queue_lock, flags);
<span class="p_del">-	blk_queue_exit(q);</span>
 }
 
 /**
<span class="p_header">diff --git a/drivers/acpi/device_pm.c b/drivers/acpi/device_pm.c</span>
<span class="p_header">index fbcc73f7a099..18af71057b44 100644</span>
<span class="p_header">--- a/drivers/acpi/device_pm.c</span>
<span class="p_header">+++ b/drivers/acpi/device_pm.c</span>
<span class="p_chunk">@@ -387,6 +387,7 @@</span> <span class="p_context"> EXPORT_SYMBOL(acpi_bus_power_manageable);</span>
 
 #ifdef CONFIG_PM
 static DEFINE_MUTEX(acpi_pm_notifier_lock);
<span class="p_add">+static DEFINE_MUTEX(acpi_pm_notifier_install_lock);</span>
 
 void acpi_pm_wakeup_event(struct device *dev)
 {
<span class="p_chunk">@@ -443,24 +444,25 @@</span> <span class="p_context"> acpi_status acpi_add_pm_notifier(struct acpi_device *adev, struct device *dev,</span>
 	if (!dev &amp;&amp; !func)
 		return AE_BAD_PARAMETER;
 
<span class="p_del">-	mutex_lock(&amp;acpi_pm_notifier_lock);</span>
<span class="p_add">+	mutex_lock(&amp;acpi_pm_notifier_install_lock);</span>
 
 	if (adev-&gt;wakeup.flags.notifier_present)
 		goto out;
 
<span class="p_del">-	adev-&gt;wakeup.ws = wakeup_source_register(dev_name(&amp;adev-&gt;dev));</span>
<span class="p_del">-	adev-&gt;wakeup.context.dev = dev;</span>
<span class="p_del">-	adev-&gt;wakeup.context.func = func;</span>
<span class="p_del">-</span>
 	status = acpi_install_notify_handler(adev-&gt;handle, ACPI_SYSTEM_NOTIFY,
 					     acpi_pm_notify_handler, NULL);
 	if (ACPI_FAILURE(status))
 		goto out;
 
<span class="p_add">+	mutex_lock(&amp;acpi_pm_notifier_lock);</span>
<span class="p_add">+	adev-&gt;wakeup.ws = wakeup_source_register(dev_name(&amp;adev-&gt;dev));</span>
<span class="p_add">+	adev-&gt;wakeup.context.dev = dev;</span>
<span class="p_add">+	adev-&gt;wakeup.context.func = func;</span>
 	adev-&gt;wakeup.flags.notifier_present = true;
<span class="p_add">+	mutex_unlock(&amp;acpi_pm_notifier_lock);</span>
 
  out:
<span class="p_del">-	mutex_unlock(&amp;acpi_pm_notifier_lock);</span>
<span class="p_add">+	mutex_unlock(&amp;acpi_pm_notifier_install_lock);</span>
 	return status;
 }
 
<span class="p_chunk">@@ -472,7 +474,7 @@</span> <span class="p_context"> acpi_status acpi_remove_pm_notifier(struct acpi_device *adev)</span>
 {
 	acpi_status status = AE_BAD_PARAMETER;
 
<span class="p_del">-	mutex_lock(&amp;acpi_pm_notifier_lock);</span>
<span class="p_add">+	mutex_lock(&amp;acpi_pm_notifier_install_lock);</span>
 
 	if (!adev-&gt;wakeup.flags.notifier_present)
 		goto out;
<span class="p_chunk">@@ -483,14 +485,15 @@</span> <span class="p_context"> acpi_status acpi_remove_pm_notifier(struct acpi_device *adev)</span>
 	if (ACPI_FAILURE(status))
 		goto out;
 
<span class="p_add">+	mutex_lock(&amp;acpi_pm_notifier_lock);</span>
 	adev-&gt;wakeup.context.func = NULL;
 	adev-&gt;wakeup.context.dev = NULL;
 	wakeup_source_unregister(adev-&gt;wakeup.ws);
<span class="p_del">-</span>
 	adev-&gt;wakeup.flags.notifier_present = false;
<span class="p_add">+	mutex_unlock(&amp;acpi_pm_notifier_lock);</span>
 
  out:
<span class="p_del">-	mutex_unlock(&amp;acpi_pm_notifier_lock);</span>
<span class="p_add">+	mutex_unlock(&amp;acpi_pm_notifier_install_lock);</span>
 	return status;
 }
 
<span class="p_header">diff --git a/drivers/acpi/ec.c b/drivers/acpi/ec.c</span>
<span class="p_header">index 236b14324780..82b3ce5e937e 100644</span>
<span class="p_header">--- a/drivers/acpi/ec.c</span>
<span class="p_header">+++ b/drivers/acpi/ec.c</span>
<span class="p_chunk">@@ -486,8 +486,11 @@</span> <span class="p_context"> static inline void __acpi_ec_enable_event(struct acpi_ec *ec)</span>
 {
 	if (!test_and_set_bit(EC_FLAGS_QUERY_ENABLED, &amp;ec-&gt;flags))
 		ec_log_drv(&quot;event unblocked&quot;);
<span class="p_del">-	if (!test_bit(EC_FLAGS_QUERY_PENDING, &amp;ec-&gt;flags))</span>
<span class="p_del">-		advance_transaction(ec);</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Unconditionally invoke this once after enabling the event</span>
<span class="p_add">+	 * handling mechanism to detect the pending events.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	advance_transaction(ec);</span>
 }
 
 static inline void __acpi_ec_disable_event(struct acpi_ec *ec)
<span class="p_chunk">@@ -1456,11 +1459,10 @@</span> <span class="p_context"> static int ec_install_handlers(struct acpi_ec *ec, bool handle_events)</span>
 			if (test_bit(EC_FLAGS_STARTED, &amp;ec-&gt;flags) &amp;&amp;
 			    ec-&gt;reference_count &gt;= 1)
 				acpi_ec_enable_gpe(ec, true);
<span class="p_del">-</span>
<span class="p_del">-			/* EC is fully operational, allow queries */</span>
<span class="p_del">-			acpi_ec_enable_event(ec);</span>
 		}
 	}
<span class="p_add">+	/* EC is fully operational, allow queries */</span>
<span class="p_add">+	acpi_ec_enable_event(ec);</span>
 
 	return 0;
 }
<span class="p_header">diff --git a/drivers/ata/libata-eh.c b/drivers/ata/libata-eh.c</span>
<span class="p_header">index e4effef0c83f..ea20e0eb4d5a 100644</span>
<span class="p_header">--- a/drivers/ata/libata-eh.c</span>
<span class="p_header">+++ b/drivers/ata/libata-eh.c</span>
<span class="p_chunk">@@ -2264,8 +2264,8 @@</span> <span class="p_context"> static void ata_eh_link_autopsy(struct ata_link *link)</span>
 		if (dev-&gt;flags &amp; ATA_DFLAG_DUBIOUS_XFER)
 			eflags |= ATA_EFLAG_DUBIOUS_XFER;
 		ehc-&gt;i.action |= ata_eh_speed_down(dev, eflags, all_err_mask);
<span class="p_add">+		trace_ata_eh_link_autopsy(dev, ehc-&gt;i.action, all_err_mask);</span>
 	}
<span class="p_del">-	trace_ata_eh_link_autopsy(dev, ehc-&gt;i.action, all_err_mask);</span>
 	DPRINTK(&quot;EXIT\n&quot;);
 }
 
<span class="p_header">diff --git a/drivers/base/power/opp/of.c b/drivers/base/power/opp/of.c</span>
<span class="p_header">index 0b718886479b..87509cb69f79 100644</span>
<span class="p_header">--- a/drivers/base/power/opp/of.c</span>
<span class="p_header">+++ b/drivers/base/power/opp/of.c</span>
<span class="p_chunk">@@ -397,6 +397,7 @@</span> <span class="p_context"> static int _of_add_opp_table_v2(struct device *dev, struct device_node *opp_np)</span>
 			dev_err(dev, &quot;%s: Failed to add OPP, %d\n&quot;, __func__,
 				ret);
 			_dev_pm_opp_remove_table(opp_table, dev, false);
<span class="p_add">+			of_node_put(np);</span>
 			goto put_opp_table;
 		}
 	}
<span class="p_header">diff --git a/drivers/block/nbd.c b/drivers/block/nbd.c</span>
<span class="p_header">index 9adfb5445f8d..5f2a4240a204 100644</span>
<span class="p_header">--- a/drivers/block/nbd.c</span>
<span class="p_header">+++ b/drivers/block/nbd.c</span>
<span class="p_chunk">@@ -288,15 +288,6 @@</span> <span class="p_context"> static enum blk_eh_timer_return nbd_xmit_timeout(struct request *req,</span>
 		cmd-&gt;status = BLK_STS_TIMEOUT;
 		return BLK_EH_HANDLED;
 	}
<span class="p_del">-</span>
<span class="p_del">-	/* If we are waiting on our dead timer then we could get timeout</span>
<span class="p_del">-	 * callbacks for our request.  For this we just want to reset the timer</span>
<span class="p_del">-	 * and let the queue side take care of everything.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	if (!completion_done(&amp;cmd-&gt;send_complete)) {</span>
<span class="p_del">-		nbd_config_put(nbd);</span>
<span class="p_del">-		return BLK_EH_RESET_TIMER;</span>
<span class="p_del">-	}</span>
 	config = nbd-&gt;config;
 
 	if (config-&gt;num_connections &gt; 1) {
<span class="p_chunk">@@ -723,9 +714,9 @@</span> <span class="p_context"> static int wait_for_reconnect(struct nbd_device *nbd)</span>
 		return 0;
 	if (test_bit(NBD_DISCONNECTED, &amp;config-&gt;runtime_flags))
 		return 0;
<span class="p_del">-	wait_event_interruptible_timeout(config-&gt;conn_wait,</span>
<span class="p_del">-					 atomic_read(&amp;config-&gt;live_connections),</span>
<span class="p_del">-					 config-&gt;dead_conn_timeout);</span>
<span class="p_add">+	wait_event_timeout(config-&gt;conn_wait,</span>
<span class="p_add">+			   atomic_read(&amp;config-&gt;live_connections),</span>
<span class="p_add">+			   config-&gt;dead_conn_timeout);</span>
 	return atomic_read(&amp;config-&gt;live_connections);
 }
 
<span class="p_chunk">@@ -740,6 +731,7 @@</span> <span class="p_context"> static int nbd_handle_cmd(struct nbd_cmd *cmd, int index)</span>
 	if (!refcount_inc_not_zero(&amp;nbd-&gt;config_refs)) {
 		dev_err_ratelimited(disk_to_dev(nbd-&gt;disk),
 				    &quot;Socks array is empty\n&quot;);
<span class="p_add">+		blk_mq_start_request(req);</span>
 		return -EINVAL;
 	}
 	config = nbd-&gt;config;
<span class="p_chunk">@@ -748,6 +740,7 @@</span> <span class="p_context"> static int nbd_handle_cmd(struct nbd_cmd *cmd, int index)</span>
 		dev_err_ratelimited(disk_to_dev(nbd-&gt;disk),
 				    &quot;Attempted send on invalid socket\n&quot;);
 		nbd_config_put(nbd);
<span class="p_add">+		blk_mq_start_request(req);</span>
 		return -EINVAL;
 	}
 	cmd-&gt;status = BLK_STS_OK;
<span class="p_chunk">@@ -771,6 +764,7 @@</span> <span class="p_context"> static int nbd_handle_cmd(struct nbd_cmd *cmd, int index)</span>
 			 */
 			sock_shutdown(nbd);
 			nbd_config_put(nbd);
<span class="p_add">+			blk_mq_start_request(req);</span>
 			return -EIO;
 		}
 		goto again;
<span class="p_chunk">@@ -781,6 +775,7 @@</span> <span class="p_context"> static int nbd_handle_cmd(struct nbd_cmd *cmd, int index)</span>
 	 * here so that it gets put _after_ the request that is already on the
 	 * dispatch list.
 	 */
<span class="p_add">+	blk_mq_start_request(req);</span>
 	if (unlikely(nsock-&gt;pending &amp;&amp; nsock-&gt;pending != req)) {
 		blk_mq_requeue_request(req, true);
 		ret = 0;
<span class="p_chunk">@@ -793,10 +788,10 @@</span> <span class="p_context"> static int nbd_handle_cmd(struct nbd_cmd *cmd, int index)</span>
 	ret = nbd_send_cmd(nbd, cmd, index);
 	if (ret == -EAGAIN) {
 		dev_err_ratelimited(disk_to_dev(nbd-&gt;disk),
<span class="p_del">-				    &quot;Request send failed trying another connection\n&quot;);</span>
<span class="p_add">+				    &quot;Request send failed, requeueing\n&quot;);</span>
 		nbd_mark_nsock_dead(nbd, nsock, 1);
<span class="p_del">-		mutex_unlock(&amp;nsock-&gt;tx_lock);</span>
<span class="p_del">-		goto again;</span>
<span class="p_add">+		blk_mq_requeue_request(req, true);</span>
<span class="p_add">+		ret = 0;</span>
 	}
 out:
 	mutex_unlock(&amp;nsock-&gt;tx_lock);
<span class="p_chunk">@@ -820,7 +815,6 @@</span> <span class="p_context"> static blk_status_t nbd_queue_rq(struct blk_mq_hw_ctx *hctx,</span>
 	 * done sending everything over the wire.
 	 */
 	init_completion(&amp;cmd-&gt;send_complete);
<span class="p_del">-	blk_mq_start_request(bd-&gt;rq);</span>
 
 	/* We can be called directly from the user space process, which means we
 	 * could possibly have signals pending so our sendmsg will fail.  In
<span class="p_header">diff --git a/drivers/bluetooth/btqcomsmd.c b/drivers/bluetooth/btqcomsmd.c</span>
<span class="p_header">index d00c4fdae924..bd810d01538a 100644</span>
<span class="p_header">--- a/drivers/bluetooth/btqcomsmd.c</span>
<span class="p_header">+++ b/drivers/bluetooth/btqcomsmd.c</span>
<span class="p_chunk">@@ -26,6 +26,7 @@</span> <span class="p_context"></span>
 struct btqcomsmd {
 	struct hci_dev *hdev;
 
<span class="p_add">+	bdaddr_t bdaddr;</span>
 	struct rpmsg_endpoint *acl_channel;
 	struct rpmsg_endpoint *cmd_channel;
 };
<span class="p_chunk">@@ -100,6 +101,38 @@</span> <span class="p_context"> static int btqcomsmd_close(struct hci_dev *hdev)</span>
 	return 0;
 }
 
<span class="p_add">+static int btqcomsmd_setup(struct hci_dev *hdev)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct btqcomsmd *btq = hci_get_drvdata(hdev);</span>
<span class="p_add">+	struct sk_buff *skb;</span>
<span class="p_add">+	int err;</span>
<span class="p_add">+</span>
<span class="p_add">+	skb = __hci_cmd_sync(hdev, HCI_OP_RESET, 0, NULL, HCI_INIT_TIMEOUT);</span>
<span class="p_add">+	if (IS_ERR(skb))</span>
<span class="p_add">+		return PTR_ERR(skb);</span>
<span class="p_add">+	kfree_skb(skb);</span>
<span class="p_add">+</span>
<span class="p_add">+	/* Devices do not have persistent storage for BD address. If no</span>
<span class="p_add">+	 * BD address has been retrieved during probe, mark the device</span>
<span class="p_add">+	 * as having an invalid BD address.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	if (!bacmp(&amp;btq-&gt;bdaddr, BDADDR_ANY)) {</span>
<span class="p_add">+		set_bit(HCI_QUIRK_INVALID_BDADDR, &amp;hdev-&gt;quirks);</span>
<span class="p_add">+		return 0;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	/* When setting a configured BD address fails, mark the device</span>
<span class="p_add">+	 * as having an invalid BD address.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	err = qca_set_bdaddr_rome(hdev, &amp;btq-&gt;bdaddr);</span>
<span class="p_add">+	if (err) {</span>
<span class="p_add">+		set_bit(HCI_QUIRK_INVALID_BDADDR, &amp;hdev-&gt;quirks);</span>
<span class="p_add">+		return 0;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	return 0;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static int btqcomsmd_probe(struct platform_device *pdev)
 {
 	struct btqcomsmd *btq;
<span class="p_chunk">@@ -135,6 +168,7 @@</span> <span class="p_context"> static int btqcomsmd_probe(struct platform_device *pdev)</span>
 	hdev-&gt;open = btqcomsmd_open;
 	hdev-&gt;close = btqcomsmd_close;
 	hdev-&gt;send = btqcomsmd_send;
<span class="p_add">+	hdev-&gt;setup = btqcomsmd_setup;</span>
 	hdev-&gt;set_bdaddr = qca_set_bdaddr_rome;
 
 	ret = hci_register_dev(hdev);
<span class="p_header">diff --git a/drivers/clk/ti/clk-dra7-atl.c b/drivers/clk/ti/clk-dra7-atl.c</span>
<span class="p_header">index 13eb04f72389..148815470431 100644</span>
<span class="p_header">--- a/drivers/clk/ti/clk-dra7-atl.c</span>
<span class="p_header">+++ b/drivers/clk/ti/clk-dra7-atl.c</span>
<span class="p_chunk">@@ -274,8 +274,7 @@</span> <span class="p_context"> static int of_dra7_atl_clk_probe(struct platform_device *pdev)</span>
 
 		/* Get configuration for the ATL instances */
 		snprintf(prop, sizeof(prop), &quot;atl%u&quot;, i);
<span class="p_del">-		of_node_get(node);</span>
<span class="p_del">-		cfg_node = of_find_node_by_name(node, prop);</span>
<span class="p_add">+		cfg_node = of_get_child_by_name(node, prop);</span>
 		if (cfg_node) {
 			ret = of_property_read_u32(cfg_node, &quot;bws&quot;,
 						   &amp;cdesc-&gt;bws);
<span class="p_header">diff --git a/drivers/dax/super.c b/drivers/dax/super.c</span>
<span class="p_header">index 557b93703532..c4cd034a3820 100644</span>
<span class="p_header">--- a/drivers/dax/super.c</span>
<span class="p_header">+++ b/drivers/dax/super.c</span>
<span class="p_chunk">@@ -344,6 +344,9 @@</span> <span class="p_context"> static struct inode *dax_alloc_inode(struct super_block *sb)</span>
 	struct inode *inode;
 
 	dax_dev = kmem_cache_alloc(dax_cache, GFP_KERNEL);
<span class="p_add">+	if (!dax_dev)</span>
<span class="p_add">+		return NULL;</span>
<span class="p_add">+</span>
 	inode = &amp;dax_dev-&gt;inode;
 	inode-&gt;i_rdev = 0;
 	return inode;
<span class="p_header">diff --git a/drivers/infiniband/core/cm.c b/drivers/infiniband/core/cm.c</span>
<span class="p_header">index 4c4b46586af2..2af79e4f3235 100644</span>
<span class="p_header">--- a/drivers/infiniband/core/cm.c</span>
<span class="p_header">+++ b/drivers/infiniband/core/cm.c</span>
<span class="p_chunk">@@ -1575,7 +1575,7 @@</span> <span class="p_context"> static void cm_format_req_event(struct cm_work *work,</span>
 	param-&gt;bth_pkey = cm_get_bth_pkey(work);
 	param-&gt;port = cm_id_priv-&gt;av.port-&gt;port_num;
 	param-&gt;primary_path = &amp;work-&gt;path[0];
<span class="p_del">-	if (req_msg-&gt;alt_local_lid)</span>
<span class="p_add">+	if (cm_req_has_alt_path(req_msg))</span>
 		param-&gt;alternate_path = &amp;work-&gt;path[1];
 	else
 		param-&gt;alternate_path = NULL;
<span class="p_chunk">@@ -1856,7 +1856,8 @@</span> <span class="p_context"> static int cm_req_handler(struct cm_work *work)</span>
 	cm_process_routed_req(req_msg, work-&gt;mad_recv_wc-&gt;wc);
 
 	memset(&amp;work-&gt;path[0], 0, sizeof(work-&gt;path[0]));
<span class="p_del">-	memset(&amp;work-&gt;path[1], 0, sizeof(work-&gt;path[1]));</span>
<span class="p_add">+	if (cm_req_has_alt_path(req_msg))</span>
<span class="p_add">+		memset(&amp;work-&gt;path[1], 0, sizeof(work-&gt;path[1]));</span>
 	grh = rdma_ah_read_grh(&amp;cm_id_priv-&gt;av.ah_attr);
 	ret = ib_get_cached_gid(work-&gt;port-&gt;cm_dev-&gt;ib_device,
 				work-&gt;port-&gt;port_num,
<span class="p_chunk">@@ -3817,14 +3818,16 @@</span> <span class="p_context"> static void cm_recv_handler(struct ib_mad_agent *mad_agent,</span>
 	struct cm_port *port = mad_agent-&gt;context;
 	struct cm_work *work;
 	enum ib_cm_event_type event;
<span class="p_add">+	bool alt_path = false;</span>
 	u16 attr_id;
 	int paths = 0;
 	int going_down = 0;
 
 	switch (mad_recv_wc-&gt;recv_buf.mad-&gt;mad_hdr.attr_id) {
 	case CM_REQ_ATTR_ID:
<span class="p_del">-		paths = 1 + (((struct cm_req_msg *) mad_recv_wc-&gt;recv_buf.mad)-&gt;</span>
<span class="p_del">-						    alt_local_lid != 0);</span>
<span class="p_add">+		alt_path = cm_req_has_alt_path((struct cm_req_msg *)</span>
<span class="p_add">+						mad_recv_wc-&gt;recv_buf.mad);</span>
<span class="p_add">+		paths = 1 + (alt_path != 0);</span>
 		event = IB_CM_REQ_RECEIVED;
 		break;
 	case CM_MRA_ATTR_ID:
<span class="p_header">diff --git a/drivers/infiniband/core/mad.c b/drivers/infiniband/core/mad.c</span>
<span class="p_header">index f8f53bb90837..cb91245e9163 100644</span>
<span class="p_header">--- a/drivers/infiniband/core/mad.c</span>
<span class="p_header">+++ b/drivers/infiniband/core/mad.c</span>
<span class="p_chunk">@@ -1974,14 +1974,15 @@</span> <span class="p_context"> static void ib_mad_complete_recv(struct ib_mad_agent_private *mad_agent_priv,</span>
 	unsigned long flags;
 	int ret;
 
<span class="p_add">+	INIT_LIST_HEAD(&amp;mad_recv_wc-&gt;rmpp_list);</span>
 	ret = ib_mad_enforce_security(mad_agent_priv,
 				      mad_recv_wc-&gt;wc-&gt;pkey_index);
 	if (ret) {
 		ib_free_recv_mad(mad_recv_wc);
 		deref_mad_agent(mad_agent_priv);
<span class="p_add">+		return;</span>
 	}
 
<span class="p_del">-	INIT_LIST_HEAD(&amp;mad_recv_wc-&gt;rmpp_list);</span>
 	list_add(&amp;mad_recv_wc-&gt;recv_buf.list, &amp;mad_recv_wc-&gt;rmpp_list);
 	if (ib_mad_kernel_rmpp_agent(&amp;mad_agent_priv-&gt;agent)) {
 		mad_recv_wc = ib_process_rmpp_recv_wc(mad_agent_priv,
<span class="p_header">diff --git a/drivers/infiniband/core/security.c b/drivers/infiniband/core/security.c</span>
<span class="p_header">index 88bdafb297f5..28607bb42d87 100644</span>
<span class="p_header">--- a/drivers/infiniband/core/security.c</span>
<span class="p_header">+++ b/drivers/infiniband/core/security.c</span>
<span class="p_chunk">@@ -87,16 +87,14 @@</span> <span class="p_context"> static int enforce_qp_pkey_security(u16 pkey,</span>
 	if (ret)
 		return ret;
 
<span class="p_del">-	if (qp_sec-&gt;qp == qp_sec-&gt;qp-&gt;real_qp) {</span>
<span class="p_del">-		list_for_each_entry(shared_qp_sec,</span>
<span class="p_del">-				    &amp;qp_sec-&gt;shared_qp_list,</span>
<span class="p_del">-				    shared_qp_list) {</span>
<span class="p_del">-			ret = security_ib_pkey_access(shared_qp_sec-&gt;security,</span>
<span class="p_del">-						      subnet_prefix,</span>
<span class="p_del">-						      pkey);</span>
<span class="p_del">-			if (ret)</span>
<span class="p_del">-				return ret;</span>
<span class="p_del">-		}</span>
<span class="p_add">+	list_for_each_entry(shared_qp_sec,</span>
<span class="p_add">+			    &amp;qp_sec-&gt;shared_qp_list,</span>
<span class="p_add">+			    shared_qp_list) {</span>
<span class="p_add">+		ret = security_ib_pkey_access(shared_qp_sec-&gt;security,</span>
<span class="p_add">+					      subnet_prefix,</span>
<span class="p_add">+					      pkey);</span>
<span class="p_add">+		if (ret)</span>
<span class="p_add">+			return ret;</span>
 	}
 	return 0;
 }
<span class="p_chunk">@@ -560,15 +558,22 @@</span> <span class="p_context"> int ib_security_modify_qp(struct ib_qp *qp,</span>
 	int ret = 0;
 	struct ib_ports_pkeys *tmp_pps;
 	struct ib_ports_pkeys *new_pps;
<span class="p_del">-	bool special_qp = (qp-&gt;qp_type == IB_QPT_SMI ||</span>
<span class="p_del">-			   qp-&gt;qp_type == IB_QPT_GSI ||</span>
<span class="p_del">-			   qp-&gt;qp_type &gt;= IB_QPT_RESERVED1);</span>
<span class="p_add">+	struct ib_qp *real_qp = qp-&gt;real_qp;</span>
<span class="p_add">+	bool special_qp = (real_qp-&gt;qp_type == IB_QPT_SMI ||</span>
<span class="p_add">+			   real_qp-&gt;qp_type == IB_QPT_GSI ||</span>
<span class="p_add">+			   real_qp-&gt;qp_type &gt;= IB_QPT_RESERVED1);</span>
 	bool pps_change = ((qp_attr_mask &amp; (IB_QP_PKEY_INDEX | IB_QP_PORT)) ||
 			   (qp_attr_mask &amp; IB_QP_ALT_PATH));
 
<span class="p_add">+	/* The port/pkey settings are maintained only for the real QP. Open</span>
<span class="p_add">+	 * handles on the real QP will be in the shared_qp_list. When</span>
<span class="p_add">+	 * enforcing security on the real QP all the shared QPs will be</span>
<span class="p_add">+	 * checked as well.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+</span>
 	if (pps_change &amp;&amp; !special_qp) {
<span class="p_del">-		mutex_lock(&amp;qp-&gt;qp_sec-&gt;mutex);</span>
<span class="p_del">-		new_pps = get_new_pps(qp,</span>
<span class="p_add">+		mutex_lock(&amp;real_qp-&gt;qp_sec-&gt;mutex);</span>
<span class="p_add">+		new_pps = get_new_pps(real_qp,</span>
 				      qp_attr,
 				      qp_attr_mask);
 
<span class="p_chunk">@@ -586,14 +591,14 @@</span> <span class="p_context"> int ib_security_modify_qp(struct ib_qp *qp,</span>
 
 		if (!ret)
 			ret = check_qp_port_pkey_settings(new_pps,
<span class="p_del">-							  qp-&gt;qp_sec);</span>
<span class="p_add">+							  real_qp-&gt;qp_sec);</span>
 	}
 
 	if (!ret)
<span class="p_del">-		ret = qp-&gt;device-&gt;modify_qp(qp-&gt;real_qp,</span>
<span class="p_del">-					    qp_attr,</span>
<span class="p_del">-					    qp_attr_mask,</span>
<span class="p_del">-					    udata);</span>
<span class="p_add">+		ret = real_qp-&gt;device-&gt;modify_qp(real_qp,</span>
<span class="p_add">+						 qp_attr,</span>
<span class="p_add">+						 qp_attr_mask,</span>
<span class="p_add">+						 udata);</span>
 
 	if (pps_change &amp;&amp; !special_qp) {
 		/* Clean up the lists and free the appropriate
<span class="p_chunk">@@ -602,8 +607,8 @@</span> <span class="p_context"> int ib_security_modify_qp(struct ib_qp *qp,</span>
 		if (ret) {
 			tmp_pps = new_pps;
 		} else {
<span class="p_del">-			tmp_pps = qp-&gt;qp_sec-&gt;ports_pkeys;</span>
<span class="p_del">-			qp-&gt;qp_sec-&gt;ports_pkeys = new_pps;</span>
<span class="p_add">+			tmp_pps = real_qp-&gt;qp_sec-&gt;ports_pkeys;</span>
<span class="p_add">+			real_qp-&gt;qp_sec-&gt;ports_pkeys = new_pps;</span>
 		}
 
 		if (tmp_pps) {
<span class="p_chunk">@@ -611,7 +616,7 @@</span> <span class="p_context"> int ib_security_modify_qp(struct ib_qp *qp,</span>
 			port_pkey_list_remove(&amp;tmp_pps-&gt;alt);
 		}
 		kfree(tmp_pps);
<span class="p_del">-		mutex_unlock(&amp;qp-&gt;qp_sec-&gt;mutex);</span>
<span class="p_add">+		mutex_unlock(&amp;real_qp-&gt;qp_sec-&gt;mutex);</span>
 	}
 	return ret;
 }
<span class="p_header">diff --git a/drivers/infiniband/hw/hfi1/chip.c b/drivers/infiniband/hw/hfi1/chip.c</span>
<span class="p_header">index 0be42787759f..312444386f54 100644</span>
<span class="p_header">--- a/drivers/infiniband/hw/hfi1/chip.c</span>
<span class="p_header">+++ b/drivers/infiniband/hw/hfi1/chip.c</span>
<span class="p_chunk">@@ -13074,7 +13074,7 @@</span> <span class="p_context"> static int request_msix_irqs(struct hfi1_devdata *dd)</span>
 	first_sdma = last_general;
 	last_sdma = first_sdma + dd-&gt;num_sdma;
 	first_rx = last_sdma;
<span class="p_del">-	last_rx = first_rx + dd-&gt;n_krcv_queues + HFI1_NUM_VNIC_CTXT;</span>
<span class="p_add">+	last_rx = first_rx + dd-&gt;n_krcv_queues + dd-&gt;num_vnic_contexts;</span>
 
 	/* VNIC MSIx interrupts get mapped when VNIC contexts are created */
 	dd-&gt;first_dyn_msix_idx = first_rx + dd-&gt;n_krcv_queues;
<span class="p_chunk">@@ -13294,8 +13294,9 @@</span> <span class="p_context"> static int set_up_interrupts(struct hfi1_devdata *dd)</span>
 	 *		slow source, SDMACleanupDone)
 	 *	N interrupts - one per used SDMA engine
 	 *	M interrupt - one per kernel receive context
<span class="p_add">+	 *	V interrupt - one for each VNIC context</span>
 	 */
<span class="p_del">-	total = 1 + dd-&gt;num_sdma + dd-&gt;n_krcv_queues + HFI1_NUM_VNIC_CTXT;</span>
<span class="p_add">+	total = 1 + dd-&gt;num_sdma + dd-&gt;n_krcv_queues + dd-&gt;num_vnic_contexts;</span>
 
 	/* ask for MSI-X interrupts */
 	request = request_msix(dd, total);
<span class="p_chunk">@@ -13356,10 +13357,12 @@</span> <span class="p_context"> static int set_up_interrupts(struct hfi1_devdata *dd)</span>
  *                             in array of contexts
  *	freectxts  - number of free user contexts
  *	num_send_contexts - number of PIO send contexts being used
<span class="p_add">+ *	num_vnic_contexts - number of contexts reserved for VNIC</span>
  */
 static int set_up_context_variables(struct hfi1_devdata *dd)
 {
 	unsigned long num_kernel_contexts;
<span class="p_add">+	u16 num_vnic_contexts = HFI1_NUM_VNIC_CTXT;</span>
 	int total_contexts;
 	int ret;
 	unsigned ngroups;
<span class="p_chunk">@@ -13393,6 +13396,14 @@</span> <span class="p_context"> static int set_up_context_variables(struct hfi1_devdata *dd)</span>
 			   num_kernel_contexts);
 		num_kernel_contexts = dd-&gt;chip_send_contexts - num_vls - 1;
 	}
<span class="p_add">+</span>
<span class="p_add">+	/* Accommodate VNIC contexts if possible */</span>
<span class="p_add">+	if ((num_kernel_contexts + num_vnic_contexts) &gt; dd-&gt;chip_rcv_contexts) {</span>
<span class="p_add">+		dd_dev_err(dd, &quot;No receive contexts available for VNIC\n&quot;);</span>
<span class="p_add">+		num_vnic_contexts = 0;</span>
<span class="p_add">+	}</span>
<span class="p_add">+	total_contexts = num_kernel_contexts + num_vnic_contexts;</span>
<span class="p_add">+</span>
 	/*
 	 * User contexts:
 	 *	- default to 1 user context per real (non-HT) CPU core if
<span class="p_chunk">@@ -13402,19 +13413,16 @@</span> <span class="p_context"> static int set_up_context_variables(struct hfi1_devdata *dd)</span>
 		num_user_contexts =
 			cpumask_weight(&amp;node_affinity.real_cpu_mask);
 
<span class="p_del">-	total_contexts = num_kernel_contexts + num_user_contexts;</span>
<span class="p_del">-</span>
 	/*
 	 * Adjust the counts given a global max.
 	 */
<span class="p_del">-	if (total_contexts &gt; dd-&gt;chip_rcv_contexts) {</span>
<span class="p_add">+	if (total_contexts + num_user_contexts &gt; dd-&gt;chip_rcv_contexts) {</span>
 		dd_dev_err(dd,
 			   &quot;Reducing # user receive contexts to: %d, from %d\n&quot;,
<span class="p_del">-			   (int)(dd-&gt;chip_rcv_contexts - num_kernel_contexts),</span>
<span class="p_add">+			   (int)(dd-&gt;chip_rcv_contexts - total_contexts),</span>
 			   (int)num_user_contexts);
<span class="p_del">-		num_user_contexts = dd-&gt;chip_rcv_contexts - num_kernel_contexts;</span>
 		/* recalculate */
<span class="p_del">-		total_contexts = num_kernel_contexts + num_user_contexts;</span>
<span class="p_add">+		num_user_contexts = dd-&gt;chip_rcv_contexts - total_contexts;</span>
 	}
 
 	/* each user context requires an entry in the RMT */
<span class="p_chunk">@@ -13427,25 +13435,24 @@</span> <span class="p_context"> static int set_up_context_variables(struct hfi1_devdata *dd)</span>
 			   user_rmt_reduced);
 		/* recalculate */
 		num_user_contexts = user_rmt_reduced;
<span class="p_del">-		total_contexts = num_kernel_contexts + num_user_contexts;</span>
 	}
 
<span class="p_del">-	/* Accommodate VNIC contexts */</span>
<span class="p_del">-	if ((total_contexts + HFI1_NUM_VNIC_CTXT) &lt;= dd-&gt;chip_rcv_contexts)</span>
<span class="p_del">-		total_contexts += HFI1_NUM_VNIC_CTXT;</span>
<span class="p_add">+	total_contexts += num_user_contexts;</span>
 
 	/* the first N are kernel contexts, the rest are user/vnic contexts */
 	dd-&gt;num_rcv_contexts = total_contexts;
 	dd-&gt;n_krcv_queues = num_kernel_contexts;
 	dd-&gt;first_dyn_alloc_ctxt = num_kernel_contexts;
<span class="p_add">+	dd-&gt;num_vnic_contexts = num_vnic_contexts;</span>
 	dd-&gt;num_user_contexts = num_user_contexts;
 	dd-&gt;freectxts = num_user_contexts;
 	dd_dev_info(dd,
<span class="p_del">-		    &quot;rcv contexts: chip %d, used %d (kernel %d, user %d)\n&quot;,</span>
<span class="p_add">+		    &quot;rcv contexts: chip %d, used %d (kernel %d, vnic %u, user %u)\n&quot;,</span>
 		    (int)dd-&gt;chip_rcv_contexts,
 		    (int)dd-&gt;num_rcv_contexts,
 		    (int)dd-&gt;n_krcv_queues,
<span class="p_del">-		    (int)dd-&gt;num_rcv_contexts - dd-&gt;n_krcv_queues);</span>
<span class="p_add">+		    dd-&gt;num_vnic_contexts,</span>
<span class="p_add">+		    dd-&gt;num_user_contexts);</span>
 
 	/*
 	 * Receive array allocation:
<span class="p_header">diff --git a/drivers/infiniband/hw/hfi1/hfi.h b/drivers/infiniband/hw/hfi1/hfi.h</span>
<span class="p_header">index 3ac9c307a285..6ff44dc606eb 100644</span>
<span class="p_header">--- a/drivers/infiniband/hw/hfi1/hfi.h</span>
<span class="p_header">+++ b/drivers/infiniband/hw/hfi1/hfi.h</span>
<span class="p_chunk">@@ -1047,6 +1047,8 @@</span> <span class="p_context"> struct hfi1_devdata {</span>
 	u64 z_send_schedule;
 
 	u64 __percpu *send_schedule;
<span class="p_add">+	/* number of reserved contexts for VNIC usage */</span>
<span class="p_add">+	u16 num_vnic_contexts;</span>
 	/* number of receive contexts in use by the driver */
 	u32 num_rcv_contexts;
 	/* number of pio send contexts in use by the driver */
<span class="p_header">diff --git a/drivers/infiniband/hw/hfi1/sysfs.c b/drivers/infiniband/hw/hfi1/sysfs.c</span>
<span class="p_header">index 6d2702ef34ac..25e867393463 100644</span>
<span class="p_header">--- a/drivers/infiniband/hw/hfi1/sysfs.c</span>
<span class="p_header">+++ b/drivers/infiniband/hw/hfi1/sysfs.c</span>
<span class="p_chunk">@@ -543,7 +543,7 @@</span> <span class="p_context"> static ssize_t show_nctxts(struct device *device,</span>
 	 * give a more accurate picture of total contexts available.
 	 */
 	return scnprintf(buf, PAGE_SIZE, &quot;%u\n&quot;,
<span class="p_del">-			 min(dd-&gt;num_rcv_contexts - dd-&gt;first_dyn_alloc_ctxt,</span>
<span class="p_add">+			 min(dd-&gt;num_user_contexts,</span>
 			     (u32)dd-&gt;sc_sizes[SC_USER].count));
 }
 
<span class="p_header">diff --git a/drivers/infiniband/hw/hfi1/vnic_main.c b/drivers/infiniband/hw/hfi1/vnic_main.c</span>
<span class="p_header">index f419cbb05928..1a17708be46a 100644</span>
<span class="p_header">--- a/drivers/infiniband/hw/hfi1/vnic_main.c</span>
<span class="p_header">+++ b/drivers/infiniband/hw/hfi1/vnic_main.c</span>
<span class="p_chunk">@@ -840,6 +840,9 @@</span> <span class="p_context"> struct net_device *hfi1_vnic_alloc_rn(struct ib_device *device,</span>
 	struct rdma_netdev *rn;
 	int i, size, rc;
 
<span class="p_add">+	if (!dd-&gt;num_vnic_contexts)</span>
<span class="p_add">+		return ERR_PTR(-ENOMEM);</span>
<span class="p_add">+</span>
 	if (!port_num || (port_num &gt; dd-&gt;num_pports))
 		return ERR_PTR(-EINVAL);
 
<span class="p_chunk">@@ -848,7 +851,7 @@</span> <span class="p_context"> struct net_device *hfi1_vnic_alloc_rn(struct ib_device *device,</span>
 
 	size = sizeof(struct opa_vnic_rdma_netdev) + sizeof(*vinfo);
 	netdev = alloc_netdev_mqs(size, name, name_assign_type, setup,
<span class="p_del">-				  dd-&gt;chip_sdma_engines, HFI1_NUM_VNIC_CTXT);</span>
<span class="p_add">+				  dd-&gt;chip_sdma_engines, dd-&gt;num_vnic_contexts);</span>
 	if (!netdev)
 		return ERR_PTR(-ENOMEM);
 
<span class="p_chunk">@@ -856,7 +859,7 @@</span> <span class="p_context"> struct net_device *hfi1_vnic_alloc_rn(struct ib_device *device,</span>
 	vinfo = opa_vnic_dev_priv(netdev);
 	vinfo-&gt;dd = dd;
 	vinfo-&gt;num_tx_q = dd-&gt;chip_sdma_engines;
<span class="p_del">-	vinfo-&gt;num_rx_q = HFI1_NUM_VNIC_CTXT;</span>
<span class="p_add">+	vinfo-&gt;num_rx_q = dd-&gt;num_vnic_contexts;</span>
 	vinfo-&gt;netdev = netdev;
 	rn-&gt;free_rdma_netdev = hfi1_vnic_free_rn;
 	rn-&gt;set_id = hfi1_vnic_set_vesw_id;
<span class="p_header">diff --git a/drivers/infiniband/ulp/srp/ib_srp.c b/drivers/infiniband/ulp/srp/ib_srp.c</span>
<span class="p_header">index fa5ccdb3bb2a..60d7b493ed2d 100644</span>
<span class="p_header">--- a/drivers/infiniband/ulp/srp/ib_srp.c</span>
<span class="p_header">+++ b/drivers/infiniband/ulp/srp/ib_srp.c</span>
<span class="p_chunk">@@ -665,12 +665,19 @@</span> <span class="p_context"> static void srp_path_rec_completion(int status,</span>
 static int srp_lookup_path(struct srp_rdma_ch *ch)
 {
 	struct srp_target_port *target = ch-&gt;target;
<span class="p_del">-	int ret;</span>
<span class="p_add">+	int ret = -ENODEV;</span>
 
 	ch-&gt;path.numb_path = 1;
 
 	init_completion(&amp;ch-&gt;done);
 
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Avoid that the SCSI host can be removed by srp_remove_target()</span>
<span class="p_add">+	 * before srp_path_rec_completion() is called.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	if (!scsi_host_get(target-&gt;scsi_host))</span>
<span class="p_add">+		goto out;</span>
<span class="p_add">+</span>
 	ch-&gt;path_query_id = ib_sa_path_rec_get(&amp;srp_sa_client,
 					       target-&gt;srp_host-&gt;srp_dev-&gt;dev,
 					       target-&gt;srp_host-&gt;port,
<span class="p_chunk">@@ -684,18 +691,24 @@</span> <span class="p_context"> static int srp_lookup_path(struct srp_rdma_ch *ch)</span>
 					       GFP_KERNEL,
 					       srp_path_rec_completion,
 					       ch, &amp;ch-&gt;path_query);
<span class="p_del">-	if (ch-&gt;path_query_id &lt; 0)</span>
<span class="p_del">-		return ch-&gt;path_query_id;</span>
<span class="p_add">+	ret = ch-&gt;path_query_id;</span>
<span class="p_add">+	if (ret &lt; 0)</span>
<span class="p_add">+		goto put;</span>
 
 	ret = wait_for_completion_interruptible(&amp;ch-&gt;done);
 	if (ret &lt; 0)
<span class="p_del">-		return ret;</span>
<span class="p_add">+		goto put;</span>
 
<span class="p_del">-	if (ch-&gt;status &lt; 0)</span>
<span class="p_add">+	ret = ch-&gt;status;</span>
<span class="p_add">+	if (ret &lt; 0)</span>
 		shost_printk(KERN_WARNING, target-&gt;scsi_host,
 			     PFX &quot;Path record query failed\n&quot;);
 
<span class="p_del">-	return ch-&gt;status;</span>
<span class="p_add">+put:</span>
<span class="p_add">+	scsi_host_put(target-&gt;scsi_host);</span>
<span class="p_add">+</span>
<span class="p_add">+out:</span>
<span class="p_add">+	return ret;</span>
 }
 
 static int srp_send_req(struct srp_rdma_ch *ch, bool multich)
<span class="p_header">diff --git a/drivers/infiniband/ulp/srpt/ib_srpt.c b/drivers/infiniband/ulp/srpt/ib_srpt.c</span>
<span class="p_header">index 9e8e9220f816..95178b4e3565 100644</span>
<span class="p_header">--- a/drivers/infiniband/ulp/srpt/ib_srpt.c</span>
<span class="p_header">+++ b/drivers/infiniband/ulp/srpt/ib_srpt.c</span>
<span class="p_chunk">@@ -2777,7 +2777,7 @@</span> <span class="p_context"> static int srpt_parse_i_port_id(u8 i_port_id[16], const char *name)</span>
 {
 	const char *p;
 	unsigned len, count, leading_zero_bytes;
<span class="p_del">-	int ret, rc;</span>
<span class="p_add">+	int ret;</span>
 
 	p = name;
 	if (strncasecmp(p, &quot;0x&quot;, 2) == 0)
<span class="p_chunk">@@ -2789,10 +2789,9 @@</span> <span class="p_context"> static int srpt_parse_i_port_id(u8 i_port_id[16], const char *name)</span>
 	count = min(len / 2, 16U);
 	leading_zero_bytes = 16 - count;
 	memset(i_port_id, 0, leading_zero_bytes);
<span class="p_del">-	rc = hex2bin(i_port_id + leading_zero_bytes, p, count);</span>
<span class="p_del">-	if (rc &lt; 0)</span>
<span class="p_del">-		pr_debug(&quot;hex2bin failed for srpt_parse_i_port_id: %d\n&quot;, rc);</span>
<span class="p_del">-	ret = 0;</span>
<span class="p_add">+	ret = hex2bin(i_port_id + leading_zero_bytes, p, count);</span>
<span class="p_add">+	if (ret &lt; 0)</span>
<span class="p_add">+		pr_debug(&quot;hex2bin failed for srpt_parse_i_port_id: %d\n&quot;, ret);</span>
 out:
 	return ret;
 }
<span class="p_header">diff --git a/drivers/irqchip/irq-gic-v3.c b/drivers/irqchip/irq-gic-v3.c</span>
<span class="p_header">index b5df99c6f680..3b35271114ee 100644</span>
<span class="p_header">--- a/drivers/irqchip/irq-gic-v3.c</span>
<span class="p_header">+++ b/drivers/irqchip/irq-gic-v3.c</span>
<span class="p_chunk">@@ -1071,18 +1071,18 @@</span> <span class="p_context"> static void __init gic_populate_ppi_partitions(struct device_node *gic_node)</span>
 	int nr_parts;
 	struct partition_affinity *parts;
 
<span class="p_del">-	parts_node = of_find_node_by_name(gic_node, &quot;ppi-partitions&quot;);</span>
<span class="p_add">+	parts_node = of_get_child_by_name(gic_node, &quot;ppi-partitions&quot;);</span>
 	if (!parts_node)
 		return;
 
 	nr_parts = of_get_child_count(parts_node);
 
 	if (!nr_parts)
<span class="p_del">-		return;</span>
<span class="p_add">+		goto out_put_node;</span>
 
 	parts = kzalloc(sizeof(*parts) * nr_parts, GFP_KERNEL);
 	if (WARN_ON(!parts))
<span class="p_del">-		return;</span>
<span class="p_add">+		goto out_put_node;</span>
 
 	for_each_child_of_node(parts_node, child_part) {
 		struct partition_affinity *part;
<span class="p_chunk">@@ -1149,6 +1149,9 @@</span> <span class="p_context"> static void __init gic_populate_ppi_partitions(struct device_node *gic_node)</span>
 
 		gic_data.ppi_descs[i] = desc;
 	}
<span class="p_add">+</span>
<span class="p_add">+out_put_node:</span>
<span class="p_add">+	of_node_put(parts_node);</span>
 }
 
 static void __init gic_of_setup_kvm_info(struct device_node *node)
<span class="p_header">diff --git a/drivers/mailbox/bcm-flexrm-mailbox.c b/drivers/mailbox/bcm-flexrm-mailbox.c</span>
<span class="p_header">index ae6146311934..f052a3eb2098 100644</span>
<span class="p_header">--- a/drivers/mailbox/bcm-flexrm-mailbox.c</span>
<span class="p_header">+++ b/drivers/mailbox/bcm-flexrm-mailbox.c</span>
<span class="p_chunk">@@ -1365,8 +1365,8 @@</span> <span class="p_context"> static void flexrm_shutdown(struct mbox_chan *chan)</span>
 	/* Disable/inactivate ring */
 	writel_relaxed(0x0, ring-&gt;regs + RING_CONTROL);
 
<span class="p_del">-	/* Flush ring with timeout of 1s */</span>
<span class="p_del">-	timeout = 1000;</span>
<span class="p_add">+	/* Set ring flush state */</span>
<span class="p_add">+	timeout = 1000; /* timeout of 1s */</span>
 	writel_relaxed(BIT(CONTROL_FLUSH_SHIFT),
 			ring-&gt;regs + RING_CONTROL);
 	do {
<span class="p_chunk">@@ -1374,7 +1374,23 @@</span> <span class="p_context"> static void flexrm_shutdown(struct mbox_chan *chan)</span>
 		    FLUSH_DONE_MASK)
 			break;
 		mdelay(1);
<span class="p_del">-	} while (timeout--);</span>
<span class="p_add">+	} while (--timeout);</span>
<span class="p_add">+	if (!timeout)</span>
<span class="p_add">+		dev_err(ring-&gt;mbox-&gt;dev,</span>
<span class="p_add">+			&quot;setting ring%d flush state timedout\n&quot;, ring-&gt;num);</span>
<span class="p_add">+</span>
<span class="p_add">+	/* Clear ring flush state */</span>
<span class="p_add">+	timeout = 1000; /* timeout of 1s */</span>
<span class="p_add">+	writel_relaxed(0x0, ring + RING_CONTROL);</span>
<span class="p_add">+	do {</span>
<span class="p_add">+		if (!(readl_relaxed(ring + RING_FLUSH_DONE) &amp;</span>
<span class="p_add">+		      FLUSH_DONE_MASK))</span>
<span class="p_add">+			break;</span>
<span class="p_add">+		mdelay(1);</span>
<span class="p_add">+	} while (--timeout);</span>
<span class="p_add">+	if (!timeout)</span>
<span class="p_add">+		dev_err(ring-&gt;mbox-&gt;dev,</span>
<span class="p_add">+			&quot;clearing ring%d flush state timedout\n&quot;, ring-&gt;num);</span>
 
 	/* Abort all in-flight requests */
 	for (reqid = 0; reqid &lt; RING_MAX_REQ_COUNT; reqid++) {
<span class="p_header">diff --git a/drivers/md/bcache/alloc.c b/drivers/md/bcache/alloc.c</span>
<span class="p_header">index 08035634795c..c9934139d609 100644</span>
<span class="p_header">--- a/drivers/md/bcache/alloc.c</span>
<span class="p_header">+++ b/drivers/md/bcache/alloc.c</span>
<span class="p_chunk">@@ -407,7 +407,8 @@</span> <span class="p_context"> long bch_bucket_alloc(struct cache *ca, unsigned reserve, bool wait)</span>
 
 	finish_wait(&amp;ca-&gt;set-&gt;bucket_wait, &amp;w);
 out:
<span class="p_del">-	wake_up_process(ca-&gt;alloc_thread);</span>
<span class="p_add">+	if (ca-&gt;alloc_thread)</span>
<span class="p_add">+		wake_up_process(ca-&gt;alloc_thread);</span>
 
 	trace_bcache_alloc(ca, reserve);
 
<span class="p_header">diff --git a/drivers/md/bitmap.c b/drivers/md/bitmap.c</span>
<span class="p_header">index d2121637b4ab..cae57b5be817 100644</span>
<span class="p_header">--- a/drivers/md/bitmap.c</span>
<span class="p_header">+++ b/drivers/md/bitmap.c</span>
<span class="p_chunk">@@ -625,7 +625,7 @@</span> <span class="p_context"> static int bitmap_read_sb(struct bitmap *bitmap)</span>
 		err = read_sb_page(bitmap-&gt;mddev,
 				   offset,
 				   sb_page,
<span class="p_del">-				   0, PAGE_SIZE);</span>
<span class="p_add">+				   0, sizeof(bitmap_super_t));</span>
 	}
 	if (err)
 		return err;
<span class="p_chunk">@@ -2123,7 +2123,7 @@</span> <span class="p_context"> int bitmap_resize(struct bitmap *bitmap, sector_t blocks,</span>
 	if (store.sb_page &amp;&amp; bitmap-&gt;storage.sb_page)
 		memcpy(page_address(store.sb_page),
 		       page_address(bitmap-&gt;storage.sb_page),
<span class="p_del">-		       PAGE_SIZE);</span>
<span class="p_add">+		       sizeof(bitmap_super_t));</span>
 	bitmap_file_unmap(&amp;bitmap-&gt;storage);
 	bitmap-&gt;storage = store;
 
<span class="p_header">diff --git a/drivers/md/dm-bufio.c b/drivers/md/dm-bufio.c</span>
<span class="p_header">index d216a8f7bc22..8e3adcb46851 100644</span>
<span class="p_header">--- a/drivers/md/dm-bufio.c</span>
<span class="p_header">+++ b/drivers/md/dm-bufio.c</span>
<span class="p_chunk">@@ -974,7 +974,8 @@</span> <span class="p_context"> static void __get_memory_limit(struct dm_bufio_client *c,</span>
 		buffers = c-&gt;minimum_buffers;
 
 	*limit_buffers = buffers;
<span class="p_del">-	*threshold_buffers = buffers * DM_BUFIO_WRITEBACK_PERCENT / 100;</span>
<span class="p_add">+	*threshold_buffers = mult_frac(buffers,</span>
<span class="p_add">+				       DM_BUFIO_WRITEBACK_PERCENT, 100);</span>
 }
 
 /*
<span class="p_chunk">@@ -1910,19 +1911,15 @@</span> <span class="p_context"> static int __init dm_bufio_init(void)</span>
 	memset(&amp;dm_bufio_caches, 0, sizeof dm_bufio_caches);
 	memset(&amp;dm_bufio_cache_names, 0, sizeof dm_bufio_cache_names);
 
<span class="p_del">-	mem = (__u64)((totalram_pages - totalhigh_pages) *</span>
<span class="p_del">-		      DM_BUFIO_MEMORY_PERCENT / 100) &lt;&lt; PAGE_SHIFT;</span>
<span class="p_add">+	mem = (__u64)mult_frac(totalram_pages - totalhigh_pages,</span>
<span class="p_add">+			       DM_BUFIO_MEMORY_PERCENT, 100) &lt;&lt; PAGE_SHIFT;</span>
 
 	if (mem &gt; ULONG_MAX)
 		mem = ULONG_MAX;
 
 #ifdef CONFIG_MMU
<span class="p_del">-	/*</span>
<span class="p_del">-	 * Get the size of vmalloc space the same way as VMALLOC_TOTAL</span>
<span class="p_del">-	 * in fs/proc/internal.h</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	if (mem &gt; (VMALLOC_END - VMALLOC_START) * DM_BUFIO_VMALLOC_PERCENT / 100)</span>
<span class="p_del">-		mem = (VMALLOC_END - VMALLOC_START) * DM_BUFIO_VMALLOC_PERCENT / 100;</span>
<span class="p_add">+	if (mem &gt; mult_frac(VMALLOC_TOTAL, DM_BUFIO_VMALLOC_PERCENT, 100))</span>
<span class="p_add">+		mem = mult_frac(VMALLOC_TOTAL, DM_BUFIO_VMALLOC_PERCENT, 100);</span>
 #endif
 
 	dm_bufio_default_cache_size = mem;
<span class="p_header">diff --git a/drivers/md/dm-cache-target.c b/drivers/md/dm-cache-target.c</span>
<span class="p_header">index 8785134c9f1f..0b7edfd0b454 100644</span>
<span class="p_header">--- a/drivers/md/dm-cache-target.c</span>
<span class="p_header">+++ b/drivers/md/dm-cache-target.c</span>
<span class="p_chunk">@@ -1201,6 +1201,18 @@</span> <span class="p_context"> static void background_work_end(struct cache *cache)</span>
 
 /*----------------------------------------------------------------*/
 
<span class="p_add">+static bool bio_writes_complete_block(struct cache *cache, struct bio *bio)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return (bio_data_dir(bio) == WRITE) &amp;&amp;</span>
<span class="p_add">+		(bio-&gt;bi_iter.bi_size == (cache-&gt;sectors_per_block &lt;&lt; SECTOR_SHIFT));</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static bool optimisable_bio(struct cache *cache, struct bio *bio, dm_oblock_t block)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return writeback_mode(&amp;cache-&gt;features) &amp;&amp;</span>
<span class="p_add">+		(is_discarded_oblock(cache, block) || bio_writes_complete_block(cache, bio));</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static void quiesce(struct dm_cache_migration *mg,
 		    void (*continuation)(struct work_struct *))
 {
<span class="p_chunk">@@ -1474,12 +1486,50 @@</span> <span class="p_context"> static void mg_upgrade_lock(struct work_struct *ws)</span>
 	}
 }
 
<span class="p_add">+static void mg_full_copy(struct work_struct *ws)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct dm_cache_migration *mg = ws_to_mg(ws);</span>
<span class="p_add">+	struct cache *cache = mg-&gt;cache;</span>
<span class="p_add">+	struct policy_work *op = mg-&gt;op;</span>
<span class="p_add">+	bool is_policy_promote = (op-&gt;op == POLICY_PROMOTE);</span>
<span class="p_add">+</span>
<span class="p_add">+	if ((!is_policy_promote &amp;&amp; !is_dirty(cache, op-&gt;cblock)) ||</span>
<span class="p_add">+	    is_discarded_oblock(cache, op-&gt;oblock)) {</span>
<span class="p_add">+		mg_upgrade_lock(ws);</span>
<span class="p_add">+		return;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	init_continuation(&amp;mg-&gt;k, mg_upgrade_lock);</span>
<span class="p_add">+</span>
<span class="p_add">+	if (copy(mg, is_policy_promote)) {</span>
<span class="p_add">+		DMERR_LIMIT(&quot;%s: migration copy failed&quot;, cache_device_name(cache));</span>
<span class="p_add">+		mg-&gt;k.input = BLK_STS_IOERR;</span>
<span class="p_add">+		mg_complete(mg, false);</span>
<span class="p_add">+	}</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static void mg_copy(struct work_struct *ws)
 {
<span class="p_del">-	int r;</span>
 	struct dm_cache_migration *mg = ws_to_mg(ws);
 
 	if (mg-&gt;overwrite_bio) {
<span class="p_add">+		/*</span>
<span class="p_add">+		 * No exclusive lock was held when we last checked if the bio</span>
<span class="p_add">+		 * was optimisable.  So we have to check again in case things</span>
<span class="p_add">+		 * have changed (eg, the block may no longer be discarded).</span>
<span class="p_add">+		 */</span>
<span class="p_add">+		if (!optimisable_bio(mg-&gt;cache, mg-&gt;overwrite_bio, mg-&gt;op-&gt;oblock)) {</span>
<span class="p_add">+			/*</span>
<span class="p_add">+			 * Fallback to a real full copy after doing some tidying up.</span>
<span class="p_add">+			 */</span>
<span class="p_add">+			bool rb = bio_detain_shared(mg-&gt;cache, mg-&gt;op-&gt;oblock, mg-&gt;overwrite_bio);</span>
<span class="p_add">+			BUG_ON(rb); /* An exclussive lock must _not_ be held for this block */</span>
<span class="p_add">+			mg-&gt;overwrite_bio = NULL;</span>
<span class="p_add">+			inc_io_migrations(mg-&gt;cache);</span>
<span class="p_add">+			mg_full_copy(ws);</span>
<span class="p_add">+			return;</span>
<span class="p_add">+		}</span>
<span class="p_add">+</span>
 		/*
 		 * It&#39;s safe to do this here, even though it&#39;s new data
 		 * because all IO has been locked out of the block.
<span class="p_chunk">@@ -1489,26 +1539,8 @@</span> <span class="p_context"> static void mg_copy(struct work_struct *ws)</span>
 		 */
 		overwrite(mg, mg_update_metadata_after_copy);
 
<span class="p_del">-	} else {</span>
<span class="p_del">-		struct cache *cache = mg-&gt;cache;</span>
<span class="p_del">-		struct policy_work *op = mg-&gt;op;</span>
<span class="p_del">-		bool is_policy_promote = (op-&gt;op == POLICY_PROMOTE);</span>
<span class="p_del">-</span>
<span class="p_del">-		if ((!is_policy_promote &amp;&amp; !is_dirty(cache, op-&gt;cblock)) ||</span>
<span class="p_del">-		    is_discarded_oblock(cache, op-&gt;oblock)) {</span>
<span class="p_del">-			mg_upgrade_lock(ws);</span>
<span class="p_del">-			return;</span>
<span class="p_del">-		}</span>
<span class="p_del">-</span>
<span class="p_del">-		init_continuation(&amp;mg-&gt;k, mg_upgrade_lock);</span>
<span class="p_del">-</span>
<span class="p_del">-		r = copy(mg, is_policy_promote);</span>
<span class="p_del">-		if (r) {</span>
<span class="p_del">-			DMERR_LIMIT(&quot;%s: migration copy failed&quot;, cache_device_name(cache));</span>
<span class="p_del">-			mg-&gt;k.input = BLK_STS_IOERR;</span>
<span class="p_del">-			mg_complete(mg, false);</span>
<span class="p_del">-		}</span>
<span class="p_del">-	}</span>
<span class="p_add">+	} else</span>
<span class="p_add">+		mg_full_copy(ws);</span>
 }
 
 static int mg_lock_writes(struct dm_cache_migration *mg)
<span class="p_chunk">@@ -1748,18 +1780,6 @@</span> <span class="p_context"> static void inc_miss_counter(struct cache *cache, struct bio *bio)</span>
 
 /*----------------------------------------------------------------*/
 
<span class="p_del">-static bool bio_writes_complete_block(struct cache *cache, struct bio *bio)</span>
<span class="p_del">-{</span>
<span class="p_del">-	return (bio_data_dir(bio) == WRITE) &amp;&amp;</span>
<span class="p_del">-		(bio-&gt;bi_iter.bi_size == (cache-&gt;sectors_per_block &lt;&lt; SECTOR_SHIFT));</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static bool optimisable_bio(struct cache *cache, struct bio *bio, dm_oblock_t block)</span>
<span class="p_del">-{</span>
<span class="p_del">-	return writeback_mode(&amp;cache-&gt;features) &amp;&amp;</span>
<span class="p_del">-		(is_discarded_oblock(cache, block) || bio_writes_complete_block(cache, bio));</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
 static int map_bio(struct cache *cache, struct bio *bio, dm_oblock_t block,
 		   bool *commit_needed)
 {
<span class="p_header">diff --git a/drivers/md/dm-core.h b/drivers/md/dm-core.h</span>
<span class="p_header">index 203144762f36..6a14f945783c 100644</span>
<span class="p_header">--- a/drivers/md/dm-core.h</span>
<span class="p_header">+++ b/drivers/md/dm-core.h</span>
<span class="p_chunk">@@ -29,7 +29,6 @@</span> <span class="p_context"> struct dm_kobject_holder {</span>
  * DM targets must _not_ deference a mapped_device to directly access its members!
  */
 struct mapped_device {
<span class="p_del">-	struct srcu_struct io_barrier;</span>
 	struct mutex suspend_lock;
 
 	/*
<span class="p_chunk">@@ -127,6 +126,8 @@</span> <span class="p_context"> struct mapped_device {</span>
 	struct blk_mq_tag_set *tag_set;
 	bool use_blk_mq:1;
 	bool init_tio_pdu:1;
<span class="p_add">+</span>
<span class="p_add">+	struct srcu_struct io_barrier;</span>
 };
 
 void dm_init_md_queue(struct mapped_device *md);
<span class="p_header">diff --git a/drivers/md/dm-crypt.c b/drivers/md/dm-crypt.c</span>
<span class="p_header">index 96ab46512e1f..9fc12f556534 100644</span>
<span class="p_header">--- a/drivers/md/dm-crypt.c</span>
<span class="p_header">+++ b/drivers/md/dm-crypt.c</span>
<span class="p_chunk">@@ -1075,7 +1075,7 @@</span> <span class="p_context"> static int crypt_convert_block_aead(struct crypt_config *cc,</span>
 	BUG_ON(cc-&gt;integrity_iv_size &amp;&amp; cc-&gt;integrity_iv_size != cc-&gt;iv_size);
 
 	/* Reject unexpected unaligned bio. */
<span class="p_del">-	if (unlikely(bv_in.bv_offset &amp; (cc-&gt;sector_size - 1)))</span>
<span class="p_add">+	if (unlikely(bv_in.bv_len &amp; (cc-&gt;sector_size - 1)))</span>
 		return -EIO;
 
 	dmreq = dmreq_of_req(cc, req);
<span class="p_chunk">@@ -1168,7 +1168,7 @@</span> <span class="p_context"> static int crypt_convert_block_skcipher(struct crypt_config *cc,</span>
 	int r = 0;
 
 	/* Reject unexpected unaligned bio. */
<span class="p_del">-	if (unlikely(bv_in.bv_offset &amp; (cc-&gt;sector_size - 1)))</span>
<span class="p_add">+	if (unlikely(bv_in.bv_len &amp; (cc-&gt;sector_size - 1)))</span>
 		return -EIO;
 
 	dmreq = dmreq_of_req(cc, req);
<span class="p_header">diff --git a/drivers/md/dm-integrity.c b/drivers/md/dm-integrity.c</span>
<span class="p_header">index 096fe9b66c50..5e6737a44468 100644</span>
<span class="p_header">--- a/drivers/md/dm-integrity.c</span>
<span class="p_header">+++ b/drivers/md/dm-integrity.c</span>
<span class="p_chunk">@@ -1376,7 +1376,7 @@</span> <span class="p_context"> static int dm_integrity_map(struct dm_target *ti, struct bio *bio)</span>
 		struct bvec_iter iter;
 		struct bio_vec bv;
 		bio_for_each_segment(bv, bio, iter) {
<span class="p_del">-			if (unlikely((bv.bv_offset | bv.bv_len) &amp; ((ic-&gt;sectors_per_block &lt;&lt; SECTOR_SHIFT) - 1))) {</span>
<span class="p_add">+			if (unlikely(bv.bv_len &amp; ((ic-&gt;sectors_per_block &lt;&lt; SECTOR_SHIFT) - 1))) {</span>
 				DMERR(&quot;Bio vector (%u,%u) is not aligned on %u-sector boundary&quot;,
 					bv.bv_offset, bv.bv_len, ic-&gt;sectors_per_block);
 				return DM_MAPIO_KILL;
<span class="p_header">diff --git a/drivers/md/dm-mpath.c b/drivers/md/dm-mpath.c</span>
<span class="p_header">index 11f273d2f018..e8094d8fbe0d 100644</span>
<span class="p_header">--- a/drivers/md/dm-mpath.c</span>
<span class="p_header">+++ b/drivers/md/dm-mpath.c</span>
<span class="p_chunk">@@ -499,8 +499,6 @@</span> <span class="p_context"> static int multipath_clone_and_map(struct dm_target *ti, struct request *rq,</span>
 	if (IS_ERR(clone)) {
 		/* EBUSY, ENODEV or EWOULDBLOCK: requeue */
 		bool queue_dying = blk_queue_dying(q);
<span class="p_del">-		DMERR_LIMIT(&quot;blk_get_request() returned %ld%s - requeuing&quot;,</span>
<span class="p_del">-			    PTR_ERR(clone), queue_dying ? &quot; (path offline)&quot; : &quot;&quot;);</span>
 		if (queue_dying) {
 			atomic_inc(&amp;m-&gt;pg_init_in_progress);
 			activate_or_offline_path(pgpath);
<span class="p_header">diff --git a/drivers/md/dm-table.c b/drivers/md/dm-table.c</span>
<span class="p_header">index ef7b8f201f73..4287fc9f3527 100644</span>
<span class="p_header">--- a/drivers/md/dm-table.c</span>
<span class="p_header">+++ b/drivers/md/dm-table.c</span>
<span class="p_chunk">@@ -1758,13 +1758,12 @@</span> <span class="p_context"> static bool dm_table_supports_write_zeroes(struct dm_table *t)</span>
 	return true;
 }
 
<span class="p_del">-</span>
<span class="p_del">-static int device_discard_capable(struct dm_target *ti, struct dm_dev *dev,</span>
<span class="p_del">-				  sector_t start, sector_t len, void *data)</span>
<span class="p_add">+static int device_not_discard_capable(struct dm_target *ti, struct dm_dev *dev,</span>
<span class="p_add">+				      sector_t start, sector_t len, void *data)</span>
 {
 	struct request_queue *q = bdev_get_queue(dev-&gt;bdev);
 
<span class="p_del">-	return q &amp;&amp; blk_queue_discard(q);</span>
<span class="p_add">+	return q &amp;&amp; !blk_queue_discard(q);</span>
 }
 
 static bool dm_table_supports_discards(struct dm_table *t)
<span class="p_chunk">@@ -1772,28 +1771,24 @@</span> <span class="p_context"> static bool dm_table_supports_discards(struct dm_table *t)</span>
 	struct dm_target *ti;
 	unsigned i;
 
<span class="p_del">-	/*</span>
<span class="p_del">-	 * Unless any target used by the table set discards_supported,</span>
<span class="p_del">-	 * require at least one underlying device to support discards.</span>
<span class="p_del">-	 * t-&gt;devices includes internal dm devices such as mirror logs</span>
<span class="p_del">-	 * so we need to use iterate_devices here, which targets</span>
<span class="p_del">-	 * supporting discard selectively must provide.</span>
<span class="p_del">-	 */</span>
 	for (i = 0; i &lt; dm_table_get_num_targets(t); i++) {
 		ti = dm_table_get_target(t, i);
 
 		if (!ti-&gt;num_discard_bios)
<span class="p_del">-			continue;</span>
<span class="p_del">-</span>
<span class="p_del">-		if (ti-&gt;discards_supported)</span>
<span class="p_del">-			return true;</span>
<span class="p_add">+			return false;</span>
 
<span class="p_del">-		if (ti-&gt;type-&gt;iterate_devices &amp;&amp;</span>
<span class="p_del">-		    ti-&gt;type-&gt;iterate_devices(ti, device_discard_capable, NULL))</span>
<span class="p_del">-			return true;</span>
<span class="p_add">+		/*</span>
<span class="p_add">+		 * Either the target provides discard support (as implied by setting</span>
<span class="p_add">+		 * &#39;discards_supported&#39;) or it relies on _all_ data devices having</span>
<span class="p_add">+		 * discard support.</span>
<span class="p_add">+		 */</span>
<span class="p_add">+		if (!ti-&gt;discards_supported &amp;&amp;</span>
<span class="p_add">+		    (!ti-&gt;type-&gt;iterate_devices ||</span>
<span class="p_add">+		     ti-&gt;type-&gt;iterate_devices(ti, device_not_discard_capable, NULL)))</span>
<span class="p_add">+			return false;</span>
 	}
 
<span class="p_del">-	return false;</span>
<span class="p_add">+	return true;</span>
 }
 
 void dm_table_set_restrictions(struct dm_table *t, struct request_queue *q,
<span class="p_header">diff --git a/drivers/md/dm-zoned-target.c b/drivers/md/dm-zoned-target.c</span>
<span class="p_header">index b87c1741da4b..6d7bda6f8190 100644</span>
<span class="p_header">--- a/drivers/md/dm-zoned-target.c</span>
<span class="p_header">+++ b/drivers/md/dm-zoned-target.c</span>
<span class="p_chunk">@@ -660,6 +660,7 @@</span> <span class="p_context"> static int dmz_get_zoned_device(struct dm_target *ti, char *path)</span>
 	struct dmz_target *dmz = ti-&gt;private;
 	struct request_queue *q;
 	struct dmz_dev *dev;
<span class="p_add">+	sector_t aligned_capacity;</span>
 	int ret;
 
 	/* Get the target device */
<span class="p_chunk">@@ -685,15 +686,17 @@</span> <span class="p_context"> static int dmz_get_zoned_device(struct dm_target *ti, char *path)</span>
 		goto err;
 	}
 
<span class="p_add">+	q = bdev_get_queue(dev-&gt;bdev);</span>
 	dev-&gt;capacity = i_size_read(dev-&gt;bdev-&gt;bd_inode) &gt;&gt; SECTOR_SHIFT;
<span class="p_del">-	if (ti-&gt;begin || (ti-&gt;len != dev-&gt;capacity)) {</span>
<span class="p_add">+	aligned_capacity = dev-&gt;capacity &amp; ~(blk_queue_zone_sectors(q) - 1);</span>
<span class="p_add">+	if (ti-&gt;begin ||</span>
<span class="p_add">+	    ((ti-&gt;len != dev-&gt;capacity) &amp;&amp; (ti-&gt;len != aligned_capacity))) {</span>
 		ti-&gt;error = &quot;Partial mapping not supported&quot;;
 		ret = -EINVAL;
 		goto err;
 	}
 
<span class="p_del">-	q = bdev_get_queue(dev-&gt;bdev);</span>
<span class="p_del">-	dev-&gt;zone_nr_sectors = q-&gt;limits.chunk_sectors;</span>
<span class="p_add">+	dev-&gt;zone_nr_sectors = blk_queue_zone_sectors(q);</span>
 	dev-&gt;zone_nr_sectors_shift = ilog2(dev-&gt;zone_nr_sectors);
 
 	dev-&gt;zone_nr_blocks = dmz_sect2blk(dev-&gt;zone_nr_sectors);
<span class="p_chunk">@@ -929,8 +932,10 @@</span> <span class="p_context"> static int dmz_iterate_devices(struct dm_target *ti,</span>
 			       iterate_devices_callout_fn fn, void *data)
 {
 	struct dmz_target *dmz = ti-&gt;private;
<span class="p_add">+	struct dmz_dev *dev = dmz-&gt;dev;</span>
<span class="p_add">+	sector_t capacity = dev-&gt;capacity &amp; ~(dev-&gt;zone_nr_sectors - 1);</span>
 
<span class="p_del">-	return fn(ti, dmz-&gt;ddev, 0, dmz-&gt;dev-&gt;capacity, data);</span>
<span class="p_add">+	return fn(ti, dmz-&gt;ddev, 0, capacity, data);</span>
 }
 
 static struct target_type dmz_type = {
<span class="p_header">diff --git a/drivers/md/dm.c b/drivers/md/dm.c</span>
<span class="p_header">index 4be85324f44d..804419635cc7 100644</span>
<span class="p_header">--- a/drivers/md/dm.c</span>
<span class="p_header">+++ b/drivers/md/dm.c</span>
<span class="p_chunk">@@ -1695,7 +1695,7 @@</span> <span class="p_context"> static struct mapped_device *alloc_dev(int minor)</span>
 	struct mapped_device *md;
 	void *old_md;
 
<span class="p_del">-	md = kzalloc_node(sizeof(*md), GFP_KERNEL, numa_node_id);</span>
<span class="p_add">+	md = kvzalloc_node(sizeof(*md), GFP_KERNEL, numa_node_id);</span>
 	if (!md) {
 		DMWARN(&quot;unable to allocate device, out of memory.&quot;);
 		return NULL;
<span class="p_chunk">@@ -1795,7 +1795,7 @@</span> <span class="p_context"> static struct mapped_device *alloc_dev(int minor)</span>
 bad_minor:
 	module_put(THIS_MODULE);
 bad_module_get:
<span class="p_del">-	kfree(md);</span>
<span class="p_add">+	kvfree(md);</span>
 	return NULL;
 }
 
<span class="p_chunk">@@ -1814,7 +1814,7 @@</span> <span class="p_context"> static void free_dev(struct mapped_device *md)</span>
 	free_minor(minor);
 
 	module_put(THIS_MODULE);
<span class="p_del">-	kfree(md);</span>
<span class="p_add">+	kvfree(md);</span>
 }
 
 static void __bind_mempools(struct mapped_device *md, struct dm_table *t)
<span class="p_chunk">@@ -2709,11 +2709,15 @@</span> <span class="p_context"> struct mapped_device *dm_get_from_kobject(struct kobject *kobj)</span>
 
 	md = container_of(kobj, struct mapped_device, kobj_holder.kobj);
 
<span class="p_del">-	if (test_bit(DMF_FREEING, &amp;md-&gt;flags) ||</span>
<span class="p_del">-	    dm_deleting_md(md))</span>
<span class="p_del">-		return NULL;</span>
<span class="p_del">-</span>
<span class="p_add">+	spin_lock(&amp;_minor_lock);</span>
<span class="p_add">+	if (test_bit(DMF_FREEING, &amp;md-&gt;flags) || dm_deleting_md(md)) {</span>
<span class="p_add">+		md = NULL;</span>
<span class="p_add">+		goto out;</span>
<span class="p_add">+	}</span>
 	dm_get(md);
<span class="p_add">+out:</span>
<span class="p_add">+	spin_unlock(&amp;_minor_lock);</span>
<span class="p_add">+</span>
 	return md;
 }
 
<span class="p_header">diff --git a/drivers/md/md.c b/drivers/md/md.c</span>
<span class="p_header">index 0ff1bbf6c90e..e019cf8c0d13 100644</span>
<span class="p_header">--- a/drivers/md/md.c</span>
<span class="p_header">+++ b/drivers/md/md.c</span>
<span class="p_chunk">@@ -8039,7 +8039,8 @@</span> <span class="p_context"> bool md_write_start(struct mddev *mddev, struct bio *bi)</span>
 	if (did_change)
 		sysfs_notify_dirent_safe(mddev-&gt;sysfs_state);
 	wait_event(mddev-&gt;sb_wait,
<span class="p_del">-		   !test_bit(MD_SB_CHANGE_PENDING, &amp;mddev-&gt;sb_flags) &amp;&amp; !mddev-&gt;suspended);</span>
<span class="p_add">+		   !test_bit(MD_SB_CHANGE_PENDING, &amp;mddev-&gt;sb_flags) ||</span>
<span class="p_add">+		   mddev-&gt;suspended);</span>
 	if (test_bit(MD_SB_CHANGE_PENDING, &amp;mddev-&gt;sb_flags)) {
 		percpu_ref_put(&amp;mddev-&gt;writes_pending);
 		return false;
<span class="p_chunk">@@ -8110,7 +8111,6 @@</span> <span class="p_context"> void md_allow_write(struct mddev *mddev)</span>
 		sysfs_notify_dirent_safe(mddev-&gt;sysfs_state);
 		/* wait for the dirty state to be recorded in the metadata */
 		wait_event(mddev-&gt;sb_wait,
<span class="p_del">-			   !test_bit(MD_SB_CHANGE_CLEAN, &amp;mddev-&gt;sb_flags) &amp;&amp;</span>
 			   !test_bit(MD_SB_CHANGE_PENDING, &amp;mddev-&gt;sb_flags));
 	} else
 		spin_unlock(&amp;mddev-&gt;lock);
<span class="p_header">diff --git a/drivers/md/raid1.c b/drivers/md/raid1.c</span>
<span class="p_header">index f3f3e40dc9d8..e4e8f9e565b7 100644</span>
<span class="p_header">--- a/drivers/md/raid1.c</span>
<span class="p_header">+++ b/drivers/md/raid1.c</span>
<span class="p_chunk">@@ -990,14 +990,6 @@</span> <span class="p_context"> static void wait_barrier(struct r1conf *conf, sector_t sector_nr)</span>
 	_wait_barrier(conf, idx);
 }
 
<span class="p_del">-static void wait_all_barriers(struct r1conf *conf)</span>
<span class="p_del">-{</span>
<span class="p_del">-	int idx;</span>
<span class="p_del">-</span>
<span class="p_del">-	for (idx = 0; idx &lt; BARRIER_BUCKETS_NR; idx++)</span>
<span class="p_del">-		_wait_barrier(conf, idx);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
 static void _allow_barrier(struct r1conf *conf, int idx)
 {
 	atomic_dec(&amp;conf-&gt;nr_pending[idx]);
<span class="p_chunk">@@ -1011,14 +1003,6 @@</span> <span class="p_context"> static void allow_barrier(struct r1conf *conf, sector_t sector_nr)</span>
 	_allow_barrier(conf, idx);
 }
 
<span class="p_del">-static void allow_all_barriers(struct r1conf *conf)</span>
<span class="p_del">-{</span>
<span class="p_del">-	int idx;</span>
<span class="p_del">-</span>
<span class="p_del">-	for (idx = 0; idx &lt; BARRIER_BUCKETS_NR; idx++)</span>
<span class="p_del">-		_allow_barrier(conf, idx);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
 /* conf-&gt;resync_lock should be held */
 static int get_unqueued_pending(struct r1conf *conf)
 {
<span class="p_chunk">@@ -1654,8 +1638,12 @@</span> <span class="p_context"> static void print_conf(struct r1conf *conf)</span>
 
 static void close_sync(struct r1conf *conf)
 {
<span class="p_del">-	wait_all_barriers(conf);</span>
<span class="p_del">-	allow_all_barriers(conf);</span>
<span class="p_add">+	int idx;</span>
<span class="p_add">+</span>
<span class="p_add">+	for (idx = 0; idx &lt; BARRIER_BUCKETS_NR; idx++) {</span>
<span class="p_add">+		_wait_barrier(conf, idx);</span>
<span class="p_add">+		_allow_barrier(conf, idx);</span>
<span class="p_add">+	}</span>
 
 	mempool_destroy(conf-&gt;r1buf_pool);
 	conf-&gt;r1buf_pool = NULL;
<span class="p_header">diff --git a/drivers/media/platform/qcom/venus/core.h b/drivers/media/platform/qcom/venus/core.h</span>
<span class="p_header">index cba092bcb76d..a0fe80df0cbd 100644</span>
<span class="p_header">--- a/drivers/media/platform/qcom/venus/core.h</span>
<span class="p_header">+++ b/drivers/media/platform/qcom/venus/core.h</span>
<span class="p_chunk">@@ -194,7 +194,6 @@</span> <span class="p_context"> struct venus_buffer {</span>
  * @fh:	 a holder of v4l file handle structure
  * @streamon_cap: stream on flag for capture queue
  * @streamon_out: stream on flag for output queue
<span class="p_del">- * @cmd_stop:	a flag to signal encoder/decoder commands</span>
  * @width:	current capture width
  * @height:	current capture height
  * @out_width:	current output width
<span class="p_chunk">@@ -258,7 +257,6 @@</span> <span class="p_context"> struct venus_inst {</span>
 	} controls;
 	struct v4l2_fh fh;
 	unsigned int streamon_cap, streamon_out;
<span class="p_del">-	bool cmd_stop;</span>
 	u32 width;
 	u32 height;
 	u32 out_width;
<span class="p_header">diff --git a/drivers/media/platform/qcom/venus/helpers.c b/drivers/media/platform/qcom/venus/helpers.c</span>
<span class="p_header">index 9b2a401a4891..0ce9559a2924 100644</span>
<span class="p_header">--- a/drivers/media/platform/qcom/venus/helpers.c</span>
<span class="p_header">+++ b/drivers/media/platform/qcom/venus/helpers.c</span>
<span class="p_chunk">@@ -623,13 +623,6 @@</span> <span class="p_context"> void venus_helper_vb2_buf_queue(struct vb2_buffer *vb)</span>
 
 	mutex_lock(&amp;inst-&gt;lock);
 
<span class="p_del">-	if (inst-&gt;cmd_stop) {</span>
<span class="p_del">-		vbuf-&gt;flags |= V4L2_BUF_FLAG_LAST;</span>
<span class="p_del">-		v4l2_m2m_buf_done(vbuf, VB2_BUF_STATE_DONE);</span>
<span class="p_del">-		inst-&gt;cmd_stop = false;</span>
<span class="p_del">-		goto unlock;</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
 	v4l2_m2m_buf_queue(m2m_ctx, vbuf);
 
 	if (!(inst-&gt;streamon_out &amp; inst-&gt;streamon_cap))
<span class="p_header">diff --git a/drivers/media/platform/qcom/venus/hfi.c b/drivers/media/platform/qcom/venus/hfi.c</span>
<span class="p_header">index c09490876516..ba29fd4d4984 100644</span>
<span class="p_header">--- a/drivers/media/platform/qcom/venus/hfi.c</span>
<span class="p_header">+++ b/drivers/media/platform/qcom/venus/hfi.c</span>
<span class="p_chunk">@@ -484,6 +484,7 @@</span> <span class="p_context"> int hfi_session_process_buf(struct venus_inst *inst, struct hfi_frame_data *fd)</span>
 
 	return -EINVAL;
 }
<span class="p_add">+EXPORT_SYMBOL_GPL(hfi_session_process_buf);</span>
 
 irqreturn_t hfi_isr_thread(int irq, void *dev_id)
 {
<span class="p_header">diff --git a/drivers/media/platform/qcom/venus/hfi_venus.c b/drivers/media/platform/qcom/venus/hfi_venus.c</span>
<span class="p_header">index 1caae8feaa36..734ce11b0ed0 100644</span>
<span class="p_header">--- a/drivers/media/platform/qcom/venus/hfi_venus.c</span>
<span class="p_header">+++ b/drivers/media/platform/qcom/venus/hfi_venus.c</span>
<span class="p_chunk">@@ -344,7 +344,7 @@</span> <span class="p_context"> static int venus_alloc(struct venus_hfi_device *hdev, struct mem_desc *desc,</span>
 	desc-&gt;attrs = DMA_ATTR_WRITE_COMBINE;
 	desc-&gt;size = ALIGN(size, SZ_4K);
 
<span class="p_del">-	desc-&gt;kva = dma_alloc_attrs(dev, size, &amp;desc-&gt;da, GFP_KERNEL,</span>
<span class="p_add">+	desc-&gt;kva = dma_alloc_attrs(dev, desc-&gt;size, &amp;desc-&gt;da, GFP_KERNEL,</span>
 				    desc-&gt;attrs);
 	if (!desc-&gt;kva)
 		return -ENOMEM;
<span class="p_chunk">@@ -710,10 +710,8 @@</span> <span class="p_context"> static int venus_interface_queues_init(struct venus_hfi_device *hdev)</span>
 	if (ret)
 		return ret;
 
<span class="p_del">-	hdev-&gt;ifaceq_table.kva = desc.kva;</span>
<span class="p_del">-	hdev-&gt;ifaceq_table.da = desc.da;</span>
<span class="p_del">-	hdev-&gt;ifaceq_table.size = IFACEQ_TABLE_SIZE;</span>
<span class="p_del">-	offset = hdev-&gt;ifaceq_table.size;</span>
<span class="p_add">+	hdev-&gt;ifaceq_table = desc;</span>
<span class="p_add">+	offset = IFACEQ_TABLE_SIZE;</span>
 
 	for (i = 0; i &lt; IFACEQ_NUM; i++) {
 		queue = &amp;hdev-&gt;queues[i];
<span class="p_chunk">@@ -755,9 +753,7 @@</span> <span class="p_context"> static int venus_interface_queues_init(struct venus_hfi_device *hdev)</span>
 	if (ret) {
 		hdev-&gt;sfr.da = 0;
 	} else {
<span class="p_del">-		hdev-&gt;sfr.da = desc.da;</span>
<span class="p_del">-		hdev-&gt;sfr.kva = desc.kva;</span>
<span class="p_del">-		hdev-&gt;sfr.size = ALIGNED_SFR_SIZE;</span>
<span class="p_add">+		hdev-&gt;sfr = desc;</span>
 		sfr = hdev-&gt;sfr.kva;
 		sfr-&gt;buf_size = ALIGNED_SFR_SIZE;
 	}
<span class="p_header">diff --git a/drivers/media/platform/qcom/venus/vdec.c b/drivers/media/platform/qcom/venus/vdec.c</span>
<span class="p_header">index da611a5eb670..c9e9576bb08a 100644</span>
<span class="p_header">--- a/drivers/media/platform/qcom/venus/vdec.c</span>
<span class="p_header">+++ b/drivers/media/platform/qcom/venus/vdec.c</span>
<span class="p_chunk">@@ -469,8 +469,14 @@</span> <span class="p_context"> static int vdec_subscribe_event(struct v4l2_fh *fh,</span>
 static int
 vdec_try_decoder_cmd(struct file *file, void *fh, struct v4l2_decoder_cmd *cmd)
 {
<span class="p_del">-	if (cmd-&gt;cmd != V4L2_DEC_CMD_STOP)</span>
<span class="p_add">+	switch (cmd-&gt;cmd) {</span>
<span class="p_add">+	case V4L2_DEC_CMD_STOP:</span>
<span class="p_add">+		if (cmd-&gt;flags &amp; V4L2_DEC_CMD_STOP_TO_BLACK)</span>
<span class="p_add">+			return -EINVAL;</span>
<span class="p_add">+		break;</span>
<span class="p_add">+	default:</span>
 		return -EINVAL;
<span class="p_add">+	}</span>
 
 	return 0;
 }
<span class="p_chunk">@@ -479,6 +485,7 @@</span> <span class="p_context"> static int</span>
 vdec_decoder_cmd(struct file *file, void *fh, struct v4l2_decoder_cmd *cmd)
 {
 	struct venus_inst *inst = to_inst(file);
<span class="p_add">+	struct hfi_frame_data fdata = {0};</span>
 	int ret;
 
 	ret = vdec_try_decoder_cmd(file, fh, cmd);
<span class="p_chunk">@@ -486,12 +493,23 @@</span> <span class="p_context"> vdec_decoder_cmd(struct file *file, void *fh, struct v4l2_decoder_cmd *cmd)</span>
 		return ret;
 
 	mutex_lock(&amp;inst-&gt;lock);
<span class="p_del">-	inst-&gt;cmd_stop = true;</span>
<span class="p_del">-	mutex_unlock(&amp;inst-&gt;lock);</span>
 
<span class="p_del">-	hfi_session_flush(inst);</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Implement V4L2_DEC_CMD_STOP by enqueue an empty buffer on decoder</span>
<span class="p_add">+	 * input to signal EOS.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	if (!(inst-&gt;streamon_out &amp; inst-&gt;streamon_cap))</span>
<span class="p_add">+		goto unlock;</span>
<span class="p_add">+</span>
<span class="p_add">+	fdata.buffer_type = HFI_BUFFER_INPUT;</span>
<span class="p_add">+	fdata.flags |= HFI_BUFFERFLAG_EOS;</span>
<span class="p_add">+	fdata.device_addr = 0xdeadbeef;</span>
 
<span class="p_del">-	return 0;</span>
<span class="p_add">+	ret = hfi_session_process_buf(inst, &amp;fdata);</span>
<span class="p_add">+</span>
<span class="p_add">+unlock:</span>
<span class="p_add">+	mutex_unlock(&amp;inst-&gt;lock);</span>
<span class="p_add">+	return ret;</span>
 }
 
 static const struct v4l2_ioctl_ops vdec_ioctl_ops = {
<span class="p_chunk">@@ -718,7 +736,6 @@</span> <span class="p_context"> static int vdec_start_streaming(struct vb2_queue *q, unsigned int count)</span>
 	inst-&gt;reconfig = false;
 	inst-&gt;sequence_cap = 0;
 	inst-&gt;sequence_out = 0;
<span class="p_del">-	inst-&gt;cmd_stop = false;</span>
 
 	ret = vdec_init_session(inst);
 	if (ret)
<span class="p_chunk">@@ -807,11 +824,6 @@</span> <span class="p_context"> static void vdec_buf_done(struct venus_inst *inst, unsigned int buf_type,</span>
 		vb-&gt;timestamp = timestamp_us * NSEC_PER_USEC;
 		vbuf-&gt;sequence = inst-&gt;sequence_cap++;
 
<span class="p_del">-		if (inst-&gt;cmd_stop) {</span>
<span class="p_del">-			vbuf-&gt;flags |= V4L2_BUF_FLAG_LAST;</span>
<span class="p_del">-			inst-&gt;cmd_stop = false;</span>
<span class="p_del">-		}</span>
<span class="p_del">-</span>
 		if (vbuf-&gt;flags &amp; V4L2_BUF_FLAG_LAST) {
 			const struct v4l2_event ev = { .type = V4L2_EVENT_EOS };
 
<span class="p_header">diff --git a/drivers/media/platform/qcom/venus/venc.c b/drivers/media/platform/qcom/venus/venc.c</span>
<span class="p_header">index 6f123a387cf9..3fcf0e9b7b29 100644</span>
<span class="p_header">--- a/drivers/media/platform/qcom/venus/venc.c</span>
<span class="p_header">+++ b/drivers/media/platform/qcom/venus/venc.c</span>
<span class="p_chunk">@@ -963,13 +963,12 @@</span> <span class="p_context"> static void venc_buf_done(struct venus_inst *inst, unsigned int buf_type,</span>
 	if (!vbuf)
 		return;
 
<span class="p_del">-	vb = &amp;vbuf-&gt;vb2_buf;</span>
<span class="p_del">-	vb-&gt;planes[0].bytesused = bytesused;</span>
<span class="p_del">-	vb-&gt;planes[0].data_offset = data_offset;</span>
<span class="p_del">-</span>
 	vbuf-&gt;flags = flags;
 
 	if (type == V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE) {
<span class="p_add">+		vb = &amp;vbuf-&gt;vb2_buf;</span>
<span class="p_add">+		vb2_set_plane_payload(vb, 0, bytesused + data_offset);</span>
<span class="p_add">+		vb-&gt;planes[0].data_offset = data_offset;</span>
 		vb-&gt;timestamp = timestamp_us * NSEC_PER_USEC;
 		vbuf-&gt;sequence = inst-&gt;sequence_cap++;
 	} else {
<span class="p_header">diff --git a/drivers/media/rc/ir-lirc-codec.c b/drivers/media/rc/ir-lirc-codec.c</span>
<span class="p_header">index d2223c04e9ad..4c8f456238bc 100644</span>
<span class="p_header">--- a/drivers/media/rc/ir-lirc-codec.c</span>
<span class="p_header">+++ b/drivers/media/rc/ir-lirc-codec.c</span>
<span class="p_chunk">@@ -298,11 +298,14 @@</span> <span class="p_context"> static long ir_lirc_ioctl(struct file *filep, unsigned int cmd,</span>
 		if (!dev-&gt;max_timeout)
 			return -ENOTTY;
 
<span class="p_add">+		/* Check for multiply overflow */</span>
<span class="p_add">+		if (val &gt; U32_MAX / 1000)</span>
<span class="p_add">+			return -EINVAL;</span>
<span class="p_add">+</span>
 		tmp = val * 1000;
 
<span class="p_del">-		if (tmp &lt; dev-&gt;min_timeout ||</span>
<span class="p_del">-		    tmp &gt; dev-&gt;max_timeout)</span>
<span class="p_del">-				return -EINVAL;</span>
<span class="p_add">+		if (tmp &lt; dev-&gt;min_timeout || tmp &gt; dev-&gt;max_timeout)</span>
<span class="p_add">+			return -EINVAL;</span>
 
 		if (dev-&gt;s_timeout)
 			ret = dev-&gt;s_timeout(dev, tmp);
<span class="p_header">diff --git a/drivers/media/rc/ir-nec-decoder.c b/drivers/media/rc/ir-nec-decoder.c</span>
<span class="p_header">index 817c18f2ddd1..a95d09acc22a 100644</span>
<span class="p_header">--- a/drivers/media/rc/ir-nec-decoder.c</span>
<span class="p_header">+++ b/drivers/media/rc/ir-nec-decoder.c</span>
<span class="p_chunk">@@ -87,8 +87,6 @@</span> <span class="p_context"> static int ir_nec_decode(struct rc_dev *dev, struct ir_raw_event ev)</span>
 			data-&gt;state = STATE_BIT_PULSE;
 			return 0;
 		} else if (eq_margin(ev.duration, NEC_REPEAT_SPACE, NEC_UNIT / 2)) {
<span class="p_del">-			rc_repeat(dev);</span>
<span class="p_del">-			IR_dprintk(1, &quot;Repeat last key\n&quot;);</span>
 			data-&gt;state = STATE_TRAILER_PULSE;
 			return 0;
 		}
<span class="p_chunk">@@ -151,19 +149,26 @@</span> <span class="p_context"> static int ir_nec_decode(struct rc_dev *dev, struct ir_raw_event ev)</span>
 		if (!geq_margin(ev.duration, NEC_TRAILER_SPACE, NEC_UNIT / 2))
 			break;
 
<span class="p_del">-		address     = bitrev8((data-&gt;bits &gt;&gt; 24) &amp; 0xff);</span>
<span class="p_del">-		not_address = bitrev8((data-&gt;bits &gt;&gt; 16) &amp; 0xff);</span>
<span class="p_del">-		command	    = bitrev8((data-&gt;bits &gt;&gt;  8) &amp; 0xff);</span>
<span class="p_del">-		not_command = bitrev8((data-&gt;bits &gt;&gt;  0) &amp; 0xff);</span>
<span class="p_add">+		if (data-&gt;count == NEC_NBITS) {</span>
<span class="p_add">+			address     = bitrev8((data-&gt;bits &gt;&gt; 24) &amp; 0xff);</span>
<span class="p_add">+			not_address = bitrev8((data-&gt;bits &gt;&gt; 16) &amp; 0xff);</span>
<span class="p_add">+			command	    = bitrev8((data-&gt;bits &gt;&gt;  8) &amp; 0xff);</span>
<span class="p_add">+			not_command = bitrev8((data-&gt;bits &gt;&gt;  0) &amp; 0xff);</span>
<span class="p_add">+</span>
<span class="p_add">+			scancode = ir_nec_bytes_to_scancode(address,</span>
<span class="p_add">+							    not_address,</span>
<span class="p_add">+							    command,</span>
<span class="p_add">+							    not_command,</span>
<span class="p_add">+							    &amp;rc_proto);</span>
 
<span class="p_del">-		scancode = ir_nec_bytes_to_scancode(address, not_address,</span>
<span class="p_del">-						    command, not_command,</span>
<span class="p_del">-						    &amp;rc_proto);</span>
<span class="p_add">+			if (data-&gt;is_nec_x)</span>
<span class="p_add">+				data-&gt;necx_repeat = true;</span>
 
<span class="p_del">-		if (data-&gt;is_nec_x)</span>
<span class="p_del">-			data-&gt;necx_repeat = true;</span>
<span class="p_add">+			rc_keydown(dev, rc_proto, scancode, 0);</span>
<span class="p_add">+		} else {</span>
<span class="p_add">+			rc_repeat(dev);</span>
<span class="p_add">+		}</span>
 
<span class="p_del">-		rc_keydown(dev, rc_proto, scancode, 0);</span>
 		data-&gt;state = STATE_INACTIVE;
 		return 0;
 	}
<span class="p_header">diff --git a/drivers/media/usb/as102/as102_fw.c b/drivers/media/usb/as102/as102_fw.c</span>
<span class="p_header">index 5a28ce3a1d49..38dbc128340d 100644</span>
<span class="p_header">--- a/drivers/media/usb/as102/as102_fw.c</span>
<span class="p_header">+++ b/drivers/media/usb/as102/as102_fw.c</span>
<span class="p_chunk">@@ -101,18 +101,23 @@</span> <span class="p_context"> static int as102_firmware_upload(struct as10x_bus_adapter_t *bus_adap,</span>
 				 unsigned char *cmd,
 				 const struct firmware *firmware) {
 
<span class="p_del">-	struct as10x_fw_pkt_t fw_pkt;</span>
<span class="p_add">+	struct as10x_fw_pkt_t *fw_pkt;</span>
 	int total_read_bytes = 0, errno = 0;
 	unsigned char addr_has_changed = 0;
 
<span class="p_add">+	fw_pkt = kmalloc(sizeof(*fw_pkt), GFP_KERNEL);</span>
<span class="p_add">+	if (!fw_pkt)</span>
<span class="p_add">+		return -ENOMEM;</span>
<span class="p_add">+</span>
<span class="p_add">+</span>
 	for (total_read_bytes = 0; total_read_bytes &lt; firmware-&gt;size; ) {
 		int read_bytes = 0, data_len = 0;
 
 		/* parse intel hex line */
 		read_bytes = parse_hex_line(
 				(u8 *) (firmware-&gt;data + total_read_bytes),
<span class="p_del">-				fw_pkt.raw.address,</span>
<span class="p_del">-				fw_pkt.raw.data,</span>
<span class="p_add">+				fw_pkt-&gt;raw.address,</span>
<span class="p_add">+				fw_pkt-&gt;raw.data,</span>
 				&amp;data_len,
 				&amp;addr_has_changed);
 
<span class="p_chunk">@@ -122,28 +127,28 @@</span> <span class="p_context"> static int as102_firmware_upload(struct as10x_bus_adapter_t *bus_adap,</span>
 		/* detect the end of file */
 		total_read_bytes += read_bytes;
 		if (total_read_bytes == firmware-&gt;size) {
<span class="p_del">-			fw_pkt.u.request[0] = 0x00;</span>
<span class="p_del">-			fw_pkt.u.request[1] = 0x03;</span>
<span class="p_add">+			fw_pkt-&gt;u.request[0] = 0x00;</span>
<span class="p_add">+			fw_pkt-&gt;u.request[1] = 0x03;</span>
 
 			/* send EOF command */
 			errno = bus_adap-&gt;ops-&gt;upload_fw_pkt(bus_adap,
 							     (uint8_t *)
<span class="p_del">-							     &amp;fw_pkt, 2, 0);</span>
<span class="p_add">+							     fw_pkt, 2, 0);</span>
 			if (errno &lt; 0)
 				goto error;
 		} else {
 			if (!addr_has_changed) {
 				/* prepare command to send */
<span class="p_del">-				fw_pkt.u.request[0] = 0x00;</span>
<span class="p_del">-				fw_pkt.u.request[1] = 0x01;</span>
<span class="p_add">+				fw_pkt-&gt;u.request[0] = 0x00;</span>
<span class="p_add">+				fw_pkt-&gt;u.request[1] = 0x01;</span>
 
<span class="p_del">-				data_len += sizeof(fw_pkt.u.request);</span>
<span class="p_del">-				data_len += sizeof(fw_pkt.raw.address);</span>
<span class="p_add">+				data_len += sizeof(fw_pkt-&gt;u.request);</span>
<span class="p_add">+				data_len += sizeof(fw_pkt-&gt;raw.address);</span>
 
 				/* send cmd to device */
 				errno = bus_adap-&gt;ops-&gt;upload_fw_pkt(bus_adap,
 								     (uint8_t *)
<span class="p_del">-								     &amp;fw_pkt,</span>
<span class="p_add">+								     fw_pkt,</span>
 								     data_len,
 								     0);
 				if (errno &lt; 0)
<span class="p_chunk">@@ -152,6 +157,7 @@</span> <span class="p_context"> static int as102_firmware_upload(struct as10x_bus_adapter_t *bus_adap,</span>
 		}
 	}
 error:
<span class="p_add">+	kfree(fw_pkt);</span>
 	return (errno == 0) ? total_read_bytes : errno;
 }
 
<span class="p_header">diff --git a/drivers/media/usb/cx231xx/cx231xx-cards.c b/drivers/media/usb/cx231xx/cx231xx-cards.c</span>
<span class="p_header">index e0daa9b6c2a0..9b742d569fb5 100644</span>
<span class="p_header">--- a/drivers/media/usb/cx231xx/cx231xx-cards.c</span>
<span class="p_header">+++ b/drivers/media/usb/cx231xx/cx231xx-cards.c</span>
<span class="p_chunk">@@ -1684,7 +1684,7 @@</span> <span class="p_context"> static int cx231xx_usb_probe(struct usb_interface *interface,</span>
 	nr = dev-&gt;devno;
 
 	assoc_desc = udev-&gt;actconfig-&gt;intf_assoc[0];
<span class="p_del">-	if (assoc_desc-&gt;bFirstInterface != ifnum) {</span>
<span class="p_add">+	if (!assoc_desc || assoc_desc-&gt;bFirstInterface != ifnum) {</span>
 		dev_err(d, &quot;Not found matching IAD interface\n&quot;);
 		retval = -ENODEV;
 		goto err_if;
<span class="p_header">diff --git a/drivers/media/v4l2-core/v4l2-ctrls.c b/drivers/media/v4l2-core/v4l2-ctrls.c</span>
<span class="p_header">index dd1db678718c..8033d6f73501 100644</span>
<span class="p_header">--- a/drivers/media/v4l2-core/v4l2-ctrls.c</span>
<span class="p_header">+++ b/drivers/media/v4l2-core/v4l2-ctrls.c</span>
<span class="p_chunk">@@ -1227,6 +1227,16 @@</span> <span class="p_context"> void v4l2_ctrl_fill(u32 id, const char **name, enum v4l2_ctrl_type *type,</span>
 }
 EXPORT_SYMBOL(v4l2_ctrl_fill);
 
<span class="p_add">+static u32 user_flags(const struct v4l2_ctrl *ctrl)</span>
<span class="p_add">+{</span>
<span class="p_add">+	u32 flags = ctrl-&gt;flags;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (ctrl-&gt;is_ptr)</span>
<span class="p_add">+		flags |= V4L2_CTRL_FLAG_HAS_PAYLOAD;</span>
<span class="p_add">+</span>
<span class="p_add">+	return flags;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static void fill_event(struct v4l2_event *ev, struct v4l2_ctrl *ctrl, u32 changes)
 {
 	memset(ev-&gt;reserved, 0, sizeof(ev-&gt;reserved));
<span class="p_chunk">@@ -1234,7 +1244,7 @@</span> <span class="p_context"> static void fill_event(struct v4l2_event *ev, struct v4l2_ctrl *ctrl, u32 change</span>
 	ev-&gt;id = ctrl-&gt;id;
 	ev-&gt;u.ctrl.changes = changes;
 	ev-&gt;u.ctrl.type = ctrl-&gt;type;
<span class="p_del">-	ev-&gt;u.ctrl.flags = ctrl-&gt;flags;</span>
<span class="p_add">+	ev-&gt;u.ctrl.flags = user_flags(ctrl);</span>
 	if (ctrl-&gt;is_ptr)
 		ev-&gt;u.ctrl.value64 = 0;
 	else
<span class="p_chunk">@@ -2577,10 +2587,8 @@</span> <span class="p_context"> int v4l2_query_ext_ctrl(struct v4l2_ctrl_handler *hdl, struct v4l2_query_ext_ctr</span>
 	else
 		qc-&gt;id = ctrl-&gt;id;
 	strlcpy(qc-&gt;name, ctrl-&gt;name, sizeof(qc-&gt;name));
<span class="p_del">-	qc-&gt;flags = ctrl-&gt;flags;</span>
<span class="p_add">+	qc-&gt;flags = user_flags(ctrl);</span>
 	qc-&gt;type = ctrl-&gt;type;
<span class="p_del">-	if (ctrl-&gt;is_ptr)</span>
<span class="p_del">-		qc-&gt;flags |= V4L2_CTRL_FLAG_HAS_PAYLOAD;</span>
 	qc-&gt;elem_size = ctrl-&gt;elem_size;
 	qc-&gt;elems = ctrl-&gt;elems;
 	qc-&gt;nr_of_dims = ctrl-&gt;nr_of_dims;
<span class="p_header">diff --git a/drivers/mfd/lpc_ich.c b/drivers/mfd/lpc_ich.c</span>
<span class="p_header">index 450ae36645aa..cf1120abbf52 100644</span>
<span class="p_header">--- a/drivers/mfd/lpc_ich.c</span>
<span class="p_header">+++ b/drivers/mfd/lpc_ich.c</span>
<span class="p_chunk">@@ -522,6 +522,7 @@</span> <span class="p_context"> static struct lpc_ich_info lpc_chipset_info[] = {</span>
 		.name = &quot;Avoton SoC&quot;,
 		.iTCO_version = 3,
 		.gpio_version = AVOTON_GPIO,
<span class="p_add">+		.spi_type = INTEL_SPI_BYT,</span>
 	},
 	[LPC_BAYTRAIL] = {
 		.name = &quot;Bay Trail SoC&quot;,
<span class="p_header">diff --git a/drivers/mtd/devices/docg3.c b/drivers/mtd/devices/docg3.c</span>
<span class="p_header">index 84b16133554b..0806f72102c0 100644</span>
<span class="p_header">--- a/drivers/mtd/devices/docg3.c</span>
<span class="p_header">+++ b/drivers/mtd/devices/docg3.c</span>
<span class="p_chunk">@@ -1814,8 +1814,13 @@</span> <span class="p_context"> static void __init doc_dbg_register(struct mtd_info *floor)</span>
 	struct dentry *root = floor-&gt;dbg.dfs_dir;
 	struct docg3 *docg3 = floor-&gt;priv;
 
<span class="p_del">-	if (IS_ERR_OR_NULL(root))</span>
<span class="p_add">+	if (IS_ERR_OR_NULL(root)) {</span>
<span class="p_add">+		if (IS_ENABLED(CONFIG_DEBUG_FS) &amp;&amp;</span>
<span class="p_add">+		    !IS_ENABLED(CONFIG_MTD_PARTITIONED_MASTER))</span>
<span class="p_add">+			dev_warn(floor-&gt;dev.parent,</span>
<span class="p_add">+				 &quot;CONFIG_MTD_PARTITIONED_MASTER must be enabled to expose debugfs stuff\n&quot;);</span>
 		return;
<span class="p_add">+	}</span>
 
 	debugfs_create_file(&quot;docg3_flashcontrol&quot;, S_IRUSR, root, docg3,
 			    &amp;flashcontrol_fops);
<span class="p_header">diff --git a/drivers/mtd/nand/atmel/nand-controller.c b/drivers/mtd/nand/atmel/nand-controller.c</span>
<span class="p_header">index f25eca79f4e5..68c9d98a3347 100644</span>
<span class="p_header">--- a/drivers/mtd/nand/atmel/nand-controller.c</span>
<span class="p_header">+++ b/drivers/mtd/nand/atmel/nand-controller.c</span>
<span class="p_chunk">@@ -2547,6 +2547,7 @@</span> <span class="p_context"> static struct platform_driver atmel_nand_controller_driver = {</span>
 	.driver = {
 		.name = &quot;atmel-nand-controller&quot;,
 		.of_match_table = of_match_ptr(atmel_nand_controller_of_ids),
<span class="p_add">+		.pm = &amp;atmel_nand_controller_pm_ops,</span>
 	},
 	.probe = atmel_nand_controller_probe,
 	.remove = atmel_nand_controller_remove,
<span class="p_header">diff --git a/drivers/mtd/nand/mtk_ecc.c b/drivers/mtd/nand/mtk_ecc.c</span>
<span class="p_header">index 7f3b065b6b8f..c51d214d169e 100644</span>
<span class="p_header">--- a/drivers/mtd/nand/mtk_ecc.c</span>
<span class="p_header">+++ b/drivers/mtd/nand/mtk_ecc.c</span>
<span class="p_chunk">@@ -115,6 +115,11 @@</span> <span class="p_context"> static irqreturn_t mtk_ecc_irq(int irq, void *id)</span>
 		op = ECC_DECODE;
 		dec = readw(ecc-&gt;regs + ECC_DECDONE);
 		if (dec &amp; ecc-&gt;sectors) {
<span class="p_add">+			/*</span>
<span class="p_add">+			 * Clear decode IRQ status once again to ensure that</span>
<span class="p_add">+			 * there will be no extra IRQ.</span>
<span class="p_add">+			 */</span>
<span class="p_add">+			readw(ecc-&gt;regs + ECC_DECIRQ_STA);</span>
 			ecc-&gt;sectors = 0;
 			complete(&amp;ecc-&gt;done);
 		} else {
<span class="p_chunk">@@ -130,8 +135,6 @@</span> <span class="p_context"> static irqreturn_t mtk_ecc_irq(int irq, void *id)</span>
 		}
 	}
 
<span class="p_del">-	writel(0, ecc-&gt;regs + ECC_IRQ_REG(op));</span>
<span class="p_del">-</span>
 	return IRQ_HANDLED;
 }
 
<span class="p_chunk">@@ -307,6 +310,12 @@</span> <span class="p_context"> void mtk_ecc_disable(struct mtk_ecc *ecc)</span>
 
 	/* disable it */
 	mtk_ecc_wait_idle(ecc, op);
<span class="p_add">+	if (op == ECC_DECODE)</span>
<span class="p_add">+		/*</span>
<span class="p_add">+		 * Clear decode IRQ status in case there is a timeout to wait</span>
<span class="p_add">+		 * decode IRQ.</span>
<span class="p_add">+		 */</span>
<span class="p_add">+		readw(ecc-&gt;regs + ECC_DECIRQ_STA);</span>
 	writew(0, ecc-&gt;regs + ECC_IRQ_REG(op));
 	writew(ECC_OP_DISABLE, ecc-&gt;regs + ECC_CTL_REG(op));
 
<span class="p_header">diff --git a/drivers/mtd/nand/nand_base.c b/drivers/mtd/nand/nand_base.c</span>
<span class="p_header">index 12edaae17d81..3f1d806e590a 100644</span>
<span class="p_header">--- a/drivers/mtd/nand/nand_base.c</span>
<span class="p_header">+++ b/drivers/mtd/nand/nand_base.c</span>
<span class="p_chunk">@@ -1246,6 +1246,7 @@</span> <span class="p_context"> int nand_reset(struct nand_chip *chip, int chipnr)</span>
 
 	return 0;
 }
<span class="p_add">+EXPORT_SYMBOL_GPL(nand_reset);</span>
 
 /**
  * nand_check_erased_buf - check if a buffer contains (almost) only 0xff data
<span class="p_chunk">@@ -2799,15 +2800,18 @@</span> <span class="p_context"> static int panic_nand_write(struct mtd_info *mtd, loff_t to, size_t len,</span>
 			    size_t *retlen, const uint8_t *buf)
 {
 	struct nand_chip *chip = mtd_to_nand(mtd);
<span class="p_add">+	int chipnr = (int)(to &gt;&gt; chip-&gt;chip_shift);</span>
 	struct mtd_oob_ops ops;
 	int ret;
 
<span class="p_del">-	/* Wait for the device to get ready */</span>
<span class="p_del">-	panic_nand_wait(mtd, chip, 400);</span>
<span class="p_del">-</span>
 	/* Grab the device */
 	panic_nand_get_device(chip, mtd, FL_WRITING);
 
<span class="p_add">+	chip-&gt;select_chip(mtd, chipnr);</span>
<span class="p_add">+</span>
<span class="p_add">+	/* Wait for the device to get ready */</span>
<span class="p_add">+	panic_nand_wait(mtd, chip, 400);</span>
<span class="p_add">+</span>
 	memset(&amp;ops, 0, sizeof(ops));
 	ops.len = len;
 	ops.datbuf = (uint8_t *)buf;
<span class="p_header">diff --git a/drivers/mtd/nand/nandsim.c b/drivers/mtd/nand/nandsim.c</span>
<span class="p_header">index 246b4393118e..44322a363ba5 100644</span>
<span class="p_header">--- a/drivers/mtd/nand/nandsim.c</span>
<span class="p_header">+++ b/drivers/mtd/nand/nandsim.c</span>
<span class="p_chunk">@@ -520,11 +520,16 @@</span> <span class="p_context"> static int nandsim_debugfs_create(struct nandsim *dev)</span>
 	struct dentry *root = nsmtd-&gt;dbg.dfs_dir;
 	struct dentry *dent;
 
<span class="p_del">-	if (!IS_ENABLED(CONFIG_DEBUG_FS))</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Just skip debugfs initialization when the debugfs directory is</span>
<span class="p_add">+	 * missing.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	if (IS_ERR_OR_NULL(root)) {</span>
<span class="p_add">+		if (IS_ENABLED(CONFIG_DEBUG_FS) &amp;&amp;</span>
<span class="p_add">+		    !IS_ENABLED(CONFIG_MTD_PARTITIONED_MASTER))</span>
<span class="p_add">+			NS_WARN(&quot;CONFIG_MTD_PARTITIONED_MASTER must be enabled to expose debugfs stuff\n&quot;);</span>
 		return 0;
<span class="p_del">-</span>
<span class="p_del">-	if (IS_ERR_OR_NULL(root))</span>
<span class="p_del">-		return -1;</span>
<span class="p_add">+	}</span>
 
 	dent = debugfs_create_file(&quot;nandsim_wear_report&quot;, S_IRUSR,
 				   root, dev, &amp;dfs_fops);
<span class="p_header">diff --git a/drivers/mtd/nand/omap2.c b/drivers/mtd/nand/omap2.c</span>
<span class="p_header">index 54540c8fa1a2..9f98f74ff221 100644</span>
<span class="p_header">--- a/drivers/mtd/nand/omap2.c</span>
<span class="p_header">+++ b/drivers/mtd/nand/omap2.c</span>
<span class="p_chunk">@@ -1133,129 +1133,172 @@</span> <span class="p_context"> static u8  bch8_polynomial[] = {0xef, 0x51, 0x2e, 0x09, 0xed, 0x93, 0x9a, 0xc2,</span>
 				0x97, 0x79, 0xe5, 0x24, 0xb5};
 
 /**
<span class="p_del">- * omap_calculate_ecc_bch - Generate bytes of ECC bytes</span>
<span class="p_add">+ * _omap_calculate_ecc_bch - Generate ECC bytes for one sector</span>
  * @mtd:	MTD device structure
  * @dat:	The pointer to data on which ecc is computed
  * @ecc_code:	The ecc_code buffer
<span class="p_add">+ * @i:		The sector number (for a multi sector page)</span>
  *
<span class="p_del">- * Support calculating of BCH4/8 ecc vectors for the page</span>
<span class="p_add">+ * Support calculating of BCH4/8/16 ECC vectors for one sector</span>
<span class="p_add">+ * within a page. Sector number is in @i.</span>
  */
<span class="p_del">-static int __maybe_unused omap_calculate_ecc_bch(struct mtd_info *mtd,</span>
<span class="p_del">-					const u_char *dat, u_char *ecc_calc)</span>
<span class="p_add">+static int _omap_calculate_ecc_bch(struct mtd_info *mtd,</span>
<span class="p_add">+				   const u_char *dat, u_char *ecc_calc, int i)</span>
 {
 	struct omap_nand_info *info = mtd_to_omap(mtd);
 	int eccbytes	= info-&gt;nand.ecc.bytes;
 	struct gpmc_nand_regs	*gpmc_regs = &amp;info-&gt;reg;
 	u8 *ecc_code;
<span class="p_del">-	unsigned long nsectors, bch_val1, bch_val2, bch_val3, bch_val4;</span>
<span class="p_add">+	unsigned long bch_val1, bch_val2, bch_val3, bch_val4;</span>
 	u32 val;
<span class="p_del">-	int i, j;</span>
<span class="p_add">+	int j;</span>
<span class="p_add">+</span>
<span class="p_add">+	ecc_code = ecc_calc;</span>
<span class="p_add">+	switch (info-&gt;ecc_opt) {</span>
<span class="p_add">+	case OMAP_ECC_BCH8_CODE_HW_DETECTION_SW:</span>
<span class="p_add">+	case OMAP_ECC_BCH8_CODE_HW:</span>
<span class="p_add">+		bch_val1 = readl(gpmc_regs-&gt;gpmc_bch_result0[i]);</span>
<span class="p_add">+		bch_val2 = readl(gpmc_regs-&gt;gpmc_bch_result1[i]);</span>
<span class="p_add">+		bch_val3 = readl(gpmc_regs-&gt;gpmc_bch_result2[i]);</span>
<span class="p_add">+		bch_val4 = readl(gpmc_regs-&gt;gpmc_bch_result3[i]);</span>
<span class="p_add">+		*ecc_code++ = (bch_val4 &amp; 0xFF);</span>
<span class="p_add">+		*ecc_code++ = ((bch_val3 &gt;&gt; 24) &amp; 0xFF);</span>
<span class="p_add">+		*ecc_code++ = ((bch_val3 &gt;&gt; 16) &amp; 0xFF);</span>
<span class="p_add">+		*ecc_code++ = ((bch_val3 &gt;&gt; 8) &amp; 0xFF);</span>
<span class="p_add">+		*ecc_code++ = (bch_val3 &amp; 0xFF);</span>
<span class="p_add">+		*ecc_code++ = ((bch_val2 &gt;&gt; 24) &amp; 0xFF);</span>
<span class="p_add">+		*ecc_code++ = ((bch_val2 &gt;&gt; 16) &amp; 0xFF);</span>
<span class="p_add">+		*ecc_code++ = ((bch_val2 &gt;&gt; 8) &amp; 0xFF);</span>
<span class="p_add">+		*ecc_code++ = (bch_val2 &amp; 0xFF);</span>
<span class="p_add">+		*ecc_code++ = ((bch_val1 &gt;&gt; 24) &amp; 0xFF);</span>
<span class="p_add">+		*ecc_code++ = ((bch_val1 &gt;&gt; 16) &amp; 0xFF);</span>
<span class="p_add">+		*ecc_code++ = ((bch_val1 &gt;&gt; 8) &amp; 0xFF);</span>
<span class="p_add">+		*ecc_code++ = (bch_val1 &amp; 0xFF);</span>
<span class="p_add">+		break;</span>
<span class="p_add">+	case OMAP_ECC_BCH4_CODE_HW_DETECTION_SW:</span>
<span class="p_add">+	case OMAP_ECC_BCH4_CODE_HW:</span>
<span class="p_add">+		bch_val1 = readl(gpmc_regs-&gt;gpmc_bch_result0[i]);</span>
<span class="p_add">+		bch_val2 = readl(gpmc_regs-&gt;gpmc_bch_result1[i]);</span>
<span class="p_add">+		*ecc_code++ = ((bch_val2 &gt;&gt; 12) &amp; 0xFF);</span>
<span class="p_add">+		*ecc_code++ = ((bch_val2 &gt;&gt; 4) &amp; 0xFF);</span>
<span class="p_add">+		*ecc_code++ = ((bch_val2 &amp; 0xF) &lt;&lt; 4) |</span>
<span class="p_add">+			((bch_val1 &gt;&gt; 28) &amp; 0xF);</span>
<span class="p_add">+		*ecc_code++ = ((bch_val1 &gt;&gt; 20) &amp; 0xFF);</span>
<span class="p_add">+		*ecc_code++ = ((bch_val1 &gt;&gt; 12) &amp; 0xFF);</span>
<span class="p_add">+		*ecc_code++ = ((bch_val1 &gt;&gt; 4) &amp; 0xFF);</span>
<span class="p_add">+		*ecc_code++ = ((bch_val1 &amp; 0xF) &lt;&lt; 4);</span>
<span class="p_add">+		break;</span>
<span class="p_add">+	case OMAP_ECC_BCH16_CODE_HW:</span>
<span class="p_add">+		val = readl(gpmc_regs-&gt;gpmc_bch_result6[i]);</span>
<span class="p_add">+		ecc_code[0]  = ((val &gt;&gt;  8) &amp; 0xFF);</span>
<span class="p_add">+		ecc_code[1]  = ((val &gt;&gt;  0) &amp; 0xFF);</span>
<span class="p_add">+		val = readl(gpmc_regs-&gt;gpmc_bch_result5[i]);</span>
<span class="p_add">+		ecc_code[2]  = ((val &gt;&gt; 24) &amp; 0xFF);</span>
<span class="p_add">+		ecc_code[3]  = ((val &gt;&gt; 16) &amp; 0xFF);</span>
<span class="p_add">+		ecc_code[4]  = ((val &gt;&gt;  8) &amp; 0xFF);</span>
<span class="p_add">+		ecc_code[5]  = ((val &gt;&gt;  0) &amp; 0xFF);</span>
<span class="p_add">+		val = readl(gpmc_regs-&gt;gpmc_bch_result4[i]);</span>
<span class="p_add">+		ecc_code[6]  = ((val &gt;&gt; 24) &amp; 0xFF);</span>
<span class="p_add">+		ecc_code[7]  = ((val &gt;&gt; 16) &amp; 0xFF);</span>
<span class="p_add">+		ecc_code[8]  = ((val &gt;&gt;  8) &amp; 0xFF);</span>
<span class="p_add">+		ecc_code[9]  = ((val &gt;&gt;  0) &amp; 0xFF);</span>
<span class="p_add">+		val = readl(gpmc_regs-&gt;gpmc_bch_result3[i]);</span>
<span class="p_add">+		ecc_code[10] = ((val &gt;&gt; 24) &amp; 0xFF);</span>
<span class="p_add">+		ecc_code[11] = ((val &gt;&gt; 16) &amp; 0xFF);</span>
<span class="p_add">+		ecc_code[12] = ((val &gt;&gt;  8) &amp; 0xFF);</span>
<span class="p_add">+		ecc_code[13] = ((val &gt;&gt;  0) &amp; 0xFF);</span>
<span class="p_add">+		val = readl(gpmc_regs-&gt;gpmc_bch_result2[i]);</span>
<span class="p_add">+		ecc_code[14] = ((val &gt;&gt; 24) &amp; 0xFF);</span>
<span class="p_add">+		ecc_code[15] = ((val &gt;&gt; 16) &amp; 0xFF);</span>
<span class="p_add">+		ecc_code[16] = ((val &gt;&gt;  8) &amp; 0xFF);</span>
<span class="p_add">+		ecc_code[17] = ((val &gt;&gt;  0) &amp; 0xFF);</span>
<span class="p_add">+		val = readl(gpmc_regs-&gt;gpmc_bch_result1[i]);</span>
<span class="p_add">+		ecc_code[18] = ((val &gt;&gt; 24) &amp; 0xFF);</span>
<span class="p_add">+		ecc_code[19] = ((val &gt;&gt; 16) &amp; 0xFF);</span>
<span class="p_add">+		ecc_code[20] = ((val &gt;&gt;  8) &amp; 0xFF);</span>
<span class="p_add">+		ecc_code[21] = ((val &gt;&gt;  0) &amp; 0xFF);</span>
<span class="p_add">+		val = readl(gpmc_regs-&gt;gpmc_bch_result0[i]);</span>
<span class="p_add">+		ecc_code[22] = ((val &gt;&gt; 24) &amp; 0xFF);</span>
<span class="p_add">+		ecc_code[23] = ((val &gt;&gt; 16) &amp; 0xFF);</span>
<span class="p_add">+		ecc_code[24] = ((val &gt;&gt;  8) &amp; 0xFF);</span>
<span class="p_add">+		ecc_code[25] = ((val &gt;&gt;  0) &amp; 0xFF);</span>
<span class="p_add">+		break;</span>
<span class="p_add">+	default:</span>
<span class="p_add">+		return -EINVAL;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	/* ECC scheme specific syndrome customizations */</span>
<span class="p_add">+	switch (info-&gt;ecc_opt) {</span>
<span class="p_add">+	case OMAP_ECC_BCH4_CODE_HW_DETECTION_SW:</span>
<span class="p_add">+		/* Add constant polynomial to remainder, so that</span>
<span class="p_add">+		 * ECC of blank pages results in 0x0 on reading back</span>
<span class="p_add">+		 */</span>
<span class="p_add">+		for (j = 0; j &lt; eccbytes; j++)</span>
<span class="p_add">+			ecc_calc[j] ^= bch4_polynomial[j];</span>
<span class="p_add">+		break;</span>
<span class="p_add">+	case OMAP_ECC_BCH4_CODE_HW:</span>
<span class="p_add">+		/* Set  8th ECC byte as 0x0 for ROM compatibility */</span>
<span class="p_add">+		ecc_calc[eccbytes - 1] = 0x0;</span>
<span class="p_add">+		break;</span>
<span class="p_add">+	case OMAP_ECC_BCH8_CODE_HW_DETECTION_SW:</span>
<span class="p_add">+		/* Add constant polynomial to remainder, so that</span>
<span class="p_add">+		 * ECC of blank pages results in 0x0 on reading back</span>
<span class="p_add">+		 */</span>
<span class="p_add">+		for (j = 0; j &lt; eccbytes; j++)</span>
<span class="p_add">+			ecc_calc[j] ^= bch8_polynomial[j];</span>
<span class="p_add">+		break;</span>
<span class="p_add">+	case OMAP_ECC_BCH8_CODE_HW:</span>
<span class="p_add">+		/* Set 14th ECC byte as 0x0 for ROM compatibility */</span>
<span class="p_add">+		ecc_calc[eccbytes - 1] = 0x0;</span>
<span class="p_add">+		break;</span>
<span class="p_add">+	case OMAP_ECC_BCH16_CODE_HW:</span>
<span class="p_add">+		break;</span>
<span class="p_add">+	default:</span>
<span class="p_add">+		return -EINVAL;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	return 0;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+/**</span>
<span class="p_add">+ * omap_calculate_ecc_bch_sw - ECC generator for sector for SW based correction</span>
<span class="p_add">+ * @mtd:	MTD device structure</span>
<span class="p_add">+ * @dat:	The pointer to data on which ecc is computed</span>
<span class="p_add">+ * @ecc_code:	The ecc_code buffer</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * Support calculating of BCH4/8/16 ECC vectors for one sector. This is used</span>
<span class="p_add">+ * when SW based correction is required as ECC is required for one sector</span>
<span class="p_add">+ * at a time.</span>
<span class="p_add">+ */</span>
<span class="p_add">+static int omap_calculate_ecc_bch_sw(struct mtd_info *mtd,</span>
<span class="p_add">+				     const u_char *dat, u_char *ecc_calc)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return _omap_calculate_ecc_bch(mtd, dat, ecc_calc, 0);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+/**</span>
<span class="p_add">+ * omap_calculate_ecc_bch_multi - Generate ECC for multiple sectors</span>
<span class="p_add">+ * @mtd:	MTD device structure</span>
<span class="p_add">+ * @dat:	The pointer to data on which ecc is computed</span>
<span class="p_add">+ * @ecc_code:	The ecc_code buffer</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * Support calculating of BCH4/8/16 ecc vectors for the entire page in one go.</span>
<span class="p_add">+ */</span>
<span class="p_add">+static int omap_calculate_ecc_bch_multi(struct mtd_info *mtd,</span>
<span class="p_add">+					const u_char *dat, u_char *ecc_calc)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct omap_nand_info *info = mtd_to_omap(mtd);</span>
<span class="p_add">+	int eccbytes = info-&gt;nand.ecc.bytes;</span>
<span class="p_add">+	unsigned long nsectors;</span>
<span class="p_add">+	int i, ret;</span>
 
 	nsectors = ((readl(info-&gt;reg.gpmc_ecc_config) &gt;&gt; 4) &amp; 0x7) + 1;
 	for (i = 0; i &lt; nsectors; i++) {
<span class="p_del">-		ecc_code = ecc_calc;</span>
<span class="p_del">-		switch (info-&gt;ecc_opt) {</span>
<span class="p_del">-		case OMAP_ECC_BCH8_CODE_HW_DETECTION_SW:</span>
<span class="p_del">-		case OMAP_ECC_BCH8_CODE_HW:</span>
<span class="p_del">-			bch_val1 = readl(gpmc_regs-&gt;gpmc_bch_result0[i]);</span>
<span class="p_del">-			bch_val2 = readl(gpmc_regs-&gt;gpmc_bch_result1[i]);</span>
<span class="p_del">-			bch_val3 = readl(gpmc_regs-&gt;gpmc_bch_result2[i]);</span>
<span class="p_del">-			bch_val4 = readl(gpmc_regs-&gt;gpmc_bch_result3[i]);</span>
<span class="p_del">-			*ecc_code++ = (bch_val4 &amp; 0xFF);</span>
<span class="p_del">-			*ecc_code++ = ((bch_val3 &gt;&gt; 24) &amp; 0xFF);</span>
<span class="p_del">-			*ecc_code++ = ((bch_val3 &gt;&gt; 16) &amp; 0xFF);</span>
<span class="p_del">-			*ecc_code++ = ((bch_val3 &gt;&gt; 8) &amp; 0xFF);</span>
<span class="p_del">-			*ecc_code++ = (bch_val3 &amp; 0xFF);</span>
<span class="p_del">-			*ecc_code++ = ((bch_val2 &gt;&gt; 24) &amp; 0xFF);</span>
<span class="p_del">-			*ecc_code++ = ((bch_val2 &gt;&gt; 16) &amp; 0xFF);</span>
<span class="p_del">-			*ecc_code++ = ((bch_val2 &gt;&gt; 8) &amp; 0xFF);</span>
<span class="p_del">-			*ecc_code++ = (bch_val2 &amp; 0xFF);</span>
<span class="p_del">-			*ecc_code++ = ((bch_val1 &gt;&gt; 24) &amp; 0xFF);</span>
<span class="p_del">-			*ecc_code++ = ((bch_val1 &gt;&gt; 16) &amp; 0xFF);</span>
<span class="p_del">-			*ecc_code++ = ((bch_val1 &gt;&gt; 8) &amp; 0xFF);</span>
<span class="p_del">-			*ecc_code++ = (bch_val1 &amp; 0xFF);</span>
<span class="p_del">-			break;</span>
<span class="p_del">-		case OMAP_ECC_BCH4_CODE_HW_DETECTION_SW:</span>
<span class="p_del">-		case OMAP_ECC_BCH4_CODE_HW:</span>
<span class="p_del">-			bch_val1 = readl(gpmc_regs-&gt;gpmc_bch_result0[i]);</span>
<span class="p_del">-			bch_val2 = readl(gpmc_regs-&gt;gpmc_bch_result1[i]);</span>
<span class="p_del">-			*ecc_code++ = ((bch_val2 &gt;&gt; 12) &amp; 0xFF);</span>
<span class="p_del">-			*ecc_code++ = ((bch_val2 &gt;&gt; 4) &amp; 0xFF);</span>
<span class="p_del">-			*ecc_code++ = ((bch_val2 &amp; 0xF) &lt;&lt; 4) |</span>
<span class="p_del">-				((bch_val1 &gt;&gt; 28) &amp; 0xF);</span>
<span class="p_del">-			*ecc_code++ = ((bch_val1 &gt;&gt; 20) &amp; 0xFF);</span>
<span class="p_del">-			*ecc_code++ = ((bch_val1 &gt;&gt; 12) &amp; 0xFF);</span>
<span class="p_del">-			*ecc_code++ = ((bch_val1 &gt;&gt; 4) &amp; 0xFF);</span>
<span class="p_del">-			*ecc_code++ = ((bch_val1 &amp; 0xF) &lt;&lt; 4);</span>
<span class="p_del">-			break;</span>
<span class="p_del">-		case OMAP_ECC_BCH16_CODE_HW:</span>
<span class="p_del">-			val = readl(gpmc_regs-&gt;gpmc_bch_result6[i]);</span>
<span class="p_del">-			ecc_code[0]  = ((val &gt;&gt;  8) &amp; 0xFF);</span>
<span class="p_del">-			ecc_code[1]  = ((val &gt;&gt;  0) &amp; 0xFF);</span>
<span class="p_del">-			val = readl(gpmc_regs-&gt;gpmc_bch_result5[i]);</span>
<span class="p_del">-			ecc_code[2]  = ((val &gt;&gt; 24) &amp; 0xFF);</span>
<span class="p_del">-			ecc_code[3]  = ((val &gt;&gt; 16) &amp; 0xFF);</span>
<span class="p_del">-			ecc_code[4]  = ((val &gt;&gt;  8) &amp; 0xFF);</span>
<span class="p_del">-			ecc_code[5]  = ((val &gt;&gt;  0) &amp; 0xFF);</span>
<span class="p_del">-			val = readl(gpmc_regs-&gt;gpmc_bch_result4[i]);</span>
<span class="p_del">-			ecc_code[6]  = ((val &gt;&gt; 24) &amp; 0xFF);</span>
<span class="p_del">-			ecc_code[7]  = ((val &gt;&gt; 16) &amp; 0xFF);</span>
<span class="p_del">-			ecc_code[8]  = ((val &gt;&gt;  8) &amp; 0xFF);</span>
<span class="p_del">-			ecc_code[9]  = ((val &gt;&gt;  0) &amp; 0xFF);</span>
<span class="p_del">-			val = readl(gpmc_regs-&gt;gpmc_bch_result3[i]);</span>
<span class="p_del">-			ecc_code[10] = ((val &gt;&gt; 24) &amp; 0xFF);</span>
<span class="p_del">-			ecc_code[11] = ((val &gt;&gt; 16) &amp; 0xFF);</span>
<span class="p_del">-			ecc_code[12] = ((val &gt;&gt;  8) &amp; 0xFF);</span>
<span class="p_del">-			ecc_code[13] = ((val &gt;&gt;  0) &amp; 0xFF);</span>
<span class="p_del">-			val = readl(gpmc_regs-&gt;gpmc_bch_result2[i]);</span>
<span class="p_del">-			ecc_code[14] = ((val &gt;&gt; 24) &amp; 0xFF);</span>
<span class="p_del">-			ecc_code[15] = ((val &gt;&gt; 16) &amp; 0xFF);</span>
<span class="p_del">-			ecc_code[16] = ((val &gt;&gt;  8) &amp; 0xFF);</span>
<span class="p_del">-			ecc_code[17] = ((val &gt;&gt;  0) &amp; 0xFF);</span>
<span class="p_del">-			val = readl(gpmc_regs-&gt;gpmc_bch_result1[i]);</span>
<span class="p_del">-			ecc_code[18] = ((val &gt;&gt; 24) &amp; 0xFF);</span>
<span class="p_del">-			ecc_code[19] = ((val &gt;&gt; 16) &amp; 0xFF);</span>
<span class="p_del">-			ecc_code[20] = ((val &gt;&gt;  8) &amp; 0xFF);</span>
<span class="p_del">-			ecc_code[21] = ((val &gt;&gt;  0) &amp; 0xFF);</span>
<span class="p_del">-			val = readl(gpmc_regs-&gt;gpmc_bch_result0[i]);</span>
<span class="p_del">-			ecc_code[22] = ((val &gt;&gt; 24) &amp; 0xFF);</span>
<span class="p_del">-			ecc_code[23] = ((val &gt;&gt; 16) &amp; 0xFF);</span>
<span class="p_del">-			ecc_code[24] = ((val &gt;&gt;  8) &amp; 0xFF);</span>
<span class="p_del">-			ecc_code[25] = ((val &gt;&gt;  0) &amp; 0xFF);</span>
<span class="p_del">-			break;</span>
<span class="p_del">-		default:</span>
<span class="p_del">-			return -EINVAL;</span>
<span class="p_del">-		}</span>
<span class="p_del">-</span>
<span class="p_del">-		/* ECC scheme specific syndrome customizations */</span>
<span class="p_del">-		switch (info-&gt;ecc_opt) {</span>
<span class="p_del">-		case OMAP_ECC_BCH4_CODE_HW_DETECTION_SW:</span>
<span class="p_del">-			/* Add constant polynomial to remainder, so that</span>
<span class="p_del">-			 * ECC of blank pages results in 0x0 on reading back */</span>
<span class="p_del">-			for (j = 0; j &lt; eccbytes; j++)</span>
<span class="p_del">-				ecc_calc[j] ^= bch4_polynomial[j];</span>
<span class="p_del">-			break;</span>
<span class="p_del">-		case OMAP_ECC_BCH4_CODE_HW:</span>
<span class="p_del">-			/* Set  8th ECC byte as 0x0 for ROM compatibility */</span>
<span class="p_del">-			ecc_calc[eccbytes - 1] = 0x0;</span>
<span class="p_del">-			break;</span>
<span class="p_del">-		case OMAP_ECC_BCH8_CODE_HW_DETECTION_SW:</span>
<span class="p_del">-			/* Add constant polynomial to remainder, so that</span>
<span class="p_del">-			 * ECC of blank pages results in 0x0 on reading back */</span>
<span class="p_del">-			for (j = 0; j &lt; eccbytes; j++)</span>
<span class="p_del">-				ecc_calc[j] ^= bch8_polynomial[j];</span>
<span class="p_del">-			break;</span>
<span class="p_del">-		case OMAP_ECC_BCH8_CODE_HW:</span>
<span class="p_del">-			/* Set 14th ECC byte as 0x0 for ROM compatibility */</span>
<span class="p_del">-			ecc_calc[eccbytes - 1] = 0x0;</span>
<span class="p_del">-			break;</span>
<span class="p_del">-		case OMAP_ECC_BCH16_CODE_HW:</span>
<span class="p_del">-			break;</span>
<span class="p_del">-		default:</span>
<span class="p_del">-			return -EINVAL;</span>
<span class="p_del">-		}</span>
<span class="p_add">+		ret = _omap_calculate_ecc_bch(mtd, dat, ecc_calc, i);</span>
<span class="p_add">+		if (ret)</span>
<span class="p_add">+			return ret;</span>
 
<span class="p_del">-	ecc_calc += eccbytes;</span>
<span class="p_add">+		ecc_calc += eccbytes;</span>
 	}
 
 	return 0;
<span class="p_chunk">@@ -1496,7 +1539,7 @@</span> <span class="p_context"> static int omap_write_page_bch(struct mtd_info *mtd, struct nand_chip *chip,</span>
 	chip-&gt;write_buf(mtd, buf, mtd-&gt;writesize);
 
 	/* Update ecc vector from GPMC result registers */
<span class="p_del">-	chip-&gt;ecc.calculate(mtd, buf, &amp;ecc_calc[0]);</span>
<span class="p_add">+	omap_calculate_ecc_bch_multi(mtd, buf, &amp;ecc_calc[0]);</span>
 
 	ret = mtd_ooblayout_set_eccbytes(mtd, ecc_calc, chip-&gt;oob_poi, 0,
 					 chip-&gt;ecc.total);
<span class="p_chunk">@@ -1508,6 +1551,72 @@</span> <span class="p_context"> static int omap_write_page_bch(struct mtd_info *mtd, struct nand_chip *chip,</span>
 	return 0;
 }
 
<span class="p_add">+/**</span>
<span class="p_add">+ * omap_write_subpage_bch - BCH hardware ECC based subpage write</span>
<span class="p_add">+ * @mtd:	mtd info structure</span>
<span class="p_add">+ * @chip:	nand chip info structure</span>
<span class="p_add">+ * @offset:	column address of subpage within the page</span>
<span class="p_add">+ * @data_len:	data length</span>
<span class="p_add">+ * @buf:	data buffer</span>
<span class="p_add">+ * @oob_required: must write chip-&gt;oob_poi to OOB</span>
<span class="p_add">+ * @page: page number to write</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * OMAP optimized subpage write method.</span>
<span class="p_add">+ */</span>
<span class="p_add">+static int omap_write_subpage_bch(struct mtd_info *mtd,</span>
<span class="p_add">+				  struct nand_chip *chip, u32 offset,</span>
<span class="p_add">+				  u32 data_len, const u8 *buf,</span>
<span class="p_add">+				  int oob_required, int page)</span>
<span class="p_add">+{</span>
<span class="p_add">+	u8 *ecc_calc = chip-&gt;buffers-&gt;ecccalc;</span>
<span class="p_add">+	int ecc_size      = chip-&gt;ecc.size;</span>
<span class="p_add">+	int ecc_bytes     = chip-&gt;ecc.bytes;</span>
<span class="p_add">+	int ecc_steps     = chip-&gt;ecc.steps;</span>
<span class="p_add">+	u32 start_step = offset / ecc_size;</span>
<span class="p_add">+	u32 end_step   = (offset + data_len - 1) / ecc_size;</span>
<span class="p_add">+	int step, ret = 0;</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Write entire page at one go as it would be optimal</span>
<span class="p_add">+	 * as ECC is calculated by hardware.</span>
<span class="p_add">+	 * ECC is calculated for all subpages but we choose</span>
<span class="p_add">+	 * only what we want.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+</span>
<span class="p_add">+	/* Enable GPMC ECC engine */</span>
<span class="p_add">+	chip-&gt;ecc.hwctl(mtd, NAND_ECC_WRITE);</span>
<span class="p_add">+</span>
<span class="p_add">+	/* Write data */</span>
<span class="p_add">+	chip-&gt;write_buf(mtd, buf, mtd-&gt;writesize);</span>
<span class="p_add">+</span>
<span class="p_add">+	for (step = 0; step &lt; ecc_steps; step++) {</span>
<span class="p_add">+		/* mask ECC of un-touched subpages by padding 0xFF */</span>
<span class="p_add">+		if (step &lt; start_step || step &gt; end_step)</span>
<span class="p_add">+			memset(ecc_calc, 0xff, ecc_bytes);</span>
<span class="p_add">+		else</span>
<span class="p_add">+			ret = _omap_calculate_ecc_bch(mtd, buf, ecc_calc, step);</span>
<span class="p_add">+</span>
<span class="p_add">+		if (ret)</span>
<span class="p_add">+			return ret;</span>
<span class="p_add">+</span>
<span class="p_add">+		buf += ecc_size;</span>
<span class="p_add">+		ecc_calc += ecc_bytes;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	/* copy calculated ECC for whole page to chip-&gt;buffer-&gt;oob */</span>
<span class="p_add">+	/* this include masked-value(0xFF) for unwritten subpages */</span>
<span class="p_add">+	ecc_calc = chip-&gt;buffers-&gt;ecccalc;</span>
<span class="p_add">+	ret = mtd_ooblayout_set_eccbytes(mtd, ecc_calc, chip-&gt;oob_poi, 0,</span>
<span class="p_add">+					 chip-&gt;ecc.total);</span>
<span class="p_add">+	if (ret)</span>
<span class="p_add">+		return ret;</span>
<span class="p_add">+</span>
<span class="p_add">+	/* write OOB buffer to NAND device */</span>
<span class="p_add">+	chip-&gt;write_buf(mtd, chip-&gt;oob_poi, mtd-&gt;oobsize);</span>
<span class="p_add">+</span>
<span class="p_add">+	return 0;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 /**
  * omap_read_page_bch - BCH ecc based page read function for entire page
  * @mtd:		mtd info structure
<span class="p_chunk">@@ -1544,7 +1653,7 @@</span> <span class="p_context"> static int omap_read_page_bch(struct mtd_info *mtd, struct nand_chip *chip,</span>
 		       chip-&gt;ecc.total);
 
 	/* Calculate ecc bytes */
<span class="p_del">-	chip-&gt;ecc.calculate(mtd, buf, ecc_calc);</span>
<span class="p_add">+	omap_calculate_ecc_bch_multi(mtd, buf, ecc_calc);</span>
 
 	ret = mtd_ooblayout_get_eccbytes(mtd, ecc_code, chip-&gt;oob_poi, 0,
 					 chip-&gt;ecc.total);
<span class="p_chunk">@@ -2044,7 +2153,7 @@</span> <span class="p_context"> static int omap_nand_probe(struct platform_device *pdev)</span>
 		nand_chip-&gt;ecc.strength		= 4;
 		nand_chip-&gt;ecc.hwctl		= omap_enable_hwecc_bch;
 		nand_chip-&gt;ecc.correct		= nand_bch_correct_data;
<span class="p_del">-		nand_chip-&gt;ecc.calculate	= omap_calculate_ecc_bch;</span>
<span class="p_add">+		nand_chip-&gt;ecc.calculate	= omap_calculate_ecc_bch_sw;</span>
 		mtd_set_ooblayout(mtd, &amp;omap_sw_ooblayout_ops);
 		/* Reserve one byte for the OMAP marker */
 		oobbytes_per_step		= nand_chip-&gt;ecc.bytes + 1;
<span class="p_chunk">@@ -2066,9 +2175,9 @@</span> <span class="p_context"> static int omap_nand_probe(struct platform_device *pdev)</span>
 		nand_chip-&gt;ecc.strength		= 4;
 		nand_chip-&gt;ecc.hwctl		= omap_enable_hwecc_bch;
 		nand_chip-&gt;ecc.correct		= omap_elm_correct_data;
<span class="p_del">-		nand_chip-&gt;ecc.calculate	= omap_calculate_ecc_bch;</span>
 		nand_chip-&gt;ecc.read_page	= omap_read_page_bch;
 		nand_chip-&gt;ecc.write_page	= omap_write_page_bch;
<span class="p_add">+		nand_chip-&gt;ecc.write_subpage	= omap_write_subpage_bch;</span>
 		mtd_set_ooblayout(mtd, &amp;omap_ooblayout_ops);
 		oobbytes_per_step		= nand_chip-&gt;ecc.bytes;
 
<span class="p_chunk">@@ -2087,7 +2196,7 @@</span> <span class="p_context"> static int omap_nand_probe(struct platform_device *pdev)</span>
 		nand_chip-&gt;ecc.strength		= 8;
 		nand_chip-&gt;ecc.hwctl		= omap_enable_hwecc_bch;
 		nand_chip-&gt;ecc.correct		= nand_bch_correct_data;
<span class="p_del">-		nand_chip-&gt;ecc.calculate	= omap_calculate_ecc_bch;</span>
<span class="p_add">+		nand_chip-&gt;ecc.calculate	= omap_calculate_ecc_bch_sw;</span>
 		mtd_set_ooblayout(mtd, &amp;omap_sw_ooblayout_ops);
 		/* Reserve one byte for the OMAP marker */
 		oobbytes_per_step		= nand_chip-&gt;ecc.bytes + 1;
<span class="p_chunk">@@ -2109,9 +2218,9 @@</span> <span class="p_context"> static int omap_nand_probe(struct platform_device *pdev)</span>
 		nand_chip-&gt;ecc.strength		= 8;
 		nand_chip-&gt;ecc.hwctl		= omap_enable_hwecc_bch;
 		nand_chip-&gt;ecc.correct		= omap_elm_correct_data;
<span class="p_del">-		nand_chip-&gt;ecc.calculate	= omap_calculate_ecc_bch;</span>
 		nand_chip-&gt;ecc.read_page	= omap_read_page_bch;
 		nand_chip-&gt;ecc.write_page	= omap_write_page_bch;
<span class="p_add">+		nand_chip-&gt;ecc.write_subpage	= omap_write_subpage_bch;</span>
 		mtd_set_ooblayout(mtd, &amp;omap_ooblayout_ops);
 		oobbytes_per_step		= nand_chip-&gt;ecc.bytes;
 
<span class="p_chunk">@@ -2131,9 +2240,9 @@</span> <span class="p_context"> static int omap_nand_probe(struct platform_device *pdev)</span>
 		nand_chip-&gt;ecc.strength		= 16;
 		nand_chip-&gt;ecc.hwctl		= omap_enable_hwecc_bch;
 		nand_chip-&gt;ecc.correct		= omap_elm_correct_data;
<span class="p_del">-		nand_chip-&gt;ecc.calculate	= omap_calculate_ecc_bch;</span>
 		nand_chip-&gt;ecc.read_page	= omap_read_page_bch;
 		nand_chip-&gt;ecc.write_page	= omap_write_page_bch;
<span class="p_add">+		nand_chip-&gt;ecc.write_subpage	= omap_write_subpage_bch;</span>
 		mtd_set_ooblayout(mtd, &amp;omap_ooblayout_ops);
 		oobbytes_per_step		= nand_chip-&gt;ecc.bytes;
 
<span class="p_header">diff --git a/drivers/mtd/spi-nor/intel-spi.c b/drivers/mtd/spi-nor/intel-spi.c</span>
<span class="p_header">index 8a596bfeddff..7802ac3ba934 100644</span>
<span class="p_header">--- a/drivers/mtd/spi-nor/intel-spi.c</span>
<span class="p_header">+++ b/drivers/mtd/spi-nor/intel-spi.c</span>
<span class="p_chunk">@@ -422,7 +422,7 @@</span> <span class="p_context"> static int intel_spi_sw_cycle(struct intel_spi *ispi, u8 opcode, u8 *buf,</span>
 	if (ret &lt; 0)
 		return ret;
 
<span class="p_del">-	val = (len &lt;&lt; SSFSTS_CTL_DBC_SHIFT) | SSFSTS_CTL_DS;</span>
<span class="p_add">+	val = ((len - 1) &lt;&lt; SSFSTS_CTL_DBC_SHIFT) | SSFSTS_CTL_DS;</span>
 	val |= ret &lt;&lt; SSFSTS_CTL_COP_SHIFT;
 	val |= SSFSTS_CTL_FCERR | SSFSTS_CTL_FDONE;
 	val |= SSFSTS_CTL_SCGO;
<span class="p_chunk">@@ -432,7 +432,7 @@</span> <span class="p_context"> static int intel_spi_sw_cycle(struct intel_spi *ispi, u8 opcode, u8 *buf,</span>
 	if (ret)
 		return ret;
 
<span class="p_del">-	status = readl(ispi-&gt;base + SSFSTS_CTL);</span>
<span class="p_add">+	status = readl(ispi-&gt;sregs + SSFSTS_CTL);</span>
 	if (status &amp; SSFSTS_CTL_FCERR)
 		return -EIO;
 	else if (status &amp; SSFSTS_CTL_AEL)
<span class="p_header">diff --git a/drivers/net/ethernet/intel/e1000e/defines.h b/drivers/net/ethernet/intel/e1000e/defines.h</span>
<span class="p_header">index 0641c0098738..afb7ebe20b24 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/intel/e1000e/defines.h</span>
<span class="p_header">+++ b/drivers/net/ethernet/intel/e1000e/defines.h</span>
<span class="p_chunk">@@ -398,6 +398,7 @@</span> <span class="p_context"></span>
 #define E1000_ICR_LSC           0x00000004 /* Link Status Change */
 #define E1000_ICR_RXSEQ         0x00000008 /* Rx sequence error */
 #define E1000_ICR_RXDMT0        0x00000010 /* Rx desc min. threshold (0) */
<span class="p_add">+#define E1000_ICR_RXO           0x00000040 /* Receiver Overrun */</span>
 #define E1000_ICR_RXT0          0x00000080 /* Rx timer intr (ring 0) */
 #define E1000_ICR_ECCER         0x00400000 /* Uncorrectable ECC Error */
 /* If this bit asserted, the driver should claim the interrupt */
<span class="p_header">diff --git a/drivers/net/ethernet/intel/e1000e/mac.c b/drivers/net/ethernet/intel/e1000e/mac.c</span>
<span class="p_header">index b322011ec282..f457c5703d0c 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/intel/e1000e/mac.c</span>
<span class="p_header">+++ b/drivers/net/ethernet/intel/e1000e/mac.c</span>
<span class="p_chunk">@@ -410,6 +410,9 @@</span> <span class="p_context"> void e1000e_clear_hw_cntrs_base(struct e1000_hw *hw)</span>
  *  Checks to see of the link status of the hardware has changed.  If a
  *  change in link status has been detected, then we read the PHY registers
  *  to get the current speed/duplex if link exists.
<span class="p_add">+ *</span>
<span class="p_add">+ *  Returns a negative error code (-E1000_ERR_*) or 0 (link down) or 1 (link</span>
<span class="p_add">+ *  up).</span>
  **/
 s32 e1000e_check_for_copper_link(struct e1000_hw *hw)
 {
<span class="p_chunk">@@ -423,7 +426,7 @@</span> <span class="p_context"> s32 e1000e_check_for_copper_link(struct e1000_hw *hw)</span>
 	 * Change or Rx Sequence Error interrupt.
 	 */
 	if (!mac-&gt;get_link_status)
<span class="p_del">-		return 0;</span>
<span class="p_add">+		return 1;</span>
 
 	/* First we want to see if the MII Status Register reports
 	 * link.  If so, then we want to get the current speed/duplex
<span class="p_chunk">@@ -461,10 +464,12 @@</span> <span class="p_context"> s32 e1000e_check_for_copper_link(struct e1000_hw *hw)</span>
 	 * different link partner.
 	 */
 	ret_val = e1000e_config_fc_after_link_up(hw);
<span class="p_del">-	if (ret_val)</span>
<span class="p_add">+	if (ret_val) {</span>
 		e_dbg(&quot;Error configuring flow control\n&quot;);
<span class="p_add">+		return ret_val;</span>
<span class="p_add">+	}</span>
 
<span class="p_del">-	return ret_val;</span>
<span class="p_add">+	return 1;</span>
 }
 
 /**
<span class="p_header">diff --git a/drivers/net/ethernet/intel/e1000e/netdev.c b/drivers/net/ethernet/intel/e1000e/netdev.c</span>
<span class="p_header">index 327dfe5bedc0..c38b00c90f48 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/intel/e1000e/netdev.c</span>
<span class="p_header">+++ b/drivers/net/ethernet/intel/e1000e/netdev.c</span>
<span class="p_chunk">@@ -1910,14 +1910,30 @@</span> <span class="p_context"> static irqreturn_t e1000_msix_other(int __always_unused irq, void *data)</span>
 	struct net_device *netdev = data;
 	struct e1000_adapter *adapter = netdev_priv(netdev);
 	struct e1000_hw *hw = &amp;adapter-&gt;hw;
<span class="p_add">+	u32 icr;</span>
<span class="p_add">+	bool enable = true;</span>
<span class="p_add">+</span>
<span class="p_add">+	icr = er32(ICR);</span>
<span class="p_add">+	if (icr &amp; E1000_ICR_RXO) {</span>
<span class="p_add">+		ew32(ICR, E1000_ICR_RXO);</span>
<span class="p_add">+		enable = false;</span>
<span class="p_add">+		/* napi poll will re-enable Other, make sure it runs */</span>
<span class="p_add">+		if (napi_schedule_prep(&amp;adapter-&gt;napi)) {</span>
<span class="p_add">+			adapter-&gt;total_rx_bytes = 0;</span>
<span class="p_add">+			adapter-&gt;total_rx_packets = 0;</span>
<span class="p_add">+			__napi_schedule(&amp;adapter-&gt;napi);</span>
<span class="p_add">+		}</span>
<span class="p_add">+	}</span>
<span class="p_add">+	if (icr &amp; E1000_ICR_LSC) {</span>
<span class="p_add">+		ew32(ICR, E1000_ICR_LSC);</span>
<span class="p_add">+		hw-&gt;mac.get_link_status = true;</span>
<span class="p_add">+		/* guard against interrupt when we&#39;re going down */</span>
<span class="p_add">+		if (!test_bit(__E1000_DOWN, &amp;adapter-&gt;state))</span>
<span class="p_add">+			mod_timer(&amp;adapter-&gt;watchdog_timer, jiffies + 1);</span>
<span class="p_add">+	}</span>
 
<span class="p_del">-	hw-&gt;mac.get_link_status = true;</span>
<span class="p_del">-</span>
<span class="p_del">-	/* guard against interrupt when we&#39;re going down */</span>
<span class="p_del">-	if (!test_bit(__E1000_DOWN, &amp;adapter-&gt;state)) {</span>
<span class="p_del">-		mod_timer(&amp;adapter-&gt;watchdog_timer, jiffies + 1);</span>
<span class="p_add">+	if (enable &amp;&amp; !test_bit(__E1000_DOWN, &amp;adapter-&gt;state))</span>
 		ew32(IMS, E1000_IMS_OTHER);
<span class="p_del">-	}</span>
 
 	return IRQ_HANDLED;
 }
<span class="p_chunk">@@ -2687,7 +2703,8 @@</span> <span class="p_context"> static int e1000e_poll(struct napi_struct *napi, int weight)</span>
 		napi_complete_done(napi, work_done);
 		if (!test_bit(__E1000_DOWN, &amp;adapter-&gt;state)) {
 			if (adapter-&gt;msix_entries)
<span class="p_del">-				ew32(IMS, adapter-&gt;rx_ring-&gt;ims_val);</span>
<span class="p_add">+				ew32(IMS, adapter-&gt;rx_ring-&gt;ims_val |</span>
<span class="p_add">+				     E1000_IMS_OTHER);</span>
 			else
 				e1000_irq_enable(adapter);
 		}
<span class="p_chunk">@@ -3004,8 +3021,8 @@</span> <span class="p_context"> static void e1000_configure_tx(struct e1000_adapter *adapter)</span>
 
 	hw-&gt;mac.ops.config_collision_dist(hw);
 
<span class="p_del">-	/* SPT and CNP Si errata workaround to avoid data corruption */</span>
<span class="p_del">-	if (hw-&gt;mac.type &gt;= e1000_pch_spt) {</span>
<span class="p_add">+	/* SPT and KBL Si errata workaround to avoid data corruption */</span>
<span class="p_add">+	if (hw-&gt;mac.type == e1000_pch_spt) {</span>
 		u32 reg_val;
 
 		reg_val = er32(IOSFPC);
<span class="p_chunk">@@ -3013,7 +3030,9 @@</span> <span class="p_context"> static void e1000_configure_tx(struct e1000_adapter *adapter)</span>
 		ew32(IOSFPC, reg_val);
 
 		reg_val = er32(TARC(0));
<span class="p_del">-		reg_val |= E1000_TARC0_CB_MULTIQ_3_REQ;</span>
<span class="p_add">+		/* SPT and KBL Si errata workaround to avoid Tx hang */</span>
<span class="p_add">+		reg_val &amp;= ~BIT(28);</span>
<span class="p_add">+		reg_val |= BIT(29);</span>
 		ew32(TARC(0), reg_val);
 	}
 }
<span class="p_chunk">@@ -4204,7 +4223,7 @@</span> <span class="p_context"> static void e1000e_trigger_lsc(struct e1000_adapter *adapter)</span>
 	struct e1000_hw *hw = &amp;adapter-&gt;hw;
 
 	if (adapter-&gt;msix_entries)
<span class="p_del">-		ew32(ICS, E1000_ICS_OTHER);</span>
<span class="p_add">+		ew32(ICS, E1000_ICS_LSC | E1000_ICS_OTHER);</span>
 	else
 		ew32(ICS, E1000_ICS_LSC);
 }
<span class="p_chunk">@@ -5081,7 +5100,7 @@</span> <span class="p_context"> static bool e1000e_has_link(struct e1000_adapter *adapter)</span>
 	case e1000_media_type_copper:
 		if (hw-&gt;mac.get_link_status) {
 			ret_val = hw-&gt;mac.ops.check_for_link(hw);
<span class="p_del">-			link_active = !hw-&gt;mac.get_link_status;</span>
<span class="p_add">+			link_active = ret_val &gt; 0;</span>
 		} else {
 			link_active = true;
 		}
<span class="p_chunk">@@ -5099,7 +5118,7 @@</span> <span class="p_context"> static bool e1000e_has_link(struct e1000_adapter *adapter)</span>
 		break;
 	}
 
<span class="p_del">-	if ((ret_val == E1000_ERR_PHY) &amp;&amp; (hw-&gt;phy.type == e1000_phy_igp_3) &amp;&amp;</span>
<span class="p_add">+	if ((ret_val == -E1000_ERR_PHY) &amp;&amp; (hw-&gt;phy.type == e1000_phy_igp_3) &amp;&amp;</span>
 	    (er32(CTRL) &amp; E1000_PHY_CTRL_GBE_DISABLE)) {
 		/* See e1000_kmrn_lock_loss_workaround_ich8lan() */
 		e_info(&quot;Gigabit has been disabled, downgrading speed\n&quot;);
<span class="p_header">diff --git a/drivers/net/ethernet/intel/e1000e/phy.c b/drivers/net/ethernet/intel/e1000e/phy.c</span>
<span class="p_header">index d78d47b41a71..86ff0969efb6 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/intel/e1000e/phy.c</span>
<span class="p_header">+++ b/drivers/net/ethernet/intel/e1000e/phy.c</span>
<span class="p_chunk">@@ -1744,6 +1744,7 @@</span> <span class="p_context"> s32 e1000e_phy_has_link_generic(struct e1000_hw *hw, u32 iterations,</span>
 	s32 ret_val = 0;
 	u16 i, phy_status;
 
<span class="p_add">+	*success = false;</span>
 	for (i = 0; i &lt; iterations; i++) {
 		/* Some PHYs require the MII_BMSR register to be read
 		 * twice due to the link bit being sticky.  No harm doing
<span class="p_chunk">@@ -1763,16 +1764,16 @@</span> <span class="p_context"> s32 e1000e_phy_has_link_generic(struct e1000_hw *hw, u32 iterations,</span>
 		ret_val = e1e_rphy(hw, MII_BMSR, &amp;phy_status);
 		if (ret_val)
 			break;
<span class="p_del">-		if (phy_status &amp; BMSR_LSTATUS)</span>
<span class="p_add">+		if (phy_status &amp; BMSR_LSTATUS) {</span>
<span class="p_add">+			*success = true;</span>
 			break;
<span class="p_add">+		}</span>
 		if (usec_interval &gt;= 1000)
 			msleep(usec_interval / 1000);
 		else
 			udelay(usec_interval);
 	}
 
<span class="p_del">-	*success = (i &lt; iterations);</span>
<span class="p_del">-</span>
 	return ret_val;
 }
 
<span class="p_header">diff --git a/drivers/net/ethernet/intel/fm10k/fm10k_main.c b/drivers/net/ethernet/intel/fm10k/fm10k_main.c</span>
<span class="p_header">index 9dffaba85ae6..103c0a742d03 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/intel/fm10k/fm10k_main.c</span>
<span class="p_header">+++ b/drivers/net/ethernet/intel/fm10k/fm10k_main.c</span>
<span class="p_chunk">@@ -1229,7 +1229,7 @@</span> <span class="p_context"> static bool fm10k_clean_tx_irq(struct fm10k_q_vector *q_vector,</span>
 			break;
 
 		/* prevent any other reads prior to eop_desc */
<span class="p_del">-		read_barrier_depends();</span>
<span class="p_add">+		smp_rmb();</span>
 
 		/* if DD is not set pending work has not been completed */
 		if (!(eop_desc-&gt;flags &amp; FM10K_TXD_FLAG_DONE))
<span class="p_header">diff --git a/drivers/net/ethernet/intel/i40e/i40e_main.c b/drivers/net/ethernet/intel/i40e/i40e_main.c</span>
<span class="p_header">index 6498da8806cb..ea20aacd5e1d 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/intel/i40e/i40e_main.c</span>
<span class="p_header">+++ b/drivers/net/ethernet/intel/i40e/i40e_main.c</span>
<span class="p_chunk">@@ -3760,7 +3760,7 @@</span> <span class="p_context"> static bool i40e_clean_fdir_tx_irq(struct i40e_ring *tx_ring, int budget)</span>
 			break;
 
 		/* prevent any other reads prior to eop_desc */
<span class="p_del">-		read_barrier_depends();</span>
<span class="p_add">+		smp_rmb();</span>
 
 		/* if the descriptor isn&#39;t done, no work yet to do */
 		if (!(eop_desc-&gt;cmd_type_offset_bsz &amp;
<span class="p_header">diff --git a/drivers/net/ethernet/intel/i40e/i40e_txrx.c b/drivers/net/ethernet/intel/i40e/i40e_txrx.c</span>
<span class="p_header">index 120c68f78951..3c07ff171ddc 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/intel/i40e/i40e_txrx.c</span>
<span class="p_header">+++ b/drivers/net/ethernet/intel/i40e/i40e_txrx.c</span>
<span class="p_chunk">@@ -759,7 +759,7 @@</span> <span class="p_context"> static bool i40e_clean_tx_irq(struct i40e_vsi *vsi,</span>
 			break;
 
 		/* prevent any other reads prior to eop_desc */
<span class="p_del">-		read_barrier_depends();</span>
<span class="p_add">+		smp_rmb();</span>
 
 		i40e_trace(clean_tx_irq, tx_ring, tx_desc, tx_buf);
 		/* we have caught up to head, no work left to do */
<span class="p_header">diff --git a/drivers/net/ethernet/intel/i40evf/i40e_txrx.c b/drivers/net/ethernet/intel/i40evf/i40e_txrx.c</span>
<span class="p_header">index c32c62462c84..07a4e6e13925 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/intel/i40evf/i40e_txrx.c</span>
<span class="p_header">+++ b/drivers/net/ethernet/intel/i40evf/i40e_txrx.c</span>
<span class="p_chunk">@@ -179,7 +179,7 @@</span> <span class="p_context"> static bool i40e_clean_tx_irq(struct i40e_vsi *vsi,</span>
 			break;
 
 		/* prevent any other reads prior to eop_desc */
<span class="p_del">-		read_barrier_depends();</span>
<span class="p_add">+		smp_rmb();</span>
 
 		i40e_trace(clean_tx_irq, tx_ring, tx_desc, tx_buf);
 		/* if the descriptor isn&#39;t done, no work yet to do */
<span class="p_header">diff --git a/drivers/net/ethernet/intel/igb/igb_main.c b/drivers/net/ethernet/intel/igb/igb_main.c</span>
<span class="p_header">index ea69af267d63..b0031c5ff767 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/intel/igb/igb_main.c</span>
<span class="p_header">+++ b/drivers/net/ethernet/intel/igb/igb_main.c</span>
<span class="p_chunk">@@ -6970,7 +6970,7 @@</span> <span class="p_context"> static bool igb_clean_tx_irq(struct igb_q_vector *q_vector, int napi_budget)</span>
 			break;
 
 		/* prevent any other reads prior to eop_desc */
<span class="p_del">-		read_barrier_depends();</span>
<span class="p_add">+		smp_rmb();</span>
 
 		/* if DD is not set pending work has not been completed */
 		if (!(eop_desc-&gt;wb.status &amp; cpu_to_le32(E1000_TXD_STAT_DD)))
<span class="p_header">diff --git a/drivers/net/ethernet/intel/igbvf/netdev.c b/drivers/net/ethernet/intel/igbvf/netdev.c</span>
<span class="p_header">index 1ed556911b14..6f5888bd9194 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/intel/igbvf/netdev.c</span>
<span class="p_header">+++ b/drivers/net/ethernet/intel/igbvf/netdev.c</span>
<span class="p_chunk">@@ -810,7 +810,7 @@</span> <span class="p_context"> static bool igbvf_clean_tx_irq(struct igbvf_ring *tx_ring)</span>
 			break;
 
 		/* prevent any other reads prior to eop_desc */
<span class="p_del">-		read_barrier_depends();</span>
<span class="p_add">+		smp_rmb();</span>
 
 		/* if DD is not set pending work has not been completed */
 		if (!(eop_desc-&gt;wb.status &amp; cpu_to_le32(E1000_TXD_STAT_DD)))
<span class="p_header">diff --git a/drivers/net/ethernet/intel/ixgbe/ixgbe_main.c b/drivers/net/ethernet/intel/ixgbe/ixgbe_main.c</span>
<span class="p_header">index 6d5f31e94358..879a9c4cef59 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/intel/ixgbe/ixgbe_main.c</span>
<span class="p_header">+++ b/drivers/net/ethernet/intel/ixgbe/ixgbe_main.c</span>
<span class="p_chunk">@@ -1192,7 +1192,7 @@</span> <span class="p_context"> static bool ixgbe_clean_tx_irq(struct ixgbe_q_vector *q_vector,</span>
 			break;
 
 		/* prevent any other reads prior to eop_desc */
<span class="p_del">-		read_barrier_depends();</span>
<span class="p_add">+		smp_rmb();</span>
 
 		/* if DD is not set pending work has not been completed */
 		if (!(eop_desc-&gt;wb.status &amp; cpu_to_le32(IXGBE_TXD_STAT_DD)))
<span class="p_header">diff --git a/drivers/net/ethernet/intel/ixgbevf/ixgbevf_main.c b/drivers/net/ethernet/intel/ixgbevf/ixgbevf_main.c</span>
<span class="p_header">index 032f8ac06357..90ecc4b06462 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/intel/ixgbevf/ixgbevf_main.c</span>
<span class="p_header">+++ b/drivers/net/ethernet/intel/ixgbevf/ixgbevf_main.c</span>
<span class="p_chunk">@@ -326,7 +326,7 @@</span> <span class="p_context"> static bool ixgbevf_clean_tx_irq(struct ixgbevf_q_vector *q_vector,</span>
 			break;
 
 		/* prevent any other reads prior to eop_desc */
<span class="p_del">-		read_barrier_depends();</span>
<span class="p_add">+		smp_rmb();</span>
 
 		/* if DD is not set pending work has not been completed */
 		if (!(eop_desc-&gt;wb.status &amp; cpu_to_le32(IXGBE_TXD_STAT_DD)))
<span class="p_header">diff --git a/drivers/net/ethernet/marvell/mvneta.c b/drivers/net/ethernet/marvell/mvneta.c</span>
<span class="p_header">index 64a04975bcf8..bc93b69cfd1e 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/marvell/mvneta.c</span>
<span class="p_header">+++ b/drivers/net/ethernet/marvell/mvneta.c</span>
<span class="p_chunk">@@ -816,11 +816,14 @@</span> <span class="p_context"> static void mvneta_txq_pend_desc_add(struct mvneta_port *pp,</span>
 {
 	u32 val;
 
<span class="p_del">-	/* Only 255 descriptors can be added at once ; Assume caller</span>
<span class="p_del">-	 * process TX desriptors in quanta less than 256</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	val = pend_desc + txq-&gt;pending;</span>
<span class="p_del">-	mvreg_write(pp, MVNETA_TXQ_UPDATE_REG(txq-&gt;id), val);</span>
<span class="p_add">+	pend_desc += txq-&gt;pending;</span>
<span class="p_add">+</span>
<span class="p_add">+	/* Only 255 Tx descriptors can be added at once */</span>
<span class="p_add">+	do {</span>
<span class="p_add">+		val = min(pend_desc, 255);</span>
<span class="p_add">+		mvreg_write(pp, MVNETA_TXQ_UPDATE_REG(txq-&gt;id), val);</span>
<span class="p_add">+		pend_desc -= val;</span>
<span class="p_add">+	} while (pend_desc &gt; 0);</span>
 	txq-&gt;pending = 0;
 }
 
<span class="p_header">diff --git a/drivers/net/wireless/intel/iwlwifi/cfg/9000.c b/drivers/net/wireless/intel/iwlwifi/cfg/9000.c</span>
<span class="p_header">index e8b5ff42f5a8..c8e7b54a538a 100644</span>
<span class="p_header">--- a/drivers/net/wireless/intel/iwlwifi/cfg/9000.c</span>
<span class="p_header">+++ b/drivers/net/wireless/intel/iwlwifi/cfg/9000.c</span>
<span class="p_chunk">@@ -72,18 +72,21 @@</span> <span class="p_context"></span>
 #define IWL9000_SMEM_OFFSET		0x400000
 #define IWL9000_SMEM_LEN		0x68000
 
<span class="p_del">-#define  IWL9000_FW_PRE &quot;iwlwifi-9000-pu-a0-jf-a0-&quot;</span>
<span class="p_add">+#define  IWL9000A_FW_PRE &quot;iwlwifi-9000-pu-a0-jf-a0-&quot;</span>
<span class="p_add">+#define  IWL9000B_FW_PRE &quot;iwlwifi-9000-pu-b0-jf-b0-&quot;</span>
 #define  IWL9000RFB_FW_PRE &quot;iwlwifi-9000-pu-a0-jf-b0-&quot;
 #define  IWL9260A_FW_PRE &quot;iwlwifi-9260-th-a0-jf-a0-&quot;
 #define  IWL9260B_FW_PRE &quot;iwlwifi-9260-th-b0-jf-b0-&quot;
<span class="p_del">-#define IWL9000_MODULE_FIRMWARE(api) \</span>
<span class="p_del">-	IWL9000_FW_PRE &quot;-&quot; __stringify(api) &quot;.ucode&quot;</span>
<span class="p_add">+#define IWL9000A_MODULE_FIRMWARE(api) \</span>
<span class="p_add">+	IWL9000A_FW_PRE __stringify(api) &quot;.ucode&quot;</span>
<span class="p_add">+#define IWL9000B_MODULE_FIRMWARE(api) \</span>
<span class="p_add">+	IWL9000B_FW_PRE __stringify(api) &quot;.ucode&quot;</span>
 #define IWL9000RFB_MODULE_FIRMWARE(api) \
<span class="p_del">-	IWL9000RFB_FW_PRE &quot;-&quot; __stringify(api) &quot;.ucode&quot;</span>
<span class="p_add">+	IWL9000RFB_FW_PRE __stringify(api) &quot;.ucode&quot;</span>
 #define IWL9260A_MODULE_FIRMWARE(api) \
<span class="p_del">-	IWL9260A_FW_PRE &quot;-&quot; __stringify(api) &quot;.ucode&quot;</span>
<span class="p_add">+	IWL9260A_FW_PRE __stringify(api) &quot;.ucode&quot;</span>
 #define IWL9260B_MODULE_FIRMWARE(api) \
<span class="p_del">-	IWL9260B_FW_PRE &quot;-&quot; __stringify(api) &quot;.ucode&quot;</span>
<span class="p_add">+	IWL9260B_FW_PRE __stringify(api) &quot;.ucode&quot;</span>
 
 #define NVM_HW_SECTION_NUM_FAMILY_9000		10
 
<span class="p_chunk">@@ -193,7 +196,48 @@</span> <span class="p_context"> const struct iwl_cfg iwl9460_2ac_cfg = {</span>
 	.nvm_ver = IWL9000_NVM_VERSION,
 	.nvm_calib_ver = IWL9000_TX_POWER_VERSION,
 	.max_ht_ampdu_exponent = IEEE80211_HT_MAX_AMPDU_64K,
<span class="p_add">+};</span>
<span class="p_add">+</span>
<span class="p_add">+const struct iwl_cfg iwl9460_2ac_cfg_soc = {</span>
<span class="p_add">+	.name = &quot;Intel(R) Dual Band Wireless AC 9460&quot;,</span>
<span class="p_add">+	.fw_name_pre = IWL9000A_FW_PRE,</span>
<span class="p_add">+	.fw_name_pre_b_or_c_step = IWL9000B_FW_PRE,</span>
<span class="p_add">+	.fw_name_pre_rf_next_step = IWL9000RFB_FW_PRE,</span>
<span class="p_add">+	IWL_DEVICE_9000,</span>
<span class="p_add">+	.ht_params = &amp;iwl9000_ht_params,</span>
<span class="p_add">+	.nvm_ver = IWL9000_NVM_VERSION,</span>
<span class="p_add">+	.nvm_calib_ver = IWL9000_TX_POWER_VERSION,</span>
<span class="p_add">+	.max_ht_ampdu_exponent = IEEE80211_HT_MAX_AMPDU_64K,</span>
 	.integrated = true,
<span class="p_add">+	.soc_latency = 5000,</span>
<span class="p_add">+};</span>
<span class="p_add">+</span>
<span class="p_add">+const struct iwl_cfg iwl9461_2ac_cfg_soc = {</span>
<span class="p_add">+		.name = &quot;Intel(R) Dual Band Wireless AC 9461&quot;,</span>
<span class="p_add">+		.fw_name_pre = IWL9000A_FW_PRE,</span>
<span class="p_add">+		.fw_name_pre_b_or_c_step = IWL9000B_FW_PRE,</span>
<span class="p_add">+		.fw_name_pre_rf_next_step = IWL9000RFB_FW_PRE,</span>
<span class="p_add">+		IWL_DEVICE_9000,</span>
<span class="p_add">+		.ht_params = &amp;iwl9000_ht_params,</span>
<span class="p_add">+		.nvm_ver = IWL9000_NVM_VERSION,</span>
<span class="p_add">+		.nvm_calib_ver = IWL9000_TX_POWER_VERSION,</span>
<span class="p_add">+		.max_ht_ampdu_exponent = IEEE80211_HT_MAX_AMPDU_64K,</span>
<span class="p_add">+		.integrated = true,</span>
<span class="p_add">+		.soc_latency = 5000,</span>
<span class="p_add">+};</span>
<span class="p_add">+</span>
<span class="p_add">+const struct iwl_cfg iwl9462_2ac_cfg_soc = {</span>
<span class="p_add">+		.name = &quot;Intel(R) Dual Band Wireless AC 9462&quot;,</span>
<span class="p_add">+		.fw_name_pre = IWL9000A_FW_PRE,</span>
<span class="p_add">+		.fw_name_pre_b_or_c_step = IWL9000B_FW_PRE,</span>
<span class="p_add">+		.fw_name_pre_rf_next_step = IWL9000RFB_FW_PRE,</span>
<span class="p_add">+		IWL_DEVICE_9000,</span>
<span class="p_add">+		.ht_params = &amp;iwl9000_ht_params,</span>
<span class="p_add">+		.nvm_ver = IWL9000_NVM_VERSION,</span>
<span class="p_add">+		.nvm_calib_ver = IWL9000_TX_POWER_VERSION,</span>
<span class="p_add">+		.max_ht_ampdu_exponent = IEEE80211_HT_MAX_AMPDU_64K,</span>
<span class="p_add">+		.integrated = true,</span>
<span class="p_add">+		.soc_latency = 5000,</span>
 };
 
 const struct iwl_cfg iwl9560_2ac_cfg = {
<span class="p_chunk">@@ -205,10 +249,23 @@</span> <span class="p_context"> const struct iwl_cfg iwl9560_2ac_cfg = {</span>
 	.nvm_ver = IWL9000_NVM_VERSION,
 	.nvm_calib_ver = IWL9000_TX_POWER_VERSION,
 	.max_ht_ampdu_exponent = IEEE80211_HT_MAX_AMPDU_64K,
<span class="p_del">-	.integrated = true,</span>
 };
 
<span class="p_del">-MODULE_FIRMWARE(IWL9000_MODULE_FIRMWARE(IWL9000_UCODE_API_MAX));</span>
<span class="p_add">+const struct iwl_cfg iwl9560_2ac_cfg_soc = {</span>
<span class="p_add">+	.name = &quot;Intel(R) Dual Band Wireless AC 9560&quot;,</span>
<span class="p_add">+	.fw_name_pre = IWL9000A_FW_PRE,</span>
<span class="p_add">+	.fw_name_pre_b_or_c_step = IWL9000B_FW_PRE,</span>
<span class="p_add">+	.fw_name_pre_rf_next_step = IWL9000RFB_FW_PRE,</span>
<span class="p_add">+	IWL_DEVICE_9000,</span>
<span class="p_add">+	.ht_params = &amp;iwl9000_ht_params,</span>
<span class="p_add">+	.nvm_ver = IWL9000_NVM_VERSION,</span>
<span class="p_add">+	.nvm_calib_ver = IWL9000_TX_POWER_VERSION,</span>
<span class="p_add">+	.max_ht_ampdu_exponent = IEEE80211_HT_MAX_AMPDU_64K,</span>
<span class="p_add">+	.integrated = true,</span>
<span class="p_add">+	.soc_latency = 5000,</span>
<span class="p_add">+};</span>
<span class="p_add">+MODULE_FIRMWARE(IWL9000A_MODULE_FIRMWARE(IWL9000_UCODE_API_MAX));</span>
<span class="p_add">+MODULE_FIRMWARE(IWL9000B_MODULE_FIRMWARE(IWL9000_UCODE_API_MAX));</span>
 MODULE_FIRMWARE(IWL9000RFB_MODULE_FIRMWARE(IWL9000_UCODE_API_MAX));
 MODULE_FIRMWARE(IWL9260A_MODULE_FIRMWARE(IWL9000_UCODE_API_MAX));
 MODULE_FIRMWARE(IWL9260B_MODULE_FIRMWARE(IWL9000_UCODE_API_MAX));
<span class="p_header">diff --git a/drivers/net/wireless/intel/iwlwifi/cfg/a000.c b/drivers/net/wireless/intel/iwlwifi/cfg/a000.c</span>
<span class="p_header">index a440140ed8dd..7eade165b747 100644</span>
<span class="p_header">--- a/drivers/net/wireless/intel/iwlwifi/cfg/a000.c</span>
<span class="p_header">+++ b/drivers/net/wireless/intel/iwlwifi/cfg/a000.c</span>
<span class="p_chunk">@@ -80,15 +80,15 @@</span> <span class="p_context"></span>
 #define IWL_A000_HR_A0_FW_PRE	&quot;iwlwifi-QuQnj-a0-hr-a0-&quot;
 
 #define IWL_A000_HR_MODULE_FIRMWARE(api) \
<span class="p_del">-	IWL_A000_HR_FW_PRE &quot;-&quot; __stringify(api) &quot;.ucode&quot;</span>
<span class="p_add">+	IWL_A000_HR_FW_PRE __stringify(api) &quot;.ucode&quot;</span>
 #define IWL_A000_JF_MODULE_FIRMWARE(api) \
<span class="p_del">-	IWL_A000_JF_FW_PRE &quot;-&quot; __stringify(api) &quot;.ucode&quot;</span>
<span class="p_add">+	IWL_A000_JF_FW_PRE __stringify(api) &quot;.ucode&quot;</span>
 #define IWL_A000_HR_F0_QNJ_MODULE_FIRMWARE(api) \
<span class="p_del">-	IWL_A000_HR_F0_FW_PRE &quot;-&quot; __stringify(api) &quot;.ucode&quot;</span>
<span class="p_add">+	IWL_A000_HR_F0_FW_PRE __stringify(api) &quot;.ucode&quot;</span>
 #define IWL_A000_JF_B0_QNJ_MODULE_FIRMWARE(api) \
<span class="p_del">-	IWL_A000_JF_B0_FW_PRE &quot;-&quot; __stringify(api) &quot;.ucode&quot;</span>
<span class="p_add">+	IWL_A000_JF_B0_FW_PRE __stringify(api) &quot;.ucode&quot;</span>
 #define IWL_A000_HR_A0_QNJ_MODULE_FIRMWARE(api) \
<span class="p_del">-	IWL_A000_HR_A0_FW_PRE &quot;-&quot; __stringify(api) &quot;.ucode&quot;</span>
<span class="p_add">+	IWL_A000_HR_A0_FW_PRE __stringify(api) &quot;.ucode&quot;</span>
 
 #define NVM_HW_SECTION_NUM_FAMILY_A000		10
 
<span class="p_header">diff --git a/drivers/net/wireless/intel/iwlwifi/fw/api/scan.h b/drivers/net/wireless/intel/iwlwifi/fw/api/scan.h</span>
<span class="p_header">index 5a40092febfb..3bfc657f6b42 100644</span>
<span class="p_header">--- a/drivers/net/wireless/intel/iwlwifi/fw/api/scan.h</span>
<span class="p_header">+++ b/drivers/net/wireless/intel/iwlwifi/fw/api/scan.h</span>
<span class="p_chunk">@@ -531,6 +531,8 @@</span> <span class="p_context"> struct iwl_scan_config_v1 {</span>
 } __packed; /* SCAN_CONFIG_DB_CMD_API_S */
 
 #define SCAN_TWO_LMACS 2
<span class="p_add">+#define SCAN_LB_LMAC_IDX 0</span>
<span class="p_add">+#define SCAN_HB_LMAC_IDX 1</span>
 
 struct iwl_scan_config {
 	__le32 flags;
<span class="p_chunk">@@ -578,6 +580,7 @@</span> <span class="p_context"> enum iwl_umac_scan_general_flags {</span>
 	IWL_UMAC_SCAN_GEN_FLAGS_MATCH			= BIT(9),
 	IWL_UMAC_SCAN_GEN_FLAGS_EXTENDED_DWELL		= BIT(10),
 	IWL_UMAC_SCAN_GEN_FLAGS_LMAC2_FRAGMENTED	= BIT(11),
<span class="p_add">+	IWL_UMAC_SCAN_GEN_FLAGS_ADAPTIVE_DWELL		= BIT(13),</span>
 };
 
 /**
<span class="p_chunk">@@ -631,12 +634,17 @@</span> <span class="p_context"> struct iwl_scan_req_umac_tail {</span>
  * @uid: scan id, &amp;enum iwl_umac_scan_uid_offsets
  * @ooc_priority: out of channel priority - &amp;enum iwl_scan_priority
  * @general_flags: &amp;enum iwl_umac_scan_general_flags
<span class="p_del">- * @reserved2: for future use and alignment</span>
  * @scan_start_mac_id: report the scan start TSF time according to this mac TSF
  * @extended_dwell: dwell time for channels 1, 6 and 11
  * @active_dwell: dwell time for active scan
  * @passive_dwell: dwell time for passive scan
  * @fragmented_dwell: dwell time for fragmented passive scan
<span class="p_add">+ * @adwell_default_n_aps: for adaptive dwell the default number of APs</span>
<span class="p_add">+ *	per channel</span>
<span class="p_add">+ * @adwell_default_n_aps_social: for adaptive dwell the default</span>
<span class="p_add">+ *	number of APs per social (1,6,11) channel</span>
<span class="p_add">+ * @adwell_max_budget: for adaptive dwell the maximal budget of TU to be added</span>
<span class="p_add">+ *	to total scan time</span>
  * @max_out_time: max out of serving channel time, per LMAC - for CDB there
  *	are 2 LMACs
  * @suspend_time: max suspend time, per LMAC - for CDB there are 2 LMACs
<span class="p_chunk">@@ -644,6 +652,8 @@</span> <span class="p_context"> struct iwl_scan_req_umac_tail {</span>
  * @channel_flags: &amp;enum iwl_scan_channel_flags
  * @n_channels: num of channels in scan request
  * @reserved: for future use and alignment
<span class="p_add">+ * @reserved2: for future use and alignment</span>
<span class="p_add">+ * @reserved3: for future use and alignment</span>
  * @data: &amp;struct iwl_scan_channel_cfg_umac and
  *	&amp;struct iwl_scan_req_umac_tail
  */
<span class="p_chunk">@@ -651,41 +661,64 @@</span> <span class="p_context"> struct iwl_scan_req_umac {</span>
 	__le32 flags;
 	__le32 uid;
 	__le32 ooc_priority;
<span class="p_del">-	/* SCAN_GENERAL_PARAMS_API_S_VER_4 */</span>
 	__le16 general_flags;
<span class="p_del">-	u8 reserved2;</span>
<span class="p_add">+	u8 reserved;</span>
 	u8 scan_start_mac_id;
<span class="p_del">-	u8 extended_dwell;</span>
<span class="p_del">-	u8 active_dwell;</span>
<span class="p_del">-	u8 passive_dwell;</span>
<span class="p_del">-	u8 fragmented_dwell;</span>
 	union {
 		struct {
<span class="p_add">+			u8 extended_dwell;</span>
<span class="p_add">+			u8 active_dwell;</span>
<span class="p_add">+			u8 passive_dwell;</span>
<span class="p_add">+			u8 fragmented_dwell;</span>
 			__le32 max_out_time;
 			__le32 suspend_time;
 			__le32 scan_priority;
<span class="p_del">-			/* SCAN_CHANNEL_PARAMS_API_S_VER_4 */</span>
<span class="p_add">+			/* SCAN_CHANNEL_PARAMS_API_S_VER_1 */</span>
 			u8 channel_flags;
 			u8 n_channels;
<span class="p_del">-			__le16 reserved;</span>
<span class="p_add">+			__le16 reserved2;</span>
 			u8 data[];
 		} v1; /* SCAN_REQUEST_CMD_UMAC_API_S_VER_1 */
 		struct {
<span class="p_add">+			u8 extended_dwell;</span>
<span class="p_add">+			u8 active_dwell;</span>
<span class="p_add">+			u8 passive_dwell;</span>
<span class="p_add">+			u8 fragmented_dwell;</span>
 			__le32 max_out_time[SCAN_TWO_LMACS];
 			__le32 suspend_time[SCAN_TWO_LMACS];
 			__le32 scan_priority;
<span class="p_del">-			/* SCAN_CHANNEL_PARAMS_API_S_VER_4 */</span>
<span class="p_add">+			/* SCAN_CHANNEL_PARAMS_API_S_VER_1 */</span>
 			u8 channel_flags;
 			u8 n_channels;
<span class="p_del">-			__le16 reserved;</span>
<span class="p_add">+			__le16 reserved2;</span>
 			u8 data[];
 		} v6; /* SCAN_REQUEST_CMD_UMAC_API_S_VER_6 */
<span class="p_add">+		struct {</span>
<span class="p_add">+			u8 active_dwell;</span>
<span class="p_add">+			u8 passive_dwell;</span>
<span class="p_add">+			u8 fragmented_dwell;</span>
<span class="p_add">+			u8 adwell_default_n_aps;</span>
<span class="p_add">+			u8 adwell_default_n_aps_social;</span>
<span class="p_add">+			u8 reserved3;</span>
<span class="p_add">+			__le16 adwell_max_budget;</span>
<span class="p_add">+			__le32 max_out_time[SCAN_TWO_LMACS];</span>
<span class="p_add">+			__le32 suspend_time[SCAN_TWO_LMACS];</span>
<span class="p_add">+			__le32 scan_priority;</span>
<span class="p_add">+			/* SCAN_CHANNEL_PARAMS_API_S_VER_1 */</span>
<span class="p_add">+			u8 channel_flags;</span>
<span class="p_add">+			u8 n_channels;</span>
<span class="p_add">+			__le16 reserved2;</span>
<span class="p_add">+			u8 data[];</span>
<span class="p_add">+		} v7; /* SCAN_REQUEST_CMD_UMAC_API_S_VER_7 */</span>
 	};
 } __packed;
 
<span class="p_del">-#define IWL_SCAN_REQ_UMAC_SIZE sizeof(struct iwl_scan_req_umac)</span>
<span class="p_add">+#define IWL_SCAN_REQ_UMAC_SIZE_V7 sizeof(struct iwl_scan_req_umac)</span>
<span class="p_add">+#define IWL_SCAN_REQ_UMAC_SIZE_V6 (sizeof(struct iwl_scan_req_umac) - \</span>
<span class="p_add">+				   2 * sizeof(u8) - sizeof(__le16))</span>
 #define IWL_SCAN_REQ_UMAC_SIZE_V1 (sizeof(struct iwl_scan_req_umac) - \
<span class="p_del">-				   2 * sizeof(__le32))</span>
<span class="p_add">+				   2 * sizeof(__le32) - 2 * sizeof(u8) - \</span>
<span class="p_add">+				   sizeof(__le16))</span>
 
 /**
  * struct iwl_umac_scan_abort
<span class="p_header">diff --git a/drivers/net/wireless/intel/iwlwifi/fw/file.h b/drivers/net/wireless/intel/iwlwifi/fw/file.h</span>
<span class="p_header">index 279248cd9cfb..e988e4c371c4 100644</span>
<span class="p_header">--- a/drivers/net/wireless/intel/iwlwifi/fw/file.h</span>
<span class="p_header">+++ b/drivers/net/wireless/intel/iwlwifi/fw/file.h</span>
<span class="p_chunk">@@ -262,6 +262,7 @@</span> <span class="p_context"> enum iwl_ucode_tlv_api {</span>
 	IWL_UCODE_TLV_API_STA_TYPE		= (__force iwl_ucode_tlv_api_t)30,
 	IWL_UCODE_TLV_API_NAN2_VER2		= (__force iwl_ucode_tlv_api_t)31,
 	/* API Set 1 */
<span class="p_add">+	IWL_UCODE_TLV_API_ADAPTIVE_DWELL	= (__force iwl_ucode_tlv_api_t)32,</span>
 	IWL_UCODE_TLV_API_NEW_BEACON_TEMPLATE	= (__force iwl_ucode_tlv_api_t)34,
 	IWL_UCODE_TLV_API_NEW_RX_STATS		= (__force iwl_ucode_tlv_api_t)35,
 	IWL_UCODE_TLV_API_COEX_ATS_EXTERNAL	= (__force iwl_ucode_tlv_api_t)37,
<span class="p_header">diff --git a/drivers/net/wireless/intel/iwlwifi/iwl-config.h b/drivers/net/wireless/intel/iwlwifi/iwl-config.h</span>
<span class="p_header">index 71cb1ecde0f7..e226179c32fa 100644</span>
<span class="p_header">--- a/drivers/net/wireless/intel/iwlwifi/iwl-config.h</span>
<span class="p_header">+++ b/drivers/net/wireless/intel/iwlwifi/iwl-config.h</span>
<span class="p_chunk">@@ -364,6 +364,7 @@</span> <span class="p_context"> struct iwl_cfg {</span>
 	u32 dccm2_len;
 	u32 smem_offset;
 	u32 smem_len;
<span class="p_add">+	u32 soc_latency;</span>
 	u16 nvm_ver;
 	u16 nvm_calib_ver;
 	u16 rx_with_siso_diversity:1,
<span class="p_chunk">@@ -471,6 +472,10 @@</span> <span class="p_context"> extern const struct iwl_cfg iwl9260_2ac_cfg;</span>
 extern const struct iwl_cfg iwl9270_2ac_cfg;
 extern const struct iwl_cfg iwl9460_2ac_cfg;
 extern const struct iwl_cfg iwl9560_2ac_cfg;
<span class="p_add">+extern const struct iwl_cfg iwl9460_2ac_cfg_soc;</span>
<span class="p_add">+extern const struct iwl_cfg iwl9461_2ac_cfg_soc;</span>
<span class="p_add">+extern const struct iwl_cfg iwl9462_2ac_cfg_soc;</span>
<span class="p_add">+extern const struct iwl_cfg iwl9560_2ac_cfg_soc;</span>
 extern const struct iwl_cfg iwla000_2ac_cfg_hr;
 extern const struct iwl_cfg iwla000_2ac_cfg_hr_cdb;
 extern const struct iwl_cfg iwla000_2ac_cfg_jf;
<span class="p_header">diff --git a/drivers/net/wireless/intel/iwlwifi/mvm/mvm.h b/drivers/net/wireless/intel/iwlwifi/mvm/mvm.h</span>
<span class="p_header">index 949e63418299..8dcdb522b846 100644</span>
<span class="p_header">--- a/drivers/net/wireless/intel/iwlwifi/mvm/mvm.h</span>
<span class="p_header">+++ b/drivers/net/wireless/intel/iwlwifi/mvm/mvm.h</span>
<span class="p_chunk">@@ -1124,6 +1124,12 @@</span> <span class="p_context"> static inline bool iwl_mvm_is_d0i3_supported(struct iwl_mvm *mvm)</span>
 			    IWL_UCODE_TLV_CAPA_D0I3_SUPPORT);
 }
 
<span class="p_add">+static inline bool iwl_mvm_is_adaptive_dwell_supported(struct iwl_mvm *mvm)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return fw_has_api(&amp;mvm-&gt;fw-&gt;ucode_capa,</span>
<span class="p_add">+			  IWL_UCODE_TLV_API_ADAPTIVE_DWELL);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static inline bool iwl_mvm_enter_d0i3_on_suspend(struct iwl_mvm *mvm)
 {
 	/* For now we only use this mode to differentiate between
<span class="p_header">diff --git a/drivers/net/wireless/intel/iwlwifi/mvm/scan.c b/drivers/net/wireless/intel/iwlwifi/mvm/scan.c</span>
<span class="p_header">index 774122fed454..e4fd476e9ccb 100644</span>
<span class="p_header">--- a/drivers/net/wireless/intel/iwlwifi/mvm/scan.c</span>
<span class="p_header">+++ b/drivers/net/wireless/intel/iwlwifi/mvm/scan.c</span>
<span class="p_chunk">@@ -130,6 +130,19 @@</span> <span class="p_context"> struct iwl_mvm_scan_params {</span>
 	u32 measurement_dwell;
 };
 
<span class="p_add">+static inline void *iwl_mvm_get_scan_req_umac_data(struct iwl_mvm *mvm)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct iwl_scan_req_umac *cmd = mvm-&gt;scan_cmd;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (iwl_mvm_is_adaptive_dwell_supported(mvm))</span>
<span class="p_add">+		return (void *)&amp;cmd-&gt;v7.data;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (iwl_mvm_has_new_tx_api(mvm))</span>
<span class="p_add">+		return (void *)&amp;cmd-&gt;v6.data;</span>
<span class="p_add">+</span>
<span class="p_add">+	return (void *)&amp;cmd-&gt;v1.data;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static u8 iwl_mvm_scan_rx_ant(struct iwl_mvm *mvm)
 {
 	if (mvm-&gt;scan_rx_ant != ANT_NONE)
<span class="p_chunk">@@ -1075,25 +1088,57 @@</span> <span class="p_context"> static void iwl_mvm_scan_umac_dwell(struct iwl_mvm *mvm,</span>
 {
 	struct iwl_mvm_scan_timing_params *timing = &amp;scan_timing[params-&gt;type];
 
<span class="p_add">+	if (iwl_mvm_is_regular_scan(params))</span>
<span class="p_add">+		cmd-&gt;ooc_priority = cpu_to_le32(IWL_SCAN_PRIORITY_EXT_6);</span>
<span class="p_add">+	else</span>
<span class="p_add">+		cmd-&gt;ooc_priority = cpu_to_le32(IWL_SCAN_PRIORITY_EXT_2);</span>
<span class="p_add">+</span>
<span class="p_add">+	if (iwl_mvm_is_adaptive_dwell_supported(mvm)) {</span>
<span class="p_add">+		if (params-&gt;measurement_dwell) {</span>
<span class="p_add">+			cmd-&gt;v7.active_dwell = params-&gt;measurement_dwell;</span>
<span class="p_add">+			cmd-&gt;v7.passive_dwell = params-&gt;measurement_dwell;</span>
<span class="p_add">+		} else {</span>
<span class="p_add">+			cmd-&gt;v7.active_dwell = IWL_SCAN_DWELL_ACTIVE;</span>
<span class="p_add">+			cmd-&gt;v7.passive_dwell = IWL_SCAN_DWELL_PASSIVE;</span>
<span class="p_add">+		}</span>
<span class="p_add">+		cmd-&gt;v7.fragmented_dwell = IWL_SCAN_DWELL_FRAGMENTED;</span>
<span class="p_add">+</span>
<span class="p_add">+		cmd-&gt;v7.scan_priority = cpu_to_le32(IWL_SCAN_PRIORITY_EXT_6);</span>
<span class="p_add">+		cmd-&gt;v7.max_out_time[SCAN_LB_LMAC_IDX] =</span>
<span class="p_add">+			cpu_to_le32(timing-&gt;max_out_time);</span>
<span class="p_add">+		cmd-&gt;v7.suspend_time[SCAN_LB_LMAC_IDX] =</span>
<span class="p_add">+			cpu_to_le32(timing-&gt;suspend_time);</span>
<span class="p_add">+		if (iwl_mvm_is_cdb_supported(mvm)) {</span>
<span class="p_add">+			cmd-&gt;v7.max_out_time[SCAN_HB_LMAC_IDX] =</span>
<span class="p_add">+				cpu_to_le32(timing-&gt;max_out_time);</span>
<span class="p_add">+			cmd-&gt;v7.suspend_time[SCAN_HB_LMAC_IDX] =</span>
<span class="p_add">+				cpu_to_le32(timing-&gt;suspend_time);</span>
<span class="p_add">+		}</span>
<span class="p_add">+</span>
<span class="p_add">+		return;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
 	if (params-&gt;measurement_dwell) {
<span class="p_del">-		cmd-&gt;active_dwell = params-&gt;measurement_dwell;</span>
<span class="p_del">-		cmd-&gt;passive_dwell = params-&gt;measurement_dwell;</span>
<span class="p_del">-		cmd-&gt;extended_dwell = params-&gt;measurement_dwell;</span>
<span class="p_add">+		cmd-&gt;v1.active_dwell = params-&gt;measurement_dwell;</span>
<span class="p_add">+		cmd-&gt;v1.passive_dwell = params-&gt;measurement_dwell;</span>
<span class="p_add">+		cmd-&gt;v1.extended_dwell = params-&gt;measurement_dwell;</span>
 	} else {
<span class="p_del">-		cmd-&gt;active_dwell = IWL_SCAN_DWELL_ACTIVE;</span>
<span class="p_del">-		cmd-&gt;passive_dwell = IWL_SCAN_DWELL_PASSIVE;</span>
<span class="p_del">-		cmd-&gt;extended_dwell = IWL_SCAN_DWELL_EXTENDED;</span>
<span class="p_add">+		cmd-&gt;v1.active_dwell = IWL_SCAN_DWELL_ACTIVE;</span>
<span class="p_add">+		cmd-&gt;v1.passive_dwell = IWL_SCAN_DWELL_PASSIVE;</span>
<span class="p_add">+		cmd-&gt;v1.extended_dwell = IWL_SCAN_DWELL_EXTENDED;</span>
 	}
<span class="p_del">-	cmd-&gt;fragmented_dwell = IWL_SCAN_DWELL_FRAGMENTED;</span>
<span class="p_add">+	cmd-&gt;v1.fragmented_dwell = IWL_SCAN_DWELL_FRAGMENTED;</span>
 
 	if (iwl_mvm_has_new_tx_api(mvm)) {
 		cmd-&gt;v6.scan_priority = cpu_to_le32(IWL_SCAN_PRIORITY_EXT_6);
<span class="p_del">-		cmd-&gt;v6.max_out_time[0] = cpu_to_le32(timing-&gt;max_out_time);</span>
<span class="p_del">-		cmd-&gt;v6.suspend_time[0] = cpu_to_le32(timing-&gt;suspend_time);</span>
<span class="p_add">+		cmd-&gt;v6.max_out_time[SCAN_LB_LMAC_IDX] =</span>
<span class="p_add">+			cpu_to_le32(timing-&gt;max_out_time);</span>
<span class="p_add">+		cmd-&gt;v6.suspend_time[SCAN_LB_LMAC_IDX] =</span>
<span class="p_add">+			cpu_to_le32(timing-&gt;suspend_time);</span>
 		if (iwl_mvm_is_cdb_supported(mvm)) {
<span class="p_del">-			cmd-&gt;v6.max_out_time[1] =</span>
<span class="p_add">+			cmd-&gt;v6.max_out_time[SCAN_HB_LMAC_IDX] =</span>
 				cpu_to_le32(timing-&gt;max_out_time);
<span class="p_del">-			cmd-&gt;v6.suspend_time[1] =</span>
<span class="p_add">+			cmd-&gt;v6.suspend_time[SCAN_HB_LMAC_IDX] =</span>
 				cpu_to_le32(timing-&gt;suspend_time);
 		}
 	} else {
<span class="p_chunk">@@ -1102,11 +1147,6 @@</span> <span class="p_context"> static void iwl_mvm_scan_umac_dwell(struct iwl_mvm *mvm,</span>
 		cmd-&gt;v1.scan_priority =
 			cpu_to_le32(IWL_SCAN_PRIORITY_EXT_6);
 	}
<span class="p_del">-</span>
<span class="p_del">-	if (iwl_mvm_is_regular_scan(params))</span>
<span class="p_del">-		cmd-&gt;ooc_priority = cpu_to_le32(IWL_SCAN_PRIORITY_EXT_6);</span>
<span class="p_del">-	else</span>
<span class="p_del">-		cmd-&gt;ooc_priority = cpu_to_le32(IWL_SCAN_PRIORITY_EXT_2);</span>
 }
 
 static void
<span class="p_chunk">@@ -1178,8 +1218,7 @@</span> <span class="p_context"> static int iwl_mvm_scan_umac(struct iwl_mvm *mvm, struct ieee80211_vif *vif,</span>
 			     int type)
 {
 	struct iwl_scan_req_umac *cmd = mvm-&gt;scan_cmd;
<span class="p_del">-	void *cmd_data = iwl_mvm_has_new_tx_api(mvm) ?</span>
<span class="p_del">-			 (void *)&amp;cmd-&gt;v6.data : (void *)&amp;cmd-&gt;v1.data;</span>
<span class="p_add">+	void *cmd_data = iwl_mvm_get_scan_req_umac_data(mvm);</span>
 	struct iwl_scan_req_umac_tail *sec_part = cmd_data +
 		sizeof(struct iwl_scan_channel_cfg_umac) *
 			mvm-&gt;fw-&gt;ucode_capa.n_scan_channels;
<span class="p_chunk">@@ -1216,7 +1255,10 @@</span> <span class="p_context"> static int iwl_mvm_scan_umac(struct iwl_mvm *mvm, struct ieee80211_vif *vif,</span>
 				IWL_SCAN_CHANNEL_FLAG_EBS_ACCURATE |
 				IWL_SCAN_CHANNEL_FLAG_CACHE_ADD;
 
<span class="p_del">-	if (iwl_mvm_has_new_tx_api(mvm)) {</span>
<span class="p_add">+	if (iwl_mvm_is_adaptive_dwell_supported(mvm)) {</span>
<span class="p_add">+		cmd-&gt;v7.channel_flags = channel_flags;</span>
<span class="p_add">+		cmd-&gt;v7.n_channels = params-&gt;n_channels;</span>
<span class="p_add">+	} else if (iwl_mvm_has_new_tx_api(mvm)) {</span>
 		cmd-&gt;v6.channel_flags = channel_flags;
 		cmd-&gt;v6.n_channels = params-&gt;n_channels;
 	} else {
<span class="p_chunk">@@ -1661,8 +1703,10 @@</span> <span class="p_context"> int iwl_mvm_scan_size(struct iwl_mvm *mvm)</span>
 {
 	int base_size = IWL_SCAN_REQ_UMAC_SIZE_V1;
 
<span class="p_del">-	if (iwl_mvm_has_new_tx_api(mvm))</span>
<span class="p_del">-		base_size = IWL_SCAN_REQ_UMAC_SIZE;</span>
<span class="p_add">+	if (iwl_mvm_is_adaptive_dwell_supported(mvm))</span>
<span class="p_add">+		base_size = IWL_SCAN_REQ_UMAC_SIZE_V7;</span>
<span class="p_add">+	else if (iwl_mvm_has_new_tx_api(mvm))</span>
<span class="p_add">+		base_size = IWL_SCAN_REQ_UMAC_SIZE_V6;</span>
 
 	if (fw_has_capa(&amp;mvm-&gt;fw-&gt;ucode_capa, IWL_UCODE_TLV_CAPA_UMAC_SCAN))
 		return base_size +
<span class="p_header">diff --git a/drivers/net/wireless/intel/iwlwifi/pcie/drv.c b/drivers/net/wireless/intel/iwlwifi/pcie/drv.c</span>
<span class="p_header">index 858765fed8f8..548e1928430d 100644</span>
<span class="p_header">--- a/drivers/net/wireless/intel/iwlwifi/pcie/drv.c</span>
<span class="p_header">+++ b/drivers/net/wireless/intel/iwlwifi/pcie/drv.c</span>
<span class="p_chunk">@@ -465,6 +465,8 @@</span> <span class="p_context"> static const struct pci_device_id iwl_hw_card_ids[] = {</span>
 	{IWL_PCI_DEVICE(0x24F3, 0x9110, iwl8260_2ac_cfg)},
 	{IWL_PCI_DEVICE(0x24F4, 0x8030, iwl8260_2ac_cfg)},
 	{IWL_PCI_DEVICE(0x24F4, 0x9030, iwl8260_2ac_cfg)},
<span class="p_add">+	{IWL_PCI_DEVICE(0x24F4, 0xC030, iwl8260_2ac_cfg)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0x24F4, 0xD030, iwl8260_2ac_cfg)},</span>
 	{IWL_PCI_DEVICE(0x24F3, 0x8130, iwl8260_2ac_cfg)},
 	{IWL_PCI_DEVICE(0x24F3, 0x9130, iwl8260_2ac_cfg)},
 	{IWL_PCI_DEVICE(0x24F3, 0x8132, iwl8260_2ac_cfg)},
<span class="p_chunk">@@ -483,6 +485,7 @@</span> <span class="p_context"> static const struct pci_device_id iwl_hw_card_ids[] = {</span>
 	{IWL_PCI_DEVICE(0x24F3, 0x0950, iwl8260_2ac_cfg)},
 	{IWL_PCI_DEVICE(0x24F3, 0x0930, iwl8260_2ac_cfg)},
 	{IWL_PCI_DEVICE(0x24F3, 0x0000, iwl8265_2ac_cfg)},
<span class="p_add">+	{IWL_PCI_DEVICE(0x24F3, 0x4010, iwl8260_2ac_cfg)},</span>
 	{IWL_PCI_DEVICE(0x24FD, 0x0010, iwl8265_2ac_cfg)},
 	{IWL_PCI_DEVICE(0x24FD, 0x0110, iwl8265_2ac_cfg)},
 	{IWL_PCI_DEVICE(0x24FD, 0x1110, iwl8265_2ac_cfg)},
<span class="p_chunk">@@ -508,67 +511,143 @@</span> <span class="p_context"> static const struct pci_device_id iwl_hw_card_ids[] = {</span>
 	{IWL_PCI_DEVICE(0x24FD, 0x3E01, iwl8275_2ac_cfg)},
 	{IWL_PCI_DEVICE(0x24FD, 0x1012, iwl8275_2ac_cfg)},
 	{IWL_PCI_DEVICE(0x24FD, 0x0012, iwl8275_2ac_cfg)},
<span class="p_add">+	{IWL_PCI_DEVICE(0x24FD, 0x0014, iwl8265_2ac_cfg)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0x24FD, 0x9074, iwl8265_2ac_cfg)},</span>
 
 /* 9000 Series */
<span class="p_del">-	{IWL_PCI_DEVICE(0x271B, 0x0010, iwl9160_2ac_cfg)},</span>
<span class="p_del">-	{IWL_PCI_DEVICE(0x271B, 0x0014, iwl9160_2ac_cfg)},</span>
<span class="p_del">-	{IWL_PCI_DEVICE(0x271B, 0x0210, iwl9160_2ac_cfg)},</span>
 	{IWL_PCI_DEVICE(0x2526, 0x0000, iwl9260_2ac_cfg)},
 	{IWL_PCI_DEVICE(0x2526, 0x0010, iwl9260_2ac_cfg)},
 	{IWL_PCI_DEVICE(0x2526, 0x0014, iwl9260_2ac_cfg)},
<span class="p_del">-	{IWL_PCI_DEVICE(0x2526, 0xA014, iwl9260_2ac_cfg)},</span>
<span class="p_del">-	{IWL_PCI_DEVICE(0x2526, 0x4010, iwl9260_2ac_cfg)},</span>
<span class="p_del">-	{IWL_PCI_DEVICE(0x2526, 0x0210, iwl9260_2ac_cfg)},</span>
<span class="p_del">-	{IWL_PCI_DEVICE(0x2526, 0x0214, iwl9260_2ac_cfg)},</span>
<span class="p_del">-	{IWL_PCI_DEVICE(0x2526, 0x1410, iwl9270_2ac_cfg)},</span>
<span class="p_del">-	{IWL_PCI_DEVICE(0x2526, 0x1610, iwl9270_2ac_cfg)},</span>
<span class="p_del">-	{IWL_PCI_DEVICE(0x9DF0, 0x0A10, iwl9460_2ac_cfg)},</span>
<span class="p_del">-	{IWL_PCI_DEVICE(0x9DF0, 0x0010, iwl9460_2ac_cfg)},</span>
<span class="p_del">-	{IWL_PCI_DEVICE(0x9DF0, 0x0210, iwl9460_2ac_cfg)},</span>
<span class="p_del">-	{IWL_PCI_DEVICE(0x9DF0, 0x0410, iwl9460_2ac_cfg)},</span>
<span class="p_del">-	{IWL_PCI_DEVICE(0x9DF0, 0x0610, iwl9460_2ac_cfg)},</span>
<span class="p_del">-	{IWL_PCI_DEVICE(0x9DF0, 0x0310, iwl9460_2ac_cfg)},</span>
<span class="p_del">-	{IWL_PCI_DEVICE(0x9DF0, 0x0000, iwl9460_2ac_cfg)},</span>
<span class="p_del">-	{IWL_PCI_DEVICE(0x9DF0, 0x0510, iwl9460_2ac_cfg)},</span>
<span class="p_del">-	{IWL_PCI_DEVICE(0x9DF0, 0x2010, iwl9460_2ac_cfg)},</span>
<span class="p_del">-	{IWL_PCI_DEVICE(0x2526, 0x1420, iwl9460_2ac_cfg)},</span>
<span class="p_del">-	{IWL_PCI_DEVICE(0x9DF0, 0x0710, iwl9460_2ac_cfg)},</span>
<span class="p_del">-	{IWL_PCI_DEVICE(0x9DF0, 0x2A10, iwl9460_2ac_cfg)},</span>
<span class="p_del">-	{IWL_PCI_DEVICE(0x30DC, 0x0060, iwl9460_2ac_cfg)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0x2526, 0x0030, iwl9560_2ac_cfg)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0x2526, 0x0034, iwl9560_2ac_cfg)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0x2526, 0x0038, iwl9560_2ac_cfg)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0x2526, 0x003C, iwl9560_2ac_cfg)},</span>
 	{IWL_PCI_DEVICE(0x2526, 0x0060, iwl9460_2ac_cfg)},
<span class="p_del">-	{IWL_PCI_DEVICE(0x2526, 0x0260, iwl9460_2ac_cfg)},</span>
 	{IWL_PCI_DEVICE(0x2526, 0x0064, iwl9460_2ac_cfg)},
<span class="p_del">-	{IWL_PCI_DEVICE(0x2526, 0x00A4, iwl9460_2ac_cfg)},</span>
<span class="p_del">-	{IWL_PCI_DEVICE(0x2526, 0x40A4, iwl9460_2ac_cfg)},</span>
<span class="p_del">-	{IWL_PCI_DEVICE(0x2526, 0x02A4, iwl9460_2ac_cfg)},</span>
 	{IWL_PCI_DEVICE(0x2526, 0x00A0, iwl9460_2ac_cfg)},
<span class="p_del">-	{IWL_PCI_DEVICE(0x2526, 0x02A0, iwl9460_2ac_cfg)},</span>
<span class="p_del">-	{IWL_PCI_DEVICE(0x9DF0, 0x0060, iwl9460_2ac_cfg)},</span>
<span class="p_del">-	{IWL_PCI_DEVICE(0xA370, 0x0060, iwl9460_2ac_cfg)},</span>
<span class="p_del">-	{IWL_PCI_DEVICE(0x31DC, 0x0060, iwl9460_2ac_cfg)},</span>
<span class="p_del">-	{IWL_PCI_DEVICE(0x2526, 0x0030, iwl9560_2ac_cfg)},</span>
<span class="p_del">-	{IWL_PCI_DEVICE(0x2526, 0x4030, iwl9560_2ac_cfg)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0x2526, 0x00A4, iwl9460_2ac_cfg)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0x2526, 0x0210, iwl9260_2ac_cfg)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0x2526, 0x0214, iwl9260_2ac_cfg)},</span>
 	{IWL_PCI_DEVICE(0x2526, 0x0230, iwl9560_2ac_cfg)},
 	{IWL_PCI_DEVICE(0x2526, 0x0234, iwl9560_2ac_cfg)},
 	{IWL_PCI_DEVICE(0x2526, 0x0238, iwl9560_2ac_cfg)},
 	{IWL_PCI_DEVICE(0x2526, 0x023C, iwl9560_2ac_cfg)},
<span class="p_del">-	{IWL_PCI_DEVICE(0x9DF0, 0x0030, iwl9560_2ac_cfg)},</span>
<span class="p_del">-	{IWL_PCI_DEVICE(0xA370, 0x0030, iwl9560_2ac_cfg)},</span>
<span class="p_del">-	{IWL_PCI_DEVICE(0x31DC, 0x0030, iwl9560_2ac_cfg)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0x2526, 0x0260, iwl9460_2ac_cfg)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0x2526, 0x0264, iwl9461_2ac_cfg_soc)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0x2526, 0x02A0, iwl9460_2ac_cfg)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0x2526, 0x02A4, iwl9460_2ac_cfg)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0x2526, 0x1010, iwl9260_2ac_cfg)},</span>
 	{IWL_PCI_DEVICE(0x2526, 0x1030, iwl9560_2ac_cfg)},
<span class="p_del">-	{IWL_PCI_DEVICE(0xA370, 0x1030, iwl9560_2ac_cfg)},</span>
<span class="p_del">-	{IWL_PCI_DEVICE(0x9DF0, 0x0034, iwl9560_2ac_cfg)},</span>
<span class="p_del">-	{IWL_PCI_DEVICE(0xA370, 0x0034, iwl9560_2ac_cfg)},</span>
<span class="p_del">-	{IWL_PCI_DEVICE(0x31DC, 0x0034, iwl9560_2ac_cfg)},</span>
<span class="p_del">-	{IWL_PCI_DEVICE(0x2526, 0x0038, iwl9560_2ac_cfg)},</span>
<span class="p_del">-	{IWL_PCI_DEVICE(0x2526, 0x003C, iwl9560_2ac_cfg)},</span>
<span class="p_del">-	{IWL_PCI_DEVICE(0x9DF0, 0x0038, iwl9560_2ac_cfg)},</span>
<span class="p_del">-	{IWL_PCI_DEVICE(0xA370, 0x0038, iwl9560_2ac_cfg)},</span>
<span class="p_del">-	{IWL_PCI_DEVICE(0x31DC, 0x0038, iwl9560_2ac_cfg)},</span>
<span class="p_del">-	{IWL_PCI_DEVICE(0x9DF0, 0x003C, iwl9560_2ac_cfg)},</span>
<span class="p_del">-	{IWL_PCI_DEVICE(0xA370, 0x003C, iwl9560_2ac_cfg)},</span>
<span class="p_del">-	{IWL_PCI_DEVICE(0x31DC, 0x003C, iwl9560_2ac_cfg)},</span>
<span class="p_del">-	{IWL_PCI_DEVICE(0x2526, 0x0034, iwl9560_2ac_cfg)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0x2526, 0x1210, iwl9260_2ac_cfg)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0x2526, 0x1410, iwl9270_2ac_cfg)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0x2526, 0x1420, iwl9460_2ac_cfg_soc)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0x2526, 0x1610, iwl9270_2ac_cfg)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0x2526, 0x4010, iwl9260_2ac_cfg)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0x2526, 0x4030, iwl9560_2ac_cfg)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0x2526, 0x40A4, iwl9460_2ac_cfg)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0x2526, 0xA014, iwl9260_2ac_cfg)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0x2526, 0x42A4, iwl9462_2ac_cfg_soc)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0x271B, 0x0010, iwl9160_2ac_cfg)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0x271B, 0x0014, iwl9160_2ac_cfg)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0x271B, 0x0210, iwl9160_2ac_cfg)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0x271B, 0x0214, iwl9260_2ac_cfg)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0x2720, 0x0034, iwl9560_2ac_cfg)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0x2720, 0x0038, iwl9560_2ac_cfg)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0x2720, 0x003C, iwl9560_2ac_cfg)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0x2720, 0x0060, iwl9461_2ac_cfg_soc)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0x2720, 0x0064, iwl9461_2ac_cfg_soc)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0x2720, 0x00A0, iwl9462_2ac_cfg_soc)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0x2720, 0x00A4, iwl9462_2ac_cfg_soc)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0x2720, 0x0230, iwl9560_2ac_cfg)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0x2720, 0x0234, iwl9560_2ac_cfg)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0x2720, 0x0238, iwl9560_2ac_cfg)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0x2720, 0x023C, iwl9560_2ac_cfg)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0x2720, 0x0260, iwl9461_2ac_cfg_soc)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0x2720, 0x0264, iwl9461_2ac_cfg_soc)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0x2720, 0x02A0, iwl9462_2ac_cfg_soc)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0x2720, 0x02A4, iwl9462_2ac_cfg_soc)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0x2720, 0x4030, iwl9560_2ac_cfg)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0x2720, 0x40A4, iwl9462_2ac_cfg_soc)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0x30DC, 0x0060, iwl9460_2ac_cfg_soc)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0x30DC, 0x0064, iwl9461_2ac_cfg_soc)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0x30DC, 0x00A0, iwl9462_2ac_cfg_soc)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0x30DC, 0x00A4, iwl9462_2ac_cfg_soc)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0x30DC, 0x0260, iwl9461_2ac_cfg_soc)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0x30DC, 0x0264, iwl9461_2ac_cfg_soc)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0x30DC, 0x02A0, iwl9462_2ac_cfg_soc)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0x30DC, 0x02A4, iwl9462_2ac_cfg_soc)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0x31DC, 0x0030, iwl9560_2ac_cfg_soc)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0x31DC, 0x0034, iwl9560_2ac_cfg_soc)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0x31DC, 0x0038, iwl9560_2ac_cfg_soc)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0x31DC, 0x003C, iwl9560_2ac_cfg_soc)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0x31DC, 0x0060, iwl9460_2ac_cfg_soc)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0x31DC, 0x0064, iwl9461_2ac_cfg_soc)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0x31DC, 0x00A0, iwl9462_2ac_cfg_soc)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0x31DC, 0x00A4, iwl9462_2ac_cfg_soc)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0x31DC, 0x0230, iwl9560_2ac_cfg_soc)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0x31DC, 0x0234, iwl9560_2ac_cfg_soc)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0x31DC, 0x0238, iwl9560_2ac_cfg_soc)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0x31DC, 0x023C, iwl9560_2ac_cfg_soc)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0x31DC, 0x0260, iwl9461_2ac_cfg_soc)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0x31DC, 0x0264, iwl9461_2ac_cfg_soc)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0x31DC, 0x02A0, iwl9462_2ac_cfg_soc)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0x31DC, 0x02A4, iwl9462_2ac_cfg_soc)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0x31DC, 0x4030, iwl9560_2ac_cfg_soc)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0x31DC, 0x4034, iwl9560_2ac_cfg_soc)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0x31DC, 0x40A4, iwl9462_2ac_cfg_soc)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0x34F0, 0x0030, iwl9560_2ac_cfg_soc)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0x34F0, 0x0034, iwl9560_2ac_cfg_soc)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0x34F0, 0x02A4, iwl9462_2ac_cfg_soc)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0x9DF0, 0x0000, iwl9460_2ac_cfg_soc)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0x9DF0, 0x0010, iwl9460_2ac_cfg_soc)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0x9DF0, 0x0030, iwl9560_2ac_cfg_soc)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0x9DF0, 0x0034, iwl9560_2ac_cfg_soc)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0x9DF0, 0x0038, iwl9560_2ac_cfg_soc)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0x9DF0, 0x003C, iwl9560_2ac_cfg_soc)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0x9DF0, 0x0060, iwl9460_2ac_cfg_soc)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0x9DF0, 0x0064, iwl9461_2ac_cfg_soc)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0x9DF0, 0x00A0, iwl9462_2ac_cfg_soc)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0x9DF0, 0x00A4, iwl9462_2ac_cfg_soc)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0x9DF0, 0x0210, iwl9460_2ac_cfg_soc)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0x9DF0, 0x0230, iwl9560_2ac_cfg_soc)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0x9DF0, 0x0234, iwl9560_2ac_cfg_soc)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0x9DF0, 0x0238, iwl9560_2ac_cfg_soc)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0x9DF0, 0x023C, iwl9560_2ac_cfg_soc)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0x9DF0, 0x0260, iwl9461_2ac_cfg_soc)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0x9DF0, 0x0264, iwl9461_2ac_cfg_soc)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0x9DF0, 0x02A0, iwl9462_2ac_cfg_soc)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0x9DF0, 0x02A4, iwl9462_2ac_cfg_soc)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0x9DF0, 0x0310, iwl9460_2ac_cfg_soc)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0x9DF0, 0x0410, iwl9460_2ac_cfg_soc)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0x9DF0, 0x0510, iwl9460_2ac_cfg_soc)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0x9DF0, 0x0610, iwl9460_2ac_cfg_soc)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0x9DF0, 0x0710, iwl9460_2ac_cfg_soc)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0x9DF0, 0x0A10, iwl9460_2ac_cfg_soc)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0x9DF0, 0x2010, iwl9460_2ac_cfg_soc)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0x9DF0, 0x2A10, iwl9460_2ac_cfg_soc)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0x9DF0, 0x4030, iwl9560_2ac_cfg_soc)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0x9DF0, 0x4034, iwl9560_2ac_cfg_soc)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0x9DF0, 0x40A4, iwl9462_2ac_cfg_soc)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0xA370, 0x0030, iwl9560_2ac_cfg_soc)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0xA370, 0x0034, iwl9560_2ac_cfg_soc)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0xA370, 0x0038, iwl9560_2ac_cfg_soc)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0xA370, 0x003C, iwl9560_2ac_cfg_soc)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0xA370, 0x0060, iwl9460_2ac_cfg_soc)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0xA370, 0x0064, iwl9461_2ac_cfg_soc)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0xA370, 0x00A0, iwl9462_2ac_cfg_soc)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0xA370, 0x00A4, iwl9462_2ac_cfg_soc)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0xA370, 0x0230, iwl9560_2ac_cfg_soc)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0xA370, 0x0234, iwl9560_2ac_cfg_soc)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0xA370, 0x0238, iwl9560_2ac_cfg_soc)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0xA370, 0x023C, iwl9560_2ac_cfg_soc)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0xA370, 0x0260, iwl9461_2ac_cfg_soc)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0xA370, 0x0264, iwl9461_2ac_cfg_soc)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0xA370, 0x02A0, iwl9462_2ac_cfg_soc)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0xA370, 0x02A4, iwl9462_2ac_cfg_soc)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0xA370, 0x1030, iwl9560_2ac_cfg_soc)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0xA370, 0x4030, iwl9560_2ac_cfg_soc)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0xA370, 0x4034, iwl9560_2ac_cfg_soc)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0xA370, 0x40A4, iwl9462_2ac_cfg_soc)},</span>
 
 /* a000 Series */
 	{IWL_PCI_DEVICE(0x2720, 0x0A10, iwla000_2ac_cfg_hr_cdb)},
<span class="p_chunk">@@ -576,8 +655,14 @@</span> <span class="p_context"> static const struct pci_device_id iwl_hw_card_ids[] = {</span>
 	{IWL_PCI_DEVICE(0x2720, 0x0000, iwla000_2ax_cfg_hr)},
 	{IWL_PCI_DEVICE(0x34F0, 0x0070, iwla000_2ax_cfg_hr)},
 	{IWL_PCI_DEVICE(0x2720, 0x0078, iwla000_2ax_cfg_hr)},
<span class="p_del">-	{IWL_PCI_DEVICE(0x2720, 0x0070, iwla000_2ax_cfg_hr)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0x2720, 0x0070, iwla000_2ac_cfg_hr_cdb)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0x2720, 0x0030, iwla000_2ac_cfg_hr_cdb)},</span>
 	{IWL_PCI_DEVICE(0x2720, 0x1080, iwla000_2ax_cfg_hr)},
<span class="p_add">+	{IWL_PCI_DEVICE(0x2720, 0x0090, iwla000_2ac_cfg_hr_cdb)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0x2720, 0x0310, iwla000_2ac_cfg_hr_cdb)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0x40C0, 0x0000, iwla000_2ax_cfg_hr)},</span>
<span class="p_add">+	{IWL_PCI_DEVICE(0x40C0, 0x0A10, iwla000_2ax_cfg_hr)},</span>
<span class="p_add">+</span>
 #endif /* CONFIG_IWLMVM */
 
 	{0}
<span class="p_header">diff --git a/drivers/net/wireless/intersil/p54/main.c b/drivers/net/wireless/intersil/p54/main.c</span>
<span class="p_header">index d5a3bf91a03e..ab6d39e12069 100644</span>
<span class="p_header">--- a/drivers/net/wireless/intersil/p54/main.c</span>
<span class="p_header">+++ b/drivers/net/wireless/intersil/p54/main.c</span>
<span class="p_chunk">@@ -852,12 +852,11 @@</span> <span class="p_context"> void p54_unregister_common(struct ieee80211_hw *dev)</span>
 {
 	struct p54_common *priv = dev-&gt;priv;
 
<span class="p_del">-#ifdef CONFIG_P54_LEDS</span>
<span class="p_del">-	p54_unregister_leds(priv);</span>
<span class="p_del">-#endif /* CONFIG_P54_LEDS */</span>
<span class="p_del">-</span>
 	if (priv-&gt;registered) {
 		priv-&gt;registered = false;
<span class="p_add">+#ifdef CONFIG_P54_LEDS</span>
<span class="p_add">+		p54_unregister_leds(priv);</span>
<span class="p_add">+#endif /* CONFIG_P54_LEDS */</span>
 		ieee80211_unregister_hw(dev);
 	}
 
<span class="p_header">diff --git a/drivers/net/wireless/ralink/rt2x00/rt2x00usb.c b/drivers/net/wireless/ralink/rt2x00/rt2x00usb.c</span>
<span class="p_header">index e2f4f5778267..086aad22743d 100644</span>
<span class="p_header">--- a/drivers/net/wireless/ralink/rt2x00/rt2x00usb.c</span>
<span class="p_header">+++ b/drivers/net/wireless/ralink/rt2x00/rt2x00usb.c</span>
<span class="p_chunk">@@ -57,7 +57,7 @@</span> <span class="p_context"> int rt2x00usb_vendor_request(struct rt2x00_dev *rt2x00dev,</span>
 		if (status &gt;= 0)
 			return 0;
 
<span class="p_del">-		if (status == -ENODEV) {</span>
<span class="p_add">+		if (status == -ENODEV || status == -ENOENT) {</span>
 			/* Device has disappeared. */
 			clear_bit(DEVICE_STATE_PRESENT, &amp;rt2x00dev-&gt;flags);
 			break;
<span class="p_chunk">@@ -321,7 +321,7 @@</span> <span class="p_context"> static bool rt2x00usb_kick_tx_entry(struct queue_entry *entry, void *data)</span>
 
 	status = usb_submit_urb(entry_priv-&gt;urb, GFP_ATOMIC);
 	if (status) {
<span class="p_del">-		if (status == -ENODEV)</span>
<span class="p_add">+		if (status == -ENODEV || status == -ENOENT)</span>
 			clear_bit(DEVICE_STATE_PRESENT, &amp;rt2x00dev-&gt;flags);
 		set_bit(ENTRY_DATA_IO_FAILED, &amp;entry-&gt;flags);
 		rt2x00lib_dmadone(entry);
<span class="p_chunk">@@ -410,7 +410,7 @@</span> <span class="p_context"> static bool rt2x00usb_kick_rx_entry(struct queue_entry *entry, void *data)</span>
 
 	status = usb_submit_urb(entry_priv-&gt;urb, GFP_ATOMIC);
 	if (status) {
<span class="p_del">-		if (status == -ENODEV)</span>
<span class="p_add">+		if (status == -ENODEV || status == -ENOENT)</span>
 			clear_bit(DEVICE_STATE_PRESENT, &amp;rt2x00dev-&gt;flags);
 		set_bit(ENTRY_DATA_IO_FAILED, &amp;entry-&gt;flags);
 		rt2x00lib_dmadone(entry);
<span class="p_header">diff --git a/drivers/net/wireless/realtek/rtlwifi/rtl8192ee/fw.c b/drivers/net/wireless/realtek/rtlwifi/rtl8192ee/fw.c</span>
<span class="p_header">index 7eae27f8e173..f9563ae301ad 100644</span>
<span class="p_header">--- a/drivers/net/wireless/realtek/rtlwifi/rtl8192ee/fw.c</span>
<span class="p_header">+++ b/drivers/net/wireless/realtek/rtlwifi/rtl8192ee/fw.c</span>
<span class="p_chunk">@@ -682,7 +682,7 @@</span> <span class="p_context"> void rtl92ee_set_fw_rsvdpagepkt(struct ieee80211_hw *hw, bool b_dl_finished)</span>
 	struct rtl_priv *rtlpriv = rtl_priv(hw);
 	struct rtl_mac *mac = rtl_mac(rtl_priv(hw));
 	struct sk_buff *skb = NULL;
<span class="p_del">-</span>
<span class="p_add">+	bool rtstatus;</span>
 	u32 totalpacketlen;
 	u8 u1rsvdpageloc[5] = { 0 };
 	bool b_dlok = false;
<span class="p_chunk">@@ -768,7 +768,9 @@</span> <span class="p_context"> void rtl92ee_set_fw_rsvdpagepkt(struct ieee80211_hw *hw, bool b_dl_finished)</span>
 	skb = dev_alloc_skb(totalpacketlen);
 	skb_put_data(skb, &amp;reserved_page_packet, totalpacketlen);
 
<span class="p_del">-	b_dlok = true;</span>
<span class="p_add">+	rtstatus = rtl_cmd_send_packet(hw, skb);</span>
<span class="p_add">+	if (rtstatus)</span>
<span class="p_add">+		b_dlok = true;</span>
 
 	if (b_dlok) {
 		RT_TRACE(rtlpriv, COMP_POWER, DBG_LOUD ,
<span class="p_header">diff --git a/drivers/net/wireless/realtek/rtlwifi/rtl8821ae/hw.c b/drivers/net/wireless/realtek/rtlwifi/rtl8821ae/hw.c</span>
<span class="p_header">index 1d431d4bf6d2..9ac1511de7ba 100644</span>
<span class="p_header">--- a/drivers/net/wireless/realtek/rtlwifi/rtl8821ae/hw.c</span>
<span class="p_header">+++ b/drivers/net/wireless/realtek/rtlwifi/rtl8821ae/hw.c</span>
<span class="p_chunk">@@ -1372,6 +1372,7 @@</span> <span class="p_context"> static void _rtl8821ae_get_wakeup_reason(struct ieee80211_hw *hw)</span>
 
 	ppsc-&gt;wakeup_reason = 0;
 
<span class="p_add">+	do_gettimeofday(&amp;ts);</span>
 	rtlhal-&gt;last_suspend_sec = ts.tv_sec;
 
 	switch (fw_reason) {
<span class="p_header">diff --git a/drivers/nvdimm/dimm.c b/drivers/nvdimm/dimm.c</span>
<span class="p_header">index e0f0e3ce1a32..98466d762c8f 100644</span>
<span class="p_header">--- a/drivers/nvdimm/dimm.c</span>
<span class="p_header">+++ b/drivers/nvdimm/dimm.c</span>
<span class="p_chunk">@@ -68,6 +68,7 @@</span> <span class="p_context"> static int nvdimm_probe(struct device *dev)</span>
 	rc = nd_label_reserve_dpa(ndd);
 	if (ndd-&gt;ns_current &gt;= 0)
 		nvdimm_set_aliasing(dev);
<span class="p_add">+	nvdimm_clear_locked(dev);</span>
 	nvdimm_bus_unlock(dev);
 
 	if (rc)
<span class="p_header">diff --git a/drivers/nvdimm/dimm_devs.c b/drivers/nvdimm/dimm_devs.c</span>
<span class="p_header">index f0d1b7e5de01..5f1385b96b13 100644</span>
<span class="p_header">--- a/drivers/nvdimm/dimm_devs.c</span>
<span class="p_header">+++ b/drivers/nvdimm/dimm_devs.c</span>
<span class="p_chunk">@@ -200,6 +200,13 @@</span> <span class="p_context"> void nvdimm_set_locked(struct device *dev)</span>
 	set_bit(NDD_LOCKED, &amp;nvdimm-&gt;flags);
 }
 
<span class="p_add">+void nvdimm_clear_locked(struct device *dev)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct nvdimm *nvdimm = to_nvdimm(dev);</span>
<span class="p_add">+</span>
<span class="p_add">+	clear_bit(NDD_LOCKED, &amp;nvdimm-&gt;flags);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static void nvdimm_release(struct device *dev)
 {
 	struct nvdimm *nvdimm = to_nvdimm(dev);
<span class="p_header">diff --git a/drivers/nvdimm/label.c b/drivers/nvdimm/label.c</span>
<span class="p_header">index 9c5f108910e3..de66c02f6140 100644</span>
<span class="p_header">--- a/drivers/nvdimm/label.c</span>
<span class="p_header">+++ b/drivers/nvdimm/label.c</span>
<span class="p_chunk">@@ -1050,7 +1050,7 @@</span> <span class="p_context"> static int init_labels(struct nd_mapping *nd_mapping, int num_labels)</span>
 	nsindex = to_namespace_index(ndd, 0);
 	memset(nsindex, 0, ndd-&gt;nsarea.config_size);
 	for (i = 0; i &lt; 2; i++) {
<span class="p_del">-		int rc = nd_label_write_index(ndd, i, i*2, ND_NSINDEX_INIT);</span>
<span class="p_add">+		int rc = nd_label_write_index(ndd, i, 3 - i, ND_NSINDEX_INIT);</span>
 
 		if (rc)
 			return rc;
<span class="p_header">diff --git a/drivers/nvdimm/namespace_devs.c b/drivers/nvdimm/namespace_devs.c</span>
<span class="p_header">index 3e4d1e7998da..0af988739a06 100644</span>
<span class="p_header">--- a/drivers/nvdimm/namespace_devs.c</span>
<span class="p_header">+++ b/drivers/nvdimm/namespace_devs.c</span>
<span class="p_chunk">@@ -1620,7 +1620,7 @@</span> <span class="p_context"> static umode_t namespace_visible(struct kobject *kobj,</span>
 	if (a == &amp;dev_attr_resource.attr) {
 		if (is_namespace_blk(dev))
 			return 0;
<span class="p_del">-		return a-&gt;mode;</span>
<span class="p_add">+		return 0400;</span>
 	}
 
 	if (is_namespace_pmem(dev) || is_namespace_blk(dev)) {
<span class="p_header">diff --git a/drivers/nvdimm/nd.h b/drivers/nvdimm/nd.h</span>
<span class="p_header">index 9c758a91372b..156be00e1f76 100644</span>
<span class="p_header">--- a/drivers/nvdimm/nd.h</span>
<span class="p_header">+++ b/drivers/nvdimm/nd.h</span>
<span class="p_chunk">@@ -254,6 +254,7 @@</span> <span class="p_context"> long nvdimm_clear_poison(struct device *dev, phys_addr_t phys,</span>
 		unsigned int len);
 void nvdimm_set_aliasing(struct device *dev);
 void nvdimm_set_locked(struct device *dev);
<span class="p_add">+void nvdimm_clear_locked(struct device *dev);</span>
 struct nd_btt *to_nd_btt(struct device *dev);
 
 struct nd_gen_sb {
<span class="p_header">diff --git a/drivers/nvdimm/pfn_devs.c b/drivers/nvdimm/pfn_devs.c</span>
<span class="p_header">index 9576c444f0ab..65cc171c721d 100644</span>
<span class="p_header">--- a/drivers/nvdimm/pfn_devs.c</span>
<span class="p_header">+++ b/drivers/nvdimm/pfn_devs.c</span>
<span class="p_chunk">@@ -282,8 +282,16 @@</span> <span class="p_context"> static struct attribute *nd_pfn_attributes[] = {</span>
 	NULL,
 };
 
<span class="p_add">+static umode_t pfn_visible(struct kobject *kobj, struct attribute *a, int n)</span>
<span class="p_add">+{</span>
<span class="p_add">+	if (a == &amp;dev_attr_resource.attr)</span>
<span class="p_add">+		return 0400;</span>
<span class="p_add">+	return a-&gt;mode;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 struct attribute_group nd_pfn_attribute_group = {
 	.attrs = nd_pfn_attributes,
<span class="p_add">+	.is_visible = pfn_visible,</span>
 };
 
 static const struct attribute_group *nd_pfn_attribute_groups[] = {
<span class="p_header">diff --git a/drivers/nvdimm/region_devs.c b/drivers/nvdimm/region_devs.c</span>
<span class="p_header">index 829d760f651c..abaf38c61220 100644</span>
<span class="p_header">--- a/drivers/nvdimm/region_devs.c</span>
<span class="p_header">+++ b/drivers/nvdimm/region_devs.c</span>
<span class="p_chunk">@@ -562,8 +562,12 @@</span> <span class="p_context"> static umode_t region_visible(struct kobject *kobj, struct attribute *a, int n)</span>
 	if (!is_nd_pmem(dev) &amp;&amp; a == &amp;dev_attr_badblocks.attr)
 		return 0;
 
<span class="p_del">-	if (!is_nd_pmem(dev) &amp;&amp; a == &amp;dev_attr_resource.attr)</span>
<span class="p_del">-		return 0;</span>
<span class="p_add">+	if (a == &amp;dev_attr_resource.attr) {</span>
<span class="p_add">+		if (is_nd_pmem(dev))</span>
<span class="p_add">+			return 0400;</span>
<span class="p_add">+		else</span>
<span class="p_add">+			return 0;</span>
<span class="p_add">+	}</span>
 
 	if (a == &amp;dev_attr_deep_flush.attr) {
 		int has_flush = nvdimm_has_flush(nd_region);
<span class="p_header">diff --git a/drivers/pci/host/pci-hyperv.c b/drivers/pci/host/pci-hyperv.c</span>
<span class="p_header">index 0fe3ea164ee5..04dac6a42c9f 100644</span>
<span class="p_header">--- a/drivers/pci/host/pci-hyperv.c</span>
<span class="p_header">+++ b/drivers/pci/host/pci-hyperv.c</span>
<span class="p_chunk">@@ -879,7 +879,7 @@</span> <span class="p_context"> static void hv_irq_unmask(struct irq_data *data)</span>
 	int cpu;
 	u64 res;
 
<span class="p_del">-	dest = irq_data_get_affinity_mask(data);</span>
<span class="p_add">+	dest = irq_data_get_effective_affinity_mask(data);</span>
 	pdev = msi_desc_to_pci_dev(msi_desc);
 	pbus = pdev-&gt;bus;
 	hbus = container_of(pbus-&gt;sysdata, struct hv_pcibus_device, sysdata);
<span class="p_chunk">@@ -1042,6 +1042,7 @@</span> <span class="p_context"> static void hv_compose_msi_msg(struct irq_data *data, struct msi_msg *msg)</span>
 	struct hv_pci_dev *hpdev;
 	struct pci_bus *pbus;
 	struct pci_dev *pdev;
<span class="p_add">+	struct cpumask *dest;</span>
 	struct compose_comp_ctxt comp;
 	struct tran_int_desc *int_desc;
 	struct {
<span class="p_chunk">@@ -1056,6 +1057,7 @@</span> <span class="p_context"> static void hv_compose_msi_msg(struct irq_data *data, struct msi_msg *msg)</span>
 	int ret;
 
 	pdev = msi_desc_to_pci_dev(irq_data_get_msi_desc(data));
<span class="p_add">+	dest = irq_data_get_effective_affinity_mask(data);</span>
 	pbus = pdev-&gt;bus;
 	hbus = container_of(pbus-&gt;sysdata, struct hv_pcibus_device, sysdata);
 	hpdev = get_pcichild_wslot(hbus, devfn_to_wslot(pdev-&gt;devfn));
<span class="p_chunk">@@ -1081,14 +1083,14 @@</span> <span class="p_context"> static void hv_compose_msi_msg(struct irq_data *data, struct msi_msg *msg)</span>
 	switch (pci_protocol_version) {
 	case PCI_PROTOCOL_VERSION_1_1:
 		size = hv_compose_msi_req_v1(&amp;ctxt.int_pkts.v1,
<span class="p_del">-					irq_data_get_affinity_mask(data),</span>
<span class="p_add">+					dest,</span>
 					hpdev-&gt;desc.win_slot.slot,
 					cfg-&gt;vector);
 		break;
 
 	case PCI_PROTOCOL_VERSION_1_2:
 		size = hv_compose_msi_req_v2(&amp;ctxt.int_pkts.v2,
<span class="p_del">-					irq_data_get_affinity_mask(data),</span>
<span class="p_add">+					dest,</span>
 					hpdev-&gt;desc.win_slot.slot,
 					cfg-&gt;vector);
 		break;
<span class="p_header">diff --git a/drivers/pci/pcie/aspm.c b/drivers/pci/pcie/aspm.c</span>
<span class="p_header">index 83e4a892b14b..cae54f8320be 100644</span>
<span class="p_header">--- a/drivers/pci/pcie/aspm.c</span>
<span class="p_header">+++ b/drivers/pci/pcie/aspm.c</span>
<span class="p_chunk">@@ -453,7 +453,7 @@</span> <span class="p_context"> static void aspm_calc_l1ss_info(struct pcie_link_state *link,</span>
 
 	/* Choose the greater of the two T_cmn_mode_rstr_time */
 	val1 = (upreg-&gt;l1ss_cap &gt;&gt; 8) &amp; 0xFF;
<span class="p_del">-	val2 = (upreg-&gt;l1ss_cap &gt;&gt; 8) &amp; 0xFF;</span>
<span class="p_add">+	val2 = (dwreg-&gt;l1ss_cap &gt;&gt; 8) &amp; 0xFF;</span>
 	if (val1 &gt; val2)
 		link-&gt;l1ss.ctl1 |= val1 &lt;&lt; 8;
 	else
<span class="p_chunk">@@ -658,7 +658,7 @@</span> <span class="p_context"> static void pcie_config_aspm_l1ss(struct pcie_link_state *link, u32 state)</span>
 					0xFF00, link-&gt;l1ss.ctl1);
 
 		/* Program LTR L1.2 threshold in both ports */
<span class="p_del">-		pci_clear_and_set_dword(parent,	dw_cap_ptr + PCI_L1SS_CTL1,</span>
<span class="p_add">+		pci_clear_and_set_dword(parent,	up_cap_ptr + PCI_L1SS_CTL1,</span>
 					0xE3FF0000, link-&gt;l1ss.ctl1);
 		pci_clear_and_set_dword(child, dw_cap_ptr + PCI_L1SS_CTL1,
 					0xE3FF0000, link-&gt;l1ss.ctl1);
<span class="p_header">diff --git a/drivers/pci/quirks.c b/drivers/pci/quirks.c</span>
<span class="p_header">index 911b3b65c8b2..f66f9375177c 100644</span>
<span class="p_header">--- a/drivers/pci/quirks.c</span>
<span class="p_header">+++ b/drivers/pci/quirks.c</span>
<span class="p_chunk">@@ -4212,17 +4212,32 @@</span> <span class="p_context"> static int pci_quirk_amd_sb_acs(struct pci_dev *dev, u16 acs_flags)</span>
 #endif
 }
 
<span class="p_add">+static bool pci_quirk_cavium_acs_match(struct pci_dev *dev)</span>
<span class="p_add">+{</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Effectively selects all downstream ports for whole ThunderX 1</span>
<span class="p_add">+	 * family by 0xf800 mask (which represents 8 SoCs), while the lower</span>
<span class="p_add">+	 * bits of device ID are used to indicate which subdevice is used</span>
<span class="p_add">+	 * within the SoC.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	return (pci_is_pcie(dev) &amp;&amp;</span>
<span class="p_add">+		(pci_pcie_type(dev) == PCI_EXP_TYPE_ROOT_PORT) &amp;&amp;</span>
<span class="p_add">+		((dev-&gt;device &amp; 0xf800) == 0xa000));</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static int pci_quirk_cavium_acs(struct pci_dev *dev, u16 acs_flags)
 {
 	/*
<span class="p_del">-	 * Cavium devices matching this quirk do not perform peer-to-peer</span>
<span class="p_del">-	 * with other functions, allowing masking out these bits as if they</span>
<span class="p_del">-	 * were unimplemented in the ACS capability.</span>
<span class="p_add">+	 * Cavium root ports don&#39;t advertise an ACS capability.  However,</span>
<span class="p_add">+	 * the RTL internally implements similar protection as if ACS had</span>
<span class="p_add">+	 * Request Redirection, Completion Redirection, Source Validation,</span>
<span class="p_add">+	 * and Upstream Forwarding features enabled.  Assert that the</span>
<span class="p_add">+	 * hardware implements and enables equivalent ACS functionality for</span>
<span class="p_add">+	 * these flags.</span>
 	 */
<span class="p_del">-	acs_flags &amp;= ~(PCI_ACS_SV | PCI_ACS_TB | PCI_ACS_RR |</span>
<span class="p_del">-		       PCI_ACS_CR | PCI_ACS_UF | PCI_ACS_DT);</span>
<span class="p_add">+	acs_flags &amp;= ~(PCI_ACS_RR | PCI_ACS_CR | PCI_ACS_SV | PCI_ACS_UF);</span>
 
<span class="p_del">-	if (!((dev-&gt;device &gt;= 0xa000) &amp;&amp; (dev-&gt;device &lt;= 0xa0ff)))</span>
<span class="p_add">+	if (!pci_quirk_cavium_acs_match(dev))</span>
 		return -ENOTTY;
 
 	return acs_flags ? 0 : 1;
<span class="p_header">diff --git a/drivers/scsi/lpfc/lpfc_attr.c b/drivers/scsi/lpfc/lpfc_attr.c</span>
<span class="p_header">index c17677f494af..dc6519b2c53a 100644</span>
<span class="p_header">--- a/drivers/scsi/lpfc/lpfc_attr.c</span>
<span class="p_header">+++ b/drivers/scsi/lpfc/lpfc_attr.c</span>
<span class="p_chunk">@@ -3134,7 +3134,8 @@</span> <span class="p_context"> lpfc_txq_hw_show(struct device *dev, struct device_attribute *attr, char *buf)</span>
 	struct lpfc_hba   *phba = ((struct lpfc_vport *) shost-&gt;hostdata)-&gt;phba;
 	struct lpfc_sli_ring *pring = lpfc_phba_elsring(phba);
 
<span class="p_del">-	return snprintf(buf, PAGE_SIZE, &quot;%d\n&quot;, pring-&gt;txq_max);</span>
<span class="p_add">+	return snprintf(buf, PAGE_SIZE, &quot;%d\n&quot;,</span>
<span class="p_add">+			pring ? pring-&gt;txq_max : 0);</span>
 }
 
 static DEVICE_ATTR(txq_hw, S_IRUGO,
<span class="p_chunk">@@ -3147,7 +3148,8 @@</span> <span class="p_context"> lpfc_txcmplq_hw_show(struct device *dev, struct device_attribute *attr,</span>
 	struct lpfc_hba   *phba = ((struct lpfc_vport *) shost-&gt;hostdata)-&gt;phba;
 	struct lpfc_sli_ring *pring = lpfc_phba_elsring(phba);
 
<span class="p_del">-	return snprintf(buf, PAGE_SIZE, &quot;%d\n&quot;, pring-&gt;txcmplq_max);</span>
<span class="p_add">+	return snprintf(buf, PAGE_SIZE, &quot;%d\n&quot;,</span>
<span class="p_add">+			pring ? pring-&gt;txcmplq_max : 0);</span>
 }
 
 static DEVICE_ATTR(txcmplq_hw, S_IRUGO,
<span class="p_header">diff --git a/drivers/scsi/lpfc/lpfc_bsg.c b/drivers/scsi/lpfc/lpfc_bsg.c</span>
<span class="p_header">index fe9e1c079c20..d89816222b23 100644</span>
<span class="p_header">--- a/drivers/scsi/lpfc/lpfc_bsg.c</span>
<span class="p_header">+++ b/drivers/scsi/lpfc/lpfc_bsg.c</span>
<span class="p_chunk">@@ -2911,7 +2911,7 @@</span> <span class="p_context"> static int lpfcdiag_loop_post_rxbufs(struct lpfc_hba *phba, uint16_t rxxri,</span>
 		}
 	}
 
<span class="p_del">-	if (!cmdiocbq || !rxbmp || !rxbpl || !rxbuffer) {</span>
<span class="p_add">+	if (!cmdiocbq || !rxbmp || !rxbpl || !rxbuffer || !pring) {</span>
 		ret_val = -ENOMEM;
 		goto err_post_rxbufs_exit;
 	}
<span class="p_chunk">@@ -5421,6 +5421,8 @@</span> <span class="p_context"> lpfc_bsg_timeout(struct bsg_job *job)</span>
 	struct lpfc_iocbq *check_iocb, *next_iocb;
 
 	pring = lpfc_phba_elsring(phba);
<span class="p_add">+	if (unlikely(!pring))</span>
<span class="p_add">+		return -EIO;</span>
 
 	/* if job&#39;s driver data is NULL, the command completed or is in the
 	 * the process of completing.  In this case, return status to request
<span class="p_header">diff --git a/drivers/scsi/lpfc/lpfc_els.c b/drivers/scsi/lpfc/lpfc_els.c</span>
<span class="p_header">index 468a66371de9..3ebf6ccba6e6 100644</span>
<span class="p_header">--- a/drivers/scsi/lpfc/lpfc_els.c</span>
<span class="p_header">+++ b/drivers/scsi/lpfc/lpfc_els.c</span>
<span class="p_chunk">@@ -7430,6 +7430,8 @@</span> <span class="p_context"> lpfc_els_timeout_handler(struct lpfc_vport *vport)</span>
 	timeout = (uint32_t)(phba-&gt;fc_ratov &lt;&lt; 1);
 
 	pring = lpfc_phba_elsring(phba);
<span class="p_add">+	if (unlikely(!pring))</span>
<span class="p_add">+		return;</span>
 
 	if ((phba-&gt;pport-&gt;load_flag &amp; FC_UNLOADING))
 		return;
<span class="p_chunk">@@ -9310,6 +9312,9 @@</span> <span class="p_context"> void lpfc_fabric_abort_nport(struct lpfc_nodelist *ndlp)</span>
 
 	pring = lpfc_phba_elsring(phba);
 
<span class="p_add">+	if (unlikely(!pring))</span>
<span class="p_add">+		return;</span>
<span class="p_add">+</span>
 	spin_lock_irq(&amp;phba-&gt;hbalock);
 	list_for_each_entry_safe(piocb, tmp_iocb, &amp;phba-&gt;fabric_iocb_list,
 				 list) {
<span class="p_chunk">@@ -9416,7 +9421,7 @@</span> <span class="p_context"> lpfc_sli4_els_xri_aborted(struct lpfc_hba *phba,</span>
 				rxid, 1);
 
 			/* Check if TXQ queue needs to be serviced */
<span class="p_del">-			if (!(list_empty(&amp;pring-&gt;txq)))</span>
<span class="p_add">+			if (pring &amp;&amp; !list_empty(&amp;pring-&gt;txq))</span>
 				lpfc_worker_wake_up(phba);
 			return;
 		}
<span class="p_header">diff --git a/drivers/scsi/lpfc/lpfc_hbadisc.c b/drivers/scsi/lpfc/lpfc_hbadisc.c</span>
<span class="p_header">index 20808349a80e..499df9d17339 100644</span>
<span class="p_header">--- a/drivers/scsi/lpfc/lpfc_hbadisc.c</span>
<span class="p_header">+++ b/drivers/scsi/lpfc/lpfc_hbadisc.c</span>
<span class="p_chunk">@@ -3324,7 +3324,8 @@</span> <span class="p_context"> lpfc_mbx_cmpl_read_topology(struct lpfc_hba *phba, LPFC_MBOXQ_t *pmb)</span>
 
 	/* Unblock ELS traffic */
 	pring = lpfc_phba_elsring(phba);
<span class="p_del">-	pring-&gt;flag &amp;= ~LPFC_STOP_IOCB_EVENT;</span>
<span class="p_add">+	if (pring)</span>
<span class="p_add">+		pring-&gt;flag &amp;= ~LPFC_STOP_IOCB_EVENT;</span>
 
 	/* Check for error */
 	if (mb-&gt;mbxStatus) {
<span class="p_chunk">@@ -5430,6 +5431,8 @@</span> <span class="p_context"> lpfc_free_tx(struct lpfc_hba *phba, struct lpfc_nodelist *ndlp)</span>
 
 	psli = &amp;phba-&gt;sli;
 	pring = lpfc_phba_elsring(phba);
<span class="p_add">+	if (unlikely(!pring))</span>
<span class="p_add">+		return;</span>
 
 	/* Error matching iocb on txq or txcmplq
 	 * First check the txq.
<span class="p_header">diff --git a/drivers/scsi/lpfc/lpfc_init.c b/drivers/scsi/lpfc/lpfc_init.c</span>
<span class="p_header">index 100bc4c8798d..6acf1bb1d320 100644</span>
<span class="p_header">--- a/drivers/scsi/lpfc/lpfc_init.c</span>
<span class="p_header">+++ b/drivers/scsi/lpfc/lpfc_init.c</span>
<span class="p_chunk">@@ -11404,6 +11404,13 @@</span> <span class="p_context"> lpfc_pci_remove_one_s4(struct pci_dev *pdev)</span>
 	/* Remove FC host and then SCSI host with the physical port */
 	fc_remove_host(shost);
 	scsi_remove_host(shost);
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Bring down the SLI Layer. This step disables all interrupts,</span>
<span class="p_add">+	 * clears the rings, discards all mailbox commands, and resets</span>
<span class="p_add">+	 * the HBA FCoE function.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	lpfc_debugfs_terminate(vport);</span>
<span class="p_add">+	lpfc_sli4_hba_unset(phba);</span>
 
 	/* Perform ndlp cleanup on the physical port.  The nvme and nvmet
 	 * localports are destroyed after to cleanup all transport memory.
<span class="p_chunk">@@ -11412,14 +11419,8 @@</span> <span class="p_context"> lpfc_pci_remove_one_s4(struct pci_dev *pdev)</span>
 	lpfc_nvmet_destroy_targetport(phba);
 	lpfc_nvme_destroy_localport(vport);
 
<span class="p_del">-	/*</span>
<span class="p_del">-	 * Bring down the SLI Layer. This step disables all interrupts,</span>
<span class="p_del">-	 * clears the rings, discards all mailbox commands, and resets</span>
<span class="p_del">-	 * the HBA FCoE function.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	lpfc_debugfs_terminate(vport);</span>
<span class="p_del">-	lpfc_sli4_hba_unset(phba);</span>
 
<span class="p_add">+	lpfc_stop_hba_timers(phba);</span>
 	spin_lock_irq(&amp;phba-&gt;hbalock);
 	list_del_init(&amp;vport-&gt;listentry);
 	spin_unlock_irq(&amp;phba-&gt;hbalock);
<span class="p_header">diff --git a/drivers/scsi/lpfc/lpfc_nportdisc.c b/drivers/scsi/lpfc/lpfc_nportdisc.c</span>
<span class="p_header">index f3ad7cac355d..b6957d944b9a 100644</span>
<span class="p_header">--- a/drivers/scsi/lpfc/lpfc_nportdisc.c</span>
<span class="p_header">+++ b/drivers/scsi/lpfc/lpfc_nportdisc.c</span>
<span class="p_chunk">@@ -216,7 +216,7 @@</span> <span class="p_context"> lpfc_els_abort(struct lpfc_hba *phba, struct lpfc_nodelist *ndlp)</span>
 	pring = lpfc_phba_elsring(phba);
 
 	/* In case of error recovery path, we might have a NULL pring here */
<span class="p_del">-	if (!pring)</span>
<span class="p_add">+	if (unlikely(!pring))</span>
 		return;
 
 	/* Abort outstanding I/O on NPort &lt;nlp_DID&gt; */
<span class="p_header">diff --git a/drivers/scsi/lpfc/lpfc_nvmet.c b/drivers/scsi/lpfc/lpfc_nvmet.c</span>
<span class="p_header">index 0b7c1a49e203..3c5b054a56ac 100644</span>
<span class="p_header">--- a/drivers/scsi/lpfc/lpfc_nvmet.c</span>
<span class="p_header">+++ b/drivers/scsi/lpfc/lpfc_nvmet.c</span>
<span class="p_chunk">@@ -1138,9 +1138,14 @@</span> <span class="p_context"> lpfc_nvmet_create_targetport(struct lpfc_hba *phba)</span>
 #endif
 	if (error) {
 		lpfc_printf_log(phba, KERN_ERR, LOG_NVME_DISC,
<span class="p_del">-				&quot;6025 Cannot register NVME targetport &quot;</span>
<span class="p_del">-				&quot;x%x\n&quot;, error);</span>
<span class="p_add">+				&quot;6025 Cannot register NVME targetport x%x: &quot;</span>
<span class="p_add">+				&quot;portnm %llx nodenm %llx segs %d qs %d\n&quot;,</span>
<span class="p_add">+				error,</span>
<span class="p_add">+				pinfo.port_name, pinfo.node_name,</span>
<span class="p_add">+				lpfc_tgttemplate.max_sgl_segments,</span>
<span class="p_add">+				lpfc_tgttemplate.max_hw_queues);</span>
 		phba-&gt;targetport = NULL;
<span class="p_add">+		phba-&gt;nvmet_support = 0;</span>
 
 		lpfc_nvmet_cleanup_io_context(phba);
 
<span class="p_chunk">@@ -1152,9 +1157,11 @@</span> <span class="p_context"> lpfc_nvmet_create_targetport(struct lpfc_hba *phba)</span>
 		lpfc_printf_log(phba, KERN_INFO, LOG_NVME_DISC,
 				&quot;6026 Registered NVME &quot;
 				&quot;targetport: %p, private %p &quot;
<span class="p_del">-				&quot;portnm %llx nodenm %llx\n&quot;,</span>
<span class="p_add">+				&quot;portnm %llx nodenm %llx segs %d qs %d\n&quot;,</span>
 				phba-&gt;targetport, tgtp,
<span class="p_del">-				pinfo.port_name, pinfo.node_name);</span>
<span class="p_add">+				pinfo.port_name, pinfo.node_name,</span>
<span class="p_add">+				lpfc_tgttemplate.max_sgl_segments,</span>
<span class="p_add">+				lpfc_tgttemplate.max_hw_queues);</span>
 
 		atomic_set(&amp;tgtp-&gt;rcv_ls_req_in, 0);
 		atomic_set(&amp;tgtp-&gt;rcv_ls_req_out, 0);
<span class="p_header">diff --git a/drivers/scsi/lpfc/lpfc_sli.c b/drivers/scsi/lpfc/lpfc_sli.c</span>
<span class="p_header">index 8b119f87b51d..455f3ce9fda9 100644</span>
<span class="p_header">--- a/drivers/scsi/lpfc/lpfc_sli.c</span>
<span class="p_header">+++ b/drivers/scsi/lpfc/lpfc_sli.c</span>
<span class="p_chunk">@@ -9396,10 +9396,13 @@</span> <span class="p_context"> lpfc_sli4_calc_ring(struct lpfc_hba *phba, struct lpfc_iocbq *piocb)</span>
 			 * for abort iocb hba_wqidx should already
 			 * be setup based on what work queue we used.
 			 */
<span class="p_del">-			if (!(piocb-&gt;iocb_flag &amp; LPFC_USE_FCPWQIDX))</span>
<span class="p_add">+			if (!(piocb-&gt;iocb_flag &amp; LPFC_USE_FCPWQIDX)) {</span>
 				piocb-&gt;hba_wqidx =
 					lpfc_sli4_scmd_to_wqidx_distr(phba,
 							      piocb-&gt;context1);
<span class="p_add">+				piocb-&gt;hba_wqidx = piocb-&gt;hba_wqidx %</span>
<span class="p_add">+					phba-&gt;cfg_fcp_io_channel;</span>
<span class="p_add">+			}</span>
 			return phba-&gt;sli4_hba.fcp_wq[piocb-&gt;hba_wqidx]-&gt;pring;
 		} else {
 			if (unlikely(!phba-&gt;sli4_hba.oas_wq))
<span class="p_chunk">@@ -10632,6 +10635,14 @@</span> <span class="p_context"> lpfc_sli_issue_abort_iotag(struct lpfc_hba *phba, struct lpfc_sli_ring *pring,</span>
 	    (cmdiocb-&gt;iocb_flag &amp; LPFC_DRIVER_ABORTED) != 0)
 		return 0;
 
<span class="p_add">+	if (!pring) {</span>
<span class="p_add">+		if (cmdiocb-&gt;iocb_flag &amp; LPFC_IO_FABRIC)</span>
<span class="p_add">+			cmdiocb-&gt;fabric_iocb_cmpl = lpfc_ignore_els_cmpl;</span>
<span class="p_add">+		else</span>
<span class="p_add">+			cmdiocb-&gt;iocb_cmpl = lpfc_ignore_els_cmpl;</span>
<span class="p_add">+		goto abort_iotag_exit;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
 	/*
 	 * If we&#39;re unloading, don&#39;t abort iocb on the ELS ring, but change
 	 * the callback so that nothing happens when it finishes.
<span class="p_chunk">@@ -12500,6 +12511,8 @@</span> <span class="p_context"> lpfc_sli4_els_wcqe_to_rspiocbq(struct lpfc_hba *phba,</span>
 	unsigned long iflags;
 
 	pring = lpfc_phba_elsring(phba);
<span class="p_add">+	if (unlikely(!pring))</span>
<span class="p_add">+		return NULL;</span>
 
 	wcqe = &amp;irspiocbq-&gt;cq_event.cqe.wcqe_cmpl;
 	spin_lock_irqsave(&amp;pring-&gt;ring_lock, iflags);
<span class="p_chunk">@@ -12507,19 +12520,21 @@</span> <span class="p_context"> lpfc_sli4_els_wcqe_to_rspiocbq(struct lpfc_hba *phba,</span>
 	/* Look up the ELS command IOCB and create pseudo response IOCB */
 	cmdiocbq = lpfc_sli_iocbq_lookup_by_tag(phba, pring,
 				bf_get(lpfc_wcqe_c_request_tag, wcqe));
<span class="p_del">-	/* Put the iocb back on the txcmplq */</span>
<span class="p_del">-	lpfc_sli_ringtxcmpl_put(phba, pring, cmdiocbq);</span>
<span class="p_del">-	spin_unlock_irqrestore(&amp;pring-&gt;ring_lock, iflags);</span>
<span class="p_del">-</span>
 	if (unlikely(!cmdiocbq)) {
<span class="p_add">+		spin_unlock_irqrestore(&amp;pring-&gt;ring_lock, iflags);</span>
 		lpfc_printf_log(phba, KERN_WARNING, LOG_SLI,
 				&quot;0386 ELS complete with no corresponding &quot;
<span class="p_del">-				&quot;cmdiocb: iotag (%d)\n&quot;,</span>
<span class="p_del">-				bf_get(lpfc_wcqe_c_request_tag, wcqe));</span>
<span class="p_add">+				&quot;cmdiocb: 0x%x 0x%x 0x%x 0x%x\n&quot;,</span>
<span class="p_add">+				wcqe-&gt;word0, wcqe-&gt;total_data_placed,</span>
<span class="p_add">+				wcqe-&gt;parameter, wcqe-&gt;word3);</span>
 		lpfc_sli_release_iocbq(phba, irspiocbq);
 		return NULL;
 	}
 
<span class="p_add">+	/* Put the iocb back on the txcmplq */</span>
<span class="p_add">+	lpfc_sli_ringtxcmpl_put(phba, pring, cmdiocbq);</span>
<span class="p_add">+	spin_unlock_irqrestore(&amp;pring-&gt;ring_lock, iflags);</span>
<span class="p_add">+</span>
 	/* Fake the irspiocbq and copy necessary response information */
 	lpfc_sli4_iocb_param_transfer(phba, irspiocbq, cmdiocbq, wcqe);
 
<span class="p_chunk">@@ -17137,7 +17152,8 @@</span> <span class="p_context"> lpfc_sli4_handle_mds_loopback(struct lpfc_vport *vport,</span>
 	if (pcmd &amp;&amp; pcmd-&gt;virt)
 		dma_pool_free(phba-&gt;lpfc_drb_pool, pcmd-&gt;virt, pcmd-&gt;phys);
 	kfree(pcmd);
<span class="p_del">-	lpfc_sli_release_iocbq(phba, iocbq);</span>
<span class="p_add">+	if (iocbq)</span>
<span class="p_add">+		lpfc_sli_release_iocbq(phba, iocbq);</span>
 	lpfc_in_buf_free(phba, &amp;dmabuf-&gt;dbuf);
 }
 
<span class="p_chunk">@@ -18691,6 +18707,8 @@</span> <span class="p_context"> lpfc_drain_txq(struct lpfc_hba *phba)</span>
 	uint32_t txq_cnt = 0;
 
 	pring = lpfc_phba_elsring(phba);
<span class="p_add">+	if (unlikely(!pring))</span>
<span class="p_add">+		return 0;</span>
 
 	spin_lock_irqsave(&amp;pring-&gt;ring_lock, iflags);
 	list_for_each_entry(piocbq, &amp;pring-&gt;txq, list) {
<span class="p_header">diff --git a/drivers/scsi/qla2xxx/qla_os.c b/drivers/scsi/qla2xxx/qla_os.c</span>
<span class="p_header">index dce42a416876..6eaaa326e508 100644</span>
<span class="p_header">--- a/drivers/scsi/qla2xxx/qla_os.c</span>
<span class="p_header">+++ b/drivers/scsi/qla2xxx/qla_os.c</span>
<span class="p_chunk">@@ -388,7 +388,7 @@</span> <span class="p_context"> static void qla_init_base_qpair(struct scsi_qla_host *vha, struct req_que *req,</span>
 	INIT_LIST_HEAD(&amp;ha-&gt;base_qpair-&gt;nvme_done_list);
 	ha-&gt;base_qpair-&gt;enable_class_2 = ql2xenableclass2;
 	/* init qpair to this cpu. Will adjust at run time. */
<span class="p_del">-	qla_cpu_update(rsp-&gt;qpair, smp_processor_id());</span>
<span class="p_add">+	qla_cpu_update(rsp-&gt;qpair, raw_smp_processor_id());</span>
 	ha-&gt;base_qpair-&gt;pdev = ha-&gt;pdev;
 
 	if (IS_QLA27XX(ha) || IS_QLA83XX(ha))
<span class="p_header">diff --git a/drivers/scsi/sd_zbc.c b/drivers/scsi/sd_zbc.c</span>
<span class="p_header">index 8aa54779aac1..2eb61d54bbb4 100644</span>
<span class="p_header">--- a/drivers/scsi/sd_zbc.c</span>
<span class="p_header">+++ b/drivers/scsi/sd_zbc.c</span>
<span class="p_chunk">@@ -375,15 +375,15 @@</span> <span class="p_context"> static int sd_zbc_read_zoned_characteristics(struct scsi_disk *sdkp,</span>
 	if (sdkp-&gt;device-&gt;type != TYPE_ZBC) {
 		/* Host-aware */
 		sdkp-&gt;urswrz = 1;
<span class="p_del">-		sdkp-&gt;zones_optimal_open = get_unaligned_be64(&amp;buf[8]);</span>
<span class="p_del">-		sdkp-&gt;zones_optimal_nonseq = get_unaligned_be64(&amp;buf[12]);</span>
<span class="p_add">+		sdkp-&gt;zones_optimal_open = get_unaligned_be32(&amp;buf[8]);</span>
<span class="p_add">+		sdkp-&gt;zones_optimal_nonseq = get_unaligned_be32(&amp;buf[12]);</span>
 		sdkp-&gt;zones_max_open = 0;
 	} else {
 		/* Host-managed */
 		sdkp-&gt;urswrz = buf[4] &amp; 1;
 		sdkp-&gt;zones_optimal_open = 0;
 		sdkp-&gt;zones_optimal_nonseq = 0;
<span class="p_del">-		sdkp-&gt;zones_max_open = get_unaligned_be64(&amp;buf[16]);</span>
<span class="p_add">+		sdkp-&gt;zones_max_open = get_unaligned_be32(&amp;buf[16]);</span>
 	}
 
 	return 0;
<span class="p_header">diff --git a/drivers/target/iscsi/iscsi_target.c b/drivers/target/iscsi/iscsi_target.c</span>
<span class="p_header">index 5001261f5d69..d9ba4ee2c62b 100644</span>
<span class="p_header">--- a/drivers/target/iscsi/iscsi_target.c</span>
<span class="p_header">+++ b/drivers/target/iscsi/iscsi_target.c</span>
<span class="p_chunk">@@ -1960,7 +1960,6 @@</span> <span class="p_context"> iscsit_handle_task_mgt_cmd(struct iscsi_conn *conn, struct iscsi_cmd *cmd,</span>
 	struct iscsi_tmr_req *tmr_req;
 	struct iscsi_tm *hdr;
 	int out_of_order_cmdsn = 0, ret;
<span class="p_del">-	bool sess_ref = false;</span>
 	u8 function, tcm_function = TMR_UNKNOWN;
 
 	hdr			= (struct iscsi_tm *) buf;
<span class="p_chunk">@@ -1993,22 +1992,23 @@</span> <span class="p_context"> iscsit_handle_task_mgt_cmd(struct iscsi_conn *conn, struct iscsi_cmd *cmd,</span>
 
 	cmd-&gt;data_direction = DMA_NONE;
 	cmd-&gt;tmr_req = kzalloc(sizeof(*cmd-&gt;tmr_req), GFP_KERNEL);
<span class="p_del">-	if (!cmd-&gt;tmr_req)</span>
<span class="p_add">+	if (!cmd-&gt;tmr_req) {</span>
 		return iscsit_add_reject_cmd(cmd,
 					     ISCSI_REASON_BOOKMARK_NO_RESOURCES,
 					     buf);
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	transport_init_se_cmd(&amp;cmd-&gt;se_cmd, &amp;iscsi_ops,</span>
<span class="p_add">+			      conn-&gt;sess-&gt;se_sess, 0, DMA_NONE,</span>
<span class="p_add">+			      TCM_SIMPLE_TAG, cmd-&gt;sense_buffer + 2);</span>
<span class="p_add">+</span>
<span class="p_add">+	target_get_sess_cmd(&amp;cmd-&gt;se_cmd, true);</span>
 
 	/*
 	 * TASK_REASSIGN for ERL=2 / connection stays inside of
 	 * LIO-Target $FABRIC_MOD
 	 */
 	if (function != ISCSI_TM_FUNC_TASK_REASSIGN) {
<span class="p_del">-		transport_init_se_cmd(&amp;cmd-&gt;se_cmd, &amp;iscsi_ops,</span>
<span class="p_del">-				      conn-&gt;sess-&gt;se_sess, 0, DMA_NONE,</span>
<span class="p_del">-				      TCM_SIMPLE_TAG, cmd-&gt;sense_buffer + 2);</span>
<span class="p_del">-</span>
<span class="p_del">-		target_get_sess_cmd(&amp;cmd-&gt;se_cmd, true);</span>
<span class="p_del">-		sess_ref = true;</span>
 		tcm_function = iscsit_convert_tmf(function);
 		if (tcm_function == TMR_UNKNOWN) {
 			pr_err(&quot;Unknown iSCSI TMR Function:&quot;
<span class="p_chunk">@@ -2099,12 +2099,14 @@</span> <span class="p_context"> iscsit_handle_task_mgt_cmd(struct iscsi_conn *conn, struct iscsi_cmd *cmd,</span>
 
 	if (!(hdr-&gt;opcode &amp; ISCSI_OP_IMMEDIATE)) {
 		int cmdsn_ret = iscsit_sequence_cmd(conn, cmd, buf, hdr-&gt;cmdsn);
<span class="p_del">-		if (cmdsn_ret == CMDSN_HIGHER_THAN_EXP)</span>
<span class="p_add">+		if (cmdsn_ret == CMDSN_HIGHER_THAN_EXP) {</span>
 			out_of_order_cmdsn = 1;
<span class="p_del">-		else if (cmdsn_ret == CMDSN_LOWER_THAN_EXP)</span>
<span class="p_add">+		} else if (cmdsn_ret == CMDSN_LOWER_THAN_EXP) {</span>
<span class="p_add">+			target_put_sess_cmd(&amp;cmd-&gt;se_cmd);</span>
 			return 0;
<span class="p_del">-		else if (cmdsn_ret == CMDSN_ERROR_CANNOT_RECOVER)</span>
<span class="p_add">+		} else if (cmdsn_ret == CMDSN_ERROR_CANNOT_RECOVER) {</span>
 			return -1;
<span class="p_add">+		}</span>
 	}
 	iscsit_ack_from_expstatsn(conn, be32_to_cpu(hdr-&gt;exp_statsn));
 
<span class="p_chunk">@@ -2124,12 +2126,8 @@</span> <span class="p_context"> iscsit_handle_task_mgt_cmd(struct iscsi_conn *conn, struct iscsi_cmd *cmd,</span>
 	 * For connection recovery, this is also the default action for
 	 * TMR TASK_REASSIGN.
 	 */
<span class="p_del">-	if (sess_ref) {</span>
<span class="p_del">-		pr_debug(&quot;Handle TMR, using sess_ref=true check\n&quot;);</span>
<span class="p_del">-		target_put_sess_cmd(&amp;cmd-&gt;se_cmd);</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
 	iscsit_add_cmd_to_response_queue(cmd, conn, cmd-&gt;i_state);
<span class="p_add">+	target_put_sess_cmd(&amp;cmd-&gt;se_cmd);</span>
 	return 0;
 }
 EXPORT_SYMBOL(iscsit_handle_task_mgt_cmd);
<span class="p_header">diff --git a/drivers/target/target_core_pr.c b/drivers/target/target_core_pr.c</span>
<span class="p_header">index dd2cd8048582..9f25c9c6f67d 100644</span>
<span class="p_header">--- a/drivers/target/target_core_pr.c</span>
<span class="p_header">+++ b/drivers/target/target_core_pr.c</span>
<span class="p_chunk">@@ -4011,6 +4011,7 @@</span> <span class="p_context"> core_scsi3_pri_read_full_status(struct se_cmd *cmd)</span>
 		 * Set the ADDITIONAL DESCRIPTOR LENGTH
 		 */
 		put_unaligned_be32(desc_len, &amp;buf[off]);
<span class="p_add">+		off += 4;</span>
 		/*
 		 * Size of full desctipor header minus TransportID
 		 * containing $FABRIC_MOD specific) initiator device/port
<span class="p_header">diff --git a/drivers/target/target_core_tmr.c b/drivers/target/target_core_tmr.c</span>
<span class="p_header">index e22847bd79b9..9c7bc1ca341a 100644</span>
<span class="p_header">--- a/drivers/target/target_core_tmr.c</span>
<span class="p_header">+++ b/drivers/target/target_core_tmr.c</span>
<span class="p_chunk">@@ -133,6 +133,15 @@</span> <span class="p_context"> static bool __target_check_io_state(struct se_cmd *se_cmd,</span>
 		spin_unlock(&amp;se_cmd-&gt;t_state_lock);
 		return false;
 	}
<span class="p_add">+	if (se_cmd-&gt;transport_state &amp; CMD_T_PRE_EXECUTE) {</span>
<span class="p_add">+		if (se_cmd-&gt;scsi_status) {</span>
<span class="p_add">+			pr_debug(&quot;Attempted to abort io tag: %llu early failure&quot;</span>
<span class="p_add">+				 &quot; status: 0x%02x\n&quot;, se_cmd-&gt;tag,</span>
<span class="p_add">+				 se_cmd-&gt;scsi_status);</span>
<span class="p_add">+			spin_unlock(&amp;se_cmd-&gt;t_state_lock);</span>
<span class="p_add">+			return false;</span>
<span class="p_add">+		}</span>
<span class="p_add">+	}</span>
 	if (sess-&gt;sess_tearing_down || se_cmd-&gt;cmd_wait_set) {
 		pr_debug(&quot;Attempted to abort io tag: %llu already shutdown,&quot;
 			&quot; skipping\n&quot;, se_cmd-&gt;tag);
<span class="p_chunk">@@ -217,7 +226,8 @@</span> <span class="p_context"> static void core_tmr_drain_tmr_list(</span>
 	 * LUN_RESET tmr..
 	 */
 	spin_lock_irqsave(&amp;dev-&gt;se_tmr_lock, flags);
<span class="p_del">-	list_del_init(&amp;tmr-&gt;tmr_list);</span>
<span class="p_add">+	if (tmr)</span>
<span class="p_add">+		list_del_init(&amp;tmr-&gt;tmr_list);</span>
 	list_for_each_entry_safe(tmr_p, tmr_pp, &amp;dev-&gt;dev_tmr_list, tmr_list) {
 		cmd = tmr_p-&gt;task_cmd;
 		if (!cmd) {
<span class="p_header">diff --git a/drivers/target/target_core_transport.c b/drivers/target/target_core_transport.c</span>
<span class="p_header">index 836d552b0385..e6d51135d105 100644</span>
<span class="p_header">--- a/drivers/target/target_core_transport.c</span>
<span class="p_header">+++ b/drivers/target/target_core_transport.c</span>
<span class="p_chunk">@@ -1730,9 +1730,6 @@</span> <span class="p_context"> void transport_generic_request_failure(struct se_cmd *cmd,</span>
 {
 	int ret = 0, post_ret = 0;
 
<span class="p_del">-	if (transport_check_aborted_status(cmd, 1))</span>
<span class="p_del">-		return;</span>
<span class="p_del">-</span>
 	pr_debug(&quot;-----[ Storage Engine Exception; sense_reason %d\n&quot;,
 		 sense_reason);
 	target_show_cmd(&quot;-----[ &quot;, cmd);
<span class="p_chunk">@@ -1741,6 +1738,7 @@</span> <span class="p_context"> void transport_generic_request_failure(struct se_cmd *cmd,</span>
 	 * For SAM Task Attribute emulation for failed struct se_cmd
 	 */
 	transport_complete_task_attr(cmd);
<span class="p_add">+</span>
 	/*
 	 * Handle special case for COMPARE_AND_WRITE failure, where the
 	 * callback is expected to drop the per device -&gt;caw_sem.
<span class="p_chunk">@@ -1749,6 +1747,9 @@</span> <span class="p_context"> void transport_generic_request_failure(struct se_cmd *cmd,</span>
 	     cmd-&gt;transport_complete_callback)
 		cmd-&gt;transport_complete_callback(cmd, false, &amp;post_ret);
 
<span class="p_add">+	if (transport_check_aborted_status(cmd, 1))</span>
<span class="p_add">+		return;</span>
<span class="p_add">+</span>
 	switch (sense_reason) {
 	case TCM_NON_EXISTENT_LUN:
 	case TCM_UNSUPPORTED_SCSI_OPCODE:
<span class="p_chunk">@@ -1973,6 +1974,7 @@</span> <span class="p_context"> void target_execute_cmd(struct se_cmd *cmd)</span>
 	}
 
 	cmd-&gt;t_state = TRANSPORT_PROCESSING;
<span class="p_add">+	cmd-&gt;transport_state &amp;= ~CMD_T_PRE_EXECUTE;</span>
 	cmd-&gt;transport_state |= CMD_T_ACTIVE | CMD_T_SENT;
 	spin_unlock_irq(&amp;cmd-&gt;t_state_lock);
 
<span class="p_chunk">@@ -2010,6 +2012,8 @@</span> <span class="p_context"> static void target_restart_delayed_cmds(struct se_device *dev)</span>
 		list_del(&amp;cmd-&gt;se_delayed_node);
 		spin_unlock(&amp;dev-&gt;delayed_cmd_lock);
 
<span class="p_add">+		cmd-&gt;transport_state |= CMD_T_SENT;</span>
<span class="p_add">+</span>
 		__target_execute_cmd(cmd, true);
 
 		if (cmd-&gt;sam_task_attr == TCM_ORDERED_TAG)
<span class="p_chunk">@@ -2045,6 +2049,8 @@</span> <span class="p_context"> static void transport_complete_task_attr(struct se_cmd *cmd)</span>
 		pr_debug(&quot;Incremented dev_cur_ordered_id: %u for ORDERED\n&quot;,
 			 dev-&gt;dev_cur_ordered_id);
 	}
<span class="p_add">+	cmd-&gt;se_cmd_flags &amp;= ~SCF_TASK_ATTR_SET;</span>
<span class="p_add">+</span>
 restart:
 	target_restart_delayed_cmds(dev);
 }
<span class="p_chunk">@@ -2570,7 +2576,20 @@</span> <span class="p_context"> EXPORT_SYMBOL(transport_generic_new_cmd);</span>
 
 static void transport_write_pending_qf(struct se_cmd *cmd)
 {
<span class="p_add">+	unsigned long flags;</span>
 	int ret;
<span class="p_add">+	bool stop;</span>
<span class="p_add">+</span>
<span class="p_add">+	spin_lock_irqsave(&amp;cmd-&gt;t_state_lock, flags);</span>
<span class="p_add">+	stop = (cmd-&gt;transport_state &amp; (CMD_T_STOP | CMD_T_ABORTED));</span>
<span class="p_add">+	spin_unlock_irqrestore(&amp;cmd-&gt;t_state_lock, flags);</span>
<span class="p_add">+</span>
<span class="p_add">+	if (stop) {</span>
<span class="p_add">+		pr_debug(&quot;%s:%d CMD_T_STOP|CMD_T_ABORTED for ITT: 0x%08llx\n&quot;,</span>
<span class="p_add">+			__func__, __LINE__, cmd-&gt;tag);</span>
<span class="p_add">+		complete_all(&amp;cmd-&gt;t_transport_stop_comp);</span>
<span class="p_add">+		return;</span>
<span class="p_add">+	}</span>
 
 	ret = cmd-&gt;se_tfo-&gt;write_pending(cmd);
 	if (ret) {
<span class="p_chunk">@@ -2664,6 +2683,7 @@</span> <span class="p_context"> int target_get_sess_cmd(struct se_cmd *se_cmd, bool ack_kref)</span>
 		ret = -ESHUTDOWN;
 		goto out;
 	}
<span class="p_add">+	se_cmd-&gt;transport_state |= CMD_T_PRE_EXECUTE;</span>
 	list_add_tail(&amp;se_cmd-&gt;se_cmd_list, &amp;se_sess-&gt;sess_cmd_list);
 out:
 	spin_unlock_irqrestore(&amp;se_sess-&gt;sess_cmd_lock, flags);
<span class="p_header">diff --git a/drivers/tty/serdev/core.c b/drivers/tty/serdev/core.c</span>
<span class="p_header">index c68fb3a8ea1c..97db76afced2 100644</span>
<span class="p_header">--- a/drivers/tty/serdev/core.c</span>
<span class="p_header">+++ b/drivers/tty/serdev/core.c</span>
<span class="p_chunk">@@ -65,21 +65,32 @@</span> <span class="p_context"> static int serdev_uevent(struct device *dev, struct kobj_uevent_env *env)</span>
  */
 int serdev_device_add(struct serdev_device *serdev)
 {
<span class="p_add">+	struct serdev_controller *ctrl = serdev-&gt;ctrl;</span>
 	struct device *parent = serdev-&gt;dev.parent;
 	int err;
 
 	dev_set_name(&amp;serdev-&gt;dev, &quot;%s-%d&quot;, dev_name(parent), serdev-&gt;nr);
 
<span class="p_add">+	/* Only a single slave device is currently supported. */</span>
<span class="p_add">+	if (ctrl-&gt;serdev) {</span>
<span class="p_add">+		dev_err(&amp;serdev-&gt;dev, &quot;controller busy\n&quot;);</span>
<span class="p_add">+		return -EBUSY;</span>
<span class="p_add">+	}</span>
<span class="p_add">+	ctrl-&gt;serdev = serdev;</span>
<span class="p_add">+</span>
 	err = device_add(&amp;serdev-&gt;dev);
 	if (err &lt; 0) {
 		dev_err(&amp;serdev-&gt;dev, &quot;Can&#39;t add %s, status %d\n&quot;,
 			dev_name(&amp;serdev-&gt;dev), err);
<span class="p_del">-		goto err_device_add;</span>
<span class="p_add">+		goto err_clear_serdev;</span>
 	}
 
 	dev_dbg(&amp;serdev-&gt;dev, &quot;device %s registered\n&quot;, dev_name(&amp;serdev-&gt;dev));
 
<span class="p_del">-err_device_add:</span>
<span class="p_add">+	return 0;</span>
<span class="p_add">+</span>
<span class="p_add">+err_clear_serdev:</span>
<span class="p_add">+	ctrl-&gt;serdev = NULL;</span>
 	return err;
 }
 EXPORT_SYMBOL_GPL(serdev_device_add);
<span class="p_chunk">@@ -90,7 +101,10 @@</span> <span class="p_context"> EXPORT_SYMBOL_GPL(serdev_device_add);</span>
  */
 void serdev_device_remove(struct serdev_device *serdev)
 {
<span class="p_add">+	struct serdev_controller *ctrl = serdev-&gt;ctrl;</span>
<span class="p_add">+</span>
 	device_unregister(&amp;serdev-&gt;dev);
<span class="p_add">+	ctrl-&gt;serdev = NULL;</span>
 }
 EXPORT_SYMBOL_GPL(serdev_device_remove);
 
<span class="p_chunk">@@ -295,7 +309,6 @@</span> <span class="p_context"> struct serdev_device *serdev_device_alloc(struct serdev_controller *ctrl)</span>
 		return NULL;
 
 	serdev-&gt;ctrl = ctrl;
<span class="p_del">-	ctrl-&gt;serdev = serdev;</span>
 	device_initialize(&amp;serdev-&gt;dev);
 	serdev-&gt;dev.parent = &amp;ctrl-&gt;dev;
 	serdev-&gt;dev.bus = &amp;serdev_bus_type;
<span class="p_header">diff --git a/drivers/vhost/scsi.c b/drivers/vhost/scsi.c</span>
<span class="p_header">index 046f6d280af5..e47c5bc3ddca 100644</span>
<span class="p_header">--- a/drivers/vhost/scsi.c</span>
<span class="p_header">+++ b/drivers/vhost/scsi.c</span>
<span class="p_chunk">@@ -688,6 +688,7 @@</span> <span class="p_context"> vhost_scsi_iov_to_sgl(struct vhost_scsi_cmd *cmd, bool write,</span>
 		      struct scatterlist *sg, int sg_count)
 {
 	size_t off = iter-&gt;iov_offset;
<span class="p_add">+	struct scatterlist *p = sg;</span>
 	int i, ret;
 
 	for (i = 0; i &lt; iter-&gt;nr_segs; i++) {
<span class="p_chunk">@@ -696,8 +697,8 @@</span> <span class="p_context"> vhost_scsi_iov_to_sgl(struct vhost_scsi_cmd *cmd, bool write,</span>
 
 		ret = vhost_scsi_map_to_sgl(cmd, base, len, sg, write);
 		if (ret &lt; 0) {
<span class="p_del">-			for (i = 0; i &lt; sg_count; i++) {</span>
<span class="p_del">-				struct page *page = sg_page(&amp;sg[i]);</span>
<span class="p_add">+			while (p &lt; sg) {</span>
<span class="p_add">+				struct page *page = sg_page(p++);</span>
 				if (page)
 					put_page(page);
 			}
<span class="p_header">diff --git a/fs/9p/vfs_inode.c b/fs/9p/vfs_inode.c</span>
<span class="p_header">index 2a5de610dd8f..bdabb2765d1b 100644</span>
<span class="p_header">--- a/fs/9p/vfs_inode.c</span>
<span class="p_header">+++ b/fs/9p/vfs_inode.c</span>
<span class="p_chunk">@@ -483,6 +483,9 @@</span> <span class="p_context"> static int v9fs_test_inode(struct inode *inode, void *data)</span>
 
 	if (v9inode-&gt;qid.type != st-&gt;qid.type)
 		return 0;
<span class="p_add">+</span>
<span class="p_add">+	if (v9inode-&gt;qid.path != st-&gt;qid.path)</span>
<span class="p_add">+		return 0;</span>
 	return 1;
 }
 
<span class="p_header">diff --git a/fs/9p/vfs_inode_dotl.c b/fs/9p/vfs_inode_dotl.c</span>
<span class="p_header">index 70f9887c59a9..7f6ae21a27b3 100644</span>
<span class="p_header">--- a/fs/9p/vfs_inode_dotl.c</span>
<span class="p_header">+++ b/fs/9p/vfs_inode_dotl.c</span>
<span class="p_chunk">@@ -87,6 +87,9 @@</span> <span class="p_context"> static int v9fs_test_inode_dotl(struct inode *inode, void *data)</span>
 
 	if (v9inode-&gt;qid.type != st-&gt;qid.type)
 		return 0;
<span class="p_add">+</span>
<span class="p_add">+	if (v9inode-&gt;qid.path != st-&gt;qid.path)</span>
<span class="p_add">+		return 0;</span>
 	return 1;
 }
 
<span class="p_header">diff --git a/fs/autofs4/waitq.c b/fs/autofs4/waitq.c</span>
<span class="p_header">index 4ac49d038bf3..8fc41705c7cd 100644</span>
<span class="p_header">--- a/fs/autofs4/waitq.c</span>
<span class="p_header">+++ b/fs/autofs4/waitq.c</span>
<span class="p_chunk">@@ -81,7 +81,8 @@</span> <span class="p_context"> static int autofs4_write(struct autofs_sb_info *sbi,</span>
 		spin_unlock_irqrestore(&amp;current-&gt;sighand-&gt;siglock, flags);
 	}
 
<span class="p_del">-	return (bytes &gt; 0);</span>
<span class="p_add">+	/* if &#39;wr&#39; returned 0 (impossible) we assume -EIO (safe) */</span>
<span class="p_add">+	return bytes == 0 ? 0 : wr &lt; 0 ? wr : -EIO;</span>
 }
 
 static void autofs4_notify_daemon(struct autofs_sb_info *sbi,
<span class="p_chunk">@@ -95,6 +96,7 @@</span> <span class="p_context"> static void autofs4_notify_daemon(struct autofs_sb_info *sbi,</span>
 	} pkt;
 	struct file *pipe = NULL;
 	size_t pktsz;
<span class="p_add">+	int ret;</span>
 
 	pr_debug(&quot;wait id = 0x%08lx, name = %.*s, type=%d\n&quot;,
 		 (unsigned long) wq-&gt;wait_queue_token,
<span class="p_chunk">@@ -169,7 +171,18 @@</span> <span class="p_context"> static void autofs4_notify_daemon(struct autofs_sb_info *sbi,</span>
 	mutex_unlock(&amp;sbi-&gt;wq_mutex);
 
 	if (autofs4_write(sbi, pipe, &amp;pkt, pktsz))
<span class="p_add">+	switch (ret = autofs4_write(sbi, pipe, &amp;pkt, pktsz)) {</span>
<span class="p_add">+	case 0:</span>
<span class="p_add">+		break;</span>
<span class="p_add">+	case -ENOMEM:</span>
<span class="p_add">+	case -ERESTARTSYS:</span>
<span class="p_add">+		/* Just fail this one */</span>
<span class="p_add">+		autofs4_wait_release(sbi, wq-&gt;wait_queue_token, ret);</span>
<span class="p_add">+		break;</span>
<span class="p_add">+	default:</span>
 		autofs4_catatonic_mode(sbi);
<span class="p_add">+		break;</span>
<span class="p_add">+	}</span>
 	fput(pipe);
 }
 
<span class="p_header">diff --git a/fs/btrfs/extent-tree.c b/fs/btrfs/extent-tree.c</span>
<span class="p_header">index e2d7e86b51d1..08698105fa4a 100644</span>
<span class="p_header">--- a/fs/btrfs/extent-tree.c</span>
<span class="p_header">+++ b/fs/btrfs/extent-tree.c</span>
<span class="p_chunk">@@ -4919,6 +4919,13 @@</span> <span class="p_context"> static void shrink_delalloc(struct btrfs_fs_info *fs_info, u64 to_reclaim,</span>
 	}
 }
 
<span class="p_add">+struct reserve_ticket {</span>
<span class="p_add">+	u64 bytes;</span>
<span class="p_add">+	int error;</span>
<span class="p_add">+	struct list_head list;</span>
<span class="p_add">+	wait_queue_head_t wait;</span>
<span class="p_add">+};</span>
<span class="p_add">+</span>
 /**
  * maybe_commit_transaction - possibly commit the transaction if its ok to
  * @root - the root we&#39;re allocating for
<span class="p_chunk">@@ -4930,18 +4937,29 @@</span> <span class="p_context"> static void shrink_delalloc(struct btrfs_fs_info *fs_info, u64 to_reclaim,</span>
  * will return -ENOSPC.
  */
 static int may_commit_transaction(struct btrfs_fs_info *fs_info,
<span class="p_del">-				  struct btrfs_space_info *space_info,</span>
<span class="p_del">-				  u64 bytes, int force)</span>
<span class="p_add">+				  struct btrfs_space_info *space_info)</span>
 {
<span class="p_add">+	struct reserve_ticket *ticket = NULL;</span>
 	struct btrfs_block_rsv *delayed_rsv = &amp;fs_info-&gt;delayed_block_rsv;
 	struct btrfs_trans_handle *trans;
<span class="p_add">+	u64 bytes;</span>
 
 	trans = (struct btrfs_trans_handle *)current-&gt;journal_info;
 	if (trans)
 		return -EAGAIN;
 
<span class="p_del">-	if (force)</span>
<span class="p_del">-		goto commit;</span>
<span class="p_add">+	spin_lock(&amp;space_info-&gt;lock);</span>
<span class="p_add">+	if (!list_empty(&amp;space_info-&gt;priority_tickets))</span>
<span class="p_add">+		ticket = list_first_entry(&amp;space_info-&gt;priority_tickets,</span>
<span class="p_add">+					  struct reserve_ticket, list);</span>
<span class="p_add">+	else if (!list_empty(&amp;space_info-&gt;tickets))</span>
<span class="p_add">+		ticket = list_first_entry(&amp;space_info-&gt;tickets,</span>
<span class="p_add">+					  struct reserve_ticket, list);</span>
<span class="p_add">+	bytes = (ticket) ? ticket-&gt;bytes : 0;</span>
<span class="p_add">+	spin_unlock(&amp;space_info-&gt;lock);</span>
<span class="p_add">+</span>
<span class="p_add">+	if (!bytes)</span>
<span class="p_add">+		return 0;</span>
 
 	/* See if there is enough pinned space to make this reservation */
 	if (percpu_counter_compare(&amp;space_info-&gt;total_bytes_pinned,
<span class="p_chunk">@@ -4956,8 +4974,12 @@</span> <span class="p_context"> static int may_commit_transaction(struct btrfs_fs_info *fs_info,</span>
 		return -ENOSPC;
 
 	spin_lock(&amp;delayed_rsv-&gt;lock);
<span class="p_add">+	if (delayed_rsv-&gt;size &gt; bytes)</span>
<span class="p_add">+		bytes = 0;</span>
<span class="p_add">+	else</span>
<span class="p_add">+		bytes -= delayed_rsv-&gt;size;</span>
 	if (percpu_counter_compare(&amp;space_info-&gt;total_bytes_pinned,
<span class="p_del">-				   bytes - delayed_rsv-&gt;size) &lt; 0) {</span>
<span class="p_add">+				   bytes) &lt; 0) {</span>
 		spin_unlock(&amp;delayed_rsv-&gt;lock);
 		return -ENOSPC;
 	}
<span class="p_chunk">@@ -4971,13 +4993,6 @@</span> <span class="p_context"> static int may_commit_transaction(struct btrfs_fs_info *fs_info,</span>
 	return btrfs_commit_transaction(trans);
 }
 
<span class="p_del">-struct reserve_ticket {</span>
<span class="p_del">-	u64 bytes;</span>
<span class="p_del">-	int error;</span>
<span class="p_del">-	struct list_head list;</span>
<span class="p_del">-	wait_queue_head_t wait;</span>
<span class="p_del">-};</span>
<span class="p_del">-</span>
 /*
  * Try to flush some data based on policy set by @state. This is only advisory
  * and may fail for various reasons. The caller is supposed to examine the
<span class="p_chunk">@@ -5027,8 +5042,7 @@</span> <span class="p_context"> static void flush_space(struct btrfs_fs_info *fs_info,</span>
 			ret = 0;
 		break;
 	case COMMIT_TRANS:
<span class="p_del">-		ret = may_commit_transaction(fs_info, space_info,</span>
<span class="p_del">-					     num_bytes, 0);</span>
<span class="p_add">+		ret = may_commit_transaction(fs_info, space_info);</span>
 		break;
 	default:
 		ret = -ENOSPC;
<span class="p_header">diff --git a/fs/buffer.c b/fs/buffer.c</span>
<span class="p_header">index 170df856bdb9..b96f3b98a6ef 100644</span>
<span class="p_header">--- a/fs/buffer.c</span>
<span class="p_header">+++ b/fs/buffer.c</span>
<span class="p_chunk">@@ -3055,8 +3055,16 @@</span> <span class="p_context"> void guard_bio_eod(int op, struct bio *bio)</span>
 	sector_t maxsector;
 	struct bio_vec *bvec = &amp;bio-&gt;bi_io_vec[bio-&gt;bi_vcnt - 1];
 	unsigned truncated_bytes;
<span class="p_add">+	struct hd_struct *part;</span>
<span class="p_add">+</span>
<span class="p_add">+	rcu_read_lock();</span>
<span class="p_add">+	part = __disk_get_part(bio-&gt;bi_disk, bio-&gt;bi_partno);</span>
<span class="p_add">+	if (part)</span>
<span class="p_add">+		maxsector = part_nr_sects_read(part);</span>
<span class="p_add">+	else</span>
<span class="p_add">+		maxsector = get_capacity(bio-&gt;bi_disk);</span>
<span class="p_add">+	rcu_read_unlock();</span>
 
<span class="p_del">-	maxsector = get_capacity(bio-&gt;bi_disk);</span>
 	if (!maxsector)
 		return;
 
<span class="p_header">diff --git a/fs/crypto/crypto.c b/fs/crypto/crypto.c</span>
<span class="p_header">index c7835df7e7b8..d262a93d9b31 100644</span>
<span class="p_header">--- a/fs/crypto/crypto.c</span>
<span class="p_header">+++ b/fs/crypto/crypto.c</span>
<span class="p_chunk">@@ -410,11 +410,8 @@</span> <span class="p_context"> int fscrypt_initialize(unsigned int cop_flags)</span>
 {
 	int i, res = -ENOMEM;
 
<span class="p_del">-	/*</span>
<span class="p_del">-	 * No need to allocate a bounce page pool if there already is one or</span>
<span class="p_del">-	 * this FS won&#39;t use it.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	if (cop_flags &amp; FS_CFLG_OWN_PAGES || fscrypt_bounce_page_pool)</span>
<span class="p_add">+	/* No need to allocate a bounce page pool if this FS won&#39;t use it. */</span>
<span class="p_add">+	if (cop_flags &amp; FS_CFLG_OWN_PAGES)</span>
 		return 0;
 
 	mutex_lock(&amp;fscrypt_init_mutex);
<span class="p_header">diff --git a/fs/dax.c b/fs/dax.c</span>
<span class="p_header">index f001d8c72a06..191306cd8b6b 100644</span>
<span class="p_header">--- a/fs/dax.c</span>
<span class="p_header">+++ b/fs/dax.c</span>
<span class="p_chunk">@@ -1327,7 +1327,7 @@</span> <span class="p_context"> static int dax_iomap_pmd_fault(struct vm_fault *vmf,</span>
 	 * this is a reliable test.
 	 */
 	pgoff = linear_page_index(vma, pmd_addr);
<span class="p_del">-	max_pgoff = (i_size_read(inode) - 1) &gt;&gt; PAGE_SHIFT;</span>
<span class="p_add">+	max_pgoff = DIV_ROUND_UP(i_size_read(inode), PAGE_SIZE);</span>
 
 	trace_dax_pmd_fault(inode, vmf, max_pgoff, 0);
 
<span class="p_chunk">@@ -1351,13 +1351,13 @@</span> <span class="p_context"> static int dax_iomap_pmd_fault(struct vm_fault *vmf,</span>
 	if ((pmd_addr + PMD_SIZE) &gt; vma-&gt;vm_end)
 		goto fallback;
 
<span class="p_del">-	if (pgoff &gt; max_pgoff) {</span>
<span class="p_add">+	if (pgoff &gt;= max_pgoff) {</span>
 		result = VM_FAULT_SIGBUS;
 		goto out;
 	}
 
 	/* If the PMD would extend beyond the file size */
<span class="p_del">-	if ((pgoff | PG_PMD_COLOUR) &gt; max_pgoff)</span>
<span class="p_add">+	if ((pgoff | PG_PMD_COLOUR) &gt;= max_pgoff)</span>
 		goto fallback;
 
 	/*
<span class="p_header">diff --git a/fs/ecryptfs/messaging.c b/fs/ecryptfs/messaging.c</span>
<span class="p_header">index 286f10b0363b..4f457d5c4933 100644</span>
<span class="p_header">--- a/fs/ecryptfs/messaging.c</span>
<span class="p_header">+++ b/fs/ecryptfs/messaging.c</span>
<span class="p_chunk">@@ -442,15 +442,16 @@</span> <span class="p_context"> void ecryptfs_release_messaging(void)</span>
 	}
 	if (ecryptfs_daemon_hash) {
 		struct ecryptfs_daemon *daemon;
<span class="p_add">+		struct hlist_node *n;</span>
 		int i;
 
 		mutex_lock(&amp;ecryptfs_daemon_hash_mux);
 		for (i = 0; i &lt; (1 &lt;&lt; ecryptfs_hash_bits); i++) {
 			int rc;
 
<span class="p_del">-			hlist_for_each_entry(daemon,</span>
<span class="p_del">-					     &amp;ecryptfs_daemon_hash[i],</span>
<span class="p_del">-					     euid_chain) {</span>
<span class="p_add">+			hlist_for_each_entry_safe(daemon, n,</span>
<span class="p_add">+						  &amp;ecryptfs_daemon_hash[i],</span>
<span class="p_add">+						  euid_chain) {</span>
 				rc = ecryptfs_exorcise_daemon(daemon);
 				if (rc)
 					printk(KERN_ERR &quot;%s: Error whilst &quot;
<span class="p_header">diff --git a/fs/ext4/extents.c b/fs/ext4/extents.c</span>
<span class="p_header">index 97f0fd06728d..07bca11749d4 100644</span>
<span class="p_header">--- a/fs/ext4/extents.c</span>
<span class="p_header">+++ b/fs/ext4/extents.c</span>
<span class="p_chunk">@@ -4794,7 +4794,8 @@</span> <span class="p_context"> static long ext4_zero_range(struct file *file, loff_t offset,</span>
 	}
 
 	if (!(mode &amp; FALLOC_FL_KEEP_SIZE) &amp;&amp;
<span class="p_del">-	     offset + len &gt; i_size_read(inode)) {</span>
<span class="p_add">+	    (offset + len &gt; i_size_read(inode) ||</span>
<span class="p_add">+	     offset + len &gt; EXT4_I(inode)-&gt;i_disksize)) {</span>
 		new_size = offset + len;
 		ret = inode_newsize_ok(inode, new_size);
 		if (ret)
<span class="p_chunk">@@ -4965,7 +4966,8 @@</span> <span class="p_context"> long ext4_fallocate(struct file *file, int mode, loff_t offset, loff_t len)</span>
 	}
 
 	if (!(mode &amp; FALLOC_FL_KEEP_SIZE) &amp;&amp;
<span class="p_del">-	     offset + len &gt; i_size_read(inode)) {</span>
<span class="p_add">+	    (offset + len &gt; i_size_read(inode) ||</span>
<span class="p_add">+	     offset + len &gt; EXT4_I(inode)-&gt;i_disksize)) {</span>
 		new_size = offset + len;
 		ret = inode_newsize_ok(inode, new_size);
 		if (ret)
<span class="p_header">diff --git a/fs/ext4/inline.c b/fs/ext4/inline.c</span>
<span class="p_header">index 28c5c3abddb3..fd9501977f1c 100644</span>
<span class="p_header">--- a/fs/ext4/inline.c</span>
<span class="p_header">+++ b/fs/ext4/inline.c</span>
<span class="p_chunk">@@ -302,11 +302,6 @@</span> <span class="p_context"> static int ext4_create_inline_data(handle_t *handle,</span>
 	EXT4_I(inode)-&gt;i_inline_size = len + EXT4_MIN_INLINE_DATA_SIZE;
 	ext4_clear_inode_flag(inode, EXT4_INODE_EXTENTS);
 	ext4_set_inode_flag(inode, EXT4_INODE_INLINE_DATA);
<span class="p_del">-	/*</span>
<span class="p_del">-	 * Propagate changes to inode-&gt;i_flags as well - e.g. S_DAX may</span>
<span class="p_del">-	 * get cleared</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	ext4_set_inode_flags(inode);</span>
 	get_bh(is.iloc.bh);
 	error = ext4_mark_iloc_dirty(handle, inode, &amp;is.iloc);
 
<span class="p_chunk">@@ -451,11 +446,6 @@</span> <span class="p_context"> static int ext4_destroy_inline_data_nolock(handle_t *handle,</span>
 		}
 	}
 	ext4_clear_inode_flag(inode, EXT4_INODE_INLINE_DATA);
<span class="p_del">-	/*</span>
<span class="p_del">-	 * Propagate changes to inode-&gt;i_flags as well - e.g. S_DAX may</span>
<span class="p_del">-	 * get set.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	ext4_set_inode_flags(inode);</span>
 
 	get_bh(is.iloc.bh);
 	error = ext4_mark_iloc_dirty(handle, inode, &amp;is.iloc);
<span class="p_header">diff --git a/fs/ext4/inode.c b/fs/ext4/inode.c</span>
<span class="p_header">index 90afeb7293a6..38eb621edd80 100644</span>
<span class="p_header">--- a/fs/ext4/inode.c</span>
<span class="p_header">+++ b/fs/ext4/inode.c</span>
<span class="p_chunk">@@ -5967,11 +5967,6 @@</span> <span class="p_context"> int ext4_change_inode_journal_flag(struct inode *inode, int val)</span>
 		ext4_clear_inode_flag(inode, EXT4_INODE_JOURNAL_DATA);
 	}
 	ext4_set_aops(inode);
<span class="p_del">-	/*</span>
<span class="p_del">-	 * Update inode-&gt;i_flags after EXT4_INODE_JOURNAL_DATA was updated.</span>
<span class="p_del">-	 * E.g. S_DAX may get cleared / set.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	ext4_set_inode_flags(inode);</span>
 
 	jbd2_journal_unlock_updates(journal);
 	percpu_up_write(&amp;sbi-&gt;s_journal_flag_rwsem);
<span class="p_header">diff --git a/fs/ext4/ioctl.c b/fs/ext4/ioctl.c</span>
<span class="p_header">index 75d83471f65c..d97f40396765 100644</span>
<span class="p_header">--- a/fs/ext4/ioctl.c</span>
<span class="p_header">+++ b/fs/ext4/ioctl.c</span>
<span class="p_chunk">@@ -291,10 +291,20 @@</span> <span class="p_context"> static int ext4_ioctl_setflags(struct inode *inode,</span>
 	if (err)
 		goto flags_out;
 
<span class="p_del">-	if ((jflag ^ oldflags) &amp; (EXT4_JOURNAL_DATA_FL))</span>
<span class="p_add">+	if ((jflag ^ oldflags) &amp; (EXT4_JOURNAL_DATA_FL)) {</span>
<span class="p_add">+		/*</span>
<span class="p_add">+		 * Changes to the journaling mode can cause unsafe changes to</span>
<span class="p_add">+		 * S_DAX if we are using the DAX mount option.</span>
<span class="p_add">+		 */</span>
<span class="p_add">+		if (test_opt(inode-&gt;i_sb, DAX)) {</span>
<span class="p_add">+			err = -EBUSY;</span>
<span class="p_add">+			goto flags_out;</span>
<span class="p_add">+		}</span>
<span class="p_add">+</span>
 		err = ext4_change_inode_journal_flag(inode, jflag);
<span class="p_del">-	if (err)</span>
<span class="p_del">-		goto flags_out;</span>
<span class="p_add">+		if (err)</span>
<span class="p_add">+			goto flags_out;</span>
<span class="p_add">+	}</span>
 	if (migrate) {
 		if (flags &amp; EXT4_EXTENTS_FL)
 			err = ext4_ext_migrate(inode);
<span class="p_header">diff --git a/fs/ext4/super.c b/fs/ext4/super.c</span>
<span class="p_header">index b0915b734a38..f29351c66610 100644</span>
<span class="p_header">--- a/fs/ext4/super.c</span>
<span class="p_header">+++ b/fs/ext4/super.c</span>
<span class="p_chunk">@@ -3708,6 +3708,11 @@</span> <span class="p_context"> static int ext4_fill_super(struct super_block *sb, void *data, int silent)</span>
 	}
 
 	if (sbi-&gt;s_mount_opt &amp; EXT4_MOUNT_DAX) {
<span class="p_add">+		if (ext4_has_feature_inline_data(sb)) {</span>
<span class="p_add">+			ext4_msg(sb, KERN_ERR, &quot;Cannot use DAX on a filesystem&quot;</span>
<span class="p_add">+					&quot; that may contain inline data&quot;);</span>
<span class="p_add">+			goto failed_mount;</span>
<span class="p_add">+		}</span>
 		err = bdev_dax_supported(sb, blocksize);
 		if (err)
 			goto failed_mount;
<span class="p_header">diff --git a/fs/f2fs/file.c b/fs/f2fs/file.c</span>
<span class="p_header">index 517e112c8a9a..6ce467872376 100644</span>
<span class="p_header">--- a/fs/f2fs/file.c</span>
<span class="p_header">+++ b/fs/f2fs/file.c</span>
<span class="p_chunk">@@ -683,6 +683,12 @@</span> <span class="p_context"> int f2fs_getattr(const struct path *path, struct kstat *stat,</span>
 				  STATX_ATTR_NODUMP);
 
 	generic_fillattr(inode, stat);
<span class="p_add">+</span>
<span class="p_add">+	/* we need to show initial sectors used for inline_data/dentries */</span>
<span class="p_add">+	if ((S_ISREG(inode-&gt;i_mode) &amp;&amp; f2fs_has_inline_data(inode)) ||</span>
<span class="p_add">+					f2fs_has_inline_dentry(inode))</span>
<span class="p_add">+		stat-&gt;blocks += (stat-&gt;size + 511) &gt;&gt; 9;</span>
<span class="p_add">+</span>
 	return 0;
 }
 
<span class="p_header">diff --git a/fs/isofs/isofs.h b/fs/isofs/isofs.h</span>
<span class="p_header">index 57d4c3e2e94a..8e42b4fbefdc 100644</span>
<span class="p_header">--- a/fs/isofs/isofs.h</span>
<span class="p_header">+++ b/fs/isofs/isofs.h</span>
<span class="p_chunk">@@ -107,7 +107,7 @@</span> <span class="p_context"> static inline unsigned int isonum_733(char *p)</span>
 	/* Ignore bigendian datum due to broken mastering programs */
 	return get_unaligned_le32(p);
 }
<span class="p_del">-extern int iso_date(char *, int);</span>
<span class="p_add">+extern int iso_date(u8 *, int);</span>
 
 struct inode;		/* To make gcc happy */
 
<span class="p_header">diff --git a/fs/isofs/rock.h b/fs/isofs/rock.h</span>
<span class="p_header">index ef03625431bb..ac5cc587d718 100644</span>
<span class="p_header">--- a/fs/isofs/rock.h</span>
<span class="p_header">+++ b/fs/isofs/rock.h</span>
<span class="p_chunk">@@ -66,7 +66,7 @@</span> <span class="p_context"> struct RR_PL_s {</span>
 };
 
 struct stamp {
<span class="p_del">-	char time[7];</span>
<span class="p_add">+	__u8 time[7];		/* actually 6 unsigned, 1 signed */</span>
 } __attribute__ ((packed));
 
 struct RR_TF_s {
<span class="p_header">diff --git a/fs/isofs/util.c b/fs/isofs/util.c</span>
<span class="p_header">index 42544bf0e222..e88dba721661 100644</span>
<span class="p_header">--- a/fs/isofs/util.c</span>
<span class="p_header">+++ b/fs/isofs/util.c</span>
<span class="p_chunk">@@ -16,7 +16,7 @@</span> <span class="p_context"></span>
  * to GMT.  Thus  we should always be correct.
  */
 
<span class="p_del">-int iso_date(char * p, int flag)</span>
<span class="p_add">+int iso_date(u8 *p, int flag)</span>
 {
 	int year, month, day, hour, minute, second, tz;
 	int crtime;
<span class="p_header">diff --git a/fs/lockd/svc.c b/fs/lockd/svc.c</span>
<span class="p_header">index b995bdc13976..f04ecfc7ece0 100644</span>
<span class="p_header">--- a/fs/lockd/svc.c</span>
<span class="p_header">+++ b/fs/lockd/svc.c</span>
<span class="p_chunk">@@ -369,6 +369,7 @@</span> <span class="p_context"> static int lockd_start_svc(struct svc_serv *serv)</span>
 		printk(KERN_WARNING
 			&quot;lockd_up: svc_rqst allocation failed, error=%d\n&quot;,
 			error);
<span class="p_add">+		lockd_unregister_notifiers();</span>
 		goto out_rqst;
 	}
 
<span class="p_chunk">@@ -459,13 +460,16 @@</span> <span class="p_context"> int lockd_up(struct net *net)</span>
 	}
 
 	error = lockd_up_net(serv, net);
<span class="p_del">-	if (error &lt; 0)</span>
<span class="p_del">-		goto err_net;</span>
<span class="p_add">+	if (error &lt; 0) {</span>
<span class="p_add">+		lockd_unregister_notifiers();</span>
<span class="p_add">+		goto err_put;</span>
<span class="p_add">+	}</span>
 
 	error = lockd_start_svc(serv);
<span class="p_del">-	if (error &lt; 0)</span>
<span class="p_del">-		goto err_start;</span>
<span class="p_del">-</span>
<span class="p_add">+	if (error &lt; 0) {</span>
<span class="p_add">+		lockd_down_net(serv, net);</span>
<span class="p_add">+		goto err_put;</span>
<span class="p_add">+	}</span>
 	nlmsvc_users++;
 	/*
 	 * Note: svc_serv structures have an initial use count of 1,
<span class="p_chunk">@@ -476,12 +480,6 @@</span> <span class="p_context"> int lockd_up(struct net *net)</span>
 err_create:
 	mutex_unlock(&amp;nlmsvc_mutex);
 	return error;
<span class="p_del">-</span>
<span class="p_del">-err_start:</span>
<span class="p_del">-	lockd_down_net(serv, net);</span>
<span class="p_del">-err_net:</span>
<span class="p_del">-	lockd_unregister_notifiers();</span>
<span class="p_del">-	goto err_put;</span>
 }
 EXPORT_SYMBOL_GPL(lockd_up);
 
<span class="p_header">diff --git a/fs/nfs/dir.c b/fs/nfs/dir.c</span>
<span class="p_header">index 5ceaeb1f6fb6..b03b3bc05f96 100644</span>
<span class="p_header">--- a/fs/nfs/dir.c</span>
<span class="p_header">+++ b/fs/nfs/dir.c</span>
<span class="p_chunk">@@ -1241,8 +1241,7 @@</span> <span class="p_context"> static int nfs_weak_revalidate(struct dentry *dentry, unsigned int flags)</span>
 		return 0;
 	}
 
<span class="p_del">-	if (nfs_mapping_need_revalidate_inode(inode))</span>
<span class="p_del">-		error = __nfs_revalidate_inode(NFS_SERVER(inode), inode);</span>
<span class="p_add">+	error = nfs_lookup_verify_inode(inode, flags);</span>
 	dfprintk(LOOKUPCACHE, &quot;NFS: %s: inode %lu is %s\n&quot;,
 			__func__, inode-&gt;i_ino, error ? &quot;invalid&quot; : &quot;valid&quot;);
 	return !error;
<span class="p_chunk">@@ -1393,6 +1392,7 @@</span> <span class="p_context"> static int nfs4_lookup_revalidate(struct dentry *, unsigned int);</span>
 
 const struct dentry_operations nfs4_dentry_operations = {
 	.d_revalidate	= nfs4_lookup_revalidate,
<span class="p_add">+	.d_weak_revalidate	= nfs_weak_revalidate,</span>
 	.d_delete	= nfs_dentry_delete,
 	.d_iput		= nfs_dentry_iput,
 	.d_automount	= nfs_d_automount,
<span class="p_header">diff --git a/fs/nfs/file.c b/fs/nfs/file.c</span>
<span class="p_header">index 0214dd1e1060..81cca49a8375 100644</span>
<span class="p_header">--- a/fs/nfs/file.c</span>
<span class="p_header">+++ b/fs/nfs/file.c</span>
<span class="p_chunk">@@ -829,23 +829,9 @@</span> <span class="p_context"> int nfs_flock(struct file *filp, int cmd, struct file_lock *fl)</span>
 	if (NFS_SERVER(inode)-&gt;flags &amp; NFS_MOUNT_LOCAL_FLOCK)
 		is_local = 1;
 
<span class="p_del">-	/*</span>
<span class="p_del">-	 * VFS doesn&#39;t require the open mode to match a flock() lock&#39;s type.</span>
<span class="p_del">-	 * NFS, however, may simulate flock() locking with posix locking which</span>
<span class="p_del">-	 * requires the open mode to match the lock type.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	switch (fl-&gt;fl_type) {</span>
<span class="p_del">-	case F_UNLCK:</span>
<span class="p_add">+	/* We&#39;re simulating flock() locks using posix locks on the server */</span>
<span class="p_add">+	if (fl-&gt;fl_type == F_UNLCK)</span>
 		return do_unlk(filp, cmd, fl, is_local);
<span class="p_del">-	case F_RDLCK:</span>
<span class="p_del">-		if (!(filp-&gt;f_mode &amp; FMODE_READ))</span>
<span class="p_del">-			return -EBADF;</span>
<span class="p_del">-		break;</span>
<span class="p_del">-	case F_WRLCK:</span>
<span class="p_del">-		if (!(filp-&gt;f_mode &amp; FMODE_WRITE))</span>
<span class="p_del">-			return -EBADF;</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
 	return do_setlk(filp, cmd, fl, is_local);
 }
 EXPORT_SYMBOL_GPL(nfs_flock);
<span class="p_header">diff --git a/fs/nfs/nfs4proc.c b/fs/nfs/nfs4proc.c</span>
<span class="p_header">index f90090e8c959..2241d52710f7 100644</span>
<span class="p_header">--- a/fs/nfs/nfs4proc.c</span>
<span class="p_header">+++ b/fs/nfs/nfs4proc.c</span>
<span class="p_chunk">@@ -254,15 +254,12 @@</span> <span class="p_context"> const u32 nfs4_fsinfo_bitmap[3] = { FATTR4_WORD0_MAXFILESIZE</span>
 };
 
 const u32 nfs4_fs_locations_bitmap[3] = {
<span class="p_del">-	FATTR4_WORD0_TYPE</span>
<span class="p_del">-	| FATTR4_WORD0_CHANGE</span>
<span class="p_add">+	FATTR4_WORD0_CHANGE</span>
 	| FATTR4_WORD0_SIZE
 	| FATTR4_WORD0_FSID
 	| FATTR4_WORD0_FILEID
 	| FATTR4_WORD0_FS_LOCATIONS,
<span class="p_del">-	FATTR4_WORD1_MODE</span>
<span class="p_del">-	| FATTR4_WORD1_NUMLINKS</span>
<span class="p_del">-	| FATTR4_WORD1_OWNER</span>
<span class="p_add">+	FATTR4_WORD1_OWNER</span>
 	| FATTR4_WORD1_OWNER_GROUP
 	| FATTR4_WORD1_RAWDEV
 	| FATTR4_WORD1_SPACE_USED
<span class="p_chunk">@@ -6568,6 +6565,20 @@</span> <span class="p_context"> nfs4_proc_lock(struct file *filp, int cmd, struct file_lock *request)</span>
 	    !test_bit(NFS_STATE_POSIX_LOCKS, &amp;state-&gt;flags))
 		return -ENOLCK;
 
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Don&#39;t rely on the VFS having checked the file open mode,</span>
<span class="p_add">+	 * since it won&#39;t do this for flock() locks.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	switch (request-&gt;fl_type) {</span>
<span class="p_add">+	case F_RDLCK:</span>
<span class="p_add">+		if (!(filp-&gt;f_mode &amp; FMODE_READ))</span>
<span class="p_add">+			return -EBADF;</span>
<span class="p_add">+		break;</span>
<span class="p_add">+	case F_WRLCK:</span>
<span class="p_add">+		if (!(filp-&gt;f_mode &amp; FMODE_WRITE))</span>
<span class="p_add">+			return -EBADF;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
 	status = nfs4_set_lock_state(state, request);
 	if (status != 0)
 		return status;
<span class="p_chunk">@@ -6763,9 +6774,7 @@</span> <span class="p_context"> static int _nfs4_proc_fs_locations(struct rpc_clnt *client, struct inode *dir,</span>
 				   struct page *page)
 {
 	struct nfs_server *server = NFS_SERVER(dir);
<span class="p_del">-	u32 bitmask[3] = {</span>
<span class="p_del">-		[0] = FATTR4_WORD0_FSID | FATTR4_WORD0_FS_LOCATIONS,</span>
<span class="p_del">-	};</span>
<span class="p_add">+	u32 bitmask[3];</span>
 	struct nfs4_fs_locations_arg args = {
 		.dir_fh = NFS_FH(dir),
 		.name = name,
<span class="p_chunk">@@ -6784,12 +6793,15 @@</span> <span class="p_context"> static int _nfs4_proc_fs_locations(struct rpc_clnt *client, struct inode *dir,</span>
 
 	dprintk(&quot;%s: start\n&quot;, __func__);
 
<span class="p_add">+	bitmask[0] = nfs4_fattr_bitmap[0] | FATTR4_WORD0_FS_LOCATIONS;</span>
<span class="p_add">+	bitmask[1] = nfs4_fattr_bitmap[1];</span>
<span class="p_add">+</span>
 	/* Ask for the fileid of the absent filesystem if mounted_on_fileid
 	 * is not supported */
 	if (NFS_SERVER(dir)-&gt;attr_bitmask[1] &amp; FATTR4_WORD1_MOUNTED_ON_FILEID)
<span class="p_del">-		bitmask[1] |= FATTR4_WORD1_MOUNTED_ON_FILEID;</span>
<span class="p_add">+		bitmask[0] &amp;= ~FATTR4_WORD0_FILEID;</span>
 	else
<span class="p_del">-		bitmask[0] |= FATTR4_WORD0_FILEID;</span>
<span class="p_add">+		bitmask[1] &amp;= ~FATTR4_WORD1_MOUNTED_ON_FILEID;</span>
 
 	nfs_fattr_init(&amp;fs_locations-&gt;fattr);
 	fs_locations-&gt;server = server;
<span class="p_header">diff --git a/fs/nfs/nfs4trace.h b/fs/nfs/nfs4trace.h</span>
<span class="p_header">index e7c6275519b0..71d2ca04a9f8 100644</span>
<span class="p_header">--- a/fs/nfs/nfs4trace.h</span>
<span class="p_header">+++ b/fs/nfs/nfs4trace.h</span>
<span class="p_chunk">@@ -202,17 +202,13 @@</span> <span class="p_context"> DECLARE_EVENT_CLASS(nfs4_clientid_event,</span>
 		TP_ARGS(clp, error),
 
 		TP_STRUCT__entry(
<span class="p_del">-			__string(dstaddr,</span>
<span class="p_del">-				rpc_peeraddr2str(clp-&gt;cl_rpcclient,</span>
<span class="p_del">-					RPC_DISPLAY_ADDR))</span>
<span class="p_add">+			__string(dstaddr, clp-&gt;cl_hostname)</span>
 			__field(int, error)
 		),
 
 		TP_fast_assign(
 			__entry-&gt;error = error;
<span class="p_del">-			__assign_str(dstaddr,</span>
<span class="p_del">-				rpc_peeraddr2str(clp-&gt;cl_rpcclient,</span>
<span class="p_del">-						RPC_DISPLAY_ADDR));</span>
<span class="p_add">+			__assign_str(dstaddr, clp-&gt;cl_hostname);</span>
 		),
 
 		TP_printk(
<span class="p_chunk">@@ -1133,9 +1129,7 @@</span> <span class="p_context"> DECLARE_EVENT_CLASS(nfs4_inode_callback_event,</span>
 			__field(dev_t, dev)
 			__field(u32, fhandle)
 			__field(u64, fileid)
<span class="p_del">-			__string(dstaddr, clp ?</span>
<span class="p_del">-				rpc_peeraddr2str(clp-&gt;cl_rpcclient,</span>
<span class="p_del">-					RPC_DISPLAY_ADDR) : &quot;unknown&quot;)</span>
<span class="p_add">+			__string(dstaddr, clp ? clp-&gt;cl_hostname : &quot;unknown&quot;)</span>
 		),
 
 		TP_fast_assign(
<span class="p_chunk">@@ -1148,9 +1142,7 @@</span> <span class="p_context"> DECLARE_EVENT_CLASS(nfs4_inode_callback_event,</span>
 				__entry-&gt;fileid = 0;
 				__entry-&gt;dev = 0;
 			}
<span class="p_del">-			__assign_str(dstaddr, clp ?</span>
<span class="p_del">-				rpc_peeraddr2str(clp-&gt;cl_rpcclient,</span>
<span class="p_del">-					RPC_DISPLAY_ADDR) : &quot;unknown&quot;)</span>
<span class="p_add">+			__assign_str(dstaddr, clp ? clp-&gt;cl_hostname : &quot;unknown&quot;)</span>
 		),
 
 		TP_printk(
<span class="p_chunk">@@ -1192,9 +1184,7 @@</span> <span class="p_context"> DECLARE_EVENT_CLASS(nfs4_inode_stateid_callback_event,</span>
 			__field(dev_t, dev)
 			__field(u32, fhandle)
 			__field(u64, fileid)
<span class="p_del">-			__string(dstaddr, clp ?</span>
<span class="p_del">-				rpc_peeraddr2str(clp-&gt;cl_rpcclient,</span>
<span class="p_del">-					RPC_DISPLAY_ADDR) : &quot;unknown&quot;)</span>
<span class="p_add">+			__string(dstaddr, clp ? clp-&gt;cl_hostname : &quot;unknown&quot;)</span>
 			__field(int, stateid_seq)
 			__field(u32, stateid_hash)
 		),
<span class="p_chunk">@@ -1209,9 +1199,7 @@</span> <span class="p_context"> DECLARE_EVENT_CLASS(nfs4_inode_stateid_callback_event,</span>
 				__entry-&gt;fileid = 0;
 				__entry-&gt;dev = 0;
 			}
<span class="p_del">-			__assign_str(dstaddr, clp ?</span>
<span class="p_del">-				rpc_peeraddr2str(clp-&gt;cl_rpcclient,</span>
<span class="p_del">-					RPC_DISPLAY_ADDR) : &quot;unknown&quot;)</span>
<span class="p_add">+			__assign_str(dstaddr, clp ? clp-&gt;cl_hostname : &quot;unknown&quot;)</span>
 			__entry-&gt;stateid_seq =
 				be32_to_cpu(stateid-&gt;seqid);
 			__entry-&gt;stateid_hash =
<span class="p_header">diff --git a/fs/nfs/super.c b/fs/nfs/super.c</span>
<span class="p_header">index c9d24bae3025..216f67d628b3 100644</span>
<span class="p_header">--- a/fs/nfs/super.c</span>
<span class="p_header">+++ b/fs/nfs/super.c</span>
<span class="p_chunk">@@ -1332,7 +1332,7 @@</span> <span class="p_context"> static int nfs_parse_mount_options(char *raw,</span>
 			mnt-&gt;options |= NFS_OPTION_MIGRATION;
 			break;
 		case Opt_nomigration:
<span class="p_del">-			mnt-&gt;options &amp;= NFS_OPTION_MIGRATION;</span>
<span class="p_add">+			mnt-&gt;options &amp;= ~NFS_OPTION_MIGRATION;</span>
 			break;
 
 		/*
<span class="p_header">diff --git a/fs/nfsd/nfs4state.c b/fs/nfsd/nfs4state.c</span>
<span class="p_header">index 0c04f81aa63b..d386d569edbc 100644</span>
<span class="p_header">--- a/fs/nfsd/nfs4state.c</span>
<span class="p_header">+++ b/fs/nfsd/nfs4state.c</span>
<span class="p_chunk">@@ -3966,7 +3966,8 @@</span> <span class="p_context"> static struct nfs4_delegation *find_deleg_stateid(struct nfs4_client *cl, statei</span>
 {
 	struct nfs4_stid *ret;
 
<span class="p_del">-	ret = find_stateid_by_type(cl, s, NFS4_DELEG_STID);</span>
<span class="p_add">+	ret = find_stateid_by_type(cl, s,</span>
<span class="p_add">+				NFS4_DELEG_STID|NFS4_REVOKED_DELEG_STID);</span>
 	if (!ret)
 		return NULL;
 	return delegstateid(ret);
<span class="p_chunk">@@ -3989,6 +3990,12 @@</span> <span class="p_context"> nfs4_check_deleg(struct nfs4_client *cl, struct nfsd4_open *open,</span>
 	deleg = find_deleg_stateid(cl, &amp;open-&gt;op_delegate_stateid);
 	if (deleg == NULL)
 		goto out;
<span class="p_add">+	if (deleg-&gt;dl_stid.sc_type == NFS4_REVOKED_DELEG_STID) {</span>
<span class="p_add">+		nfs4_put_stid(&amp;deleg-&gt;dl_stid);</span>
<span class="p_add">+		if (cl-&gt;cl_minorversion)</span>
<span class="p_add">+			status = nfserr_deleg_revoked;</span>
<span class="p_add">+		goto out;</span>
<span class="p_add">+	}</span>
 	flags = share_access_to_flags(open-&gt;op_share_access);
 	status = nfs4_check_delegmode(deleg, flags);
 	if (status) {
<span class="p_chunk">@@ -4858,6 +4865,16 @@</span> <span class="p_context"> nfsd4_lookup_stateid(struct nfsd4_compound_state *cstate,</span>
 		     struct nfs4_stid **s, struct nfsd_net *nn)
 {
 	__be32 status;
<span class="p_add">+	bool return_revoked = false;</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 *  only return revoked delegations if explicitly asked.</span>
<span class="p_add">+	 *  otherwise we report revoked or bad_stateid status.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	if (typemask &amp; NFS4_REVOKED_DELEG_STID)</span>
<span class="p_add">+		return_revoked = true;</span>
<span class="p_add">+	else if (typemask &amp; NFS4_DELEG_STID)</span>
<span class="p_add">+		typemask |= NFS4_REVOKED_DELEG_STID;</span>
 
 	if (ZERO_STATEID(stateid) || ONE_STATEID(stateid))
 		return nfserr_bad_stateid;
<span class="p_chunk">@@ -4872,6 +4889,12 @@</span> <span class="p_context"> nfsd4_lookup_stateid(struct nfsd4_compound_state *cstate,</span>
 	*s = find_stateid_by_type(cstate-&gt;clp, stateid, typemask);
 	if (!*s)
 		return nfserr_bad_stateid;
<span class="p_add">+	if (((*s)-&gt;sc_type == NFS4_REVOKED_DELEG_STID) &amp;&amp; !return_revoked) {</span>
<span class="p_add">+		nfs4_put_stid(*s);</span>
<span class="p_add">+		if (cstate-&gt;minorversion)</span>
<span class="p_add">+			return nfserr_deleg_revoked;</span>
<span class="p_add">+		return nfserr_bad_stateid;</span>
<span class="p_add">+	}</span>
 	return nfs_ok;
 }
 
<span class="p_header">diff --git a/fs/nilfs2/segment.c b/fs/nilfs2/segment.c</span>
<span class="p_header">index 70ded52dc1dd..50e12956c737 100644</span>
<span class="p_header">--- a/fs/nilfs2/segment.c</span>
<span class="p_header">+++ b/fs/nilfs2/segment.c</span>
<span class="p_chunk">@@ -1958,8 +1958,6 @@</span> <span class="p_context"> static int nilfs_segctor_collect_dirty_files(struct nilfs_sc_info *sci,</span>
 					  err, ii-&gt;vfs_inode.i_ino);
 				return err;
 			}
<span class="p_del">-			mark_buffer_dirty(ibh);</span>
<span class="p_del">-			nilfs_mdt_mark_dirty(ifile);</span>
 			spin_lock(&amp;nilfs-&gt;ns_inode_lock);
 			if (likely(!ii-&gt;i_bh))
 				ii-&gt;i_bh = ibh;
<span class="p_chunk">@@ -1968,6 +1966,10 @@</span> <span class="p_context"> static int nilfs_segctor_collect_dirty_files(struct nilfs_sc_info *sci,</span>
 			goto retry;
 		}
 
<span class="p_add">+		// Always redirty the buffer to avoid race condition</span>
<span class="p_add">+		mark_buffer_dirty(ii-&gt;i_bh);</span>
<span class="p_add">+		nilfs_mdt_mark_dirty(ifile);</span>
<span class="p_add">+</span>
 		clear_bit(NILFS_I_QUEUED, &amp;ii-&gt;i_state);
 		set_bit(NILFS_I_BUSY, &amp;ii-&gt;i_state);
 		list_move_tail(&amp;ii-&gt;i_dirty, &amp;sci-&gt;sc_dirty_files);
<span class="p_header">diff --git a/fs/notify/fanotify/fanotify.c b/fs/notify/fanotify/fanotify.c</span>
<span class="p_header">index 09640b546363..3c7053207297 100644</span>
<span class="p_header">--- a/fs/notify/fanotify/fanotify.c</span>
<span class="p_header">+++ b/fs/notify/fanotify/fanotify.c</span>
<span class="p_chunk">@@ -65,19 +65,8 @@</span> <span class="p_context"> static int fanotify_get_response(struct fsnotify_group *group,</span>
 
 	pr_debug(&quot;%s: group=%p event=%p\n&quot;, __func__, group, event);
 
<span class="p_del">-	/*</span>
<span class="p_del">-	 * fsnotify_prepare_user_wait() fails if we race with mark deletion.</span>
<span class="p_del">-	 * Just let the operation pass in that case.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	if (!fsnotify_prepare_user_wait(iter_info)) {</span>
<span class="p_del">-		event-&gt;response = FAN_ALLOW;</span>
<span class="p_del">-		goto out;</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
 	wait_event(group-&gt;fanotify_data.access_waitq, event-&gt;response);
 
<span class="p_del">-	fsnotify_finish_user_wait(iter_info);</span>
<span class="p_del">-out:</span>
 	/* userspace responded, convert to something usable */
 	switch (event-&gt;response) {
 	case FAN_ALLOW:
<span class="p_chunk">@@ -212,9 +201,21 @@</span> <span class="p_context"> static int fanotify_handle_event(struct fsnotify_group *group,</span>
 	pr_debug(&quot;%s: group=%p inode=%p mask=%x\n&quot;, __func__, group, inode,
 		 mask);
 
<span class="p_add">+#ifdef CONFIG_FANOTIFY_ACCESS_PERMISSIONS</span>
<span class="p_add">+	if (mask &amp; FAN_ALL_PERM_EVENTS) {</span>
<span class="p_add">+		/*</span>
<span class="p_add">+		 * fsnotify_prepare_user_wait() fails if we race with mark</span>
<span class="p_add">+		 * deletion.  Just let the operation pass in that case.</span>
<span class="p_add">+		 */</span>
<span class="p_add">+		if (!fsnotify_prepare_user_wait(iter_info))</span>
<span class="p_add">+			return 0;</span>
<span class="p_add">+	}</span>
<span class="p_add">+#endif</span>
<span class="p_add">+</span>
 	event = fanotify_alloc_event(inode, mask, data);
<span class="p_add">+	ret = -ENOMEM;</span>
 	if (unlikely(!event))
<span class="p_del">-		return -ENOMEM;</span>
<span class="p_add">+		goto finish;</span>
 
 	fsn_event = &amp;event-&gt;fse;
 	ret = fsnotify_add_event(group, fsn_event, fanotify_merge);
<span class="p_chunk">@@ -224,7 +225,8 @@</span> <span class="p_context"> static int fanotify_handle_event(struct fsnotify_group *group,</span>
 		/* Our event wasn&#39;t used in the end. Free it. */
 		fsnotify_destroy_event(group, fsn_event);
 
<span class="p_del">-		return 0;</span>
<span class="p_add">+		ret = 0;</span>
<span class="p_add">+		goto finish;</span>
 	}
 
 #ifdef CONFIG_FANOTIFY_ACCESS_PERMISSIONS
<span class="p_chunk">@@ -233,6 +235,11 @@</span> <span class="p_context"> static int fanotify_handle_event(struct fsnotify_group *group,</span>
 					    iter_info);
 		fsnotify_destroy_event(group, fsn_event);
 	}
<span class="p_add">+finish:</span>
<span class="p_add">+	if (mask &amp; FAN_ALL_PERM_EVENTS)</span>
<span class="p_add">+		fsnotify_finish_user_wait(iter_info);</span>
<span class="p_add">+#else</span>
<span class="p_add">+finish:</span>
 #endif
 	return ret;
 }
<span class="p_header">diff --git a/fs/notify/fsnotify.c b/fs/notify/fsnotify.c</span>
<span class="p_header">index 0c4583b61717..074716293829 100644</span>
<span class="p_header">--- a/fs/notify/fsnotify.c</span>
<span class="p_header">+++ b/fs/notify/fsnotify.c</span>
<span class="p_chunk">@@ -335,6 +335,13 @@</span> <span class="p_context"> int fsnotify(struct inode *to_tell, __u32 mask, const void *data, int data_is,</span>
 						    struct fsnotify_mark, obj_list);
 			vfsmount_group = vfsmount_mark-&gt;group;
 		}
<span class="p_add">+		/*</span>
<span class="p_add">+		 * Need to protect both marks against freeing so that we can</span>
<span class="p_add">+		 * continue iteration from this place, regardless of which mark</span>
<span class="p_add">+		 * we actually happen to send an event for.</span>
<span class="p_add">+		 */</span>
<span class="p_add">+		iter_info.inode_mark = inode_mark;</span>
<span class="p_add">+		iter_info.vfsmount_mark = vfsmount_mark;</span>
 
 		if (inode_group &amp;&amp; vfsmount_group) {
 			int cmp = fsnotify_compare_groups(inode_group,
<span class="p_chunk">@@ -348,9 +355,6 @@</span> <span class="p_context"> int fsnotify(struct inode *to_tell, __u32 mask, const void *data, int data_is,</span>
 			}
 		}
 
<span class="p_del">-		iter_info.inode_mark = inode_mark;</span>
<span class="p_del">-		iter_info.vfsmount_mark = vfsmount_mark;</span>
<span class="p_del">-</span>
 		ret = send_to_group(to_tell, inode_mark, vfsmount_mark, mask,
 				    data, data_is, cookie, file_name,
 				    &amp;iter_info);
<span class="p_header">diff --git a/fs/notify/mark.c b/fs/notify/mark.c</span>
<span class="p_header">index 9991f8826734..258d99087183 100644</span>
<span class="p_header">--- a/fs/notify/mark.c</span>
<span class="p_header">+++ b/fs/notify/mark.c</span>
<span class="p_chunk">@@ -109,16 +109,6 @@</span> <span class="p_context"> void fsnotify_get_mark(struct fsnotify_mark *mark)</span>
 	atomic_inc(&amp;mark-&gt;refcnt);
 }
 
<span class="p_del">-/*</span>
<span class="p_del">- * Get mark reference when we found the mark via lockless traversal of object</span>
<span class="p_del">- * list. Mark can be already removed from the list by now and on its way to be</span>
<span class="p_del">- * destroyed once SRCU period ends.</span>
<span class="p_del">- */</span>
<span class="p_del">-static bool fsnotify_get_mark_safe(struct fsnotify_mark *mark)</span>
<span class="p_del">-{</span>
<span class="p_del">-	return atomic_inc_not_zero(&amp;mark-&gt;refcnt);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
 static void __fsnotify_recalc_mask(struct fsnotify_mark_connector *conn)
 {
 	u32 new_mask = 0;
<span class="p_chunk">@@ -256,32 +246,60 @@</span> <span class="p_context"> void fsnotify_put_mark(struct fsnotify_mark *mark)</span>
 			   FSNOTIFY_REAPER_DELAY);
 }
 
<span class="p_del">-bool fsnotify_prepare_user_wait(struct fsnotify_iter_info *iter_info)</span>
<span class="p_add">+/*</span>
<span class="p_add">+ * Get mark reference when we found the mark via lockless traversal of object</span>
<span class="p_add">+ * list. Mark can be already removed from the list by now and on its way to be</span>
<span class="p_add">+ * destroyed once SRCU period ends.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * Also pin the group so it doesn&#39;t disappear under us.</span>
<span class="p_add">+ */</span>
<span class="p_add">+static bool fsnotify_get_mark_safe(struct fsnotify_mark *mark)</span>
 {
<span class="p_del">-	struct fsnotify_group *group;</span>
<span class="p_del">-</span>
<span class="p_del">-	if (WARN_ON_ONCE(!iter_info-&gt;inode_mark &amp;&amp; !iter_info-&gt;vfsmount_mark))</span>
<span class="p_del">-		return false;</span>
<span class="p_del">-</span>
<span class="p_del">-	if (iter_info-&gt;inode_mark)</span>
<span class="p_del">-		group = iter_info-&gt;inode_mark-&gt;group;</span>
<span class="p_del">-	else</span>
<span class="p_del">-		group = iter_info-&gt;vfsmount_mark-&gt;group;</span>
<span class="p_add">+	if (!mark)</span>
<span class="p_add">+		return true;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (atomic_inc_not_zero(&amp;mark-&gt;refcnt)) {</span>
<span class="p_add">+		spin_lock(&amp;mark-&gt;lock);</span>
<span class="p_add">+		if (mark-&gt;flags &amp; FSNOTIFY_MARK_FLAG_ATTACHED) {</span>
<span class="p_add">+			/* mark is attached, group is still alive then */</span>
<span class="p_add">+			atomic_inc(&amp;mark-&gt;group-&gt;user_waits);</span>
<span class="p_add">+			spin_unlock(&amp;mark-&gt;lock);</span>
<span class="p_add">+			return true;</span>
<span class="p_add">+		}</span>
<span class="p_add">+		spin_unlock(&amp;mark-&gt;lock);</span>
<span class="p_add">+		fsnotify_put_mark(mark);</span>
<span class="p_add">+	}</span>
<span class="p_add">+	return false;</span>
<span class="p_add">+}</span>
 
<span class="p_del">-	/*</span>
<span class="p_del">-	 * Since acquisition of mark reference is an atomic op as well, we can</span>
<span class="p_del">-	 * be sure this inc is seen before any effect of refcount increment.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	atomic_inc(&amp;group-&gt;user_waits);</span>
<span class="p_add">+/*</span>
<span class="p_add">+ * Puts marks and wakes up group destruction if necessary.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * Pairs with fsnotify_get_mark_safe()</span>
<span class="p_add">+ */</span>
<span class="p_add">+static void fsnotify_put_mark_wake(struct fsnotify_mark *mark)</span>
<span class="p_add">+{</span>
<span class="p_add">+	if (mark) {</span>
<span class="p_add">+		struct fsnotify_group *group = mark-&gt;group;</span>
 
<span class="p_del">-	if (iter_info-&gt;inode_mark) {</span>
<span class="p_del">-		/* This can fail if mark is being removed */</span>
<span class="p_del">-		if (!fsnotify_get_mark_safe(iter_info-&gt;inode_mark))</span>
<span class="p_del">-			goto out_wait;</span>
<span class="p_add">+		fsnotify_put_mark(mark);</span>
<span class="p_add">+		/*</span>
<span class="p_add">+		 * We abuse notification_waitq on group shutdown for waiting for</span>
<span class="p_add">+		 * all marks pinned when waiting for userspace.</span>
<span class="p_add">+		 */</span>
<span class="p_add">+		if (atomic_dec_and_test(&amp;group-&gt;user_waits) &amp;&amp; group-&gt;shutdown)</span>
<span class="p_add">+			wake_up(&amp;group-&gt;notification_waitq);</span>
 	}
<span class="p_del">-	if (iter_info-&gt;vfsmount_mark) {</span>
<span class="p_del">-		if (!fsnotify_get_mark_safe(iter_info-&gt;vfsmount_mark))</span>
<span class="p_del">-			goto out_inode;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+bool fsnotify_prepare_user_wait(struct fsnotify_iter_info *iter_info)</span>
<span class="p_add">+{</span>
<span class="p_add">+	/* This can fail if mark is being removed */</span>
<span class="p_add">+	if (!fsnotify_get_mark_safe(iter_info-&gt;inode_mark))</span>
<span class="p_add">+		return false;</span>
<span class="p_add">+	if (!fsnotify_get_mark_safe(iter_info-&gt;vfsmount_mark)) {</span>
<span class="p_add">+		fsnotify_put_mark_wake(iter_info-&gt;inode_mark);</span>
<span class="p_add">+		return false;</span>
 	}
 
 	/*
<span class="p_chunk">@@ -292,34 +310,13 @@</span> <span class="p_context"> bool fsnotify_prepare_user_wait(struct fsnotify_iter_info *iter_info)</span>
 	srcu_read_unlock(&amp;fsnotify_mark_srcu, iter_info-&gt;srcu_idx);
 
 	return true;
<span class="p_del">-out_inode:</span>
<span class="p_del">-	if (iter_info-&gt;inode_mark)</span>
<span class="p_del">-		fsnotify_put_mark(iter_info-&gt;inode_mark);</span>
<span class="p_del">-out_wait:</span>
<span class="p_del">-	if (atomic_dec_and_test(&amp;group-&gt;user_waits) &amp;&amp; group-&gt;shutdown)</span>
<span class="p_del">-		wake_up(&amp;group-&gt;notification_waitq);</span>
<span class="p_del">-	return false;</span>
 }
 
 void fsnotify_finish_user_wait(struct fsnotify_iter_info *iter_info)
 {
<span class="p_del">-	struct fsnotify_group *group = NULL;</span>
<span class="p_del">-</span>
 	iter_info-&gt;srcu_idx = srcu_read_lock(&amp;fsnotify_mark_srcu);
<span class="p_del">-	if (iter_info-&gt;inode_mark) {</span>
<span class="p_del">-		group = iter_info-&gt;inode_mark-&gt;group;</span>
<span class="p_del">-		fsnotify_put_mark(iter_info-&gt;inode_mark);</span>
<span class="p_del">-	}</span>
<span class="p_del">-	if (iter_info-&gt;vfsmount_mark) {</span>
<span class="p_del">-		group = iter_info-&gt;vfsmount_mark-&gt;group;</span>
<span class="p_del">-		fsnotify_put_mark(iter_info-&gt;vfsmount_mark);</span>
<span class="p_del">-	}</span>
<span class="p_del">-	/*</span>
<span class="p_del">-	 * We abuse notification_waitq on group shutdown for waiting for all</span>
<span class="p_del">-	 * marks pinned when waiting for userspace.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	if (atomic_dec_and_test(&amp;group-&gt;user_waits) &amp;&amp; group-&gt;shutdown)</span>
<span class="p_del">-		wake_up(&amp;group-&gt;notification_waitq);</span>
<span class="p_add">+	fsnotify_put_mark_wake(iter_info-&gt;inode_mark);</span>
<span class="p_add">+	fsnotify_put_mark_wake(iter_info-&gt;vfsmount_mark);</span>
 }
 
 /*
<span class="p_header">diff --git a/fs/overlayfs/namei.c b/fs/overlayfs/namei.c</span>
<span class="p_header">index a12dc10bf726..bc6d5c5a3443 100644</span>
<span class="p_header">--- a/fs/overlayfs/namei.c</span>
<span class="p_header">+++ b/fs/overlayfs/namei.c</span>
<span class="p_chunk">@@ -630,7 +630,7 @@</span> <span class="p_context"> struct dentry *ovl_lookup(struct inode *dir, struct dentry *dentry,</span>
 			err = ovl_check_origin(upperdentry, roe-&gt;lowerstack,
 					       roe-&gt;numlower, &amp;stack, &amp;ctr);
 			if (err)
<span class="p_del">-				goto out;</span>
<span class="p_add">+				goto out_put_upper;</span>
 		}
 
 		if (d.redirect) {
<span class="p_header">diff --git a/include/linux/genhd.h b/include/linux/genhd.h</span>
<span class="p_header">index 44790523057f..5ade8f2a6987 100644</span>
<span class="p_header">--- a/include/linux/genhd.h</span>
<span class="p_header">+++ b/include/linux/genhd.h</span>
<span class="p_chunk">@@ -243,6 +243,7 @@</span> <span class="p_context"> static inline dev_t part_devt(struct hd_struct *part)</span>
 	return part_to_dev(part)-&gt;devt;
 }
 
<span class="p_add">+extern struct hd_struct *__disk_get_part(struct gendisk *disk, int partno);</span>
 extern struct hd_struct *disk_get_part(struct gendisk *disk, int partno);
 
 static inline void disk_put_part(struct hd_struct *part)
<span class="p_header">diff --git a/include/linux/irq.h b/include/linux/irq.h</span>
<span class="p_header">index 4536286cc4d2..0d53626405bf 100644</span>
<span class="p_header">--- a/include/linux/irq.h</span>
<span class="p_header">+++ b/include/linux/irq.h</span>
<span class="p_chunk">@@ -211,6 +211,7 @@</span> <span class="p_context"> struct irq_data {</span>
  * IRQD_MANAGED_SHUTDOWN	- Interrupt was shutdown due to empty affinity
  *				  mask. Applies only to affinity managed irqs.
  * IRQD_SINGLE_TARGET		- IRQ allows only a single affinity target
<span class="p_add">+ * IRQD_DEFAULT_TRIGGER_SET	- Expected trigger already been set</span>
  */
 enum {
 	IRQD_TRIGGER_MASK		= 0xf,
<span class="p_chunk">@@ -231,6 +232,7 @@</span> <span class="p_context"> enum {</span>
 	IRQD_IRQ_STARTED		= (1 &lt;&lt; 22),
 	IRQD_MANAGED_SHUTDOWN		= (1 &lt;&lt; 23),
 	IRQD_SINGLE_TARGET		= (1 &lt;&lt; 24),
<span class="p_add">+	IRQD_DEFAULT_TRIGGER_SET	= (1 &lt;&lt; 25),</span>
 };
 
 #define __irqd_to_state(d) ACCESS_PRIVATE((d)-&gt;common, state_use_accessors)
<span class="p_chunk">@@ -260,18 +262,25 @@</span> <span class="p_context"> static inline void irqd_mark_affinity_was_set(struct irq_data *d)</span>
 	__irqd_to_state(d) |= IRQD_AFFINITY_SET;
 }
 
<span class="p_add">+static inline bool irqd_trigger_type_was_set(struct irq_data *d)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return __irqd_to_state(d) &amp; IRQD_DEFAULT_TRIGGER_SET;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static inline u32 irqd_get_trigger_type(struct irq_data *d)
 {
 	return __irqd_to_state(d) &amp; IRQD_TRIGGER_MASK;
 }
 
 /*
<span class="p_del">- * Must only be called inside irq_chip.irq_set_type() functions.</span>
<span class="p_add">+ * Must only be called inside irq_chip.irq_set_type() functions or</span>
<span class="p_add">+ * from the DT/ACPI setup code.</span>
  */
 static inline void irqd_set_trigger_type(struct irq_data *d, u32 type)
 {
 	__irqd_to_state(d) &amp;= ~IRQD_TRIGGER_MASK;
 	__irqd_to_state(d) |= type &amp; IRQD_TRIGGER_MASK;
<span class="p_add">+	__irqd_to_state(d) |= IRQD_DEFAULT_TRIGGER_SET;</span>
 }
 
 static inline bool irqd_is_level_type(struct irq_data *d)
<span class="p_header">diff --git a/include/net/tls.h b/include/net/tls.h</span>
<span class="p_header">index b89d397dd62f..c06db1eadac2 100644</span>
<span class="p_header">--- a/include/net/tls.h</span>
<span class="p_header">+++ b/include/net/tls.h</span>
<span class="p_chunk">@@ -35,6 +35,10 @@</span> <span class="p_context"></span>
 #define _TLS_OFFLOAD_H
 
 #include &lt;linux/types.h&gt;
<span class="p_add">+#include &lt;asm/byteorder.h&gt;</span>
<span class="p_add">+#include &lt;linux/socket.h&gt;</span>
<span class="p_add">+#include &lt;linux/tcp.h&gt;</span>
<span class="p_add">+#include &lt;net/tcp.h&gt;</span>
 
 #include &lt;uapi/linux/tls.h&gt;
 
<span class="p_header">diff --git a/include/sound/control.h b/include/sound/control.h</span>
<span class="p_header">index a1f1152bc687..ca13a44ae9d4 100644</span>
<span class="p_header">--- a/include/sound/control.h</span>
<span class="p_header">+++ b/include/sound/control.h</span>
<span class="p_chunk">@@ -249,7 +249,9 @@</span> <span class="p_context"> int snd_ctl_add_vmaster_hook(struct snd_kcontrol *kctl,</span>
 void snd_ctl_sync_vmaster(struct snd_kcontrol *kctl, bool hook_only);
 #define snd_ctl_sync_vmaster_hook(kctl)	snd_ctl_sync_vmaster(kctl, true)
 int snd_ctl_apply_vmaster_slaves(struct snd_kcontrol *kctl,
<span class="p_del">-				 int (*func)(struct snd_kcontrol *, void *),</span>
<span class="p_add">+				 int (*func)(struct snd_kcontrol *vslave,</span>
<span class="p_add">+					     struct snd_kcontrol *slave,</span>
<span class="p_add">+					     void *arg),</span>
 				 void *arg);
 
 /*
<span class="p_header">diff --git a/include/target/target_core_base.h b/include/target/target_core_base.h</span>
<span class="p_header">index f5db145e68ec..0d924e968c94 100644</span>
<span class="p_header">--- a/include/target/target_core_base.h</span>
<span class="p_header">+++ b/include/target/target_core_base.h</span>
<span class="p_chunk">@@ -490,6 +490,7 @@</span> <span class="p_context"> struct se_cmd {</span>
 #define CMD_T_STOP		(1 &lt;&lt; 5)
 #define CMD_T_TAS		(1 &lt;&lt; 10)
 #define CMD_T_FABRIC_STOP	(1 &lt;&lt; 11)
<span class="p_add">+#define CMD_T_PRE_EXECUTE	(1 &lt;&lt; 12)</span>
 	spinlock_t		t_state_lock;
 	struct kref		cmd_kref;
 	struct completion	t_transport_stop_comp;
<span class="p_header">diff --git a/include/trace/events/sunrpc.h b/include/trace/events/sunrpc.h</span>
<span class="p_header">index 25a7739514cd..3868b4752324 100644</span>
<span class="p_header">--- a/include/trace/events/sunrpc.h</span>
<span class="p_header">+++ b/include/trace/events/sunrpc.h</span>
<span class="p_chunk">@@ -456,20 +456,22 @@</span> <span class="p_context"> TRACE_EVENT(svc_recv,</span>
 	TP_ARGS(rqst, status),
 
 	TP_STRUCT__entry(
<span class="p_del">-		__field(struct sockaddr *, addr)</span>
 		__field(__be32, xid)
 		__field(int, status)
 		__field(unsigned long, flags)
<span class="p_add">+		__dynamic_array(unsigned char, addr, rqst-&gt;rq_addrlen)</span>
 	),
 
 	TP_fast_assign(
<span class="p_del">-		__entry-&gt;addr = (struct sockaddr *)&amp;rqst-&gt;rq_addr;</span>
 		__entry-&gt;xid = status &gt; 0 ? rqst-&gt;rq_xid : 0;
 		__entry-&gt;status = status;
 		__entry-&gt;flags = rqst-&gt;rq_flags;
<span class="p_add">+		memcpy(__get_dynamic_array(addr),</span>
<span class="p_add">+			&amp;rqst-&gt;rq_addr, rqst-&gt;rq_addrlen);</span>
 	),
 
<span class="p_del">-	TP_printk(&quot;addr=%pIScp xid=0x%x status=%d flags=%s&quot;, __entry-&gt;addr,</span>
<span class="p_add">+	TP_printk(&quot;addr=%pIScp xid=0x%x status=%d flags=%s&quot;,</span>
<span class="p_add">+			(struct sockaddr *)__get_dynamic_array(addr),</span>
 			be32_to_cpu(__entry-&gt;xid), __entry-&gt;status,
 			show_rqstp_flags(__entry-&gt;flags))
 );
<span class="p_chunk">@@ -514,22 +516,23 @@</span> <span class="p_context"> DECLARE_EVENT_CLASS(svc_rqst_status,</span>
 	TP_ARGS(rqst, status),
 
 	TP_STRUCT__entry(
<span class="p_del">-		__field(struct sockaddr *, addr)</span>
 		__field(__be32, xid)
<span class="p_del">-		__field(int, dropme)</span>
 		__field(int, status)
 		__field(unsigned long, flags)
<span class="p_add">+		__dynamic_array(unsigned char, addr, rqst-&gt;rq_addrlen)</span>
 	),
 
 	TP_fast_assign(
<span class="p_del">-		__entry-&gt;addr = (struct sockaddr *)&amp;rqst-&gt;rq_addr;</span>
 		__entry-&gt;xid = rqst-&gt;rq_xid;
 		__entry-&gt;status = status;
 		__entry-&gt;flags = rqst-&gt;rq_flags;
<span class="p_add">+		memcpy(__get_dynamic_array(addr),</span>
<span class="p_add">+			&amp;rqst-&gt;rq_addr, rqst-&gt;rq_addrlen);</span>
 	),
 
 	TP_printk(&quot;addr=%pIScp rq_xid=0x%x status=%d flags=%s&quot;,
<span class="p_del">-		__entry-&gt;addr, be32_to_cpu(__entry-&gt;xid),</span>
<span class="p_add">+		(struct sockaddr *)__get_dynamic_array(addr),</span>
<span class="p_add">+		be32_to_cpu(__entry-&gt;xid),</span>
 		__entry-&gt;status, show_rqstp_flags(__entry-&gt;flags))
 );
 
<span class="p_header">diff --git a/include/uapi/linux/rxrpc.h b/include/uapi/linux/rxrpc.h</span>
<span class="p_header">index 9656aad8f8f7..9d4afea308a4 100644</span>
<span class="p_header">--- a/include/uapi/linux/rxrpc.h</span>
<span class="p_header">+++ b/include/uapi/linux/rxrpc.h</span>
<span class="p_chunk">@@ -20,12 +20,12 @@</span> <span class="p_context"></span>
  * RxRPC socket address
  */
 struct sockaddr_rxrpc {
<span class="p_del">-	sa_family_t	srx_family;	/* address family */</span>
<span class="p_del">-	u16		srx_service;	/* service desired */</span>
<span class="p_del">-	u16		transport_type;	/* type of transport socket (SOCK_DGRAM) */</span>
<span class="p_del">-	u16		transport_len;	/* length of transport address */</span>
<span class="p_add">+	__kernel_sa_family_t	srx_family;	/* address family */</span>
<span class="p_add">+	__u16			srx_service;	/* service desired */</span>
<span class="p_add">+	__u16			transport_type;	/* type of transport socket (SOCK_DGRAM) */</span>
<span class="p_add">+	__u16			transport_len;	/* length of transport address */</span>
 	union {
<span class="p_del">-		sa_family_t family;		/* transport address family */</span>
<span class="p_add">+		__kernel_sa_family_t family;	/* transport address family */</span>
 		struct sockaddr_in sin;		/* IPv4 transport address */
 		struct sockaddr_in6 sin6;	/* IPv6 transport address */
 	} transport;
<span class="p_header">diff --git a/include/uapi/linux/tls.h b/include/uapi/linux/tls.h</span>
<span class="p_header">index d5e0682ab837..293b2cdad88d 100644</span>
<span class="p_header">--- a/include/uapi/linux/tls.h</span>
<span class="p_header">+++ b/include/uapi/linux/tls.h</span>
<span class="p_chunk">@@ -35,10 +35,6 @@</span> <span class="p_context"></span>
 #define _UAPI_LINUX_TLS_H
 
 #include &lt;linux/types.h&gt;
<span class="p_del">-#include &lt;asm/byteorder.h&gt;</span>
<span class="p_del">-#include &lt;linux/socket.h&gt;</span>
<span class="p_del">-#include &lt;linux/tcp.h&gt;</span>
<span class="p_del">-#include &lt;net/tcp.h&gt;</span>
 
 /* TLS socket options */
 #define TLS_TX			1	/* Set transmit parameters */
<span class="p_header">diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c</span>
<span class="p_header">index 4bff6a10ae8e..b02caa442776 100644</span>
<span class="p_header">--- a/kernel/irq/manage.c</span>
<span class="p_header">+++ b/kernel/irq/manage.c</span>
<span class="p_chunk">@@ -1245,7 +1245,18 @@</span> <span class="p_context"> __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)</span>
 		 * set the trigger type must match. Also all must
 		 * agree on ONESHOT.
 		 */
<span class="p_del">-		unsigned int oldtype = irqd_get_trigger_type(&amp;desc-&gt;irq_data);</span>
<span class="p_add">+		unsigned int oldtype;</span>
<span class="p_add">+</span>
<span class="p_add">+		/*</span>
<span class="p_add">+		 * If nobody did set the configuration before, inherit</span>
<span class="p_add">+		 * the one provided by the requester.</span>
<span class="p_add">+		 */</span>
<span class="p_add">+		if (irqd_trigger_type_was_set(&amp;desc-&gt;irq_data)) {</span>
<span class="p_add">+			oldtype = irqd_get_trigger_type(&amp;desc-&gt;irq_data);</span>
<span class="p_add">+		} else {</span>
<span class="p_add">+			oldtype = new-&gt;flags &amp; IRQF_TRIGGER_MASK;</span>
<span class="p_add">+			irqd_set_trigger_type(&amp;desc-&gt;irq_data, oldtype);</span>
<span class="p_add">+		}</span>
 
 		if (!((old-&gt;flags &amp; new-&gt;flags) &amp; IRQF_SHARED) ||
 		    (oldtype != (new-&gt;flags &amp; IRQF_TRIGGER_MASK)) ||
<span class="p_header">diff --git a/kernel/sched/core.c b/kernel/sched/core.c</span>
<span class="p_header">index d17c5da523a0..8fa7b6f9e19b 100644</span>
<span class="p_header">--- a/kernel/sched/core.c</span>
<span class="p_header">+++ b/kernel/sched/core.c</span>
<span class="p_chunk">@@ -505,8 +505,7 @@</span> <span class="p_context"> void resched_cpu(int cpu)</span>
 	struct rq *rq = cpu_rq(cpu);
 	unsigned long flags;
 
<span class="p_del">-	if (!raw_spin_trylock_irqsave(&amp;rq-&gt;lock, flags))</span>
<span class="p_del">-		return;</span>
<span class="p_add">+	raw_spin_lock_irqsave(&amp;rq-&gt;lock, flags);</span>
 	resched_curr(rq);
 	raw_spin_unlock_irqrestore(&amp;rq-&gt;lock, flags);
 }
<span class="p_header">diff --git a/kernel/sched/cpufreq_schedutil.c b/kernel/sched/cpufreq_schedutil.c</span>
<span class="p_header">index ba0da243fdd8..2f52ec0f1539 100644</span>
<span class="p_header">--- a/kernel/sched/cpufreq_schedutil.c</span>
<span class="p_header">+++ b/kernel/sched/cpufreq_schedutil.c</span>
<span class="p_chunk">@@ -282,8 +282,12 @@</span> <span class="p_context"> static void sugov_update_single(struct update_util_data *hook, u64 time,</span>
 		 * Do not reduce the frequency if the CPU has not been idle
 		 * recently, as the reduction is likely to be premature then.
 		 */
<span class="p_del">-		if (busy &amp;&amp; next_f &lt; sg_policy-&gt;next_freq)</span>
<span class="p_add">+		if (busy &amp;&amp; next_f &lt; sg_policy-&gt;next_freq) {</span>
 			next_f = sg_policy-&gt;next_freq;
<span class="p_add">+</span>
<span class="p_add">+			/* Reset cached freq as next_freq has changed */</span>
<span class="p_add">+			sg_policy-&gt;cached_raw_freq = 0;</span>
<span class="p_add">+		}</span>
 	}
 	sugov_update_commit(sg_policy, time, next_f);
 }
<span class="p_header">diff --git a/kernel/sched/rt.c b/kernel/sched/rt.c</span>
<span class="p_header">index 3c96c80e0992..d8c43d73e078 100644</span>
<span class="p_header">--- a/kernel/sched/rt.c</span>
<span class="p_header">+++ b/kernel/sched/rt.c</span>
<span class="p_chunk">@@ -74,10 +74,6 @@</span> <span class="p_context"> static void start_rt_bandwidth(struct rt_bandwidth *rt_b)</span>
 	raw_spin_unlock(&amp;rt_b-&gt;rt_runtime_lock);
 }
 
<span class="p_del">-#if defined(CONFIG_SMP) &amp;&amp; defined(HAVE_RT_PUSH_IPI)</span>
<span class="p_del">-static void push_irq_work_func(struct irq_work *work);</span>
<span class="p_del">-#endif</span>
<span class="p_del">-</span>
 void init_rt_rq(struct rt_rq *rt_rq)
 {
 	struct rt_prio_array *array;
<span class="p_chunk">@@ -97,13 +93,6 @@</span> <span class="p_context"> void init_rt_rq(struct rt_rq *rt_rq)</span>
 	rt_rq-&gt;rt_nr_migratory = 0;
 	rt_rq-&gt;overloaded = 0;
 	plist_head_init(&amp;rt_rq-&gt;pushable_tasks);
<span class="p_del">-</span>
<span class="p_del">-#ifdef HAVE_RT_PUSH_IPI</span>
<span class="p_del">-	rt_rq-&gt;push_flags = 0;</span>
<span class="p_del">-	rt_rq-&gt;push_cpu = nr_cpu_ids;</span>
<span class="p_del">-	raw_spin_lock_init(&amp;rt_rq-&gt;push_lock);</span>
<span class="p_del">-	init_irq_work(&amp;rt_rq-&gt;push_work, push_irq_work_func);</span>
<span class="p_del">-#endif</span>
 #endif /* CONFIG_SMP */
 	/* We start is dequeued state, because no RT tasks are queued */
 	rt_rq-&gt;rt_queued = 0;
<span class="p_chunk">@@ -1876,241 +1865,166 @@</span> <span class="p_context"> static void push_rt_tasks(struct rq *rq)</span>
 }
 
 #ifdef HAVE_RT_PUSH_IPI
<span class="p_add">+</span>
 /*
<span class="p_del">- * The search for the next cpu always starts at rq-&gt;cpu and ends</span>
<span class="p_del">- * when we reach rq-&gt;cpu again. It will never return rq-&gt;cpu.</span>
<span class="p_del">- * This returns the next cpu to check, or nr_cpu_ids if the loop</span>
<span class="p_del">- * is complete.</span>
<span class="p_add">+ * When a high priority task schedules out from a CPU and a lower priority</span>
<span class="p_add">+ * task is scheduled in, a check is made to see if there&#39;s any RT tasks</span>
<span class="p_add">+ * on other CPUs that are waiting to run because a higher priority RT task</span>
<span class="p_add">+ * is currently running on its CPU. In this case, the CPU with multiple RT</span>
<span class="p_add">+ * tasks queued on it (overloaded) needs to be notified that a CPU has opened</span>
<span class="p_add">+ * up that may be able to run one of its non-running queued RT tasks.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * All CPUs with overloaded RT tasks need to be notified as there is currently</span>
<span class="p_add">+ * no way to know which of these CPUs have the highest priority task waiting</span>
<span class="p_add">+ * to run. Instead of trying to take a spinlock on each of these CPUs,</span>
<span class="p_add">+ * which has shown to cause large latency when done on machines with many</span>
<span class="p_add">+ * CPUs, sending an IPI to the CPUs to have them push off the overloaded</span>
<span class="p_add">+ * RT tasks waiting to run.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * Just sending an IPI to each of the CPUs is also an issue, as on large</span>
<span class="p_add">+ * count CPU machines, this can cause an IPI storm on a CPU, especially</span>
<span class="p_add">+ * if its the only CPU with multiple RT tasks queued, and a large number</span>
<span class="p_add">+ * of CPUs scheduling a lower priority task at the same time.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * Each root domain has its own irq work function that can iterate over</span>
<span class="p_add">+ * all CPUs with RT overloaded tasks. Since all CPUs with overloaded RT</span>
<span class="p_add">+ * tassk must be checked if there&#39;s one or many CPUs that are lowering</span>
<span class="p_add">+ * their priority, there&#39;s a single irq work iterator that will try to</span>
<span class="p_add">+ * push off RT tasks that are waiting to run.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * When a CPU schedules a lower priority task, it will kick off the</span>
<span class="p_add">+ * irq work iterator that will jump to each CPU with overloaded RT tasks.</span>
<span class="p_add">+ * As it only takes the first CPU that schedules a lower priority task</span>
<span class="p_add">+ * to start the process, the rto_start variable is incremented and if</span>
<span class="p_add">+ * the atomic result is one, then that CPU will try to take the rto_lock.</span>
<span class="p_add">+ * This prevents high contention on the lock as the process handles all</span>
<span class="p_add">+ * CPUs scheduling lower priority tasks.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * All CPUs that are scheduling a lower priority task will increment the</span>
<span class="p_add">+ * rt_loop_next variable. This will make sure that the irq work iterator</span>
<span class="p_add">+ * checks all RT overloaded CPUs whenever a CPU schedules a new lower</span>
<span class="p_add">+ * priority task, even if the iterator is in the middle of a scan. Incrementing</span>
<span class="p_add">+ * the rt_loop_next will cause the iterator to perform another scan.</span>
  *
<span class="p_del">- * rq-&gt;rt.push_cpu holds the last cpu returned by this function,</span>
<span class="p_del">- * or if this is the first instance, it must hold rq-&gt;cpu.</span>
  */
 static int rto_next_cpu(struct rq *rq)
 {
<span class="p_del">-	int prev_cpu = rq-&gt;rt.push_cpu;</span>
<span class="p_add">+	struct root_domain *rd = rq-&gt;rd;</span>
<span class="p_add">+	int next;</span>
 	int cpu;
 
<span class="p_del">-	cpu = cpumask_next(prev_cpu, rq-&gt;rd-&gt;rto_mask);</span>
<span class="p_del">-</span>
 	/*
<span class="p_del">-	 * If the previous cpu is less than the rq&#39;s CPU, then it already</span>
<span class="p_del">-	 * passed the end of the mask, and has started from the beginning.</span>
<span class="p_del">-	 * We end if the next CPU is greater or equal to rq&#39;s CPU.</span>
<span class="p_add">+	 * When starting the IPI RT pushing, the rto_cpu is set to -1,</span>
<span class="p_add">+	 * rt_next_cpu() will simply return the first CPU found in</span>
<span class="p_add">+	 * the rto_mask.</span>
<span class="p_add">+	 *</span>
<span class="p_add">+	 * If rto_next_cpu() is called with rto_cpu is a valid cpu, it</span>
<span class="p_add">+	 * will return the next CPU found in the rto_mask.</span>
<span class="p_add">+	 *</span>
<span class="p_add">+	 * If there are no more CPUs left in the rto_mask, then a check is made</span>
<span class="p_add">+	 * against rto_loop and rto_loop_next. rto_loop is only updated with</span>
<span class="p_add">+	 * the rto_lock held, but any CPU may increment the rto_loop_next</span>
<span class="p_add">+	 * without any locking.</span>
 	 */
<span class="p_del">-	if (prev_cpu &lt; rq-&gt;cpu) {</span>
<span class="p_del">-		if (cpu &gt;= rq-&gt;cpu)</span>
<span class="p_del">-			return nr_cpu_ids;</span>
<span class="p_add">+	for (;;) {</span>
 
<span class="p_del">-	} else if (cpu &gt;= nr_cpu_ids) {</span>
<span class="p_del">-		/*</span>
<span class="p_del">-		 * We passed the end of the mask, start at the beginning.</span>
<span class="p_del">-		 * If the result is greater or equal to the rq&#39;s CPU, then</span>
<span class="p_del">-		 * the loop is finished.</span>
<span class="p_del">-		 */</span>
<span class="p_del">-		cpu = cpumask_first(rq-&gt;rd-&gt;rto_mask);</span>
<span class="p_del">-		if (cpu &gt;= rq-&gt;cpu)</span>
<span class="p_del">-			return nr_cpu_ids;</span>
<span class="p_del">-	}</span>
<span class="p_del">-	rq-&gt;rt.push_cpu = cpu;</span>
<span class="p_add">+		/* When rto_cpu is -1 this acts like cpumask_first() */</span>
<span class="p_add">+		cpu = cpumask_next(rd-&gt;rto_cpu, rd-&gt;rto_mask);</span>
 
<span class="p_del">-	/* Return cpu to let the caller know if the loop is finished or not */</span>
<span class="p_del">-	return cpu;</span>
<span class="p_del">-}</span>
<span class="p_add">+		rd-&gt;rto_cpu = cpu;</span>
 
<span class="p_del">-static int find_next_push_cpu(struct rq *rq)</span>
<span class="p_del">-{</span>
<span class="p_del">-	struct rq *next_rq;</span>
<span class="p_del">-	int cpu;</span>
<span class="p_add">+		if (cpu &lt; nr_cpu_ids)</span>
<span class="p_add">+			return cpu;</span>
 
<span class="p_del">-	while (1) {</span>
<span class="p_del">-		cpu = rto_next_cpu(rq);</span>
<span class="p_del">-		if (cpu &gt;= nr_cpu_ids)</span>
<span class="p_del">-			break;</span>
<span class="p_del">-		next_rq = cpu_rq(cpu);</span>
<span class="p_add">+		rd-&gt;rto_cpu = -1;</span>
<span class="p_add">+</span>
<span class="p_add">+		/*</span>
<span class="p_add">+		 * ACQUIRE ensures we see the @rto_mask changes</span>
<span class="p_add">+		 * made prior to the @next value observed.</span>
<span class="p_add">+		 *</span>
<span class="p_add">+		 * Matches WMB in rt_set_overload().</span>
<span class="p_add">+		 */</span>
<span class="p_add">+		next = atomic_read_acquire(&amp;rd-&gt;rto_loop_next);</span>
 
<span class="p_del">-		/* Make sure the next rq can push to this rq */</span>
<span class="p_del">-		if (next_rq-&gt;rt.highest_prio.next &lt; rq-&gt;rt.highest_prio.curr)</span>
<span class="p_add">+		if (rd-&gt;rto_loop == next)</span>
 			break;
<span class="p_add">+</span>
<span class="p_add">+		rd-&gt;rto_loop = next;</span>
 	}
 
<span class="p_del">-	return cpu;</span>
<span class="p_add">+	return -1;</span>
 }
 
<span class="p_del">-#define RT_PUSH_IPI_EXECUTING		1</span>
<span class="p_del">-#define RT_PUSH_IPI_RESTART		2</span>
<span class="p_add">+static inline bool rto_start_trylock(atomic_t *v)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return !atomic_cmpxchg_acquire(v, 0, 1);</span>
<span class="p_add">+}</span>
 
<span class="p_del">-/*</span>
<span class="p_del">- * When a high priority task schedules out from a CPU and a lower priority</span>
<span class="p_del">- * task is scheduled in, a check is made to see if there&#39;s any RT tasks</span>
<span class="p_del">- * on other CPUs that are waiting to run because a higher priority RT task</span>
<span class="p_del">- * is currently running on its CPU. In this case, the CPU with multiple RT</span>
<span class="p_del">- * tasks queued on it (overloaded) needs to be notified that a CPU has opened</span>
<span class="p_del">- * up that may be able to run one of its non-running queued RT tasks.</span>
<span class="p_del">- *</span>
<span class="p_del">- * On large CPU boxes, there&#39;s the case that several CPUs could schedule</span>
<span class="p_del">- * a lower priority task at the same time, in which case it will look for</span>
<span class="p_del">- * any overloaded CPUs that it could pull a task from. To do this, the runqueue</span>
<span class="p_del">- * lock must be taken from that overloaded CPU. Having 10s of CPUs all fighting</span>
<span class="p_del">- * for a single overloaded CPU&#39;s runqueue lock can produce a large latency.</span>
<span class="p_del">- * (This has actually been observed on large boxes running cyclictest).</span>
<span class="p_del">- * Instead of taking the runqueue lock of the overloaded CPU, each of the</span>
<span class="p_del">- * CPUs that scheduled a lower priority task simply sends an IPI to the</span>
<span class="p_del">- * overloaded CPU. An IPI is much cheaper than taking an runqueue lock with</span>
<span class="p_del">- * lots of contention. The overloaded CPU will look to push its non-running</span>
<span class="p_del">- * RT task off, and if it does, it can then ignore the other IPIs coming</span>
<span class="p_del">- * in, and just pass those IPIs off to any other overloaded CPU.</span>
<span class="p_del">- *</span>
<span class="p_del">- * When a CPU schedules a lower priority task, it only sends an IPI to</span>
<span class="p_del">- * the &quot;next&quot; CPU that has overloaded RT tasks. This prevents IPI storms,</span>
<span class="p_del">- * as having 10 CPUs scheduling lower priority tasks and 10 CPUs with</span>
<span class="p_del">- * RT overloaded tasks, would cause 100 IPIs to go out at once.</span>
<span class="p_del">- *</span>
<span class="p_del">- * The overloaded RT CPU, when receiving an IPI, will try to push off its</span>
<span class="p_del">- * overloaded RT tasks and then send an IPI to the next CPU that has</span>
<span class="p_del">- * overloaded RT tasks. This stops when all CPUs with overloaded RT tasks</span>
<span class="p_del">- * have completed. Just because a CPU may have pushed off its own overloaded</span>
<span class="p_del">- * RT task does not mean it should stop sending the IPI around to other</span>
<span class="p_del">- * overloaded CPUs. There may be another RT task waiting to run on one of</span>
<span class="p_del">- * those CPUs that are of higher priority than the one that was just</span>
<span class="p_del">- * pushed.</span>
<span class="p_del">- *</span>
<span class="p_del">- * An optimization that could possibly be made is to make a CPU array similar</span>
<span class="p_del">- * to the cpupri array mask of all running RT tasks, but for the overloaded</span>
<span class="p_del">- * case, then the IPI could be sent to only the CPU with the highest priority</span>
<span class="p_del">- * RT task waiting, and that CPU could send off further IPIs to the CPU with</span>
<span class="p_del">- * the next highest waiting task. Since the overloaded case is much less likely</span>
<span class="p_del">- * to happen, the complexity of this implementation may not be worth it.</span>
<span class="p_del">- * Instead, just send an IPI around to all overloaded CPUs.</span>
<span class="p_del">- *</span>
<span class="p_del">- * The rq-&gt;rt.push_flags holds the status of the IPI that is going around.</span>
<span class="p_del">- * A run queue can only send out a single IPI at a time. The possible flags</span>
<span class="p_del">- * for rq-&gt;rt.push_flags are:</span>
<span class="p_del">- *</span>
<span class="p_del">- *    (None or zero):		No IPI is going around for the current rq</span>
<span class="p_del">- *    RT_PUSH_IPI_EXECUTING:	An IPI for the rq is being passed around</span>
<span class="p_del">- *    RT_PUSH_IPI_RESTART:	The priority of the running task for the rq</span>
<span class="p_del">- *				has changed, and the IPI should restart</span>
<span class="p_del">- *				circulating the overloaded CPUs again.</span>
<span class="p_del">- *</span>
<span class="p_del">- * rq-&gt;rt.push_cpu contains the CPU that is being sent the IPI. It is updated</span>
<span class="p_del">- * before sending to the next CPU.</span>
<span class="p_del">- *</span>
<span class="p_del">- * Instead of having all CPUs that schedule a lower priority task send</span>
<span class="p_del">- * an IPI to the same &quot;first&quot; CPU in the RT overload mask, they send it</span>
<span class="p_del">- * to the next overloaded CPU after their own CPU. This helps distribute</span>
<span class="p_del">- * the work when there&#39;s more than one overloaded CPU and multiple CPUs</span>
<span class="p_del">- * scheduling in lower priority tasks.</span>
<span class="p_del">- *</span>
<span class="p_del">- * When a rq schedules a lower priority task than what was currently</span>
<span class="p_del">- * running, the next CPU with overloaded RT tasks is examined first.</span>
<span class="p_del">- * That is, if CPU 1 and 5 are overloaded, and CPU 3 schedules a lower</span>
<span class="p_del">- * priority task, it will send an IPI first to CPU 5, then CPU 5 will</span>
<span class="p_del">- * send to CPU 1 if it is still overloaded. CPU 1 will clear the</span>
<span class="p_del">- * rq-&gt;rt.push_flags if RT_PUSH_IPI_RESTART is not set.</span>
<span class="p_del">- *</span>
<span class="p_del">- * The first CPU to notice IPI_RESTART is set, will clear that flag and then</span>
<span class="p_del">- * send an IPI to the next overloaded CPU after the rq-&gt;cpu and not the next</span>
<span class="p_del">- * CPU after push_cpu. That is, if CPU 1, 4 and 5 are overloaded when CPU 3</span>
<span class="p_del">- * schedules a lower priority task, and the IPI_RESTART gets set while the</span>
<span class="p_del">- * handling is being done on CPU 5, it will clear the flag and send it back to</span>
<span class="p_del">- * CPU 4 instead of CPU 1.</span>
<span class="p_del">- *</span>
<span class="p_del">- * Note, the above logic can be disabled by turning off the sched_feature</span>
<span class="p_del">- * RT_PUSH_IPI. Then the rq lock of the overloaded CPU will simply be</span>
<span class="p_del">- * taken by the CPU requesting a pull and the waiting RT task will be pulled</span>
<span class="p_del">- * by that CPU. This may be fine for machines with few CPUs.</span>
<span class="p_del">- */</span>
<span class="p_del">-static void tell_cpu_to_push(struct rq *rq)</span>
<span class="p_add">+static inline void rto_start_unlock(atomic_t *v)</span>
 {
<span class="p_del">-	int cpu;</span>
<span class="p_add">+	atomic_set_release(v, 0);</span>
<span class="p_add">+}</span>
 
<span class="p_del">-	if (rq-&gt;rt.push_flags &amp; RT_PUSH_IPI_EXECUTING) {</span>
<span class="p_del">-		raw_spin_lock(&amp;rq-&gt;rt.push_lock);</span>
<span class="p_del">-		/* Make sure it&#39;s still executing */</span>
<span class="p_del">-		if (rq-&gt;rt.push_flags &amp; RT_PUSH_IPI_EXECUTING) {</span>
<span class="p_del">-			/*</span>
<span class="p_del">-			 * Tell the IPI to restart the loop as things have</span>
<span class="p_del">-			 * changed since it started.</span>
<span class="p_del">-			 */</span>
<span class="p_del">-			rq-&gt;rt.push_flags |= RT_PUSH_IPI_RESTART;</span>
<span class="p_del">-			raw_spin_unlock(&amp;rq-&gt;rt.push_lock);</span>
<span class="p_del">-			return;</span>
<span class="p_del">-		}</span>
<span class="p_del">-		raw_spin_unlock(&amp;rq-&gt;rt.push_lock);</span>
<span class="p_del">-	}</span>
<span class="p_add">+static void tell_cpu_to_push(struct rq *rq)</span>
<span class="p_add">+{</span>
<span class="p_add">+	int cpu = -1;</span>
 
<span class="p_del">-	/* When here, there&#39;s no IPI going around */</span>
<span class="p_add">+	/* Keep the loop going if the IPI is currently active */</span>
<span class="p_add">+	atomic_inc(&amp;rq-&gt;rd-&gt;rto_loop_next);</span>
 
<span class="p_del">-	rq-&gt;rt.push_cpu = rq-&gt;cpu;</span>
<span class="p_del">-	cpu = find_next_push_cpu(rq);</span>
<span class="p_del">-	if (cpu &gt;= nr_cpu_ids)</span>
<span class="p_add">+	/* Only one CPU can initiate a loop at a time */</span>
<span class="p_add">+	if (!rto_start_trylock(&amp;rq-&gt;rd-&gt;rto_loop_start))</span>
 		return;
 
<span class="p_del">-	rq-&gt;rt.push_flags = RT_PUSH_IPI_EXECUTING;</span>
<span class="p_add">+	raw_spin_lock(&amp;rq-&gt;rd-&gt;rto_lock);</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * The rto_cpu is updated under the lock, if it has a valid cpu</span>
<span class="p_add">+	 * then the IPI is still running and will continue due to the</span>
<span class="p_add">+	 * update to loop_next, and nothing needs to be done here.</span>
<span class="p_add">+	 * Otherwise it is finishing up and an ipi needs to be sent.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	if (rq-&gt;rd-&gt;rto_cpu &lt; 0)</span>
<span class="p_add">+		cpu = rto_next_cpu(rq);</span>
 
<span class="p_del">-	irq_work_queue_on(&amp;rq-&gt;rt.push_work, cpu);</span>
<span class="p_add">+	raw_spin_unlock(&amp;rq-&gt;rd-&gt;rto_lock);</span>
<span class="p_add">+</span>
<span class="p_add">+	rto_start_unlock(&amp;rq-&gt;rd-&gt;rto_loop_start);</span>
<span class="p_add">+</span>
<span class="p_add">+	if (cpu &gt;= 0)</span>
<span class="p_add">+		irq_work_queue_on(&amp;rq-&gt;rd-&gt;rto_push_work, cpu);</span>
 }
 
 /* Called from hardirq context */
<span class="p_del">-static void try_to_push_tasks(void *arg)</span>
<span class="p_add">+void rto_push_irq_work_func(struct irq_work *work)</span>
 {
<span class="p_del">-	struct rt_rq *rt_rq = arg;</span>
<span class="p_del">-	struct rq *rq, *src_rq;</span>
<span class="p_del">-	int this_cpu;</span>
<span class="p_add">+	struct rq *rq;</span>
 	int cpu;
 
<span class="p_del">-	this_cpu = rt_rq-&gt;push_cpu;</span>
<span class="p_add">+	rq = this_rq();</span>
 
<span class="p_del">-	/* Paranoid check */</span>
<span class="p_del">-	BUG_ON(this_cpu != smp_processor_id());</span>
<span class="p_del">-</span>
<span class="p_del">-	rq = cpu_rq(this_cpu);</span>
<span class="p_del">-	src_rq = rq_of_rt_rq(rt_rq);</span>
<span class="p_del">-</span>
<span class="p_del">-again:</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * We do not need to grab the lock to check for has_pushable_tasks.</span>
<span class="p_add">+	 * When it gets updated, a check is made if a push is possible.</span>
<span class="p_add">+	 */</span>
 	if (has_pushable_tasks(rq)) {
 		raw_spin_lock(&amp;rq-&gt;lock);
<span class="p_del">-		push_rt_task(rq);</span>
<span class="p_add">+		push_rt_tasks(rq);</span>
 		raw_spin_unlock(&amp;rq-&gt;lock);
 	}
 
<span class="p_del">-	/* Pass the IPI to the next rt overloaded queue */</span>
<span class="p_del">-	raw_spin_lock(&amp;rt_rq-&gt;push_lock);</span>
<span class="p_del">-	/*</span>
<span class="p_del">-	 * If the source queue changed since the IPI went out,</span>
<span class="p_del">-	 * we need to restart the search from that CPU again.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	if (rt_rq-&gt;push_flags &amp; RT_PUSH_IPI_RESTART) {</span>
<span class="p_del">-		rt_rq-&gt;push_flags &amp;= ~RT_PUSH_IPI_RESTART;</span>
<span class="p_del">-		rt_rq-&gt;push_cpu = src_rq-&gt;cpu;</span>
<span class="p_del">-	}</span>
<span class="p_add">+	raw_spin_lock(&amp;rq-&gt;rd-&gt;rto_lock);</span>
 
<span class="p_del">-	cpu = find_next_push_cpu(src_rq);</span>
<span class="p_add">+	/* Pass the IPI to the next rt overloaded queue */</span>
<span class="p_add">+	cpu = rto_next_cpu(rq);</span>
 
<span class="p_del">-	if (cpu &gt;= nr_cpu_ids)</span>
<span class="p_del">-		rt_rq-&gt;push_flags &amp;= ~RT_PUSH_IPI_EXECUTING;</span>
<span class="p_del">-	raw_spin_unlock(&amp;rt_rq-&gt;push_lock);</span>
<span class="p_add">+	raw_spin_unlock(&amp;rq-&gt;rd-&gt;rto_lock);</span>
 
<span class="p_del">-	if (cpu &gt;= nr_cpu_ids)</span>
<span class="p_add">+	if (cpu &lt; 0)</span>
 		return;
 
<span class="p_del">-	/*</span>
<span class="p_del">-	 * It is possible that a restart caused this CPU to be</span>
<span class="p_del">-	 * chosen again. Don&#39;t bother with an IPI, just see if we</span>
<span class="p_del">-	 * have more to push.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	if (unlikely(cpu == rq-&gt;cpu))</span>
<span class="p_del">-		goto again;</span>
<span class="p_del">-</span>
 	/* Try the next RT overloaded CPU */
<span class="p_del">-	irq_work_queue_on(&amp;rt_rq-&gt;push_work, cpu);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static void push_irq_work_func(struct irq_work *work)</span>
<span class="p_del">-{</span>
<span class="p_del">-	struct rt_rq *rt_rq = container_of(work, struct rt_rq, push_work);</span>
<span class="p_del">-</span>
<span class="p_del">-	try_to_push_tasks(rt_rq);</span>
<span class="p_add">+	irq_work_queue_on(&amp;rq-&gt;rd-&gt;rto_push_work, cpu);</span>
 }
 #endif /* HAVE_RT_PUSH_IPI */
 
<span class="p_header">diff --git a/kernel/sched/sched.h b/kernel/sched/sched.h</span>
<span class="p_header">index 3b448ba82225..b732e779fe7d 100644</span>
<span class="p_header">--- a/kernel/sched/sched.h</span>
<span class="p_header">+++ b/kernel/sched/sched.h</span>
<span class="p_chunk">@@ -502,7 +502,7 @@</span> <span class="p_context"> static inline int rt_bandwidth_enabled(void)</span>
 }
 
 /* RT IPI pull logic requires IRQ_WORK */
<span class="p_del">-#ifdef CONFIG_IRQ_WORK</span>
<span class="p_add">+#if defined(CONFIG_IRQ_WORK) &amp;&amp; defined(CONFIG_SMP)</span>
 # define HAVE_RT_PUSH_IPI
 #endif
 
<span class="p_chunk">@@ -524,12 +524,6 @@</span> <span class="p_context"> struct rt_rq {</span>
 	unsigned long rt_nr_total;
 	int overloaded;
 	struct plist_head pushable_tasks;
<span class="p_del">-#ifdef HAVE_RT_PUSH_IPI</span>
<span class="p_del">-	int push_flags;</span>
<span class="p_del">-	int push_cpu;</span>
<span class="p_del">-	struct irq_work push_work;</span>
<span class="p_del">-	raw_spinlock_t push_lock;</span>
<span class="p_del">-#endif</span>
 #endif /* CONFIG_SMP */
 	int rt_queued;
 
<span class="p_chunk">@@ -638,6 +632,19 @@</span> <span class="p_context"> struct root_domain {</span>
 	struct dl_bw dl_bw;
 	struct cpudl cpudl;
 
<span class="p_add">+#ifdef HAVE_RT_PUSH_IPI</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * For IPI pull requests, loop across the rto_mask.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	struct irq_work rto_push_work;</span>
<span class="p_add">+	raw_spinlock_t rto_lock;</span>
<span class="p_add">+	/* These are only updated and read within rto_lock */</span>
<span class="p_add">+	int rto_loop;</span>
<span class="p_add">+	int rto_cpu;</span>
<span class="p_add">+	/* These atomics are updated outside of a lock */</span>
<span class="p_add">+	atomic_t rto_loop_next;</span>
<span class="p_add">+	atomic_t rto_loop_start;</span>
<span class="p_add">+#endif</span>
 	/*
 	 * The &quot;RT overload&quot; flag: it gets set if a CPU has more than
 	 * one runnable RT task.
<span class="p_chunk">@@ -655,6 +662,9 @@</span> <span class="p_context"> extern void init_defrootdomain(void);</span>
 extern int sched_init_domains(const struct cpumask *cpu_map);
 extern void rq_attach_root(struct rq *rq, struct root_domain *rd);
 
<span class="p_add">+#ifdef HAVE_RT_PUSH_IPI</span>
<span class="p_add">+extern void rto_push_irq_work_func(struct irq_work *work);</span>
<span class="p_add">+#endif</span>
 #endif /* CONFIG_SMP */
 
 /*
<span class="p_header">diff --git a/kernel/sched/topology.c b/kernel/sched/topology.c</span>
<span class="p_header">index 6798276d29af..093f2ceba2e2 100644</span>
<span class="p_header">--- a/kernel/sched/topology.c</span>
<span class="p_header">+++ b/kernel/sched/topology.c</span>
<span class="p_chunk">@@ -269,6 +269,12 @@</span> <span class="p_context"> static int init_rootdomain(struct root_domain *rd)</span>
 	if (!zalloc_cpumask_var(&amp;rd-&gt;rto_mask, GFP_KERNEL))
 		goto free_dlo_mask;
 
<span class="p_add">+#ifdef HAVE_RT_PUSH_IPI</span>
<span class="p_add">+	rd-&gt;rto_cpu = -1;</span>
<span class="p_add">+	raw_spin_lock_init(&amp;rd-&gt;rto_lock);</span>
<span class="p_add">+	init_irq_work(&amp;rd-&gt;rto_push_work, rto_push_irq_work_func);</span>
<span class="p_add">+#endif</span>
<span class="p_add">+</span>
 	init_dl_bw(&amp;rd-&gt;dl_bw);
 	if (cpudl_init(&amp;rd-&gt;cpudl) != 0)
 		goto free_rto_mask;
<span class="p_header">diff --git a/lib/mpi/mpi-pow.c b/lib/mpi/mpi-pow.c</span>
<span class="p_header">index e24388a863a7..468fb7cd1221 100644</span>
<span class="p_header">--- a/lib/mpi/mpi-pow.c</span>
<span class="p_header">+++ b/lib/mpi/mpi-pow.c</span>
<span class="p_chunk">@@ -26,6 +26,7 @@</span> <span class="p_context"></span>
  *	 however I decided to publish this code under the plain GPL.
  */
 
<span class="p_add">+#include &lt;linux/sched.h&gt;</span>
 #include &lt;linux/string.h&gt;
 #include &quot;mpi-internal.h&quot;
 #include &quot;longlong.h&quot;
<span class="p_chunk">@@ -256,6 +257,7 @@</span> <span class="p_context"> int mpi_powm(MPI res, MPI base, MPI exp, MPI mod)</span>
 				}
 				e &lt;&lt;= 1;
 				c--;
<span class="p_add">+				cond_resched();</span>
 			}
 
 			i--;
<span class="p_header">diff --git a/mm/z3fold.c b/mm/z3fold.c</span>
<span class="p_header">index b2ba2ba585f3..39e19125d6a0 100644</span>
<span class="p_header">--- a/mm/z3fold.c</span>
<span class="p_header">+++ b/mm/z3fold.c</span>
<span class="p_chunk">@@ -404,8 +404,7 @@</span> <span class="p_context"> static void do_compact_page(struct z3fold_header *zhdr, bool locked)</span>
 		WARN_ON(z3fold_page_trylock(zhdr));
 	else
 		z3fold_page_lock(zhdr);
<span class="p_del">-	if (test_bit(PAGE_STALE, &amp;page-&gt;private) ||</span>
<span class="p_del">-	    !test_and_clear_bit(NEEDS_COMPACTING, &amp;page-&gt;private)) {</span>
<span class="p_add">+	if (WARN_ON(!test_and_clear_bit(NEEDS_COMPACTING, &amp;page-&gt;private))) {</span>
 		z3fold_page_unlock(zhdr);
 		return;
 	}
<span class="p_chunk">@@ -413,6 +412,11 @@</span> <span class="p_context"> static void do_compact_page(struct z3fold_header *zhdr, bool locked)</span>
 	list_del_init(&amp;zhdr-&gt;buddy);
 	spin_unlock(&amp;pool-&gt;lock);
 
<span class="p_add">+	if (kref_put(&amp;zhdr-&gt;refcount, release_z3fold_page_locked)) {</span>
<span class="p_add">+		atomic64_dec(&amp;pool-&gt;pages_nr);</span>
<span class="p_add">+		return;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
 	z3fold_compact_page(zhdr);
 	unbuddied = get_cpu_ptr(pool-&gt;unbuddied);
 	fchunks = num_free_chunks(zhdr);
<span class="p_chunk">@@ -753,9 +757,11 @@</span> <span class="p_context"> static void z3fold_free(struct z3fold_pool *pool, unsigned long handle)</span>
 		list_del_init(&amp;zhdr-&gt;buddy);
 		spin_unlock(&amp;pool-&gt;lock);
 		zhdr-&gt;cpu = -1;
<span class="p_add">+		kref_get(&amp;zhdr-&gt;refcount);</span>
 		do_compact_page(zhdr, true);
 		return;
 	}
<span class="p_add">+	kref_get(&amp;zhdr-&gt;refcount);</span>
 	queue_work_on(zhdr-&gt;cpu, pool-&gt;compact_wq, &amp;zhdr-&gt;work);
 	z3fold_page_unlock(zhdr);
 }
<span class="p_header">diff --git a/net/9p/client.c b/net/9p/client.c</span>
<span class="p_header">index 4674235b0d9b..b433aff5ff13 100644</span>
<span class="p_header">--- a/net/9p/client.c</span>
<span class="p_header">+++ b/net/9p/client.c</span>
<span class="p_chunk">@@ -82,7 +82,7 @@</span> <span class="p_context"> int p9_show_client_options(struct seq_file *m, struct p9_client *clnt)</span>
 {
 	if (clnt-&gt;msize != 8192)
 		seq_printf(m, &quot;,msize=%u&quot;, clnt-&gt;msize);
<span class="p_del">-	seq_printf(m, &quot;trans=%s&quot;, clnt-&gt;trans_mod-&gt;name);</span>
<span class="p_add">+	seq_printf(m, &quot;,trans=%s&quot;, clnt-&gt;trans_mod-&gt;name);</span>
 
 	switch (clnt-&gt;proto_version) {
 	case p9_proto_legacy:
<span class="p_chunk">@@ -773,8 +773,7 @@</span> <span class="p_context"> p9_client_rpc(struct p9_client *c, int8_t type, const char *fmt, ...)</span>
 	}
 again:
 	/* Wait for the response */
<span class="p_del">-	err = wait_event_interruptible(*req-&gt;wq,</span>
<span class="p_del">-				       req-&gt;status &gt;= REQ_STATUS_RCVD);</span>
<span class="p_add">+	err = wait_event_killable(*req-&gt;wq, req-&gt;status &gt;= REQ_STATUS_RCVD);</span>
 
 	/*
 	 * Make sure our req is coherent with regard to updates in other
<span class="p_header">diff --git a/net/9p/trans_fd.c b/net/9p/trans_fd.c</span>
<span class="p_header">index 903a190319b9..985046ae4231 100644</span>
<span class="p_header">--- a/net/9p/trans_fd.c</span>
<span class="p_header">+++ b/net/9p/trans_fd.c</span>
<span class="p_chunk">@@ -724,12 +724,12 @@</span> <span class="p_context"> static int p9_fd_show_options(struct seq_file *m, struct p9_client *clnt)</span>
 {
 	if (clnt-&gt;trans_mod == &amp;p9_tcp_trans) {
 		if (clnt-&gt;trans_opts.tcp.port != P9_PORT)
<span class="p_del">-			seq_printf(m, &quot;port=%u&quot;, clnt-&gt;trans_opts.tcp.port);</span>
<span class="p_add">+			seq_printf(m, &quot;,port=%u&quot;, clnt-&gt;trans_opts.tcp.port);</span>
 	} else if (clnt-&gt;trans_mod == &amp;p9_fd_trans) {
 		if (clnt-&gt;trans_opts.fd.rfd != ~0)
<span class="p_del">-			seq_printf(m, &quot;rfd=%u&quot;, clnt-&gt;trans_opts.fd.rfd);</span>
<span class="p_add">+			seq_printf(m, &quot;,rfd=%u&quot;, clnt-&gt;trans_opts.fd.rfd);</span>
 		if (clnt-&gt;trans_opts.fd.wfd != ~0)
<span class="p_del">-			seq_printf(m, &quot;wfd=%u&quot;, clnt-&gt;trans_opts.fd.wfd);</span>
<span class="p_add">+			seq_printf(m, &quot;,wfd=%u&quot;, clnt-&gt;trans_opts.fd.wfd);</span>
 	}
 	return 0;
 }
<span class="p_header">diff --git a/net/9p/trans_virtio.c b/net/9p/trans_virtio.c</span>
<span class="p_header">index f24b25c25106..f3a4efcf1456 100644</span>
<span class="p_header">--- a/net/9p/trans_virtio.c</span>
<span class="p_header">+++ b/net/9p/trans_virtio.c</span>
<span class="p_chunk">@@ -286,8 +286,8 @@</span> <span class="p_context"> p9_virtio_request(struct p9_client *client, struct p9_req_t *req)</span>
 		if (err == -ENOSPC) {
 			chan-&gt;ring_bufs_avail = 0;
 			spin_unlock_irqrestore(&amp;chan-&gt;lock, flags);
<span class="p_del">-			err = wait_event_interruptible(*chan-&gt;vc_wq,</span>
<span class="p_del">-							chan-&gt;ring_bufs_avail);</span>
<span class="p_add">+			err = wait_event_killable(*chan-&gt;vc_wq,</span>
<span class="p_add">+						  chan-&gt;ring_bufs_avail);</span>
 			if (err  == -ERESTARTSYS)
 				return err;
 
<span class="p_chunk">@@ -327,7 +327,7 @@</span> <span class="p_context"> static int p9_get_mapped_pages(struct virtio_chan *chan,</span>
 		 * Other zc request to finish here
 		 */
 		if (atomic_read(&amp;vp_pinned) &gt;= chan-&gt;p9_max_pages) {
<span class="p_del">-			err = wait_event_interruptible(vp_wq,</span>
<span class="p_add">+			err = wait_event_killable(vp_wq,</span>
 			      (atomic_read(&amp;vp_pinned) &lt; chan-&gt;p9_max_pages));
 			if (err == -ERESTARTSYS)
 				return err;
<span class="p_chunk">@@ -471,8 +471,8 @@</span> <span class="p_context"> p9_virtio_zc_request(struct p9_client *client, struct p9_req_t *req,</span>
 		if (err == -ENOSPC) {
 			chan-&gt;ring_bufs_avail = 0;
 			spin_unlock_irqrestore(&amp;chan-&gt;lock, flags);
<span class="p_del">-			err = wait_event_interruptible(*chan-&gt;vc_wq,</span>
<span class="p_del">-						       chan-&gt;ring_bufs_avail);</span>
<span class="p_add">+			err = wait_event_killable(*chan-&gt;vc_wq,</span>
<span class="p_add">+						  chan-&gt;ring_bufs_avail);</span>
 			if (err  == -ERESTARTSYS)
 				goto err_out;
 
<span class="p_chunk">@@ -489,8 +489,7 @@</span> <span class="p_context"> p9_virtio_zc_request(struct p9_client *client, struct p9_req_t *req,</span>
 	virtqueue_kick(chan-&gt;vq);
 	spin_unlock_irqrestore(&amp;chan-&gt;lock, flags);
 	p9_debug(P9_DEBUG_TRANS, &quot;virtio request kicked\n&quot;);
<span class="p_del">-	err = wait_event_interruptible(*req-&gt;wq,</span>
<span class="p_del">-				       req-&gt;status &gt;= REQ_STATUS_RCVD);</span>
<span class="p_add">+	err = wait_event_killable(*req-&gt;wq, req-&gt;status &gt;= REQ_STATUS_RCVD);</span>
 	/*
 	 * Non kernel buffers are pinned, unpin them
 	 */
<span class="p_header">diff --git a/net/9p/trans_xen.c b/net/9p/trans_xen.c</span>
<span class="p_header">index 6ad3e043c617..325c56043007 100644</span>
<span class="p_header">--- a/net/9p/trans_xen.c</span>
<span class="p_header">+++ b/net/9p/trans_xen.c</span>
<span class="p_chunk">@@ -156,8 +156,8 @@</span> <span class="p_context"> static int p9_xen_request(struct p9_client *client, struct p9_req_t *p9_req)</span>
 	ring = &amp;priv-&gt;rings[num];
 
 again:
<span class="p_del">-	while (wait_event_interruptible(ring-&gt;wq,</span>
<span class="p_del">-					p9_xen_write_todo(ring, size)) != 0)</span>
<span class="p_add">+	while (wait_event_killable(ring-&gt;wq,</span>
<span class="p_add">+				   p9_xen_write_todo(ring, size)) != 0)</span>
 		;
 
 	spin_lock_irqsave(&amp;ring-&gt;lock, flags);
<span class="p_header">diff --git a/net/ceph/crypto.c b/net/ceph/crypto.c</span>
<span class="p_header">index 489610ac1cdd..bf9d079cbafd 100644</span>
<span class="p_header">--- a/net/ceph/crypto.c</span>
<span class="p_header">+++ b/net/ceph/crypto.c</span>
<span class="p_chunk">@@ -37,7 +37,9 @@</span> <span class="p_context"> static int set_secret(struct ceph_crypto_key *key, void *buf)</span>
 		return -ENOTSUPP;
 	}
 
<span class="p_del">-	WARN_ON(!key-&gt;len);</span>
<span class="p_add">+	if (!key-&gt;len)</span>
<span class="p_add">+		return -EINVAL;</span>
<span class="p_add">+</span>
 	key-&gt;key = kmemdup(buf, key-&gt;len, GFP_NOIO);
 	if (!key-&gt;key) {
 		ret = -ENOMEM;
<span class="p_header">diff --git a/net/nfc/core.c b/net/nfc/core.c</span>
<span class="p_header">index 5cf33df888c3..c699d64a0753 100644</span>
<span class="p_header">--- a/net/nfc/core.c</span>
<span class="p_header">+++ b/net/nfc/core.c</span>
<span class="p_chunk">@@ -1106,7 +1106,7 @@</span> <span class="p_context"> struct nfc_dev *nfc_allocate_device(struct nfc_ops *ops,</span>
 err_free_dev:
 	kfree(dev);
 
<span class="p_del">-	return ERR_PTR(rc);</span>
<span class="p_add">+	return NULL;</span>
 }
 EXPORT_SYMBOL(nfc_allocate_device);
 
<span class="p_header">diff --git a/net/sunrpc/xprtrdma/svc_rdma_backchannel.c b/net/sunrpc/xprtrdma/svc_rdma_backchannel.c</span>
<span class="p_header">index 992594b7cc6b..af7893501e40 100644</span>
<span class="p_header">--- a/net/sunrpc/xprtrdma/svc_rdma_backchannel.c</span>
<span class="p_header">+++ b/net/sunrpc/xprtrdma/svc_rdma_backchannel.c</span>
<span class="p_chunk">@@ -133,6 +133,10 @@</span> <span class="p_context"> static int svc_rdma_bc_sendto(struct svcxprt_rdma *rdma,</span>
 	if (ret)
 		goto out_err;
 
<span class="p_add">+	/* Bump page refcnt so Send completion doesn&#39;t release</span>
<span class="p_add">+	 * the rq_buffer before all retransmits are complete.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	get_page(virt_to_page(rqst-&gt;rq_buffer));</span>
 	ret = svc_rdma_post_send_wr(rdma, ctxt, 1, 0);
 	if (ret)
 		goto out_unmap;
<span class="p_chunk">@@ -165,7 +169,6 @@</span> <span class="p_context"> xprt_rdma_bc_allocate(struct rpc_task *task)</span>
 		return -EINVAL;
 	}
 
<span class="p_del">-	/* svc_rdma_sendto releases this page */</span>
 	page = alloc_page(RPCRDMA_DEF_GFP);
 	if (!page)
 		return -ENOMEM;
<span class="p_chunk">@@ -184,6 +187,7 @@</span> <span class="p_context"> xprt_rdma_bc_free(struct rpc_task *task)</span>
 {
 	struct rpc_rqst *rqst = task-&gt;tk_rqstp;
 
<span class="p_add">+	put_page(virt_to_page(rqst-&gt;rq_buffer));</span>
 	kfree(rqst-&gt;rq_rbuffer);
 }
 
<span class="p_header">diff --git a/sound/core/pcm_lib.c b/sound/core/pcm_lib.c</span>
<span class="p_header">index a93a4235a332..10e7ef7a8804 100644</span>
<span class="p_header">--- a/sound/core/pcm_lib.c</span>
<span class="p_header">+++ b/sound/core/pcm_lib.c</span>
<span class="p_chunk">@@ -248,8 +248,10 @@</span> <span class="p_context"> static void update_audio_tstamp(struct snd_pcm_substream *substream,</span>
 				runtime-&gt;rate);
 		*audio_tstamp = ns_to_timespec(audio_nsecs);
 	}
<span class="p_del">-	runtime-&gt;status-&gt;audio_tstamp = *audio_tstamp;</span>
<span class="p_del">-	runtime-&gt;status-&gt;tstamp = *curr_tstamp;</span>
<span class="p_add">+	if (!timespec_equal(&amp;runtime-&gt;status-&gt;audio_tstamp, audio_tstamp)) {</span>
<span class="p_add">+		runtime-&gt;status-&gt;audio_tstamp = *audio_tstamp;</span>
<span class="p_add">+		runtime-&gt;status-&gt;tstamp = *curr_tstamp;</span>
<span class="p_add">+	}</span>
 
 	/*
 	 * re-take a driver timestamp to let apps detect if the reference tstamp
<span class="p_header">diff --git a/sound/core/timer_compat.c b/sound/core/timer_compat.c</span>
<span class="p_header">index 59127b6ef39e..e00f7e399e46 100644</span>
<span class="p_header">--- a/sound/core/timer_compat.c</span>
<span class="p_header">+++ b/sound/core/timer_compat.c</span>
<span class="p_chunk">@@ -66,11 +66,11 @@</span> <span class="p_context"> static int snd_timer_user_info_compat(struct file *file,</span>
 	struct snd_timer *t;
 
 	tu = file-&gt;private_data;
<span class="p_del">-	if (snd_BUG_ON(!tu-&gt;timeri))</span>
<span class="p_del">-		return -ENXIO;</span>
<span class="p_add">+	if (!tu-&gt;timeri)</span>
<span class="p_add">+		return -EBADFD;</span>
 	t = tu-&gt;timeri-&gt;timer;
<span class="p_del">-	if (snd_BUG_ON(!t))</span>
<span class="p_del">-		return -ENXIO;</span>
<span class="p_add">+	if (!t)</span>
<span class="p_add">+		return -EBADFD;</span>
 	memset(&amp;info, 0, sizeof(info));
 	info.card = t-&gt;card ? t-&gt;card-&gt;number : -1;
 	if (t-&gt;hw.flags &amp; SNDRV_TIMER_HW_SLAVE)
<span class="p_chunk">@@ -99,8 +99,8 @@</span> <span class="p_context"> static int snd_timer_user_status_compat(struct file *file,</span>
 	struct snd_timer_status32 status;
 	
 	tu = file-&gt;private_data;
<span class="p_del">-	if (snd_BUG_ON(!tu-&gt;timeri))</span>
<span class="p_del">-		return -ENXIO;</span>
<span class="p_add">+	if (!tu-&gt;timeri)</span>
<span class="p_add">+		return -EBADFD;</span>
 	memset(&amp;status, 0, sizeof(status));
 	status.tstamp.tv_sec = tu-&gt;tstamp.tv_sec;
 	status.tstamp.tv_nsec = tu-&gt;tstamp.tv_nsec;
<span class="p_header">diff --git a/sound/core/vmaster.c b/sound/core/vmaster.c</span>
<span class="p_header">index e43af18d4383..8632301489fa 100644</span>
<span class="p_header">--- a/sound/core/vmaster.c</span>
<span class="p_header">+++ b/sound/core/vmaster.c</span>
<span class="p_chunk">@@ -495,7 +495,9 @@</span> <span class="p_context"> EXPORT_SYMBOL_GPL(snd_ctl_sync_vmaster);</span>
  * Returns 0 if successful, or a negative error code.
  */
 int snd_ctl_apply_vmaster_slaves(struct snd_kcontrol *kctl,
<span class="p_del">-				 int (*func)(struct snd_kcontrol *, void *),</span>
<span class="p_add">+				 int (*func)(struct snd_kcontrol *vslave,</span>
<span class="p_add">+					     struct snd_kcontrol *slave,</span>
<span class="p_add">+					     void *arg),</span>
 				 void *arg)
 {
 	struct link_master *master;
<span class="p_chunk">@@ -507,7 +509,7 @@</span> <span class="p_context"> int snd_ctl_apply_vmaster_slaves(struct snd_kcontrol *kctl,</span>
 	if (err &lt; 0)
 		return err;
 	list_for_each_entry(slave, &amp;master-&gt;slaves, list) {
<span class="p_del">-		err = func(&amp;slave-&gt;slave, arg);</span>
<span class="p_add">+		err = func(slave-&gt;kctl, &amp;slave-&gt;slave, arg);</span>
 		if (err &lt; 0)
 			return err;
 	}
<span class="p_header">diff --git a/sound/hda/hdmi_chmap.c b/sound/hda/hdmi_chmap.c</span>
<span class="p_header">index 81acc20c2535..f21633cd9b38 100644</span>
<span class="p_header">--- a/sound/hda/hdmi_chmap.c</span>
<span class="p_header">+++ b/sound/hda/hdmi_chmap.c</span>
<span class="p_chunk">@@ -746,7 +746,7 @@</span> <span class="p_context"> static int hdmi_chmap_ctl_get(struct snd_kcontrol *kcontrol,</span>
 	memset(pcm_chmap, 0, sizeof(pcm_chmap));
 	chmap-&gt;ops.get_chmap(chmap-&gt;hdac, pcm_idx, pcm_chmap);
 
<span class="p_del">-	for (i = 0; i &lt; sizeof(chmap); i++)</span>
<span class="p_add">+	for (i = 0; i &lt; ARRAY_SIZE(pcm_chmap); i++)</span>
 		ucontrol-&gt;value.integer.value[i] = pcm_chmap[i];
 
 	return 0;
<span class="p_header">diff --git a/sound/pci/hda/hda_codec.c b/sound/pci/hda/hda_codec.c</span>
<span class="p_header">index a0989d231fd0..417abbb1f72c 100644</span>
<span class="p_header">--- a/sound/pci/hda/hda_codec.c</span>
<span class="p_header">+++ b/sound/pci/hda/hda_codec.c</span>
<span class="p_chunk">@@ -1823,7 +1823,9 @@</span> <span class="p_context"> struct slave_init_arg {</span>
 };
 
 /* initialize the slave volume with 0dB via snd_ctl_apply_vmaster_slaves() */
<span class="p_del">-static int init_slave_0dB(struct snd_kcontrol *kctl, void *_arg)</span>
<span class="p_add">+static int init_slave_0dB(struct snd_kcontrol *slave,</span>
<span class="p_add">+			  struct snd_kcontrol *kctl,</span>
<span class="p_add">+			  void *_arg)</span>
 {
 	struct slave_init_arg *arg = _arg;
 	int _tlv[4];
<span class="p_chunk">@@ -1860,7 +1862,7 @@</span> <span class="p_context"> static int init_slave_0dB(struct snd_kcontrol *kctl, void *_arg)</span>
 	arg-&gt;step = step;
 	val = -tlv[2] / step;
 	if (val &gt; 0) {
<span class="p_del">-		put_kctl_with_value(kctl, val);</span>
<span class="p_add">+		put_kctl_with_value(slave, val);</span>
 		return val;
 	}
 
<span class="p_chunk">@@ -1868,7 +1870,9 @@</span> <span class="p_context"> static int init_slave_0dB(struct snd_kcontrol *kctl, void *_arg)</span>
 }
 
 /* unmute the slave via snd_ctl_apply_vmaster_slaves() */
<span class="p_del">-static int init_slave_unmute(struct snd_kcontrol *slave, void *_arg)</span>
<span class="p_add">+static int init_slave_unmute(struct snd_kcontrol *slave,</span>
<span class="p_add">+			     struct snd_kcontrol *kctl,</span>
<span class="p_add">+			     void *_arg)</span>
 {
 	return put_kctl_with_value(slave, 1);
 }
<span class="p_header">diff --git a/sound/pci/hda/hda_intel.c b/sound/pci/hda/hda_intel.c</span>
<span class="p_header">index f958d8d54d15..c71dcacea807 100644</span>
<span class="p_header">--- a/sound/pci/hda/hda_intel.c</span>
<span class="p_header">+++ b/sound/pci/hda/hda_intel.c</span>
<span class="p_chunk">@@ -2463,6 +2463,9 @@</span> <span class="p_context"> static const struct pci_device_id azx_ids[] = {</span>
 	/* AMD Hudson */
 	{ PCI_DEVICE(0x1022, 0x780d),
 	  .driver_data = AZX_DRIVER_GENERIC | AZX_DCAPS_PRESET_ATI_SB },
<span class="p_add">+	/* AMD Raven */</span>
<span class="p_add">+	{ PCI_DEVICE(0x1022, 0x15e3),</span>
<span class="p_add">+	  .driver_data = AZX_DRIVER_GENERIC | AZX_DCAPS_PRESET_ATI_SB },</span>
 	/* ATI HDMI */
 	{ PCI_DEVICE(0x1002, 0x0002),
 	  .driver_data = AZX_DRIVER_ATIHDMI_NS | AZX_DCAPS_PRESET_ATI_HDMI_NS },
<span class="p_header">diff --git a/sound/pci/hda/patch_realtek.c b/sound/pci/hda/patch_realtek.c</span>
<span class="p_header">index dce0682c5001..7c39114d124f 100644</span>
<span class="p_header">--- a/sound/pci/hda/patch_realtek.c</span>
<span class="p_header">+++ b/sound/pci/hda/patch_realtek.c</span>
<span class="p_chunk">@@ -341,6 +341,9 @@</span> <span class="p_context"> static void alc_fill_eapd_coef(struct hda_codec *codec)</span>
 	case 0x10ec0299:
 		alc_update_coef_idx(codec, 0x10, 1&lt;&lt;9, 0);
 		break;
<span class="p_add">+	case 0x10ec0275:</span>
<span class="p_add">+		alc_update_coef_idx(codec, 0xe, 0, 1&lt;&lt;0);</span>
<span class="p_add">+		break;</span>
 	case 0x10ec0293:
 		alc_update_coef_idx(codec, 0xa, 1&lt;&lt;13, 0);
 		break;
<span class="p_chunk">@@ -6863,7 +6866,7 @@</span> <span class="p_context"> static int patch_alc269(struct hda_codec *codec)</span>
 	case 0x10ec0703:
 		spec-&gt;codec_variant = ALC269_TYPE_ALC700;
 		spec-&gt;gen.mixer_nid = 0; /* ALC700 does not have any loopback mixer path */
<span class="p_del">-		alc_update_coef_idx(codec, 0x4a, 0, 1 &lt;&lt; 15); /* Combo jack auto trigger control */</span>
<span class="p_add">+		alc_update_coef_idx(codec, 0x4a, 1 &lt;&lt; 15, 0); /* Combo jack auto trigger control */</span>
 		break;
 
 	}
<span class="p_header">diff --git a/sound/soc/sunxi/sun8i-codec.c b/sound/soc/sunxi/sun8i-codec.c</span>
<span class="p_header">index abfb710df7cb..7a312168f864 100644</span>
<span class="p_header">--- a/sound/soc/sunxi/sun8i-codec.c</span>
<span class="p_header">+++ b/sound/soc/sunxi/sun8i-codec.c</span>
<span class="p_chunk">@@ -73,6 +73,7 @@</span> <span class="p_context"></span>
 #define SUN8I_SYS_SR_CTRL_AIF2_FS_MASK		GENMASK(11, 8)
 #define SUN8I_AIF1CLK_CTRL_AIF1_WORD_SIZ_MASK	GENMASK(5, 4)
 #define SUN8I_AIF1CLK_CTRL_AIF1_LRCK_DIV_MASK	GENMASK(8, 6)
<span class="p_add">+#define SUN8I_AIF1CLK_CTRL_AIF1_BCLK_DIV_MASK	GENMASK(12, 9)</span>
 
 struct sun8i_codec {
 	struct device	*dev;
<span class="p_chunk">@@ -170,11 +171,11 @@</span> <span class="p_context"> static int sun8i_set_fmt(struct snd_soc_dai *dai, unsigned int fmt)</span>
 
 	/* clock masters */
 	switch (fmt &amp; SND_SOC_DAIFMT_MASTER_MASK) {
<span class="p_del">-	case SND_SOC_DAIFMT_CBS_CFS: /* DAI Slave */</span>
<span class="p_del">-		value = 0x0; /* Codec Master */</span>
<span class="p_add">+	case SND_SOC_DAIFMT_CBS_CFS: /* Codec slave, DAI master */</span>
<span class="p_add">+		value = 0x1;</span>
 		break;
<span class="p_del">-	case SND_SOC_DAIFMT_CBM_CFM: /* DAI Master */</span>
<span class="p_del">-		value = 0x1; /* Codec Slave */</span>
<span class="p_add">+	case SND_SOC_DAIFMT_CBM_CFM: /* Codec Master, DAI slave */</span>
<span class="p_add">+		value = 0x0;</span>
 		break;
 	default:
 		return -EINVAL;
<span class="p_chunk">@@ -199,7 +200,7 @@</span> <span class="p_context"> static int sun8i_set_fmt(struct snd_soc_dai *dai, unsigned int fmt)</span>
 			   value &lt;&lt; SUN8I_AIF1CLK_CTRL_AIF1_BCLK_INV);
 	regmap_update_bits(scodec-&gt;regmap, SUN8I_AIF1CLK_CTRL,
 			   BIT(SUN8I_AIF1CLK_CTRL_AIF1_LRCK_INV),
<span class="p_del">-			   value &lt;&lt; SUN8I_AIF1CLK_CTRL_AIF1_LRCK_INV);</span>
<span class="p_add">+			   !value &lt;&lt; SUN8I_AIF1CLK_CTRL_AIF1_LRCK_INV);</span>
 
 	/* DAI format */
 	switch (fmt &amp; SND_SOC_DAIFMT_FORMAT_MASK) {
<span class="p_chunk">@@ -226,12 +227,57 @@</span> <span class="p_context"> static int sun8i_set_fmt(struct snd_soc_dai *dai, unsigned int fmt)</span>
 	return 0;
 }
 
<span class="p_add">+struct sun8i_codec_clk_div {</span>
<span class="p_add">+	u8	div;</span>
<span class="p_add">+	u8	val;</span>
<span class="p_add">+};</span>
<span class="p_add">+</span>
<span class="p_add">+static const struct sun8i_codec_clk_div sun8i_codec_bclk_div[] = {</span>
<span class="p_add">+	{ .div = 1,	.val = 0 },</span>
<span class="p_add">+	{ .div = 2,	.val = 1 },</span>
<span class="p_add">+	{ .div = 4,	.val = 2 },</span>
<span class="p_add">+	{ .div = 6,	.val = 3 },</span>
<span class="p_add">+	{ .div = 8,	.val = 4 },</span>
<span class="p_add">+	{ .div = 12,	.val = 5 },</span>
<span class="p_add">+	{ .div = 16,	.val = 6 },</span>
<span class="p_add">+	{ .div = 24,	.val = 7 },</span>
<span class="p_add">+	{ .div = 32,	.val = 8 },</span>
<span class="p_add">+	{ .div = 48,	.val = 9 },</span>
<span class="p_add">+	{ .div = 64,	.val = 10 },</span>
<span class="p_add">+	{ .div = 96,	.val = 11 },</span>
<span class="p_add">+	{ .div = 128,	.val = 12 },</span>
<span class="p_add">+	{ .div = 192,	.val = 13 },</span>
<span class="p_add">+};</span>
<span class="p_add">+</span>
<span class="p_add">+static u8 sun8i_codec_get_bclk_div(struct sun8i_codec *scodec,</span>
<span class="p_add">+				   unsigned int rate,</span>
<span class="p_add">+				   unsigned int word_size)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long clk_rate = clk_get_rate(scodec-&gt;clk_module);</span>
<span class="p_add">+	unsigned int div = clk_rate / rate / word_size / 2;</span>
<span class="p_add">+	unsigned int best_val = 0, best_diff = ~0;</span>
<span class="p_add">+	int i;</span>
<span class="p_add">+</span>
<span class="p_add">+	for (i = 0; i &lt; ARRAY_SIZE(sun8i_codec_bclk_div); i++) {</span>
<span class="p_add">+		const struct sun8i_codec_clk_div *bdiv = &amp;sun8i_codec_bclk_div[i];</span>
<span class="p_add">+		unsigned int diff = abs(bdiv-&gt;div - div);</span>
<span class="p_add">+</span>
<span class="p_add">+		if (diff &lt; best_diff) {</span>
<span class="p_add">+			best_diff = diff;</span>
<span class="p_add">+			best_val = bdiv-&gt;val;</span>
<span class="p_add">+		}</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	return best_val;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static int sun8i_codec_hw_params(struct snd_pcm_substream *substream,
 				 struct snd_pcm_hw_params *params,
 				 struct snd_soc_dai *dai)
 {
 	struct sun8i_codec *scodec = snd_soc_codec_get_drvdata(dai-&gt;codec);
 	int sample_rate;
<span class="p_add">+	u8 bclk_div;</span>
 
 	/*
 	 * The CPU DAI handles only a sample of 16 bits. Configure the
<span class="p_chunk">@@ -241,6 +287,11 @@</span> <span class="p_context"> static int sun8i_codec_hw_params(struct snd_pcm_substream *substream,</span>
 			   SUN8I_AIF1CLK_CTRL_AIF1_WORD_SIZ_MASK,
 			   SUN8I_AIF1CLK_CTRL_AIF1_WORD_SIZ_16);
 
<span class="p_add">+	bclk_div = sun8i_codec_get_bclk_div(scodec, params_rate(params), 16);</span>
<span class="p_add">+	regmap_update_bits(scodec-&gt;regmap, SUN8I_AIF1CLK_CTRL,</span>
<span class="p_add">+			   SUN8I_AIF1CLK_CTRL_AIF1_BCLK_DIV_MASK,</span>
<span class="p_add">+			   bclk_div &lt;&lt; SUN8I_AIF1CLK_CTRL_AIF1_BCLK_DIV);</span>
<span class="p_add">+</span>
 	regmap_update_bits(scodec-&gt;regmap, SUN8I_AIF1CLK_CTRL,
 			   SUN8I_AIF1CLK_CTRL_AIF1_LRCK_DIV_MASK,
 			   SUN8I_AIF1CLK_CTRL_AIF1_LRCK_DIV_16);
<span class="p_header">diff --git a/sound/usb/clock.c b/sound/usb/clock.c</span>
<span class="p_header">index 26dd5f20f149..eb3396ffba4c 100644</span>
<span class="p_header">--- a/sound/usb/clock.c</span>
<span class="p_header">+++ b/sound/usb/clock.c</span>
<span class="p_chunk">@@ -43,7 +43,7 @@</span> <span class="p_context"> static struct uac_clock_source_descriptor *</span>
 	while ((cs = snd_usb_find_csint_desc(ctrl_iface-&gt;extra,
 					     ctrl_iface-&gt;extralen,
 					     cs, UAC2_CLOCK_SOURCE))) {
<span class="p_del">-		if (cs-&gt;bClockID == clock_id)</span>
<span class="p_add">+		if (cs-&gt;bLength &gt;= sizeof(*cs) &amp;&amp; cs-&gt;bClockID == clock_id)</span>
 			return cs;
 	}
 
<span class="p_chunk">@@ -59,8 +59,11 @@</span> <span class="p_context"> static struct uac_clock_selector_descriptor *</span>
 	while ((cs = snd_usb_find_csint_desc(ctrl_iface-&gt;extra,
 					     ctrl_iface-&gt;extralen,
 					     cs, UAC2_CLOCK_SELECTOR))) {
<span class="p_del">-		if (cs-&gt;bClockID == clock_id)</span>
<span class="p_add">+		if (cs-&gt;bLength &gt;= sizeof(*cs) &amp;&amp; cs-&gt;bClockID == clock_id) {</span>
<span class="p_add">+			if (cs-&gt;bLength &lt; 5 + cs-&gt;bNrInPins)</span>
<span class="p_add">+				return NULL;</span>
 			return cs;
<span class="p_add">+		}</span>
 	}
 
 	return NULL;
<span class="p_chunk">@@ -75,7 +78,7 @@</span> <span class="p_context"> static struct uac_clock_multiplier_descriptor *</span>
 	while ((cs = snd_usb_find_csint_desc(ctrl_iface-&gt;extra,
 					     ctrl_iface-&gt;extralen,
 					     cs, UAC2_CLOCK_MULTIPLIER))) {
<span class="p_del">-		if (cs-&gt;bClockID == clock_id)</span>
<span class="p_add">+		if (cs-&gt;bLength &gt;= sizeof(*cs) &amp;&amp; cs-&gt;bClockID == clock_id)</span>
 			return cs;
 	}
 
<span class="p_header">diff --git a/sound/usb/mixer.c b/sound/usb/mixer.c</span>
<span class="p_header">index 91bc8f18791e..2b835cca41b1 100644</span>
<span class="p_header">--- a/sound/usb/mixer.c</span>
<span class="p_header">+++ b/sound/usb/mixer.c</span>
<span class="p_chunk">@@ -1469,6 +1469,12 @@</span> <span class="p_context"> static int parse_audio_feature_unit(struct mixer_build *state, int unitid,</span>
 	__u8 *bmaControls;
 
 	if (state-&gt;mixer-&gt;protocol == UAC_VERSION_1) {
<span class="p_add">+		if (hdr-&gt;bLength &lt; 7) {</span>
<span class="p_add">+			usb_audio_err(state-&gt;chip,</span>
<span class="p_add">+				      &quot;unit %u: invalid UAC_FEATURE_UNIT descriptor\n&quot;,</span>
<span class="p_add">+				      unitid);</span>
<span class="p_add">+			return -EINVAL;</span>
<span class="p_add">+		}</span>
 		csize = hdr-&gt;bControlSize;
 		if (!csize) {
 			usb_audio_dbg(state-&gt;chip,
<span class="p_chunk">@@ -1486,6 +1492,12 @@</span> <span class="p_context"> static int parse_audio_feature_unit(struct mixer_build *state, int unitid,</span>
 		}
 	} else {
 		struct uac2_feature_unit_descriptor *ftr = _ftr;
<span class="p_add">+		if (hdr-&gt;bLength &lt; 6) {</span>
<span class="p_add">+			usb_audio_err(state-&gt;chip,</span>
<span class="p_add">+				      &quot;unit %u: invalid UAC_FEATURE_UNIT descriptor\n&quot;,</span>
<span class="p_add">+				      unitid);</span>
<span class="p_add">+			return -EINVAL;</span>
<span class="p_add">+		}</span>
 		csize = 4;
 		channels = (hdr-&gt;bLength - 6) / 4 - 1;
 		bmaControls = ftr-&gt;bmaControls;
<span class="p_chunk">@@ -2086,7 +2098,8 @@</span> <span class="p_context"> static int parse_audio_selector_unit(struct mixer_build *state, int unitid,</span>
 	const struct usbmix_name_map *map;
 	char **namelist;
 
<span class="p_del">-	if (!desc-&gt;bNrInPins || desc-&gt;bLength &lt; 5 + desc-&gt;bNrInPins) {</span>
<span class="p_add">+	if (desc-&gt;bLength &lt; 5 || !desc-&gt;bNrInPins ||</span>
<span class="p_add">+	    desc-&gt;bLength &lt; 5 + desc-&gt;bNrInPins) {</span>
 		usb_audio_err(state-&gt;chip,
 			&quot;invalid SELECTOR UNIT descriptor %d\n&quot;, unitid);
 		return -EINVAL;

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



