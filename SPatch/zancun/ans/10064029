
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>[1/2] vfio/type1: Adopt fast IOTLB flush interface when unmap IOVAs - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    [1/2] vfio/type1: Adopt fast IOTLB flush interface when unmap IOVAs</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=2908">Suthikulpanit, Suravee</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>Nov. 17, 2017, 9:11 p.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;1510953080-5619-2-git-send-email-Suravee.Suthikulpanit@amd.com&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/10064029/mbox/"
   >mbox</a>
|
   <a href="/patch/10064029/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/10064029/">/patch/10064029/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
	[172.30.200.125])
	by pdx-korg-patchwork.web.codeaurora.org (Postfix) with ESMTP id
	DEC2E601D3 for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Fri, 17 Nov 2017 21:12:27 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id D284C2AE06
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Fri, 17 Nov 2017 21:12:27 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id C6B9C2AE08; Fri, 17 Nov 2017 21:12:27 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-6.9 required=2.0 tests=BAYES_00,DKIM_SIGNED,
	DKIM_VALID,RCVD_IN_DNSWL_HI autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 343A32AE06
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Fri, 17 Nov 2017 21:12:27 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1762193AbdKQVMV (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Fri, 17 Nov 2017 16:12:21 -0500
Received: from mail-bl2nam02on0089.outbound.protection.outlook.com
	([104.47.38.89]:20274
	&quot;EHLO NAM02-BL2-obe.outbound.protection.outlook.com&quot;
	rhost-flags-OK-OK-OK-FAIL) by vger.kernel.org with ESMTP
	id S1762155AbdKQVLu (ORCPT &lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Fri, 17 Nov 2017 16:11:50 -0500
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
	d=amdcloud.onmicrosoft.com; s=selector1-amd-com;
	h=From:Date:Subject:Message-ID:Content-Type:MIME-Version;
	bh=vYYoZqUaE6nfrxUpeT8W9lVRGvj3ytIHvhSHwQ5QrLU=;
	b=vAOyJ/JaJ6sifEWbUFHqG1wMVI7zFyz8g+T2TuQrmRRw83Gqf/0NzZF3pgTGeBfs44kpCIS4sStEzLmvpakD7n0XpK0H1F+JPN7Faz+0rpWrvHdXJzXV77C5Ox49OW7qSO2BO81gTbMX4Tp2jatcruchDyiwCJeOEuHJGNUTACY=
Authentication-Results: spf=none (sender IP is )
	smtp.mailfrom=Suravee.Suthikulpanit@amd.com; 
Received: from ssuthiku-rhel73-zp.amd.com (165.204.77.1) by
	MWHPR12MB1742.namprd12.prod.outlook.com (10.175.55.13) with Microsoft
	SMTP Server (version=TLS1_2,
	cipher=TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA384_P256) id
	15.20.239.5; Fri, 17 Nov 2017 21:11:45 +0000
From: Suravee Suthikulpanit &lt;Suravee.Suthikulpanit@amd.com&gt;
To: linux-kernel@vger.kernel.org, iommu@lists.linux-foundation.org
Cc: joro@8bytes.org, jroedel@suse.de, alex.williamson@redhat.com,
	Suravee Suthikulpanit &lt;suravee.suthikulpanit@amd.com&gt;
Subject: [PATCH 1/2] vfio/type1: Adopt fast IOTLB flush interface when unmap
	IOVAs
Date: Fri, 17 Nov 2017 15:11:19 -0600
Message-Id: &lt;1510953080-5619-2-git-send-email-Suravee.Suthikulpanit@amd.com&gt;
X-Mailer: git-send-email 1.8.3.1
In-Reply-To: &lt;1510953080-5619-1-git-send-email-Suravee.Suthikulpanit@amd.com&gt;
References: &lt;1510953080-5619-1-git-send-email-Suravee.Suthikulpanit@amd.com&gt;
MIME-Version: 1.0
Content-Type: text/plain
X-Originating-IP: [165.204.77.1]
X-ClientProxiedBy: SN4PR0501CA0100.namprd05.prod.outlook.com (10.167.128.17)
	To MWHPR12MB1742.namprd12.prod.outlook.com (10.175.55.13)
X-MS-PublicTrafficType: Email
X-MS-Office365-Filtering-Correlation-Id: 3c96c3b5-bf0b-430a-2f16-08d52dffcf39
X-MS-Office365-Filtering-HT: Tenant
X-Microsoft-Antispam: UriScan:; BCL:0; PCL:0;
	RULEID:(22001)(4534020)(4602075)(4627115)(201703031133081)(201702281549075)(48565401081)(2017052603258);
	SRVR:MWHPR12MB1742; 
X-Microsoft-Exchange-Diagnostics: 1; MWHPR12MB1742;
	3:GBmHWvCgkwxYNy24/uLhEYeSfir9vui3JmfDDcmFiuIXsUDNe6uXkcL+Y4iImSJ6Y2YIgt76B4y0CpeHOQbWxwKMlOEWbZwV6jcCz1sqK2vsJqaas9rv4DCFcIDrnZwvxV49N6gPB0NfFjjGM5IbT25qN/Kqgt/BO1cJat+Jz/t88VKiE6ajDLtvfAKkTuPQvkVU9RLrCgyb4zETayu0KZSqVzXnjFISedRJ2arLSUyw9OUZJCUnn2y11aYqOfwa;
	25:h0WacVBI6/1gEiBBKUE14/zosei+xdXM3ZkaHTOU0NcCDswOIv/QX0sosRe10IC/w44wsbIiH99mvHOb9H5BHjfEcrXDeDityF31V8s/Vvu4O0Wog2d0UFK9hEIq9mTy1n3ozFE3XjAdY6lHRteLKKZbGVwpxcLKArMJedhwOU21lASR8jT8i37XBl0WqHc3EG4nUUfYW1KVADyI5khJC2f2JBxbZomFcxgxGv9XV5wi0VAPTKsW3LfnmjlmAZ1ejVFqO/Wi4YqxzgIKXDfEWsO/wStNAdrgyX4++ZQc8a86Q49nXz9SslhSgXernZydA7CGXFipOCgDQZvN3HiqmQ==;
	31:beblAlB2knse/lG1JI8F8GKGt2+uDx8/YuxExgq9KHtPWkY5hjI3/dAxw80zyGCMAOcbw5fdlEYTQPoooWE+czLshDxwu8nz+5CgCGmmF+UWBprQ47sfJJ1N8w5qintDExkBFXlv+f624nIU1IVFDtDaYoiFAjtvAoULvvPt5w7on+tkL7BlInzeW8de40lWwGw3xR1JhuCLtodyjJh3Ok+qzSUXRRUwVZfTN9Iw2fY=
X-MS-TrafficTypeDiagnostic: MWHPR12MB1742:
X-Microsoft-Exchange-Diagnostics: 1; MWHPR12MB1742;
	20:NH5RUsYRl0CarCWQhKYZrVIIntbVds4p0YRnNxGoQ31mMpo4gsbYyM3quzCyr+8C6B11GRR1phuafqyMTwpL7I8eqKihSJ2dFa2DCKc00qNY31ELhRvPziIICn7I193JaohzT9MWd1lZnKIMAZNMYwa3lS3EfTPOw8hrIhylRqHA1bqcXy4Ts/UP3ToHKBYZTMi7i0t+e9s/7fOovN/n3LaQoiMfFX3AT0HyrNEgM3iZktm8tLLeXV4CYH8tybMfIYoyUMsJRKtnN3MjDX6KQra89SNITs6uMyoZpr7WWLo4tbUoGWZssewALyrkQoNgnT6YiGehYLPZAxkbudCYgoMunkhMuB2YKh85JQ2+I4p2kP8/iDNQrfyQO8EfLQrKfZV1s/YZMsKZX66YF/NHxPFKDJQfCncOUqaYLul/y4rYgZUb8yhJWV6ffsnS36sGuSdfBeiyRZRndTWdiH3iZi18Yso0OAhlqUmAzcWF4ltlfD2A/fR4gJkAAP+VW7HQ;
	4:ypr0OWslydMu7XB6ylRx0tNG/j9vtIGp532B3OGkOgkIJNt2mY47PzaUFRs6II84YjqEo1pDfIGSk3/G1sygpX3F4PqCi/p8wR9jaQej6Yi9hNS7L8g1rS5F97O/4N/rz51XhnT/gFYv/PCwRDx+bgdCCl9hEPFT7XrhuatXPriOZZF6gq88K5cAcH1+Sj+Ev792QZLrWOvfjXmGwBgCx8n+KZ0yYS6tBTbyllFzuUnrivudU1Y/xHwBTjjXttC3w6NGQTvCNzGL23uPadnFdTOGVrZlZpCdOvimkgmgPWxZDsj/xMhLHwwzOPH8EitL
X-Microsoft-Antispam-PRVS: &lt;MWHPR12MB1742F7F6C03E08C448413092F32F0@MWHPR12MB1742.namprd12.prod.outlook.com&gt;
X-Exchange-Antispam-Report-Test: UriScan:(767451399110);
X-Exchange-Antispam-Report-CFA-Test: BCL:0; PCL:0;
	RULEID:(100000700101)(100105000095)(100000701101)(100105300095)(100000702101)(100105100095)(6040450)(2401047)(8121501046)(5005006)(10201501046)(100000703101)(100105400095)(3231022)(93006095)(93001095)(3002001)(6055026)(6041248)(20161123555025)(201703131423075)(201702281528075)(201703061421075)(201703061406153)(20161123562025)(20161123560025)(20161123558100)(20161123564025)(6072148)(201708071742011)(100000704101)(100105200095)(100000705101)(100105500095);
	SRVR:MWHPR12MB1742; BCL:0; PCL:0;
	RULEID:(100000800101)(100110000095)(100000801101)(100110300095)(100000802101)(100110100095)(100000803101)(100110400095)(100000804101)(100110200095)(100000805101)(100110500095);
	SRVR:MWHPR12MB1742; 
X-Forefront-PRVS: 049486C505
X-Forefront-Antispam-Report: SFV:NSPM;
	SFS:(10009020)(6009001)(346002)(39860400002)(376002)(199003)(189002)(36756003)(48376002)(50986999)(478600001)(6116002)(101416001)(3846002)(81156014)(8676002)(81166006)(16526018)(76176999)(4720700003)(189998001)(16586007)(305945005)(2906002)(2950100002)(7736002)(6666003)(72206003)(86362001)(316002)(50226002)(47776003)(5003940100001)(6486002)(50466002)(97736004)(53416004)(68736007)(105586002)(53936002)(8936002)(66066001)(106356001)(25786009)(4326008)(5660300001);
	DIR:OUT; SFP:1101; SCL:1; SRVR:MWHPR12MB1742;
	H:ssuthiku-rhel73-zp.amd.com; FPR:; SPF:None;
	PTR:InfoNoRecords; A:1; MX:1; LANG:en; 
Received-SPF: None (protection.outlook.com: amd.com does not designate
	permitted sender hosts)
X-Microsoft-Exchange-Diagnostics: =?us-ascii?Q?1; MWHPR12MB1742;
	23:HKZm4wYKbrIHVxQLS3bVq3YNk3dxcsBUJBF89/t0l?=
	=?us-ascii?Q?SNPqi8zYqtG9GspPiZunLPWXDx3mq78FHCaCLWdgOMZ4JmUp/d9vX3SlMMEv?=
	=?us-ascii?Q?tb6vutfG3QJ2Y/+7J4I+KDRslXAIK5T7bl4w3xQTT83YjRIaqe0xPwtjwMDZ?=
	=?us-ascii?Q?XPSj2MAtefyUbyyuLnkziO+HOsrD1XANLPPBma8KnljakRDEpP9MMycuQ1dI?=
	=?us-ascii?Q?Ru6NtHuGqNOsQ7JFL+McLFKWFzqGIJ1zT0/W4jFUdlOjajnkIqUM06jmp+Ac?=
	=?us-ascii?Q?J4Q58jpUdWmMze7nBWpTb6bfrvU9E/NG+9KnTDTbyuvfrT2K9Q81crwEJhkD?=
	=?us-ascii?Q?Spk6udlYSK/EC9hjWVmBRHcg6tUBdxYhegU02xUxB9eUJEek8Zx24nPwvdEP?=
	=?us-ascii?Q?j3gt5tldkY5HolgV0FK2KweMhG5aHPS8GUMqDPmtpou+Paez0XaK1ox2zzl6?=
	=?us-ascii?Q?SjUXnhERWpm/pGd4y3HaLqrXFcWf/J56W5yXj8K7JCrHB6Ty4kzrhyF3tROR?=
	=?us-ascii?Q?rIPZpN+nLQoVQFFayZwmYYlr/Hu0MdIMBpqNtccl8FT3ECUUNtuDYHmYa6/l?=
	=?us-ascii?Q?ynuSx4E1JRE8kG+dHMm59QJ6BBAlkinmxPSNcONCM8UBMQ9dt4fzE+it3VRt?=
	=?us-ascii?Q?QjnIdETPjXhyV6ImIzq9UaqnCo06GV7gFbcvQN3UUNeKXaeax98SJVIKUT7E?=
	=?us-ascii?Q?j9FSEiRcE97s1bYs9QPx5R3+YhsXnrx/GFvqyH65tXcmeEDeHTAPrYZN1B2Z?=
	=?us-ascii?Q?uHU+P0wjjKlcqVMkM0AusJrnSPl+tIqmIxmh1bC3ckv7hnlR4NbtGbQdGh7L?=
	=?us-ascii?Q?bfUvCzJ/2wVLwlXaja7ngVmw6lA+3xJg1nGLUx3w9dboWNR2bxnqSVMOHhzu?=
	=?us-ascii?Q?BHSPkuTGCNckLW0cwGTjnF3JMcYUV5/64zYP7vwG+ekE55zYrOMWoFj0Z5VL?=
	=?us-ascii?Q?Cnozex2njSjpFtKjPzskZkrlwzzfD0hH/uE0CIHuI/6jK+01fSUrhkLSRDaw?=
	=?us-ascii?Q?RKtd3vjNACiEoB8csQapaI8Wu6QibRjljbbW9fDW+g/GCWAXfrmry4Pv/uZF?=
	=?us-ascii?Q?FNoQrF2ZbNOPlH1jpTcYihmrDKX?=
X-Microsoft-Exchange-Diagnostics: 1; MWHPR12MB1742;
	6:Em23zfXA/15BoWigUnGVM2YQRoDTOC9DmAWd3w8dRv2ix1iDxBEUxyFlSB0pBNVMC3vAVsD4zLOa/m/Oyr8QL1sEk5kQj6yLlGJ3qOBVsqcuDFpNDRzDLOkG17UOFbb/dich4qE/sQ7kz/GRTEb5kGnjUpnVyfBsigy9QVR0ObguOZFx61zHRBZZlwqQry6bfwbYSeTMOWVmVQiIvVX19ux5PoHTcBOXXsmqulMImXDEMPN81zo9Rb23arZF7wsTJ5z2Nn62wBox8tTsAXuZQqs9LI/rAYjYEuGedashtFqLKYTmC5oB0CaLEGAYemu1EPJipwzs/tRoKD5CEtfCRhp5TcOBCl5JXcGwP8HukU8=;
	5:aErPUqqr6Az7M/Y6S0XtW8x/Ax80TZkJeDZhUy8ub94LSy2DazyewFLoMw3L/F/pkHrBrwlQmidlolZySyDzjDE4ZX3pho/SDDPo5JCr+8jefcU77nNaD0z2D7TbLgFiLT36JscfG3d3qhkUGT+cLH00SsVCB3TxF+aTkNsByvg=;
	24:K/FUte8sGYo6J5m2kMpGmHlUK3xIBvlcSMi5WXJNla8dIKxB5Evjm7BHrrzyNcR9VJrnaCd7JO64i8LzH5nHuuG0GfZQ/leTIduBM4Yvl8U=;
	7:YqsrSwKywCg7QUSt0fI4yRJII+5yHyNBf+tF8Fh/Aa/ZzfpQOtfJEl/jjpgw1giKpeZNYhscuuq2Jcwv0+JKwhIxPo6nbzaTwLegFW/NIfmq07dYWkeMTKjH/IAf3DqWGayG2Iy7dx57srvQWrty23GuHDQeh6WfBWoc7wT1eJ57h/xP8dE7w/WN/tMipzzgt/tIm0UvI7m9VoJrphLJMgDIREJ8JsnC5PVvbK8WGcTZof34rPV2PRBXgXqFzt6m
SpamDiagnosticOutput: 1:99
SpamDiagnosticMetadata: NSPM
X-Microsoft-Exchange-Diagnostics: 1; MWHPR12MB1742;
	20:d4QhMP3ras9CI1JaYVjU4cuNVP/kBcuVYm38wIijZWl3/Ie+R95BQK0RgDeOJGCau3ZkDT7L80UR+g0GNb3vfqGN4BvAM3hEd48U+EUmOSF4KB5G8jZXQMqD6M2f7rcklNltbLpgDoLgozfjhpGH+Pmk3rapQeuHVChSRFstaGFY6A2GbAtAUhEFRl7UxA+kcD5lWuqhNuRvgiYx+F4GTDec/iFDZdnJN64CKUVhLNO9DwHHnkcbeMDZXuLNaBAE
X-OriginatorOrg: amd.com
X-MS-Exchange-CrossTenant-OriginalArrivalTime: 17 Nov 2017 21:11:45.4022
	(UTC)
X-MS-Exchange-CrossTenant-Network-Message-Id: 3c96c3b5-bf0b-430a-2f16-08d52dffcf39
X-MS-Exchange-CrossTenant-FromEntityHeader: Hosted
X-MS-Exchange-CrossTenant-Id: 3dd8961f-e488-4e60-8e11-a82d994e183d
X-MS-Exchange-Transport-CrossTenantHeadersStamped: MWHPR12MB1742
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=2908">Suthikulpanit, Suravee</a> - Nov. 17, 2017, 9:11 p.m.</div>
<pre class="content">
<span class="from">From: Suravee Suthikulpanit &lt;suravee.suthikulpanit@amd.com&gt;</span>

VFIO IOMMU type1 currently upmaps IOVA pages synchronously, which requires
IOTLB flushing for every unmapping. This results in large IOTLB flushing
overhead when handling pass-through devices with a large number of mapped
IOVAs (e.g. GPUs).

This can be avoided by using the new IOTLB flushing interface.

Cc: Alex Williamson &lt;alex.williamson@redhat.com&gt;
Cc: Joerg Roedel &lt;jroedel@suse.de&gt;
<span class="signed-off-by">Signed-off-by: Suravee Suthikulpanit &lt;suravee.suthikulpanit@amd.com&gt;</span>
---
 drivers/vfio/vfio_iommu_type1.c | 12 +++++++++---
 1 file changed, 9 insertions(+), 3 deletions(-)
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=7781">Alex Williamson</a> - Nov. 17, 2017, 9:51 p.m.</div>
<pre class="content">
On Fri, 17 Nov 2017 15:11:19 -0600
Suravee Suthikulpanit &lt;Suravee.Suthikulpanit@amd.com&gt; wrote:
<span class="quote">
&gt; From: Suravee Suthikulpanit &lt;suravee.suthikulpanit@amd.com&gt;</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; VFIO IOMMU type1 currently upmaps IOVA pages synchronously, which requires</span>
<span class="quote">&gt; IOTLB flushing for every unmapping. This results in large IOTLB flushing</span>
<span class="quote">&gt; overhead when handling pass-through devices with a large number of mapped</span>
<span class="quote">&gt; IOVAs (e.g. GPUs).</span>

Of course the type of device is really irrelevant, QEMU maps the entire
VM address space for any assigned device.
<span class="quote">
&gt; This can be avoided by using the new IOTLB flushing interface.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Cc: Alex Williamson &lt;alex.williamson@redhat.com&gt;</span>
<span class="quote">&gt; Cc: Joerg Roedel &lt;jroedel@suse.de&gt;</span>
<span class="quote">&gt; Signed-off-by: Suravee Suthikulpanit &lt;suravee.suthikulpanit@amd.com&gt;</span>
<span class="quote">&gt; ---</span>
<span class="quote">&gt;  drivers/vfio/vfio_iommu_type1.c | 12 +++++++++---</span>
<span class="quote">&gt;  1 file changed, 9 insertions(+), 3 deletions(-)</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; diff --git a/drivers/vfio/vfio_iommu_type1.c b/drivers/vfio/vfio_iommu_type1.c</span>
<span class="quote">&gt; index 92155cc..28a7ab6 100644</span>
<span class="quote">&gt; --- a/drivers/vfio/vfio_iommu_type1.c</span>
<span class="quote">&gt; +++ b/drivers/vfio/vfio_iommu_type1.c</span>
<span class="quote">&gt; @@ -698,10 +698,12 @@ static long vfio_unmap_unpin(struct vfio_iommu *iommu, struct vfio_dma *dma,</span>
<span class="quote">&gt;  				break;</span>
<span class="quote">&gt;  		}</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; -		unmapped = iommu_unmap(domain-&gt;domain, iova, len);</span>
<span class="quote">&gt; +		unmapped = iommu_unmap_fast(domain-&gt;domain, iova, len);</span>
<span class="quote">&gt;  		if (WARN_ON(!unmapped))</span>
<span class="quote">&gt;  			break;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; +		iommu_tlb_range_add(domain-&gt;domain, iova, len);</span>
<span class="quote">&gt; +</span>

We should only add @unmapped, not @len, right?
<span class="quote">
&gt;  		unlocked += vfio_unpin_pages_remote(dma, iova,</span>
<span class="quote">&gt;  						    phys &gt;&gt; PAGE_SHIFT,</span>
<span class="quote">&gt;  						    unmapped &gt;&gt; PAGE_SHIFT,</span>
<span class="quote">&gt; @@ -710,6 +712,7 @@ static long vfio_unmap_unpin(struct vfio_iommu *iommu, struct vfio_dma *dma,</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  		cond_resched();</span>
<span class="quote">&gt;  	}</span>
<span class="quote">&gt; +	iommu_tlb_sync(domain-&gt;domain);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	dma-&gt;iommu_mapped = false;</span>
<span class="quote">&gt;  	if (do_accounting) {</span>
<span class="quote">&gt; @@ -884,8 +887,11 @@ static int map_try_harder(struct vfio_domain *domain, dma_addr_t iova,</span>
<span class="quote">&gt;  			break;</span>
<span class="quote">&gt;  	}</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; -	for (; i &lt; npage &amp;&amp; i &gt; 0; i--, iova -= PAGE_SIZE)</span>
<span class="quote">&gt; -		iommu_unmap(domain-&gt;domain, iova, PAGE_SIZE);</span>
<span class="quote">&gt; +	for (; i &lt; npage &amp;&amp; i &gt; 0; i--, iova -= PAGE_SIZE) {</span>
<span class="quote">&gt; +		iommu_unmap_fast(domain-&gt;domain, iova, PAGE_SIZE);</span>
<span class="quote">&gt; +		iommu_tlb_range_add(domain-&gt;domain, iova, PAGE_SIZE);</span>
<span class="quote">&gt; +	}</span>
<span class="quote">&gt; +	iommu_tlb_sync(domain-&gt;domain);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	return ret;</span>
<span class="quote">&gt;  }</span>
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=7781">Alex Williamson</a> - Nov. 18, 2017, 4:20 a.m.</div>
<pre class="content">
On Fri, 17 Nov 2017 14:51:52 -0700
Alex Williamson &lt;alex.williamson@redhat.com&gt; wrote:
<span class="quote">
&gt; On Fri, 17 Nov 2017 15:11:19 -0600</span>
<span class="quote">&gt; Suravee Suthikulpanit &lt;Suravee.Suthikulpanit@amd.com&gt; wrote:</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; &gt; From: Suravee Suthikulpanit &lt;suravee.suthikulpanit@amd.com&gt;</span>
<span class="quote">&gt; &gt; </span>
<span class="quote">&gt; &gt; VFIO IOMMU type1 currently upmaps IOVA pages synchronously, which requires</span>
<span class="quote">&gt; &gt; IOTLB flushing for every unmapping. This results in large IOTLB flushing</span>
<span class="quote">&gt; &gt; overhead when handling pass-through devices with a large number of mapped</span>
<span class="quote">&gt; &gt; IOVAs (e.g. GPUs).  </span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Of course the type of device is really irrelevant, QEMU maps the entire</span>
<span class="quote">&gt; VM address space for any assigned device.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; &gt; This can be avoided by using the new IOTLB flushing interface.</span>
<span class="quote">&gt; &gt; </span>
<span class="quote">&gt; &gt; Cc: Alex Williamson &lt;alex.williamson@redhat.com&gt;</span>
<span class="quote">&gt; &gt; Cc: Joerg Roedel &lt;jroedel@suse.de&gt;</span>
<span class="quote">&gt; &gt; Signed-off-by: Suravee Suthikulpanit &lt;suravee.suthikulpanit@amd.com&gt;</span>
<span class="quote">&gt; &gt; ---</span>
<span class="quote">&gt; &gt;  drivers/vfio/vfio_iommu_type1.c | 12 +++++++++---</span>
<span class="quote">&gt; &gt;  1 file changed, 9 insertions(+), 3 deletions(-)</span>
<span class="quote">&gt; &gt; </span>
<span class="quote">&gt; &gt; diff --git a/drivers/vfio/vfio_iommu_type1.c b/drivers/vfio/vfio_iommu_type1.c</span>
<span class="quote">&gt; &gt; index 92155cc..28a7ab6 100644</span>
<span class="quote">&gt; &gt; --- a/drivers/vfio/vfio_iommu_type1.c</span>
<span class="quote">&gt; &gt; +++ b/drivers/vfio/vfio_iommu_type1.c</span>
<span class="quote">&gt; &gt; @@ -698,10 +698,12 @@ static long vfio_unmap_unpin(struct vfio_iommu *iommu, struct vfio_dma *dma,</span>
<span class="quote">&gt; &gt;  				break;</span>
<span class="quote">&gt; &gt;  		}</span>
<span class="quote">&gt; &gt;  </span>
<span class="quote">&gt; &gt; -		unmapped = iommu_unmap(domain-&gt;domain, iova, len);</span>
<span class="quote">&gt; &gt; +		unmapped = iommu_unmap_fast(domain-&gt;domain, iova, len);</span>
<span class="quote">&gt; &gt;  		if (WARN_ON(!unmapped))</span>
<span class="quote">&gt; &gt;  			break;</span>
<span class="quote">&gt; &gt;  </span>
<span class="quote">&gt; &gt; +		iommu_tlb_range_add(domain-&gt;domain, iova, len);</span>
<span class="quote">&gt; &gt; +  </span>
<span class="quote">&gt; </span>
<span class="quote">&gt; We should only add @unmapped, not @len, right?</span>

Actually, the problems are deeper than that, if we can&#39;t guarantee that
the above iommu_unmap_fast has removed the iommu mapping, then we can&#39;t
do the unpin below as that would potentially allow the device access to
unknown memory.  Thus, to support this, the unpinning would need to be
pushed until after the sync and we therefore need some mechanism of
remembering the phys addresses that we&#39;ve unmapped.  Thanks,

Alex
<span class="quote"> 
&gt; &gt;  		unlocked += vfio_unpin_pages_remote(dma, iova,</span>
<span class="quote">&gt; &gt;  						    phys &gt;&gt; PAGE_SHIFT,</span>
<span class="quote">&gt; &gt;  						    unmapped &gt;&gt; PAGE_SHIFT,</span>
<span class="quote">&gt; &gt; @@ -710,6 +712,7 @@ static long vfio_unmap_unpin(struct vfio_iommu *iommu, struct vfio_dma *dma,</span>
<span class="quote">&gt; &gt;  </span>
<span class="quote">&gt; &gt;  		cond_resched();</span>
<span class="quote">&gt; &gt;  	}</span>
<span class="quote">&gt; &gt; +	iommu_tlb_sync(domain-&gt;domain);</span>
<span class="quote">&gt; &gt;  </span>
<span class="quote">&gt; &gt;  	dma-&gt;iommu_mapped = false;</span>
<span class="quote">&gt; &gt;  	if (do_accounting) {</span>
<span class="quote">&gt; &gt; @@ -884,8 +887,11 @@ static int map_try_harder(struct vfio_domain *domain, dma_addr_t iova,</span>
<span class="quote">&gt; &gt;  			break;</span>
<span class="quote">&gt; &gt;  	}</span>
<span class="quote">&gt; &gt;  </span>
<span class="quote">&gt; &gt; -	for (; i &lt; npage &amp;&amp; i &gt; 0; i--, iova -= PAGE_SIZE)</span>
<span class="quote">&gt; &gt; -		iommu_unmap(domain-&gt;domain, iova, PAGE_SIZE);</span>
<span class="quote">&gt; &gt; +	for (; i &lt; npage &amp;&amp; i &gt; 0; i--, iova -= PAGE_SIZE) {</span>
<span class="quote">&gt; &gt; +		iommu_unmap_fast(domain-&gt;domain, iova, PAGE_SIZE);</span>
<span class="quote">&gt; &gt; +		iommu_tlb_range_add(domain-&gt;domain, iova, PAGE_SIZE);</span>
<span class="quote">&gt; &gt; +	}</span>
<span class="quote">&gt; &gt; +	iommu_tlb_sync(domain-&gt;domain);</span>
<span class="quote">&gt; &gt;  </span>
<span class="quote">&gt; &gt;  	return ret;</span>
<span class="quote">&gt; &gt;  }  </span>
<span class="quote">&gt; </span>
<span class="quote">&gt; _______________________________________________</span>
<span class="quote">&gt; iommu mailing list</span>
<span class="quote">&gt; iommu@lists.linux-foundation.org</span>
<span class="quote">&gt; https://lists.linuxfoundation.org/mailman/listinfo/iommu</span>
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=2908">Suthikulpanit, Suravee</a> - Nov. 27, 2017, 8:12 a.m.</div>
<pre class="content">
Hi Alex,

On 11/18/17 4:51 AM, Alex Williamson wrote:
<span class="quote">&gt; On Fri, 17 Nov 2017 15:11:19 -0600</span>
<span class="quote">&gt; Suravee Suthikulpanit&lt;Suravee.Suthikulpanit@amd.com&gt;  wrote:</span>
<span class="quote">&gt; </span>
<span class="quote">&gt;&gt; From: Suravee Suthikulpanit&lt;suravee.suthikulpanit@amd.com&gt;</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; VFIO IOMMU type1 currently upmaps IOVA pages synchronously, which requires</span>
<span class="quote">&gt;&gt; IOTLB flushing for every unmapping. This results in large IOTLB flushing</span>
<span class="quote">&gt;&gt; overhead when handling pass-through devices with a large number of mapped</span>
<span class="quote">&gt;&gt; IOVAs (e.g. GPUs).</span>
<span class="quote">&gt; Of course the type of device is really irrelevant, QEMU maps the entire</span>
<span class="quote">&gt; VM address space for any assigned device.</span>

Right, in this case certain high performance dGPUs map large address space.
<span class="quote">
&gt; </span>
<span class="quote">&gt;&gt; This can be avoided by using the new IOTLB flushing interface.</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; Cc: Alex Williamson&lt;alex.williamson@redhat.com&gt;</span>
<span class="quote">&gt;&gt; Cc: Joerg Roedel&lt;jroedel@suse.de&gt;</span>
<span class="quote">&gt;&gt; Signed-off-by: Suravee Suthikulpanit&lt;suravee.suthikulpanit@amd.com&gt;</span>
<span class="quote">&gt;&gt; ---</span>
<span class="quote">&gt;&gt;   drivers/vfio/vfio_iommu_type1.c | 12 +++++++++---</span>
<span class="quote">&gt;&gt;   1 file changed, 9 insertions(+), 3 deletions(-)</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; diff --git a/drivers/vfio/vfio_iommu_type1.c b/drivers/vfio/vfio_iommu_type1.c</span>
<span class="quote">&gt;&gt; index 92155cc..28a7ab6 100644</span>
<span class="quote">&gt;&gt; --- a/drivers/vfio/vfio_iommu_type1.c</span>
<span class="quote">&gt;&gt; +++ b/drivers/vfio/vfio_iommu_type1.c</span>
<span class="quote">&gt;&gt; @@ -698,10 +698,12 @@ static long vfio_unmap_unpin(struct vfio_iommu *iommu, struct vfio_dma *dma,</span>
<span class="quote">&gt;&gt;   				break;</span>
<span class="quote">&gt;&gt;   		}</span>
<span class="quote">&gt;&gt;   </span>
<span class="quote">&gt;&gt; -		unmapped = iommu_unmap(domain-&gt;domain, iova, len);</span>
<span class="quote">&gt;&gt; +		unmapped = iommu_unmap_fast(domain-&gt;domain, iova, len);</span>
<span class="quote">&gt;&gt;   		if (WARN_ON(!unmapped))</span>
<span class="quote">&gt;&gt;   			break;</span>
<span class="quote">&gt;&gt;   </span>
<span class="quote">&gt;&gt; +		iommu_tlb_range_add(domain-&gt;domain, iova, len);</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt; We should only add @unmapped, not @len, right?</span>

Hm right, I will change this in V2.

Thanks,
Suravee
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=2908">Suthikulpanit, Suravee</a> - Nov. 27, 2017, 8:14 a.m.</div>
<pre class="content">
Hi Alex,

On 11/18/17 11:20 AM, Alex Williamson wrote:
<span class="quote">&gt; On Fri, 17 Nov 2017 14:51:52 -0700</span>
<span class="quote">&gt; Alex Williamson&lt;alex.williamson@redhat.com&gt;  wrote:</span>
<span class="quote">&gt; </span>
<span class="quote">&gt;&gt; On Fri, 17 Nov 2017 15:11:19 -0600</span>
<span class="quote">&gt;&gt; Suravee Suthikulpanit&lt;Suravee.Suthikulpanit@amd.com&gt;  wrote:</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt; From: Suravee Suthikulpanit&lt;suravee.suthikulpanit@amd.com&gt;</span>
<span class="quote">&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt; VFIO IOMMU type1 currently upmaps IOVA pages synchronously, which requires</span>
<span class="quote">&gt;&gt;&gt; IOTLB flushing for every unmapping. This results in large IOTLB flushing</span>
<span class="quote">&gt;&gt;&gt; overhead when handling pass-through devices with a large number of mapped</span>
<span class="quote">&gt;&gt;&gt; IOVAs (e.g. GPUs).</span>
<span class="quote">&gt;&gt; Of course the type of device is really irrelevant, QEMU maps the entire</span>
<span class="quote">&gt;&gt; VM address space for any assigned device.</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt; This can be avoided by using the new IOTLB flushing interface.</span>
<span class="quote">&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt; Cc: Alex Williamson&lt;alex.williamson@redhat.com&gt;</span>
<span class="quote">&gt;&gt;&gt; Cc: Joerg Roedel&lt;jroedel@suse.de&gt;</span>
<span class="quote">&gt;&gt;&gt; Signed-off-by: Suravee Suthikulpanit&lt;suravee.suthikulpanit@amd.com&gt;</span>
<span class="quote">&gt;&gt;&gt; ---</span>
<span class="quote">&gt;&gt;&gt;   drivers/vfio/vfio_iommu_type1.c | 12 +++++++++---</span>
<span class="quote">&gt;&gt;&gt;   1 file changed, 9 insertions(+), 3 deletions(-)</span>
<span class="quote">&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt; diff --git a/drivers/vfio/vfio_iommu_type1.c b/drivers/vfio/vfio_iommu_type1.c</span>
<span class="quote">&gt;&gt;&gt; index 92155cc..28a7ab6 100644</span>
<span class="quote">&gt;&gt;&gt; --- a/drivers/vfio/vfio_iommu_type1.c</span>
<span class="quote">&gt;&gt;&gt; +++ b/drivers/vfio/vfio_iommu_type1.c</span>
<span class="quote">&gt;&gt;&gt; @@ -698,10 +698,12 @@ static long vfio_unmap_unpin(struct vfio_iommu *iommu, struct vfio_dma *dma,</span>
<span class="quote">&gt;&gt;&gt;   				break;</span>
<span class="quote">&gt;&gt;&gt;   		}</span>
<span class="quote">&gt;&gt;&gt;   </span>
<span class="quote">&gt;&gt;&gt; -		unmapped = iommu_unmap(domain-&gt;domain, iova, len);</span>
<span class="quote">&gt;&gt;&gt; +		unmapped = iommu_unmap_fast(domain-&gt;domain, iova, len);</span>
<span class="quote">&gt;&gt;&gt;   		if (WARN_ON(!unmapped))</span>
<span class="quote">&gt;&gt;&gt;   			break;</span>
<span class="quote">&gt;&gt;&gt;   </span>
<span class="quote">&gt;&gt;&gt; +		iommu_tlb_range_add(domain-&gt;domain, iova, len);</span>
<span class="quote">&gt;&gt;&gt; +</span>
<span class="quote">&gt;&gt; We should only add @unmapped, not @len, right?</span>
<span class="quote">&gt; Actually, the problems are deeper than that, if we can&#39;t guarantee that</span>
<span class="quote">&gt; the above iommu_unmap_fast has removed the iommu mapping, then we can&#39;t</span>
<span class="quote">&gt; do the unpin below as that would potentially allow the device access to</span>
<span class="quote">&gt; unknown memory.  Thus, to support this, the unpinning would need to be</span>
<span class="quote">&gt; pushed until after the sync and we therefore need some mechanism of</span>
<span class="quote">&gt; remembering the phys addresses that we&#39;ve unmapped.  Thanks,</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Alex</span>
<span class="quote">&gt;   </span>

If so, I am planning to use a list to temporary store information for 
unmapped regions to be unpinned after sync.  Please lemme know if that 
would be alright.

Suravee
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/drivers/vfio/vfio_iommu_type1.c b/drivers/vfio/vfio_iommu_type1.c</span>
<span class="p_header">index 92155cc..28a7ab6 100644</span>
<span class="p_header">--- a/drivers/vfio/vfio_iommu_type1.c</span>
<span class="p_header">+++ b/drivers/vfio/vfio_iommu_type1.c</span>
<span class="p_chunk">@@ -698,10 +698,12 @@</span> <span class="p_context"> static long vfio_unmap_unpin(struct vfio_iommu *iommu, struct vfio_dma *dma,</span>
 				break;
 		}
 
<span class="p_del">-		unmapped = iommu_unmap(domain-&gt;domain, iova, len);</span>
<span class="p_add">+		unmapped = iommu_unmap_fast(domain-&gt;domain, iova, len);</span>
 		if (WARN_ON(!unmapped))
 			break;
 
<span class="p_add">+		iommu_tlb_range_add(domain-&gt;domain, iova, len);</span>
<span class="p_add">+</span>
 		unlocked += vfio_unpin_pages_remote(dma, iova,
 						    phys &gt;&gt; PAGE_SHIFT,
 						    unmapped &gt;&gt; PAGE_SHIFT,
<span class="p_chunk">@@ -710,6 +712,7 @@</span> <span class="p_context"> static long vfio_unmap_unpin(struct vfio_iommu *iommu, struct vfio_dma *dma,</span>
 
 		cond_resched();
 	}
<span class="p_add">+	iommu_tlb_sync(domain-&gt;domain);</span>
 
 	dma-&gt;iommu_mapped = false;
 	if (do_accounting) {
<span class="p_chunk">@@ -884,8 +887,11 @@</span> <span class="p_context"> static int map_try_harder(struct vfio_domain *domain, dma_addr_t iova,</span>
 			break;
 	}
 
<span class="p_del">-	for (; i &lt; npage &amp;&amp; i &gt; 0; i--, iova -= PAGE_SIZE)</span>
<span class="p_del">-		iommu_unmap(domain-&gt;domain, iova, PAGE_SIZE);</span>
<span class="p_add">+	for (; i &lt; npage &amp;&amp; i &gt; 0; i--, iova -= PAGE_SIZE) {</span>
<span class="p_add">+		iommu_unmap_fast(domain-&gt;domain, iova, PAGE_SIZE);</span>
<span class="p_add">+		iommu_tlb_range_add(domain-&gt;domain, iova, PAGE_SIZE);</span>
<span class="p_add">+	}</span>
<span class="p_add">+	iommu_tlb_sync(domain-&gt;domain);</span>
 
 	return ret;
 }

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



