
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>[v12,10/11] sparc64: Add support for ADI (Application Data Integrity) - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    [v12,10/11] sparc64: Add support for ADI (Application Data Integrity)</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=63231">Khalid Aziz</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>Feb. 21, 2018, 5:15 p.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;d8602e35e65c8bf6df1a85166bf181536a6f3664.1519227112.git.khalid.aziz@oracle.com&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/10233615/mbox/"
   >mbox</a>
|
   <a href="/patch/10233615/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/10233615/">/patch/10233615/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
	[172.30.200.125])
	by pdx-korg-patchwork.web.codeaurora.org (Postfix) with ESMTP id
	A2D6C602A7 for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Wed, 21 Feb 2018 17:22:09 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 8579F22A6B
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Wed, 21 Feb 2018 17:22:09 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id 7654123794; Wed, 21 Feb 2018 17:22:09 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-7.0 required=2.0 tests=BAYES_00,DKIM_SIGNED,
	DKIM_VALID, DKIM_VALID_AU, RCVD_IN_DNSWL_HI,
	UNPARSEABLE_RELAY autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 8082222A6B
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Wed, 21 Feb 2018 17:22:06 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S934514AbeBURWC (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Wed, 21 Feb 2018 12:22:02 -0500
Received: from userp2130.oracle.com ([156.151.31.86]:49460 &quot;EHLO
	userp2130.oracle.com&quot; rhost-flags-OK-OK-OK-OK) by vger.kernel.org
	with ESMTP id S934244AbeBURV6 (ORCPT
	&lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Wed, 21 Feb 2018 12:21:58 -0500
Received: from pps.filterd (userp2130.oracle.com [127.0.0.1])
	by userp2130.oracle.com (8.16.0.22/8.16.0.22) with SMTP id
	w1LHGxVo171404; Wed, 21 Feb 2018 17:17:05 GMT
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed; d=oracle.com;
	h=from : to : cc :
	subject : date : message-id : in-reply-to : references : in-reply-to
	: references; s=corp-2017-10-26;
	bh=W44SKjdgu7b8V1mkTjZuTjk0SkNCYGVh2mDzq47C7I4=;
	b=DyK+8n1Ge9/I0xVt8ZEy9rp1BgW6eKn8pch+EjlhX5waDtxzAbka1Wo3iSPioWt7/Q0Y
	ddM5duwTaqszAPrW7Mj9sCqu/2njyBBwj61ZknTyr5wBxn5fwn0etq8a+hMC2U8rZXsK
	qi35uDFYr5u5GkNcqX1Vnf4utiNpIg3blzJmgpXSUxUQl0orN2TXpPXRhuXhjbuuuGda
	HqqKJXdK9CBNscBFNvvIlJnCawhstuF0O1GWqYIiUR5vLS46aL11TNfPom/sYFGLOg9w
	2x1ZFBbPQDHC6wflx5SeYmXQ+WTbcSIcbJhWqnSVaaOkMRjJMYHxKjPTChhqJh9RpCEV
	kA== 
Received: from userv0022.oracle.com (userv0022.oracle.com [156.151.31.74])
	by userp2130.oracle.com with ESMTP id 2g9brq8mqf-1
	(version=TLSv1.2 cipher=ECDHE-RSA-AES256-GCM-SHA384 bits=256
	verify=OK); Wed, 21 Feb 2018 17:17:05 +0000
Received: from aserv0121.oracle.com (aserv0121.oracle.com [141.146.126.235])
	by userv0022.oracle.com (8.14.4/8.14.4) with ESMTP id
	w1LHH32o029276
	(version=TLSv1/SSLv3 cipher=DHE-RSA-AES256-GCM-SHA384 bits=256
	verify=FAIL); Wed, 21 Feb 2018 17:17:03 GMT
Received: from abhmp0014.oracle.com (abhmp0014.oracle.com [141.146.116.20])
	by aserv0121.oracle.com (8.14.4/8.13.8) with ESMTP id
	w1LHH3to009969; Wed, 21 Feb 2018 17:17:03 GMT
Received: from concerto.us.oracle.com (/24.9.64.241)
	by default (Oracle Beehive Gateway v4.0)
	with ESMTP ; Wed, 21 Feb 2018 09:17:02 -0800
From: Khalid Aziz &lt;khalid.aziz@oracle.com&gt;
To: davem@davemloft.net, akpm@linux-foundation.org,
	dave.hansen@linux.intel.com
Cc: Khalid Aziz &lt;khalid.aziz@oracle.com&gt;, corbet@lwn.net,
	bob.picco@oracle.com, steven.sistare@oracle.com,
	pasha.tatashin@oracle.com, mike.kravetz@oracle.com,
	rob.gardner@oracle.com, mingo@kernel.org, nitin.m.gupta@oracle.com,
	anthony.yznaga@oracle.com, kirill.shutemov@linux.intel.com,
	tom.hromatka@oracle.com, allen.pais@oracle.com,
	tklauser@distanz.ch, shannon.nelson@oracle.com,
	vijay.ac.kumar@oracle.com, mhocko@suse.com, jack@suse.cz,
	punit.agrawal@arm.com, hughd@google.com, thomas.tai@oracle.com,
	ross.zwisler@linux.intel.com, dave.jiang@intel.com,
	willy@infradead.org, minchan@kernel.org,
	imbrenda@linux.vnet.ibm.com, aarcange@redhat.com,
	kstewart@linuxfoundation.org, pombredanne@nexb.com,
	tglx@linutronix.de, gregkh@linuxfoundation.org,
	nagarathnam.muthusamy@oracle.com, linux@roeck-us.net,
	jane.chu@oracle.com, dan.j.williams@intel.com, jglisse@redhat.com,
	ktkhai@virtuozzo.com, linux-doc@vger.kernel.org,
	linux-kernel@vger.kernel.org, linux-mm@kvack.org,
	sparclinux@vger.kernel.org, Khalid Aziz &lt;khalid@gonehiking.org&gt;
Subject: [PATCH v12 10/11] sparc64: Add support for ADI (Application Data
	Integrity)
Date: Wed, 21 Feb 2018 10:15:52 -0700
Message-Id: &lt;d8602e35e65c8bf6df1a85166bf181536a6f3664.1519227112.git.khalid.aziz@oracle.com&gt;
X-Mailer: git-send-email 2.11.0
In-Reply-To: &lt;cover.1519227112.git.khalid.aziz@oracle.com&gt;
References: &lt;cover.1519227112.git.khalid.aziz@oracle.com&gt;
In-Reply-To: &lt;cover.1519227112.git.khalid.aziz@oracle.com&gt;
References: &lt;cover.1519227112.git.khalid.aziz@oracle.com&gt;
X-Proofpoint-Virus-Version: vendor=nai engine=5900 definitions=8811
	signatures=668676
X-Proofpoint-Spam-Details: rule=notspam policy=default score=0
	suspectscore=2 malwarescore=0
	phishscore=0 bulkscore=0 spamscore=0 mlxscore=0 mlxlogscore=999
	adultscore=0 classifier=spam adjust=0 reason=mlx scancount=1
	engine=8.0.1-1711220000 definitions=main-1802210211
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=63231">Khalid Aziz</a> - Feb. 21, 2018, 5:15 p.m.</div>
<pre class="content">
ADI is a new feature supported on SPARC M7 and newer processors to allow
hardware to catch rogue accesses to memory. ADI is supported for data
fetches only and not instruction fetches. An app can enable ADI on its
data pages, set version tags on them and use versioned addresses to
access the data pages. Upper bits of the address contain the version
tag. On M7 processors, upper four bits (bits 63-60) contain the version
tag. If a rogue app attempts to access ADI enabled data pages, its
access is blocked and processor generates an exception. Please see
Documentation/sparc/adi.txt for further details.

This patch extends mprotect to enable ADI (TSTATE.mcde), enable/disable
MCD (Memory Corruption Detection) on selected memory ranges, enable
TTE.mcd in PTEs, return ADI parameters to userspace and save/restore ADI
version tags on page swap out/in or migration. ADI is not enabled by
default for any task. A task must explicitly enable ADI on a memory
range and set version tag for ADI to be effective for the task.
<span class="signed-off-by">
Signed-off-by: Khalid Aziz &lt;khalid.aziz@oracle.com&gt;</span>
Cc: Khalid Aziz &lt;khalid@gonehiking.org&gt;
<span class="reviewed-by">Reviewed-by: Anthony Yznaga &lt;anthony.yznaga@oracle.com&gt;</span>
---
v10:
	- Added code to return from kernel path to set PSTATE.mcde if
	  kernel continues execution in another thread (Suggested by
	  Anthony Yznaga)
v9:
	- Added code to migrate ADI tags to copy_highpage() to
	  ensure tags get copied on page migration
	- Improved code to detect underflow and overflow when allocating
	  tag storage
v8: 
	- Added note to doc about non-faulting loads not triggering
	  ADI tag mismatch and more details on special tag values
	  of 0x0 and 0xf, as suggested by Anthony Yznaga)
	- Added an IPI on mprotect(...PROT_ADI...) call to set
	  TSTATE.MCDE on threads running on other processors and
	  restore of TSTATE.MCDE on context switch (suggested by
	  David Miller)
	- Removed restriction on enabling ADI on read-only memory
	  (suggested by Anthony Yznaga)
	- Changed kzalloc() for tag storage to use GFP_NOWAIT
	- Added code to handle overflow and underflow when allocating
	  tag storage, as suggested by Anthony Yznaga
	- Replaced sun_m7_patch_1insn_range() with sun4v_patch_1insn_range()
	  which is functionally identical (suggested by Anthony Yznaga)
	- Added membar after restoring ADI tags in copy_user_highpage(),
	  as suggested by David Miller

v7:
	- Enhanced arch_validate_prot() to enable ADI only on writable
	  addresses backed by physical RAM
	- Added support for saving/restoring ADI tags for each ADI
	  block size address range on a page on swap in/out
	- Added code to copy ADI tags on COW
	- Updated values for auxiliary vectors to not conflict with
	  values on other architectures to avoid conflict in glibc. glibc
	  consolidates all auxiliary vectors into its headers and
	  duplicate values in consolidated header are problematic
	- Disable same page merging on ADI enabled pages since ADI tags
	  may not match on pages with identical data
	- Broke the patch up further into smaller patches

v6:
	- Eliminated instructions to read and write PSTATE as well as
	  MCDPER and PMCDPER on every access to userspace addresses
	  by setting PSTATE and PMCDPER correctly upon entry into
	  kernel. PSTATE.mcde and PMCDPER are set upon entry into
	  kernel when running on an M7 processor. PSTATE.mcde being
	  set only affects memory accesses that have TTE.mcd set.
	  PMCDPER being set only affects writes to memory addresses
	  that have TTE.mcd set. This ensures any faults caused by
	  ADI tag mismatch on a write are exposed before kernel returns
	  to userspace.

v5:
	- Fixed indentation issues and instrcuctions in assembly code
	- Removed CONFIG_SPARC64 from mdesc.c
	- Changed to maintain state of MCDPER register in thread info
	  flags as opposed to in mm context. MCDPER is a per-thread
	  state and belongs in thread info flag as opposed to mm context
	  which is shared across threads. Added comments to clarify this
	  is a lazily maintained state and must be updated on context
	  switch and copy_process()
	- Updated code to use the new arch_do_swap_page() and
	  arch_unmap_one() functions

v4:
	- Broke patch up into smaller patches

v3:
	- Removed CONFIG_SPARC_ADI
	- Replaced prctl commands with mprotect
	- Added auxiliary vectors for ADI parameters
	- Enabled ADI for swappable pages

v2:
	- Fixed a build error

 Documentation/sparc/adi.txt             | 278 +++++++++++++++++++++++++++++
 arch/sparc/include/asm/mman.h           |  84 ++++++++-
 arch/sparc/include/asm/mmu_64.h         |  17 ++
 arch/sparc/include/asm/mmu_context_64.h |  50 ++++++
 arch/sparc/include/asm/page_64.h        |   6 +
 arch/sparc/include/asm/pgtable_64.h     |  46 +++++
 arch/sparc/include/asm/thread_info_64.h |   2 +-
 arch/sparc/include/asm/trap_block.h     |   2 +
 arch/sparc/include/uapi/asm/mman.h      |   2 +
 arch/sparc/kernel/adi_64.c              | 301 ++++++++++++++++++++++++++++++++
 arch/sparc/kernel/etrap_64.S            |  27 ++-
 arch/sparc/kernel/process_64.c          |  25 +++
 arch/sparc/kernel/rtrap_64.S            |  33 +++-
 arch/sparc/kernel/setup_64.c            |   2 +
 arch/sparc/kernel/urtt_fill.S           |   7 +-
 arch/sparc/kernel/vmlinux.lds.S         |   5 +
 arch/sparc/mm/gup.c                     |  37 ++++
 arch/sparc/mm/hugetlbpage.c             |  14 +-
 arch/sparc/mm/init_64.c                 |  69 ++++++++
 arch/sparc/mm/tsb.c                     |  21 +++
 include/linux/mm.h                      |   3 +
 mm/ksm.c                                |   4 +
 22 files changed, 1027 insertions(+), 8 deletions(-)
 create mode 100644 Documentation/sparc/adi.txt
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=143191">kbuild test robot</a> - Feb. 23, 2018, 2:50 a.m.</div>
<pre class="content">
Hi Khalid,

I love your patch! Yet something to improve:

[auto build test ERROR on sparc-next/master]
[also build test ERROR on v4.16-rc2]
[cannot apply to next-20180222]
[if your patch is applied to the wrong git tree, please drop us a note to help improve the system]

url:    https://github.com/0day-ci/linux/commits/Khalid-Aziz/Application-Data-Integrity-feature-introduced-by-SPARC-M7/20180223-071725
base:   https://git.kernel.org/pub/scm/linux/kernel/git/davem/sparc-next.git master
config: sparc64-allyesconfig (attached as .config)
compiler: sparc64-linux-gnu-gcc (Debian 7.2.0-11) 7.2.0
reproduce:
        wget https://raw.githubusercontent.com/intel/lkp-tests/master/sbin/make.cross -O ~/bin/make.cross
        chmod +x ~/bin/make.cross
        # save the attached .config to linux build tree
        make.cross ARCH=sparc64 

All error/warnings (new ones prefixed by &gt;&gt;):

   In file included from arch/sparc/include/asm/mmu_context.h:5:0,
                    from include/linux/mmu_context.h:5,
                    from drivers/gpu/drm/amd/amdgpu/amdgpu_amdkfd.h:29,
                    from drivers/gpu/drm/amd/amdgpu/amdgpu_amdkfd.c:23:
   arch/sparc/include/asm/mmu_context_64.h: In function &#39;arch_start_context_switch&#39;:
<span class="quote">&gt;&gt; arch/sparc/include/asm/mmu_context_64.h:157:4: error: implicit declaration of function &#39;set_tsk_thread_flag&#39;; did you mean &#39;set_ti_thread_flag&#39;? [-Werror=implicit-function-declaration]</span>
       set_tsk_thread_flag(prev, TIF_MCDPER);
       ^~~~~~~~~~~~~~~~~~~
       set_ti_thread_flag
<span class="quote">&gt;&gt; arch/sparc/include/asm/mmu_context_64.h:159:4: error: implicit declaration of function &#39;clear_tsk_thread_flag&#39;; did you mean &#39;clear_ti_thread_flag&#39;? [-Werror=implicit-function-declaration]</span>
       clear_tsk_thread_flag(prev, TIF_MCDPER);
       ^~~~~~~~~~~~~~~~~~~~~
       clear_ti_thread_flag
   arch/sparc/include/asm/mmu_context_64.h: In function &#39;finish_arch_post_lock_switch&#39;:
<span class="quote">&gt;&gt; arch/sparc/include/asm/mmu_context_64.h:180:25: error: dereferencing pointer to incomplete type &#39;struct task_struct&#39;</span>
      if (current &amp;&amp; current-&gt;mm &amp;&amp; current-&gt;mm-&gt;context.adi) {
                            ^~
   In file included from arch/sparc/include/asm/processor.h:5:0,
                    from arch/sparc/include/asm/spinlock_64.h:12,
                    from arch/sparc/include/asm/spinlock.h:5,
                    from include/linux/spinlock.h:88,
                    from arch/sparc/include/asm/mmu_context_64.h:9,
                    from arch/sparc/include/asm/mmu_context.h:5,
                    from include/linux/mmu_context.h:5,
                    from drivers/gpu/drm/amd/amdgpu/amdgpu_amdkfd.h:29,
                    from drivers/gpu/drm/amd/amdgpu/amdgpu_amdkfd.c:23:
<span class="quote">&gt;&gt; arch/sparc/include/asm/processor_64.h:194:28: error: implicit declaration of function &#39;task_thread_info&#39;; did you mean &#39;test_thread_flag&#39;? [-Werror=implicit-function-declaration]</span>
    #define task_pt_regs(tsk) (task_thread_info(tsk)-&gt;kregs)
                               ^
<span class="quote">&gt;&gt; arch/sparc/include/asm/mmu_context_64.h:183:11: note: in expansion of macro &#39;task_pt_regs&#39;</span>
       regs = task_pt_regs(current);
              ^~~~~~~~~~~~
<span class="quote">&gt;&gt; arch/sparc/include/asm/processor_64.h:194:49: error: invalid type argument of &#39;-&gt;&#39; (have &#39;int&#39;)</span>
    #define task_pt_regs(tsk) (task_thread_info(tsk)-&gt;kregs)
                                                    ^
<span class="quote">&gt;&gt; arch/sparc/include/asm/mmu_context_64.h:183:11: note: in expansion of macro &#39;task_pt_regs&#39;</span>
       regs = task_pt_regs(current);
              ^~~~~~~~~~~~
   In file included from include/linux/cred.h:21:0,
                    from include/linux/seq_file.h:12,
                    from include/linux/pinctrl/consumer.h:17,
                    from include/linux/pinctrl/devinfo.h:21,
                    from include/linux/device.h:23,
                    from include/linux/cdev.h:8,
                    from include/drm/drmP.h:36,
                    from drivers/gpu/drm/amd/amdgpu/amdgpu_amdkfd.c:25:
   include/linux/sched.h: At top level:
<span class="quote">&gt;&gt; include/linux/sched.h:1530:20: warning: conflicting types for &#39;set_tsk_thread_flag&#39;</span>
    static inline void set_tsk_thread_flag(struct task_struct *tsk, int flag)
                       ^~~~~~~~~~~~~~~~~~~
<span class="quote">&gt;&gt; include/linux/sched.h:1530:20: error: static declaration of &#39;set_tsk_thread_flag&#39; follows non-static declaration</span>
   In file included from arch/sparc/include/asm/mmu_context.h:5:0,
                    from include/linux/mmu_context.h:5,
                    from drivers/gpu/drm/amd/amdgpu/amdgpu_amdkfd.h:29,
                    from drivers/gpu/drm/amd/amdgpu/amdgpu_amdkfd.c:23:
   arch/sparc/include/asm/mmu_context_64.h:157:4: note: previous implicit declaration of &#39;set_tsk_thread_flag&#39; was here
       set_tsk_thread_flag(prev, TIF_MCDPER);
       ^~~~~~~~~~~~~~~~~~~
   In file included from include/linux/cred.h:21:0,
                    from include/linux/seq_file.h:12,
                    from include/linux/pinctrl/consumer.h:17,
                    from include/linux/pinctrl/devinfo.h:21,
                    from include/linux/device.h:23,
                    from include/linux/cdev.h:8,
                    from include/drm/drmP.h:36,
                    from drivers/gpu/drm/amd/amdgpu/amdgpu_amdkfd.c:25:
<span class="quote">&gt;&gt; include/linux/sched.h:1535:20: warning: conflicting types for &#39;clear_tsk_thread_flag&#39;</span>
    static inline void clear_tsk_thread_flag(struct task_struct *tsk, int flag)
                       ^~~~~~~~~~~~~~~~~~~~~
<span class="quote">&gt;&gt; include/linux/sched.h:1535:20: error: static declaration of &#39;clear_tsk_thread_flag&#39; follows non-static declaration</span>
   In file included from arch/sparc/include/asm/mmu_context.h:5:0,
                    from include/linux/mmu_context.h:5,
                    from drivers/gpu/drm/amd/amdgpu/amdgpu_amdkfd.h:29,
                    from drivers/gpu/drm/amd/amdgpu/amdgpu_amdkfd.c:23:
   arch/sparc/include/asm/mmu_context_64.h:159:4: note: previous implicit declaration of &#39;clear_tsk_thread_flag&#39; was here
       clear_tsk_thread_flag(prev, TIF_MCDPER);
       ^~~~~~~~~~~~~~~~~~~~~
   cc1: some warnings being treated as errors

vim +157 arch/sparc/include/asm/mmu_context_64.h

     8	
<span class="quote">   &gt; 9	#include &lt;linux/spinlock.h&gt;</span>
    10	#include &lt;linux/mm_types.h&gt;
    11	#include &lt;linux/smp.h&gt;
    12	
    13	#include &lt;asm/spitfire.h&gt;
    14	#include &lt;asm/adi_64.h&gt;
    15	#include &lt;asm-generic/mm_hooks.h&gt;
    16	#include &lt;asm/percpu.h&gt;
    17	
    18	static inline void enter_lazy_tlb(struct mm_struct *mm, struct task_struct *tsk)
    19	{
    20	}
    21	
    22	extern spinlock_t ctx_alloc_lock;
    23	extern unsigned long tlb_context_cache;
    24	extern unsigned long mmu_context_bmap[];
    25	
    26	DECLARE_PER_CPU(struct mm_struct *, per_cpu_secondary_mm);
    27	void get_new_mmu_context(struct mm_struct *mm);
    28	int init_new_context(struct task_struct *tsk, struct mm_struct *mm);
    29	void destroy_context(struct mm_struct *mm);
    30	
    31	void __tsb_context_switch(unsigned long pgd_pa,
    32				  struct tsb_config *tsb_base,
    33				  struct tsb_config *tsb_huge,
    34				  unsigned long tsb_descr_pa,
    35				  unsigned long secondary_ctx);
    36	
    37	static inline void tsb_context_switch_ctx(struct mm_struct *mm,
    38						  unsigned long ctx)
    39	{
    40		__tsb_context_switch(__pa(mm-&gt;pgd),
    41				     &amp;mm-&gt;context.tsb_block[MM_TSB_BASE],
    42	#if defined(CONFIG_HUGETLB_PAGE) || defined(CONFIG_TRANSPARENT_HUGEPAGE)
    43				     (mm-&gt;context.tsb_block[MM_TSB_HUGE].tsb ?
    44				      &amp;mm-&gt;context.tsb_block[MM_TSB_HUGE] :
    45				      NULL)
    46	#else
    47				     NULL
    48	#endif
    49				     , __pa(&amp;mm-&gt;context.tsb_descr[MM_TSB_BASE]),
    50				     ctx);
    51	}
    52	
    53	#define tsb_context_switch(X) tsb_context_switch_ctx(X, 0)
    54	
    55	void tsb_grow(struct mm_struct *mm,
    56		      unsigned long tsb_index,
    57		      unsigned long mm_rss);
    58	#ifdef CONFIG_SMP
    59	void smp_tsb_sync(struct mm_struct *mm);
    60	#else
    61	#define smp_tsb_sync(__mm) do { } while (0)
    62	#endif
    63	
    64	/* Set MMU context in the actual hardware. */
    65	#define load_secondary_context(__mm) \
    66		__asm__ __volatile__( \
    67		&quot;\n661:	stxa		%0, [%1] %2\n&quot; \
    68		&quot;	.section	.sun4v_1insn_patch, \&quot;ax\&quot;\n&quot; \
    69		&quot;	.word		661b\n&quot; \
    70		&quot;	stxa		%0, [%1] %3\n&quot; \
    71		&quot;	.previous\n&quot; \
    72		&quot;	flush		%%g6\n&quot; \
    73		: /* No outputs */ \
    74		: &quot;r&quot; (CTX_HWBITS((__mm)-&gt;context)), \
    75		  &quot;r&quot; (SECONDARY_CONTEXT), &quot;i&quot; (ASI_DMMU), &quot;i&quot; (ASI_MMU))
    76	
    77	void __flush_tlb_mm(unsigned long, unsigned long);
    78	
    79	/* Switch the current MM context. */
    80	static inline void switch_mm(struct mm_struct *old_mm, struct mm_struct *mm, struct task_struct *tsk)
    81	{
    82		unsigned long ctx_valid, flags;
    83		int cpu = smp_processor_id();
    84	
    85		per_cpu(per_cpu_secondary_mm, cpu) = mm;
    86		if (unlikely(mm == &amp;init_mm))
    87			return;
    88	
    89		spin_lock_irqsave(&amp;mm-&gt;context.lock, flags);
    90		ctx_valid = CTX_VALID(mm-&gt;context);
    91		if (!ctx_valid)
    92			get_new_mmu_context(mm);
    93	
    94		/* We have to be extremely careful here or else we will miss
    95		 * a TSB grow if we switch back and forth between a kernel
    96		 * thread and an address space which has it&#39;s TSB size increased
    97		 * on another processor.
    98		 *
    99		 * It is possible to play some games in order to optimize the
   100		 * switch, but the safest thing to do is to unconditionally
   101		 * perform the secondary context load and the TSB context switch.
   102		 *
   103		 * For reference the bad case is, for address space &quot;A&quot;:
   104		 *
   105		 *		CPU 0			CPU 1
   106		 *	run address space A
   107		 *	set cpu0&#39;s bits in cpu_vm_mask
   108		 *	switch to kernel thread, borrow
   109		 *	address space A via entry_lazy_tlb
   110		 *					run address space A
   111		 *					set cpu1&#39;s bit in cpu_vm_mask
   112		 *					flush_tlb_pending()
   113		 *					reset cpu_vm_mask to just cpu1
   114		 *					TSB grow
   115		 *	run address space A
   116		 *	context was valid, so skip
   117		 *	TSB context switch
   118		 *
   119		 * At that point cpu0 continues to use a stale TSB, the one from
   120		 * before the TSB grow performed on cpu1.  cpu1 did not cross-call
   121		 * cpu0 to update it&#39;s TSB because at that point the cpu_vm_mask
   122		 * only had cpu1 set in it.
   123		 */
   124		tsb_context_switch_ctx(mm, CTX_HWBITS(mm-&gt;context));
   125	
   126		/* Any time a processor runs a context on an address space
   127		 * for the first time, we must flush that context out of the
   128		 * local TLB.
   129		 */
   130		if (!ctx_valid || !cpumask_test_cpu(cpu, mm_cpumask(mm))) {
   131			cpumask_set_cpu(cpu, mm_cpumask(mm));
   132			__flush_tlb_mm(CTX_HWBITS(mm-&gt;context),
   133				       SECONDARY_CONTEXT);
   134		}
   135		spin_unlock_irqrestore(&amp;mm-&gt;context.lock, flags);
   136	}
   137	
   138	#define deactivate_mm(tsk,mm)	do { } while (0)
   139	#define activate_mm(active_mm, mm) switch_mm(active_mm, mm, NULL)
   140	
   141	#define  __HAVE_ARCH_START_CONTEXT_SWITCH
   142	static inline void arch_start_context_switch(struct task_struct *prev)
   143	{
   144		/* Save the current state of MCDPER register for the process
   145		 * we are switching from
   146		 */
   147		if (adi_capable()) {
   148			register unsigned long tmp_mcdper;
   149	
   150			__asm__ __volatile__(
   151				&quot;.word 0x83438000\n\t&quot;	/* rd  %mcdper, %g1 */
   152				&quot;mov %%g1, %0\n\t&quot;
   153				: &quot;=r&quot; (tmp_mcdper)
   154				:
   155				: &quot;g1&quot;);
   156			if (tmp_mcdper)
<span class="quote"> &gt; 157				set_tsk_thread_flag(prev, TIF_MCDPER);</span>
   158			else
<span class="quote"> &gt; 159				clear_tsk_thread_flag(prev, TIF_MCDPER);</span>
   160		}
   161	}
   162	
   163	#define finish_arch_post_lock_switch	finish_arch_post_lock_switch
   164	static inline void finish_arch_post_lock_switch(void)
   165	{
   166		/* Restore the state of MCDPER register for the new process
   167		 * just switched to.
   168		 */
   169		if (adi_capable()) {
   170			register unsigned long tmp_mcdper;
   171	
   172			tmp_mcdper = test_thread_flag(TIF_MCDPER);
   173			__asm__ __volatile__(
   174				&quot;mov %0, %%g1\n\t&quot;
   175				&quot;.word 0x9d800001\n\t&quot;	/* wr %g0, %g1, %mcdper&quot; */
   176				&quot;.word 0xaf902001\n\t&quot;	/* wrpr %g0, 1, %pmcdper */
   177				:
   178				: &quot;ir&quot; (tmp_mcdper)
   179				: &quot;g1&quot;);
<span class="quote"> &gt; 180			if (current &amp;&amp; current-&gt;mm &amp;&amp; current-&gt;mm-&gt;context.adi) {</span>
   181				struct pt_regs *regs;
   182	
<span class="quote"> &gt; 183				regs = task_pt_regs(current);</span>
   184				regs-&gt;tstate |= TSTATE_MCDE;
   185			}
   186		}
   187	}
   188	

---
0-DAY kernel test infrastructure                Open Source Technology Center
https://lists.01.org/pipermail/kbuild-all                   Intel Corporation
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=63231">Khalid Aziz</a> - Feb. 23, 2018, 6:51 p.m.</div>
<pre class="content">
On 02/22/2018 07:50 PM, kbuild test robot wrote:
<span class="quote">&gt; Hi Khalid,</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; I love your patch! Yet something to improve:</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; [auto build test ERROR on sparc-next/master]</span>
<span class="quote">&gt; [also build test ERROR on v4.16-rc2]</span>
<span class="quote">&gt; [cannot apply to next-20180222]</span>
<span class="quote">&gt; [if your patch is applied to the wrong git tree, please drop us a note to help improve the system]</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; url:    https://github.com/0day-ci/linux/commits/Khalid-Aziz/Application-Data-Integrity-feature-introduced-by-SPARC-M7/20180223-071725</span>
<span class="quote">&gt; base:   https://git.kernel.org/pub/scm/linux/kernel/git/davem/sparc-next.git master</span>
<span class="quote">&gt; config: sparc64-allyesconfig (attached as .config)</span>
<span class="quote">&gt; compiler: sparc64-linux-gnu-gcc (Debian 7.2.0-11) 7.2.0</span>
<span class="quote">&gt; reproduce:</span>
<span class="quote">&gt;          wget https://raw.githubusercontent.com/intel/lkp-tests/master/sbin/make.cross -O ~/bin/make.cross</span>
<span class="quote">&gt;          chmod +x ~/bin/make.cross</span>
<span class="quote">&gt;          # save the attached .config to linux build tree</span>
<span class="quote">&gt;          make.cross ARCH=sparc64</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; All error/warnings (new ones prefixed by &gt;&gt;):</span>

Hi Dave,

Including linux/sched.h in arch/sparc/include/asm/mmu_context.h should 
eliminate these build warnings. My gcc version 6.2.1 does not report 
these errors. Build bot is using 7.2.0.

I can add a patch 12 to add the include, revise patch 10 or you can add 
the include in your tree. Let me know how you would prefer to resolve this.

Thanks,
Khalid
<span class="quote">
&gt; </span>
<span class="quote">&gt;     In file included from arch/sparc/include/asm/mmu_context.h:5:0,</span>
<span class="quote">&gt;                      from include/linux/mmu_context.h:5,</span>
<span class="quote">&gt;                      from drivers/gpu/drm/amd/amdgpu/amdgpu_amdkfd.h:29,</span>
<span class="quote">&gt;                      from drivers/gpu/drm/amd/amdgpu/amdgpu_amdkfd.c:23:</span>
<span class="quote">&gt;     arch/sparc/include/asm/mmu_context_64.h: In function &#39;arch_start_context_switch&#39;:</span>
<span class="quote">&gt;&gt;&gt; arch/sparc/include/asm/mmu_context_64.h:157:4: error: implicit declaration of function &#39;set_tsk_thread_flag&#39;; did you mean &#39;set_ti_thread_flag&#39;? [-Werror=implicit-function-declaration]</span>
<span class="quote">&gt;         set_tsk_thread_flag(prev, TIF_MCDPER);</span>
<span class="quote">&gt;         ^~~~~~~~~~~~~~~~~~~</span>
<span class="quote">&gt;         set_ti_thread_flag</span>
<span class="quote">&gt;&gt;&gt; arch/sparc/include/asm/mmu_context_64.h:159:4: error: implicit declaration of function &#39;clear_tsk_thread_flag&#39;; did you mean &#39;clear_ti_thread_flag&#39;? [-Werror=implicit-function-declaration]</span>
<span class="quote">&gt;         clear_tsk_thread_flag(prev, TIF_MCDPER);</span>
<span class="quote">&gt;         ^~~~~~~~~~~~~~~~~~~~~</span>
<span class="quote">&gt;         clear_ti_thread_flag</span>
<span class="quote">&gt;     arch/sparc/include/asm/mmu_context_64.h: In function &#39;finish_arch_post_lock_switch&#39;:</span>
<span class="quote">&gt;&gt;&gt; arch/sparc/include/asm/mmu_context_64.h:180:25: error: dereferencing pointer to incomplete type &#39;struct task_struct&#39;</span>
<span class="quote">&gt;        if (current &amp;&amp; current-&gt;mm &amp;&amp; current-&gt;mm-&gt;context.adi) {</span>
<span class="quote">&gt;                              ^~</span>
<span class="quote">&gt;     In file included from arch/sparc/include/asm/processor.h:5:0,</span>
<span class="quote">&gt;                      from arch/sparc/include/asm/spinlock_64.h:12,</span>
<span class="quote">&gt;                      from arch/sparc/include/asm/spinlock.h:5,</span>
<span class="quote">&gt;                      from include/linux/spinlock.h:88,</span>
<span class="quote">&gt;                      from arch/sparc/include/asm/mmu_context_64.h:9,</span>
<span class="quote">&gt;                      from arch/sparc/include/asm/mmu_context.h:5,</span>
<span class="quote">&gt;                      from include/linux/mmu_context.h:5,</span>
<span class="quote">&gt;                      from drivers/gpu/drm/amd/amdgpu/amdgpu_amdkfd.h:29,</span>
<span class="quote">&gt;                      from drivers/gpu/drm/amd/amdgpu/amdgpu_amdkfd.c:23:</span>
<span class="quote">&gt;&gt;&gt; arch/sparc/include/asm/processor_64.h:194:28: error: implicit declaration of function &#39;task_thread_info&#39;; did you mean &#39;test_thread_flag&#39;? [-Werror=implicit-function-declaration]</span>
<span class="quote">&gt;      #define task_pt_regs(tsk) (task_thread_info(tsk)-&gt;kregs)</span>
<span class="quote">&gt;                                 ^</span>
<span class="quote">&gt;&gt;&gt; arch/sparc/include/asm/mmu_context_64.h:183:11: note: in expansion of macro &#39;task_pt_regs&#39;</span>
<span class="quote">&gt;         regs = task_pt_regs(current);</span>
<span class="quote">&gt;                ^~~~~~~~~~~~</span>
<span class="quote">&gt;&gt;&gt; arch/sparc/include/asm/processor_64.h:194:49: error: invalid type argument of &#39;-&gt;&#39; (have &#39;int&#39;)</span>
<span class="quote">&gt;      #define task_pt_regs(tsk) (task_thread_info(tsk)-&gt;kregs)</span>
<span class="quote">&gt;                                                      ^</span>
<span class="quote">&gt;&gt;&gt; arch/sparc/include/asm/mmu_context_64.h:183:11: note: in expansion of macro &#39;task_pt_regs&#39;</span>
<span class="quote">&gt;         regs = task_pt_regs(current);</span>
<span class="quote">&gt;                ^~~~~~~~~~~~</span>
<span class="quote">&gt;     In file included from include/linux/cred.h:21:0,</span>
<span class="quote">&gt;                      from include/linux/seq_file.h:12,</span>
<span class="quote">&gt;                      from include/linux/pinctrl/consumer.h:17,</span>
<span class="quote">&gt;                      from include/linux/pinctrl/devinfo.h:21,</span>
<span class="quote">&gt;                      from include/linux/device.h:23,</span>
<span class="quote">&gt;                      from include/linux/cdev.h:8,</span>
<span class="quote">&gt;                      from include/drm/drmP.h:36,</span>
<span class="quote">&gt;                      from drivers/gpu/drm/amd/amdgpu/amdgpu_amdkfd.c:25:</span>
<span class="quote">&gt;     include/linux/sched.h: At top level:</span>
<span class="quote">&gt;&gt;&gt; include/linux/sched.h:1530:20: warning: conflicting types for &#39;set_tsk_thread_flag&#39;</span>
<span class="quote">&gt;      static inline void set_tsk_thread_flag(struct task_struct *tsk, int flag)</span>
<span class="quote">&gt;                         ^~~~~~~~~~~~~~~~~~~</span>
<span class="quote">&gt;&gt;&gt; include/linux/sched.h:1530:20: error: static declaration of &#39;set_tsk_thread_flag&#39; follows non-static declaration</span>
<span class="quote">&gt;     In file included from arch/sparc/include/asm/mmu_context.h:5:0,</span>
<span class="quote">&gt;                      from include/linux/mmu_context.h:5,</span>
<span class="quote">&gt;                      from drivers/gpu/drm/amd/amdgpu/amdgpu_amdkfd.h:29,</span>
<span class="quote">&gt;                      from drivers/gpu/drm/amd/amdgpu/amdgpu_amdkfd.c:23:</span>
<span class="quote">&gt;     arch/sparc/include/asm/mmu_context_64.h:157:4: note: previous implicit declaration of &#39;set_tsk_thread_flag&#39; was here</span>
<span class="quote">&gt;         set_tsk_thread_flag(prev, TIF_MCDPER);</span>
<span class="quote">&gt;         ^~~~~~~~~~~~~~~~~~~</span>
<span class="quote">&gt;     In file included from include/linux/cred.h:21:0,</span>
<span class="quote">&gt;                      from include/linux/seq_file.h:12,</span>
<span class="quote">&gt;                      from include/linux/pinctrl/consumer.h:17,</span>
<span class="quote">&gt;                      from include/linux/pinctrl/devinfo.h:21,</span>
<span class="quote">&gt;                      from include/linux/device.h:23,</span>
<span class="quote">&gt;                      from include/linux/cdev.h:8,</span>
<span class="quote">&gt;                      from include/drm/drmP.h:36,</span>
<span class="quote">&gt;                      from drivers/gpu/drm/amd/amdgpu/amdgpu_amdkfd.c:25:</span>
<span class="quote">&gt;&gt;&gt; include/linux/sched.h:1535:20: warning: conflicting types for &#39;clear_tsk_thread_flag&#39;</span>
<span class="quote">&gt;      static inline void clear_tsk_thread_flag(struct task_struct *tsk, int flag)</span>
<span class="quote">&gt;                         ^~~~~~~~~~~~~~~~~~~~~</span>
<span class="quote">&gt;&gt;&gt; include/linux/sched.h:1535:20: error: static declaration of &#39;clear_tsk_thread_flag&#39; follows non-static declaration</span>
<span class="quote">&gt;     In file included from arch/sparc/include/asm/mmu_context.h:5:0,</span>
<span class="quote">&gt;                      from include/linux/mmu_context.h:5,</span>
<span class="quote">&gt;                      from drivers/gpu/drm/amd/amdgpu/amdgpu_amdkfd.h:29,</span>
<span class="quote">&gt;                      from drivers/gpu/drm/amd/amdgpu/amdgpu_amdkfd.c:23:</span>
<span class="quote">&gt;     arch/sparc/include/asm/mmu_context_64.h:159:4: note: previous implicit declaration of &#39;clear_tsk_thread_flag&#39; was here</span>
<span class="quote">&gt;         clear_tsk_thread_flag(prev, TIF_MCDPER);</span>
<span class="quote">&gt;         ^~~~~~~~~~~~~~~~~~~~~</span>
<span class="quote">&gt;     cc1: some warnings being treated as errors</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; vim +157 arch/sparc/include/asm/mmu_context_64.h</span>
<span class="quote">&gt; </span>
<span class="quote">&gt;       8	</span>
<span class="quote">&gt;     &gt; 9	#include &lt;linux/spinlock.h&gt;</span>
<span class="quote">&gt;      10	#include &lt;linux/mm_types.h&gt;</span>
<span class="quote">&gt;      11	#include &lt;linux/smp.h&gt;</span>
<span class="quote">&gt;      12	</span>
<span class="quote">&gt;      13	#include &lt;asm/spitfire.h&gt;</span>
<span class="quote">&gt;      14	#include &lt;asm/adi_64.h&gt;</span>
<span class="quote">&gt;      15	#include &lt;asm-generic/mm_hooks.h&gt;</span>
<span class="quote">&gt;      16	#include &lt;asm/percpu.h&gt;</span>
<span class="quote">&gt;      17	</span>
<span class="quote">&gt;      18	static inline void enter_lazy_tlb(struct mm_struct *mm, struct task_struct *tsk)</span>
<span class="quote">&gt;      19	{</span>
<span class="quote">&gt;      20	}</span>
<span class="quote">&gt;      21	</span>
<span class="quote">&gt;      22	extern spinlock_t ctx_alloc_lock;</span>
<span class="quote">&gt;      23	extern unsigned long tlb_context_cache;</span>
<span class="quote">&gt;      24	extern unsigned long mmu_context_bmap[];</span>
<span class="quote">&gt;      25	</span>
<span class="quote">&gt;      26	DECLARE_PER_CPU(struct mm_struct *, per_cpu_secondary_mm);</span>
<span class="quote">&gt;      27	void get_new_mmu_context(struct mm_struct *mm);</span>
<span class="quote">&gt;      28	int init_new_context(struct task_struct *tsk, struct mm_struct *mm);</span>
<span class="quote">&gt;      29	void destroy_context(struct mm_struct *mm);</span>
<span class="quote">&gt;      30	</span>
<span class="quote">&gt;      31	void __tsb_context_switch(unsigned long pgd_pa,</span>
<span class="quote">&gt;      32				  struct tsb_config *tsb_base,</span>
<span class="quote">&gt;      33				  struct tsb_config *tsb_huge,</span>
<span class="quote">&gt;      34				  unsigned long tsb_descr_pa,</span>
<span class="quote">&gt;      35				  unsigned long secondary_ctx);</span>
<span class="quote">&gt;      36	</span>
<span class="quote">&gt;      37	static inline void tsb_context_switch_ctx(struct mm_struct *mm,</span>
<span class="quote">&gt;      38						  unsigned long ctx)</span>
<span class="quote">&gt;      39	{</span>
<span class="quote">&gt;      40		__tsb_context_switch(__pa(mm-&gt;pgd),</span>
<span class="quote">&gt;      41				     &amp;mm-&gt;context.tsb_block[MM_TSB_BASE],</span>
<span class="quote">&gt;      42	#if defined(CONFIG_HUGETLB_PAGE) || defined(CONFIG_TRANSPARENT_HUGEPAGE)</span>
<span class="quote">&gt;      43				     (mm-&gt;context.tsb_block[MM_TSB_HUGE].tsb ?</span>
<span class="quote">&gt;      44				      &amp;mm-&gt;context.tsb_block[MM_TSB_HUGE] :</span>
<span class="quote">&gt;      45				      NULL)</span>
<span class="quote">&gt;      46	#else</span>
<span class="quote">&gt;      47				     NULL</span>
<span class="quote">&gt;      48	#endif</span>
<span class="quote">&gt;      49				     , __pa(&amp;mm-&gt;context.tsb_descr[MM_TSB_BASE]),</span>
<span class="quote">&gt;      50				     ctx);</span>
<span class="quote">&gt;      51	}</span>
<span class="quote">&gt;      52	</span>
<span class="quote">&gt;      53	#define tsb_context_switch(X) tsb_context_switch_ctx(X, 0)</span>
<span class="quote">&gt;      54	</span>
<span class="quote">&gt;      55	void tsb_grow(struct mm_struct *mm,</span>
<span class="quote">&gt;      56		      unsigned long tsb_index,</span>
<span class="quote">&gt;      57		      unsigned long mm_rss);</span>
<span class="quote">&gt;      58	#ifdef CONFIG_SMP</span>
<span class="quote">&gt;      59	void smp_tsb_sync(struct mm_struct *mm);</span>
<span class="quote">&gt;      60	#else</span>
<span class="quote">&gt;      61	#define smp_tsb_sync(__mm) do { } while (0)</span>
<span class="quote">&gt;      62	#endif</span>
<span class="quote">&gt;      63	</span>
<span class="quote">&gt;      64	/* Set MMU context in the actual hardware. */</span>
<span class="quote">&gt;      65	#define load_secondary_context(__mm) \</span>
<span class="quote">&gt;      66		__asm__ __volatile__( \</span>
<span class="quote">&gt;      67		&quot;\n661:	stxa		%0, [%1] %2\n&quot; \</span>
<span class="quote">&gt;      68		&quot;	.section	.sun4v_1insn_patch, \&quot;ax\&quot;\n&quot; \</span>
<span class="quote">&gt;      69		&quot;	.word		661b\n&quot; \</span>
<span class="quote">&gt;      70		&quot;	stxa		%0, [%1] %3\n&quot; \</span>
<span class="quote">&gt;      71		&quot;	.previous\n&quot; \</span>
<span class="quote">&gt;      72		&quot;	flush		%%g6\n&quot; \</span>
<span class="quote">&gt;      73		: /* No outputs */ \</span>
<span class="quote">&gt;      74		: &quot;r&quot; (CTX_HWBITS((__mm)-&gt;context)), \</span>
<span class="quote">&gt;      75		  &quot;r&quot; (SECONDARY_CONTEXT), &quot;i&quot; (ASI_DMMU), &quot;i&quot; (ASI_MMU))</span>
<span class="quote">&gt;      76	</span>
<span class="quote">&gt;      77	void __flush_tlb_mm(unsigned long, unsigned long);</span>
<span class="quote">&gt;      78	</span>
<span class="quote">&gt;      79	/* Switch the current MM context. */</span>
<span class="quote">&gt;      80	static inline void switch_mm(struct mm_struct *old_mm, struct mm_struct *mm, struct task_struct *tsk)</span>
<span class="quote">&gt;      81	{</span>
<span class="quote">&gt;      82		unsigned long ctx_valid, flags;</span>
<span class="quote">&gt;      83		int cpu = smp_processor_id();</span>
<span class="quote">&gt;      84	</span>
<span class="quote">&gt;      85		per_cpu(per_cpu_secondary_mm, cpu) = mm;</span>
<span class="quote">&gt;      86		if (unlikely(mm == &amp;init_mm))</span>
<span class="quote">&gt;      87			return;</span>
<span class="quote">&gt;      88	</span>
<span class="quote">&gt;      89		spin_lock_irqsave(&amp;mm-&gt;context.lock, flags);</span>
<span class="quote">&gt;      90		ctx_valid = CTX_VALID(mm-&gt;context);</span>
<span class="quote">&gt;      91		if (!ctx_valid)</span>
<span class="quote">&gt;      92			get_new_mmu_context(mm);</span>
<span class="quote">&gt;      93	</span>
<span class="quote">&gt;      94		/* We have to be extremely careful here or else we will miss</span>
<span class="quote">&gt;      95		 * a TSB grow if we switch back and forth between a kernel</span>
<span class="quote">&gt;      96		 * thread and an address space which has it&#39;s TSB size increased</span>
<span class="quote">&gt;      97		 * on another processor.</span>
<span class="quote">&gt;      98		 *</span>
<span class="quote">&gt;      99		 * It is possible to play some games in order to optimize the</span>
<span class="quote">&gt;     100		 * switch, but the safest thing to do is to unconditionally</span>
<span class="quote">&gt;     101		 * perform the secondary context load and the TSB context switch.</span>
<span class="quote">&gt;     102		 *</span>
<span class="quote">&gt;     103		 * For reference the bad case is, for address space &quot;A&quot;:</span>
<span class="quote">&gt;     104		 *</span>
<span class="quote">&gt;     105		 *		CPU 0			CPU 1</span>
<span class="quote">&gt;     106		 *	run address space A</span>
<span class="quote">&gt;     107		 *	set cpu0&#39;s bits in cpu_vm_mask</span>
<span class="quote">&gt;     108		 *	switch to kernel thread, borrow</span>
<span class="quote">&gt;     109		 *	address space A via entry_lazy_tlb</span>
<span class="quote">&gt;     110		 *					run address space A</span>
<span class="quote">&gt;     111		 *					set cpu1&#39;s bit in cpu_vm_mask</span>
<span class="quote">&gt;     112		 *					flush_tlb_pending()</span>
<span class="quote">&gt;     113		 *					reset cpu_vm_mask to just cpu1</span>
<span class="quote">&gt;     114		 *					TSB grow</span>
<span class="quote">&gt;     115		 *	run address space A</span>
<span class="quote">&gt;     116		 *	context was valid, so skip</span>
<span class="quote">&gt;     117		 *	TSB context switch</span>
<span class="quote">&gt;     118		 *</span>
<span class="quote">&gt;     119		 * At that point cpu0 continues to use a stale TSB, the one from</span>
<span class="quote">&gt;     120		 * before the TSB grow performed on cpu1.  cpu1 did not cross-call</span>
<span class="quote">&gt;     121		 * cpu0 to update it&#39;s TSB because at that point the cpu_vm_mask</span>
<span class="quote">&gt;     122		 * only had cpu1 set in it.</span>
<span class="quote">&gt;     123		 */</span>
<span class="quote">&gt;     124		tsb_context_switch_ctx(mm, CTX_HWBITS(mm-&gt;context));</span>
<span class="quote">&gt;     125	</span>
<span class="quote">&gt;     126		/* Any time a processor runs a context on an address space</span>
<span class="quote">&gt;     127		 * for the first time, we must flush that context out of the</span>
<span class="quote">&gt;     128		 * local TLB.</span>
<span class="quote">&gt;     129		 */</span>
<span class="quote">&gt;     130		if (!ctx_valid || !cpumask_test_cpu(cpu, mm_cpumask(mm))) {</span>
<span class="quote">&gt;     131			cpumask_set_cpu(cpu, mm_cpumask(mm));</span>
<span class="quote">&gt;     132			__flush_tlb_mm(CTX_HWBITS(mm-&gt;context),</span>
<span class="quote">&gt;     133				       SECONDARY_CONTEXT);</span>
<span class="quote">&gt;     134		}</span>
<span class="quote">&gt;     135		spin_unlock_irqrestore(&amp;mm-&gt;context.lock, flags);</span>
<span class="quote">&gt;     136	}</span>
<span class="quote">&gt;     137	</span>
<span class="quote">&gt;     138	#define deactivate_mm(tsk,mm)	do { } while (0)</span>
<span class="quote">&gt;     139	#define activate_mm(active_mm, mm) switch_mm(active_mm, mm, NULL)</span>
<span class="quote">&gt;     140	</span>
<span class="quote">&gt;     141	#define  __HAVE_ARCH_START_CONTEXT_SWITCH</span>
<span class="quote">&gt;     142	static inline void arch_start_context_switch(struct task_struct *prev)</span>
<span class="quote">&gt;     143	{</span>
<span class="quote">&gt;     144		/* Save the current state of MCDPER register for the process</span>
<span class="quote">&gt;     145		 * we are switching from</span>
<span class="quote">&gt;     146		 */</span>
<span class="quote">&gt;     147		if (adi_capable()) {</span>
<span class="quote">&gt;     148			register unsigned long tmp_mcdper;</span>
<span class="quote">&gt;     149	</span>
<span class="quote">&gt;     150			__asm__ __volatile__(</span>
<span class="quote">&gt;     151				&quot;.word 0x83438000\n\t&quot;	/* rd  %mcdper, %g1 */</span>
<span class="quote">&gt;     152				&quot;mov %%g1, %0\n\t&quot;</span>
<span class="quote">&gt;     153				: &quot;=r&quot; (tmp_mcdper)</span>
<span class="quote">&gt;     154				:</span>
<span class="quote">&gt;     155				: &quot;g1&quot;);</span>
<span class="quote">&gt;     156			if (tmp_mcdper)</span>
<span class="quote">&gt;   &gt; 157				set_tsk_thread_flag(prev, TIF_MCDPER);</span>
<span class="quote">&gt;     158			else</span>
<span class="quote">&gt;   &gt; 159				clear_tsk_thread_flag(prev, TIF_MCDPER);</span>
<span class="quote">&gt;     160		}</span>
<span class="quote">&gt;     161	}</span>
<span class="quote">&gt;     162	</span>
<span class="quote">&gt;     163	#define finish_arch_post_lock_switch	finish_arch_post_lock_switch</span>
<span class="quote">&gt;     164	static inline void finish_arch_post_lock_switch(void)</span>
<span class="quote">&gt;     165	{</span>
<span class="quote">&gt;     166		/* Restore the state of MCDPER register for the new process</span>
<span class="quote">&gt;     167		 * just switched to.</span>
<span class="quote">&gt;     168		 */</span>
<span class="quote">&gt;     169		if (adi_capable()) {</span>
<span class="quote">&gt;     170			register unsigned long tmp_mcdper;</span>
<span class="quote">&gt;     171	</span>
<span class="quote">&gt;     172			tmp_mcdper = test_thread_flag(TIF_MCDPER);</span>
<span class="quote">&gt;     173			__asm__ __volatile__(</span>
<span class="quote">&gt;     174				&quot;mov %0, %%g1\n\t&quot;</span>
<span class="quote">&gt;     175				&quot;.word 0x9d800001\n\t&quot;	/* wr %g0, %g1, %mcdper&quot; */</span>
<span class="quote">&gt;     176				&quot;.word 0xaf902001\n\t&quot;	/* wrpr %g0, 1, %pmcdper */</span>
<span class="quote">&gt;     177				:</span>
<span class="quote">&gt;     178				: &quot;ir&quot; (tmp_mcdper)</span>
<span class="quote">&gt;     179				: &quot;g1&quot;);</span>
<span class="quote">&gt;   &gt; 180			if (current &amp;&amp; current-&gt;mm &amp;&amp; current-&gt;mm-&gt;context.adi) {</span>
<span class="quote">&gt;     181				struct pt_regs *regs;</span>
<span class="quote">&gt;     182	</span>
<span class="quote">&gt;   &gt; 183				regs = task_pt_regs(current);</span>
<span class="quote">&gt;     184				regs-&gt;tstate |= TSTATE_MCDE;</span>
<span class="quote">&gt;     185			}</span>
<span class="quote">&gt;     186		}</span>
<span class="quote">&gt;     187	}</span>
<span class="quote">&gt;     188	</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; ---</span>
<span class="quote">&gt; 0-DAY kernel test infrastructure                Open Source Technology Center</span>
<span class="quote">&gt; https://lists.01.org/pipermail/kbuild-all                   Intel Corporation</span>
<span class="quote">&gt;</span>
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=129">David Miller</a> - Feb. 23, 2018, 6:57 p.m.</div>
<pre class="content">
<span class="from">From: Khalid Aziz &lt;khalid.aziz@oracle.com&gt;</span>
Date: Fri, 23 Feb 2018 11:51:25 -0700
<span class="quote">
&gt; On 02/22/2018 07:50 PM, kbuild test robot wrote:</span>
<span class="quote">&gt;&gt; Hi Khalid,</span>
<span class="quote">&gt;&gt; I love your patch! Yet something to improve:</span>
<span class="quote">&gt;&gt; [auto build test ERROR on sparc-next/master]</span>
<span class="quote">&gt;&gt; [also build test ERROR on v4.16-rc2]</span>
<span class="quote">&gt;&gt; [cannot apply to next-20180222]</span>
<span class="quote">&gt;&gt; [if your patch is applied to the wrong git tree, please drop us a note</span>
<span class="quote">&gt;&gt; to help improve the system]</span>
<span class="quote">&gt;&gt; url:</span>
<span class="quote">&gt;&gt; https://github.com/0day-ci/linux/commits/Khalid-Aziz/Application-Data-Integrity-feature-introduced-by-SPARC-M7/20180223-071725</span>
<span class="quote">&gt;&gt; base:</span>
<span class="quote">&gt;&gt; https://git.kernel.org/pub/scm/linux/kernel/git/davem/sparc-next.git</span>
<span class="quote">&gt;&gt; master</span>
<span class="quote">&gt;&gt; config: sparc64-allyesconfig (attached as .config)</span>
<span class="quote">&gt;&gt; compiler: sparc64-linux-gnu-gcc (Debian 7.2.0-11) 7.2.0</span>
<span class="quote">&gt;&gt; reproduce:</span>
<span class="quote">&gt;&gt;          wget</span>
<span class="quote">&gt;&gt;          https://raw.githubusercontent.com/intel/lkp-tests/master/sbin/make.cross</span>
<span class="quote">&gt;&gt;          -O ~/bin/make.cross</span>
<span class="quote">&gt;&gt;          chmod +x ~/bin/make.cross</span>
<span class="quote">&gt;&gt;          # save the attached .config to linux build tree</span>
<span class="quote">&gt;&gt;          make.cross ARCH=sparc64</span>
<span class="quote">&gt;&gt; All error/warnings (new ones prefixed by &gt;&gt;):</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Hi Dave,</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Including linux/sched.h in arch/sparc/include/asm/mmu_context.h should</span>
<span class="quote">&gt; eliminate these build warnings. My gcc version 6.2.1 does not report</span>
<span class="quote">&gt; these errors. Build bot is using 7.2.0.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; I can add a patch 12 to add the include, revise patch 10 or you can</span>
<span class="quote">&gt; add the include in your tree. Let me know how you would prefer to</span>
<span class="quote">&gt; resolve this.</span>

You need to update patch #10 so that your patch series is fully
bisectable.

Thank you.
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=63231">Khalid Aziz</a> - Feb. 23, 2018, 10:11 p.m.</div>
<pre class="content">
On 02/23/2018 11:57 AM, David Miller wrote:
<span class="quote">&gt; From: Khalid Aziz &lt;khalid.aziz@oracle.com&gt;</span>
<span class="quote">&gt; Date: Fri, 23 Feb 2018 11:51:25 -0700</span>
<span class="quote">&gt; </span>
<span class="quote">&gt;&gt; On 02/22/2018 07:50 PM, kbuild test robot wrote:</span>
<span class="quote">&gt;&gt;&gt; Hi Khalid,</span>
<span class="quote">&gt;&gt;&gt; I love your patch! Yet something to improve:</span>
<span class="quote">&gt;&gt;&gt; [auto build test ERROR on sparc-next/master]</span>
<span class="quote">&gt;&gt;&gt; [also build test ERROR on v4.16-rc2]</span>
<span class="quote">&gt;&gt;&gt; [cannot apply to next-20180222]</span>
<span class="quote">&gt;&gt;&gt; [if your patch is applied to the wrong git tree, please drop us a note</span>
<span class="quote">&gt;&gt;&gt; to help improve the system]</span>
<span class="quote">&gt;&gt;&gt; url:</span>
<span class="quote">&gt;&gt;&gt; https://github.com/0day-ci/linux/commits/Khalid-Aziz/Application-Data-Integrity-feature-introduced-by-SPARC-M7/20180223-071725</span>
<span class="quote">&gt;&gt;&gt; base:</span>
<span class="quote">&gt;&gt;&gt; https://git.kernel.org/pub/scm/linux/kernel/git/davem/sparc-next.git</span>
<span class="quote">&gt;&gt;&gt; master</span>
<span class="quote">&gt;&gt;&gt; config: sparc64-allyesconfig (attached as .config)</span>
<span class="quote">&gt;&gt;&gt; compiler: sparc64-linux-gnu-gcc (Debian 7.2.0-11) 7.2.0</span>
<span class="quote">&gt;&gt;&gt; reproduce:</span>
<span class="quote">&gt;&gt;&gt;           wget</span>
<span class="quote">&gt;&gt;&gt;           https://raw.githubusercontent.com/intel/lkp-tests/master/sbin/make.cross</span>
<span class="quote">&gt;&gt;&gt;           -O ~/bin/make.cross</span>
<span class="quote">&gt;&gt;&gt;           chmod +x ~/bin/make.cross</span>
<span class="quote">&gt;&gt;&gt;           # save the attached .config to linux build tree</span>
<span class="quote">&gt;&gt;&gt;           make.cross ARCH=sparc64</span>
<span class="quote">&gt;&gt;&gt; All error/warnings (new ones prefixed by &gt;&gt;):</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; Hi Dave,</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; Including linux/sched.h in arch/sparc/include/asm/mmu_context.h should</span>
<span class="quote">&gt;&gt; eliminate these build warnings. My gcc version 6.2.1 does not report</span>
<span class="quote">&gt;&gt; these errors. Build bot is using 7.2.0.</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; I can add a patch 12 to add the include, revise patch 10 or you can</span>
<span class="quote">&gt;&gt; add the include in your tree. Let me know how you would prefer to</span>
<span class="quote">&gt;&gt; resolve this.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; You need to update patch #10 so that your patch series is fully</span>
<span class="quote">&gt; bisectable.</span>

Hi Dave,

That sounds like the right thing to do. I am updating patch 10 and will 
send out v13 for patch 10/11. Rest of the series is unchanged but I can 
send the whole series if you prefer that.

Thanks,
Khalid
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=64071">Dave Hansen</a> - March 5, 2018, 7:22 p.m.</div>
<pre class="content">
On 02/21/2018 09:15 AM, Khalid Aziz wrote:
<span class="quote">&gt; +#define arch_validate_prot(prot, addr) sparc_validate_prot(prot, addr)</span>
<span class="quote">&gt; +static inline int sparc_validate_prot(unsigned long prot, unsigned long addr)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	if (prot &amp; ~(PROT_READ | PROT_WRITE | PROT_EXEC | PROT_SEM | PROT_ADI))</span>
<span class="quote">&gt; +		return 0;</span>
<span class="quote">&gt; +	if (prot &amp; PROT_ADI) {</span>
<span class="quote">&gt; +		if (!adi_capable())</span>
<span class="quote">&gt; +			return 0;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +		if (addr) {</span>
<span class="quote">&gt; +			struct vm_area_struct *vma;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +			vma = find_vma(current-&gt;mm, addr);</span>
<span class="quote">&gt; +			if (vma) {</span>
<span class="quote">&gt; +				/* ADI can not be enabled on PFN</span>
<span class="quote">&gt; +				 * mapped pages</span>
<span class="quote">&gt; +				 */</span>
<span class="quote">&gt; +				if (vma-&gt;vm_flags &amp; (VM_PFNMAP | VM_MIXEDMAP))</span>
<span class="quote">&gt; +					return 0;</span>

You don&#39;t hold mmap_sem here.  How can this work?
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=63231">Khalid Aziz</a> - March 5, 2018, 9:14 p.m.</div>
<pre class="content">
On 03/05/2018 12:22 PM, Dave Hansen wrote:
<span class="quote">&gt; On 02/21/2018 09:15 AM, Khalid Aziz wrote:</span>
<span class="quote">&gt;&gt; +#define arch_validate_prot(prot, addr) sparc_validate_prot(prot, addr)</span>
<span class="quote">&gt;&gt; +static inline int sparc_validate_prot(unsigned long prot, unsigned long addr)</span>
<span class="quote">&gt;&gt; +{</span>
<span class="quote">&gt;&gt; +	if (prot &amp; ~(PROT_READ | PROT_WRITE | PROT_EXEC | PROT_SEM | PROT_ADI))</span>
<span class="quote">&gt;&gt; +		return 0;</span>
<span class="quote">&gt;&gt; +	if (prot &amp; PROT_ADI) {</span>
<span class="quote">&gt;&gt; +		if (!adi_capable())</span>
<span class="quote">&gt;&gt; +			return 0;</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +		if (addr) {</span>
<span class="quote">&gt;&gt; +			struct vm_area_struct *vma;</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +			vma = find_vma(current-&gt;mm, addr);</span>
<span class="quote">&gt;&gt; +			if (vma) {</span>
<span class="quote">&gt;&gt; +				/* ADI can not be enabled on PFN</span>
<span class="quote">&gt;&gt; +				 * mapped pages</span>
<span class="quote">&gt;&gt; +				 */</span>
<span class="quote">&gt;&gt; +				if (vma-&gt;vm_flags &amp; (VM_PFNMAP | VM_MIXEDMAP))</span>
<span class="quote">&gt;&gt; +					return 0;</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; You don&#39;t hold mmap_sem here.  How can this work?</span>
<span class="quote">&gt;</span>

Are you suggesting that vma returned by find_vma() could be split or 
merged underneath me if I do not hold mmap_sem and thus make the flag 
check invalid? If so, that is a good point.

Thanks,
Khalid
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=64071">Dave Hansen</a> - March 5, 2018, 9:26 p.m.</div>
<pre class="content">
On 02/21/2018 09:15 AM, Khalid Aziz wrote:
<span class="quote">&gt; +tag_storage_desc_t *alloc_tag_store(struct mm_struct *mm,</span>
<span class="quote">&gt; +				    struct vm_area_struct *vma,</span>
<span class="quote">&gt; +				    unsigned long addr)</span>
...
<span class="quote">&gt; +	tags = kzalloc(size, GFP_NOWAIT|__GFP_NOWARN);</span>
<span class="quote">&gt; +	if (tags == NULL) {</span>
<span class="quote">&gt; +		tag_desc-&gt;tag_users = 0;</span>
<span class="quote">&gt; +		tag_desc = NULL;</span>
<span class="quote">&gt; +		goto out;</span>
<span class="quote">&gt; +	}</span>
<span class="quote">&gt; +	tag_desc-&gt;start = addr;</span>
<span class="quote">&gt; +	tag_desc-&gt;tags = tags;</span>
<span class="quote">&gt; +	tag_desc-&gt;end = end_addr;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +out:</span>
<span class="quote">&gt; +	spin_unlock_irqrestore(&amp;mm-&gt;context.tag_lock, flags);</span>
<span class="quote">&gt; +	return tag_desc;</span>
<span class="quote">&gt; +}</span>

OK, sorry, I missed this.  I do see that you now have per-ADI-block tag
storage and it is not per-page.

How big can this storage get, btw?  Superficially it seems like it might
be able to be gigantic for a large, sparse VMA.
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=64071">Dave Hansen</a> - March 5, 2018, 9:26 p.m.</div>
<pre class="content">
On 03/05/2018 01:14 PM, Khalid Aziz wrote:
<span class="quote">&gt; On 03/05/2018 12:22 PM, Dave Hansen wrote:</span>
<span class="quote">&gt;&gt; On 02/21/2018 09:15 AM, Khalid Aziz wrote:</span>
<span class="quote">&gt;&gt;&gt; +#define arch_validate_prot(prot, addr) sparc_validate_prot(prot, addr)</span>
<span class="quote">&gt;&gt;&gt; +static inline int sparc_validate_prot(unsigned long prot, unsigned</span>
<span class="quote">&gt;&gt;&gt; long addr)</span>
<span class="quote">&gt;&gt;&gt; +{</span>
<span class="quote">&gt;&gt;&gt; +    if (prot &amp; ~(PROT_READ | PROT_WRITE | PROT_EXEC | PROT_SEM |</span>
<span class="quote">&gt;&gt;&gt; PROT_ADI))</span>
<span class="quote">&gt;&gt;&gt; +        return 0;</span>
<span class="quote">&gt;&gt;&gt; +    if (prot &amp; PROT_ADI) {</span>
<span class="quote">&gt;&gt;&gt; +        if (!adi_capable())</span>
<span class="quote">&gt;&gt;&gt; +            return 0;</span>
<span class="quote">&gt;&gt;&gt; +</span>
<span class="quote">&gt;&gt;&gt; +        if (addr) {</span>
<span class="quote">&gt;&gt;&gt; +            struct vm_area_struct *vma;</span>
<span class="quote">&gt;&gt;&gt; +</span>
<span class="quote">&gt;&gt;&gt; +            vma = find_vma(current-&gt;mm, addr);</span>
<span class="quote">&gt;&gt;&gt; +            if (vma) {</span>
<span class="quote">&gt;&gt;&gt; +                /* ADI can not be enabled on PFN</span>
<span class="quote">&gt;&gt;&gt; +                 * mapped pages</span>
<span class="quote">&gt;&gt;&gt; +                 */</span>
<span class="quote">&gt;&gt;&gt; +                if (vma-&gt;vm_flags &amp; (VM_PFNMAP | VM_MIXEDMAP))</span>
<span class="quote">&gt;&gt;&gt; +                    return 0;</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; You don&#39;t hold mmap_sem here.  How can this work?</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt; Are you suggesting that vma returned by find_vma() could be split or</span>
<span class="quote">&gt; merged underneath me if I do not hold mmap_sem and thus make the flag</span>
<span class="quote">&gt; check invalid? If so, that is a good point.</span>

Um, yes.  You can&#39;t walk the vma tree without holding mmap_sem.
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=64071">Dave Hansen</a> - March 5, 2018, 9:31 p.m.</div>
<pre class="content">
On 03/05/2018 01:14 PM, Khalid Aziz wrote:
<span class="quote">&gt; Are you suggesting that vma returned by find_vma() could be split or</span>
<span class="quote">&gt; merged underneath me if I do not hold mmap_sem and thus make the flag</span>
<span class="quote">&gt; check invalid? If so, that is a good point.</span>

This part does make me think that this code hasn&#39;t been tested very
thoroughly.  Could you describe the testing that you have done?  For MPX
and protection keys, I added something to tools/testing/selftests/x86,
for instance.
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=63231">Khalid Aziz</a> - March 5, 2018, 9:37 p.m.</div>
<pre class="content">
On 03/05/2018 02:26 PM, Dave Hansen wrote:
<span class="quote">&gt; On 02/21/2018 09:15 AM, Khalid Aziz wrote:</span>
<span class="quote">&gt;&gt; +tag_storage_desc_t *alloc_tag_store(struct mm_struct *mm,</span>
<span class="quote">&gt;&gt; +				    struct vm_area_struct *vma,</span>
<span class="quote">&gt;&gt; +				    unsigned long addr)</span>
<span class="quote">&gt; ...</span>
<span class="quote">&gt;&gt; +	tags = kzalloc(size, GFP_NOWAIT|__GFP_NOWARN);</span>
<span class="quote">&gt;&gt; +	if (tags == NULL) {</span>
<span class="quote">&gt;&gt; +		tag_desc-&gt;tag_users = 0;</span>
<span class="quote">&gt;&gt; +		tag_desc = NULL;</span>
<span class="quote">&gt;&gt; +		goto out;</span>
<span class="quote">&gt;&gt; +	}</span>
<span class="quote">&gt;&gt; +	tag_desc-&gt;start = addr;</span>
<span class="quote">&gt;&gt; +	tag_desc-&gt;tags = tags;</span>
<span class="quote">&gt;&gt; +	tag_desc-&gt;end = end_addr;</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +out:</span>
<span class="quote">&gt;&gt; +	spin_unlock_irqrestore(&amp;mm-&gt;context.tag_lock, flags);</span>
<span class="quote">&gt;&gt; +	return tag_desc;</span>
<span class="quote">&gt;&gt; +}</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; OK, sorry, I missed this.  I do see that you now have per-ADI-block tag</span>
<span class="quote">&gt; storage and it is not per-page.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; How big can this storage get, btw?  Superficially it seems like it might</span>
<span class="quote">&gt; be able to be gigantic for a large, sparse VMA.</span>
<span class="quote">&gt; </span>

Tags are stored only for the pages being swapped out, not for the pages 
in entire vma. Each tag storage page can hold tags for 128 pages (each 
page has 128 4-bit tags, hence 64 bytes are needed to store tags for an 
entire page allowing each page to store tags for 128 pages). Sparse VMA 
does not cause any problems since holes do not have corresponding pages 
that will be swapped out. Tag storage pages are freed once all the pages 
they store tags for have been swapped back in, except for a small number 
of pages (maximum of 8) marked for emergency tag storage.

--
Khalid
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=64071">Dave Hansen</a> - March 5, 2018, 9:50 p.m.</div>
<pre class="content">
On 03/05/2018 01:37 PM, Khalid Aziz wrote:
<span class="quote">&gt;&gt; How big can this storage get, btw?  Superficially it seems like it might</span>
<span class="quote">&gt;&gt; be able to be gigantic for a large, sparse VMA.</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt; Tags are stored only for the pages being swapped out, not for the pages</span>
<span class="quote">&gt; in entire vma. Each tag storage page can hold tags for 128 pages (each</span>
<span class="quote">&gt; page has 128 4-bit tags, hence 64 bytes are needed to store tags for an</span>
<span class="quote">&gt; entire page allowing each page to store tags for 128 pages). Sparse VMA</span>
<span class="quote">&gt; does not cause any problems since holes do not have corresponding pages</span>
<span class="quote">&gt; that will be swapped out. Tag storage pages are freed once all the pages</span>
<span class="quote">&gt; they store tags for have been swapped back in, except for a small number</span>
<span class="quote">&gt; of pages (maximum of 8) marked for emergency tag storage.</span>

With a linear scan holding a process-wide spinlock?  If you have a fast
swap device, does this become the bottleneck when swapping ADI-tagged
memory?

FWIW, this tag storage is complex and subtle enough code that it
deserves to be in its own well-documented patch, not buried in a
thousand-line patch.
<span class="quote">
&gt; +tag_storage_desc_t *find_tag_store(struct mm_struct *mm,</span>
<span class="quote">&gt; +				   struct vm_area_struct *vma,</span>
<span class="quote">&gt; +				   unsigned long addr)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	tag_storage_desc_t *tag_desc = NULL;</span>
<span class="quote">&gt; +	unsigned long i, max_desc, flags;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	/* Check if this vma already has tag storage descriptor</span>
<span class="quote">&gt; +	 * allocated for it.</span>
<span class="quote">&gt; +	 */</span>
<span class="quote">&gt; +	max_desc = PAGE_SIZE/sizeof(tag_storage_desc_t);</span>
<span class="quote">&gt; +	if (mm-&gt;context.tag_store) {</span>
<span class="quote">&gt; +		tag_desc = mm-&gt;context.tag_store;</span>
<span class="quote">&gt; +		spin_lock_irqsave(&amp;mm-&gt;context.tag_lock, flags);</span>
<span class="quote">&gt; +		for (i = 0; i &lt; max_desc; i++) {</span>
<span class="quote">&gt; +			if ((addr &gt;= tag_desc-&gt;start) &amp;&amp;</span>
<span class="quote">&gt; +			    ((addr + PAGE_SIZE - 1) &lt;= tag_desc-&gt;end))</span>
<span class="quote">&gt; +				break;</span>
<span class="quote">&gt; +			tag_desc++;</span>
<span class="quote">&gt; +		}</span>
<span class="quote">&gt; +		spin_unlock_irqrestore(&amp;mm-&gt;context.tag_lock, flags);</span>
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=63231">Khalid Aziz</a> - March 5, 2018, 10:55 p.m.</div>
<pre class="content">
On 03/05/2018 02:31 PM, Dave Hansen wrote:
<span class="quote">&gt; On 03/05/2018 01:14 PM, Khalid Aziz wrote:</span>
<span class="quote">&gt;&gt; Are you suggesting that vma returned by find_vma() could be split or</span>
<span class="quote">&gt;&gt; merged underneath me if I do not hold mmap_sem and thus make the flag</span>
<span class="quote">&gt;&gt; check invalid? If so, that is a good point.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; This part does make me think that this code hasn&#39;t been tested very</span>
<span class="quote">&gt; thoroughly.  Could you describe the testing that you have done?  For MPX</span>
<span class="quote">&gt; and protection keys, I added something to tools/testing/selftests/x86,</span>
<span class="quote">&gt; for instance.</span>

This code was tested by a QA team and I ran a number of tests myself. I 
wrote tests to exercise all of the API, induce exceptions for 
invalid/illegal accesses and swapping was tested by allocating memory 
2-4 times of the system RAM available across 4-8 threads and 
reading/writing to this memory with ADI enabled. QA team wrote unit 
tests to test each API with valid and invalid combinations of arguments 
to the API. Stress tests that allocate and free ADI tagged memory were 
also run. A version of database server was created that uses ADI tagged 
memory for in-memory copy of database to test database workload. 100&#39;s 
of hours of tests were run across these tests over the last 1+ year 
these patches have been under review for. Cover letter includes 
description of most of these tests. This code has held up through all of 
these tests. It is entirely feasible some race conditions have not been 
uncovered yet, just like any other piece of software. Pulling this code 
into mainline kernel and having lot more people exercise this code will 
help shake out any remaining issues.

Thanks,
Khalid
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/Documentation/sparc/adi.txt b/Documentation/sparc/adi.txt</span>
new file mode 100644
<span class="p_header">index 000000000000..e1aed155fb89</span>
<span class="p_header">--- /dev/null</span>
<span class="p_header">+++ b/Documentation/sparc/adi.txt</span>
<span class="p_chunk">@@ -0,0 +1,278 @@</span> <span class="p_context"></span>
<span class="p_add">+Application Data Integrity (ADI)</span>
<span class="p_add">+================================</span>
<span class="p_add">+</span>
<span class="p_add">+SPARC M7 processor adds the Application Data Integrity (ADI) feature.</span>
<span class="p_add">+ADI allows a task to set version tags on any subset of its address</span>
<span class="p_add">+space. Once ADI is enabled and version tags are set for ranges of</span>
<span class="p_add">+address space of a task, the processor will compare the tag in pointers</span>
<span class="p_add">+to memory in these ranges to the version set by the application</span>
<span class="p_add">+previously. Access to memory is granted only if the tag in given pointer</span>
<span class="p_add">+matches the tag set by the application. In case of mismatch, processor</span>
<span class="p_add">+raises an exception.</span>
<span class="p_add">+</span>
<span class="p_add">+Following steps must be taken by a task to enable ADI fully:</span>
<span class="p_add">+</span>
<span class="p_add">+1. Set the user mode PSTATE.mcde bit. This acts as master switch for</span>
<span class="p_add">+   the task&#39;s entire address space to enable/disable ADI for the task.</span>
<span class="p_add">+</span>
<span class="p_add">+2. Set TTE.mcd bit on any TLB entries that correspond to the range of</span>
<span class="p_add">+   addresses ADI is being enabled on. MMU checks the version tag only</span>
<span class="p_add">+   on the pages that have TTE.mcd bit set.</span>
<span class="p_add">+</span>
<span class="p_add">+3. Set the version tag for virtual addresses using stxa instruction</span>
<span class="p_add">+   and one of the MCD specific ASIs. Each stxa instruction sets the</span>
<span class="p_add">+   given tag for one ADI block size number of bytes. This step must</span>
<span class="p_add">+   be repeated for entire page to set tags for entire page.</span>
<span class="p_add">+</span>
<span class="p_add">+ADI block size for the platform is provided by the hypervisor to kernel</span>
<span class="p_add">+in machine description tables. Hypervisor also provides the number of</span>
<span class="p_add">+top bits in the virtual address that specify the version tag.  Once</span>
<span class="p_add">+version tag has been set for a memory location, the tag is stored in the</span>
<span class="p_add">+physical memory and the same tag must be present in the ADI version tag</span>
<span class="p_add">+bits of the virtual address being presented to the MMU. For example on</span>
<span class="p_add">+SPARC M7 processor, MMU uses bits 63-60 for version tags and ADI block</span>
<span class="p_add">+size is same as cacheline size which is 64 bytes. A task that sets ADI</span>
<span class="p_add">+version to, say 10, on a range of memory, must access that memory using</span>
<span class="p_add">+virtual addresses that contain 0xa in bits 63-60.</span>
<span class="p_add">+</span>
<span class="p_add">+ADI is enabled on a set of pages using mprotect() with PROT_ADI flag.</span>
<span class="p_add">+When ADI is enabled on a set of pages by a task for the first time,</span>
<span class="p_add">+kernel sets the PSTATE.mcde bit fot the task. Version tags for memory</span>
<span class="p_add">+addresses are set with an stxa instruction on the addresses using</span>
<span class="p_add">+ASI_MCD_PRIMARY or ASI_MCD_ST_BLKINIT_PRIMARY. ADI block size is</span>
<span class="p_add">+provided by the hypervisor to the kernel.  Kernel returns the value of</span>
<span class="p_add">+ADI block size to userspace using auxiliary vector along with other ADI</span>
<span class="p_add">+info. Following auxiliary vectors are provided by the kernel:</span>
<span class="p_add">+</span>
<span class="p_add">+	AT_ADI_BLKSZ	ADI block size. This is the granularity and</span>
<span class="p_add">+			alignment, in bytes, of ADI versioning.</span>
<span class="p_add">+	AT_ADI_NBITS	Number of ADI version bits in the VA</span>
<span class="p_add">+</span>
<span class="p_add">+</span>
<span class="p_add">+IMPORTANT NOTES:</span>
<span class="p_add">+</span>
<span class="p_add">+- Version tag values of 0x0 and 0xf are reserved. These values match any</span>
<span class="p_add">+  tag in virtual address and never generate a mismatch exception.</span>
<span class="p_add">+</span>
<span class="p_add">+- Version tags are set on virtual addresses from userspace even though</span>
<span class="p_add">+  tags are stored in physical memory. Tags are set on a physical page</span>
<span class="p_add">+  after it has been allocated to a task and a pte has been created for</span>
<span class="p_add">+  it.</span>
<span class="p_add">+</span>
<span class="p_add">+- When a task frees a memory page it had set version tags on, the page</span>
<span class="p_add">+  goes back to free page pool. When this page is re-allocated to a task,</span>
<span class="p_add">+  kernel clears the page using block initialization ASI which clears the</span>
<span class="p_add">+  version tags as well for the page. If a page allocated to a task is</span>
<span class="p_add">+  freed and allocated back to the same task, old version tags set by the</span>
<span class="p_add">+  task on that page will no longer be present.</span>
<span class="p_add">+</span>
<span class="p_add">+- ADI tag mismatches are not detected for non-faulting loads.</span>
<span class="p_add">+</span>
<span class="p_add">+- Kernel does not set any tags for user pages and it is entirely a</span>
<span class="p_add">+  task&#39;s responsibility to set any version tags. Kernel does ensure the</span>
<span class="p_add">+  version tags are preserved if a page is swapped out to the disk and</span>
<span class="p_add">+  swapped back in. It also preserves that version tags if a page is</span>
<span class="p_add">+  migrated.</span>
<span class="p_add">+</span>
<span class="p_add">+- ADI works for any size pages. A userspace task need not be aware of</span>
<span class="p_add">+  page size when using ADI. It can simply select a virtual address</span>
<span class="p_add">+  range, enable ADI on the range using mprotect() and set version tags</span>
<span class="p_add">+  for the entire range. mprotect() ensures range is aligned to page size</span>
<span class="p_add">+  and is a multiple of page size.</span>
<span class="p_add">+</span>
<span class="p_add">+- ADI tags can only be set on writable memory. For example, ADI tags can</span>
<span class="p_add">+  not be set on read-only mappings.</span>
<span class="p_add">+</span>
<span class="p_add">+</span>
<span class="p_add">+</span>
<span class="p_add">+ADI related traps</span>
<span class="p_add">+-----------------</span>
<span class="p_add">+</span>
<span class="p_add">+With ADI enabled, following new traps may occur:</span>
<span class="p_add">+</span>
<span class="p_add">+Disrupting memory corruption</span>
<span class="p_add">+</span>
<span class="p_add">+	When a store accesses a memory localtion that has TTE.mcd=1,</span>
<span class="p_add">+	the task is running with ADI enabled (PSTATE.mcde=1), and the ADI</span>
<span class="p_add">+	tag in the address used (bits 63:60) does not match the tag set on</span>
<span class="p_add">+	the corresponding cacheline, a memory corruption trap occurs. By</span>
<span class="p_add">+	default, it is a disrupting trap and is sent to the hypervisor</span>
<span class="p_add">+	first. Hypervisor creates a sun4v error report and sends a</span>
<span class="p_add">+	resumable error (TT=0x7e) trap to the kernel. The kernel sends</span>
<span class="p_add">+	a SIGSEGV to the task that resulted in this trap with the following</span>
<span class="p_add">+	info:</span>
<span class="p_add">+</span>
<span class="p_add">+		siginfo.si_signo = SIGSEGV;</span>
<span class="p_add">+		siginfo.errno = 0;</span>
<span class="p_add">+		siginfo.si_code = SEGV_ADIDERR;</span>
<span class="p_add">+		siginfo.si_addr = addr; /* PC where first mismatch occurred */</span>
<span class="p_add">+		siginfo.si_trapno = 0;</span>
<span class="p_add">+</span>
<span class="p_add">+</span>
<span class="p_add">+Precise memory corruption</span>
<span class="p_add">+</span>
<span class="p_add">+	When a store accesses a memory location that has TTE.mcd=1,</span>
<span class="p_add">+	the task is running with ADI enabled (PSTATE.mcde=1), and the ADI</span>
<span class="p_add">+	tag in the address used (bits 63:60) does not match the tag set on</span>
<span class="p_add">+	the corresponding cacheline, a memory corruption trap occurs. If</span>
<span class="p_add">+	MCD precise exception is enabled (MCDPERR=1), a precise</span>
<span class="p_add">+	exception is sent to the kernel with TT=0x1a. The kernel sends</span>
<span class="p_add">+	a SIGSEGV to the task that resulted in this trap with the following</span>
<span class="p_add">+	info:</span>
<span class="p_add">+</span>
<span class="p_add">+		siginfo.si_signo = SIGSEGV;</span>
<span class="p_add">+		siginfo.errno = 0;</span>
<span class="p_add">+		siginfo.si_code = SEGV_ADIPERR;</span>
<span class="p_add">+		siginfo.si_addr = addr;	/* address that caused trap */</span>
<span class="p_add">+		siginfo.si_trapno = 0;</span>
<span class="p_add">+</span>
<span class="p_add">+	NOTE: ADI tag mismatch on a load always results in precise trap.</span>
<span class="p_add">+</span>
<span class="p_add">+</span>
<span class="p_add">+MCD disabled</span>
<span class="p_add">+</span>
<span class="p_add">+	When a task has not enabled ADI and attempts to set ADI version</span>
<span class="p_add">+	on a memory address, processor sends an MCD disabled trap. This</span>
<span class="p_add">+	trap is handled by hypervisor first and the hypervisor vectors this</span>
<span class="p_add">+	trap through to the kernel as Data Access Exception trap with</span>
<span class="p_add">+	fault type set to 0xa (invalid ASI). When this occurs, the kernel</span>
<span class="p_add">+	sends the task SIGSEGV signal with following info:</span>
<span class="p_add">+</span>
<span class="p_add">+		siginfo.si_signo = SIGSEGV;</span>
<span class="p_add">+		siginfo.errno = 0;</span>
<span class="p_add">+		siginfo.si_code = SEGV_ACCADI;</span>
<span class="p_add">+		siginfo.si_addr = addr;	/* address that caused trap */</span>
<span class="p_add">+		siginfo.si_trapno = 0;</span>
<span class="p_add">+</span>
<span class="p_add">+</span>
<span class="p_add">+Sample program to use ADI</span>
<span class="p_add">+-------------------------</span>
<span class="p_add">+</span>
<span class="p_add">+Following sample program is meant to illustrate how to use the ADI</span>
<span class="p_add">+functionality.</span>
<span class="p_add">+</span>
<span class="p_add">+#include &lt;unistd.h&gt;</span>
<span class="p_add">+#include &lt;stdio.h&gt;</span>
<span class="p_add">+#include &lt;stdlib.h&gt;</span>
<span class="p_add">+#include &lt;elf.h&gt;</span>
<span class="p_add">+#include &lt;sys/ipc.h&gt;</span>
<span class="p_add">+#include &lt;sys/shm.h&gt;</span>
<span class="p_add">+#include &lt;sys/mman.h&gt;</span>
<span class="p_add">+#include &lt;asm/asi.h&gt;</span>
<span class="p_add">+</span>
<span class="p_add">+#ifndef AT_ADI_BLKSZ</span>
<span class="p_add">+#define AT_ADI_BLKSZ	48</span>
<span class="p_add">+#endif</span>
<span class="p_add">+#ifndef AT_ADI_NBITS</span>
<span class="p_add">+#define AT_ADI_NBITS	49</span>
<span class="p_add">+#endif</span>
<span class="p_add">+</span>
<span class="p_add">+#ifndef PROT_ADI</span>
<span class="p_add">+#define PROT_ADI	0x10</span>
<span class="p_add">+#endif</span>
<span class="p_add">+</span>
<span class="p_add">+#define BUFFER_SIZE     32*1024*1024UL</span>
<span class="p_add">+</span>
<span class="p_add">+main(int argc, char* argv[], char* envp[])</span>
<span class="p_add">+{</span>
<span class="p_add">+        unsigned long i, mcde, adi_blksz, adi_nbits;</span>
<span class="p_add">+        char *shmaddr, *tmp_addr, *end, *veraddr, *clraddr;</span>
<span class="p_add">+        int shmid, version;</span>
<span class="p_add">+	Elf64_auxv_t *auxv;</span>
<span class="p_add">+</span>
<span class="p_add">+	adi_blksz = 0;</span>
<span class="p_add">+</span>
<span class="p_add">+	while(*envp++ != NULL);</span>
<span class="p_add">+	for (auxv = (Elf64_auxv_t *)envp; auxv-&gt;a_type != AT_NULL; auxv++) {</span>
<span class="p_add">+		switch (auxv-&gt;a_type) {</span>
<span class="p_add">+		case AT_ADI_BLKSZ:</span>
<span class="p_add">+			adi_blksz = auxv-&gt;a_un.a_val;</span>
<span class="p_add">+			break;</span>
<span class="p_add">+		case AT_ADI_NBITS:</span>
<span class="p_add">+			adi_nbits = auxv-&gt;a_un.a_val;</span>
<span class="p_add">+			break;</span>
<span class="p_add">+		}</span>
<span class="p_add">+	}</span>
<span class="p_add">+	if (adi_blksz == 0) {</span>
<span class="p_add">+		fprintf(stderr, &quot;Oops! ADI is not supported\n&quot;);</span>
<span class="p_add">+		exit(1);</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	printf(&quot;ADI capabilities:\n&quot;);</span>
<span class="p_add">+	printf(&quot;\tBlock size = %ld\n&quot;, adi_blksz);</span>
<span class="p_add">+	printf(&quot;\tNumber of bits = %ld\n&quot;, adi_nbits);</span>
<span class="p_add">+</span>
<span class="p_add">+        if ((shmid = shmget(2, BUFFER_SIZE,</span>
<span class="p_add">+                                IPC_CREAT | SHM_R | SHM_W)) &lt; 0) {</span>
<span class="p_add">+                perror(&quot;shmget failed&quot;);</span>
<span class="p_add">+                exit(1);</span>
<span class="p_add">+        }</span>
<span class="p_add">+</span>
<span class="p_add">+        shmaddr = shmat(shmid, NULL, 0);</span>
<span class="p_add">+        if (shmaddr == (char *)-1) {</span>
<span class="p_add">+                perror(&quot;shm attach failed&quot;);</span>
<span class="p_add">+                shmctl(shmid, IPC_RMID, NULL);</span>
<span class="p_add">+                exit(1);</span>
<span class="p_add">+        }</span>
<span class="p_add">+</span>
<span class="p_add">+	if (mprotect(shmaddr, BUFFER_SIZE, PROT_READ|PROT_WRITE|PROT_ADI)) {</span>
<span class="p_add">+		perror(&quot;mprotect failed&quot;);</span>
<span class="p_add">+		goto err_out;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+        /* Set the ADI version tag on the shm segment</span>
<span class="p_add">+         */</span>
<span class="p_add">+        version = 10;</span>
<span class="p_add">+        tmp_addr = shmaddr;</span>
<span class="p_add">+        end = shmaddr + BUFFER_SIZE;</span>
<span class="p_add">+        while (tmp_addr &lt; end) {</span>
<span class="p_add">+                asm volatile(</span>
<span class="p_add">+                        &quot;stxa %1, [%0]0x90\n\t&quot;</span>
<span class="p_add">+                        :</span>
<span class="p_add">+                        : &quot;r&quot; (tmp_addr), &quot;r&quot; (version));</span>
<span class="p_add">+                tmp_addr += adi_blksz;</span>
<span class="p_add">+        }</span>
<span class="p_add">+	asm volatile(&quot;membar #Sync\n\t&quot;);</span>
<span class="p_add">+</span>
<span class="p_add">+        /* Create a versioned address from the normal address by placing</span>
<span class="p_add">+	 * version tag in the upper adi_nbits bits</span>
<span class="p_add">+         */</span>
<span class="p_add">+        tmp_addr = (void *) ((unsigned long)shmaddr &lt;&lt; adi_nbits);</span>
<span class="p_add">+        tmp_addr = (void *) ((unsigned long)tmp_addr &gt;&gt; adi_nbits);</span>
<span class="p_add">+        veraddr = (void *) (((unsigned long)version &lt;&lt; (64-adi_nbits))</span>
<span class="p_add">+                        | (unsigned long)tmp_addr);</span>
<span class="p_add">+</span>
<span class="p_add">+        printf(&quot;Starting the writes:\n&quot;);</span>
<span class="p_add">+        for (i = 0; i &lt; BUFFER_SIZE; i++) {</span>
<span class="p_add">+                veraddr[i] = (char)(i);</span>
<span class="p_add">+                if (!(i % (1024 * 1024)))</span>
<span class="p_add">+                        printf(&quot;.&quot;);</span>
<span class="p_add">+        }</span>
<span class="p_add">+        printf(&quot;\n&quot;);</span>
<span class="p_add">+</span>
<span class="p_add">+        printf(&quot;Verifying data...&quot;);</span>
<span class="p_add">+	fflush(stdout);</span>
<span class="p_add">+        for (i = 0; i &lt; BUFFER_SIZE; i++)</span>
<span class="p_add">+                if (veraddr[i] != (char)i)</span>
<span class="p_add">+                        printf(&quot;\nIndex %lu mismatched\n&quot;, i);</span>
<span class="p_add">+        printf(&quot;Done.\n&quot;);</span>
<span class="p_add">+</span>
<span class="p_add">+        /* Disable ADI and clean up</span>
<span class="p_add">+         */</span>
<span class="p_add">+	if (mprotect(shmaddr, BUFFER_SIZE, PROT_READ|PROT_WRITE)) {</span>
<span class="p_add">+		perror(&quot;mprotect failed&quot;);</span>
<span class="p_add">+		goto err_out;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+        if (shmdt((const void *)shmaddr) != 0)</span>
<span class="p_add">+                perror(&quot;Detach failure&quot;);</span>
<span class="p_add">+        shmctl(shmid, IPC_RMID, NULL);</span>
<span class="p_add">+</span>
<span class="p_add">+        exit(0);</span>
<span class="p_add">+</span>
<span class="p_add">+err_out:</span>
<span class="p_add">+        if (shmdt((const void *)shmaddr) != 0)</span>
<span class="p_add">+                perror(&quot;Detach failure&quot;);</span>
<span class="p_add">+        shmctl(shmid, IPC_RMID, NULL);</span>
<span class="p_add">+        exit(1);</span>
<span class="p_add">+}</span>
<span class="p_header">diff --git a/arch/sparc/include/asm/mman.h b/arch/sparc/include/asm/mman.h</span>
<span class="p_header">index 7e9472143f9b..f94532f25db1 100644</span>
<span class="p_header">--- a/arch/sparc/include/asm/mman.h</span>
<span class="p_header">+++ b/arch/sparc/include/asm/mman.h</span>
<span class="p_chunk">@@ -7,5 +7,87 @@</span> <span class="p_context"></span>
 #ifndef __ASSEMBLY__
 #define arch_mmap_check(addr,len,flags)	sparc_mmap_check(addr,len)
 int sparc_mmap_check(unsigned long addr, unsigned long len);
<span class="p_del">-#endif</span>
<span class="p_add">+</span>
<span class="p_add">+#ifdef CONFIG_SPARC64</span>
<span class="p_add">+#include &lt;asm/adi_64.h&gt;</span>
<span class="p_add">+</span>
<span class="p_add">+static inline void ipi_set_tstate_mcde(void *arg)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct mm_struct *mm = arg;</span>
<span class="p_add">+</span>
<span class="p_add">+	/* Set TSTATE_MCDE for the task using address map that ADI has been</span>
<span class="p_add">+	 * enabled on if the task is running. If not, it will be set</span>
<span class="p_add">+	 * automatically at the next context switch</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	if (current-&gt;mm == mm) {</span>
<span class="p_add">+		struct pt_regs *regs;</span>
<span class="p_add">+</span>
<span class="p_add">+		regs = task_pt_regs(current);</span>
<span class="p_add">+		regs-&gt;tstate |= TSTATE_MCDE;</span>
<span class="p_add">+	}</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+#define arch_calc_vm_prot_bits(prot, pkey) sparc_calc_vm_prot_bits(prot)</span>
<span class="p_add">+static inline unsigned long sparc_calc_vm_prot_bits(unsigned long prot)</span>
<span class="p_add">+{</span>
<span class="p_add">+	if (adi_capable() &amp;&amp; (prot &amp; PROT_ADI)) {</span>
<span class="p_add">+		struct pt_regs *regs;</span>
<span class="p_add">+</span>
<span class="p_add">+		if (!current-&gt;mm-&gt;context.adi) {</span>
<span class="p_add">+			regs = task_pt_regs(current);</span>
<span class="p_add">+			regs-&gt;tstate |= TSTATE_MCDE;</span>
<span class="p_add">+			current-&gt;mm-&gt;context.adi = true;</span>
<span class="p_add">+			on_each_cpu_mask(mm_cpumask(current-&gt;mm),</span>
<span class="p_add">+					 ipi_set_tstate_mcde, current-&gt;mm, 0);</span>
<span class="p_add">+		}</span>
<span class="p_add">+		return VM_SPARC_ADI;</span>
<span class="p_add">+	} else {</span>
<span class="p_add">+		return 0;</span>
<span class="p_add">+	}</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+#define arch_vm_get_page_prot(vm_flags) sparc_vm_get_page_prot(vm_flags)</span>
<span class="p_add">+static inline pgprot_t sparc_vm_get_page_prot(unsigned long vm_flags)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return (vm_flags &amp; VM_SPARC_ADI) ? __pgprot(_PAGE_MCD_4V) : __pgprot(0);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+#define arch_validate_prot(prot, addr) sparc_validate_prot(prot, addr)</span>
<span class="p_add">+static inline int sparc_validate_prot(unsigned long prot, unsigned long addr)</span>
<span class="p_add">+{</span>
<span class="p_add">+	if (prot &amp; ~(PROT_READ | PROT_WRITE | PROT_EXEC | PROT_SEM | PROT_ADI))</span>
<span class="p_add">+		return 0;</span>
<span class="p_add">+	if (prot &amp; PROT_ADI) {</span>
<span class="p_add">+		if (!adi_capable())</span>
<span class="p_add">+			return 0;</span>
<span class="p_add">+</span>
<span class="p_add">+		if (addr) {</span>
<span class="p_add">+			struct vm_area_struct *vma;</span>
<span class="p_add">+</span>
<span class="p_add">+			vma = find_vma(current-&gt;mm, addr);</span>
<span class="p_add">+			if (vma) {</span>
<span class="p_add">+				/* ADI can not be enabled on PFN</span>
<span class="p_add">+				 * mapped pages</span>
<span class="p_add">+				 */</span>
<span class="p_add">+				if (vma-&gt;vm_flags &amp; (VM_PFNMAP | VM_MIXEDMAP))</span>
<span class="p_add">+					return 0;</span>
<span class="p_add">+</span>
<span class="p_add">+				/* Mergeable pages can become unmergeable</span>
<span class="p_add">+				 * if ADI is enabled on them even if they</span>
<span class="p_add">+				 * have identical data on them. This can be</span>
<span class="p_add">+				 * because ADI enabled pages with identical</span>
<span class="p_add">+				 * data may still not have identical ADI</span>
<span class="p_add">+				 * tags on them. Disallow ADI on mergeable</span>
<span class="p_add">+				 * pages.</span>
<span class="p_add">+				 */</span>
<span class="p_add">+				if (vma-&gt;vm_flags &amp; VM_MERGEABLE)</span>
<span class="p_add">+					return 0;</span>
<span class="p_add">+			}</span>
<span class="p_add">+		}</span>
<span class="p_add">+	}</span>
<span class="p_add">+	return 1;</span>
<span class="p_add">+}</span>
<span class="p_add">+#endif /* CONFIG_SPARC64 */</span>
<span class="p_add">+</span>
<span class="p_add">+#endif /* __ASSEMBLY__ */</span>
 #endif /* __SPARC_MMAN_H__ */
<span class="p_header">diff --git a/arch/sparc/include/asm/mmu_64.h b/arch/sparc/include/asm/mmu_64.h</span>
<span class="p_header">index ad4fb93508ba..7e2704c770e9 100644</span>
<span class="p_header">--- a/arch/sparc/include/asm/mmu_64.h</span>
<span class="p_header">+++ b/arch/sparc/include/asm/mmu_64.h</span>
<span class="p_chunk">@@ -90,6 +90,20 @@</span> <span class="p_context"> struct tsb_config {</span>
 #define MM_NUM_TSBS	1
 #endif
 
<span class="p_add">+/* ADI tags are stored when a page is swapped out and the storage for</span>
<span class="p_add">+ * tags is allocated dynamically. There is a tag storage descriptor</span>
<span class="p_add">+ * associated with each set of tag storage pages. Tag storage descriptors</span>
<span class="p_add">+ * are allocated dynamically. Since kernel will allocate a full page for</span>
<span class="p_add">+ * each tag storage descriptor, we can store up to</span>
<span class="p_add">+ * PAGE_SIZE/sizeof(tag storage descriptor) descriptors on that page.</span>
<span class="p_add">+ */</span>
<span class="p_add">+typedef struct {</span>
<span class="p_add">+	unsigned long	start;		/* Start address for this tag storage */</span>
<span class="p_add">+	unsigned long	end;		/* Last address for tag storage */</span>
<span class="p_add">+	unsigned char	*tags;		/* Where the tags are */</span>
<span class="p_add">+	unsigned long	tag_users;	/* number of references to descriptor */</span>
<span class="p_add">+} tag_storage_desc_t;</span>
<span class="p_add">+</span>
 typedef struct {
 	spinlock_t		lock;
 	unsigned long		sparc64_ctx_val;
<span class="p_chunk">@@ -98,6 +112,9 @@</span> <span class="p_context"> typedef struct {</span>
 	struct tsb_config	tsb_block[MM_NUM_TSBS];
 	struct hv_tsb_descr	tsb_descr[MM_NUM_TSBS];
 	void			*vdso;
<span class="p_add">+	bool			adi;</span>
<span class="p_add">+	tag_storage_desc_t	*tag_store;</span>
<span class="p_add">+	spinlock_t		tag_lock;</span>
 } mm_context_t;
 
 #endif /* !__ASSEMBLY__ */
<span class="p_header">diff --git a/arch/sparc/include/asm/mmu_context_64.h b/arch/sparc/include/asm/mmu_context_64.h</span>
<span class="p_header">index b361702ef52a..d12b35ac46d3 100644</span>
<span class="p_header">--- a/arch/sparc/include/asm/mmu_context_64.h</span>
<span class="p_header">+++ b/arch/sparc/include/asm/mmu_context_64.h</span>
<span class="p_chunk">@@ -11,6 +11,7 @@</span> <span class="p_context"></span>
 #include &lt;linux/smp.h&gt;
 
 #include &lt;asm/spitfire.h&gt;
<span class="p_add">+#include &lt;asm/adi_64.h&gt;</span>
 #include &lt;asm-generic/mm_hooks.h&gt;
 #include &lt;asm/percpu.h&gt;
 
<span class="p_chunk">@@ -136,6 +137,55 @@</span> <span class="p_context"> static inline void switch_mm(struct mm_struct *old_mm, struct mm_struct *mm, str</span>
 
 #define deactivate_mm(tsk,mm)	do { } while (0)
 #define activate_mm(active_mm, mm) switch_mm(active_mm, mm, NULL)
<span class="p_add">+</span>
<span class="p_add">+#define  __HAVE_ARCH_START_CONTEXT_SWITCH</span>
<span class="p_add">+static inline void arch_start_context_switch(struct task_struct *prev)</span>
<span class="p_add">+{</span>
<span class="p_add">+	/* Save the current state of MCDPER register for the process</span>
<span class="p_add">+	 * we are switching from</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	if (adi_capable()) {</span>
<span class="p_add">+		register unsigned long tmp_mcdper;</span>
<span class="p_add">+</span>
<span class="p_add">+		__asm__ __volatile__(</span>
<span class="p_add">+			&quot;.word 0x83438000\n\t&quot;	/* rd  %mcdper, %g1 */</span>
<span class="p_add">+			&quot;mov %%g1, %0\n\t&quot;</span>
<span class="p_add">+			: &quot;=r&quot; (tmp_mcdper)</span>
<span class="p_add">+			:</span>
<span class="p_add">+			: &quot;g1&quot;);</span>
<span class="p_add">+		if (tmp_mcdper)</span>
<span class="p_add">+			set_tsk_thread_flag(prev, TIF_MCDPER);</span>
<span class="p_add">+		else</span>
<span class="p_add">+			clear_tsk_thread_flag(prev, TIF_MCDPER);</span>
<span class="p_add">+	}</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+#define finish_arch_post_lock_switch	finish_arch_post_lock_switch</span>
<span class="p_add">+static inline void finish_arch_post_lock_switch(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	/* Restore the state of MCDPER register for the new process</span>
<span class="p_add">+	 * just switched to.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	if (adi_capable()) {</span>
<span class="p_add">+		register unsigned long tmp_mcdper;</span>
<span class="p_add">+</span>
<span class="p_add">+		tmp_mcdper = test_thread_flag(TIF_MCDPER);</span>
<span class="p_add">+		__asm__ __volatile__(</span>
<span class="p_add">+			&quot;mov %0, %%g1\n\t&quot;</span>
<span class="p_add">+			&quot;.word 0x9d800001\n\t&quot;	/* wr %g0, %g1, %mcdper&quot; */</span>
<span class="p_add">+			&quot;.word 0xaf902001\n\t&quot;	/* wrpr %g0, 1, %pmcdper */</span>
<span class="p_add">+			:</span>
<span class="p_add">+			: &quot;ir&quot; (tmp_mcdper)</span>
<span class="p_add">+			: &quot;g1&quot;);</span>
<span class="p_add">+		if (current &amp;&amp; current-&gt;mm &amp;&amp; current-&gt;mm-&gt;context.adi) {</span>
<span class="p_add">+			struct pt_regs *regs;</span>
<span class="p_add">+</span>
<span class="p_add">+			regs = task_pt_regs(current);</span>
<span class="p_add">+			regs-&gt;tstate |= TSTATE_MCDE;</span>
<span class="p_add">+		}</span>
<span class="p_add">+	}</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 #endif /* !(__ASSEMBLY__) */
 
 #endif /* !(__SPARC64_MMU_CONTEXT_H) */
<span class="p_header">diff --git a/arch/sparc/include/asm/page_64.h b/arch/sparc/include/asm/page_64.h</span>
<span class="p_header">index c28379b1b0fc..e80f2d5bf62f 100644</span>
<span class="p_header">--- a/arch/sparc/include/asm/page_64.h</span>
<span class="p_header">+++ b/arch/sparc/include/asm/page_64.h</span>
<span class="p_chunk">@@ -48,6 +48,12 @@</span> <span class="p_context"> struct page;</span>
 void clear_user_page(void *addr, unsigned long vaddr, struct page *page);
 #define copy_page(X,Y)	memcpy((void *)(X), (void *)(Y), PAGE_SIZE)
 void copy_user_page(void *to, void *from, unsigned long vaddr, struct page *topage);
<span class="p_add">+#define __HAVE_ARCH_COPY_USER_HIGHPAGE</span>
<span class="p_add">+struct vm_area_struct;</span>
<span class="p_add">+void copy_user_highpage(struct page *to, struct page *from,</span>
<span class="p_add">+			unsigned long vaddr, struct vm_area_struct *vma);</span>
<span class="p_add">+#define __HAVE_ARCH_COPY_HIGHPAGE</span>
<span class="p_add">+void copy_highpage(struct page *to, struct page *from);</span>
 
 /* Unlike sparc32, sparc64&#39;s parameter passing API is more
  * sane in that structures which as small enough are passed
<span class="p_header">diff --git a/arch/sparc/include/asm/pgtable_64.h b/arch/sparc/include/asm/pgtable_64.h</span>
<span class="p_header">index 619332a44402..44d6ac47e035 100644</span>
<span class="p_header">--- a/arch/sparc/include/asm/pgtable_64.h</span>
<span class="p_header">+++ b/arch/sparc/include/asm/pgtable_64.h</span>
<span class="p_chunk">@@ -19,6 +19,7 @@</span> <span class="p_context"></span>
 #include &lt;asm/types.h&gt;
 #include &lt;asm/spitfire.h&gt;
 #include &lt;asm/asi.h&gt;
<span class="p_add">+#include &lt;asm/adi.h&gt;</span>
 #include &lt;asm/page.h&gt;
 #include &lt;asm/processor.h&gt;
 
<span class="p_chunk">@@ -606,6 +607,18 @@</span> <span class="p_context"> static inline pte_t pte_mkspecial(pte_t pte)</span>
 	return pte;
 }
 
<span class="p_add">+static inline pte_t pte_mkmcd(pte_t pte)</span>
<span class="p_add">+{</span>
<span class="p_add">+	pte_val(pte) |= _PAGE_MCD_4V;</span>
<span class="p_add">+	return pte;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline pte_t pte_mknotmcd(pte_t pte)</span>
<span class="p_add">+{</span>
<span class="p_add">+	pte_val(pte) &amp;= ~_PAGE_MCD_4V;</span>
<span class="p_add">+	return pte;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static inline unsigned long pte_young(pte_t pte)
 {
 	unsigned long mask;
<span class="p_chunk">@@ -1048,6 +1061,39 @@</span> <span class="p_context"> int page_in_phys_avail(unsigned long paddr);</span>
 int remap_pfn_range(struct vm_area_struct *, unsigned long, unsigned long,
 		    unsigned long, pgprot_t);
 
<span class="p_add">+void adi_restore_tags(struct mm_struct *mm, struct vm_area_struct *vma,</span>
<span class="p_add">+		      unsigned long addr, pte_t pte);</span>
<span class="p_add">+</span>
<span class="p_add">+int adi_save_tags(struct mm_struct *mm, struct vm_area_struct *vma,</span>
<span class="p_add">+		  unsigned long addr, pte_t oldpte);</span>
<span class="p_add">+</span>
<span class="p_add">+#define __HAVE_ARCH_DO_SWAP_PAGE</span>
<span class="p_add">+static inline void arch_do_swap_page(struct mm_struct *mm,</span>
<span class="p_add">+				     struct vm_area_struct *vma,</span>
<span class="p_add">+				     unsigned long addr,</span>
<span class="p_add">+				     pte_t pte, pte_t oldpte)</span>
<span class="p_add">+{</span>
<span class="p_add">+	/* If this is a new page being mapped in, there can be no</span>
<span class="p_add">+	 * ADI tags stored away for this page. Skip looking for</span>
<span class="p_add">+	 * stored tags</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	if (pte_none(oldpte))</span>
<span class="p_add">+		return;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (adi_state.enabled &amp;&amp; (pte_val(pte) &amp; _PAGE_MCD_4V))</span>
<span class="p_add">+		adi_restore_tags(mm, vma, addr, pte);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+#define __HAVE_ARCH_UNMAP_ONE</span>
<span class="p_add">+static inline int arch_unmap_one(struct mm_struct *mm,</span>
<span class="p_add">+				 struct vm_area_struct *vma,</span>
<span class="p_add">+				 unsigned long addr, pte_t oldpte)</span>
<span class="p_add">+{</span>
<span class="p_add">+	if (adi_state.enabled &amp;&amp; (pte_val(oldpte) &amp; _PAGE_MCD_4V))</span>
<span class="p_add">+		return adi_save_tags(mm, vma, addr, oldpte);</span>
<span class="p_add">+	return 0;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static inline int io_remap_pfn_range(struct vm_area_struct *vma,
 				     unsigned long from, unsigned long pfn,
 				     unsigned long size, pgprot_t prot)
<span class="p_header">diff --git a/arch/sparc/include/asm/thread_info_64.h b/arch/sparc/include/asm/thread_info_64.h</span>
<span class="p_header">index f7e7b0baec9f..7fb676360928 100644</span>
<span class="p_header">--- a/arch/sparc/include/asm/thread_info_64.h</span>
<span class="p_header">+++ b/arch/sparc/include/asm/thread_info_64.h</span>
<span class="p_chunk">@@ -188,7 +188,7 @@</span> <span class="p_context"> register struct thread_info *current_thread_info_reg asm(&quot;g6&quot;);</span>
  *       in using in assembly, else we can&#39;t use the mask as
  *       an immediate value in instructions such as andcc.
  */
<span class="p_del">-/* flag bit 12 is available */</span>
<span class="p_add">+#define TIF_MCDPER		12	/* Precise MCD exception */</span>
 #define TIF_MEMDIE		13	/* is terminating due to OOM killer */
 #define TIF_POLLING_NRFLAG	14
 
<span class="p_header">diff --git a/arch/sparc/include/asm/trap_block.h b/arch/sparc/include/asm/trap_block.h</span>
<span class="p_header">index 6a4c8652ad67..0f6d0c4f6683 100644</span>
<span class="p_header">--- a/arch/sparc/include/asm/trap_block.h</span>
<span class="p_header">+++ b/arch/sparc/include/asm/trap_block.h</span>
<span class="p_chunk">@@ -76,6 +76,8 @@</span> <span class="p_context"> extern struct sun4v_1insn_patch_entry __sun4v_1insn_patch,</span>
 	__sun4v_1insn_patch_end;
 extern struct sun4v_1insn_patch_entry __fast_win_ctrl_1insn_patch,
 	__fast_win_ctrl_1insn_patch_end;
<span class="p_add">+extern struct sun4v_1insn_patch_entry __sun_m7_1insn_patch,</span>
<span class="p_add">+	__sun_m7_1insn_patch_end;</span>
 
 struct sun4v_2insn_patch_entry {
 	unsigned int	addr;
<span class="p_header">diff --git a/arch/sparc/include/uapi/asm/mman.h b/arch/sparc/include/uapi/asm/mman.h</span>
<span class="p_header">index 715a2c927e79..f6f99ec65bb3 100644</span>
<span class="p_header">--- a/arch/sparc/include/uapi/asm/mman.h</span>
<span class="p_header">+++ b/arch/sparc/include/uapi/asm/mman.h</span>
<span class="p_chunk">@@ -6,6 +6,8 @@</span> <span class="p_context"></span>
 
 /* SunOS&#39;ified... */
 
<span class="p_add">+#define PROT_ADI	0x10		/* ADI enabled */</span>
<span class="p_add">+</span>
 #define MAP_RENAME      MAP_ANONYMOUS   /* In SunOS terminology */
 #define MAP_NORESERVE   0x40            /* don&#39;t reserve swap pages */
 #define MAP_INHERIT     0x80            /* SunOS doesn&#39;t do this, but... */
<span class="p_header">diff --git a/arch/sparc/kernel/adi_64.c b/arch/sparc/kernel/adi_64.c</span>
<span class="p_header">index 8fb72585d9f1..d0a2ac975b42 100644</span>
<span class="p_header">--- a/arch/sparc/kernel/adi_64.c</span>
<span class="p_header">+++ b/arch/sparc/kernel/adi_64.c</span>
<span class="p_chunk">@@ -8,10 +8,24 @@</span> <span class="p_context"></span>
  * This work is licensed under the terms of the GNU GPL, version 2.
  */
 #include &lt;linux/init.h&gt;
<span class="p_add">+#include &lt;linux/slab.h&gt;</span>
<span class="p_add">+#include &lt;linux/mm_types.h&gt;</span>
 #include &lt;asm/mdesc.h&gt;
 #include &lt;asm/adi_64.h&gt;
<span class="p_add">+#include &lt;asm/mmu_64.h&gt;</span>
<span class="p_add">+#include &lt;asm/pgtable_64.h&gt;</span>
<span class="p_add">+</span>
<span class="p_add">+/* Each page of storage for ADI tags can accommodate tags for 128</span>
<span class="p_add">+ * pages. When ADI enabled pages are being swapped out, it would be</span>
<span class="p_add">+ * prudent to allocate at least enough tag storage space to accommodate</span>
<span class="p_add">+ * SWAPFILE_CLUSTER number of pages. Allocate enough tag storage to</span>
<span class="p_add">+ * store tags for four SWAPFILE_CLUSTER pages to reduce need for</span>
<span class="p_add">+ * further allocations for same vma.</span>
<span class="p_add">+ */</span>
<span class="p_add">+#define TAG_STORAGE_PAGES	8</span>
 
 struct adi_config adi_state;
<span class="p_add">+EXPORT_SYMBOL(adi_state);</span>
 
 /* mdesc_adi_init() : Parse machine description provided by the
  *	hypervisor to detect ADI capabilities
<span class="p_chunk">@@ -84,6 +98,19 @@</span> <span class="p_context"> void __init mdesc_adi_init(void)</span>
 		goto adi_not_found;
 	adi_state.caps.ue_on_adi = *val;
 
<span class="p_add">+	/* Some of the code to support swapping ADI tags is written</span>
<span class="p_add">+	 * assumption that two ADI tags can fit inside one byte. If</span>
<span class="p_add">+	 * this assumption is broken by a future architecture change,</span>
<span class="p_add">+	 * that code will have to be revisited. If that were to happen,</span>
<span class="p_add">+	 * disable ADI support so we do not get unpredictable results</span>
<span class="p_add">+	 * with programs trying to use ADI and their pages getting</span>
<span class="p_add">+	 * swapped out</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	if (adi_state.caps.nbits &gt; 4) {</span>
<span class="p_add">+		pr_warn(&quot;WARNING: ADI tag size &gt;4 on this platform. Disabling AADI support\n&quot;);</span>
<span class="p_add">+		adi_state.enabled = false;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
 	mdesc_release(hp);
 	return;
 
<span class="p_chunk">@@ -94,3 +121,277 @@</span> <span class="p_context"> void __init mdesc_adi_init(void)</span>
 	if (hp)
 		mdesc_release(hp);
 }
<span class="p_add">+</span>
<span class="p_add">+tag_storage_desc_t *find_tag_store(struct mm_struct *mm,</span>
<span class="p_add">+				   struct vm_area_struct *vma,</span>
<span class="p_add">+				   unsigned long addr)</span>
<span class="p_add">+{</span>
<span class="p_add">+	tag_storage_desc_t *tag_desc = NULL;</span>
<span class="p_add">+	unsigned long i, max_desc, flags;</span>
<span class="p_add">+</span>
<span class="p_add">+	/* Check if this vma already has tag storage descriptor</span>
<span class="p_add">+	 * allocated for it.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	max_desc = PAGE_SIZE/sizeof(tag_storage_desc_t);</span>
<span class="p_add">+	if (mm-&gt;context.tag_store) {</span>
<span class="p_add">+		tag_desc = mm-&gt;context.tag_store;</span>
<span class="p_add">+		spin_lock_irqsave(&amp;mm-&gt;context.tag_lock, flags);</span>
<span class="p_add">+		for (i = 0; i &lt; max_desc; i++) {</span>
<span class="p_add">+			if ((addr &gt;= tag_desc-&gt;start) &amp;&amp;</span>
<span class="p_add">+			    ((addr + PAGE_SIZE - 1) &lt;= tag_desc-&gt;end))</span>
<span class="p_add">+				break;</span>
<span class="p_add">+			tag_desc++;</span>
<span class="p_add">+		}</span>
<span class="p_add">+		spin_unlock_irqrestore(&amp;mm-&gt;context.tag_lock, flags);</span>
<span class="p_add">+</span>
<span class="p_add">+		/* If no matching entries were found, this must be a</span>
<span class="p_add">+		 * freshly allocated page</span>
<span class="p_add">+		 */</span>
<span class="p_add">+		if (i &gt;= max_desc)</span>
<span class="p_add">+			tag_desc = NULL;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	return tag_desc;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+tag_storage_desc_t *alloc_tag_store(struct mm_struct *mm,</span>
<span class="p_add">+				    struct vm_area_struct *vma,</span>
<span class="p_add">+				    unsigned long addr)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned char *tags;</span>
<span class="p_add">+	unsigned long i, size, max_desc, flags;</span>
<span class="p_add">+	tag_storage_desc_t *tag_desc, *open_desc;</span>
<span class="p_add">+	unsigned long end_addr, hole_start, hole_end;</span>
<span class="p_add">+</span>
<span class="p_add">+	max_desc = PAGE_SIZE/sizeof(tag_storage_desc_t);</span>
<span class="p_add">+	open_desc = NULL;</span>
<span class="p_add">+	hole_start = 0;</span>
<span class="p_add">+	hole_end = ULONG_MAX;</span>
<span class="p_add">+	end_addr = addr + PAGE_SIZE - 1;</span>
<span class="p_add">+</span>
<span class="p_add">+	/* Check if this vma already has tag storage descriptor</span>
<span class="p_add">+	 * allocated for it.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	spin_lock_irqsave(&amp;mm-&gt;context.tag_lock, flags);</span>
<span class="p_add">+	if (mm-&gt;context.tag_store) {</span>
<span class="p_add">+		tag_desc = mm-&gt;context.tag_store;</span>
<span class="p_add">+</span>
<span class="p_add">+		/* Look for a matching entry for this address. While doing</span>
<span class="p_add">+		 * that, look for the first open slot as well and find</span>
<span class="p_add">+		 * the hole in already allocated range where this request</span>
<span class="p_add">+		 * will fit in.</span>
<span class="p_add">+		 */</span>
<span class="p_add">+		for (i = 0; i &lt; max_desc; i++) {</span>
<span class="p_add">+			if (tag_desc-&gt;tag_users == 0) {</span>
<span class="p_add">+				if (open_desc == NULL)</span>
<span class="p_add">+					open_desc = tag_desc;</span>
<span class="p_add">+			} else {</span>
<span class="p_add">+				if ((addr &gt;= tag_desc-&gt;start) &amp;&amp;</span>
<span class="p_add">+				    (tag_desc-&gt;end &gt;= (addr + PAGE_SIZE - 1))) {</span>
<span class="p_add">+					tag_desc-&gt;tag_users++;</span>
<span class="p_add">+					goto out;</span>
<span class="p_add">+				}</span>
<span class="p_add">+			}</span>
<span class="p_add">+			if ((tag_desc-&gt;start &gt; end_addr) &amp;&amp;</span>
<span class="p_add">+			    (tag_desc-&gt;start &lt; hole_end))</span>
<span class="p_add">+				hole_end = tag_desc-&gt;start;</span>
<span class="p_add">+			if ((tag_desc-&gt;end &lt; addr) &amp;&amp;</span>
<span class="p_add">+			    (tag_desc-&gt;end &gt; hole_start))</span>
<span class="p_add">+				hole_start = tag_desc-&gt;end;</span>
<span class="p_add">+			tag_desc++;</span>
<span class="p_add">+		}</span>
<span class="p_add">+</span>
<span class="p_add">+	} else {</span>
<span class="p_add">+		size = sizeof(tag_storage_desc_t)*max_desc;</span>
<span class="p_add">+		mm-&gt;context.tag_store = kzalloc(size, GFP_NOWAIT|__GFP_NOWARN);</span>
<span class="p_add">+		if (mm-&gt;context.tag_store == NULL) {</span>
<span class="p_add">+			tag_desc = NULL;</span>
<span class="p_add">+			goto out;</span>
<span class="p_add">+		}</span>
<span class="p_add">+		tag_desc = mm-&gt;context.tag_store;</span>
<span class="p_add">+		for (i = 0; i &lt; max_desc; i++, tag_desc++)</span>
<span class="p_add">+			tag_desc-&gt;tag_users = 0;</span>
<span class="p_add">+		open_desc = mm-&gt;context.tag_store;</span>
<span class="p_add">+		i = 0;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	/* Check if we ran out of tag storage descriptors */</span>
<span class="p_add">+	if (open_desc == NULL) {</span>
<span class="p_add">+		tag_desc = NULL;</span>
<span class="p_add">+		goto out;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	/* Mark this tag descriptor slot in use and then initialize it */</span>
<span class="p_add">+	tag_desc = open_desc;</span>
<span class="p_add">+	tag_desc-&gt;tag_users = 1;</span>
<span class="p_add">+</span>
<span class="p_add">+	/* Tag storage has not been allocated for this vma and space</span>
<span class="p_add">+	 * is available in tag storage descriptor. Since this page is</span>
<span class="p_add">+	 * being swapped out, there is high probability subsequent pages</span>
<span class="p_add">+	 * in the VMA will be swapped out as well. Allocate pages to</span>
<span class="p_add">+	 * store tags for as many pages in this vma as possible but not</span>
<span class="p_add">+	 * more than TAG_STORAGE_PAGES. Each byte in tag space holds</span>
<span class="p_add">+	 * two ADI tags since each ADI tag is 4 bits. Each ADI tag</span>
<span class="p_add">+	 * covers adi_blksize() worth of addresses. Check if the hole is</span>
<span class="p_add">+	 * big enough to accommodate full address range for using</span>
<span class="p_add">+	 * TAG_STORAGE_PAGES number of tag pages.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	size = TAG_STORAGE_PAGES * PAGE_SIZE;</span>
<span class="p_add">+	end_addr = addr + (size*2*adi_blksize()) - 1;</span>
<span class="p_add">+	/* Check for overflow. If overflow occurs, allocate only one page */</span>
<span class="p_add">+	if (end_addr &lt; addr) {</span>
<span class="p_add">+		size = PAGE_SIZE;</span>
<span class="p_add">+		end_addr = addr + (size*2*adi_blksize()) - 1;</span>
<span class="p_add">+		/* If overflow happens with the minimum tag storage</span>
<span class="p_add">+		 * allocation as well, adjust ending address for this</span>
<span class="p_add">+		 * tag storage.</span>
<span class="p_add">+		 */</span>
<span class="p_add">+		if (end_addr &lt; addr)</span>
<span class="p_add">+			end_addr = ULONG_MAX;</span>
<span class="p_add">+	}</span>
<span class="p_add">+	if (hole_end &lt; end_addr) {</span>
<span class="p_add">+		/* Available hole is too small on the upper end of</span>
<span class="p_add">+		 * address. Can we expand the range towards the lower</span>
<span class="p_add">+		 * address and maximize use of this slot?</span>
<span class="p_add">+		 */</span>
<span class="p_add">+		unsigned long tmp_addr;</span>
<span class="p_add">+</span>
<span class="p_add">+		end_addr = hole_end - 1;</span>
<span class="p_add">+		tmp_addr = end_addr - (size*2*adi_blksize()) + 1;</span>
<span class="p_add">+		/* Check for underflow. If underflow occurs, allocate</span>
<span class="p_add">+		 * only one page for storing ADI tags</span>
<span class="p_add">+		 */</span>
<span class="p_add">+		if (tmp_addr &gt; addr) {</span>
<span class="p_add">+			size = PAGE_SIZE;</span>
<span class="p_add">+			tmp_addr = end_addr - (size*2*adi_blksize()) - 1;</span>
<span class="p_add">+			/* If underflow happens with the minimum tag storage</span>
<span class="p_add">+			 * allocation as well, adjust starting address for</span>
<span class="p_add">+			 * this tag storage.</span>
<span class="p_add">+			 */</span>
<span class="p_add">+			if (tmp_addr &gt; addr)</span>
<span class="p_add">+				tmp_addr = 0;</span>
<span class="p_add">+		}</span>
<span class="p_add">+		if (tmp_addr &lt; hole_start) {</span>
<span class="p_add">+			/* Available hole is restricted on lower address</span>
<span class="p_add">+			 * end as well</span>
<span class="p_add">+			 */</span>
<span class="p_add">+			tmp_addr = hole_start + 1;</span>
<span class="p_add">+		}</span>
<span class="p_add">+		addr = tmp_addr;</span>
<span class="p_add">+		size = (end_addr + 1 - addr)/(2*adi_blksize());</span>
<span class="p_add">+		size = (size + (PAGE_SIZE-adi_blksize()))/PAGE_SIZE;</span>
<span class="p_add">+		size = size * PAGE_SIZE;</span>
<span class="p_add">+	}</span>
<span class="p_add">+	tags = kzalloc(size, GFP_NOWAIT|__GFP_NOWARN);</span>
<span class="p_add">+	if (tags == NULL) {</span>
<span class="p_add">+		tag_desc-&gt;tag_users = 0;</span>
<span class="p_add">+		tag_desc = NULL;</span>
<span class="p_add">+		goto out;</span>
<span class="p_add">+	}</span>
<span class="p_add">+	tag_desc-&gt;start = addr;</span>
<span class="p_add">+	tag_desc-&gt;tags = tags;</span>
<span class="p_add">+	tag_desc-&gt;end = end_addr;</span>
<span class="p_add">+</span>
<span class="p_add">+out:</span>
<span class="p_add">+	spin_unlock_irqrestore(&amp;mm-&gt;context.tag_lock, flags);</span>
<span class="p_add">+	return tag_desc;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void del_tag_store(tag_storage_desc_t *tag_desc, struct mm_struct *mm)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long flags;</span>
<span class="p_add">+	unsigned char *tags = NULL;</span>
<span class="p_add">+</span>
<span class="p_add">+	spin_lock_irqsave(&amp;mm-&gt;context.tag_lock, flags);</span>
<span class="p_add">+	tag_desc-&gt;tag_users--;</span>
<span class="p_add">+	if (tag_desc-&gt;tag_users == 0) {</span>
<span class="p_add">+		tag_desc-&gt;start = tag_desc-&gt;end = 0;</span>
<span class="p_add">+		/* Do not free up the tag storage space allocated</span>
<span class="p_add">+		 * by the first descriptor. This is persistent</span>
<span class="p_add">+		 * emergency tag storage space for the task.</span>
<span class="p_add">+		 */</span>
<span class="p_add">+		if (tag_desc != mm-&gt;context.tag_store) {</span>
<span class="p_add">+			tags = tag_desc-&gt;tags;</span>
<span class="p_add">+			tag_desc-&gt;tags = NULL;</span>
<span class="p_add">+		}</span>
<span class="p_add">+	}</span>
<span class="p_add">+	spin_unlock_irqrestore(&amp;mm-&gt;context.tag_lock, flags);</span>
<span class="p_add">+	kfree(tags);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+#define tag_start(addr, tag_desc)		\</span>
<span class="p_add">+	((tag_desc)-&gt;tags + ((addr - (tag_desc)-&gt;start)/(2*adi_blksize())))</span>
<span class="p_add">+</span>
<span class="p_add">+/* Retrieve any saved ADI tags for the page being swapped back in and</span>
<span class="p_add">+ * restore these tags to the newly allocated physical page.</span>
<span class="p_add">+ */</span>
<span class="p_add">+void adi_restore_tags(struct mm_struct *mm, struct vm_area_struct *vma,</span>
<span class="p_add">+		      unsigned long addr, pte_t pte)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned char *tag;</span>
<span class="p_add">+	tag_storage_desc_t *tag_desc;</span>
<span class="p_add">+	unsigned long paddr, tmp, version1, version2;</span>
<span class="p_add">+</span>
<span class="p_add">+	/* Check if the swapped out page has an ADI version</span>
<span class="p_add">+	 * saved. If yes, restore version tag to the newly</span>
<span class="p_add">+	 * allocated page.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	tag_desc = find_tag_store(mm, vma, addr);</span>
<span class="p_add">+	if (tag_desc == NULL)</span>
<span class="p_add">+		return;</span>
<span class="p_add">+</span>
<span class="p_add">+	tag = tag_start(addr, tag_desc);</span>
<span class="p_add">+	paddr = pte_val(pte) &amp; _PAGE_PADDR_4V;</span>
<span class="p_add">+	for (tmp = paddr; tmp &lt; (paddr+PAGE_SIZE); tmp += adi_blksize()) {</span>
<span class="p_add">+		version1 = (*tag) &gt;&gt; 4;</span>
<span class="p_add">+		version2 = (*tag) &amp; 0x0f;</span>
<span class="p_add">+		*tag++ = 0;</span>
<span class="p_add">+		asm volatile(&quot;stxa %0, [%1] %2\n\t&quot;</span>
<span class="p_add">+			:</span>
<span class="p_add">+			: &quot;r&quot; (version1), &quot;r&quot; (tmp),</span>
<span class="p_add">+			  &quot;i&quot; (ASI_MCD_REAL));</span>
<span class="p_add">+		tmp += adi_blksize();</span>
<span class="p_add">+		asm volatile(&quot;stxa %0, [%1] %2\n\t&quot;</span>
<span class="p_add">+			:</span>
<span class="p_add">+			: &quot;r&quot; (version2), &quot;r&quot; (tmp),</span>
<span class="p_add">+			  &quot;i&quot; (ASI_MCD_REAL));</span>
<span class="p_add">+	}</span>
<span class="p_add">+	asm volatile(&quot;membar #Sync\n\t&quot;);</span>
<span class="p_add">+</span>
<span class="p_add">+	/* Check and mark this tag space for release later if</span>
<span class="p_add">+	 * the swapped in page was the last user of tag space</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	del_tag_store(tag_desc, mm);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+/* A page is about to be swapped out. Save any ADI tags associated with</span>
<span class="p_add">+ * this physical page so they can be restored later when the page is swapped</span>
<span class="p_add">+ * back in.</span>
<span class="p_add">+ */</span>
<span class="p_add">+int adi_save_tags(struct mm_struct *mm, struct vm_area_struct *vma,</span>
<span class="p_add">+		  unsigned long addr, pte_t oldpte)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned char *tag;</span>
<span class="p_add">+	tag_storage_desc_t *tag_desc;</span>
<span class="p_add">+	unsigned long version1, version2, paddr, tmp;</span>
<span class="p_add">+</span>
<span class="p_add">+	tag_desc = alloc_tag_store(mm, vma, addr);</span>
<span class="p_add">+	if (tag_desc == NULL)</span>
<span class="p_add">+		return -1;</span>
<span class="p_add">+</span>
<span class="p_add">+	tag = tag_start(addr, tag_desc);</span>
<span class="p_add">+	paddr = pte_val(oldpte) &amp; _PAGE_PADDR_4V;</span>
<span class="p_add">+	for (tmp = paddr; tmp &lt; (paddr+PAGE_SIZE); tmp += adi_blksize()) {</span>
<span class="p_add">+		asm volatile(&quot;ldxa [%1] %2, %0\n\t&quot;</span>
<span class="p_add">+				: &quot;=r&quot; (version1)</span>
<span class="p_add">+				: &quot;r&quot; (tmp), &quot;i&quot; (ASI_MCD_REAL));</span>
<span class="p_add">+		tmp += adi_blksize();</span>
<span class="p_add">+		asm volatile(&quot;ldxa [%1] %2, %0\n\t&quot;</span>
<span class="p_add">+				: &quot;=r&quot; (version2)</span>
<span class="p_add">+				: &quot;r&quot; (tmp), &quot;i&quot; (ASI_MCD_REAL));</span>
<span class="p_add">+		*tag = (version1 &lt;&lt; 4) | version2;</span>
<span class="p_add">+		tag++;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	return 0;</span>
<span class="p_add">+}</span>
<span class="p_header">diff --git a/arch/sparc/kernel/etrap_64.S b/arch/sparc/kernel/etrap_64.S</span>
<span class="p_header">index 5c77a2e0e991..08cc41f64725 100644</span>
<span class="p_header">--- a/arch/sparc/kernel/etrap_64.S</span>
<span class="p_header">+++ b/arch/sparc/kernel/etrap_64.S</span>
<span class="p_chunk">@@ -151,7 +151,32 @@</span> <span class="p_context"> etrap_save:	save	%g2, -STACK_BIAS, %sp</span>
 		stx	%g6, [%sp + PTREGS_OFF + PT_V9_G6]
 		stx	%g7, [%sp + PTREGS_OFF + PT_V9_G7]
 		or	%l7, %l0, %l7
<span class="p_del">-		sethi	%hi(TSTATE_TSO | TSTATE_PEF), %l0</span>
<span class="p_add">+661:		sethi	%hi(TSTATE_TSO | TSTATE_PEF), %l0</span>
<span class="p_add">+		/* If userspace is using ADI, it could potentially pass</span>
<span class="p_add">+		 * a pointer with version tag embedded in it. To maintain</span>
<span class="p_add">+		 * the ADI security, we must enable PSTATE.mcde. Userspace</span>
<span class="p_add">+		 * would have already set TTE.mcd in an earlier call to</span>
<span class="p_add">+		 * kernel and set the version tag for the address being</span>
<span class="p_add">+		 * dereferenced. Setting PSTATE.mcde would ensure any</span>
<span class="p_add">+		 * access to userspace data through a system call honors</span>
<span class="p_add">+		 * ADI and does not allow a rogue app to bypass ADI by</span>
<span class="p_add">+		 * using system calls. Setting PSTATE.mcde only affects</span>
<span class="p_add">+		 * accesses to virtual addresses that have TTE.mcd set.</span>
<span class="p_add">+		 * Set PMCDPER to ensure any exceptions caused by ADI</span>
<span class="p_add">+		 * version tag mismatch are exposed before system call</span>
<span class="p_add">+		 * returns to userspace. Setting PMCDPER affects only</span>
<span class="p_add">+		 * writes to virtual addresses that have TTE.mcd set and</span>
<span class="p_add">+		 * have a version tag set as well.</span>
<span class="p_add">+		 */</span>
<span class="p_add">+		.section .sun_m7_1insn_patch, &quot;ax&quot;</span>
<span class="p_add">+		.word	661b</span>
<span class="p_add">+		sethi	%hi(TSTATE_TSO | TSTATE_PEF | TSTATE_MCDE), %l0</span>
<span class="p_add">+		.previous</span>
<span class="p_add">+661:		nop</span>
<span class="p_add">+		.section .sun_m7_1insn_patch, &quot;ax&quot;</span>
<span class="p_add">+		.word	661b</span>
<span class="p_add">+		.word 0xaf902001	/* wrpr %g0, 1, %pmcdper */</span>
<span class="p_add">+		.previous</span>
 		or	%l7, %l0, %l7
 		wrpr	%l2, %tnpc
 		wrpr	%l7, (TSTATE_PRIV | TSTATE_IE), %tstate
<span class="p_header">diff --git a/arch/sparc/kernel/process_64.c b/arch/sparc/kernel/process_64.c</span>
<span class="p_header">index 318efd784a0b..454a8af28f13 100644</span>
<span class="p_header">--- a/arch/sparc/kernel/process_64.c</span>
<span class="p_header">+++ b/arch/sparc/kernel/process_64.c</span>
<span class="p_chunk">@@ -670,6 +670,31 @@</span> <span class="p_context"> int copy_thread(unsigned long clone_flags, unsigned long sp,</span>
 	return 0;
 }
 
<span class="p_add">+/* TIF_MCDPER in thread info flags for current task is updated lazily upon</span>
<span class="p_add">+ * a context switch. Update this flag in current task&#39;s thread flags</span>
<span class="p_add">+ * before dup so the dup&#39;d task will inherit the current TIF_MCDPER flag.</span>
<span class="p_add">+ */</span>
<span class="p_add">+int arch_dup_task_struct(struct task_struct *dst, struct task_struct *src)</span>
<span class="p_add">+{</span>
<span class="p_add">+	if (adi_capable()) {</span>
<span class="p_add">+		register unsigned long tmp_mcdper;</span>
<span class="p_add">+</span>
<span class="p_add">+		__asm__ __volatile__(</span>
<span class="p_add">+			&quot;.word 0x83438000\n\t&quot;	/* rd  %mcdper, %g1 */</span>
<span class="p_add">+			&quot;mov %%g1, %0\n\t&quot;</span>
<span class="p_add">+			: &quot;=r&quot; (tmp_mcdper)</span>
<span class="p_add">+			:</span>
<span class="p_add">+			: &quot;g1&quot;);</span>
<span class="p_add">+		if (tmp_mcdper)</span>
<span class="p_add">+			set_thread_flag(TIF_MCDPER);</span>
<span class="p_add">+		else</span>
<span class="p_add">+			clear_thread_flag(TIF_MCDPER);</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	*dst = *src;</span>
<span class="p_add">+	return 0;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 typedef struct {
 	union {
 		unsigned int	pr_regs[32];
<span class="p_header">diff --git a/arch/sparc/kernel/rtrap_64.S b/arch/sparc/kernel/rtrap_64.S</span>
<span class="p_header">index 0b21042ab181..f6528884a2c8 100644</span>
<span class="p_header">--- a/arch/sparc/kernel/rtrap_64.S</span>
<span class="p_header">+++ b/arch/sparc/kernel/rtrap_64.S</span>
<span class="p_chunk">@@ -25,13 +25,31 @@</span> <span class="p_context"></span>
 		.align			32
 __handle_preemption:
 		call			SCHEDULE_USER
<span class="p_del">-		 wrpr			%g0, RTRAP_PSTATE, %pstate</span>
<span class="p_add">+661:		 wrpr			%g0, RTRAP_PSTATE, %pstate</span>
<span class="p_add">+		/* If userspace is using ADI, it could potentially pass</span>
<span class="p_add">+		 * a pointer with version tag embedded in it. To maintain</span>
<span class="p_add">+		 * the ADI security, we must re-enable PSTATE.mcde before</span>
<span class="p_add">+		 * we continue execution in the kernel for another thread.</span>
<span class="p_add">+		 */</span>
<span class="p_add">+		.section .sun_m7_1insn_patch, &quot;ax&quot;</span>
<span class="p_add">+		.word	661b</span>
<span class="p_add">+		 wrpr			%g0, RTRAP_PSTATE|PSTATE_MCDE, %pstate</span>
<span class="p_add">+		.previous</span>
 		ba,pt			%xcc, __handle_preemption_continue
 		 wrpr			%g0, RTRAP_PSTATE_IRQOFF, %pstate
 
 __handle_user_windows:
 		call			fault_in_user_windows
<span class="p_del">-		 wrpr			%g0, RTRAP_PSTATE, %pstate</span>
<span class="p_add">+661:		 wrpr			%g0, RTRAP_PSTATE, %pstate</span>
<span class="p_add">+		/* If userspace is using ADI, it could potentially pass</span>
<span class="p_add">+		 * a pointer with version tag embedded in it. To maintain</span>
<span class="p_add">+		 * the ADI security, we must re-enable PSTATE.mcde before</span>
<span class="p_add">+		 * we continue execution in the kernel for another thread.</span>
<span class="p_add">+		 */</span>
<span class="p_add">+		.section .sun_m7_1insn_patch, &quot;ax&quot;</span>
<span class="p_add">+		.word	661b</span>
<span class="p_add">+		 wrpr			%g0, RTRAP_PSTATE|PSTATE_MCDE, %pstate</span>
<span class="p_add">+		.previous</span>
 		ba,pt			%xcc, __handle_preemption_continue
 		 wrpr			%g0, RTRAP_PSTATE_IRQOFF, %pstate
 
<span class="p_chunk">@@ -48,7 +66,16 @@</span> <span class="p_context"> __handle_signal:</span>
 		add			%sp, PTREGS_OFF, %o0
 		mov			%l0, %o2
 		call			do_notify_resume
<span class="p_del">-		 wrpr			%g0, RTRAP_PSTATE, %pstate</span>
<span class="p_add">+661:		 wrpr			%g0, RTRAP_PSTATE, %pstate</span>
<span class="p_add">+		/* If userspace is using ADI, it could potentially pass</span>
<span class="p_add">+		 * a pointer with version tag embedded in it. To maintain</span>
<span class="p_add">+		 * the ADI security, we must re-enable PSTATE.mcde before</span>
<span class="p_add">+		 * we continue execution in the kernel for another thread.</span>
<span class="p_add">+		 */</span>
<span class="p_add">+		.section .sun_m7_1insn_patch, &quot;ax&quot;</span>
<span class="p_add">+		.word	661b</span>
<span class="p_add">+		 wrpr			%g0, RTRAP_PSTATE|PSTATE_MCDE, %pstate</span>
<span class="p_add">+		.previous</span>
 		wrpr			%g0, RTRAP_PSTATE_IRQOFF, %pstate
 
 		/* Signal delivery can modify pt_regs tstate, so we must
<span class="p_header">diff --git a/arch/sparc/kernel/setup_64.c b/arch/sparc/kernel/setup_64.c</span>
<span class="p_header">index 34f7a533a74f..7944b3ca216a 100644</span>
<span class="p_header">--- a/arch/sparc/kernel/setup_64.c</span>
<span class="p_header">+++ b/arch/sparc/kernel/setup_64.c</span>
<span class="p_chunk">@@ -294,6 +294,8 @@</span> <span class="p_context"> static void __init sun4v_patch(void)</span>
 	case SUN4V_CHIP_SPARC_M7:
 	case SUN4V_CHIP_SPARC_M8:
 	case SUN4V_CHIP_SPARC_SN:
<span class="p_add">+		sun4v_patch_1insn_range(&amp;__sun_m7_1insn_patch,</span>
<span class="p_add">+					&amp;__sun_m7_1insn_patch_end);</span>
 		sun_m7_patch_2insn_range(&amp;__sun_m7_2insn_patch,
 					 &amp;__sun_m7_2insn_patch_end);
 		break;
<span class="p_header">diff --git a/arch/sparc/kernel/urtt_fill.S b/arch/sparc/kernel/urtt_fill.S</span>
<span class="p_header">index 44183aa59168..e4cee7be5cd0 100644</span>
<span class="p_header">--- a/arch/sparc/kernel/urtt_fill.S</span>
<span class="p_header">+++ b/arch/sparc/kernel/urtt_fill.S</span>
<span class="p_chunk">@@ -50,7 +50,12 @@</span> <span class="p_context"> user_rtt_fill_fixup_common:</span>
 		SET_GL(0)
 		.previous
 
<span class="p_del">-		wrpr	%g0, RTRAP_PSTATE, %pstate</span>
<span class="p_add">+661:		wrpr	%g0, RTRAP_PSTATE, %pstate</span>
<span class="p_add">+		.section		.sun_m7_1insn_patch, &quot;ax&quot;</span>
<span class="p_add">+		.word			661b</span>
<span class="p_add">+		/* Re-enable PSTATE.mcde to maintain ADI security */</span>
<span class="p_add">+		wrpr	%g0, RTRAP_PSTATE|PSTATE_MCDE, %pstate</span>
<span class="p_add">+		.previous</span>
 
 		mov	%l1, %g6
 		ldx	[%g6 + TI_TASK], %g4
<span class="p_header">diff --git a/arch/sparc/kernel/vmlinux.lds.S b/arch/sparc/kernel/vmlinux.lds.S</span>
<span class="p_header">index 5a2344574f39..61afd787bd0c 100644</span>
<span class="p_header">--- a/arch/sparc/kernel/vmlinux.lds.S</span>
<span class="p_header">+++ b/arch/sparc/kernel/vmlinux.lds.S</span>
<span class="p_chunk">@@ -145,6 +145,11 @@</span> <span class="p_context"> SECTIONS</span>
 		*(.pause_3insn_patch)
 		__pause_3insn_patch_end = .;
 	}
<span class="p_add">+	.sun_m7_1insn_patch : {</span>
<span class="p_add">+		__sun_m7_1insn_patch = .;</span>
<span class="p_add">+		*(.sun_m7_1insn_patch)</span>
<span class="p_add">+		__sun_m7_1insn_patch_end = .;</span>
<span class="p_add">+	}</span>
 	.sun_m7_2insn_patch : {
 		__sun_m7_2insn_patch = .;
 		*(.sun_m7_2insn_patch)
<span class="p_header">diff --git a/arch/sparc/mm/gup.c b/arch/sparc/mm/gup.c</span>
<span class="p_header">index 5335ba3c850e..357b6047653a 100644</span>
<span class="p_header">--- a/arch/sparc/mm/gup.c</span>
<span class="p_header">+++ b/arch/sparc/mm/gup.c</span>
<span class="p_chunk">@@ -12,6 +12,7 @@</span> <span class="p_context"></span>
 #include &lt;linux/pagemap.h&gt;
 #include &lt;linux/rwsem.h&gt;
 #include &lt;asm/pgtable.h&gt;
<span class="p_add">+#include &lt;asm/adi.h&gt;</span>
 
 /*
  * The performance critical leaf functions are made noinline otherwise gcc
<span class="p_chunk">@@ -201,6 +202,24 @@</span> <span class="p_context"> int __get_user_pages_fast(unsigned long start, int nr_pages, int write,</span>
 	pgd_t *pgdp;
 	int nr = 0;
 
<span class="p_add">+#ifdef CONFIG_SPARC64</span>
<span class="p_add">+	if (adi_capable()) {</span>
<span class="p_add">+		long addr = start;</span>
<span class="p_add">+</span>
<span class="p_add">+		/* If userspace has passed a versioned address, kernel</span>
<span class="p_add">+		 * will not find it in the VMAs since it does not store</span>
<span class="p_add">+		 * the version tags in the list of VMAs. Storing version</span>
<span class="p_add">+		 * tags in list of VMAs is impractical since they can be</span>
<span class="p_add">+		 * changed any time from userspace without dropping into</span>
<span class="p_add">+		 * kernel. Any address search in VMAs will be done with</span>
<span class="p_add">+		 * non-versioned addresses. Ensure the ADI version bits</span>
<span class="p_add">+		 * are dropped here by sign extending the last bit before</span>
<span class="p_add">+		 * ADI bits. IOMMU does not implement version tags.</span>
<span class="p_add">+		 */</span>
<span class="p_add">+		addr = (addr &lt;&lt; (long)adi_nbits()) &gt;&gt; (long)adi_nbits();</span>
<span class="p_add">+		start = addr;</span>
<span class="p_add">+	}</span>
<span class="p_add">+#endif</span>
 	start &amp;= PAGE_MASK;
 	addr = start;
 	len = (unsigned long) nr_pages &lt;&lt; PAGE_SHIFT;
<span class="p_chunk">@@ -231,6 +250,24 @@</span> <span class="p_context"> int get_user_pages_fast(unsigned long start, int nr_pages, int write,</span>
 	pgd_t *pgdp;
 	int nr = 0;
 
<span class="p_add">+#ifdef CONFIG_SPARC64</span>
<span class="p_add">+	if (adi_capable()) {</span>
<span class="p_add">+		long addr = start;</span>
<span class="p_add">+</span>
<span class="p_add">+		/* If userspace has passed a versioned address, kernel</span>
<span class="p_add">+		 * will not find it in the VMAs since it does not store</span>
<span class="p_add">+		 * the version tags in the list of VMAs. Storing version</span>
<span class="p_add">+		 * tags in list of VMAs is impractical since they can be</span>
<span class="p_add">+		 * changed any time from userspace without dropping into</span>
<span class="p_add">+		 * kernel. Any address search in VMAs will be done with</span>
<span class="p_add">+		 * non-versioned addresses. Ensure the ADI version bits</span>
<span class="p_add">+		 * are dropped here by sign extending the last bit before</span>
<span class="p_add">+		 * ADI bits. IOMMU does not implements version tags,</span>
<span class="p_add">+		 */</span>
<span class="p_add">+		addr = (addr &lt;&lt; (long)adi_nbits()) &gt;&gt; (long)adi_nbits();</span>
<span class="p_add">+		start = addr;</span>
<span class="p_add">+	}</span>
<span class="p_add">+#endif</span>
 	start &amp;= PAGE_MASK;
 	addr = start;
 	len = (unsigned long) nr_pages &lt;&lt; PAGE_SHIFT;
<span class="p_header">diff --git a/arch/sparc/mm/hugetlbpage.c b/arch/sparc/mm/hugetlbpage.c</span>
<span class="p_header">index 0112d6942288..f78793a06bbd 100644</span>
<span class="p_header">--- a/arch/sparc/mm/hugetlbpage.c</span>
<span class="p_header">+++ b/arch/sparc/mm/hugetlbpage.c</span>
<span class="p_chunk">@@ -182,8 +182,20 @@</span> <span class="p_context"> pte_t arch_make_huge_pte(pte_t entry, struct vm_area_struct *vma,</span>
 			 struct page *page, int writeable)
 {
 	unsigned int shift = huge_page_shift(hstate_vma(vma));
<span class="p_add">+	pte_t pte;</span>
 
<span class="p_del">-	return hugepage_shift_to_tte(entry, shift);</span>
<span class="p_add">+	pte = hugepage_shift_to_tte(entry, shift);</span>
<span class="p_add">+</span>
<span class="p_add">+#ifdef CONFIG_SPARC64</span>
<span class="p_add">+	/* If this vma has ADI enabled on it, turn on TTE.mcd</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	if (vma-&gt;vm_flags &amp; VM_SPARC_ADI)</span>
<span class="p_add">+		return pte_mkmcd(pte);</span>
<span class="p_add">+	else</span>
<span class="p_add">+		return pte_mknotmcd(pte);</span>
<span class="p_add">+#else</span>
<span class="p_add">+	return pte;</span>
<span class="p_add">+#endif</span>
 }
 
 static unsigned int sun4v_huge_tte_to_shift(pte_t entry)
<span class="p_header">diff --git a/arch/sparc/mm/init_64.c b/arch/sparc/mm/init_64.c</span>
<span class="p_header">index 995f9490334d..cb9ebac6663f 100644</span>
<span class="p_header">--- a/arch/sparc/mm/init_64.c</span>
<span class="p_header">+++ b/arch/sparc/mm/init_64.c</span>
<span class="p_chunk">@@ -3160,3 +3160,72 @@</span> <span class="p_context"> void flush_tlb_kernel_range(unsigned long start, unsigned long end)</span>
 		do_flush_tlb_kernel_range(start, end);
 	}
 }
<span class="p_add">+</span>
<span class="p_add">+void copy_user_highpage(struct page *to, struct page *from,</span>
<span class="p_add">+	unsigned long vaddr, struct vm_area_struct *vma)</span>
<span class="p_add">+{</span>
<span class="p_add">+	char *vfrom, *vto;</span>
<span class="p_add">+</span>
<span class="p_add">+	vfrom = kmap_atomic(from);</span>
<span class="p_add">+	vto = kmap_atomic(to);</span>
<span class="p_add">+	copy_user_page(vto, vfrom, vaddr, to);</span>
<span class="p_add">+	kunmap_atomic(vto);</span>
<span class="p_add">+	kunmap_atomic(vfrom);</span>
<span class="p_add">+</span>
<span class="p_add">+	/* If this page has ADI enabled, copy over any ADI tags</span>
<span class="p_add">+	 * as well</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	if (vma-&gt;vm_flags &amp; VM_SPARC_ADI) {</span>
<span class="p_add">+		unsigned long pfrom, pto, i, adi_tag;</span>
<span class="p_add">+</span>
<span class="p_add">+		pfrom = page_to_phys(from);</span>
<span class="p_add">+		pto = page_to_phys(to);</span>
<span class="p_add">+</span>
<span class="p_add">+		for (i = pfrom; i &lt; (pfrom + PAGE_SIZE); i += adi_blksize()) {</span>
<span class="p_add">+			asm volatile(&quot;ldxa [%1] %2, %0\n\t&quot;</span>
<span class="p_add">+					: &quot;=r&quot; (adi_tag)</span>
<span class="p_add">+					:  &quot;r&quot; (i), &quot;i&quot; (ASI_MCD_REAL));</span>
<span class="p_add">+			asm volatile(&quot;stxa %0, [%1] %2\n\t&quot;</span>
<span class="p_add">+					:</span>
<span class="p_add">+					: &quot;r&quot; (adi_tag), &quot;r&quot; (pto),</span>
<span class="p_add">+					  &quot;i&quot; (ASI_MCD_REAL));</span>
<span class="p_add">+			pto += adi_blksize();</span>
<span class="p_add">+		}</span>
<span class="p_add">+		asm volatile(&quot;membar #Sync\n\t&quot;);</span>
<span class="p_add">+	}</span>
<span class="p_add">+}</span>
<span class="p_add">+EXPORT_SYMBOL(copy_user_highpage);</span>
<span class="p_add">+</span>
<span class="p_add">+void copy_highpage(struct page *to, struct page *from)</span>
<span class="p_add">+{</span>
<span class="p_add">+	char *vfrom, *vto;</span>
<span class="p_add">+</span>
<span class="p_add">+	vfrom = kmap_atomic(from);</span>
<span class="p_add">+	vto = kmap_atomic(to);</span>
<span class="p_add">+	copy_page(vto, vfrom);</span>
<span class="p_add">+	kunmap_atomic(vto);</span>
<span class="p_add">+	kunmap_atomic(vfrom);</span>
<span class="p_add">+</span>
<span class="p_add">+	/* If this platform is ADI enabled, copy any ADI tags</span>
<span class="p_add">+	 * as well</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	if (adi_capable()) {</span>
<span class="p_add">+		unsigned long pfrom, pto, i, adi_tag;</span>
<span class="p_add">+</span>
<span class="p_add">+		pfrom = page_to_phys(from);</span>
<span class="p_add">+		pto = page_to_phys(to);</span>
<span class="p_add">+</span>
<span class="p_add">+		for (i = pfrom; i &lt; (pfrom + PAGE_SIZE); i += adi_blksize()) {</span>
<span class="p_add">+			asm volatile(&quot;ldxa [%1] %2, %0\n\t&quot;</span>
<span class="p_add">+					: &quot;=r&quot; (adi_tag)</span>
<span class="p_add">+					:  &quot;r&quot; (i), &quot;i&quot; (ASI_MCD_REAL));</span>
<span class="p_add">+			asm volatile(&quot;stxa %0, [%1] %2\n\t&quot;</span>
<span class="p_add">+					:</span>
<span class="p_add">+					: &quot;r&quot; (adi_tag), &quot;r&quot; (pto),</span>
<span class="p_add">+					  &quot;i&quot; (ASI_MCD_REAL));</span>
<span class="p_add">+			pto += adi_blksize();</span>
<span class="p_add">+		}</span>
<span class="p_add">+		asm volatile(&quot;membar #Sync\n\t&quot;);</span>
<span class="p_add">+	}</span>
<span class="p_add">+}</span>
<span class="p_add">+EXPORT_SYMBOL(copy_highpage);</span>
<span class="p_header">diff --git a/arch/sparc/mm/tsb.c b/arch/sparc/mm/tsb.c</span>
<span class="p_header">index 75a04c1a2383..f5edc28aa3a5 100644</span>
<span class="p_header">--- a/arch/sparc/mm/tsb.c</span>
<span class="p_header">+++ b/arch/sparc/mm/tsb.c</span>
<span class="p_chunk">@@ -546,6 +546,9 @@</span> <span class="p_context"> int init_new_context(struct task_struct *tsk, struct mm_struct *mm)</span>
 
 	mm-&gt;context.sparc64_ctx_val = 0UL;
 
<span class="p_add">+	mm-&gt;context.tag_store = NULL;</span>
<span class="p_add">+	spin_lock_init(&amp;mm-&gt;context.tag_lock);</span>
<span class="p_add">+</span>
 #if defined(CONFIG_HUGETLB_PAGE) || defined(CONFIG_TRANSPARENT_HUGEPAGE)
 	/* We reset them to zero because the fork() page copying
 	 * will re-increment the counters as the parent PTEs are
<span class="p_chunk">@@ -611,4 +614,22 @@</span> <span class="p_context"> void destroy_context(struct mm_struct *mm)</span>
 	}
 
 	spin_unlock_irqrestore(&amp;ctx_alloc_lock, flags);
<span class="p_add">+</span>
<span class="p_add">+	/* If ADI tag storage was allocated for this task, free it */</span>
<span class="p_add">+	if (mm-&gt;context.tag_store) {</span>
<span class="p_add">+		tag_storage_desc_t *tag_desc;</span>
<span class="p_add">+		unsigned long max_desc;</span>
<span class="p_add">+		unsigned char *tags;</span>
<span class="p_add">+</span>
<span class="p_add">+		tag_desc = mm-&gt;context.tag_store;</span>
<span class="p_add">+		max_desc = PAGE_SIZE/sizeof(tag_storage_desc_t);</span>
<span class="p_add">+		for (i = 0; i &lt; max_desc; i++) {</span>
<span class="p_add">+			tags = tag_desc-&gt;tags;</span>
<span class="p_add">+			tag_desc-&gt;tags = NULL;</span>
<span class="p_add">+			kfree(tags);</span>
<span class="p_add">+			tag_desc++;</span>
<span class="p_add">+		}</span>
<span class="p_add">+		kfree(mm-&gt;context.tag_store);</span>
<span class="p_add">+		mm-&gt;context.tag_store = NULL;</span>
<span class="p_add">+	}</span>
 }
<span class="p_header">diff --git a/include/linux/mm.h b/include/linux/mm.h</span>
<span class="p_header">index ae806dbc63ee..32fe6919a11b 100644</span>
<span class="p_header">--- a/include/linux/mm.h</span>
<span class="p_header">+++ b/include/linux/mm.h</span>
<span class="p_chunk">@@ -245,6 +245,9 @@</span> <span class="p_context"> extern unsigned int kobjsize(const void *objp);</span>
 # define VM_GROWSUP	VM_ARCH_1
 #elif defined(CONFIG_IA64)
 # define VM_GROWSUP	VM_ARCH_1
<span class="p_add">+#elif defined(CONFIG_SPARC64)</span>
<span class="p_add">+# define VM_SPARC_ADI	VM_ARCH_1	/* Uses ADI tag for access control */</span>
<span class="p_add">+# define VM_ARCH_CLEAR	VM_SPARC_ADI</span>
 #elif !defined(CONFIG_MMU)
 # define VM_MAPPED_COPY	VM_ARCH_1	/* T if mapped copy of data (nommu mmap) */
 #endif
<span class="p_header">diff --git a/mm/ksm.c b/mm/ksm.c</span>
<span class="p_header">index 293721f5da70..adb5f991da8e 100644</span>
<span class="p_header">--- a/mm/ksm.c</span>
<span class="p_header">+++ b/mm/ksm.c</span>
<span class="p_chunk">@@ -2369,6 +2369,10 @@</span> <span class="p_context"> int ksm_madvise(struct vm_area_struct *vma, unsigned long start,</span>
 		if (*vm_flags &amp; VM_SAO)
 			return 0;
 #endif
<span class="p_add">+#ifdef VM_SPARC_ADI</span>
<span class="p_add">+		if (*vm_flags &amp; VM_SPARC_ADI)</span>
<span class="p_add">+			return 0;</span>
<span class="p_add">+#endif</span>
 
 		if (!test_bit(MMF_VM_MERGEABLE, &amp;mm-&gt;flags)) {
 			err = __ksm_enter(mm);

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



