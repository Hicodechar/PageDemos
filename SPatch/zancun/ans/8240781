
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>[PATCHv4,2/3] arm64: Add support for ARCH_SUPPORTS_DEBUG_PAGEALLOC - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    [PATCHv4,2/3] arm64: Add support for ARCH_SUPPORTS_DEBUG_PAGEALLOC</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=130331">Laura Abbott</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>Feb. 6, 2016, 12:24 a.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;1454718288-31374-3-git-send-email-labbott@fedoraproject.org&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/8240781/mbox/"
   >mbox</a>
|
   <a href="/patch/8240781/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/8240781/">/patch/8240781/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
X-Original-To: patchwork-LKML@patchwork.kernel.org
Delivered-To: patchwork-parsemail@patchwork2.web.kernel.org
Received: from mail.kernel.org (mail.kernel.org [198.145.29.136])
	by patchwork2.web.kernel.org (Postfix) with ESMTP id CD6BBBEEE5
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Sat,  6 Feb 2016 00:25:56 +0000 (UTC)
Received: from mail.kernel.org (localhost [127.0.0.1])
	by mail.kernel.org (Postfix) with ESMTP id 153F7203B4
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Sat,  6 Feb 2016 00:25:56 +0000 (UTC)
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.kernel.org (Postfix) with ESMTP id 2FBA2203C0
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Sat,  6 Feb 2016 00:25:55 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1751185AbcBFAZ2 (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Fri, 5 Feb 2016 19:25:28 -0500
Received: from mx1.redhat.com ([209.132.183.28]:44671 &quot;EHLO mx1.redhat.com&quot;
	rhost-flags-OK-OK-OK-OK) by vger.kernel.org with ESMTP
	id S1750848AbcBFAYz (ORCPT &lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Fri, 5 Feb 2016 19:24:55 -0500
Received: from int-mx11.intmail.prod.int.phx2.redhat.com
	(int-mx11.intmail.prod.int.phx2.redhat.com [10.5.11.24])
	by mx1.redhat.com (Postfix) with ESMTPS id 28E8670D62;
	Sat,  6 Feb 2016 00:24:55 +0000 (UTC)
Received: from labbott-redhat-machine.redhat.com
	(ovpn-112-42.phx2.redhat.com [10.3.112.42])
	by int-mx11.intmail.prod.int.phx2.redhat.com (8.14.4/8.14.4) with
	ESMTP id u160Opdd027605; Fri, 5 Feb 2016 19:24:54 -0500
From: Laura Abbott &lt;labbott@fedoraproject.org&gt;
To: Catalin Marinas &lt;catalin.marinas@arm.com&gt;,
	Will Deacon &lt;will.deacon@arm.com&gt;, Mark Rutland &lt;mark.rutland@arm.com&gt;,
	Ard Biesheuvel &lt;ard.biesheuvel@linaro.org&gt;
Cc: Laura Abbott &lt;labbott@fedoraproject.org&gt;,
	linux-arm-kernel@lists.infradead.org, linux-kernel@vger.kernel.org
Subject: [PATCHv4 2/3] arm64: Add support for ARCH_SUPPORTS_DEBUG_PAGEALLOC
Date: Fri,  5 Feb 2016 16:24:47 -0800
Message-Id: &lt;1454718288-31374-3-git-send-email-labbott@fedoraproject.org&gt;
In-Reply-To: &lt;1454718288-31374-1-git-send-email-labbott@fedoraproject.org&gt;
References: &lt;1454718288-31374-1-git-send-email-labbott@fedoraproject.org&gt;
X-Scanned-By: MIMEDefang 2.68 on 10.5.11.24
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Spam-Status: No, score=-7.2 required=5.0 tests=BAYES_00, RCVD_IN_DNSWL_HI, 
	RP_MATCHES_RCVD,
	UNPARSEABLE_RELAY autolearn=unavailable version=3.3.1
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on mail.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=130331">Laura Abbott</a> - Feb. 6, 2016, 12:24 a.m.</div>
<pre class="content">
ARCH_SUPPORTS_DEBUG_PAGEALLOC provides a hook to map and unmap
pages for debugging purposes. This requires memory be mapped
with PAGE_SIZE mappings since breaking down larger mappings
at runtime will lead to TLB conflicts. Check if debug_pagealloc
is enabled at runtime and if so, map everyting with PAGE_SIZE
pages. Implement the functions to actually map/unmap the
pages at runtime.
<span class="reviewed-by">
Reviewed-by: Ard Biesheuvel &lt;ard.biesheuvel@linaro.org&gt;</span>
<span class="reviewed-by">Reviewed-by: Mark Rutland &lt;mark.rutland@arm.com&gt;</span>
<span class="tested-by">Tested-by: Mark Rutland &lt;mark.rutland@arm.com&gt;</span>
<span class="signed-off-by">Signed-off-by: Laura Abbott &lt;labbott@fedoraproject.org&gt;</span>
---
 arch/arm64/Kconfig       |  3 +++
 arch/arm64/mm/mmu.c      | 19 +++++++++++++++++--
 arch/arm64/mm/pageattr.c | 46 ++++++++++++++++++++++++++++++++++++----------
 3 files changed, 56 insertions(+), 12 deletions(-)
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=352">Catalin Marinas</a> - Feb. 10, 2016, 10:38 a.m.</div>
<pre class="content">
On Fri, Feb 05, 2016 at 04:24:47PM -0800, Laura Abbott wrote:
<span class="quote">&gt; --- a/arch/arm64/mm/mmu.c</span>
<span class="quote">&gt; +++ b/arch/arm64/mm/mmu.c</span>
<span class="quote">&gt; @@ -149,6 +149,19 @@ static void split_pud(pud_t *old_pud, pmd_t *pmd)</span>
<span class="quote">&gt;  	} while (pmd++, i++, i &lt; PTRS_PER_PMD);</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; +bool block_mappings_allowed(phys_addr_t (*pgtable_alloc)(void))</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	/*</span>
<span class="quote">&gt; +	 * If debug_page_alloc is enabled we must map the linear map</span>
<span class="quote">&gt; +	 * using pages. However, other mappings created by</span>
<span class="quote">&gt; +	 * create_mapping_noalloc must use sections in some cases. Allow</span>
<span class="quote">&gt; +	 * sections to be used in those cases, where no pgtable_alloc</span>
<span class="quote">&gt; +	 * function is provided.</span>
<span class="quote">&gt; +	 */</span>
<span class="quote">&gt; +	return !pgtable_alloc || !debug_pagealloc_enabled();</span>
<span class="quote">&gt; +}</span>

This breaks the build when CONFIG_DEBUG_PAGEALLOC is not enabled
(defconfig) since debug_pagealloc_enabled() is not defined. A fix went
in next/master as commit 0987684b855c
(&quot;mm-slab-clean-up-debug_pagealloc-processing-code-fix&quot;). I need to
track it down and merge it via the arm64 tree, otherwise I&#39;ll add some
#ifdefs in this function.

BTW, shouldn&#39;t the block_mappings_allowed() function be static?
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=66681">Ard Biesheuvel</a> - Feb. 10, 2016, 10:40 a.m.</div>
<pre class="content">
On 10 February 2016 at 11:38, Catalin Marinas &lt;catalin.marinas@arm.com&gt; wrote:
<span class="quote">&gt; On Fri, Feb 05, 2016 at 04:24:47PM -0800, Laura Abbott wrote:</span>
<span class="quote">&gt;&gt; --- a/arch/arm64/mm/mmu.c</span>
<span class="quote">&gt;&gt; +++ b/arch/arm64/mm/mmu.c</span>
<span class="quote">&gt;&gt; @@ -149,6 +149,19 @@ static void split_pud(pud_t *old_pud, pmd_t *pmd)</span>
<span class="quote">&gt;&gt;       } while (pmd++, i++, i &lt; PTRS_PER_PMD);</span>
<span class="quote">&gt;&gt;  }</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; +bool block_mappings_allowed(phys_addr_t (*pgtable_alloc)(void))</span>
<span class="quote">&gt;&gt; +{</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +     /*</span>
<span class="quote">&gt;&gt; +      * If debug_page_alloc is enabled we must map the linear map</span>
<span class="quote">&gt;&gt; +      * using pages. However, other mappings created by</span>
<span class="quote">&gt;&gt; +      * create_mapping_noalloc must use sections in some cases. Allow</span>
<span class="quote">&gt;&gt; +      * sections to be used in those cases, where no pgtable_alloc</span>
<span class="quote">&gt;&gt; +      * function is provided.</span>
<span class="quote">&gt;&gt; +      */</span>
<span class="quote">&gt;&gt; +     return !pgtable_alloc || !debug_pagealloc_enabled();</span>
<span class="quote">&gt;&gt; +}</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; This breaks the build when CONFIG_DEBUG_PAGEALLOC is not enabled</span>
<span class="quote">&gt; (defconfig) since debug_pagealloc_enabled() is not defined. A fix went</span>
<span class="quote">&gt; in next/master as commit 0987684b855c</span>
<span class="quote">&gt; (&quot;mm-slab-clean-up-debug_pagealloc-processing-code-fix&quot;). I need to</span>
<span class="quote">&gt; track it down and merge it via the arm64 tree, otherwise I&#39;ll add some</span>
<span class="quote">&gt; #ifdefs in this function.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; BTW, shouldn&#39;t the block_mappings_allowed() function be static?</span>
<span class="quote">&gt;</span>

Yes, it should.
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=30282">Mark Rutland</a> - Feb. 10, 2016, 10:54 a.m.</div>
<pre class="content">
On Wed, Feb 10, 2016 at 10:38:14AM +0000, Catalin Marinas wrote:
<span class="quote">&gt; On Fri, Feb 05, 2016 at 04:24:47PM -0800, Laura Abbott wrote:</span>
<span class="quote">&gt; &gt; --- a/arch/arm64/mm/mmu.c</span>
<span class="quote">&gt; &gt; +++ b/arch/arm64/mm/mmu.c</span>
<span class="quote">&gt; &gt; @@ -149,6 +149,19 @@ static void split_pud(pud_t *old_pud, pmd_t *pmd)</span>
<span class="quote">&gt; &gt;  	} while (pmd++, i++, i &lt; PTRS_PER_PMD);</span>
<span class="quote">&gt; &gt;  }</span>
<span class="quote">&gt; &gt;  </span>
<span class="quote">&gt; &gt; +bool block_mappings_allowed(phys_addr_t (*pgtable_alloc)(void))</span>
<span class="quote">&gt; &gt; +{</span>
<span class="quote">&gt; &gt; +</span>
<span class="quote">&gt; &gt; +	/*</span>
<span class="quote">&gt; &gt; +	 * If debug_page_alloc is enabled we must map the linear map</span>
<span class="quote">&gt; &gt; +	 * using pages. However, other mappings created by</span>
<span class="quote">&gt; &gt; +	 * create_mapping_noalloc must use sections in some cases. Allow</span>
<span class="quote">&gt; &gt; +	 * sections to be used in those cases, where no pgtable_alloc</span>
<span class="quote">&gt; &gt; +	 * function is provided.</span>
<span class="quote">&gt; &gt; +	 */</span>
<span class="quote">&gt; &gt; +	return !pgtable_alloc || !debug_pagealloc_enabled();</span>
<span class="quote">&gt; &gt; +}</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; This breaks the build when CONFIG_DEBUG_PAGEALLOC is not enabled</span>
<span class="quote">&gt; (defconfig) since debug_pagealloc_enabled() is not defined. A fix went</span>
<span class="quote">&gt; in next/master as commit 0987684b855c</span>
<span class="quote">&gt; (&quot;mm-slab-clean-up-debug_pagealloc-processing-code-fix&quot;). I need to</span>
<span class="quote">&gt; track it down and merge it via the arm64 tree, otherwise I&#39;ll add some</span>
<span class="quote">&gt; #ifdefs in this function.</span>

In the cover for v2 [1],  it was mentioend that we needed a patch [2]
&quot;mm: provide debug_pagealloc_enabled() without CONFIG_DEBUG_PAGEALLOC&quot;.
I assumed that was already queued via the mm tree.
<span class="quote">
&gt; BTW, shouldn&#39;t the block_mappings_allowed() function be static?</span>

That would make sense to me, yes.

Mark.

[1] http://lists.infradead.org/pipermail/linux-arm-kernel/2016-January/403439.html  
[2] http://article.gmane.org/gmane.linux.kernel.mm/1452
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=352">Catalin Marinas</a> - Feb. 10, 2016, 11:02 a.m.</div>
<pre class="content">
On Wed, Feb 10, 2016 at 10:38:14AM +0000, Catalin Marinas wrote:
<span class="quote">&gt; On Fri, Feb 05, 2016 at 04:24:47PM -0800, Laura Abbott wrote:</span>
<span class="quote">&gt; &gt; --- a/arch/arm64/mm/mmu.c</span>
<span class="quote">&gt; &gt; +++ b/arch/arm64/mm/mmu.c</span>
<span class="quote">&gt; &gt; @@ -149,6 +149,19 @@ static void split_pud(pud_t *old_pud, pmd_t *pmd)</span>
<span class="quote">&gt; &gt;  	} while (pmd++, i++, i &lt; PTRS_PER_PMD);</span>
<span class="quote">&gt; &gt;  }</span>
<span class="quote">&gt; &gt;  </span>
<span class="quote">&gt; &gt; +bool block_mappings_allowed(phys_addr_t (*pgtable_alloc)(void))</span>
<span class="quote">&gt; &gt; +{</span>
<span class="quote">&gt; &gt; +</span>
<span class="quote">&gt; &gt; +	/*</span>
<span class="quote">&gt; &gt; +	 * If debug_page_alloc is enabled we must map the linear map</span>
<span class="quote">&gt; &gt; +	 * using pages. However, other mappings created by</span>
<span class="quote">&gt; &gt; +	 * create_mapping_noalloc must use sections in some cases. Allow</span>
<span class="quote">&gt; &gt; +	 * sections to be used in those cases, where no pgtable_alloc</span>
<span class="quote">&gt; &gt; +	 * function is provided.</span>
<span class="quote">&gt; &gt; +	 */</span>
<span class="quote">&gt; &gt; +	return !pgtable_alloc || !debug_pagealloc_enabled();</span>
<span class="quote">&gt; &gt; +}</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; This breaks the build when CONFIG_DEBUG_PAGEALLOC is not enabled</span>
<span class="quote">&gt; (defconfig) since debug_pagealloc_enabled() is not defined. A fix went</span>
<span class="quote">&gt; in next/master as commit 0987684b855c</span>
<span class="quote">&gt; (&quot;mm-slab-clean-up-debug_pagealloc-processing-code-fix&quot;). I need to</span>
<span class="quote">&gt; track it down and merge it via the arm64 tree, otherwise I&#39;ll add some</span>
<span class="quote">&gt; #ifdefs in this function.</span>

It seems that there are other patches in the mm tree requiring this
change. I&#39;ll fix it locally (#ifdefs) and revert the change after -rc1.
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/arch/arm64/Kconfig b/arch/arm64/Kconfig</span>
<span class="p_header">index 8cc6228..0f33218 100644</span>
<span class="p_header">--- a/arch/arm64/Kconfig</span>
<span class="p_header">+++ b/arch/arm64/Kconfig</span>
<span class="p_chunk">@@ -537,6 +537,9 @@</span> <span class="p_context"> config HOTPLUG_CPU</span>
 source kernel/Kconfig.preempt
 source kernel/Kconfig.hz
 
<span class="p_add">+config ARCH_SUPPORTS_DEBUG_PAGEALLOC</span>
<span class="p_add">+	def_bool y</span>
<span class="p_add">+</span>
 config ARCH_HAS_HOLES_MEMORYMODEL
 	def_bool y if SPARSEMEM
 
<span class="p_header">diff --git a/arch/arm64/mm/mmu.c b/arch/arm64/mm/mmu.c</span>
<span class="p_header">index ef0d66c..29dcc83 100644</span>
<span class="p_header">--- a/arch/arm64/mm/mmu.c</span>
<span class="p_header">+++ b/arch/arm64/mm/mmu.c</span>
<span class="p_chunk">@@ -149,6 +149,19 @@</span> <span class="p_context"> static void split_pud(pud_t *old_pud, pmd_t *pmd)</span>
 	} while (pmd++, i++, i &lt; PTRS_PER_PMD);
 }
 
<span class="p_add">+bool block_mappings_allowed(phys_addr_t (*pgtable_alloc)(void))</span>
<span class="p_add">+{</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * If debug_page_alloc is enabled we must map the linear map</span>
<span class="p_add">+	 * using pages. However, other mappings created by</span>
<span class="p_add">+	 * create_mapping_noalloc must use sections in some cases. Allow</span>
<span class="p_add">+	 * sections to be used in those cases, where no pgtable_alloc</span>
<span class="p_add">+	 * function is provided.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	return !pgtable_alloc || !debug_pagealloc_enabled();</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static void alloc_init_pmd(pud_t *pud, unsigned long addr, unsigned long end,
 				  phys_addr_t phys, pgprot_t prot,
 				  phys_addr_t (*pgtable_alloc)(void))
<span class="p_chunk">@@ -181,7 +194,8 @@</span> <span class="p_context"> static void alloc_init_pmd(pud_t *pud, unsigned long addr, unsigned long end,</span>
 	do {
 		next = pmd_addr_end(addr, end);
 		/* try section mapping first */
<span class="p_del">-		if (((addr | next | phys) &amp; ~SECTION_MASK) == 0) {</span>
<span class="p_add">+		if (((addr | next | phys) &amp; ~SECTION_MASK) == 0 &amp;&amp;</span>
<span class="p_add">+		      block_mappings_allowed(pgtable_alloc)) {</span>
 			pmd_t old_pmd =*pmd;
 			set_pmd(pmd, __pmd(phys |
 					   pgprot_val(mk_sect_prot(prot))));
<span class="p_chunk">@@ -241,7 +255,8 @@</span> <span class="p_context"> static void alloc_init_pud(pgd_t *pgd, unsigned long addr, unsigned long end,</span>
 		/*
 		 * For 4K granule only, attempt to put down a 1GB block
 		 */
<span class="p_del">-		if (use_1G_block(addr, next, phys)) {</span>
<span class="p_add">+		if (use_1G_block(addr, next, phys) &amp;&amp;</span>
<span class="p_add">+		    block_mappings_allowed(pgtable_alloc)) {</span>
 			pud_t old_pud = *pud;
 			set_pud(pud, __pud(phys |
 					   pgprot_val(mk_sect_prot(prot))));
<span class="p_header">diff --git a/arch/arm64/mm/pageattr.c b/arch/arm64/mm/pageattr.c</span>
<span class="p_header">index 1360a02..7ba87c4 100644</span>
<span class="p_header">--- a/arch/arm64/mm/pageattr.c</span>
<span class="p_header">+++ b/arch/arm64/mm/pageattr.c</span>
<span class="p_chunk">@@ -37,14 +37,31 @@</span> <span class="p_context"> static int change_page_range(pte_t *ptep, pgtable_t token, unsigned long addr,</span>
 	return 0;
 }
 
<span class="p_add">+/*</span>
<span class="p_add">+ * This function assumes that the range is mapped with PAGE_SIZE pages.</span>
<span class="p_add">+ */</span>
<span class="p_add">+static int __change_memory_common(unsigned long start, unsigned long size,</span>
<span class="p_add">+				pgprot_t set_mask, pgprot_t clear_mask)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct page_change_data data;</span>
<span class="p_add">+	int ret;</span>
<span class="p_add">+</span>
<span class="p_add">+	data.set_mask = set_mask;</span>
<span class="p_add">+	data.clear_mask = clear_mask;</span>
<span class="p_add">+</span>
<span class="p_add">+	ret = apply_to_page_range(&amp;init_mm, start, size, change_page_range,</span>
<span class="p_add">+					&amp;data);</span>
<span class="p_add">+</span>
<span class="p_add">+	flush_tlb_kernel_range(start, start + size);</span>
<span class="p_add">+	return ret;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static int change_memory_common(unsigned long addr, int numpages,
 				pgprot_t set_mask, pgprot_t clear_mask)
 {
 	unsigned long start = addr;
 	unsigned long size = PAGE_SIZE*numpages;
 	unsigned long end = start + size;
<span class="p_del">-	int ret;</span>
<span class="p_del">-	struct page_change_data data;</span>
 	struct vm_struct *area;
 
 	if (!PAGE_ALIGNED(addr)) {
<span class="p_chunk">@@ -72,14 +89,7 @@</span> <span class="p_context"> static int change_memory_common(unsigned long addr, int numpages,</span>
 	    !(area-&gt;flags &amp; VM_ALLOC))
 		return -EINVAL;
 
<span class="p_del">-	data.set_mask = set_mask;</span>
<span class="p_del">-	data.clear_mask = clear_mask;</span>
<span class="p_del">-</span>
<span class="p_del">-	ret = apply_to_page_range(&amp;init_mm, start, size, change_page_range,</span>
<span class="p_del">-					&amp;data);</span>
<span class="p_del">-</span>
<span class="p_del">-	flush_tlb_kernel_range(start, end);</span>
<span class="p_del">-	return ret;</span>
<span class="p_add">+	return __change_memory_common(start, size, set_mask, clear_mask);</span>
 }
 
 int set_memory_ro(unsigned long addr, int numpages)
<span class="p_chunk">@@ -111,3 +121,19 @@</span> <span class="p_context"> int set_memory_x(unsigned long addr, int numpages)</span>
 					__pgprot(PTE_PXN));
 }
 EXPORT_SYMBOL_GPL(set_memory_x);
<span class="p_add">+</span>
<span class="p_add">+#ifdef CONFIG_DEBUG_PAGEALLOC</span>
<span class="p_add">+void __kernel_map_pages(struct page *page, int numpages, int enable)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long addr = (unsigned long) page_address(page);</span>
<span class="p_add">+</span>
<span class="p_add">+	if (enable)</span>
<span class="p_add">+		__change_memory_common(addr, PAGE_SIZE * numpages,</span>
<span class="p_add">+					__pgprot(PTE_VALID),</span>
<span class="p_add">+					__pgprot(0));</span>
<span class="p_add">+	else</span>
<span class="p_add">+		__change_memory_common(addr, PAGE_SIZE * numpages,</span>
<span class="p_add">+					__pgprot(0),</span>
<span class="p_add">+					__pgprot(PTE_VALID));</span>
<span class="p_add">+}</span>
<span class="p_add">+#endif</span>

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



