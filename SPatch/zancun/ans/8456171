
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>[ANNOUNCE] 3.18.27-rt26 - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    [ANNOUNCE] 3.18.27-rt26</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=310">Steven Rostedt</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>Feb. 29, 2016, 5:05 p.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;20160229120512.3830fb23@gandalf.local.home&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/8456171/mbox/"
   >mbox</a>
|
   <a href="/patch/8456171/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/8456171/">/patch/8456171/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
X-Original-To: patchwork-LKML@patchwork.kernel.org
Delivered-To: patchwork-parsemail@patchwork2.web.kernel.org
Received: from mail.kernel.org (mail.kernel.org [198.145.29.136])
	by patchwork2.web.kernel.org (Postfix) with ESMTP id EA00BC0553
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Mon, 29 Feb 2016 17:05:35 +0000 (UTC)
Received: from mail.kernel.org (localhost [127.0.0.1])
	by mail.kernel.org (Postfix) with ESMTP id DB13B2021A
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Mon, 29 Feb 2016 17:05:33 +0000 (UTC)
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.kernel.org (Postfix) with ESMTP id 709AA2022A
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Mon, 29 Feb 2016 17:05:26 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1751780AbcB2RFV (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Mon, 29 Feb 2016 12:05:21 -0500
Received: from smtprelay0145.hostedemail.com ([216.40.44.145]:54079 &quot;EHLO
	smtprelay.hostedemail.com&quot; rhost-flags-OK-OK-OK-FAIL)
	by vger.kernel.org with ESMTP id S1751163AbcB2RFR (ORCPT
	&lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Mon, 29 Feb 2016 12:05:17 -0500
Received: from filter.hostedemail.com (unknown [216.40.38.60])
	by smtprelay02.hostedemail.com (Postfix) with ESMTP id EB05712BA1A;
	Mon, 29 Feb 2016 17:05:14 +0000 (UTC)
X-Session-Marker: 726F737465647440676F6F646D69732E6F7267
X-Spam-Summary: 50, 0, 0, , d41d8cd98f00b204, rostedt@goodmis.org,
	:::::::::::,
	RULES_HIT:41:69:327:355:379:541:800:960:966:967:968:969:973:988:989:1260:1263:1277:1311:1313:1314:1345:1437:1515:1516:1518:1593:1594:1605:1730:1747:1777:1792:1801:2194:2196:2199:2200:2393:2525:2566:2682:2685:2687:2736:2859:2897:2904:2910:2916:2933:2937:2939:2942:2945:2947:2951:2954:3022:3138:3139:3140:3141:3142:3165:3770:3834:3865:3866:3867:3868:3871:3872:3873:3874:3934:3936:3938:3941:3944:3947:3950:3953:3956:3959:4250:4321:4385:4560:4605:5007:6119:6261:6299:6684:7266:7875:7903:7974:8509:8531:8599:8660:8784:8985:9025:9038:9072:9388:9592:10004:10049:10848:11026:11232:11473:11657:11658:11914:12043:12198:12291:12294:12296:12438:12517:12519:12555:12663:12679:12683:13019:13148:13230:13439:13972:14096:14097:14394:14659:21080:21365:30012:30029:30045:30054:30056:30070,
	0, RBL:none, CacheIP:none, Bayesian:0.5, 0.5, 0.5,
	Netcheck:none, DomainCache:0, MSF:not bulk, SPF:fn, MSBL:0,
	DNSBL:none, Custom_rules:0:0:0, LFtime:6, LUA_SUM MARY:non
X-HE-Tag: cat32_4abe5a624574d
X-Filterd-Recvd-Size: 28141
Received: from gandalf.local.home (cpe-67-246-153-56.stny.res.rr.com
	[67.246.153.56]) (Authenticated sender: rostedt@goodmis.org)
	by omf01.hostedemail.com (Postfix) with ESMTPA;
	Mon, 29 Feb 2016 17:05:13 +0000 (UTC)
Date: Mon, 29 Feb 2016 12:05:12 -0500
From: Steven Rostedt &lt;rostedt@goodmis.org&gt;
To: LKML &lt;linux-kernel@vger.kernel.org&gt;,
	linux-rt-users &lt;linux-rt-users@vger.kernel.org&gt;
Cc: Thomas Gleixner &lt;tglx@linutronix.de&gt;, Carsten Emde &lt;C.Emde@osadl.org&gt;,
	John Kacur &lt;jkacur@redhat.com&gt;,
	Sebastian Andrzej Siewior &lt;bigeasy@linutronix.de&gt;
Subject: [ANNOUNCE] 3.18.27-rt26
Message-ID: &lt;20160229120512.3830fb23@gandalf.local.home&gt;
X-Mailer: Claws Mail 3.13.2 (GTK+ 2.24.29; x86_64-pc-linux-gnu)
MIME-Version: 1.0
Content-Type: text/plain; charset=US-ASCII
Content-Transfer-Encoding: 7bit
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Spam-Status: No, score=-6.9 required=5.0 tests=BAYES_00, RCVD_IN_DNSWL_HI, 
	RP_MATCHES_RCVD,
	UNPARSEABLE_RELAY autolearn=unavailable version=3.3.1
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on mail.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=310">Steven Rostedt</a> - Feb. 29, 2016, 5:05 p.m.</div>
<pre class="content">
Dear RT Folks,

I&#39;m pleased to announce the 3.18.27-rt26 stable release.


You can get this release via the git tree at:

  git://git.kernel.org/pub/scm/linux/kernel/git/rt/linux-stable-rt.git

  branch: v3.18-rt
  Head SHA1: 9df6942317afb556a87b905a0c1137c06d6b53a3


Or to build 3.18.27-rt26 directly, the following patches should be applied:

  http://www.kernel.org/pub/linux/kernel/v3.x/linux-3.18.tar.xz

  http://www.kernel.org/pub/linux/kernel/v3.x/patch-3.18.27.xz

  http://www.kernel.org/pub/linux/kernel/projects/rt/3.18/patch-3.18.27-rt26.patch.xz



You can also build from 3.18.27-rt25 by applying the incremental patch:

  http://www.kernel.org/pub/linux/kernel/projects/rt/3.18/incr/patch-3.18.27-rt25-rt26.patch.xz



Enjoy,

-- Steve


Changes from v3.18.27-rt25:

---

Grygorii Strashko (2):
      ARM: smp: Move clear_tasks_mm_cpumask() call to __cpu_die()
      net/core/cpuhotplug: Drain input_pkt_queue lockless

Josh Cartwright (1):
      net: Make synchronize_rcu_expedited() conditional on !RT_FULL

Peter Zijlstra (1):
      sched: Introduce the trace_sched_waking tracepoint

Sebastian Andrzej Siewior (2):
      cpufreq: Remove cpufreq_rwsem
      dump stack: don&#39;t disable preemption during trace

Steven Rostedt (Red Hat) (1):
      Linux 3.18.27-rt26

Thomas Gleixner (3):
      genirq: Handle force threading of interrupts with primary and thread handler
      rtmutex: Handle non enqueued waiters gracefully
      irqwork: Move irq safe work to irq context

Wolfgang M. Reimer (1):
      locking: locktorture: Do NOT include rwlock.h directly

bmouring@ni.com (1):
      rtmutex: Use chainwalking control enum

----
 arch/arm/kernel/smp.c             |   5 +-
 arch/x86/kernel/dumpstack_32.c    |   4 +-
 arch/x86/kernel/dumpstack_64.c    |   8 +-
 drivers/cpufreq/cpufreq.c         |  34 +-------
 include/linux/interrupt.h         |   2 +
 include/linux/irq_work.h          |   6 ++
 include/trace/events/sched.h      |  30 +++++---
 kernel/irq/manage.c               | 158 ++++++++++++++++++++++++++++----------
 kernel/irq_work.c                 |   9 +++
 kernel/locking/locktorture.c      |   1 -
 kernel/locking/rtmutex.c          |   4 +-
 kernel/sched/core.c               |   8 +-
 kernel/time/timer.c               |   6 +-
 kernel/trace/trace_sched_switch.c |   2 +-
 kernel/trace/trace_sched_wakeup.c |   2 +-
 lib/dump_stack.c                  |   6 +-
 localversion-rt                   |   2 +-
 net/core/dev.c                    |   4 +-
 18 files changed, 183 insertions(+), 108 deletions(-)
---------------------------
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c</span>
<span class="p_header">index a8e32aaf0383..6e9b81666a23 100644</span>
<span class="p_header">--- a/arch/arm/kernel/smp.c</span>
<span class="p_header">+++ b/arch/arm/kernel/smp.c</span>
<span class="p_chunk">@@ -208,8 +208,6 @@</span> <span class="p_context"> int __cpu_disable(void)</span>
 	flush_cache_louis();
 	local_flush_tlb_all();
 
<span class="p_del">-	clear_tasks_mm_cpumask(cpu);</span>
<span class="p_del">-</span>
 	return 0;
 }
 
<span class="p_chunk">@@ -225,6 +223,9 @@</span> <span class="p_context"> void __cpu_die(unsigned int cpu)</span>
 		pr_err(&quot;CPU%u: cpu didn&#39;t die\n&quot;, cpu);
 		return;
 	}
<span class="p_add">+</span>
<span class="p_add">+	clear_tasks_mm_cpumask(cpu);</span>
<span class="p_add">+</span>
 	printk(KERN_NOTICE &quot;CPU%u: shutdown\n&quot;, cpu);
 
 	/*
<span class="p_header">diff --git a/arch/x86/kernel/dumpstack_32.c b/arch/x86/kernel/dumpstack_32.c</span>
<span class="p_header">index 5abd4cd4230c..1282817bb4c3 100644</span>
<span class="p_header">--- a/arch/x86/kernel/dumpstack_32.c</span>
<span class="p_header">+++ b/arch/x86/kernel/dumpstack_32.c</span>
<span class="p_chunk">@@ -42,7 +42,7 @@</span> <span class="p_context"> void dump_trace(struct task_struct *task, struct pt_regs *regs,</span>
 		unsigned long *stack, unsigned long bp,
 		const struct stacktrace_ops *ops, void *data)
 {
<span class="p_del">-	const unsigned cpu = get_cpu();</span>
<span class="p_add">+	const unsigned cpu = get_cpu_light();</span>
 	int graph = 0;
 	u32 *prev_esp;
 
<span class="p_chunk">@@ -86,7 +86,7 @@</span> <span class="p_context"> void dump_trace(struct task_struct *task, struct pt_regs *regs,</span>
 			break;
 		touch_nmi_watchdog();
 	}
<span class="p_del">-	put_cpu();</span>
<span class="p_add">+	put_cpu_light();</span>
 }
 EXPORT_SYMBOL(dump_trace);
 
<span class="p_header">diff --git a/arch/x86/kernel/dumpstack_64.c b/arch/x86/kernel/dumpstack_64.c</span>
<span class="p_header">index ff86f19b5758..4821f291890f 100644</span>
<span class="p_header">--- a/arch/x86/kernel/dumpstack_64.c</span>
<span class="p_header">+++ b/arch/x86/kernel/dumpstack_64.c</span>
<span class="p_chunk">@@ -152,7 +152,7 @@</span> <span class="p_context"> void dump_trace(struct task_struct *task, struct pt_regs *regs,</span>
 		unsigned long *stack, unsigned long bp,
 		const struct stacktrace_ops *ops, void *data)
 {
<span class="p_del">-	const unsigned cpu = get_cpu();</span>
<span class="p_add">+	const unsigned cpu = get_cpu_light();</span>
 	struct thread_info *tinfo;
 	unsigned long *irq_stack = (unsigned long *)per_cpu(irq_stack_ptr, cpu);
 	unsigned long dummy;
<span class="p_chunk">@@ -241,7 +241,7 @@</span> <span class="p_context"> void dump_trace(struct task_struct *task, struct pt_regs *regs,</span>
 	 * This handles the process stack:
 	 */
 	bp = ops-&gt;walk_stack(tinfo, stack, bp, ops, data, NULL, &amp;graph);
<span class="p_del">-	put_cpu();</span>
<span class="p_add">+	put_cpu_light();</span>
 }
 EXPORT_SYMBOL(dump_trace);
 
<span class="p_chunk">@@ -255,7 +255,7 @@</span> <span class="p_context"> show_stack_log_lvl(struct task_struct *task, struct pt_regs *regs,</span>
 	int cpu;
 	int i;
 
<span class="p_del">-	preempt_disable();</span>
<span class="p_add">+	migrate_disable();</span>
 	cpu = smp_processor_id();
 
 	irq_stack_end	= (unsigned long *)(per_cpu(irq_stack_ptr, cpu));
<span class="p_chunk">@@ -288,7 +288,7 @@</span> <span class="p_context"> show_stack_log_lvl(struct task_struct *task, struct pt_regs *regs,</span>
 		pr_cont(&quot; %016lx&quot;, *stack++);
 		touch_nmi_watchdog();
 	}
<span class="p_del">-	preempt_enable();</span>
<span class="p_add">+	migrate_enable();</span>
 
 	pr_cont(&quot;\n&quot;);
 	show_trace_log_lvl(task, regs, sp, bp, log_lvl);
<span class="p_header">diff --git a/drivers/cpufreq/cpufreq.c b/drivers/cpufreq/cpufreq.c</span>
<span class="p_header">index 90e8deb6c15e..7a9c1a7ecfe5 100644</span>
<span class="p_header">--- a/drivers/cpufreq/cpufreq.c</span>
<span class="p_header">+++ b/drivers/cpufreq/cpufreq.c</span>
<span class="p_chunk">@@ -53,12 +53,6 @@</span> <span class="p_context"> static inline bool has_target(void)</span>
 	return cpufreq_driver-&gt;target_index || cpufreq_driver-&gt;target;
 }
 
<span class="p_del">-/*</span>
<span class="p_del">- * rwsem to guarantee that cpufreq driver module doesn&#39;t unload during critical</span>
<span class="p_del">- * sections</span>
<span class="p_del">- */</span>
<span class="p_del">-static DECLARE_RWSEM(cpufreq_rwsem);</span>
<span class="p_del">-</span>
 /* internal prototypes */
 static int __cpufreq_governor(struct cpufreq_policy *policy,
 		unsigned int event);
<span class="p_chunk">@@ -205,9 +199,6 @@</span> <span class="p_context"> struct cpufreq_policy *cpufreq_cpu_get(unsigned int cpu)</span>
 	if (cpufreq_disabled() || (cpu &gt;= nr_cpu_ids))
 		return NULL;
 
<span class="p_del">-	if (!down_read_trylock(&amp;cpufreq_rwsem))</span>
<span class="p_del">-		return NULL;</span>
<span class="p_del">-</span>
 	/* get the cpufreq driver */
 	read_lock_irqsave(&amp;cpufreq_driver_lock, flags);
 
<span class="p_chunk">@@ -220,9 +211,6 @@</span> <span class="p_context"> struct cpufreq_policy *cpufreq_cpu_get(unsigned int cpu)</span>
 
 	read_unlock_irqrestore(&amp;cpufreq_driver_lock, flags);
 
<span class="p_del">-	if (!policy)</span>
<span class="p_del">-		up_read(&amp;cpufreq_rwsem);</span>
<span class="p_del">-</span>
 	return policy;
 }
 EXPORT_SYMBOL_GPL(cpufreq_cpu_get);
<span class="p_chunk">@@ -233,7 +221,6 @@</span> <span class="p_context"> void cpufreq_cpu_put(struct cpufreq_policy *policy)</span>
 		return;
 
 	kobject_put(&amp;policy-&gt;kobj);
<span class="p_del">-	up_read(&amp;cpufreq_rwsem);</span>
 }
 EXPORT_SYMBOL_GPL(cpufreq_cpu_put);
 
<span class="p_chunk">@@ -762,9 +749,6 @@</span> <span class="p_context"> static ssize_t show(struct kobject *kobj, struct attribute *attr, char *buf)</span>
 	struct freq_attr *fattr = to_attr(attr);
 	ssize_t ret;
 
<span class="p_del">-	if (!down_read_trylock(&amp;cpufreq_rwsem))</span>
<span class="p_del">-		return -EINVAL;</span>
<span class="p_del">-</span>
 	down_read(&amp;policy-&gt;rwsem);
 
 	if (fattr-&gt;show)
<span class="p_chunk">@@ -773,7 +757,6 @@</span> <span class="p_context"> static ssize_t show(struct kobject *kobj, struct attribute *attr, char *buf)</span>
 		ret = -EIO;
 
 	up_read(&amp;policy-&gt;rwsem);
<span class="p_del">-	up_read(&amp;cpufreq_rwsem);</span>
 
 	return ret;
 }
<span class="p_chunk">@@ -790,9 +773,6 @@</span> <span class="p_context"> static ssize_t store(struct kobject *kobj, struct attribute *attr,</span>
 	if (!cpu_online(policy-&gt;cpu))
 		goto unlock;
 
<span class="p_del">-	if (!down_read_trylock(&amp;cpufreq_rwsem))</span>
<span class="p_del">-		goto unlock;</span>
<span class="p_del">-</span>
 	down_write(&amp;policy-&gt;rwsem);
 
 	if (fattr-&gt;store)
<span class="p_chunk">@@ -801,8 +781,6 @@</span> <span class="p_context"> static ssize_t store(struct kobject *kobj, struct attribute *attr,</span>
 		ret = -EIO;
 
 	up_write(&amp;policy-&gt;rwsem);
<span class="p_del">-</span>
<span class="p_del">-	up_read(&amp;cpufreq_rwsem);</span>
 unlock:
 	put_online_cpus();
 
<span class="p_chunk">@@ -1142,9 +1120,6 @@</span> <span class="p_context"> static int __cpufreq_add_dev(struct device *dev, struct subsys_interface *sif)</span>
 	}
 #endif
 
<span class="p_del">-	if (!down_read_trylock(&amp;cpufreq_rwsem))</span>
<span class="p_del">-		return 0;</span>
<span class="p_del">-</span>
 #ifdef CONFIG_HOTPLUG_CPU
 	/* Check if this cpu was hot-unplugged earlier and has siblings */
 	read_lock_irqsave(&amp;cpufreq_driver_lock, flags);
<span class="p_chunk">@@ -1152,7 +1127,6 @@</span> <span class="p_context"> static int __cpufreq_add_dev(struct device *dev, struct subsys_interface *sif)</span>
 		if (cpumask_test_cpu(cpu, tpolicy-&gt;related_cpus)) {
 			read_unlock_irqrestore(&amp;cpufreq_driver_lock, flags);
 			ret = cpufreq_add_policy_cpu(tpolicy, cpu, dev);
<span class="p_del">-			up_read(&amp;cpufreq_rwsem);</span>
 			return ret;
 		}
 	}
<span class="p_chunk">@@ -1288,7 +1262,6 @@</span> <span class="p_context"> static int __cpufreq_add_dev(struct device *dev, struct subsys_interface *sif)</span>
 	up_write(&amp;policy-&gt;rwsem);
 
 	kobject_uevent(&amp;policy-&gt;kobj, KOBJ_ADD);
<span class="p_del">-	up_read(&amp;cpufreq_rwsem);</span>
 
 	pr_debug(&quot;initialization complete\n&quot;);
 
<span class="p_chunk">@@ -1314,8 +1287,6 @@</span> <span class="p_context"> err_set_policy_cpu:</span>
 	cpufreq_policy_free(policy);
 
 nomem_out:
<span class="p_del">-	up_read(&amp;cpufreq_rwsem);</span>
<span class="p_del">-</span>
 	return ret;
 }
 
<span class="p_chunk">@@ -2528,19 +2499,20 @@</span> <span class="p_context"> int cpufreq_unregister_driver(struct cpufreq_driver *driver)</span>
 
 	pr_debug(&quot;unregistering driver %s\n&quot;, driver-&gt;name);
 
<span class="p_add">+	/* Protect against concurrent cpu hotplug */</span>
<span class="p_add">+	get_online_cpus();</span>
 	subsys_interface_unregister(&amp;cpufreq_interface);
 	if (cpufreq_boost_supported())
 		cpufreq_sysfs_remove_file(&amp;boost.attr);
 
 	unregister_hotcpu_notifier(&amp;cpufreq_cpu_notifier);
 
<span class="p_del">-	down_write(&amp;cpufreq_rwsem);</span>
 	write_lock_irqsave(&amp;cpufreq_driver_lock, flags);
 
 	cpufreq_driver = NULL;
 
 	write_unlock_irqrestore(&amp;cpufreq_driver_lock, flags);
<span class="p_del">-	up_write(&amp;cpufreq_rwsem);</span>
<span class="p_add">+	put_online_cpus();</span>
 
 	return 0;
 }
<span class="p_header">diff --git a/include/linux/interrupt.h b/include/linux/interrupt.h</span>
<span class="p_header">index 33cfbc085a94..86628c733be7 100644</span>
<span class="p_header">--- a/include/linux/interrupt.h</span>
<span class="p_header">+++ b/include/linux/interrupt.h</span>
<span class="p_chunk">@@ -100,6 +100,7 @@</span> <span class="p_context"> typedef irqreturn_t (*irq_handler_t)(int, void *);</span>
  * @flags:	flags (see IRQF_* above)
  * @thread_fn:	interrupt handler function for threaded interrupts
  * @thread:	thread pointer for threaded interrupts
<span class="p_add">+ * @secondary:	pointer to secondary irqaction (force threading)</span>
  * @thread_flags:	flags related to @thread
  * @thread_mask:	bitmask for keeping track of @thread activity
  * @dir:	pointer to the proc/irq/NN/name entry
<span class="p_chunk">@@ -111,6 +112,7 @@</span> <span class="p_context"> struct irqaction {</span>
 	struct irqaction	*next;
 	irq_handler_t		thread_fn;
 	struct task_struct	*thread;
<span class="p_add">+	struct irqaction	*secondary;</span>
 	unsigned int		irq;
 	unsigned int		flags;
 	unsigned long		thread_flags;
<span class="p_header">diff --git a/include/linux/irq_work.h b/include/linux/irq_work.h</span>
<span class="p_header">index 30ef6c214e6f..af7ed9ad52c3 100644</span>
<span class="p_header">--- a/include/linux/irq_work.h</span>
<span class="p_header">+++ b/include/linux/irq_work.h</span>
<span class="p_chunk">@@ -51,4 +51,10 @@</span> <span class="p_context"> bool irq_work_needs_cpu(void);</span>
 static inline bool irq_work_needs_cpu(void) { return false; }
 #endif
 
<span class="p_add">+#if defined(CONFIG_IRQ_WORK) &amp;&amp; defined(CONFIG_PREEMPT_RT_FULL)</span>
<span class="p_add">+void irq_work_tick_soft(void);</span>
<span class="p_add">+#else</span>
<span class="p_add">+static inline void irq_work_tick_soft(void) { }</span>
<span class="p_add">+#endif</span>
<span class="p_add">+</span>
 #endif /* _LINUX_IRQ_WORK_H */
<span class="p_header">diff --git a/include/trace/events/sched.h b/include/trace/events/sched.h</span>
<span class="p_header">index a7d67bc14906..09f27eb85ef8 100644</span>
<span class="p_header">--- a/include/trace/events/sched.h</span>
<span class="p_header">+++ b/include/trace/events/sched.h</span>
<span class="p_chunk">@@ -55,9 +55,9 @@</span> <span class="p_context"> TRACE_EVENT(sched_kthread_stop_ret,</span>
  */
 DECLARE_EVENT_CLASS(sched_wakeup_template,
 
<span class="p_del">-	TP_PROTO(struct task_struct *p, int success),</span>
<span class="p_add">+	TP_PROTO(struct task_struct *p),</span>
 
<span class="p_del">-	TP_ARGS(__perf_task(p), success),</span>
<span class="p_add">+	TP_ARGS(__perf_task(p)),</span>
 
 	TP_STRUCT__entry(
 		__array(	char,	comm,	TASK_COMM_LEN	)
<span class="p_chunk">@@ -71,25 +71,37 @@</span> <span class="p_context"> DECLARE_EVENT_CLASS(sched_wakeup_template,</span>
 		memcpy(__entry-&gt;comm, p-&gt;comm, TASK_COMM_LEN);
 		__entry-&gt;pid		= p-&gt;pid;
 		__entry-&gt;prio		= p-&gt;prio;
<span class="p_del">-		__entry-&gt;success	= success;</span>
<span class="p_add">+		__entry-&gt;success	= 1; /* rudiment, kill when possible */</span>
 		__entry-&gt;target_cpu	= task_cpu(p);
 	),
 
<span class="p_del">-	TP_printk(&quot;comm=%s pid=%d prio=%d success=%d target_cpu=%03d&quot;,</span>
<span class="p_add">+	TP_printk(&quot;comm=%s pid=%d prio=%d target_cpu=%03d&quot;,</span>
 		  __entry-&gt;comm, __entry-&gt;pid, __entry-&gt;prio,
<span class="p_del">-		  __entry-&gt;success, __entry-&gt;target_cpu)</span>
<span class="p_add">+		  __entry-&gt;target_cpu)</span>
 );
 
<span class="p_add">+/*</span>
<span class="p_add">+ * Tracepoint called when waking a task; this tracepoint is guaranteed to be</span>
<span class="p_add">+ * called from the waking context.</span>
<span class="p_add">+ */</span>
<span class="p_add">+DEFINE_EVENT(sched_wakeup_template, sched_waking,</span>
<span class="p_add">+	     TP_PROTO(struct task_struct *p),</span>
<span class="p_add">+	     TP_ARGS(p));</span>
<span class="p_add">+</span>
<span class="p_add">+/*</span>
<span class="p_add">+ * Tracepoint called when the task is actually woken; p-&gt;state == TASK_RUNNNG.</span>
<span class="p_add">+ * It it not always called from the waking context.</span>
<span class="p_add">+ */</span>
 DEFINE_EVENT(sched_wakeup_template, sched_wakeup,
<span class="p_del">-	     TP_PROTO(struct task_struct *p, int success),</span>
<span class="p_del">-	     TP_ARGS(p, success));</span>
<span class="p_add">+	     TP_PROTO(struct task_struct *p),</span>
<span class="p_add">+	     TP_ARGS(p));</span>
 
 /*
  * Tracepoint for waking up a new task:
  */
 DEFINE_EVENT(sched_wakeup_template, sched_wakeup_new,
<span class="p_del">-	     TP_PROTO(struct task_struct *p, int success),</span>
<span class="p_del">-	     TP_ARGS(p, success));</span>
<span class="p_add">+	     TP_PROTO(struct task_struct *p),</span>
<span class="p_add">+	     TP_ARGS(p));</span>
 
 #ifdef CREATE_TRACE_POINTS
 static inline long __trace_sched_switch_state(struct task_struct *p)
<span class="p_header">diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c</span>
<span class="p_header">index 382cbe57abf3..70f59992c201 100644</span>
<span class="p_header">--- a/kernel/irq/manage.c</span>
<span class="p_header">+++ b/kernel/irq/manage.c</span>
<span class="p_chunk">@@ -735,6 +735,12 @@</span> <span class="p_context"> static irqreturn_t irq_nested_primary_handler(int irq, void *dev_id)</span>
 	return IRQ_NONE;
 }
 
<span class="p_add">+static irqreturn_t irq_forced_secondary_handler(int irq, void *dev_id)</span>
<span class="p_add">+{</span>
<span class="p_add">+	WARN(1, &quot;Secondary action handler called for irq %d\n&quot;, irq);</span>
<span class="p_add">+	return IRQ_NONE;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static int irq_wait_for_interrupt(struct irqaction *action)
 {
 	set_current_state(TASK_INTERRUPTIBLE);
<span class="p_chunk">@@ -761,7 +767,8 @@</span> <span class="p_context"> static int irq_wait_for_interrupt(struct irqaction *action)</span>
 static void irq_finalize_oneshot(struct irq_desc *desc,
 				 struct irqaction *action)
 {
<span class="p_del">-	if (!(desc-&gt;istate &amp; IRQS_ONESHOT))</span>
<span class="p_add">+	if (!(desc-&gt;istate &amp; IRQS_ONESHOT) ||</span>
<span class="p_add">+	    action-&gt;handler == irq_forced_secondary_handler)</span>
 		return;
 again:
 	chip_bus_lock(desc);
<span class="p_chunk">@@ -923,6 +930,18 @@</span> <span class="p_context"> static void irq_thread_dtor(struct callback_head *unused)</span>
 	irq_finalize_oneshot(desc, action);
 }
 
<span class="p_add">+static void irq_wake_secondary(struct irq_desc *desc, struct irqaction *action)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct irqaction *secondary = action-&gt;secondary;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (WARN_ON_ONCE(!secondary))</span>
<span class="p_add">+		return;</span>
<span class="p_add">+</span>
<span class="p_add">+	raw_spin_lock_irq(&amp;desc-&gt;lock);</span>
<span class="p_add">+	__irq_wake_thread(desc, secondary);</span>
<span class="p_add">+	raw_spin_unlock_irq(&amp;desc-&gt;lock);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 /*
  * Interrupt handler thread
  */
<span class="p_chunk">@@ -953,6 +972,8 @@</span> <span class="p_context"> static int irq_thread(void *data)</span>
 		action_ret = handler_fn(desc, action);
 		if (action_ret == IRQ_HANDLED)
 			atomic_inc(&amp;desc-&gt;threads_handled);
<span class="p_add">+		if (action_ret == IRQ_WAKE_THREAD)</span>
<span class="p_add">+			irq_wake_secondary(desc, action);</span>
 
 #ifdef CONFIG_PREEMPT_RT_FULL
 		migrate_disable();
<span class="p_chunk">@@ -1003,20 +1024,36 @@</span> <span class="p_context"> void irq_wake_thread(unsigned int irq, void *dev_id)</span>
 }
 EXPORT_SYMBOL_GPL(irq_wake_thread);
 
<span class="p_del">-static void irq_setup_forced_threading(struct irqaction *new)</span>
<span class="p_add">+static int irq_setup_forced_threading(struct irqaction *new)</span>
 {
 	if (!force_irqthreads)
<span class="p_del">-		return;</span>
<span class="p_add">+		return 0;</span>
 	if (new-&gt;flags &amp; (IRQF_NO_THREAD | IRQF_PERCPU | IRQF_ONESHOT))
<span class="p_del">-		return;</span>
<span class="p_add">+		return 0;</span>
 
 	new-&gt;flags |= IRQF_ONESHOT;
 
<span class="p_del">-	if (!new-&gt;thread_fn) {</span>
<span class="p_del">-		set_bit(IRQTF_FORCED_THREAD, &amp;new-&gt;thread_flags);</span>
<span class="p_del">-		new-&gt;thread_fn = new-&gt;handler;</span>
<span class="p_del">-		new-&gt;handler = irq_default_primary_handler;</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Handle the case where we have a real primary handler and a</span>
<span class="p_add">+	 * thread handler. We force thread them as well by creating a</span>
<span class="p_add">+	 * secondary action.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	if (new-&gt;handler != irq_default_primary_handler &amp;&amp; new-&gt;thread_fn) {</span>
<span class="p_add">+		/* Allocate the secondary action */</span>
<span class="p_add">+		new-&gt;secondary = kzalloc(sizeof(struct irqaction), GFP_KERNEL);</span>
<span class="p_add">+		if (!new-&gt;secondary)</span>
<span class="p_add">+			return -ENOMEM;</span>
<span class="p_add">+		new-&gt;secondary-&gt;handler = irq_forced_secondary_handler;</span>
<span class="p_add">+		new-&gt;secondary-&gt;thread_fn = new-&gt;thread_fn;</span>
<span class="p_add">+		new-&gt;secondary-&gt;dev_id = new-&gt;dev_id;</span>
<span class="p_add">+		new-&gt;secondary-&gt;irq = new-&gt;irq;</span>
<span class="p_add">+		new-&gt;secondary-&gt;name = new-&gt;name;</span>
 	}
<span class="p_add">+	/* Deal with the primary handler */</span>
<span class="p_add">+	set_bit(IRQTF_FORCED_THREAD, &amp;new-&gt;thread_flags);</span>
<span class="p_add">+	new-&gt;thread_fn = new-&gt;handler;</span>
<span class="p_add">+	new-&gt;handler = irq_default_primary_handler;</span>
<span class="p_add">+	return 0;</span>
 }
 
 static int irq_request_resources(struct irq_desc *desc)
<span class="p_chunk">@@ -1036,6 +1073,48 @@</span> <span class="p_context"> static void irq_release_resources(struct irq_desc *desc)</span>
 		c-&gt;irq_release_resources(d);
 }
 
<span class="p_add">+static int</span>
<span class="p_add">+setup_irq_thread(struct irqaction *new, unsigned int irq, bool secondary)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct task_struct *t;</span>
<span class="p_add">+	struct sched_param param = {</span>
<span class="p_add">+		.sched_priority = MAX_USER_RT_PRIO/2,</span>
<span class="p_add">+	};</span>
<span class="p_add">+</span>
<span class="p_add">+	if (!secondary) {</span>
<span class="p_add">+		t = kthread_create(irq_thread, new, &quot;irq/%d-%s&quot;, irq,</span>
<span class="p_add">+				   new-&gt;name);</span>
<span class="p_add">+	} else {</span>
<span class="p_add">+		t = kthread_create(irq_thread, new, &quot;irq/%d-s-%s&quot;, irq,</span>
<span class="p_add">+				   new-&gt;name);</span>
<span class="p_add">+		param.sched_priority += 1;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	if (IS_ERR(t))</span>
<span class="p_add">+		return PTR_ERR(t);</span>
<span class="p_add">+</span>
<span class="p_add">+	sched_setscheduler_nocheck(t, SCHED_FIFO, &amp;param);</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * We keep the reference to the task struct even if</span>
<span class="p_add">+	 * the thread dies to avoid that the interrupt code</span>
<span class="p_add">+	 * references an already freed task_struct.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	get_task_struct(t);</span>
<span class="p_add">+	new-&gt;thread = t;</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Tell the thread to set its affinity. This is</span>
<span class="p_add">+	 * important for shared interrupt handlers as we do</span>
<span class="p_add">+	 * not invoke setup_affinity() for the secondary</span>
<span class="p_add">+	 * handlers as everything is already set up. Even for</span>
<span class="p_add">+	 * interrupts marked with IRQF_NO_BALANCE this is</span>
<span class="p_add">+	 * correct as we want the thread to move to the cpu(s)</span>
<span class="p_add">+	 * on which the requesting code placed the interrupt.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	set_bit(IRQTF_AFFINITY, &amp;new-&gt;thread_flags);</span>
<span class="p_add">+	return 0;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 /*
  * Internal function to register an irqaction - typically used to
  * allocate special interrupts that are part of the architecture.
<span class="p_chunk">@@ -1056,6 +1135,8 @@</span> <span class="p_context"> __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)</span>
 	if (!try_module_get(desc-&gt;owner))
 		return -ENODEV;
 
<span class="p_add">+	new-&gt;irq = irq;</span>
<span class="p_add">+</span>
 	/*
 	 * Check whether the interrupt nests into another interrupt
 	 * thread.
<span class="p_chunk">@@ -1073,8 +1154,11 @@</span> <span class="p_context"> __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)</span>
 		 */
 		new-&gt;handler = irq_nested_primary_handler;
 	} else {
<span class="p_del">-		if (irq_settings_can_thread(desc))</span>
<span class="p_del">-			irq_setup_forced_threading(new);</span>
<span class="p_add">+		if (irq_settings_can_thread(desc)) {</span>
<span class="p_add">+			ret = irq_setup_forced_threading(new);</span>
<span class="p_add">+			if (ret)</span>
<span class="p_add">+				goto out_mput;</span>
<span class="p_add">+		}</span>
 	}
 
 	/*
<span class="p_chunk">@@ -1083,37 +1167,14 @@</span> <span class="p_context"> __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)</span>
 	 * thread.
 	 */
 	if (new-&gt;thread_fn &amp;&amp; !nested) {
<span class="p_del">-		struct task_struct *t;</span>
<span class="p_del">-		static const struct sched_param param = {</span>
<span class="p_del">-			.sched_priority = MAX_USER_RT_PRIO/2,</span>
<span class="p_del">-		};</span>
<span class="p_del">-</span>
<span class="p_del">-		t = kthread_create(irq_thread, new, &quot;irq/%d-%s&quot;, irq,</span>
<span class="p_del">-				   new-&gt;name);</span>
<span class="p_del">-		if (IS_ERR(t)) {</span>
<span class="p_del">-			ret = PTR_ERR(t);</span>
<span class="p_add">+		ret = setup_irq_thread(new, irq, false);</span>
<span class="p_add">+		if (ret)</span>
 			goto out_mput;
<span class="p_add">+		if (new-&gt;secondary) {</span>
<span class="p_add">+			ret = setup_irq_thread(new-&gt;secondary, irq, true);</span>
<span class="p_add">+			if (ret)</span>
<span class="p_add">+				goto out_thread;</span>
 		}
<span class="p_del">-</span>
<span class="p_del">-		sched_setscheduler_nocheck(t, SCHED_FIFO, &amp;param);</span>
<span class="p_del">-</span>
<span class="p_del">-		/*</span>
<span class="p_del">-		 * We keep the reference to the task struct even if</span>
<span class="p_del">-		 * the thread dies to avoid that the interrupt code</span>
<span class="p_del">-		 * references an already freed task_struct.</span>
<span class="p_del">-		 */</span>
<span class="p_del">-		get_task_struct(t);</span>
<span class="p_del">-		new-&gt;thread = t;</span>
<span class="p_del">-		/*</span>
<span class="p_del">-		 * Tell the thread to set its affinity. This is</span>
<span class="p_del">-		 * important for shared interrupt handlers as we do</span>
<span class="p_del">-		 * not invoke setup_affinity() for the secondary</span>
<span class="p_del">-		 * handlers as everything is already set up. Even for</span>
<span class="p_del">-		 * interrupts marked with IRQF_NO_BALANCE this is</span>
<span class="p_del">-		 * correct as we want the thread to move to the cpu(s)</span>
<span class="p_del">-		 * on which the requesting code placed the interrupt.</span>
<span class="p_del">-		 */</span>
<span class="p_del">-		set_bit(IRQTF_AFFINITY, &amp;new-&gt;thread_flags);</span>
 	}
 
 	if (!alloc_cpumask_var(&amp;mask, GFP_KERNEL)) {
<span class="p_chunk">@@ -1289,7 +1350,6 @@</span> <span class="p_context"> __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)</span>
 				   irq, nmsk, omsk);
 	}
 
<span class="p_del">-	new-&gt;irq = irq;</span>
 	*old_ptr = new;
 
 	irq_pm_install_action(desc, new);
<span class="p_chunk">@@ -1315,6 +1375,8 @@</span> <span class="p_context"> __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)</span>
 	 */
 	if (new-&gt;thread)
 		wake_up_process(new-&gt;thread);
<span class="p_add">+	if (new-&gt;secondary)</span>
<span class="p_add">+		wake_up_process(new-&gt;secondary-&gt;thread);</span>
 
 	register_irq_proc(irq, desc);
 	new-&gt;dir = NULL;
<span class="p_chunk">@@ -1345,6 +1407,13 @@</span> <span class="p_context"> out_thread:</span>
 		kthread_stop(t);
 		put_task_struct(t);
 	}
<span class="p_add">+	if (new-&gt;secondary &amp;&amp; new-&gt;secondary-&gt;thread) {</span>
<span class="p_add">+		struct task_struct *t = new-&gt;secondary-&gt;thread;</span>
<span class="p_add">+</span>
<span class="p_add">+		new-&gt;secondary-&gt;thread = NULL;</span>
<span class="p_add">+		kthread_stop(t);</span>
<span class="p_add">+		put_task_struct(t);</span>
<span class="p_add">+	}</span>
 out_mput:
 	module_put(desc-&gt;owner);
 	return ret;
<span class="p_chunk">@@ -1452,9 +1521,14 @@</span> <span class="p_context"> static struct irqaction *__free_irq(unsigned int irq, void *dev_id)</span>
 	if (action-&gt;thread) {
 		kthread_stop(action-&gt;thread);
 		put_task_struct(action-&gt;thread);
<span class="p_add">+		if (action-&gt;secondary &amp;&amp; action-&gt;secondary-&gt;thread) {</span>
<span class="p_add">+			kthread_stop(action-&gt;secondary-&gt;thread);</span>
<span class="p_add">+			put_task_struct(action-&gt;secondary-&gt;thread);</span>
<span class="p_add">+		}</span>
 	}
 
 	module_put(desc-&gt;owner);
<span class="p_add">+	kfree(action-&gt;secondary);</span>
 	return action;
 }
 
<span class="p_chunk">@@ -1593,8 +1667,10 @@</span> <span class="p_context"> int request_threaded_irq(unsigned int irq, irq_handler_t handler,</span>
 	retval = __setup_irq(irq, desc, action);
 	chip_bus_sync_unlock(desc);
 
<span class="p_del">-	if (retval)</span>
<span class="p_add">+	if (retval) {</span>
<span class="p_add">+		kfree(action-&gt;secondary);</span>
 		kfree(action);
<span class="p_add">+	}</span>
 
 #ifdef CONFIG_DEBUG_SHIRQ_FIXME
 	if (!retval &amp;&amp; (irqflags &amp; IRQF_SHARED)) {
<span class="p_header">diff --git a/kernel/irq_work.c b/kernel/irq_work.c</span>
<span class="p_header">index 9678fd1382a7..3d5a476b58b9 100644</span>
<span class="p_header">--- a/kernel/irq_work.c</span>
<span class="p_header">+++ b/kernel/irq_work.c</span>
<span class="p_chunk">@@ -200,8 +200,17 @@</span> <span class="p_context"> void irq_work_tick(void)</span>
 
 	if (!llist_empty(raised) &amp;&amp; !arch_irq_work_has_interrupt())
 		irq_work_run_list(raised);
<span class="p_add">+</span>
<span class="p_add">+	if (!IS_ENABLED(CONFIG_PREEMPT_RT_FULL))</span>
<span class="p_add">+		irq_work_run_list(this_cpu_ptr(&amp;lazy_list));</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+#if defined(CONFIG_IRQ_WORK) &amp;&amp; defined(CONFIG_PREEMPT_RT_FULL)</span>
<span class="p_add">+void irq_work_tick_soft(void)</span>
<span class="p_add">+{</span>
 	irq_work_run_list(this_cpu_ptr(&amp;lazy_list));
 }
<span class="p_add">+#endif</span>
 
 /*
  * Synchronize against the irq_work @entry, ensures the entry is not
<span class="p_header">diff --git a/kernel/locking/locktorture.c b/kernel/locking/locktorture.c</span>
<span class="p_header">index ec8cce259779..aa60d919e336 100644</span>
<span class="p_header">--- a/kernel/locking/locktorture.c</span>
<span class="p_header">+++ b/kernel/locking/locktorture.c</span>
<span class="p_chunk">@@ -24,7 +24,6 @@</span> <span class="p_context"></span>
 #include &lt;linux/module.h&gt;
 #include &lt;linux/kthread.h&gt;
 #include &lt;linux/spinlock.h&gt;
<span class="p_del">-#include &lt;linux/rwlock.h&gt;</span>
 #include &lt;linux/mutex.h&gt;
 #include &lt;linux/rwsem.h&gt;
 #include &lt;linux/smp.h&gt;
<span class="p_header">diff --git a/kernel/locking/rtmutex.c b/kernel/locking/rtmutex.c</span>
<span class="p_header">index 64973df0c686..8d950b4521fc 100644</span>
<span class="p_header">--- a/kernel/locking/rtmutex.c</span>
<span class="p_header">+++ b/kernel/locking/rtmutex.c</span>
<span class="p_chunk">@@ -1008,7 +1008,7 @@</span> <span class="p_context"> static void  noinline __sched rt_spin_lock_slowlock(struct rt_mutex *lock)</span>
 	__set_current_state(TASK_UNINTERRUPTIBLE);
 	pi_unlock(&amp;self-&gt;pi_lock);
 
<span class="p_del">-	ret = task_blocks_on_rt_mutex(lock, &amp;waiter, self, 0);</span>
<span class="p_add">+	ret = task_blocks_on_rt_mutex(lock, &amp;waiter, self, RT_MUTEX_MIN_CHAINWALK);</span>
 	BUG_ON(ret);
 
 	for (;;) {
<span class="p_chunk">@@ -2144,7 +2144,7 @@</span> <span class="p_context"> int rt_mutex_start_proxy_lock(struct rt_mutex *lock,</span>
 		ret = 0;
 	}
 
<span class="p_del">-	if (unlikely(ret))</span>
<span class="p_add">+	if (ret &amp;&amp; rt_mutex_has_waiters(lock))</span>
 		remove_waiter(lock, waiter);
 
 	raw_spin_unlock(&amp;lock-&gt;wait_lock);
<span class="p_header">diff --git a/kernel/sched/core.c b/kernel/sched/core.c</span>
<span class="p_header">index 7e844b4f1701..9e01a8f358f8 100644</span>
<span class="p_header">--- a/kernel/sched/core.c</span>
<span class="p_header">+++ b/kernel/sched/core.c</span>
<span class="p_chunk">@@ -1606,9 +1606,9 @@</span> <span class="p_context"> static void</span>
 ttwu_do_wakeup(struct rq *rq, struct task_struct *p, int wake_flags)
 {
 	check_preempt_curr(rq, p, wake_flags);
<span class="p_del">-	trace_sched_wakeup(p, true);</span>
<span class="p_del">-</span>
 	p-&gt;state = TASK_RUNNING;
<span class="p_add">+	trace_sched_wakeup(p);</span>
<span class="p_add">+</span>
 #ifdef CONFIG_SMP
 	if (p-&gt;sched_class-&gt;task_woken)
 		p-&gt;sched_class-&gt;task_woken(rq, p);
<span class="p_chunk">@@ -1832,6 +1832,8 @@</span> <span class="p_context"> try_to_wake_up(struct task_struct *p, unsigned int state, int wake_flags)</span>
 	if (!(wake_flags &amp; WF_LOCK_SLEEPER))
 		p-&gt;saved_state = TASK_RUNNING;
 
<span class="p_add">+	trace_sched_waking(p);</span>
<span class="p_add">+</span>
 	success = 1; /* we&#39;re going to change -&gt;state */
 	cpu = task_cpu(p);
 
<span class="p_chunk">@@ -2247,7 +2249,7 @@</span> <span class="p_context"> void wake_up_new_task(struct task_struct *p)</span>
 	rq = __task_rq_lock(p);
 	activate_task(rq, p, 0);
 	p-&gt;on_rq = TASK_ON_RQ_QUEUED;
<span class="p_del">-	trace_sched_wakeup_new(p, true);</span>
<span class="p_add">+	trace_sched_wakeup_new(p);</span>
 	check_preempt_curr(rq, p, WF_FORK);
 #ifdef CONFIG_SMP
 	if (p-&gt;sched_class-&gt;task_woken)
<span class="p_header">diff --git a/kernel/time/timer.c b/kernel/time/timer.c</span>
<span class="p_header">index 3a978d000fce..78e39b644780 100644</span>
<span class="p_header">--- a/kernel/time/timer.c</span>
<span class="p_header">+++ b/kernel/time/timer.c</span>
<span class="p_chunk">@@ -1451,7 +1451,7 @@</span> <span class="p_context"> void update_process_times(int user_tick)</span>
 	run_local_timers();
 	rcu_check_callbacks(cpu, user_tick);
 
<span class="p_del">-#if defined(CONFIG_IRQ_WORK) &amp;&amp; !defined(CONFIG_PREEMPT_RT_FULL)</span>
<span class="p_add">+#if defined(CONFIG_IRQ_WORK)</span>
 	if (in_irq())
 		irq_work_tick();
 #endif
<span class="p_chunk">@@ -1467,9 +1467,7 @@</span> <span class="p_context"> static void run_timer_softirq(struct softirq_action *h)</span>
 
 	hrtimer_run_pending();
 
<span class="p_del">-#if defined(CONFIG_IRQ_WORK) &amp;&amp; defined(CONFIG_PREEMPT_RT_FULL)</span>
<span class="p_del">-	irq_work_tick();</span>
<span class="p_del">-#endif</span>
<span class="p_add">+	irq_work_tick_soft();</span>
 
 	if (time_after_eq(jiffies, base-&gt;timer_jiffies))
 		__run_timers(base);
<span class="p_header">diff --git a/kernel/trace/trace_sched_switch.c b/kernel/trace/trace_sched_switch.c</span>
<span class="p_header">index 3f34dc9b40f3..9586cde520b0 100644</span>
<span class="p_header">--- a/kernel/trace/trace_sched_switch.c</span>
<span class="p_header">+++ b/kernel/trace/trace_sched_switch.c</span>
<span class="p_chunk">@@ -106,7 +106,7 @@</span> <span class="p_context"> tracing_sched_wakeup_trace(struct trace_array *tr,</span>
 }
 
 static void
<span class="p_del">-probe_sched_wakeup(void *ignore, struct task_struct *wakee, int success)</span>
<span class="p_add">+probe_sched_wakeup(void *ignore, struct task_struct *wakee)</span>
 {
 	struct trace_array_cpu *data;
 	unsigned long flags;
<span class="p_header">diff --git a/kernel/trace/trace_sched_wakeup.c b/kernel/trace/trace_sched_wakeup.c</span>
<span class="p_header">index 19bd8928ce94..808258ccf6c5 100644</span>
<span class="p_header">--- a/kernel/trace/trace_sched_wakeup.c</span>
<span class="p_header">+++ b/kernel/trace/trace_sched_wakeup.c</span>
<span class="p_chunk">@@ -460,7 +460,7 @@</span> <span class="p_context"> static void wakeup_reset(struct trace_array *tr)</span>
 }
 
 static void
<span class="p_del">-probe_wakeup(void *ignore, struct task_struct *p, int success)</span>
<span class="p_add">+probe_wakeup(void *ignore, struct task_struct *p)</span>
 {
 	struct trace_array_cpu *data;
 	int cpu = smp_processor_id();
<span class="p_header">diff --git a/lib/dump_stack.c b/lib/dump_stack.c</span>
<span class="p_header">index c30d07e99dba..01ca6dae9414 100644</span>
<span class="p_header">--- a/lib/dump_stack.c</span>
<span class="p_header">+++ b/lib/dump_stack.c</span>
<span class="p_chunk">@@ -25,7 +25,6 @@</span> <span class="p_context"> static atomic_t dump_lock = ATOMIC_INIT(-1);</span>
 
 asmlinkage __visible void dump_stack(void)
 {
<span class="p_del">-	unsigned long flags;</span>
 	int was_locked;
 	int old;
 	int cpu;
<span class="p_chunk">@@ -34,8 +33,8 @@</span> <span class="p_context"> asmlinkage __visible void dump_stack(void)</span>
 	 * Permit this cpu to perform nested stack dumps while serialising
 	 * against other CPUs
 	 */
<span class="p_add">+	migrate_disable();</span>
 retry:
<span class="p_del">-	local_irq_save(flags);</span>
 	cpu = smp_processor_id();
 	old = atomic_cmpxchg(&amp;dump_lock, -1, cpu);
 	if (old == -1) {
<span class="p_chunk">@@ -43,7 +42,6 @@</span> <span class="p_context"> retry:</span>
 	} else if (old == cpu) {
 		was_locked = 1;
 	} else {
<span class="p_del">-		local_irq_restore(flags);</span>
 		cpu_relax();
 		goto retry;
 	}
<span class="p_chunk">@@ -53,7 +51,7 @@</span> <span class="p_context"> retry:</span>
 	if (!was_locked)
 		atomic_set(&amp;dump_lock, -1);
 
<span class="p_del">-	local_irq_restore(flags);</span>
<span class="p_add">+	migrate_enable();</span>
 }
 #else
 asmlinkage __visible void dump_stack(void)
<span class="p_header">diff --git a/localversion-rt b/localversion-rt</span>
<span class="p_header">index c5b71f9a229d..2e9afd4a0afd 100644</span>
<span class="p_header">--- a/localversion-rt</span>
<span class="p_header">+++ b/localversion-rt</span>
<span class="p_chunk">@@ -1 +1 @@</span> <span class="p_context"></span>
<span class="p_del">--rt25</span>
<span class="p_add">+-rt26</span>
<span class="p_header">diff --git a/net/core/dev.c b/net/core/dev.c</span>
<span class="p_header">index 1cbcf08cc224..39d2a0ba38ed 100644</span>
<span class="p_header">--- a/net/core/dev.c</span>
<span class="p_header">+++ b/net/core/dev.c</span>
<span class="p_chunk">@@ -6813,7 +6813,7 @@</span> <span class="p_context"> EXPORT_SYMBOL(free_netdev);</span>
 void synchronize_net(void)
 {
 	might_sleep();
<span class="p_del">-	if (rtnl_is_locked())</span>
<span class="p_add">+	if (rtnl_is_locked() &amp;&amp; !IS_ENABLED(CONFIG_PREEMPT_RT_FULL))</span>
 		synchronize_rcu_expedited();
 	else
 		synchronize_rcu();
<span class="p_chunk">@@ -7065,7 +7065,7 @@</span> <span class="p_context"> static int dev_cpu_callback(struct notifier_block *nfb,</span>
 		netif_rx_internal(skb);
 		input_queue_head_incr(oldsd);
 	}
<span class="p_del">-	while ((skb = skb_dequeue(&amp;oldsd-&gt;input_pkt_queue))) {</span>
<span class="p_add">+	while ((skb = __skb_dequeue(&amp;oldsd-&gt;input_pkt_queue))) {</span>
 		netif_rx_internal(skb);
 		input_queue_head_incr(oldsd);
 	}

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



