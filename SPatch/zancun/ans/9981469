
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>[RFC,v2,30/31] KVM: arm64: Emulate TLBI instructions accesible from EL1 - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    [RFC,v2,30/31] KVM: arm64: Emulate TLBI instructions accesible from EL1</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=174677">Jintack Lim</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>Oct. 3, 2017, 3:11 a.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;1507000273-3735-28-git-send-email-jintack.lim@linaro.org&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/9981469/mbox/"
   >mbox</a>
|
   <a href="/patch/9981469/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/9981469/">/patch/9981469/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
	[172.30.200.125])
	by pdx-korg-patchwork.web.codeaurora.org (Postfix) with ESMTP id
	B113060384 for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Tue,  3 Oct 2017 03:12:58 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id A36AA2881D
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Tue,  3 Oct 2017 03:12:58 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id 9744428822; Tue,  3 Oct 2017 03:12:58 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-6.5 required=2.0 tests=BAYES_00,DKIM_SIGNED,
	DKIM_VALID, DKIM_VALID_AU, RCVD_IN_DNSWL_HI,
	RCVD_IN_SORBS_SPAM autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id A5AD72881D
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Tue,  3 Oct 2017 03:12:57 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1751833AbdJCDM4 (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Mon, 2 Oct 2017 23:12:56 -0400
Received: from mail-it0-f46.google.com ([209.85.214.46]:48286 &quot;EHLO
	mail-it0-f46.google.com&quot; rhost-flags-OK-OK-OK-OK) by vger.kernel.org
	with ESMTP id S1752019AbdJCDMN (ORCPT
	&lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Mon, 2 Oct 2017 23:12:13 -0400
Received: by mail-it0-f46.google.com with SMTP id m123so10019152ita.3
	for &lt;linux-kernel@vger.kernel.org&gt;;
	Mon, 02 Oct 2017 20:12:12 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed; d=linaro.org; s=google;
	h=from:to:cc:subject:date:message-id:in-reply-to:references;
	bh=pAiPmFwFxMcTXQhMqBTVIE4zrReCYLZM+nCfRdFLbvs=;
	b=gx7EwkcuYNL00dgNPvCupNYQGsM6Jnuwp7ss3Xm1O7DwOC6srj/dr5KLCADlNH3T1U
	q99dxIGc8B6ELkcWrb902J1f2GfAJZRJVdVZTCiXchWmgHsDLaYZo67Zefb4YMAxNwsj
	KL09V+H7iDRGBIPyNi+dsEj2G1bGXo/CI7l7o=
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
	d=1e100.net; s=20161025;
	h=x-gm-message-state:from:to:cc:subject:date:message-id:in-reply-to
	:references;
	bh=pAiPmFwFxMcTXQhMqBTVIE4zrReCYLZM+nCfRdFLbvs=;
	b=oeaYLPrNC7RYRm+N8Bc2AMnuMPxEoD8YShCXkyiDWii9c3XcvyCe6PVnCIwlwSInTP
	axDEN0kfOVJlmmQONKMPGwu0KDg4ILNal7yhaltFeCFVjYK05pg8AKq0LeeNzcQGVobb
	LB8uv9aM1v+Y3zjFlXVUzWd9wa+QPS7PT/yBz5P8AHklSNNFi2IYI31jxf+aviR4KF99
	9DurWLiVBVnYR+S0qcooxR9WD/SG/W4ccg6iLZDR39eclUkc1uuWk8o73nZcSiaWgDui
	5s8titcJH+fB2Xj7Z1G//JxWkRlrKuFEWHwfjFKBX3GOddtNT4YF47NBVcs9PVK0vktl
	hf6w==
X-Gm-Message-State: AMCzsaXLTH85+RpNvpkg54V0pcUIqO08pj2Lxt05XuXhniSwXrIaF1uX
	97K5ukbtHzdv2lWrW17wzdUqvQ==
X-Google-Smtp-Source: AOwi7QDH8wtRzaJkESZEuIwsRs2uqv5n0H1pApy+7w09EwsOIPBjRT7d9Q3+pbmWxp7L0XF8MHTcLQ==
X-Received: by 10.36.84.82 with SMTP id t79mr22628266ita.98.1507000332416;
	Mon, 02 Oct 2017 20:12:12 -0700 (PDT)
Received: from node.jintackl-qv28633.kvmarm-pg0.wisc.cloudlab.us
	(c220g1-031126.wisc.cloudlab.us. [128.104.222.76])
	by smtp.gmail.com with ESMTPSA id
	h84sm5367193iod.72.2017.10.02.20.12.11
	(version=TLS1_2 cipher=ECDHE-RSA-AES128-SHA bits=128/128);
	Mon, 02 Oct 2017 20:12:11 -0700 (PDT)
From: Jintack Lim &lt;jintack.lim@linaro.org&gt;
To: christoffer.dall@linaro.org, marc.zyngier@arm.com,
	kvmarm@lists.cs.columbia.edu
Cc: jintack@cs.columbia.edu, pbonzini@redhat.com, rkrcmar@redhat.com,
	catalin.marinas@arm.com, will.deacon@arm.com,
	linux@armlinux.org.uk, mark.rutland@arm.com,
	linux-arm-kernel@lists.infradead.org, kvm@vger.kernel.org,
	linux-kernel@vger.kernel.org, Jintack Lim &lt;jintack.lim@linaro.org&gt;
Subject: [RFC PATCH v2 30/31] KVM: arm64: Emulate TLBI instructions
	accesible from EL1
Date: Mon,  2 Oct 2017 22:11:12 -0500
Message-Id: &lt;1507000273-3735-28-git-send-email-jintack.lim@linaro.org&gt;
X-Mailer: git-send-email 1.9.1
In-Reply-To: &lt;1507000273-3735-1-git-send-email-jintack.lim@linaro.org&gt;
References: &lt;1507000273-3735-1-git-send-email-jintack.lim@linaro.org&gt;
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=174677">Jintack Lim</a> - Oct. 3, 2017, 3:11 a.m.</div>
<pre class="content">
Even though a guest hypervisor can execute TLBI instructions that are
accesible at EL1 without trap, it&#39;s wrong; All those TLBI instructions
work based on current VMID, and when running a guest hypervisor current
VMID is the one for itself, not the one from the virtual vttbr_el2. So
letting a guest hypervisor execute those TLBI instructions results in
invalidating its own TLB entries and leaving invalid TLB entries
unhandled.

Therefore we trap and emulate those TLBI instructions. The emulation is
simple; we find a shadow VMID mapped to the virtual vttbr_el2, set it in
the physical vttbr_el2, then execute the same instruction in EL2.

We don&#39;t set HCR_EL2.TTLB bit yet.
<span class="signed-off-by">
Signed-off-by: Jintack Lim &lt;jintack.lim@linaro.org&gt;</span>
---
 arch/arm64/include/asm/kvm_asm.h |  1 +
 arch/arm64/include/asm/kvm_mmu.h |  1 +
 arch/arm64/include/asm/sysreg.h  | 15 ++++++++++++
 arch/arm64/kvm/hyp/tlb.c         | 52 ++++++++++++++++++++++++++++++++++++++++
 arch/arm64/kvm/mmu-nested.c      |  3 +--
 arch/arm64/kvm/sys_regs.c        | 50 ++++++++++++++++++++++++++++++++++++++
 6 files changed, 120 insertions(+), 2 deletions(-)
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/arch/arm64/include/asm/kvm_asm.h b/arch/arm64/include/asm/kvm_asm.h</span>
<span class="p_header">index cd7fb85..ce331d7 100644</span>
<span class="p_header">--- a/arch/arm64/include/asm/kvm_asm.h</span>
<span class="p_header">+++ b/arch/arm64/include/asm/kvm_asm.h</span>
<span class="p_chunk">@@ -56,6 +56,7 @@</span> <span class="p_context"></span>
 extern void __kvm_tlb_flush_vmid(u64 vttbr);
 extern void __kvm_tlb_flush_local_vmid(u64 vttbr);
 extern void __kvm_tlb_vae2(u64 vttbr, u64 va, u64 sys_encoding);
<span class="p_add">+extern void __kvm_tlb_el1_instr(u64 vttbr, u64 val, u64 sys_encoding);</span>
 
 extern void __kvm_at_insn(struct kvm_vcpu *vcpu, unsigned long vaddr,
 			  bool el2_regime, int sys_encoding);
<span class="p_header">diff --git a/arch/arm64/include/asm/kvm_mmu.h b/arch/arm64/include/asm/kvm_mmu.h</span>
<span class="p_header">index 6681be1..601f431 100644</span>
<span class="p_header">--- a/arch/arm64/include/asm/kvm_mmu.h</span>
<span class="p_header">+++ b/arch/arm64/include/asm/kvm_mmu.h</span>
<span class="p_chunk">@@ -347,6 +347,7 @@</span> <span class="p_context"> int kvm_s2_handle_perm_fault(struct kvm_vcpu *vcpu, phys_addr_t fault_ipa,</span>
 int kvm_inject_s2_fault(struct kvm_vcpu *vcpu, u64 esr_el2);
 bool kvm_nested_s2_clear_curr_vmid(struct kvm_vcpu *vcpu, phys_addr_t start,
 				   u64 size);
<span class="p_add">+struct kvm_nested_s2_mmu *lookup_nested_mmu(struct kvm_vcpu *vcpu, u64 vttbr);</span>
 
 static inline u64 kvm_get_vttbr(struct kvm_s2_vmid *vmid,
 				struct kvm_s2_mmu *mmu)
<span class="p_header">diff --git a/arch/arm64/include/asm/sysreg.h b/arch/arm64/include/asm/sysreg.h</span>
<span class="p_header">index 53df733..fd6b98a 100644</span>
<span class="p_header">--- a/arch/arm64/include/asm/sysreg.h</span>
<span class="p_header">+++ b/arch/arm64/include/asm/sysreg.h</span>
<span class="p_chunk">@@ -386,10 +386,25 @@</span> <span class="p_context"></span>
 
 /* TLBI instructions */
 #define TLBI_Op0	1
<span class="p_add">+#define TLBI_Op1_EL1	0	/* Accessible from EL1 or higher */</span>
 #define TLBI_Op1_EL2	4	/* Accessible from EL2 or higher */
 #define TLBI_CRn	8
<span class="p_add">+#define tlbi_insn_el1(CRm, Op2)	sys_insn(TLBI_Op0, TLBI_Op1_EL1, TLBI_CRn, (CRm), (Op2))</span>
 #define tlbi_insn_el2(CRm, Op2)	sys_insn(TLBI_Op0, TLBI_Op1_EL2, TLBI_CRn, (CRm), (Op2))
 
<span class="p_add">+#define TLBI_VMALLE1IS	tlbi_insn_el1(3, 0)</span>
<span class="p_add">+#define TLBI_VAE1IS	tlbi_insn_el1(3, 1)</span>
<span class="p_add">+#define TLBI_ASIDE1IS	tlbi_insn_el1(3, 2)</span>
<span class="p_add">+#define TLBI_VAAE1IS	tlbi_insn_el1(3, 3)</span>
<span class="p_add">+#define TLBI_VALE1IS	tlbi_insn_el1(3, 5)</span>
<span class="p_add">+#define TLBI_VAALE1IS	tlbi_insn_el1(3, 7)</span>
<span class="p_add">+#define TLBI_VMALLE1	tlbi_insn_el1(7, 0)</span>
<span class="p_add">+#define TLBI_VAE1	tlbi_insn_el1(7, 1)</span>
<span class="p_add">+#define TLBI_ASIDE1	tlbi_insn_el1(7, 2)</span>
<span class="p_add">+#define TLBI_VAAE1	tlbi_insn_el1(7, 3)</span>
<span class="p_add">+#define TLBI_VALE1	tlbi_insn_el1(7, 5)</span>
<span class="p_add">+#define TLBI_VAALE1	tlbi_insn_el1(7, 7)</span>
<span class="p_add">+</span>
 #define TLBI_IPAS2E1IS	tlbi_insn_el2(0, 1)
 #define TLBI_IPAS2LE1IS	tlbi_insn_el2(0, 5)
 #define TLBI_ALLE2IS	tlbi_insn_el2(3, 0)
<span class="p_header">diff --git a/arch/arm64/kvm/hyp/tlb.c b/arch/arm64/kvm/hyp/tlb.c</span>
<span class="p_header">index bd8b92c..096c234 100644</span>
<span class="p_header">--- a/arch/arm64/kvm/hyp/tlb.c</span>
<span class="p_header">+++ b/arch/arm64/kvm/hyp/tlb.c</span>
<span class="p_chunk">@@ -179,3 +179,55 @@</span> <span class="p_context"> void __hyp_text __kvm_tlb_vae2(u64 vttbr, u64 va, u64 sys_encoding)</span>
 
 	__tlb_switch_to_host()();
 }
<span class="p_add">+</span>
<span class="p_add">+void __hyp_text __kvm_tlb_el1_instr(u64 vttbr, u64 val, u64 sys_encoding)</span>
<span class="p_add">+{</span>
<span class="p_add">+	/* Switch to requested VMID */</span>
<span class="p_add">+	__tlb_switch_to_guest()(vttbr);</span>
<span class="p_add">+</span>
<span class="p_add">+	/* Execute the same instruction as the guest hypervisor did */</span>
<span class="p_add">+	switch (sys_encoding) {</span>
<span class="p_add">+	case TLBI_VMALLE1IS:</span>
<span class="p_add">+		__tlbi(vmalle1is);</span>
<span class="p_add">+		break;</span>
<span class="p_add">+	case TLBI_VAE1IS:</span>
<span class="p_add">+		__tlbi(vae1is, val);</span>
<span class="p_add">+		break;</span>
<span class="p_add">+	case TLBI_ASIDE1IS:</span>
<span class="p_add">+		__tlbi(aside1is, val);</span>
<span class="p_add">+		break;</span>
<span class="p_add">+	case TLBI_VAAE1IS:</span>
<span class="p_add">+		__tlbi(vaae1is, val);</span>
<span class="p_add">+		break;</span>
<span class="p_add">+	case TLBI_VALE1IS:</span>
<span class="p_add">+		__tlbi(vale1is, val);</span>
<span class="p_add">+		break;</span>
<span class="p_add">+	case TLBI_VAALE1IS:</span>
<span class="p_add">+		__tlbi(vaale1is, val);</span>
<span class="p_add">+		break;</span>
<span class="p_add">+	case TLBI_VMALLE1:</span>
<span class="p_add">+		__tlbi(vmalle1);</span>
<span class="p_add">+		break;</span>
<span class="p_add">+	case TLBI_VAE1:</span>
<span class="p_add">+		__tlbi(vae1, val);</span>
<span class="p_add">+		break;</span>
<span class="p_add">+	case TLBI_ASIDE1:</span>
<span class="p_add">+		__tlbi(aside1, val);</span>
<span class="p_add">+		break;</span>
<span class="p_add">+	case TLBI_VAAE1:</span>
<span class="p_add">+		__tlbi(vaae1, val);</span>
<span class="p_add">+		break;</span>
<span class="p_add">+	case TLBI_VALE1:</span>
<span class="p_add">+		__tlbi(vale1, val);</span>
<span class="p_add">+		break;</span>
<span class="p_add">+	case TLBI_VAALE1:</span>
<span class="p_add">+		__tlbi(vaale1, val);</span>
<span class="p_add">+		break;</span>
<span class="p_add">+	default:</span>
<span class="p_add">+		break;</span>
<span class="p_add">+	}</span>
<span class="p_add">+	dsb(nsh);</span>
<span class="p_add">+	isb();</span>
<span class="p_add">+</span>
<span class="p_add">+	__tlb_switch_to_host()();</span>
<span class="p_add">+}</span>
<span class="p_header">diff --git a/arch/arm64/kvm/mmu-nested.c b/arch/arm64/kvm/mmu-nested.c</span>
<span class="p_header">index 2189f2b..8826eaa 100644</span>
<span class="p_header">--- a/arch/arm64/kvm/mmu-nested.c</span>
<span class="p_header">+++ b/arch/arm64/kvm/mmu-nested.c</span>
<span class="p_chunk">@@ -332,8 +332,7 @@</span> <span class="p_context"> void kvm_nested_s2_free(struct kvm *kvm)</span>
 		__kvm_free_stage2_pgd(kvm, &amp;nested_mmu-&gt;mmu);
 }
 
<span class="p_del">-static struct kvm_nested_s2_mmu *lookup_nested_mmu(struct kvm_vcpu *vcpu,</span>
<span class="p_del">-						   u64 vttbr)</span>
<span class="p_add">+struct kvm_nested_s2_mmu *lookup_nested_mmu(struct kvm_vcpu *vcpu, u64 vttbr)</span>
 {
 	struct kvm_nested_s2_mmu *mmu;
 	u64 virtual_vmid;
<span class="p_header">diff --git a/arch/arm64/kvm/sys_regs.c b/arch/arm64/kvm/sys_regs.c</span>
<span class="p_header">index 89e73af..1dcbe70 100644</span>
<span class="p_header">--- a/arch/arm64/kvm/sys_regs.c</span>
<span class="p_header">+++ b/arch/arm64/kvm/sys_regs.c</span>
<span class="p_chunk">@@ -983,6 +983,11 @@</span> <span class="p_context"> static bool forward_at_traps(struct kvm_vcpu *vcpu)</span>
 	return forward_traps(vcpu, HCR_AT);
 }
 
<span class="p_add">+static bool forward_ttlb_traps(struct kvm_vcpu *vcpu)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return forward_traps(vcpu, HCR_TTLB);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 /* This function is to support the recursive nested virtualization */
 bool forward_nv_traps(struct kvm_vcpu *vcpu)
 {
<span class="p_chunk">@@ -1896,6 +1901,37 @@</span> <span class="p_context"> static bool handle_ipas2e1is(struct kvm_vcpu *vcpu, struct sys_reg_params *p,</span>
 	return true;
 }
 
<span class="p_add">+static bool handle_tlbi_el1(struct kvm_vcpu *vcpu, struct sys_reg_params *p,</span>
<span class="p_add">+			    const struct sys_reg_desc *r)</span>
<span class="p_add">+{</span>
<span class="p_add">+	u64 virtual_vttbr = vcpu_sys_reg(vcpu, VTTBR_EL2);</span>
<span class="p_add">+	u64 vttbr;</span>
<span class="p_add">+	struct kvm_nested_s2_mmu *nested_mmu;</span>
<span class="p_add">+	struct kvm_s2_mmu *mmu = &amp;vcpu-&gt;kvm-&gt;arch.mmu;</span>
<span class="p_add">+	int sys_encoding = sys_insn(p-&gt;Op0, p-&gt;Op1, p-&gt;CRn, p-&gt;CRm, p-&gt;Op2);</span>
<span class="p_add">+</span>
<span class="p_add">+	nested_mmu = lookup_nested_mmu(vcpu, virtual_vttbr);</span>
<span class="p_add">+	if (!nested_mmu) {</span>
<span class="p_add">+		/*</span>
<span class="p_add">+		 * If we can&#39;t find a shadow VMID, it is either the virtual</span>
<span class="p_add">+		 * VMID is for the host OS or the nested VM having the virtual</span>
<span class="p_add">+		 * VMID is never executed. (Note that we create a showdow VMID</span>
<span class="p_add">+		 * when entering a VM.) For the former, we can flush TLB</span>
<span class="p_add">+		 * entries belonging to the host OS in a VM. For the latter, we</span>
<span class="p_add">+		 * don&#39;t have to do anything. Since we can&#39;t differentiate</span>
<span class="p_add">+		 * between those cases, just do what we can do for the former.</span>
<span class="p_add">+		 */</span>
<span class="p_add">+		mmu = &amp;vcpu-&gt;kvm-&gt;arch.mmu;</span>
<span class="p_add">+	} else {</span>
<span class="p_add">+		mmu = &amp;nested_mmu-&gt;mmu;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	vttbr = kvm_get_vttbr(&amp;mmu-&gt;vmid, mmu);</span>
<span class="p_add">+	kvm_call_hyp(__kvm_tlb_el1_instr, vttbr, p-&gt;regval, sys_encoding);</span>
<span class="p_add">+</span>
<span class="p_add">+	return true;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 /*
  * AT instruction emulation
  *
<span class="p_chunk">@@ -1971,6 +2007,20 @@</span> <span class="p_context"> static bool handle_ipas2e1is(struct kvm_vcpu *vcpu, struct sys_reg_params *p,</span>
 	SYS_INSN_TO_DESC(AT_S1E0W, handle_s1e01, forward_at_traps),
 	SYS_INSN_TO_DESC(AT_S1E1RP, handle_s1e01, forward_at_traps),
 	SYS_INSN_TO_DESC(AT_S1E1WP, handle_s1e01, forward_at_traps),
<span class="p_add">+</span>
<span class="p_add">+	SYS_INSN_TO_DESC(TLBI_VMALLE1IS, handle_tlbi_el1, forward_ttlb_traps),</span>
<span class="p_add">+	SYS_INSN_TO_DESC(TLBI_VAE1IS, handle_tlbi_el1, forward_ttlb_traps),</span>
<span class="p_add">+	SYS_INSN_TO_DESC(TLBI_ASIDE1IS, handle_tlbi_el1, forward_ttlb_traps),</span>
<span class="p_add">+	SYS_INSN_TO_DESC(TLBI_VAAE1IS, handle_tlbi_el1, forward_ttlb_traps),</span>
<span class="p_add">+	SYS_INSN_TO_DESC(TLBI_VALE1IS, handle_tlbi_el1, forward_ttlb_traps),</span>
<span class="p_add">+	SYS_INSN_TO_DESC(TLBI_VAALE1IS, handle_tlbi_el1, forward_ttlb_traps),</span>
<span class="p_add">+	SYS_INSN_TO_DESC(TLBI_VMALLE1, handle_tlbi_el1, forward_ttlb_traps),</span>
<span class="p_add">+	SYS_INSN_TO_DESC(TLBI_VAE1, handle_tlbi_el1, forward_ttlb_traps),</span>
<span class="p_add">+	SYS_INSN_TO_DESC(TLBI_ASIDE1, handle_tlbi_el1, forward_ttlb_traps),</span>
<span class="p_add">+	SYS_INSN_TO_DESC(TLBI_VAAE1, handle_tlbi_el1, forward_ttlb_traps),</span>
<span class="p_add">+	SYS_INSN_TO_DESC(TLBI_VALE1, handle_tlbi_el1, forward_ttlb_traps),</span>
<span class="p_add">+	SYS_INSN_TO_DESC(TLBI_VAALE1, handle_tlbi_el1, forward_ttlb_traps),</span>
<span class="p_add">+</span>
 	SYS_INSN_TO_DESC(AT_S1E2R, handle_s1e2, forward_nv_traps),
 	SYS_INSN_TO_DESC(AT_S1E2W, handle_s1e2, forward_nv_traps),
 	SYS_INSN_TO_DESC(AT_S12E1R, handle_s12r, forward_nv_traps),

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



