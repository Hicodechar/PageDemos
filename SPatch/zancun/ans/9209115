
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>[3/6] mm: add force_batch_flush to mmu_gather - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    [3/6] mm: add force_batch_flush to mmu_gather</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=2302">Dave Hansen</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>July 1, 2016, 12:12 a.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;20160701001214.94D8F14C@viggo.jf.intel.com&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/9209115/mbox/"
   >mbox</a>
|
   <a href="/patch/9209115/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/9209115/">/patch/9209115/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
	[172.30.200.125])
	by pdx-korg-patchwork.web.codeaurora.org (Postfix) with ESMTP id
	E566A6075F for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Fri,  1 Jul 2016 00:13:24 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id D646D28654
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Fri,  1 Jul 2016 00:13:24 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id C9E3C2868A; Fri,  1 Jul 2016 00:13:24 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-6.9 required=2.0 tests=BAYES_00,RCVD_IN_DNSWL_HI
	autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id D992828657
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Fri,  1 Jul 2016 00:13:22 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1752151AbcGAANP (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Thu, 30 Jun 2016 20:13:15 -0400
Received: from mga11.intel.com ([192.55.52.93]:6019 &quot;EHLO mga11.intel.com&quot;
	rhost-flags-OK-OK-OK-OK) by vger.kernel.org with ESMTP
	id S1751052AbcGAANM (ORCPT &lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Thu, 30 Jun 2016 20:13:12 -0400
Received: from orsmga001.jf.intel.com ([10.7.209.18])
	by fmsmga102.fm.intel.com with ESMTP; 30 Jun 2016 17:12:14 -0700
X-ExtLoop1: 1
X-IronPort-AV: E=Sophos;i=&quot;5.26,554,1459839600&quot;; d=&quot;scan&#39;208&quot;;a=&quot;986740986&quot;
Received: from viggo.jf.intel.com (HELO localhost.localdomain)
	([10.54.39.121])
	by orsmga001.jf.intel.com with ESMTP; 30 Jun 2016 17:12:14 -0700
Subject: [PATCH 3/6] mm: add force_batch_flush to mmu_gather
To: linux-kernel@vger.kernel.org
Cc: x86@kernel.org, linux-mm@kvack.org, torvalds@linux-foundation.org,
	akpm@linux-foundation.org, bp@alien8.de, ak@linux.intel.com,
	mhocko@suse.com, Dave Hansen &lt;dave@sr71.net&gt;, dave.hansen@linux.intel.com
From: Dave Hansen &lt;dave@sr71.net&gt;
Date: Thu, 30 Jun 2016 17:12:14 -0700
References: &lt;20160701001209.7DA24D1C@viggo.jf.intel.com&gt;
In-Reply-To: &lt;20160701001209.7DA24D1C@viggo.jf.intel.com&gt;
Message-Id: &lt;20160701001214.94D8F14C@viggo.jf.intel.com&gt;
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=2302">Dave Hansen</a> - July 1, 2016, 12:12 a.m.</div>
<pre class="content">
<span class="from">From: Dave Hansen &lt;dave.hansen@linux.intel.com&gt;</span>

Currently, zap_pte_range() has a local variable called
&#39;force_flush&#39;.  It is set when the zapping code runs in to an
entry that requires flushing before the ptl is released.

Currently, there are two reasons we might do that:
1. The TLB batching in __tlb_remove_page() has run out of
   space and can no longer record new pages being flushed.
2. An entry for a dirty page was flushed, and we need to
   ensure that software walking the page tables can not
   observe the cleared bit before we flush the TLB.

We need the x86 code to be able to force a flush for an
additional reason: if the PTE being cleared might have a stray
Accessed or Dirty bit set on it because of a hardware erratum.
For these purposes, we also need to flush before the ptl is
released.  So, we move the &#39;force_flush&#39; variable into the
mmu_gather structure where we can set it from arch code.
<span class="signed-off-by">
Signed-off-by: Dave Hansen &lt;dave.hansen@linux.intel.com&gt;</span>
---

 b/arch/arm/include/asm/tlb.h  |    1 +
 b/arch/ia64/include/asm/tlb.h |    1 +
 b/arch/s390/include/asm/tlb.h |    1 +
 b/arch/sh/include/asm/tlb.h   |    1 +
 b/arch/um/include/asm/tlb.h   |    1 +
 b/include/asm-generic/tlb.h   |    3 +++
 b/mm/memory.c                 |   22 ++++++++++++----------
 7 files changed, 20 insertions(+), 10 deletions(-)
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff -puN arch/arm/include/asm/tlb.h~knl-leak-30-tlb_force_flush arch/arm/include/asm/tlb.h</span>
<span class="p_header">--- a/arch/arm/include/asm/tlb.h~knl-leak-30-tlb_force_flush	2016-06-30 17:10:42.021222437 -0700</span>
<span class="p_header">+++ b/arch/arm/include/asm/tlb.h	2016-06-30 17:10:42.037223163 -0700</span>
<span class="p_chunk">@@ -69,6 +69,7 @@</span> <span class="p_context"> struct mmu_gather {</span>
 	unsigned int		need_flush;
 #endif
 	unsigned int		fullmm;
<span class="p_add">+	unsigned int		force_batch_flush;</span>
 	struct vm_area_struct	*vma;
 	unsigned long		start, end;
 	unsigned long		range_start;
<span class="p_header">diff -puN arch/ia64/include/asm/tlb.h~knl-leak-30-tlb_force_flush arch/ia64/include/asm/tlb.h</span>
<span class="p_header">--- a/arch/ia64/include/asm/tlb.h~knl-leak-30-tlb_force_flush	2016-06-30 17:10:42.022222482 -0700</span>
<span class="p_header">+++ b/arch/ia64/include/asm/tlb.h	2016-06-30 17:10:42.037223163 -0700</span>
<span class="p_chunk">@@ -57,6 +57,7 @@</span> <span class="p_context"> struct mmu_gather {</span>
 	unsigned int		nr;
 	unsigned int		max;
 	unsigned char		fullmm;		/* non-zero means full mm flush */
<span class="p_add">+	unsigned int		force_batch_flush; /* stop batching and flush */</span>
 	unsigned char		need_flush;	/* really unmapped some PTEs? */
 	unsigned long		start, end;
 	unsigned long		start_addr;
<span class="p_header">diff -puN arch/s390/include/asm/tlb.h~knl-leak-30-tlb_force_flush arch/s390/include/asm/tlb.h</span>
<span class="p_header">--- a/arch/s390/include/asm/tlb.h~knl-leak-30-tlb_force_flush	2016-06-30 17:10:42.024222573 -0700</span>
<span class="p_header">+++ b/arch/s390/include/asm/tlb.h	2016-06-30 17:10:42.038223208 -0700</span>
<span class="p_chunk">@@ -32,6 +32,7 @@</span> <span class="p_context"> struct mmu_gather {</span>
 	struct mm_struct *mm;
 	struct mmu_table_batch *batch;
 	unsigned int fullmm;
<span class="p_add">+	unsigned int force_batch_flush; /* stop batching and flush */</span>
 	unsigned long start, end;
 };
 
<span class="p_header">diff -puN arch/sh/include/asm/tlb.h~knl-leak-30-tlb_force_flush arch/sh/include/asm/tlb.h</span>
<span class="p_header">--- a/arch/sh/include/asm/tlb.h~knl-leak-30-tlb_force_flush	2016-06-30 17:10:42.025222618 -0700</span>
<span class="p_header">+++ b/arch/sh/include/asm/tlb.h	2016-06-30 17:10:42.038223208 -0700</span>
<span class="p_chunk">@@ -21,6 +21,7 @@</span> <span class="p_context"></span>
 struct mmu_gather {
 	struct mm_struct	*mm;
 	unsigned int		fullmm;
<span class="p_add">+	unsigned int		force_batch_flush; /* stop batching and flush */</span>
 	unsigned long		start, end;
 };
 
<span class="p_header">diff -puN arch/um/include/asm/tlb.h~knl-leak-30-tlb_force_flush arch/um/include/asm/tlb.h</span>
<span class="p_header">--- a/arch/um/include/asm/tlb.h~knl-leak-30-tlb_force_flush	2016-06-30 17:10:42.027222709 -0700</span>
<span class="p_header">+++ b/arch/um/include/asm/tlb.h	2016-06-30 17:10:42.039223253 -0700</span>
<span class="p_chunk">@@ -20,6 +20,7 @@</span> <span class="p_context"> struct mmu_gather {</span>
 	unsigned long		start;
 	unsigned long		end;
 	unsigned int		fullmm; /* non-zero means full mm flush */
<span class="p_add">+	unsigned int		force_batch_flush; /* stop batching and flush */</span>
 };
 
 static inline void __tlb_remove_tlb_entry(struct mmu_gather *tlb, pte_t *ptep,
<span class="p_header">diff -puN include/asm-generic/tlb.h~knl-leak-30-tlb_force_flush include/asm-generic/tlb.h</span>
<span class="p_header">--- a/include/asm-generic/tlb.h~knl-leak-30-tlb_force_flush	2016-06-30 17:10:42.028222754 -0700</span>
<span class="p_header">+++ b/include/asm-generic/tlb.h	2016-06-30 17:10:42.039223253 -0700</span>
<span class="p_chunk">@@ -102,6 +102,9 @@</span> <span class="p_context"> struct mmu_gather {</span>
 	/* we have performed an operation which
 	 * requires a complete flush of the tlb */
 				need_flush_all : 1,
<span class="p_add">+	/* need to flush the tlb and stop batching</span>
<span class="p_add">+	 * before we release ptl */</span>
<span class="p_add">+				force_batch_flush : 1,</span>
 	/* we cleared a PTE bit which may potentially
 	 * get set by hardware */
 				saw_unset_a_or_d: 1;
<span class="p_header">diff -puN mm/memory.c~knl-leak-30-tlb_force_flush mm/memory.c</span>
<span class="p_header">--- a/mm/memory.c~knl-leak-30-tlb_force_flush	2016-06-30 17:10:42.031222890 -0700</span>
<span class="p_header">+++ b/mm/memory.c	2016-06-30 17:10:42.040223299 -0700</span>
<span class="p_chunk">@@ -225,6 +225,7 @@</span> <span class="p_context"> void tlb_gather_mmu(struct mmu_gather *t</span>
 	tlb-&gt;fullmm		= !(start | (end+1));
 	tlb-&gt;need_flush_all	= 0;
 	tlb-&gt;saw_unset_a_or_d	= 0;
<span class="p_add">+	tlb-&gt;force_batch_flush	= 0;</span>
 
 	tlb-&gt;local.next = NULL;
 	tlb-&gt;local.nr   = 0;
<span class="p_chunk">@@ -1105,7 +1106,6 @@</span> <span class="p_context"> static unsigned long zap_pte_range(struc</span>
 				struct zap_details *details)
 {
 	struct mm_struct *mm = tlb-&gt;mm;
<span class="p_del">-	int force_flush = 0;</span>
 	int rss[NR_MM_COUNTERS];
 	spinlock_t *ptl;
 	pte_t *start_pte;
<span class="p_chunk">@@ -1151,7 +1151,7 @@</span> <span class="p_context"> again:</span>
 					 */
 					if (unlikely(details &amp;&amp; details-&gt;ignore_dirty))
 						continue;
<span class="p_del">-					force_flush = 1;</span>
<span class="p_add">+					tlb-&gt;force_batch_flush = 1;</span>
 					set_page_dirty(page);
 				}
 				if (pte_young(ptent) &amp;&amp;
<span class="p_chunk">@@ -1163,7 +1163,7 @@</span> <span class="p_context"> again:</span>
 			if (unlikely(page_mapcount(page) &lt; 0))
 				print_bad_pte(vma, addr, ptent, page);
 			if (unlikely(!__tlb_remove_page(tlb, page))) {
<span class="p_del">-				force_flush = 1;</span>
<span class="p_add">+				tlb-&gt;force_batch_flush = 1;</span>
 				addr += PAGE_SIZE;
 				break;
 			}
<span class="p_chunk">@@ -1191,18 +1191,20 @@</span> <span class="p_context"> again:</span>
 	arch_leave_lazy_mmu_mode();
 
 	/* Do the actual TLB flush before dropping ptl */
<span class="p_del">-	if (force_flush)</span>
<span class="p_add">+	if (tlb-&gt;force_batch_flush)</span>
 		tlb_flush_mmu_tlbonly(tlb);
 	pte_unmap_unlock(start_pte, ptl);
 
 	/*
<span class="p_del">-	 * If we forced a TLB flush (either due to running out of</span>
<span class="p_del">-	 * batch buffers or because we needed to flush dirty TLB</span>
<span class="p_del">-	 * entries before releasing the ptl), free the batched</span>
<span class="p_del">-	 * memory too. Restart if we didn&#39;t do everything.</span>
<span class="p_add">+	 * If we forced a TLB flush, free the batched</span>
<span class="p_add">+	 * memory too.  Restart if we didn&#39;t do everything.</span>
<span class="p_add">+	 *</span>
<span class="p_add">+	 * We force this due to running out of batch buffers,</span>
<span class="p_add">+	 * needing to flush dirty TLB entries before releasing</span>
<span class="p_add">+	 * the ptl, or for arch-specific reasons.</span>
 	 */
<span class="p_del">-	if (force_flush) {</span>
<span class="p_del">-		force_flush = 0;</span>
<span class="p_add">+	if (tlb-&gt;force_batch_flush) {</span>
<span class="p_add">+		tlb-&gt;force_batch_flush = 0;</span>
 		tlb_flush_mmu_free(tlb);
 
 		if (addr != end)

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



