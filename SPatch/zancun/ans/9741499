
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>[v2,03/11] x86/mm: Make the batched unmap TLB flush API more generic - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    [v2,03/11] x86/mm: Make the batched unmap TLB flush API more generic</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=125831">Andrew Lutomirski</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>May 22, 2017, 10:30 p.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;19f25a8581f9fb77876b7ff3b001f89835e34ea3.1495492063.git.luto@kernel.org&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/9741499/mbox/"
   >mbox</a>
|
   <a href="/patch/9741499/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/9741499/">/patch/9741499/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
	[172.30.200.125])
	by pdx-korg-patchwork.web.codeaurora.org (Postfix) with ESMTP id
	6BD4E60392 for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Mon, 22 May 2017 22:31:52 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 5CC7826E49
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Mon, 22 May 2017 22:31:52 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id 518C628772; Mon, 22 May 2017 22:31:52 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-6.9 required=2.0 tests=BAYES_00,RCVD_IN_DNSWL_HI
	autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id B34CA26E49
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Mon, 22 May 2017 22:31:51 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S965385AbdEVWbY (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Mon, 22 May 2017 18:31:24 -0400
Received: from mail.kernel.org ([198.145.29.99]:47894 &quot;EHLO mail.kernel.org&quot;
	rhost-flags-OK-OK-OK-OK) by vger.kernel.org with ESMTP
	id S965278AbdEVWac (ORCPT &lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Mon, 22 May 2017 18:30:32 -0400
Received: from localhost (ycr.static.monkeybrains.net [199.241.202.194])
	(using TLSv1.2 with cipher ECDHE-RSA-AES256-GCM-SHA384 (256/256
	bits)) (No client certificate requested)
	by mail.kernel.org (Postfix) with ESMTPSA id B5D31239D3;
	Mon, 22 May 2017 22:30:20 +0000 (UTC)
DMARC-Filter: OpenDMARC Filter v1.3.2 mail.kernel.org B5D31239D3
Authentication-Results: mail.kernel.org;
	dmarc=none (p=none dis=none) header.from=kernel.org
Authentication-Results: mail.kernel.org;
	spf=none smtp.mailfrom=luto@kernel.org
From: Andy Lutomirski &lt;luto@kernel.org&gt;
To: X86 ML &lt;x86@kernel.org&gt;
Cc: &quot;linux-kernel@vger.kernel.org&quot; &lt;linux-kernel@vger.kernel.org&gt;,
	Borislav Petkov &lt;bpetkov@suse.de&gt;,
	Linus Torvalds &lt;torvalds@linux-foundation.org&gt;,
	Andrew Morton &lt;akpm@linux-foundation.org&gt;, Mel Gorman &lt;mgorman@suse.de&gt;,
	&quot;linux-mm@kvack.org&quot; &lt;linux-mm@kvack.org&gt;,
	Nadav Amit &lt;nadav.amit@gmail.com&gt;, Andy Lutomirski &lt;luto@kernel.org&gt;,
	Rik van Riel &lt;riel@redhat.com&gt;, Dave Hansen &lt;dave.hansen@intel.com&gt;,
	Nadav Amit &lt;namit@vmware.com&gt;, Michal Hocko &lt;mhocko@suse.com&gt;,
	Sasha Levin &lt;sasha.levin@oracle.com&gt;
Subject: [PATCH v2 03/11] x86/mm: Make the batched unmap TLB flush API more
	generic
Date: Mon, 22 May 2017 15:30:03 -0700
Message-Id: &lt;19f25a8581f9fb77876b7ff3b001f89835e34ea3.1495492063.git.luto@kernel.org&gt;
X-Mailer: git-send-email 2.9.3
In-Reply-To: &lt;cover.1495492063.git.luto@kernel.org&gt;
References: &lt;cover.1495492063.git.luto@kernel.org&gt;
In-Reply-To: &lt;cover.1495492063.git.luto@kernel.org&gt;
References: &lt;cover.1495492063.git.luto@kernel.org&gt;
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=125831">Andrew Lutomirski</a> - May 22, 2017, 10:30 p.m.</div>
<pre class="content">
try_to_unmap_flush() used to open-code a rather x86-centric flush
sequence: local_flush_tlb() + flush_tlb_others().  Rearrange the
code so that the arch (only x86 for now) provides
arch_tlbbatch_add_mm() and arch_tlbbatch_flush() and the core code
calls those functions instead.

I&#39;ll want this for x86 because, to enable address space ids, I can&#39;t
support the flush_tlb_others() mode used by exising
try_to_unmap_flush() implementation with good performance.  I can
support the new API fairly easily, though.

I imagine that other architectures may be in a similar position.
Architectures with strong remote flush primitives (arm64?) may have
even worse performance problems with flush_tlb_others() the way that
try_to_unmap_flush() uses it.

Cc: Mel Gorman &lt;mgorman@suse.de&gt;
Cc: Rik van Riel &lt;riel@redhat.com&gt;
Cc: Dave Hansen &lt;dave.hansen@intel.com&gt;
Cc: Nadav Amit &lt;namit@vmware.com&gt;
Cc: Michal Hocko &lt;mhocko@suse.com&gt;
Cc: Sasha Levin &lt;sasha.levin@oracle.com&gt;
Cc: Andrew Morton &lt;akpm@linux-foundation.org&gt;
<span class="signed-off-by">Signed-off-by: Andy Lutomirski &lt;luto@kernel.org&gt;</span>
---
 arch/x86/include/asm/tlbbatch.h | 16 ++++++++++++++++
 arch/x86/include/asm/tlbflush.h |  8 ++++++++
 arch/x86/mm/tlb.c               | 17 +++++++++++++++++
 include/linux/mm_types_task.h   | 15 +++++++++++----
 mm/rmap.c                       | 16 ++--------------
 5 files changed, 54 insertions(+), 18 deletions(-)
 create mode 100644 arch/x86/include/asm/tlbbatch.h
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/arch/x86/include/asm/tlbbatch.h b/arch/x86/include/asm/tlbbatch.h</span>
new file mode 100644
<span class="p_header">index 000000000000..01a6de16fb96</span>
<span class="p_header">--- /dev/null</span>
<span class="p_header">+++ b/arch/x86/include/asm/tlbbatch.h</span>
<span class="p_chunk">@@ -0,0 +1,16 @@</span> <span class="p_context"></span>
<span class="p_add">+#ifndef _ARCH_X86_TLBBATCH_H</span>
<span class="p_add">+#define _ARCH_X86_TLBBATCH_H</span>
<span class="p_add">+</span>
<span class="p_add">+#include &lt;linux/cpumask.h&gt;</span>
<span class="p_add">+</span>
<span class="p_add">+#ifdef CONFIG_SMP</span>
<span class="p_add">+struct arch_tlbflush_unmap_batch {</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Each bit set is a CPU that potentially has a TLB entry for one of</span>
<span class="p_add">+	 * the PFNs being flushed..</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	struct cpumask cpumask;</span>
<span class="p_add">+};</span>
<span class="p_add">+#endif</span>
<span class="p_add">+</span>
<span class="p_add">+#endif /* _ARCH_X86_TLBBATCH_H */</span>
<span class="p_header">diff --git a/arch/x86/include/asm/tlbflush.h b/arch/x86/include/asm/tlbflush.h</span>
<span class="p_header">index b9db0f8fef55..8f6e2f87511b 100644</span>
<span class="p_header">--- a/arch/x86/include/asm/tlbflush.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/tlbflush.h</span>
<span class="p_chunk">@@ -329,6 +329,14 @@</span> <span class="p_context"> static inline void reset_lazy_tlbstate(void)</span>
 	this_cpu_write(cpu_tlbstate.active_mm, &amp;init_mm);
 }
 
<span class="p_add">+static inline void arch_tlbbatch_add_mm(struct arch_tlbflush_unmap_batch *batch,</span>
<span class="p_add">+					struct mm_struct *mm)</span>
<span class="p_add">+{</span>
<span class="p_add">+	cpumask_or(&amp;batch-&gt;cpumask, &amp;batch-&gt;cpumask, mm_cpumask(mm));</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+extern void arch_tlbbatch_flush(struct arch_tlbflush_unmap_batch *batch);</span>
<span class="p_add">+</span>
 #endif	/* SMP */
 
 #ifndef CONFIG_PARAVIRT
<span class="p_header">diff --git a/arch/x86/mm/tlb.c b/arch/x86/mm/tlb.c</span>
<span class="p_header">index 4d303864b310..743e4c6b4529 100644</span>
<span class="p_header">--- a/arch/x86/mm/tlb.c</span>
<span class="p_header">+++ b/arch/x86/mm/tlb.c</span>
<span class="p_chunk">@@ -395,6 +395,23 @@</span> <span class="p_context"> void flush_tlb_kernel_range(unsigned long start, unsigned long end)</span>
 	}
 }
 
<span class="p_add">+void arch_tlbbatch_flush(struct arch_tlbflush_unmap_batch *batch)</span>
<span class="p_add">+{</span>
<span class="p_add">+	int cpu = get_cpu();</span>
<span class="p_add">+</span>
<span class="p_add">+	if (cpumask_test_cpu(cpu, &amp;batch-&gt;cpumask)) {</span>
<span class="p_add">+		count_vm_tlb_event(NR_TLB_LOCAL_FLUSH_ALL);</span>
<span class="p_add">+		local_flush_tlb();</span>
<span class="p_add">+		trace_tlb_flush(TLB_LOCAL_SHOOTDOWN, TLB_FLUSH_ALL);</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	if (cpumask_any_but(&amp;batch-&gt;cpumask, cpu) &lt; nr_cpu_ids)</span>
<span class="p_add">+		flush_tlb_others(&amp;batch-&gt;cpumask, NULL, 0, TLB_FLUSH_ALL);</span>
<span class="p_add">+	cpumask_clear(&amp;batch-&gt;cpumask);</span>
<span class="p_add">+</span>
<span class="p_add">+	put_cpu();</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static ssize_t tlbflush_read_file(struct file *file, char __user *user_buf,
 			     size_t count, loff_t *ppos)
 {
<span class="p_header">diff --git a/include/linux/mm_types_task.h b/include/linux/mm_types_task.h</span>
<span class="p_header">index 136dfdf63ba1..fc412fbd80bd 100644</span>
<span class="p_header">--- a/include/linux/mm_types_task.h</span>
<span class="p_header">+++ b/include/linux/mm_types_task.h</span>
<span class="p_chunk">@@ -14,6 +14,10 @@</span> <span class="p_context"></span>
 
 #include &lt;asm/page.h&gt;
 
<span class="p_add">+#ifdef CONFIG_ARCH_WANT_BATCHED_UNMAP_TLB_FLUSH</span>
<span class="p_add">+#include &lt;asm/tlbbatch.h&gt;</span>
<span class="p_add">+#endif</span>
<span class="p_add">+</span>
 #define USE_SPLIT_PTE_PTLOCKS	(NR_CPUS &gt;= CONFIG_SPLIT_PTLOCK_CPUS)
 #define USE_SPLIT_PMD_PTLOCKS	(USE_SPLIT_PTE_PTLOCKS &amp;&amp; \
 		IS_ENABLED(CONFIG_ARCH_ENABLE_SPLIT_PMD_PTLOCK))
<span class="p_chunk">@@ -67,12 +71,15 @@</span> <span class="p_context"> struct page_frag {</span>
 struct tlbflush_unmap_batch {
 #ifdef CONFIG_ARCH_WANT_BATCHED_UNMAP_TLB_FLUSH
 	/*
<span class="p_del">-	 * Each bit set is a CPU that potentially has a TLB entry for one of</span>
<span class="p_del">-	 * the PFNs being flushed. See set_tlb_ubc_flush_pending().</span>
<span class="p_add">+	 * The arch code makes the following promise: generic code can modify a</span>
<span class="p_add">+	 * PTE, then call arch_tlbbatch_add_mm() (which internally provides all</span>
<span class="p_add">+	 * needed barriers), then call arch_tlbbatch_flush(), and the entries</span>
<span class="p_add">+	 * will be flushed on all CPUs by the time that arch_tlbbatch_flush()</span>
<span class="p_add">+	 * returns.</span>
 	 */
<span class="p_del">-	struct cpumask cpumask;</span>
<span class="p_add">+	struct arch_tlbflush_unmap_batch arch;</span>
 
<span class="p_del">-	/* True if any bit in cpumask is set */</span>
<span class="p_add">+	/* True if a flush is needed. */</span>
 	bool flush_required;
 
 	/*
<span class="p_header">diff --git a/mm/rmap.c b/mm/rmap.c</span>
<span class="p_header">index f6838015810f..f29d725528d2 100644</span>
<span class="p_header">--- a/mm/rmap.c</span>
<span class="p_header">+++ b/mm/rmap.c</span>
<span class="p_chunk">@@ -579,25 +579,13 @@</span> <span class="p_context"> void page_unlock_anon_vma_read(struct anon_vma *anon_vma)</span>
 void try_to_unmap_flush(void)
 {
 	struct tlbflush_unmap_batch *tlb_ubc = &amp;current-&gt;tlb_ubc;
<span class="p_del">-	int cpu;</span>
 
 	if (!tlb_ubc-&gt;flush_required)
 		return;
 
<span class="p_del">-	cpu = get_cpu();</span>
<span class="p_del">-</span>
<span class="p_del">-	if (cpumask_test_cpu(cpu, &amp;tlb_ubc-&gt;cpumask)) {</span>
<span class="p_del">-		count_vm_tlb_event(NR_TLB_LOCAL_FLUSH_ALL);</span>
<span class="p_del">-		local_flush_tlb();</span>
<span class="p_del">-		trace_tlb_flush(TLB_LOCAL_SHOOTDOWN, TLB_FLUSH_ALL);</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">-	if (cpumask_any_but(&amp;tlb_ubc-&gt;cpumask, cpu) &lt; nr_cpu_ids)</span>
<span class="p_del">-		flush_tlb_others(&amp;tlb_ubc-&gt;cpumask, NULL, 0, TLB_FLUSH_ALL);</span>
<span class="p_del">-	cpumask_clear(&amp;tlb_ubc-&gt;cpumask);</span>
<span class="p_add">+	arch_tlbbatch_flush(&amp;tlb_ubc-&gt;arch);</span>
 	tlb_ubc-&gt;flush_required = false;
 	tlb_ubc-&gt;writable = false;
<span class="p_del">-	put_cpu();</span>
 }
 
 /* Flush iff there are potentially writable TLB entries that can race with IO */
<span class="p_chunk">@@ -613,7 +601,7 @@</span> <span class="p_context"> static void set_tlb_ubc_flush_pending(struct mm_struct *mm, bool writable)</span>
 {
 	struct tlbflush_unmap_batch *tlb_ubc = &amp;current-&gt;tlb_ubc;
 
<span class="p_del">-	cpumask_or(&amp;tlb_ubc-&gt;cpumask, &amp;tlb_ubc-&gt;cpumask, mm_cpumask(mm));</span>
<span class="p_add">+	arch_tlbbatch_add_mm(&amp;tlb_ubc-&gt;arch, mm);</span>
 	tlb_ubc-&gt;flush_required = true;
 
 	/*

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



