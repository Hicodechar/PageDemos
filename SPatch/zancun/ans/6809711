
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>[27/28] atomic: Replace atomic_{set,clear}_mask() usage - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    [27/28] atomic: Replace atomic_{set,clear}_mask() usage</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=137">Peter Zijlstra</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>July 16, 2015, 5:21 p.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;20150716172926.571899873@infradead.org&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/6809711/mbox/"
   >mbox</a>
|
   <a href="/patch/6809711/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/6809711/">/patch/6809711/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
X-Original-To: patchwork-LKML@patchwork.kernel.org
Delivered-To: patchwork-parsemail@patchwork2.web.kernel.org
Received: from mail.kernel.org (mail.kernel.org [198.145.29.136])
	by patchwork2.web.kernel.org (Postfix) with ESMTP id ECCC6C05AC
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Thu, 16 Jul 2015 17:38:36 +0000 (UTC)
Received: from mail.kernel.org (localhost [127.0.0.1])
	by mail.kernel.org (Postfix) with ESMTP id DB8D8206E8
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Thu, 16 Jul 2015 17:38:34 +0000 (UTC)
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.kernel.org (Postfix) with ESMTP id 8213820691
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Thu, 16 Jul 2015 17:38:32 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1756510AbbGPRiU (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Thu, 16 Jul 2015 13:38:20 -0400
Received: from bombadil.infradead.org ([198.137.202.9]:36486 &quot;EHLO
	bombadil.infradead.org&quot; rhost-flags-OK-OK-OK-OK) by vger.kernel.org
	with ESMTP id S1756257AbbGPReM (ORCPT
	&lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Thu, 16 Jul 2015 13:34:12 -0400
Received: from 178-85-85-44.dynamic.upc.nl ([178.85.85.44] helo=twins)
	by bombadil.infradead.org with esmtpsa (Exim 4.80.1 #2 (Red Hat
	Linux)) id 1ZFn1K-0002Y2-As; Thu, 16 Jul 2015 17:32:30 +0000
Received: by twins (Postfix, from userid 0)
	id 01ED211E47662; Thu, 16 Jul 2015 19:32:21 +0200 (CEST)
Message-Id: &lt;20150716172926.571899873@infradead.org&gt;
User-Agent: quilt/0.61-1
Date: Thu, 16 Jul 2015 19:21:37 +0200
From: Peter Zijlstra &lt;peterz@infradead.org&gt;
To: linux-kernel@vger.kernel.org, linux-arch@vger.kernel.org
Cc: rth@twiddle.net, vgupta@synopsys.com, linux@arm.linux.org.uk,
	will.deacon@arm.com, hskinnemoen@gmail.com, realmz6@gmail.com,
	dhowells@redhat.com, rkuo@codeaurora.org, tony.luck@intel.com,
	geert@linux-m68k.org, james.hogan@imgtec.com, ralf@linux-mips.org,
	jejb@parisc-linux.org, benh@kernel.crashing.org,
	heiko.carstens@de.ibm.com, davem@davemloft.net,
	cmetcalf@ezchip.com, ysato@users.sourceforge.jp, mingo@kernel.org,
	peterz@infradead.org
Subject: [PATCH 27/28] atomic: Replace atomic_{set,clear}_mask() usage
References: &lt;20150716172110.587529075@infradead.org&gt;
MIME-Version: 1.0
Content-Type: text/plain; charset=UTF-8
Content-Disposition: inline; filename=peterz-atomic-mask-remove.patch
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Spam-Status: No, score=-8.2 required=5.0 tests=BAYES_00, RCVD_IN_DNSWL_HI, 
	RP_MATCHES_RCVD,
	UNPARSEABLE_RELAY autolearn=unavailable version=3.3.1
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on mail.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=137">Peter Zijlstra</a> - July 16, 2015, 5:21 p.m.</div>
<pre class="content">
Replace the deprecated atomic_{set,clear}_mask() usage with the now
ubiquous atomic_{or,andnot}() functions.
<span class="signed-off-by">
Signed-off-by: Peter Zijlstra (Intel) &lt;peterz@infradead.org&gt;</span>
---
 arch/blackfin/mach-common/smp.c |    2 -
 arch/m32r/kernel/smp.c          |    4 +-
 arch/mn10300/mm/tlb-smp.c       |    2 -
 arch/s390/kernel/time.c         |    4 +-
 arch/s390/kvm/interrupt.c       |   30 +++++++++----------
 arch/s390/kvm/kvm-s390.c        |   32 ++++++++++----------
 drivers/gpu/drm/i915/i915_drv.c |    2 -
 drivers/gpu/drm/i915/i915_gem.c |    2 -
 drivers/gpu/drm/i915/i915_irq.c |    4 +-
 drivers/s390/scsi/zfcp_aux.c    |    2 -
 drivers/s390/scsi/zfcp_erp.c    |   62 ++++++++++++++++++++--------------------
 drivers/s390/scsi/zfcp_fc.c     |    8 ++---
 drivers/s390/scsi/zfcp_fsf.c    |   26 ++++++++--------
 drivers/s390/scsi/zfcp_qdio.c   |   14 ++++-----
 14 files changed, 97 insertions(+), 97 deletions(-)



--
To unsubscribe from this list: send the line &quot;unsubscribe linux-kernel&quot; in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
Please read the FAQ at  http://www.tux.org/lkml/
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">--- a/arch/blackfin/mach-common/smp.c</span>
<span class="p_header">+++ b/arch/blackfin/mach-common/smp.c</span>
<span class="p_chunk">@@ -195,7 +195,7 @@</span> <span class="p_context"> void send_ipi(const struct cpumask *cpum</span>
 	local_irq_save(flags);
 	for_each_cpu(cpu, cpumask) {
 		bfin_ipi_data = &amp;per_cpu(bfin_ipi, cpu);
<span class="p_del">-		atomic_set_mask((1 &lt;&lt; msg), &amp;bfin_ipi_data-&gt;bits);</span>
<span class="p_add">+		atomic_or((1 &lt;&lt; msg), &amp;bfin_ipi_data-&gt;bits);</span>
 		atomic_inc(&amp;bfin_ipi_data-&gt;count);
 	}
 	local_irq_restore(flags);
<span class="p_header">--- a/arch/m32r/kernel/smp.c</span>
<span class="p_header">+++ b/arch/m32r/kernel/smp.c</span>
<span class="p_chunk">@@ -156,7 +156,7 @@</span> <span class="p_context"> void smp_flush_cache_all(void)</span>
 	cpumask_clear_cpu(smp_processor_id(), &amp;cpumask);
 	spin_lock(&amp;flushcache_lock);
 	mask=cpumask_bits(&amp;cpumask);
<span class="p_del">-	atomic_set_mask(*mask, (atomic_t *)&amp;flushcache_cpumask);</span>
<span class="p_add">+	atomic_or(*mask, (atomic_t *)&amp;flushcache_cpumask);</span>
 	send_IPI_mask(&amp;cpumask, INVALIDATE_CACHE_IPI, 0);
 	_flush_cache_copyback_all();
 	while (flushcache_cpumask)
<span class="p_chunk">@@ -407,7 +407,7 @@</span> <span class="p_context"> static void flush_tlb_others(cpumask_t c</span>
 	flush_vma = vma;
 	flush_va = va;
 	mask=cpumask_bits(&amp;cpumask);
<span class="p_del">-	atomic_set_mask(*mask, (atomic_t *)&amp;flush_cpumask);</span>
<span class="p_add">+	atomic_or(*mask, (atomic_t *)&amp;flush_cpumask);</span>
 
 	/*
 	 * We have to send the IPI only to
<span class="p_header">--- a/arch/mn10300/mm/tlb-smp.c</span>
<span class="p_header">+++ b/arch/mn10300/mm/tlb-smp.c</span>
<span class="p_chunk">@@ -119,7 +119,7 @@</span> <span class="p_context"> static void flush_tlb_others(cpumask_t c</span>
 	flush_mm = mm;
 	flush_va = va;
 #if NR_CPUS &lt;= BITS_PER_LONG
<span class="p_del">-	atomic_set_mask(cpumask.bits[0], &amp;flush_cpumask.bits[0]);</span>
<span class="p_add">+	atomic_or(cpumask.bits[0], (atomic_t *)&amp;flush_cpumask.bits[0]);</span>
 #else
 #error Not supported.
 #endif
<span class="p_header">--- a/arch/s390/kernel/time.c</span>
<span class="p_header">+++ b/arch/s390/kernel/time.c</span>
<span class="p_chunk">@@ -381,7 +381,7 @@</span> <span class="p_context"> static void disable_sync_clock(void *dum</span>
 	 * increase the &quot;sequence&quot; counter to avoid the race of an
 	 * etr event and the complete recovery against get_sync_clock.
 	 */
<span class="p_del">-	atomic_clear_mask(0x80000000, sw_ptr);</span>
<span class="p_add">+	atomic_andnot(0x80000000, sw_ptr);</span>
 	atomic_inc(sw_ptr);
 }
 
<span class="p_chunk">@@ -392,7 +392,7 @@</span> <span class="p_context"> static void disable_sync_clock(void *dum</span>
 static void enable_sync_clock(void)
 {
 	atomic_t *sw_ptr = this_cpu_ptr(&amp;clock_sync_word);
<span class="p_del">-	atomic_set_mask(0x80000000, sw_ptr);</span>
<span class="p_add">+	atomic_or(0x80000000, sw_ptr);</span>
 }
 
 /*
<span class="p_header">--- a/arch/s390/kvm/interrupt.c</span>
<span class="p_header">+++ b/arch/s390/kvm/interrupt.c</span>
<span class="p_chunk">@@ -170,20 +170,20 @@</span> <span class="p_context"> static unsigned long deliverable_irqs(st</span>
 
 static void __set_cpu_idle(struct kvm_vcpu *vcpu)
 {
<span class="p_del">-	atomic_set_mask(CPUSTAT_WAIT, &amp;vcpu-&gt;arch.sie_block-&gt;cpuflags);</span>
<span class="p_add">+	atomic_or(CPUSTAT_WAIT, &amp;vcpu-&gt;arch.sie_block-&gt;cpuflags);</span>
 	set_bit(vcpu-&gt;vcpu_id, vcpu-&gt;arch.local_int.float_int-&gt;idle_mask);
 }
 
 static void __unset_cpu_idle(struct kvm_vcpu *vcpu)
 {
<span class="p_del">-	atomic_clear_mask(CPUSTAT_WAIT, &amp;vcpu-&gt;arch.sie_block-&gt;cpuflags);</span>
<span class="p_add">+	atomic_andnot(CPUSTAT_WAIT, &amp;vcpu-&gt;arch.sie_block-&gt;cpuflags);</span>
 	clear_bit(vcpu-&gt;vcpu_id, vcpu-&gt;arch.local_int.float_int-&gt;idle_mask);
 }
 
 static void __reset_intercept_indicators(struct kvm_vcpu *vcpu)
 {
<span class="p_del">-	atomic_clear_mask(CPUSTAT_IO_INT | CPUSTAT_EXT_INT | CPUSTAT_STOP_INT,</span>
<span class="p_del">-			  &amp;vcpu-&gt;arch.sie_block-&gt;cpuflags);</span>
<span class="p_add">+	atomic_andnot(CPUSTAT_IO_INT | CPUSTAT_EXT_INT | CPUSTAT_STOP_INT,</span>
<span class="p_add">+		    &amp;vcpu-&gt;arch.sie_block-&gt;cpuflags);</span>
 	vcpu-&gt;arch.sie_block-&gt;lctl = 0x0000;
 	vcpu-&gt;arch.sie_block-&gt;ictl &amp;= ~(ICTL_LPSW | ICTL_STCTL | ICTL_PINT);
 
<span class="p_chunk">@@ -196,7 +196,7 @@</span> <span class="p_context"> static void __reset_intercept_indicators</span>
 
 static void __set_cpuflag(struct kvm_vcpu *vcpu, u32 flag)
 {
<span class="p_del">-	atomic_set_mask(flag, &amp;vcpu-&gt;arch.sie_block-&gt;cpuflags);</span>
<span class="p_add">+	atomic_or(flag, &amp;vcpu-&gt;arch.sie_block-&gt;cpuflags);</span>
 }
 
 static void set_intercept_indicators_io(struct kvm_vcpu *vcpu)
<span class="p_chunk">@@ -919,7 +919,7 @@</span> <span class="p_context"> void kvm_s390_clear_local_irqs(struct kv</span>
 	spin_unlock(&amp;li-&gt;lock);
 
 	/* clear pending external calls set by sigp interpretation facility */
<span class="p_del">-	atomic_clear_mask(CPUSTAT_ECALL_PEND, li-&gt;cpuflags);</span>
<span class="p_add">+	atomic_andnot(CPUSTAT_ECALL_PEND, li-&gt;cpuflags);</span>
 	vcpu-&gt;kvm-&gt;arch.sca-&gt;cpu[vcpu-&gt;vcpu_id].sigp_ctrl = 0;
 }
 
<span class="p_chunk">@@ -1020,7 +1020,7 @@</span> <span class="p_context"> static int __inject_pfault_init(struct k</span>
 
 	li-&gt;irq.ext = irq-&gt;u.ext;
 	set_bit(IRQ_PEND_PFAULT_INIT, &amp;li-&gt;pending_irqs);
<span class="p_del">-	atomic_set_mask(CPUSTAT_EXT_INT, li-&gt;cpuflags);</span>
<span class="p_add">+	atomic_or(CPUSTAT_EXT_INT, li-&gt;cpuflags);</span>
 	return 0;
 }
 
<span class="p_chunk">@@ -1035,7 +1035,7 @@</span> <span class="p_context"> static int __inject_extcall_sigpif(struc</span>
 		/* another external call is pending */
 		return -EBUSY;
 	}
<span class="p_del">-	atomic_set_mask(CPUSTAT_ECALL_PEND, &amp;vcpu-&gt;arch.sie_block-&gt;cpuflags);</span>
<span class="p_add">+	atomic_or(CPUSTAT_ECALL_PEND, &amp;vcpu-&gt;arch.sie_block-&gt;cpuflags);</span>
 	return 0;
 }
 
<span class="p_chunk">@@ -1061,7 +1061,7 @@</span> <span class="p_context"> static int __inject_extcall(struct kvm_v</span>
 	if (test_and_set_bit(IRQ_PEND_EXT_EXTERNAL, &amp;li-&gt;pending_irqs))
 		return -EBUSY;
 	*extcall = irq-&gt;u.extcall;
<span class="p_del">-	atomic_set_mask(CPUSTAT_EXT_INT, li-&gt;cpuflags);</span>
<span class="p_add">+	atomic_or(CPUSTAT_EXT_INT, li-&gt;cpuflags);</span>
 	return 0;
 }
 
<span class="p_chunk">@@ -1133,7 +1133,7 @@</span> <span class="p_context"> static int __inject_sigp_emergency(struc</span>
 
 	set_bit(irq-&gt;u.emerg.code, li-&gt;sigp_emerg_pending);
 	set_bit(IRQ_PEND_EXT_EMERGENCY, &amp;li-&gt;pending_irqs);
<span class="p_del">-	atomic_set_mask(CPUSTAT_EXT_INT, li-&gt;cpuflags);</span>
<span class="p_add">+	atomic_or(CPUSTAT_EXT_INT, li-&gt;cpuflags);</span>
 	return 0;
 }
 
<span class="p_chunk">@@ -1177,7 +1177,7 @@</span> <span class="p_context"> static int __inject_ckc(struct kvm_vcpu</span>
 				   0, 0, 2);
 
 	set_bit(IRQ_PEND_EXT_CLOCK_COMP, &amp;li-&gt;pending_irqs);
<span class="p_del">-	atomic_set_mask(CPUSTAT_EXT_INT, li-&gt;cpuflags);</span>
<span class="p_add">+	atomic_or(CPUSTAT_EXT_INT, li-&gt;cpuflags);</span>
 	return 0;
 }
 
<span class="p_chunk">@@ -1190,7 +1190,7 @@</span> <span class="p_context"> static int __inject_cpu_timer(struct kvm</span>
 				   0, 0, 2);
 
 	set_bit(IRQ_PEND_EXT_CPU_TIMER, &amp;li-&gt;pending_irqs);
<span class="p_del">-	atomic_set_mask(CPUSTAT_EXT_INT, li-&gt;cpuflags);</span>
<span class="p_add">+	atomic_or(CPUSTAT_EXT_INT, li-&gt;cpuflags);</span>
 	return 0;
 }
 
<span class="p_chunk">@@ -1369,13 +1369,13 @@</span> <span class="p_context"> static void __floating_irq_kick(struct k</span>
 	spin_lock(&amp;li-&gt;lock);
 	switch (type) {
 	case KVM_S390_MCHK:
<span class="p_del">-		atomic_set_mask(CPUSTAT_STOP_INT, li-&gt;cpuflags);</span>
<span class="p_add">+		atomic_or(CPUSTAT_STOP_INT, li-&gt;cpuflags);</span>
 		break;
 	case KVM_S390_INT_IO_MIN...KVM_S390_INT_IO_MAX:
<span class="p_del">-		atomic_set_mask(CPUSTAT_IO_INT, li-&gt;cpuflags);</span>
<span class="p_add">+		atomic_or(CPUSTAT_IO_INT, li-&gt;cpuflags);</span>
 		break;
 	default:
<span class="p_del">-		atomic_set_mask(CPUSTAT_EXT_INT, li-&gt;cpuflags);</span>
<span class="p_add">+		atomic_or(CPUSTAT_EXT_INT, li-&gt;cpuflags);</span>
 		break;
 	}
 	spin_unlock(&amp;li-&gt;lock);
<span class="p_header">--- a/arch/s390/kvm/kvm-s390.c</span>
<span class="p_header">+++ b/arch/s390/kvm/kvm-s390.c</span>
<span class="p_chunk">@@ -1215,12 +1215,12 @@</span> <span class="p_context"> void kvm_arch_vcpu_load(struct kvm_vcpu</span>
 	}
 	restore_access_regs(vcpu-&gt;run-&gt;s.regs.acrs);
 	gmap_enable(vcpu-&gt;arch.gmap);
<span class="p_del">-	atomic_set_mask(CPUSTAT_RUNNING, &amp;vcpu-&gt;arch.sie_block-&gt;cpuflags);</span>
<span class="p_add">+	atomic_or(CPUSTAT_RUNNING, &amp;vcpu-&gt;arch.sie_block-&gt;cpuflags);</span>
 }
 
 void kvm_arch_vcpu_put(struct kvm_vcpu *vcpu)
 {
<span class="p_del">-	atomic_clear_mask(CPUSTAT_RUNNING, &amp;vcpu-&gt;arch.sie_block-&gt;cpuflags);</span>
<span class="p_add">+	atomic_andnot(CPUSTAT_RUNNING, &amp;vcpu-&gt;arch.sie_block-&gt;cpuflags);</span>
 	gmap_disable(vcpu-&gt;arch.gmap);
 	if (test_kvm_facility(vcpu-&gt;kvm, 129)) {
 		save_fp_ctl(&amp;vcpu-&gt;run-&gt;s.regs.fpc);
<span class="p_chunk">@@ -1320,9 +1320,9 @@</span> <span class="p_context"> int kvm_arch_vcpu_setup(struct kvm_vcpu</span>
 						    CPUSTAT_STOPPED);
 
 	if (test_kvm_facility(vcpu-&gt;kvm, 78))
<span class="p_del">-		atomic_set_mask(CPUSTAT_GED2, &amp;vcpu-&gt;arch.sie_block-&gt;cpuflags);</span>
<span class="p_add">+		atomic_or(CPUSTAT_GED2, &amp;vcpu-&gt;arch.sie_block-&gt;cpuflags);</span>
 	else if (test_kvm_facility(vcpu-&gt;kvm, 8))
<span class="p_del">-		atomic_set_mask(CPUSTAT_GED, &amp;vcpu-&gt;arch.sie_block-&gt;cpuflags);</span>
<span class="p_add">+		atomic_or(CPUSTAT_GED, &amp;vcpu-&gt;arch.sie_block-&gt;cpuflags);</span>
 
 	kvm_s390_vcpu_setup_model(vcpu);
 
<span class="p_chunk">@@ -1422,24 +1422,24 @@</span> <span class="p_context"> int kvm_arch_vcpu_runnable(struct kvm_vc</span>
 
 void kvm_s390_vcpu_block(struct kvm_vcpu *vcpu)
 {
<span class="p_del">-	atomic_set_mask(PROG_BLOCK_SIE, &amp;vcpu-&gt;arch.sie_block-&gt;prog20);</span>
<span class="p_add">+	atomic_or(PROG_BLOCK_SIE, &amp;vcpu-&gt;arch.sie_block-&gt;prog20);</span>
 	exit_sie(vcpu);
 }
 
 void kvm_s390_vcpu_unblock(struct kvm_vcpu *vcpu)
 {
<span class="p_del">-	atomic_clear_mask(PROG_BLOCK_SIE, &amp;vcpu-&gt;arch.sie_block-&gt;prog20);</span>
<span class="p_add">+	atomic_andnot(PROG_BLOCK_SIE, &amp;vcpu-&gt;arch.sie_block-&gt;prog20);</span>
 }
 
 static void kvm_s390_vcpu_request(struct kvm_vcpu *vcpu)
 {
<span class="p_del">-	atomic_set_mask(PROG_REQUEST, &amp;vcpu-&gt;arch.sie_block-&gt;prog20);</span>
<span class="p_add">+	atomic_or(PROG_REQUEST, &amp;vcpu-&gt;arch.sie_block-&gt;prog20);</span>
 	exit_sie(vcpu);
 }
 
 static void kvm_s390_vcpu_request_handled(struct kvm_vcpu *vcpu)
 {
<span class="p_del">-	atomic_clear_mask(PROG_REQUEST, &amp;vcpu-&gt;arch.sie_block-&gt;prog20);</span>
<span class="p_add">+	atomic_or(PROG_REQUEST, &amp;vcpu-&gt;arch.sie_block-&gt;prog20);</span>
 }
 
 /*
<span class="p_chunk">@@ -1448,7 +1448,7 @@</span> <span class="p_context"> static void kvm_s390_vcpu_request_handle</span>
  * return immediately. */
 void exit_sie(struct kvm_vcpu *vcpu)
 {
<span class="p_del">-	atomic_set_mask(CPUSTAT_STOP_INT, &amp;vcpu-&gt;arch.sie_block-&gt;cpuflags);</span>
<span class="p_add">+	atomic_or(CPUSTAT_STOP_INT, &amp;vcpu-&gt;arch.sie_block-&gt;cpuflags);</span>
 	while (vcpu-&gt;arch.sie_block-&gt;prog0c &amp; PROG_IN_SIE)
 		cpu_relax();
 }
<span class="p_chunk">@@ -1672,19 +1672,19 @@</span> <span class="p_context"> int kvm_arch_vcpu_ioctl_set_guest_debug(</span>
 	if (dbg-&gt;control &amp; KVM_GUESTDBG_ENABLE) {
 		vcpu-&gt;guest_debug = dbg-&gt;control;
 		/* enforce guest PER */
<span class="p_del">-		atomic_set_mask(CPUSTAT_P, &amp;vcpu-&gt;arch.sie_block-&gt;cpuflags);</span>
<span class="p_add">+		atomic_or(CPUSTAT_P, &amp;vcpu-&gt;arch.sie_block-&gt;cpuflags);</span>
 
 		if (dbg-&gt;control &amp; KVM_GUESTDBG_USE_HW_BP)
 			rc = kvm_s390_import_bp_data(vcpu, dbg);
 	} else {
<span class="p_del">-		atomic_clear_mask(CPUSTAT_P, &amp;vcpu-&gt;arch.sie_block-&gt;cpuflags);</span>
<span class="p_add">+		atomic_andnot(CPUSTAT_P, &amp;vcpu-&gt;arch.sie_block-&gt;cpuflags);</span>
 		vcpu-&gt;arch.guestdbg.last_bp = 0;
 	}
 
 	if (rc) {
 		vcpu-&gt;guest_debug = 0;
 		kvm_s390_clear_bp_data(vcpu);
<span class="p_del">-		atomic_clear_mask(CPUSTAT_P, &amp;vcpu-&gt;arch.sie_block-&gt;cpuflags);</span>
<span class="p_add">+		atomic_andnot(CPUSTAT_P, &amp;vcpu-&gt;arch.sie_block-&gt;cpuflags);</span>
 	}
 
 	return rc;
<span class="p_chunk">@@ -1771,7 +1771,7 @@</span> <span class="p_context"> static int kvm_s390_handle_requests(stru</span>
 	if (kvm_check_request(KVM_REQ_ENABLE_IBS, vcpu)) {
 		if (!ibs_enabled(vcpu)) {
 			trace_kvm_s390_enable_disable_ibs(vcpu-&gt;vcpu_id, 1);
<span class="p_del">-			atomic_set_mask(CPUSTAT_IBS,</span>
<span class="p_add">+			atomic_or(CPUSTAT_IBS,</span>
 					&amp;vcpu-&gt;arch.sie_block-&gt;cpuflags);
 		}
 		goto retry;
<span class="p_chunk">@@ -1780,7 +1780,7 @@</span> <span class="p_context"> static int kvm_s390_handle_requests(stru</span>
 	if (kvm_check_request(KVM_REQ_DISABLE_IBS, vcpu)) {
 		if (ibs_enabled(vcpu)) {
 			trace_kvm_s390_enable_disable_ibs(vcpu-&gt;vcpu_id, 0);
<span class="p_del">-			atomic_clear_mask(CPUSTAT_IBS,</span>
<span class="p_add">+			atomic_andnot(CPUSTAT_IBS,</span>
 					  &amp;vcpu-&gt;arch.sie_block-&gt;cpuflags);
 		}
 		goto retry;
<span class="p_chunk">@@ -2280,7 +2280,7 @@</span> <span class="p_context"> void kvm_s390_vcpu_start(struct kvm_vcpu</span>
 		__disable_ibs_on_all_vcpus(vcpu-&gt;kvm);
 	}
 
<span class="p_del">-	atomic_clear_mask(CPUSTAT_STOPPED, &amp;vcpu-&gt;arch.sie_block-&gt;cpuflags);</span>
<span class="p_add">+	atomic_andnot(CPUSTAT_STOPPED, &amp;vcpu-&gt;arch.sie_block-&gt;cpuflags);</span>
 	/*
 	 * Another VCPU might have used IBS while we were offline.
 	 * Let&#39;s play safe and flush the VCPU at startup.
<span class="p_chunk">@@ -2306,7 +2306,7 @@</span> <span class="p_context"> void kvm_s390_vcpu_stop(struct kvm_vcpu</span>
 	/* SIGP STOP and SIGP STOP AND STORE STATUS has been fully processed */
 	kvm_s390_clear_stop_irq(vcpu);
 
<span class="p_del">-	atomic_set_mask(CPUSTAT_STOPPED, &amp;vcpu-&gt;arch.sie_block-&gt;cpuflags);</span>
<span class="p_add">+	atomic_or(CPUSTAT_STOPPED, &amp;vcpu-&gt;arch.sie_block-&gt;cpuflags);</span>
 	__disable_ibs_on_vcpu(vcpu);
 
 	for (i = 0; i &lt; online_vcpus; i++) {
<span class="p_header">--- a/drivers/gpu/drm/i915/i915_drv.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/i915/i915_drv.c</span>
<span class="p_chunk">@@ -748,7 +748,7 @@</span> <span class="p_context"> static int i915_drm_resume(struct drm_de</span>
 	mutex_lock(&amp;dev-&gt;struct_mutex);
 	if (i915_gem_init_hw(dev)) {
 		DRM_ERROR(&quot;failed to re-initialize GPU, declaring wedged!\n&quot;);
<span class="p_del">-		atomic_set_mask(I915_WEDGED, &amp;dev_priv-&gt;gpu_error.reset_counter);</span>
<span class="p_add">+			atomic_or(I915_WEDGED, &amp;dev_priv-&gt;gpu_error.reset_counter);</span>
 	}
 	mutex_unlock(&amp;dev-&gt;struct_mutex);
 
<span class="p_header">--- a/drivers/gpu/drm/i915/i915_gem.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/i915/i915_gem.c</span>
<span class="p_chunk">@@ -5092,7 +5092,7 @@</span> <span class="p_context"> int i915_gem_init(struct drm_device *dev</span>
 		 * for all other failure, such as an allocation failure, bail.
 		 */
 		DRM_ERROR(&quot;Failed to initialize GPU, declaring it wedged\n&quot;);
<span class="p_del">-		atomic_set_mask(I915_WEDGED, &amp;dev_priv-&gt;gpu_error.reset_counter);</span>
<span class="p_add">+		atomic_or(I915_WEDGED, &amp;dev_priv-&gt;gpu_error.reset_counter);</span>
 		ret = 0;
 	}
 
<span class="p_header">--- a/drivers/gpu/drm/i915/i915_irq.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/i915/i915_irq.c</span>
<span class="p_chunk">@@ -2446,7 +2446,7 @@</span> <span class="p_context"> static void i915_reset_and_wakeup(struct</span>
 			kobject_uevent_env(&amp;dev-&gt;primary-&gt;kdev-&gt;kobj,
 					   KOBJ_CHANGE, reset_done_event);
 		} else {
<span class="p_del">-			atomic_set_mask(I915_WEDGED, &amp;error-&gt;reset_counter);</span>
<span class="p_add">+			atomic_or(I915_WEDGED, &amp;error-&gt;reset_counter);</span>
 		}
 
 		/*
<span class="p_chunk">@@ -2574,7 +2574,7 @@</span> <span class="p_context"> void i915_handle_error(struct drm_device</span>
 	i915_report_and_clear_eir(dev);
 
 	if (wedged) {
<span class="p_del">-		atomic_set_mask(I915_RESET_IN_PROGRESS_FLAG,</span>
<span class="p_add">+		atomic_or(I915_RESET_IN_PROGRESS_FLAG,</span>
 				&amp;dev_priv-&gt;gpu_error.reset_counter);
 
 		/*
<span class="p_header">--- a/drivers/s390/scsi/zfcp_aux.c</span>
<span class="p_header">+++ b/drivers/s390/scsi/zfcp_aux.c</span>
<span class="p_chunk">@@ -529,7 +529,7 @@</span> <span class="p_context"> struct zfcp_port *zfcp_port_enqueue(stru</span>
 	list_add_tail(&amp;port-&gt;list, &amp;adapter-&gt;port_list);
 	write_unlock_irq(&amp;adapter-&gt;port_list_lock);
 
<span class="p_del">-	atomic_set_mask(status | ZFCP_STATUS_COMMON_RUNNING, &amp;port-&gt;status);</span>
<span class="p_add">+	atomic_or(status | ZFCP_STATUS_COMMON_RUNNING, &amp;port-&gt;status);</span>
 
 	return port;
 
<span class="p_header">--- a/drivers/s390/scsi/zfcp_erp.c</span>
<span class="p_header">+++ b/drivers/s390/scsi/zfcp_erp.c</span>
<span class="p_chunk">@@ -190,7 +190,7 @@</span> <span class="p_context"> static struct zfcp_erp_action *zfcp_erp_</span>
 		if (!(act_status &amp; ZFCP_STATUS_ERP_NO_REF))
 			if (scsi_device_get(sdev))
 				return NULL;
<span class="p_del">-		atomic_set_mask(ZFCP_STATUS_COMMON_ERP_INUSE,</span>
<span class="p_add">+		atomic_or(ZFCP_STATUS_COMMON_ERP_INUSE,</span>
 				&amp;zfcp_sdev-&gt;status);
 		erp_action = &amp;zfcp_sdev-&gt;erp_action;
 		memset(erp_action, 0, sizeof(struct zfcp_erp_action));
<span class="p_chunk">@@ -206,7 +206,7 @@</span> <span class="p_context"> static struct zfcp_erp_action *zfcp_erp_</span>
 		if (!get_device(&amp;port-&gt;dev))
 			return NULL;
 		zfcp_erp_action_dismiss_port(port);
<span class="p_del">-		atomic_set_mask(ZFCP_STATUS_COMMON_ERP_INUSE, &amp;port-&gt;status);</span>
<span class="p_add">+		atomic_or(ZFCP_STATUS_COMMON_ERP_INUSE, &amp;port-&gt;status);</span>
 		erp_action = &amp;port-&gt;erp_action;
 		memset(erp_action, 0, sizeof(struct zfcp_erp_action));
 		erp_action-&gt;port = port;
<span class="p_chunk">@@ -217,7 +217,7 @@</span> <span class="p_context"> static struct zfcp_erp_action *zfcp_erp_</span>
 	case ZFCP_ERP_ACTION_REOPEN_ADAPTER:
 		kref_get(&amp;adapter-&gt;ref);
 		zfcp_erp_action_dismiss_adapter(adapter);
<span class="p_del">-		atomic_set_mask(ZFCP_STATUS_COMMON_ERP_INUSE, &amp;adapter-&gt;status);</span>
<span class="p_add">+		atomic_or(ZFCP_STATUS_COMMON_ERP_INUSE, &amp;adapter-&gt;status);</span>
 		erp_action = &amp;adapter-&gt;erp_action;
 		memset(erp_action, 0, sizeof(struct zfcp_erp_action));
 		if (!(atomic_read(&amp;adapter-&gt;status) &amp;
<span class="p_chunk">@@ -254,7 +254,7 @@</span> <span class="p_context"> static int zfcp_erp_action_enqueue(int w</span>
 	act = zfcp_erp_setup_act(need, act_status, adapter, port, sdev);
 	if (!act)
 		goto out;
<span class="p_del">-	atomic_set_mask(ZFCP_STATUS_ADAPTER_ERP_PENDING, &amp;adapter-&gt;status);</span>
<span class="p_add">+	atomic_or(ZFCP_STATUS_ADAPTER_ERP_PENDING, &amp;adapter-&gt;status);</span>
 	++adapter-&gt;erp_total_count;
 	list_add_tail(&amp;act-&gt;list, &amp;adapter-&gt;erp_ready_head);
 	wake_up(&amp;adapter-&gt;erp_ready_wq);
<span class="p_chunk">@@ -486,14 +486,14 @@</span> <span class="p_context"> static void zfcp_erp_adapter_unblock(str</span>
 {
 	if (status_change_set(ZFCP_STATUS_COMMON_UNBLOCKED, &amp;adapter-&gt;status))
 		zfcp_dbf_rec_run(&quot;eraubl1&quot;, &amp;adapter-&gt;erp_action);
<span class="p_del">-	atomic_set_mask(ZFCP_STATUS_COMMON_UNBLOCKED, &amp;adapter-&gt;status);</span>
<span class="p_add">+	atomic_or(ZFCP_STATUS_COMMON_UNBLOCKED, &amp;adapter-&gt;status);</span>
 }
 
 static void zfcp_erp_port_unblock(struct zfcp_port *port)
 {
 	if (status_change_set(ZFCP_STATUS_COMMON_UNBLOCKED, &amp;port-&gt;status))
 		zfcp_dbf_rec_run(&quot;erpubl1&quot;, &amp;port-&gt;erp_action);
<span class="p_del">-	atomic_set_mask(ZFCP_STATUS_COMMON_UNBLOCKED, &amp;port-&gt;status);</span>
<span class="p_add">+	atomic_or(ZFCP_STATUS_COMMON_UNBLOCKED, &amp;port-&gt;status);</span>
 }
 
 static void zfcp_erp_lun_unblock(struct scsi_device *sdev)
<span class="p_chunk">@@ -502,7 +502,7 @@</span> <span class="p_context"> static void zfcp_erp_lun_unblock(struct</span>
 
 	if (status_change_set(ZFCP_STATUS_COMMON_UNBLOCKED, &amp;zfcp_sdev-&gt;status))
 		zfcp_dbf_rec_run(&quot;erlubl1&quot;, &amp;sdev_to_zfcp(sdev)-&gt;erp_action);
<span class="p_del">-	atomic_set_mask(ZFCP_STATUS_COMMON_UNBLOCKED, &amp;zfcp_sdev-&gt;status);</span>
<span class="p_add">+	atomic_or(ZFCP_STATUS_COMMON_UNBLOCKED, &amp;zfcp_sdev-&gt;status);</span>
 }
 
 static void zfcp_erp_action_to_running(struct zfcp_erp_action *erp_action)
<span class="p_chunk">@@ -642,7 +642,7 @@</span> <span class="p_context"> static void zfcp_erp_wakeup(struct zfcp_</span>
 	read_lock_irqsave(&amp;adapter-&gt;erp_lock, flags);
 	if (list_empty(&amp;adapter-&gt;erp_ready_head) &amp;&amp;
 	    list_empty(&amp;adapter-&gt;erp_running_head)) {
<span class="p_del">-			atomic_clear_mask(ZFCP_STATUS_ADAPTER_ERP_PENDING,</span>
<span class="p_add">+			atomic_andnot(ZFCP_STATUS_ADAPTER_ERP_PENDING,</span>
 					  &amp;adapter-&gt;status);
 			wake_up(&amp;adapter-&gt;erp_done_wqh);
 	}
<span class="p_chunk">@@ -665,16 +665,16 @@</span> <span class="p_context"> static int zfcp_erp_adapter_strat_fsf_xc</span>
 	int sleep = 1;
 	struct zfcp_adapter *adapter = erp_action-&gt;adapter;
 
<span class="p_del">-	atomic_clear_mask(ZFCP_STATUS_ADAPTER_XCONFIG_OK, &amp;adapter-&gt;status);</span>
<span class="p_add">+	atomic_andnot(ZFCP_STATUS_ADAPTER_XCONFIG_OK, &amp;adapter-&gt;status);</span>
 
 	for (retries = 7; retries; retries--) {
<span class="p_del">-		atomic_clear_mask(ZFCP_STATUS_ADAPTER_HOST_CON_INIT,</span>
<span class="p_add">+		atomic_andnot(ZFCP_STATUS_ADAPTER_HOST_CON_INIT,</span>
 				  &amp;adapter-&gt;status);
 		write_lock_irq(&amp;adapter-&gt;erp_lock);
 		zfcp_erp_action_to_running(erp_action);
 		write_unlock_irq(&amp;adapter-&gt;erp_lock);
 		if (zfcp_fsf_exchange_config_data(erp_action)) {
<span class="p_del">-			atomic_clear_mask(ZFCP_STATUS_ADAPTER_HOST_CON_INIT,</span>
<span class="p_add">+			atomic_andnot(ZFCP_STATUS_ADAPTER_HOST_CON_INIT,</span>
 					  &amp;adapter-&gt;status);
 			return ZFCP_ERP_FAILED;
 		}
<span class="p_chunk">@@ -692,7 +692,7 @@</span> <span class="p_context"> static int zfcp_erp_adapter_strat_fsf_xc</span>
 		sleep *= 2;
 	}
 
<span class="p_del">-	atomic_clear_mask(ZFCP_STATUS_ADAPTER_HOST_CON_INIT,</span>
<span class="p_add">+	atomic_andnot(ZFCP_STATUS_ADAPTER_HOST_CON_INIT,</span>
 			  &amp;adapter-&gt;status);
 
 	if (!(atomic_read(&amp;adapter-&gt;status) &amp; ZFCP_STATUS_ADAPTER_XCONFIG_OK))
<span class="p_chunk">@@ -764,7 +764,7 @@</span> <span class="p_context"> static void zfcp_erp_adapter_strategy_cl</span>
 	/* all ports and LUNs are closed */
 	zfcp_erp_clear_adapter_status(adapter, ZFCP_STATUS_COMMON_OPEN);
 
<span class="p_del">-	atomic_clear_mask(ZFCP_STATUS_ADAPTER_XCONFIG_OK |</span>
<span class="p_add">+	atomic_andnot(ZFCP_STATUS_ADAPTER_XCONFIG_OK |</span>
 			  ZFCP_STATUS_ADAPTER_LINK_UNPLUGGED, &amp;adapter-&gt;status);
 }
 
<span class="p_chunk">@@ -773,7 +773,7 @@</span> <span class="p_context"> static int zfcp_erp_adapter_strategy_ope</span>
 	struct zfcp_adapter *adapter = act-&gt;adapter;
 
 	if (zfcp_qdio_open(adapter-&gt;qdio)) {
<span class="p_del">-		atomic_clear_mask(ZFCP_STATUS_ADAPTER_XCONFIG_OK |</span>
<span class="p_add">+		atomic_andnot(ZFCP_STATUS_ADAPTER_XCONFIG_OK |</span>
 				  ZFCP_STATUS_ADAPTER_LINK_UNPLUGGED,
 				  &amp;adapter-&gt;status);
 		return ZFCP_ERP_FAILED;
<span class="p_chunk">@@ -784,7 +784,7 @@</span> <span class="p_context"> static int zfcp_erp_adapter_strategy_ope</span>
 		return ZFCP_ERP_FAILED;
 	}
 
<span class="p_del">-	atomic_set_mask(ZFCP_STATUS_COMMON_OPEN, &amp;adapter-&gt;status);</span>
<span class="p_add">+	atomic_or(ZFCP_STATUS_COMMON_OPEN, &amp;adapter-&gt;status);</span>
 
 	return ZFCP_ERP_SUCCEEDED;
 }
<span class="p_chunk">@@ -948,7 +948,7 @@</span> <span class="p_context"> static void zfcp_erp_lun_strategy_clears</span>
 {
 	struct zfcp_scsi_dev *zfcp_sdev = sdev_to_zfcp(sdev);
 
<span class="p_del">-	atomic_clear_mask(ZFCP_STATUS_COMMON_ACCESS_DENIED,</span>
<span class="p_add">+	atomic_andnot(ZFCP_STATUS_COMMON_ACCESS_DENIED,</span>
 			  &amp;zfcp_sdev-&gt;status);
 }
 
<span class="p_chunk">@@ -1187,18 +1187,18 @@</span> <span class="p_context"> static void zfcp_erp_action_dequeue(stru</span>
 	switch (erp_action-&gt;action) {
 	case ZFCP_ERP_ACTION_REOPEN_LUN:
 		zfcp_sdev = sdev_to_zfcp(erp_action-&gt;sdev);
<span class="p_del">-		atomic_clear_mask(ZFCP_STATUS_COMMON_ERP_INUSE,</span>
<span class="p_add">+		atomic_andnot(ZFCP_STATUS_COMMON_ERP_INUSE,</span>
 				  &amp;zfcp_sdev-&gt;status);
 		break;
 
 	case ZFCP_ERP_ACTION_REOPEN_PORT_FORCED:
 	case ZFCP_ERP_ACTION_REOPEN_PORT:
<span class="p_del">-		atomic_clear_mask(ZFCP_STATUS_COMMON_ERP_INUSE,</span>
<span class="p_add">+		atomic_andnot(ZFCP_STATUS_COMMON_ERP_INUSE,</span>
 				  &amp;erp_action-&gt;port-&gt;status);
 		break;
 
 	case ZFCP_ERP_ACTION_REOPEN_ADAPTER:
<span class="p_del">-		atomic_clear_mask(ZFCP_STATUS_COMMON_ERP_INUSE,</span>
<span class="p_add">+		atomic_andnot(ZFCP_STATUS_COMMON_ERP_INUSE,</span>
 				  &amp;erp_action-&gt;adapter-&gt;status);
 		break;
 	}
<span class="p_chunk">@@ -1422,19 +1422,19 @@</span> <span class="p_context"> void zfcp_erp_set_adapter_status(struct</span>
 	unsigned long flags;
 	u32 common_mask = mask &amp; ZFCP_COMMON_FLAGS;
 
<span class="p_del">-	atomic_set_mask(mask, &amp;adapter-&gt;status);</span>
<span class="p_add">+	atomic_or(mask, &amp;adapter-&gt;status);</span>
 
 	if (!common_mask)
 		return;
 
 	read_lock_irqsave(&amp;adapter-&gt;port_list_lock, flags);
 	list_for_each_entry(port, &amp;adapter-&gt;port_list, list)
<span class="p_del">-		atomic_set_mask(common_mask, &amp;port-&gt;status);</span>
<span class="p_add">+		atomic_or(common_mask, &amp;port-&gt;status);</span>
 	read_unlock_irqrestore(&amp;adapter-&gt;port_list_lock, flags);
 
 	spin_lock_irqsave(adapter-&gt;scsi_host-&gt;host_lock, flags);
 	__shost_for_each_device(sdev, adapter-&gt;scsi_host)
<span class="p_del">-		atomic_set_mask(common_mask, &amp;sdev_to_zfcp(sdev)-&gt;status);</span>
<span class="p_add">+		atomic_or(common_mask, &amp;sdev_to_zfcp(sdev)-&gt;status);</span>
 	spin_unlock_irqrestore(adapter-&gt;scsi_host-&gt;host_lock, flags);
 }
 
<span class="p_chunk">@@ -1453,7 +1453,7 @@</span> <span class="p_context"> void zfcp_erp_clear_adapter_status(struc</span>
 	u32 common_mask = mask &amp; ZFCP_COMMON_FLAGS;
 	u32 clear_counter = mask &amp; ZFCP_STATUS_COMMON_ERP_FAILED;
 
<span class="p_del">-	atomic_clear_mask(mask, &amp;adapter-&gt;status);</span>
<span class="p_add">+	atomic_andnot(mask, &amp;adapter-&gt;status);</span>
 
 	if (!common_mask)
 		return;
<span class="p_chunk">@@ -1463,7 +1463,7 @@</span> <span class="p_context"> void zfcp_erp_clear_adapter_status(struc</span>
 
 	read_lock_irqsave(&amp;adapter-&gt;port_list_lock, flags);
 	list_for_each_entry(port, &amp;adapter-&gt;port_list, list) {
<span class="p_del">-		atomic_clear_mask(common_mask, &amp;port-&gt;status);</span>
<span class="p_add">+		atomic_andnot(common_mask, &amp;port-&gt;status);</span>
 		if (clear_counter)
 			atomic_set(&amp;port-&gt;erp_counter, 0);
 	}
<span class="p_chunk">@@ -1471,7 +1471,7 @@</span> <span class="p_context"> void zfcp_erp_clear_adapter_status(struc</span>
 
 	spin_lock_irqsave(adapter-&gt;scsi_host-&gt;host_lock, flags);
 	__shost_for_each_device(sdev, adapter-&gt;scsi_host) {
<span class="p_del">-		atomic_clear_mask(common_mask, &amp;sdev_to_zfcp(sdev)-&gt;status);</span>
<span class="p_add">+		atomic_andnot(common_mask, &amp;sdev_to_zfcp(sdev)-&gt;status);</span>
 		if (clear_counter)
 			atomic_set(&amp;sdev_to_zfcp(sdev)-&gt;erp_counter, 0);
 	}
<span class="p_chunk">@@ -1491,7 +1491,7 @@</span> <span class="p_context"> void zfcp_erp_set_port_status(struct zfc</span>
 	u32 common_mask = mask &amp; ZFCP_COMMON_FLAGS;
 	unsigned long flags;
 
<span class="p_del">-	atomic_set_mask(mask, &amp;port-&gt;status);</span>
<span class="p_add">+	atomic_or(mask, &amp;port-&gt;status);</span>
 
 	if (!common_mask)
 		return;
<span class="p_chunk">@@ -1499,7 +1499,7 @@</span> <span class="p_context"> void zfcp_erp_set_port_status(struct zfc</span>
 	spin_lock_irqsave(port-&gt;adapter-&gt;scsi_host-&gt;host_lock, flags);
 	__shost_for_each_device(sdev, port-&gt;adapter-&gt;scsi_host)
 		if (sdev_to_zfcp(sdev)-&gt;port == port)
<span class="p_del">-			atomic_set_mask(common_mask,</span>
<span class="p_add">+			atomic_or(common_mask,</span>
 					&amp;sdev_to_zfcp(sdev)-&gt;status);
 	spin_unlock_irqrestore(port-&gt;adapter-&gt;scsi_host-&gt;host_lock, flags);
 }
<span class="p_chunk">@@ -1518,7 +1518,7 @@</span> <span class="p_context"> void zfcp_erp_clear_port_status(struct z</span>
 	u32 clear_counter = mask &amp; ZFCP_STATUS_COMMON_ERP_FAILED;
 	unsigned long flags;
 
<span class="p_del">-	atomic_clear_mask(mask, &amp;port-&gt;status);</span>
<span class="p_add">+	atomic_andnot(mask, &amp;port-&gt;status);</span>
 
 	if (!common_mask)
 		return;
<span class="p_chunk">@@ -1529,7 +1529,7 @@</span> <span class="p_context"> void zfcp_erp_clear_port_status(struct z</span>
 	spin_lock_irqsave(port-&gt;adapter-&gt;scsi_host-&gt;host_lock, flags);
 	__shost_for_each_device(sdev, port-&gt;adapter-&gt;scsi_host)
 		if (sdev_to_zfcp(sdev)-&gt;port == port) {
<span class="p_del">-			atomic_clear_mask(common_mask,</span>
<span class="p_add">+			atomic_andnot(common_mask,</span>
 					  &amp;sdev_to_zfcp(sdev)-&gt;status);
 			if (clear_counter)
 				atomic_set(&amp;sdev_to_zfcp(sdev)-&gt;erp_counter, 0);
<span class="p_chunk">@@ -1546,7 +1546,7 @@</span> <span class="p_context"> void zfcp_erp_set_lun_status(struct scsi</span>
 {
 	struct zfcp_scsi_dev *zfcp_sdev = sdev_to_zfcp(sdev);
 
<span class="p_del">-	atomic_set_mask(mask, &amp;zfcp_sdev-&gt;status);</span>
<span class="p_add">+	atomic_or(mask, &amp;zfcp_sdev-&gt;status);</span>
 }
 
 /**
<span class="p_chunk">@@ -1558,7 +1558,7 @@</span> <span class="p_context"> void zfcp_erp_clear_lun_status(struct sc</span>
 {
 	struct zfcp_scsi_dev *zfcp_sdev = sdev_to_zfcp(sdev);
 
<span class="p_del">-	atomic_clear_mask(mask, &amp;zfcp_sdev-&gt;status);</span>
<span class="p_add">+	atomic_andnot(mask, &amp;zfcp_sdev-&gt;status);</span>
 
 	if (mask &amp; ZFCP_STATUS_COMMON_ERP_FAILED)
 		atomic_set(&amp;zfcp_sdev-&gt;erp_counter, 0);
<span class="p_header">--- a/drivers/s390/scsi/zfcp_fc.c</span>
<span class="p_header">+++ b/drivers/s390/scsi/zfcp_fc.c</span>
<span class="p_chunk">@@ -508,7 +508,7 @@</span> <span class="p_context"> static void zfcp_fc_adisc_handler(void *</span>
 	/* port is good, unblock rport without going through erp */
 	zfcp_scsi_schedule_rport_register(port);
  out:
<span class="p_del">-	atomic_clear_mask(ZFCP_STATUS_PORT_LINK_TEST, &amp;port-&gt;status);</span>
<span class="p_add">+	atomic_andnot(ZFCP_STATUS_PORT_LINK_TEST, &amp;port-&gt;status);</span>
 	put_device(&amp;port-&gt;dev);
 	kmem_cache_free(zfcp_fc_req_cache, fc_req);
 }
<span class="p_chunk">@@ -564,14 +564,14 @@</span> <span class="p_context"> void zfcp_fc_link_test_work(struct work_</span>
 	if (atomic_read(&amp;port-&gt;status) &amp; ZFCP_STATUS_PORT_LINK_TEST)
 		goto out;
 
<span class="p_del">-	atomic_set_mask(ZFCP_STATUS_PORT_LINK_TEST, &amp;port-&gt;status);</span>
<span class="p_add">+	atomic_or(ZFCP_STATUS_PORT_LINK_TEST, &amp;port-&gt;status);</span>
 
 	retval = zfcp_fc_adisc(port);
 	if (retval == 0)
 		return;
 
 	/* send of ADISC was not possible */
<span class="p_del">-	atomic_clear_mask(ZFCP_STATUS_PORT_LINK_TEST, &amp;port-&gt;status);</span>
<span class="p_add">+	atomic_andnot(ZFCP_STATUS_PORT_LINK_TEST, &amp;port-&gt;status);</span>
 	zfcp_erp_port_forced_reopen(port, 0, &quot;fcltwk1&quot;);
 
 out:
<span class="p_chunk">@@ -640,7 +640,7 @@</span> <span class="p_context"> static void zfcp_fc_validate_port(struct</span>
 	if (!(atomic_read(&amp;port-&gt;status) &amp; ZFCP_STATUS_COMMON_NOESC))
 		return;
 
<span class="p_del">-	atomic_clear_mask(ZFCP_STATUS_COMMON_NOESC, &amp;port-&gt;status);</span>
<span class="p_add">+	atomic_andnot(ZFCP_STATUS_COMMON_NOESC, &amp;port-&gt;status);</span>
 
 	if ((port-&gt;supported_classes != 0) ||
 	    !list_empty(&amp;port-&gt;unit_list))
<span class="p_header">--- a/drivers/s390/scsi/zfcp_fsf.c</span>
<span class="p_header">+++ b/drivers/s390/scsi/zfcp_fsf.c</span>
<span class="p_chunk">@@ -114,7 +114,7 @@</span> <span class="p_context"> static void zfcp_fsf_link_down_info_eval</span>
 	if (atomic_read(&amp;adapter-&gt;status) &amp; ZFCP_STATUS_ADAPTER_LINK_UNPLUGGED)
 		return;
 
<span class="p_del">-	atomic_set_mask(ZFCP_STATUS_ADAPTER_LINK_UNPLUGGED, &amp;adapter-&gt;status);</span>
<span class="p_add">+	atomic_or(ZFCP_STATUS_ADAPTER_LINK_UNPLUGGED, &amp;adapter-&gt;status);</span>
 
 	zfcp_scsi_schedule_rports_block(adapter);
 
<span class="p_chunk">@@ -345,7 +345,7 @@</span> <span class="p_context"> static void zfcp_fsf_protstatus_eval(str</span>
 		zfcp_erp_adapter_shutdown(adapter, 0, &quot;fspse_3&quot;);
 		break;
 	case FSF_PROT_HOST_CONNECTION_INITIALIZING:
<span class="p_del">-		atomic_set_mask(ZFCP_STATUS_ADAPTER_HOST_CON_INIT,</span>
<span class="p_add">+		atomic_or(ZFCP_STATUS_ADAPTER_HOST_CON_INIT,</span>
 				&amp;adapter-&gt;status);
 		break;
 	case FSF_PROT_DUPLICATE_REQUEST_ID:
<span class="p_chunk">@@ -554,7 +554,7 @@</span> <span class="p_context"> static void zfcp_fsf_exchange_config_dat</span>
 			zfcp_erp_adapter_shutdown(adapter, 0, &quot;fsecdh1&quot;);
 			return;
 		}
<span class="p_del">-		atomic_set_mask(ZFCP_STATUS_ADAPTER_XCONFIG_OK,</span>
<span class="p_add">+		atomic_or(ZFCP_STATUS_ADAPTER_XCONFIG_OK,</span>
 				&amp;adapter-&gt;status);
 		break;
 	case FSF_EXCHANGE_CONFIG_DATA_INCOMPLETE:
<span class="p_chunk">@@ -567,7 +567,7 @@</span> <span class="p_context"> static void zfcp_fsf_exchange_config_dat</span>
 
 		/* avoids adapter shutdown to be able to recognize
 		 * events such as LINK UP */
<span class="p_del">-		atomic_set_mask(ZFCP_STATUS_ADAPTER_XCONFIG_OK,</span>
<span class="p_add">+		atomic_or(ZFCP_STATUS_ADAPTER_XCONFIG_OK,</span>
 				&amp;adapter-&gt;status);
 		zfcp_fsf_link_down_info_eval(req,
 			&amp;qtcb-&gt;header.fsf_status_qual.link_down_info);
<span class="p_chunk">@@ -1394,9 +1394,9 @@</span> <span class="p_context"> static void zfcp_fsf_open_port_handler(s</span>
 		break;
 	case FSF_GOOD:
 		port-&gt;handle = header-&gt;port_handle;
<span class="p_del">-		atomic_set_mask(ZFCP_STATUS_COMMON_OPEN |</span>
<span class="p_add">+		atomic_or(ZFCP_STATUS_COMMON_OPEN |</span>
 				ZFCP_STATUS_PORT_PHYS_OPEN, &amp;port-&gt;status);
<span class="p_del">-		atomic_clear_mask(ZFCP_STATUS_COMMON_ACCESS_BOXED,</span>
<span class="p_add">+		atomic_andnot(ZFCP_STATUS_COMMON_ACCESS_BOXED,</span>
 		                  &amp;port-&gt;status);
 		/* check whether D_ID has changed during open */
 		/*
<span class="p_chunk">@@ -1677,10 +1677,10 @@</span> <span class="p_context"> static void zfcp_fsf_close_physical_port</span>
 	case FSF_PORT_BOXED:
 		/* can&#39;t use generic zfcp_erp_modify_port_status because
 		 * ZFCP_STATUS_COMMON_OPEN must not be reset for the port */
<span class="p_del">-		atomic_clear_mask(ZFCP_STATUS_PORT_PHYS_OPEN, &amp;port-&gt;status);</span>
<span class="p_add">+		atomic_andnot(ZFCP_STATUS_PORT_PHYS_OPEN, &amp;port-&gt;status);</span>
 		shost_for_each_device(sdev, port-&gt;adapter-&gt;scsi_host)
 			if (sdev_to_zfcp(sdev)-&gt;port == port)
<span class="p_del">-				atomic_clear_mask(ZFCP_STATUS_COMMON_OPEN,</span>
<span class="p_add">+				atomic_andnot(ZFCP_STATUS_COMMON_OPEN,</span>
 						  &amp;sdev_to_zfcp(sdev)-&gt;status);
 		zfcp_erp_set_port_status(port, ZFCP_STATUS_COMMON_ACCESS_BOXED);
 		zfcp_erp_port_reopen(port, ZFCP_STATUS_COMMON_ERP_FAILED,
<span class="p_chunk">@@ -1700,10 +1700,10 @@</span> <span class="p_context"> static void zfcp_fsf_close_physical_port</span>
 		/* can&#39;t use generic zfcp_erp_modify_port_status because
 		 * ZFCP_STATUS_COMMON_OPEN must not be reset for the port
 		 */
<span class="p_del">-		atomic_clear_mask(ZFCP_STATUS_PORT_PHYS_OPEN, &amp;port-&gt;status);</span>
<span class="p_add">+		atomic_andnot(ZFCP_STATUS_PORT_PHYS_OPEN, &amp;port-&gt;status);</span>
 		shost_for_each_device(sdev, port-&gt;adapter-&gt;scsi_host)
 			if (sdev_to_zfcp(sdev)-&gt;port == port)
<span class="p_del">-				atomic_clear_mask(ZFCP_STATUS_COMMON_OPEN,</span>
<span class="p_add">+				atomic_andnot(ZFCP_STATUS_COMMON_OPEN,</span>
 						  &amp;sdev_to_zfcp(sdev)-&gt;status);
 		break;
 	}
<span class="p_chunk">@@ -1766,7 +1766,7 @@</span> <span class="p_context"> static void zfcp_fsf_open_lun_handler(st</span>
 
 	zfcp_sdev = sdev_to_zfcp(sdev);
 
<span class="p_del">-	atomic_clear_mask(ZFCP_STATUS_COMMON_ACCESS_DENIED |</span>
<span class="p_add">+	atomic_andnot(ZFCP_STATUS_COMMON_ACCESS_DENIED |</span>
 			  ZFCP_STATUS_COMMON_ACCESS_BOXED,
 			  &amp;zfcp_sdev-&gt;status);
 
<span class="p_chunk">@@ -1822,7 +1822,7 @@</span> <span class="p_context"> static void zfcp_fsf_open_lun_handler(st</span>
 
 	case FSF_GOOD:
 		zfcp_sdev-&gt;lun_handle = header-&gt;lun_handle;
<span class="p_del">-		atomic_set_mask(ZFCP_STATUS_COMMON_OPEN, &amp;zfcp_sdev-&gt;status);</span>
<span class="p_add">+		atomic_or(ZFCP_STATUS_COMMON_OPEN, &amp;zfcp_sdev-&gt;status);</span>
 		break;
 	}
 }
<span class="p_chunk">@@ -1913,7 +1913,7 @@</span> <span class="p_context"> static void zfcp_fsf_close_lun_handler(s</span>
 		}
 		break;
 	case FSF_GOOD:
<span class="p_del">-		atomic_clear_mask(ZFCP_STATUS_COMMON_OPEN, &amp;zfcp_sdev-&gt;status);</span>
<span class="p_add">+		atomic_andnot(ZFCP_STATUS_COMMON_OPEN, &amp;zfcp_sdev-&gt;status);</span>
 		break;
 	}
 }
<span class="p_header">--- a/drivers/s390/scsi/zfcp_qdio.c</span>
<span class="p_header">+++ b/drivers/s390/scsi/zfcp_qdio.c</span>
<span class="p_chunk">@@ -349,7 +349,7 @@</span> <span class="p_context"> void zfcp_qdio_close(struct zfcp_qdio *q</span>
 
 	/* clear QDIOUP flag, thus do_QDIO is not called during qdio_shutdown */
 	spin_lock_irq(&amp;qdio-&gt;req_q_lock);
<span class="p_del">-	atomic_clear_mask(ZFCP_STATUS_ADAPTER_QDIOUP, &amp;adapter-&gt;status);</span>
<span class="p_add">+	atomic_andnot(ZFCP_STATUS_ADAPTER_QDIOUP, &amp;adapter-&gt;status);</span>
 	spin_unlock_irq(&amp;qdio-&gt;req_q_lock);
 
 	wake_up(&amp;qdio-&gt;req_q_wq);
<span class="p_chunk">@@ -384,7 +384,7 @@</span> <span class="p_context"> int zfcp_qdio_open(struct zfcp_qdio *qdi</span>
 	if (atomic_read(&amp;adapter-&gt;status) &amp; ZFCP_STATUS_ADAPTER_QDIOUP)
 		return -EIO;
 
<span class="p_del">-	atomic_clear_mask(ZFCP_STATUS_ADAPTER_SIOSL_ISSUED,</span>
<span class="p_add">+	atomic_andnot(ZFCP_STATUS_ADAPTER_SIOSL_ISSUED,</span>
 			  &amp;qdio-&gt;adapter-&gt;status);
 
 	zfcp_qdio_setup_init_data(&amp;init_data, qdio);
<span class="p_chunk">@@ -396,14 +396,14 @@</span> <span class="p_context"> int zfcp_qdio_open(struct zfcp_qdio *qdi</span>
 		goto failed_qdio;
 
 	if (ssqd.qdioac2 &amp; CHSC_AC2_DATA_DIV_ENABLED)
<span class="p_del">-		atomic_set_mask(ZFCP_STATUS_ADAPTER_DATA_DIV_ENABLED,</span>
<span class="p_add">+		atomic_or(ZFCP_STATUS_ADAPTER_DATA_DIV_ENABLED,</span>
 				&amp;qdio-&gt;adapter-&gt;status);
 
 	if (ssqd.qdioac2 &amp; CHSC_AC2_MULTI_BUFFER_ENABLED) {
<span class="p_del">-		atomic_set_mask(ZFCP_STATUS_ADAPTER_MB_ACT, &amp;adapter-&gt;status);</span>
<span class="p_add">+		atomic_or(ZFCP_STATUS_ADAPTER_MB_ACT, &amp;adapter-&gt;status);</span>
 		qdio-&gt;max_sbale_per_sbal = QDIO_MAX_ELEMENTS_PER_BUFFER;
 	} else {
<span class="p_del">-		atomic_clear_mask(ZFCP_STATUS_ADAPTER_MB_ACT, &amp;adapter-&gt;status);</span>
<span class="p_add">+		atomic_andnot(ZFCP_STATUS_ADAPTER_MB_ACT, &amp;adapter-&gt;status);</span>
 		qdio-&gt;max_sbale_per_sbal = QDIO_MAX_ELEMENTS_PER_BUFFER - 1;
 	}
 
<span class="p_chunk">@@ -427,7 +427,7 @@</span> <span class="p_context"> int zfcp_qdio_open(struct zfcp_qdio *qdi</span>
 	/* set index of first available SBALS / number of available SBALS */
 	qdio-&gt;req_q_idx = 0;
 	atomic_set(&amp;qdio-&gt;req_q_free, QDIO_MAX_BUFFERS_PER_Q);
<span class="p_del">-	atomic_set_mask(ZFCP_STATUS_ADAPTER_QDIOUP, &amp;qdio-&gt;adapter-&gt;status);</span>
<span class="p_add">+	atomic_or(ZFCP_STATUS_ADAPTER_QDIOUP, &amp;qdio-&gt;adapter-&gt;status);</span>
 
 	if (adapter-&gt;scsi_host) {
 		adapter-&gt;scsi_host-&gt;sg_tablesize = qdio-&gt;max_sbale_per_req;
<span class="p_chunk">@@ -499,6 +499,6 @@</span> <span class="p_context"> void zfcp_qdio_siosl(struct zfcp_adapter</span>
 
 	rc = ccw_device_siosl(adapter-&gt;ccw_device);
 	if (!rc)
<span class="p_del">-		atomic_set_mask(ZFCP_STATUS_ADAPTER_SIOSL_ISSUED,</span>
<span class="p_add">+		atomic_or(ZFCP_STATUS_ADAPTER_SIOSL_ISSUED,</span>
 				&amp;adapter-&gt;status);
 }

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



