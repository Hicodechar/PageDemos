
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>[RFC,2/2] vhost: packed ring support - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    [RFC,2/2] vhost: packed ring support</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=2154">Jason Wang</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>Feb. 14, 2018, 2:37 a.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;1518575829-1431-3-git-send-email-jasowang@redhat.com&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/10217955/mbox/"
   >mbox</a>
|
   <a href="/patch/10217955/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/10217955/">/patch/10217955/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
	[172.30.200.125])
	by pdx-korg-patchwork.web.codeaurora.org (Postfix) with ESMTP id
	EFA8860216 for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Wed, 14 Feb 2018 02:47:35 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id CCF6423E64
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Wed, 14 Feb 2018 02:47:35 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id BD49B228C8; Wed, 14 Feb 2018 02:47:35 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-6.9 required=2.0 tests=BAYES_00,RCVD_IN_DNSWL_HI
	autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 88C0E228C8
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Wed, 14 Feb 2018 02:47:34 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S966625AbeBNCr3 (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Tue, 13 Feb 2018 21:47:29 -0500
Received: from mx3-rdu2.redhat.com ([66.187.233.73]:56340 &quot;EHLO
	mx1.redhat.com&quot;
	rhost-flags-OK-OK-OK-FAIL) by vger.kernel.org with ESMTP
	id S966497AbeBNCr1 (ORCPT &lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Tue, 13 Feb 2018 21:47:27 -0500
Received: from smtp.corp.redhat.com
	(int-mx05.intmail.prod.int.rdu2.redhat.com [10.11.54.5])
	(using TLSv1.2 with cipher AECDH-AES256-SHA (256/256 bits))
	(No client certificate requested)
	by mx1.redhat.com (Postfix) with ESMTPS id 9C6BBEAEB0;
	Wed, 14 Feb 2018 02:37:26 +0000 (UTC)
Received: from jason-ThinkPad-T450s.redhat.com (ovpn-12-122.pek2.redhat.com
	[10.72.12.122])
	by smtp.corp.redhat.com (Postfix) with ESMTP id 514AEB34F5;
	Wed, 14 Feb 2018 02:37:23 +0000 (UTC)
From: Jason Wang &lt;jasowang@redhat.com&gt;
To: mst@redhat.com, virtualization@lists.linux-foundation.org,
	linux-kernel@vger.kernel.org, netdev@vger.kernel.org
Cc: wexu@redhat.com, jfreimann@redhat.com, tiwei.bie@intel.com,
	Jason Wang &lt;jasowang@redhat.com&gt;
Subject: [PATCH RFC 2/2] vhost: packed ring support
Date: Wed, 14 Feb 2018 10:37:09 +0800
Message-Id: &lt;1518575829-1431-3-git-send-email-jasowang@redhat.com&gt;
In-Reply-To: &lt;1518575829-1431-1-git-send-email-jasowang@redhat.com&gt;
References: &lt;1518575829-1431-1-git-send-email-jasowang@redhat.com&gt;
X-Scanned-By: MIMEDefang 2.79 on 10.11.54.5
X-Greylist: Sender IP whitelisted, not delayed by milter-greylist-4.5.16
	(mx1.redhat.com [10.11.55.1]);
	Wed, 14 Feb 2018 02:37:26 +0000 (UTC)
X-Greylist: inspected by milter-greylist-4.5.16 (mx1.redhat.com
	[10.11.55.1]);
	Wed, 14 Feb 2018 02:37:26 +0000 (UTC) for IP:&#39;10.11.54.5&#39;
	DOMAIN:&#39;int-mx05.intmail.prod.int.rdu2.redhat.com&#39;
	HELO:&#39;smtp.corp.redhat.com&#39; FROM:&#39;jasowang@redhat.com&#39; RCPT:&#39;&#39;
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=2154">Jason Wang</a> - Feb. 14, 2018, 2:37 a.m.</div>
<pre class="content">
<span class="signed-off-by">Signed-off-by: Jason Wang &lt;jasowang@redhat.com&gt;</span>
---
 drivers/vhost/net.c   |  14 +-
 drivers/vhost/vhost.c | 351 ++++++++++++++++++++++++++++++++++++++++++++++----
 drivers/vhost/vhost.h |   6 +-
 3 files changed, 343 insertions(+), 28 deletions(-)
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=178051">Tiwei Bie</a> - Feb. 27, 2018, 9:03 a.m.</div>
<pre class="content">
On Wed, Feb 14, 2018 at 10:37:09AM +0800, Jason Wang wrote:
[...]
<span class="quote">&gt; +static void set_desc_used(struct vhost_virtqueue *vq,</span>
<span class="quote">&gt; +			  struct vring_desc_packed *desc, bool wrap_counter)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	__virtio16 flags = desc-&gt;flags;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	if (wrap_counter) {</span>
<span class="quote">&gt; +		desc-&gt;flags |= cpu_to_vhost16(vq, DESC_AVAIL);</span>
<span class="quote">&gt; +		desc-&gt;flags |= cpu_to_vhost16(vq, DESC_USED);</span>
<span class="quote">&gt; +	} else {</span>
<span class="quote">&gt; +		desc-&gt;flags &amp;= ~cpu_to_vhost16(vq, DESC_AVAIL);</span>
<span class="quote">&gt; +		desc-&gt;flags &amp;= ~cpu_to_vhost16(vq, DESC_USED);</span>
<span class="quote">&gt; +	}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	desc-&gt;flags = flags;</span>

The `desc-&gt;flags` is restored after the change.
<span class="quote">
&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +static int vhost_get_vq_desc_packed(struct vhost_virtqueue *vq,</span>
<span class="quote">&gt; +				    struct iovec iov[], unsigned int iov_size,</span>
<span class="quote">&gt; +				    unsigned int *out_num, unsigned int *in_num,</span>
<span class="quote">&gt; +				    struct vhost_log *log,</span>
<span class="quote">&gt; +				    unsigned int *log_num)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	struct vring_desc_packed desc;</span>
<span class="quote">&gt; +	int ret, access, i;</span>
<span class="quote">&gt; +	u16 avail_idx = vq-&gt;last_avail_idx;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	/* When we start there are none of either input nor output. */</span>
<span class="quote">&gt; +	*out_num = *in_num = 0;</span>
<span class="quote">&gt; +	if (unlikely(log))</span>
<span class="quote">&gt; +		*log_num = 0;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	do {</span>
<span class="quote">&gt; +		unsigned int iov_count = *in_num + *out_num;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +		i = vq-&gt;last_avail_idx &amp; (vq-&gt;num - 1);</span>

The queue size may not be a power of 2 in packed ring.

Best regards,
Tiwei Bie
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=2154">Jason Wang</a> - Feb. 28, 2018, 2:38 a.m.</div>
<pre class="content">
On 2018年02月27日 17:03, Tiwei Bie wrote:
<span class="quote">&gt; On Wed, Feb 14, 2018 at 10:37:09AM +0800, Jason Wang wrote:</span>
<span class="quote">&gt; [...]</span>
<span class="quote">&gt;&gt; +static void set_desc_used(struct vhost_virtqueue *vq,</span>
<span class="quote">&gt;&gt; +			  struct vring_desc_packed *desc, bool wrap_counter)</span>
<span class="quote">&gt;&gt; +{</span>
<span class="quote">&gt;&gt; +	__virtio16 flags = desc-&gt;flags;</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +	if (wrap_counter) {</span>
<span class="quote">&gt;&gt; +		desc-&gt;flags |= cpu_to_vhost16(vq, DESC_AVAIL);</span>
<span class="quote">&gt;&gt; +		desc-&gt;flags |= cpu_to_vhost16(vq, DESC_USED);</span>
<span class="quote">&gt;&gt; +	} else {</span>
<span class="quote">&gt;&gt; +		desc-&gt;flags &amp;= ~cpu_to_vhost16(vq, DESC_AVAIL);</span>
<span class="quote">&gt;&gt; +		desc-&gt;flags &amp;= ~cpu_to_vhost16(vq, DESC_USED);</span>
<span class="quote">&gt;&gt; +	}</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +	desc-&gt;flags = flags;</span>
<span class="quote">&gt; The `desc-&gt;flags` is restored after the change.</span>

Right, will fix.
<span class="quote">
&gt;&gt; +}</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +static int vhost_get_vq_desc_packed(struct vhost_virtqueue *vq,</span>
<span class="quote">&gt;&gt; +				    struct iovec iov[], unsigned int iov_size,</span>
<span class="quote">&gt;&gt; +				    unsigned int *out_num, unsigned int *in_num,</span>
<span class="quote">&gt;&gt; +				    struct vhost_log *log,</span>
<span class="quote">&gt;&gt; +				    unsigned int *log_num)</span>
<span class="quote">&gt;&gt; +{</span>
<span class="quote">&gt;&gt; +	struct vring_desc_packed desc;</span>
<span class="quote">&gt;&gt; +	int ret, access, i;</span>
<span class="quote">&gt;&gt; +	u16 avail_idx = vq-&gt;last_avail_idx;</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +	/* When we start there are none of either input nor output. */</span>
<span class="quote">&gt;&gt; +	*out_num = *in_num = 0;</span>
<span class="quote">&gt;&gt; +	if (unlikely(log))</span>
<span class="quote">&gt;&gt; +		*log_num = 0;</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +	do {</span>
<span class="quote">&gt;&gt; +		unsigned int iov_count = *in_num + *out_num;</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +		i = vq-&gt;last_avail_idx &amp; (vq-&gt;num - 1);</span>
<span class="quote">&gt; The queue size may not be a power of 2 in packed ring.</span>

Will fix this too.

Thanks
<span class="quote">
&gt; Best regards,</span>
<span class="quote">&gt; Tiwei Bie</span>
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/drivers/vhost/net.c b/drivers/vhost/net.c</span>
<span class="p_header">index c613d2e..65b27c9 100644</span>
<span class="p_header">--- a/drivers/vhost/net.c</span>
<span class="p_header">+++ b/drivers/vhost/net.c</span>
<span class="p_chunk">@@ -67,7 +67,8 @@</span> <span class="p_context"> enum {</span>
 	VHOST_NET_FEATURES = VHOST_FEATURES |
 			 (1ULL &lt;&lt; VHOST_NET_F_VIRTIO_NET_HDR) |
 			 (1ULL &lt;&lt; VIRTIO_NET_F_MRG_RXBUF) |
<span class="p_del">-			 (1ULL &lt;&lt; VIRTIO_F_IOMMU_PLATFORM)</span>
<span class="p_add">+			 (1ULL &lt;&lt; VIRTIO_F_IOMMU_PLATFORM) |</span>
<span class="p_add">+			 (1ULL &lt;&lt; VIRTIO_F_RING_PACKED)</span>
 };
 
 enum {
<span class="p_chunk">@@ -473,6 +474,7 @@</span> <span class="p_context"> static void handle_tx(struct vhost_net *net)</span>
 	struct socket *sock;
 	struct vhost_net_ubuf_ref *uninitialized_var(ubufs);
 	bool zcopy, zcopy_used;
<span class="p_add">+	struct vring_used_elem used;</span>
 
 	mutex_lock(&amp;vq-&gt;mutex);
 	sock = vq-&gt;private_data;
<span class="p_chunk">@@ -494,6 +496,8 @@</span> <span class="p_context"> static void handle_tx(struct vhost_net *net)</span>
 			vhost_zerocopy_signal_used(net, vq);
 
 
<span class="p_add">+		used.idx = vq-&gt;last_avail_idx &amp; (vq-&gt;num - 1);</span>
<span class="p_add">+		used.wrap_counter = vq-&gt;used_wrap_counter;</span>
 		head = vhost_net_tx_get_vq_desc(net, vq, vq-&gt;iov,
 						ARRAY_SIZE(vq-&gt;iov),
 						&amp;out, &amp;in);
<span class="p_chunk">@@ -515,6 +519,8 @@</span> <span class="p_context"> static void handle_tx(struct vhost_net *net)</span>
 		}
 		/* Skip header. TODO: support TSO. */
 		len = iov_length(vq-&gt;iov, out);
<span class="p_add">+		used.id = head;</span>
<span class="p_add">+		used.len = 0;</span>
 		iov_iter_init(&amp;msg.msg_iter, WRITE, vq-&gt;iov, out, len);
 		iov_iter_advance(&amp;msg.msg_iter, hdr_size);
 		/* Sanity check */
<span class="p_chunk">@@ -576,7 +582,7 @@</span> <span class="p_context"> static void handle_tx(struct vhost_net *net)</span>
 			pr_debug(&quot;Truncated TX packet: &quot;
 				 &quot; len %d != %zd\n&quot;, err, len);
 		if (!zcopy_used)
<span class="p_del">-			vhost_add_used_and_signal(&amp;net-&gt;dev, vq, head, 0);</span>
<span class="p_add">+			vhost_add_used_and_signal_n(&amp;net-&gt;dev, vq, &amp;used, 1);</span>
 		else
 			vhost_zerocopy_signal_used(net, vq);
 		vhost_net_tx_packet(net);
<span class="p_chunk">@@ -691,6 +697,8 @@</span> <span class="p_context"> static int get_rx_bufs(struct vhost_virtqueue *vq,</span>
 			r = -ENOBUFS;
 			goto err;
 		}
<span class="p_add">+		heads[headcount].idx = vq-&gt;last_avail_idx &amp; (vq-&gt;num - 1);</span>
<span class="p_add">+		heads[headcount].wrap_counter = vq-&gt;used_wrap_counter;</span>
 		r = vhost_get_vq_desc(vq, vq-&gt;iov + seg,
 				      ARRAY_SIZE(vq-&gt;iov) - seg, &amp;out,
 				      &amp;in, log, log_num);
<span class="p_chunk">@@ -780,6 +788,8 @@</span> <span class="p_context"> static void handle_rx(struct vhost_net *net)</span>
 	vq_log = unlikely(vhost_has_feature(vq, VHOST_F_LOG_ALL)) ?
 		vq-&gt;log : NULL;
 	mergeable = vhost_has_feature(vq, VIRTIO_NET_F_MRG_RXBUF);
<span class="p_add">+	/* FIXME: workaround for current dpdk prototype */</span>
<span class="p_add">+	mergeable = false;</span>
 
 	while ((sock_len = vhost_net_rx_peek_head_len(net, sock-&gt;sk))) {
 		sock_len += sock_hlen;
<span class="p_header">diff --git a/drivers/vhost/vhost.c b/drivers/vhost/vhost.c</span>
<span class="p_header">index 2db5af8..5667d03 100644</span>
<span class="p_header">--- a/drivers/vhost/vhost.c</span>
<span class="p_header">+++ b/drivers/vhost/vhost.c</span>
<span class="p_chunk">@@ -324,6 +324,7 @@</span> <span class="p_context"> static void vhost_vq_reset(struct vhost_dev *dev,</span>
 	vhost_reset_is_le(vq);
 	vhost_disable_cross_endian(vq);
 	vq-&gt;busyloop_timeout = 0;
<span class="p_add">+	vq-&gt;used_wrap_counter = true;</span>
 	vq-&gt;umem = NULL;
 	vq-&gt;iotlb = NULL;
 	__vhost_vq_meta_reset(vq);
<span class="p_chunk">@@ -1136,10 +1137,22 @@</span> <span class="p_context"> static int vhost_iotlb_miss(struct vhost_virtqueue *vq, u64 iova, int access)</span>
 	return 0;
 }
 
<span class="p_del">-static int vq_access_ok(struct vhost_virtqueue *vq, unsigned int num,</span>
<span class="p_del">-			struct vring_desc __user *desc,</span>
<span class="p_del">-			struct vring_avail __user *avail,</span>
<span class="p_del">-			struct vring_used __user *used)</span>
<span class="p_add">+static int vq_access_ok_packed(struct vhost_virtqueue *vq, unsigned int num,</span>
<span class="p_add">+			       struct vring_desc __user *desc,</span>
<span class="p_add">+			       struct vring_avail __user *avail,</span>
<span class="p_add">+			       struct vring_used __user *used)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct vring_desc_packed *packed = (struct vring_desc_packed *)desc;</span>
<span class="p_add">+</span>
<span class="p_add">+	/* FIXME: check device area and driver area */</span>
<span class="p_add">+	return access_ok(VERIFY_READ, packed, num * sizeof(*packed)) &amp;&amp;</span>
<span class="p_add">+	       access_ok(VERIFY_WRITE, packed, num * sizeof(*packed));</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static int vq_access_ok_split(struct vhost_virtqueue *vq, unsigned int num,</span>
<span class="p_add">+			      struct vring_desc __user *desc,</span>
<span class="p_add">+			      struct vring_avail __user *avail,</span>
<span class="p_add">+			      struct vring_used __user *used)</span>
 
 {
 	size_t s = vhost_has_feature(vq, VIRTIO_RING_F_EVENT_IDX) ? 2 : 0;
<span class="p_chunk">@@ -1151,6 +1164,17 @@</span> <span class="p_context"> static int vq_access_ok(struct vhost_virtqueue *vq, unsigned int num,</span>
 			sizeof *used + num * sizeof *used-&gt;ring + s);
 }
 
<span class="p_add">+static int vq_access_ok(struct vhost_virtqueue *vq, unsigned int num,</span>
<span class="p_add">+			struct vring_desc __user *desc,</span>
<span class="p_add">+			struct vring_avail __user *avail,</span>
<span class="p_add">+			struct vring_used __user *used)</span>
<span class="p_add">+{</span>
<span class="p_add">+	if (vhost_has_feature(vq, VIRTIO_F_RING_PACKED))</span>
<span class="p_add">+		return vq_access_ok_packed(vq, num, desc, avail, used);</span>
<span class="p_add">+	else</span>
<span class="p_add">+		return vq_access_ok_split(vq, num, desc, avail, used);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static void vhost_vq_meta_update(struct vhost_virtqueue *vq,
 				 const struct vhost_umem_node *node,
 				 int type)
<span class="p_chunk">@@ -1763,6 +1787,9 @@</span> <span class="p_context"> int vhost_vq_init_access(struct vhost_virtqueue *vq)</span>
 
 	vhost_init_is_le(vq);
 
<span class="p_add">+	if (vhost_has_feature(vq, VIRTIO_F_RING_PACKED))</span>
<span class="p_add">+		return 0;</span>
<span class="p_add">+</span>
 	r = vhost_update_used_flags(vq);
 	if (r)
 		goto err;
<span class="p_chunk">@@ -1947,18 +1974,136 @@</span> <span class="p_context"> static int get_indirect(struct vhost_virtqueue *vq,</span>
 	return 0;
 }
 
<span class="p_del">-/* This looks in the virtqueue and for the first available buffer, and converts</span>
<span class="p_del">- * it to an iovec for convenient access.  Since descriptors consist of some</span>
<span class="p_del">- * number of output then some number of input descriptors, it&#39;s actually two</span>
<span class="p_del">- * iovecs, but we pack them into one and note how many of each there were.</span>
<span class="p_del">- *</span>
<span class="p_del">- * This function returns the descriptor number found, or vq-&gt;num (which is</span>
<span class="p_del">- * never a valid descriptor number) if none was found.  A negative code is</span>
<span class="p_del">- * returned on error. */</span>
<span class="p_del">-int vhost_get_vq_desc(struct vhost_virtqueue *vq,</span>
<span class="p_del">-		      struct iovec iov[], unsigned int iov_size,</span>
<span class="p_del">-		      unsigned int *out_num, unsigned int *in_num,</span>
<span class="p_del">-		      struct vhost_log *log, unsigned int *log_num)</span>
<span class="p_add">+#define DESC_AVAIL (1 &lt;&lt; VRING_DESC_F_AVAIL)</span>
<span class="p_add">+#define DESC_USED  (1 &lt;&lt; VRING_DESC_F_USED)</span>
<span class="p_add">+static bool desc_is_avail(struct vhost_virtqueue *vq,</span>
<span class="p_add">+			  struct vring_desc_packed *desc)</span>
<span class="p_add">+{</span>
<span class="p_add">+	if (vq-&gt;used_wrap_counter)</span>
<span class="p_add">+		if ((desc-&gt;flags &amp; DESC_AVAIL) &amp;&amp; !(desc-&gt;flags &amp; DESC_USED))</span>
<span class="p_add">+			return true;</span>
<span class="p_add">+	if (vq-&gt;used_wrap_counter == false)</span>
<span class="p_add">+		if (!(desc-&gt;flags &amp; DESC_AVAIL) &amp;&amp; (desc-&gt;flags &amp; DESC_USED))</span>
<span class="p_add">+			return true;</span>
<span class="p_add">+</span>
<span class="p_add">+	return false;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static void set_desc_used(struct vhost_virtqueue *vq,</span>
<span class="p_add">+			  struct vring_desc_packed *desc, bool wrap_counter)</span>
<span class="p_add">+{</span>
<span class="p_add">+	__virtio16 flags = desc-&gt;flags;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (wrap_counter) {</span>
<span class="p_add">+		desc-&gt;flags |= cpu_to_vhost16(vq, DESC_AVAIL);</span>
<span class="p_add">+		desc-&gt;flags |= cpu_to_vhost16(vq, DESC_USED);</span>
<span class="p_add">+	} else {</span>
<span class="p_add">+		desc-&gt;flags &amp;= ~cpu_to_vhost16(vq, DESC_AVAIL);</span>
<span class="p_add">+		desc-&gt;flags &amp;= ~cpu_to_vhost16(vq, DESC_USED);</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	desc-&gt;flags = flags;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static int vhost_get_vq_desc_packed(struct vhost_virtqueue *vq,</span>
<span class="p_add">+				    struct iovec iov[], unsigned int iov_size,</span>
<span class="p_add">+				    unsigned int *out_num, unsigned int *in_num,</span>
<span class="p_add">+				    struct vhost_log *log,</span>
<span class="p_add">+				    unsigned int *log_num)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct vring_desc_packed desc;</span>
<span class="p_add">+	int ret, access, i;</span>
<span class="p_add">+	u16 avail_idx = vq-&gt;last_avail_idx;</span>
<span class="p_add">+</span>
<span class="p_add">+	/* When we start there are none of either input nor output. */</span>
<span class="p_add">+	*out_num = *in_num = 0;</span>
<span class="p_add">+	if (unlikely(log))</span>
<span class="p_add">+		*log_num = 0;</span>
<span class="p_add">+</span>
<span class="p_add">+	do {</span>
<span class="p_add">+		unsigned int iov_count = *in_num + *out_num;</span>
<span class="p_add">+</span>
<span class="p_add">+		i = vq-&gt;last_avail_idx &amp; (vq-&gt;num - 1);</span>
<span class="p_add">+		ret = vhost_copy_from_user(vq, &amp;desc, vq-&gt;desc_packed + i,</span>
<span class="p_add">+					   sizeof(desc));</span>
<span class="p_add">+		if (unlikely(ret)) {</span>
<span class="p_add">+			vq_err(vq, &quot;Failed to get descriptor: idx %d addr %p\n&quot;,</span>
<span class="p_add">+				i, vq-&gt;desc_packed + i);</span>
<span class="p_add">+			return -EFAULT;</span>
<span class="p_add">+		}</span>
<span class="p_add">+</span>
<span class="p_add">+		if (!desc_is_avail(vq, &amp;desc)) {</span>
<span class="p_add">+			/* If there&#39;s nothing new since last we looked, return</span>
<span class="p_add">+			 * invalid.</span>
<span class="p_add">+			 */</span>
<span class="p_add">+			if (likely(avail_idx == vq-&gt;last_avail_idx))</span>
<span class="p_add">+				return vq-&gt;num;</span>
<span class="p_add">+		}</span>
<span class="p_add">+</span>
<span class="p_add">+		/* Only start to read descriptor after we&#39;re sure it was</span>
<span class="p_add">+		 * available.</span>
<span class="p_add">+		 */</span>
<span class="p_add">+		smp_rmb();</span>
<span class="p_add">+</span>
<span class="p_add">+		/* FIXME: support indirect */</span>
<span class="p_add">+		if (desc.flags &amp; cpu_to_vhost16(vq, VRING_DESC_F_INDIRECT)) {</span>
<span class="p_add">+			vq_err(vq, &quot;Indirect descriptor is not supported\n&quot;);</span>
<span class="p_add">+			return -EFAULT;</span>
<span class="p_add">+		}</span>
<span class="p_add">+</span>
<span class="p_add">+		if (desc.flags &amp; cpu_to_vhost16(vq, VRING_DESC_F_WRITE))</span>
<span class="p_add">+			access = VHOST_ACCESS_WO;</span>
<span class="p_add">+		else</span>
<span class="p_add">+			access = VHOST_ACCESS_RO;</span>
<span class="p_add">+		ret = translate_desc(vq, vhost64_to_cpu(vq, desc.addr),</span>
<span class="p_add">+				     vhost32_to_cpu(vq, desc.len),</span>
<span class="p_add">+				     iov + iov_count, iov_size - iov_count,</span>
<span class="p_add">+				     access);</span>
<span class="p_add">+		if (unlikely(ret &lt; 0)) {</span>
<span class="p_add">+			if (ret != -EAGAIN)</span>
<span class="p_add">+				vq_err(vq, &quot;Translation failure %d idx %d\n&quot;,</span>
<span class="p_add">+					ret, i);</span>
<span class="p_add">+			return ret;</span>
<span class="p_add">+		}</span>
<span class="p_add">+</span>
<span class="p_add">+		if (access == VHOST_ACCESS_WO) {</span>
<span class="p_add">+			/* If this is an input descriptor,</span>
<span class="p_add">+			 * increment that count.</span>
<span class="p_add">+			 */</span>
<span class="p_add">+			*in_num += ret;</span>
<span class="p_add">+			if (unlikely(log)) {</span>
<span class="p_add">+				log[*log_num].addr =</span>
<span class="p_add">+					vhost64_to_cpu(vq, desc.addr);</span>
<span class="p_add">+				log[*log_num].len =</span>
<span class="p_add">+					vhost32_to_cpu(vq, desc.len);</span>
<span class="p_add">+				++*log_num;</span>
<span class="p_add">+			}</span>
<span class="p_add">+		} else {</span>
<span class="p_add">+			/* If it&#39;s an output descriptor, they&#39;re all supposed</span>
<span class="p_add">+			 * to come before any input descriptors.</span>
<span class="p_add">+			 */</span>
<span class="p_add">+			if (unlikely(*in_num)) {</span>
<span class="p_add">+				vq_err(vq, &quot;Desc out after in: idx %d\n&quot;,</span>
<span class="p_add">+				       i);</span>
<span class="p_add">+				return -EINVAL;</span>
<span class="p_add">+			}</span>
<span class="p_add">+			*out_num += ret;</span>
<span class="p_add">+		}</span>
<span class="p_add">+</span>
<span class="p_add">+		/* On success, increment avail index. */</span>
<span class="p_add">+		if ((++vq-&gt;last_avail_idx &amp; (vq-&gt;num - 1)) == 0)</span>
<span class="p_add">+			vq-&gt;used_wrap_counter ^= 1;</span>
<span class="p_add">+</span>
<span class="p_add">+	/* If this descriptor says it doesn&#39;t chain, we&#39;re done. */</span>
<span class="p_add">+	} while (desc.flags &amp; cpu_to_vhost16(vq, VRING_DESC_F_NEXT));</span>
<span class="p_add">+</span>
<span class="p_add">+	return desc.id;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static int vhost_get_vq_desc_split(struct vhost_virtqueue *vq,</span>
<span class="p_add">+				   struct iovec iov[], unsigned int iov_size,</span>
<span class="p_add">+				   unsigned int *out_num, unsigned int *in_num,</span>
<span class="p_add">+				   struct vhost_log *log, unsigned int *log_num)</span>
 {
 	struct vring_desc desc;
 	unsigned int i, head, found = 0;
<span class="p_chunk">@@ -2096,6 +2241,30 @@</span> <span class="p_context"> int vhost_get_vq_desc(struct vhost_virtqueue *vq,</span>
 	BUG_ON(!(vq-&gt;used_flags &amp; VRING_USED_F_NO_NOTIFY));
 	return head;
 }
<span class="p_add">+</span>
<span class="p_add">+/* This looks in the virtqueue and for the first available buffer, and converts</span>
<span class="p_add">+ * it to an iovec for convenient access.  Since descriptors consist of some</span>
<span class="p_add">+ * number of output then some number of input descriptors, it&#39;s actually two</span>
<span class="p_add">+ * iovecs, but we pack them into one and note how many of each there were.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * This function returns the descriptor number found, or vq-&gt;num (which is</span>
<span class="p_add">+ * never a valid descriptor number) if none was found.  A negative code is</span>
<span class="p_add">+ * returned on error.</span>
<span class="p_add">+ */</span>
<span class="p_add">+int vhost_get_vq_desc(struct vhost_virtqueue *vq,</span>
<span class="p_add">+		      struct iovec iov[], unsigned int iov_size,</span>
<span class="p_add">+		      unsigned int *out_num, unsigned int *in_num,</span>
<span class="p_add">+		      struct vhost_log *log, unsigned int *log_num)</span>
<span class="p_add">+{</span>
<span class="p_add">+	if (vhost_has_feature(vq, VIRTIO_F_RING_PACKED))</span>
<span class="p_add">+		return vhost_get_vq_desc_packed(vq, iov, iov_size,</span>
<span class="p_add">+						out_num, in_num,</span>
<span class="p_add">+						log, log_num);</span>
<span class="p_add">+	else</span>
<span class="p_add">+		return vhost_get_vq_desc_split(vq, iov, iov_size,</span>
<span class="p_add">+					       out_num, in_num,</span>
<span class="p_add">+					       log, log_num);</span>
<span class="p_add">+}</span>
 EXPORT_SYMBOL_GPL(vhost_get_vq_desc);
 
 /* Reverse the effect of vhost_get_vq_desc. Useful for error handling. */
<span class="p_chunk">@@ -2161,10 +2330,48 @@</span> <span class="p_context"> static int __vhost_add_used_n(struct vhost_virtqueue *vq,</span>
 	return 0;
 }
 
<span class="p_del">-/* After we&#39;ve used one of their buffers, we tell them about it.  We&#39;ll then</span>
<span class="p_del">- * want to notify the guest, using eventfd. */</span>
<span class="p_del">-int vhost_add_used_n(struct vhost_virtqueue *vq, struct vring_used_elem *heads,</span>
<span class="p_del">-		     unsigned count)</span>
<span class="p_add">+static int vhost_add_used_n_packed(struct vhost_virtqueue *vq,</span>
<span class="p_add">+				   struct vring_used_elem *heads,</span>
<span class="p_add">+				   unsigned int count)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct vring_desc_packed desc = {</span>
<span class="p_add">+		.addr = 0,</span>
<span class="p_add">+		.flags = 0,</span>
<span class="p_add">+	};</span>
<span class="p_add">+	int i, ret;</span>
<span class="p_add">+</span>
<span class="p_add">+	for (i = 0; i &lt; count; i++) {</span>
<span class="p_add">+		desc.id = heads[i].id;</span>
<span class="p_add">+		desc.len = heads[i].len;</span>
<span class="p_add">+		set_desc_used(vq, &amp;desc, heads[i].wrap_counter);</span>
<span class="p_add">+</span>
<span class="p_add">+		/* Update flags etc before desc is written */</span>
<span class="p_add">+		smp_mb();</span>
<span class="p_add">+</span>
<span class="p_add">+		ret = vhost_copy_to_user(vq, vq-&gt;desc_packed + heads[i].idx,</span>
<span class="p_add">+					 &amp;desc, sizeof(desc));</span>
<span class="p_add">+		if (unlikely(ret)) {</span>
<span class="p_add">+			vq_err(vq, &quot;Failed to set descriptor: idx %d addr %p\n&quot;,</span>
<span class="p_add">+			       heads[i].idx, vq-&gt;desc_packed + heads[i].idx);</span>
<span class="p_add">+			return -EFAULT;</span>
<span class="p_add">+		}</span>
<span class="p_add">+		if (unlikely(vq-&gt;log_used)) {</span>
<span class="p_add">+			/* Make sure desc is written before update log. */</span>
<span class="p_add">+			smp_wmb();</span>
<span class="p_add">+			log_write(vq-&gt;log_base,</span>
<span class="p_add">+				  vq-&gt;log_addr + heads[i].idx * sizeof(desc),</span>
<span class="p_add">+				  sizeof(desc));</span>
<span class="p_add">+			if (vq-&gt;log_ctx)</span>
<span class="p_add">+				eventfd_signal(vq-&gt;log_ctx, 1);</span>
<span class="p_add">+		}</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	return 0;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static int vhost_add_used_n_split(struct vhost_virtqueue *vq,</span>
<span class="p_add">+				  struct vring_used_elem *heads,</span>
<span class="p_add">+				  unsigned int count)</span>
 {
 	int start, n, r;
 
<span class="p_chunk">@@ -2196,6 +2403,19 @@</span> <span class="p_context"> int vhost_add_used_n(struct vhost_virtqueue *vq, struct vring_used_elem *heads,</span>
 	}
 	return r;
 }
<span class="p_add">+</span>
<span class="p_add">+/* After we&#39;ve used one of their buffers, we tell them about it.  We&#39;ll then</span>
<span class="p_add">+ * want to notify the guest, using eventfd.</span>
<span class="p_add">+ */</span>
<span class="p_add">+int vhost_add_used_n(struct vhost_virtqueue *vq,</span>
<span class="p_add">+		     struct vring_used_elem *heads,</span>
<span class="p_add">+		     unsigned int count)</span>
<span class="p_add">+{</span>
<span class="p_add">+	if (vhost_has_feature(vq, VIRTIO_F_RING_PACKED))</span>
<span class="p_add">+		return vhost_add_used_n_packed(vq, heads, count);</span>
<span class="p_add">+	else</span>
<span class="p_add">+		return vhost_add_used_n_split(vq, heads, count);</span>
<span class="p_add">+}</span>
 EXPORT_SYMBOL_GPL(vhost_add_used_n);
 
 static bool vhost_notify(struct vhost_dev *dev, struct vhost_virtqueue *vq)
<span class="p_chunk">@@ -2203,6 +2423,11 @@</span> <span class="p_context"> static bool vhost_notify(struct vhost_dev *dev, struct vhost_virtqueue *vq)</span>
 	__u16 old, new;
 	__virtio16 event;
 	bool v;
<span class="p_add">+</span>
<span class="p_add">+	/* FIXME: check driver area */</span>
<span class="p_add">+	if (vhost_has_feature(vq, VIRTIO_F_RING_PACKED))</span>
<span class="p_add">+		return false;</span>
<span class="p_add">+</span>
 	/* Flush out used index updates. This is paired
 	 * with the barrier that the Guest executes when enabling
 	 * interrupts. */
<span class="p_chunk">@@ -2265,7 +2490,8 @@</span> <span class="p_context"> void vhost_add_used_and_signal_n(struct vhost_dev *dev,</span>
 EXPORT_SYMBOL_GPL(vhost_add_used_and_signal_n);
 
 /* return true if we&#39;re sure that avaiable ring is empty */
<span class="p_del">-bool vhost_vq_avail_empty(struct vhost_dev *dev, struct vhost_virtqueue *vq)</span>
<span class="p_add">+static bool vhost_vq_avail_empty_split(struct vhost_dev *dev,</span>
<span class="p_add">+				       struct vhost_virtqueue *vq)</span>
 {
 	__virtio16 avail_idx;
 	int r;
<span class="p_chunk">@@ -2280,10 +2506,61 @@</span> <span class="p_context"> bool vhost_vq_avail_empty(struct vhost_dev *dev, struct vhost_virtqueue *vq)</span>
 
 	return vq-&gt;avail_idx == vq-&gt;last_avail_idx;
 }
<span class="p_add">+</span>
<span class="p_add">+/* FIXME: unify codes with vhost_enable_notify_packed() */</span>
<span class="p_add">+static bool vhost_vq_avail_empty_packed(struct vhost_dev *dev,</span>
<span class="p_add">+					struct vhost_virtqueue *vq)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct vring_desc_packed desc;</span>
<span class="p_add">+	int ret, i = vq-&gt;last_avail_idx &amp; (vq-&gt;num - 1);</span>
<span class="p_add">+</span>
<span class="p_add">+	ret = vhost_copy_from_user(vq, &amp;desc, vq-&gt;desc_packed + i,</span>
<span class="p_add">+				   sizeof(desc));</span>
<span class="p_add">+	if (unlikely(ret)) {</span>
<span class="p_add">+		vq_err(vq, &quot;Failed to get descriptor: idx %d addr %p\n&quot;,</span>
<span class="p_add">+			i, vq-&gt;desc_packed + i);</span>
<span class="p_add">+		return -EFAULT;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	/* Read flag after desc is read */</span>
<span class="p_add">+	smp_mb();</span>
<span class="p_add">+</span>
<span class="p_add">+	return desc_is_avail(vq, &amp;desc);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+bool vhost_vq_avail_empty(struct vhost_dev *dev, struct vhost_virtqueue *vq)</span>
<span class="p_add">+{</span>
<span class="p_add">+	if (vhost_has_feature(vq, VIRTIO_F_RING_PACKED))</span>
<span class="p_add">+		return vhost_vq_avail_empty_packed(dev, vq);</span>
<span class="p_add">+	else</span>
<span class="p_add">+		return vhost_vq_avail_empty_split(dev, vq);</span>
<span class="p_add">+}</span>
 EXPORT_SYMBOL_GPL(vhost_vq_avail_empty);
 
<span class="p_del">-/* OK, now we need to know about added descriptors. */</span>
<span class="p_del">-bool vhost_enable_notify(struct vhost_dev *dev, struct vhost_virtqueue *vq)</span>
<span class="p_add">+static bool vhost_enable_notify_packed(struct vhost_dev *dev,</span>
<span class="p_add">+				       struct vhost_virtqueue *vq)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct vring_desc_packed desc;</span>
<span class="p_add">+	int ret, i = vq-&gt;last_avail_idx &amp; (vq-&gt;num - 1);</span>
<span class="p_add">+</span>
<span class="p_add">+	/* FIXME: disable notification through device area */</span>
<span class="p_add">+</span>
<span class="p_add">+	ret = vhost_copy_from_user(vq, &amp;desc, vq-&gt;desc_packed + i,</span>
<span class="p_add">+				   sizeof(desc));</span>
<span class="p_add">+	if (unlikely(ret)) {</span>
<span class="p_add">+		vq_err(vq, &quot;Failed to get descriptor: idx %d addr %p\n&quot;,</span>
<span class="p_add">+			i, vq-&gt;desc_packed + i);</span>
<span class="p_add">+		return -EFAULT;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	/* Read flag after desc is read */</span>
<span class="p_add">+	smp_mb();</span>
<span class="p_add">+</span>
<span class="p_add">+	return desc_is_avail(vq, &amp;desc);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static bool vhost_enable_notify_split(struct vhost_dev *dev,</span>
<span class="p_add">+				      struct vhost_virtqueue *vq)</span>
 {
 	__virtio16 avail_idx;
 	int r;
<span class="p_chunk">@@ -2318,10 +2595,25 @@</span> <span class="p_context"> bool vhost_enable_notify(struct vhost_dev *dev, struct vhost_virtqueue *vq)</span>
 
 	return vhost16_to_cpu(vq, avail_idx) != vq-&gt;avail_idx;
 }
<span class="p_add">+</span>
<span class="p_add">+/* OK, now we need to know about added descriptors. */</span>
<span class="p_add">+bool vhost_enable_notify(struct vhost_dev *dev, struct vhost_virtqueue *vq)</span>
<span class="p_add">+{</span>
<span class="p_add">+	if (vhost_has_feature(vq, VIRTIO_F_RING_PACKED))</span>
<span class="p_add">+		return vhost_enable_notify_packed(dev, vq);</span>
<span class="p_add">+	else</span>
<span class="p_add">+		return vhost_enable_notify_split(dev, vq);</span>
<span class="p_add">+}</span>
 EXPORT_SYMBOL_GPL(vhost_enable_notify);
 
<span class="p_del">-/* We don&#39;t need to be notified again. */</span>
<span class="p_del">-void vhost_disable_notify(struct vhost_dev *dev, struct vhost_virtqueue *vq)</span>
<span class="p_add">+static void vhost_disable_notify_packed(struct vhost_dev *dev,</span>
<span class="p_add">+					struct vhost_virtqueue *vq)</span>
<span class="p_add">+{</span>
<span class="p_add">+	/* FIXME: disable notification through device area */</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static void vhost_disable_notify_split(struct vhost_dev *dev,</span>
<span class="p_add">+				       struct vhost_virtqueue *vq)</span>
 {
 	int r;
 
<span class="p_chunk">@@ -2335,6 +2627,15 @@</span> <span class="p_context"> void vhost_disable_notify(struct vhost_dev *dev, struct vhost_virtqueue *vq)</span>
 			       &amp;vq-&gt;used-&gt;flags, r);
 	}
 }
<span class="p_add">+</span>
<span class="p_add">+/* We don&#39;t need to be notified again. */</span>
<span class="p_add">+void vhost_disable_notify(struct vhost_dev *dev, struct vhost_virtqueue *vq)</span>
<span class="p_add">+{</span>
<span class="p_add">+	if (vhost_has_feature(vq, VIRTIO_F_RING_PACKED))</span>
<span class="p_add">+		return vhost_disable_notify_packed(dev, vq);</span>
<span class="p_add">+	else</span>
<span class="p_add">+		return vhost_disable_notify_split(dev, vq);</span>
<span class="p_add">+}</span>
 EXPORT_SYMBOL_GPL(vhost_disable_notify);
 
 /* Create a new message. */
<span class="p_header">diff --git a/drivers/vhost/vhost.h b/drivers/vhost/vhost.h</span>
<span class="p_header">index ac4b605..cf6533a 100644</span>
<span class="p_header">--- a/drivers/vhost/vhost.h</span>
<span class="p_header">+++ b/drivers/vhost/vhost.h</span>
<span class="p_chunk">@@ -87,7 +87,10 @@</span> <span class="p_context"> struct vhost_virtqueue {</span>
 	/* The actual ring of buffers. */
 	struct mutex mutex;
 	unsigned int num;
<span class="p_del">-	struct vring_desc __user *desc;</span>
<span class="p_add">+	union {</span>
<span class="p_add">+		struct vring_desc __user *desc;</span>
<span class="p_add">+		struct vring_desc_packed __user *desc_packed;</span>
<span class="p_add">+	};</span>
 	struct vring_avail __user *avail;
 	struct vring_used __user *used;
 	const struct vhost_umem_node *meta_iotlb[VHOST_NUM_ADDRS];
<span class="p_chunk">@@ -144,6 +147,7 @@</span> <span class="p_context"> struct vhost_virtqueue {</span>
 	bool user_be;
 #endif
 	u32 busyloop_timeout;
<span class="p_add">+	bool used_wrap_counter;</span>
 };
 
 struct vhost_msg_node {

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



