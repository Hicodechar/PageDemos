
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>[v1,04/11] mm/kasan: extend kasan_populate_zero_shadow() - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    [v1,04/11] mm/kasan: extend kasan_populate_zero_shadow()</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=39721">Joonsoo Kim</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>May 16, 2017, 1:16 a.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;1494897409-14408-5-git-send-email-iamjoonsoo.kim@lge.com&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/9728265/mbox/"
   >mbox</a>
|
   <a href="/patch/9728265/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/9728265/">/patch/9728265/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
	[172.30.200.125])
	by pdx-korg-patchwork.web.codeaurora.org (Postfix) with ESMTP id
	52AA760380 for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Tue, 16 May 2017 01:18:06 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 3896B289E8
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Tue, 16 May 2017 01:18:06 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id 2C58E289EB; Tue, 16 May 2017 01:18:06 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-6.5 required=2.0 tests=BAYES_00,DKIM_SIGNED,
	DKIM_VALID, DKIM_VALID_AU, FREEMAIL_FROM, RCVD_IN_DNSWL_HI,
	RCVD_IN_SORBS_SPAM autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 4B768289E8
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Tue, 16 May 2017 01:18:05 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1751357AbdEPBR5 (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Mon, 15 May 2017 21:17:57 -0400
Received: from mail-pg0-f68.google.com ([74.125.83.68]:34579 &quot;EHLO
	mail-pg0-f68.google.com&quot; rhost-flags-OK-OK-OK-OK) by vger.kernel.org
	with ESMTP id S1751040AbdEPBRu (ORCPT
	&lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Mon, 15 May 2017 21:17:50 -0400
Received: by mail-pg0-f68.google.com with SMTP id u187so19164559pgb.1
	for &lt;linux-kernel@vger.kernel.org&gt;;
	Mon, 15 May 2017 18:17:50 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
	d=gmail.com; s=20161025;
	h=from:to:cc:subject:date:message-id:in-reply-to:references;
	bh=OrI8lEqh4BVosflnTOuRVh5sOeZEl2iP5HSKRVZw5ak=;
	b=s28JJxxfsJBM9UfQYesgiKM5pUVBT3KYnIbdffKS9QKC2paUhs3urh25KbCIUtEe9c
	KeJsctVTC7CN1AOnA78fDQlwLE0xkNjRfhIbF9JkKAZEWErCq4+2SfcoJ1l9DXJd3hum
	QlxBT77sbwmNXIuzN99nAV1LgA6heR31HJfsitbugZz1V7NOM9iOi93lP8JUIIjnyWb5
	N+2VdurwNET1z8IAS8FDyDIIKk/S5UMBGFKc82Zq7pkgCNh16efp1QAt960//47brNuS
	wwCEPkMYChbHv2x9CnsKLn+XSzgD+Sp9aA1TWUcCA2pqtMfVfGKChqvs+PbAZI5bNueM
	3SIQ==
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
	d=1e100.net; s=20161025;
	h=x-gm-message-state:from:to:cc:subject:date:message-id:in-reply-to
	:references;
	bh=OrI8lEqh4BVosflnTOuRVh5sOeZEl2iP5HSKRVZw5ak=;
	b=NfKJJEpR41Uj5KVf++EBmkKmMJ89ZAxb+58q3KBFs9yDJ1jfD2Y9pVHCjRA4bDMhQD
	Qrx0pPiKrPuzRYaJXdeapInNZN/c7Q99po8ceOBUmdVxgXvyuMFP5NJ3cROc0t/x5s6a
	TOcykbxbxu98/g353gz8AG5o0+UoaeOlUfkq3oWxOynZQBdwqQKkbQYA9dNUNL0zuGlP
	3YmtrUJusl/LfLtoHQ4hSIqzYi7kPXFvbSBqfzb1QK5GJ19UrXNjEOAxAhdmxV74e9Ou
	VxoSrR5aADc3nZhknx9gydmVdr3G+AG/p2UEj6KFDGOgDnyM/rSP3kRBCMJ8gFuuG/mF
	yF9A==
X-Gm-Message-State: AODbwcA6GWd1wZ3/8OLnUVcrzn1fXTTSZf8eaS7wJsSgyLwUnZftBlll
	IOJHHoz7BQeiGQ==
X-Received: by 10.84.224.1 with SMTP id r1mr1566356plj.78.1494897469871;
	Mon, 15 May 2017 18:17:49 -0700 (PDT)
Received: from localhost.localdomain ([124.56.155.17])
	by smtp.gmail.com with ESMTPSA id
	c7sm25648186pfk.103.2017.05.15.18.17.46
	(version=TLS1_2 cipher=ECDHE-RSA-AES128-SHA bits=128/128);
	Mon, 15 May 2017 18:17:48 -0700 (PDT)
From: js1304@gmail.com
X-Google-Original-From: iamjoonsoo.kim@lge.com
To: Andrew Morton &lt;akpm@linux-foundation.org&gt;
Cc: Andrey Ryabinin &lt;aryabinin@virtuozzo.com&gt;,
	Alexander Potapenko &lt;glider@google.com&gt;,
	Dmitry Vyukov &lt;dvyukov@google.com&gt;, kasan-dev@googlegroups.com,
	linux-mm@kvack.org, linux-kernel@vger.kernel.org,
	Thomas Gleixner &lt;tglx@linutronix.de&gt;, Ingo Molnar &lt;mingo@redhat.com&gt;,
	&quot;H . Peter Anvin&quot; &lt;hpa@zytor.com&gt;, kernel-team@lge.com,
	Joonsoo Kim &lt;iamjoonsoo.kim@lge.com&gt;
Subject: [PATCH v1 04/11] mm/kasan: extend kasan_populate_zero_shadow()
Date: Tue, 16 May 2017 10:16:42 +0900
Message-Id: &lt;1494897409-14408-5-git-send-email-iamjoonsoo.kim@lge.com&gt;
X-Mailer: git-send-email 2.7.4
In-Reply-To: &lt;1494897409-14408-1-git-send-email-iamjoonsoo.kim@lge.com&gt;
References: &lt;1494897409-14408-1-git-send-email-iamjoonsoo.kim@lge.com&gt;
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=39721">Joonsoo Kim</a> - May 16, 2017, 1:16 a.m.</div>
<pre class="content">
<span class="from">From: Joonsoo Kim &lt;iamjoonsoo.kim@lge.com&gt;</span>

In the following patch, per-page shadow memory will be introduced and
some ranges are checked by per-page shadow and the others are checked by
original shadow. To notify the range type, per-page shadow will be mapped
by the page that is filled by a special shadow value,
KASAN_PER_PAGE_BYPASS. Using the actual page for this purpose causes
memory consumption so this patch introduces the black shadow page which
is conceptually similar to the zero shadow page. And, this patch also
extend kasan_populate_zero_shadow() to handle/map the black shadow page.

In addition, this patch adds &#39;private&#39; argument to this function to force
populate intermediate level page table. It will also used by
the following patch to reduce memory consumption.
<span class="signed-off-by">
Signed-off-by: Joonsoo Kim &lt;iamjoonsoo.kim@lge.com&gt;</span>
---
 arch/arm64/mm/kasan_init.c  |  17 +++---
 arch/x86/mm/kasan_init_64.c |  15 +++---
 include/linux/kasan.h       |  11 +++-
 mm/kasan/kasan_init.c       | 123 ++++++++++++++++++++++++++++++--------------
 4 files changed, 112 insertions(+), 54 deletions(-)
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/arch/arm64/mm/kasan_init.c b/arch/arm64/mm/kasan_init.c</span>
<span class="p_header">index 687a358..f60b74d 100644</span>
<span class="p_header">--- a/arch/arm64/mm/kasan_init.c</span>
<span class="p_header">+++ b/arch/arm64/mm/kasan_init.c</span>
<span class="p_chunk">@@ -168,21 +168,24 @@</span> <span class="p_context"> void __init kasan_init(void)</span>
 	 * vmemmap_populate() has populated the shadow region that covers the
 	 * kernel image with SWAPPER_BLOCK_SIZE mappings, so we have to round
 	 * the start and end addresses to SWAPPER_BLOCK_SIZE as well, to prevent
<span class="p_del">-	 * kasan_populate_zero_shadow() from replacing the page table entries</span>
<span class="p_add">+	 * kasan_populate_shadow() from replacing the page table entries</span>
 	 * (PMD or PTE) at the edges of the shadow region for the kernel
 	 * image.
 	 */
 	kimg_shadow_start = round_down(kimg_shadow_start, SWAPPER_BLOCK_SIZE);
 	kimg_shadow_end = round_up(kimg_shadow_end, SWAPPER_BLOCK_SIZE);
 
<span class="p_del">-	kasan_populate_zero_shadow((void *)KASAN_SHADOW_START,</span>
<span class="p_del">-				   (void *)mod_shadow_start);</span>
<span class="p_del">-	kasan_populate_zero_shadow((void *)kimg_shadow_end,</span>
<span class="p_del">-				   kasan_mem_to_shadow((void *)PAGE_OFFSET));</span>
<span class="p_add">+	kasan_populate_shadow((void *)KASAN_SHADOW_START,</span>
<span class="p_add">+				   (void *)mod_shadow_start,</span>
<span class="p_add">+				   true, false);</span>
<span class="p_add">+	kasan_populate_shadow((void *)kimg_shadow_end,</span>
<span class="p_add">+				   kasan_mem_to_shadow((void *)PAGE_OFFSET),</span>
<span class="p_add">+				   true, false);</span>
 
 	if (kimg_shadow_start &gt; mod_shadow_end)
<span class="p_del">-		kasan_populate_zero_shadow((void *)mod_shadow_end,</span>
<span class="p_del">-					   (void *)kimg_shadow_start);</span>
<span class="p_add">+		kasan_populate_shadow((void *)mod_shadow_end,</span>
<span class="p_add">+					   (void *)kimg_shadow_start,</span>
<span class="p_add">+					   true, false);</span>
 
 	for_each_memblock(memory, reg) {
 		void *start = (void *)__phys_to_virt(reg-&gt;base);
<span class="p_header">diff --git a/arch/x86/mm/kasan_init_64.c b/arch/x86/mm/kasan_init_64.c</span>
<span class="p_header">index 0c7d812..adc673b 100644</span>
<span class="p_header">--- a/arch/x86/mm/kasan_init_64.c</span>
<span class="p_header">+++ b/arch/x86/mm/kasan_init_64.c</span>
<span class="p_chunk">@@ -127,8 +127,9 @@</span> <span class="p_context"> void __init kasan_init(void)</span>
 
 	clear_pgds(KASAN_SHADOW_START, KASAN_SHADOW_END);
 
<span class="p_del">-	kasan_populate_zero_shadow((void *)KASAN_SHADOW_START,</span>
<span class="p_del">-			kasan_mem_to_shadow((void *)PAGE_OFFSET));</span>
<span class="p_add">+	kasan_populate_shadow((void *)KASAN_SHADOW_START,</span>
<span class="p_add">+			kasan_mem_to_shadow((void *)PAGE_OFFSET),</span>
<span class="p_add">+			true, false);</span>
 
 	for (i = 0; i &lt; E820_MAX_ENTRIES; i++) {
 		if (pfn_mapped[i].end == 0)
<span class="p_chunk">@@ -137,16 +138,18 @@</span> <span class="p_context"> void __init kasan_init(void)</span>
 		if (map_range(&amp;pfn_mapped[i]))
 			panic(&quot;kasan: unable to allocate shadow!&quot;);
 	}
<span class="p_del">-	kasan_populate_zero_shadow(</span>
<span class="p_add">+	kasan_populate_shadow(</span>
 		kasan_mem_to_shadow((void *)PAGE_OFFSET + MAXMEM),
<span class="p_del">-		kasan_mem_to_shadow((void *)__START_KERNEL_map));</span>
<span class="p_add">+		kasan_mem_to_shadow((void *)__START_KERNEL_map),</span>
<span class="p_add">+		true, false);</span>
 
 	vmemmap_populate((unsigned long)kasan_mem_to_shadow(_stext),
 			(unsigned long)kasan_mem_to_shadow(_end),
 			NUMA_NO_NODE);
 
<span class="p_del">-	kasan_populate_zero_shadow(kasan_mem_to_shadow((void *)MODULES_END),</span>
<span class="p_del">-			(void *)KASAN_SHADOW_END);</span>
<span class="p_add">+	kasan_populate_shadow(kasan_mem_to_shadow((void *)MODULES_END),</span>
<span class="p_add">+			(void *)KASAN_SHADOW_END,</span>
<span class="p_add">+			true, false);</span>
 
 	load_cr3(init_level4_pgt);
 	__flush_tlb_all();
<span class="p_header">diff --git a/include/linux/kasan.h b/include/linux/kasan.h</span>
<span class="p_header">index a5c7046..7e501b3 100644</span>
<span class="p_header">--- a/include/linux/kasan.h</span>
<span class="p_header">+++ b/include/linux/kasan.h</span>
<span class="p_chunk">@@ -21,8 +21,15 @@</span> <span class="p_context"> extern pmd_t kasan_zero_pmd[PTRS_PER_PMD];</span>
 extern pud_t kasan_zero_pud[PTRS_PER_PUD];
 extern p4d_t kasan_zero_p4d[PTRS_PER_P4D];
 
<span class="p_del">-void kasan_populate_zero_shadow(const void *shadow_start,</span>
<span class="p_del">-				const void *shadow_end);</span>
<span class="p_add">+extern unsigned char kasan_black_page[PAGE_SIZE];</span>
<span class="p_add">+extern pte_t kasan_black_pte[PTRS_PER_PTE];</span>
<span class="p_add">+extern pmd_t kasan_black_pmd[PTRS_PER_PMD];</span>
<span class="p_add">+extern pud_t kasan_black_pud[PTRS_PER_PUD];</span>
<span class="p_add">+extern p4d_t kasan_black_p4d[PTRS_PER_P4D];</span>
<span class="p_add">+</span>
<span class="p_add">+void kasan_populate_shadow(const void *shadow_start,</span>
<span class="p_add">+				const void *shadow_end,</span>
<span class="p_add">+				bool zero, bool private);</span>
 
 static inline void *kasan_mem_to_shadow(const void *addr)
 {
<span class="p_header">diff --git a/mm/kasan/kasan_init.c b/mm/kasan/kasan_init.c</span>
<span class="p_header">index 48559d9..cd0a551 100644</span>
<span class="p_header">--- a/mm/kasan/kasan_init.c</span>
<span class="p_header">+++ b/mm/kasan/kasan_init.c</span>
<span class="p_chunk">@@ -21,6 +21,8 @@</span> <span class="p_context"></span>
 #include &lt;asm/page.h&gt;
 #include &lt;asm/pgalloc.h&gt;
 
<span class="p_add">+#include &quot;kasan.h&quot;</span>
<span class="p_add">+</span>
 /*
  * This page serves two purposes:
  *   - It used as early shadow memory. The entire shadow region populated
<span class="p_chunk">@@ -30,16 +32,26 @@</span> <span class="p_context"></span>
  */
 unsigned char kasan_zero_page[PAGE_SIZE] __page_aligned_bss;
 
<span class="p_add">+/*</span>
<span class="p_add">+ * The shadow memory range that this page is mapped will be considered</span>
<span class="p_add">+ * to be checked later by another shadow memory.</span>
<span class="p_add">+ */</span>
<span class="p_add">+unsigned char kasan_black_page[PAGE_SIZE] __page_aligned_bss;</span>
<span class="p_add">+</span>
 #if CONFIG_PGTABLE_LEVELS &gt; 4
 p4d_t kasan_zero_p4d[PTRS_PER_P4D] __page_aligned_bss;
<span class="p_add">+p4d_t kasan_black_p4d[PTRS_PER_P4D] __page_aligned_bss;</span>
 #endif
 #if CONFIG_PGTABLE_LEVELS &gt; 3
 pud_t kasan_zero_pud[PTRS_PER_PUD] __page_aligned_bss;
<span class="p_add">+pud_t kasan_black_pud[PTRS_PER_PUD] __page_aligned_bss;</span>
 #endif
 #if CONFIG_PGTABLE_LEVELS &gt; 2
 pmd_t kasan_zero_pmd[PTRS_PER_PMD] __page_aligned_bss;
<span class="p_add">+pmd_t kasan_black_pmd[PTRS_PER_PMD] __page_aligned_bss;</span>
 #endif
 pte_t kasan_zero_pte[PTRS_PER_PTE] __page_aligned_bss;
<span class="p_add">+pte_t kasan_black_pte[PTRS_PER_PTE] __page_aligned_bss;</span>
 
 static __init void *early_alloc(size_t size, int node)
 {
<span class="p_chunk">@@ -47,32 +59,38 @@</span> <span class="p_context"> static __init void *early_alloc(size_t size, int node)</span>
 					BOOTMEM_ALLOC_ACCESSIBLE, node);
 }
 
<span class="p_del">-static void __init zero_pte_populate(pmd_t *pmd, unsigned long addr,</span>
<span class="p_del">-				unsigned long end)</span>
<span class="p_add">+static void __init kasan_pte_populate(pmd_t *pmd, unsigned long addr,</span>
<span class="p_add">+				unsigned long end, bool zero)</span>
 {
<span class="p_del">-	pte_t *pte = pte_offset_kernel(pmd, addr);</span>
<span class="p_del">-	pte_t zero_pte;</span>
<span class="p_add">+	pte_t *ptep = pte_offset_kernel(pmd, addr);</span>
<span class="p_add">+	pte_t pte;</span>
<span class="p_add">+	unsigned char *page;</span>
 
<span class="p_del">-	zero_pte = pfn_pte(PFN_DOWN(__pa_symbol(kasan_zero_page)), PAGE_KERNEL);</span>
<span class="p_del">-	zero_pte = pte_wrprotect(zero_pte);</span>
<span class="p_add">+	pte = pfn_pte(PFN_DOWN(zero ?</span>
<span class="p_add">+		__pa_symbol(kasan_zero_page) : __pa_symbol(kasan_black_page)),</span>
<span class="p_add">+		PAGE_KERNEL);</span>
<span class="p_add">+	pte = pte_wrprotect(pte);</span>
 
 	while (addr + PAGE_SIZE &lt;= end) {
<span class="p_del">-		set_pte_at(&amp;init_mm, addr, pte, zero_pte);</span>
<span class="p_add">+		set_pte_at(&amp;init_mm, addr, ptep, pte);</span>
 		addr += PAGE_SIZE;
<span class="p_del">-		pte = pte_offset_kernel(pmd, addr);</span>
<span class="p_add">+		ptep = pte_offset_kernel(pmd, addr);</span>
 	}
 
 	if (addr == end)
 		return;
 
 	/* Population for unaligned end address */
<span class="p_del">-	zero_pte = pfn_pte(PFN_DOWN(</span>
<span class="p_del">-		__pa(early_alloc(PAGE_SIZE, NUMA_NO_NODE))), PAGE_KERNEL);</span>
<span class="p_del">-	set_pte_at(&amp;init_mm, addr, pte, zero_pte);</span>
<span class="p_add">+	page = early_alloc(PAGE_SIZE, NUMA_NO_NODE);</span>
<span class="p_add">+	if (!zero)</span>
<span class="p_add">+		__memcpy(page, kasan_black_page, end - addr);</span>
<span class="p_add">+</span>
<span class="p_add">+	pte = pfn_pte(PFN_DOWN(__pa(page)), PAGE_KERNEL);</span>
<span class="p_add">+	set_pte_at(&amp;init_mm, addr, ptep, pte);</span>
 }
 
<span class="p_del">-static void __init zero_pmd_populate(pud_t *pud, unsigned long addr,</span>
<span class="p_del">-				unsigned long end)</span>
<span class="p_add">+static void __init kasan_pmd_populate(pud_t *pud, unsigned long addr,</span>
<span class="p_add">+				unsigned long end, bool zero, bool private)</span>
 {
 	pmd_t *pmd = pmd_offset(pud, addr);
 	unsigned long next;
<span class="p_chunk">@@ -80,8 +98,11 @@</span> <span class="p_context"> static void __init zero_pmd_populate(pud_t *pud, unsigned long addr,</span>
 	do {
 		next = pmd_addr_end(addr, end);
 
<span class="p_del">-		if (IS_ALIGNED(addr, PMD_SIZE) &amp;&amp; end - addr &gt;= PMD_SIZE) {</span>
<span class="p_del">-			pmd_populate_kernel(&amp;init_mm, pmd, lm_alias(kasan_zero_pte));</span>
<span class="p_add">+		if (IS_ALIGNED(addr, PMD_SIZE) &amp;&amp; end - addr &gt;= PMD_SIZE &amp;&amp;</span>
<span class="p_add">+			!private) {</span>
<span class="p_add">+			pmd_populate_kernel(&amp;init_mm, pmd,</span>
<span class="p_add">+				zero ? lm_alias(kasan_zero_pte) :</span>
<span class="p_add">+					lm_alias(kasan_black_pte));</span>
 			continue;
 		}
 
<span class="p_chunk">@@ -89,24 +110,30 @@</span> <span class="p_context"> static void __init zero_pmd_populate(pud_t *pud, unsigned long addr,</span>
 			pmd_populate_kernel(&amp;init_mm, pmd,
 					early_alloc(PAGE_SIZE, NUMA_NO_NODE));
 		}
<span class="p_del">-		zero_pte_populate(pmd, addr, next);</span>
<span class="p_add">+</span>
<span class="p_add">+		kasan_pte_populate(pmd, addr, next, zero);</span>
 	} while (pmd++, addr = next, addr != end);
 }
 
<span class="p_del">-static void __init zero_pud_populate(p4d_t *p4d, unsigned long addr,</span>
<span class="p_del">-				unsigned long end)</span>
<span class="p_add">+static void __init kasan_pud_populate(p4d_t *p4d, unsigned long addr,</span>
<span class="p_add">+				unsigned long end, bool zero, bool private)</span>
 {
 	pud_t *pud = pud_offset(p4d, addr);
 	unsigned long next;
 
 	do {
 		next = pud_addr_end(addr, end);
<span class="p_del">-		if (IS_ALIGNED(addr, PUD_SIZE) &amp;&amp; end - addr &gt;= PUD_SIZE) {</span>
<span class="p_add">+		if (IS_ALIGNED(addr, PUD_SIZE) &amp;&amp; end - addr &gt;= PUD_SIZE &amp;&amp;</span>
<span class="p_add">+			!private) {</span>
 			pmd_t *pmd;
 
<span class="p_del">-			pud_populate(&amp;init_mm, pud, lm_alias(kasan_zero_pmd));</span>
<span class="p_add">+			pud_populate(&amp;init_mm, pud,</span>
<span class="p_add">+				zero ? lm_alias(kasan_zero_pmd) :</span>
<span class="p_add">+					lm_alias(kasan_black_pmd));</span>
 			pmd = pmd_offset(pud, addr);
<span class="p_del">-			pmd_populate_kernel(&amp;init_mm, pmd, lm_alias(kasan_zero_pte));</span>
<span class="p_add">+			pmd_populate_kernel(&amp;init_mm, pmd,</span>
<span class="p_add">+				zero ? lm_alias(kasan_zero_pte) :</span>
<span class="p_add">+					lm_alias(kasan_black_pte));</span>
 			continue;
 		}
 
<span class="p_chunk">@@ -114,28 +141,34 @@</span> <span class="p_context"> static void __init zero_pud_populate(p4d_t *p4d, unsigned long addr,</span>
 			pud_populate(&amp;init_mm, pud,
 				early_alloc(PAGE_SIZE, NUMA_NO_NODE));
 		}
<span class="p_del">-		zero_pmd_populate(pud, addr, next);</span>
<span class="p_add">+		kasan_pmd_populate(pud, addr, next, zero, private);</span>
 	} while (pud++, addr = next, addr != end);
 }
 
<span class="p_del">-static void __init zero_p4d_populate(pgd_t *pgd, unsigned long addr,</span>
<span class="p_del">-				unsigned long end)</span>
<span class="p_add">+static void __init kasan_p4d_populate(pgd_t *pgd, unsigned long addr,</span>
<span class="p_add">+				unsigned long end, bool zero, bool private)</span>
 {
 	p4d_t *p4d = p4d_offset(pgd, addr);
 	unsigned long next;
 
 	do {
 		next = p4d_addr_end(addr, end);
<span class="p_del">-		if (IS_ALIGNED(addr, P4D_SIZE) &amp;&amp; end - addr &gt;= P4D_SIZE) {</span>
<span class="p_add">+		if (IS_ALIGNED(addr, P4D_SIZE) &amp;&amp; end - addr &gt;= P4D_SIZE &amp;&amp;</span>
<span class="p_add">+			!private) {</span>
 			pud_t *pud;
 			pmd_t *pmd;
 
<span class="p_del">-			p4d_populate(&amp;init_mm, p4d, lm_alias(kasan_zero_pud));</span>
<span class="p_add">+			p4d_populate(&amp;init_mm, p4d,</span>
<span class="p_add">+				zero ? lm_alias(kasan_zero_pud) :</span>
<span class="p_add">+					lm_alias(kasan_black_pud));</span>
 			pud = pud_offset(p4d, addr);
<span class="p_del">-			pud_populate(&amp;init_mm, pud, lm_alias(kasan_zero_pmd));</span>
<span class="p_add">+			pud_populate(&amp;init_mm, pud,</span>
<span class="p_add">+				zero ? lm_alias(kasan_zero_pmd) :</span>
<span class="p_add">+					lm_alias(kasan_black_pmd));</span>
 			pmd = pmd_offset(pud, addr);
 			pmd_populate_kernel(&amp;init_mm, pmd,
<span class="p_del">-						lm_alias(kasan_zero_pte));</span>
<span class="p_add">+				zero ? lm_alias(kasan_zero_pte) :</span>
<span class="p_add">+					lm_alias(kasan_black_pte));</span>
 			continue;
 		}
 
<span class="p_chunk">@@ -143,18 +176,21 @@</span> <span class="p_context"> static void __init zero_p4d_populate(pgd_t *pgd, unsigned long addr,</span>
 			p4d_populate(&amp;init_mm, p4d,
 				early_alloc(PAGE_SIZE, NUMA_NO_NODE));
 		}
<span class="p_del">-		zero_pud_populate(p4d, addr, next);</span>
<span class="p_add">+		kasan_pud_populate(p4d, addr, next, zero, private);</span>
 	} while (p4d++, addr = next, addr != end);
 }
 
 /**
<span class="p_del">- * kasan_populate_zero_shadow - populate shadow memory region with</span>
<span class="p_del">- *                               kasan_zero_page</span>
<span class="p_add">+ * kasan_populate_shadow - populate shadow memory region with</span>
<span class="p_add">+ *                               kasan_(zero|black)_page</span>
  * @shadow_start - start of the memory range to populate
  * @shadow_end   - end of the memory range to populate
<span class="p_add">+ * @zero	 - type of populated shadow, zero and black</span>
<span class="p_add">+ * @private	 - force to populate private shadow except the last page</span>
  */
<span class="p_del">-void __init kasan_populate_zero_shadow(const void *shadow_start,</span>
<span class="p_del">-				const void *shadow_end)</span>
<span class="p_add">+void __init kasan_populate_shadow(const void *shadow_start,</span>
<span class="p_add">+				const void *shadow_end,</span>
<span class="p_add">+				bool zero, bool private)</span>
 {
 	unsigned long addr = (unsigned long)shadow_start;
 	unsigned long end = (unsigned long)shadow_end;
<span class="p_chunk">@@ -164,7 +200,8 @@</span> <span class="p_context"> void __init kasan_populate_zero_shadow(const void *shadow_start,</span>
 	do {
 		next = pgd_addr_end(addr, end);
 
<span class="p_del">-		if (IS_ALIGNED(addr, PGDIR_SIZE) &amp;&amp; end - addr &gt;= PGDIR_SIZE) {</span>
<span class="p_add">+		if (IS_ALIGNED(addr, PGDIR_SIZE) &amp;&amp; end - addr &gt;= PGDIR_SIZE &amp;&amp;</span>
<span class="p_add">+			!private) {</span>
 			p4d_t *p4d;
 			pud_t *pud;
 			pmd_t *pmd;
<span class="p_chunk">@@ -187,14 +224,22 @@</span> <span class="p_context"> void __init kasan_populate_zero_shadow(const void *shadow_start,</span>
 			 * architectures will switch to pgtable-nop4d.h.
 			 */
 #ifndef __ARCH_HAS_5LEVEL_HACK
<span class="p_del">-			pgd_populate(&amp;init_mm, pgd, lm_alias(kasan_zero_p4d));</span>
<span class="p_add">+			pgd_populate(&amp;init_mm, pgd,</span>
<span class="p_add">+				zero ? lm_alias(kasan_zero_p4d) :</span>
<span class="p_add">+					lm_alias(kasan_black_p4d));</span>
 #endif
 			p4d = p4d_offset(pgd, addr);
<span class="p_del">-			p4d_populate(&amp;init_mm, p4d, lm_alias(kasan_zero_pud));</span>
<span class="p_add">+			p4d_populate(&amp;init_mm, p4d,</span>
<span class="p_add">+				zero ? lm_alias(kasan_zero_pud) :</span>
<span class="p_add">+					lm_alias(kasan_black_pud));</span>
 			pud = pud_offset(p4d, addr);
<span class="p_del">-			pud_populate(&amp;init_mm, pud, lm_alias(kasan_zero_pmd));</span>
<span class="p_add">+			pud_populate(&amp;init_mm, pud,</span>
<span class="p_add">+				zero ? lm_alias(kasan_zero_pmd) :</span>
<span class="p_add">+					lm_alias(kasan_black_pmd));</span>
 			pmd = pmd_offset(pud, addr);
<span class="p_del">-			pmd_populate_kernel(&amp;init_mm, pmd, lm_alias(kasan_zero_pte));</span>
<span class="p_add">+			pmd_populate_kernel(&amp;init_mm, pmd,</span>
<span class="p_add">+				zero ? lm_alias(kasan_zero_pte) :</span>
<span class="p_add">+					lm_alias(kasan_black_pte));</span>
 			continue;
 		}
 
<span class="p_chunk">@@ -202,6 +247,6 @@</span> <span class="p_context"> void __init kasan_populate_zero_shadow(const void *shadow_start,</span>
 			pgd_populate(&amp;init_mm, pgd,
 				early_alloc(PAGE_SIZE, NUMA_NO_NODE));
 		}
<span class="p_del">-		zero_p4d_populate(pgd, addr, next);</span>
<span class="p_add">+		kasan_p4d_populate(pgd, addr, next, zero, private);</span>
 	} while (pgd++, addr = next, addr != end);
 }

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



