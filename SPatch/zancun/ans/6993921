
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>[3.13.y-ckt,stable] Linux 3.13.11-ckt25 - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    [3.13.y-ckt,stable] Linux 3.13.11-ckt25</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=7718">Kamal Mostafa</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>Aug. 11, 2015, 5:22 p.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;1439313770-27516-2-git-send-email-kamal@canonical.com&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/6993921/mbox/"
   >mbox</a>
|
   <a href="/patch/6993921/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/6993921/">/patch/6993921/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
X-Original-To: patchwork-LKML@patchwork.kernel.org
Delivered-To: patchwork-parsemail@patchwork2.web.kernel.org
Received: from mail.kernel.org (mail.kernel.org [198.145.29.136])
	by patchwork2.web.kernel.org (Postfix) with ESMTP id 645BEC05AC
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Tue, 11 Aug 2015 17:23:31 +0000 (UTC)
Received: from mail.kernel.org (localhost [127.0.0.1])
	by mail.kernel.org (Postfix) with ESMTP id 7972F2060A
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Tue, 11 Aug 2015 17:23:27 +0000 (UTC)
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.kernel.org (Postfix) with ESMTP id 783D620562
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Tue, 11 Aug 2015 17:23:23 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1752283AbbHKRXS (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Tue, 11 Aug 2015 13:23:18 -0400
Received: from youngberry.canonical.com ([91.189.89.112]:52747 &quot;EHLO
	youngberry.canonical.com&quot; rhost-flags-OK-OK-OK-OK) by vger.kernel.org
	with ESMTP id S933160AbbHKRW4 (ORCPT
	&lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Tue, 11 Aug 2015 13:22:56 -0400
Received: from 1.general.kamal.us.vpn ([10.172.68.52] helo=fourier)
	by youngberry.canonical.com with esmtpsa
	(TLS1.0:DHE_RSA_AES_128_CBC_SHA1:16) (Exim 4.76)
	(envelope-from &lt;kamal@canonical.com&gt;)
	id 1ZPDGI-0000xm-3T; Tue, 11 Aug 2015 17:22:54 +0000
Received: from kamal by fourier with local (Exim 4.82)
	(envelope-from &lt;kamal@whence.com&gt;)
	id 1ZPDGF-0007AZ-Sl; Tue, 11 Aug 2015 10:22:51 -0700
From: Kamal Mostafa &lt;kamal@canonical.com&gt;
To: linux-kernel@vger.kernel.org, stable@vger.kernel.org,
	kernel-team@lists.ubuntu.com
Cc: lwn@lwn.net
Subject: Re: [3.13.y-ckt stable] Linux 3.13.11-ckt25
Date: Tue, 11 Aug 2015 10:22:50 -0700
Message-Id: &lt;1439313770-27516-2-git-send-email-kamal@canonical.com&gt;
X-Mailer: git-send-email 1.9.1
In-Reply-To: &lt;1439313770-27516-1-git-send-email-kamal@canonical.com&gt;
References: &lt;1439313770-27516-1-git-send-email-kamal@canonical.com&gt;
X-Extended-Stable: 3.13
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Spam-Status: No, score=-7.1 required=5.0 tests=BAYES_00, RCVD_IN_DNSWL_HI, 
	RP_MATCHES_RCVD,
	UNPARSEABLE_RELAY autolearn=unavailable version=3.3.1
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on mail.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=7718">Kamal Mostafa</a> - Aug. 11, 2015, 5:22 p.m.</div>
<pre class="content">
--
To unsubscribe from this list: send the line &quot;unsubscribe linux-kernel&quot; in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
Please read the FAQ at  http://www.tux.org/lkml/
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/Makefile b/Makefile</span>
<span class="p_header">index d2cf49b..964e360 100644</span>
<span class="p_header">--- a/Makefile</span>
<span class="p_header">+++ b/Makefile</span>
<span class="p_chunk">@@ -1,7 +1,7 @@</span> <span class="p_context"></span>
 VERSION = 3
 PATCHLEVEL = 13
 SUBLEVEL = 11
<span class="p_del">-EXTRAVERSION = -ckt24</span>
<span class="p_add">+EXTRAVERSION = -ckt25</span>
 NAME = King of Alienated Frog Porn
 
 # *DOCUMENTATION*
<span class="p_header">diff --git a/arch/arc/include/asm/ptrace.h b/arch/arc/include/asm/ptrace.h</span>
<span class="p_header">index 1bfeec2..2a58af7 100644</span>
<span class="p_header">--- a/arch/arc/include/asm/ptrace.h</span>
<span class="p_header">+++ b/arch/arc/include/asm/ptrace.h</span>
<span class="p_chunk">@@ -63,7 +63,7 @@</span> <span class="p_context"> struct callee_regs {</span>
 	long r25, r24, r23, r22, r21, r20, r19, r18, r17, r16, r15, r14, r13;
 };
 
<span class="p_del">-#define instruction_pointer(regs)	((regs)-&gt;ret)</span>
<span class="p_add">+#define instruction_pointer(regs)	(unsigned long)((regs)-&gt;ret)</span>
 #define profile_pc(regs)		instruction_pointer(regs)
 
 /* return 1 if user mode or 0 if kernel mode */
<span class="p_header">diff --git a/arch/arm/boot/dts/imx23.dtsi b/arch/arm/boot/dts/imx23.dtsi</span>
<span class="p_header">index c96ceae..c800c1e 100644</span>
<span class="p_header">--- a/arch/arm/boot/dts/imx23.dtsi</span>
<span class="p_header">+++ b/arch/arm/boot/dts/imx23.dtsi</span>
<span class="p_chunk">@@ -432,6 +432,7 @@</span> <span class="p_context"></span>
 				interrupts = &lt;36 37 38 39 40 41 42 43 44&gt;;
 				status = &quot;disabled&quot;;
 				clocks = &lt;&amp;clks 26&gt;;
<span class="p_add">+				#io-channel-cells = &lt;1&gt;;</span>
 			};
 
 			spdif@80054000 {
<span class="p_header">diff --git a/arch/s390/kernel/process.c b/arch/s390/kernel/process.c</span>
<span class="p_header">index 7ed0d4e..f9c21cf 100644</span>
<span class="p_header">--- a/arch/s390/kernel/process.c</span>
<span class="p_header">+++ b/arch/s390/kernel/process.c</span>
<span class="p_chunk">@@ -195,7 +195,7 @@</span> <span class="p_context"> asmlinkage void execve_tail(void)</span>
 {
 	current-&gt;thread.fp_regs.fpc = 0;
 	if (MACHINE_HAS_IEEE)
<span class="p_del">-		asm volatile(&quot;sfpc %0,%0&quot; : : &quot;d&quot; (0));</span>
<span class="p_add">+		asm volatile(&quot;sfpc %0&quot; : : &quot;d&quot; (0));</span>
 }
 
 /*
<span class="p_header">diff --git a/arch/s390/kernel/sclp.S b/arch/s390/kernel/sclp.S</span>
<span class="p_header">index 29bd7be..1ecd47b 100644</span>
<span class="p_header">--- a/arch/s390/kernel/sclp.S</span>
<span class="p_header">+++ b/arch/s390/kernel/sclp.S</span>
<span class="p_chunk">@@ -276,6 +276,8 @@</span> <span class="p_context"> ENTRY(_sclp_print_early)</span>
 	jno	.Lesa2
 	ahi	%r15,-80
 	stmh	%r6,%r15,96(%r15)		# store upper register halves
<span class="p_add">+	basr	%r13,0</span>
<span class="p_add">+	lmh	%r0,%r15,.Lzeroes-.(%r13)	# clear upper register halves</span>
 .Lesa2:
 #endif
 	lr	%r10,%r2			# save string pointer
<span class="p_chunk">@@ -299,6 +301,8 @@</span> <span class="p_context"> ENTRY(_sclp_print_early)</span>
 #endif
 	lm	%r6,%r15,120(%r15)		# restore registers
 	br	%r14
<span class="p_add">+.Lzeroes:</span>
<span class="p_add">+	.fill	64,4,0</span>
 
 .LwritedataS4:
 	.long	0x00760005			# SCLP command for write data
<span class="p_header">diff --git a/arch/x86/kernel/entry_64.S b/arch/x86/kernel/entry_64.S</span>
<span class="p_header">index 082d3ce..8ca354c 100644</span>
<span class="p_header">--- a/arch/x86/kernel/entry_64.S</span>
<span class="p_header">+++ b/arch/x86/kernel/entry_64.S</span>
<span class="p_chunk">@@ -1706,19 +1706,7 @@</span> <span class="p_context"> ENTRY(error_exit)</span>
 	CFI_ENDPROC
 END(error_exit)
 
<span class="p_del">-/*</span>
<span class="p_del">- * Test if a given stack is an NMI stack or not.</span>
<span class="p_del">- */</span>
<span class="p_del">-	.macro test_in_nmi reg stack nmi_ret normal_ret</span>
<span class="p_del">-	cmpq %\reg, \stack</span>
<span class="p_del">-	ja \normal_ret</span>
<span class="p_del">-	subq $EXCEPTION_STKSZ, %\reg</span>
<span class="p_del">-	cmpq %\reg, \stack</span>
<span class="p_del">-	jb \normal_ret</span>
<span class="p_del">-	jmp \nmi_ret</span>
<span class="p_del">-	.endm</span>
<span class="p_del">-</span>
<span class="p_del">-	/* runs on exception stack */</span>
<span class="p_add">+/* Runs on exception stack */</span>
 ENTRY(nmi)
 	INTR_FRAME
 	PARAVIRT_ADJUST_EXCEPTION_FRAME
<span class="p_chunk">@@ -1739,11 +1727,12 @@</span> <span class="p_context"> ENTRY(nmi)</span>
 	 *  If the variable is not set and the stack is not the NMI
 	 *  stack then:
 	 *    o Set the special variable on the stack
<span class="p_del">-	 *    o Copy the interrupt frame into a &quot;saved&quot; location on the stack</span>
<span class="p_del">-	 *    o Copy the interrupt frame into a &quot;copy&quot; location on the stack</span>
<span class="p_add">+	 *    o Copy the interrupt frame into an &quot;outermost&quot; location on the</span>
<span class="p_add">+	 *      stack</span>
<span class="p_add">+	 *    o Copy the interrupt frame into an &quot;iret&quot; location on the stack</span>
 	 *    o Continue processing the NMI
 	 *  If the variable is set or the previous stack is the NMI stack:
<span class="p_del">-	 *    o Modify the &quot;copy&quot; location to jump to the repeate_nmi</span>
<span class="p_add">+	 *    o Modify the &quot;iret&quot; location to jump to the repeat_nmi</span>
 	 *    o return back to the first NMI
 	 *
 	 * Now on exit of the first NMI, we first clear the stack variable
<span class="p_chunk">@@ -1752,52 +1741,194 @@</span> <span class="p_context"> ENTRY(nmi)</span>
 	 * a nested NMI that updated the copy interrupt stack frame, a
 	 * jump will be made to the repeat_nmi code that will handle the second
 	 * NMI.
<span class="p_add">+	 *</span>
<span class="p_add">+	 * However, espfix prevents us from directly returning to userspace</span>
<span class="p_add">+	 * with a single IRET instruction.  Similarly, IRET to user mode</span>
<span class="p_add">+	 * can fault.  We therefore handle NMIs from user space like</span>
<span class="p_add">+	 * other IST entries.</span>
 	 */
 
 	/* Use %rdx as out temp variable throughout */
 	pushq_cfi %rdx
 	CFI_REL_OFFSET rdx, 0
 
<span class="p_add">+	testb	$3, CS-RIP+8(%rsp)</span>
<span class="p_add">+	jz	.Lnmi_from_kernel</span>
<span class="p_add">+</span>
 	/*
<span class="p_del">-	 * If %cs was not the kernel segment, then the NMI triggered in user</span>
<span class="p_del">-	 * space, which means it is definitely not nested.</span>
<span class="p_add">+	 * NMI from user mode.  We need to run on the thread stack, but we</span>
<span class="p_add">+	 * can&#39;t go through the normal entry paths: NMIs are masked, and</span>
<span class="p_add">+	 * we don&#39;t want to enable interrupts, because then we&#39;ll end</span>
<span class="p_add">+	 * up in an awkward situation in which IRQs are on but NMIs</span>
<span class="p_add">+	 * are off.</span>
 	 */
<span class="p_del">-	cmpl $__KERNEL_CS, 16(%rsp)</span>
<span class="p_del">-	jne first_nmi</span>
<span class="p_add">+</span>
<span class="p_add">+	SWAPGS</span>
<span class="p_add">+	cld</span>
<span class="p_add">+	movq	%rsp, %rdx</span>
<span class="p_add">+	movq	PER_CPU_VAR(kernel_stack), %rsp</span>
<span class="p_add">+	addq	$KERNEL_STACK_OFFSET, %rsp</span>
<span class="p_add">+	pushq	5*8(%rdx)	/* pt_regs-&gt;ss */</span>
<span class="p_add">+	pushq	4*8(%rdx)	/* pt_regs-&gt;rsp */</span>
<span class="p_add">+	pushq	3*8(%rdx)	/* pt_regs-&gt;flags */</span>
<span class="p_add">+	pushq	2*8(%rdx)	/* pt_regs-&gt;cs */</span>
<span class="p_add">+	pushq	1*8(%rdx)	/* pt_regs-&gt;rip */</span>
<span class="p_add">+	pushq   $-1		/* pt_regs-&gt;orig_ax */</span>
<span class="p_add">+	pushq   %rdi		/* pt_regs-&gt;di */</span>
<span class="p_add">+	pushq   %rsi		/* pt_regs-&gt;si */</span>
<span class="p_add">+	pushq   (%rdx)		/* pt_regs-&gt;dx */</span>
<span class="p_add">+	pushq   %rcx		/* pt_regs-&gt;cx */</span>
<span class="p_add">+	pushq   %rax		/* pt_regs-&gt;ax */</span>
<span class="p_add">+	pushq   %r8		/* pt_regs-&gt;r8 */</span>
<span class="p_add">+	pushq   %r9		/* pt_regs-&gt;r9 */</span>
<span class="p_add">+	pushq   %r10		/* pt_regs-&gt;r10 */</span>
<span class="p_add">+	pushq   %r11		/* pt_regs-&gt;r11 */</span>
<span class="p_add">+	pushq	%rbx		/* pt_regs-&gt;rbx */</span>
<span class="p_add">+	pushq	%rbp		/* pt_regs-&gt;rbp */</span>
<span class="p_add">+	pushq	%r12		/* pt_regs-&gt;r12 */</span>
<span class="p_add">+	pushq	%r13		/* pt_regs-&gt;r13 */</span>
<span class="p_add">+	pushq	%r14		/* pt_regs-&gt;r14 */</span>
<span class="p_add">+	pushq	%r15		/* pt_regs-&gt;r15 */</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * At this point we no longer need to worry about stack damage</span>
<span class="p_add">+	 * due to nesting -- we&#39;re on the normal thread stack and we&#39;re</span>
<span class="p_add">+	 * done with the NMI stack.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+</span>
<span class="p_add">+	movq	%rsp, %rdi</span>
<span class="p_add">+	movq	$-1, %rsi</span>
<span class="p_add">+	call	do_nmi</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Return back to user mode.  We must *not* do the normal exit</span>
<span class="p_add">+	 * work, because we don&#39;t want to enable interrupts.  Fortunately,</span>
<span class="p_add">+	 * do_nmi doesn&#39;t modify pt_regs.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	SWAPGS</span>
 
 	/*
<span class="p_del">-	 * Check the special variable on the stack to see if NMIs are</span>
<span class="p_del">-	 * executing.</span>
<span class="p_add">+	 * Open-code the entire return process for compatibility with varying</span>
<span class="p_add">+	 * register layouts across different kernel versions.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	addq	$6*8, %rsp	/* skip bx, bp, and r12-r15 */</span>
<span class="p_add">+	popq	%r11		/* pt_regs-&gt;r11 */</span>
<span class="p_add">+	popq	%r10		/* pt_regs-&gt;r10 */</span>
<span class="p_add">+	popq	%r9		/* pt_regs-&gt;r9 */</span>
<span class="p_add">+	popq	%r8		/* pt_regs-&gt;r8 */</span>
<span class="p_add">+	popq	%rax		/* pt_regs-&gt;ax */</span>
<span class="p_add">+	popq	%rcx		/* pt_regs-&gt;cx */</span>
<span class="p_add">+	popq	%rdx		/* pt_regs-&gt;dx */</span>
<span class="p_add">+	popq	%rsi		/* pt_regs-&gt;si */</span>
<span class="p_add">+	popq	%rdi		/* pt_regs-&gt;di */</span>
<span class="p_add">+	addq	$8, %rsp	/* skip orig_ax */</span>
<span class="p_add">+	INTERRUPT_RETURN</span>
<span class="p_add">+</span>
<span class="p_add">+.Lnmi_from_kernel:</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Here&#39;s what our stack frame will look like:</span>
<span class="p_add">+	 * +---------------------------------------------------------+</span>
<span class="p_add">+	 * | original SS                                             |</span>
<span class="p_add">+	 * | original Return RSP                                     |</span>
<span class="p_add">+	 * | original RFLAGS                                         |</span>
<span class="p_add">+	 * | original CS                                             |</span>
<span class="p_add">+	 * | original RIP                                            |</span>
<span class="p_add">+	 * +---------------------------------------------------------+</span>
<span class="p_add">+	 * | temp storage for rdx                                    |</span>
<span class="p_add">+	 * +---------------------------------------------------------+</span>
<span class="p_add">+	 * | &quot;NMI executing&quot; variable                                |</span>
<span class="p_add">+	 * +---------------------------------------------------------+</span>
<span class="p_add">+	 * | iret SS          } Copied from &quot;outermost&quot; frame        |</span>
<span class="p_add">+	 * | iret Return RSP  } on each loop iteration; overwritten  |</span>
<span class="p_add">+	 * | iret RFLAGS      } by a nested NMI to force another     |</span>
<span class="p_add">+	 * | iret CS          } iteration if needed.                 |</span>
<span class="p_add">+	 * | iret RIP         }                                      |</span>
<span class="p_add">+	 * +---------------------------------------------------------+</span>
<span class="p_add">+	 * | outermost SS          } initialized in first_nmi;       |</span>
<span class="p_add">+	 * | outermost Return RSP  } will not be changed before      |</span>
<span class="p_add">+	 * | outermost RFLAGS      } NMI processing is done.         |</span>
<span class="p_add">+	 * | outermost CS          } Copied to &quot;iret&quot; frame on each  |</span>
<span class="p_add">+	 * | outermost RIP         } iteration.                      |</span>
<span class="p_add">+	 * +---------------------------------------------------------+</span>
<span class="p_add">+	 * | pt_regs                                                 |</span>
<span class="p_add">+	 * +---------------------------------------------------------+</span>
<span class="p_add">+	 *</span>
<span class="p_add">+	 * The &quot;original&quot; frame is used by hardware.  Before re-enabling</span>
<span class="p_add">+	 * NMIs, we need to be done with it, and we need to leave enough</span>
<span class="p_add">+	 * space for the asm code here.</span>
<span class="p_add">+	 *</span>
<span class="p_add">+	 * We return by executing IRET while RSP points to the &quot;iret&quot; frame.</span>
<span class="p_add">+	 * That will either return for real or it will loop back into NMI</span>
<span class="p_add">+	 * processing.</span>
<span class="p_add">+	 *</span>
<span class="p_add">+	 * The &quot;outermost&quot; frame is copied to the &quot;iret&quot; frame on each</span>
<span class="p_add">+	 * iteration of the loop, so each iteration starts with the &quot;iret&quot;</span>
<span class="p_add">+	 * frame pointing to the final return target.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Determine whether we&#39;re a nested NMI.</span>
<span class="p_add">+	 *</span>
<span class="p_add">+	 * If we interrupted kernel code between repeat_nmi and</span>
<span class="p_add">+	 * end_repeat_nmi, then we are a nested NMI.  We must not</span>
<span class="p_add">+	 * modify the &quot;iret&quot; frame because it&#39;s being written by</span>
<span class="p_add">+	 * the outer NMI.  That&#39;s okay: the outer NMI handler is</span>
<span class="p_add">+	 * about to about to call do_nmi anyway, so we can just</span>
<span class="p_add">+	 * resume the outer NMI.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+</span>
<span class="p_add">+	movq	$repeat_nmi, %rdx</span>
<span class="p_add">+	cmpq	8(%rsp), %rdx</span>
<span class="p_add">+	ja	1f</span>
<span class="p_add">+	movq	$end_repeat_nmi, %rdx</span>
<span class="p_add">+	cmpq	8(%rsp), %rdx</span>
<span class="p_add">+	ja	nested_nmi_out</span>
<span class="p_add">+1:</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Now check &quot;NMI executing&quot;.  If it&#39;s set, then we&#39;re nested.</span>
<span class="p_add">+	 * This will not detect if we interrupted an outer NMI just</span>
<span class="p_add">+	 * before IRET.</span>
 	 */
 	cmpl $1, -8(%rsp)
 	je nested_nmi
 
 	/*
<span class="p_del">-	 * Now test if the previous stack was an NMI stack.</span>
<span class="p_del">-	 * We need the double check. We check the NMI stack to satisfy the</span>
<span class="p_del">-	 * race when the first NMI clears the variable before returning.</span>
<span class="p_del">-	 * We check the variable because the first NMI could be in a</span>
<span class="p_del">-	 * breakpoint routine using a breakpoint stack.</span>
<span class="p_add">+	 * Now test if the previous stack was an NMI stack.  This covers</span>
<span class="p_add">+	 * the case where we interrupt an outer NMI after it clears</span>
<span class="p_add">+	 * &quot;NMI executing&quot; but before IRET.  We need to be careful, though:</span>
<span class="p_add">+	 * there is one case in which RSP could point to the NMI stack</span>
<span class="p_add">+	 * despite there being no NMI active: naughty userspace controls</span>
<span class="p_add">+	 * RSP at the very beginning of the SYSCALL targets.  We can</span>
<span class="p_add">+	 * pull a fast one on naughty userspace, though: we program</span>
<span class="p_add">+	 * SYSCALL to mask DF, so userspace cannot cause DF to be set</span>
<span class="p_add">+	 * if it controls the kernel&#39;s RSP.  We set DF before we clear</span>
<span class="p_add">+	 * &quot;NMI executing&quot;.</span>
 	 */
<span class="p_del">-	lea 6*8(%rsp), %rdx</span>
<span class="p_del">-	test_in_nmi rdx, 4*8(%rsp), nested_nmi, first_nmi</span>
<span class="p_add">+	lea	6*8(%rsp), %rdx</span>
<span class="p_add">+	/* Compare the NMI stack (rdx) with the stack we came from (4*8(%rsp)) */</span>
<span class="p_add">+	cmpq	%rdx, 4*8(%rsp)</span>
<span class="p_add">+	/* If the stack pointer is above the NMI stack, this is a normal NMI */</span>
<span class="p_add">+	ja	first_nmi</span>
<span class="p_add">+	subq	$EXCEPTION_STKSZ, %rdx</span>
<span class="p_add">+	cmpq	%rdx, 4*8(%rsp)</span>
<span class="p_add">+	/* If it is below the NMI stack, it is a normal NMI */</span>
<span class="p_add">+	jb	first_nmi</span>
<span class="p_add">+</span>
<span class="p_add">+	/* Ah, it is within the NMI stack. */</span>
<span class="p_add">+</span>
<span class="p_add">+	testb	$(X86_EFLAGS_DF &gt;&gt; 8), (3*8 + 1)(%rsp)</span>
<span class="p_add">+	jz	first_nmi	/* RSP was user controlled. */</span>
<span class="p_add">+</span>
 	CFI_REMEMBER_STATE
 
<span class="p_add">+	/* This is a nested NMI. */</span>
<span class="p_add">+</span>
 nested_nmi:
 	/*
<span class="p_del">-	 * Do nothing if we interrupted the fixup in repeat_nmi.</span>
<span class="p_del">-	 * It&#39;s about to repeat the NMI handler, so we are fine</span>
<span class="p_del">-	 * with ignoring this one.</span>
<span class="p_add">+	 * Modify the &quot;iret&quot; frame to point to repeat_nmi, forcing another</span>
<span class="p_add">+	 * iteration of NMI handling.</span>
 	 */
<span class="p_del">-	movq $repeat_nmi, %rdx</span>
<span class="p_del">-	cmpq 8(%rsp), %rdx</span>
<span class="p_del">-	ja 1f</span>
<span class="p_del">-	movq $end_repeat_nmi, %rdx</span>
<span class="p_del">-	cmpq 8(%rsp), %rdx</span>
<span class="p_del">-	ja nested_nmi_out</span>
<span class="p_del">-</span>
<span class="p_del">-1:</span>
<span class="p_del">-	/* Set up the interrupted NMIs stack to jump to repeat_nmi */</span>
 	leaq -1*8(%rsp), %rdx
 	movq %rdx, %rsp
 	CFI_ADJUST_CFA_OFFSET 1*8
<span class="p_chunk">@@ -1816,60 +1947,23 @@</span> <span class="p_context"> nested_nmi_out:</span>
 	popq_cfi %rdx
 	CFI_RESTORE rdx
 
<span class="p_del">-	/* No need to check faults here */</span>
<span class="p_add">+	/* We are returning to kernel mode, so this cannot result in a fault. */</span>
 	INTERRUPT_RETURN
 
 	CFI_RESTORE_STATE
 first_nmi:
<span class="p_del">-	/*</span>
<span class="p_del">-	 * Because nested NMIs will use the pushed location that we</span>
<span class="p_del">-	 * stored in rdx, we must keep that space available.</span>
<span class="p_del">-	 * Here&#39;s what our stack frame will look like:</span>
<span class="p_del">-	 * +-------------------------+</span>
<span class="p_del">-	 * | original SS             |</span>
<span class="p_del">-	 * | original Return RSP     |</span>
<span class="p_del">-	 * | original RFLAGS         |</span>
<span class="p_del">-	 * | original CS             |</span>
<span class="p_del">-	 * | original RIP            |</span>
<span class="p_del">-	 * +-------------------------+</span>
<span class="p_del">-	 * | temp storage for rdx    |</span>
<span class="p_del">-	 * +-------------------------+</span>
<span class="p_del">-	 * | NMI executing variable  |</span>
<span class="p_del">-	 * +-------------------------+</span>
<span class="p_del">-	 * | copied SS               |</span>
<span class="p_del">-	 * | copied Return RSP       |</span>
<span class="p_del">-	 * | copied RFLAGS           |</span>
<span class="p_del">-	 * | copied CS               |</span>
<span class="p_del">-	 * | copied RIP              |</span>
<span class="p_del">-	 * +-------------------------+</span>
<span class="p_del">-	 * | Saved SS                |</span>
<span class="p_del">-	 * | Saved Return RSP        |</span>
<span class="p_del">-	 * | Saved RFLAGS            |</span>
<span class="p_del">-	 * | Saved CS                |</span>
<span class="p_del">-	 * | Saved RIP               |</span>
<span class="p_del">-	 * +-------------------------+</span>
<span class="p_del">-	 * | pt_regs                 |</span>
<span class="p_del">-	 * +-------------------------+</span>
<span class="p_del">-	 *</span>
<span class="p_del">-	 * The saved stack frame is used to fix up the copied stack frame</span>
<span class="p_del">-	 * that a nested NMI may change to make the interrupted NMI iret jump</span>
<span class="p_del">-	 * to the repeat_nmi. The original stack frame and the temp storage</span>
<span class="p_del">-	 * is also used by nested NMIs and can not be trusted on exit.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	/* Do not pop rdx, nested NMIs will corrupt that part of the stack */</span>
<span class="p_add">+	/* Restore rdx. */</span>
 	movq (%rsp), %rdx
 	CFI_RESTORE rdx
 
<span class="p_del">-	/* Set the NMI executing variable on the stack. */</span>
<span class="p_add">+	/* Set &quot;NMI executing&quot; on the stack. */</span>
 	pushq_cfi $1
 
<span class="p_del">-	/*</span>
<span class="p_del">-	 * Leave room for the &quot;copied&quot; frame</span>
<span class="p_del">-	 */</span>
<span class="p_add">+	/* Leave room for the &quot;iret&quot; frame */</span>
 	subq $(5*8), %rsp
 	CFI_ADJUST_CFA_OFFSET 5*8
 
<span class="p_del">-	/* Copy the stack frame to the Saved frame */</span>
<span class="p_add">+	/* Copy the &quot;original&quot; frame to the &quot;outermost&quot; frame */</span>
 	.rept 5
 	pushq_cfi 11*8(%rsp)
 	.endr
<span class="p_chunk">@@ -1877,6 +1971,7 @@</span> <span class="p_context"> first_nmi:</span>
 
 	/* Everything up to here is safe from nested NMIs */
 
<span class="p_add">+repeat_nmi:</span>
 	/*
 	 * If there was a nested NMI, the first NMI&#39;s iret will return
 	 * here. But NMIs are still enabled and we can take another
<span class="p_chunk">@@ -1885,16 +1980,21 @@</span> <span class="p_context"> first_nmi:</span>
 	 * it will just return, as we are about to repeat an NMI anyway.
 	 * This makes it safe to copy to the stack frame that a nested
 	 * NMI will update.
<span class="p_del">-	 */</span>
<span class="p_del">-repeat_nmi:</span>
<span class="p_del">-	/*</span>
<span class="p_del">-	 * Update the stack variable to say we are still in NMI (the update</span>
<span class="p_del">-	 * is benign for the non-repeat case, where 1 was pushed just above</span>
<span class="p_del">-	 * to this very stack slot).</span>
<span class="p_add">+	 *</span>
<span class="p_add">+	 * RSP is pointing to &quot;outermost RIP&quot;.  gsbase is unknown, but, if</span>
<span class="p_add">+	 * we&#39;re repeating an NMI, gsbase has the same value that it had on</span>
<span class="p_add">+	 * the first iteration.  paranoid_entry will load the kernel</span>
<span class="p_add">+	 * gsbase if needed before we call do_nmi.</span>
<span class="p_add">+	 *</span>
<span class="p_add">+	 * Set &quot;NMI executing&quot; in case we came back here via IRET.</span>
 	 */
 	movq $1, 10*8(%rsp)
 
<span class="p_del">-	/* Make another copy, this one may be modified by nested NMIs */</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Copy the &quot;outermost&quot; frame to the &quot;iret&quot; frame.  NMIs that nest</span>
<span class="p_add">+	 * here must not modify the &quot;iret&quot; frame while we&#39;re writing to</span>
<span class="p_add">+	 * it or it will end up containing garbage.</span>
<span class="p_add">+	 */</span>
 	addq $(10*8), %rsp
 	CFI_ADJUST_CFA_OFFSET -10*8
 	.rept 5
<span class="p_chunk">@@ -1905,9 +2005,9 @@</span> <span class="p_context"> repeat_nmi:</span>
 end_repeat_nmi:
 
 	/*
<span class="p_del">-	 * Everything below this point can be preempted by a nested</span>
<span class="p_del">-	 * NMI if the first NMI took an exception and reset our iret stack</span>
<span class="p_del">-	 * so that we repeat another NMI.</span>
<span class="p_add">+	 * Everything below this point can be preempted by a nested NMI.</span>
<span class="p_add">+	 * If this happens, then the inner NMI will change the &quot;iret&quot;</span>
<span class="p_add">+	 * frame to point back to repeat_nmi.</span>
 	 */
 	pushq_cfi $-1		/* ORIG_RAX: no syscall to restart */
 	subq $ORIG_RAX-R15, %rsp
<span class="p_chunk">@@ -1922,39 +2022,35 @@</span> <span class="p_context"> end_repeat_nmi:</span>
 	call save_paranoid
 	DEFAULT_FRAME 0
 
<span class="p_del">-	/*</span>
<span class="p_del">-	 * Save off the CR2 register. If we take a page fault in the NMI then</span>
<span class="p_del">-	 * it could corrupt the CR2 value. If the NMI preempts a page fault</span>
<span class="p_del">-	 * handler before it was able to read the CR2 register, and then the</span>
<span class="p_del">-	 * NMI itself takes a page fault, the page fault that was preempted</span>
<span class="p_del">-	 * will read the information from the NMI page fault and not the</span>
<span class="p_del">-	 * origin fault. Save it off and restore it if it changes.</span>
<span class="p_del">-	 * Use the r12 callee-saved register.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	movq %cr2, %r12</span>
<span class="p_del">-</span>
 	/* paranoidentry do_nmi, 0; without TRACE_IRQS_OFF */
 	movq %rsp,%rdi
 	movq $-1,%rsi
 	call do_nmi
 
<span class="p_del">-	/* Did the NMI take a page fault? Restore cr2 if it did */</span>
<span class="p_del">-	movq %cr2, %rcx</span>
<span class="p_del">-	cmpq %rcx, %r12</span>
<span class="p_del">-	je 1f</span>
<span class="p_del">-	movq %r12, %cr2</span>
<span class="p_del">-1:</span>
<span class="p_del">-	</span>
 	testl %ebx,%ebx				/* swapgs needed? */
 	jnz nmi_restore
 nmi_swapgs:
 	SWAPGS_UNSAFE_STACK
 nmi_restore:
<span class="p_del">-	/* Pop the extra iret frame at once */</span>
<span class="p_add">+</span>
 	RESTORE_ALL 6*8
 
<span class="p_del">-	/* Clear the NMI executing stack variable */</span>
<span class="p_del">-	movq $0, 5*8(%rsp)</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Clear &quot;NMI executing&quot;.  Set DF first so that we can easily</span>
<span class="p_add">+	 * distinguish the remaining code between here and IRET from</span>
<span class="p_add">+	 * the SYSCALL entry and exit paths.  On a native kernel, we</span>
<span class="p_add">+	 * could just inspect RIP, but, on paravirt kernels,</span>
<span class="p_add">+	 * INTERRUPT_RETURN can translate into a jump into a</span>
<span class="p_add">+	 * hypercall page.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	std</span>
<span class="p_add">+	movq	$0, 5*8(%rsp)		/* clear &quot;NMI executing&quot; */</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * INTERRUPT_RETURN reads the &quot;iret&quot; frame and exits the NMI</span>
<span class="p_add">+	 * stack in a single instruction.  We are returning to kernel</span>
<span class="p_add">+	 * mode, so this cannot result in a fault.</span>
<span class="p_add">+	 */</span>
 	jmp irq_return
 	CFI_ENDPROC
 END(nmi)
<span class="p_header">diff --git a/arch/x86/kernel/nmi.c b/arch/x86/kernel/nmi.c</span>
<span class="p_header">index 6fcb49c..85ede73 100644</span>
<span class="p_header">--- a/arch/x86/kernel/nmi.c</span>
<span class="p_header">+++ b/arch/x86/kernel/nmi.c</span>
<span class="p_chunk">@@ -392,15 +392,15 @@</span> <span class="p_context"> static __kprobes void default_do_nmi(struct pt_regs *regs)</span>
 }
 
 /*
<span class="p_del">- * NMIs can hit breakpoints which will cause it to lose its</span>
<span class="p_del">- * NMI context with the CPU when the breakpoint does an iret.</span>
<span class="p_del">- */</span>
<span class="p_del">-#ifdef CONFIG_X86_32</span>
<span class="p_del">-/*</span>
<span class="p_del">- * For i386, NMIs use the same stack as the kernel, and we can</span>
<span class="p_del">- * add a workaround to the iret problem in C (preventing nested</span>
<span class="p_del">- * NMIs if an NMI takes a trap). Simply have 3 states the NMI</span>
<span class="p_del">- * can be in:</span>
<span class="p_add">+ * NMIs can page fault or hit breakpoints which will cause it to lose</span>
<span class="p_add">+ * its NMI context with the CPU when the breakpoint or page fault does an IRET.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * As a result, NMIs can nest if NMIs get unmasked due an IRET during</span>
<span class="p_add">+ * NMI processing.  On x86_64, the asm glue protects us from nested NMIs</span>
<span class="p_add">+ * if the outer NMI came from kernel mode, but we can still nest if the</span>
<span class="p_add">+ * outer NMI came from user mode.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * To handle these nested NMIs, we have three states:</span>
  *
  *  1) not running
  *  2) executing
<span class="p_chunk">@@ -414,15 +414,14 @@</span> <span class="p_context"> static __kprobes void default_do_nmi(struct pt_regs *regs)</span>
  * (Note, the latch is binary, thus multiple NMIs triggering,
  *  when one is running, are ignored. Only one NMI is restarted.)
  *
<span class="p_del">- * If an NMI hits a breakpoint that executes an iret, another</span>
<span class="p_del">- * NMI can preempt it. We do not want to allow this new NMI</span>
<span class="p_del">- * to run, but we want to execute it when the first one finishes.</span>
<span class="p_del">- * We set the state to &quot;latched&quot;, and the exit of the first NMI will</span>
<span class="p_del">- * perform a dec_return, if the result is zero (NOT_RUNNING), then</span>
<span class="p_del">- * it will simply exit the NMI handler. If not, the dec_return</span>
<span class="p_del">- * would have set the state to NMI_EXECUTING (what we want it to</span>
<span class="p_del">- * be when we are running). In this case, we simply jump back</span>
<span class="p_del">- * to rerun the NMI handler again, and restart the &#39;latched&#39; NMI.</span>
<span class="p_add">+ * If an NMI executes an iret, another NMI can preempt it. We do not</span>
<span class="p_add">+ * want to allow this new NMI to run, but we want to execute it when the</span>
<span class="p_add">+ * first one finishes.  We set the state to &quot;latched&quot;, and the exit of</span>
<span class="p_add">+ * the first NMI will perform a dec_return, if the result is zero</span>
<span class="p_add">+ * (NOT_RUNNING), then it will simply exit the NMI handler. If not, the</span>
<span class="p_add">+ * dec_return would have set the state to NMI_EXECUTING (what we want it</span>
<span class="p_add">+ * to be when we are running). In this case, we simply jump back to</span>
<span class="p_add">+ * rerun the NMI handler again, and restart the &#39;latched&#39; NMI.</span>
  *
  * No trap (breakpoint or page fault) should be hit before nmi_restart,
  * thus there is no race between the first check of state for NOT_RUNNING
<span class="p_chunk">@@ -445,49 +444,36 @@</span> <span class="p_context"> enum nmi_states {</span>
 static DEFINE_PER_CPU(enum nmi_states, nmi_state);
 static DEFINE_PER_CPU(unsigned long, nmi_cr2);
 
<span class="p_del">-#define nmi_nesting_preprocess(regs)					\</span>
<span class="p_del">-	do {								\</span>
<span class="p_del">-		if (this_cpu_read(nmi_state) != NMI_NOT_RUNNING) {	\</span>
<span class="p_del">-			this_cpu_write(nmi_state, NMI_LATCHED);		\</span>
<span class="p_del">-			return;						\</span>
<span class="p_del">-		}							\</span>
<span class="p_del">-		this_cpu_write(nmi_state, NMI_EXECUTING);		\</span>
<span class="p_del">-		this_cpu_write(nmi_cr2, read_cr2());			\</span>
<span class="p_del">-	} while (0);							\</span>
<span class="p_del">-	nmi_restart:</span>
<span class="p_del">-</span>
<span class="p_del">-#define nmi_nesting_postprocess()					\</span>
<span class="p_del">-	do {								\</span>
<span class="p_del">-		if (unlikely(this_cpu_read(nmi_cr2) != read_cr2()))	\</span>
<span class="p_del">-			write_cr2(this_cpu_read(nmi_cr2));		\</span>
<span class="p_del">-		if (this_cpu_dec_return(nmi_state))			\</span>
<span class="p_del">-			goto nmi_restart;				\</span>
<span class="p_del">-	} while (0)</span>
<span class="p_del">-#else /* x86_64 */</span>
<span class="p_add">+#ifdef CONFIG_X86_64</span>
 /*
<span class="p_del">- * In x86_64 things are a bit more difficult. This has the same problem</span>
<span class="p_del">- * where an NMI hitting a breakpoint that calls iret will remove the</span>
<span class="p_del">- * NMI context, allowing a nested NMI to enter. What makes this more</span>
<span class="p_del">- * difficult is that both NMIs and breakpoints have their own stack.</span>
<span class="p_del">- * When a new NMI or breakpoint is executed, the stack is set to a fixed</span>
<span class="p_del">- * point. If an NMI is nested, it will have its stack set at that same</span>
<span class="p_del">- * fixed address that the first NMI had, and will start corrupting the</span>
<span class="p_del">- * stack. This is handled in entry_64.S, but the same problem exists with</span>
<span class="p_del">- * the breakpoint stack.</span>
<span class="p_add">+ * In x86_64, we need to handle breakpoint -&gt; NMI -&gt; breakpoint.  Without</span>
<span class="p_add">+ * some care, the inner breakpoint will clobber the outer breakpoint&#39;s</span>
<span class="p_add">+ * stack.</span>
  *
<span class="p_del">- * If a breakpoint is being processed, and the debug stack is being used,</span>
<span class="p_del">- * if an NMI comes in and also hits a breakpoint, the stack pointer</span>
<span class="p_del">- * will be set to the same fixed address as the breakpoint that was</span>
<span class="p_del">- * interrupted, causing that stack to be corrupted. To handle this case,</span>
<span class="p_del">- * check if the stack that was interrupted is the debug stack, and if</span>
<span class="p_del">- * so, change the IDT so that new breakpoints will use the current stack</span>
<span class="p_del">- * and not switch to the fixed address. On return of the NMI, switch back</span>
<span class="p_del">- * to the original IDT.</span>
<span class="p_add">+ * If a breakpoint is being processed, and the debug stack is being</span>
<span class="p_add">+ * used, if an NMI comes in and also hits a breakpoint, the stack</span>
<span class="p_add">+ * pointer will be set to the same fixed address as the breakpoint that</span>
<span class="p_add">+ * was interrupted, causing that stack to be corrupted. To handle this</span>
<span class="p_add">+ * case, check if the stack that was interrupted is the debug stack, and</span>
<span class="p_add">+ * if so, change the IDT so that new breakpoints will use the current</span>
<span class="p_add">+ * stack and not switch to the fixed address. On return of the NMI,</span>
<span class="p_add">+ * switch back to the original IDT.</span>
  */
 static DEFINE_PER_CPU(int, update_debug_stack);
<span class="p_add">+#endif</span>
 
<span class="p_del">-static inline void nmi_nesting_preprocess(struct pt_regs *regs)</span>
<span class="p_add">+dotraplinkage notrace __kprobes void</span>
<span class="p_add">+do_nmi(struct pt_regs *regs, long error_code)</span>
 {
<span class="p_add">+	if (this_cpu_read(nmi_state) != NMI_NOT_RUNNING) {</span>
<span class="p_add">+		this_cpu_write(nmi_state, NMI_LATCHED);</span>
<span class="p_add">+		return;</span>
<span class="p_add">+	}</span>
<span class="p_add">+	this_cpu_write(nmi_state, NMI_EXECUTING);</span>
<span class="p_add">+	this_cpu_write(nmi_cr2, read_cr2());</span>
<span class="p_add">+nmi_restart:</span>
<span class="p_add">+</span>
<span class="p_add">+#ifdef CONFIG_X86_64</span>
 	/*
 	 * If we interrupted a breakpoint, it is possible that
 	 * the nmi handler will have breakpoints too. We need to
<span class="p_chunk">@@ -498,22 +484,8 @@</span> <span class="p_context"> static inline void nmi_nesting_preprocess(struct pt_regs *regs)</span>
 		debug_stack_set_zero();
 		this_cpu_write(update_debug_stack, 1);
 	}
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static inline void nmi_nesting_postprocess(void)</span>
<span class="p_del">-{</span>
<span class="p_del">-	if (unlikely(this_cpu_read(update_debug_stack))) {</span>
<span class="p_del">-		debug_stack_reset();</span>
<span class="p_del">-		this_cpu_write(update_debug_stack, 0);</span>
<span class="p_del">-	}</span>
<span class="p_del">-}</span>
 #endif
 
<span class="p_del">-dotraplinkage notrace __kprobes void</span>
<span class="p_del">-do_nmi(struct pt_regs *regs, long error_code)</span>
<span class="p_del">-{</span>
<span class="p_del">-	nmi_nesting_preprocess(regs);</span>
<span class="p_del">-</span>
 	nmi_enter();
 
 	inc_irq_stat(__nmi_count);
<span class="p_chunk">@@ -523,8 +495,17 @@</span> <span class="p_context"> do_nmi(struct pt_regs *regs, long error_code)</span>
 
 	nmi_exit();
 
<span class="p_del">-	/* On i386, may loop back to preprocess */</span>
<span class="p_del">-	nmi_nesting_postprocess();</span>
<span class="p_add">+#ifdef CONFIG_X86_64</span>
<span class="p_add">+	if (unlikely(this_cpu_read(update_debug_stack))) {</span>
<span class="p_add">+		debug_stack_reset();</span>
<span class="p_add">+		this_cpu_write(update_debug_stack, 0);</span>
<span class="p_add">+	}</span>
<span class="p_add">+#endif</span>
<span class="p_add">+</span>
<span class="p_add">+	if (unlikely(this_cpu_read(nmi_cr2) != read_cr2()))</span>
<span class="p_add">+		write_cr2(this_cpu_read(nmi_cr2));</span>
<span class="p_add">+	if (this_cpu_dec_return(nmi_state))</span>
<span class="p_add">+		goto nmi_restart;</span>
 }
 
 void stop_nmi(void)
<span class="p_header">diff --git a/drivers/acpi/osl.c b/drivers/acpi/osl.c</span>
<span class="p_header">index 65d93f4..bd2e23e 100644</span>
<span class="p_header">--- a/drivers/acpi/osl.c</span>
<span class="p_header">+++ b/drivers/acpi/osl.c</span>
<span class="p_chunk">@@ -169,10 +169,14 @@</span> <span class="p_context"> static void __init acpi_request_region (struct acpi_generic_address *gas,</span>
 	if (!addr || !length)
 		return;
 
<span class="p_del">-	acpi_reserve_region(addr, length, gas-&gt;space_id, 0, desc);</span>
<span class="p_add">+	/* Resources are never freed */</span>
<span class="p_add">+	if (gas-&gt;space_id == ACPI_ADR_SPACE_SYSTEM_IO)</span>
<span class="p_add">+		request_region(addr, length, desc);</span>
<span class="p_add">+	else if (gas-&gt;space_id == ACPI_ADR_SPACE_SYSTEM_MEMORY)</span>
<span class="p_add">+		request_mem_region(addr, length, desc);</span>
 }
 
<span class="p_del">-static void __init acpi_reserve_resources(void)</span>
<span class="p_add">+static int __init acpi_reserve_resources(void)</span>
 {
 	acpi_request_region(&amp;acpi_gbl_FADT.xpm1a_event_block, acpi_gbl_FADT.pm1_event_length,
 		&quot;ACPI PM1a_EVT_BLK&quot;);
<span class="p_chunk">@@ -201,7 +205,10 @@</span> <span class="p_context"> static void __init acpi_reserve_resources(void)</span>
 	if (!(acpi_gbl_FADT.gpe1_block_length &amp; 0x1))
 		acpi_request_region(&amp;acpi_gbl_FADT.xgpe1_block,
 			       acpi_gbl_FADT.gpe1_block_length, &quot;ACPI GPE1_BLK&quot;);
<span class="p_add">+</span>
<span class="p_add">+	return 0;</span>
 }
<span class="p_add">+fs_initcall_sync(acpi_reserve_resources);</span>
 
 void acpi_os_printf(const char *fmt, ...)
 {
<span class="p_chunk">@@ -1785,7 +1792,6 @@</span> <span class="p_context"> acpi_status __init acpi_os_initialize(void)</span>
 
 acpi_status __init acpi_os_initialize1(void)
 {
<span class="p_del">-	acpi_reserve_resources();</span>
 	kacpid_wq = alloc_workqueue(&quot;kacpid&quot;, 0, 1);
 	kacpi_notify_wq = alloc_workqueue(&quot;kacpi_notify&quot;, 0, 1);
 	kacpi_hotplug_wq = alloc_workqueue(&quot;kacpi_hotplug&quot;, 0, 1);
<span class="p_header">diff --git a/drivers/acpi/resource.c b/drivers/acpi/resource.c</span>
<span class="p_header">index 9e1ea53..0bdacc5 100644</span>
<span class="p_header">--- a/drivers/acpi/resource.c</span>
<span class="p_header">+++ b/drivers/acpi/resource.c</span>
<span class="p_chunk">@@ -26,7 +26,6 @@</span> <span class="p_context"></span>
 #include &lt;linux/device.h&gt;
 #include &lt;linux/export.h&gt;
 #include &lt;linux/ioport.h&gt;
<span class="p_del">-#include &lt;linux/list.h&gt;</span>
 #include &lt;linux/slab.h&gt;
 
 #ifdef CONFIG_X86
<span class="p_chunk">@@ -539,164 +538,3 @@</span> <span class="p_context"> int acpi_dev_get_resources(struct acpi_device *adev, struct list_head *list,</span>
 	return c.count;
 }
 EXPORT_SYMBOL_GPL(acpi_dev_get_resources);
<span class="p_del">-</span>
<span class="p_del">-struct reserved_region {</span>
<span class="p_del">-	struct list_head node;</span>
<span class="p_del">-	u64 start;</span>
<span class="p_del">-	u64 end;</span>
<span class="p_del">-};</span>
<span class="p_del">-</span>
<span class="p_del">-static LIST_HEAD(reserved_io_regions);</span>
<span class="p_del">-static LIST_HEAD(reserved_mem_regions);</span>
<span class="p_del">-</span>
<span class="p_del">-static int request_range(u64 start, u64 end, u8 space_id, unsigned long flags,</span>
<span class="p_del">-			 char *desc)</span>
<span class="p_del">-{</span>
<span class="p_del">-	unsigned int length = end - start + 1;</span>
<span class="p_del">-	struct resource *res;</span>
<span class="p_del">-</span>
<span class="p_del">-	res = space_id == ACPI_ADR_SPACE_SYSTEM_IO ?</span>
<span class="p_del">-		request_region(start, length, desc) :</span>
<span class="p_del">-		request_mem_region(start, length, desc);</span>
<span class="p_del">-	if (!res)</span>
<span class="p_del">-		return -EIO;</span>
<span class="p_del">-</span>
<span class="p_del">-	res-&gt;flags &amp;= ~flags;</span>
<span class="p_del">-	return 0;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static int add_region_before(u64 start, u64 end, u8 space_id,</span>
<span class="p_del">-			     unsigned long flags, char *desc,</span>
<span class="p_del">-			     struct list_head *head)</span>
<span class="p_del">-{</span>
<span class="p_del">-	struct reserved_region *reg;</span>
<span class="p_del">-	int error;</span>
<span class="p_del">-</span>
<span class="p_del">-	reg = kmalloc(sizeof(*reg), GFP_KERNEL);</span>
<span class="p_del">-	if (!reg)</span>
<span class="p_del">-		return -ENOMEM;</span>
<span class="p_del">-</span>
<span class="p_del">-	error = request_range(start, end, space_id, flags, desc);</span>
<span class="p_del">-	if (error) {</span>
<span class="p_del">-		kfree(reg);</span>
<span class="p_del">-		return error;</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">-	reg-&gt;start = start;</span>
<span class="p_del">-	reg-&gt;end = end;</span>
<span class="p_del">-	list_add_tail(&amp;reg-&gt;node, head);</span>
<span class="p_del">-	return 0;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-/**</span>
<span class="p_del">- * acpi_reserve_region - Reserve an I/O or memory region as a system resource.</span>
<span class="p_del">- * @start: Starting address of the region.</span>
<span class="p_del">- * @length: Length of the region.</span>
<span class="p_del">- * @space_id: Identifier of address space to reserve the region from.</span>
<span class="p_del">- * @flags: Resource flags to clear for the region after requesting it.</span>
<span class="p_del">- * @desc: Region description (for messages).</span>
<span class="p_del">- *</span>
<span class="p_del">- * Reserve an I/O or memory region as a system resource to prevent others from</span>
<span class="p_del">- * using it.  If the new region overlaps with one of the regions (in the given</span>
<span class="p_del">- * address space) already reserved by this routine, only the non-overlapping</span>
<span class="p_del">- * parts of it will be reserved.</span>
<span class="p_del">- *</span>
<span class="p_del">- * Returned is either 0 (success) or a negative error code indicating a resource</span>
<span class="p_del">- * reservation problem.  It is the code of the first encountered error, but the</span>
<span class="p_del">- * routine doesn&#39;t abort until it has attempted to request all of the parts of</span>
<span class="p_del">- * the new region that don&#39;t overlap with other regions reserved previously.</span>
<span class="p_del">- *</span>
<span class="p_del">- * The resources requested by this routine are never released.</span>
<span class="p_del">- */</span>
<span class="p_del">-int acpi_reserve_region(u64 start, unsigned int length, u8 space_id,</span>
<span class="p_del">-			unsigned long flags, char *desc)</span>
<span class="p_del">-{</span>
<span class="p_del">-	struct list_head *regions;</span>
<span class="p_del">-	struct reserved_region *reg;</span>
<span class="p_del">-	u64 end = start + length - 1;</span>
<span class="p_del">-	int ret = 0, error = 0;</span>
<span class="p_del">-</span>
<span class="p_del">-	if (space_id == ACPI_ADR_SPACE_SYSTEM_IO)</span>
<span class="p_del">-		regions = &amp;reserved_io_regions;</span>
<span class="p_del">-	else if (space_id == ACPI_ADR_SPACE_SYSTEM_MEMORY)</span>
<span class="p_del">-		regions = &amp;reserved_mem_regions;</span>
<span class="p_del">-	else</span>
<span class="p_del">-		return -EINVAL;</span>
<span class="p_del">-</span>
<span class="p_del">-	if (list_empty(regions))</span>
<span class="p_del">-		return add_region_before(start, end, space_id, flags, desc, regions);</span>
<span class="p_del">-</span>
<span class="p_del">-	list_for_each_entry(reg, regions, node)</span>
<span class="p_del">-		if (reg-&gt;start == end + 1) {</span>
<span class="p_del">-			/* The new region can be prepended to this one. */</span>
<span class="p_del">-			ret = request_range(start, end, space_id, flags, desc);</span>
<span class="p_del">-			if (!ret)</span>
<span class="p_del">-				reg-&gt;start = start;</span>
<span class="p_del">-</span>
<span class="p_del">-			return ret;</span>
<span class="p_del">-		} else if (reg-&gt;start &gt; end) {</span>
<span class="p_del">-			/* No overlap.  Add the new region here and get out. */</span>
<span class="p_del">-			return add_region_before(start, end, space_id, flags,</span>
<span class="p_del">-						 desc, &amp;reg-&gt;node);</span>
<span class="p_del">-		} else if (reg-&gt;end == start - 1) {</span>
<span class="p_del">-			goto combine;</span>
<span class="p_del">-		} else if (reg-&gt;end &gt;= start) {</span>
<span class="p_del">-			goto overlap;</span>
<span class="p_del">-		}</span>
<span class="p_del">-</span>
<span class="p_del">-	/* The new region goes after the last existing one. */</span>
<span class="p_del">-	return add_region_before(start, end, space_id, flags, desc, regions);</span>
<span class="p_del">-</span>
<span class="p_del">- overlap:</span>
<span class="p_del">-	/*</span>
<span class="p_del">-	 * The new region overlaps an existing one.</span>
<span class="p_del">-	 *</span>
<span class="p_del">-	 * The head part of the new region immediately preceding the existing</span>
<span class="p_del">-	 * overlapping one can be combined with it right away.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	if (reg-&gt;start &gt; start) {</span>
<span class="p_del">-		error = request_range(start, reg-&gt;start - 1, space_id, flags, desc);</span>
<span class="p_del">-		if (error)</span>
<span class="p_del">-			ret = error;</span>
<span class="p_del">-		else</span>
<span class="p_del">-			reg-&gt;start = start;</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">- combine:</span>
<span class="p_del">-	/*</span>
<span class="p_del">-	 * The new region is adjacent to an existing one.  If it extends beyond</span>
<span class="p_del">-	 * that region all the way to the next one, it is possible to combine</span>
<span class="p_del">-	 * all three of them.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	while (reg-&gt;end &lt; end) {</span>
<span class="p_del">-		struct reserved_region *next = NULL;</span>
<span class="p_del">-		u64 a = reg-&gt;end + 1, b = end;</span>
<span class="p_del">-</span>
<span class="p_del">-		if (!list_is_last(&amp;reg-&gt;node, regions)) {</span>
<span class="p_del">-			next = list_next_entry(reg, node);</span>
<span class="p_del">-			if (next-&gt;start &lt;= end)</span>
<span class="p_del">-				b = next-&gt;start - 1;</span>
<span class="p_del">-		}</span>
<span class="p_del">-		error = request_range(a, b, space_id, flags, desc);</span>
<span class="p_del">-		if (!error) {</span>
<span class="p_del">-			if (next &amp;&amp; next-&gt;start == b + 1) {</span>
<span class="p_del">-				reg-&gt;end = next-&gt;end;</span>
<span class="p_del">-				list_del(&amp;next-&gt;node);</span>
<span class="p_del">-				kfree(next);</span>
<span class="p_del">-			} else {</span>
<span class="p_del">-				reg-&gt;end = end;</span>
<span class="p_del">-				break;</span>
<span class="p_del">-			}</span>
<span class="p_del">-		} else if (next) {</span>
<span class="p_del">-			if (!ret)</span>
<span class="p_del">-				ret = error;</span>
<span class="p_del">-</span>
<span class="p_del">-			reg = next;</span>
<span class="p_del">-		} else {</span>
<span class="p_del">-			break;</span>
<span class="p_del">-		}</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">-	return ret ? ret : error;</span>
<span class="p_del">-}</span>
<span class="p_del">-EXPORT_SYMBOL_GPL(acpi_reserve_region);</span>
<span class="p_header">diff --git a/drivers/gpu/drm/drm_crtc.c b/drivers/gpu/drm/drm_crtc.c</span>
<span class="p_header">index d6cf77c..944ff1e 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/drm_crtc.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/drm_crtc.c</span>
<span class="p_chunk">@@ -2132,8 +2132,11 @@</span> <span class="p_context"> int drm_mode_setcrtc(struct drm_device *dev, void *data,</span>
 	if (!drm_core_check_feature(dev, DRIVER_MODESET))
 		return -EINVAL;
 
<span class="p_del">-	/* For some reason crtc x/y offsets are signed internally. */</span>
<span class="p_del">-	if (crtc_req-&gt;x &gt; INT_MAX || crtc_req-&gt;y &gt; INT_MAX)</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Universal plane src offsets are only 16.16, prevent havoc for</span>
<span class="p_add">+	 * drivers using universal plane code internally.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	if (crtc_req-&gt;x &amp; 0xffff0000 || crtc_req-&gt;y &amp; 0xffff0000)</span>
 		return -ERANGE;
 
 	drm_modeset_lock_all(dev);
<span class="p_header">diff --git a/drivers/gpu/drm/radeon/radeon_gart.c b/drivers/gpu/drm/radeon/radeon_gart.c</span>
<span class="p_header">index 96e4400..275c829 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/radeon/radeon_gart.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/radeon/radeon_gart.c</span>
<span class="p_chunk">@@ -251,8 +251,10 @@</span> <span class="p_context"> void radeon_gart_unbind(struct radeon_device *rdev, unsigned offset,</span>
 			}
 		}
 	}
<span class="p_del">-	mb();</span>
<span class="p_del">-	radeon_gart_tlb_flush(rdev);</span>
<span class="p_add">+	if (rdev-&gt;gart.ptr) {</span>
<span class="p_add">+		mb();</span>
<span class="p_add">+		radeon_gart_tlb_flush(rdev);</span>
<span class="p_add">+	}</span>
 }
 
 /**
<span class="p_chunk">@@ -294,8 +296,10 @@</span> <span class="p_context"> int radeon_gart_bind(struct radeon_device *rdev, unsigned offset,</span>
 			}
 		}
 	}
<span class="p_del">-	mb();</span>
<span class="p_del">-	radeon_gart_tlb_flush(rdev);</span>
<span class="p_add">+	if (rdev-&gt;gart.ptr) {</span>
<span class="p_add">+		mb();</span>
<span class="p_add">+		radeon_gart_tlb_flush(rdev);</span>
<span class="p_add">+	}</span>
 	return 0;
 }
 
<span class="p_header">diff --git a/drivers/gpu/drm/radeon/si_dpm.c b/drivers/gpu/drm/radeon/si_dpm.c</span>
<span class="p_header">index 188f292..e6e22d5 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/radeon/si_dpm.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/radeon/si_dpm.c</span>
<span class="p_chunk">@@ -2915,6 +2915,7 @@</span> <span class="p_context"> static struct si_dpm_quirk si_dpm_quirk_list[] = {</span>
 	/* PITCAIRN - https://bugs.freedesktop.org/show_bug.cgi?id=76490 */
 	{ PCI_VENDOR_ID_ATI, 0x6810, 0x1462, 0x3036, 0, 120000 },
 	{ PCI_VENDOR_ID_ATI, 0x6811, 0x174b, 0xe271, 0, 120000 },
<span class="p_add">+	{ PCI_VENDOR_ID_ATI, 0x6810, 0x174b, 0xe271, 85000, 90000 },</span>
 	{ 0, 0, 0, 0 },
 };
 
<span class="p_header">diff --git a/drivers/iio/adc/at91_adc.c b/drivers/iio/adc/at91_adc.c</span>
<span class="p_header">index c42bace..ef63347 100644</span>
<span class="p_header">--- a/drivers/iio/adc/at91_adc.c</span>
<span class="p_header">+++ b/drivers/iio/adc/at91_adc.c</span>
<span class="p_chunk">@@ -58,7 +58,7 @@</span> <span class="p_context"> struct at91_adc_caps {</span>
 	u8	ts_pen_detect_sensitivity;
 
 	/* startup time calculate function */
<span class="p_del">-	u32 (*calc_startup_ticks)(u8 startup_time, u32 adc_clk_khz);</span>
<span class="p_add">+	u32 (*calc_startup_ticks)(u32 startup_time, u32 adc_clk_khz);</span>
 
 	u8	num_channels;
 	struct at91_adc_reg_desc registers;
<span class="p_chunk">@@ -83,7 +83,7 @@</span> <span class="p_context"> struct at91_adc_state {</span>
 	u8			num_channels;
 	void __iomem		*reg_base;
 	struct at91_adc_reg_desc *registers;
<span class="p_del">-	u8			startup_time;</span>
<span class="p_add">+	u32			startup_time;</span>
 	u8			sample_hold_time;
 	bool			sleep_mode;
 	struct iio_trigger	**trig;
<span class="p_chunk">@@ -591,7 +591,7 @@</span> <span class="p_context"> ret:</span>
 	return ret;
 }
 
<span class="p_del">-static u32 calc_startup_ticks_9260(u8 startup_time, u32 adc_clk_khz)</span>
<span class="p_add">+static u32 calc_startup_ticks_9260(u32 startup_time, u32 adc_clk_khz)</span>
 {
 	/*
 	 * Number of ticks needed to cover the startup time of the ADC
<span class="p_chunk">@@ -602,7 +602,7 @@</span> <span class="p_context"> static u32 calc_startup_ticks_9260(u8 startup_time, u32 adc_clk_khz)</span>
 	return round_up((startup_time * adc_clk_khz / 1000) - 1, 8) / 8;
 }
 
<span class="p_del">-static u32 calc_startup_ticks_9x5(u8 startup_time, u32 adc_clk_khz)</span>
<span class="p_add">+static u32 calc_startup_ticks_9x5(u32 startup_time, u32 adc_clk_khz)</span>
 {
 	/*
 	 * For sama5d3x and at91sam9x5, the formula changes to:
<span class="p_header">diff --git a/drivers/iio/dac/ad5624r_spi.c b/drivers/iio/dac/ad5624r_spi.c</span>
<span class="p_header">index 774dd96..45483ac 100644</span>
<span class="p_header">--- a/drivers/iio/dac/ad5624r_spi.c</span>
<span class="p_header">+++ b/drivers/iio/dac/ad5624r_spi.c</span>
<span class="p_chunk">@@ -22,7 +22,7 @@</span> <span class="p_context"></span>
 #include &quot;ad5624r.h&quot;
 
 static int ad5624r_spi_write(struct spi_device *spi,
<span class="p_del">-			     u8 cmd, u8 addr, u16 val, u8 len)</span>
<span class="p_add">+			     u8 cmd, u8 addr, u16 val, u8 shift)</span>
 {
 	u32 data;
 	u8 msg[3];
<span class="p_chunk">@@ -35,7 +35,7 @@</span> <span class="p_context"> static int ad5624r_spi_write(struct spi_device *spi,</span>
 	 * 14-, 12-bit input code followed by 0, 2, or 4 don&#39;t care bits,
 	 * for the AD5664R, AD5644R, and AD5624R, respectively.
 	 */
<span class="p_del">-	data = (0 &lt;&lt; 22) | (cmd &lt;&lt; 19) | (addr &lt;&lt; 16) | (val &lt;&lt; (16 - len));</span>
<span class="p_add">+	data = (0 &lt;&lt; 22) | (cmd &lt;&lt; 19) | (addr &lt;&lt; 16) | (val &lt;&lt; shift);</span>
 	msg[0] = data &gt;&gt; 16;
 	msg[1] = data &gt;&gt; 8;
 	msg[2] = data;
<span class="p_header">diff --git a/drivers/iio/imu/inv_mpu6050/inv_mpu_core.c b/drivers/iio/imu/inv_mpu6050/inv_mpu_core.c</span>
<span class="p_header">index 27a9176..12217fa 100644</span>
<span class="p_header">--- a/drivers/iio/imu/inv_mpu6050/inv_mpu_core.c</span>
<span class="p_header">+++ b/drivers/iio/imu/inv_mpu6050/inv_mpu_core.c</span>
<span class="p_chunk">@@ -322,6 +322,24 @@</span> <span class="p_context"> error_read_raw:</span>
 	}
 }
 
<span class="p_add">+static int inv_write_raw_get_fmt(struct iio_dev *indio_dev,</span>
<span class="p_add">+				 struct iio_chan_spec const *chan, long mask)</span>
<span class="p_add">+{</span>
<span class="p_add">+	switch (mask) {</span>
<span class="p_add">+	case IIO_CHAN_INFO_SCALE:</span>
<span class="p_add">+		switch (chan-&gt;type) {</span>
<span class="p_add">+		case IIO_ANGL_VEL:</span>
<span class="p_add">+			return IIO_VAL_INT_PLUS_NANO;</span>
<span class="p_add">+		default:</span>
<span class="p_add">+			return IIO_VAL_INT_PLUS_MICRO;</span>
<span class="p_add">+		}</span>
<span class="p_add">+	default:</span>
<span class="p_add">+		return IIO_VAL_INT_PLUS_MICRO;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	return -EINVAL;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static int inv_mpu6050_write_fsr(struct inv_mpu6050_state *st, int fsr)
 {
 	int result;
<span class="p_chunk">@@ -604,6 +622,7 @@</span> <span class="p_context"> static const struct iio_info mpu_info = {</span>
 	.driver_module = THIS_MODULE,
 	.read_raw = &amp;inv_mpu6050_read_raw,
 	.write_raw = &amp;inv_mpu6050_write_raw,
<span class="p_add">+	.write_raw_get_fmt = &amp;inv_write_raw_get_fmt,</span>
 	.attrs = &amp;inv_attribute_group,
 	.validate_trigger = inv_mpu6050_validate_trigger,
 };
<span class="p_header">diff --git a/drivers/iio/temperature/tmp006.c b/drivers/iio/temperature/tmp006.c</span>
<span class="p_header">index 84a0789..7a80509 100644</span>
<span class="p_header">--- a/drivers/iio/temperature/tmp006.c</span>
<span class="p_header">+++ b/drivers/iio/temperature/tmp006.c</span>
<span class="p_chunk">@@ -132,6 +132,9 @@</span> <span class="p_context"> static int tmp006_write_raw(struct iio_dev *indio_dev,</span>
 	struct tmp006_data *data = iio_priv(indio_dev);
 	int i;
 
<span class="p_add">+	if (mask != IIO_CHAN_INFO_SAMP_FREQ)</span>
<span class="p_add">+		return -EINVAL;</span>
<span class="p_add">+</span>
 	for (i = 0; i &lt; ARRAY_SIZE(tmp006_freqs); i++)
 		if ((val == tmp006_freqs[i][0]) &amp;&amp;
 		    (val2 == tmp006_freqs[i][1])) {
<span class="p_header">diff --git a/drivers/md/persistent-data/dm-btree-remove.c b/drivers/md/persistent-data/dm-btree-remove.c</span>
<span class="p_header">index b88757c..a03178e 100644</span>
<span class="p_header">--- a/drivers/md/persistent-data/dm-btree-remove.c</span>
<span class="p_header">+++ b/drivers/md/persistent-data/dm-btree-remove.c</span>
<span class="p_chunk">@@ -309,8 +309,8 @@</span> <span class="p_context"> static void redistribute3(struct dm_btree_info *info, struct btree_node *parent,</span>
 
 		if (s &lt; 0 &amp;&amp; nr_center &lt; -s) {
 			/* not enough in central node */
<span class="p_del">-			shift(left, center, nr_center);</span>
<span class="p_del">-			s = nr_center - target;</span>
<span class="p_add">+			shift(left, center, -nr_center);</span>
<span class="p_add">+			s += nr_center;</span>
 			shift(left, right, s);
 			nr_right += s;
 		} else
<span class="p_chunk">@@ -323,7 +323,7 @@</span> <span class="p_context"> static void redistribute3(struct dm_btree_info *info, struct btree_node *parent,</span>
 		if (s &gt; 0 &amp;&amp; nr_center &lt; s) {
 			/* not enough in central node */
 			shift(center, right, nr_center);
<span class="p_del">-			s = target - nr_center;</span>
<span class="p_add">+			s -= nr_center;</span>
 			shift(left, right, s);
 			nr_left -= s;
 		} else
<span class="p_header">diff --git a/drivers/md/persistent-data/dm-btree.c b/drivers/md/persistent-data/dm-btree.c</span>
<span class="p_header">index 9701d29..8dad984 100644</span>
<span class="p_header">--- a/drivers/md/persistent-data/dm-btree.c</span>
<span class="p_header">+++ b/drivers/md/persistent-data/dm-btree.c</span>
<span class="p_chunk">@@ -255,7 +255,7 @@</span> <span class="p_context"> int dm_btree_del(struct dm_btree_info *info, dm_block_t root)</span>
 	int r;
 	struct del_stack *s;
 
<span class="p_del">-	s = kmalloc(sizeof(*s), GFP_KERNEL);</span>
<span class="p_add">+	s = kmalloc(sizeof(*s), GFP_NOIO);</span>
 	if (!s)
 		return -ENOMEM;
 	s-&gt;info = info;
<span class="p_header">diff --git a/drivers/net/ethernet/ti/cpsw.c b/drivers/net/ethernet/ti/cpsw.c</span>
<span class="p_header">index 7bf6c4e..a2edd2d 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/ti/cpsw.c</span>
<span class="p_header">+++ b/drivers/net/ethernet/ti/cpsw.c</span>
<span class="p_chunk">@@ -497,9 +497,11 @@</span> <span class="p_context"> static const struct cpsw_stats cpsw_gstrings_stats[] = {</span>
 				(func)(slave++, ##arg);			\
 	} while (0)
 #define cpsw_get_slave_ndev(priv, __slave_no__)				\
<span class="p_del">-	(priv-&gt;slaves[__slave_no__].ndev)</span>
<span class="p_add">+	((__slave_no__ &lt; priv-&gt;data.slaves) ?				\</span>
<span class="p_add">+		priv-&gt;slaves[__slave_no__].ndev : NULL)</span>
 #define cpsw_get_slave_priv(priv, __slave_no__)				\
<span class="p_del">-	((priv-&gt;slaves[__slave_no__].ndev) ?				\</span>
<span class="p_add">+	(((__slave_no__ &lt; priv-&gt;data.slaves) &amp;&amp;				\</span>
<span class="p_add">+		(priv-&gt;slaves[__slave_no__].ndev)) ?			\</span>
 		netdev_priv(priv-&gt;slaves[__slave_no__].ndev) : NULL)	\
 
 #define cpsw_dual_emac_src_port_detect(status, priv, ndev, skb)		\
<span class="p_header">diff --git a/drivers/pnp/system.c b/drivers/pnp/system.c</span>
<span class="p_header">index 515f338..49c1720 100644</span>
<span class="p_header">--- a/drivers/pnp/system.c</span>
<span class="p_header">+++ b/drivers/pnp/system.c</span>
<span class="p_chunk">@@ -7,7 +7,6 @@</span> <span class="p_context"></span>
  *	Bjorn Helgaas &lt;bjorn.helgaas@hp.com&gt;
  */
 
<span class="p_del">-#include &lt;linux/acpi.h&gt;</span>
 #include &lt;linux/pnp.h&gt;
 #include &lt;linux/device.h&gt;
 #include &lt;linux/init.h&gt;
<span class="p_chunk">@@ -23,41 +22,25 @@</span> <span class="p_context"> static const struct pnp_device_id pnp_dev_table[] = {</span>
 	{&quot;&quot;, 0}
 };
 
<span class="p_del">-#ifdef CONFIG_ACPI</span>
<span class="p_del">-static bool __reserve_range(u64 start, unsigned int length, bool io, char *desc)</span>
<span class="p_del">-{</span>
<span class="p_del">-	u8 space_id = io ? ACPI_ADR_SPACE_SYSTEM_IO : ACPI_ADR_SPACE_SYSTEM_MEMORY;</span>
<span class="p_del">-	return !acpi_reserve_region(start, length, space_id, IORESOURCE_BUSY, desc);</span>
<span class="p_del">-}</span>
<span class="p_del">-#else</span>
<span class="p_del">-static bool __reserve_range(u64 start, unsigned int length, bool io, char *desc)</span>
<span class="p_del">-{</span>
<span class="p_del">-	struct resource *res;</span>
<span class="p_del">-</span>
<span class="p_del">-	res = io ? request_region(start, length, desc) :</span>
<span class="p_del">-		request_mem_region(start, length, desc);</span>
<span class="p_del">-	if (res) {</span>
<span class="p_del">-		res-&gt;flags &amp;= ~IORESOURCE_BUSY;</span>
<span class="p_del">-		return true;</span>
<span class="p_del">-	}</span>
<span class="p_del">-	return false;</span>
<span class="p_del">-}</span>
<span class="p_del">-#endif</span>
<span class="p_del">-</span>
 static void reserve_range(struct pnp_dev *dev, struct resource *r, int port)
 {
 	char *regionid;
 	const char *pnpid = dev_name(&amp;dev-&gt;dev);
 	resource_size_t start = r-&gt;start, end = r-&gt;end;
<span class="p_del">-	bool reserved;</span>
<span class="p_add">+	struct resource *res;</span>
 
 	regionid = kmalloc(16, GFP_KERNEL);
 	if (!regionid)
 		return;
 
 	snprintf(regionid, 16, &quot;pnp %s&quot;, pnpid);
<span class="p_del">-	reserved = __reserve_range(start, end - start + 1, !!port, regionid);</span>
<span class="p_del">-	if (!reserved)</span>
<span class="p_add">+	if (port)</span>
<span class="p_add">+		res = request_region(start, end - start + 1, regionid);</span>
<span class="p_add">+	else</span>
<span class="p_add">+		res = request_mem_region(start, end - start + 1, regionid);</span>
<span class="p_add">+	if (res)</span>
<span class="p_add">+		res-&gt;flags &amp;= ~IORESOURCE_BUSY;</span>
<span class="p_add">+	else</span>
 		kfree(regionid);
 
 	/*
<span class="p_chunk">@@ -66,7 +49,7 @@</span> <span class="p_context"> static void reserve_range(struct pnp_dev *dev, struct resource *r, int port)</span>
 	 * have double reservations.
 	 */
 	dev_info(&amp;dev-&gt;dev, &quot;%pR %s reserved\n&quot;, r,
<span class="p_del">-		 reserved ? &quot;has been&quot; : &quot;could not be&quot;);</span>
<span class="p_add">+		 res ? &quot;has been&quot; : &quot;could not be&quot;);</span>
 }
 
 static void reserve_resources_of_dev(struct pnp_dev *dev)
<span class="p_header">diff --git a/drivers/scsi/sg.c b/drivers/scsi/sg.c</span>
<span class="p_header">index eb81c98..721d839 100644</span>
<span class="p_header">--- a/drivers/scsi/sg.c</span>
<span class="p_header">+++ b/drivers/scsi/sg.c</span>
<span class="p_chunk">@@ -1694,6 +1694,9 @@</span> <span class="p_context"> static int sg_start_req(Sg_request *srp, unsigned char *cmd)</span>
 			md-&gt;from_user = 0;
 	}
 
<span class="p_add">+	if (unlikely(iov_count &gt; UIO_MAXIOV))</span>
<span class="p_add">+		return -EINVAL;</span>
<span class="p_add">+</span>
 	if (iov_count) {
 		int len, size = sizeof(struct sg_iovec) * iov_count;
 		struct iovec *iov;
<span class="p_header">diff --git a/drivers/scsi/st.c b/drivers/scsi/st.c</span>
<span class="p_header">index ff44b3c..9903f1d 100644</span>
<span class="p_header">--- a/drivers/scsi/st.c</span>
<span class="p_header">+++ b/drivers/scsi/st.c</span>
<span class="p_chunk">@@ -1262,9 +1262,9 @@</span> <span class="p_context"> static int st_open(struct inode *inode, struct file *filp)</span>
 	spin_lock(&amp;st_use_lock);
 	STp-&gt;in_use = 0;
 	spin_unlock(&amp;st_use_lock);
<span class="p_del">-	scsi_tape_put(STp);</span>
 	if (resumed)
 		scsi_autopm_put_device(STp-&gt;device);
<span class="p_add">+	scsi_tape_put(STp);</span>
 	return retval;
 
 }
<span class="p_header">diff --git a/drivers/usb/musb/musb_virthub.c b/drivers/usb/musb/musb_virthub.c</span>
<span class="p_header">index 5448125..94cdd96 100644</span>
<span class="p_header">--- a/drivers/usb/musb/musb_virthub.c</span>
<span class="p_header">+++ b/drivers/usb/musb/musb_virthub.c</span>
<span class="p_chunk">@@ -231,9 +231,7 @@</span> <span class="p_context"> static int musb_has_gadget(struct musb *musb)</span>
 #ifdef CONFIG_USB_MUSB_HOST
 	return 1;
 #else
<span class="p_del">-	if (musb-&gt;port_mode == MUSB_PORT_MODE_HOST)</span>
<span class="p_del">-		return 1;</span>
<span class="p_del">-	return musb-&gt;g.dev.driver != NULL;</span>
<span class="p_add">+	return musb-&gt;port_mode == MUSB_PORT_MODE_HOST;</span>
 #endif
 }
 
<span class="p_header">diff --git a/drivers/usb/serial/cp210x.c b/drivers/usb/serial/cp210x.c</span>
<span class="p_header">index 280cf22..8452030 100644</span>
<span class="p_header">--- a/drivers/usb/serial/cp210x.c</span>
<span class="p_header">+++ b/drivers/usb/serial/cp210x.c</span>
<span class="p_chunk">@@ -187,6 +187,7 @@</span> <span class="p_context"> static const struct usb_device_id id_table[] = {</span>
 	{ USB_DEVICE(0x1FB9, 0x0602) }, /* Lake Shore Model 648 Magnet Power Supply */
 	{ USB_DEVICE(0x1FB9, 0x0700) }, /* Lake Shore Model 737 VSM Controller */
 	{ USB_DEVICE(0x1FB9, 0x0701) }, /* Lake Shore Model 776 Hall Matrix */
<span class="p_add">+	{ USB_DEVICE(0x2626, 0xEA60) }, /* Aruba Networks 7xxx USB Serial Console */</span>
 	{ USB_DEVICE(0x3195, 0xF190) }, /* Link Instruments MSO-19 */
 	{ USB_DEVICE(0x3195, 0xF280) }, /* Link Instruments MSO-28 */
 	{ USB_DEVICE(0x3195, 0xF281) }, /* Link Instruments MSO-28 */
<span class="p_header">diff --git a/drivers/usb/serial/option.c b/drivers/usb/serial/option.c</span>
<span class="p_header">index 801f799..e2cc293 100644</span>
<span class="p_header">--- a/drivers/usb/serial/option.c</span>
<span class="p_header">+++ b/drivers/usb/serial/option.c</span>
<span class="p_chunk">@@ -1764,6 +1764,7 @@</span> <span class="p_context"> static const struct usb_device_id option_ids[] = {</span>
 	{ USB_DEVICE_AND_INTERFACE_INFO(0x2001, 0x7d03, 0xff, 0x00, 0x00) },
 	{ USB_DEVICE_AND_INTERFACE_INFO(0x07d1, 0x3e01, 0xff, 0xff, 0xff) }, /* D-Link DWM-152/C1 */
 	{ USB_DEVICE_AND_INTERFACE_INFO(0x07d1, 0x3e02, 0xff, 0xff, 0xff) }, /* D-Link DWM-156/C1 */
<span class="p_add">+	{ USB_DEVICE_INTERFACE_CLASS(0x2020, 0x4000, 0xff) },                /* OLICARD300 - MT6225 */</span>
 	{ USB_DEVICE(INOVIA_VENDOR_ID, INOVIA_SEW858) },
 	{ USB_DEVICE(VIATELECOM_VENDOR_ID, VIATELECOM_PRODUCT_CDS7) },
 	{ } /* Terminating entry */
<span class="p_header">diff --git a/drivers/usb/serial/usb-serial.c b/drivers/usb/serial/usb-serial.c</span>
<span class="p_header">index cb6eff2..c567522 100644</span>
<span class="p_header">--- a/drivers/usb/serial/usb-serial.c</span>
<span class="p_header">+++ b/drivers/usb/serial/usb-serial.c</span>
<span class="p_chunk">@@ -1300,6 +1300,7 @@</span> <span class="p_context"> static void __exit usb_serial_exit(void)</span>
 	tty_unregister_driver(usb_serial_tty_driver);
 	put_tty_driver(usb_serial_tty_driver);
 	bus_unregister(&amp;usb_serial_bus_type);
<span class="p_add">+	idr_destroy(&amp;serial_minors);</span>
 }
 
 
<span class="p_header">diff --git a/fs/9p/vfs_inode.c b/fs/9p/vfs_inode.c</span>
<span class="p_header">index 4e65aa9..5a80d7a 100644</span>
<span class="p_header">--- a/fs/9p/vfs_inode.c</span>
<span class="p_header">+++ b/fs/9p/vfs_inode.c</span>
<span class="p_chunk">@@ -533,8 +533,7 @@</span> <span class="p_context"> static struct inode *v9fs_qid_iget(struct super_block *sb,</span>
 	unlock_new_inode(inode);
 	return inode;
 error:
<span class="p_del">-	unlock_new_inode(inode);</span>
<span class="p_del">-	iput(inode);</span>
<span class="p_add">+	iget_failed(inode);</span>
 	return ERR_PTR(retval);
 
 }
<span class="p_header">diff --git a/fs/9p/vfs_inode_dotl.c b/fs/9p/vfs_inode_dotl.c</span>
<span class="p_header">index 4c10edec2..5d73779 100644</span>
<span class="p_header">--- a/fs/9p/vfs_inode_dotl.c</span>
<span class="p_header">+++ b/fs/9p/vfs_inode_dotl.c</span>
<span class="p_chunk">@@ -149,8 +149,7 @@</span> <span class="p_context"> static struct inode *v9fs_qid_iget_dotl(struct super_block *sb,</span>
 	unlock_new_inode(inode);
 	return inode;
 error:
<span class="p_del">-	unlock_new_inode(inode);</span>
<span class="p_del">-	iput(inode);</span>
<span class="p_add">+	iget_failed(inode);</span>
 	return ERR_PTR(retval);
 
 }
<span class="p_header">diff --git a/fs/btrfs/inode-map.c b/fs/btrfs/inode-map.c</span>
<span class="p_header">index bac4511..cb5c24c 100644</span>
<span class="p_header">--- a/fs/btrfs/inode-map.c</span>
<span class="p_header">+++ b/fs/btrfs/inode-map.c</span>
<span class="p_chunk">@@ -242,6 +242,7 @@</span> <span class="p_context"> void btrfs_unpin_free_ino(struct btrfs_root *root)</span>
 {
 	struct btrfs_free_space_ctl *ctl = root-&gt;free_ino_ctl;
 	struct rb_root *rbroot = &amp;root-&gt;free_ino_pinned-&gt;free_space_offset;
<span class="p_add">+	spinlock_t *rbroot_lock = &amp;root-&gt;free_ino_pinned-&gt;tree_lock;</span>
 	struct btrfs_free_space *info;
 	struct rb_node *n;
 	u64 count;
<span class="p_chunk">@@ -250,24 +251,30 @@</span> <span class="p_context"> void btrfs_unpin_free_ino(struct btrfs_root *root)</span>
 		return;
 
 	while (1) {
<span class="p_add">+		bool add_to_ctl = true;</span>
<span class="p_add">+</span>
<span class="p_add">+		spin_lock(rbroot_lock);</span>
 		n = rb_first(rbroot);
<span class="p_del">-		if (!n)</span>
<span class="p_add">+		if (!n) {</span>
<span class="p_add">+			spin_unlock(rbroot_lock);</span>
 			break;
<span class="p_add">+		}</span>
 
 		info = rb_entry(n, struct btrfs_free_space, offset_index);
 		BUG_ON(info-&gt;bitmap); /* Logic error */
 
 		if (info-&gt;offset &gt; root-&gt;cache_progress)
<span class="p_del">-			goto free;</span>
<span class="p_add">+			add_to_ctl = false;</span>
 		else if (info-&gt;offset + info-&gt;bytes &gt; root-&gt;cache_progress)
 			count = root-&gt;cache_progress - info-&gt;offset + 1;
 		else
 			count = info-&gt;bytes;
 
<span class="p_del">-		__btrfs_add_free_space(ctl, info-&gt;offset, count);</span>
<span class="p_del">-free:</span>
 		rb_erase(&amp;info-&gt;offset_index, rbroot);
<span class="p_del">-		kfree(info);</span>
<span class="p_add">+		spin_unlock(rbroot_lock);</span>
<span class="p_add">+		if (add_to_ctl)</span>
<span class="p_add">+			__btrfs_add_free_space(ctl, info-&gt;offset, count);</span>
<span class="p_add">+		kmem_cache_free(btrfs_free_space_cachep, info);</span>
 	}
 }
 
<span class="p_header">diff --git a/fs/btrfs/ioctl.c b/fs/btrfs/ioctl.c</span>
<span class="p_header">index 05f5c87..3152235 100644</span>
<span class="p_header">--- a/fs/btrfs/ioctl.c</span>
<span class="p_header">+++ b/fs/btrfs/ioctl.c</span>
<span class="p_chunk">@@ -2698,7 +2698,7 @@</span> <span class="p_context"> static long btrfs_ioctl_file_extent_same(struct file *file,</span>
 					 void __user *argp)
 {
 	struct btrfs_ioctl_same_args tmp;
<span class="p_del">-	struct btrfs_ioctl_same_args *same;</span>
<span class="p_add">+	struct btrfs_ioctl_same_args *same = NULL;</span>
 	struct btrfs_ioctl_same_extent_info *info;
 	struct inode *src = file-&gt;f_dentry-&gt;d_inode;
 	struct file *dst_file = NULL;
<span class="p_chunk">@@ -2732,6 +2732,7 @@</span> <span class="p_context"> static long btrfs_ioctl_file_extent_same(struct file *file,</span>
 
 	if (IS_ERR(same)) {
 		ret = PTR_ERR(same);
<span class="p_add">+		same = NULL;</span>
 		goto out;
 	}
 
<span class="p_chunk">@@ -2819,6 +2820,7 @@</span> <span class="p_context"> next:</span>
 
 out:
 	mnt_drop_write_file(file);
<span class="p_add">+	kfree(same);</span>
 	return ret;
 }
 
<span class="p_header">diff --git a/fs/btrfs/tree-log.c b/fs/btrfs/tree-log.c</span>
<span class="p_header">index 29f3a9b..6e9d26f 100644</span>
<span class="p_header">--- a/fs/btrfs/tree-log.c</span>
<span class="p_header">+++ b/fs/btrfs/tree-log.c</span>
<span class="p_chunk">@@ -3680,6 +3680,7 @@</span> <span class="p_context"> static int btrfs_log_inode(struct btrfs_trans_handle *trans,</span>
 	bool fast_search = false;
 	u64 ino = btrfs_ino(inode);
 	u64 logged_isize = 0;
<span class="p_add">+	bool need_log_inode_item = true;</span>
 
 	path = btrfs_alloc_path();
 	if (!path)
<span class="p_chunk">@@ -3769,11 +3770,6 @@</span> <span class="p_context"> static int btrfs_log_inode(struct btrfs_trans_handle *trans,</span>
 		} else {
 			if (inode_only == LOG_INODE_ALL)
 				fast_search = true;
<span class="p_del">-			ret = log_inode_item(trans, log, dst_path, inode);</span>
<span class="p_del">-			if (ret) {</span>
<span class="p_del">-				err = ret;</span>
<span class="p_del">-				goto out_unlock;</span>
<span class="p_del">-			}</span>
 			goto log_extents;
 		}
 
<span class="p_chunk">@@ -3797,6 +3793,9 @@</span> <span class="p_context"> again:</span>
 		if (min_key.type &gt; max_key.type)
 			break;
 
<span class="p_add">+		if (min_key.type == BTRFS_INODE_ITEM_KEY)</span>
<span class="p_add">+			need_log_inode_item = false;</span>
<span class="p_add">+</span>
 		src = path-&gt;nodes[0];
 		if (ins_nr &amp;&amp; ins_start_slot + ins_nr == path-&gt;slots[0]) {
 			ins_nr++;
<span class="p_chunk">@@ -3858,6 +3857,11 @@</span> <span class="p_context"> next_slot:</span>
 log_extents:
 	btrfs_release_path(path);
 	btrfs_release_path(dst_path);
<span class="p_add">+	if (need_log_inode_item) {</span>
<span class="p_add">+		err = log_inode_item(trans, log, dst_path, inode);</span>
<span class="p_add">+		if (err)</span>
<span class="p_add">+			goto out_unlock;</span>
<span class="p_add">+	}</span>
 	if (fast_search) {
 		ret = btrfs_log_changed_extents(trans, root, inode, dst_path);
 		if (ret) {
<span class="p_header">diff --git a/fs/dcache.c b/fs/dcache.c</span>
<span class="p_header">index 9b3751a..09b4a3e 100644</span>
<span class="p_header">--- a/fs/dcache.c</span>
<span class="p_header">+++ b/fs/dcache.c</span>
<span class="p_chunk">@@ -589,6 +589,9 @@</span> <span class="p_context"> repeat:</span>
 	if (unlikely(d_unhashed(dentry)))
 		goto kill_it;
 
<span class="p_add">+	if (unlikely(dentry-&gt;d_flags &amp; DCACHE_DISCONNECTED))</span>
<span class="p_add">+		goto kill_it;</span>
<span class="p_add">+</span>
 	if (unlikely(dentry-&gt;d_flags &amp; DCACHE_OP_DELETE)) {
 		if (dentry-&gt;d_op-&gt;d_delete(dentry))
 			goto kill_it;
<span class="p_header">diff --git a/fs/ext4/inode.c b/fs/ext4/inode.c</span>
<span class="p_header">index 638de3d..776de0e 100644</span>
<span class="p_header">--- a/fs/ext4/inode.c</span>
<span class="p_header">+++ b/fs/ext4/inode.c</span>
<span class="p_chunk">@@ -1362,7 +1362,7 @@</span> <span class="p_context"> static void ext4_da_page_release_reservation(struct page *page,</span>
 					     unsigned int offset,
 					     unsigned int length)
 {
<span class="p_del">-	int to_release = 0;</span>
<span class="p_add">+	int to_release = 0, contiguous_blks = 0;</span>
 	struct buffer_head *head, *bh;
 	unsigned int curr_off = 0;
 	struct inode *inode = page-&gt;mapping-&gt;host;
<span class="p_chunk">@@ -1383,14 +1383,23 @@</span> <span class="p_context"> static void ext4_da_page_release_reservation(struct page *page,</span>
 
 		if ((offset &lt;= curr_off) &amp;&amp; (buffer_delay(bh))) {
 			to_release++;
<span class="p_add">+			contiguous_blks++;</span>
 			clear_buffer_delay(bh);
<span class="p_add">+		} else if (contiguous_blks) {</span>
<span class="p_add">+			lblk = page-&gt;index &lt;&lt;</span>
<span class="p_add">+			       (PAGE_CACHE_SHIFT - inode-&gt;i_blkbits);</span>
<span class="p_add">+			lblk += (curr_off &gt;&gt; inode-&gt;i_blkbits) -</span>
<span class="p_add">+				contiguous_blks;</span>
<span class="p_add">+			ext4_es_remove_extent(inode, lblk, contiguous_blks);</span>
<span class="p_add">+			contiguous_blks = 0;</span>
 		}
 		curr_off = next_off;
 	} while ((bh = bh-&gt;b_this_page) != head);
 
<span class="p_del">-	if (to_release) {</span>
<span class="p_add">+	if (contiguous_blks) {</span>
 		lblk = page-&gt;index &lt;&lt; (PAGE_CACHE_SHIFT - inode-&gt;i_blkbits);
<span class="p_del">-		ext4_es_remove_extent(inode, lblk, to_release);</span>
<span class="p_add">+		lblk += (curr_off &gt;&gt; inode-&gt;i_blkbits) - contiguous_blks;</span>
<span class="p_add">+		ext4_es_remove_extent(inode, lblk, contiguous_blks);</span>
 	}
 
 	/* If we have released all the blocks belonging to a cluster, then we
<span class="p_header">diff --git a/fs/ext4/mballoc.c b/fs/ext4/mballoc.c</span>
<span class="p_header">index 242226a..a948468 100644</span>
<span class="p_header">--- a/fs/ext4/mballoc.c</span>
<span class="p_header">+++ b/fs/ext4/mballoc.c</span>
<span class="p_chunk">@@ -4791,18 +4791,12 @@</span> <span class="p_context"> do_more:</span>
 		/*
 		 * blocks being freed are metadata. these blocks shouldn&#39;t
 		 * be used until this transaction is committed
<span class="p_add">+		 *</span>
<span class="p_add">+		 * We use __GFP_NOFAIL because ext4_free_blocks() is not allowed</span>
<span class="p_add">+		 * to fail.</span>
 		 */
<span class="p_del">-	retry:</span>
<span class="p_del">-		new_entry = kmem_cache_alloc(ext4_free_data_cachep, GFP_NOFS);</span>
<span class="p_del">-		if (!new_entry) {</span>
<span class="p_del">-			/*</span>
<span class="p_del">-			 * We use a retry loop because</span>
<span class="p_del">-			 * ext4_free_blocks() is not allowed to fail.</span>
<span class="p_del">-			 */</span>
<span class="p_del">-			cond_resched();</span>
<span class="p_del">-			congestion_wait(BLK_RW_ASYNC, HZ/50);</span>
<span class="p_del">-			goto retry;</span>
<span class="p_del">-		}</span>
<span class="p_add">+		new_entry = kmem_cache_alloc(ext4_free_data_cachep,</span>
<span class="p_add">+				GFP_NOFS|__GFP_NOFAIL);</span>
 		new_entry-&gt;efd_start_cluster = bit;
 		new_entry-&gt;efd_group = block_group;
 		new_entry-&gt;efd_count = count_clusters;
<span class="p_header">diff --git a/fs/ext4/migrate.c b/fs/ext4/migrate.c</span>
<span class="p_header">index 2ae73a8..be92ed2 100644</span>
<span class="p_header">--- a/fs/ext4/migrate.c</span>
<span class="p_header">+++ b/fs/ext4/migrate.c</span>
<span class="p_chunk">@@ -616,6 +616,7 @@</span> <span class="p_context"> int ext4_ind_migrate(struct inode *inode)</span>
 	struct ext4_inode_info		*ei = EXT4_I(inode);
 	struct ext4_extent		*ex;
 	unsigned int			i, len;
<span class="p_add">+	ext4_lblk_t			start, end;</span>
 	ext4_fsblk_t			blk;
 	handle_t			*handle;
 	int				ret;
<span class="p_chunk">@@ -629,6 +630,14 @@</span> <span class="p_context"> int ext4_ind_migrate(struct inode *inode)</span>
 				       EXT4_FEATURE_RO_COMPAT_BIGALLOC))
 		return -EOPNOTSUPP;
 
<span class="p_add">+	/*</span>
<span class="p_add">+	 * In order to get correct extent info, force all delayed allocation</span>
<span class="p_add">+	 * blocks to be allocated, otherwise delayed allocation blocks may not</span>
<span class="p_add">+	 * be reflected and bypass the checks on extent header.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	if (test_opt(inode-&gt;i_sb, DELALLOC))</span>
<span class="p_add">+		ext4_alloc_da_blocks(inode);</span>
<span class="p_add">+</span>
 	handle = ext4_journal_start(inode, EXT4_HT_MIGRATE, 1);
 	if (IS_ERR(handle))
 		return PTR_ERR(handle);
<span class="p_chunk">@@ -646,11 +655,13 @@</span> <span class="p_context"> int ext4_ind_migrate(struct inode *inode)</span>
 		goto errout;
 	}
 	if (eh-&gt;eh_entries == 0)
<span class="p_del">-		blk = len = 0;</span>
<span class="p_add">+		blk = len = start = end = 0;</span>
 	else {
 		len = le16_to_cpu(ex-&gt;ee_len);
 		blk = ext4_ext_pblock(ex);
<span class="p_del">-		if (len &gt; EXT4_NDIR_BLOCKS) {</span>
<span class="p_add">+		start = le32_to_cpu(ex-&gt;ee_block);</span>
<span class="p_add">+		end = start + len - 1;</span>
<span class="p_add">+		if (end &gt;= EXT4_NDIR_BLOCKS) {</span>
 			ret = -EOPNOTSUPP;
 			goto errout;
 		}
<span class="p_chunk">@@ -658,7 +669,7 @@</span> <span class="p_context"> int ext4_ind_migrate(struct inode *inode)</span>
 
 	ext4_clear_inode_flag(inode, EXT4_INODE_EXTENTS);
 	memset(ei-&gt;i_data, 0, sizeof(ei-&gt;i_data));
<span class="p_del">-	for (i=0; i &lt; len; i++)</span>
<span class="p_add">+	for (i = start; i &lt;= end; i++)</span>
 		ei-&gt;i_data[i] = cpu_to_le32(blk++);
 	ext4_mark_inode_dirty(handle, inode);
 errout:
<span class="p_header">diff --git a/fs/hpfs/super.c b/fs/hpfs/super.c</span>
<span class="p_header">index 4534ff6..f9866e4 100644</span>
<span class="p_header">--- a/fs/hpfs/super.c</span>
<span class="p_header">+++ b/fs/hpfs/super.c</span>
<span class="p_chunk">@@ -420,9 +420,12 @@</span> <span class="p_context"> static int hpfs_remount_fs(struct super_block *s, int *flags, char *data)</span>
 	int o;
 	struct hpfs_sb_info *sbi = hpfs_sb(s);
 	char *new_opts = kstrdup(data, GFP_KERNEL);
<span class="p_del">-	</span>
<span class="p_add">+</span>
<span class="p_add">+	if (!new_opts)</span>
<span class="p_add">+		return -ENOMEM;</span>
<span class="p_add">+</span>
 	*flags |= MS_NOATIME;
<span class="p_del">-	</span>
<span class="p_add">+</span>
 	hpfs_lock(s);
 	uid = sbi-&gt;sb_uid; gid = sbi-&gt;sb_gid;
 	umask = 0777 &amp; ~sbi-&gt;sb_mode;
<span class="p_header">diff --git a/include/linux/acpi.h b/include/linux/acpi.h</span>
<span class="p_header">index 1652d53..d9099b1 100644</span>
<span class="p_header">--- a/include/linux/acpi.h</span>
<span class="p_header">+++ b/include/linux/acpi.h</span>
<span class="p_chunk">@@ -297,9 +297,6 @@</span> <span class="p_context"> int acpi_check_region(resource_size_t start, resource_size_t n,</span>
 
 int acpi_resources_are_enforced(void);
 
<span class="p_del">-int acpi_reserve_region(u64 start, unsigned int length, u8 space_id,</span>
<span class="p_del">-			unsigned long flags, char *desc);</span>
<span class="p_del">-</span>
 #ifdef CONFIG_HIBERNATION
 void __init acpi_no_s4_hw_signature(void);
 #endif
<span class="p_chunk">@@ -459,13 +456,6 @@</span> <span class="p_context"> static inline int acpi_check_region(resource_size_t start, resource_size_t n,</span>
 	return 0;
 }
 
<span class="p_del">-static inline int acpi_reserve_region(u64 start, unsigned int length,</span>
<span class="p_del">-				      u8 space_id, unsigned long flags,</span>
<span class="p_del">-				      char *desc)</span>
<span class="p_del">-{</span>
<span class="p_del">-	return -ENXIO;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
 struct acpi_table_header;
 static inline int acpi_table_parse(char *id,
 				int (*handler)(struct acpi_table_header *))
<span class="p_header">diff --git a/kernel/irq/resend.c b/kernel/irq/resend.c</span>
<span class="p_header">index 9065107..7a5237a 100644</span>
<span class="p_header">--- a/kernel/irq/resend.c</span>
<span class="p_header">+++ b/kernel/irq/resend.c</span>
<span class="p_chunk">@@ -75,13 +75,21 @@</span> <span class="p_context"> void check_irq_resend(struct irq_desc *desc, unsigned int irq)</span>
 		    !desc-&gt;irq_data.chip-&gt;irq_retrigger(&amp;desc-&gt;irq_data)) {
 #ifdef CONFIG_HARDIRQS_SW_RESEND
 			/*
<span class="p_del">-			 * If the interrupt has a parent irq and runs</span>
<span class="p_del">-			 * in the thread context of the parent irq,</span>
<span class="p_del">-			 * retrigger the parent.</span>
<span class="p_add">+			 * If the interrupt is running in the thread</span>
<span class="p_add">+			 * context of the parent irq we need to be</span>
<span class="p_add">+			 * careful, because we cannot trigger it</span>
<span class="p_add">+			 * directly.</span>
 			 */
<span class="p_del">-			if (desc-&gt;parent_irq &amp;&amp;</span>
<span class="p_del">-			    irq_settings_is_nested_thread(desc))</span>
<span class="p_add">+			if (irq_settings_is_nested_thread(desc)) {</span>
<span class="p_add">+				/*</span>
<span class="p_add">+				 * If the parent_irq is valid, we</span>
<span class="p_add">+				 * retrigger the parent, otherwise we</span>
<span class="p_add">+				 * do nothing.</span>
<span class="p_add">+				 */</span>
<span class="p_add">+				if (!desc-&gt;parent_irq)</span>
<span class="p_add">+					return;</span>
 				irq = desc-&gt;parent_irq;
<span class="p_add">+			}</span>
 			/* Set it pending and activate the softirq: */
 			set_bit(irq, irqs_resend);
 			tasklet_schedule(&amp;resend_tasklet);
<span class="p_header">diff --git a/kernel/trace/trace.h b/kernel/trace/trace.h</span>
<span class="p_header">index ea189e0..57d6490 100644</span>
<span class="p_header">--- a/kernel/trace/trace.h</span>
<span class="p_header">+++ b/kernel/trace/trace.h</span>
<span class="p_chunk">@@ -421,6 +421,7 @@</span> <span class="p_context"> enum {</span>
 
 	TRACE_CONTROL_BIT,
 
<span class="p_add">+	TRACE_BRANCH_BIT,</span>
 /*
  * Abuse of the trace_recursion.
  * As we need a way to maintain state if we are tracing the function
<span class="p_header">diff --git a/kernel/trace/trace_branch.c b/kernel/trace/trace_branch.c</span>
<span class="p_header">index 697fb9b..60850b4 100644</span>
<span class="p_header">--- a/kernel/trace/trace_branch.c</span>
<span class="p_header">+++ b/kernel/trace/trace_branch.c</span>
<span class="p_chunk">@@ -37,9 +37,12 @@</span> <span class="p_context"> probe_likely_condition(struct ftrace_branch_data *f, int val, int expect)</span>
 	struct trace_branch *entry;
 	struct ring_buffer *buffer;
 	unsigned long flags;
<span class="p_del">-	int cpu, pc;</span>
<span class="p_add">+	int pc;</span>
 	const char *p;
 
<span class="p_add">+	if (current-&gt;trace_recursion &amp; TRACE_BRANCH_BIT)</span>
<span class="p_add">+		return;</span>
<span class="p_add">+</span>
 	/*
 	 * I would love to save just the ftrace_likely_data pointer, but
 	 * this code can also be used by modules. Ugly things can happen
<span class="p_chunk">@@ -50,10 +53,10 @@</span> <span class="p_context"> probe_likely_condition(struct ftrace_branch_data *f, int val, int expect)</span>
 	if (unlikely(!tr))
 		return;
 
<span class="p_del">-	local_irq_save(flags);</span>
<span class="p_del">-	cpu = raw_smp_processor_id();</span>
<span class="p_del">-	data = per_cpu_ptr(tr-&gt;trace_buffer.data, cpu);</span>
<span class="p_del">-	if (atomic_inc_return(&amp;data-&gt;disabled) != 1)</span>
<span class="p_add">+	raw_local_irq_save(flags);</span>
<span class="p_add">+	current-&gt;trace_recursion |= TRACE_BRANCH_BIT;</span>
<span class="p_add">+	data = this_cpu_ptr(tr-&gt;trace_buffer.data);</span>
<span class="p_add">+	if (atomic_read(&amp;data-&gt;disabled))</span>
 		goto out;
 
 	pc = preempt_count();
<span class="p_chunk">@@ -82,8 +85,8 @@</span> <span class="p_context"> probe_likely_condition(struct ftrace_branch_data *f, int val, int expect)</span>
 		__buffer_unlock_commit(buffer, event);
 
  out:
<span class="p_del">-	atomic_dec(&amp;data-&gt;disabled);</span>
<span class="p_del">-	local_irq_restore(flags);</span>
<span class="p_add">+	current-&gt;trace_recursion &amp;= ~TRACE_BRANCH_BIT;</span>
<span class="p_add">+	raw_local_irq_restore(flags);</span>
 }
 
 static inline
<span class="p_header">diff --git a/net/bridge/br_mdb.c b/net/bridge/br_mdb.c</span>
<span class="p_header">index b734575..af8315a 100644</span>
<span class="p_header">--- a/net/bridge/br_mdb.c</span>
<span class="p_header">+++ b/net/bridge/br_mdb.c</span>
<span class="p_chunk">@@ -322,6 +322,7 @@</span> <span class="p_context"> static int br_mdb_add_group(struct net_bridge *br, struct net_bridge_port *port,</span>
 	struct net_bridge_port_group *p;
 	struct net_bridge_port_group __rcu **pp;
 	struct net_bridge_mdb_htable *mdb;
<span class="p_add">+	unsigned long now = jiffies;</span>
 	int err;
 
 	mdb = mlock_dereference(br-&gt;mdb, br);
<span class="p_chunk">@@ -346,6 +347,8 @@</span> <span class="p_context"> static int br_mdb_add_group(struct net_bridge *br, struct net_bridge_port *port,</span>
 	if (unlikely(!p))
 		return -ENOMEM;
 	rcu_assign_pointer(*pp, p);
<span class="p_add">+	if (state == MDB_TEMPORARY)</span>
<span class="p_add">+		mod_timer(&amp;p-&gt;timer, now + br-&gt;multicast_membership_interval);</span>
 
 	br_mdb_notify(br-&gt;dev, port, group, RTM_NEWMDB);
 	return 0;
<span class="p_chunk">@@ -370,6 +373,7 @@</span> <span class="p_context"> static int __br_mdb_add(struct net *net, struct net_bridge *br,</span>
 	if (!p || p-&gt;br != br || p-&gt;state == BR_STATE_DISABLED)
 		return -EINVAL;
 
<span class="p_add">+	memset(&amp;ip, 0, sizeof(ip));</span>
 	ip.proto = entry-&gt;addr.proto;
 	if (ip.proto == htons(ETH_P_IP))
 		ip.u.ip4 = entry-&gt;addr.u.ip4;
<span class="p_chunk">@@ -416,6 +420,7 @@</span> <span class="p_context"> static int __br_mdb_del(struct net_bridge *br, struct br_mdb_entry *entry)</span>
 	if (!netif_running(br-&gt;dev) || br-&gt;multicast_disabled)
 		return -EINVAL;
 
<span class="p_add">+	memset(&amp;ip, 0, sizeof(ip));</span>
 	ip.proto = entry-&gt;addr.proto;
 	if (ip.proto == htons(ETH_P_IP)) {
 		if (timer_pending(&amp;br-&gt;ip4_querier.timer))
<span class="p_header">diff --git a/net/core/dev.c b/net/core/dev.c</span>
<span class="p_header">index 937fa81..870b9ec 100644</span>
<span class="p_header">--- a/net/core/dev.c</span>
<span class="p_header">+++ b/net/core/dev.c</span>
<span class="p_chunk">@@ -3206,6 +3206,8 @@</span> <span class="p_context"> static int enqueue_to_backlog(struct sk_buff *skb, int cpu,</span>
 	local_irq_save(flags);
 
 	rps_lock(sd);
<span class="p_add">+	if (!netif_running(skb-&gt;dev))</span>
<span class="p_add">+		goto drop;</span>
 	qlen = skb_queue_len(&amp;sd-&gt;input_pkt_queue);
 	if (qlen &lt;= netdev_max_backlog &amp;&amp; !skb_flow_limit(skb, qlen)) {
 		if (skb_queue_len(&amp;sd-&gt;input_pkt_queue)) {
<span class="p_chunk">@@ -3227,6 +3229,7 @@</span> <span class="p_context"> enqueue:</span>
 		goto enqueue;
 	}
 
<span class="p_add">+drop:</span>
 	sd-&gt;dropped++;
 	rps_unlock(sd);
 
<span class="p_chunk">@@ -5542,6 +5545,7 @@</span> <span class="p_context"> static void rollback_registered_many(struct list_head *head)</span>
 		unlist_netdevice(dev);
 
 		dev-&gt;reg_state = NETREG_UNREGISTERING;
<span class="p_add">+		on_each_cpu(flush_backlog, dev, 1);</span>
 	}
 
 	synchronize_net();
<span class="p_chunk">@@ -5799,7 +5803,8 @@</span> <span class="p_context"> static int netif_alloc_netdev_queues(struct net_device *dev)</span>
 	struct netdev_queue *tx;
 	size_t sz = count * sizeof(*tx);
 
<span class="p_del">-	BUG_ON(count &lt; 1 || count &gt; 0xffff);</span>
<span class="p_add">+	if (count &lt; 1 || count &gt; 0xffff)</span>
<span class="p_add">+		return -EINVAL;</span>
 
 	tx = kzalloc(sz, GFP_KERNEL | __GFP_NOWARN | __GFP_REPEAT);
 	if (!tx) {
<span class="p_chunk">@@ -6162,8 +6167,6 @@</span> <span class="p_context"> void netdev_run_todo(void)</span>
 
 		dev-&gt;reg_state = NETREG_UNREGISTERED;
 
<span class="p_del">-		on_each_cpu(flush_backlog, dev, 1);</span>
<span class="p_del">-</span>
 		netdev_wait_allrefs(dev);
 
 		/* paranoia */
<span class="p_header">diff --git a/net/dsa/dsa.c b/net/dsa/dsa.c</span>
<span class="p_header">index 0eb5d5e..19e7448 100644</span>
<span class="p_header">--- a/net/dsa/dsa.c</span>
<span class="p_header">+++ b/net/dsa/dsa.c</span>
<span class="p_chunk">@@ -417,7 +417,7 @@</span> <span class="p_context"> static int dsa_of_probe(struct platform_device *pdev)</span>
 			continue;
 
 		cd-&gt;sw_addr = be32_to_cpup(sw_addr);
<span class="p_del">-		if (cd-&gt;sw_addr &gt; PHY_MAX_ADDR)</span>
<span class="p_add">+		if (cd-&gt;sw_addr &gt;= PHY_MAX_ADDR)</span>
 			continue;
 
 		for_each_available_child_of_node(child, port) {
<span class="p_chunk">@@ -426,6 +426,8 @@</span> <span class="p_context"> static int dsa_of_probe(struct platform_device *pdev)</span>
 				continue;
 
 			port_index = be32_to_cpup(port_reg);
<span class="p_add">+			if (port_index &gt;= DSA_MAX_PORTS)</span>
<span class="p_add">+				break;</span>
 
 			port_name = of_get_property(port, &quot;label&quot;, NULL);
 			if (!port_name)
<span class="p_chunk">@@ -448,8 +450,6 @@</span> <span class="p_context"> static int dsa_of_probe(struct platform_device *pdev)</span>
 					goto out_free_chip;
 			}
 
<span class="p_del">-			if (port_index == DSA_MAX_PORTS)</span>
<span class="p_del">-				break;</span>
 		}
 	}
 
<span class="p_header">diff --git a/net/ipv4/ip_tunnel.c b/net/ipv4/ip_tunnel.c</span>
<span class="p_header">index d4e7bd7..0b5d216 100644</span>
<span class="p_header">--- a/net/ipv4/ip_tunnel.c</span>
<span class="p_header">+++ b/net/ipv4/ip_tunnel.c</span>
<span class="p_chunk">@@ -476,7 +476,8 @@</span> <span class="p_context"> drop:</span>
 EXPORT_SYMBOL_GPL(ip_tunnel_rcv);
 
 static int tnl_update_pmtu(struct net_device *dev, struct sk_buff *skb,
<span class="p_del">-			    struct rtable *rt, __be16 df)</span>
<span class="p_add">+			    struct rtable *rt, __be16 df,</span>
<span class="p_add">+			    const struct iphdr *inner_iph)</span>
 {
 	struct ip_tunnel *tunnel = netdev_priv(dev);
 	int pkt_size = skb-&gt;len - tunnel-&gt;hlen - dev-&gt;hard_header_len;
<span class="p_chunk">@@ -493,7 +494,8 @@</span> <span class="p_context"> static int tnl_update_pmtu(struct net_device *dev, struct sk_buff *skb,</span>
 
 	if (skb-&gt;protocol == htons(ETH_P_IP)) {
 		if (!skb_is_gso(skb) &amp;&amp;
<span class="p_del">-		    (df &amp; htons(IP_DF)) &amp;&amp; mtu &lt; pkt_size) {</span>
<span class="p_add">+		    (inner_iph-&gt;frag_off &amp; htons(IP_DF)) &amp;&amp;</span>
<span class="p_add">+		    mtu &lt; pkt_size) {</span>
 			memset(IPCB(skb), 0, sizeof(*IPCB(skb)));
 			icmp_send(skb, ICMP_DEST_UNREACH, ICMP_FRAG_NEEDED, htonl(mtu));
 			return -E2BIG;
<span class="p_chunk">@@ -611,7 +613,7 @@</span> <span class="p_context"> void ip_tunnel_xmit(struct sk_buff *skb, struct net_device *dev,</span>
 		goto tx_error;
 	}
 
<span class="p_del">-	if (tnl_update_pmtu(dev, skb, rt, tnl_params-&gt;frag_off)) {</span>
<span class="p_add">+	if (tnl_update_pmtu(dev, skb, rt, tnl_params-&gt;frag_off, inner_iph)) {</span>
 		ip_rt_put(rt);
 		goto tx_error;
 	}
<span class="p_header">diff --git a/net/ipv6/ip6_input.c b/net/ipv6/ip6_input.c</span>
<span class="p_header">index 51d54dc..05c94d9 100644</span>
<span class="p_header">--- a/net/ipv6/ip6_input.c</span>
<span class="p_header">+++ b/net/ipv6/ip6_input.c</span>
<span class="p_chunk">@@ -329,10 +329,10 @@</span> <span class="p_context"> int ip6_mc_input(struct sk_buff *skb)</span>
 				if (offset &lt; 0)
 					goto out;
 
<span class="p_del">-				if (!ipv6_is_mld(skb, nexthdr, offset))</span>
<span class="p_del">-					goto out;</span>
<span class="p_add">+				if (ipv6_is_mld(skb, nexthdr, offset))</span>
<span class="p_add">+					deliver = true;</span>
 
<span class="p_del">-				deliver = true;</span>
<span class="p_add">+				goto out;</span>
 			}
 			/* unknown RA - process it normally */
 		}
<span class="p_header">diff --git a/net/rds/ib_rdma.c b/net/rds/ib_rdma.c</span>
<span class="p_header">index e8fdb17..a985158 100644</span>
<span class="p_header">--- a/net/rds/ib_rdma.c</span>
<span class="p_header">+++ b/net/rds/ib_rdma.c</span>
<span class="p_chunk">@@ -759,8 +759,10 @@</span> <span class="p_context"> void *rds_ib_get_mr(struct scatterlist *sg, unsigned long nents,</span>
 	}
 
 	ibmr = rds_ib_alloc_fmr(rds_ibdev);
<span class="p_del">-	if (IS_ERR(ibmr))</span>
<span class="p_add">+	if (IS_ERR(ibmr)) {</span>
<span class="p_add">+		rds_ib_dev_put(rds_ibdev);</span>
 		return ibmr;
<span class="p_add">+	}</span>
 
 	ret = rds_ib_map_fmr(rds_ibdev, ibmr, sg, nents);
 	if (ret == 0)
<span class="p_header">diff --git a/security/keys/keyring.c b/security/keys/keyring.c</span>
<span class="p_header">index d46cbc5..eefe216 100644</span>
<span class="p_header">--- a/security/keys/keyring.c</span>
<span class="p_header">+++ b/security/keys/keyring.c</span>
<span class="p_chunk">@@ -1147,9 +1147,11 @@</span> <span class="p_context"> void __key_link_end(struct key *keyring,</span>
 	if (index_key-&gt;type == &amp;key_type_keyring)
 		up_write(&amp;keyring_serialise_link_sem);
 
<span class="p_del">-	if (edit &amp;&amp; !edit-&gt;dead_leaf) {</span>
<span class="p_del">-		key_payload_reserve(keyring,</span>
<span class="p_del">-				    keyring-&gt;datalen - KEYQUOTA_LINK_BYTES);</span>
<span class="p_add">+	if (edit) {</span>
<span class="p_add">+		if (!edit-&gt;dead_leaf) {</span>
<span class="p_add">+			key_payload_reserve(keyring,</span>
<span class="p_add">+				keyring-&gt;datalen - KEYQUOTA_LINK_BYTES);</span>
<span class="p_add">+		}</span>
 		assoc_array_cancel_edit(edit);
 	}
 	up_write(&amp;keyring-&gt;sem);
<span class="p_header">diff --git a/sound/usb/quirks-table.h b/sound/usb/quirks-table.h</span>
<span class="p_header">index 0acb7c6..e3bd28a 100644</span>
<span class="p_header">--- a/sound/usb/quirks-table.h</span>
<span class="p_header">+++ b/sound/usb/quirks-table.h</span>
<span class="p_chunk">@@ -2546,6 +2546,74 @@</span> <span class="p_context"> YAMAHA_DEVICE(0x7010, &quot;UB99&quot;),</span>
 	}
 },
 
<span class="p_add">+/* Steinberg devices */</span>
<span class="p_add">+{</span>
<span class="p_add">+	/* Steinberg MI2 */</span>
<span class="p_add">+	USB_DEVICE_VENDOR_SPEC(0x0a4e, 0x2040),</span>
<span class="p_add">+	.driver_info = (unsigned long) &amp; (const struct snd_usb_audio_quirk) {</span>
<span class="p_add">+		.ifnum = QUIRK_ANY_INTERFACE,</span>
<span class="p_add">+		.type = QUIRK_COMPOSITE,</span>
<span class="p_add">+		.data = &amp; (const struct snd_usb_audio_quirk[]) {</span>
<span class="p_add">+			{</span>
<span class="p_add">+				.ifnum = 0,</span>
<span class="p_add">+				.type = QUIRK_AUDIO_STANDARD_INTERFACE</span>
<span class="p_add">+			},</span>
<span class="p_add">+			{</span>
<span class="p_add">+				.ifnum = 1,</span>
<span class="p_add">+				.type = QUIRK_AUDIO_STANDARD_INTERFACE</span>
<span class="p_add">+			},</span>
<span class="p_add">+			{</span>
<span class="p_add">+				.ifnum = 2,</span>
<span class="p_add">+				.type = QUIRK_AUDIO_STANDARD_INTERFACE</span>
<span class="p_add">+			},</span>
<span class="p_add">+			{</span>
<span class="p_add">+				.ifnum = 3,</span>
<span class="p_add">+				.type = QUIRK_MIDI_FIXED_ENDPOINT,</span>
<span class="p_add">+				.data = &amp;(const struct snd_usb_midi_endpoint_info) {</span>
<span class="p_add">+					.out_cables = 0x0001,</span>
<span class="p_add">+					.in_cables  = 0x0001</span>
<span class="p_add">+				}</span>
<span class="p_add">+			},</span>
<span class="p_add">+			{</span>
<span class="p_add">+				.ifnum = -1</span>
<span class="p_add">+			}</span>
<span class="p_add">+		}</span>
<span class="p_add">+	}</span>
<span class="p_add">+},</span>
<span class="p_add">+{</span>
<span class="p_add">+	/* Steinberg MI4 */</span>
<span class="p_add">+	USB_DEVICE_VENDOR_SPEC(0x0a4e, 0x4040),</span>
<span class="p_add">+	.driver_info = (unsigned long) &amp; (const struct snd_usb_audio_quirk) {</span>
<span class="p_add">+		.ifnum = QUIRK_ANY_INTERFACE,</span>
<span class="p_add">+		.type = QUIRK_COMPOSITE,</span>
<span class="p_add">+		.data = &amp; (const struct snd_usb_audio_quirk[]) {</span>
<span class="p_add">+			{</span>
<span class="p_add">+				.ifnum = 0,</span>
<span class="p_add">+				.type = QUIRK_AUDIO_STANDARD_INTERFACE</span>
<span class="p_add">+			},</span>
<span class="p_add">+			{</span>
<span class="p_add">+				.ifnum = 1,</span>
<span class="p_add">+				.type = QUIRK_AUDIO_STANDARD_INTERFACE</span>
<span class="p_add">+			},</span>
<span class="p_add">+			{</span>
<span class="p_add">+				.ifnum = 2,</span>
<span class="p_add">+				.type = QUIRK_AUDIO_STANDARD_INTERFACE</span>
<span class="p_add">+			},</span>
<span class="p_add">+			{</span>
<span class="p_add">+				.ifnum = 3,</span>
<span class="p_add">+				.type = QUIRK_MIDI_FIXED_ENDPOINT,</span>
<span class="p_add">+				.data = &amp;(const struct snd_usb_midi_endpoint_info) {</span>
<span class="p_add">+					.out_cables = 0x0001,</span>
<span class="p_add">+					.in_cables  = 0x0001</span>
<span class="p_add">+				}</span>
<span class="p_add">+			},</span>
<span class="p_add">+			{</span>
<span class="p_add">+				.ifnum = -1</span>
<span class="p_add">+			}</span>
<span class="p_add">+		}</span>
<span class="p_add">+	}</span>
<span class="p_add">+},</span>
<span class="p_add">+</span>
 /* TerraTec devices */
 {
 	USB_DEVICE_VENDOR_SPEC(0x0ccd, 0x0012),

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



