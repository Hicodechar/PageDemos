
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>[tip:x86/boot] x86/mm: Update physical mapping variable names - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    [tip:x86/boot] x86/mm: Update physical mapping variable names</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=60001">tip-bot for Jacob Shin</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>July 8, 2016, 8:34 p.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;tip-59b3d0206d74a700069e49160e8194b2ca93b703@git.kernel.org&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/9221779/mbox/"
   >mbox</a>
|
   <a href="/patch/9221779/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/9221779/">/patch/9221779/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
	[172.30.200.125])
	by pdx-korg-patchwork.web.codeaurora.org (Postfix) with ESMTP id
	53BDC60467 for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Fri,  8 Jul 2016 20:38:14 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 421C7284CF
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Fri,  8 Jul 2016 20:38:14 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id 34B8F284D3; Fri,  8 Jul 2016 20:38:14 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-6.9 required=2.0 tests=BAYES_00,RCVD_IN_DNSWL_HI
	autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 29024284CF
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Fri,  8 Jul 2016 20:38:11 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1756213AbcGHUhy (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Fri, 8 Jul 2016 16:37:54 -0400
Received: from terminus.zytor.com ([198.137.202.10]:35672 &quot;EHLO
	terminus.zytor.com&quot; rhost-flags-OK-OK-OK-OK) by vger.kernel.org
	with ESMTP id S1752120AbcGHUhb (ORCPT
	&lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Fri, 8 Jul 2016 16:37:31 -0400
Received: from terminus.zytor.com (localhost [127.0.0.1])
	by terminus.zytor.com (8.15.2/8.15.2) with ESMTP id u68KYD7S009423;
	Fri, 8 Jul 2016 13:34:13 -0700
Received: (from tipbot@localhost)
	by terminus.zytor.com (8.15.2/8.15.2/Submit) id u68KYC1J009415;
	Fri, 8 Jul 2016 13:34:12 -0700
Date: Fri, 8 Jul 2016 13:34:12 -0700
X-Authentication-Warning: terminus.zytor.com: tipbot set sender to
	tipbot@zytor.com using -f
From: tip-bot for Thomas Garnier &lt;tipbot@zytor.com&gt;
Message-ID: &lt;tip-59b3d0206d74a700069e49160e8194b2ca93b703@git.kernel.org&gt;
Cc: guangrong.xiao@linux.intel.com, toshi.kani@hpe.com,
	dan.j.williams@intel.com, akpm@linux-foundation.org,
	jpoimboe@redhat.com, corbet@lwn.net, brgerst@gmail.com,
	torvalds@linux-foundation.org, alpopov@ptsecurity.com,
	dyoung@redhat.com, bp@alien8.de, luto@kernel.org,
	thgarnie@google.com, tglx@linutronix.de, peterz@infradead.org,
	kuleshovmail@gmail.com, jroedel@suse.de,
	kirill.shutemov@linux.intel.com, boris.ostrovsky@oracle.com,
	msalter@redhat.com, bp@suse.de, matt@codeblueprint.co.uk,
	JBeulich@suse.com, schwidefsky@de.ibm.com, sds@tycho.nsa.gov,
	hpa@zytor.com, linux-kernel@vger.kernel.org,
	borntraeger@de.ibm.com, bhe@redhat.com, mingo@kernel.org,
	keescook@chromium.org, dvyukov@google.com, dvlasenk@redhat.com,
	aneesh.kumar@linux.vnet.ibm.com, yinghai@kernel.org,
	lv.zheng@intel.com, dave.hansen@linux.intel.com, jgross@suse.com
Reply-To: bhe@redhat.com, borntraeger@de.ibm.com,
	linux-kernel@vger.kernel.org, hpa@zytor.com, sds@tycho.nsa.gov,
	schwidefsky@de.ibm.com, JBeulich@suse.com,
	matt@codeblueprint.co.uk, jgross@suse.com,
	dave.hansen@linux.intel.com, lv.zheng@intel.com,
	yinghai@kernel.org, aneesh.kumar@linux.vnet.ibm.com,
	dvlasenk@redhat.com, dvyukov@google.com, keescook@chromium.org,
	mingo@kernel.org, alpopov@ptsecurity.com,
	torvalds@linux-foundation.org, brgerst@gmail.com, corbet@lwn.net,
	jpoimboe@redhat.com, akpm@linux-foundation.org,
	dan.j.williams@intel.com, toshi.kani@hpe.com,
	guangrong.xiao@linux.intel.com, bp@suse.de, msalter@redhat.com,
	boris.ostrovsky@oracle.com, kirill.shutemov@linux.intel.com,
	jroedel@suse.de, kuleshovmail@gmail.com, peterz@infradead.org,
	tglx@linutronix.de, thgarnie@google.com, luto@kernel.org,
	bp@alien8.de, dyoung@redhat.com
In-Reply-To: &lt;1466556426-32664-3-git-send-email-keescook@chromium.org&gt;
References: &lt;1466556426-32664-3-git-send-email-keescook@chromium.org&gt;
To: linux-tip-commits@vger.kernel.org
Subject: [tip:x86/boot] x86/mm: Update physical mapping variable names
Git-Commit-ID: 59b3d0206d74a700069e49160e8194b2ca93b703
X-Mailer: tip-git-log-daemon
Robot-ID: &lt;tip-bot.git.kernel.org&gt;
Robot-Unsubscribe: Contact &lt;mailto:hpa@kernel.org&gt; to get blacklisted from
	these emails
MIME-Version: 1.0
Content-Transfer-Encoding: 8bit
Content-Type: text/plain; charset=UTF-8
Content-Disposition: inline
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=60001">tip-bot for Jacob Shin</a> - July 8, 2016, 8:34 p.m.</div>
<pre class="content">
Commit-ID:  59b3d0206d74a700069e49160e8194b2ca93b703
Gitweb:     http://git.kernel.org/tip/59b3d0206d74a700069e49160e8194b2ca93b703
Author:     Thomas Garnier &lt;thgarnie@google.com&gt;
AuthorDate: Tue, 21 Jun 2016 17:46:59 -0700
Committer:  Ingo Molnar &lt;mingo@kernel.org&gt;
CommitDate: Fri, 8 Jul 2016 17:33:46 +0200

x86/mm: Update physical mapping variable names

Change the variable names in kernel_physical_mapping_init() and related
functions to correctly reflect physical and virtual memory addresses.
Also add comments on each function to describe usage and alignment
constraints.
<span class="signed-off-by">
Signed-off-by: Thomas Garnier &lt;thgarnie@google.com&gt;</span>
<span class="signed-off-by">Signed-off-by: Kees Cook &lt;keescook@chromium.org&gt;</span>
Cc: Alexander Kuleshov &lt;kuleshovmail@gmail.com&gt;
Cc: Alexander Popov &lt;alpopov@ptsecurity.com&gt;
Cc: Andrew Morton &lt;akpm@linux-foundation.org&gt;
Cc: Andy Lutomirski &lt;luto@kernel.org&gt;
Cc: Aneesh Kumar K.V &lt;aneesh.kumar@linux.vnet.ibm.com&gt;
Cc: Baoquan He &lt;bhe@redhat.com&gt;
Cc: Boris Ostrovsky &lt;boris.ostrovsky@oracle.com&gt;
Cc: Borislav Petkov &lt;bp@alien8.de&gt;
Cc: Borislav Petkov &lt;bp@suse.de&gt;
Cc: Brian Gerst &lt;brgerst@gmail.com&gt;
Cc: Christian Borntraeger &lt;borntraeger@de.ibm.com&gt;
Cc: Dan Williams &lt;dan.j.williams@intel.com&gt;
Cc: Dave Hansen &lt;dave.hansen@linux.intel.com&gt;
Cc: Dave Young &lt;dyoung@redhat.com&gt;
Cc: Denys Vlasenko &lt;dvlasenk@redhat.com&gt;
Cc: Dmitry Vyukov &lt;dvyukov@google.com&gt;
Cc: H. Peter Anvin &lt;hpa@zytor.com&gt;
Cc: Jan Beulich &lt;JBeulich@suse.com&gt;
Cc: Joerg Roedel &lt;jroedel@suse.de&gt;
Cc: Jonathan Corbet &lt;corbet@lwn.net&gt;
Cc: Josh Poimboeuf &lt;jpoimboe@redhat.com&gt;
Cc: Juergen Gross &lt;jgross@suse.com&gt;
Cc: Kirill A. Shutemov &lt;kirill.shutemov@linux.intel.com&gt;
Cc: Linus Torvalds &lt;torvalds@linux-foundation.org&gt;
Cc: Lv Zheng &lt;lv.zheng@intel.com&gt;
Cc: Mark Salter &lt;msalter@redhat.com&gt;
Cc: Martin Schwidefsky &lt;schwidefsky@de.ibm.com&gt;
Cc: Matt Fleming &lt;matt@codeblueprint.co.uk&gt;
Cc: Peter Zijlstra &lt;peterz@infradead.org&gt;
Cc: Stephen Smalley &lt;sds@tycho.nsa.gov&gt;
Cc: Thomas Gleixner &lt;tglx@linutronix.de&gt;
Cc: Toshi Kani &lt;toshi.kani@hpe.com&gt;
Cc: Xiao Guangrong &lt;guangrong.xiao@linux.intel.com&gt;
Cc: Yinghai Lu &lt;yinghai@kernel.org&gt;
Cc: kernel-hardening@lists.openwall.com
Cc: linux-doc@vger.kernel.org
Link: http://lkml.kernel.org/r/1466556426-32664-3-git-send-email-keescook@chromium.org
<span class="signed-off-by">Signed-off-by: Ingo Molnar &lt;mingo@kernel.org&gt;</span>
---
 arch/x86/mm/init_64.c | 162 ++++++++++++++++++++++++++++++--------------------
 1 file changed, 96 insertions(+), 66 deletions(-)
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/arch/x86/mm/init_64.c b/arch/x86/mm/init_64.c</span>
<span class="p_header">index bce2e5d..6714712 100644</span>
<span class="p_header">--- a/arch/x86/mm/init_64.c</span>
<span class="p_header">+++ b/arch/x86/mm/init_64.c</span>
<span class="p_chunk">@@ -328,22 +328,30 @@</span> <span class="p_context"> void __init cleanup_highmap(void)</span>
 	}
 }
 
<span class="p_add">+/*</span>
<span class="p_add">+ * Create PTE level page table mapping for physical addresses.</span>
<span class="p_add">+ * It returns the last physical address mapped.</span>
<span class="p_add">+ */</span>
 static unsigned long __meminit
<span class="p_del">-phys_pte_init(pte_t *pte_page, unsigned long addr, unsigned long end,</span>
<span class="p_add">+phys_pte_init(pte_t *pte_page, unsigned long paddr, unsigned long paddr_end,</span>
 	      pgprot_t prot)
 {
<span class="p_del">-	unsigned long pages = 0, next;</span>
<span class="p_del">-	unsigned long last_map_addr = end;</span>
<span class="p_add">+	unsigned long pages = 0, paddr_next;</span>
<span class="p_add">+	unsigned long paddr_last = paddr_end;</span>
<span class="p_add">+	pte_t *pte;</span>
 	int i;
 
<span class="p_del">-	pte_t *pte = pte_page + pte_index(addr);</span>
<span class="p_add">+	pte = pte_page + pte_index(paddr);</span>
<span class="p_add">+	i = pte_index(paddr);</span>
 
<span class="p_del">-	for (i = pte_index(addr); i &lt; PTRS_PER_PTE; i++, addr = next, pte++) {</span>
<span class="p_del">-		next = (addr &amp; PAGE_MASK) + PAGE_SIZE;</span>
<span class="p_del">-		if (addr &gt;= end) {</span>
<span class="p_add">+	for (; i &lt; PTRS_PER_PTE; i++, paddr = paddr_next, pte++) {</span>
<span class="p_add">+		paddr_next = (paddr &amp; PAGE_MASK) + PAGE_SIZE;</span>
<span class="p_add">+		if (paddr &gt;= paddr_end) {</span>
 			if (!after_bootmem &amp;&amp;
<span class="p_del">-			    !e820_any_mapped(addr &amp; PAGE_MASK, next, E820_RAM) &amp;&amp;</span>
<span class="p_del">-			    !e820_any_mapped(addr &amp; PAGE_MASK, next, E820_RESERVED_KERN))</span>
<span class="p_add">+			    !e820_any_mapped(paddr &amp; PAGE_MASK, paddr_next,</span>
<span class="p_add">+					     E820_RAM) &amp;&amp;</span>
<span class="p_add">+			    !e820_any_mapped(paddr &amp; PAGE_MASK, paddr_next,</span>
<span class="p_add">+					     E820_RESERVED_KERN))</span>
 				set_pte(pte, __pte(0));
 			continue;
 		}
<span class="p_chunk">@@ -361,37 +369,44 @@</span> <span class="p_context"> phys_pte_init(pte_t *pte_page, unsigned long addr, unsigned long end,</span>
 		}
 
 		if (0)
<span class="p_del">-			printk(&quot;   pte=%p addr=%lx pte=%016lx\n&quot;,</span>
<span class="p_del">-			       pte, addr, pfn_pte(addr &gt;&gt; PAGE_SHIFT, PAGE_KERNEL).pte);</span>
<span class="p_add">+			pr_info(&quot;   pte=%p addr=%lx pte=%016lx\n&quot;, pte, paddr,</span>
<span class="p_add">+				pfn_pte(paddr &gt;&gt; PAGE_SHIFT, PAGE_KERNEL).pte);</span>
 		pages++;
<span class="p_del">-		set_pte(pte, pfn_pte(addr &gt;&gt; PAGE_SHIFT, prot));</span>
<span class="p_del">-		last_map_addr = (addr &amp; PAGE_MASK) + PAGE_SIZE;</span>
<span class="p_add">+		set_pte(pte, pfn_pte(paddr &gt;&gt; PAGE_SHIFT, prot));</span>
<span class="p_add">+		paddr_last = (paddr &amp; PAGE_MASK) + PAGE_SIZE;</span>
 	}
 
 	update_page_count(PG_LEVEL_4K, pages);
 
<span class="p_del">-	return last_map_addr;</span>
<span class="p_add">+	return paddr_last;</span>
 }
 
<span class="p_add">+/*</span>
<span class="p_add">+ * Create PMD level page table mapping for physical addresses. The virtual</span>
<span class="p_add">+ * and physical address have to be aligned at this level.</span>
<span class="p_add">+ * It returns the last physical address mapped.</span>
<span class="p_add">+ */</span>
 static unsigned long __meminit
<span class="p_del">-phys_pmd_init(pmd_t *pmd_page, unsigned long address, unsigned long end,</span>
<span class="p_add">+phys_pmd_init(pmd_t *pmd_page, unsigned long paddr, unsigned long paddr_end,</span>
 	      unsigned long page_size_mask, pgprot_t prot)
 {
<span class="p_del">-	unsigned long pages = 0, next;</span>
<span class="p_del">-	unsigned long last_map_addr = end;</span>
<span class="p_add">+	unsigned long pages = 0, paddr_next;</span>
<span class="p_add">+	unsigned long paddr_last = paddr_end;</span>
 
<span class="p_del">-	int i = pmd_index(address);</span>
<span class="p_add">+	int i = pmd_index(paddr);</span>
 
<span class="p_del">-	for (; i &lt; PTRS_PER_PMD; i++, address = next) {</span>
<span class="p_del">-		pmd_t *pmd = pmd_page + pmd_index(address);</span>
<span class="p_add">+	for (; i &lt; PTRS_PER_PMD; i++, paddr = paddr_next) {</span>
<span class="p_add">+		pmd_t *pmd = pmd_page + pmd_index(paddr);</span>
 		pte_t *pte;
 		pgprot_t new_prot = prot;
 
<span class="p_del">-		next = (address &amp; PMD_MASK) + PMD_SIZE;</span>
<span class="p_del">-		if (address &gt;= end) {</span>
<span class="p_add">+		paddr_next = (paddr &amp; PMD_MASK) + PMD_SIZE;</span>
<span class="p_add">+		if (paddr &gt;= paddr_end) {</span>
 			if (!after_bootmem &amp;&amp;
<span class="p_del">-			    !e820_any_mapped(address &amp; PMD_MASK, next, E820_RAM) &amp;&amp;</span>
<span class="p_del">-			    !e820_any_mapped(address &amp; PMD_MASK, next, E820_RESERVED_KERN))</span>
<span class="p_add">+			    !e820_any_mapped(paddr &amp; PMD_MASK, paddr_next,</span>
<span class="p_add">+					     E820_RAM) &amp;&amp;</span>
<span class="p_add">+			    !e820_any_mapped(paddr &amp; PMD_MASK, paddr_next,</span>
<span class="p_add">+					     E820_RESERVED_KERN))</span>
 				set_pmd(pmd, __pmd(0));
 			continue;
 		}
<span class="p_chunk">@@ -400,8 +415,8 @@</span> <span class="p_context"> phys_pmd_init(pmd_t *pmd_page, unsigned long address, unsigned long end,</span>
 			if (!pmd_large(*pmd)) {
 				spin_lock(&amp;init_mm.page_table_lock);
 				pte = (pte_t *)pmd_page_vaddr(*pmd);
<span class="p_del">-				last_map_addr = phys_pte_init(pte, address,</span>
<span class="p_del">-								end, prot);</span>
<span class="p_add">+				paddr_last = phys_pte_init(pte, paddr,</span>
<span class="p_add">+							   paddr_end, prot);</span>
 				spin_unlock(&amp;init_mm.page_table_lock);
 				continue;
 			}
<span class="p_chunk">@@ -420,7 +435,7 @@</span> <span class="p_context"> phys_pmd_init(pmd_t *pmd_page, unsigned long address, unsigned long end,</span>
 			if (page_size_mask &amp; (1 &lt;&lt; PG_LEVEL_2M)) {
 				if (!after_bootmem)
 					pages++;
<span class="p_del">-				last_map_addr = next;</span>
<span class="p_add">+				paddr_last = paddr_next;</span>
 				continue;
 			}
 			new_prot = pte_pgprot(pte_clrhuge(*(pte_t *)pmd));
<span class="p_chunk">@@ -430,42 +445,49 @@</span> <span class="p_context"> phys_pmd_init(pmd_t *pmd_page, unsigned long address, unsigned long end,</span>
 			pages++;
 			spin_lock(&amp;init_mm.page_table_lock);
 			set_pte((pte_t *)pmd,
<span class="p_del">-				pfn_pte((address &amp; PMD_MASK) &gt;&gt; PAGE_SHIFT,</span>
<span class="p_add">+				pfn_pte((paddr &amp; PMD_MASK) &gt;&gt; PAGE_SHIFT,</span>
 					__pgprot(pgprot_val(prot) | _PAGE_PSE)));
 			spin_unlock(&amp;init_mm.page_table_lock);
<span class="p_del">-			last_map_addr = next;</span>
<span class="p_add">+			paddr_last = paddr_next;</span>
 			continue;
 		}
 
 		pte = alloc_low_page();
<span class="p_del">-		last_map_addr = phys_pte_init(pte, address, end, new_prot);</span>
<span class="p_add">+		paddr_last = phys_pte_init(pte, paddr, paddr_end, new_prot);</span>
 
 		spin_lock(&amp;init_mm.page_table_lock);
 		pmd_populate_kernel(&amp;init_mm, pmd, pte);
 		spin_unlock(&amp;init_mm.page_table_lock);
 	}
 	update_page_count(PG_LEVEL_2M, pages);
<span class="p_del">-	return last_map_addr;</span>
<span class="p_add">+	return paddr_last;</span>
 }
 
<span class="p_add">+/*</span>
<span class="p_add">+ * Create PUD level page table mapping for physical addresses. The virtual</span>
<span class="p_add">+ * and physical address have to be aligned at this level.</span>
<span class="p_add">+ * It returns the last physical address mapped.</span>
<span class="p_add">+ */</span>
 static unsigned long __meminit
<span class="p_del">-phys_pud_init(pud_t *pud_page, unsigned long addr, unsigned long end,</span>
<span class="p_del">-			 unsigned long page_size_mask)</span>
<span class="p_add">+phys_pud_init(pud_t *pud_page, unsigned long paddr, unsigned long paddr_end,</span>
<span class="p_add">+	      unsigned long page_size_mask)</span>
 {
<span class="p_del">-	unsigned long pages = 0, next;</span>
<span class="p_del">-	unsigned long last_map_addr = end;</span>
<span class="p_del">-	int i = pud_index(addr);</span>
<span class="p_add">+	unsigned long pages = 0, paddr_next;</span>
<span class="p_add">+	unsigned long paddr_last = paddr_end;</span>
<span class="p_add">+	int i = pud_index(paddr);</span>
 
<span class="p_del">-	for (; i &lt; PTRS_PER_PUD; i++, addr = next) {</span>
<span class="p_del">-		pud_t *pud = pud_page + pud_index(addr);</span>
<span class="p_add">+	for (; i &lt; PTRS_PER_PUD; i++, paddr = paddr_next) {</span>
<span class="p_add">+		pud_t *pud = pud_page + pud_index(paddr);</span>
 		pmd_t *pmd;
 		pgprot_t prot = PAGE_KERNEL;
 
<span class="p_del">-		next = (addr &amp; PUD_MASK) + PUD_SIZE;</span>
<span class="p_del">-		if (addr &gt;= end) {</span>
<span class="p_add">+		paddr_next = (paddr &amp; PUD_MASK) + PUD_SIZE;</span>
<span class="p_add">+		if (paddr &gt;= paddr_end) {</span>
 			if (!after_bootmem &amp;&amp;
<span class="p_del">-			    !e820_any_mapped(addr &amp; PUD_MASK, next, E820_RAM) &amp;&amp;</span>
<span class="p_del">-			    !e820_any_mapped(addr &amp; PUD_MASK, next, E820_RESERVED_KERN))</span>
<span class="p_add">+			    !e820_any_mapped(paddr &amp; PUD_MASK, paddr_next,</span>
<span class="p_add">+					     E820_RAM) &amp;&amp;</span>
<span class="p_add">+			    !e820_any_mapped(paddr &amp; PUD_MASK, paddr_next,</span>
<span class="p_add">+					     E820_RESERVED_KERN))</span>
 				set_pud(pud, __pud(0));
 			continue;
 		}
<span class="p_chunk">@@ -473,8 +495,10 @@</span> <span class="p_context"> phys_pud_init(pud_t *pud_page, unsigned long addr, unsigned long end,</span>
 		if (pud_val(*pud)) {
 			if (!pud_large(*pud)) {
 				pmd = pmd_offset(pud, 0);
<span class="p_del">-				last_map_addr = phys_pmd_init(pmd, addr, end,</span>
<span class="p_del">-							 page_size_mask, prot);</span>
<span class="p_add">+				paddr_last = phys_pmd_init(pmd, paddr,</span>
<span class="p_add">+							   paddr_end,</span>
<span class="p_add">+							   page_size_mask,</span>
<span class="p_add">+							   prot);</span>
 				__flush_tlb_all();
 				continue;
 			}
<span class="p_chunk">@@ -493,7 +517,7 @@</span> <span class="p_context"> phys_pud_init(pud_t *pud_page, unsigned long addr, unsigned long end,</span>
 			if (page_size_mask &amp; (1 &lt;&lt; PG_LEVEL_1G)) {
 				if (!after_bootmem)
 					pages++;
<span class="p_del">-				last_map_addr = next;</span>
<span class="p_add">+				paddr_last = paddr_next;</span>
 				continue;
 			}
 			prot = pte_pgprot(pte_clrhuge(*(pte_t *)pud));
<span class="p_chunk">@@ -503,16 +527,16 @@</span> <span class="p_context"> phys_pud_init(pud_t *pud_page, unsigned long addr, unsigned long end,</span>
 			pages++;
 			spin_lock(&amp;init_mm.page_table_lock);
 			set_pte((pte_t *)pud,
<span class="p_del">-				pfn_pte((addr &amp; PUD_MASK) &gt;&gt; PAGE_SHIFT,</span>
<span class="p_add">+				pfn_pte((paddr &amp; PUD_MASK) &gt;&gt; PAGE_SHIFT,</span>
 					PAGE_KERNEL_LARGE));
 			spin_unlock(&amp;init_mm.page_table_lock);
<span class="p_del">-			last_map_addr = next;</span>
<span class="p_add">+			paddr_last = paddr_next;</span>
 			continue;
 		}
 
 		pmd = alloc_low_page();
<span class="p_del">-		last_map_addr = phys_pmd_init(pmd, addr, end, page_size_mask,</span>
<span class="p_del">-					      prot);</span>
<span class="p_add">+		paddr_last = phys_pmd_init(pmd, paddr, paddr_end,</span>
<span class="p_add">+					   page_size_mask, prot);</span>
 
 		spin_lock(&amp;init_mm.page_table_lock);
 		pud_populate(&amp;init_mm, pud, pmd);
<span class="p_chunk">@@ -522,38 +546,44 @@</span> <span class="p_context"> phys_pud_init(pud_t *pud_page, unsigned long addr, unsigned long end,</span>
 
 	update_page_count(PG_LEVEL_1G, pages);
 
<span class="p_del">-	return last_map_addr;</span>
<span class="p_add">+	return paddr_last;</span>
 }
 
<span class="p_add">+/*</span>
<span class="p_add">+ * Create page table mapping for the physical memory for specific physical</span>
<span class="p_add">+ * addresses. The virtual and physical addresses have to be aligned on PUD level</span>
<span class="p_add">+ * down. It returns the last physical address mapped.</span>
<span class="p_add">+ */</span>
 unsigned long __meminit
<span class="p_del">-kernel_physical_mapping_init(unsigned long start,</span>
<span class="p_del">-			     unsigned long end,</span>
<span class="p_add">+kernel_physical_mapping_init(unsigned long paddr_start,</span>
<span class="p_add">+			     unsigned long paddr_end,</span>
 			     unsigned long page_size_mask)
 {
 	bool pgd_changed = false;
<span class="p_del">-	unsigned long next, last_map_addr = end;</span>
<span class="p_del">-	unsigned long addr;</span>
<span class="p_add">+	unsigned long vaddr, vaddr_start, vaddr_end, vaddr_next, paddr_last;</span>
 
<span class="p_del">-	start = (unsigned long)__va(start);</span>
<span class="p_del">-	end = (unsigned long)__va(end);</span>
<span class="p_del">-	addr = start;</span>
<span class="p_add">+	paddr_last = paddr_end;</span>
<span class="p_add">+	vaddr = (unsigned long)__va(paddr_start);</span>
<span class="p_add">+	vaddr_end = (unsigned long)__va(paddr_end);</span>
<span class="p_add">+	vaddr_start = vaddr;</span>
 
<span class="p_del">-	for (; start &lt; end; start = next) {</span>
<span class="p_del">-		pgd_t *pgd = pgd_offset_k(start);</span>
<span class="p_add">+	for (; vaddr &lt; vaddr_end; vaddr = vaddr_next) {</span>
<span class="p_add">+		pgd_t *pgd = pgd_offset_k(vaddr);</span>
 		pud_t *pud;
 
<span class="p_del">-		next = (start &amp; PGDIR_MASK) + PGDIR_SIZE;</span>
<span class="p_add">+		vaddr_next = (vaddr &amp; PGDIR_MASK) + PGDIR_SIZE;</span>
 
 		if (pgd_val(*pgd)) {
 			pud = (pud_t *)pgd_page_vaddr(*pgd);
<span class="p_del">-			last_map_addr = phys_pud_init(pud, __pa(start),</span>
<span class="p_del">-						 __pa(end), page_size_mask);</span>
<span class="p_add">+			paddr_last = phys_pud_init(pud, __pa(vaddr),</span>
<span class="p_add">+						   __pa(vaddr_end),</span>
<span class="p_add">+						   page_size_mask);</span>
 			continue;
 		}
 
 		pud = alloc_low_page();
<span class="p_del">-		last_map_addr = phys_pud_init(pud, __pa(start), __pa(end),</span>
<span class="p_del">-						 page_size_mask);</span>
<span class="p_add">+		paddr_last = phys_pud_init(pud, __pa(vaddr), __pa(vaddr_end),</span>
<span class="p_add">+					   page_size_mask);</span>
 
 		spin_lock(&amp;init_mm.page_table_lock);
 		pgd_populate(&amp;init_mm, pgd, pud);
<span class="p_chunk">@@ -562,11 +592,11 @@</span> <span class="p_context"> kernel_physical_mapping_init(unsigned long start,</span>
 	}
 
 	if (pgd_changed)
<span class="p_del">-		sync_global_pgds(addr, end - 1, 0);</span>
<span class="p_add">+		sync_global_pgds(vaddr_start, vaddr_end - 1, 0);</span>
 
 	__flush_tlb_all();
 
<span class="p_del">-	return last_map_addr;</span>
<span class="p_add">+	return paddr_last;</span>
 }
 
 #ifndef CONFIG_NUMA

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



