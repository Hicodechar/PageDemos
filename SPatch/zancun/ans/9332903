
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>Linux 4.4.21 - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    Linux 4.4.21</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=37061">gregkh@linuxfoundation.org</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>Sept. 15, 2016, 7:32 a.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;20160915073249.GB2931@kroah.com&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/9332903/mbox/"
   >mbox</a>
|
   <a href="/patch/9332903/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/9332903/">/patch/9332903/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
	[172.30.200.125])
	by pdx-korg-patchwork.web.codeaurora.org (Postfix) with ESMTP id
	576DE6077F for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Thu, 15 Sep 2016 07:35:50 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 2CA84292A1
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Thu, 15 Sep 2016 07:35:50 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id 1848229355; Thu, 15 Sep 2016 07:35:50 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-6.9 required=2.0 tests=BAYES_00, RCVD_IN_DNSWL_HI, 
	TVD_PH_BODY_ACCOUNTS_PRE autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id A8DA8292A1
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Thu, 15 Sep 2016 07:35:34 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S934075AbcIOHdg (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Thu, 15 Sep 2016 03:33:36 -0400
Received: from mail.linuxfoundation.org ([140.211.169.12]:49560 &quot;EHLO
	mail.linuxfoundation.org&quot; rhost-flags-OK-OK-OK-OK) by vger.kernel.org
	with ESMTP id S933592AbcIOHcq (ORCPT
	&lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Thu, 15 Sep 2016 03:32:46 -0400
Received: from localhost (pes75-3-78-192-101-3.fbxo.proxad.net
	[78.192.101.3])
	by mail.linuxfoundation.org (Postfix) with ESMTPSA id 6010C26C;
	Thu, 15 Sep 2016 07:32:43 +0000 (UTC)
Date: Thu, 15 Sep 2016 09:32:49 +0200
From: Greg KH &lt;gregkh@linuxfoundation.org&gt;
To: linux-kernel@vger.kernel.org, Andrew Morton &lt;akpm@linux-foundation.org&gt;,
	torvalds@linux-foundation.org, stable@vger.kernel.org
Cc: lwn@lwn.net, Jiri Slaby &lt;jslaby@suse.cz&gt;
Subject: Re: Linux 4.4.21
Message-ID: &lt;20160915073249.GB2931@kroah.com&gt;
References: &lt;20160915073241.GA2931@kroah.com&gt;
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Disposition: inline
In-Reply-To: &lt;20160915073241.GA2931@kroah.com&gt;
User-Agent: Mutt/1.7.0 (2016-08-17)
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=37061">gregkh@linuxfoundation.org</a> - Sept. 15, 2016, 7:32 a.m.</div>
<pre class="content">

</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/Documentation/filesystems/proc.txt b/Documentation/filesystems/proc.txt</span>
<span class="p_header">index 402ab99e409f..6716413c17ba 100644</span>
<span class="p_header">--- a/Documentation/filesystems/proc.txt</span>
<span class="p_header">+++ b/Documentation/filesystems/proc.txt</span>
<span class="p_chunk">@@ -346,7 +346,7 @@</span> <span class="p_context"> address           perms offset  dev   inode      pathname</span>
 a7cb1000-a7cb2000 ---p 00000000 00:00 0
 a7cb2000-a7eb2000 rw-p 00000000 00:00 0
 a7eb2000-a7eb3000 ---p 00000000 00:00 0
<span class="p_del">-a7eb3000-a7ed5000 rw-p 00000000 00:00 0          [stack:1001]</span>
<span class="p_add">+a7eb3000-a7ed5000 rw-p 00000000 00:00 0</span>
 a7ed5000-a8008000 r-xp 00000000 03:00 4222       /lib/libc.so.6
 a8008000-a800a000 r--p 00133000 03:00 4222       /lib/libc.so.6
 a800a000-a800b000 rw-p 00135000 03:00 4222       /lib/libc.so.6
<span class="p_chunk">@@ -378,7 +378,6 @@</span> <span class="p_context"> is not associated with a file:</span>
 
  [heap]                   = the heap of the program
  [stack]                  = the stack of the main process
<span class="p_del">- [stack:1001]             = the stack of the thread with tid 1001</span>
  [vdso]                   = the &quot;virtual dynamic shared object&quot;,
                             the kernel system call handler
 
<span class="p_chunk">@@ -386,10 +385,8 @@</span> <span class="p_context"> is not associated with a file:</span>
 
 The /proc/PID/task/TID/maps is a view of the virtual memory from the viewpoint
 of the individual tasks of a process. In this file you will see a mapping marked
<span class="p_del">-as [stack] if that task sees it as a stack. This is a key difference from the</span>
<span class="p_del">-content of /proc/PID/maps, where you will see all mappings that are being used</span>
<span class="p_del">-as stack by all of those tasks. Hence, for the example above, the task-level</span>
<span class="p_del">-map, i.e. /proc/PID/task/TID/maps for thread 1001 will look like this:</span>
<span class="p_add">+as [stack] if that task sees it as a stack. Hence, for the example above, the</span>
<span class="p_add">+task-level map, i.e. /proc/PID/task/TID/maps for thread 1001 will look like this:</span>
 
 08048000-08049000 r-xp 00000000 03:00 8312       /opt/test
 08049000-0804a000 rw-p 00001000 03:00 8312       /opt/test
<span class="p_header">diff --git a/Makefile b/Makefile</span>
<span class="p_header">index b74d60081a16..d1cc9e0b7473 100644</span>
<span class="p_header">--- a/Makefile</span>
<span class="p_header">+++ b/Makefile</span>
<span class="p_chunk">@@ -1,6 +1,6 @@</span> <span class="p_context"></span>
 VERSION = 4
 PATCHLEVEL = 4
<span class="p_del">-SUBLEVEL = 20</span>
<span class="p_add">+SUBLEVEL = 21</span>
 EXTRAVERSION =
 NAME = Blurry Fish Butt
 
<span class="p_header">diff --git a/arch/arm64/Kconfig b/arch/arm64/Kconfig</span>
<span class="p_header">index 871f21783866..14cdc6dea493 100644</span>
<span class="p_header">--- a/arch/arm64/Kconfig</span>
<span class="p_header">+++ b/arch/arm64/Kconfig</span>
<span class="p_chunk">@@ -391,6 +391,15 @@</span> <span class="p_context"> config CAVIUM_ERRATUM_22375</span>
 
 	  If unsure, say Y.
 
<span class="p_add">+config CAVIUM_ERRATUM_23144</span>
<span class="p_add">+	bool &quot;Cavium erratum 23144: ITS SYNC hang on dual socket system&quot;</span>
<span class="p_add">+	depends on NUMA</span>
<span class="p_add">+	default y</span>
<span class="p_add">+	help</span>
<span class="p_add">+	  ITS SYNC command hang for cross node io and collections/cpu mapping.</span>
<span class="p_add">+</span>
<span class="p_add">+	  If unsure, say Y.</span>
<span class="p_add">+</span>
 config CAVIUM_ERRATUM_23154
 	bool &quot;Cavium erratum 23154: Access to ICC_IAR1_EL1 is not sync&#39;ed&quot;
 	default y
<span class="p_chunk">@@ -401,6 +410,17 @@</span> <span class="p_context"> config CAVIUM_ERRATUM_23154</span>
 
 	  If unsure, say Y.
 
<span class="p_add">+config CAVIUM_ERRATUM_27456</span>
<span class="p_add">+	bool &quot;Cavium erratum 27456: Broadcast TLBI instructions may cause icache corruption&quot;</span>
<span class="p_add">+	default y</span>
<span class="p_add">+	help</span>
<span class="p_add">+	  On ThunderX T88 pass 1.x through 2.1 parts, broadcast TLBI</span>
<span class="p_add">+	  instructions may cause the icache to become corrupted if it</span>
<span class="p_add">+	  contains data for a non-current ASID.  The fix is to</span>
<span class="p_add">+	  invalidate the icache when changing the mm context.</span>
<span class="p_add">+</span>
<span class="p_add">+	  If unsure, say Y.</span>
<span class="p_add">+</span>
 endmenu
 
 
<span class="p_header">diff --git a/arch/arm64/include/asm/arch_gicv3.h b/arch/arm64/include/asm/arch_gicv3.h</span>
<span class="p_header">index 2731d3b25ed2..8ec88e5b290f 100644</span>
<span class="p_header">--- a/arch/arm64/include/asm/arch_gicv3.h</span>
<span class="p_header">+++ b/arch/arm64/include/asm/arch_gicv3.h</span>
<span class="p_chunk">@@ -103,6 +103,7 @@</span> <span class="p_context"> static inline u64 gic_read_iar_common(void)</span>
 	u64 irqstat;
 
 	asm volatile(&quot;mrs_s %0, &quot; __stringify(ICC_IAR1_EL1) : &quot;=r&quot; (irqstat));
<span class="p_add">+	dsb(sy);</span>
 	return irqstat;
 }
 
<span class="p_header">diff --git a/arch/arm64/include/asm/cpufeature.h b/arch/arm64/include/asm/cpufeature.h</span>
<span class="p_header">index 8f271b83f910..8136afc9df0d 100644</span>
<span class="p_header">--- a/arch/arm64/include/asm/cpufeature.h</span>
<span class="p_header">+++ b/arch/arm64/include/asm/cpufeature.h</span>
<span class="p_chunk">@@ -30,8 +30,9 @@</span> <span class="p_context"></span>
 #define ARM64_HAS_LSE_ATOMICS			5
 #define ARM64_WORKAROUND_CAVIUM_23154		6
 #define ARM64_WORKAROUND_834220			7
<span class="p_add">+#define ARM64_WORKAROUND_CAVIUM_27456		8</span>
 
<span class="p_del">-#define ARM64_NCAPS				8</span>
<span class="p_add">+#define ARM64_NCAPS				9</span>
 
 #ifndef __ASSEMBLY__
 
<span class="p_header">diff --git a/arch/arm64/include/asm/kvm_arm.h b/arch/arm64/include/asm/kvm_arm.h</span>
<span class="p_header">index 5e6857b6bdc4..2d960f8588b0 100644</span>
<span class="p_header">--- a/arch/arm64/include/asm/kvm_arm.h</span>
<span class="p_header">+++ b/arch/arm64/include/asm/kvm_arm.h</span>
<span class="p_chunk">@@ -107,8 +107,6 @@</span> <span class="p_context"></span>
 #define TCR_EL2_MASK	(TCR_EL2_TG0 | TCR_EL2_SH0 | \
 			 TCR_EL2_ORGN0 | TCR_EL2_IRGN0 | TCR_EL2_T0SZ)
 
<span class="p_del">-#define TCR_EL2_FLAGS	(TCR_EL2_RES1 | TCR_EL2_PS_40B)</span>
<span class="p_del">-</span>
 /* VTCR_EL2 Registers bits */
 #define VTCR_EL2_RES1		(1 &lt;&lt; 31)
 #define VTCR_EL2_PS_MASK	(7 &lt;&lt; 16)
<span class="p_header">diff --git a/arch/arm64/kernel/cpu_errata.c b/arch/arm64/kernel/cpu_errata.c</span>
<span class="p_header">index feb6b4efa641..a3e846a28b05 100644</span>
<span class="p_header">--- a/arch/arm64/kernel/cpu_errata.c</span>
<span class="p_header">+++ b/arch/arm64/kernel/cpu_errata.c</span>
<span class="p_chunk">@@ -100,6 +100,15 @@</span> <span class="p_context"> const struct arm64_cpu_capabilities arm64_errata[] = {</span>
 		MIDR_RANGE(MIDR_THUNDERX, 0x00, 0x01),
 	},
 #endif
<span class="p_add">+#ifdef CONFIG_CAVIUM_ERRATUM_27456</span>
<span class="p_add">+	{</span>
<span class="p_add">+	/* Cavium ThunderX, T88 pass 1.x - 2.1 */</span>
<span class="p_add">+		.desc = &quot;Cavium erratum 27456&quot;,</span>
<span class="p_add">+		.capability = ARM64_WORKAROUND_CAVIUM_27456,</span>
<span class="p_add">+		MIDR_RANGE(MIDR_THUNDERX, 0x00,</span>
<span class="p_add">+			   (1 &lt;&lt; MIDR_VARIANT_SHIFT) | 1),</span>
<span class="p_add">+	},</span>
<span class="p_add">+#endif</span>
 	{
 	}
 };
<span class="p_header">diff --git a/arch/arm64/kvm/hyp-init.S b/arch/arm64/kvm/hyp-init.S</span>
<span class="p_header">index 178ba2248a98..84c338f017b2 100644</span>
<span class="p_header">--- a/arch/arm64/kvm/hyp-init.S</span>
<span class="p_header">+++ b/arch/arm64/kvm/hyp-init.S</span>
<span class="p_chunk">@@ -64,7 +64,7 @@</span> <span class="p_context"> __do_hyp_init:</span>
 	mrs	x4, tcr_el1
 	ldr	x5, =TCR_EL2_MASK
 	and	x4, x4, x5
<span class="p_del">-	ldr	x5, =TCR_EL2_FLAGS</span>
<span class="p_add">+	mov	x5, #TCR_EL2_RES1</span>
 	orr	x4, x4, x5
 
 #ifndef CONFIG_ARM64_VA_BITS_48
<span class="p_chunk">@@ -85,15 +85,18 @@</span> <span class="p_context"> __do_hyp_init:</span>
 	ldr_l	x5, idmap_t0sz
 	bfi	x4, x5, TCR_T0SZ_OFFSET, TCR_TxSZ_WIDTH
 #endif
<span class="p_del">-	msr	tcr_el2, x4</span>
<span class="p_del">-</span>
<span class="p_del">-	ldr	x4, =VTCR_EL2_FLAGS</span>
 	/*
 	 * Read the PARange bits from ID_AA64MMFR0_EL1 and set the PS bits in
<span class="p_del">-	 * VTCR_EL2.</span>
<span class="p_add">+	 * TCR_EL2 and VTCR_EL2.</span>
 	 */
 	mrs	x5, ID_AA64MMFR0_EL1
 	bfi	x4, x5, #16, #3
<span class="p_add">+</span>
<span class="p_add">+	msr	tcr_el2, x4</span>
<span class="p_add">+</span>
<span class="p_add">+	ldr	x4, =VTCR_EL2_FLAGS</span>
<span class="p_add">+	bfi	x4, x5, #16, #3</span>
<span class="p_add">+</span>
 	msr	vtcr_el2, x4
 
 	mrs	x4, mair_el1
<span class="p_header">diff --git a/arch/arm64/mm/proc.S b/arch/arm64/mm/proc.S</span>
<span class="p_header">index 1f6bb29ca53b..18201e9e8cc7 100644</span>
<span class="p_header">--- a/arch/arm64/mm/proc.S</span>
<span class="p_header">+++ b/arch/arm64/mm/proc.S</span>
<span class="p_chunk">@@ -25,6 +25,8 @@</span> <span class="p_context"></span>
 #include &lt;asm/hwcap.h&gt;
 #include &lt;asm/pgtable-hwdef.h&gt;
 #include &lt;asm/pgtable.h&gt;
<span class="p_add">+#include &lt;asm/cpufeature.h&gt;</span>
<span class="p_add">+#include &lt;asm/alternative.h&gt;</span>
 
 #include &quot;proc-macros.S&quot;
 
<span class="p_chunk">@@ -137,7 +139,17 @@</span> <span class="p_context"> ENTRY(cpu_do_switch_mm)</span>
 	bfi	x0, x1, #48, #16		// set the ASID
 	msr	ttbr0_el1, x0			// set TTBR0
 	isb
<span class="p_add">+alternative_if_not ARM64_WORKAROUND_CAVIUM_27456</span>
 	ret
<span class="p_add">+	nop</span>
<span class="p_add">+	nop</span>
<span class="p_add">+	nop</span>
<span class="p_add">+alternative_else</span>
<span class="p_add">+	ic	iallu</span>
<span class="p_add">+	dsb	nsh</span>
<span class="p_add">+	isb</span>
<span class="p_add">+	ret</span>
<span class="p_add">+alternative_endif</span>
 ENDPROC(cpu_do_switch_mm)
 
 	.section &quot;.text.init&quot;, #alloc, #execinstr
<span class="p_header">diff --git a/arch/metag/include/asm/atomic_lnkget.h b/arch/metag/include/asm/atomic_lnkget.h</span>
<span class="p_header">index a62581815624..88fa25fae8bd 100644</span>
<span class="p_header">--- a/arch/metag/include/asm/atomic_lnkget.h</span>
<span class="p_header">+++ b/arch/metag/include/asm/atomic_lnkget.h</span>
<span class="p_chunk">@@ -61,7 +61,7 @@</span> <span class="p_context"> static inline int atomic_##op##_return(int i, atomic_t *v)		\</span>
 		&quot;	CMPT	%0, #HI(0x02000000)\n&quot;			\
 		&quot;	BNZ 1b\n&quot;					\
 		: &quot;=&amp;d&quot; (temp), &quot;=&amp;da&quot; (result)				\
<span class="p_del">-		: &quot;da&quot; (&amp;v-&gt;counter), &quot;bd&quot; (i)				\</span>
<span class="p_add">+		: &quot;da&quot; (&amp;v-&gt;counter), &quot;br&quot; (i)				\</span>
 		: &quot;cc&quot;);						\
 									\
 	smp_mb();							\
<span class="p_header">diff --git a/arch/powerpc/include/asm/icswx.h b/arch/powerpc/include/asm/icswx.h</span>
<span class="p_header">index 9f8402b35115..27e588f6c72e 100644</span>
<span class="p_header">--- a/arch/powerpc/include/asm/icswx.h</span>
<span class="p_header">+++ b/arch/powerpc/include/asm/icswx.h</span>
<span class="p_chunk">@@ -164,6 +164,7 @@</span> <span class="p_context"> struct coprocessor_request_block {</span>
 #define ICSWX_INITIATED		(0x8)
 #define ICSWX_BUSY		(0x4)
 #define ICSWX_REJECTED		(0x2)
<span class="p_add">+#define ICSWX_XERS0		(0x1)	/* undefined or set from XERSO. */</span>
 
 static inline int icswx(__be32 ccw, struct coprocessor_request_block *crb)
 {
<span class="p_header">diff --git a/arch/powerpc/kernel/tm.S b/arch/powerpc/kernel/tm.S</span>
<span class="p_header">index bf8f34a58670..b7019b559ddb 100644</span>
<span class="p_header">--- a/arch/powerpc/kernel/tm.S</span>
<span class="p_header">+++ b/arch/powerpc/kernel/tm.S</span>
<span class="p_chunk">@@ -110,17 +110,11 @@</span> <span class="p_context"> _GLOBAL(tm_reclaim)</span>
 	std	r3, STK_PARAM(R3)(r1)
 	SAVE_NVGPRS(r1)
 
<span class="p_del">-	/* We need to setup MSR for VSX register save instructions.  Here we</span>
<span class="p_del">-	 * also clear the MSR RI since when we do the treclaim, we won&#39;t have a</span>
<span class="p_del">-	 * valid kernel pointer for a while.  We clear RI here as it avoids</span>
<span class="p_del">-	 * adding another mtmsr closer to the treclaim.  This makes the region</span>
<span class="p_del">-	 * maked as non-recoverable wider than it needs to be but it saves on</span>
<span class="p_del">-	 * inserting another mtmsrd later.</span>
<span class="p_del">-	 */</span>
<span class="p_add">+	/* We need to setup MSR for VSX register save instructions. */</span>
 	mfmsr	r14
 	mr	r15, r14
 	ori	r15, r15, MSR_FP
<span class="p_del">-	li	r16, MSR_RI</span>
<span class="p_add">+	li	r16, 0</span>
 	ori	r16, r16, MSR_EE /* IRQs hard off */
 	andc	r15, r15, r16
 	oris	r15, r15, MSR_VEC@h
<span class="p_chunk">@@ -176,7 +170,17 @@</span> <span class="p_context"> dont_backup_fp:</span>
 1:	tdeqi   r6, 0
 	EMIT_BUG_ENTRY 1b,__FILE__,__LINE__,0
 
<span class="p_del">-	/* The moment we treclaim, ALL of our GPRs will switch</span>
<span class="p_add">+	/* Clear MSR RI since we are about to change r1, EE is already off. */</span>
<span class="p_add">+	li	r4, 0</span>
<span class="p_add">+	mtmsrd	r4, 1</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * BE CAREFUL HERE:</span>
<span class="p_add">+	 * At this point we can&#39;t take an SLB miss since we have MSR_RI</span>
<span class="p_add">+	 * off. Load only to/from the stack/paca which are in SLB bolted regions</span>
<span class="p_add">+	 * until we turn MSR RI back on.</span>
<span class="p_add">+	 *</span>
<span class="p_add">+	 * The moment we treclaim, ALL of our GPRs will switch</span>
 	 * to user register state.  (FPRs, CCR etc. also!)
 	 * Use an sprg and a tm_scratch in the PACA to shuffle.
 	 */
<span class="p_chunk">@@ -197,6 +201,11 @@</span> <span class="p_context"> dont_backup_fp:</span>
 
 	/* Store the PPR in r11 and reset to decent value */
 	std	r11, GPR11(r1)			/* Temporary stash */
<span class="p_add">+</span>
<span class="p_add">+	/* Reset MSR RI so we can take SLB faults again */</span>
<span class="p_add">+	li	r11, MSR_RI</span>
<span class="p_add">+	mtmsrd	r11, 1</span>
<span class="p_add">+</span>
 	mfspr	r11, SPRN_PPR
 	HMT_MEDIUM
 
<span class="p_chunk">@@ -397,11 +406,6 @@</span> <span class="p_context"> restore_gprs:</span>
 	ld	r5, THREAD_TM_DSCR(r3)
 	ld	r6, THREAD_TM_PPR(r3)
 
<span class="p_del">-	/* Clear the MSR RI since we are about to change R1.  EE is already off</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	li	r4, 0</span>
<span class="p_del">-	mtmsrd	r4, 1</span>
<span class="p_del">-</span>
 	REST_GPR(0, r7)				/* GPR0 */
 	REST_2GPRS(2, r7)			/* GPR2-3 */
 	REST_GPR(4, r7)				/* GPR4 */
<span class="p_chunk">@@ -439,10 +443,33 @@</span> <span class="p_context"> restore_gprs:</span>
 	ld	r6, _CCR(r7)
 	mtcr    r6
 
<span class="p_del">-	REST_GPR(1, r7)				/* GPR1 */</span>
<span class="p_del">-	REST_GPR(5, r7)				/* GPR5-7 */</span>
 	REST_GPR(6, r7)
<span class="p_del">-	ld	r7, GPR7(r7)</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Store r1 and r5 on the stack so that we can access them</span>
<span class="p_add">+	 * after we clear MSR RI.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+</span>
<span class="p_add">+	REST_GPR(5, r7)</span>
<span class="p_add">+	std	r5, -8(r1)</span>
<span class="p_add">+	ld	r5, GPR1(r7)</span>
<span class="p_add">+	std	r5, -16(r1)</span>
<span class="p_add">+</span>
<span class="p_add">+	REST_GPR(7, r7)</span>
<span class="p_add">+</span>
<span class="p_add">+	/* Clear MSR RI since we are about to change r1. EE is already off */</span>
<span class="p_add">+	li	r5, 0</span>
<span class="p_add">+	mtmsrd	r5, 1</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * BE CAREFUL HERE:</span>
<span class="p_add">+	 * At this point we can&#39;t take an SLB miss since we have MSR_RI</span>
<span class="p_add">+	 * off. Load only to/from the stack/paca which are in SLB bolted regions</span>
<span class="p_add">+	 * until we turn MSR RI back on.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+</span>
<span class="p_add">+	ld	r5, -8(r1)</span>
<span class="p_add">+	ld	r1, -16(r1)</span>
 
 	/* Commit register state as checkpointed state: */
 	TRECHKPT
<span class="p_header">diff --git a/arch/s390/crypto/prng.c b/arch/s390/crypto/prng.c</span>
<span class="p_header">index b8045b97f4fb..d750cc0dfe30 100644</span>
<span class="p_header">--- a/arch/s390/crypto/prng.c</span>
<span class="p_header">+++ b/arch/s390/crypto/prng.c</span>
<span class="p_chunk">@@ -669,11 +669,13 @@</span> <span class="p_context"> static const struct file_operations prng_tdes_fops = {</span>
 static struct miscdevice prng_sha512_dev = {
 	.name	= &quot;prandom&quot;,
 	.minor	= MISC_DYNAMIC_MINOR,
<span class="p_add">+	.mode	= 0644,</span>
 	.fops	= &amp;prng_sha512_fops,
 };
 static struct miscdevice prng_tdes_dev = {
 	.name	= &quot;prandom&quot;,
 	.minor	= MISC_DYNAMIC_MINOR,
<span class="p_add">+	.mode	= 0644,</span>
 	.fops	= &amp;prng_tdes_fops,
 };
 
<span class="p_header">diff --git a/arch/s390/include/asm/pci_dma.h b/arch/s390/include/asm/pci_dma.h</span>
<span class="p_header">index 1aac41e83ea1..92df3eb8d14e 100644</span>
<span class="p_header">--- a/arch/s390/include/asm/pci_dma.h</span>
<span class="p_header">+++ b/arch/s390/include/asm/pci_dma.h</span>
<span class="p_chunk">@@ -23,6 +23,8 @@</span> <span class="p_context"> enum zpci_ioat_dtype {</span>
 #define ZPCI_IOTA_FS_2G			2
 #define ZPCI_KEY			(PAGE_DEFAULT_KEY &lt;&lt; 5)
 
<span class="p_add">+#define ZPCI_TABLE_SIZE_RT	(1UL &lt;&lt; 42)</span>
<span class="p_add">+</span>
 #define ZPCI_IOTA_STO_FLAG	(ZPCI_IOTA_IOT_ENABLED | ZPCI_KEY | ZPCI_IOTA_DT_ST)
 #define ZPCI_IOTA_RTTO_FLAG	(ZPCI_IOTA_IOT_ENABLED | ZPCI_KEY | ZPCI_IOTA_DT_RT)
 #define ZPCI_IOTA_RSTO_FLAG	(ZPCI_IOTA_IOT_ENABLED | ZPCI_KEY | ZPCI_IOTA_DT_RS)
<span class="p_header">diff --git a/arch/s390/pci/pci.c b/arch/s390/pci/pci.c</span>
<span class="p_header">index 19442395f413..f2f6720a3331 100644</span>
<span class="p_header">--- a/arch/s390/pci/pci.c</span>
<span class="p_header">+++ b/arch/s390/pci/pci.c</span>
<span class="p_chunk">@@ -701,8 +701,7 @@</span> <span class="p_context"> static int zpci_restore(struct device *dev)</span>
 		goto out;
 
 	zpci_map_resources(pdev);
<span class="p_del">-	zpci_register_ioat(zdev, 0, zdev-&gt;start_dma + PAGE_OFFSET,</span>
<span class="p_del">-			   zdev-&gt;start_dma + zdev-&gt;iommu_size - 1,</span>
<span class="p_add">+	zpci_register_ioat(zdev, 0, zdev-&gt;start_dma, zdev-&gt;end_dma,</span>
 			   (u64) zdev-&gt;dma_table);
 
 out:
<span class="p_header">diff --git a/arch/s390/pci/pci_dma.c b/arch/s390/pci/pci_dma.c</span>
<span class="p_header">index d348f2c09a1e..3a40f718baef 100644</span>
<span class="p_header">--- a/arch/s390/pci/pci_dma.c</span>
<span class="p_header">+++ b/arch/s390/pci/pci_dma.c</span>
<span class="p_chunk">@@ -458,7 +458,19 @@</span> <span class="p_context"> int zpci_dma_init_device(struct zpci_dev *zdev)</span>
 		goto out_clean;
 	}
 
<span class="p_del">-	zdev-&gt;iommu_size = (unsigned long) high_memory - PAGE_OFFSET;</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Restrict the iommu bitmap size to the minimum of the following:</span>
<span class="p_add">+	 * - main memory size</span>
<span class="p_add">+	 * - 3-level pagetable address limit minus start_dma offset</span>
<span class="p_add">+	 * - DMA address range allowed by the hardware (clp query pci fn)</span>
<span class="p_add">+	 *</span>
<span class="p_add">+	 * Also set zdev-&gt;end_dma to the actual end address of the usable</span>
<span class="p_add">+	 * range, instead of the theoretical maximum as reported by hardware.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	zdev-&gt;iommu_size = min3((u64) high_memory,</span>
<span class="p_add">+				ZPCI_TABLE_SIZE_RT - zdev-&gt;start_dma,</span>
<span class="p_add">+				zdev-&gt;end_dma - zdev-&gt;start_dma + 1);</span>
<span class="p_add">+	zdev-&gt;end_dma = zdev-&gt;start_dma + zdev-&gt;iommu_size - 1;</span>
 	zdev-&gt;iommu_pages = zdev-&gt;iommu_size &gt;&gt; PAGE_SHIFT;
 	zdev-&gt;iommu_bitmap = vzalloc(zdev-&gt;iommu_pages / 8);
 	if (!zdev-&gt;iommu_bitmap) {
<span class="p_chunk">@@ -466,10 +478,7 @@</span> <span class="p_context"> int zpci_dma_init_device(struct zpci_dev *zdev)</span>
 		goto out_reg;
 	}
 
<span class="p_del">-	rc = zpci_register_ioat(zdev,</span>
<span class="p_del">-				0,</span>
<span class="p_del">-				zdev-&gt;start_dma + PAGE_OFFSET,</span>
<span class="p_del">-				zdev-&gt;start_dma + zdev-&gt;iommu_size - 1,</span>
<span class="p_add">+	rc = zpci_register_ioat(zdev, 0, zdev-&gt;start_dma, zdev-&gt;end_dma,</span>
 				(u64) zdev-&gt;dma_table);
 	if (rc)
 		goto out_reg;
<span class="p_header">diff --git a/arch/x86/kernel/apic/apic.c b/arch/x86/kernel/apic/apic.c</span>
<span class="p_header">index 2f69e3b184f6..a3e1f8497f8c 100644</span>
<span class="p_header">--- a/arch/x86/kernel/apic/apic.c</span>
<span class="p_header">+++ b/arch/x86/kernel/apic/apic.c</span>
<span class="p_chunk">@@ -1587,6 +1587,9 @@</span> <span class="p_context"> void __init enable_IR_x2apic(void)</span>
 	unsigned long flags;
 	int ret, ir_stat;
 
<span class="p_add">+	if (skip_ioapic_setup)</span>
<span class="p_add">+		return;</span>
<span class="p_add">+</span>
 	ir_stat = irq_remapping_prepare();
 	if (ir_stat &lt; 0 &amp;&amp; !x2apic_supported())
 		return;
<span class="p_header">diff --git a/arch/x86/kernel/cpu/mshyperv.c b/arch/x86/kernel/cpu/mshyperv.c</span>
<span class="p_header">index 20e242ea1bc4..cfc4a966e2b9 100644</span>
<span class="p_header">--- a/arch/x86/kernel/cpu/mshyperv.c</span>
<span class="p_header">+++ b/arch/x86/kernel/cpu/mshyperv.c</span>
<span class="p_chunk">@@ -152,6 +152,11 @@</span> <span class="p_context"> static struct clocksource hyperv_cs = {</span>
 	.flags		= CLOCK_SOURCE_IS_CONTINUOUS,
 };
 
<span class="p_add">+static unsigned char hv_get_nmi_reason(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return 0;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static void __init ms_hyperv_init_platform(void)
 {
 	/*
<span class="p_chunk">@@ -191,6 +196,13 @@</span> <span class="p_context"> static void __init ms_hyperv_init_platform(void)</span>
 	machine_ops.crash_shutdown = hv_machine_crash_shutdown;
 #endif
 	mark_tsc_unstable(&quot;running on Hyper-V&quot;);
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Generation 2 instances don&#39;t support reading the NMI status from</span>
<span class="p_add">+	 * 0x61 port.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	if (efi_enabled(EFI_BOOT))</span>
<span class="p_add">+		x86_platform.get_nmi_reason = hv_get_nmi_reason;</span>
 }
 
 const __refconst struct hypervisor_x86 x86_hyper_ms_hyperv = {
<span class="p_header">diff --git a/arch/x86/kernel/cpu/perf_event_intel_cqm.c b/arch/x86/kernel/cpu/perf_event_intel_cqm.c</span>
<span class="p_header">index a316ca96f1b6..fc704ed587e8 100644</span>
<span class="p_header">--- a/arch/x86/kernel/cpu/perf_event_intel_cqm.c</span>
<span class="p_header">+++ b/arch/x86/kernel/cpu/perf_event_intel_cqm.c</span>
<span class="p_chunk">@@ -211,6 +211,20 @@</span> <span class="p_context"> static void __put_rmid(u32 rmid)</span>
 	list_add_tail(&amp;entry-&gt;list, &amp;cqm_rmid_limbo_lru);
 }
 
<span class="p_add">+static void cqm_cleanup(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	int i;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (!cqm_rmid_ptrs)</span>
<span class="p_add">+		return;</span>
<span class="p_add">+</span>
<span class="p_add">+	for (i = 0; i &lt; cqm_max_rmid; i++)</span>
<span class="p_add">+		kfree(cqm_rmid_ptrs[i]);</span>
<span class="p_add">+</span>
<span class="p_add">+	kfree(cqm_rmid_ptrs);</span>
<span class="p_add">+	cqm_rmid_ptrs = NULL;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static int intel_cqm_setup_rmid_cache(void)
 {
 	struct cqm_rmid_entry *entry;
<span class="p_chunk">@@ -218,7 +232,7 @@</span> <span class="p_context"> static int intel_cqm_setup_rmid_cache(void)</span>
 	int r = 0;
 
 	nr_rmids = cqm_max_rmid + 1;
<span class="p_del">-	cqm_rmid_ptrs = kmalloc(sizeof(struct cqm_rmid_entry *) *</span>
<span class="p_add">+	cqm_rmid_ptrs = kzalloc(sizeof(struct cqm_rmid_entry *) *</span>
 				nr_rmids, GFP_KERNEL);
 	if (!cqm_rmid_ptrs)
 		return -ENOMEM;
<span class="p_chunk">@@ -249,11 +263,9 @@</span> <span class="p_context"> static int intel_cqm_setup_rmid_cache(void)</span>
 	mutex_unlock(&amp;cache_mutex);
 
 	return 0;
<span class="p_del">-fail:</span>
<span class="p_del">-	while (r--)</span>
<span class="p_del">-		kfree(cqm_rmid_ptrs[r]);</span>
 
<span class="p_del">-	kfree(cqm_rmid_ptrs);</span>
<span class="p_add">+fail:</span>
<span class="p_add">+	cqm_cleanup();</span>
 	return -ENOMEM;
 }
 
<span class="p_chunk">@@ -281,9 +293,13 @@</span> <span class="p_context"> static bool __match_event(struct perf_event *a, struct perf_event *b)</span>
 
 	/*
 	 * Events that target same task are placed into the same cache group.
<span class="p_add">+	 * Mark it as a multi event group, so that we update -&gt;count</span>
<span class="p_add">+	 * for every event rather than just the group leader later.</span>
 	 */
<span class="p_del">-	if (a-&gt;hw.target == b-&gt;hw.target)</span>
<span class="p_add">+	if (a-&gt;hw.target == b-&gt;hw.target) {</span>
<span class="p_add">+		b-&gt;hw.is_group_event = true;</span>
 		return true;
<span class="p_add">+	}</span>
 
 	/*
 	 * Are we an inherited event?
<span class="p_chunk">@@ -849,6 +865,7 @@</span> <span class="p_context"> static void intel_cqm_setup_event(struct perf_event *event,</span>
 	bool conflict = false;
 	u32 rmid;
 
<span class="p_add">+	event-&gt;hw.is_group_event = false;</span>
 	list_for_each_entry(iter, &amp;cache_groups, hw.cqm_groups_entry) {
 		rmid = iter-&gt;hw.cqm_rmid;
 
<span class="p_chunk">@@ -940,7 +957,9 @@</span> <span class="p_context"> static u64 intel_cqm_event_count(struct perf_event *event)</span>
 		return __perf_event_count(event);
 
 	/*
<span class="p_del">-	 * Only the group leader gets to report values. This stops us</span>
<span class="p_add">+	 * Only the group leader gets to report values except in case of</span>
<span class="p_add">+	 * multiple events in the same group, we still need to read the</span>
<span class="p_add">+	 * other events.This stops us</span>
 	 * reporting duplicate values to userspace, and gives us a clear
 	 * rule for which task gets to report the values.
 	 *
<span class="p_chunk">@@ -948,7 +967,7 @@</span> <span class="p_context"> static u64 intel_cqm_event_count(struct perf_event *event)</span>
 	 * specific packages - we forfeit that ability when we create
 	 * task events.
 	 */
<span class="p_del">-	if (!cqm_group_leader(event))</span>
<span class="p_add">+	if (!cqm_group_leader(event) &amp;&amp; !event-&gt;hw.is_group_event)</span>
 		return 0;
 
 	/*
<span class="p_chunk">@@ -1315,7 +1334,7 @@</span> <span class="p_context"> static const struct x86_cpu_id intel_cqm_match[] = {</span>
 
 static int __init intel_cqm_init(void)
 {
<span class="p_del">-	char *str, scale[20];</span>
<span class="p_add">+	char *str = NULL, scale[20];</span>
 	int i, cpu, ret;
 
 	if (!x86_match_cpu(intel_cqm_match))
<span class="p_chunk">@@ -1375,16 +1394,25 @@</span> <span class="p_context"> static int __init intel_cqm_init(void)</span>
 		cqm_pick_event_reader(i);
 	}
 
<span class="p_del">-	__perf_cpu_notifier(intel_cqm_cpu_notifier);</span>
<span class="p_del">-</span>
 	ret = perf_pmu_register(&amp;intel_cqm_pmu, &quot;intel_cqm&quot;, -1);
<span class="p_del">-	if (ret)</span>
<span class="p_add">+	if (ret) {</span>
 		pr_err(&quot;Intel CQM perf registration failed: %d\n&quot;, ret);
<span class="p_del">-	else</span>
<span class="p_del">-		pr_info(&quot;Intel CQM monitoring enabled\n&quot;);</span>
<span class="p_add">+		goto out;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	pr_info(&quot;Intel CQM monitoring enabled\n&quot;);</span>
 
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Register the hot cpu notifier once we are sure cqm</span>
<span class="p_add">+	 * is enabled to avoid notifier leak.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	__perf_cpu_notifier(intel_cqm_cpu_notifier);</span>
 out:
 	cpu_notifier_register_done();
<span class="p_add">+	if (ret) {</span>
<span class="p_add">+		kfree(str);</span>
<span class="p_add">+		cqm_cleanup();</span>
<span class="p_add">+	}</span>
 
 	return ret;
 }
<span class="p_header">diff --git a/block/blk-core.c b/block/blk-core.c</span>
<span class="p_header">index f8e64cac981a..4fab5d610805 100644</span>
<span class="p_header">--- a/block/blk-core.c</span>
<span class="p_header">+++ b/block/blk-core.c</span>
<span class="p_chunk">@@ -515,7 +515,9 @@</span> <span class="p_context"> EXPORT_SYMBOL_GPL(blk_queue_bypass_end);</span>
 
 void blk_set_queue_dying(struct request_queue *q)
 {
<span class="p_del">-	queue_flag_set_unlocked(QUEUE_FLAG_DYING, q);</span>
<span class="p_add">+	spin_lock_irq(q-&gt;queue_lock);</span>
<span class="p_add">+	queue_flag_set(QUEUE_FLAG_DYING, q);</span>
<span class="p_add">+	spin_unlock_irq(q-&gt;queue_lock);</span>
 
 	if (q-&gt;mq_ops)
 		blk_mq_wake_waiters(q);
<span class="p_header">diff --git a/block/blk-merge.c b/block/blk-merge.c</span>
<span class="p_header">index b966db8f3556..7225511cf0b4 100644</span>
<span class="p_header">--- a/block/blk-merge.c</span>
<span class="p_header">+++ b/block/blk-merge.c</span>
<span class="p_chunk">@@ -92,9 +92,31 @@</span> <span class="p_context"> static struct bio *blk_bio_segment_split(struct request_queue *q,</span>
 	bool do_split = true;
 	struct bio *new = NULL;
 	const unsigned max_sectors = get_max_io_size(q, bio);
<span class="p_add">+	unsigned bvecs = 0;</span>
 
 	bio_for_each_segment(bv, bio, iter) {
 		/*
<span class="p_add">+		 * With arbitrary bio size, the incoming bio may be very</span>
<span class="p_add">+		 * big. We have to split the bio into small bios so that</span>
<span class="p_add">+		 * each holds at most BIO_MAX_PAGES bvecs because</span>
<span class="p_add">+		 * bio_clone() can fail to allocate big bvecs.</span>
<span class="p_add">+		 *</span>
<span class="p_add">+		 * It should have been better to apply the limit per</span>
<span class="p_add">+		 * request queue in which bio_clone() is involved,</span>
<span class="p_add">+		 * instead of globally. The biggest blocker is the</span>
<span class="p_add">+		 * bio_clone() in bio bounce.</span>
<span class="p_add">+		 *</span>
<span class="p_add">+		 * If bio is splitted by this reason, we should have</span>
<span class="p_add">+		 * allowed to continue bios merging, but don&#39;t do</span>
<span class="p_add">+		 * that now for making the change simple.</span>
<span class="p_add">+		 *</span>
<span class="p_add">+		 * TODO: deal with bio bounce&#39;s bio_clone() gracefully</span>
<span class="p_add">+		 * and convert the global limit into per-queue limit.</span>
<span class="p_add">+		 */</span>
<span class="p_add">+		if (bvecs++ &gt;= BIO_MAX_PAGES)</span>
<span class="p_add">+			goto split;</span>
<span class="p_add">+</span>
<span class="p_add">+		/*</span>
 		 * If the queue doesn&#39;t support SG gaps and adding this
 		 * offset would create a gap, disallow it.
 		 */
<span class="p_header">diff --git a/block/blk-mq.c b/block/blk-mq.c</span>
<span class="p_header">index 6d6f8feb48c0..839b1e17481b 100644</span>
<span class="p_header">--- a/block/blk-mq.c</span>
<span class="p_header">+++ b/block/blk-mq.c</span>
<span class="p_chunk">@@ -601,8 +601,10 @@</span> <span class="p_context"> static void blk_mq_check_expired(struct blk_mq_hw_ctx *hctx,</span>
 		 * If a request wasn&#39;t started before the queue was
 		 * marked dying, kill it here or it&#39;ll go unnoticed.
 		 */
<span class="p_del">-		if (unlikely(blk_queue_dying(rq-&gt;q)))</span>
<span class="p_del">-			blk_mq_complete_request(rq, -EIO);</span>
<span class="p_add">+		if (unlikely(blk_queue_dying(rq-&gt;q))) {</span>
<span class="p_add">+			rq-&gt;errors = -EIO;</span>
<span class="p_add">+			blk_mq_end_request(rq, rq-&gt;errors);</span>
<span class="p_add">+		}</span>
 		return;
 	}
 	if (rq-&gt;cmd_flags &amp; REQ_NO_TIMEOUT)
<span class="p_header">diff --git a/drivers/bluetooth/btusb.c b/drivers/bluetooth/btusb.c</span>
<span class="p_header">index 79107597a594..c306b483de60 100644</span>
<span class="p_header">--- a/drivers/bluetooth/btusb.c</span>
<span class="p_header">+++ b/drivers/bluetooth/btusb.c</span>
<span class="p_chunk">@@ -2056,12 +2056,13 @@</span> <span class="p_context"> static int btusb_setup_intel_new(struct hci_dev *hdev)</span>
 		return -EINVAL;
 	}
 
<span class="p_del">-	/* At the moment only the hardware variant iBT 3.0 (LnP/SfP) is</span>
<span class="p_del">-	 * supported by this firmware loading method. This check has been</span>
<span class="p_del">-	 * put in place to ensure correct forward compatibility options</span>
<span class="p_del">-	 * when newer hardware variants come along.</span>
<span class="p_add">+	/* At the moment the iBT 3.0 hardware variants 0x0b (LnP/SfP)</span>
<span class="p_add">+	 * and 0x0c (WsP) are supported by this firmware loading method.</span>
<span class="p_add">+	 *</span>
<span class="p_add">+	 * This check has been put in place to ensure correct forward</span>
<span class="p_add">+	 * compatibility options when newer hardware variants come along.</span>
 	 */
<span class="p_del">-	if (ver-&gt;hw_variant != 0x0b) {</span>
<span class="p_add">+	if (ver-&gt;hw_variant != 0x0b &amp;&amp; ver-&gt;hw_variant != 0x0c) {</span>
 		BT_ERR(&quot;%s: Unsupported Intel hardware variant (%u)&quot;,
 		       hdev-&gt;name, ver-&gt;hw_variant);
 		kfree_skb(skb);
<span class="p_header">diff --git a/drivers/char/hw_random/exynos-rng.c b/drivers/char/hw_random/exynos-rng.c</span>
<span class="p_header">index aa30af5f0f2b..7845a38b6604 100644</span>
<span class="p_header">--- a/drivers/char/hw_random/exynos-rng.c</span>
<span class="p_header">+++ b/drivers/char/hw_random/exynos-rng.c</span>
<span class="p_chunk">@@ -118,6 +118,7 @@</span> <span class="p_context"> static int exynos_rng_probe(struct platform_device *pdev)</span>
 {
 	struct exynos_rng *exynos_rng;
 	struct resource *res;
<span class="p_add">+	int ret;</span>
 
 	exynos_rng = devm_kzalloc(&amp;pdev-&gt;dev, sizeof(struct exynos_rng),
 					GFP_KERNEL);
<span class="p_chunk">@@ -145,7 +146,13 @@</span> <span class="p_context"> static int exynos_rng_probe(struct platform_device *pdev)</span>
 	pm_runtime_use_autosuspend(&amp;pdev-&gt;dev);
 	pm_runtime_enable(&amp;pdev-&gt;dev);
 
<span class="p_del">-	return devm_hwrng_register(&amp;pdev-&gt;dev, &amp;exynos_rng-&gt;rng);</span>
<span class="p_add">+	ret = devm_hwrng_register(&amp;pdev-&gt;dev, &amp;exynos_rng-&gt;rng);</span>
<span class="p_add">+	if (ret) {</span>
<span class="p_add">+		pm_runtime_dont_use_autosuspend(&amp;pdev-&gt;dev);</span>
<span class="p_add">+		pm_runtime_disable(&amp;pdev-&gt;dev);</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	return ret;</span>
 }
 
 #ifdef CONFIG_PM
<span class="p_header">diff --git a/drivers/clk/clk-xgene.c b/drivers/clk/clk-xgene.c</span>
<span class="p_header">index 27c0da29eca3..10224b01b97c 100644</span>
<span class="p_header">--- a/drivers/clk/clk-xgene.c</span>
<span class="p_header">+++ b/drivers/clk/clk-xgene.c</span>
<span class="p_chunk">@@ -351,7 +351,8 @@</span> <span class="p_context"> static int xgene_clk_set_rate(struct clk_hw *hw, unsigned long rate,</span>
 		/* Set new divider */
 		data = xgene_clk_read(pclk-&gt;param.divider_reg +
 				pclk-&gt;param.reg_divider_offset);
<span class="p_del">-		data &amp;= ~((1 &lt;&lt; pclk-&gt;param.reg_divider_width) - 1);</span>
<span class="p_add">+		data &amp;= ~((1 &lt;&lt; pclk-&gt;param.reg_divider_width) - 1)</span>
<span class="p_add">+				&lt;&lt; pclk-&gt;param.reg_divider_shift;</span>
 		data |= divider;
 		xgene_clk_write(data, pclk-&gt;param.divider_reg +
 					pclk-&gt;param.reg_divider_offset);
<span class="p_header">diff --git a/drivers/cpufreq/cpufreq_userspace.c b/drivers/cpufreq/cpufreq_userspace.c</span>
<span class="p_header">index 4dbf1db16aca..9cc8abd3d116 100644</span>
<span class="p_header">--- a/drivers/cpufreq/cpufreq_userspace.c</span>
<span class="p_header">+++ b/drivers/cpufreq/cpufreq_userspace.c</span>
<span class="p_chunk">@@ -17,6 +17,7 @@</span> <span class="p_context"></span>
 #include &lt;linux/init.h&gt;
 #include &lt;linux/module.h&gt;
 #include &lt;linux/mutex.h&gt;
<span class="p_add">+#include &lt;linux/slab.h&gt;</span>
 
 static DEFINE_PER_CPU(unsigned int, cpu_is_managed);
 static DEFINE_MUTEX(userspace_mutex);
<span class="p_chunk">@@ -31,6 +32,7 @@</span> <span class="p_context"> static DEFINE_MUTEX(userspace_mutex);</span>
 static int cpufreq_set(struct cpufreq_policy *policy, unsigned int freq)
 {
 	int ret = -EINVAL;
<span class="p_add">+	unsigned int *setspeed = policy-&gt;governor_data;</span>
 
 	pr_debug(&quot;cpufreq_set for cpu %u, freq %u kHz\n&quot;, policy-&gt;cpu, freq);
 
<span class="p_chunk">@@ -38,6 +40,8 @@</span> <span class="p_context"> static int cpufreq_set(struct cpufreq_policy *policy, unsigned int freq)</span>
 	if (!per_cpu(cpu_is_managed, policy-&gt;cpu))
 		goto err;
 
<span class="p_add">+	*setspeed = freq;</span>
<span class="p_add">+</span>
 	ret = __cpufreq_driver_target(policy, freq, CPUFREQ_RELATION_L);
  err:
 	mutex_unlock(&amp;userspace_mutex);
<span class="p_chunk">@@ -49,19 +53,45 @@</span> <span class="p_context"> static ssize_t show_speed(struct cpufreq_policy *policy, char *buf)</span>
 	return sprintf(buf, &quot;%u\n&quot;, policy-&gt;cur);
 }
 
<span class="p_add">+static int cpufreq_userspace_policy_init(struct cpufreq_policy *policy)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned int *setspeed;</span>
<span class="p_add">+</span>
<span class="p_add">+	setspeed = kzalloc(sizeof(*setspeed), GFP_KERNEL);</span>
<span class="p_add">+	if (!setspeed)</span>
<span class="p_add">+		return -ENOMEM;</span>
<span class="p_add">+</span>
<span class="p_add">+	policy-&gt;governor_data = setspeed;</span>
<span class="p_add">+	return 0;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static int cpufreq_governor_userspace(struct cpufreq_policy *policy,
 				   unsigned int event)
 {
<span class="p_add">+	unsigned int *setspeed = policy-&gt;governor_data;</span>
 	unsigned int cpu = policy-&gt;cpu;
 	int rc = 0;
 
<span class="p_add">+	if (event == CPUFREQ_GOV_POLICY_INIT)</span>
<span class="p_add">+		return cpufreq_userspace_policy_init(policy);</span>
<span class="p_add">+</span>
<span class="p_add">+	if (!setspeed)</span>
<span class="p_add">+		return -EINVAL;</span>
<span class="p_add">+</span>
 	switch (event) {
<span class="p_add">+	case CPUFREQ_GOV_POLICY_EXIT:</span>
<span class="p_add">+		mutex_lock(&amp;userspace_mutex);</span>
<span class="p_add">+		policy-&gt;governor_data = NULL;</span>
<span class="p_add">+		kfree(setspeed);</span>
<span class="p_add">+		mutex_unlock(&amp;userspace_mutex);</span>
<span class="p_add">+		break;</span>
 	case CPUFREQ_GOV_START:
 		BUG_ON(!policy-&gt;cur);
 		pr_debug(&quot;started managing cpu %u\n&quot;, cpu);
 
 		mutex_lock(&amp;userspace_mutex);
 		per_cpu(cpu_is_managed, cpu) = 1;
<span class="p_add">+		*setspeed = policy-&gt;cur;</span>
 		mutex_unlock(&amp;userspace_mutex);
 		break;
 	case CPUFREQ_GOV_STOP:
<span class="p_chunk">@@ -69,20 +99,23 @@</span> <span class="p_context"> static int cpufreq_governor_userspace(struct cpufreq_policy *policy,</span>
 
 		mutex_lock(&amp;userspace_mutex);
 		per_cpu(cpu_is_managed, cpu) = 0;
<span class="p_add">+		*setspeed = 0;</span>
 		mutex_unlock(&amp;userspace_mutex);
 		break;
 	case CPUFREQ_GOV_LIMITS:
 		mutex_lock(&amp;userspace_mutex);
<span class="p_del">-		pr_debug(&quot;limit event for cpu %u: %u - %u kHz, currently %u kHz\n&quot;,</span>
<span class="p_del">-			cpu, policy-&gt;min, policy-&gt;max,</span>
<span class="p_del">-			policy-&gt;cur);</span>
<span class="p_add">+		pr_debug(&quot;limit event for cpu %u: %u - %u kHz, currently %u kHz, last set to %u kHz\n&quot;,</span>
<span class="p_add">+			cpu, policy-&gt;min, policy-&gt;max, policy-&gt;cur, *setspeed);</span>
 
<span class="p_del">-		if (policy-&gt;max &lt; policy-&gt;cur)</span>
<span class="p_add">+		if (policy-&gt;max &lt; *setspeed)</span>
 			__cpufreq_driver_target(policy, policy-&gt;max,
 						CPUFREQ_RELATION_H);
<span class="p_del">-		else if (policy-&gt;min &gt; policy-&gt;cur)</span>
<span class="p_add">+		else if (policy-&gt;min &gt; *setspeed)</span>
 			__cpufreq_driver_target(policy, policy-&gt;min,
 						CPUFREQ_RELATION_L);
<span class="p_add">+		else</span>
<span class="p_add">+			__cpufreq_driver_target(policy, *setspeed,</span>
<span class="p_add">+						CPUFREQ_RELATION_L);</span>
 		mutex_unlock(&amp;userspace_mutex);
 		break;
 	}
<span class="p_header">diff --git a/drivers/crypto/caam/caamalg.c b/drivers/crypto/caam/caamalg.c</span>
<span class="p_header">index 6dc597126b79..b3044219772c 100644</span>
<span class="p_header">--- a/drivers/crypto/caam/caamalg.c</span>
<span class="p_header">+++ b/drivers/crypto/caam/caamalg.c</span>
<span class="p_chunk">@@ -556,7 +556,10 @@</span> <span class="p_context"> skip_enc:</span>
 
 	/* Read and write assoclen bytes */
 	append_math_add(desc, VARSEQINLEN, ZERO, REG3, CAAM_CMD_SZ);
<span class="p_del">-	append_math_add(desc, VARSEQOUTLEN, ZERO, REG3, CAAM_CMD_SZ);</span>
<span class="p_add">+	if (alg-&gt;caam.geniv)</span>
<span class="p_add">+		append_math_add_imm_u32(desc, VARSEQOUTLEN, REG3, IMM, ivsize);</span>
<span class="p_add">+	else</span>
<span class="p_add">+		append_math_add(desc, VARSEQOUTLEN, ZERO, REG3, CAAM_CMD_SZ);</span>
 
 	/* Skip assoc data */
 	append_seq_fifo_store(desc, 0, FIFOST_TYPE_SKIP | FIFOLDST_VLF);
<span class="p_chunk">@@ -565,6 +568,14 @@</span> <span class="p_context"> skip_enc:</span>
 	append_seq_fifo_load(desc, 0, FIFOLD_CLASS_CLASS2 | FIFOLD_TYPE_MSG |
 			     KEY_VLF);
 
<span class="p_add">+	if (alg-&gt;caam.geniv) {</span>
<span class="p_add">+		append_seq_load(desc, ivsize, LDST_CLASS_1_CCB |</span>
<span class="p_add">+				LDST_SRCDST_BYTE_CONTEXT |</span>
<span class="p_add">+				(ctx1_iv_off &lt;&lt; LDST_OFFSET_SHIFT));</span>
<span class="p_add">+		append_move(desc, MOVE_SRC_CLASS1CTX | MOVE_DEST_CLASS2INFIFO |</span>
<span class="p_add">+			    (ctx1_iv_off &lt;&lt; MOVE_OFFSET_SHIFT) | ivsize);</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
 	/* Load Counter into CONTEXT1 reg */
 	if (is_rfc3686)
 		append_load_imm_u32(desc, be32_to_cpu(1), LDST_IMM |
<span class="p_chunk">@@ -2150,7 +2161,7 @@</span> <span class="p_context"> static void init_authenc_job(struct aead_request *req,</span>
 
 	init_aead_job(req, edesc, all_contig, encrypt);
 
<span class="p_del">-	if (ivsize &amp;&amp; (is_rfc3686 || !(alg-&gt;caam.geniv &amp;&amp; encrypt)))</span>
<span class="p_add">+	if (ivsize &amp;&amp; ((is_rfc3686 &amp;&amp; encrypt) || !alg-&gt;caam.geniv))</span>
 		append_load_as_imm(desc, req-&gt;iv, ivsize,
 				   LDST_CLASS_1_CCB |
 				   LDST_SRCDST_BYTE_CONTEXT |
<span class="p_chunk">@@ -2537,20 +2548,6 @@</span> <span class="p_context"> static int aead_decrypt(struct aead_request *req)</span>
 	return ret;
 }
 
<span class="p_del">-static int aead_givdecrypt(struct aead_request *req)</span>
<span class="p_del">-{</span>
<span class="p_del">-	struct crypto_aead *aead = crypto_aead_reqtfm(req);</span>
<span class="p_del">-	unsigned int ivsize = crypto_aead_ivsize(aead);</span>
<span class="p_del">-</span>
<span class="p_del">-	if (req-&gt;cryptlen &lt; ivsize)</span>
<span class="p_del">-		return -EINVAL;</span>
<span class="p_del">-</span>
<span class="p_del">-	req-&gt;cryptlen -= ivsize;</span>
<span class="p_del">-	req-&gt;assoclen += ivsize;</span>
<span class="p_del">-</span>
<span class="p_del">-	return aead_decrypt(req);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
 /*
  * allocate and map the ablkcipher extended descriptor for ablkcipher
  */
<span class="p_chunk">@@ -3210,7 +3207,7 @@</span> <span class="p_context"> static struct caam_aead_alg driver_aeads[] = {</span>
 			.setkey = aead_setkey,
 			.setauthsize = aead_setauthsize,
 			.encrypt = aead_encrypt,
<span class="p_del">-			.decrypt = aead_givdecrypt,</span>
<span class="p_add">+			.decrypt = aead_decrypt,</span>
 			.ivsize = AES_BLOCK_SIZE,
 			.maxauthsize = MD5_DIGEST_SIZE,
 		},
<span class="p_chunk">@@ -3256,7 +3253,7 @@</span> <span class="p_context"> static struct caam_aead_alg driver_aeads[] = {</span>
 			.setkey = aead_setkey,
 			.setauthsize = aead_setauthsize,
 			.encrypt = aead_encrypt,
<span class="p_del">-			.decrypt = aead_givdecrypt,</span>
<span class="p_add">+			.decrypt = aead_decrypt,</span>
 			.ivsize = AES_BLOCK_SIZE,
 			.maxauthsize = SHA1_DIGEST_SIZE,
 		},
<span class="p_chunk">@@ -3302,7 +3299,7 @@</span> <span class="p_context"> static struct caam_aead_alg driver_aeads[] = {</span>
 			.setkey = aead_setkey,
 			.setauthsize = aead_setauthsize,
 			.encrypt = aead_encrypt,
<span class="p_del">-			.decrypt = aead_givdecrypt,</span>
<span class="p_add">+			.decrypt = aead_decrypt,</span>
 			.ivsize = AES_BLOCK_SIZE,
 			.maxauthsize = SHA224_DIGEST_SIZE,
 		},
<span class="p_chunk">@@ -3348,7 +3345,7 @@</span> <span class="p_context"> static struct caam_aead_alg driver_aeads[] = {</span>
 			.setkey = aead_setkey,
 			.setauthsize = aead_setauthsize,
 			.encrypt = aead_encrypt,
<span class="p_del">-			.decrypt = aead_givdecrypt,</span>
<span class="p_add">+			.decrypt = aead_decrypt,</span>
 			.ivsize = AES_BLOCK_SIZE,
 			.maxauthsize = SHA256_DIGEST_SIZE,
 		},
<span class="p_chunk">@@ -3394,7 +3391,7 @@</span> <span class="p_context"> static struct caam_aead_alg driver_aeads[] = {</span>
 			.setkey = aead_setkey,
 			.setauthsize = aead_setauthsize,
 			.encrypt = aead_encrypt,
<span class="p_del">-			.decrypt = aead_givdecrypt,</span>
<span class="p_add">+			.decrypt = aead_decrypt,</span>
 			.ivsize = AES_BLOCK_SIZE,
 			.maxauthsize = SHA384_DIGEST_SIZE,
 		},
<span class="p_chunk">@@ -3440,7 +3437,7 @@</span> <span class="p_context"> static struct caam_aead_alg driver_aeads[] = {</span>
 			.setkey = aead_setkey,
 			.setauthsize = aead_setauthsize,
 			.encrypt = aead_encrypt,
<span class="p_del">-			.decrypt = aead_givdecrypt,</span>
<span class="p_add">+			.decrypt = aead_decrypt,</span>
 			.ivsize = AES_BLOCK_SIZE,
 			.maxauthsize = SHA512_DIGEST_SIZE,
 		},
<span class="p_chunk">@@ -3486,7 +3483,7 @@</span> <span class="p_context"> static struct caam_aead_alg driver_aeads[] = {</span>
 			.setkey = aead_setkey,
 			.setauthsize = aead_setauthsize,
 			.encrypt = aead_encrypt,
<span class="p_del">-			.decrypt = aead_givdecrypt,</span>
<span class="p_add">+			.decrypt = aead_decrypt,</span>
 			.ivsize = DES3_EDE_BLOCK_SIZE,
 			.maxauthsize = MD5_DIGEST_SIZE,
 		},
<span class="p_chunk">@@ -3534,7 +3531,7 @@</span> <span class="p_context"> static struct caam_aead_alg driver_aeads[] = {</span>
 			.setkey = aead_setkey,
 			.setauthsize = aead_setauthsize,
 			.encrypt = aead_encrypt,
<span class="p_del">-			.decrypt = aead_givdecrypt,</span>
<span class="p_add">+			.decrypt = aead_decrypt,</span>
 			.ivsize = DES3_EDE_BLOCK_SIZE,
 			.maxauthsize = SHA1_DIGEST_SIZE,
 		},
<span class="p_chunk">@@ -3582,7 +3579,7 @@</span> <span class="p_context"> static struct caam_aead_alg driver_aeads[] = {</span>
 			.setkey = aead_setkey,
 			.setauthsize = aead_setauthsize,
 			.encrypt = aead_encrypt,
<span class="p_del">-			.decrypt = aead_givdecrypt,</span>
<span class="p_add">+			.decrypt = aead_decrypt,</span>
 			.ivsize = DES3_EDE_BLOCK_SIZE,
 			.maxauthsize = SHA224_DIGEST_SIZE,
 		},
<span class="p_chunk">@@ -3630,7 +3627,7 @@</span> <span class="p_context"> static struct caam_aead_alg driver_aeads[] = {</span>
 			.setkey = aead_setkey,
 			.setauthsize = aead_setauthsize,
 			.encrypt = aead_encrypt,
<span class="p_del">-			.decrypt = aead_givdecrypt,</span>
<span class="p_add">+			.decrypt = aead_decrypt,</span>
 			.ivsize = DES3_EDE_BLOCK_SIZE,
 			.maxauthsize = SHA256_DIGEST_SIZE,
 		},
<span class="p_chunk">@@ -3678,7 +3675,7 @@</span> <span class="p_context"> static struct caam_aead_alg driver_aeads[] = {</span>
 			.setkey = aead_setkey,
 			.setauthsize = aead_setauthsize,
 			.encrypt = aead_encrypt,
<span class="p_del">-			.decrypt = aead_givdecrypt,</span>
<span class="p_add">+			.decrypt = aead_decrypt,</span>
 			.ivsize = DES3_EDE_BLOCK_SIZE,
 			.maxauthsize = SHA384_DIGEST_SIZE,
 		},
<span class="p_chunk">@@ -3726,7 +3723,7 @@</span> <span class="p_context"> static struct caam_aead_alg driver_aeads[] = {</span>
 			.setkey = aead_setkey,
 			.setauthsize = aead_setauthsize,
 			.encrypt = aead_encrypt,
<span class="p_del">-			.decrypt = aead_givdecrypt,</span>
<span class="p_add">+			.decrypt = aead_decrypt,</span>
 			.ivsize = DES3_EDE_BLOCK_SIZE,
 			.maxauthsize = SHA512_DIGEST_SIZE,
 		},
<span class="p_chunk">@@ -3772,7 +3769,7 @@</span> <span class="p_context"> static struct caam_aead_alg driver_aeads[] = {</span>
 			.setkey = aead_setkey,
 			.setauthsize = aead_setauthsize,
 			.encrypt = aead_encrypt,
<span class="p_del">-			.decrypt = aead_givdecrypt,</span>
<span class="p_add">+			.decrypt = aead_decrypt,</span>
 			.ivsize = DES_BLOCK_SIZE,
 			.maxauthsize = MD5_DIGEST_SIZE,
 		},
<span class="p_chunk">@@ -3818,7 +3815,7 @@</span> <span class="p_context"> static struct caam_aead_alg driver_aeads[] = {</span>
 			.setkey = aead_setkey,
 			.setauthsize = aead_setauthsize,
 			.encrypt = aead_encrypt,
<span class="p_del">-			.decrypt = aead_givdecrypt,</span>
<span class="p_add">+			.decrypt = aead_decrypt,</span>
 			.ivsize = DES_BLOCK_SIZE,
 			.maxauthsize = SHA1_DIGEST_SIZE,
 		},
<span class="p_chunk">@@ -3864,7 +3861,7 @@</span> <span class="p_context"> static struct caam_aead_alg driver_aeads[] = {</span>
 			.setkey = aead_setkey,
 			.setauthsize = aead_setauthsize,
 			.encrypt = aead_encrypt,
<span class="p_del">-			.decrypt = aead_givdecrypt,</span>
<span class="p_add">+			.decrypt = aead_decrypt,</span>
 			.ivsize = DES_BLOCK_SIZE,
 			.maxauthsize = SHA224_DIGEST_SIZE,
 		},
<span class="p_chunk">@@ -3910,7 +3907,7 @@</span> <span class="p_context"> static struct caam_aead_alg driver_aeads[] = {</span>
 			.setkey = aead_setkey,
 			.setauthsize = aead_setauthsize,
 			.encrypt = aead_encrypt,
<span class="p_del">-			.decrypt = aead_givdecrypt,</span>
<span class="p_add">+			.decrypt = aead_decrypt,</span>
 			.ivsize = DES_BLOCK_SIZE,
 			.maxauthsize = SHA256_DIGEST_SIZE,
 		},
<span class="p_chunk">@@ -3956,7 +3953,7 @@</span> <span class="p_context"> static struct caam_aead_alg driver_aeads[] = {</span>
 			.setkey = aead_setkey,
 			.setauthsize = aead_setauthsize,
 			.encrypt = aead_encrypt,
<span class="p_del">-			.decrypt = aead_givdecrypt,</span>
<span class="p_add">+			.decrypt = aead_decrypt,</span>
 			.ivsize = DES_BLOCK_SIZE,
 			.maxauthsize = SHA384_DIGEST_SIZE,
 		},
<span class="p_chunk">@@ -4002,7 +3999,7 @@</span> <span class="p_context"> static struct caam_aead_alg driver_aeads[] = {</span>
 			.setkey = aead_setkey,
 			.setauthsize = aead_setauthsize,
 			.encrypt = aead_encrypt,
<span class="p_del">-			.decrypt = aead_givdecrypt,</span>
<span class="p_add">+			.decrypt = aead_decrypt,</span>
 			.ivsize = DES_BLOCK_SIZE,
 			.maxauthsize = SHA512_DIGEST_SIZE,
 		},
<span class="p_chunk">@@ -4051,7 +4048,7 @@</span> <span class="p_context"> static struct caam_aead_alg driver_aeads[] = {</span>
 			.setkey = aead_setkey,
 			.setauthsize = aead_setauthsize,
 			.encrypt = aead_encrypt,
<span class="p_del">-			.decrypt = aead_givdecrypt,</span>
<span class="p_add">+			.decrypt = aead_decrypt,</span>
 			.ivsize = CTR_RFC3686_IV_SIZE,
 			.maxauthsize = MD5_DIGEST_SIZE,
 		},
<span class="p_chunk">@@ -4102,7 +4099,7 @@</span> <span class="p_context"> static struct caam_aead_alg driver_aeads[] = {</span>
 			.setkey = aead_setkey,
 			.setauthsize = aead_setauthsize,
 			.encrypt = aead_encrypt,
<span class="p_del">-			.decrypt = aead_givdecrypt,</span>
<span class="p_add">+			.decrypt = aead_decrypt,</span>
 			.ivsize = CTR_RFC3686_IV_SIZE,
 			.maxauthsize = SHA1_DIGEST_SIZE,
 		},
<span class="p_chunk">@@ -4153,7 +4150,7 @@</span> <span class="p_context"> static struct caam_aead_alg driver_aeads[] = {</span>
 			.setkey = aead_setkey,
 			.setauthsize = aead_setauthsize,
 			.encrypt = aead_encrypt,
<span class="p_del">-			.decrypt = aead_givdecrypt,</span>
<span class="p_add">+			.decrypt = aead_decrypt,</span>
 			.ivsize = CTR_RFC3686_IV_SIZE,
 			.maxauthsize = SHA224_DIGEST_SIZE,
 		},
<span class="p_chunk">@@ -4204,7 +4201,7 @@</span> <span class="p_context"> static struct caam_aead_alg driver_aeads[] = {</span>
 			.setkey = aead_setkey,
 			.setauthsize = aead_setauthsize,
 			.encrypt = aead_encrypt,
<span class="p_del">-			.decrypt = aead_givdecrypt,</span>
<span class="p_add">+			.decrypt = aead_decrypt,</span>
 			.ivsize = CTR_RFC3686_IV_SIZE,
 			.maxauthsize = SHA256_DIGEST_SIZE,
 		},
<span class="p_chunk">@@ -4255,7 +4252,7 @@</span> <span class="p_context"> static struct caam_aead_alg driver_aeads[] = {</span>
 			.setkey = aead_setkey,
 			.setauthsize = aead_setauthsize,
 			.encrypt = aead_encrypt,
<span class="p_del">-			.decrypt = aead_givdecrypt,</span>
<span class="p_add">+			.decrypt = aead_decrypt,</span>
 			.ivsize = CTR_RFC3686_IV_SIZE,
 			.maxauthsize = SHA384_DIGEST_SIZE,
 		},
<span class="p_chunk">@@ -4306,7 +4303,7 @@</span> <span class="p_context"> static struct caam_aead_alg driver_aeads[] = {</span>
 			.setkey = aead_setkey,
 			.setauthsize = aead_setauthsize,
 			.encrypt = aead_encrypt,
<span class="p_del">-			.decrypt = aead_givdecrypt,</span>
<span class="p_add">+			.decrypt = aead_decrypt,</span>
 			.ivsize = CTR_RFC3686_IV_SIZE,
 			.maxauthsize = SHA512_DIGEST_SIZE,
 		},
<span class="p_header">diff --git a/drivers/crypto/nx/nx-842-powernv.c b/drivers/crypto/nx/nx-842-powernv.c</span>
<span class="p_header">index 9ef51fafdbff..6e105e87b8ff 100644</span>
<span class="p_header">--- a/drivers/crypto/nx/nx-842-powernv.c</span>
<span class="p_header">+++ b/drivers/crypto/nx/nx-842-powernv.c</span>
<span class="p_chunk">@@ -442,6 +442,14 @@</span> <span class="p_context"> static int nx842_powernv_function(const unsigned char *in, unsigned int inlen,</span>
 			     (unsigned int)ccw,
 			     (unsigned int)be32_to_cpu(crb-&gt;ccw));
 
<span class="p_add">+	/*</span>
<span class="p_add">+	 * NX842 coprocessor sets 3rd bit in CR register with XER[S0].</span>
<span class="p_add">+	 * XER[S0] is the integer summary overflow bit which is nothing</span>
<span class="p_add">+	 * to do NX. Since this bit can be set with other return values,</span>
<span class="p_add">+	 * mask this bit.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	ret &amp;= ~ICSWX_XERS0;</span>
<span class="p_add">+</span>
 	switch (ret) {
 	case ICSWX_INITIATED:
 		ret = wait_for_csb(wmem, csb);
<span class="p_chunk">@@ -454,10 +462,6 @@</span> <span class="p_context"> static int nx842_powernv_function(const unsigned char *in, unsigned int inlen,</span>
 		pr_err_ratelimited(&quot;ICSWX rejected\n&quot;);
 		ret = -EPROTO;
 		break;
<span class="p_del">-	default:</span>
<span class="p_del">-		pr_err_ratelimited(&quot;Invalid ICSWX return code %x\n&quot;, ret);</span>
<span class="p_del">-		ret = -EPROTO;</span>
<span class="p_del">-		break;</span>
 	}
 
 	if (!ret)
<span class="p_header">diff --git a/drivers/crypto/vmx/aes_cbc.c b/drivers/crypto/vmx/aes_cbc.c</span>
<span class="p_header">index f3801b983f42..3f8bb9a40df1 100644</span>
<span class="p_header">--- a/drivers/crypto/vmx/aes_cbc.c</span>
<span class="p_header">+++ b/drivers/crypto/vmx/aes_cbc.c</span>
<span class="p_chunk">@@ -191,7 +191,7 @@</span> <span class="p_context"> struct crypto_alg p8_aes_cbc_alg = {</span>
 	.cra_init = p8_aes_cbc_init,
 	.cra_exit = p8_aes_cbc_exit,
 	.cra_blkcipher = {
<span class="p_del">-			  .ivsize = 0,</span>
<span class="p_add">+			  .ivsize = AES_BLOCK_SIZE,</span>
 			  .min_keysize = AES_MIN_KEY_SIZE,
 			  .max_keysize = AES_MAX_KEY_SIZE,
 			  .setkey = p8_aes_cbc_setkey,
<span class="p_header">diff --git a/drivers/crypto/vmx/aes_ctr.c b/drivers/crypto/vmx/aes_ctr.c</span>
<span class="p_header">index 404a1b69a3ab..72f138985e18 100644</span>
<span class="p_header">--- a/drivers/crypto/vmx/aes_ctr.c</span>
<span class="p_header">+++ b/drivers/crypto/vmx/aes_ctr.c</span>
<span class="p_chunk">@@ -175,7 +175,7 @@</span> <span class="p_context"> struct crypto_alg p8_aes_ctr_alg = {</span>
 	.cra_init = p8_aes_ctr_init,
 	.cra_exit = p8_aes_ctr_exit,
 	.cra_blkcipher = {
<span class="p_del">-			  .ivsize = 0,</span>
<span class="p_add">+			  .ivsize = AES_BLOCK_SIZE,</span>
 			  .min_keysize = AES_MIN_KEY_SIZE,
 			  .max_keysize = AES_MAX_KEY_SIZE,
 			  .setkey = p8_aes_ctr_setkey,
<span class="p_header">diff --git a/drivers/crypto/vmx/ppc-xlate.pl b/drivers/crypto/vmx/ppc-xlate.pl</span>
<span class="p_header">index b9997335f193..b18e67d0e065 100644</span>
<span class="p_header">--- a/drivers/crypto/vmx/ppc-xlate.pl</span>
<span class="p_header">+++ b/drivers/crypto/vmx/ppc-xlate.pl</span>
<span class="p_chunk">@@ -139,6 +139,26 @@</span> <span class="p_context"> my $vmr = sub {</span>
     &quot;	vor	$vx,$vy,$vy&quot;;
 };
 
<span class="p_add">+# Some ABIs specify vrsave, special-purpose register #256, as reserved</span>
<span class="p_add">+# for system use.</span>
<span class="p_add">+my $no_vrsave = ($flavour =~ /linux-ppc64le/);</span>
<span class="p_add">+my $mtspr = sub {</span>
<span class="p_add">+    my ($f,$idx,$ra) = @_;</span>
<span class="p_add">+    if ($idx == 256 &amp;&amp; $no_vrsave) {</span>
<span class="p_add">+	&quot;	or	$ra,$ra,$ra&quot;;</span>
<span class="p_add">+    } else {</span>
<span class="p_add">+	&quot;	mtspr	$idx,$ra&quot;;</span>
<span class="p_add">+    }</span>
<span class="p_add">+};</span>
<span class="p_add">+my $mfspr = sub {</span>
<span class="p_add">+    my ($f,$rd,$idx) = @_;</span>
<span class="p_add">+    if ($idx == 256 &amp;&amp; $no_vrsave) {</span>
<span class="p_add">+	&quot;	li	$rd,-1&quot;;</span>
<span class="p_add">+    } else {</span>
<span class="p_add">+	&quot;	mfspr	$rd,$idx&quot;;</span>
<span class="p_add">+    }</span>
<span class="p_add">+};</span>
<span class="p_add">+</span>
 # PowerISA 2.06 stuff
 sub vsxmem_op {
     my ($f, $vrt, $ra, $rb, $op) = @_;
<span class="p_header">diff --git a/drivers/gpu/drm/amd/amdgpu/atombios_dp.c b/drivers/gpu/drm/amd/amdgpu/atombios_dp.c</span>
<span class="p_header">index 92b6acadfc52..21aacc1f45c1 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/amd/amdgpu/atombios_dp.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/amd/amdgpu/atombios_dp.c</span>
<span class="p_chunk">@@ -243,7 +243,7 @@</span> <span class="p_context"> static void amdgpu_atombios_dp_get_adjust_train(const u8 link_status[DP_LINK_STA</span>
 
 /* convert bits per color to bits per pixel */
 /* get bpc from the EDID */
<span class="p_del">-static int amdgpu_atombios_dp_convert_bpc_to_bpp(int bpc)</span>
<span class="p_add">+static unsigned amdgpu_atombios_dp_convert_bpc_to_bpp(int bpc)</span>
 {
 	if (bpc == 0)
 		return 24;
<span class="p_chunk">@@ -251,64 +251,32 @@</span> <span class="p_context"> static int amdgpu_atombios_dp_convert_bpc_to_bpp(int bpc)</span>
 		return bpc * 3;
 }
 
<span class="p_del">-/* get the max pix clock supported by the link rate and lane num */</span>
<span class="p_del">-static int amdgpu_atombios_dp_get_max_dp_pix_clock(int link_rate,</span>
<span class="p_del">-					    int lane_num,</span>
<span class="p_del">-					    int bpp)</span>
<span class="p_del">-{</span>
<span class="p_del">-	return (link_rate * lane_num * 8) / bpp;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
 /***** amdgpu specific DP functions *****/
 
<span class="p_del">-/* First get the min lane# when low rate is used according to pixel clock</span>
<span class="p_del">- * (prefer low rate), second check max lane# supported by DP panel,</span>
<span class="p_del">- * if the max lane# &lt; low rate lane# then use max lane# instead.</span>
<span class="p_del">- */</span>
<span class="p_del">-static int amdgpu_atombios_dp_get_dp_lane_number(struct drm_connector *connector,</span>
<span class="p_add">+static int amdgpu_atombios_dp_get_dp_link_config(struct drm_connector *connector,</span>
 						 const u8 dpcd[DP_DPCD_SIZE],
<span class="p_del">-						 int pix_clock)</span>
<span class="p_del">-{</span>
<span class="p_del">-	int bpp = amdgpu_atombios_dp_convert_bpc_to_bpp(amdgpu_connector_get_monitor_bpc(connector));</span>
<span class="p_del">-	int max_link_rate = drm_dp_max_link_rate(dpcd);</span>
<span class="p_del">-	int max_lane_num = drm_dp_max_lane_count(dpcd);</span>
<span class="p_del">-	int lane_num;</span>
<span class="p_del">-	int max_dp_pix_clock;</span>
<span class="p_del">-</span>
<span class="p_del">-	for (lane_num = 1; lane_num &lt; max_lane_num; lane_num &lt;&lt;= 1) {</span>
<span class="p_del">-		max_dp_pix_clock = amdgpu_atombios_dp_get_max_dp_pix_clock(max_link_rate, lane_num, bpp);</span>
<span class="p_del">-		if (pix_clock &lt;= max_dp_pix_clock)</span>
<span class="p_del">-			break;</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">-	return lane_num;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static int amdgpu_atombios_dp_get_dp_link_clock(struct drm_connector *connector,</span>
<span class="p_del">-						const u8 dpcd[DP_DPCD_SIZE],</span>
<span class="p_del">-						int pix_clock)</span>
<span class="p_add">+						 unsigned pix_clock,</span>
<span class="p_add">+						 unsigned *dp_lanes, unsigned *dp_rate)</span>
 {
<span class="p_del">-	int bpp = amdgpu_atombios_dp_convert_bpc_to_bpp(amdgpu_connector_get_monitor_bpc(connector));</span>
<span class="p_del">-	int lane_num, max_pix_clock;</span>
<span class="p_del">-</span>
<span class="p_del">-	if (amdgpu_connector_encoder_get_dp_bridge_encoder_id(connector) ==</span>
<span class="p_del">-	    ENCODER_OBJECT_ID_NUTMEG)</span>
<span class="p_del">-		return 270000;</span>
<span class="p_del">-</span>
<span class="p_del">-	lane_num = amdgpu_atombios_dp_get_dp_lane_number(connector, dpcd, pix_clock);</span>
<span class="p_del">-	max_pix_clock = amdgpu_atombios_dp_get_max_dp_pix_clock(162000, lane_num, bpp);</span>
<span class="p_del">-	if (pix_clock &lt;= max_pix_clock)</span>
<span class="p_del">-		return 162000;</span>
<span class="p_del">-	max_pix_clock = amdgpu_atombios_dp_get_max_dp_pix_clock(270000, lane_num, bpp);</span>
<span class="p_del">-	if (pix_clock &lt;= max_pix_clock)</span>
<span class="p_del">-		return 270000;</span>
<span class="p_del">-	if (amdgpu_connector_is_dp12_capable(connector)) {</span>
<span class="p_del">-		max_pix_clock = amdgpu_atombios_dp_get_max_dp_pix_clock(540000, lane_num, bpp);</span>
<span class="p_del">-		if (pix_clock &lt;= max_pix_clock)</span>
<span class="p_del">-			return 540000;</span>
<span class="p_add">+	unsigned bpp =</span>
<span class="p_add">+		amdgpu_atombios_dp_convert_bpc_to_bpp(amdgpu_connector_get_monitor_bpc(connector));</span>
<span class="p_add">+	static const unsigned link_rates[3] = { 162000, 270000, 540000 };</span>
<span class="p_add">+	unsigned max_link_rate = drm_dp_max_link_rate(dpcd);</span>
<span class="p_add">+	unsigned max_lane_num = drm_dp_max_lane_count(dpcd);</span>
<span class="p_add">+	unsigned lane_num, i, max_pix_clock;</span>
<span class="p_add">+</span>
<span class="p_add">+	for (lane_num = 1; lane_num &lt;= max_lane_num; lane_num &lt;&lt;= 1) {</span>
<span class="p_add">+		for (i = 0; i &lt; ARRAY_SIZE(link_rates) &amp;&amp; link_rates[i] &lt;= max_link_rate; i++) {</span>
<span class="p_add">+			max_pix_clock = (lane_num * link_rates[i] * 8) / bpp;</span>
<span class="p_add">+			if (max_pix_clock &gt;= pix_clock) {</span>
<span class="p_add">+				*dp_lanes = lane_num;</span>
<span class="p_add">+				*dp_rate = link_rates[i];</span>
<span class="p_add">+				return 0;</span>
<span class="p_add">+			}</span>
<span class="p_add">+		}</span>
 	}
 
<span class="p_del">-	return drm_dp_max_link_rate(dpcd);</span>
<span class="p_add">+	return -EINVAL;</span>
 }
 
 static u8 amdgpu_atombios_dp_encoder_service(struct amdgpu_device *adev,
<span class="p_chunk">@@ -422,6 +390,7 @@</span> <span class="p_context"> void amdgpu_atombios_dp_set_link_config(struct drm_connector *connector,</span>
 {
 	struct amdgpu_connector *amdgpu_connector = to_amdgpu_connector(connector);
 	struct amdgpu_connector_atom_dig *dig_connector;
<span class="p_add">+	int ret;</span>
 
 	if (!amdgpu_connector-&gt;con_priv)
 		return;
<span class="p_chunk">@@ -429,10 +398,14 @@</span> <span class="p_context"> void amdgpu_atombios_dp_set_link_config(struct drm_connector *connector,</span>
 
 	if ((dig_connector-&gt;dp_sink_type == CONNECTOR_OBJECT_ID_DISPLAYPORT) ||
 	    (dig_connector-&gt;dp_sink_type == CONNECTOR_OBJECT_ID_eDP)) {
<span class="p_del">-		dig_connector-&gt;dp_clock =</span>
<span class="p_del">-			amdgpu_atombios_dp_get_dp_link_clock(connector, dig_connector-&gt;dpcd, mode-&gt;clock);</span>
<span class="p_del">-		dig_connector-&gt;dp_lane_count =</span>
<span class="p_del">-			amdgpu_atombios_dp_get_dp_lane_number(connector, dig_connector-&gt;dpcd, mode-&gt;clock);</span>
<span class="p_add">+		ret = amdgpu_atombios_dp_get_dp_link_config(connector, dig_connector-&gt;dpcd,</span>
<span class="p_add">+							    mode-&gt;clock,</span>
<span class="p_add">+							    &amp;dig_connector-&gt;dp_lane_count,</span>
<span class="p_add">+							    &amp;dig_connector-&gt;dp_clock);</span>
<span class="p_add">+		if (ret) {</span>
<span class="p_add">+			dig_connector-&gt;dp_clock = 0;</span>
<span class="p_add">+			dig_connector-&gt;dp_lane_count = 0;</span>
<span class="p_add">+		}</span>
 	}
 }
 
<span class="p_chunk">@@ -441,14 +414,17 @@</span> <span class="p_context"> int amdgpu_atombios_dp_mode_valid_helper(struct drm_connector *connector,</span>
 {
 	struct amdgpu_connector *amdgpu_connector = to_amdgpu_connector(connector);
 	struct amdgpu_connector_atom_dig *dig_connector;
<span class="p_del">-	int dp_clock;</span>
<span class="p_add">+	unsigned dp_lanes, dp_clock;</span>
<span class="p_add">+	int ret;</span>
 
 	if (!amdgpu_connector-&gt;con_priv)
 		return MODE_CLOCK_HIGH;
 	dig_connector = amdgpu_connector-&gt;con_priv;
 
<span class="p_del">-	dp_clock =</span>
<span class="p_del">-		amdgpu_atombios_dp_get_dp_link_clock(connector, dig_connector-&gt;dpcd, mode-&gt;clock);</span>
<span class="p_add">+	ret = amdgpu_atombios_dp_get_dp_link_config(connector, dig_connector-&gt;dpcd,</span>
<span class="p_add">+						    mode-&gt;clock, &amp;dp_lanes, &amp;dp_clock);</span>
<span class="p_add">+	if (ret)</span>
<span class="p_add">+		return MODE_CLOCK_HIGH;</span>
 
 	if ((dp_clock == 540000) &amp;&amp;
 	    (!amdgpu_connector_is_dp12_capable(connector)))
<span class="p_header">diff --git a/drivers/gpu/drm/amd/amdgpu/cz_dpm.c b/drivers/gpu/drm/amd/amdgpu/cz_dpm.c</span>
<span class="p_header">index 8035d4d6a4f5..653917a3bcc2 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/amd/amdgpu/cz_dpm.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/amd/amdgpu/cz_dpm.c</span>
<span class="p_chunk">@@ -1955,10 +1955,8 @@</span> <span class="p_context"> static void cz_dpm_powergate_vce(struct amdgpu_device *adev, bool gate)</span>
 		}
 	} else { /*pi-&gt;caps_vce_pg*/
 		cz_update_vce_dpm(adev);
<span class="p_del">-		cz_enable_vce_dpm(adev, true);</span>
<span class="p_add">+		cz_enable_vce_dpm(adev, !gate);</span>
 	}
<span class="p_del">-</span>
<span class="p_del">-	return;</span>
 }
 
 const struct amd_ip_funcs cz_dpm_ip_funcs = {
<span class="p_header">diff --git a/drivers/gpu/drm/drm_atomic_helper.c b/drivers/gpu/drm/drm_atomic_helper.c</span>
<span class="p_header">index e5aec45bf985..1ac29d703c12 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/drm_atomic_helper.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/drm_atomic_helper.c</span>
<span class="p_chunk">@@ -108,7 +108,6 @@</span> <span class="p_context"> steal_encoder(struct drm_atomic_state *state,</span>
 	struct drm_crtc_state *crtc_state;
 	struct drm_connector *connector;
 	struct drm_connector_state *connector_state;
<span class="p_del">-	int ret;</span>
 
 	/*
 	 * We can only steal an encoder coming from a connector, which means we
<span class="p_chunk">@@ -139,9 +138,6 @@</span> <span class="p_context"> steal_encoder(struct drm_atomic_state *state,</span>
 		if (IS_ERR(connector_state))
 			return PTR_ERR(connector_state);
 
<span class="p_del">-		ret = drm_atomic_set_crtc_for_connector(connector_state, NULL);</span>
<span class="p_del">-		if (ret)</span>
<span class="p_del">-			return ret;</span>
 		connector_state-&gt;best_encoder = NULL;
 	}
 
<span class="p_header">diff --git a/drivers/gpu/drm/drm_crtc.c b/drivers/gpu/drm/drm_crtc.c</span>
<span class="p_header">index dc84003f694e..5e4bb4837bae 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/drm_crtc.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/drm_crtc.c</span>
<span class="p_chunk">@@ -5231,6 +5231,9 @@</span> <span class="p_context"> int drm_mode_page_flip_ioctl(struct drm_device *dev,</span>
 	unsigned long flags;
 	int ret = -EINVAL;
 
<span class="p_add">+	if (!drm_core_check_feature(dev, DRIVER_MODESET))</span>
<span class="p_add">+		return -EINVAL;</span>
<span class="p_add">+</span>
 	if (page_flip-&gt;flags &amp; ~DRM_MODE_PAGE_FLIP_FLAGS ||
 	    page_flip-&gt;reserved != 0)
 		return -EINVAL;
<span class="p_header">diff --git a/drivers/gpu/drm/drm_gem.c b/drivers/gpu/drm/drm_gem.c</span>
<span class="p_header">index c7de454e8e88..b205224f1a44 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/drm_gem.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/drm_gem.c</span>
<span class="p_chunk">@@ -338,27 +338,32 @@</span> <span class="p_context"> drm_gem_handle_create_tail(struct drm_file *file_priv,</span>
 	spin_unlock(&amp;file_priv-&gt;table_lock);
 	idr_preload_end();
 	mutex_unlock(&amp;dev-&gt;object_name_lock);
<span class="p_del">-	if (ret &lt; 0) {</span>
<span class="p_del">-		drm_gem_object_handle_unreference_unlocked(obj);</span>
<span class="p_del">-		return ret;</span>
<span class="p_del">-	}</span>
<span class="p_add">+	if (ret &lt; 0)</span>
<span class="p_add">+		goto err_unref;</span>
<span class="p_add">+</span>
 	*handlep = ret;
 
 	ret = drm_vma_node_allow(&amp;obj-&gt;vma_node, file_priv-&gt;filp);
<span class="p_del">-	if (ret) {</span>
<span class="p_del">-		drm_gem_handle_delete(file_priv, *handlep);</span>
<span class="p_del">-		return ret;</span>
<span class="p_del">-	}</span>
<span class="p_add">+	if (ret)</span>
<span class="p_add">+		goto err_remove;</span>
 
 	if (dev-&gt;driver-&gt;gem_open_object) {
 		ret = dev-&gt;driver-&gt;gem_open_object(obj, file_priv);
<span class="p_del">-		if (ret) {</span>
<span class="p_del">-			drm_gem_handle_delete(file_priv, *handlep);</span>
<span class="p_del">-			return ret;</span>
<span class="p_del">-		}</span>
<span class="p_add">+		if (ret)</span>
<span class="p_add">+			goto err_revoke;</span>
 	}
 
 	return 0;
<span class="p_add">+</span>
<span class="p_add">+err_revoke:</span>
<span class="p_add">+	drm_vma_node_revoke(&amp;obj-&gt;vma_node, file_priv-&gt;filp);</span>
<span class="p_add">+err_remove:</span>
<span class="p_add">+	spin_lock(&amp;file_priv-&gt;table_lock);</span>
<span class="p_add">+	idr_remove(&amp;file_priv-&gt;object_idr, *handlep);</span>
<span class="p_add">+	spin_unlock(&amp;file_priv-&gt;table_lock);</span>
<span class="p_add">+err_unref:</span>
<span class="p_add">+	drm_gem_object_handle_unreference_unlocked(obj);</span>
<span class="p_add">+	return ret;</span>
 }
 
 /**
<span class="p_header">diff --git a/drivers/gpu/drm/i915/i915_drv.h b/drivers/gpu/drm/i915/i915_drv.h</span>
<span class="p_header">index d3ce4da6a6ad..d400d6773bbb 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/i915/i915_drv.h</span>
<span class="p_header">+++ b/drivers/gpu/drm/i915/i915_drv.h</span>
<span class="p_chunk">@@ -3313,6 +3313,9 @@</span> <span class="p_context"> static inline bool intel_gmbus_is_forced_bit(struct i2c_adapter *adapter)</span>
 }
 extern void intel_i2c_reset(struct drm_device *dev);
 
<span class="p_add">+/* intel_bios.c */</span>
<span class="p_add">+bool intel_bios_is_port_present(struct drm_i915_private *dev_priv, enum port port);</span>
<span class="p_add">+</span>
 /* intel_opregion.c */
 #ifdef CONFIG_ACPI
 extern int intel_opregion_setup(struct drm_device *dev);
<span class="p_header">diff --git a/drivers/gpu/drm/i915/i915_reg.h b/drivers/gpu/drm/i915/i915_reg.h</span>
<span class="p_header">index 9ed9f6dde86f..cace154bbdc0 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/i915/i915_reg.h</span>
<span class="p_header">+++ b/drivers/gpu/drm/i915/i915_reg.h</span>
<span class="p_chunk">@@ -3240,19 +3240,20 @@</span> <span class="p_context"> enum skl_disp_power_wells {</span>
 
 #define PORT_HOTPLUG_STAT	(dev_priv-&gt;info.display_mmio_offset + 0x61114)
 /*
<span class="p_del">- * HDMI/DP bits are gen4+</span>
<span class="p_add">+ * HDMI/DP bits are g4x+</span>
  *
  * WARNING: Bspec for hpd status bits on gen4 seems to be completely confused.
  * Please check the detailed lore in the commit message for for experimental
  * evidence.
  */
<span class="p_del">-#define   PORTD_HOTPLUG_LIVE_STATUS_G4X		(1 &lt;&lt; 29)</span>
<span class="p_add">+/* Bspec says GM45 should match G4X/VLV/CHV, but reality disagrees */</span>
<span class="p_add">+#define   PORTD_HOTPLUG_LIVE_STATUS_GM45	(1 &lt;&lt; 29)</span>
<span class="p_add">+#define   PORTC_HOTPLUG_LIVE_STATUS_GM45	(1 &lt;&lt; 28)</span>
<span class="p_add">+#define   PORTB_HOTPLUG_LIVE_STATUS_GM45	(1 &lt;&lt; 27)</span>
<span class="p_add">+/* G4X/VLV/CHV DP/HDMI bits again match Bspec */</span>
<span class="p_add">+#define   PORTD_HOTPLUG_LIVE_STATUS_G4X		(1 &lt;&lt; 27)</span>
 #define   PORTC_HOTPLUG_LIVE_STATUS_G4X		(1 &lt;&lt; 28)
<span class="p_del">-#define   PORTB_HOTPLUG_LIVE_STATUS_G4X		(1 &lt;&lt; 27)</span>
<span class="p_del">-/* VLV DP/HDMI bits again match Bspec */</span>
<span class="p_del">-#define   PORTD_HOTPLUG_LIVE_STATUS_VLV		(1 &lt;&lt; 27)</span>
<span class="p_del">-#define   PORTC_HOTPLUG_LIVE_STATUS_VLV		(1 &lt;&lt; 28)</span>
<span class="p_del">-#define   PORTB_HOTPLUG_LIVE_STATUS_VLV		(1 &lt;&lt; 29)</span>
<span class="p_add">+#define   PORTB_HOTPLUG_LIVE_STATUS_G4X		(1 &lt;&lt; 29)</span>
 #define   PORTD_HOTPLUG_INT_STATUS		(3 &lt;&lt; 21)
 #define   PORTD_HOTPLUG_INT_LONG_PULSE		(2 &lt;&lt; 21)
 #define   PORTD_HOTPLUG_INT_SHORT_PULSE		(1 &lt;&lt; 21)
<span class="p_header">diff --git a/drivers/gpu/drm/i915/intel_bios.c b/drivers/gpu/drm/i915/intel_bios.c</span>
<span class="p_header">index ce82f9c7df24..d14bdc537587 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/i915/intel_bios.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/i915/intel_bios.c</span>
<span class="p_chunk">@@ -1351,3 +1351,42 @@</span> <span class="p_context"> intel_parse_bios(struct drm_device *dev)</span>
 
 	return 0;
 }
<span class="p_add">+</span>
<span class="p_add">+/**</span>
<span class="p_add">+ * intel_bios_is_port_present - is the specified digital port present</span>
<span class="p_add">+ * @dev_priv:	i915 device instance</span>
<span class="p_add">+ * @port:	port to check</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * Return true if the device in %port is present.</span>
<span class="p_add">+ */</span>
<span class="p_add">+bool intel_bios_is_port_present(struct drm_i915_private *dev_priv, enum port port)</span>
<span class="p_add">+{</span>
<span class="p_add">+	static const struct {</span>
<span class="p_add">+		u16 dp, hdmi;</span>
<span class="p_add">+	} port_mapping[] = {</span>
<span class="p_add">+		[PORT_B] = { DVO_PORT_DPB, DVO_PORT_HDMIB, },</span>
<span class="p_add">+		[PORT_C] = { DVO_PORT_DPC, DVO_PORT_HDMIC, },</span>
<span class="p_add">+		[PORT_D] = { DVO_PORT_DPD, DVO_PORT_HDMID, },</span>
<span class="p_add">+		[PORT_E] = { DVO_PORT_DPE, DVO_PORT_HDMIE, },</span>
<span class="p_add">+	};</span>
<span class="p_add">+	int i;</span>
<span class="p_add">+</span>
<span class="p_add">+	/* FIXME maybe deal with port A as well? */</span>
<span class="p_add">+	if (WARN_ON(port == PORT_A) || port &gt;= ARRAY_SIZE(port_mapping))</span>
<span class="p_add">+		return false;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (!dev_priv-&gt;vbt.child_dev_num)</span>
<span class="p_add">+		return false;</span>
<span class="p_add">+</span>
<span class="p_add">+	for (i = 0; i &lt; dev_priv-&gt;vbt.child_dev_num; i++) {</span>
<span class="p_add">+		const union child_device_config *p_child =</span>
<span class="p_add">+			&amp;dev_priv-&gt;vbt.child_dev[i];</span>
<span class="p_add">+		if ((p_child-&gt;common.dvo_port == port_mapping[port].dp ||</span>
<span class="p_add">+		     p_child-&gt;common.dvo_port == port_mapping[port].hdmi) &amp;&amp;</span>
<span class="p_add">+		    (p_child-&gt;common.device_type &amp; (DEVICE_TYPE_TMDS_DVI_SIGNALING |</span>
<span class="p_add">+						    DEVICE_TYPE_DISPLAYPORT_OUTPUT)))</span>
<span class="p_add">+			return true;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	return false;</span>
<span class="p_add">+}</span>
<span class="p_header">diff --git a/drivers/gpu/drm/i915/intel_display.c b/drivers/gpu/drm/i915/intel_display.c</span>
<span class="p_header">index 3292495ee10f..a3254c3bcc7c 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/i915/intel_display.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/i915/intel_display.c</span>
<span class="p_chunk">@@ -14160,6 +14160,8 @@</span> <span class="p_context"> static void intel_setup_outputs(struct drm_device *dev)</span>
 		if (I915_READ(PCH_DP_D) &amp; DP_DETECTED)
 			intel_dp_init(dev, PCH_DP_D, PORT_D);
 	} else if (IS_VALLEYVIEW(dev)) {
<span class="p_add">+		bool has_edp, has_port;</span>
<span class="p_add">+</span>
 		/*
 		 * The DP_DETECTED bit is the latched state of the DDC
 		 * SDA pin at boot. However since eDP doesn&#39;t require DDC
<span class="p_chunk">@@ -14168,27 +14170,37 @@</span> <span class="p_context"> static void intel_setup_outputs(struct drm_device *dev)</span>
 		 * Thus we can&#39;t rely on the DP_DETECTED bit alone to detect
 		 * eDP ports. Consult the VBT as well as DP_DETECTED to
 		 * detect eDP ports.
<span class="p_add">+		 *</span>
<span class="p_add">+		 * Sadly the straps seem to be missing sometimes even for HDMI</span>
<span class="p_add">+		 * ports (eg. on Voyo V3 - CHT x7-Z8700), so check both strap</span>
<span class="p_add">+		 * and VBT for the presence of the port. Additionally we can&#39;t</span>
<span class="p_add">+		 * trust the port type the VBT declares as we&#39;ve seen at least</span>
<span class="p_add">+		 * HDMI ports that the VBT claim are DP or eDP.</span>
 		 */
<span class="p_del">-		if (I915_READ(VLV_HDMIB) &amp; SDVO_DETECTED &amp;&amp;</span>
<span class="p_del">-		    !intel_dp_is_edp(dev, PORT_B))</span>
<span class="p_add">+		has_edp = intel_dp_is_edp(dev, PORT_B);</span>
<span class="p_add">+		has_port = intel_bios_is_port_present(dev_priv, PORT_B);</span>
<span class="p_add">+		if (I915_READ(VLV_DP_B) &amp; DP_DETECTED || has_port)</span>
<span class="p_add">+			has_edp &amp;= intel_dp_init(dev, VLV_DP_B, PORT_B);</span>
<span class="p_add">+		if ((I915_READ(VLV_HDMIB) &amp; SDVO_DETECTED || has_port) &amp;&amp; !has_edp)</span>
 			intel_hdmi_init(dev, VLV_HDMIB, PORT_B);
<span class="p_del">-		if (I915_READ(VLV_DP_B) &amp; DP_DETECTED ||</span>
<span class="p_del">-		    intel_dp_is_edp(dev, PORT_B))</span>
<span class="p_del">-			intel_dp_init(dev, VLV_DP_B, PORT_B);</span>
 
<span class="p_del">-		if (I915_READ(VLV_HDMIC) &amp; SDVO_DETECTED &amp;&amp;</span>
<span class="p_del">-		    !intel_dp_is_edp(dev, PORT_C))</span>
<span class="p_add">+		has_edp = intel_dp_is_edp(dev, PORT_C);</span>
<span class="p_add">+		has_port = intel_bios_is_port_present(dev_priv, PORT_C);</span>
<span class="p_add">+		if (I915_READ(VLV_DP_C) &amp; DP_DETECTED || has_port)</span>
<span class="p_add">+			has_edp &amp;= intel_dp_init(dev, VLV_DP_C, PORT_C);</span>
<span class="p_add">+		if ((I915_READ(VLV_HDMIC) &amp; SDVO_DETECTED || has_port) &amp;&amp; !has_edp)</span>
 			intel_hdmi_init(dev, VLV_HDMIC, PORT_C);
<span class="p_del">-		if (I915_READ(VLV_DP_C) &amp; DP_DETECTED ||</span>
<span class="p_del">-		    intel_dp_is_edp(dev, PORT_C))</span>
<span class="p_del">-			intel_dp_init(dev, VLV_DP_C, PORT_C);</span>
 
 		if (IS_CHERRYVIEW(dev)) {
<span class="p_del">-			/* eDP not supported on port D, so don&#39;t check VBT */</span>
<span class="p_del">-			if (I915_READ(CHV_HDMID) &amp; SDVO_DETECTED)</span>
<span class="p_del">-				intel_hdmi_init(dev, CHV_HDMID, PORT_D);</span>
<span class="p_del">-			if (I915_READ(CHV_DP_D) &amp; DP_DETECTED)</span>
<span class="p_add">+			/*</span>
<span class="p_add">+			 * eDP not supported on port D,</span>
<span class="p_add">+			 * so no need to worry about it</span>
<span class="p_add">+			 */</span>
<span class="p_add">+			has_port = intel_bios_is_port_present(dev_priv, PORT_D);</span>
<span class="p_add">+			if (I915_READ(CHV_DP_D) &amp; DP_DETECTED || has_port)</span>
 				intel_dp_init(dev, CHV_DP_D, PORT_D);
<span class="p_add">+			if (I915_READ(CHV_HDMID) &amp; SDVO_DETECTED || has_port)</span>
<span class="p_add">+				intel_hdmi_init(dev, CHV_HDMID, PORT_D);</span>
 		}
 
 		intel_dsi_init(dev);
<span class="p_header">diff --git a/drivers/gpu/drm/i915/intel_dp.c b/drivers/gpu/drm/i915/intel_dp.c</span>
<span class="p_header">index 8e1d6d74c203..ebbd23407a80 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/i915/intel_dp.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/i915/intel_dp.c</span>
<span class="p_chunk">@@ -4592,20 +4592,20 @@</span> <span class="p_context"> static bool g4x_digital_port_connected(struct drm_i915_private *dev_priv,</span>
 	return I915_READ(PORT_HOTPLUG_STAT) &amp; bit;
 }
 
<span class="p_del">-static bool vlv_digital_port_connected(struct drm_i915_private *dev_priv,</span>
<span class="p_del">-				       struct intel_digital_port *port)</span>
<span class="p_add">+static bool gm45_digital_port_connected(struct drm_i915_private *dev_priv,</span>
<span class="p_add">+					struct intel_digital_port *port)</span>
 {
 	u32 bit;
 
 	switch (port-&gt;port) {
 	case PORT_B:
<span class="p_del">-		bit = PORTB_HOTPLUG_LIVE_STATUS_VLV;</span>
<span class="p_add">+		bit = PORTB_HOTPLUG_LIVE_STATUS_GM45;</span>
 		break;
 	case PORT_C:
<span class="p_del">-		bit = PORTC_HOTPLUG_LIVE_STATUS_VLV;</span>
<span class="p_add">+		bit = PORTC_HOTPLUG_LIVE_STATUS_GM45;</span>
 		break;
 	case PORT_D:
<span class="p_del">-		bit = PORTD_HOTPLUG_LIVE_STATUS_VLV;</span>
<span class="p_add">+		bit = PORTD_HOTPLUG_LIVE_STATUS_GM45;</span>
 		break;
 	default:
 		MISSING_CASE(port-&gt;port);
<span class="p_chunk">@@ -4657,8 +4657,8 @@</span> <span class="p_context"> bool intel_digital_port_connected(struct drm_i915_private *dev_priv,</span>
 		return cpt_digital_port_connected(dev_priv, port);
 	else if (IS_BROXTON(dev_priv))
 		return bxt_digital_port_connected(dev_priv, port);
<span class="p_del">-	else if (IS_VALLEYVIEW(dev_priv))</span>
<span class="p_del">-		return vlv_digital_port_connected(dev_priv, port);</span>
<span class="p_add">+	else if (IS_GM45(dev_priv))</span>
<span class="p_add">+		return gm45_digital_port_connected(dev_priv, port);</span>
 	else
 		return g4x_digital_port_connected(dev_priv, port);
 }
<span class="p_chunk">@@ -6113,8 +6113,9 @@</span> <span class="p_context"> intel_dp_init_connector(struct intel_digital_port *intel_dig_port,</span>
 	return true;
 }
 
<span class="p_del">-void</span>
<span class="p_del">-intel_dp_init(struct drm_device *dev, int output_reg, enum port port)</span>
<span class="p_add">+bool intel_dp_init(struct drm_device *dev,</span>
<span class="p_add">+		   int output_reg,</span>
<span class="p_add">+		   enum port port)</span>
 {
 	struct drm_i915_private *dev_priv = dev-&gt;dev_private;
 	struct intel_digital_port *intel_dig_port;
<span class="p_chunk">@@ -6124,7 +6125,7 @@</span> <span class="p_context"> intel_dp_init(struct drm_device *dev, int output_reg, enum port port)</span>
 
 	intel_dig_port = kzalloc(sizeof(*intel_dig_port), GFP_KERNEL);
 	if (!intel_dig_port)
<span class="p_del">-		return;</span>
<span class="p_add">+		return false;</span>
 
 	intel_connector = intel_connector_alloc();
 	if (!intel_connector)
<span class="p_chunk">@@ -6179,15 +6180,14 @@</span> <span class="p_context"> intel_dp_init(struct drm_device *dev, int output_reg, enum port port)</span>
 	if (!intel_dp_init_connector(intel_dig_port, intel_connector))
 		goto err_init_connector;
 
<span class="p_del">-	return;</span>
<span class="p_add">+	return true;</span>
 
 err_init_connector:
 	drm_encoder_cleanup(encoder);
 	kfree(intel_connector);
 err_connector_alloc:
 	kfree(intel_dig_port);
<span class="p_del">-</span>
<span class="p_del">-	return;</span>
<span class="p_add">+	return false;</span>
 }
 
 void intel_dp_mst_suspend(struct drm_device *dev)
<span class="p_header">diff --git a/drivers/gpu/drm/i915/intel_drv.h b/drivers/gpu/drm/i915/intel_drv.h</span>
<span class="p_header">index c5f11e0c5d5b..67f72a7ee7cb 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/i915/intel_drv.h</span>
<span class="p_header">+++ b/drivers/gpu/drm/i915/intel_drv.h</span>
<span class="p_chunk">@@ -1195,7 +1195,7 @@</span> <span class="p_context"> void intel_csr_ucode_fini(struct drm_device *dev);</span>
 void assert_csr_loaded(struct drm_i915_private *dev_priv);
 
 /* intel_dp.c */
<span class="p_del">-void intel_dp_init(struct drm_device *dev, int output_reg, enum port port);</span>
<span class="p_add">+bool intel_dp_init(struct drm_device *dev, int output_reg, enum port port);</span>
 bool intel_dp_init_connector(struct intel_digital_port *intel_dig_port,
 			     struct intel_connector *intel_connector);
 void intel_dp_set_link_params(struct intel_dp *intel_dp,
<span class="p_header">diff --git a/drivers/gpu/drm/i915/intel_hdmi.c b/drivers/gpu/drm/i915/intel_hdmi.c</span>
<span class="p_header">index 4b8ed9f2dabc..dff69fef47e0 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/i915/intel_hdmi.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/i915/intel_hdmi.c</span>
<span class="p_chunk">@@ -2030,6 +2030,9 @@</span> <span class="p_context"> void intel_hdmi_init_connector(struct intel_digital_port *intel_dig_port,</span>
 	enum port port = intel_dig_port-&gt;port;
 	uint8_t alternate_ddc_pin;
 
<span class="p_add">+	DRM_DEBUG_KMS(&quot;Adding HDMI connector on port %c\n&quot;,</span>
<span class="p_add">+		      port_name(port));</span>
<span class="p_add">+</span>
 	drm_connector_init(dev, connector, &amp;intel_hdmi_connector_funcs,
 			   DRM_MODE_CONNECTOR_HDMIA);
 	drm_connector_helper_add(connector, &amp;intel_hdmi_connector_helper_funcs);
<span class="p_header">diff --git a/drivers/gpu/drm/msm/msm_gem_submit.c b/drivers/gpu/drm/msm/msm_gem_submit.c</span>
<span class="p_header">index 6d7cd3fe21e7..1847f83b1e33 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/msm/msm_gem_submit.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/msm/msm_gem_submit.c</span>
<span class="p_chunk">@@ -55,6 +55,14 @@</span> <span class="p_context"> static struct msm_gem_submit *submit_create(struct drm_device *dev,</span>
 	return submit;
 }
 
<span class="p_add">+static inline unsigned long __must_check</span>
<span class="p_add">+copy_from_user_inatomic(void *to, const void __user *from, unsigned long n)</span>
<span class="p_add">+{</span>
<span class="p_add">+	if (access_ok(VERIFY_READ, from, n))</span>
<span class="p_add">+		return __copy_from_user_inatomic(to, from, n);</span>
<span class="p_add">+	return -EFAULT;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static int submit_lookup_objects(struct msm_gem_submit *submit,
 		struct drm_msm_gem_submit *args, struct drm_file *file)
 {
<span class="p_chunk">@@ -62,6 +70,7 @@</span> <span class="p_context"> static int submit_lookup_objects(struct msm_gem_submit *submit,</span>
 	int ret = 0;
 
 	spin_lock(&amp;file-&gt;table_lock);
<span class="p_add">+	pagefault_disable();</span>
 
 	for (i = 0; i &lt; args-&gt;nr_bos; i++) {
 		struct drm_msm_gem_submit_bo submit_bo;
<span class="p_chunk">@@ -70,10 +79,15 @@</span> <span class="p_context"> static int submit_lookup_objects(struct msm_gem_submit *submit,</span>
 		void __user *userptr =
 			to_user_ptr(args-&gt;bos + (i * sizeof(submit_bo)));
 
<span class="p_del">-		ret = copy_from_user(&amp;submit_bo, userptr, sizeof(submit_bo));</span>
<span class="p_del">-		if (ret) {</span>
<span class="p_del">-			ret = -EFAULT;</span>
<span class="p_del">-			goto out_unlock;</span>
<span class="p_add">+		ret = copy_from_user_inatomic(&amp;submit_bo, userptr, sizeof(submit_bo));</span>
<span class="p_add">+		if (unlikely(ret)) {</span>
<span class="p_add">+			pagefault_enable();</span>
<span class="p_add">+			spin_unlock(&amp;file-&gt;table_lock);</span>
<span class="p_add">+			ret = copy_from_user(&amp;submit_bo, userptr, sizeof(submit_bo));</span>
<span class="p_add">+			if (ret)</span>
<span class="p_add">+				goto out;</span>
<span class="p_add">+			spin_lock(&amp;file-&gt;table_lock);</span>
<span class="p_add">+			pagefault_disable();</span>
 		}
 
 		if (submit_bo.flags &amp; ~MSM_SUBMIT_BO_FLAGS) {
<span class="p_chunk">@@ -113,9 +127,12 @@</span> <span class="p_context"> static int submit_lookup_objects(struct msm_gem_submit *submit,</span>
 	}
 
 out_unlock:
<span class="p_del">-	submit-&gt;nr_bos = i;</span>
<span class="p_add">+	pagefault_enable();</span>
 	spin_unlock(&amp;file-&gt;table_lock);
 
<span class="p_add">+out:</span>
<span class="p_add">+	submit-&gt;nr_bos = i;</span>
<span class="p_add">+</span>
 	return ret;
 }
 
<span class="p_header">diff --git a/drivers/gpu/drm/radeon/atombios_dp.c b/drivers/gpu/drm/radeon/atombios_dp.c</span>
<span class="p_header">index bd73b4069069..44ee72e04df9 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/radeon/atombios_dp.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/radeon/atombios_dp.c</span>
<span class="p_chunk">@@ -302,77 +302,31 @@</span> <span class="p_context"> static int convert_bpc_to_bpp(int bpc)</span>
 		return bpc * 3;
 }
 
<span class="p_del">-/* get the max pix clock supported by the link rate and lane num */</span>
<span class="p_del">-static int dp_get_max_dp_pix_clock(int link_rate,</span>
<span class="p_del">-				   int lane_num,</span>
<span class="p_del">-				   int bpp)</span>
<span class="p_del">-{</span>
<span class="p_del">-	return (link_rate * lane_num * 8) / bpp;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
 /***** radeon specific DP functions *****/
 
<span class="p_del">-int radeon_dp_get_max_link_rate(struct drm_connector *connector,</span>
<span class="p_del">-				const u8 dpcd[DP_DPCD_SIZE])</span>
<span class="p_del">-{</span>
<span class="p_del">-	int max_link_rate;</span>
<span class="p_del">-</span>
<span class="p_del">-	if (radeon_connector_is_dp12_capable(connector))</span>
<span class="p_del">-		max_link_rate = min(drm_dp_max_link_rate(dpcd), 540000);</span>
<span class="p_del">-	else</span>
<span class="p_del">-		max_link_rate = min(drm_dp_max_link_rate(dpcd), 270000);</span>
<span class="p_del">-</span>
<span class="p_del">-	return max_link_rate;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-/* First get the min lane# when low rate is used according to pixel clock</span>
<span class="p_del">- * (prefer low rate), second check max lane# supported by DP panel,</span>
<span class="p_del">- * if the max lane# &lt; low rate lane# then use max lane# instead.</span>
<span class="p_del">- */</span>
<span class="p_del">-static int radeon_dp_get_dp_lane_number(struct drm_connector *connector,</span>
<span class="p_del">-					const u8 dpcd[DP_DPCD_SIZE],</span>
<span class="p_del">-					int pix_clock)</span>
<span class="p_del">-{</span>
<span class="p_del">-	int bpp = convert_bpc_to_bpp(radeon_get_monitor_bpc(connector));</span>
<span class="p_del">-	int max_link_rate = radeon_dp_get_max_link_rate(connector, dpcd);</span>
<span class="p_del">-	int max_lane_num = drm_dp_max_lane_count(dpcd);</span>
<span class="p_del">-	int lane_num;</span>
<span class="p_del">-	int max_dp_pix_clock;</span>
<span class="p_del">-</span>
<span class="p_del">-	for (lane_num = 1; lane_num &lt; max_lane_num; lane_num &lt;&lt;= 1) {</span>
<span class="p_del">-		max_dp_pix_clock = dp_get_max_dp_pix_clock(max_link_rate, lane_num, bpp);</span>
<span class="p_del">-		if (pix_clock &lt;= max_dp_pix_clock)</span>
<span class="p_del">-			break;</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">-	return lane_num;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static int radeon_dp_get_dp_link_clock(struct drm_connector *connector,</span>
<span class="p_del">-				       const u8 dpcd[DP_DPCD_SIZE],</span>
<span class="p_del">-				       int pix_clock)</span>
<span class="p_add">+int radeon_dp_get_dp_link_config(struct drm_connector *connector,</span>
<span class="p_add">+				 const u8 dpcd[DP_DPCD_SIZE],</span>
<span class="p_add">+				 unsigned pix_clock,</span>
<span class="p_add">+				 unsigned *dp_lanes, unsigned *dp_rate)</span>
 {
 	int bpp = convert_bpc_to_bpp(radeon_get_monitor_bpc(connector));
<span class="p_del">-	int lane_num, max_pix_clock;</span>
<span class="p_del">-</span>
<span class="p_del">-	if (radeon_connector_encoder_get_dp_bridge_encoder_id(connector) ==</span>
<span class="p_del">-	    ENCODER_OBJECT_ID_NUTMEG)</span>
<span class="p_del">-		return 270000;</span>
<span class="p_del">-</span>
<span class="p_del">-	lane_num = radeon_dp_get_dp_lane_number(connector, dpcd, pix_clock);</span>
<span class="p_del">-	max_pix_clock = dp_get_max_dp_pix_clock(162000, lane_num, bpp);</span>
<span class="p_del">-	if (pix_clock &lt;= max_pix_clock)</span>
<span class="p_del">-		return 162000;</span>
<span class="p_del">-	max_pix_clock = dp_get_max_dp_pix_clock(270000, lane_num, bpp);</span>
<span class="p_del">-	if (pix_clock &lt;= max_pix_clock)</span>
<span class="p_del">-		return 270000;</span>
<span class="p_del">-	if (radeon_connector_is_dp12_capable(connector)) {</span>
<span class="p_del">-		max_pix_clock = dp_get_max_dp_pix_clock(540000, lane_num, bpp);</span>
<span class="p_del">-		if (pix_clock &lt;= max_pix_clock)</span>
<span class="p_del">-			return 540000;</span>
<span class="p_add">+	static const unsigned link_rates[3] = { 162000, 270000, 540000 };</span>
<span class="p_add">+	unsigned max_link_rate = drm_dp_max_link_rate(dpcd);</span>
<span class="p_add">+	unsigned max_lane_num = drm_dp_max_lane_count(dpcd);</span>
<span class="p_add">+	unsigned lane_num, i, max_pix_clock;</span>
<span class="p_add">+</span>
<span class="p_add">+	for (lane_num = 1; lane_num &lt;= max_lane_num; lane_num &lt;&lt;= 1) {</span>
<span class="p_add">+		for (i = 0; i &lt; ARRAY_SIZE(link_rates) &amp;&amp; link_rates[i] &lt;= max_link_rate; i++) {</span>
<span class="p_add">+			max_pix_clock = (lane_num * link_rates[i] * 8) / bpp;</span>
<span class="p_add">+			if (max_pix_clock &gt;= pix_clock) {</span>
<span class="p_add">+				*dp_lanes = lane_num;</span>
<span class="p_add">+				*dp_rate = link_rates[i];</span>
<span class="p_add">+				return 0;</span>
<span class="p_add">+			}</span>
<span class="p_add">+		}</span>
 	}
 
<span class="p_del">-	return radeon_dp_get_max_link_rate(connector, dpcd);</span>
<span class="p_add">+	return -EINVAL;</span>
 }
 
 static u8 radeon_dp_encoder_service(struct radeon_device *rdev,
<span class="p_chunk">@@ -491,6 +445,7 @@</span> <span class="p_context"> void radeon_dp_set_link_config(struct drm_connector *connector,</span>
 {
 	struct radeon_connector *radeon_connector = to_radeon_connector(connector);
 	struct radeon_connector_atom_dig *dig_connector;
<span class="p_add">+	int ret;</span>
 
 	if (!radeon_connector-&gt;con_priv)
 		return;
<span class="p_chunk">@@ -498,10 +453,14 @@</span> <span class="p_context"> void radeon_dp_set_link_config(struct drm_connector *connector,</span>
 
 	if ((dig_connector-&gt;dp_sink_type == CONNECTOR_OBJECT_ID_DISPLAYPORT) ||
 	    (dig_connector-&gt;dp_sink_type == CONNECTOR_OBJECT_ID_eDP)) {
<span class="p_del">-		dig_connector-&gt;dp_clock =</span>
<span class="p_del">-			radeon_dp_get_dp_link_clock(connector, dig_connector-&gt;dpcd, mode-&gt;clock);</span>
<span class="p_del">-		dig_connector-&gt;dp_lane_count =</span>
<span class="p_del">-			radeon_dp_get_dp_lane_number(connector, dig_connector-&gt;dpcd, mode-&gt;clock);</span>
<span class="p_add">+		ret = radeon_dp_get_dp_link_config(connector, dig_connector-&gt;dpcd,</span>
<span class="p_add">+						   mode-&gt;clock,</span>
<span class="p_add">+						   &amp;dig_connector-&gt;dp_lane_count,</span>
<span class="p_add">+						   &amp;dig_connector-&gt;dp_clock);</span>
<span class="p_add">+		if (ret) {</span>
<span class="p_add">+			dig_connector-&gt;dp_clock = 0;</span>
<span class="p_add">+			dig_connector-&gt;dp_lane_count = 0;</span>
<span class="p_add">+		}</span>
 	}
 }
 
<span class="p_chunk">@@ -510,7 +469,8 @@</span> <span class="p_context"> int radeon_dp_mode_valid_helper(struct drm_connector *connector,</span>
 {
 	struct radeon_connector *radeon_connector = to_radeon_connector(connector);
 	struct radeon_connector_atom_dig *dig_connector;
<span class="p_del">-	int dp_clock;</span>
<span class="p_add">+	unsigned dp_clock, dp_lanes;</span>
<span class="p_add">+	int ret;</span>
 
 	if ((mode-&gt;clock &gt; 340000) &amp;&amp;
 	    (!radeon_connector_is_dp12_capable(connector)))
<span class="p_chunk">@@ -520,8 +480,12 @@</span> <span class="p_context"> int radeon_dp_mode_valid_helper(struct drm_connector *connector,</span>
 		return MODE_CLOCK_HIGH;
 	dig_connector = radeon_connector-&gt;con_priv;
 
<span class="p_del">-	dp_clock =</span>
<span class="p_del">-		radeon_dp_get_dp_link_clock(connector, dig_connector-&gt;dpcd, mode-&gt;clock);</span>
<span class="p_add">+	ret = radeon_dp_get_dp_link_config(connector, dig_connector-&gt;dpcd,</span>
<span class="p_add">+					   mode-&gt;clock,</span>
<span class="p_add">+					   &amp;dp_lanes,</span>
<span class="p_add">+					   &amp;dp_clock);</span>
<span class="p_add">+	if (ret)</span>
<span class="p_add">+		return MODE_CLOCK_HIGH;</span>
 
 	if ((dp_clock == 540000) &amp;&amp;
 	    (!radeon_connector_is_dp12_capable(connector)))
<span class="p_header">diff --git a/drivers/gpu/drm/radeon/radeon_dp_mst.c b/drivers/gpu/drm/radeon/radeon_dp_mst.c</span>
<span class="p_header">index 744f5c49c664..6dd39bdedb97 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/radeon/radeon_dp_mst.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/radeon/radeon_dp_mst.c</span>
<span class="p_chunk">@@ -525,11 +525,9 @@</span> <span class="p_context"> static bool radeon_mst_mode_fixup(struct drm_encoder *encoder,</span>
 	drm_mode_set_crtcinfo(adjusted_mode, 0);
 	{
 	  struct radeon_connector_atom_dig *dig_connector;
<span class="p_del">-</span>
 	  dig_connector = mst_enc-&gt;connector-&gt;con_priv;
 	  dig_connector-&gt;dp_lane_count = drm_dp_max_lane_count(dig_connector-&gt;dpcd);
<span class="p_del">-	  dig_connector-&gt;dp_clock = radeon_dp_get_max_link_rate(&amp;mst_enc-&gt;connector-&gt;base,</span>
<span class="p_del">-								dig_connector-&gt;dpcd);</span>
<span class="p_add">+	  dig_connector-&gt;dp_clock = drm_dp_max_link_rate(dig_connector-&gt;dpcd);</span>
 	  DRM_DEBUG_KMS(&quot;dig clock %p %d %d\n&quot;, dig_connector,
 			dig_connector-&gt;dp_lane_count, dig_connector-&gt;dp_clock);
 	}
<span class="p_header">diff --git a/drivers/gpu/drm/radeon/radeon_mode.h b/drivers/gpu/drm/radeon/radeon_mode.h</span>
<span class="p_header">index bba112628b47..7a0666ac4e23 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/radeon/radeon_mode.h</span>
<span class="p_header">+++ b/drivers/gpu/drm/radeon/radeon_mode.h</span>
<span class="p_chunk">@@ -757,8 +757,10 @@</span> <span class="p_context"> extern u8 radeon_dp_getsinktype(struct radeon_connector *radeon_connector);</span>
 extern bool radeon_dp_getdpcd(struct radeon_connector *radeon_connector);
 extern int radeon_dp_get_panel_mode(struct drm_encoder *encoder,
 				    struct drm_connector *connector);
<span class="p_del">-int radeon_dp_get_max_link_rate(struct drm_connector *connector,</span>
<span class="p_del">-				const u8 *dpcd);</span>
<span class="p_add">+extern int radeon_dp_get_dp_link_config(struct drm_connector *connector,</span>
<span class="p_add">+					const u8 *dpcd,</span>
<span class="p_add">+					unsigned pix_clock,</span>
<span class="p_add">+					unsigned *dp_lanes, unsigned *dp_rate);</span>
 extern void radeon_dp_set_rx_power_state(struct drm_connector *connector,
 					 u8 power_state);
 extern void radeon_dp_aux_init(struct radeon_connector *radeon_connector);
<span class="p_header">diff --git a/drivers/gpu/drm/radeon/radeon_ttm.c b/drivers/gpu/drm/radeon/radeon_ttm.c</span>
<span class="p_header">index f342aad79cc6..35310336dd0a 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/radeon/radeon_ttm.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/radeon/radeon_ttm.c</span>
<span class="p_chunk">@@ -263,8 +263,8 @@</span> <span class="p_context"> static int radeon_move_blit(struct ttm_buffer_object *bo,</span>
 
 	rdev = radeon_get_rdev(bo-&gt;bdev);
 	ridx = radeon_copy_ring_index(rdev);
<span class="p_del">-	old_start = old_mem-&gt;start &lt;&lt; PAGE_SHIFT;</span>
<span class="p_del">-	new_start = new_mem-&gt;start &lt;&lt; PAGE_SHIFT;</span>
<span class="p_add">+	old_start = (u64)old_mem-&gt;start &lt;&lt; PAGE_SHIFT;</span>
<span class="p_add">+	new_start = (u64)new_mem-&gt;start &lt;&lt; PAGE_SHIFT;</span>
 
 	switch (old_mem-&gt;mem_type) {
 	case TTM_PL_VRAM:
<span class="p_header">diff --git a/drivers/hid/hid-core.c b/drivers/hid/hid-core.c</span>
<span class="p_header">index ec791e169f8f..936960202cf4 100644</span>
<span class="p_header">--- a/drivers/hid/hid-core.c</span>
<span class="p_header">+++ b/drivers/hid/hid-core.c</span>
<span class="p_chunk">@@ -1251,6 +1251,7 @@</span> <span class="p_context"> static void hid_input_field(struct hid_device *hid, struct hid_field *field,</span>
 		/* Ignore report if ErrorRollOver */
 		if (!(field-&gt;flags &amp; HID_MAIN_ITEM_VARIABLE) &amp;&amp;
 		    value[n] &gt;= min &amp;&amp; value[n] &lt;= max &amp;&amp;
<span class="p_add">+		    value[n] - min &lt; field-&gt;maxusage &amp;&amp;</span>
 		    field-&gt;usage[value[n] - min].hid == HID_UP_KEYBOARD + 1)
 			goto exit;
 	}
<span class="p_chunk">@@ -1263,11 +1264,13 @@</span> <span class="p_context"> static void hid_input_field(struct hid_device *hid, struct hid_field *field,</span>
 		}
 
 		if (field-&gt;value[n] &gt;= min &amp;&amp; field-&gt;value[n] &lt;= max
<span class="p_add">+			&amp;&amp; field-&gt;value[n] - min &lt; field-&gt;maxusage</span>
 			&amp;&amp; field-&gt;usage[field-&gt;value[n] - min].hid
 			&amp;&amp; search(value, field-&gt;value[n], count))
 				hid_process_event(hid, field, &amp;field-&gt;usage[field-&gt;value[n] - min], 0, interrupt);
 
 		if (value[n] &gt;= min &amp;&amp; value[n] &lt;= max
<span class="p_add">+			&amp;&amp; value[n] - min &lt; field-&gt;maxusage</span>
 			&amp;&amp; field-&gt;usage[value[n] - min].hid
 			&amp;&amp; search(field-&gt;value, value[n], count))
 				hid_process_event(hid, field, &amp;field-&gt;usage[value[n] - min], 1, interrupt);
<span class="p_header">diff --git a/drivers/hv/channel.c b/drivers/hv/channel.c</span>
<span class="p_header">index 9098f13f2f44..1ef37c727572 100644</span>
<span class="p_header">--- a/drivers/hv/channel.c</span>
<span class="p_header">+++ b/drivers/hv/channel.c</span>
<span class="p_chunk">@@ -28,6 +28,7 @@</span> <span class="p_context"></span>
 #include &lt;linux/module.h&gt;
 #include &lt;linux/hyperv.h&gt;
 #include &lt;linux/uio.h&gt;
<span class="p_add">+#include &lt;linux/interrupt.h&gt;</span>
 
 #include &quot;hyperv_vmbus.h&quot;
 
<span class="p_chunk">@@ -496,8 +497,21 @@</span> <span class="p_context"> static void reset_channel_cb(void *arg)</span>
 static int vmbus_close_internal(struct vmbus_channel *channel)
 {
 	struct vmbus_channel_close_channel *msg;
<span class="p_add">+	struct tasklet_struct *tasklet;</span>
 	int ret;
 
<span class="p_add">+	/*</span>
<span class="p_add">+	 * process_chn_event(), running in the tasklet, can race</span>
<span class="p_add">+	 * with vmbus_close_internal() in the case of SMP guest, e.g., when</span>
<span class="p_add">+	 * the former is accessing channel-&gt;inbound.ring_buffer, the latter</span>
<span class="p_add">+	 * could be freeing the ring_buffer pages.</span>
<span class="p_add">+	 *</span>
<span class="p_add">+	 * To resolve the race, we can serialize them by disabling the</span>
<span class="p_add">+	 * tasklet when the latter is running here.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	tasklet = hv_context.event_dpc[channel-&gt;target_cpu];</span>
<span class="p_add">+	tasklet_disable(tasklet);</span>
<span class="p_add">+</span>
 	channel-&gt;state = CHANNEL_OPEN_STATE;
 	channel-&gt;sc_creation_callback = NULL;
 	/* Stop callback and cancel the timer asap */
<span class="p_chunk">@@ -525,7 +539,7 @@</span> <span class="p_context"> static int vmbus_close_internal(struct vmbus_channel *channel)</span>
 		 * If we failed to post the close msg,
 		 * it is perhaps better to leak memory.
 		 */
<span class="p_del">-		return ret;</span>
<span class="p_add">+		goto out;</span>
 	}
 
 	/* Tear down the gpadl for the channel&#39;s ring buffer */
<span class="p_chunk">@@ -538,7 +552,7 @@</span> <span class="p_context"> static int vmbus_close_internal(struct vmbus_channel *channel)</span>
 			 * If we failed to teardown gpadl,
 			 * it is perhaps better to leak memory.
 			 */
<span class="p_del">-			return ret;</span>
<span class="p_add">+			goto out;</span>
 		}
 	}
 
<span class="p_chunk">@@ -549,12 +563,9 @@</span> <span class="p_context"> static int vmbus_close_internal(struct vmbus_channel *channel)</span>
 	free_pages((unsigned long)channel-&gt;ringbuffer_pages,
 		get_order(channel-&gt;ringbuffer_pagecount * PAGE_SIZE));
 
<span class="p_del">-	/*</span>
<span class="p_del">-	 * If the channel has been rescinded; process device removal.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	if (channel-&gt;rescind)</span>
<span class="p_del">-		hv_process_channel_removal(channel,</span>
<span class="p_del">-					   channel-&gt;offermsg.child_relid);</span>
<span class="p_add">+out:</span>
<span class="p_add">+	tasklet_enable(tasklet);</span>
<span class="p_add">+</span>
 	return ret;
 }
 
<span class="p_header">diff --git a/drivers/hv/channel_mgmt.c b/drivers/hv/channel_mgmt.c</span>
<span class="p_header">index 652afd11a9ef..37238dffd947 100644</span>
<span class="p_header">--- a/drivers/hv/channel_mgmt.c</span>
<span class="p_header">+++ b/drivers/hv/channel_mgmt.c</span>
<span class="p_chunk">@@ -28,6 +28,7 @@</span> <span class="p_context"></span>
 #include &lt;linux/list.h&gt;
 #include &lt;linux/module.h&gt;
 #include &lt;linux/completion.h&gt;
<span class="p_add">+#include &lt;linux/delay.h&gt;</span>
 #include &lt;linux/hyperv.h&gt;
 
 #include &quot;hyperv_vmbus.h&quot;
<span class="p_chunk">@@ -191,6 +192,8 @@</span> <span class="p_context"> void hv_process_channel_removal(struct vmbus_channel *channel, u32 relid)</span>
 	if (channel == NULL)
 		return;
 
<span class="p_add">+	BUG_ON(!channel-&gt;rescind);</span>
<span class="p_add">+</span>
 	if (channel-&gt;target_cpu != get_cpu()) {
 		put_cpu();
 		smp_call_function_single(channel-&gt;target_cpu,
<span class="p_chunk">@@ -230,9 +233,7 @@</span> <span class="p_context"> void vmbus_free_channels(void)</span>
 
 	list_for_each_entry_safe(channel, tmp, &amp;vmbus_connection.chn_list,
 		listentry) {
<span class="p_del">-		/* if we don&#39;t set rescind to true, vmbus_close_internal()</span>
<span class="p_del">-		 * won&#39;t invoke hv_process_channel_removal().</span>
<span class="p_del">-		 */</span>
<span class="p_add">+		/* hv_process_channel_removal() needs this */</span>
 		channel-&gt;rescind = true;
 
 		vmbus_device_unregister(channel-&gt;device_obj);
<span class="p_chunk">@@ -459,6 +460,17 @@</span> <span class="p_context"> static void init_vp_index(struct vmbus_channel *channel, const uuid_le *type_gui</span>
 		    cpumask_of_node(primary-&gt;numa_node));
 
 	cur_cpu = -1;
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Normally Hyper-V host doesn&#39;t create more subchannels than there</span>
<span class="p_add">+	 * are VCPUs on the node but it is possible when not all present VCPUs</span>
<span class="p_add">+	 * on the node are initialized by guest. Clear the alloced_cpus_in_node</span>
<span class="p_add">+	 * to start over.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	if (cpumask_equal(&amp;primary-&gt;alloced_cpus_in_node,</span>
<span class="p_add">+			  cpumask_of_node(primary-&gt;numa_node)))</span>
<span class="p_add">+		cpumask_clear(&amp;primary-&gt;alloced_cpus_in_node);</span>
<span class="p_add">+</span>
 	while (true) {
 		cur_cpu = cpumask_next(cur_cpu, &amp;available_mask);
 		if (cur_cpu &gt;= nr_cpu_ids) {
<span class="p_chunk">@@ -488,6 +500,40 @@</span> <span class="p_context"> static void init_vp_index(struct vmbus_channel *channel, const uuid_le *type_gui</span>
 	channel-&gt;target_vp = hv_context.vp_index[cur_cpu];
 }
 
<span class="p_add">+static void vmbus_wait_for_unload(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	int cpu = smp_processor_id();</span>
<span class="p_add">+	void *page_addr = hv_context.synic_message_page[cpu];</span>
<span class="p_add">+	struct hv_message *msg = (struct hv_message *)page_addr +</span>
<span class="p_add">+				  VMBUS_MESSAGE_SINT;</span>
<span class="p_add">+	struct vmbus_channel_message_header *hdr;</span>
<span class="p_add">+	bool unloaded = false;</span>
<span class="p_add">+</span>
<span class="p_add">+	while (1) {</span>
<span class="p_add">+		if (msg-&gt;header.message_type == HVMSG_NONE) {</span>
<span class="p_add">+			mdelay(10);</span>
<span class="p_add">+			continue;</span>
<span class="p_add">+		}</span>
<span class="p_add">+</span>
<span class="p_add">+		hdr = (struct vmbus_channel_message_header *)msg-&gt;u.payload;</span>
<span class="p_add">+		if (hdr-&gt;msgtype == CHANNELMSG_UNLOAD_RESPONSE)</span>
<span class="p_add">+			unloaded = true;</span>
<span class="p_add">+</span>
<span class="p_add">+		msg-&gt;header.message_type = HVMSG_NONE;</span>
<span class="p_add">+		/*</span>
<span class="p_add">+		 * header.message_type needs to be written before we do</span>
<span class="p_add">+		 * wrmsrl() below.</span>
<span class="p_add">+		 */</span>
<span class="p_add">+		mb();</span>
<span class="p_add">+</span>
<span class="p_add">+		if (msg-&gt;header.message_flags.msg_pending)</span>
<span class="p_add">+			wrmsrl(HV_X64_MSR_EOM, 0);</span>
<span class="p_add">+</span>
<span class="p_add">+		if (unloaded)</span>
<span class="p_add">+			break;</span>
<span class="p_add">+	}</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 /*
  * vmbus_unload_response - Handler for the unload response.
  */
<span class="p_chunk">@@ -513,7 +559,14 @@</span> <span class="p_context"> void vmbus_initiate_unload(void)</span>
 	hdr.msgtype = CHANNELMSG_UNLOAD;
 	vmbus_post_msg(&amp;hdr, sizeof(struct vmbus_channel_message_header));
 
<span class="p_del">-	wait_for_completion(&amp;vmbus_connection.unload_event);</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * vmbus_initiate_unload() is also called on crash and the crash can be</span>
<span class="p_add">+	 * happening in an interrupt context, where scheduling is impossible.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	if (!in_interrupt())</span>
<span class="p_add">+		wait_for_completion(&amp;vmbus_connection.unload_event);</span>
<span class="p_add">+	else</span>
<span class="p_add">+		vmbus_wait_for_unload();</span>
 }
 
 /*
<span class="p_header">diff --git a/drivers/hv/hv.c b/drivers/hv/hv.c</span>
<span class="p_header">index 6341be8739ae..63194a9a7189 100644</span>
<span class="p_header">--- a/drivers/hv/hv.c</span>
<span class="p_header">+++ b/drivers/hv/hv.c</span>
<span class="p_chunk">@@ -293,8 +293,14 @@</span> <span class="p_context"> void hv_cleanup(void)</span>
 	 * Cleanup the TSC page based CS.
 	 */
 	if (ms_hyperv.features &amp; HV_X64_MSR_REFERENCE_TSC_AVAILABLE) {
<span class="p_del">-		clocksource_change_rating(&amp;hyperv_cs_tsc, 10);</span>
<span class="p_del">-		clocksource_unregister(&amp;hyperv_cs_tsc);</span>
<span class="p_add">+		/*</span>
<span class="p_add">+		 * Crash can happen in an interrupt context and unregistering</span>
<span class="p_add">+		 * a clocksource is impossible and redundant in this case.</span>
<span class="p_add">+		 */</span>
<span class="p_add">+		if (!oops_in_progress) {</span>
<span class="p_add">+			clocksource_change_rating(&amp;hyperv_cs_tsc, 10);</span>
<span class="p_add">+			clocksource_unregister(&amp;hyperv_cs_tsc);</span>
<span class="p_add">+		}</span>
 
 		hypercall_msr.as_uint64 = 0;
 		wrmsrl(HV_X64_MSR_REFERENCE_TSC, hypercall_msr.as_uint64);
<span class="p_header">diff --git a/drivers/hv/hv_fcopy.c b/drivers/hv/hv_fcopy.c</span>
<span class="p_header">index db4b887b889d..c37a71e13de0 100644</span>
<span class="p_header">--- a/drivers/hv/hv_fcopy.c</span>
<span class="p_header">+++ b/drivers/hv/hv_fcopy.c</span>
<span class="p_chunk">@@ -51,7 +51,6 @@</span> <span class="p_context"> static struct {</span>
 	struct hv_fcopy_hdr  *fcopy_msg; /* current message */
 	struct vmbus_channel *recv_channel; /* chn we got the request */
 	u64 recv_req_id; /* request ID. */
<span class="p_del">-	void *fcopy_context; /* for the channel callback */</span>
 } fcopy_transaction;
 
 static void fcopy_respond_to_host(int error);
<span class="p_chunk">@@ -67,6 +66,13 @@</span> <span class="p_context"> static struct hvutil_transport *hvt;</span>
  */
 static int dm_reg_value;
 
<span class="p_add">+static void fcopy_poll_wrapper(void *channel)</span>
<span class="p_add">+{</span>
<span class="p_add">+	/* Transaction is finished, reset the state here to avoid races. */</span>
<span class="p_add">+	fcopy_transaction.state = HVUTIL_READY;</span>
<span class="p_add">+	hv_fcopy_onchannelcallback(channel);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static void fcopy_timeout_func(struct work_struct *dummy)
 {
 	/*
<span class="p_chunk">@@ -74,13 +80,7 @@</span> <span class="p_context"> static void fcopy_timeout_func(struct work_struct *dummy)</span>
 	 * process the pending transaction.
 	 */
 	fcopy_respond_to_host(HV_E_FAIL);
<span class="p_del">-</span>
<span class="p_del">-	/* Transaction is finished, reset the state. */</span>
<span class="p_del">-	if (fcopy_transaction.state &gt; HVUTIL_READY)</span>
<span class="p_del">-		fcopy_transaction.state = HVUTIL_READY;</span>
<span class="p_del">-</span>
<span class="p_del">-	hv_poll_channel(fcopy_transaction.fcopy_context,</span>
<span class="p_del">-			hv_fcopy_onchannelcallback);</span>
<span class="p_add">+	hv_poll_channel(fcopy_transaction.recv_channel, fcopy_poll_wrapper);</span>
 }
 
 static int fcopy_handle_handshake(u32 version)
<span class="p_chunk">@@ -108,9 +108,7 @@</span> <span class="p_context"> static int fcopy_handle_handshake(u32 version)</span>
 		return -EINVAL;
 	}
 	pr_debug(&quot;FCP: userspace daemon ver. %d registered\n&quot;, version);
<span class="p_del">-	fcopy_transaction.state = HVUTIL_READY;</span>
<span class="p_del">-	hv_poll_channel(fcopy_transaction.fcopy_context,</span>
<span class="p_del">-			hv_fcopy_onchannelcallback);</span>
<span class="p_add">+	hv_poll_channel(fcopy_transaction.recv_channel, fcopy_poll_wrapper);</span>
 	return 0;
 }
 
<span class="p_chunk">@@ -227,15 +225,8 @@</span> <span class="p_context"> void hv_fcopy_onchannelcallback(void *context)</span>
 	int util_fw_version;
 	int fcopy_srv_version;
 
<span class="p_del">-	if (fcopy_transaction.state &gt; HVUTIL_READY) {</span>
<span class="p_del">-		/*</span>
<span class="p_del">-		 * We will defer processing this callback once</span>
<span class="p_del">-		 * the current transaction is complete.</span>
<span class="p_del">-		 */</span>
<span class="p_del">-		fcopy_transaction.fcopy_context = context;</span>
<span class="p_add">+	if (fcopy_transaction.state &gt; HVUTIL_READY)</span>
 		return;
<span class="p_del">-	}</span>
<span class="p_del">-	fcopy_transaction.fcopy_context = NULL;</span>
 
 	vmbus_recvpacket(channel, recv_buffer, PAGE_SIZE * 2, &amp;recvlen,
 			 &amp;requestid);
<span class="p_chunk">@@ -275,7 +266,8 @@</span> <span class="p_context"> void hv_fcopy_onchannelcallback(void *context)</span>
 		 * Send the information to the user-level daemon.
 		 */
 		schedule_work(&amp;fcopy_send_work);
<span class="p_del">-		schedule_delayed_work(&amp;fcopy_timeout_work, 5*HZ);</span>
<span class="p_add">+		schedule_delayed_work(&amp;fcopy_timeout_work,</span>
<span class="p_add">+				      HV_UTIL_TIMEOUT * HZ);</span>
 		return;
 	}
 	icmsghdr-&gt;icflags = ICMSGHDRFLAG_TRANSACTION | ICMSGHDRFLAG_RESPONSE;
<span class="p_chunk">@@ -304,9 +296,8 @@</span> <span class="p_context"> static int fcopy_on_msg(void *msg, int len)</span>
 	if (cancel_delayed_work_sync(&amp;fcopy_timeout_work)) {
 		fcopy_transaction.state = HVUTIL_USERSPACE_RECV;
 		fcopy_respond_to_host(*val);
<span class="p_del">-		fcopy_transaction.state = HVUTIL_READY;</span>
<span class="p_del">-		hv_poll_channel(fcopy_transaction.fcopy_context,</span>
<span class="p_del">-				hv_fcopy_onchannelcallback);</span>
<span class="p_add">+		hv_poll_channel(fcopy_transaction.recv_channel,</span>
<span class="p_add">+				fcopy_poll_wrapper);</span>
 	}
 
 	return 0;
<span class="p_header">diff --git a/drivers/hv/hv_kvp.c b/drivers/hv/hv_kvp.c</span>
<span class="p_header">index 74c38a9f34a6..2a3420c4ca59 100644</span>
<span class="p_header">--- a/drivers/hv/hv_kvp.c</span>
<span class="p_header">+++ b/drivers/hv/hv_kvp.c</span>
<span class="p_chunk">@@ -66,7 +66,6 @@</span> <span class="p_context"> static struct {</span>
 	struct hv_kvp_msg  *kvp_msg; /* current message */
 	struct vmbus_channel *recv_channel; /* chn we got the request */
 	u64 recv_req_id; /* request ID. */
<span class="p_del">-	void *kvp_context; /* for the channel callback */</span>
 } kvp_transaction;
 
 /*
<span class="p_chunk">@@ -94,6 +93,13 @@</span> <span class="p_context"> static struct hvutil_transport *hvt;</span>
  */
 #define HV_DRV_VERSION           &quot;3.1&quot;
 
<span class="p_add">+static void kvp_poll_wrapper(void *channel)</span>
<span class="p_add">+{</span>
<span class="p_add">+	/* Transaction is finished, reset the state here to avoid races. */</span>
<span class="p_add">+	kvp_transaction.state = HVUTIL_READY;</span>
<span class="p_add">+	hv_kvp_onchannelcallback(channel);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static void
 kvp_register(int reg_value)
 {
<span class="p_chunk">@@ -121,12 +127,7 @@</span> <span class="p_context"> static void kvp_timeout_func(struct work_struct *dummy)</span>
 	 */
 	kvp_respond_to_host(NULL, HV_E_FAIL);
 
<span class="p_del">-	/* Transaction is finished, reset the state. */</span>
<span class="p_del">-	if (kvp_transaction.state &gt; HVUTIL_READY)</span>
<span class="p_del">-		kvp_transaction.state = HVUTIL_READY;</span>
<span class="p_del">-</span>
<span class="p_del">-	hv_poll_channel(kvp_transaction.kvp_context,</span>
<span class="p_del">-			hv_kvp_onchannelcallback);</span>
<span class="p_add">+	hv_poll_channel(kvp_transaction.recv_channel, kvp_poll_wrapper);</span>
 }
 
 static int kvp_handle_handshake(struct hv_kvp_msg *msg)
<span class="p_chunk">@@ -218,9 +219,7 @@</span> <span class="p_context"> static int kvp_on_msg(void *msg, int len)</span>
 	 */
 	if (cancel_delayed_work_sync(&amp;kvp_timeout_work)) {
 		kvp_respond_to_host(message, error);
<span class="p_del">-		kvp_transaction.state = HVUTIL_READY;</span>
<span class="p_del">-		hv_poll_channel(kvp_transaction.kvp_context,</span>
<span class="p_del">-				hv_kvp_onchannelcallback);</span>
<span class="p_add">+		hv_poll_channel(kvp_transaction.recv_channel, kvp_poll_wrapper);</span>
 	}
 
 	return 0;
<span class="p_chunk">@@ -596,15 +595,8 @@</span> <span class="p_context"> void hv_kvp_onchannelcallback(void *context)</span>
 	int util_fw_version;
 	int kvp_srv_version;
 
<span class="p_del">-	if (kvp_transaction.state &gt; HVUTIL_READY) {</span>
<span class="p_del">-		/*</span>
<span class="p_del">-		 * We will defer processing this callback once</span>
<span class="p_del">-		 * the current transaction is complete.</span>
<span class="p_del">-		 */</span>
<span class="p_del">-		kvp_transaction.kvp_context = context;</span>
<span class="p_add">+	if (kvp_transaction.state &gt; HVUTIL_READY)</span>
 		return;
<span class="p_del">-	}</span>
<span class="p_del">-	kvp_transaction.kvp_context = NULL;</span>
 
 	vmbus_recvpacket(channel, recv_buffer, PAGE_SIZE * 4, &amp;recvlen,
 			 &amp;requestid);
<span class="p_chunk">@@ -668,7 +660,8 @@</span> <span class="p_context"> void hv_kvp_onchannelcallback(void *context)</span>
 			 * user-mode not responding.
 			 */
 			schedule_work(&amp;kvp_sendkey_work);
<span class="p_del">-			schedule_delayed_work(&amp;kvp_timeout_work, 5*HZ);</span>
<span class="p_add">+			schedule_delayed_work(&amp;kvp_timeout_work,</span>
<span class="p_add">+					      HV_UTIL_TIMEOUT * HZ);</span>
 
 			return;
 
<span class="p_header">diff --git a/drivers/hv/hv_snapshot.c b/drivers/hv/hv_snapshot.c</span>
<span class="p_header">index 815405f2e777..81882d4848bd 100644</span>
<span class="p_header">--- a/drivers/hv/hv_snapshot.c</span>
<span class="p_header">+++ b/drivers/hv/hv_snapshot.c</span>
<span class="p_chunk">@@ -53,7 +53,6 @@</span> <span class="p_context"> static struct {</span>
 	struct vmbus_channel *recv_channel; /* chn we got the request */
 	u64 recv_req_id; /* request ID. */
 	struct hv_vss_msg  *msg; /* current message */
<span class="p_del">-	void *vss_context; /* for the channel callback */</span>
 } vss_transaction;
 
 
<span class="p_chunk">@@ -74,6 +73,13 @@</span> <span class="p_context"> static void vss_timeout_func(struct work_struct *dummy);</span>
 static DECLARE_DELAYED_WORK(vss_timeout_work, vss_timeout_func);
 static DECLARE_WORK(vss_send_op_work, vss_send_op);
 
<span class="p_add">+static void vss_poll_wrapper(void *channel)</span>
<span class="p_add">+{</span>
<span class="p_add">+	/* Transaction is finished, reset the state here to avoid races. */</span>
<span class="p_add">+	vss_transaction.state = HVUTIL_READY;</span>
<span class="p_add">+	hv_vss_onchannelcallback(channel);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 /*
  * Callback when data is received from user mode.
  */
<span class="p_chunk">@@ -86,12 +92,7 @@</span> <span class="p_context"> static void vss_timeout_func(struct work_struct *dummy)</span>
 	pr_warn(&quot;VSS: timeout waiting for daemon to reply\n&quot;);
 	vss_respond_to_host(HV_E_FAIL);
 
<span class="p_del">-	/* Transaction is finished, reset the state. */</span>
<span class="p_del">-	if (vss_transaction.state &gt; HVUTIL_READY)</span>
<span class="p_del">-		vss_transaction.state = HVUTIL_READY;</span>
<span class="p_del">-</span>
<span class="p_del">-	hv_poll_channel(vss_transaction.vss_context,</span>
<span class="p_del">-			hv_vss_onchannelcallback);</span>
<span class="p_add">+	hv_poll_channel(vss_transaction.recv_channel, vss_poll_wrapper);</span>
 }
 
 static int vss_handle_handshake(struct hv_vss_msg *vss_msg)
<span class="p_chunk">@@ -138,9 +139,8 @@</span> <span class="p_context"> static int vss_on_msg(void *msg, int len)</span>
 		if (cancel_delayed_work_sync(&amp;vss_timeout_work)) {
 			vss_respond_to_host(vss_msg-&gt;error);
 			/* Transaction is finished, reset the state. */
<span class="p_del">-			vss_transaction.state = HVUTIL_READY;</span>
<span class="p_del">-			hv_poll_channel(vss_transaction.vss_context,</span>
<span class="p_del">-					hv_vss_onchannelcallback);</span>
<span class="p_add">+			hv_poll_channel(vss_transaction.recv_channel,</span>
<span class="p_add">+					vss_poll_wrapper);</span>
 		}
 	} else {
 		/* This is a spurious call! */
<span class="p_chunk">@@ -238,15 +238,8 @@</span> <span class="p_context"> void hv_vss_onchannelcallback(void *context)</span>
 	struct icmsg_hdr *icmsghdrp;
 	struct icmsg_negotiate *negop = NULL;
 
<span class="p_del">-	if (vss_transaction.state &gt; HVUTIL_READY) {</span>
<span class="p_del">-		/*</span>
<span class="p_del">-		 * We will defer processing this callback once</span>
<span class="p_del">-		 * the current transaction is complete.</span>
<span class="p_del">-		 */</span>
<span class="p_del">-		vss_transaction.vss_context = context;</span>
<span class="p_add">+	if (vss_transaction.state &gt; HVUTIL_READY)</span>
 		return;
<span class="p_del">-	}</span>
<span class="p_del">-	vss_transaction.vss_context = NULL;</span>
 
 	vmbus_recvpacket(channel, recv_buffer, PAGE_SIZE * 2, &amp;recvlen,
 			 &amp;requestid);
<span class="p_chunk">@@ -338,6 +331,11 @@</span> <span class="p_context"> static void vss_on_reset(void)</span>
 int
 hv_vss_init(struct hv_util_service *srv)
 {
<span class="p_add">+	if (vmbus_proto_version &lt; VERSION_WIN8_1) {</span>
<span class="p_add">+		pr_warn(&quot;Integration service &#39;Backup (volume snapshot)&#39;&quot;</span>
<span class="p_add">+			&quot; not supported on this host version.\n&quot;);</span>
<span class="p_add">+		return -ENOTSUPP;</span>
<span class="p_add">+	}</span>
 	recv_buffer = srv-&gt;recv_buffer;
 
 	/*
<span class="p_header">diff --git a/drivers/hv/hv_utils_transport.c b/drivers/hv/hv_utils_transport.c</span>
<span class="p_header">index 6a9d80a5332d..1505ee6e6605 100644</span>
<span class="p_header">--- a/drivers/hv/hv_utils_transport.c</span>
<span class="p_header">+++ b/drivers/hv/hv_utils_transport.c</span>
<span class="p_chunk">@@ -204,9 +204,12 @@</span> <span class="p_context"> int hvutil_transport_send(struct hvutil_transport *hvt, void *msg, int len)</span>
 		goto out_unlock;
 	}
 	hvt-&gt;outmsg = kzalloc(len, GFP_KERNEL);
<span class="p_del">-	memcpy(hvt-&gt;outmsg, msg, len);</span>
<span class="p_del">-	hvt-&gt;outmsg_len = len;</span>
<span class="p_del">-	wake_up_interruptible(&amp;hvt-&gt;outmsg_q);</span>
<span class="p_add">+	if (hvt-&gt;outmsg) {</span>
<span class="p_add">+		memcpy(hvt-&gt;outmsg, msg, len);</span>
<span class="p_add">+		hvt-&gt;outmsg_len = len;</span>
<span class="p_add">+		wake_up_interruptible(&amp;hvt-&gt;outmsg_q);</span>
<span class="p_add">+	} else</span>
<span class="p_add">+		ret = -ENOMEM;</span>
 out_unlock:
 	mutex_unlock(&amp;hvt-&gt;outmsg_lock);
 	return ret;
<span class="p_header">diff --git a/drivers/hv/hyperv_vmbus.h b/drivers/hv/hyperv_vmbus.h</span>
<span class="p_header">index 3782636562a1..12156db2e88e 100644</span>
<span class="p_header">--- a/drivers/hv/hyperv_vmbus.h</span>
<span class="p_header">+++ b/drivers/hv/hyperv_vmbus.h</span>
<span class="p_chunk">@@ -31,6 +31,11 @@</span> <span class="p_context"></span>
 #include &lt;linux/hyperv.h&gt;
 
 /*
<span class="p_add">+ * Timeout for services such as KVP and fcopy.</span>
<span class="p_add">+ */</span>
<span class="p_add">+#define HV_UTIL_TIMEOUT 30</span>
<span class="p_add">+</span>
<span class="p_add">+/*</span>
  * The below CPUID leaves are present if VersionAndFeatures.HypervisorPresent
  * is set by CPUID(HVCPUID_VERSION_FEATURES).
  */
<span class="p_chunk">@@ -759,11 +764,7 @@</span> <span class="p_context"> static inline void hv_poll_channel(struct vmbus_channel *channel,</span>
 	if (!channel)
 		return;
 
<span class="p_del">-	if (channel-&gt;target_cpu != smp_processor_id())</span>
<span class="p_del">-		smp_call_function_single(channel-&gt;target_cpu,</span>
<span class="p_del">-					 cb, channel, true);</span>
<span class="p_del">-	else</span>
<span class="p_del">-		cb(channel);</span>
<span class="p_add">+	smp_call_function_single(channel-&gt;target_cpu, cb, channel, true);</span>
 }
 
 enum hvutil_device_state {
<span class="p_header">diff --git a/drivers/hv/vmbus_drv.c b/drivers/hv/vmbus_drv.c</span>
<span class="p_header">index 9b5440f6b3b4..509ed9731630 100644</span>
<span class="p_header">--- a/drivers/hv/vmbus_drv.c</span>
<span class="p_header">+++ b/drivers/hv/vmbus_drv.c</span>
<span class="p_chunk">@@ -105,6 +105,7 @@</span> <span class="p_context"> static struct notifier_block hyperv_panic_block = {</span>
 };
 
 struct resource *hyperv_mmio;
<span class="p_add">+DEFINE_SEMAPHORE(hyperv_mmio_lock);</span>
 
 static int vmbus_exists(void)
 {
<span class="p_chunk">@@ -603,23 +604,11 @@</span> <span class="p_context"> static int vmbus_remove(struct device *child_device)</span>
 {
 	struct hv_driver *drv;
 	struct hv_device *dev = device_to_hv_device(child_device);
<span class="p_del">-	u32 relid = dev-&gt;channel-&gt;offermsg.child_relid;</span>
 
 	if (child_device-&gt;driver) {
 		drv = drv_to_hv_drv(child_device-&gt;driver);
 		if (drv-&gt;remove)
 			drv-&gt;remove(dev);
<span class="p_del">-		else {</span>
<span class="p_del">-			hv_process_channel_removal(dev-&gt;channel, relid);</span>
<span class="p_del">-			pr_err(&quot;remove not set for driver %s\n&quot;,</span>
<span class="p_del">-				dev_name(child_device));</span>
<span class="p_del">-		}</span>
<span class="p_del">-	} else {</span>
<span class="p_del">-		/*</span>
<span class="p_del">-		 * We don&#39;t have a driver for this device; deal with the</span>
<span class="p_del">-		 * rescind message by removing the channel.</span>
<span class="p_del">-		 */</span>
<span class="p_del">-		hv_process_channel_removal(dev-&gt;channel, relid);</span>
 	}
 
 	return 0;
<span class="p_chunk">@@ -654,7 +643,10 @@</span> <span class="p_context"> static void vmbus_shutdown(struct device *child_device)</span>
 static void vmbus_device_release(struct device *device)
 {
 	struct hv_device *hv_dev = device_to_hv_device(device);
<span class="p_add">+	struct vmbus_channel *channel = hv_dev-&gt;channel;</span>
 
<span class="p_add">+	hv_process_channel_removal(channel,</span>
<span class="p_add">+				   channel-&gt;offermsg.child_relid);</span>
 	kfree(hv_dev);
 
 }
<span class="p_chunk">@@ -870,7 +862,7 @@</span> <span class="p_context"> static int vmbus_bus_init(int irq)</span>
 	on_each_cpu(hv_synic_init, NULL, 1);
 	ret = vmbus_connect();
 	if (ret)
<span class="p_del">-		goto err_alloc;</span>
<span class="p_add">+		goto err_connect;</span>
 
 	if (vmbus_proto_version &gt; VERSION_WIN7)
 		cpu_hotplug_disable();
<span class="p_chunk">@@ -888,6 +880,8 @@</span> <span class="p_context"> static int vmbus_bus_init(int irq)</span>
 
 	return 0;
 
<span class="p_add">+err_connect:</span>
<span class="p_add">+	on_each_cpu(hv_synic_cleanup, NULL, 1);</span>
 err_alloc:
 	hv_synic_free();
 	hv_remove_vmbus_irq();
<span class="p_chunk">@@ -1147,7 +1141,10 @@</span> <span class="p_context"> int vmbus_allocate_mmio(struct resource **new, struct hv_device *device_obj,</span>
 	resource_size_t range_min, range_max, start, local_min, local_max;
 	const char *dev_n = dev_name(&amp;device_obj-&gt;device);
 	u32 fb_end = screen_info.lfb_base + (screen_info.lfb_size &lt;&lt; 1);
<span class="p_del">-	int i;</span>
<span class="p_add">+	int i, retval;</span>
<span class="p_add">+</span>
<span class="p_add">+	retval = -ENXIO;</span>
<span class="p_add">+	down(&amp;hyperv_mmio_lock);</span>
 
 	for (iter = hyperv_mmio; iter; iter = iter-&gt;sibling) {
 		if ((iter-&gt;start &gt;= max) || (iter-&gt;end &lt;= min))
<span class="p_chunk">@@ -1184,13 +1181,17 @@</span> <span class="p_context"> int vmbus_allocate_mmio(struct resource **new, struct hv_device *device_obj,</span>
 			for (; start + size - 1 &lt;= local_max; start += align) {
 				*new = request_mem_region_exclusive(start, size,
 								    dev_n);
<span class="p_del">-				if (*new)</span>
<span class="p_del">-					return 0;</span>
<span class="p_add">+				if (*new) {</span>
<span class="p_add">+					retval = 0;</span>
<span class="p_add">+					goto exit;</span>
<span class="p_add">+				}</span>
 			}
 		}
 	}
 
<span class="p_del">-	return -ENXIO;</span>
<span class="p_add">+exit:</span>
<span class="p_add">+	up(&amp;hyperv_mmio_lock);</span>
<span class="p_add">+	return retval;</span>
 }
 EXPORT_SYMBOL_GPL(vmbus_allocate_mmio);
 
<span class="p_header">diff --git a/drivers/idle/intel_idle.c b/drivers/idle/intel_idle.c</span>
<span class="p_header">index 146eed70bdf4..ba947df5a8c7 100644</span>
<span class="p_header">--- a/drivers/idle/intel_idle.c</span>
<span class="p_header">+++ b/drivers/idle/intel_idle.c</span>
<span class="p_chunk">@@ -716,6 +716,26 @@</span> <span class="p_context"> static struct cpuidle_state avn_cstates[] = {</span>
 	{
 		.enter = NULL }
 };
<span class="p_add">+static struct cpuidle_state knl_cstates[] = {</span>
<span class="p_add">+	{</span>
<span class="p_add">+		.name = &quot;C1-KNL&quot;,</span>
<span class="p_add">+		.desc = &quot;MWAIT 0x00&quot;,</span>
<span class="p_add">+		.flags = MWAIT2flg(0x00),</span>
<span class="p_add">+		.exit_latency = 1,</span>
<span class="p_add">+		.target_residency = 2,</span>
<span class="p_add">+		.enter = &amp;intel_idle,</span>
<span class="p_add">+		.enter_freeze = intel_idle_freeze },</span>
<span class="p_add">+	{</span>
<span class="p_add">+		.name = &quot;C6-KNL&quot;,</span>
<span class="p_add">+		.desc = &quot;MWAIT 0x10&quot;,</span>
<span class="p_add">+		.flags = MWAIT2flg(0x10) | CPUIDLE_FLAG_TLB_FLUSHED,</span>
<span class="p_add">+		.exit_latency = 120,</span>
<span class="p_add">+		.target_residency = 500,</span>
<span class="p_add">+		.enter = &amp;intel_idle,</span>
<span class="p_add">+		.enter_freeze = intel_idle_freeze },</span>
<span class="p_add">+	{</span>
<span class="p_add">+		.enter = NULL }</span>
<span class="p_add">+};</span>
 
 /**
  * intel_idle
<span class="p_chunk">@@ -890,6 +910,10 @@</span> <span class="p_context"> static const struct idle_cpu idle_cpu_avn = {</span>
 	.disable_promotion_to_c1e = true,
 };
 
<span class="p_add">+static const struct idle_cpu idle_cpu_knl = {</span>
<span class="p_add">+	.state_table = knl_cstates,</span>
<span class="p_add">+};</span>
<span class="p_add">+</span>
 #define ICPU(model, cpu) \
 	{ X86_VENDOR_INTEL, 6, model, X86_FEATURE_MWAIT, (unsigned long)&amp;cpu }
 
<span class="p_chunk">@@ -921,6 +945,7 @@</span> <span class="p_context"> static const struct x86_cpu_id intel_idle_ids[] __initconst = {</span>
 	ICPU(0x56, idle_cpu_bdw),
 	ICPU(0x4e, idle_cpu_skl),
 	ICPU(0x5e, idle_cpu_skl),
<span class="p_add">+	ICPU(0x57, idle_cpu_knl),</span>
 	{}
 };
 MODULE_DEVICE_TABLE(x86cpu, intel_idle_ids);
<span class="p_header">diff --git a/drivers/infiniband/ulp/ipoib/ipoib_ib.c b/drivers/infiniband/ulp/ipoib/ipoib_ib.c</span>
<span class="p_header">index 5ea0c14070d1..fa9c42ff1fb0 100644</span>
<span class="p_header">--- a/drivers/infiniband/ulp/ipoib/ipoib_ib.c</span>
<span class="p_header">+++ b/drivers/infiniband/ulp/ipoib/ipoib_ib.c</span>
<span class="p_chunk">@@ -245,8 +245,6 @@</span> <span class="p_context"> static void ipoib_ib_handle_rx_wc(struct net_device *dev, struct ib_wc *wc)</span>
 	skb_reset_mac_header(skb);
 	skb_pull(skb, IPOIB_ENCAP_LEN);
 
<span class="p_del">-	skb-&gt;truesize = SKB_TRUESIZE(skb-&gt;len);</span>
<span class="p_del">-</span>
 	++dev-&gt;stats.rx_packets;
 	dev-&gt;stats.rx_bytes += skb-&gt;len;
 
<span class="p_header">diff --git a/drivers/input/joystick/xpad.c b/drivers/input/joystick/xpad.c</span>
<span class="p_header">index 2b2f9d66c2c7..aff42d5e2296 100644</span>
<span class="p_header">--- a/drivers/input/joystick/xpad.c</span>
<span class="p_header">+++ b/drivers/input/joystick/xpad.c</span>
<span class="p_chunk">@@ -317,6 +317,19 @@</span> <span class="p_context"> static struct usb_device_id xpad_table[] = {</span>
 
 MODULE_DEVICE_TABLE(usb, xpad_table);
 
<span class="p_add">+struct xpad_output_packet {</span>
<span class="p_add">+	u8 data[XPAD_PKT_LEN];</span>
<span class="p_add">+	u8 len;</span>
<span class="p_add">+	bool pending;</span>
<span class="p_add">+};</span>
<span class="p_add">+</span>
<span class="p_add">+#define XPAD_OUT_CMD_IDX	0</span>
<span class="p_add">+#define XPAD_OUT_FF_IDX		1</span>
<span class="p_add">+#define XPAD_OUT_LED_IDX	(1 + IS_ENABLED(CONFIG_JOYSTICK_XPAD_FF))</span>
<span class="p_add">+#define XPAD_NUM_OUT_PACKETS	(1 + \</span>
<span class="p_add">+				 IS_ENABLED(CONFIG_JOYSTICK_XPAD_FF) + \</span>
<span class="p_add">+				 IS_ENABLED(CONFIG_JOYSTICK_XPAD_LEDS))</span>
<span class="p_add">+</span>
 struct usb_xpad {
 	struct input_dev *dev;		/* input device interface */
 	struct usb_device *udev;	/* usb device */
<span class="p_chunk">@@ -329,9 +342,13 @@</span> <span class="p_context"> struct usb_xpad {</span>
 	dma_addr_t idata_dma;
 
 	struct urb *irq_out;		/* urb for interrupt out report */
<span class="p_add">+	bool irq_out_active;		/* we must not use an active URB */</span>
 	unsigned char *odata;		/* output data */
 	dma_addr_t odata_dma;
<span class="p_del">-	struct mutex odata_mutex;</span>
<span class="p_add">+	spinlock_t odata_lock;</span>
<span class="p_add">+</span>
<span class="p_add">+	struct xpad_output_packet out_packets[XPAD_NUM_OUT_PACKETS];</span>
<span class="p_add">+	int last_out_packet;</span>
 
 #if defined(CONFIG_JOYSTICK_XPAD_LEDS)
 	struct xpad_led *led;
<span class="p_chunk">@@ -678,18 +695,71 @@</span> <span class="p_context"> exit:</span>
 			__func__, retval);
 }
 
<span class="p_add">+/* Callers must hold xpad-&gt;odata_lock spinlock */</span>
<span class="p_add">+static bool xpad_prepare_next_out_packet(struct usb_xpad *xpad)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct xpad_output_packet *pkt, *packet = NULL;</span>
<span class="p_add">+	int i;</span>
<span class="p_add">+</span>
<span class="p_add">+	for (i = 0; i &lt; XPAD_NUM_OUT_PACKETS; i++) {</span>
<span class="p_add">+		if (++xpad-&gt;last_out_packet &gt;= XPAD_NUM_OUT_PACKETS)</span>
<span class="p_add">+			xpad-&gt;last_out_packet = 0;</span>
<span class="p_add">+</span>
<span class="p_add">+		pkt = &amp;xpad-&gt;out_packets[xpad-&gt;last_out_packet];</span>
<span class="p_add">+		if (pkt-&gt;pending) {</span>
<span class="p_add">+			dev_dbg(&amp;xpad-&gt;intf-&gt;dev,</span>
<span class="p_add">+				&quot;%s - found pending output packet %d\n&quot;,</span>
<span class="p_add">+				__func__, xpad-&gt;last_out_packet);</span>
<span class="p_add">+			packet = pkt;</span>
<span class="p_add">+			break;</span>
<span class="p_add">+		}</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	if (packet) {</span>
<span class="p_add">+		memcpy(xpad-&gt;odata, packet-&gt;data, packet-&gt;len);</span>
<span class="p_add">+		xpad-&gt;irq_out-&gt;transfer_buffer_length = packet-&gt;len;</span>
<span class="p_add">+		packet-&gt;pending = false;</span>
<span class="p_add">+		return true;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	return false;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+/* Callers must hold xpad-&gt;odata_lock spinlock */</span>
<span class="p_add">+static int xpad_try_sending_next_out_packet(struct usb_xpad *xpad)</span>
<span class="p_add">+{</span>
<span class="p_add">+	int error;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (!xpad-&gt;irq_out_active &amp;&amp; xpad_prepare_next_out_packet(xpad)) {</span>
<span class="p_add">+		error = usb_submit_urb(xpad-&gt;irq_out, GFP_ATOMIC);</span>
<span class="p_add">+		if (error) {</span>
<span class="p_add">+			dev_err(&amp;xpad-&gt;intf-&gt;dev,</span>
<span class="p_add">+				&quot;%s - usb_submit_urb failed with result %d\n&quot;,</span>
<span class="p_add">+				__func__, error);</span>
<span class="p_add">+			return -EIO;</span>
<span class="p_add">+		}</span>
<span class="p_add">+</span>
<span class="p_add">+		xpad-&gt;irq_out_active = true;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	return 0;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static void xpad_irq_out(struct urb *urb)
 {
 	struct usb_xpad *xpad = urb-&gt;context;
 	struct device *dev = &amp;xpad-&gt;intf-&gt;dev;
<span class="p_del">-	int retval, status;</span>
<span class="p_add">+	int status = urb-&gt;status;</span>
<span class="p_add">+	int error;</span>
<span class="p_add">+	unsigned long flags;</span>
 
<span class="p_del">-	status = urb-&gt;status;</span>
<span class="p_add">+	spin_lock_irqsave(&amp;xpad-&gt;odata_lock, flags);</span>
 
 	switch (status) {
 	case 0:
 		/* success */
<span class="p_del">-		return;</span>
<span class="p_add">+		xpad-&gt;irq_out_active = xpad_prepare_next_out_packet(xpad);</span>
<span class="p_add">+		break;</span>
 
 	case -ECONNRESET:
 	case -ENOENT:
<span class="p_chunk">@@ -697,19 +767,26 @@</span> <span class="p_context"> static void xpad_irq_out(struct urb *urb)</span>
 		/* this urb is terminated, clean up */
 		dev_dbg(dev, &quot;%s - urb shutting down with status: %d\n&quot;,
 			__func__, status);
<span class="p_del">-		return;</span>
<span class="p_add">+		xpad-&gt;irq_out_active = false;</span>
<span class="p_add">+		break;</span>
 
 	default:
 		dev_dbg(dev, &quot;%s - nonzero urb status received: %d\n&quot;,
 			__func__, status);
<span class="p_del">-		goto exit;</span>
<span class="p_add">+		break;</span>
 	}
 
<span class="p_del">-exit:</span>
<span class="p_del">-	retval = usb_submit_urb(urb, GFP_ATOMIC);</span>
<span class="p_del">-	if (retval)</span>
<span class="p_del">-		dev_err(dev, &quot;%s - usb_submit_urb failed with result %d\n&quot;,</span>
<span class="p_del">-			__func__, retval);</span>
<span class="p_add">+	if (xpad-&gt;irq_out_active) {</span>
<span class="p_add">+		error = usb_submit_urb(urb, GFP_ATOMIC);</span>
<span class="p_add">+		if (error) {</span>
<span class="p_add">+			dev_err(dev,</span>
<span class="p_add">+				&quot;%s - usb_submit_urb failed with result %d\n&quot;,</span>
<span class="p_add">+				__func__, error);</span>
<span class="p_add">+			xpad-&gt;irq_out_active = false;</span>
<span class="p_add">+		}</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	spin_unlock_irqrestore(&amp;xpad-&gt;odata_lock, flags);</span>
 }
 
 static int xpad_init_output(struct usb_interface *intf, struct usb_xpad *xpad)
<span class="p_chunk">@@ -728,7 +805,7 @@</span> <span class="p_context"> static int xpad_init_output(struct usb_interface *intf, struct usb_xpad *xpad)</span>
 		goto fail1;
 	}
 
<span class="p_del">-	mutex_init(&amp;xpad-&gt;odata_mutex);</span>
<span class="p_add">+	spin_lock_init(&amp;xpad-&gt;odata_lock);</span>
 
 	xpad-&gt;irq_out = usb_alloc_urb(0, GFP_KERNEL);
 	if (!xpad-&gt;irq_out) {
<span class="p_chunk">@@ -770,27 +847,57 @@</span> <span class="p_context"> static void xpad_deinit_output(struct usb_xpad *xpad)</span>
 
 static int xpad_inquiry_pad_presence(struct usb_xpad *xpad)
 {
<span class="p_add">+	struct xpad_output_packet *packet =</span>
<span class="p_add">+			&amp;xpad-&gt;out_packets[XPAD_OUT_CMD_IDX];</span>
<span class="p_add">+	unsigned long flags;</span>
 	int retval;
 
<span class="p_del">-	mutex_lock(&amp;xpad-&gt;odata_mutex);</span>
<span class="p_add">+	spin_lock_irqsave(&amp;xpad-&gt;odata_lock, flags);</span>
<span class="p_add">+</span>
<span class="p_add">+	packet-&gt;data[0] = 0x08;</span>
<span class="p_add">+	packet-&gt;data[1] = 0x00;</span>
<span class="p_add">+	packet-&gt;data[2] = 0x0F;</span>
<span class="p_add">+	packet-&gt;data[3] = 0xC0;</span>
<span class="p_add">+	packet-&gt;data[4] = 0x00;</span>
<span class="p_add">+	packet-&gt;data[5] = 0x00;</span>
<span class="p_add">+	packet-&gt;data[6] = 0x00;</span>
<span class="p_add">+	packet-&gt;data[7] = 0x00;</span>
<span class="p_add">+	packet-&gt;data[8] = 0x00;</span>
<span class="p_add">+	packet-&gt;data[9] = 0x00;</span>
<span class="p_add">+	packet-&gt;data[10] = 0x00;</span>
<span class="p_add">+	packet-&gt;data[11] = 0x00;</span>
<span class="p_add">+	packet-&gt;len = 12;</span>
<span class="p_add">+	packet-&gt;pending = true;</span>
<span class="p_add">+</span>
<span class="p_add">+	/* Reset the sequence so we send out presence first */</span>
<span class="p_add">+	xpad-&gt;last_out_packet = -1;</span>
<span class="p_add">+	retval = xpad_try_sending_next_out_packet(xpad);</span>
<span class="p_add">+</span>
<span class="p_add">+	spin_unlock_irqrestore(&amp;xpad-&gt;odata_lock, flags);</span>
 
<span class="p_del">-	xpad-&gt;odata[0] = 0x08;</span>
<span class="p_del">-	xpad-&gt;odata[1] = 0x00;</span>
<span class="p_del">-	xpad-&gt;odata[2] = 0x0F;</span>
<span class="p_del">-	xpad-&gt;odata[3] = 0xC0;</span>
<span class="p_del">-	xpad-&gt;odata[4] = 0x00;</span>
<span class="p_del">-	xpad-&gt;odata[5] = 0x00;</span>
<span class="p_del">-	xpad-&gt;odata[6] = 0x00;</span>
<span class="p_del">-	xpad-&gt;odata[7] = 0x00;</span>
<span class="p_del">-	xpad-&gt;odata[8] = 0x00;</span>
<span class="p_del">-	xpad-&gt;odata[9] = 0x00;</span>
<span class="p_del">-	xpad-&gt;odata[10] = 0x00;</span>
<span class="p_del">-	xpad-&gt;odata[11] = 0x00;</span>
<span class="p_del">-	xpad-&gt;irq_out-&gt;transfer_buffer_length = 12;</span>
<span class="p_add">+	return retval;</span>
<span class="p_add">+}</span>
 
<span class="p_del">-	retval = usb_submit_urb(xpad-&gt;irq_out, GFP_KERNEL);</span>
<span class="p_add">+static int xpad_start_xbox_one(struct usb_xpad *xpad)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct xpad_output_packet *packet =</span>
<span class="p_add">+			&amp;xpad-&gt;out_packets[XPAD_OUT_CMD_IDX];</span>
<span class="p_add">+	unsigned long flags;</span>
<span class="p_add">+	int retval;</span>
<span class="p_add">+</span>
<span class="p_add">+	spin_lock_irqsave(&amp;xpad-&gt;odata_lock, flags);</span>
<span class="p_add">+</span>
<span class="p_add">+	/* Xbox one controller needs to be initialized. */</span>
<span class="p_add">+	packet-&gt;data[0] = 0x05;</span>
<span class="p_add">+	packet-&gt;data[1] = 0x20;</span>
<span class="p_add">+	packet-&gt;len = 2;</span>
<span class="p_add">+	packet-&gt;pending = true;</span>
 
<span class="p_del">-	mutex_unlock(&amp;xpad-&gt;odata_mutex);</span>
<span class="p_add">+	/* Reset the sequence so we send out start packet first */</span>
<span class="p_add">+	xpad-&gt;last_out_packet = -1;</span>
<span class="p_add">+	retval = xpad_try_sending_next_out_packet(xpad);</span>
<span class="p_add">+</span>
<span class="p_add">+	spin_unlock_irqrestore(&amp;xpad-&gt;odata_lock, flags);</span>
 
 	return retval;
 }
<span class="p_chunk">@@ -799,8 +906,11 @@</span> <span class="p_context"> static int xpad_inquiry_pad_presence(struct usb_xpad *xpad)</span>
 static int xpad_play_effect(struct input_dev *dev, void *data, struct ff_effect *effect)
 {
 	struct usb_xpad *xpad = input_get_drvdata(dev);
<span class="p_add">+	struct xpad_output_packet *packet = &amp;xpad-&gt;out_packets[XPAD_OUT_FF_IDX];</span>
 	__u16 strong;
 	__u16 weak;
<span class="p_add">+	int retval;</span>
<span class="p_add">+	unsigned long flags;</span>
 
 	if (effect-&gt;type != FF_RUMBLE)
 		return 0;
<span class="p_chunk">@@ -808,69 +918,80 @@</span> <span class="p_context"> static int xpad_play_effect(struct input_dev *dev, void *data, struct ff_effect</span>
 	strong = effect-&gt;u.rumble.strong_magnitude;
 	weak = effect-&gt;u.rumble.weak_magnitude;
 
<span class="p_add">+	spin_lock_irqsave(&amp;xpad-&gt;odata_lock, flags);</span>
<span class="p_add">+</span>
 	switch (xpad-&gt;xtype) {
 	case XTYPE_XBOX:
<span class="p_del">-		xpad-&gt;odata[0] = 0x00;</span>
<span class="p_del">-		xpad-&gt;odata[1] = 0x06;</span>
<span class="p_del">-		xpad-&gt;odata[2] = 0x00;</span>
<span class="p_del">-		xpad-&gt;odata[3] = strong / 256;	/* left actuator */</span>
<span class="p_del">-		xpad-&gt;odata[4] = 0x00;</span>
<span class="p_del">-		xpad-&gt;odata[5] = weak / 256;	/* right actuator */</span>
<span class="p_del">-		xpad-&gt;irq_out-&gt;transfer_buffer_length = 6;</span>
<span class="p_add">+		packet-&gt;data[0] = 0x00;</span>
<span class="p_add">+		packet-&gt;data[1] = 0x06;</span>
<span class="p_add">+		packet-&gt;data[2] = 0x00;</span>
<span class="p_add">+		packet-&gt;data[3] = strong / 256;	/* left actuator */</span>
<span class="p_add">+		packet-&gt;data[4] = 0x00;</span>
<span class="p_add">+		packet-&gt;data[5] = weak / 256;	/* right actuator */</span>
<span class="p_add">+		packet-&gt;len = 6;</span>
<span class="p_add">+		packet-&gt;pending = true;</span>
 		break;
 
 	case XTYPE_XBOX360:
<span class="p_del">-		xpad-&gt;odata[0] = 0x00;</span>
<span class="p_del">-		xpad-&gt;odata[1] = 0x08;</span>
<span class="p_del">-		xpad-&gt;odata[2] = 0x00;</span>
<span class="p_del">-		xpad-&gt;odata[3] = strong / 256;  /* left actuator? */</span>
<span class="p_del">-		xpad-&gt;odata[4] = weak / 256;	/* right actuator? */</span>
<span class="p_del">-		xpad-&gt;odata[5] = 0x00;</span>
<span class="p_del">-		xpad-&gt;odata[6] = 0x00;</span>
<span class="p_del">-		xpad-&gt;odata[7] = 0x00;</span>
<span class="p_del">-		xpad-&gt;irq_out-&gt;transfer_buffer_length = 8;</span>
<span class="p_add">+		packet-&gt;data[0] = 0x00;</span>
<span class="p_add">+		packet-&gt;data[1] = 0x08;</span>
<span class="p_add">+		packet-&gt;data[2] = 0x00;</span>
<span class="p_add">+		packet-&gt;data[3] = strong / 256;  /* left actuator? */</span>
<span class="p_add">+		packet-&gt;data[4] = weak / 256;	/* right actuator? */</span>
<span class="p_add">+		packet-&gt;data[5] = 0x00;</span>
<span class="p_add">+		packet-&gt;data[6] = 0x00;</span>
<span class="p_add">+		packet-&gt;data[7] = 0x00;</span>
<span class="p_add">+		packet-&gt;len = 8;</span>
<span class="p_add">+		packet-&gt;pending = true;</span>
 		break;
 
 	case XTYPE_XBOX360W:
<span class="p_del">-		xpad-&gt;odata[0] = 0x00;</span>
<span class="p_del">-		xpad-&gt;odata[1] = 0x01;</span>
<span class="p_del">-		xpad-&gt;odata[2] = 0x0F;</span>
<span class="p_del">-		xpad-&gt;odata[3] = 0xC0;</span>
<span class="p_del">-		xpad-&gt;odata[4] = 0x00;</span>
<span class="p_del">-		xpad-&gt;odata[5] = strong / 256;</span>
<span class="p_del">-		xpad-&gt;odata[6] = weak / 256;</span>
<span class="p_del">-		xpad-&gt;odata[7] = 0x00;</span>
<span class="p_del">-		xpad-&gt;odata[8] = 0x00;</span>
<span class="p_del">-		xpad-&gt;odata[9] = 0x00;</span>
<span class="p_del">-		xpad-&gt;odata[10] = 0x00;</span>
<span class="p_del">-		xpad-&gt;odata[11] = 0x00;</span>
<span class="p_del">-		xpad-&gt;irq_out-&gt;transfer_buffer_length = 12;</span>
<span class="p_add">+		packet-&gt;data[0] = 0x00;</span>
<span class="p_add">+		packet-&gt;data[1] = 0x01;</span>
<span class="p_add">+		packet-&gt;data[2] = 0x0F;</span>
<span class="p_add">+		packet-&gt;data[3] = 0xC0;</span>
<span class="p_add">+		packet-&gt;data[4] = 0x00;</span>
<span class="p_add">+		packet-&gt;data[5] = strong / 256;</span>
<span class="p_add">+		packet-&gt;data[6] = weak / 256;</span>
<span class="p_add">+		packet-&gt;data[7] = 0x00;</span>
<span class="p_add">+		packet-&gt;data[8] = 0x00;</span>
<span class="p_add">+		packet-&gt;data[9] = 0x00;</span>
<span class="p_add">+		packet-&gt;data[10] = 0x00;</span>
<span class="p_add">+		packet-&gt;data[11] = 0x00;</span>
<span class="p_add">+		packet-&gt;len = 12;</span>
<span class="p_add">+		packet-&gt;pending = true;</span>
 		break;
 
 	case XTYPE_XBOXONE:
<span class="p_del">-		xpad-&gt;odata[0] = 0x09; /* activate rumble */</span>
<span class="p_del">-		xpad-&gt;odata[1] = 0x08;</span>
<span class="p_del">-		xpad-&gt;odata[2] = 0x00;</span>
<span class="p_del">-		xpad-&gt;odata[3] = 0x08; /* continuous effect */</span>
<span class="p_del">-		xpad-&gt;odata[4] = 0x00; /* simple rumble mode */</span>
<span class="p_del">-		xpad-&gt;odata[5] = 0x03; /* L and R actuator only */</span>
<span class="p_del">-		xpad-&gt;odata[6] = 0x00; /* TODO: LT actuator */</span>
<span class="p_del">-		xpad-&gt;odata[7] = 0x00; /* TODO: RT actuator */</span>
<span class="p_del">-		xpad-&gt;odata[8] = strong / 256;	/* left actuator */</span>
<span class="p_del">-		xpad-&gt;odata[9] = weak / 256;	/* right actuator */</span>
<span class="p_del">-		xpad-&gt;odata[10] = 0x80;	/* length of pulse */</span>
<span class="p_del">-		xpad-&gt;odata[11] = 0x00;	/* stop period of pulse */</span>
<span class="p_del">-		xpad-&gt;irq_out-&gt;transfer_buffer_length = 12;</span>
<span class="p_add">+		packet-&gt;data[0] = 0x09; /* activate rumble */</span>
<span class="p_add">+		packet-&gt;data[1] = 0x08;</span>
<span class="p_add">+		packet-&gt;data[2] = 0x00;</span>
<span class="p_add">+		packet-&gt;data[3] = 0x08; /* continuous effect */</span>
<span class="p_add">+		packet-&gt;data[4] = 0x00; /* simple rumble mode */</span>
<span class="p_add">+		packet-&gt;data[5] = 0x03; /* L and R actuator only */</span>
<span class="p_add">+		packet-&gt;data[6] = 0x00; /* TODO: LT actuator */</span>
<span class="p_add">+		packet-&gt;data[7] = 0x00; /* TODO: RT actuator */</span>
<span class="p_add">+		packet-&gt;data[8] = strong / 256;	/* left actuator */</span>
<span class="p_add">+		packet-&gt;data[9] = weak / 256;	/* right actuator */</span>
<span class="p_add">+		packet-&gt;data[10] = 0x80;	/* length of pulse */</span>
<span class="p_add">+		packet-&gt;data[11] = 0x00;	/* stop period of pulse */</span>
<span class="p_add">+		packet-&gt;len = 12;</span>
<span class="p_add">+		packet-&gt;pending = true;</span>
 		break;
 
 	default:
 		dev_dbg(&amp;xpad-&gt;dev-&gt;dev,
 			&quot;%s - rumble command sent to unsupported xpad type: %d\n&quot;,
 			__func__, xpad-&gt;xtype);
<span class="p_del">-		return -EINVAL;</span>
<span class="p_add">+		retval = -EINVAL;</span>
<span class="p_add">+		goto out;</span>
 	}
 
<span class="p_del">-	return usb_submit_urb(xpad-&gt;irq_out, GFP_ATOMIC);</span>
<span class="p_add">+	retval = xpad_try_sending_next_out_packet(xpad);</span>
<span class="p_add">+</span>
<span class="p_add">+out:</span>
<span class="p_add">+	spin_unlock_irqrestore(&amp;xpad-&gt;odata_lock, flags);</span>
<span class="p_add">+	return retval;</span>
 }
 
 static int xpad_init_ff(struct usb_xpad *xpad)
<span class="p_chunk">@@ -921,36 +1042,44 @@</span> <span class="p_context"> struct xpad_led {</span>
  */
 static void xpad_send_led_command(struct usb_xpad *xpad, int command)
 {
<span class="p_add">+	struct xpad_output_packet *packet =</span>
<span class="p_add">+			&amp;xpad-&gt;out_packets[XPAD_OUT_LED_IDX];</span>
<span class="p_add">+	unsigned long flags;</span>
<span class="p_add">+</span>
 	command %= 16;
 
<span class="p_del">-	mutex_lock(&amp;xpad-&gt;odata_mutex);</span>
<span class="p_add">+	spin_lock_irqsave(&amp;xpad-&gt;odata_lock, flags);</span>
 
 	switch (xpad-&gt;xtype) {
 	case XTYPE_XBOX360:
<span class="p_del">-		xpad-&gt;odata[0] = 0x01;</span>
<span class="p_del">-		xpad-&gt;odata[1] = 0x03;</span>
<span class="p_del">-		xpad-&gt;odata[2] = command;</span>
<span class="p_del">-		xpad-&gt;irq_out-&gt;transfer_buffer_length = 3;</span>
<span class="p_add">+		packet-&gt;data[0] = 0x01;</span>
<span class="p_add">+		packet-&gt;data[1] = 0x03;</span>
<span class="p_add">+		packet-&gt;data[2] = command;</span>
<span class="p_add">+		packet-&gt;len = 3;</span>
<span class="p_add">+		packet-&gt;pending = true;</span>
 		break;
<span class="p_add">+</span>
 	case XTYPE_XBOX360W:
<span class="p_del">-		xpad-&gt;odata[0] = 0x00;</span>
<span class="p_del">-		xpad-&gt;odata[1] = 0x00;</span>
<span class="p_del">-		xpad-&gt;odata[2] = 0x08;</span>
<span class="p_del">-		xpad-&gt;odata[3] = 0x40 + command;</span>
<span class="p_del">-		xpad-&gt;odata[4] = 0x00;</span>
<span class="p_del">-		xpad-&gt;odata[5] = 0x00;</span>
<span class="p_del">-		xpad-&gt;odata[6] = 0x00;</span>
<span class="p_del">-		xpad-&gt;odata[7] = 0x00;</span>
<span class="p_del">-		xpad-&gt;odata[8] = 0x00;</span>
<span class="p_del">-		xpad-&gt;odata[9] = 0x00;</span>
<span class="p_del">-		xpad-&gt;odata[10] = 0x00;</span>
<span class="p_del">-		xpad-&gt;odata[11] = 0x00;</span>
<span class="p_del">-		xpad-&gt;irq_out-&gt;transfer_buffer_length = 12;</span>
<span class="p_add">+		packet-&gt;data[0] = 0x00;</span>
<span class="p_add">+		packet-&gt;data[1] = 0x00;</span>
<span class="p_add">+		packet-&gt;data[2] = 0x08;</span>
<span class="p_add">+		packet-&gt;data[3] = 0x40 + command;</span>
<span class="p_add">+		packet-&gt;data[4] = 0x00;</span>
<span class="p_add">+		packet-&gt;data[5] = 0x00;</span>
<span class="p_add">+		packet-&gt;data[6] = 0x00;</span>
<span class="p_add">+		packet-&gt;data[7] = 0x00;</span>
<span class="p_add">+		packet-&gt;data[8] = 0x00;</span>
<span class="p_add">+		packet-&gt;data[9] = 0x00;</span>
<span class="p_add">+		packet-&gt;data[10] = 0x00;</span>
<span class="p_add">+		packet-&gt;data[11] = 0x00;</span>
<span class="p_add">+		packet-&gt;len = 12;</span>
<span class="p_add">+		packet-&gt;pending = true;</span>
 		break;
 	}
 
<span class="p_del">-	usb_submit_urb(xpad-&gt;irq_out, GFP_KERNEL);</span>
<span class="p_del">-	mutex_unlock(&amp;xpad-&gt;odata_mutex);</span>
<span class="p_add">+	xpad_try_sending_next_out_packet(xpad);</span>
<span class="p_add">+</span>
<span class="p_add">+	spin_unlock_irqrestore(&amp;xpad-&gt;odata_lock, flags);</span>
 }
 
 /*
<span class="p_chunk">@@ -1048,13 +1177,8 @@</span> <span class="p_context"> static int xpad_open(struct input_dev *dev)</span>
 	if (usb_submit_urb(xpad-&gt;irq_in, GFP_KERNEL))
 		return -EIO;
 
<span class="p_del">-	if (xpad-&gt;xtype == XTYPE_XBOXONE) {</span>
<span class="p_del">-		/* Xbox one controller needs to be initialized. */</span>
<span class="p_del">-		xpad-&gt;odata[0] = 0x05;</span>
<span class="p_del">-		xpad-&gt;odata[1] = 0x20;</span>
<span class="p_del">-		xpad-&gt;irq_out-&gt;transfer_buffer_length = 2;</span>
<span class="p_del">-		return usb_submit_urb(xpad-&gt;irq_out, GFP_KERNEL);</span>
<span class="p_del">-	}</span>
<span class="p_add">+	if (xpad-&gt;xtype == XTYPE_XBOXONE)</span>
<span class="p_add">+		return xpad_start_xbox_one(xpad);</span>
 
 	return 0;
 }
<span class="p_header">diff --git a/drivers/irqchip/irq-gic-v3-its.c b/drivers/irqchip/irq-gic-v3-its.c</span>
<span class="p_header">index a159529f9d53..c5f1757ac61d 100644</span>
<span class="p_header">--- a/drivers/irqchip/irq-gic-v3-its.c</span>
<span class="p_header">+++ b/drivers/irqchip/irq-gic-v3-its.c</span>
<span class="p_chunk">@@ -41,6 +41,7 @@</span> <span class="p_context"></span>
 
 #define ITS_FLAGS_CMDQ_NEEDS_FLUSHING		(1ULL &lt;&lt; 0)
 #define ITS_FLAGS_WORKAROUND_CAVIUM_22375	(1ULL &lt;&lt; 1)
<span class="p_add">+#define ITS_FLAGS_WORKAROUND_CAVIUM_23144	(1ULL &lt;&lt; 2)</span>
 
 #define RDIST_FLAGS_PROPBASE_NEEDS_FLUSHING	(1 &lt;&lt; 0)
 
<span class="p_chunk">@@ -71,6 +72,7 @@</span> <span class="p_context"> struct its_node {</span>
 	struct list_head	its_device_list;
 	u64			flags;
 	u32			ite_size;
<span class="p_add">+	int			numa_node;</span>
 };
 
 #define ITS_ITT_ALIGN		SZ_256
<span class="p_chunk">@@ -600,11 +602,23 @@</span> <span class="p_context"> static void its_unmask_irq(struct irq_data *d)</span>
 static int its_set_affinity(struct irq_data *d, const struct cpumask *mask_val,
 			    bool force)
 {
<span class="p_del">-	unsigned int cpu = cpumask_any_and(mask_val, cpu_online_mask);</span>
<span class="p_add">+	unsigned int cpu;</span>
<span class="p_add">+	const struct cpumask *cpu_mask = cpu_online_mask;</span>
 	struct its_device *its_dev = irq_data_get_irq_chip_data(d);
 	struct its_collection *target_col;
 	u32 id = its_get_event_id(d);
 
<span class="p_add">+       /* lpi cannot be routed to a redistributor that is on a foreign node */</span>
<span class="p_add">+	if (its_dev-&gt;its-&gt;flags &amp; ITS_FLAGS_WORKAROUND_CAVIUM_23144) {</span>
<span class="p_add">+		if (its_dev-&gt;its-&gt;numa_node &gt;= 0) {</span>
<span class="p_add">+			cpu_mask = cpumask_of_node(its_dev-&gt;its-&gt;numa_node);</span>
<span class="p_add">+			if (!cpumask_intersects(mask_val, cpu_mask))</span>
<span class="p_add">+				return -EINVAL;</span>
<span class="p_add">+		}</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	cpu = cpumask_any_and(mask_val, cpu_mask);</span>
<span class="p_add">+</span>
 	if (cpu &gt;= nr_cpu_ids)
 		return -EINVAL;
 
<span class="p_chunk">@@ -1081,6 +1095,16 @@</span> <span class="p_context"> static void its_cpu_init_collection(void)</span>
 	list_for_each_entry(its, &amp;its_nodes, entry) {
 		u64 target;
 
<span class="p_add">+		/* avoid cross node collections and its mapping */</span>
<span class="p_add">+		if (its-&gt;flags &amp; ITS_FLAGS_WORKAROUND_CAVIUM_23144) {</span>
<span class="p_add">+			struct device_node *cpu_node;</span>
<span class="p_add">+</span>
<span class="p_add">+			cpu_node = of_get_cpu_node(cpu, NULL);</span>
<span class="p_add">+			if (its-&gt;numa_node != NUMA_NO_NODE &amp;&amp;</span>
<span class="p_add">+				its-&gt;numa_node != of_node_to_nid(cpu_node))</span>
<span class="p_add">+				continue;</span>
<span class="p_add">+		}</span>
<span class="p_add">+</span>
 		/*
 		 * We now have to bind each collection to its target
 		 * redistributor.
<span class="p_chunk">@@ -1308,9 +1332,14 @@</span> <span class="p_context"> static void its_irq_domain_activate(struct irq_domain *domain,</span>
 {
 	struct its_device *its_dev = irq_data_get_irq_chip_data(d);
 	u32 event = its_get_event_id(d);
<span class="p_add">+	const struct cpumask *cpu_mask = cpu_online_mask;</span>
<span class="p_add">+</span>
<span class="p_add">+	/* get the cpu_mask of local node */</span>
<span class="p_add">+	if (its_dev-&gt;its-&gt;numa_node &gt;= 0)</span>
<span class="p_add">+		cpu_mask = cpumask_of_node(its_dev-&gt;its-&gt;numa_node);</span>
 
 	/* Bind the LPI to the first possible CPU */
<span class="p_del">-	its_dev-&gt;event_map.col_map[event] = cpumask_first(cpu_online_mask);</span>
<span class="p_add">+	its_dev-&gt;event_map.col_map[event] = cpumask_first(cpu_mask);</span>
 
 	/* Map the GIC IRQ and event to the device */
 	its_send_mapvi(its_dev, d-&gt;hwirq, event);
<span class="p_chunk">@@ -1400,6 +1429,13 @@</span> <span class="p_context"> static void __maybe_unused its_enable_quirk_cavium_22375(void *data)</span>
 	its-&gt;flags |= ITS_FLAGS_WORKAROUND_CAVIUM_22375;
 }
 
<span class="p_add">+static void __maybe_unused its_enable_quirk_cavium_23144(void *data)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct its_node *its = data;</span>
<span class="p_add">+</span>
<span class="p_add">+	its-&gt;flags |= ITS_FLAGS_WORKAROUND_CAVIUM_23144;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static const struct gic_quirk its_quirks[] = {
 #ifdef CONFIG_CAVIUM_ERRATUM_22375
 	{
<span class="p_chunk">@@ -1409,6 +1445,14 @@</span> <span class="p_context"> static const struct gic_quirk its_quirks[] = {</span>
 		.init	= its_enable_quirk_cavium_22375,
 	},
 #endif
<span class="p_add">+#ifdef CONFIG_CAVIUM_ERRATUM_23144</span>
<span class="p_add">+	{</span>
<span class="p_add">+		.desc	= &quot;ITS: Cavium erratum 23144&quot;,</span>
<span class="p_add">+		.iidr	= 0xa100034c,	/* ThunderX pass 1.x */</span>
<span class="p_add">+		.mask	= 0xffff0fff,</span>
<span class="p_add">+		.init	= its_enable_quirk_cavium_23144,</span>
<span class="p_add">+	},</span>
<span class="p_add">+#endif</span>
 	{
 	}
 };
<span class="p_chunk">@@ -1470,6 +1514,7 @@</span> <span class="p_context"> static int its_probe(struct device_node *node, struct irq_domain *parent)</span>
 	its-&gt;base = its_base;
 	its-&gt;phys_base = res.start;
 	its-&gt;ite_size = ((readl_relaxed(its_base + GITS_TYPER) &gt;&gt; 4) &amp; 0xf) + 1;
<span class="p_add">+	its-&gt;numa_node = of_node_to_nid(node);</span>
 
 	its-&gt;cmd_base = kzalloc(ITS_CMD_QUEUE_SZ, GFP_KERNEL);
 	if (!its-&gt;cmd_base) {
<span class="p_header">diff --git a/drivers/lightnvm/gennvm.c b/drivers/lightnvm/gennvm.c</span>
<span class="p_header">index a54b339951a3..2a96ff6923f0 100644</span>
<span class="p_header">--- a/drivers/lightnvm/gennvm.c</span>
<span class="p_header">+++ b/drivers/lightnvm/gennvm.c</span>
<span class="p_chunk">@@ -89,6 +89,7 @@</span> <span class="p_context"> static int gennvm_block_bb(struct ppa_addr ppa, int nr_blocks, u8 *blks,</span>
 
 		list_move_tail(&amp;blk-&gt;list, &amp;lun-&gt;bb_list);
 		lun-&gt;vlun.nr_bad_blocks++;
<span class="p_add">+		lun-&gt;vlun.nr_free_blocks--;</span>
 	}
 
 	return 0;
<span class="p_chunk">@@ -345,7 +346,7 @@</span> <span class="p_context"> static void gennvm_generic_to_addr_mode(struct nvm_dev *dev, struct nvm_rq *rqd)</span>
 static int gennvm_submit_io(struct nvm_dev *dev, struct nvm_rq *rqd)
 {
 	if (!dev-&gt;ops-&gt;submit_io)
<span class="p_del">-		return 0;</span>
<span class="p_add">+		return -ENODEV;</span>
 
 	/* Convert address space */
 	gennvm_generic_to_addr_mode(dev, rqd);
<span class="p_header">diff --git a/drivers/lightnvm/rrpc.c b/drivers/lightnvm/rrpc.c</span>
<span class="p_header">index 134e4faba482..a9859489acf6 100644</span>
<span class="p_header">--- a/drivers/lightnvm/rrpc.c</span>
<span class="p_header">+++ b/drivers/lightnvm/rrpc.c</span>
<span class="p_chunk">@@ -287,6 +287,8 @@</span> <span class="p_context"> static int rrpc_move_valid_pages(struct rrpc *rrpc, struct rrpc_block *rblk)</span>
 	}
 
 	page = mempool_alloc(rrpc-&gt;page_pool, GFP_NOIO);
<span class="p_add">+	if (!page)</span>
<span class="p_add">+		return -ENOMEM;</span>
 
 	while ((slot = find_first_zero_bit(rblk-&gt;invalid_pages,
 					    nr_pgs_per_blk)) &lt; nr_pgs_per_blk) {
<span class="p_chunk">@@ -427,7 +429,7 @@</span> <span class="p_context"> static void rrpc_lun_gc(struct work_struct *work)</span>
 	if (nr_blocks_need &lt; rrpc-&gt;nr_luns)
 		nr_blocks_need = rrpc-&gt;nr_luns;
 
<span class="p_del">-	spin_lock(&amp;lun-&gt;lock);</span>
<span class="p_add">+	spin_lock(&amp;rlun-&gt;lock);</span>
 	while (nr_blocks_need &gt; lun-&gt;nr_free_blocks &amp;&amp;
 					!list_empty(&amp;rlun-&gt;prio_list)) {
 		struct rrpc_block *rblock = block_prio_find_max(rlun);
<span class="p_chunk">@@ -436,16 +438,16 @@</span> <span class="p_context"> static void rrpc_lun_gc(struct work_struct *work)</span>
 		if (!rblock-&gt;nr_invalid_pages)
 			break;
 
<span class="p_add">+		gcb = mempool_alloc(rrpc-&gt;gcb_pool, GFP_ATOMIC);</span>
<span class="p_add">+		if (!gcb)</span>
<span class="p_add">+			break;</span>
<span class="p_add">+</span>
 		list_del_init(&amp;rblock-&gt;prio);
 
 		BUG_ON(!block_is_full(rrpc, rblock));
 
 		pr_debug(&quot;rrpc: selected block &#39;%lu&#39; for GC\n&quot;, block-&gt;id);
 
<span class="p_del">-		gcb = mempool_alloc(rrpc-&gt;gcb_pool, GFP_ATOMIC);</span>
<span class="p_del">-		if (!gcb)</span>
<span class="p_del">-			break;</span>
<span class="p_del">-</span>
 		gcb-&gt;rrpc = rrpc;
 		gcb-&gt;rblk = rblock;
 		INIT_WORK(&amp;gcb-&gt;ws_gc, rrpc_block_gc);
<span class="p_chunk">@@ -454,7 +456,7 @@</span> <span class="p_context"> static void rrpc_lun_gc(struct work_struct *work)</span>
 
 		nr_blocks_need--;
 	}
<span class="p_del">-	spin_unlock(&amp;lun-&gt;lock);</span>
<span class="p_add">+	spin_unlock(&amp;rlun-&gt;lock);</span>
 
 	/* TODO: Hint that request queue can be started again */
 }
<span class="p_chunk">@@ -650,11 +652,12 @@</span> <span class="p_context"> static int rrpc_end_io(struct nvm_rq *rqd, int error)</span>
 	if (bio_data_dir(rqd-&gt;bio) == WRITE)
 		rrpc_end_io_write(rrpc, rrqd, laddr, npages);
 
<span class="p_add">+	bio_put(rqd-&gt;bio);</span>
<span class="p_add">+</span>
 	if (rrqd-&gt;flags &amp; NVM_IOTYPE_GC)
 		return 0;
 
 	rrpc_unlock_rq(rrpc, rqd);
<span class="p_del">-	bio_put(rqd-&gt;bio);</span>
 
 	if (npages &gt; 1)
 		nvm_dev_dma_free(rrpc-&gt;dev, rqd-&gt;ppa_list, rqd-&gt;dma_ppa_list);
<span class="p_chunk">@@ -841,6 +844,13 @@</span> <span class="p_context"> static int rrpc_submit_io(struct rrpc *rrpc, struct bio *bio,</span>
 	err = nvm_submit_io(rrpc-&gt;dev, rqd);
 	if (err) {
 		pr_err(&quot;rrpc: I/O submission failed: %d\n&quot;, err);
<span class="p_add">+		bio_put(bio);</span>
<span class="p_add">+		if (!(flags &amp; NVM_IOTYPE_GC)) {</span>
<span class="p_add">+			rrpc_unlock_rq(rrpc, rqd);</span>
<span class="p_add">+			if (rqd-&gt;nr_pages &gt; 1)</span>
<span class="p_add">+				nvm_dev_dma_free(rrpc-&gt;dev,</span>
<span class="p_add">+			rqd-&gt;ppa_list, rqd-&gt;dma_ppa_list);</span>
<span class="p_add">+		}</span>
 		return NVM_IO_ERR;
 	}
 
<span class="p_header">diff --git a/drivers/md/bcache/super.c b/drivers/md/bcache/super.c</span>
<span class="p_header">index a296425a7270..3d5c0ba13181 100644</span>
<span class="p_header">--- a/drivers/md/bcache/super.c</span>
<span class="p_header">+++ b/drivers/md/bcache/super.c</span>
<span class="p_chunk">@@ -1818,7 +1818,7 @@</span> <span class="p_context"> static int cache_alloc(struct cache_sb *sb, struct cache *ca)</span>
 	free = roundup_pow_of_two(ca-&gt;sb.nbuckets) &gt;&gt; 10;
 
 	if (!init_fifo(&amp;ca-&gt;free[RESERVE_BTREE], 8, GFP_KERNEL) ||
<span class="p_del">-	    !init_fifo(&amp;ca-&gt;free[RESERVE_PRIO], prio_buckets(ca), GFP_KERNEL) ||</span>
<span class="p_add">+	    !init_fifo_exact(&amp;ca-&gt;free[RESERVE_PRIO], prio_buckets(ca), GFP_KERNEL) ||</span>
 	    !init_fifo(&amp;ca-&gt;free[RESERVE_MOVINGGC], free, GFP_KERNEL) ||
 	    !init_fifo(&amp;ca-&gt;free[RESERVE_NONE], free, GFP_KERNEL) ||
 	    !init_fifo(&amp;ca-&gt;free_inc,	free &lt;&lt; 2, GFP_KERNEL) ||
<span class="p_header">diff --git a/drivers/media/dvb-frontends/Kconfig b/drivers/media/dvb-frontends/Kconfig</span>
<span class="p_header">index 292c9479bb75..310e4b8beae8 100644</span>
<span class="p_header">--- a/drivers/media/dvb-frontends/Kconfig</span>
<span class="p_header">+++ b/drivers/media/dvb-frontends/Kconfig</span>
<span class="p_chunk">@@ -264,7 +264,7 @@</span> <span class="p_context"> config DVB_MB86A16</span>
 config DVB_TDA10071
 	tristate &quot;NXP TDA10071&quot;
 	depends on DVB_CORE &amp;&amp; I2C
<span class="p_del">-	select REGMAP</span>
<span class="p_add">+	select REGMAP_I2C</span>
 	default m if !MEDIA_SUBDRV_AUTOSELECT
 	help
 	  Say Y when you want to support this frontend.
<span class="p_header">diff --git a/drivers/media/usb/uvc/uvc_driver.c b/drivers/media/usb/uvc/uvc_driver.c</span>
<span class="p_header">index d11fd6ac2df0..5cefca95734e 100644</span>
<span class="p_header">--- a/drivers/media/usb/uvc/uvc_driver.c</span>
<span class="p_header">+++ b/drivers/media/usb/uvc/uvc_driver.c</span>
<span class="p_chunk">@@ -148,6 +148,26 @@</span> <span class="p_context"> static struct uvc_format_desc uvc_fmts[] = {</span>
 		.guid		= UVC_GUID_FORMAT_H264,
 		.fcc		= V4L2_PIX_FMT_H264,
 	},
<span class="p_add">+	{</span>
<span class="p_add">+		.name		= &quot;Greyscale 8 L/R (Y8I)&quot;,</span>
<span class="p_add">+		.guid		= UVC_GUID_FORMAT_Y8I,</span>
<span class="p_add">+		.fcc		= V4L2_PIX_FMT_Y8I,</span>
<span class="p_add">+	},</span>
<span class="p_add">+	{</span>
<span class="p_add">+		.name		= &quot;Greyscale 12 L/R (Y12I)&quot;,</span>
<span class="p_add">+		.guid		= UVC_GUID_FORMAT_Y12I,</span>
<span class="p_add">+		.fcc		= V4L2_PIX_FMT_Y12I,</span>
<span class="p_add">+	},</span>
<span class="p_add">+	{</span>
<span class="p_add">+		.name		= &quot;Depth data 16-bit (Z16)&quot;,</span>
<span class="p_add">+		.guid		= UVC_GUID_FORMAT_Z16,</span>
<span class="p_add">+		.fcc		= V4L2_PIX_FMT_Z16,</span>
<span class="p_add">+	},</span>
<span class="p_add">+	{</span>
<span class="p_add">+		.name		= &quot;Bayer 10-bit (SRGGB10P)&quot;,</span>
<span class="p_add">+		.guid		= UVC_GUID_FORMAT_RW10,</span>
<span class="p_add">+		.fcc		= V4L2_PIX_FMT_SRGGB10P,</span>
<span class="p_add">+	},</span>
 };
 
 /* ------------------------------------------------------------------------
<span class="p_header">diff --git a/drivers/media/usb/uvc/uvcvideo.h b/drivers/media/usb/uvc/uvcvideo.h</span>
<span class="p_header">index f0f2391e1b43..7e4d3eea371b 100644</span>
<span class="p_header">--- a/drivers/media/usb/uvc/uvcvideo.h</span>
<span class="p_header">+++ b/drivers/media/usb/uvc/uvcvideo.h</span>
<span class="p_chunk">@@ -119,6 +119,18 @@</span> <span class="p_context"></span>
 #define UVC_GUID_FORMAT_H264 \
 	{ &#39;H&#39;,  &#39;2&#39;,  &#39;6&#39;,  &#39;4&#39;, 0x00, 0x00, 0x10, 0x00, \
 	 0x80, 0x00, 0x00, 0xaa, 0x00, 0x38, 0x9b, 0x71}
<span class="p_add">+#define UVC_GUID_FORMAT_Y8I \</span>
<span class="p_add">+	{ &#39;Y&#39;,  &#39;8&#39;,  &#39;I&#39;,  &#39; &#39;, 0x00, 0x00, 0x10, 0x00, \</span>
<span class="p_add">+	 0x80, 0x00, 0x00, 0xaa, 0x00, 0x38, 0x9b, 0x71}</span>
<span class="p_add">+#define UVC_GUID_FORMAT_Y12I \</span>
<span class="p_add">+	{ &#39;Y&#39;,  &#39;1&#39;,  &#39;2&#39;,  &#39;I&#39;, 0x00, 0x00, 0x10, 0x00, \</span>
<span class="p_add">+	 0x80, 0x00, 0x00, 0xaa, 0x00, 0x38, 0x9b, 0x71}</span>
<span class="p_add">+#define UVC_GUID_FORMAT_Z16 \</span>
<span class="p_add">+	{ &#39;Z&#39;,  &#39;1&#39;,  &#39;6&#39;,  &#39; &#39;, 0x00, 0x00, 0x10, 0x00, \</span>
<span class="p_add">+	 0x80, 0x00, 0x00, 0xaa, 0x00, 0x38, 0x9b, 0x71}</span>
<span class="p_add">+#define UVC_GUID_FORMAT_RW10 \</span>
<span class="p_add">+	{ &#39;R&#39;,  &#39;W&#39;,  &#39;1&#39;,  &#39;0&#39;, 0x00, 0x00, 0x10, 0x00, \</span>
<span class="p_add">+	 0x80, 0x00, 0x00, 0xaa, 0x00, 0x38, 0x9b, 0x71}</span>
 
 /* ------------------------------------------------------------------------
  * Driver specific constants.
<span class="p_header">diff --git a/drivers/misc/cxl/Makefile b/drivers/misc/cxl/Makefile</span>
<span class="p_header">index 6982f603fadc..ab6f392d3504 100644</span>
<span class="p_header">--- a/drivers/misc/cxl/Makefile</span>
<span class="p_header">+++ b/drivers/misc/cxl/Makefile</span>
<span class="p_chunk">@@ -1,4 +1,4 @@</span> <span class="p_context"></span>
<span class="p_del">-ccflags-y := -Werror -Wno-unused-const-variable</span>
<span class="p_add">+ccflags-y := -Werror $(call cc-disable-warning, unused-const-variable)</span>
 
 cxl-y				+= main.o file.o irq.o fault.o native.o
 cxl-y				+= context.o sysfs.o debugfs.o pci.o trace.o
<span class="p_header">diff --git a/drivers/misc/cxl/api.c b/drivers/misc/cxl/api.c</span>
<span class="p_header">index 103baf0e0c5b..ea3eeb7011e1 100644</span>
<span class="p_header">--- a/drivers/misc/cxl/api.c</span>
<span class="p_header">+++ b/drivers/misc/cxl/api.c</span>
<span class="p_chunk">@@ -25,7 +25,6 @@</span> <span class="p_context"> struct cxl_context *cxl_dev_context_init(struct pci_dev *dev)</span>
 
 	afu = cxl_pci_to_afu(dev);
 
<span class="p_del">-	get_device(&amp;afu-&gt;dev);</span>
 	ctx = cxl_context_alloc();
 	if (IS_ERR(ctx)) {
 		rc = PTR_ERR(ctx);
<span class="p_chunk">@@ -61,7 +60,6 @@</span> <span class="p_context"> err_mapping:</span>
 err_ctx:
 	kfree(ctx);
 err_dev:
<span class="p_del">-	put_device(&amp;afu-&gt;dev);</span>
 	return ERR_PTR(rc);
 }
 EXPORT_SYMBOL_GPL(cxl_dev_context_init);
<span class="p_chunk">@@ -87,8 +85,6 @@</span> <span class="p_context"> int cxl_release_context(struct cxl_context *ctx)</span>
 	if (ctx-&gt;status &gt;= STARTED)
 		return -EBUSY;
 
<span class="p_del">-	put_device(&amp;ctx-&gt;afu-&gt;dev);</span>
<span class="p_del">-</span>
 	cxl_context_free(ctx);
 
 	return 0;
<span class="p_chunk">@@ -176,7 +172,7 @@</span> <span class="p_context"> int cxl_start_context(struct cxl_context *ctx, u64 wed,</span>
 
 	if (task) {
 		ctx-&gt;pid = get_task_pid(task, PIDTYPE_PID);
<span class="p_del">-		get_pid(ctx-&gt;pid);</span>
<span class="p_add">+		ctx-&gt;glpid = get_task_pid(task-&gt;group_leader, PIDTYPE_PID);</span>
 		kernel = false;
 	}
 
<span class="p_header">diff --git a/drivers/misc/cxl/context.c b/drivers/misc/cxl/context.c</span>
<span class="p_header">index 2faa1270d085..262b88eac414 100644</span>
<span class="p_header">--- a/drivers/misc/cxl/context.c</span>
<span class="p_header">+++ b/drivers/misc/cxl/context.c</span>
<span class="p_chunk">@@ -42,7 +42,7 @@</span> <span class="p_context"> int cxl_context_init(struct cxl_context *ctx, struct cxl_afu *afu, bool master,</span>
 	spin_lock_init(&amp;ctx-&gt;sste_lock);
 	ctx-&gt;afu = afu;
 	ctx-&gt;master = master;
<span class="p_del">-	ctx-&gt;pid = NULL; /* Set in start work ioctl */</span>
<span class="p_add">+	ctx-&gt;pid = ctx-&gt;glpid = NULL; /* Set in start work ioctl */</span>
 	mutex_init(&amp;ctx-&gt;mapping_lock);
 	ctx-&gt;mapping = mapping;
 
<span class="p_chunk">@@ -97,6 +97,12 @@</span> <span class="p_context"> int cxl_context_init(struct cxl_context *ctx, struct cxl_afu *afu, bool master,</span>
 	ctx-&gt;pe = i;
 	ctx-&gt;elem = &amp;ctx-&gt;afu-&gt;spa[i];
 	ctx-&gt;pe_inserted = false;
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * take a ref on the afu so that it stays alive at-least till</span>
<span class="p_add">+	 * this context is reclaimed inside reclaim_ctx.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	cxl_afu_get(afu);</span>
 	return 0;
 }
 
<span class="p_chunk">@@ -211,7 +217,11 @@</span> <span class="p_context"> int __detach_context(struct cxl_context *ctx)</span>
 	WARN_ON(cxl_detach_process(ctx) &amp;&amp;
 		cxl_adapter_link_ok(ctx-&gt;afu-&gt;adapter));
 	flush_work(&amp;ctx-&gt;fault_work); /* Only needed for dedicated process */
<span class="p_add">+</span>
<span class="p_add">+	/* release the reference to the group leader and mm handling pid */</span>
 	put_pid(ctx-&gt;pid);
<span class="p_add">+	put_pid(ctx-&gt;glpid);</span>
<span class="p_add">+</span>
 	cxl_ctx_put();
 	return 0;
 }
<span class="p_chunk">@@ -278,6 +288,9 @@</span> <span class="p_context"> static void reclaim_ctx(struct rcu_head *rcu)</span>
 	if (ctx-&gt;irq_bitmap)
 		kfree(ctx-&gt;irq_bitmap);
 
<span class="p_add">+	/* Drop ref to the afu device taken during cxl_context_init */</span>
<span class="p_add">+	cxl_afu_put(ctx-&gt;afu);</span>
<span class="p_add">+</span>
 	kfree(ctx);
 }
 
<span class="p_header">diff --git a/drivers/misc/cxl/cxl.h b/drivers/misc/cxl/cxl.h</span>
<span class="p_header">index 0cfb9c129f27..a521bc72cec2 100644</span>
<span class="p_header">--- a/drivers/misc/cxl/cxl.h</span>
<span class="p_header">+++ b/drivers/misc/cxl/cxl.h</span>
<span class="p_chunk">@@ -403,6 +403,18 @@</span> <span class="p_context"> struct cxl_afu {</span>
 	bool enabled;
 };
 
<span class="p_add">+/* AFU refcount management */</span>
<span class="p_add">+static inline struct cxl_afu *cxl_afu_get(struct cxl_afu *afu)</span>
<span class="p_add">+{</span>
<span class="p_add">+</span>
<span class="p_add">+	return (get_device(&amp;afu-&gt;dev) == NULL) ? NULL : afu;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline void  cxl_afu_put(struct cxl_afu *afu)</span>
<span class="p_add">+{</span>
<span class="p_add">+	put_device(&amp;afu-&gt;dev);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 
 struct cxl_irq_name {
 	struct list_head list;
<span class="p_chunk">@@ -433,6 +445,9 @@</span> <span class="p_context"> struct cxl_context {</span>
 	unsigned int sst_size, sst_lru;
 
 	wait_queue_head_t wq;
<span class="p_add">+	/* pid of the group leader associated with the pid */</span>
<span class="p_add">+	struct pid *glpid;</span>
<span class="p_add">+	/* use mm context associated with this pid for ds faults */</span>
 	struct pid *pid;
 	spinlock_t lock; /* Protects pending_irq_mask, pending_fault and fault_addr */
 	/* Only used in PR mode */
<span class="p_header">diff --git a/drivers/misc/cxl/fault.c b/drivers/misc/cxl/fault.c</span>
<span class="p_header">index 25a5418c55cb..81c3f75b7330 100644</span>
<span class="p_header">--- a/drivers/misc/cxl/fault.c</span>
<span class="p_header">+++ b/drivers/misc/cxl/fault.c</span>
<span class="p_chunk">@@ -166,13 +166,92 @@</span> <span class="p_context"> static void cxl_handle_page_fault(struct cxl_context *ctx,</span>
 	cxl_ack_irq(ctx, CXL_PSL_TFC_An_R, 0);
 }
 
<span class="p_add">+/*</span>
<span class="p_add">+ * Returns the mm_struct corresponding to the context ctx via ctx-&gt;pid</span>
<span class="p_add">+ * In case the task has exited we use the task group leader accessible</span>
<span class="p_add">+ * via ctx-&gt;glpid to find the next task in the thread group that has a</span>
<span class="p_add">+ * valid  mm_struct associated with it. If a task with valid mm_struct</span>
<span class="p_add">+ * is found the ctx-&gt;pid is updated to use the task struct for subsequent</span>
<span class="p_add">+ * translations. In case no valid mm_struct is found in the task group to</span>
<span class="p_add">+ * service the fault a NULL is returned.</span>
<span class="p_add">+ */</span>
<span class="p_add">+static struct mm_struct *get_mem_context(struct cxl_context *ctx)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct task_struct *task = NULL;</span>
<span class="p_add">+	struct mm_struct *mm = NULL;</span>
<span class="p_add">+	struct pid *old_pid = ctx-&gt;pid;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (old_pid == NULL) {</span>
<span class="p_add">+		pr_warn(&quot;%s: Invalid context for pe=%d\n&quot;,</span>
<span class="p_add">+			 __func__, ctx-&gt;pe);</span>
<span class="p_add">+		return NULL;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	task = get_pid_task(old_pid, PIDTYPE_PID);</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * pid_alive may look racy but this saves us from costly</span>
<span class="p_add">+	 * get_task_mm when the task is a zombie. In worst case</span>
<span class="p_add">+	 * we may think a task is alive, which is about to die</span>
<span class="p_add">+	 * but get_task_mm will return NULL.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	if (task != NULL &amp;&amp; pid_alive(task))</span>
<span class="p_add">+		mm = get_task_mm(task);</span>
<span class="p_add">+</span>
<span class="p_add">+	/* release the task struct that was taken earlier */</span>
<span class="p_add">+	if (task)</span>
<span class="p_add">+		put_task_struct(task);</span>
<span class="p_add">+	else</span>
<span class="p_add">+		pr_devel(&quot;%s: Context owning pid=%i for pe=%i dead\n&quot;,</span>
<span class="p_add">+			__func__, pid_nr(old_pid), ctx-&gt;pe);</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * If we couldn&#39;t find the mm context then use the group</span>
<span class="p_add">+	 * leader to iterate over the task group and find a task</span>
<span class="p_add">+	 * that gives us mm_struct.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	if (unlikely(mm == NULL &amp;&amp; ctx-&gt;glpid != NULL)) {</span>
<span class="p_add">+</span>
<span class="p_add">+		rcu_read_lock();</span>
<span class="p_add">+		task = pid_task(ctx-&gt;glpid, PIDTYPE_PID);</span>
<span class="p_add">+		if (task)</span>
<span class="p_add">+			do {</span>
<span class="p_add">+				mm = get_task_mm(task);</span>
<span class="p_add">+				if (mm) {</span>
<span class="p_add">+					ctx-&gt;pid = get_task_pid(task,</span>
<span class="p_add">+								PIDTYPE_PID);</span>
<span class="p_add">+					break;</span>
<span class="p_add">+				}</span>
<span class="p_add">+				task = next_thread(task);</span>
<span class="p_add">+			} while (task &amp;&amp; !thread_group_leader(task));</span>
<span class="p_add">+		rcu_read_unlock();</span>
<span class="p_add">+</span>
<span class="p_add">+		/* check if we switched pid */</span>
<span class="p_add">+		if (ctx-&gt;pid != old_pid) {</span>
<span class="p_add">+			if (mm)</span>
<span class="p_add">+				pr_devel(&quot;%s:pe=%i switch pid %i-&gt;%i\n&quot;,</span>
<span class="p_add">+					 __func__, ctx-&gt;pe, pid_nr(old_pid),</span>
<span class="p_add">+					 pid_nr(ctx-&gt;pid));</span>
<span class="p_add">+			else</span>
<span class="p_add">+				pr_devel(&quot;%s:Cannot find mm for pid=%i\n&quot;,</span>
<span class="p_add">+					 __func__, pid_nr(old_pid));</span>
<span class="p_add">+</span>
<span class="p_add">+			/* drop the reference to older pid */</span>
<span class="p_add">+			put_pid(old_pid);</span>
<span class="p_add">+		}</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	return mm;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+</span>
<span class="p_add">+</span>
 void cxl_handle_fault(struct work_struct *fault_work)
 {
 	struct cxl_context *ctx =
 		container_of(fault_work, struct cxl_context, fault_work);
 	u64 dsisr = ctx-&gt;dsisr;
 	u64 dar = ctx-&gt;dar;
<span class="p_del">-	struct task_struct *task = NULL;</span>
 	struct mm_struct *mm = NULL;
 
 	if (cxl_p2n_read(ctx-&gt;afu, CXL_PSL_DSISR_An) != dsisr ||
<span class="p_chunk">@@ -195,17 +274,17 @@</span> <span class="p_context"> void cxl_handle_fault(struct work_struct *fault_work)</span>
 		&quot;DSISR: %#llx DAR: %#llx\n&quot;, ctx-&gt;pe, dsisr, dar);
 
 	if (!ctx-&gt;kernel) {
<span class="p_del">-		if (!(task = get_pid_task(ctx-&gt;pid, PIDTYPE_PID))) {</span>
<span class="p_del">-			pr_devel(&quot;cxl_handle_fault unable to get task %i\n&quot;,</span>
<span class="p_del">-				 pid_nr(ctx-&gt;pid));</span>
<span class="p_add">+</span>
<span class="p_add">+		mm = get_mem_context(ctx);</span>
<span class="p_add">+		/* indicates all the thread in task group have exited */</span>
<span class="p_add">+		if (mm == NULL) {</span>
<span class="p_add">+			pr_devel(&quot;%s: unable to get mm for pe=%d pid=%i\n&quot;,</span>
<span class="p_add">+				 __func__, ctx-&gt;pe, pid_nr(ctx-&gt;pid));</span>
 			cxl_ack_ae(ctx);
 			return;
<span class="p_del">-		}</span>
<span class="p_del">-		if (!(mm = get_task_mm(task))) {</span>
<span class="p_del">-			pr_devel(&quot;cxl_handle_fault unable to get mm %i\n&quot;,</span>
<span class="p_del">-				 pid_nr(ctx-&gt;pid));</span>
<span class="p_del">-			cxl_ack_ae(ctx);</span>
<span class="p_del">-			goto out;</span>
<span class="p_add">+		} else {</span>
<span class="p_add">+			pr_devel(&quot;Handling page fault for pe=%d pid=%i\n&quot;,</span>
<span class="p_add">+				 ctx-&gt;pe, pid_nr(ctx-&gt;pid));</span>
 		}
 	}
 
<span class="p_chunk">@@ -218,33 +297,22 @@</span> <span class="p_context"> void cxl_handle_fault(struct work_struct *fault_work)</span>
 
 	if (mm)
 		mmput(mm);
<span class="p_del">-out:</span>
<span class="p_del">-	if (task)</span>
<span class="p_del">-		put_task_struct(task);</span>
 }
 
 static void cxl_prefault_one(struct cxl_context *ctx, u64 ea)
 {
<span class="p_del">-	int rc;</span>
<span class="p_del">-	struct task_struct *task;</span>
 	struct mm_struct *mm;
 
<span class="p_del">-	if (!(task = get_pid_task(ctx-&gt;pid, PIDTYPE_PID))) {</span>
<span class="p_del">-		pr_devel(&quot;cxl_prefault_one unable to get task %i\n&quot;,</span>
<span class="p_del">-			 pid_nr(ctx-&gt;pid));</span>
<span class="p_del">-		return;</span>
<span class="p_del">-	}</span>
<span class="p_del">-	if (!(mm = get_task_mm(task))) {</span>
<span class="p_add">+	mm = get_mem_context(ctx);</span>
<span class="p_add">+	if (mm == NULL) {</span>
 		pr_devel(&quot;cxl_prefault_one unable to get mm %i\n&quot;,
 			 pid_nr(ctx-&gt;pid));
<span class="p_del">-		put_task_struct(task);</span>
 		return;
 	}
 
<span class="p_del">-	rc = cxl_fault_segment(ctx, mm, ea);</span>
<span class="p_add">+	cxl_fault_segment(ctx, mm, ea);</span>
 
 	mmput(mm);
<span class="p_del">-	put_task_struct(task);</span>
 }
 
 static u64 next_segment(u64 ea, u64 vsid)
<span class="p_chunk">@@ -263,18 +331,13 @@</span> <span class="p_context"> static void cxl_prefault_vma(struct cxl_context *ctx)</span>
 	struct copro_slb slb;
 	struct vm_area_struct *vma;
 	int rc;
<span class="p_del">-	struct task_struct *task;</span>
 	struct mm_struct *mm;
 
<span class="p_del">-	if (!(task = get_pid_task(ctx-&gt;pid, PIDTYPE_PID))) {</span>
<span class="p_del">-		pr_devel(&quot;cxl_prefault_vma unable to get task %i\n&quot;,</span>
<span class="p_del">-			 pid_nr(ctx-&gt;pid));</span>
<span class="p_del">-		return;</span>
<span class="p_del">-	}</span>
<span class="p_del">-	if (!(mm = get_task_mm(task))) {</span>
<span class="p_add">+	mm = get_mem_context(ctx);</span>
<span class="p_add">+	if (mm == NULL) {</span>
 		pr_devel(&quot;cxl_prefault_vm unable to get mm %i\n&quot;,
 			 pid_nr(ctx-&gt;pid));
<span class="p_del">-		goto out1;</span>
<span class="p_add">+		return;</span>
 	}
 
 	down_read(&amp;mm-&gt;mmap_sem);
<span class="p_chunk">@@ -295,8 +358,6 @@</span> <span class="p_context"> static void cxl_prefault_vma(struct cxl_context *ctx)</span>
 	up_read(&amp;mm-&gt;mmap_sem);
 
 	mmput(mm);
<span class="p_del">-out1:</span>
<span class="p_del">-	put_task_struct(task);</span>
 }
 
 void cxl_prefault(struct cxl_context *ctx, u64 wed)
<span class="p_header">diff --git a/drivers/misc/cxl/file.c b/drivers/misc/cxl/file.c</span>
<span class="p_header">index 7ccd2998be92..783337d22f36 100644</span>
<span class="p_header">--- a/drivers/misc/cxl/file.c</span>
<span class="p_header">+++ b/drivers/misc/cxl/file.c</span>
<span class="p_chunk">@@ -67,7 +67,13 @@</span> <span class="p_context"> static int __afu_open(struct inode *inode, struct file *file, bool master)</span>
 		spin_unlock(&amp;adapter-&gt;afu_list_lock);
 		goto err_put_adapter;
 	}
<span class="p_del">-	get_device(&amp;afu-&gt;dev);</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * taking a ref to the afu so that it doesn&#39;t go away</span>
<span class="p_add">+	 * for rest of the function. This ref is released before</span>
<span class="p_add">+	 * we return.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	cxl_afu_get(afu);</span>
 	spin_unlock(&amp;adapter-&gt;afu_list_lock);
 
 	if (!afu-&gt;current_mode)
<span class="p_chunk">@@ -90,13 +96,12 @@</span> <span class="p_context"> static int __afu_open(struct inode *inode, struct file *file, bool master)</span>
 	file-&gt;private_data = ctx;
 	cxl_ctx_get();
 
<span class="p_del">-	/* Our ref on the AFU will now hold the adapter */</span>
<span class="p_del">-	put_device(&amp;adapter-&gt;dev);</span>
<span class="p_del">-</span>
<span class="p_del">-	return 0;</span>
<span class="p_add">+	/* indicate success */</span>
<span class="p_add">+	rc = 0;</span>
 
 err_put_afu:
<span class="p_del">-	put_device(&amp;afu-&gt;dev);</span>
<span class="p_add">+	/* release the ref taken earlier */</span>
<span class="p_add">+	cxl_afu_put(afu);</span>
 err_put_adapter:
 	put_device(&amp;adapter-&gt;dev);
 	return rc;
<span class="p_chunk">@@ -131,8 +136,6 @@</span> <span class="p_context"> int afu_release(struct inode *inode, struct file *file)</span>
 		mutex_unlock(&amp;ctx-&gt;mapping_lock);
 	}
 
<span class="p_del">-	put_device(&amp;ctx-&gt;afu-&gt;dev);</span>
<span class="p_del">-</span>
 	/*
 	 * At this this point all bottom halfs have finished and we should be
 	 * getting no more IRQs from the hardware for this context.  Once it&#39;s
<span class="p_chunk">@@ -198,8 +201,12 @@</span> <span class="p_context"> static long afu_ioctl_start_work(struct cxl_context *ctx,</span>
 	 * where a process (master, some daemon, etc) has opened the chardev on
 	 * behalf of another process, so the AFU&#39;s mm gets bound to the process
 	 * that performs this ioctl and not the process that opened the file.
<span class="p_add">+	 * Also we grab the PID of the group leader so that if the task that</span>
<span class="p_add">+	 * has performed the attach operation exits the mm context of the</span>
<span class="p_add">+	 * process is still accessible.</span>
 	 */
<span class="p_del">-	ctx-&gt;pid = get_pid(get_task_pid(current, PIDTYPE_PID));</span>
<span class="p_add">+	ctx-&gt;pid = get_task_pid(current, PIDTYPE_PID);</span>
<span class="p_add">+	ctx-&gt;glpid = get_task_pid(current-&gt;group_leader, PIDTYPE_PID);</span>
 
 	trace_cxl_attach(ctx, work.work_element_descriptor, work.num_interrupts, amr);
 
<span class="p_header">diff --git a/drivers/misc/cxl/pci.c b/drivers/misc/cxl/pci.c</span>
<span class="p_header">index be2c8e248e2e..0c6c17a1c59e 100644</span>
<span class="p_header">--- a/drivers/misc/cxl/pci.c</span>
<span class="p_header">+++ b/drivers/misc/cxl/pci.c</span>
<span class="p_chunk">@@ -138,6 +138,7 @@</span> <span class="p_context"> static const struct pci_device_id cxl_pci_tbl[] = {</span>
 	{ PCI_DEVICE(PCI_VENDOR_ID_IBM, 0x0477), },
 	{ PCI_DEVICE(PCI_VENDOR_ID_IBM, 0x044b), },
 	{ PCI_DEVICE(PCI_VENDOR_ID_IBM, 0x04cf), },
<span class="p_add">+	{ PCI_DEVICE(PCI_VENDOR_ID_IBM, 0x0601), },</span>
 	{ PCI_DEVICE_CLASS(0x120000, ~0), },
 
 	{ }
<span class="p_header">diff --git a/drivers/mmc/host/sdhci.c b/drivers/mmc/host/sdhci.c</span>
<span class="p_header">index 1a802af827ed..552a34dc4f82 100644</span>
<span class="p_header">--- a/drivers/mmc/host/sdhci.c</span>
<span class="p_header">+++ b/drivers/mmc/host/sdhci.c</span>
<span class="p_chunk">@@ -492,7 +492,7 @@</span> <span class="p_context"> static int sdhci_adma_table_pre(struct sdhci_host *host,</span>
 		host-&gt;align_buffer, host-&gt;align_buffer_sz, direction);
 	if (dma_mapping_error(mmc_dev(host-&gt;mmc), host-&gt;align_addr))
 		goto fail;
<span class="p_del">-	BUG_ON(host-&gt;align_addr &amp; host-&gt;align_mask);</span>
<span class="p_add">+	BUG_ON(host-&gt;align_addr &amp; SDHCI_ADMA2_MASK);</span>
 
 	host-&gt;sg_count = sdhci_pre_dma_transfer(host, data);
 	if (host-&gt;sg_count &lt; 0)
<span class="p_chunk">@@ -514,8 +514,8 @@</span> <span class="p_context"> static int sdhci_adma_table_pre(struct sdhci_host *host,</span>
 		 * the (up to three) bytes that screw up the
 		 * alignment.
 		 */
<span class="p_del">-		offset = (host-&gt;align_sz - (addr &amp; host-&gt;align_mask)) &amp;</span>
<span class="p_del">-			 host-&gt;align_mask;</span>
<span class="p_add">+		offset = (SDHCI_ADMA2_ALIGN - (addr &amp; SDHCI_ADMA2_MASK)) &amp;</span>
<span class="p_add">+			 SDHCI_ADMA2_MASK;</span>
 		if (offset) {
 			if (data-&gt;flags &amp; MMC_DATA_WRITE) {
 				buffer = sdhci_kmap_atomic(sg, &amp;flags);
<span class="p_chunk">@@ -529,8 +529,8 @@</span> <span class="p_context"> static int sdhci_adma_table_pre(struct sdhci_host *host,</span>
 
 			BUG_ON(offset &gt; 65536);
 
<span class="p_del">-			align += host-&gt;align_sz;</span>
<span class="p_del">-			align_addr += host-&gt;align_sz;</span>
<span class="p_add">+			align += SDHCI_ADMA2_ALIGN;</span>
<span class="p_add">+			align_addr += SDHCI_ADMA2_ALIGN;</span>
 
 			desc += host-&gt;desc_sz;
 
<span class="p_chunk">@@ -611,7 +611,7 @@</span> <span class="p_context"> static void sdhci_adma_table_post(struct sdhci_host *host,</span>
 	/* Do a quick scan of the SG list for any unaligned mappings */
 	has_unaligned = false;
 	for_each_sg(data-&gt;sg, sg, host-&gt;sg_count, i)
<span class="p_del">-		if (sg_dma_address(sg) &amp; host-&gt;align_mask) {</span>
<span class="p_add">+		if (sg_dma_address(sg) &amp; SDHCI_ADMA2_MASK) {</span>
 			has_unaligned = true;
 			break;
 		}
<span class="p_chunk">@@ -623,15 +623,15 @@</span> <span class="p_context"> static void sdhci_adma_table_post(struct sdhci_host *host,</span>
 		align = host-&gt;align_buffer;
 
 		for_each_sg(data-&gt;sg, sg, host-&gt;sg_count, i) {
<span class="p_del">-			if (sg_dma_address(sg) &amp; host-&gt;align_mask) {</span>
<span class="p_del">-				size = host-&gt;align_sz -</span>
<span class="p_del">-				       (sg_dma_address(sg) &amp; host-&gt;align_mask);</span>
<span class="p_add">+			if (sg_dma_address(sg) &amp; SDHCI_ADMA2_MASK) {</span>
<span class="p_add">+				size = SDHCI_ADMA2_ALIGN -</span>
<span class="p_add">+				       (sg_dma_address(sg) &amp; SDHCI_ADMA2_MASK);</span>
 
 				buffer = sdhci_kmap_atomic(sg, &amp;flags);
 				memcpy(buffer, align, size);
 				sdhci_kunmap_atomic(buffer, &amp;flags);
 
<span class="p_del">-				align += host-&gt;align_sz;</span>
<span class="p_add">+				align += SDHCI_ADMA2_ALIGN;</span>
 			}
 		}
 	}
<span class="p_chunk">@@ -1315,7 +1315,9 @@</span> <span class="p_context"> static void sdhci_set_power(struct sdhci_host *host, unsigned char mode,</span>
 			pwr = SDHCI_POWER_330;
 			break;
 		default:
<span class="p_del">-			BUG();</span>
<span class="p_add">+			WARN(1, &quot;%s: Invalid vdd %#x\n&quot;,</span>
<span class="p_add">+			     mmc_hostname(host-&gt;mmc), vdd);</span>
<span class="p_add">+			break;</span>
 		}
 	}
 
<span class="p_chunk">@@ -2983,24 +2985,17 @@</span> <span class="p_context"> int sdhci_add_host(struct sdhci_host *host)</span>
 		if (host-&gt;flags &amp; SDHCI_USE_64_BIT_DMA) {
 			host-&gt;adma_table_sz = (SDHCI_MAX_SEGS * 2 + 1) *
 					      SDHCI_ADMA2_64_DESC_SZ;
<span class="p_del">-			host-&gt;align_buffer_sz = SDHCI_MAX_SEGS *</span>
<span class="p_del">-						SDHCI_ADMA2_64_ALIGN;</span>
 			host-&gt;desc_sz = SDHCI_ADMA2_64_DESC_SZ;
<span class="p_del">-			host-&gt;align_sz = SDHCI_ADMA2_64_ALIGN;</span>
<span class="p_del">-			host-&gt;align_mask = SDHCI_ADMA2_64_ALIGN - 1;</span>
 		} else {
 			host-&gt;adma_table_sz = (SDHCI_MAX_SEGS * 2 + 1) *
 					      SDHCI_ADMA2_32_DESC_SZ;
<span class="p_del">-			host-&gt;align_buffer_sz = SDHCI_MAX_SEGS *</span>
<span class="p_del">-						SDHCI_ADMA2_32_ALIGN;</span>
 			host-&gt;desc_sz = SDHCI_ADMA2_32_DESC_SZ;
<span class="p_del">-			host-&gt;align_sz = SDHCI_ADMA2_32_ALIGN;</span>
<span class="p_del">-			host-&gt;align_mask = SDHCI_ADMA2_32_ALIGN - 1;</span>
 		}
 		host-&gt;adma_table = dma_alloc_coherent(mmc_dev(mmc),
 						      host-&gt;adma_table_sz,
 						      &amp;host-&gt;adma_addr,
 						      GFP_KERNEL);
<span class="p_add">+		host-&gt;align_buffer_sz = SDHCI_MAX_SEGS * SDHCI_ADMA2_ALIGN;</span>
 		host-&gt;align_buffer = kmalloc(host-&gt;align_buffer_sz, GFP_KERNEL);
 		if (!host-&gt;adma_table || !host-&gt;align_buffer) {
 			if (host-&gt;adma_table)
<span class="p_chunk">@@ -3014,7 +3009,7 @@</span> <span class="p_context"> int sdhci_add_host(struct sdhci_host *host)</span>
 			host-&gt;flags &amp;= ~SDHCI_USE_ADMA;
 			host-&gt;adma_table = NULL;
 			host-&gt;align_buffer = NULL;
<span class="p_del">-		} else if (host-&gt;adma_addr &amp; host-&gt;align_mask) {</span>
<span class="p_add">+		} else if (host-&gt;adma_addr &amp; (SDHCI_ADMA2_DESC_ALIGN - 1)) {</span>
 			pr_warn(&quot;%s: unable to allocate aligned ADMA descriptor\n&quot;,
 				mmc_hostname(mmc));
 			host-&gt;flags &amp;= ~SDHCI_USE_ADMA;
<span class="p_header">diff --git a/drivers/mmc/host/sdhci.h b/drivers/mmc/host/sdhci.h</span>
<span class="p_header">index 9c331ac5ad6b..0115e9907bf8 100644</span>
<span class="p_header">--- a/drivers/mmc/host/sdhci.h</span>
<span class="p_header">+++ b/drivers/mmc/host/sdhci.h</span>
<span class="p_chunk">@@ -272,22 +272,27 @@</span> <span class="p_context"></span>
 /* ADMA2 32-bit DMA descriptor size */
 #define SDHCI_ADMA2_32_DESC_SZ	8
 
<span class="p_del">-/* ADMA2 32-bit DMA alignment */</span>
<span class="p_del">-#define SDHCI_ADMA2_32_ALIGN	4</span>
<span class="p_del">-</span>
 /* ADMA2 32-bit descriptor */
 struct sdhci_adma2_32_desc {
 	__le16	cmd;
 	__le16	len;
 	__le32	addr;
<span class="p_del">-}  __packed __aligned(SDHCI_ADMA2_32_ALIGN);</span>
<span class="p_add">+}  __packed __aligned(4);</span>
<span class="p_add">+</span>
<span class="p_add">+/* ADMA2 data alignment */</span>
<span class="p_add">+#define SDHCI_ADMA2_ALIGN	4</span>
<span class="p_add">+#define SDHCI_ADMA2_MASK	(SDHCI_ADMA2_ALIGN - 1)</span>
<span class="p_add">+</span>
<span class="p_add">+/*</span>
<span class="p_add">+ * ADMA2 descriptor alignment.  Some controllers (e.g. Intel) require 8 byte</span>
<span class="p_add">+ * alignment for the descriptor table even in 32-bit DMA mode.  Memory</span>
<span class="p_add">+ * allocation is at least 8 byte aligned anyway, so just stipulate 8 always.</span>
<span class="p_add">+ */</span>
<span class="p_add">+#define SDHCI_ADMA2_DESC_ALIGN	8</span>
 
 /* ADMA2 64-bit DMA descriptor size */
 #define SDHCI_ADMA2_64_DESC_SZ	12
 
<span class="p_del">-/* ADMA2 64-bit DMA alignment */</span>
<span class="p_del">-#define SDHCI_ADMA2_64_ALIGN	8</span>
<span class="p_del">-</span>
 /*
  * ADMA2 64-bit descriptor. Note 12-byte descriptor can&#39;t always be 8-byte
  * aligned.
<span class="p_chunk">@@ -483,8 +488,6 @@</span> <span class="p_context"> struct sdhci_host {</span>
 	dma_addr_t align_addr;	/* Mapped bounce buffer */
 
 	unsigned int desc_sz;	/* ADMA descriptor size */
<span class="p_del">-	unsigned int align_sz;	/* ADMA alignment */</span>
<span class="p_del">-	unsigned int align_mask;	/* ADMA alignment mask */</span>
 
 	struct tasklet_struct finish_tasklet;	/* Tasklet structures */
 
<span class="p_header">diff --git a/drivers/net/ethernet/cavium/liquidio/lio_main.c b/drivers/net/ethernet/cavium/liquidio/lio_main.c</span>
<span class="p_header">index b89504405b72..7445da218bd9 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/cavium/liquidio/lio_main.c</span>
<span class="p_header">+++ b/drivers/net/ethernet/cavium/liquidio/lio_main.c</span>
<span class="p_chunk">@@ -2526,7 +2526,7 @@</span> <span class="p_context"> static void handle_timestamp(struct octeon_device *oct,</span>
 
 	octeon_swap_8B_data(&amp;resp-&gt;timestamp, 1);
 
<span class="p_del">-	if (unlikely((skb_shinfo(skb)-&gt;tx_flags | SKBTX_IN_PROGRESS) != 0)) {</span>
<span class="p_add">+	if (unlikely((skb_shinfo(skb)-&gt;tx_flags &amp; SKBTX_IN_PROGRESS) != 0)) {</span>
 		struct skb_shared_hwtstamps ts;
 		u64 ns = resp-&gt;timestamp;
 
<span class="p_header">diff --git a/drivers/net/ethernet/cavium/thunder/nic.h b/drivers/net/ethernet/cavium/thunder/nic.h</span>
<span class="p_header">index 39ca6744a4e6..22471d283a95 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/cavium/thunder/nic.h</span>
<span class="p_header">+++ b/drivers/net/ethernet/cavium/thunder/nic.h</span>
<span class="p_chunk">@@ -116,6 +116,15 @@</span> <span class="p_context"></span>
 #define NIC_PF_INTR_ID_MBOX0		8
 #define NIC_PF_INTR_ID_MBOX1		9
 
<span class="p_add">+/* Minimum FIFO level before all packets for the CQ are dropped</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * This value ensures that once a packet has been &quot;accepted&quot;</span>
<span class="p_add">+ * for reception it will not get dropped due to non-availability</span>
<span class="p_add">+ * of CQ descriptor. An errata in HW mandates this value to be</span>
<span class="p_add">+ * atleast 0x100.</span>
<span class="p_add">+ */</span>
<span class="p_add">+#define NICPF_CQM_MIN_DROP_LEVEL       0x100</span>
<span class="p_add">+</span>
 /* Global timer for CQ timer thresh interrupts
  * Calculated for SCLK of 700Mhz
  * value written should be a 1/16th of what is expected
<span class="p_header">diff --git a/drivers/net/ethernet/cavium/thunder/nic_main.c b/drivers/net/ethernet/cavium/thunder/nic_main.c</span>
<span class="p_header">index 5f24d11cb16a..16baaafed26c 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/cavium/thunder/nic_main.c</span>
<span class="p_header">+++ b/drivers/net/ethernet/cavium/thunder/nic_main.c</span>
<span class="p_chunk">@@ -309,6 +309,7 @@</span> <span class="p_context"> static void nic_set_lmac_vf_mapping(struct nicpf *nic)</span>
 static void nic_init_hw(struct nicpf *nic)
 {
 	int i;
<span class="p_add">+	u64 cqm_cfg;</span>
 
 	/* Enable NIC HW block */
 	nic_reg_write(nic, NIC_PF_CFG, 0x3);
<span class="p_chunk">@@ -345,6 +346,11 @@</span> <span class="p_context"> static void nic_init_hw(struct nicpf *nic)</span>
 	/* Enable VLAN ethertype matching and stripping */
 	nic_reg_write(nic, NIC_PF_RX_ETYPE_0_7,
 		      (2 &lt;&lt; 19) | (ETYPE_ALG_VLAN_STRIP &lt;&lt; 16) | ETH_P_8021Q);
<span class="p_add">+</span>
<span class="p_add">+	/* Check if HW expected value is higher (could be in future chips) */</span>
<span class="p_add">+	cqm_cfg = nic_reg_read(nic, NIC_PF_CQM_CFG);</span>
<span class="p_add">+	if (cqm_cfg &lt; NICPF_CQM_MIN_DROP_LEVEL)</span>
<span class="p_add">+		nic_reg_write(nic, NIC_PF_CQM_CFG, NICPF_CQM_MIN_DROP_LEVEL);</span>
 }
 
 /* Channel parse index configuration */
<span class="p_header">diff --git a/drivers/net/ethernet/cavium/thunder/nic_reg.h b/drivers/net/ethernet/cavium/thunder/nic_reg.h</span>
<span class="p_header">index dd536be20193..afb10e326b4f 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/cavium/thunder/nic_reg.h</span>
<span class="p_header">+++ b/drivers/net/ethernet/cavium/thunder/nic_reg.h</span>
<span class="p_chunk">@@ -21,7 +21,7 @@</span> <span class="p_context"></span>
 #define   NIC_PF_TCP_TIMER			(0x0060)
 #define   NIC_PF_BP_CFG				(0x0080)
 #define   NIC_PF_RRM_CFG			(0x0088)
<span class="p_del">-#define   NIC_PF_CQM_CF				(0x00A0)</span>
<span class="p_add">+#define   NIC_PF_CQM_CFG			(0x00A0)</span>
 #define   NIC_PF_CNM_CF				(0x00A8)
 #define   NIC_PF_CNM_STATUS			(0x00B0)
 #define   NIC_PF_CQ_AVG_CFG			(0x00C0)
<span class="p_header">diff --git a/drivers/net/ethernet/cavium/thunder/nicvf_main.c b/drivers/net/ethernet/cavium/thunder/nicvf_main.c</span>
<span class="p_header">index dde8dc720cd3..b7093b9cd1e8 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/cavium/thunder/nicvf_main.c</span>
<span class="p_header">+++ b/drivers/net/ethernet/cavium/thunder/nicvf_main.c</span>
<span class="p_chunk">@@ -566,8 +566,7 @@</span> <span class="p_context"> static inline void nicvf_set_rxhash(struct net_device *netdev,</span>
 
 static void nicvf_rcv_pkt_handler(struct net_device *netdev,
 				  struct napi_struct *napi,
<span class="p_del">-				  struct cmp_queue *cq,</span>
<span class="p_del">-				  struct cqe_rx_t *cqe_rx, int cqe_type)</span>
<span class="p_add">+				  struct cqe_rx_t *cqe_rx)</span>
 {
 	struct sk_buff *skb;
 	struct nicvf *nic = netdev_priv(netdev);
<span class="p_chunk">@@ -583,7 +582,7 @@</span> <span class="p_context"> static void nicvf_rcv_pkt_handler(struct net_device *netdev,</span>
 	}
 
 	/* Check for errors */
<span class="p_del">-	err = nicvf_check_cqe_rx_errs(nic, cq, cqe_rx);</span>
<span class="p_add">+	err = nicvf_check_cqe_rx_errs(nic, cqe_rx);</span>
 	if (err &amp;&amp; !cqe_rx-&gt;rb_cnt)
 		return;
 
<span class="p_chunk">@@ -674,8 +673,7 @@</span> <span class="p_context"> loop:</span>
 			   cq_idx, cq_desc-&gt;cqe_type);
 		switch (cq_desc-&gt;cqe_type) {
 		case CQE_TYPE_RX:
<span class="p_del">-			nicvf_rcv_pkt_handler(netdev, napi, cq,</span>
<span class="p_del">-					      cq_desc, CQE_TYPE_RX);</span>
<span class="p_add">+			nicvf_rcv_pkt_handler(netdev, napi, cq_desc);</span>
 			work_done++;
 		break;
 		case CQE_TYPE_SEND:
<span class="p_chunk">@@ -1117,7 +1115,6 @@</span> <span class="p_context"> int nicvf_stop(struct net_device *netdev)</span>
 
 	/* Clear multiqset info */
 	nic-&gt;pnicvf = nic;
<span class="p_del">-	nic-&gt;sqs_count = 0;</span>
 
 	return 0;
 }
<span class="p_chunk">@@ -1346,6 +1343,9 @@</span> <span class="p_context"> void nicvf_update_stats(struct nicvf *nic)</span>
 	drv_stats-&gt;tx_frames_ok = stats-&gt;tx_ucast_frames_ok +
 				  stats-&gt;tx_bcast_frames_ok +
 				  stats-&gt;tx_mcast_frames_ok;
<span class="p_add">+	drv_stats-&gt;rx_frames_ok = stats-&gt;rx_ucast_frames +</span>
<span class="p_add">+				  stats-&gt;rx_bcast_frames +</span>
<span class="p_add">+				  stats-&gt;rx_mcast_frames;</span>
 	drv_stats-&gt;rx_drops = stats-&gt;rx_drop_red +
 			      stats-&gt;rx_drop_overrun;
 	drv_stats-&gt;tx_drops = stats-&gt;tx_drops;
<span class="p_header">diff --git a/drivers/net/ethernet/cavium/thunder/nicvf_queues.c b/drivers/net/ethernet/cavium/thunder/nicvf_queues.c</span>
<span class="p_header">index d1c217eaf417..912ee28ab58b 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/cavium/thunder/nicvf_queues.c</span>
<span class="p_header">+++ b/drivers/net/ethernet/cavium/thunder/nicvf_queues.c</span>
<span class="p_chunk">@@ -1414,16 +1414,12 @@</span> <span class="p_context"> void nicvf_update_sq_stats(struct nicvf *nic, int sq_idx)</span>
 }
 
 /* Check for errors in the receive cmp.queue entry */
<span class="p_del">-int nicvf_check_cqe_rx_errs(struct nicvf *nic,</span>
<span class="p_del">-			    struct cmp_queue *cq, struct cqe_rx_t *cqe_rx)</span>
<span class="p_add">+int nicvf_check_cqe_rx_errs(struct nicvf *nic, struct cqe_rx_t *cqe_rx)</span>
 {
 	struct nicvf_hw_stats *stats = &amp;nic-&gt;hw_stats;
<span class="p_del">-	struct nicvf_drv_stats *drv_stats = &amp;nic-&gt;drv_stats;</span>
 
<span class="p_del">-	if (!cqe_rx-&gt;err_level &amp;&amp; !cqe_rx-&gt;err_opcode) {</span>
<span class="p_del">-		drv_stats-&gt;rx_frames_ok++;</span>
<span class="p_add">+	if (!cqe_rx-&gt;err_level &amp;&amp; !cqe_rx-&gt;err_opcode)</span>
 		return 0;
<span class="p_del">-	}</span>
 
 	if (netif_msg_rx_err(nic))
 		netdev_err(nic-&gt;netdev,
<span class="p_header">diff --git a/drivers/net/ethernet/cavium/thunder/nicvf_queues.h b/drivers/net/ethernet/cavium/thunder/nicvf_queues.h</span>
<span class="p_header">index 033e8306e91c..5652c612e20b 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/cavium/thunder/nicvf_queues.h</span>
<span class="p_header">+++ b/drivers/net/ethernet/cavium/thunder/nicvf_queues.h</span>
<span class="p_chunk">@@ -344,8 +344,7 @@</span> <span class="p_context"> u64  nicvf_queue_reg_read(struct nicvf *nic,</span>
 /* Stats */
 void nicvf_update_rq_stats(struct nicvf *nic, int rq_idx);
 void nicvf_update_sq_stats(struct nicvf *nic, int sq_idx);
<span class="p_del">-int nicvf_check_cqe_rx_errs(struct nicvf *nic,</span>
<span class="p_del">-			    struct cmp_queue *cq, struct cqe_rx_t *cqe_rx);</span>
<span class="p_add">+int nicvf_check_cqe_rx_errs(struct nicvf *nic, struct cqe_rx_t *cqe_rx);</span>
 int nicvf_check_cqe_tx_errs(struct nicvf *nic,
 			    struct cmp_queue *cq, struct cqe_send_t *cqe_tx);
 #endif /* NICVF_QUEUES_H */
<span class="p_header">diff --git a/drivers/net/ethernet/cavium/thunder/thunder_bgx.c b/drivers/net/ethernet/cavium/thunder/thunder_bgx.c</span>
<span class="p_header">index 9df26c2263bc..42718cc7d4e8 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/cavium/thunder/thunder_bgx.c</span>
<span class="p_header">+++ b/drivers/net/ethernet/cavium/thunder/thunder_bgx.c</span>
<span class="p_chunk">@@ -549,7 +549,9 @@</span> <span class="p_context"> static int bgx_xaui_check_link(struct lmac *lmac)</span>
 	}
 
 	/* Clear rcvflt bit (latching high) and read it back */
<span class="p_del">-	bgx_reg_modify(bgx, lmacid, BGX_SPUX_STATUS2, SPU_STATUS2_RCVFLT);</span>
<span class="p_add">+	if (bgx_reg_read(bgx, lmacid, BGX_SPUX_STATUS2) &amp; SPU_STATUS2_RCVFLT)</span>
<span class="p_add">+		bgx_reg_modify(bgx, lmacid,</span>
<span class="p_add">+			       BGX_SPUX_STATUS2, SPU_STATUS2_RCVFLT);</span>
 	if (bgx_reg_read(bgx, lmacid, BGX_SPUX_STATUS2) &amp; SPU_STATUS2_RCVFLT) {
 		dev_err(&amp;bgx-&gt;pdev-&gt;dev, &quot;Receive fault, retry training\n&quot;);
 		if (bgx-&gt;use_training) {
<span class="p_chunk">@@ -568,13 +570,6 @@</span> <span class="p_context"> static int bgx_xaui_check_link(struct lmac *lmac)</span>
 		return -1;
 	}
 
<span class="p_del">-	/* Wait for MAC RX to be ready */</span>
<span class="p_del">-	if (bgx_poll_reg(bgx, lmacid, BGX_SMUX_RX_CTL,</span>
<span class="p_del">-			 SMU_RX_CTL_STATUS, true)) {</span>
<span class="p_del">-		dev_err(&amp;bgx-&gt;pdev-&gt;dev, &quot;SMU RX link not okay\n&quot;);</span>
<span class="p_del">-		return -1;</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
 	/* Wait for BGX RX to be idle */
 	if (bgx_poll_reg(bgx, lmacid, BGX_SMUX_CTL, SMU_CTL_RX_IDLE, false)) {
 		dev_err(&amp;bgx-&gt;pdev-&gt;dev, &quot;SMU RX not idle\n&quot;);
<span class="p_chunk">@@ -587,29 +582,30 @@</span> <span class="p_context"> static int bgx_xaui_check_link(struct lmac *lmac)</span>
 		return -1;
 	}
 
<span class="p_del">-	if (bgx_reg_read(bgx, lmacid, BGX_SPUX_STATUS2) &amp; SPU_STATUS2_RCVFLT) {</span>
<span class="p_del">-		dev_err(&amp;bgx-&gt;pdev-&gt;dev, &quot;Receive fault\n&quot;);</span>
<span class="p_del">-		return -1;</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">-	/* Receive link is latching low. Force it high and verify it */</span>
<span class="p_del">-	bgx_reg_modify(bgx, lmacid, BGX_SPUX_STATUS1, SPU_STATUS1_RCV_LNK);</span>
<span class="p_del">-	if (bgx_poll_reg(bgx, lmacid, BGX_SPUX_STATUS1,</span>
<span class="p_del">-			 SPU_STATUS1_RCV_LNK, false)) {</span>
<span class="p_del">-		dev_err(&amp;bgx-&gt;pdev-&gt;dev, &quot;SPU receive link down\n&quot;);</span>
<span class="p_del">-		return -1;</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_add">+	/* Clear receive packet disable */</span>
 	cfg = bgx_reg_read(bgx, lmacid, BGX_SPUX_MISC_CONTROL);
 	cfg &amp;= ~SPU_MISC_CTL_RX_DIS;
 	bgx_reg_write(bgx, lmacid, BGX_SPUX_MISC_CONTROL, cfg);
<span class="p_del">-	return 0;</span>
<span class="p_add">+</span>
<span class="p_add">+	/* Check for MAC RX faults */</span>
<span class="p_add">+	cfg = bgx_reg_read(bgx, lmacid, BGX_SMUX_RX_CTL);</span>
<span class="p_add">+	/* 0 - Link is okay, 1 - Local fault, 2 - Remote fault */</span>
<span class="p_add">+	cfg &amp;= SMU_RX_CTL_STATUS;</span>
<span class="p_add">+	if (!cfg)</span>
<span class="p_add">+		return 0;</span>
<span class="p_add">+</span>
<span class="p_add">+	/* Rx local/remote fault seen.</span>
<span class="p_add">+	 * Do lmac reinit to see if condition recovers</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	bgx_lmac_xaui_init(bgx, lmacid, bgx-&gt;lmac_type);</span>
<span class="p_add">+</span>
<span class="p_add">+	return -1;</span>
 }
 
 static void bgx_poll_for_link(struct work_struct *work)
 {
 	struct lmac *lmac;
<span class="p_del">-	u64 link;</span>
<span class="p_add">+	u64 spu_link, smu_link;</span>
 
 	lmac = container_of(work, struct lmac, dwork.work);
 
<span class="p_chunk">@@ -619,8 +615,11 @@</span> <span class="p_context"> static void bgx_poll_for_link(struct work_struct *work)</span>
 	bgx_poll_reg(lmac-&gt;bgx, lmac-&gt;lmacid, BGX_SPUX_STATUS1,
 		     SPU_STATUS1_RCV_LNK, false);
 
<span class="p_del">-	link = bgx_reg_read(lmac-&gt;bgx, lmac-&gt;lmacid, BGX_SPUX_STATUS1);</span>
<span class="p_del">-	if (link &amp; SPU_STATUS1_RCV_LNK) {</span>
<span class="p_add">+	spu_link = bgx_reg_read(lmac-&gt;bgx, lmac-&gt;lmacid, BGX_SPUX_STATUS1);</span>
<span class="p_add">+	smu_link = bgx_reg_read(lmac-&gt;bgx, lmac-&gt;lmacid, BGX_SMUX_RX_CTL);</span>
<span class="p_add">+</span>
<span class="p_add">+	if ((spu_link &amp; SPU_STATUS1_RCV_LNK) &amp;&amp;</span>
<span class="p_add">+	    !(smu_link &amp; SMU_RX_CTL_STATUS)) {</span>
 		lmac-&gt;link_up = 1;
 		if (lmac-&gt;bgx-&gt;lmac_type == BGX_MODE_XLAUI)
 			lmac-&gt;last_speed = 40000;
<span class="p_chunk">@@ -634,9 +633,15 @@</span> <span class="p_context"> static void bgx_poll_for_link(struct work_struct *work)</span>
 	}
 
 	if (lmac-&gt;last_link != lmac-&gt;link_up) {
<span class="p_add">+		if (lmac-&gt;link_up) {</span>
<span class="p_add">+			if (bgx_xaui_check_link(lmac)) {</span>
<span class="p_add">+				/* Errors, clear link_up state */</span>
<span class="p_add">+				lmac-&gt;link_up = 0;</span>
<span class="p_add">+				lmac-&gt;last_speed = SPEED_UNKNOWN;</span>
<span class="p_add">+				lmac-&gt;last_duplex = DUPLEX_UNKNOWN;</span>
<span class="p_add">+			}</span>
<span class="p_add">+		}</span>
 		lmac-&gt;last_link = lmac-&gt;link_up;
<span class="p_del">-		if (lmac-&gt;link_up)</span>
<span class="p_del">-			bgx_xaui_check_link(lmac);</span>
 	}
 
 	queue_delayed_work(lmac-&gt;check_link, &amp;lmac-&gt;dwork, HZ * 2);
<span class="p_chunk">@@ -708,7 +713,7 @@</span> <span class="p_context"> static int bgx_lmac_enable(struct bgx *bgx, u8 lmacid)</span>
 static void bgx_lmac_disable(struct bgx *bgx, u8 lmacid)
 {
 	struct lmac *lmac;
<span class="p_del">-	u64 cmrx_cfg;</span>
<span class="p_add">+	u64 cfg;</span>
 
 	lmac = &amp;bgx-&gt;lmac[lmacid];
 	if (lmac-&gt;check_link) {
<span class="p_chunk">@@ -717,9 +722,33 @@</span> <span class="p_context"> static void bgx_lmac_disable(struct bgx *bgx, u8 lmacid)</span>
 		destroy_workqueue(lmac-&gt;check_link);
 	}
 
<span class="p_del">-	cmrx_cfg = bgx_reg_read(bgx, lmacid, BGX_CMRX_CFG);</span>
<span class="p_del">-	cmrx_cfg &amp;= ~(1 &lt;&lt; 15);</span>
<span class="p_del">-	bgx_reg_write(bgx, lmacid, BGX_CMRX_CFG, cmrx_cfg);</span>
<span class="p_add">+	/* Disable packet reception */</span>
<span class="p_add">+	cfg = bgx_reg_read(bgx, lmacid, BGX_CMRX_CFG);</span>
<span class="p_add">+	cfg &amp;= ~CMR_PKT_RX_EN;</span>
<span class="p_add">+	bgx_reg_write(bgx, lmacid, BGX_CMRX_CFG, cfg);</span>
<span class="p_add">+</span>
<span class="p_add">+	/* Give chance for Rx/Tx FIFO to get drained */</span>
<span class="p_add">+	bgx_poll_reg(bgx, lmacid, BGX_CMRX_RX_FIFO_LEN, (u64)0x1FFF, true);</span>
<span class="p_add">+	bgx_poll_reg(bgx, lmacid, BGX_CMRX_TX_FIFO_LEN, (u64)0x3FFF, true);</span>
<span class="p_add">+</span>
<span class="p_add">+	/* Disable packet transmission */</span>
<span class="p_add">+	cfg = bgx_reg_read(bgx, lmacid, BGX_CMRX_CFG);</span>
<span class="p_add">+	cfg &amp;= ~CMR_PKT_TX_EN;</span>
<span class="p_add">+	bgx_reg_write(bgx, lmacid, BGX_CMRX_CFG, cfg);</span>
<span class="p_add">+</span>
<span class="p_add">+	/* Disable serdes lanes */</span>
<span class="p_add">+        if (!lmac-&gt;is_sgmii)</span>
<span class="p_add">+                bgx_reg_modify(bgx, lmacid,</span>
<span class="p_add">+                               BGX_SPUX_CONTROL1, SPU_CTL_LOW_POWER);</span>
<span class="p_add">+        else</span>
<span class="p_add">+                bgx_reg_modify(bgx, lmacid,</span>
<span class="p_add">+                               BGX_GMP_PCS_MRX_CTL, PCS_MRX_CTL_PWR_DN);</span>
<span class="p_add">+</span>
<span class="p_add">+	/* Disable LMAC */</span>
<span class="p_add">+	cfg = bgx_reg_read(bgx, lmacid, BGX_CMRX_CFG);</span>
<span class="p_add">+	cfg &amp;= ~CMR_EN;</span>
<span class="p_add">+	bgx_reg_write(bgx, lmacid, BGX_CMRX_CFG, cfg);</span>
<span class="p_add">+</span>
 	bgx_flush_dmac_addrs(bgx, lmacid);
 
 	if ((bgx-&gt;lmac_type != BGX_MODE_XFI) &amp;&amp;
<span class="p_header">diff --git a/drivers/net/ethernet/cavium/thunder/thunder_bgx.h b/drivers/net/ethernet/cavium/thunder/thunder_bgx.h</span>
<span class="p_header">index 149e179363a1..42010d2e5ddf 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/cavium/thunder/thunder_bgx.h</span>
<span class="p_header">+++ b/drivers/net/ethernet/cavium/thunder/thunder_bgx.h</span>
<span class="p_chunk">@@ -41,6 +41,7 @@</span> <span class="p_context"></span>
 #define BGX_CMRX_RX_STAT10		0xC0
 #define BGX_CMRX_RX_BP_DROP		0xC8
 #define BGX_CMRX_RX_DMAC_CTL		0x0E8
<span class="p_add">+#define BGX_CMRX_RX_FIFO_LEN		0x108</span>
 #define BGX_CMR_RX_DMACX_CAM		0x200
 #define  RX_DMACX_CAM_EN			BIT_ULL(48)
 #define  RX_DMACX_CAM_LMACID(x)			(x &lt;&lt; 49)
<span class="p_chunk">@@ -50,6 +51,7 @@</span> <span class="p_context"></span>
 #define BGX_CMR_CHAN_MSK_AND		0x450
 #define BGX_CMR_BIST_STATUS		0x460
 #define BGX_CMR_RX_LMACS		0x468
<span class="p_add">+#define BGX_CMRX_TX_FIFO_LEN		0x518</span>
 #define BGX_CMRX_TX_STAT0		0x600
 #define BGX_CMRX_TX_STAT1		0x608
 #define BGX_CMRX_TX_STAT2		0x610
<span class="p_header">diff --git a/drivers/net/ethernet/intel/e1000/e1000.h b/drivers/net/ethernet/intel/e1000/e1000.h</span>
<span class="p_header">index 69707108d23c..98fe5a2cd6e3 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/intel/e1000/e1000.h</span>
<span class="p_header">+++ b/drivers/net/ethernet/intel/e1000/e1000.h</span>
<span class="p_chunk">@@ -213,8 +213,11 @@</span> <span class="p_context"> struct e1000_rx_ring {</span>
 };
 
 #define E1000_DESC_UNUSED(R)						\
<span class="p_del">-	((((R)-&gt;next_to_clean &gt; (R)-&gt;next_to_use)			\</span>
<span class="p_del">-	  ? 0 : (R)-&gt;count) + (R)-&gt;next_to_clean - (R)-&gt;next_to_use - 1)</span>
<span class="p_add">+({									\</span>
<span class="p_add">+	unsigned int clean = smp_load_acquire(&amp;(R)-&gt;next_to_clean);	\</span>
<span class="p_add">+	unsigned int use = READ_ONCE((R)-&gt;next_to_use);			\</span>
<span class="p_add">+	(clean &gt; use ? 0 : (R)-&gt;count) + clean - use - 1;		\</span>
<span class="p_add">+})</span>
 
 #define E1000_RX_DESC_EXT(R, i)						\
 	(&amp;(((union e1000_rx_desc_extended *)((R).desc))[i]))
<span class="p_header">diff --git a/drivers/net/ethernet/intel/e1000/e1000_main.c b/drivers/net/ethernet/intel/e1000/e1000_main.c</span>
<span class="p_header">index fd7be860c201..068023595d84 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/intel/e1000/e1000_main.c</span>
<span class="p_header">+++ b/drivers/net/ethernet/intel/e1000/e1000_main.c</span>
<span class="p_chunk">@@ -3876,7 +3876,10 @@</span> <span class="p_context"> static bool e1000_clean_tx_irq(struct e1000_adapter *adapter,</span>
 		eop_desc = E1000_TX_DESC(*tx_ring, eop);
 	}
 
<span class="p_del">-	tx_ring-&gt;next_to_clean = i;</span>
<span class="p_add">+	/* Synchronize with E1000_DESC_UNUSED called from e1000_xmit_frame,</span>
<span class="p_add">+	 * which will reuse the cleaned buffers.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	smp_store_release(&amp;tx_ring-&gt;next_to_clean, i);</span>
 
 	netdev_completed_queue(netdev, pkts_compl, bytes_compl);
 
<span class="p_header">diff --git a/drivers/net/ethernet/intel/e1000e/netdev.c b/drivers/net/ethernet/intel/e1000e/netdev.c</span>
<span class="p_header">index 0a854a47d31a..80ec587d510e 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/intel/e1000e/netdev.c</span>
<span class="p_header">+++ b/drivers/net/ethernet/intel/e1000e/netdev.c</span>
<span class="p_chunk">@@ -1959,8 +1959,10 @@</span> <span class="p_context"> static irqreturn_t e1000_intr_msix_rx(int __always_unused irq, void *data)</span>
 	 * previous interrupt.
 	 */
 	if (rx_ring-&gt;set_itr) {
<span class="p_del">-		writel(1000000000 / (rx_ring-&gt;itr_val * 256),</span>
<span class="p_del">-		       rx_ring-&gt;itr_register);</span>
<span class="p_add">+		u32 itr = rx_ring-&gt;itr_val ?</span>
<span class="p_add">+			  1000000000 / (rx_ring-&gt;itr_val * 256) : 0;</span>
<span class="p_add">+</span>
<span class="p_add">+		writel(itr, rx_ring-&gt;itr_register);</span>
 		rx_ring-&gt;set_itr = 0;
 	}
 
<span class="p_header">diff --git a/drivers/net/ethernet/intel/fm10k/fm10k.h b/drivers/net/ethernet/intel/fm10k/fm10k.h</span>
<span class="p_header">index 14440200499b..48809e5d3f79 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/intel/fm10k/fm10k.h</span>
<span class="p_header">+++ b/drivers/net/ethernet/intel/fm10k/fm10k.h</span>
<span class="p_chunk">@@ -33,7 +33,7 @@</span> <span class="p_context"></span>
 #include &quot;fm10k_pf.h&quot;
 #include &quot;fm10k_vf.h&quot;
 
<span class="p_del">-#define FM10K_MAX_JUMBO_FRAME_SIZE	15358	/* Maximum supported size 15K */</span>
<span class="p_add">+#define FM10K_MAX_JUMBO_FRAME_SIZE	15342	/* Maximum supported size 15K */</span>
 
 #define MAX_QUEUES	FM10K_MAX_QUEUES_PF
 
<span class="p_header">diff --git a/drivers/net/ethernet/intel/fm10k/fm10k_main.c b/drivers/net/ethernet/intel/fm10k/fm10k_main.c</span>
<span class="p_header">index e76a44cf330c..09281558bfbc 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/intel/fm10k/fm10k_main.c</span>
<span class="p_header">+++ b/drivers/net/ethernet/intel/fm10k/fm10k_main.c</span>
<span class="p_chunk">@@ -1428,6 +1428,10 @@</span> <span class="p_context"> static int fm10k_poll(struct napi_struct *napi, int budget)</span>
 	fm10k_for_each_ring(ring, q_vector-&gt;tx)
 		clean_complete &amp;= fm10k_clean_tx_irq(q_vector, ring);
 
<span class="p_add">+	/* Handle case where we are called by netpoll with a budget of 0 */</span>
<span class="p_add">+	if (budget &lt;= 0)</span>
<span class="p_add">+		return budget;</span>
<span class="p_add">+</span>
 	/* attempt to distribute budget to each queue fairly, but don&#39;t
 	 * allow the budget to go below 1 because we&#39;ll exit polling
 	 */
<span class="p_chunk">@@ -1966,8 +1970,10 @@</span> <span class="p_context"> int fm10k_init_queueing_scheme(struct fm10k_intfc *interface)</span>
 
 	/* Allocate memory for queues */
 	err = fm10k_alloc_q_vectors(interface);
<span class="p_del">-	if (err)</span>
<span class="p_add">+	if (err) {</span>
<span class="p_add">+		fm10k_reset_msix_capability(interface);</span>
 		return err;
<span class="p_add">+	}</span>
 
 	/* Map rings to devices, and map devices to physical queues */
 	fm10k_assign_rings(interface);
<span class="p_header">diff --git a/drivers/net/ethernet/intel/fm10k/fm10k_pci.c b/drivers/net/ethernet/intel/fm10k/fm10k_pci.c</span>
<span class="p_header">index 74be792f3f1b..7f3fb51bc37b 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/intel/fm10k/fm10k_pci.c</span>
<span class="p_header">+++ b/drivers/net/ethernet/intel/fm10k/fm10k_pci.c</span>
<span class="p_chunk">@@ -159,13 +159,30 @@</span> <span class="p_context"> static void fm10k_reinit(struct fm10k_intfc *interface)</span>
 
 	fm10k_mbx_free_irq(interface);
 
<span class="p_add">+	/* free interrupts */</span>
<span class="p_add">+	fm10k_clear_queueing_scheme(interface);</span>
<span class="p_add">+</span>
 	/* delay any future reset requests */
 	interface-&gt;last_reset = jiffies + (10 * HZ);
 
 	/* reset and initialize the hardware so it is in a known state */
<span class="p_del">-	err = hw-&gt;mac.ops.reset_hw(hw) ? : hw-&gt;mac.ops.init_hw(hw);</span>
<span class="p_del">-	if (err)</span>
<span class="p_add">+	err = hw-&gt;mac.ops.reset_hw(hw);</span>
<span class="p_add">+	if (err) {</span>
<span class="p_add">+		dev_err(&amp;interface-&gt;pdev-&gt;dev, &quot;reset_hw failed: %d\n&quot;, err);</span>
<span class="p_add">+		goto reinit_err;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	err = hw-&gt;mac.ops.init_hw(hw);</span>
<span class="p_add">+	if (err) {</span>
 		dev_err(&amp;interface-&gt;pdev-&gt;dev, &quot;init_hw failed: %d\n&quot;, err);
<span class="p_add">+		goto reinit_err;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	err = fm10k_init_queueing_scheme(interface);</span>
<span class="p_add">+	if (err) {</span>
<span class="p_add">+		dev_err(&amp;interface-&gt;pdev-&gt;dev, &quot;init_queueing_scheme failed: %d\n&quot;, err);</span>
<span class="p_add">+		goto reinit_err;</span>
<span class="p_add">+	}</span>
 
 	/* reassociate interrupts */
 	fm10k_mbx_request_irq(interface);
<span class="p_chunk">@@ -193,6 +210,10 @@</span> <span class="p_context"> static void fm10k_reinit(struct fm10k_intfc *interface)</span>
 
 	fm10k_iov_resume(interface-&gt;pdev);
 
<span class="p_add">+reinit_err:</span>
<span class="p_add">+	if (err)</span>
<span class="p_add">+		netif_device_detach(netdev);</span>
<span class="p_add">+</span>
 	rtnl_unlock();
 
 	clear_bit(__FM10K_RESETTING, &amp;interface-&gt;state);
<span class="p_chunk">@@ -1101,6 +1122,10 @@</span> <span class="p_context"> void fm10k_mbx_free_irq(struct fm10k_intfc *interface)</span>
 	struct fm10k_hw *hw = &amp;interface-&gt;hw;
 	int itr_reg;
 
<span class="p_add">+	/* no mailbox IRQ to free if MSI-X is not enabled */</span>
<span class="p_add">+	if (!interface-&gt;msix_entries)</span>
<span class="p_add">+		return;</span>
<span class="p_add">+</span>
 	/* disconnect the mailbox */
 	hw-&gt;mbx.ops.disconnect(hw, &amp;hw-&gt;mbx);
 
<span class="p_chunk">@@ -1423,10 +1448,15 @@</span> <span class="p_context"> int fm10k_mbx_request_irq(struct fm10k_intfc *interface)</span>
 		err = fm10k_mbx_request_irq_pf(interface);
 	else
 		err = fm10k_mbx_request_irq_vf(interface);
<span class="p_add">+	if (err)</span>
<span class="p_add">+		return err;</span>
 
 	/* connect mailbox */
<span class="p_del">-	if (!err)</span>
<span class="p_del">-		err = hw-&gt;mbx.ops.connect(hw, &amp;hw-&gt;mbx);</span>
<span class="p_add">+	err = hw-&gt;mbx.ops.connect(hw, &amp;hw-&gt;mbx);</span>
<span class="p_add">+</span>
<span class="p_add">+	/* if the mailbox failed to connect, then free IRQ */</span>
<span class="p_add">+	if (err)</span>
<span class="p_add">+		fm10k_mbx_free_irq(interface);</span>
 
 	return err;
 }
<span class="p_chunk">@@ -1684,7 +1714,13 @@</span> <span class="p_context"> static int fm10k_sw_init(struct fm10k_intfc *interface,</span>
 	interface-&gt;last_reset = jiffies + (10 * HZ);
 
 	/* reset and initialize the hardware so it is in a known state */
<span class="p_del">-	err = hw-&gt;mac.ops.reset_hw(hw) ? : hw-&gt;mac.ops.init_hw(hw);</span>
<span class="p_add">+	err = hw-&gt;mac.ops.reset_hw(hw);</span>
<span class="p_add">+	if (err) {</span>
<span class="p_add">+		dev_err(&amp;pdev-&gt;dev, &quot;reset_hw failed: %d\n&quot;, err);</span>
<span class="p_add">+		return err;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	err = hw-&gt;mac.ops.init_hw(hw);</span>
 	if (err) {
 		dev_err(&amp;pdev-&gt;dev, &quot;init_hw failed: %d\n&quot;, err);
 		return err;
<span class="p_chunk">@@ -2071,8 +2107,10 @@</span> <span class="p_context"> static int fm10k_resume(struct pci_dev *pdev)</span>
 
 	/* reset hardware to known state */
 	err = hw-&gt;mac.ops.init_hw(&amp;interface-&gt;hw);
<span class="p_del">-	if (err)</span>
<span class="p_add">+	if (err) {</span>
<span class="p_add">+		dev_err(&amp;pdev-&gt;dev, &quot;init_hw failed: %d\n&quot;, err);</span>
 		return err;
<span class="p_add">+	}</span>
 
 	/* reset statistics starting values */
 	hw-&gt;mac.ops.rebind_hw_stats(hw, &amp;interface-&gt;stats);
<span class="p_chunk">@@ -2185,6 +2223,9 @@</span> <span class="p_context"> static pci_ers_result_t fm10k_io_error_detected(struct pci_dev *pdev,</span>
 	if (netif_running(netdev))
 		fm10k_close(netdev);
 
<span class="p_add">+	/* free interrupts */</span>
<span class="p_add">+	fm10k_clear_queueing_scheme(interface);</span>
<span class="p_add">+</span>
 	fm10k_mbx_free_irq(interface);
 
 	pci_disable_device(pdev);
<span class="p_chunk">@@ -2248,11 +2289,21 @@</span> <span class="p_context"> static void fm10k_io_resume(struct pci_dev *pdev)</span>
 	int err = 0;
 
 	/* reset hardware to known state */
<span class="p_del">-	hw-&gt;mac.ops.init_hw(&amp;interface-&gt;hw);</span>
<span class="p_add">+	err = hw-&gt;mac.ops.init_hw(&amp;interface-&gt;hw);</span>
<span class="p_add">+	if (err) {</span>
<span class="p_add">+		dev_err(&amp;pdev-&gt;dev, &quot;init_hw failed: %d\n&quot;, err);</span>
<span class="p_add">+		return;</span>
<span class="p_add">+	}</span>
 
 	/* reset statistics starting values */
 	hw-&gt;mac.ops.rebind_hw_stats(hw, &amp;interface-&gt;stats);
 
<span class="p_add">+	err = fm10k_init_queueing_scheme(interface);</span>
<span class="p_add">+	if (err) {</span>
<span class="p_add">+		dev_err(&amp;interface-&gt;pdev-&gt;dev, &quot;init_queueing_scheme failed: %d\n&quot;, err);</span>
<span class="p_add">+		return;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
 	/* reassociate interrupts */
 	fm10k_mbx_request_irq(interface);
 
<span class="p_header">diff --git a/drivers/net/ethernet/intel/fm10k/fm10k_type.h b/drivers/net/ethernet/intel/fm10k/fm10k_type.h</span>
<span class="p_header">index 318a212f0a78..35afd711d144 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/intel/fm10k/fm10k_type.h</span>
<span class="p_header">+++ b/drivers/net/ethernet/intel/fm10k/fm10k_type.h</span>
<span class="p_chunk">@@ -77,6 +77,7 @@</span> <span class="p_context"> struct fm10k_hw;</span>
 #define FM10K_PCIE_SRIOV_CTRL_VFARI		0x10
 
 #define FM10K_ERR_PARAM				-2
<span class="p_add">+#define FM10K_ERR_NO_RESOURCES			-3</span>
 #define FM10K_ERR_REQUESTS_PENDING		-4
 #define FM10K_ERR_RESET_REQUESTED		-5
 #define FM10K_ERR_DMA_PENDING			-6
<span class="p_header">diff --git a/drivers/net/ethernet/intel/fm10k/fm10k_vf.c b/drivers/net/ethernet/intel/fm10k/fm10k_vf.c</span>
<span class="p_header">index 36c8b0aa08fd..d512575c33f3 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/intel/fm10k/fm10k_vf.c</span>
<span class="p_header">+++ b/drivers/net/ethernet/intel/fm10k/fm10k_vf.c</span>
<span class="p_chunk">@@ -103,7 +103,14 @@</span> <span class="p_context"> static s32 fm10k_init_hw_vf(struct fm10k_hw *hw)</span>
 	s32 err;
 	u16 i;
 
<span class="p_del">-	/* assume we always have at least 1 queue */</span>
<span class="p_add">+	/* verify we have at least 1 queue */</span>
<span class="p_add">+	if (!~fm10k_read_reg(hw, FM10K_TXQCTL(0)) ||</span>
<span class="p_add">+	    !~fm10k_read_reg(hw, FM10K_RXQCTL(0))) {</span>
<span class="p_add">+		err = FM10K_ERR_NO_RESOURCES;</span>
<span class="p_add">+		goto reset_max_queues;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	/* determine how many queues we have */</span>
 	for (i = 1; tqdloc0 &amp;&amp; (i &lt; FM10K_MAX_QUEUES_POOL); i++) {
 		/* verify the Descriptor cache offsets are increasing */
 		tqdloc = ~fm10k_read_reg(hw, FM10K_TQDLOC(i));
<span class="p_chunk">@@ -119,7 +126,7 @@</span> <span class="p_context"> static s32 fm10k_init_hw_vf(struct fm10k_hw *hw)</span>
 	/* shut down queues we own and reset DMA configuration */
 	err = fm10k_disable_queues_generic(hw, i);
 	if (err)
<span class="p_del">-		return err;</span>
<span class="p_add">+		goto reset_max_queues;</span>
 
 	/* record maximum queue count */
 	hw-&gt;mac.max_queues = i;
<span class="p_chunk">@@ -129,6 +136,11 @@</span> <span class="p_context"> static s32 fm10k_init_hw_vf(struct fm10k_hw *hw)</span>
 			       FM10K_TXQCTL_VID_MASK) &gt;&gt; FM10K_TXQCTL_VID_SHIFT;
 
 	return 0;
<span class="p_add">+</span>
<span class="p_add">+reset_max_queues:</span>
<span class="p_add">+	hw-&gt;mac.max_queues = 0;</span>
<span class="p_add">+</span>
<span class="p_add">+	return err;</span>
 }
 
 /* This structure defines the attibutes to be parsed below */
<span class="p_header">diff --git a/drivers/net/ethernet/intel/i40e/i40e.h b/drivers/net/ethernet/intel/i40e/i40e.h</span>
<span class="p_header">index 4dd3e26129b4..7e258a83ccab 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/intel/i40e/i40e.h</span>
<span class="p_header">+++ b/drivers/net/ethernet/intel/i40e/i40e.h</span>
<span class="p_chunk">@@ -767,6 +767,8 @@</span> <span class="p_context"> int i40e_vsi_add_vlan(struct i40e_vsi *vsi, s16 vid);</span>
 int i40e_vsi_kill_vlan(struct i40e_vsi *vsi, s16 vid);
 struct i40e_mac_filter *i40e_put_mac_in_vlan(struct i40e_vsi *vsi, u8 *macaddr,
 					     bool is_vf, bool is_netdev);
<span class="p_add">+int i40e_del_mac_all_vlan(struct i40e_vsi *vsi, u8 *macaddr,</span>
<span class="p_add">+			  bool is_vf, bool is_netdev);</span>
 bool i40e_is_vsi_in_vlan(struct i40e_vsi *vsi);
 struct i40e_mac_filter *i40e_find_mac(struct i40e_vsi *vsi, u8 *macaddr,
 				      bool is_vf, bool is_netdev);
<span class="p_header">diff --git a/drivers/net/ethernet/intel/i40e/i40e_ethtool.c b/drivers/net/ethernet/intel/i40e/i40e_ethtool.c</span>
<span class="p_header">index 3f385ffe420f..488a50d59dca 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/intel/i40e/i40e_ethtool.c</span>
<span class="p_header">+++ b/drivers/net/ethernet/intel/i40e/i40e_ethtool.c</span>
<span class="p_chunk">@@ -2164,8 +2164,7 @@</span> <span class="p_context"> static int i40e_set_rss_hash_opt(struct i40e_pf *pf, struct ethtool_rxnfc *nfc)</span>
 	case TCP_V4_FLOW:
 		switch (nfc-&gt;data &amp; (RXH_L4_B_0_1 | RXH_L4_B_2_3)) {
 		case 0:
<span class="p_del">-			hena &amp;= ~BIT_ULL(I40E_FILTER_PCTYPE_NONF_IPV4_TCP);</span>
<span class="p_del">-			break;</span>
<span class="p_add">+			return -EINVAL;</span>
 		case (RXH_L4_B_0_1 | RXH_L4_B_2_3):
 			hena |= BIT_ULL(I40E_FILTER_PCTYPE_NONF_IPV4_TCP);
 			break;
<span class="p_chunk">@@ -2176,8 +2175,7 @@</span> <span class="p_context"> static int i40e_set_rss_hash_opt(struct i40e_pf *pf, struct ethtool_rxnfc *nfc)</span>
 	case TCP_V6_FLOW:
 		switch (nfc-&gt;data &amp; (RXH_L4_B_0_1 | RXH_L4_B_2_3)) {
 		case 0:
<span class="p_del">-			hena &amp;= ~BIT_ULL(I40E_FILTER_PCTYPE_NONF_IPV6_TCP);</span>
<span class="p_del">-			break;</span>
<span class="p_add">+			return -EINVAL;</span>
 		case (RXH_L4_B_0_1 | RXH_L4_B_2_3):
 			hena |= BIT_ULL(I40E_FILTER_PCTYPE_NONF_IPV6_TCP);
 			break;
<span class="p_chunk">@@ -2188,9 +2186,7 @@</span> <span class="p_context"> static int i40e_set_rss_hash_opt(struct i40e_pf *pf, struct ethtool_rxnfc *nfc)</span>
 	case UDP_V4_FLOW:
 		switch (nfc-&gt;data &amp; (RXH_L4_B_0_1 | RXH_L4_B_2_3)) {
 		case 0:
<span class="p_del">-			hena &amp;= ~(BIT_ULL(I40E_FILTER_PCTYPE_NONF_IPV4_UDP) |</span>
<span class="p_del">-				  BIT_ULL(I40E_FILTER_PCTYPE_FRAG_IPV4));</span>
<span class="p_del">-			break;</span>
<span class="p_add">+			return -EINVAL;</span>
 		case (RXH_L4_B_0_1 | RXH_L4_B_2_3):
 			hena |= (BIT_ULL(I40E_FILTER_PCTYPE_NONF_IPV4_UDP) |
 				 BIT_ULL(I40E_FILTER_PCTYPE_FRAG_IPV4));
<span class="p_chunk">@@ -2202,9 +2198,7 @@</span> <span class="p_context"> static int i40e_set_rss_hash_opt(struct i40e_pf *pf, struct ethtool_rxnfc *nfc)</span>
 	case UDP_V6_FLOW:
 		switch (nfc-&gt;data &amp; (RXH_L4_B_0_1 | RXH_L4_B_2_3)) {
 		case 0:
<span class="p_del">-			hena &amp;= ~(BIT_ULL(I40E_FILTER_PCTYPE_NONF_IPV6_UDP) |</span>
<span class="p_del">-				  BIT_ULL(I40E_FILTER_PCTYPE_FRAG_IPV6));</span>
<span class="p_del">-			break;</span>
<span class="p_add">+			return -EINVAL;</span>
 		case (RXH_L4_B_0_1 | RXH_L4_B_2_3):
 			hena |= (BIT_ULL(I40E_FILTER_PCTYPE_NONF_IPV6_UDP) |
 				 BIT_ULL(I40E_FILTER_PCTYPE_FRAG_IPV6));
<span class="p_header">diff --git a/drivers/net/ethernet/intel/i40e/i40e_main.c b/drivers/net/ethernet/intel/i40e/i40e_main.c</span>
<span class="p_header">index 4a9873ec28c7..2215bebe208e 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/intel/i40e/i40e_main.c</span>
<span class="p_header">+++ b/drivers/net/ethernet/intel/i40e/i40e_main.c</span>
<span class="p_chunk">@@ -1317,6 +1317,42 @@</span> <span class="p_context"> struct i40e_mac_filter *i40e_put_mac_in_vlan(struct i40e_vsi *vsi, u8 *macaddr,</span>
 }
 
 /**
<span class="p_add">+ * i40e_del_mac_all_vlan - Remove a MAC filter from all VLANS</span>
<span class="p_add">+ * @vsi: the VSI to be searched</span>
<span class="p_add">+ * @macaddr: the mac address to be removed</span>
<span class="p_add">+ * @is_vf: true if it is a VF</span>
<span class="p_add">+ * @is_netdev: true if it is a netdev</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * Removes a given MAC address from a VSI, regardless of VLAN</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * Returns 0 for success, or error</span>
<span class="p_add">+ **/</span>
<span class="p_add">+int i40e_del_mac_all_vlan(struct i40e_vsi *vsi, u8 *macaddr,</span>
<span class="p_add">+			  bool is_vf, bool is_netdev)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct i40e_mac_filter *f = NULL;</span>
<span class="p_add">+	int changed = 0;</span>
<span class="p_add">+</span>
<span class="p_add">+	WARN(!spin_is_locked(&amp;vsi-&gt;mac_filter_list_lock),</span>
<span class="p_add">+	     &quot;Missing mac_filter_list_lock\n&quot;);</span>
<span class="p_add">+	list_for_each_entry(f, &amp;vsi-&gt;mac_filter_list, list) {</span>
<span class="p_add">+		if ((ether_addr_equal(macaddr, f-&gt;macaddr)) &amp;&amp;</span>
<span class="p_add">+		    (is_vf == f-&gt;is_vf) &amp;&amp;</span>
<span class="p_add">+		    (is_netdev == f-&gt;is_netdev)) {</span>
<span class="p_add">+			f-&gt;counter--;</span>
<span class="p_add">+			f-&gt;changed = true;</span>
<span class="p_add">+			changed = 1;</span>
<span class="p_add">+		}</span>
<span class="p_add">+	}</span>
<span class="p_add">+	if (changed) {</span>
<span class="p_add">+		vsi-&gt;flags |= I40E_VSI_FLAG_FILTER_CHANGED;</span>
<span class="p_add">+		vsi-&gt;back-&gt;flags |= I40E_FLAG_FILTER_SYNC;</span>
<span class="p_add">+		return 0;</span>
<span class="p_add">+	}</span>
<span class="p_add">+	return -ENOENT;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+/**</span>
  * i40e_rm_default_mac_filter - Remove the default MAC filter set by NVM
  * @vsi: the PF Main VSI - inappropriate for any other VSI
  * @macaddr: the MAC address
<span class="p_chunk">@@ -1547,9 +1583,11 @@</span> <span class="p_context"> static int i40e_set_mac(struct net_device *netdev, void *p)</span>
 		spin_unlock_bh(&amp;vsi-&gt;mac_filter_list_lock);
 	}
 
<span class="p_del">-	i40e_sync_vsi_filters(vsi, false);</span>
 	ether_addr_copy(netdev-&gt;dev_addr, addr-&gt;sa_data);
<span class="p_del">-</span>
<span class="p_add">+	/* schedule our worker thread which will take care of</span>
<span class="p_add">+	 * applying the new filter changes</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	i40e_service_event_schedule(vsi-&gt;back);</span>
 	return 0;
 }
 
<span class="p_chunk">@@ -1935,11 +1973,13 @@</span> <span class="p_context"> int i40e_sync_vsi_filters(struct i40e_vsi *vsi, bool grab_rtnl)</span>
 
 	/* Now process &#39;del_list&#39; outside the lock */
 	if (!list_empty(&amp;tmp_del_list)) {
<span class="p_add">+		int del_list_size;</span>
<span class="p_add">+</span>
 		filter_list_len = pf-&gt;hw.aq.asq_buf_size /
 			    sizeof(struct i40e_aqc_remove_macvlan_element_data);
<span class="p_del">-		del_list = kcalloc(filter_list_len,</span>
<span class="p_del">-			    sizeof(struct i40e_aqc_remove_macvlan_element_data),</span>
<span class="p_del">-			    GFP_KERNEL);</span>
<span class="p_add">+		del_list_size = filter_list_len *</span>
<span class="p_add">+			    sizeof(struct i40e_aqc_remove_macvlan_element_data);</span>
<span class="p_add">+		del_list = kzalloc(del_list_size, GFP_KERNEL);</span>
 		if (!del_list) {
 			i40e_cleanup_add_list(&amp;tmp_add_list);
 
<span class="p_chunk">@@ -1971,7 +2011,7 @@</span> <span class="p_context"> int i40e_sync_vsi_filters(struct i40e_vsi *vsi, bool grab_rtnl)</span>
 						  NULL);
 				aq_err = pf-&gt;hw.aq.asq_last_status;
 				num_del = 0;
<span class="p_del">-				memset(del_list, 0, sizeof(*del_list));</span>
<span class="p_add">+				memset(del_list, 0, del_list_size);</span>
 
 				if (ret &amp;&amp; aq_err != I40E_AQ_RC_ENOENT)
 					dev_err(&amp;pf-&gt;pdev-&gt;dev,
<span class="p_chunk">@@ -2004,13 +2044,14 @@</span> <span class="p_context"> int i40e_sync_vsi_filters(struct i40e_vsi *vsi, bool grab_rtnl)</span>
 	}
 
 	if (!list_empty(&amp;tmp_add_list)) {
<span class="p_add">+		int add_list_size;</span>
 
 		/* do all the adds now */
 		filter_list_len = pf-&gt;hw.aq.asq_buf_size /
 			       sizeof(struct i40e_aqc_add_macvlan_element_data),
<span class="p_del">-		add_list = kcalloc(filter_list_len,</span>
<span class="p_del">-			       sizeof(struct i40e_aqc_add_macvlan_element_data),</span>
<span class="p_del">-			       GFP_KERNEL);</span>
<span class="p_add">+		add_list_size = filter_list_len *</span>
<span class="p_add">+			       sizeof(struct i40e_aqc_add_macvlan_element_data);</span>
<span class="p_add">+		add_list = kzalloc(add_list_size, GFP_KERNEL);</span>
 		if (!add_list) {
 			/* Purge element from temporary lists */
 			i40e_cleanup_add_list(&amp;tmp_add_list);
<span class="p_chunk">@@ -2048,7 +2089,7 @@</span> <span class="p_context"> int i40e_sync_vsi_filters(struct i40e_vsi *vsi, bool grab_rtnl)</span>
 
 				if (ret)
 					break;
<span class="p_del">-				memset(add_list, 0, sizeof(*add_list));</span>
<span class="p_add">+				memset(add_list, 0, add_list_size);</span>
 			}
 			/* Entries from tmp_add_list were cloned from MAC
 			 * filter list, hence clean those cloned entries
<span class="p_chunk">@@ -2112,12 +2153,7 @@</span> <span class="p_context"> int i40e_sync_vsi_filters(struct i40e_vsi *vsi, bool grab_rtnl)</span>
 			 */
 			if (pf-&gt;cur_promisc != cur_promisc) {
 				pf-&gt;cur_promisc = cur_promisc;
<span class="p_del">-				if (grab_rtnl)</span>
<span class="p_del">-					i40e_do_reset_safe(pf,</span>
<span class="p_del">-						BIT(__I40E_PF_RESET_REQUESTED));</span>
<span class="p_del">-				else</span>
<span class="p_del">-					i40e_do_reset(pf,</span>
<span class="p_del">-						BIT(__I40E_PF_RESET_REQUESTED));</span>
<span class="p_add">+				set_bit(__I40E_PF_RESET_REQUESTED, &amp;pf-&gt;state);</span>
 			}
 		} else {
 			ret = i40e_aq_set_vsi_unicast_promiscuous(
<span class="p_chunk">@@ -2377,16 +2413,13 @@</span> <span class="p_context"> int i40e_vsi_add_vlan(struct i40e_vsi *vsi, s16 vid)</span>
 		}
 	}
 
<span class="p_del">-	/* Make sure to release before sync_vsi_filter because that</span>
<span class="p_del">-	 * function will lock/unlock as necessary</span>
<span class="p_del">-	 */</span>
 	spin_unlock_bh(&amp;vsi-&gt;mac_filter_list_lock);
 
<span class="p_del">-	if (test_bit(__I40E_DOWN, &amp;vsi-&gt;back-&gt;state) ||</span>
<span class="p_del">-	    test_bit(__I40E_RESET_RECOVERY_PENDING, &amp;vsi-&gt;back-&gt;state))</span>
<span class="p_del">-		return 0;</span>
<span class="p_del">-</span>
<span class="p_del">-	return i40e_sync_vsi_filters(vsi, false);</span>
<span class="p_add">+	/* schedule our worker thread which will take care of</span>
<span class="p_add">+	 * applying the new filter changes</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	i40e_service_event_schedule(vsi-&gt;back);</span>
<span class="p_add">+	return 0;</span>
 }
 
 /**
<span class="p_chunk">@@ -2459,16 +2492,13 @@</span> <span class="p_context"> int i40e_vsi_kill_vlan(struct i40e_vsi *vsi, s16 vid)</span>
 		}
 	}
 
<span class="p_del">-	/* Make sure to release before sync_vsi_filter because that</span>
<span class="p_del">-	 * function with lock/unlock as necessary</span>
<span class="p_del">-	 */</span>
 	spin_unlock_bh(&amp;vsi-&gt;mac_filter_list_lock);
 
<span class="p_del">-	if (test_bit(__I40E_DOWN, &amp;vsi-&gt;back-&gt;state) ||</span>
<span class="p_del">-	    test_bit(__I40E_RESET_RECOVERY_PENDING, &amp;vsi-&gt;back-&gt;state))</span>
<span class="p_del">-		return 0;</span>
<span class="p_del">-</span>
<span class="p_del">-	return i40e_sync_vsi_filters(vsi, false);</span>
<span class="p_add">+	/* schedule our worker thread which will take care of</span>
<span class="p_add">+	 * applying the new filter changes</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	i40e_service_event_schedule(vsi-&gt;back);</span>
<span class="p_add">+	return 0;</span>
 }
 
 /**
<span class="p_chunk">@@ -2711,6 +2741,11 @@</span> <span class="p_context"> static void i40e_config_xps_tx_ring(struct i40e_ring *ring)</span>
 		netif_set_xps_queue(ring-&gt;netdev, mask, ring-&gt;queue_index);
 		free_cpumask_var(mask);
 	}
<span class="p_add">+</span>
<span class="p_add">+	/* schedule our worker thread which will take care of</span>
<span class="p_add">+	 * applying the new filter changes</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	i40e_service_event_schedule(vsi-&gt;back);</span>
 }
 
 /**
<span class="p_chunk">@@ -6685,6 +6720,7 @@</span> <span class="p_context"> static void i40e_reset_and_rebuild(struct i40e_pf *pf, bool reinit)</span>
 	struct i40e_hw *hw = &amp;pf-&gt;hw;
 	u8 set_fc_aq_fail = 0;
 	i40e_status ret;
<span class="p_add">+	u32 val;</span>
 	u32 v;
 
 	/* Now we wait for GRST to settle out.
<span class="p_chunk">@@ -6823,6 +6859,20 @@</span> <span class="p_context"> static void i40e_reset_and_rebuild(struct i40e_pf *pf, bool reinit)</span>
 		}
 	}
 
<span class="p_add">+	/* Reconfigure hardware for allowing smaller MSS in the case</span>
<span class="p_add">+	 * of TSO, so that we avoid the MDD being fired and causing</span>
<span class="p_add">+	 * a reset in the case of small MSS+TSO.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+#define I40E_REG_MSS          0x000E64DC</span>
<span class="p_add">+#define I40E_REG_MSS_MIN_MASK 0x3FF0000</span>
<span class="p_add">+#define I40E_64BYTE_MSS       0x400000</span>
<span class="p_add">+	val = rd32(hw, I40E_REG_MSS);</span>
<span class="p_add">+	if ((val &amp; I40E_REG_MSS_MIN_MASK) &gt; I40E_64BYTE_MSS) {</span>
<span class="p_add">+		val &amp;= ~I40E_REG_MSS_MIN_MASK;</span>
<span class="p_add">+		val |= I40E_64BYTE_MSS;</span>
<span class="p_add">+		wr32(hw, I40E_REG_MSS, val);</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
 	if (((pf-&gt;hw.aq.fw_maj_ver == 4) &amp;&amp; (pf-&gt;hw.aq.fw_min_ver &lt; 33)) ||
 	    (pf-&gt;hw.aq.fw_maj_ver &lt; 4)) {
 		msleep(75);
<span class="p_chunk">@@ -10183,6 +10233,7 @@</span> <span class="p_context"> static int i40e_probe(struct pci_dev *pdev, const struct pci_device_id *ent)</span>
 	u16 link_status;
 	int err;
 	u32 len;
<span class="p_add">+	u32 val;</span>
 	u32 i;
 	u8 set_fc_aq_fail;
 
<span class="p_chunk">@@ -10493,6 +10544,17 @@</span> <span class="p_context"> static int i40e_probe(struct pci_dev *pdev, const struct pci_device_id *ent)</span>
 			 i40e_stat_str(&amp;pf-&gt;hw, err),
 			 i40e_aq_str(&amp;pf-&gt;hw, pf-&gt;hw.aq.asq_last_status));
 
<span class="p_add">+	/* Reconfigure hardware for allowing smaller MSS in the case</span>
<span class="p_add">+	 * of TSO, so that we avoid the MDD being fired and causing</span>
<span class="p_add">+	 * a reset in the case of small MSS+TSO.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	val = rd32(hw, I40E_REG_MSS);</span>
<span class="p_add">+	if ((val &amp; I40E_REG_MSS_MIN_MASK) &gt; I40E_64BYTE_MSS) {</span>
<span class="p_add">+		val &amp;= ~I40E_REG_MSS_MIN_MASK;</span>
<span class="p_add">+		val |= I40E_64BYTE_MSS;</span>
<span class="p_add">+		wr32(hw, I40E_REG_MSS, val);</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
 	if (((pf-&gt;hw.aq.fw_maj_ver == 4) &amp;&amp; (pf-&gt;hw.aq.fw_min_ver &lt; 33)) ||
 	    (pf-&gt;hw.aq.fw_maj_ver &lt; 4)) {
 		msleep(75);
<span class="p_header">diff --git a/drivers/net/ethernet/intel/i40e/i40e_txrx.c b/drivers/net/ethernet/intel/i40e/i40e_txrx.c</span>
<span class="p_header">index 635b3ac17877..26c55bba4bf3 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/intel/i40e/i40e_txrx.c</span>
<span class="p_header">+++ b/drivers/net/ethernet/intel/i40e/i40e_txrx.c</span>
<span class="p_chunk">@@ -235,6 +235,9 @@</span> <span class="p_context"> static int i40e_add_del_fdir_udpv4(struct i40e_vsi *vsi,</span>
 				 &quot;Filter deleted for PCTYPE %d loc = %d\n&quot;,
 				 fd_data-&gt;pctype, fd_data-&gt;fd_id);
 	}
<span class="p_add">+	if (err)</span>
<span class="p_add">+		kfree(raw_packet);</span>
<span class="p_add">+</span>
 	return err ? -EOPNOTSUPP : 0;
 }
 
<span class="p_chunk">@@ -312,6 +315,9 @@</span> <span class="p_context"> static int i40e_add_del_fdir_tcpv4(struct i40e_vsi *vsi,</span>
 				 fd_data-&gt;pctype, fd_data-&gt;fd_id);
 	}
 
<span class="p_add">+	if (err)</span>
<span class="p_add">+		kfree(raw_packet);</span>
<span class="p_add">+</span>
 	return err ? -EOPNOTSUPP : 0;
 }
 
<span class="p_chunk">@@ -387,6 +393,9 @@</span> <span class="p_context"> static int i40e_add_del_fdir_ipv4(struct i40e_vsi *vsi,</span>
 		}
 	}
 
<span class="p_add">+	if (err)</span>
<span class="p_add">+		kfree(raw_packet);</span>
<span class="p_add">+</span>
 	return err ? -EOPNOTSUPP : 0;
 }
 
<span class="p_chunk">@@ -526,11 +535,7 @@</span> <span class="p_context"> static void i40e_unmap_and_free_tx_resource(struct i40e_ring *ring,</span>
 					    struct i40e_tx_buffer *tx_buffer)
 {
 	if (tx_buffer-&gt;skb) {
<span class="p_del">-		if (tx_buffer-&gt;tx_flags &amp; I40E_TX_FLAGS_FD_SB)</span>
<span class="p_del">-			kfree(tx_buffer-&gt;raw_buf);</span>
<span class="p_del">-		else</span>
<span class="p_del">-			dev_kfree_skb_any(tx_buffer-&gt;skb);</span>
<span class="p_del">-</span>
<span class="p_add">+		dev_kfree_skb_any(tx_buffer-&gt;skb);</span>
 		if (dma_unmap_len(tx_buffer, len))
 			dma_unmap_single(ring-&gt;dev,
 					 dma_unmap_addr(tx_buffer, dma),
<span class="p_chunk">@@ -542,6 +547,10 @@</span> <span class="p_context"> static void i40e_unmap_and_free_tx_resource(struct i40e_ring *ring,</span>
 			       dma_unmap_len(tx_buffer, len),
 			       DMA_TO_DEVICE);
 	}
<span class="p_add">+</span>
<span class="p_add">+	if (tx_buffer-&gt;tx_flags &amp; I40E_TX_FLAGS_FD_SB)</span>
<span class="p_add">+		kfree(tx_buffer-&gt;raw_buf);</span>
<span class="p_add">+</span>
 	tx_buffer-&gt;next_to_watch = NULL;
 	tx_buffer-&gt;skb = NULL;
 	dma_unmap_len_set(tx_buffer, len, 0);
<span class="p_chunk">@@ -1416,31 +1425,12 @@</span> <span class="p_context"> checksum_fail:</span>
 }
 
 /**
<span class="p_del">- * i40e_rx_hash - returns the hash value from the Rx descriptor</span>
<span class="p_del">- * @ring: descriptor ring</span>
<span class="p_del">- * @rx_desc: specific descriptor</span>
<span class="p_del">- **/</span>
<span class="p_del">-static inline u32 i40e_rx_hash(struct i40e_ring *ring,</span>
<span class="p_del">-			       union i40e_rx_desc *rx_desc)</span>
<span class="p_del">-{</span>
<span class="p_del">-	const __le64 rss_mask =</span>
<span class="p_del">-		cpu_to_le64((u64)I40E_RX_DESC_FLTSTAT_RSS_HASH &lt;&lt;</span>
<span class="p_del">-			    I40E_RX_DESC_STATUS_FLTSTAT_SHIFT);</span>
<span class="p_del">-</span>
<span class="p_del">-	if ((ring-&gt;netdev-&gt;features &amp; NETIF_F_RXHASH) &amp;&amp;</span>
<span class="p_del">-	    (rx_desc-&gt;wb.qword1.status_error_len &amp; rss_mask) == rss_mask)</span>
<span class="p_del">-		return le32_to_cpu(rx_desc-&gt;wb.qword0.hi_dword.rss);</span>
<span class="p_del">-	else</span>
<span class="p_del">-		return 0;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-/**</span>
<span class="p_del">- * i40e_ptype_to_hash - get a hash type</span>
<span class="p_add">+ * i40e_ptype_to_htype - get a hash type</span>
  * @ptype: the ptype value from the descriptor
  *
  * Returns a hash type to be used by skb_set_hash
  **/
<span class="p_del">-static inline enum pkt_hash_types i40e_ptype_to_hash(u8 ptype)</span>
<span class="p_add">+static inline enum pkt_hash_types i40e_ptype_to_htype(u8 ptype)</span>
 {
 	struct i40e_rx_ptype_decoded decoded = decode_rx_desc_ptype(ptype);
 
<span class="p_chunk">@@ -1458,6 +1448,30 @@</span> <span class="p_context"> static inline enum pkt_hash_types i40e_ptype_to_hash(u8 ptype)</span>
 }
 
 /**
<span class="p_add">+ * i40e_rx_hash - set the hash value in the skb</span>
<span class="p_add">+ * @ring: descriptor ring</span>
<span class="p_add">+ * @rx_desc: specific descriptor</span>
<span class="p_add">+ **/</span>
<span class="p_add">+static inline void i40e_rx_hash(struct i40e_ring *ring,</span>
<span class="p_add">+				union i40e_rx_desc *rx_desc,</span>
<span class="p_add">+				struct sk_buff *skb,</span>
<span class="p_add">+				u8 rx_ptype)</span>
<span class="p_add">+{</span>
<span class="p_add">+	u32 hash;</span>
<span class="p_add">+	const __le64 rss_mask  =</span>
<span class="p_add">+		cpu_to_le64((u64)I40E_RX_DESC_FLTSTAT_RSS_HASH &lt;&lt;</span>
<span class="p_add">+			    I40E_RX_DESC_STATUS_FLTSTAT_SHIFT);</span>
<span class="p_add">+</span>
<span class="p_add">+	if (ring-&gt;netdev-&gt;features &amp; NETIF_F_RXHASH)</span>
<span class="p_add">+		return;</span>
<span class="p_add">+</span>
<span class="p_add">+	if ((rx_desc-&gt;wb.qword1.status_error_len &amp; rss_mask) == rss_mask) {</span>
<span class="p_add">+		hash = le32_to_cpu(rx_desc-&gt;wb.qword0.hi_dword.rss);</span>
<span class="p_add">+		skb_set_hash(skb, hash, i40e_ptype_to_htype(rx_ptype));</span>
<span class="p_add">+	}</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+/**</span>
  * i40e_clean_rx_irq_ps - Reclaim resources after receive; packet split
  * @rx_ring:  rx ring to clean
  * @budget:   how many cleans we&#39;re allowed
<span class="p_chunk">@@ -1606,8 +1620,8 @@</span> <span class="p_context"> static int i40e_clean_rx_irq_ps(struct i40e_ring *rx_ring, int budget)</span>
 			continue;
 		}
 
<span class="p_del">-		skb_set_hash(skb, i40e_rx_hash(rx_ring, rx_desc),</span>
<span class="p_del">-			     i40e_ptype_to_hash(rx_ptype));</span>
<span class="p_add">+		i40e_rx_hash(rx_ring, rx_desc, skb, rx_ptype);</span>
<span class="p_add">+</span>
 		if (unlikely(rx_status &amp; I40E_RXD_QW1_STATUS_TSYNVALID_MASK)) {
 			i40e_ptp_rx_hwtstamp(vsi-&gt;back, skb, (rx_status &amp;
 					   I40E_RXD_QW1_STATUS_TSYNINDX_MASK) &gt;&gt;
<span class="p_chunk">@@ -1736,8 +1750,7 @@</span> <span class="p_context"> static int i40e_clean_rx_irq_1buf(struct i40e_ring *rx_ring, int budget)</span>
 			continue;
 		}
 
<span class="p_del">-		skb_set_hash(skb, i40e_rx_hash(rx_ring, rx_desc),</span>
<span class="p_del">-			     i40e_ptype_to_hash(rx_ptype));</span>
<span class="p_add">+		i40e_rx_hash(rx_ring, rx_desc, skb, rx_ptype);</span>
 		if (unlikely(rx_status &amp; I40E_RXD_QW1_STATUS_TSYNVALID_MASK)) {
 			i40e_ptp_rx_hwtstamp(vsi-&gt;back, skb, (rx_status &amp;
 					   I40E_RXD_QW1_STATUS_TSYNINDX_MASK) &gt;&gt;
<span class="p_header">diff --git a/drivers/net/ethernet/intel/i40e/i40e_virtchnl_pf.c b/drivers/net/ethernet/intel/i40e/i40e_virtchnl_pf.c</span>
<span class="p_header">index 44462b40f2d7..e116d9a99b8e 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/intel/i40e/i40e_virtchnl_pf.c</span>
<span class="p_header">+++ b/drivers/net/ethernet/intel/i40e/i40e_virtchnl_pf.c</span>
<span class="p_chunk">@@ -549,12 +549,15 @@</span> <span class="p_context"> static int i40e_alloc_vsi_res(struct i40e_vf *vf, enum i40e_vsi_type type)</span>
 			i40e_vsi_add_pvid(vsi, vf-&gt;port_vlan_id);
 
 		spin_lock_bh(&amp;vsi-&gt;mac_filter_list_lock);
<span class="p_del">-		f = i40e_add_filter(vsi, vf-&gt;default_lan_addr.addr,</span>
<span class="p_del">-				    vf-&gt;port_vlan_id ? vf-&gt;port_vlan_id : -1,</span>
<span class="p_del">-				    true, false);</span>
<span class="p_del">-		if (!f)</span>
<span class="p_del">-			dev_info(&amp;pf-&gt;pdev-&gt;dev,</span>
<span class="p_del">-				 &quot;Could not allocate VF MAC addr\n&quot;);</span>
<span class="p_add">+		if (is_valid_ether_addr(vf-&gt;default_lan_addr.addr)) {</span>
<span class="p_add">+			f = i40e_add_filter(vsi, vf-&gt;default_lan_addr.addr,</span>
<span class="p_add">+				       vf-&gt;port_vlan_id ? vf-&gt;port_vlan_id : -1,</span>
<span class="p_add">+				       true, false);</span>
<span class="p_add">+			if (!f)</span>
<span class="p_add">+				dev_info(&amp;pf-&gt;pdev-&gt;dev,</span>
<span class="p_add">+					 &quot;Could not add MAC filter %pM for VF %d\n&quot;,</span>
<span class="p_add">+					vf-&gt;default_lan_addr.addr, vf-&gt;vf_id);</span>
<span class="p_add">+		}</span>
 		f = i40e_add_filter(vsi, brdcast,
 				    vf-&gt;port_vlan_id ? vf-&gt;port_vlan_id : -1,
 				    true, false);
<span class="p_chunk">@@ -1680,8 +1683,12 @@</span> <span class="p_context"> static int i40e_vc_del_mac_addr_msg(struct i40e_vf *vf, u8 *msg, u16 msglen)</span>
 	spin_lock_bh(&amp;vsi-&gt;mac_filter_list_lock);
 	/* delete addresses from the list */
 	for (i = 0; i &lt; al-&gt;num_elements; i++)
<span class="p_del">-		i40e_del_filter(vsi, al-&gt;list[i].addr,</span>
<span class="p_del">-				I40E_VLAN_ANY, true, false);</span>
<span class="p_add">+		if (i40e_del_mac_all_vlan(vsi, al-&gt;list[i].addr, true, false)) {</span>
<span class="p_add">+			ret = I40E_ERR_INVALID_MAC_ADDR;</span>
<span class="p_add">+			spin_unlock_bh(&amp;vsi-&gt;mac_filter_list_lock);</span>
<span class="p_add">+			goto error_param;</span>
<span class="p_add">+		}</span>
<span class="p_add">+</span>
 	spin_unlock_bh(&amp;vsi-&gt;mac_filter_list_lock);
 
 	/* program the updated filter list */
<span class="p_header">diff --git a/drivers/net/ethernet/intel/i40evf/i40e_txrx.c b/drivers/net/ethernet/intel/i40evf/i40e_txrx.c</span>
<span class="p_header">index 47e9a90d6b10..39db70a597ed 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/intel/i40evf/i40e_txrx.c</span>
<span class="p_header">+++ b/drivers/net/ethernet/intel/i40evf/i40e_txrx.c</span>
<span class="p_chunk">@@ -51,11 +51,7 @@</span> <span class="p_context"> static void i40e_unmap_and_free_tx_resource(struct i40e_ring *ring,</span>
 					    struct i40e_tx_buffer *tx_buffer)
 {
 	if (tx_buffer-&gt;skb) {
<span class="p_del">-		if (tx_buffer-&gt;tx_flags &amp; I40E_TX_FLAGS_FD_SB)</span>
<span class="p_del">-			kfree(tx_buffer-&gt;raw_buf);</span>
<span class="p_del">-		else</span>
<span class="p_del">-			dev_kfree_skb_any(tx_buffer-&gt;skb);</span>
<span class="p_del">-</span>
<span class="p_add">+		dev_kfree_skb_any(tx_buffer-&gt;skb);</span>
 		if (dma_unmap_len(tx_buffer, len))
 			dma_unmap_single(ring-&gt;dev,
 					 dma_unmap_addr(tx_buffer, dma),
<span class="p_chunk">@@ -67,6 +63,10 @@</span> <span class="p_context"> static void i40e_unmap_and_free_tx_resource(struct i40e_ring *ring,</span>
 			       dma_unmap_len(tx_buffer, len),
 			       DMA_TO_DEVICE);
 	}
<span class="p_add">+</span>
<span class="p_add">+	if (tx_buffer-&gt;tx_flags &amp; I40E_TX_FLAGS_FD_SB)</span>
<span class="p_add">+		kfree(tx_buffer-&gt;raw_buf);</span>
<span class="p_add">+</span>
 	tx_buffer-&gt;next_to_watch = NULL;
 	tx_buffer-&gt;skb = NULL;
 	dma_unmap_len_set(tx_buffer, len, 0);
<span class="p_chunk">@@ -245,16 +245,6 @@</span> <span class="p_context"> static bool i40e_clean_tx_irq(struct i40e_ring *tx_ring, int budget)</span>
 	tx_ring-&gt;q_vector-&gt;tx.total_bytes += total_bytes;
 	tx_ring-&gt;q_vector-&gt;tx.total_packets += total_packets;
 
<span class="p_del">-	/* check to see if there are any non-cache aligned descriptors</span>
<span class="p_del">-	 * waiting to be written back, and kick the hardware to force</span>
<span class="p_del">-	 * them to be written back in case of napi polling</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	if (budget &amp;&amp;</span>
<span class="p_del">-	    !((i &amp; WB_STRIDE) == WB_STRIDE) &amp;&amp;</span>
<span class="p_del">-	    !test_bit(__I40E_DOWN, &amp;tx_ring-&gt;vsi-&gt;state) &amp;&amp;</span>
<span class="p_del">-	    (I40E_DESC_UNUSED(tx_ring) != tx_ring-&gt;count))</span>
<span class="p_del">-		tx_ring-&gt;arm_wb = true;</span>
<span class="p_del">-</span>
 	netdev_tx_completed_queue(netdev_get_tx_queue(tx_ring-&gt;netdev,
 						      tx_ring-&gt;queue_index),
 				  total_packets, total_bytes);
<span class="p_chunk">@@ -889,31 +879,12 @@</span> <span class="p_context"> checksum_fail:</span>
 }
 
 /**
<span class="p_del">- * i40e_rx_hash - returns the hash value from the Rx descriptor</span>
<span class="p_del">- * @ring: descriptor ring</span>
<span class="p_del">- * @rx_desc: specific descriptor</span>
<span class="p_del">- **/</span>
<span class="p_del">-static inline u32 i40e_rx_hash(struct i40e_ring *ring,</span>
<span class="p_del">-			       union i40e_rx_desc *rx_desc)</span>
<span class="p_del">-{</span>
<span class="p_del">-	const __le64 rss_mask =</span>
<span class="p_del">-		cpu_to_le64((u64)I40E_RX_DESC_FLTSTAT_RSS_HASH &lt;&lt;</span>
<span class="p_del">-			    I40E_RX_DESC_STATUS_FLTSTAT_SHIFT);</span>
<span class="p_del">-</span>
<span class="p_del">-	if ((ring-&gt;netdev-&gt;features &amp; NETIF_F_RXHASH) &amp;&amp;</span>
<span class="p_del">-	    (rx_desc-&gt;wb.qword1.status_error_len &amp; rss_mask) == rss_mask)</span>
<span class="p_del">-		return le32_to_cpu(rx_desc-&gt;wb.qword0.hi_dword.rss);</span>
<span class="p_del">-	else</span>
<span class="p_del">-		return 0;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-/**</span>
<span class="p_del">- * i40e_ptype_to_hash - get a hash type</span>
<span class="p_add">+ * i40e_ptype_to_htype - get a hash type</span>
  * @ptype: the ptype value from the descriptor
  *
  * Returns a hash type to be used by skb_set_hash
  **/
<span class="p_del">-static inline enum pkt_hash_types i40e_ptype_to_hash(u8 ptype)</span>
<span class="p_add">+static inline enum pkt_hash_types i40e_ptype_to_htype(u8 ptype)</span>
 {
 	struct i40e_rx_ptype_decoded decoded = decode_rx_desc_ptype(ptype);
 
<span class="p_chunk">@@ -931,6 +902,30 @@</span> <span class="p_context"> static inline enum pkt_hash_types i40e_ptype_to_hash(u8 ptype)</span>
 }
 
 /**
<span class="p_add">+ * i40e_rx_hash - set the hash value in the skb</span>
<span class="p_add">+ * @ring: descriptor ring</span>
<span class="p_add">+ * @rx_desc: specific descriptor</span>
<span class="p_add">+ **/</span>
<span class="p_add">+static inline void i40e_rx_hash(struct i40e_ring *ring,</span>
<span class="p_add">+				union i40e_rx_desc *rx_desc,</span>
<span class="p_add">+				struct sk_buff *skb,</span>
<span class="p_add">+				u8 rx_ptype)</span>
<span class="p_add">+{</span>
<span class="p_add">+	u32 hash;</span>
<span class="p_add">+	const __le64 rss_mask  =</span>
<span class="p_add">+		cpu_to_le64((u64)I40E_RX_DESC_FLTSTAT_RSS_HASH &lt;&lt;</span>
<span class="p_add">+			    I40E_RX_DESC_STATUS_FLTSTAT_SHIFT);</span>
<span class="p_add">+</span>
<span class="p_add">+	if (ring-&gt;netdev-&gt;features &amp; NETIF_F_RXHASH)</span>
<span class="p_add">+		return;</span>
<span class="p_add">+</span>
<span class="p_add">+	if ((rx_desc-&gt;wb.qword1.status_error_len &amp; rss_mask) == rss_mask) {</span>
<span class="p_add">+		hash = le32_to_cpu(rx_desc-&gt;wb.qword0.hi_dword.rss);</span>
<span class="p_add">+		skb_set_hash(skb, hash, i40e_ptype_to_htype(rx_ptype));</span>
<span class="p_add">+	}</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+/**</span>
  * i40e_clean_rx_irq_ps - Reclaim resources after receive; packet split
  * @rx_ring:  rx ring to clean
  * @budget:   how many cleans we&#39;re allowed
<span class="p_chunk">@@ -1071,8 +1066,8 @@</span> <span class="p_context"> static int i40e_clean_rx_irq_ps(struct i40e_ring *rx_ring, int budget)</span>
 			continue;
 		}
 
<span class="p_del">-		skb_set_hash(skb, i40e_rx_hash(rx_ring, rx_desc),</span>
<span class="p_del">-			     i40e_ptype_to_hash(rx_ptype));</span>
<span class="p_add">+		i40e_rx_hash(rx_ring, rx_desc, skb, rx_ptype);</span>
<span class="p_add">+</span>
 		/* probably a little skewed due to removing CRC */
 		total_rx_bytes += skb-&gt;len;
 		total_rx_packets++;
<span class="p_chunk">@@ -1189,8 +1184,7 @@</span> <span class="p_context"> static int i40e_clean_rx_irq_1buf(struct i40e_ring *rx_ring, int budget)</span>
 			continue;
 		}
 
<span class="p_del">-		skb_set_hash(skb, i40e_rx_hash(rx_ring, rx_desc),</span>
<span class="p_del">-			     i40e_ptype_to_hash(rx_ptype));</span>
<span class="p_add">+		i40e_rx_hash(rx_ring, rx_desc, skb, rx_ptype);</span>
 		/* probably a little skewed due to removing CRC */
 		total_rx_bytes += skb-&gt;len;
 		total_rx_packets++;
<span class="p_chunk">@@ -1770,6 +1764,9 @@</span> <span class="p_context"> static inline void i40evf_tx_map(struct i40e_ring *tx_ring, struct sk_buff *skb,</span>
 	u32 td_tag = 0;
 	dma_addr_t dma;
 	u16 gso_segs;
<span class="p_add">+	u16 desc_count = 0;</span>
<span class="p_add">+	bool tail_bump = true;</span>
<span class="p_add">+	bool do_rs = false;</span>
 
 	if (tx_flags &amp; I40E_TX_FLAGS_HW_VLAN) {
 		td_cmd |= I40E_TX_DESC_CMD_IL2TAG1;
<span class="p_chunk">@@ -1810,6 +1807,8 @@</span> <span class="p_context"> static inline void i40evf_tx_map(struct i40e_ring *tx_ring, struct sk_buff *skb,</span>
 
 			tx_desc++;
 			i++;
<span class="p_add">+			desc_count++;</span>
<span class="p_add">+</span>
 			if (i == tx_ring-&gt;count) {
 				tx_desc = I40E_TX_DESC(tx_ring, 0);
 				i = 0;
<span class="p_chunk">@@ -1829,6 +1828,8 @@</span> <span class="p_context"> static inline void i40evf_tx_map(struct i40e_ring *tx_ring, struct sk_buff *skb,</span>
 
 		tx_desc++;
 		i++;
<span class="p_add">+		desc_count++;</span>
<span class="p_add">+</span>
 		if (i == tx_ring-&gt;count) {
 			tx_desc = I40E_TX_DESC(tx_ring, 0);
 			i = 0;
<span class="p_chunk">@@ -1843,35 +1844,7 @@</span> <span class="p_context"> static inline void i40evf_tx_map(struct i40e_ring *tx_ring, struct sk_buff *skb,</span>
 		tx_bi = &amp;tx_ring-&gt;tx_bi[i];
 	}
 
<span class="p_del">-	/* Place RS bit on last descriptor of any packet that spans across the</span>
<span class="p_del">-	 * 4th descriptor (WB_STRIDE aka 0x3) in a 64B cacheline.</span>
<span class="p_del">-	 */</span>
 #define WB_STRIDE 0x3
<span class="p_del">-	if (((i &amp; WB_STRIDE) != WB_STRIDE) &amp;&amp;</span>
<span class="p_del">-	    (first &lt;= &amp;tx_ring-&gt;tx_bi[i]) &amp;&amp;</span>
<span class="p_del">-	    (first &gt;= &amp;tx_ring-&gt;tx_bi[i &amp; ~WB_STRIDE])) {</span>
<span class="p_del">-		tx_desc-&gt;cmd_type_offset_bsz =</span>
<span class="p_del">-			build_ctob(td_cmd, td_offset, size, td_tag) |</span>
<span class="p_del">-			cpu_to_le64((u64)I40E_TX_DESC_CMD_EOP &lt;&lt;</span>
<span class="p_del">-					 I40E_TXD_QW1_CMD_SHIFT);</span>
<span class="p_del">-	} else {</span>
<span class="p_del">-		tx_desc-&gt;cmd_type_offset_bsz =</span>
<span class="p_del">-			build_ctob(td_cmd, td_offset, size, td_tag) |</span>
<span class="p_del">-			cpu_to_le64((u64)I40E_TXD_CMD &lt;&lt;</span>
<span class="p_del">-					 I40E_TXD_QW1_CMD_SHIFT);</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">-	netdev_tx_sent_queue(netdev_get_tx_queue(tx_ring-&gt;netdev,</span>
<span class="p_del">-						 tx_ring-&gt;queue_index),</span>
<span class="p_del">-			     first-&gt;bytecount);</span>
<span class="p_del">-</span>
<span class="p_del">-	/* Force memory writes to complete before letting h/w</span>
<span class="p_del">-	 * know there are new descriptors to fetch.  (Only</span>
<span class="p_del">-	 * applicable for weak-ordered memory model archs,</span>
<span class="p_del">-	 * such as IA-64).</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	wmb();</span>
<span class="p_del">-</span>
 	/* set next_to_watch value indicating a packet is present */
 	first-&gt;next_to_watch = tx_desc;
 
<span class="p_chunk">@@ -1881,15 +1854,78 @@</span> <span class="p_context"> static inline void i40evf_tx_map(struct i40e_ring *tx_ring, struct sk_buff *skb,</span>
 
 	tx_ring-&gt;next_to_use = i;
 
<span class="p_add">+	netdev_tx_sent_queue(netdev_get_tx_queue(tx_ring-&gt;netdev,</span>
<span class="p_add">+						 tx_ring-&gt;queue_index),</span>
<span class="p_add">+						 first-&gt;bytecount);</span>
 	i40evf_maybe_stop_tx(tx_ring, DESC_NEEDED);
<span class="p_add">+</span>
<span class="p_add">+	/* Algorithm to optimize tail and RS bit setting:</span>
<span class="p_add">+	 * if xmit_more is supported</span>
<span class="p_add">+	 *	if xmit_more is true</span>
<span class="p_add">+	 *		do not update tail and do not mark RS bit.</span>
<span class="p_add">+	 *	if xmit_more is false and last xmit_more was false</span>
<span class="p_add">+	 *		if every packet spanned less than 4 desc</span>
<span class="p_add">+	 *			then set RS bit on 4th packet and update tail</span>
<span class="p_add">+	 *			on every packet</span>
<span class="p_add">+	 *		else</span>
<span class="p_add">+	 *			update tail and set RS bit on every packet.</span>
<span class="p_add">+	 *	if xmit_more is false and last_xmit_more was true</span>
<span class="p_add">+	 *		update tail and set RS bit.</span>
<span class="p_add">+	 * else (kernel &lt; 3.18)</span>
<span class="p_add">+	 *	if every packet spanned less than 4 desc</span>
<span class="p_add">+	 *		then set RS bit on 4th packet and update tail</span>
<span class="p_add">+	 *		on every packet</span>
<span class="p_add">+	 *	else</span>
<span class="p_add">+	 *		set RS bit on EOP for every packet and update tail</span>
<span class="p_add">+	 *</span>
<span class="p_add">+	 * Optimization: wmb to be issued only in case of tail update.</span>
<span class="p_add">+	 * Also optimize the Descriptor WB path for RS bit with the same</span>
<span class="p_add">+	 * algorithm.</span>
<span class="p_add">+	 *</span>
<span class="p_add">+	 * Note: If there are less than 4 packets</span>
<span class="p_add">+	 * pending and interrupts were disabled the service task will</span>
<span class="p_add">+	 * trigger a force WB.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	if (skb-&gt;xmit_more  &amp;&amp;</span>
<span class="p_add">+	    !netif_xmit_stopped(netdev_get_tx_queue(tx_ring-&gt;netdev,</span>
<span class="p_add">+						    tx_ring-&gt;queue_index))) {</span>
<span class="p_add">+		tx_ring-&gt;flags |= I40E_TXR_FLAGS_LAST_XMIT_MORE_SET;</span>
<span class="p_add">+		tail_bump = false;</span>
<span class="p_add">+	} else if (!skb-&gt;xmit_more &amp;&amp;</span>
<span class="p_add">+		   !netif_xmit_stopped(netdev_get_tx_queue(tx_ring-&gt;netdev,</span>
<span class="p_add">+						       tx_ring-&gt;queue_index)) &amp;&amp;</span>
<span class="p_add">+		   (!(tx_ring-&gt;flags &amp; I40E_TXR_FLAGS_LAST_XMIT_MORE_SET)) &amp;&amp;</span>
<span class="p_add">+		   (tx_ring-&gt;packet_stride &lt; WB_STRIDE) &amp;&amp;</span>
<span class="p_add">+		   (desc_count &lt; WB_STRIDE)) {</span>
<span class="p_add">+		tx_ring-&gt;packet_stride++;</span>
<span class="p_add">+	} else {</span>
<span class="p_add">+		tx_ring-&gt;packet_stride = 0;</span>
<span class="p_add">+		tx_ring-&gt;flags &amp;= ~I40E_TXR_FLAGS_LAST_XMIT_MORE_SET;</span>
<span class="p_add">+		do_rs = true;</span>
<span class="p_add">+	}</span>
<span class="p_add">+	if (do_rs)</span>
<span class="p_add">+		tx_ring-&gt;packet_stride = 0;</span>
<span class="p_add">+</span>
<span class="p_add">+	tx_desc-&gt;cmd_type_offset_bsz =</span>
<span class="p_add">+			build_ctob(td_cmd, td_offset, size, td_tag) |</span>
<span class="p_add">+			cpu_to_le64((u64)(do_rs ? I40E_TXD_CMD :</span>
<span class="p_add">+						  I40E_TX_DESC_CMD_EOP) &lt;&lt;</span>
<span class="p_add">+						  I40E_TXD_QW1_CMD_SHIFT);</span>
<span class="p_add">+</span>
 	/* notify HW of packet */
<span class="p_del">-	if (!skb-&gt;xmit_more ||</span>
<span class="p_del">-	    netif_xmit_stopped(netdev_get_tx_queue(tx_ring-&gt;netdev,</span>
<span class="p_del">-						   tx_ring-&gt;queue_index)))</span>
<span class="p_del">-		writel(i, tx_ring-&gt;tail);</span>
<span class="p_del">-	else</span>
<span class="p_add">+	if (!tail_bump)</span>
 		prefetchw(tx_desc + 1);
 
<span class="p_add">+	if (tail_bump) {</span>
<span class="p_add">+		/* Force memory writes to complete before letting h/w</span>
<span class="p_add">+		 * know there are new descriptors to fetch.  (Only</span>
<span class="p_add">+		 * applicable for weak-ordered memory model archs,</span>
<span class="p_add">+		 * such as IA-64).</span>
<span class="p_add">+		 */</span>
<span class="p_add">+		wmb();</span>
<span class="p_add">+		writel(i, tx_ring-&gt;tail);</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
 	return;
 
 dma_error:
<span class="p_header">diff --git a/drivers/net/ethernet/intel/i40evf/i40e_txrx.h b/drivers/net/ethernet/intel/i40evf/i40e_txrx.h</span>
<span class="p_header">index ebc1bf77f036..998976844e4e 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/intel/i40evf/i40e_txrx.h</span>
<span class="p_header">+++ b/drivers/net/ethernet/intel/i40evf/i40e_txrx.h</span>
<span class="p_chunk">@@ -267,6 +267,8 @@</span> <span class="p_context"> struct i40e_ring {</span>
 
 	bool ring_active;		/* is ring online or not */
 	bool arm_wb;		/* do something to arm write back */
<span class="p_add">+	u8 packet_stride;</span>
<span class="p_add">+#define I40E_TXR_FLAGS_LAST_XMIT_MORE_SET BIT(2)</span>
 
 	u16 flags;
 #define I40E_TXR_FLAGS_WB_ON_ITR	BIT(0)
<span class="p_header">diff --git a/drivers/net/ethernet/intel/i40evf/i40evf_ethtool.c b/drivers/net/ethernet/intel/i40evf/i40evf_ethtool.c</span>
<span class="p_header">index 4790437a50ac..2ac62efc36f7 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/intel/i40evf/i40evf_ethtool.c</span>
<span class="p_header">+++ b/drivers/net/ethernet/intel/i40evf/i40evf_ethtool.c</span>
<span class="p_chunk">@@ -477,54 +477,30 @@</span> <span class="p_context"> static int i40evf_set_rss_hash_opt(struct i40evf_adapter *adapter,</span>
 
 	switch (nfc-&gt;flow_type) {
 	case TCP_V4_FLOW:
<span class="p_del">-		switch (nfc-&gt;data &amp; (RXH_L4_B_0_1 | RXH_L4_B_2_3)) {</span>
<span class="p_del">-		case 0:</span>
<span class="p_del">-			hena &amp;= ~BIT_ULL(I40E_FILTER_PCTYPE_NONF_IPV4_TCP);</span>
<span class="p_del">-			break;</span>
<span class="p_del">-		case (RXH_L4_B_0_1 | RXH_L4_B_2_3):</span>
<span class="p_add">+		if (nfc-&gt;data &amp; (RXH_L4_B_0_1 | RXH_L4_B_2_3))</span>
 			hena |= BIT_ULL(I40E_FILTER_PCTYPE_NONF_IPV4_TCP);
<span class="p_del">-			break;</span>
<span class="p_del">-		default:</span>
<span class="p_add">+		else</span>
 			return -EINVAL;
<span class="p_del">-		}</span>
 		break;
 	case TCP_V6_FLOW:
<span class="p_del">-		switch (nfc-&gt;data &amp; (RXH_L4_B_0_1 | RXH_L4_B_2_3)) {</span>
<span class="p_del">-		case 0:</span>
<span class="p_del">-			hena &amp;= ~BIT_ULL(I40E_FILTER_PCTYPE_NONF_IPV6_TCP);</span>
<span class="p_del">-			break;</span>
<span class="p_del">-		case (RXH_L4_B_0_1 | RXH_L4_B_2_3):</span>
<span class="p_add">+		if (nfc-&gt;data &amp; (RXH_L4_B_0_1 | RXH_L4_B_2_3))</span>
 			hena |= BIT_ULL(I40E_FILTER_PCTYPE_NONF_IPV6_TCP);
<span class="p_del">-			break;</span>
<span class="p_del">-		default:</span>
<span class="p_add">+		else</span>
 			return -EINVAL;
<span class="p_del">-		}</span>
 		break;
 	case UDP_V4_FLOW:
<span class="p_del">-		switch (nfc-&gt;data &amp; (RXH_L4_B_0_1 | RXH_L4_B_2_3)) {</span>
<span class="p_del">-		case 0:</span>
<span class="p_del">-			hena &amp;= ~(BIT_ULL(I40E_FILTER_PCTYPE_NONF_IPV4_UDP) |</span>
<span class="p_del">-				  BIT_ULL(I40E_FILTER_PCTYPE_FRAG_IPV4));</span>
<span class="p_del">-			break;</span>
<span class="p_del">-		case (RXH_L4_B_0_1 | RXH_L4_B_2_3):</span>
<span class="p_add">+		if (nfc-&gt;data &amp; (RXH_L4_B_0_1 | RXH_L4_B_2_3)) {</span>
 			hena |= (BIT_ULL(I40E_FILTER_PCTYPE_NONF_IPV4_UDP) |
 				 BIT_ULL(I40E_FILTER_PCTYPE_FRAG_IPV4));
<span class="p_del">-			break;</span>
<span class="p_del">-		default:</span>
<span class="p_add">+		} else {</span>
 			return -EINVAL;
 		}
 		break;
 	case UDP_V6_FLOW:
<span class="p_del">-		switch (nfc-&gt;data &amp; (RXH_L4_B_0_1 | RXH_L4_B_2_3)) {</span>
<span class="p_del">-		case 0:</span>
<span class="p_del">-			hena &amp;= ~(BIT_ULL(I40E_FILTER_PCTYPE_NONF_IPV6_UDP) |</span>
<span class="p_del">-				  BIT_ULL(I40E_FILTER_PCTYPE_FRAG_IPV6));</span>
<span class="p_del">-			break;</span>
<span class="p_del">-		case (RXH_L4_B_0_1 | RXH_L4_B_2_3):</span>
<span class="p_add">+		if (nfc-&gt;data &amp; (RXH_L4_B_0_1 | RXH_L4_B_2_3)) {</span>
 			hena |= (BIT_ULL(I40E_FILTER_PCTYPE_NONF_IPV6_UDP) |
 				 BIT_ULL(I40E_FILTER_PCTYPE_FRAG_IPV6));
<span class="p_del">-			break;</span>
<span class="p_del">-		default:</span>
<span class="p_add">+		} else {</span>
 			return -EINVAL;
 		}
 		break;
<span class="p_header">diff --git a/drivers/net/ethernet/intel/i40evf/i40evf_main.c b/drivers/net/ethernet/intel/i40evf/i40evf_main.c</span>
<span class="p_header">index 99d2cffae0cd..5f03ab3dfa19 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/intel/i40evf/i40evf_main.c</span>
<span class="p_header">+++ b/drivers/net/ethernet/intel/i40evf/i40evf_main.c</span>
<span class="p_chunk">@@ -1864,6 +1864,9 @@</span> <span class="p_context"> void i40evf_free_all_tx_resources(struct i40evf_adapter *adapter)</span>
 {
 	int i;
 
<span class="p_add">+	if (!adapter-&gt;tx_rings)</span>
<span class="p_add">+		return;</span>
<span class="p_add">+</span>
 	for (i = 0; i &lt; adapter-&gt;num_active_queues; i++)
 		if (adapter-&gt;tx_rings[i]-&gt;desc)
 			i40evf_free_tx_resources(adapter-&gt;tx_rings[i]);
<span class="p_chunk">@@ -1932,6 +1935,9 @@</span> <span class="p_context"> void i40evf_free_all_rx_resources(struct i40evf_adapter *adapter)</span>
 {
 	int i;
 
<span class="p_add">+	if (!adapter-&gt;rx_rings)</span>
<span class="p_add">+		return;</span>
<span class="p_add">+</span>
 	for (i = 0; i &lt; adapter-&gt;num_active_queues; i++)
 		if (adapter-&gt;rx_rings[i]-&gt;desc)
 			i40evf_free_rx_resources(adapter-&gt;rx_rings[i]);
<span class="p_header">diff --git a/drivers/net/ethernet/intel/i40evf/i40evf_virtchnl.c b/drivers/net/ethernet/intel/i40evf/i40evf_virtchnl.c</span>
<span class="p_header">index 32e620e1eb5c..5de3f52fd31f 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/intel/i40evf/i40evf_virtchnl.c</span>
<span class="p_header">+++ b/drivers/net/ethernet/intel/i40evf/i40evf_virtchnl.c</span>
<span class="p_chunk">@@ -391,6 +391,7 @@</span> <span class="p_context"> void i40evf_add_ether_addrs(struct i40evf_adapter *adapter)</span>
 	struct i40e_virtchnl_ether_addr_list *veal;
 	int len, i = 0, count = 0;
 	struct i40evf_mac_filter *f;
<span class="p_add">+	bool more = false;</span>
 
 	if (adapter-&gt;current_op != I40E_VIRTCHNL_OP_UNKNOWN) {
 		/* bail because we already have a command pending */
<span class="p_chunk">@@ -415,7 +416,9 @@</span> <span class="p_context"> void i40evf_add_ether_addrs(struct i40evf_adapter *adapter)</span>
 		count = (I40EVF_MAX_AQ_BUF_SIZE -
 			 sizeof(struct i40e_virtchnl_ether_addr_list)) /
 			sizeof(struct i40e_virtchnl_ether_addr);
<span class="p_del">-		len = I40EVF_MAX_AQ_BUF_SIZE;</span>
<span class="p_add">+		len = sizeof(struct i40e_virtchnl_ether_addr_list) +</span>
<span class="p_add">+		      (count * sizeof(struct i40e_virtchnl_ether_addr));</span>
<span class="p_add">+		more = true;</span>
 	}
 
 	veal = kzalloc(len, GFP_ATOMIC);
<span class="p_chunk">@@ -431,7 +434,8 @@</span> <span class="p_context"> void i40evf_add_ether_addrs(struct i40evf_adapter *adapter)</span>
 			f-&gt;add = false;
 		}
 	}
<span class="p_del">-	adapter-&gt;aq_required &amp;= ~I40EVF_FLAG_AQ_ADD_MAC_FILTER;</span>
<span class="p_add">+	if (!more)</span>
<span class="p_add">+		adapter-&gt;aq_required &amp;= ~I40EVF_FLAG_AQ_ADD_MAC_FILTER;</span>
 	i40evf_send_pf_msg(adapter, I40E_VIRTCHNL_OP_ADD_ETHER_ADDRESS,
 			   (u8 *)veal, len);
 	kfree(veal);
<span class="p_chunk">@@ -450,6 +454,7 @@</span> <span class="p_context"> void i40evf_del_ether_addrs(struct i40evf_adapter *adapter)</span>
 	struct i40e_virtchnl_ether_addr_list *veal;
 	struct i40evf_mac_filter *f, *ftmp;
 	int len, i = 0, count = 0;
<span class="p_add">+	bool more = false;</span>
 
 	if (adapter-&gt;current_op != I40E_VIRTCHNL_OP_UNKNOWN) {
 		/* bail because we already have a command pending */
<span class="p_chunk">@@ -474,7 +479,9 @@</span> <span class="p_context"> void i40evf_del_ether_addrs(struct i40evf_adapter *adapter)</span>
 		count = (I40EVF_MAX_AQ_BUF_SIZE -
 			 sizeof(struct i40e_virtchnl_ether_addr_list)) /
 			sizeof(struct i40e_virtchnl_ether_addr);
<span class="p_del">-		len = I40EVF_MAX_AQ_BUF_SIZE;</span>
<span class="p_add">+		len = sizeof(struct i40e_virtchnl_ether_addr_list) +</span>
<span class="p_add">+		      (count * sizeof(struct i40e_virtchnl_ether_addr));</span>
<span class="p_add">+		more = true;</span>
 	}
 	veal = kzalloc(len, GFP_ATOMIC);
 	if (!veal)
<span class="p_chunk">@@ -490,7 +497,8 @@</span> <span class="p_context"> void i40evf_del_ether_addrs(struct i40evf_adapter *adapter)</span>
 			kfree(f);
 		}
 	}
<span class="p_del">-	adapter-&gt;aq_required &amp;= ~I40EVF_FLAG_AQ_DEL_MAC_FILTER;</span>
<span class="p_add">+	if (!more)</span>
<span class="p_add">+		adapter-&gt;aq_required &amp;= ~I40EVF_FLAG_AQ_DEL_MAC_FILTER;</span>
 	i40evf_send_pf_msg(adapter, I40E_VIRTCHNL_OP_DEL_ETHER_ADDRESS,
 			   (u8 *)veal, len);
 	kfree(veal);
<span class="p_chunk">@@ -509,6 +517,7 @@</span> <span class="p_context"> void i40evf_add_vlans(struct i40evf_adapter *adapter)</span>
 	struct i40e_virtchnl_vlan_filter_list *vvfl;
 	int len, i = 0, count = 0;
 	struct i40evf_vlan_filter *f;
<span class="p_add">+	bool more = false;</span>
 
 	if (adapter-&gt;current_op != I40E_VIRTCHNL_OP_UNKNOWN) {
 		/* bail because we already have a command pending */
<span class="p_chunk">@@ -534,7 +543,9 @@</span> <span class="p_context"> void i40evf_add_vlans(struct i40evf_adapter *adapter)</span>
 		count = (I40EVF_MAX_AQ_BUF_SIZE -
 			 sizeof(struct i40e_virtchnl_vlan_filter_list)) /
 			sizeof(u16);
<span class="p_del">-		len = I40EVF_MAX_AQ_BUF_SIZE;</span>
<span class="p_add">+		len = sizeof(struct i40e_virtchnl_vlan_filter_list) +</span>
<span class="p_add">+		      (count * sizeof(u16));</span>
<span class="p_add">+		more = true;</span>
 	}
 	vvfl = kzalloc(len, GFP_ATOMIC);
 	if (!vvfl)
<span class="p_chunk">@@ -549,7 +560,8 @@</span> <span class="p_context"> void i40evf_add_vlans(struct i40evf_adapter *adapter)</span>
 			f-&gt;add = false;
 		}
 	}
<span class="p_del">-	adapter-&gt;aq_required &amp;= ~I40EVF_FLAG_AQ_ADD_VLAN_FILTER;</span>
<span class="p_add">+	if (!more)</span>
<span class="p_add">+		adapter-&gt;aq_required &amp;= ~I40EVF_FLAG_AQ_ADD_VLAN_FILTER;</span>
 	i40evf_send_pf_msg(adapter, I40E_VIRTCHNL_OP_ADD_VLAN, (u8 *)vvfl, len);
 	kfree(vvfl);
 }
<span class="p_chunk">@@ -567,6 +579,7 @@</span> <span class="p_context"> void i40evf_del_vlans(struct i40evf_adapter *adapter)</span>
 	struct i40e_virtchnl_vlan_filter_list *vvfl;
 	struct i40evf_vlan_filter *f, *ftmp;
 	int len, i = 0, count = 0;
<span class="p_add">+	bool more = false;</span>
 
 	if (adapter-&gt;current_op != I40E_VIRTCHNL_OP_UNKNOWN) {
 		/* bail because we already have a command pending */
<span class="p_chunk">@@ -592,7 +605,9 @@</span> <span class="p_context"> void i40evf_del_vlans(struct i40evf_adapter *adapter)</span>
 		count = (I40EVF_MAX_AQ_BUF_SIZE -
 			 sizeof(struct i40e_virtchnl_vlan_filter_list)) /
 			sizeof(u16);
<span class="p_del">-		len = I40EVF_MAX_AQ_BUF_SIZE;</span>
<span class="p_add">+		len = sizeof(struct i40e_virtchnl_vlan_filter_list) +</span>
<span class="p_add">+		      (count * sizeof(u16));</span>
<span class="p_add">+		more = true;</span>
 	}
 	vvfl = kzalloc(len, GFP_ATOMIC);
 	if (!vvfl)
<span class="p_chunk">@@ -608,7 +623,8 @@</span> <span class="p_context"> void i40evf_del_vlans(struct i40evf_adapter *adapter)</span>
 			kfree(f);
 		}
 	}
<span class="p_del">-	adapter-&gt;aq_required &amp;= ~I40EVF_FLAG_AQ_DEL_VLAN_FILTER;</span>
<span class="p_add">+	if (!more)</span>
<span class="p_add">+		adapter-&gt;aq_required &amp;= ~I40EVF_FLAG_AQ_DEL_VLAN_FILTER;</span>
 	i40evf_send_pf_msg(adapter, I40E_VIRTCHNL_OP_DEL_VLAN, (u8 *)vvfl, len);
 	kfree(vvfl);
 }
<span class="p_header">diff --git a/drivers/net/ethernet/intel/igb/e1000_82575.c b/drivers/net/ethernet/intel/igb/e1000_82575.c</span>
<span class="p_header">index 7a73510e547c..97bf0c3d5c69 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/intel/igb/e1000_82575.c</span>
<span class="p_header">+++ b/drivers/net/ethernet/intel/igb/e1000_82575.c</span>
<span class="p_chunk">@@ -294,6 +294,7 @@</span> <span class="p_context"> static s32 igb_init_phy_params_82575(struct e1000_hw *hw)</span>
 	case I210_I_PHY_ID:
 		phy-&gt;type		= e1000_phy_i210;
 		phy-&gt;ops.check_polarity	= igb_check_polarity_m88;
<span class="p_add">+		phy-&gt;ops.get_cfg_done	= igb_get_cfg_done_i210;</span>
 		phy-&gt;ops.get_phy_info	= igb_get_phy_info_m88;
 		phy-&gt;ops.get_cable_length = igb_get_cable_length_m88_gen2;
 		phy-&gt;ops.set_d0_lplu_state = igb_set_d0_lplu_state_82580;
<span class="p_header">diff --git a/drivers/net/ethernet/intel/igb/e1000_i210.c b/drivers/net/ethernet/intel/igb/e1000_i210.c</span>
<span class="p_header">index 65d931669f81..29f59c76878a 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/intel/igb/e1000_i210.c</span>
<span class="p_header">+++ b/drivers/net/ethernet/intel/igb/e1000_i210.c</span>
<span class="p_chunk">@@ -900,3 +900,30 @@</span> <span class="p_context"> s32 igb_pll_workaround_i210(struct e1000_hw *hw)</span>
 	wr32(E1000_MDICNFG, mdicnfg);
 	return ret_val;
 }
<span class="p_add">+</span>
<span class="p_add">+/**</span>
<span class="p_add">+ *  igb_get_cfg_done_i210 - Read config done bit</span>
<span class="p_add">+ *  @hw: pointer to the HW structure</span>
<span class="p_add">+ *</span>
<span class="p_add">+ *  Read the management control register for the config done bit for</span>
<span class="p_add">+ *  completion status.  NOTE: silicon which is EEPROM-less will fail trying</span>
<span class="p_add">+ *  to read the config done bit, so an error is *ONLY* logged and returns</span>
<span class="p_add">+ *  0.  If we were to return with error, EEPROM-less silicon</span>
<span class="p_add">+ *  would not be able to be reset or change link.</span>
<span class="p_add">+ **/</span>
<span class="p_add">+s32 igb_get_cfg_done_i210(struct e1000_hw *hw)</span>
<span class="p_add">+{</span>
<span class="p_add">+	s32 timeout = PHY_CFG_TIMEOUT;</span>
<span class="p_add">+	u32 mask = E1000_NVM_CFG_DONE_PORT_0;</span>
<span class="p_add">+</span>
<span class="p_add">+	while (timeout) {</span>
<span class="p_add">+		if (rd32(E1000_EEMNGCTL_I210) &amp; mask)</span>
<span class="p_add">+			break;</span>
<span class="p_add">+		usleep_range(1000, 2000);</span>
<span class="p_add">+		timeout--;</span>
<span class="p_add">+	}</span>
<span class="p_add">+	if (!timeout)</span>
<span class="p_add">+		hw_dbg(&quot;MNG configuration cycle has not completed.\n&quot;);</span>
<span class="p_add">+</span>
<span class="p_add">+	return 0;</span>
<span class="p_add">+}</span>
<span class="p_header">diff --git a/drivers/net/ethernet/intel/igb/e1000_i210.h b/drivers/net/ethernet/intel/igb/e1000_i210.h</span>
<span class="p_header">index 3442b6357d01..eaa68a50cb3b 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/intel/igb/e1000_i210.h</span>
<span class="p_header">+++ b/drivers/net/ethernet/intel/igb/e1000_i210.h</span>
<span class="p_chunk">@@ -34,6 +34,7 @@</span> <span class="p_context"> s32 igb_write_xmdio_reg(struct e1000_hw *hw, u16 addr, u8 dev_addr, u16 data);</span>
 s32 igb_init_nvm_params_i210(struct e1000_hw *hw);
 bool igb_get_flash_presence_i210(struct e1000_hw *hw);
 s32 igb_pll_workaround_i210(struct e1000_hw *hw);
<span class="p_add">+s32 igb_get_cfg_done_i210(struct e1000_hw *hw);</span>
 
 #define E1000_STM_OPCODE		0xDB00
 #define E1000_EEPROM_FLASH_SIZE_WORD	0x11
<span class="p_header">diff --git a/drivers/net/ethernet/intel/igb/e1000_regs.h b/drivers/net/ethernet/intel/igb/e1000_regs.h</span>
<span class="p_header">index 4af2870e49f8..0fdcd4d1b982 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/intel/igb/e1000_regs.h</span>
<span class="p_header">+++ b/drivers/net/ethernet/intel/igb/e1000_regs.h</span>
<span class="p_chunk">@@ -66,6 +66,7 @@</span> <span class="p_context"></span>
 #define E1000_PBA      0x01000  /* Packet Buffer Allocation - RW */
 #define E1000_PBS      0x01008  /* Packet Buffer Size */
 #define E1000_EEMNGCTL 0x01010  /* MNG EEprom Control */
<span class="p_add">+#define E1000_EEMNGCTL_I210 0x12030  /* MNG EEprom Control */</span>
 #define E1000_EEARBC_I210 0x12024  /* EEPROM Auto Read Bus Control */
 #define E1000_EEWR     0x0102C  /* EEPROM Write Register - RW */
 #define E1000_I2CCMD   0x01028  /* SFPI2C Command Register - RW */
<span class="p_header">diff --git a/drivers/net/ethernet/intel/igb/igb.h b/drivers/net/ethernet/intel/igb/igb.h</span>
<span class="p_header">index 1a2f1cc44b28..e3cb93bdb21a 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/intel/igb/igb.h</span>
<span class="p_header">+++ b/drivers/net/ethernet/intel/igb/igb.h</span>
<span class="p_chunk">@@ -389,6 +389,8 @@</span> <span class="p_context"> struct igb_adapter {</span>
 	u16 link_speed;
 	u16 link_duplex;
 
<span class="p_add">+	u8 __iomem *io_addr; /* Mainly for iounmap use */</span>
<span class="p_add">+</span>
 	struct work_struct reset_task;
 	struct work_struct watchdog_task;
 	bool fc_autoneg;
<span class="p_header">diff --git a/drivers/net/ethernet/intel/igb/igb_main.c b/drivers/net/ethernet/intel/igb/igb_main.c</span>
<span class="p_header">index ea7b09887245..fa3b4cbea23b 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/intel/igb/igb_main.c</span>
<span class="p_header">+++ b/drivers/net/ethernet/intel/igb/igb_main.c</span>
<span class="p_chunk">@@ -2294,9 +2294,11 @@</span> <span class="p_context"> static int igb_probe(struct pci_dev *pdev, const struct pci_device_id *ent)</span>
 	adapter-&gt;msg_enable = netif_msg_init(debug, DEFAULT_MSG_ENABLE);
 
 	err = -EIO;
<span class="p_del">-	hw-&gt;hw_addr = pci_iomap(pdev, 0, 0);</span>
<span class="p_del">-	if (!hw-&gt;hw_addr)</span>
<span class="p_add">+	adapter-&gt;io_addr = pci_iomap(pdev, 0, 0);</span>
<span class="p_add">+	if (!adapter-&gt;io_addr)</span>
 		goto err_ioremap;
<span class="p_add">+	/* hw-&gt;hw_addr can be altered, we&#39;ll use adapter-&gt;io_addr for unmap */</span>
<span class="p_add">+	hw-&gt;hw_addr = adapter-&gt;io_addr;</span>
 
 	netdev-&gt;netdev_ops = &amp;igb_netdev_ops;
 	igb_set_ethtool_ops(netdev);
<span class="p_chunk">@@ -2656,7 +2658,7 @@</span> <span class="p_context"> err_sw_init:</span>
 #ifdef CONFIG_PCI_IOV
 	igb_disable_sriov(pdev);
 #endif
<span class="p_del">-	pci_iounmap(pdev, hw-&gt;hw_addr);</span>
<span class="p_add">+	pci_iounmap(pdev, adapter-&gt;io_addr);</span>
 err_ioremap:
 	free_netdev(netdev);
 err_alloc_etherdev:
<span class="p_chunk">@@ -2823,7 +2825,7 @@</span> <span class="p_context"> static void igb_remove(struct pci_dev *pdev)</span>
 
 	igb_clear_interrupt_scheme(adapter);
 
<span class="p_del">-	pci_iounmap(pdev, hw-&gt;hw_addr);</span>
<span class="p_add">+	pci_iounmap(pdev, adapter-&gt;io_addr);</span>
 	if (hw-&gt;flash_address)
 		iounmap(hw-&gt;flash_address);
 	pci_release_selected_regions(pdev,
<span class="p_chunk">@@ -2856,6 +2858,13 @@</span> <span class="p_context"> static void igb_probe_vfs(struct igb_adapter *adapter)</span>
 	if ((hw-&gt;mac.type == e1000_i210) || (hw-&gt;mac.type == e1000_i211))
 		return;
 
<span class="p_add">+	/* Of the below we really only want the effect of getting</span>
<span class="p_add">+	 * IGB_FLAG_HAS_MSIX set (if available), without which</span>
<span class="p_add">+	 * igb_enable_sriov() has no effect.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	igb_set_interrupt_capability(adapter, true);</span>
<span class="p_add">+	igb_reset_interrupt_capability(adapter);</span>
<span class="p_add">+</span>
 	pci_sriov_set_totalvfs(pdev, 7);
 	igb_enable_sriov(pdev, max_vfs);
 
<span class="p_header">diff --git a/drivers/net/ethernet/intel/ixgbe/ixgbe_main.c b/drivers/net/ethernet/intel/ixgbe/ixgbe_main.c</span>
<span class="p_header">index aed8d029b23d..cd9b284bc83b 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/intel/ixgbe/ixgbe_main.c</span>
<span class="p_header">+++ b/drivers/net/ethernet/intel/ixgbe/ixgbe_main.c</span>
<span class="p_chunk">@@ -2786,7 +2786,8 @@</span> <span class="p_context"> int ixgbe_poll(struct napi_struct *napi, int budget)</span>
 	ixgbe_for_each_ring(ring, q_vector-&gt;tx)
 		clean_complete &amp;= !!ixgbe_clean_tx_irq(q_vector, ring);
 
<span class="p_del">-	if (!ixgbe_qv_lock_napi(q_vector))</span>
<span class="p_add">+	/* Exit if we are called by netpoll or busy polling is active */</span>
<span class="p_add">+	if ((budget &lt;= 0) || !ixgbe_qv_lock_napi(q_vector))</span>
 		return budget;
 
 	/* attempt to distribute budget to each queue fairly, but don&#39;t allow
<span class="p_header">diff --git a/drivers/net/ethernet/mellanox/mlx5/core/en_ethtool.c b/drivers/net/ethernet/mellanox/mlx5/core/en_ethtool.c</span>
<span class="p_header">index 2e022e900939..7cc9df717323 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/mellanox/mlx5/core/en_ethtool.c</span>
<span class="p_header">+++ b/drivers/net/ethernet/mellanox/mlx5/core/en_ethtool.c</span>
<span class="p_chunk">@@ -399,6 +399,9 @@</span> <span class="p_context"> static int mlx5e_get_coalesce(struct net_device *netdev,</span>
 {
 	struct mlx5e_priv *priv = netdev_priv(netdev);
 
<span class="p_add">+	if (!MLX5_CAP_GEN(priv-&gt;mdev, cq_moderation))</span>
<span class="p_add">+		return -ENOTSUPP;</span>
<span class="p_add">+</span>
 	coal-&gt;rx_coalesce_usecs       = priv-&gt;params.rx_cq_moderation_usec;
 	coal-&gt;rx_max_coalesced_frames = priv-&gt;params.rx_cq_moderation_pkts;
 	coal-&gt;tx_coalesce_usecs       = priv-&gt;params.tx_cq_moderation_usec;
<span class="p_chunk">@@ -416,11 +419,18 @@</span> <span class="p_context"> static int mlx5e_set_coalesce(struct net_device *netdev,</span>
 	int tc;
 	int i;
 
<span class="p_add">+	if (!MLX5_CAP_GEN(mdev, cq_moderation))</span>
<span class="p_add">+		return -ENOTSUPP;</span>
<span class="p_add">+</span>
<span class="p_add">+	mutex_lock(&amp;priv-&gt;state_lock);</span>
 	priv-&gt;params.tx_cq_moderation_usec = coal-&gt;tx_coalesce_usecs;
 	priv-&gt;params.tx_cq_moderation_pkts = coal-&gt;tx_max_coalesced_frames;
 	priv-&gt;params.rx_cq_moderation_usec = coal-&gt;rx_coalesce_usecs;
 	priv-&gt;params.rx_cq_moderation_pkts = coal-&gt;rx_max_coalesced_frames;
 
<span class="p_add">+	if (!test_bit(MLX5E_STATE_OPENED, &amp;priv-&gt;state))</span>
<span class="p_add">+		goto out;</span>
<span class="p_add">+</span>
 	for (i = 0; i &lt; priv-&gt;params.num_channels; ++i) {
 		c = priv-&gt;channel[i];
 
<span class="p_chunk">@@ -436,6 +446,8 @@</span> <span class="p_context"> static int mlx5e_set_coalesce(struct net_device *netdev,</span>
 					       coal-&gt;rx_max_coalesced_frames);
 	}
 
<span class="p_add">+out:</span>
<span class="p_add">+	mutex_unlock(&amp;priv-&gt;state_lock);</span>
 	return 0;
 }
 
<span class="p_header">diff --git a/drivers/net/ethernet/mellanox/mlx5/core/en_main.c b/drivers/net/ethernet/mellanox/mlx5/core/en_main.c</span>
<span class="p_header">index cbd17e25beeb..90e876ecc720 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/mellanox/mlx5/core/en_main.c</span>
<span class="p_header">+++ b/drivers/net/ethernet/mellanox/mlx5/core/en_main.c</span>
<span class="p_chunk">@@ -863,12 +863,10 @@</span> <span class="p_context"> static int mlx5e_open_cq(struct mlx5e_channel *c,</span>
 	if (err)
 		goto err_destroy_cq;
 
<span class="p_del">-	err = mlx5_core_modify_cq_moderation(mdev, &amp;cq-&gt;mcq,</span>
<span class="p_del">-					     moderation_usecs,</span>
<span class="p_del">-					     moderation_frames);</span>
<span class="p_del">-	if (err)</span>
<span class="p_del">-		goto err_destroy_cq;</span>
<span class="p_del">-</span>
<span class="p_add">+	if (MLX5_CAP_GEN(mdev, cq_moderation))</span>
<span class="p_add">+		mlx5_core_modify_cq_moderation(mdev, &amp;cq-&gt;mcq,</span>
<span class="p_add">+					       moderation_usecs,</span>
<span class="p_add">+					       moderation_frames);</span>
 	return 0;
 
 err_destroy_cq:
<span class="p_chunk">@@ -1963,6 +1961,8 @@</span> <span class="p_context"> static int mlx5e_check_required_hca_cap(struct mlx5_core_dev *mdev)</span>
 	}
 	if (!MLX5_CAP_ETH(mdev, self_lb_en_modifiable))
 		mlx5_core_warn(mdev, &quot;Self loop back prevention is not supported\n&quot;);
<span class="p_add">+	if (!MLX5_CAP_GEN(mdev, cq_moderation))</span>
<span class="p_add">+		mlx5_core_warn(mdev, &quot;CQ modiration is not supported\n&quot;);</span>
 
 	return 0;
 }
<span class="p_header">diff --git a/drivers/nvme/host/pci.c b/drivers/nvme/host/pci.c</span>
<span class="p_header">index 289a5df0d44a..c851bc53831c 100644</span>
<span class="p_header">--- a/drivers/nvme/host/pci.c</span>
<span class="p_header">+++ b/drivers/nvme/host/pci.c</span>
<span class="p_chunk">@@ -2725,7 +2725,7 @@</span> <span class="p_context"> static int nvme_pci_enable(struct nvme_dev *dev)</span>
 	return 0;
 
  disable:
<span class="p_del">-	pci_release_regions(pdev);</span>
<span class="p_add">+	pci_disable_device(pdev);</span>
 
 	return result;
 }
<span class="p_header">diff --git a/drivers/pwm/pwm-fsl-ftm.c b/drivers/pwm/pwm-fsl-ftm.c</span>
<span class="p_header">index f9dfc8b6407a..7225ac6b3df5 100644</span>
<span class="p_header">--- a/drivers/pwm/pwm-fsl-ftm.c</span>
<span class="p_header">+++ b/drivers/pwm/pwm-fsl-ftm.c</span>
<span class="p_chunk">@@ -80,7 +80,6 @@</span> <span class="p_context"> struct fsl_pwm_chip {</span>
 
 	struct mutex lock;
 
<span class="p_del">-	unsigned int use_count;</span>
 	unsigned int cnt_select;
 	unsigned int clk_ps;
 
<span class="p_chunk">@@ -300,9 +299,6 @@</span> <span class="p_context"> static int fsl_counter_clock_enable(struct fsl_pwm_chip *fpc)</span>
 {
 	int ret;
 
<span class="p_del">-	if (fpc-&gt;use_count++ != 0)</span>
<span class="p_del">-		return 0;</span>
<span class="p_del">-</span>
 	/* select counter clock source */
 	regmap_update_bits(fpc-&gt;regmap, FTM_SC, FTM_SC_CLK_MASK,
 			   FTM_SC_CLK(fpc-&gt;cnt_select));
<span class="p_chunk">@@ -334,25 +330,6 @@</span> <span class="p_context"> static int fsl_pwm_enable(struct pwm_chip *chip, struct pwm_device *pwm)</span>
 	return ret;
 }
 
<span class="p_del">-static void fsl_counter_clock_disable(struct fsl_pwm_chip *fpc)</span>
<span class="p_del">-{</span>
<span class="p_del">-	/*</span>
<span class="p_del">-	 * already disabled, do nothing</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	if (fpc-&gt;use_count == 0)</span>
<span class="p_del">-		return;</span>
<span class="p_del">-</span>
<span class="p_del">-	/* there are still users, so can&#39;t disable yet */</span>
<span class="p_del">-	if (--fpc-&gt;use_count &gt; 0)</span>
<span class="p_del">-		return;</span>
<span class="p_del">-</span>
<span class="p_del">-	/* no users left, disable PWM counter clock */</span>
<span class="p_del">-	regmap_update_bits(fpc-&gt;regmap, FTM_SC, FTM_SC_CLK_MASK, 0);</span>
<span class="p_del">-</span>
<span class="p_del">-	clk_disable_unprepare(fpc-&gt;clk[FSL_PWM_CLK_CNTEN]);</span>
<span class="p_del">-	clk_disable_unprepare(fpc-&gt;clk[fpc-&gt;cnt_select]);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
 static void fsl_pwm_disable(struct pwm_chip *chip, struct pwm_device *pwm)
 {
 	struct fsl_pwm_chip *fpc = to_fsl_chip(chip);
<span class="p_chunk">@@ -362,7 +339,8 @@</span> <span class="p_context"> static void fsl_pwm_disable(struct pwm_chip *chip, struct pwm_device *pwm)</span>
 	regmap_update_bits(fpc-&gt;regmap, FTM_OUTMASK, BIT(pwm-&gt;hwpwm),
 			   BIT(pwm-&gt;hwpwm));
 
<span class="p_del">-	fsl_counter_clock_disable(fpc);</span>
<span class="p_add">+	clk_disable_unprepare(fpc-&gt;clk[FSL_PWM_CLK_CNTEN]);</span>
<span class="p_add">+	clk_disable_unprepare(fpc-&gt;clk[fpc-&gt;cnt_select]);</span>
 
 	regmap_read(fpc-&gt;regmap, FTM_OUTMASK, &amp;val);
 	if ((val &amp; 0xFF) == 0xFF)
<span class="p_chunk">@@ -492,17 +470,24 @@</span> <span class="p_context"> static int fsl_pwm_remove(struct platform_device *pdev)</span>
 static int fsl_pwm_suspend(struct device *dev)
 {
 	struct fsl_pwm_chip *fpc = dev_get_drvdata(dev);
<span class="p_del">-	u32 val;</span>
<span class="p_add">+	int i;</span>
 
 	regcache_cache_only(fpc-&gt;regmap, true);
 	regcache_mark_dirty(fpc-&gt;regmap);
 
<span class="p_del">-	/* read from cache */</span>
<span class="p_del">-	regmap_read(fpc-&gt;regmap, FTM_OUTMASK, &amp;val);</span>
<span class="p_del">-	if ((val &amp; 0xFF) != 0xFF) {</span>
<span class="p_add">+	for (i = 0; i &lt; fpc-&gt;chip.npwm; i++) {</span>
<span class="p_add">+		struct pwm_device *pwm = &amp;fpc-&gt;chip.pwms[i];</span>
<span class="p_add">+</span>
<span class="p_add">+		if (!test_bit(PWMF_REQUESTED, &amp;pwm-&gt;flags))</span>
<span class="p_add">+			continue;</span>
<span class="p_add">+</span>
<span class="p_add">+		clk_disable_unprepare(fpc-&gt;clk[FSL_PWM_CLK_SYS]);</span>
<span class="p_add">+</span>
<span class="p_add">+		if (!pwm_is_enabled(pwm))</span>
<span class="p_add">+			continue;</span>
<span class="p_add">+</span>
 		clk_disable_unprepare(fpc-&gt;clk[FSL_PWM_CLK_CNTEN]);
 		clk_disable_unprepare(fpc-&gt;clk[fpc-&gt;cnt_select]);
<span class="p_del">-		clk_disable_unprepare(fpc-&gt;clk[FSL_PWM_CLK_SYS]);</span>
 	}
 
 	return 0;
<span class="p_chunk">@@ -511,12 +496,19 @@</span> <span class="p_context"> static int fsl_pwm_suspend(struct device *dev)</span>
 static int fsl_pwm_resume(struct device *dev)
 {
 	struct fsl_pwm_chip *fpc = dev_get_drvdata(dev);
<span class="p_del">-	u32 val;</span>
<span class="p_add">+	int i;</span>
<span class="p_add">+</span>
<span class="p_add">+	for (i = 0; i &lt; fpc-&gt;chip.npwm; i++) {</span>
<span class="p_add">+		struct pwm_device *pwm = &amp;fpc-&gt;chip.pwms[i];</span>
<span class="p_add">+</span>
<span class="p_add">+		if (!test_bit(PWMF_REQUESTED, &amp;pwm-&gt;flags))</span>
<span class="p_add">+			continue;</span>
 
<span class="p_del">-	/* read from cache */</span>
<span class="p_del">-	regmap_read(fpc-&gt;regmap, FTM_OUTMASK, &amp;val);</span>
<span class="p_del">-	if ((val &amp; 0xFF) != 0xFF) {</span>
 		clk_prepare_enable(fpc-&gt;clk[FSL_PWM_CLK_SYS]);
<span class="p_add">+</span>
<span class="p_add">+		if (!pwm_is_enabled(pwm))</span>
<span class="p_add">+			continue;</span>
<span class="p_add">+</span>
 		clk_prepare_enable(fpc-&gt;clk[fpc-&gt;cnt_select]);
 		clk_prepare_enable(fpc-&gt;clk[FSL_PWM_CLK_CNTEN]);
 	}
<span class="p_header">diff --git a/drivers/pwm/pwm-lpc32xx.c b/drivers/pwm/pwm-lpc32xx.c</span>
<span class="p_header">index 9fde60ce8e7b..6e203a65effb 100644</span>
<span class="p_header">--- a/drivers/pwm/pwm-lpc32xx.c</span>
<span class="p_header">+++ b/drivers/pwm/pwm-lpc32xx.c</span>
<span class="p_chunk">@@ -24,9 +24,7 @@</span> <span class="p_context"> struct lpc32xx_pwm_chip {</span>
 	void __iomem *base;
 };
 
<span class="p_del">-#define PWM_ENABLE	(1 &lt;&lt; 31)</span>
<span class="p_del">-#define PWM_RELOADV(x)	(((x) &amp; 0xFF) &lt;&lt; 8)</span>
<span class="p_del">-#define PWM_DUTY(x)	((x) &amp; 0xFF)</span>
<span class="p_add">+#define PWM_ENABLE	BIT(31)</span>
 
 #define to_lpc32xx_pwm_chip(_chip) \
 	container_of(_chip, struct lpc32xx_pwm_chip, chip)
<span class="p_chunk">@@ -38,40 +36,27 @@</span> <span class="p_context"> static int lpc32xx_pwm_config(struct pwm_chip *chip, struct pwm_device *pwm,</span>
 	unsigned long long c;
 	int period_cycles, duty_cycles;
 	u32 val;
<span class="p_del">-</span>
<span class="p_del">-	c = clk_get_rate(lpc32xx-&gt;clk) / 256;</span>
<span class="p_del">-	c = c * period_ns;</span>
<span class="p_del">-	do_div(c, NSEC_PER_SEC);</span>
<span class="p_del">-</span>
<span class="p_del">-	/* Handle high and low extremes */</span>
<span class="p_del">-	if (c == 0)</span>
<span class="p_del">-		c = 1;</span>
<span class="p_del">-	if (c &gt; 255)</span>
<span class="p_del">-		c = 0; /* 0 set division by 256 */</span>
<span class="p_del">-	period_cycles = c;</span>
<span class="p_del">-</span>
<span class="p_del">-	/* The duty-cycle value is as follows:</span>
<span class="p_del">-	 *</span>
<span class="p_del">-	 *  DUTY-CYCLE     HIGH LEVEL</span>
<span class="p_del">-	 *      1            99.9%</span>
<span class="p_del">-	 *      25           90.0%</span>
<span class="p_del">-	 *      128          50.0%</span>
<span class="p_del">-	 *      220          10.0%</span>
<span class="p_del">-	 *      255           0.1%</span>
<span class="p_del">-	 *      0             0.0%</span>
<span class="p_del">-	 *</span>
<span class="p_del">-	 * In other words, the register value is duty-cycle % 256 with</span>
<span class="p_del">-	 * duty-cycle in the range 1-256.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	c = 256 * duty_ns;</span>
<span class="p_del">-	do_div(c, period_ns);</span>
<span class="p_del">-	if (c &gt; 255)</span>
<span class="p_del">-		c = 255;</span>
<span class="p_del">-	duty_cycles = 256 - c;</span>
<span class="p_add">+	c = clk_get_rate(lpc32xx-&gt;clk);</span>
<span class="p_add">+</span>
<span class="p_add">+	/* The highest acceptable divisor is 256, which is represented by 0 */</span>
<span class="p_add">+	period_cycles = div64_u64(c * period_ns,</span>
<span class="p_add">+			       (unsigned long long)NSEC_PER_SEC * 256);</span>
<span class="p_add">+	if (!period_cycles)</span>
<span class="p_add">+		period_cycles = 1;</span>
<span class="p_add">+	if (period_cycles &gt; 255)</span>
<span class="p_add">+		period_cycles = 0;</span>
<span class="p_add">+</span>
<span class="p_add">+	/* Compute 256 x #duty/period value and care for corner cases */</span>
<span class="p_add">+	duty_cycles = div64_u64((unsigned long long)(period_ns - duty_ns) * 256,</span>
<span class="p_add">+				period_ns);</span>
<span class="p_add">+	if (!duty_cycles)</span>
<span class="p_add">+		duty_cycles = 1;</span>
<span class="p_add">+	if (duty_cycles &gt; 255)</span>
<span class="p_add">+		duty_cycles = 255;</span>
 
 	val = readl(lpc32xx-&gt;base + (pwm-&gt;hwpwm &lt;&lt; 2));
 	val &amp;= ~0xFFFF;
<span class="p_del">-	val |= PWM_RELOADV(period_cycles) | PWM_DUTY(duty_cycles);</span>
<span class="p_add">+	val |= (period_cycles &lt;&lt; 8) | duty_cycles;</span>
 	writel(val, lpc32xx-&gt;base + (pwm-&gt;hwpwm &lt;&lt; 2));
 
 	return 0;
<span class="p_chunk">@@ -134,7 +119,7 @@</span> <span class="p_context"> static int lpc32xx_pwm_probe(struct platform_device *pdev)</span>
 
 	lpc32xx-&gt;chip.dev = &amp;pdev-&gt;dev;
 	lpc32xx-&gt;chip.ops = &amp;lpc32xx_pwm_ops;
<span class="p_del">-	lpc32xx-&gt;chip.npwm = 2;</span>
<span class="p_add">+	lpc32xx-&gt;chip.npwm = 1;</span>
 	lpc32xx-&gt;chip.base = -1;
 
 	ret = pwmchip_add(&amp;lpc32xx-&gt;chip);
<span class="p_header">diff --git a/drivers/regulator/anatop-regulator.c b/drivers/regulator/anatop-regulator.c</span>
<span class="p_header">index 63cd5e68c864..3a6d0290c54c 100644</span>
<span class="p_header">--- a/drivers/regulator/anatop-regulator.c</span>
<span class="p_header">+++ b/drivers/regulator/anatop-regulator.c</span>
<span class="p_chunk">@@ -296,7 +296,7 @@</span> <span class="p_context"> static int anatop_regulator_probe(struct platform_device *pdev)</span>
 		if (!sreg-&gt;sel &amp;&amp; !strcmp(sreg-&gt;name, &quot;vddpu&quot;))
 			sreg-&gt;sel = 22;
 
<span class="p_del">-		if (!sreg-&gt;sel) {</span>
<span class="p_add">+		if (!sreg-&gt;bypass &amp;&amp; !sreg-&gt;sel) {</span>
 			dev_err(&amp;pdev-&gt;dev, &quot;Failed to read a valid default voltage selector.\n&quot;);
 			return -EINVAL;
 		}
<span class="p_header">diff --git a/drivers/s390/char/sclp_ctl.c b/drivers/s390/char/sclp_ctl.c</span>
<span class="p_header">index 648cb86afd42..ea607a4a1bdd 100644</span>
<span class="p_header">--- a/drivers/s390/char/sclp_ctl.c</span>
<span class="p_header">+++ b/drivers/s390/char/sclp_ctl.c</span>
<span class="p_chunk">@@ -56,6 +56,7 @@</span> <span class="p_context"> static int sclp_ctl_ioctl_sccb(void __user *user_area)</span>
 {
 	struct sclp_ctl_sccb ctl_sccb;
 	struct sccb_header *sccb;
<span class="p_add">+	unsigned long copied;</span>
 	int rc;
 
 	if (copy_from_user(&amp;ctl_sccb, user_area, sizeof(ctl_sccb)))
<span class="p_chunk">@@ -65,14 +66,15 @@</span> <span class="p_context"> static int sclp_ctl_ioctl_sccb(void __user *user_area)</span>
 	sccb = (void *) get_zeroed_page(GFP_KERNEL | GFP_DMA);
 	if (!sccb)
 		return -ENOMEM;
<span class="p_del">-	if (copy_from_user(sccb, u64_to_uptr(ctl_sccb.sccb), sizeof(*sccb))) {</span>
<span class="p_add">+	copied = PAGE_SIZE -</span>
<span class="p_add">+		copy_from_user(sccb, u64_to_uptr(ctl_sccb.sccb), PAGE_SIZE);</span>
<span class="p_add">+	if (offsetof(struct sccb_header, length) +</span>
<span class="p_add">+	    sizeof(sccb-&gt;length) &gt; copied || sccb-&gt;length &gt; copied) {</span>
 		rc = -EFAULT;
 		goto out_free;
 	}
<span class="p_del">-	if (sccb-&gt;length &gt; PAGE_SIZE || sccb-&gt;length &lt; 8)</span>
<span class="p_del">-		return -EINVAL;</span>
<span class="p_del">-	if (copy_from_user(sccb, u64_to_uptr(ctl_sccb.sccb), sccb-&gt;length)) {</span>
<span class="p_del">-		rc = -EFAULT;</span>
<span class="p_add">+	if (sccb-&gt;length &lt; 8) {</span>
<span class="p_add">+		rc = -EINVAL;</span>
 		goto out_free;
 	}
 	rc = sclp_sync_request(ctl_sccb.cmdw, sccb);
<span class="p_header">diff --git a/drivers/s390/cio/chp.c b/drivers/s390/cio/chp.c</span>
<span class="p_header">index c692dfebd0ba..50597f9522fe 100644</span>
<span class="p_header">--- a/drivers/s390/cio/chp.c</span>
<span class="p_header">+++ b/drivers/s390/cio/chp.c</span>
<span class="p_chunk">@@ -139,11 +139,11 @@</span> <span class="p_context"> static ssize_t chp_measurement_chars_read(struct file *filp,</span>
 
 	device = container_of(kobj, struct device, kobj);
 	chp = to_channelpath(device);
<span class="p_del">-	if (!chp-&gt;cmg_chars)</span>
<span class="p_add">+	if (chp-&gt;cmg == -1)</span>
 		return 0;
 
<span class="p_del">-	return memory_read_from_buffer(buf, count, &amp;off,</span>
<span class="p_del">-				chp-&gt;cmg_chars, sizeof(struct cmg_chars));</span>
<span class="p_add">+	return memory_read_from_buffer(buf, count, &amp;off, &amp;chp-&gt;cmg_chars,</span>
<span class="p_add">+				       sizeof(chp-&gt;cmg_chars));</span>
 }
 
 static struct bin_attribute chp_measurement_chars_attr = {
<span class="p_chunk">@@ -416,7 +416,8 @@</span> <span class="p_context"> static void chp_release(struct device *dev)</span>
  * chp_update_desc - update channel-path description
  * @chp - channel-path
  *
<span class="p_del">- * Update the channel-path description of the specified channel-path.</span>
<span class="p_add">+ * Update the channel-path description of the specified channel-path</span>
<span class="p_add">+ * including channel measurement related information.</span>
  * Return zero on success, non-zero otherwise.
  */
 int chp_update_desc(struct channel_path *chp)
<span class="p_chunk">@@ -428,8 +429,10 @@</span> <span class="p_context"> int chp_update_desc(struct channel_path *chp)</span>
 		return rc;
 
 	rc = chsc_determine_fmt1_channel_path_desc(chp-&gt;chpid, &amp;chp-&gt;desc_fmt1);
<span class="p_add">+	if (rc)</span>
<span class="p_add">+		return rc;</span>
 
<span class="p_del">-	return rc;</span>
<span class="p_add">+	return chsc_get_channel_measurement_chars(chp);</span>
 }
 
 /**
<span class="p_chunk">@@ -466,14 +469,6 @@</span> <span class="p_context"> int chp_new(struct chp_id chpid)</span>
 		ret = -ENODEV;
 		goto out_free;
 	}
<span class="p_del">-	/* Get channel-measurement characteristics. */</span>
<span class="p_del">-	if (css_chsc_characteristics.scmc &amp;&amp; css_chsc_characteristics.secm) {</span>
<span class="p_del">-		ret = chsc_get_channel_measurement_chars(chp);</span>
<span class="p_del">-		if (ret)</span>
<span class="p_del">-			goto out_free;</span>
<span class="p_del">-	} else {</span>
<span class="p_del">-		chp-&gt;cmg = -1;</span>
<span class="p_del">-	}</span>
 	dev_set_name(&amp;chp-&gt;dev, &quot;chp%x.%02x&quot;, chpid.cssid, chpid.id);
 
 	/* make it known to the system */
<span class="p_header">diff --git a/drivers/s390/cio/chp.h b/drivers/s390/cio/chp.h</span>
<span class="p_header">index 4efd5b867cc3..af0232290dc4 100644</span>
<span class="p_header">--- a/drivers/s390/cio/chp.h</span>
<span class="p_header">+++ b/drivers/s390/cio/chp.h</span>
<span class="p_chunk">@@ -48,7 +48,7 @@</span> <span class="p_context"> struct channel_path {</span>
 	/* Channel-measurement related stuff: */
 	int cmg;
 	int shared;
<span class="p_del">-	void *cmg_chars;</span>
<span class="p_add">+	struct cmg_chars cmg_chars;</span>
 };
 
 /* Return channel_path struct for given chpid. */
<span class="p_header">diff --git a/drivers/s390/cio/chsc.c b/drivers/s390/cio/chsc.c</span>
<span class="p_header">index a831d18596a5..c424c0c7367e 100644</span>
<span class="p_header">--- a/drivers/s390/cio/chsc.c</span>
<span class="p_header">+++ b/drivers/s390/cio/chsc.c</span>
<span class="p_chunk">@@ -14,6 +14,7 @@</span> <span class="p_context"></span>
 #include &lt;linux/slab.h&gt;
 #include &lt;linux/init.h&gt;
 #include &lt;linux/device.h&gt;
<span class="p_add">+#include &lt;linux/mutex.h&gt;</span>
 #include &lt;linux/pci.h&gt;
 
 #include &lt;asm/cio.h&gt;
<span class="p_chunk">@@ -224,8 +225,9 @@</span> <span class="p_context"> out_unreg:</span>
 
 void chsc_chp_offline(struct chp_id chpid)
 {
<span class="p_del">-	char dbf_txt[15];</span>
<span class="p_add">+	struct channel_path *chp = chpid_to_chp(chpid);</span>
 	struct chp_link link;
<span class="p_add">+	char dbf_txt[15];</span>
 
 	sprintf(dbf_txt, &quot;chpr%x.%02x&quot;, chpid.cssid, chpid.id);
 	CIO_TRACE_EVENT(2, dbf_txt);
<span class="p_chunk">@@ -236,6 +238,11 @@</span> <span class="p_context"> void chsc_chp_offline(struct chp_id chpid)</span>
 	link.chpid = chpid;
 	/* Wait until previous actions have settled. */
 	css_wait_for_slow_path();
<span class="p_add">+</span>
<span class="p_add">+	mutex_lock(&amp;chp-&gt;lock);</span>
<span class="p_add">+	chp_update_desc(chp);</span>
<span class="p_add">+	mutex_unlock(&amp;chp-&gt;lock);</span>
<span class="p_add">+</span>
 	for_each_subchannel_staged(s390_subchannel_remove_chpid, NULL, &amp;link);
 }
 
<span class="p_chunk">@@ -690,8 +697,9 @@</span> <span class="p_context"> static void chsc_process_crw(struct crw *crw0, struct crw *crw1, int overflow)</span>
 
 void chsc_chp_online(struct chp_id chpid)
 {
<span class="p_del">-	char dbf_txt[15];</span>
<span class="p_add">+	struct channel_path *chp = chpid_to_chp(chpid);</span>
 	struct chp_link link;
<span class="p_add">+	char dbf_txt[15];</span>
 
 	sprintf(dbf_txt, &quot;cadd%x.%02x&quot;, chpid.cssid, chpid.id);
 	CIO_TRACE_EVENT(2, dbf_txt);
<span class="p_chunk">@@ -701,6 +709,11 @@</span> <span class="p_context"> void chsc_chp_online(struct chp_id chpid)</span>
 		link.chpid = chpid;
 		/* Wait until previous actions have settled. */
 		css_wait_for_slow_path();
<span class="p_add">+</span>
<span class="p_add">+		mutex_lock(&amp;chp-&gt;lock);</span>
<span class="p_add">+		chp_update_desc(chp);</span>
<span class="p_add">+		mutex_unlock(&amp;chp-&gt;lock);</span>
<span class="p_add">+</span>
 		for_each_subchannel_staged(__s390_process_res_acc, NULL,
 					   &amp;link);
 		css_schedule_reprobe();
<span class="p_chunk">@@ -967,22 +980,19 @@</span> <span class="p_context"> static void</span>
 chsc_initialize_cmg_chars(struct channel_path *chp, u8 cmcv,
 			  struct cmg_chars *chars)
 {
<span class="p_del">-	struct cmg_chars *cmg_chars;</span>
 	int i, mask;
 
<span class="p_del">-	cmg_chars = chp-&gt;cmg_chars;</span>
 	for (i = 0; i &lt; NR_MEASUREMENT_CHARS; i++) {
 		mask = 0x80 &gt;&gt; (i + 3);
 		if (cmcv &amp; mask)
<span class="p_del">-			cmg_chars-&gt;values[i] = chars-&gt;values[i];</span>
<span class="p_add">+			chp-&gt;cmg_chars.values[i] = chars-&gt;values[i];</span>
 		else
<span class="p_del">-			cmg_chars-&gt;values[i] = 0;</span>
<span class="p_add">+			chp-&gt;cmg_chars.values[i] = 0;</span>
 	}
 }
 
 int chsc_get_channel_measurement_chars(struct channel_path *chp)
 {
<span class="p_del">-	struct cmg_chars *cmg_chars;</span>
 	int ccode, ret;
 
 	struct {
<span class="p_chunk">@@ -1006,10 +1016,11 @@</span> <span class="p_context"> int chsc_get_channel_measurement_chars(struct channel_path *chp)</span>
 		u32 data[NR_MEASUREMENT_CHARS];
 	} __attribute__ ((packed)) *scmc_area;
 
<span class="p_del">-	chp-&gt;cmg_chars = NULL;</span>
<span class="p_del">-	cmg_chars = kmalloc(sizeof(*cmg_chars), GFP_KERNEL);</span>
<span class="p_del">-	if (!cmg_chars)</span>
<span class="p_del">-		return -ENOMEM;</span>
<span class="p_add">+	chp-&gt;shared = -1;</span>
<span class="p_add">+	chp-&gt;cmg = -1;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (!css_chsc_characteristics.scmc || !css_chsc_characteristics.secm)</span>
<span class="p_add">+		return 0;</span>
 
 	spin_lock_irq(&amp;chsc_page_lock);
 	memset(chsc_page, 0, PAGE_SIZE);
<span class="p_chunk">@@ -1031,25 +1042,19 @@</span> <span class="p_context"> int chsc_get_channel_measurement_chars(struct channel_path *chp)</span>
 			      scmc_area-&gt;response.code);
 		goto out;
 	}
<span class="p_del">-	if (scmc_area-&gt;not_valid) {</span>
<span class="p_del">-		chp-&gt;cmg = -1;</span>
<span class="p_del">-		chp-&gt;shared = -1;</span>
<span class="p_add">+	if (scmc_area-&gt;not_valid)</span>
 		goto out;
<span class="p_del">-	}</span>
<span class="p_add">+</span>
 	chp-&gt;cmg = scmc_area-&gt;cmg;
 	chp-&gt;shared = scmc_area-&gt;shared;
 	if (chp-&gt;cmg != 2 &amp;&amp; chp-&gt;cmg != 3) {
 		/* No cmg-dependent data. */
 		goto out;
 	}
<span class="p_del">-	chp-&gt;cmg_chars = cmg_chars;</span>
 	chsc_initialize_cmg_chars(chp, scmc_area-&gt;cmcv,
 				  (struct cmg_chars *) &amp;scmc_area-&gt;data);
 out:
 	spin_unlock_irq(&amp;chsc_page_lock);
<span class="p_del">-	if (!chp-&gt;cmg_chars)</span>
<span class="p_del">-		kfree(cmg_chars);</span>
<span class="p_del">-</span>
 	return ret;
 }
 
<span class="p_header">diff --git a/drivers/s390/net/qeth_l2_main.c b/drivers/s390/net/qeth_l2_main.c</span>
<span class="p_header">index 12b2cb7769f9..df036b872b05 100644</span>
<span class="p_header">--- a/drivers/s390/net/qeth_l2_main.c</span>
<span class="p_header">+++ b/drivers/s390/net/qeth_l2_main.c</span>
<span class="p_chunk">@@ -1127,6 +1127,7 @@</span> <span class="p_context"> static int qeth_l2_setup_netdev(struct qeth_card *card)</span>
 	qeth_l2_request_initial_mac(card);
 	SET_NETDEV_DEV(card-&gt;dev, &amp;card-&gt;gdev-&gt;dev);
 	netif_napi_add(card-&gt;dev, &amp;card-&gt;napi, qeth_l2_poll, QETH_NAPI_WEIGHT);
<span class="p_add">+	netif_carrier_off(card-&gt;dev);</span>
 	return register_netdev(card-&gt;dev);
 }
 
<span class="p_header">diff --git a/drivers/s390/net/qeth_l3_main.c b/drivers/s390/net/qeth_l3_main.c</span>
<span class="p_header">index 50cec6b13d27..cc4d3c3d8cc5 100644</span>
<span class="p_header">--- a/drivers/s390/net/qeth_l3_main.c</span>
<span class="p_header">+++ b/drivers/s390/net/qeth_l3_main.c</span>
<span class="p_chunk">@@ -3220,6 +3220,7 @@</span> <span class="p_context"> static int qeth_l3_setup_netdev(struct qeth_card *card)</span>
 
 	SET_NETDEV_DEV(card-&gt;dev, &amp;card-&gt;gdev-&gt;dev);
 	netif_napi_add(card-&gt;dev, &amp;card-&gt;napi, qeth_l3_poll, QETH_NAPI_WEIGHT);
<span class="p_add">+	netif_carrier_off(card-&gt;dev);</span>
 	return register_netdev(card-&gt;dev);
 }
 
<span class="p_header">diff --git a/drivers/scsi/arcmsr/arcmsr_hba.c b/drivers/scsi/arcmsr/arcmsr_hba.c</span>
<span class="p_header">index 333db5953607..41f9a00e4f74 100644</span>
<span class="p_header">--- a/drivers/scsi/arcmsr/arcmsr_hba.c</span>
<span class="p_header">+++ b/drivers/scsi/arcmsr/arcmsr_hba.c</span>
<span class="p_chunk">@@ -2664,7 +2664,7 @@</span> <span class="p_context"> static bool arcmsr_hbaB_get_config(struct AdapterControlBlock *acb)</span>
 	if (!arcmsr_hbaB_wait_msgint_ready(acb)) {
 		printk(KERN_NOTICE &quot;arcmsr%d: wait &#39;get adapter firmware \
 			miscellaneous data&#39; timeout \n&quot;, acb-&gt;host-&gt;host_no);
<span class="p_del">-		return false;</span>
<span class="p_add">+		goto err_free_dma;</span>
 	}
 	count = 8;
 	while (count){
<span class="p_chunk">@@ -2694,19 +2694,23 @@</span> <span class="p_context"> static bool arcmsr_hbaB_get_config(struct AdapterControlBlock *acb)</span>
 		acb-&gt;firm_model,
 		acb-&gt;firm_version);
 
<span class="p_del">-	acb-&gt;signature = readl(&amp;reg-&gt;message_rwbuffer[1]);</span>
<span class="p_add">+	acb-&gt;signature = readl(&amp;reg-&gt;message_rwbuffer[0]);</span>
 	/*firm_signature,1,00-03*/
<span class="p_del">-	acb-&gt;firm_request_len = readl(&amp;reg-&gt;message_rwbuffer[2]);</span>
<span class="p_add">+	acb-&gt;firm_request_len = readl(&amp;reg-&gt;message_rwbuffer[1]);</span>
 	/*firm_request_len,1,04-07*/
<span class="p_del">-	acb-&gt;firm_numbers_queue = readl(&amp;reg-&gt;message_rwbuffer[3]);</span>
<span class="p_add">+	acb-&gt;firm_numbers_queue = readl(&amp;reg-&gt;message_rwbuffer[2]);</span>
 	/*firm_numbers_queue,2,08-11*/
<span class="p_del">-	acb-&gt;firm_sdram_size = readl(&amp;reg-&gt;message_rwbuffer[4]);</span>
<span class="p_add">+	acb-&gt;firm_sdram_size = readl(&amp;reg-&gt;message_rwbuffer[3]);</span>
 	/*firm_sdram_size,3,12-15*/
<span class="p_del">-	acb-&gt;firm_hd_channels = readl(&amp;reg-&gt;message_rwbuffer[5]);</span>
<span class="p_add">+	acb-&gt;firm_hd_channels = readl(&amp;reg-&gt;message_rwbuffer[4]);</span>
 	/*firm_ide_channels,4,16-19*/
 	acb-&gt;firm_cfg_version = readl(&amp;reg-&gt;message_rwbuffer[25]);  /*firm_cfg_version,25,100-103*/
 	/*firm_ide_channels,4,16-19*/
 	return true;
<span class="p_add">+err_free_dma:</span>
<span class="p_add">+	dma_free_coherent(&amp;acb-&gt;pdev-&gt;dev, acb-&gt;roundup_ccbsize,</span>
<span class="p_add">+			acb-&gt;dma_coherent2, acb-&gt;dma_coherent_handle2);</span>
<span class="p_add">+	return false;</span>
 }
 
 static bool arcmsr_hbaC_get_config(struct AdapterControlBlock *pACB)
<span class="p_chunk">@@ -2880,15 +2884,15 @@</span> <span class="p_context"> static bool arcmsr_hbaD_get_config(struct AdapterControlBlock *acb)</span>
 		iop_device_map++;
 		count--;
 	}
<span class="p_del">-	acb-&gt;signature = readl(&amp;reg-&gt;msgcode_rwbuffer[1]);</span>
<span class="p_add">+	acb-&gt;signature = readl(&amp;reg-&gt;msgcode_rwbuffer[0]);</span>
 	/*firm_signature,1,00-03*/
<span class="p_del">-	acb-&gt;firm_request_len = readl(&amp;reg-&gt;msgcode_rwbuffer[2]);</span>
<span class="p_add">+	acb-&gt;firm_request_len = readl(&amp;reg-&gt;msgcode_rwbuffer[1]);</span>
 	/*firm_request_len,1,04-07*/
<span class="p_del">-	acb-&gt;firm_numbers_queue = readl(&amp;reg-&gt;msgcode_rwbuffer[3]);</span>
<span class="p_add">+	acb-&gt;firm_numbers_queue = readl(&amp;reg-&gt;msgcode_rwbuffer[2]);</span>
 	/*firm_numbers_queue,2,08-11*/
<span class="p_del">-	acb-&gt;firm_sdram_size = readl(&amp;reg-&gt;msgcode_rwbuffer[4]);</span>
<span class="p_add">+	acb-&gt;firm_sdram_size = readl(&amp;reg-&gt;msgcode_rwbuffer[3]);</span>
 	/*firm_sdram_size,3,12-15*/
<span class="p_del">-	acb-&gt;firm_hd_channels = readl(&amp;reg-&gt;msgcode_rwbuffer[5]);</span>
<span class="p_add">+	acb-&gt;firm_hd_channels = readl(&amp;reg-&gt;msgcode_rwbuffer[4]);</span>
 	/*firm_hd_channels,4,16-19*/
 	acb-&gt;firm_cfg_version = readl(&amp;reg-&gt;msgcode_rwbuffer[25]);
 	pr_notice(&quot;Areca RAID Controller%d: Model %s, F/W %s\n&quot;,
<span class="p_header">diff --git a/drivers/scsi/constants.c b/drivers/scsi/constants.c</span>
<span class="p_header">index fa09d4be2b53..2b456ca69d5c 100644</span>
<span class="p_header">--- a/drivers/scsi/constants.c</span>
<span class="p_header">+++ b/drivers/scsi/constants.c</span>
<span class="p_chunk">@@ -1181,8 +1181,9 @@</span> <span class="p_context"> static const char * const snstext[] = {</span>
 
 /* Get sense key string or NULL if not available */
 const char *
<span class="p_del">-scsi_sense_key_string(unsigned char key) {</span>
<span class="p_del">-	if (key &lt;= 0xE)</span>
<span class="p_add">+scsi_sense_key_string(unsigned char key)</span>
<span class="p_add">+{</span>
<span class="p_add">+	if (key &lt; ARRAY_SIZE(snstext))</span>
 		return snstext[key];
 	return NULL;
 }
<span class="p_header">diff --git a/drivers/scsi/cxlflash/common.h b/drivers/scsi/cxlflash/common.h</span>
<span class="p_header">index c11cd193f896..5ada9268a450 100644</span>
<span class="p_header">--- a/drivers/scsi/cxlflash/common.h</span>
<span class="p_header">+++ b/drivers/scsi/cxlflash/common.h</span>
<span class="p_chunk">@@ -165,6 +165,8 @@</span> <span class="p_context"> struct afu {</span>
 	struct sisl_host_map __iomem *host_map;		/* MC host map */
 	struct sisl_ctrl_map __iomem *ctrl_map;		/* MC control map */
 
<span class="p_add">+	struct kref mapcount;</span>
<span class="p_add">+</span>
 	ctx_hndl_t ctx_hndl;	/* master&#39;s context handle */
 	u64 *hrrq_start;
 	u64 *hrrq_end;
<span class="p_header">diff --git a/drivers/scsi/cxlflash/main.c b/drivers/scsi/cxlflash/main.c</span>
<span class="p_header">index 1e5bf0ca81da..c86847c68448 100644</span>
<span class="p_header">--- a/drivers/scsi/cxlflash/main.c</span>
<span class="p_header">+++ b/drivers/scsi/cxlflash/main.c</span>
<span class="p_chunk">@@ -289,7 +289,7 @@</span> <span class="p_context"> static void context_reset(struct afu_cmd *cmd)</span>
 		atomic64_set(&amp;afu-&gt;room, room);
 		if (room)
 			goto write_rrin;
<span class="p_del">-		udelay(nretry);</span>
<span class="p_add">+		udelay(1 &lt;&lt; nretry);</span>
 	} while (nretry++ &lt; MC_ROOM_RETRY_CNT);
 
 	pr_err(&quot;%s: no cmd_room to send reset\n&quot;, __func__);
<span class="p_chunk">@@ -303,7 +303,7 @@</span> <span class="p_context"> write_rrin:</span>
 		if (rrin != 0x1)
 			break;
 		/* Double delay each time */
<span class="p_del">-		udelay(2 &lt;&lt; nretry);</span>
<span class="p_add">+		udelay(1 &lt;&lt; nretry);</span>
 	} while (nretry++ &lt; MC_ROOM_RETRY_CNT);
 }
 
<span class="p_chunk">@@ -338,7 +338,7 @@</span> <span class="p_context"> retry:</span>
 			atomic64_set(&amp;afu-&gt;room, room);
 			if (room)
 				goto write_ioarrin;
<span class="p_del">-			udelay(nretry);</span>
<span class="p_add">+			udelay(1 &lt;&lt; nretry);</span>
 		} while (nretry++ &lt; MC_ROOM_RETRY_CNT);
 
 		dev_err(dev, &quot;%s: no cmd_room to send 0x%X\n&quot;,
<span class="p_chunk">@@ -352,7 +352,7 @@</span> <span class="p_context"> retry:</span>
 		 * afu-&gt;room.
 		 */
 		if (nretry++ &lt; MC_ROOM_RETRY_CNT) {
<span class="p_del">-			udelay(nretry);</span>
<span class="p_add">+			udelay(1 &lt;&lt; nretry);</span>
 			goto retry;
 		}
 
<span class="p_chunk">@@ -368,6 +368,7 @@</span> <span class="p_context"> out:</span>
 
 no_room:
 	afu-&gt;read_room = true;
<span class="p_add">+	kref_get(&amp;cfg-&gt;afu-&gt;mapcount);</span>
 	schedule_work(&amp;cfg-&gt;work_q);
 	rc = SCSI_MLQUEUE_HOST_BUSY;
 	goto out;
<span class="p_chunk">@@ -473,6 +474,16 @@</span> <span class="p_context"> out:</span>
 	return rc;
 }
 
<span class="p_add">+static void afu_unmap(struct kref *ref)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct afu *afu = container_of(ref, struct afu, mapcount);</span>
<span class="p_add">+</span>
<span class="p_add">+	if (likely(afu-&gt;afu_map)) {</span>
<span class="p_add">+		cxl_psa_unmap((void __iomem *)afu-&gt;afu_map);</span>
<span class="p_add">+		afu-&gt;afu_map = NULL;</span>
<span class="p_add">+	}</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 /**
  * cxlflash_driver_info() - information handler for this host driver
  * @host:	SCSI host associated with device.
<span class="p_chunk">@@ -503,6 +514,7 @@</span> <span class="p_context"> static int cxlflash_queuecommand(struct Scsi_Host *host, struct scsi_cmnd *scp)</span>
 	ulong lock_flags;
 	short lflag = 0;
 	int rc = 0;
<span class="p_add">+	int kref_got = 0;</span>
 
 	dev_dbg_ratelimited(dev, &quot;%s: (scp=%p) %d/%d/%d/%llu &quot;
 			    &quot;cdb=(%08X-%08X-%08X-%08X)\n&quot;,
<span class="p_chunk">@@ -547,6 +559,9 @@</span> <span class="p_context"> static int cxlflash_queuecommand(struct Scsi_Host *host, struct scsi_cmnd *scp)</span>
 		goto out;
 	}
 
<span class="p_add">+	kref_get(&amp;cfg-&gt;afu-&gt;mapcount);</span>
<span class="p_add">+	kref_got = 1;</span>
<span class="p_add">+</span>
 	cmd-&gt;rcb.ctx_id = afu-&gt;ctx_hndl;
 	cmd-&gt;rcb.port_sel = port_sel;
 	cmd-&gt;rcb.lun_id = lun_to_lunid(scp-&gt;device-&gt;lun);
<span class="p_chunk">@@ -587,6 +602,8 @@</span> <span class="p_context"> static int cxlflash_queuecommand(struct Scsi_Host *host, struct scsi_cmnd *scp)</span>
 	}
 
 out:
<span class="p_add">+	if (kref_got)</span>
<span class="p_add">+		kref_put(&amp;afu-&gt;mapcount, afu_unmap);</span>
 	pr_devel(&quot;%s: returning rc=%d\n&quot;, __func__, rc);
 	return rc;
 }
<span class="p_chunk">@@ -632,20 +649,36 @@</span> <span class="p_context"> static void free_mem(struct cxlflash_cfg *cfg)</span>
  * @cfg:	Internal structure associated with the host.
  *
  * Safe to call with AFU in a partially allocated/initialized state.
<span class="p_add">+ *</span>
<span class="p_add">+ * Cleans up all state associated with the command queue, and unmaps</span>
<span class="p_add">+ * the MMIO space.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ *  - complete() will take care of commands we initiated (they&#39;ll be checked</span>
<span class="p_add">+ *  in as part of the cleanup that occurs after the completion)</span>
<span class="p_add">+ *</span>
<span class="p_add">+ *  - cmd_checkin() will take care of entries that we did not initiate and that</span>
<span class="p_add">+ *  have not (and will not) complete because they are sitting on a [now stale]</span>
<span class="p_add">+ *  hardware queue</span>
  */
 static void stop_afu(struct cxlflash_cfg *cfg)
 {
 	int i;
 	struct afu *afu = cfg-&gt;afu;
<span class="p_add">+	struct afu_cmd *cmd;</span>
 
 	if (likely(afu)) {
<span class="p_del">-		for (i = 0; i &lt; CXLFLASH_NUM_CMDS; i++)</span>
<span class="p_del">-			complete(&amp;afu-&gt;cmd[i].cevent);</span>
<span class="p_add">+		for (i = 0; i &lt; CXLFLASH_NUM_CMDS; i++) {</span>
<span class="p_add">+			cmd = &amp;afu-&gt;cmd[i];</span>
<span class="p_add">+			complete(&amp;cmd-&gt;cevent);</span>
<span class="p_add">+			if (!atomic_read(&amp;cmd-&gt;free))</span>
<span class="p_add">+				cmd_checkin(cmd);</span>
<span class="p_add">+		}</span>
 
 		if (likely(afu-&gt;afu_map)) {
 			cxl_psa_unmap((void __iomem *)afu-&gt;afu_map);
 			afu-&gt;afu_map = NULL;
 		}
<span class="p_add">+		kref_put(&amp;afu-&gt;mapcount, afu_unmap);</span>
 	}
 }
 
<span class="p_chunk">@@ -731,8 +764,8 @@</span> <span class="p_context"> static void cxlflash_remove(struct pci_dev *pdev)</span>
 		scsi_remove_host(cfg-&gt;host);
 		/* fall through */
 	case INIT_STATE_AFU:
<span class="p_del">-		term_afu(cfg);</span>
 		cancel_work_sync(&amp;cfg-&gt;work_q);
<span class="p_add">+		term_afu(cfg);</span>
 	case INIT_STATE_PCI:
 		pci_release_regions(cfg-&gt;dev);
 		pci_disable_device(pdev);
<span class="p_chunk">@@ -1108,7 +1141,7 @@</span> <span class="p_context"> static const struct asyc_intr_info ainfo[] = {</span>
 	{SISL_ASTATUS_FC1_OTHER, &quot;other error&quot;, 1, CLR_FC_ERROR | LINK_RESET},
 	{SISL_ASTATUS_FC1_LOGO, &quot;target initiated LOGO&quot;, 1, 0},
 	{SISL_ASTATUS_FC1_CRC_T, &quot;CRC threshold exceeded&quot;, 1, LINK_RESET},
<span class="p_del">-	{SISL_ASTATUS_FC1_LOGI_R, &quot;login timed out, retrying&quot;, 1, 0},</span>
<span class="p_add">+	{SISL_ASTATUS_FC1_LOGI_R, &quot;login timed out, retrying&quot;, 1, LINK_RESET},</span>
 	{SISL_ASTATUS_FC1_LOGI_F, &quot;login failed&quot;, 1, CLR_FC_ERROR},
 	{SISL_ASTATUS_FC1_LOGI_S, &quot;login succeeded&quot;, 1, SCAN_HOST},
 	{SISL_ASTATUS_FC1_LINK_DN, &quot;link down&quot;, 1, 0},
<span class="p_chunk">@@ -1316,6 +1349,7 @@</span> <span class="p_context"> static irqreturn_t cxlflash_async_err_irq(int irq, void *data)</span>
 				__func__, port);
 			cfg-&gt;lr_state = LINK_RESET_REQUIRED;
 			cfg-&gt;lr_port = port;
<span class="p_add">+			kref_get(&amp;cfg-&gt;afu-&gt;mapcount);</span>
 			schedule_work(&amp;cfg-&gt;work_q);
 		}
 
<span class="p_chunk">@@ -1336,6 +1370,7 @@</span> <span class="p_context"> static irqreturn_t cxlflash_async_err_irq(int irq, void *data)</span>
 
 		if (info-&gt;action &amp; SCAN_HOST) {
 			atomic_inc(&amp;cfg-&gt;scan_host_needed);
<span class="p_add">+			kref_get(&amp;cfg-&gt;afu-&gt;mapcount);</span>
 			schedule_work(&amp;cfg-&gt;work_q);
 		}
 	}
<span class="p_chunk">@@ -1731,6 +1766,7 @@</span> <span class="p_context"> static int init_afu(struct cxlflash_cfg *cfg)</span>
 		rc = -ENOMEM;
 		goto err1;
 	}
<span class="p_add">+	kref_init(&amp;afu-&gt;mapcount);</span>
 
 	/* No byte reverse on reading afu_version or string will be backwards */
 	reg = readq(&amp;afu-&gt;afu_map-&gt;global.regs.afu_version);
<span class="p_chunk">@@ -1765,8 +1801,7 @@</span> <span class="p_context"> out:</span>
 	return rc;
 
 err2:
<span class="p_del">-	cxl_psa_unmap((void __iomem *)afu-&gt;afu_map);</span>
<span class="p_del">-	afu-&gt;afu_map = NULL;</span>
<span class="p_add">+	kref_put(&amp;afu-&gt;mapcount, afu_unmap);</span>
 err1:
 	term_mc(cfg, UNDO_START);
 	goto out;
<span class="p_chunk">@@ -2114,6 +2149,16 @@</span> <span class="p_context"> static ssize_t lun_mode_store(struct device *dev,</span>
 	rc = kstrtouint(buf, 10, &amp;lun_mode);
 	if (!rc &amp;&amp; (lun_mode &lt; 5) &amp;&amp; (lun_mode != afu-&gt;internal_lun)) {
 		afu-&gt;internal_lun = lun_mode;
<span class="p_add">+</span>
<span class="p_add">+		/*</span>
<span class="p_add">+		 * When configured for internal LUN, there is only one channel,</span>
<span class="p_add">+		 * channel number 0, else there will be 2 (default).</span>
<span class="p_add">+		 */</span>
<span class="p_add">+		if (afu-&gt;internal_lun)</span>
<span class="p_add">+			shost-&gt;max_channel = 0;</span>
<span class="p_add">+		else</span>
<span class="p_add">+			shost-&gt;max_channel = NUM_FC_PORTS - 1;</span>
<span class="p_add">+</span>
 		afu_reset(cfg);
 		scsi_scan_host(cfg-&gt;host);
 	}
<span class="p_chunk">@@ -2274,6 +2319,7 @@</span> <span class="p_context"> static struct scsi_host_template driver_template = {</span>
  * Device dependent values
  */
 static struct dev_dependent_vals dev_corsa_vals = { CXLFLASH_MAX_SECTORS };
<span class="p_add">+static struct dev_dependent_vals dev_flash_gt_vals = { CXLFLASH_MAX_SECTORS };</span>
 
 /*
  * PCI device binding table
<span class="p_chunk">@@ -2281,6 +2327,8 @@</span> <span class="p_context"> static struct dev_dependent_vals dev_corsa_vals = { CXLFLASH_MAX_SECTORS };</span>
 static struct pci_device_id cxlflash_pci_table[] = {
 	{PCI_VENDOR_ID_IBM, PCI_DEVICE_ID_IBM_CORSA,
 	 PCI_ANY_ID, PCI_ANY_ID, 0, 0, (kernel_ulong_t)&amp;dev_corsa_vals},
<span class="p_add">+	{PCI_VENDOR_ID_IBM, PCI_DEVICE_ID_IBM_FLASH_GT,</span>
<span class="p_add">+	 PCI_ANY_ID, PCI_ANY_ID, 0, 0, (kernel_ulong_t)&amp;dev_flash_gt_vals},</span>
 	{}
 };
 
<span class="p_chunk">@@ -2339,6 +2387,7 @@</span> <span class="p_context"> static void cxlflash_worker_thread(struct work_struct *work)</span>
 
 	if (atomic_dec_if_positive(&amp;cfg-&gt;scan_host_needed) &gt;= 0)
 		scsi_scan_host(cfg-&gt;host);
<span class="p_add">+	kref_put(&amp;afu-&gt;mapcount, afu_unmap);</span>
 }
 
 /**
<span class="p_header">diff --git a/drivers/scsi/cxlflash/main.h b/drivers/scsi/cxlflash/main.h</span>
<span class="p_header">index 60324566c14f..3d2d606fafb3 100644</span>
<span class="p_header">--- a/drivers/scsi/cxlflash/main.h</span>
<span class="p_header">+++ b/drivers/scsi/cxlflash/main.h</span>
<span class="p_chunk">@@ -24,8 +24,8 @@</span> <span class="p_context"></span>
 #define CXLFLASH_ADAPTER_NAME	&quot;IBM POWER CXL Flash Adapter&quot;
 #define CXLFLASH_DRIVER_DATE	&quot;(August 13, 2015)&quot;
 
<span class="p_del">-#define PCI_DEVICE_ID_IBM_CORSA	0x04F0</span>
<span class="p_del">-#define CXLFLASH_SUBS_DEV_ID	0x04F0</span>
<span class="p_add">+#define PCI_DEVICE_ID_IBM_CORSA		0x04F0</span>
<span class="p_add">+#define PCI_DEVICE_ID_IBM_FLASH_GT	0x0600</span>
 
 /* Since there is only one target, make it 0 */
 #define CXLFLASH_TARGET		0
<span class="p_header">diff --git a/drivers/scsi/cxlflash/superpipe.c b/drivers/scsi/cxlflash/superpipe.c</span>
<span class="p_header">index cac2e6a50efd..babe7ccc1777 100644</span>
<span class="p_header">--- a/drivers/scsi/cxlflash/superpipe.c</span>
<span class="p_header">+++ b/drivers/scsi/cxlflash/superpipe.c</span>
<span class="p_chunk">@@ -1380,7 +1380,7 @@</span> <span class="p_context"> static int cxlflash_disk_attach(struct scsi_device *sdev,</span>
 	}
 
 	ctxid = cxl_process_element(ctx);
<span class="p_del">-	if (unlikely((ctxid &gt; MAX_CONTEXT) || (ctxid &lt; 0))) {</span>
<span class="p_add">+	if (unlikely((ctxid &gt;= MAX_CONTEXT) || (ctxid &lt; 0))) {</span>
 		dev_err(dev, &quot;%s: ctxid (%d) invalid!\n&quot;, __func__, ctxid);
 		rc = -EPERM;
 		goto err2;
<span class="p_chunk">@@ -1508,7 +1508,7 @@</span> <span class="p_context"> static int recover_context(struct cxlflash_cfg *cfg, struct ctx_info *ctxi)</span>
 	}
 
 	ctxid = cxl_process_element(ctx);
<span class="p_del">-	if (unlikely((ctxid &gt; MAX_CONTEXT) || (ctxid &lt; 0))) {</span>
<span class="p_add">+	if (unlikely((ctxid &gt;= MAX_CONTEXT) || (ctxid &lt; 0))) {</span>
 		dev_err(dev, &quot;%s: ctxid (%d) invalid!\n&quot;, __func__, ctxid);
 		rc = -EPERM;
 		goto err1;
<span class="p_chunk">@@ -1590,6 +1590,13 @@</span> <span class="p_context"> err1:</span>
  * place at the same time and the failure was due to CXL services being
  * unable to keep up.
  *
<span class="p_add">+ * As this routine is called on ioctl context, it holds the ioctl r/w</span>
<span class="p_add">+ * semaphore that is used to drain ioctls in recovery scenarios. The</span>
<span class="p_add">+ * implementation to achieve the pacing described above (a local mutex)</span>
<span class="p_add">+ * requires that the ioctl r/w semaphore be dropped and reacquired to</span>
<span class="p_add">+ * avoid a 3-way deadlock when multiple process recoveries operate in</span>
<span class="p_add">+ * parallel.</span>
<span class="p_add">+ *</span>
  * Because a user can detect an error condition before the kernel, it is
  * quite possible for this routine to act as the kernel&#39;s EEH detection
  * source (MMIO read of mbox_r). Because of this, there is a window of
<span class="p_chunk">@@ -1617,9 +1624,17 @@</span> <span class="p_context"> static int cxlflash_afu_recover(struct scsi_device *sdev,</span>
 	int rc = 0;
 
 	atomic_inc(&amp;cfg-&gt;recovery_threads);
<span class="p_add">+	up_read(&amp;cfg-&gt;ioctl_rwsem);</span>
 	rc = mutex_lock_interruptible(mutex);
<span class="p_add">+	down_read(&amp;cfg-&gt;ioctl_rwsem);</span>
 	if (rc)
 		goto out;
<span class="p_add">+	rc = check_state(cfg);</span>
<span class="p_add">+	if (rc) {</span>
<span class="p_add">+		dev_err(dev, &quot;%s: Failed state! rc=%d\n&quot;, __func__, rc);</span>
<span class="p_add">+		rc = -ENODEV;</span>
<span class="p_add">+		goto out;</span>
<span class="p_add">+	}</span>
 
 	dev_dbg(dev, &quot;%s: reason 0x%016llX rctxid=%016llX\n&quot;,
 		__func__, recover-&gt;reason, rctxid);
<span class="p_header">diff --git a/drivers/scsi/cxlflash/vlun.c b/drivers/scsi/cxlflash/vlun.c</span>
<span class="p_header">index a53f583e2d7b..50f8e9300770 100644</span>
<span class="p_header">--- a/drivers/scsi/cxlflash/vlun.c</span>
<span class="p_header">+++ b/drivers/scsi/cxlflash/vlun.c</span>
<span class="p_chunk">@@ -1008,6 +1008,8 @@</span> <span class="p_context"> int cxlflash_disk_virtual_open(struct scsi_device *sdev, void *arg)</span>
 	virt-&gt;last_lba = last_lba;
 	virt-&gt;rsrc_handle = rsrc_handle;
 
<span class="p_add">+	if (lli-&gt;port_sel == BOTH_PORTS)</span>
<span class="p_add">+		virt-&gt;hdr.return_flags |= DK_CXLFLASH_ALL_PORTS_ACTIVE;</span>
 out:
 	if (likely(ctxi))
 		put_context(ctxi);
<span class="p_header">diff --git a/drivers/scsi/lpfc/lpfc_crtn.h b/drivers/scsi/lpfc/lpfc_crtn.h</span>
<span class="p_header">index b0e6fe46448d..80d3c740a8a8 100644</span>
<span class="p_header">--- a/drivers/scsi/lpfc/lpfc_crtn.h</span>
<span class="p_header">+++ b/drivers/scsi/lpfc/lpfc_crtn.h</span>
<span class="p_chunk">@@ -72,6 +72,7 @@</span> <span class="p_context"> void lpfc_cancel_all_vport_retry_delay_timer(struct lpfc_hba *);</span>
 void lpfc_retry_pport_discovery(struct lpfc_hba *);
 void lpfc_release_rpi(struct lpfc_hba *, struct lpfc_vport *, uint16_t);
 
<span class="p_add">+void lpfc_mbx_cmpl_local_config_link(struct lpfc_hba *, LPFC_MBOXQ_t *);</span>
 void lpfc_mbx_cmpl_reg_login(struct lpfc_hba *, LPFC_MBOXQ_t *);
 void lpfc_mbx_cmpl_dflt_rpi(struct lpfc_hba *, LPFC_MBOXQ_t *);
 void lpfc_mbx_cmpl_fabric_reg_login(struct lpfc_hba *, LPFC_MBOXQ_t *);
<span class="p_header">diff --git a/drivers/scsi/lpfc/lpfc_els.c b/drivers/scsi/lpfc/lpfc_els.c</span>
<span class="p_header">index b6fa257ea3e0..59ced8864b2f 100644</span>
<span class="p_header">--- a/drivers/scsi/lpfc/lpfc_els.c</span>
<span class="p_header">+++ b/drivers/scsi/lpfc/lpfc_els.c</span>
<span class="p_chunk">@@ -455,9 +455,9 @@</span> <span class="p_context"> int</span>
 lpfc_issue_reg_vfi(struct lpfc_vport *vport)
 {
 	struct lpfc_hba  *phba = vport-&gt;phba;
<span class="p_del">-	LPFC_MBOXQ_t *mboxq;</span>
<span class="p_add">+	LPFC_MBOXQ_t *mboxq = NULL;</span>
 	struct lpfc_nodelist *ndlp;
<span class="p_del">-	struct lpfc_dmabuf *dmabuf;</span>
<span class="p_add">+	struct lpfc_dmabuf *dmabuf = NULL;</span>
 	int rc = 0;
 
 	/* move forward in case of SLI4 FC port loopback test and pt2pt mode */
<span class="p_chunk">@@ -471,25 +471,33 @@</span> <span class="p_context"> lpfc_issue_reg_vfi(struct lpfc_vport *vport)</span>
 		}
 	}
 
<span class="p_del">-	dmabuf = kzalloc(sizeof(struct lpfc_dmabuf), GFP_KERNEL);</span>
<span class="p_del">-	if (!dmabuf) {</span>
<span class="p_add">+	mboxq = mempool_alloc(phba-&gt;mbox_mem_pool, GFP_KERNEL);</span>
<span class="p_add">+	if (!mboxq) {</span>
 		rc = -ENOMEM;
 		goto fail;
 	}
<span class="p_del">-	dmabuf-&gt;virt = lpfc_mbuf_alloc(phba, MEM_PRI, &amp;dmabuf-&gt;phys);</span>
<span class="p_del">-	if (!dmabuf-&gt;virt) {</span>
<span class="p_del">-		rc = -ENOMEM;</span>
<span class="p_del">-		goto fail_free_dmabuf;</span>
<span class="p_del">-	}</span>
 
<span class="p_del">-	mboxq = mempool_alloc(phba-&gt;mbox_mem_pool, GFP_KERNEL);</span>
<span class="p_del">-	if (!mboxq) {</span>
<span class="p_del">-		rc = -ENOMEM;</span>
<span class="p_del">-		goto fail_free_coherent;</span>
<span class="p_add">+	/* Supply CSP&#39;s only if we are fabric connect or pt-to-pt connect */</span>
<span class="p_add">+	if ((vport-&gt;fc_flag &amp; FC_FABRIC) || (vport-&gt;fc_flag &amp; FC_PT2PT)) {</span>
<span class="p_add">+		dmabuf = kzalloc(sizeof(struct lpfc_dmabuf), GFP_KERNEL);</span>
<span class="p_add">+		if (!dmabuf) {</span>
<span class="p_add">+			rc = -ENOMEM;</span>
<span class="p_add">+			goto fail;</span>
<span class="p_add">+		}</span>
<span class="p_add">+		dmabuf-&gt;virt = lpfc_mbuf_alloc(phba, MEM_PRI, &amp;dmabuf-&gt;phys);</span>
<span class="p_add">+		if (!dmabuf-&gt;virt) {</span>
<span class="p_add">+			rc = -ENOMEM;</span>
<span class="p_add">+			goto fail;</span>
<span class="p_add">+		}</span>
<span class="p_add">+		memcpy(dmabuf-&gt;virt, &amp;phba-&gt;fc_fabparam,</span>
<span class="p_add">+		       sizeof(struct serv_parm));</span>
 	}
<span class="p_add">+</span>
 	vport-&gt;port_state = LPFC_FABRIC_CFG_LINK;
<span class="p_del">-	memcpy(dmabuf-&gt;virt, &amp;phba-&gt;fc_fabparam, sizeof(vport-&gt;fc_sparam));</span>
<span class="p_del">-	lpfc_reg_vfi(mboxq, vport, dmabuf-&gt;phys);</span>
<span class="p_add">+	if (dmabuf)</span>
<span class="p_add">+		lpfc_reg_vfi(mboxq, vport, dmabuf-&gt;phys);</span>
<span class="p_add">+	else</span>
<span class="p_add">+		lpfc_reg_vfi(mboxq, vport, 0);</span>
 
 	mboxq-&gt;mbox_cmpl = lpfc_mbx_cmpl_reg_vfi;
 	mboxq-&gt;vport = vport;
<span class="p_chunk">@@ -497,17 +505,19 @@</span> <span class="p_context"> lpfc_issue_reg_vfi(struct lpfc_vport *vport)</span>
 	rc = lpfc_sli_issue_mbox(phba, mboxq, MBX_NOWAIT);
 	if (rc == MBX_NOT_FINISHED) {
 		rc = -ENXIO;
<span class="p_del">-		goto fail_free_mbox;</span>
<span class="p_add">+		goto fail;</span>
 	}
 	return 0;
 
<span class="p_del">-fail_free_mbox:</span>
<span class="p_del">-	mempool_free(mboxq, phba-&gt;mbox_mem_pool);</span>
<span class="p_del">-fail_free_coherent:</span>
<span class="p_del">-	lpfc_mbuf_free(phba, dmabuf-&gt;virt, dmabuf-&gt;phys);</span>
<span class="p_del">-fail_free_dmabuf:</span>
<span class="p_del">-	kfree(dmabuf);</span>
 fail:
<span class="p_add">+	if (mboxq)</span>
<span class="p_add">+		mempool_free(mboxq, phba-&gt;mbox_mem_pool);</span>
<span class="p_add">+	if (dmabuf) {</span>
<span class="p_add">+		if (dmabuf-&gt;virt)</span>
<span class="p_add">+			lpfc_mbuf_free(phba, dmabuf-&gt;virt, dmabuf-&gt;phys);</span>
<span class="p_add">+		kfree(dmabuf);</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
 	lpfc_vport_set_state(vport, FC_VPORT_FAILED);
 	lpfc_printf_vlog(vport, KERN_ERR, LOG_ELS,
 		&quot;0289 Issue Register VFI failed: Err %d\n&quot;, rc);
<span class="p_chunk">@@ -711,9 +721,10 @@</span> <span class="p_context"> lpfc_cmpl_els_flogi_fabric(struct lpfc_vport *vport, struct lpfc_nodelist *ndlp,</span>
 	 * For FC we need to do some special processing because of the SLI
 	 * Port&#39;s default settings of the Common Service Parameters.
 	 */
<span class="p_del">-	if (phba-&gt;sli4_hba.lnk_info.lnk_tp == LPFC_LNK_TYPE_FC) {</span>
<span class="p_add">+	if ((phba-&gt;sli_rev == LPFC_SLI_REV4) &amp;&amp;</span>
<span class="p_add">+	    (phba-&gt;sli4_hba.lnk_info.lnk_tp == LPFC_LNK_TYPE_FC)) {</span>
 		/* If physical FC port changed, unreg VFI and ALL VPIs / RPIs */
<span class="p_del">-		if ((phba-&gt;sli_rev == LPFC_SLI_REV4) &amp;&amp; fabric_param_changed)</span>
<span class="p_add">+		if (fabric_param_changed)</span>
 			lpfc_unregister_fcf_prep(phba);
 
 		/* This should just update the VFI CSPs*/
<span class="p_chunk">@@ -824,13 +835,21 @@</span> <span class="p_context"> lpfc_cmpl_els_flogi_nport(struct lpfc_vport *vport, struct lpfc_nodelist *ndlp,</span>
 
 	spin_lock_irq(shost-&gt;host_lock);
 	vport-&gt;fc_flag &amp;= ~(FC_FABRIC | FC_PUBLIC_LOOP);
<span class="p_add">+	vport-&gt;fc_flag |= FC_PT2PT;</span>
 	spin_unlock_irq(shost-&gt;host_lock);
 
<span class="p_del">-	phba-&gt;fc_edtov = FF_DEF_EDTOV;</span>
<span class="p_del">-	phba-&gt;fc_ratov = FF_DEF_RATOV;</span>
<span class="p_add">+	/* If physical FC port changed, unreg VFI and ALL VPIs / RPIs */</span>
<span class="p_add">+	if ((phba-&gt;sli_rev == LPFC_SLI_REV4) &amp;&amp; phba-&gt;fc_topology_changed) {</span>
<span class="p_add">+		lpfc_unregister_fcf_prep(phba);</span>
<span class="p_add">+</span>
<span class="p_add">+		spin_lock_irq(shost-&gt;host_lock);</span>
<span class="p_add">+		vport-&gt;fc_flag &amp;= ~FC_VFI_REGISTERED;</span>
<span class="p_add">+		spin_unlock_irq(shost-&gt;host_lock);</span>
<span class="p_add">+		phba-&gt;fc_topology_changed = 0;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
 	rc = memcmp(&amp;vport-&gt;fc_portname, &amp;sp-&gt;portName,
 		    sizeof(vport-&gt;fc_portname));
<span class="p_del">-	memcpy(&amp;phba-&gt;fc_fabparam, sp, sizeof(struct serv_parm));</span>
 
 	if (rc &gt;= 0) {
 		/* This side will initiate the PLOGI */
<span class="p_chunk">@@ -839,38 +858,14 @@</span> <span class="p_context"> lpfc_cmpl_els_flogi_nport(struct lpfc_vport *vport, struct lpfc_nodelist *ndlp,</span>
 		spin_unlock_irq(shost-&gt;host_lock);
 
 		/*
<span class="p_del">-		 * N_Port ID cannot be 0, set our to LocalID the other</span>
<span class="p_del">-		 * side will be RemoteID.</span>
<span class="p_add">+		 * N_Port ID cannot be 0, set our Id to LocalID</span>
<span class="p_add">+		 * the other side will be RemoteID.</span>
 		 */
 
 		/* not equal */
 		if (rc)
 			vport-&gt;fc_myDID = PT2PT_LocalID;
 
<span class="p_del">-		mbox = mempool_alloc(phba-&gt;mbox_mem_pool, GFP_KERNEL);</span>
<span class="p_del">-		if (!mbox)</span>
<span class="p_del">-			goto fail;</span>
<span class="p_del">-</span>
<span class="p_del">-		lpfc_config_link(phba, mbox);</span>
<span class="p_del">-</span>
<span class="p_del">-		mbox-&gt;mbox_cmpl = lpfc_sli_def_mbox_cmpl;</span>
<span class="p_del">-		mbox-&gt;vport = vport;</span>
<span class="p_del">-		rc = lpfc_sli_issue_mbox(phba, mbox, MBX_NOWAIT);</span>
<span class="p_del">-		if (rc == MBX_NOT_FINISHED) {</span>
<span class="p_del">-			mempool_free(mbox, phba-&gt;mbox_mem_pool);</span>
<span class="p_del">-			goto fail;</span>
<span class="p_del">-		}</span>
<span class="p_del">-</span>
<span class="p_del">-		/*</span>
<span class="p_del">-		 * For SLI4, the VFI/VPI are registered AFTER the</span>
<span class="p_del">-		 * Nport with the higher WWPN sends the PLOGI with</span>
<span class="p_del">-		 * an assigned NPortId.</span>
<span class="p_del">-		 */</span>
<span class="p_del">-</span>
<span class="p_del">-		/* not equal */</span>
<span class="p_del">-		if ((phba-&gt;sli_rev == LPFC_SLI_REV4) &amp;&amp; rc)</span>
<span class="p_del">-			lpfc_issue_reg_vfi(vport);</span>
<span class="p_del">-</span>
 		/* Decrement ndlp reference count indicating that ndlp can be
 		 * safely released when other references to it are done.
 		 */
<span class="p_chunk">@@ -912,29 +907,20 @@</span> <span class="p_context"> lpfc_cmpl_els_flogi_nport(struct lpfc_vport *vport, struct lpfc_nodelist *ndlp,</span>
 	/* If we are pt2pt with another NPort, force NPIV off! */
 	phba-&gt;sli3_options &amp;= ~LPFC_SLI3_NPIV_ENABLED;
 
<span class="p_del">-	spin_lock_irq(shost-&gt;host_lock);</span>
<span class="p_del">-	vport-&gt;fc_flag |= FC_PT2PT;</span>
<span class="p_del">-	spin_unlock_irq(shost-&gt;host_lock);</span>
<span class="p_del">-	/* If physical FC port changed, unreg VFI and ALL VPIs / RPIs */</span>
<span class="p_del">-	if ((phba-&gt;sli_rev == LPFC_SLI_REV4) &amp;&amp; phba-&gt;fc_topology_changed) {</span>
<span class="p_del">-		lpfc_unregister_fcf_prep(phba);</span>
<span class="p_add">+	mbox = mempool_alloc(phba-&gt;mbox_mem_pool, GFP_KERNEL);</span>
<span class="p_add">+	if (!mbox)</span>
<span class="p_add">+		goto fail;</span>
 
<span class="p_del">-		/* The FC_VFI_REGISTERED flag will get clear in the cmpl</span>
<span class="p_del">-		 * handler for unreg_vfi, but if we don&#39;t force the</span>
<span class="p_del">-		 * FC_VFI_REGISTERED flag then the reg_vfi mailbox could be</span>
<span class="p_del">-		 * built with the update bit set instead of just the vp bit to</span>
<span class="p_del">-		 * change the Nport ID.  We need to have the vp set and the</span>
<span class="p_del">-		 * Upd cleared on topology changes.</span>
<span class="p_del">-		 */</span>
<span class="p_del">-		spin_lock_irq(shost-&gt;host_lock);</span>
<span class="p_del">-		vport-&gt;fc_flag &amp;= ~FC_VFI_REGISTERED;</span>
<span class="p_del">-		spin_unlock_irq(shost-&gt;host_lock);</span>
<span class="p_del">-		phba-&gt;fc_topology_changed = 0;</span>
<span class="p_del">-		lpfc_issue_reg_vfi(vport);</span>
<span class="p_add">+	lpfc_config_link(phba, mbox);</span>
<span class="p_add">+</span>
<span class="p_add">+	mbox-&gt;mbox_cmpl = lpfc_mbx_cmpl_local_config_link;</span>
<span class="p_add">+	mbox-&gt;vport = vport;</span>
<span class="p_add">+	rc = lpfc_sli_issue_mbox(phba, mbox, MBX_NOWAIT);</span>
<span class="p_add">+	if (rc == MBX_NOT_FINISHED) {</span>
<span class="p_add">+		mempool_free(mbox, phba-&gt;mbox_mem_pool);</span>
<span class="p_add">+		goto fail;</span>
 	}
 
<span class="p_del">-	/* Start discovery - this should just do CLEAR_LA */</span>
<span class="p_del">-	lpfc_disc_start(vport);</span>
 	return 0;
 fail:
 	return -ENXIO;
<span class="p_chunk">@@ -1157,6 +1143,7 @@</span> <span class="p_context"> flogifail:</span>
 	spin_lock_irq(&amp;phba-&gt;hbalock);
 	phba-&gt;fcf.fcf_flag &amp;= ~FCF_DISCOVERY;
 	spin_unlock_irq(&amp;phba-&gt;hbalock);
<span class="p_add">+</span>
 	lpfc_nlp_put(ndlp);
 
 	if (!lpfc_error_lost_link(irsp)) {
<span class="p_chunk">@@ -3792,14 +3779,17 @@</span> <span class="p_context"> lpfc_cmpl_els_rsp(struct lpfc_hba *phba, struct lpfc_iocbq *cmdiocb,</span>
 				lpfc_nlp_set_state(vport, ndlp,
 					   NLP_STE_REG_LOGIN_ISSUE);
 			}
<span class="p_add">+</span>
<span class="p_add">+			ndlp-&gt;nlp_flag |= NLP_REG_LOGIN_SEND;</span>
 			if (lpfc_sli_issue_mbox(phba, mbox, MBX_NOWAIT)
 			    != MBX_NOT_FINISHED)
 				goto out;
<span class="p_del">-			else</span>
<span class="p_del">-				/* Decrement the ndlp reference count we</span>
<span class="p_del">-				 * set for this failed mailbox command.</span>
<span class="p_del">-				 */</span>
<span class="p_del">-				lpfc_nlp_put(ndlp);</span>
<span class="p_add">+</span>
<span class="p_add">+			/* Decrement the ndlp reference count we</span>
<span class="p_add">+			 * set for this failed mailbox command.</span>
<span class="p_add">+			 */</span>
<span class="p_add">+			lpfc_nlp_put(ndlp);</span>
<span class="p_add">+			ndlp-&gt;nlp_flag &amp;= ~NLP_REG_LOGIN_SEND;</span>
 
 			/* ELS rsp: Cannot issue reg_login for &lt;NPortid&gt; */
 			lpfc_printf_vlog(vport, KERN_ERR, LOG_ELS,
<span class="p_chunk">@@ -3856,6 +3846,7 @@</span> <span class="p_context"> out:</span>
 				 * the routine lpfc_els_free_iocb.
 				 */
 				cmdiocb-&gt;context1 = NULL;
<span class="p_add">+</span>
 	}
 
 	lpfc_els_free_iocb(phba, cmdiocb);
<span class="p_chunk">@@ -3898,6 +3889,7 @@</span> <span class="p_context"> lpfc_els_rsp_acc(struct lpfc_vport *vport, uint32_t flag,</span>
 	IOCB_t *oldcmd;
 	struct lpfc_iocbq *elsiocb;
 	uint8_t *pcmd;
<span class="p_add">+	struct serv_parm *sp;</span>
 	uint16_t cmdsize;
 	int rc;
 	ELS_PKT *els_pkt_ptr;
<span class="p_chunk">@@ -3927,6 +3919,7 @@</span> <span class="p_context"> lpfc_els_rsp_acc(struct lpfc_vport *vport, uint32_t flag,</span>
 			&quot;Issue ACC:       did:x%x flg:x%x&quot;,
 			ndlp-&gt;nlp_DID, ndlp-&gt;nlp_flag, 0);
 		break;
<span class="p_add">+	case ELS_CMD_FLOGI:</span>
 	case ELS_CMD_PLOGI:
 		cmdsize = (sizeof(struct serv_parm) + sizeof(uint32_t));
 		elsiocb = lpfc_prep_els_iocb(vport, 0, cmdsize, oldiocb-&gt;retry,
<span class="p_chunk">@@ -3944,10 +3937,34 @@</span> <span class="p_context"> lpfc_els_rsp_acc(struct lpfc_vport *vport, uint32_t flag,</span>
 
 		*((uint32_t *) (pcmd)) = ELS_CMD_ACC;
 		pcmd += sizeof(uint32_t);
<span class="p_del">-		memcpy(pcmd, &amp;vport-&gt;fc_sparam, sizeof(struct serv_parm));</span>
<span class="p_add">+		sp = (struct serv_parm *)pcmd;</span>
<span class="p_add">+</span>
<span class="p_add">+		if (flag == ELS_CMD_FLOGI) {</span>
<span class="p_add">+			/* Copy the received service parameters back */</span>
<span class="p_add">+			memcpy(sp, &amp;phba-&gt;fc_fabparam,</span>
<span class="p_add">+			       sizeof(struct serv_parm));</span>
<span class="p_add">+</span>
<span class="p_add">+			/* Clear the F_Port bit */</span>
<span class="p_add">+			sp-&gt;cmn.fPort = 0;</span>
<span class="p_add">+</span>
<span class="p_add">+			/* Mark all class service parameters as invalid */</span>
<span class="p_add">+			sp-&gt;cls1.classValid = 0;</span>
<span class="p_add">+			sp-&gt;cls2.classValid = 0;</span>
<span class="p_add">+			sp-&gt;cls3.classValid = 0;</span>
<span class="p_add">+			sp-&gt;cls4.classValid = 0;</span>
<span class="p_add">+</span>
<span class="p_add">+			/* Copy our worldwide names */</span>
<span class="p_add">+			memcpy(&amp;sp-&gt;portName, &amp;vport-&gt;fc_sparam.portName,</span>
<span class="p_add">+			       sizeof(struct lpfc_name));</span>
<span class="p_add">+			memcpy(&amp;sp-&gt;nodeName, &amp;vport-&gt;fc_sparam.nodeName,</span>
<span class="p_add">+			       sizeof(struct lpfc_name));</span>
<span class="p_add">+		} else {</span>
<span class="p_add">+			memcpy(pcmd, &amp;vport-&gt;fc_sparam,</span>
<span class="p_add">+			       sizeof(struct serv_parm));</span>
<span class="p_add">+		}</span>
 
 		lpfc_debugfs_disc_trc(vport, LPFC_DISC_TRC_ELS_RSP,
<span class="p_del">-			&quot;Issue ACC PLOGI: did:x%x flg:x%x&quot;,</span>
<span class="p_add">+			&quot;Issue ACC FLOGI/PLOGI: did:x%x flg:x%x&quot;,</span>
 			ndlp-&gt;nlp_DID, ndlp-&gt;nlp_flag, 0);
 		break;
 	case ELS_CMD_PRLO:
<span class="p_chunk">@@ -4681,28 +4698,25 @@</span> <span class="p_context"> lpfc_rdp_res_speed(struct fc_rdp_port_speed_desc *desc, struct lpfc_hba *phba)</span>
 
 	desc-&gt;tag = cpu_to_be32(RDP_PORT_SPEED_DESC_TAG);
 
<span class="p_del">-	switch (phba-&gt;sli4_hba.link_state.speed) {</span>
<span class="p_del">-	case LPFC_FC_LA_SPEED_1G:</span>
<span class="p_add">+	switch (phba-&gt;fc_linkspeed) {</span>
<span class="p_add">+	case LPFC_LINK_SPEED_1GHZ:</span>
 		rdp_speed = RDP_PS_1GB;
 		break;
<span class="p_del">-	case LPFC_FC_LA_SPEED_2G:</span>
<span class="p_add">+	case LPFC_LINK_SPEED_2GHZ:</span>
 		rdp_speed = RDP_PS_2GB;
 		break;
<span class="p_del">-	case LPFC_FC_LA_SPEED_4G:</span>
<span class="p_add">+	case LPFC_LINK_SPEED_4GHZ:</span>
 		rdp_speed = RDP_PS_4GB;
 		break;
<span class="p_del">-	case LPFC_FC_LA_SPEED_8G:</span>
<span class="p_add">+	case LPFC_LINK_SPEED_8GHZ:</span>
 		rdp_speed = RDP_PS_8GB;
 		break;
<span class="p_del">-	case LPFC_FC_LA_SPEED_10G:</span>
<span class="p_add">+	case LPFC_LINK_SPEED_10GHZ:</span>
 		rdp_speed = RDP_PS_10GB;
 		break;
<span class="p_del">-	case LPFC_FC_LA_SPEED_16G:</span>
<span class="p_add">+	case LPFC_LINK_SPEED_16GHZ:</span>
 		rdp_speed = RDP_PS_16GB;
 		break;
<span class="p_del">-	case LPFC_FC_LA_SPEED_32G:</span>
<span class="p_del">-		rdp_speed = RDP_PS_32GB;</span>
<span class="p_del">-		break;</span>
 	default:
 		rdp_speed = RDP_PS_UNKNOWN;
 		break;
<span class="p_chunk">@@ -5739,7 +5753,6 @@</span> <span class="p_context"> lpfc_els_rcv_flogi(struct lpfc_vport *vport, struct lpfc_iocbq *cmdiocb,</span>
 	IOCB_t *icmd = &amp;cmdiocb-&gt;iocb;
 	struct serv_parm *sp;
 	LPFC_MBOXQ_t *mbox;
<span class="p_del">-	struct ls_rjt stat;</span>
 	uint32_t cmd, did;
 	int rc;
 	uint32_t fc_flag = 0;
<span class="p_chunk">@@ -5765,135 +5778,92 @@</span> <span class="p_context"> lpfc_els_rcv_flogi(struct lpfc_vport *vport, struct lpfc_iocbq *cmdiocb,</span>
 		return 1;
 	}
 
<span class="p_del">-	if ((lpfc_check_sparm(vport, ndlp, sp, CLASS3, 1))) {</span>
<span class="p_del">-		/* For a FLOGI we accept, then if our portname is greater</span>
<span class="p_del">-		 * then the remote portname we initiate Nport login.</span>
<span class="p_del">-		 */</span>
<span class="p_add">+	(void) lpfc_check_sparm(vport, ndlp, sp, CLASS3, 1);</span>
 
<span class="p_del">-		rc = memcmp(&amp;vport-&gt;fc_portname, &amp;sp-&gt;portName,</span>
<span class="p_del">-			    sizeof(struct lpfc_name));</span>
 
<span class="p_del">-		if (!rc) {</span>
<span class="p_del">-			if (phba-&gt;sli_rev &lt; LPFC_SLI_REV4) {</span>
<span class="p_del">-				mbox = mempool_alloc(phba-&gt;mbox_mem_pool,</span>
<span class="p_del">-						     GFP_KERNEL);</span>
<span class="p_del">-				if (!mbox)</span>
<span class="p_del">-					return 1;</span>
<span class="p_del">-				lpfc_linkdown(phba);</span>
<span class="p_del">-				lpfc_init_link(phba, mbox,</span>
<span class="p_del">-					       phba-&gt;cfg_topology,</span>
<span class="p_del">-					       phba-&gt;cfg_link_speed);</span>
<span class="p_del">-				mbox-&gt;u.mb.un.varInitLnk.lipsr_AL_PA = 0;</span>
<span class="p_del">-				mbox-&gt;mbox_cmpl = lpfc_sli_def_mbox_cmpl;</span>
<span class="p_del">-				mbox-&gt;vport = vport;</span>
<span class="p_del">-				rc = lpfc_sli_issue_mbox(phba, mbox,</span>
<span class="p_del">-							 MBX_NOWAIT);</span>
<span class="p_del">-				lpfc_set_loopback_flag(phba);</span>
<span class="p_del">-				if (rc == MBX_NOT_FINISHED)</span>
<span class="p_del">-					mempool_free(mbox, phba-&gt;mbox_mem_pool);</span>
<span class="p_del">-				return 1;</span>
<span class="p_del">-			} else {</span>
<span class="p_del">-				/* abort the flogi coming back to ourselves</span>
<span class="p_del">-				 * due to external loopback on the port.</span>
<span class="p_del">-				 */</span>
<span class="p_del">-				lpfc_els_abort_flogi(phba);</span>
<span class="p_del">-				return 0;</span>
<span class="p_del">-			}</span>
<span class="p_del">-		} else if (rc &gt; 0) {	/* greater than */</span>
<span class="p_del">-			spin_lock_irq(shost-&gt;host_lock);</span>
<span class="p_del">-			vport-&gt;fc_flag |= FC_PT2PT_PLOGI;</span>
<span class="p_del">-			spin_unlock_irq(shost-&gt;host_lock);</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * If our portname is greater than the remote portname,</span>
<span class="p_add">+	 * then we initiate Nport login.</span>
<span class="p_add">+	 */</span>
 
<span class="p_del">-			/* If we have the high WWPN we can assign our own</span>
<span class="p_del">-			 * myDID; otherwise, we have to WAIT for a PLOGI</span>
<span class="p_del">-			 * from the remote NPort to find out what it</span>
<span class="p_del">-			 * will be.</span>
<span class="p_del">-			 */</span>
<span class="p_del">-			vport-&gt;fc_myDID = PT2PT_LocalID;</span>
<span class="p_del">-		} else</span>
<span class="p_del">-			vport-&gt;fc_myDID = PT2PT_RemoteID;</span>
<span class="p_add">+	rc = memcmp(&amp;vport-&gt;fc_portname, &amp;sp-&gt;portName,</span>
<span class="p_add">+		    sizeof(struct lpfc_name));</span>
 
<span class="p_del">-		/*</span>
<span class="p_del">-		 * The vport state should go to LPFC_FLOGI only</span>
<span class="p_del">-		 * AFTER we issue a FLOGI, not receive one.</span>
<span class="p_add">+	if (!rc) {</span>
<span class="p_add">+		if (phba-&gt;sli_rev &lt; LPFC_SLI_REV4) {</span>
<span class="p_add">+			mbox = mempool_alloc(phba-&gt;mbox_mem_pool,</span>
<span class="p_add">+					     GFP_KERNEL);</span>
<span class="p_add">+			if (!mbox)</span>
<span class="p_add">+				return 1;</span>
<span class="p_add">+			lpfc_linkdown(phba);</span>
<span class="p_add">+			lpfc_init_link(phba, mbox,</span>
<span class="p_add">+				       phba-&gt;cfg_topology,</span>
<span class="p_add">+				       phba-&gt;cfg_link_speed);</span>
<span class="p_add">+			mbox-&gt;u.mb.un.varInitLnk.lipsr_AL_PA = 0;</span>
<span class="p_add">+			mbox-&gt;mbox_cmpl = lpfc_sli_def_mbox_cmpl;</span>
<span class="p_add">+			mbox-&gt;vport = vport;</span>
<span class="p_add">+			rc = lpfc_sli_issue_mbox(phba, mbox,</span>
<span class="p_add">+						 MBX_NOWAIT);</span>
<span class="p_add">+			lpfc_set_loopback_flag(phba);</span>
<span class="p_add">+			if (rc == MBX_NOT_FINISHED)</span>
<span class="p_add">+				mempool_free(mbox, phba-&gt;mbox_mem_pool);</span>
<span class="p_add">+			return 1;</span>
<span class="p_add">+		}</span>
<span class="p_add">+</span>
<span class="p_add">+		/* abort the flogi coming back to ourselves</span>
<span class="p_add">+		 * due to external loopback on the port.</span>
 		 */
<span class="p_add">+		lpfc_els_abort_flogi(phba);</span>
<span class="p_add">+		return 0;</span>
<span class="p_add">+</span>
<span class="p_add">+	} else if (rc &gt; 0) {	/* greater than */</span>
 		spin_lock_irq(shost-&gt;host_lock);
<span class="p_del">-		fc_flag = vport-&gt;fc_flag;</span>
<span class="p_del">-		port_state = vport-&gt;port_state;</span>
<span class="p_del">-		vport-&gt;fc_flag |= FC_PT2PT;</span>
<span class="p_del">-		vport-&gt;fc_flag &amp;= ~(FC_FABRIC | FC_PUBLIC_LOOP);</span>
<span class="p_add">+		vport-&gt;fc_flag |= FC_PT2PT_PLOGI;</span>
 		spin_unlock_irq(shost-&gt;host_lock);
<span class="p_del">-		lpfc_printf_vlog(vport, KERN_INFO, LOG_ELS,</span>
<span class="p_del">-				 &quot;3311 Rcv Flogi PS x%x new PS x%x &quot;</span>
<span class="p_del">-				 &quot;fc_flag x%x new fc_flag x%x\n&quot;,</span>
<span class="p_del">-				 port_state, vport-&gt;port_state,</span>
<span class="p_del">-				 fc_flag, vport-&gt;fc_flag);</span>
 
<span class="p_del">-		/*</span>
<span class="p_del">-		 * We temporarily set fc_myDID to make it look like we are</span>
<span class="p_del">-		 * a Fabric. This is done just so we end up with the right</span>
<span class="p_del">-		 * did / sid on the FLOGI ACC rsp.</span>
<span class="p_add">+		/* If we have the high WWPN we can assign our own</span>
<span class="p_add">+		 * myDID; otherwise, we have to WAIT for a PLOGI</span>
<span class="p_add">+		 * from the remote NPort to find out what it</span>
<span class="p_add">+		 * will be.</span>
 		 */
<span class="p_del">-		did = vport-&gt;fc_myDID;</span>
<span class="p_del">-		vport-&gt;fc_myDID = Fabric_DID;</span>
<span class="p_del">-</span>
<span class="p_add">+		vport-&gt;fc_myDID = PT2PT_LocalID;</span>
 	} else {
<span class="p_del">-		/* Reject this request because invalid parameters */</span>
<span class="p_del">-		stat.un.b.lsRjtRsvd0 = 0;</span>
<span class="p_del">-		stat.un.b.lsRjtRsnCode = LSRJT_UNABLE_TPC;</span>
<span class="p_del">-		stat.un.b.lsRjtRsnCodeExp = LSEXP_SPARM_OPTIONS;</span>
<span class="p_del">-		stat.un.b.vendorUnique = 0;</span>
<span class="p_del">-</span>
<span class="p_del">-		/*</span>
<span class="p_del">-		 * We temporarily set fc_myDID to make it look like we are</span>
<span class="p_del">-		 * a Fabric. This is done just so we end up with the right</span>
<span class="p_del">-		 * did / sid on the FLOGI LS_RJT rsp.</span>
<span class="p_del">-		 */</span>
<span class="p_del">-		did = vport-&gt;fc_myDID;</span>
<span class="p_del">-		vport-&gt;fc_myDID = Fabric_DID;</span>
<span class="p_del">-</span>
<span class="p_del">-		lpfc_els_rsp_reject(vport, stat.un.lsRjtError, cmdiocb, ndlp,</span>
<span class="p_del">-			NULL);</span>
<span class="p_add">+		vport-&gt;fc_myDID = PT2PT_RemoteID;</span>
<span class="p_add">+	}</span>
 
<span class="p_del">-		/* Now lets put fc_myDID back to what its supposed to be */</span>
<span class="p_del">-		vport-&gt;fc_myDID = did;</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * The vport state should go to LPFC_FLOGI only</span>
<span class="p_add">+	 * AFTER we issue a FLOGI, not receive one.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	spin_lock_irq(shost-&gt;host_lock);</span>
<span class="p_add">+	fc_flag = vport-&gt;fc_flag;</span>
<span class="p_add">+	port_state = vport-&gt;port_state;</span>
<span class="p_add">+	vport-&gt;fc_flag |= FC_PT2PT;</span>
<span class="p_add">+	vport-&gt;fc_flag &amp;= ~(FC_FABRIC | FC_PUBLIC_LOOP);</span>
<span class="p_add">+	spin_unlock_irq(shost-&gt;host_lock);</span>
<span class="p_add">+	lpfc_printf_vlog(vport, KERN_INFO, LOG_ELS,</span>
<span class="p_add">+			 &quot;3311 Rcv Flogi PS x%x new PS x%x &quot;</span>
<span class="p_add">+			 &quot;fc_flag x%x new fc_flag x%x\n&quot;,</span>
<span class="p_add">+			 port_state, vport-&gt;port_state,</span>
<span class="p_add">+			 fc_flag, vport-&gt;fc_flag);</span>
 
<span class="p_del">-		return 1;</span>
<span class="p_del">-	}</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * We temporarily set fc_myDID to make it look like we are</span>
<span class="p_add">+	 * a Fabric. This is done just so we end up with the right</span>
<span class="p_add">+	 * did / sid on the FLOGI ACC rsp.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	did = vport-&gt;fc_myDID;</span>
<span class="p_add">+	vport-&gt;fc_myDID = Fabric_DID;</span>
 
<span class="p_del">-	/* send our FLOGI first */</span>
<span class="p_del">-	if (vport-&gt;port_state &lt; LPFC_FLOGI) {</span>
<span class="p_del">-		vport-&gt;fc_myDID = 0;</span>
<span class="p_del">-		lpfc_initial_flogi(vport);</span>
<span class="p_del">-		vport-&gt;fc_myDID = Fabric_DID;</span>
<span class="p_del">-	}</span>
<span class="p_add">+	memcpy(&amp;phba-&gt;fc_fabparam, sp, sizeof(struct serv_parm));</span>
 
 	/* Send back ACC */
<span class="p_del">-	lpfc_els_rsp_acc(vport, ELS_CMD_PLOGI, cmdiocb, ndlp, NULL);</span>
<span class="p_add">+	lpfc_els_rsp_acc(vport, ELS_CMD_FLOGI, cmdiocb, ndlp, NULL);</span>
 
 	/* Now lets put fc_myDID back to what its supposed to be */
 	vport-&gt;fc_myDID = did;
 
<span class="p_del">-	if (!(vport-&gt;fc_flag &amp; FC_PT2PT_PLOGI)) {</span>
<span class="p_del">-</span>
<span class="p_del">-		mbox = mempool_alloc(phba-&gt;mbox_mem_pool, GFP_KERNEL);</span>
<span class="p_del">-		if (!mbox)</span>
<span class="p_del">-			goto fail;</span>
<span class="p_del">-</span>
<span class="p_del">-		lpfc_config_link(phba, mbox);</span>
<span class="p_del">-</span>
<span class="p_del">-		mbox-&gt;mbox_cmpl = lpfc_sli_def_mbox_cmpl;</span>
<span class="p_del">-		mbox-&gt;vport = vport;</span>
<span class="p_del">-		rc = lpfc_sli_issue_mbox(phba, mbox, MBX_NOWAIT);</span>
<span class="p_del">-		if (rc == MBX_NOT_FINISHED) {</span>
<span class="p_del">-			mempool_free(mbox, phba-&gt;mbox_mem_pool);</span>
<span class="p_del">-			goto fail;</span>
<span class="p_del">-		}</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
 	return 0;
<span class="p_del">-fail:</span>
<span class="p_del">-	return 1;</span>
 }
 
 /**
<span class="p_chunk">@@ -7345,7 +7315,7 @@</span> <span class="p_context"> lpfc_els_unsol_buffer(struct lpfc_hba *phba, struct lpfc_sli_ring *pring,</span>
 
 	/* reject till our FLOGI completes */
 	if ((vport-&gt;port_state &lt; LPFC_FABRIC_CFG_LINK) &amp;&amp;
<span class="p_del">-		(cmd != ELS_CMD_FLOGI)) {</span>
<span class="p_add">+	    (cmd != ELS_CMD_FLOGI)) {</span>
 		rjt_err = LSRJT_UNABLE_TPC;
 		rjt_exp = LSEXP_NOTHING_MORE;
 		goto lsrjt;
<span class="p_chunk">@@ -7381,6 +7351,7 @@</span> <span class="p_context"> lpfc_els_unsol_buffer(struct lpfc_hba *phba, struct lpfc_sli_ring *pring,</span>
 			rjt_exp = LSEXP_NOTHING_MORE;
 			break;
 		}
<span class="p_add">+</span>
 		if (vport-&gt;port_state &lt; LPFC_DISC_AUTH) {
 			if (!(phba-&gt;pport-&gt;fc_flag &amp; FC_PT2PT) ||
 				(phba-&gt;pport-&gt;fc_flag &amp; FC_PT2PT_PLOGI)) {
<span class="p_header">diff --git a/drivers/scsi/lpfc/lpfc_hbadisc.c b/drivers/scsi/lpfc/lpfc_hbadisc.c</span>
<span class="p_header">index bfc2442dd74a..d3668aa555d5 100644</span>
<span class="p_header">--- a/drivers/scsi/lpfc/lpfc_hbadisc.c</span>
<span class="p_header">+++ b/drivers/scsi/lpfc/lpfc_hbadisc.c</span>
<span class="p_chunk">@@ -1083,7 +1083,7 @@</span> <span class="p_context"> out:</span>
 }
 
 
<span class="p_del">-static void</span>
<span class="p_add">+void</span>
 lpfc_mbx_cmpl_local_config_link(struct lpfc_hba *phba, LPFC_MBOXQ_t *pmb)
 {
 	struct lpfc_vport *vport = pmb-&gt;vport;
<span class="p_chunk">@@ -1113,8 +1113,10 @@</span> <span class="p_context"> lpfc_mbx_cmpl_local_config_link(struct lpfc_hba *phba, LPFC_MBOXQ_t *pmb)</span>
 	/* Start discovery by sending a FLOGI. port_state is identically
 	 * LPFC_FLOGI while waiting for FLOGI cmpl
 	 */
<span class="p_del">-	if (vport-&gt;port_state != LPFC_FLOGI || vport-&gt;fc_flag &amp; FC_PT2PT_PLOGI)</span>
<span class="p_add">+	if (vport-&gt;port_state != LPFC_FLOGI)</span>
 		lpfc_initial_flogi(vport);
<span class="p_add">+	else if (vport-&gt;fc_flag &amp; FC_PT2PT)</span>
<span class="p_add">+		lpfc_disc_start(vport);</span>
 	return;
 
 out:
<span class="p_chunk">@@ -2963,8 +2965,10 @@</span> <span class="p_context"> lpfc_mbx_cmpl_reg_vfi(struct lpfc_hba *phba, LPFC_MBOXQ_t *mboxq)</span>
 
 out_free_mem:
 	mempool_free(mboxq, phba-&gt;mbox_mem_pool);
<span class="p_del">-	lpfc_mbuf_free(phba, dmabuf-&gt;virt, dmabuf-&gt;phys);</span>
<span class="p_del">-	kfree(dmabuf);</span>
<span class="p_add">+	if (dmabuf) {</span>
<span class="p_add">+		lpfc_mbuf_free(phba, dmabuf-&gt;virt, dmabuf-&gt;phys);</span>
<span class="p_add">+		kfree(dmabuf);</span>
<span class="p_add">+	}</span>
 	return;
 }
 
<span class="p_chunk">@@ -3448,10 +3452,10 @@</span> <span class="p_context"> lpfc_mbx_cmpl_reg_login(struct lpfc_hba *phba, LPFC_MBOXQ_t *pmb)</span>
 		spin_lock_irq(shost-&gt;host_lock);
 		ndlp-&gt;nlp_flag &amp;= ~NLP_IGNR_REG_CMPL;
 		spin_unlock_irq(shost-&gt;host_lock);
<span class="p_del">-	} else</span>
<span class="p_del">-		/* Good status, call state machine */</span>
<span class="p_del">-		lpfc_disc_state_machine(vport, ndlp, pmb,</span>
<span class="p_del">-				NLP_EVT_CMPL_REG_LOGIN);</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	/* Call state machine */</span>
<span class="p_add">+	lpfc_disc_state_machine(vport, ndlp, pmb, NLP_EVT_CMPL_REG_LOGIN);</span>
 
 	lpfc_mbuf_free(phba, mp-&gt;virt, mp-&gt;phys);
 	kfree(mp);
<span class="p_header">diff --git a/drivers/scsi/lpfc/lpfc_init.c b/drivers/scsi/lpfc/lpfc_init.c</span>
<span class="p_header">index b0d92b84bcdc..c14ab6c3ae40 100644</span>
<span class="p_header">--- a/drivers/scsi/lpfc/lpfc_init.c</span>
<span class="p_header">+++ b/drivers/scsi/lpfc/lpfc_init.c</span>
<span class="p_chunk">@@ -8834,9 +8834,12 @@</span> <span class="p_context"> found:</span>
 				 * already mapped to this phys_id.
 				 */
 				if (cpup-&gt;irq != LPFC_VECTOR_MAP_EMPTY) {
<span class="p_del">-					chann[saved_chann] =</span>
<span class="p_del">-						cpup-&gt;channel_id;</span>
<span class="p_del">-					saved_chann++;</span>
<span class="p_add">+					if (saved_chann &lt;=</span>
<span class="p_add">+					    LPFC_FCP_IO_CHAN_MAX) {</span>
<span class="p_add">+						chann[saved_chann] =</span>
<span class="p_add">+							cpup-&gt;channel_id;</span>
<span class="p_add">+						saved_chann++;</span>
<span class="p_add">+					}</span>
 					goto out;
 				}
 
<span class="p_header">diff --git a/drivers/scsi/lpfc/lpfc_mbox.c b/drivers/scsi/lpfc/lpfc_mbox.c</span>
<span class="p_header">index f87f90e9b7df..1e34b5408a29 100644</span>
<span class="p_header">--- a/drivers/scsi/lpfc/lpfc_mbox.c</span>
<span class="p_header">+++ b/drivers/scsi/lpfc/lpfc_mbox.c</span>
<span class="p_chunk">@@ -2145,10 +2145,12 @@</span> <span class="p_context"> lpfc_reg_vfi(struct lpfcMboxq *mbox, struct lpfc_vport *vport, dma_addr_t phys)</span>
 	reg_vfi-&gt;wwn[1] = cpu_to_le32(reg_vfi-&gt;wwn[1]);
 	reg_vfi-&gt;e_d_tov = phba-&gt;fc_edtov;
 	reg_vfi-&gt;r_a_tov = phba-&gt;fc_ratov;
<span class="p_del">-	reg_vfi-&gt;bde.addrHigh = putPaddrHigh(phys);</span>
<span class="p_del">-	reg_vfi-&gt;bde.addrLow = putPaddrLow(phys);</span>
<span class="p_del">-	reg_vfi-&gt;bde.tus.f.bdeSize = sizeof(vport-&gt;fc_sparam);</span>
<span class="p_del">-	reg_vfi-&gt;bde.tus.f.bdeFlags = BUFF_TYPE_BDE_64;</span>
<span class="p_add">+	if (phys) {</span>
<span class="p_add">+		reg_vfi-&gt;bde.addrHigh = putPaddrHigh(phys);</span>
<span class="p_add">+		reg_vfi-&gt;bde.addrLow = putPaddrLow(phys);</span>
<span class="p_add">+		reg_vfi-&gt;bde.tus.f.bdeSize = sizeof(vport-&gt;fc_sparam);</span>
<span class="p_add">+		reg_vfi-&gt;bde.tus.f.bdeFlags = BUFF_TYPE_BDE_64;</span>
<span class="p_add">+	}</span>
 	bf_set(lpfc_reg_vfi_nport_id, reg_vfi, vport-&gt;fc_myDID);
 
 	/* Only FC supports upd bit */
<span class="p_header">diff --git a/drivers/scsi/lpfc/lpfc_nportdisc.c b/drivers/scsi/lpfc/lpfc_nportdisc.c</span>
<span class="p_header">index ed9a2c80c4aa..193733e8c823 100644</span>
<span class="p_header">--- a/drivers/scsi/lpfc/lpfc_nportdisc.c</span>
<span class="p_header">+++ b/drivers/scsi/lpfc/lpfc_nportdisc.c</span>
<span class="p_chunk">@@ -280,38 +280,12 @@</span> <span class="p_context"> lpfc_rcv_plogi(struct lpfc_vport *vport, struct lpfc_nodelist *ndlp,</span>
 	uint32_t *lp;
 	IOCB_t *icmd;
 	struct serv_parm *sp;
<span class="p_add">+	uint32_t ed_tov;</span>
 	LPFC_MBOXQ_t *mbox;
 	struct ls_rjt stat;
 	int rc;
 
 	memset(&amp;stat, 0, sizeof (struct ls_rjt));
<span class="p_del">-	if (vport-&gt;port_state &lt;= LPFC_FDISC) {</span>
<span class="p_del">-		/* Before responding to PLOGI, check for pt2pt mode.</span>
<span class="p_del">-		 * If we are pt2pt, with an outstanding FLOGI, abort</span>
<span class="p_del">-		 * the FLOGI and resend it first.</span>
<span class="p_del">-		 */</span>
<span class="p_del">-		if (vport-&gt;fc_flag &amp; FC_PT2PT) {</span>
<span class="p_del">-			 lpfc_els_abort_flogi(phba);</span>
<span class="p_del">-		        if (!(vport-&gt;fc_flag &amp; FC_PT2PT_PLOGI)) {</span>
<span class="p_del">-				/* If the other side is supposed to initiate</span>
<span class="p_del">-				 * the PLOGI anyway, just ACC it now and</span>
<span class="p_del">-				 * move on with discovery.</span>
<span class="p_del">-				 */</span>
<span class="p_del">-				phba-&gt;fc_edtov = FF_DEF_EDTOV;</span>
<span class="p_del">-				phba-&gt;fc_ratov = FF_DEF_RATOV;</span>
<span class="p_del">-				/* Start discovery - this should just do</span>
<span class="p_del">-				   CLEAR_LA */</span>
<span class="p_del">-				lpfc_disc_start(vport);</span>
<span class="p_del">-			} else</span>
<span class="p_del">-				lpfc_initial_flogi(vport);</span>
<span class="p_del">-		} else {</span>
<span class="p_del">-			stat.un.b.lsRjtRsnCode = LSRJT_LOGICAL_BSY;</span>
<span class="p_del">-			stat.un.b.lsRjtRsnCodeExp = LSEXP_NOTHING_MORE;</span>
<span class="p_del">-			lpfc_els_rsp_reject(vport, stat.un.lsRjtError, cmdiocb,</span>
<span class="p_del">-					    ndlp, NULL);</span>
<span class="p_del">-			return 0;</span>
<span class="p_del">-		}</span>
<span class="p_del">-	}</span>
 	pcmd = (struct lpfc_dmabuf *) cmdiocb-&gt;context2;
 	lp = (uint32_t *) pcmd-&gt;virt;
 	sp = (struct serv_parm *) ((uint8_t *) lp + sizeof (uint32_t));
<span class="p_chunk">@@ -404,30 +378,46 @@</span> <span class="p_context"> lpfc_rcv_plogi(struct lpfc_vport *vport, struct lpfc_nodelist *ndlp,</span>
 	/* Check for Nport to NPort pt2pt protocol */
 	if ((vport-&gt;fc_flag &amp; FC_PT2PT) &amp;&amp;
 	    !(vport-&gt;fc_flag &amp; FC_PT2PT_PLOGI)) {
<span class="p_del">-</span>
 		/* rcv&#39;ed PLOGI decides what our NPortId will be */
 		vport-&gt;fc_myDID = icmd-&gt;un.rcvels.parmRo;
<span class="p_del">-		mbox = mempool_alloc(phba-&gt;mbox_mem_pool, GFP_KERNEL);</span>
<span class="p_del">-		if (mbox == NULL)</span>
<span class="p_del">-			goto out;</span>
<span class="p_del">-		lpfc_config_link(phba, mbox);</span>
<span class="p_del">-		mbox-&gt;mbox_cmpl = lpfc_sli_def_mbox_cmpl;</span>
<span class="p_del">-		mbox-&gt;vport = vport;</span>
<span class="p_del">-		rc = lpfc_sli_issue_mbox(phba, mbox, MBX_NOWAIT);</span>
<span class="p_del">-		if (rc == MBX_NOT_FINISHED) {</span>
<span class="p_del">-			mempool_free(mbox, phba-&gt;mbox_mem_pool);</span>
<span class="p_del">-			goto out;</span>
<span class="p_add">+</span>
<span class="p_add">+		ed_tov = be32_to_cpu(sp-&gt;cmn.e_d_tov);</span>
<span class="p_add">+		if (sp-&gt;cmn.edtovResolution) {</span>
<span class="p_add">+			/* E_D_TOV ticks are in nanoseconds */</span>
<span class="p_add">+			ed_tov = (phba-&gt;fc_edtov + 999999) / 1000000;</span>
 		}
<span class="p_add">+</span>
 		/*
<span class="p_del">-		 * For SLI4, the VFI/VPI are registered AFTER the</span>
<span class="p_del">-		 * Nport with the higher WWPN sends us a PLOGI with</span>
<span class="p_del">-		 * our assigned NPortId.</span>
<span class="p_add">+		 * For pt-to-pt, use the larger EDTOV</span>
<span class="p_add">+		 * RATOV = 2 * EDTOV</span>
 		 */
<span class="p_add">+		if (ed_tov &gt; phba-&gt;fc_edtov)</span>
<span class="p_add">+			phba-&gt;fc_edtov = ed_tov;</span>
<span class="p_add">+		phba-&gt;fc_ratov = (2 * phba-&gt;fc_edtov) / 1000;</span>
<span class="p_add">+</span>
<span class="p_add">+		memcpy(&amp;phba-&gt;fc_fabparam, sp, sizeof(struct serv_parm));</span>
<span class="p_add">+</span>
<span class="p_add">+		/* Issue config_link / reg_vfi to account for updated TOV&#39;s */</span>
<span class="p_add">+</span>
 		if (phba-&gt;sli_rev == LPFC_SLI_REV4)
 			lpfc_issue_reg_vfi(vport);
<span class="p_add">+		else {</span>
<span class="p_add">+			mbox = mempool_alloc(phba-&gt;mbox_mem_pool, GFP_KERNEL);</span>
<span class="p_add">+			if (mbox == NULL)</span>
<span class="p_add">+				goto out;</span>
<span class="p_add">+			lpfc_config_link(phba, mbox);</span>
<span class="p_add">+			mbox-&gt;mbox_cmpl = lpfc_sli_def_mbox_cmpl;</span>
<span class="p_add">+			mbox-&gt;vport = vport;</span>
<span class="p_add">+			rc = lpfc_sli_issue_mbox(phba, mbox, MBX_NOWAIT);</span>
<span class="p_add">+			if (rc == MBX_NOT_FINISHED) {</span>
<span class="p_add">+				mempool_free(mbox, phba-&gt;mbox_mem_pool);</span>
<span class="p_add">+				goto out;</span>
<span class="p_add">+			}</span>
<span class="p_add">+		}</span>
 
 		lpfc_can_disctmo(vport);
 	}
<span class="p_add">+</span>
 	mbox = mempool_alloc(phba-&gt;mbox_mem_pool, GFP_KERNEL);
 	if (!mbox)
 		goto out;
<span class="p_chunk">@@ -1038,7 +1028,9 @@</span> <span class="p_context"> lpfc_cmpl_plogi_plogi_issue(struct lpfc_vport *vport,</span>
 	uint32_t *lp;
 	IOCB_t *irsp;
 	struct serv_parm *sp;
<span class="p_add">+	uint32_t ed_tov;</span>
 	LPFC_MBOXQ_t *mbox;
<span class="p_add">+	int rc;</span>
 
 	cmdiocb = (struct lpfc_iocbq *) arg;
 	rspiocb = cmdiocb-&gt;context_un.rsp_iocb;
<span class="p_chunk">@@ -1094,18 +1086,63 @@</span> <span class="p_context"> lpfc_cmpl_plogi_plogi_issue(struct lpfc_vport *vport,</span>
 	ndlp-&gt;nlp_maxframe =
 		((sp-&gt;cmn.bbRcvSizeMsb &amp; 0x0F) &lt;&lt; 8) | sp-&gt;cmn.bbRcvSizeLsb;
 
<span class="p_add">+	if ((vport-&gt;fc_flag &amp; FC_PT2PT) &amp;&amp;</span>
<span class="p_add">+	    (vport-&gt;fc_flag &amp; FC_PT2PT_PLOGI)) {</span>
<span class="p_add">+		ed_tov = be32_to_cpu(sp-&gt;cmn.e_d_tov);</span>
<span class="p_add">+		if (sp-&gt;cmn.edtovResolution) {</span>
<span class="p_add">+			/* E_D_TOV ticks are in nanoseconds */</span>
<span class="p_add">+			ed_tov = (phba-&gt;fc_edtov + 999999) / 1000000;</span>
<span class="p_add">+		}</span>
<span class="p_add">+</span>
<span class="p_add">+		/*</span>
<span class="p_add">+		 * Use the larger EDTOV</span>
<span class="p_add">+		 * RATOV = 2 * EDTOV for pt-to-pt</span>
<span class="p_add">+		 */</span>
<span class="p_add">+		if (ed_tov &gt; phba-&gt;fc_edtov)</span>
<span class="p_add">+			phba-&gt;fc_edtov = ed_tov;</span>
<span class="p_add">+		phba-&gt;fc_ratov = (2 * phba-&gt;fc_edtov) / 1000;</span>
<span class="p_add">+</span>
<span class="p_add">+		memcpy(&amp;phba-&gt;fc_fabparam, sp, sizeof(struct serv_parm));</span>
<span class="p_add">+</span>
<span class="p_add">+		/* Issue config_link / reg_vfi to account for updated TOV&#39;s */</span>
<span class="p_add">+		if (phba-&gt;sli_rev == LPFC_SLI_REV4) {</span>
<span class="p_add">+			lpfc_issue_reg_vfi(vport);</span>
<span class="p_add">+		} else {</span>
<span class="p_add">+			mbox = mempool_alloc(phba-&gt;mbox_mem_pool, GFP_KERNEL);</span>
<span class="p_add">+			if (!mbox) {</span>
<span class="p_add">+				lpfc_printf_vlog(vport, KERN_ERR, LOG_ELS,</span>
<span class="p_add">+						 &quot;0133 PLOGI: no memory &quot;</span>
<span class="p_add">+						 &quot;for config_link &quot;</span>
<span class="p_add">+						 &quot;Data: x%x x%x x%x x%x\n&quot;,</span>
<span class="p_add">+						 ndlp-&gt;nlp_DID, ndlp-&gt;nlp_state,</span>
<span class="p_add">+						 ndlp-&gt;nlp_flag, ndlp-&gt;nlp_rpi);</span>
<span class="p_add">+				goto out;</span>
<span class="p_add">+			}</span>
<span class="p_add">+</span>
<span class="p_add">+			lpfc_config_link(phba, mbox);</span>
<span class="p_add">+</span>
<span class="p_add">+			mbox-&gt;mbox_cmpl = lpfc_sli_def_mbox_cmpl;</span>
<span class="p_add">+			mbox-&gt;vport = vport;</span>
<span class="p_add">+			rc = lpfc_sli_issue_mbox(phba, mbox, MBX_NOWAIT);</span>
<span class="p_add">+			if (rc == MBX_NOT_FINISHED) {</span>
<span class="p_add">+				mempool_free(mbox, phba-&gt;mbox_mem_pool);</span>
<span class="p_add">+				goto out;</span>
<span class="p_add">+			}</span>
<span class="p_add">+		}</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	lpfc_unreg_rpi(vport, ndlp);</span>
<span class="p_add">+</span>
 	mbox = mempool_alloc(phba-&gt;mbox_mem_pool, GFP_KERNEL);
 	if (!mbox) {
 		lpfc_printf_vlog(vport, KERN_ERR, LOG_ELS,
<span class="p_del">-			&quot;0133 PLOGI: no memory for reg_login &quot;</span>
<span class="p_del">-			&quot;Data: x%x x%x x%x x%x\n&quot;,</span>
<span class="p_del">-			ndlp-&gt;nlp_DID, ndlp-&gt;nlp_state,</span>
<span class="p_del">-			ndlp-&gt;nlp_flag, ndlp-&gt;nlp_rpi);</span>
<span class="p_add">+				 &quot;0018 PLOGI: no memory for reg_login &quot;</span>
<span class="p_add">+				 &quot;Data: x%x x%x x%x x%x\n&quot;,</span>
<span class="p_add">+				 ndlp-&gt;nlp_DID, ndlp-&gt;nlp_state,</span>
<span class="p_add">+				 ndlp-&gt;nlp_flag, ndlp-&gt;nlp_rpi);</span>
 		goto out;
 	}
 
<span class="p_del">-	lpfc_unreg_rpi(vport, ndlp);</span>
<span class="p_del">-</span>
 	if (lpfc_reg_rpi(phba, vport-&gt;vpi, irsp-&gt;un.elsreq64.remoteID,
 			 (uint8_t *) sp, mbox, ndlp-&gt;nlp_rpi) == 0) {
 		switch (ndlp-&gt;nlp_DID) {
<span class="p_chunk">@@ -2299,6 +2336,9 @@</span> <span class="p_context"> lpfc_cmpl_reglogin_npr_node(struct lpfc_vport *vport,</span>
 		if (vport-&gt;phba-&gt;sli_rev &lt; LPFC_SLI_REV4)
 			ndlp-&gt;nlp_rpi = mb-&gt;un.varWords[0];
 		ndlp-&gt;nlp_flag |= NLP_RPI_REGISTERED;
<span class="p_add">+		if (ndlp-&gt;nlp_flag &amp; NLP_LOGO_ACC) {</span>
<span class="p_add">+			lpfc_unreg_rpi(vport, ndlp);</span>
<span class="p_add">+		}</span>
 	} else {
 		if (ndlp-&gt;nlp_flag &amp; NLP_NODEV_REMOVE) {
 			lpfc_drop_node(vport, ndlp);
<span class="p_header">diff --git a/drivers/scsi/lpfc/lpfc_scsi.c b/drivers/scsi/lpfc/lpfc_scsi.c</span>
<span class="p_header">index 9e165bc05ee1..bae36cc3740b 100644</span>
<span class="p_header">--- a/drivers/scsi/lpfc/lpfc_scsi.c</span>
<span class="p_header">+++ b/drivers/scsi/lpfc/lpfc_scsi.c</span>
<span class="p_chunk">@@ -3908,9 +3908,9 @@</span> <span class="p_context"> lpfc_scsi_cmd_iocb_cmpl(struct lpfc_hba *phba, struct lpfc_iocbq *pIocbIn,</span>
 	uint32_t logit = LOG_FCP;
 
 	/* Sanity check on return of outstanding command */
<span class="p_del">-	if (!(lpfc_cmd-&gt;pCmd))</span>
<span class="p_del">-		return;</span>
 	cmd = lpfc_cmd-&gt;pCmd;
<span class="p_add">+	if (!cmd)</span>
<span class="p_add">+		return;</span>
 	shost = cmd-&gt;device-&gt;host;
 
 	lpfc_cmd-&gt;result = (pIocbOut-&gt;iocb.un.ulpWord[4] &amp; IOERR_PARAM_MASK);
<span class="p_header">diff --git a/drivers/scsi/lpfc/lpfc_sli.c b/drivers/scsi/lpfc/lpfc_sli.c</span>
<span class="p_header">index f9585cdd8933..92dfd6a5178c 100644</span>
<span class="p_header">--- a/drivers/scsi/lpfc/lpfc_sli.c</span>
<span class="p_header">+++ b/drivers/scsi/lpfc/lpfc_sli.c</span>
<span class="p_chunk">@@ -14842,10 +14842,12 @@</span> <span class="p_context"> lpfc_fc_frame_add(struct lpfc_vport *vport, struct hbq_dmabuf *dmabuf)</span>
 	struct lpfc_dmabuf *h_buf;
 	struct hbq_dmabuf *seq_dmabuf = NULL;
 	struct hbq_dmabuf *temp_dmabuf = NULL;
<span class="p_add">+	uint8_t	found = 0;</span>
 
 	INIT_LIST_HEAD(&amp;dmabuf-&gt;dbuf.list);
 	dmabuf-&gt;time_stamp = jiffies;
 	new_hdr = (struct fc_frame_header *)dmabuf-&gt;hbuf.virt;
<span class="p_add">+</span>
 	/* Use the hdr_buf to find the sequence that this frame belongs to */
 	list_for_each_entry(h_buf, &amp;vport-&gt;rcv_buffer_list, list) {
 		temp_hdr = (struct fc_frame_header *)h_buf-&gt;virt;
<span class="p_chunk">@@ -14885,7 +14887,8 @@</span> <span class="p_context"> lpfc_fc_frame_add(struct lpfc_vport *vport, struct hbq_dmabuf *dmabuf)</span>
 		return seq_dmabuf;
 	}
 	/* find the correct place in the sequence to insert this frame */
<span class="p_del">-	list_for_each_entry_reverse(d_buf, &amp;seq_dmabuf-&gt;dbuf.list, list) {</span>
<span class="p_add">+	d_buf = list_entry(seq_dmabuf-&gt;dbuf.list.prev, typeof(*d_buf), list);</span>
<span class="p_add">+	while (!found) {</span>
 		temp_dmabuf = container_of(d_buf, struct hbq_dmabuf, dbuf);
 		temp_hdr = (struct fc_frame_header *)temp_dmabuf-&gt;hbuf.virt;
 		/*
<span class="p_chunk">@@ -14895,9 +14898,17 @@</span> <span class="p_context"> lpfc_fc_frame_add(struct lpfc_vport *vport, struct hbq_dmabuf *dmabuf)</span>
 		if (be16_to_cpu(new_hdr-&gt;fh_seq_cnt) &gt;
 			be16_to_cpu(temp_hdr-&gt;fh_seq_cnt)) {
 			list_add(&amp;dmabuf-&gt;dbuf.list, &amp;temp_dmabuf-&gt;dbuf.list);
<span class="p_del">-			return seq_dmabuf;</span>
<span class="p_add">+			found = 1;</span>
<span class="p_add">+			break;</span>
 		}
<span class="p_add">+</span>
<span class="p_add">+		if (&amp;d_buf-&gt;list == &amp;seq_dmabuf-&gt;dbuf.list)</span>
<span class="p_add">+			break;</span>
<span class="p_add">+		d_buf = list_entry(d_buf-&gt;list.prev, typeof(*d_buf), list);</span>
 	}
<span class="p_add">+</span>
<span class="p_add">+	if (found)</span>
<span class="p_add">+		return seq_dmabuf;</span>
 	return NULL;
 }
 
<span class="p_chunk">@@ -16173,7 +16184,7 @@</span> <span class="p_context"> fail_fcf_read:</span>
 }
 
 /**
<span class="p_del">- * lpfc_check_next_fcf_pri</span>
<span class="p_add">+ * lpfc_check_next_fcf_pri_level</span>
  * phba pointer to the lpfc_hba struct for this port.
  * This routine is called from the lpfc_sli4_fcf_rr_next_index_get
  * routine when the rr_bmask is empty. The FCF indecies are put into the
<span class="p_chunk">@@ -16329,8 +16340,12 @@</span> <span class="p_context"> next_priority:</span>
 
 	if (next_fcf_index &lt; LPFC_SLI4_FCF_TBL_INDX_MAX &amp;&amp;
 		phba-&gt;fcf.fcf_pri[next_fcf_index].fcf_rec.flag &amp;
<span class="p_del">-		LPFC_FCF_FLOGI_FAILED)</span>
<span class="p_add">+		LPFC_FCF_FLOGI_FAILED) {</span>
<span class="p_add">+		if (list_is_singular(&amp;phba-&gt;fcf.fcf_pri_list))</span>
<span class="p_add">+			return LPFC_FCOE_FCF_NEXT_NONE;</span>
<span class="p_add">+</span>
 		goto next_priority;
<span class="p_add">+	}</span>
 
 	lpfc_printf_log(phba, KERN_INFO, LOG_FIP,
 			&quot;2845 Get next roundrobin failover FCF (x%x)\n&quot;,
<span class="p_header">diff --git a/drivers/scsi/megaraid/megaraid_sas.h b/drivers/scsi/megaraid/megaraid_sas.h</span>
<span class="p_header">index c0f7c8ce54aa..ef4ff03242ea 100644</span>
<span class="p_header">--- a/drivers/scsi/megaraid/megaraid_sas.h</span>
<span class="p_header">+++ b/drivers/scsi/megaraid/megaraid_sas.h</span>
<span class="p_chunk">@@ -1083,6 +1083,8 @@</span> <span class="p_context"> struct megasas_ctrl_info {</span>
 
 #define VD_EXT_DEBUG 0
 
<span class="p_add">+#define SCAN_PD_CHANNEL	0x1</span>
<span class="p_add">+#define SCAN_VD_CHANNEL	0x2</span>
 
 enum MR_SCSI_CMD_TYPE {
 	READ_WRITE_LDIO = 0,
<span class="p_header">diff --git a/drivers/scsi/megaraid/megaraid_sas_base.c b/drivers/scsi/megaraid/megaraid_sas_base.c</span>
<span class="p_header">index e994ff944091..3f8d357b1bac 100644</span>
<span class="p_header">--- a/drivers/scsi/megaraid/megaraid_sas_base.c</span>
<span class="p_header">+++ b/drivers/scsi/megaraid/megaraid_sas_base.c</span>
<span class="p_chunk">@@ -735,6 +735,7 @@</span> <span class="p_context"> megasas_fire_cmd_skinny(struct megasas_instance *instance,</span>
 	       &amp;(regs)-&gt;inbound_high_queue_port);
 	writel((lower_32_bits(frame_phys_addr) | (frame_count&lt;&lt;1))|1,
 	       &amp;(regs)-&gt;inbound_low_queue_port);
<span class="p_add">+	mmiowb();</span>
 	spin_unlock_irqrestore(&amp;instance-&gt;hba_lock, flags);
 }
 
<span class="p_chunk">@@ -5476,7 +5477,6 @@</span> <span class="p_context"> static int megasas_probe_one(struct pci_dev *pdev,</span>
 	spin_lock_init(&amp;instance-&gt;hba_lock);
 	spin_lock_init(&amp;instance-&gt;completion_lock);
 
<span class="p_del">-	mutex_init(&amp;instance-&gt;aen_mutex);</span>
 	mutex_init(&amp;instance-&gt;reset_mutex);
 
 	/*
<span class="p_chunk">@@ -6443,10 +6443,10 @@</span> <span class="p_context"> static int megasas_mgmt_ioctl_aen(struct file *file, unsigned long arg)</span>
 	}
 	spin_unlock_irqrestore(&amp;instance-&gt;hba_lock, flags);
 
<span class="p_del">-	mutex_lock(&amp;instance-&gt;aen_mutex);</span>
<span class="p_add">+	mutex_lock(&amp;instance-&gt;reset_mutex);</span>
 	error = megasas_register_aen(instance, aen.seq_num,
 				     aen.class_locale_word);
<span class="p_del">-	mutex_unlock(&amp;instance-&gt;aen_mutex);</span>
<span class="p_add">+	mutex_unlock(&amp;instance-&gt;reset_mutex);</span>
 	return error;
 }
 
<span class="p_chunk">@@ -6477,9 +6477,9 @@</span> <span class="p_context"> static int megasas_mgmt_compat_ioctl_fw(struct file *file, unsigned long arg)</span>
 	int i;
 	int error = 0;
 	compat_uptr_t ptr;
<span class="p_del">-	unsigned long local_raw_ptr;</span>
 	u32 local_sense_off;
 	u32 local_sense_len;
<span class="p_add">+	u32 user_sense_off;</span>
 
 	if (clear_user(ioc, sizeof(*ioc)))
 		return -EFAULT;
<span class="p_chunk">@@ -6497,17 +6497,16 @@</span> <span class="p_context"> static int megasas_mgmt_compat_ioctl_fw(struct file *file, unsigned long arg)</span>
 	 * sense_len is not null, so prepare the 64bit value under
 	 * the same condition.
 	 */
<span class="p_del">-	if (get_user(local_raw_ptr, ioc-&gt;frame.raw) ||</span>
<span class="p_del">-		get_user(local_sense_off, &amp;ioc-&gt;sense_off) ||</span>
<span class="p_del">-		get_user(local_sense_len, &amp;ioc-&gt;sense_len))</span>
<span class="p_add">+	if (get_user(local_sense_off, &amp;ioc-&gt;sense_off) ||</span>
<span class="p_add">+		get_user(local_sense_len, &amp;ioc-&gt;sense_len) ||</span>
<span class="p_add">+		get_user(user_sense_off, &amp;cioc-&gt;sense_off))</span>
 		return -EFAULT;
 
<span class="p_del">-</span>
 	if (local_sense_len) {
 		void __user **sense_ioc_ptr =
<span class="p_del">-			(void __user **)((u8*)local_raw_ptr + local_sense_off);</span>
<span class="p_add">+			(void __user **)((u8 *)((unsigned long)&amp;ioc-&gt;frame.raw) + local_sense_off);</span>
 		compat_uptr_t *sense_cioc_ptr =
<span class="p_del">-			(compat_uptr_t *)(cioc-&gt;frame.raw + cioc-&gt;sense_off);</span>
<span class="p_add">+			(compat_uptr_t *)(((unsigned long)&amp;cioc-&gt;frame.raw) + user_sense_off);</span>
 		if (get_user(ptr, sense_cioc_ptr) ||
 		    put_user(compat_ptr(ptr), sense_ioc_ptr))
 			return -EFAULT;
<span class="p_chunk">@@ -6648,6 +6647,7 @@</span> <span class="p_context"> megasas_aen_polling(struct work_struct *work)</span>
 	int     i, j, doscan = 0;
 	u32 seq_num, wait_time = MEGASAS_RESET_WAIT_TIME;
 	int error;
<span class="p_add">+	u8  dcmd_ret = 0;</span>
 
 	if (!instance) {
 		printk(KERN_ERR &quot;invalid instance!\n&quot;);
<span class="p_chunk">@@ -6660,16 +6660,7 @@</span> <span class="p_context"> megasas_aen_polling(struct work_struct *work)</span>
 		wait_time = MEGASAS_ROUTINE_WAIT_TIME_VF;
 
 	/* Don&#39;t run the event workqueue thread if OCR is running */
<span class="p_del">-	for (i = 0; i &lt; wait_time; i++) {</span>
<span class="p_del">-		if (instance-&gt;adprecovery == MEGASAS_HBA_OPERATIONAL)</span>
<span class="p_del">-			break;</span>
<span class="p_del">-		if (!(i % MEGASAS_RESET_NOTICE_INTERVAL)) {</span>
<span class="p_del">-			dev_notice(&amp;instance-&gt;pdev-&gt;dev, &quot;%s waiting for &quot;</span>
<span class="p_del">-			       &quot;controller reset to finish for scsi%d\n&quot;,</span>
<span class="p_del">-			       __func__, instance-&gt;host-&gt;host_no);</span>
<span class="p_del">-		}</span>
<span class="p_del">-		msleep(1000);</span>
<span class="p_del">-	}</span>
<span class="p_add">+	mutex_lock(&amp;instance-&gt;reset_mutex);</span>
 
 	instance-&gt;ev = NULL;
 	host = instance-&gt;host;
<span class="p_chunk">@@ -6677,212 +6668,127 @@</span> <span class="p_context"> megasas_aen_polling(struct work_struct *work)</span>
 		megasas_decode_evt(instance);
 
 		switch (le32_to_cpu(instance-&gt;evt_detail-&gt;code)) {
<span class="p_del">-		case MR_EVT_PD_INSERTED:</span>
<span class="p_del">-			if (megasas_get_pd_list(instance) == 0) {</span>
<span class="p_del">-			for (i = 0; i &lt; MEGASAS_MAX_PD_CHANNELS; i++) {</span>
<span class="p_del">-				for (j = 0;</span>
<span class="p_del">-				j &lt; MEGASAS_MAX_DEV_PER_CHANNEL;</span>
<span class="p_del">-				j++) {</span>
<span class="p_del">-</span>
<span class="p_del">-				pd_index =</span>
<span class="p_del">-				(i * MEGASAS_MAX_DEV_PER_CHANNEL) + j;</span>
<span class="p_del">-</span>
<span class="p_del">-				sdev1 = scsi_device_lookup(host, i, j, 0);</span>
<span class="p_del">-</span>
<span class="p_del">-				if (instance-&gt;pd_list[pd_index].driveState</span>
<span class="p_del">-						== MR_PD_STATE_SYSTEM) {</span>
<span class="p_del">-					if (!sdev1)</span>
<span class="p_del">-						scsi_add_device(host, i, j, 0);</span>
<span class="p_del">-</span>
<span class="p_del">-					if (sdev1)</span>
<span class="p_del">-						scsi_device_put(sdev1);</span>
<span class="p_del">-					}</span>
<span class="p_del">-				}</span>
<span class="p_del">-			}</span>
<span class="p_del">-			}</span>
<span class="p_del">-			doscan = 0;</span>
<span class="p_del">-			break;</span>
 
<span class="p_add">+		case MR_EVT_PD_INSERTED:</span>
 		case MR_EVT_PD_REMOVED:
<span class="p_del">-			if (megasas_get_pd_list(instance) == 0) {</span>
<span class="p_del">-			for (i = 0; i &lt; MEGASAS_MAX_PD_CHANNELS; i++) {</span>
<span class="p_del">-				for (j = 0;</span>
<span class="p_del">-				j &lt; MEGASAS_MAX_DEV_PER_CHANNEL;</span>
<span class="p_del">-				j++) {</span>
<span class="p_del">-</span>
<span class="p_del">-				pd_index =</span>
<span class="p_del">-				(i * MEGASAS_MAX_DEV_PER_CHANNEL) + j;</span>
<span class="p_del">-</span>
<span class="p_del">-				sdev1 = scsi_device_lookup(host, i, j, 0);</span>
<span class="p_del">-</span>
<span class="p_del">-				if (instance-&gt;pd_list[pd_index].driveState</span>
<span class="p_del">-					== MR_PD_STATE_SYSTEM) {</span>
<span class="p_del">-					if (sdev1)</span>
<span class="p_del">-						scsi_device_put(sdev1);</span>
<span class="p_del">-				} else {</span>
<span class="p_del">-					if (sdev1) {</span>
<span class="p_del">-						scsi_remove_device(sdev1);</span>
<span class="p_del">-						scsi_device_put(sdev1);</span>
<span class="p_del">-					}</span>
<span class="p_del">-				}</span>
<span class="p_del">-				}</span>
<span class="p_del">-			}</span>
<span class="p_del">-			}</span>
<span class="p_del">-			doscan = 0;</span>
<span class="p_add">+			dcmd_ret = megasas_get_pd_list(instance);</span>
<span class="p_add">+			if (dcmd_ret == 0)</span>
<span class="p_add">+				doscan = SCAN_PD_CHANNEL;</span>
 			break;
 
 		case MR_EVT_LD_OFFLINE:
 		case MR_EVT_CFG_CLEARED:
 		case MR_EVT_LD_DELETED:
<span class="p_del">-			if (!instance-&gt;requestorId ||</span>
<span class="p_del">-			    megasas_get_ld_vf_affiliation(instance, 0)) {</span>
<span class="p_del">-				if (megasas_ld_list_query(instance,</span>
<span class="p_del">-							  MR_LD_QUERY_TYPE_EXPOSED_TO_HOST))</span>
<span class="p_del">-					megasas_get_ld_list(instance);</span>
<span class="p_del">-				for (i = 0; i &lt; MEGASAS_MAX_LD_CHANNELS; i++) {</span>
<span class="p_del">-					for (j = 0;</span>
<span class="p_del">-					     j &lt; MEGASAS_MAX_DEV_PER_CHANNEL;</span>
<span class="p_del">-					     j++) {</span>
<span class="p_del">-</span>
<span class="p_del">-						ld_index =</span>
<span class="p_del">-							(i * MEGASAS_MAX_DEV_PER_CHANNEL) + j;</span>
<span class="p_del">-</span>
<span class="p_del">-						sdev1 = scsi_device_lookup(host, MEGASAS_MAX_PD_CHANNELS + i, j, 0);</span>
<span class="p_del">-</span>
<span class="p_del">-						if (instance-&gt;ld_ids[ld_index]</span>
<span class="p_del">-						    != 0xff) {</span>
<span class="p_del">-							if (sdev1)</span>
<span class="p_del">-								scsi_device_put(sdev1);</span>
<span class="p_del">-						} else {</span>
<span class="p_del">-							if (sdev1) {</span>
<span class="p_del">-								scsi_remove_device(sdev1);</span>
<span class="p_del">-								scsi_device_put(sdev1);</span>
<span class="p_del">-							}</span>
<span class="p_del">-						}</span>
<span class="p_del">-					}</span>
<span class="p_del">-				}</span>
<span class="p_del">-				doscan = 0;</span>
<span class="p_del">-			}</span>
<span class="p_del">-			break;</span>
 		case MR_EVT_LD_CREATED:
 			if (!instance-&gt;requestorId ||
<span class="p_del">-			    megasas_get_ld_vf_affiliation(instance, 0)) {</span>
<span class="p_del">-				if (megasas_ld_list_query(instance,</span>
<span class="p_del">-							  MR_LD_QUERY_TYPE_EXPOSED_TO_HOST))</span>
<span class="p_del">-					megasas_get_ld_list(instance);</span>
<span class="p_del">-				for (i = 0; i &lt; MEGASAS_MAX_LD_CHANNELS; i++) {</span>
<span class="p_del">-					for (j = 0;</span>
<span class="p_del">-					     j &lt; MEGASAS_MAX_DEV_PER_CHANNEL;</span>
<span class="p_del">-					     j++) {</span>
<span class="p_del">-						ld_index =</span>
<span class="p_del">-							(i * MEGASAS_MAX_DEV_PER_CHANNEL) + j;</span>
<span class="p_del">-</span>
<span class="p_del">-						sdev1 = scsi_device_lookup(host, MEGASAS_MAX_PD_CHANNELS + i, j, 0);</span>
<span class="p_del">-</span>
<span class="p_del">-						if (instance-&gt;ld_ids[ld_index]</span>
<span class="p_del">-						    != 0xff) {</span>
<span class="p_del">-							if (!sdev1)</span>
<span class="p_del">-								scsi_add_device(host, MEGASAS_MAX_PD_CHANNELS + i, j, 0);</span>
<span class="p_del">-						}</span>
<span class="p_del">-						if (sdev1)</span>
<span class="p_del">-							scsi_device_put(sdev1);</span>
<span class="p_del">-					}</span>
<span class="p_del">-				}</span>
<span class="p_del">-				doscan = 0;</span>
<span class="p_del">-			}</span>
<span class="p_add">+				(instance-&gt;requestorId &amp;&amp; megasas_get_ld_vf_affiliation(instance, 0)))</span>
<span class="p_add">+				dcmd_ret = megasas_ld_list_query(instance, MR_LD_QUERY_TYPE_EXPOSED_TO_HOST);</span>
<span class="p_add">+</span>
<span class="p_add">+			if (dcmd_ret == 0)</span>
<span class="p_add">+				doscan = SCAN_VD_CHANNEL;</span>
<span class="p_add">+</span>
 			break;
<span class="p_add">+</span>
 		case MR_EVT_CTRL_HOST_BUS_SCAN_REQUESTED:
 		case MR_EVT_FOREIGN_CFG_IMPORTED:
 		case MR_EVT_LD_STATE_CHANGE:
<span class="p_del">-			doscan = 1;</span>
<span class="p_add">+			dcmd_ret = megasas_get_pd_list(instance);</span>
<span class="p_add">+</span>
<span class="p_add">+			if (dcmd_ret != 0)</span>
<span class="p_add">+				break;</span>
<span class="p_add">+</span>
<span class="p_add">+			if (!instance-&gt;requestorId ||</span>
<span class="p_add">+				(instance-&gt;requestorId &amp;&amp; megasas_get_ld_vf_affiliation(instance, 0)))</span>
<span class="p_add">+				dcmd_ret = megasas_ld_list_query(instance, MR_LD_QUERY_TYPE_EXPOSED_TO_HOST);</span>
<span class="p_add">+</span>
<span class="p_add">+			if (dcmd_ret != 0)</span>
<span class="p_add">+				break;</span>
<span class="p_add">+</span>
<span class="p_add">+			doscan = SCAN_VD_CHANNEL | SCAN_PD_CHANNEL;</span>
<span class="p_add">+			dev_info(&amp;instance-&gt;pdev-&gt;dev, &quot;scanning for scsi%d...\n&quot;,</span>
<span class="p_add">+				instance-&gt;host-&gt;host_no);</span>
 			break;
<span class="p_add">+</span>
 		case MR_EVT_CTRL_PROP_CHANGED:
<span class="p_del">-			megasas_get_ctrl_info(instance);</span>
<span class="p_del">-			break;</span>
<span class="p_add">+				dcmd_ret = megasas_get_ctrl_info(instance);</span>
<span class="p_add">+				break;</span>
 		default:
 			doscan = 0;
 			break;
 		}
 	} else {
 		dev_err(&amp;instance-&gt;pdev-&gt;dev, &quot;invalid evt_detail!\n&quot;);
<span class="p_add">+		mutex_unlock(&amp;instance-&gt;reset_mutex);</span>
 		kfree(ev);
 		return;
 	}
 
<span class="p_del">-	if (doscan) {</span>
<span class="p_del">-		dev_info(&amp;instance-&gt;pdev-&gt;dev, &quot;scanning for scsi%d...\n&quot;,</span>
<span class="p_del">-		       instance-&gt;host-&gt;host_no);</span>
<span class="p_del">-		if (megasas_get_pd_list(instance) == 0) {</span>
<span class="p_del">-			for (i = 0; i &lt; MEGASAS_MAX_PD_CHANNELS; i++) {</span>
<span class="p_del">-				for (j = 0; j &lt; MEGASAS_MAX_DEV_PER_CHANNEL; j++) {</span>
<span class="p_del">-					pd_index = i*MEGASAS_MAX_DEV_PER_CHANNEL + j;</span>
<span class="p_del">-					sdev1 = scsi_device_lookup(host, i, j, 0);</span>
<span class="p_del">-					if (instance-&gt;pd_list[pd_index].driveState ==</span>
<span class="p_del">-					    MR_PD_STATE_SYSTEM) {</span>
<span class="p_del">-						if (!sdev1) {</span>
<span class="p_del">-							scsi_add_device(host, i, j, 0);</span>
<span class="p_del">-						}</span>
<span class="p_del">-						if (sdev1)</span>
<span class="p_del">-							scsi_device_put(sdev1);</span>
<span class="p_del">-					} else {</span>
<span class="p_del">-						if (sdev1) {</span>
<span class="p_del">-							scsi_remove_device(sdev1);</span>
<span class="p_del">-							scsi_device_put(sdev1);</span>
<span class="p_del">-						}</span>
<span class="p_add">+	mutex_unlock(&amp;instance-&gt;reset_mutex);</span>
<span class="p_add">+</span>
<span class="p_add">+	if (doscan &amp; SCAN_PD_CHANNEL) {</span>
<span class="p_add">+		for (i = 0; i &lt; MEGASAS_MAX_PD_CHANNELS; i++) {</span>
<span class="p_add">+			for (j = 0; j &lt; MEGASAS_MAX_DEV_PER_CHANNEL; j++) {</span>
<span class="p_add">+				pd_index = i*MEGASAS_MAX_DEV_PER_CHANNEL + j;</span>
<span class="p_add">+				sdev1 = scsi_device_lookup(host, i, j, 0);</span>
<span class="p_add">+				if (instance-&gt;pd_list[pd_index].driveState ==</span>
<span class="p_add">+							MR_PD_STATE_SYSTEM) {</span>
<span class="p_add">+					if (!sdev1)</span>
<span class="p_add">+						scsi_add_device(host, i, j, 0);</span>
<span class="p_add">+					else</span>
<span class="p_add">+						scsi_device_put(sdev1);</span>
<span class="p_add">+				} else {</span>
<span class="p_add">+					if (sdev1) {</span>
<span class="p_add">+						scsi_remove_device(sdev1);</span>
<span class="p_add">+						scsi_device_put(sdev1);</span>
 					}
 				}
 			}
 		}
<span class="p_add">+	}</span>
 
<span class="p_del">-		if (!instance-&gt;requestorId ||</span>
<span class="p_del">-		    megasas_get_ld_vf_affiliation(instance, 0)) {</span>
<span class="p_del">-			if (megasas_ld_list_query(instance,</span>
<span class="p_del">-						  MR_LD_QUERY_TYPE_EXPOSED_TO_HOST))</span>
<span class="p_del">-				megasas_get_ld_list(instance);</span>
<span class="p_del">-			for (i = 0; i &lt; MEGASAS_MAX_LD_CHANNELS; i++) {</span>
<span class="p_del">-				for (j = 0; j &lt; MEGASAS_MAX_DEV_PER_CHANNEL;</span>
<span class="p_del">-				     j++) {</span>
<span class="p_del">-					ld_index =</span>
<span class="p_del">-						(i * MEGASAS_MAX_DEV_PER_CHANNEL) + j;</span>
<span class="p_del">-</span>
<span class="p_del">-					sdev1 = scsi_device_lookup(host,</span>
<span class="p_del">-								   MEGASAS_MAX_PD_CHANNELS + i, j, 0);</span>
<span class="p_del">-					if (instance-&gt;ld_ids[ld_index]</span>
<span class="p_del">-					    != 0xff) {</span>
<span class="p_del">-						if (!sdev1)</span>
<span class="p_del">-							scsi_add_device(host, MEGASAS_MAX_PD_CHANNELS + i, j, 0);</span>
<span class="p_del">-						else</span>
<span class="p_del">-							scsi_device_put(sdev1);</span>
<span class="p_del">-					} else {</span>
<span class="p_del">-						if (sdev1) {</span>
<span class="p_del">-							scsi_remove_device(sdev1);</span>
<span class="p_del">-							scsi_device_put(sdev1);</span>
<span class="p_del">-						}</span>
<span class="p_add">+	if (doscan &amp; SCAN_VD_CHANNEL) {</span>
<span class="p_add">+		for (i = 0; i &lt; MEGASAS_MAX_LD_CHANNELS; i++) {</span>
<span class="p_add">+			for (j = 0; j &lt; MEGASAS_MAX_DEV_PER_CHANNEL; j++) {</span>
<span class="p_add">+				ld_index = (i * MEGASAS_MAX_DEV_PER_CHANNEL) + j;</span>
<span class="p_add">+				sdev1 = scsi_device_lookup(host, MEGASAS_MAX_PD_CHANNELS + i, j, 0);</span>
<span class="p_add">+				if (instance-&gt;ld_ids[ld_index] != 0xff) {</span>
<span class="p_add">+					if (!sdev1)</span>
<span class="p_add">+						scsi_add_device(host, MEGASAS_MAX_PD_CHANNELS + i, j, 0);</span>
<span class="p_add">+					else</span>
<span class="p_add">+						scsi_device_put(sdev1);</span>
<span class="p_add">+				} else {</span>
<span class="p_add">+					if (sdev1) {</span>
<span class="p_add">+						scsi_remove_device(sdev1);</span>
<span class="p_add">+						scsi_device_put(sdev1);</span>
 					}
 				}
 			}
 		}
 	}
 
<span class="p_del">-	if (instance-&gt;aen_cmd != NULL) {</span>
<span class="p_del">-		kfree(ev);</span>
<span class="p_del">-		return ;</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">-	seq_num = le32_to_cpu(instance-&gt;evt_detail-&gt;seq_num) + 1;</span>
<span class="p_add">+	if (dcmd_ret == 0)</span>
<span class="p_add">+		seq_num = le32_to_cpu(instance-&gt;evt_detail-&gt;seq_num) + 1;</span>
<span class="p_add">+	else</span>
<span class="p_add">+		seq_num = instance-&gt;last_seq_num;</span>
 
 	/* Register AEN with FW for latest sequence number plus 1 */
 	class_locale.members.reserved = 0;
 	class_locale.members.locale = MR_EVT_LOCALE_ALL;
 	class_locale.members.class = MR_EVT_CLASS_DEBUG;
<span class="p_del">-	mutex_lock(&amp;instance-&gt;aen_mutex);</span>
<span class="p_add">+</span>
<span class="p_add">+	if (instance-&gt;aen_cmd != NULL) {</span>
<span class="p_add">+		kfree(ev);</span>
<span class="p_add">+		return;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	mutex_lock(&amp;instance-&gt;reset_mutex);</span>
 	error = megasas_register_aen(instance, seq_num,
 					class_locale.word);
<span class="p_del">-	mutex_unlock(&amp;instance-&gt;aen_mutex);</span>
<span class="p_del">-</span>
 	if (error)
<span class="p_del">-		dev_err(&amp;instance-&gt;pdev-&gt;dev, &quot;register aen failed error %x\n&quot;, error);</span>
<span class="p_add">+		dev_err(&amp;instance-&gt;pdev-&gt;dev,</span>
<span class="p_add">+			&quot;register aen failed error %x\n&quot;, error);</span>
 
<span class="p_add">+	mutex_unlock(&amp;instance-&gt;reset_mutex);</span>
 	kfree(ev);
 }
 
<span class="p_header">diff --git a/drivers/scsi/megaraid/megaraid_sas_fusion.c b/drivers/scsi/megaraid/megaraid_sas_fusion.c</span>
<span class="p_header">index 4f391e747be2..021b994fdae8 100644</span>
<span class="p_header">--- a/drivers/scsi/megaraid/megaraid_sas_fusion.c</span>
<span class="p_header">+++ b/drivers/scsi/megaraid/megaraid_sas_fusion.c</span>
<span class="p_chunk">@@ -201,6 +201,7 @@</span> <span class="p_context"> megasas_fire_cmd_fusion(struct megasas_instance *instance,</span>
 		&amp;instance-&gt;reg_set-&gt;inbound_low_queue_port);
 	writel(le32_to_cpu(req_desc-&gt;u.high),
 		&amp;instance-&gt;reg_set-&gt;inbound_high_queue_port);
<span class="p_add">+	mmiowb();</span>
 	spin_unlock_irqrestore(&amp;instance-&gt;hba_lock, flags);
 #endif
 }
<span class="p_header">diff --git a/drivers/scsi/mpt3sas/mpt3sas_base.c b/drivers/scsi/mpt3sas/mpt3sas_base.c</span>
<span class="p_header">index 356233f86064..5b2c37f1e908 100644</span>
<span class="p_header">--- a/drivers/scsi/mpt3sas/mpt3sas_base.c</span>
<span class="p_header">+++ b/drivers/scsi/mpt3sas/mpt3sas_base.c</span>
<span class="p_chunk">@@ -2020,8 +2020,10 @@</span> <span class="p_context"> mpt3sas_base_unmap_resources(struct MPT3SAS_ADAPTER *ioc)</span>
 	_base_free_irq(ioc);
 	_base_disable_msix(ioc);
 
<span class="p_del">-	if (ioc-&gt;msix96_vector)</span>
<span class="p_add">+	if (ioc-&gt;msix96_vector) {</span>
 		kfree(ioc-&gt;replyPostRegisterIndex);
<span class="p_add">+		ioc-&gt;replyPostRegisterIndex = NULL;</span>
<span class="p_add">+	}</span>
 
 	if (ioc-&gt;chip_phys) {
 		iounmap(ioc-&gt;chip);
<span class="p_chunk">@@ -2240,6 +2242,12 @@</span> <span class="p_context"> mpt3sas_base_get_reply_virt_addr(struct MPT3SAS_ADAPTER *ioc, u32 phys_addr)</span>
 	return ioc-&gt;reply + (phys_addr - (u32)ioc-&gt;reply_dma);
 }
 
<span class="p_add">+static inline u8</span>
<span class="p_add">+_base_get_msix_index(struct MPT3SAS_ADAPTER *ioc)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return ioc-&gt;cpu_msix_table[raw_smp_processor_id()];</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 /**
  * mpt3sas_base_get_smid - obtain a free smid from internal queue
  * @ioc: per adapter object
<span class="p_chunk">@@ -2300,6 +2308,7 @@</span> <span class="p_context"> mpt3sas_base_get_smid_scsiio(struct MPT3SAS_ADAPTER *ioc, u8 cb_idx,</span>
 	request-&gt;scmd = scmd;
 	request-&gt;cb_idx = cb_idx;
 	smid = request-&gt;smid;
<span class="p_add">+	request-&gt;msix_io = _base_get_msix_index(ioc);</span>
 	list_del(&amp;request-&gt;tracker_list);
 	spin_unlock_irqrestore(&amp;ioc-&gt;scsi_lookup_lock, flags);
 	return smid;
<span class="p_chunk">@@ -2422,12 +2431,6 @@</span> <span class="p_context"> _base_writeq(__u64 b, volatile void __iomem *addr, spinlock_t *writeq_lock)</span>
 }
 #endif
 
<span class="p_del">-static inline u8</span>
<span class="p_del">-_base_get_msix_index(struct MPT3SAS_ADAPTER *ioc)</span>
<span class="p_del">-{</span>
<span class="p_del">-	return ioc-&gt;cpu_msix_table[raw_smp_processor_id()];</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
 /**
  * mpt3sas_base_put_smid_scsi_io - send SCSI_IO request to firmware
  * @ioc: per adapter object
<span class="p_chunk">@@ -2481,18 +2484,19 @@</span> <span class="p_context"> mpt3sas_base_put_smid_fast_path(struct MPT3SAS_ADAPTER *ioc, u16 smid,</span>
  * mpt3sas_base_put_smid_hi_priority - send Task Managment request to firmware
  * @ioc: per adapter object
  * @smid: system request message index
<span class="p_del">- *</span>
<span class="p_add">+ * @msix_task: msix_task will be same as msix of IO incase of task abort else 0.</span>
  * Return nothing.
  */
 void
<span class="p_del">-mpt3sas_base_put_smid_hi_priority(struct MPT3SAS_ADAPTER *ioc, u16 smid)</span>
<span class="p_add">+mpt3sas_base_put_smid_hi_priority(struct MPT3SAS_ADAPTER *ioc, u16 smid,</span>
<span class="p_add">+	u16 msix_task)</span>
 {
 	Mpi2RequestDescriptorUnion_t descriptor;
 	u64 *request = (u64 *)&amp;descriptor;
 
 	descriptor.HighPriority.RequestFlags =
 	    MPI2_REQ_DESCRIPT_FLAGS_HIGH_PRIORITY;
<span class="p_del">-	descriptor.HighPriority.MSIxIndex =  0;</span>
<span class="p_add">+	descriptor.HighPriority.MSIxIndex =  msix_task;</span>
 	descriptor.HighPriority.SMID = cpu_to_le16(smid);
 	descriptor.HighPriority.LMID = 0;
 	descriptor.HighPriority.Reserved1 = 0;
<span class="p_header">diff --git a/drivers/scsi/mpt3sas/mpt3sas_base.h b/drivers/scsi/mpt3sas/mpt3sas_base.h</span>
<span class="p_header">index 5ad271efbd45..92648a5ea2d2 100644</span>
<span class="p_header">--- a/drivers/scsi/mpt3sas/mpt3sas_base.h</span>
<span class="p_header">+++ b/drivers/scsi/mpt3sas/mpt3sas_base.h</span>
<span class="p_chunk">@@ -643,6 +643,7 @@</span> <span class="p_context"> struct chain_tracker {</span>
  * @cb_idx: callback index
  * @direct_io: To indicate whether I/O is direct (WARPDRIVE)
  * @tracker_list: list of free request (ioc-&gt;free_list)
<span class="p_add">+ * @msix_io: IO&#39;s msix</span>
  */
 struct scsiio_tracker {
 	u16	smid;
<span class="p_chunk">@@ -651,6 +652,7 @@</span> <span class="p_context"> struct scsiio_tracker {</span>
 	u8	direct_io;
 	struct list_head chain_list;
 	struct list_head tracker_list;
<span class="p_add">+	u16     msix_io;</span>
 };
 
 /**
<span class="p_chunk">@@ -1213,7 +1215,8 @@</span> <span class="p_context"> void mpt3sas_base_put_smid_scsi_io(struct MPT3SAS_ADAPTER *ioc, u16 smid,</span>
 	u16 handle);
 void mpt3sas_base_put_smid_fast_path(struct MPT3SAS_ADAPTER *ioc, u16 smid,
 	u16 handle);
<span class="p_del">-void mpt3sas_base_put_smid_hi_priority(struct MPT3SAS_ADAPTER *ioc, u16 smid);</span>
<span class="p_add">+void mpt3sas_base_put_smid_hi_priority(struct MPT3SAS_ADAPTER *ioc,</span>
<span class="p_add">+	u16 smid, u16 msix_task);</span>
 void mpt3sas_base_put_smid_default(struct MPT3SAS_ADAPTER *ioc, u16 smid);
 void mpt3sas_base_initialize_callback_handler(void);
 u8 mpt3sas_base_register_callback_handler(MPT_CALLBACK cb_func);
<span class="p_header">diff --git a/drivers/scsi/mpt3sas/mpt3sas_ctl.c b/drivers/scsi/mpt3sas/mpt3sas_ctl.c</span>
<span class="p_header">index d8366b056b70..4ccde5a05b70 100644</span>
<span class="p_header">--- a/drivers/scsi/mpt3sas/mpt3sas_ctl.c</span>
<span class="p_header">+++ b/drivers/scsi/mpt3sas/mpt3sas_ctl.c</span>
<span class="p_chunk">@@ -817,7 +817,7 @@</span> <span class="p_context"> _ctl_do_mpt_command(struct MPT3SAS_ADAPTER *ioc, struct mpt3_ioctl_command karg,</span>
 		    tm_request-&gt;DevHandle));
 		ioc-&gt;build_sg_mpi(ioc, psge, data_out_dma, data_out_sz,
 		    data_in_dma, data_in_sz);
<span class="p_del">-		mpt3sas_base_put_smid_hi_priority(ioc, smid);</span>
<span class="p_add">+		mpt3sas_base_put_smid_hi_priority(ioc, smid, 0);</span>
 		break;
 	}
 	case MPI2_FUNCTION_SMP_PASSTHROUGH:
<span class="p_header">diff --git a/drivers/scsi/mpt3sas/mpt3sas_scsih.c b/drivers/scsi/mpt3sas/mpt3sas_scsih.c</span>
<span class="p_header">index 9ab77b06434d..6180f7970bbf 100644</span>
<span class="p_header">--- a/drivers/scsi/mpt3sas/mpt3sas_scsih.c</span>
<span class="p_header">+++ b/drivers/scsi/mpt3sas/mpt3sas_scsih.c</span>
<span class="p_chunk">@@ -2193,6 +2193,7 @@</span> <span class="p_context"> mpt3sas_scsih_issue_tm(struct MPT3SAS_ADAPTER *ioc, u16 handle, uint channel,</span>
 	unsigned long timeleft;
 	struct scsiio_tracker *scsi_lookup = NULL;
 	int rc;
<span class="p_add">+	u16 msix_task = 0;</span>
 
 	if (m_type == TM_MUTEX_ON)
 		mutex_lock(&amp;ioc-&gt;tm_cmds.mutex);
<span class="p_chunk">@@ -2256,7 +2257,12 @@</span> <span class="p_context"> mpt3sas_scsih_issue_tm(struct MPT3SAS_ADAPTER *ioc, u16 handle, uint channel,</span>
 	int_to_scsilun(lun, (struct scsi_lun *)mpi_request-&gt;LUN);
 	mpt3sas_scsih_set_tm_flag(ioc, handle);
 	init_completion(&amp;ioc-&gt;tm_cmds.done);
<span class="p_del">-	mpt3sas_base_put_smid_hi_priority(ioc, smid);</span>
<span class="p_add">+	if ((type == MPI2_SCSITASKMGMT_TASKTYPE_ABORT_TASK) &amp;&amp;</span>
<span class="p_add">+			(scsi_lookup-&gt;msix_io &lt; ioc-&gt;reply_queue_count))</span>
<span class="p_add">+		msix_task = scsi_lookup-&gt;msix_io;</span>
<span class="p_add">+	else</span>
<span class="p_add">+		msix_task = 0;</span>
<span class="p_add">+	mpt3sas_base_put_smid_hi_priority(ioc, smid, msix_task);</span>
 	timeleft = wait_for_completion_timeout(&amp;ioc-&gt;tm_cmds.done, timeout*HZ);
 	if (!(ioc-&gt;tm_cmds.status &amp; MPT3_CMD_COMPLETE)) {
 		pr_err(MPT3SAS_FMT &quot;%s: timeout\n&quot;,
<span class="p_chunk">@@ -3151,7 +3157,7 @@</span> <span class="p_context"> _scsih_tm_tr_send(struct MPT3SAS_ADAPTER *ioc, u16 handle)</span>
 	mpi_request-&gt;Function = MPI2_FUNCTION_SCSI_TASK_MGMT;
 	mpi_request-&gt;DevHandle = cpu_to_le16(handle);
 	mpi_request-&gt;TaskType = MPI2_SCSITASKMGMT_TASKTYPE_TARGET_RESET;
<span class="p_del">-	mpt3sas_base_put_smid_hi_priority(ioc, smid);</span>
<span class="p_add">+	mpt3sas_base_put_smid_hi_priority(ioc, smid, 0);</span>
 	mpt3sas_trigger_master(ioc, MASTER_TRIGGER_DEVICE_REMOVAL);
 
 out:
<span class="p_chunk">@@ -3332,7 +3338,7 @@</span> <span class="p_context"> _scsih_tm_tr_volume_send(struct MPT3SAS_ADAPTER *ioc, u16 handle)</span>
 	mpi_request-&gt;Function = MPI2_FUNCTION_SCSI_TASK_MGMT;
 	mpi_request-&gt;DevHandle = cpu_to_le16(handle);
 	mpi_request-&gt;TaskType = MPI2_SCSITASKMGMT_TASKTYPE_TARGET_RESET;
<span class="p_del">-	mpt3sas_base_put_smid_hi_priority(ioc, smid);</span>
<span class="p_add">+	mpt3sas_base_put_smid_hi_priority(ioc, smid, 0);</span>
 }
 
 /**
<span class="p_header">diff --git a/drivers/scsi/qla2xxx/qla_target.c b/drivers/scsi/qla2xxx/qla_target.c</span>
<span class="p_header">index 75514a15bea0..f57d96984ae4 100644</span>
<span class="p_header">--- a/drivers/scsi/qla2xxx/qla_target.c</span>
<span class="p_header">+++ b/drivers/scsi/qla2xxx/qla_target.c</span>
<span class="p_chunk">@@ -1578,7 +1578,7 @@</span> <span class="p_context"> void qlt_xmit_tm_rsp(struct qla_tgt_mgmt_cmd *mcmd)</span>
 		qlt_send_notify_ack(vha, &amp;mcmd-&gt;orig_iocb.imm_ntfy,
 		    0, 0, 0, 0, 0, 0);
 	else {
<span class="p_del">-		if (mcmd-&gt;se_cmd.se_tmr_req-&gt;function == TMR_ABORT_TASK)</span>
<span class="p_add">+		if (mcmd-&gt;orig_iocb.atio.u.raw.entry_type == ABTS_RECV_24XX)</span>
 			qlt_24xx_send_abts_resp(vha, &amp;mcmd-&gt;orig_iocb.abts,
 			    mcmd-&gt;fc_tm_rsp, false);
 		else
<span class="p_header">diff --git a/drivers/staging/lustre/lustre/llite/llite_internal.h b/drivers/staging/lustre/lustre/llite/llite_internal.h</span>
<span class="p_header">index 9096d311e45d..c2d9b793759d 100644</span>
<span class="p_header">--- a/drivers/staging/lustre/lustre/llite/llite_internal.h</span>
<span class="p_header">+++ b/drivers/staging/lustre/lustre/llite/llite_internal.h</span>
<span class="p_chunk">@@ -631,8 +631,6 @@</span> <span class="p_context"> struct ll_file_data {</span>
 
 struct lov_stripe_md;
 
<span class="p_del">-extern spinlock_t inode_lock;</span>
<span class="p_del">-</span>
 extern struct dentry *llite_root;
 extern struct kset *llite_kset;
 
<span class="p_header">diff --git a/drivers/vhost/scsi.c b/drivers/vhost/scsi.c</span>
<span class="p_header">index 29cfc57d496e..e4110d6de0b5 100644</span>
<span class="p_header">--- a/drivers/vhost/scsi.c</span>
<span class="p_header">+++ b/drivers/vhost/scsi.c</span>
<span class="p_chunk">@@ -88,7 +88,7 @@</span> <span class="p_context"> struct vhost_scsi_cmd {</span>
 	struct scatterlist *tvc_prot_sgl;
 	struct page **tvc_upages;
 	/* Pointer to response header iovec */
<span class="p_del">-	struct iovec *tvc_resp_iov;</span>
<span class="p_add">+	struct iovec tvc_resp_iov;</span>
 	/* Pointer to vhost_scsi for our device */
 	struct vhost_scsi *tvc_vhost;
 	/* Pointer to vhost_virtqueue for the cmd */
<span class="p_chunk">@@ -557,7 +557,7 @@</span> <span class="p_context"> static void vhost_scsi_complete_cmd_work(struct vhost_work *work)</span>
 		memcpy(v_rsp.sense, cmd-&gt;tvc_sense_buf,
 		       se_cmd-&gt;scsi_sense_length);
 
<span class="p_del">-		iov_iter_init(&amp;iov_iter, READ, cmd-&gt;tvc_resp_iov,</span>
<span class="p_add">+		iov_iter_init(&amp;iov_iter, READ, &amp;cmd-&gt;tvc_resp_iov,</span>
 			      cmd-&gt;tvc_in_iovs, sizeof(v_rsp));
 		ret = copy_to_iter(&amp;v_rsp, sizeof(v_rsp), &amp;iov_iter);
 		if (likely(ret == sizeof(v_rsp))) {
<span class="p_chunk">@@ -1054,7 +1054,7 @@</span> <span class="p_context"> vhost_scsi_handle_vq(struct vhost_scsi *vs, struct vhost_virtqueue *vq)</span>
 		}
 		cmd-&gt;tvc_vhost = vs;
 		cmd-&gt;tvc_vq = vq;
<span class="p_del">-		cmd-&gt;tvc_resp_iov = &amp;vq-&gt;iov[out];</span>
<span class="p_add">+		cmd-&gt;tvc_resp_iov = vq-&gt;iov[out];</span>
 		cmd-&gt;tvc_in_iovs = in;
 
 		pr_debug(&quot;vhost_scsi got command opcode: %#02x, lun: %d\n&quot;,
<span class="p_header">diff --git a/fs/btrfs/file.c b/fs/btrfs/file.c</span>
<span class="p_header">index 5e5db3687e34..353f4bae658c 100644</span>
<span class="p_header">--- a/fs/btrfs/file.c</span>
<span class="p_header">+++ b/fs/btrfs/file.c</span>
<span class="p_chunk">@@ -1526,27 +1526,24 @@</span> <span class="p_context"> static noinline ssize_t __btrfs_buffered_write(struct file *file,</span>
 
 		reserve_bytes = num_pages &lt;&lt; PAGE_CACHE_SHIFT;
 
<span class="p_del">-		if (BTRFS_I(inode)-&gt;flags &amp; (BTRFS_INODE_NODATACOW |</span>
<span class="p_del">-					     BTRFS_INODE_PREALLOC)) {</span>
<span class="p_del">-			ret = check_can_nocow(inode, pos, &amp;write_bytes);</span>
<span class="p_del">-			if (ret &lt; 0)</span>
<span class="p_del">-				break;</span>
<span class="p_del">-			if (ret &gt; 0) {</span>
<span class="p_del">-				/*</span>
<span class="p_del">-				 * For nodata cow case, no need to reserve</span>
<span class="p_del">-				 * data space.</span>
<span class="p_del">-				 */</span>
<span class="p_del">-				only_release_metadata = true;</span>
<span class="p_del">-				/*</span>
<span class="p_del">-				 * our prealloc extent may be smaller than</span>
<span class="p_del">-				 * write_bytes, so scale down.</span>
<span class="p_del">-				 */</span>
<span class="p_del">-				num_pages = DIV_ROUND_UP(write_bytes + offset,</span>
<span class="p_del">-							 PAGE_CACHE_SIZE);</span>
<span class="p_del">-				reserve_bytes = num_pages &lt;&lt; PAGE_CACHE_SHIFT;</span>
<span class="p_del">-				goto reserve_metadata;</span>
<span class="p_del">-			}</span>
<span class="p_add">+		if ((BTRFS_I(inode)-&gt;flags &amp; (BTRFS_INODE_NODATACOW |</span>
<span class="p_add">+					      BTRFS_INODE_PREALLOC)) &amp;&amp;</span>
<span class="p_add">+		    check_can_nocow(inode, pos, &amp;write_bytes) &gt; 0) {</span>
<span class="p_add">+			/*</span>
<span class="p_add">+			 * For nodata cow case, no need to reserve</span>
<span class="p_add">+			 * data space.</span>
<span class="p_add">+			 */</span>
<span class="p_add">+			only_release_metadata = true;</span>
<span class="p_add">+			/*</span>
<span class="p_add">+			 * our prealloc extent may be smaller than</span>
<span class="p_add">+			 * write_bytes, so scale down.</span>
<span class="p_add">+			 */</span>
<span class="p_add">+			num_pages = DIV_ROUND_UP(write_bytes + offset,</span>
<span class="p_add">+						 PAGE_CACHE_SIZE);</span>
<span class="p_add">+			reserve_bytes = num_pages &lt;&lt; PAGE_CACHE_SHIFT;</span>
<span class="p_add">+			goto reserve_metadata;</span>
 		}
<span class="p_add">+</span>
 		ret = btrfs_check_data_free_space(inode, pos, write_bytes);
 		if (ret &lt; 0)
 			break;
<span class="p_header">diff --git a/fs/ecryptfs/file.c b/fs/ecryptfs/file.c</span>
<span class="p_header">index 11309683d65f..27794b137b24 100644</span>
<span class="p_header">--- a/fs/ecryptfs/file.c</span>
<span class="p_header">+++ b/fs/ecryptfs/file.c</span>
<span class="p_chunk">@@ -112,7 +112,6 @@</span> <span class="p_context"> static int ecryptfs_readdir(struct file *file, struct dir_context *ctx)</span>
 		.sb = inode-&gt;i_sb,
 	};
 	lower_file = ecryptfs_file_to_lower(file);
<span class="p_del">-	lower_file-&gt;f_pos = ctx-&gt;pos;</span>
 	rc = iterate_dir(lower_file, &amp;buf.ctx);
 	ctx-&gt;pos = buf.ctx.pos;
 	if (rc &lt; 0)
<span class="p_chunk">@@ -236,14 +235,6 @@</span> <span class="p_context"> static int ecryptfs_open(struct inode *inode, struct file *file)</span>
 	}
 	ecryptfs_set_file_lower(
 		file, ecryptfs_inode_to_private(inode)-&gt;lower_file);
<span class="p_del">-	if (d_is_dir(ecryptfs_dentry)) {</span>
<span class="p_del">-		ecryptfs_printk(KERN_DEBUG, &quot;This is a directory\n&quot;);</span>
<span class="p_del">-		mutex_lock(&amp;crypt_stat-&gt;cs_mutex);</span>
<span class="p_del">-		crypt_stat-&gt;flags &amp;= ~(ECRYPTFS_ENCRYPTED);</span>
<span class="p_del">-		mutex_unlock(&amp;crypt_stat-&gt;cs_mutex);</span>
<span class="p_del">-		rc = 0;</span>
<span class="p_del">-		goto out;</span>
<span class="p_del">-	}</span>
 	rc = read_or_initialize_metadata(ecryptfs_dentry);
 	if (rc)
 		goto out_put;
<span class="p_chunk">@@ -260,6 +251,45 @@</span> <span class="p_context"> out:</span>
 	return rc;
 }
 
<span class="p_add">+/**</span>
<span class="p_add">+ * ecryptfs_dir_open</span>
<span class="p_add">+ * @inode: inode speciying file to open</span>
<span class="p_add">+ * @file: Structure to return filled in</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * Opens the file specified by inode.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * Returns zero on success; non-zero otherwise</span>
<span class="p_add">+ */</span>
<span class="p_add">+static int ecryptfs_dir_open(struct inode *inode, struct file *file)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct dentry *ecryptfs_dentry = file-&gt;f_path.dentry;</span>
<span class="p_add">+	/* Private value of ecryptfs_dentry allocated in</span>
<span class="p_add">+	 * ecryptfs_lookup() */</span>
<span class="p_add">+	struct ecryptfs_file_info *file_info;</span>
<span class="p_add">+	struct file *lower_file;</span>
<span class="p_add">+</span>
<span class="p_add">+	/* Released in ecryptfs_release or end of function if failure */</span>
<span class="p_add">+	file_info = kmem_cache_zalloc(ecryptfs_file_info_cache, GFP_KERNEL);</span>
<span class="p_add">+	ecryptfs_set_file_private(file, file_info);</span>
<span class="p_add">+	if (unlikely(!file_info)) {</span>
<span class="p_add">+		ecryptfs_printk(KERN_ERR,</span>
<span class="p_add">+				&quot;Error attempting to allocate memory\n&quot;);</span>
<span class="p_add">+		return -ENOMEM;</span>
<span class="p_add">+	}</span>
<span class="p_add">+	lower_file = dentry_open(ecryptfs_dentry_to_lower_path(ecryptfs_dentry),</span>
<span class="p_add">+				 file-&gt;f_flags, current_cred());</span>
<span class="p_add">+	if (IS_ERR(lower_file)) {</span>
<span class="p_add">+		printk(KERN_ERR &quot;%s: Error attempting to initialize &quot;</span>
<span class="p_add">+			&quot;the lower file for the dentry with name &quot;</span>
<span class="p_add">+			&quot;[%pd]; rc = [%ld]\n&quot;, __func__,</span>
<span class="p_add">+			ecryptfs_dentry, PTR_ERR(lower_file));</span>
<span class="p_add">+		kmem_cache_free(ecryptfs_file_info_cache, file_info);</span>
<span class="p_add">+		return PTR_ERR(lower_file);</span>
<span class="p_add">+	}</span>
<span class="p_add">+	ecryptfs_set_file_lower(file, lower_file);</span>
<span class="p_add">+	return 0;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static int ecryptfs_flush(struct file *file, fl_owner_t td)
 {
 	struct file *lower_file = ecryptfs_file_to_lower(file);
<span class="p_chunk">@@ -280,6 +310,19 @@</span> <span class="p_context"> static int ecryptfs_release(struct inode *inode, struct file *file)</span>
 	return 0;
 }
 
<span class="p_add">+static int ecryptfs_dir_release(struct inode *inode, struct file *file)</span>
<span class="p_add">+{</span>
<span class="p_add">+	fput(ecryptfs_file_to_lower(file));</span>
<span class="p_add">+	kmem_cache_free(ecryptfs_file_info_cache,</span>
<span class="p_add">+			ecryptfs_file_to_private(file));</span>
<span class="p_add">+	return 0;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static loff_t ecryptfs_dir_llseek(struct file *file, loff_t offset, int whence)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return vfs_llseek(ecryptfs_file_to_lower(file), offset, whence);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static int
 ecryptfs_fsync(struct file *file, loff_t start, loff_t end, int datasync)
 {
<span class="p_chunk">@@ -359,20 +402,16 @@</span> <span class="p_context"> const struct file_operations ecryptfs_dir_fops = {</span>
 #ifdef CONFIG_COMPAT
 	.compat_ioctl = ecryptfs_compat_ioctl,
 #endif
<span class="p_del">-	.open = ecryptfs_open,</span>
<span class="p_del">-	.flush = ecryptfs_flush,</span>
<span class="p_del">-	.release = ecryptfs_release,</span>
<span class="p_add">+	.open = ecryptfs_dir_open,</span>
<span class="p_add">+	.release = ecryptfs_dir_release,</span>
 	.fsync = ecryptfs_fsync,
<span class="p_del">-	.fasync = ecryptfs_fasync,</span>
<span class="p_del">-	.splice_read = generic_file_splice_read,</span>
<span class="p_del">-	.llseek = default_llseek,</span>
<span class="p_add">+	.llseek = ecryptfs_dir_llseek,</span>
 };
 
 const struct file_operations ecryptfs_main_fops = {
 	.llseek = generic_file_llseek,
 	.read_iter = ecryptfs_read_update_atime,
 	.write_iter = generic_file_write_iter,
<span class="p_del">-	.iterate = ecryptfs_readdir,</span>
 	.unlocked_ioctl = ecryptfs_unlocked_ioctl,
 #ifdef CONFIG_COMPAT
 	.compat_ioctl = ecryptfs_compat_ioctl,
<span class="p_header">diff --git a/fs/ext4/inode.c b/fs/ext4/inode.c</span>
<span class="p_header">index 9a5ad0f0d3ed..28702932a908 100644</span>
<span class="p_header">--- a/fs/ext4/inode.c</span>
<span class="p_header">+++ b/fs/ext4/inode.c</span>
<span class="p_chunk">@@ -51,25 +51,31 @@</span> <span class="p_context"> static __u32 ext4_inode_csum(struct inode *inode, struct ext4_inode *raw,</span>
 			      struct ext4_inode_info *ei)
 {
 	struct ext4_sb_info *sbi = EXT4_SB(inode-&gt;i_sb);
<span class="p_del">-	__u16 csum_lo;</span>
<span class="p_del">-	__u16 csum_hi = 0;</span>
 	__u32 csum;
<span class="p_add">+	__u16 dummy_csum = 0;</span>
<span class="p_add">+	int offset = offsetof(struct ext4_inode, i_checksum_lo);</span>
<span class="p_add">+	unsigned int csum_size = sizeof(dummy_csum);</span>
 
<span class="p_del">-	csum_lo = le16_to_cpu(raw-&gt;i_checksum_lo);</span>
<span class="p_del">-	raw-&gt;i_checksum_lo = 0;</span>
<span class="p_del">-	if (EXT4_INODE_SIZE(inode-&gt;i_sb) &gt; EXT4_GOOD_OLD_INODE_SIZE &amp;&amp;</span>
<span class="p_del">-	    EXT4_FITS_IN_INODE(raw, ei, i_checksum_hi)) {</span>
<span class="p_del">-		csum_hi = le16_to_cpu(raw-&gt;i_checksum_hi);</span>
<span class="p_del">-		raw-&gt;i_checksum_hi = 0;</span>
<span class="p_del">-	}</span>
<span class="p_add">+	csum = ext4_chksum(sbi, ei-&gt;i_csum_seed, (__u8 *)raw, offset);</span>
<span class="p_add">+	csum = ext4_chksum(sbi, csum, (__u8 *)&amp;dummy_csum, csum_size);</span>
<span class="p_add">+	offset += csum_size;</span>
<span class="p_add">+	csum = ext4_chksum(sbi, csum, (__u8 *)raw + offset,</span>
<span class="p_add">+			   EXT4_GOOD_OLD_INODE_SIZE - offset);</span>
 
<span class="p_del">-	csum = ext4_chksum(sbi, ei-&gt;i_csum_seed, (__u8 *)raw,</span>
<span class="p_del">-			   EXT4_INODE_SIZE(inode-&gt;i_sb));</span>
<span class="p_del">-</span>
<span class="p_del">-	raw-&gt;i_checksum_lo = cpu_to_le16(csum_lo);</span>
<span class="p_del">-	if (EXT4_INODE_SIZE(inode-&gt;i_sb) &gt; EXT4_GOOD_OLD_INODE_SIZE &amp;&amp;</span>
<span class="p_del">-	    EXT4_FITS_IN_INODE(raw, ei, i_checksum_hi))</span>
<span class="p_del">-		raw-&gt;i_checksum_hi = cpu_to_le16(csum_hi);</span>
<span class="p_add">+	if (EXT4_INODE_SIZE(inode-&gt;i_sb) &gt; EXT4_GOOD_OLD_INODE_SIZE) {</span>
<span class="p_add">+		offset = offsetof(struct ext4_inode, i_checksum_hi);</span>
<span class="p_add">+		csum = ext4_chksum(sbi, csum, (__u8 *)raw +</span>
<span class="p_add">+				   EXT4_GOOD_OLD_INODE_SIZE,</span>
<span class="p_add">+				   offset - EXT4_GOOD_OLD_INODE_SIZE);</span>
<span class="p_add">+		if (EXT4_FITS_IN_INODE(raw, ei, i_checksum_hi)) {</span>
<span class="p_add">+			csum = ext4_chksum(sbi, csum, (__u8 *)&amp;dummy_csum,</span>
<span class="p_add">+					   csum_size);</span>
<span class="p_add">+			offset += csum_size;</span>
<span class="p_add">+			csum = ext4_chksum(sbi, csum, (__u8 *)raw + offset,</span>
<span class="p_add">+					   EXT4_INODE_SIZE(inode-&gt;i_sb) -</span>
<span class="p_add">+					   offset);</span>
<span class="p_add">+		}</span>
<span class="p_add">+	}</span>
 
 	return csum;
 }
<span class="p_chunk">@@ -5186,8 +5192,6 @@</span> <span class="p_context"> int ext4_mark_inode_dirty(handle_t *handle, struct inode *inode)</span>
 						      sbi-&gt;s_want_extra_isize,
 						      iloc, handle);
 			if (ret) {
<span class="p_del">-				ext4_set_inode_state(inode,</span>
<span class="p_del">-						     EXT4_STATE_NO_EXPAND);</span>
 				if (mnt_count !=
 					le16_to_cpu(sbi-&gt;s_es-&gt;s_mnt_count)) {
 					ext4_warning(inode-&gt;i_sb,
<span class="p_header">diff --git a/fs/ext4/namei.c b/fs/ext4/namei.c</span>
<span class="p_header">index 91bf36f22dbf..38eb0c8e43b9 100644</span>
<span class="p_header">--- a/fs/ext4/namei.c</span>
<span class="p_header">+++ b/fs/ext4/namei.c</span>
<span class="p_chunk">@@ -420,15 +420,14 @@</span> <span class="p_context"> static __le32 ext4_dx_csum(struct inode *inode, struct ext4_dir_entry *dirent,</span>
 	struct ext4_sb_info *sbi = EXT4_SB(inode-&gt;i_sb);
 	struct ext4_inode_info *ei = EXT4_I(inode);
 	__u32 csum;
<span class="p_del">-	__le32 save_csum;</span>
 	int size;
<span class="p_add">+	__u32 dummy_csum = 0;</span>
<span class="p_add">+	int offset = offsetof(struct dx_tail, dt_checksum);</span>
 
 	size = count_offset + (count * sizeof(struct dx_entry));
<span class="p_del">-	save_csum = t-&gt;dt_checksum;</span>
<span class="p_del">-	t-&gt;dt_checksum = 0;</span>
 	csum = ext4_chksum(sbi, ei-&gt;i_csum_seed, (__u8 *)dirent, size);
<span class="p_del">-	csum = ext4_chksum(sbi, csum, (__u8 *)t, sizeof(struct dx_tail));</span>
<span class="p_del">-	t-&gt;dt_checksum = save_csum;</span>
<span class="p_add">+	csum = ext4_chksum(sbi, csum, (__u8 *)t, offset);</span>
<span class="p_add">+	csum = ext4_chksum(sbi, csum, (__u8 *)&amp;dummy_csum, sizeof(dummy_csum));</span>
 
 	return cpu_to_le32(csum);
 }
<span class="p_header">diff --git a/fs/ext4/super.c b/fs/ext4/super.c</span>
<span class="p_header">index c542ebcf7a92..5bab28caa9d4 100644</span>
<span class="p_header">--- a/fs/ext4/super.c</span>
<span class="p_header">+++ b/fs/ext4/super.c</span>
<span class="p_chunk">@@ -2030,23 +2030,25 @@</span> <span class="p_context"> failed:</span>
 static __le16 ext4_group_desc_csum(struct super_block *sb, __u32 block_group,
 				   struct ext4_group_desc *gdp)
 {
<span class="p_del">-	int offset;</span>
<span class="p_add">+	int offset = offsetof(struct ext4_group_desc, bg_checksum);</span>
 	__u16 crc = 0;
 	__le32 le_group = cpu_to_le32(block_group);
 	struct ext4_sb_info *sbi = EXT4_SB(sb);
 
 	if (ext4_has_metadata_csum(sbi-&gt;s_sb)) {
 		/* Use new metadata_csum algorithm */
<span class="p_del">-		__le16 save_csum;</span>
 		__u32 csum32;
<span class="p_add">+		__u16 dummy_csum = 0;</span>
 
<span class="p_del">-		save_csum = gdp-&gt;bg_checksum;</span>
<span class="p_del">-		gdp-&gt;bg_checksum = 0;</span>
 		csum32 = ext4_chksum(sbi, sbi-&gt;s_csum_seed, (__u8 *)&amp;le_group,
 				     sizeof(le_group));
<span class="p_del">-		csum32 = ext4_chksum(sbi, csum32, (__u8 *)gdp,</span>
<span class="p_del">-				     sbi-&gt;s_desc_size);</span>
<span class="p_del">-		gdp-&gt;bg_checksum = save_csum;</span>
<span class="p_add">+		csum32 = ext4_chksum(sbi, csum32, (__u8 *)gdp, offset);</span>
<span class="p_add">+		csum32 = ext4_chksum(sbi, csum32, (__u8 *)&amp;dummy_csum,</span>
<span class="p_add">+				     sizeof(dummy_csum));</span>
<span class="p_add">+		offset += sizeof(dummy_csum);</span>
<span class="p_add">+		if (offset &lt; sbi-&gt;s_desc_size)</span>
<span class="p_add">+			csum32 = ext4_chksum(sbi, csum32, (__u8 *)gdp + offset,</span>
<span class="p_add">+					     sbi-&gt;s_desc_size - offset);</span>
 
 		crc = csum32 &amp; 0xFFFF;
 		goto out;
<span class="p_chunk">@@ -2056,8 +2058,6 @@</span> <span class="p_context"> static __le16 ext4_group_desc_csum(struct super_block *sb, __u32 block_group,</span>
 	if (!ext4_has_feature_gdt_csum(sb))
 		return 0;
 
<span class="p_del">-	offset = offsetof(struct ext4_group_desc, bg_checksum);</span>
<span class="p_del">-</span>
 	crc = crc16(~0, sbi-&gt;s_es-&gt;s_uuid, sizeof(sbi-&gt;s_es-&gt;s_uuid));
 	crc = crc16(crc, (__u8 *)&amp;le_group, sizeof(le_group));
 	crc = crc16(crc, (__u8 *)gdp, offset);
<span class="p_chunk">@@ -2093,6 +2093,7 @@</span> <span class="p_context"> void ext4_group_desc_csum_set(struct super_block *sb, __u32 block_group,</span>
 
 /* Called at mount-time, super-block is locked */
 static int ext4_check_descriptors(struct super_block *sb,
<span class="p_add">+				  ext4_fsblk_t sb_block,</span>
 				  ext4_group_t *first_not_zeroed)
 {
 	struct ext4_sb_info *sbi = EXT4_SB(sb);
<span class="p_chunk">@@ -2123,6 +2124,11 @@</span> <span class="p_context"> static int ext4_check_descriptors(struct super_block *sb,</span>
 			grp = i;
 
 		block_bitmap = ext4_block_bitmap(sb, gdp);
<span class="p_add">+		if (block_bitmap == sb_block) {</span>
<span class="p_add">+			ext4_msg(sb, KERN_ERR, &quot;ext4_check_descriptors: &quot;</span>
<span class="p_add">+				 &quot;Block bitmap for group %u overlaps &quot;</span>
<span class="p_add">+				 &quot;superblock&quot;, i);</span>
<span class="p_add">+		}</span>
 		if (block_bitmap &lt; first_block || block_bitmap &gt; last_block) {
 			ext4_msg(sb, KERN_ERR, &quot;ext4_check_descriptors: &quot;
 			       &quot;Block bitmap for group %u not in group &quot;
<span class="p_chunk">@@ -2130,6 +2136,11 @@</span> <span class="p_context"> static int ext4_check_descriptors(struct super_block *sb,</span>
 			return 0;
 		}
 		inode_bitmap = ext4_inode_bitmap(sb, gdp);
<span class="p_add">+		if (inode_bitmap == sb_block) {</span>
<span class="p_add">+			ext4_msg(sb, KERN_ERR, &quot;ext4_check_descriptors: &quot;</span>
<span class="p_add">+				 &quot;Inode bitmap for group %u overlaps &quot;</span>
<span class="p_add">+				 &quot;superblock&quot;, i);</span>
<span class="p_add">+		}</span>
 		if (inode_bitmap &lt; first_block || inode_bitmap &gt; last_block) {
 			ext4_msg(sb, KERN_ERR, &quot;ext4_check_descriptors: &quot;
 			       &quot;Inode bitmap for group %u not in group &quot;
<span class="p_chunk">@@ -2137,6 +2148,11 @@</span> <span class="p_context"> static int ext4_check_descriptors(struct super_block *sb,</span>
 			return 0;
 		}
 		inode_table = ext4_inode_table(sb, gdp);
<span class="p_add">+		if (inode_table == sb_block) {</span>
<span class="p_add">+			ext4_msg(sb, KERN_ERR, &quot;ext4_check_descriptors: &quot;</span>
<span class="p_add">+				 &quot;Inode table for group %u overlaps &quot;</span>
<span class="p_add">+				 &quot;superblock&quot;, i);</span>
<span class="p_add">+		}</span>
 		if (inode_table &lt; first_block ||
 		    inode_table + sbi-&gt;s_itb_per_group - 1 &gt; last_block) {
 			ext4_msg(sb, KERN_ERR, &quot;ext4_check_descriptors: &quot;
<span class="p_chunk">@@ -3640,7 +3656,7 @@</span> <span class="p_context"> static int ext4_fill_super(struct super_block *sb, void *data, int silent)</span>
 			goto failed_mount2;
 		}
 	}
<span class="p_del">-	if (!ext4_check_descriptors(sb, &amp;first_not_zeroed)) {</span>
<span class="p_add">+	if (!ext4_check_descriptors(sb, logical_sb_block, &amp;first_not_zeroed)) {</span>
 		ext4_msg(sb, KERN_ERR, &quot;group descriptors corrupted!&quot;);
 		ret = -EFSCORRUPTED;
 		goto failed_mount2;
<span class="p_header">diff --git a/fs/ext4/xattr.c b/fs/ext4/xattr.c</span>
<span class="p_header">index 6b6b3e751f8c..263002f0389d 100644</span>
<span class="p_header">--- a/fs/ext4/xattr.c</span>
<span class="p_header">+++ b/fs/ext4/xattr.c</span>
<span class="p_chunk">@@ -123,17 +123,18 @@</span> <span class="p_context"> static __le32 ext4_xattr_block_csum(struct inode *inode,</span>
 {
 	struct ext4_sb_info *sbi = EXT4_SB(inode-&gt;i_sb);
 	__u32 csum;
<span class="p_del">-	__le32 save_csum;</span>
 	__le64 dsk_block_nr = cpu_to_le64(block_nr);
<span class="p_add">+	__u32 dummy_csum = 0;</span>
<span class="p_add">+	int offset = offsetof(struct ext4_xattr_header, h_checksum);</span>
 
<span class="p_del">-	save_csum = hdr-&gt;h_checksum;</span>
<span class="p_del">-	hdr-&gt;h_checksum = 0;</span>
 	csum = ext4_chksum(sbi, sbi-&gt;s_csum_seed, (__u8 *)&amp;dsk_block_nr,
 			   sizeof(dsk_block_nr));
<span class="p_del">-	csum = ext4_chksum(sbi, csum, (__u8 *)hdr,</span>
<span class="p_del">-			   EXT4_BLOCK_SIZE(inode-&gt;i_sb));</span>
<span class="p_add">+	csum = ext4_chksum(sbi, csum, (__u8 *)hdr, offset);</span>
<span class="p_add">+	csum = ext4_chksum(sbi, csum, (__u8 *)&amp;dummy_csum, sizeof(dummy_csum));</span>
<span class="p_add">+	offset += sizeof(dummy_csum);</span>
<span class="p_add">+	csum = ext4_chksum(sbi, csum, (__u8 *)hdr + offset,</span>
<span class="p_add">+			   EXT4_BLOCK_SIZE(inode-&gt;i_sb) - offset);</span>
 
<span class="p_del">-	hdr-&gt;h_checksum = save_csum;</span>
 	return cpu_to_le32(csum);
 }
 
<span class="p_chunk">@@ -1264,15 +1265,19 @@</span> <span class="p_context"> int ext4_expand_extra_isize_ea(struct inode *inode, int new_extra_isize,</span>
 	size_t min_offs, free;
 	int total_ino;
 	void *base, *start, *end;
<span class="p_del">-	int extra_isize = 0, error = 0, tried_min_extra_isize = 0;</span>
<span class="p_add">+	int error = 0, tried_min_extra_isize = 0;</span>
 	int s_min_extra_isize = le16_to_cpu(EXT4_SB(inode-&gt;i_sb)-&gt;s_es-&gt;s_min_extra_isize);
<span class="p_add">+	int isize_diff;	/* How much do we need to grow i_extra_isize */</span>
 
 	down_write(&amp;EXT4_I(inode)-&gt;xattr_sem);
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Set EXT4_STATE_NO_EXPAND to avoid recursion when marking inode dirty</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	ext4_set_inode_state(inode, EXT4_STATE_NO_EXPAND);</span>
 retry:
<span class="p_del">-	if (EXT4_I(inode)-&gt;i_extra_isize &gt;= new_extra_isize) {</span>
<span class="p_del">-		up_write(&amp;EXT4_I(inode)-&gt;xattr_sem);</span>
<span class="p_del">-		return 0;</span>
<span class="p_del">-	}</span>
<span class="p_add">+	isize_diff = new_extra_isize - EXT4_I(inode)-&gt;i_extra_isize;</span>
<span class="p_add">+	if (EXT4_I(inode)-&gt;i_extra_isize &gt;= new_extra_isize)</span>
<span class="p_add">+		goto out;</span>
 
 	header = IHDR(inode, raw_inode);
 	entry = IFIRST(header);
<span class="p_chunk">@@ -1289,7 +1294,7 @@</span> <span class="p_context"> retry:</span>
 	total_ino = sizeof(struct ext4_xattr_ibody_header);
 
 	free = ext4_xattr_free_space(last, &amp;min_offs, base, &amp;total_ino);
<span class="p_del">-	if (free &gt;= new_extra_isize) {</span>
<span class="p_add">+	if (free &gt;= isize_diff) {</span>
 		entry = IFIRST(header);
 		ext4_xattr_shift_entries(entry,	EXT4_I(inode)-&gt;i_extra_isize
 				- new_extra_isize, (void *)raw_inode +
<span class="p_chunk">@@ -1297,8 +1302,7 @@</span> <span class="p_context"> retry:</span>
 				(void *)header, total_ino,
 				inode-&gt;i_sb-&gt;s_blocksize);
 		EXT4_I(inode)-&gt;i_extra_isize = new_extra_isize;
<span class="p_del">-		error = 0;</span>
<span class="p_del">-		goto cleanup;</span>
<span class="p_add">+		goto out;</span>
 	}
 
 	/*
<span class="p_chunk">@@ -1321,7 +1325,7 @@</span> <span class="p_context"> retry:</span>
 		end = bh-&gt;b_data + bh-&gt;b_size;
 		min_offs = end - base;
 		free = ext4_xattr_free_space(first, &amp;min_offs, base, NULL);
<span class="p_del">-		if (free &lt; new_extra_isize) {</span>
<span class="p_add">+		if (free &lt; isize_diff) {</span>
 			if (!tried_min_extra_isize &amp;&amp; s_min_extra_isize) {
 				tried_min_extra_isize++;
 				new_extra_isize = s_min_extra_isize;
<span class="p_chunk">@@ -1335,7 +1339,7 @@</span> <span class="p_context"> retry:</span>
 		free = inode-&gt;i_sb-&gt;s_blocksize;
 	}
 
<span class="p_del">-	while (new_extra_isize &gt; 0) {</span>
<span class="p_add">+	while (isize_diff &gt; 0) {</span>
 		size_t offs, size, entry_size;
 		struct ext4_xattr_entry *small_entry = NULL;
 		struct ext4_xattr_info i = {
<span class="p_chunk">@@ -1366,7 +1370,7 @@</span> <span class="p_context"> retry:</span>
 			EXT4_XATTR_SIZE(le32_to_cpu(last-&gt;e_value_size)) +
 					EXT4_XATTR_LEN(last-&gt;e_name_len);
 			if (total_size &lt;= free &amp;&amp; total_size &lt; min_total_size) {
<span class="p_del">-				if (total_size &lt; new_extra_isize) {</span>
<span class="p_add">+				if (total_size &lt; isize_diff) {</span>
 					small_entry = last;
 				} else {
 					entry = last;
<span class="p_chunk">@@ -1421,22 +1425,22 @@</span> <span class="p_context"> retry:</span>
 		error = ext4_xattr_ibody_set(handle, inode, &amp;i, is);
 		if (error)
 			goto cleanup;
<span class="p_add">+		total_ino -= entry_size;</span>
 
 		entry = IFIRST(header);
<span class="p_del">-		if (entry_size + EXT4_XATTR_SIZE(size) &gt;= new_extra_isize)</span>
<span class="p_del">-			shift_bytes = new_extra_isize;</span>
<span class="p_add">+		if (entry_size + EXT4_XATTR_SIZE(size) &gt;= isize_diff)</span>
<span class="p_add">+			shift_bytes = isize_diff;</span>
 		else
<span class="p_del">-			shift_bytes = entry_size + size;</span>
<span class="p_add">+			shift_bytes = entry_size + EXT4_XATTR_SIZE(size);</span>
 		/* Adjust the offsets and shift the remaining entries ahead */
<span class="p_del">-		ext4_xattr_shift_entries(entry, EXT4_I(inode)-&gt;i_extra_isize -</span>
<span class="p_del">-			shift_bytes, (void *)raw_inode +</span>
<span class="p_del">-			EXT4_GOOD_OLD_INODE_SIZE + extra_isize + shift_bytes,</span>
<span class="p_del">-			(void *)header, total_ino - entry_size,</span>
<span class="p_del">-			inode-&gt;i_sb-&gt;s_blocksize);</span>
<span class="p_add">+		ext4_xattr_shift_entries(entry, -shift_bytes,</span>
<span class="p_add">+			(void *)raw_inode + EXT4_GOOD_OLD_INODE_SIZE +</span>
<span class="p_add">+			EXT4_I(inode)-&gt;i_extra_isize + shift_bytes,</span>
<span class="p_add">+			(void *)header, total_ino, inode-&gt;i_sb-&gt;s_blocksize);</span>
 
<span class="p_del">-		extra_isize += shift_bytes;</span>
<span class="p_del">-		new_extra_isize -= shift_bytes;</span>
<span class="p_del">-		EXT4_I(inode)-&gt;i_extra_isize = extra_isize;</span>
<span class="p_add">+		isize_diff -= shift_bytes;</span>
<span class="p_add">+		EXT4_I(inode)-&gt;i_extra_isize += shift_bytes;</span>
<span class="p_add">+		header = IHDR(inode, raw_inode);</span>
 
 		i.name = b_entry_name;
 		i.value = buffer;
<span class="p_chunk">@@ -1458,6 +1462,8 @@</span> <span class="p_context"> retry:</span>
 		kfree(bs);
 	}
 	brelse(bh);
<span class="p_add">+out:</span>
<span class="p_add">+	ext4_clear_inode_state(inode, EXT4_STATE_NO_EXPAND);</span>
 	up_write(&amp;EXT4_I(inode)-&gt;xattr_sem);
 	return 0;
 
<span class="p_chunk">@@ -1469,6 +1475,10 @@</span> <span class="p_context"> cleanup:</span>
 	kfree(is);
 	kfree(bs);
 	brelse(bh);
<span class="p_add">+	/*</span>
<span class="p_add">+	 * We deliberately leave EXT4_STATE_NO_EXPAND set here since inode</span>
<span class="p_add">+	 * size expansion failed.</span>
<span class="p_add">+	 */</span>
 	up_write(&amp;EXT4_I(inode)-&gt;xattr_sem);
 	return error;
 }
<span class="p_header">diff --git a/fs/namei.c b/fs/namei.c</span>
<span class="p_header">index 209ca7737cb2..0b0acba72a71 100644</span>
<span class="p_header">--- a/fs/namei.c</span>
<span class="p_header">+++ b/fs/namei.c</span>
<span class="p_chunk">@@ -887,6 +887,7 @@</span> <span class="p_context"> static inline int may_follow_link(struct nameidata *nd)</span>
 {
 	const struct inode *inode;
 	const struct inode *parent;
<span class="p_add">+	kuid_t puid;</span>
 
 	if (!sysctl_protected_symlinks)
 		return 0;
<span class="p_chunk">@@ -902,7 +903,8 @@</span> <span class="p_context"> static inline int may_follow_link(struct nameidata *nd)</span>
 		return 0;
 
 	/* Allowed if parent directory and link owner match. */
<span class="p_del">-	if (uid_eq(parent-&gt;i_uid, inode-&gt;i_uid))</span>
<span class="p_add">+	puid = parent-&gt;i_uid;</span>
<span class="p_add">+	if (uid_valid(puid) &amp;&amp; uid_eq(puid, inode-&gt;i_uid))</span>
 		return 0;
 
 	if (nd-&gt;flags &amp; LOOKUP_RCU)
<span class="p_header">diff --git a/fs/overlayfs/copy_up.c b/fs/overlayfs/copy_up.c</span>
<span class="p_header">index eff6319d5037..9e52609cd683 100644</span>
<span class="p_header">--- a/fs/overlayfs/copy_up.c</span>
<span class="p_header">+++ b/fs/overlayfs/copy_up.c</span>
<span class="p_chunk">@@ -48,6 +48,8 @@</span> <span class="p_context"> int ovl_copy_xattr(struct dentry *old, struct dentry *new)</span>
 	}
 
 	for (name = buf; name &lt; (buf + list_size); name += strlen(name) + 1) {
<span class="p_add">+		if (ovl_is_private_xattr(name))</span>
<span class="p_add">+			continue;</span>
 retry:
 		size = vfs_getxattr(old, name, value, value_size);
 		if (size == -ERANGE)
<span class="p_header">diff --git a/fs/overlayfs/inode.c b/fs/overlayfs/inode.c</span>
<span class="p_header">index 4f729ffff75d..220b04f04523 100644</span>
<span class="p_header">--- a/fs/overlayfs/inode.c</span>
<span class="p_header">+++ b/fs/overlayfs/inode.c</span>
<span class="p_chunk">@@ -219,7 +219,7 @@</span> <span class="p_context"> static int ovl_readlink(struct dentry *dentry, char __user *buf, int bufsiz)</span>
 }
 
 
<span class="p_del">-static bool ovl_is_private_xattr(const char *name)</span>
<span class="p_add">+bool ovl_is_private_xattr(const char *name)</span>
 {
 	return strncmp(name, OVL_XATTR_PRE_NAME, OVL_XATTR_PRE_LEN) == 0;
 }
<span class="p_chunk">@@ -277,7 +277,8 @@</span> <span class="p_context"> ssize_t ovl_listxattr(struct dentry *dentry, char *list, size_t size)</span>
 	struct path realpath;
 	enum ovl_path_type type = ovl_path_real(dentry, &amp;realpath);
 	ssize_t res;
<span class="p_del">-	int off;</span>
<span class="p_add">+	size_t len;</span>
<span class="p_add">+	char *s;</span>
 
 	res = vfs_listxattr(realpath.dentry, list, size);
 	if (res &lt;= 0 || size == 0)
<span class="p_chunk">@@ -287,17 +288,19 @@</span> <span class="p_context"> ssize_t ovl_listxattr(struct dentry *dentry, char *list, size_t size)</span>
 		return res;
 
 	/* filter out private xattrs */
<span class="p_del">-	for (off = 0; off &lt; res;) {</span>
<span class="p_del">-		char *s = list + off;</span>
<span class="p_del">-		size_t slen = strlen(s) + 1;</span>
<span class="p_add">+	for (s = list, len = res; len;) {</span>
<span class="p_add">+		size_t slen = strnlen(s, len) + 1;</span>
 
<span class="p_del">-		BUG_ON(off + slen &gt; res);</span>
<span class="p_add">+		/* underlying fs providing us with an broken xattr list? */</span>
<span class="p_add">+		if (WARN_ON(slen &gt; len))</span>
<span class="p_add">+			return -EIO;</span>
 
<span class="p_add">+		len -= slen;</span>
 		if (ovl_is_private_xattr(s)) {
 			res -= slen;
<span class="p_del">-			memmove(s, s + slen, res - off);</span>
<span class="p_add">+			memmove(s, s + slen, len);</span>
 		} else {
<span class="p_del">-			off += slen;</span>
<span class="p_add">+			s += slen;</span>
 		}
 	}
 
<span class="p_header">diff --git a/fs/overlayfs/overlayfs.h b/fs/overlayfs/overlayfs.h</span>
<span class="p_header">index 735e1d49b301..c319d5eaabcf 100644</span>
<span class="p_header">--- a/fs/overlayfs/overlayfs.h</span>
<span class="p_header">+++ b/fs/overlayfs/overlayfs.h</span>
<span class="p_chunk">@@ -174,6 +174,7 @@</span> <span class="p_context"> ssize_t ovl_getxattr(struct dentry *dentry, const char *name,</span>
 ssize_t ovl_listxattr(struct dentry *dentry, char *list, size_t size);
 int ovl_removexattr(struct dentry *dentry, const char *name);
 struct inode *ovl_d_select_inode(struct dentry *dentry, unsigned file_flags);
<span class="p_add">+bool ovl_is_private_xattr(const char *name);</span>
 
 struct inode *ovl_new_inode(struct super_block *sb, umode_t mode,
 			    struct ovl_entry *oe);
<span class="p_header">diff --git a/fs/overlayfs/super.c b/fs/overlayfs/super.c</span>
<span class="p_header">index 70a7bbe199d0..d70208c0de84 100644</span>
<span class="p_header">--- a/fs/overlayfs/super.c</span>
<span class="p_header">+++ b/fs/overlayfs/super.c</span>
<span class="p_chunk">@@ -763,6 +763,10 @@</span> <span class="p_context"> retry:</span>
 		struct kstat stat = {
 			.mode = S_IFDIR | 0,
 		};
<span class="p_add">+		struct iattr attr = {</span>
<span class="p_add">+			.ia_valid = ATTR_MODE,</span>
<span class="p_add">+			.ia_mode = stat.mode,</span>
<span class="p_add">+		};</span>
 
 		if (work-&gt;d_inode) {
 			err = -EEXIST;
<span class="p_chunk">@@ -778,6 +782,21 @@</span> <span class="p_context"> retry:</span>
 		err = ovl_create_real(dir, work, &amp;stat, NULL, NULL, true);
 		if (err)
 			goto out_dput;
<span class="p_add">+</span>
<span class="p_add">+		err = vfs_removexattr(work, XATTR_NAME_POSIX_ACL_DEFAULT);</span>
<span class="p_add">+		if (err &amp;&amp; err != -ENODATA &amp;&amp; err != -EOPNOTSUPP)</span>
<span class="p_add">+			goto out_dput;</span>
<span class="p_add">+</span>
<span class="p_add">+		err = vfs_removexattr(work, XATTR_NAME_POSIX_ACL_ACCESS);</span>
<span class="p_add">+		if (err &amp;&amp; err != -ENODATA &amp;&amp; err != -EOPNOTSUPP)</span>
<span class="p_add">+			goto out_dput;</span>
<span class="p_add">+</span>
<span class="p_add">+		/* Clear any inherited mode bits */</span>
<span class="p_add">+		inode_lock(work-&gt;d_inode);</span>
<span class="p_add">+		err = notify_change(work, &amp;attr, NULL);</span>
<span class="p_add">+		inode_unlock(work-&gt;d_inode);</span>
<span class="p_add">+		if (err)</span>
<span class="p_add">+			goto out_dput;</span>
 	}
 out_unlock:
 	mutex_unlock(&amp;dir-&gt;i_mutex);
<span class="p_header">diff --git a/fs/proc/task_mmu.c b/fs/proc/task_mmu.c</span>
<span class="p_header">index f6478301db00..d598b9c809c1 100644</span>
<span class="p_header">--- a/fs/proc/task_mmu.c</span>
<span class="p_header">+++ b/fs/proc/task_mmu.c</span>
<span class="p_chunk">@@ -248,23 +248,29 @@</span> <span class="p_context"> static int do_maps_open(struct inode *inode, struct file *file,</span>
 				sizeof(struct proc_maps_private));
 }
 
<span class="p_del">-static pid_t pid_of_stack(struct proc_maps_private *priv,</span>
<span class="p_del">-				struct vm_area_struct *vma, bool is_pid)</span>
<span class="p_add">+/*</span>
<span class="p_add">+ * Indicate if the VMA is a stack for the given task; for</span>
<span class="p_add">+ * /proc/PID/maps that is the stack of the main task.</span>
<span class="p_add">+ */</span>
<span class="p_add">+static int is_stack(struct proc_maps_private *priv,</span>
<span class="p_add">+		    struct vm_area_struct *vma, int is_pid)</span>
 {
<span class="p_del">-	struct inode *inode = priv-&gt;inode;</span>
<span class="p_del">-	struct task_struct *task;</span>
<span class="p_del">-	pid_t ret = 0;</span>
<span class="p_add">+	int stack = 0;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (is_pid) {</span>
<span class="p_add">+		stack = vma-&gt;vm_start &lt;= vma-&gt;vm_mm-&gt;start_stack &amp;&amp;</span>
<span class="p_add">+			vma-&gt;vm_end &gt;= vma-&gt;vm_mm-&gt;start_stack;</span>
<span class="p_add">+	} else {</span>
<span class="p_add">+		struct inode *inode = priv-&gt;inode;</span>
<span class="p_add">+		struct task_struct *task;</span>
 
<span class="p_del">-	rcu_read_lock();</span>
<span class="p_del">-	task = pid_task(proc_pid(inode), PIDTYPE_PID);</span>
<span class="p_del">-	if (task) {</span>
<span class="p_del">-		task = task_of_stack(task, vma, is_pid);</span>
<span class="p_add">+		rcu_read_lock();</span>
<span class="p_add">+		task = pid_task(proc_pid(inode), PIDTYPE_PID);</span>
 		if (task)
<span class="p_del">-			ret = task_pid_nr_ns(task, inode-&gt;i_sb-&gt;s_fs_info);</span>
<span class="p_add">+			stack = vma_is_stack_for_task(vma, task);</span>
<span class="p_add">+		rcu_read_unlock();</span>
 	}
<span class="p_del">-	rcu_read_unlock();</span>
<span class="p_del">-</span>
<span class="p_del">-	return ret;</span>
<span class="p_add">+	return stack;</span>
 }
 
 static void
<span class="p_chunk">@@ -324,8 +330,6 @@</span> <span class="p_context"> show_map_vma(struct seq_file *m, struct vm_area_struct *vma, int is_pid)</span>
 
 	name = arch_vma_name(vma);
 	if (!name) {
<span class="p_del">-		pid_t tid;</span>
<span class="p_del">-</span>
 		if (!mm) {
 			name = &quot;[vdso]&quot;;
 			goto done;
<span class="p_chunk">@@ -337,21 +341,8 @@</span> <span class="p_context"> show_map_vma(struct seq_file *m, struct vm_area_struct *vma, int is_pid)</span>
 			goto done;
 		}
 
<span class="p_del">-		tid = pid_of_stack(priv, vma, is_pid);</span>
<span class="p_del">-		if (tid != 0) {</span>
<span class="p_del">-			/*</span>
<span class="p_del">-			 * Thread stack in /proc/PID/task/TID/maps or</span>
<span class="p_del">-			 * the main process stack.</span>
<span class="p_del">-			 */</span>
<span class="p_del">-			if (!is_pid || (vma-&gt;vm_start &lt;= mm-&gt;start_stack &amp;&amp;</span>
<span class="p_del">-			    vma-&gt;vm_end &gt;= mm-&gt;start_stack)) {</span>
<span class="p_del">-				name = &quot;[stack]&quot;;</span>
<span class="p_del">-			} else {</span>
<span class="p_del">-				/* Thread stack in /proc/PID/maps */</span>
<span class="p_del">-				seq_pad(m, &#39; &#39;);</span>
<span class="p_del">-				seq_printf(m, &quot;[stack:%d]&quot;, tid);</span>
<span class="p_del">-			}</span>
<span class="p_del">-		}</span>
<span class="p_add">+		if (is_stack(priv, vma, is_pid))</span>
<span class="p_add">+			name = &quot;[stack]&quot;;</span>
 	}
 
 done:
<span class="p_chunk">@@ -1566,19 +1557,8 @@</span> <span class="p_context"> static int show_numa_map(struct seq_file *m, void *v, int is_pid)</span>
 		seq_file_path(m, file, &quot;\n\t= &quot;);
 	} else if (vma-&gt;vm_start &lt;= mm-&gt;brk &amp;&amp; vma-&gt;vm_end &gt;= mm-&gt;start_brk) {
 		seq_puts(m, &quot; heap&quot;);
<span class="p_del">-	} else {</span>
<span class="p_del">-		pid_t tid = pid_of_stack(proc_priv, vma, is_pid);</span>
<span class="p_del">-		if (tid != 0) {</span>
<span class="p_del">-			/*</span>
<span class="p_del">-			 * Thread stack in /proc/PID/task/TID/maps or</span>
<span class="p_del">-			 * the main process stack.</span>
<span class="p_del">-			 */</span>
<span class="p_del">-			if (!is_pid || (vma-&gt;vm_start &lt;= mm-&gt;start_stack &amp;&amp;</span>
<span class="p_del">-			    vma-&gt;vm_end &gt;= mm-&gt;start_stack))</span>
<span class="p_del">-				seq_puts(m, &quot; stack&quot;);</span>
<span class="p_del">-			else</span>
<span class="p_del">-				seq_printf(m, &quot; stack:%d&quot;, tid);</span>
<span class="p_del">-		}</span>
<span class="p_add">+	} else if (is_stack(proc_priv, vma, is_pid)) {</span>
<span class="p_add">+		seq_puts(m, &quot; stack&quot;);</span>
 	}
 
 	if (is_vm_hugetlb_page(vma))
<span class="p_header">diff --git a/fs/proc/task_nommu.c b/fs/proc/task_nommu.c</span>
<span class="p_header">index e0d64c92e4f6..faacb0c0d857 100644</span>
<span class="p_header">--- a/fs/proc/task_nommu.c</span>
<span class="p_header">+++ b/fs/proc/task_nommu.c</span>
<span class="p_chunk">@@ -123,23 +123,26 @@</span> <span class="p_context"> unsigned long task_statm(struct mm_struct *mm,</span>
 	return size;
 }
 
<span class="p_del">-static pid_t pid_of_stack(struct proc_maps_private *priv,</span>
<span class="p_del">-				struct vm_area_struct *vma, bool is_pid)</span>
<span class="p_add">+static int is_stack(struct proc_maps_private *priv,</span>
<span class="p_add">+		    struct vm_area_struct *vma, int is_pid)</span>
 {
<span class="p_del">-	struct inode *inode = priv-&gt;inode;</span>
<span class="p_del">-	struct task_struct *task;</span>
<span class="p_del">-	pid_t ret = 0;</span>
<span class="p_del">-</span>
<span class="p_del">-	rcu_read_lock();</span>
<span class="p_del">-	task = pid_task(proc_pid(inode), PIDTYPE_PID);</span>
<span class="p_del">-	if (task) {</span>
<span class="p_del">-		task = task_of_stack(task, vma, is_pid);</span>
<span class="p_add">+	struct mm_struct *mm = vma-&gt;vm_mm;</span>
<span class="p_add">+	int stack = 0;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (is_pid) {</span>
<span class="p_add">+		stack = vma-&gt;vm_start &lt;= mm-&gt;start_stack &amp;&amp;</span>
<span class="p_add">+			vma-&gt;vm_end &gt;= mm-&gt;start_stack;</span>
<span class="p_add">+	} else {</span>
<span class="p_add">+		struct inode *inode = priv-&gt;inode;</span>
<span class="p_add">+		struct task_struct *task;</span>
<span class="p_add">+</span>
<span class="p_add">+		rcu_read_lock();</span>
<span class="p_add">+		task = pid_task(proc_pid(inode), PIDTYPE_PID);</span>
 		if (task)
<span class="p_del">-			ret = task_pid_nr_ns(task, inode-&gt;i_sb-&gt;s_fs_info);</span>
<span class="p_add">+			stack = vma_is_stack_for_task(vma, task);</span>
<span class="p_add">+		rcu_read_unlock();</span>
 	}
<span class="p_del">-	rcu_read_unlock();</span>
<span class="p_del">-</span>
<span class="p_del">-	return ret;</span>
<span class="p_add">+	return stack;</span>
 }
 
 /*
<span class="p_chunk">@@ -181,21 +184,9 @@</span> <span class="p_context"> static int nommu_vma_show(struct seq_file *m, struct vm_area_struct *vma,</span>
 	if (file) {
 		seq_pad(m, &#39; &#39;);
 		seq_file_path(m, file, &quot;&quot;);
<span class="p_del">-	} else if (mm) {</span>
<span class="p_del">-		pid_t tid = pid_of_stack(priv, vma, is_pid);</span>
<span class="p_del">-</span>
<span class="p_del">-		if (tid != 0) {</span>
<span class="p_del">-			seq_pad(m, &#39; &#39;);</span>
<span class="p_del">-			/*</span>
<span class="p_del">-			 * Thread stack in /proc/PID/task/TID/maps or</span>
<span class="p_del">-			 * the main process stack.</span>
<span class="p_del">-			 */</span>
<span class="p_del">-			if (!is_pid || (vma-&gt;vm_start &lt;= mm-&gt;start_stack &amp;&amp;</span>
<span class="p_del">-			    vma-&gt;vm_end &gt;= mm-&gt;start_stack))</span>
<span class="p_del">-				seq_printf(m, &quot;[stack]&quot;);</span>
<span class="p_del">-			else</span>
<span class="p_del">-				seq_printf(m, &quot;[stack:%d]&quot;, tid);</span>
<span class="p_del">-		}</span>
<span class="p_add">+	} else if (mm &amp;&amp; is_stack(priv, vma, is_pid)) {</span>
<span class="p_add">+		seq_pad(m, &#39; &#39;);</span>
<span class="p_add">+		seq_printf(m, &quot;[stack]&quot;);</span>
 	}
 
 	seq_putc(m, &#39;\n&#39;);
<span class="p_header">diff --git a/fs/ubifs/tnc_commit.c b/fs/ubifs/tnc_commit.c</span>
<span class="p_header">index b45345d701e7..51157da3f76e 100644</span>
<span class="p_header">--- a/fs/ubifs/tnc_commit.c</span>
<span class="p_header">+++ b/fs/ubifs/tnc_commit.c</span>
<span class="p_chunk">@@ -370,7 +370,7 @@</span> <span class="p_context"> static int layout_in_gaps(struct ubifs_info *c, int cnt)</span>
 
 	p = c-&gt;gap_lebs;
 	do {
<span class="p_del">-		ubifs_assert(p &lt; c-&gt;gap_lebs + sizeof(int) * c-&gt;lst.idx_lebs);</span>
<span class="p_add">+		ubifs_assert(p &lt; c-&gt;gap_lebs + c-&gt;lst.idx_lebs);</span>
 		written = layout_leb_in_gaps(c, p);
 		if (written &lt; 0) {
 			err = written;
<span class="p_header">diff --git a/fs/xfs/libxfs/xfs_sb.c b/fs/xfs/libxfs/xfs_sb.c</span>
<span class="p_header">index 8a53eaa349f4..7088be6afb3c 100644</span>
<span class="p_header">--- a/fs/xfs/libxfs/xfs_sb.c</span>
<span class="p_header">+++ b/fs/xfs/libxfs/xfs_sb.c</span>
<span class="p_chunk">@@ -581,7 +581,8 @@</span> <span class="p_context"> xfs_sb_verify(</span>
 	 * Only check the in progress field for the primary superblock as
 	 * mkfs.xfs doesn&#39;t clear it from secondary superblocks.
 	 */
<span class="p_del">-	return xfs_mount_validate_sb(mp, &amp;sb, bp-&gt;b_bn == XFS_SB_DADDR,</span>
<span class="p_add">+	return xfs_mount_validate_sb(mp, &amp;sb,</span>
<span class="p_add">+				     bp-&gt;b_maps[0].bm_bn == XFS_SB_DADDR,</span>
 				     check_version);
 }
 
<span class="p_header">diff --git a/include/drm/i915_pciids.h b/include/drm/i915_pciids.h</span>
<span class="p_header">index 17c445612e01..2cdc723d750f 100644</span>
<span class="p_header">--- a/include/drm/i915_pciids.h</span>
<span class="p_header">+++ b/include/drm/i915_pciids.h</span>
<span class="p_chunk">@@ -277,7 +277,9 @@</span> <span class="p_context"></span>
 	INTEL_VGA_DEVICE(0x191D, info)  /* WKS GT2 */
 
 #define INTEL_SKL_GT3_IDS(info) \
<span class="p_add">+	INTEL_VGA_DEVICE(0x1923, info), /* ULT GT3 */ \</span>
 	INTEL_VGA_DEVICE(0x1926, info), /* ULT GT3 */ \
<span class="p_add">+	INTEL_VGA_DEVICE(0x1927, info), /* ULT GT3 */ \</span>
 	INTEL_VGA_DEVICE(0x192B, info), /* Halo GT3 */ \
 	INTEL_VGA_DEVICE(0x192A, info) /* SRV GT3 */ \
 
<span class="p_chunk">@@ -289,6 +291,8 @@</span> <span class="p_context"></span>
 #define INTEL_BXT_IDS(info) \
 	INTEL_VGA_DEVICE(0x0A84, info), \
 	INTEL_VGA_DEVICE(0x1A84, info), \
<span class="p_del">-	INTEL_VGA_DEVICE(0x5A84, info)</span>
<span class="p_add">+	INTEL_VGA_DEVICE(0x1A85, info), \</span>
<span class="p_add">+	INTEL_VGA_DEVICE(0x5A84, info), /* APL HD Graphics 505 */ \</span>
<span class="p_add">+	INTEL_VGA_DEVICE(0x5A85, info)  /* APL HD Graphics 500 */</span>
 
 #endif /* _I915_PCIIDS_H */
<span class="p_header">diff --git a/include/linux/blkdev.h b/include/linux/blkdev.h</span>
<span class="p_header">index 168755791ec8..fe14382f9664 100644</span>
<span class="p_header">--- a/include/linux/blkdev.h</span>
<span class="p_header">+++ b/include/linux/blkdev.h</span>
<span class="p_chunk">@@ -890,7 +890,7 @@</span> <span class="p_context"> static inline unsigned int blk_rq_get_max_sectors(struct request *rq)</span>
 {
 	struct request_queue *q = rq-&gt;q;
 
<span class="p_del">-	if (unlikely(rq-&gt;cmd_type == REQ_TYPE_BLOCK_PC))</span>
<span class="p_add">+	if (unlikely(rq-&gt;cmd_type != REQ_TYPE_FS))</span>
 		return q-&gt;limits.max_hw_sectors;
 
 	if (!q-&gt;limits.chunk_sectors || (rq-&gt;cmd_flags &amp; REQ_DISCARD))
<span class="p_header">diff --git a/include/linux/capability.h b/include/linux/capability.h</span>
<span class="p_header">index af9f0b9e80e6..5f8249d378a2 100644</span>
<span class="p_header">--- a/include/linux/capability.h</span>
<span class="p_header">+++ b/include/linux/capability.h</span>
<span class="p_chunk">@@ -214,6 +214,7 @@</span> <span class="p_context"> extern bool has_ns_capability_noaudit(struct task_struct *t,</span>
 				      struct user_namespace *ns, int cap);
 extern bool capable(int cap);
 extern bool ns_capable(struct user_namespace *ns, int cap);
<span class="p_add">+extern bool ns_capable_noaudit(struct user_namespace *ns, int cap);</span>
 #else
 static inline bool has_capability(struct task_struct *t, int cap)
 {
<span class="p_chunk">@@ -241,6 +242,10 @@</span> <span class="p_context"> static inline bool ns_capable(struct user_namespace *ns, int cap)</span>
 {
 	return true;
 }
<span class="p_add">+static inline bool ns_capable_noaudit(struct user_namespace *ns, int cap)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return true;</span>
<span class="p_add">+}</span>
 #endif /* CONFIG_MULTIUSER */
 extern bool capable_wrt_inode_uidgid(const struct inode *inode, int cap);
 extern bool file_ns_capable(const struct file *file, struct user_namespace *ns, int cap);
<span class="p_header">diff --git a/include/linux/fs.h b/include/linux/fs.h</span>
<span class="p_header">index ab3d8d9bb3ef..0166582c4d78 100644</span>
<span class="p_header">--- a/include/linux/fs.h</span>
<span class="p_header">+++ b/include/linux/fs.h</span>
<span class="p_chunk">@@ -710,6 +710,31 @@</span> <span class="p_context"> enum inode_i_mutex_lock_class</span>
 	I_MUTEX_PARENT2,
 };
 
<span class="p_add">+static inline void inode_lock(struct inode *inode)</span>
<span class="p_add">+{</span>
<span class="p_add">+	mutex_lock(&amp;inode-&gt;i_mutex);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline void inode_unlock(struct inode *inode)</span>
<span class="p_add">+{</span>
<span class="p_add">+	mutex_unlock(&amp;inode-&gt;i_mutex);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline int inode_trylock(struct inode *inode)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return mutex_trylock(&amp;inode-&gt;i_mutex);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline int inode_is_locked(struct inode *inode)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return mutex_is_locked(&amp;inode-&gt;i_mutex);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline void inode_lock_nested(struct inode *inode, unsigned subclass)</span>
<span class="p_add">+{</span>
<span class="p_add">+	mutex_lock_nested(&amp;inode-&gt;i_mutex, subclass);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 void lock_two_nondirectories(struct inode *, struct inode*);
 void unlock_two_nondirectories(struct inode *, struct inode*);
 
<span class="p_chunk">@@ -3029,8 +3054,8 @@</span> <span class="p_context"> static inline bool dir_emit_dots(struct file *file, struct dir_context *ctx)</span>
 }
 static inline bool dir_relax(struct inode *inode)
 {
<span class="p_del">-	mutex_unlock(&amp;inode-&gt;i_mutex);</span>
<span class="p_del">-	mutex_lock(&amp;inode-&gt;i_mutex);</span>
<span class="p_add">+	inode_unlock(inode);</span>
<span class="p_add">+	inode_lock(inode);</span>
 	return !IS_DEADDIR(inode);
 }
 
<span class="p_header">diff --git a/include/linux/lightnvm.h b/include/linux/lightnvm.h</span>
<span class="p_header">index 034117b3be5f..f09648d14694 100644</span>
<span class="p_header">--- a/include/linux/lightnvm.h</span>
<span class="p_header">+++ b/include/linux/lightnvm.h</span>
<span class="p_chunk">@@ -58,8 +58,9 @@</span> <span class="p_context"> enum {</span>
 	/* Block Types */
 	NVM_BLK_T_FREE		= 0x0,
 	NVM_BLK_T_BAD		= 0x1,
<span class="p_del">-	NVM_BLK_T_DEV		= 0x2,</span>
<span class="p_del">-	NVM_BLK_T_HOST		= 0x4,</span>
<span class="p_add">+	NVM_BLK_T_GRWN_BAD	= 0x2,</span>
<span class="p_add">+	NVM_BLK_T_DEV		= 0x4,</span>
<span class="p_add">+	NVM_BLK_T_HOST		= 0x8,</span>
 };
 
 struct nvm_id_group {
<span class="p_header">diff --git a/include/linux/mm.h b/include/linux/mm.h</span>
<span class="p_header">index f24df9c0b9df..8a761248d01e 100644</span>
<span class="p_header">--- a/include/linux/mm.h</span>
<span class="p_header">+++ b/include/linux/mm.h</span>
<span class="p_chunk">@@ -1311,8 +1311,7 @@</span> <span class="p_context"> static inline int stack_guard_page_end(struct vm_area_struct *vma,</span>
 		!vma_growsup(vma-&gt;vm_next, addr);
 }
 
<span class="p_del">-extern struct task_struct *task_of_stack(struct task_struct *task,</span>
<span class="p_del">-				struct vm_area_struct *vma, bool in_group);</span>
<span class="p_add">+int vma_is_stack_for_task(struct vm_area_struct *vma, struct task_struct *t);</span>
 
 extern unsigned long move_page_tables(struct vm_area_struct *vma,
 		unsigned long old_addr, struct vm_area_struct *new_vma,
<span class="p_header">diff --git a/include/linux/perf_event.h b/include/linux/perf_event.h</span>
<span class="p_header">index f9828a48f16a..6cdd50f7f52d 100644</span>
<span class="p_header">--- a/include/linux/perf_event.h</span>
<span class="p_header">+++ b/include/linux/perf_event.h</span>
<span class="p_chunk">@@ -121,6 +121,7 @@</span> <span class="p_context"> struct hw_perf_event {</span>
 		struct { /* intel_cqm */
 			int			cqm_state;
 			u32			cqm_rmid;
<span class="p_add">+			int			is_group_event;</span>
 			struct list_head	cqm_events_entry;
 			struct list_head	cqm_groups_entry;
 			struct list_head	cqm_group_entry;
<span class="p_header">diff --git a/include/linux/time.h b/include/linux/time.h</span>
<span class="p_header">index beebe3a02d43..297f09f23896 100644</span>
<span class="p_header">--- a/include/linux/time.h</span>
<span class="p_header">+++ b/include/linux/time.h</span>
<span class="p_chunk">@@ -125,6 +125,32 @@</span> <span class="p_context"> static inline bool timeval_valid(const struct timeval *tv)</span>
 
 extern struct timespec timespec_trunc(struct timespec t, unsigned gran);
 
<span class="p_add">+/*</span>
<span class="p_add">+ * Validates if a timespec/timeval used to inject a time offset is valid.</span>
<span class="p_add">+ * Offsets can be postive or negative. The value of the timeval/timespec</span>
<span class="p_add">+ * is the sum of its fields, but *NOTE*: the field tv_usec/tv_nsec must</span>
<span class="p_add">+ * always be non-negative.</span>
<span class="p_add">+ */</span>
<span class="p_add">+static inline bool timeval_inject_offset_valid(const struct timeval *tv)</span>
<span class="p_add">+{</span>
<span class="p_add">+	/* We don&#39;t check the tv_sec as it can be positive or negative */</span>
<span class="p_add">+</span>
<span class="p_add">+	/* Can&#39;t have more microseconds then a second */</span>
<span class="p_add">+	if (tv-&gt;tv_usec &lt; 0 || tv-&gt;tv_usec &gt;= USEC_PER_SEC)</span>
<span class="p_add">+		return false;</span>
<span class="p_add">+	return true;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline bool timespec_inject_offset_valid(const struct timespec *ts)</span>
<span class="p_add">+{</span>
<span class="p_add">+	/* We don&#39;t check the tv_sec as it can be positive or negative */</span>
<span class="p_add">+</span>
<span class="p_add">+	/* Can&#39;t have more nanoseconds then a second */</span>
<span class="p_add">+	if (ts-&gt;tv_nsec &lt; 0 || ts-&gt;tv_nsec &gt;= NSEC_PER_SEC)</span>
<span class="p_add">+		return false;</span>
<span class="p_add">+	return true;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 #define CURRENT_TIME		(current_kernel_time())
 #define CURRENT_TIME_SEC	((struct timespec) { get_seconds(), 0 })
 
<span class="p_header">diff --git a/include/uapi/linux/hyperv.h b/include/uapi/linux/hyperv.h</span>
<span class="p_header">index e4c0a35d6417..e347b24ef9fb 100644</span>
<span class="p_header">--- a/include/uapi/linux/hyperv.h</span>
<span class="p_header">+++ b/include/uapi/linux/hyperv.h</span>
<span class="p_chunk">@@ -313,6 +313,7 @@</span> <span class="p_context"> enum hv_kvp_exchg_pool {</span>
 #define HV_INVALIDARG			0x80070057
 #define HV_GUID_NOTFOUND		0x80041002
 #define HV_ERROR_ALREADY_EXISTS		0x80070050
<span class="p_add">+#define HV_ERROR_DISK_FULL		0x80070070</span>
 
 #define ADDR_FAMILY_NONE	0x00
 #define ADDR_FAMILY_IPV4	0x01
<span class="p_header">diff --git a/include/uapi/linux/videodev2.h b/include/uapi/linux/videodev2.h</span>
<span class="p_header">index a0e87d16b726..421d27413731 100644</span>
<span class="p_header">--- a/include/uapi/linux/videodev2.h</span>
<span class="p_header">+++ b/include/uapi/linux/videodev2.h</span>
<span class="p_chunk">@@ -621,6 +621,9 @@</span> <span class="p_context"> struct v4l2_pix_format {</span>
 #define V4L2_PIX_FMT_JPGL	v4l2_fourcc(&#39;J&#39;, &#39;P&#39;, &#39;G&#39;, &#39;L&#39;) /* JPEG-Lite */
 #define V4L2_PIX_FMT_SE401      v4l2_fourcc(&#39;S&#39;, &#39;4&#39;, &#39;0&#39;, &#39;1&#39;) /* se401 janggu compressed rgb */
 #define V4L2_PIX_FMT_S5C_UYVY_JPG v4l2_fourcc(&#39;S&#39;, &#39;5&#39;, &#39;C&#39;, &#39;I&#39;) /* S5C73M3 interleaved UYVY/JPEG */
<span class="p_add">+#define V4L2_PIX_FMT_Y8I      v4l2_fourcc(&#39;Y&#39;, &#39;8&#39;, &#39;I&#39;, &#39; &#39;) /* Greyscale 8-bit L/R interleaved */</span>
<span class="p_add">+#define V4L2_PIX_FMT_Y12I     v4l2_fourcc(&#39;Y&#39;, &#39;1&#39;, &#39;2&#39;, &#39;I&#39;) /* Greyscale 12-bit L/R interleaved */</span>
<span class="p_add">+#define V4L2_PIX_FMT_Z16      v4l2_fourcc(&#39;Z&#39;, &#39;1&#39;, &#39;6&#39;, &#39; &#39;) /* Depth data 16-bit */</span>
 
 /* SDR formats - used only for Software Defined Radio devices */
 #define V4L2_SDR_FMT_CU8          v4l2_fourcc(&#39;C&#39;, &#39;U&#39;, &#39;0&#39;, &#39;8&#39;) /* IQ u8 */
<span class="p_header">diff --git a/include/uapi/scsi/cxlflash_ioctl.h b/include/uapi/scsi/cxlflash_ioctl.h</span>
<span class="p_header">index 831351b2e660..2302f3ce5f86 100644</span>
<span class="p_header">--- a/include/uapi/scsi/cxlflash_ioctl.h</span>
<span class="p_header">+++ b/include/uapi/scsi/cxlflash_ioctl.h</span>
<span class="p_chunk">@@ -31,6 +31,16 @@</span> <span class="p_context"> struct dk_cxlflash_hdr {</span>
 };
 
 /*
<span class="p_add">+ * Return flag definitions available to all ioctls</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * Similar to the input flags, these are grown from the bottom-up with the</span>
<span class="p_add">+ * intention that ioctl-specific return flag definitions would grow from the</span>
<span class="p_add">+ * top-down, allowing the two sets to co-exist. While not required/enforced</span>
<span class="p_add">+ * at this time, this provides future flexibility.</span>
<span class="p_add">+ */</span>
<span class="p_add">+#define DK_CXLFLASH_ALL_PORTS_ACTIVE	0x0000000000000001ULL</span>
<span class="p_add">+</span>
<span class="p_add">+/*</span>
  * Notes:
  * -----
  * The &#39;context_id&#39; field of all ioctl structures contains the context
<span class="p_header">diff --git a/kernel/capability.c b/kernel/capability.c</span>
<span class="p_header">index 45432b54d5c6..00411c82dac5 100644</span>
<span class="p_header">--- a/kernel/capability.c</span>
<span class="p_header">+++ b/kernel/capability.c</span>
<span class="p_chunk">@@ -361,6 +361,24 @@</span> <span class="p_context"> bool has_capability_noaudit(struct task_struct *t, int cap)</span>
 	return has_ns_capability_noaudit(t, &amp;init_user_ns, cap);
 }
 
<span class="p_add">+static bool ns_capable_common(struct user_namespace *ns, int cap, bool audit)</span>
<span class="p_add">+{</span>
<span class="p_add">+	int capable;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (unlikely(!cap_valid(cap))) {</span>
<span class="p_add">+		pr_crit(&quot;capable() called with invalid cap=%u\n&quot;, cap);</span>
<span class="p_add">+		BUG();</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	capable = audit ? security_capable(current_cred(), ns, cap) :</span>
<span class="p_add">+			  security_capable_noaudit(current_cred(), ns, cap);</span>
<span class="p_add">+	if (capable == 0) {</span>
<span class="p_add">+		current-&gt;flags |= PF_SUPERPRIV;</span>
<span class="p_add">+		return true;</span>
<span class="p_add">+	}</span>
<span class="p_add">+	return false;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 /**
  * ns_capable - Determine if the current task has a superior capability in effect
  * @ns:  The usernamespace we want the capability in
<span class="p_chunk">@@ -374,19 +392,27 @@</span> <span class="p_context"> bool has_capability_noaudit(struct task_struct *t, int cap)</span>
  */
 bool ns_capable(struct user_namespace *ns, int cap)
 {
<span class="p_del">-	if (unlikely(!cap_valid(cap))) {</span>
<span class="p_del">-		pr_crit(&quot;capable() called with invalid cap=%u\n&quot;, cap);</span>
<span class="p_del">-		BUG();</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">-	if (security_capable(current_cred(), ns, cap) == 0) {</span>
<span class="p_del">-		current-&gt;flags |= PF_SUPERPRIV;</span>
<span class="p_del">-		return true;</span>
<span class="p_del">-	}</span>
<span class="p_del">-	return false;</span>
<span class="p_add">+	return ns_capable_common(ns, cap, true);</span>
 }
 EXPORT_SYMBOL(ns_capable);
 
<span class="p_add">+/**</span>
<span class="p_add">+ * ns_capable_noaudit - Determine if the current task has a superior capability</span>
<span class="p_add">+ * (unaudited) in effect</span>
<span class="p_add">+ * @ns:  The usernamespace we want the capability in</span>
<span class="p_add">+ * @cap: The capability to be tested for</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * Return true if the current task has the given superior capability currently</span>
<span class="p_add">+ * available for use, false if not.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * This sets PF_SUPERPRIV on the task if the capability is available on the</span>
<span class="p_add">+ * assumption that it&#39;s about to be used.</span>
<span class="p_add">+ */</span>
<span class="p_add">+bool ns_capable_noaudit(struct user_namespace *ns, int cap)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return ns_capable_common(ns, cap, false);</span>
<span class="p_add">+}</span>
<span class="p_add">+EXPORT_SYMBOL(ns_capable_noaudit);</span>
 
 /**
  * capable - Determine if the current task has a superior capability in effect
<span class="p_header">diff --git a/kernel/cred.c b/kernel/cred.c</span>
<span class="p_header">index 71179a09c1d6..ff8606f77d90 100644</span>
<span class="p_header">--- a/kernel/cred.c</span>
<span class="p_header">+++ b/kernel/cred.c</span>
<span class="p_chunk">@@ -689,6 +689,8 @@</span> <span class="p_context"> EXPORT_SYMBOL(set_security_override_from_ctx);</span>
  */
 int set_create_files_as(struct cred *new, struct inode *inode)
 {
<span class="p_add">+	if (!uid_valid(inode-&gt;i_uid) || !gid_valid(inode-&gt;i_gid))</span>
<span class="p_add">+		return -EINVAL;</span>
 	new-&gt;fsuid = inode-&gt;i_uid;
 	new-&gt;fsgid = inode-&gt;i_gid;
 	return security_kernel_create_files_as(new, inode);
<span class="p_header">diff --git a/kernel/events/uprobes.c b/kernel/events/uprobes.c</span>
<span class="p_header">index 7dad84913abf..da0c09ff6112 100644</span>
<span class="p_header">--- a/kernel/events/uprobes.c</span>
<span class="p_header">+++ b/kernel/events/uprobes.c</span>
<span class="p_chunk">@@ -171,8 +171,10 @@</span> <span class="p_context"> static int __replace_page(struct vm_area_struct *vma, unsigned long addr,</span>
 	mmu_notifier_invalidate_range_start(mm, mmun_start, mmun_end);
 	err = -EAGAIN;
 	ptep = page_check_address(page, mm, addr, &amp;ptl, 0);
<span class="p_del">-	if (!ptep)</span>
<span class="p_add">+	if (!ptep) {</span>
<span class="p_add">+		mem_cgroup_cancel_charge(kpage, memcg);</span>
 		goto unlock;
<span class="p_add">+	}</span>
 
 	get_page(kpage);
 	page_add_new_anon_rmap(kpage, vma, addr);
<span class="p_chunk">@@ -199,7 +201,6 @@</span> <span class="p_context"> static int __replace_page(struct vm_area_struct *vma, unsigned long addr,</span>
 
 	err = 0;
  unlock:
<span class="p_del">-	mem_cgroup_cancel_charge(kpage, memcg);</span>
 	mmu_notifier_invalidate_range_end(mm, mmun_start, mmun_end);
 	unlock_page(page);
 	return err;
<span class="p_header">diff --git a/kernel/fork.c b/kernel/fork.c</span>
<span class="p_header">index 1155eac61687..c485cb156772 100644</span>
<span class="p_header">--- a/kernel/fork.c</span>
<span class="p_header">+++ b/kernel/fork.c</span>
<span class="p_chunk">@@ -1369,7 +1369,6 @@</span> <span class="p_context"> static struct task_struct *copy_process(unsigned long clone_flags,</span>
 	p-&gt;real_start_time = ktime_get_boot_ns();
 	p-&gt;io_context = NULL;
 	p-&gt;audit_context = NULL;
<span class="p_del">-	threadgroup_change_begin(current);</span>
 	cgroup_fork(p);
 #ifdef CONFIG_NUMA
 	p-&gt;mempolicy = mpol_dup(p-&gt;mempolicy);
<span class="p_chunk">@@ -1521,6 +1520,7 @@</span> <span class="p_context"> static struct task_struct *copy_process(unsigned long clone_flags,</span>
 	INIT_LIST_HEAD(&amp;p-&gt;thread_group);
 	p-&gt;task_works = NULL;
 
<span class="p_add">+	threadgroup_change_begin(current);</span>
 	/*
 	 * Ensure that the cgroup subsystem policies allow the new process to be
 	 * forked. It should be noted the the new process&#39;s css_set can be changed
<span class="p_chunk">@@ -1621,6 +1621,7 @@</span> <span class="p_context"> static struct task_struct *copy_process(unsigned long clone_flags,</span>
 bad_fork_cancel_cgroup:
 	cgroup_cancel_fork(p, cgrp_ss_priv);
 bad_fork_free_pid:
<span class="p_add">+	threadgroup_change_end(current);</span>
 	if (pid != &amp;init_struct_pid)
 		free_pid(pid);
 bad_fork_cleanup_io:
<span class="p_chunk">@@ -1651,7 +1652,6 @@</span> <span class="p_context"> bad_fork_cleanup_policy:</span>
 	mpol_put(p-&gt;mempolicy);
 bad_fork_cleanup_threadgroup_lock:
 #endif
<span class="p_del">-	threadgroup_change_end(current);</span>
 	delayacct_tsk_free(p);
 bad_fork_cleanup_count:
 	atomic_dec(&amp;p-&gt;cred-&gt;user-&gt;processes);
<span class="p_header">diff --git a/kernel/sched/fair.c b/kernel/sched/fair.c</span>
<span class="p_header">index b8b516c37bf1..8f258f437ac2 100644</span>
<span class="p_header">--- a/kernel/sched/fair.c</span>
<span class="p_header">+++ b/kernel/sched/fair.c</span>
<span class="p_chunk">@@ -1191,8 +1191,6 @@</span> <span class="p_context"> static void task_numa_assign(struct task_numa_env *env,</span>
 {
 	if (env-&gt;best_task)
 		put_task_struct(env-&gt;best_task);
<span class="p_del">-	if (p)</span>
<span class="p_del">-		get_task_struct(p);</span>
 
 	env-&gt;best_task = p;
 	env-&gt;best_imp = imp;
<span class="p_chunk">@@ -1260,20 +1258,30 @@</span> <span class="p_context"> static void task_numa_compare(struct task_numa_env *env,</span>
 	long imp = env-&gt;p-&gt;numa_group ? groupimp : taskimp;
 	long moveimp = imp;
 	int dist = env-&gt;dist;
<span class="p_add">+	bool assigned = false;</span>
 
 	rcu_read_lock();
 
 	raw_spin_lock_irq(&amp;dst_rq-&gt;lock);
 	cur = dst_rq-&gt;curr;
 	/*
<span class="p_del">-	 * No need to move the exiting task, and this ensures that -&gt;curr</span>
<span class="p_del">-	 * wasn&#39;t reaped and thus get_task_struct() in task_numa_assign()</span>
<span class="p_del">-	 * is safe under RCU read lock.</span>
<span class="p_del">-	 * Note that rcu_read_lock() itself can&#39;t protect from the final</span>
<span class="p_del">-	 * put_task_struct() after the last schedule().</span>
<span class="p_add">+	 * No need to move the exiting task or idle task.</span>
 	 */
 	if ((cur-&gt;flags &amp; PF_EXITING) || is_idle_task(cur))
 		cur = NULL;
<span class="p_add">+	else {</span>
<span class="p_add">+		/*</span>
<span class="p_add">+		 * The task_struct must be protected here to protect the</span>
<span class="p_add">+		 * p-&gt;numa_faults access in the task_weight since the</span>
<span class="p_add">+		 * numa_faults could already be freed in the following path:</span>
<span class="p_add">+		 * finish_task_switch()</span>
<span class="p_add">+		 *     --&gt; put_task_struct()</span>
<span class="p_add">+		 *         --&gt; __put_task_struct()</span>
<span class="p_add">+		 *             --&gt; task_numa_free()</span>
<span class="p_add">+		 */</span>
<span class="p_add">+		get_task_struct(cur);</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
 	raw_spin_unlock_irq(&amp;dst_rq-&gt;lock);
 
 	/*
<span class="p_chunk">@@ -1357,6 +1365,7 @@</span> <span class="p_context"> balance:</span>
 		 */
 		if (!load_too_imbalanced(src_load, dst_load, env)) {
 			imp = moveimp - 1;
<span class="p_add">+			put_task_struct(cur);</span>
 			cur = NULL;
 			goto assign;
 		}
<span class="p_chunk">@@ -1382,9 +1391,16 @@</span> <span class="p_context"> balance:</span>
 		env-&gt;dst_cpu = select_idle_sibling(env-&gt;p, env-&gt;dst_cpu);
 
 assign:
<span class="p_add">+	assigned = true;</span>
 	task_numa_assign(env, cur, imp);
 unlock:
 	rcu_read_unlock();
<span class="p_add">+	/*</span>
<span class="p_add">+	 * The dst_rq-&gt;curr isn&#39;t assigned. The protection for task_struct is</span>
<span class="p_add">+	 * finished.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	if (cur &amp;&amp; !assigned)</span>
<span class="p_add">+		put_task_struct(cur);</span>
 }
 
 static void task_numa_find_cpu(struct task_numa_env *env,
<span class="p_header">diff --git a/kernel/time/clocksource.c b/kernel/time/clocksource.c</span>
<span class="p_header">index 1347882d131e..b98810d2f3b4 100644</span>
<span class="p_header">--- a/kernel/time/clocksource.c</span>
<span class="p_header">+++ b/kernel/time/clocksource.c</span>
<span class="p_chunk">@@ -323,13 +323,42 @@</span> <span class="p_context"> static void clocksource_enqueue_watchdog(struct clocksource *cs)</span>
 		/* cs is a watchdog. */
 		if (cs-&gt;flags &amp; CLOCK_SOURCE_IS_CONTINUOUS)
 			cs-&gt;flags |= CLOCK_SOURCE_VALID_FOR_HRES;
<span class="p_add">+	}</span>
<span class="p_add">+	spin_unlock_irqrestore(&amp;watchdog_lock, flags);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static void clocksource_select_watchdog(bool fallback)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct clocksource *cs, *old_wd;</span>
<span class="p_add">+	unsigned long flags;</span>
<span class="p_add">+</span>
<span class="p_add">+	spin_lock_irqsave(&amp;watchdog_lock, flags);</span>
<span class="p_add">+	/* save current watchdog */</span>
<span class="p_add">+	old_wd = watchdog;</span>
<span class="p_add">+	if (fallback)</span>
<span class="p_add">+		watchdog = NULL;</span>
<span class="p_add">+</span>
<span class="p_add">+	list_for_each_entry(cs, &amp;clocksource_list, list) {</span>
<span class="p_add">+		/* cs is a clocksource to be watched. */</span>
<span class="p_add">+		if (cs-&gt;flags &amp; CLOCK_SOURCE_MUST_VERIFY)</span>
<span class="p_add">+			continue;</span>
<span class="p_add">+</span>
<span class="p_add">+		/* Skip current if we were requested for a fallback. */</span>
<span class="p_add">+		if (fallback &amp;&amp; cs == old_wd)</span>
<span class="p_add">+			continue;</span>
<span class="p_add">+</span>
 		/* Pick the best watchdog. */
<span class="p_del">-		if (!watchdog || cs-&gt;rating &gt; watchdog-&gt;rating) {</span>
<span class="p_add">+		if (!watchdog || cs-&gt;rating &gt; watchdog-&gt;rating)</span>
 			watchdog = cs;
<span class="p_del">-			/* Reset watchdog cycles */</span>
<span class="p_del">-			clocksource_reset_watchdog();</span>
<span class="p_del">-		}</span>
 	}
<span class="p_add">+	/* If we failed to find a fallback restore the old one. */</span>
<span class="p_add">+	if (!watchdog)</span>
<span class="p_add">+		watchdog = old_wd;</span>
<span class="p_add">+</span>
<span class="p_add">+	/* If we changed the watchdog we need to reset cycles. */</span>
<span class="p_add">+	if (watchdog != old_wd)</span>
<span class="p_add">+		clocksource_reset_watchdog();</span>
<span class="p_add">+</span>
 	/* Check if the watchdog timer needs to be started. */
 	clocksource_start_watchdog();
 	spin_unlock_irqrestore(&amp;watchdog_lock, flags);
<span class="p_chunk">@@ -404,6 +433,7 @@</span> <span class="p_context"> static void clocksource_enqueue_watchdog(struct clocksource *cs)</span>
 		cs-&gt;flags |= CLOCK_SOURCE_VALID_FOR_HRES;
 }
 
<span class="p_add">+static void clocksource_select_watchdog(bool fallback) { }</span>
 static inline void clocksource_dequeue_watchdog(struct clocksource *cs) { }
 static inline void clocksource_resume_watchdog(void) { }
 static inline int __clocksource_watchdog_kthread(void) { return 0; }
<span class="p_chunk">@@ -736,6 +766,7 @@</span> <span class="p_context"> int __clocksource_register_scale(struct clocksource *cs, u32 scale, u32 freq)</span>
 	clocksource_enqueue(cs);
 	clocksource_enqueue_watchdog(cs);
 	clocksource_select();
<span class="p_add">+	clocksource_select_watchdog(false);</span>
 	mutex_unlock(&amp;clocksource_mutex);
 	return 0;
 }
<span class="p_chunk">@@ -758,6 +789,7 @@</span> <span class="p_context"> void clocksource_change_rating(struct clocksource *cs, int rating)</span>
 	mutex_lock(&amp;clocksource_mutex);
 	__clocksource_change_rating(cs, rating);
 	clocksource_select();
<span class="p_add">+	clocksource_select_watchdog(false);</span>
 	mutex_unlock(&amp;clocksource_mutex);
 }
 EXPORT_SYMBOL(clocksource_change_rating);
<span class="p_chunk">@@ -767,12 +799,12 @@</span> <span class="p_context"> EXPORT_SYMBOL(clocksource_change_rating);</span>
  */
 static int clocksource_unbind(struct clocksource *cs)
 {
<span class="p_del">-	/*</span>
<span class="p_del">-	 * I really can&#39;t convince myself to support this on hardware</span>
<span class="p_del">-	 * designed by lobotomized monkeys.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	if (clocksource_is_watchdog(cs))</span>
<span class="p_del">-		return -EBUSY;</span>
<span class="p_add">+	if (clocksource_is_watchdog(cs)) {</span>
<span class="p_add">+		/* Select and try to install a replacement watchdog. */</span>
<span class="p_add">+		clocksource_select_watchdog(true);</span>
<span class="p_add">+		if (clocksource_is_watchdog(cs))</span>
<span class="p_add">+			return -EBUSY;</span>
<span class="p_add">+	}</span>
 
 	if (cs == curr_clocksource) {
 		/* Select and try to install a replacement clock source */
<span class="p_header">diff --git a/kernel/time/hrtimer.c b/kernel/time/hrtimer.c</span>
<span class="p_header">index fa909f9fd559..17f7bcff1e02 100644</span>
<span class="p_header">--- a/kernel/time/hrtimer.c</span>
<span class="p_header">+++ b/kernel/time/hrtimer.c</span>
<span class="p_chunk">@@ -94,6 +94,9 @@</span> <span class="p_context"> DEFINE_PER_CPU(struct hrtimer_cpu_base, hrtimer_bases) =</span>
 };
 
 static const int hrtimer_clock_to_base_table[MAX_CLOCKS] = {
<span class="p_add">+	/* Make sure we catch unsupported clockids */</span>
<span class="p_add">+	[0 ... MAX_CLOCKS - 1]	= HRTIMER_MAX_CLOCK_BASES,</span>
<span class="p_add">+</span>
 	[CLOCK_REALTIME]	= HRTIMER_BASE_REALTIME,
 	[CLOCK_MONOTONIC]	= HRTIMER_BASE_MONOTONIC,
 	[CLOCK_BOOTTIME]	= HRTIMER_BASE_BOOTTIME,
<span class="p_chunk">@@ -102,7 +105,9 @@</span> <span class="p_context"> static const int hrtimer_clock_to_base_table[MAX_CLOCKS] = {</span>
 
 static inline int hrtimer_clockid_to_base(clockid_t clock_id)
 {
<span class="p_del">-	return hrtimer_clock_to_base_table[clock_id];</span>
<span class="p_add">+	int base = hrtimer_clock_to_base_table[clock_id];</span>
<span class="p_add">+	BUG_ON(base == HRTIMER_MAX_CLOCK_BASES);</span>
<span class="p_add">+	return base;</span>
 }
 
 /*
<span class="p_header">diff --git a/kernel/time/ntp.c b/kernel/time/ntp.c</span>
<span class="p_header">index 149cc8086aea..ab861771e37f 100644</span>
<span class="p_header">--- a/kernel/time/ntp.c</span>
<span class="p_header">+++ b/kernel/time/ntp.c</span>
<span class="p_chunk">@@ -674,8 +674,24 @@</span> <span class="p_context"> int ntp_validate_timex(struct timex *txc)</span>
 			return -EINVAL;
 	}
 
<span class="p_del">-	if ((txc-&gt;modes &amp; ADJ_SETOFFSET) &amp;&amp; (!capable(CAP_SYS_TIME)))</span>
<span class="p_del">-		return -EPERM;</span>
<span class="p_add">+	if (txc-&gt;modes &amp; ADJ_SETOFFSET) {</span>
<span class="p_add">+		/* In order to inject time, you gotta be super-user! */</span>
<span class="p_add">+		if (!capable(CAP_SYS_TIME))</span>
<span class="p_add">+			return -EPERM;</span>
<span class="p_add">+</span>
<span class="p_add">+		if (txc-&gt;modes &amp; ADJ_NANO) {</span>
<span class="p_add">+			struct timespec ts;</span>
<span class="p_add">+</span>
<span class="p_add">+			ts.tv_sec = txc-&gt;time.tv_sec;</span>
<span class="p_add">+			ts.tv_nsec = txc-&gt;time.tv_usec;</span>
<span class="p_add">+			if (!timespec_inject_offset_valid(&amp;ts))</span>
<span class="p_add">+				return -EINVAL;</span>
<span class="p_add">+</span>
<span class="p_add">+		} else {</span>
<span class="p_add">+			if (!timeval_inject_offset_valid(&amp;txc-&gt;time))</span>
<span class="p_add">+				return -EINVAL;</span>
<span class="p_add">+		}</span>
<span class="p_add">+	}</span>
 
 	/*
 	 * Check for potential multiplication overflows that can
<span class="p_header">diff --git a/kernel/time/timekeeping.c b/kernel/time/timekeeping.c</span>
<span class="p_header">index 99188ee5d9d0..4ff237dbc006 100644</span>
<span class="p_header">--- a/kernel/time/timekeeping.c</span>
<span class="p_header">+++ b/kernel/time/timekeeping.c</span>
<span class="p_chunk">@@ -383,7 +383,10 @@</span> <span class="p_context"> static __always_inline u64 __ktime_get_fast_ns(struct tk_fast *tkf)</span>
 	do {
 		seq = raw_read_seqcount_latch(&amp;tkf-&gt;seq);
 		tkr = tkf-&gt;base + (seq &amp; 0x01);
<span class="p_del">-		now = ktime_to_ns(tkr-&gt;base) + timekeeping_get_ns(tkr);</span>
<span class="p_add">+		now = ktime_to_ns(tkr-&gt;base);</span>
<span class="p_add">+</span>
<span class="p_add">+		now += clocksource_delta(tkr-&gt;read(tkr-&gt;clock),</span>
<span class="p_add">+					 tkr-&gt;cycle_last, tkr-&gt;mask);</span>
 	} while (read_seqcount_retry(&amp;tkf-&gt;seq, seq));
 
 	return now;
<span class="p_chunk">@@ -958,7 +961,7 @@</span> <span class="p_context"> int timekeeping_inject_offset(struct timespec *ts)</span>
 	struct timespec64 ts64, tmp;
 	int ret = 0;
 
<span class="p_del">-	if ((unsigned long)ts-&gt;tv_nsec &gt;= NSEC_PER_SEC)</span>
<span class="p_add">+	if (!timespec_inject_offset_valid(ts))</span>
 		return -EINVAL;
 
 	ts64 = timespec_to_timespec64(*ts);
<span class="p_header">diff --git a/kernel/time/timekeeping_debug.c b/kernel/time/timekeeping_debug.c</span>
<span class="p_header">index f6bd65236712..107310a6f36f 100644</span>
<span class="p_header">--- a/kernel/time/timekeeping_debug.c</span>
<span class="p_header">+++ b/kernel/time/timekeeping_debug.c</span>
<span class="p_chunk">@@ -23,7 +23,9 @@</span> <span class="p_context"></span>
 
 #include &quot;timekeeping_internal.h&quot;
 
<span class="p_del">-static unsigned int sleep_time_bin[32] = {0};</span>
<span class="p_add">+#define NUM_BINS 32</span>
<span class="p_add">+</span>
<span class="p_add">+static unsigned int sleep_time_bin[NUM_BINS] = {0};</span>
 
 static int tk_debug_show_sleep_time(struct seq_file *s, void *data)
 {
<span class="p_chunk">@@ -69,6 +71,9 @@</span> <span class="p_context"> late_initcall(tk_debug_sleep_time_init);</span>
 
 void tk_debug_account_sleep_time(struct timespec64 *t)
 {
<span class="p_del">-	sleep_time_bin[fls(t-&gt;tv_sec)]++;</span>
<span class="p_add">+	/* Cap bin index so we don&#39;t overflow the array */</span>
<span class="p_add">+	int bin = min(fls(t-&gt;tv_sec), NUM_BINS-1);</span>
<span class="p_add">+</span>
<span class="p_add">+	sleep_time_bin[bin]++;</span>
 }
 
<span class="p_header">diff --git a/lib/asn1_decoder.c b/lib/asn1_decoder.c</span>
<span class="p_header">index 2b3f46c049d4..554522934c44 100644</span>
<span class="p_header">--- a/lib/asn1_decoder.c</span>
<span class="p_header">+++ b/lib/asn1_decoder.c</span>
<span class="p_chunk">@@ -74,7 +74,7 @@</span> <span class="p_context"> next_tag:</span>
 
 	/* Extract a tag from the data */
 	tag = data[dp++];
<span class="p_del">-	if (tag == 0) {</span>
<span class="p_add">+	if (tag == ASN1_EOC) {</span>
 		/* It appears to be an EOC. */
 		if (data[dp++] != 0)
 			goto invalid_eoc;
<span class="p_chunk">@@ -96,10 +96,8 @@</span> <span class="p_context"> next_tag:</span>
 
 	/* Extract the length */
 	len = data[dp++];
<span class="p_del">-	if (len &lt;= 0x7f) {</span>
<span class="p_del">-		dp += len;</span>
<span class="p_del">-		goto next_tag;</span>
<span class="p_del">-	}</span>
<span class="p_add">+	if (len &lt;= 0x7f)</span>
<span class="p_add">+		goto check_length;</span>
 
 	if (unlikely(len == ASN1_INDEFINITE_LENGTH)) {
 		/* Indefinite length */
<span class="p_chunk">@@ -110,14 +108,18 @@</span> <span class="p_context"> next_tag:</span>
 	}
 
 	n = len - 0x80;
<span class="p_del">-	if (unlikely(n &gt; sizeof(size_t) - 1))</span>
<span class="p_add">+	if (unlikely(n &gt; sizeof(len) - 1))</span>
 		goto length_too_long;
 	if (unlikely(n &gt; datalen - dp))
 		goto data_overrun_error;
<span class="p_del">-	for (len = 0; n &gt; 0; n--) {</span>
<span class="p_add">+	len = 0;</span>
<span class="p_add">+	for (; n &gt; 0; n--) {</span>
 		len &lt;&lt;= 8;
 		len |= data[dp++];
 	}
<span class="p_add">+check_length:</span>
<span class="p_add">+	if (len &gt; datalen - dp)</span>
<span class="p_add">+		goto data_overrun_error;</span>
 	dp += len;
 	goto next_tag;
 
<span class="p_header">diff --git a/lib/mpi/mpicoder.c b/lib/mpi/mpicoder.c</span>
<span class="p_header">index e00ff00e861c..e37dbf53e226 100644</span>
<span class="p_header">--- a/lib/mpi/mpicoder.c</span>
<span class="p_header">+++ b/lib/mpi/mpicoder.c</span>
<span class="p_chunk">@@ -367,7 +367,9 @@</span> <span class="p_context"> int mpi_write_to_sgl(MPI a, struct scatterlist *sgl, unsigned *nbytes,</span>
 	buf_len = sgl-&gt;length;
 	p2 = sg_virt(sgl);
 
<span class="p_del">-	for (i = a-&gt;nlimbs - 1; i &gt;= 0; i--) {</span>
<span class="p_add">+	for (i = a-&gt;nlimbs - 1 - lzeros / BYTES_PER_MPI_LIMB,</span>
<span class="p_add">+			lzeros %= BYTES_PER_MPI_LIMB;</span>
<span class="p_add">+		i &gt;= 0; i--) {</span>
 		alimb = a-&gt;d[i];
 		p = (u8 *)&amp;alimb2;
 #if BYTES_PER_MPI_LIMB == 4
<span class="p_chunk">@@ -388,17 +390,12 @@</span> <span class="p_context"> int mpi_write_to_sgl(MPI a, struct scatterlist *sgl, unsigned *nbytes,</span>
 #error please implement for this limb size.
 #endif
 		if (lzeros &gt; 0) {
<span class="p_del">-			if (lzeros &gt;= sizeof(alimb)) {</span>
<span class="p_del">-				p -= sizeof(alimb);</span>
<span class="p_del">-				continue;</span>
<span class="p_del">-			} else {</span>
<span class="p_del">-				mpi_limb_t *limb1 = (void *)p - sizeof(alimb);</span>
<span class="p_del">-				mpi_limb_t *limb2 = (void *)p - sizeof(alimb)</span>
<span class="p_del">-							+ lzeros;</span>
<span class="p_del">-				*limb1 = *limb2;</span>
<span class="p_del">-				p -= lzeros;</span>
<span class="p_del">-				y = lzeros;</span>
<span class="p_del">-			}</span>
<span class="p_add">+			mpi_limb_t *limb1 = (void *)p - sizeof(alimb);</span>
<span class="p_add">+			mpi_limb_t *limb2 = (void *)p - sizeof(alimb)</span>
<span class="p_add">+				+ lzeros;</span>
<span class="p_add">+			*limb1 = *limb2;</span>
<span class="p_add">+			p -= lzeros;</span>
<span class="p_add">+			y = lzeros;</span>
 			lzeros -= sizeof(alimb);
 		}
 
<span class="p_header">diff --git a/mm/util.c b/mm/util.c</span>
<span class="p_header">index 9af1c12b310c..d5259b62f8d7 100644</span>
<span class="p_header">--- a/mm/util.c</span>
<span class="p_header">+++ b/mm/util.c</span>
<span class="p_chunk">@@ -199,36 +199,11 @@</span> <span class="p_context"> void __vma_link_list(struct mm_struct *mm, struct vm_area_struct *vma,</span>
 }
 
 /* Check if the vma is being used as a stack by this task */
<span class="p_del">-static int vm_is_stack_for_task(struct task_struct *t,</span>
<span class="p_del">-				struct vm_area_struct *vma)</span>
<span class="p_add">+int vma_is_stack_for_task(struct vm_area_struct *vma, struct task_struct *t)</span>
 {
 	return (vma-&gt;vm_start &lt;= KSTK_ESP(t) &amp;&amp; vma-&gt;vm_end &gt;= KSTK_ESP(t));
 }
 
<span class="p_del">-/*</span>
<span class="p_del">- * Check if the vma is being used as a stack.</span>
<span class="p_del">- * If is_group is non-zero, check in the entire thread group or else</span>
<span class="p_del">- * just check in the current task. Returns the task_struct of the task</span>
<span class="p_del">- * that the vma is stack for. Must be called under rcu_read_lock().</span>
<span class="p_del">- */</span>
<span class="p_del">-struct task_struct *task_of_stack(struct task_struct *task,</span>
<span class="p_del">-				struct vm_area_struct *vma, bool in_group)</span>
<span class="p_del">-{</span>
<span class="p_del">-	if (vm_is_stack_for_task(task, vma))</span>
<span class="p_del">-		return task;</span>
<span class="p_del">-</span>
<span class="p_del">-	if (in_group) {</span>
<span class="p_del">-		struct task_struct *t;</span>
<span class="p_del">-</span>
<span class="p_del">-		for_each_thread(task, t) {</span>
<span class="p_del">-			if (vm_is_stack_for_task(t, vma))</span>
<span class="p_del">-				return t;</span>
<span class="p_del">-		}</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">-	return NULL;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
 #if defined(CONFIG_MMU) &amp;&amp; !defined(HAVE_ARCH_PICK_MMAP_LAYOUT)
 void arch_pick_mmap_layout(struct mm_struct *mm)
 {
<span class="p_header">diff --git a/net/ipv4/udp.c b/net/ipv4/udp.c</span>
<span class="p_header">index 44e1632370dd..0b1ea5abcc04 100644</span>
<span class="p_header">--- a/net/ipv4/udp.c</span>
<span class="p_header">+++ b/net/ipv4/udp.c</span>
<span class="p_chunk">@@ -1275,6 +1275,7 @@</span> <span class="p_context"> int udp_recvmsg(struct sock *sk, struct msghdr *msg, size_t len, int noblock,</span>
 	int peeked, off = 0;
 	int err;
 	int is_udplite = IS_UDPLITE(sk);
<span class="p_add">+	bool checksum_valid = false;</span>
 	bool slow;
 
 	if (flags &amp; MSG_ERRQUEUE)
<span class="p_chunk">@@ -1300,11 +1301,12 @@</span> <span class="p_context"> try_again:</span>
 	 */
 
 	if (copied &lt; ulen || UDP_SKB_CB(skb)-&gt;partial_cov) {
<span class="p_del">-		if (udp_lib_checksum_complete(skb))</span>
<span class="p_add">+		checksum_valid = !udp_lib_checksum_complete(skb);</span>
<span class="p_add">+		if (!checksum_valid)</span>
 			goto csum_copy_err;
 	}
 
<span class="p_del">-	if (skb_csum_unnecessary(skb))</span>
<span class="p_add">+	if (checksum_valid || skb_csum_unnecessary(skb))</span>
 		err = skb_copy_datagram_msg(skb, sizeof(struct udphdr),
 					    msg, copied);
 	else {
<span class="p_header">diff --git a/net/ipv6/udp.c b/net/ipv6/udp.c</span>
<span class="p_header">index 275af43306f9..e6092bd72ee2 100644</span>
<span class="p_header">--- a/net/ipv6/udp.c</span>
<span class="p_header">+++ b/net/ipv6/udp.c</span>
<span class="p_chunk">@@ -402,6 +402,7 @@</span> <span class="p_context"> int udpv6_recvmsg(struct sock *sk, struct msghdr *msg, size_t len,</span>
 	int peeked, off = 0;
 	int err;
 	int is_udplite = IS_UDPLITE(sk);
<span class="p_add">+	bool checksum_valid = false;</span>
 	int is_udp4;
 	bool slow;
 
<span class="p_chunk">@@ -433,11 +434,12 @@</span> <span class="p_context"> try_again:</span>
 	 */
 
 	if (copied &lt; ulen || UDP_SKB_CB(skb)-&gt;partial_cov) {
<span class="p_del">-		if (udp_lib_checksum_complete(skb))</span>
<span class="p_add">+		checksum_valid = !udp_lib_checksum_complete(skb);</span>
<span class="p_add">+		if (!checksum_valid)</span>
 			goto csum_copy_err;
 	}
 
<span class="p_del">-	if (skb_csum_unnecessary(skb))</span>
<span class="p_add">+	if (checksum_valid || skb_csum_unnecessary(skb))</span>
 		err = skb_copy_datagram_msg(skb, sizeof(struct udphdr),
 					    msg, copied);
 	else {
<span class="p_header">diff --git a/net/netfilter/x_tables.c b/net/netfilter/x_tables.c</span>
<span class="p_header">index 25391fb25516..2fc6ca9d1286 100644</span>
<span class="p_header">--- a/net/netfilter/x_tables.c</span>
<span class="p_header">+++ b/net/netfilter/x_tables.c</span>
<span class="p_chunk">@@ -897,6 +897,12 @@</span> <span class="p_context"> struct xt_table_info *xt_alloc_table_info(unsigned int size)</span>
 	struct xt_table_info *info = NULL;
 	size_t sz = sizeof(*info) + size;
 
<span class="p_add">+	if (sz &lt; sizeof(*info))</span>
<span class="p_add">+		return NULL;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (sz &lt; sizeof(*info))</span>
<span class="p_add">+		return NULL;</span>
<span class="p_add">+</span>
 	/* Pedantry: prevent them from hitting BUG() in vmalloc.c --RR */
 	if ((SMP_ALIGN(size) &gt;&gt; PAGE_SHIFT) + 2 &gt; totalram_pages)
 		return NULL;
<span class="p_header">diff --git a/net/rds/recv.c b/net/rds/recv.c</span>
<span class="p_header">index a00462b0d01d..0514af3ab378 100644</span>
<span class="p_header">--- a/net/rds/recv.c</span>
<span class="p_header">+++ b/net/rds/recv.c</span>
<span class="p_chunk">@@ -545,5 +545,7 @@</span> <span class="p_context"> void rds_inc_info_copy(struct rds_incoming *inc,</span>
 		minfo.fport = inc-&gt;i_hdr.h_dport;
 	}
 
<span class="p_add">+	minfo.flags = 0;</span>
<span class="p_add">+</span>
 	rds_info_copy(iter, &amp;minfo, sizeof(minfo));
 }
<span class="p_header">diff --git a/net/sysctl_net.c b/net/sysctl_net.c</span>
<span class="p_header">index ed98c1fc3de1..46a71c701e7c 100644</span>
<span class="p_header">--- a/net/sysctl_net.c</span>
<span class="p_header">+++ b/net/sysctl_net.c</span>
<span class="p_chunk">@@ -46,7 +46,7 @@</span> <span class="p_context"> static int net_ctl_permissions(struct ctl_table_header *head,</span>
 	kgid_t root_gid = make_kgid(net-&gt;user_ns, 0);
 
 	/* Allow network administrator to have same access as root. */
<span class="p_del">-	if (ns_capable(net-&gt;user_ns, CAP_NET_ADMIN) ||</span>
<span class="p_add">+	if (ns_capable_noaudit(net-&gt;user_ns, CAP_NET_ADMIN) ||</span>
 	    uid_eq(root_uid, current_euid())) {
 		int mode = (table-&gt;mode &gt;&gt; 6) &amp; 7;
 		return (mode &lt;&lt; 6) | (mode &lt;&lt; 3) | mode;
<span class="p_header">diff --git a/net/tipc/netlink_compat.c b/net/tipc/netlink_compat.c</span>
<span class="p_header">index 2ed732bfe94b..a0c90572d0e5 100644</span>
<span class="p_header">--- a/net/tipc/netlink_compat.c</span>
<span class="p_header">+++ b/net/tipc/netlink_compat.c</span>
<span class="p_chunk">@@ -574,7 +574,8 @@</span> <span class="p_context"> static int tipc_nl_compat_link_dump(struct tipc_nl_compat_msg *msg,</span>
 
 	link_info.dest = nla_get_flag(link[TIPC_NLA_LINK_DEST]);
 	link_info.up = htonl(nla_get_flag(link[TIPC_NLA_LINK_UP]));
<span class="p_del">-	strcpy(link_info.str, nla_data(link[TIPC_NLA_LINK_NAME]));</span>
<span class="p_add">+	nla_strlcpy(link_info.str, link[TIPC_NLA_LINK_NAME],</span>
<span class="p_add">+		    TIPC_MAX_LINK_NAME);</span>
 
 	return tipc_add_tlv(msg-&gt;rep, TIPC_TLV_LINK_INFO,
 			    &amp;link_info, sizeof(link_info));
<span class="p_header">diff --git a/net/tipc/subscr.c b/net/tipc/subscr.c</span>
<span class="p_header">index 69ee2eeef968..f9ff73a8d815 100644</span>
<span class="p_header">--- a/net/tipc/subscr.c</span>
<span class="p_header">+++ b/net/tipc/subscr.c</span>
<span class="p_chunk">@@ -296,7 +296,8 @@</span> <span class="p_context"> static void tipc_subscrb_rcv_cb(struct net *net, int conid,</span>
 	if (tipc_subscrp_create(net, (struct tipc_subscr *)buf, subscrb, &amp;sub))
 		return tipc_conn_terminate(tn-&gt;topsrv, subscrb-&gt;conid);
 
<span class="p_del">-	tipc_nametbl_subscribe(sub);</span>
<span class="p_add">+	if (sub)</span>
<span class="p_add">+		tipc_nametbl_subscribe(sub);</span>
 }
 
 /* Handle one request to establish a new subscriber */
<span class="p_header">diff --git a/sound/core/rawmidi.c b/sound/core/rawmidi.c</span>
<span class="p_header">index 795437b10082..b450a27588c8 100644</span>
<span class="p_header">--- a/sound/core/rawmidi.c</span>
<span class="p_header">+++ b/sound/core/rawmidi.c</span>
<span class="p_chunk">@@ -1633,11 +1633,13 @@</span> <span class="p_context"> static int snd_rawmidi_dev_register(struct snd_device *device)</span>
 		return -EBUSY;
 	}
 	list_add_tail(&amp;rmidi-&gt;list, &amp;snd_rawmidi_devices);
<span class="p_add">+	mutex_unlock(&amp;register_mutex);</span>
 	err = snd_register_device(SNDRV_DEVICE_TYPE_RAWMIDI,
 				  rmidi-&gt;card, rmidi-&gt;device,
 				  &amp;snd_rawmidi_f_ops, rmidi, &amp;rmidi-&gt;dev);
 	if (err &lt; 0) {
 		rmidi_err(rmidi, &quot;unable to register\n&quot;);
<span class="p_add">+		mutex_lock(&amp;register_mutex);</span>
 		list_del(&amp;rmidi-&gt;list);
 		mutex_unlock(&amp;register_mutex);
 		return err;
<span class="p_chunk">@@ -1645,6 +1647,7 @@</span> <span class="p_context"> static int snd_rawmidi_dev_register(struct snd_device *device)</span>
 	if (rmidi-&gt;ops &amp;&amp; rmidi-&gt;ops-&gt;dev_register &amp;&amp;
 	    (err = rmidi-&gt;ops-&gt;dev_register(rmidi)) &lt; 0) {
 		snd_unregister_device(&amp;rmidi-&gt;dev);
<span class="p_add">+		mutex_lock(&amp;register_mutex);</span>
 		list_del(&amp;rmidi-&gt;list);
 		mutex_unlock(&amp;register_mutex);
 		return err;
<span class="p_chunk">@@ -1677,7 +1680,6 @@</span> <span class="p_context"> static int snd_rawmidi_dev_register(struct snd_device *device)</span>
 		}
 	}
 #endif /* CONFIG_SND_OSSEMUL */
<span class="p_del">-	mutex_unlock(&amp;register_mutex);</span>
 	sprintf(name, &quot;midi%d&quot;, rmidi-&gt;device);
 	entry = snd_info_create_card_entry(rmidi-&gt;card, name, rmidi-&gt;card-&gt;proc_root);
 	if (entry) {
<span class="p_header">diff --git a/sound/core/timer.c b/sound/core/timer.c</span>
<span class="p_header">index 637d034bb084..ae4ea2e2e7fe 100644</span>
<span class="p_header">--- a/sound/core/timer.c</span>
<span class="p_header">+++ b/sound/core/timer.c</span>
<span class="p_chunk">@@ -296,8 +296,21 @@</span> <span class="p_context"> int snd_timer_open(struct snd_timer_instance **ti,</span>
 		get_device(&amp;timer-&gt;card-&gt;card_dev);
 	timeri-&gt;slave_class = tid-&gt;dev_sclass;
 	timeri-&gt;slave_id = slave_id;
<span class="p_del">-	if (list_empty(&amp;timer-&gt;open_list_head) &amp;&amp; timer-&gt;hw.open)</span>
<span class="p_del">-		timer-&gt;hw.open(timer);</span>
<span class="p_add">+</span>
<span class="p_add">+	if (list_empty(&amp;timer-&gt;open_list_head) &amp;&amp; timer-&gt;hw.open) {</span>
<span class="p_add">+		int err = timer-&gt;hw.open(timer);</span>
<span class="p_add">+		if (err) {</span>
<span class="p_add">+			kfree(timeri-&gt;owner);</span>
<span class="p_add">+			kfree(timeri);</span>
<span class="p_add">+</span>
<span class="p_add">+			if (timer-&gt;card)</span>
<span class="p_add">+				put_device(&amp;timer-&gt;card-&gt;card_dev);</span>
<span class="p_add">+			module_put(timer-&gt;module);</span>
<span class="p_add">+			mutex_unlock(&amp;register_mutex);</span>
<span class="p_add">+			return err;</span>
<span class="p_add">+		}</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
 	list_add_tail(&amp;timeri-&gt;open_list, &amp;timer-&gt;open_list_head);
 	snd_timer_check_master(timeri);
 	mutex_unlock(&amp;register_mutex);
<span class="p_chunk">@@ -837,6 +850,7 @@</span> <span class="p_context"> int snd_timer_new(struct snd_card *card, char *id, struct snd_timer_id *tid,</span>
 	timer-&gt;tmr_subdevice = tid-&gt;subdevice;
 	if (id)
 		strlcpy(timer-&gt;id, id, sizeof(timer-&gt;id));
<span class="p_add">+	timer-&gt;sticks = 1;</span>
 	INIT_LIST_HEAD(&amp;timer-&gt;device_list);
 	INIT_LIST_HEAD(&amp;timer-&gt;open_list_head);
 	INIT_LIST_HEAD(&amp;timer-&gt;active_list_head);
<span class="p_chunk">@@ -1967,6 +1981,7 @@</span> <span class="p_context"> static ssize_t snd_timer_user_read(struct file *file, char __user *buffer,</span>
 		tu-&gt;qused--;
 		spin_unlock_irq(&amp;tu-&gt;qlock);
 
<span class="p_add">+		mutex_lock(&amp;tu-&gt;ioctl_lock);</span>
 		if (tu-&gt;tread) {
 			if (copy_to_user(buffer, &amp;tu-&gt;tqueue[qhead],
 					 sizeof(struct snd_timer_tread)))
<span class="p_chunk">@@ -1976,6 +1991,7 @@</span> <span class="p_context"> static ssize_t snd_timer_user_read(struct file *file, char __user *buffer,</span>
 					 sizeof(struct snd_timer_read)))
 				err = -EFAULT;
 		}
<span class="p_add">+		mutex_unlock(&amp;tu-&gt;ioctl_lock);</span>
 
 		spin_lock_irq(&amp;tu-&gt;qlock);
 		if (err &lt; 0)
<span class="p_header">diff --git a/sound/firewire/fireworks/fireworks.h b/sound/firewire/fireworks/fireworks.h</span>
<span class="p_header">index c7cb7deafe48..2c316a9bc7f6 100644</span>
<span class="p_header">--- a/sound/firewire/fireworks/fireworks.h</span>
<span class="p_header">+++ b/sound/firewire/fireworks/fireworks.h</span>
<span class="p_chunk">@@ -106,7 +106,6 @@</span> <span class="p_context"> struct snd_efw {</span>
 	u8 *resp_buf;
 	u8 *pull_ptr;
 	u8 *push_ptr;
<span class="p_del">-	unsigned int resp_queues;</span>
 };
 
 int snd_efw_transaction_cmd(struct fw_unit *unit,
<span class="p_header">diff --git a/sound/firewire/fireworks/fireworks_hwdep.c b/sound/firewire/fireworks/fireworks_hwdep.c</span>
<span class="p_header">index 33df8655fe81..2e1d9a23920c 100644</span>
<span class="p_header">--- a/sound/firewire/fireworks/fireworks_hwdep.c</span>
<span class="p_header">+++ b/sound/firewire/fireworks/fireworks_hwdep.c</span>
<span class="p_chunk">@@ -25,6 +25,7 @@</span> <span class="p_context"> hwdep_read_resp_buf(struct snd_efw *efw, char __user *buf, long remained,</span>
 {
 	unsigned int length, till_end, type;
 	struct snd_efw_transaction *t;
<span class="p_add">+	u8 *pull_ptr;</span>
 	long count = 0;
 
 	if (remained &lt; sizeof(type) + sizeof(struct snd_efw_transaction))
<span class="p_chunk">@@ -38,8 +39,17 @@</span> <span class="p_context"> hwdep_read_resp_buf(struct snd_efw *efw, char __user *buf, long remained,</span>
 	buf += sizeof(type);
 
 	/* write into buffer as many responses as possible */
<span class="p_del">-	while (efw-&gt;resp_queues &gt; 0) {</span>
<span class="p_del">-		t = (struct snd_efw_transaction *)(efw-&gt;pull_ptr);</span>
<span class="p_add">+	spin_lock_irq(&amp;efw-&gt;lock);</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * When another task reaches here during this task&#39;s access to user</span>
<span class="p_add">+	 * space, it picks up current position in buffer and can read the same</span>
<span class="p_add">+	 * series of responses.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	pull_ptr = efw-&gt;pull_ptr;</span>
<span class="p_add">+</span>
<span class="p_add">+	while (efw-&gt;push_ptr != pull_ptr) {</span>
<span class="p_add">+		t = (struct snd_efw_transaction *)(pull_ptr);</span>
 		length = be32_to_cpu(t-&gt;length) * sizeof(__be32);
 
 		/* confirm enough space for this response */
<span class="p_chunk">@@ -49,26 +59,39 @@</span> <span class="p_context"> hwdep_read_resp_buf(struct snd_efw *efw, char __user *buf, long remained,</span>
 		/* copy from ring buffer to user buffer */
 		while (length &gt; 0) {
 			till_end = snd_efw_resp_buf_size -
<span class="p_del">-				(unsigned int)(efw-&gt;pull_ptr - efw-&gt;resp_buf);</span>
<span class="p_add">+				(unsigned int)(pull_ptr - efw-&gt;resp_buf);</span>
 			till_end = min_t(unsigned int, length, till_end);
 
<span class="p_del">-			if (copy_to_user(buf, efw-&gt;pull_ptr, till_end))</span>
<span class="p_add">+			spin_unlock_irq(&amp;efw-&gt;lock);</span>
<span class="p_add">+</span>
<span class="p_add">+			if (copy_to_user(buf, pull_ptr, till_end))</span>
 				return -EFAULT;
 
<span class="p_del">-			efw-&gt;pull_ptr += till_end;</span>
<span class="p_del">-			if (efw-&gt;pull_ptr &gt;= efw-&gt;resp_buf +</span>
<span class="p_del">-					     snd_efw_resp_buf_size)</span>
<span class="p_del">-				efw-&gt;pull_ptr -= snd_efw_resp_buf_size;</span>
<span class="p_add">+			spin_lock_irq(&amp;efw-&gt;lock);</span>
<span class="p_add">+</span>
<span class="p_add">+			pull_ptr += till_end;</span>
<span class="p_add">+			if (pull_ptr &gt;= efw-&gt;resp_buf + snd_efw_resp_buf_size)</span>
<span class="p_add">+				pull_ptr -= snd_efw_resp_buf_size;</span>
 
 			length -= till_end;
 			buf += till_end;
 			count += till_end;
 			remained -= till_end;
 		}
<span class="p_del">-</span>
<span class="p_del">-		efw-&gt;resp_queues--;</span>
 	}
 
<span class="p_add">+	/*</span>
<span class="p_add">+	 * All of tasks can read from the buffer nearly simultaneously, but the</span>
<span class="p_add">+	 * last position for each task is different depending on the length of</span>
<span class="p_add">+	 * given buffer. Here, for simplicity, a position of buffer is set by</span>
<span class="p_add">+	 * the latest task. It&#39;s better for a listening application to allow one</span>
<span class="p_add">+	 * thread to read from the buffer. Unless, each task can read different</span>
<span class="p_add">+	 * sequence of responses depending on variation of buffer length.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	efw-&gt;pull_ptr = pull_ptr;</span>
<span class="p_add">+</span>
<span class="p_add">+	spin_unlock_irq(&amp;efw-&gt;lock);</span>
<span class="p_add">+</span>
 	return count;
 }
 
<span class="p_chunk">@@ -76,14 +99,17 @@</span> <span class="p_context"> static long</span>
 hwdep_read_locked(struct snd_efw *efw, char __user *buf, long count,
 		  loff_t *offset)
 {
<span class="p_del">-	union snd_firewire_event event;</span>
<span class="p_add">+	union snd_firewire_event event = {</span>
<span class="p_add">+		.lock_status.type = SNDRV_FIREWIRE_EVENT_LOCK_STATUS,</span>
<span class="p_add">+	};</span>
 
<span class="p_del">-	memset(&amp;event, 0, sizeof(event));</span>
<span class="p_add">+	spin_lock_irq(&amp;efw-&gt;lock);</span>
 
<span class="p_del">-	event.lock_status.type = SNDRV_FIREWIRE_EVENT_LOCK_STATUS;</span>
 	event.lock_status.status = (efw-&gt;dev_lock_count &gt; 0);
 	efw-&gt;dev_lock_changed = false;
 
<span class="p_add">+	spin_unlock_irq(&amp;efw-&gt;lock);</span>
<span class="p_add">+</span>
 	count = min_t(long, count, sizeof(event.lock_status));
 
 	if (copy_to_user(buf, &amp;event, count))
<span class="p_chunk">@@ -98,10 +124,15 @@</span> <span class="p_context"> hwdep_read(struct snd_hwdep *hwdep, char __user *buf, long count,</span>
 {
 	struct snd_efw *efw = hwdep-&gt;private_data;
 	DEFINE_WAIT(wait);
<span class="p_add">+	bool dev_lock_changed;</span>
<span class="p_add">+	bool queued;</span>
 
 	spin_lock_irq(&amp;efw-&gt;lock);
 
<span class="p_del">-	while ((!efw-&gt;dev_lock_changed) &amp;&amp; (efw-&gt;resp_queues == 0)) {</span>
<span class="p_add">+	dev_lock_changed = efw-&gt;dev_lock_changed;</span>
<span class="p_add">+	queued = efw-&gt;push_ptr != efw-&gt;pull_ptr;</span>
<span class="p_add">+</span>
<span class="p_add">+	while (!dev_lock_changed &amp;&amp; !queued) {</span>
 		prepare_to_wait(&amp;efw-&gt;hwdep_wait, &amp;wait, TASK_INTERRUPTIBLE);
 		spin_unlock_irq(&amp;efw-&gt;lock);
 		schedule();
<span class="p_chunk">@@ -109,15 +140,17 @@</span> <span class="p_context"> hwdep_read(struct snd_hwdep *hwdep, char __user *buf, long count,</span>
 		if (signal_pending(current))
 			return -ERESTARTSYS;
 		spin_lock_irq(&amp;efw-&gt;lock);
<span class="p_add">+		dev_lock_changed = efw-&gt;dev_lock_changed;</span>
<span class="p_add">+		queued = efw-&gt;push_ptr != efw-&gt;pull_ptr;</span>
 	}
 
<span class="p_del">-	if (efw-&gt;dev_lock_changed)</span>
<span class="p_add">+	spin_unlock_irq(&amp;efw-&gt;lock);</span>
<span class="p_add">+</span>
<span class="p_add">+	if (dev_lock_changed)</span>
 		count = hwdep_read_locked(efw, buf, count, offset);
<span class="p_del">-	else if (efw-&gt;resp_queues &gt; 0)</span>
<span class="p_add">+	else if (queued)</span>
 		count = hwdep_read_resp_buf(efw, buf, count, offset);
 
<span class="p_del">-	spin_unlock_irq(&amp;efw-&gt;lock);</span>
<span class="p_del">-</span>
 	return count;
 }
 
<span class="p_chunk">@@ -160,7 +193,7 @@</span> <span class="p_context"> hwdep_poll(struct snd_hwdep *hwdep, struct file *file, poll_table *wait)</span>
 	poll_wait(file, &amp;efw-&gt;hwdep_wait, wait);
 
 	spin_lock_irq(&amp;efw-&gt;lock);
<span class="p_del">-	if (efw-&gt;dev_lock_changed || (efw-&gt;resp_queues &gt; 0))</span>
<span class="p_add">+	if (efw-&gt;dev_lock_changed || efw-&gt;pull_ptr != efw-&gt;push_ptr)</span>
 		events = POLLIN | POLLRDNORM;
 	else
 		events = 0;
<span class="p_header">diff --git a/sound/firewire/fireworks/fireworks_proc.c b/sound/firewire/fireworks/fireworks_proc.c</span>
<span class="p_header">index 0639dcb13f7d..beb0a0ffee57 100644</span>
<span class="p_header">--- a/sound/firewire/fireworks/fireworks_proc.c</span>
<span class="p_header">+++ b/sound/firewire/fireworks/fireworks_proc.c</span>
<span class="p_chunk">@@ -188,8 +188,8 @@</span> <span class="p_context"> proc_read_queues_state(struct snd_info_entry *entry,</span>
 	else
 		consumed = (unsigned int)(efw-&gt;push_ptr - efw-&gt;pull_ptr);
 
<span class="p_del">-	snd_iprintf(buffer, &quot;%d %d/%d\n&quot;,</span>
<span class="p_del">-		    efw-&gt;resp_queues, consumed, snd_efw_resp_buf_size);</span>
<span class="p_add">+	snd_iprintf(buffer, &quot;%d/%d\n&quot;,</span>
<span class="p_add">+		    consumed, snd_efw_resp_buf_size);</span>
 }
 
 static void
<span class="p_header">diff --git a/sound/firewire/fireworks/fireworks_transaction.c b/sound/firewire/fireworks/fireworks_transaction.c</span>
<span class="p_header">index f550808d1784..36a08ba51ec7 100644</span>
<span class="p_header">--- a/sound/firewire/fireworks/fireworks_transaction.c</span>
<span class="p_header">+++ b/sound/firewire/fireworks/fireworks_transaction.c</span>
<span class="p_chunk">@@ -121,11 +121,11 @@</span> <span class="p_context"> copy_resp_to_buf(struct snd_efw *efw, void *data, size_t length, int *rcode)</span>
 	size_t capacity, till_end;
 	struct snd_efw_transaction *t;
 
<span class="p_del">-	spin_lock_irq(&amp;efw-&gt;lock);</span>
<span class="p_del">-</span>
 	t = (struct snd_efw_transaction *)data;
 	length = min_t(size_t, be32_to_cpu(t-&gt;length) * sizeof(u32), length);
 
<span class="p_add">+	spin_lock_irq(&amp;efw-&gt;lock);</span>
<span class="p_add">+</span>
 	if (efw-&gt;push_ptr &lt; efw-&gt;pull_ptr)
 		capacity = (unsigned int)(efw-&gt;pull_ptr - efw-&gt;push_ptr);
 	else
<span class="p_chunk">@@ -155,7 +155,6 @@</span> <span class="p_context"> copy_resp_to_buf(struct snd_efw *efw, void *data, size_t length, int *rcode)</span>
 	}
 
 	/* for hwdep */
<span class="p_del">-	efw-&gt;resp_queues++;</span>
 	wake_up(&amp;efw-&gt;hwdep_wait);
 
 	*rcode = RCODE_COMPLETE;
<span class="p_header">diff --git a/sound/firewire/tascam/tascam-hwdep.c b/sound/firewire/tascam/tascam-hwdep.c</span>
<span class="p_header">index 131267c3a042..106406cbfaa3 100644</span>
<span class="p_header">--- a/sound/firewire/tascam/tascam-hwdep.c</span>
<span class="p_header">+++ b/sound/firewire/tascam/tascam-hwdep.c</span>
<span class="p_chunk">@@ -16,31 +16,14 @@</span> <span class="p_context"></span>
 
 #include &quot;tascam.h&quot;
 
<span class="p_del">-static long hwdep_read_locked(struct snd_tscm *tscm, char __user *buf,</span>
<span class="p_del">-			      long count)</span>
<span class="p_del">-{</span>
<span class="p_del">-	union snd_firewire_event event;</span>
<span class="p_del">-</span>
<span class="p_del">-	memset(&amp;event, 0, sizeof(event));</span>
<span class="p_del">-</span>
<span class="p_del">-	event.lock_status.type = SNDRV_FIREWIRE_EVENT_LOCK_STATUS;</span>
<span class="p_del">-	event.lock_status.status = (tscm-&gt;dev_lock_count &gt; 0);</span>
<span class="p_del">-	tscm-&gt;dev_lock_changed = false;</span>
<span class="p_del">-</span>
<span class="p_del">-	count = min_t(long, count, sizeof(event.lock_status));</span>
<span class="p_del">-</span>
<span class="p_del">-	if (copy_to_user(buf, &amp;event, count))</span>
<span class="p_del">-		return -EFAULT;</span>
<span class="p_del">-</span>
<span class="p_del">-	return count;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
 static long hwdep_read(struct snd_hwdep *hwdep, char __user *buf, long count,
 		       loff_t *offset)
 {
 	struct snd_tscm *tscm = hwdep-&gt;private_data;
 	DEFINE_WAIT(wait);
<span class="p_del">-	union snd_firewire_event event;</span>
<span class="p_add">+	union snd_firewire_event event = {</span>
<span class="p_add">+		.lock_status.type = SNDRV_FIREWIRE_EVENT_LOCK_STATUS,</span>
<span class="p_add">+	};</span>
 
 	spin_lock_irq(&amp;tscm-&gt;lock);
 
<span class="p_chunk">@@ -54,10 +37,16 @@</span> <span class="p_context"> static long hwdep_read(struct snd_hwdep *hwdep, char __user *buf, long count,</span>
 		spin_lock_irq(&amp;tscm-&gt;lock);
 	}
 
<span class="p_del">-	memset(&amp;event, 0, sizeof(event));</span>
<span class="p_del">-	count = hwdep_read_locked(tscm, buf, count);</span>
<span class="p_add">+	event.lock_status.status = (tscm-&gt;dev_lock_count &gt; 0);</span>
<span class="p_add">+	tscm-&gt;dev_lock_changed = false;</span>
<span class="p_add">+</span>
 	spin_unlock_irq(&amp;tscm-&gt;lock);
 
<span class="p_add">+	count = min_t(long, count, sizeof(event.lock_status));</span>
<span class="p_add">+</span>
<span class="p_add">+	if (copy_to_user(buf, &amp;event, count))</span>
<span class="p_add">+		return -EFAULT;</span>
<span class="p_add">+</span>
 	return count;
 }
 
<span class="p_header">diff --git a/sound/pci/hda/hda_intel.c b/sound/pci/hda/hda_intel.c</span>
<span class="p_header">index 12f7f6fdae4d..d4671973d889 100644</span>
<span class="p_header">--- a/sound/pci/hda/hda_intel.c</span>
<span class="p_header">+++ b/sound/pci/hda/hda_intel.c</span>
<span class="p_chunk">@@ -2366,6 +2366,10 @@</span> <span class="p_context"> static const struct pci_device_id azx_ids[] = {</span>
 	  .driver_data = AZX_DRIVER_ATIHDMI_NS | AZX_DCAPS_PRESET_ATI_HDMI_NS },
 	{ PCI_DEVICE(0x1002, 0xaae8),
 	  .driver_data = AZX_DRIVER_ATIHDMI_NS | AZX_DCAPS_PRESET_ATI_HDMI_NS },
<span class="p_add">+	{ PCI_DEVICE(0x1002, 0xaae0),</span>
<span class="p_add">+	  .driver_data = AZX_DRIVER_ATIHDMI_NS | AZX_DCAPS_PRESET_ATI_HDMI_NS },</span>
<span class="p_add">+	{ PCI_DEVICE(0x1002, 0xaaf0),</span>
<span class="p_add">+	  .driver_data = AZX_DRIVER_ATIHDMI_NS | AZX_DCAPS_PRESET_ATI_HDMI_NS },</span>
 	/* VIA VT8251/VT8237A */
 	{ PCI_DEVICE(0x1106, 0x3288),
 	  .driver_data = AZX_DRIVER_VIA | AZX_DCAPS_POSFIX_VIA },
<span class="p_header">diff --git a/sound/pci/hda/patch_hdmi.c b/sound/pci/hda/patch_hdmi.c</span>
<span class="p_header">index f7bcd8dbac14..a8045b8a2a18 100644</span>
<span class="p_header">--- a/sound/pci/hda/patch_hdmi.c</span>
<span class="p_header">+++ b/sound/pci/hda/patch_hdmi.c</span>
<span class="p_chunk">@@ -51,8 +51,10 @@</span> <span class="p_context"> MODULE_PARM_DESC(static_hdmi_pcm, &quot;Don&#39;t restrict PCM parameters per ELD info&quot;);</span>
 #define is_broadwell(codec)    ((codec)-&gt;core.vendor_id == 0x80862808)
 #define is_skylake(codec) ((codec)-&gt;core.vendor_id == 0x80862809)
 #define is_broxton(codec) ((codec)-&gt;core.vendor_id == 0x8086280a)
<span class="p_add">+#define is_kabylake(codec) ((codec)-&gt;core.vendor_id == 0x8086280b)</span>
 #define is_haswell_plus(codec) (is_haswell(codec) || is_broadwell(codec) \
<span class="p_del">-				|| is_skylake(codec) || is_broxton(codec))</span>
<span class="p_add">+				|| is_skylake(codec) || is_broxton(codec) \</span>
<span class="p_add">+				|| is_kabylake(codec))</span>
 
 #define is_valleyview(codec) ((codec)-&gt;core.vendor_id == 0x80862882)
 #define is_cherryview(codec) ((codec)-&gt;core.vendor_id == 0x80862883)
<span class="p_chunk">@@ -3584,6 +3586,7 @@</span> <span class="p_context"> HDA_CODEC_ENTRY(0x80862807, &quot;Haswell HDMI&quot;,	patch_generic_hdmi),</span>
 HDA_CODEC_ENTRY(0x80862808, &quot;Broadwell HDMI&quot;,	patch_generic_hdmi),
 HDA_CODEC_ENTRY(0x80862809, &quot;Skylake HDMI&quot;,	patch_generic_hdmi),
 HDA_CODEC_ENTRY(0x8086280a, &quot;Broxton HDMI&quot;,	patch_generic_hdmi),
<span class="p_add">+HDA_CODEC_ENTRY(0x8086280b, &quot;Kabylake HDMI&quot;,	patch_generic_hdmi),</span>
 HDA_CODEC_ENTRY(0x80862880, &quot;CedarTrail HDMI&quot;,	patch_generic_hdmi),
 HDA_CODEC_ENTRY(0x80862882, &quot;Valleyview2 HDMI&quot;,	patch_generic_hdmi),
 HDA_CODEC_ENTRY(0x80862883, &quot;Braswell HDMI&quot;,	patch_generic_hdmi),
<span class="p_header">diff --git a/sound/pci/hda/patch_realtek.c b/sound/pci/hda/patch_realtek.c</span>
<span class="p_header">index f25479ba3981..eaee626ab185 100644</span>
<span class="p_header">--- a/sound/pci/hda/patch_realtek.c</span>
<span class="p_header">+++ b/sound/pci/hda/patch_realtek.c</span>
<span class="p_chunk">@@ -4840,6 +4840,7 @@</span> <span class="p_context"> enum {</span>
 	ALC221_FIXUP_HP_FRONT_MIC,
 	ALC292_FIXUP_TPT460,
 	ALC298_FIXUP_SPK_VOLUME,
<span class="p_add">+	ALC256_FIXUP_DELL_INSPIRON_7559_SUBWOOFER,</span>
 };
 
 static const struct hda_fixup alc269_fixups[] = {
<span class="p_chunk">@@ -5501,6 +5502,15 @@</span> <span class="p_context"> static const struct hda_fixup alc269_fixups[] = {</span>
 		.chained = true,
 		.chain_id = ALC298_FIXUP_DELL1_MIC_NO_PRESENCE,
 	},
<span class="p_add">+	[ALC256_FIXUP_DELL_INSPIRON_7559_SUBWOOFER] = {</span>
<span class="p_add">+		.type = HDA_FIXUP_PINS,</span>
<span class="p_add">+		.v.pins = (const struct hda_pintbl[]) {</span>
<span class="p_add">+			{ 0x1b, 0x90170151 },</span>
<span class="p_add">+			{ }</span>
<span class="p_add">+		},</span>
<span class="p_add">+		.chained = true,</span>
<span class="p_add">+		.chain_id = ALC255_FIXUP_DELL1_MIC_NO_PRESENCE</span>
<span class="p_add">+	},</span>
 };
 
 static const struct snd_pci_quirk alc269_fixup_tbl[] = {
<span class="p_chunk">@@ -5545,6 +5555,7 @@</span> <span class="p_context"> static const struct snd_pci_quirk alc269_fixup_tbl[] = {</span>
 	SND_PCI_QUIRK(0x1028, 0x06df, &quot;Dell&quot;, ALC293_FIXUP_DISABLE_AAMIX_MULTIJACK),
 	SND_PCI_QUIRK(0x1028, 0x06e0, &quot;Dell&quot;, ALC293_FIXUP_DISABLE_AAMIX_MULTIJACK),
 	SND_PCI_QUIRK(0x1028, 0x0704, &quot;Dell XPS 13 9350&quot;, ALC256_FIXUP_DELL_XPS_13_HEADPHONE_NOISE),
<span class="p_add">+	SND_PCI_QUIRK(0x1028, 0x0706, &quot;Dell Inspiron 7559&quot;, ALC256_FIXUP_DELL_INSPIRON_7559_SUBWOOFER),</span>
 	SND_PCI_QUIRK(0x1028, 0x0725, &quot;Dell Inspiron 3162&quot;, ALC255_FIXUP_DELL_SPK_NOISE),
 	SND_PCI_QUIRK(0x1028, 0x075b, &quot;Dell XPS 13 9360&quot;, ALC256_FIXUP_DELL_XPS_13_HEADPHONE_NOISE),
 	SND_PCI_QUIRK(0x1028, 0x075d, &quot;Dell AIO&quot;, ALC298_FIXUP_SPK_VOLUME),
<span class="p_chunk">@@ -5879,6 +5890,10 @@</span> <span class="p_context"> static const struct snd_hda_pin_quirk alc269_pin_fixup_tbl[] = {</span>
 		{0x12, 0x90a60170},
 		{0x14, 0x90170120},
 		{0x21, 0x02211030}),
<span class="p_add">+	SND_HDA_PIN_QUIRK(0x10ec0256, 0x1028, &quot;Dell Inspiron 5468&quot;, ALC255_FIXUP_DELL1_MIC_NO_PRESENCE,</span>
<span class="p_add">+		{0x12, 0x90a60180},</span>
<span class="p_add">+		{0x14, 0x90170120},</span>
<span class="p_add">+		{0x21, 0x02211030}),</span>
 	SND_HDA_PIN_QUIRK(0x10ec0256, 0x1028, &quot;Dell&quot;, ALC255_FIXUP_DELL1_MIC_NO_PRESENCE,
 		ALC256_STANDARD_PINS),
 	SND_HDA_PIN_QUIRK(0x10ec0280, 0x103c, &quot;HP&quot;, ALC280_FIXUP_HP_GPIO4,
<span class="p_header">diff --git a/sound/soc/atmel/atmel_ssc_dai.c b/sound/soc/atmel/atmel_ssc_dai.c</span>
<span class="p_header">index ba8def5665c4..6726143c7fc5 100644</span>
<span class="p_header">--- a/sound/soc/atmel/atmel_ssc_dai.c</span>
<span class="p_header">+++ b/sound/soc/atmel/atmel_ssc_dai.c</span>
<span class="p_chunk">@@ -298,8 +298,9 @@</span> <span class="p_context"> static int atmel_ssc_startup(struct snd_pcm_substream *substream,</span>
 	clk_enable(ssc_p-&gt;ssc-&gt;clk);
 	ssc_p-&gt;mck_rate = clk_get_rate(ssc_p-&gt;ssc-&gt;clk);
 
<span class="p_del">-	/* Reset the SSC to keep it at a clean status */</span>
<span class="p_del">-	ssc_writel(ssc_p-&gt;ssc-&gt;regs, CR, SSC_BIT(CR_SWRST));</span>
<span class="p_add">+	/* Reset the SSC unless initialized to keep it in a clean state */</span>
<span class="p_add">+	if (!ssc_p-&gt;initialized)</span>
<span class="p_add">+		ssc_writel(ssc_p-&gt;ssc-&gt;regs, CR, SSC_BIT(CR_SWRST));</span>
 
 	if (substream-&gt;stream == SNDRV_PCM_STREAM_PLAYBACK) {
 		dir = 0;
<span class="p_header">diff --git a/sound/usb/quirks.c b/sound/usb/quirks.c</span>
<span class="p_header">index a3e1252ce242..3039e907f1f8 100644</span>
<span class="p_header">--- a/sound/usb/quirks.c</span>
<span class="p_header">+++ b/sound/usb/quirks.c</span>
<span class="p_chunk">@@ -1142,6 +1142,7 @@</span> <span class="p_context"> bool snd_usb_get_sample_rate_quirk(struct snd_usb_audio *chip)</span>
 	case USB_ID(0x0556, 0x0014): /* Phoenix Audio TMX320VC */
 	case USB_ID(0x05A3, 0x9420): /* ELP HD USB Camera */
 	case USB_ID(0x074D, 0x3553): /* Outlaw RR2150 (Micronas UAC3553B) */
<span class="p_add">+	case USB_ID(0x1901, 0x0191): /* GE B850V3 CP2114 audio interface */</span>
 	case USB_ID(0x1de7, 0x0013): /* Phoenix Audio MT202exe */
 	case USB_ID(0x1de7, 0x0014): /* Phoenix Audio TMX320 */
 	case USB_ID(0x1de7, 0x0114): /* Phoenix Audio MT202pcs */
<span class="p_header">diff --git a/tools/hv/hv_fcopy_daemon.c b/tools/hv/hv_fcopy_daemon.c</span>
<span class="p_header">index 5480e4e424eb..f1d742682317 100644</span>
<span class="p_header">--- a/tools/hv/hv_fcopy_daemon.c</span>
<span class="p_header">+++ b/tools/hv/hv_fcopy_daemon.c</span>
<span class="p_chunk">@@ -37,12 +37,14 @@</span> <span class="p_context"></span>
 
 static int target_fd;
 static char target_fname[W_MAX_PATH];
<span class="p_add">+static unsigned long long filesize;</span>
 
 static int hv_start_fcopy(struct hv_start_fcopy *smsg)
 {
 	int error = HV_E_FAIL;
 	char *q, *p;
 
<span class="p_add">+	filesize = 0;</span>
 	p = (char *)smsg-&gt;path_name;
 	snprintf(target_fname, sizeof(target_fname), &quot;%s/%s&quot;,
 		 (char *)smsg-&gt;path_name, (char *)smsg-&gt;file_name);
<span class="p_chunk">@@ -98,14 +100,26 @@</span> <span class="p_context"> done:</span>
 static int hv_copy_data(struct hv_do_fcopy *cpmsg)
 {
 	ssize_t bytes_written;
<span class="p_add">+	int ret = 0;</span>
 
 	bytes_written = pwrite(target_fd, cpmsg-&gt;data, cpmsg-&gt;size,
 				cpmsg-&gt;offset);
 
<span class="p_del">-	if (bytes_written != cpmsg-&gt;size)</span>
<span class="p_del">-		return HV_E_FAIL;</span>
<span class="p_add">+	filesize += cpmsg-&gt;size;</span>
<span class="p_add">+	if (bytes_written != cpmsg-&gt;size) {</span>
<span class="p_add">+		switch (errno) {</span>
<span class="p_add">+		case ENOSPC:</span>
<span class="p_add">+			ret = HV_ERROR_DISK_FULL;</span>
<span class="p_add">+			break;</span>
<span class="p_add">+		default:</span>
<span class="p_add">+			ret = HV_E_FAIL;</span>
<span class="p_add">+			break;</span>
<span class="p_add">+		}</span>
<span class="p_add">+		syslog(LOG_ERR, &quot;pwrite failed to write %llu bytes: %ld (%s)&quot;,</span>
<span class="p_add">+		       filesize, (long)bytes_written, strerror(errno));</span>
<span class="p_add">+	}</span>
 
<span class="p_del">-	return 0;</span>
<span class="p_add">+	return ret;</span>
 }
 
 static int hv_copy_finished(void)

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



