
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>Linux 4.10.5 - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    Linux 4.10.5</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=37061">gregkh@linuxfoundation.org</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>March 22, 2017, 1:06 p.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;20170322130637.GB5759@kroah.com&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/9638763/mbox/"
   >mbox</a>
|
   <a href="/patch/9638763/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/9638763/">/patch/9638763/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
	[172.30.200.125])
	by pdx-korg-patchwork.web.codeaurora.org (Postfix) with ESMTP id
	B70B660327 for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Wed, 22 Mar 2017 13:08:35 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id A248F281F9
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Wed, 22 Mar 2017 13:08:35 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id 969BB28459; Wed, 22 Mar 2017 13:08:35 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-6.9 required=2.0 tests=BAYES_00,RCVD_IN_DNSWL_HI
	autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id EB69F281F9
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Wed, 22 Mar 2017 13:08:31 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1758666AbdCVNIX (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Wed, 22 Mar 2017 09:08:23 -0400
Received: from mail.linuxfoundation.org ([140.211.169.12]:46996 &quot;EHLO
	mail.linuxfoundation.org&quot; rhost-flags-OK-OK-OK-OK) by vger.kernel.org
	with ESMTP id S934086AbdCVNHh (ORCPT
	&lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Wed, 22 Mar 2017 09:07:37 -0400
Received: from localhost (LFbn-1-12060-104.w90-92.abo.wanadoo.fr
	[90.92.122.104])
	by mail.linuxfoundation.org (Postfix) with ESMTPSA id ADBBDBD6;
	Wed, 22 Mar 2017 13:06:50 +0000 (UTC)
Date: Wed, 22 Mar 2017 14:06:37 +0100
From: Greg KH &lt;gregkh@linuxfoundation.org&gt;
To: linux-kernel@vger.kernel.org, Andrew Morton &lt;akpm@linux-foundation.org&gt;,
	torvalds@linux-foundation.org, stable@vger.kernel.org
Cc: lwn@lwn.net, Jiri Slaby &lt;jslaby@suse.cz&gt;
Subject: Re: Linux 4.10.5
Message-ID: &lt;20170322130637.GB5759@kroah.com&gt;
References: &lt;20170322130633.GA5759@kroah.com&gt;
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Disposition: inline
In-Reply-To: &lt;20170322130633.GA5759@kroah.com&gt;
User-Agent: Mutt/1.8.0 (2017-02-23)
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=37061">gregkh@linuxfoundation.org</a> - March 22, 2017, 1:06 p.m.</div>
<pre class="content">

</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/Documentation/arm64/silicon-errata.txt b/Documentation/arm64/silicon-errata.txt</span>
<span class="p_header">index 405da11fc3e4..d11af52427b4 100644</span>
<span class="p_header">--- a/Documentation/arm64/silicon-errata.txt</span>
<span class="p_header">+++ b/Documentation/arm64/silicon-errata.txt</span>
<span class="p_chunk">@@ -42,24 +42,26 @@</span> <span class="p_context"> file acts as a registry of software workarounds in the Linux Kernel and</span>
 will be updated when new workarounds are committed and backported to
 stable kernels.
 
<span class="p_del">-| Implementor    | Component       | Erratum ID      | Kconfig                 |</span>
<span class="p_del">-+----------------+-----------------+-----------------+-------------------------+</span>
<span class="p_del">-| ARM            | Cortex-A53      | #826319         | ARM64_ERRATUM_826319    |</span>
<span class="p_del">-| ARM            | Cortex-A53      | #827319         | ARM64_ERRATUM_827319    |</span>
<span class="p_del">-| ARM            | Cortex-A53      | #824069         | ARM64_ERRATUM_824069    |</span>
<span class="p_del">-| ARM            | Cortex-A53      | #819472         | ARM64_ERRATUM_819472    |</span>
<span class="p_del">-| ARM            | Cortex-A53      | #845719         | ARM64_ERRATUM_845719    |</span>
<span class="p_del">-| ARM            | Cortex-A53      | #843419         | ARM64_ERRATUM_843419    |</span>
<span class="p_del">-| ARM            | Cortex-A57      | #832075         | ARM64_ERRATUM_832075    |</span>
<span class="p_del">-| ARM            | Cortex-A57      | #852523         | N/A                     |</span>
<span class="p_del">-| ARM            | Cortex-A57      | #834220         | ARM64_ERRATUM_834220    |</span>
<span class="p_del">-| ARM            | Cortex-A72      | #853709         | N/A                     |</span>
<span class="p_del">-| ARM            | MMU-500         | #841119,#826419 | N/A                     |</span>
<span class="p_del">-|                |                 |                 |                         |</span>
<span class="p_del">-| Cavium         | ThunderX ITS    | #22375, #24313  | CAVIUM_ERRATUM_22375    |</span>
<span class="p_del">-| Cavium         | ThunderX ITS    | #23144          | CAVIUM_ERRATUM_23144    |</span>
<span class="p_del">-| Cavium         | ThunderX GICv3  | #23154          | CAVIUM_ERRATUM_23154    |</span>
<span class="p_del">-| Cavium         | ThunderX Core   | #27456          | CAVIUM_ERRATUM_27456    |</span>
<span class="p_del">-| Cavium         | ThunderX SMMUv2 | #27704          | N/A		       |</span>
<span class="p_del">-|                |                 |                 |                         |</span>
<span class="p_del">-| Freescale/NXP  | LS2080A/LS1043A | A-008585        | FSL_ERRATUM_A008585     |</span>
<span class="p_add">+| Implementor    | Component       | Erratum ID      | Kconfig                     |</span>
<span class="p_add">++----------------+-----------------+-----------------+-----------------------------+</span>
<span class="p_add">+| ARM            | Cortex-A53      | #826319         | ARM64_ERRATUM_826319        |</span>
<span class="p_add">+| ARM            | Cortex-A53      | #827319         | ARM64_ERRATUM_827319        |</span>
<span class="p_add">+| ARM            | Cortex-A53      | #824069         | ARM64_ERRATUM_824069        |</span>
<span class="p_add">+| ARM            | Cortex-A53      | #819472         | ARM64_ERRATUM_819472        |</span>
<span class="p_add">+| ARM            | Cortex-A53      | #845719         | ARM64_ERRATUM_845719        |</span>
<span class="p_add">+| ARM            | Cortex-A53      | #843419         | ARM64_ERRATUM_843419        |</span>
<span class="p_add">+| ARM            | Cortex-A57      | #832075         | ARM64_ERRATUM_832075        |</span>
<span class="p_add">+| ARM            | Cortex-A57      | #852523         | N/A                         |</span>
<span class="p_add">+| ARM            | Cortex-A57      | #834220         | ARM64_ERRATUM_834220        |</span>
<span class="p_add">+| ARM            | Cortex-A72      | #853709         | N/A                         |</span>
<span class="p_add">+| ARM            | MMU-500         | #841119,#826419 | N/A                         |</span>
<span class="p_add">+|                |                 |                 |                             |</span>
<span class="p_add">+| Cavium         | ThunderX ITS    | #22375, #24313  | CAVIUM_ERRATUM_22375        |</span>
<span class="p_add">+| Cavium         | ThunderX ITS    | #23144          | CAVIUM_ERRATUM_23144        |</span>
<span class="p_add">+| Cavium         | ThunderX GICv3  | #23154          | CAVIUM_ERRATUM_23154        |</span>
<span class="p_add">+| Cavium         | ThunderX Core   | #27456          | CAVIUM_ERRATUM_27456        |</span>
<span class="p_add">+| Cavium         | ThunderX SMMUv2 | #27704          | N/A                         |</span>
<span class="p_add">+|                |                 |                 |                             |</span>
<span class="p_add">+| Freescale/NXP  | LS2080A/LS1043A | A-008585        | FSL_ERRATUM_A008585         |</span>
<span class="p_add">+|                |                 |                 |                             |</span>
<span class="p_add">+| Qualcomm Tech. | QDF2400 ITS     | E0065           | QCOM_QDF2400_ERRATUM_0065   |</span>
<span class="p_header">diff --git a/Makefile b/Makefile</span>
<span class="p_header">index 8df819e31882..48e18096913f 100644</span>
<span class="p_header">--- a/Makefile</span>
<span class="p_header">+++ b/Makefile</span>
<span class="p_chunk">@@ -1,6 +1,6 @@</span> <span class="p_context"></span>
 VERSION = 4
 PATCHLEVEL = 10
<span class="p_del">-SUBLEVEL = 4</span>
<span class="p_add">+SUBLEVEL = 5</span>
 EXTRAVERSION =
 NAME = Fearless Coyote
 
<span class="p_header">diff --git a/arch/arm64/Kconfig b/arch/arm64/Kconfig</span>
<span class="p_header">index 111742126897..51634f7f0aff 100644</span>
<span class="p_header">--- a/arch/arm64/Kconfig</span>
<span class="p_header">+++ b/arch/arm64/Kconfig</span>
<span class="p_chunk">@@ -479,6 +479,16 @@</span> <span class="p_context"> config CAVIUM_ERRATUM_27456</span>
 
 	  If unsure, say Y.
 
<span class="p_add">+config QCOM_QDF2400_ERRATUM_0065</span>
<span class="p_add">+	bool &quot;QDF2400 E0065: Incorrect GITS_TYPER.ITT_Entry_size&quot;</span>
<span class="p_add">+	default y</span>
<span class="p_add">+	help</span>
<span class="p_add">+	  On Qualcomm Datacenter Technologies QDF2400 SoC, ITS hardware reports</span>
<span class="p_add">+	  ITE size incorrectly. The GITS_TYPER.ITT_Entry_size field should have</span>
<span class="p_add">+	  been indicated as 16Bytes (0xf), not 8Bytes (0x7).</span>
<span class="p_add">+</span>
<span class="p_add">+	  If unsure, say Y.</span>
<span class="p_add">+</span>
 endmenu
 
 
<span class="p_header">diff --git a/arch/arm64/kvm/hyp/tlb.c b/arch/arm64/kvm/hyp/tlb.c</span>
<span class="p_header">index 88e2f2b938f0..55889d057757 100644</span>
<span class="p_header">--- a/arch/arm64/kvm/hyp/tlb.c</span>
<span class="p_header">+++ b/arch/arm64/kvm/hyp/tlb.c</span>
<span class="p_chunk">@@ -17,14 +17,62 @@</span> <span class="p_context"></span>
 
 #include &lt;asm/kvm_hyp.h&gt;
 
<span class="p_add">+static void __hyp_text __tlb_switch_to_guest_vhe(struct kvm *kvm)</span>
<span class="p_add">+{</span>
<span class="p_add">+	u64 val;</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * With VHE enabled, we have HCR_EL2.{E2H,TGE} = {1,1}, and</span>
<span class="p_add">+	 * most TLB operations target EL2/EL0. In order to affect the</span>
<span class="p_add">+	 * guest TLBs (EL1/EL0), we need to change one of these two</span>
<span class="p_add">+	 * bits. Changing E2H is impossible (goodbye TTBR1_EL2), so</span>
<span class="p_add">+	 * let&#39;s flip TGE before executing the TLB operation.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	write_sysreg(kvm-&gt;arch.vttbr, vttbr_el2);</span>
<span class="p_add">+	val = read_sysreg(hcr_el2);</span>
<span class="p_add">+	val &amp;= ~HCR_TGE;</span>
<span class="p_add">+	write_sysreg(val, hcr_el2);</span>
<span class="p_add">+	isb();</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static void __hyp_text __tlb_switch_to_guest_nvhe(struct kvm *kvm)</span>
<span class="p_add">+{</span>
<span class="p_add">+	write_sysreg(kvm-&gt;arch.vttbr, vttbr_el2);</span>
<span class="p_add">+	isb();</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static hyp_alternate_select(__tlb_switch_to_guest,</span>
<span class="p_add">+			    __tlb_switch_to_guest_nvhe,</span>
<span class="p_add">+			    __tlb_switch_to_guest_vhe,</span>
<span class="p_add">+			    ARM64_HAS_VIRT_HOST_EXTN);</span>
<span class="p_add">+</span>
<span class="p_add">+static void __hyp_text __tlb_switch_to_host_vhe(struct kvm *kvm)</span>
<span class="p_add">+{</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * We&#39;re done with the TLB operation, let&#39;s restore the host&#39;s</span>
<span class="p_add">+	 * view of HCR_EL2.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	write_sysreg(0, vttbr_el2);</span>
<span class="p_add">+	write_sysreg(HCR_HOST_VHE_FLAGS, hcr_el2);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static void __hyp_text __tlb_switch_to_host_nvhe(struct kvm *kvm)</span>
<span class="p_add">+{</span>
<span class="p_add">+	write_sysreg(0, vttbr_el2);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static hyp_alternate_select(__tlb_switch_to_host,</span>
<span class="p_add">+			    __tlb_switch_to_host_nvhe,</span>
<span class="p_add">+			    __tlb_switch_to_host_vhe,</span>
<span class="p_add">+			    ARM64_HAS_VIRT_HOST_EXTN);</span>
<span class="p_add">+</span>
 void __hyp_text __kvm_tlb_flush_vmid_ipa(struct kvm *kvm, phys_addr_t ipa)
 {
 	dsb(ishst);
 
 	/* Switch to requested VMID */
 	kvm = kern_hyp_va(kvm);
<span class="p_del">-	write_sysreg(kvm-&gt;arch.vttbr, vttbr_el2);</span>
<span class="p_del">-	isb();</span>
<span class="p_add">+	__tlb_switch_to_guest()(kvm);</span>
 
 	/*
 	 * We could do so much better if we had the VA as well.
<span class="p_chunk">@@ -45,7 +93,7 @@</span> <span class="p_context"> void __hyp_text __kvm_tlb_flush_vmid_ipa(struct kvm *kvm, phys_addr_t ipa)</span>
 	dsb(ish);
 	isb();
 
<span class="p_del">-	write_sysreg(0, vttbr_el2);</span>
<span class="p_add">+	__tlb_switch_to_host()(kvm);</span>
 }
 
 void __hyp_text __kvm_tlb_flush_vmid(struct kvm *kvm)
<span class="p_chunk">@@ -54,14 +102,13 @@</span> <span class="p_context"> void __hyp_text __kvm_tlb_flush_vmid(struct kvm *kvm)</span>
 
 	/* Switch to requested VMID */
 	kvm = kern_hyp_va(kvm);
<span class="p_del">-	write_sysreg(kvm-&gt;arch.vttbr, vttbr_el2);</span>
<span class="p_del">-	isb();</span>
<span class="p_add">+	__tlb_switch_to_guest()(kvm);</span>
 
 	asm volatile(&quot;tlbi vmalls12e1is&quot; : : );
 	dsb(ish);
 	isb();
 
<span class="p_del">-	write_sysreg(0, vttbr_el2);</span>
<span class="p_add">+	__tlb_switch_to_host()(kvm);</span>
 }
 
 void __hyp_text __kvm_tlb_flush_local_vmid(struct kvm_vcpu *vcpu)
<span class="p_chunk">@@ -69,14 +116,13 @@</span> <span class="p_context"> void __hyp_text __kvm_tlb_flush_local_vmid(struct kvm_vcpu *vcpu)</span>
 	struct kvm *kvm = kern_hyp_va(kern_hyp_va(vcpu)-&gt;kvm);
 
 	/* Switch to requested VMID */
<span class="p_del">-	write_sysreg(kvm-&gt;arch.vttbr, vttbr_el2);</span>
<span class="p_del">-	isb();</span>
<span class="p_add">+	__tlb_switch_to_guest()(kvm);</span>
 
 	asm volatile(&quot;tlbi vmalle1&quot; : : );
 	dsb(nsh);
 	isb();
 
<span class="p_del">-	write_sysreg(0, vttbr_el2);</span>
<span class="p_add">+	__tlb_switch_to_host()(kvm);</span>
 }
 
 void __hyp_text __kvm_flush_vm_context(void)
<span class="p_header">diff --git a/arch/powerpc/crypto/crc32c-vpmsum_glue.c b/arch/powerpc/crypto/crc32c-vpmsum_glue.c</span>
<span class="p_header">index 9fa046d56eba..411994551afc 100644</span>
<span class="p_header">--- a/arch/powerpc/crypto/crc32c-vpmsum_glue.c</span>
<span class="p_header">+++ b/arch/powerpc/crypto/crc32c-vpmsum_glue.c</span>
<span class="p_chunk">@@ -52,7 +52,7 @@</span> <span class="p_context"> static int crc32c_vpmsum_cra_init(struct crypto_tfm *tfm)</span>
 {
 	u32 *key = crypto_tfm_ctx(tfm);
 
<span class="p_del">-	*key = 0;</span>
<span class="p_add">+	*key = ~0;</span>
 
 	return 0;
 }
<span class="p_header">diff --git a/arch/x86/events/core.c b/arch/x86/events/core.c</span>
<span class="p_header">index 1635c0c8df23..e07b36c5588a 100644</span>
<span class="p_header">--- a/arch/x86/events/core.c</span>
<span class="p_header">+++ b/arch/x86/events/core.c</span>
<span class="p_chunk">@@ -2100,8 +2100,8 @@</span> <span class="p_context"> static int x86_pmu_event_init(struct perf_event *event)</span>
 
 static void refresh_pce(void *ignored)
 {
<span class="p_del">-	if (current-&gt;mm)</span>
<span class="p_del">-		load_mm_cr4(current-&gt;mm);</span>
<span class="p_add">+	if (current-&gt;active_mm)</span>
<span class="p_add">+		load_mm_cr4(current-&gt;active_mm);</span>
 }
 
 static void x86_pmu_event_mapped(struct perf_event *event)
<span class="p_header">diff --git a/arch/x86/kernel/cpu/intel_rdt_rdtgroup.c b/arch/x86/kernel/cpu/intel_rdt_rdtgroup.c</span>
<span class="p_header">index 8af04afdfcb9..84c0f23ea644 100644</span>
<span class="p_header">--- a/arch/x86/kernel/cpu/intel_rdt_rdtgroup.c</span>
<span class="p_header">+++ b/arch/x86/kernel/cpu/intel_rdt_rdtgroup.c</span>
<span class="p_chunk">@@ -727,7 +727,7 @@</span> <span class="p_context"> void rdtgroup_kn_unlock(struct kernfs_node *kn)</span>
 	if (atomic_dec_and_test(&amp;rdtgrp-&gt;waitcount) &amp;&amp;
 	    (rdtgrp-&gt;flags &amp; RDT_DELETED)) {
 		kernfs_unbreak_active_protection(kn);
<span class="p_del">-		kernfs_put(kn);</span>
<span class="p_add">+		kernfs_put(rdtgrp-&gt;kn);</span>
 		kfree(rdtgrp);
 	} else {
 		kernfs_unbreak_active_protection(kn);
<span class="p_header">diff --git a/arch/x86/kernel/head64.c b/arch/x86/kernel/head64.c</span>
<span class="p_header">index 54a2372f5dbb..b5785c197e53 100644</span>
<span class="p_header">--- a/arch/x86/kernel/head64.c</span>
<span class="p_header">+++ b/arch/x86/kernel/head64.c</span>
<span class="p_chunk">@@ -4,6 +4,7 @@</span> <span class="p_context"></span>
  *  Copyright (C) 2000 Andrea Arcangeli &lt;andrea@suse.de&gt; SuSE
  */
 
<span class="p_add">+#define DISABLE_BRANCH_PROFILING</span>
 #include &lt;linux/init.h&gt;
 #include &lt;linux/linkage.h&gt;
 #include &lt;linux/types.h&gt;
<span class="p_header">diff --git a/arch/x86/kernel/tsc.c b/arch/x86/kernel/tsc.c</span>
<span class="p_header">index 37e7cf544e51..62d55e34d373 100644</span>
<span class="p_header">--- a/arch/x86/kernel/tsc.c</span>
<span class="p_header">+++ b/arch/x86/kernel/tsc.c</span>
<span class="p_chunk">@@ -1310,6 +1310,8 @@</span> <span class="p_context"> static int __init init_tsc_clocksource(void)</span>
 	 * the refined calibration and directly register it as a clocksource.
 	 */
 	if (boot_cpu_has(X86_FEATURE_TSC_KNOWN_FREQ)) {
<span class="p_add">+		if (boot_cpu_has(X86_FEATURE_ART))</span>
<span class="p_add">+			art_related_clocksource = &amp;clocksource_tsc;</span>
 		clocksource_register_khz(&amp;clocksource_tsc, tsc_khz);
 		return 0;
 	}
<span class="p_header">diff --git a/arch/x86/kernel/unwind_frame.c b/arch/x86/kernel/unwind_frame.c</span>
<span class="p_header">index 23d15565d02a..919a7b78f945 100644</span>
<span class="p_header">--- a/arch/x86/kernel/unwind_frame.c</span>
<span class="p_header">+++ b/arch/x86/kernel/unwind_frame.c</span>
<span class="p_chunk">@@ -80,19 +80,43 @@</span> <span class="p_context"> static size_t regs_size(struct pt_regs *regs)</span>
 	return sizeof(*regs);
 }
 
<span class="p_add">+#ifdef CONFIG_X86_32</span>
<span class="p_add">+#define GCC_REALIGN_WORDS 3</span>
<span class="p_add">+#else</span>
<span class="p_add">+#define GCC_REALIGN_WORDS 1</span>
<span class="p_add">+#endif</span>
<span class="p_add">+</span>
 static bool is_last_task_frame(struct unwind_state *state)
 {
<span class="p_del">-	unsigned long bp = (unsigned long)state-&gt;bp;</span>
<span class="p_del">-	unsigned long regs = (unsigned long)task_pt_regs(state-&gt;task);</span>
<span class="p_add">+	unsigned long *last_bp = (unsigned long *)task_pt_regs(state-&gt;task) - 2;</span>
<span class="p_add">+	unsigned long *aligned_bp = last_bp - GCC_REALIGN_WORDS;</span>
 
 	/*
 	 * We have to check for the last task frame at two different locations
 	 * because gcc can occasionally decide to realign the stack pointer and
<span class="p_del">-	 * change the offset of the stack frame by a word in the prologue of a</span>
<span class="p_del">-	 * function called by head/entry code.</span>
<span class="p_add">+	 * change the offset of the stack frame in the prologue of a function</span>
<span class="p_add">+	 * called by head/entry code.  Examples:</span>
<span class="p_add">+	 *</span>
<span class="p_add">+	 * &lt;start_secondary&gt;:</span>
<span class="p_add">+	 *      push   %edi</span>
<span class="p_add">+	 *      lea    0x8(%esp),%edi</span>
<span class="p_add">+	 *      and    $0xfffffff8,%esp</span>
<span class="p_add">+	 *      pushl  -0x4(%edi)</span>
<span class="p_add">+	 *      push   %ebp</span>
<span class="p_add">+	 *      mov    %esp,%ebp</span>
<span class="p_add">+	 *</span>
<span class="p_add">+	 * &lt;x86_64_start_kernel&gt;:</span>
<span class="p_add">+	 *      lea    0x8(%rsp),%r10</span>
<span class="p_add">+	 *      and    $0xfffffffffffffff0,%rsp</span>
<span class="p_add">+	 *      pushq  -0x8(%r10)</span>
<span class="p_add">+	 *      push   %rbp</span>
<span class="p_add">+	 *      mov    %rsp,%rbp</span>
<span class="p_add">+	 *</span>
<span class="p_add">+	 * Note that after aligning the stack, it pushes a duplicate copy of</span>
<span class="p_add">+	 * the return address before pushing the frame pointer.</span>
 	 */
<span class="p_del">-	return bp == regs - FRAME_HEADER_SIZE ||</span>
<span class="p_del">-	       bp == regs - FRAME_HEADER_SIZE - sizeof(long);</span>
<span class="p_add">+	return (state-&gt;bp == last_bp ||</span>
<span class="p_add">+		(state-&gt;bp == aligned_bp &amp;&amp; *(aligned_bp+1) == *(last_bp+1)));</span>
 }
 
 /*
<span class="p_header">diff --git a/arch/x86/mm/kasan_init_64.c b/arch/x86/mm/kasan_init_64.c</span>
<span class="p_header">index 0493c17b8a51..333362f992e4 100644</span>
<span class="p_header">--- a/arch/x86/mm/kasan_init_64.c</span>
<span class="p_header">+++ b/arch/x86/mm/kasan_init_64.c</span>
<span class="p_chunk">@@ -1,3 +1,4 @@</span> <span class="p_context"></span>
<span class="p_add">+#define DISABLE_BRANCH_PROFILING</span>
 #define pr_fmt(fmt) &quot;kasan: &quot; fmt
 #include &lt;linux/bootmem.h&gt;
 #include &lt;linux/kasan.h&gt;
<span class="p_header">diff --git a/drivers/crypto/s5p-sss.c b/drivers/crypto/s5p-sss.c</span>
<span class="p_header">index dce1af0ce85c..4721d50c4628 100644</span>
<span class="p_header">--- a/drivers/crypto/s5p-sss.c</span>
<span class="p_header">+++ b/drivers/crypto/s5p-sss.c</span>
<span class="p_chunk">@@ -270,7 +270,7 @@</span> <span class="p_context"> static void s5p_sg_copy_buf(void *buf, struct scatterlist *sg,</span>
 	scatterwalk_done(&amp;walk, out, 0);
 }
 
<span class="p_del">-static void s5p_aes_complete(struct s5p_aes_dev *dev, int err)</span>
<span class="p_add">+static void s5p_sg_done(struct s5p_aes_dev *dev)</span>
 {
 	if (dev-&gt;sg_dst_cpy) {
 		dev_dbg(dev-&gt;dev,
<span class="p_chunk">@@ -281,8 +281,11 @@</span> <span class="p_context"> static void s5p_aes_complete(struct s5p_aes_dev *dev, int err)</span>
 	}
 	s5p_free_sg_cpy(dev, &amp;dev-&gt;sg_src_cpy);
 	s5p_free_sg_cpy(dev, &amp;dev-&gt;sg_dst_cpy);
<span class="p_add">+}</span>
 
<span class="p_del">-	/* holding a lock outside */</span>
<span class="p_add">+/* Calls the completion. Cannot be called with dev-&gt;lock hold. */</span>
<span class="p_add">+static void s5p_aes_complete(struct s5p_aes_dev *dev, int err)</span>
<span class="p_add">+{</span>
 	dev-&gt;req-&gt;base.complete(&amp;dev-&gt;req-&gt;base, err);
 	dev-&gt;busy = false;
 }
<span class="p_chunk">@@ -368,51 +371,44 @@</span> <span class="p_context"> static int s5p_set_indata(struct s5p_aes_dev *dev, struct scatterlist *sg)</span>
 }
 
 /*
<span class="p_del">- * Returns true if new transmitting (output) data is ready and its</span>
<span class="p_del">- * address+length have to be written to device (by calling</span>
<span class="p_del">- * s5p_set_dma_outdata()). False otherwise.</span>
<span class="p_add">+ * Returns -ERRNO on error (mapping of new data failed).</span>
<span class="p_add">+ * On success returns:</span>
<span class="p_add">+ *  - 0 if there is no more data,</span>
<span class="p_add">+ *  - 1 if new transmitting (output) data is ready and its address+length</span>
<span class="p_add">+ *     have to be written to device (by calling s5p_set_dma_outdata()).</span>
  */
<span class="p_del">-static bool s5p_aes_tx(struct s5p_aes_dev *dev)</span>
<span class="p_add">+static int s5p_aes_tx(struct s5p_aes_dev *dev)</span>
 {
<span class="p_del">-	int err = 0;</span>
<span class="p_del">-	bool ret = false;</span>
<span class="p_add">+	int ret = 0;</span>
 
 	s5p_unset_outdata(dev);
 
 	if (!sg_is_last(dev-&gt;sg_dst)) {
<span class="p_del">-		err = s5p_set_outdata(dev, sg_next(dev-&gt;sg_dst));</span>
<span class="p_del">-		if (err)</span>
<span class="p_del">-			s5p_aes_complete(dev, err);</span>
<span class="p_del">-		else</span>
<span class="p_del">-			ret = true;</span>
<span class="p_del">-	} else {</span>
<span class="p_del">-		s5p_aes_complete(dev, err);</span>
<span class="p_del">-</span>
<span class="p_del">-		dev-&gt;busy = true;</span>
<span class="p_del">-		tasklet_schedule(&amp;dev-&gt;tasklet);</span>
<span class="p_add">+		ret = s5p_set_outdata(dev, sg_next(dev-&gt;sg_dst));</span>
<span class="p_add">+		if (!ret)</span>
<span class="p_add">+			ret = 1;</span>
 	}
 
 	return ret;
 }
 
 /*
<span class="p_del">- * Returns true if new receiving (input) data is ready and its</span>
<span class="p_del">- * address+length have to be written to device (by calling</span>
<span class="p_del">- * s5p_set_dma_indata()). False otherwise.</span>
<span class="p_add">+ * Returns -ERRNO on error (mapping of new data failed).</span>
<span class="p_add">+ * On success returns:</span>
<span class="p_add">+ *  - 0 if there is no more data,</span>
<span class="p_add">+ *  - 1 if new receiving (input) data is ready and its address+length</span>
<span class="p_add">+ *     have to be written to device (by calling s5p_set_dma_indata()).</span>
  */
<span class="p_del">-static bool s5p_aes_rx(struct s5p_aes_dev *dev)</span>
<span class="p_add">+static int s5p_aes_rx(struct s5p_aes_dev *dev/*, bool *set_dma*/)</span>
 {
<span class="p_del">-	int err;</span>
<span class="p_del">-	bool ret = false;</span>
<span class="p_add">+	int ret = 0;</span>
 
 	s5p_unset_indata(dev);
 
 	if (!sg_is_last(dev-&gt;sg_src)) {
<span class="p_del">-		err = s5p_set_indata(dev, sg_next(dev-&gt;sg_src));</span>
<span class="p_del">-		if (err)</span>
<span class="p_del">-			s5p_aes_complete(dev, err);</span>
<span class="p_del">-		else</span>
<span class="p_del">-			ret = true;</span>
<span class="p_add">+		ret = s5p_set_indata(dev, sg_next(dev-&gt;sg_src));</span>
<span class="p_add">+		if (!ret)</span>
<span class="p_add">+			ret = 1;</span>
 	}
 
 	return ret;
<span class="p_chunk">@@ -422,33 +418,73 @@</span> <span class="p_context"> static irqreturn_t s5p_aes_interrupt(int irq, void *dev_id)</span>
 {
 	struct platform_device *pdev = dev_id;
 	struct s5p_aes_dev *dev = platform_get_drvdata(pdev);
<span class="p_del">-	bool set_dma_tx = false;</span>
<span class="p_del">-	bool set_dma_rx = false;</span>
<span class="p_add">+	int err_dma_tx = 0;</span>
<span class="p_add">+	int err_dma_rx = 0;</span>
<span class="p_add">+	bool tx_end = false;</span>
 	unsigned long flags;
 	uint32_t status;
<span class="p_add">+	int err;</span>
 
 	spin_lock_irqsave(&amp;dev-&gt;lock, flags);
 
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Handle rx or tx interrupt. If there is still data (scatterlist did not</span>
<span class="p_add">+	 * reach end), then map next scatterlist entry.</span>
<span class="p_add">+	 * In case of such mapping error, s5p_aes_complete() should be called.</span>
<span class="p_add">+	 *</span>
<span class="p_add">+	 * If there is no more data in tx scatter list, call s5p_aes_complete()</span>
<span class="p_add">+	 * and schedule new tasklet.</span>
<span class="p_add">+	 */</span>
 	status = SSS_READ(dev, FCINTSTAT);
 	if (status &amp; SSS_FCINTSTAT_BRDMAINT)
<span class="p_del">-		set_dma_rx = s5p_aes_rx(dev);</span>
<span class="p_del">-	if (status &amp; SSS_FCINTSTAT_BTDMAINT)</span>
<span class="p_del">-		set_dma_tx = s5p_aes_tx(dev);</span>
<span class="p_add">+		err_dma_rx = s5p_aes_rx(dev);</span>
<span class="p_add">+</span>
<span class="p_add">+	if (status &amp; SSS_FCINTSTAT_BTDMAINT) {</span>
<span class="p_add">+		if (sg_is_last(dev-&gt;sg_dst))</span>
<span class="p_add">+			tx_end = true;</span>
<span class="p_add">+		err_dma_tx = s5p_aes_tx(dev);</span>
<span class="p_add">+	}</span>
 
 	SSS_WRITE(dev, FCINTPEND, status);
 
<span class="p_del">-	/*</span>
<span class="p_del">-	 * Writing length of DMA block (either receiving or transmitting)</span>
<span class="p_del">-	 * will start the operation immediately, so this should be done</span>
<span class="p_del">-	 * at the end (even after clearing pending interrupts to not miss the</span>
<span class="p_del">-	 * interrupt).</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	if (set_dma_tx)</span>
<span class="p_del">-		s5p_set_dma_outdata(dev, dev-&gt;sg_dst);</span>
<span class="p_del">-	if (set_dma_rx)</span>
<span class="p_del">-		s5p_set_dma_indata(dev, dev-&gt;sg_src);</span>
<span class="p_add">+	if (err_dma_rx &lt; 0) {</span>
<span class="p_add">+		err = err_dma_rx;</span>
<span class="p_add">+		goto error;</span>
<span class="p_add">+	}</span>
<span class="p_add">+	if (err_dma_tx &lt; 0) {</span>
<span class="p_add">+		err = err_dma_tx;</span>
<span class="p_add">+		goto error;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	if (tx_end) {</span>
<span class="p_add">+		s5p_sg_done(dev);</span>
<span class="p_add">+</span>
<span class="p_add">+		spin_unlock_irqrestore(&amp;dev-&gt;lock, flags);</span>
<span class="p_add">+</span>
<span class="p_add">+		s5p_aes_complete(dev, 0);</span>
<span class="p_add">+		dev-&gt;busy = true;</span>
<span class="p_add">+		tasklet_schedule(&amp;dev-&gt;tasklet);</span>
<span class="p_add">+	} else {</span>
<span class="p_add">+		/*</span>
<span class="p_add">+		 * Writing length of DMA block (either receiving or</span>
<span class="p_add">+		 * transmitting) will start the operation immediately, so this</span>
<span class="p_add">+		 * should be done at the end (even after clearing pending</span>
<span class="p_add">+		 * interrupts to not miss the interrupt).</span>
<span class="p_add">+		 */</span>
<span class="p_add">+		if (err_dma_tx == 1)</span>
<span class="p_add">+			s5p_set_dma_outdata(dev, dev-&gt;sg_dst);</span>
<span class="p_add">+		if (err_dma_rx == 1)</span>
<span class="p_add">+			s5p_set_dma_indata(dev, dev-&gt;sg_src);</span>
 
<span class="p_add">+		spin_unlock_irqrestore(&amp;dev-&gt;lock, flags);</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	return IRQ_HANDLED;</span>
<span class="p_add">+</span>
<span class="p_add">+error:</span>
<span class="p_add">+	s5p_sg_done(dev);</span>
 	spin_unlock_irqrestore(&amp;dev-&gt;lock, flags);
<span class="p_add">+	s5p_aes_complete(dev, err);</span>
 
 	return IRQ_HANDLED;
 }
<span class="p_chunk">@@ -597,8 +633,9 @@</span> <span class="p_context"> static void s5p_aes_crypt_start(struct s5p_aes_dev *dev, unsigned long mode)</span>
 	s5p_unset_indata(dev);
 
 indata_error:
<span class="p_del">-	s5p_aes_complete(dev, err);</span>
<span class="p_add">+	s5p_sg_done(dev);</span>
 	spin_unlock_irqrestore(&amp;dev-&gt;lock, flags);
<span class="p_add">+	s5p_aes_complete(dev, err);</span>
 }
 
 static void s5p_tasklet_cb(unsigned long data)
<span class="p_header">diff --git a/drivers/gpu/drm/i915/i915_drv.c b/drivers/gpu/drm/i915/i915_drv.c</span>
<span class="p_header">index 728ca3ea74d2..f02da12f2860 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/i915/i915_drv.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/i915/i915_drv.c</span>
<span class="p_chunk">@@ -1573,18 +1573,21 @@</span> <span class="p_context"> static int i915_drm_resume(struct drm_device *dev)</span>
 	intel_opregion_setup(dev_priv);
 
 	intel_init_pch_refclk(dev);
<span class="p_del">-	drm_mode_config_reset(dev);</span>
 
 	/*
 	 * Interrupts have to be enabled before any batches are run. If not the
 	 * GPU will hang. i915_gem_init_hw() will initiate batches to
 	 * update/restore the context.
 	 *
<span class="p_add">+	 * drm_mode_config_reset() needs AUX interrupts.</span>
<span class="p_add">+	 *</span>
 	 * Modeset enabling in intel_modeset_init_hw() also needs working
 	 * interrupts.
 	 */
 	intel_runtime_pm_enable_interrupts(dev_priv);
 
<span class="p_add">+	drm_mode_config_reset(dev);</span>
<span class="p_add">+</span>
 	mutex_lock(&amp;dev-&gt;struct_mutex);
 	if (i915_gem_init_hw(dev)) {
 		DRM_ERROR(&quot;failed to re-initialize GPU, declaring wedged!\n&quot;);
<span class="p_header">diff --git a/drivers/gpu/drm/i915/i915_irq.c b/drivers/gpu/drm/i915/i915_irq.c</span>
<span class="p_header">index 07ca71cabb2b..f914581b1729 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/i915/i915_irq.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/i915/i915_irq.c</span>
<span class="p_chunk">@@ -3089,19 +3089,16 @@</span> <span class="p_context"> static void ibx_hpd_irq_setup(struct drm_i915_private *dev_priv)</span>
 	I915_WRITE(PCH_PORT_HOTPLUG, hotplug);
 }
 
<span class="p_del">-static void spt_hpd_irq_setup(struct drm_i915_private *dev_priv)</span>
<span class="p_add">+static void spt_hpd_detection_setup(struct drm_i915_private *dev_priv)</span>
 {
<span class="p_del">-	u32 hotplug_irqs, hotplug, enabled_irqs;</span>
<span class="p_del">-</span>
<span class="p_del">-	hotplug_irqs = SDE_HOTPLUG_MASK_SPT;</span>
<span class="p_del">-	enabled_irqs = intel_hpd_enabled_irqs(dev_priv, hpd_spt);</span>
<span class="p_del">-</span>
<span class="p_del">-	ibx_display_interrupt_update(dev_priv, hotplug_irqs, enabled_irqs);</span>
<span class="p_add">+	u32 hotplug;</span>
 
 	/* Enable digital hotplug on the PCH */
 	hotplug = I915_READ(PCH_PORT_HOTPLUG);
<span class="p_del">-	hotplug |= PORTD_HOTPLUG_ENABLE | PORTC_HOTPLUG_ENABLE |</span>
<span class="p_del">-		PORTB_HOTPLUG_ENABLE | PORTA_HOTPLUG_ENABLE;</span>
<span class="p_add">+	hotplug |= PORTA_HOTPLUG_ENABLE |</span>
<span class="p_add">+		   PORTB_HOTPLUG_ENABLE |</span>
<span class="p_add">+		   PORTC_HOTPLUG_ENABLE |</span>
<span class="p_add">+		   PORTD_HOTPLUG_ENABLE;</span>
 	I915_WRITE(PCH_PORT_HOTPLUG, hotplug);
 
 	hotplug = I915_READ(PCH_PORT_HOTPLUG2);
<span class="p_chunk">@@ -3109,6 +3106,18 @@</span> <span class="p_context"> static void spt_hpd_irq_setup(struct drm_i915_private *dev_priv)</span>
 	I915_WRITE(PCH_PORT_HOTPLUG2, hotplug);
 }
 
<span class="p_add">+static void spt_hpd_irq_setup(struct drm_i915_private *dev_priv)</span>
<span class="p_add">+{</span>
<span class="p_add">+	u32 hotplug_irqs, enabled_irqs;</span>
<span class="p_add">+</span>
<span class="p_add">+	hotplug_irqs = SDE_HOTPLUG_MASK_SPT;</span>
<span class="p_add">+	enabled_irqs = intel_hpd_enabled_irqs(dev_priv, hpd_spt);</span>
<span class="p_add">+</span>
<span class="p_add">+	ibx_display_interrupt_update(dev_priv, hotplug_irqs, enabled_irqs);</span>
<span class="p_add">+</span>
<span class="p_add">+	spt_hpd_detection_setup(dev_priv);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static void ilk_hpd_irq_setup(struct drm_i915_private *dev_priv)
 {
 	u32 hotplug_irqs, hotplug, enabled_irqs;
<span class="p_chunk">@@ -3143,18 +3152,15 @@</span> <span class="p_context"> static void ilk_hpd_irq_setup(struct drm_i915_private *dev_priv)</span>
 	ibx_hpd_irq_setup(dev_priv);
 }
 
<span class="p_del">-static void bxt_hpd_irq_setup(struct drm_i915_private *dev_priv)</span>
<span class="p_add">+static void __bxt_hpd_detection_setup(struct drm_i915_private *dev_priv,</span>
<span class="p_add">+				      u32 enabled_irqs)</span>
 {
<span class="p_del">-	u32 hotplug_irqs, hotplug, enabled_irqs;</span>
<span class="p_del">-</span>
<span class="p_del">-	enabled_irqs = intel_hpd_enabled_irqs(dev_priv, hpd_bxt);</span>
<span class="p_del">-	hotplug_irqs = BXT_DE_PORT_HOTPLUG_MASK;</span>
<span class="p_del">-</span>
<span class="p_del">-	bdw_update_port_irq(dev_priv, hotplug_irqs, enabled_irqs);</span>
<span class="p_add">+	u32 hotplug;</span>
 
 	hotplug = I915_READ(PCH_PORT_HOTPLUG);
<span class="p_del">-	hotplug |= PORTC_HOTPLUG_ENABLE | PORTB_HOTPLUG_ENABLE |</span>
<span class="p_del">-		PORTA_HOTPLUG_ENABLE;</span>
<span class="p_add">+	hotplug |= PORTA_HOTPLUG_ENABLE |</span>
<span class="p_add">+		   PORTB_HOTPLUG_ENABLE |</span>
<span class="p_add">+		   PORTC_HOTPLUG_ENABLE;</span>
 
 	DRM_DEBUG_KMS(&quot;Invert bit setting: hp_ctl:%x hp_port:%x\n&quot;,
 		      hotplug, enabled_irqs);
<span class="p_chunk">@@ -3164,7 +3170,6 @@</span> <span class="p_context"> static void bxt_hpd_irq_setup(struct drm_i915_private *dev_priv)</span>
 	 * For BXT invert bit has to be set based on AOB design
 	 * for HPD detection logic, update it based on VBT fields.
 	 */
<span class="p_del">-</span>
 	if ((enabled_irqs &amp; BXT_DE_PORT_HP_DDIA) &amp;&amp;
 	    intel_bios_is_port_hpd_inverted(dev_priv, PORT_A))
 		hotplug |= BXT_DDIA_HPD_INVERT;
<span class="p_chunk">@@ -3178,6 +3183,23 @@</span> <span class="p_context"> static void bxt_hpd_irq_setup(struct drm_i915_private *dev_priv)</span>
 	I915_WRITE(PCH_PORT_HOTPLUG, hotplug);
 }
 
<span class="p_add">+static void bxt_hpd_detection_setup(struct drm_i915_private *dev_priv)</span>
<span class="p_add">+{</span>
<span class="p_add">+	__bxt_hpd_detection_setup(dev_priv, BXT_DE_PORT_HOTPLUG_MASK);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static void bxt_hpd_irq_setup(struct drm_i915_private *dev_priv)</span>
<span class="p_add">+{</span>
<span class="p_add">+	u32 hotplug_irqs, enabled_irqs;</span>
<span class="p_add">+</span>
<span class="p_add">+	enabled_irqs = intel_hpd_enabled_irqs(dev_priv, hpd_bxt);</span>
<span class="p_add">+	hotplug_irqs = BXT_DE_PORT_HOTPLUG_MASK;</span>
<span class="p_add">+</span>
<span class="p_add">+	bdw_update_port_irq(dev_priv, hotplug_irqs, enabled_irqs);</span>
<span class="p_add">+</span>
<span class="p_add">+	__bxt_hpd_detection_setup(dev_priv, enabled_irqs);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static void ibx_irq_postinstall(struct drm_device *dev)
 {
 	struct drm_i915_private *dev_priv = to_i915(dev);
<span class="p_chunk">@@ -3193,6 +3215,12 @@</span> <span class="p_context"> static void ibx_irq_postinstall(struct drm_device *dev)</span>
 
 	gen5_assert_iir_is_zero(dev_priv, SDEIIR);
 	I915_WRITE(SDEIMR, ~mask);
<span class="p_add">+</span>
<span class="p_add">+	if (HAS_PCH_IBX(dev_priv) || HAS_PCH_CPT(dev_priv) ||</span>
<span class="p_add">+	    HAS_PCH_LPT(dev_priv))</span>
<span class="p_add">+		; /* TODO: Enable HPD detection on older PCH platforms too */</span>
<span class="p_add">+	else</span>
<span class="p_add">+		spt_hpd_detection_setup(dev_priv);</span>
 }
 
 static void gen5_gt_irq_postinstall(struct drm_device *dev)
<span class="p_chunk">@@ -3404,6 +3432,9 @@</span> <span class="p_context"> static void gen8_de_irq_postinstall(struct drm_i915_private *dev_priv)</span>
 
 	GEN5_IRQ_INIT(GEN8_DE_PORT_, ~de_port_masked, de_port_enables);
 	GEN5_IRQ_INIT(GEN8_DE_MISC_, ~de_misc_masked, de_misc_masked);
<span class="p_add">+</span>
<span class="p_add">+	if (IS_BROXTON(dev_priv))</span>
<span class="p_add">+		bxt_hpd_detection_setup(dev_priv);</span>
 }
 
 static int gen8_irq_postinstall(struct drm_device *dev)
<span class="p_header">diff --git a/drivers/gpu/drm/i915/intel_dp.c b/drivers/gpu/drm/i915/intel_dp.c</span>
<span class="p_header">index 4daf7dda9cca..c3ab0240691a 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/i915/intel_dp.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/i915/intel_dp.c</span>
<span class="p_chunk">@@ -4289,8 +4289,8 @@</span> <span class="p_context"> static bool bxt_digital_port_connected(struct drm_i915_private *dev_priv,</span>
  *
  * Return %true if @port is connected, %false otherwise.
  */
<span class="p_del">-static bool intel_digital_port_connected(struct drm_i915_private *dev_priv,</span>
<span class="p_del">-					 struct intel_digital_port *port)</span>
<span class="p_add">+bool intel_digital_port_connected(struct drm_i915_private *dev_priv,</span>
<span class="p_add">+				  struct intel_digital_port *port)</span>
 {
 	if (HAS_PCH_IBX(dev_priv))
 		return ibx_digital_port_connected(dev_priv, port);
<span class="p_header">diff --git a/drivers/gpu/drm/i915/intel_drv.h b/drivers/gpu/drm/i915/intel_drv.h</span>
<span class="p_header">index 03a2112004f9..a0af54bba85b 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/i915/intel_drv.h</span>
<span class="p_header">+++ b/drivers/gpu/drm/i915/intel_drv.h</span>
<span class="p_chunk">@@ -1451,6 +1451,8 @@</span> <span class="p_context"> bool intel_dp_read_dpcd(struct intel_dp *intel_dp);</span>
 bool __intel_dp_read_desc(struct intel_dp *intel_dp,
 			  struct intel_dp_desc *desc);
 bool intel_dp_read_desc(struct intel_dp *intel_dp);
<span class="p_add">+bool intel_digital_port_connected(struct drm_i915_private *dev_priv,</span>
<span class="p_add">+				  struct intel_digital_port *port);</span>
 
 /* intel_dp_aux_backlight.c */
 int intel_dp_aux_init_backlight_funcs(struct intel_connector *intel_connector);
<span class="p_header">diff --git a/drivers/gpu/drm/i915/intel_lspcon.c b/drivers/gpu/drm/i915/intel_lspcon.c</span>
<span class="p_header">index daa523410953..12695616f673 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/i915/intel_lspcon.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/i915/intel_lspcon.c</span>
<span class="p_chunk">@@ -100,6 +100,8 @@</span> <span class="p_context"> static bool lspcon_probe(struct intel_lspcon *lspcon)</span>
 static void lspcon_resume_in_pcon_wa(struct intel_lspcon *lspcon)
 {
 	struct intel_dp *intel_dp = lspcon_to_intel_dp(lspcon);
<span class="p_add">+	struct intel_digital_port *dig_port = dp_to_dig_port(intel_dp);</span>
<span class="p_add">+	struct drm_i915_private *dev_priv = to_i915(dig_port-&gt;base.base.dev);</span>
 	unsigned long start = jiffies;
 
 	if (!lspcon-&gt;desc_valid)
<span class="p_chunk">@@ -115,7 +117,8 @@</span> <span class="p_context"> static void lspcon_resume_in_pcon_wa(struct intel_lspcon *lspcon)</span>
 		if (!__intel_dp_read_desc(intel_dp, &amp;desc))
 			return;
 
<span class="p_del">-		if (!memcmp(&amp;intel_dp-&gt;desc, &amp;desc, sizeof(desc))) {</span>
<span class="p_add">+		if (intel_digital_port_connected(dev_priv, dig_port) &amp;&amp;</span>
<span class="p_add">+		    !memcmp(&amp;intel_dp-&gt;desc, &amp;desc, sizeof(desc))) {</span>
 			DRM_DEBUG_KMS(&quot;LSPCON recovering in PCON mode after %u ms\n&quot;,
 				      jiffies_to_msecs(jiffies - start));
 			return;
<span class="p_header">diff --git a/drivers/irqchip/irq-gic-v3-its.c b/drivers/irqchip/irq-gic-v3-its.c</span>
<span class="p_header">index 69b040f47d56..519ff7a18b5b 100644</span>
<span class="p_header">--- a/drivers/irqchip/irq-gic-v3-its.c</span>
<span class="p_header">+++ b/drivers/irqchip/irq-gic-v3-its.c</span>
<span class="p_chunk">@@ -1597,6 +1597,14 @@</span> <span class="p_context"> static void __maybe_unused its_enable_quirk_cavium_23144(void *data)</span>
 	its-&gt;flags |= ITS_FLAGS_WORKAROUND_CAVIUM_23144;
 }
 
<span class="p_add">+static void __maybe_unused its_enable_quirk_qdf2400_e0065(void *data)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct its_node *its = data;</span>
<span class="p_add">+</span>
<span class="p_add">+	/* On QDF2400, the size of the ITE is 16Bytes */</span>
<span class="p_add">+	its-&gt;ite_size = 16;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static const struct gic_quirk its_quirks[] = {
 #ifdef CONFIG_CAVIUM_ERRATUM_22375
 	{
<span class="p_chunk">@@ -1614,6 +1622,14 @@</span> <span class="p_context"> static const struct gic_quirk its_quirks[] = {</span>
 		.init	= its_enable_quirk_cavium_23144,
 	},
 #endif
<span class="p_add">+#ifdef CONFIG_QCOM_QDF2400_ERRATUM_0065</span>
<span class="p_add">+	{</span>
<span class="p_add">+		.desc	= &quot;ITS: QDF2400 erratum 0065&quot;,</span>
<span class="p_add">+		.iidr	= 0x00001070, /* QDF2400 ITS rev 1.x */</span>
<span class="p_add">+		.mask	= 0xffffffff,</span>
<span class="p_add">+		.init	= its_enable_quirk_qdf2400_e0065,</span>
<span class="p_add">+	},</span>
<span class="p_add">+#endif</span>
 	{
 	}
 };
<span class="p_header">diff --git a/drivers/net/bonding/bond_main.c b/drivers/net/bonding/bond_main.c</span>
<span class="p_header">index 8029dd4912b6..644d2bf0c451 100644</span>
<span class="p_header">--- a/drivers/net/bonding/bond_main.c</span>
<span class="p_header">+++ b/drivers/net/bonding/bond_main.c</span>
<span class="p_chunk">@@ -4185,6 +4185,7 @@</span> <span class="p_context"> void bond_setup(struct net_device *bond_dev)</span>
 
 	/* Initialize the device entry points */
 	ether_setup(bond_dev);
<span class="p_add">+	bond_dev-&gt;max_mtu = ETH_MAX_MTU;</span>
 	bond_dev-&gt;netdev_ops = &amp;bond_netdev_ops;
 	bond_dev-&gt;ethtool_ops = &amp;bond_ethtool_ops;
 
<span class="p_header">diff --git a/drivers/net/ethernet/amd/xgbe/xgbe-dev.c b/drivers/net/ethernet/amd/xgbe/xgbe-dev.c</span>
<span class="p_header">index a7d16db5c4b2..937f37a5dcb2 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/amd/xgbe/xgbe-dev.c</span>
<span class="p_header">+++ b/drivers/net/ethernet/amd/xgbe/xgbe-dev.c</span>
<span class="p_chunk">@@ -1323,7 +1323,7 @@</span> <span class="p_context"> static int xgbe_read_ext_mii_regs(struct xgbe_prv_data *pdata, int addr,</span>
 static int xgbe_set_ext_mii_mode(struct xgbe_prv_data *pdata, unsigned int port,
 				 enum xgbe_mdio_mode mode)
 {
<span class="p_del">-	unsigned int reg_val = 0;</span>
<span class="p_add">+	unsigned int reg_val = XGMAC_IOREAD(pdata, MAC_MDIOCL22R);</span>
 
 	switch (mode) {
 	case XGBE_MDIO_MODE_CL22:
<span class="p_header">diff --git a/drivers/net/ethernet/amd/xgbe/xgbe-drv.c b/drivers/net/ethernet/amd/xgbe/xgbe-drv.c</span>
<span class="p_header">index 1c87cc204075..742e5d1b5da4 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/amd/xgbe/xgbe-drv.c</span>
<span class="p_header">+++ b/drivers/net/ethernet/amd/xgbe/xgbe-drv.c</span>
<span class="p_chunk">@@ -1131,12 +1131,12 @@</span> <span class="p_context"> static void xgbe_stop(struct xgbe_prv_data *pdata)</span>
 	hw_if-&gt;disable_tx(pdata);
 	hw_if-&gt;disable_rx(pdata);
 
<span class="p_add">+	phy_if-&gt;phy_stop(pdata);</span>
<span class="p_add">+</span>
 	xgbe_free_irqs(pdata);
 
 	xgbe_napi_disable(pdata, 1);
 
<span class="p_del">-	phy_if-&gt;phy_stop(pdata);</span>
<span class="p_del">-</span>
 	hw_if-&gt;exit(pdata);
 
 	channel = pdata-&gt;channel;
<span class="p_chunk">@@ -2274,10 +2274,7 @@</span> <span class="p_context"> static int xgbe_one_poll(struct napi_struct *napi, int budget)</span>
 	processed = xgbe_rx_poll(channel, budget);
 
 	/* If we processed everything, we are done */
<span class="p_del">-	if (processed &lt; budget) {</span>
<span class="p_del">-		/* Turn off polling */</span>
<span class="p_del">-		napi_complete_done(napi, processed);</span>
<span class="p_del">-</span>
<span class="p_add">+	if ((processed &lt; budget) &amp;&amp; napi_complete_done(napi, processed)) {</span>
 		/* Enable Tx and Rx interrupts */
 		if (pdata-&gt;channel_irq_mode)
 			xgbe_enable_rx_tx_int(pdata, channel);
<span class="p_chunk">@@ -2319,10 +2316,7 @@</span> <span class="p_context"> static int xgbe_all_poll(struct napi_struct *napi, int budget)</span>
 	} while ((processed &lt; budget) &amp;&amp; (processed != last_processed));
 
 	/* If we processed everything, we are done */
<span class="p_del">-	if (processed &lt; budget) {</span>
<span class="p_del">-		/* Turn off polling */</span>
<span class="p_del">-		napi_complete_done(napi, processed);</span>
<span class="p_del">-</span>
<span class="p_add">+	if ((processed &lt; budget) &amp;&amp; napi_complete_done(napi, processed)) {</span>
 		/* Enable Tx and Rx interrupts */
 		xgbe_enable_rx_tx_ints(pdata);
 	}
<span class="p_header">diff --git a/drivers/net/ethernet/amd/xgbe/xgbe-phy-v2.c b/drivers/net/ethernet/amd/xgbe/xgbe-phy-v2.c</span>
<span class="p_header">index 9d8c953083b4..e707c49cc55a 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/amd/xgbe/xgbe-phy-v2.c</span>
<span class="p_header">+++ b/drivers/net/ethernet/amd/xgbe/xgbe-phy-v2.c</span>
<span class="p_chunk">@@ -716,6 +716,8 @@</span> <span class="p_context"> static void xgbe_phy_sfp_phy_settings(struct xgbe_prv_data *pdata)</span>
 		pdata-&gt;phy.duplex = DUPLEX_UNKNOWN;
 		pdata-&gt;phy.autoneg = AUTONEG_ENABLE;
 		pdata-&gt;phy.advertising = pdata-&gt;phy.supported;
<span class="p_add">+</span>
<span class="p_add">+		return;</span>
 	}
 
 	pdata-&gt;phy.advertising &amp;= ~ADVERTISED_Autoneg;
<span class="p_chunk">@@ -875,6 +877,16 @@</span> <span class="p_context"> static int xgbe_phy_find_phy_device(struct xgbe_prv_data *pdata)</span>
 	    !phy_data-&gt;sfp_phy_avail)
 		return 0;
 
<span class="p_add">+	/* Set the proper MDIO mode for the PHY */</span>
<span class="p_add">+	ret = pdata-&gt;hw_if.set_ext_mii_mode(pdata, phy_data-&gt;mdio_addr,</span>
<span class="p_add">+					    phy_data-&gt;phydev_mode);</span>
<span class="p_add">+	if (ret) {</span>
<span class="p_add">+		netdev_err(pdata-&gt;netdev,</span>
<span class="p_add">+			   &quot;mdio port/clause not compatible (%u/%u)\n&quot;,</span>
<span class="p_add">+			   phy_data-&gt;mdio_addr, phy_data-&gt;phydev_mode);</span>
<span class="p_add">+		return ret;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
 	/* Create and connect to the PHY device */
 	phydev = get_phy_device(phy_data-&gt;mii, phy_data-&gt;mdio_addr,
 				(phy_data-&gt;phydev_mode == XGBE_MDIO_MODE_CL45));
<span class="p_chunk">@@ -2722,6 +2734,18 @@</span> <span class="p_context"> static int xgbe_phy_start(struct xgbe_prv_data *pdata)</span>
 	if (ret)
 		return ret;
 
<span class="p_add">+	/* Set the proper MDIO mode for the re-driver */</span>
<span class="p_add">+	if (phy_data-&gt;redrv &amp;&amp; !phy_data-&gt;redrv_if) {</span>
<span class="p_add">+		ret = pdata-&gt;hw_if.set_ext_mii_mode(pdata, phy_data-&gt;redrv_addr,</span>
<span class="p_add">+						    XGBE_MDIO_MODE_CL22);</span>
<span class="p_add">+		if (ret) {</span>
<span class="p_add">+			netdev_err(pdata-&gt;netdev,</span>
<span class="p_add">+				   &quot;redriver mdio port not compatible (%u)\n&quot;,</span>
<span class="p_add">+				   phy_data-&gt;redrv_addr);</span>
<span class="p_add">+			return ret;</span>
<span class="p_add">+		}</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
 	/* Start in highest supported mode */
 	xgbe_phy_set_mode(pdata, phy_data-&gt;start_mode);
 
<span class="p_header">diff --git a/drivers/net/ethernet/mellanox/mlx5/core/en.h b/drivers/net/ethernet/mellanox/mlx5/core/en.h</span>
<span class="p_header">index d5ecb8f53fd4..c69a1f827b65 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/mellanox/mlx5/core/en.h</span>
<span class="p_header">+++ b/drivers/net/ethernet/mellanox/mlx5/core/en.h</span>
<span class="p_chunk">@@ -803,6 +803,7 @@</span> <span class="p_context"> int mlx5e_get_max_linkspeed(struct mlx5_core_dev *mdev, u32 *speed);</span>
 
 void mlx5e_set_rx_cq_mode_params(struct mlx5e_params *params,
 				 u8 cq_period_mode);
<span class="p_add">+void mlx5e_set_rq_type_params(struct mlx5e_priv *priv, u8 rq_type);</span>
 
 static inline void mlx5e_tx_notify_hw(struct mlx5e_sq *sq,
 				      struct mlx5_wqe_ctrl_seg *ctrl, int bf_sz)
<span class="p_header">diff --git a/drivers/net/ethernet/mellanox/mlx5/core/en_ethtool.c b/drivers/net/ethernet/mellanox/mlx5/core/en_ethtool.c</span>
<span class="p_header">index bb67863aa361..6906deae06e0 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/mellanox/mlx5/core/en_ethtool.c</span>
<span class="p_header">+++ b/drivers/net/ethernet/mellanox/mlx5/core/en_ethtool.c</span>
<span class="p_chunk">@@ -1477,6 +1477,7 @@</span> <span class="p_context"> static int set_pflag_rx_cqe_compress(struct net_device *netdev,</span>
 
 	MLX5E_SET_PFLAG(priv, MLX5E_PFLAG_RX_CQE_COMPRESS, enable);
 	priv-&gt;params.rx_cqe_compress_def = enable;
<span class="p_add">+	mlx5e_set_rq_type_params(priv, priv-&gt;params.rq_wq_type);</span>
 
 	if (reset)
 		err = mlx5e_open_locked(netdev);
<span class="p_header">diff --git a/drivers/net/ethernet/mellanox/mlx5/core/en_main.c b/drivers/net/ethernet/mellanox/mlx5/core/en_main.c</span>
<span class="p_header">index f14ca3385fdd..9d9c64927372 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/mellanox/mlx5/core/en_main.c</span>
<span class="p_header">+++ b/drivers/net/ethernet/mellanox/mlx5/core/en_main.c</span>
<span class="p_chunk">@@ -78,9 +78,10 @@</span> <span class="p_context"> static bool mlx5e_check_fragmented_striding_rq_cap(struct mlx5_core_dev *mdev)</span>
 		MLX5_CAP_ETH(mdev, reg_umr_sq);
 }
 
<span class="p_del">-static void mlx5e_set_rq_type_params(struct mlx5e_priv *priv, u8 rq_type)</span>
<span class="p_add">+void mlx5e_set_rq_type_params(struct mlx5e_priv *priv, u8 rq_type)</span>
 {
 	priv-&gt;params.rq_wq_type = rq_type;
<span class="p_add">+	priv-&gt;params.lro_wqe_sz = MLX5E_PARAMS_DEFAULT_LRO_WQE_SZ;</span>
 	switch (priv-&gt;params.rq_wq_type) {
 	case MLX5_WQ_TYPE_LINKED_LIST_STRIDING_RQ:
 		priv-&gt;params.log_rq_size = MLX5E_PARAMS_DEFAULT_LOG_RQ_SIZE_MPW;
<span class="p_chunk">@@ -93,6 +94,10 @@</span> <span class="p_context"> static void mlx5e_set_rq_type_params(struct mlx5e_priv *priv, u8 rq_type)</span>
 		break;
 	default: /* MLX5_WQ_TYPE_LINKED_LIST */
 		priv-&gt;params.log_rq_size = MLX5E_PARAMS_DEFAULT_LOG_RQ_SIZE;
<span class="p_add">+</span>
<span class="p_add">+		/* Extra room needed for build_skb */</span>
<span class="p_add">+		priv-&gt;params.lro_wqe_sz -= MLX5_RX_HEADROOM +</span>
<span class="p_add">+			SKB_DATA_ALIGN(sizeof(struct skb_shared_info));</span>
 	}
 	priv-&gt;params.min_rx_wqes = mlx5_min_rx_wqes(priv-&gt;params.rq_wq_type,
 					       BIT(priv-&gt;params.log_rq_size));
<span class="p_chunk">@@ -3495,6 +3500,9 @@</span> <span class="p_context"> static void mlx5e_build_nic_netdev_priv(struct mlx5_core_dev *mdev,</span>
 			cqe_compress_heuristic(link_speed, pci_bw);
 	}
 
<span class="p_add">+	MLX5E_SET_PFLAG(priv, MLX5E_PFLAG_RX_CQE_COMPRESS,</span>
<span class="p_add">+			priv-&gt;params.rx_cqe_compress_def);</span>
<span class="p_add">+</span>
 	mlx5e_set_rq_priv_params(priv);
 	if (priv-&gt;params.rq_wq_type == MLX5_WQ_TYPE_LINKED_LIST_STRIDING_RQ)
 		priv-&gt;params.lro_en = true;
<span class="p_chunk">@@ -3517,16 +3525,9 @@</span> <span class="p_context"> static void mlx5e_build_nic_netdev_priv(struct mlx5_core_dev *mdev,</span>
 	mlx5e_build_default_indir_rqt(mdev, priv-&gt;params.indirection_rqt,
 				      MLX5E_INDIR_RQT_SIZE, profile-&gt;max_nch(mdev));
 
<span class="p_del">-	priv-&gt;params.lro_wqe_sz =</span>
<span class="p_del">-		MLX5E_PARAMS_DEFAULT_LRO_WQE_SZ -</span>
<span class="p_del">-		/* Extra room needed for build_skb */</span>
<span class="p_del">-		MLX5_RX_HEADROOM -</span>
<span class="p_del">-		SKB_DATA_ALIGN(sizeof(struct skb_shared_info));</span>
<span class="p_del">-</span>
 	/* Initialize pflags */
 	MLX5E_SET_PFLAG(priv, MLX5E_PFLAG_RX_CQE_BASED_MODER,
 			priv-&gt;params.rx_cq_period_mode == MLX5_CQ_PERIOD_MODE_START_FROM_CQE);
<span class="p_del">-	MLX5E_SET_PFLAG(priv, MLX5E_PFLAG_RX_CQE_COMPRESS, priv-&gt;params.rx_cqe_compress_def);</span>
 
 	mutex_init(&amp;priv-&gt;state_lock);
 
<span class="p_chunk">@@ -3940,6 +3941,19 @@</span> <span class="p_context"> static void mlx5e_register_vport_rep(struct mlx5_core_dev *mdev)</span>
 	}
 }
 
<span class="p_add">+static void mlx5e_unregister_vport_rep(struct mlx5_core_dev *mdev)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct mlx5_eswitch *esw = mdev-&gt;priv.eswitch;</span>
<span class="p_add">+	int total_vfs = MLX5_TOTAL_VPORTS(mdev);</span>
<span class="p_add">+	int vport;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (!MLX5_CAP_GEN(mdev, vport_group_manager))</span>
<span class="p_add">+		return;</span>
<span class="p_add">+</span>
<span class="p_add">+	for (vport = 1; vport &lt; total_vfs; vport++)</span>
<span class="p_add">+		mlx5_eswitch_unregister_vport_rep(esw, vport);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 void mlx5e_detach_netdev(struct mlx5_core_dev *mdev, struct net_device *netdev)
 {
 	struct mlx5e_priv *priv = netdev_priv(netdev);
<span class="p_chunk">@@ -3986,6 +4000,7 @@</span> <span class="p_context"> static int mlx5e_attach(struct mlx5_core_dev *mdev, void *vpriv)</span>
 		return err;
 	}
 
<span class="p_add">+	mlx5e_register_vport_rep(mdev);</span>
 	return 0;
 }
 
<span class="p_chunk">@@ -3997,6 +4012,7 @@</span> <span class="p_context"> static void mlx5e_detach(struct mlx5_core_dev *mdev, void *vpriv)</span>
 	if (!netif_device_present(netdev))
 		return;
 
<span class="p_add">+	mlx5e_unregister_vport_rep(mdev);</span>
 	mlx5e_detach_netdev(mdev, netdev);
 	mlx5e_destroy_mdev_resources(mdev);
 }
<span class="p_chunk">@@ -4015,8 +4031,6 @@</span> <span class="p_context"> static void *mlx5e_add(struct mlx5_core_dev *mdev)</span>
 	if (err)
 		return NULL;
 
<span class="p_del">-	mlx5e_register_vport_rep(mdev);</span>
<span class="p_del">-</span>
 	if (MLX5_CAP_GEN(mdev, vport_group_manager))
 		ppriv = &amp;esw-&gt;offloads.vport_reps[0];
 
<span class="p_chunk">@@ -4068,13 +4082,7 @@</span> <span class="p_context"> void mlx5e_destroy_netdev(struct mlx5_core_dev *mdev, struct mlx5e_priv *priv)</span>
 
 static void mlx5e_remove(struct mlx5_core_dev *mdev, void *vpriv)
 {
<span class="p_del">-	struct mlx5_eswitch *esw = mdev-&gt;priv.eswitch;</span>
<span class="p_del">-	int total_vfs = MLX5_TOTAL_VPORTS(mdev);</span>
 	struct mlx5e_priv *priv = vpriv;
<span class="p_del">-	int vport;</span>
<span class="p_del">-</span>
<span class="p_del">-	for (vport = 1; vport &lt; total_vfs; vport++)</span>
<span class="p_del">-		mlx5_eswitch_unregister_vport_rep(esw, vport);</span>
 
 	unregister_netdev(priv-&gt;netdev);
 	mlx5e_detach(mdev, vpriv);
<span class="p_header">diff --git a/drivers/net/ethernet/mellanox/mlx5/core/en_rx.c b/drivers/net/ethernet/mellanox/mlx5/core/en_rx.c</span>
<span class="p_header">index 06d5e6fecb0a..e3b88bbb9dcf 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/mellanox/mlx5/core/en_rx.c</span>
<span class="p_header">+++ b/drivers/net/ethernet/mellanox/mlx5/core/en_rx.c</span>
<span class="p_chunk">@@ -92,19 +92,18 @@</span> <span class="p_context"> static inline void mlx5e_cqes_update_owner(struct mlx5e_cq *cq, u32 cqcc, int n)</span>
 static inline void mlx5e_decompress_cqe(struct mlx5e_rq *rq,
 					struct mlx5e_cq *cq, u32 cqcc)
 {
<span class="p_del">-	u16 wqe_cnt_step;</span>
<span class="p_del">-</span>
 	cq-&gt;title.byte_cnt     = cq-&gt;mini_arr[cq-&gt;mini_arr_idx].byte_cnt;
 	cq-&gt;title.check_sum    = cq-&gt;mini_arr[cq-&gt;mini_arr_idx].checksum;
 	cq-&gt;title.op_own      &amp;= 0xf0;
 	cq-&gt;title.op_own      |= 0x01 &amp; (cqcc &gt;&gt; cq-&gt;wq.log_sz);
 	cq-&gt;title.wqe_counter  = cpu_to_be16(cq-&gt;decmprs_wqe_counter);
 
<span class="p_del">-	wqe_cnt_step =</span>
<span class="p_del">-		rq-&gt;wq_type == MLX5_WQ_TYPE_LINKED_LIST_STRIDING_RQ ?</span>
<span class="p_del">-		mpwrq_get_cqe_consumed_strides(&amp;cq-&gt;title) : 1;</span>
<span class="p_del">-	cq-&gt;decmprs_wqe_counter =</span>
<span class="p_del">-		(cq-&gt;decmprs_wqe_counter + wqe_cnt_step) &amp; rq-&gt;wq.sz_m1;</span>
<span class="p_add">+	if (rq-&gt;wq_type == MLX5_WQ_TYPE_LINKED_LIST_STRIDING_RQ)</span>
<span class="p_add">+		cq-&gt;decmprs_wqe_counter +=</span>
<span class="p_add">+			mpwrq_get_cqe_consumed_strides(&amp;cq-&gt;title);</span>
<span class="p_add">+	else</span>
<span class="p_add">+		cq-&gt;decmprs_wqe_counter =</span>
<span class="p_add">+			(cq-&gt;decmprs_wqe_counter + 1) &amp; rq-&gt;wq.sz_m1;</span>
 }
 
 static inline void mlx5e_decompress_cqe_no_hash(struct mlx5e_rq *rq,
<span class="p_chunk">@@ -172,6 +171,7 @@</span> <span class="p_context"> void mlx5e_modify_rx_cqe_compression(struct mlx5e_priv *priv, bool val)</span>
 		mlx5e_close_locked(priv-&gt;netdev);
 
 	MLX5E_SET_PFLAG(priv, MLX5E_PFLAG_RX_CQE_COMPRESS, val);
<span class="p_add">+	mlx5e_set_rq_type_params(priv, priv-&gt;params.rq_wq_type);</span>
 
 	if (was_opened)
 		mlx5e_open_locked(priv-&gt;netdev);
<span class="p_header">diff --git a/drivers/net/ethernet/mellanox/mlxsw/spectrum_router.c b/drivers/net/ethernet/mellanox/mlxsw/spectrum_router.c</span>
<span class="p_header">index 9e494a446b7e..f17f906f1d3a 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/mellanox/mlxsw/spectrum_router.c</span>
<span class="p_header">+++ b/drivers/net/ethernet/mellanox/mlxsw/spectrum_router.c</span>
<span class="p_chunk">@@ -496,30 +496,40 @@</span> <span class="p_context"> static int</span>
 mlxsw_sp_vr_lpm_tree_check(struct mlxsw_sp *mlxsw_sp, struct mlxsw_sp_vr *vr,
 			   struct mlxsw_sp_prefix_usage *req_prefix_usage)
 {
<span class="p_del">-	struct mlxsw_sp_lpm_tree *lpm_tree;</span>
<span class="p_add">+	struct mlxsw_sp_lpm_tree *lpm_tree = vr-&gt;lpm_tree;</span>
<span class="p_add">+	struct mlxsw_sp_lpm_tree *new_tree;</span>
<span class="p_add">+	int err;</span>
 
<span class="p_del">-	if (mlxsw_sp_prefix_usage_eq(req_prefix_usage,</span>
<span class="p_del">-				     &amp;vr-&gt;lpm_tree-&gt;prefix_usage))</span>
<span class="p_add">+	if (mlxsw_sp_prefix_usage_eq(req_prefix_usage, &amp;lpm_tree-&gt;prefix_usage))</span>
 		return 0;
 
<span class="p_del">-	lpm_tree = mlxsw_sp_lpm_tree_get(mlxsw_sp, req_prefix_usage,</span>
<span class="p_add">+	new_tree = mlxsw_sp_lpm_tree_get(mlxsw_sp, req_prefix_usage,</span>
 					 vr-&gt;proto, false);
<span class="p_del">-	if (IS_ERR(lpm_tree)) {</span>
<span class="p_add">+	if (IS_ERR(new_tree)) {</span>
 		/* We failed to get a tree according to the required
 		 * prefix usage. However, the current tree might be still good
 		 * for us if our requirement is subset of the prefixes used
 		 * in the tree.
 		 */
 		if (mlxsw_sp_prefix_usage_subset(req_prefix_usage,
<span class="p_del">-						 &amp;vr-&gt;lpm_tree-&gt;prefix_usage))</span>
<span class="p_add">+						 &amp;lpm_tree-&gt;prefix_usage))</span>
 			return 0;
<span class="p_del">-		return PTR_ERR(lpm_tree);</span>
<span class="p_add">+		return PTR_ERR(new_tree);</span>
 	}
 
<span class="p_del">-	mlxsw_sp_vr_lpm_tree_unbind(mlxsw_sp, vr);</span>
<span class="p_del">-	mlxsw_sp_lpm_tree_put(mlxsw_sp, vr-&gt;lpm_tree);</span>
<span class="p_add">+	/* Prevent packet loss by overwriting existing binding */</span>
<span class="p_add">+	vr-&gt;lpm_tree = new_tree;</span>
<span class="p_add">+	err = mlxsw_sp_vr_lpm_tree_bind(mlxsw_sp, vr);</span>
<span class="p_add">+	if (err)</span>
<span class="p_add">+		goto err_tree_bind;</span>
<span class="p_add">+	mlxsw_sp_lpm_tree_put(mlxsw_sp, lpm_tree);</span>
<span class="p_add">+</span>
<span class="p_add">+	return 0;</span>
<span class="p_add">+</span>
<span class="p_add">+err_tree_bind:</span>
 	vr-&gt;lpm_tree = lpm_tree;
<span class="p_del">-	return mlxsw_sp_vr_lpm_tree_bind(mlxsw_sp, vr);</span>
<span class="p_add">+	mlxsw_sp_lpm_tree_put(mlxsw_sp, new_tree);</span>
<span class="p_add">+	return err;</span>
 }
 
 static struct mlxsw_sp_vr *mlxsw_sp_vr_get(struct mlxsw_sp *mlxsw_sp,
<span class="p_header">diff --git a/drivers/net/geneve.c b/drivers/net/geneve.c</span>
<span class="p_header">index 45301cb98bc1..7074b40ebd7f 100644</span>
<span class="p_header">--- a/drivers/net/geneve.c</span>
<span class="p_header">+++ b/drivers/net/geneve.c</span>
<span class="p_chunk">@@ -881,12 +881,14 @@</span> <span class="p_context"> static netdev_tx_t geneve_xmit(struct sk_buff *skb, struct net_device *dev)</span>
 		info = &amp;geneve-&gt;info;
 	}
 
<span class="p_add">+	rcu_read_lock();</span>
 #if IS_ENABLED(CONFIG_IPV6)
 	if (info-&gt;mode &amp; IP_TUNNEL_INFO_IPV6)
 		err = geneve6_xmit_skb(skb, dev, geneve, info);
 	else
 #endif
 		err = geneve_xmit_skb(skb, dev, geneve, info);
<span class="p_add">+	rcu_read_unlock();</span>
 
 	if (likely(!err))
 		return NETDEV_TX_OK;
<span class="p_header">diff --git a/drivers/net/team/team.c b/drivers/net/team/team.c</span>
<span class="p_header">index bdc58567d10e..707321508c69 100644</span>
<span class="p_header">--- a/drivers/net/team/team.c</span>
<span class="p_header">+++ b/drivers/net/team/team.c</span>
<span class="p_chunk">@@ -2075,6 +2075,7 @@</span> <span class="p_context"> static int team_dev_type_check_change(struct net_device *dev,</span>
 static void team_setup(struct net_device *dev)
 {
 	ether_setup(dev);
<span class="p_add">+	dev-&gt;max_mtu = ETH_MAX_MTU;</span>
 
 	dev-&gt;netdev_ops = &amp;team_netdev_ops;
 	dev-&gt;ethtool_ops = &amp;team_ethtool_ops;
<span class="p_header">diff --git a/drivers/net/tun.c b/drivers/net/tun.c</span>
<span class="p_header">index bfabe180053e..cdf6339827e6 100644</span>
<span class="p_header">--- a/drivers/net/tun.c</span>
<span class="p_header">+++ b/drivers/net/tun.c</span>
<span class="p_chunk">@@ -819,7 +819,18 @@</span> <span class="p_context"> static void tun_net_uninit(struct net_device *dev)</span>
 /* Net device open. */
 static int tun_net_open(struct net_device *dev)
 {
<span class="p_add">+	struct tun_struct *tun = netdev_priv(dev);</span>
<span class="p_add">+	int i;</span>
<span class="p_add">+</span>
 	netif_tx_start_all_queues(dev);
<span class="p_add">+</span>
<span class="p_add">+	for (i = 0; i &lt; tun-&gt;numqueues; i++) {</span>
<span class="p_add">+		struct tun_file *tfile;</span>
<span class="p_add">+</span>
<span class="p_add">+		tfile = rtnl_dereference(tun-&gt;tfiles[i]);</span>
<span class="p_add">+		tfile-&gt;socket.sk-&gt;sk_write_space(tfile-&gt;socket.sk);</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
 	return 0;
 }
 
<span class="p_chunk">@@ -1101,9 +1112,10 @@</span> <span class="p_context"> static unsigned int tun_chr_poll(struct file *file, poll_table *wait)</span>
 	if (!skb_array_empty(&amp;tfile-&gt;tx_array))
 		mask |= POLLIN | POLLRDNORM;
 
<span class="p_del">-	if (sock_writeable(sk) ||</span>
<span class="p_del">-	    (!test_and_set_bit(SOCKWQ_ASYNC_NOSPACE, &amp;sk-&gt;sk_socket-&gt;flags) &amp;&amp;</span>
<span class="p_del">-	     sock_writeable(sk)))</span>
<span class="p_add">+	if (tun-&gt;dev-&gt;flags &amp; IFF_UP &amp;&amp;</span>
<span class="p_add">+	    (sock_writeable(sk) ||</span>
<span class="p_add">+	     (!test_and_set_bit(SOCKWQ_ASYNC_NOSPACE, &amp;sk-&gt;sk_socket-&gt;flags) &amp;&amp;</span>
<span class="p_add">+	      sock_writeable(sk))))</span>
 		mask |= POLLOUT | POLLWRNORM;
 
 	if (tun-&gt;dev-&gt;reg_state != NETREG_REGISTERED)
<span class="p_header">diff --git a/drivers/net/vrf.c b/drivers/net/vrf.c</span>
<span class="p_header">index 454f907d419a..682aac0a2267 100644</span>
<span class="p_header">--- a/drivers/net/vrf.c</span>
<span class="p_header">+++ b/drivers/net/vrf.c</span>
<span class="p_chunk">@@ -341,6 +341,7 @@</span> <span class="p_context"> static netdev_tx_t is_ip_tx_frame(struct sk_buff *skb, struct net_device *dev)</span>
 
 static netdev_tx_t vrf_xmit(struct sk_buff *skb, struct net_device *dev)
 {
<span class="p_add">+	int len = skb-&gt;len;</span>
 	netdev_tx_t ret = is_ip_tx_frame(skb, dev);
 
 	if (likely(ret == NET_XMIT_SUCCESS || ret == NET_XMIT_CN)) {
<span class="p_chunk">@@ -348,7 +349,7 @@</span> <span class="p_context"> static netdev_tx_t vrf_xmit(struct sk_buff *skb, struct net_device *dev)</span>
 
 		u64_stats_update_begin(&amp;dstats-&gt;syncp);
 		dstats-&gt;tx_pkts++;
<span class="p_del">-		dstats-&gt;tx_bytes += skb-&gt;len;</span>
<span class="p_add">+		dstats-&gt;tx_bytes += len;</span>
 		u64_stats_update_end(&amp;dstats-&gt;syncp);
 	} else {
 		this_cpu_inc(dev-&gt;dstats-&gt;tx_drps);
<span class="p_header">diff --git a/drivers/net/vxlan.c b/drivers/net/vxlan.c</span>
<span class="p_header">index 30b04cf2bb1e..0e204f1a5072 100644</span>
<span class="p_header">--- a/drivers/net/vxlan.c</span>
<span class="p_header">+++ b/drivers/net/vxlan.c</span>
<span class="p_chunk">@@ -1992,7 +1992,6 @@</span> <span class="p_context"> static void vxlan_xmit_one(struct sk_buff *skb, struct net_device *dev,</span>
 	const struct iphdr *old_iph = ip_hdr(skb);
 	union vxlan_addr *dst;
 	union vxlan_addr remote_ip, local_ip;
<span class="p_del">-	union vxlan_addr *src;</span>
 	struct vxlan_metadata _md;
 	struct vxlan_metadata *md = &amp;_md;
 	__be16 src_port = 0, dst_port;
<span class="p_chunk">@@ -2019,7 +2018,7 @@</span> <span class="p_context"> static void vxlan_xmit_one(struct sk_buff *skb, struct net_device *dev,</span>
 
 		dst_port = rdst-&gt;remote_port ? rdst-&gt;remote_port : vxlan-&gt;cfg.dst_port;
 		vni = rdst-&gt;remote_vni;
<span class="p_del">-		src = &amp;vxlan-&gt;cfg.saddr;</span>
<span class="p_add">+		local_ip = vxlan-&gt;cfg.saddr;</span>
 		dst_cache = &amp;rdst-&gt;dst_cache;
 		md-&gt;gbp = skb-&gt;mark;
 		ttl = vxlan-&gt;cfg.ttl;
<span class="p_chunk">@@ -2052,7 +2051,6 @@</span> <span class="p_context"> static void vxlan_xmit_one(struct sk_buff *skb, struct net_device *dev,</span>
 		dst = &amp;remote_ip;
 		dst_port = info-&gt;key.tp_dst ? : vxlan-&gt;cfg.dst_port;
 		vni = tunnel_id_to_key32(info-&gt;key.tun_id);
<span class="p_del">-		src = &amp;local_ip;</span>
 		dst_cache = &amp;info-&gt;dst_cache;
 		if (info-&gt;options_len)
 			md = ip_tunnel_info_opts(info);
<span class="p_chunk">@@ -2064,6 +2062,7 @@</span> <span class="p_context"> static void vxlan_xmit_one(struct sk_buff *skb, struct net_device *dev,</span>
 	src_port = udp_flow_src_port(dev_net(dev), skb, vxlan-&gt;cfg.port_min,
 				     vxlan-&gt;cfg.port_max, true);
 
<span class="p_add">+	rcu_read_lock();</span>
 	if (dst-&gt;sa.sa_family == AF_INET) {
 		struct vxlan_sock *sock4 = rcu_dereference(vxlan-&gt;vn4_sock);
 		struct rtable *rt;
<span class="p_chunk">@@ -2072,7 +2071,7 @@</span> <span class="p_context"> static void vxlan_xmit_one(struct sk_buff *skb, struct net_device *dev,</span>
 		rt = vxlan_get_route(vxlan, dev, sock4, skb,
 				     rdst ? rdst-&gt;remote_ifindex : 0, tos,
 				     dst-&gt;sin.sin_addr.s_addr,
<span class="p_del">-				     &amp;src-&gt;sin.sin_addr.s_addr,</span>
<span class="p_add">+				     &amp;local_ip.sin.sin_addr.s_addr,</span>
 				     dst_port, src_port,
 				     dst_cache, info);
 		if (IS_ERR(rt)) {
<span class="p_chunk">@@ -2086,7 +2085,7 @@</span> <span class="p_context"> static void vxlan_xmit_one(struct sk_buff *skb, struct net_device *dev,</span>
 						    dst_port, vni, &amp;rt-&gt;dst,
 						    rt-&gt;rt_flags);
 			if (err)
<span class="p_del">-				return;</span>
<span class="p_add">+				goto out_unlock;</span>
 		} else if (info-&gt;key.tun_flags &amp; TUNNEL_DONT_FRAGMENT) {
 			df = htons(IP_DF);
 		}
<span class="p_chunk">@@ -2099,7 +2098,7 @@</span> <span class="p_context"> static void vxlan_xmit_one(struct sk_buff *skb, struct net_device *dev,</span>
 		if (err &lt; 0)
 			goto tx_error;
 
<span class="p_del">-		udp_tunnel_xmit_skb(rt, sock4-&gt;sock-&gt;sk, skb, src-&gt;sin.sin_addr.s_addr,</span>
<span class="p_add">+		udp_tunnel_xmit_skb(rt, sock4-&gt;sock-&gt;sk, skb, local_ip.sin.sin_addr.s_addr,</span>
 				    dst-&gt;sin.sin_addr.s_addr, tos, ttl, df,
 				    src_port, dst_port, xnet, !udp_sum);
 #if IS_ENABLED(CONFIG_IPV6)
<span class="p_chunk">@@ -2109,7 +2108,7 @@</span> <span class="p_context"> static void vxlan_xmit_one(struct sk_buff *skb, struct net_device *dev,</span>
 		ndst = vxlan6_get_route(vxlan, dev, sock6, skb,
 					rdst ? rdst-&gt;remote_ifindex : 0, tos,
 					label, &amp;dst-&gt;sin6.sin6_addr,
<span class="p_del">-					&amp;src-&gt;sin6.sin6_addr,</span>
<span class="p_add">+					&amp;local_ip.sin6.sin6_addr,</span>
 					dst_port, src_port,
 					dst_cache, info);
 		if (IS_ERR(ndst)) {
<span class="p_chunk">@@ -2125,7 +2124,7 @@</span> <span class="p_context"> static void vxlan_xmit_one(struct sk_buff *skb, struct net_device *dev,</span>
 						    dst_port, vni, ndst,
 						    rt6i_flags);
 			if (err)
<span class="p_del">-				return;</span>
<span class="p_add">+				goto out_unlock;</span>
 		}
 
 		tos = ip_tunnel_ecn_encap(tos, old_iph, skb);
<span class="p_chunk">@@ -2137,11 +2136,13 @@</span> <span class="p_context"> static void vxlan_xmit_one(struct sk_buff *skb, struct net_device *dev,</span>
 			goto tx_error;
 
 		udp_tunnel6_xmit_skb(ndst, sock6-&gt;sock-&gt;sk, skb, dev,
<span class="p_del">-				     &amp;src-&gt;sin6.sin6_addr,</span>
<span class="p_add">+				     &amp;local_ip.sin6.sin6_addr,</span>
 				     &amp;dst-&gt;sin6.sin6_addr, tos, ttl,
 				     label, src_port, dst_port, !udp_sum);
 #endif
 	}
<span class="p_add">+out_unlock:</span>
<span class="p_add">+	rcu_read_unlock();</span>
 	return;
 
 drop:
<span class="p_chunk">@@ -2150,6 +2151,7 @@</span> <span class="p_context"> static void vxlan_xmit_one(struct sk_buff *skb, struct net_device *dev,</span>
 	return;
 
 tx_error:
<span class="p_add">+	rcu_read_unlock();</span>
 	if (err == -ELOOP)
 		dev-&gt;stats.collisions++;
 	else if (err == -ENETUNREACH)
<span class="p_chunk">@@ -2626,7 +2628,7 @@</span> <span class="p_context"> static int vxlan_validate(struct nlattr *tb[], struct nlattr *data[])</span>
 
 	if (data[IFLA_VXLAN_ID]) {
 		__u32 id = nla_get_u32(data[IFLA_VXLAN_ID]);
<span class="p_del">-		if (id &gt;= VXLAN_VID_MASK)</span>
<span class="p_add">+		if (id &gt;= VXLAN_N_VID)</span>
 			return -ERANGE;
 	}
 
<span class="p_header">diff --git a/include/linux/dccp.h b/include/linux/dccp.h</span>
<span class="p_header">index 61d042bbbf60..68449293c4b6 100644</span>
<span class="p_header">--- a/include/linux/dccp.h</span>
<span class="p_header">+++ b/include/linux/dccp.h</span>
<span class="p_chunk">@@ -163,6 +163,7 @@</span> <span class="p_context"> struct dccp_request_sock {</span>
 	__u64			 dreq_isr;
 	__u64			 dreq_gsr;
 	__be32			 dreq_service;
<span class="p_add">+	spinlock_t		 dreq_lock;</span>
 	struct list_head	 dreq_featneg;
 	__u32			 dreq_timestamp_echo;
 	__u32			 dreq_timestamp_time;
<span class="p_header">diff --git a/include/uapi/linux/packet_diag.h b/include/uapi/linux/packet_diag.h</span>
<span class="p_header">index d08c63f3dd6f..0c5d5dd61b6a 100644</span>
<span class="p_header">--- a/include/uapi/linux/packet_diag.h</span>
<span class="p_header">+++ b/include/uapi/linux/packet_diag.h</span>
<span class="p_chunk">@@ -64,7 +64,7 @@</span> <span class="p_context"> struct packet_diag_mclist {</span>
 	__u32	pdmc_count;
 	__u16	pdmc_type;
 	__u16	pdmc_alen;
<span class="p_del">-	__u8	pdmc_addr[MAX_ADDR_LEN];</span>
<span class="p_add">+	__u8	pdmc_addr[32]; /* MAX_ADDR_LEN */</span>
 };
 
 struct packet_diag_ring {
<span class="p_header">diff --git a/kernel/futex.c b/kernel/futex.c</span>
<span class="p_header">index cdf365036141..dda00f03337d 100644</span>
<span class="p_header">--- a/kernel/futex.c</span>
<span class="p_header">+++ b/kernel/futex.c</span>
<span class="p_chunk">@@ -2813,7 +2813,6 @@</span> <span class="p_context"> static int futex_wait_requeue_pi(u32 __user *uaddr, unsigned int flags,</span>
 {
 	struct hrtimer_sleeper timeout, *to = NULL;
 	struct rt_mutex_waiter rt_waiter;
<span class="p_del">-	struct rt_mutex *pi_mutex = NULL;</span>
 	struct futex_hash_bucket *hb;
 	union futex_key key2 = FUTEX_KEY_INIT;
 	struct futex_q q = futex_q_init;
<span class="p_chunk">@@ -2897,6 +2896,8 @@</span> <span class="p_context"> static int futex_wait_requeue_pi(u32 __user *uaddr, unsigned int flags,</span>
 		if (q.pi_state &amp;&amp; (q.pi_state-&gt;owner != current)) {
 			spin_lock(q.lock_ptr);
 			ret = fixup_pi_state_owner(uaddr2, &amp;q, current);
<span class="p_add">+			if (ret &amp;&amp; rt_mutex_owner(&amp;q.pi_state-&gt;pi_mutex) == current)</span>
<span class="p_add">+				rt_mutex_unlock(&amp;q.pi_state-&gt;pi_mutex);</span>
 			/*
 			 * Drop the reference to the pi state which
 			 * the requeue_pi() code acquired for us.
<span class="p_chunk">@@ -2905,6 +2906,8 @@</span> <span class="p_context"> static int futex_wait_requeue_pi(u32 __user *uaddr, unsigned int flags,</span>
 			spin_unlock(q.lock_ptr);
 		}
 	} else {
<span class="p_add">+		struct rt_mutex *pi_mutex;</span>
<span class="p_add">+</span>
 		/*
 		 * We have been woken up by futex_unlock_pi(), a timeout, or a
 		 * signal.  futex_unlock_pi() will not destroy the lock_ptr nor
<span class="p_chunk">@@ -2928,18 +2931,19 @@</span> <span class="p_context"> static int futex_wait_requeue_pi(u32 __user *uaddr, unsigned int flags,</span>
 		if (res)
 			ret = (res &lt; 0) ? res : 0;
 
<span class="p_add">+		/*</span>
<span class="p_add">+		 * If fixup_pi_state_owner() faulted and was unable to handle</span>
<span class="p_add">+		 * the fault, unlock the rt_mutex and return the fault to</span>
<span class="p_add">+		 * userspace.</span>
<span class="p_add">+		 */</span>
<span class="p_add">+		if (ret &amp;&amp; rt_mutex_owner(pi_mutex) == current)</span>
<span class="p_add">+			rt_mutex_unlock(pi_mutex);</span>
<span class="p_add">+</span>
 		/* Unqueue and drop the lock. */
 		unqueue_me_pi(&amp;q);
 	}
 
<span class="p_del">-	/*</span>
<span class="p_del">-	 * If fixup_pi_state_owner() faulted and was unable to handle the</span>
<span class="p_del">-	 * fault, unlock the rt_mutex and return the fault to userspace.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	if (ret == -EFAULT) {</span>
<span class="p_del">-		if (pi_mutex &amp;&amp; rt_mutex_owner(pi_mutex) == current)</span>
<span class="p_del">-			rt_mutex_unlock(pi_mutex);</span>
<span class="p_del">-	} else if (ret == -EINTR) {</span>
<span class="p_add">+	if (ret == -EINTR) {</span>
 		/*
 		 * We&#39;ve already been requeued, but cannot restart by calling
 		 * futex_lock_pi() directly. We could restart this syscall, but
<span class="p_header">diff --git a/kernel/locking/rwsem-spinlock.c b/kernel/locking/rwsem-spinlock.c</span>
<span class="p_header">index 1591f6b3539f..2bef4ab94003 100644</span>
<span class="p_header">--- a/kernel/locking/rwsem-spinlock.c</span>
<span class="p_header">+++ b/kernel/locking/rwsem-spinlock.c</span>
<span class="p_chunk">@@ -216,10 +216,8 @@</span> <span class="p_context"> int __sched __down_write_common(struct rw_semaphore *sem, int state)</span>
 		 */
 		if (sem-&gt;count == 0)
 			break;
<span class="p_del">-		if (signal_pending_state(state, current)) {</span>
<span class="p_del">-			ret = -EINTR;</span>
<span class="p_del">-			goto out;</span>
<span class="p_del">-		}</span>
<span class="p_add">+		if (signal_pending_state(state, current))</span>
<span class="p_add">+			goto out_nolock;</span>
 		set_task_state(tsk, state);
 		raw_spin_unlock_irqrestore(&amp;sem-&gt;wait_lock, flags);
 		schedule();
<span class="p_chunk">@@ -227,12 +225,19 @@</span> <span class="p_context"> int __sched __down_write_common(struct rw_semaphore *sem, int state)</span>
 	}
 	/* got the lock */
 	sem-&gt;count = -1;
<span class="p_del">-out:</span>
 	list_del(&amp;waiter.list);
 
 	raw_spin_unlock_irqrestore(&amp;sem-&gt;wait_lock, flags);
 
 	return ret;
<span class="p_add">+</span>
<span class="p_add">+out_nolock:</span>
<span class="p_add">+	list_del(&amp;waiter.list);</span>
<span class="p_add">+	if (!list_empty(&amp;sem-&gt;wait_list))</span>
<span class="p_add">+		__rwsem_do_wake(sem, 1);</span>
<span class="p_add">+	raw_spin_unlock_irqrestore(&amp;sem-&gt;wait_lock, flags);</span>
<span class="p_add">+</span>
<span class="p_add">+	return -EINTR;</span>
 }
 
 void __sched __down_write(struct rw_semaphore *sem)
<span class="p_header">diff --git a/net/bridge/br_forward.c b/net/bridge/br_forward.c</span>
<span class="p_header">index 7cb41aee4c82..8498e3503605 100644</span>
<span class="p_header">--- a/net/bridge/br_forward.c</span>
<span class="p_header">+++ b/net/bridge/br_forward.c</span>
<span class="p_chunk">@@ -186,8 +186,9 @@</span> <span class="p_context"> void br_flood(struct net_bridge *br, struct sk_buff *skb,</span>
 		/* Do not flood unicast traffic to ports that turn it off */
 		if (pkt_type == BR_PKT_UNICAST &amp;&amp; !(p-&gt;flags &amp; BR_FLOOD))
 			continue;
<span class="p_add">+		/* Do not flood if mc off, except for traffic we originate */</span>
 		if (pkt_type == BR_PKT_MULTICAST &amp;&amp;
<span class="p_del">-		    !(p-&gt;flags &amp; BR_MCAST_FLOOD))</span>
<span class="p_add">+		    !(p-&gt;flags &amp; BR_MCAST_FLOOD) &amp;&amp; skb-&gt;dev != br-&gt;dev)</span>
 			continue;
 
 		/* Do not flood to ports that enable proxy ARP */
<span class="p_header">diff --git a/net/bridge/br_input.c b/net/bridge/br_input.c</span>
<span class="p_header">index 855b72fbe1da..267b46af407f 100644</span>
<span class="p_header">--- a/net/bridge/br_input.c</span>
<span class="p_header">+++ b/net/bridge/br_input.c</span>
<span class="p_chunk">@@ -29,6 +29,7 @@</span> <span class="p_context"> EXPORT_SYMBOL(br_should_route_hook);</span>
 static int
 br_netif_receive_skb(struct net *net, struct sock *sk, struct sk_buff *skb)
 {
<span class="p_add">+	br_drop_fake_rtable(skb);</span>
 	return netif_receive_skb(skb);
 }
 
<span class="p_header">diff --git a/net/bridge/br_netfilter_hooks.c b/net/bridge/br_netfilter_hooks.c</span>
<span class="p_header">index 95087e6e8258..fa87fbd62bb7 100644</span>
<span class="p_header">--- a/net/bridge/br_netfilter_hooks.c</span>
<span class="p_header">+++ b/net/bridge/br_netfilter_hooks.c</span>
<span class="p_chunk">@@ -521,21 +521,6 @@</span> <span class="p_context"> static unsigned int br_nf_pre_routing(void *priv,</span>
 }
 
 
<span class="p_del">-/* PF_BRIDGE/LOCAL_IN ************************************************/</span>
<span class="p_del">-/* The packet is locally destined, which requires a real</span>
<span class="p_del">- * dst_entry, so detach the fake one.  On the way up, the</span>
<span class="p_del">- * packet would pass through PRE_ROUTING again (which already</span>
<span class="p_del">- * took place when the packet entered the bridge), but we</span>
<span class="p_del">- * register an IPv4 PRE_ROUTING &#39;sabotage&#39; hook that will</span>
<span class="p_del">- * prevent this from happening. */</span>
<span class="p_del">-static unsigned int br_nf_local_in(void *priv,</span>
<span class="p_del">-				   struct sk_buff *skb,</span>
<span class="p_del">-				   const struct nf_hook_state *state)</span>
<span class="p_del">-{</span>
<span class="p_del">-	br_drop_fake_rtable(skb);</span>
<span class="p_del">-	return NF_ACCEPT;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
 /* PF_BRIDGE/FORWARD *************************************************/
 static int br_nf_forward_finish(struct net *net, struct sock *sk, struct sk_buff *skb)
 {
<span class="p_chunk">@@ -908,12 +893,6 @@</span> <span class="p_context"> static struct nf_hook_ops br_nf_ops[] __read_mostly = {</span>
 		.priority = NF_BR_PRI_BRNF,
 	},
 	{
<span class="p_del">-		.hook = br_nf_local_in,</span>
<span class="p_del">-		.pf = NFPROTO_BRIDGE,</span>
<span class="p_del">-		.hooknum = NF_BR_LOCAL_IN,</span>
<span class="p_del">-		.priority = NF_BR_PRI_BRNF,</span>
<span class="p_del">-	},</span>
<span class="p_del">-	{</span>
 		.hook = br_nf_forward_ip,
 		.pf = NFPROTO_BRIDGE,
 		.hooknum = NF_BR_FORWARD,
<span class="p_header">diff --git a/net/core/dev.c b/net/core/dev.c</span>
<span class="p_header">index 29101c98399f..fd6e2dfda45f 100644</span>
<span class="p_header">--- a/net/core/dev.c</span>
<span class="p_header">+++ b/net/core/dev.c</span>
<span class="p_chunk">@@ -1696,27 +1696,54 @@</span> <span class="p_context"> EXPORT_SYMBOL_GPL(net_dec_egress_queue);</span>
 static struct static_key netstamp_needed __read_mostly;
 #ifdef HAVE_JUMP_LABEL
 static atomic_t netstamp_needed_deferred;
<span class="p_add">+static atomic_t netstamp_wanted;</span>
 static void netstamp_clear(struct work_struct *work)
 {
 	int deferred = atomic_xchg(&amp;netstamp_needed_deferred, 0);
<span class="p_add">+	int wanted;</span>
 
<span class="p_del">-	while (deferred--)</span>
<span class="p_del">-		static_key_slow_dec(&amp;netstamp_needed);</span>
<span class="p_add">+	wanted = atomic_add_return(deferred, &amp;netstamp_wanted);</span>
<span class="p_add">+	if (wanted &gt; 0)</span>
<span class="p_add">+		static_key_enable(&amp;netstamp_needed);</span>
<span class="p_add">+	else</span>
<span class="p_add">+		static_key_disable(&amp;netstamp_needed);</span>
 }
 static DECLARE_WORK(netstamp_work, netstamp_clear);
 #endif
 
 void net_enable_timestamp(void)
 {
<span class="p_add">+#ifdef HAVE_JUMP_LABEL</span>
<span class="p_add">+	int wanted;</span>
<span class="p_add">+</span>
<span class="p_add">+	while (1) {</span>
<span class="p_add">+		wanted = atomic_read(&amp;netstamp_wanted);</span>
<span class="p_add">+		if (wanted &lt;= 0)</span>
<span class="p_add">+			break;</span>
<span class="p_add">+		if (atomic_cmpxchg(&amp;netstamp_wanted, wanted, wanted + 1) == wanted)</span>
<span class="p_add">+			return;</span>
<span class="p_add">+	}</span>
<span class="p_add">+	atomic_inc(&amp;netstamp_needed_deferred);</span>
<span class="p_add">+	schedule_work(&amp;netstamp_work);</span>
<span class="p_add">+#else</span>
 	static_key_slow_inc(&amp;netstamp_needed);
<span class="p_add">+#endif</span>
 }
 EXPORT_SYMBOL(net_enable_timestamp);
 
 void net_disable_timestamp(void)
 {
 #ifdef HAVE_JUMP_LABEL
<span class="p_del">-	/* net_disable_timestamp() can be called from non process context */</span>
<span class="p_del">-	atomic_inc(&amp;netstamp_needed_deferred);</span>
<span class="p_add">+	int wanted;</span>
<span class="p_add">+</span>
<span class="p_add">+	while (1) {</span>
<span class="p_add">+		wanted = atomic_read(&amp;netstamp_wanted);</span>
<span class="p_add">+		if (wanted &lt;= 1)</span>
<span class="p_add">+			break;</span>
<span class="p_add">+		if (atomic_cmpxchg(&amp;netstamp_wanted, wanted, wanted - 1) == wanted)</span>
<span class="p_add">+			return;</span>
<span class="p_add">+	}</span>
<span class="p_add">+	atomic_dec(&amp;netstamp_needed_deferred);</span>
 	schedule_work(&amp;netstamp_work);
 #else
 	static_key_slow_dec(&amp;netstamp_needed);
<span class="p_header">diff --git a/net/core/net-sysfs.c b/net/core/net-sysfs.c</span>
<span class="p_header">index b0c04cf4851d..1004418d937e 100644</span>
<span class="p_header">--- a/net/core/net-sysfs.c</span>
<span class="p_header">+++ b/net/core/net-sysfs.c</span>
<span class="p_chunk">@@ -952,7 +952,7 @@</span> <span class="p_context"> net_rx_queue_update_kobjects(struct net_device *dev, int old_num, int new_num)</span>
 	while (--i &gt;= new_num) {
 		struct kobject *kobj = &amp;dev-&gt;_rx[i].kobj;
 
<span class="p_del">-		if (!list_empty(&amp;dev_net(dev)-&gt;exit_list))</span>
<span class="p_add">+		if (!atomic_read(&amp;dev_net(dev)-&gt;count))</span>
 			kobj-&gt;uevent_suppress = 1;
 		if (dev-&gt;sysfs_rx_queue_group)
 			sysfs_remove_group(kobj, dev-&gt;sysfs_rx_queue_group);
<span class="p_chunk">@@ -1370,7 +1370,7 @@</span> <span class="p_context"> netdev_queue_update_kobjects(struct net_device *dev, int old_num, int new_num)</span>
 	while (--i &gt;= new_num) {
 		struct netdev_queue *queue = dev-&gt;_tx + i;
 
<span class="p_del">-		if (!list_empty(&amp;dev_net(dev)-&gt;exit_list))</span>
<span class="p_add">+		if (!atomic_read(&amp;dev_net(dev)-&gt;count))</span>
 			queue-&gt;kobj.uevent_suppress = 1;
 #ifdef CONFIG_BQL
 		sysfs_remove_group(&amp;queue-&gt;kobj, &amp;dql_group);
<span class="p_chunk">@@ -1557,7 +1557,7 @@</span> <span class="p_context"> void netdev_unregister_kobject(struct net_device *ndev)</span>
 {
 	struct device *dev = &amp;(ndev-&gt;dev);
 
<span class="p_del">-	if (!list_empty(&amp;dev_net(ndev)-&gt;exit_list))</span>
<span class="p_add">+	if (!atomic_read(&amp;dev_net(ndev)-&gt;count))</span>
 		dev_set_uevent_suppress(dev, 1);
 
 	kobject_get(&amp;dev-&gt;kobj);
<span class="p_header">diff --git a/net/core/skbuff.c b/net/core/skbuff.c</span>
<span class="p_header">index 734c71468b01..aa3a13378c90 100644</span>
<span class="p_header">--- a/net/core/skbuff.c</span>
<span class="p_header">+++ b/net/core/skbuff.c</span>
<span class="p_chunk">@@ -3824,13 +3824,14 @@</span> <span class="p_context"> void skb_complete_tx_timestamp(struct sk_buff *skb,</span>
 	if (!skb_may_tx_timestamp(sk, false))
 		return;
 
<span class="p_del">-	/* take a reference to prevent skb_orphan() from freeing the socket */</span>
<span class="p_del">-	sock_hold(sk);</span>
<span class="p_del">-</span>
<span class="p_del">-	*skb_hwtstamps(skb) = *hwtstamps;</span>
<span class="p_del">-	__skb_complete_tx_timestamp(skb, sk, SCM_TSTAMP_SND);</span>
<span class="p_del">-</span>
<span class="p_del">-	sock_put(sk);</span>
<span class="p_add">+	/* Take a reference to prevent skb_orphan() from freeing the socket,</span>
<span class="p_add">+	 * but only if the socket refcount is not zero.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	if (likely(atomic_inc_not_zero(&amp;sk-&gt;sk_refcnt))) {</span>
<span class="p_add">+		*skb_hwtstamps(skb) = *hwtstamps;</span>
<span class="p_add">+		__skb_complete_tx_timestamp(skb, sk, SCM_TSTAMP_SND);</span>
<span class="p_add">+		sock_put(sk);</span>
<span class="p_add">+	}</span>
 }
 EXPORT_SYMBOL_GPL(skb_complete_tx_timestamp);
 
<span class="p_chunk">@@ -3889,7 +3890,7 @@</span> <span class="p_context"> void skb_complete_wifi_ack(struct sk_buff *skb, bool acked)</span>
 {
 	struct sock *sk = skb-&gt;sk;
 	struct sock_exterr_skb *serr;
<span class="p_del">-	int err;</span>
<span class="p_add">+	int err = 1;</span>
 
 	skb-&gt;wifi_acked_valid = 1;
 	skb-&gt;wifi_acked = acked;
<span class="p_chunk">@@ -3899,14 +3900,15 @@</span> <span class="p_context"> void skb_complete_wifi_ack(struct sk_buff *skb, bool acked)</span>
 	serr-&gt;ee.ee_errno = ENOMSG;
 	serr-&gt;ee.ee_origin = SO_EE_ORIGIN_TXSTATUS;
 
<span class="p_del">-	/* take a reference to prevent skb_orphan() from freeing the socket */</span>
<span class="p_del">-	sock_hold(sk);</span>
<span class="p_del">-</span>
<span class="p_del">-	err = sock_queue_err_skb(sk, skb);</span>
<span class="p_add">+	/* Take a reference to prevent skb_orphan() from freeing the socket,</span>
<span class="p_add">+	 * but only if the socket refcount is not zero.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	if (likely(atomic_inc_not_zero(&amp;sk-&gt;sk_refcnt))) {</span>
<span class="p_add">+		err = sock_queue_err_skb(sk, skb);</span>
<span class="p_add">+		sock_put(sk);</span>
<span class="p_add">+	}</span>
 	if (err)
 		kfree_skb(skb);
<span class="p_del">-</span>
<span class="p_del">-	sock_put(sk);</span>
 }
 EXPORT_SYMBOL_GPL(skb_complete_wifi_ack);
 
<span class="p_header">diff --git a/net/dccp/ccids/ccid2.c b/net/dccp/ccids/ccid2.c</span>
<span class="p_header">index f053198e730c..5e3a7302f774 100644</span>
<span class="p_header">--- a/net/dccp/ccids/ccid2.c</span>
<span class="p_header">+++ b/net/dccp/ccids/ccid2.c</span>
<span class="p_chunk">@@ -749,6 +749,7 @@</span> <span class="p_context"> static void ccid2_hc_tx_exit(struct sock *sk)</span>
 	for (i = 0; i &lt; hc-&gt;tx_seqbufc; i++)
 		kfree(hc-&gt;tx_seqbuf[i]);
 	hc-&gt;tx_seqbufc = 0;
<span class="p_add">+	dccp_ackvec_parsed_cleanup(&amp;hc-&gt;tx_av_chunks);</span>
 }
 
 static void ccid2_hc_rx_packet_recv(struct sock *sk, struct sk_buff *skb)
<span class="p_header">diff --git a/net/dccp/input.c b/net/dccp/input.c</span>
<span class="p_header">index 8fedc2d49770..4a05d7876850 100644</span>
<span class="p_header">--- a/net/dccp/input.c</span>
<span class="p_header">+++ b/net/dccp/input.c</span>
<span class="p_chunk">@@ -577,6 +577,7 @@</span> <span class="p_context"> int dccp_rcv_state_process(struct sock *sk, struct sk_buff *skb,</span>
 	struct dccp_sock *dp = dccp_sk(sk);
 	struct dccp_skb_cb *dcb = DCCP_SKB_CB(skb);
 	const int old_state = sk-&gt;sk_state;
<span class="p_add">+	bool acceptable;</span>
 	int queued = 0;
 
 	/*
<span class="p_chunk">@@ -603,8 +604,13 @@</span> <span class="p_context"> int dccp_rcv_state_process(struct sock *sk, struct sk_buff *skb,</span>
 	 */
 	if (sk-&gt;sk_state == DCCP_LISTEN) {
 		if (dh-&gt;dccph_type == DCCP_PKT_REQUEST) {
<span class="p_del">-			if (inet_csk(sk)-&gt;icsk_af_ops-&gt;conn_request(sk,</span>
<span class="p_del">-								    skb) &lt; 0)</span>
<span class="p_add">+			/* It is possible that we process SYN packets from backlog,</span>
<span class="p_add">+			 * so we need to make sure to disable BH right there.</span>
<span class="p_add">+			 */</span>
<span class="p_add">+			local_bh_disable();</span>
<span class="p_add">+			acceptable = inet_csk(sk)-&gt;icsk_af_ops-&gt;conn_request(sk, skb) &gt;= 0;</span>
<span class="p_add">+			local_bh_enable();</span>
<span class="p_add">+			if (!acceptable)</span>
 				return 1;
 			consume_skb(skb);
 			return 0;
<span class="p_header">diff --git a/net/dccp/ipv4.c b/net/dccp/ipv4.c</span>
<span class="p_header">index d859a5c36e70..b0a1ba968ed5 100644</span>
<span class="p_header">--- a/net/dccp/ipv4.c</span>
<span class="p_header">+++ b/net/dccp/ipv4.c</span>
<span class="p_chunk">@@ -289,7 +289,8 @@</span> <span class="p_context"> static void dccp_v4_err(struct sk_buff *skb, u32 info)</span>
 
 	switch (type) {
 	case ICMP_REDIRECT:
<span class="p_del">-		dccp_do_redirect(skb, sk);</span>
<span class="p_add">+		if (!sock_owned_by_user(sk))</span>
<span class="p_add">+			dccp_do_redirect(skb, sk);</span>
 		goto out;
 	case ICMP_SOURCE_QUENCH:
 		/* Just silently ignore these. */
<span class="p_header">diff --git a/net/dccp/ipv6.c b/net/dccp/ipv6.c</span>
<span class="p_header">index c4e879c02186..2f3e8bbe2cb9 100644</span>
<span class="p_header">--- a/net/dccp/ipv6.c</span>
<span class="p_header">+++ b/net/dccp/ipv6.c</span>
<span class="p_chunk">@@ -122,10 +122,12 @@</span> <span class="p_context"> static void dccp_v6_err(struct sk_buff *skb, struct inet6_skb_parm *opt,</span>
 	np = inet6_sk(sk);
 
 	if (type == NDISC_REDIRECT) {
<span class="p_del">-		struct dst_entry *dst = __sk_dst_check(sk, np-&gt;dst_cookie);</span>
<span class="p_add">+		if (!sock_owned_by_user(sk)) {</span>
<span class="p_add">+			struct dst_entry *dst = __sk_dst_check(sk, np-&gt;dst_cookie);</span>
 
<span class="p_del">-		if (dst)</span>
<span class="p_del">-			dst-&gt;ops-&gt;redirect(dst, sk, skb);</span>
<span class="p_add">+			if (dst)</span>
<span class="p_add">+				dst-&gt;ops-&gt;redirect(dst, sk, skb);</span>
<span class="p_add">+		}</span>
 		goto out;
 	}
 
<span class="p_header">diff --git a/net/dccp/minisocks.c b/net/dccp/minisocks.c</span>
<span class="p_header">index 53eddf99e4f6..39e7e2bca8db 100644</span>
<span class="p_header">--- a/net/dccp/minisocks.c</span>
<span class="p_header">+++ b/net/dccp/minisocks.c</span>
<span class="p_chunk">@@ -122,6 +122,7 @@</span> <span class="p_context"> struct sock *dccp_create_openreq_child(const struct sock *sk,</span>
 			/* It is still raw copy of parent, so invalidate
 			 * destructor and make plain sk_free() */
 			newsk-&gt;sk_destruct = NULL;
<span class="p_add">+			bh_unlock_sock(newsk);</span>
 			sk_free(newsk);
 			return NULL;
 		}
<span class="p_chunk">@@ -145,6 +146,13 @@</span> <span class="p_context"> struct sock *dccp_check_req(struct sock *sk, struct sk_buff *skb,</span>
 	struct dccp_request_sock *dreq = dccp_rsk(req);
 	bool own_req;
 
<span class="p_add">+	/* TCP/DCCP listeners became lockless.</span>
<span class="p_add">+	 * DCCP stores complex state in its request_sock, so we need</span>
<span class="p_add">+	 * a protection for them, now this code runs without being protected</span>
<span class="p_add">+	 * by the parent (listener) lock.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	spin_lock_bh(&amp;dreq-&gt;dreq_lock);</span>
<span class="p_add">+</span>
 	/* Check for retransmitted REQUEST */
 	if (dccp_hdr(skb)-&gt;dccph_type == DCCP_PKT_REQUEST) {
 
<span class="p_chunk">@@ -159,7 +167,7 @@</span> <span class="p_context"> struct sock *dccp_check_req(struct sock *sk, struct sk_buff *skb,</span>
 			inet_rtx_syn_ack(sk, req);
 		}
 		/* Network Duplicate, discard packet */
<span class="p_del">-		return NULL;</span>
<span class="p_add">+		goto out;</span>
 	}
 
 	DCCP_SKB_CB(skb)-&gt;dccpd_reset_code = DCCP_RESET_CODE_PACKET_ERROR;
<span class="p_chunk">@@ -185,20 +193,20 @@</span> <span class="p_context"> struct sock *dccp_check_req(struct sock *sk, struct sk_buff *skb,</span>
 
 	child = inet_csk(sk)-&gt;icsk_af_ops-&gt;syn_recv_sock(sk, skb, req, NULL,
 							 req, &amp;own_req);
<span class="p_del">-	if (!child)</span>
<span class="p_del">-		goto listen_overflow;</span>
<span class="p_del">-</span>
<span class="p_del">-	return inet_csk_complete_hashdance(sk, child, req, own_req);</span>
<span class="p_add">+	if (child) {</span>
<span class="p_add">+		child = inet_csk_complete_hashdance(sk, child, req, own_req);</span>
<span class="p_add">+		goto out;</span>
<span class="p_add">+	}</span>
 
<span class="p_del">-listen_overflow:</span>
<span class="p_del">-	dccp_pr_debug(&quot;listen_overflow!\n&quot;);</span>
 	DCCP_SKB_CB(skb)-&gt;dccpd_reset_code = DCCP_RESET_CODE_TOO_BUSY;
 drop:
 	if (dccp_hdr(skb)-&gt;dccph_type != DCCP_PKT_RESET)
 		req-&gt;rsk_ops-&gt;send_reset(sk, skb);
 
 	inet_csk_reqsk_queue_drop(sk, req);
<span class="p_del">-	return NULL;</span>
<span class="p_add">+out:</span>
<span class="p_add">+	spin_unlock_bh(&amp;dreq-&gt;dreq_lock);</span>
<span class="p_add">+	return child;</span>
 }
 
 EXPORT_SYMBOL_GPL(dccp_check_req);
<span class="p_chunk">@@ -249,6 +257,7 @@</span> <span class="p_context"> int dccp_reqsk_init(struct request_sock *req,</span>
 {
 	struct dccp_request_sock *dreq = dccp_rsk(req);
 
<span class="p_add">+	spin_lock_init(&amp;dreq-&gt;dreq_lock);</span>
 	inet_rsk(req)-&gt;ir_rmt_port = dccp_hdr(skb)-&gt;dccph_sport;
 	inet_rsk(req)-&gt;ir_num	   = ntohs(dccp_hdr(skb)-&gt;dccph_dport);
 	inet_rsk(req)-&gt;acked	   = 0;
<span class="p_header">diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c</span>
<span class="p_header">index f75069883f2b..4391da91789f 100644</span>
<span class="p_header">--- a/net/ipv4/af_inet.c</span>
<span class="p_header">+++ b/net/ipv4/af_inet.c</span>
<span class="p_chunk">@@ -1470,8 +1470,10 @@</span> <span class="p_context"> int inet_gro_complete(struct sk_buff *skb, int nhoff)</span>
 	int proto = iph-&gt;protocol;
 	int err = -ENOSYS;
 
<span class="p_del">-	if (skb-&gt;encapsulation)</span>
<span class="p_add">+	if (skb-&gt;encapsulation) {</span>
<span class="p_add">+		skb_set_inner_protocol(skb, cpu_to_be16(ETH_P_IP));</span>
 		skb_set_inner_network_header(skb, nhoff);
<span class="p_add">+	}</span>
 
 	csum_replace2(&amp;iph-&gt;check, iph-&gt;tot_len, newlen);
 	iph-&gt;tot_len = newlen;
<span class="p_header">diff --git a/net/ipv4/fib_frontend.c b/net/ipv4/fib_frontend.c</span>
<span class="p_header">index 7db2ad2e82d3..b39a791f6756 100644</span>
<span class="p_header">--- a/net/ipv4/fib_frontend.c</span>
<span class="p_header">+++ b/net/ipv4/fib_frontend.c</span>
<span class="p_chunk">@@ -319,7 +319,7 @@</span> <span class="p_context"> static int __fib_validate_source(struct sk_buff *skb, __be32 src, __be32 dst,</span>
 	int ret, no_addr;
 	struct fib_result res;
 	struct flowi4 fl4;
<span class="p_del">-	struct net *net;</span>
<span class="p_add">+	struct net *net = dev_net(dev);</span>
 	bool dev_match;
 
 	fl4.flowi4_oif = 0;
<span class="p_chunk">@@ -332,6 +332,7 @@</span> <span class="p_context"> static int __fib_validate_source(struct sk_buff *skb, __be32 src, __be32 dst,</span>
 	fl4.flowi4_scope = RT_SCOPE_UNIVERSE;
 	fl4.flowi4_tun_key.tun_id = 0;
 	fl4.flowi4_flags = 0;
<span class="p_add">+	fl4.flowi4_uid = sock_net_uid(net, NULL);</span>
 
 	no_addr = idev-&gt;ifa_list == NULL;
 
<span class="p_chunk">@@ -339,13 +340,12 @@</span> <span class="p_context"> static int __fib_validate_source(struct sk_buff *skb, __be32 src, __be32 dst,</span>
 
 	trace_fib_validate_source(dev, &amp;fl4);
 
<span class="p_del">-	net = dev_net(dev);</span>
 	if (fib_lookup(net, &amp;fl4, &amp;res, 0))
 		goto last_resort;
 	if (res.type != RTN_UNICAST &amp;&amp;
 	    (res.type != RTN_LOCAL || !IN_DEV_ACCEPT_LOCAL(idev)))
 		goto e_inval;
<span class="p_del">-	if (!rpf &amp;&amp; !fib_num_tclassid_users(dev_net(dev)) &amp;&amp;</span>
<span class="p_add">+	if (!rpf &amp;&amp; !fib_num_tclassid_users(net) &amp;&amp;</span>
 	    (dev-&gt;ifindex != oif || !IN_DEV_TX_REDIRECTS(idev)))
 		goto last_resort;
 	fib_combine_itag(itag, &amp;res);
<span class="p_header">diff --git a/net/ipv4/route.c b/net/ipv4/route.c</span>
<span class="p_header">index 709ffe67d1de..8976887dc83e 100644</span>
<span class="p_header">--- a/net/ipv4/route.c</span>
<span class="p_header">+++ b/net/ipv4/route.c</span>
<span class="p_chunk">@@ -1858,6 +1858,7 @@</span> <span class="p_context"> static int ip_route_input_slow(struct sk_buff *skb, __be32 daddr, __be32 saddr,</span>
 	fl4.flowi4_flags = 0;
 	fl4.daddr = daddr;
 	fl4.saddr = saddr;
<span class="p_add">+	fl4.flowi4_uid = sock_net_uid(net, NULL);</span>
 	err = fib_lookup(net, &amp;fl4, &amp;res, 0);
 	if (err != 0) {
 		if (!IN_DEV_FORWARD(in_dev))
<span class="p_chunk">@@ -1990,6 +1991,7 @@</span> <span class="p_context"> int ip_route_input_noref(struct sk_buff *skb, __be32 daddr, __be32 saddr,</span>
 {
 	int res;
 
<span class="p_add">+	tos &amp;= IPTOS_RT_MASK;</span>
 	rcu_read_lock();
 
 	/* Multicast recognition logic is moved from route cache to here.
<span class="p_header">diff --git a/net/ipv4/tcp_input.c b/net/ipv4/tcp_input.c</span>
<span class="p_header">index 41dcbd568cbe..28777a0307c8 100644</span>
<span class="p_header">--- a/net/ipv4/tcp_input.c</span>
<span class="p_header">+++ b/net/ipv4/tcp_input.c</span>
<span class="p_chunk">@@ -5916,9 +5916,15 @@</span> <span class="p_context"> int tcp_rcv_state_process(struct sock *sk, struct sk_buff *skb)</span>
 		if (th-&gt;syn) {
 			if (th-&gt;fin)
 				goto discard;
<span class="p_del">-			if (icsk-&gt;icsk_af_ops-&gt;conn_request(sk, skb) &lt; 0)</span>
<span class="p_del">-				return 1;</span>
<span class="p_add">+			/* It is possible that we process SYN packets from backlog,</span>
<span class="p_add">+			 * so we need to make sure to disable BH right there.</span>
<span class="p_add">+			 */</span>
<span class="p_add">+			local_bh_disable();</span>
<span class="p_add">+			acceptable = icsk-&gt;icsk_af_ops-&gt;conn_request(sk, skb) &gt;= 0;</span>
<span class="p_add">+			local_bh_enable();</span>
 
<span class="p_add">+			if (!acceptable)</span>
<span class="p_add">+				return 1;</span>
 			consume_skb(skb);
 			return 0;
 		}
<span class="p_header">diff --git a/net/ipv4/tcp_ipv4.c b/net/ipv4/tcp_ipv4.c</span>
<span class="p_header">index fe9da4fb96bf..bb629dc2bfb0 100644</span>
<span class="p_header">--- a/net/ipv4/tcp_ipv4.c</span>
<span class="p_header">+++ b/net/ipv4/tcp_ipv4.c</span>
<span class="p_chunk">@@ -269,10 +269,13 @@</span> <span class="p_context"> EXPORT_SYMBOL(tcp_v4_connect);</span>
  */
 void tcp_v4_mtu_reduced(struct sock *sk)
 {
<span class="p_del">-	struct dst_entry *dst;</span>
 	struct inet_sock *inet = inet_sk(sk);
<span class="p_del">-	u32 mtu = tcp_sk(sk)-&gt;mtu_info;</span>
<span class="p_add">+	struct dst_entry *dst;</span>
<span class="p_add">+	u32 mtu;</span>
 
<span class="p_add">+	if ((1 &lt;&lt; sk-&gt;sk_state) &amp; (TCPF_LISTEN | TCPF_CLOSE))</span>
<span class="p_add">+		return;</span>
<span class="p_add">+	mtu = tcp_sk(sk)-&gt;mtu_info;</span>
 	dst = inet_csk_update_pmtu(sk, mtu);
 	if (!dst)
 		return;
<span class="p_chunk">@@ -418,7 +421,8 @@</span> <span class="p_context"> void tcp_v4_err(struct sk_buff *icmp_skb, u32 info)</span>
 
 	switch (type) {
 	case ICMP_REDIRECT:
<span class="p_del">-		do_redirect(icmp_skb, sk);</span>
<span class="p_add">+		if (!sock_owned_by_user(sk))</span>
<span class="p_add">+			do_redirect(icmp_skb, sk);</span>
 		goto out;
 	case ICMP_SOURCE_QUENCH:
 		/* Just silently ignore these. */
<span class="p_header">diff --git a/net/ipv4/tcp_timer.c b/net/ipv4/tcp_timer.c</span>
<span class="p_header">index 3705075f42c3..45d707569af6 100644</span>
<span class="p_header">--- a/net/ipv4/tcp_timer.c</span>
<span class="p_header">+++ b/net/ipv4/tcp_timer.c</span>
<span class="p_chunk">@@ -249,7 +249,8 @@</span> <span class="p_context"> void tcp_delack_timer_handler(struct sock *sk)</span>
 
 	sk_mem_reclaim_partial(sk);
 
<span class="p_del">-	if (sk-&gt;sk_state == TCP_CLOSE || !(icsk-&gt;icsk_ack.pending &amp; ICSK_ACK_TIMER))</span>
<span class="p_add">+	if (((1 &lt;&lt; sk-&gt;sk_state) &amp; (TCPF_CLOSE | TCPF_LISTEN)) ||</span>
<span class="p_add">+	    !(icsk-&gt;icsk_ack.pending &amp; ICSK_ACK_TIMER))</span>
 		goto out;
 
 	if (time_after(icsk-&gt;icsk_ack.timeout, jiffies)) {
<span class="p_chunk">@@ -552,7 +553,8 @@</span> <span class="p_context"> void tcp_write_timer_handler(struct sock *sk)</span>
 	struct inet_connection_sock *icsk = inet_csk(sk);
 	int event;
 
<span class="p_del">-	if (sk-&gt;sk_state == TCP_CLOSE || !icsk-&gt;icsk_pending)</span>
<span class="p_add">+	if (((1 &lt;&lt; sk-&gt;sk_state) &amp; (TCPF_CLOSE | TCPF_LISTEN)) ||</span>
<span class="p_add">+	    !icsk-&gt;icsk_pending)</span>
 		goto out;
 
 	if (time_after(icsk-&gt;icsk_timeout, jiffies)) {
<span class="p_header">diff --git a/net/ipv6/ip6_fib.c b/net/ipv6/ip6_fib.c</span>
<span class="p_header">index ef5485204522..8c88a37392d0 100644</span>
<span class="p_header">--- a/net/ipv6/ip6_fib.c</span>
<span class="p_header">+++ b/net/ipv6/ip6_fib.c</span>
<span class="p_chunk">@@ -908,6 +908,8 @@</span> <span class="p_context"> static int fib6_add_rt2node(struct fib6_node *fn, struct rt6_info *rt,</span>
 			ins = &amp;rt-&gt;dst.rt6_next;
 			iter = *ins;
 			while (iter) {
<span class="p_add">+				if (iter-&gt;rt6i_metric &gt; rt-&gt;rt6i_metric)</span>
<span class="p_add">+					break;</span>
 				if (rt6_qualify_for_ecmp(iter)) {
 					*ins = iter-&gt;dst.rt6_next;
 					fib6_purge_rt(iter, fn, info-&gt;nl_net);
<span class="p_header">diff --git a/net/ipv6/ip6_offload.c b/net/ipv6/ip6_offload.c</span>
<span class="p_header">index fc7b4017ba24..33b04ec2744a 100644</span>
<span class="p_header">--- a/net/ipv6/ip6_offload.c</span>
<span class="p_header">+++ b/net/ipv6/ip6_offload.c</span>
<span class="p_chunk">@@ -294,8 +294,10 @@</span> <span class="p_context"> static int ipv6_gro_complete(struct sk_buff *skb, int nhoff)</span>
 	struct ipv6hdr *iph = (struct ipv6hdr *)(skb-&gt;data + nhoff);
 	int err = -ENOSYS;
 
<span class="p_del">-	if (skb-&gt;encapsulation)</span>
<span class="p_add">+	if (skb-&gt;encapsulation) {</span>
<span class="p_add">+		skb_set_inner_protocol(skb, cpu_to_be16(ETH_P_IPV6));</span>
 		skb_set_inner_network_header(skb, nhoff);
<span class="p_add">+	}</span>
 
 	iph-&gt;payload_len = htons(skb-&gt;len - nhoff - sizeof(*iph));
 
<span class="p_header">diff --git a/net/ipv6/ip6_output.c b/net/ipv6/ip6_output.c</span>
<span class="p_header">index 7cebee58e55b..d57f4ee5ec29 100644</span>
<span class="p_header">--- a/net/ipv6/ip6_output.c</span>
<span class="p_header">+++ b/net/ipv6/ip6_output.c</span>
<span class="p_chunk">@@ -767,13 +767,14 @@</span> <span class="p_context"> int ip6_fragment(struct net *net, struct sock *sk, struct sk_buff *skb,</span>
 	 *	Fragment the datagram.
 	 */
 
<span class="p_del">-	*prevhdr = NEXTHDR_FRAGMENT;</span>
 	troom = rt-&gt;dst.dev-&gt;needed_tailroom;
 
 	/*
 	 *	Keep copying data until we run out.
 	 */
 	while (left &gt; 0)	{
<span class="p_add">+		u8 *fragnexthdr_offset;</span>
<span class="p_add">+</span>
 		len = left;
 		/* IF: it doesn&#39;t fit, use &#39;mtu&#39; - the data space left */
 		if (len &gt; mtu)
<span class="p_chunk">@@ -818,6 +819,10 @@</span> <span class="p_context"> int ip6_fragment(struct net *net, struct sock *sk, struct sk_buff *skb,</span>
 		 */
 		skb_copy_from_linear_data(skb, skb_network_header(frag), hlen);
 
<span class="p_add">+		fragnexthdr_offset = skb_network_header(frag);</span>
<span class="p_add">+		fragnexthdr_offset += prevhdr - skb_network_header(skb);</span>
<span class="p_add">+		*fragnexthdr_offset = NEXTHDR_FRAGMENT;</span>
<span class="p_add">+</span>
 		/*
 		 *	Build fragment header.
 		 */
<span class="p_header">diff --git a/net/ipv6/ip6_vti.c b/net/ipv6/ip6_vti.c</span>
<span class="p_header">index d82042c8d8fd..733c63ef4b8a 100644</span>
<span class="p_header">--- a/net/ipv6/ip6_vti.c</span>
<span class="p_header">+++ b/net/ipv6/ip6_vti.c</span>
<span class="p_chunk">@@ -692,6 +692,10 @@</span> <span class="p_context"> vti6_parm_to_user(struct ip6_tnl_parm2 *u, const struct __ip6_tnl_parm *p)</span>
 	u-&gt;link = p-&gt;link;
 	u-&gt;i_key = p-&gt;i_key;
 	u-&gt;o_key = p-&gt;o_key;
<span class="p_add">+	if (u-&gt;i_key)</span>
<span class="p_add">+		u-&gt;i_flags |= GRE_KEY;</span>
<span class="p_add">+	if (u-&gt;o_key)</span>
<span class="p_add">+		u-&gt;o_flags |= GRE_KEY;</span>
 	u-&gt;proto = p-&gt;proto;
 
 	memcpy(u-&gt;name, p-&gt;name, sizeof(u-&gt;name));
<span class="p_header">diff --git a/net/ipv6/netfilter/nf_conntrack_reasm.c b/net/ipv6/netfilter/nf_conntrack_reasm.c</span>
<span class="p_header">index 9948b5ce52da..986d4ca38832 100644</span>
<span class="p_header">--- a/net/ipv6/netfilter/nf_conntrack_reasm.c</span>
<span class="p_header">+++ b/net/ipv6/netfilter/nf_conntrack_reasm.c</span>
<span class="p_chunk">@@ -589,6 +589,7 @@</span> <span class="p_context"> int nf_ct_frag6_gather(struct net *net, struct sk_buff *skb, u32 user)</span>
 	hdr = ipv6_hdr(skb);
 	fhdr = (struct frag_hdr *)skb_transport_header(skb);
 
<span class="p_add">+	skb_orphan(skb);</span>
 	fq = fq_find(net, fhdr-&gt;identification, user, &amp;hdr-&gt;saddr, &amp;hdr-&gt;daddr,
 		     skb-&gt;dev ? skb-&gt;dev-&gt;ifindex : 0, ip6_frag_ecn(hdr));
 	if (fq == NULL) {
<span class="p_header">diff --git a/net/ipv6/tcp_ipv6.c b/net/ipv6/tcp_ipv6.c</span>
<span class="p_header">index 4c60c6f71cd3..cfc232714139 100644</span>
<span class="p_header">--- a/net/ipv6/tcp_ipv6.c</span>
<span class="p_header">+++ b/net/ipv6/tcp_ipv6.c</span>
<span class="p_chunk">@@ -382,10 +382,12 @@</span> <span class="p_context"> static void tcp_v6_err(struct sk_buff *skb, struct inet6_skb_parm *opt,</span>
 	np = inet6_sk(sk);
 
 	if (type == NDISC_REDIRECT) {
<span class="p_del">-		struct dst_entry *dst = __sk_dst_check(sk, np-&gt;dst_cookie);</span>
<span class="p_add">+		if (!sock_owned_by_user(sk)) {</span>
<span class="p_add">+			struct dst_entry *dst = __sk_dst_check(sk, np-&gt;dst_cookie);</span>
 
<span class="p_del">-		if (dst)</span>
<span class="p_del">-			dst-&gt;ops-&gt;redirect(dst, sk, skb);</span>
<span class="p_add">+			if (dst)</span>
<span class="p_add">+				dst-&gt;ops-&gt;redirect(dst, sk, skb);</span>
<span class="p_add">+		}</span>
 		goto out;
 	}
 
<span class="p_header">diff --git a/net/l2tp/l2tp_ip.c b/net/l2tp/l2tp_ip.c</span>
<span class="p_header">index 28c21546d5b6..3ed30153a6f5 100644</span>
<span class="p_header">--- a/net/l2tp/l2tp_ip.c</span>
<span class="p_header">+++ b/net/l2tp/l2tp_ip.c</span>
<span class="p_chunk">@@ -381,7 +381,7 @@</span> <span class="p_context"> static int l2tp_ip_backlog_recv(struct sock *sk, struct sk_buff *skb)</span>
 drop:
 	IP_INC_STATS(sock_net(sk), IPSTATS_MIB_INDISCARDS);
 	kfree_skb(skb);
<span class="p_del">-	return -1;</span>
<span class="p_add">+	return 0;</span>
 }
 
 /* Userspace will call sendmsg() on the tunnel socket to send L2TP
<span class="p_header">diff --git a/net/mpls/af_mpls.c b/net/mpls/af_mpls.c</span>
<span class="p_header">index 5b77377e5a15..1309e2c34764 100644</span>
<span class="p_header">--- a/net/mpls/af_mpls.c</span>
<span class="p_header">+++ b/net/mpls/af_mpls.c</span>
<span class="p_chunk">@@ -956,7 +956,8 @@</span> <span class="p_context"> static void mpls_ifdown(struct net_device *dev, int event)</span>
 				/* fall through */
 			case NETDEV_CHANGE:
 				nh-&gt;nh_flags |= RTNH_F_LINKDOWN;
<span class="p_del">-				ACCESS_ONCE(rt-&gt;rt_nhn_alive) = rt-&gt;rt_nhn_alive - 1;</span>
<span class="p_add">+				if (event != NETDEV_UNREGISTER)</span>
<span class="p_add">+					ACCESS_ONCE(rt-&gt;rt_nhn_alive) = rt-&gt;rt_nhn_alive - 1;</span>
 				break;
 			}
 			if (event == NETDEV_UNREGISTER)
<span class="p_chunk">@@ -1696,6 +1697,7 @@</span> <span class="p_context"> static void mpls_net_exit(struct net *net)</span>
 	for (index = 0; index &lt; platform_labels; index++) {
 		struct mpls_route *rt = rtnl_dereference(platform_label[index]);
 		RCU_INIT_POINTER(platform_label[index], NULL);
<span class="p_add">+		mpls_notify_route(net, index, rt, NULL, NULL);</span>
 		mpls_rt_free(rt);
 	}
 	rtnl_unlock();
<span class="p_header">diff --git a/net/openvswitch/conntrack.c b/net/openvswitch/conntrack.c</span>
<span class="p_header">index 54253ea5976e..919d66e083d1 100644</span>
<span class="p_header">--- a/net/openvswitch/conntrack.c</span>
<span class="p_header">+++ b/net/openvswitch/conntrack.c</span>
<span class="p_chunk">@@ -367,7 +367,6 @@</span> <span class="p_context"> static int handle_fragments(struct net *net, struct sw_flow_key *key,</span>
 	} else if (key-&gt;eth.type == htons(ETH_P_IPV6)) {
 		enum ip6_defrag_users user = IP6_DEFRAG_CONNTRACK_IN + zone;
 
<span class="p_del">-		skb_orphan(skb);</span>
 		memset(IP6CB(skb), 0, sizeof(struct inet6_skb_parm));
 		err = nf_ct_frag6_gather(net, skb, user);
 		if (err) {
<span class="p_header">diff --git a/net/packet/af_packet.c b/net/packet/af_packet.c</span>
<span class="p_header">index 70f5b6a4683c..c59fcc79ba32 100644</span>
<span class="p_header">--- a/net/packet/af_packet.c</span>
<span class="p_header">+++ b/net/packet/af_packet.c</span>
<span class="p_chunk">@@ -3082,7 +3082,7 @@</span> <span class="p_context"> static int packet_bind_spkt(struct socket *sock, struct sockaddr *uaddr,</span>
 			    int addr_len)
 {
 	struct sock *sk = sock-&gt;sk;
<span class="p_del">-	char name[15];</span>
<span class="p_add">+	char name[sizeof(uaddr-&gt;sa_data) + 1];</span>
 
 	/*
 	 *	Check legality
<span class="p_chunk">@@ -3090,7 +3090,11 @@</span> <span class="p_context"> static int packet_bind_spkt(struct socket *sock, struct sockaddr *uaddr,</span>
 
 	if (addr_len != sizeof(struct sockaddr))
 		return -EINVAL;
<span class="p_del">-	strlcpy(name, uaddr-&gt;sa_data, sizeof(name));</span>
<span class="p_add">+	/* uaddr-&gt;sa_data comes from the userspace, it&#39;s not guaranteed to be</span>
<span class="p_add">+	 * zero-terminated.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	memcpy(name, uaddr-&gt;sa_data, sizeof(uaddr-&gt;sa_data));</span>
<span class="p_add">+	name[sizeof(uaddr-&gt;sa_data)] = 0;</span>
 
 	return packet_do_bind(sk, name, 0, pkt_sk(sk)-&gt;num);
 }
<span class="p_header">diff --git a/net/sched/act_api.c b/net/sched/act_api.c</span>
<span class="p_header">index e10456ef6f7a..9b29b6115384 100644</span>
<span class="p_header">--- a/net/sched/act_api.c</span>
<span class="p_header">+++ b/net/sched/act_api.c</span>
<span class="p_chunk">@@ -817,10 +817,8 @@</span> <span class="p_context"> static int tca_action_flush(struct net *net, struct nlattr *nla,</span>
 		goto out_module_put;
 
 	err = ops-&gt;walk(net, skb, &amp;dcb, RTM_DELACTION, ops);
<span class="p_del">-	if (err &lt; 0)</span>
<span class="p_add">+	if (err &lt;= 0)</span>
 		goto out_module_put;
<span class="p_del">-	if (err == 0)</span>
<span class="p_del">-		goto noflush_out;</span>
 
 	nla_nest_end(skb, nest);
 
<span class="p_chunk">@@ -837,7 +835,6 @@</span> <span class="p_context"> static int tca_action_flush(struct net *net, struct nlattr *nla,</span>
 out_module_put:
 	module_put(ops-&gt;owner);
 err_out:
<span class="p_del">-noflush_out:</span>
 	kfree_skb(skb);
 	return err;
 }
<span class="p_header">diff --git a/net/sched/act_connmark.c b/net/sched/act_connmark.c</span>
<span class="p_header">index ab8062909962..f9bb43c25697 100644</span>
<span class="p_header">--- a/net/sched/act_connmark.c</span>
<span class="p_header">+++ b/net/sched/act_connmark.c</span>
<span class="p_chunk">@@ -113,6 +113,9 @@</span> <span class="p_context"> static int tcf_connmark_init(struct net *net, struct nlattr *nla,</span>
 	if (ret &lt; 0)
 		return ret;
 
<span class="p_add">+	if (!tb[TCA_CONNMARK_PARMS])</span>
<span class="p_add">+		return -EINVAL;</span>
<span class="p_add">+</span>
 	parm = nla_data(tb[TCA_CONNMARK_PARMS]);
 
 	if (!tcf_hash_check(tn, parm-&gt;index, a, bind)) {
<span class="p_header">diff --git a/net/sched/act_skbmod.c b/net/sched/act_skbmod.c</span>
<span class="p_header">index 3b7074e23024..c736627f8f4a 100644</span>
<span class="p_header">--- a/net/sched/act_skbmod.c</span>
<span class="p_header">+++ b/net/sched/act_skbmod.c</span>
<span class="p_chunk">@@ -228,7 +228,6 @@</span> <span class="p_context"> static int tcf_skbmod_dump(struct sk_buff *skb, struct tc_action *a,</span>
 
 	return skb-&gt;len;
 nla_put_failure:
<span class="p_del">-	rcu_read_unlock();</span>
 	nlmsg_trim(skb, b);
 	return -1;
 }
<span class="p_header">diff --git a/net/sctp/protocol.c b/net/sctp/protocol.c</span>
<span class="p_header">index 616a9428e0c4..4ee4a33e34dc 100644</span>
<span class="p_header">--- a/net/sctp/protocol.c</span>
<span class="p_header">+++ b/net/sctp/protocol.c</span>
<span class="p_chunk">@@ -199,6 +199,7 @@</span> <span class="p_context"> int sctp_copy_local_addr_list(struct net *net, struct sctp_bind_addr *bp,</span>
 			      sctp_scope_t scope, gfp_t gfp, int copy_flags)
 {
 	struct sctp_sockaddr_entry *addr;
<span class="p_add">+	union sctp_addr laddr;</span>
 	int error = 0;
 
 	rcu_read_lock();
<span class="p_chunk">@@ -220,7 +221,10 @@</span> <span class="p_context"> int sctp_copy_local_addr_list(struct net *net, struct sctp_bind_addr *bp,</span>
 		     !(copy_flags &amp; SCTP_ADDR6_PEERSUPP)))
 			continue;
 
<span class="p_del">-		if (sctp_bind_addr_state(bp, &amp;addr-&gt;a) != -1)</span>
<span class="p_add">+		laddr = addr-&gt;a;</span>
<span class="p_add">+		/* also works for setting ipv6 address port */</span>
<span class="p_add">+		laddr.v4.sin_port = htons(bp-&gt;port);</span>
<span class="p_add">+		if (sctp_bind_addr_state(bp, &amp;laddr) != -1)</span>
 			continue;
 
 		error = sctp_add_bind_addr(bp, &amp;addr-&gt;a, sizeof(addr-&gt;a),
<span class="p_header">diff --git a/net/sctp/socket.c b/net/sctp/socket.c</span>
<span class="p_header">index 1b5d669e3029..d04a8b66098c 100644</span>
<span class="p_header">--- a/net/sctp/socket.c</span>
<span class="p_header">+++ b/net/sctp/socket.c</span>
<span class="p_chunk">@@ -4734,6 +4734,12 @@</span> <span class="p_context"> int sctp_do_peeloff(struct sock *sk, sctp_assoc_t id, struct socket **sockp)</span>
 	if (!asoc)
 		return -EINVAL;
 
<span class="p_add">+	/* If there is a thread waiting on more sndbuf space for</span>
<span class="p_add">+	 * sending on this asoc, it cannot be peeled.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	if (waitqueue_active(&amp;asoc-&gt;wait))</span>
<span class="p_add">+		return -EBUSY;</span>
<span class="p_add">+</span>
 	/* An association cannot be branched off from an already peeled-off
 	 * socket, nor is this supported for tcp style sockets.
 	 */
<span class="p_chunk">@@ -7426,8 +7432,6 @@</span> <span class="p_context"> static int sctp_wait_for_sndbuf(struct sctp_association *asoc, long *timeo_p,</span>
 		 */
 		release_sock(sk);
 		current_timeo = schedule_timeout(current_timeo);
<span class="p_del">-		if (sk != asoc-&gt;base.sk)</span>
<span class="p_del">-			goto do_error;</span>
 		lock_sock(sk);
 
 		*timeo_p = current_timeo;
<span class="p_header">diff --git a/net/strparser/strparser.c b/net/strparser/strparser.c</span>
<span class="p_header">index 41adf362936d..b5c279b22680 100644</span>
<span class="p_header">--- a/net/strparser/strparser.c</span>
<span class="p_header">+++ b/net/strparser/strparser.c</span>
<span class="p_chunk">@@ -504,6 +504,7 @@</span> <span class="p_context"> static int __init strp_mod_init(void)</span>
 
 static void __exit strp_mod_exit(void)
 {
<span class="p_add">+	destroy_workqueue(strp_wq);</span>
 }
 module_init(strp_mod_init);
 module_exit(strp_mod_exit);

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



