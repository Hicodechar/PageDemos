
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>[v3,3/6] mm/hugetlb: add size parameter to huge_pte_offset() - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    [v3,3/6] mm/hugetlb: add size parameter to huge_pte_offset()</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=58591">Punit Agrawal</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>May 22, 2017, 1:36 p.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;20170522133604.11392-4-punit.agrawal@arm.com&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/9740347/mbox/"
   >mbox</a>
|
   <a href="/patch/9740347/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/9740347/">/patch/9740347/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
	[172.30.200.125])
	by pdx-korg-patchwork.web.codeaurora.org (Postfix) with ESMTP id
	526086034C for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Mon, 22 May 2017 13:37:27 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 3E48026E51
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Mon, 22 May 2017 13:37:27 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id 3247028650; Mon, 22 May 2017 13:37:27 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-6.9 required=2.0 tests=BAYES_00,RCVD_IN_DNSWL_HI
	autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 6C8D926E51
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Mon, 22 May 2017 13:37:23 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S933714AbdEVNhI (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Mon, 22 May 2017 09:37:08 -0400
Received: from foss.arm.com ([217.140.101.70]:37338 &quot;EHLO foss.arm.com&quot;
	rhost-flags-OK-OK-OK-OK) by vger.kernel.org with ESMTP
	id S933695AbdEVNhE (ORCPT &lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Mon, 22 May 2017 09:37:04 -0400
Received: from usa-sjc-imap-foss1.foss.arm.com (unknown [10.72.51.249])
	by usa-sjc-mx-foss1.foss.arm.com (Postfix) with ESMTP id 8D3061435;
	Mon, 22 May 2017 06:37:03 -0700 (PDT)
Received: from localhost (e105922-lin.cambridge.arm.com [10.1.207.56])
	by usa-sjc-imap-foss1.foss.arm.com (Postfix) with ESMTPSA id
	5944E3F53D; Mon, 22 May 2017 06:37:03 -0700 (PDT)
From: Punit Agrawal &lt;punit.agrawal@arm.com&gt;
To: akpm@linux-foundation.org
Cc: Punit Agrawal &lt;punit.agrawal@arm.com&gt;, linux-mm@kvack.org,
	linux-kernel@vger.kernel.org, linux-arm-kernel@lists.infradead.org,
	catalin.marinas@arm.com, will.deacon@arm.com,
	n-horiguchi@ah.jp.nec.com, kirill.shutemov@linux.intel.com,
	mike.kravetz@oracle.com, steve.capper@arm.com,
	mark.rutland@arm.com, hillf.zj@alibaba-inc.com,
	linux-arch@vger.kernel.org, aneesh.kumar@linux.vnet.ibm.com,
	Tony Luck &lt;tony.luck@intel.com&gt;, Fenghua Yu &lt;fenghua.yu@intel.com&gt;,
	James Hogan &lt;james.hogan@imgtec.com&gt;, Ralf Baechle &lt;ralf@linux-mips.org&gt;,
	&quot;James E.J. Bottomley&quot; &lt;jejb@parisc-linux.org&gt;,
	Helge Deller &lt;deller@gmx.de&gt;,
	Benjamin Herrenschmidt &lt;benh@kernel.crashing.org&gt;,
	Paul Mackerras &lt;paulus@samba.org&gt;, Michael Ellerman &lt;mpe@ellerman.id.au&gt;,
	Martin Schwidefsky &lt;schwidefsky@de.ibm.com&gt;,
	Heiko Carstens &lt;heiko.carstens@de.ibm.com&gt;,
	Yoshinori Sato &lt;ysato@users.sourceforge.jp&gt;,
	Rich Felker &lt;dalias@libc.org&gt;, &quot;David S. Miller&quot; &lt;davem@davemloft.net&gt;,
	Chris Metcalf &lt;cmetcalf@mellanox.com&gt;,
	Thomas Gleixner &lt;tglx@linutronix.de&gt;, Ingo Molnar &lt;mingo@redhat.com&gt;,
	&quot;H. Peter Anvin&quot; &lt;hpa@zytor.com&gt;,
	Alexander Viro &lt;viro@zeniv.linux.org.uk&gt;, Michal Hocko &lt;mhocko@suse.com&gt;
Subject: [PATCH v3 3/6] mm/hugetlb: add size parameter to huge_pte_offset()
Date: Mon, 22 May 2017 14:36:01 +0100
Message-Id: &lt;20170522133604.11392-4-punit.agrawal@arm.com&gt;
X-Mailer: git-send-email 2.11.0
In-Reply-To: &lt;20170522133604.11392-1-punit.agrawal@arm.com&gt;
References: &lt;20170522133604.11392-1-punit.agrawal@arm.com&gt;
X-ARM-No-Footer: FoSSMail
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=58591">Punit Agrawal</a> - May 22, 2017, 1:36 p.m.</div>
<pre class="content">
A poisoned or migrated hugepage is stored as a swap entry in the page
tables. On architectures that support hugepages consisting of contiguous
page table entries (such as on arm64) this leads to ambiguity in
determining the page table entry to return in huge_pte_offset() when a
poisoned entry is encountered.

Let&#39;s remove the ambiguity by adding a size parameter to convey
additional information about the requested address. Also fixup the
definition/usage of huge_pte_offset() throughout the tree.
<span class="signed-off-by">
Signed-off-by: Punit Agrawal &lt;punit.agrawal@arm.com&gt;</span>
<span class="acked-by">Acked-by: Steve Capper &lt;steve.capper@arm.com&gt;</span>
Cc: Catalin Marinas &lt;catalin.marinas@arm.com&gt;
Cc: Will Deacon &lt;will.deacon@arm.com&gt;
Cc: Tony Luck &lt;tony.luck@intel.com&gt;
Cc: Fenghua Yu &lt;fenghua.yu@intel.com&gt;
Cc: James Hogan &lt;james.hogan@imgtec.com&gt; (odd fixer:METAG ARCHITECTURE)
Cc: Ralf Baechle &lt;ralf@linux-mips.org&gt; (supporter:MIPS)
Cc: &quot;James E.J. Bottomley&quot; &lt;jejb@parisc-linux.org&gt;
Cc: Helge Deller &lt;deller@gmx.de&gt;
Cc: Benjamin Herrenschmidt &lt;benh@kernel.crashing.org&gt;
Cc: Paul Mackerras &lt;paulus@samba.org&gt;
Cc: Michael Ellerman &lt;mpe@ellerman.id.au&gt;
Cc: Martin Schwidefsky &lt;schwidefsky@de.ibm.com&gt;
Cc: Heiko Carstens &lt;heiko.carstens@de.ibm.com&gt;
Cc: Yoshinori Sato &lt;ysato@users.sourceforge.jp&gt;
Cc: Rich Felker &lt;dalias@libc.org&gt;
Cc: &quot;David S. Miller&quot; &lt;davem@davemloft.net&gt;
Cc: Chris Metcalf &lt;cmetcalf@mellanox.com&gt;
Cc: Thomas Gleixner &lt;tglx@linutronix.de&gt;
Cc: Ingo Molnar &lt;mingo@redhat.com&gt;
Cc: &quot;H. Peter Anvin&quot; &lt;hpa@zytor.com&gt;
Cc: Alexander Viro &lt;viro@zeniv.linux.org.uk&gt;
Cc: Andrew Morton &lt;akpm@linux-foundation.org&gt;
Cc: Michal Hocko &lt;mhocko@suse.com&gt;
Cc: Mike Kravetz &lt;mike.kravetz@oracle.com&gt;
Cc: Naoya Horiguchi &lt;n-horiguchi@ah.jp.nec.com&gt;
Cc: &quot;Aneesh Kumar K.V&quot; &lt;aneesh.kumar@linux.vnet.ibm.com&gt;
Cc: &quot;Kirill A. Shutemov&quot; &lt;kirill.shutemov@linux.intel.com&gt;
Cc: Hillf Danton &lt;hillf.zj@alibaba-inc.com&gt;
---
 arch/arm64/mm/hugetlbpage.c   |  3 ++-
 arch/ia64/mm/hugetlbpage.c    |  4 ++--
 arch/metag/mm/hugetlbpage.c   |  3 ++-
 arch/mips/mm/hugetlbpage.c    |  3 ++-
 arch/parisc/mm/hugetlbpage.c  |  3 ++-
 arch/powerpc/mm/hugetlbpage.c |  2 +-
 arch/s390/mm/hugetlbpage.c    |  3 ++-
 arch/sh/mm/hugetlbpage.c      |  3 ++-
 arch/sparc/mm/hugetlbpage.c   |  3 ++-
 arch/tile/mm/hugetlbpage.c    |  3 ++-
 arch/x86/mm/hugetlbpage.c     |  2 +-
 fs/userfaultfd.c              |  7 +++++--
 include/linux/hugetlb.h       |  5 +++--
 mm/hugetlb.c                  | 23 ++++++++++++++---------
 mm/page_vma_mapped.c          |  3 ++-
 mm/pagewalk.c                 |  3 ++-
 16 files changed, 46 insertions(+), 27 deletions(-)
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=143191">kbuild test robot</a> - May 23, 2017, 10:04 a.m.</div>
<pre class="content">
Hi Punit,

[auto build test ERROR on linus/master]
[also build test ERROR on v4.12-rc2 next-20170523]
[cannot apply to mmotm/master]
[if your patch is applied to the wrong git tree, please drop us a note to help improve the system]

url:    https://github.com/0day-ci/linux/commits/Punit-Agrawal/Support-for-contiguous-pte-hugepages/20170523-142407
config: arm64-defconfig (attached as .config)
compiler: aarch64-linux-gnu-gcc (Debian 6.1.1-9) 6.1.1 20160705
reproduce:
        wget https://raw.githubusercontent.com/01org/lkp-tests/master/sbin/make.cross -O ~/bin/make.cross
        chmod +x ~/bin/make.cross
        # save the attached .config to linux build tree
        make.cross ARCH=arm64 

All errors (new ones prefixed by &gt;&gt;):

   arch/arm64/mm/hugetlbpage.c: In function &#39;huge_ptep_get_and_clear&#39;:
<span class="quote">&gt;&gt; arch/arm64/mm/hugetlbpage.c:200:10: error: too few arguments to function &#39;huge_pte_offset&#39;</span>
      cpte = huge_pte_offset(mm, addr);
             ^~~~~~~~~~~~~~~
   arch/arm64/mm/hugetlbpage.c:135:8: note: declared here
    pte_t *huge_pte_offset(struct mm_struct *mm,
           ^~~~~~~~~~~~~~~
   arch/arm64/mm/hugetlbpage.c: In function &#39;huge_ptep_set_access_flags&#39;:
   arch/arm64/mm/hugetlbpage.c:238:10: error: too few arguments to function &#39;huge_pte_offset&#39;
      cpte = huge_pte_offset(vma-&gt;vm_mm, addr);
             ^~~~~~~~~~~~~~~
   arch/arm64/mm/hugetlbpage.c:135:8: note: declared here
    pte_t *huge_pte_offset(struct mm_struct *mm,
           ^~~~~~~~~~~~~~~
   arch/arm64/mm/hugetlbpage.c: In function &#39;huge_ptep_set_wrprotect&#39;:
   arch/arm64/mm/hugetlbpage.c:263:10: error: too few arguments to function &#39;huge_pte_offset&#39;
      cpte = huge_pte_offset(mm, addr);
             ^~~~~~~~~~~~~~~
   arch/arm64/mm/hugetlbpage.c:135:8: note: declared here
    pte_t *huge_pte_offset(struct mm_struct *mm,
           ^~~~~~~~~~~~~~~
   arch/arm64/mm/hugetlbpage.c: In function &#39;huge_ptep_clear_flush&#39;:
   arch/arm64/mm/hugetlbpage.c:280:10: error: too few arguments to function &#39;huge_pte_offset&#39;
      cpte = huge_pte_offset(vma-&gt;vm_mm, addr);
             ^~~~~~~~~~~~~~~
   arch/arm64/mm/hugetlbpage.c:135:8: note: declared here
    pte_t *huge_pte_offset(struct mm_struct *mm,
           ^~~~~~~~~~~~~~~

vim +/huge_pte_offset +200 arch/arm64/mm/hugetlbpage.c

66b3923a David Woods 2015-12-17  194  	if (pte_cont(*ptep)) {
66b3923a David Woods 2015-12-17  195  		int ncontig, i;
66b3923a David Woods 2015-12-17  196  		size_t pgsize;
66b3923a David Woods 2015-12-17  197  		pte_t *cpte;
66b3923a David Woods 2015-12-17  198  		bool is_dirty = false;
66b3923a David Woods 2015-12-17  199  
66b3923a David Woods 2015-12-17 @200  		cpte = huge_pte_offset(mm, addr);
66b3923a David Woods 2015-12-17  201  		ncontig = find_num_contig(mm, addr, cpte, *cpte, &amp;pgsize);
66b3923a David Woods 2015-12-17  202  		/* save the 1st pte to return */
66b3923a David Woods 2015-12-17  203  		pte = ptep_get_and_clear(mm, addr, cpte);

:::::: The code at line 200 was first introduced by commit
:::::: 66b3923a1a0f77a563b43f43f6ad091354abbfe9 arm64: hugetlb: add support for PTE contiguous bit

:::::: TO: David Woods &lt;dwoods@ezchip.com&gt;
:::::: CC: Will Deacon &lt;will.deacon@arm.com&gt;

---
0-DAY kernel test infrastructure                Open Source Technology Center
https://lists.01.org/pipermail/kbuild-all                   Intel Corporation
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/arch/arm64/mm/hugetlbpage.c b/arch/arm64/mm/hugetlbpage.c</span>
<span class="p_header">index 69b8200b1cfd..425a8fcd3d38 100644</span>
<span class="p_header">--- a/arch/arm64/mm/hugetlbpage.c</span>
<span class="p_header">+++ b/arch/arm64/mm/hugetlbpage.c</span>
<span class="p_chunk">@@ -132,7 +132,8 @@</span> <span class="p_context"> pte_t *huge_pte_alloc(struct mm_struct *mm,</span>
 	return pte;
 }
 
<span class="p_del">-pte_t *huge_pte_offset(struct mm_struct *mm, unsigned long addr)</span>
<span class="p_add">+pte_t *huge_pte_offset(struct mm_struct *mm,</span>
<span class="p_add">+		       unsigned long addr, unsigned long sz)</span>
 {
 	pgd_t *pgd;
 	pud_t *pud;
<span class="p_header">diff --git a/arch/ia64/mm/hugetlbpage.c b/arch/ia64/mm/hugetlbpage.c</span>
<span class="p_header">index 85de86d36fdf..ae35140332f7 100644</span>
<span class="p_header">--- a/arch/ia64/mm/hugetlbpage.c</span>
<span class="p_header">+++ b/arch/ia64/mm/hugetlbpage.c</span>
<span class="p_chunk">@@ -44,7 +44,7 @@</span> <span class="p_context"> huge_pte_alloc(struct mm_struct *mm, unsigned long addr, unsigned long sz)</span>
 }
 
 pte_t *
<span class="p_del">-huge_pte_offset (struct mm_struct *mm, unsigned long addr)</span>
<span class="p_add">+huge_pte_offset (struct mm_struct *mm, unsigned long addr, unsigned long sz)</span>
 {
 	unsigned long taddr = htlbpage_to_page(addr);
 	pgd_t *pgd;
<span class="p_chunk">@@ -92,7 +92,7 @@</span> <span class="p_context"> struct page *follow_huge_addr(struct mm_struct *mm, unsigned long addr, int writ</span>
 	if (REGION_NUMBER(addr) != RGN_HPAGE)
 		return ERR_PTR(-EINVAL);
 
<span class="p_del">-	ptep = huge_pte_offset(mm, addr);</span>
<span class="p_add">+	ptep = huge_pte_offset(mm, addr, HPAGE_SIZE);</span>
 	if (!ptep || pte_none(*ptep))
 		return NULL;
 	page = pte_page(*ptep);
<span class="p_header">diff --git a/arch/metag/mm/hugetlbpage.c b/arch/metag/mm/hugetlbpage.c</span>
<span class="p_header">index db1b7da91e4f..67fd53e2935a 100644</span>
<span class="p_header">--- a/arch/metag/mm/hugetlbpage.c</span>
<span class="p_header">+++ b/arch/metag/mm/hugetlbpage.c</span>
<span class="p_chunk">@@ -74,7 +74,8 @@</span> <span class="p_context"> pte_t *huge_pte_alloc(struct mm_struct *mm,</span>
 	return pte;
 }
 
<span class="p_del">-pte_t *huge_pte_offset(struct mm_struct *mm, unsigned long addr)</span>
<span class="p_add">+pte_t *huge_pte_offset(struct mm_struct *mm,</span>
<span class="p_add">+		       unsigned long addr, unsigned long sz)</span>
 {
 	pgd_t *pgd;
 	pud_t *pud;
<span class="p_header">diff --git a/arch/mips/mm/hugetlbpage.c b/arch/mips/mm/hugetlbpage.c</span>
<span class="p_header">index 74aa6f62468f..cef152234312 100644</span>
<span class="p_header">--- a/arch/mips/mm/hugetlbpage.c</span>
<span class="p_header">+++ b/arch/mips/mm/hugetlbpage.c</span>
<span class="p_chunk">@@ -36,7 +36,8 @@</span> <span class="p_context"> pte_t *huge_pte_alloc(struct mm_struct *mm, unsigned long addr,</span>
 	return pte;
 }
 
<span class="p_del">-pte_t *huge_pte_offset(struct mm_struct *mm, unsigned long addr)</span>
<span class="p_add">+pte_t *huge_pte_offset(struct mm_struct *mm, unsigned long addr,</span>
<span class="p_add">+		       unsigned long sz)</span>
 {
 	pgd_t *pgd;
 	pud_t *pud;
<span class="p_header">diff --git a/arch/parisc/mm/hugetlbpage.c b/arch/parisc/mm/hugetlbpage.c</span>
<span class="p_header">index aa50ac090e9b..5eb8f633b282 100644</span>
<span class="p_header">--- a/arch/parisc/mm/hugetlbpage.c</span>
<span class="p_header">+++ b/arch/parisc/mm/hugetlbpage.c</span>
<span class="p_chunk">@@ -69,7 +69,8 @@</span> <span class="p_context"> pte_t *huge_pte_alloc(struct mm_struct *mm,</span>
 	return pte;
 }
 
<span class="p_del">-pte_t *huge_pte_offset(struct mm_struct *mm, unsigned long addr)</span>
<span class="p_add">+pte_t *huge_pte_offset(struct mm_struct *mm,</span>
<span class="p_add">+		       unsigned long addr, unsigned long sz)</span>
 {
 	pgd_t *pgd;
 	pud_t *pud;
<span class="p_header">diff --git a/arch/powerpc/mm/hugetlbpage.c b/arch/powerpc/mm/hugetlbpage.c</span>
<span class="p_header">index a4f33de4008e..e46744d3b4ae 100644</span>
<span class="p_header">--- a/arch/powerpc/mm/hugetlbpage.c</span>
<span class="p_header">+++ b/arch/powerpc/mm/hugetlbpage.c</span>
<span class="p_chunk">@@ -55,7 +55,7 @@</span> <span class="p_context"> static unsigned nr_gpages;</span>
 
 #define hugepd_none(hpd)	(hpd_val(hpd) == 0)
 
<span class="p_del">-pte_t *huge_pte_offset(struct mm_struct *mm, unsigned long addr)</span>
<span class="p_add">+pte_t *huge_pte_offset(struct mm_struct *mm, unsigned long addr, unsigned long sz)</span>
 {
 	/* Only called for hugetlbfs pages, hence can ignore THP */
 	return __find_linux_pte_or_hugepte(mm-&gt;pgd, addr, NULL, NULL);
<span class="p_header">diff --git a/arch/s390/mm/hugetlbpage.c b/arch/s390/mm/hugetlbpage.c</span>
<span class="p_header">index 9b4050caa4e9..ae23afc18493 100644</span>
<span class="p_header">--- a/arch/s390/mm/hugetlbpage.c</span>
<span class="p_header">+++ b/arch/s390/mm/hugetlbpage.c</span>
<span class="p_chunk">@@ -176,7 +176,8 @@</span> <span class="p_context"> pte_t *huge_pte_alloc(struct mm_struct *mm,</span>
 	return (pte_t *) pmdp;
 }
 
<span class="p_del">-pte_t *huge_pte_offset(struct mm_struct *mm, unsigned long addr)</span>
<span class="p_add">+pte_t *huge_pte_offset(struct mm_struct *mm,</span>
<span class="p_add">+		       unsigned long addr, unsigned long sz)</span>
 {
 	pgd_t *pgdp;
 	pud_t *pudp;
<span class="p_header">diff --git a/arch/sh/mm/hugetlbpage.c b/arch/sh/mm/hugetlbpage.c</span>
<span class="p_header">index cc948db74878..d2412d2d6462 100644</span>
<span class="p_header">--- a/arch/sh/mm/hugetlbpage.c</span>
<span class="p_header">+++ b/arch/sh/mm/hugetlbpage.c</span>
<span class="p_chunk">@@ -42,7 +42,8 @@</span> <span class="p_context"> pte_t *huge_pte_alloc(struct mm_struct *mm,</span>
 	return pte;
 }
 
<span class="p_del">-pte_t *huge_pte_offset(struct mm_struct *mm, unsigned long addr)</span>
<span class="p_add">+pte_t *huge_pte_offset(struct mm_struct *mm,</span>
<span class="p_add">+		       unsigned long addr, unsigned long sz)</span>
 {
 	pgd_t *pgd;
 	pud_t *pud;
<span class="p_header">diff --git a/arch/sparc/mm/hugetlbpage.c b/arch/sparc/mm/hugetlbpage.c</span>
<span class="p_header">index 7c29d38e6b99..8989c5e155b3 100644</span>
<span class="p_header">--- a/arch/sparc/mm/hugetlbpage.c</span>
<span class="p_header">+++ b/arch/sparc/mm/hugetlbpage.c</span>
<span class="p_chunk">@@ -277,7 +277,8 @@</span> <span class="p_context"> pte_t *huge_pte_alloc(struct mm_struct *mm,</span>
 	return pte;
 }
 
<span class="p_del">-pte_t *huge_pte_offset(struct mm_struct *mm, unsigned long addr)</span>
<span class="p_add">+pte_t *huge_pte_offset(struct mm_struct *mm,</span>
<span class="p_add">+		       unsigned long addr, unsigned long sz)</span>
 {
 	pgd_t *pgd;
 	pud_t *pud;
<span class="p_header">diff --git a/arch/tile/mm/hugetlbpage.c b/arch/tile/mm/hugetlbpage.c</span>
<span class="p_header">index cb10153b5c9f..1f0993945521 100644</span>
<span class="p_header">--- a/arch/tile/mm/hugetlbpage.c</span>
<span class="p_header">+++ b/arch/tile/mm/hugetlbpage.c</span>
<span class="p_chunk">@@ -102,7 +102,8 @@</span> <span class="p_context"> static pte_t *get_pte(pte_t *base, int index, int level)</span>
 	return ptep;
 }
 
<span class="p_del">-pte_t *huge_pte_offset(struct mm_struct *mm, unsigned long addr)</span>
<span class="p_add">+pte_t *huge_pte_offset(struct mm_struct *mm,</span>
<span class="p_add">+		       unsigned long addr, unsigned long sz)</span>
 {
 	pgd_t *pgd;
 	pud_t *pud;
<span class="p_header">diff --git a/arch/x86/mm/hugetlbpage.c b/arch/x86/mm/hugetlbpage.c</span>
<span class="p_header">index 302f43fd9c28..ccf509063dfd 100644</span>
<span class="p_header">--- a/arch/x86/mm/hugetlbpage.c</span>
<span class="p_header">+++ b/arch/x86/mm/hugetlbpage.c</span>
<span class="p_chunk">@@ -33,7 +33,7 @@</span> <span class="p_context"> follow_huge_addr(struct mm_struct *mm, unsigned long address, int write)</span>
 	if (!vma || !is_vm_hugetlb_page(vma))
 		return ERR_PTR(-EINVAL);
 
<span class="p_del">-	pte = huge_pte_offset(mm, address);</span>
<span class="p_add">+	pte = huge_pte_offset(mm, address, vma_mmu_pagesize(vma));</span>
 
 	/* hugetlb should be locked, and hence, prefaulted */
 	WARN_ON(!pte || pte_none(*pte));
<span class="p_header">diff --git a/fs/userfaultfd.c b/fs/userfaultfd.c</span>
<span class="p_header">index f7555fc25877..7b9c94837895 100644</span>
<span class="p_header">--- a/fs/userfaultfd.c</span>
<span class="p_header">+++ b/fs/userfaultfd.c</span>
<span class="p_chunk">@@ -214,6 +214,7 @@</span> <span class="p_context"> static inline struct uffd_msg userfault_msg(unsigned long address,</span>
  * hugepmd ranges.
  */
 static inline bool userfaultfd_huge_must_wait(struct userfaultfd_ctx *ctx,
<span class="p_add">+					 struct vm_area_struct *vma,</span>
 					 unsigned long address,
 					 unsigned long flags,
 					 unsigned long reason)
<span class="p_chunk">@@ -224,7 +225,7 @@</span> <span class="p_context"> static inline bool userfaultfd_huge_must_wait(struct userfaultfd_ctx *ctx,</span>
 
 	VM_BUG_ON(!rwsem_is_locked(&amp;mm-&gt;mmap_sem));
 
<span class="p_del">-	pte = huge_pte_offset(mm, address);</span>
<span class="p_add">+	pte = huge_pte_offset(mm, address, vma_mmu_pagesize(vma));</span>
 	if (!pte)
 		goto out;
 
<span class="p_chunk">@@ -243,6 +244,7 @@</span> <span class="p_context"> static inline bool userfaultfd_huge_must_wait(struct userfaultfd_ctx *ctx,</span>
 }
 #else
 static inline bool userfaultfd_huge_must_wait(struct userfaultfd_ctx *ctx,
<span class="p_add">+					 struct vm_area_struct *vma,</span>
 					 unsigned long address,
 					 unsigned long flags,
 					 unsigned long reason)
<span class="p_chunk">@@ -435,7 +437,8 @@</span> <span class="p_context"> int handle_userfault(struct vm_fault *vmf, unsigned long reason)</span>
 		must_wait = userfaultfd_must_wait(ctx, vmf-&gt;address, vmf-&gt;flags,
 						  reason);
 	else
<span class="p_del">-		must_wait = userfaultfd_huge_must_wait(ctx, vmf-&gt;address,</span>
<span class="p_add">+		must_wait = userfaultfd_huge_must_wait(ctx, vmf-&gt;vma,</span>
<span class="p_add">+						       vmf-&gt;address,</span>
 						       vmf-&gt;flags, reason);
 	up_read(&amp;mm-&gt;mmap_sem);
 
<span class="p_header">diff --git a/include/linux/hugetlb.h b/include/linux/hugetlb.h</span>
<span class="p_header">index b857fc8cc2ec..23010a3b2047 100644</span>
<span class="p_header">--- a/include/linux/hugetlb.h</span>
<span class="p_header">+++ b/include/linux/hugetlb.h</span>
<span class="p_chunk">@@ -113,7 +113,8 @@</span> <span class="p_context"> extern struct list_head huge_boot_pages;</span>
 
 pte_t *huge_pte_alloc(struct mm_struct *mm,
 			unsigned long addr, unsigned long sz);
<span class="p_del">-pte_t *huge_pte_offset(struct mm_struct *mm, unsigned long addr);</span>
<span class="p_add">+pte_t *huge_pte_offset(struct mm_struct *mm,</span>
<span class="p_add">+		       unsigned long addr, unsigned long sz);</span>
 int huge_pmd_unshare(struct mm_struct *mm, unsigned long *addr, pte_t *ptep);
 struct page *follow_huge_addr(struct mm_struct *mm, unsigned long address,
 			      int write);
<span class="p_chunk">@@ -157,7 +158,7 @@</span> <span class="p_context"> static inline void hugetlb_show_meminfo(void)</span>
 #define hugetlb_fault(mm, vma, addr, flags)	({ BUG(); 0; })
 #define hugetlb_mcopy_atomic_pte(dst_mm, dst_pte, dst_vma, dst_addr, \
 				src_addr, pagep)	({ BUG(); 0; })
<span class="p_del">-#define huge_pte_offset(mm, address)	0</span>
<span class="p_add">+#define huge_pte_offset(mm, address, sz)	0</span>
 static inline int dequeue_hwpoisoned_huge_page(struct page *page)
 {
 	return 0;
<span class="p_header">diff --git a/mm/hugetlb.c b/mm/hugetlb.c</span>
<span class="p_header">index e5828875f7bb..0e4d1fb3122f 100644</span>
<span class="p_header">--- a/mm/hugetlb.c</span>
<span class="p_header">+++ b/mm/hugetlb.c</span>
<span class="p_chunk">@@ -3233,7 +3233,7 @@</span> <span class="p_context"> int copy_hugetlb_page_range(struct mm_struct *dst, struct mm_struct *src,</span>
 
 	for (addr = vma-&gt;vm_start; addr &lt; vma-&gt;vm_end; addr += sz) {
 		spinlock_t *src_ptl, *dst_ptl;
<span class="p_del">-		src_pte = huge_pte_offset(src, addr);</span>
<span class="p_add">+		src_pte = huge_pte_offset(src, addr, sz);</span>
 		if (!src_pte)
 			continue;
 		dst_pte = huge_pte_alloc(dst, addr, sz);
<span class="p_chunk">@@ -3317,7 +3317,7 @@</span> <span class="p_context"> void __unmap_hugepage_range(struct mmu_gather *tlb, struct vm_area_struct *vma,</span>
 	mmu_notifier_invalidate_range_start(mm, mmun_start, mmun_end);
 	address = start;
 	for (; address &lt; end; address += sz) {
<span class="p_del">-		ptep = huge_pte_offset(mm, address);</span>
<span class="p_add">+		ptep = huge_pte_offset(mm, address, sz);</span>
 		if (!ptep)
 			continue;
 
<span class="p_chunk">@@ -3535,7 +3535,8 @@</span> <span class="p_context"> static int hugetlb_cow(struct mm_struct *mm, struct vm_area_struct *vma,</span>
 			unmap_ref_private(mm, vma, old_page, address);
 			BUG_ON(huge_pte_none(pte));
 			spin_lock(ptl);
<span class="p_del">-			ptep = huge_pte_offset(mm, address &amp; huge_page_mask(h));</span>
<span class="p_add">+			ptep = huge_pte_offset(mm, address &amp; huge_page_mask(h),</span>
<span class="p_add">+					       huge_page_size(h));</span>
 			if (likely(ptep &amp;&amp;
 				   pte_same(huge_ptep_get(ptep), pte)))
 				goto retry_avoidcopy;
<span class="p_chunk">@@ -3574,7 +3575,8 @@</span> <span class="p_context"> static int hugetlb_cow(struct mm_struct *mm, struct vm_area_struct *vma,</span>
 	 * before the page tables are altered
 	 */
 	spin_lock(ptl);
<span class="p_del">-	ptep = huge_pte_offset(mm, address &amp; huge_page_mask(h));</span>
<span class="p_add">+	ptep = huge_pte_offset(mm, address &amp; huge_page_mask(h),</span>
<span class="p_add">+			       huge_page_size(h));</span>
 	if (likely(ptep &amp;&amp; pte_same(huge_ptep_get(ptep), pte))) {
 		ClearPagePrivate(new_page);
 
<span class="p_chunk">@@ -3861,7 +3863,7 @@</span> <span class="p_context"> int hugetlb_fault(struct mm_struct *mm, struct vm_area_struct *vma,</span>
 
 	address &amp;= huge_page_mask(h);
 
<span class="p_del">-	ptep = huge_pte_offset(mm, address);</span>
<span class="p_add">+	ptep = huge_pte_offset(mm, address, huge_page_size(h));</span>
 	if (ptep) {
 		entry = huge_ptep_get(ptep);
 		if (unlikely(is_hugetlb_entry_migration(entry))) {
<span class="p_chunk">@@ -4118,7 +4120,8 @@</span> <span class="p_context"> long follow_hugetlb_page(struct mm_struct *mm, struct vm_area_struct *vma,</span>
 		 *
 		 * Note that page table lock is not held when pte is null.
 		 */
<span class="p_del">-		pte = huge_pte_offset(mm, vaddr &amp; huge_page_mask(h));</span>
<span class="p_add">+		pte = huge_pte_offset(mm, vaddr &amp; huge_page_mask(h),</span>
<span class="p_add">+				      huge_page_size(h));</span>
 		if (pte)
 			ptl = huge_pte_lock(h, mm, pte);
 		absent = !pte || huge_pte_none(huge_ptep_get(pte));
<span class="p_chunk">@@ -4252,7 +4255,7 @@</span> <span class="p_context"> unsigned long hugetlb_change_protection(struct vm_area_struct *vma,</span>
 	i_mmap_lock_write(vma-&gt;vm_file-&gt;f_mapping);
 	for (; address &lt; end; address += huge_page_size(h)) {
 		spinlock_t *ptl;
<span class="p_del">-		ptep = huge_pte_offset(mm, address);</span>
<span class="p_add">+		ptep = huge_pte_offset(mm, address, huge_page_size(h));</span>
 		if (!ptep)
 			continue;
 		ptl = huge_pte_lock(h, mm, ptep);
<span class="p_chunk">@@ -4516,7 +4519,8 @@</span> <span class="p_context"> pte_t *huge_pmd_share(struct mm_struct *mm, unsigned long addr, pud_t *pud)</span>
 
 		saddr = page_table_shareable(svma, vma, addr, idx);
 		if (saddr) {
<span class="p_del">-			spte = huge_pte_offset(svma-&gt;vm_mm, saddr);</span>
<span class="p_add">+			spte = huge_pte_offset(svma-&gt;vm_mm, saddr,</span>
<span class="p_add">+					       vma_mmu_pagesize(svma));</span>
 			if (spte) {
 				get_page(virt_to_page(spte));
 				break;
<span class="p_chunk">@@ -4612,7 +4616,8 @@</span> <span class="p_context"> pte_t *huge_pte_alloc(struct mm_struct *mm,</span>
 	return pte;
 }
 
<span class="p_del">-pte_t *huge_pte_offset(struct mm_struct *mm, unsigned long addr)</span>
<span class="p_add">+pte_t *huge_pte_offset(struct mm_struct *mm,</span>
<span class="p_add">+		       unsigned long addr, unsigned long sz)</span>
 {
 	pgd_t *pgd;
 	p4d_t *p4d;
<span class="p_header">diff --git a/mm/page_vma_mapped.c b/mm/page_vma_mapped.c</span>
<span class="p_header">index de9c40d7304a..8ec6ba230bb9 100644</span>
<span class="p_header">--- a/mm/page_vma_mapped.c</span>
<span class="p_header">+++ b/mm/page_vma_mapped.c</span>
<span class="p_chunk">@@ -116,7 +116,8 @@</span> <span class="p_context"> bool page_vma_mapped_walk(struct page_vma_mapped_walk *pvmw)</span>
 
 	if (unlikely(PageHuge(pvmw-&gt;page))) {
 		/* when pud is not present, pte will be NULL */
<span class="p_del">-		pvmw-&gt;pte = huge_pte_offset(mm, pvmw-&gt;address);</span>
<span class="p_add">+		pvmw-&gt;pte = huge_pte_offset(mm, pvmw-&gt;address,</span>
<span class="p_add">+					    PAGE_SIZE &lt;&lt; compound_order(page));</span>
 		if (!pvmw-&gt;pte)
 			return false;
 
<span class="p_header">diff --git a/mm/pagewalk.c b/mm/pagewalk.c</span>
<span class="p_header">index 60f7856e508f..1a4197965415 100644</span>
<span class="p_header">--- a/mm/pagewalk.c</span>
<span class="p_header">+++ b/mm/pagewalk.c</span>
<span class="p_chunk">@@ -180,12 +180,13 @@</span> <span class="p_context"> static int walk_hugetlb_range(unsigned long addr, unsigned long end,</span>
 	struct hstate *h = hstate_vma(vma);
 	unsigned long next;
 	unsigned long hmask = huge_page_mask(h);
<span class="p_add">+	unsigned long sz = huge_page_size(h);</span>
 	pte_t *pte;
 	int err = 0;
 
 	do {
 		next = hugetlb_entry_end(h, addr, end);
<span class="p_del">-		pte = huge_pte_offset(walk-&gt;mm, addr &amp; hmask);</span>
<span class="p_add">+		pte = huge_pte_offset(walk-&gt;mm, addr &amp; hmask, sz);</span>
 		if (pte &amp;&amp; walk-&gt;hugetlb_entry)
 			err = walk-&gt;hugetlb_entry(pte, hmask, addr, next, walk);
 		if (err)

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



