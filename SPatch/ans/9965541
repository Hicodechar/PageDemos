
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>mm: Account pud page tables - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    mm: Account pud page tables</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=40781">Kirill A. Shutemov</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>Sept. 22, 2017, 8:41 a.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;20170922084146.39974-1-kirill.shutemov@linux.intel.com&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/9965541/mbox/"
   >mbox</a>
|
   <a href="/patch/9965541/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/9965541/">/patch/9965541/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
	[172.30.200.125])
	by pdx-korg-patchwork.web.codeaurora.org (Postfix) with ESMTP id
	208066020C for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Fri, 22 Sep 2017 08:42:00 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 0BD6928975
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Fri, 22 Sep 2017 08:42:00 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id F1D4C292DD; Fri, 22 Sep 2017 08:41:59 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-6.9 required=2.0 tests=BAYES_00,RCVD_IN_DNSWL_HI
	autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id EF74828975
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Fri, 22 Sep 2017 08:41:58 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1751929AbdIVIl4 (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Fri, 22 Sep 2017 04:41:56 -0400
Received: from mga03.intel.com ([134.134.136.65]:50570 &quot;EHLO mga03.intel.com&quot;
	rhost-flags-OK-OK-OK-OK) by vger.kernel.org with ESMTP
	id S1751808AbdIVIly (ORCPT &lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Fri, 22 Sep 2017 04:41:54 -0400
Received: from fmsmga002.fm.intel.com ([10.253.24.26])
	by orsmga103.jf.intel.com with ESMTP/TLS/DHE-RSA-AES256-GCM-SHA384;
	22 Sep 2017 01:41:54 -0700
X-ExtLoop1: 1
X-IronPort-AV: E=Sophos;i=&quot;5.42,427,1500966000&quot;; d=&quot;scan&#39;208&quot;;a=&quot;1222280634&quot;
Received: from black.fi.intel.com ([10.237.72.28])
	by fmsmga002.fm.intel.com with ESMTP; 22 Sep 2017 01:41:51 -0700
Received: by black.fi.intel.com (Postfix, from userid 1000)
	id 1F935163; Fri, 22 Sep 2017 11:41:50 +0300 (EEST)
From: &quot;Kirill A. Shutemov&quot; &lt;kirill.shutemov@linux.intel.com&gt;
To: Andrew Morton &lt;akpm@linux-foundation.org&gt;
Cc: linux-mm@kvack.org, linux-kernel@vger.kernel.org,
	&quot;Kirill A. Shutemov&quot; &lt;kirill.shutemov@linux.intel.com&gt;,
	Michal Hocko &lt;mhocko@suse.com&gt;, Vlastimil Babka &lt;vbabka@suse.cz&gt;
Subject: [PATCH] mm: Account pud page tables
Date: Fri, 22 Sep 2017 11:41:46 +0300
Message-Id: &lt;20170922084146.39974-1-kirill.shutemov@linux.intel.com&gt;
X-Mailer: git-send-email 2.14.1
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=40781">Kirill A. Shutemov</a> - Sept. 22, 2017, 8:41 a.m.</div>
<pre class="content">
On machine with 5-level paging support a process can allocate
significant amount of memory and stay unnoticed by oom-killer and
memory cgroup. The trick is to allocate a lot of PUD page tables.
We don&#39;t account PUD page tables, only PMD and PTE.

We already addressed the same issue for PMD page tables, see
dc6c9a35b66b (&quot;mm: account pmd page tables to the process&quot;).
Introduction 5-level paging bring the same issue for PUD page tables.

The patch expands accounting to PUD level.
<span class="signed-off-by">
Signed-off-by: Kirill A. Shutemov &lt;kirill.shutemov@linux.intel.com&gt;</span>
Cc: Michal Hocko &lt;mhocko@suse.com&gt;
Cc: Vlastimil Babka &lt;vbabka@suse.cz&gt;
---
 Documentation/sysctl/vm.txt   |  8 ++++----
 arch/powerpc/mm/hugetlbpage.c |  1 +
 arch/sparc/mm/hugetlbpage.c   |  1 +
 fs/proc/task_mmu.c            |  5 ++++-
 include/linux/mm.h            | 32 +++++++++++++++++++++++++++++++-
 include/linux/mm_types.h      |  3 +++
 kernel/fork.c                 |  4 ++++
 mm/debug.c                    |  6 ++++--
 mm/memory.c                   | 15 +++++++++------
 mm/oom_kill.c                 |  8 +++++---
 10 files changed, 66 insertions(+), 17 deletions(-)
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=143191">kbuild test robot</a> - Sept. 24, 2017, 9:12 p.m.</div>
<pre class="content">
Hi Kirill,

[auto build test WARNING on linus/master]
[also build test WARNING on v4.14-rc1]
[if your patch is applied to the wrong git tree, please drop us a note to help improve the system]

url:    https://github.com/0day-ci/linux/commits/Kirill-A-Shutemov/mm-Account-pud-page-tables/20170925-035907
config: i386-randconfig-x077-201739 (attached as .config)
compiler: gcc-6 (Debian 6.2.0-3) 6.2.0 20160901
reproduce:
        # save the attached .config to linux build tree
        make ARCH=i386 

All warnings (new ones prefixed by &gt;&gt;):

   In file included from include/linux/kernel.h:13:0,
                    from mm/debug.c:8:
   mm/debug.c: In function &#39;dump_mm&#39;:
<span class="quote">&gt;&gt; mm/debug.c:139:14: warning: passing argument 1 of &#39;mm_nr_pmds&#39; discards &#39;const&#39; qualifier from pointer target type [-Wdiscarded-qualifiers]</span>
      mm_nr_pmds(mm),
                 ^
   include/linux/printk.h:295:35: note: in definition of macro &#39;pr_emerg&#39;
     printk(KERN_EMERG pr_fmt(fmt), ##__VA_ARGS__)
                                      ^~~~~~~~~~~
   In file included from mm/debug.c:9:0:
   include/linux/mm.h:1650:29: note: expected &#39;struct mm_struct *&#39; but argument is of type &#39;const struct mm_struct *&#39;
    static inline unsigned long mm_nr_pmds(struct mm_struct *mm)
                                ^~~~~~~~~~
   In file included from include/linux/kernel.h:13:0,
                    from mm/debug.c:8:
   mm/debug.c:140:14: warning: passing argument 1 of &#39;mm_nr_puds&#39; discards &#39;const&#39; qualifier from pointer target type [-Wdiscarded-qualifiers]
      mm_nr_puds(mm),
                 ^
   include/linux/printk.h:295:35: note: in definition of macro &#39;pr_emerg&#39;
     printk(KERN_EMERG pr_fmt(fmt), ##__VA_ARGS__)
                                      ^~~~~~~~~~~
   In file included from mm/debug.c:9:0:
   include/linux/mm.h:1608:29: note: expected &#39;struct mm_struct *&#39; but argument is of type &#39;const struct mm_struct *&#39;
    static inline unsigned long mm_nr_puds(struct mm_struct *mm)
                                ^~~~~~~~~~

vim +139 mm/debug.c
<span class="quote">
   &gt; 8	#include &lt;linux/kernel.h&gt;</span>
     9	#include &lt;linux/mm.h&gt;
    10	#include &lt;linux/trace_events.h&gt;
    11	#include &lt;linux/memcontrol.h&gt;
    12	#include &lt;trace/events/mmflags.h&gt;
    13	#include &lt;linux/migrate.h&gt;
    14	#include &lt;linux/page_owner.h&gt;
    15	
    16	#include &quot;internal.h&quot;
    17	
    18	char *migrate_reason_names[MR_TYPES] = {
    19		&quot;compaction&quot;,
    20		&quot;memory_failure&quot;,
    21		&quot;memory_hotplug&quot;,
    22		&quot;syscall_or_cpuset&quot;,
    23		&quot;mempolicy_mbind&quot;,
    24		&quot;numa_misplaced&quot;,
    25		&quot;cma&quot;,
    26	};
    27	
    28	const struct trace_print_flags pageflag_names[] = {
    29		__def_pageflag_names,
    30		{0, NULL}
    31	};
    32	
    33	const struct trace_print_flags gfpflag_names[] = {
    34		__def_gfpflag_names,
    35		{0, NULL}
    36	};
    37	
    38	const struct trace_print_flags vmaflag_names[] = {
    39		__def_vmaflag_names,
    40		{0, NULL}
    41	};
    42	
    43	void __dump_page(struct page *page, const char *reason)
    44	{
    45		/*
    46		 * Avoid VM_BUG_ON() in page_mapcount().
    47		 * page-&gt;_mapcount space in struct page is used by sl[aou]b pages to
    48		 * encode own info.
    49		 */
    50		int mapcount = PageSlab(page) ? 0 : page_mapcount(page);
    51	
    52		pr_emerg(&quot;page:%p count:%d mapcount:%d mapping:%p index:%#lx&quot;,
    53			  page, page_ref_count(page), mapcount,
    54			  page-&gt;mapping, page_to_pgoff(page));
    55		if (PageCompound(page))
    56			pr_cont(&quot; compound_mapcount: %d&quot;, compound_mapcount(page));
    57		pr_cont(&quot;\n&quot;);
    58		BUILD_BUG_ON(ARRAY_SIZE(pageflag_names) != __NR_PAGEFLAGS + 1);
    59	
    60		pr_emerg(&quot;flags: %#lx(%pGp)\n&quot;, page-&gt;flags, &amp;page-&gt;flags);
    61	
    62		print_hex_dump(KERN_ALERT, &quot;raw: &quot;, DUMP_PREFIX_NONE, 32,
    63				sizeof(unsigned long), page,
    64				sizeof(struct page), false);
    65	
    66		if (reason)
    67			pr_alert(&quot;page dumped because: %s\n&quot;, reason);
    68	
    69	#ifdef CONFIG_MEMCG
    70		if (page-&gt;mem_cgroup)
    71			pr_alert(&quot;page-&gt;mem_cgroup:%p\n&quot;, page-&gt;mem_cgroup);
    72	#endif
    73	}
    74	
    75	void dump_page(struct page *page, const char *reason)
    76	{
    77		__dump_page(page, reason);
    78		dump_page_owner(page);
    79	}
    80	EXPORT_SYMBOL(dump_page);
    81	
    82	#ifdef CONFIG_DEBUG_VM
    83	
    84	void dump_vma(const struct vm_area_struct *vma)
    85	{
    86		pr_emerg(&quot;vma %p start %p end %p\n&quot;
    87			&quot;next %p prev %p mm %p\n&quot;
    88			&quot;prot %lx anon_vma %p vm_ops %p\n&quot;
    89			&quot;pgoff %lx file %p private_data %p\n&quot;
    90			&quot;flags: %#lx(%pGv)\n&quot;,
    91			vma, (void *)vma-&gt;vm_start, (void *)vma-&gt;vm_end, vma-&gt;vm_next,
    92			vma-&gt;vm_prev, vma-&gt;vm_mm,
    93			(unsigned long)pgprot_val(vma-&gt;vm_page_prot),
    94			vma-&gt;anon_vma, vma-&gt;vm_ops, vma-&gt;vm_pgoff,
    95			vma-&gt;vm_file, vma-&gt;vm_private_data,
    96			vma-&gt;vm_flags, &amp;vma-&gt;vm_flags);
    97	}
    98	EXPORT_SYMBOL(dump_vma);
    99	
   100	void dump_mm(const struct mm_struct *mm)
   101	{
   102		pr_emerg(&quot;mm %p mmap %p seqnum %d task_size %lu\n&quot;
   103	#ifdef CONFIG_MMU
   104			&quot;get_unmapped_area %p\n&quot;
   105	#endif
   106			&quot;mmap_base %lu mmap_legacy_base %lu highest_vm_end %lu\n&quot;
   107			&quot;pgd %p mm_users %d mm_count %d\n&quot;
   108			&quot;nr_ptes %lu nr_pmds %lu nr_puds %lu map_count %d\n&quot;
   109			&quot;hiwater_rss %lx hiwater_vm %lx total_vm %lx locked_vm %lx\n&quot;
   110			&quot;pinned_vm %lx data_vm %lx exec_vm %lx stack_vm %lx\n&quot;
   111			&quot;start_code %lx end_code %lx start_data %lx end_data %lx\n&quot;
   112			&quot;start_brk %lx brk %lx start_stack %lx\n&quot;
   113			&quot;arg_start %lx arg_end %lx env_start %lx env_end %lx\n&quot;
   114			&quot;binfmt %p flags %lx core_state %p\n&quot;
   115	#ifdef CONFIG_AIO
   116			&quot;ioctx_table %p\n&quot;
   117	#endif
   118	#ifdef CONFIG_MEMCG
   119			&quot;owner %p &quot;
   120	#endif
   121			&quot;exe_file %p\n&quot;
   122	#ifdef CONFIG_MMU_NOTIFIER
   123			&quot;mmu_notifier_mm %p\n&quot;
   124	#endif
   125	#ifdef CONFIG_NUMA_BALANCING
   126			&quot;numa_next_scan %lu numa_scan_offset %lu numa_scan_seq %d\n&quot;
   127	#endif
   128			&quot;tlb_flush_pending %d\n&quot;
   129			&quot;def_flags: %#lx(%pGv)\n&quot;,
   130	
   131			mm, mm-&gt;mmap, mm-&gt;vmacache_seqnum, mm-&gt;task_size,
   132	#ifdef CONFIG_MMU
   133			mm-&gt;get_unmapped_area,
   134	#endif
   135			mm-&gt;mmap_base, mm-&gt;mmap_legacy_base, mm-&gt;highest_vm_end,
   136			mm-&gt;pgd, atomic_read(&amp;mm-&gt;mm_users),
   137			atomic_read(&amp;mm-&gt;mm_count),
   138			atomic_long_read((atomic_long_t *)&amp;mm-&gt;nr_ptes),
<span class="quote"> &gt; 139			mm_nr_pmds(mm),</span>
   140			mm_nr_puds(mm),
   141			mm-&gt;map_count,
   142			mm-&gt;hiwater_rss, mm-&gt;hiwater_vm, mm-&gt;total_vm, mm-&gt;locked_vm,
   143			mm-&gt;pinned_vm, mm-&gt;data_vm, mm-&gt;exec_vm, mm-&gt;stack_vm,
   144			mm-&gt;start_code, mm-&gt;end_code, mm-&gt;start_data, mm-&gt;end_data,
   145			mm-&gt;start_brk, mm-&gt;brk, mm-&gt;start_stack,
   146			mm-&gt;arg_start, mm-&gt;arg_end, mm-&gt;env_start, mm-&gt;env_end,
   147			mm-&gt;binfmt, mm-&gt;flags, mm-&gt;core_state,
   148	#ifdef CONFIG_AIO
   149			mm-&gt;ioctx_table,
   150	#endif
   151	#ifdef CONFIG_MEMCG
   152			mm-&gt;owner,
   153	#endif
   154			mm-&gt;exe_file,
   155	#ifdef CONFIG_MMU_NOTIFIER
   156			mm-&gt;mmu_notifier_mm,
   157	#endif
   158	#ifdef CONFIG_NUMA_BALANCING
   159			mm-&gt;numa_next_scan, mm-&gt;numa_scan_offset, mm-&gt;numa_scan_seq,
   160	#endif
   161			atomic_read(&amp;mm-&gt;tlb_flush_pending),
   162			mm-&gt;def_flags, &amp;mm-&gt;def_flags
   163		);
   164	}
   165	

---
0-DAY kernel test infrastructure                Open Source Technology Center
https://lists.01.org/pipermail/kbuild-all                   Intel Corporation
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=143191">kbuild test robot</a> - Sept. 24, 2017, 9:13 p.m.</div>
<pre class="content">
Hi Kirill,

[auto build test WARNING on linus/master]
[also build test WARNING on v4.14-rc1 next-20170922]
[if your patch is applied to the wrong git tree, please drop us a note to help improve the system]

url:    https://github.com/0day-ci/linux/commits/Kirill-A-Shutemov/mm-Account-pud-page-tables/20170925-035907
config: i386-randconfig-x070-201739 (attached as .config)
compiler: gcc-6 (Debian 6.2.0-3) 6.2.0 20160901
reproduce:
        # save the attached .config to linux build tree
        make ARCH=i386 

All warnings (new ones prefixed by &gt;&gt;):

   In file included from include/linux/kernel.h:13:0,
                    from mm/debug.c:8:
   mm/debug.c: In function &#39;dump_mm&#39;:
<span class="quote">&gt;&gt; mm/debug.c:140:14: warning: passing argument 1 of &#39;mm_nr_puds&#39; discards &#39;const&#39; qualifier from pointer target type [-Wdiscarded-qualifiers]</span>
      mm_nr_puds(mm),
                 ^
   include/linux/printk.h:295:35: note: in definition of macro &#39;pr_emerg&#39;
     printk(KERN_EMERG pr_fmt(fmt), ##__VA_ARGS__)
                                      ^~~~~~~~~~~
   In file included from mm/debug.c:9:0:
   include/linux/mm.h:1608:29: note: expected &#39;struct mm_struct *&#39; but argument is of type &#39;const struct mm_struct *&#39;
    static inline unsigned long mm_nr_puds(struct mm_struct *mm)
                                ^~~~~~~~~~

vim +140 mm/debug.c
<span class="quote">
   &gt; 8	#include &lt;linux/kernel.h&gt;</span>
     9	#include &lt;linux/mm.h&gt;
    10	#include &lt;linux/trace_events.h&gt;
    11	#include &lt;linux/memcontrol.h&gt;
    12	#include &lt;trace/events/mmflags.h&gt;
    13	#include &lt;linux/migrate.h&gt;
    14	#include &lt;linux/page_owner.h&gt;
    15	
    16	#include &quot;internal.h&quot;
    17	
    18	char *migrate_reason_names[MR_TYPES] = {
    19		&quot;compaction&quot;,
    20		&quot;memory_failure&quot;,
    21		&quot;memory_hotplug&quot;,
    22		&quot;syscall_or_cpuset&quot;,
    23		&quot;mempolicy_mbind&quot;,
    24		&quot;numa_misplaced&quot;,
    25		&quot;cma&quot;,
    26	};
    27	
    28	const struct trace_print_flags pageflag_names[] = {
    29		__def_pageflag_names,
    30		{0, NULL}
    31	};
    32	
    33	const struct trace_print_flags gfpflag_names[] = {
    34		__def_gfpflag_names,
    35		{0, NULL}
    36	};
    37	
    38	const struct trace_print_flags vmaflag_names[] = {
    39		__def_vmaflag_names,
    40		{0, NULL}
    41	};
    42	
    43	void __dump_page(struct page *page, const char *reason)
    44	{
    45		/*
    46		 * Avoid VM_BUG_ON() in page_mapcount().
    47		 * page-&gt;_mapcount space in struct page is used by sl[aou]b pages to
    48		 * encode own info.
    49		 */
    50		int mapcount = PageSlab(page) ? 0 : page_mapcount(page);
    51	
    52		pr_emerg(&quot;page:%p count:%d mapcount:%d mapping:%p index:%#lx&quot;,
    53			  page, page_ref_count(page), mapcount,
    54			  page-&gt;mapping, page_to_pgoff(page));
    55		if (PageCompound(page))
    56			pr_cont(&quot; compound_mapcount: %d&quot;, compound_mapcount(page));
    57		pr_cont(&quot;\n&quot;);
    58		BUILD_BUG_ON(ARRAY_SIZE(pageflag_names) != __NR_PAGEFLAGS + 1);
    59	
    60		pr_emerg(&quot;flags: %#lx(%pGp)\n&quot;, page-&gt;flags, &amp;page-&gt;flags);
    61	
    62		print_hex_dump(KERN_ALERT, &quot;raw: &quot;, DUMP_PREFIX_NONE, 32,
    63				sizeof(unsigned long), page,
    64				sizeof(struct page), false);
    65	
    66		if (reason)
    67			pr_alert(&quot;page dumped because: %s\n&quot;, reason);
    68	
    69	#ifdef CONFIG_MEMCG
    70		if (page-&gt;mem_cgroup)
    71			pr_alert(&quot;page-&gt;mem_cgroup:%p\n&quot;, page-&gt;mem_cgroup);
    72	#endif
    73	}
    74	
    75	void dump_page(struct page *page, const char *reason)
    76	{
    77		__dump_page(page, reason);
    78		dump_page_owner(page);
    79	}
    80	EXPORT_SYMBOL(dump_page);
    81	
    82	#ifdef CONFIG_DEBUG_VM
    83	
    84	void dump_vma(const struct vm_area_struct *vma)
    85	{
    86		pr_emerg(&quot;vma %p start %p end %p\n&quot;
    87			&quot;next %p prev %p mm %p\n&quot;
    88			&quot;prot %lx anon_vma %p vm_ops %p\n&quot;
    89			&quot;pgoff %lx file %p private_data %p\n&quot;
    90			&quot;flags: %#lx(%pGv)\n&quot;,
    91			vma, (void *)vma-&gt;vm_start, (void *)vma-&gt;vm_end, vma-&gt;vm_next,
    92			vma-&gt;vm_prev, vma-&gt;vm_mm,
    93			(unsigned long)pgprot_val(vma-&gt;vm_page_prot),
    94			vma-&gt;anon_vma, vma-&gt;vm_ops, vma-&gt;vm_pgoff,
    95			vma-&gt;vm_file, vma-&gt;vm_private_data,
    96			vma-&gt;vm_flags, &amp;vma-&gt;vm_flags);
    97	}
    98	EXPORT_SYMBOL(dump_vma);
    99	
   100	void dump_mm(const struct mm_struct *mm)
   101	{
   102		pr_emerg(&quot;mm %p mmap %p seqnum %d task_size %lu\n&quot;
   103	#ifdef CONFIG_MMU
   104			&quot;get_unmapped_area %p\n&quot;
   105	#endif
   106			&quot;mmap_base %lu mmap_legacy_base %lu highest_vm_end %lu\n&quot;
   107			&quot;pgd %p mm_users %d mm_count %d\n&quot;
   108			&quot;nr_ptes %lu nr_pmds %lu nr_puds %lu map_count %d\n&quot;
   109			&quot;hiwater_rss %lx hiwater_vm %lx total_vm %lx locked_vm %lx\n&quot;
   110			&quot;pinned_vm %lx data_vm %lx exec_vm %lx stack_vm %lx\n&quot;
   111			&quot;start_code %lx end_code %lx start_data %lx end_data %lx\n&quot;
   112			&quot;start_brk %lx brk %lx start_stack %lx\n&quot;
   113			&quot;arg_start %lx arg_end %lx env_start %lx env_end %lx\n&quot;
   114			&quot;binfmt %p flags %lx core_state %p\n&quot;
   115	#ifdef CONFIG_AIO
   116			&quot;ioctx_table %p\n&quot;
   117	#endif
   118	#ifdef CONFIG_MEMCG
   119			&quot;owner %p &quot;
   120	#endif
   121			&quot;exe_file %p\n&quot;
   122	#ifdef CONFIG_MMU_NOTIFIER
   123			&quot;mmu_notifier_mm %p\n&quot;
   124	#endif
   125	#ifdef CONFIG_NUMA_BALANCING
   126			&quot;numa_next_scan %lu numa_scan_offset %lu numa_scan_seq %d\n&quot;
   127	#endif
   128			&quot;tlb_flush_pending %d\n&quot;
   129			&quot;def_flags: %#lx(%pGv)\n&quot;,
   130	
   131			mm, mm-&gt;mmap, mm-&gt;vmacache_seqnum, mm-&gt;task_size,
   132	#ifdef CONFIG_MMU
   133			mm-&gt;get_unmapped_area,
   134	#endif
   135			mm-&gt;mmap_base, mm-&gt;mmap_legacy_base, mm-&gt;highest_vm_end,
   136			mm-&gt;pgd, atomic_read(&amp;mm-&gt;mm_users),
   137			atomic_read(&amp;mm-&gt;mm_count),
   138			atomic_long_read((atomic_long_t *)&amp;mm-&gt;nr_ptes),
   139			mm_nr_pmds(mm),
<span class="quote"> &gt; 140			mm_nr_puds(mm),</span>
   141			mm-&gt;map_count,
   142			mm-&gt;hiwater_rss, mm-&gt;hiwater_vm, mm-&gt;total_vm, mm-&gt;locked_vm,
   143			mm-&gt;pinned_vm, mm-&gt;data_vm, mm-&gt;exec_vm, mm-&gt;stack_vm,
   144			mm-&gt;start_code, mm-&gt;end_code, mm-&gt;start_data, mm-&gt;end_data,
   145			mm-&gt;start_brk, mm-&gt;brk, mm-&gt;start_stack,
   146			mm-&gt;arg_start, mm-&gt;arg_end, mm-&gt;env_start, mm-&gt;env_end,
   147			mm-&gt;binfmt, mm-&gt;flags, mm-&gt;core_state,
   148	#ifdef CONFIG_AIO
   149			mm-&gt;ioctx_table,
   150	#endif
   151	#ifdef CONFIG_MEMCG
   152			mm-&gt;owner,
   153	#endif
   154			mm-&gt;exe_file,
   155	#ifdef CONFIG_MMU_NOTIFIER
   156			mm-&gt;mmu_notifier_mm,
   157	#endif
   158	#ifdef CONFIG_NUMA_BALANCING
   159			mm-&gt;numa_next_scan, mm-&gt;numa_scan_offset, mm-&gt;numa_scan_seq,
   160	#endif
   161			atomic_read(&amp;mm-&gt;tlb_flush_pending),
   162			mm-&gt;def_flags, &amp;mm-&gt;def_flags
   163		);
   164	}
   165	

---
0-DAY kernel test infrastructure                Open Source Technology Center
https://lists.01.org/pipermail/kbuild-all                   Intel Corporation
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/Documentation/sysctl/vm.txt b/Documentation/sysctl/vm.txt</span>
<span class="p_header">index 9baf66a9ef4e..2717b6f2d706 100644</span>
<span class="p_header">--- a/Documentation/sysctl/vm.txt</span>
<span class="p_header">+++ b/Documentation/sysctl/vm.txt</span>
<span class="p_chunk">@@ -622,10 +622,10 @@</span> <span class="p_context"> oom_dump_tasks</span>
 
 Enables a system-wide task dump (excluding kernel threads) to be produced
 when the kernel performs an OOM-killing and includes such information as
<span class="p_del">-pid, uid, tgid, vm size, rss, nr_ptes, nr_pmds, swapents, oom_score_adj</span>
<span class="p_del">-score, and name.  This is helpful to determine why the OOM killer was</span>
<span class="p_del">-invoked, to identify the rogue task that caused it, and to determine why</span>
<span class="p_del">-the OOM killer chose the task it did to kill.</span>
<span class="p_add">+pid, uid, tgid, vm size, rss, nr_ptes, nr_pmds, nr_puds, swapents,</span>
<span class="p_add">+oom_score_adj score, and name.  This is helpful to determine why the OOM</span>
<span class="p_add">+killer was invoked, to identify the rogue task that caused it, and to</span>
<span class="p_add">+determine why the OOM killer chose the task it did to kill.</span>
 
 If this is set to zero, this information is suppressed.  On very
 large systems with thousands of tasks it may not be feasible to dump
<span class="p_header">diff --git a/arch/powerpc/mm/hugetlbpage.c b/arch/powerpc/mm/hugetlbpage.c</span>
<span class="p_header">index 1571a498a33f..a9b9083c5e49 100644</span>
<span class="p_header">--- a/arch/powerpc/mm/hugetlbpage.c</span>
<span class="p_header">+++ b/arch/powerpc/mm/hugetlbpage.c</span>
<span class="p_chunk">@@ -433,6 +433,7 @@</span> <span class="p_context"> static void hugetlb_free_pud_range(struct mmu_gather *tlb, pgd_t *pgd,</span>
 	pud = pud_offset(pgd, start);
 	pgd_clear(pgd);
 	pud_free_tlb(tlb, pud, start);
<span class="p_add">+	mm_dec_nr_puds(tlb-&gt;mm);</span>
 }
 
 /*
<span class="p_header">diff --git a/arch/sparc/mm/hugetlbpage.c b/arch/sparc/mm/hugetlbpage.c</span>
<span class="p_header">index bcd8cdbc377f..fd0d85808828 100644</span>
<span class="p_header">--- a/arch/sparc/mm/hugetlbpage.c</span>
<span class="p_header">+++ b/arch/sparc/mm/hugetlbpage.c</span>
<span class="p_chunk">@@ -471,6 +471,7 @@</span> <span class="p_context"> static void hugetlb_free_pud_range(struct mmu_gather *tlb, pgd_t *pgd,</span>
 	pud = pud_offset(pgd, start);
 	pgd_clear(pgd);
 	pud_free_tlb(tlb, pud, start);
<span class="p_add">+	mm_dec_nr_puds(tlb-&gt;mm);</span>
 }
 
 void hugetlb_free_pgd_range(struct mmu_gather *tlb,
<span class="p_header">diff --git a/fs/proc/task_mmu.c b/fs/proc/task_mmu.c</span>
<span class="p_header">index 5589b4bd4b85..0bf9e423aa99 100644</span>
<span class="p_header">--- a/fs/proc/task_mmu.c</span>
<span class="p_header">+++ b/fs/proc/task_mmu.c</span>
<span class="p_chunk">@@ -25,7 +25,7 @@</span> <span class="p_context"></span>
 
 void task_mem(struct seq_file *m, struct mm_struct *mm)
 {
<span class="p_del">-	unsigned long text, lib, swap, ptes, pmds, anon, file, shmem;</span>
<span class="p_add">+	unsigned long text, lib, swap, ptes, pmds, puds, anon, file, shmem;</span>
 	unsigned long hiwater_vm, total_vm, hiwater_rss, total_rss;
 
 	anon = get_mm_counter(mm, MM_ANONPAGES);
<span class="p_chunk">@@ -51,6 +51,7 @@</span> <span class="p_context"> void task_mem(struct seq_file *m, struct mm_struct *mm)</span>
 	swap = get_mm_counter(mm, MM_SWAPENTS);
 	ptes = PTRS_PER_PTE * sizeof(pte_t) * atomic_long_read(&amp;mm-&gt;nr_ptes);
 	pmds = PTRS_PER_PMD * sizeof(pmd_t) * mm_nr_pmds(mm);
<span class="p_add">+	puds = PTRS_PER_PUD * sizeof(pmd_t) * mm_nr_puds(mm);</span>
 	seq_printf(m,
 		&quot;VmPeak:\t%8lu kB\n&quot;
 		&quot;VmSize:\t%8lu kB\n&quot;
<span class="p_chunk">@@ -67,6 +68,7 @@</span> <span class="p_context"> void task_mem(struct seq_file *m, struct mm_struct *mm)</span>
 		&quot;VmLib:\t%8lu kB\n&quot;
 		&quot;VmPTE:\t%8lu kB\n&quot;
 		&quot;VmPMD:\t%8lu kB\n&quot;
<span class="p_add">+		&quot;VmPUD:\t%8lu kB\n&quot;</span>
 		&quot;VmSwap:\t%8lu kB\n&quot;,
 		hiwater_vm &lt;&lt; (PAGE_SHIFT-10),
 		total_vm &lt;&lt; (PAGE_SHIFT-10),
<span class="p_chunk">@@ -81,6 +83,7 @@</span> <span class="p_context"> void task_mem(struct seq_file *m, struct mm_struct *mm)</span>
 		mm-&gt;stack_vm &lt;&lt; (PAGE_SHIFT-10), text, lib,
 		ptes &gt;&gt; 10,
 		pmds &gt;&gt; 10,
<span class="p_add">+		puds &gt;&gt; 10,</span>
 		swap &lt;&lt; (PAGE_SHIFT-10));
 	hugetlb_report_usage(m, mm);
 }
<span class="p_header">diff --git a/include/linux/mm.h b/include/linux/mm.h</span>
<span class="p_header">index f8c10d336e42..70ca95d2deee 100644</span>
<span class="p_header">--- a/include/linux/mm.h</span>
<span class="p_header">+++ b/include/linux/mm.h</span>
<span class="p_chunk">@@ -1604,8 +1604,38 @@</span> <span class="p_context"> static inline int __pud_alloc(struct mm_struct *mm, p4d_t *p4d,</span>
 {
 	return 0;
 }
<span class="p_add">+</span>
<span class="p_add">+static inline unsigned long mm_nr_puds(struct mm_struct *mm)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return 0;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline void mm_nr_puds_init(struct mm_struct *mm) {}</span>
<span class="p_add">+static inline void mm_inc_nr_puds(struct mm_struct *mm) {}</span>
<span class="p_add">+static inline void mm_dec_nr_puds(struct mm_struct *mm) {}</span>
<span class="p_add">+</span>
 #else
 int __pud_alloc(struct mm_struct *mm, p4d_t *p4d, unsigned long address);
<span class="p_add">+</span>
<span class="p_add">+static inline void mm_nr_puds_init(struct mm_struct *mm)</span>
<span class="p_add">+{</span>
<span class="p_add">+	atomic_long_set(&amp;mm-&gt;nr_puds, 0);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline unsigned long mm_nr_puds(const struct mm_struct *mm)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return atomic_long_read(&amp;mm-&gt;nr_puds);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline void mm_inc_nr_puds(struct mm_struct *mm)</span>
<span class="p_add">+{</span>
<span class="p_add">+	atomic_long_inc(&amp;mm-&gt;nr_puds);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline void mm_dec_nr_puds(struct mm_struct *mm)</span>
<span class="p_add">+{</span>
<span class="p_add">+	atomic_long_dec(&amp;mm-&gt;nr_puds);</span>
<span class="p_add">+}</span>
 #endif
 
 #if defined(__PAGETABLE_PMD_FOLDED) || !defined(CONFIG_MMU)
<span class="p_chunk">@@ -1633,7 +1663,7 @@</span> <span class="p_context"> static inline void mm_nr_pmds_init(struct mm_struct *mm)</span>
 	atomic_long_set(&amp;mm-&gt;nr_pmds, 0);
 }
 
<span class="p_del">-static inline unsigned long mm_nr_pmds(struct mm_struct *mm)</span>
<span class="p_add">+static inline unsigned long mm_nr_pmds(const struct mm_struct *mm)</span>
 {
 	return atomic_long_read(&amp;mm-&gt;nr_pmds);
 }
<span class="p_header">diff --git a/include/linux/mm_types.h b/include/linux/mm_types.h</span>
<span class="p_header">index 46f4ecf5479a..6c8c2bb9e5a1 100644</span>
<span class="p_header">--- a/include/linux/mm_types.h</span>
<span class="p_header">+++ b/include/linux/mm_types.h</span>
<span class="p_chunk">@@ -401,6 +401,9 @@</span> <span class="p_context"> struct mm_struct {</span>
 	atomic_long_t nr_ptes;			/* PTE page table pages */
 #if CONFIG_PGTABLE_LEVELS &gt; 2
 	atomic_long_t nr_pmds;			/* PMD page table pages */
<span class="p_add">+#endif</span>
<span class="p_add">+#if CONFIG_PGTABLE_LEVELS &gt; 3</span>
<span class="p_add">+	atomic_long_t nr_puds;			/* PUD page table pages */</span>
 #endif
 	int map_count;				/* number of VMAs */
 
<span class="p_header">diff --git a/kernel/fork.c b/kernel/fork.c</span>
<span class="p_header">index 10646182440f..5624918154db 100644</span>
<span class="p_header">--- a/kernel/fork.c</span>
<span class="p_header">+++ b/kernel/fork.c</span>
<span class="p_chunk">@@ -815,6 +815,7 @@</span> <span class="p_context"> static struct mm_struct *mm_init(struct mm_struct *mm, struct task_struct *p,</span>
 	mm-&gt;core_state = NULL;
 	atomic_long_set(&amp;mm-&gt;nr_ptes, 0);
 	mm_nr_pmds_init(mm);
<span class="p_add">+	mm_nr_puds_init(mm);</span>
 	mm-&gt;map_count = 0;
 	mm-&gt;locked_vm = 0;
 	mm-&gt;pinned_vm = 0;
<span class="p_chunk">@@ -874,6 +875,9 @@</span> <span class="p_context"> static void check_mm(struct mm_struct *mm)</span>
 	if (mm_nr_pmds(mm))
 		pr_alert(&quot;BUG: non-zero nr_pmds on freeing mm: %ld\n&quot;,
 				mm_nr_pmds(mm));
<span class="p_add">+	if (mm_nr_puds(mm))</span>
<span class="p_add">+		pr_alert(&quot;BUG: non-zero nr_puds on freeing mm: %ld\n&quot;,</span>
<span class="p_add">+				mm_nr_puds(mm));</span>
 
 #if defined(CONFIG_TRANSPARENT_HUGEPAGE) &amp;&amp; !USE_SPLIT_PMD_PTLOCKS
 	VM_BUG_ON_MM(mm-&gt;pmd_huge_pte, mm);
<span class="p_header">diff --git a/mm/debug.c b/mm/debug.c</span>
<span class="p_header">index 5715448ab0b5..afccb2565269 100644</span>
<span class="p_header">--- a/mm/debug.c</span>
<span class="p_header">+++ b/mm/debug.c</span>
<span class="p_chunk">@@ -104,7 +104,8 @@</span> <span class="p_context"> void dump_mm(const struct mm_struct *mm)</span>
 		&quot;get_unmapped_area %p\n&quot;
 #endif
 		&quot;mmap_base %lu mmap_legacy_base %lu highest_vm_end %lu\n&quot;
<span class="p_del">-		&quot;pgd %p mm_users %d mm_count %d nr_ptes %lu nr_pmds %lu map_count %d\n&quot;</span>
<span class="p_add">+		&quot;pgd %p mm_users %d mm_count %d\n&quot;</span>
<span class="p_add">+		&quot;nr_ptes %lu nr_pmds %lu nr_puds %lu map_count %d\n&quot;</span>
 		&quot;hiwater_rss %lx hiwater_vm %lx total_vm %lx locked_vm %lx\n&quot;
 		&quot;pinned_vm %lx data_vm %lx exec_vm %lx stack_vm %lx\n&quot;
 		&quot;start_code %lx end_code %lx start_data %lx end_data %lx\n&quot;
<span class="p_chunk">@@ -135,7 +136,8 @@</span> <span class="p_context"> void dump_mm(const struct mm_struct *mm)</span>
 		mm-&gt;pgd, atomic_read(&amp;mm-&gt;mm_users),
 		atomic_read(&amp;mm-&gt;mm_count),
 		atomic_long_read((atomic_long_t *)&amp;mm-&gt;nr_ptes),
<span class="p_del">-		mm_nr_pmds((struct mm_struct *)mm),</span>
<span class="p_add">+		mm_nr_pmds(mm),</span>
<span class="p_add">+		mm_nr_puds(mm),</span>
 		mm-&gt;map_count,
 		mm-&gt;hiwater_rss, mm-&gt;hiwater_vm, mm-&gt;total_vm, mm-&gt;locked_vm,
 		mm-&gt;pinned_vm, mm-&gt;data_vm, mm-&gt;exec_vm, mm-&gt;stack_vm,
<span class="p_header">diff --git a/mm/memory.c b/mm/memory.c</span>
<span class="p_header">index ec4e15494901..8f49fdafac56 100644</span>
<span class="p_header">--- a/mm/memory.c</span>
<span class="p_header">+++ b/mm/memory.c</span>
<span class="p_chunk">@@ -506,6 +506,7 @@</span> <span class="p_context"> static inline void free_pud_range(struct mmu_gather *tlb, p4d_t *p4d,</span>
 	pud = pud_offset(p4d, start);
 	p4d_clear(p4d);
 	pud_free_tlb(tlb, pud, start);
<span class="p_add">+	mm_dec_nr_puds(tlb-&gt;mm);</span>
 }
 
 static inline void free_p4d_range(struct mmu_gather *tlb, pgd_t *pgd,
<span class="p_chunk">@@ -4124,15 +4125,17 @@</span> <span class="p_context"> int __pud_alloc(struct mm_struct *mm, p4d_t *p4d, unsigned long address)</span>
 
 	spin_lock(&amp;mm-&gt;page_table_lock);
 #ifndef __ARCH_HAS_5LEVEL_HACK
<span class="p_del">-	if (p4d_present(*p4d))		/* Another has populated it */</span>
<span class="p_del">-		pud_free(mm, new);</span>
<span class="p_del">-	else</span>
<span class="p_add">+	if (!p4d_present(*p4d)) {</span>
<span class="p_add">+		mm_inc_nr_puds(mm);</span>
 		p4d_populate(mm, p4d, new);
<span class="p_del">-#else</span>
<span class="p_del">-	if (pgd_present(*p4d))		/* Another has populated it */</span>
<span class="p_add">+	} else	/* Another has populated it */</span>
 		pud_free(mm, new);
<span class="p_del">-	else</span>
<span class="p_add">+#else</span>
<span class="p_add">+	if (!pgd_present(*pud)) {</span>
<span class="p_add">+		mm_inc_nr_puds(mm);</span>
 		pgd_populate(mm, p4d, new);
<span class="p_add">+	} else	/* Another has populated it */</span>
<span class="p_add">+		pud_free(mm, new);</span>
 #endif /* __ARCH_HAS_5LEVEL_HACK */
 	spin_unlock(&amp;mm-&gt;page_table_lock);
 	return 0;
<span class="p_header">diff --git a/mm/oom_kill.c b/mm/oom_kill.c</span>
<span class="p_header">index 99736e026712..4bee6968885d 100644</span>
<span class="p_header">--- a/mm/oom_kill.c</span>
<span class="p_header">+++ b/mm/oom_kill.c</span>
<span class="p_chunk">@@ -200,7 +200,8 @@</span> <span class="p_context"> unsigned long oom_badness(struct task_struct *p, struct mem_cgroup *memcg,</span>
 	 * task&#39;s rss, pagetable and swap space use.
 	 */
 	points = get_mm_rss(p-&gt;mm) + get_mm_counter(p-&gt;mm, MM_SWAPENTS) +
<span class="p_del">-		atomic_long_read(&amp;p-&gt;mm-&gt;nr_ptes) + mm_nr_pmds(p-&gt;mm);</span>
<span class="p_add">+		atomic_long_read(&amp;p-&gt;mm-&gt;nr_ptes) + mm_nr_pmds(p-&gt;mm) +</span>
<span class="p_add">+		mm_nr_puds(p-&gt;mm);</span>
 	task_unlock(p);
 
 	/*
<span class="p_chunk">@@ -376,7 +377,7 @@</span> <span class="p_context"> static void dump_tasks(struct mem_cgroup *memcg, const nodemask_t *nodemask)</span>
 	struct task_struct *p;
 	struct task_struct *task;
 
<span class="p_del">-	pr_info(&quot;[ pid ]   uid  tgid total_vm      rss nr_ptes nr_pmds swapents oom_score_adj name\n&quot;);</span>
<span class="p_add">+	pr_info(&quot;[ pid ]   uid  tgid total_vm      rss nr_ptes nr_pmds nr_puds swapents oom_score_adj name\n&quot;);</span>
 	rcu_read_lock();
 	for_each_process(p) {
 		if (oom_unkillable_task(p, memcg, nodemask))
<span class="p_chunk">@@ -392,11 +393,12 @@</span> <span class="p_context"> static void dump_tasks(struct mem_cgroup *memcg, const nodemask_t *nodemask)</span>
 			continue;
 		}
 
<span class="p_del">-		pr_info(&quot;[%5d] %5d %5d %8lu %8lu %7ld %7ld %8lu         %5hd %s\n&quot;,</span>
<span class="p_add">+		pr_info(&quot;[%5d] %5d %5d %8lu %8lu %7ld %7ld %7ld %8lu         %5hd %s\n&quot;,</span>
 			task-&gt;pid, from_kuid(&amp;init_user_ns, task_uid(task)),
 			task-&gt;tgid, task-&gt;mm-&gt;total_vm, get_mm_rss(task-&gt;mm),
 			atomic_long_read(&amp;task-&gt;mm-&gt;nr_ptes),
 			mm_nr_pmds(task-&gt;mm),
<span class="p_add">+			mm_nr_puds(task-&gt;mm),</span>
 			get_mm_counter(task-&gt;mm, MM_SWAPENTS),
 			task-&gt;signal-&gt;oom_score_adj, task-&gt;comm);
 		task_unlock(task);

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



