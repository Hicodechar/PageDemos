
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>[RFC] dma/swiotlb: Add helper for device driver to opt-out from swiotlb. - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    [RFC] dma/swiotlb: Add helper for device driver to opt-out from swiotlb.</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=2554">Jerome Glisse</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>Sept. 17, 2015, 6:22 p.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;1442514158-30281-1-git-send-email-jglisse@redhat.com&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/7209701/mbox/"
   >mbox</a>
|
   <a href="/patch/7209701/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/7209701/">/patch/7209701/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
X-Original-To: patchwork-LKML@patchwork.kernel.org
Delivered-To: patchwork-parsemail@patchwork1.web.kernel.org
Received: from mail.kernel.org (mail.kernel.org [198.145.29.136])
	by patchwork1.web.kernel.org (Postfix) with ESMTP id B88A49F380
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Thu, 17 Sep 2015 18:22:56 +0000 (UTC)
Received: from mail.kernel.org (localhost [127.0.0.1])
	by mail.kernel.org (Postfix) with ESMTP id D25AE2073D
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Thu, 17 Sep 2015 18:22:55 +0000 (UTC)
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.kernel.org (Postfix) with ESMTP id C54602072F
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Thu, 17 Sep 2015 18:22:54 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1752931AbbIQSWv (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Thu, 17 Sep 2015 14:22:51 -0400
Received: from mx1.redhat.com ([209.132.183.28]:34036 &quot;EHLO mx1.redhat.com&quot;
	rhost-flags-OK-OK-OK-OK) by vger.kernel.org with ESMTP
	id S1752872AbbIQSWu (ORCPT &lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Thu, 17 Sep 2015 14:22:50 -0400
Received: from int-mx14.intmail.prod.int.phx2.redhat.com
	(int-mx14.intmail.prod.int.phx2.redhat.com [10.5.11.27])
	by mx1.redhat.com (Postfix) with ESMTPS id 1B22FA9A;
	Thu, 17 Sep 2015 18:22:50 +0000 (UTC)
Received: from localhost.localdomain.com (vpn-58-138.rdu2.redhat.com
	[10.10.58.138])
	by int-mx14.intmail.prod.int.phx2.redhat.com (8.14.4/8.14.4) with
	ESMTP id t8HIMktf028456; Thu, 17 Sep 2015 14:22:47 -0400
From: jglisse@redhat.com
To: iommu@lists.linux-foundation.org
Cc: =?UTF-8?q?J=C3=A9r=C3=B4me=20Glisse?= &lt;jglisse@redhat.com&gt;,
	Joerg Roedel &lt;jroedel@suse.de&gt;,
	Konrad Rzeszutek Wilk &lt;Konrad.wilk@oracle.com&gt;,
	Alex Deucher &lt;alexander.deucher@amd.com&gt;,
	Dave Airlie &lt;airlied@redhat.com&gt;, linux-kernel@vger.kernel.org
Subject: [RFC PATCH] dma/swiotlb: Add helper for device driver to opt-out
	from swiotlb.
Date: Thu, 17 Sep 2015 14:22:38 -0400
Message-Id: &lt;1442514158-30281-1-git-send-email-jglisse@redhat.com&gt;
MIME-Version: 1.0
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 8bit
X-Scanned-By: MIMEDefang 2.68 on 10.5.11.27
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Spam-Status: No, score=-6.9 required=5.0 tests=BAYES_00, RCVD_IN_DNSWL_HI, 
	T_RP_MATCHES_RCVD,
	UNPARSEABLE_RELAY autolearn=unavailable version=3.3.1
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on mail.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=2554">Jerome Glisse</a> - Sept. 17, 2015, 6:22 p.m.</div>
<pre class="content">
<span class="from">From: Jérôme Glisse &lt;jglisse@redhat.com&gt;</span>

The swiotlb dma backend is not appropriate for some devices like
GPU where bounce buffer or slow dma page allocations is just not
acceptable. With that helper device drivers can opt-out from the
swiotlb and just do sane things without wasting CPU cycles inside
the swiotlb code.
<span class="signed-off-by">
Signed-off-by: Jérôme Glisse &lt;jglisse@redhat.com&gt;</span>
To: iommu@lists.linux-foundation.org
Cc: Joerg Roedel &lt;jroedel@suse.de&gt;
Cc: Konrad Rzeszutek Wilk &lt;Konrad.wilk@oracle.com&gt;
Cc: Alex Deucher &lt;alexander.deucher@amd.com&gt;
CC: Dave Airlie &lt;airlied@redhat.com&gt;
CC: linux-kernel@vger.kernel.org
---
 arch/x86/include/asm/dma-mapping.h       |  3 +++
 arch/x86/kernel/pci-swiotlb.c            | 18 ++++++++++++++++++
 include/asm-generic/dma-mapping-common.h |  7 +++++++
 3 files changed, 28 insertions(+)
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=3407">Konrad Rzeszutek Wilk</a> - Sept. 17, 2015, 7:02 p.m.</div>
<pre class="content">
On Thu, Sep 17, 2015 at 02:22:38PM -0400, jglisse@redhat.com wrote:
<span class="quote">&gt; From: Jérôme Glisse &lt;jglisse@redhat.com&gt;</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; The swiotlb dma backend is not appropriate for some devices like</span>
<span class="quote">&gt; GPU where bounce buffer or slow dma page allocations is just not</span>
<span class="quote">&gt; acceptable. With that helper device drivers can opt-out from the</span>
<span class="quote">&gt; swiotlb and just do sane things without wasting CPU cycles inside</span>
<span class="quote">&gt; the swiotlb code.</span>

What if SWIOTLB is the only one available?

And what can&#39;t the devices use the TTM DMA backend which sets up
buffers which don&#39;t need bounce buffer or slow dma page allocations?
<span class="quote">
&gt; </span>
<span class="quote">&gt; Signed-off-by: Jérôme Glisse &lt;jglisse@redhat.com&gt;</span>
<span class="quote">&gt; To: iommu@lists.linux-foundation.org</span>
<span class="quote">&gt; Cc: Joerg Roedel &lt;jroedel@suse.de&gt;</span>
<span class="quote">&gt; Cc: Konrad Rzeszutek Wilk &lt;Konrad.wilk@oracle.com&gt;</span>
<span class="quote">&gt; Cc: Alex Deucher &lt;alexander.deucher@amd.com&gt;</span>
<span class="quote">&gt; CC: Dave Airlie &lt;airlied@redhat.com&gt;</span>
<span class="quote">&gt; CC: linux-kernel@vger.kernel.org</span>
<span class="quote">&gt; ---</span>
<span class="quote">&gt;  arch/x86/include/asm/dma-mapping.h       |  3 +++</span>
<span class="quote">&gt;  arch/x86/kernel/pci-swiotlb.c            | 18 ++++++++++++++++++</span>
<span class="quote">&gt;  include/asm-generic/dma-mapping-common.h |  7 +++++++</span>
<span class="quote">&gt;  3 files changed, 28 insertions(+)</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; diff --git a/arch/x86/include/asm/dma-mapping.h b/arch/x86/include/asm/dma-mapping.h</span>
<span class="quote">&gt; index 953b726..b50745f 100644</span>
<span class="quote">&gt; --- a/arch/x86/include/asm/dma-mapping.h</span>
<span class="quote">&gt; +++ b/arch/x86/include/asm/dma-mapping.h</span>
<span class="quote">&gt; @@ -46,6 +46,9 @@ bool arch_dma_alloc_attrs(struct device **dev, gfp_t *gfp);</span>
<span class="quote">&gt;  #define HAVE_ARCH_DMA_SUPPORTED 1</span>
<span class="quote">&gt;  extern int dma_supported(struct device *hwdev, u64 mask);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; +#define HAVE_ARCH_DMA_OVERRIDE_SWIOTLB 1</span>
<span class="quote">&gt; +int dma_override_swiotlb(struct device *dev);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt;  #include &lt;asm-generic/dma-mapping-common.h&gt;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  extern void *dma_generic_alloc_coherent(struct device *dev, size_t size,</span>
<span class="quote">&gt; diff --git a/arch/x86/kernel/pci-swiotlb.c b/arch/x86/kernel/pci-swiotlb.c</span>
<span class="quote">&gt; index adf0392..6a9efab 100644</span>
<span class="quote">&gt; --- a/arch/x86/kernel/pci-swiotlb.c</span>
<span class="quote">&gt; +++ b/arch/x86/kernel/pci-swiotlb.c</span>
<span class="quote">&gt; @@ -117,3 +117,21 @@ void __init pci_swiotlb_late_init(void)</span>
<span class="quote">&gt;  		swiotlb_print_info();</span>
<span class="quote">&gt;  	}</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +/* dma_override_swiotlb() -  Override swiotlb with nommu.</span>
<span class="quote">&gt; + *</span>
<span class="quote">&gt; + * @device: Device for which to disable swiotlb.</span>
<span class="quote">&gt; + *</span>
<span class="quote">&gt; + * The swiotlb infrastructure just get in the way for some devices like GPU,</span>
<span class="quote">&gt; + * where things like bounce pages can not work properly or for which we do not</span>
<span class="quote">&gt; + * want to take slow page allocation code path. This function allows device</span>
<span class="quote">&gt; + * driver opportunity to opt-out from swiotlb.</span>
<span class="quote">&gt; + */</span>
<span class="quote">&gt; +int dma_override_swiotlb(struct device *dev)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	if (dev-&gt;archdata.dma_ops != &amp;swiotlb_dma_ops)</span>
<span class="quote">&gt; +		return 1;</span>
<span class="quote">&gt; +	dev-&gt;archdata.dma_ops = &amp;nommu_dma_ops;</span>
<span class="quote">&gt; +	return 1;</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +EXPORT_SYMBOL(dma_override_swiotlb);</span>
<span class="quote">&gt; diff --git a/include/asm-generic/dma-mapping-common.h b/include/asm-generic/dma-mapping-common.h</span>
<span class="quote">&gt; index b1bc954..452d947 100644</span>
<span class="quote">&gt; --- a/include/asm-generic/dma-mapping-common.h</span>
<span class="quote">&gt; +++ b/include/asm-generic/dma-mapping-common.h</span>
<span class="quote">&gt; @@ -355,4 +355,11 @@ static inline int dma_set_mask(struct device *dev, u64 mask)</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;  #endif</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; +#ifndef HAVE_ARCH_DMA_OVERRIDE_SWIOTLB</span>
<span class="quote">&gt; +static inline int dma_override_swiotlb(struct device *dev)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	return 0;</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +#endif</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt;  #endif</span>
<span class="quote">&gt; -- </span>
<span class="quote">&gt; 2.1.0</span>
<span class="quote">&gt; </span>
--
To unsubscribe from this list: send the line &quot;unsubscribe linux-kernel&quot; in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
Please read the FAQ at  http://www.tux.org/lkml/
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=3407">Konrad Rzeszutek Wilk</a> - Sept. 17, 2015, 7:06 p.m.</div>
<pre class="content">
On Thu, Sep 17, 2015 at 03:02:51PM -0400, Konrad Rzeszutek Wilk wrote:
<span class="quote">&gt; On Thu, Sep 17, 2015 at 02:22:38PM -0400, jglisse@redhat.com wrote:</span>
<span class="quote">&gt; &gt; From: Jérôme Glisse &lt;jglisse@redhat.com&gt;</span>
<span class="quote">&gt; &gt; </span>
<span class="quote">&gt; &gt; The swiotlb dma backend is not appropriate for some devices like</span>
<span class="quote">&gt; &gt; GPU where bounce buffer or slow dma page allocations is just not</span>
<span class="quote">&gt; &gt; acceptable. With that helper device drivers can opt-out from the</span>
<span class="quote">&gt; &gt; swiotlb and just do sane things without wasting CPU cycles inside</span>
<span class="quote">&gt; &gt; the swiotlb code.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; What if SWIOTLB is the only one available?</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; And what can&#39;t the devices use the TTM DMA backend which sets up</span>
<span class="quote">&gt; buffers which don&#39;t need bounce buffer or slow dma page allocations?</span>

And then the followup question. If it opts out - how can it do
sane things without an DMA API available? It would assume physical
addresses match the bus addresses which is not always the sane
thing.
<span class="quote">&gt; </span>
<span class="quote">&gt; &gt; </span>
<span class="quote">&gt; &gt; Signed-off-by: Jérôme Glisse &lt;jglisse@redhat.com&gt;</span>
<span class="quote">&gt; &gt; To: iommu@lists.linux-foundation.org</span>
<span class="quote">&gt; &gt; Cc: Joerg Roedel &lt;jroedel@suse.de&gt;</span>
<span class="quote">&gt; &gt; Cc: Konrad Rzeszutek Wilk &lt;Konrad.wilk@oracle.com&gt;</span>
<span class="quote">&gt; &gt; Cc: Alex Deucher &lt;alexander.deucher@amd.com&gt;</span>
<span class="quote">&gt; &gt; CC: Dave Airlie &lt;airlied@redhat.com&gt;</span>
<span class="quote">&gt; &gt; CC: linux-kernel@vger.kernel.org</span>
<span class="quote">&gt; &gt; ---</span>
<span class="quote">&gt; &gt;  arch/x86/include/asm/dma-mapping.h       |  3 +++</span>
<span class="quote">&gt; &gt;  arch/x86/kernel/pci-swiotlb.c            | 18 ++++++++++++++++++</span>
<span class="quote">&gt; &gt;  include/asm-generic/dma-mapping-common.h |  7 +++++++</span>
<span class="quote">&gt; &gt;  3 files changed, 28 insertions(+)</span>
<span class="quote">&gt; &gt; </span>
<span class="quote">&gt; &gt; diff --git a/arch/x86/include/asm/dma-mapping.h b/arch/x86/include/asm/dma-mapping.h</span>
<span class="quote">&gt; &gt; index 953b726..b50745f 100644</span>
<span class="quote">&gt; &gt; --- a/arch/x86/include/asm/dma-mapping.h</span>
<span class="quote">&gt; &gt; +++ b/arch/x86/include/asm/dma-mapping.h</span>
<span class="quote">&gt; &gt; @@ -46,6 +46,9 @@ bool arch_dma_alloc_attrs(struct device **dev, gfp_t *gfp);</span>
<span class="quote">&gt; &gt;  #define HAVE_ARCH_DMA_SUPPORTED 1</span>
<span class="quote">&gt; &gt;  extern int dma_supported(struct device *hwdev, u64 mask);</span>
<span class="quote">&gt; &gt;  </span>
<span class="quote">&gt; &gt; +#define HAVE_ARCH_DMA_OVERRIDE_SWIOTLB 1</span>
<span class="quote">&gt; &gt; +int dma_override_swiotlb(struct device *dev);</span>
<span class="quote">&gt; &gt; +</span>
<span class="quote">&gt; &gt;  #include &lt;asm-generic/dma-mapping-common.h&gt;</span>
<span class="quote">&gt; &gt;  </span>
<span class="quote">&gt; &gt;  extern void *dma_generic_alloc_coherent(struct device *dev, size_t size,</span>
<span class="quote">&gt; &gt; diff --git a/arch/x86/kernel/pci-swiotlb.c b/arch/x86/kernel/pci-swiotlb.c</span>
<span class="quote">&gt; &gt; index adf0392..6a9efab 100644</span>
<span class="quote">&gt; &gt; --- a/arch/x86/kernel/pci-swiotlb.c</span>
<span class="quote">&gt; &gt; +++ b/arch/x86/kernel/pci-swiotlb.c</span>
<span class="quote">&gt; &gt; @@ -117,3 +117,21 @@ void __init pci_swiotlb_late_init(void)</span>
<span class="quote">&gt; &gt;  		swiotlb_print_info();</span>
<span class="quote">&gt; &gt;  	}</span>
<span class="quote">&gt; &gt;  }</span>
<span class="quote">&gt; &gt; +</span>
<span class="quote">&gt; &gt; +/* dma_override_swiotlb() -  Override swiotlb with nommu.</span>
<span class="quote">&gt; &gt; + *</span>
<span class="quote">&gt; &gt; + * @device: Device for which to disable swiotlb.</span>
<span class="quote">&gt; &gt; + *</span>
<span class="quote">&gt; &gt; + * The swiotlb infrastructure just get in the way for some devices like GPU,</span>
<span class="quote">&gt; &gt; + * where things like bounce pages can not work properly or for which we do not</span>
<span class="quote">&gt; &gt; + * want to take slow page allocation code path. This function allows device</span>
<span class="quote">&gt; &gt; + * driver opportunity to opt-out from swiotlb.</span>
<span class="quote">&gt; &gt; + */</span>
<span class="quote">&gt; &gt; +int dma_override_swiotlb(struct device *dev)</span>
<span class="quote">&gt; &gt; +{</span>
<span class="quote">&gt; &gt; +	if (dev-&gt;archdata.dma_ops != &amp;swiotlb_dma_ops)</span>
<span class="quote">&gt; &gt; +		return 1;</span>
<span class="quote">&gt; &gt; +	dev-&gt;archdata.dma_ops = &amp;nommu_dma_ops;</span>
<span class="quote">&gt; &gt; +	return 1;</span>
<span class="quote">&gt; &gt; +}</span>
<span class="quote">&gt; &gt; +EXPORT_SYMBOL(dma_override_swiotlb);</span>
<span class="quote">&gt; &gt; diff --git a/include/asm-generic/dma-mapping-common.h b/include/asm-generic/dma-mapping-common.h</span>
<span class="quote">&gt; &gt; index b1bc954..452d947 100644</span>
<span class="quote">&gt; &gt; --- a/include/asm-generic/dma-mapping-common.h</span>
<span class="quote">&gt; &gt; +++ b/include/asm-generic/dma-mapping-common.h</span>
<span class="quote">&gt; &gt; @@ -355,4 +355,11 @@ static inline int dma_set_mask(struct device *dev, u64 mask)</span>
<span class="quote">&gt; &gt;  }</span>
<span class="quote">&gt; &gt;  #endif</span>
<span class="quote">&gt; &gt;  </span>
<span class="quote">&gt; &gt; +#ifndef HAVE_ARCH_DMA_OVERRIDE_SWIOTLB</span>
<span class="quote">&gt; &gt; +static inline int dma_override_swiotlb(struct device *dev)</span>
<span class="quote">&gt; &gt; +{</span>
<span class="quote">&gt; &gt; +	return 0;</span>
<span class="quote">&gt; &gt; +}</span>
<span class="quote">&gt; &gt; +#endif</span>
<span class="quote">&gt; &gt; +</span>
<span class="quote">&gt; &gt;  #endif</span>
<span class="quote">&gt; &gt; -- </span>
<span class="quote">&gt; &gt; 2.1.0</span>
<span class="quote">&gt; &gt; </span>
<span class="quote">&gt; _______________________________________________</span>
<span class="quote">&gt; iommu mailing list</span>
<span class="quote">&gt; iommu@lists.linux-foundation.org</span>
<span class="quote">&gt; https://lists.linuxfoundation.org/mailman/listinfo/iommu</span>
--
To unsubscribe from this list: send the line &quot;unsubscribe linux-kernel&quot; in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
Please read the FAQ at  http://www.tux.org/lkml/
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=2554">Jerome Glisse</a> - Sept. 17, 2015, 7:07 p.m.</div>
<pre class="content">
On Thu, Sep 17, 2015 at 03:02:51PM -0400, Konrad Rzeszutek Wilk wrote:
<span class="quote">&gt; On Thu, Sep 17, 2015 at 02:22:38PM -0400, jglisse@redhat.com wrote:</span>
<span class="quote">&gt; &gt; From: Jérôme Glisse &lt;jglisse@redhat.com&gt;</span>
<span class="quote">&gt; &gt; </span>
<span class="quote">&gt; &gt; The swiotlb dma backend is not appropriate for some devices like</span>
<span class="quote">&gt; &gt; GPU where bounce buffer or slow dma page allocations is just not</span>
<span class="quote">&gt; &gt; acceptable. With that helper device drivers can opt-out from the</span>
<span class="quote">&gt; &gt; swiotlb and just do sane things without wasting CPU cycles inside</span>
<span class="quote">&gt; &gt; the swiotlb code.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; What if SWIOTLB is the only one available?</span>

On x86 no_mmu is always available and we assume that device driver
that would use this knows that their device can access all memory
with no restriction or at very least use DMA32 gfp flag.
<span class="quote">

&gt; And what can&#39;t the devices use the TTM DMA backend which sets up</span>
<span class="quote">&gt; buffers which don&#39;t need bounce buffer or slow dma page allocations?</span>

We want to get rid of this TTM code path for radeon and likely
nouveau. This is the motivation for that patch. Benchmark shows
that the TTM DMA backend is much much much slower (20% on some
benchmark) that the regular page allocation and going through
no_mmu.

So this is all about allowing to directly allocate page through
regular kernel page alloc code and not through specialize dma
allocator.

Cheers,
Jérôme
--
To unsubscribe from this list: send the line &quot;unsubscribe linux-kernel&quot; in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
Please read the FAQ at  http://www.tux.org/lkml/
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=2554">Jerome Glisse</a> - Sept. 17, 2015, 7:11 p.m.</div>
<pre class="content">
On Thu, Sep 17, 2015 at 03:06:57PM -0400, Konrad Rzeszutek Wilk wrote:
<span class="quote">&gt; On Thu, Sep 17, 2015 at 03:02:51PM -0400, Konrad Rzeszutek Wilk wrote:</span>
<span class="quote">&gt; &gt; On Thu, Sep 17, 2015 at 02:22:38PM -0400, jglisse@redhat.com wrote:</span>
<span class="quote">&gt; &gt; &gt; From: Jérôme Glisse &lt;jglisse@redhat.com&gt;</span>
<span class="quote">&gt; &gt; &gt; </span>
<span class="quote">&gt; &gt; &gt; The swiotlb dma backend is not appropriate for some devices like</span>
<span class="quote">&gt; &gt; &gt; GPU where bounce buffer or slow dma page allocations is just not</span>
<span class="quote">&gt; &gt; &gt; acceptable. With that helper device drivers can opt-out from the</span>
<span class="quote">&gt; &gt; &gt; swiotlb and just do sane things without wasting CPU cycles inside</span>
<span class="quote">&gt; &gt; &gt; the swiotlb code.</span>
<span class="quote">&gt; &gt; </span>
<span class="quote">&gt; &gt; What if SWIOTLB is the only one available?</span>
<span class="quote">&gt; &gt; </span>
<span class="quote">&gt; &gt; And what can&#39;t the devices use the TTM DMA backend which sets up</span>
<span class="quote">&gt; &gt; buffers which don&#39;t need bounce buffer or slow dma page allocations?</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; And then the followup question. If it opts out - how can it do</span>
<span class="quote">&gt; sane things without an DMA API available? It would assume physical</span>
<span class="quote">&gt; addresses match the bus addresses which is not always the sane</span>
<span class="quote">&gt; thing.</span>

This is why this is an arch specific function, on x86 with pci device,
the driver knows what is the dma mask and thus if it can access directly
all the memory or not. So in the end swiotlb vs no_mmu gives the same
physical address to the device so there is no difference there.

Obviously device driver needs to know what it is doing depending on the
arch and bus the device is use in.

Cheers,
Jérôme
--
To unsubscribe from this list: send the line &quot;unsubscribe linux-kernel&quot; in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
Please read the FAQ at  http://www.tux.org/lkml/
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=3407">Konrad Rzeszutek Wilk</a> - Sept. 17, 2015, 7:24 p.m.</div>
<pre class="content">
On Thu, Sep 17, 2015 at 03:11:14PM -0400, Jerome Glisse wrote:
<span class="quote">&gt; On Thu, Sep 17, 2015 at 03:06:57PM -0400, Konrad Rzeszutek Wilk wrote:</span>
<span class="quote">&gt; &gt; On Thu, Sep 17, 2015 at 03:02:51PM -0400, Konrad Rzeszutek Wilk wrote:</span>
<span class="quote">&gt; &gt; &gt; On Thu, Sep 17, 2015 at 02:22:38PM -0400, jglisse@redhat.com wrote:</span>
<span class="quote">&gt; &gt; &gt; &gt; From: Jérôme Glisse &lt;jglisse@redhat.com&gt;</span>
<span class="quote">&gt; &gt; &gt; &gt; </span>
<span class="quote">&gt; &gt; &gt; &gt; The swiotlb dma backend is not appropriate for some devices like</span>
<span class="quote">&gt; &gt; &gt; &gt; GPU where bounce buffer or slow dma page allocations is just not</span>
<span class="quote">&gt; &gt; &gt; &gt; acceptable. With that helper device drivers can opt-out from the</span>
<span class="quote">&gt; &gt; &gt; &gt; swiotlb and just do sane things without wasting CPU cycles inside</span>
<span class="quote">&gt; &gt; &gt; &gt; the swiotlb code.</span>
<span class="quote">&gt; &gt; &gt; </span>
<span class="quote">&gt; &gt; &gt; What if SWIOTLB is the only one available?</span>
<span class="quote">&gt; &gt; &gt; </span>
<span class="quote">&gt; &gt; &gt; And what can&#39;t the devices use the TTM DMA backend which sets up</span>
<span class="quote">&gt; &gt; &gt; buffers which don&#39;t need bounce buffer or slow dma page allocations?</span>
<span class="quote">&gt; &gt; </span>
<span class="quote">&gt; &gt; And then the followup question. If it opts out - how can it do</span>
<span class="quote">&gt; &gt; sane things without an DMA API available? It would assume physical</span>
<span class="quote">&gt; &gt; addresses match the bus addresses which is not always the sane</span>
<span class="quote">&gt; &gt; thing.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; This is why this is an arch specific function, on x86 with pci device,</span>
<span class="quote">&gt; the driver knows what is the dma mask and thus if it can access directly</span>
<span class="quote">&gt; all the memory or not. So in the end swiotlb vs no_mmu gives the same</span>
<span class="quote">&gt; physical address to the device so there is no difference there.</span>

Not with Intel or AMD IOMMUs. The bus address it gives is not the same
as the physical address.
<span class="quote">&gt; </span>
<span class="quote">&gt; Obviously device driver needs to know what it is doing depending on the</span>
<span class="quote">&gt; arch and bus the device is use in.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Cheers,</span>
<span class="quote">&gt; Jérôme</span>
--
To unsubscribe from this list: send the line &quot;unsubscribe linux-kernel&quot; in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
Please read the FAQ at  http://www.tux.org/lkml/
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=2554">Jerome Glisse</a> - Sept. 17, 2015, 7:27 p.m.</div>
<pre class="content">
On Thu, Sep 17, 2015 at 03:24:25PM -0400, Konrad Rzeszutek Wilk wrote:
<span class="quote">&gt; On Thu, Sep 17, 2015 at 03:11:14PM -0400, Jerome Glisse wrote:</span>
<span class="quote">&gt; &gt; On Thu, Sep 17, 2015 at 03:06:57PM -0400, Konrad Rzeszutek Wilk wrote:</span>
<span class="quote">&gt; &gt; &gt; On Thu, Sep 17, 2015 at 03:02:51PM -0400, Konrad Rzeszutek Wilk wrote:</span>
<span class="quote">&gt; &gt; &gt; &gt; On Thu, Sep 17, 2015 at 02:22:38PM -0400, jglisse@redhat.com wrote:</span>
<span class="quote">&gt; &gt; &gt; &gt; &gt; From: Jérôme Glisse &lt;jglisse@redhat.com&gt;</span>
<span class="quote">&gt; &gt; &gt; &gt; &gt; </span>
<span class="quote">&gt; &gt; &gt; &gt; &gt; The swiotlb dma backend is not appropriate for some devices like</span>
<span class="quote">&gt; &gt; &gt; &gt; &gt; GPU where bounce buffer or slow dma page allocations is just not</span>
<span class="quote">&gt; &gt; &gt; &gt; &gt; acceptable. With that helper device drivers can opt-out from the</span>
<span class="quote">&gt; &gt; &gt; &gt; &gt; swiotlb and just do sane things without wasting CPU cycles inside</span>
<span class="quote">&gt; &gt; &gt; &gt; &gt; the swiotlb code.</span>
<span class="quote">&gt; &gt; &gt; &gt; </span>
<span class="quote">&gt; &gt; &gt; &gt; What if SWIOTLB is the only one available?</span>
<span class="quote">&gt; &gt; &gt; &gt; </span>
<span class="quote">&gt; &gt; &gt; &gt; And what can&#39;t the devices use the TTM DMA backend which sets up</span>
<span class="quote">&gt; &gt; &gt; &gt; buffers which don&#39;t need bounce buffer or slow dma page allocations?</span>
<span class="quote">&gt; &gt; &gt; </span>
<span class="quote">&gt; &gt; &gt; And then the followup question. If it opts out - how can it do</span>
<span class="quote">&gt; &gt; &gt; sane things without an DMA API available? It would assume physical</span>
<span class="quote">&gt; &gt; &gt; addresses match the bus addresses which is not always the sane</span>
<span class="quote">&gt; &gt; &gt; thing.</span>
<span class="quote">&gt; &gt; </span>
<span class="quote">&gt; &gt; This is why this is an arch specific function, on x86 with pci device,</span>
<span class="quote">&gt; &gt; the driver knows what is the dma mask and thus if it can access directly</span>
<span class="quote">&gt; &gt; all the memory or not. So in the end swiotlb vs no_mmu gives the same</span>
<span class="quote">&gt; &gt; physical address to the device so there is no difference there.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Not with Intel or AMD IOMMUs. The bus address it gives is not the same</span>
<span class="quote">&gt; as the physical address.</span>

Yes but this patch never overidde if the dma_ops are the one from any IOMMU
thus it can only override if there is a 1 to 1 mapping btw bus address and
physical address.

Cheers,
Jérôme
--
To unsubscribe from this list: send the line &quot;unsubscribe linux-kernel&quot; in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
Please read the FAQ at  http://www.tux.org/lkml/
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=3407">Konrad Rzeszutek Wilk</a> - Sept. 17, 2015, 7:31 p.m.</div>
<pre class="content">
On Thu, Sep 17, 2015 at 03:07:47PM -0400, Jerome Glisse wrote:
<span class="quote">&gt; On Thu, Sep 17, 2015 at 03:02:51PM -0400, Konrad Rzeszutek Wilk wrote:</span>
<span class="quote">&gt; &gt; On Thu, Sep 17, 2015 at 02:22:38PM -0400, jglisse@redhat.com wrote:</span>
<span class="quote">&gt; &gt; &gt; From: Jérôme Glisse &lt;jglisse@redhat.com&gt;</span>
<span class="quote">&gt; &gt; &gt; </span>
<span class="quote">&gt; &gt; &gt; The swiotlb dma backend is not appropriate for some devices like</span>
<span class="quote">&gt; &gt; &gt; GPU where bounce buffer or slow dma page allocations is just not</span>
<span class="quote">&gt; &gt; &gt; acceptable. With that helper device drivers can opt-out from the</span>
<span class="quote">&gt; &gt; &gt; swiotlb and just do sane things without wasting CPU cycles inside</span>
<span class="quote">&gt; &gt; &gt; the swiotlb code.</span>
<span class="quote">&gt; &gt; </span>
<span class="quote">&gt; &gt; What if SWIOTLB is the only one available?</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; On x86 no_mmu is always available and we assume that device driver</span>
<span class="quote">&gt; that would use this knows that their device can access all memory</span>
<span class="quote">&gt; with no restriction or at very least use DMA32 gfp flag.</span>

That runs afoul of the purpose of the DMA API. On x86 you may have
an IOMMU - GART, AMD Vi, Intel VT-d, Calgary, etc which will provide
you with the proper dma address. As the physical to bus address
topology does not have to be 1:1.
<span class="quote">&gt; </span>
<span class="quote">&gt; </span>
<span class="quote">&gt; &gt; And what can&#39;t the devices use the TTM DMA backend which sets up</span>
<span class="quote">&gt; &gt; buffers which don&#39;t need bounce buffer or slow dma page allocations?</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; We want to get rid of this TTM code path for radeon and likely</span>
<span class="quote">&gt; nouveau. This is the motivation for that patch. Benchmark shows</span>
<span class="quote">&gt; that the TTM DMA backend is much much much slower (20% on some</span>
<span class="quote">&gt; benchmark) that the regular page allocation and going through</span>
<span class="quote">&gt; no_mmu.</span>

You end up using the DMA API scatter gather API later on though.

I am also a bit confused on your use-case - when do you see this?
On regular desktop machines you will use the IOMMU API most of
the time because that hardware exists. The SWIOTLB should only
be used on hardware that is old, odd, or perhaps virtualized.
<span class="quote">
&gt; </span>
<span class="quote">&gt; So this is all about allowing to directly allocate page through</span>
<span class="quote">&gt; regular kernel page alloc code and not through specialize dma</span>
<span class="quote">&gt; allocator.</span>

.. What you are saying is that the intent of this patch is
to not use TTM DMA.

Are you using the SWIOTLB 99% of the time? 1%? Or is this
related to the unfortunate patch that enabled SWIOTLB all the time?
(If so, please please mention that in the commit, it didn&#39;t
occur to me until just now).

If that is the case we should attack the problem in a different
way - see if the IOMMU API is setup? Or is that set already
to some no_iommu option?

I think what you are looking for is a simple flag telling you
whether the IOMMU is there - in which case use the streaming
DMA API calls (dma_map_page, etc)?
<span class="quote">
&gt; </span>
<span class="quote">&gt; Cheers,</span>
<span class="quote">&gt; Jérôme</span>
--
To unsubscribe from this list: send the line &quot;unsubscribe linux-kernel&quot; in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
Please read the FAQ at  http://www.tux.org/lkml/
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=2554">Jerome Glisse</a> - Sept. 17, 2015, 7:40 p.m.</div>
<pre class="content">
On Thu, Sep 17, 2015 at 03:31:58PM -0400, Konrad Rzeszutek Wilk wrote:
<span class="quote">&gt; On Thu, Sep 17, 2015 at 03:07:47PM -0400, Jerome Glisse wrote:</span>
<span class="quote">&gt; &gt; On Thu, Sep 17, 2015 at 03:02:51PM -0400, Konrad Rzeszutek Wilk wrote:</span>
<span class="quote">&gt; &gt; &gt; On Thu, Sep 17, 2015 at 02:22:38PM -0400, jglisse@redhat.com wrote:</span>
<span class="quote">&gt; &gt; &gt; &gt; From: Jérôme Glisse &lt;jglisse@redhat.com&gt;</span>
<span class="quote">&gt; &gt; &gt; &gt; </span>
<span class="quote">&gt; &gt; &gt; &gt; The swiotlb dma backend is not appropriate for some devices like</span>
<span class="quote">&gt; &gt; &gt; &gt; GPU where bounce buffer or slow dma page allocations is just not</span>
<span class="quote">&gt; &gt; &gt; &gt; acceptable. With that helper device drivers can opt-out from the</span>
<span class="quote">&gt; &gt; &gt; &gt; swiotlb and just do sane things without wasting CPU cycles inside</span>
<span class="quote">&gt; &gt; &gt; &gt; the swiotlb code.</span>
<span class="quote">&gt; &gt; &gt; </span>
<span class="quote">&gt; &gt; &gt; What if SWIOTLB is the only one available?</span>
<span class="quote">&gt; &gt; </span>
<span class="quote">&gt; &gt; On x86 no_mmu is always available and we assume that device driver</span>
<span class="quote">&gt; &gt; that would use this knows that their device can access all memory</span>
<span class="quote">&gt; &gt; with no restriction or at very least use DMA32 gfp flag.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; That runs afoul of the purpose of the DMA API. On x86 you may have</span>
<span class="quote">&gt; an IOMMU - GART, AMD Vi, Intel VT-d, Calgary, etc which will provide</span>
<span class="quote">&gt; you with the proper dma address. As the physical to bus address</span>
<span class="quote">&gt; topology does not have to be 1:1.</span>

I am well aware of that but saddly IOMMU is not as widespread as you
would think on x86, on many platform it is still disabled by default
by BIOS and linux kernel endup binding the swiotlb as default dma ops
and thus you have a 1:1 mapping btw bus and physical address. My patch
does not impact the case where you have an IOMMU, it only caters to
the case where the swiotlb is the DMA API backend.
<span class="quote">
&gt; &gt; </span>
<span class="quote">&gt; &gt; </span>
<span class="quote">&gt; &gt; &gt; And what can&#39;t the devices use the TTM DMA backend which sets up</span>
<span class="quote">&gt; &gt; &gt; buffers which don&#39;t need bounce buffer or slow dma page allocations?</span>
<span class="quote">&gt; &gt; </span>
<span class="quote">&gt; &gt; We want to get rid of this TTM code path for radeon and likely</span>
<span class="quote">&gt; &gt; nouveau. This is the motivation for that patch. Benchmark shows</span>
<span class="quote">&gt; &gt; that the TTM DMA backend is much much much slower (20% on some</span>
<span class="quote">&gt; &gt; benchmark) that the regular page allocation and going through</span>
<span class="quote">&gt; &gt; no_mmu.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; You end up using the DMA API scatter gather API later on though.</span>

The DMA API scatter gather is only use for DMA buffer object and
this is a minority of the buffer object you have on today graphic
stacks and it&#39;s not use to present contiguous address to the GPU
(at least on GPU i care about). So most of the GPU object do not
use the DMA API scatter gather but the GPU hardware mmu that does
the scatter gather.
<span class="quote">
&gt; </span>
<span class="quote">&gt; I am also a bit confused on your use-case - when do you see this?</span>
<span class="quote">&gt; On regular desktop machines you will use the IOMMU API most of</span>
<span class="quote">&gt; the time because that hardware exists. The SWIOTLB should only</span>
<span class="quote">&gt; be used on hardware that is old, odd, or perhaps virtualized.</span>

Sadly it&#39;s not the case even recent x86 computer have the IOMMU
disabled by BIOS by default. User need to go into the bios and
enable virtualization option for the IOMMU to be enabled. I wish
that IOMMU was the default for all recent computer but it is just
not the case.
<span class="quote">
&gt; &gt; </span>
<span class="quote">&gt; &gt; So this is all about allowing to directly allocate page through</span>
<span class="quote">&gt; &gt; regular kernel page alloc code and not through specialize dma</span>
<span class="quote">&gt; &gt; allocator.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; .. What you are saying is that the intent of this patch is</span>
<span class="quote">&gt; to not use TTM DMA.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Are you using the SWIOTLB 99% of the time? 1%? Or is this</span>
<span class="quote">&gt; related to the unfortunate patch that enabled SWIOTLB all the time?</span>
<span class="quote">&gt; (If so, please please mention that in the commit, it didn&#39;t</span>
<span class="quote">&gt; occur to me until just now).</span>

Yes the patch that always enable the SWIOTLB is a pain point but
this patch also had other purpose that are now escaping my mind.
After discussion with other folks it seemed like the easiest
solution would be to opt-out from the swiotlb if it is in use.
<span class="quote">
&gt; </span>
<span class="quote">&gt; If that is the case we should attack the problem in a different</span>
<span class="quote">&gt; way - see if the IOMMU API is setup? Or is that set already</span>
<span class="quote">&gt; to some no_iommu option?</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; I think what you are looking for is a simple flag telling you</span>
<span class="quote">&gt; whether the IOMMU is there - in which case use the streaming</span>
<span class="quote">&gt; DMA API calls (dma_map_page, etc)?</span>

Device driver would still use dma_map_page, but this would not be
the swiotlb one but the no_mmu one which is pretty much a no op
and thus fast.

Cheers,
Jérôme
--
To unsubscribe from this list: send the line &quot;unsubscribe linux-kernel&quot; in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
Please read the FAQ at  http://www.tux.org/lkml/
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=11822">Jerome Glisse</a> - Sept. 22, 2015, 3:43 p.m.</div>
<pre class="content">
On Thu, Sep 17, 2015 at 03:31:58PM -0400, Konrad Rzeszutek Wilk wrote:
<span class="quote">&gt; On Thu, Sep 17, 2015 at 03:07:47PM -0400, Jerome Glisse wrote:</span>
<span class="quote">&gt; &gt; On Thu, Sep 17, 2015 at 03:02:51PM -0400, Konrad Rzeszutek Wilk wrote:</span>
<span class="quote">&gt; &gt; &gt; On Thu, Sep 17, 2015 at 02:22:38PM -0400, jglisse@redhat.com wrote:</span>
<span class="quote">&gt; &gt; &gt; &gt; From: Jérôme Glisse &lt;jglisse@redhat.com&gt;</span>
<span class="quote">&gt; &gt; &gt; &gt; </span>
<span class="quote">&gt; &gt; &gt; &gt; The swiotlb dma backend is not appropriate for some devices like</span>
<span class="quote">&gt; &gt; &gt; &gt; GPU where bounce buffer or slow dma page allocations is just not</span>
<span class="quote">&gt; &gt; &gt; &gt; acceptable. With that helper device drivers can opt-out from the</span>
<span class="quote">&gt; &gt; &gt; &gt; swiotlb and just do sane things without wasting CPU cycles inside</span>
<span class="quote">&gt; &gt; &gt; &gt; the swiotlb code.</span>
<span class="quote">&gt; &gt; &gt; </span>
<span class="quote">&gt; &gt; &gt; What if SWIOTLB is the only one available?</span>
<span class="quote">&gt; &gt; </span>
<span class="quote">&gt; &gt; On x86 no_mmu is always available and we assume that device driver</span>
<span class="quote">&gt; &gt; that would use this knows that their device can access all memory</span>
<span class="quote">&gt; &gt; with no restriction or at very least use DMA32 gfp flag.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; That runs afoul of the purpose of the DMA API. On x86 you may have</span>
<span class="quote">&gt; an IOMMU - GART, AMD Vi, Intel VT-d, Calgary, etc which will provide</span>
<span class="quote">&gt; you with the proper dma address. As the physical to bus address</span>
<span class="quote">&gt; topology does not have to be 1:1.</span>
<span class="quote">&gt; &gt; </span>
<span class="quote">&gt; &gt; </span>
<span class="quote">&gt; &gt; &gt; And what can&#39;t the devices use the TTM DMA backend which sets up</span>
<span class="quote">&gt; &gt; &gt; buffers which don&#39;t need bounce buffer or slow dma page allocations?</span>
<span class="quote">&gt; &gt; </span>
<span class="quote">&gt; &gt; We want to get rid of this TTM code path for radeon and likely</span>
<span class="quote">&gt; &gt; nouveau. This is the motivation for that patch. Benchmark shows</span>
<span class="quote">&gt; &gt; that the TTM DMA backend is much much much slower (20% on some</span>
<span class="quote">&gt; &gt; benchmark) that the regular page allocation and going through</span>
<span class="quote">&gt; &gt; no_mmu.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; You end up using the DMA API scatter gather API later on though.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; I am also a bit confused on your use-case - when do you see this?</span>
<span class="quote">&gt; On regular desktop machines you will use the IOMMU API most of</span>
<span class="quote">&gt; the time because that hardware exists. The SWIOTLB should only</span>
<span class="quote">&gt; be used on hardware that is old, odd, or perhaps virtualized.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; &gt; </span>
<span class="quote">&gt; &gt; So this is all about allowing to directly allocate page through</span>
<span class="quote">&gt; &gt; regular kernel page alloc code and not through specialize dma</span>
<span class="quote">&gt; &gt; allocator.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; .. What you are saying is that the intent of this patch is</span>
<span class="quote">&gt; to not use TTM DMA.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Are you using the SWIOTLB 99% of the time? 1%? Or is this</span>
<span class="quote">&gt; related to the unfortunate patch that enabled SWIOTLB all the time?</span>
<span class="quote">&gt; (If so, please please mention that in the commit, it didn&#39;t</span>
<span class="quote">&gt; occur to me until just now).</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; If that is the case we should attack the problem in a different</span>
<span class="quote">&gt; way - see if the IOMMU API is setup? Or is that set already</span>
<span class="quote">&gt; to some no_iommu option?</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; I think what you are looking for is a simple flag telling you</span>
<span class="quote">&gt; whether the IOMMU is there - in which case use the streaming</span>
<span class="quote">&gt; DMA API calls (dma_map_page, etc)?</span>

Konrad are you happy with all the explanation ? I am want to move
that patch forward so we can fix performance and forget about swiotlb
for GPU.

Cheers,
Jérôme
--
To unsubscribe from this list: send the line &quot;unsubscribe linux-kernel&quot; in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
Please read the FAQ at  http://www.tux.org/lkml/
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/arch/x86/include/asm/dma-mapping.h b/arch/x86/include/asm/dma-mapping.h</span>
<span class="p_header">index 953b726..b50745f 100644</span>
<span class="p_header">--- a/arch/x86/include/asm/dma-mapping.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/dma-mapping.h</span>
<span class="p_chunk">@@ -46,6 +46,9 @@</span> <span class="p_context"> bool arch_dma_alloc_attrs(struct device **dev, gfp_t *gfp);</span>
 #define HAVE_ARCH_DMA_SUPPORTED 1
 extern int dma_supported(struct device *hwdev, u64 mask);
 
<span class="p_add">+#define HAVE_ARCH_DMA_OVERRIDE_SWIOTLB 1</span>
<span class="p_add">+int dma_override_swiotlb(struct device *dev);</span>
<span class="p_add">+</span>
 #include &lt;asm-generic/dma-mapping-common.h&gt;
 
 extern void *dma_generic_alloc_coherent(struct device *dev, size_t size,
<span class="p_header">diff --git a/arch/x86/kernel/pci-swiotlb.c b/arch/x86/kernel/pci-swiotlb.c</span>
<span class="p_header">index adf0392..6a9efab 100644</span>
<span class="p_header">--- a/arch/x86/kernel/pci-swiotlb.c</span>
<span class="p_header">+++ b/arch/x86/kernel/pci-swiotlb.c</span>
<span class="p_chunk">@@ -117,3 +117,21 @@</span> <span class="p_context"> void __init pci_swiotlb_late_init(void)</span>
 		swiotlb_print_info();
 	}
 }
<span class="p_add">+</span>
<span class="p_add">+/* dma_override_swiotlb() -  Override swiotlb with nommu.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * @device: Device for which to disable swiotlb.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * The swiotlb infrastructure just get in the way for some devices like GPU,</span>
<span class="p_add">+ * where things like bounce pages can not work properly or for which we do not</span>
<span class="p_add">+ * want to take slow page allocation code path. This function allows device</span>
<span class="p_add">+ * driver opportunity to opt-out from swiotlb.</span>
<span class="p_add">+ */</span>
<span class="p_add">+int dma_override_swiotlb(struct device *dev)</span>
<span class="p_add">+{</span>
<span class="p_add">+	if (dev-&gt;archdata.dma_ops != &amp;swiotlb_dma_ops)</span>
<span class="p_add">+		return 1;</span>
<span class="p_add">+	dev-&gt;archdata.dma_ops = &amp;nommu_dma_ops;</span>
<span class="p_add">+	return 1;</span>
<span class="p_add">+}</span>
<span class="p_add">+EXPORT_SYMBOL(dma_override_swiotlb);</span>
<span class="p_header">diff --git a/include/asm-generic/dma-mapping-common.h b/include/asm-generic/dma-mapping-common.h</span>
<span class="p_header">index b1bc954..452d947 100644</span>
<span class="p_header">--- a/include/asm-generic/dma-mapping-common.h</span>
<span class="p_header">+++ b/include/asm-generic/dma-mapping-common.h</span>
<span class="p_chunk">@@ -355,4 +355,11 @@</span> <span class="p_context"> static inline int dma_set_mask(struct device *dev, u64 mask)</span>
 }
 #endif
 
<span class="p_add">+#ifndef HAVE_ARCH_DMA_OVERRIDE_SWIOTLB</span>
<span class="p_add">+static inline int dma_override_swiotlb(struct device *dev)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return 0;</span>
<span class="p_add">+}</span>
<span class="p_add">+#endif</span>
<span class="p_add">+</span>
 #endif

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



