
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>[PATCHv2,5/6] arm64: Use __pa_symbol for _end - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    [PATCHv2,5/6] arm64: Use __pa_symbol for _end</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=352">Catalin Marinas</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>Nov. 15, 2016, 6:35 p.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;20161115183508.GJ3096@e104818-lin.cambridge.arm.com&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/9430333/mbox/"
   >mbox</a>
|
   <a href="/patch/9430333/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/9430333/">/patch/9430333/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
	[172.30.200.125])
	by pdx-korg-patchwork.web.codeaurora.org (Postfix) with ESMTP id
	413A760469 for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Tue, 15 Nov 2016 18:35:29 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 2C46228C18
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Tue, 15 Nov 2016 18:35:29 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id 1CE8128C67; Tue, 15 Nov 2016 18:35:29 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-6.9 required=2.0 tests=BAYES_00,RCVD_IN_DNSWL_HI
	autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id C21E128C18
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Tue, 15 Nov 2016 18:35:27 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1753313AbcKOSfU (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Tue, 15 Nov 2016 13:35:20 -0500
Received: from foss.arm.com ([217.140.101.70]:34952 &quot;EHLO foss.arm.com&quot;
	rhost-flags-OK-OK-OK-OK) by vger.kernel.org with ESMTP
	id S1751611AbcKOSfO (ORCPT &lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Tue, 15 Nov 2016 13:35:14 -0500
Received: from usa-sjc-imap-foss1.foss.arm.com (unknown [10.72.51.249])
	by usa-sjc-mx-foss1.foss.arm.com (Postfix) with ESMTP id 22B4D16;
	Tue, 15 Nov 2016 10:35:13 -0800 (PST)
Received: from e104818-lin.cambridge.arm.com (e104818-lin.cambridge.arm.com
	[10.1.206.48])
	by usa-sjc-imap-foss1.foss.arm.com (Postfix) with ESMTPSA id
	07BA33F218; Tue, 15 Nov 2016 10:35:10 -0800 (PST)
Date: Tue, 15 Nov 2016 18:35:08 +0000
From: Catalin Marinas &lt;catalin.marinas@arm.com&gt;
To: Laura Abbott &lt;labbott@redhat.com&gt;
Cc: Mark Rutland &lt;mark.rutland@arm.com&gt;,
	Andrew Morton &lt;akpm@linux-foundation.org&gt;,
	Ard Biesheuvel &lt;ard.biesheuvel@linaro.org&gt;, x86@kernel.org,
	Will Deacon &lt;will.deacon@arm.com&gt;,
	linux-kernel@vger.kernel.org, linux-mm@kvack.org,
	Ingo Molnar &lt;mingo@redhat.com&gt;, &quot;H. Peter Anvin&quot; &lt;hpa@zytor.com&gt;,
	Joonsoo Kim &lt;iamjoonsoo.kim@lge.com&gt;,
	Thomas Gleixner &lt;tglx@linutronix.de&gt;,
	linux-arm-kernel@lists.infradead.org,
	Marek Szyprowski &lt;m.szyprowski@samsung.com&gt;
Subject: Re: [PATCHv2 5/6] arm64: Use __pa_symbol for _end
Message-ID: &lt;20161115183508.GJ3096@e104818-lin.cambridge.arm.com&gt;
References: &lt;20161102210054.16621-1-labbott@redhat.com&gt;
	&lt;20161102210054.16621-6-labbott@redhat.com&gt;
	&lt;20161102225241.GA19591@remoulade&gt;
	&lt;3724ea58-3c04-1248-8359-e2927da03aaf@redhat.com&gt;
	&lt;20161103155106.GF25852@remoulade&gt;
	&lt;20161114181937.GG3096@e104818-lin.cambridge.arm.com&gt;
	&lt;06569a6b-3846-5e18-28c1-7c16a9697663@redhat.com&gt;
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Disposition: inline
In-Reply-To: &lt;06569a6b-3846-5e18-28c1-7c16a9697663@redhat.com&gt;
User-Agent: Mutt/1.5.23 (2014-03-12)
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=352">Catalin Marinas</a> - Nov. 15, 2016, 6:35 p.m.</div>
<pre class="content">
On Mon, Nov 14, 2016 at 10:41:29AM -0800, Laura Abbott wrote:
<span class="quote">&gt; On 11/14/2016 10:19 AM, Catalin Marinas wrote:</span>
<span class="quote">&gt; &gt; On Thu, Nov 03, 2016 at 03:51:07PM +0000, Mark Rutland wrote:</span>
<span class="quote">&gt; &gt;&gt; On Wed, Nov 02, 2016 at 05:56:42PM -0600, Laura Abbott wrote:</span>
<span class="quote">&gt; &gt;&gt;&gt; On 11/02/2016 04:52 PM, Mark Rutland wrote:</span>
<span class="quote">&gt; &gt;&gt;&gt;&gt; On Wed, Nov 02, 2016 at 03:00:53PM -0600, Laura Abbott wrote:</span>
<span class="quote">&gt; &gt;&gt;&gt;&gt;&gt;</span>
<span class="quote">&gt; &gt;&gt;&gt;&gt;&gt; __pa_symbol is technically the marco that should be used for kernel</span>
<span class="quote">&gt; &gt;&gt;&gt;&gt;&gt; symbols. Switch to this as a pre-requisite for DEBUG_VIRTUAL.</span>
<span class="quote">&gt; &gt;&gt;&gt;&gt;</span>
<span class="quote">&gt; &gt;&gt;&gt;&gt; Nit: s/marco/macro/</span>
<span class="quote">&gt; &gt;&gt;&gt;&gt;</span>
<span class="quote">&gt; &gt;&gt;&gt;&gt; I see there are some other uses of __pa() that look like they could/should be</span>
<span class="quote">&gt; &gt;&gt;&gt;&gt; __pa_symbol(), e.g. in mark_rodata_ro().</span>
<span class="quote">&gt; &gt;&gt;&gt;&gt;</span>
<span class="quote">&gt; &gt;&gt;&gt;&gt; I guess strictly speaking those need to be updated to? Or is there a reason</span>
<span class="quote">&gt; &gt;&gt;&gt;&gt; that we should not?</span>
<span class="quote">&gt; &gt;&gt;&gt;</span>
<span class="quote">&gt; &gt;&gt;&gt; If the concept of __pa_symbol is okay then yes I think all uses of __pa</span>
<span class="quote">&gt; &gt;&gt;&gt; should eventually be converted for consistency and debugging.</span>
<span class="quote">&gt; &gt;&gt;</span>
<span class="quote">&gt; &gt;&gt; I have no strong feelings either way about __pa_symbol(); I&#39;m not clear on what</span>
<span class="quote">&gt; &gt;&gt; the purpose of __pa_symbol() is specifically, but I&#39;m happy even if it&#39;s just</span>
<span class="quote">&gt; &gt;&gt; for consistency with other architectures.</span>
<span class="quote">&gt; &gt; </span>
<span class="quote">&gt; &gt; At a quick grep, it seems to only be used by mips and x86 and a single</span>
<span class="quote">&gt; &gt; place in mm/memblock.c.</span>
<span class="quote">&gt; &gt; </span>
<span class="quote">&gt; &gt; Since we haven&#39;t seen any issues on arm/arm64 without this macro, can we</span>
<span class="quote">&gt; &gt; not just continue to use __pa()?</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Technically yes but if it&#39;s introduced it may be confusing why it&#39;s being</span>
<span class="quote">&gt; used some places but not others.</span>

As it currently stands, your patches introduce the first and only use of
__pa_symbol to arch/arm64. But I don&#39;t see the point, unless we replace
all of the other uses.
<span class="quote">
&gt; Maybe the bounds in the debug virtual check should just be adjusted so</span>
<span class="quote">&gt; we don&#39;t need __pa_symbol along with a nice fat comment explaining</span>
<span class="quote">&gt; why. </span>

I&#39;m fine with __pa_symbol use entirely from under arch/arm64. But if you
want to use __pa_symbol, I tried to change most (all?) places where
necessary, together with making virt_to_phys() only deal with the kernel
linear mapping. Not sure it looks cleaner, especially the
__va(__pa_symbol()) cases (we could replace the latter with another
macro and proper comment):

-------------8&lt;--------------------------------------
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=130411">Laura Abbott</a> - Nov. 16, 2016, 12:09 a.m.</div>
<pre class="content">
On 11/15/2016 10:35 AM, Catalin Marinas wrote:
<span class="quote">&gt; On Mon, Nov 14, 2016 at 10:41:29AM -0800, Laura Abbott wrote:</span>
<span class="quote">&gt;&gt; On 11/14/2016 10:19 AM, Catalin Marinas wrote:</span>
<span class="quote">&gt;&gt;&gt; On Thu, Nov 03, 2016 at 03:51:07PM +0000, Mark Rutland wrote:</span>
<span class="quote">&gt;&gt;&gt;&gt; On Wed, Nov 02, 2016 at 05:56:42PM -0600, Laura Abbott wrote:</span>
<span class="quote">&gt;&gt;&gt;&gt;&gt; On 11/02/2016 04:52 PM, Mark Rutland wrote:</span>
<span class="quote">&gt;&gt;&gt;&gt;&gt;&gt; On Wed, Nov 02, 2016 at 03:00:53PM -0600, Laura Abbott wrote:</span>
<span class="quote">&gt;&gt;&gt;&gt;&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt;&gt;&gt;&gt;&gt; __pa_symbol is technically the marco that should be used for kernel</span>
<span class="quote">&gt;&gt;&gt;&gt;&gt;&gt;&gt; symbols. Switch to this as a pre-requisite for DEBUG_VIRTUAL.</span>
<span class="quote">&gt;&gt;&gt;&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt;&gt;&gt;&gt; Nit: s/marco/macro/</span>
<span class="quote">&gt;&gt;&gt;&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt;&gt;&gt;&gt; I see there are some other uses of __pa() that look like they could/should be</span>
<span class="quote">&gt;&gt;&gt;&gt;&gt;&gt; __pa_symbol(), e.g. in mark_rodata_ro().</span>
<span class="quote">&gt;&gt;&gt;&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt;&gt;&gt;&gt; I guess strictly speaking those need to be updated to? Or is there a reason</span>
<span class="quote">&gt;&gt;&gt;&gt;&gt;&gt; that we should not?</span>
<span class="quote">&gt;&gt;&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt;&gt;&gt; If the concept of __pa_symbol is okay then yes I think all uses of __pa</span>
<span class="quote">&gt;&gt;&gt;&gt;&gt; should eventually be converted for consistency and debugging.</span>
<span class="quote">&gt;&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt;&gt; I have no strong feelings either way about __pa_symbol(); I&#39;m not clear on what</span>
<span class="quote">&gt;&gt;&gt;&gt; the purpose of __pa_symbol() is specifically, but I&#39;m happy even if it&#39;s just</span>
<span class="quote">&gt;&gt;&gt;&gt; for consistency with other architectures.</span>
<span class="quote">&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt; At a quick grep, it seems to only be used by mips and x86 and a single</span>
<span class="quote">&gt;&gt;&gt; place in mm/memblock.c.</span>
<span class="quote">&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt; Since we haven&#39;t seen any issues on arm/arm64 without this macro, can we</span>
<span class="quote">&gt;&gt;&gt; not just continue to use __pa()?</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; Technically yes but if it&#39;s introduced it may be confusing why it&#39;s being</span>
<span class="quote">&gt;&gt; used some places but not others.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; As it currently stands, your patches introduce the first and only use of</span>
<span class="quote">&gt; __pa_symbol to arch/arm64. But I don&#39;t see the point, unless we replace</span>
<span class="quote">&gt; all of the other uses.</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;&gt; Maybe the bounds in the debug virtual check should just be adjusted so</span>
<span class="quote">&gt;&gt; we don&#39;t need __pa_symbol along with a nice fat comment explaining</span>
<span class="quote">&gt;&gt; why. </span>
<span class="quote">&gt; </span>
<span class="quote">&gt; I&#39;m fine with __pa_symbol use entirely from under arch/arm64. But if you</span>
<span class="quote">&gt; want to use __pa_symbol, I tried to change most (all?) places where</span>
<span class="quote">&gt; necessary, together with making virt_to_phys() only deal with the kernel</span>
<span class="quote">&gt; linear mapping. Not sure it looks cleaner, especially the</span>
<span class="quote">&gt; __va(__pa_symbol()) cases (we could replace the latter with another</span>
<span class="quote">&gt; macro and proper comment):</span>
<span class="quote">&gt; </span>

I agree everything should be converted over, I was considering doing
that in a separate patch but this covers everything nicely. Are you
okay with me folding this in? (Few comments below)
<span class="quote">
&gt; -------------8&lt;--------------------------------------</span>
<span class="quote">&gt; diff --git a/arch/arm64/include/asm/kvm_mmu.h b/arch/arm64/include/asm/kvm_mmu.h</span>
<span class="quote">&gt; index a79b969c26fc..fa6c44ebb51f 100644</span>
<span class="quote">&gt; --- a/arch/arm64/include/asm/kvm_mmu.h</span>
<span class="quote">&gt; +++ b/arch/arm64/include/asm/kvm_mmu.h</span>
<span class="quote">&gt; @@ -47,7 +47,7 @@</span>
<span class="quote">&gt;   * If the page is in the bottom half, we have to use the top half. If</span>
<span class="quote">&gt;   * the page is in the top half, we have to use the bottom half:</span>
<span class="quote">&gt;   *</span>
<span class="quote">&gt; - * T = __virt_to_phys(__hyp_idmap_text_start)</span>
<span class="quote">&gt; + * T = __pa_symbol(__hyp_idmap_text_start)</span>
<span class="quote">&gt;   * if (T &amp; BIT(VA_BITS - 1))</span>
<span class="quote">&gt;   *	HYP_VA_MIN = 0  //idmap in upper half</span>
<span class="quote">&gt;   * else</span>
<span class="quote">&gt; @@ -271,7 +271,7 @@ static inline void __kvm_flush_dcache_pud(pud_t pud)</span>
<span class="quote">&gt;  	kvm_flush_dcache_to_poc(page_address(page), PUD_SIZE);</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; -#define kvm_virt_to_phys(x)		__virt_to_phys((unsigned long)(x))</span>
<span class="quote">&gt; +#define kvm_virt_to_phys(x)		__pa_symbol((unsigned long)(x))</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  void kvm_set_way_flush(struct kvm_vcpu *vcpu);</span>
<span class="quote">&gt;  void kvm_toggle_cache(struct kvm_vcpu *vcpu, bool was_enabled);</span>
<span class="quote">&gt; diff --git a/arch/arm64/include/asm/memory.h b/arch/arm64/include/asm/memory.h</span>
<span class="quote">&gt; index eac3dbb7e313..e02f45e5ee1b 100644</span>
<span class="quote">&gt; --- a/arch/arm64/include/asm/memory.h</span>
<span class="quote">&gt; +++ b/arch/arm64/include/asm/memory.h</span>
<span class="quote">&gt; @@ -169,15 +169,22 @@ extern u64			kimage_voffset;</span>
<span class="quote">&gt;   */</span>
<span class="quote">&gt;  #define __virt_to_phys_nodebug(x) ({					\</span>
<span class="quote">&gt;  	phys_addr_t __x = (phys_addr_t)(x);				\</span>
<span class="quote">&gt; -	__x &amp; BIT(VA_BITS - 1) ? (__x &amp; ~PAGE_OFFSET) + PHYS_OFFSET :	\</span>
<span class="quote">&gt; -				 (__x - kimage_voffset); })</span>
<span class="quote">&gt; +	VM_BUG_ON(!(__x &amp; BIT(VA_BITS - 1)));				\</span>
<span class="quote">&gt; +	((__x &amp; ~PAGE_OFFSET) + PHYS_OFFSET);				\</span>
<span class="quote">&gt; +})</span>

I do think this is easier to understand vs the ternary operator.
I&#39;ll add a comment detailing the use of __pa vs __pa_symbol somewhere
as well.
<span class="quote">
&gt; +</span>
<span class="quote">&gt; +#define __pa_symbol_nodebug(x) ({					\</span>
<span class="quote">&gt; +	phys_addr_t __x = (phys_addr_t)(x);				\</span>
<span class="quote">&gt; +	VM_BUG_ON(__x &amp; BIT(VA_BITS - 1));				\</span>
<span class="quote">&gt; +	(__x - kimage_voffset);						\</span>
<span class="quote">&gt; +})</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  #ifdef CONFIG_DEBUG_VIRTUAL</span>
<span class="quote">&gt;  extern unsigned long __virt_to_phys(unsigned long x);</span>
<span class="quote">&gt;  extern unsigned long __phys_addr_symbol(unsigned long x);</span>
<span class="quote">&gt;  #else</span>
<span class="quote">&gt;  #define __virt_to_phys(x)	__virt_to_phys_nodebug(x)</span>
<span class="quote">&gt; -#define __phys_addr_symbol	__pa</span>
<span class="quote">&gt; +#define __phys_addr_symbol(x)	__pa_symbol_nodebug(x)</span>
<span class="quote">&gt;  #endif</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  #define __phys_to_virt(x)	((unsigned long)((x) - PHYS_OFFSET) | PAGE_OFFSET)</span>
<span class="quote">&gt; @@ -210,7 +217,7 @@ static inline void *phys_to_virt(phys_addr_t x)</span>
<span class="quote">&gt;   * Drivers should NOT use these either.</span>
<span class="quote">&gt;   */</span>
<span class="quote">&gt;  #define __pa(x)			__virt_to_phys((unsigned long)(x))</span>
<span class="quote">&gt; -#define __pa_symbol(x)  __phys_addr_symbol(RELOC_HIDE((unsigned long)(x), 0))</span>
<span class="quote">&gt; +#define __pa_symbol(x)		__phys_addr_symbol(RELOC_HIDE((unsigned long)(x), 0))</span>
<span class="quote">&gt;  #define __pa_nodebug(x)		__virt_to_phys_nodebug((unsigned long)(x))</span>
<span class="quote">&gt;  #define __va(x)			((void *)__phys_to_virt((phys_addr_t)(x)))</span>
<span class="quote">&gt;  #define pfn_to_kaddr(pfn)	__va((pfn) &lt;&lt; PAGE_SHIFT)</span>
<span class="quote">&gt; diff --git a/arch/arm64/include/asm/mmu_context.h b/arch/arm64/include/asm/mmu_context.h</span>
<span class="quote">&gt; index a50185375f09..6cf3763c6e11 100644</span>
<span class="quote">&gt; --- a/arch/arm64/include/asm/mmu_context.h</span>
<span class="quote">&gt; +++ b/arch/arm64/include/asm/mmu_context.h</span>
<span class="quote">&gt; @@ -44,7 +44,7 @@ static inline void contextidr_thread_switch(struct task_struct *next)</span>
<span class="quote">&gt;   */</span>
<span class="quote">&gt;  static inline void cpu_set_reserved_ttbr0(void)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt; -	unsigned long ttbr = virt_to_phys(empty_zero_page);</span>
<span class="quote">&gt; +	unsigned long ttbr = __pa_symbol(empty_zero_page);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	write_sysreg(ttbr, ttbr0_el1);</span>
<span class="quote">&gt;  	isb();</span>
<span class="quote">&gt; @@ -113,7 +113,7 @@ static inline void cpu_install_idmap(void)</span>
<span class="quote">&gt;  	local_flush_tlb_all();</span>
<span class="quote">&gt;  	cpu_set_idmap_tcr_t0sz();</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; -	cpu_switch_mm(idmap_pg_dir, &amp;init_mm);</span>
<span class="quote">&gt; +	cpu_switch_mm(__va(__pa_symbol(idmap_pg_dir)), &amp;init_mm);</span>

Yes, the __va(__pa_symbol(..)) idiom needs to be macroized and commented...
<span class="quote">
&gt;  }</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  /*</span>
<span class="quote">&gt; @@ -128,7 +128,7 @@ static inline void cpu_replace_ttbr1(pgd_t *pgd)</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	phys_addr_t pgd_phys = virt_to_phys(pgd);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; -	replace_phys = (void *)virt_to_phys(idmap_cpu_replace_ttbr1);</span>
<span class="quote">&gt; +	replace_phys = (void *)__pa_symbol(idmap_cpu_replace_ttbr1);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	cpu_install_idmap();</span>
<span class="quote">&gt;  	replace_phys(pgd_phys);</span>
<span class="quote">&gt; diff --git a/arch/arm64/include/asm/pgtable.h b/arch/arm64/include/asm/pgtable.h</span>
<span class="quote">&gt; index ffbb9a520563..c2041a39a3e3 100644</span>
<span class="quote">&gt; --- a/arch/arm64/include/asm/pgtable.h</span>
<span class="quote">&gt; +++ b/arch/arm64/include/asm/pgtable.h</span>
<span class="quote">&gt; @@ -52,7 +52,7 @@ extern void __pgd_error(const char *file, int line, unsigned long val);</span>
<span class="quote">&gt;   * for zero-mapped memory areas etc..</span>
<span class="quote">&gt;   */</span>
<span class="quote">&gt;  extern unsigned long empty_zero_page[PAGE_SIZE / sizeof(unsigned long)];</span>
<span class="quote">&gt; -#define ZERO_PAGE(vaddr)	pfn_to_page(PHYS_PFN(__pa(empty_zero_page)))</span>
<span class="quote">&gt; +#define ZERO_PAGE(vaddr)	pfn_to_page(PHYS_PFN(__pa_symbol(empty_zero_page)))</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  #define pte_ERROR(pte)		__pte_error(__FILE__, __LINE__, pte_val(pte))</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; diff --git a/arch/arm64/kernel/acpi_parking_protocol.c b/arch/arm64/kernel/acpi_parking_protocol.c</span>
<span class="quote">&gt; index a32b4011d711..df58310660c6 100644</span>
<span class="quote">&gt; --- a/arch/arm64/kernel/acpi_parking_protocol.c</span>
<span class="quote">&gt; +++ b/arch/arm64/kernel/acpi_parking_protocol.c</span>
<span class="quote">&gt; @@ -109,7 +109,7 @@ static int acpi_parking_protocol_cpu_boot(unsigned int cpu)</span>
<span class="quote">&gt;  	 * that read this address need to convert this address to the</span>
<span class="quote">&gt;  	 * Boot-Loader&#39;s endianness before jumping.</span>
<span class="quote">&gt;  	 */</span>
<span class="quote">&gt; -	writeq_relaxed(__pa(secondary_entry), &amp;mailbox-&gt;entry_point);</span>
<span class="quote">&gt; +	writeq_relaxed(__pa_symbol(secondary_entry), &amp;mailbox-&gt;entry_point);</span>
<span class="quote">&gt;  	writel_relaxed(cpu_entry-&gt;gic_cpu_id, &amp;mailbox-&gt;cpu_id);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	arch_send_wakeup_ipi_mask(cpumask_of(cpu));</span>
<span class="quote">&gt; diff --git a/arch/arm64/kernel/cpufeature.c b/arch/arm64/kernel/cpufeature.c</span>
<span class="quote">&gt; index c02504ea304b..6ccadf255fba 100644</span>
<span class="quote">&gt; --- a/arch/arm64/kernel/cpufeature.c</span>
<span class="quote">&gt; +++ b/arch/arm64/kernel/cpufeature.c</span>
<span class="quote">&gt; @@ -736,7 +736,7 @@ static bool runs_at_el2(const struct arm64_cpu_capabilities *entry, int __unused</span>
<span class="quote">&gt;  static bool hyp_offset_low(const struct arm64_cpu_capabilities *entry,</span>
<span class="quote">&gt;  			   int __unused)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt; -	phys_addr_t idmap_addr = virt_to_phys(__hyp_idmap_text_start);</span>
<span class="quote">&gt; +	phys_addr_t idmap_addr = __pa_symbol(__hyp_idmap_text_start);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	/*</span>
<span class="quote">&gt;  	 * Activate the lower HYP offset only if:</span>
<span class="quote">&gt; diff --git a/arch/arm64/kernel/hibernate.c b/arch/arm64/kernel/hibernate.c</span>
<span class="quote">&gt; index d55a7b09959b..81c03c74e5fe 100644</span>
<span class="quote">&gt; --- a/arch/arm64/kernel/hibernate.c</span>
<span class="quote">&gt; +++ b/arch/arm64/kernel/hibernate.c</span>
<span class="quote">&gt; @@ -51,7 +51,7 @@</span>
<span class="quote">&gt;  extern int in_suspend;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  /* Find a symbols alias in the linear map */</span>
<span class="quote">&gt; -#define LMADDR(x)	phys_to_virt(virt_to_phys(x))</span>
<span class="quote">&gt; +#define LMADDR(x)	__va(__pa_symbol(x))</span>

...Perhaps just borrowing this macro?
<span class="quote">
&gt;  </span>
<span class="quote">&gt;  /* Do we need to reset el2? */</span>
<span class="quote">&gt;  #define el2_reset_needed() (is_hyp_mode_available() &amp;&amp; !is_kernel_in_hyp_mode())</span>
<span class="quote">&gt; @@ -125,12 +125,12 @@ int arch_hibernation_header_save(void *addr, unsigned int max_size)</span>
<span class="quote">&gt;  		return -EOVERFLOW;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	arch_hdr_invariants(&amp;hdr-&gt;invariants);</span>
<span class="quote">&gt; -	hdr-&gt;ttbr1_el1		= virt_to_phys(swapper_pg_dir);</span>
<span class="quote">&gt; +	hdr-&gt;ttbr1_el1		= __pa_symbol(swapper_pg_dir);</span>
<span class="quote">&gt;  	hdr-&gt;reenter_kernel	= _cpu_resume;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	/* We can&#39;t use __hyp_get_vectors() because kvm may still be loaded */</span>
<span class="quote">&gt;  	if (el2_reset_needed())</span>
<span class="quote">&gt; -		hdr-&gt;__hyp_stub_vectors = virt_to_phys(__hyp_stub_vectors);</span>
<span class="quote">&gt; +		hdr-&gt;__hyp_stub_vectors = __pa_symbol(__hyp_stub_vectors);</span>
<span class="quote">&gt;  	else</span>
<span class="quote">&gt;  		hdr-&gt;__hyp_stub_vectors = 0;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; diff --git a/arch/arm64/kernel/insn.c b/arch/arm64/kernel/insn.c</span>
<span class="quote">&gt; index 6f2ac4fc66ca..af8967a0343b 100644</span>
<span class="quote">&gt; --- a/arch/arm64/kernel/insn.c</span>
<span class="quote">&gt; +++ b/arch/arm64/kernel/insn.c</span>
<span class="quote">&gt; @@ -97,7 +97,7 @@ static void __kprobes *patch_map(void *addr, int fixmap)</span>
<span class="quote">&gt;  	if (module &amp;&amp; IS_ENABLED(CONFIG_DEBUG_SET_MODULE_RONX))</span>
<span class="quote">&gt;  		page = vmalloc_to_page(addr);</span>
<span class="quote">&gt;  	else if (!module)</span>
<span class="quote">&gt; -		page = pfn_to_page(PHYS_PFN(__pa(addr)));</span>
<span class="quote">&gt; +		page = pfn_to_page(PHYS_PFN(__pa_symbol(addr)));</span>
<span class="quote">&gt;  	else</span>
<span class="quote">&gt;  		return addr;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; diff --git a/arch/arm64/kernel/psci.c b/arch/arm64/kernel/psci.c</span>
<span class="quote">&gt; index 42816bebb1e0..f0f2abb72cf9 100644</span>
<span class="quote">&gt; --- a/arch/arm64/kernel/psci.c</span>
<span class="quote">&gt; +++ b/arch/arm64/kernel/psci.c</span>
<span class="quote">&gt; @@ -45,7 +45,7 @@ static int __init cpu_psci_cpu_prepare(unsigned int cpu)</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  static int cpu_psci_cpu_boot(unsigned int cpu)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt; -	int err = psci_ops.cpu_on(cpu_logical_map(cpu), __pa(secondary_entry));</span>
<span class="quote">&gt; +	int err = psci_ops.cpu_on(cpu_logical_map(cpu), __pa_symbol(secondary_entry));</span>
<span class="quote">&gt;  	if (err)</span>
<span class="quote">&gt;  		pr_err(&quot;failed to boot CPU%d (%d)\n&quot;, cpu, err);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c</span>
<span class="quote">&gt; index f534f492a268..e2dbc02f4792 100644</span>
<span class="quote">&gt; --- a/arch/arm64/kernel/setup.c</span>
<span class="quote">&gt; +++ b/arch/arm64/kernel/setup.c</span>
<span class="quote">&gt; @@ -199,10 +199,10 @@ static void __init request_standard_resources(void)</span>
<span class="quote">&gt;  	struct memblock_region *region;</span>
<span class="quote">&gt;  	struct resource *res;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; -	kernel_code.start   = virt_to_phys(_text);</span>
<span class="quote">&gt; -	kernel_code.end     = virt_to_phys(__init_begin - 1);</span>
<span class="quote">&gt; -	kernel_data.start   = virt_to_phys(_sdata);</span>
<span class="quote">&gt; -	kernel_data.end     = virt_to_phys(_end - 1);</span>
<span class="quote">&gt; +	kernel_code.start   = __pa_symbol(_text);</span>
<span class="quote">&gt; +	kernel_code.end     = __pa_symbol(__init_begin - 1);</span>
<span class="quote">&gt; +	kernel_data.start   = __pa_symbol(_sdata);</span>
<span class="quote">&gt; +	kernel_data.end     = __pa_symbol(_end - 1);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	for_each_memblock(memory, region) {</span>
<span class="quote">&gt;  		res = alloc_bootmem_low(sizeof(*res));</span>
<span class="quote">&gt; diff --git a/arch/arm64/kernel/smp_spin_table.c b/arch/arm64/kernel/smp_spin_table.c</span>
<span class="quote">&gt; index 9a00eee9acc8..25fcccaf79b8 100644</span>
<span class="quote">&gt; --- a/arch/arm64/kernel/smp_spin_table.c</span>
<span class="quote">&gt; +++ b/arch/arm64/kernel/smp_spin_table.c</span>
<span class="quote">&gt; @@ -98,7 +98,7 @@ static int smp_spin_table_cpu_prepare(unsigned int cpu)</span>
<span class="quote">&gt;  	 * boot-loader&#39;s endianess before jumping. This is mandated by</span>
<span class="quote">&gt;  	 * the boot protocol.</span>
<span class="quote">&gt;  	 */</span>
<span class="quote">&gt; -	writeq_relaxed(__pa(secondary_holding_pen), release_addr);</span>
<span class="quote">&gt; +	writeq_relaxed(__pa_symbol(secondary_holding_pen), release_addr);</span>
<span class="quote">&gt;  	__flush_dcache_area((__force void *)release_addr,</span>
<span class="quote">&gt;  			    sizeof(*release_addr));</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; diff --git a/arch/arm64/kernel/vdso.c b/arch/arm64/kernel/vdso.c</span>
<span class="quote">&gt; index a2c2478e7d78..791e87a99148 100644</span>
<span class="quote">&gt; --- a/arch/arm64/kernel/vdso.c</span>
<span class="quote">&gt; +++ b/arch/arm64/kernel/vdso.c</span>
<span class="quote">&gt; @@ -140,11 +140,11 @@ static int __init vdso_init(void)</span>
<span class="quote">&gt;  		return -ENOMEM;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	/* Grab the vDSO data page. */</span>
<span class="quote">&gt; -	vdso_pagelist[0] = pfn_to_page(PHYS_PFN(__pa(vdso_data)));</span>
<span class="quote">&gt; +	vdso_pagelist[0] = pfn_to_page(PHYS_PFN(__pa_symbol(vdso_data)));</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	/* Grab the vDSO code pages. */</span>
<span class="quote">&gt;  	for (i = 0; i &lt; vdso_pages; i++)</span>
<span class="quote">&gt; -		vdso_pagelist[i + 1] = pfn_to_page(PHYS_PFN(__pa(&amp;vdso_start)) + i);</span>
<span class="quote">&gt; +		vdso_pagelist[i + 1] = pfn_to_page(PHYS_PFN(__pa_symbol(&amp;vdso_start)) + i);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	vdso_spec[0].pages = &amp;vdso_pagelist[0];</span>
<span class="quote">&gt;  	vdso_spec[1].pages = &amp;vdso_pagelist[1];</span>
<span class="quote">&gt; diff --git a/arch/arm64/mm/init.c b/arch/arm64/mm/init.c</span>
<span class="quote">&gt; index 3236eb062444..14f426fea61b 100644</span>
<span class="quote">&gt; --- a/arch/arm64/mm/init.c</span>
<span class="quote">&gt; +++ b/arch/arm64/mm/init.c</span>
<span class="quote">&gt; @@ -225,7 +225,7 @@ void __init arm64_memblock_init(void)</span>
<span class="quote">&gt;  	 */</span>
<span class="quote">&gt;  	if (memory_limit != (phys_addr_t)ULLONG_MAX) {</span>
<span class="quote">&gt;  		memblock_mem_limit_remove_map(memory_limit);</span>
<span class="quote">&gt; -		memblock_add(__pa(_text), (u64)(_end - _text));</span>
<span class="quote">&gt; +		memblock_add(__pa_symbol(_text), (u64)(_end - _text));</span>
<span class="quote">&gt;  	}</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	if (IS_ENABLED(CONFIG_BLK_DEV_INITRD) &amp;&amp; initrd_start) {</span>
<span class="quote">&gt; @@ -278,7 +278,7 @@ void __init arm64_memblock_init(void)</span>
<span class="quote">&gt;  	 * Register the kernel text, kernel data, initrd, and initial</span>
<span class="quote">&gt;  	 * pagetables with memblock.</span>
<span class="quote">&gt;  	 */</span>
<span class="quote">&gt; -	memblock_reserve(__pa(_text), _end - _text);</span>
<span class="quote">&gt; +	memblock_reserve(__pa_symbol(_text), _end - _text);</span>
<span class="quote">&gt;  #ifdef CONFIG_BLK_DEV_INITRD</span>
<span class="quote">&gt;  	if (initrd_start) {</span>
<span class="quote">&gt;  		memblock_reserve(initrd_start, initrd_end - initrd_start);</span>
<span class="quote">&gt; @@ -483,7 +483,8 @@ void __init mem_init(void)</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  void free_initmem(void)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt; -	free_reserved_area(__va(__pa(__init_begin)), __va(__pa(__init_end)),</span>
<span class="quote">&gt; +	free_reserved_area(__va(__pa_symbol(__init_begin)),</span>
<span class="quote">&gt; +			   __va(__pa_symbol(__init_end)),</span>
<span class="quote">&gt;  			   0, &quot;unused kernel&quot;);</span>
<span class="quote">&gt;  	/*</span>
<span class="quote">&gt;  	 * Unmap the __init region but leave the VM area in place. This</span>
<span class="quote">&gt; diff --git a/arch/arm64/mm/mmu.c b/arch/arm64/mm/mmu.c</span>
<span class="quote">&gt; index 17243e43184e..f7c0a47a8ebd 100644</span>
<span class="quote">&gt; --- a/arch/arm64/mm/mmu.c</span>
<span class="quote">&gt; +++ b/arch/arm64/mm/mmu.c</span>
<span class="quote">&gt; @@ -359,8 +359,8 @@ static void create_mapping_late(phys_addr_t phys, unsigned long virt,</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  static void __init __map_memblock(pgd_t *pgd, phys_addr_t start, phys_addr_t end)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt; -	unsigned long kernel_start = __pa(_text);</span>
<span class="quote">&gt; -	unsigned long kernel_end = __pa(__init_begin);</span>
<span class="quote">&gt; +	unsigned long kernel_start = __pa_symbol(_text);</span>
<span class="quote">&gt; +	unsigned long kernel_end = __pa_symbol(__init_begin);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	/*</span>
<span class="quote">&gt;  	 * Take care not to create a writable alias for the</span>
<span class="quote">&gt; @@ -427,14 +427,14 @@ void mark_rodata_ro(void)</span>
<span class="quote">&gt;  	unsigned long section_size;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	section_size = (unsigned long)_etext - (unsigned long)_text;</span>
<span class="quote">&gt; -	create_mapping_late(__pa(_text), (unsigned long)_text,</span>
<span class="quote">&gt; +	create_mapping_late(__pa_symbol(_text), (unsigned long)_text,</span>
<span class="quote">&gt;  			    section_size, PAGE_KERNEL_ROX);</span>
<span class="quote">&gt;  	/*</span>
<span class="quote">&gt;  	 * mark .rodata as read only. Use __init_begin rather than __end_rodata</span>
<span class="quote">&gt;  	 * to cover NOTES and EXCEPTION_TABLE.</span>
<span class="quote">&gt;  	 */</span>
<span class="quote">&gt;  	section_size = (unsigned long)__init_begin - (unsigned long)__start_rodata;</span>
<span class="quote">&gt; -	create_mapping_late(__pa(__start_rodata), (unsigned long)__start_rodata,</span>
<span class="quote">&gt; +	create_mapping_late(__pa_symbol(__start_rodata), (unsigned long)__start_rodata,</span>
<span class="quote">&gt;  			    section_size, PAGE_KERNEL_RO);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	/* flush the TLBs after updating live kernel mappings */</span>
<span class="quote">&gt; @@ -446,7 +446,7 @@ void mark_rodata_ro(void)</span>
<span class="quote">&gt;  static void __init map_kernel_segment(pgd_t *pgd, void *va_start, void *va_end,</span>
<span class="quote">&gt;  				      pgprot_t prot, struct vm_struct *vma)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt; -	phys_addr_t pa_start = __pa(va_start);</span>
<span class="quote">&gt; +	phys_addr_t pa_start = __pa_symbol(va_start);</span>
<span class="quote">&gt;  	unsigned long size = va_end - va_start;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	BUG_ON(!PAGE_ALIGNED(pa_start));</span>
<span class="quote">&gt; @@ -494,7 +494,7 @@ static void __init map_kernel(pgd_t *pgd)</span>
<span class="quote">&gt;  		 */</span>
<span class="quote">&gt;  		BUG_ON(!IS_ENABLED(CONFIG_ARM64_16K_PAGES));</span>
<span class="quote">&gt;  		set_pud(pud_set_fixmap_offset(pgd, FIXADDR_START),</span>
<span class="quote">&gt; -			__pud(__pa(bm_pmd) | PUD_TYPE_TABLE));</span>
<span class="quote">&gt; +			__pud(__pa_symbol(bm_pmd) | PUD_TYPE_TABLE));</span>
<span class="quote">&gt;  		pud_clear_fixmap();</span>
<span class="quote">&gt;  	} else {</span>
<span class="quote">&gt;  		BUG();</span>
<span class="quote">&gt; @@ -525,7 +525,7 @@ void __init paging_init(void)</span>
<span class="quote">&gt;  	 */</span>
<span class="quote">&gt;  	cpu_replace_ttbr1(__va(pgd_phys));</span>
<span class="quote">&gt;  	memcpy(swapper_pg_dir, pgd, PAGE_SIZE);</span>
<span class="quote">&gt; -	cpu_replace_ttbr1(swapper_pg_dir);</span>
<span class="quote">&gt; +	cpu_replace_ttbr1(__va(__pa_symbol(swapper_pg_dir)));</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	pgd_clear_fixmap();</span>
<span class="quote">&gt;  	memblock_free(pgd_phys, PAGE_SIZE);</span>
<span class="quote">&gt; @@ -534,7 +534,7 @@ void __init paging_init(void)</span>
<span class="quote">&gt;  	 * We only reuse the PGD from the swapper_pg_dir, not the pud + pmd</span>
<span class="quote">&gt;  	 * allocated with it.</span>
<span class="quote">&gt;  	 */</span>
<span class="quote">&gt; -	memblock_free(__pa(swapper_pg_dir) + PAGE_SIZE,</span>
<span class="quote">&gt; +	memblock_free(__pa_symbol(swapper_pg_dir) + PAGE_SIZE,</span>
<span class="quote">&gt;  		      SWAPPER_DIR_SIZE - PAGE_SIZE);</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; @@ -654,7 +654,7 @@ void __init early_fixmap_init(void)</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	pgd = pgd_offset_k(addr);</span>
<span class="quote">&gt;  	if (CONFIG_PGTABLE_LEVELS &gt; 3 &amp;&amp;</span>
<span class="quote">&gt; -	    !(pgd_none(*pgd) || pgd_page_paddr(*pgd) == __pa(bm_pud))) {</span>
<span class="quote">&gt; +	    !(pgd_none(*pgd) || pgd_page_paddr(*pgd) == __pa_symbol(bm_pud))) {</span>
<span class="quote">&gt;  		/*</span>
<span class="quote">&gt;  		 * We only end up here if the kernel mapping and the fixmap</span>
<span class="quote">&gt;  		 * share the top level pgd entry, which should only happen on</span>
<span class="quote">&gt; @@ -663,12 +663,12 @@ void __init early_fixmap_init(void)</span>
<span class="quote">&gt;  		BUG_ON(!IS_ENABLED(CONFIG_ARM64_16K_PAGES));</span>
<span class="quote">&gt;  		pud = pud_offset_kimg(pgd, addr);</span>
<span class="quote">&gt;  	} else {</span>
<span class="quote">&gt; -		pgd_populate(&amp;init_mm, pgd, bm_pud);</span>
<span class="quote">&gt; +		pgd_populate(&amp;init_mm, pgd, __va(__pa_symbol(bm_pud)));</span>
<span class="quote">&gt;  		pud = fixmap_pud(addr);</span>
<span class="quote">&gt;  	}</span>
<span class="quote">&gt; -	pud_populate(&amp;init_mm, pud, bm_pmd);</span>
<span class="quote">&gt; +	pud_populate(&amp;init_mm, pud, __va(__pa_symbol(bm_pmd)));</span>
<span class="quote">&gt;  	pmd = fixmap_pmd(addr);</span>
<span class="quote">&gt; -	pmd_populate_kernel(&amp;init_mm, pmd, bm_pte);</span>
<span class="quote">&gt; +	pmd_populate_kernel(&amp;init_mm, pmd, __va(__pa_symbol(bm_pte)));</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	/*</span>
<span class="quote">&gt;  	 * The boot-ioremap range spans multiple pmds, for which</span>
<span class="quote">&gt; diff --git a/arch/arm64/mm/physaddr.c b/arch/arm64/mm/physaddr.c</span>
<span class="quote">&gt; index 874c78201a2b..98dae943e496 100644</span>
<span class="quote">&gt; --- a/arch/arm64/mm/physaddr.c</span>
<span class="quote">&gt; +++ b/arch/arm64/mm/physaddr.c</span>
<span class="quote">&gt; @@ -14,8 +14,8 @@ unsigned long __virt_to_phys(unsigned long x)</span>
<span class="quote">&gt;  		 */</span>
<span class="quote">&gt;  		return (__x &amp; ~PAGE_OFFSET) + PHYS_OFFSET;</span>
<span class="quote">&gt;  	} else {</span>
<span class="quote">&gt; -		VIRTUAL_BUG_ON(x &lt; kimage_vaddr || x &gt;= (unsigned long)_end);</span>
<span class="quote">&gt; -		return (__x - kimage_voffset);</span>
<span class="quote">&gt; +		WARN_ON(1);</span>

Was the deletion of the BUG_ON here intentional? VIRTUAL_BUG_ON
is the check enabled by CONFIG_DEBUG_VIRTUAL vs just CONFIG_DEBUG_VM.
I intentionally kept CONFIG_DEBUG_VIRTUAL separate since the checks
are expensive.
<span class="quote">
&gt; +		return __phys_addr_symbol(x);</span>
<span class="quote">&gt;  	}</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;  EXPORT_SYMBOL(__virt_to_phys);</span>
<span class="quote">&gt; diff --git a/drivers/firmware/psci.c b/drivers/firmware/psci.c</span>
<span class="quote">&gt; index 8263429e21b8..9defbe243c2f 100644</span>
<span class="quote">&gt; --- a/drivers/firmware/psci.c</span>
<span class="quote">&gt; +++ b/drivers/firmware/psci.c</span>
<span class="quote">&gt; @@ -383,7 +383,7 @@ static int psci_suspend_finisher(unsigned long index)</span>
<span class="quote">&gt;  	u32 *state = __this_cpu_read(psci_power_state);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	return psci_ops.cpu_suspend(state[index - 1],</span>
<span class="quote">&gt; -				    virt_to_phys(cpu_resume));</span>
<span class="quote">&gt; +				    __pa_symbol(cpu_resume));</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  int psci_cpu_suspend_enter(unsigned long index)</span>
<span class="quote">&gt; </span>

Thanks,
Laura
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=352">Catalin Marinas</a> - Nov. 16, 2016, 5:32 p.m.</div>
<pre class="content">
On Tue, Nov 15, 2016 at 04:09:07PM -0800, Laura Abbott wrote:
<span class="quote">&gt; On 11/15/2016 10:35 AM, Catalin Marinas wrote:</span>
<span class="quote">&gt; &gt; I&#39;m fine with __pa_symbol use entirely from under arch/arm64. But if you</span>
<span class="quote">&gt; &gt; want to use __pa_symbol, I tried to change most (all?) places where</span>
<span class="quote">&gt; &gt; necessary, together with making virt_to_phys() only deal with the kernel</span>
<span class="quote">&gt; &gt; linear mapping. Not sure it looks cleaner, especially the</span>
<span class="quote">&gt; &gt; __va(__pa_symbol()) cases (we could replace the latter with another</span>
<span class="quote">&gt; &gt; macro and proper comment):</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; I agree everything should be converted over, I was considering doing</span>
<span class="quote">&gt; that in a separate patch but this covers everything nicely. Are you</span>
<span class="quote">&gt; okay with me folding this in? (Few comments below)</span>

Yes. I would also like Ard to review it since he introduced the current
__virt_to_phys() macro.
<span class="quote">
&gt; &gt; diff --git a/arch/arm64/include/asm/memory.h b/arch/arm64/include/asm/memory.h</span>
<span class="quote">&gt; &gt; index eac3dbb7e313..e02f45e5ee1b 100644</span>
<span class="quote">&gt; &gt; --- a/arch/arm64/include/asm/memory.h</span>
<span class="quote">&gt; &gt; +++ b/arch/arm64/include/asm/memory.h</span>
<span class="quote">&gt; &gt; @@ -169,15 +169,22 @@ extern u64			kimage_voffset;</span>
<span class="quote">&gt; &gt;   */</span>
<span class="quote">&gt; &gt;  #define __virt_to_phys_nodebug(x) ({					\</span>
<span class="quote">&gt; &gt;  	phys_addr_t __x = (phys_addr_t)(x);				\</span>
<span class="quote">&gt; &gt; -	__x &amp; BIT(VA_BITS - 1) ? (__x &amp; ~PAGE_OFFSET) + PHYS_OFFSET :	\</span>
<span class="quote">&gt; &gt; -				 (__x - kimage_voffset); })</span>
<span class="quote">&gt; &gt; +	VM_BUG_ON(!(__x &amp; BIT(VA_BITS - 1)));				\</span>
<span class="quote">&gt; &gt; +	((__x &amp; ~PAGE_OFFSET) + PHYS_OFFSET);				\</span>
<span class="quote">&gt; &gt; +})</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; I do think this is easier to understand vs the ternary operator.</span>
<span class="quote">&gt; I&#39;ll add a comment detailing the use of __pa vs __pa_symbol somewhere</span>
<span class="quote">&gt; as well.</span>

Of course, a comment is welcome (I just did a quick hack to check that
it works).
<span class="quote">
&gt; &gt; --- a/arch/arm64/include/asm/mmu_context.h</span>
<span class="quote">&gt; &gt; +++ b/arch/arm64/include/asm/mmu_context.h</span>
<span class="quote">&gt; &gt; @@ -44,7 +44,7 @@ static inline void contextidr_thread_switch(struct task_struct *next)</span>
<span class="quote">&gt; &gt;   */</span>
<span class="quote">&gt; &gt;  static inline void cpu_set_reserved_ttbr0(void)</span>
<span class="quote">&gt; &gt;  {</span>
<span class="quote">&gt; &gt; -	unsigned long ttbr = virt_to_phys(empty_zero_page);</span>
<span class="quote">&gt; &gt; +	unsigned long ttbr = __pa_symbol(empty_zero_page);</span>
<span class="quote">&gt; &gt;  </span>
<span class="quote">&gt; &gt;  	write_sysreg(ttbr, ttbr0_el1);</span>
<span class="quote">&gt; &gt;  	isb();</span>
<span class="quote">&gt; &gt; @@ -113,7 +113,7 @@ static inline void cpu_install_idmap(void)</span>
<span class="quote">&gt; &gt;  	local_flush_tlb_all();</span>
<span class="quote">&gt; &gt;  	cpu_set_idmap_tcr_t0sz();</span>
<span class="quote">&gt; &gt;  </span>
<span class="quote">&gt; &gt; -	cpu_switch_mm(idmap_pg_dir, &amp;init_mm);</span>
<span class="quote">&gt; &gt; +	cpu_switch_mm(__va(__pa_symbol(idmap_pg_dir)), &amp;init_mm);</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Yes, the __va(__pa_symbol(..)) idiom needs to be macroized and commented...</span>

Indeed. At the same time we should also replace the LMADDR macro in
hibernate.c with whatever you come up with.
<span class="quote">
&gt; &gt; diff --git a/arch/arm64/kernel/hibernate.c b/arch/arm64/kernel/hibernate.c</span>
<span class="quote">&gt; &gt; index d55a7b09959b..81c03c74e5fe 100644</span>
<span class="quote">&gt; &gt; --- a/arch/arm64/kernel/hibernate.c</span>
<span class="quote">&gt; &gt; +++ b/arch/arm64/kernel/hibernate.c</span>
<span class="quote">&gt; &gt; @@ -51,7 +51,7 @@</span>
<span class="quote">&gt; &gt;  extern int in_suspend;</span>
<span class="quote">&gt; &gt;  </span>
<span class="quote">&gt; &gt;  /* Find a symbols alias in the linear map */</span>
<span class="quote">&gt; &gt; -#define LMADDR(x)	phys_to_virt(virt_to_phys(x))</span>
<span class="quote">&gt; &gt; +#define LMADDR(x)	__va(__pa_symbol(x))</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; ...Perhaps just borrowing this macro?</span>

Yes but I don&#39;t particularly like the name, especially since it goes
into a .h file. Maybe __lm_sym_addr() or something else if you have a
better idea.
<span class="quote">
&gt; &gt; diff --git a/arch/arm64/mm/physaddr.c b/arch/arm64/mm/physaddr.c</span>
<span class="quote">&gt; &gt; index 874c78201a2b..98dae943e496 100644</span>
<span class="quote">&gt; &gt; --- a/arch/arm64/mm/physaddr.c</span>
<span class="quote">&gt; &gt; +++ b/arch/arm64/mm/physaddr.c</span>
<span class="quote">&gt; &gt; @@ -14,8 +14,8 @@ unsigned long __virt_to_phys(unsigned long x)</span>
<span class="quote">&gt; &gt;  		 */</span>
<span class="quote">&gt; &gt;  		return (__x &amp; ~PAGE_OFFSET) + PHYS_OFFSET;</span>
<span class="quote">&gt; &gt;  	} else {</span>
<span class="quote">&gt; &gt; -		VIRTUAL_BUG_ON(x &lt; kimage_vaddr || x &gt;= (unsigned long)_end);</span>
<span class="quote">&gt; &gt; -		return (__x - kimage_voffset);</span>
<span class="quote">&gt; &gt; +		WARN_ON(1);</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Was the deletion of the BUG_ON here intentional? VIRTUAL_BUG_ON</span>
<span class="quote">&gt; is the check enabled by CONFIG_DEBUG_VIRTUAL vs just CONFIG_DEBUG_VM.</span>
<span class="quote">&gt; I intentionally kept CONFIG_DEBUG_VIRTUAL separate since the checks</span>
<span class="quote">&gt; are expensive.</span>

I wanted to always get a warning but fall back to __phys_addr_symbol()
so that I can track down other uses of __virt_to_phys() on kernel
symbols without killing the kernel. A better option would have been
VIRTUAL_WARN_ON (or *_ONCE) but we don&#39;t have it. VM_WARN_ON, as you
said, is independent of CONFIG_DEBUG_VIRTUAL.

We could as well kill the system with VIRTUAL_BUG_ON in this case but I
thought we should be more gentle until all the __virt_to_phys use-cases
are sorted out.
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=66681">Ard Biesheuvel</a> - Nov. 18, 2016, 10:23 a.m.</div>
<pre class="content">
On 16 November 2016 at 17:32, Catalin Marinas &lt;catalin.marinas@arm.com&gt; wrote:
<span class="quote">&gt; On Tue, Nov 15, 2016 at 04:09:07PM -0800, Laura Abbott wrote:</span>
<span class="quote">&gt;&gt; On 11/15/2016 10:35 AM, Catalin Marinas wrote:</span>
<span class="quote">&gt;&gt; &gt; I&#39;m fine with __pa_symbol use entirely from under arch/arm64. But if you</span>
<span class="quote">&gt;&gt; &gt; want to use __pa_symbol, I tried to change most (all?) places where</span>
<span class="quote">&gt;&gt; &gt; necessary, together with making virt_to_phys() only deal with the kernel</span>
<span class="quote">&gt;&gt; &gt; linear mapping. Not sure it looks cleaner, especially the</span>
<span class="quote">&gt;&gt; &gt; __va(__pa_symbol()) cases (we could replace the latter with another</span>
<span class="quote">&gt;&gt; &gt; macro and proper comment):</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; I agree everything should be converted over, I was considering doing</span>
<span class="quote">&gt;&gt; that in a separate patch but this covers everything nicely. Are you</span>
<span class="quote">&gt;&gt; okay with me folding this in? (Few comments below)</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; Yes. I would also like Ard to review it since he introduced the current</span>
<span class="quote">&gt; __virt_to_phys() macro.</span>
<span class="quote">&gt;</span>

I think this is a clear improvement. I didn&#39;t dare to propose it at
the time, due to the fallout, but it is obviously much better to have
separate accessors than to have runtime tests to decide something that
is already known at compile time. My only concern is potential uses in
generic code: I think there may be something in the handling of
initramfs, or freeing the __init segment (I know it had &#39;init&#39; in the
name :-)) that refers to the physical address of symbols, but I don&#39;t
remember exactly what it is.

Did you test it with a initramfs?
<span class="quote">
&gt;&gt; &gt; diff --git a/arch/arm64/include/asm/memory.h b/arch/arm64/include/asm/memory.h</span>
<span class="quote">&gt;&gt; &gt; index eac3dbb7e313..e02f45e5ee1b 100644</span>
<span class="quote">&gt;&gt; &gt; --- a/arch/arm64/include/asm/memory.h</span>
<span class="quote">&gt;&gt; &gt; +++ b/arch/arm64/include/asm/memory.h</span>
<span class="quote">&gt;&gt; &gt; @@ -169,15 +169,22 @@ extern u64                    kimage_voffset;</span>
<span class="quote">&gt;&gt; &gt;   */</span>
<span class="quote">&gt;&gt; &gt;  #define __virt_to_phys_nodebug(x) ({                                       \</span>
<span class="quote">&gt;&gt; &gt;     phys_addr_t __x = (phys_addr_t)(x);                             \</span>
<span class="quote">&gt;&gt; &gt; -   __x &amp; BIT(VA_BITS - 1) ? (__x &amp; ~PAGE_OFFSET) + PHYS_OFFSET :   \</span>
<span class="quote">&gt;&gt; &gt; -                            (__x - kimage_voffset); })</span>
<span class="quote">&gt;&gt; &gt; +   VM_BUG_ON(!(__x &amp; BIT(VA_BITS - 1)));                           \</span>
<span class="quote">&gt;&gt; &gt; +   ((__x &amp; ~PAGE_OFFSET) + PHYS_OFFSET);                           \</span>
<span class="quote">&gt;&gt; &gt; +})</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; I do think this is easier to understand vs the ternary operator.</span>
<span class="quote">&gt;&gt; I&#39;ll add a comment detailing the use of __pa vs __pa_symbol somewhere</span>
<span class="quote">&gt;&gt; as well.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; Of course, a comment is welcome (I just did a quick hack to check that</span>
<span class="quote">&gt; it works).</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;&gt; &gt; --- a/arch/arm64/include/asm/mmu_context.h</span>
<span class="quote">&gt;&gt; &gt; +++ b/arch/arm64/include/asm/mmu_context.h</span>
<span class="quote">&gt;&gt; &gt; @@ -44,7 +44,7 @@ static inline void contextidr_thread_switch(struct task_struct *next)</span>
<span class="quote">&gt;&gt; &gt;   */</span>
<span class="quote">&gt;&gt; &gt;  static inline void cpu_set_reserved_ttbr0(void)</span>
<span class="quote">&gt;&gt; &gt;  {</span>
<span class="quote">&gt;&gt; &gt; -   unsigned long ttbr = virt_to_phys(empty_zero_page);</span>
<span class="quote">&gt;&gt; &gt; +   unsigned long ttbr = __pa_symbol(empty_zero_page);</span>
<span class="quote">&gt;&gt; &gt;</span>
<span class="quote">&gt;&gt; &gt;     write_sysreg(ttbr, ttbr0_el1);</span>
<span class="quote">&gt;&gt; &gt;     isb();</span>
<span class="quote">&gt;&gt; &gt; @@ -113,7 +113,7 @@ static inline void cpu_install_idmap(void)</span>
<span class="quote">&gt;&gt; &gt;     local_flush_tlb_all();</span>
<span class="quote">&gt;&gt; &gt;     cpu_set_idmap_tcr_t0sz();</span>
<span class="quote">&gt;&gt; &gt;</span>
<span class="quote">&gt;&gt; &gt; -   cpu_switch_mm(idmap_pg_dir, &amp;init_mm);</span>
<span class="quote">&gt;&gt; &gt; +   cpu_switch_mm(__va(__pa_symbol(idmap_pg_dir)), &amp;init_mm);</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; Yes, the __va(__pa_symbol(..)) idiom needs to be macroized and commented...</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; Indeed. At the same time we should also replace the LMADDR macro in</span>
<span class="quote">&gt; hibernate.c with whatever you come up with.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;&gt; &gt; diff --git a/arch/arm64/kernel/hibernate.c b/arch/arm64/kernel/hibernate.c</span>
<span class="quote">&gt;&gt; &gt; index d55a7b09959b..81c03c74e5fe 100644</span>
<span class="quote">&gt;&gt; &gt; --- a/arch/arm64/kernel/hibernate.c</span>
<span class="quote">&gt;&gt; &gt; +++ b/arch/arm64/kernel/hibernate.c</span>
<span class="quote">&gt;&gt; &gt; @@ -51,7 +51,7 @@</span>
<span class="quote">&gt;&gt; &gt;  extern int in_suspend;</span>
<span class="quote">&gt;&gt; &gt;</span>
<span class="quote">&gt;&gt; &gt;  /* Find a symbols alias in the linear map */</span>
<span class="quote">&gt;&gt; &gt; -#define LMADDR(x)  phys_to_virt(virt_to_phys(x))</span>
<span class="quote">&gt;&gt; &gt; +#define LMADDR(x)  __va(__pa_symbol(x))</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; ...Perhaps just borrowing this macro?</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; Yes but I don&#39;t particularly like the name, especially since it goes</span>
<span class="quote">&gt; into a .h file. Maybe __lm_sym_addr() or something else if you have a</span>
<span class="quote">&gt; better idea.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;&gt; &gt; diff --git a/arch/arm64/mm/physaddr.c b/arch/arm64/mm/physaddr.c</span>
<span class="quote">&gt;&gt; &gt; index 874c78201a2b..98dae943e496 100644</span>
<span class="quote">&gt;&gt; &gt; --- a/arch/arm64/mm/physaddr.c</span>
<span class="quote">&gt;&gt; &gt; +++ b/arch/arm64/mm/physaddr.c</span>
<span class="quote">&gt;&gt; &gt; @@ -14,8 +14,8 @@ unsigned long __virt_to_phys(unsigned long x)</span>
<span class="quote">&gt;&gt; &gt;              */</span>
<span class="quote">&gt;&gt; &gt;             return (__x &amp; ~PAGE_OFFSET) + PHYS_OFFSET;</span>
<span class="quote">&gt;&gt; &gt;     } else {</span>
<span class="quote">&gt;&gt; &gt; -           VIRTUAL_BUG_ON(x &lt; kimage_vaddr || x &gt;= (unsigned long)_end);</span>
<span class="quote">&gt;&gt; &gt; -           return (__x - kimage_voffset);</span>
<span class="quote">&gt;&gt; &gt; +           WARN_ON(1);</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; Was the deletion of the BUG_ON here intentional? VIRTUAL_BUG_ON</span>
<span class="quote">&gt;&gt; is the check enabled by CONFIG_DEBUG_VIRTUAL vs just CONFIG_DEBUG_VM.</span>
<span class="quote">&gt;&gt; I intentionally kept CONFIG_DEBUG_VIRTUAL separate since the checks</span>
<span class="quote">&gt;&gt; are expensive.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; I wanted to always get a warning but fall back to __phys_addr_symbol()</span>
<span class="quote">&gt; so that I can track down other uses of __virt_to_phys() on kernel</span>
<span class="quote">&gt; symbols without killing the kernel. A better option would have been</span>
<span class="quote">&gt; VIRTUAL_WARN_ON (or *_ONCE) but we don&#39;t have it. VM_WARN_ON, as you</span>
<span class="quote">&gt; said, is independent of CONFIG_DEBUG_VIRTUAL.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; We could as well kill the system with VIRTUAL_BUG_ON in this case but I</span>
<span class="quote">&gt; thought we should be more gentle until all the __virt_to_phys use-cases</span>
<span class="quote">&gt; are sorted out.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; --</span>
<span class="quote">&gt; Catalin</span>
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/arch/arm64/include/asm/kvm_mmu.h b/arch/arm64/include/asm/kvm_mmu.h</span>
<span class="p_header">index a79b969c26fc..fa6c44ebb51f 100644</span>
<span class="p_header">--- a/arch/arm64/include/asm/kvm_mmu.h</span>
<span class="p_header">+++ b/arch/arm64/include/asm/kvm_mmu.h</span>
<span class="p_chunk">@@ -47,7 +47,7 @@</span> <span class="p_context"></span>
  * If the page is in the bottom half, we have to use the top half. If
  * the page is in the top half, we have to use the bottom half:
  *
<span class="p_del">- * T = __virt_to_phys(__hyp_idmap_text_start)</span>
<span class="p_add">+ * T = __pa_symbol(__hyp_idmap_text_start)</span>
  * if (T &amp; BIT(VA_BITS - 1))
  *	HYP_VA_MIN = 0  //idmap in upper half
  * else
<span class="p_chunk">@@ -271,7 +271,7 @@</span> <span class="p_context"> static inline void __kvm_flush_dcache_pud(pud_t pud)</span>
 	kvm_flush_dcache_to_poc(page_address(page), PUD_SIZE);
 }
 
<span class="p_del">-#define kvm_virt_to_phys(x)		__virt_to_phys((unsigned long)(x))</span>
<span class="p_add">+#define kvm_virt_to_phys(x)		__pa_symbol((unsigned long)(x))</span>
 
 void kvm_set_way_flush(struct kvm_vcpu *vcpu);
 void kvm_toggle_cache(struct kvm_vcpu *vcpu, bool was_enabled);
<span class="p_header">diff --git a/arch/arm64/include/asm/memory.h b/arch/arm64/include/asm/memory.h</span>
<span class="p_header">index eac3dbb7e313..e02f45e5ee1b 100644</span>
<span class="p_header">--- a/arch/arm64/include/asm/memory.h</span>
<span class="p_header">+++ b/arch/arm64/include/asm/memory.h</span>
<span class="p_chunk">@@ -169,15 +169,22 @@</span> <span class="p_context"> extern u64			kimage_voffset;</span>
  */
 #define __virt_to_phys_nodebug(x) ({					\
 	phys_addr_t __x = (phys_addr_t)(x);				\
<span class="p_del">-	__x &amp; BIT(VA_BITS - 1) ? (__x &amp; ~PAGE_OFFSET) + PHYS_OFFSET :	\</span>
<span class="p_del">-				 (__x - kimage_voffset); })</span>
<span class="p_add">+	VM_BUG_ON(!(__x &amp; BIT(VA_BITS - 1)));				\</span>
<span class="p_add">+	((__x &amp; ~PAGE_OFFSET) + PHYS_OFFSET);				\</span>
<span class="p_add">+})</span>
<span class="p_add">+</span>
<span class="p_add">+#define __pa_symbol_nodebug(x) ({					\</span>
<span class="p_add">+	phys_addr_t __x = (phys_addr_t)(x);				\</span>
<span class="p_add">+	VM_BUG_ON(__x &amp; BIT(VA_BITS - 1));				\</span>
<span class="p_add">+	(__x - kimage_voffset);						\</span>
<span class="p_add">+})</span>
 
 #ifdef CONFIG_DEBUG_VIRTUAL
 extern unsigned long __virt_to_phys(unsigned long x);
 extern unsigned long __phys_addr_symbol(unsigned long x);
 #else
 #define __virt_to_phys(x)	__virt_to_phys_nodebug(x)
<span class="p_del">-#define __phys_addr_symbol	__pa</span>
<span class="p_add">+#define __phys_addr_symbol(x)	__pa_symbol_nodebug(x)</span>
 #endif
 
 #define __phys_to_virt(x)	((unsigned long)((x) - PHYS_OFFSET) | PAGE_OFFSET)
<span class="p_chunk">@@ -210,7 +217,7 @@</span> <span class="p_context"> static inline void *phys_to_virt(phys_addr_t x)</span>
  * Drivers should NOT use these either.
  */
 #define __pa(x)			__virt_to_phys((unsigned long)(x))
<span class="p_del">-#define __pa_symbol(x)  __phys_addr_symbol(RELOC_HIDE((unsigned long)(x), 0))</span>
<span class="p_add">+#define __pa_symbol(x)		__phys_addr_symbol(RELOC_HIDE((unsigned long)(x), 0))</span>
 #define __pa_nodebug(x)		__virt_to_phys_nodebug((unsigned long)(x))
 #define __va(x)			((void *)__phys_to_virt((phys_addr_t)(x)))
 #define pfn_to_kaddr(pfn)	__va((pfn) &lt;&lt; PAGE_SHIFT)
<span class="p_header">diff --git a/arch/arm64/include/asm/mmu_context.h b/arch/arm64/include/asm/mmu_context.h</span>
<span class="p_header">index a50185375f09..6cf3763c6e11 100644</span>
<span class="p_header">--- a/arch/arm64/include/asm/mmu_context.h</span>
<span class="p_header">+++ b/arch/arm64/include/asm/mmu_context.h</span>
<span class="p_chunk">@@ -44,7 +44,7 @@</span> <span class="p_context"> static inline void contextidr_thread_switch(struct task_struct *next)</span>
  */
 static inline void cpu_set_reserved_ttbr0(void)
 {
<span class="p_del">-	unsigned long ttbr = virt_to_phys(empty_zero_page);</span>
<span class="p_add">+	unsigned long ttbr = __pa_symbol(empty_zero_page);</span>
 
 	write_sysreg(ttbr, ttbr0_el1);
 	isb();
<span class="p_chunk">@@ -113,7 +113,7 @@</span> <span class="p_context"> static inline void cpu_install_idmap(void)</span>
 	local_flush_tlb_all();
 	cpu_set_idmap_tcr_t0sz();
 
<span class="p_del">-	cpu_switch_mm(idmap_pg_dir, &amp;init_mm);</span>
<span class="p_add">+	cpu_switch_mm(__va(__pa_symbol(idmap_pg_dir)), &amp;init_mm);</span>
 }
 
 /*
<span class="p_chunk">@@ -128,7 +128,7 @@</span> <span class="p_context"> static inline void cpu_replace_ttbr1(pgd_t *pgd)</span>
 
 	phys_addr_t pgd_phys = virt_to_phys(pgd);
 
<span class="p_del">-	replace_phys = (void *)virt_to_phys(idmap_cpu_replace_ttbr1);</span>
<span class="p_add">+	replace_phys = (void *)__pa_symbol(idmap_cpu_replace_ttbr1);</span>
 
 	cpu_install_idmap();
 	replace_phys(pgd_phys);
<span class="p_header">diff --git a/arch/arm64/include/asm/pgtable.h b/arch/arm64/include/asm/pgtable.h</span>
<span class="p_header">index ffbb9a520563..c2041a39a3e3 100644</span>
<span class="p_header">--- a/arch/arm64/include/asm/pgtable.h</span>
<span class="p_header">+++ b/arch/arm64/include/asm/pgtable.h</span>
<span class="p_chunk">@@ -52,7 +52,7 @@</span> <span class="p_context"> extern void __pgd_error(const char *file, int line, unsigned long val);</span>
  * for zero-mapped memory areas etc..
  */
 extern unsigned long empty_zero_page[PAGE_SIZE / sizeof(unsigned long)];
<span class="p_del">-#define ZERO_PAGE(vaddr)	pfn_to_page(PHYS_PFN(__pa(empty_zero_page)))</span>
<span class="p_add">+#define ZERO_PAGE(vaddr)	pfn_to_page(PHYS_PFN(__pa_symbol(empty_zero_page)))</span>
 
 #define pte_ERROR(pte)		__pte_error(__FILE__, __LINE__, pte_val(pte))
 
<span class="p_header">diff --git a/arch/arm64/kernel/acpi_parking_protocol.c b/arch/arm64/kernel/acpi_parking_protocol.c</span>
<span class="p_header">index a32b4011d711..df58310660c6 100644</span>
<span class="p_header">--- a/arch/arm64/kernel/acpi_parking_protocol.c</span>
<span class="p_header">+++ b/arch/arm64/kernel/acpi_parking_protocol.c</span>
<span class="p_chunk">@@ -109,7 +109,7 @@</span> <span class="p_context"> static int acpi_parking_protocol_cpu_boot(unsigned int cpu)</span>
 	 * that read this address need to convert this address to the
 	 * Boot-Loader&#39;s endianness before jumping.
 	 */
<span class="p_del">-	writeq_relaxed(__pa(secondary_entry), &amp;mailbox-&gt;entry_point);</span>
<span class="p_add">+	writeq_relaxed(__pa_symbol(secondary_entry), &amp;mailbox-&gt;entry_point);</span>
 	writel_relaxed(cpu_entry-&gt;gic_cpu_id, &amp;mailbox-&gt;cpu_id);
 
 	arch_send_wakeup_ipi_mask(cpumask_of(cpu));
<span class="p_header">diff --git a/arch/arm64/kernel/cpufeature.c b/arch/arm64/kernel/cpufeature.c</span>
<span class="p_header">index c02504ea304b..6ccadf255fba 100644</span>
<span class="p_header">--- a/arch/arm64/kernel/cpufeature.c</span>
<span class="p_header">+++ b/arch/arm64/kernel/cpufeature.c</span>
<span class="p_chunk">@@ -736,7 +736,7 @@</span> <span class="p_context"> static bool runs_at_el2(const struct arm64_cpu_capabilities *entry, int __unused</span>
 static bool hyp_offset_low(const struct arm64_cpu_capabilities *entry,
 			   int __unused)
 {
<span class="p_del">-	phys_addr_t idmap_addr = virt_to_phys(__hyp_idmap_text_start);</span>
<span class="p_add">+	phys_addr_t idmap_addr = __pa_symbol(__hyp_idmap_text_start);</span>
 
 	/*
 	 * Activate the lower HYP offset only if:
<span class="p_header">diff --git a/arch/arm64/kernel/hibernate.c b/arch/arm64/kernel/hibernate.c</span>
<span class="p_header">index d55a7b09959b..81c03c74e5fe 100644</span>
<span class="p_header">--- a/arch/arm64/kernel/hibernate.c</span>
<span class="p_header">+++ b/arch/arm64/kernel/hibernate.c</span>
<span class="p_chunk">@@ -51,7 +51,7 @@</span> <span class="p_context"></span>
 extern int in_suspend;
 
 /* Find a symbols alias in the linear map */
<span class="p_del">-#define LMADDR(x)	phys_to_virt(virt_to_phys(x))</span>
<span class="p_add">+#define LMADDR(x)	__va(__pa_symbol(x))</span>
 
 /* Do we need to reset el2? */
 #define el2_reset_needed() (is_hyp_mode_available() &amp;&amp; !is_kernel_in_hyp_mode())
<span class="p_chunk">@@ -125,12 +125,12 @@</span> <span class="p_context"> int arch_hibernation_header_save(void *addr, unsigned int max_size)</span>
 		return -EOVERFLOW;
 
 	arch_hdr_invariants(&amp;hdr-&gt;invariants);
<span class="p_del">-	hdr-&gt;ttbr1_el1		= virt_to_phys(swapper_pg_dir);</span>
<span class="p_add">+	hdr-&gt;ttbr1_el1		= __pa_symbol(swapper_pg_dir);</span>
 	hdr-&gt;reenter_kernel	= _cpu_resume;
 
 	/* We can&#39;t use __hyp_get_vectors() because kvm may still be loaded */
 	if (el2_reset_needed())
<span class="p_del">-		hdr-&gt;__hyp_stub_vectors = virt_to_phys(__hyp_stub_vectors);</span>
<span class="p_add">+		hdr-&gt;__hyp_stub_vectors = __pa_symbol(__hyp_stub_vectors);</span>
 	else
 		hdr-&gt;__hyp_stub_vectors = 0;
 
<span class="p_header">diff --git a/arch/arm64/kernel/insn.c b/arch/arm64/kernel/insn.c</span>
<span class="p_header">index 6f2ac4fc66ca..af8967a0343b 100644</span>
<span class="p_header">--- a/arch/arm64/kernel/insn.c</span>
<span class="p_header">+++ b/arch/arm64/kernel/insn.c</span>
<span class="p_chunk">@@ -97,7 +97,7 @@</span> <span class="p_context"> static void __kprobes *patch_map(void *addr, int fixmap)</span>
 	if (module &amp;&amp; IS_ENABLED(CONFIG_DEBUG_SET_MODULE_RONX))
 		page = vmalloc_to_page(addr);
 	else if (!module)
<span class="p_del">-		page = pfn_to_page(PHYS_PFN(__pa(addr)));</span>
<span class="p_add">+		page = pfn_to_page(PHYS_PFN(__pa_symbol(addr)));</span>
 	else
 		return addr;
 
<span class="p_header">diff --git a/arch/arm64/kernel/psci.c b/arch/arm64/kernel/psci.c</span>
<span class="p_header">index 42816bebb1e0..f0f2abb72cf9 100644</span>
<span class="p_header">--- a/arch/arm64/kernel/psci.c</span>
<span class="p_header">+++ b/arch/arm64/kernel/psci.c</span>
<span class="p_chunk">@@ -45,7 +45,7 @@</span> <span class="p_context"> static int __init cpu_psci_cpu_prepare(unsigned int cpu)</span>
 
 static int cpu_psci_cpu_boot(unsigned int cpu)
 {
<span class="p_del">-	int err = psci_ops.cpu_on(cpu_logical_map(cpu), __pa(secondary_entry));</span>
<span class="p_add">+	int err = psci_ops.cpu_on(cpu_logical_map(cpu), __pa_symbol(secondary_entry));</span>
 	if (err)
 		pr_err(&quot;failed to boot CPU%d (%d)\n&quot;, cpu, err);
 
<span class="p_header">diff --git a/arch/arm64/kernel/setup.c b/arch/arm64/kernel/setup.c</span>
<span class="p_header">index f534f492a268..e2dbc02f4792 100644</span>
<span class="p_header">--- a/arch/arm64/kernel/setup.c</span>
<span class="p_header">+++ b/arch/arm64/kernel/setup.c</span>
<span class="p_chunk">@@ -199,10 +199,10 @@</span> <span class="p_context"> static void __init request_standard_resources(void)</span>
 	struct memblock_region *region;
 	struct resource *res;
 
<span class="p_del">-	kernel_code.start   = virt_to_phys(_text);</span>
<span class="p_del">-	kernel_code.end     = virt_to_phys(__init_begin - 1);</span>
<span class="p_del">-	kernel_data.start   = virt_to_phys(_sdata);</span>
<span class="p_del">-	kernel_data.end     = virt_to_phys(_end - 1);</span>
<span class="p_add">+	kernel_code.start   = __pa_symbol(_text);</span>
<span class="p_add">+	kernel_code.end     = __pa_symbol(__init_begin - 1);</span>
<span class="p_add">+	kernel_data.start   = __pa_symbol(_sdata);</span>
<span class="p_add">+	kernel_data.end     = __pa_symbol(_end - 1);</span>
 
 	for_each_memblock(memory, region) {
 		res = alloc_bootmem_low(sizeof(*res));
<span class="p_header">diff --git a/arch/arm64/kernel/smp_spin_table.c b/arch/arm64/kernel/smp_spin_table.c</span>
<span class="p_header">index 9a00eee9acc8..25fcccaf79b8 100644</span>
<span class="p_header">--- a/arch/arm64/kernel/smp_spin_table.c</span>
<span class="p_header">+++ b/arch/arm64/kernel/smp_spin_table.c</span>
<span class="p_chunk">@@ -98,7 +98,7 @@</span> <span class="p_context"> static int smp_spin_table_cpu_prepare(unsigned int cpu)</span>
 	 * boot-loader&#39;s endianess before jumping. This is mandated by
 	 * the boot protocol.
 	 */
<span class="p_del">-	writeq_relaxed(__pa(secondary_holding_pen), release_addr);</span>
<span class="p_add">+	writeq_relaxed(__pa_symbol(secondary_holding_pen), release_addr);</span>
 	__flush_dcache_area((__force void *)release_addr,
 			    sizeof(*release_addr));
 
<span class="p_header">diff --git a/arch/arm64/kernel/vdso.c b/arch/arm64/kernel/vdso.c</span>
<span class="p_header">index a2c2478e7d78..791e87a99148 100644</span>
<span class="p_header">--- a/arch/arm64/kernel/vdso.c</span>
<span class="p_header">+++ b/arch/arm64/kernel/vdso.c</span>
<span class="p_chunk">@@ -140,11 +140,11 @@</span> <span class="p_context"> static int __init vdso_init(void)</span>
 		return -ENOMEM;
 
 	/* Grab the vDSO data page. */
<span class="p_del">-	vdso_pagelist[0] = pfn_to_page(PHYS_PFN(__pa(vdso_data)));</span>
<span class="p_add">+	vdso_pagelist[0] = pfn_to_page(PHYS_PFN(__pa_symbol(vdso_data)));</span>
 
 	/* Grab the vDSO code pages. */
 	for (i = 0; i &lt; vdso_pages; i++)
<span class="p_del">-		vdso_pagelist[i + 1] = pfn_to_page(PHYS_PFN(__pa(&amp;vdso_start)) + i);</span>
<span class="p_add">+		vdso_pagelist[i + 1] = pfn_to_page(PHYS_PFN(__pa_symbol(&amp;vdso_start)) + i);</span>
 
 	vdso_spec[0].pages = &amp;vdso_pagelist[0];
 	vdso_spec[1].pages = &amp;vdso_pagelist[1];
<span class="p_header">diff --git a/arch/arm64/mm/init.c b/arch/arm64/mm/init.c</span>
<span class="p_header">index 3236eb062444..14f426fea61b 100644</span>
<span class="p_header">--- a/arch/arm64/mm/init.c</span>
<span class="p_header">+++ b/arch/arm64/mm/init.c</span>
<span class="p_chunk">@@ -225,7 +225,7 @@</span> <span class="p_context"> void __init arm64_memblock_init(void)</span>
 	 */
 	if (memory_limit != (phys_addr_t)ULLONG_MAX) {
 		memblock_mem_limit_remove_map(memory_limit);
<span class="p_del">-		memblock_add(__pa(_text), (u64)(_end - _text));</span>
<span class="p_add">+		memblock_add(__pa_symbol(_text), (u64)(_end - _text));</span>
 	}
 
 	if (IS_ENABLED(CONFIG_BLK_DEV_INITRD) &amp;&amp; initrd_start) {
<span class="p_chunk">@@ -278,7 +278,7 @@</span> <span class="p_context"> void __init arm64_memblock_init(void)</span>
 	 * Register the kernel text, kernel data, initrd, and initial
 	 * pagetables with memblock.
 	 */
<span class="p_del">-	memblock_reserve(__pa(_text), _end - _text);</span>
<span class="p_add">+	memblock_reserve(__pa_symbol(_text), _end - _text);</span>
 #ifdef CONFIG_BLK_DEV_INITRD
 	if (initrd_start) {
 		memblock_reserve(initrd_start, initrd_end - initrd_start);
<span class="p_chunk">@@ -483,7 +483,8 @@</span> <span class="p_context"> void __init mem_init(void)</span>
 
 void free_initmem(void)
 {
<span class="p_del">-	free_reserved_area(__va(__pa(__init_begin)), __va(__pa(__init_end)),</span>
<span class="p_add">+	free_reserved_area(__va(__pa_symbol(__init_begin)),</span>
<span class="p_add">+			   __va(__pa_symbol(__init_end)),</span>
 			   0, &quot;unused kernel&quot;);
 	/*
 	 * Unmap the __init region but leave the VM area in place. This
<span class="p_header">diff --git a/arch/arm64/mm/mmu.c b/arch/arm64/mm/mmu.c</span>
<span class="p_header">index 17243e43184e..f7c0a47a8ebd 100644</span>
<span class="p_header">--- a/arch/arm64/mm/mmu.c</span>
<span class="p_header">+++ b/arch/arm64/mm/mmu.c</span>
<span class="p_chunk">@@ -359,8 +359,8 @@</span> <span class="p_context"> static void create_mapping_late(phys_addr_t phys, unsigned long virt,</span>
 
 static void __init __map_memblock(pgd_t *pgd, phys_addr_t start, phys_addr_t end)
 {
<span class="p_del">-	unsigned long kernel_start = __pa(_text);</span>
<span class="p_del">-	unsigned long kernel_end = __pa(__init_begin);</span>
<span class="p_add">+	unsigned long kernel_start = __pa_symbol(_text);</span>
<span class="p_add">+	unsigned long kernel_end = __pa_symbol(__init_begin);</span>
 
 	/*
 	 * Take care not to create a writable alias for the
<span class="p_chunk">@@ -427,14 +427,14 @@</span> <span class="p_context"> void mark_rodata_ro(void)</span>
 	unsigned long section_size;
 
 	section_size = (unsigned long)_etext - (unsigned long)_text;
<span class="p_del">-	create_mapping_late(__pa(_text), (unsigned long)_text,</span>
<span class="p_add">+	create_mapping_late(__pa_symbol(_text), (unsigned long)_text,</span>
 			    section_size, PAGE_KERNEL_ROX);
 	/*
 	 * mark .rodata as read only. Use __init_begin rather than __end_rodata
 	 * to cover NOTES and EXCEPTION_TABLE.
 	 */
 	section_size = (unsigned long)__init_begin - (unsigned long)__start_rodata;
<span class="p_del">-	create_mapping_late(__pa(__start_rodata), (unsigned long)__start_rodata,</span>
<span class="p_add">+	create_mapping_late(__pa_symbol(__start_rodata), (unsigned long)__start_rodata,</span>
 			    section_size, PAGE_KERNEL_RO);
 
 	/* flush the TLBs after updating live kernel mappings */
<span class="p_chunk">@@ -446,7 +446,7 @@</span> <span class="p_context"> void mark_rodata_ro(void)</span>
 static void __init map_kernel_segment(pgd_t *pgd, void *va_start, void *va_end,
 				      pgprot_t prot, struct vm_struct *vma)
 {
<span class="p_del">-	phys_addr_t pa_start = __pa(va_start);</span>
<span class="p_add">+	phys_addr_t pa_start = __pa_symbol(va_start);</span>
 	unsigned long size = va_end - va_start;
 
 	BUG_ON(!PAGE_ALIGNED(pa_start));
<span class="p_chunk">@@ -494,7 +494,7 @@</span> <span class="p_context"> static void __init map_kernel(pgd_t *pgd)</span>
 		 */
 		BUG_ON(!IS_ENABLED(CONFIG_ARM64_16K_PAGES));
 		set_pud(pud_set_fixmap_offset(pgd, FIXADDR_START),
<span class="p_del">-			__pud(__pa(bm_pmd) | PUD_TYPE_TABLE));</span>
<span class="p_add">+			__pud(__pa_symbol(bm_pmd) | PUD_TYPE_TABLE));</span>
 		pud_clear_fixmap();
 	} else {
 		BUG();
<span class="p_chunk">@@ -525,7 +525,7 @@</span> <span class="p_context"> void __init paging_init(void)</span>
 	 */
 	cpu_replace_ttbr1(__va(pgd_phys));
 	memcpy(swapper_pg_dir, pgd, PAGE_SIZE);
<span class="p_del">-	cpu_replace_ttbr1(swapper_pg_dir);</span>
<span class="p_add">+	cpu_replace_ttbr1(__va(__pa_symbol(swapper_pg_dir)));</span>
 
 	pgd_clear_fixmap();
 	memblock_free(pgd_phys, PAGE_SIZE);
<span class="p_chunk">@@ -534,7 +534,7 @@</span> <span class="p_context"> void __init paging_init(void)</span>
 	 * We only reuse the PGD from the swapper_pg_dir, not the pud + pmd
 	 * allocated with it.
 	 */
<span class="p_del">-	memblock_free(__pa(swapper_pg_dir) + PAGE_SIZE,</span>
<span class="p_add">+	memblock_free(__pa_symbol(swapper_pg_dir) + PAGE_SIZE,</span>
 		      SWAPPER_DIR_SIZE - PAGE_SIZE);
 }
 
<span class="p_chunk">@@ -654,7 +654,7 @@</span> <span class="p_context"> void __init early_fixmap_init(void)</span>
 
 	pgd = pgd_offset_k(addr);
 	if (CONFIG_PGTABLE_LEVELS &gt; 3 &amp;&amp;
<span class="p_del">-	    !(pgd_none(*pgd) || pgd_page_paddr(*pgd) == __pa(bm_pud))) {</span>
<span class="p_add">+	    !(pgd_none(*pgd) || pgd_page_paddr(*pgd) == __pa_symbol(bm_pud))) {</span>
 		/*
 		 * We only end up here if the kernel mapping and the fixmap
 		 * share the top level pgd entry, which should only happen on
<span class="p_chunk">@@ -663,12 +663,12 @@</span> <span class="p_context"> void __init early_fixmap_init(void)</span>
 		BUG_ON(!IS_ENABLED(CONFIG_ARM64_16K_PAGES));
 		pud = pud_offset_kimg(pgd, addr);
 	} else {
<span class="p_del">-		pgd_populate(&amp;init_mm, pgd, bm_pud);</span>
<span class="p_add">+		pgd_populate(&amp;init_mm, pgd, __va(__pa_symbol(bm_pud)));</span>
 		pud = fixmap_pud(addr);
 	}
<span class="p_del">-	pud_populate(&amp;init_mm, pud, bm_pmd);</span>
<span class="p_add">+	pud_populate(&amp;init_mm, pud, __va(__pa_symbol(bm_pmd)));</span>
 	pmd = fixmap_pmd(addr);
<span class="p_del">-	pmd_populate_kernel(&amp;init_mm, pmd, bm_pte);</span>
<span class="p_add">+	pmd_populate_kernel(&amp;init_mm, pmd, __va(__pa_symbol(bm_pte)));</span>
 
 	/*
 	 * The boot-ioremap range spans multiple pmds, for which
<span class="p_header">diff --git a/arch/arm64/mm/physaddr.c b/arch/arm64/mm/physaddr.c</span>
<span class="p_header">index 874c78201a2b..98dae943e496 100644</span>
<span class="p_header">--- a/arch/arm64/mm/physaddr.c</span>
<span class="p_header">+++ b/arch/arm64/mm/physaddr.c</span>
<span class="p_chunk">@@ -14,8 +14,8 @@</span> <span class="p_context"> unsigned long __virt_to_phys(unsigned long x)</span>
 		 */
 		return (__x &amp; ~PAGE_OFFSET) + PHYS_OFFSET;
 	} else {
<span class="p_del">-		VIRTUAL_BUG_ON(x &lt; kimage_vaddr || x &gt;= (unsigned long)_end);</span>
<span class="p_del">-		return (__x - kimage_voffset);</span>
<span class="p_add">+		WARN_ON(1);</span>
<span class="p_add">+		return __phys_addr_symbol(x);</span>
 	}
 }
 EXPORT_SYMBOL(__virt_to_phys);
<span class="p_header">diff --git a/drivers/firmware/psci.c b/drivers/firmware/psci.c</span>
<span class="p_header">index 8263429e21b8..9defbe243c2f 100644</span>
<span class="p_header">--- a/drivers/firmware/psci.c</span>
<span class="p_header">+++ b/drivers/firmware/psci.c</span>
<span class="p_chunk">@@ -383,7 +383,7 @@</span> <span class="p_context"> static int psci_suspend_finisher(unsigned long index)</span>
 	u32 *state = __this_cpu_read(psci_power_state);
 
 	return psci_ops.cpu_suspend(state[index - 1],
<span class="p_del">-				    virt_to_phys(cpu_resume));</span>
<span class="p_add">+				    __pa_symbol(cpu_resume));</span>
 }
 
 int psci_cpu_suspend_enter(unsigned long index)

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



