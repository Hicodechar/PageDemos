
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>[RFC,v2,5/6] x86: Use global pages when PTI is disabled - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    [RFC,v2,5/6] x86: Use global pages when PTI is disabled</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=159401">Nadav Amit</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>Feb. 15, 2018, 4:36 p.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;20180215163602.61162-6-namit@vmware.com&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/10222375/mbox/"
   >mbox</a>
|
   <a href="/patch/10222375/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/10222375/">/patch/10222375/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
	[172.30.200.125])
	by pdx-korg-patchwork.web.codeaurora.org (Postfix) with ESMTP id
	B3AFB6055C for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Thu, 15 Feb 2018 16:36:41 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id A56662948D
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Thu, 15 Feb 2018 16:36:41 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id 9A39729490; Thu, 15 Feb 2018 16:36:41 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-6.9 required=2.0 tests=BAYES_00,RCVD_IN_DNSWL_HI
	autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 3C4632948D
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Thu, 15 Feb 2018 16:36:41 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1426114AbeBOQgh (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Thu, 15 Feb 2018 11:36:37 -0500
Received: from ex13-edg-ou-002.vmware.com ([208.91.0.190]:37394 &quot;EHLO
	EX13-EDG-OU-002.vmware.com&quot; rhost-flags-OK-OK-OK-OK)
	by vger.kernel.org with ESMTP id S1426090AbeBOQgU (ORCPT
	&lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Thu, 15 Feb 2018 11:36:20 -0500
Received: from sc9-mailhost3.vmware.com (10.113.161.73) by
	EX13-EDG-OU-002.vmware.com (10.113.208.156) with Microsoft SMTP
	Server id 15.0.1156.6; Thu, 15 Feb 2018 08:36:08 -0800
Received: from ubuntu.localdomain (unknown [10.2.101.129])
	by sc9-mailhost3.vmware.com (Postfix) with ESMTP id 6D0A040B58;
	Thu, 15 Feb 2018 08:36:16 -0800 (PST)
From: Nadav Amit &lt;namit@vmware.com&gt;
To: Ingo Molnar &lt;mingo@redhat.com&gt;
CC: Thomas Gleixner &lt;tglx@linutronix.de&gt;, Andy Lutomirski &lt;luto@kernel.org&gt;,
	Peter Zijlstra &lt;peterz@infradead.org&gt;,
	Dave Hansen &lt;dave.hansen@linux.intel.com&gt;,
	Willy Tarreau &lt;w@1wt.eu&gt;, Nadav Amit &lt;nadav.amit@gmail.com&gt;,
	&lt;x86@kernel.org&gt;, &lt;linux-kernel@vger.kernel.org&gt;,
	Nadav Amit &lt;namit@vmware.com&gt;
Subject: [PATCH RFC v2 5/6] x86: Use global pages when PTI is disabled
Date: Thu, 15 Feb 2018 08:36:01 -0800
Message-ID: &lt;20180215163602.61162-6-namit@vmware.com&gt;
X-Mailer: git-send-email 2.14.1
In-Reply-To: &lt;20180215163602.61162-1-namit@vmware.com&gt;
References: &lt;20180215163602.61162-1-namit@vmware.com&gt;
MIME-Version: 1.0
Content-Type: text/plain
Received-SPF: None (EX13-EDG-OU-002.vmware.com: namit@vmware.com does not
	designate permitted sender hosts)
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=159401">Nadav Amit</a> - Feb. 15, 2018, 4:36 p.m.</div>
<pre class="content">
As long as PTI is disabled, it is possible to use global pages, as long
as we remove them once PTI is enabled again. To do so, return the global
bit to __supported_pte_mask and disable global pages using CR4.
<span class="signed-off-by">
Signed-off-by: Nadav Amit &lt;namit@vmware.com&gt;</span>
---
 arch/x86/include/asm/tlbflush.h |  6 ++++++
 arch/x86/mm/init.c              | 14 ++++++--------
 arch/x86/mm/tlb.c               |  3 ++-
 3 files changed, 14 insertions(+), 9 deletions(-)
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=64071">Dave Hansen</a> - Feb. 15, 2018, 4:54 p.m.</div>
<pre class="content">
On 02/15/2018 08:36 AM, Nadav Amit wrote:
<span class="quote">&gt; As long as PTI is disabled, it is possible to use global pages, as long</span>
<span class="quote">&gt; as we remove them once PTI is enabled again. To do so, return the global</span>
<span class="quote">&gt; bit to __supported_pte_mask and disable global pages using CR4.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Signed-off-by: Nadav Amit &lt;namit@vmware.com&gt;</span>
<span class="quote">&gt; ---</span>
<span class="quote">&gt;  arch/x86/include/asm/tlbflush.h |  6 ++++++</span>
<span class="quote">&gt;  arch/x86/mm/init.c              | 14 ++++++--------</span>
<span class="quote">&gt;  arch/x86/mm/tlb.c               |  3 ++-</span>
<span class="quote">&gt;  3 files changed, 14 insertions(+), 9 deletions(-)</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; diff --git a/arch/x86/include/asm/tlbflush.h b/arch/x86/include/asm/tlbflush.h</span>
<span class="quote">&gt; index ea65cf951c49..3a44cb0a9f56 100644</span>
<span class="quote">&gt; --- a/arch/x86/include/asm/tlbflush.h</span>
<span class="quote">&gt; +++ b/arch/x86/include/asm/tlbflush.h</span>
<span class="quote">&gt; @@ -319,6 +319,12 @@ static inline void set_cpu_pti_disable(unsigned short disable)</span>
<span class="quote">&gt;  	WARN_ON_ONCE(preemptible());</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	pti_update_user_cs64(cpu_pti_disable(), disable);</span>
<span class="quote">&gt; +	if (__supported_pte_mask &amp; _PAGE_GLOBAL) {</span>
<span class="quote">&gt; +		if (disable)</span>
<span class="quote">&gt; +			cr4_set_bits(X86_CR4_PGE);</span>
<span class="quote">&gt; +		else</span>
<span class="quote">&gt; +			cr4_clear_bits(X86_CR4_PGE);</span>
<span class="quote">&gt; +	}</span>
<span class="quote">&gt;  	this_cpu_write(cpu_tlbstate.pti_disable, disable);</span>
<span class="quote">&gt;  }</span>

The TLB invalidations when doing this switch are *CRITICAL*.  Otherwise,
we end up globally-mapped kernel entries persisting to other processes
that are then vulnerable to Meltdown.

So, where are the TLB flushes?

They&#39;re hidden in the cr4_set/clear_bits() function, of course.  This is
dangerous for two reasons because it makes them non-obvious and hard to
find.  It also has no interactions with the existing TLB invalidation
infrastructure.  That&#39;s _safe_ of course because extra flushing is OK,
but it feels really funky because you&#39;re going to end up double-flushing
on context switches which is rather unfortunate.

This also needs some heavy commenting about the fact that _PAGE_GLOBAL
is ignored when CR4.PGE=0.  That&#39;s key to this working and not mentioned
anywhere.

While this looks OK to me, it still makes me rather nervous.  The
changelog and commenting definitely need a lot of work.  I&#39;m also still
rather unconvinced that the added complexity here is worth it.
<span class="quote">
&gt; diff --git a/arch/x86/mm/tlb.c b/arch/x86/mm/tlb.c</span>
<span class="quote">&gt; index c67ef3fb4f35..979c7ec6baab 100644</span>
<span class="quote">&gt; --- a/arch/x86/mm/tlb.c</span>
<span class="quote">&gt; +++ b/arch/x86/mm/tlb.c</span>
<span class="quote">&gt; @@ -74,7 +74,8 @@ static void choose_new_asid(struct mm_struct *next, u64 next_tlb_gen,</span>
<span class="quote">&gt;  		return;</span>
<span class="quote">&gt;  	}</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; -	if (this_cpu_read(cpu_tlbstate.invalidate_other))</span>
<span class="quote">&gt; +	if (this_cpu_read(cpu_tlbstate.invalidate_other) &amp;&amp;</span>
<span class="quote">&gt; +	    !mm_pti_disable(next))</span>
<span class="quote">&gt;  		clear_asid_other();</span>

This isn&#39;t obviously correct.  Don&#39;t we still need to invalidate other
user asids?
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=159401">Nadav Amit</a> - Feb. 15, 2018, 5:36 p.m.</div>
<pre class="content">
Dave Hansen &lt;dave.hansen@linux.intel.com&gt; wrote:
<span class="quote">
&gt; On 02/15/2018 08:36 AM, Nadav Amit wrote:</span>
<span class="quote">&gt;&gt; As long as PTI is disabled, it is possible to use global pages, as long</span>
<span class="quote">&gt;&gt; as we remove them once PTI is enabled again. To do so, return the global</span>
<span class="quote">&gt;&gt; bit to __supported_pte_mask and disable global pages using CR4.</span>
<span class="quote">&gt;&gt; </span>
<span class="quote">&gt;&gt; Signed-off-by: Nadav Amit &lt;namit@vmware.com&gt;</span>
<span class="quote">&gt;&gt; ---</span>
<span class="quote">&gt;&gt; arch/x86/include/asm/tlbflush.h |  6 ++++++</span>
<span class="quote">&gt;&gt; arch/x86/mm/init.c              | 14 ++++++--------</span>
<span class="quote">&gt;&gt; arch/x86/mm/tlb.c               |  3 ++-</span>
<span class="quote">&gt;&gt; 3 files changed, 14 insertions(+), 9 deletions(-)</span>
<span class="quote">&gt;&gt; </span>
<span class="quote">&gt;&gt; diff --git a/arch/x86/include/asm/tlbflush.h b/arch/x86/include/asm/tlbflush.h</span>
<span class="quote">&gt;&gt; index ea65cf951c49..3a44cb0a9f56 100644</span>
<span class="quote">&gt;&gt; --- a/arch/x86/include/asm/tlbflush.h</span>
<span class="quote">&gt;&gt; +++ b/arch/x86/include/asm/tlbflush.h</span>
<span class="quote">&gt;&gt; @@ -319,6 +319,12 @@ static inline void set_cpu_pti_disable(unsigned short disable)</span>
<span class="quote">&gt;&gt; 	WARN_ON_ONCE(preemptible());</span>
<span class="quote">&gt;&gt; </span>
<span class="quote">&gt;&gt; 	pti_update_user_cs64(cpu_pti_disable(), disable);</span>
<span class="quote">&gt;&gt; +	if (__supported_pte_mask &amp; _PAGE_GLOBAL) {</span>
<span class="quote">&gt;&gt; +		if (disable)</span>
<span class="quote">&gt;&gt; +			cr4_set_bits(X86_CR4_PGE);</span>
<span class="quote">&gt;&gt; +		else</span>
<span class="quote">&gt;&gt; +			cr4_clear_bits(X86_CR4_PGE);</span>
<span class="quote">&gt;&gt; +	}</span>
<span class="quote">&gt;&gt; 	this_cpu_write(cpu_tlbstate.pti_disable, disable);</span>
<span class="quote">&gt;&gt; }</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; The TLB invalidations when doing this switch are *CRITICAL*.  Otherwise,</span>
<span class="quote">&gt; we end up globally-mapped kernel entries persisting to other processes</span>
<span class="quote">&gt; that are then vulnerable to Meltdown.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; So, where are the TLB flushes?</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; They&#39;re hidden in the cr4_set/clear_bits() function, of course.  This is</span>
<span class="quote">&gt; dangerous for two reasons because it makes them non-obvious and hard to</span>
<span class="quote">&gt; find.  It also has no interactions with the existing TLB invalidation</span>
<span class="quote">&gt; infrastructure.  That&#39;s _safe_ of course because extra flushing is OK,</span>
<span class="quote">&gt; but it feels really funky because you&#39;re going to end up double-flushing</span>
<span class="quote">&gt; on context switches which is rather unfortunate.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; This also needs some heavy commenting about the fact that _PAGE_GLOBAL</span>
<span class="quote">&gt; is ignored when CR4.PGE=0.  That&#39;s key to this working and not mentioned</span>
<span class="quote">&gt; anywhere.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; While this looks OK to me, it still makes me rather nervous.  The</span>
<span class="quote">&gt; changelog and commenting definitely need a lot of work.  I&#39;m also still</span>
<span class="quote">&gt; rather unconvinced that the added complexity here is worth it.</span>

I agree that comments, and perhaps some wrapper functions to clarify when a
flush takes place are necessary. I actually sent the patches before making
another pass since I saw they somewhat conflict with your recent patches.

I think that there are several reasons why these patches are not as bad as
they look: 

1) Legacy mode performance (with PTI) is bad, but apparently x86-32
applications are still widely used: https://lkml.org/lkml/2018/2/10/38

2) It is likely that at some point you will want to disable PTI selectively
for processes, similarly to the way Windows “trusts” Microsoft SQL. At this
point you are likely to end up with most of the code that these patches
introduce.
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=159401">Nadav Amit</a> - Feb. 15, 2018, 5:47 p.m.</div>
<pre class="content">
Dave Hansen &lt;dave.hansen@linux.intel.com&gt; wrote:
<span class="quote">
&gt;&gt; diff --git a/arch/x86/mm/tlb.c b/arch/x86/mm/tlb.c</span>
<span class="quote">&gt;&gt; index c67ef3fb4f35..979c7ec6baab 100644</span>
<span class="quote">&gt;&gt; --- a/arch/x86/mm/tlb.c</span>
<span class="quote">&gt;&gt; +++ b/arch/x86/mm/tlb.c</span>
<span class="quote">&gt;&gt; @@ -74,7 +74,8 @@ static void choose_new_asid(struct mm_struct *next, u64 next_tlb_gen,</span>
<span class="quote">&gt;&gt; 		return;</span>
<span class="quote">&gt;&gt; 	}</span>
<span class="quote">&gt;&gt; </span>
<span class="quote">&gt;&gt; -	if (this_cpu_read(cpu_tlbstate.invalidate_other))</span>
<span class="quote">&gt;&gt; +	if (this_cpu_read(cpu_tlbstate.invalidate_other) &amp;&amp;</span>
<span class="quote">&gt;&gt; +	    !mm_pti_disable(next))</span>
<span class="quote">&gt;&gt; 		clear_asid_other();</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; This isn&#39;t obviously correct.  Don&#39;t we still need to invalidate other</span>
<span class="quote">&gt; user asids?</span>

I forgot to regard this question: When you reenable PTI (after switching back
to 64-bit process), you flush the global pages, so no kernel mappings for the
32-bit process are left.

As for kernel mappings of 64-bit processes, you will flush them later, when
you switch back to 64-bit process (the indication is left set).
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=64071">Dave Hansen</a> - Feb. 15, 2018, 6:08 p.m.</div>
<pre class="content">
On 02/15/2018 09:47 AM, Nadav Amit wrote:
<span class="quote">&gt; Dave Hansen &lt;dave.hansen@linux.intel.com&gt; wrote:</span>
<span class="quote">&gt;&gt;&gt; diff --git a/arch/x86/mm/tlb.c b/arch/x86/mm/tlb.c</span>
<span class="quote">&gt;&gt;&gt; index c67ef3fb4f35..979c7ec6baab 100644</span>
<span class="quote">&gt;&gt;&gt; --- a/arch/x86/mm/tlb.c</span>
<span class="quote">&gt;&gt;&gt; +++ b/arch/x86/mm/tlb.c</span>
<span class="quote">&gt;&gt;&gt; @@ -74,7 +74,8 @@ static void choose_new_asid(struct mm_struct *next, u64 next_tlb_gen,</span>
<span class="quote">&gt;&gt;&gt; 		return;</span>
<span class="quote">&gt;&gt;&gt; 	}</span>
<span class="quote">&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt; -	if (this_cpu_read(cpu_tlbstate.invalidate_other))</span>
<span class="quote">&gt;&gt;&gt; +	if (this_cpu_read(cpu_tlbstate.invalidate_other) &amp;&amp;</span>
<span class="quote">&gt;&gt;&gt; +	    !mm_pti_disable(next))</span>
<span class="quote">&gt;&gt;&gt; 		clear_asid_other();</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; This isn&#39;t obviously correct.  Don&#39;t we still need to invalidate other</span>
<span class="quote">&gt;&gt; user asids?</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; I forgot to regard this question: When you reenable PTI (after switching back</span>
<span class="quote">&gt; to 64-bit process), you flush the global pages, so no kernel mappings for the</span>
<span class="quote">&gt; 32-bit process are left.</span>

Can you please write up a proper description for this?  It&#39;s horribly
complicated, intertwined with global pages, and sets up a dependency
that *ALL* TLB entries invalidated via __flush_tlb_one_kernel() must be
_PAGE_GLOBAL.

How about you actually clear cpu_tlbstate.invalidate_other when you do
the CR4.PGE switching?  That seems a much more direct way and is much
more self-documenting.

That brings up another point: these patches rather ignore cpu_tlbstate.
That leads to confusing code (this) and the double-flushing on context
switch I brought up earlier.  Was this intentional, or is it something
you can reconsider going forward?
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=125831">Andrew Lutomirski</a> - Feb. 15, 2018, 7:53 p.m.</div>
<pre class="content">
On Thu, Feb 15, 2018 at 4:36 PM, Nadav Amit &lt;namit@vmware.com&gt; wrote:
<span class="quote">&gt; As long as PTI is disabled, it is possible to use global pages, as long</span>
<span class="quote">&gt; as we remove them once PTI is enabled again. To do so, return the global</span>
<span class="quote">&gt; bit to __supported_pte_mask and disable global pages using CR4.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; Signed-off-by: Nadav Amit &lt;namit@vmware.com&gt;</span>
<span class="quote">&gt; ---</span>
<span class="quote">&gt;  arch/x86/include/asm/tlbflush.h |  6 ++++++</span>
<span class="quote">&gt;  arch/x86/mm/init.c              | 14 ++++++--------</span>
<span class="quote">&gt;  arch/x86/mm/tlb.c               |  3 ++-</span>
<span class="quote">&gt;  3 files changed, 14 insertions(+), 9 deletions(-)</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; diff --git a/arch/x86/include/asm/tlbflush.h b/arch/x86/include/asm/tlbflush.h</span>
<span class="quote">&gt; index ea65cf951c49..3a44cb0a9f56 100644</span>
<span class="quote">&gt; --- a/arch/x86/include/asm/tlbflush.h</span>
<span class="quote">&gt; +++ b/arch/x86/include/asm/tlbflush.h</span>
<span class="quote">&gt; @@ -319,6 +319,12 @@ static inline void set_cpu_pti_disable(unsigned short disable)</span>
<span class="quote">&gt;         WARN_ON_ONCE(preemptible());</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;         pti_update_user_cs64(cpu_pti_disable(), disable);</span>
<span class="quote">&gt; +       if (__supported_pte_mask &amp; _PAGE_GLOBAL) {</span>
<span class="quote">&gt; +               if (disable)</span>
<span class="quote">&gt; +                       cr4_set_bits(X86_CR4_PGE);</span>
<span class="quote">&gt; +               else</span>
<span class="quote">&gt; +                       cr4_clear_bits(X86_CR4_PGE);</span>
<span class="quote">&gt; +       }</span>

This will be *extremely* slow, and I don&#39;t see the point at all.  What
are you accomplishing here?

At best, you might gain something by adjusting the page table entries
to get globalness back, but I see no reason to fiddle with CR4.  Also,
if you do any of this at all and you run on K8, you&#39;re at risk of
getting machine checks unless you&#39;re very careful to get the
invalidation right.

I would just drop this patch, personally.
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=64071">Dave Hansen</a> - Feb. 15, 2018, 8:32 p.m.</div>
<pre class="content">
On 02/15/2018 11:53 AM, Andy Lutomirski wrote:
<span class="quote">&gt;&gt; --- a/arch/x86/include/asm/tlbflush.h</span>
<span class="quote">&gt;&gt; +++ b/arch/x86/include/asm/tlbflush.h</span>
<span class="quote">&gt;&gt; @@ -319,6 +319,12 @@ static inline void set_cpu_pti_disable(unsigned short disable)</span>
<span class="quote">&gt;&gt;         WARN_ON_ONCE(preemptible());</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt;         pti_update_user_cs64(cpu_pti_disable(), disable);</span>
<span class="quote">&gt;&gt; +       if (__supported_pte_mask &amp; _PAGE_GLOBAL) {</span>
<span class="quote">&gt;&gt; +               if (disable)</span>
<span class="quote">&gt;&gt; +                       cr4_set_bits(X86_CR4_PGE);</span>
<span class="quote">&gt;&gt; +               else</span>
<span class="quote">&gt;&gt; +                       cr4_clear_bits(X86_CR4_PGE);</span>
<span class="quote">&gt;&gt; +       }</span>
<span class="quote">&gt; This will be *extremely* slow, and I don&#39;t see the point at all.  What</span>
<span class="quote">&gt; are you accomplishing here?</span>

It won&#39;t be slow if you always run compat processes, I guess.

But mixing these in here will eat a big chunk of the benefit of having
global pages (or PCIDs for that matter) in the first place.
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=55071">Nadav Amit</a> - Feb. 15, 2018, 8:45 p.m.</div>
<pre class="content">
Dave Hansen &lt;dave.hansen@linux.intel.com&gt; wrote:
<span class="quote">
&gt; On 02/15/2018 11:53 AM, Andy Lutomirski wrote:</span>
<span class="quote">&gt;&gt;&gt; --- a/arch/x86/include/asm/tlbflush.h</span>
<span class="quote">&gt;&gt;&gt; +++ b/arch/x86/include/asm/tlbflush.h</span>
<span class="quote">&gt;&gt;&gt; @@ -319,6 +319,12 @@ static inline void set_cpu_pti_disable(unsigned short disable)</span>
<span class="quote">&gt;&gt;&gt;        WARN_ON_ONCE(preemptible());</span>
<span class="quote">&gt;&gt;&gt; </span>
<span class="quote">&gt;&gt;&gt;        pti_update_user_cs64(cpu_pti_disable(), disable);</span>
<span class="quote">&gt;&gt;&gt; +       if (__supported_pte_mask &amp; _PAGE_GLOBAL) {</span>
<span class="quote">&gt;&gt;&gt; +               if (disable)</span>
<span class="quote">&gt;&gt;&gt; +                       cr4_set_bits(X86_CR4_PGE);</span>
<span class="quote">&gt;&gt;&gt; +               else</span>
<span class="quote">&gt;&gt;&gt; +                       cr4_clear_bits(X86_CR4_PGE);</span>
<span class="quote">&gt;&gt;&gt; +       }</span>
<span class="quote">&gt;&gt; This will be *extremely* slow, and I don&#39;t see the point at all.  What</span>
<span class="quote">&gt;&gt; are you accomplishing here?</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; It won&#39;t be slow if you always run compat processes, I guess.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; But mixing these in here will eat a big chunk of the benefit of having</span>
<span class="quote">&gt; global pages (or PCIDs for that matter) in the first place.</span>

These are all good points. The idea was to allow workloads like Apache, that
spawn multiple processes that frequently perform context-switches to incur
TLB misses on kernel pages. 

The double-flushing was not intentional - I missed it. Anyhow, based on your
comments, and because I don’t see an easy way to make the global
cpu_entry_area (your recent patches) to work with this patch, I think I will
drop this patch.
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/arch/x86/include/asm/tlbflush.h b/arch/x86/include/asm/tlbflush.h</span>
<span class="p_header">index ea65cf951c49..3a44cb0a9f56 100644</span>
<span class="p_header">--- a/arch/x86/include/asm/tlbflush.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/tlbflush.h</span>
<span class="p_chunk">@@ -319,6 +319,12 @@</span> <span class="p_context"> static inline void set_cpu_pti_disable(unsigned short disable)</span>
 	WARN_ON_ONCE(preemptible());
 
 	pti_update_user_cs64(cpu_pti_disable(), disable);
<span class="p_add">+	if (__supported_pte_mask &amp; _PAGE_GLOBAL) {</span>
<span class="p_add">+		if (disable)</span>
<span class="p_add">+			cr4_set_bits(X86_CR4_PGE);</span>
<span class="p_add">+		else</span>
<span class="p_add">+			cr4_clear_bits(X86_CR4_PGE);</span>
<span class="p_add">+	}</span>
 	this_cpu_write(cpu_tlbstate.pti_disable, disable);
 }
 
<span class="p_header">diff --git a/arch/x86/mm/init.c b/arch/x86/mm/init.c</span>
<span class="p_header">index 82f5252c723a..7f918a59c536 100644</span>
<span class="p_header">--- a/arch/x86/mm/init.c</span>
<span class="p_header">+++ b/arch/x86/mm/init.c</span>
<span class="p_chunk">@@ -161,12 +161,6 @@</span> <span class="p_context"> struct map_range {</span>
 
 static int page_size_mask;
 
<span class="p_del">-static void enable_global_pages(void)</span>
<span class="p_del">-{</span>
<span class="p_del">-	if (!static_cpu_has(X86_FEATURE_PTI))</span>
<span class="p_del">-		__supported_pte_mask |= _PAGE_GLOBAL;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
 static void __init probe_page_size_mask(void)
 {
 	/*
<span class="p_chunk">@@ -186,8 +180,10 @@</span> <span class="p_context"> static void __init probe_page_size_mask(void)</span>
 	/* Enable PGE if available */
 	__supported_pte_mask &amp;= ~_PAGE_GLOBAL;
 	if (boot_cpu_has(X86_FEATURE_PGE)) {
<span class="p_del">-		cr4_set_bits_and_update_boot(X86_CR4_PGE);</span>
<span class="p_del">-		enable_global_pages();</span>
<span class="p_add">+		__supported_pte_mask |= _PAGE_GLOBAL;</span>
<span class="p_add">+</span>
<span class="p_add">+		if (!static_cpu_has(X86_FEATURE_PTI))</span>
<span class="p_add">+			cr4_set_bits_and_update_boot(X86_CR4_PGE);</span>
 	}
 
 	/* Enable 1 GB linear kernel mappings if available: */
<span class="p_chunk">@@ -683,6 +679,8 @@</span> <span class="p_context"> void __init init_mem_mapping(void)</span>
 #else
 	early_ioremap_page_table_range_init();
 #endif
<span class="p_add">+	if (static_cpu_has(X86_FEATURE_PTI))</span>
<span class="p_add">+		cr4_clear_bits(X86_CR4_PGE);</span>
 
 	load_cr3(swapper_pg_dir);
 	__flush_tlb_all();
<span class="p_header">diff --git a/arch/x86/mm/tlb.c b/arch/x86/mm/tlb.c</span>
<span class="p_header">index c67ef3fb4f35..979c7ec6baab 100644</span>
<span class="p_header">--- a/arch/x86/mm/tlb.c</span>
<span class="p_header">+++ b/arch/x86/mm/tlb.c</span>
<span class="p_chunk">@@ -74,7 +74,8 @@</span> <span class="p_context"> static void choose_new_asid(struct mm_struct *next, u64 next_tlb_gen,</span>
 		return;
 	}
 
<span class="p_del">-	if (this_cpu_read(cpu_tlbstate.invalidate_other))</span>
<span class="p_add">+	if (this_cpu_read(cpu_tlbstate.invalidate_other) &amp;&amp;</span>
<span class="p_add">+	    !mm_pti_disable(next))</span>
 		clear_asid_other();
 
 	for (asid = 0; asid &lt; TLB_NR_DYN_ASIDS; asid++) {

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



