
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>[1/2] KVM: x86: simplify handling of PKRU - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    [1/2] KVM: x86: simplify handling of PKRU</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=2536">Paolo Bonzini</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>Aug. 23, 2017, 9:26 p.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;1503523566-25624-2-git-send-email-pbonzini@redhat.com&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/9918403/mbox/"
   >mbox</a>
|
   <a href="/patch/9918403/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/9918403/">/patch/9918403/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
	[172.30.200.125])
	by pdx-korg-patchwork.web.codeaurora.org (Postfix) with ESMTP id
	2FF06600C5 for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Wed, 23 Aug 2017 21:26:44 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 23D0628935
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Wed, 23 Aug 2017 21:26:44 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id 18EB328A85; Wed, 23 Aug 2017 21:26:44 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-6.3 required=2.0 tests=BAYES_00,DKIM_SIGNED,
	RCVD_IN_DNSWL_HI, RCVD_IN_SORBS_SPAM,
	T_DKIM_INVALID autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 8E34D28935
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Wed, 23 Aug 2017 21:26:43 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1751213AbdHWV0k (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Wed, 23 Aug 2017 17:26:40 -0400
Received: from mail-wm0-f67.google.com ([74.125.82.67]:38152 &quot;EHLO
	mail-wm0-f67.google.com&quot; rhost-flags-OK-OK-OK-OK) by vger.kernel.org
	with ESMTP id S1751115AbdHWV0N (ORCPT
	&lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Wed, 23 Aug 2017 17:26:13 -0400
Received: by mail-wm0-f67.google.com with SMTP id a70so784919wmd.5;
	Wed, 23 Aug 2017 14:26:12 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
	d=gmail.com; s=20161025;
	h=sender:from:to:cc:subject:date:message-id:in-reply-to:references;
	bh=MOey/9FPH+9zGAdY9RYLcXFpZMGv/rgtGFYfWDiKf+Y=;
	b=E4MzbiqcoYnkKTFCftt1M1pvkAG33decuOgOLtZN6b7luXdyzlWKfmE17GYEZVuQWA
	KyIJCTk2FCJSpiIVa9FTPC9XveA2Gf3ZOTmZ8S34QBe4HbzlF35EZxCYGK8+3EIvA0uc
	e3UaJbH6CsK1oZ6d6FmYVeA3eDP9tdwRINH5iFKSgI+C/YzmsdUHPvKdyiQcB15S23fQ
	E9WVYYcJe6q/bd7q5drwLql0BSs0BBfN5aakFAWpVM3lxO8EuUYOMrrR/xeH//NN1qo4
	+QIb+VTRd/BZCVje7Z6n4/zWr2Qlyg1ENOSYDO8zALU8Q3WFjHdX8GUs0whu05tp8Twp
	RgCQ==
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
	d=1e100.net; s=20161025;
	h=x-gm-message-state:sender:from:to:cc:subject:date:message-id
	:in-reply-to:references;
	bh=MOey/9FPH+9zGAdY9RYLcXFpZMGv/rgtGFYfWDiKf+Y=;
	b=mQ+WngDt2My+kOOjUDaQgJjL4FdmA/l1QVj0VqTc8l6Zr2kBHguHwbPU2IDN5rTTkA
	RCcJLqBqfnKIqMleiksm2Yqm3P92B51WbgMXAgESBfaQBoLxcJiZnY6pna8papBrwIon
	jJnC06+EMiXztmE7OkxFxZS7JozZlJt52RBzze4W+8XAMqdGOUQ9Oq5o6k5VqIBl9JpZ
	RNGiMUaMVJHmdsJliZ/sg2QnNwB6V44JTiikr5SWZ2/jD+BuMKdGZh8OLBzbDOKkDRou
	zKtuzH5+tvFcJIwTmEipEfjcL7UAD41W5njEtDkvbpGx+HvyfPbXOOaS1ZwhAc5Z4nXO
	pYSw==
X-Gm-Message-State: AHYfb5gjUKln3X8rTsshLWUChMEVFDajvaqafxhpkRgEyeP466b3NELK
	3UTvqS3WOKYNKWMqXvA=
X-Received: by 10.28.87.6 with SMTP id l6mr2444256wmb.110.1503523571291;
	Wed, 23 Aug 2017 14:26:11 -0700 (PDT)
Received: from 640k.lan (94-39-192-75.adsl-ull.clienti.tiscali.it.
	[94.39.192.75]) by smtp.gmail.com with ESMTPSA id
	l4sm1612432wrb.70.2017.08.23.14.26.10
	(version=TLS1_2 cipher=ECDHE-RSA-AES128-GCM-SHA256 bits=128/128);
	Wed, 23 Aug 2017 14:26:10 -0700 (PDT)
From: Paolo Bonzini &lt;pbonzini@redhat.com&gt;
To: linux-kernel@vger.kernel.org, kvm@vger.kernel.org
Cc: junkang.fjk@alibaba-inc.com, yang.zhang.wz@gmail.com
Subject: [PATCH 1/2] KVM: x86: simplify handling of PKRU
Date: Wed, 23 Aug 2017 23:26:05 +0200
Message-Id: &lt;1503523566-25624-2-git-send-email-pbonzini@redhat.com&gt;
X-Mailer: git-send-email 1.8.3.1
In-Reply-To: &lt;1503523566-25624-1-git-send-email-pbonzini@redhat.com&gt;
References: &lt;1503523566-25624-1-git-send-email-pbonzini@redhat.com&gt;
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=2536">Paolo Bonzini</a> - Aug. 23, 2017, 9:26 p.m.</div>
<pre class="content">
Move it to struct kvm_arch_vcpu, replacing guest_pkru_valid with a
simple comparison against the host value of the register.
<span class="signed-off-by">
Signed-off-by: Paolo Bonzini &lt;pbonzini@redhat.com&gt;</span>
---
 arch/x86/include/asm/kvm_host.h |  1 +
 arch/x86/kvm/kvm_cache_regs.h   |  5 -----
 arch/x86/kvm/mmu.h              |  2 +-
 arch/x86/kvm/svm.c              |  7 -------
 arch/x86/kvm/vmx.c              | 23 ++++++-----------------
 5 files changed, 8 insertions(+), 30 deletions(-)
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=148521">Yang Zhang</a> - Aug. 24, 2017, 9:09 a.m.</div>
<pre class="content">
On 2017/8/24 5:26, Paolo Bonzini wrote:
<span class="quote">&gt; Move it to struct kvm_arch_vcpu, replacing guest_pkru_valid with a</span>
<span class="quote">&gt; simple comparison against the host value of the register.</span>

Thanks for refine the patches.:)
<span class="quote">
&gt; </span>
<span class="quote">&gt; Signed-off-by: Paolo Bonzini &lt;pbonzini@redhat.com&gt;</span>
<span class="quote">&gt; ---</span>
<span class="quote">&gt;   arch/x86/include/asm/kvm_host.h |  1 +</span>
<span class="quote">&gt;   arch/x86/kvm/kvm_cache_regs.h   |  5 -----</span>
<span class="quote">&gt;   arch/x86/kvm/mmu.h              |  2 +-</span>
<span class="quote">&gt;   arch/x86/kvm/svm.c              |  7 -------</span>
<span class="quote">&gt;   arch/x86/kvm/vmx.c              | 23 ++++++-----------------</span>
<span class="quote">&gt;   5 files changed, 8 insertions(+), 30 deletions(-)</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; diff --git a/arch/x86/include/asm/kvm_host.h b/arch/x86/include/asm/kvm_host.h</span>
<span class="quote">&gt; index 643308143bea..beb185361045 100644</span>
<span class="quote">&gt; --- a/arch/x86/include/asm/kvm_host.h</span>
<span class="quote">&gt; +++ b/arch/x86/include/asm/kvm_host.h</span>
<span class="quote">&gt; @@ -491,6 +491,7 @@ struct kvm_vcpu_arch {</span>
<span class="quote">&gt;   	unsigned long cr4;</span>
<span class="quote">&gt;   	unsigned long cr4_guest_owned_bits;</span>
<span class="quote">&gt;   	unsigned long cr8;</span>
<span class="quote">&gt; +	u32 pkru;</span>
<span class="quote">&gt;   	u32 hflags;</span>
<span class="quote">&gt;   	u64 efer;</span>
<span class="quote">&gt;   	u64 apic_base;</span>
<span class="quote">&gt; diff --git a/arch/x86/kvm/kvm_cache_regs.h b/arch/x86/kvm/kvm_cache_regs.h</span>
<span class="quote">&gt; index 762cdf2595f9..e1e89ee4af75 100644</span>
<span class="quote">&gt; --- a/arch/x86/kvm/kvm_cache_regs.h</span>
<span class="quote">&gt; +++ b/arch/x86/kvm/kvm_cache_regs.h</span>
<span class="quote">&gt; @@ -84,11 +84,6 @@ static inline u64 kvm_read_edx_eax(struct kvm_vcpu *vcpu)</span>
<span class="quote">&gt;   		| ((u64)(kvm_register_read(vcpu, VCPU_REGS_RDX) &amp; -1u) &lt;&lt; 32);</span>
<span class="quote">&gt;   }</span>
<span class="quote">&gt;   </span>
<span class="quote">&gt; -static inline u32 kvm_read_pkru(struct kvm_vcpu *vcpu)</span>
<span class="quote">&gt; -{</span>
<span class="quote">&gt; -	return kvm_x86_ops-&gt;get_pkru(vcpu);</span>
<span class="quote">&gt; -}</span>
<span class="quote">&gt; -</span>
<span class="quote">&gt;   static inline void enter_guest_mode(struct kvm_vcpu *vcpu)</span>
<span class="quote">&gt;   {</span>
<span class="quote">&gt;   	vcpu-&gt;arch.hflags |= HF_GUEST_MASK;</span>
<span class="quote">&gt; diff --git a/arch/x86/kvm/mmu.h b/arch/x86/kvm/mmu.h</span>
<span class="quote">&gt; index 3ed6192d93b1..1b3095264fcf 100644</span>
<span class="quote">&gt; --- a/arch/x86/kvm/mmu.h</span>
<span class="quote">&gt; +++ b/arch/x86/kvm/mmu.h</span>
<span class="quote">&gt; @@ -168,7 +168,7 @@ static inline u8 permission_fault(struct kvm_vcpu *vcpu, struct kvm_mmu *mmu,</span>
<span class="quote">&gt;   		* index of the protection domain, so pte_pkey * 2 is</span>
<span class="quote">&gt;   		* is the index of the first bit for the domain.</span>
<span class="quote">&gt;   		*/</span>
<span class="quote">&gt; -		pkru_bits = (kvm_read_pkru(vcpu) &gt;&gt; (pte_pkey * 2)) &amp; 3;</span>
<span class="quote">&gt; +		pkru_bits = (vcpu-&gt;arch.pkru &gt;&gt; (pte_pkey * 2)) &amp; 3;</span>
<span class="quote">&gt;   </span>
<span class="quote">&gt;   		/* clear present bit, replace PFEC.RSVD with ACC_USER_MASK. */</span>
<span class="quote">&gt;   		offset = (pfec &amp; ~1) +</span>
<span class="quote">&gt; diff --git a/arch/x86/kvm/svm.c b/arch/x86/kvm/svm.c</span>
<span class="quote">&gt; index 32c8d8f62985..f2355135164c 100644</span>
<span class="quote">&gt; --- a/arch/x86/kvm/svm.c</span>
<span class="quote">&gt; +++ b/arch/x86/kvm/svm.c</span>
<span class="quote">&gt; @@ -1826,11 +1826,6 @@ static void svm_set_rflags(struct kvm_vcpu *vcpu, unsigned long rflags)</span>
<span class="quote">&gt;   	to_svm(vcpu)-&gt;vmcb-&gt;save.rflags = rflags;</span>
<span class="quote">&gt;   }</span>
<span class="quote">&gt;   </span>
<span class="quote">&gt; -static u32 svm_get_pkru(struct kvm_vcpu *vcpu)</span>
<span class="quote">&gt; -{</span>
<span class="quote">&gt; -	return 0;</span>
<span class="quote">&gt; -}</span>
<span class="quote">&gt; -</span>
<span class="quote">&gt;   static void svm_cache_reg(struct kvm_vcpu *vcpu, enum kvm_reg reg)</span>
<span class="quote">&gt;   {</span>
<span class="quote">&gt;   	switch (reg) {</span>
<span class="quote">&gt; @@ -5438,8 +5433,6 @@ static void svm_setup_mce(struct kvm_vcpu *vcpu)</span>
<span class="quote">&gt;   	.get_rflags = svm_get_rflags,</span>
<span class="quote">&gt;   	.set_rflags = svm_set_rflags,</span>
<span class="quote">&gt;   </span>
<span class="quote">&gt; -	.get_pkru = svm_get_pkru,</span>
<span class="quote">&gt; -</span>
<span class="quote">&gt;   	.tlb_flush = svm_flush_tlb,</span>
<span class="quote">&gt;   </span>
<span class="quote">&gt;   	.run = svm_vcpu_run,</span>
<span class="quote">&gt; diff --git a/arch/x86/kvm/vmx.c b/arch/x86/kvm/vmx.c</span>
<span class="quote">&gt; index ddabed8425b3..c603f658c42a 100644</span>
<span class="quote">&gt; --- a/arch/x86/kvm/vmx.c</span>
<span class="quote">&gt; +++ b/arch/x86/kvm/vmx.c</span>
<span class="quote">&gt; @@ -639,8 +639,6 @@ struct vcpu_vmx {</span>
<span class="quote">&gt;   </span>
<span class="quote">&gt;   	u64 current_tsc_ratio;</span>
<span class="quote">&gt;   </span>
<span class="quote">&gt; -	bool guest_pkru_valid;</span>
<span class="quote">&gt; -	u32 guest_pkru;</span>
<span class="quote">&gt;   	u32 host_pkru;</span>
<span class="quote">&gt;   </span>
<span class="quote">&gt;   	/*</span>
<span class="quote">&gt; @@ -2392,11 +2390,6 @@ static void vmx_set_rflags(struct kvm_vcpu *vcpu, unsigned long rflags)</span>
<span class="quote">&gt;   		to_vmx(vcpu)-&gt;emulation_required = emulation_required(vcpu);</span>
<span class="quote">&gt;   }</span>
<span class="quote">&gt;   </span>
<span class="quote">&gt; -static u32 vmx_get_pkru(struct kvm_vcpu *vcpu)</span>
<span class="quote">&gt; -{</span>
<span class="quote">&gt; -	return to_vmx(vcpu)-&gt;guest_pkru;</span>
<span class="quote">&gt; -}</span>
<span class="quote">&gt; -</span>
<span class="quote">&gt;   static u32 vmx_get_interrupt_shadow(struct kvm_vcpu *vcpu)</span>
<span class="quote">&gt;   {</span>
<span class="quote">&gt;   	u32 interruptibility = vmcs_read32(GUEST_INTERRUPTIBILITY_INFO);</span>
<span class="quote">&gt; @@ -9239,8 +9232,9 @@ static void __noclone vmx_vcpu_run(struct kvm_vcpu *vcpu)</span>
<span class="quote">&gt;   	if (vcpu-&gt;guest_debug &amp; KVM_GUESTDBG_SINGLESTEP)</span>
<span class="quote">&gt;   		vmx_set_interrupt_shadow(vcpu, 0);</span>
<span class="quote">&gt;   </span>
<span class="quote">&gt; -	if (vmx-&gt;guest_pkru_valid)</span>
<span class="quote">&gt; -		__write_pkru(vmx-&gt;guest_pkru);</span>
<span class="quote">&gt; +	if (static_cpu_has(X86_FEATURE_OSPKE) &amp;&amp;</span>

We expose protection key to VM without check whether OSPKE is enabled or 
not. Why not check guest&#39;s cpuid here which also can avoid unnecessary 
access to pkru?
<span class="quote">
&gt; +	    vcpu-&gt;arch.pkru != vmx-&gt;host_pkru)</span>
<span class="quote">&gt; +		__write_pkru(vcpu-&gt;arch.pkru);</span>
<span class="quote">&gt;   </span>
<span class="quote">&gt;   	atomic_switch_perf_msrs(vmx);</span>
<span class="quote">&gt;   	debugctlmsr = get_debugctlmsr();</span>
<span class="quote">&gt; @@ -9388,13 +9382,10 @@ static void __noclone vmx_vcpu_run(struct kvm_vcpu *vcpu)</span>
<span class="quote">&gt;   	 * back on host, so it is safe to read guest PKRU from current</span>
<span class="quote">&gt;   	 * XSAVE.</span>
<span class="quote">&gt;   	 */</span>
<span class="quote">&gt; -	if (boot_cpu_has(X86_FEATURE_OSPKE)) {</span>
<span class="quote">&gt; -		vmx-&gt;guest_pkru = __read_pkru();</span>
<span class="quote">&gt; -		if (vmx-&gt;guest_pkru != vmx-&gt;host_pkru) {</span>
<span class="quote">&gt; -			vmx-&gt;guest_pkru_valid = true;</span>
<span class="quote">&gt; +	if (static_cpu_has(X86_FEATURE_OSPKE)) {</span>
<span class="quote">&gt; +		vcpu-&gt;arch.pkru = __read_pkru();</span>
<span class="quote">&gt; +		if (vcpu-&gt;arch.pkru != vmx-&gt;host_pkru)</span>
<span class="quote">&gt;   			__write_pkru(vmx-&gt;host_pkru);</span>
<span class="quote">&gt; -		} else</span>
<span class="quote">&gt; -			vmx-&gt;guest_pkru_valid = false;</span>
<span class="quote">&gt;   	}</span>
<span class="quote">&gt;   </span>
<span class="quote">&gt;   	/*</span>
<span class="quote">&gt; @@ -11875,8 +11866,6 @@ static void vmx_setup_mce(struct kvm_vcpu *vcpu)</span>
<span class="quote">&gt;   	.get_rflags = vmx_get_rflags,</span>
<span class="quote">&gt;   	.set_rflags = vmx_set_rflags,</span>
<span class="quote">&gt;   </span>
<span class="quote">&gt; -	.get_pkru = vmx_get_pkru,</span>
<span class="quote">&gt; -</span>
<span class="quote">&gt;   	.tlb_flush = vmx_flush_tlb,</span>
<span class="quote">&gt;   </span>
<span class="quote">&gt;   	.run = vmx_vcpu_run,</span>
<span class="quote">&gt;</span>
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=2536">Paolo Bonzini</a> - Aug. 24, 2017, 9:19 a.m.</div>
<pre class="content">
On 24/08/2017 11:09, Yang Zhang wrote:
<span class="quote">&gt;&gt; +    if (static_cpu_has(X86_FEATURE_OSPKE) &amp;&amp;</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; We expose protection key to VM without check whether OSPKE is enabled or</span>
<span class="quote">&gt; not. Why not check guest&#39;s cpuid here which also can avoid unnecessary</span>
<span class="quote">&gt; access to pkru?</span>

Checking guest CPUID is pretty slow.  We could check CR4.PKE though.

Also, using static_cpu_has with OSPKE is probably wrong.  But if we do
check CR4.PKE, we can check X86_FEATURE_PKU instead, so something like

	if (static_cpu_has(X86_FEATURE_PKU) &amp;&amp;
	    kvm_read_cr4_bits(vcpu, X86_CR4_PKE) &amp;&amp;
	    vcpu-&gt;arch.pkru != vmx-&gt;host_pkru)

... but then, kvm_read_cr4_bits is also pretty slow---and we don&#39;t
really need it, since all CR4 writes cause a vmexit.  So for now I&#39;d
stay with this patch, only s/static_cpu_has/boot_cpu_has/g.

Of course you can send improvements on top!

Paolo
<span class="quote">
&gt;&gt; +        vcpu-&gt;arch.pkru != vmx-&gt;host_pkru)</span>
<span class="quote">&gt;&gt; +        __write_pkru(vcpu-&gt;arch.pkru);</span>
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=148521">Yang Zhang</a> - Aug. 24, 2017, 10:05 a.m.</div>
<pre class="content">
On 2017/8/24 17:19, Paolo Bonzini wrote:
<span class="quote">&gt; On 24/08/2017 11:09, Yang Zhang wrote:</span>
<span class="quote">&gt;&gt;&gt; +    if (static_cpu_has(X86_FEATURE_OSPKE) &amp;&amp;</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; We expose protection key to VM without check whether OSPKE is enabled or</span>
<span class="quote">&gt;&gt; not. Why not check guest&#39;s cpuid here which also can avoid unnecessary</span>
<span class="quote">&gt;&gt; access to pkru?</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Checking guest CPUID is pretty slow.  We could check CR4.PKE though.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Also, using static_cpu_has with OSPKE is probably wrong.  But if we do</span>
<span class="quote">&gt; check CR4.PKE, we can check X86_FEATURE_PKU instead, so something like</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; 	if (static_cpu_has(X86_FEATURE_PKU) &amp;&amp;</span>
<span class="quote">&gt; 	    kvm_read_cr4_bits(vcpu, X86_CR4_PKE) &amp;&amp;</span>
<span class="quote">&gt; 	    vcpu-&gt;arch.pkru != vmx-&gt;host_pkru)</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; ... but then, kvm_read_cr4_bits is also pretty slow---and we don&#39;t</span>
<span class="quote">&gt; really need it, since all CR4 writes cause a vmexit.  So for now I&#39;d</span>
<span class="quote">&gt; stay with this patch, only s/static_cpu_has/boot_cpu_has/g.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Of course you can send improvements on top!</span>

ok, since most OS distributions don&#39;t support protection key so far 
which means vcpu-&gt;arch.pkru always 0 in it and i remember host_pkru will 
be set to 55555554 be default. To avoid the unnecessary access to pkru, 
how about the following change:

@@ -4338,6 +4331,9 @@ static int vmx_set_cr4(struct kvm_vcpu *vcpu, 
unsigned long cr4)
                         return 1;
         }

+       if (cr4 &amp; X86_CR4_PKE)
+               to_vmx(vcpu)-&gt;guest_pkru_valid = true;
+
         if (to_vmx(vcpu)-&gt;nested.vmxon &amp;&amp; !nested_cr4_valid(vcpu, cr4))
                 return 1;

@@ -9020,8 +9016,10 @@ static void __noclone vmx_vcpu_run(struct 
kvm_vcpu *vcpu)
         if (vcpu-&gt;guest_debug &amp; KVM_GUESTDBG_SINGLESTEP)
                 vmx_set_interrupt_shadow(vcpu, 0);

-       if (vmx-&gt;guest_pkru_valid)
-               __write_pkru(vmx-&gt;guest_pkru);
+       if (static_cpu_has(X86_FEATURE_OSPKE) &amp;&amp;
+           vmx-&gt;guest_pkru_valid &amp;&amp;
+           vcpu-&gt;arch.pkru != vmx-&gt;host_pkru)
+               __write_pkru(vcpu-&gt;arch.pkru);

         atomic_switch_perf_msrs(vmx);
         debugctlmsr = get_debugctlmsr();
@@ -9169,13 +9167,11 @@ static void __noclone vmx_vcpu_run(struct 
kvm_vcpu *vcpu)
          * back on host, so it is safe to read guest PKRU from current
          * XSAVE.
          */
-       if (boot_cpu_has(X86_FEATURE_OSPKE)) {
-               vmx-&gt;guest_pkru = __read_pkru();
-               if (vmx-&gt;guest_pkru != vmx-&gt;host_pkru) {
-                       vmx-&gt;guest_pkru_valid = true;
+       if (static_cpu_has(X86_FEATURE_OSPKE) &amp;&amp;
+           vmx-&gt;guest_pkru_valid) {
+               vcpu-&gt;arch.pkru = __read_pkru();
+               if (vcpu-&gt;arch.pkru != vmx-&gt;host_pkru)
                         __write_pkru(vmx-&gt;host_pkru);
-               } else
-                       vmx-&gt;guest_pkru_valid = false;
         }

         /*
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=2536">Paolo Bonzini</a> - Aug. 24, 2017, 10:14 a.m.</div>
<pre class="content">
On 24/08/2017 12:05, Yang Zhang wrote:
<span class="quote">&gt; On 2017/8/24 17:19, Paolo Bonzini wrote:</span>
<span class="quote">&gt;&gt; On 24/08/2017 11:09, Yang Zhang wrote:</span>
<span class="quote">&gt;&gt;&gt;&gt; +    if (static_cpu_has(X86_FEATURE_OSPKE) &amp;&amp;</span>
<span class="quote">&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt; We expose protection key to VM without check whether OSPKE is enabled or</span>
<span class="quote">&gt;&gt;&gt; not. Why not check guest&#39;s cpuid here which also can avoid unnecessary</span>
<span class="quote">&gt;&gt;&gt; access to pkru?</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; Checking guest CPUID is pretty slow.  We could check CR4.PKE though.</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; Also, using static_cpu_has with OSPKE is probably wrong.  But if we do</span>
<span class="quote">&gt;&gt; check CR4.PKE, we can check X86_FEATURE_PKU instead, so something like</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt;     if (static_cpu_has(X86_FEATURE_PKU) &amp;&amp;</span>
<span class="quote">&gt;&gt;         kvm_read_cr4_bits(vcpu, X86_CR4_PKE) &amp;&amp;</span>
<span class="quote">&gt;&gt;         vcpu-&gt;arch.pkru != vmx-&gt;host_pkru)</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; ... but then, kvm_read_cr4_bits is also pretty slow---and we don&#39;t</span>
<span class="quote">&gt;&gt; really need it, since all CR4 writes cause a vmexit.  So for now I&#39;d</span>
<span class="quote">&gt;&gt; stay with this patch, only s/static_cpu_has/boot_cpu_has/g.</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; Of course you can send improvements on top!</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; ok, since most OS distributions don&#39;t support protection key so far</span>
<span class="quote">&gt; which means vcpu-&gt;arch.pkru always 0 in it and i remember host_pkru will</span>
<span class="quote">&gt; be set to 55555554 be default. To avoid the unnecessary access to pkru,</span>
<span class="quote">&gt; how about the following change:</span>

Even better: reading guest&#39;s CR4.PKE is actually _not_ slow because
X86_CR4_PKE is not part of KVM_POSSIBLE_CR4_GUEST_BITS.  So
kvm_read_cr4_bits(vcpu, X86_CR4_PKE) is compiled to just &quot;vcpu-&gt;arch.cr4
&amp; X86_CR4_PKE&quot;.

We need to be careful though to disable guest PKU if host OSPKE is off,
because otherwise __read_pkru and __write_pkru cause a #GP.

I&#39;ve sent v2 of the series now, incorporating your suggestion.  Thanks!

Paolo
<span class="quote">
&gt; @@ -4338,6 +4331,9 @@ static int vmx_set_cr4(struct kvm_vcpu *vcpu,</span>
<span class="quote">&gt; unsigned long cr4)</span>
<span class="quote">&gt;                         return 1;</span>
<span class="quote">&gt;         }</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; +       if (cr4 &amp; X86_CR4_PKE)</span>
<span class="quote">&gt; +               to_vmx(vcpu)-&gt;guest_pkru_valid = true;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt;         if (to_vmx(vcpu)-&gt;nested.vmxon &amp;&amp; !nested_cr4_valid(vcpu, cr4))</span>
<span class="quote">&gt;                 return 1;</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; @@ -9020,8 +9016,10 @@ static void __noclone vmx_vcpu_run(struct</span>
<span class="quote">&gt; kvm_vcpu *vcpu)</span>
<span class="quote">&gt;         if (vcpu-&gt;guest_debug &amp; KVM_GUESTDBG_SINGLESTEP)</span>
<span class="quote">&gt;                 vmx_set_interrupt_shadow(vcpu, 0);</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; -       if (vmx-&gt;guest_pkru_valid)</span>
<span class="quote">&gt; -               __write_pkru(vmx-&gt;guest_pkru);</span>
<span class="quote">&gt; +       if (static_cpu_has(X86_FEATURE_OSPKE) &amp;&amp;</span>
<span class="quote">&gt; +           vmx-&gt;guest_pkru_valid &amp;&amp;</span>
<span class="quote">&gt; +           vcpu-&gt;arch.pkru != vmx-&gt;host_pkru)</span>
<span class="quote">&gt; +               __write_pkru(vcpu-&gt;arch.pkru);</span>
<span class="quote">&gt; </span>
<span class="quote">&gt;         atomic_switch_perf_msrs(vmx);</span>
<span class="quote">&gt;         debugctlmsr = get_debugctlmsr();</span>
<span class="quote">&gt; @@ -9169,13 +9167,11 @@ static void __noclone vmx_vcpu_run(struct</span>
<span class="quote">&gt; kvm_vcpu *vcpu)</span>
<span class="quote">&gt;          * back on host, so it is safe to read guest PKRU from current</span>
<span class="quote">&gt;          * XSAVE.</span>
<span class="quote">&gt;          */</span>
<span class="quote">&gt; -       if (boot_cpu_has(X86_FEATURE_OSPKE)) {</span>
<span class="quote">&gt; -               vmx-&gt;guest_pkru = __read_pkru();</span>
<span class="quote">&gt; -               if (vmx-&gt;guest_pkru != vmx-&gt;host_pkru) {</span>
<span class="quote">&gt; -                       vmx-&gt;guest_pkru_valid = true;</span>
<span class="quote">&gt; +       if (static_cpu_has(X86_FEATURE_OSPKE) &amp;&amp;</span>
<span class="quote">&gt; +           vmx-&gt;guest_pkru_valid) {</span>
<span class="quote">&gt; +               vcpu-&gt;arch.pkru = __read_pkru();</span>
<span class="quote">&gt; +               if (vcpu-&gt;arch.pkru != vmx-&gt;host_pkru)</span>
<span class="quote">&gt;                         __write_pkru(vmx-&gt;host_pkru);</span>
<span class="quote">&gt; -               } else</span>
<span class="quote">&gt; -                       vmx-&gt;guest_pkru_valid = false;</span>
<span class="quote">&gt;         }</span>
<span class="quote">&gt; </span>
<span class="quote">&gt;         /*</span>
<span class="quote">&gt;</span>
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/arch/x86/include/asm/kvm_host.h b/arch/x86/include/asm/kvm_host.h</span>
<span class="p_header">index 643308143bea..beb185361045 100644</span>
<span class="p_header">--- a/arch/x86/include/asm/kvm_host.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/kvm_host.h</span>
<span class="p_chunk">@@ -491,6 +491,7 @@</span> <span class="p_context"> struct kvm_vcpu_arch {</span>
 	unsigned long cr4;
 	unsigned long cr4_guest_owned_bits;
 	unsigned long cr8;
<span class="p_add">+	u32 pkru;</span>
 	u32 hflags;
 	u64 efer;
 	u64 apic_base;
<span class="p_header">diff --git a/arch/x86/kvm/kvm_cache_regs.h b/arch/x86/kvm/kvm_cache_regs.h</span>
<span class="p_header">index 762cdf2595f9..e1e89ee4af75 100644</span>
<span class="p_header">--- a/arch/x86/kvm/kvm_cache_regs.h</span>
<span class="p_header">+++ b/arch/x86/kvm/kvm_cache_regs.h</span>
<span class="p_chunk">@@ -84,11 +84,6 @@</span> <span class="p_context"> static inline u64 kvm_read_edx_eax(struct kvm_vcpu *vcpu)</span>
 		| ((u64)(kvm_register_read(vcpu, VCPU_REGS_RDX) &amp; -1u) &lt;&lt; 32);
 }
 
<span class="p_del">-static inline u32 kvm_read_pkru(struct kvm_vcpu *vcpu)</span>
<span class="p_del">-{</span>
<span class="p_del">-	return kvm_x86_ops-&gt;get_pkru(vcpu);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
 static inline void enter_guest_mode(struct kvm_vcpu *vcpu)
 {
 	vcpu-&gt;arch.hflags |= HF_GUEST_MASK;
<span class="p_header">diff --git a/arch/x86/kvm/mmu.h b/arch/x86/kvm/mmu.h</span>
<span class="p_header">index 3ed6192d93b1..1b3095264fcf 100644</span>
<span class="p_header">--- a/arch/x86/kvm/mmu.h</span>
<span class="p_header">+++ b/arch/x86/kvm/mmu.h</span>
<span class="p_chunk">@@ -168,7 +168,7 @@</span> <span class="p_context"> static inline u8 permission_fault(struct kvm_vcpu *vcpu, struct kvm_mmu *mmu,</span>
 		* index of the protection domain, so pte_pkey * 2 is
 		* is the index of the first bit for the domain.
 		*/
<span class="p_del">-		pkru_bits = (kvm_read_pkru(vcpu) &gt;&gt; (pte_pkey * 2)) &amp; 3;</span>
<span class="p_add">+		pkru_bits = (vcpu-&gt;arch.pkru &gt;&gt; (pte_pkey * 2)) &amp; 3;</span>
 
 		/* clear present bit, replace PFEC.RSVD with ACC_USER_MASK. */
 		offset = (pfec &amp; ~1) +
<span class="p_header">diff --git a/arch/x86/kvm/svm.c b/arch/x86/kvm/svm.c</span>
<span class="p_header">index 32c8d8f62985..f2355135164c 100644</span>
<span class="p_header">--- a/arch/x86/kvm/svm.c</span>
<span class="p_header">+++ b/arch/x86/kvm/svm.c</span>
<span class="p_chunk">@@ -1826,11 +1826,6 @@</span> <span class="p_context"> static void svm_set_rflags(struct kvm_vcpu *vcpu, unsigned long rflags)</span>
 	to_svm(vcpu)-&gt;vmcb-&gt;save.rflags = rflags;
 }
 
<span class="p_del">-static u32 svm_get_pkru(struct kvm_vcpu *vcpu)</span>
<span class="p_del">-{</span>
<span class="p_del">-	return 0;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
 static void svm_cache_reg(struct kvm_vcpu *vcpu, enum kvm_reg reg)
 {
 	switch (reg) {
<span class="p_chunk">@@ -5438,8 +5433,6 @@</span> <span class="p_context"> static void svm_setup_mce(struct kvm_vcpu *vcpu)</span>
 	.get_rflags = svm_get_rflags,
 	.set_rflags = svm_set_rflags,
 
<span class="p_del">-	.get_pkru = svm_get_pkru,</span>
<span class="p_del">-</span>
 	.tlb_flush = svm_flush_tlb,
 
 	.run = svm_vcpu_run,
<span class="p_header">diff --git a/arch/x86/kvm/vmx.c b/arch/x86/kvm/vmx.c</span>
<span class="p_header">index ddabed8425b3..c603f658c42a 100644</span>
<span class="p_header">--- a/arch/x86/kvm/vmx.c</span>
<span class="p_header">+++ b/arch/x86/kvm/vmx.c</span>
<span class="p_chunk">@@ -639,8 +639,6 @@</span> <span class="p_context"> struct vcpu_vmx {</span>
 
 	u64 current_tsc_ratio;
 
<span class="p_del">-	bool guest_pkru_valid;</span>
<span class="p_del">-	u32 guest_pkru;</span>
 	u32 host_pkru;
 
 	/*
<span class="p_chunk">@@ -2392,11 +2390,6 @@</span> <span class="p_context"> static void vmx_set_rflags(struct kvm_vcpu *vcpu, unsigned long rflags)</span>
 		to_vmx(vcpu)-&gt;emulation_required = emulation_required(vcpu);
 }
 
<span class="p_del">-static u32 vmx_get_pkru(struct kvm_vcpu *vcpu)</span>
<span class="p_del">-{</span>
<span class="p_del">-	return to_vmx(vcpu)-&gt;guest_pkru;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
 static u32 vmx_get_interrupt_shadow(struct kvm_vcpu *vcpu)
 {
 	u32 interruptibility = vmcs_read32(GUEST_INTERRUPTIBILITY_INFO);
<span class="p_chunk">@@ -9239,8 +9232,9 @@</span> <span class="p_context"> static void __noclone vmx_vcpu_run(struct kvm_vcpu *vcpu)</span>
 	if (vcpu-&gt;guest_debug &amp; KVM_GUESTDBG_SINGLESTEP)
 		vmx_set_interrupt_shadow(vcpu, 0);
 
<span class="p_del">-	if (vmx-&gt;guest_pkru_valid)</span>
<span class="p_del">-		__write_pkru(vmx-&gt;guest_pkru);</span>
<span class="p_add">+	if (static_cpu_has(X86_FEATURE_OSPKE) &amp;&amp;</span>
<span class="p_add">+	    vcpu-&gt;arch.pkru != vmx-&gt;host_pkru)</span>
<span class="p_add">+		__write_pkru(vcpu-&gt;arch.pkru);</span>
 
 	atomic_switch_perf_msrs(vmx);
 	debugctlmsr = get_debugctlmsr();
<span class="p_chunk">@@ -9388,13 +9382,10 @@</span> <span class="p_context"> static void __noclone vmx_vcpu_run(struct kvm_vcpu *vcpu)</span>
 	 * back on host, so it is safe to read guest PKRU from current
 	 * XSAVE.
 	 */
<span class="p_del">-	if (boot_cpu_has(X86_FEATURE_OSPKE)) {</span>
<span class="p_del">-		vmx-&gt;guest_pkru = __read_pkru();</span>
<span class="p_del">-		if (vmx-&gt;guest_pkru != vmx-&gt;host_pkru) {</span>
<span class="p_del">-			vmx-&gt;guest_pkru_valid = true;</span>
<span class="p_add">+	if (static_cpu_has(X86_FEATURE_OSPKE)) {</span>
<span class="p_add">+		vcpu-&gt;arch.pkru = __read_pkru();</span>
<span class="p_add">+		if (vcpu-&gt;arch.pkru != vmx-&gt;host_pkru)</span>
 			__write_pkru(vmx-&gt;host_pkru);
<span class="p_del">-		} else</span>
<span class="p_del">-			vmx-&gt;guest_pkru_valid = false;</span>
 	}
 
 	/*
<span class="p_chunk">@@ -11875,8 +11866,6 @@</span> <span class="p_context"> static void vmx_setup_mce(struct kvm_vcpu *vcpu)</span>
 	.get_rflags = vmx_get_rflags,
 	.set_rflags = vmx_set_rflags,
 
<span class="p_del">-	.get_pkru = vmx_get_pkru,</span>
<span class="p_del">-</span>
 	.tlb_flush = vmx_flush_tlb,
 
 	.run = vmx_vcpu_run,

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



