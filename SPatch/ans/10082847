
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>[ANNOUNCE] 4.4.97-rt111 - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    [ANNOUNCE] 4.4.97-rt111</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=310">Steven Rostedt</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>Nov. 29, 2017, 4:52 p.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;20171129115259.170bb9a8@gandalf.local.home&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/10082847/mbox/"
   >mbox</a>
|
   <a href="/patch/10082847/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/10082847/">/patch/10082847/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
	[172.30.200.125])
	by pdx-korg-patchwork.web.codeaurora.org (Postfix) with ESMTP id
	AFAA160353 for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Wed, 29 Nov 2017 16:53:08 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 98E2E29B38
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Wed, 29 Nov 2017 16:53:08 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id 8DCF429B6A; Wed, 29 Nov 2017 16:53:08 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-6.9 required=2.0 tests=BAYES_00,RCVD_IN_DNSWL_HI
	autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 88ED829B38
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Wed, 29 Nov 2017 16:53:07 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S933833AbdK2QxE (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Wed, 29 Nov 2017 11:53:04 -0500
Received: from mail.kernel.org ([198.145.29.99]:45156 &quot;EHLO mail.kernel.org&quot;
	rhost-flags-OK-OK-OK-OK) by vger.kernel.org with ESMTP
	id S933711AbdK2QxC (ORCPT &lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Wed, 29 Nov 2017 11:53:02 -0500
Received: from gandalf.local.home (cpe-172-100-180-131.stny.res.rr.com
	[172.100.180.131])
	(using TLSv1.2 with cipher ECDHE-RSA-AES256-GCM-SHA384 (256/256
	bits)) (No client certificate requested)
	by mail.kernel.org (Postfix) with ESMTPSA id A5DBC2197D;
	Wed, 29 Nov 2017 16:53:00 +0000 (UTC)
DMARC-Filter: OpenDMARC Filter v1.3.2 mail.kernel.org A5DBC2197D
Authentication-Results: mail.kernel.org;
	dmarc=none (p=none dis=none) header.from=goodmis.org
Authentication-Results: mail.kernel.org;
	spf=none smtp.mailfrom=rostedt@goodmis.org
Date: Wed, 29 Nov 2017 11:52:59 -0500
From: Steven Rostedt &lt;rostedt@goodmis.org&gt;
To: LKML &lt;linux-kernel@vger.kernel.org&gt;,
	linux-rt-users &lt;linux-rt-users@vger.kernel.org&gt;
Cc: Thomas Gleixner &lt;tglx@linutronix.de&gt;, Carsten Emde &lt;C.Emde@osadl.org&gt;,
	John Kacur &lt;jkacur@redhat.com&gt;,
	Sebastian Andrzej Siewior &lt;bigeasy@linutronix.de&gt;,
	Julia Cartwright &lt;julia@ni.com&gt;,
	Daniel Wagner &lt;daniel.wagner@siemens.com&gt;,
	tom.zanussi@linux.intel.com, Alex Shi &lt;alex.shi@linaro.org&gt;
Subject: [ANNOUNCE] 4.4.97-rt111
Message-ID: &lt;20171129115259.170bb9a8@gandalf.local.home&gt;
X-Mailer: Claws Mail 3.14.0 (GTK+ 2.24.31; x86_64-pc-linux-gnu)
MIME-Version: 1.0
Content-Type: text/plain; charset=US-ASCII
Content-Transfer-Encoding: 7bit
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=310">Steven Rostedt</a> - Nov. 29, 2017, 4:52 p.m.</div>
<pre class="content">
Dear RT Folks,

I&#39;m pleased to announce the 4.4.97-rt111 stable release.


You can get this release via the git tree at:

  git://git.kernel.org/pub/scm/linux/kernel/git/rt/linux-stable-rt.git

  branch: v4.4-rt
  Head SHA1: 8a76c8160f17b98621e66686d042afdd7a981ece


Or to build 4.4.97-rt111 directly, the following patches should be applied:

  http://www.kernel.org/pub/linux/kernel/v4.x/linux-4.4.tar.xz

  http://www.kernel.org/pub/linux/kernel/v4.x/patch-4.4.97.xz

  http://www.kernel.org/pub/linux/kernel/projects/rt/4.4/patch-4.4.97-rt111.patch.xz



You can also build from 4.4.97-rt110 by applying the incremental patch:

  http://www.kernel.org/pub/linux/kernel/projects/rt/4.4/incr/patch-4.4.97-rt110-rt111.patch.xz



Enjoy,

-- Steve


Changes from v4.4.97-rt110:

---

Peter Zijlstra (1):
      sched: Remove TASK_ALL

Sebastian Andrzej Siewior (6):
      timer/hrtimer: check properly for a running timer
      random: avoid preempt_disable()ed section
      sched/migrate disable: handle updated task-mask mg-dis section
      kernel/locking: use an exclusive wait_q for sleepers
      fs: convert two more BH_Uptodate_Lock related bitspinlocks
      md/raid5: do not disable interrupts

Steven Rostedt (VMware) (1):
      Linux 4.4.97-rt111

Thomas Gleixner (2):
      rtmutex: Make lock_killable work
      sched: Prevent task state corruption by spurious lock wakeup

----
 drivers/char/random.c    | 10 +++---
 drivers/md/raid5.c       |  4 +--
 fs/ext4/page-io.c        |  6 ++--
 include/linux/hrtimer.h  |  8 ++++-
 include/linux/sched.h    | 19 ++++++++++--
 kernel/fork.c            |  1 +
 kernel/locking/rtmutex.c | 21 +++++--------
 kernel/sched/core.c      | 81 +++++++++++++++++++++++++++++++++++++++++-------
 localversion-rt          |  2 +-
 9 files changed, 113 insertions(+), 39 deletions(-)
---------------------------
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/drivers/char/random.c b/drivers/char/random.c</span>
<span class="p_header">index fecc40a69df8..46c0e27cf27f 100644</span>
<span class="p_header">--- a/drivers/char/random.c</span>
<span class="p_header">+++ b/drivers/char/random.c</span>
<span class="p_chunk">@@ -260,6 +260,7 @@</span> <span class="p_context"></span>
 #include &lt;linux/irq.h&gt;
 #include &lt;linux/syscalls.h&gt;
 #include &lt;linux/completion.h&gt;
<span class="p_add">+#include &lt;linux/locallock.h&gt;</span>
 
 #include &lt;asm/processor.h&gt;
 #include &lt;asm/uaccess.h&gt;
<span class="p_chunk">@@ -1796,6 +1797,7 @@</span> <span class="p_context"> int random_int_secret_init(void)</span>
 
 static DEFINE_PER_CPU(__u32 [MD5_DIGEST_WORDS], get_random_int_hash)
 		__aligned(sizeof(unsigned long));
<span class="p_add">+static DEFINE_LOCAL_IRQ_LOCK(hash_entropy_int_lock);</span>
 
 /*
  * Get a random word for internal kernel use only. Similar to urandom but
<span class="p_chunk">@@ -1811,12 +1813,12 @@</span> <span class="p_context"> unsigned int get_random_int(void)</span>
 	if (arch_get_random_int(&amp;ret))
 		return ret;
 
<span class="p_del">-	hash = get_cpu_var(get_random_int_hash);</span>
<span class="p_add">+	hash = get_locked_var(hash_entropy_int_lock, get_random_int_hash);</span>
 
 	hash[0] += current-&gt;pid + jiffies + random_get_entropy();
 	md5_transform(hash, random_int_secret);
 	ret = hash[0];
<span class="p_del">-	put_cpu_var(get_random_int_hash);</span>
<span class="p_add">+	put_locked_var(hash_entropy_int_lock, get_random_int_hash);</span>
 
 	return ret;
 }
<span class="p_chunk">@@ -1833,12 +1835,12 @@</span> <span class="p_context"> unsigned long get_random_long(void)</span>
 	if (arch_get_random_long(&amp;ret))
 		return ret;
 
<span class="p_del">-	hash = get_cpu_var(get_random_int_hash);</span>
<span class="p_add">+	hash = get_locked_var(hash_entropy_int_lock, get_random_int_hash);</span>
 
 	hash[0] += current-&gt;pid + jiffies + random_get_entropy();
 	md5_transform(hash, random_int_secret);
 	ret = *(unsigned long *)hash;
<span class="p_del">-	put_cpu_var(get_random_int_hash);</span>
<span class="p_add">+	put_locked_var(hash_entropy_int_lock, get_random_int_hash);</span>
 
 	return ret;
 }
<span class="p_header">diff --git a/drivers/md/raid5.c b/drivers/md/raid5.c</span>
<span class="p_header">index 9b1aedb8e5df..8b236d622889 100644</span>
<span class="p_header">--- a/drivers/md/raid5.c</span>
<span class="p_header">+++ b/drivers/md/raid5.c</span>
<span class="p_chunk">@@ -429,7 +429,7 @@</span> <span class="p_context"> void raid5_release_stripe(struct stripe_head *sh)</span>
 		md_wakeup_thread(conf-&gt;mddev-&gt;thread);
 	return;
 slow_path:
<span class="p_del">-	local_irq_save(flags);</span>
<span class="p_add">+	local_irq_save_nort(flags);</span>
 	/* we are ok here if STRIPE_ON_RELEASE_LIST is set or not */
 	if (atomic_dec_and_lock(&amp;sh-&gt;count, &amp;conf-&gt;device_lock)) {
 		INIT_LIST_HEAD(&amp;list);
<span class="p_chunk">@@ -438,7 +438,7 @@</span> <span class="p_context"> slow_path:</span>
 		spin_unlock(&amp;conf-&gt;device_lock);
 		release_inactive_stripe_list(conf, &amp;list, hash);
 	}
<span class="p_del">-	local_irq_restore(flags);</span>
<span class="p_add">+	local_irq_restore_nort(flags);</span>
 }
 
 static inline void remove_hash(struct stripe_head *sh)
<span class="p_header">diff --git a/fs/ext4/page-io.c b/fs/ext4/page-io.c</span>
<span class="p_header">index 6ca56f5f72b5..9e145fe7cae0 100644</span>
<span class="p_header">--- a/fs/ext4/page-io.c</span>
<span class="p_header">+++ b/fs/ext4/page-io.c</span>
<span class="p_chunk">@@ -97,8 +97,7 @@</span> <span class="p_context"> static void ext4_finish_bio(struct bio *bio)</span>
 		 * We check all buffers in the page under BH_Uptodate_Lock
 		 * to avoid races with other end io clearing async_write flags
 		 */
<span class="p_del">-		local_irq_save(flags);</span>
<span class="p_del">-		bit_spin_lock(BH_Uptodate_Lock, &amp;head-&gt;b_state);</span>
<span class="p_add">+		flags = bh_uptodate_lock_irqsave(head);</span>
 		do {
 			if (bh_offset(bh) &lt; bio_start ||
 			    bh_offset(bh) + bh-&gt;b_size &gt; bio_end) {
<span class="p_chunk">@@ -110,8 +109,7 @@</span> <span class="p_context"> static void ext4_finish_bio(struct bio *bio)</span>
 			if (bio-&gt;bi_error)
 				buffer_io_error(bh);
 		} while ((bh = bh-&gt;b_this_page) != head);
<span class="p_del">-		bit_spin_unlock(BH_Uptodate_Lock, &amp;head-&gt;b_state);</span>
<span class="p_del">-		local_irq_restore(flags);</span>
<span class="p_add">+		bh_uptodate_unlock_irqrestore(head, flags);</span>
 		if (!under_io) {
 #ifdef CONFIG_EXT4_FS_ENCRYPTION
 			if (ctx)
<span class="p_header">diff --git a/include/linux/hrtimer.h b/include/linux/hrtimer.h</span>
<span class="p_header">index 8fbcdfa5dc77..ff317006d3e8 100644</span>
<span class="p_header">--- a/include/linux/hrtimer.h</span>
<span class="p_header">+++ b/include/linux/hrtimer.h</span>
<span class="p_chunk">@@ -455,7 +455,13 @@</span> <span class="p_context"> static inline int hrtimer_is_queued(struct hrtimer *timer)</span>
  */
 static inline int hrtimer_callback_running(const struct hrtimer *timer)
 {
<span class="p_del">-	return timer-&gt;base-&gt;cpu_base-&gt;running == timer;</span>
<span class="p_add">+	if (timer-&gt;base-&gt;cpu_base-&gt;running == timer)</span>
<span class="p_add">+		return 1;</span>
<span class="p_add">+#ifdef CONFIG_PREEMPT_RT_BASE</span>
<span class="p_add">+	if (timer-&gt;base-&gt;cpu_base-&gt;running_soft == timer)</span>
<span class="p_add">+		return 1;</span>
<span class="p_add">+#endif</span>
<span class="p_add">+	return 0;</span>
 }
 
 /* Forward a hrtimer so it expires after now: */
<span class="p_header">diff --git a/include/linux/sched.h b/include/linux/sched.h</span>
<span class="p_header">index b7b001e26509..f37654adf12a 100644</span>
<span class="p_header">--- a/include/linux/sched.h</span>
<span class="p_header">+++ b/include/linux/sched.h</span>
<span class="p_chunk">@@ -234,7 +234,6 @@</span> <span class="p_context"> extern char ___assert_task_state[1 - 2*!!(</span>
 
 /* Convenience macros for the sake of wake_up */
 #define TASK_NORMAL		(TASK_INTERRUPTIBLE | TASK_UNINTERRUPTIBLE)
<span class="p_del">-#define TASK_ALL		(TASK_NORMAL | __TASK_STOPPED | __TASK_TRACED)</span>
 
 /* get_task_state() */
 #define TASK_REPORT		(TASK_RUNNING | TASK_INTERRUPTIBLE | \
<span class="p_chunk">@@ -980,8 +979,20 @@</span> <span class="p_context"> struct wake_q_head {</span>
 #define WAKE_Q(name)					\
 	struct wake_q_head name = { WAKE_Q_TAIL, &amp;name.first }
 
<span class="p_del">-extern void wake_q_add(struct wake_q_head *head,</span>
<span class="p_del">-			      struct task_struct *task);</span>
<span class="p_add">+extern void __wake_q_add(struct wake_q_head *head,</span>
<span class="p_add">+			 struct task_struct *task, bool sleeper);</span>
<span class="p_add">+static inline void wake_q_add(struct wake_q_head *head,</span>
<span class="p_add">+			      struct task_struct *task)</span>
<span class="p_add">+{</span>
<span class="p_add">+	__wake_q_add(head, task, false);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline void wake_q_add_sleeper(struct wake_q_head *head,</span>
<span class="p_add">+				      struct task_struct *task)</span>
<span class="p_add">+{</span>
<span class="p_add">+	__wake_q_add(head, task, true);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 extern void __wake_up_q(struct wake_q_head *head, bool sleeper);
 
 static inline void wake_up_q(struct wake_q_head *head)
<span class="p_chunk">@@ -1439,6 +1450,7 @@</span> <span class="p_context"> struct task_struct {</span>
 	unsigned int policy;
 #ifdef CONFIG_PREEMPT_RT_FULL
 	int migrate_disable;
<span class="p_add">+	int migrate_disable_update;</span>
 # ifdef CONFIG_SCHED_DEBUG
 	int migrate_disable_atomic;
 # endif
<span class="p_chunk">@@ -1640,6 +1652,7 @@</span> <span class="p_context"> struct task_struct {</span>
 	raw_spinlock_t pi_lock;
 
 	struct wake_q_node wake_q;
<span class="p_add">+	struct wake_q_node wake_q_sleeper;</span>
 
 #ifdef CONFIG_RT_MUTEXES
 	/* PI waiters blocked on a rt_mutex held by this task */
<span class="p_header">diff --git a/kernel/fork.c b/kernel/fork.c</span>
<span class="p_header">index 0a873f52999f..368e770abee6 100644</span>
<span class="p_header">--- a/kernel/fork.c</span>
<span class="p_header">+++ b/kernel/fork.c</span>
<span class="p_chunk">@@ -395,6 +395,7 @@</span> <span class="p_context"> static struct task_struct *dup_task_struct(struct task_struct *orig, int node)</span>
 	tsk-&gt;splice_pipe = NULL;
 	tsk-&gt;task_frag.page = NULL;
 	tsk-&gt;wake_q.next = NULL;
<span class="p_add">+	tsk-&gt;wake_q_sleeper.next = NULL;</span>
 
 	account_kernel_stack(ti, 1);
 
<span class="p_header">diff --git a/kernel/locking/rtmutex.c b/kernel/locking/rtmutex.c</span>
<span class="p_header">index 0e9a6260441d..b5b89c51f27e 100644</span>
<span class="p_header">--- a/kernel/locking/rtmutex.c</span>
<span class="p_header">+++ b/kernel/locking/rtmutex.c</span>
<span class="p_chunk">@@ -1557,7 +1557,7 @@</span> <span class="p_context"> static void mark_wakeup_next_waiter(struct wake_q_head *wake_q,</span>
 	raw_spin_unlock(&amp;current-&gt;pi_lock);
 
 	if (waiter-&gt;savestate)
<span class="p_del">-		wake_q_add(wake_sleeper_q, waiter-&gt;task);</span>
<span class="p_add">+		wake_q_add_sleeper(wake_sleeper_q, waiter-&gt;task);</span>
 	else
 		wake_q_add(wake_q, waiter-&gt;task);
 }
<span class="p_chunk">@@ -1672,18 +1672,13 @@</span> <span class="p_context"> __rt_mutex_slowlock(struct rt_mutex *lock, int state,</span>
 		if (try_to_take_rt_mutex(lock, current, waiter))
 			break;
 
<span class="p_del">-		/*</span>
<span class="p_del">-		 * TASK_INTERRUPTIBLE checks for signals and</span>
<span class="p_del">-		 * timeout. Ignored otherwise.</span>
<span class="p_del">-		 */</span>
<span class="p_del">-		if (unlikely(state == TASK_INTERRUPTIBLE)) {</span>
<span class="p_del">-			/* Signal pending? */</span>
<span class="p_del">-			if (signal_pending(current))</span>
<span class="p_del">-				ret = -EINTR;</span>
<span class="p_del">-			if (timeout &amp;&amp; !timeout-&gt;task)</span>
<span class="p_del">-				ret = -ETIMEDOUT;</span>
<span class="p_del">-			if (ret)</span>
<span class="p_del">-				break;</span>
<span class="p_add">+		if (timeout &amp;&amp; !timeout-&gt;task) {</span>
<span class="p_add">+			ret = -ETIMEDOUT;</span>
<span class="p_add">+			break;</span>
<span class="p_add">+		}</span>
<span class="p_add">+		if (signal_pending_state(state, current)) {</span>
<span class="p_add">+			ret = -EINTR;</span>
<span class="p_add">+			break;</span>
 		}
 
 		if (ww_ctx &amp;&amp; ww_ctx-&gt;acquired &gt; 0) {
<span class="p_header">diff --git a/kernel/sched/core.c b/kernel/sched/core.c</span>
<span class="p_header">index ed9550c87f66..ed0f841d4d5c 100644</span>
<span class="p_header">--- a/kernel/sched/core.c</span>
<span class="p_header">+++ b/kernel/sched/core.c</span>
<span class="p_chunk">@@ -523,9 +523,15 @@</span> <span class="p_context"> static bool set_nr_if_polling(struct task_struct *p)</span>
 #endif
 #endif
 
<span class="p_del">-void wake_q_add(struct wake_q_head *head, struct task_struct *task)</span>
<span class="p_add">+void __wake_q_add(struct wake_q_head *head, struct task_struct *task,</span>
<span class="p_add">+		  bool sleeper)</span>
 {
<span class="p_del">-	struct wake_q_node *node = &amp;task-&gt;wake_q;</span>
<span class="p_add">+	struct wake_q_node *node;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (sleeper)</span>
<span class="p_add">+		node = &amp;task-&gt;wake_q_sleeper;</span>
<span class="p_add">+	else</span>
<span class="p_add">+		node = &amp;task-&gt;wake_q;</span>
 
 	/*
 	 * Atomically grab the task, if -&gt;wake_q is !nil already it means
<span class="p_chunk">@@ -554,11 +560,17 @@</span> <span class="p_context"> void __wake_up_q(struct wake_q_head *head, bool sleeper)</span>
 	while (node != WAKE_Q_TAIL) {
 		struct task_struct *task;
 
<span class="p_del">-		task = container_of(node, struct task_struct, wake_q);</span>
<span class="p_add">+		if (sleeper)</span>
<span class="p_add">+			task = container_of(node, struct task_struct, wake_q_sleeper);</span>
<span class="p_add">+		else</span>
<span class="p_add">+			task = container_of(node, struct task_struct, wake_q);</span>
 		BUG_ON(!task);
 		/* task can safely be re-inserted now */
 		node = node-&gt;next;
<span class="p_del">-		task-&gt;wake_q.next = NULL;</span>
<span class="p_add">+		if (sleeper)</span>
<span class="p_add">+			task-&gt;wake_q_sleeper.next = NULL;</span>
<span class="p_add">+		else</span>
<span class="p_add">+			task-&gt;wake_q.next = NULL;</span>
 
 		/*
 		 * wake_up_process() implies a wmb() to pair with the queueing
<span class="p_chunk">@@ -1212,18 +1224,14 @@</span> <span class="p_context"> void set_cpus_allowed_common(struct task_struct *p, const struct cpumask *new_ma</span>
 	p-&gt;nr_cpus_allowed = cpumask_weight(new_mask);
 }
 
<span class="p_del">-void do_set_cpus_allowed(struct task_struct *p, const struct cpumask *new_mask)</span>
<span class="p_add">+static void __do_set_cpus_allowed_tail(struct task_struct *p,</span>
<span class="p_add">+				       const struct cpumask *new_mask)</span>
 {
 	struct rq *rq = task_rq(p);
 	bool queued, running;
 
 	lockdep_assert_held(&amp;p-&gt;pi_lock);
 
<span class="p_del">-	if (__migrate_disabled(p)) {</span>
<span class="p_del">-		cpumask_copy(&amp;p-&gt;cpus_allowed, new_mask);</span>
<span class="p_del">-		return;</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
 	queued = task_on_rq_queued(p);
 	running = task_current(rq, p);
 
<span class="p_chunk">@@ -1246,6 +1254,20 @@</span> <span class="p_context"> void do_set_cpus_allowed(struct task_struct *p, const struct cpumask *new_mask)</span>
 		enqueue_task(rq, p, ENQUEUE_RESTORE);
 }
 
<span class="p_add">+void do_set_cpus_allowed(struct task_struct *p, const struct cpumask *new_mask)</span>
<span class="p_add">+{</span>
<span class="p_add">+	if (__migrate_disabled(p)) {</span>
<span class="p_add">+		lockdep_assert_held(&amp;p-&gt;pi_lock);</span>
<span class="p_add">+</span>
<span class="p_add">+		cpumask_copy(&amp;p-&gt;cpus_allowed, new_mask);</span>
<span class="p_add">+#if defined(CONFIG_PREEMPT_RT_FULL) &amp;&amp; defined(CONFIG_SMP)</span>
<span class="p_add">+		p-&gt;migrate_disable_update = 1;</span>
<span class="p_add">+#endif</span>
<span class="p_add">+		return;</span>
<span class="p_add">+	}</span>
<span class="p_add">+	__do_set_cpus_allowed_tail(p, new_mask);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static DEFINE_PER_CPU(struct cpumask, sched_cpumasks);
 static DEFINE_MUTEX(sched_down_mutex);
 static cpumask_t sched_down_cpumask;
<span class="p_chunk">@@ -2212,7 +2234,7 @@</span> <span class="p_context"> EXPORT_SYMBOL(wake_up_process);</span>
  */
 int wake_up_lock_sleeper(struct task_struct *p)
 {
<span class="p_del">-	return try_to_wake_up(p, TASK_ALL, WF_LOCK_SLEEPER);</span>
<span class="p_add">+	return try_to_wake_up(p, TASK_UNINTERRUPTIBLE, WF_LOCK_SLEEPER);</span>
 }
 
 int wake_up_state(struct task_struct *p, unsigned int state)
<span class="p_chunk">@@ -3231,6 +3253,43 @@</span> <span class="p_context"> void migrate_enable(void)</span>
 	 */
 	p-&gt;migrate_disable = 0;
 
<span class="p_add">+	if (p-&gt;migrate_disable_update) {</span>
<span class="p_add">+		unsigned long flags;</span>
<span class="p_add">+		struct rq *rq;</span>
<span class="p_add">+</span>
<span class="p_add">+		rq = task_rq_lock(p, &amp;flags);</span>
<span class="p_add">+		update_rq_clock(rq);</span>
<span class="p_add">+</span>
<span class="p_add">+		__do_set_cpus_allowed_tail(p, &amp;p-&gt;cpus_allowed);</span>
<span class="p_add">+		task_rq_unlock(rq, p, &amp;flags);</span>
<span class="p_add">+</span>
<span class="p_add">+		p-&gt;migrate_disable_update = 0;</span>
<span class="p_add">+</span>
<span class="p_add">+		WARN_ON(smp_processor_id() != task_cpu(p));</span>
<span class="p_add">+		if (!cpumask_test_cpu(task_cpu(p), &amp;p-&gt;cpus_allowed)) {</span>
<span class="p_add">+			const struct cpumask *cpu_valid_mask = cpu_active_mask;</span>
<span class="p_add">+			struct migration_arg arg;</span>
<span class="p_add">+			unsigned int dest_cpu;</span>
<span class="p_add">+</span>
<span class="p_add">+			if (p-&gt;flags &amp; PF_KTHREAD) {</span>
<span class="p_add">+				/*</span>
<span class="p_add">+				 * Kernel threads are allowed on online &amp;&amp; !active CPUs</span>
<span class="p_add">+				 */</span>
<span class="p_add">+				cpu_valid_mask = cpu_online_mask;</span>
<span class="p_add">+			}</span>
<span class="p_add">+			dest_cpu = cpumask_any_and(cpu_valid_mask, &amp;p-&gt;cpus_allowed);</span>
<span class="p_add">+			arg.task = p;</span>
<span class="p_add">+			arg.dest_cpu = dest_cpu;</span>
<span class="p_add">+</span>
<span class="p_add">+			unpin_current_cpu();</span>
<span class="p_add">+			preempt_lazy_enable();</span>
<span class="p_add">+			preempt_enable();</span>
<span class="p_add">+			stop_one_cpu(task_cpu(p), migration_cpu_stop, &amp;arg);</span>
<span class="p_add">+			tlb_migrate_finish(p-&gt;mm);</span>
<span class="p_add">+			return;</span>
<span class="p_add">+		}</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
 	unpin_current_cpu();
 	preempt_enable();
 	preempt_lazy_enable();
<span class="p_header">diff --git a/localversion-rt b/localversion-rt</span>
<span class="p_header">index b3e668a8fb94..9969a4b69fad 100644</span>
<span class="p_header">--- a/localversion-rt</span>
<span class="p_header">+++ b/localversion-rt</span>
<span class="p_chunk">@@ -1 +1 @@</span> <span class="p_context"></span>
<span class="p_del">--rt110</span>
<span class="p_add">+-rt111</span>

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



