
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>[v6,05/11] arm64/mm: Add support for XPFO - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    [v6,05/11] arm64/mm: Add support for XPFO</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=173139">Tycho Andersen</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>Sept. 7, 2017, 5:36 p.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;20170907173609.22696-6-tycho@docker.com&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/9942563/mbox/"
   >mbox</a>
|
   <a href="/patch/9942563/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/9942563/">/patch/9942563/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
	[172.30.200.125])
	by pdx-korg-patchwork.web.codeaurora.org (Postfix) with ESMTP id
	9556A600CB for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Thu,  7 Sep 2017 17:37:18 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 86B2C285B5
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Thu,  7 Sep 2017 17:37:18 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id 7B9EE2861A; Thu,  7 Sep 2017 17:37:18 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-6.5 required=2.0 tests=BAYES_00,DKIM_SIGNED,
	DKIM_VALID, DKIM_VALID_AU, RCVD_IN_DNSWL_HI,
	RCVD_IN_SORBS_SPAM autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 4BB04285B5
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Thu,  7 Sep 2017 17:37:17 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1755596AbdIGRhL (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Thu, 7 Sep 2017 13:37:11 -0400
Received: from mail-io0-f178.google.com ([209.85.223.178]:37625 &quot;EHLO
	mail-io0-f178.google.com&quot; rhost-flags-OK-OK-OK-OK) by vger.kernel.org
	with ESMTP id S1751829AbdIGRhJ (ORCPT
	&lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Thu, 7 Sep 2017 13:37:09 -0400
Received: by mail-io0-f178.google.com with SMTP id j141so810276ioj.4
	for &lt;linux-kernel@vger.kernel.org&gt;;
	Thu, 07 Sep 2017 10:37:09 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed; d=docker.com; s=google;
	h=from:to:cc:subject:date:message-id:in-reply-to:references;
	bh=wTMqlrSD9opSYjmt1poVezmy/+2uVGJTpEnRMa8QSSc=;
	b=hlqQhJY+vKL7/T1oR17XE2n6o6Garotip5o46m7zSv80j8APYfRJcCW+l21VkjR2HH
	h+G4ttgF+H4HeKDEN1oPp1ZCn9H+y14Otm+zhgzOYCgkcrK2m0ud+uxT/cknKJgauREl
	eFXXRIVanwjuG+ADvtHTEI7JL1u8Ms2SUr17M=
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
	d=1e100.net; s=20161025;
	h=x-gm-message-state:from:to:cc:subject:date:message-id:in-reply-to
	:references;
	bh=wTMqlrSD9opSYjmt1poVezmy/+2uVGJTpEnRMa8QSSc=;
	b=Xacx9h2gsk0qejK28bhuDTaFQ+L2+ETDueYMr9TYIYbQcxUQb3KWLQmnANne0yoKG3
	qbe6gu7+uPAYfouCO1lnz3iMI0v6kevgUAMdDC/G91bwJP9aiA/+50N4xuwIgyksmNXl
	L7AiM8w4U2ZMSEhx+Zxkjerq3Sq272CyX4j3zieB41D9NrMjrA4eJGCquHxMcWd1/0M0
	cj2ssWADJkHO7usC1yzB2YO0Yggn/s26TLlFeKf/hOcPid1xqIUc6cKZGQL1Cugdqfbq
	CnNohM920Wu8FdtozvhKs+Ny/+pDzf5xOMoAsMp9tLFweJp7b0aYyhD3irhC6bbqIvxH
	T3Vg==
X-Gm-Message-State: AHPjjUj3onODQ95Tioj+GZ+XjfpiFW1lrtWxtRZ3+iOpIUXCCWtDuz9D
	RG1rpHQ1DCtHXDMwpV0rjQ==
X-Google-Smtp-Source: ADKCNb6oOzsEIpjCIQUeqawDF9/qLa+VNCPtonqvfNuRiYkok9EDJUS9OawjtWNu3esb6ub7dMKPug==
X-Received: by 10.107.13.138 with SMTP id 132mr64842ion.351.1504805828709;
	Thu, 07 Sep 2017 10:37:08 -0700 (PDT)
Received: from localhost.localdomain ([8.24.24.129])
	by smtp.gmail.com with ESMTPSA id
	t127sm94404iod.26.2017.09.07.10.37.07
	(version=TLS1_2 cipher=ECDHE-RSA-AES128-GCM-SHA256 bits=128/128);
	Thu, 07 Sep 2017 10:37:07 -0700 (PDT)
From: Tycho Andersen &lt;tycho@docker.com&gt;
To: linux-kernel@vger.kernel.org
Cc: linux-mm@kvack.org, kernel-hardening@lists.openwall.com,
	Marco Benatto &lt;marco.antonio.780@gmail.com&gt;,
	Juerg Haefliger &lt;juerg.haefliger@canonical.com&gt;,
	linux-arm-kernel@lists.infradead.org, Tycho Andersen &lt;tycho@docker.com&gt;
Subject: [PATCH v6 05/11] arm64/mm: Add support for XPFO
Date: Thu,  7 Sep 2017 11:36:03 -0600
Message-Id: &lt;20170907173609.22696-6-tycho@docker.com&gt;
X-Mailer: git-send-email 2.11.0
In-Reply-To: &lt;20170907173609.22696-1-tycho@docker.com&gt;
References: &lt;20170907173609.22696-1-tycho@docker.com&gt;
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=173139">Tycho Andersen</a> - Sept. 7, 2017, 5:36 p.m.</div>
<pre class="content">
<span class="from">From: Juerg Haefliger &lt;juerg.haefliger@canonical.com&gt;</span>

Enable support for eXclusive Page Frame Ownership (XPFO) for arm64 and
provide a hook for updating a single kernel page table entry (which is
required by the generic XPFO code).

v6: use flush_tlb_kernel_range() instead of __flush_tlb_one()

CC: linux-arm-kernel@lists.infradead.org
<span class="signed-off-by">Signed-off-by: Juerg Haefliger &lt;juerg.haefliger@canonical.com&gt;</span>
<span class="signed-off-by">Signed-off-by: Tycho Andersen &lt;tycho@docker.com&gt;</span>
---
 arch/arm64/Kconfig     |  1 +
 arch/arm64/mm/Makefile |  2 ++
 arch/arm64/mm/xpfo.c   | 58 ++++++++++++++++++++++++++++++++++++++++++++++++++
 3 files changed, 61 insertions(+)
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=101">Christoph Hellwig</a> - Sept. 8, 2017, 7:53 a.m.</div>
<pre class="content">
<span class="quote">&gt; +/*</span>
<span class="quote">&gt; + * Lookup the page table entry for a virtual address and return a pointer to</span>
<span class="quote">&gt; + * the entry. Based on x86 tree.</span>
<span class="quote">&gt; + */</span>
<span class="quote">&gt; +static pte_t *lookup_address(unsigned long addr)</span>

Seems like this should be moved to common arm64 mm code and used by
kernel_page_present.
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=30282">Mark Rutland</a> - Sept. 14, 2017, 6:22 p.m.</div>
<pre class="content">
Hi,

On Thu, Sep 07, 2017 at 11:36:03AM -0600, Tycho Andersen wrote:
<span class="quote">&gt; From: Juerg Haefliger &lt;juerg.haefliger@canonical.com&gt;</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Enable support for eXclusive Page Frame Ownership (XPFO) for arm64 and</span>
<span class="quote">&gt; provide a hook for updating a single kernel page table entry (which is</span>
<span class="quote">&gt; required by the generic XPFO code).</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; v6: use flush_tlb_kernel_range() instead of __flush_tlb_one()</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; CC: linux-arm-kernel@lists.infradead.org</span>
<span class="quote">&gt; Signed-off-by: Juerg Haefliger &lt;juerg.haefliger@canonical.com&gt;</span>
<span class="quote">&gt; Signed-off-by: Tycho Andersen &lt;tycho@docker.com&gt;</span>
<span class="quote">&gt; ---</span>
<span class="quote">&gt;  arch/arm64/Kconfig     |  1 +</span>
<span class="quote">&gt;  arch/arm64/mm/Makefile |  2 ++</span>
<span class="quote">&gt;  arch/arm64/mm/xpfo.c   | 58 ++++++++++++++++++++++++++++++++++++++++++++++++++</span>
<span class="quote">&gt;  3 files changed, 61 insertions(+)</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; diff --git a/arch/arm64/Kconfig b/arch/arm64/Kconfig</span>
<span class="quote">&gt; index dfd908630631..44fa44ef02ec 100644</span>
<span class="quote">&gt; --- a/arch/arm64/Kconfig</span>
<span class="quote">&gt; +++ b/arch/arm64/Kconfig</span>
<span class="quote">&gt; @@ -121,6 +121,7 @@ config ARM64</span>
<span class="quote">&gt;  	select SPARSE_IRQ</span>
<span class="quote">&gt;  	select SYSCTL_EXCEPTION_TRACE</span>
<span class="quote">&gt;  	select THREAD_INFO_IN_TASK</span>
<span class="quote">&gt; +	select ARCH_SUPPORTS_XPFO</span>

A bit of a nit, but this list is (intended to be) organised alphabetically.
Could you please try to retain that?

i.e. place this between ARCH_SUPPORTS_NUMA_BALANCING and
ARCH_WANT_COMPAT_IPC_PARSE_VERSION.
<span class="quote">
&gt;  	help</span>
<span class="quote">&gt;  	  ARM 64-bit (AArch64) Linux support.</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; diff --git a/arch/arm64/mm/Makefile b/arch/arm64/mm/Makefile</span>
<span class="quote">&gt; index 9b0ba191e48e..22e5cab543d8 100644</span>
<span class="quote">&gt; --- a/arch/arm64/mm/Makefile</span>
<span class="quote">&gt; +++ b/arch/arm64/mm/Makefile</span>
<span class="quote">&gt; @@ -11,3 +11,5 @@ KASAN_SANITIZE_physaddr.o	+= n</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  obj-$(CONFIG_KASAN)		+= kasan_init.o</span>
<span class="quote">&gt;  KASAN_SANITIZE_kasan_init.o	:= n</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +obj-$(CONFIG_XPFO)		+= xpfo.o</span>
<span class="quote">&gt; diff --git a/arch/arm64/mm/xpfo.c b/arch/arm64/mm/xpfo.c</span>
<span class="quote">&gt; new file mode 100644</span>
<span class="quote">&gt; index 000000000000..678e2be848eb</span>
<span class="quote">&gt; --- /dev/null</span>
<span class="quote">&gt; +++ b/arch/arm64/mm/xpfo.c</span>
<span class="quote">&gt; @@ -0,0 +1,58 @@</span>
<span class="quote">&gt; +/*</span>
<span class="quote">&gt; + * Copyright (C) 2017 Hewlett Packard Enterprise Development, L.P.</span>
<span class="quote">&gt; + * Copyright (C) 2016 Brown University. All rights reserved.</span>
<span class="quote">&gt; + *</span>
<span class="quote">&gt; + * Authors:</span>
<span class="quote">&gt; + *   Juerg Haefliger &lt;juerg.haefliger@hpe.com&gt;</span>
<span class="quote">&gt; + *   Vasileios P. Kemerlis &lt;vpk@cs.brown.edu&gt;</span>
<span class="quote">&gt; + *</span>
<span class="quote">&gt; + * This program is free software; you can redistribute it and/or modify it</span>
<span class="quote">&gt; + * under the terms of the GNU General Public License version 2 as published by</span>
<span class="quote">&gt; + * the Free Software Foundation.</span>
<span class="quote">&gt; + */</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +#include &lt;linux/mm.h&gt;</span>
<span class="quote">&gt; +#include &lt;linux/module.h&gt;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +#include &lt;asm/tlbflush.h&gt;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +/*</span>
<span class="quote">&gt; + * Lookup the page table entry for a virtual address and return a pointer to</span>
<span class="quote">&gt; + * the entry. Based on x86 tree.</span>
<span class="quote">&gt; + */</span>

Is this intended for kernel VAs, user VAs, or both?

There are different constraints for fiddling with either (e.g. holding
mmap_sem), so we should be clear regarding the intended use-case.
<span class="quote">
&gt; +static pte_t *lookup_address(unsigned long addr)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	pgd_t *pgd;</span>
<span class="quote">&gt; +	pud_t *pud;</span>
<span class="quote">&gt; +	pmd_t *pmd;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	pgd = pgd_offset_k(addr);</span>
<span class="quote">&gt; +	if (pgd_none(*pgd))</span>
<span class="quote">&gt; +		return NULL;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	pud = pud_offset(pgd, addr);</span>
<span class="quote">&gt; +	if (pud_none(*pud))</span>
<span class="quote">&gt; +		return NULL;</span>

What if it&#39;s not none, but not a table?

I think we chould check pud_sect() here, and/or pud_bad().
<span class="quote">
&gt; +</span>
<span class="quote">&gt; +	pmd = pmd_offset(pud, addr);</span>
<span class="quote">&gt; +	if (pmd_none(*pmd))</span>
<span class="quote">&gt; +		return NULL;</span>

Likewise.
<span class="quote">
&gt; +</span>
<span class="quote">&gt; +	return pte_offset_kernel(pmd, addr);</span>
<span class="quote">&gt; +}</span>

Given this expects a pte, it might make more sense to call this
lookup_address_pte() to make that clear.
<span class="quote">
&gt; +</span>
<span class="quote">&gt; +/* Update a single kernel page table entry */</span>
<span class="quote">&gt; +inline void set_kpte(void *kaddr, struct page *page, pgprot_t prot)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	pte_t *pte = lookup_address((unsigned long)kaddr);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	set_pte(pte, pfn_pte(page_to_pfn(page), prot));</span>

We can get NULL from lookup_address(), so this doesn&#39;t look right.

If NULL implies an error, drop a BUG_ON(!pte) before the set_pte.
<span class="quote">
&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +inline void xpfo_flush_kernel_tlb(struct page *page, int order)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	unsigned long kaddr = (unsigned long)page_address(page);</span>
<span class="quote">&gt; +	unsigned long size = PAGE_SIZE;</span>

unsigned long size = PAGE_SIZE &lt;&lt; order;
<span class="quote">
&gt; +</span>
<span class="quote">&gt; +	flush_tlb_kernel_range(kaddr, kaddr + (1 &lt;&lt; order) * size);</span>

... and this can be simpler.

I haven&#39;t brought myself back up to speed, so it might not be possible, but I
still think it would be preferable for XPFO to call flush_tlb_kernel_range()
directly.

Thanks,
Mark.
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=173139">Tycho Andersen</a> - Sept. 18, 2017, 9:27 p.m.</div>
<pre class="content">
Hi Mark,

On Thu, Sep 14, 2017 at 07:22:08PM +0100, Mark Rutland wrote:
<span class="quote">&gt; Hi,</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; On Thu, Sep 07, 2017 at 11:36:03AM -0600, Tycho Andersen wrote:</span>
<span class="quote">&gt; &gt; From: Juerg Haefliger &lt;juerg.haefliger@canonical.com&gt;</span>
<span class="quote">&gt; &gt; </span>
<span class="quote">&gt; &gt; Enable support for eXclusive Page Frame Ownership (XPFO) for arm64 and</span>
<span class="quote">&gt; &gt; provide a hook for updating a single kernel page table entry (which is</span>
<span class="quote">&gt; &gt; required by the generic XPFO code).</span>
<span class="quote">&gt; &gt; </span>
<span class="quote">&gt; &gt; v6: use flush_tlb_kernel_range() instead of __flush_tlb_one()</span>
<span class="quote">&gt; &gt; </span>
<span class="quote">&gt; &gt; CC: linux-arm-kernel@lists.infradead.org</span>
<span class="quote">&gt; &gt; Signed-off-by: Juerg Haefliger &lt;juerg.haefliger@canonical.com&gt;</span>
<span class="quote">&gt; &gt; Signed-off-by: Tycho Andersen &lt;tycho@docker.com&gt;</span>
<span class="quote">&gt; &gt; ---</span>
<span class="quote">&gt; &gt;  arch/arm64/Kconfig     |  1 +</span>
<span class="quote">&gt; &gt;  arch/arm64/mm/Makefile |  2 ++</span>
<span class="quote">&gt; &gt;  arch/arm64/mm/xpfo.c   | 58 ++++++++++++++++++++++++++++++++++++++++++++++++++</span>
<span class="quote">&gt; &gt;  3 files changed, 61 insertions(+)</span>
<span class="quote">&gt; &gt; </span>
<span class="quote">&gt; &gt; diff --git a/arch/arm64/Kconfig b/arch/arm64/Kconfig</span>
<span class="quote">&gt; &gt; index dfd908630631..44fa44ef02ec 100644</span>
<span class="quote">&gt; &gt; --- a/arch/arm64/Kconfig</span>
<span class="quote">&gt; &gt; +++ b/arch/arm64/Kconfig</span>
<span class="quote">&gt; &gt; @@ -121,6 +121,7 @@ config ARM64</span>
<span class="quote">&gt; &gt;  	select SPARSE_IRQ</span>
<span class="quote">&gt; &gt;  	select SYSCTL_EXCEPTION_TRACE</span>
<span class="quote">&gt; &gt;  	select THREAD_INFO_IN_TASK</span>
<span class="quote">&gt; &gt; +	select ARCH_SUPPORTS_XPFO</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; A bit of a nit, but this list is (intended to be) organised alphabetically.</span>
<span class="quote">&gt; Could you please try to retain that?</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; i.e. place this between ARCH_SUPPORTS_NUMA_BALANCING and</span>
<span class="quote">&gt; ARCH_WANT_COMPAT_IPC_PARSE_VERSION.</span>

Will do.
<span class="quote">
&gt; &gt;  	help</span>
<span class="quote">&gt; &gt;  	  ARM 64-bit (AArch64) Linux support.</span>
<span class="quote">&gt; &gt;  </span>
<span class="quote">&gt; &gt; diff --git a/arch/arm64/mm/Makefile b/arch/arm64/mm/Makefile</span>
<span class="quote">&gt; &gt; index 9b0ba191e48e..22e5cab543d8 100644</span>
<span class="quote">&gt; &gt; --- a/arch/arm64/mm/Makefile</span>
<span class="quote">&gt; &gt; +++ b/arch/arm64/mm/Makefile</span>
<span class="quote">&gt; &gt; @@ -11,3 +11,5 @@ KASAN_SANITIZE_physaddr.o	+= n</span>
<span class="quote">&gt; &gt;  </span>
<span class="quote">&gt; &gt;  obj-$(CONFIG_KASAN)		+= kasan_init.o</span>
<span class="quote">&gt; &gt;  KASAN_SANITIZE_kasan_init.o	:= n</span>
<span class="quote">&gt; &gt; +</span>
<span class="quote">&gt; &gt; +obj-$(CONFIG_XPFO)		+= xpfo.o</span>
<span class="quote">&gt; &gt; diff --git a/arch/arm64/mm/xpfo.c b/arch/arm64/mm/xpfo.c</span>
<span class="quote">&gt; &gt; new file mode 100644</span>
<span class="quote">&gt; &gt; index 000000000000..678e2be848eb</span>
<span class="quote">&gt; &gt; --- /dev/null</span>
<span class="quote">&gt; &gt; +++ b/arch/arm64/mm/xpfo.c</span>
<span class="quote">&gt; &gt; @@ -0,0 +1,58 @@</span>
<span class="quote">&gt; &gt; +/*</span>
<span class="quote">&gt; &gt; + * Copyright (C) 2017 Hewlett Packard Enterprise Development, L.P.</span>
<span class="quote">&gt; &gt; + * Copyright (C) 2016 Brown University. All rights reserved.</span>
<span class="quote">&gt; &gt; + *</span>
<span class="quote">&gt; &gt; + * Authors:</span>
<span class="quote">&gt; &gt; + *   Juerg Haefliger &lt;juerg.haefliger@hpe.com&gt;</span>
<span class="quote">&gt; &gt; + *   Vasileios P. Kemerlis &lt;vpk@cs.brown.edu&gt;</span>
<span class="quote">&gt; &gt; + *</span>
<span class="quote">&gt; &gt; + * This program is free software; you can redistribute it and/or modify it</span>
<span class="quote">&gt; &gt; + * under the terms of the GNU General Public License version 2 as published by</span>
<span class="quote">&gt; &gt; + * the Free Software Foundation.</span>
<span class="quote">&gt; &gt; + */</span>
<span class="quote">&gt; &gt; +</span>
<span class="quote">&gt; &gt; +#include &lt;linux/mm.h&gt;</span>
<span class="quote">&gt; &gt; +#include &lt;linux/module.h&gt;</span>
<span class="quote">&gt; &gt; +</span>
<span class="quote">&gt; &gt; +#include &lt;asm/tlbflush.h&gt;</span>
<span class="quote">&gt; &gt; +</span>
<span class="quote">&gt; &gt; +/*</span>
<span class="quote">&gt; &gt; + * Lookup the page table entry for a virtual address and return a pointer to</span>
<span class="quote">&gt; &gt; + * the entry. Based on x86 tree.</span>
<span class="quote">&gt; &gt; + */</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Is this intended for kernel VAs, user VAs, or both?</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; There are different constraints for fiddling with either (e.g. holding</span>
<span class="quote">&gt; mmap_sem), so we should be clear regarding the intended use-case.</span>

kernel only; I can add a comment noting this.
<span class="quote">
&gt; &gt; +static pte_t *lookup_address(unsigned long addr)</span>
<span class="quote">&gt; &gt; +{</span>
<span class="quote">&gt; &gt; +	pgd_t *pgd;</span>
<span class="quote">&gt; &gt; +	pud_t *pud;</span>
<span class="quote">&gt; &gt; +	pmd_t *pmd;</span>
<span class="quote">&gt; &gt; +</span>
<span class="quote">&gt; &gt; +	pgd = pgd_offset_k(addr);</span>
<span class="quote">&gt; &gt; +	if (pgd_none(*pgd))</span>
<span class="quote">&gt; &gt; +		return NULL;</span>
<span class="quote">&gt; &gt; +</span>
<span class="quote">&gt; &gt; +	pud = pud_offset(pgd, addr);</span>
<span class="quote">&gt; &gt; +	if (pud_none(*pud))</span>
<span class="quote">&gt; &gt; +		return NULL;</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; What if it&#39;s not none, but not a table?</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; I think we chould check pud_sect() here, and/or pud_bad().</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; &gt; +</span>
<span class="quote">&gt; &gt; +	pmd = pmd_offset(pud, addr);</span>
<span class="quote">&gt; &gt; +	if (pmd_none(*pmd))</span>
<span class="quote">&gt; &gt; +		return NULL;</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Likewise.</span>

In principle pud_sect() should be okay, because we say that XPFO
doesn&#39;t support section mappings yet. I&#39;ll add a check for pud_bad().

However, Christoph suggested that we move this to common code and
there it won&#39;t be okay.
<span class="quote">
&gt; &gt; +</span>
<span class="quote">&gt; &gt; +	return pte_offset_kernel(pmd, addr);</span>
<span class="quote">&gt; &gt; +}</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Given this expects a pte, it might make more sense to call this</span>
<span class="quote">&gt; lookup_address_pte() to make that clear.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; &gt; +</span>
<span class="quote">&gt; &gt; +/* Update a single kernel page table entry */</span>
<span class="quote">&gt; &gt; +inline void set_kpte(void *kaddr, struct page *page, pgprot_t prot)</span>
<span class="quote">&gt; &gt; +{</span>
<span class="quote">&gt; &gt; +	pte_t *pte = lookup_address((unsigned long)kaddr);</span>
<span class="quote">&gt; &gt; +</span>
<span class="quote">&gt; &gt; +	set_pte(pte, pfn_pte(page_to_pfn(page), prot));</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; We can get NULL from lookup_address(), so this doesn&#39;t look right.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; If NULL implies an error, drop a BUG_ON(!pte) before the set_pte.</span>

It does, I&#39;ll add this (as a WARN() and then no-op), thanks.
<span class="quote">
&gt; &gt; +}</span>
<span class="quote">&gt; &gt; +</span>
<span class="quote">&gt; &gt; +inline void xpfo_flush_kernel_tlb(struct page *page, int order)</span>
<span class="quote">&gt; &gt; +{</span>
<span class="quote">&gt; &gt; +	unsigned long kaddr = (unsigned long)page_address(page);</span>
<span class="quote">&gt; &gt; +	unsigned long size = PAGE_SIZE;</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; unsigned long size = PAGE_SIZE &lt;&lt; order;</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; &gt; +</span>
<span class="quote">&gt; &gt; +	flush_tlb_kernel_range(kaddr, kaddr + (1 &lt;&lt; order) * size);</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; ... and this can be simpler.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; I haven&#39;t brought myself back up to speed, so it might not be possible, but I</span>
<span class="quote">&gt; still think it would be preferable for XPFO to call flush_tlb_kernel_range()</span>
<span class="quote">&gt; directly.</span>

I don&#39;t think we can, since on x86 it uses smp functions, and in some
cases those aren&#39;t safe.

Cheers,

Tycho
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/arch/arm64/Kconfig b/arch/arm64/Kconfig</span>
<span class="p_header">index dfd908630631..44fa44ef02ec 100644</span>
<span class="p_header">--- a/arch/arm64/Kconfig</span>
<span class="p_header">+++ b/arch/arm64/Kconfig</span>
<span class="p_chunk">@@ -121,6 +121,7 @@</span> <span class="p_context"> config ARM64</span>
 	select SPARSE_IRQ
 	select SYSCTL_EXCEPTION_TRACE
 	select THREAD_INFO_IN_TASK
<span class="p_add">+	select ARCH_SUPPORTS_XPFO</span>
 	help
 	  ARM 64-bit (AArch64) Linux support.
 
<span class="p_header">diff --git a/arch/arm64/mm/Makefile b/arch/arm64/mm/Makefile</span>
<span class="p_header">index 9b0ba191e48e..22e5cab543d8 100644</span>
<span class="p_header">--- a/arch/arm64/mm/Makefile</span>
<span class="p_header">+++ b/arch/arm64/mm/Makefile</span>
<span class="p_chunk">@@ -11,3 +11,5 @@</span> <span class="p_context"> KASAN_SANITIZE_physaddr.o	+= n</span>
 
 obj-$(CONFIG_KASAN)		+= kasan_init.o
 KASAN_SANITIZE_kasan_init.o	:= n
<span class="p_add">+</span>
<span class="p_add">+obj-$(CONFIG_XPFO)		+= xpfo.o</span>
<span class="p_header">diff --git a/arch/arm64/mm/xpfo.c b/arch/arm64/mm/xpfo.c</span>
new file mode 100644
<span class="p_header">index 000000000000..678e2be848eb</span>
<span class="p_header">--- /dev/null</span>
<span class="p_header">+++ b/arch/arm64/mm/xpfo.c</span>
<span class="p_chunk">@@ -0,0 +1,58 @@</span> <span class="p_context"></span>
<span class="p_add">+/*</span>
<span class="p_add">+ * Copyright (C) 2017 Hewlett Packard Enterprise Development, L.P.</span>
<span class="p_add">+ * Copyright (C) 2016 Brown University. All rights reserved.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * Authors:</span>
<span class="p_add">+ *   Juerg Haefliger &lt;juerg.haefliger@hpe.com&gt;</span>
<span class="p_add">+ *   Vasileios P. Kemerlis &lt;vpk@cs.brown.edu&gt;</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * This program is free software; you can redistribute it and/or modify it</span>
<span class="p_add">+ * under the terms of the GNU General Public License version 2 as published by</span>
<span class="p_add">+ * the Free Software Foundation.</span>
<span class="p_add">+ */</span>
<span class="p_add">+</span>
<span class="p_add">+#include &lt;linux/mm.h&gt;</span>
<span class="p_add">+#include &lt;linux/module.h&gt;</span>
<span class="p_add">+</span>
<span class="p_add">+#include &lt;asm/tlbflush.h&gt;</span>
<span class="p_add">+</span>
<span class="p_add">+/*</span>
<span class="p_add">+ * Lookup the page table entry for a virtual address and return a pointer to</span>
<span class="p_add">+ * the entry. Based on x86 tree.</span>
<span class="p_add">+ */</span>
<span class="p_add">+static pte_t *lookup_address(unsigned long addr)</span>
<span class="p_add">+{</span>
<span class="p_add">+	pgd_t *pgd;</span>
<span class="p_add">+	pud_t *pud;</span>
<span class="p_add">+	pmd_t *pmd;</span>
<span class="p_add">+</span>
<span class="p_add">+	pgd = pgd_offset_k(addr);</span>
<span class="p_add">+	if (pgd_none(*pgd))</span>
<span class="p_add">+		return NULL;</span>
<span class="p_add">+</span>
<span class="p_add">+	pud = pud_offset(pgd, addr);</span>
<span class="p_add">+	if (pud_none(*pud))</span>
<span class="p_add">+		return NULL;</span>
<span class="p_add">+</span>
<span class="p_add">+	pmd = pmd_offset(pud, addr);</span>
<span class="p_add">+	if (pmd_none(*pmd))</span>
<span class="p_add">+		return NULL;</span>
<span class="p_add">+</span>
<span class="p_add">+	return pte_offset_kernel(pmd, addr);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+/* Update a single kernel page table entry */</span>
<span class="p_add">+inline void set_kpte(void *kaddr, struct page *page, pgprot_t prot)</span>
<span class="p_add">+{</span>
<span class="p_add">+	pte_t *pte = lookup_address((unsigned long)kaddr);</span>
<span class="p_add">+</span>
<span class="p_add">+	set_pte(pte, pfn_pte(page_to_pfn(page), prot));</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+inline void xpfo_flush_kernel_tlb(struct page *page, int order)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long kaddr = (unsigned long)page_address(page);</span>
<span class="p_add">+	unsigned long size = PAGE_SIZE;</span>
<span class="p_add">+</span>
<span class="p_add">+	flush_tlb_kernel_range(kaddr, kaddr + (1 &lt;&lt; order) * size);</span>
<span class="p_add">+}</span>

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



