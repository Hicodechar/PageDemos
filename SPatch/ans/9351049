
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>[v4,1/3] mm/hugetlb: fix memory offline with hugepage size &gt; memory block size - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    [v4,1/3] mm/hugetlb: fix memory offline with hugepage size &gt; memory block size</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=2816">Gerald Schaefer</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>Sept. 26, 2016, 5:28 p.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;20160926172811.94033-2-gerald.schaefer@de.ibm.com&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/9351049/mbox/"
   >mbox</a>
|
   <a href="/patch/9351049/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/9351049/">/patch/9351049/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
	[172.30.200.125])
	by pdx-korg-patchwork.web.codeaurora.org (Postfix) with ESMTP id
	252966086A for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Mon, 26 Sep 2016 17:28:37 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 1333D28AE4
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Mon, 26 Sep 2016 17:28:37 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id 07DC428D4A; Mon, 26 Sep 2016 17:28:37 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-6.9 required=2.0 tests=BAYES_00,RCVD_IN_DNSWL_HI
	autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 8922C28AEF
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Mon, 26 Sep 2016 17:28:36 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1424333AbcIZR2d (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Mon, 26 Sep 2016 13:28:33 -0400
Received: from mx0a-001b2d01.pphosted.com ([148.163.156.1]:35786 &quot;EHLO
	mx0a-001b2d01.pphosted.com&quot; rhost-flags-OK-OK-OK-OK)
	by vger.kernel.org with ESMTP id S1424240AbcIZR23 (ORCPT
	&lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Mon, 26 Sep 2016 13:28:29 -0400
Received: from pps.filterd (m0098393.ppops.net [127.0.0.1])
	by mx0a-001b2d01.pphosted.com (8.16.0.17/8.16.0.17) with SMTP id
	u8QHN3BI048470
	for &lt;linux-kernel@vger.kernel.org&gt;; Mon, 26 Sep 2016 13:28:29 -0400
Received: from e06smtp11.uk.ibm.com (e06smtp11.uk.ibm.com [195.75.94.107])
	by mx0a-001b2d01.pphosted.com with ESMTP id 25q53w8veb-1
	(version=TLSv1.2 cipher=AES256-SHA bits=256 verify=NOT)
	for &lt;linux-kernel@vger.kernel.org&gt;; Mon, 26 Sep 2016 13:28:28 -0400
Received: from localhost
	by e06smtp11.uk.ibm.com with IBM ESMTP SMTP Gateway: Authorized Use
	Only! Violators will be prosecuted
	for &lt;linux-kernel@vger.kernel.org&gt; from &lt;gerald.schaefer@de.ibm.com&gt;; 
	Mon, 26 Sep 2016 18:28:26 +0100
Received: from d06dlp03.portsmouth.uk.ibm.com (9.149.20.15)
	by e06smtp11.uk.ibm.com (192.168.101.141) with IBM ESMTP SMTP
	Gateway: Authorized Use Only! Violators will be prosecuted; 
	Mon, 26 Sep 2016 18:28:25 +0100
Received: from b06cxnps3075.portsmouth.uk.ibm.com
	(d06relay10.portsmouth.uk.ibm.com [9.149.109.195])
	by d06dlp03.portsmouth.uk.ibm.com (Postfix) with ESMTP id
	E31C71B08023 for &lt;linux-kernel@vger.kernel.org&gt;;
	Mon, 26 Sep 2016 18:30:18 +0100 (BST)
Received: from d06av03.portsmouth.uk.ibm.com (d06av03.portsmouth.uk.ibm.com
	[9.149.37.213])
	by b06cxnps3075.portsmouth.uk.ibm.com (8.14.9/8.14.9/NCO v10.0) with
	ESMTP id u8QHSPKD17236236
	for &lt;linux-kernel@vger.kernel.org&gt;; Mon, 26 Sep 2016 17:28:25 GMT
Received: from d06av03.portsmouth.uk.ibm.com (localhost [127.0.0.1])
	by d06av03.portsmouth.uk.ibm.com (8.14.4/8.14.4/NCO v10.0 AVout) with
	ESMTP id u8QHSLLD008371
	for &lt;linux-kernel@vger.kernel.org&gt;; Mon, 26 Sep 2016 11:28:24 -0600
Received: from tuxmaker.boeblingen.de.ibm.com
	(tuxmaker.boeblingen.de.ibm.com [9.152.85.9])
	by d06av03.portsmouth.uk.ibm.com (8.14.4/8.14.4/NCO v10.0 AVin) with
	ESMTP id u8QHSJCZ008338
	(version=TLSv1/SSLv3 cipher=DHE-RSA-AES256-SHA256 bits=256 verify=NO);
	Mon, 26 Sep 2016 11:28:20 -0600
From: Gerald Schaefer &lt;gerald.schaefer@de.ibm.com&gt;
To: Andrew Morton &lt;akpm@linux-foundation.org&gt;
Cc: Naoya Horiguchi &lt;n-horiguchi@ah.jp.nec.com&gt;, linux-mm@kvack.org,
	linux-kernel@vger.kernel.org, Michal Hocko &lt;mhocko@suse.cz&gt;,
	&quot;Kirill A . Shutemov&quot; &lt;kirill.shutemov@linux.intel.com&gt;,
	Vlastimil Babka &lt;vbabka@suse.cz&gt;, Mike Kravetz &lt;mike.kravetz@oracle.com&gt;,
	&quot;Aneesh Kumar K . V&quot; &lt;aneesh.kumar@linux.vnet.ibm.com&gt;,
	Martin Schwidefsky &lt;schwidefsky@de.ibm.com&gt;,
	Heiko Carstens &lt;heiko.carstens@de.ibm.com&gt;,
	Rui Teng &lt;rui.teng@linux.vnet.ibm.com&gt;,
	Dave Hansen &lt;dave.hansen@linux.intel.com&gt;
Subject: [PATCH v4 1/3] mm/hugetlb: fix memory offline with hugepage size &gt;
	memory block size
Date: Mon, 26 Sep 2016 19:28:09 +0200
X-Mailer: git-send-email 2.8.4
In-Reply-To: &lt;20160926172811.94033-1-gerald.schaefer@de.ibm.com&gt;
References: &lt;20160926172811.94033-1-gerald.schaefer@de.ibm.com&gt;
X-TM-AS-MML: disable
X-Content-Scanned: Fidelis XPS MAILER
x-cbid: 16092617-0040-0000-0000-000002E23718
X-IBM-AV-DETECTION: SAVI=unused REMOTE=unused XFE=unused
x-cbparentid: 16092617-0041-0000-0000-00001D404CAC
Message-Id: &lt;20160926172811.94033-2-gerald.schaefer@de.ibm.com&gt;
X-Proofpoint-Virus-Version: vendor=fsecure engine=2.50.10432:, ,
	definitions=2016-09-26_08:, , signatures=0
X-Proofpoint-Spam-Details: rule=outbound_notspam policy=outbound score=0
	spamscore=0 suspectscore=2
	malwarescore=0 phishscore=0 adultscore=0 bulkscore=0 classifier=spam
	adjust=0 reason=mlx scancount=1 engine=8.0.1-1609020000
	definitions=main-1609260327
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=2816">Gerald Schaefer</a> - Sept. 26, 2016, 5:28 p.m.</div>
<pre class="content">
dissolve_free_huge_pages() will either run into the VM_BUG_ON() or a
list corruption and addressing exception when trying to set a memory
block offline that is part (but not the first part) of a &quot;gigantic&quot;
hugetlb page with a size &gt; memory block size.

When no other smaller hugetlb page sizes are present, the VM_BUG_ON()
will trigger directly. In the other case we will run into an addressing
exception later, because dissolve_free_huge_page() will not work on the
head page of the compound hugetlb page which will result in a NULL
hstate from page_hstate().

To fix this, first remove the VM_BUG_ON() because it is wrong, and then
use the compound head page in dissolve_free_huge_page(). This means that
an unused pre-allocated gigantic page that has any part of itself inside
the memory block that is going offline will be dissolved completely.
Losing an unused gigantic hugepage is preferable to failing the memory
offline, for example in the situation where a (possibly faulty) memory
DIMM needs to go offline.

Fixes: c8721bbb (&quot;mm: memory-hotplug: enable memory hotplug to handle hugepage&quot;)
Cc: &lt;stable@vger.kernel.org&gt;
<span class="signed-off-by">Signed-off-by: Gerald Schaefer &lt;gerald.schaefer@de.ibm.com&gt;</span>
---
 mm/hugetlb.c | 13 +++++++------
 1 file changed, 7 insertions(+), 6 deletions(-)
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=137061">Michal Hocko</a> - Sept. 29, 2016, 12:11 p.m.</div>
<pre class="content">
On Mon 26-09-16 19:28:09, Gerald Schaefer wrote:
<span class="quote">&gt; dissolve_free_huge_pages() will either run into the VM_BUG_ON() or a</span>
<span class="quote">&gt; list corruption and addressing exception when trying to set a memory</span>
<span class="quote">&gt; block offline that is part (but not the first part) of a &quot;gigantic&quot;</span>
<span class="quote">&gt; hugetlb page with a size &gt; memory block size.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; When no other smaller hugetlb page sizes are present, the VM_BUG_ON()</span>
<span class="quote">&gt; will trigger directly. In the other case we will run into an addressing</span>
<span class="quote">&gt; exception later, because dissolve_free_huge_page() will not work on the</span>
<span class="quote">&gt; head page of the compound hugetlb page which will result in a NULL</span>
<span class="quote">&gt; hstate from page_hstate().</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; To fix this, first remove the VM_BUG_ON() because it is wrong, and then</span>
<span class="quote">&gt; use the compound head page in dissolve_free_huge_page(). This means that</span>
<span class="quote">&gt; an unused pre-allocated gigantic page that has any part of itself inside</span>
<span class="quote">&gt; the memory block that is going offline will be dissolved completely.</span>
<span class="quote">&gt; Losing an unused gigantic hugepage is preferable to failing the memory</span>
<span class="quote">&gt; offline, for example in the situation where a (possibly faulty) memory</span>
<span class="quote">&gt; DIMM needs to go offline.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Fixes: c8721bbb (&quot;mm: memory-hotplug: enable memory hotplug to handle hugepage&quot;)</span>
<span class="quote">&gt; Cc: &lt;stable@vger.kernel.org&gt;</span>
<span class="quote">&gt; Signed-off-by: Gerald Schaefer &lt;gerald.schaefer@de.ibm.com&gt;</span>
<span class="acked-by">
Acked-by: Michal Hocko &lt;mhocko@suse.com&gt;</span>
<span class="quote">
&gt; ---</span>
<span class="quote">&gt;  mm/hugetlb.c | 13 +++++++------</span>
<span class="quote">&gt;  1 file changed, 7 insertions(+), 6 deletions(-)</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; diff --git a/mm/hugetlb.c b/mm/hugetlb.c</span>
<span class="quote">&gt; index 87e11d8..603bdd0 100644</span>
<span class="quote">&gt; --- a/mm/hugetlb.c</span>
<span class="quote">&gt; +++ b/mm/hugetlb.c</span>
<span class="quote">&gt; @@ -1443,13 +1443,14 @@ static void dissolve_free_huge_page(struct page *page)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	spin_lock(&amp;hugetlb_lock);</span>
<span class="quote">&gt;  	if (PageHuge(page) &amp;&amp; !page_count(page)) {</span>
<span class="quote">&gt; -		struct hstate *h = page_hstate(page);</span>
<span class="quote">&gt; -		int nid = page_to_nid(page);</span>
<span class="quote">&gt; -		list_del(&amp;page-&gt;lru);</span>
<span class="quote">&gt; +		struct page *head = compound_head(page);</span>
<span class="quote">&gt; +		struct hstate *h = page_hstate(head);</span>
<span class="quote">&gt; +		int nid = page_to_nid(head);</span>
<span class="quote">&gt; +		list_del(&amp;head-&gt;lru);</span>
<span class="quote">&gt;  		h-&gt;free_huge_pages--;</span>
<span class="quote">&gt;  		h-&gt;free_huge_pages_node[nid]--;</span>
<span class="quote">&gt;  		h-&gt;max_huge_pages--;</span>
<span class="quote">&gt; -		update_and_free_page(h, page);</span>
<span class="quote">&gt; +		update_and_free_page(h, head);</span>
<span class="quote">&gt;  	}</span>
<span class="quote">&gt;  	spin_unlock(&amp;hugetlb_lock);</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt; @@ -1457,7 +1458,8 @@ static void dissolve_free_huge_page(struct page *page)</span>
<span class="quote">&gt;  /*</span>
<span class="quote">&gt;   * Dissolve free hugepages in a given pfn range. Used by memory hotplug to</span>
<span class="quote">&gt;   * make specified memory blocks removable from the system.</span>
<span class="quote">&gt; - * Note that start_pfn should aligned with (minimum) hugepage size.</span>
<span class="quote">&gt; + * Note that this will dissolve a free gigantic hugepage completely, if any</span>
<span class="quote">&gt; + * part of it lies within the given range.</span>
<span class="quote">&gt;   */</span>
<span class="quote">&gt;  void dissolve_free_huge_pages(unsigned long start_pfn, unsigned long end_pfn)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt; @@ -1466,7 +1468,6 @@ void dissolve_free_huge_pages(unsigned long start_pfn, unsigned long end_pfn)</span>
<span class="quote">&gt;  	if (!hugepages_supported())</span>
<span class="quote">&gt;  		return;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; -	VM_BUG_ON(!IS_ALIGNED(start_pfn, 1 &lt;&lt; minimum_order));</span>
<span class="quote">&gt;  	for (pfn = start_pfn; pfn &lt; end_pfn; pfn += 1 &lt;&lt; minimum_order)</span>
<span class="quote">&gt;  		dissolve_free_huge_page(pfn_to_page(pfn));</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt; -- </span>
<span class="quote">&gt; 2.8.4</span>
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/mm/hugetlb.c b/mm/hugetlb.c</span>
<span class="p_header">index 87e11d8..603bdd0 100644</span>
<span class="p_header">--- a/mm/hugetlb.c</span>
<span class="p_header">+++ b/mm/hugetlb.c</span>
<span class="p_chunk">@@ -1443,13 +1443,14 @@</span> <span class="p_context"> static void dissolve_free_huge_page(struct page *page)</span>
 {
 	spin_lock(&amp;hugetlb_lock);
 	if (PageHuge(page) &amp;&amp; !page_count(page)) {
<span class="p_del">-		struct hstate *h = page_hstate(page);</span>
<span class="p_del">-		int nid = page_to_nid(page);</span>
<span class="p_del">-		list_del(&amp;page-&gt;lru);</span>
<span class="p_add">+		struct page *head = compound_head(page);</span>
<span class="p_add">+		struct hstate *h = page_hstate(head);</span>
<span class="p_add">+		int nid = page_to_nid(head);</span>
<span class="p_add">+		list_del(&amp;head-&gt;lru);</span>
 		h-&gt;free_huge_pages--;
 		h-&gt;free_huge_pages_node[nid]--;
 		h-&gt;max_huge_pages--;
<span class="p_del">-		update_and_free_page(h, page);</span>
<span class="p_add">+		update_and_free_page(h, head);</span>
 	}
 	spin_unlock(&amp;hugetlb_lock);
 }
<span class="p_chunk">@@ -1457,7 +1458,8 @@</span> <span class="p_context"> static void dissolve_free_huge_page(struct page *page)</span>
 /*
  * Dissolve free hugepages in a given pfn range. Used by memory hotplug to
  * make specified memory blocks removable from the system.
<span class="p_del">- * Note that start_pfn should aligned with (minimum) hugepage size.</span>
<span class="p_add">+ * Note that this will dissolve a free gigantic hugepage completely, if any</span>
<span class="p_add">+ * part of it lies within the given range.</span>
  */
 void dissolve_free_huge_pages(unsigned long start_pfn, unsigned long end_pfn)
 {
<span class="p_chunk">@@ -1466,7 +1468,6 @@</span> <span class="p_context"> void dissolve_free_huge_pages(unsigned long start_pfn, unsigned long end_pfn)</span>
 	if (!hugepages_supported())
 		return;
 
<span class="p_del">-	VM_BUG_ON(!IS_ALIGNED(start_pfn, 1 &lt;&lt; minimum_order));</span>
 	for (pfn = start_pfn; pfn &lt; end_pfn; pfn += 1 &lt;&lt; minimum_order)
 		dissolve_free_huge_page(pfn_to_page(pfn));
 }

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



