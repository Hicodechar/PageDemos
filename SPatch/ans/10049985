
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>[RESEND,2/3] KVM: Add paravirt remote TLB flush - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    [RESEND,2/3] KVM: Add paravirt remote TLB flush</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=104371">Wanpeng Li</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>Nov. 9, 2017, 2:02 a.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;1510192934-5369-3-git-send-email-wanpeng.li@hotmail.com&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/10049985/mbox/"
   >mbox</a>
|
   <a href="/patch/10049985/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/10049985/">/patch/10049985/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
	[172.30.200.125])
	by pdx-korg-patchwork.web.codeaurora.org (Postfix) with ESMTP id
	305D8602D7 for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Thu,  9 Nov 2017 02:02:35 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 204CE2A842
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Thu,  9 Nov 2017 02:02:35 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id 1537F2A847; Thu,  9 Nov 2017 02:02:35 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-6.5 required=2.0 tests=BAYES_00,DKIM_SIGNED,
	DKIM_VALID, DKIM_VALID_AU, FREEMAIL_FROM, RCVD_IN_DNSWL_HI,
	RCVD_IN_SORBS_SPAM autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id B01892A84D
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Thu,  9 Nov 2017 02:02:34 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1752243AbdKICC2 (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Wed, 8 Nov 2017 21:02:28 -0500
Received: from mail-pg0-f66.google.com ([74.125.83.66]:45995 &quot;EHLO
	mail-pg0-f66.google.com&quot; rhost-flags-OK-OK-OK-OK) by vger.kernel.org
	with ESMTP id S1751930AbdKICCW (ORCPT
	&lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Wed, 8 Nov 2017 21:02:22 -0500
Received: by mail-pg0-f66.google.com with SMTP id l19so889493pgo.2;
	Wed, 08 Nov 2017 18:02:22 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
	d=gmail.com; s=20161025;
	h=from:to:cc:subject:date:message-id:in-reply-to:references
	:mime-version:content-transfer-encoding;
	bh=hOaj+r30mxyu4GJK6WMd/pslc8zdO2agY+rvmdwpbZg=;
	b=qPsKyESq5EK7A++gU5lO/3UnRv/RC00bN1qXzlqE1bx2k2Fq6M0F1Zv6ezFT9YbXNx
	qd3/M+EDxnhZvPH40aKEUE75RX2CcDkmRvTGyGYtfbpeVUhMY6AFj3NtQDx0T2uMiKYB
	2jK8EzZ13//9yvFfdcTHUlMiGrWBbc6o0+oCRfxWGAk5YnQ8MoIO+I7KZeNoM70ywa/X
	w8r6rN5bDakW5I7vX4osAoauYeQyEfE4yn7+Ye8HVmTy991J36TiC9bgMurjTd/ZuVJn
	aKH/FEz3mcfohPT7aX0rYGhkG5INbb+tt4H5YX9Vzos1p7eSjIeiyLJWsOq9/3ety7c2
	YoFA==
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
	d=1e100.net; s=20161025;
	h=x-gm-message-state:from:to:cc:subject:date:message-id:in-reply-to
	:references:mime-version:content-transfer-encoding;
	bh=hOaj+r30mxyu4GJK6WMd/pslc8zdO2agY+rvmdwpbZg=;
	b=qM6L07/zPiHL704JS5Jn3PwiLyvzphdMx91mIKe9y2wJSv1Dh20ZUmgENmHe8+moLG
	iMA5eY+D65wTBSLRph9QAp/QnuvIx2lCVkv9FAVOjmo/oi6ZO+9prC2g379TDU0FOwyT
	Ecf1zzLKxPs/Y8IUMVMTj0oeoRbKoK70SgIJz1AiMgxe2o1cgzjWBPx7pJyqHB4T4Iqr
	pU9xVuvuCiqQ9jBkJItJiCljSBECQ4l5gx4NostPo4GQ25waU5NgP/B7bRmKxKNEEN8y
	jI18pnjzfKLPxIhM1hf7mmt1RBJCrX8a6cEpvbMwo2WYrIUDdav/Mb7onyNmXBFq/c9l
	cn2w==
X-Gm-Message-State: AJaThX4BGzn/bUfDwrmT/XwKitZ9pFCjCeVkJJTj+FnRmj0WDYQK9KTE
	9vDodjbIADpDrDBOWSV1006VHQ==
X-Google-Smtp-Source: ABhQp+ShagNjBLYM+0iK36Owp+hh6wW4oc904AbhciBz5eba/UFaJ77IOfHQP8oQct/9qm5H1y7Pcw==
X-Received: by 10.99.116.89 with SMTP id e25mr2275983pgn.218.1510192941925; 
	Wed, 08 Nov 2017 18:02:21 -0800 (PST)
Received: from localhost ([203.205.141.123])
	by smtp.gmail.com with ESMTPSA id
	b9sm8106716pgu.20.2017.11.08.18.02.21
	(version=TLS1_2 cipher=ECDHE-RSA-AES128-GCM-SHA256 bits=128/128);
	Wed, 08 Nov 2017 18:02:21 -0800 (PST)
From: Wanpeng Li &lt;kernellwp@gmail.com&gt;
X-Google-Original-From: Wanpeng Li &lt;wanpeng.li@hotmail.com&gt;
To: linux-kernel@vger.kernel.org, kvm@vger.kernel.org
Cc: Paolo Bonzini &lt;pbonzini@redhat.com&gt;,
	=?UTF-8?q?Radim=20Kr=C4=8Dm=C3=A1=C5=99?= &lt;rkrcmar@redhat.com&gt;,
	Wanpeng Li &lt;wanpeng.li@hotmail.com&gt;
Subject: [PATCH RESEND 2/3] KVM: Add paravirt remote TLB flush
Date: Wed,  8 Nov 2017 18:02:13 -0800
Message-Id: &lt;1510192934-5369-3-git-send-email-wanpeng.li@hotmail.com&gt;
X-Mailer: git-send-email 2.7.4
In-Reply-To: &lt;1510192934-5369-1-git-send-email-wanpeng.li@hotmail.com&gt;
References: &lt;1510192934-5369-1-git-send-email-wanpeng.li@hotmail.com&gt;
MIME-Version: 1.0
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 8bit
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=104371">Wanpeng Li</a> - Nov. 9, 2017, 2:02 a.m.</div>
<pre class="content">
<span class="from">From: Wanpeng Li &lt;wanpeng.li@hotmail.com&gt;</span>

Remote flushing api&#39;s does a busy wait which is fine in bare-metal
scenario. But with-in the guest, the vcpus might have been pre-empted
or blocked. In this scenario, the initator vcpu would end up
busy-waiting for a long amount of time.

This patch set implements para-virt flush tlbs making sure that it
does not wait for vcpus that are sleeping. And all the sleeping vcpus
flush the tlb on guest enter.

The best result is achieved when we&#39;re overcommiting the host by running 
multiple vCPUs on each pCPU. In this case PV tlb flush avoids touching 
vCPUs which are not scheduled and avoid the wait on the main CPU.

Test on a Haswell i7 desktop 4 cores (2HT), so 8 pCPUs, running ebizzy in 
one linux guest.

ebizzy -M 
              vanilla    optimized     boost
 8 vCPUs       10152       10083       -0.68% 
16 vCPUs        1224        4866       297.5% 
24 vCPUs        1109        3871       249%
32 vCPUs        1025        3375       229.3% 

Cc: Paolo Bonzini &lt;pbonzini@redhat.com&gt;
Cc: Radim Krčmář &lt;rkrcmar@redhat.com&gt;
<span class="signed-off-by">Signed-off-by: Wanpeng Li &lt;wanpeng.li@hotmail.com&gt;</span>
---
 arch/x86/include/uapi/asm/kvm_para.h |  1 +
 arch/x86/kernel/kvm.c                | 29 +++++++++++++++++++++++++++++
 2 files changed, 30 insertions(+)
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=2536">Paolo Bonzini</a> - Nov. 9, 2017, 10:48 a.m.</div>
<pre class="content">
On 09/11/2017 03:02, Wanpeng Li wrote:
<span class="quote">&gt; From: Wanpeng Li &lt;wanpeng.li@hotmail.com&gt;</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Remote flushing api&#39;s does a busy wait which is fine in bare-metal</span>
<span class="quote">&gt; scenario. But with-in the guest, the vcpus might have been pre-empted</span>
<span class="quote">&gt; or blocked. In this scenario, the initator vcpu would end up</span>
<span class="quote">&gt; busy-waiting for a long amount of time.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; This patch set implements para-virt flush tlbs making sure that it</span>
<span class="quote">&gt; does not wait for vcpus that are sleeping. And all the sleeping vcpus</span>
<span class="quote">&gt; flush the tlb on guest enter.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; The best result is achieved when we&#39;re overcommiting the host by running </span>
<span class="quote">&gt; multiple vCPUs on each pCPU. In this case PV tlb flush avoids touching </span>
<span class="quote">&gt; vCPUs which are not scheduled and avoid the wait on the main CPU.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Test on a Haswell i7 desktop 4 cores (2HT), so 8 pCPUs, running ebizzy in </span>
<span class="quote">&gt; one linux guest.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; ebizzy -M </span>
<span class="quote">&gt;               vanilla    optimized     boost</span>
<span class="quote">&gt;  8 vCPUs       10152       10083       -0.68% </span>
<span class="quote">&gt; 16 vCPUs        1224        4866       297.5% </span>
<span class="quote">&gt; 24 vCPUs        1109        3871       249%</span>
<span class="quote">&gt; 32 vCPUs        1025        3375       229.3% </span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Cc: Paolo Bonzini &lt;pbonzini@redhat.com&gt;</span>
<span class="quote">&gt; Cc: Radim Krčmář &lt;rkrcmar@redhat.com&gt;</span>
<span class="quote">&gt; Signed-off-by: Wanpeng Li &lt;wanpeng.li@hotmail.com&gt;</span>
<span class="quote">&gt; ---</span>
<span class="quote">&gt;  arch/x86/include/uapi/asm/kvm_para.h |  1 +</span>
<span class="quote">&gt;  arch/x86/kernel/kvm.c                | 29 +++++++++++++++++++++++++++++</span>
<span class="quote">&gt;  2 files changed, 30 insertions(+)</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; diff --git a/arch/x86/include/uapi/asm/kvm_para.h b/arch/x86/include/uapi/asm/kvm_para.h</span>
<span class="quote">&gt; index ff23ce9..189e354 100644</span>
<span class="quote">&gt; --- a/arch/x86/include/uapi/asm/kvm_para.h</span>
<span class="quote">&gt; +++ b/arch/x86/include/uapi/asm/kvm_para.h</span>
<span class="quote">&gt; @@ -52,6 +52,7 @@ struct kvm_steal_time {</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  #define KVM_VCPU_NOT_PREEMPTED      (0 &lt;&lt; 0)</span>
<span class="quote">&gt;  #define KVM_VCPU_PREEMPTED          (1 &lt;&lt; 0)</span>
<span class="quote">&gt; +#define KVM_VCPU_SHOULD_FLUSH       (1 &lt;&lt; 1)</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  #define KVM_CLOCK_PAIRING_WALLCLOCK 0</span>
<span class="quote">&gt;  struct kvm_clock_pairing {</span>
<span class="quote">&gt; diff --git a/arch/x86/kernel/kvm.c b/arch/x86/kernel/kvm.c</span>
<span class="quote">&gt; index 1b1b641..2e2f3ae 100644</span>
<span class="quote">&gt; --- a/arch/x86/kernel/kvm.c</span>
<span class="quote">&gt; +++ b/arch/x86/kernel/kvm.c</span>
<span class="quote">&gt; @@ -465,6 +465,33 @@ static void __init kvm_apf_trap_init(void)</span>
<span class="quote">&gt;  	update_intr_gate(X86_TRAP_PF, async_page_fault);</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; +static void kvm_flush_tlb_others(const struct cpumask *cpumask,</span>
<span class="quote">&gt; +			const struct flush_tlb_info *info)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	u8 state;</span>
<span class="quote">&gt; +	int cpu;</span>
<span class="quote">&gt; +	struct kvm_steal_time *src;</span>
<span class="quote">&gt; +	cpumask_t flushmask;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	cpumask_copy(&amp;flushmask, cpumask);</span>
<span class="quote">&gt; +	/*</span>
<span class="quote">&gt; +	 * We have to call flush only on online vCPUs. And</span>
<span class="quote">&gt; +	 * queue flush_on_enter for pre-empted vCPUs</span>
<span class="quote">&gt; +	 */</span>
<span class="quote">&gt; +	for_each_cpu(cpu, cpumask) {</span>
<span class="quote">&gt; +		src = &amp;per_cpu(steal_time, cpu);</span>
<span class="quote">&gt; +		state = src-&gt;preempted;</span>
<span class="quote">&gt; +		if ((state &amp; KVM_VCPU_PREEMPTED)) {</span>
<span class="quote">&gt; +			if (cmpxchg(&amp;src-&gt;preempted, state, state | 1 &lt;&lt;</span>
<span class="quote">&gt; +				KVM_VCPU_SHOULD_FLUSH))</span>
<span class="quote">&gt; +					cpumask_clear_cpu(cpu, &amp;flushmask);</span>
<span class="quote">&gt; +		}</span>
<span class="quote">&gt; +	}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	native_flush_tlb_others(&amp;flushmask, info);</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt;  void __init kvm_guest_init(void)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	int i;</span>
<span class="quote">&gt; @@ -484,6 +511,8 @@ void __init kvm_guest_init(void)</span>
<span class="quote">&gt;  		pv_time_ops.steal_clock = kvm_steal_clock;</span>
<span class="quote">&gt;  	}</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; +	pv_mmu_ops.flush_tlb_others = kvm_flush_tlb_others;</span>

This needs to be keyed on a new CPUID feature bit.  Eduardo is also
adding a new &quot;PV_DEDICATED&quot; hint and you might disable PV TLB flush when
PV_DEDICATED is set.

Paolo
<span class="quote">
&gt;  	if (kvm_para_has_feature(KVM_FEATURE_PV_EOI))</span>
<span class="quote">&gt;  		apic_set_eoi_write(kvm_guest_apic_eoi_write);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;</span>
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=104371">Wanpeng Li</a> - Nov. 9, 2017, 11:01 a.m.</div>
<pre class="content">
2017-11-09 18:48 GMT+08:00 Paolo Bonzini &lt;pbonzini@redhat.com&gt;:
<span class="quote">&gt; On 09/11/2017 03:02, Wanpeng Li wrote:</span>
<span class="quote">&gt;&gt; From: Wanpeng Li &lt;wanpeng.li@hotmail.com&gt;</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; Remote flushing api&#39;s does a busy wait which is fine in bare-metal</span>
<span class="quote">&gt;&gt; scenario. But with-in the guest, the vcpus might have been pre-empted</span>
<span class="quote">&gt;&gt; or blocked. In this scenario, the initator vcpu would end up</span>
<span class="quote">&gt;&gt; busy-waiting for a long amount of time.</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; This patch set implements para-virt flush tlbs making sure that it</span>
<span class="quote">&gt;&gt; does not wait for vcpus that are sleeping. And all the sleeping vcpus</span>
<span class="quote">&gt;&gt; flush the tlb on guest enter.</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; The best result is achieved when we&#39;re overcommiting the host by running</span>
<span class="quote">&gt;&gt; multiple vCPUs on each pCPU. In this case PV tlb flush avoids touching</span>
<span class="quote">&gt;&gt; vCPUs which are not scheduled and avoid the wait on the main CPU.</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; Test on a Haswell i7 desktop 4 cores (2HT), so 8 pCPUs, running ebizzy in</span>
<span class="quote">&gt;&gt; one linux guest.</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; ebizzy -M</span>
<span class="quote">&gt;&gt;               vanilla    optimized     boost</span>
<span class="quote">&gt;&gt;  8 vCPUs       10152       10083       -0.68%</span>
<span class="quote">&gt;&gt; 16 vCPUs        1224        4866       297.5%</span>
<span class="quote">&gt;&gt; 24 vCPUs        1109        3871       249%</span>
<span class="quote">&gt;&gt; 32 vCPUs        1025        3375       229.3%</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; Cc: Paolo Bonzini &lt;pbonzini@redhat.com&gt;</span>
<span class="quote">&gt;&gt; Cc: Radim Krčmář &lt;rkrcmar@redhat.com&gt;</span>
<span class="quote">&gt;&gt; Signed-off-by: Wanpeng Li &lt;wanpeng.li@hotmail.com&gt;</span>
<span class="quote">&gt;&gt; ---</span>
<span class="quote">&gt;&gt;  arch/x86/include/uapi/asm/kvm_para.h |  1 +</span>
<span class="quote">&gt;&gt;  arch/x86/kernel/kvm.c                | 29 +++++++++++++++++++++++++++++</span>
<span class="quote">&gt;&gt;  2 files changed, 30 insertions(+)</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; diff --git a/arch/x86/include/uapi/asm/kvm_para.h b/arch/x86/include/uapi/asm/kvm_para.h</span>
<span class="quote">&gt;&gt; index ff23ce9..189e354 100644</span>
<span class="quote">&gt;&gt; --- a/arch/x86/include/uapi/asm/kvm_para.h</span>
<span class="quote">&gt;&gt; +++ b/arch/x86/include/uapi/asm/kvm_para.h</span>
<span class="quote">&gt;&gt; @@ -52,6 +52,7 @@ struct kvm_steal_time {</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt;  #define KVM_VCPU_NOT_PREEMPTED      (0 &lt;&lt; 0)</span>
<span class="quote">&gt;&gt;  #define KVM_VCPU_PREEMPTED          (1 &lt;&lt; 0)</span>
<span class="quote">&gt;&gt; +#define KVM_VCPU_SHOULD_FLUSH       (1 &lt;&lt; 1)</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt;  #define KVM_CLOCK_PAIRING_WALLCLOCK 0</span>
<span class="quote">&gt;&gt;  struct kvm_clock_pairing {</span>
<span class="quote">&gt;&gt; diff --git a/arch/x86/kernel/kvm.c b/arch/x86/kernel/kvm.c</span>
<span class="quote">&gt;&gt; index 1b1b641..2e2f3ae 100644</span>
<span class="quote">&gt;&gt; --- a/arch/x86/kernel/kvm.c</span>
<span class="quote">&gt;&gt; +++ b/arch/x86/kernel/kvm.c</span>
<span class="quote">&gt;&gt; @@ -465,6 +465,33 @@ static void __init kvm_apf_trap_init(void)</span>
<span class="quote">&gt;&gt;       update_intr_gate(X86_TRAP_PF, async_page_fault);</span>
<span class="quote">&gt;&gt;  }</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; +static void kvm_flush_tlb_others(const struct cpumask *cpumask,</span>
<span class="quote">&gt;&gt; +                     const struct flush_tlb_info *info)</span>
<span class="quote">&gt;&gt; +{</span>
<span class="quote">&gt;&gt; +     u8 state;</span>
<span class="quote">&gt;&gt; +     int cpu;</span>
<span class="quote">&gt;&gt; +     struct kvm_steal_time *src;</span>
<span class="quote">&gt;&gt; +     cpumask_t flushmask;</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +     cpumask_copy(&amp;flushmask, cpumask);</span>
<span class="quote">&gt;&gt; +     /*</span>
<span class="quote">&gt;&gt; +      * We have to call flush only on online vCPUs. And</span>
<span class="quote">&gt;&gt; +      * queue flush_on_enter for pre-empted vCPUs</span>
<span class="quote">&gt;&gt; +      */</span>
<span class="quote">&gt;&gt; +     for_each_cpu(cpu, cpumask) {</span>
<span class="quote">&gt;&gt; +             src = &amp;per_cpu(steal_time, cpu);</span>
<span class="quote">&gt;&gt; +             state = src-&gt;preempted;</span>
<span class="quote">&gt;&gt; +             if ((state &amp; KVM_VCPU_PREEMPTED)) {</span>
<span class="quote">&gt;&gt; +                     if (cmpxchg(&amp;src-&gt;preempted, state, state | 1 &lt;&lt;</span>
<span class="quote">&gt;&gt; +                             KVM_VCPU_SHOULD_FLUSH))</span>
<span class="quote">&gt;&gt; +                                     cpumask_clear_cpu(cpu, &amp;flushmask);</span>
<span class="quote">&gt;&gt; +             }</span>
<span class="quote">&gt;&gt; +     }</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +     native_flush_tlb_others(&amp;flushmask, info);</span>
<span class="quote">&gt;&gt; +}</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt;  void __init kvm_guest_init(void)</span>
<span class="quote">&gt;&gt;  {</span>
<span class="quote">&gt;&gt;       int i;</span>
<span class="quote">&gt;&gt; @@ -484,6 +511,8 @@ void __init kvm_guest_init(void)</span>
<span class="quote">&gt;&gt;               pv_time_ops.steal_clock = kvm_steal_clock;</span>
<span class="quote">&gt;&gt;       }</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; +     pv_mmu_ops.flush_tlb_others = kvm_flush_tlb_others;</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; This needs to be keyed on a new CPUID feature bit.  Eduardo is also</span>

Will do.
<span class="quote">
&gt; adding a new &quot;PV_DEDICATED&quot; hint and you might disable PV TLB flush when</span>
<span class="quote">&gt; PV_DEDICATED is set.</span>

Why disable PV TLB flush for PV_DEDICATED(qspinlock)?

Regards,
Wanpeng Li
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=2536">Paolo Bonzini</a> - Nov. 9, 2017, 11:02 a.m.</div>
<pre class="content">
On 09/11/2017 12:01, Wanpeng Li wrote:
<span class="quote">&gt; 2017-11-09 18:48 GMT+08:00 Paolo Bonzini &lt;pbonzini@redhat.com&gt;:</span>
<span class="quote">&gt;&gt; On 09/11/2017 03:02, Wanpeng Li wrote:</span>
<span class="quote">&gt;&gt;&gt; @@ -484,6 +511,8 @@ void __init kvm_guest_init(void)</span>
<span class="quote">&gt;&gt;&gt;               pv_time_ops.steal_clock = kvm_steal_clock;</span>
<span class="quote">&gt;&gt;&gt;       }</span>
<span class="quote">&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt; +     pv_mmu_ops.flush_tlb_others = kvm_flush_tlb_others;</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; This needs to be keyed on a new CPUID feature bit.  Eduardo is also</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Will do.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt;&gt; adding a new &quot;PV_DEDICATED&quot; hint and you might disable PV TLB flush when</span>
<span class="quote">&gt;&gt; PV_DEDICATED is set.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Why disable PV TLB flush for PV_DEDICATED(qspinlock)?</span>

PV_DEDICATED says pretty much that it is very unlikely to have a
preempted vCPU.  Therefore, the cpumask loop is unnecessary.

Paolo
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=104371">Wanpeng Li</a> - Nov. 9, 2017, 11:08 a.m.</div>
<pre class="content">
2017-11-09 19:02 GMT+08:00 Paolo Bonzini &lt;pbonzini@redhat.com&gt;:
<span class="quote">&gt; On 09/11/2017 12:01, Wanpeng Li wrote:</span>
<span class="quote">&gt;&gt; 2017-11-09 18:48 GMT+08:00 Paolo Bonzini &lt;pbonzini@redhat.com&gt;:</span>
<span class="quote">&gt;&gt;&gt; On 09/11/2017 03:02, Wanpeng Li wrote:</span>
<span class="quote">&gt;&gt;&gt;&gt; @@ -484,6 +511,8 @@ void __init kvm_guest_init(void)</span>
<span class="quote">&gt;&gt;&gt;&gt;               pv_time_ops.steal_clock = kvm_steal_clock;</span>
<span class="quote">&gt;&gt;&gt;&gt;       }</span>
<span class="quote">&gt;&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt;&gt; +     pv_mmu_ops.flush_tlb_others = kvm_flush_tlb_others;</span>
<span class="quote">&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt; This needs to be keyed on a new CPUID feature bit.  Eduardo is also</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; Will do.</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt; adding a new &quot;PV_DEDICATED&quot; hint and you might disable PV TLB flush when</span>
<span class="quote">&gt;&gt;&gt; PV_DEDICATED is set.</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; Why disable PV TLB flush for PV_DEDICATED(qspinlock)?</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; PV_DEDICATED says pretty much that it is very unlikely to have a</span>
<span class="quote">&gt; preempted vCPU.  Therefore, the cpumask loop is unnecessary.</span>

Thanks for pointing out this. :)

Regards,
Wanpeng Li
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=69351">Radim Kr?má?</a> - Nov. 9, 2017, 3:11 p.m.</div>
<pre class="content">
2017-11-08 18:02-0800, Wanpeng Li:
<span class="quote">&gt; From: Wanpeng Li &lt;wanpeng.li@hotmail.com&gt;</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Remote flushing api&#39;s does a busy wait which is fine in bare-metal</span>
<span class="quote">&gt; scenario. But with-in the guest, the vcpus might have been pre-empted</span>
<span class="quote">&gt; or blocked. In this scenario, the initator vcpu would end up</span>
<span class="quote">&gt; busy-waiting for a long amount of time.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; This patch set implements para-virt flush tlbs making sure that it</span>
<span class="quote">&gt; does not wait for vcpus that are sleeping. And all the sleeping vcpus</span>
<span class="quote">&gt; flush the tlb on guest enter.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; The best result is achieved when we&#39;re overcommiting the host by running </span>
<span class="quote">&gt; multiple vCPUs on each pCPU. In this case PV tlb flush avoids touching </span>
<span class="quote">&gt; vCPUs which are not scheduled and avoid the wait on the main CPU.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Test on a Haswell i7 desktop 4 cores (2HT), so 8 pCPUs, running ebizzy in </span>
<span class="quote">&gt; one linux guest.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; ebizzy -M </span>
<span class="quote">&gt;               vanilla    optimized     boost</span>
<span class="quote">&gt;  8 vCPUs       10152       10083       -0.68% </span>
<span class="quote">&gt; 16 vCPUs        1224        4866       297.5% </span>
<span class="quote">&gt; 24 vCPUs        1109        3871       249%</span>
<span class="quote">&gt; 32 vCPUs        1025        3375       229.3% </span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Cc: Paolo Bonzini &lt;pbonzini@redhat.com&gt;</span>
<span class="quote">&gt; Cc: Radim Krčmář &lt;rkrcmar@redhat.com&gt;</span>
<span class="quote">&gt; Signed-off-by: Wanpeng Li &lt;wanpeng.li@hotmail.com&gt;</span>
<span class="quote">&gt; ---</span>
<span class="quote">&gt; diff --git a/arch/x86/kernel/kvm.c b/arch/x86/kernel/kvm.c</span>
<span class="quote">&gt; @@ -465,6 +465,33 @@ static void __init kvm_apf_trap_init(void)</span>
<span class="quote">&gt;  	update_intr_gate(X86_TRAP_PF, async_page_fault);</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; +static void kvm_flush_tlb_others(const struct cpumask *cpumask,</span>
<span class="quote">&gt; +			const struct flush_tlb_info *info)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	u8 state;</span>
<span class="quote">&gt; +	int cpu;</span>
<span class="quote">&gt; +	struct kvm_steal_time *src;</span>
<span class="quote">&gt; +	cpumask_t flushmask;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	cpumask_copy(&amp;flushmask, cpumask);</span>
<span class="quote">&gt; +	/*</span>
<span class="quote">&gt; +	 * We have to call flush only on online vCPUs. And</span>
<span class="quote">&gt; +	 * queue flush_on_enter for pre-empted vCPUs</span>
<span class="quote">&gt; +	 */</span>
<span class="quote">&gt; +	for_each_cpu(cpu, cpumask) {</span>
<span class="quote">&gt; +		src = &amp;per_cpu(steal_time, cpu);</span>
<span class="quote">&gt; +		state = src-&gt;preempted;</span>
<span class="quote">&gt; +		if ((state &amp; KVM_VCPU_PREEMPTED)) {</span>
<span class="quote">&gt; +			if (cmpxchg(&amp;src-&gt;preempted, state, state | 1 &lt;&lt;</span>
<span class="quote">&gt; +				KVM_VCPU_SHOULD_FLUSH))</span>

We won&#39;t be flushing unless the last argument reads &#39;state |
KVM_VCPU_SHOULD_FLUSH&#39; and the result will be the original value that
should be compared with state to avoid a race that would drop running
VCPU:

  if (cmpxchg(&amp;src-&gt;preempted, state, state | KVM_VCPU_SHOULD_FLUSH) == state)
<span class="quote">
&gt; +					cpumask_clear_cpu(cpu, &amp;flushmask);</span>
<span class="quote">&gt; +		}</span>
<span class="quote">&gt; +	}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	native_flush_tlb_others(&amp;flushmask, info);</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt;  void __init kvm_guest_init(void)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	int i;</span>
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/arch/x86/include/uapi/asm/kvm_para.h b/arch/x86/include/uapi/asm/kvm_para.h</span>
<span class="p_header">index ff23ce9..189e354 100644</span>
<span class="p_header">--- a/arch/x86/include/uapi/asm/kvm_para.h</span>
<span class="p_header">+++ b/arch/x86/include/uapi/asm/kvm_para.h</span>
<span class="p_chunk">@@ -52,6 +52,7 @@</span> <span class="p_context"> struct kvm_steal_time {</span>
 
 #define KVM_VCPU_NOT_PREEMPTED      (0 &lt;&lt; 0)
 #define KVM_VCPU_PREEMPTED          (1 &lt;&lt; 0)
<span class="p_add">+#define KVM_VCPU_SHOULD_FLUSH       (1 &lt;&lt; 1)</span>
 
 #define KVM_CLOCK_PAIRING_WALLCLOCK 0
 struct kvm_clock_pairing {
<span class="p_header">diff --git a/arch/x86/kernel/kvm.c b/arch/x86/kernel/kvm.c</span>
<span class="p_header">index 1b1b641..2e2f3ae 100644</span>
<span class="p_header">--- a/arch/x86/kernel/kvm.c</span>
<span class="p_header">+++ b/arch/x86/kernel/kvm.c</span>
<span class="p_chunk">@@ -465,6 +465,33 @@</span> <span class="p_context"> static void __init kvm_apf_trap_init(void)</span>
 	update_intr_gate(X86_TRAP_PF, async_page_fault);
 }
 
<span class="p_add">+static void kvm_flush_tlb_others(const struct cpumask *cpumask,</span>
<span class="p_add">+			const struct flush_tlb_info *info)</span>
<span class="p_add">+{</span>
<span class="p_add">+	u8 state;</span>
<span class="p_add">+	int cpu;</span>
<span class="p_add">+	struct kvm_steal_time *src;</span>
<span class="p_add">+	cpumask_t flushmask;</span>
<span class="p_add">+</span>
<span class="p_add">+</span>
<span class="p_add">+	cpumask_copy(&amp;flushmask, cpumask);</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * We have to call flush only on online vCPUs. And</span>
<span class="p_add">+	 * queue flush_on_enter for pre-empted vCPUs</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	for_each_cpu(cpu, cpumask) {</span>
<span class="p_add">+		src = &amp;per_cpu(steal_time, cpu);</span>
<span class="p_add">+		state = src-&gt;preempted;</span>
<span class="p_add">+		if ((state &amp; KVM_VCPU_PREEMPTED)) {</span>
<span class="p_add">+			if (cmpxchg(&amp;src-&gt;preempted, state, state | 1 &lt;&lt;</span>
<span class="p_add">+				KVM_VCPU_SHOULD_FLUSH))</span>
<span class="p_add">+					cpumask_clear_cpu(cpu, &amp;flushmask);</span>
<span class="p_add">+		}</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	native_flush_tlb_others(&amp;flushmask, info);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 void __init kvm_guest_init(void)
 {
 	int i;
<span class="p_chunk">@@ -484,6 +511,8 @@</span> <span class="p_context"> void __init kvm_guest_init(void)</span>
 		pv_time_ops.steal_clock = kvm_steal_clock;
 	}
 
<span class="p_add">+	pv_mmu_ops.flush_tlb_others = kvm_flush_tlb_others;</span>
<span class="p_add">+</span>
 	if (kvm_para_has_feature(KVM_FEATURE_PV_EOI))
 		apic_set_eoi_write(kvm_guest_apic_eoi_write);
 

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



