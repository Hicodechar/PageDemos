
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>[GIT,PULL] tracing: Updates for v4.6 - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    [GIT,PULL] tracing: Updates for v4.6</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=310">Steven Rostedt</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>March 24, 2016, 2:16 p.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;20160324101611.5bd03f51@gandalf.local.home&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/8661181/mbox/"
   >mbox</a>
|
   <a href="/patch/8661181/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/8661181/">/patch/8661181/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
X-Original-To: patchwork-LKML@patchwork.kernel.org
Delivered-To: patchwork-parsemail@patchwork2.web.kernel.org
Received: from mail.kernel.org (mail.kernel.org [198.145.29.136])
	by patchwork2.web.kernel.org (Postfix) with ESMTP id 30EF1C0554
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Thu, 24 Mar 2016 14:16:56 +0000 (UTC)
Received: from mail.kernel.org (localhost [127.0.0.1])
	by mail.kernel.org (Postfix) with ESMTP id 53A1320389
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Thu, 24 Mar 2016 14:16:53 +0000 (UTC)
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.kernel.org (Postfix) with ESMTP id 98D06203AD
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Thu, 24 Mar 2016 14:16:44 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1755412AbcCXOQj (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Thu, 24 Mar 2016 10:16:39 -0400
Received: from smtprelay0219.hostedemail.com ([216.40.44.219]:35553 &quot;EHLO
	smtprelay.hostedemail.com&quot; rhost-flags-OK-OK-OK-FAIL)
	by vger.kernel.org with ESMTP id S1750818AbcCXOQ3 (ORCPT
	&lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Thu, 24 Mar 2016 10:16:29 -0400
Received: from filter.hostedemail.com (unknown [216.40.38.60])
	by smtprelay04.hostedemail.com (Postfix) with ESMTP id D177635203F;
	Thu, 24 Mar 2016 14:16:15 +0000 (UTC)
X-Session-Marker: 726F737465647440676F6F646D69732E6F7267
X-Spam-Summary: 2, 0, 0, , d41d8cd98f00b204, rostedt@goodmis.org, :::::,
	RULES_HIT:69:355:379:541:960:966:968:973:988:989:1260:1277:1311:1313:1314:1345:1437:1500:1515:1516:1518:1593:1594:1605:1730:1747:1777:1792:1801:1981:2194:2196:2198:2199:2200:2201:2393:2538:2559:2562:2693:2731:2895:2898:2901:2907:2924:2926:3138:3139:3140:3141:3142:3865:3866:3867:3868:3870:3871:3872:3873:3874:4250:4321:4384:4385:4395:4398:4605:4641:5007:6261:7862:7875:7903:7904:8660:9010:9592:10004:10848:11026:11232:11914:12043:12291:12294:12295:12296:12438:12517:12519:12555:12663:12679:12683:13138:13148:13230:13231:13439:13972:14659:21060:21063:21080:21121:21222:21365:30004:30012:30029:30034:30045:30051:30054:30055:30056:30067:30070:30090,
	0, RBL:none, CacheIP:none, Bayesian:0.5, 0.5, 0.5,
	Netcheck:none, DomainCache:0, MSF:not bulk, SPF:fn, MSBL:0,
	DNSBL:none, Custom_rules:0:0:0, LFtime:2, LUA_SUMMARY:none
X-HE-Tag: knee95_8dc22405e1106
X-Filterd-Recvd-Size: 51189
Received: from gandalf.local.home (cpe-67-246-153-56.stny.res.rr.com
	[67.246.153.56]) (Authenticated sender: rostedt@goodmis.org)
	by omf09.hostedemail.com (Postfix) with ESMTPA;
	Thu, 24 Mar 2016 14:16:14 +0000 (UTC)
Date: Thu, 24 Mar 2016 10:16:11 -0400
From: Steven Rostedt &lt;rostedt@goodmis.org&gt;
To: Linus Torvalds &lt;torvalds@linux-foundation.org&gt;
Cc: LKML &lt;linux-kernel@vger.kernel.org&gt;, Ingo Molnar &lt;mingo@kernel.org&gt;
Subject: [GIT PULL] tracing: Updates for v4.6
Message-ID: &lt;20160324101611.5bd03f51@gandalf.local.home&gt;
X-Mailer: Claws Mail 3.13.2 (GTK+ 2.24.29; x86_64-pc-linux-gnu)
MIME-Version: 1.0
Content-Type: text/plain; charset=US-ASCII
Content-Transfer-Encoding: 7bit
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Spam-Status: No, score=-6.9 required=5.0 tests=BAYES_00, RCVD_IN_DNSWL_HI, 
	T_RP_MATCHES_RCVD,
	UNPARSEABLE_RELAY autolearn=unavailable version=3.3.1
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on mail.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=310">Steven Rostedt</a> - March 24, 2016, 2:16 p.m.</div>
<pre class="content">
Linus,

Nothing major this round. Mostly small clean ups and fixes.

Some visible changes:

 A new flag was added to distinguish traces done in NMI context.

 Preempt tracer now shows functions where preemption is disabled but
 interrupts are still enabled.

Other notes:

 Updates were done to function tracing to allow better performance
 with perf.

 Infrastructure code has been added to allow for a new histogram
 feature for recording live trace event histograms that can be
 configured by simple user commands. The feature itself was just
 finished, but needs a round in linux-next before being pulled.
 This only includes some infrastructure changes that will be needed.


Please pull the latest trace-v4.6 tree, which can be found at:


  git://git.kernel.org/pub/scm/linux/kernel/git/rostedt/linux-trace.git
trace-v4.6

Tag SHA1: 1d61869c658fb2969ef40f23474b007285b51904
Head SHA1: 7e6867bf831c71fe0e47438831ae3a94d4c7ab3c


Chunyu Hu (3):
      tracing: Make tracer_flags use the right set_flag callback
      tracing: Fix typoes in code comment and printk in trace_nop.c
      tracing: Fix return while holding a lock in register_tracer()

Dmitry Safonov (1):
      tracing: Remove redundant reset per-CPU buff in irqsoff tracer

Geliang Tang (1):
      ftrace: Use kasprintf() in ftrace_profile_tracefs()

Jiri Olsa (2):
      ftrace: Make ftrace_hash_rec_enable return update bool
      ftrace: Update dynamic ftrace calls only if necessary

Li Bin (1):
      x86: ftrace: Fix the misleading comment for arch/x86/kernel/ftrace.c

Peter Zijlstra (1):
      tracing: Record and show NMI state

Steven Rostedt (Red Hat) (5):
      tracing: Remove duplicate checks for online CPUs
      tracing: Use flags instead of bool in trigger structure
      tracing: Have preempt(irqs)off trace preempt disabled functions
      tracing: Fix crash from reading trace_pipe with sendfile
      tracing: Fix trace_printk() to print when not using bprintk()

Tom Zanussi (7):
      tracing: Make ftrace_event_field checking functions available
      tracing: Make event trigger functions available
      tracing: Add event record param to trigger_ops.func()
      tracing: Add get_syscall_name()
      tracing: Add a per-event-trigger &#39;paused&#39; field
      tracing: Add needs_rec flag to event triggers
      tracing: Add an unreg_all() callback to trigger commands

Yang Shi (1):
      tracing, writeback: Replace cgroup path to cgroup ino

----
 arch/x86/kernel/ftrace.c            |   2 +-
 include/linux/kernel.h              |   6 +-
 include/linux/trace_events.h        |   7 ++-
 include/trace/events/kmem.h         |  42 ++-----------
 include/trace/events/tlb.h          |   4 +-
 include/trace/events/writeback.h    | 121 ++++++++++++++----------------------
 kernel/trace/ftrace.c               |  41 ++++++------
 kernel/trace/trace.c                |  36 ++++++-----
 kernel/trace/trace.h                | 113 ++++++++++++++++++++++++++-------
 kernel/trace/trace_events_filter.c  |  12 ----
 kernel/trace/trace_events_trigger.c |  88 +++++++++++++++-----------
 kernel/trace/trace_functions.c      |   6 ++
 kernel/trace/trace_irqsoff.c        |   9 ++-
 kernel/trace/trace_nop.c            |   4 +-
 kernel/trace/trace_output.c         |  10 ++-
 kernel/trace/trace_printk.c         |   3 +
 kernel/trace/trace_syscalls.c       |  11 ++++
 17 files changed, 280 insertions(+), 235 deletions(-)
---------------------------
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/arch/x86/kernel/ftrace.c b/arch/x86/kernel/ftrace.c</span>
<span class="p_header">index 29408d6d6626..1b7d7e4fd7b0 100644</span>
<span class="p_header">--- a/arch/x86/kernel/ftrace.c</span>
<span class="p_header">+++ b/arch/x86/kernel/ftrace.c</span>
<span class="p_chunk">@@ -1,5 +1,5 @@</span> <span class="p_context"></span>
 /*
<span class="p_del">- * Code for replacing ftrace calls with jumps.</span>
<span class="p_add">+ * Dynamic function tracing support.</span>
  *
  * Copyright (C) 2007-2008 Steven Rostedt &lt;srostedt@redhat.com&gt;
  *
<span class="p_header">diff --git a/include/linux/kernel.h b/include/linux/kernel.h</span>
<span class="p_header">index f31638c6e873..95452f72349a 100644</span>
<span class="p_header">--- a/include/linux/kernel.h</span>
<span class="p_header">+++ b/include/linux/kernel.h</span>
<span class="p_chunk">@@ -635,7 +635,7 @@</span> <span class="p_context"> do {							\</span>
 
 #define do_trace_printk(fmt, args...)					\
 do {									\
<span class="p_del">-	static const char *trace_printk_fmt				\</span>
<span class="p_add">+	static const char *trace_printk_fmt __used			\</span>
 		__attribute__((section(&quot;__trace_printk_fmt&quot;))) =	\
 		__builtin_constant_p(fmt) ? fmt : NULL;			\
 									\
<span class="p_chunk">@@ -679,7 +679,7 @@</span> <span class="p_context"> int __trace_printk(unsigned long ip, const char *fmt, ...);</span>
  */
 
 #define trace_puts(str) ({						\
<span class="p_del">-	static const char *trace_printk_fmt				\</span>
<span class="p_add">+	static const char *trace_printk_fmt __used			\</span>
 		__attribute__((section(&quot;__trace_printk_fmt&quot;))) =	\
 		__builtin_constant_p(str) ? str : NULL;			\
 									\
<span class="p_chunk">@@ -701,7 +701,7 @@</span> <span class="p_context"> extern void trace_dump_stack(int skip);</span>
 #define ftrace_vprintk(fmt, vargs)					\
 do {									\
 	if (__builtin_constant_p(fmt)) {				\
<span class="p_del">-		static const char *trace_printk_fmt			\</span>
<span class="p_add">+		static const char *trace_printk_fmt __used		\</span>
 		  __attribute__((section(&quot;__trace_printk_fmt&quot;))) =	\
 			__builtin_constant_p(fmt) ? fmt : NULL;		\
 									\
<span class="p_header">diff --git a/include/linux/trace_events.h b/include/linux/trace_events.h</span>
<span class="p_header">index 925730bc9fc1..0d6930e941e8 100644</span>
<span class="p_header">--- a/include/linux/trace_events.h</span>
<span class="p_header">+++ b/include/linux/trace_events.h</span>
<span class="p_chunk">@@ -430,7 +430,8 @@</span> <span class="p_context"> extern int call_filter_check_discard(struct trace_event_call *call, void *rec,</span>
 extern enum event_trigger_type event_triggers_call(struct trace_event_file *file,
 						   void *rec);
 extern void event_triggers_post_call(struct trace_event_file *file,
<span class="p_del">-				     enum event_trigger_type tt);</span>
<span class="p_add">+				     enum event_trigger_type tt,</span>
<span class="p_add">+				     void *rec);</span>
 
 bool trace_event_ignore_this_pid(struct trace_event_file *trace_file);
 
<span class="p_chunk">@@ -517,7 +518,7 @@</span> <span class="p_context"> event_trigger_unlock_commit(struct trace_event_file *file,</span>
 		trace_buffer_unlock_commit(file-&gt;tr, buffer, event, irq_flags, pc);
 
 	if (tt)
<span class="p_del">-		event_triggers_post_call(file, tt);</span>
<span class="p_add">+		event_triggers_post_call(file, tt, entry);</span>
 }
 
 /**
<span class="p_chunk">@@ -550,7 +551,7 @@</span> <span class="p_context"> event_trigger_unlock_commit_regs(struct trace_event_file *file,</span>
 						irq_flags, pc, regs);
 
 	if (tt)
<span class="p_del">-		event_triggers_post_call(file, tt);</span>
<span class="p_add">+		event_triggers_post_call(file, tt, entry);</span>
 }
 
 #ifdef CONFIG_BPF_EVENTS
<span class="p_header">diff --git a/include/trace/events/kmem.h b/include/trace/events/kmem.h</span>
<span class="p_header">index f7554fd7fc62..325b2a9b1959 100644</span>
<span class="p_header">--- a/include/trace/events/kmem.h</span>
<span class="p_header">+++ b/include/trace/events/kmem.h</span>
<span class="p_chunk">@@ -140,42 +140,19 @@</span> <span class="p_context"> DEFINE_EVENT(kmem_free, kfree,</span>
 	TP_ARGS(call_site, ptr)
 );
 
<span class="p_del">-DEFINE_EVENT_CONDITION(kmem_free, kmem_cache_free,</span>
<span class="p_add">+DEFINE_EVENT(kmem_free, kmem_cache_free,</span>
 
 	TP_PROTO(unsigned long call_site, const void *ptr),
 
<span class="p_del">-	TP_ARGS(call_site, ptr),</span>
<span class="p_del">-</span>
<span class="p_del">-	/*</span>
<span class="p_del">-	 * This trace can be potentially called from an offlined cpu.</span>
<span class="p_del">-	 * Since trace points use RCU and RCU should not be used from</span>
<span class="p_del">-	 * offline cpus, filter such calls out.</span>
<span class="p_del">-	 * While this trace can be called from a preemptable section,</span>
<span class="p_del">-	 * it has no impact on the condition since tasks can migrate</span>
<span class="p_del">-	 * only from online cpus to other online cpus. Thus its safe</span>
<span class="p_del">-	 * to use raw_smp_processor_id.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	TP_CONDITION(cpu_online(raw_smp_processor_id()))</span>
<span class="p_add">+	TP_ARGS(call_site, ptr)</span>
 );
 
<span class="p_del">-TRACE_EVENT_CONDITION(mm_page_free,</span>
<span class="p_add">+TRACE_EVENT(mm_page_free,</span>
 
 	TP_PROTO(struct page *page, unsigned int order),
 
 	TP_ARGS(page, order),
 
<span class="p_del">-</span>
<span class="p_del">-	/*</span>
<span class="p_del">-	 * This trace can be potentially called from an offlined cpu.</span>
<span class="p_del">-	 * Since trace points use RCU and RCU should not be used from</span>
<span class="p_del">-	 * offline cpus, filter such calls out.</span>
<span class="p_del">-	 * While this trace can be called from a preemptable section,</span>
<span class="p_del">-	 * it has no impact on the condition since tasks can migrate</span>
<span class="p_del">-	 * only from online cpus to other online cpus. Thus its safe</span>
<span class="p_del">-	 * to use raw_smp_processor_id.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	TP_CONDITION(cpu_online(raw_smp_processor_id())),</span>
<span class="p_del">-</span>
 	TP_STRUCT__entry(
 		__field(	unsigned long,	pfn		)
 		__field(	unsigned int,	order		)
<span class="p_chunk">@@ -276,23 +253,12 @@</span> <span class="p_context"> DEFINE_EVENT(mm_page, mm_page_alloc_zone_locked,</span>
 	TP_ARGS(page, order, migratetype)
 );
 
<span class="p_del">-TRACE_EVENT_CONDITION(mm_page_pcpu_drain,</span>
<span class="p_add">+TRACE_EVENT(mm_page_pcpu_drain,</span>
 
 	TP_PROTO(struct page *page, unsigned int order, int migratetype),
 
 	TP_ARGS(page, order, migratetype),
 
<span class="p_del">-	/*</span>
<span class="p_del">-	 * This trace can be potentially called from an offlined cpu.</span>
<span class="p_del">-	 * Since trace points use RCU and RCU should not be used from</span>
<span class="p_del">-	 * offline cpus, filter such calls out.</span>
<span class="p_del">-	 * While this trace can be called from a preemptable section,</span>
<span class="p_del">-	 * it has no impact on the condition since tasks can migrate</span>
<span class="p_del">-	 * only from online cpus to other online cpus. Thus its safe</span>
<span class="p_del">-	 * to use raw_smp_processor_id.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	TP_CONDITION(cpu_online(raw_smp_processor_id())),</span>
<span class="p_del">-</span>
 	TP_STRUCT__entry(
 		__field(	unsigned long,	pfn		)
 		__field(	unsigned int,	order		)
<span class="p_header">diff --git a/include/trace/events/tlb.h b/include/trace/events/tlb.h</span>
<span class="p_header">index bc8815f45f3b..9d14b1992108 100644</span>
<span class="p_header">--- a/include/trace/events/tlb.h</span>
<span class="p_header">+++ b/include/trace/events/tlb.h</span>
<span class="p_chunk">@@ -34,13 +34,11 @@</span> <span class="p_context"> TLB_FLUSH_REASON</span>
 #define EM(a,b)		{ a, b },
 #define EMe(a,b)	{ a, b }
 
<span class="p_del">-TRACE_EVENT_CONDITION(tlb_flush,</span>
<span class="p_add">+TRACE_EVENT(tlb_flush,</span>
 
 	TP_PROTO(int reason, unsigned long pages),
 	TP_ARGS(reason, pages),
 
<span class="p_del">-	TP_CONDITION(cpu_online(smp_processor_id())),</span>
<span class="p_del">-</span>
 	TP_STRUCT__entry(
 		__field(	  int, reason)
 		__field(unsigned long,  pages)
<span class="p_header">diff --git a/include/trace/events/writeback.h b/include/trace/events/writeback.h</span>
<span class="p_header">index fff846b512e6..73614ce1d204 100644</span>
<span class="p_header">--- a/include/trace/events/writeback.h</span>
<span class="p_header">+++ b/include/trace/events/writeback.h</span>
<span class="p_chunk">@@ -134,58 +134,28 @@</span> <span class="p_context"> DEFINE_EVENT(writeback_dirty_inode_template, writeback_dirty_inode,</span>
 #ifdef CREATE_TRACE_POINTS
 #ifdef CONFIG_CGROUP_WRITEBACK
 
<span class="p_del">-static inline size_t __trace_wb_cgroup_size(struct bdi_writeback *wb)</span>
<span class="p_add">+static inline unsigned int __trace_wb_assign_cgroup(struct bdi_writeback *wb)</span>
 {
<span class="p_del">-	return kernfs_path_len(wb-&gt;memcg_css-&gt;cgroup-&gt;kn) + 1;</span>
<span class="p_add">+	return wb-&gt;memcg_css-&gt;cgroup-&gt;kn-&gt;ino;</span>
 }
 
<span class="p_del">-static inline void __trace_wb_assign_cgroup(char *buf, struct bdi_writeback *wb)</span>
<span class="p_del">-{</span>
<span class="p_del">-	struct cgroup *cgrp = wb-&gt;memcg_css-&gt;cgroup;</span>
<span class="p_del">-	char *path;</span>
<span class="p_del">-</span>
<span class="p_del">-	path = cgroup_path(cgrp, buf, kernfs_path_len(cgrp-&gt;kn) + 1);</span>
<span class="p_del">-	WARN_ON_ONCE(path != buf);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static inline size_t __trace_wbc_cgroup_size(struct writeback_control *wbc)</span>
<span class="p_del">-{</span>
<span class="p_del">-	if (wbc-&gt;wb)</span>
<span class="p_del">-		return __trace_wb_cgroup_size(wbc-&gt;wb);</span>
<span class="p_del">-	else</span>
<span class="p_del">-		return 2;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static inline void __trace_wbc_assign_cgroup(char *buf,</span>
<span class="p_del">-					     struct writeback_control *wbc)</span>
<span class="p_add">+static inline unsigned int __trace_wbc_assign_cgroup(struct writeback_control *wbc)</span>
 {
 	if (wbc-&gt;wb)
<span class="p_del">-		__trace_wb_assign_cgroup(buf, wbc-&gt;wb);</span>
<span class="p_add">+		return __trace_wb_assign_cgroup(wbc-&gt;wb);</span>
 	else
<span class="p_del">-		strcpy(buf, &quot;/&quot;);</span>
<span class="p_add">+		return -1U;</span>
 }
<span class="p_del">-</span>
 #else	/* CONFIG_CGROUP_WRITEBACK */
 
<span class="p_del">-static inline size_t __trace_wb_cgroup_size(struct bdi_writeback *wb)</span>
<span class="p_del">-{</span>
<span class="p_del">-	return 2;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static inline void __trace_wb_assign_cgroup(char *buf, struct bdi_writeback *wb)</span>
<span class="p_del">-{</span>
<span class="p_del">-	strcpy(buf, &quot;/&quot;);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static inline size_t __trace_wbc_cgroup_size(struct writeback_control *wbc)</span>
<span class="p_add">+static inline unsigned int __trace_wb_assign_cgroup(struct bdi_writeback *wb)</span>
 {
<span class="p_del">-	return 2;</span>
<span class="p_add">+	return -1U;</span>
 }
 
<span class="p_del">-static inline void __trace_wbc_assign_cgroup(char *buf,</span>
<span class="p_del">-					     struct writeback_control *wbc)</span>
<span class="p_add">+static inline unsigned int __trace_wbc_assign_cgroup(struct writeback_control *wbc)</span>
 {
<span class="p_del">-	strcpy(buf, &quot;/&quot;);</span>
<span class="p_add">+	return -1U;</span>
 }
 
 #endif	/* CONFIG_CGROUP_WRITEBACK */
<span class="p_chunk">@@ -201,7 +171,7 @@</span> <span class="p_context"> DECLARE_EVENT_CLASS(writeback_write_inode_template,</span>
 		__array(char, name, 32)
 		__field(unsigned long, ino)
 		__field(int, sync_mode)
<span class="p_del">-		__dynamic_array(char, cgroup, __trace_wbc_cgroup_size(wbc))</span>
<span class="p_add">+		__field(unsigned int, cgroup_ino)</span>
 	),
 
 	TP_fast_assign(
<span class="p_chunk">@@ -209,14 +179,14 @@</span> <span class="p_context"> DECLARE_EVENT_CLASS(writeback_write_inode_template,</span>
 			dev_name(inode_to_bdi(inode)-&gt;dev), 32);
 		__entry-&gt;ino		= inode-&gt;i_ino;
 		__entry-&gt;sync_mode	= wbc-&gt;sync_mode;
<span class="p_del">-		__trace_wbc_assign_cgroup(__get_str(cgroup), wbc);</span>
<span class="p_add">+		__entry-&gt;cgroup_ino	= __trace_wbc_assign_cgroup(wbc);</span>
 	),
 
<span class="p_del">-	TP_printk(&quot;bdi %s: ino=%lu sync_mode=%d cgroup=%s&quot;,</span>
<span class="p_add">+	TP_printk(&quot;bdi %s: ino=%lu sync_mode=%d cgroup_ino=%u&quot;,</span>
 		__entry-&gt;name,
 		__entry-&gt;ino,
 		__entry-&gt;sync_mode,
<span class="p_del">-		__get_str(cgroup)</span>
<span class="p_add">+		__entry-&gt;cgroup_ino</span>
 	)
 );
 
<span class="p_chunk">@@ -246,7 +216,7 @@</span> <span class="p_context"> DECLARE_EVENT_CLASS(writeback_work_class,</span>
 		__field(int, range_cyclic)
 		__field(int, for_background)
 		__field(int, reason)
<span class="p_del">-		__dynamic_array(char, cgroup, __trace_wb_cgroup_size(wb))</span>
<span class="p_add">+		__field(unsigned int, cgroup_ino)</span>
 	),
 	TP_fast_assign(
 		strncpy(__entry-&gt;name,
<span class="p_chunk">@@ -258,10 +228,10 @@</span> <span class="p_context"> DECLARE_EVENT_CLASS(writeback_work_class,</span>
 		__entry-&gt;range_cyclic = work-&gt;range_cyclic;
 		__entry-&gt;for_background	= work-&gt;for_background;
 		__entry-&gt;reason = work-&gt;reason;
<span class="p_del">-		__trace_wb_assign_cgroup(__get_str(cgroup), wb);</span>
<span class="p_add">+		__entry-&gt;cgroup_ino = __trace_wb_assign_cgroup(wb);</span>
 	),
 	TP_printk(&quot;bdi %s: sb_dev %d:%d nr_pages=%ld sync_mode=%d &quot;
<span class="p_del">-		  &quot;kupdate=%d range_cyclic=%d background=%d reason=%s cgroup=%s&quot;,</span>
<span class="p_add">+		  &quot;kupdate=%d range_cyclic=%d background=%d reason=%s cgroup_ino=%u&quot;,</span>
 		  __entry-&gt;name,
 		  MAJOR(__entry-&gt;sb_dev), MINOR(__entry-&gt;sb_dev),
 		  __entry-&gt;nr_pages,
<span class="p_chunk">@@ -270,7 +240,7 @@</span> <span class="p_context"> DECLARE_EVENT_CLASS(writeback_work_class,</span>
 		  __entry-&gt;range_cyclic,
 		  __entry-&gt;for_background,
 		  __print_symbolic(__entry-&gt;reason, WB_WORK_REASON),
<span class="p_del">-		  __get_str(cgroup)</span>
<span class="p_add">+		  __entry-&gt;cgroup_ino</span>
 	)
 );
 #define DEFINE_WRITEBACK_WORK_EVENT(name) \
<span class="p_chunk">@@ -300,15 +270,15 @@</span> <span class="p_context"> DECLARE_EVENT_CLASS(writeback_class,</span>
 	TP_ARGS(wb),
 	TP_STRUCT__entry(
 		__array(char, name, 32)
<span class="p_del">-		__dynamic_array(char, cgroup, __trace_wb_cgroup_size(wb))</span>
<span class="p_add">+		__field(unsigned int, cgroup_ino)</span>
 	),
 	TP_fast_assign(
 		strncpy(__entry-&gt;name, dev_name(wb-&gt;bdi-&gt;dev), 32);
<span class="p_del">-		__trace_wb_assign_cgroup(__get_str(cgroup), wb);</span>
<span class="p_add">+		__entry-&gt;cgroup_ino = __trace_wb_assign_cgroup(wb);</span>
 	),
<span class="p_del">-	TP_printk(&quot;bdi %s: cgroup=%s&quot;,</span>
<span class="p_add">+	TP_printk(&quot;bdi %s: cgroup_ino=%u&quot;,</span>
 		  __entry-&gt;name,
<span class="p_del">-		  __get_str(cgroup)</span>
<span class="p_add">+		  __entry-&gt;cgroup_ino</span>
 	)
 );
 #define DEFINE_WRITEBACK_EVENT(name) \
<span class="p_chunk">@@ -347,7 +317,7 @@</span> <span class="p_context"> DECLARE_EVENT_CLASS(wbc_class,</span>
 		__field(int, range_cyclic)
 		__field(long, range_start)
 		__field(long, range_end)
<span class="p_del">-		__dynamic_array(char, cgroup, __trace_wbc_cgroup_size(wbc))</span>
<span class="p_add">+		__field(unsigned int, cgroup_ino)</span>
 	),
 
 	TP_fast_assign(
<span class="p_chunk">@@ -361,12 +331,12 @@</span> <span class="p_context"> DECLARE_EVENT_CLASS(wbc_class,</span>
 		__entry-&gt;range_cyclic	= wbc-&gt;range_cyclic;
 		__entry-&gt;range_start	= (long)wbc-&gt;range_start;
 		__entry-&gt;range_end	= (long)wbc-&gt;range_end;
<span class="p_del">-		__trace_wbc_assign_cgroup(__get_str(cgroup), wbc);</span>
<span class="p_add">+		__entry-&gt;cgroup_ino	= __trace_wbc_assign_cgroup(wbc);</span>
 	),
 
 	TP_printk(&quot;bdi %s: towrt=%ld skip=%ld mode=%d kupd=%d &quot;
 		&quot;bgrd=%d reclm=%d cyclic=%d &quot;
<span class="p_del">-		&quot;start=0x%lx end=0x%lx cgroup=%s&quot;,</span>
<span class="p_add">+		&quot;start=0x%lx end=0x%lx cgroup_ino=%u&quot;,</span>
 		__entry-&gt;name,
 		__entry-&gt;nr_to_write,
 		__entry-&gt;pages_skipped,
<span class="p_chunk">@@ -377,7 +347,7 @@</span> <span class="p_context"> DECLARE_EVENT_CLASS(wbc_class,</span>
 		__entry-&gt;range_cyclic,
 		__entry-&gt;range_start,
 		__entry-&gt;range_end,
<span class="p_del">-		__get_str(cgroup)</span>
<span class="p_add">+		__entry-&gt;cgroup_ino</span>
 	)
 )
 
<span class="p_chunk">@@ -398,7 +368,7 @@</span> <span class="p_context"> TRACE_EVENT(writeback_queue_io,</span>
 		__field(long,		age)
 		__field(int,		moved)
 		__field(int,		reason)
<span class="p_del">-		__dynamic_array(char, cgroup, __trace_wb_cgroup_size(wb))</span>
<span class="p_add">+		__field(unsigned int,	cgroup_ino)</span>
 	),
 	TP_fast_assign(
 		unsigned long *older_than_this = work-&gt;older_than_this;
<span class="p_chunk">@@ -408,15 +378,15 @@</span> <span class="p_context"> TRACE_EVENT(writeback_queue_io,</span>
 				  (jiffies - *older_than_this) * 1000 / HZ : -1;
 		__entry-&gt;moved	= moved;
 		__entry-&gt;reason	= work-&gt;reason;
<span class="p_del">-		__trace_wb_assign_cgroup(__get_str(cgroup), wb);</span>
<span class="p_add">+		__entry-&gt;cgroup_ino	= __trace_wb_assign_cgroup(wb);</span>
 	),
<span class="p_del">-	TP_printk(&quot;bdi %s: older=%lu age=%ld enqueue=%d reason=%s cgroup=%s&quot;,</span>
<span class="p_add">+	TP_printk(&quot;bdi %s: older=%lu age=%ld enqueue=%d reason=%s cgroup_ino=%u&quot;,</span>
 		__entry-&gt;name,
 		__entry-&gt;older,	/* older_than_this in jiffies */
 		__entry-&gt;age,	/* older_than_this in relative milliseconds */
 		__entry-&gt;moved,
 		__print_symbolic(__entry-&gt;reason, WB_WORK_REASON),
<span class="p_del">-		__get_str(cgroup)</span>
<span class="p_add">+		__entry-&gt;cgroup_ino</span>
 	)
 );
 
<span class="p_chunk">@@ -484,7 +454,7 @@</span> <span class="p_context"> TRACE_EVENT(bdi_dirty_ratelimit,</span>
 		__field(unsigned long,	dirty_ratelimit)
 		__field(unsigned long,	task_ratelimit)
 		__field(unsigned long,	balanced_dirty_ratelimit)
<span class="p_del">-		__dynamic_array(char, cgroup, __trace_wb_cgroup_size(wb))</span>
<span class="p_add">+		__field(unsigned int,	cgroup_ino)</span>
 	),
 
 	TP_fast_assign(
<span class="p_chunk">@@ -496,13 +466,13 @@</span> <span class="p_context"> TRACE_EVENT(bdi_dirty_ratelimit,</span>
 		__entry-&gt;task_ratelimit	= KBps(task_ratelimit);
 		__entry-&gt;balanced_dirty_ratelimit =
 					KBps(wb-&gt;balanced_dirty_ratelimit);
<span class="p_del">-		__trace_wb_assign_cgroup(__get_str(cgroup), wb);</span>
<span class="p_add">+		__entry-&gt;cgroup_ino	= __trace_wb_assign_cgroup(wb);</span>
 	),
 
 	TP_printk(&quot;bdi %s: &quot;
 		  &quot;write_bw=%lu awrite_bw=%lu dirty_rate=%lu &quot;
 		  &quot;dirty_ratelimit=%lu task_ratelimit=%lu &quot;
<span class="p_del">-		  &quot;balanced_dirty_ratelimit=%lu cgroup=%s&quot;,</span>
<span class="p_add">+		  &quot;balanced_dirty_ratelimit=%lu cgroup_ino=%u&quot;,</span>
 		  __entry-&gt;bdi,
 		  __entry-&gt;write_bw,		/* write bandwidth */
 		  __entry-&gt;avg_write_bw,	/* avg write bandwidth */
<span class="p_chunk">@@ -510,7 +480,7 @@</span> <span class="p_context"> TRACE_EVENT(bdi_dirty_ratelimit,</span>
 		  __entry-&gt;dirty_ratelimit,	/* base ratelimit */
 		  __entry-&gt;task_ratelimit, /* ratelimit with position control */
 		  __entry-&gt;balanced_dirty_ratelimit, /* the balanced ratelimit */
<span class="p_del">-		  __get_str(cgroup)</span>
<span class="p_add">+		  __entry-&gt;cgroup_ino</span>
 	)
 );
 
<span class="p_chunk">@@ -548,7 +518,7 @@</span> <span class="p_context"> TRACE_EVENT(balance_dirty_pages,</span>
 		__field(	 long,	pause)
 		__field(unsigned long,	period)
 		__field(	 long,	think)
<span class="p_del">-		__dynamic_array(char, cgroup, __trace_wb_cgroup_size(wb))</span>
<span class="p_add">+		__field(unsigned int,	cgroup_ino)</span>
 	),
 
 	TP_fast_assign(
<span class="p_chunk">@@ -571,7 +541,7 @@</span> <span class="p_context"> TRACE_EVENT(balance_dirty_pages,</span>
 		__entry-&gt;period		= period * 1000 / HZ;
 		__entry-&gt;pause		= pause * 1000 / HZ;
 		__entry-&gt;paused		= (jiffies - start_time) * 1000 / HZ;
<span class="p_del">-		__trace_wb_assign_cgroup(__get_str(cgroup), wb);</span>
<span class="p_add">+		__entry-&gt;cgroup_ino	= __trace_wb_assign_cgroup(wb);</span>
 	),
 
 
<span class="p_chunk">@@ -580,7 +550,7 @@</span> <span class="p_context"> TRACE_EVENT(balance_dirty_pages,</span>
 		  &quot;bdi_setpoint=%lu bdi_dirty=%lu &quot;
 		  &quot;dirty_ratelimit=%lu task_ratelimit=%lu &quot;
 		  &quot;dirtied=%u dirtied_pause=%u &quot;
<span class="p_del">-		  &quot;paused=%lu pause=%ld period=%lu think=%ld cgroup=%s&quot;,</span>
<span class="p_add">+		  &quot;paused=%lu pause=%ld period=%lu think=%ld cgroup_ino=%u&quot;,</span>
 		  __entry-&gt;bdi,
 		  __entry-&gt;limit,
 		  __entry-&gt;setpoint,
<span class="p_chunk">@@ -595,7 +565,7 @@</span> <span class="p_context"> TRACE_EVENT(balance_dirty_pages,</span>
 		  __entry-&gt;pause,	/* ms */
 		  __entry-&gt;period,	/* ms */
 		  __entry-&gt;think,	/* ms */
<span class="p_del">-		  __get_str(cgroup)</span>
<span class="p_add">+		  __entry-&gt;cgroup_ino</span>
 	  )
 );
 
<span class="p_chunk">@@ -609,8 +579,7 @@</span> <span class="p_context"> TRACE_EVENT(writeback_sb_inodes_requeue,</span>
 		__field(unsigned long, ino)
 		__field(unsigned long, state)
 		__field(unsigned long, dirtied_when)
<span class="p_del">-		__dynamic_array(char, cgroup,</span>
<span class="p_del">-				__trace_wb_cgroup_size(inode_to_wb(inode)))</span>
<span class="p_add">+		__field(unsigned int, cgroup_ino)</span>
 	),
 
 	TP_fast_assign(
<span class="p_chunk">@@ -619,16 +588,16 @@</span> <span class="p_context"> TRACE_EVENT(writeback_sb_inodes_requeue,</span>
 		__entry-&gt;ino		= inode-&gt;i_ino;
 		__entry-&gt;state		= inode-&gt;i_state;
 		__entry-&gt;dirtied_when	= inode-&gt;dirtied_when;
<span class="p_del">-		__trace_wb_assign_cgroup(__get_str(cgroup), inode_to_wb(inode));</span>
<span class="p_add">+		__entry-&gt;cgroup_ino	= __trace_wb_assign_cgroup(inode_to_wb(inode));</span>
 	),
 
<span class="p_del">-	TP_printk(&quot;bdi %s: ino=%lu state=%s dirtied_when=%lu age=%lu cgroup=%s&quot;,</span>
<span class="p_add">+	TP_printk(&quot;bdi %s: ino=%lu state=%s dirtied_when=%lu age=%lu cgroup_ino=%u&quot;,</span>
 		  __entry-&gt;name,
 		  __entry-&gt;ino,
 		  show_inode_state(__entry-&gt;state),
 		  __entry-&gt;dirtied_when,
 		  (jiffies - __entry-&gt;dirtied_when) / HZ,
<span class="p_del">-		  __get_str(cgroup)</span>
<span class="p_add">+		  __entry-&gt;cgroup_ino</span>
 	)
 );
 
<span class="p_chunk">@@ -684,7 +653,7 @@</span> <span class="p_context"> DECLARE_EVENT_CLASS(writeback_single_inode_template,</span>
 		__field(unsigned long, writeback_index)
 		__field(long, nr_to_write)
 		__field(unsigned long, wrote)
<span class="p_del">-		__dynamic_array(char, cgroup, __trace_wbc_cgroup_size(wbc))</span>
<span class="p_add">+		__field(unsigned int, cgroup_ino)</span>
 	),
 
 	TP_fast_assign(
<span class="p_chunk">@@ -696,11 +665,11 @@</span> <span class="p_context"> DECLARE_EVENT_CLASS(writeback_single_inode_template,</span>
 		__entry-&gt;writeback_index = inode-&gt;i_mapping-&gt;writeback_index;
 		__entry-&gt;nr_to_write	= nr_to_write;
 		__entry-&gt;wrote		= nr_to_write - wbc-&gt;nr_to_write;
<span class="p_del">-		__trace_wbc_assign_cgroup(__get_str(cgroup), wbc);</span>
<span class="p_add">+		__entry-&gt;cgroup_ino	= __trace_wbc_assign_cgroup(wbc);</span>
 	),
 
 	TP_printk(&quot;bdi %s: ino=%lu state=%s dirtied_when=%lu age=%lu &quot;
<span class="p_del">-		  &quot;index=%lu to_write=%ld wrote=%lu cgroup=%s&quot;,</span>
<span class="p_add">+		  &quot;index=%lu to_write=%ld wrote=%lu cgroup_ino=%u&quot;,</span>
 		  __entry-&gt;name,
 		  __entry-&gt;ino,
 		  show_inode_state(__entry-&gt;state),
<span class="p_chunk">@@ -709,7 +678,7 @@</span> <span class="p_context"> DECLARE_EVENT_CLASS(writeback_single_inode_template,</span>
 		  __entry-&gt;writeback_index,
 		  __entry-&gt;nr_to_write,
 		  __entry-&gt;wrote,
<span class="p_del">-		  __get_str(cgroup)</span>
<span class="p_add">+		  __entry-&gt;cgroup_ino</span>
 	)
 );
 
<span class="p_header">diff --git a/kernel/trace/ftrace.c b/kernel/trace/ftrace.c</span>
<span class="p_header">index 57a6eea84694..6a93faafbea4 100644</span>
<span class="p_header">--- a/kernel/trace/ftrace.c</span>
<span class="p_header">+++ b/kernel/trace/ftrace.c</span>
<span class="p_chunk">@@ -1030,8 +1030,7 @@</span> <span class="p_context"> static __init void ftrace_profile_tracefs(struct dentry *d_tracer)</span>
 	for_each_possible_cpu(cpu) {
 		stat = &amp;per_cpu(ftrace_profile_stats, cpu);
 
<span class="p_del">-		/* allocate enough for function name + cpu number */</span>
<span class="p_del">-		name = kmalloc(32, GFP_KERNEL);</span>
<span class="p_add">+		name = kasprintf(GFP_KERNEL, &quot;function%d&quot;, cpu);</span>
 		if (!name) {
 			/*
 			 * The files created are permanent, if something happens
<span class="p_chunk">@@ -1043,7 +1042,6 @@</span> <span class="p_context"> static __init void ftrace_profile_tracefs(struct dentry *d_tracer)</span>
 			return;
 		}
 		stat-&gt;stat = function_stats;
<span class="p_del">-		snprintf(name, 32, &quot;function%d&quot;, cpu);</span>
 		stat-&gt;stat.name = name;
 		ret = register_stat_tracer(&amp;stat-&gt;stat);
 		if (ret) {
<span class="p_chunk">@@ -1610,7 +1608,7 @@</span> <span class="p_context"> static bool test_rec_ops_needs_regs(struct dyn_ftrace *rec)</span>
 	return  keep_regs;
 }
 
<span class="p_del">-static void __ftrace_hash_rec_update(struct ftrace_ops *ops,</span>
<span class="p_add">+static bool __ftrace_hash_rec_update(struct ftrace_ops *ops,</span>
 				     int filter_hash,
 				     bool inc)
 {
<span class="p_chunk">@@ -1618,12 +1616,13 @@</span> <span class="p_context"> static void __ftrace_hash_rec_update(struct ftrace_ops *ops,</span>
 	struct ftrace_hash *other_hash;
 	struct ftrace_page *pg;
 	struct dyn_ftrace *rec;
<span class="p_add">+	bool update = false;</span>
 	int count = 0;
 	int all = 0;
 
 	/* Only update if the ops has been registered */
 	if (!(ops-&gt;flags &amp; FTRACE_OPS_FL_ENABLED))
<span class="p_del">-		return;</span>
<span class="p_add">+		return false;</span>
 
 	/*
 	 * In the filter_hash case:
<span class="p_chunk">@@ -1650,7 +1649,7 @@</span> <span class="p_context"> static void __ftrace_hash_rec_update(struct ftrace_ops *ops,</span>
 		 * then there&#39;s nothing to do.
 		 */
 		if (ftrace_hash_empty(hash))
<span class="p_del">-			return;</span>
<span class="p_add">+			return false;</span>
 	}
 
 	do_for_each_ftrace_rec(pg, rec) {
<span class="p_chunk">@@ -1694,7 +1693,7 @@</span> <span class="p_context"> static void __ftrace_hash_rec_update(struct ftrace_ops *ops,</span>
 		if (inc) {
 			rec-&gt;flags++;
 			if (FTRACE_WARN_ON(ftrace_rec_count(rec) == FTRACE_REF_MAX))
<span class="p_del">-				return;</span>
<span class="p_add">+				return false;</span>
 
 			/*
 			 * If there&#39;s only a single callback registered to a
<span class="p_chunk">@@ -1720,7 +1719,7 @@</span> <span class="p_context"> static void __ftrace_hash_rec_update(struct ftrace_ops *ops,</span>
 				rec-&gt;flags |= FTRACE_FL_REGS;
 		} else {
 			if (FTRACE_WARN_ON(ftrace_rec_count(rec) == 0))
<span class="p_del">-				return;</span>
<span class="p_add">+				return false;</span>
 			rec-&gt;flags--;
 
 			/*
<span class="p_chunk">@@ -1753,22 +1752,28 @@</span> <span class="p_context"> static void __ftrace_hash_rec_update(struct ftrace_ops *ops,</span>
 			 */
 		}
 		count++;
<span class="p_add">+</span>
<span class="p_add">+		/* Must match FTRACE_UPDATE_CALLS in ftrace_modify_all_code() */</span>
<span class="p_add">+		update |= ftrace_test_record(rec, 1) != FTRACE_UPDATE_IGNORE;</span>
<span class="p_add">+</span>
 		/* Shortcut, if we handled all records, we are done. */
 		if (!all &amp;&amp; count == hash-&gt;count)
<span class="p_del">-			return;</span>
<span class="p_add">+			return update;</span>
 	} while_for_each_ftrace_rec();
<span class="p_add">+</span>
<span class="p_add">+	return update;</span>
 }
 
<span class="p_del">-static void ftrace_hash_rec_disable(struct ftrace_ops *ops,</span>
<span class="p_add">+static bool ftrace_hash_rec_disable(struct ftrace_ops *ops,</span>
 				    int filter_hash)
 {
<span class="p_del">-	__ftrace_hash_rec_update(ops, filter_hash, 0);</span>
<span class="p_add">+	return __ftrace_hash_rec_update(ops, filter_hash, 0);</span>
 }
 
<span class="p_del">-static void ftrace_hash_rec_enable(struct ftrace_ops *ops,</span>
<span class="p_add">+static bool ftrace_hash_rec_enable(struct ftrace_ops *ops,</span>
 				   int filter_hash)
 {
<span class="p_del">-	__ftrace_hash_rec_update(ops, filter_hash, 1);</span>
<span class="p_add">+	return __ftrace_hash_rec_update(ops, filter_hash, 1);</span>
 }
 
 static void ftrace_hash_rec_update_modify(struct ftrace_ops *ops,
<span class="p_chunk">@@ -2644,7 +2649,6 @@</span> <span class="p_context"> static int ftrace_startup(struct ftrace_ops *ops, int command)</span>
 		return ret;
 
 	ftrace_start_up++;
<span class="p_del">-	command |= FTRACE_UPDATE_CALLS;</span>
 
 	/*
 	 * Note that ftrace probes uses this to start up
<span class="p_chunk">@@ -2665,7 +2669,8 @@</span> <span class="p_context"> static int ftrace_startup(struct ftrace_ops *ops, int command)</span>
 		return ret;
 	}
 
<span class="p_del">-	ftrace_hash_rec_enable(ops, 1);</span>
<span class="p_add">+	if (ftrace_hash_rec_enable(ops, 1))</span>
<span class="p_add">+		command |= FTRACE_UPDATE_CALLS;</span>
 
 	ftrace_startup_enable(command);
 
<span class="p_chunk">@@ -2695,11 +2700,11 @@</span> <span class="p_context"> static int ftrace_shutdown(struct ftrace_ops *ops, int command)</span>
 
 	/* Disabling ipmodify never fails */
 	ftrace_hash_ipmodify_disable(ops);
<span class="p_del">-	ftrace_hash_rec_disable(ops, 1);</span>
 
<span class="p_del">-	ops-&gt;flags &amp;= ~FTRACE_OPS_FL_ENABLED;</span>
<span class="p_add">+	if (ftrace_hash_rec_disable(ops, 1))</span>
<span class="p_add">+		command |= FTRACE_UPDATE_CALLS;</span>
 
<span class="p_del">-	command |= FTRACE_UPDATE_CALLS;</span>
<span class="p_add">+	ops-&gt;flags &amp;= ~FTRACE_OPS_FL_ENABLED;</span>
 
 	if (saved_ftrace_func != ftrace_trace_function) {
 		saved_ftrace_func = ftrace_trace_function;
<span class="p_header">diff --git a/kernel/trace/trace.c b/kernel/trace/trace.c</span>
<span class="p_header">index d9293402ee68..7bdf8ba323ec 100644</span>
<span class="p_header">--- a/kernel/trace/trace.c</span>
<span class="p_header">+++ b/kernel/trace/trace.c</span>
<span class="p_chunk">@@ -74,11 +74,6 @@</span> <span class="p_context"> static struct tracer_opt dummy_tracer_opt[] = {</span>
 	{ }
 };
 
<span class="p_del">-static struct tracer_flags dummy_tracer_flags = {</span>
<span class="p_del">-	.val = 0,</span>
<span class="p_del">-	.opts = dummy_tracer_opt</span>
<span class="p_del">-};</span>
<span class="p_del">-</span>
 static int
 dummy_set_flag(struct trace_array *tr, u32 old_flags, u32 bit, int set)
 {
<span class="p_chunk">@@ -1258,12 +1253,22 @@</span> <span class="p_context"> int __init register_tracer(struct tracer *type)</span>
 
 	if (!type-&gt;set_flag)
 		type-&gt;set_flag = &amp;dummy_set_flag;
<span class="p_del">-	if (!type-&gt;flags)</span>
<span class="p_del">-		type-&gt;flags = &amp;dummy_tracer_flags;</span>
<span class="p_del">-	else</span>
<span class="p_add">+	if (!type-&gt;flags) {</span>
<span class="p_add">+		/*allocate a dummy tracer_flags*/</span>
<span class="p_add">+		type-&gt;flags = kmalloc(sizeof(*type-&gt;flags), GFP_KERNEL);</span>
<span class="p_add">+		if (!type-&gt;flags) {</span>
<span class="p_add">+			ret = -ENOMEM;</span>
<span class="p_add">+			goto out;</span>
<span class="p_add">+		}</span>
<span class="p_add">+		type-&gt;flags-&gt;val = 0;</span>
<span class="p_add">+		type-&gt;flags-&gt;opts = dummy_tracer_opt;</span>
<span class="p_add">+	} else</span>
 		if (!type-&gt;flags-&gt;opts)
 			type-&gt;flags-&gt;opts = dummy_tracer_opt;
 
<span class="p_add">+	/* store the tracer for __set_tracer_option */</span>
<span class="p_add">+	type-&gt;flags-&gt;trace = type;</span>
<span class="p_add">+</span>
 	ret = run_tracer_selftest(type);
 	if (ret &lt; 0)
 		goto out;
<span class="p_chunk">@@ -1659,6 +1664,7 @@</span> <span class="p_context"> tracing_generic_entry_update(struct trace_entry *entry, unsigned long flags,</span>
 #else
 		TRACE_FLAG_IRQS_NOSUPPORT |
 #endif
<span class="p_add">+		((pc &amp; NMI_MASK    ) ? TRACE_FLAG_NMI     : 0) |</span>
 		((pc &amp; HARDIRQ_MASK) ? TRACE_FLAG_HARDIRQ : 0) |
 		((pc &amp; SOFTIRQ_MASK) ? TRACE_FLAG_SOFTIRQ : 0) |
 		(tif_need_resched() ? TRACE_FLAG_NEED_RESCHED : 0) |
<span class="p_chunk">@@ -3505,7 +3511,7 @@</span> <span class="p_context"> static int __set_tracer_option(struct trace_array *tr,</span>
 			       struct tracer_flags *tracer_flags,
 			       struct tracer_opt *opts, int neg)
 {
<span class="p_del">-	struct tracer *trace = tr-&gt;current_trace;</span>
<span class="p_add">+	struct tracer *trace = tracer_flags-&gt;trace;</span>
 	int ret;
 
 	ret = trace-&gt;set_flag(tr, tracer_flags-&gt;val, opts-&gt;bit, !neg);
<span class="p_chunk">@@ -4949,7 +4955,10 @@</span> <span class="p_context"> static ssize_t tracing_splice_read_pipe(struct file *filp,</span>
 
 	spd.nr_pages = i;
 
<span class="p_del">-	ret = splice_to_pipe(pipe, &amp;spd);</span>
<span class="p_add">+	if (i)</span>
<span class="p_add">+		ret = splice_to_pipe(pipe, &amp;spd);</span>
<span class="p_add">+	else</span>
<span class="p_add">+		ret = 0;</span>
 out:
 	splice_shrink_spd(&amp;spd);
 	return ret;
<span class="p_chunk">@@ -6391,11 +6400,8 @@</span> <span class="p_context"> create_trace_option_files(struct trace_array *tr, struct tracer *tracer)</span>
 		return;
 
 	for (i = 0; i &lt; tr-&gt;nr_topts; i++) {
<span class="p_del">-		/*</span>
<span class="p_del">-		 * Check if these flags have already been added.</span>
<span class="p_del">-		 * Some tracers share flags.</span>
<span class="p_del">-		 */</span>
<span class="p_del">-		if (tr-&gt;topts[i].tracer-&gt;flags == tracer-&gt;flags)</span>
<span class="p_add">+		/* Make sure there&#39;s no duplicate flags. */</span>
<span class="p_add">+		if (WARN_ON_ONCE(tr-&gt;topts[i].tracer-&gt;flags == tracer-&gt;flags))</span>
 			return;
 	}
 
<span class="p_header">diff --git a/kernel/trace/trace.h b/kernel/trace/trace.h</span>
<span class="p_header">index 8414fa40bf27..3fff4adfd431 100644</span>
<span class="p_header">--- a/kernel/trace/trace.h</span>
<span class="p_header">+++ b/kernel/trace/trace.h</span>
<span class="p_chunk">@@ -125,6 +125,7 @@</span> <span class="p_context"> enum trace_flag_type {</span>
 	TRACE_FLAG_HARDIRQ		= 0x08,
 	TRACE_FLAG_SOFTIRQ		= 0x10,
 	TRACE_FLAG_PREEMPT_RESCHED	= 0x20,
<span class="p_add">+	TRACE_FLAG_NMI			= 0x40,</span>
 };
 
 #define TRACE_BUF_SIZE		1024
<span class="p_chunk">@@ -345,6 +346,7 @@</span> <span class="p_context"> struct tracer_opt {</span>
 struct tracer_flags {
 	u32			val;
 	struct tracer_opt	*opts;
<span class="p_add">+	struct tracer		*trace;</span>
 };
 
 /* Makes more easy to define a tracer opt */
<span class="p_chunk">@@ -1111,6 +1113,18 @@</span> <span class="p_context"> struct filter_pred {</span>
 	unsigned short		right;
 };
 
<span class="p_add">+static inline bool is_string_field(struct ftrace_event_field *field)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return field-&gt;filter_type == FILTER_DYN_STRING ||</span>
<span class="p_add">+	       field-&gt;filter_type == FILTER_STATIC_STRING ||</span>
<span class="p_add">+	       field-&gt;filter_type == FILTER_PTR_STRING;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline bool is_function_field(struct ftrace_event_field *field)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return field-&gt;filter_type == FILTER_TRACE_FN;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 extern enum regex_type
 filter_parse_regex(char *buff, int len, char **search, int *not);
 extern void print_event_filter(struct trace_event_file *file,
<span class="p_chunk">@@ -1159,9 +1173,24 @@</span> <span class="p_context"> struct event_trigger_data {</span>
 	struct event_filter __rcu	*filter;
 	char				*filter_str;
 	void				*private_data;
<span class="p_add">+	bool				paused;</span>
 	struct list_head		list;
 };
 
<span class="p_add">+extern void trigger_data_free(struct event_trigger_data *data);</span>
<span class="p_add">+extern int event_trigger_init(struct event_trigger_ops *ops,</span>
<span class="p_add">+			      struct event_trigger_data *data);</span>
<span class="p_add">+extern int trace_event_trigger_enable_disable(struct trace_event_file *file,</span>
<span class="p_add">+					      int trigger_enable);</span>
<span class="p_add">+extern void update_cond_flag(struct trace_event_file *file);</span>
<span class="p_add">+extern void unregister_trigger(char *glob, struct event_trigger_ops *ops,</span>
<span class="p_add">+			       struct event_trigger_data *test,</span>
<span class="p_add">+			       struct trace_event_file *file);</span>
<span class="p_add">+extern int set_trigger_filter(char *filter_str,</span>
<span class="p_add">+			      struct event_trigger_data *trigger_data,</span>
<span class="p_add">+			      struct trace_event_file *file);</span>
<span class="p_add">+extern int register_event_command(struct event_command *cmd);</span>
<span class="p_add">+</span>
 /**
  * struct event_trigger_ops - callbacks for trace event triggers
  *
<span class="p_chunk">@@ -1174,7 +1203,8 @@</span> <span class="p_context"> struct event_trigger_data {</span>
  * @func: The trigger &#39;probe&#39; function called when the triggering
  *	event occurs.  The data passed into this callback is the data
  *	that was supplied to the event_command @reg() function that
<span class="p_del">- *	registered the trigger (see struct event_command).</span>
<span class="p_add">+ *	registered the trigger (see struct event_command) along with</span>
<span class="p_add">+ *	the trace record, rec.</span>
  *
  * @init: An optional initialization function called for the trigger
  *	when the trigger is registered (via the event_command reg()
<span class="p_chunk">@@ -1199,7 +1229,8 @@</span> <span class="p_context"> struct event_trigger_data {</span>
  *	(see trace_event_triggers.c).
  */
 struct event_trigger_ops {
<span class="p_del">-	void			(*func)(struct event_trigger_data *data);</span>
<span class="p_add">+	void			(*func)(struct event_trigger_data *data,</span>
<span class="p_add">+					void *rec);</span>
 	int			(*init)(struct event_trigger_ops *ops,
 					struct event_trigger_data *data);
 	void			(*free)(struct event_trigger_ops *ops,
<span class="p_chunk">@@ -1243,27 +1274,10 @@</span> <span class="p_context"> struct event_trigger_ops {</span>
  *	values are defined by adding new values to the trigger_type
  *	enum in include/linux/trace_events.h.
  *
<span class="p_del">- * @post_trigger: A flag that says whether or not this command needs</span>
<span class="p_del">- *	to have its action delayed until after the current event has</span>
<span class="p_del">- *	been closed.  Some triggers need to avoid being invoked while</span>
<span class="p_del">- *	an event is currently in the process of being logged, since</span>
<span class="p_del">- *	the trigger may itself log data into the trace buffer.  Thus</span>
<span class="p_del">- *	we make sure the current event is committed before invoking</span>
<span class="p_del">- *	those triggers.  To do that, the trigger invocation is split</span>
<span class="p_del">- *	in two - the first part checks the filter using the current</span>
<span class="p_del">- *	trace record; if a command has the @post_trigger flag set, it</span>
<span class="p_del">- *	sets a bit for itself in the return value, otherwise it</span>
<span class="p_del">- *	directly invokes the trigger.  Once all commands have been</span>
<span class="p_del">- *	either invoked or set their return flag, the current record is</span>
<span class="p_del">- *	either committed or discarded.  At that point, if any commands</span>
<span class="p_del">- *	have deferred their triggers, those commands are finally</span>
<span class="p_del">- *	invoked following the close of the current event.  In other</span>
<span class="p_del">- *	words, if the event_trigger_ops @func() probe implementation</span>
<span class="p_del">- *	itself logs to the trace buffer, this flag should be set,</span>
<span class="p_del">- *	otherwise it can be left unspecified.</span>
<span class="p_add">+ * @flags: See the enum event_command_flags below.</span>
  *
<span class="p_del">- * All the methods below, except for @set_filter(), must be</span>
<span class="p_del">- * implemented.</span>
<span class="p_add">+ * All the methods below, except for @set_filter() and @unreg_all(),</span>
<span class="p_add">+ * must be implemented.</span>
  *
  * @func: The callback function responsible for parsing and
  *	registering the trigger written to the &#39;trigger&#39; file by the
<span class="p_chunk">@@ -1288,6 +1302,10 @@</span> <span class="p_context"> struct event_trigger_ops {</span>
  *	This is usually implemented by the generic utility function
  *	@unregister_trigger() (see trace_event_triggers.c).
  *
<span class="p_add">+ * @unreg_all: An optional function called to remove all the triggers</span>
<span class="p_add">+ *	from the list of triggers associated with the event.  Called</span>
<span class="p_add">+ *	when a trigger file is opened in truncate mode.</span>
<span class="p_add">+ *</span>
  * @set_filter: An optional function called to parse and set a filter
  *	for the trigger.  If no @set_filter() method is set for the
  *	event command, filters set by the user for the command will be
<span class="p_chunk">@@ -1301,7 +1319,7 @@</span> <span class="p_context"> struct event_command {</span>
 	struct list_head	list;
 	char			*name;
 	enum event_trigger_type	trigger_type;
<span class="p_del">-	bool			post_trigger;</span>
<span class="p_add">+	int			flags;</span>
 	int			(*func)(struct event_command *cmd_ops,
 					struct trace_event_file *file,
 					char *glob, char *cmd, char *params);
<span class="p_chunk">@@ -1313,12 +1331,56 @@</span> <span class="p_context"> struct event_command {</span>
 					 struct event_trigger_ops *ops,
 					 struct event_trigger_data *data,
 					 struct trace_event_file *file);
<span class="p_add">+	void			(*unreg_all)(struct trace_event_file *file);</span>
 	int			(*set_filter)(char *filter_str,
 					      struct event_trigger_data *data,
 					      struct trace_event_file *file);
 	struct event_trigger_ops *(*get_trigger_ops)(char *cmd, char *param);
 };
 
<span class="p_add">+/**</span>
<span class="p_add">+ * enum event_command_flags - flags for struct event_command</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * @POST_TRIGGER: A flag that says whether or not this command needs</span>
<span class="p_add">+ *	to have its action delayed until after the current event has</span>
<span class="p_add">+ *	been closed.  Some triggers need to avoid being invoked while</span>
<span class="p_add">+ *	an event is currently in the process of being logged, since</span>
<span class="p_add">+ *	the trigger may itself log data into the trace buffer.  Thus</span>
<span class="p_add">+ *	we make sure the current event is committed before invoking</span>
<span class="p_add">+ *	those triggers.  To do that, the trigger invocation is split</span>
<span class="p_add">+ *	in two - the first part checks the filter using the current</span>
<span class="p_add">+ *	trace record; if a command has the @post_trigger flag set, it</span>
<span class="p_add">+ *	sets a bit for itself in the return value, otherwise it</span>
<span class="p_add">+ *	directly invokes the trigger.  Once all commands have been</span>
<span class="p_add">+ *	either invoked or set their return flag, the current record is</span>
<span class="p_add">+ *	either committed or discarded.  At that point, if any commands</span>
<span class="p_add">+ *	have deferred their triggers, those commands are finally</span>
<span class="p_add">+ *	invoked following the close of the current event.  In other</span>
<span class="p_add">+ *	words, if the event_trigger_ops @func() probe implementation</span>
<span class="p_add">+ *	itself logs to the trace buffer, this flag should be set,</span>
<span class="p_add">+ *	otherwise it can be left unspecified.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * @NEEDS_REC: A flag that says whether or not this command needs</span>
<span class="p_add">+ *	access to the trace record in order to perform its function,</span>
<span class="p_add">+ *	regardless of whether or not it has a filter associated with</span>
<span class="p_add">+ *	it (filters make a trigger require access to the trace record</span>
<span class="p_add">+ *	but are not always present).</span>
<span class="p_add">+ */</span>
<span class="p_add">+enum event_command_flags {</span>
<span class="p_add">+	EVENT_CMD_FL_POST_TRIGGER	= 1,</span>
<span class="p_add">+	EVENT_CMD_FL_NEEDS_REC		= 2,</span>
<span class="p_add">+};</span>
<span class="p_add">+</span>
<span class="p_add">+static inline bool event_command_post_trigger(struct event_command *cmd_ops)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return cmd_ops-&gt;flags &amp; EVENT_CMD_FL_POST_TRIGGER;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline bool event_command_needs_rec(struct event_command *cmd_ops)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return cmd_ops-&gt;flags &amp; EVENT_CMD_FL_NEEDS_REC;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 extern int trace_event_enable_disable(struct trace_event_file *file,
 				      int enable, int soft_disable);
 extern int tracing_alloc_snapshot(void);
<span class="p_chunk">@@ -1365,8 +1427,13 @@</span> <span class="p_context"> int perf_ftrace_event_register(struct trace_event_call *call,</span>
 
 #ifdef CONFIG_FTRACE_SYSCALLS
 void init_ftrace_syscalls(void);
<span class="p_add">+const char *get_syscall_name(int syscall);</span>
 #else
 static inline void init_ftrace_syscalls(void) { }
<span class="p_add">+static inline const char *get_syscall_name(int syscall)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return NULL;</span>
<span class="p_add">+}</span>
 #endif
 
 #ifdef CONFIG_EVENT_TRACING
<span class="p_header">diff --git a/kernel/trace/trace_events_filter.c b/kernel/trace/trace_events_filter.c</span>
<span class="p_header">index 6816302542b2..b3f5051cd4e9 100644</span>
<span class="p_header">--- a/kernel/trace/trace_events_filter.c</span>
<span class="p_header">+++ b/kernel/trace/trace_events_filter.c</span>
<span class="p_chunk">@@ -961,18 +961,6 @@</span> <span class="p_context"> int filter_assign_type(const char *type)</span>
 	return FILTER_OTHER;
 }
 
<span class="p_del">-static bool is_function_field(struct ftrace_event_field *field)</span>
<span class="p_del">-{</span>
<span class="p_del">-	return field-&gt;filter_type == FILTER_TRACE_FN;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static bool is_string_field(struct ftrace_event_field *field)</span>
<span class="p_del">-{</span>
<span class="p_del">-	return field-&gt;filter_type == FILTER_DYN_STRING ||</span>
<span class="p_del">-	       field-&gt;filter_type == FILTER_STATIC_STRING ||</span>
<span class="p_del">-	       field-&gt;filter_type == FILTER_PTR_STRING;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
 static bool is_legal_op(struct ftrace_event_field *field, int op)
 {
 	if (is_string_field(field) &amp;&amp;
<span class="p_header">diff --git a/kernel/trace/trace_events_trigger.c b/kernel/trace/trace_events_trigger.c</span>
<span class="p_header">index b38f617b6181..d67992f3bb0e 100644</span>
<span class="p_header">--- a/kernel/trace/trace_events_trigger.c</span>
<span class="p_header">+++ b/kernel/trace/trace_events_trigger.c</span>
<span class="p_chunk">@@ -28,8 +28,7 @@</span> <span class="p_context"></span>
 static LIST_HEAD(trigger_commands);
 static DEFINE_MUTEX(trigger_cmd_mutex);
 
<span class="p_del">-static void</span>
<span class="p_del">-trigger_data_free(struct event_trigger_data *data)</span>
<span class="p_add">+void trigger_data_free(struct event_trigger_data *data)</span>
 {
 	if (data-&gt;cmd_ops-&gt;set_filter)
 		data-&gt;cmd_ops-&gt;set_filter(NULL, data, NULL);
<span class="p_chunk">@@ -73,18 +72,20 @@</span> <span class="p_context"> event_triggers_call(struct trace_event_file *file, void *rec)</span>
 		return tt;
 
 	list_for_each_entry_rcu(data, &amp;file-&gt;triggers, list) {
<span class="p_add">+		if (data-&gt;paused)</span>
<span class="p_add">+			continue;</span>
 		if (!rec) {
<span class="p_del">-			data-&gt;ops-&gt;func(data);</span>
<span class="p_add">+			data-&gt;ops-&gt;func(data, rec);</span>
 			continue;
 		}
 		filter = rcu_dereference_sched(data-&gt;filter);
 		if (filter &amp;&amp; !filter_match_preds(filter, rec))
 			continue;
<span class="p_del">-		if (data-&gt;cmd_ops-&gt;post_trigger) {</span>
<span class="p_add">+		if (event_command_post_trigger(data-&gt;cmd_ops)) {</span>
 			tt |= data-&gt;cmd_ops-&gt;trigger_type;
 			continue;
 		}
<span class="p_del">-		data-&gt;ops-&gt;func(data);</span>
<span class="p_add">+		data-&gt;ops-&gt;func(data, rec);</span>
 	}
 	return tt;
 }
<span class="p_chunk">@@ -94,6 +95,7 @@</span> <span class="p_context"> EXPORT_SYMBOL_GPL(event_triggers_call);</span>
  * event_triggers_post_call - Call &#39;post_triggers&#39; for a trace event
  * @file: The trace_event_file associated with the event
  * @tt: enum event_trigger_type containing a set bit for each trigger to invoke
<span class="p_add">+ * @rec: The trace entry for the event</span>
  *
  * For each trigger associated with an event, invoke the trigger
  * function registered with the associated trigger command, if the
<span class="p_chunk">@@ -104,13 +106,16 @@</span> <span class="p_context"> EXPORT_SYMBOL_GPL(event_triggers_call);</span>
  */
 void
 event_triggers_post_call(struct trace_event_file *file,
<span class="p_del">-			 enum event_trigger_type tt)</span>
<span class="p_add">+			 enum event_trigger_type tt,</span>
<span class="p_add">+			 void *rec)</span>
 {
 	struct event_trigger_data *data;
 
 	list_for_each_entry_rcu(data, &amp;file-&gt;triggers, list) {
<span class="p_add">+		if (data-&gt;paused)</span>
<span class="p_add">+			continue;</span>
 		if (data-&gt;cmd_ops-&gt;trigger_type &amp; tt)
<span class="p_del">-			data-&gt;ops-&gt;func(data);</span>
<span class="p_add">+			data-&gt;ops-&gt;func(data, rec);</span>
 	}
 }
 EXPORT_SYMBOL_GPL(event_triggers_post_call);
<span class="p_chunk">@@ -188,6 +193,19 @@</span> <span class="p_context"> static int event_trigger_regex_open(struct inode *inode, struct file *file)</span>
 		return -ENODEV;
 	}
 
<span class="p_add">+	if ((file-&gt;f_mode &amp; FMODE_WRITE) &amp;&amp;</span>
<span class="p_add">+	    (file-&gt;f_flags &amp; O_TRUNC)) {</span>
<span class="p_add">+		struct trace_event_file *event_file;</span>
<span class="p_add">+		struct event_command *p;</span>
<span class="p_add">+</span>
<span class="p_add">+		event_file = event_file_data(file);</span>
<span class="p_add">+</span>
<span class="p_add">+		list_for_each_entry(p, &amp;trigger_commands, list) {</span>
<span class="p_add">+			if (p-&gt;unreg_all)</span>
<span class="p_add">+				p-&gt;unreg_all(event_file);</span>
<span class="p_add">+		}</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
 	if (file-&gt;f_mode &amp; FMODE_READ) {
 		ret = seq_open(file, &amp;event_triggers_seq_ops);
 		if (!ret) {
<span class="p_chunk">@@ -306,7 +324,7 @@</span> <span class="p_context"> const struct file_operations event_trigger_fops = {</span>
  * Currently we only register event commands from __init, so mark this
  * __init too.
  */
<span class="p_del">-static __init int register_event_command(struct event_command *cmd)</span>
<span class="p_add">+__init int register_event_command(struct event_command *cmd)</span>
 {
 	struct event_command *p;
 	int ret = 0;
<span class="p_chunk">@@ -395,9 +413,8 @@</span> <span class="p_context"> event_trigger_print(const char *name, struct seq_file *m,</span>
  *
  * Return: 0 on success, errno otherwise
  */
<span class="p_del">-static int</span>
<span class="p_del">-event_trigger_init(struct event_trigger_ops *ops,</span>
<span class="p_del">-		   struct event_trigger_data *data)</span>
<span class="p_add">+int event_trigger_init(struct event_trigger_ops *ops,</span>
<span class="p_add">+		       struct event_trigger_data *data)</span>
 {
 	data-&gt;ref++;
 	return 0;
<span class="p_chunk">@@ -425,8 +442,8 @@</span> <span class="p_context"> event_trigger_free(struct event_trigger_ops *ops,</span>
 		trigger_data_free(data);
 }
 
<span class="p_del">-static int trace_event_trigger_enable_disable(struct trace_event_file *file,</span>
<span class="p_del">-					      int trigger_enable)</span>
<span class="p_add">+int trace_event_trigger_enable_disable(struct trace_event_file *file,</span>
<span class="p_add">+				       int trigger_enable)</span>
 {
 	int ret = 0;
 
<span class="p_chunk">@@ -483,13 +500,14 @@</span> <span class="p_context"> clear_event_triggers(struct trace_array *tr)</span>
  * its TRIGGER_COND bit set, otherwise the TRIGGER_COND bit should be
  * cleared.
  */
<span class="p_del">-static void update_cond_flag(struct trace_event_file *file)</span>
<span class="p_add">+void update_cond_flag(struct trace_event_file *file)</span>
 {
 	struct event_trigger_data *data;
 	bool set_cond = false;
 
 	list_for_each_entry_rcu(data, &amp;file-&gt;triggers, list) {
<span class="p_del">-		if (data-&gt;filter || data-&gt;cmd_ops-&gt;post_trigger) {</span>
<span class="p_add">+		if (data-&gt;filter || event_command_post_trigger(data-&gt;cmd_ops) ||</span>
<span class="p_add">+		    event_command_needs_rec(data-&gt;cmd_ops)) {</span>
 			set_cond = true;
 			break;
 		}
<span class="p_chunk">@@ -560,9 +578,9 @@</span> <span class="p_context"> out:</span>
  * Usually used directly as the @unreg method in event command
  * implementations.
  */
<span class="p_del">-static void unregister_trigger(char *glob, struct event_trigger_ops *ops,</span>
<span class="p_del">-			       struct event_trigger_data *test,</span>
<span class="p_del">-			       struct trace_event_file *file)</span>
<span class="p_add">+void unregister_trigger(char *glob, struct event_trigger_ops *ops,</span>
<span class="p_add">+			struct event_trigger_data *test,</span>
<span class="p_add">+			struct trace_event_file *file)</span>
 {
 	struct event_trigger_data *data;
 	bool unregistered = false;
<span class="p_chunk">@@ -696,9 +714,9 @@</span> <span class="p_context"> event_trigger_callback(struct event_command *cmd_ops,</span>
  *
  * Return: 0 on success, errno otherwise
  */
<span class="p_del">-static int set_trigger_filter(char *filter_str,</span>
<span class="p_del">-			      struct event_trigger_data *trigger_data,</span>
<span class="p_del">-			      struct trace_event_file *file)</span>
<span class="p_add">+int set_trigger_filter(char *filter_str,</span>
<span class="p_add">+		       struct event_trigger_data *trigger_data,</span>
<span class="p_add">+		       struct trace_event_file *file)</span>
 {
 	struct event_trigger_data *data = trigger_data;
 	struct event_filter *filter = NULL, *tmp;
<span class="p_chunk">@@ -747,7 +765,7 @@</span> <span class="p_context"> static int set_trigger_filter(char *filter_str,</span>
 }
 
 static void
<span class="p_del">-traceon_trigger(struct event_trigger_data *data)</span>
<span class="p_add">+traceon_trigger(struct event_trigger_data *data, void *rec)</span>
 {
 	if (tracing_is_on())
 		return;
<span class="p_chunk">@@ -756,7 +774,7 @@</span> <span class="p_context"> traceon_trigger(struct event_trigger_data *data)</span>
 }
 
 static void
<span class="p_del">-traceon_count_trigger(struct event_trigger_data *data)</span>
<span class="p_add">+traceon_count_trigger(struct event_trigger_data *data, void *rec)</span>
 {
 	if (tracing_is_on())
 		return;
<span class="p_chunk">@@ -771,7 +789,7 @@</span> <span class="p_context"> traceon_count_trigger(struct event_trigger_data *data)</span>
 }
 
 static void
<span class="p_del">-traceoff_trigger(struct event_trigger_data *data)</span>
<span class="p_add">+traceoff_trigger(struct event_trigger_data *data, void *rec)</span>
 {
 	if (!tracing_is_on())
 		return;
<span class="p_chunk">@@ -780,7 +798,7 @@</span> <span class="p_context"> traceoff_trigger(struct event_trigger_data *data)</span>
 }
 
 static void
<span class="p_del">-traceoff_count_trigger(struct event_trigger_data *data)</span>
<span class="p_add">+traceoff_count_trigger(struct event_trigger_data *data, void *rec)</span>
 {
 	if (!tracing_is_on())
 		return;
<span class="p_chunk">@@ -876,13 +894,13 @@</span> <span class="p_context"> static struct event_command trigger_traceoff_cmd = {</span>
 
 #ifdef CONFIG_TRACER_SNAPSHOT
 static void
<span class="p_del">-snapshot_trigger(struct event_trigger_data *data)</span>
<span class="p_add">+snapshot_trigger(struct event_trigger_data *data, void *rec)</span>
 {
 	tracing_snapshot();
 }
 
 static void
<span class="p_del">-snapshot_count_trigger(struct event_trigger_data *data)</span>
<span class="p_add">+snapshot_count_trigger(struct event_trigger_data *data, void *rec)</span>
 {
 	if (!data-&gt;count)
 		return;
<span class="p_chunk">@@ -890,7 +908,7 @@</span> <span class="p_context"> snapshot_count_trigger(struct event_trigger_data *data)</span>
 	if (data-&gt;count != -1)
 		(data-&gt;count)--;
 
<span class="p_del">-	snapshot_trigger(data);</span>
<span class="p_add">+	snapshot_trigger(data, rec);</span>
 }
 
 static int
<span class="p_chunk">@@ -969,13 +987,13 @@</span> <span class="p_context"> static __init int register_trigger_snapshot_cmd(void) { return 0; }</span>
 #define STACK_SKIP 3
 
 static void
<span class="p_del">-stacktrace_trigger(struct event_trigger_data *data)</span>
<span class="p_add">+stacktrace_trigger(struct event_trigger_data *data, void *rec)</span>
 {
 	trace_dump_stack(STACK_SKIP);
 }
 
 static void
<span class="p_del">-stacktrace_count_trigger(struct event_trigger_data *data)</span>
<span class="p_add">+stacktrace_count_trigger(struct event_trigger_data *data, void *rec)</span>
 {
 	if (!data-&gt;count)
 		return;
<span class="p_chunk">@@ -983,7 +1001,7 @@</span> <span class="p_context"> stacktrace_count_trigger(struct event_trigger_data *data)</span>
 	if (data-&gt;count != -1)
 		(data-&gt;count)--;
 
<span class="p_del">-	stacktrace_trigger(data);</span>
<span class="p_add">+	stacktrace_trigger(data, rec);</span>
 }
 
 static int
<span class="p_chunk">@@ -1017,7 +1035,7 @@</span> <span class="p_context"> stacktrace_get_trigger_ops(char *cmd, char *param)</span>
 static struct event_command trigger_stacktrace_cmd = {
 	.name			= &quot;stacktrace&quot;,
 	.trigger_type		= ETT_STACKTRACE,
<span class="p_del">-	.post_trigger		= true,</span>
<span class="p_add">+	.flags			= EVENT_CMD_FL_POST_TRIGGER,</span>
 	.func			= event_trigger_callback,
 	.reg			= register_trigger,
 	.unreg			= unregister_trigger,
<span class="p_chunk">@@ -1054,7 +1072,7 @@</span> <span class="p_context"> struct enable_trigger_data {</span>
 };
 
 static void
<span class="p_del">-event_enable_trigger(struct event_trigger_data *data)</span>
<span class="p_add">+event_enable_trigger(struct event_trigger_data *data, void *rec)</span>
 {
 	struct enable_trigger_data *enable_data = data-&gt;private_data;
 
<span class="p_chunk">@@ -1065,7 +1083,7 @@</span> <span class="p_context"> event_enable_trigger(struct event_trigger_data *data)</span>
 }
 
 static void
<span class="p_del">-event_enable_count_trigger(struct event_trigger_data *data)</span>
<span class="p_add">+event_enable_count_trigger(struct event_trigger_data *data, void *rec)</span>
 {
 	struct enable_trigger_data *enable_data = data-&gt;private_data;
 
<span class="p_chunk">@@ -1079,7 +1097,7 @@</span> <span class="p_context"> event_enable_count_trigger(struct event_trigger_data *data)</span>
 	if (data-&gt;count != -1)
 		(data-&gt;count)--;
 
<span class="p_del">-	event_enable_trigger(data);</span>
<span class="p_add">+	event_enable_trigger(data, rec);</span>
 }
 
 static int
<span class="p_header">diff --git a/kernel/trace/trace_functions.c b/kernel/trace/trace_functions.c</span>
<span class="p_header">index fcd41a166405..5a095c2e4b69 100644</span>
<span class="p_header">--- a/kernel/trace/trace_functions.c</span>
<span class="p_header">+++ b/kernel/trace/trace_functions.c</span>
<span class="p_chunk">@@ -219,6 +219,8 @@</span> <span class="p_context"> static void tracing_stop_function_trace(struct trace_array *tr)</span>
 	unregister_ftrace_function(tr-&gt;ops);
 }
 
<span class="p_add">+static struct tracer function_trace;</span>
<span class="p_add">+</span>
 static int
 func_set_flag(struct trace_array *tr, u32 old_flags, u32 bit, int set)
 {
<span class="p_chunk">@@ -228,6 +230,10 @@</span> <span class="p_context"> func_set_flag(struct trace_array *tr, u32 old_flags, u32 bit, int set)</span>
 		if (!!set == !!(func_flags.val &amp; TRACE_FUNC_OPT_STACK))
 			break;
 
<span class="p_add">+		/* We can change this flag when not running. */</span>
<span class="p_add">+		if (tr-&gt;current_trace != &amp;function_trace)</span>
<span class="p_add">+			break;</span>
<span class="p_add">+</span>
 		unregister_ftrace_function(tr-&gt;ops);
 
 		if (set) {
<span class="p_header">diff --git a/kernel/trace/trace_irqsoff.c b/kernel/trace/trace_irqsoff.c</span>
<span class="p_header">index e4e56589ec1d..03cdff84d026 100644</span>
<span class="p_header">--- a/kernel/trace/trace_irqsoff.c</span>
<span class="p_header">+++ b/kernel/trace/trace_irqsoff.c</span>
<span class="p_chunk">@@ -109,8 +109,12 @@</span> <span class="p_context"> static int func_prolog_dec(struct trace_array *tr,</span>
 		return 0;
 
 	local_save_flags(*flags);
<span class="p_del">-	/* slight chance to get a false positive on tracing_cpu */</span>
<span class="p_del">-	if (!irqs_disabled_flags(*flags))</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Slight chance to get a false positive on tracing_cpu,</span>
<span class="p_add">+	 * although I&#39;m starting to think there isn&#39;t a chance.</span>
<span class="p_add">+	 * Leave this for now just to be paranoid.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	if (!irqs_disabled_flags(*flags) &amp;&amp; !preempt_count())</span>
 		return 0;
 
 	*data = per_cpu_ptr(tr-&gt;trace_buffer.data, cpu);
<span class="p_chunk">@@ -622,7 +626,6 @@</span> <span class="p_context"> static int __irqsoff_tracer_init(struct trace_array *tr)</span>
 	irqsoff_trace = tr;
 	/* make sure that the tracer is visible */
 	smp_wmb();
<span class="p_del">-	tracing_reset_online_cpus(&amp;tr-&gt;trace_buffer);</span>
 
 	ftrace_init_array_ops(tr, irqsoff_tracer_call);
 
<span class="p_header">diff --git a/kernel/trace/trace_nop.c b/kernel/trace/trace_nop.c</span>
<span class="p_header">index 8bb2071474dd..49f61fe96a6b 100644</span>
<span class="p_header">--- a/kernel/trace/trace_nop.c</span>
<span class="p_header">+++ b/kernel/trace/trace_nop.c</span>
<span class="p_chunk">@@ -56,7 +56,7 @@</span> <span class="p_context"> static void nop_trace_reset(struct trace_array *tr)</span>
 }
 
 /* It only serves as a signal handler and a callback to
<span class="p_del">- * accept or refuse tthe setting of a flag.</span>
<span class="p_add">+ * accept or refuse the setting of a flag.</span>
  * If you don&#39;t implement it, then the flag setting will be
  * automatically accepted.
  */
<span class="p_chunk">@@ -75,7 +75,7 @@</span> <span class="p_context"> static int nop_set_flag(struct trace_array *tr, u32 old_flags, u32 bit, int set)</span>
 
 	if (bit == TRACE_NOP_OPT_REFUSE) {
 		printk(KERN_DEBUG &quot;nop_test_refuse flag set to %d: we refuse.&quot;
<span class="p_del">-			&quot;Now cat trace_options to see the result\n&quot;,</span>
<span class="p_add">+			&quot; Now cat trace_options to see the result\n&quot;,</span>
 			set);
 		return -EINVAL;
 	}
<span class="p_header">diff --git a/kernel/trace/trace_output.c b/kernel/trace/trace_output.c</span>
<span class="p_header">index 282982195e09..0bb9cf2d53e6 100644</span>
<span class="p_header">--- a/kernel/trace/trace_output.c</span>
<span class="p_header">+++ b/kernel/trace/trace_output.c</span>
<span class="p_chunk">@@ -389,7 +389,9 @@</span> <span class="p_context"> int trace_print_lat_fmt(struct trace_seq *s, struct trace_entry *entry)</span>
 	char irqs_off;
 	int hardirq;
 	int softirq;
<span class="p_add">+	int nmi;</span>
 
<span class="p_add">+	nmi = entry-&gt;flags &amp; TRACE_FLAG_NMI;</span>
 	hardirq = entry-&gt;flags &amp; TRACE_FLAG_HARDIRQ;
 	softirq = entry-&gt;flags &amp; TRACE_FLAG_SOFTIRQ;
 
<span class="p_chunk">@@ -415,10 +417,12 @@</span> <span class="p_context"> int trace_print_lat_fmt(struct trace_seq *s, struct trace_entry *entry)</span>
 	}
 
 	hardsoft_irq =
<span class="p_add">+		(nmi &amp;&amp; hardirq)     ? &#39;Z&#39; :</span>
<span class="p_add">+		nmi                  ? &#39;z&#39; :</span>
 		(hardirq &amp;&amp; softirq) ? &#39;H&#39; :
<span class="p_del">-		hardirq ? &#39;h&#39; :</span>
<span class="p_del">-		softirq ? &#39;s&#39; :</span>
<span class="p_del">-		&#39;.&#39;;</span>
<span class="p_add">+		hardirq              ? &#39;h&#39; :</span>
<span class="p_add">+		softirq              ? &#39;s&#39; :</span>
<span class="p_add">+		                       &#39;.&#39; ;</span>
 
 	trace_seq_printf(s, &quot;%c%c%c&quot;,
 			 irqs_off, need_resched, hardsoft_irq);
<span class="p_header">diff --git a/kernel/trace/trace_printk.c b/kernel/trace/trace_printk.c</span>
<span class="p_header">index 060df67dbdd1..f96f0383f6c6 100644</span>
<span class="p_header">--- a/kernel/trace/trace_printk.c</span>
<span class="p_header">+++ b/kernel/trace/trace_printk.c</span>
<span class="p_chunk">@@ -296,6 +296,9 @@</span> <span class="p_context"> static int t_show(struct seq_file *m, void *v)</span>
 	const char *str = *fmt;
 	int i;
 
<span class="p_add">+	if (!*fmt)</span>
<span class="p_add">+		return 0;</span>
<span class="p_add">+</span>
 	seq_printf(m, &quot;0x%lx : \&quot;&quot;, *(unsigned long *)fmt);
 
 	/*
<span class="p_header">diff --git a/kernel/trace/trace_syscalls.c b/kernel/trace/trace_syscalls.c</span>
<span class="p_header">index 0655afbea83f..50be5602217c 100644</span>
<span class="p_header">--- a/kernel/trace/trace_syscalls.c</span>
<span class="p_header">+++ b/kernel/trace/trace_syscalls.c</span>
<span class="p_chunk">@@ -106,6 +106,17 @@</span> <span class="p_context"> static struct syscall_metadata *syscall_nr_to_meta(int nr)</span>
 	return syscalls_metadata[nr];
 }
 
<span class="p_add">+const char *get_syscall_name(int syscall)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct syscall_metadata *entry;</span>
<span class="p_add">+</span>
<span class="p_add">+	entry = syscall_nr_to_meta(syscall);</span>
<span class="p_add">+	if (!entry)</span>
<span class="p_add">+		return NULL;</span>
<span class="p_add">+</span>
<span class="p_add">+	return entry-&gt;name;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static enum print_line_t
 print_syscall_enter(struct trace_iterator *iter, int flags,
 		    struct trace_event *event)

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



