
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>[v2] x86/ibpb: Skip IBPB when we switch back to same user process - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    [v2] x86/ibpb: Skip IBPB when we switch back to same user process</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=7886">tim</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>Jan. 25, 2018, 11:37 p.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;a001fc041197f04ecf080ba606d8e8cef730ec3e.1516923053.git.tim.c.chen@linux.intel.com&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/10184941/mbox/"
   >mbox</a>
|
   <a href="/patch/10184941/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/10184941/">/patch/10184941/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
	[172.30.200.125])
	by pdx-korg-patchwork.web.codeaurora.org (Postfix) with ESMTP id
	778DE601D2 for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Thu, 25 Jan 2018 23:57:39 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 64C2A28795
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Thu, 25 Jan 2018 23:57:39 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id 55AE628BB4; Thu, 25 Jan 2018 23:57:39 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-6.9 required=2.0 tests=BAYES_00,RCVD_IN_DNSWL_HI
	autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 8725F28795
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Thu, 25 Jan 2018 23:57:38 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1751683AbeAYX5g (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Thu, 25 Jan 2018 18:57:36 -0500
Received: from mga09.intel.com ([134.134.136.24]:63444 &quot;EHLO mga09.intel.com&quot;
	rhost-flags-OK-OK-OK-OK) by vger.kernel.org with ESMTP
	id S1751353AbeAYX5f (ORCPT &lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Thu, 25 Jan 2018 18:57:35 -0500
X-Amp-Result: SKIPPED(no attachment in message)
X-Amp-File-Uploaded: False
Received: from orsmga007.jf.intel.com ([10.7.209.58])
	by orsmga102.jf.intel.com with ESMTP/TLS/DHE-RSA-AES256-GCM-SHA384;
	25 Jan 2018 15:57:34 -0800
X-ExtLoop1: 1
X-IronPort-AV: E=Sophos;i=&quot;5.46,414,1511856000&quot;; d=&quot;scan&#39;208&quot;;a=&quot;12678151&quot;
Received: from skl-02.jf.intel.com ([10.54.74.43])
	by orsmga007.jf.intel.com with ESMTP; 25 Jan 2018 15:57:34 -0800
From: Tim Chen &lt;tim.c.chen@linux.intel.com&gt;
To: linux-kernel@vger.kernel.org
Cc: Tim Chen &lt;tim.c.chen@linux.intel.com&gt;,
	KarimAllah Ahmed &lt;karahmed@amazon.de&gt;, Andi Kleen &lt;ak@linux.intel.com&gt;,
	Andrea Arcangeli &lt;aarcange@redhat.com&gt;,
	Andy Lutomirski &lt;luto@kernel.org&gt;,
	Arjan van de Ven &lt;arjan@linux.intel.com&gt;,
	Ashok Raj &lt;ashok.raj@intel.com&gt;, Asit Mallick &lt;asit.k.mallick@intel.com&gt;,
	Borislav Petkov &lt;bp@suse.de&gt;, Dan Williams &lt;dan.j.williams@intel.com&gt;,
	Dave Hansen &lt;dave.hansen@intel.com&gt;, David Woodhouse &lt;dwmw@amazon.co.uk&gt;,
	Greg Kroah-Hartman &lt;gregkh@linuxfoundation.org&gt;,
	&quot;H . Peter Anvin&quot; &lt;hpa@zytor.com&gt;, Ingo Molnar &lt;mingo@redhat.com&gt;,
	Janakarajan Natarajan &lt;Janakarajan.Natarajan@amd.com&gt;,
	Joerg Roedel &lt;joro@8bytes.org&gt;, Jun Nakajima &lt;jun.nakajima@intel.com&gt;,
	Laura Abbott &lt;labbott@redhat.com&gt;,
	Linus Torvalds &lt;torvalds@linux-foundation.org&gt;,
	Masami Hiramatsu &lt;mhiramat@kernel.org&gt;,
	Paolo Bonzini &lt;pbonzini@redhat.com&gt;,
	Peter Zijlstra &lt;peterz@infradead.org&gt;, rkrcmar@redhat.com,
	Thomas Gleixner &lt;tglx@linutronix.de&gt;,
	Tom Lendacky &lt;thomas.lendacky@amd.com&gt;, x86@kernel.org
Subject: [PATCH v2] x86/ibpb: Skip IBPB when we switch back to same user
	process
Date: Thu, 25 Jan 2018 15:37:17 -0800
Message-Id: &lt;a001fc041197f04ecf080ba606d8e8cef730ec3e.1516923053.git.tim.c.chen@linux.intel.com&gt;
X-Mailer: git-send-email 2.9.4
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=7886">tim</a> - Jan. 25, 2018, 11:37 p.m.</div>
<pre class="content">
Thanks to the reviewers and Andy Lutomirski for the suggestion of
using ctx_id which got rid of the problem of mm pointer recycling.
Here&#39;s an update of this patch based on Andy&#39;s suggestion.

We could switch to a kernel idle thread and then back to the original
process such as:
process A -&gt; idle -&gt; process A

In such scenario, we do not have to do IBPB here even though the process is
non-dumpable, as we are switching back to the same process after
an hiatus.

We track the last mm user context id before we switch to init_mm by calling
leave_mm when tlb_defer_switch_to_init_mm returns false (pcid available).

The cost is to have an extra u64 mm context id to track the last mm we were using before
switching to the init_mm used by idle.  Avoiding the extra IBPB
is probably worth the extra memory for this common scenario.

For those cases where tlb_defer_switch_to_init_mm returns true (non pcid),
lazy tlb will defer switch to init_mm, so we will not be changing
the mm for the process A -&gt; idle -&gt; process A switch. So
IBPB will be skipped for this case.

v2:
1. Save last user context id instead of last user mm to avoid the problem of recycled mm
<span class="signed-off-by">
Signed-off-by: Tim Chen &lt;tim.c.chen@linux.intel.com&gt;</span>
---
 arch/x86/include/asm/tlbflush.h |  2 ++
 arch/x86/mm/tlb.c               | 23 ++++++++++++++++-------
 2 files changed, 18 insertions(+), 7 deletions(-)
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=35552">Ingo Molnar</a> - Jan. 28, 2018, 9:56 a.m.</div>
<pre class="content">
* Tim Chen &lt;tim.c.chen@linux.intel.com&gt; wrote:
<span class="quote">
&gt; Thanks to the reviewers and Andy Lutomirski for the suggestion of</span>
<span class="quote">&gt; using ctx_id which got rid of the problem of mm pointer recycling.</span>
<span class="quote">&gt; Here&#39;s an update of this patch based on Andy&#39;s suggestion.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; We could switch to a kernel idle thread and then back to the original</span>
<span class="quote">&gt; process such as:</span>
<span class="quote">&gt; process A -&gt; idle -&gt; process A</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; In such scenario, we do not have to do IBPB here even though the process is</span>
<span class="quote">&gt; non-dumpable, as we are switching back to the same process after</span>
<span class="quote">&gt; an hiatus.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; We track the last mm user context id before we switch to init_mm by calling</span>
<span class="quote">&gt; leave_mm when tlb_defer_switch_to_init_mm returns false (pcid available).</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; The cost is to have an extra u64 mm context id to track the last mm we were using before</span>
<span class="quote">&gt; switching to the init_mm used by idle.  Avoiding the extra IBPB</span>
<span class="quote">&gt; is probably worth the extra memory for this common scenario.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; For those cases where tlb_defer_switch_to_init_mm returns true (non pcid),</span>
<span class="quote">&gt; lazy tlb will defer switch to init_mm, so we will not be changing</span>
<span class="quote">&gt; the mm for the process A -&gt; idle -&gt; process A switch. So</span>
<span class="quote">&gt; IBPB will be skipped for this case.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; v2:</span>
<span class="quote">&gt; 1. Save last user context id instead of last user mm to avoid the problem of recycled mm</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Signed-off-by: Tim Chen &lt;tim.c.chen@linux.intel.com&gt;</span>
<span class="quote">&gt; ---</span>
<span class="quote">&gt;  arch/x86/include/asm/tlbflush.h |  2 ++</span>
<span class="quote">&gt;  arch/x86/mm/tlb.c               | 23 ++++++++++++++++-------</span>
<span class="quote">&gt;  2 files changed, 18 insertions(+), 7 deletions(-)</span>

What tree is this patch against? It doesn&#39;t apply to linus&#39;s latest, nor to 
tip:master.

Thanks,

	Ingo
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=178213">Woodhouse, David</a> - Jan. 28, 2018, 10:38 a.m.</div>
<pre class="content">
On Sun, 2018-01-28 at 10:56 +0100, Ingo Molnar wrote:
<span class="quote">&gt; </span>
<span class="quote">&gt; What tree is this patch against? It doesn&#39;t apply to linus&#39;s latest, nor to </span>
<span class="quote">&gt; tip:master.</span>

It&#39;s in my tree at
 http://git.infradead.org/users/dwmw2/linux-retpoline.git/shortlog/refs/heads/ibpb
which is gradually being finalized and flushed via tip/x86/pti.

The IBPB on context switch parts are currently the first three patches
there, which roughly suggests they might be the next to get sent out
for real, if we have reached a consensus. The three patches there
probably want collapsing into one, but I&#39;ve left them as-is for now
while we&#39;re discussing it.

The other thing that&#39;s next on the list is exposing the MSRs to guests.
The IBPB one is fairly simple, and Karim is working on exposing IBRS to
guests too, using Paolo&#39;s per-vCPU MSR bitmap to do the same trick
we&#39;ve done in Xen, to expose it only after the guest first touches it
(to avoid the cost of swapping it when it&#39;s always 0←→0 in the common
case). I think Ashok was talking about doing the same thing? We&#39;ll see
who gets there first :)
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/arch/x86/include/asm/tlbflush.h b/arch/x86/include/asm/tlbflush.h</span>
<span class="p_header">index 3effd3c..4405c4b 100644</span>
<span class="p_header">--- a/arch/x86/include/asm/tlbflush.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/tlbflush.h</span>
<span class="p_chunk">@@ -174,6 +174,8 @@</span> <span class="p_context"> struct tlb_state {</span>
 	struct mm_struct *loaded_mm;
 	u16 loaded_mm_asid;
 	u16 next_asid;
<span class="p_add">+	/* last user mm&#39;s ctx id */</span>
<span class="p_add">+	u64 last_ctx_id;</span>
 
 	/*
 	 * We can be in one of several states:
<span class="p_header">diff --git a/arch/x86/mm/tlb.c b/arch/x86/mm/tlb.c</span>
<span class="p_header">index 33f5f97..2179b90 100644</span>
<span class="p_header">--- a/arch/x86/mm/tlb.c</span>
<span class="p_header">+++ b/arch/x86/mm/tlb.c</span>
<span class="p_chunk">@@ -220,6 +220,7 @@</span> <span class="p_context"> void switch_mm_irqs_off(struct mm_struct *prev, struct mm_struct *next,</span>
 	} else {
 		u16 new_asid;
 		bool need_flush;
<span class="p_add">+		u64 last_ctx_id = this_cpu_read(cpu_tlbstate.last_ctx_id);</span>
 
 		/*
 		 * Avoid user/user BTB poisoning by flushing the branch predictor
<span class="p_chunk">@@ -230,14 +231,13 @@</span> <span class="p_context"> void switch_mm_irqs_off(struct mm_struct *prev, struct mm_struct *next,</span>
 		 * switching into processes that disable dumping.
 		 *
 		 * This will not flush branches when switching into kernel
<span class="p_del">-		 * threads, but it would flush them when switching to the</span>
<span class="p_del">-		 * idle thread and back.</span>
<span class="p_del">-		 *</span>
<span class="p_del">-		 * It might be useful to have a one-off cache here</span>
<span class="p_del">-		 * to also not flush the idle case, but we would need some</span>
<span class="p_del">-		 * kind of stable sequence number to remember the previous mm.</span>
<span class="p_add">+		 * threads. It will also not flush if we switch to idle</span>
<span class="p_add">+		 * thread and back to the same process. It will flush if we</span>
<span class="p_add">+		 * switch to a different non-dumpable process.</span>
 		 */
<span class="p_del">-		if (tsk &amp;&amp; tsk-&gt;mm &amp;&amp; get_dumpable(tsk-&gt;mm) != SUID_DUMP_USER)</span>
<span class="p_add">+		if (tsk &amp;&amp; tsk-&gt;mm &amp;&amp;</span>
<span class="p_add">+		    tsk-&gt;mm-&gt;context.ctx_id != last_ctx_id &amp;&amp;</span>
<span class="p_add">+		    get_dumpable(tsk-&gt;mm) != SUID_DUMP_USER)</span>
 			indirect_branch_prediction_barrier();
 
 		if (IS_ENABLED(CONFIG_VMAP_STACK)) {
<span class="p_chunk">@@ -288,6 +288,14 @@</span> <span class="p_context"> void switch_mm_irqs_off(struct mm_struct *prev, struct mm_struct *next,</span>
 			trace_tlb_flush_rcuidle(TLB_FLUSH_ON_TASK_SWITCH, 0);
 		}
 
<span class="p_add">+		/*</span>
<span class="p_add">+		 * Record last user mm&#39;s context id, so we can avoid</span>
<span class="p_add">+		 * flushing branch buffer with IBPB if we switch back</span>
<span class="p_add">+		 * to the same user.</span>
<span class="p_add">+		 */</span>
<span class="p_add">+		if (next != &amp;init_mm)</span>
<span class="p_add">+			this_cpu_write(cpu_tlbstate.last_ctx_id, next-&gt;context.ctx_id);</span>
<span class="p_add">+</span>
 		this_cpu_write(cpu_tlbstate.loaded_mm, next);
 		this_cpu_write(cpu_tlbstate.loaded_mm_asid, new_asid);
 	}
<span class="p_chunk">@@ -365,6 +373,7 @@</span> <span class="p_context"> void initialize_tlbstate_and_flush(void)</span>
 	write_cr3(build_cr3(mm-&gt;pgd, 0));
 
 	/* Reinitialize tlbstate. */
<span class="p_add">+	this_cpu_write(cpu_tlbstate.last_ctx_id, mm-&gt;context.ctx_id);</span>
 	this_cpu_write(cpu_tlbstate.loaded_mm_asid, 0);
 	this_cpu_write(cpu_tlbstate.next_asid, 1);
 	this_cpu_write(cpu_tlbstate.ctxs[0].ctx_id, mm-&gt;context.ctx_id);

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



