
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>[18/27] mm: Move most file-based accounting to the node - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    [18/27] mm: Move most file-based accounting to the node</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=138281">Mel Gorman</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>June 21, 2016, 2:15 p.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;1466518566-30034-19-git-send-email-mgorman@techsingularity.net&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/9190695/mbox/"
   >mbox</a>
|
   <a href="/patch/9190695/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/9190695/">/patch/9190695/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
	[172.30.200.125])
	by pdx-korg-patchwork.web.codeaurora.org (Postfix) with ESMTP id
	18CA86089F for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Tue, 21 Jun 2016 14:21:13 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 0833B28173
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Tue, 21 Jun 2016 14:21:13 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id F083D2818B; Tue, 21 Jun 2016 14:21:12 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-6.9 required=2.0 tests=BAYES_00,RCVD_IN_DNSWL_HI
	autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 776142818A
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Tue, 21 Jun 2016 14:21:11 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1752288AbcFUOU7 (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Tue, 21 Jun 2016 10:20:59 -0400
Received: from outbound-smtp11.blacknight.com ([46.22.139.16]:42274 &quot;EHLO
	outbound-smtp11.blacknight.com&quot; rhost-flags-OK-OK-OK-OK)
	by vger.kernel.org with ESMTP id S1752119AbcFUOUe (ORCPT
	&lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Tue, 21 Jun 2016 10:20:34 -0400
Received: from mail.blacknight.com (pemlinmail01.blacknight.ie
	[81.17.254.10])
	by outbound-smtp11.blacknight.com (Postfix) with ESMTPS id
	DF3991C19A3 for &lt;linux-kernel@vger.kernel.org&gt;;
	Tue, 21 Jun 2016 15:19:20 +0100 (IST)
Received: (qmail 21370 invoked from network); 21 Jun 2016 14:19:20 -0000
Received: from unknown (HELO stampy.163woodhaven.lan)
	(mgorman@techsingularity.net@[37.228.231.136])
	by 81.17.254.9 with ESMTPA; 21 Jun 2016 14:19:20 -0000
From: Mel Gorman &lt;mgorman@techsingularity.net&gt;
To: Andrew Morton &lt;akpm@linux-foundation.org&gt;, Linux-MM &lt;linux-mm@kvack.org&gt;
Cc: Rik van Riel &lt;riel@surriel.com&gt;, Vlastimil Babka &lt;vbabka@suse.cz&gt;,
	Johannes Weiner &lt;hannes@cmpxchg.org&gt;,
	LKML &lt;linux-kernel@vger.kernel.org&gt;,
	Mel Gorman &lt;mgorman@techsingularity.net&gt;
Subject: [PATCH 18/27] mm: Move most file-based accounting to the node
Date: Tue, 21 Jun 2016 15:15:57 +0100
Message-Id: &lt;1466518566-30034-19-git-send-email-mgorman@techsingularity.net&gt;
X-Mailer: git-send-email 2.6.4
In-Reply-To: &lt;1466518566-30034-1-git-send-email-mgorman@techsingularity.net&gt;
References: &lt;1466518566-30034-1-git-send-email-mgorman@techsingularity.net&gt;
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=138281">Mel Gorman</a> - June 21, 2016, 2:15 p.m.</div>
<pre class="content">
There are now a number of accounting oddities such as mapped file pages
being accounted for on the node while the total number of file pages are
accounted on the zone. This can be coped with to some extent but it&#39;s
confusing so this patch moves the relevant file-based accounted.
<span class="signed-off-by">
Signed-off-by: Mel Gorman &lt;mgorman@techsingularity.net&gt;</span>
<span class="acked-by">Acked-by: Vlastimil Babka &lt;vbabka@suse.cz&gt;</span>
---
 arch/s390/appldata/appldata_mem.c         |  2 +-
 arch/tile/mm/pgtable.c                    |  8 +++---
 drivers/base/node.c                       | 10 ++++----
 drivers/staging/android/lowmemorykiller.c |  4 +--
 fs/fs-writeback.c                         |  4 +--
 fs/fuse/file.c                            |  8 +++---
 fs/nfs/internal.h                         |  2 +-
 fs/nfs/write.c                            |  2 +-
 fs/proc/meminfo.c                         | 10 ++++----
 include/linux/mmzone.h                    | 12 ++++-----
 include/trace/events/writeback.h          |  6 ++---
 mm/filemap.c                              | 10 ++++----
 mm/migrate.c                              | 12 ++++-----
 mm/page-writeback.c                       | 42 +++++++++++++------------------
 mm/page_alloc.c                           | 34 ++++++++++++-------------
 mm/shmem.c                                | 12 ++++-----
 mm/swap_state.c                           |  4 +--
 mm/util.c                                 |  4 +--
 mm/vmscan.c                               | 16 ++++++------
 mm/vmstat.c                               | 12 ++++-----
 20 files changed, 103 insertions(+), 111 deletions(-)
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=137061">Michal Hocko</a> - June 22, 2016, 2:38 p.m.</div>
<pre class="content">
On Tue 21-06-16 15:15:57, Mel Gorman wrote:
<span class="quote">&gt; There are now a number of accounting oddities such as mapped file pages</span>
<span class="quote">&gt; being accounted for on the node while the total number of file pages are</span>
<span class="quote">&gt; accounted on the zone. This can be coped with to some extent but it&#39;s</span>
<span class="quote">&gt; confusing so this patch moves the relevant file-based accounted.</span>

Same concern about the zoneinfo as for the other patch, but other than
that no issues spotted.
<span class="quote"> 
&gt; Signed-off-by: Mel Gorman &lt;mgorman@techsingularity.net&gt;</span>
<span class="quote">&gt; Acked-by: Vlastimil Babka &lt;vbabka@suse.cz&gt;</span>
<span class="acked-by">
Acked-by: Michal Hocko &lt;mhocko@suse.com&gt;</span>
<span class="quote">
&gt; ---</span>
<span class="quote">&gt;  arch/s390/appldata/appldata_mem.c         |  2 +-</span>
<span class="quote">&gt;  arch/tile/mm/pgtable.c                    |  8 +++---</span>
<span class="quote">&gt;  drivers/base/node.c                       | 10 ++++----</span>
<span class="quote">&gt;  drivers/staging/android/lowmemorykiller.c |  4 +--</span>
<span class="quote">&gt;  fs/fs-writeback.c                         |  4 +--</span>
<span class="quote">&gt;  fs/fuse/file.c                            |  8 +++---</span>
<span class="quote">&gt;  fs/nfs/internal.h                         |  2 +-</span>
<span class="quote">&gt;  fs/nfs/write.c                            |  2 +-</span>
<span class="quote">&gt;  fs/proc/meminfo.c                         | 10 ++++----</span>
<span class="quote">&gt;  include/linux/mmzone.h                    | 12 ++++-----</span>
<span class="quote">&gt;  include/trace/events/writeback.h          |  6 ++---</span>
<span class="quote">&gt;  mm/filemap.c                              | 10 ++++----</span>
<span class="quote">&gt;  mm/migrate.c                              | 12 ++++-----</span>
<span class="quote">&gt;  mm/page-writeback.c                       | 42 +++++++++++++------------------</span>
<span class="quote">&gt;  mm/page_alloc.c                           | 34 ++++++++++++-------------</span>
<span class="quote">&gt;  mm/shmem.c                                | 12 ++++-----</span>
<span class="quote">&gt;  mm/swap_state.c                           |  4 +--</span>
<span class="quote">&gt;  mm/util.c                                 |  4 +--</span>
<span class="quote">&gt;  mm/vmscan.c                               | 16 ++++++------</span>
<span class="quote">&gt;  mm/vmstat.c                               | 12 ++++-----</span>
<span class="quote">&gt;  20 files changed, 103 insertions(+), 111 deletions(-)</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; diff --git a/arch/s390/appldata/appldata_mem.c b/arch/s390/appldata/appldata_mem.c</span>
<span class="quote">&gt; index edcf2a706942..598df5708501 100644</span>
<span class="quote">&gt; --- a/arch/s390/appldata/appldata_mem.c</span>
<span class="quote">&gt; +++ b/arch/s390/appldata/appldata_mem.c</span>
<span class="quote">&gt; @@ -102,7 +102,7 @@ static void appldata_get_mem_data(void *data)</span>
<span class="quote">&gt;  	mem_data-&gt;totalhigh = P2K(val.totalhigh);</span>
<span class="quote">&gt;  	mem_data-&gt;freehigh  = P2K(val.freehigh);</span>
<span class="quote">&gt;  	mem_data-&gt;bufferram = P2K(val.bufferram);</span>
<span class="quote">&gt; -	mem_data-&gt;cached    = P2K(global_page_state(NR_FILE_PAGES)</span>
<span class="quote">&gt; +	mem_data-&gt;cached    = P2K(global_node_page_state(NR_FILE_PAGES)</span>
<span class="quote">&gt;  				- val.bufferram);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	si_swapinfo(&amp;val);</span>
<span class="quote">&gt; diff --git a/arch/tile/mm/pgtable.c b/arch/tile/mm/pgtable.c</span>
<span class="quote">&gt; index c606b0ef2f7e..7cc6ee7f1a58 100644</span>
<span class="quote">&gt; --- a/arch/tile/mm/pgtable.c</span>
<span class="quote">&gt; +++ b/arch/tile/mm/pgtable.c</span>
<span class="quote">&gt; @@ -49,16 +49,16 @@ void show_mem(unsigned int filter)</span>
<span class="quote">&gt;  		global_node_page_state(NR_ACTIVE_FILE)),</span>
<span class="quote">&gt;  	       (global_node_page_state(NR_INACTIVE_ANON) +</span>
<span class="quote">&gt;  		global_node_page_state(NR_INACTIVE_FILE)),</span>
<span class="quote">&gt; -	       global_page_state(NR_FILE_DIRTY),</span>
<span class="quote">&gt; -	       global_page_state(NR_WRITEBACK),</span>
<span class="quote">&gt; -	       global_page_state(NR_UNSTABLE_NFS),</span>
<span class="quote">&gt; +	       global_node_page_state(NR_FILE_DIRTY),</span>
<span class="quote">&gt; +	       global_node_page_state(NR_WRITEBACK),</span>
<span class="quote">&gt; +	       global_node_page_state(NR_UNSTABLE_NFS),</span>
<span class="quote">&gt;  	       global_page_state(NR_FREE_PAGES),</span>
<span class="quote">&gt;  	       (global_page_state(NR_SLAB_RECLAIMABLE) +</span>
<span class="quote">&gt;  		global_page_state(NR_SLAB_UNRECLAIMABLE)),</span>
<span class="quote">&gt;  	       global_node_page_state(NR_FILE_MAPPED),</span>
<span class="quote">&gt;  	       global_page_state(NR_PAGETABLE),</span>
<span class="quote">&gt;  	       global_page_state(NR_BOUNCE),</span>
<span class="quote">&gt; -	       global_page_state(NR_FILE_PAGES),</span>
<span class="quote">&gt; +	       global_node_page_state(NR_FILE_PAGES),</span>
<span class="quote">&gt;  	       get_nr_swap_pages());</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	for_each_zone(zone) {</span>
<span class="quote">&gt; diff --git a/drivers/base/node.c b/drivers/base/node.c</span>
<span class="quote">&gt; index 897b6bcb36be..ec733919bc6b 100644</span>
<span class="quote">&gt; --- a/drivers/base/node.c</span>
<span class="quote">&gt; +++ b/drivers/base/node.c</span>
<span class="quote">&gt; @@ -116,18 +116,18 @@ static ssize_t node_read_meminfo(struct device *dev,</span>
<span class="quote">&gt;  		       &quot;Node %d AnonHugePages:  %8lu kB\n&quot;</span>
<span class="quote">&gt;  #endif</span>
<span class="quote">&gt;  			,</span>
<span class="quote">&gt; -		       nid, K(sum_zone_node_page_state(nid, NR_FILE_DIRTY)),</span>
<span class="quote">&gt; -		       nid, K(sum_zone_node_page_state(nid, NR_WRITEBACK)),</span>
<span class="quote">&gt; -		       nid, K(sum_zone_node_page_state(nid, NR_FILE_PAGES)),</span>
<span class="quote">&gt; +		       nid, K(node_page_state(pgdat, NR_FILE_DIRTY)),</span>
<span class="quote">&gt; +		       nid, K(node_page_state(pgdat, NR_WRITEBACK)),</span>
<span class="quote">&gt; +		       nid, K(node_page_state(pgdat, NR_FILE_PAGES)),</span>
<span class="quote">&gt;  		       nid, K(node_page_state(pgdat, NR_FILE_MAPPED)),</span>
<span class="quote">&gt;  		       nid, K(node_page_state(pgdat, NR_ANON_MAPPED)),</span>
<span class="quote">&gt;  		       nid, K(i.sharedram),</span>
<span class="quote">&gt;  		       nid, sum_zone_node_page_state(nid, NR_KERNEL_STACK) *</span>
<span class="quote">&gt;  				THREAD_SIZE / 1024,</span>
<span class="quote">&gt;  		       nid, K(sum_zone_node_page_state(nid, NR_PAGETABLE)),</span>
<span class="quote">&gt; -		       nid, K(sum_zone_node_page_state(nid, NR_UNSTABLE_NFS)),</span>
<span class="quote">&gt; +		       nid, K(node_page_state(pgdat, NR_UNSTABLE_NFS)),</span>
<span class="quote">&gt;  		       nid, K(sum_zone_node_page_state(nid, NR_BOUNCE)),</span>
<span class="quote">&gt; -		       nid, K(sum_zone_node_page_state(nid, NR_WRITEBACK_TEMP)),</span>
<span class="quote">&gt; +		       nid, K(node_page_state(pgdat, NR_WRITEBACK_TEMP)),</span>
<span class="quote">&gt;  		       nid, K(sum_zone_node_page_state(nid, NR_SLAB_RECLAIMABLE) +</span>
<span class="quote">&gt;  				sum_zone_node_page_state(nid, NR_SLAB_UNRECLAIMABLE)),</span>
<span class="quote">&gt;  		       nid, K(sum_zone_node_page_state(nid, NR_SLAB_RECLAIMABLE)),</span>
<span class="quote">&gt; diff --git a/drivers/staging/android/lowmemorykiller.c b/drivers/staging/android/lowmemorykiller.c</span>
<span class="quote">&gt; index 93dbcc38eb0f..45a1b4ec4ca3 100644</span>
<span class="quote">&gt; --- a/drivers/staging/android/lowmemorykiller.c</span>
<span class="quote">&gt; +++ b/drivers/staging/android/lowmemorykiller.c</span>
<span class="quote">&gt; @@ -91,8 +91,8 @@ static unsigned long lowmem_scan(struct shrinker *s, struct shrink_control *sc)</span>
<span class="quote">&gt;  	short selected_oom_score_adj;</span>
<span class="quote">&gt;  	int array_size = ARRAY_SIZE(lowmem_adj);</span>
<span class="quote">&gt;  	int other_free = global_page_state(NR_FREE_PAGES) - totalreserve_pages;</span>
<span class="quote">&gt; -	int other_file = global_page_state(NR_FILE_PAGES) -</span>
<span class="quote">&gt; -						global_page_state(NR_SHMEM) -</span>
<span class="quote">&gt; +	int other_file = global_node_page_state(NR_FILE_PAGES) -</span>
<span class="quote">&gt; +						global_node_page_state(NR_SHMEM) -</span>
<span class="quote">&gt;  						total_swapcache_pages();</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	if (lowmem_adj_size &lt; array_size)</span>
<span class="quote">&gt; diff --git a/fs/fs-writeback.c b/fs/fs-writeback.c</span>
<span class="quote">&gt; index 989a2cef6b76..fd68f8efb440 100644</span>
<span class="quote">&gt; --- a/fs/fs-writeback.c</span>
<span class="quote">&gt; +++ b/fs/fs-writeback.c</span>
<span class="quote">&gt; @@ -1771,8 +1771,8 @@ static struct wb_writeback_work *get_next_work_item(struct bdi_writeback *wb)</span>
<span class="quote">&gt;   */</span>
<span class="quote">&gt;  static unsigned long get_nr_dirty_pages(void)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt; -	return global_page_state(NR_FILE_DIRTY) +</span>
<span class="quote">&gt; -		global_page_state(NR_UNSTABLE_NFS) +</span>
<span class="quote">&gt; +	return global_node_page_state(NR_FILE_DIRTY) +</span>
<span class="quote">&gt; +		global_node_page_state(NR_UNSTABLE_NFS) +</span>
<span class="quote">&gt;  		get_nr_dirty_inodes();</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; diff --git a/fs/fuse/file.c b/fs/fuse/file.c</span>
<span class="quote">&gt; index 9154f8679024..2382f22a2a8b 100644</span>
<span class="quote">&gt; --- a/fs/fuse/file.c</span>
<span class="quote">&gt; +++ b/fs/fuse/file.c</span>
<span class="quote">&gt; @@ -1452,7 +1452,7 @@ static void fuse_writepage_finish(struct fuse_conn *fc, struct fuse_req *req)</span>
<span class="quote">&gt;  	list_del(&amp;req-&gt;writepages_entry);</span>
<span class="quote">&gt;  	for (i = 0; i &lt; req-&gt;num_pages; i++) {</span>
<span class="quote">&gt;  		dec_wb_stat(&amp;bdi-&gt;wb, WB_WRITEBACK);</span>
<span class="quote">&gt; -		dec_zone_page_state(req-&gt;pages[i], NR_WRITEBACK_TEMP);</span>
<span class="quote">&gt; +		dec_node_page_state(req-&gt;pages[i], NR_WRITEBACK_TEMP);</span>
<span class="quote">&gt;  		wb_writeout_inc(&amp;bdi-&gt;wb);</span>
<span class="quote">&gt;  	}</span>
<span class="quote">&gt;  	wake_up(&amp;fi-&gt;page_waitq);</span>
<span class="quote">&gt; @@ -1642,7 +1642,7 @@ static int fuse_writepage_locked(struct page *page)</span>
<span class="quote">&gt;  	req-&gt;inode = inode;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	inc_wb_stat(&amp;inode_to_bdi(inode)-&gt;wb, WB_WRITEBACK);</span>
<span class="quote">&gt; -	inc_zone_page_state(tmp_page, NR_WRITEBACK_TEMP);</span>
<span class="quote">&gt; +	inc_node_page_state(tmp_page, NR_WRITEBACK_TEMP);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	spin_lock(&amp;fc-&gt;lock);</span>
<span class="quote">&gt;  	list_add(&amp;req-&gt;writepages_entry, &amp;fi-&gt;writepages);</span>
<span class="quote">&gt; @@ -1756,7 +1756,7 @@ static bool fuse_writepage_in_flight(struct fuse_req *new_req,</span>
<span class="quote">&gt;  		spin_unlock(&amp;fc-&gt;lock);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  		dec_wb_stat(&amp;bdi-&gt;wb, WB_WRITEBACK);</span>
<span class="quote">&gt; -		dec_zone_page_state(page, NR_WRITEBACK_TEMP);</span>
<span class="quote">&gt; +		dec_node_page_state(page, NR_WRITEBACK_TEMP);</span>
<span class="quote">&gt;  		wb_writeout_inc(&amp;bdi-&gt;wb);</span>
<span class="quote">&gt;  		fuse_writepage_free(fc, new_req);</span>
<span class="quote">&gt;  		fuse_request_free(new_req);</span>
<span class="quote">&gt; @@ -1855,7 +1855,7 @@ static int fuse_writepages_fill(struct page *page,</span>
<span class="quote">&gt;  	req-&gt;page_descs[req-&gt;num_pages].length = PAGE_SIZE;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	inc_wb_stat(&amp;inode_to_bdi(inode)-&gt;wb, WB_WRITEBACK);</span>
<span class="quote">&gt; -	inc_zone_page_state(tmp_page, NR_WRITEBACK_TEMP);</span>
<span class="quote">&gt; +	inc_node_page_state(tmp_page, NR_WRITEBACK_TEMP);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	err = 0;</span>
<span class="quote">&gt;  	if (is_writeback &amp;&amp; fuse_writepage_in_flight(req, page)) {</span>
<span class="quote">&gt; diff --git a/fs/nfs/internal.h b/fs/nfs/internal.h</span>
<span class="quote">&gt; index 6b89fdf2c7fa..722731e16648 100644</span>
<span class="quote">&gt; --- a/fs/nfs/internal.h</span>
<span class="quote">&gt; +++ b/fs/nfs/internal.h</span>
<span class="quote">&gt; @@ -653,7 +653,7 @@ void nfs_mark_page_unstable(struct page *page, struct nfs_commit_info *cinfo)</span>
<span class="quote">&gt;  	if (!cinfo-&gt;dreq) {</span>
<span class="quote">&gt;  		struct inode *inode = page_file_mapping(page)-&gt;host;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; -		inc_zone_page_state(page, NR_UNSTABLE_NFS);</span>
<span class="quote">&gt; +		inc_node_page_state(page, NR_UNSTABLE_NFS);</span>
<span class="quote">&gt;  		inc_wb_stat(&amp;inode_to_bdi(inode)-&gt;wb, WB_RECLAIMABLE);</span>
<span class="quote">&gt;  		__mark_inode_dirty(inode, I_DIRTY_DATASYNC);</span>
<span class="quote">&gt;  	}</span>
<span class="quote">&gt; diff --git a/fs/nfs/write.c b/fs/nfs/write.c</span>
<span class="quote">&gt; index 3087fb6f1983..4715549be0c3 100644</span>
<span class="quote">&gt; --- a/fs/nfs/write.c</span>
<span class="quote">&gt; +++ b/fs/nfs/write.c</span>
<span class="quote">&gt; @@ -887,7 +887,7 @@ nfs_mark_request_commit(struct nfs_page *req, struct pnfs_layout_segment *lseg,</span>
<span class="quote">&gt;  static void</span>
<span class="quote">&gt;  nfs_clear_page_commit(struct page *page)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt; -	dec_zone_page_state(page, NR_UNSTABLE_NFS);</span>
<span class="quote">&gt; +	dec_node_page_state(page, NR_UNSTABLE_NFS);</span>
<span class="quote">&gt;  	dec_wb_stat(&amp;inode_to_bdi(page_file_mapping(page)-&gt;host)-&gt;wb,</span>
<span class="quote">&gt;  		    WB_RECLAIMABLE);</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt; diff --git a/fs/proc/meminfo.c b/fs/proc/meminfo.c</span>
<span class="quote">&gt; index 076afb43fc56..6cb9ea36d0fc 100644</span>
<span class="quote">&gt; --- a/fs/proc/meminfo.c</span>
<span class="quote">&gt; +++ b/fs/proc/meminfo.c</span>
<span class="quote">&gt; @@ -40,7 +40,7 @@ static int meminfo_proc_show(struct seq_file *m, void *v)</span>
<span class="quote">&gt;  	si_swapinfo(&amp;i);</span>
<span class="quote">&gt;  	committed = percpu_counter_read_positive(&amp;vm_committed_as);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; -	cached = global_page_state(NR_FILE_PAGES) -</span>
<span class="quote">&gt; +	cached = global_node_page_state(NR_FILE_PAGES) -</span>
<span class="quote">&gt;  			total_swapcache_pages() - i.bufferram;</span>
<span class="quote">&gt;  	if (cached &lt; 0)</span>
<span class="quote">&gt;  		cached = 0;</span>
<span class="quote">&gt; @@ -136,8 +136,8 @@ static int meminfo_proc_show(struct seq_file *m, void *v)</span>
<span class="quote">&gt;  #endif</span>
<span class="quote">&gt;  		K(i.totalswap),</span>
<span class="quote">&gt;  		K(i.freeswap),</span>
<span class="quote">&gt; -		K(global_page_state(NR_FILE_DIRTY)),</span>
<span class="quote">&gt; -		K(global_page_state(NR_WRITEBACK)),</span>
<span class="quote">&gt; +		K(global_node_page_state(NR_FILE_DIRTY)),</span>
<span class="quote">&gt; +		K(global_node_page_state(NR_WRITEBACK)),</span>
<span class="quote">&gt;  		K(global_node_page_state(NR_ANON_MAPPED)),</span>
<span class="quote">&gt;  		K(global_node_page_state(NR_FILE_MAPPED)),</span>
<span class="quote">&gt;  		K(i.sharedram),</span>
<span class="quote">&gt; @@ -150,9 +150,9 @@ static int meminfo_proc_show(struct seq_file *m, void *v)</span>
<span class="quote">&gt;  #ifdef CONFIG_QUICKLIST</span>
<span class="quote">&gt;  		K(quicklist_total_size()),</span>
<span class="quote">&gt;  #endif</span>
<span class="quote">&gt; -		K(global_page_state(NR_UNSTABLE_NFS)),</span>
<span class="quote">&gt; +		K(global_node_page_state(NR_UNSTABLE_NFS)),</span>
<span class="quote">&gt;  		K(global_page_state(NR_BOUNCE)),</span>
<span class="quote">&gt; -		K(global_page_state(NR_WRITEBACK_TEMP)),</span>
<span class="quote">&gt; +		K(global_node_page_state(NR_WRITEBACK_TEMP)),</span>
<span class="quote">&gt;  		K(vm_commit_limit()),</span>
<span class="quote">&gt;  		K(committed),</span>
<span class="quote">&gt;  		(unsigned long)VMALLOC_TOTAL &gt;&gt; 10,</span>
<span class="quote">&gt; diff --git a/include/linux/mmzone.h b/include/linux/mmzone.h</span>
<span class="quote">&gt; index 6b1fea6cde9a..9924b46e3a13 100644</span>
<span class="quote">&gt; --- a/include/linux/mmzone.h</span>
<span class="quote">&gt; +++ b/include/linux/mmzone.h</span>
<span class="quote">&gt; @@ -115,20 +115,14 @@ enum zone_stat_item {</span>
<span class="quote">&gt;  	NR_ZONE_LRU_ANON = NR_ZONE_LRU_BASE,</span>
<span class="quote">&gt;  	NR_ZONE_LRU_FILE,</span>
<span class="quote">&gt;  	NR_MLOCK,		/* mlock()ed pages found and moved off LRU */</span>
<span class="quote">&gt; -	NR_FILE_PAGES,</span>
<span class="quote">&gt; -	NR_FILE_DIRTY,</span>
<span class="quote">&gt; -	NR_WRITEBACK,</span>
<span class="quote">&gt;  	NR_SLAB_RECLAIMABLE,</span>
<span class="quote">&gt;  	NR_SLAB_UNRECLAIMABLE,</span>
<span class="quote">&gt;  	NR_PAGETABLE,		/* used for pagetables */</span>
<span class="quote">&gt;  	NR_KERNEL_STACK,</span>
<span class="quote">&gt;  	/* Second 128 byte cacheline */</span>
<span class="quote">&gt; -	NR_UNSTABLE_NFS,	/* NFS unstable pages */</span>
<span class="quote">&gt;  	NR_BOUNCE,</span>
<span class="quote">&gt;  	NR_VMSCAN_WRITE,</span>
<span class="quote">&gt;  	NR_VMSCAN_IMMEDIATE,	/* Prioritise for reclaim when writeback ends */</span>
<span class="quote">&gt; -	NR_WRITEBACK_TEMP,	/* Writeback using temporary buffers */</span>
<span class="quote">&gt; -	NR_SHMEM,		/* shmem pages (included tmpfs/GEM pages) */</span>
<span class="quote">&gt;  	NR_DIRTIED,		/* page dirtyings since bootup */</span>
<span class="quote">&gt;  	NR_WRITTEN,		/* page writings since bootup */</span>
<span class="quote">&gt;  #if IS_ENABLED(CONFIG_ZSMALLOC)</span>
<span class="quote">&gt; @@ -162,6 +156,12 @@ enum node_stat_item {</span>
<span class="quote">&gt;  	NR_ANON_MAPPED,	/* Mapped anonymous pages */</span>
<span class="quote">&gt;  	NR_FILE_MAPPED,	/* pagecache pages mapped into pagetables.</span>
<span class="quote">&gt;  			   only modified from process context */</span>
<span class="quote">&gt; +	NR_FILE_PAGES,</span>
<span class="quote">&gt; +	NR_FILE_DIRTY,</span>
<span class="quote">&gt; +	NR_WRITEBACK,</span>
<span class="quote">&gt; +	NR_WRITEBACK_TEMP,	/* Writeback using temporary buffers */</span>
<span class="quote">&gt; +	NR_SHMEM,		/* shmem pages (included tmpfs/GEM pages) */</span>
<span class="quote">&gt; +	NR_UNSTABLE_NFS,	/* NFS unstable pages */</span>
<span class="quote">&gt;  	NR_VM_NODE_STAT_ITEMS</span>
<span class="quote">&gt;  };</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; diff --git a/include/trace/events/writeback.h b/include/trace/events/writeback.h</span>
<span class="quote">&gt; index 73614ce1d204..c581d9c04ca5 100644</span>
<span class="quote">&gt; --- a/include/trace/events/writeback.h</span>
<span class="quote">&gt; +++ b/include/trace/events/writeback.h</span>
<span class="quote">&gt; @@ -412,9 +412,9 @@ TRACE_EVENT(global_dirty_state,</span>
<span class="quote">&gt;  	),</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	TP_fast_assign(</span>
<span class="quote">&gt; -		__entry-&gt;nr_dirty	= global_page_state(NR_FILE_DIRTY);</span>
<span class="quote">&gt; -		__entry-&gt;nr_writeback	= global_page_state(NR_WRITEBACK);</span>
<span class="quote">&gt; -		__entry-&gt;nr_unstable	= global_page_state(NR_UNSTABLE_NFS);</span>
<span class="quote">&gt; +		__entry-&gt;nr_dirty	= global_node_page_state(NR_FILE_DIRTY);</span>
<span class="quote">&gt; +		__entry-&gt;nr_writeback	= global_node_page_state(NR_WRITEBACK);</span>
<span class="quote">&gt; +		__entry-&gt;nr_unstable	= global_node_page_state(NR_UNSTABLE_NFS);</span>
<span class="quote">&gt;  		__entry-&gt;nr_dirtied	= global_page_state(NR_DIRTIED);</span>
<span class="quote">&gt;  		__entry-&gt;nr_written	= global_page_state(NR_WRITTEN);</span>
<span class="quote">&gt;  		__entry-&gt;background_thresh = background_thresh;</span>
<span class="quote">&gt; diff --git a/mm/filemap.c b/mm/filemap.c</span>
<span class="quote">&gt; index d50619adfd7f..b99035dd2288 100644</span>
<span class="quote">&gt; --- a/mm/filemap.c</span>
<span class="quote">&gt; +++ b/mm/filemap.c</span>
<span class="quote">&gt; @@ -209,9 +209,9 @@ void __delete_from_page_cache(struct page *page, void *shadow)</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	/* hugetlb pages do not participate in page cache accounting. */</span>
<span class="quote">&gt;  	if (!PageHuge(page))</span>
<span class="quote">&gt; -		__dec_zone_page_state(page, NR_FILE_PAGES);</span>
<span class="quote">&gt; +		__dec_node_page_state(page, NR_FILE_PAGES);</span>
<span class="quote">&gt;  	if (PageSwapBacked(page))</span>
<span class="quote">&gt; -		__dec_zone_page_state(page, NR_SHMEM);</span>
<span class="quote">&gt; +		__dec_node_page_state(page, NR_SHMEM);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	/*</span>
<span class="quote">&gt;  	 * At this point page must be either written or cleaned by truncate.</span>
<span class="quote">&gt; @@ -549,9 +549,9 @@ int replace_page_cache_page(struct page *old, struct page *new, gfp_t gfp_mask)</span>
<span class="quote">&gt;  		 * hugetlb pages do not participate in page cache accounting.</span>
<span class="quote">&gt;  		 */</span>
<span class="quote">&gt;  		if (!PageHuge(new))</span>
<span class="quote">&gt; -			__inc_zone_page_state(new, NR_FILE_PAGES);</span>
<span class="quote">&gt; +			__inc_node_page_state(new, NR_FILE_PAGES);</span>
<span class="quote">&gt;  		if (PageSwapBacked(new))</span>
<span class="quote">&gt; -			__inc_zone_page_state(new, NR_SHMEM);</span>
<span class="quote">&gt; +			__inc_node_page_state(new, NR_SHMEM);</span>
<span class="quote">&gt;  		spin_unlock_irqrestore(&amp;mapping-&gt;tree_lock, flags);</span>
<span class="quote">&gt;  		mem_cgroup_migrate(old, new);</span>
<span class="quote">&gt;  		radix_tree_preload_end();</span>
<span class="quote">&gt; @@ -658,7 +658,7 @@ static int __add_to_page_cache_locked(struct page *page,</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	/* hugetlb pages do not participate in page cache accounting. */</span>
<span class="quote">&gt;  	if (!huge)</span>
<span class="quote">&gt; -		__inc_zone_page_state(page, NR_FILE_PAGES);</span>
<span class="quote">&gt; +		__inc_node_page_state(page, NR_FILE_PAGES);</span>
<span class="quote">&gt;  	spin_unlock_irq(&amp;mapping-&gt;tree_lock);</span>
<span class="quote">&gt;  	if (!huge)</span>
<span class="quote">&gt;  		mem_cgroup_commit_charge(page, memcg, false, false);</span>
<span class="quote">&gt; diff --git a/mm/migrate.c b/mm/migrate.c</span>
<span class="quote">&gt; index 1582c07205c6..d3fe4cfc2808 100644</span>
<span class="quote">&gt; --- a/mm/migrate.c</span>
<span class="quote">&gt; +++ b/mm/migrate.c</span>
<span class="quote">&gt; @@ -505,15 +505,15 @@ int migrate_page_move_mapping(struct address_space *mapping,</span>
<span class="quote">&gt;  	 * are mapped to swap space.</span>
<span class="quote">&gt;  	 */</span>
<span class="quote">&gt;  	if (newzone != oldzone) {</span>
<span class="quote">&gt; -		__dec_zone_state(oldzone, NR_FILE_PAGES);</span>
<span class="quote">&gt; -		__inc_zone_state(newzone, NR_FILE_PAGES);</span>
<span class="quote">&gt; +		__dec_node_state(oldzone-&gt;zone_pgdat, NR_FILE_PAGES);</span>
<span class="quote">&gt; +		__inc_node_state(newzone-&gt;zone_pgdat, NR_FILE_PAGES);</span>
<span class="quote">&gt;  		if (PageSwapBacked(page) &amp;&amp; !PageSwapCache(page)) {</span>
<span class="quote">&gt; -			__dec_zone_state(oldzone, NR_SHMEM);</span>
<span class="quote">&gt; -			__inc_zone_state(newzone, NR_SHMEM);</span>
<span class="quote">&gt; +			__dec_node_state(oldzone-&gt;zone_pgdat, NR_SHMEM);</span>
<span class="quote">&gt; +			__inc_node_state(newzone-&gt;zone_pgdat, NR_SHMEM);</span>
<span class="quote">&gt;  		}</span>
<span class="quote">&gt;  		if (dirty &amp;&amp; mapping_cap_account_dirty(mapping)) {</span>
<span class="quote">&gt; -			__dec_zone_state(oldzone, NR_FILE_DIRTY);</span>
<span class="quote">&gt; -			__inc_zone_state(newzone, NR_FILE_DIRTY);</span>
<span class="quote">&gt; +			__dec_node_state(oldzone-&gt;zone_pgdat, NR_FILE_DIRTY);</span>
<span class="quote">&gt; +			__inc_node_state(newzone-&gt;zone_pgdat, NR_FILE_DIRTY);</span>
<span class="quote">&gt;  		}</span>
<span class="quote">&gt;  	}</span>
<span class="quote">&gt;  	local_irq_enable();</span>
<span class="quote">&gt; diff --git a/mm/page-writeback.c b/mm/page-writeback.c</span>
<span class="quote">&gt; index a2b24d5ea43a..aa9fa1eb8b80 100644</span>
<span class="quote">&gt; --- a/mm/page-writeback.c</span>
<span class="quote">&gt; +++ b/mm/page-writeback.c</span>
<span class="quote">&gt; @@ -471,20 +471,12 @@ static unsigned long node_dirty_limit(struct pglist_data *pgdat)</span>
<span class="quote">&gt;   */</span>
<span class="quote">&gt;  bool node_dirty_ok(struct pglist_data *pgdat)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt; -	int z;</span>
<span class="quote">&gt;  	unsigned long limit = node_dirty_limit(pgdat);</span>
<span class="quote">&gt;  	unsigned long nr_pages = 0;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; -	for (z = 0; z &lt; MAX_NR_ZONES; z++) {</span>
<span class="quote">&gt; -		struct zone *zone = pgdat-&gt;node_zones + z;</span>
<span class="quote">&gt; -</span>
<span class="quote">&gt; -		if (!populated_zone(zone))</span>
<span class="quote">&gt; -			continue;</span>
<span class="quote">&gt; -</span>
<span class="quote">&gt; -		nr_pages += zone_page_state(zone, NR_FILE_DIRTY);</span>
<span class="quote">&gt; -		nr_pages += zone_page_state(zone, NR_UNSTABLE_NFS);</span>
<span class="quote">&gt; -		nr_pages += zone_page_state(zone, NR_WRITEBACK);</span>
<span class="quote">&gt; -	}</span>
<span class="quote">&gt; +	nr_pages += node_page_state(pgdat, NR_FILE_DIRTY);</span>
<span class="quote">&gt; +	nr_pages += node_page_state(pgdat, NR_UNSTABLE_NFS);</span>
<span class="quote">&gt; +	nr_pages += node_page_state(pgdat, NR_WRITEBACK);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	return nr_pages &lt;= limit;</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt; @@ -1574,10 +1566,10 @@ static void balance_dirty_pages(struct address_space *mapping,</span>
<span class="quote">&gt;  		 * written to the server&#39;s write cache, but has not yet</span>
<span class="quote">&gt;  		 * been flushed to permanent storage.</span>
<span class="quote">&gt;  		 */</span>
<span class="quote">&gt; -		nr_reclaimable = global_page_state(NR_FILE_DIRTY) +</span>
<span class="quote">&gt; -					global_page_state(NR_UNSTABLE_NFS);</span>
<span class="quote">&gt; +		nr_reclaimable = global_node_page_state(NR_FILE_DIRTY) +</span>
<span class="quote">&gt; +					global_node_page_state(NR_UNSTABLE_NFS);</span>
<span class="quote">&gt;  		gdtc-&gt;avail = global_dirtyable_memory();</span>
<span class="quote">&gt; -		gdtc-&gt;dirty = nr_reclaimable + global_page_state(NR_WRITEBACK);</span>
<span class="quote">&gt; +		gdtc-&gt;dirty = nr_reclaimable + global_node_page_state(NR_WRITEBACK);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  		domain_dirty_limits(gdtc);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; @@ -1914,8 +1906,8 @@ bool wb_over_bg_thresh(struct bdi_writeback *wb)</span>
<span class="quote">&gt;  	 * as we&#39;re trying to decide whether to put more under writeback.</span>
<span class="quote">&gt;  	 */</span>
<span class="quote">&gt;  	gdtc-&gt;avail = global_dirtyable_memory();</span>
<span class="quote">&gt; -	gdtc-&gt;dirty = global_page_state(NR_FILE_DIRTY) +</span>
<span class="quote">&gt; -		      global_page_state(NR_UNSTABLE_NFS);</span>
<span class="quote">&gt; +	gdtc-&gt;dirty = global_node_page_state(NR_FILE_DIRTY) +</span>
<span class="quote">&gt; +		      global_node_page_state(NR_UNSTABLE_NFS);</span>
<span class="quote">&gt;  	domain_dirty_limits(gdtc);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	if (gdtc-&gt;dirty &gt; gdtc-&gt;bg_thresh)</span>
<span class="quote">&gt; @@ -1959,8 +1951,8 @@ void throttle_vm_writeout(gfp_t gfp_mask)</span>
<span class="quote">&gt;                   */</span>
<span class="quote">&gt;                  dirty_thresh += dirty_thresh / 10;      /* wheeee... */</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; -                if (global_page_state(NR_UNSTABLE_NFS) +</span>
<span class="quote">&gt; -			global_page_state(NR_WRITEBACK) &lt;= dirty_thresh)</span>
<span class="quote">&gt; +                if (global_node_page_state(NR_UNSTABLE_NFS) +</span>
<span class="quote">&gt; +			global_node_page_state(NR_WRITEBACK) &lt;= dirty_thresh)</span>
<span class="quote">&gt;                          	break;</span>
<span class="quote">&gt;                  congestion_wait(BLK_RW_ASYNC, HZ/10);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; @@ -1988,8 +1980,8 @@ int dirty_writeback_centisecs_handler(struct ctl_table *table, int write,</span>
<span class="quote">&gt;  void laptop_mode_timer_fn(unsigned long data)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	struct request_queue *q = (struct request_queue *)data;</span>
<span class="quote">&gt; -	int nr_pages = global_page_state(NR_FILE_DIRTY) +</span>
<span class="quote">&gt; -		global_page_state(NR_UNSTABLE_NFS);</span>
<span class="quote">&gt; +	int nr_pages = global_node_page_state(NR_FILE_DIRTY) +</span>
<span class="quote">&gt; +		global_node_page_state(NR_UNSTABLE_NFS);</span>
<span class="quote">&gt;  	struct bdi_writeback *wb;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	/*</span>
<span class="quote">&gt; @@ -2440,7 +2432,7 @@ void account_page_dirtied(struct page *page, struct address_space *mapping)</span>
<span class="quote">&gt;  		wb = inode_to_wb(inode);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  		mem_cgroup_inc_page_stat(page, MEM_CGROUP_STAT_DIRTY);</span>
<span class="quote">&gt; -		__inc_zone_page_state(page, NR_FILE_DIRTY);</span>
<span class="quote">&gt; +		__inc_node_page_state(page, NR_FILE_DIRTY);</span>
<span class="quote">&gt;  		__inc_zone_page_state(page, NR_DIRTIED);</span>
<span class="quote">&gt;  		__inc_wb_stat(wb, WB_RECLAIMABLE);</span>
<span class="quote">&gt;  		__inc_wb_stat(wb, WB_DIRTIED);</span>
<span class="quote">&gt; @@ -2461,7 +2453,7 @@ void account_page_cleaned(struct page *page, struct address_space *mapping,</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	if (mapping_cap_account_dirty(mapping)) {</span>
<span class="quote">&gt;  		mem_cgroup_dec_page_stat(page, MEM_CGROUP_STAT_DIRTY);</span>
<span class="quote">&gt; -		dec_zone_page_state(page, NR_FILE_DIRTY);</span>
<span class="quote">&gt; +		dec_node_page_state(page, NR_FILE_DIRTY);</span>
<span class="quote">&gt;  		dec_wb_stat(wb, WB_RECLAIMABLE);</span>
<span class="quote">&gt;  		task_io_account_cancelled_write(PAGE_SIZE);</span>
<span class="quote">&gt;  	}</span>
<span class="quote">&gt; @@ -2716,7 +2708,7 @@ int clear_page_dirty_for_io(struct page *page)</span>
<span class="quote">&gt;  		wb = unlocked_inode_to_wb_begin(inode, &amp;locked);</span>
<span class="quote">&gt;  		if (TestClearPageDirty(page)) {</span>
<span class="quote">&gt;  			mem_cgroup_dec_page_stat(page, MEM_CGROUP_STAT_DIRTY);</span>
<span class="quote">&gt; -			dec_zone_page_state(page, NR_FILE_DIRTY);</span>
<span class="quote">&gt; +			dec_node_page_state(page, NR_FILE_DIRTY);</span>
<span class="quote">&gt;  			dec_wb_stat(wb, WB_RECLAIMABLE);</span>
<span class="quote">&gt;  			ret = 1;</span>
<span class="quote">&gt;  		}</span>
<span class="quote">&gt; @@ -2757,7 +2749,7 @@ int test_clear_page_writeback(struct page *page)</span>
<span class="quote">&gt;  	}</span>
<span class="quote">&gt;  	if (ret) {</span>
<span class="quote">&gt;  		mem_cgroup_dec_page_stat(page, MEM_CGROUP_STAT_WRITEBACK);</span>
<span class="quote">&gt; -		dec_zone_page_state(page, NR_WRITEBACK);</span>
<span class="quote">&gt; +		dec_node_page_state(page, NR_WRITEBACK);</span>
<span class="quote">&gt;  		inc_zone_page_state(page, NR_WRITTEN);</span>
<span class="quote">&gt;  	}</span>
<span class="quote">&gt;  	unlock_page_memcg(page);</span>
<span class="quote">&gt; @@ -2798,7 +2790,7 @@ int __test_set_page_writeback(struct page *page, bool keep_write)</span>
<span class="quote">&gt;  	}</span>
<span class="quote">&gt;  	if (!ret) {</span>
<span class="quote">&gt;  		mem_cgroup_inc_page_stat(page, MEM_CGROUP_STAT_WRITEBACK);</span>
<span class="quote">&gt; -		inc_zone_page_state(page, NR_WRITEBACK);</span>
<span class="quote">&gt; +		inc_node_page_state(page, NR_WRITEBACK);</span>
<span class="quote">&gt;  	}</span>
<span class="quote">&gt;  	unlock_page_memcg(page);</span>
<span class="quote">&gt;  	return ret;</span>
<span class="quote">&gt; diff --git a/mm/page_alloc.c b/mm/page_alloc.c</span>
<span class="quote">&gt; index cf3523f399e5..6f5120a282c3 100644</span>
<span class="quote">&gt; --- a/mm/page_alloc.c</span>
<span class="quote">&gt; +++ b/mm/page_alloc.c</span>
<span class="quote">&gt; @@ -4180,7 +4180,7 @@ EXPORT_SYMBOL_GPL(si_mem_available);</span>
<span class="quote">&gt;  void si_meminfo(struct sysinfo *val)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	val-&gt;totalram = totalram_pages;</span>
<span class="quote">&gt; -	val-&gt;sharedram = global_page_state(NR_SHMEM);</span>
<span class="quote">&gt; +	val-&gt;sharedram = global_node_page_state(NR_SHMEM);</span>
<span class="quote">&gt;  	val-&gt;freeram = global_page_state(NR_FREE_PAGES);</span>
<span class="quote">&gt;  	val-&gt;bufferram = nr_blockdev_pages();</span>
<span class="quote">&gt;  	val-&gt;totalhigh = totalhigh_pages;</span>
<span class="quote">&gt; @@ -4202,7 +4202,7 @@ void si_meminfo_node(struct sysinfo *val, int nid)</span>
<span class="quote">&gt;  	for (zone_type = 0; zone_type &lt; MAX_NR_ZONES; zone_type++)</span>
<span class="quote">&gt;  		managed_pages += pgdat-&gt;node_zones[zone_type].managed_pages;</span>
<span class="quote">&gt;  	val-&gt;totalram = managed_pages;</span>
<span class="quote">&gt; -	val-&gt;sharedram = sum_zone_node_page_state(nid, NR_SHMEM);</span>
<span class="quote">&gt; +	val-&gt;sharedram = node_page_state(pgdat, NR_SHMEM);</span>
<span class="quote">&gt;  	val-&gt;freeram = sum_zone_node_page_state(nid, NR_FREE_PAGES);</span>
<span class="quote">&gt;  #ifdef CONFIG_HIGHMEM</span>
<span class="quote">&gt;  	for (zone_type = 0; zone_type &lt; MAX_NR_ZONES; zone_type++) {</span>
<span class="quote">&gt; @@ -4309,13 +4309,13 @@ void show_free_areas(unsigned int filter)</span>
<span class="quote">&gt;  		global_node_page_state(NR_INACTIVE_FILE),</span>
<span class="quote">&gt;  		global_node_page_state(NR_ISOLATED_FILE),</span>
<span class="quote">&gt;  		global_node_page_state(NR_UNEVICTABLE),</span>
<span class="quote">&gt; -		global_page_state(NR_FILE_DIRTY),</span>
<span class="quote">&gt; -		global_page_state(NR_WRITEBACK),</span>
<span class="quote">&gt; -		global_page_state(NR_UNSTABLE_NFS),</span>
<span class="quote">&gt; +		global_node_page_state(NR_FILE_DIRTY),</span>
<span class="quote">&gt; +		global_node_page_state(NR_WRITEBACK),</span>
<span class="quote">&gt; +		global_node_page_state(NR_UNSTABLE_NFS),</span>
<span class="quote">&gt;  		global_page_state(NR_SLAB_RECLAIMABLE),</span>
<span class="quote">&gt;  		global_page_state(NR_SLAB_UNRECLAIMABLE),</span>
<span class="quote">&gt;  		global_node_page_state(NR_FILE_MAPPED),</span>
<span class="quote">&gt; -		global_page_state(NR_SHMEM),</span>
<span class="quote">&gt; +		global_node_page_state(NR_SHMEM),</span>
<span class="quote">&gt;  		global_page_state(NR_PAGETABLE),</span>
<span class="quote">&gt;  		global_page_state(NR_BOUNCE),</span>
<span class="quote">&gt;  		global_page_state(NR_FREE_PAGES),</span>
<span class="quote">&gt; @@ -4332,6 +4332,11 @@ void show_free_areas(unsigned int filter)</span>
<span class="quote">&gt;  			&quot; isolated(anon):%lukB&quot;</span>
<span class="quote">&gt;  			&quot; isolated(file):%lukB&quot;</span>
<span class="quote">&gt;  			&quot; mapped:%lukB&quot;</span>
<span class="quote">&gt; +			&quot; dirty:%lukB&quot;</span>
<span class="quote">&gt; +			&quot; writeback:%lukB&quot;</span>
<span class="quote">&gt; +			&quot; shmem:%lukB&quot;</span>
<span class="quote">&gt; +			&quot; writeback_tmp:%lukB&quot;</span>
<span class="quote">&gt; +			&quot; unstable:%lukB&quot;</span>
<span class="quote">&gt;  			&quot; all_unreclaimable? %s&quot;</span>
<span class="quote">&gt;  			&quot;\n&quot;,</span>
<span class="quote">&gt;  			pgdat-&gt;node_id,</span>
<span class="quote">&gt; @@ -4343,6 +4348,11 @@ void show_free_areas(unsigned int filter)</span>
<span class="quote">&gt;  			K(node_page_state(pgdat, NR_ISOLATED_ANON)),</span>
<span class="quote">&gt;  			K(node_page_state(pgdat, NR_ISOLATED_FILE)),</span>
<span class="quote">&gt;  			K(node_page_state(pgdat, NR_FILE_MAPPED)),</span>
<span class="quote">&gt; +			K(node_page_state(pgdat, NR_FILE_DIRTY)),</span>
<span class="quote">&gt; +			K(node_page_state(pgdat, NR_WRITEBACK)),</span>
<span class="quote">&gt; +			K(node_page_state(pgdat, NR_SHMEM)),</span>
<span class="quote">&gt; +			K(node_page_state(pgdat, NR_WRITEBACK_TEMP)),</span>
<span class="quote">&gt; +			K(node_page_state(pgdat, NR_UNSTABLE_NFS)),</span>
<span class="quote">&gt;  			!pgdat_reclaimable(pgdat) ? &quot;yes&quot; : &quot;no&quot;);</span>
<span class="quote">&gt;  	}</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; @@ -4365,19 +4375,14 @@ void show_free_areas(unsigned int filter)</span>
<span class="quote">&gt;  			&quot; present:%lukB&quot;</span>
<span class="quote">&gt;  			&quot; managed:%lukB&quot;</span>
<span class="quote">&gt;  			&quot; mlocked:%lukB&quot;</span>
<span class="quote">&gt; -			&quot; dirty:%lukB&quot;</span>
<span class="quote">&gt; -			&quot; writeback:%lukB&quot;</span>
<span class="quote">&gt; -			&quot; shmem:%lukB&quot;</span>
<span class="quote">&gt;  			&quot; slab_reclaimable:%lukB&quot;</span>
<span class="quote">&gt;  			&quot; slab_unreclaimable:%lukB&quot;</span>
<span class="quote">&gt;  			&quot; kernel_stack:%lukB&quot;</span>
<span class="quote">&gt;  			&quot; pagetables:%lukB&quot;</span>
<span class="quote">&gt; -			&quot; unstable:%lukB&quot;</span>
<span class="quote">&gt;  			&quot; bounce:%lukB&quot;</span>
<span class="quote">&gt;  			&quot; free_pcp:%lukB&quot;</span>
<span class="quote">&gt;  			&quot; local_pcp:%ukB&quot;</span>
<span class="quote">&gt;  			&quot; free_cma:%lukB&quot;</span>
<span class="quote">&gt; -			&quot; writeback_tmp:%lukB&quot;</span>
<span class="quote">&gt;  			&quot; node_pages_scanned:%lu&quot;</span>
<span class="quote">&gt;  			&quot;\n&quot;,</span>
<span class="quote">&gt;  			zone-&gt;name,</span>
<span class="quote">&gt; @@ -4388,20 +4393,15 @@ void show_free_areas(unsigned int filter)</span>
<span class="quote">&gt;  			K(zone-&gt;present_pages),</span>
<span class="quote">&gt;  			K(zone-&gt;managed_pages),</span>
<span class="quote">&gt;  			K(zone_page_state(zone, NR_MLOCK)),</span>
<span class="quote">&gt; -			K(zone_page_state(zone, NR_FILE_DIRTY)),</span>
<span class="quote">&gt; -			K(zone_page_state(zone, NR_WRITEBACK)),</span>
<span class="quote">&gt; -			K(zone_page_state(zone, NR_SHMEM)),</span>
<span class="quote">&gt;  			K(zone_page_state(zone, NR_SLAB_RECLAIMABLE)),</span>
<span class="quote">&gt;  			K(zone_page_state(zone, NR_SLAB_UNRECLAIMABLE)),</span>
<span class="quote">&gt;  			zone_page_state(zone, NR_KERNEL_STACK) *</span>
<span class="quote">&gt;  				THREAD_SIZE / 1024,</span>
<span class="quote">&gt;  			K(zone_page_state(zone, NR_PAGETABLE)),</span>
<span class="quote">&gt; -			K(zone_page_state(zone, NR_UNSTABLE_NFS)),</span>
<span class="quote">&gt;  			K(zone_page_state(zone, NR_BOUNCE)),</span>
<span class="quote">&gt;  			K(free_pcp),</span>
<span class="quote">&gt;  			K(this_cpu_read(zone-&gt;pageset-&gt;pcp.count)),</span>
<span class="quote">&gt;  			K(zone_page_state(zone, NR_FREE_CMA_PAGES)),</span>
<span class="quote">&gt; -			K(zone_page_state(zone, NR_WRITEBACK_TEMP)),</span>
<span class="quote">&gt;  			K(node_page_state(zone-&gt;zone_pgdat, NR_PAGES_SCANNED)));</span>
<span class="quote">&gt;  		printk(&quot;lowmem_reserve[]:&quot;);</span>
<span class="quote">&gt;  		for (i = 0; i &lt; MAX_NR_ZONES; i++)</span>
<span class="quote">&gt; @@ -4444,7 +4444,7 @@ void show_free_areas(unsigned int filter)</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	hugetlb_show_meminfo();</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; -	printk(&quot;%ld total pagecache pages\n&quot;, global_page_state(NR_FILE_PAGES));</span>
<span class="quote">&gt; +	printk(&quot;%ld total pagecache pages\n&quot;, global_node_page_state(NR_FILE_PAGES));</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	show_swap_cache_info();</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt; diff --git a/mm/shmem.c b/mm/shmem.c</span>
<span class="quote">&gt; index 24463b67b6ef..f01d291012d5 100644</span>
<span class="quote">&gt; --- a/mm/shmem.c</span>
<span class="quote">&gt; +++ b/mm/shmem.c</span>
<span class="quote">&gt; @@ -312,8 +312,8 @@ static int shmem_add_to_page_cache(struct page *page,</span>
<span class="quote">&gt;  								 page);</span>
<span class="quote">&gt;  	if (!error) {</span>
<span class="quote">&gt;  		mapping-&gt;nrpages++;</span>
<span class="quote">&gt; -		__inc_zone_page_state(page, NR_FILE_PAGES);</span>
<span class="quote">&gt; -		__inc_zone_page_state(page, NR_SHMEM);</span>
<span class="quote">&gt; +		__inc_node_page_state(page, NR_FILE_PAGES);</span>
<span class="quote">&gt; +		__inc_node_page_state(page, NR_SHMEM);</span>
<span class="quote">&gt;  		spin_unlock_irq(&amp;mapping-&gt;tree_lock);</span>
<span class="quote">&gt;  	} else {</span>
<span class="quote">&gt;  		page-&gt;mapping = NULL;</span>
<span class="quote">&gt; @@ -335,8 +335,8 @@ static void shmem_delete_from_page_cache(struct page *page, void *radswap)</span>
<span class="quote">&gt;  	error = shmem_radix_tree_replace(mapping, page-&gt;index, page, radswap);</span>
<span class="quote">&gt;  	page-&gt;mapping = NULL;</span>
<span class="quote">&gt;  	mapping-&gt;nrpages--;</span>
<span class="quote">&gt; -	__dec_zone_page_state(page, NR_FILE_PAGES);</span>
<span class="quote">&gt; -	__dec_zone_page_state(page, NR_SHMEM);</span>
<span class="quote">&gt; +	__dec_node_page_state(page, NR_FILE_PAGES);</span>
<span class="quote">&gt; +	__dec_node_page_state(page, NR_SHMEM);</span>
<span class="quote">&gt;  	spin_unlock_irq(&amp;mapping-&gt;tree_lock);</span>
<span class="quote">&gt;  	put_page(page);</span>
<span class="quote">&gt;  	BUG_ON(error);</span>
<span class="quote">&gt; @@ -1084,8 +1084,8 @@ static int shmem_replace_page(struct page **pagep, gfp_t gfp,</span>
<span class="quote">&gt;  	error = shmem_radix_tree_replace(swap_mapping, swap_index, oldpage,</span>
<span class="quote">&gt;  								   newpage);</span>
<span class="quote">&gt;  	if (!error) {</span>
<span class="quote">&gt; -		__inc_zone_page_state(newpage, NR_FILE_PAGES);</span>
<span class="quote">&gt; -		__dec_zone_page_state(oldpage, NR_FILE_PAGES);</span>
<span class="quote">&gt; +		__inc_node_page_state(newpage, NR_FILE_PAGES);</span>
<span class="quote">&gt; +		__dec_node_page_state(oldpage, NR_FILE_PAGES);</span>
<span class="quote">&gt;  	}</span>
<span class="quote">&gt;  	spin_unlock_irq(&amp;swap_mapping-&gt;tree_lock);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; diff --git a/mm/swap_state.c b/mm/swap_state.c</span>
<span class="quote">&gt; index c99463ac02fb..c8310a37be3a 100644</span>
<span class="quote">&gt; --- a/mm/swap_state.c</span>
<span class="quote">&gt; +++ b/mm/swap_state.c</span>
<span class="quote">&gt; @@ -95,7 +95,7 @@ int __add_to_swap_cache(struct page *page, swp_entry_t entry)</span>
<span class="quote">&gt;  					entry.val, page);</span>
<span class="quote">&gt;  	if (likely(!error)) {</span>
<span class="quote">&gt;  		address_space-&gt;nrpages++;</span>
<span class="quote">&gt; -		__inc_zone_page_state(page, NR_FILE_PAGES);</span>
<span class="quote">&gt; +		__inc_node_page_state(page, NR_FILE_PAGES);</span>
<span class="quote">&gt;  		INC_CACHE_INFO(add_total);</span>
<span class="quote">&gt;  	}</span>
<span class="quote">&gt;  	spin_unlock_irq(&amp;address_space-&gt;tree_lock);</span>
<span class="quote">&gt; @@ -147,7 +147,7 @@ void __delete_from_swap_cache(struct page *page)</span>
<span class="quote">&gt;  	set_page_private(page, 0);</span>
<span class="quote">&gt;  	ClearPageSwapCache(page);</span>
<span class="quote">&gt;  	address_space-&gt;nrpages--;</span>
<span class="quote">&gt; -	__dec_zone_page_state(page, NR_FILE_PAGES);</span>
<span class="quote">&gt; +	__dec_node_page_state(page, NR_FILE_PAGES);</span>
<span class="quote">&gt;  	INC_CACHE_INFO(del_total);</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; diff --git a/mm/util.c b/mm/util.c</span>
<span class="quote">&gt; index b756ee36f7f0..21cbc0fc2fd4 100644</span>
<span class="quote">&gt; --- a/mm/util.c</span>
<span class="quote">&gt; +++ b/mm/util.c</span>
<span class="quote">&gt; @@ -522,7 +522,7 @@ int __vm_enough_memory(struct mm_struct *mm, long pages, int cap_sys_admin)</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	if (sysctl_overcommit_memory == OVERCOMMIT_GUESS) {</span>
<span class="quote">&gt;  		free = global_page_state(NR_FREE_PAGES);</span>
<span class="quote">&gt; -		free += global_page_state(NR_FILE_PAGES);</span>
<span class="quote">&gt; +		free += global_node_page_state(NR_FILE_PAGES);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  		/*</span>
<span class="quote">&gt;  		 * shmem pages shouldn&#39;t be counted as free in this</span>
<span class="quote">&gt; @@ -530,7 +530,7 @@ int __vm_enough_memory(struct mm_struct *mm, long pages, int cap_sys_admin)</span>
<span class="quote">&gt;  		 * that won&#39;t affect the overall amount of available</span>
<span class="quote">&gt;  		 * memory in the system.</span>
<span class="quote">&gt;  		 */</span>
<span class="quote">&gt; -		free -= global_page_state(NR_SHMEM);</span>
<span class="quote">&gt; +		free -= global_node_page_state(NR_SHMEM);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  		free += get_nr_swap_pages();</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; diff --git a/mm/vmscan.c b/mm/vmscan.c</span>
<span class="quote">&gt; index c6e958079398..4501a9ab1d3f 100644</span>
<span class="quote">&gt; --- a/mm/vmscan.c</span>
<span class="quote">&gt; +++ b/mm/vmscan.c</span>
<span class="quote">&gt; @@ -3594,11 +3594,11 @@ int sysctl_min_unmapped_ratio = 1;</span>
<span class="quote">&gt;   */</span>
<span class="quote">&gt;  int sysctl_min_slab_ratio = 5;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; -static inline unsigned long zone_unmapped_file_pages(struct zone *zone)</span>
<span class="quote">&gt; +static inline unsigned long node_unmapped_file_pages(struct pglist_data *pgdat)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt; -	unsigned long file_mapped = node_page_state(zone-&gt;zone_pgdat, NR_FILE_MAPPED);</span>
<span class="quote">&gt; -	unsigned long file_lru = node_page_state(zone-&gt;zone_pgdat, NR_INACTIVE_FILE) +</span>
<span class="quote">&gt; -		node_page_state(zone-&gt;zone_pgdat, NR_ACTIVE_FILE);</span>
<span class="quote">&gt; +	unsigned long file_mapped = node_page_state(pgdat, NR_FILE_MAPPED);</span>
<span class="quote">&gt; +	unsigned long file_lru = node_page_state(pgdat, NR_INACTIVE_FILE) +</span>
<span class="quote">&gt; +		node_page_state(pgdat, NR_ACTIVE_FILE);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	/*</span>
<span class="quote">&gt;  	 * It&#39;s possible for there to be more file mapped pages than</span>
<span class="quote">&gt; @@ -3617,17 +3617,17 @@ static unsigned long zone_pagecache_reclaimable(struct zone *zone)</span>
<span class="quote">&gt;  	/*</span>
<span class="quote">&gt;  	 * If RECLAIM_UNMAP is set, then all file pages are considered</span>
<span class="quote">&gt;  	 * potentially reclaimable. Otherwise, we have to worry about</span>
<span class="quote">&gt; -	 * pages like swapcache and zone_unmapped_file_pages() provides</span>
<span class="quote">&gt; +	 * pages like swapcache and node_unmapped_file_pages() provides</span>
<span class="quote">&gt;  	 * a better estimate</span>
<span class="quote">&gt;  	 */</span>
<span class="quote">&gt;  	if (zone_reclaim_mode &amp; RECLAIM_UNMAP)</span>
<span class="quote">&gt; -		nr_pagecache_reclaimable = zone_page_state(zone, NR_FILE_PAGES);</span>
<span class="quote">&gt; +		nr_pagecache_reclaimable = node_page_state(zone-&gt;zone_pgdat, NR_FILE_PAGES);</span>
<span class="quote">&gt;  	else</span>
<span class="quote">&gt; -		nr_pagecache_reclaimable = zone_unmapped_file_pages(zone);</span>
<span class="quote">&gt; +		nr_pagecache_reclaimable = node_unmapped_file_pages(zone-&gt;zone_pgdat);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	/* If we can&#39;t clean pages, remove dirty pages from consideration */</span>
<span class="quote">&gt;  	if (!(zone_reclaim_mode &amp; RECLAIM_WRITE))</span>
<span class="quote">&gt; -		delta += zone_page_state(zone, NR_FILE_DIRTY);</span>
<span class="quote">&gt; +		delta += node_page_state(zone-&gt;zone_pgdat, NR_FILE_DIRTY);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	/* Watch for any possible underflows due to delta */</span>
<span class="quote">&gt;  	if (unlikely(delta &gt; nr_pagecache_reclaimable))</span>
<span class="quote">&gt; diff --git a/mm/vmstat.c b/mm/vmstat.c</span>
<span class="quote">&gt; index 12022ed481f0..32c499251174 100644</span>
<span class="quote">&gt; --- a/mm/vmstat.c</span>
<span class="quote">&gt; +++ b/mm/vmstat.c</span>
<span class="quote">&gt; @@ -924,19 +924,13 @@ const char * const vmstat_text[] = {</span>
<span class="quote">&gt;  	&quot;nr_zone_anon_lru&quot;,</span>
<span class="quote">&gt;  	&quot;nr_zone_file_lru&quot;,</span>
<span class="quote">&gt;  	&quot;nr_mlock&quot;,</span>
<span class="quote">&gt; -	&quot;nr_file_pages&quot;,</span>
<span class="quote">&gt; -	&quot;nr_dirty&quot;,</span>
<span class="quote">&gt; -	&quot;nr_writeback&quot;,</span>
<span class="quote">&gt;  	&quot;nr_slab_reclaimable&quot;,</span>
<span class="quote">&gt;  	&quot;nr_slab_unreclaimable&quot;,</span>
<span class="quote">&gt;  	&quot;nr_page_table_pages&quot;,</span>
<span class="quote">&gt;  	&quot;nr_kernel_stack&quot;,</span>
<span class="quote">&gt; -	&quot;nr_unstable&quot;,</span>
<span class="quote">&gt;  	&quot;nr_bounce&quot;,</span>
<span class="quote">&gt;  	&quot;nr_vmscan_write&quot;,</span>
<span class="quote">&gt;  	&quot;nr_vmscan_immediate_reclaim&quot;,</span>
<span class="quote">&gt; -	&quot;nr_writeback_temp&quot;,</span>
<span class="quote">&gt; -	&quot;nr_shmem&quot;,</span>
<span class="quote">&gt;  	&quot;nr_dirtied&quot;,</span>
<span class="quote">&gt;  	&quot;nr_written&quot;,</span>
<span class="quote">&gt;  #if IS_ENABLED(CONFIG_ZSMALLOC)</span>
<span class="quote">&gt; @@ -967,6 +961,12 @@ const char * const vmstat_text[] = {</span>
<span class="quote">&gt;  	&quot;workingset_nodereclaim&quot;,</span>
<span class="quote">&gt;  	&quot;nr_anon_pages&quot;,</span>
<span class="quote">&gt;  	&quot;nr_mapped&quot;,</span>
<span class="quote">&gt; +	&quot;nr_file_pages&quot;,</span>
<span class="quote">&gt; +	&quot;nr_dirty&quot;,</span>
<span class="quote">&gt; +	&quot;nr_writeback&quot;,</span>
<span class="quote">&gt; +	&quot;nr_writeback_temp&quot;,</span>
<span class="quote">&gt; +	&quot;nr_shmem&quot;,</span>
<span class="quote">&gt; +	&quot;nr_unstable&quot;,</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	/* enum writeback_stat_item counters */</span>
<span class="quote">&gt;  	&quot;nr_dirty_threshold&quot;,</span>
<span class="quote">&gt; -- </span>
<span class="quote">&gt; 2.6.4</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; --</span>
<span class="quote">&gt; To unsubscribe, send a message with &#39;unsubscribe linux-mm&#39; in</span>
<span class="quote">&gt; the body to majordomo@kvack.org.  For more info on Linux MM,</span>
<span class="quote">&gt; see: http://www.linux-mm.org/ .</span>
<span class="quote">&gt; Don&#39;t email: &lt;a href=mailto:&quot;dont@kvack.org&quot;&gt; email@kvack.org &lt;/a&gt;</span>
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/arch/s390/appldata/appldata_mem.c b/arch/s390/appldata/appldata_mem.c</span>
<span class="p_header">index edcf2a706942..598df5708501 100644</span>
<span class="p_header">--- a/arch/s390/appldata/appldata_mem.c</span>
<span class="p_header">+++ b/arch/s390/appldata/appldata_mem.c</span>
<span class="p_chunk">@@ -102,7 +102,7 @@</span> <span class="p_context"> static void appldata_get_mem_data(void *data)</span>
 	mem_data-&gt;totalhigh = P2K(val.totalhigh);
 	mem_data-&gt;freehigh  = P2K(val.freehigh);
 	mem_data-&gt;bufferram = P2K(val.bufferram);
<span class="p_del">-	mem_data-&gt;cached    = P2K(global_page_state(NR_FILE_PAGES)</span>
<span class="p_add">+	mem_data-&gt;cached    = P2K(global_node_page_state(NR_FILE_PAGES)</span>
 				- val.bufferram);
 
 	si_swapinfo(&amp;val);
<span class="p_header">diff --git a/arch/tile/mm/pgtable.c b/arch/tile/mm/pgtable.c</span>
<span class="p_header">index c606b0ef2f7e..7cc6ee7f1a58 100644</span>
<span class="p_header">--- a/arch/tile/mm/pgtable.c</span>
<span class="p_header">+++ b/arch/tile/mm/pgtable.c</span>
<span class="p_chunk">@@ -49,16 +49,16 @@</span> <span class="p_context"> void show_mem(unsigned int filter)</span>
 		global_node_page_state(NR_ACTIVE_FILE)),
 	       (global_node_page_state(NR_INACTIVE_ANON) +
 		global_node_page_state(NR_INACTIVE_FILE)),
<span class="p_del">-	       global_page_state(NR_FILE_DIRTY),</span>
<span class="p_del">-	       global_page_state(NR_WRITEBACK),</span>
<span class="p_del">-	       global_page_state(NR_UNSTABLE_NFS),</span>
<span class="p_add">+	       global_node_page_state(NR_FILE_DIRTY),</span>
<span class="p_add">+	       global_node_page_state(NR_WRITEBACK),</span>
<span class="p_add">+	       global_node_page_state(NR_UNSTABLE_NFS),</span>
 	       global_page_state(NR_FREE_PAGES),
 	       (global_page_state(NR_SLAB_RECLAIMABLE) +
 		global_page_state(NR_SLAB_UNRECLAIMABLE)),
 	       global_node_page_state(NR_FILE_MAPPED),
 	       global_page_state(NR_PAGETABLE),
 	       global_page_state(NR_BOUNCE),
<span class="p_del">-	       global_page_state(NR_FILE_PAGES),</span>
<span class="p_add">+	       global_node_page_state(NR_FILE_PAGES),</span>
 	       get_nr_swap_pages());
 
 	for_each_zone(zone) {
<span class="p_header">diff --git a/drivers/base/node.c b/drivers/base/node.c</span>
<span class="p_header">index 897b6bcb36be..ec733919bc6b 100644</span>
<span class="p_header">--- a/drivers/base/node.c</span>
<span class="p_header">+++ b/drivers/base/node.c</span>
<span class="p_chunk">@@ -116,18 +116,18 @@</span> <span class="p_context"> static ssize_t node_read_meminfo(struct device *dev,</span>
 		       &quot;Node %d AnonHugePages:  %8lu kB\n&quot;
 #endif
 			,
<span class="p_del">-		       nid, K(sum_zone_node_page_state(nid, NR_FILE_DIRTY)),</span>
<span class="p_del">-		       nid, K(sum_zone_node_page_state(nid, NR_WRITEBACK)),</span>
<span class="p_del">-		       nid, K(sum_zone_node_page_state(nid, NR_FILE_PAGES)),</span>
<span class="p_add">+		       nid, K(node_page_state(pgdat, NR_FILE_DIRTY)),</span>
<span class="p_add">+		       nid, K(node_page_state(pgdat, NR_WRITEBACK)),</span>
<span class="p_add">+		       nid, K(node_page_state(pgdat, NR_FILE_PAGES)),</span>
 		       nid, K(node_page_state(pgdat, NR_FILE_MAPPED)),
 		       nid, K(node_page_state(pgdat, NR_ANON_MAPPED)),
 		       nid, K(i.sharedram),
 		       nid, sum_zone_node_page_state(nid, NR_KERNEL_STACK) *
 				THREAD_SIZE / 1024,
 		       nid, K(sum_zone_node_page_state(nid, NR_PAGETABLE)),
<span class="p_del">-		       nid, K(sum_zone_node_page_state(nid, NR_UNSTABLE_NFS)),</span>
<span class="p_add">+		       nid, K(node_page_state(pgdat, NR_UNSTABLE_NFS)),</span>
 		       nid, K(sum_zone_node_page_state(nid, NR_BOUNCE)),
<span class="p_del">-		       nid, K(sum_zone_node_page_state(nid, NR_WRITEBACK_TEMP)),</span>
<span class="p_add">+		       nid, K(node_page_state(pgdat, NR_WRITEBACK_TEMP)),</span>
 		       nid, K(sum_zone_node_page_state(nid, NR_SLAB_RECLAIMABLE) +
 				sum_zone_node_page_state(nid, NR_SLAB_UNRECLAIMABLE)),
 		       nid, K(sum_zone_node_page_state(nid, NR_SLAB_RECLAIMABLE)),
<span class="p_header">diff --git a/drivers/staging/android/lowmemorykiller.c b/drivers/staging/android/lowmemorykiller.c</span>
<span class="p_header">index 93dbcc38eb0f..45a1b4ec4ca3 100644</span>
<span class="p_header">--- a/drivers/staging/android/lowmemorykiller.c</span>
<span class="p_header">+++ b/drivers/staging/android/lowmemorykiller.c</span>
<span class="p_chunk">@@ -91,8 +91,8 @@</span> <span class="p_context"> static unsigned long lowmem_scan(struct shrinker *s, struct shrink_control *sc)</span>
 	short selected_oom_score_adj;
 	int array_size = ARRAY_SIZE(lowmem_adj);
 	int other_free = global_page_state(NR_FREE_PAGES) - totalreserve_pages;
<span class="p_del">-	int other_file = global_page_state(NR_FILE_PAGES) -</span>
<span class="p_del">-						global_page_state(NR_SHMEM) -</span>
<span class="p_add">+	int other_file = global_node_page_state(NR_FILE_PAGES) -</span>
<span class="p_add">+						global_node_page_state(NR_SHMEM) -</span>
 						total_swapcache_pages();
 
 	if (lowmem_adj_size &lt; array_size)
<span class="p_header">diff --git a/fs/fs-writeback.c b/fs/fs-writeback.c</span>
<span class="p_header">index 989a2cef6b76..fd68f8efb440 100644</span>
<span class="p_header">--- a/fs/fs-writeback.c</span>
<span class="p_header">+++ b/fs/fs-writeback.c</span>
<span class="p_chunk">@@ -1771,8 +1771,8 @@</span> <span class="p_context"> static struct wb_writeback_work *get_next_work_item(struct bdi_writeback *wb)</span>
  */
 static unsigned long get_nr_dirty_pages(void)
 {
<span class="p_del">-	return global_page_state(NR_FILE_DIRTY) +</span>
<span class="p_del">-		global_page_state(NR_UNSTABLE_NFS) +</span>
<span class="p_add">+	return global_node_page_state(NR_FILE_DIRTY) +</span>
<span class="p_add">+		global_node_page_state(NR_UNSTABLE_NFS) +</span>
 		get_nr_dirty_inodes();
 }
 
<span class="p_header">diff --git a/fs/fuse/file.c b/fs/fuse/file.c</span>
<span class="p_header">index 9154f8679024..2382f22a2a8b 100644</span>
<span class="p_header">--- a/fs/fuse/file.c</span>
<span class="p_header">+++ b/fs/fuse/file.c</span>
<span class="p_chunk">@@ -1452,7 +1452,7 @@</span> <span class="p_context"> static void fuse_writepage_finish(struct fuse_conn *fc, struct fuse_req *req)</span>
 	list_del(&amp;req-&gt;writepages_entry);
 	for (i = 0; i &lt; req-&gt;num_pages; i++) {
 		dec_wb_stat(&amp;bdi-&gt;wb, WB_WRITEBACK);
<span class="p_del">-		dec_zone_page_state(req-&gt;pages[i], NR_WRITEBACK_TEMP);</span>
<span class="p_add">+		dec_node_page_state(req-&gt;pages[i], NR_WRITEBACK_TEMP);</span>
 		wb_writeout_inc(&amp;bdi-&gt;wb);
 	}
 	wake_up(&amp;fi-&gt;page_waitq);
<span class="p_chunk">@@ -1642,7 +1642,7 @@</span> <span class="p_context"> static int fuse_writepage_locked(struct page *page)</span>
 	req-&gt;inode = inode;
 
 	inc_wb_stat(&amp;inode_to_bdi(inode)-&gt;wb, WB_WRITEBACK);
<span class="p_del">-	inc_zone_page_state(tmp_page, NR_WRITEBACK_TEMP);</span>
<span class="p_add">+	inc_node_page_state(tmp_page, NR_WRITEBACK_TEMP);</span>
 
 	spin_lock(&amp;fc-&gt;lock);
 	list_add(&amp;req-&gt;writepages_entry, &amp;fi-&gt;writepages);
<span class="p_chunk">@@ -1756,7 +1756,7 @@</span> <span class="p_context"> static bool fuse_writepage_in_flight(struct fuse_req *new_req,</span>
 		spin_unlock(&amp;fc-&gt;lock);
 
 		dec_wb_stat(&amp;bdi-&gt;wb, WB_WRITEBACK);
<span class="p_del">-		dec_zone_page_state(page, NR_WRITEBACK_TEMP);</span>
<span class="p_add">+		dec_node_page_state(page, NR_WRITEBACK_TEMP);</span>
 		wb_writeout_inc(&amp;bdi-&gt;wb);
 		fuse_writepage_free(fc, new_req);
 		fuse_request_free(new_req);
<span class="p_chunk">@@ -1855,7 +1855,7 @@</span> <span class="p_context"> static int fuse_writepages_fill(struct page *page,</span>
 	req-&gt;page_descs[req-&gt;num_pages].length = PAGE_SIZE;
 
 	inc_wb_stat(&amp;inode_to_bdi(inode)-&gt;wb, WB_WRITEBACK);
<span class="p_del">-	inc_zone_page_state(tmp_page, NR_WRITEBACK_TEMP);</span>
<span class="p_add">+	inc_node_page_state(tmp_page, NR_WRITEBACK_TEMP);</span>
 
 	err = 0;
 	if (is_writeback &amp;&amp; fuse_writepage_in_flight(req, page)) {
<span class="p_header">diff --git a/fs/nfs/internal.h b/fs/nfs/internal.h</span>
<span class="p_header">index 6b89fdf2c7fa..722731e16648 100644</span>
<span class="p_header">--- a/fs/nfs/internal.h</span>
<span class="p_header">+++ b/fs/nfs/internal.h</span>
<span class="p_chunk">@@ -653,7 +653,7 @@</span> <span class="p_context"> void nfs_mark_page_unstable(struct page *page, struct nfs_commit_info *cinfo)</span>
 	if (!cinfo-&gt;dreq) {
 		struct inode *inode = page_file_mapping(page)-&gt;host;
 
<span class="p_del">-		inc_zone_page_state(page, NR_UNSTABLE_NFS);</span>
<span class="p_add">+		inc_node_page_state(page, NR_UNSTABLE_NFS);</span>
 		inc_wb_stat(&amp;inode_to_bdi(inode)-&gt;wb, WB_RECLAIMABLE);
 		__mark_inode_dirty(inode, I_DIRTY_DATASYNC);
 	}
<span class="p_header">diff --git a/fs/nfs/write.c b/fs/nfs/write.c</span>
<span class="p_header">index 3087fb6f1983..4715549be0c3 100644</span>
<span class="p_header">--- a/fs/nfs/write.c</span>
<span class="p_header">+++ b/fs/nfs/write.c</span>
<span class="p_chunk">@@ -887,7 +887,7 @@</span> <span class="p_context"> nfs_mark_request_commit(struct nfs_page *req, struct pnfs_layout_segment *lseg,</span>
 static void
 nfs_clear_page_commit(struct page *page)
 {
<span class="p_del">-	dec_zone_page_state(page, NR_UNSTABLE_NFS);</span>
<span class="p_add">+	dec_node_page_state(page, NR_UNSTABLE_NFS);</span>
 	dec_wb_stat(&amp;inode_to_bdi(page_file_mapping(page)-&gt;host)-&gt;wb,
 		    WB_RECLAIMABLE);
 }
<span class="p_header">diff --git a/fs/proc/meminfo.c b/fs/proc/meminfo.c</span>
<span class="p_header">index 076afb43fc56..6cb9ea36d0fc 100644</span>
<span class="p_header">--- a/fs/proc/meminfo.c</span>
<span class="p_header">+++ b/fs/proc/meminfo.c</span>
<span class="p_chunk">@@ -40,7 +40,7 @@</span> <span class="p_context"> static int meminfo_proc_show(struct seq_file *m, void *v)</span>
 	si_swapinfo(&amp;i);
 	committed = percpu_counter_read_positive(&amp;vm_committed_as);
 
<span class="p_del">-	cached = global_page_state(NR_FILE_PAGES) -</span>
<span class="p_add">+	cached = global_node_page_state(NR_FILE_PAGES) -</span>
 			total_swapcache_pages() - i.bufferram;
 	if (cached &lt; 0)
 		cached = 0;
<span class="p_chunk">@@ -136,8 +136,8 @@</span> <span class="p_context"> static int meminfo_proc_show(struct seq_file *m, void *v)</span>
 #endif
 		K(i.totalswap),
 		K(i.freeswap),
<span class="p_del">-		K(global_page_state(NR_FILE_DIRTY)),</span>
<span class="p_del">-		K(global_page_state(NR_WRITEBACK)),</span>
<span class="p_add">+		K(global_node_page_state(NR_FILE_DIRTY)),</span>
<span class="p_add">+		K(global_node_page_state(NR_WRITEBACK)),</span>
 		K(global_node_page_state(NR_ANON_MAPPED)),
 		K(global_node_page_state(NR_FILE_MAPPED)),
 		K(i.sharedram),
<span class="p_chunk">@@ -150,9 +150,9 @@</span> <span class="p_context"> static int meminfo_proc_show(struct seq_file *m, void *v)</span>
 #ifdef CONFIG_QUICKLIST
 		K(quicklist_total_size()),
 #endif
<span class="p_del">-		K(global_page_state(NR_UNSTABLE_NFS)),</span>
<span class="p_add">+		K(global_node_page_state(NR_UNSTABLE_NFS)),</span>
 		K(global_page_state(NR_BOUNCE)),
<span class="p_del">-		K(global_page_state(NR_WRITEBACK_TEMP)),</span>
<span class="p_add">+		K(global_node_page_state(NR_WRITEBACK_TEMP)),</span>
 		K(vm_commit_limit()),
 		K(committed),
 		(unsigned long)VMALLOC_TOTAL &gt;&gt; 10,
<span class="p_header">diff --git a/include/linux/mmzone.h b/include/linux/mmzone.h</span>
<span class="p_header">index 6b1fea6cde9a..9924b46e3a13 100644</span>
<span class="p_header">--- a/include/linux/mmzone.h</span>
<span class="p_header">+++ b/include/linux/mmzone.h</span>
<span class="p_chunk">@@ -115,20 +115,14 @@</span> <span class="p_context"> enum zone_stat_item {</span>
 	NR_ZONE_LRU_ANON = NR_ZONE_LRU_BASE,
 	NR_ZONE_LRU_FILE,
 	NR_MLOCK,		/* mlock()ed pages found and moved off LRU */
<span class="p_del">-	NR_FILE_PAGES,</span>
<span class="p_del">-	NR_FILE_DIRTY,</span>
<span class="p_del">-	NR_WRITEBACK,</span>
 	NR_SLAB_RECLAIMABLE,
 	NR_SLAB_UNRECLAIMABLE,
 	NR_PAGETABLE,		/* used for pagetables */
 	NR_KERNEL_STACK,
 	/* Second 128 byte cacheline */
<span class="p_del">-	NR_UNSTABLE_NFS,	/* NFS unstable pages */</span>
 	NR_BOUNCE,
 	NR_VMSCAN_WRITE,
 	NR_VMSCAN_IMMEDIATE,	/* Prioritise for reclaim when writeback ends */
<span class="p_del">-	NR_WRITEBACK_TEMP,	/* Writeback using temporary buffers */</span>
<span class="p_del">-	NR_SHMEM,		/* shmem pages (included tmpfs/GEM pages) */</span>
 	NR_DIRTIED,		/* page dirtyings since bootup */
 	NR_WRITTEN,		/* page writings since bootup */
 #if IS_ENABLED(CONFIG_ZSMALLOC)
<span class="p_chunk">@@ -162,6 +156,12 @@</span> <span class="p_context"> enum node_stat_item {</span>
 	NR_ANON_MAPPED,	/* Mapped anonymous pages */
 	NR_FILE_MAPPED,	/* pagecache pages mapped into pagetables.
 			   only modified from process context */
<span class="p_add">+	NR_FILE_PAGES,</span>
<span class="p_add">+	NR_FILE_DIRTY,</span>
<span class="p_add">+	NR_WRITEBACK,</span>
<span class="p_add">+	NR_WRITEBACK_TEMP,	/* Writeback using temporary buffers */</span>
<span class="p_add">+	NR_SHMEM,		/* shmem pages (included tmpfs/GEM pages) */</span>
<span class="p_add">+	NR_UNSTABLE_NFS,	/* NFS unstable pages */</span>
 	NR_VM_NODE_STAT_ITEMS
 };
 
<span class="p_header">diff --git a/include/trace/events/writeback.h b/include/trace/events/writeback.h</span>
<span class="p_header">index 73614ce1d204..c581d9c04ca5 100644</span>
<span class="p_header">--- a/include/trace/events/writeback.h</span>
<span class="p_header">+++ b/include/trace/events/writeback.h</span>
<span class="p_chunk">@@ -412,9 +412,9 @@</span> <span class="p_context"> TRACE_EVENT(global_dirty_state,</span>
 	),
 
 	TP_fast_assign(
<span class="p_del">-		__entry-&gt;nr_dirty	= global_page_state(NR_FILE_DIRTY);</span>
<span class="p_del">-		__entry-&gt;nr_writeback	= global_page_state(NR_WRITEBACK);</span>
<span class="p_del">-		__entry-&gt;nr_unstable	= global_page_state(NR_UNSTABLE_NFS);</span>
<span class="p_add">+		__entry-&gt;nr_dirty	= global_node_page_state(NR_FILE_DIRTY);</span>
<span class="p_add">+		__entry-&gt;nr_writeback	= global_node_page_state(NR_WRITEBACK);</span>
<span class="p_add">+		__entry-&gt;nr_unstable	= global_node_page_state(NR_UNSTABLE_NFS);</span>
 		__entry-&gt;nr_dirtied	= global_page_state(NR_DIRTIED);
 		__entry-&gt;nr_written	= global_page_state(NR_WRITTEN);
 		__entry-&gt;background_thresh = background_thresh;
<span class="p_header">diff --git a/mm/filemap.c b/mm/filemap.c</span>
<span class="p_header">index d50619adfd7f..b99035dd2288 100644</span>
<span class="p_header">--- a/mm/filemap.c</span>
<span class="p_header">+++ b/mm/filemap.c</span>
<span class="p_chunk">@@ -209,9 +209,9 @@</span> <span class="p_context"> void __delete_from_page_cache(struct page *page, void *shadow)</span>
 
 	/* hugetlb pages do not participate in page cache accounting. */
 	if (!PageHuge(page))
<span class="p_del">-		__dec_zone_page_state(page, NR_FILE_PAGES);</span>
<span class="p_add">+		__dec_node_page_state(page, NR_FILE_PAGES);</span>
 	if (PageSwapBacked(page))
<span class="p_del">-		__dec_zone_page_state(page, NR_SHMEM);</span>
<span class="p_add">+		__dec_node_page_state(page, NR_SHMEM);</span>
 
 	/*
 	 * At this point page must be either written or cleaned by truncate.
<span class="p_chunk">@@ -549,9 +549,9 @@</span> <span class="p_context"> int replace_page_cache_page(struct page *old, struct page *new, gfp_t gfp_mask)</span>
 		 * hugetlb pages do not participate in page cache accounting.
 		 */
 		if (!PageHuge(new))
<span class="p_del">-			__inc_zone_page_state(new, NR_FILE_PAGES);</span>
<span class="p_add">+			__inc_node_page_state(new, NR_FILE_PAGES);</span>
 		if (PageSwapBacked(new))
<span class="p_del">-			__inc_zone_page_state(new, NR_SHMEM);</span>
<span class="p_add">+			__inc_node_page_state(new, NR_SHMEM);</span>
 		spin_unlock_irqrestore(&amp;mapping-&gt;tree_lock, flags);
 		mem_cgroup_migrate(old, new);
 		radix_tree_preload_end();
<span class="p_chunk">@@ -658,7 +658,7 @@</span> <span class="p_context"> static int __add_to_page_cache_locked(struct page *page,</span>
 
 	/* hugetlb pages do not participate in page cache accounting. */
 	if (!huge)
<span class="p_del">-		__inc_zone_page_state(page, NR_FILE_PAGES);</span>
<span class="p_add">+		__inc_node_page_state(page, NR_FILE_PAGES);</span>
 	spin_unlock_irq(&amp;mapping-&gt;tree_lock);
 	if (!huge)
 		mem_cgroup_commit_charge(page, memcg, false, false);
<span class="p_header">diff --git a/mm/migrate.c b/mm/migrate.c</span>
<span class="p_header">index 1582c07205c6..d3fe4cfc2808 100644</span>
<span class="p_header">--- a/mm/migrate.c</span>
<span class="p_header">+++ b/mm/migrate.c</span>
<span class="p_chunk">@@ -505,15 +505,15 @@</span> <span class="p_context"> int migrate_page_move_mapping(struct address_space *mapping,</span>
 	 * are mapped to swap space.
 	 */
 	if (newzone != oldzone) {
<span class="p_del">-		__dec_zone_state(oldzone, NR_FILE_PAGES);</span>
<span class="p_del">-		__inc_zone_state(newzone, NR_FILE_PAGES);</span>
<span class="p_add">+		__dec_node_state(oldzone-&gt;zone_pgdat, NR_FILE_PAGES);</span>
<span class="p_add">+		__inc_node_state(newzone-&gt;zone_pgdat, NR_FILE_PAGES);</span>
 		if (PageSwapBacked(page) &amp;&amp; !PageSwapCache(page)) {
<span class="p_del">-			__dec_zone_state(oldzone, NR_SHMEM);</span>
<span class="p_del">-			__inc_zone_state(newzone, NR_SHMEM);</span>
<span class="p_add">+			__dec_node_state(oldzone-&gt;zone_pgdat, NR_SHMEM);</span>
<span class="p_add">+			__inc_node_state(newzone-&gt;zone_pgdat, NR_SHMEM);</span>
 		}
 		if (dirty &amp;&amp; mapping_cap_account_dirty(mapping)) {
<span class="p_del">-			__dec_zone_state(oldzone, NR_FILE_DIRTY);</span>
<span class="p_del">-			__inc_zone_state(newzone, NR_FILE_DIRTY);</span>
<span class="p_add">+			__dec_node_state(oldzone-&gt;zone_pgdat, NR_FILE_DIRTY);</span>
<span class="p_add">+			__inc_node_state(newzone-&gt;zone_pgdat, NR_FILE_DIRTY);</span>
 		}
 	}
 	local_irq_enable();
<span class="p_header">diff --git a/mm/page-writeback.c b/mm/page-writeback.c</span>
<span class="p_header">index a2b24d5ea43a..aa9fa1eb8b80 100644</span>
<span class="p_header">--- a/mm/page-writeback.c</span>
<span class="p_header">+++ b/mm/page-writeback.c</span>
<span class="p_chunk">@@ -471,20 +471,12 @@</span> <span class="p_context"> static unsigned long node_dirty_limit(struct pglist_data *pgdat)</span>
  */
 bool node_dirty_ok(struct pglist_data *pgdat)
 {
<span class="p_del">-	int z;</span>
 	unsigned long limit = node_dirty_limit(pgdat);
 	unsigned long nr_pages = 0;
 
<span class="p_del">-	for (z = 0; z &lt; MAX_NR_ZONES; z++) {</span>
<span class="p_del">-		struct zone *zone = pgdat-&gt;node_zones + z;</span>
<span class="p_del">-</span>
<span class="p_del">-		if (!populated_zone(zone))</span>
<span class="p_del">-			continue;</span>
<span class="p_del">-</span>
<span class="p_del">-		nr_pages += zone_page_state(zone, NR_FILE_DIRTY);</span>
<span class="p_del">-		nr_pages += zone_page_state(zone, NR_UNSTABLE_NFS);</span>
<span class="p_del">-		nr_pages += zone_page_state(zone, NR_WRITEBACK);</span>
<span class="p_del">-	}</span>
<span class="p_add">+	nr_pages += node_page_state(pgdat, NR_FILE_DIRTY);</span>
<span class="p_add">+	nr_pages += node_page_state(pgdat, NR_UNSTABLE_NFS);</span>
<span class="p_add">+	nr_pages += node_page_state(pgdat, NR_WRITEBACK);</span>
 
 	return nr_pages &lt;= limit;
 }
<span class="p_chunk">@@ -1574,10 +1566,10 @@</span> <span class="p_context"> static void balance_dirty_pages(struct address_space *mapping,</span>
 		 * written to the server&#39;s write cache, but has not yet
 		 * been flushed to permanent storage.
 		 */
<span class="p_del">-		nr_reclaimable = global_page_state(NR_FILE_DIRTY) +</span>
<span class="p_del">-					global_page_state(NR_UNSTABLE_NFS);</span>
<span class="p_add">+		nr_reclaimable = global_node_page_state(NR_FILE_DIRTY) +</span>
<span class="p_add">+					global_node_page_state(NR_UNSTABLE_NFS);</span>
 		gdtc-&gt;avail = global_dirtyable_memory();
<span class="p_del">-		gdtc-&gt;dirty = nr_reclaimable + global_page_state(NR_WRITEBACK);</span>
<span class="p_add">+		gdtc-&gt;dirty = nr_reclaimable + global_node_page_state(NR_WRITEBACK);</span>
 
 		domain_dirty_limits(gdtc);
 
<span class="p_chunk">@@ -1914,8 +1906,8 @@</span> <span class="p_context"> bool wb_over_bg_thresh(struct bdi_writeback *wb)</span>
 	 * as we&#39;re trying to decide whether to put more under writeback.
 	 */
 	gdtc-&gt;avail = global_dirtyable_memory();
<span class="p_del">-	gdtc-&gt;dirty = global_page_state(NR_FILE_DIRTY) +</span>
<span class="p_del">-		      global_page_state(NR_UNSTABLE_NFS);</span>
<span class="p_add">+	gdtc-&gt;dirty = global_node_page_state(NR_FILE_DIRTY) +</span>
<span class="p_add">+		      global_node_page_state(NR_UNSTABLE_NFS);</span>
 	domain_dirty_limits(gdtc);
 
 	if (gdtc-&gt;dirty &gt; gdtc-&gt;bg_thresh)
<span class="p_chunk">@@ -1959,8 +1951,8 @@</span> <span class="p_context"> void throttle_vm_writeout(gfp_t gfp_mask)</span>
                  */
                 dirty_thresh += dirty_thresh / 10;      /* wheeee... */
 
<span class="p_del">-                if (global_page_state(NR_UNSTABLE_NFS) +</span>
<span class="p_del">-			global_page_state(NR_WRITEBACK) &lt;= dirty_thresh)</span>
<span class="p_add">+                if (global_node_page_state(NR_UNSTABLE_NFS) +</span>
<span class="p_add">+			global_node_page_state(NR_WRITEBACK) &lt;= dirty_thresh)</span>
                         	break;
                 congestion_wait(BLK_RW_ASYNC, HZ/10);
 
<span class="p_chunk">@@ -1988,8 +1980,8 @@</span> <span class="p_context"> int dirty_writeback_centisecs_handler(struct ctl_table *table, int write,</span>
 void laptop_mode_timer_fn(unsigned long data)
 {
 	struct request_queue *q = (struct request_queue *)data;
<span class="p_del">-	int nr_pages = global_page_state(NR_FILE_DIRTY) +</span>
<span class="p_del">-		global_page_state(NR_UNSTABLE_NFS);</span>
<span class="p_add">+	int nr_pages = global_node_page_state(NR_FILE_DIRTY) +</span>
<span class="p_add">+		global_node_page_state(NR_UNSTABLE_NFS);</span>
 	struct bdi_writeback *wb;
 
 	/*
<span class="p_chunk">@@ -2440,7 +2432,7 @@</span> <span class="p_context"> void account_page_dirtied(struct page *page, struct address_space *mapping)</span>
 		wb = inode_to_wb(inode);
 
 		mem_cgroup_inc_page_stat(page, MEM_CGROUP_STAT_DIRTY);
<span class="p_del">-		__inc_zone_page_state(page, NR_FILE_DIRTY);</span>
<span class="p_add">+		__inc_node_page_state(page, NR_FILE_DIRTY);</span>
 		__inc_zone_page_state(page, NR_DIRTIED);
 		__inc_wb_stat(wb, WB_RECLAIMABLE);
 		__inc_wb_stat(wb, WB_DIRTIED);
<span class="p_chunk">@@ -2461,7 +2453,7 @@</span> <span class="p_context"> void account_page_cleaned(struct page *page, struct address_space *mapping,</span>
 {
 	if (mapping_cap_account_dirty(mapping)) {
 		mem_cgroup_dec_page_stat(page, MEM_CGROUP_STAT_DIRTY);
<span class="p_del">-		dec_zone_page_state(page, NR_FILE_DIRTY);</span>
<span class="p_add">+		dec_node_page_state(page, NR_FILE_DIRTY);</span>
 		dec_wb_stat(wb, WB_RECLAIMABLE);
 		task_io_account_cancelled_write(PAGE_SIZE);
 	}
<span class="p_chunk">@@ -2716,7 +2708,7 @@</span> <span class="p_context"> int clear_page_dirty_for_io(struct page *page)</span>
 		wb = unlocked_inode_to_wb_begin(inode, &amp;locked);
 		if (TestClearPageDirty(page)) {
 			mem_cgroup_dec_page_stat(page, MEM_CGROUP_STAT_DIRTY);
<span class="p_del">-			dec_zone_page_state(page, NR_FILE_DIRTY);</span>
<span class="p_add">+			dec_node_page_state(page, NR_FILE_DIRTY);</span>
 			dec_wb_stat(wb, WB_RECLAIMABLE);
 			ret = 1;
 		}
<span class="p_chunk">@@ -2757,7 +2749,7 @@</span> <span class="p_context"> int test_clear_page_writeback(struct page *page)</span>
 	}
 	if (ret) {
 		mem_cgroup_dec_page_stat(page, MEM_CGROUP_STAT_WRITEBACK);
<span class="p_del">-		dec_zone_page_state(page, NR_WRITEBACK);</span>
<span class="p_add">+		dec_node_page_state(page, NR_WRITEBACK);</span>
 		inc_zone_page_state(page, NR_WRITTEN);
 	}
 	unlock_page_memcg(page);
<span class="p_chunk">@@ -2798,7 +2790,7 @@</span> <span class="p_context"> int __test_set_page_writeback(struct page *page, bool keep_write)</span>
 	}
 	if (!ret) {
 		mem_cgroup_inc_page_stat(page, MEM_CGROUP_STAT_WRITEBACK);
<span class="p_del">-		inc_zone_page_state(page, NR_WRITEBACK);</span>
<span class="p_add">+		inc_node_page_state(page, NR_WRITEBACK);</span>
 	}
 	unlock_page_memcg(page);
 	return ret;
<span class="p_header">diff --git a/mm/page_alloc.c b/mm/page_alloc.c</span>
<span class="p_header">index cf3523f399e5..6f5120a282c3 100644</span>
<span class="p_header">--- a/mm/page_alloc.c</span>
<span class="p_header">+++ b/mm/page_alloc.c</span>
<span class="p_chunk">@@ -4180,7 +4180,7 @@</span> <span class="p_context"> EXPORT_SYMBOL_GPL(si_mem_available);</span>
 void si_meminfo(struct sysinfo *val)
 {
 	val-&gt;totalram = totalram_pages;
<span class="p_del">-	val-&gt;sharedram = global_page_state(NR_SHMEM);</span>
<span class="p_add">+	val-&gt;sharedram = global_node_page_state(NR_SHMEM);</span>
 	val-&gt;freeram = global_page_state(NR_FREE_PAGES);
 	val-&gt;bufferram = nr_blockdev_pages();
 	val-&gt;totalhigh = totalhigh_pages;
<span class="p_chunk">@@ -4202,7 +4202,7 @@</span> <span class="p_context"> void si_meminfo_node(struct sysinfo *val, int nid)</span>
 	for (zone_type = 0; zone_type &lt; MAX_NR_ZONES; zone_type++)
 		managed_pages += pgdat-&gt;node_zones[zone_type].managed_pages;
 	val-&gt;totalram = managed_pages;
<span class="p_del">-	val-&gt;sharedram = sum_zone_node_page_state(nid, NR_SHMEM);</span>
<span class="p_add">+	val-&gt;sharedram = node_page_state(pgdat, NR_SHMEM);</span>
 	val-&gt;freeram = sum_zone_node_page_state(nid, NR_FREE_PAGES);
 #ifdef CONFIG_HIGHMEM
 	for (zone_type = 0; zone_type &lt; MAX_NR_ZONES; zone_type++) {
<span class="p_chunk">@@ -4309,13 +4309,13 @@</span> <span class="p_context"> void show_free_areas(unsigned int filter)</span>
 		global_node_page_state(NR_INACTIVE_FILE),
 		global_node_page_state(NR_ISOLATED_FILE),
 		global_node_page_state(NR_UNEVICTABLE),
<span class="p_del">-		global_page_state(NR_FILE_DIRTY),</span>
<span class="p_del">-		global_page_state(NR_WRITEBACK),</span>
<span class="p_del">-		global_page_state(NR_UNSTABLE_NFS),</span>
<span class="p_add">+		global_node_page_state(NR_FILE_DIRTY),</span>
<span class="p_add">+		global_node_page_state(NR_WRITEBACK),</span>
<span class="p_add">+		global_node_page_state(NR_UNSTABLE_NFS),</span>
 		global_page_state(NR_SLAB_RECLAIMABLE),
 		global_page_state(NR_SLAB_UNRECLAIMABLE),
 		global_node_page_state(NR_FILE_MAPPED),
<span class="p_del">-		global_page_state(NR_SHMEM),</span>
<span class="p_add">+		global_node_page_state(NR_SHMEM),</span>
 		global_page_state(NR_PAGETABLE),
 		global_page_state(NR_BOUNCE),
 		global_page_state(NR_FREE_PAGES),
<span class="p_chunk">@@ -4332,6 +4332,11 @@</span> <span class="p_context"> void show_free_areas(unsigned int filter)</span>
 			&quot; isolated(anon):%lukB&quot;
 			&quot; isolated(file):%lukB&quot;
 			&quot; mapped:%lukB&quot;
<span class="p_add">+			&quot; dirty:%lukB&quot;</span>
<span class="p_add">+			&quot; writeback:%lukB&quot;</span>
<span class="p_add">+			&quot; shmem:%lukB&quot;</span>
<span class="p_add">+			&quot; writeback_tmp:%lukB&quot;</span>
<span class="p_add">+			&quot; unstable:%lukB&quot;</span>
 			&quot; all_unreclaimable? %s&quot;
 			&quot;\n&quot;,
 			pgdat-&gt;node_id,
<span class="p_chunk">@@ -4343,6 +4348,11 @@</span> <span class="p_context"> void show_free_areas(unsigned int filter)</span>
 			K(node_page_state(pgdat, NR_ISOLATED_ANON)),
 			K(node_page_state(pgdat, NR_ISOLATED_FILE)),
 			K(node_page_state(pgdat, NR_FILE_MAPPED)),
<span class="p_add">+			K(node_page_state(pgdat, NR_FILE_DIRTY)),</span>
<span class="p_add">+			K(node_page_state(pgdat, NR_WRITEBACK)),</span>
<span class="p_add">+			K(node_page_state(pgdat, NR_SHMEM)),</span>
<span class="p_add">+			K(node_page_state(pgdat, NR_WRITEBACK_TEMP)),</span>
<span class="p_add">+			K(node_page_state(pgdat, NR_UNSTABLE_NFS)),</span>
 			!pgdat_reclaimable(pgdat) ? &quot;yes&quot; : &quot;no&quot;);
 	}
 
<span class="p_chunk">@@ -4365,19 +4375,14 @@</span> <span class="p_context"> void show_free_areas(unsigned int filter)</span>
 			&quot; present:%lukB&quot;
 			&quot; managed:%lukB&quot;
 			&quot; mlocked:%lukB&quot;
<span class="p_del">-			&quot; dirty:%lukB&quot;</span>
<span class="p_del">-			&quot; writeback:%lukB&quot;</span>
<span class="p_del">-			&quot; shmem:%lukB&quot;</span>
 			&quot; slab_reclaimable:%lukB&quot;
 			&quot; slab_unreclaimable:%lukB&quot;
 			&quot; kernel_stack:%lukB&quot;
 			&quot; pagetables:%lukB&quot;
<span class="p_del">-			&quot; unstable:%lukB&quot;</span>
 			&quot; bounce:%lukB&quot;
 			&quot; free_pcp:%lukB&quot;
 			&quot; local_pcp:%ukB&quot;
 			&quot; free_cma:%lukB&quot;
<span class="p_del">-			&quot; writeback_tmp:%lukB&quot;</span>
 			&quot; node_pages_scanned:%lu&quot;
 			&quot;\n&quot;,
 			zone-&gt;name,
<span class="p_chunk">@@ -4388,20 +4393,15 @@</span> <span class="p_context"> void show_free_areas(unsigned int filter)</span>
 			K(zone-&gt;present_pages),
 			K(zone-&gt;managed_pages),
 			K(zone_page_state(zone, NR_MLOCK)),
<span class="p_del">-			K(zone_page_state(zone, NR_FILE_DIRTY)),</span>
<span class="p_del">-			K(zone_page_state(zone, NR_WRITEBACK)),</span>
<span class="p_del">-			K(zone_page_state(zone, NR_SHMEM)),</span>
 			K(zone_page_state(zone, NR_SLAB_RECLAIMABLE)),
 			K(zone_page_state(zone, NR_SLAB_UNRECLAIMABLE)),
 			zone_page_state(zone, NR_KERNEL_STACK) *
 				THREAD_SIZE / 1024,
 			K(zone_page_state(zone, NR_PAGETABLE)),
<span class="p_del">-			K(zone_page_state(zone, NR_UNSTABLE_NFS)),</span>
 			K(zone_page_state(zone, NR_BOUNCE)),
 			K(free_pcp),
 			K(this_cpu_read(zone-&gt;pageset-&gt;pcp.count)),
 			K(zone_page_state(zone, NR_FREE_CMA_PAGES)),
<span class="p_del">-			K(zone_page_state(zone, NR_WRITEBACK_TEMP)),</span>
 			K(node_page_state(zone-&gt;zone_pgdat, NR_PAGES_SCANNED)));
 		printk(&quot;lowmem_reserve[]:&quot;);
 		for (i = 0; i &lt; MAX_NR_ZONES; i++)
<span class="p_chunk">@@ -4444,7 +4444,7 @@</span> <span class="p_context"> void show_free_areas(unsigned int filter)</span>
 
 	hugetlb_show_meminfo();
 
<span class="p_del">-	printk(&quot;%ld total pagecache pages\n&quot;, global_page_state(NR_FILE_PAGES));</span>
<span class="p_add">+	printk(&quot;%ld total pagecache pages\n&quot;, global_node_page_state(NR_FILE_PAGES));</span>
 
 	show_swap_cache_info();
 }
<span class="p_header">diff --git a/mm/shmem.c b/mm/shmem.c</span>
<span class="p_header">index 24463b67b6ef..f01d291012d5 100644</span>
<span class="p_header">--- a/mm/shmem.c</span>
<span class="p_header">+++ b/mm/shmem.c</span>
<span class="p_chunk">@@ -312,8 +312,8 @@</span> <span class="p_context"> static int shmem_add_to_page_cache(struct page *page,</span>
 								 page);
 	if (!error) {
 		mapping-&gt;nrpages++;
<span class="p_del">-		__inc_zone_page_state(page, NR_FILE_PAGES);</span>
<span class="p_del">-		__inc_zone_page_state(page, NR_SHMEM);</span>
<span class="p_add">+		__inc_node_page_state(page, NR_FILE_PAGES);</span>
<span class="p_add">+		__inc_node_page_state(page, NR_SHMEM);</span>
 		spin_unlock_irq(&amp;mapping-&gt;tree_lock);
 	} else {
 		page-&gt;mapping = NULL;
<span class="p_chunk">@@ -335,8 +335,8 @@</span> <span class="p_context"> static void shmem_delete_from_page_cache(struct page *page, void *radswap)</span>
 	error = shmem_radix_tree_replace(mapping, page-&gt;index, page, radswap);
 	page-&gt;mapping = NULL;
 	mapping-&gt;nrpages--;
<span class="p_del">-	__dec_zone_page_state(page, NR_FILE_PAGES);</span>
<span class="p_del">-	__dec_zone_page_state(page, NR_SHMEM);</span>
<span class="p_add">+	__dec_node_page_state(page, NR_FILE_PAGES);</span>
<span class="p_add">+	__dec_node_page_state(page, NR_SHMEM);</span>
 	spin_unlock_irq(&amp;mapping-&gt;tree_lock);
 	put_page(page);
 	BUG_ON(error);
<span class="p_chunk">@@ -1084,8 +1084,8 @@</span> <span class="p_context"> static int shmem_replace_page(struct page **pagep, gfp_t gfp,</span>
 	error = shmem_radix_tree_replace(swap_mapping, swap_index, oldpage,
 								   newpage);
 	if (!error) {
<span class="p_del">-		__inc_zone_page_state(newpage, NR_FILE_PAGES);</span>
<span class="p_del">-		__dec_zone_page_state(oldpage, NR_FILE_PAGES);</span>
<span class="p_add">+		__inc_node_page_state(newpage, NR_FILE_PAGES);</span>
<span class="p_add">+		__dec_node_page_state(oldpage, NR_FILE_PAGES);</span>
 	}
 	spin_unlock_irq(&amp;swap_mapping-&gt;tree_lock);
 
<span class="p_header">diff --git a/mm/swap_state.c b/mm/swap_state.c</span>
<span class="p_header">index c99463ac02fb..c8310a37be3a 100644</span>
<span class="p_header">--- a/mm/swap_state.c</span>
<span class="p_header">+++ b/mm/swap_state.c</span>
<span class="p_chunk">@@ -95,7 +95,7 @@</span> <span class="p_context"> int __add_to_swap_cache(struct page *page, swp_entry_t entry)</span>
 					entry.val, page);
 	if (likely(!error)) {
 		address_space-&gt;nrpages++;
<span class="p_del">-		__inc_zone_page_state(page, NR_FILE_PAGES);</span>
<span class="p_add">+		__inc_node_page_state(page, NR_FILE_PAGES);</span>
 		INC_CACHE_INFO(add_total);
 	}
 	spin_unlock_irq(&amp;address_space-&gt;tree_lock);
<span class="p_chunk">@@ -147,7 +147,7 @@</span> <span class="p_context"> void __delete_from_swap_cache(struct page *page)</span>
 	set_page_private(page, 0);
 	ClearPageSwapCache(page);
 	address_space-&gt;nrpages--;
<span class="p_del">-	__dec_zone_page_state(page, NR_FILE_PAGES);</span>
<span class="p_add">+	__dec_node_page_state(page, NR_FILE_PAGES);</span>
 	INC_CACHE_INFO(del_total);
 }
 
<span class="p_header">diff --git a/mm/util.c b/mm/util.c</span>
<span class="p_header">index b756ee36f7f0..21cbc0fc2fd4 100644</span>
<span class="p_header">--- a/mm/util.c</span>
<span class="p_header">+++ b/mm/util.c</span>
<span class="p_chunk">@@ -522,7 +522,7 @@</span> <span class="p_context"> int __vm_enough_memory(struct mm_struct *mm, long pages, int cap_sys_admin)</span>
 
 	if (sysctl_overcommit_memory == OVERCOMMIT_GUESS) {
 		free = global_page_state(NR_FREE_PAGES);
<span class="p_del">-		free += global_page_state(NR_FILE_PAGES);</span>
<span class="p_add">+		free += global_node_page_state(NR_FILE_PAGES);</span>
 
 		/*
 		 * shmem pages shouldn&#39;t be counted as free in this
<span class="p_chunk">@@ -530,7 +530,7 @@</span> <span class="p_context"> int __vm_enough_memory(struct mm_struct *mm, long pages, int cap_sys_admin)</span>
 		 * that won&#39;t affect the overall amount of available
 		 * memory in the system.
 		 */
<span class="p_del">-		free -= global_page_state(NR_SHMEM);</span>
<span class="p_add">+		free -= global_node_page_state(NR_SHMEM);</span>
 
 		free += get_nr_swap_pages();
 
<span class="p_header">diff --git a/mm/vmscan.c b/mm/vmscan.c</span>
<span class="p_header">index c6e958079398..4501a9ab1d3f 100644</span>
<span class="p_header">--- a/mm/vmscan.c</span>
<span class="p_header">+++ b/mm/vmscan.c</span>
<span class="p_chunk">@@ -3594,11 +3594,11 @@</span> <span class="p_context"> int sysctl_min_unmapped_ratio = 1;</span>
  */
 int sysctl_min_slab_ratio = 5;
 
<span class="p_del">-static inline unsigned long zone_unmapped_file_pages(struct zone *zone)</span>
<span class="p_add">+static inline unsigned long node_unmapped_file_pages(struct pglist_data *pgdat)</span>
 {
<span class="p_del">-	unsigned long file_mapped = node_page_state(zone-&gt;zone_pgdat, NR_FILE_MAPPED);</span>
<span class="p_del">-	unsigned long file_lru = node_page_state(zone-&gt;zone_pgdat, NR_INACTIVE_FILE) +</span>
<span class="p_del">-		node_page_state(zone-&gt;zone_pgdat, NR_ACTIVE_FILE);</span>
<span class="p_add">+	unsigned long file_mapped = node_page_state(pgdat, NR_FILE_MAPPED);</span>
<span class="p_add">+	unsigned long file_lru = node_page_state(pgdat, NR_INACTIVE_FILE) +</span>
<span class="p_add">+		node_page_state(pgdat, NR_ACTIVE_FILE);</span>
 
 	/*
 	 * It&#39;s possible for there to be more file mapped pages than
<span class="p_chunk">@@ -3617,17 +3617,17 @@</span> <span class="p_context"> static unsigned long zone_pagecache_reclaimable(struct zone *zone)</span>
 	/*
 	 * If RECLAIM_UNMAP is set, then all file pages are considered
 	 * potentially reclaimable. Otherwise, we have to worry about
<span class="p_del">-	 * pages like swapcache and zone_unmapped_file_pages() provides</span>
<span class="p_add">+	 * pages like swapcache and node_unmapped_file_pages() provides</span>
 	 * a better estimate
 	 */
 	if (zone_reclaim_mode &amp; RECLAIM_UNMAP)
<span class="p_del">-		nr_pagecache_reclaimable = zone_page_state(zone, NR_FILE_PAGES);</span>
<span class="p_add">+		nr_pagecache_reclaimable = node_page_state(zone-&gt;zone_pgdat, NR_FILE_PAGES);</span>
 	else
<span class="p_del">-		nr_pagecache_reclaimable = zone_unmapped_file_pages(zone);</span>
<span class="p_add">+		nr_pagecache_reclaimable = node_unmapped_file_pages(zone-&gt;zone_pgdat);</span>
 
 	/* If we can&#39;t clean pages, remove dirty pages from consideration */
 	if (!(zone_reclaim_mode &amp; RECLAIM_WRITE))
<span class="p_del">-		delta += zone_page_state(zone, NR_FILE_DIRTY);</span>
<span class="p_add">+		delta += node_page_state(zone-&gt;zone_pgdat, NR_FILE_DIRTY);</span>
 
 	/* Watch for any possible underflows due to delta */
 	if (unlikely(delta &gt; nr_pagecache_reclaimable))
<span class="p_header">diff --git a/mm/vmstat.c b/mm/vmstat.c</span>
<span class="p_header">index 12022ed481f0..32c499251174 100644</span>
<span class="p_header">--- a/mm/vmstat.c</span>
<span class="p_header">+++ b/mm/vmstat.c</span>
<span class="p_chunk">@@ -924,19 +924,13 @@</span> <span class="p_context"> const char * const vmstat_text[] = {</span>
 	&quot;nr_zone_anon_lru&quot;,
 	&quot;nr_zone_file_lru&quot;,
 	&quot;nr_mlock&quot;,
<span class="p_del">-	&quot;nr_file_pages&quot;,</span>
<span class="p_del">-	&quot;nr_dirty&quot;,</span>
<span class="p_del">-	&quot;nr_writeback&quot;,</span>
 	&quot;nr_slab_reclaimable&quot;,
 	&quot;nr_slab_unreclaimable&quot;,
 	&quot;nr_page_table_pages&quot;,
 	&quot;nr_kernel_stack&quot;,
<span class="p_del">-	&quot;nr_unstable&quot;,</span>
 	&quot;nr_bounce&quot;,
 	&quot;nr_vmscan_write&quot;,
 	&quot;nr_vmscan_immediate_reclaim&quot;,
<span class="p_del">-	&quot;nr_writeback_temp&quot;,</span>
<span class="p_del">-	&quot;nr_shmem&quot;,</span>
 	&quot;nr_dirtied&quot;,
 	&quot;nr_written&quot;,
 #if IS_ENABLED(CONFIG_ZSMALLOC)
<span class="p_chunk">@@ -967,6 +961,12 @@</span> <span class="p_context"> const char * const vmstat_text[] = {</span>
 	&quot;workingset_nodereclaim&quot;,
 	&quot;nr_anon_pages&quot;,
 	&quot;nr_mapped&quot;,
<span class="p_add">+	&quot;nr_file_pages&quot;,</span>
<span class="p_add">+	&quot;nr_dirty&quot;,</span>
<span class="p_add">+	&quot;nr_writeback&quot;,</span>
<span class="p_add">+	&quot;nr_writeback_temp&quot;,</span>
<span class="p_add">+	&quot;nr_shmem&quot;,</span>
<span class="p_add">+	&quot;nr_unstable&quot;,</span>
 
 	/* enum writeback_stat_item counters */
 	&quot;nr_dirty_threshold&quot;,

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



