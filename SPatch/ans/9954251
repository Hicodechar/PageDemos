
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>[Part1,v4,14/17] x86: Add support for changing memory encryption attribute in early boot - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    [Part1,v4,14/17] x86: Add support for changing memory encryption attribute in early boot</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=150921">Brijesh Singh</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>Sept. 16, 2017, 12:34 p.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;20170916123418.37807-15-brijesh.singh@amd.com&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/9954251/mbox/"
   >mbox</a>
|
   <a href="/patch/9954251/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/9954251/">/patch/9954251/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
	[172.30.200.125])
	by pdx-korg-patchwork.web.codeaurora.org (Postfix) with ESMTP id
	55FA0601D5 for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Sat, 16 Sep 2017 12:37:12 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 444EC20855
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Sat, 16 Sep 2017 12:37:12 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id 3839627F91; Sat, 16 Sep 2017 12:37:12 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-6.9 required=2.0 tests=BAYES_00,DKIM_SIGNED,
	DKIM_VALID,RCVD_IN_DNSWL_HI autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 7C63720855
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Sat, 16 Sep 2017 12:37:11 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1751799AbdIPMg0 (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Sat, 16 Sep 2017 08:36:26 -0400
Received: from mail-dm3nam03on0057.outbound.protection.outlook.com
	([104.47.41.57]:43351
	&quot;EHLO NAM03-DM3-obe.outbound.protection.outlook.com&quot;
	rhost-flags-OK-OK-OK-FAIL) by vger.kernel.org with ESMTP
	id S1751443AbdIPMfM (ORCPT &lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Sat, 16 Sep 2017 08:35:12 -0400
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
	d=amdcloud.onmicrosoft.com; s=selector1-amd-com;
	h=From:Date:Subject:Message-ID:Content-Type:MIME-Version;
	bh=rXDtq9fKgEpc1fBhdwmCnUO9M6noWHX9FIUf6SYcSpY=;
	b=zLo8cnHf21vWxbZN+2L78wTxjvT6dwKFvtEyn28/9J0XN8mkkmTLtRTIJu70Ic9Rmz7MoQ/h/FAE/ZjCWd84BfT3j4cRu4r8b4hZoRlUqX7qofdH6S0dt4FRiEAF7/2+/Nn4rXPMEt18SxewGSjEGJ0699zIQDaCyDilRMbTohg=
Authentication-Results: spf=none (sender IP is )
	smtp.mailfrom=brijesh.singh@amd.com; 
Received: from ubuntu-010236106000.amd.com (165.204.78.1) by
	CY1PR12MB0152.namprd12.prod.outlook.com (10.161.173.22) with
	Microsoft SMTP Server (version=TLS1_2,
	cipher=TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA384_P256) id
	15.20.56.11; Sat, 16 Sep 2017 12:34:52 +0000
From: Brijesh Singh &lt;brijesh.singh@amd.com&gt;
To: linux-kernel@vger.kernel.org, x86@kernel.org, kvm@vger.kernel.org
Cc: Thomas Gleixner &lt;tglx@linutronix.de&gt;, Ingo Molnar &lt;mingo@redhat.com&gt;,
	&quot;H . Peter Anvin&quot; &lt;hpa@zytor.com&gt;, Borislav Petkov &lt;bp@suse.de&gt;,
	Andy Lutomirski &lt;luto@kernel.org&gt;,
	Tom Lendacky &lt;thomas.lendacky@amd.com&gt;,
	Brijesh Singh &lt;brijesh.singh@amd.com&gt;
Subject: [Part1 PATCH v4 14/17] x86: Add support for changing memory
	encryption attribute in early boot
Date: Sat, 16 Sep 2017 07:34:15 -0500
Message-Id: &lt;20170916123418.37807-15-brijesh.singh@amd.com&gt;
X-Mailer: git-send-email 2.9.5
In-Reply-To: &lt;20170916123418.37807-1-brijesh.singh@amd.com&gt;
References: &lt;20170916123418.37807-1-brijesh.singh@amd.com&gt;
MIME-Version: 1.0
Content-Type: text/plain
X-Originating-IP: [165.204.78.1]
X-ClientProxiedBy: DM3PR12CA0051.namprd12.prod.outlook.com (10.161.151.19) To
	CY1PR12MB0152.namprd12.prod.outlook.com (10.161.173.22)
X-MS-PublicTrafficType: Email
X-MS-Office365-Filtering-Correlation-Id: 5409eaad-3034-49fa-c4f8-08d4fcff54a4
X-MS-Office365-Filtering-HT: Tenant
X-Microsoft-Antispam: UriScan:; BCL:0; PCL:0;
	RULEID:(300000500095)(300135000095)(300000501095)(300135300095)(22001)(300000502095)(300135100095)(2017030254152)(48565401081)(300000503095)(300135400095)(2017052603199)(201703131423075)(201703031133081)(201702281549075)(300000504095)(300135200095)(300000505095)(300135600095)(300000506095)(300135500095);
	SRVR:CY1PR12MB0152; 
X-Microsoft-Exchange-Diagnostics: 1; CY1PR12MB0152;
	3:MQqGGpyhnU2l2+3hClAsiHLhCok9qaUcLW0rwr64xGJMDmH8l+X+vWhh+oFNvUZnvyV05fsqy8EZNhrM0u/d/zkQRKMj1dAV3qB+HFOZYGz/nrnV11J424MPT6GkEFg7iCTh/nNNw34Ba9FjPACgXJDLsTolNkSD8//0OS0nO/o0qeAu3Ld4a21AwgV3tTtGJte1/lL3nT62HKF2Ln01P539tfXgXHxPZ443dxvVZXeF44OdKSXRM39gDHEqWNQh;
	25:1mvKXaNEsMWwqdfEY6s021MYSV1qO0ixaTCxFXSZ4vpVUmSSzxeApHtGXX9QrkzocijXWVAUg2HpwocorsghL07Nc0FIt27bV31RlL95Eu8j2RAzyEmbuYFixhA2usxG/A84HT54Je8X2GSs9zeyb9E5zJcuEmI/NUVEREooQFoL1VgdA19VXVOozxgwuBEy5PQ3YPr5xOeJRs8nRKZe6KgVDUIIgGKBDWhynhdqsxZAhpJpdY6jasfZilMjssjKo+N2A/ekifn/vFaC9amBEhEyG5ZYS97s3f/+qqK23kUNb+Ei86L+dliDyjpJQJQZkwKOMNk092NTBfdjjWneeA==;
	31:iEyBDT4AJuE8OwbMVS5BWs93oKKScBULqTUM7b4BcC1bO/h53i+cJjYnLfssKHV3yoxzwWlcAuFRl7m6VYfeFjenFJbyQz3q3f6ntAdLMvcyvMvUk44ak7otRiMRG5B78RJxBNtLUdNTzzVHyFRYiHlDyhWWYsDvdvBN/JapvKc7PCNsWFYsf9uz6ayT02I+BgfKxubN0QEfVsGR8XQ2bnA5Red76Em3Ey/8hDqagSw=
X-MS-TrafficTypeDiagnostic: CY1PR12MB0152:
X-Microsoft-Exchange-Diagnostics: 1; CY1PR12MB0152;
	20:LVBBIWHEnfu6PFFCmEO9TQp01YYUtPH14zUppIh2ftOm+1K/Ii9GczOv8JOycnyBwEZwV0mjK24SQ9l654nva/iVenosb6SW6Z39zKDGD7Bue6bntXPEA/ed78EteDgSkSXpcZFgVwBHUehM4v8gxyPZoYd9SW7onsgsQ62oYpM2BiqVdsHIsqkmMTl4F26YC2q4O9cPIkd1tiLXNT0jp3bbh7TmFq7dTqZKw3+rEktEoJ96qepBq1dULtd5LAUpwiq8AyLWpg4EjCF5DUm0r94E04+ylcvoUUO2/YGlNT6xRWXbRMaMZVuv4MYp1n2mNPRbLFdAmVbU2feoiVNUkJEBVL+x1ZkPcTYpndHOmDpIFEVCcofyz6Jyx78IyurS0A7/UH8TqDv9T/dvhGZeq5e5h6+LmbDlDM6EpJyro8ZjIRO7J2NM7ZvekVB+qIE9gmmaaTbA9/F0Ko8Yikbe6aC6SEZ8MX0NNa90vXQOUdq8lrIdn4LuuSxMfrdKTq08;
	4:HqZkon/f+PT8jRPZAC7bNCIpn14OmkWKeYJBvkKXdOnc3wquuU0DroaAK45d9hXMaAinHhAhRQuX4z15MraqB+JD7mciLAnk7Qgk4ThVXSzJeAAaqF8a5LRZLk53Mdtbac2AYi8mApSbUG27kf8Cl39YMRm2uVuNeqpNHJgrqV5Io5682Fa56wO35s9cu14lnI2VkCApZJE23gYBBtRXJ0cB1Y+WqYYOVUKKUcQtaRnBpR0rLIUBTR5GJnF2UoXxyJWZQiHfH+mPamW+V0zTkEBcpZCcf35+MyWwpAz4GLpwNBQql068QQfBegI3ZM/j
X-Exchange-Antispam-Report-Test: UriScan:(9452136761055)(767451399110);
X-Microsoft-Antispam-PRVS: &lt;CY1PR12MB015273AF2E0E9175CDD349ACE56D0@CY1PR12MB0152.namprd12.prod.outlook.com&gt;
X-Exchange-Antispam-Report-CFA-Test: BCL:0; PCL:0;
	RULEID:(100000700101)(100105000095)(100000701101)(100105300095)(100000702101)(100105100095)(6040450)(2401047)(8121501046)(5005006)(100000703101)(100105400095)(93006095)(93001095)(3002001)(10201501046)(6055026)(6041248)(20161123564025)(20161123562025)(20161123558100)(201703131423075)(201702281528075)(201703061421075)(201703061406153)(20161123560025)(20161123555025)(6072148)(201708071742011)(100000704101)(100105200095)(100000705101)(100105500095);
	SRVR:CY1PR12MB0152; BCL:0; PCL:0;
	RULEID:(100000800101)(100110000095)(100000801101)(100110300095)(100000802101)(100110100095)(100000803101)(100110400095)(100000804101)(100110200095)(100000805101)(100110500095);
	SRVR:CY1PR12MB0152; 
X-Forefront-PRVS: 0432A04947
X-Forefront-Antispam-Report: SFV:NSPM;
	SFS:(10009020)(6009001)(346002)(376002)(199003)(189002)(6486002)(53416004)(81156014)(48376002)(81166006)(50466002)(6666003)(5003940100001)(7736002)(54906002)(316002)(16586007)(8676002)(97736004)(2906002)(305945005)(53936002)(5660300001)(86362001)(478600001)(16526017)(1076002)(106356001)(110136004)(3846002)(4326008)(50226002)(68736007)(25786009)(6116002)(33646002)(105586002)(101416001)(50986999)(47776003)(2950100002)(8936002)(66066001)(36756003)(189998001)(76176999);
	DIR:OUT; SFP:1101; SCL:1; SRVR:CY1PR12MB0152;
	H:ubuntu-010236106000.amd.com; FPR:; SPF:None;
	PTR:InfoNoRecords; A:1; MX:1; LANG:en; 
Received-SPF: None (protection.outlook.com: amd.com does not designate
	permitted sender hosts)
X-Microsoft-Exchange-Diagnostics: =?us-ascii?Q?1; CY1PR12MB0152;
	23:Tnslh+TmPt7IUMvNBa2P/yV+a/tcgTmFi/tMz1waE?=
	=?us-ascii?Q?cLyDrGGtG36faiivDsMTATYErxjfbxfP5pyrUyHwBmoLdma5TWrDmWhbKj/I?=
	=?us-ascii?Q?GNf/v8GcDindEX4rTkzd0lvKNHbMlISOFWAlxMxew/bvuoEY8fJBTIHHgny8?=
	=?us-ascii?Q?iIsRUM+qTdPocoyfEgdxOUA2f1NZjq0Nt20WQQRCoKbbT3Dm6ipLcCLF91gu?=
	=?us-ascii?Q?mOUx4ofoNBTepx83IgqNL2QDKlNbMAU2sqgtXbfc1zqCJxTnOH+zbSX8OSxl?=
	=?us-ascii?Q?bOahqAVrGF8IizqiNLd/kski3pFXRYmLgYtELslMZVs8C08keidjP1o4cQhv?=
	=?us-ascii?Q?zVASGBAZtr1R5qexMhje3z4SlDAyvkAKpuee7WdAk0B1Sq2ZCky1mLJtHxdk?=
	=?us-ascii?Q?7W+Sz9mxMtkynvPKNxmdPEvike0VMqSDAacy13yfR7qkXEU6LtGv4wDqmSnH?=
	=?us-ascii?Q?TpkmmBsS7Fakg+TL69dFRZF8M/3vMuVGvAhl7DZ2vmeG2qAn3MUWy2SwDhYd?=
	=?us-ascii?Q?X3SEngt+i3kFgHkFwgdY5rkJiaOV42rUc2sRE+ZheIrC0tJvjraPj+5WBpOs?=
	=?us-ascii?Q?6aegwO3ayCt3s7ovFVfl1O5Ktwgs8yA1HZ2nApP4++KHgtlxPfSt97uF7Nrm?=
	=?us-ascii?Q?pFXipNzk54G28E3Vvjm2ly/XAHHPK/YgY3Zlej8CFl1xwhPCYnqPc4vfRVBa?=
	=?us-ascii?Q?i4pz/6G8xNWGMg96W1UAqgi3L3xQG8NtVRDVUWJT/C+fCMYQBxHEoAD9pcPo?=
	=?us-ascii?Q?VXGvCYQXz9LvKKYue47CuTFNCm46ZJC1JRN0BBGu0SZ4xCTEonGxjc5rQGol?=
	=?us-ascii?Q?uZlTIfb0cZZyAsc+QwPdl3vcgOzcMBwP9xrdkFPuFWjUUZjoFv0ZQV4NUfY1?=
	=?us-ascii?Q?T5praUfc7vm6PcdR7dF7/VNVC0f9r50b+wmiTkrSvACWBo5W/5FDQsMv2gNT?=
	=?us-ascii?Q?tlQzCnFoKrp2W+th24IZcUQJZLiy6dh/5HDQuIONcWCFKJBLij0sJeJhHN6y?=
	=?us-ascii?Q?/gaXmlFrMf77otMpUJg3wsHk+8hRUK5rKdy/vLN8sWzih2bsqbUSx8lGjj+f?=
	=?us-ascii?Q?qgLOHhhVtSz556AqY62QuNoTlAzydu9WGZ0I+Qy9J7bdrhlEQ=3D=3D?=
X-Microsoft-Exchange-Diagnostics: 1; CY1PR12MB0152;
	6:3d4asIzg9Q9frxTobkml7vSu7sNtrRHBoCJIzKAU9/XYCRBFtS2yqLZgb5yUG4YSoyHKR5RgoRb8nqGt91rViyRa9uK8cWrovK0tIPR0XTHR+Lj3iNZgMg0HLoMkk49Sbx2SrBaFGe+t7dwl0ZfalNOKBUs3W7KdVwSPbKtEcGlirCnm5Dyl73B6Zaic8A/LzJfoDb7sl5wWpxli3hsKYFx2Rj/LUnFDZFl+W4cUw6fVyGVpzN96CxKzPq7FM3CrFAZto4bSRRypGfnnRzyFY9svfyWW8tfgMutsz3fT9tsYDZ1ajSoONUqBZvvVtiB4d4VV8FSKugStPasIo4Xrjw==;
	5:4qSnMWkzMv6MSxrv5wwnimCJnRmu5ZVmyCN+Fl3QjLFWWKJJbwxpOnJnaP/8Wyj8rdwccDnnJQtUx7iTSidYRXjdUgizUaiidykTn/+0VNlUrFEAeyE5kTvokbcTzO4lScN5+MZN32cygZcOT363qQ==;
	24:Yzs8YLSO9MS/oBCOrTzZ7jsBbofVm+mUGhM4Ayie+y/+1vvmiVNWy78vp5gFC+UqucUD9fXkROowpjgMmU7Eb6V0xSj40m2GJ3+un6reoLg=;
	7:5C3RRUFt97G4BCPRM0N5VvxEYl8Mw+n/LRiq38M8XKzMqoSY2YJebnuP3ltdhf3ZLzuDWI8FxGJ/V1qiuEGIovf3MCs9OSvO+sDt87+mi8VIz2fqDJe/Tdv1CiEjZuoLw/jaNKSGQvBGq26TfauMOb3YSG9aHcxbjs2rZ1iVqj+1jLkGILw6roBDsQXOiSE3wriLwPxiMvxIjezK+E4WrjszstFrmo6+UdIzKX9zxHM=
SpamDiagnosticOutput: 1:99
SpamDiagnosticMetadata: NSPM
X-Microsoft-Exchange-Diagnostics: 1; CY1PR12MB0152;
	20:yBmVmUsCIjWh5vS+HKrtklDK7iDeCdmsbMFOiuaOpsTZZ+STOpDhxJK6IvxJsscFgQCR7+HdFqMjKTdhFKWt4aEprn589DH0m3VFpdxotbZQVrUglHUSJQKid1Mbn/adHysA5g4Hifw6iwFhL9Sg8AJ6wnLPoO+URgL2GZwYyq63P+eUxxdxtDT+AmUfG4/XwfhhaRNKMvNt1BqKjkfhn71WO1Ra36KJq/p3aKld2ADrMjoF5ypjzmxq7MERGfFT
X-OriginatorOrg: amd.com
X-MS-Exchange-CrossTenant-OriginalArrivalTime: 16 Sep 2017 12:34:52.8183
	(UTC)
X-MS-Exchange-CrossTenant-FromEntityHeader: Hosted
X-MS-Exchange-CrossTenant-Id: 3dd8961f-e488-4e60-8e11-a82d994e183d
X-MS-Exchange-Transport-CrossTenantHeadersStamped: CY1PR12MB0152
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=150921">Brijesh Singh</a> - Sept. 16, 2017, 12:34 p.m.</div>
<pre class="content">
Some KVM-specific custom MSRs share the guest physical address with the
hypervisor in early boot. When SEV is active, the shared physical address
must be mapped with memory encryption attribute cleared so that both
hypervisor and guest can access the data.

Add APIs to change the memory encryption attribute in early boot code.

Cc: Thomas Gleixner &lt;tglx@linutronix.de&gt;
Cc: Ingo Molnar &lt;mingo@redhat.com&gt;
Cc: &quot;H. Peter Anvin&quot; &lt;hpa@zytor.com&gt;
Cc: Borislav Petkov &lt;bp@suse.de&gt;
Cc: x86@kernel.org
Cc: linux-kernel@vger.kernel.org
Cc: Tom Lendacky &lt;thomas.lendacky@amd.com&gt;
<span class="signed-off-by">Signed-off-by: Brijesh Singh &lt;brijesh.singh@amd.com&gt;</span>
---
 arch/x86/include/asm/mem_encrypt.h |  17 ++++++
 arch/x86/mm/mem_encrypt.c          | 121 +++++++++++++++++++++++++++++++++++++
 2 files changed, 138 insertions(+)
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=57321">Borislav Petkov</a> - Sept. 17, 2017, 3:25 p.m.</div>
<pre class="content">
On Sat, Sep 16, 2017 at 07:34:15AM -0500, Brijesh Singh wrote:
<span class="quote">&gt; Some KVM-specific custom MSRs share the guest physical address with the</span>
<span class="quote">&gt; hypervisor in early boot. When SEV is active, the shared physical address</span>
<span class="quote">&gt; must be mapped with memory encryption attribute cleared so that both</span>
<span class="quote">&gt; hypervisor and guest can access the data.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Add APIs to change the memory encryption attribute in early boot code.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Cc: Thomas Gleixner &lt;tglx@linutronix.de&gt;</span>
<span class="quote">&gt; Cc: Ingo Molnar &lt;mingo@redhat.com&gt;</span>
<span class="quote">&gt; Cc: &quot;H. Peter Anvin&quot; &lt;hpa@zytor.com&gt;</span>
<span class="quote">&gt; Cc: Borislav Petkov &lt;bp@suse.de&gt;</span>
<span class="quote">&gt; Cc: x86@kernel.org</span>
<span class="quote">&gt; Cc: linux-kernel@vger.kernel.org</span>
<span class="quote">&gt; Cc: Tom Lendacky &lt;thomas.lendacky@amd.com&gt;</span>
<span class="quote">&gt; Signed-off-by: Brijesh Singh &lt;brijesh.singh@amd.com&gt;</span>
<span class="quote">&gt; ---</span>
<span class="quote">&gt;  arch/x86/include/asm/mem_encrypt.h |  17 ++++++</span>
<span class="quote">&gt;  arch/x86/mm/mem_encrypt.c          | 121 +++++++++++++++++++++++++++++++++++++</span>
<span class="quote">&gt;  2 files changed, 138 insertions(+)</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; diff --git a/arch/x86/include/asm/mem_encrypt.h b/arch/x86/include/asm/mem_encrypt.h</span>
<span class="quote">&gt; index 2b024741bce9..21b9d8fc8293 100644</span>
<span class="quote">&gt; --- a/arch/x86/include/asm/mem_encrypt.h</span>
<span class="quote">&gt; +++ b/arch/x86/include/asm/mem_encrypt.h</span>
<span class="quote">&gt; @@ -42,6 +42,11 @@ void __init sme_early_init(void);</span>
<span class="quote">&gt;  void __init sme_encrypt_kernel(void);</span>
<span class="quote">&gt;  void __init sme_enable(struct boot_params *bp);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; +int __init early_set_memory_decrypted(resource_size_t paddr,</span>
<span class="quote">&gt; +				      unsigned long size);</span>
<span class="quote">&gt; +int __init early_set_memory_encrypted(resource_size_t paddr,</span>
<span class="quote">&gt; +				      unsigned long size);</span>
<span class="quote">&gt; +</span>

Let those stick out on a single line.
<span class="quote">
&gt;  /* Architecture __weak replacement functions */</span>
<span class="quote">&gt;  void __init mem_encrypt_init(void);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; @@ -70,6 +75,18 @@ static inline void __init sme_enable(struct boot_params *bp) { }</span>
<span class="quote">&gt;  static inline bool sme_active(void) { return false; }</span>
<span class="quote">&gt;  static inline bool sev_active(void) { return false; }</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; +static inline int __init early_set_memory_decrypted(resource_size_t paddr,</span>
<span class="quote">&gt; +						    unsigned long size)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	return 0;</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +static inline int __init early_set_memory_encrypted(resource_size_t paddr,</span>
<span class="quote">&gt; +						    unsigned long size)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	return 0;</span>
<span class="quote">&gt; +}</span>

Yeah, let&#39;s save some screen real-estate like this:

static inline int __init
early_set_memory_decrypted(resource_size_t paddr, unsigned long size)	{ return 0; }
static inline int __init
early_set_memory_encrypted(resource_size_t paddr, unsigned long size)	{ return 0; }

With that fixed:
<span class="reviewed-by">
Reviewed-by: Borislav Petkov &lt;bp@suse.de&gt;</span>
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/arch/x86/include/asm/mem_encrypt.h b/arch/x86/include/asm/mem_encrypt.h</span>
<span class="p_header">index 2b024741bce9..21b9d8fc8293 100644</span>
<span class="p_header">--- a/arch/x86/include/asm/mem_encrypt.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/mem_encrypt.h</span>
<span class="p_chunk">@@ -42,6 +42,11 @@</span> <span class="p_context"> void __init sme_early_init(void);</span>
 void __init sme_encrypt_kernel(void);
 void __init sme_enable(struct boot_params *bp);
 
<span class="p_add">+int __init early_set_memory_decrypted(resource_size_t paddr,</span>
<span class="p_add">+				      unsigned long size);</span>
<span class="p_add">+int __init early_set_memory_encrypted(resource_size_t paddr,</span>
<span class="p_add">+				      unsigned long size);</span>
<span class="p_add">+</span>
 /* Architecture __weak replacement functions */
 void __init mem_encrypt_init(void);
 
<span class="p_chunk">@@ -70,6 +75,18 @@</span> <span class="p_context"> static inline void __init sme_enable(struct boot_params *bp) { }</span>
 static inline bool sme_active(void) { return false; }
 static inline bool sev_active(void) { return false; }
 
<span class="p_add">+static inline int __init early_set_memory_decrypted(resource_size_t paddr,</span>
<span class="p_add">+						    unsigned long size)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return 0;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline int __init early_set_memory_encrypted(resource_size_t paddr,</span>
<span class="p_add">+						    unsigned long size)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return 0;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 #endif	/* CONFIG_AMD_MEM_ENCRYPT */
 
 /*
<span class="p_header">diff --git a/arch/x86/mm/mem_encrypt.c b/arch/x86/mm/mem_encrypt.c</span>
<span class="p_header">index b361fabde4c8..cecdf52f3c70 100644</span>
<span class="p_header">--- a/arch/x86/mm/mem_encrypt.c</span>
<span class="p_header">+++ b/arch/x86/mm/mem_encrypt.c</span>
<span class="p_chunk">@@ -28,6 +28,8 @@</span> <span class="p_context"></span>
 #include &lt;asm/msr.h&gt;
 #include &lt;asm/cmdline.h&gt;
 
<span class="p_add">+#include &quot;mm_internal.h&quot;</span>
<span class="p_add">+</span>
 static char sme_cmdline_arg[] __initdata = &quot;mem_encrypt&quot;;
 static char sme_cmdline_on[]  __initdata = &quot;on&quot;;
 static char sme_cmdline_off[] __initdata = &quot;off&quot;;
<span class="p_chunk">@@ -258,6 +260,125 @@</span> <span class="p_context"> static void sme_free(struct device *dev, size_t size, void *vaddr,</span>
 	swiotlb_free_coherent(dev, size, vaddr, dma_handle);
 }
 
<span class="p_add">+static void __init __set_clr_pte_enc(pte_t *kpte, int level, bool enc)</span>
<span class="p_add">+{</span>
<span class="p_add">+	pgprot_t old_prot, new_prot;</span>
<span class="p_add">+	unsigned long pfn;</span>
<span class="p_add">+	pte_t new_pte;</span>
<span class="p_add">+</span>
<span class="p_add">+	switch (level) {</span>
<span class="p_add">+	case PG_LEVEL_4K:</span>
<span class="p_add">+		pfn = pte_pfn(*kpte);</span>
<span class="p_add">+		old_prot = pte_pgprot(*kpte);</span>
<span class="p_add">+		break;</span>
<span class="p_add">+	case PG_LEVEL_2M:</span>
<span class="p_add">+		pfn = pmd_pfn(*(pmd_t *)kpte);</span>
<span class="p_add">+		old_prot = pmd_pgprot(*(pmd_t *)kpte);</span>
<span class="p_add">+		break;</span>
<span class="p_add">+	case PG_LEVEL_1G:</span>
<span class="p_add">+		pfn = pud_pfn(*(pud_t *)kpte);</span>
<span class="p_add">+		old_prot = pud_pgprot(*(pud_t *)kpte);</span>
<span class="p_add">+		break;</span>
<span class="p_add">+	default:</span>
<span class="p_add">+		return;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	new_prot = old_prot;</span>
<span class="p_add">+	if (enc)</span>
<span class="p_add">+		pgprot_val(new_prot) |= _PAGE_ENC;</span>
<span class="p_add">+	else</span>
<span class="p_add">+		pgprot_val(new_prot) &amp;= ~_PAGE_ENC;</span>
<span class="p_add">+</span>
<span class="p_add">+	/* if prot is same then do nothing */</span>
<span class="p_add">+	if (pgprot_val(old_prot) == pgprot_val(new_prot))</span>
<span class="p_add">+		return;</span>
<span class="p_add">+</span>
<span class="p_add">+	new_pte = pfn_pte(pfn, new_prot);</span>
<span class="p_add">+	set_pte_atomic(kpte, new_pte);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static int __init early_set_memory_enc_dec(resource_size_t paddr,</span>
<span class="p_add">+					   unsigned long size, bool enc)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long vaddr, vaddr_end, vaddr_next;</span>
<span class="p_add">+	unsigned long psize, pmask;</span>
<span class="p_add">+	int split_page_size_mask;</span>
<span class="p_add">+	pte_t *kpte;</span>
<span class="p_add">+	int level, ret;</span>
<span class="p_add">+</span>
<span class="p_add">+	vaddr = (unsigned long)__va(paddr);</span>
<span class="p_add">+	vaddr_next = vaddr;</span>
<span class="p_add">+	vaddr_end = vaddr + size;</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * We are going to change the physical page attribute from C=1 to C=0</span>
<span class="p_add">+	 * or vice versa. Flush the caches to ensure that data is written into</span>
<span class="p_add">+	 * memory with correct C-bit before we change attribute.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	clflush_cache_range(__va(paddr), size);</span>
<span class="p_add">+</span>
<span class="p_add">+	for (; vaddr &lt; vaddr_end; vaddr = vaddr_next) {</span>
<span class="p_add">+		kpte = lookup_address(vaddr, &amp;level);</span>
<span class="p_add">+		if (!kpte || pte_none(*kpte)) {</span>
<span class="p_add">+			ret = 1;</span>
<span class="p_add">+			goto out;</span>
<span class="p_add">+		}</span>
<span class="p_add">+</span>
<span class="p_add">+		if (level == PG_LEVEL_4K) {</span>
<span class="p_add">+			__set_clr_pte_enc(kpte, level, enc);</span>
<span class="p_add">+			vaddr_next = (vaddr &amp; PAGE_MASK) + PAGE_SIZE;</span>
<span class="p_add">+			continue;</span>
<span class="p_add">+		}</span>
<span class="p_add">+</span>
<span class="p_add">+		psize = page_level_size(level);</span>
<span class="p_add">+		pmask = page_level_mask(level);</span>
<span class="p_add">+</span>
<span class="p_add">+		/*</span>
<span class="p_add">+		 * Check, whether we can change the large page in one go.</span>
<span class="p_add">+		 * We request a split, when the address is not aligned and</span>
<span class="p_add">+		 * the number of pages to set/clear encryption bit is smaller</span>
<span class="p_add">+		 * than the number of pages in the large page.</span>
<span class="p_add">+		 */</span>
<span class="p_add">+		if (vaddr == (vaddr &amp; pmask) &amp;&amp;</span>
<span class="p_add">+			((vaddr_end - vaddr) &gt;= psize)) {</span>
<span class="p_add">+			__set_clr_pte_enc(kpte, level, enc);</span>
<span class="p_add">+			vaddr_next = (vaddr &amp; pmask) + psize;</span>
<span class="p_add">+			continue;</span>
<span class="p_add">+		}</span>
<span class="p_add">+</span>
<span class="p_add">+		/*</span>
<span class="p_add">+		 * virtual address is part of large page, create the page table</span>
<span class="p_add">+		 * mapping to use smaller pages (4K or 2M). If virtual address</span>
<span class="p_add">+		 * is part of 2M page the we request spliting the large page</span>
<span class="p_add">+		 * into 4K, similarly 1GB large page is requested to split into</span>
<span class="p_add">+		 * 2M pages.</span>
<span class="p_add">+		 */</span>
<span class="p_add">+		if (level == PG_LEVEL_2M)</span>
<span class="p_add">+			split_page_size_mask = 0;</span>
<span class="p_add">+		else</span>
<span class="p_add">+			split_page_size_mask = 1 &lt;&lt; PG_LEVEL_2M;</span>
<span class="p_add">+</span>
<span class="p_add">+		kernel_physical_mapping_init(__pa(vaddr &amp; pmask),</span>
<span class="p_add">+					     __pa((vaddr_end &amp; pmask) + psize),</span>
<span class="p_add">+					     split_page_size_mask);</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	ret = 0;</span>
<span class="p_add">+out:</span>
<span class="p_add">+	__flush_tlb_all();</span>
<span class="p_add">+	return ret;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+int __init early_set_memory_decrypted(resource_size_t paddr, unsigned long size)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return early_set_memory_enc_dec(paddr, size, false);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+int __init early_set_memory_encrypted(resource_size_t paddr, unsigned long size)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return early_set_memory_enc_dec(paddr, size, true);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 /*
  * SME and SEV are very similar but they are not the same, so there are
  * times that the kernel will need to distinguish between SME and SEV. The

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



