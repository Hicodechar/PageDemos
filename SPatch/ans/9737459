
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>[08/10] paravirt: split pv_mmu_ops for support of PARAVIRT_FULL - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    [08/10] paravirt: split pv_mmu_ops for support of PARAVIRT_FULL</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=100191">Juergen Gross</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>May 19, 2017, 3:47 p.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;20170519154746.29389-9-jgross@suse.com&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/9737459/mbox/"
   >mbox</a>
|
   <a href="/patch/9737459/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/9737459/">/patch/9737459/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
	[172.30.200.125])
	by pdx-korg-patchwork.web.codeaurora.org (Postfix) with ESMTP id
	256FB6020B for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Fri, 19 May 2017 15:48:27 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 24EDB28814
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Fri, 19 May 2017 15:48:27 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id 193E7288B5; Fri, 19 May 2017 15:48:27 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-6.9 required=2.0 tests=BAYES_00,RCVD_IN_DNSWL_HI
	autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 51EAD28814
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Fri, 19 May 2017 15:48:24 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1755885AbdESPsT (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Fri, 19 May 2017 11:48:19 -0400
Received: from mx2.suse.de ([195.135.220.15]:33018 &quot;EHLO mx1.suse.de&quot;
	rhost-flags-OK-OK-OK-FAIL) by vger.kernel.org with ESMTP
	id S1755606AbdESPsA (ORCPT &lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Fri, 19 May 2017 11:48:00 -0400
X-Virus-Scanned: by amavisd-new at test-mx.suse.de
Received: from relay2.suse.de (charybdis-ext.suse.de [195.135.220.254])
	by mx1.suse.de (Postfix) with ESMTP id 98B91AD9A;
	Fri, 19 May 2017 15:47:58 +0000 (UTC)
From: Juergen Gross &lt;jgross@suse.com&gt;
To: linux-kernel@vger.kernel.org, xen-devel@lists.xenproject.org,
	x86@kernel.org, virtualization@lists.linux-foundation.org
Cc: jeremy@goop.org, chrisw@sous-sol.org, akataria@vmware.com,
	rusty@rustcorp.com.au, boris.ostrovsky@oracle.com, hpa@zytor.com,
	tglx@linutronix.de, mingo@redhat.com, Juergen Gross &lt;jgross@suse.com&gt;
Subject: [PATCH 08/10] paravirt: split pv_mmu_ops for support of
	PARAVIRT_FULL
Date: Fri, 19 May 2017 17:47:44 +0200
Message-Id: &lt;20170519154746.29389-9-jgross@suse.com&gt;
X-Mailer: git-send-email 2.12.0
In-Reply-To: &lt;20170519154746.29389-1-jgross@suse.com&gt;
References: &lt;20170519154746.29389-1-jgross@suse.com&gt;
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=100191">Juergen Gross</a> - May 19, 2017, 3:47 p.m.</div>
<pre class="content">
Move functions needed for fully paravirtualized guests only into a new
structure pvfull_mmu_ops in paravirt_types_full.h, paravirt_full.h and
the associated vector into paravirt_full.c.

.flush_tlb_others is left in pv_mmu_ops as hyperv support will use it
soon.
<span class="signed-off-by">
Signed-off-by: Juergen Gross &lt;jgross@suse.com&gt;</span>
---
 arch/x86/include/asm/fixmap.h              |   2 +-
 arch/x86/include/asm/mmu_context.h         |   4 +-
 arch/x86/include/asm/paravirt.h            | 442 ++---------------------------
 arch/x86/include/asm/paravirt_full.h       | 422 +++++++++++++++++++++++++++
 arch/x86/include/asm/paravirt_types.h      | 117 +-------
 arch/x86/include/asm/paravirt_types_full.h | 116 ++++++++
 arch/x86/include/asm/pgalloc.h             |   2 +-
 arch/x86/include/asm/pgtable.h             |   8 +-
 arch/x86/include/asm/special_insns.h       |   6 +-
 arch/x86/include/asm/tlbflush.h            |   2 +-
 arch/x86/kernel/asm-offsets.c              |   4 +-
 arch/x86/kernel/head_64.S                  |   2 +-
 arch/x86/kernel/paravirt.c                 | 171 -----------
 arch/x86/kernel/paravirt_full.c            | 176 ++++++++++++
 arch/x86/kernel/paravirt_patch_32.c        |  12 +-
 arch/x86/kernel/paravirt_patch_64.c        |  16 +-
 arch/x86/lguest/boot.c                     |  36 +--
 arch/x86/xen/enlighten_pv.c                |   8 +-
 arch/x86/xen/mmu_pv.c                      |  34 +--
 19 files changed, 797 insertions(+), 783 deletions(-)
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/arch/x86/include/asm/fixmap.h b/arch/x86/include/asm/fixmap.h</span>
<span class="p_header">index b65155cc3760..dfef874cb9d6 100644</span>
<span class="p_header">--- a/arch/x86/include/asm/fixmap.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/fixmap.h</span>
<span class="p_chunk">@@ -149,7 +149,7 @@</span> <span class="p_context"> void __native_set_fixmap(enum fixed_addresses idx, pte_t pte);</span>
 void native_set_fixmap(enum fixed_addresses idx,
 		       phys_addr_t phys, pgprot_t flags);
 
<span class="p_del">-#ifndef CONFIG_PARAVIRT</span>
<span class="p_add">+#ifndef CONFIG_PARAVIRT_FULL</span>
 static inline void __set_fixmap(enum fixed_addresses idx,
 				phys_addr_t phys, pgprot_t flags)
 {
<span class="p_header">diff --git a/arch/x86/include/asm/mmu_context.h b/arch/x86/include/asm/mmu_context.h</span>
<span class="p_header">index 68b329d77b3a..b38431024463 100644</span>
<span class="p_header">--- a/arch/x86/include/asm/mmu_context.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/mmu_context.h</span>
<span class="p_chunk">@@ -12,12 +12,12 @@</span> <span class="p_context"></span>
 #include &lt;asm/tlbflush.h&gt;
 #include &lt;asm/paravirt.h&gt;
 #include &lt;asm/mpx.h&gt;
<span class="p_del">-#ifndef CONFIG_PARAVIRT</span>
<span class="p_add">+#ifndef CONFIG_PARAVIRT_FULL</span>
 static inline void paravirt_activate_mm(struct mm_struct *prev,
 					struct mm_struct *next)
 {
 }
<span class="p_del">-#endif	/* !CONFIG_PARAVIRT */</span>
<span class="p_add">+#endif	/* !CONFIG_PARAVIRT_FULL */</span>
 
 #ifdef CONFIG_PERF_EVENTS
 extern struct static_key rdpmc_always_available;
<span class="p_header">diff --git a/arch/x86/include/asm/paravirt.h b/arch/x86/include/asm/paravirt.h</span>
<span class="p_header">index f1680e70162b..3b9960a5de4a 100644</span>
<span class="p_header">--- a/arch/x86/include/asm/paravirt.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/paravirt.h</span>
<span class="p_chunk">@@ -17,28 +17,15 @@</span> <span class="p_context"></span>
 
 #ifdef CONFIG_PARAVIRT_FULL
 #include &lt;asm/paravirt_full.h&gt;
<span class="p_add">+#else</span>
<span class="p_add">+</span>
<span class="p_add">+static inline enum paravirt_lazy_mode paravirt_get_lazy_mode(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return PARAVIRT_LAZY_NONE;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 #endif
 
<span class="p_del">-static inline unsigned long read_cr2(void)</span>
<span class="p_del">-{</span>
<span class="p_del">-	return PVOP_CALL0(unsigned long, pv_mmu_ops.read_cr2);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static inline void write_cr2(unsigned long x)</span>
<span class="p_del">-{</span>
<span class="p_del">-	PVOP_VCALL1(pv_mmu_ops.write_cr2, x);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static inline unsigned long read_cr3(void)</span>
<span class="p_del">-{</span>
<span class="p_del">-	return PVOP_CALL0(unsigned long, pv_mmu_ops.read_cr3);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static inline void write_cr3(unsigned long x)</span>
<span class="p_del">-{</span>
<span class="p_del">-	PVOP_VCALL1(pv_mmu_ops.write_cr3, x);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
 #define get_kernel_rpl()  (pv_info.kernel_rpl)
 
 static inline unsigned long long paravirt_sched_clock(void)
<span class="p_chunk">@@ -66,36 +53,11 @@</span> <span class="p_context"> static inline void slow_down_io(void)</span>
 #endif
 }
 
<span class="p_del">-static inline void paravirt_activate_mm(struct mm_struct *prev,</span>
<span class="p_del">-					struct mm_struct *next)</span>
<span class="p_del">-{</span>
<span class="p_del">-	PVOP_VCALL2(pv_mmu_ops.activate_mm, prev, next);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static inline void paravirt_arch_dup_mmap(struct mm_struct *oldmm,</span>
<span class="p_del">-					  struct mm_struct *mm)</span>
<span class="p_del">-{</span>
<span class="p_del">-	PVOP_VCALL2(pv_mmu_ops.dup_mmap, oldmm, mm);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
 static inline void paravirt_arch_exit_mmap(struct mm_struct *mm)
 {
 	PVOP_VCALL1(pv_mmu_ops.exit_mmap, mm);
 }
 
<span class="p_del">-static inline void __flush_tlb(void)</span>
<span class="p_del">-{</span>
<span class="p_del">-	PVOP_VCALL0(pv_mmu_ops.flush_tlb_user);</span>
<span class="p_del">-}</span>
<span class="p_del">-static inline void __flush_tlb_global(void)</span>
<span class="p_del">-{</span>
<span class="p_del">-	PVOP_VCALL0(pv_mmu_ops.flush_tlb_kernel);</span>
<span class="p_del">-}</span>
<span class="p_del">-static inline void __flush_tlb_single(unsigned long addr)</span>
<span class="p_del">-{</span>
<span class="p_del">-	PVOP_VCALL1(pv_mmu_ops.flush_tlb_single, addr);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
 static inline void flush_tlb_others(const struct cpumask *cpumask,
 				    struct mm_struct *mm,
 				    unsigned long start,
<span class="p_chunk">@@ -104,375 +66,6 @@</span> <span class="p_context"> static inline void flush_tlb_others(const struct cpumask *cpumask,</span>
 	PVOP_VCALL4(pv_mmu_ops.flush_tlb_others, cpumask, mm, start, end);
 }
 
<span class="p_del">-static inline int paravirt_pgd_alloc(struct mm_struct *mm)</span>
<span class="p_del">-{</span>
<span class="p_del">-	return PVOP_CALL1(int, pv_mmu_ops.pgd_alloc, mm);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static inline void paravirt_pgd_free(struct mm_struct *mm, pgd_t *pgd)</span>
<span class="p_del">-{</span>
<span class="p_del">-	PVOP_VCALL2(pv_mmu_ops.pgd_free, mm, pgd);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static inline void paravirt_alloc_pte(struct mm_struct *mm, unsigned long pfn)</span>
<span class="p_del">-{</span>
<span class="p_del">-	PVOP_VCALL2(pv_mmu_ops.alloc_pte, mm, pfn);</span>
<span class="p_del">-}</span>
<span class="p_del">-static inline void paravirt_release_pte(unsigned long pfn)</span>
<span class="p_del">-{</span>
<span class="p_del">-	PVOP_VCALL1(pv_mmu_ops.release_pte, pfn);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static inline void paravirt_alloc_pmd(struct mm_struct *mm, unsigned long pfn)</span>
<span class="p_del">-{</span>
<span class="p_del">-	PVOP_VCALL2(pv_mmu_ops.alloc_pmd, mm, pfn);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static inline void paravirt_release_pmd(unsigned long pfn)</span>
<span class="p_del">-{</span>
<span class="p_del">-	PVOP_VCALL1(pv_mmu_ops.release_pmd, pfn);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static inline void paravirt_alloc_pud(struct mm_struct *mm, unsigned long pfn)</span>
<span class="p_del">-{</span>
<span class="p_del">-	PVOP_VCALL2(pv_mmu_ops.alloc_pud, mm, pfn);</span>
<span class="p_del">-}</span>
<span class="p_del">-static inline void paravirt_release_pud(unsigned long pfn)</span>
<span class="p_del">-{</span>
<span class="p_del">-	PVOP_VCALL1(pv_mmu_ops.release_pud, pfn);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static inline void paravirt_alloc_p4d(struct mm_struct *mm, unsigned long pfn)</span>
<span class="p_del">-{</span>
<span class="p_del">-	PVOP_VCALL2(pv_mmu_ops.alloc_p4d, mm, pfn);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static inline void paravirt_release_p4d(unsigned long pfn)</span>
<span class="p_del">-{</span>
<span class="p_del">-	PVOP_VCALL1(pv_mmu_ops.release_p4d, pfn);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static inline void pte_update(struct mm_struct *mm, unsigned long addr,</span>
<span class="p_del">-			      pte_t *ptep)</span>
<span class="p_del">-{</span>
<span class="p_del">-	PVOP_VCALL3(pv_mmu_ops.pte_update, mm, addr, ptep);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static inline pte_t __pte(pteval_t val)</span>
<span class="p_del">-{</span>
<span class="p_del">-	pteval_t ret;</span>
<span class="p_del">-</span>
<span class="p_del">-	if (sizeof(pteval_t) &gt; sizeof(long))</span>
<span class="p_del">-		ret = PVOP_CALLEE2(pteval_t,</span>
<span class="p_del">-				   pv_mmu_ops.make_pte,</span>
<span class="p_del">-				   val, (u64)val &gt;&gt; 32);</span>
<span class="p_del">-	else</span>
<span class="p_del">-		ret = PVOP_CALLEE1(pteval_t,</span>
<span class="p_del">-				   pv_mmu_ops.make_pte,</span>
<span class="p_del">-				   val);</span>
<span class="p_del">-</span>
<span class="p_del">-	return (pte_t) { .pte = ret };</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static inline pteval_t pte_val(pte_t pte)</span>
<span class="p_del">-{</span>
<span class="p_del">-	pteval_t ret;</span>
<span class="p_del">-</span>
<span class="p_del">-	if (sizeof(pteval_t) &gt; sizeof(long))</span>
<span class="p_del">-		ret = PVOP_CALLEE2(pteval_t, pv_mmu_ops.pte_val,</span>
<span class="p_del">-				   pte.pte, (u64)pte.pte &gt;&gt; 32);</span>
<span class="p_del">-	else</span>
<span class="p_del">-		ret = PVOP_CALLEE1(pteval_t, pv_mmu_ops.pte_val,</span>
<span class="p_del">-				   pte.pte);</span>
<span class="p_del">-</span>
<span class="p_del">-	return ret;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static inline pgd_t __pgd(pgdval_t val)</span>
<span class="p_del">-{</span>
<span class="p_del">-	pgdval_t ret;</span>
<span class="p_del">-</span>
<span class="p_del">-	if (sizeof(pgdval_t) &gt; sizeof(long))</span>
<span class="p_del">-		ret = PVOP_CALLEE2(pgdval_t, pv_mmu_ops.make_pgd,</span>
<span class="p_del">-				   val, (u64)val &gt;&gt; 32);</span>
<span class="p_del">-	else</span>
<span class="p_del">-		ret = PVOP_CALLEE1(pgdval_t, pv_mmu_ops.make_pgd,</span>
<span class="p_del">-				   val);</span>
<span class="p_del">-</span>
<span class="p_del">-	return (pgd_t) { ret };</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static inline pgdval_t pgd_val(pgd_t pgd)</span>
<span class="p_del">-{</span>
<span class="p_del">-	pgdval_t ret;</span>
<span class="p_del">-</span>
<span class="p_del">-	if (sizeof(pgdval_t) &gt; sizeof(long))</span>
<span class="p_del">-		ret =  PVOP_CALLEE2(pgdval_t, pv_mmu_ops.pgd_val,</span>
<span class="p_del">-				    pgd.pgd, (u64)pgd.pgd &gt;&gt; 32);</span>
<span class="p_del">-	else</span>
<span class="p_del">-		ret =  PVOP_CALLEE1(pgdval_t, pv_mmu_ops.pgd_val,</span>
<span class="p_del">-				    pgd.pgd);</span>
<span class="p_del">-</span>
<span class="p_del">-	return ret;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-#define  __HAVE_ARCH_PTEP_MODIFY_PROT_TRANSACTION</span>
<span class="p_del">-static inline pte_t ptep_modify_prot_start(struct mm_struct *mm, unsigned long addr,</span>
<span class="p_del">-					   pte_t *ptep)</span>
<span class="p_del">-{</span>
<span class="p_del">-	pteval_t ret;</span>
<span class="p_del">-</span>
<span class="p_del">-	ret = PVOP_CALL3(pteval_t, pv_mmu_ops.ptep_modify_prot_start,</span>
<span class="p_del">-			 mm, addr, ptep);</span>
<span class="p_del">-</span>
<span class="p_del">-	return (pte_t) { .pte = ret };</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static inline void ptep_modify_prot_commit(struct mm_struct *mm, unsigned long addr,</span>
<span class="p_del">-					   pte_t *ptep, pte_t pte)</span>
<span class="p_del">-{</span>
<span class="p_del">-	if (sizeof(pteval_t) &gt; sizeof(long))</span>
<span class="p_del">-		/* 5 arg words */</span>
<span class="p_del">-		pv_mmu_ops.ptep_modify_prot_commit(mm, addr, ptep, pte);</span>
<span class="p_del">-	else</span>
<span class="p_del">-		PVOP_VCALL4(pv_mmu_ops.ptep_modify_prot_commit,</span>
<span class="p_del">-			    mm, addr, ptep, pte.pte);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static inline void set_pte(pte_t *ptep, pte_t pte)</span>
<span class="p_del">-{</span>
<span class="p_del">-	if (sizeof(pteval_t) &gt; sizeof(long))</span>
<span class="p_del">-		PVOP_VCALL3(pv_mmu_ops.set_pte, ptep,</span>
<span class="p_del">-			    pte.pte, (u64)pte.pte &gt;&gt; 32);</span>
<span class="p_del">-	else</span>
<span class="p_del">-		PVOP_VCALL2(pv_mmu_ops.set_pte, ptep,</span>
<span class="p_del">-			    pte.pte);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static inline void set_pte_at(struct mm_struct *mm, unsigned long addr,</span>
<span class="p_del">-			      pte_t *ptep, pte_t pte)</span>
<span class="p_del">-{</span>
<span class="p_del">-	if (sizeof(pteval_t) &gt; sizeof(long))</span>
<span class="p_del">-		/* 5 arg words */</span>
<span class="p_del">-		pv_mmu_ops.set_pte_at(mm, addr, ptep, pte);</span>
<span class="p_del">-	else</span>
<span class="p_del">-		PVOP_VCALL4(pv_mmu_ops.set_pte_at, mm, addr, ptep, pte.pte);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static inline void set_pmd_at(struct mm_struct *mm, unsigned long addr,</span>
<span class="p_del">-			      pmd_t *pmdp, pmd_t pmd)</span>
<span class="p_del">-{</span>
<span class="p_del">-	if (sizeof(pmdval_t) &gt; sizeof(long))</span>
<span class="p_del">-		/* 5 arg words */</span>
<span class="p_del">-		pv_mmu_ops.set_pmd_at(mm, addr, pmdp, pmd);</span>
<span class="p_del">-	else</span>
<span class="p_del">-		PVOP_VCALL4(pv_mmu_ops.set_pmd_at, mm, addr, pmdp,</span>
<span class="p_del">-			    native_pmd_val(pmd));</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static inline void set_pud_at(struct mm_struct *mm, unsigned long addr,</span>
<span class="p_del">-			      pud_t *pudp, pud_t pud)</span>
<span class="p_del">-{</span>
<span class="p_del">-	if (sizeof(pudval_t) &gt; sizeof(long))</span>
<span class="p_del">-		/* 5 arg words */</span>
<span class="p_del">-		pv_mmu_ops.set_pud_at(mm, addr, pudp, pud);</span>
<span class="p_del">-	else</span>
<span class="p_del">-		PVOP_VCALL4(pv_mmu_ops.set_pud_at, mm, addr, pudp,</span>
<span class="p_del">-			    native_pud_val(pud));</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static inline void set_pmd(pmd_t *pmdp, pmd_t pmd)</span>
<span class="p_del">-{</span>
<span class="p_del">-	pmdval_t val = native_pmd_val(pmd);</span>
<span class="p_del">-</span>
<span class="p_del">-	if (sizeof(pmdval_t) &gt; sizeof(long))</span>
<span class="p_del">-		PVOP_VCALL3(pv_mmu_ops.set_pmd, pmdp, val, (u64)val &gt;&gt; 32);</span>
<span class="p_del">-	else</span>
<span class="p_del">-		PVOP_VCALL2(pv_mmu_ops.set_pmd, pmdp, val);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-#if CONFIG_PGTABLE_LEVELS &gt;= 3</span>
<span class="p_del">-static inline pmd_t __pmd(pmdval_t val)</span>
<span class="p_del">-{</span>
<span class="p_del">-	pmdval_t ret;</span>
<span class="p_del">-</span>
<span class="p_del">-	if (sizeof(pmdval_t) &gt; sizeof(long))</span>
<span class="p_del">-		ret = PVOP_CALLEE2(pmdval_t, pv_mmu_ops.make_pmd,</span>
<span class="p_del">-				   val, (u64)val &gt;&gt; 32);</span>
<span class="p_del">-	else</span>
<span class="p_del">-		ret = PVOP_CALLEE1(pmdval_t, pv_mmu_ops.make_pmd,</span>
<span class="p_del">-				   val);</span>
<span class="p_del">-</span>
<span class="p_del">-	return (pmd_t) { ret };</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static inline pmdval_t pmd_val(pmd_t pmd)</span>
<span class="p_del">-{</span>
<span class="p_del">-	pmdval_t ret;</span>
<span class="p_del">-</span>
<span class="p_del">-	if (sizeof(pmdval_t) &gt; sizeof(long))</span>
<span class="p_del">-		ret =  PVOP_CALLEE2(pmdval_t, pv_mmu_ops.pmd_val,</span>
<span class="p_del">-				    pmd.pmd, (u64)pmd.pmd &gt;&gt; 32);</span>
<span class="p_del">-	else</span>
<span class="p_del">-		ret =  PVOP_CALLEE1(pmdval_t, pv_mmu_ops.pmd_val,</span>
<span class="p_del">-				    pmd.pmd);</span>
<span class="p_del">-</span>
<span class="p_del">-	return ret;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static inline void set_pud(pud_t *pudp, pud_t pud)</span>
<span class="p_del">-{</span>
<span class="p_del">-	pudval_t val = native_pud_val(pud);</span>
<span class="p_del">-</span>
<span class="p_del">-	if (sizeof(pudval_t) &gt; sizeof(long))</span>
<span class="p_del">-		PVOP_VCALL3(pv_mmu_ops.set_pud, pudp,</span>
<span class="p_del">-			    val, (u64)val &gt;&gt; 32);</span>
<span class="p_del">-	else</span>
<span class="p_del">-		PVOP_VCALL2(pv_mmu_ops.set_pud, pudp,</span>
<span class="p_del">-			    val);</span>
<span class="p_del">-}</span>
<span class="p_del">-#if CONFIG_PGTABLE_LEVELS &gt;= 4</span>
<span class="p_del">-static inline pud_t __pud(pudval_t val)</span>
<span class="p_del">-{</span>
<span class="p_del">-	pudval_t ret;</span>
<span class="p_del">-</span>
<span class="p_del">-	if (sizeof(pudval_t) &gt; sizeof(long))</span>
<span class="p_del">-		ret = PVOP_CALLEE2(pudval_t, pv_mmu_ops.make_pud,</span>
<span class="p_del">-				   val, (u64)val &gt;&gt; 32);</span>
<span class="p_del">-	else</span>
<span class="p_del">-		ret = PVOP_CALLEE1(pudval_t, pv_mmu_ops.make_pud,</span>
<span class="p_del">-				   val);</span>
<span class="p_del">-</span>
<span class="p_del">-	return (pud_t) { ret };</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static inline pudval_t pud_val(pud_t pud)</span>
<span class="p_del">-{</span>
<span class="p_del">-	pudval_t ret;</span>
<span class="p_del">-</span>
<span class="p_del">-	if (sizeof(pudval_t) &gt; sizeof(long))</span>
<span class="p_del">-		ret =  PVOP_CALLEE2(pudval_t, pv_mmu_ops.pud_val,</span>
<span class="p_del">-				    pud.pud, (u64)pud.pud &gt;&gt; 32);</span>
<span class="p_del">-	else</span>
<span class="p_del">-		ret =  PVOP_CALLEE1(pudval_t, pv_mmu_ops.pud_val,</span>
<span class="p_del">-				    pud.pud);</span>
<span class="p_del">-</span>
<span class="p_del">-	return ret;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static inline void pud_clear(pud_t *pudp)</span>
<span class="p_del">-{</span>
<span class="p_del">-	set_pud(pudp, __pud(0));</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static inline void set_p4d(p4d_t *p4dp, p4d_t p4d)</span>
<span class="p_del">-{</span>
<span class="p_del">-	p4dval_t val = native_p4d_val(p4d);</span>
<span class="p_del">-</span>
<span class="p_del">-	if (sizeof(p4dval_t) &gt; sizeof(long))</span>
<span class="p_del">-		PVOP_VCALL3(pv_mmu_ops.set_p4d, p4dp,</span>
<span class="p_del">-			    val, (u64)val &gt;&gt; 32);</span>
<span class="p_del">-	else</span>
<span class="p_del">-		PVOP_VCALL2(pv_mmu_ops.set_p4d, p4dp,</span>
<span class="p_del">-			    val);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-#if CONFIG_PGTABLE_LEVELS &gt;= 5</span>
<span class="p_del">-</span>
<span class="p_del">-static inline p4d_t __p4d(p4dval_t val)</span>
<span class="p_del">-{</span>
<span class="p_del">-	p4dval_t ret = PVOP_CALLEE1(p4dval_t, pv_mmu_ops.make_p4d, val);</span>
<span class="p_del">-</span>
<span class="p_del">-	return (p4d_t) { ret };</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static inline p4dval_t p4d_val(p4d_t p4d)</span>
<span class="p_del">-{</span>
<span class="p_del">-	return PVOP_CALLEE1(p4dval_t, pv_mmu_ops.p4d_val, p4d.p4d);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static inline void set_pgd(pgd_t *pgdp, pgd_t pgd)</span>
<span class="p_del">-{</span>
<span class="p_del">-	pgdval_t val = native_pgd_val(pgd);</span>
<span class="p_del">-</span>
<span class="p_del">-	PVOP_VCALL2(pv_mmu_ops.set_pgd, pgdp, val);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static inline void pgd_clear(pgd_t *pgdp)</span>
<span class="p_del">-{</span>
<span class="p_del">-	set_pgd(pgdp, __pgd(0));</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-#endif  /* CONFIG_PGTABLE_LEVELS == 5 */</span>
<span class="p_del">-</span>
<span class="p_del">-static inline void p4d_clear(p4d_t *p4dp)</span>
<span class="p_del">-{</span>
<span class="p_del">-	set_p4d(p4dp, __p4d(0));</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-#endif	/* CONFIG_PGTABLE_LEVELS == 4 */</span>
<span class="p_del">-</span>
<span class="p_del">-#endif	/* CONFIG_PGTABLE_LEVELS &gt;= 3 */</span>
<span class="p_del">-</span>
<span class="p_del">-#ifdef CONFIG_X86_PAE</span>
<span class="p_del">-/* Special-case pte-setting operations for PAE, which can&#39;t update a</span>
<span class="p_del">-   64-bit pte atomically */</span>
<span class="p_del">-static inline void set_pte_atomic(pte_t *ptep, pte_t pte)</span>
<span class="p_del">-{</span>
<span class="p_del">-	PVOP_VCALL3(pv_mmu_ops.set_pte_atomic, ptep,</span>
<span class="p_del">-		    pte.pte, pte.pte &gt;&gt; 32);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static inline void pte_clear(struct mm_struct *mm, unsigned long addr,</span>
<span class="p_del">-			     pte_t *ptep)</span>
<span class="p_del">-{</span>
<span class="p_del">-	PVOP_VCALL3(pv_mmu_ops.pte_clear, mm, addr, ptep);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static inline void pmd_clear(pmd_t *pmdp)</span>
<span class="p_del">-{</span>
<span class="p_del">-	PVOP_VCALL1(pv_mmu_ops.pmd_clear, pmdp);</span>
<span class="p_del">-}</span>
<span class="p_del">-#else  /* !CONFIG_X86_PAE */</span>
<span class="p_del">-static inline void set_pte_atomic(pte_t *ptep, pte_t pte)</span>
<span class="p_del">-{</span>
<span class="p_del">-	set_pte(ptep, pte);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static inline void pte_clear(struct mm_struct *mm, unsigned long addr,</span>
<span class="p_del">-			     pte_t *ptep)</span>
<span class="p_del">-{</span>
<span class="p_del">-	set_pte_at(mm, addr, ptep, __pte(0));</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static inline void pmd_clear(pmd_t *pmdp)</span>
<span class="p_del">-{</span>
<span class="p_del">-	set_pmd(pmdp, __pmd(0));</span>
<span class="p_del">-}</span>
<span class="p_del">-#endif	/* CONFIG_X86_PAE */</span>
<span class="p_del">-</span>
<span class="p_del">-#define  __HAVE_ARCH_ENTER_LAZY_MMU_MODE</span>
<span class="p_del">-static inline void arch_enter_lazy_mmu_mode(void)</span>
<span class="p_del">-{</span>
<span class="p_del">-	PVOP_VCALL0(pv_mmu_ops.lazy_mode.enter);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static inline void arch_leave_lazy_mmu_mode(void)</span>
<span class="p_del">-{</span>
<span class="p_del">-	PVOP_VCALL0(pv_mmu_ops.lazy_mode.leave);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static inline void arch_flush_lazy_mmu_mode(void)</span>
<span class="p_del">-{</span>
<span class="p_del">-	PVOP_VCALL0(pv_mmu_ops.lazy_mode.flush);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static inline void __set_fixmap(unsigned /* enum fixed_addresses */ idx,</span>
<span class="p_del">-				phys_addr_t phys, pgprot_t flags)</span>
<span class="p_del">-{</span>
<span class="p_del">-	pv_mmu_ops.set_fixmap(idx, phys, flags);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
 #if defined(CONFIG_SMP) &amp;&amp; defined(CONFIG_PARAVIRT_SPINLOCKS)
 
 static __always_inline void pv_queued_spin_lock_slowpath(struct qspinlock *lock,
<span class="p_chunk">@@ -706,25 +299,22 @@</span> <span class="p_context"> extern void default_banner(void);</span>
 		  call PARA_INDIRECT(pv_irq_ops+PV_IRQ_irq_enable);	\
 		  PV_RESTORE_REGS(clobbers | CLBR_CALLEE_SAVE);)
 
<span class="p_del">-#ifdef CONFIG_X86_64</span>
<span class="p_del">-</span>
<span class="p_del">-#define GET_CR2_INTO_RAX				\</span>
<span class="p_del">-	call PARA_INDIRECT(pv_mmu_ops+PV_MMU_read_cr2)</span>
<span class="p_del">-</span>
<span class="p_del">-#endif	/* CONFIG_X86_64 */</span>
<span class="p_del">-</span>
 #endif /* __ASSEMBLY__ */
 #else  /* CONFIG_PARAVIRT */
 # define default_banner x86_init_noop
 #ifndef __ASSEMBLY__
<span class="p_del">-static inline void paravirt_arch_dup_mmap(struct mm_struct *oldmm,</span>
<span class="p_del">-					  struct mm_struct *mm)</span>
<span class="p_del">-{</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
 static inline void paravirt_arch_exit_mmap(struct mm_struct *mm)
 {
 }
 #endif /* __ASSEMBLY__ */
 #endif /* !CONFIG_PARAVIRT */
<span class="p_add">+</span>
<span class="p_add">+#ifndef CONFIG_PARAVIRT_FULL</span>
<span class="p_add">+#ifndef __ASSEMBLY__</span>
<span class="p_add">+static inline void paravirt_arch_dup_mmap(struct mm_struct *oldmm,</span>
<span class="p_add">+					  struct mm_struct *mm)</span>
<span class="p_add">+{</span>
<span class="p_add">+}</span>
<span class="p_add">+#endif /* __ASSEMBLY__ */</span>
<span class="p_add">+#endif /* CONFIG_PARAVIRT_FULL */</span>
 #endif /* _ASM_X86_PARAVIRT_H */
<span class="p_header">diff --git a/arch/x86/include/asm/paravirt_full.h b/arch/x86/include/asm/paravirt_full.h</span>
<span class="p_header">index 64753ef1d36f..53f2eb436ba3 100644</span>
<span class="p_header">--- a/arch/x86/include/asm/paravirt_full.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/paravirt_full.h</span>
<span class="p_chunk">@@ -241,6 +241,425 @@</span> <span class="p_context"> static inline void halt(void)</span>
 	PVOP_VCALL0(pvfull_irq_ops.halt);
 }
 
<span class="p_add">+static inline unsigned long read_cr2(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return PVOP_CALL0(unsigned long, pvfull_mmu_ops.read_cr2);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline void write_cr2(unsigned long x)</span>
<span class="p_add">+{</span>
<span class="p_add">+	PVOP_VCALL1(pvfull_mmu_ops.write_cr2, x);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline unsigned long read_cr3(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return PVOP_CALL0(unsigned long, pvfull_mmu_ops.read_cr3);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline void write_cr3(unsigned long x)</span>
<span class="p_add">+{</span>
<span class="p_add">+	PVOP_VCALL1(pvfull_mmu_ops.write_cr3, x);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline void paravirt_activate_mm(struct mm_struct *prev,</span>
<span class="p_add">+					struct mm_struct *next)</span>
<span class="p_add">+{</span>
<span class="p_add">+	PVOP_VCALL2(pvfull_mmu_ops.activate_mm, prev, next);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline void paravirt_arch_dup_mmap(struct mm_struct *oldmm,</span>
<span class="p_add">+					  struct mm_struct *mm)</span>
<span class="p_add">+{</span>
<span class="p_add">+	PVOP_VCALL2(pvfull_mmu_ops.dup_mmap, oldmm, mm);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline void __flush_tlb(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	PVOP_VCALL0(pvfull_mmu_ops.flush_tlb_user);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline void __flush_tlb_global(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	PVOP_VCALL0(pvfull_mmu_ops.flush_tlb_kernel);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline void __flush_tlb_single(unsigned long addr)</span>
<span class="p_add">+{</span>
<span class="p_add">+	PVOP_VCALL1(pvfull_mmu_ops.flush_tlb_single, addr);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline int paravirt_pgd_alloc(struct mm_struct *mm)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return PVOP_CALL1(int, pvfull_mmu_ops.pgd_alloc, mm);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline void paravirt_pgd_free(struct mm_struct *mm, pgd_t *pgd)</span>
<span class="p_add">+{</span>
<span class="p_add">+	PVOP_VCALL2(pvfull_mmu_ops.pgd_free, mm, pgd);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline void paravirt_alloc_pte(struct mm_struct *mm, unsigned long pfn)</span>
<span class="p_add">+{</span>
<span class="p_add">+	PVOP_VCALL2(pvfull_mmu_ops.alloc_pte, mm, pfn);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline void paravirt_release_pte(unsigned long pfn)</span>
<span class="p_add">+{</span>
<span class="p_add">+	PVOP_VCALL1(pvfull_mmu_ops.release_pte, pfn);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline void paravirt_alloc_pmd(struct mm_struct *mm, unsigned long pfn)</span>
<span class="p_add">+{</span>
<span class="p_add">+	PVOP_VCALL2(pvfull_mmu_ops.alloc_pmd, mm, pfn);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline void paravirt_release_pmd(unsigned long pfn)</span>
<span class="p_add">+{</span>
<span class="p_add">+	PVOP_VCALL1(pvfull_mmu_ops.release_pmd, pfn);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline void paravirt_alloc_pud(struct mm_struct *mm, unsigned long pfn)</span>
<span class="p_add">+{</span>
<span class="p_add">+	PVOP_VCALL2(pvfull_mmu_ops.alloc_pud, mm, pfn);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline void paravirt_release_pud(unsigned long pfn)</span>
<span class="p_add">+{</span>
<span class="p_add">+	PVOP_VCALL1(pvfull_mmu_ops.release_pud, pfn);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline void paravirt_alloc_p4d(struct mm_struct *mm, unsigned long pfn)</span>
<span class="p_add">+{</span>
<span class="p_add">+	PVOP_VCALL2(pvfull_mmu_ops.alloc_p4d, mm, pfn);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline void paravirt_release_p4d(unsigned long pfn)</span>
<span class="p_add">+{</span>
<span class="p_add">+	PVOP_VCALL1(pvfull_mmu_ops.release_p4d, pfn);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline void pte_update(struct mm_struct *mm, unsigned long addr,</span>
<span class="p_add">+			      pte_t *ptep)</span>
<span class="p_add">+{</span>
<span class="p_add">+	PVOP_VCALL3(pvfull_mmu_ops.pte_update, mm, addr, ptep);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline pte_t __pte(pteval_t val)</span>
<span class="p_add">+{</span>
<span class="p_add">+	pteval_t ret;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (sizeof(pteval_t) &gt; sizeof(long))</span>
<span class="p_add">+		ret = PVOP_CALLEE2(pteval_t,</span>
<span class="p_add">+				   pvfull_mmu_ops.make_pte,</span>
<span class="p_add">+				   val, (u64)val &gt;&gt; 32);</span>
<span class="p_add">+	else</span>
<span class="p_add">+		ret = PVOP_CALLEE1(pteval_t,</span>
<span class="p_add">+				   pvfull_mmu_ops.make_pte,</span>
<span class="p_add">+				   val);</span>
<span class="p_add">+</span>
<span class="p_add">+	return (pte_t) { .pte = ret };</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline pteval_t pte_val(pte_t pte)</span>
<span class="p_add">+{</span>
<span class="p_add">+	pteval_t ret;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (sizeof(pteval_t) &gt; sizeof(long))</span>
<span class="p_add">+		ret = PVOP_CALLEE2(pteval_t, pvfull_mmu_ops.pte_val,</span>
<span class="p_add">+				   pte.pte, (u64)pte.pte &gt;&gt; 32);</span>
<span class="p_add">+	else</span>
<span class="p_add">+		ret = PVOP_CALLEE1(pteval_t, pvfull_mmu_ops.pte_val,</span>
<span class="p_add">+				   pte.pte);</span>
<span class="p_add">+</span>
<span class="p_add">+	return ret;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline pgd_t __pgd(pgdval_t val)</span>
<span class="p_add">+{</span>
<span class="p_add">+	pgdval_t ret;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (sizeof(pgdval_t) &gt; sizeof(long))</span>
<span class="p_add">+		ret = PVOP_CALLEE2(pgdval_t, pvfull_mmu_ops.make_pgd,</span>
<span class="p_add">+				   val, (u64)val &gt;&gt; 32);</span>
<span class="p_add">+	else</span>
<span class="p_add">+		ret = PVOP_CALLEE1(pgdval_t, pvfull_mmu_ops.make_pgd,</span>
<span class="p_add">+				   val);</span>
<span class="p_add">+</span>
<span class="p_add">+	return (pgd_t) { ret };</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline pgdval_t pgd_val(pgd_t pgd)</span>
<span class="p_add">+{</span>
<span class="p_add">+	pgdval_t ret;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (sizeof(pgdval_t) &gt; sizeof(long))</span>
<span class="p_add">+		ret =  PVOP_CALLEE2(pgdval_t, pvfull_mmu_ops.pgd_val,</span>
<span class="p_add">+				    pgd.pgd, (u64)pgd.pgd &gt;&gt; 32);</span>
<span class="p_add">+	else</span>
<span class="p_add">+		ret =  PVOP_CALLEE1(pgdval_t, pvfull_mmu_ops.pgd_val,</span>
<span class="p_add">+				    pgd.pgd);</span>
<span class="p_add">+</span>
<span class="p_add">+	return ret;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+#define  __HAVE_ARCH_PTEP_MODIFY_PROT_TRANSACTION</span>
<span class="p_add">+static inline pte_t ptep_modify_prot_start(struct mm_struct *mm,</span>
<span class="p_add">+					   unsigned long addr, pte_t *ptep)</span>
<span class="p_add">+{</span>
<span class="p_add">+	pteval_t ret;</span>
<span class="p_add">+</span>
<span class="p_add">+	ret = PVOP_CALL3(pteval_t, pvfull_mmu_ops.ptep_modify_prot_start,</span>
<span class="p_add">+			 mm, addr, ptep);</span>
<span class="p_add">+</span>
<span class="p_add">+	return (pte_t) { .pte = ret };</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline void ptep_modify_prot_commit(struct mm_struct *mm,</span>
<span class="p_add">+					   unsigned long addr, pte_t *ptep,</span>
<span class="p_add">+					   pte_t pte)</span>
<span class="p_add">+{</span>
<span class="p_add">+	if (sizeof(pteval_t) &gt; sizeof(long))</span>
<span class="p_add">+		/* 5 arg words */</span>
<span class="p_add">+		pvfull_mmu_ops.ptep_modify_prot_commit(mm, addr, ptep, pte);</span>
<span class="p_add">+	else</span>
<span class="p_add">+		PVOP_VCALL4(pvfull_mmu_ops.ptep_modify_prot_commit,</span>
<span class="p_add">+			    mm, addr, ptep, pte.pte);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline void set_pte(pte_t *ptep, pte_t pte)</span>
<span class="p_add">+{</span>
<span class="p_add">+	if (sizeof(pteval_t) &gt; sizeof(long))</span>
<span class="p_add">+		PVOP_VCALL3(pvfull_mmu_ops.set_pte, ptep,</span>
<span class="p_add">+			    pte.pte, (u64)pte.pte &gt;&gt; 32);</span>
<span class="p_add">+	else</span>
<span class="p_add">+		PVOP_VCALL2(pvfull_mmu_ops.set_pte, ptep,</span>
<span class="p_add">+			    pte.pte);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline void set_pte_at(struct mm_struct *mm, unsigned long addr,</span>
<span class="p_add">+			      pte_t *ptep, pte_t pte)</span>
<span class="p_add">+{</span>
<span class="p_add">+	if (sizeof(pteval_t) &gt; sizeof(long))</span>
<span class="p_add">+		/* 5 arg words */</span>
<span class="p_add">+		pvfull_mmu_ops.set_pte_at(mm, addr, ptep, pte);</span>
<span class="p_add">+	else</span>
<span class="p_add">+		PVOP_VCALL4(pvfull_mmu_ops.set_pte_at, mm, addr, ptep, pte.pte);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline void set_pmd_at(struct mm_struct *mm, unsigned long addr,</span>
<span class="p_add">+			      pmd_t *pmdp, pmd_t pmd)</span>
<span class="p_add">+{</span>
<span class="p_add">+	if (sizeof(pmdval_t) &gt; sizeof(long))</span>
<span class="p_add">+		/* 5 arg words */</span>
<span class="p_add">+		pvfull_mmu_ops.set_pmd_at(mm, addr, pmdp, pmd);</span>
<span class="p_add">+	else</span>
<span class="p_add">+		PVOP_VCALL4(pvfull_mmu_ops.set_pmd_at, mm, addr, pmdp,</span>
<span class="p_add">+			    native_pmd_val(pmd));</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline void set_pud_at(struct mm_struct *mm, unsigned long addr,</span>
<span class="p_add">+			      pud_t *pudp, pud_t pud)</span>
<span class="p_add">+{</span>
<span class="p_add">+	if (sizeof(pudval_t) &gt; sizeof(long))</span>
<span class="p_add">+		/* 5 arg words */</span>
<span class="p_add">+		pvfull_mmu_ops.set_pud_at(mm, addr, pudp, pud);</span>
<span class="p_add">+	else</span>
<span class="p_add">+		PVOP_VCALL4(pvfull_mmu_ops.set_pud_at, mm, addr, pudp,</span>
<span class="p_add">+			    native_pud_val(pud));</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline void set_pmd(pmd_t *pmdp, pmd_t pmd)</span>
<span class="p_add">+{</span>
<span class="p_add">+	pmdval_t val = native_pmd_val(pmd);</span>
<span class="p_add">+</span>
<span class="p_add">+	if (sizeof(pmdval_t) &gt; sizeof(long))</span>
<span class="p_add">+		PVOP_VCALL3(pvfull_mmu_ops.set_pmd, pmdp, val, (u64)val &gt;&gt; 32);</span>
<span class="p_add">+	else</span>
<span class="p_add">+		PVOP_VCALL2(pvfull_mmu_ops.set_pmd, pmdp, val);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+#if CONFIG_PGTABLE_LEVELS &gt;= 3</span>
<span class="p_add">+static inline pmd_t __pmd(pmdval_t val)</span>
<span class="p_add">+{</span>
<span class="p_add">+	pmdval_t ret;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (sizeof(pmdval_t) &gt; sizeof(long))</span>
<span class="p_add">+		ret = PVOP_CALLEE2(pmdval_t, pvfull_mmu_ops.make_pmd,</span>
<span class="p_add">+				   val, (u64)val &gt;&gt; 32);</span>
<span class="p_add">+	else</span>
<span class="p_add">+		ret = PVOP_CALLEE1(pmdval_t, pvfull_mmu_ops.make_pmd,</span>
<span class="p_add">+				   val);</span>
<span class="p_add">+</span>
<span class="p_add">+	return (pmd_t) { ret };</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline pmdval_t pmd_val(pmd_t pmd)</span>
<span class="p_add">+{</span>
<span class="p_add">+	pmdval_t ret;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (sizeof(pmdval_t) &gt; sizeof(long))</span>
<span class="p_add">+		ret =  PVOP_CALLEE2(pmdval_t, pvfull_mmu_ops.pmd_val,</span>
<span class="p_add">+				    pmd.pmd, (u64)pmd.pmd &gt;&gt; 32);</span>
<span class="p_add">+	else</span>
<span class="p_add">+		ret =  PVOP_CALLEE1(pmdval_t, pvfull_mmu_ops.pmd_val,</span>
<span class="p_add">+				    pmd.pmd);</span>
<span class="p_add">+</span>
<span class="p_add">+	return ret;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline void set_pud(pud_t *pudp, pud_t pud)</span>
<span class="p_add">+{</span>
<span class="p_add">+	pudval_t val = native_pud_val(pud);</span>
<span class="p_add">+</span>
<span class="p_add">+	if (sizeof(pudval_t) &gt; sizeof(long))</span>
<span class="p_add">+		PVOP_VCALL3(pvfull_mmu_ops.set_pud, pudp,</span>
<span class="p_add">+			    val, (u64)val &gt;&gt; 32);</span>
<span class="p_add">+	else</span>
<span class="p_add">+		PVOP_VCALL2(pvfull_mmu_ops.set_pud, pudp,</span>
<span class="p_add">+			    val);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+#if CONFIG_PGTABLE_LEVELS &gt;= 4</span>
<span class="p_add">+static inline pud_t __pud(pudval_t val)</span>
<span class="p_add">+{</span>
<span class="p_add">+	pudval_t ret;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (sizeof(pudval_t) &gt; sizeof(long))</span>
<span class="p_add">+		ret = PVOP_CALLEE2(pudval_t, pvfull_mmu_ops.make_pud,</span>
<span class="p_add">+				   val, (u64)val &gt;&gt; 32);</span>
<span class="p_add">+	else</span>
<span class="p_add">+		ret = PVOP_CALLEE1(pudval_t, pvfull_mmu_ops.make_pud,</span>
<span class="p_add">+				   val);</span>
<span class="p_add">+</span>
<span class="p_add">+	return (pud_t) { ret };</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline pudval_t pud_val(pud_t pud)</span>
<span class="p_add">+{</span>
<span class="p_add">+	pudval_t ret;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (sizeof(pudval_t) &gt; sizeof(long))</span>
<span class="p_add">+		ret =  PVOP_CALLEE2(pudval_t, pvfull_mmu_ops.pud_val,</span>
<span class="p_add">+				    pud.pud, (u64)pud.pud &gt;&gt; 32);</span>
<span class="p_add">+	else</span>
<span class="p_add">+		ret =  PVOP_CALLEE1(pudval_t, pvfull_mmu_ops.pud_val,</span>
<span class="p_add">+				    pud.pud);</span>
<span class="p_add">+</span>
<span class="p_add">+	return ret;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline void pud_clear(pud_t *pudp)</span>
<span class="p_add">+{</span>
<span class="p_add">+	set_pud(pudp, __pud(0));</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline void set_p4d(p4d_t *p4dp, p4d_t p4d)</span>
<span class="p_add">+{</span>
<span class="p_add">+	p4dval_t val = native_p4d_val(p4d);</span>
<span class="p_add">+</span>
<span class="p_add">+	if (sizeof(p4dval_t) &gt; sizeof(long))</span>
<span class="p_add">+		PVOP_VCALL3(pvfull_mmu_ops.set_p4d, p4dp,</span>
<span class="p_add">+			    val, (u64)val &gt;&gt; 32);</span>
<span class="p_add">+	else</span>
<span class="p_add">+		PVOP_VCALL2(pvfull_mmu_ops.set_p4d, p4dp,</span>
<span class="p_add">+			    val);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+#if CONFIG_PGTABLE_LEVELS &gt;= 5</span>
<span class="p_add">+static inline p4d_t __p4d(p4dval_t val)</span>
<span class="p_add">+{</span>
<span class="p_add">+	p4dval_t ret = PVOP_CALLEE1(p4dval_t, pvfull_mmu_ops.make_p4d, val);</span>
<span class="p_add">+</span>
<span class="p_add">+	return (p4d_t) { ret };</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline p4dval_t p4d_val(p4d_t p4d)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return PVOP_CALLEE1(p4dval_t, pvfull_mmu_ops.p4d_val, p4d.p4d);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline void set_pgd(pgd_t *pgdp, pgd_t pgd)</span>
<span class="p_add">+{</span>
<span class="p_add">+	pgdval_t val = native_pgd_val(pgd);</span>
<span class="p_add">+</span>
<span class="p_add">+	PVOP_VCALL2(pvfull_mmu_ops.set_pgd, pgdp, val);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline void pgd_clear(pgd_t *pgdp)</span>
<span class="p_add">+{</span>
<span class="p_add">+	set_pgd(pgdp, __pgd(0));</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+#endif  /* CONFIG_PGTABLE_LEVELS &gt;= 5 */</span>
<span class="p_add">+</span>
<span class="p_add">+static inline void p4d_clear(p4d_t *p4dp)</span>
<span class="p_add">+{</span>
<span class="p_add">+	set_p4d(p4dp, __p4d(0));</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+#endif  /* CONFIG_PGTABLE_LEVELS &gt;= 4 */</span>
<span class="p_add">+</span>
<span class="p_add">+#endif  /* CONFIG_PGTABLE_LEVELS &gt;= 3 */</span>
<span class="p_add">+</span>
<span class="p_add">+#ifdef CONFIG_X86_PAE</span>
<span class="p_add">+/* Special-case pte-setting operations for PAE, which can&#39;t update a</span>
<span class="p_add">+   64-bit pte atomically */</span>
<span class="p_add">+static inline void set_pte_atomic(pte_t *ptep, pte_t pte)</span>
<span class="p_add">+{</span>
<span class="p_add">+	PVOP_VCALL3(pvfull_mmu_ops.set_pte_atomic, ptep,</span>
<span class="p_add">+		    pte.pte, pte.pte &gt;&gt; 32);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline void pte_clear(struct mm_struct *mm, unsigned long addr,</span>
<span class="p_add">+			     pte_t *ptep)</span>
<span class="p_add">+{</span>
<span class="p_add">+	PVOP_VCALL3(pvfull_mmu_ops.pte_clear, mm, addr, ptep);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline void pmd_clear(pmd_t *pmdp)</span>
<span class="p_add">+{</span>
<span class="p_add">+	PVOP_VCALL1(pvfull_mmu_ops.pmd_clear, pmdp);</span>
<span class="p_add">+}</span>
<span class="p_add">+#else  /* !CONFIG_X86_PAE */</span>
<span class="p_add">+static inline void set_pte_atomic(pte_t *ptep, pte_t pte)</span>
<span class="p_add">+{</span>
<span class="p_add">+	set_pte(ptep, pte);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline void pte_clear(struct mm_struct *mm, unsigned long addr,</span>
<span class="p_add">+			     pte_t *ptep)</span>
<span class="p_add">+{</span>
<span class="p_add">+	set_pte_at(mm, addr, ptep, __pte(0));</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline void pmd_clear(pmd_t *pmdp)</span>
<span class="p_add">+{</span>
<span class="p_add">+	set_pmd(pmdp, __pmd(0));</span>
<span class="p_add">+}</span>
<span class="p_add">+#endif  /* CONFIG_X86_PAE */</span>
<span class="p_add">+</span>
<span class="p_add">+#define  __HAVE_ARCH_ENTER_LAZY_MMU_MODE</span>
<span class="p_add">+static inline void arch_enter_lazy_mmu_mode(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	PVOP_VCALL0(pvfull_mmu_ops.lazy_mode.enter);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline void arch_leave_lazy_mmu_mode(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	PVOP_VCALL0(pvfull_mmu_ops.lazy_mode.leave);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline void arch_flush_lazy_mmu_mode(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	PVOP_VCALL0(pvfull_mmu_ops.lazy_mode.flush);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline void __set_fixmap(unsigned /* enum fixed_addresses */ idx,</span>
<span class="p_add">+				phys_addr_t phys, pgprot_t flags)</span>
<span class="p_add">+{</span>
<span class="p_add">+	pvfull_mmu_ops.set_fixmap(idx, phys, flags);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 #else /* __ASSEMBLY__ */
 
 #define INTERRUPT_RETURN						\
<span class="p_chunk">@@ -284,6 +703,9 @@</span> <span class="p_context"> static inline void halt(void)</span>
 		  call PARA_INDIRECT(pvfull_irq_ops +			\
 				     PV_IRQ_adjust_exception_frame))
 
<span class="p_add">+#define GET_CR2_INTO_RAX						\</span>
<span class="p_add">+	call PARA_INDIRECT(pvfull_mmu_ops+PV_MMU_read_cr2)</span>
<span class="p_add">+</span>
 #endif  /* CONFIG_X86_32 */
 
 #endif /* __ASSEMBLY__ */
<span class="p_header">diff --git a/arch/x86/include/asm/paravirt_types.h b/arch/x86/include/asm/paravirt_types.h</span>
<span class="p_header">index de95e6253516..b1ac2a5698b4 100644</span>
<span class="p_header">--- a/arch/x86/include/asm/paravirt_types.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/paravirt_types.h</span>
<span class="p_chunk">@@ -89,14 +89,6 @@</span> <span class="p_context"> struct pv_init_ops {</span>
 			  unsigned long addr, unsigned len);
 };
 
<span class="p_del">-</span>
<span class="p_del">-struct pv_lazy_ops {</span>
<span class="p_del">-	/* Set deferred update mode, used for batching operations. */</span>
<span class="p_del">-	void (*enter)(void);</span>
<span class="p_del">-	void (*leave)(void);</span>
<span class="p_del">-	void (*flush)(void);</span>
<span class="p_del">-};</span>
<span class="p_del">-</span>
 struct pv_time_ops {
 	unsigned long long (*sched_clock)(void);
 	unsigned long long (*steal_clock)(int cpu);
<span class="p_chunk">@@ -123,111 +115,11 @@</span> <span class="p_context"> struct pv_irq_ops {</span>
 };
 
 struct pv_mmu_ops {
<span class="p_del">-	unsigned long (*read_cr2)(void);</span>
<span class="p_del">-	void (*write_cr2)(unsigned long);</span>
<span class="p_del">-</span>
<span class="p_del">-	unsigned long (*read_cr3)(void);</span>
<span class="p_del">-	void (*write_cr3)(unsigned long);</span>
<span class="p_del">-</span>
<span class="p_del">-	/*</span>
<span class="p_del">-	 * Hooks for intercepting the creation/use/destruction of an</span>
<span class="p_del">-	 * mm_struct.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	void (*activate_mm)(struct mm_struct *prev,</span>
<span class="p_del">-			    struct mm_struct *next);</span>
<span class="p_del">-	void (*dup_mmap)(struct mm_struct *oldmm,</span>
<span class="p_del">-			 struct mm_struct *mm);</span>
 	void (*exit_mmap)(struct mm_struct *mm);
<span class="p_del">-</span>
<span class="p_del">-</span>
<span class="p_del">-	/* TLB operations */</span>
<span class="p_del">-	void (*flush_tlb_user)(void);</span>
<span class="p_del">-	void (*flush_tlb_kernel)(void);</span>
<span class="p_del">-	void (*flush_tlb_single)(unsigned long addr);</span>
 	void (*flush_tlb_others)(const struct cpumask *cpus,
 				 struct mm_struct *mm,
 				 unsigned long start,
 				 unsigned long end);
<span class="p_del">-</span>
<span class="p_del">-	/* Hooks for allocating and freeing a pagetable top-level */</span>
<span class="p_del">-	int  (*pgd_alloc)(struct mm_struct *mm);</span>
<span class="p_del">-	void (*pgd_free)(struct mm_struct *mm, pgd_t *pgd);</span>
<span class="p_del">-</span>
<span class="p_del">-	/*</span>
<span class="p_del">-	 * Hooks for allocating/releasing pagetable pages when they&#39;re</span>
<span class="p_del">-	 * attached to a pagetable</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	void (*alloc_pte)(struct mm_struct *mm, unsigned long pfn);</span>
<span class="p_del">-	void (*alloc_pmd)(struct mm_struct *mm, unsigned long pfn);</span>
<span class="p_del">-	void (*alloc_pud)(struct mm_struct *mm, unsigned long pfn);</span>
<span class="p_del">-	void (*alloc_p4d)(struct mm_struct *mm, unsigned long pfn);</span>
<span class="p_del">-	void (*release_pte)(unsigned long pfn);</span>
<span class="p_del">-	void (*release_pmd)(unsigned long pfn);</span>
<span class="p_del">-	void (*release_pud)(unsigned long pfn);</span>
<span class="p_del">-	void (*release_p4d)(unsigned long pfn);</span>
<span class="p_del">-</span>
<span class="p_del">-	/* Pagetable manipulation functions */</span>
<span class="p_del">-	void (*set_pte)(pte_t *ptep, pte_t pteval);</span>
<span class="p_del">-	void (*set_pte_at)(struct mm_struct *mm, unsigned long addr,</span>
<span class="p_del">-			   pte_t *ptep, pte_t pteval);</span>
<span class="p_del">-	void (*set_pmd)(pmd_t *pmdp, pmd_t pmdval);</span>
<span class="p_del">-	void (*set_pmd_at)(struct mm_struct *mm, unsigned long addr,</span>
<span class="p_del">-			   pmd_t *pmdp, pmd_t pmdval);</span>
<span class="p_del">-	void (*set_pud_at)(struct mm_struct *mm, unsigned long addr,</span>
<span class="p_del">-			   pud_t *pudp, pud_t pudval);</span>
<span class="p_del">-	void (*pte_update)(struct mm_struct *mm, unsigned long addr,</span>
<span class="p_del">-			   pte_t *ptep);</span>
<span class="p_del">-</span>
<span class="p_del">-	pte_t (*ptep_modify_prot_start)(struct mm_struct *mm, unsigned long addr,</span>
<span class="p_del">-					pte_t *ptep);</span>
<span class="p_del">-	void (*ptep_modify_prot_commit)(struct mm_struct *mm, unsigned long addr,</span>
<span class="p_del">-					pte_t *ptep, pte_t pte);</span>
<span class="p_del">-</span>
<span class="p_del">-	struct paravirt_callee_save pte_val;</span>
<span class="p_del">-	struct paravirt_callee_save make_pte;</span>
<span class="p_del">-</span>
<span class="p_del">-	struct paravirt_callee_save pgd_val;</span>
<span class="p_del">-	struct paravirt_callee_save make_pgd;</span>
<span class="p_del">-</span>
<span class="p_del">-#if CONFIG_PGTABLE_LEVELS &gt;= 3</span>
<span class="p_del">-#ifdef CONFIG_X86_PAE</span>
<span class="p_del">-	void (*set_pte_atomic)(pte_t *ptep, pte_t pteval);</span>
<span class="p_del">-	void (*pte_clear)(struct mm_struct *mm, unsigned long addr,</span>
<span class="p_del">-			  pte_t *ptep);</span>
<span class="p_del">-	void (*pmd_clear)(pmd_t *pmdp);</span>
<span class="p_del">-</span>
<span class="p_del">-#endif	/* CONFIG_X86_PAE */</span>
<span class="p_del">-</span>
<span class="p_del">-	void (*set_pud)(pud_t *pudp, pud_t pudval);</span>
<span class="p_del">-</span>
<span class="p_del">-	struct paravirt_callee_save pmd_val;</span>
<span class="p_del">-	struct paravirt_callee_save make_pmd;</span>
<span class="p_del">-</span>
<span class="p_del">-#if CONFIG_PGTABLE_LEVELS &gt;= 4</span>
<span class="p_del">-	struct paravirt_callee_save pud_val;</span>
<span class="p_del">-	struct paravirt_callee_save make_pud;</span>
<span class="p_del">-</span>
<span class="p_del">-	void (*set_p4d)(p4d_t *p4dp, p4d_t p4dval);</span>
<span class="p_del">-</span>
<span class="p_del">-#if CONFIG_PGTABLE_LEVELS &gt;= 5</span>
<span class="p_del">-	struct paravirt_callee_save p4d_val;</span>
<span class="p_del">-	struct paravirt_callee_save make_p4d;</span>
<span class="p_del">-</span>
<span class="p_del">-	void (*set_pgd)(pgd_t *pgdp, pgd_t pgdval);</span>
<span class="p_del">-#endif	/* CONFIG_PGTABLE_LEVELS &gt;= 5 */</span>
<span class="p_del">-</span>
<span class="p_del">-#endif	/* CONFIG_PGTABLE_LEVELS &gt;= 4 */</span>
<span class="p_del">-</span>
<span class="p_del">-#endif	/* CONFIG_PGTABLE_LEVELS &gt;= 3 */</span>
<span class="p_del">-</span>
<span class="p_del">-	struct pv_lazy_ops lazy_mode;</span>
<span class="p_del">-</span>
<span class="p_del">-	/* dom0 ops */</span>
<span class="p_del">-</span>
<span class="p_del">-	/* Sometimes the physical address is a pfn, and sometimes its</span>
<span class="p_del">-	   an mfn.  We can tell which is which from the index. */</span>
<span class="p_del">-	void (*set_fixmap)(unsigned /* enum fixed_addresses */ idx,</span>
<span class="p_del">-			   phys_addr_t phys, pgprot_t flags);</span>
 };
 
 struct arch_spinlock;
<span class="p_chunk">@@ -260,6 +152,7 @@</span> <span class="p_context"> struct paravirt_patch_template {</span>
 #ifdef CONFIG_PARAVIRT_FULL
 	struct pvfull_cpu_ops pvfull_cpu_ops;
 	struct pvfull_irq_ops pvfull_irq_ops;
<span class="p_add">+	struct pvfull_mmu_ops pvfull_mmu_ops;</span>
 #endif
 };
 
<span class="p_chunk">@@ -599,14 +492,6 @@</span> <span class="p_context"> enum paravirt_lazy_mode {</span>
 	PARAVIRT_LAZY_CPU,
 };
 
<span class="p_del">-enum paravirt_lazy_mode paravirt_get_lazy_mode(void);</span>
<span class="p_del">-void paravirt_start_context_switch(struct task_struct *prev);</span>
<span class="p_del">-void paravirt_end_context_switch(struct task_struct *next);</span>
<span class="p_del">-</span>
<span class="p_del">-void paravirt_enter_lazy_mmu(void);</span>
<span class="p_del">-void paravirt_leave_lazy_mmu(void);</span>
<span class="p_del">-void paravirt_flush_lazy_mmu(void);</span>
<span class="p_del">-</span>
 void _paravirt_nop(void);
 u32 _paravirt_ident_32(u32);
 u64 _paravirt_ident_64(u64);
<span class="p_header">diff --git a/arch/x86/include/asm/paravirt_types_full.h b/arch/x86/include/asm/paravirt_types_full.h</span>
<span class="p_header">index eabc0ecec8e4..15d595a5f9d2 100644</span>
<span class="p_header">--- a/arch/x86/include/asm/paravirt_types_full.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/paravirt_types_full.h</span>
<span class="p_chunk">@@ -1,6 +1,13 @@</span> <span class="p_context"></span>
 #ifndef _ASM_X86_PARAVIRT_TYPES_FULL_H
 #define _ASM_X86_PARAVIRT_TYPES_FULL_H
 
<span class="p_add">+struct pv_lazy_ops {</span>
<span class="p_add">+	/* Set deferred update mode, used for batching operations. */</span>
<span class="p_add">+	void (*enter)(void);</span>
<span class="p_add">+	void (*leave)(void);</span>
<span class="p_add">+	void (*flush)(void);</span>
<span class="p_add">+};</span>
<span class="p_add">+</span>
 struct pvfull_cpu_ops {
 	/* hooks for various privileged instructions */
 	unsigned long (*get_debugreg)(int regno);
<span class="p_chunk">@@ -86,7 +93,116 @@</span> <span class="p_context"> struct pvfull_irq_ops {</span>
 #endif
 };
 
<span class="p_add">+struct pvfull_mmu_ops {</span>
<span class="p_add">+	unsigned long (*read_cr2)(void);</span>
<span class="p_add">+	void (*write_cr2)(unsigned long);</span>
<span class="p_add">+</span>
<span class="p_add">+	unsigned long (*read_cr3)(void);</span>
<span class="p_add">+	void (*write_cr3)(unsigned long);</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Hooks for intercepting the creation/use/destruction of an</span>
<span class="p_add">+	 * mm_struct.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	void (*activate_mm)(struct mm_struct *prev,</span>
<span class="p_add">+			    struct mm_struct *next);</span>
<span class="p_add">+	void (*dup_mmap)(struct mm_struct *oldmm,</span>
<span class="p_add">+			 struct mm_struct *mm);</span>
<span class="p_add">+</span>
<span class="p_add">+	/* TLB operations */</span>
<span class="p_add">+	void (*flush_tlb_user)(void);</span>
<span class="p_add">+	void (*flush_tlb_kernel)(void);</span>
<span class="p_add">+	void (*flush_tlb_single)(unsigned long addr);</span>
<span class="p_add">+</span>
<span class="p_add">+	/* Hooks for allocating and freeing a pagetable top-level */</span>
<span class="p_add">+	int  (*pgd_alloc)(struct mm_struct *mm);</span>
<span class="p_add">+	void (*pgd_free)(struct mm_struct *mm, pgd_t *pgd);</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Hooks for allocating/releasing pagetable pages when they&#39;re</span>
<span class="p_add">+	 * attached to a pagetable</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	void (*alloc_pte)(struct mm_struct *mm, unsigned long pfn);</span>
<span class="p_add">+	void (*alloc_pmd)(struct mm_struct *mm, unsigned long pfn);</span>
<span class="p_add">+	void (*alloc_pud)(struct mm_struct *mm, unsigned long pfn);</span>
<span class="p_add">+	void (*alloc_p4d)(struct mm_struct *mm, unsigned long pfn);</span>
<span class="p_add">+	void (*release_pte)(unsigned long pfn);</span>
<span class="p_add">+	void (*release_pmd)(unsigned long pfn);</span>
<span class="p_add">+	void (*release_pud)(unsigned long pfn);</span>
<span class="p_add">+	void (*release_p4d)(unsigned long pfn);</span>
<span class="p_add">+</span>
<span class="p_add">+	/* Pagetable manipulation functions */</span>
<span class="p_add">+	void (*set_pte)(pte_t *ptep, pte_t pteval);</span>
<span class="p_add">+	void (*set_pte_at)(struct mm_struct *mm, unsigned long addr,</span>
<span class="p_add">+			   pte_t *ptep, pte_t pteval);</span>
<span class="p_add">+	void (*set_pmd)(pmd_t *pmdp, pmd_t pmdval);</span>
<span class="p_add">+	void (*set_pmd_at)(struct mm_struct *mm, unsigned long addr,</span>
<span class="p_add">+			   pmd_t *pmdp, pmd_t pmdval);</span>
<span class="p_add">+	void (*set_pud_at)(struct mm_struct *mm, unsigned long addr,</span>
<span class="p_add">+			   pud_t *pudp, pud_t pudval);</span>
<span class="p_add">+	void (*pte_update)(struct mm_struct *mm, unsigned long addr,</span>
<span class="p_add">+			   pte_t *ptep);</span>
<span class="p_add">+</span>
<span class="p_add">+	pte_t (*ptep_modify_prot_start)(struct mm_struct *mm, unsigned long addr,</span>
<span class="p_add">+					pte_t *ptep);</span>
<span class="p_add">+	void (*ptep_modify_prot_commit)(struct mm_struct *mm, unsigned long addr,</span>
<span class="p_add">+					pte_t *ptep, pte_t pte);</span>
<span class="p_add">+</span>
<span class="p_add">+	struct paravirt_callee_save pte_val;</span>
<span class="p_add">+	struct paravirt_callee_save make_pte;</span>
<span class="p_add">+</span>
<span class="p_add">+	struct paravirt_callee_save pgd_val;</span>
<span class="p_add">+	struct paravirt_callee_save make_pgd;</span>
<span class="p_add">+</span>
<span class="p_add">+#if CONFIG_PGTABLE_LEVELS &gt;= 3</span>
<span class="p_add">+#ifdef CONFIG_X86_PAE</span>
<span class="p_add">+	void (*set_pte_atomic)(pte_t *ptep, pte_t pteval);</span>
<span class="p_add">+	void (*pte_clear)(struct mm_struct *mm, unsigned long addr,</span>
<span class="p_add">+			  pte_t *ptep);</span>
<span class="p_add">+	void (*pmd_clear)(pmd_t *pmdp);</span>
<span class="p_add">+</span>
<span class="p_add">+#endif  /* CONFIG_X86_PAE */</span>
<span class="p_add">+</span>
<span class="p_add">+	void (*set_pud)(pud_t *pudp, pud_t pudval);</span>
<span class="p_add">+</span>
<span class="p_add">+	struct paravirt_callee_save pmd_val;</span>
<span class="p_add">+	struct paravirt_callee_save make_pmd;</span>
<span class="p_add">+</span>
<span class="p_add">+#if CONFIG_PGTABLE_LEVELS &gt;= 4</span>
<span class="p_add">+	struct paravirt_callee_save pud_val;</span>
<span class="p_add">+	struct paravirt_callee_save make_pud;</span>
<span class="p_add">+</span>
<span class="p_add">+	void (*set_p4d)(p4d_t *p4dp, p4d_t p4dval);</span>
<span class="p_add">+</span>
<span class="p_add">+#if CONFIG_PGTABLE_LEVELS &gt;= 5</span>
<span class="p_add">+	struct paravirt_callee_save p4d_val;</span>
<span class="p_add">+	struct paravirt_callee_save make_p4d;</span>
<span class="p_add">+</span>
<span class="p_add">+	void (*set_pgd)(pgd_t *pgdp, pgd_t pgdval);</span>
<span class="p_add">+#endif  /* CONFIG_PGTABLE_LEVELS &gt;= 5 */</span>
<span class="p_add">+</span>
<span class="p_add">+#endif  /* CONFIG_PGTABLE_LEVELS &gt;= 4 */</span>
<span class="p_add">+</span>
<span class="p_add">+#endif  /* CONFIG_PGTABLE_LEVELS &gt;= 3 */</span>
<span class="p_add">+</span>
<span class="p_add">+	struct pv_lazy_ops lazy_mode;</span>
<span class="p_add">+</span>
<span class="p_add">+	/* Sometimes the physical address is a pfn, and sometimes its</span>
<span class="p_add">+	   an mfn.  We can tell which is which from the index. */</span>
<span class="p_add">+	void (*set_fixmap)(unsigned /* enum fixed_addresses */ idx,</span>
<span class="p_add">+			   phys_addr_t phys, pgprot_t flags);</span>
<span class="p_add">+};</span>
<span class="p_add">+</span>
 extern struct pvfull_cpu_ops pvfull_cpu_ops;
 extern struct pvfull_irq_ops pvfull_irq_ops;
<span class="p_add">+extern struct pvfull_mmu_ops pvfull_mmu_ops;</span>
<span class="p_add">+</span>
<span class="p_add">+enum paravirt_lazy_mode paravirt_get_lazy_mode(void);</span>
<span class="p_add">+void paravirt_start_context_switch(struct task_struct *prev);</span>
<span class="p_add">+void paravirt_end_context_switch(struct task_struct *next);</span>
<span class="p_add">+</span>
<span class="p_add">+void paravirt_enter_lazy_mmu(void);</span>
<span class="p_add">+void paravirt_leave_lazy_mmu(void);</span>
<span class="p_add">+void paravirt_flush_lazy_mmu(void);</span>
 
 #endif  /* _ASM_X86_PARAVIRT_TYPES_FULL_H */
<span class="p_header">diff --git a/arch/x86/include/asm/pgalloc.h b/arch/x86/include/asm/pgalloc.h</span>
<span class="p_header">index 71de65bb1791..5cff39bd7f6d 100644</span>
<span class="p_header">--- a/arch/x86/include/asm/pgalloc.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/pgalloc.h</span>
<span class="p_chunk">@@ -7,7 +7,7 @@</span> <span class="p_context"></span>
 
 static inline int  __paravirt_pgd_alloc(struct mm_struct *mm) { return 0; }
 
<span class="p_del">-#ifdef CONFIG_PARAVIRT</span>
<span class="p_add">+#ifdef CONFIG_PARAVIRT_FULL</span>
 #include &lt;asm/paravirt.h&gt;
 #else
 #define paravirt_pgd_alloc(mm)	__paravirt_pgd_alloc(mm)
<span class="p_header">diff --git a/arch/x86/include/asm/pgtable.h b/arch/x86/include/asm/pgtable.h</span>
<span class="p_header">index fad12c481bf9..60c8f2ac7fee 100644</span>
<span class="p_header">--- a/arch/x86/include/asm/pgtable.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/pgtable.h</span>
<span class="p_chunk">@@ -38,9 +38,9 @@</span> <span class="p_context"> extern struct list_head pgd_list;</span>
 
 extern struct mm_struct *pgd_page_get_mm(struct page *page);
 
<span class="p_del">-#ifdef CONFIG_PARAVIRT</span>
<span class="p_add">+#ifdef CONFIG_PARAVIRT_FULL</span>
 #include &lt;asm/paravirt.h&gt;
<span class="p_del">-#else  /* !CONFIG_PARAVIRT */</span>
<span class="p_add">+#else  /* !CONFIG_PARAVIRT_FULL */</span>
 #define set_pte(ptep, pte)		native_set_pte(ptep, pte)
 #define set_pte_at(mm, addr, ptep, pte)	native_set_pte_at(mm, addr, ptep, pte)
 #define set_pmd_at(mm, addr, pmdp, pmd)	native_set_pmd_at(mm, addr, pmdp, pmd)
<span class="p_chunk">@@ -98,10 +98,6 @@</span> <span class="p_context"> extern struct mm_struct *pgd_page_get_mm(struct page *page);</span>
 #define pte_val(x)	native_pte_val(x)
 #define __pte(x)	native_make_pte(x)
 
<span class="p_del">-#endif	/* CONFIG_PARAVIRT */</span>
<span class="p_del">-</span>
<span class="p_del">-#ifndef CONFIG_PARAVIRT_FULL</span>
<span class="p_del">-</span>
 #define arch_end_context_switch(prev)	do {} while (0)
 
 #endif  /* CONFIG_PARAVIRT_FULL */
<span class="p_header">diff --git a/arch/x86/include/asm/special_insns.h b/arch/x86/include/asm/special_insns.h</span>
<span class="p_header">index ca3a3103791d..1ad38e40a770 100644</span>
<span class="p_header">--- a/arch/x86/include/asm/special_insns.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/special_insns.h</span>
<span class="p_chunk">@@ -135,7 +135,7 @@</span> <span class="p_context"> static inline void native_wbinvd(void)</span>
 
 extern asmlinkage void native_load_gs_index(unsigned);
 
<span class="p_del">-#ifdef CONFIG_PARAVIRT</span>
<span class="p_add">+#ifdef CONFIG_PARAVIRT_FULL</span>
 #include &lt;asm/paravirt.h&gt;
 #else
 
<span class="p_chunk">@@ -159,10 +159,6 @@</span> <span class="p_context"> static inline void write_cr3(unsigned long x)</span>
 	native_write_cr3(x);
 }
 
<span class="p_del">-#endif/* CONFIG_PARAVIRT */</span>
<span class="p_del">-</span>
<span class="p_del">-#ifndef CONFIG_PARAVIRT_FULL</span>
<span class="p_del">-</span>
 static inline unsigned long read_cr0(void)
 {
 	return native_read_cr0();
<span class="p_header">diff --git a/arch/x86/include/asm/tlbflush.h b/arch/x86/include/asm/tlbflush.h</span>
<span class="p_header">index 6ed9ea469b48..6b0b6a1f231f 100644</span>
<span class="p_header">--- a/arch/x86/include/asm/tlbflush.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/tlbflush.h</span>
<span class="p_chunk">@@ -56,7 +56,7 @@</span> <span class="p_context"> static inline void invpcid_flush_all_nonglobals(void)</span>
 	__invpcid(0, 0, INVPCID_TYPE_ALL_NON_GLOBAL);
 }
 
<span class="p_del">-#ifdef CONFIG_PARAVIRT</span>
<span class="p_add">+#ifdef CONFIG_PARAVIRT_FULL</span>
 #include &lt;asm/paravirt.h&gt;
 #else
 #define __flush_tlb() __native_flush_tlb()
<span class="p_header">diff --git a/arch/x86/kernel/asm-offsets.c b/arch/x86/kernel/asm-offsets.c</span>
<span class="p_header">index a32148390e49..18a5c06c007a 100644</span>
<span class="p_header">--- a/arch/x86/kernel/asm-offsets.c</span>
<span class="p_header">+++ b/arch/x86/kernel/asm-offsets.c</span>
<span class="p_chunk">@@ -67,15 +67,17 @@</span> <span class="p_context"> void common(void) {</span>
 	OFFSET(PARAVIRT_PATCH_pv_irq_ops, paravirt_patch_template, pv_irq_ops);
 	OFFSET(PV_IRQ_irq_disable, pv_irq_ops, irq_disable);
 	OFFSET(PV_IRQ_irq_enable, pv_irq_ops, irq_enable);
<span class="p_del">-	OFFSET(PV_MMU_read_cr2, pv_mmu_ops, read_cr2);</span>
 #endif
 #ifdef CONFIG_PARAVIRT_FULL
 	OFFSET(PARAVIRT_PATCH_pvfull_cpu_ops, paravirt_patch_template,
 	       pvfull_cpu_ops);
 	OFFSET(PARAVIRT_PATCH_pvfull_irq_ops, paravirt_patch_template,
 	       pvfull_irq_ops);
<span class="p_add">+	OFFSET(PARAVIRT_PATCH_pvfull_mmu_ops, paravirt_patch_template,</span>
<span class="p_add">+	       pvfull_mmu_ops);</span>
 	OFFSET(PV_CPU_iret, pvfull_cpu_ops, iret);
 	OFFSET(PV_CPU_read_cr0, pvfull_cpu_ops, read_cr0);
<span class="p_add">+	OFFSET(PV_MMU_read_cr2, pvfull_mmu_ops, read_cr2);</span>
 #endif
 
 #ifdef CONFIG_XEN
<span class="p_header">diff --git a/arch/x86/kernel/head_64.S b/arch/x86/kernel/head_64.S</span>
<span class="p_header">index ac9d327d2e42..f004edaf0d1f 100644</span>
<span class="p_header">--- a/arch/x86/kernel/head_64.S</span>
<span class="p_header">+++ b/arch/x86/kernel/head_64.S</span>
<span class="p_chunk">@@ -23,7 +23,7 @@</span> <span class="p_context"></span>
 #include &quot;../entry/calling.h&quot;
 #include &lt;asm/export.h&gt;
 
<span class="p_del">-#ifdef CONFIG_PARAVIRT</span>
<span class="p_add">+#ifdef CONFIG_PARAVIRT_FULL</span>
 #include &lt;asm/asm-offsets.h&gt;
 #include &lt;asm/paravirt.h&gt;
 #define GET_CR2_INTO(reg) GET_CR2_INTO_RAX ; movq %rax, reg
<span class="p_header">diff --git a/arch/x86/kernel/paravirt.c b/arch/x86/kernel/paravirt.c</span>
<span class="p_header">index 8e22cfc73349..6fb642572bff 100644</span>
<span class="p_header">--- a/arch/x86/kernel/paravirt.c</span>
<span class="p_header">+++ b/arch/x86/kernel/paravirt.c</span>
<span class="p_chunk">@@ -28,12 +28,9 @@</span> <span class="p_context"></span>
 #include &lt;asm/bug.h&gt;
 #include &lt;asm/paravirt.h&gt;
 #include &lt;asm/setup.h&gt;
<span class="p_del">-#include &lt;asm/pgtable.h&gt;</span>
 #include &lt;asm/time.h&gt;
<span class="p_del">-#include &lt;asm/pgalloc.h&gt;</span>
 #include &lt;asm/irq.h&gt;
 #include &lt;asm/delay.h&gt;
<span class="p_del">-#include &lt;asm/fixmap.h&gt;</span>
 #include &lt;asm/apic.h&gt;
 #include &lt;asm/tlbflush.h&gt;
 #include &lt;asm/timer.h&gt;
<span class="p_chunk">@@ -179,25 +176,6 @@</span> <span class="p_context"> unsigned paravirt_patch_insns(void *insnbuf, unsigned len,</span>
 	return insn_len;
 }
 
<span class="p_del">-static void native_flush_tlb(void)</span>
<span class="p_del">-{</span>
<span class="p_del">-	__native_flush_tlb();</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-/*</span>
<span class="p_del">- * Global pages have to be flushed a bit differently. Not a real</span>
<span class="p_del">- * performance problem because this does not happen often.</span>
<span class="p_del">- */</span>
<span class="p_del">-static void native_flush_tlb_global(void)</span>
<span class="p_del">-{</span>
<span class="p_del">-	__native_flush_tlb_global();</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static void native_flush_tlb_single(unsigned long addr)</span>
<span class="p_del">-{</span>
<span class="p_del">-	__native_flush_tlb_single(addr);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
 struct static_key paravirt_steal_enabled;
 struct static_key paravirt_steal_rq_enabled;
 
<span class="p_chunk">@@ -206,73 +184,6 @@</span> <span class="p_context"> static u64 native_steal_clock(int cpu)</span>
 	return 0;
 }
 
<span class="p_del">-static DEFINE_PER_CPU(enum paravirt_lazy_mode, paravirt_lazy_mode) = PARAVIRT_LAZY_NONE;</span>
<span class="p_del">-</span>
<span class="p_del">-static inline void enter_lazy(enum paravirt_lazy_mode mode)</span>
<span class="p_del">-{</span>
<span class="p_del">-	BUG_ON(this_cpu_read(paravirt_lazy_mode) != PARAVIRT_LAZY_NONE);</span>
<span class="p_del">-</span>
<span class="p_del">-	this_cpu_write(paravirt_lazy_mode, mode);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static void leave_lazy(enum paravirt_lazy_mode mode)</span>
<span class="p_del">-{</span>
<span class="p_del">-	BUG_ON(this_cpu_read(paravirt_lazy_mode) != mode);</span>
<span class="p_del">-</span>
<span class="p_del">-	this_cpu_write(paravirt_lazy_mode, PARAVIRT_LAZY_NONE);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-void paravirt_enter_lazy_mmu(void)</span>
<span class="p_del">-{</span>
<span class="p_del">-	enter_lazy(PARAVIRT_LAZY_MMU);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-void paravirt_leave_lazy_mmu(void)</span>
<span class="p_del">-{</span>
<span class="p_del">-	leave_lazy(PARAVIRT_LAZY_MMU);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-void paravirt_flush_lazy_mmu(void)</span>
<span class="p_del">-{</span>
<span class="p_del">-	preempt_disable();</span>
<span class="p_del">-</span>
<span class="p_del">-	if (paravirt_get_lazy_mode() == PARAVIRT_LAZY_MMU) {</span>
<span class="p_del">-		arch_leave_lazy_mmu_mode();</span>
<span class="p_del">-		arch_enter_lazy_mmu_mode();</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">-	preempt_enable();</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-void paravirt_start_context_switch(struct task_struct *prev)</span>
<span class="p_del">-{</span>
<span class="p_del">-	BUG_ON(preemptible());</span>
<span class="p_del">-</span>
<span class="p_del">-	if (this_cpu_read(paravirt_lazy_mode) == PARAVIRT_LAZY_MMU) {</span>
<span class="p_del">-		arch_leave_lazy_mmu_mode();</span>
<span class="p_del">-		set_ti_thread_flag(task_thread_info(prev), TIF_LAZY_MMU_UPDATES);</span>
<span class="p_del">-	}</span>
<span class="p_del">-	enter_lazy(PARAVIRT_LAZY_CPU);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-void paravirt_end_context_switch(struct task_struct *next)</span>
<span class="p_del">-{</span>
<span class="p_del">-	BUG_ON(preemptible());</span>
<span class="p_del">-</span>
<span class="p_del">-	leave_lazy(PARAVIRT_LAZY_CPU);</span>
<span class="p_del">-</span>
<span class="p_del">-	if (test_and_clear_ti_thread_flag(task_thread_info(next), TIF_LAZY_MMU_UPDATES))</span>
<span class="p_del">-		arch_enter_lazy_mmu_mode();</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-enum paravirt_lazy_mode paravirt_get_lazy_mode(void)</span>
<span class="p_del">-{</span>
<span class="p_del">-	if (in_interrupt())</span>
<span class="p_del">-		return PARAVIRT_LAZY_NONE;</span>
<span class="p_del">-</span>
<span class="p_del">-	return this_cpu_read(paravirt_lazy_mode);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
 struct pv_info pv_info = {
 	.name = &quot;bare hardware&quot;,
 	.kernel_rpl = 0,
<span class="p_chunk">@@ -303,91 +214,9 @@</span> <span class="p_context"> __visible struct pv_cpu_ops pv_cpu_ops = {</span>
 	.io_delay = native_io_delay,
 };
 
<span class="p_del">-#if defined(CONFIG_X86_32) &amp;&amp; !defined(CONFIG_X86_PAE)</span>
<span class="p_del">-/* 32-bit pagetable entries */</span>
<span class="p_del">-#define PTE_IDENT	__PV_IS_CALLEE_SAVE(_paravirt_ident_32)</span>
<span class="p_del">-#else</span>
<span class="p_del">-/* 64-bit pagetable entries */</span>
<span class="p_del">-#define PTE_IDENT	__PV_IS_CALLEE_SAVE(_paravirt_ident_64)</span>
<span class="p_del">-#endif</span>
<span class="p_del">-</span>
 struct pv_mmu_ops pv_mmu_ops __ro_after_init = {
<span class="p_del">-</span>
<span class="p_del">-	.read_cr2 = native_read_cr2,</span>
<span class="p_del">-	.write_cr2 = native_write_cr2,</span>
<span class="p_del">-	.read_cr3 = native_read_cr3,</span>
<span class="p_del">-	.write_cr3 = native_write_cr3,</span>
<span class="p_del">-</span>
<span class="p_del">-	.flush_tlb_user = native_flush_tlb,</span>
<span class="p_del">-	.flush_tlb_kernel = native_flush_tlb_global,</span>
<span class="p_del">-	.flush_tlb_single = native_flush_tlb_single,</span>
 	.flush_tlb_others = native_flush_tlb_others,
<span class="p_del">-</span>
<span class="p_del">-	.pgd_alloc = __paravirt_pgd_alloc,</span>
<span class="p_del">-	.pgd_free = paravirt_nop,</span>
<span class="p_del">-</span>
<span class="p_del">-	.alloc_pte = paravirt_nop,</span>
<span class="p_del">-	.alloc_pmd = paravirt_nop,</span>
<span class="p_del">-	.alloc_pud = paravirt_nop,</span>
<span class="p_del">-	.alloc_p4d = paravirt_nop,</span>
<span class="p_del">-	.release_pte = paravirt_nop,</span>
<span class="p_del">-	.release_pmd = paravirt_nop,</span>
<span class="p_del">-	.release_pud = paravirt_nop,</span>
<span class="p_del">-	.release_p4d = paravirt_nop,</span>
<span class="p_del">-</span>
<span class="p_del">-	.set_pte = native_set_pte,</span>
<span class="p_del">-	.set_pte_at = native_set_pte_at,</span>
<span class="p_del">-	.set_pmd = native_set_pmd,</span>
<span class="p_del">-	.set_pmd_at = native_set_pmd_at,</span>
<span class="p_del">-	.pte_update = paravirt_nop,</span>
<span class="p_del">-</span>
<span class="p_del">-	.ptep_modify_prot_start = __ptep_modify_prot_start,</span>
<span class="p_del">-	.ptep_modify_prot_commit = __ptep_modify_prot_commit,</span>
<span class="p_del">-</span>
<span class="p_del">-#if CONFIG_PGTABLE_LEVELS &gt;= 3</span>
<span class="p_del">-#ifdef CONFIG_X86_PAE</span>
<span class="p_del">-	.set_pte_atomic = native_set_pte_atomic,</span>
<span class="p_del">-	.pte_clear = native_pte_clear,</span>
<span class="p_del">-	.pmd_clear = native_pmd_clear,</span>
<span class="p_del">-#endif</span>
<span class="p_del">-	.set_pud = native_set_pud,</span>
<span class="p_del">-	.set_pud_at = native_set_pud_at,</span>
<span class="p_del">-</span>
<span class="p_del">-	.pmd_val = PTE_IDENT,</span>
<span class="p_del">-	.make_pmd = PTE_IDENT,</span>
<span class="p_del">-</span>
<span class="p_del">-#if CONFIG_PGTABLE_LEVELS &gt;= 4</span>
<span class="p_del">-	.pud_val = PTE_IDENT,</span>
<span class="p_del">-	.make_pud = PTE_IDENT,</span>
<span class="p_del">-</span>
<span class="p_del">-	.set_p4d = native_set_p4d,</span>
<span class="p_del">-</span>
<span class="p_del">-#if CONFIG_PGTABLE_LEVELS &gt;= 5</span>
<span class="p_del">-	.p4d_val = PTE_IDENT,</span>
<span class="p_del">-	.make_p4d = PTE_IDENT,</span>
<span class="p_del">-</span>
<span class="p_del">-	.set_pgd = native_set_pgd,</span>
<span class="p_del">-#endif /* CONFIG_PGTABLE_LEVELS &gt;= 5 */</span>
<span class="p_del">-#endif /* CONFIG_PGTABLE_LEVELS &gt;= 4 */</span>
<span class="p_del">-#endif /* CONFIG_PGTABLE_LEVELS &gt;= 3 */</span>
<span class="p_del">-</span>
<span class="p_del">-	.pte_val = PTE_IDENT,</span>
<span class="p_del">-	.pgd_val = PTE_IDENT,</span>
<span class="p_del">-</span>
<span class="p_del">-	.make_pte = PTE_IDENT,</span>
<span class="p_del">-	.make_pgd = PTE_IDENT,</span>
<span class="p_del">-</span>
<span class="p_del">-	.dup_mmap = paravirt_nop,</span>
 	.exit_mmap = paravirt_nop,
<span class="p_del">-	.activate_mm = paravirt_nop,</span>
<span class="p_del">-</span>
<span class="p_del">-	.lazy_mode = {</span>
<span class="p_del">-		.enter = paravirt_nop,</span>
<span class="p_del">-		.leave = paravirt_nop,</span>
<span class="p_del">-		.flush = paravirt_nop,</span>
<span class="p_del">-	},</span>
<span class="p_del">-</span>
<span class="p_del">-	.set_fixmap = native_set_fixmap,</span>
 };
 
 EXPORT_SYMBOL_GPL(pv_time_ops);
<span class="p_header">diff --git a/arch/x86/kernel/paravirt_full.c b/arch/x86/kernel/paravirt_full.c</span>
<span class="p_header">index 353968da3ddc..b90dfa7428bd 100644</span>
<span class="p_header">--- a/arch/x86/kernel/paravirt_full.c</span>
<span class="p_header">+++ b/arch/x86/kernel/paravirt_full.c</span>
<span class="p_chunk">@@ -19,12 +19,103 @@</span> <span class="p_context"></span>
 #include &lt;asm/paravirt.h&gt;
 #include &lt;asm/debugreg.h&gt;
 #include &lt;asm/desc.h&gt;
<span class="p_add">+#include &lt;asm/pgalloc.h&gt;</span>
 #include &lt;asm/processor.h&gt;
<span class="p_add">+#include &lt;asm/tlbflush.h&gt;</span>
 
 /* These are in entry.S */
 extern void native_iret(void);
 extern void native_usergs_sysret64(void);
 
<span class="p_add">+static DEFINE_PER_CPU(enum paravirt_lazy_mode, paravirt_lazy_mode) =</span>
<span class="p_add">+	PARAVIRT_LAZY_NONE;</span>
<span class="p_add">+</span>
<span class="p_add">+static inline void enter_lazy(enum paravirt_lazy_mode mode)</span>
<span class="p_add">+{</span>
<span class="p_add">+	BUG_ON(this_cpu_read(paravirt_lazy_mode) != PARAVIRT_LAZY_NONE);</span>
<span class="p_add">+</span>
<span class="p_add">+	this_cpu_write(paravirt_lazy_mode, mode);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static void leave_lazy(enum paravirt_lazy_mode mode)</span>
<span class="p_add">+{</span>
<span class="p_add">+	BUG_ON(this_cpu_read(paravirt_lazy_mode) != mode);</span>
<span class="p_add">+</span>
<span class="p_add">+	this_cpu_write(paravirt_lazy_mode, PARAVIRT_LAZY_NONE);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void paravirt_enter_lazy_mmu(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	enter_lazy(PARAVIRT_LAZY_MMU);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void paravirt_leave_lazy_mmu(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	leave_lazy(PARAVIRT_LAZY_MMU);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void paravirt_flush_lazy_mmu(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	preempt_disable();</span>
<span class="p_add">+</span>
<span class="p_add">+	if (paravirt_get_lazy_mode() == PARAVIRT_LAZY_MMU) {</span>
<span class="p_add">+		arch_leave_lazy_mmu_mode();</span>
<span class="p_add">+		arch_enter_lazy_mmu_mode();</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	preempt_enable();</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void paravirt_start_context_switch(struct task_struct *prev)</span>
<span class="p_add">+{</span>
<span class="p_add">+	BUG_ON(preemptible());</span>
<span class="p_add">+</span>
<span class="p_add">+	if (this_cpu_read(paravirt_lazy_mode) == PARAVIRT_LAZY_MMU) {</span>
<span class="p_add">+		arch_leave_lazy_mmu_mode();</span>
<span class="p_add">+		set_ti_thread_flag(task_thread_info(prev),</span>
<span class="p_add">+				   TIF_LAZY_MMU_UPDATES);</span>
<span class="p_add">+	}</span>
<span class="p_add">+	enter_lazy(PARAVIRT_LAZY_CPU);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void paravirt_end_context_switch(struct task_struct *next)</span>
<span class="p_add">+{</span>
<span class="p_add">+	BUG_ON(preemptible());</span>
<span class="p_add">+</span>
<span class="p_add">+	leave_lazy(PARAVIRT_LAZY_CPU);</span>
<span class="p_add">+</span>
<span class="p_add">+	if (test_and_clear_ti_thread_flag(task_thread_info(next),</span>
<span class="p_add">+					  TIF_LAZY_MMU_UPDATES))</span>
<span class="p_add">+		arch_enter_lazy_mmu_mode();</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+enum paravirt_lazy_mode paravirt_get_lazy_mode(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	if (in_interrupt())</span>
<span class="p_add">+		return PARAVIRT_LAZY_NONE;</span>
<span class="p_add">+</span>
<span class="p_add">+	return this_cpu_read(paravirt_lazy_mode);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static void native_flush_tlb(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	__native_flush_tlb();</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+/*</span>
<span class="p_add">+ * Global pages have to be flushed a bit differently. Not a real</span>
<span class="p_add">+ * performance problem because this does not happen often.</span>
<span class="p_add">+ */</span>
<span class="p_add">+static void native_flush_tlb_global(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	__native_flush_tlb_global();</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static void native_flush_tlb_single(unsigned long addr)</span>
<span class="p_add">+{</span>
<span class="p_add">+	__native_flush_tlb_single(addr);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 __visible struct pvfull_cpu_ops pvfull_cpu_ops = {
 	.cpuid = native_cpuid,
 	.get_debugreg = native_get_debugreg,
<span class="p_chunk">@@ -82,6 +173,90 @@</span> <span class="p_context"> __visible struct pvfull_irq_ops pvfull_irq_ops = {</span>
 #endif
 };
 
<span class="p_add">+#if defined(CONFIG_X86_32) &amp;&amp; !defined(CONFIG_X86_PAE)</span>
<span class="p_add">+/* 32-bit pagetable entries */</span>
<span class="p_add">+#define PTE_IDENT       __PV_IS_CALLEE_SAVE(_paravirt_ident_32)</span>
<span class="p_add">+#else</span>
<span class="p_add">+/* 64-bit pagetable entries */</span>
<span class="p_add">+#define PTE_IDENT       __PV_IS_CALLEE_SAVE(_paravirt_ident_64)</span>
<span class="p_add">+#endif</span>
<span class="p_add">+</span>
<span class="p_add">+struct pvfull_mmu_ops pvfull_mmu_ops = {</span>
<span class="p_add">+	.read_cr2 = native_read_cr2,</span>
<span class="p_add">+	.write_cr2 = native_write_cr2,</span>
<span class="p_add">+	.read_cr3 = native_read_cr3,</span>
<span class="p_add">+	.write_cr3 = native_write_cr3,</span>
<span class="p_add">+</span>
<span class="p_add">+	.flush_tlb_user = native_flush_tlb,</span>
<span class="p_add">+	.flush_tlb_kernel = native_flush_tlb_global,</span>
<span class="p_add">+	.flush_tlb_single = native_flush_tlb_single,</span>
<span class="p_add">+</span>
<span class="p_add">+	.pgd_alloc = __paravirt_pgd_alloc,</span>
<span class="p_add">+	.pgd_free = paravirt_nop,</span>
<span class="p_add">+</span>
<span class="p_add">+	.alloc_pte = paravirt_nop,</span>
<span class="p_add">+	.alloc_pmd = paravirt_nop,</span>
<span class="p_add">+	.alloc_pud = paravirt_nop,</span>
<span class="p_add">+	.alloc_p4d = paravirt_nop,</span>
<span class="p_add">+	.release_pte = paravirt_nop,</span>
<span class="p_add">+	.release_pmd = paravirt_nop,</span>
<span class="p_add">+	.release_pud = paravirt_nop,</span>
<span class="p_add">+	.release_p4d = paravirt_nop,</span>
<span class="p_add">+</span>
<span class="p_add">+	.set_pte = native_set_pte,</span>
<span class="p_add">+	.set_pte_at = native_set_pte_at,</span>
<span class="p_add">+	.set_pmd = native_set_pmd,</span>
<span class="p_add">+	.set_pmd_at = native_set_pmd_at,</span>
<span class="p_add">+	.pte_update = paravirt_nop,</span>
<span class="p_add">+</span>
<span class="p_add">+	.ptep_modify_prot_start = __ptep_modify_prot_start,</span>
<span class="p_add">+	.ptep_modify_prot_commit = __ptep_modify_prot_commit,</span>
<span class="p_add">+</span>
<span class="p_add">+#if CONFIG_PGTABLE_LEVELS &gt;= 3</span>
<span class="p_add">+#ifdef CONFIG_X86_PAE</span>
<span class="p_add">+	.set_pte_atomic = native_set_pte_atomic,</span>
<span class="p_add">+	.pte_clear = native_pte_clear,</span>
<span class="p_add">+	.pmd_clear = native_pmd_clear,</span>
<span class="p_add">+#endif</span>
<span class="p_add">+	.set_pud = native_set_pud,</span>
<span class="p_add">+	.set_pud_at = native_set_pud_at,</span>
<span class="p_add">+</span>
<span class="p_add">+	.pmd_val = PTE_IDENT,</span>
<span class="p_add">+	.make_pmd = PTE_IDENT,</span>
<span class="p_add">+</span>
<span class="p_add">+#if CONFIG_PGTABLE_LEVELS &gt;= 4</span>
<span class="p_add">+	.pud_val = PTE_IDENT,</span>
<span class="p_add">+	.make_pud = PTE_IDENT,</span>
<span class="p_add">+</span>
<span class="p_add">+	.set_p4d = native_set_p4d,</span>
<span class="p_add">+</span>
<span class="p_add">+#if CONFIG_PGTABLE_LEVELS &gt;= 5</span>
<span class="p_add">+	.p4d_val = PTE_IDENT,</span>
<span class="p_add">+	.make_p4d = PTE_IDENT,</span>
<span class="p_add">+</span>
<span class="p_add">+	.set_pgd = native_set_pgd,</span>
<span class="p_add">+#endif /* CONFIG_PGTABLE_LEVELS &gt;= 5 */</span>
<span class="p_add">+#endif /* CONFIG_PGTABLE_LEVELS &gt;= 4 */</span>
<span class="p_add">+#endif /* CONFIG_PGTABLE_LEVELS &gt;= 3 */</span>
<span class="p_add">+</span>
<span class="p_add">+	.pte_val = PTE_IDENT,</span>
<span class="p_add">+	.pgd_val = PTE_IDENT,</span>
<span class="p_add">+</span>
<span class="p_add">+	.make_pte = PTE_IDENT,</span>
<span class="p_add">+	.make_pgd = PTE_IDENT,</span>
<span class="p_add">+</span>
<span class="p_add">+	.dup_mmap = paravirt_nop,</span>
<span class="p_add">+	.activate_mm = paravirt_nop,</span>
<span class="p_add">+</span>
<span class="p_add">+	.lazy_mode = {</span>
<span class="p_add">+		.enter = paravirt_nop,</span>
<span class="p_add">+		.leave = paravirt_nop,</span>
<span class="p_add">+		.flush = paravirt_nop,</span>
<span class="p_add">+	},</span>
<span class="p_add">+</span>
<span class="p_add">+	.set_fixmap = native_set_fixmap,</span>
<span class="p_add">+};</span>
<span class="p_add">+</span>
 /* At this point, native_get/set_debugreg has real function entries */
 NOKPROBE_SYMBOL(native_get_debugreg);
 NOKPROBE_SYMBOL(native_set_debugreg);
<span class="p_chunk">@@ -89,3 +264,4 @@</span> <span class="p_context"> NOKPROBE_SYMBOL(native_load_idt);</span>
 
 EXPORT_SYMBOL(pvfull_cpu_ops);
 EXPORT_SYMBOL_GPL(pvfull_irq_ops);
<span class="p_add">+EXPORT_SYMBOL(pvfull_mmu_ops);</span>
<span class="p_header">diff --git a/arch/x86/kernel/paravirt_patch_32.c b/arch/x86/kernel/paravirt_patch_32.c</span>
<span class="p_header">index ccb75951aed5..b5f93cb0d05f 100644</span>
<span class="p_header">--- a/arch/x86/kernel/paravirt_patch_32.c</span>
<span class="p_header">+++ b/arch/x86/kernel/paravirt_patch_32.c</span>
<span class="p_chunk">@@ -4,10 +4,10 @@</span> <span class="p_context"> DEF_NATIVE(pv_irq_ops, irq_disable, &quot;cli&quot;);</span>
 DEF_NATIVE(pv_irq_ops, irq_enable, &quot;sti&quot;);
 DEF_NATIVE(pv_irq_ops, restore_fl, &quot;push %eax; popf&quot;);
 DEF_NATIVE(pv_irq_ops, save_fl, &quot;pushf; pop %eax&quot;);
<span class="p_del">-DEF_NATIVE(pv_mmu_ops, read_cr2, &quot;mov %cr2, %eax&quot;);</span>
<span class="p_del">-DEF_NATIVE(pv_mmu_ops, write_cr3, &quot;mov %eax, %cr3&quot;);</span>
<span class="p_del">-DEF_NATIVE(pv_mmu_ops, read_cr3, &quot;mov %cr3, %eax&quot;);</span>
 #ifdef CONFIG_PARAVIRT_FULL
<span class="p_add">+DEF_NATIVE(pvfull_mmu_ops, read_cr2, &quot;mov %cr2, %eax&quot;);</span>
<span class="p_add">+DEF_NATIVE(pvfull_mmu_ops, write_cr3, &quot;mov %eax, %cr3&quot;);</span>
<span class="p_add">+DEF_NATIVE(pvfull_mmu_ops, read_cr3, &quot;mov %cr3, %eax&quot;);</span>
 DEF_NATIVE(pvfull_cpu_ops, iret, &quot;iret&quot;);
 #endif
 
<span class="p_chunk">@@ -47,10 +47,10 @@</span> <span class="p_context"> unsigned native_patch(u8 type, u16 clobbers, void *ibuf,</span>
 		PATCH_SITE(pv_irq_ops, irq_enable);
 		PATCH_SITE(pv_irq_ops, restore_fl);
 		PATCH_SITE(pv_irq_ops, save_fl);
<span class="p_del">-		PATCH_SITE(pv_mmu_ops, read_cr2);</span>
<span class="p_del">-		PATCH_SITE(pv_mmu_ops, read_cr3);</span>
<span class="p_del">-		PATCH_SITE(pv_mmu_ops, write_cr3);</span>
 #ifdef CONFIG_PARAVIRT_FULL
<span class="p_add">+		PATCH_SITE(pvfull_mmu_ops, read_cr2);</span>
<span class="p_add">+		PATCH_SITE(pvfull_mmu_ops, read_cr3);</span>
<span class="p_add">+		PATCH_SITE(pvfull_mmu_ops, write_cr3);</span>
 		PATCH_SITE(pvfull_cpu_ops, iret);
 #endif
 #if defined(CONFIG_PARAVIRT_SPINLOCKS)
<span class="p_header">diff --git a/arch/x86/kernel/paravirt_patch_64.c b/arch/x86/kernel/paravirt_patch_64.c</span>
<span class="p_header">index 00d5c77d23a7..473688054f0b 100644</span>
<span class="p_header">--- a/arch/x86/kernel/paravirt_patch_64.c</span>
<span class="p_header">+++ b/arch/x86/kernel/paravirt_patch_64.c</span>
<span class="p_chunk">@@ -6,15 +6,15 @@</span> <span class="p_context"> DEF_NATIVE(pv_irq_ops, irq_disable, &quot;cli&quot;);</span>
 DEF_NATIVE(pv_irq_ops, irq_enable, &quot;sti&quot;);
 DEF_NATIVE(pv_irq_ops, restore_fl, &quot;pushq %rdi; popfq&quot;);
 DEF_NATIVE(pv_irq_ops, save_fl, &quot;pushfq; popq %rax&quot;);
<span class="p_del">-DEF_NATIVE(pv_mmu_ops, read_cr2, &quot;movq %cr2, %rax&quot;);</span>
<span class="p_del">-DEF_NATIVE(pv_mmu_ops, read_cr3, &quot;movq %cr3, %rax&quot;);</span>
<span class="p_del">-DEF_NATIVE(pv_mmu_ops, write_cr3, &quot;movq %rdi, %cr3&quot;);</span>
<span class="p_del">-DEF_NATIVE(pv_mmu_ops, flush_tlb_single, &quot;invlpg (%rdi)&quot;);</span>
 
 DEF_NATIVE(, mov32, &quot;mov %edi, %eax&quot;);
 DEF_NATIVE(, mov64, &quot;mov %rdi, %rax&quot;);
 
 #ifdef CONFIG_PARAVIRT_FULL
<span class="p_add">+DEF_NATIVE(pvfull_mmu_ops, read_cr2, &quot;movq %cr2, %rax&quot;);</span>
<span class="p_add">+DEF_NATIVE(pvfull_mmu_ops, read_cr3, &quot;movq %cr3, %rax&quot;);</span>
<span class="p_add">+DEF_NATIVE(pvfull_mmu_ops, write_cr3, &quot;movq %rdi, %cr3&quot;);</span>
<span class="p_add">+DEF_NATIVE(pvfull_mmu_ops, flush_tlb_single, &quot;invlpg (%rdi)&quot;);</span>
 DEF_NATIVE(pvfull_cpu_ops, wbinvd, &quot;wbinvd&quot;);
 DEF_NATIVE(pvfull_cpu_ops, usergs_sysret64, &quot;swapgs; sysretq&quot;);
 DEF_NATIVE(pvfull_cpu_ops, swapgs, &quot;swapgs&quot;);
<span class="p_chunk">@@ -56,11 +56,11 @@</span> <span class="p_context"> unsigned native_patch(u8 type, u16 clobbers, void *ibuf,</span>
 		PATCH_SITE(pv_irq_ops, save_fl);
 		PATCH_SITE(pv_irq_ops, irq_enable);
 		PATCH_SITE(pv_irq_ops, irq_disable);
<span class="p_del">-		PATCH_SITE(pv_mmu_ops, read_cr2);</span>
<span class="p_del">-		PATCH_SITE(pv_mmu_ops, read_cr3);</span>
<span class="p_del">-		PATCH_SITE(pv_mmu_ops, write_cr3);</span>
<span class="p_del">-		PATCH_SITE(pv_mmu_ops, flush_tlb_single);</span>
 #ifdef CONFIG_PARAVIRT_FULL
<span class="p_add">+		PATCH_SITE(pvfull_mmu_ops, read_cr2);</span>
<span class="p_add">+		PATCH_SITE(pvfull_mmu_ops, read_cr3);</span>
<span class="p_add">+		PATCH_SITE(pvfull_mmu_ops, write_cr3);</span>
<span class="p_add">+		PATCH_SITE(pvfull_mmu_ops, flush_tlb_single);</span>
 		PATCH_SITE(pvfull_cpu_ops, usergs_sysret64);
 		PATCH_SITE(pvfull_cpu_ops, swapgs);
 		PATCH_SITE(pvfull_cpu_ops, wbinvd);
<span class="p_header">diff --git a/arch/x86/lguest/boot.c b/arch/x86/lguest/boot.c</span>
<span class="p_header">index bf8773854ab0..b9757853cf79 100644</span>
<span class="p_header">--- a/arch/x86/lguest/boot.c</span>
<span class="p_header">+++ b/arch/x86/lguest/boot.c</span>
<span class="p_chunk">@@ -753,7 +753,7 @@</span> <span class="p_context"> static void lguest_pmd_clear(pmd_t *pmdp)</span>
 #endif
 
 /*
<span class="p_del">- * Unfortunately for Lguest, the pv_mmu_ops for page tables were based on</span>
<span class="p_add">+ * Unfortunately for Lguest, the pvfull_mmu_ops for page tables were based on</span>
  * native page table operations.  On native hardware you can set a new page
  * table entry whenever you want, but if you want to remove one you have to do
  * a TLB flush (a TLB is a little cache of page table entries kept by the CPU).
<span class="p_chunk">@@ -1431,25 +1431,25 @@</span> <span class="p_context"> __init void lguest_init(void)</span>
 	pvfull_cpu_ops.end_context_switch = lguest_end_context_switch;
 
 	/* Pagetable management */
<span class="p_del">-	pv_mmu_ops.write_cr3 = lguest_write_cr3;</span>
<span class="p_del">-	pv_mmu_ops.flush_tlb_user = lguest_flush_tlb_user;</span>
<span class="p_del">-	pv_mmu_ops.flush_tlb_single = lguest_flush_tlb_single;</span>
<span class="p_del">-	pv_mmu_ops.flush_tlb_kernel = lguest_flush_tlb_kernel;</span>
<span class="p_del">-	pv_mmu_ops.set_pte = lguest_set_pte;</span>
<span class="p_del">-	pv_mmu_ops.set_pte_at = lguest_set_pte_at;</span>
<span class="p_del">-	pv_mmu_ops.set_pmd = lguest_set_pmd;</span>
<span class="p_add">+	pvfull_mmu_ops.write_cr3 = lguest_write_cr3;</span>
<span class="p_add">+	pvfull_mmu_ops.flush_tlb_user = lguest_flush_tlb_user;</span>
<span class="p_add">+	pvfull_mmu_ops.flush_tlb_single = lguest_flush_tlb_single;</span>
<span class="p_add">+	pvfull_mmu_ops.flush_tlb_kernel = lguest_flush_tlb_kernel;</span>
<span class="p_add">+	pvfull_mmu_ops.set_pte = lguest_set_pte;</span>
<span class="p_add">+	pvfull_mmu_ops.set_pte_at = lguest_set_pte_at;</span>
<span class="p_add">+	pvfull_mmu_ops.set_pmd = lguest_set_pmd;</span>
 #ifdef CONFIG_X86_PAE
<span class="p_del">-	pv_mmu_ops.set_pte_atomic = lguest_set_pte_atomic;</span>
<span class="p_del">-	pv_mmu_ops.pte_clear = lguest_pte_clear;</span>
<span class="p_del">-	pv_mmu_ops.pmd_clear = lguest_pmd_clear;</span>
<span class="p_del">-	pv_mmu_ops.set_pud = lguest_set_pud;</span>
<span class="p_add">+	pvfull_mmu_ops.set_pte_atomic = lguest_set_pte_atomic;</span>
<span class="p_add">+	pvfull_mmu_ops.pte_clear = lguest_pte_clear;</span>
<span class="p_add">+	pvfull_mmu_ops.pmd_clear = lguest_pmd_clear;</span>
<span class="p_add">+	pvfull_mmu_ops.set_pud = lguest_set_pud;</span>
 #endif
<span class="p_del">-	pv_mmu_ops.read_cr2 = lguest_read_cr2;</span>
<span class="p_del">-	pv_mmu_ops.read_cr3 = lguest_read_cr3;</span>
<span class="p_del">-	pv_mmu_ops.lazy_mode.enter = paravirt_enter_lazy_mmu;</span>
<span class="p_del">-	pv_mmu_ops.lazy_mode.leave = lguest_leave_lazy_mmu_mode;</span>
<span class="p_del">-	pv_mmu_ops.lazy_mode.flush = paravirt_flush_lazy_mmu;</span>
<span class="p_del">-	pv_mmu_ops.pte_update = lguest_pte_update;</span>
<span class="p_add">+	pvfull_mmu_ops.read_cr2 = lguest_read_cr2;</span>
<span class="p_add">+	pvfull_mmu_ops.read_cr3 = lguest_read_cr3;</span>
<span class="p_add">+	pvfull_mmu_ops.lazy_mode.enter = paravirt_enter_lazy_mmu;</span>
<span class="p_add">+	pvfull_mmu_ops.lazy_mode.leave = lguest_leave_lazy_mmu_mode;</span>
<span class="p_add">+	pvfull_mmu_ops.lazy_mode.flush = paravirt_flush_lazy_mmu;</span>
<span class="p_add">+	pvfull_mmu_ops.pte_update = lguest_pte_update;</span>
 
 #ifdef CONFIG_X86_LOCAL_APIC
 	/* APIC read/write intercepts */
<span class="p_header">diff --git a/arch/x86/xen/enlighten_pv.c b/arch/x86/xen/enlighten_pv.c</span>
<span class="p_header">index 89cd5cc5f1a2..9badad9f82e0 100644</span>
<span class="p_header">--- a/arch/x86/xen/enlighten_pv.c</span>
<span class="p_header">+++ b/arch/x86/xen/enlighten_pv.c</span>
<span class="p_chunk">@@ -1002,7 +1002,7 @@</span> <span class="p_context"> void xen_setup_vcpu_info_placement(void)</span>
 		pv_irq_ops.restore_fl = __PV_IS_CALLEE_SAVE(xen_restore_fl_direct);
 		pv_irq_ops.irq_disable = __PV_IS_CALLEE_SAVE(xen_irq_disable_direct);
 		pv_irq_ops.irq_enable = __PV_IS_CALLEE_SAVE(xen_irq_enable_direct);
<span class="p_del">-		pv_mmu_ops.read_cr2 = xen_read_cr2_direct;</span>
<span class="p_add">+		pvfull_mmu_ops.read_cr2 = xen_read_cr2_direct;</span>
 	}
 }
 
<span class="p_chunk">@@ -1316,8 +1316,10 @@</span> <span class="p_context"> asmlinkage __visible void __init xen_start_kernel(void)</span>
 #endif
 
 	if (xen_feature(XENFEAT_mmu_pt_update_preserve_ad)) {
<span class="p_del">-		pv_mmu_ops.ptep_modify_prot_start = xen_ptep_modify_prot_start;</span>
<span class="p_del">-		pv_mmu_ops.ptep_modify_prot_commit = xen_ptep_modify_prot_commit;</span>
<span class="p_add">+		pvfull_mmu_ops.ptep_modify_prot_start =</span>
<span class="p_add">+			xen_ptep_modify_prot_start;</span>
<span class="p_add">+		pvfull_mmu_ops.ptep_modify_prot_commit =</span>
<span class="p_add">+			xen_ptep_modify_prot_commit;</span>
 	}
 
 	machine_ops = xen_machine_ops;
<span class="p_header">diff --git a/arch/x86/xen/mmu_pv.c b/arch/x86/xen/mmu_pv.c</span>
<span class="p_header">index 7397d8b8459d..7be3e21a4dac 100644</span>
<span class="p_header">--- a/arch/x86/xen/mmu_pv.c</span>
<span class="p_header">+++ b/arch/x86/xen/mmu_pv.c</span>
<span class="p_chunk">@@ -2252,7 +2252,7 @@</span> <span class="p_context"> static void __init xen_write_cr3_init(unsigned long cr3)</span>
 	set_page_prot(initial_page_table, PAGE_KERNEL);
 	set_page_prot(initial_kernel_pmd, PAGE_KERNEL);
 
<span class="p_del">-	pv_mmu_ops.write_cr3 = &amp;xen_write_cr3;</span>
<span class="p_add">+	pvfull_mmu_ops.write_cr3 = &amp;xen_write_cr3;</span>
 }
 
 /*
<span class="p_chunk">@@ -2406,27 +2406,27 @@</span> <span class="p_context"> static void __init xen_post_allocator_init(void)</span>
 	if (xen_feature(XENFEAT_auto_translated_physmap))
 		return;
 
<span class="p_del">-	pv_mmu_ops.set_pte = xen_set_pte;</span>
<span class="p_del">-	pv_mmu_ops.set_pmd = xen_set_pmd;</span>
<span class="p_del">-	pv_mmu_ops.set_pud = xen_set_pud;</span>
<span class="p_add">+	pvfull_mmu_ops.set_pte = xen_set_pte;</span>
<span class="p_add">+	pvfull_mmu_ops.set_pmd = xen_set_pmd;</span>
<span class="p_add">+	pvfull_mmu_ops.set_pud = xen_set_pud;</span>
 #if CONFIG_PGTABLE_LEVELS &gt;= 4
<span class="p_del">-	pv_mmu_ops.set_p4d = xen_set_p4d;</span>
<span class="p_add">+	pvfull_mmu_ops.set_p4d = xen_set_p4d;</span>
 #endif
 
 	/* This will work as long as patching hasn&#39;t happened yet
 	   (which it hasn&#39;t) */
<span class="p_del">-	pv_mmu_ops.alloc_pte = xen_alloc_pte;</span>
<span class="p_del">-	pv_mmu_ops.alloc_pmd = xen_alloc_pmd;</span>
<span class="p_del">-	pv_mmu_ops.release_pte = xen_release_pte;</span>
<span class="p_del">-	pv_mmu_ops.release_pmd = xen_release_pmd;</span>
<span class="p_add">+	pvfull_mmu_ops.alloc_pte = xen_alloc_pte;</span>
<span class="p_add">+	pvfull_mmu_ops.alloc_pmd = xen_alloc_pmd;</span>
<span class="p_add">+	pvfull_mmu_ops.release_pte = xen_release_pte;</span>
<span class="p_add">+	pvfull_mmu_ops.release_pmd = xen_release_pmd;</span>
 #if CONFIG_PGTABLE_LEVELS &gt;= 4
<span class="p_del">-	pv_mmu_ops.alloc_pud = xen_alloc_pud;</span>
<span class="p_del">-	pv_mmu_ops.release_pud = xen_release_pud;</span>
<span class="p_add">+	pvfull_mmu_ops.alloc_pud = xen_alloc_pud;</span>
<span class="p_add">+	pvfull_mmu_ops.release_pud = xen_release_pud;</span>
 #endif
<span class="p_del">-	pv_mmu_ops.make_pte = PV_CALLEE_SAVE(xen_make_pte);</span>
<span class="p_add">+	pvfull_mmu_ops.make_pte = PV_CALLEE_SAVE(xen_make_pte);</span>
 
 #ifdef CONFIG_X86_64
<span class="p_del">-	pv_mmu_ops.write_cr3 = &amp;xen_write_cr3;</span>
<span class="p_add">+	pvfull_mmu_ops.write_cr3 = &amp;xen_write_cr3;</span>
 	SetPagePinned(virt_to_page(level3_user_vsyscall));
 #endif
 	xen_mark_init_mm_pinned();
<span class="p_chunk">@@ -2440,7 +2440,7 @@</span> <span class="p_context"> static void xen_leave_lazy_mmu(void)</span>
 	preempt_enable();
 }
 
<span class="p_del">-static const struct pv_mmu_ops xen_mmu_ops __initconst = {</span>
<span class="p_add">+static const struct pvfull_mmu_ops xen_mmu_ops __initconst = {</span>
 	.read_cr2 = xen_read_cr2,
 	.write_cr2 = xen_write_cr2,
 
<span class="p_chunk">@@ -2450,7 +2450,6 @@</span> <span class="p_context"> static const struct pv_mmu_ops xen_mmu_ops __initconst = {</span>
 	.flush_tlb_user = xen_flush_tlb,
 	.flush_tlb_kernel = xen_flush_tlb,
 	.flush_tlb_single = xen_flush_tlb_single,
<span class="p_del">-	.flush_tlb_others = xen_flush_tlb_others,</span>
 
 	.pte_update = paravirt_nop,
 
<span class="p_chunk">@@ -2496,7 +2495,6 @@</span> <span class="p_context"> static const struct pv_mmu_ops xen_mmu_ops __initconst = {</span>
 
 	.activate_mm = xen_activate_mm,
 	.dup_mmap = xen_dup_mmap,
<span class="p_del">-	.exit_mmap = xen_exit_mmap,</span>
 
 	.lazy_mode = {
 		.enter = paravirt_enter_lazy_mmu,
<span class="p_chunk">@@ -2514,7 +2512,9 @@</span> <span class="p_context"> void __init xen_init_mmu_ops(void)</span>
 	if (xen_feature(XENFEAT_auto_translated_physmap))
 		return;
 
<span class="p_del">-	pv_mmu_ops = xen_mmu_ops;</span>
<span class="p_add">+	pvfull_mmu_ops = xen_mmu_ops;</span>
<span class="p_add">+	pv_mmu_ops.flush_tlb_others = xen_flush_tlb_others;</span>
<span class="p_add">+	pv_mmu_ops.exit_mmap = xen_exit_mmap;</span>
 
 	memset(dummy_mapping, 0xff, PAGE_SIZE);
 }

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



