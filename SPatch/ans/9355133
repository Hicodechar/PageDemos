
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>[v2,2/3] mm: add LSM hook for writes to readonly memory - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    [v2,2/3] mm: add LSM hook for writes to readonly memory</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=96711">Jann Horn</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>Sept. 28, 2016, 10:54 p.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;1475103281-7989-3-git-send-email-jann@thejh.net&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/9355133/mbox/"
   >mbox</a>
|
   <a href="/patch/9355133/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/9355133/">/patch/9355133/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
	[172.30.200.125])
	by pdx-korg-patchwork.web.codeaurora.org (Postfix) with ESMTP id
	133886086A for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Wed, 28 Sep 2016 22:55:50 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 021A42964E
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Wed, 28 Sep 2016 22:55:50 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id EA98C296A0; Wed, 28 Sep 2016 22:55:49 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-7.0 required=2.0 tests=BAYES_00,DKIM_SIGNED,
	DKIM_VALID, DKIM_VALID_AU,
	RCVD_IN_DNSWL_HI autolearn=unavailable version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 28BE9296A0
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Wed, 28 Sep 2016 22:55:48 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S933623AbcI1Wzi (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Wed, 28 Sep 2016 18:55:38 -0400
Received: from thejh.net ([37.221.195.125]:52533 &quot;EHLO thejh.net&quot;
	rhost-flags-OK-OK-OK-OK) by vger.kernel.org with ESMTP
	id S1753382AbcI1Wy5 (ORCPT &lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Wed, 28 Sep 2016 18:54:57 -0400
Received: from pc.thejh.net (pc.vpn [192.168.44.2])
	by thejh.net (Postfix) with ESMTPSA id D8CE1180162;
	Thu, 29 Sep 2016 00:54:54 +0200 (CEST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/simple; d=thejh.net; s=s2016;
	t=1475103295; bh=VIM2VIuwem7fdtFqJaaYBLTaU/egKLqNsB8VYttRtXk=;
	h=From:To:Cc:Subject:Date:In-Reply-To:References:From;
	b=F0k/JR4EEnhQxsUuN9WbvA7EegkVLFIbDNqD6FTICjls8W58tScaq77U27Zum8njs
	v1dmdc5liHjhEIn/6d7S+wwdZBMEFHg2RYbM5kZm8R3IuDhhcTGOpBUzwrqKu9enFn
	My5WyuHUSCCC8Fwo3LkVxLDmYCODuxNr5v291Tb8sUpHiE1bWcbNDKHzH8/HKT+JXj
	GPyuzo07USSGXEpJRhdOsAewigkvUVRSFNuCmgxVr2OT2gstFTf6bVmFn/1Tt9KGSU
	1+KtaDtKRPGPTOeis7t3+EkHcVTvahgaL0m7qhYe+Fqub+B/DqVUYuItfl6vNzsqI7
	5J2aMTy3UvFnA==
From: Jann Horn &lt;jann@thejh.net&gt;
To: security@kernel.org, Alexander Viro &lt;viro@zeniv.linux.org.uk&gt;,
	Paul Moore &lt;paul@paul-moore.com&gt;, Stephen Smalley &lt;sds@tycho.nsa.gov&gt;,
	Eric Paris &lt;eparis@parisplace.org&gt;,
	James Morris &lt;james.l.morris@oracle.com&gt;,
	&quot;Serge E. Hallyn&quot; &lt;serge@hallyn.com&gt;
Cc: Nick Kralevich &lt;nnk@google.com&gt;, Janis Danisevskis &lt;jdanis@google.com&gt;,
	linux-security-module@vger.kernel.org, linux-mm@kvack.org,
	linux-kernel@vger.kernel.org
Subject: [PATCH v2 2/3] mm: add LSM hook for writes to readonly memory
Date: Thu, 29 Sep 2016 00:54:40 +0200
Message-Id: &lt;1475103281-7989-3-git-send-email-jann@thejh.net&gt;
X-Mailer: git-send-email 2.1.4
In-Reply-To: &lt;1475103281-7989-1-git-send-email-jann@thejh.net&gt;
References: &lt;1475103281-7989-1-git-send-email-jann@thejh.net&gt;
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=96711">Jann Horn</a> - Sept. 28, 2016, 10:54 p.m.</div>
<pre class="content">
SELinux attempts to make it possible to whitelist trustworthy sources of
code that may be mapped into memory, and Android makes use of this feature.
To prevent an attacker from bypassing this by modifying R+X memory through
/proc/$pid/mem or PTRACE_POKETEXT, it is necessary to call a security hook
in check_vma_flags().

The new security hook security_forced_write() takes three arguments:

 - The modified VMA, so the security check can e.g. test for executability.
 - The subject performing the access. For remote accesses, this may be
   different from the target of the access. This can e.g. be used to create
   a security policy that permits a privileged debugger to set software
   breakpoints in the address space of a sandboxed process.
 - The target of the access. This is useful if only a subset of the
   processes on the system should be prevented from executing arbitrary
   code, as is the case on Android.

changed in v2:
 - fix comment (Janis Danisevsk)
 - simplify code a bit (Janis Danisevsk)
<span class="signed-off-by">
Signed-off-by: Jann Horn &lt;jann@thejh.net&gt;</span>
<span class="reviewed-by">Reviewed-by: Janis Danisevskis &lt;jdanis@android.com&gt;</span>
---
 drivers/gpu/drm/etnaviv/etnaviv_gem.c   |  3 +-
 drivers/gpu/drm/i915/i915_gem_userptr.c |  2 +-
 drivers/infiniband/core/umem_odp.c      |  4 +-
 fs/exec.c                               |  4 +-
 fs/proc/base.c                          | 68 +++++++++++++++++++++-------
 fs/proc/internal.h                      |  4 +-
 fs/proc/task_mmu.c                      |  4 +-
 fs/proc/task_nommu.c                    |  2 +-
 include/linux/lsm_hooks.h               |  9 ++++
 include/linux/mm.h                      | 12 ++++-
 include/linux/sched.h                   |  4 +-
 include/linux/security.h                | 10 +++++
 kernel/events/uprobes.c                 |  6 ++-
 kernel/fork.c                           |  6 ++-
 mm/gup.c                                | 80 +++++++++++++++++++++++++--------
 mm/memory.c                             | 22 ++++++---
 mm/nommu.c                              | 22 +++++----
 mm/process_vm_access.c                  |  8 ++--
 security/security.c                     |  8 ++++
 security/tomoyo/domain.c                |  2 +-
 virt/kvm/async_pf.c                     |  3 +-
 virt/kvm/kvm_main.c                     |  9 ++--
 22 files changed, 215 insertions(+), 77 deletions(-)
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=41531">Andy Lutomirski</a> - Sept. 28, 2016, 11:22 p.m.</div>
<pre class="content">
On Wed, Sep 28, 2016 at 3:54 PM, Jann Horn &lt;jann@thejh.net&gt; wrote:
<span class="quote">&gt; SELinux attempts to make it possible to whitelist trustworthy sources of</span>
<span class="quote">&gt; code that may be mapped into memory, and Android makes use of this feature.</span>
<span class="quote">&gt; To prevent an attacker from bypassing this by modifying R+X memory through</span>
<span class="quote">&gt; /proc/$pid/mem or PTRACE_POKETEXT, it is necessary to call a security hook</span>
<span class="quote">&gt; in check_vma_flags().</span>

If selinux policy allows PTRACE_POKETEXT, is it really so bad for that
to result in code execution?
<span class="quote">

&gt; -struct mm_struct *proc_mem_open(struct inode *inode, unsigned int mode)</span>
<span class="quote">&gt; +struct mm_struct *proc_mem_open(struct inode *inode,</span>
<span class="quote">&gt; +                               const struct cred **object_cred,</span>
<span class="quote">&gt; +                               unsigned int mode)</span>
<span class="quote">&gt;  {</span>

Why are you passing object_cred all over the place like this?  You
have an inode, and an inode implies a task.

For that matter, would it possibly make sense to use MEMCG&#39;s mm-&gt;owner
and get rid of object_cred entirely?  I can see this causing issues in
strange threading cases, e.g. accessing your own /proc/$$/mem vs
another thread in your process&#39;s.
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=96711">Jann Horn</a> - Sept. 28, 2016, 11:32 p.m.</div>
<pre class="content">
On Wed, Sep 28, 2016 at 04:22:53PM -0700, Andy Lutomirski wrote:
<span class="quote">&gt; On Wed, Sep 28, 2016 at 3:54 PM, Jann Horn &lt;jann@thejh.net&gt; wrote:</span>
<span class="quote">&gt; &gt; SELinux attempts to make it possible to whitelist trustworthy sources of</span>
<span class="quote">&gt; &gt; code that may be mapped into memory, and Android makes use of this feature.</span>
<span class="quote">&gt; &gt; To prevent an attacker from bypassing this by modifying R+X memory through</span>
<span class="quote">&gt; &gt; /proc/$pid/mem or PTRACE_POKETEXT, it is necessary to call a security hook</span>
<span class="quote">&gt; &gt; in check_vma_flags().</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; If selinux policy allows PTRACE_POKETEXT, is it really so bad for that</span>
<span class="quote">&gt; to result in code execution?</span>

Have a look at __ptrace_may_access():

	/* Don&#39;t let security modules deny introspection */
	if (same_thread_group(task, current))
		return 0;

This means thread A can attach to thread B and poke its memory, and SELinux
can&#39;t do anything about it.

I guess another perspective on this would be that it&#39;s a problem that
interfaces usable for poking user memory are subject to introspection rules
(as opposed to e.g. /proc/self/maps, where it is actually useful).
<span class="quote">
&gt; &gt; -struct mm_struct *proc_mem_open(struct inode *inode, unsigned int mode)</span>
<span class="quote">&gt; &gt; +struct mm_struct *proc_mem_open(struct inode *inode,</span>
<span class="quote">&gt; &gt; +                               const struct cred **object_cred,</span>
<span class="quote">&gt; &gt; +                               unsigned int mode)</span>
<span class="quote">&gt; &gt;  {</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Why are you passing object_cred all over the place like this?  You</span>
<span class="quote">&gt; have an inode, and an inode implies a task.</span>

But the task&#39;s mm and objective credentials can change, and only mm_access()
holds the cred_guard_mutex during the mm lookup. Although, if the objective
credentials change because of a setuid execution, being able to poke in the
old mm would be pretty harmless...
<span class="quote">

&gt; For that matter, would it possibly make sense to use MEMCG&#39;s mm-&gt;owner</span>
<span class="quote">&gt; and get rid of object_cred entirely?</span>

I guess it might.
<span class="quote">

&gt; I can see this causing issues in</span>
<span class="quote">&gt; strange threading cases, e.g. accessing your own /proc/$$/mem vs</span>
<span class="quote">&gt; another thread in your process&#39;s.</span>

Can you elaborate on that?
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=96711">Jann Horn</a> - Sept. 28, 2016, 11:44 p.m.</div>
<pre class="content">
On Thu, Sep 29, 2016 at 01:32:56AM +0200, Jann Horn wrote:
<span class="quote">&gt; On Wed, Sep 28, 2016 at 04:22:53PM -0700, Andy Lutomirski wrote:</span>
<span class="quote">&gt; &gt; On Wed, Sep 28, 2016 at 3:54 PM, Jann Horn &lt;jann@thejh.net&gt; wrote:</span>
<span class="quote">&gt; &gt; &gt; SELinux attempts to make it possible to whitelist trustworthy sources of</span>
<span class="quote">&gt; &gt; &gt; code that may be mapped into memory, and Android makes use of this feature.</span>
<span class="quote">&gt; &gt; &gt; To prevent an attacker from bypassing this by modifying R+X memory through</span>
<span class="quote">&gt; &gt; &gt; /proc/$pid/mem or PTRACE_POKETEXT, it is necessary to call a security hook</span>
<span class="quote">&gt; &gt; &gt; in check_vma_flags().</span>
<span class="quote">&gt; &gt; </span>
<span class="quote">&gt; &gt; If selinux policy allows PTRACE_POKETEXT, is it really so bad for that</span>
<span class="quote">&gt; &gt; to result in code execution?</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Have a look at __ptrace_may_access():</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; 	/* Don&#39;t let security modules deny introspection */</span>
<span class="quote">&gt; 	if (same_thread_group(task, current))</span>
<span class="quote">&gt; 		return 0;</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; This means thread A can attach to thread B and poke its memory, and SELinux</span>
<span class="quote">&gt; can&#39;t do anything about it.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; I guess another perspective on this would be that it&#39;s a problem that</span>
<span class="quote">&gt; interfaces usable for poking user memory are subject to introspection rules</span>
<span class="quote">&gt; (as opposed to e.g. /proc/self/maps, where it is actually useful).</span>

Ugh, I&#39;m talking nonsense, ptrace() doesn&#39;t work on threads. (/proc/$pid/mem
works though). And then, ptrace-ish APIs aside, there are those weird
devices that do DMA with force=1.
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=35552">Ingo Molnar</a> - Sept. 29, 2016, 6:25 a.m.</div>
<pre class="content">
* Jann Horn &lt;jann@thejh.net&gt; wrote:
<span class="quote">
&gt; +/*</span>
<span class="quote">&gt; + * subject_cred must be the subjective credentials using which access is</span>
<span class="quote">&gt; + * requested.</span>
<span class="quote">&gt; + * object_cred must be the objective credentials of the target task at the time</span>
<span class="quote">&gt; + * the mm_struct was acquired.</span>
<span class="quote">&gt; + * Both of these may be NULL if FOLL_FORCE is unset or FOLL_WRITE is unset.</span>

Hm, I have trouble parsing the first sentence.
<span class="quote">
&gt; -	return __get_user_pages_locked(current, current-&gt;mm, start, nr_pages,</span>
<span class="quote">&gt; -				       write, force, pages, vmas, NULL, false,</span>
<span class="quote">&gt; -				       FOLL_TOUCH);</span>
<span class="quote">&gt; +	return __get_user_pages_locked(current, current-&gt;mm, current_cred(),</span>
<span class="quote">&gt; +				       current_real_cred(), start,</span>
<span class="quote">&gt; +				       nr_pages, write, force, pages, vmas,</span>
<span class="quote">&gt; +				       NULL, false, FOLL_TOUCH);</span>

So the parameter passing was disgustig before, and now it became super disgusing! 

Would it improve the code if we added a friendly helper structure (or two if 
that&#39;s better) to clean up all the interactions within these various functions?

Thanks,

	Ingo
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=96711">Jann Horn</a> - Nov. 3, 2016, 2:25 a.m.</div>
<pre class="content">
On Thu, Sep 29, 2016 at 01:32:56AM +0200, Jann Horn wrote:
<span class="quote">&gt; On Wed, Sep 28, 2016 at 04:22:53PM -0700, Andy Lutomirski wrote:</span>
<span class="quote">&gt; &gt; On Wed, Sep 28, 2016 at 3:54 PM, Jann Horn &lt;jann@thejh.net&gt; wrote:</span>
<span class="quote">&gt; &gt; &gt; -struct mm_struct *proc_mem_open(struct inode *inode, unsigned int mode)</span>
<span class="quote">&gt; &gt; &gt; +struct mm_struct *proc_mem_open(struct inode *inode,</span>
<span class="quote">&gt; &gt; &gt; +                               const struct cred **object_cred,</span>
<span class="quote">&gt; &gt; &gt; +                               unsigned int mode)</span>
<span class="quote">&gt; &gt; &gt;  {</span>
<span class="quote">&gt; &gt; </span>
<span class="quote">&gt; &gt; Why are you passing object_cred all over the place like this?  You</span>
<span class="quote">&gt; &gt; have an inode, and an inode implies a task.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; But the task&#39;s mm and objective credentials can change, and only mm_access()</span>
<span class="quote">&gt; holds the cred_guard_mutex during the mm lookup. Although, if the objective</span>
<span class="quote">&gt; credentials change because of a setuid execution, being able to poke in the</span>
<span class="quote">&gt; old mm would be pretty harmless...</span>

Actually, no. If you can poke in the pre-execve memory, but are checked
against the (possibly more permissive) objective creds of the post-execve
process, you can affect another process that shares the pre-execve memory
(the case where task B, which calls execve(), was clone()d from task A
with CLONE_VM). So I&#39;m keeping this code the way I wrote it.
<span class="quote">

&gt; &gt; For that matter, would it possibly make sense to use MEMCG&#39;s mm-&gt;owner</span>
<span class="quote">&gt; &gt; and get rid of object_cred entirely?</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; I guess it might.</span>

Actually, I&#39;d prefer not to do that - I think it would be unnecessarily
unintuitive to check against the objective creds of task A when accessing
task B if task B was clone()d from A with clone(CLONE_VM).
<span class="quote">
&gt; &gt; I can see this causing issues in</span>
<span class="quote">&gt; &gt; strange threading cases, e.g. accessing your own /proc/$$/mem vs</span>
<span class="quote">&gt; &gt; another thread in your process&#39;s.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Can you elaborate on that?</span>
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/drivers/gpu/drm/etnaviv/etnaviv_gem.c b/drivers/gpu/drm/etnaviv/etnaviv_gem.c</span>
<span class="p_header">index 5ce3603..873130d 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/etnaviv/etnaviv_gem.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/etnaviv/etnaviv_gem.c</span>
<span class="p_chunk">@@ -758,7 +758,8 @@</span> <span class="p_context"> static struct page **etnaviv_gem_userptr_do_get_pages(</span>
 
 	down_read(&amp;mm-&gt;mmap_sem);
 	while (pinned &lt; npages) {
<span class="p_del">-		ret = get_user_pages_remote(task, mm, ptr, npages - pinned,</span>
<span class="p_add">+		ret = get_user_pages_remote(task, mm, NULL, NULL, ptr,</span>
<span class="p_add">+					    npages - pinned,</span>
 					    !etnaviv_obj-&gt;userptr.ro, 0,
 					    pvec + pinned, NULL);
 		if (ret &lt; 0)
<span class="p_header">diff --git a/drivers/gpu/drm/i915/i915_gem_userptr.c b/drivers/gpu/drm/i915/i915_gem_userptr.c</span>
<span class="p_header">index 2314c88..1633081 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/i915/i915_gem_userptr.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/i915/i915_gem_userptr.c</span>
<span class="p_chunk">@@ -544,7 +544,7 @@</span> <span class="p_context"> __i915_gem_userptr_get_pages_worker(struct work_struct *_work)</span>
 			down_read(&amp;mm-&gt;mmap_sem);
 			while (pinned &lt; npages) {
 				ret = get_user_pages_remote
<span class="p_del">-					(work-&gt;task, mm,</span>
<span class="p_add">+					(work-&gt;task, mm, NULL, NULL,</span>
 					 obj-&gt;userptr.ptr + pinned * PAGE_SIZE,
 					 npages - pinned,
 					 !obj-&gt;userptr.read_only, 0,
<span class="p_header">diff --git a/drivers/infiniband/core/umem_odp.c b/drivers/infiniband/core/umem_odp.c</span>
<span class="p_header">index 75077a0..cbebfaa 100644</span>
<span class="p_header">--- a/drivers/infiniband/core/umem_odp.c</span>
<span class="p_header">+++ b/drivers/infiniband/core/umem_odp.c</span>
<span class="p_chunk">@@ -572,8 +572,8 @@</span> <span class="p_context"> int ib_umem_odp_map_dma_pages(struct ib_umem *umem, u64 user_virt, u64 bcnt,</span>
 		 * complex (and doesn&#39;t gain us much performance in most use
 		 * cases).
 		 */
<span class="p_del">-		npages = get_user_pages_remote(owning_process, owning_mm,</span>
<span class="p_del">-				user_virt, gup_num_pages,</span>
<span class="p_add">+		npages = get_user_pages_remote(owning_process, owning_mm, NULL,</span>
<span class="p_add">+				NULL, user_virt, gup_num_pages,</span>
 				access_mask &amp; ODP_WRITE_ALLOWED_BIT,
 				0, local_page_list, NULL);
 		up_read(&amp;owning_mm-&gt;mmap_sem);
<span class="p_header">diff --git a/fs/exec.c b/fs/exec.c</span>
<span class="p_header">index d607da8..c57a8f0 100644</span>
<span class="p_header">--- a/fs/exec.c</span>
<span class="p_header">+++ b/fs/exec.c</span>
<span class="p_chunk">@@ -203,8 +203,8 @@</span> <span class="p_context"> static struct page *get_arg_page(struct linux_binprm *bprm, unsigned long pos,</span>
 	 * We are doing an exec().  &#39;current&#39; is the process
 	 * doing the exec and bprm-&gt;mm is the new process&#39;s mm.
 	 */
<span class="p_del">-	ret = get_user_pages_remote(current, bprm-&gt;mm, pos, 1, write,</span>
<span class="p_del">-			0, &amp;page, NULL);</span>
<span class="p_add">+	ret = get_user_pages_remote(current, bprm-&gt;mm, NULL, NULL, pos, 1,</span>
<span class="p_add">+			write, 0, &amp;page, NULL);</span>
 	if (ret &lt;= 0)
 		return NULL;
 
<span class="p_header">diff --git a/fs/proc/base.c b/fs/proc/base.c</span>
<span class="p_header">index ac0df4d..9575975 100644</span>
<span class="p_header">--- a/fs/proc/base.c</span>
<span class="p_header">+++ b/fs/proc/base.c</span>
<span class="p_chunk">@@ -113,6 +113,11 @@</span> <span class="p_context"> struct pid_entry {</span>
 	union proc_op op;
 };
 
<span class="p_add">+struct mem_private {</span>
<span class="p_add">+	struct mm_struct *mm;</span>
<span class="p_add">+	const struct cred *object_cred;</span>
<span class="p_add">+};</span>
<span class="p_add">+</span>
 #define NOD(NAME, MODE, IOP, FOP, OP) {			\
 	.name = (NAME),					\
 	.len  = sizeof(NAME) - 1,			\
<span class="p_chunk">@@ -252,7 +257,7 @@</span> <span class="p_context"> static ssize_t proc_pid_cmdline_read(struct file *file, char __user *buf,</span>
 	 * Inherently racy -- command line shares address space
 	 * with code and data.
 	 */
<span class="p_del">-	rv = access_remote_vm(mm, arg_end - 1, &amp;c, 1, 0);</span>
<span class="p_add">+	rv = access_remote_vm(mm, NULL, NULL, arg_end - 1, &amp;c, 1, 0);</span>
 	if (rv &lt;= 0)
 		goto out_free_page;
 
<span class="p_chunk">@@ -270,7 +275,8 @@</span> <span class="p_context"> static ssize_t proc_pid_cmdline_read(struct file *file, char __user *buf,</span>
 			int nr_read;
 
 			_count = min3(count, len, PAGE_SIZE);
<span class="p_del">-			nr_read = access_remote_vm(mm, p, page, _count, 0);</span>
<span class="p_add">+			nr_read = access_remote_vm(mm, NULL, NULL, p, page,</span>
<span class="p_add">+						   _count, 0);</span>
 			if (nr_read &lt; 0)
 				rv = nr_read;
 			if (nr_read &lt;= 0)
<span class="p_chunk">@@ -305,7 +311,8 @@</span> <span class="p_context"> static ssize_t proc_pid_cmdline_read(struct file *file, char __user *buf,</span>
 			bool final;
 
 			_count = min3(count, len, PAGE_SIZE);
<span class="p_del">-			nr_read = access_remote_vm(mm, p, page, _count, 0);</span>
<span class="p_add">+			nr_read = access_remote_vm(mm, NULL, NULL, p, page,</span>
<span class="p_add">+						   _count, 0);</span>
 			if (nr_read &lt; 0)
 				rv = nr_read;
 			if (nr_read &lt;= 0)
<span class="p_chunk">@@ -354,7 +361,8 @@</span> <span class="p_context"> skip_argv:</span>
 			bool final;
 
 			_count = min3(count, len, PAGE_SIZE);
<span class="p_del">-			nr_read = access_remote_vm(mm, p, page, _count, 0);</span>
<span class="p_add">+			nr_read = access_remote_vm(mm, NULL, NULL, p, page,</span>
<span class="p_add">+						   _count, 0);</span>
 			if (nr_read &lt; 0)
 				rv = nr_read;
 			if (nr_read &lt;= 0)
<span class="p_chunk">@@ -403,7 +411,7 @@</span> <span class="p_context"> static const struct file_operations proc_pid_cmdline_ops = {</span>
 static int proc_pid_auxv(struct seq_file *m, struct pid_namespace *ns,
 			 struct pid *pid, struct task_struct *task)
 {
<span class="p_del">-	struct mm_struct *mm = mm_access(task, PTRACE_MODE_READ_FSCREDS);</span>
<span class="p_add">+	struct mm_struct *mm = mm_access(task, NULL, PTRACE_MODE_READ_FSCREDS);</span>
 	if (mm &amp;&amp; !IS_ERR(mm)) {
 		unsigned int nwords = 0;
 		do {
<span class="p_chunk">@@ -801,13 +809,15 @@</span> <span class="p_context"> static const struct file_operations proc_single_file_operations = {</span>
 };
 
 
<span class="p_del">-struct mm_struct *proc_mem_open(struct inode *inode, unsigned int mode)</span>
<span class="p_add">+struct mm_struct *proc_mem_open(struct inode *inode,</span>
<span class="p_add">+				const struct cred **object_cred,</span>
<span class="p_add">+				unsigned int mode)</span>
 {
 	struct task_struct *task = get_proc_task(inode);
 	struct mm_struct *mm = ERR_PTR(-ESRCH);
 
 	if (task) {
<span class="p_del">-		mm = mm_access(task, mode | PTRACE_MODE_FSCREDS);</span>
<span class="p_add">+		mm = mm_access(task, object_cred, mode | PTRACE_MODE_FSCREDS);</span>
 		put_task_struct(task);
 
 		if (!IS_ERR_OR_NULL(mm)) {
<span class="p_chunk">@@ -823,7 +833,7 @@</span> <span class="p_context"> struct mm_struct *proc_mem_open(struct inode *inode, unsigned int mode)</span>
 
 static int __mem_open(struct inode *inode, struct file *file, unsigned int mode)
 {
<span class="p_del">-	struct mm_struct *mm = proc_mem_open(inode, mode);</span>
<span class="p_add">+	struct mm_struct *mm = proc_mem_open(inode, NULL, mode);</span>
 
 	if (IS_ERR(mm))
 		return PTR_ERR(mm);
<span class="p_chunk">@@ -834,18 +844,36 @@</span> <span class="p_context"> static int __mem_open(struct inode *inode, struct file *file, unsigned int mode)</span>
 
 static int mem_open(struct inode *inode, struct file *file)
 {
<span class="p_del">-	int ret = __mem_open(inode, file, PTRACE_MODE_ATTACH);</span>
<span class="p_add">+	struct mem_private *private = kmalloc(sizeof(*private), GFP_KERNEL);</span>
<span class="p_add">+	struct mm_struct *mm;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (!private)</span>
<span class="p_add">+		return -ENOMEM;</span>
<span class="p_add">+</span>
<span class="p_add">+	mm = proc_mem_open(inode, &amp;private-&gt;object_cred, PTRACE_MODE_ATTACH);</span>
<span class="p_add">+</span>
<span class="p_add">+	if (!mm)</span>
<span class="p_add">+		private-&gt;object_cred = NULL;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (IS_ERR(mm)) {</span>
<span class="p_add">+		kfree(private);</span>
<span class="p_add">+		return PTR_ERR(mm);</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	private-&gt;mm = mm;</span>
<span class="p_add">+	file-&gt;private_data = private;</span>
 
 	/* OK to pass negative loff_t, we can catch out-of-range */
 	file-&gt;f_mode |= FMODE_UNSIGNED_OFFSET;
 
<span class="p_del">-	return ret;</span>
<span class="p_add">+	return 0;</span>
 }
 
 static ssize_t mem_rw(struct file *file, char __user *buf,
 			size_t count, loff_t *ppos, int write)
 {
<span class="p_del">-	struct mm_struct *mm = file-&gt;private_data;</span>
<span class="p_add">+	struct mem_private *private = file-&gt;private_data;</span>
<span class="p_add">+	struct mm_struct *mm = private-&gt;mm;</span>
 	unsigned long addr = *ppos;
 	ssize_t copied;
 	char *page;
<span class="p_chunk">@@ -869,7 +897,9 @@</span> <span class="p_context"> static ssize_t mem_rw(struct file *file, char __user *buf,</span>
 			break;
 		}
 
<span class="p_del">-		this_len = access_remote_vm(mm, addr, page, this_len, write);</span>
<span class="p_add">+		this_len = access_remote_vm(mm, file-&gt;f_cred,</span>
<span class="p_add">+					    private-&gt;object_cred, addr,</span>
<span class="p_add">+					    page, this_len, write);</span>
 		if (!this_len) {
 			if (!copied)
 				copied = -EIO;
<span class="p_chunk">@@ -924,9 +954,13 @@</span> <span class="p_context"> loff_t mem_lseek(struct file *file, loff_t offset, int orig)</span>
 
 static int mem_release(struct inode *inode, struct file *file)
 {
<span class="p_del">-	struct mm_struct *mm = file-&gt;private_data;</span>
<span class="p_del">-	if (mm)</span>
<span class="p_del">-		mmdrop(mm);</span>
<span class="p_add">+	struct mem_private *private = file-&gt;private_data;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (private-&gt;mm) {</span>
<span class="p_add">+		mmdrop(private-&gt;mm);</span>
<span class="p_add">+		put_cred(private-&gt;object_cred);</span>
<span class="p_add">+	}</span>
<span class="p_add">+	kfree(private);</span>
 	return 0;
 }
 
<span class="p_chunk">@@ -981,7 +1015,7 @@</span> <span class="p_context"> static ssize_t environ_read(struct file *file, char __user *buf,</span>
 		max_len = min_t(size_t, PAGE_SIZE, count);
 		this_len = min(max_len, this_len);
 
<span class="p_del">-		retval = access_remote_vm(mm, (env_start + src),</span>
<span class="p_add">+		retval = access_remote_vm(mm, NULL, NULL, (env_start + src),</span>
 			page, this_len, 0);
 
 		if (retval &lt;= 0) {
<span class="p_chunk">@@ -1873,7 +1907,7 @@</span> <span class="p_context"> static int map_files_d_revalidate(struct dentry *dentry, unsigned int flags)</span>
 	if (!task)
 		goto out_notask;
 
<span class="p_del">-	mm = mm_access(task, PTRACE_MODE_READ_FSCREDS);</span>
<span class="p_add">+	mm = mm_access(task, NULL, PTRACE_MODE_READ_FSCREDS);</span>
 	if (IS_ERR_OR_NULL(mm))
 		goto out;
 
<span class="p_header">diff --git a/fs/proc/internal.h b/fs/proc/internal.h</span>
<span class="p_header">index 7931c55..53e4ad6 100644</span>
<span class="p_header">--- a/fs/proc/internal.h</span>
<span class="p_header">+++ b/fs/proc/internal.h</span>
<span class="p_chunk">@@ -288,7 +288,9 @@</span> <span class="p_context"> struct proc_maps_private {</span>
 #endif
 };
 
<span class="p_del">-struct mm_struct *proc_mem_open(struct inode *inode, unsigned int mode);</span>
<span class="p_add">+struct mm_struct *proc_mem_open(struct inode *inode,</span>
<span class="p_add">+				const struct cred **object_cred,</span>
<span class="p_add">+				unsigned int mode);</span>
 
 extern const struct file_operations proc_pid_maps_operations;
 extern const struct file_operations proc_tid_maps_operations;
<span class="p_header">diff --git a/fs/proc/task_mmu.c b/fs/proc/task_mmu.c</span>
<span class="p_header">index f6fa99e..f7ab4aa 100644</span>
<span class="p_header">--- a/fs/proc/task_mmu.c</span>
<span class="p_header">+++ b/fs/proc/task_mmu.c</span>
<span class="p_chunk">@@ -230,7 +230,7 @@</span> <span class="p_context"> static int proc_maps_open(struct inode *inode, struct file *file,</span>
 		return -ENOMEM;
 
 	priv-&gt;inode = inode;
<span class="p_del">-	priv-&gt;mm = proc_mem_open(inode, PTRACE_MODE_READ);</span>
<span class="p_add">+	priv-&gt;mm = proc_mem_open(inode, NULL, PTRACE_MODE_READ);</span>
 	if (IS_ERR(priv-&gt;mm)) {
 		int err = PTR_ERR(priv-&gt;mm);
 
<span class="p_chunk">@@ -1443,7 +1443,7 @@</span> <span class="p_context"> static int pagemap_open(struct inode *inode, struct file *file)</span>
 {
 	struct mm_struct *mm;
 
<span class="p_del">-	mm = proc_mem_open(inode, PTRACE_MODE_READ);</span>
<span class="p_add">+	mm = proc_mem_open(inode, NULL, PTRACE_MODE_READ);</span>
 	if (IS_ERR(mm))
 		return PTR_ERR(mm);
 	file-&gt;private_data = mm;
<span class="p_header">diff --git a/fs/proc/task_nommu.c b/fs/proc/task_nommu.c</span>
<span class="p_header">index faacb0c..6243696 100644</span>
<span class="p_header">--- a/fs/proc/task_nommu.c</span>
<span class="p_header">+++ b/fs/proc/task_nommu.c</span>
<span class="p_chunk">@@ -287,7 +287,7 @@</span> <span class="p_context"> static int maps_open(struct inode *inode, struct file *file,</span>
 		return -ENOMEM;
 
 	priv-&gt;inode = inode;
<span class="p_del">-	priv-&gt;mm = proc_mem_open(inode, PTRACE_MODE_READ);</span>
<span class="p_add">+	priv-&gt;mm = proc_mem_open(inode, NULL, PTRACE_MODE_READ);</span>
 	if (IS_ERR(priv-&gt;mm)) {
 		int err = PTR_ERR(priv-&gt;mm);
 
<span class="p_header">diff --git a/include/linux/lsm_hooks.h b/include/linux/lsm_hooks.h</span>
<span class="p_header">index 101bf19..b62d989 100644</span>
<span class="p_header">--- a/include/linux/lsm_hooks.h</span>
<span class="p_header">+++ b/include/linux/lsm_hooks.h</span>
<span class="p_chunk">@@ -1154,6 +1154,11 @@</span> <span class="p_context"></span>
  *	to the @parent process for tracing.
  *	@parent contains the task_struct structure for debugger process.
  *	Return 0 if permission is granted.
<span class="p_add">+ * @forced_write:</span>
<span class="p_add">+ *	Check whether @subject_cred is permitted to forcibly write to the</span>
<span class="p_add">+ *	non-writable mapping @vma that belongs to a process with objective</span>
<span class="p_add">+ *	credentials @object_cred.</span>
<span class="p_add">+ *	Return 0 if permission is granted.</span>
  * @capget:
  *	Get the @effective, @inheritable, and @permitted capability sets for
  *	the @target process.  The hook may also perform permission checking to
<span class="p_chunk">@@ -1317,6 +1322,9 @@</span> <span class="p_context"> union security_list_options {</span>
 	int (*ptrace_access_check)(struct task_struct *child,
 					unsigned int mode);
 	int (*ptrace_traceme)(struct task_struct *parent);
<span class="p_add">+	int (*forced_write)(struct vm_area_struct *vma,</span>
<span class="p_add">+				const struct cred *subject_cred,</span>
<span class="p_add">+				const struct cred *object_cred);</span>
 	int (*capget)(struct task_struct *target, kernel_cap_t *effective,
 			kernel_cap_t *inheritable, kernel_cap_t *permitted);
 	int (*capset)(struct cred *new, const struct cred *old,
<span class="p_chunk">@@ -1629,6 +1637,7 @@</span> <span class="p_context"> struct security_hook_heads {</span>
 	struct list_head binder_transfer_file;
 	struct list_head ptrace_access_check;
 	struct list_head ptrace_traceme;
<span class="p_add">+	struct list_head forced_write;</span>
 	struct list_head capget;
 	struct list_head capset;
 	struct list_head capable;
<span class="p_header">diff --git a/include/linux/mm.h b/include/linux/mm.h</span>
<span class="p_header">index ef815b9..ef92319 100644</span>
<span class="p_header">--- a/include/linux/mm.h</span>
<span class="p_header">+++ b/include/linux/mm.h</span>
<span class="p_chunk">@@ -23,6 +23,7 @@</span> <span class="p_context"></span>
 #include &lt;linux/page_ext.h&gt;
 #include &lt;linux/err.h&gt;
 #include &lt;linux/page_ref.h&gt;
<span class="p_add">+#include &lt;linux/cred.h&gt;</span>
 
 struct mempolicy;
 struct anon_vma;
<span class="p_chunk">@@ -1279,14 +1280,19 @@</span> <span class="p_context"> static inline int fixup_user_fault(struct task_struct *tsk,</span>
 #endif
 
 extern int access_process_vm(struct task_struct *tsk, unsigned long addr, void *buf, int len, int write);
<span class="p_del">-extern int access_remote_vm(struct mm_struct *mm, unsigned long addr,</span>
<span class="p_del">-		void *buf, int len, int write);</span>
<span class="p_add">+extern int access_remote_vm(struct mm_struct *mm,</span>
<span class="p_add">+		const struct cred *subject_cred, const struct cred *object_cred,</span>
<span class="p_add">+		unsigned long addr, void *buf, int len, int write);</span>
 
 long __get_user_pages(struct task_struct *tsk, struct mm_struct *mm,
<span class="p_add">+		      const struct cred *subject_cred,</span>
<span class="p_add">+		      const struct cred *object_cred,</span>
 		      unsigned long start, unsigned long nr_pages,
 		      unsigned int foll_flags, struct page **pages,
 		      struct vm_area_struct **vmas, int *nonblocking);
 long get_user_pages_remote(struct task_struct *tsk, struct mm_struct *mm,
<span class="p_add">+			    const struct cred *subject_cred,</span>
<span class="p_add">+			    const struct cred *object_cred,</span>
 			    unsigned long start, unsigned long nr_pages,
 			    int write, int force, struct page **pages,
 			    struct vm_area_struct **vmas);
<span class="p_chunk">@@ -1296,6 +1302,8 @@</span> <span class="p_context"> long get_user_pages(unsigned long start, unsigned long nr_pages,</span>
 long get_user_pages_locked(unsigned long start, unsigned long nr_pages,
 		    int write, int force, struct page **pages, int *locked);
 long __get_user_pages_unlocked(struct task_struct *tsk, struct mm_struct *mm,
<span class="p_add">+			       const struct cred *subject_cred,</span>
<span class="p_add">+			       const struct cred *object_cred,</span>
 			       unsigned long start, unsigned long nr_pages,
 			       int write, int force, struct page **pages,
 			       unsigned int gup_flags);
<span class="p_header">diff --git a/include/linux/sched.h b/include/linux/sched.h</span>
<span class="p_header">index 62c68e5..c792341 100644</span>
<span class="p_header">--- a/include/linux/sched.h</span>
<span class="p_header">+++ b/include/linux/sched.h</span>
<span class="p_chunk">@@ -2853,7 +2853,9 @@</span> <span class="p_context"> extern struct mm_struct *get_task_mm(struct task_struct *task);</span>
  * and ptrace_may_access with the mode parameter passed to it
  * succeeds.
  */
<span class="p_del">-extern struct mm_struct *mm_access(struct task_struct *task, unsigned int mode);</span>
<span class="p_add">+extern struct mm_struct *mm_access(struct task_struct *task,</span>
<span class="p_add">+				   const struct cred **object_cred,</span>
<span class="p_add">+				   unsigned int mode);</span>
 /* Remove the current tasks stale references to the old mm_struct */
 extern void mm_release(struct task_struct *, struct mm_struct *);
 
<span class="p_header">diff --git a/include/linux/security.h b/include/linux/security.h</span>
<span class="p_header">index 7831cd5..8f0dbce 100644</span>
<span class="p_header">--- a/include/linux/security.h</span>
<span class="p_header">+++ b/include/linux/security.h</span>
<span class="p_chunk">@@ -193,6 +193,9 @@</span> <span class="p_context"> int security_binder_transfer_file(struct task_struct *from,</span>
 				  struct task_struct *to, struct file *file);
 int security_ptrace_access_check(struct task_struct *child, unsigned int mode);
 int security_ptrace_traceme(struct task_struct *parent);
<span class="p_add">+int security_forced_write(struct vm_area_struct *vma,</span>
<span class="p_add">+			  const struct cred *subject_cred,</span>
<span class="p_add">+			  const struct cred *object_cred);</span>
 int security_capget(struct task_struct *target,
 		    kernel_cap_t *effective,
 		    kernel_cap_t *inheritable,
<span class="p_chunk">@@ -424,6 +427,13 @@</span> <span class="p_context"> static inline int security_ptrace_traceme(struct task_struct *parent)</span>
 	return cap_ptrace_traceme(parent);
 }
 
<span class="p_add">+static inline int security_forced_write(struct vm_area_struct *vma,</span>
<span class="p_add">+					const struct cred *subject_cred,</span>
<span class="p_add">+					const struct cred *object_cred)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return 0;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static inline int security_capget(struct task_struct *target,
 				   kernel_cap_t *effective,
 				   kernel_cap_t *inheritable,
<span class="p_header">diff --git a/kernel/events/uprobes.c b/kernel/events/uprobes.c</span>
<span class="p_header">index 8c50276..26021e1 100644</span>
<span class="p_header">--- a/kernel/events/uprobes.c</span>
<span class="p_header">+++ b/kernel/events/uprobes.c</span>
<span class="p_chunk">@@ -300,7 +300,8 @@</span> <span class="p_context"> int uprobe_write_opcode(struct mm_struct *mm, unsigned long vaddr,</span>
 
 retry:
 	/* Read the page with vaddr into memory */
<span class="p_del">-	ret = get_user_pages_remote(NULL, mm, vaddr, 1, 0, 1, &amp;old_page, &amp;vma);</span>
<span class="p_add">+	ret = get_user_pages_remote(NULL, mm, NULL, NULL, vaddr, 1, 0, 1,</span>
<span class="p_add">+				    &amp;old_page, &amp;vma);</span>
 	if (ret &lt;= 0)
 		return ret;
 
<span class="p_chunk">@@ -1710,7 +1711,8 @@</span> <span class="p_context"> static int is_trap_at_addr(struct mm_struct *mm, unsigned long vaddr)</span>
 	 * but we treat this as a &#39;remote&#39; access since it is
 	 * essentially a kernel access to the memory.
 	 */
<span class="p_del">-	result = get_user_pages_remote(NULL, mm, vaddr, 1, 0, 1, &amp;page, NULL);</span>
<span class="p_add">+	result = get_user_pages_remote(NULL, mm, NULL, NULL, vaddr, 1, 0, 1,</span>
<span class="p_add">+				       &amp;page, NULL);</span>
 	if (result &lt; 0)
 		return result;
 
<span class="p_header">diff --git a/kernel/fork.c b/kernel/fork.c</span>
<span class="p_header">index beb3172..e6e1fd7 100644</span>
<span class="p_header">--- a/kernel/fork.c</span>
<span class="p_header">+++ b/kernel/fork.c</span>
<span class="p_chunk">@@ -847,7 +847,8 @@</span> <span class="p_context"> struct mm_struct *get_task_mm(struct task_struct *task)</span>
 }
 EXPORT_SYMBOL_GPL(get_task_mm);
 
<span class="p_del">-struct mm_struct *mm_access(struct task_struct *task, unsigned int mode)</span>
<span class="p_add">+struct mm_struct *mm_access(struct task_struct *task,</span>
<span class="p_add">+			    const struct cred **object_cred, unsigned int mode)</span>
 {
 	struct mm_struct *mm;
 	int err;
<span class="p_chunk">@@ -862,6 +863,9 @@</span> <span class="p_context"> struct mm_struct *mm_access(struct task_struct *task, unsigned int mode)</span>
 		mmput(mm);
 		mm = ERR_PTR(-EACCES);
 	}
<span class="p_add">+	if (!IS_ERR_OR_NULL(mm) &amp;&amp; object_cred)</span>
<span class="p_add">+		*object_cred = get_task_cred(task);</span>
<span class="p_add">+</span>
 	mutex_unlock(&amp;task-&gt;signal-&gt;cred_guard_mutex);
 
 	return mm;
<span class="p_header">diff --git a/mm/gup.c b/mm/gup.c</span>
<span class="p_header">index 96b2b2f..481ab81 100644</span>
<span class="p_header">--- a/mm/gup.c</span>
<span class="p_header">+++ b/mm/gup.c</span>
<span class="p_chunk">@@ -2,6 +2,7 @@</span> <span class="p_context"></span>
 #include &lt;linux/errno.h&gt;
 #include &lt;linux/err.h&gt;
 #include &lt;linux/spinlock.h&gt;
<span class="p_add">+#include &lt;linux/security.h&gt;</span>
 
 #include &lt;linux/mm.h&gt;
 #include &lt;linux/memremap.h&gt;
<span class="p_chunk">@@ -416,7 +417,17 @@</span> <span class="p_context"> static int faultin_page(struct task_struct *tsk, struct vm_area_struct *vma,</span>
 	return 0;
 }
 
<span class="p_del">-static int check_vma_flags(struct vm_area_struct *vma, unsigned long gup_flags)</span>
<span class="p_add">+/*</span>
<span class="p_add">+ * subject_cred must be the subjective credentials using which access is</span>
<span class="p_add">+ * requested.</span>
<span class="p_add">+ * object_cred must be the objective credentials of the target task at the time</span>
<span class="p_add">+ * the mm_struct was acquired.</span>
<span class="p_add">+ * Both of these may be NULL if FOLL_FORCE is unset or FOLL_WRITE is unset.</span>
<span class="p_add">+ */</span>
<span class="p_add">+static int check_vma_flags(struct vm_area_struct *vma,</span>
<span class="p_add">+			   const struct cred *subject_cred,</span>
<span class="p_add">+			   const struct cred *object_cred,</span>
<span class="p_add">+			   unsigned long gup_flags)</span>
 {
 	vm_flags_t vm_flags = vma-&gt;vm_flags;
 	int write = (gup_flags &amp; FOLL_WRITE);
<span class="p_chunk">@@ -426,9 +437,19 @@</span> <span class="p_context"> static int check_vma_flags(struct vm_area_struct *vma, unsigned long gup_flags)</span>
 		return -EFAULT;
 
 	if (write) {
<span class="p_add">+		/* If one of the cred parameters is missing and the WRITE and</span>
<span class="p_add">+		 * FORCE flags are set, that&#39;s a kernel bug.</span>
<span class="p_add">+		 */</span>
<span class="p_add">+		if (WARN_ON((gup_flags &amp; FOLL_FORCE) &amp;&amp;</span>
<span class="p_add">+		    (subject_cred == NULL || object_cred == NULL)))</span>
<span class="p_add">+			return -EFAULT;</span>
<span class="p_add">+</span>
 		if (!(vm_flags &amp; VM_WRITE)) {
 			if (!(gup_flags &amp; FOLL_FORCE))
 				return -EFAULT;
<span class="p_add">+			if (security_forced_write(vma, subject_cred,</span>
<span class="p_add">+						  object_cred))</span>
<span class="p_add">+				return -EFAULT;</span>
 			/*
 			 * We used to let the write,force case do COW in a
 			 * VM_MAYWRITE VM_SHARED !VM_WRITE vma, so ptrace could
<span class="p_chunk">@@ -517,6 +538,8 @@</span> <span class="p_context"> static int check_vma_flags(struct vm_area_struct *vma, unsigned long gup_flags)</span>
  * you need some special @gup_flags.
  */
 long __get_user_pages(struct task_struct *tsk, struct mm_struct *mm,
<span class="p_add">+		const struct cred *subject_cred,</span>
<span class="p_add">+		const struct cred *object_cred,</span>
 		unsigned long start, unsigned long nr_pages,
 		unsigned int gup_flags, struct page **pages,
 		struct vm_area_struct **vmas, int *nonblocking)
<span class="p_chunk">@@ -557,7 +580,8 @@</span> <span class="p_context"> long __get_user_pages(struct task_struct *tsk, struct mm_struct *mm,</span>
 				goto next_page;
 			}
 
<span class="p_del">-			if (!vma || check_vma_flags(vma, gup_flags))</span>
<span class="p_add">+			if (!vma || check_vma_flags(vma, subject_cred,</span>
<span class="p_add">+						    object_cred, gup_flags))</span>
 				return i ? : -EFAULT;
 			if (is_vm_hugetlb_page(vma)) {
 				i = follow_hugetlb_page(mm, vma, pages, vmas,
<span class="p_chunk">@@ -727,6 +751,8 @@</span> <span class="p_context"> EXPORT_SYMBOL_GPL(fixup_user_fault);</span>
 
 static __always_inline long __get_user_pages_locked(struct task_struct *tsk,
 						struct mm_struct *mm,
<span class="p_add">+						const struct cred *subject_cred,</span>
<span class="p_add">+						const struct cred *object_cred,</span>
 						unsigned long start,
 						unsigned long nr_pages,
 						int write, int force,
<span class="p_chunk">@@ -755,8 +781,9 @@</span> <span class="p_context"> static __always_inline long __get_user_pages_locked(struct task_struct *tsk,</span>
 	pages_done = 0;
 	lock_dropped = false;
 	for (;;) {
<span class="p_del">-		ret = __get_user_pages(tsk, mm, start, nr_pages, flags, pages,</span>
<span class="p_del">-				       vmas, locked);</span>
<span class="p_add">+		ret = __get_user_pages(tsk, mm, subject_cred, object_cred,</span>
<span class="p_add">+				       start, nr_pages, flags, pages, vmas,</span>
<span class="p_add">+				       locked);</span>
 		if (!locked)
 			/* VM_FAULT_RETRY couldn&#39;t trigger, bypass */
 			return ret;
<span class="p_chunk">@@ -795,8 +822,9 @@</span> <span class="p_context"> static __always_inline long __get_user_pages_locked(struct task_struct *tsk,</span>
 		*locked = 1;
 		lock_dropped = true;
 		down_read(&amp;mm-&gt;mmap_sem);
<span class="p_del">-		ret = __get_user_pages(tsk, mm, start, 1, flags | FOLL_TRIED,</span>
<span class="p_del">-				       pages, NULL, NULL);</span>
<span class="p_add">+		ret = __get_user_pages(tsk, mm, subject_cred, object_cred,</span>
<span class="p_add">+				       start, 1, flags | FOLL_TRIED, pages,</span>
<span class="p_add">+				       NULL, NULL);</span>
 		if (ret != 1) {
 			BUG_ON(ret &gt; 1);
 			if (!pages_done)
<span class="p_chunk">@@ -846,9 +874,10 @@</span> <span class="p_context"> long get_user_pages_locked(unsigned long start, unsigned long nr_pages,</span>
 			   int write, int force, struct page **pages,
 			   int *locked)
 {
<span class="p_del">-	return __get_user_pages_locked(current, current-&gt;mm, start, nr_pages,</span>
<span class="p_del">-				       write, force, pages, NULL, locked, true,</span>
<span class="p_del">-				       FOLL_TOUCH);</span>
<span class="p_add">+	return __get_user_pages_locked(current, current-&gt;mm, current_cred(),</span>
<span class="p_add">+				       current_real_cred(), start,</span>
<span class="p_add">+				       nr_pages, write, force, pages, NULL,</span>
<span class="p_add">+				       locked, true, FOLL_TOUCH);</span>
 }
 EXPORT_SYMBOL(get_user_pages_locked);
 
<span class="p_chunk">@@ -863,6 +892,8 @@</span> <span class="p_context"> EXPORT_SYMBOL(get_user_pages_locked);</span>
  * respectively.
  */
 __always_inline long __get_user_pages_unlocked(struct task_struct *tsk, struct mm_struct *mm,
<span class="p_add">+					       const struct cred *subject_cred,</span>
<span class="p_add">+					       const struct cred *object_cred,</span>
 					       unsigned long start, unsigned long nr_pages,
 					       int write, int force, struct page **pages,
 					       unsigned int gup_flags)
<span class="p_chunk">@@ -870,8 +901,9 @@</span> <span class="p_context"> __always_inline long __get_user_pages_unlocked(struct task_struct *tsk, struct m</span>
 	long ret;
 	int locked = 1;
 	down_read(&amp;mm-&gt;mmap_sem);
<span class="p_del">-	ret = __get_user_pages_locked(tsk, mm, start, nr_pages, write, force,</span>
<span class="p_del">-				      pages, NULL, &amp;locked, false, gup_flags);</span>
<span class="p_add">+	ret = __get_user_pages_locked(tsk, mm, subject_cred, object_cred, start,</span>
<span class="p_add">+				      nr_pages, write, force, pages, NULL,</span>
<span class="p_add">+				      &amp;locked, false, gup_flags);</span>
 	if (locked)
 		up_read(&amp;mm-&gt;mmap_sem);
 	return ret;
<span class="p_chunk">@@ -898,7 +930,12 @@</span> <span class="p_context"> EXPORT_SYMBOL(__get_user_pages_unlocked);</span>
 long get_user_pages_unlocked(unsigned long start, unsigned long nr_pages,
 			     int write, int force, struct page **pages)
 {
<span class="p_del">-	return __get_user_pages_unlocked(current, current-&gt;mm, start, nr_pages,</span>
<span class="p_add">+	/* None of the current callers actually pass write=1 together with</span>
<span class="p_add">+	 * force=1, but pass in current_cred() and current_read_cred() in case</span>
<span class="p_add">+	 * that changes in the future.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	return __get_user_pages_unlocked(current, current-&gt;mm, current_cred(),</span>
<span class="p_add">+					 current_real_cred(), start, nr_pages,</span>
 					 write, force, pages, FOLL_TOUCH);
 }
 EXPORT_SYMBOL(get_user_pages_unlocked);
<span class="p_chunk">@@ -959,12 +996,15 @@</span> <span class="p_context"> EXPORT_SYMBOL(get_user_pages_unlocked);</span>
  * FAULT_FLAG_ALLOW_RETRY to handle_mm_fault.
  */
 long get_user_pages_remote(struct task_struct *tsk, struct mm_struct *mm,
<span class="p_add">+		const struct cred *subject_cred,</span>
<span class="p_add">+		const struct cred *object_cred,</span>
 		unsigned long start, unsigned long nr_pages,
 		int write, int force, struct page **pages,
 		struct vm_area_struct **vmas)
 {
<span class="p_del">-	return __get_user_pages_locked(tsk, mm, start, nr_pages, write, force,</span>
<span class="p_del">-				       pages, vmas, NULL, false,</span>
<span class="p_add">+	return __get_user_pages_locked(tsk, mm, subject_cred, object_cred,</span>
<span class="p_add">+				       start, nr_pages, write, force, pages,</span>
<span class="p_add">+				       vmas, NULL, false,</span>
 				       FOLL_TOUCH | FOLL_REMOTE);
 }
 EXPORT_SYMBOL(get_user_pages_remote);
<span class="p_chunk">@@ -979,9 +1019,10 @@</span> <span class="p_context"> long get_user_pages(unsigned long start, unsigned long nr_pages,</span>
 		int write, int force, struct page **pages,
 		struct vm_area_struct **vmas)
 {
<span class="p_del">-	return __get_user_pages_locked(current, current-&gt;mm, start, nr_pages,</span>
<span class="p_del">-				       write, force, pages, vmas, NULL, false,</span>
<span class="p_del">-				       FOLL_TOUCH);</span>
<span class="p_add">+	return __get_user_pages_locked(current, current-&gt;mm, current_cred(),</span>
<span class="p_add">+				       current_real_cred(), start,</span>
<span class="p_add">+				       nr_pages, write, force, pages, vmas,</span>
<span class="p_add">+				       NULL, false, FOLL_TOUCH);</span>
 }
 EXPORT_SYMBOL(get_user_pages);
 
<span class="p_chunk">@@ -1039,7 +1080,8 @@</span> <span class="p_context"> long populate_vma_page_range(struct vm_area_struct *vma,</span>
 	 * We made sure addr is within a VMA, so the following will
 	 * not result in a stack expansion that recurses back here.
 	 */
<span class="p_del">-	return __get_user_pages(current, mm, start, nr_pages, gup_flags,</span>
<span class="p_add">+	return __get_user_pages(current, mm, current_cred(),</span>
<span class="p_add">+				current_real_cred(), start, nr_pages, gup_flags,</span>
 				NULL, NULL, nonblocking);
 }
 
<span class="p_chunk">@@ -1125,7 +1167,7 @@</span> <span class="p_context"> struct page *get_dump_page(unsigned long addr)</span>
 	struct vm_area_struct *vma;
 	struct page *page;
 
<span class="p_del">-	if (__get_user_pages(current, current-&gt;mm, addr, 1,</span>
<span class="p_add">+	if (__get_user_pages(current, current-&gt;mm, NULL, NULL, addr, 1,</span>
 			     FOLL_FORCE | FOLL_DUMP | FOLL_GET, &amp;page, &amp;vma,
 			     NULL) &lt; 1)
 		return NULL;
<span class="p_header">diff --git a/mm/memory.c b/mm/memory.c</span>
<span class="p_header">index 83be99d..8209d4f 100644</span>
<span class="p_header">--- a/mm/memory.c</span>
<span class="p_header">+++ b/mm/memory.c</span>
<span class="p_chunk">@@ -3850,6 +3850,7 @@</span> <span class="p_context"> EXPORT_SYMBOL_GPL(generic_access_phys);</span>
  * given task for page fault accounting.
  */
 static int __access_remote_vm(struct task_struct *tsk, struct mm_struct *mm,
<span class="p_add">+		const struct cred *subject_cred, const struct cred *object_cred,</span>
 		unsigned long addr, void *buf, int len, int write)
 {
 	struct vm_area_struct *vma;
<span class="p_chunk">@@ -3862,8 +3863,8 @@</span> <span class="p_context"> static int __access_remote_vm(struct task_struct *tsk, struct mm_struct *mm,</span>
 		void *maddr;
 		struct page *page = NULL;
 
<span class="p_del">-		ret = get_user_pages_remote(tsk, mm, addr, 1,</span>
<span class="p_del">-				write, 1, &amp;page, &amp;vma);</span>
<span class="p_add">+		ret = get_user_pages_remote(tsk, mm, subject_cred, object_cred,</span>
<span class="p_add">+				addr, 1, write, 1, &amp;page, &amp;vma);</span>
 		if (ret &lt;= 0) {
 #ifndef CONFIG_HAVE_IOREMAP_PROT
 			break;
<span class="p_chunk">@@ -3919,28 +3920,35 @@</span> <span class="p_context"> static int __access_remote_vm(struct task_struct *tsk, struct mm_struct *mm,</span>
  *
  * The caller must hold a reference on @mm.
  */
<span class="p_del">-int access_remote_vm(struct mm_struct *mm, unsigned long addr,</span>
<span class="p_del">-		void *buf, int len, int write)</span>
<span class="p_add">+int access_remote_vm(struct mm_struct *mm, const struct cred *subject_cred,</span>
<span class="p_add">+		     const struct cred *object_cred, unsigned long addr,</span>
<span class="p_add">+		     void *buf, int len, int write)</span>
 {
<span class="p_del">-	return __access_remote_vm(NULL, mm, addr, buf, len, write);</span>
<span class="p_add">+	return __access_remote_vm(NULL, mm, subject_cred, object_cred, addr,</span>
<span class="p_add">+				  buf, len, write);</span>
 }
 
 /*
  * Access another process&#39; address space.
  * Source/target buffer must be kernel space,
<span class="p_del">- * Do not walk the page table directly, use get_user_pages</span>
<span class="p_add">+ * Do not walk the page table directly, use get_user_pages.</span>
<span class="p_add">+ * @tsk must be ptrace-stopped by current.</span>
  */
 int access_process_vm(struct task_struct *tsk, unsigned long addr,
 		void *buf, int len, int write)
 {
 	struct mm_struct *mm;
 	int ret;
<span class="p_add">+	const struct cred *object_cred;</span>
 
 	mm = get_task_mm(tsk);
 	if (!mm)
 		return 0;
<span class="p_add">+	object_cred = get_task_cred(tsk);</span>
 
<span class="p_del">-	ret = __access_remote_vm(tsk, mm, addr, buf, len, write);</span>
<span class="p_add">+	ret = __access_remote_vm(tsk, mm, current_cred(), object_cred, addr,</span>
<span class="p_add">+				 buf, len, write);</span>
<span class="p_add">+	put_cred(object_cred);</span>
 	mmput(mm);
 
 	return ret;
<span class="p_header">diff --git a/mm/nommu.c b/mm/nommu.c</span>
<span class="p_header">index 95daf81..ebb03ba 100644</span>
<span class="p_header">--- a/mm/nommu.c</span>
<span class="p_header">+++ b/mm/nommu.c</span>
<span class="p_chunk">@@ -110,6 +110,8 @@</span> <span class="p_context"> unsigned int kobjsize(const void *objp)</span>
 }
 
 long __get_user_pages(struct task_struct *tsk, struct mm_struct *mm,
<span class="p_add">+		      const struct cred *subject_cred,</span>
<span class="p_add">+		      const struct cred *object_cred,</span>
 		      unsigned long start, unsigned long nr_pages,
 		      unsigned int foll_flags, struct page **pages,
 		      struct vm_area_struct **vmas, int *nonblocking)
<span class="p_chunk">@@ -170,8 +172,8 @@</span> <span class="p_context"> long get_user_pages(unsigned long start, unsigned long nr_pages,</span>
 	if (force)
 		flags |= FOLL_FORCE;
 
<span class="p_del">-	return __get_user_pages(current, current-&gt;mm, start, nr_pages, flags,</span>
<span class="p_del">-				pages, vmas, NULL);</span>
<span class="p_add">+	return __get_user_pages(current, current-&gt;mm, NULL, NULL, start,</span>
<span class="p_add">+				nr_pages, flags, pages, vmas, NULL);</span>
 }
 EXPORT_SYMBOL(get_user_pages);
 
<span class="p_chunk">@@ -184,14 +186,16 @@</span> <span class="p_context"> long get_user_pages_locked(unsigned long start, unsigned long nr_pages,</span>
 EXPORT_SYMBOL(get_user_pages_locked);
 
 long __get_user_pages_unlocked(struct task_struct *tsk, struct mm_struct *mm,
<span class="p_add">+			       const struct cred *subject_cred,</span>
<span class="p_add">+			       const struct cred *object_cred,</span>
 			       unsigned long start, unsigned long nr_pages,
 			       int write, int force, struct page **pages,
 			       unsigned int gup_flags)
 {
 	long ret;
 	down_read(&amp;mm-&gt;mmap_sem);
<span class="p_del">-	ret = __get_user_pages(tsk, mm, start, nr_pages, gup_flags, pages,</span>
<span class="p_del">-				NULL, NULL);</span>
<span class="p_add">+	ret = __get_user_pages(tsk, mm, subject_cred, object_cred, start,</span>
<span class="p_add">+				nr_pages, gup_flags, pages, NULL, NULL);</span>
 	up_read(&amp;mm-&gt;mmap_sem);
 	return ret;
 }
<span class="p_chunk">@@ -200,8 +204,9 @@</span> <span class="p_context"> EXPORT_SYMBOL(__get_user_pages_unlocked);</span>
 long get_user_pages_unlocked(unsigned long start, unsigned long nr_pages,
 			     int write, int force, struct page **pages)
 {
<span class="p_del">-	return __get_user_pages_unlocked(current, current-&gt;mm, start, nr_pages,</span>
<span class="p_del">-					 write, force, pages, 0);</span>
<span class="p_add">+	return __get_user_pages_unlocked(current, current-&gt;mm, NULL, NULL,</span>
<span class="p_add">+					 start, nr_pages, write, force, pages,</span>
<span class="p_add">+					 0);</span>
 }
 EXPORT_SYMBOL(get_user_pages_unlocked);
 
<span class="p_chunk">@@ -1858,8 +1863,9 @@</span> <span class="p_context"> static int __access_remote_vm(struct task_struct *tsk, struct mm_struct *mm,</span>
  *
  * The caller must hold a reference on @mm.
  */
<span class="p_del">-int access_remote_vm(struct mm_struct *mm, unsigned long addr,</span>
<span class="p_del">-		void *buf, int len, int write)</span>
<span class="p_add">+int access_remote_vm(struct mm_struct *mm, const struct cred *subject_cred,</span>
<span class="p_add">+		const struct cred *object_cred, unsigned long addr, void *buf,</span>
<span class="p_add">+		int len, int write)</span>
 {
 	return __access_remote_vm(NULL, mm, addr, buf, len, write);
 }
<span class="p_header">diff --git a/mm/process_vm_access.c b/mm/process_vm_access.c</span>
<span class="p_header">index 07514d4..9f2b6a1 100644</span>
<span class="p_header">--- a/mm/process_vm_access.c</span>
<span class="p_header">+++ b/mm/process_vm_access.c</span>
<span class="p_chunk">@@ -103,9 +103,9 @@</span> <span class="p_context"> static int process_vm_rw_single_vec(unsigned long addr,</span>
 		 * add FOLL_REMOTE because task/mm might not
 		 * current/current-&gt;mm
 		 */
<span class="p_del">-		pages = __get_user_pages_unlocked(task, mm, pa, pages,</span>
<span class="p_del">-						  vm_write, 0, process_pages,</span>
<span class="p_del">-						  FOLL_REMOTE);</span>
<span class="p_add">+		pages = __get_user_pages_unlocked(task, mm, NULL, NULL, pa,</span>
<span class="p_add">+						  pages, vm_write, 0,</span>
<span class="p_add">+						  process_pages, FOLL_REMOTE);</span>
 		if (pages &lt;= 0)
 			return -EFAULT;
 
<span class="p_chunk">@@ -199,7 +199,7 @@</span> <span class="p_context"> static ssize_t process_vm_rw_core(pid_t pid, struct iov_iter *iter,</span>
 		goto free_proc_pages;
 	}
 
<span class="p_del">-	mm = mm_access(task, PTRACE_MODE_ATTACH_REALCREDS);</span>
<span class="p_add">+	mm = mm_access(task, NULL, PTRACE_MODE_ATTACH_REALCREDS);</span>
 	if (!mm || IS_ERR(mm)) {
 		rc = IS_ERR(mm) ? PTR_ERR(mm) : -ESRCH;
 		/*
<span class="p_header">diff --git a/security/security.c b/security/security.c</span>
<span class="p_header">index 4838e7f..0c16a6c 100644</span>
<span class="p_header">--- a/security/security.c</span>
<span class="p_header">+++ b/security/security.c</span>
<span class="p_chunk">@@ -164,6 +164,13 @@</span> <span class="p_context"> int security_ptrace_traceme(struct task_struct *parent)</span>
 	return call_int_hook(ptrace_traceme, 0, parent);
 }
 
<span class="p_add">+int security_forced_write(struct vm_area_struct *vma,</span>
<span class="p_add">+			  const struct cred *subject_cred,</span>
<span class="p_add">+			  const struct cred *object_cred)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return call_int_hook(forced_write, 0, vma, subject_cred, object_cred);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 int security_capget(struct task_struct *target,
 		     kernel_cap_t *effective,
 		     kernel_cap_t *inheritable,
<span class="p_chunk">@@ -1582,6 +1589,7 @@</span> <span class="p_context"> struct security_hook_heads security_hook_heads = {</span>
 		LIST_HEAD_INIT(security_hook_heads.ptrace_access_check),
 	.ptrace_traceme =
 		LIST_HEAD_INIT(security_hook_heads.ptrace_traceme),
<span class="p_add">+	.forced_write =	LIST_HEAD_INIT(security_hook_heads.forced_write),</span>
 	.capget =	LIST_HEAD_INIT(security_hook_heads.capget),
 	.capset =	LIST_HEAD_INIT(security_hook_heads.capset),
 	.capable =	LIST_HEAD_INIT(security_hook_heads.capable),
<span class="p_header">diff --git a/security/tomoyo/domain.c b/security/tomoyo/domain.c</span>
<span class="p_header">index ade7c6c..f5acc47 100644</span>
<span class="p_header">--- a/security/tomoyo/domain.c</span>
<span class="p_header">+++ b/security/tomoyo/domain.c</span>
<span class="p_chunk">@@ -880,7 +880,7 @@</span> <span class="p_context"> bool tomoyo_dump_page(struct linux_binprm *bprm, unsigned long pos,</span>
 	 * (represented by bprm).  &#39;current&#39; is the process doing
 	 * the execve().
 	 */
<span class="p_del">-	if (get_user_pages_remote(current, bprm-&gt;mm, pos, 1,</span>
<span class="p_add">+	if (get_user_pages_remote(current, bprm-&gt;mm, NULL, NULL, pos, 1,</span>
 				0, 1, &amp;page, NULL) &lt;= 0)
 		return false;
 #else
<span class="p_header">diff --git a/virt/kvm/async_pf.c b/virt/kvm/async_pf.c</span>
<span class="p_header">index db96688..e49acb7 100644</span>
<span class="p_header">--- a/virt/kvm/async_pf.c</span>
<span class="p_header">+++ b/virt/kvm/async_pf.c</span>
<span class="p_chunk">@@ -84,7 +84,8 @@</span> <span class="p_context"> static void async_pf_execute(struct work_struct *work)</span>
 	 * mm and might be done in another context, so we must
 	 * use FOLL_REMOTE.
 	 */
<span class="p_del">-	__get_user_pages_unlocked(NULL, mm, addr, 1, 1, 0, NULL, FOLL_REMOTE);</span>
<span class="p_add">+	__get_user_pages_unlocked(NULL, mm, NULL, NULL, addr, 1, 1, 0, NULL,</span>
<span class="p_add">+				  FOLL_REMOTE);</span>
 
 	kvm_async_page_present_sync(vcpu, apf);
 
<span class="p_header">diff --git a/virt/kvm/kvm_main.c b/virt/kvm/kvm_main.c</span>
<span class="p_header">index 1950782..5bedffe 100644</span>
<span class="p_header">--- a/virt/kvm/kvm_main.c</span>
<span class="p_header">+++ b/virt/kvm/kvm_main.c</span>
<span class="p_chunk">@@ -1349,15 +1349,15 @@</span> <span class="p_context"> static int get_user_page_nowait(unsigned long start, int write,</span>
 	if (write)
 		flags |= FOLL_WRITE;
 
<span class="p_del">-	return __get_user_pages(current, current-&gt;mm, start, 1, flags, page,</span>
<span class="p_del">-			NULL, NULL);</span>
<span class="p_add">+	return __get_user_pages(current, current-&gt;mm, NULL, NULL, start, 1,</span>
<span class="p_add">+			flags, page, NULL, NULL);</span>
 }
 
 static inline int check_user_page_hwpoison(unsigned long addr)
 {
 	int rc, flags = FOLL_TOUCH | FOLL_HWPOISON | FOLL_WRITE;
 
<span class="p_del">-	rc = __get_user_pages(current, current-&gt;mm, addr, 1,</span>
<span class="p_add">+	rc = __get_user_pages(current, current-&gt;mm, NULL, NULL, addr, 1,</span>
 			      flags, NULL, NULL, NULL);
 	return rc == -EHWPOISON;
 }
<span class="p_chunk">@@ -1415,7 +1415,8 @@</span> <span class="p_context"> static int hva_to_pfn_slow(unsigned long addr, bool *async, bool write_fault,</span>
 		npages = get_user_page_nowait(addr, write_fault, page);
 		up_read(&amp;current-&gt;mm-&gt;mmap_sem);
 	} else
<span class="p_del">-		npages = __get_user_pages_unlocked(current, current-&gt;mm, addr, 1,</span>
<span class="p_add">+		npages = __get_user_pages_unlocked(current, current-&gt;mm, NULL,</span>
<span class="p_add">+						   NULL, addr, 1,</span>
 						   write_fault, 0, page,
 						   FOLL_TOUCH|FOLL_HWPOISON);
 	if (npages != 1)

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



