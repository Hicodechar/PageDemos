
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>arm64: mm: take CWG into account in __inval_cache_range() - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    arm64: mm: take CWG into account in __inval_cache_range()</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=352">Catalin Marinas</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>April 19, 2016, 2:13 p.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;20160419141321.GD8482@e104818-lin.cambridge.arm.com&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/8880501/mbox/"
   >mbox</a>
|
   <a href="/patch/8880501/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/8880501/">/patch/8880501/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
X-Original-To: patchwork-LKML@patchwork.kernel.org
Delivered-To: patchwork-parsemail@patchwork2.web.kernel.org
Received: from mail.kernel.org (mail.kernel.org [198.145.29.136])
	by patchwork2.web.kernel.org (Postfix) with ESMTP id 7E81BBF29F
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Tue, 19 Apr 2016 14:13:52 +0000 (UTC)
Received: from mail.kernel.org (localhost [127.0.0.1])
	by mail.kernel.org (Postfix) with ESMTP id AAFFF202BE
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Tue, 19 Apr 2016 14:13:51 +0000 (UTC)
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.kernel.org (Postfix) with ESMTP id 47BDB2027D
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Tue, 19 Apr 2016 14:13:50 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1754728AbcDSONb (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Tue, 19 Apr 2016 10:13:31 -0400
Received: from foss.arm.com ([217.140.101.70]:40252 &quot;EHLO foss.arm.com&quot;
	rhost-flags-OK-OK-OK-OK) by vger.kernel.org with ESMTP
	id S1754030AbcDSON0 (ORCPT &lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Tue, 19 Apr 2016 10:13:26 -0400
Received: from usa-sjc-imap-foss1.foss.arm.com (unknown [10.72.51.249])
	by usa-sjc-mx-foss1.foss.arm.com (Postfix) with ESMTP id 4CCFE28;
	Tue, 19 Apr 2016 07:12:09 -0700 (PDT)
Received: from e104818-lin.cambridge.arm.com (e104818-lin.cambridge.arm.com
	[10.1.203.148])
	by usa-sjc-imap-foss1.foss.arm.com (Postfix) with ESMTPSA id
	62FDB3F215; Tue, 19 Apr 2016 07:13:24 -0700 (PDT)
Date: Tue, 19 Apr 2016 15:13:21 +0100
From: Catalin Marinas &lt;catalin.marinas@arm.com&gt;
To: Ard Biesheuvel &lt;ard.biesheuvel@linaro.org&gt;
Cc: Mark Rutland &lt;mark.rutland@arm.com&gt;, Will Deacon &lt;will.deacon@arm.com&gt;,
	&quot;linux-kernel@vger.kernel.org&quot; &lt;linux-kernel@vger.kernel.org&gt;,
	James Morse &lt;james.morse@arm.com&gt;, robin.murphy@arm.com,
	&quot;linux-arm-kernel@lists.infradead.org&quot; 
	&lt;linux-arm-kernel@lists.infradead.org&gt;
Subject: Re: [PATCH] arm64: mm: take CWG into account in
	__inval_cache_range()
Message-ID: &lt;20160419141321.GD8482@e104818-lin.cambridge.arm.com&gt;
References: &lt;1461061773-19571-1-git-send-email-ard.biesheuvel@linaro.org&gt;
	&lt;20160419125615.GA20991@leverpostej&gt;
	&lt;CAKv+Gu91hFkn5k0s=xVmJ+z0vEYMNe6h6UD6z9Qb0fxe7ba0Vw@mail.gmail.com&gt;
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Disposition: inline
In-Reply-To: &lt;CAKv+Gu91hFkn5k0s=xVmJ+z0vEYMNe6h6UD6z9Qb0fxe7ba0Vw@mail.gmail.com&gt;
User-Agent: Mutt/1.5.23 (2014-03-12)
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Spam-Status: No, score=-7.9 required=5.0 tests=BAYES_00, RCVD_IN_DNSWL_HI, 
	RP_MATCHES_RCVD,
	UNPARSEABLE_RELAY autolearn=unavailable version=3.3.1
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on mail.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=352">Catalin Marinas</a> - April 19, 2016, 2:13 p.m.</div>
<pre class="content">
On Tue, Apr 19, 2016 at 03:08:27PM +0200, Ard Biesheuvel wrote:
<span class="quote">&gt; On 19 April 2016 at 14:56, Mark Rutland &lt;mark.rutland@arm.com&gt; wrote:</span>
<span class="quote">&gt; &gt; Is sharing a CWG broken by design, or is there some caveat I&#39;m missing</span>
<span class="quote">&gt; &gt; that prevents/prohibits unrelated data from being dirtied?</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; I think sharing a CWG window is broken by design, now that I think of</span>
<span class="quote">&gt; it. The invalidate is part of the dma_unmap() code path, which means</span>
<span class="quote">&gt; the cleaning we do on the edges of the buffer may clobber data in</span>
<span class="quote">&gt; memory written by the device, and not cleaning isn&#39;t an option either.</span>

Indeed. It only works if the cache line is always clean (e.g. read or
speculatively loaded) but you can&#39;t guarantee what&#39;s accessing it. I
think we shouldn&#39;t even bother with the edges at all in __dma_inv_range.

The best we could do is to warn if ARCH_DMA_MINALIGN is smaller than CWG
(as Robin suggested, we could do this only if we have non-coherent DMA
masters via arch_setup_dma_ops()). Quick hack below:

-------------------------------8&lt;-----------------------------------
-------------------------------8&lt;-----------------------------------

This way we could also reduce L1_CACHE_SHIFT back to 6 as it shouldn&#39;t
cause any correctness issues (potentially performance but so far it
seems that increasing it made things worse on some SoCs).

The reason for cache_line_size() using ARCH_DMA_MINALIGN instead of
L1_CACHE_BYTES is that I can see it used in the sl*b code when
SLAB_HWCACHE_ALIGN is passed and on few occasions for DMA buffers.
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=66681">Ard Biesheuvel</a> - April 19, 2016, 2:48 p.m.</div>
<pre class="content">
On 19 April 2016 at 16:13, Catalin Marinas &lt;catalin.marinas@arm.com&gt; wrote:
<span class="quote">&gt; On Tue, Apr 19, 2016 at 03:08:27PM +0200, Ard Biesheuvel wrote:</span>
<span class="quote">&gt;&gt; On 19 April 2016 at 14:56, Mark Rutland &lt;mark.rutland@arm.com&gt; wrote:</span>
<span class="quote">&gt;&gt; &gt; Is sharing a CWG broken by design, or is there some caveat I&#39;m missing</span>
<span class="quote">&gt;&gt; &gt; that prevents/prohibits unrelated data from being dirtied?</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; I think sharing a CWG window is broken by design, now that I think of</span>
<span class="quote">&gt;&gt; it. The invalidate is part of the dma_unmap() code path, which means</span>
<span class="quote">&gt;&gt; the cleaning we do on the edges of the buffer may clobber data in</span>
<span class="quote">&gt;&gt; memory written by the device, and not cleaning isn&#39;t an option either.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; Indeed. It only works if the cache line is always clean (e.g. read or</span>
<span class="quote">&gt; speculatively loaded) but you can&#39;t guarantee what&#39;s accessing it. I</span>
<span class="quote">&gt; think we shouldn&#39;t even bother with the edges at all in __dma_inv_range.</span>
<span class="quote">&gt;</span>

Agreed.
<span class="quote">
&gt; The best we could do is to warn if ARCH_DMA_MINALIGN is smaller than CWG</span>
<span class="quote">&gt; (as Robin suggested, we could do this only if we have non-coherent DMA</span>
<span class="quote">&gt; masters via arch_setup_dma_ops()). Quick hack below:</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; -------------------------------8&lt;-----------------------------------</span>
<span class="quote">&gt; diff --git a/arch/arm64/include/asm/cache.h b/arch/arm64/include/asm/cache.h</span>
<span class="quote">&gt; index 5082b30bc2c0..5967fcbb617a 100644</span>
<span class="quote">&gt; --- a/arch/arm64/include/asm/cache.h</span>
<span class="quote">&gt; +++ b/arch/arm64/include/asm/cache.h</span>
<span class="quote">&gt; @@ -28,7 +28,7 @@</span>
<span class="quote">&gt;   * cache before the transfer is done, causing old data to be seen by</span>
<span class="quote">&gt;   * the CPU.</span>
<span class="quote">&gt;   */</span>
<span class="quote">&gt; -#define ARCH_DMA_MINALIGN      L1_CACHE_BYTES</span>
<span class="quote">&gt; +#define ARCH_DMA_MINALIGN      128</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;  #ifndef __ASSEMBLY__</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; @@ -37,7 +37,7 @@</span>
<span class="quote">&gt;  static inline int cache_line_size(void)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;         u32 cwg = cache_type_cwg();</span>
<span class="quote">&gt; -       return cwg ? 4 &lt;&lt; cwg : L1_CACHE_BYTES;</span>
<span class="quote">&gt; +       return cwg ? 4 &lt;&lt; cwg : ARCH_DMA_MINALIGN;</span>

Unrelated, but this does not look right: if the CWG field is zero, we
should either assume 2 KB, or iterate over all the CCSIDR values and
take the maximum linesize.
<span class="quote">
&gt;  }</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;  #endif /* __ASSEMBLY__ */</span>
<span class="quote">&gt; diff --git a/arch/arm64/kernel/cpufeature.c b/arch/arm64/kernel/cpufeature.c</span>
<span class="quote">&gt; index 943f5140e0f3..b1d4d1f5b0dd 100644</span>
<span class="quote">&gt; --- a/arch/arm64/kernel/cpufeature.c</span>
<span class="quote">&gt; +++ b/arch/arm64/kernel/cpufeature.c</span>
<span class="quote">&gt; @@ -970,7 +970,6 @@ static void __init setup_feature_capabilities(void)</span>
<span class="quote">&gt;  void __init setup_cpu_features(void)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;         u32 cwg;</span>
<span class="quote">&gt; -       int cls;</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;         /* Set the CPU feature capabilies */</span>
<span class="quote">&gt;         setup_feature_capabilities();</span>
<span class="quote">&gt; @@ -983,13 +982,9 @@ void __init setup_cpu_features(void)</span>
<span class="quote">&gt;          * Check for sane CTR_EL0.CWG value.</span>
<span class="quote">&gt;          */</span>
<span class="quote">&gt;         cwg = cache_type_cwg();</span>
<span class="quote">&gt; -       cls = cache_line_size();</span>
<span class="quote">&gt;         if (!cwg)</span>
<span class="quote">&gt; -               pr_warn(&quot;No Cache Writeback Granule information, assuming cache line size %d\n&quot;,</span>
<span class="quote">&gt; -                       cls);</span>
<span class="quote">&gt; -       if (L1_CACHE_BYTES &lt; cls)</span>
<span class="quote">&gt; -               pr_warn(&quot;L1_CACHE_BYTES smaller than the Cache Writeback Granule (%d &lt; %d)\n&quot;,</span>
<span class="quote">&gt; -                       L1_CACHE_BYTES, cls);</span>
<span class="quote">&gt; +               pr_warn(&quot;No Cache Writeback Granule information, assuming %d\n&quot;,</span>
<span class="quote">&gt; +                       ARCH_DMA_MINALIGN);</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;  static bool __maybe_unused</span>
<span class="quote">&gt; diff --git a/arch/arm64/mm/dma-mapping.c b/arch/arm64/mm/dma-mapping.c</span>
<span class="quote">&gt; index a6e757cbab77..08232faf38ad 100644</span>
<span class="quote">&gt; --- a/arch/arm64/mm/dma-mapping.c</span>
<span class="quote">&gt; +++ b/arch/arm64/mm/dma-mapping.c</span>
<span class="quote">&gt; @@ -987,6 +987,11 @@ static void __iommu_setup_dma_ops(struct device *dev, u64 dma_base, u64 size,</span>
<span class="quote">&gt;  void arch_setup_dma_ops(struct device *dev, u64 dma_base, u64 size,</span>
<span class="quote">&gt;                         struct iommu_ops *iommu, bool coherent)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt; +       WARN_TAINT_ONCE(!coherent &amp;&amp; ARCH_DMA_MINALIGN &lt; cache_line_size(),</span>
<span class="quote">&gt; +                       TAINT_CPU_OUT_OF_SPEC,</span>
<span class="quote">&gt; +                       &quot;ARCH_DMA_MINALIGN smaller than the Cache Writeback Granule (%d &lt; %d)&quot;,</span>
<span class="quote">&gt; +                       ARCH_DMA_MINALIGN, cache_line_size());</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt;         if (!dev-&gt;archdata.dma_ops)</span>
<span class="quote">&gt;                 dev-&gt;archdata.dma_ops = &amp;swiotlb_dma_ops;</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; -------------------------------8&lt;-----------------------------------</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; This way we could also reduce L1_CACHE_SHIFT back to 6 as it shouldn&#39;t</span>
<span class="quote">&gt; cause any correctness issues (potentially performance but so far it</span>
<span class="quote">&gt; seems that increasing it made things worse on some SoCs).</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; The reason for cache_line_size() using ARCH_DMA_MINALIGN instead of</span>
<span class="quote">&gt; L1_CACHE_BYTES is that I can see it used in the sl*b code when</span>
<span class="quote">&gt; SLAB_HWCACHE_ALIGN is passed and on few occasions for DMA buffers.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; --</span>
<span class="quote">&gt; Catalin</span>
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=352">Catalin Marinas</a> - April 19, 2016, 3:32 p.m.</div>
<pre class="content">
On Tue, Apr 19, 2016 at 04:48:32PM +0200, Ard Biesheuvel wrote:
<span class="quote">&gt; On 19 April 2016 at 16:13, Catalin Marinas &lt;catalin.marinas@arm.com&gt; wrote:</span>
<span class="quote">&gt; &gt; The best we could do is to warn if ARCH_DMA_MINALIGN is smaller than CWG</span>
<span class="quote">&gt; &gt; (as Robin suggested, we could do this only if we have non-coherent DMA</span>
<span class="quote">&gt; &gt; masters via arch_setup_dma_ops()). Quick hack below:</span>
<span class="quote">&gt; &gt;</span>
<span class="quote">&gt; &gt; -------------------------------8&lt;-----------------------------------</span>
<span class="quote">&gt; &gt; diff --git a/arch/arm64/include/asm/cache.h b/arch/arm64/include/asm/cache.h</span>
<span class="quote">&gt; &gt; index 5082b30bc2c0..5967fcbb617a 100644</span>
<span class="quote">&gt; &gt; --- a/arch/arm64/include/asm/cache.h</span>
<span class="quote">&gt; &gt; +++ b/arch/arm64/include/asm/cache.h</span>
<span class="quote">&gt; &gt; @@ -28,7 +28,7 @@</span>
<span class="quote">&gt; &gt;   * cache before the transfer is done, causing old data to be seen by</span>
<span class="quote">&gt; &gt;   * the CPU.</span>
<span class="quote">&gt; &gt;   */</span>
<span class="quote">&gt; &gt; -#define ARCH_DMA_MINALIGN      L1_CACHE_BYTES</span>
<span class="quote">&gt; &gt; +#define ARCH_DMA_MINALIGN      128</span>
<span class="quote">&gt; &gt;</span>
<span class="quote">&gt; &gt;  #ifndef __ASSEMBLY__</span>
<span class="quote">&gt; &gt;</span>
<span class="quote">&gt; &gt; @@ -37,7 +37,7 @@</span>
<span class="quote">&gt; &gt;  static inline int cache_line_size(void)</span>
<span class="quote">&gt; &gt;  {</span>
<span class="quote">&gt; &gt;         u32 cwg = cache_type_cwg();</span>
<span class="quote">&gt; &gt; -       return cwg ? 4 &lt;&lt; cwg : L1_CACHE_BYTES;</span>
<span class="quote">&gt; &gt; +       return cwg ? 4 &lt;&lt; cwg : ARCH_DMA_MINALIGN;</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Unrelated, but this does not look right: if the CWG field is zero, we</span>
<span class="quote">&gt; should either assume 2 KB, or iterate over all the CCSIDR values and</span>
<span class="quote">&gt; take the maximum linesize.</span>

It may be a better guess but even that is not always relevant since
CCSIDR may not present the real hardware information. It&#39;s only meant to
give enough information to be able to do cache maintenance by set/way
and we&#39;ve seen CPU implementations where this has nothing to do with the
actual cache geometry.

So I don&#39;t think we can do anything more than just hard-coding and hope
that implementations where CWG is 0 (or higher than 128) are only
deployed in a fully coherent configuration.
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=66681">Ard Biesheuvel</a> - April 19, 2016, 3:38 p.m.</div>
<pre class="content">
On 19 April 2016 at 17:32, Catalin Marinas &lt;catalin.marinas@arm.com&gt; wrote:
<span class="quote">&gt; On Tue, Apr 19, 2016 at 04:48:32PM +0200, Ard Biesheuvel wrote:</span>
<span class="quote">&gt;&gt; On 19 April 2016 at 16:13, Catalin Marinas &lt;catalin.marinas@arm.com&gt; wrote:</span>
<span class="quote">&gt;&gt; &gt; The best we could do is to warn if ARCH_DMA_MINALIGN is smaller than CWG</span>
<span class="quote">&gt;&gt; &gt; (as Robin suggested, we could do this only if we have non-coherent DMA</span>
<span class="quote">&gt;&gt; &gt; masters via arch_setup_dma_ops()). Quick hack below:</span>
<span class="quote">&gt;&gt; &gt;</span>
<span class="quote">&gt;&gt; &gt; -------------------------------8&lt;-----------------------------------</span>
<span class="quote">&gt;&gt; &gt; diff --git a/arch/arm64/include/asm/cache.h b/arch/arm64/include/asm/cache.h</span>
<span class="quote">&gt;&gt; &gt; index 5082b30bc2c0..5967fcbb617a 100644</span>
<span class="quote">&gt;&gt; &gt; --- a/arch/arm64/include/asm/cache.h</span>
<span class="quote">&gt;&gt; &gt; +++ b/arch/arm64/include/asm/cache.h</span>
<span class="quote">&gt;&gt; &gt; @@ -28,7 +28,7 @@</span>
<span class="quote">&gt;&gt; &gt;   * cache before the transfer is done, causing old data to be seen by</span>
<span class="quote">&gt;&gt; &gt;   * the CPU.</span>
<span class="quote">&gt;&gt; &gt;   */</span>
<span class="quote">&gt;&gt; &gt; -#define ARCH_DMA_MINALIGN      L1_CACHE_BYTES</span>
<span class="quote">&gt;&gt; &gt; +#define ARCH_DMA_MINALIGN      128</span>
<span class="quote">&gt;&gt; &gt;</span>
<span class="quote">&gt;&gt; &gt;  #ifndef __ASSEMBLY__</span>
<span class="quote">&gt;&gt; &gt;</span>
<span class="quote">&gt;&gt; &gt; @@ -37,7 +37,7 @@</span>
<span class="quote">&gt;&gt; &gt;  static inline int cache_line_size(void)</span>
<span class="quote">&gt;&gt; &gt;  {</span>
<span class="quote">&gt;&gt; &gt;         u32 cwg = cache_type_cwg();</span>
<span class="quote">&gt;&gt; &gt; -       return cwg ? 4 &lt;&lt; cwg : L1_CACHE_BYTES;</span>
<span class="quote">&gt;&gt; &gt; +       return cwg ? 4 &lt;&lt; cwg : ARCH_DMA_MINALIGN;</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; Unrelated, but this does not look right: if the CWG field is zero, we</span>
<span class="quote">&gt;&gt; should either assume 2 KB, or iterate over all the CCSIDR values and</span>
<span class="quote">&gt;&gt; take the maximum linesize.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; It may be a better guess but even that is not always relevant since</span>
<span class="quote">&gt; CCSIDR may not present the real hardware information. It&#39;s only meant to</span>
<span class="quote">&gt; give enough information to be able to do cache maintenance by set/way</span>
<span class="quote">&gt; and we&#39;ve seen CPU implementations where this has nothing to do with the</span>
<span class="quote">&gt; actual cache geometry.</span>
<span class="quote">&gt;</span>

I am aware of that discussion, but that was about inferring aliasing
properties from the way size, which combines the linesize and the
number of sets/ways, and the latter are apparently set to 1/1 in some
cases so that any set/way operation simply affects the entire cache.

However, the CCSIDR linesize field itself is mentioned in the
description of CWG in the ARM ARM, as a suitable source of obtaining
the maximum linesize in the system.
<span class="quote">
&gt; So I don&#39;t think we can do anything more than just hard-coding and hope</span>
<span class="quote">&gt; that implementations where CWG is 0 (or higher than 128) are only</span>
<span class="quote">&gt; deployed in a fully coherent configuration.</span>
<span class="quote">&gt;</span>
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=352">Catalin Marinas</a> - April 19, 2016, 4:09 p.m.</div>
<pre class="content">
On Tue, Apr 19, 2016 at 05:38:56PM +0200, Ard Biesheuvel wrote:
<span class="quote">&gt; On 19 April 2016 at 17:32, Catalin Marinas &lt;catalin.marinas@arm.com&gt; wrote:</span>
<span class="quote">&gt; &gt; On Tue, Apr 19, 2016 at 04:48:32PM +0200, Ard Biesheuvel wrote:</span>
<span class="quote">&gt; &gt;&gt; On 19 April 2016 at 16:13, Catalin Marinas &lt;catalin.marinas@arm.com&gt; wrote:</span>
<span class="quote">&gt; &gt;&gt; &gt; The best we could do is to warn if ARCH_DMA_MINALIGN is smaller than CWG</span>
<span class="quote">&gt; &gt;&gt; &gt; (as Robin suggested, we could do this only if we have non-coherent DMA</span>
<span class="quote">&gt; &gt;&gt; &gt; masters via arch_setup_dma_ops()). Quick hack below:</span>
<span class="quote">&gt; &gt;&gt; &gt;</span>
<span class="quote">&gt; &gt;&gt; &gt; -------------------------------8&lt;-----------------------------------</span>
<span class="quote">&gt; &gt;&gt; &gt; diff --git a/arch/arm64/include/asm/cache.h b/arch/arm64/include/asm/cache.h</span>
<span class="quote">&gt; &gt;&gt; &gt; index 5082b30bc2c0..5967fcbb617a 100644</span>
<span class="quote">&gt; &gt;&gt; &gt; --- a/arch/arm64/include/asm/cache.h</span>
<span class="quote">&gt; &gt;&gt; &gt; +++ b/arch/arm64/include/asm/cache.h</span>
<span class="quote">&gt; &gt;&gt; &gt; @@ -28,7 +28,7 @@</span>
<span class="quote">&gt; &gt;&gt; &gt;   * cache before the transfer is done, causing old data to be seen by</span>
<span class="quote">&gt; &gt;&gt; &gt;   * the CPU.</span>
<span class="quote">&gt; &gt;&gt; &gt;   */</span>
<span class="quote">&gt; &gt;&gt; &gt; -#define ARCH_DMA_MINALIGN      L1_CACHE_BYTES</span>
<span class="quote">&gt; &gt;&gt; &gt; +#define ARCH_DMA_MINALIGN      128</span>
<span class="quote">&gt; &gt;&gt; &gt;</span>
<span class="quote">&gt; &gt;&gt; &gt;  #ifndef __ASSEMBLY__</span>
<span class="quote">&gt; &gt;&gt; &gt;</span>
<span class="quote">&gt; &gt;&gt; &gt; @@ -37,7 +37,7 @@</span>
<span class="quote">&gt; &gt;&gt; &gt;  static inline int cache_line_size(void)</span>
<span class="quote">&gt; &gt;&gt; &gt;  {</span>
<span class="quote">&gt; &gt;&gt; &gt;         u32 cwg = cache_type_cwg();</span>
<span class="quote">&gt; &gt;&gt; &gt; -       return cwg ? 4 &lt;&lt; cwg : L1_CACHE_BYTES;</span>
<span class="quote">&gt; &gt;&gt; &gt; +       return cwg ? 4 &lt;&lt; cwg : ARCH_DMA_MINALIGN;</span>
<span class="quote">&gt; &gt;&gt;</span>
<span class="quote">&gt; &gt;&gt; Unrelated, but this does not look right: if the CWG field is zero, we</span>
<span class="quote">&gt; &gt;&gt; should either assume 2 KB, or iterate over all the CCSIDR values and</span>
<span class="quote">&gt; &gt;&gt; take the maximum linesize.</span>
<span class="quote">&gt; &gt;</span>
<span class="quote">&gt; &gt; It may be a better guess but even that is not always relevant since</span>
<span class="quote">&gt; &gt; CCSIDR may not present the real hardware information. It&#39;s only meant to</span>
<span class="quote">&gt; &gt; give enough information to be able to do cache maintenance by set/way</span>
<span class="quote">&gt; &gt; and we&#39;ve seen CPU implementations where this has nothing to do with the</span>
<span class="quote">&gt; &gt; actual cache geometry.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; I am aware of that discussion, but that was about inferring aliasing</span>
<span class="quote">&gt; properties from the way size, which combines the linesize and the</span>
<span class="quote">&gt; number of sets/ways, and the latter are apparently set to 1/1 in some</span>
<span class="quote">&gt; cases so that any set/way operation simply affects the entire cache.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; However, the CCSIDR linesize field itself is mentioned in the</span>
<span class="quote">&gt; description of CWG in the ARM ARM, as a suitable source of obtaining</span>
<span class="quote">&gt; the maximum linesize in the system.</span>

The ARM ARM confuses me. While CTR_EL0.CWG indeed talks about CCSIDR as
a fall back, the latter has a note:

  The parameters NumSets, Associativity, and LineSize in these registers
  define the architecturally visible parameters that are required for
  the cache maintenance by Set/Way instructions. They are not guaranteed
  to represent the actual microarchitectural features of a design. You
  cannot make any inference about the actual sizes of caches based on
  these parameters.

So it&#39;s not clear to me whether LineSize would give us the information
we need for cache maintenance by VA. But I&#39;m not opposed to using this
on a CPU that doesn&#39;t have CWG (once we see one).
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/arch/arm64/include/asm/cache.h b/arch/arm64/include/asm/cache.h</span>
<span class="p_header">index 5082b30bc2c0..5967fcbb617a 100644</span>
<span class="p_header">--- a/arch/arm64/include/asm/cache.h</span>
<span class="p_header">+++ b/arch/arm64/include/asm/cache.h</span>
<span class="p_chunk">@@ -28,7 +28,7 @@</span> <span class="p_context"></span>
  * cache before the transfer is done, causing old data to be seen by
  * the CPU.
  */
<span class="p_del">-#define ARCH_DMA_MINALIGN	L1_CACHE_BYTES</span>
<span class="p_add">+#define ARCH_DMA_MINALIGN	128</span>
 
 #ifndef __ASSEMBLY__
 
<span class="p_chunk">@@ -37,7 +37,7 @@</span> <span class="p_context"></span>
 static inline int cache_line_size(void)
 {
 	u32 cwg = cache_type_cwg();
<span class="p_del">-	return cwg ? 4 &lt;&lt; cwg : L1_CACHE_BYTES;</span>
<span class="p_add">+	return cwg ? 4 &lt;&lt; cwg : ARCH_DMA_MINALIGN;</span>
 }
 
 #endif	/* __ASSEMBLY__ */
<span class="p_header">diff --git a/arch/arm64/kernel/cpufeature.c b/arch/arm64/kernel/cpufeature.c</span>
<span class="p_header">index 943f5140e0f3..b1d4d1f5b0dd 100644</span>
<span class="p_header">--- a/arch/arm64/kernel/cpufeature.c</span>
<span class="p_header">+++ b/arch/arm64/kernel/cpufeature.c</span>
<span class="p_chunk">@@ -970,7 +970,6 @@</span> <span class="p_context"> static void __init setup_feature_capabilities(void)</span>
 void __init setup_cpu_features(void)
 {
 	u32 cwg;
<span class="p_del">-	int cls;</span>
 
 	/* Set the CPU feature capabilies */
 	setup_feature_capabilities();
<span class="p_chunk">@@ -983,13 +982,9 @@</span> <span class="p_context"> void __init setup_cpu_features(void)</span>
 	 * Check for sane CTR_EL0.CWG value.
 	 */
 	cwg = cache_type_cwg();
<span class="p_del">-	cls = cache_line_size();</span>
 	if (!cwg)
<span class="p_del">-		pr_warn(&quot;No Cache Writeback Granule information, assuming cache line size %d\n&quot;,</span>
<span class="p_del">-			cls);</span>
<span class="p_del">-	if (L1_CACHE_BYTES &lt; cls)</span>
<span class="p_del">-		pr_warn(&quot;L1_CACHE_BYTES smaller than the Cache Writeback Granule (%d &lt; %d)\n&quot;,</span>
<span class="p_del">-			L1_CACHE_BYTES, cls);</span>
<span class="p_add">+		pr_warn(&quot;No Cache Writeback Granule information, assuming %d\n&quot;,</span>
<span class="p_add">+			ARCH_DMA_MINALIGN);</span>
 }
 
 static bool __maybe_unused
<span class="p_header">diff --git a/arch/arm64/mm/dma-mapping.c b/arch/arm64/mm/dma-mapping.c</span>
<span class="p_header">index a6e757cbab77..08232faf38ad 100644</span>
<span class="p_header">--- a/arch/arm64/mm/dma-mapping.c</span>
<span class="p_header">+++ b/arch/arm64/mm/dma-mapping.c</span>
<span class="p_chunk">@@ -987,6 +987,11 @@</span> <span class="p_context"> static void __iommu_setup_dma_ops(struct device *dev, u64 dma_base, u64 size,</span>
 void arch_setup_dma_ops(struct device *dev, u64 dma_base, u64 size,
 			struct iommu_ops *iommu, bool coherent)
 {
<span class="p_add">+	WARN_TAINT_ONCE(!coherent &amp;&amp; ARCH_DMA_MINALIGN &lt; cache_line_size(),</span>
<span class="p_add">+			TAINT_CPU_OUT_OF_SPEC,</span>
<span class="p_add">+			&quot;ARCH_DMA_MINALIGN smaller than the Cache Writeback Granule (%d &lt; %d)&quot;,</span>
<span class="p_add">+			ARCH_DMA_MINALIGN, cache_line_size());</span>
<span class="p_add">+</span>
 	if (!dev-&gt;archdata.dma_ops)
 		dev-&gt;archdata.dma_ops = &amp;swiotlb_dma_ops;
 

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



