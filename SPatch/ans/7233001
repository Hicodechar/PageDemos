
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>[ANNOUNCE] 4.1.7-rt8 - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    [ANNOUNCE] 4.1.7-rt8</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=107">Thomas Gleixner</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>Sept. 21, 2015, 4:48 p.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;alpine.DEB.2.11.1509211845280.5606@nanos&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/7233001/mbox/"
   >mbox</a>
|
   <a href="/patch/7233001/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/7233001/">/patch/7233001/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
X-Original-To: patchwork-LKML@patchwork.kernel.org
Delivered-To: patchwork-parsemail@patchwork2.web.kernel.org
Received: from mail.kernel.org (mail.kernel.org [198.145.29.136])
	by patchwork2.web.kernel.org (Postfix) with ESMTP id 0466FBEEC1
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Mon, 21 Sep 2015 16:49:00 +0000 (UTC)
Received: from mail.kernel.org (localhost [127.0.0.1])
	by mail.kernel.org (Postfix) with ESMTP id 1C27820701
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Mon, 21 Sep 2015 16:48:58 +0000 (UTC)
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.kernel.org (Postfix) with ESMTP id 62B0520707
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Mon, 21 Sep 2015 16:48:55 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1757267AbbIUQsv (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Mon, 21 Sep 2015 12:48:51 -0400
Received: from www.linutronix.de ([62.245.132.108]:37287 &quot;EHLO
	Galois.linutronix.de&quot; rhost-flags-OK-OK-OK-OK) by vger.kernel.org
	with ESMTP id S1752148AbbIUQst (ORCPT
	&lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Mon, 21 Sep 2015 12:48:49 -0400
Received: from localhost ([127.0.0.1]) by Galois.linutronix.de with esmtps
	(TLS1.0:DHE_RSA_AES_256_CBC_SHA1:256) (Exim 4.80)
	(envelope-from &lt;tglx@linutronix.de&gt;)
	id 1Ze4Gk-0007uX-Ri; Mon, 21 Sep 2015 18:48:47 +0200
Date: Mon, 21 Sep 2015 18:48:12 +0200 (CEST)
From: Thomas Gleixner &lt;tglx@linutronix.de&gt;
To: LKML &lt;linux-kernel@vger.kernel.org&gt;
cc: linux-rt-users &lt;linux-rt-users@vger.kernel.org&gt;,
	Sebastian Andrzej Siewior &lt;bigeasy@linutronix.de&gt;,
	Steven Rostedt &lt;rostedt@goodmis.org&gt;
Subject: [ANNOUNCE] 4.1.7-rt8
Message-ID: &lt;alpine.DEB.2.11.1509211845280.5606@nanos&gt;
User-Agent: Alpine 2.11 (DEB 23 2013-08-11)
MIME-Version: 1.0
Content-Type: TEXT/PLAIN; charset=US-ASCII
X-Linutronix-Spam-Score: -1.0
X-Linutronix-Spam-Level: -
X-Linutronix-Spam-Status: No , -1.0 points, 5.0 required, ALL_TRUSTED=-1,
	SHORTCIRCUIT=-0.0001
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Spam-Status: No, score=-6.9 required=5.0 tests=BAYES_00, RCVD_IN_DNSWL_HI, 
	RP_MATCHES_RCVD,
	UNPARSEABLE_RELAY autolearn=unavailable version=3.3.1
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on mail.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=107">Thomas Gleixner</a> - Sept. 21, 2015, 4:48 p.m.</div>
<pre class="content">
Dear RT folks!

I&#39;m pleased to announce the v4.1.7-rt8 patch set. v4.1.6-rt6 and
v4.1.7-rt7 are non-announced updates to incorporate the linux-4.1.y
stable tree changes.

Changes since v4.1.5-rt5:

  - Update to 4.1.7

  - Cherry-pick a XFS lockdep annotation fix from mainline

  - Use preempt_xxx_nort in the generic implementation of
    k[un]map_atomic.

  - Revert d04ea10ba1ea mmc: sdhci: don&#39;t provide hard irq handler

  - Force thread primary handlers of interrupts which provide both a
    primary and a threaded handler

  - Move clear_tasks_mm_cpumask() call to __cpu_die() on ARM
    (Grygoriii)

  - Fix a RCU splat in the trace histogram (Philipp)

Solved issues:

  - The high CPU usage problem reported by Nicholas turned out to be a
    scalability issue of the gcov instrumentation

Known issues:

  - bcache stays disabled

  - CPU hotplug is not better than before

  - The netlink_release() OOPS, reported by Clark, is still on the
    list, but unsolved due to lack of information

The delta patch against 4.1.7-rt7 is appended below and can be found here:

    https://www.kernel.org/pub/linux/kernel/projects/rt/4.1/incr/patch-4.1.7-rt7-rt8.patch.xz

You can get this release via the git tree at:

    git://git.kernel.org/pub/scm/linux/kernel/git/rt/linux-rt-devel.git v4.1.7-rt8

The RT patch against 4.1.5 can be found here:

    https://www.kernel.org/pub/linux/kernel/projects/rt/4.1/patch-4.1.7-rt8.patch.xz

The split quilt queue is available at:

    https://www.kernel.org/pub/linux/kernel/projects/rt/4.1/patches-4.1.7-rt8.tar.xz

Enjoy!

	tglx
---
--
To unsubscribe from this list: send the line &quot;unsubscribe linux-kernel&quot; in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
Please read the FAQ at  http://www.tux.org/lkml/
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c</span>
<span class="p_header">index f11d82527076..e561aef093c7 100644</span>
<span class="p_header">--- a/arch/arm/kernel/smp.c</span>
<span class="p_header">+++ b/arch/arm/kernel/smp.c</span>
<span class="p_chunk">@@ -213,8 +213,6 @@</span> <span class="p_context"> int __cpu_disable(void)</span>
 	flush_cache_louis();
 	local_flush_tlb_all();
 
<span class="p_del">-	clear_tasks_mm_cpumask(cpu);</span>
<span class="p_del">-</span>
 	return 0;
 }
 
<span class="p_chunk">@@ -230,6 +228,9 @@</span> <span class="p_context"> void __cpu_die(unsigned int cpu)</span>
 		pr_err(&quot;CPU%u: cpu didn&#39;t die\n&quot;, cpu);
 		return;
 	}
<span class="p_add">+</span>
<span class="p_add">+	clear_tasks_mm_cpumask(cpu);</span>
<span class="p_add">+</span>
 	pr_notice(&quot;CPU%u: shutdown\n&quot;, cpu);
 
 	/*
<span class="p_header">diff --git a/drivers/mmc/host/sdhci.c b/drivers/mmc/host/sdhci.c</span>
<span class="p_header">index acd8c620ec43..bec8a307f8cd 100644</span>
<span class="p_header">--- a/drivers/mmc/host/sdhci.c</span>
<span class="p_header">+++ b/drivers/mmc/host/sdhci.c</span>
<span class="p_chunk">@@ -2691,31 +2691,6 @@</span> <span class="p_context"> static irqreturn_t sdhci_thread_irq(int irq, void *dev_id)</span>
 	return isr ? IRQ_HANDLED : IRQ_NONE;
 }
 
<span class="p_del">-#ifdef CONFIG_PREEMPT_RT_BASE</span>
<span class="p_del">-static irqreturn_t sdhci_rt_irq(int irq, void *dev_id)</span>
<span class="p_del">-{</span>
<span class="p_del">-	irqreturn_t ret;</span>
<span class="p_del">-</span>
<span class="p_del">-	local_bh_disable();</span>
<span class="p_del">-	ret = sdhci_irq(irq, dev_id);</span>
<span class="p_del">-	local_bh_enable();</span>
<span class="p_del">-	if (ret == IRQ_WAKE_THREAD)</span>
<span class="p_del">-		ret = sdhci_thread_irq(irq, dev_id);</span>
<span class="p_del">-	return ret;</span>
<span class="p_del">-}</span>
<span class="p_del">-#endif</span>
<span class="p_del">-</span>
<span class="p_del">-static int sdhci_req_irq(struct sdhci_host *host)</span>
<span class="p_del">-{</span>
<span class="p_del">-#ifdef CONFIG_PREEMPT_RT_BASE</span>
<span class="p_del">-	return request_threaded_irq(host-&gt;irq, NULL, sdhci_rt_irq,</span>
<span class="p_del">-				    IRQF_SHARED, mmc_hostname(host-&gt;mmc), host);</span>
<span class="p_del">-#else</span>
<span class="p_del">-	return request_threaded_irq(host-&gt;irq, sdhci_irq, sdhci_thread_irq,</span>
<span class="p_del">-				    IRQF_SHARED, mmc_hostname(host-&gt;mmc), host);</span>
<span class="p_del">-#endif</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
 /*****************************************************************************\
  *                                                                           *
  * Suspend/resume                                                            *
<span class="p_chunk">@@ -2783,7 +2758,9 @@</span> <span class="p_context"> int sdhci_resume_host(struct sdhci_host *host)</span>
 	}
 
 	if (!device_may_wakeup(mmc_dev(host-&gt;mmc))) {
<span class="p_del">-		ret = sdhci_req_irq(host);</span>
<span class="p_add">+		ret = request_threaded_irq(host-&gt;irq, sdhci_irq,</span>
<span class="p_add">+					   sdhci_thread_irq, IRQF_SHARED,</span>
<span class="p_add">+					   mmc_hostname(host-&gt;mmc), host);</span>
 		if (ret)
 			return ret;
 	} else {
<span class="p_chunk">@@ -3444,7 +3421,8 @@</span> <span class="p_context"> int sdhci_add_host(struct sdhci_host *host)</span>
 
 	sdhci_init(host, 0);
 
<span class="p_del">-	ret = sdhci_req_irq(host);</span>
<span class="p_add">+	ret = request_threaded_irq(host-&gt;irq, sdhci_irq, sdhci_thread_irq,</span>
<span class="p_add">+				   IRQF_SHARED,	mmc_hostname(mmc), host);</span>
 	if (ret) {
 		pr_err(&quot;%s: Failed to request IRQ %d: %d\n&quot;,
 		       mmc_hostname(mmc), host-&gt;irq, ret);
<span class="p_header">diff --git a/fs/xfs/xfs_inode.c b/fs/xfs/xfs_inode.c</span>
<span class="p_header">index 539a85fddbc2..fec4bfba0839 100644</span>
<span class="p_header">--- a/fs/xfs/xfs_inode.c</span>
<span class="p_header">+++ b/fs/xfs/xfs_inode.c</span>
<span class="p_chunk">@@ -164,7 +164,7 @@</span> <span class="p_context"> xfs_ilock(</span>
 	       (XFS_MMAPLOCK_SHARED | XFS_MMAPLOCK_EXCL));
 	ASSERT((lock_flags &amp; (XFS_ILOCK_SHARED | XFS_ILOCK_EXCL)) !=
 	       (XFS_ILOCK_SHARED | XFS_ILOCK_EXCL));
<span class="p_del">-	ASSERT((lock_flags &amp; ~(XFS_LOCK_MASK | XFS_LOCK_DEP_MASK)) == 0);</span>
<span class="p_add">+	ASSERT((lock_flags &amp; ~(XFS_LOCK_MASK | XFS_LOCK_SUBCLASS_MASK)) == 0);</span>
 
 	if (lock_flags &amp; XFS_IOLOCK_EXCL)
 		mrupdate_nested(&amp;ip-&gt;i_iolock, XFS_IOLOCK_DEP(lock_flags));
<span class="p_chunk">@@ -212,7 +212,7 @@</span> <span class="p_context"> xfs_ilock_nowait(</span>
 	       (XFS_MMAPLOCK_SHARED | XFS_MMAPLOCK_EXCL));
 	ASSERT((lock_flags &amp; (XFS_ILOCK_SHARED | XFS_ILOCK_EXCL)) !=
 	       (XFS_ILOCK_SHARED | XFS_ILOCK_EXCL));
<span class="p_del">-	ASSERT((lock_flags &amp; ~(XFS_LOCK_MASK | XFS_LOCK_DEP_MASK)) == 0);</span>
<span class="p_add">+	ASSERT((lock_flags &amp; ~(XFS_LOCK_MASK | XFS_LOCK_SUBCLASS_MASK)) == 0);</span>
 
 	if (lock_flags &amp; XFS_IOLOCK_EXCL) {
 		if (!mrtryupdate(&amp;ip-&gt;i_iolock))
<span class="p_chunk">@@ -281,7 +281,7 @@</span> <span class="p_context"> xfs_iunlock(</span>
 	       (XFS_MMAPLOCK_SHARED | XFS_MMAPLOCK_EXCL));
 	ASSERT((lock_flags &amp; (XFS_ILOCK_SHARED | XFS_ILOCK_EXCL)) !=
 	       (XFS_ILOCK_SHARED | XFS_ILOCK_EXCL));
<span class="p_del">-	ASSERT((lock_flags &amp; ~(XFS_LOCK_MASK | XFS_LOCK_DEP_MASK)) == 0);</span>
<span class="p_add">+	ASSERT((lock_flags &amp; ~(XFS_LOCK_MASK | XFS_LOCK_SUBCLASS_MASK)) == 0);</span>
 	ASSERT(lock_flags != 0);
 
 	if (lock_flags &amp; XFS_IOLOCK_EXCL)
<span class="p_chunk">@@ -364,30 +364,38 @@</span> <span class="p_context"> int xfs_lock_delays;</span>
 
 /*
  * Bump the subclass so xfs_lock_inodes() acquires each lock with a different
<span class="p_del">- * value. This shouldn&#39;t be called for page fault locking, but we also need to</span>
<span class="p_del">- * ensure we don&#39;t overrun the number of lockdep subclasses for the iolock or</span>
<span class="p_del">- * mmaplock as that is limited to 12 by the mmap lock lockdep annotations.</span>
<span class="p_add">+ * value. This can be called for any type of inode lock combination, including</span>
<span class="p_add">+ * parent locking. Care must be taken to ensure we don&#39;t overrun the subclass</span>
<span class="p_add">+ * storage fields in the class mask we build.</span>
  */
 static inline int
 xfs_lock_inumorder(int lock_mode, int subclass)
 {
<span class="p_add">+	int	class = 0;</span>
<span class="p_add">+</span>
<span class="p_add">+	ASSERT(!(lock_mode &amp; (XFS_ILOCK_PARENT | XFS_ILOCK_RTBITMAP |</span>
<span class="p_add">+			      XFS_ILOCK_RTSUM)));</span>
<span class="p_add">+</span>
 	if (lock_mode &amp; (XFS_IOLOCK_SHARED|XFS_IOLOCK_EXCL)) {
<span class="p_del">-		ASSERT(subclass + XFS_LOCK_INUMORDER &lt;</span>
<span class="p_del">-			(1 &lt;&lt; (XFS_MMAPLOCK_SHIFT - XFS_IOLOCK_SHIFT)));</span>
<span class="p_del">-		lock_mode |= (subclass + XFS_LOCK_INUMORDER) &lt;&lt; XFS_IOLOCK_SHIFT;</span>
<span class="p_add">+		ASSERT(subclass &lt;= XFS_IOLOCK_MAX_SUBCLASS);</span>
<span class="p_add">+		ASSERT(subclass + XFS_IOLOCK_PARENT_VAL &lt;</span>
<span class="p_add">+						MAX_LOCKDEP_SUBCLASSES);</span>
<span class="p_add">+		class += subclass &lt;&lt; XFS_IOLOCK_SHIFT;</span>
<span class="p_add">+		if (lock_mode &amp; XFS_IOLOCK_PARENT)</span>
<span class="p_add">+			class += XFS_IOLOCK_PARENT_VAL &lt;&lt; XFS_IOLOCK_SHIFT;</span>
 	}
 
 	if (lock_mode &amp; (XFS_MMAPLOCK_SHARED|XFS_MMAPLOCK_EXCL)) {
<span class="p_del">-		ASSERT(subclass + XFS_LOCK_INUMORDER &lt;</span>
<span class="p_del">-			(1 &lt;&lt; (XFS_ILOCK_SHIFT - XFS_MMAPLOCK_SHIFT)));</span>
<span class="p_del">-		lock_mode |= (subclass + XFS_LOCK_INUMORDER) &lt;&lt;</span>
<span class="p_del">-							XFS_MMAPLOCK_SHIFT;</span>
<span class="p_add">+		ASSERT(subclass &lt;= XFS_MMAPLOCK_MAX_SUBCLASS);</span>
<span class="p_add">+		class += subclass &lt;&lt; XFS_MMAPLOCK_SHIFT;</span>
 	}
 
<span class="p_del">-	if (lock_mode &amp; (XFS_ILOCK_SHARED|XFS_ILOCK_EXCL))</span>
<span class="p_del">-		lock_mode |= (subclass + XFS_LOCK_INUMORDER) &lt;&lt; XFS_ILOCK_SHIFT;</span>
<span class="p_add">+	if (lock_mode &amp; (XFS_ILOCK_SHARED|XFS_ILOCK_EXCL)) {</span>
<span class="p_add">+		ASSERT(subclass &lt;= XFS_ILOCK_MAX_SUBCLASS);</span>
<span class="p_add">+		class += subclass &lt;&lt; XFS_ILOCK_SHIFT;</span>
<span class="p_add">+	}</span>
 
<span class="p_del">-	return lock_mode;</span>
<span class="p_add">+	return (lock_mode &amp; ~XFS_LOCK_SUBCLASS_MASK) | class;</span>
 }
 
 /*
<span class="p_chunk">@@ -399,6 +407,11 @@</span> <span class="p_context"> xfs_lock_inumorder(int lock_mode, int subclass)</span>
  * transaction (such as truncate). This can result in deadlock since the long
  * running trans might need to wait for the inode we just locked in order to
  * push the tail and free space in the log.
<span class="p_add">+ *</span>
<span class="p_add">+ * xfs_lock_inodes() can only be used to lock one type of lock at a time -</span>
<span class="p_add">+ * the iolock, the mmaplock or the ilock, but not more than one at a time. If we</span>
<span class="p_add">+ * lock more than one at a time, lockdep will report false positives saying we</span>
<span class="p_add">+ * have violated locking orders.</span>
  */
 void
 xfs_lock_inodes(
<span class="p_chunk">@@ -409,8 +422,29 @@</span> <span class="p_context"> xfs_lock_inodes(</span>
 	int		attempts = 0, i, j, try_lock;
 	xfs_log_item_t	*lp;
 
<span class="p_del">-	/* currently supports between 2 and 5 inodes */</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Currently supports between 2 and 5 inodes with exclusive locking.  We</span>
<span class="p_add">+	 * support an arbitrary depth of locking here, but absolute limits on</span>
<span class="p_add">+	 * inodes depend on the the type of locking and the limits placed by</span>
<span class="p_add">+	 * lockdep annotations in xfs_lock_inumorder.  These are all checked by</span>
<span class="p_add">+	 * the asserts.</span>
<span class="p_add">+	 */</span>
 	ASSERT(ips &amp;&amp; inodes &gt;= 2 &amp;&amp; inodes &lt;= 5);
<span class="p_add">+	ASSERT(lock_mode &amp; (XFS_IOLOCK_EXCL | XFS_MMAPLOCK_EXCL |</span>
<span class="p_add">+			    XFS_ILOCK_EXCL));</span>
<span class="p_add">+	ASSERT(!(lock_mode &amp; (XFS_IOLOCK_SHARED | XFS_MMAPLOCK_SHARED |</span>
<span class="p_add">+			      XFS_ILOCK_SHARED)));</span>
<span class="p_add">+	ASSERT(!(lock_mode &amp; XFS_IOLOCK_EXCL) ||</span>
<span class="p_add">+		inodes &lt;= XFS_IOLOCK_MAX_SUBCLASS + 1);</span>
<span class="p_add">+	ASSERT(!(lock_mode &amp; XFS_MMAPLOCK_EXCL) ||</span>
<span class="p_add">+		inodes &lt;= XFS_MMAPLOCK_MAX_SUBCLASS + 1);</span>
<span class="p_add">+	ASSERT(!(lock_mode &amp; XFS_ILOCK_EXCL) ||</span>
<span class="p_add">+		inodes &lt;= XFS_ILOCK_MAX_SUBCLASS + 1);</span>
<span class="p_add">+</span>
<span class="p_add">+	if (lock_mode &amp; XFS_IOLOCK_EXCL) {</span>
<span class="p_add">+		ASSERT(!(lock_mode &amp; (XFS_MMAPLOCK_EXCL | XFS_ILOCK_EXCL)));</span>
<span class="p_add">+	} else if (lock_mode &amp; XFS_MMAPLOCK_EXCL)</span>
<span class="p_add">+		ASSERT(!(lock_mode &amp; XFS_ILOCK_EXCL));</span>
 
 	try_lock = 0;
 	i = 0;
<span class="p_header">diff --git a/fs/xfs/xfs_inode.h b/fs/xfs/xfs_inode.h</span>
<span class="p_header">index 8f22d20368d8..ee26a603c131 100644</span>
<span class="p_header">--- a/fs/xfs/xfs_inode.h</span>
<span class="p_header">+++ b/fs/xfs/xfs_inode.h</span>
<span class="p_chunk">@@ -284,9 +284,9 @@</span> <span class="p_context"> static inline int xfs_isiflocked(struct xfs_inode *ip)</span>
  * Flags for lockdep annotations.
  *
  * XFS_LOCK_PARENT - for directory operations that require locking a
<span class="p_del">- * parent directory inode and a child entry inode.  The parent gets locked</span>
<span class="p_del">- * with this flag so it gets a lockdep subclass of 1 and the child entry</span>
<span class="p_del">- * lock will have a lockdep subclass of 0.</span>
<span class="p_add">+ * parent directory inode and a child entry inode. IOLOCK requires nesting,</span>
<span class="p_add">+ * MMAPLOCK does not support this class, ILOCK requires a single subclass</span>
<span class="p_add">+ * to differentiate parent from child.</span>
  *
  * XFS_LOCK_RTBITMAP/XFS_LOCK_RTSUM - the realtime device bitmap and summary
  * inodes do not participate in the normal lock order, and thus have their
<span class="p_chunk">@@ -295,30 +295,63 @@</span> <span class="p_context"> static inline int xfs_isiflocked(struct xfs_inode *ip)</span>
  * XFS_LOCK_INUMORDER - for locking several inodes at the some time
  * with xfs_lock_inodes().  This flag is used as the starting subclass
  * and each subsequent lock acquired will increment the subclass by one.
<span class="p_del">- * So the first lock acquired will have a lockdep subclass of 4, the</span>
<span class="p_del">- * second lock will have a lockdep subclass of 5, and so on. It is</span>
<span class="p_del">- * the responsibility of the class builder to shift this to the correct</span>
<span class="p_del">- * portion of the lock_mode lockdep mask.</span>
<span class="p_add">+ * However, MAX_LOCKDEP_SUBCLASSES == 8, which means we are greatly</span>
<span class="p_add">+ * limited to the subclasses we can represent via nesting. We need at least</span>
<span class="p_add">+ * 5 inodes nest depth for the ILOCK through rename, and we also have to support</span>
<span class="p_add">+ * XFS_ILOCK_PARENT, which gives 6 subclasses. Then we have XFS_ILOCK_RTBITMAP</span>
<span class="p_add">+ * and XFS_ILOCK_RTSUM, which are another 2 unique subclasses, so that&#39;s all</span>
<span class="p_add">+ * 8 subclasses supported by lockdep.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * This also means we have to number the sub-classes in the lowest bits of</span>
<span class="p_add">+ * the mask we keep, and we have to ensure we never exceed 3 bits of lockdep</span>
<span class="p_add">+ * mask and we can&#39;t use bit-masking to build the subclasses. What a mess.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * Bit layout:</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * Bit		Lock Region</span>
<span class="p_add">+ * 16-19	XFS_IOLOCK_SHIFT dependencies</span>
<span class="p_add">+ * 20-23	XFS_MMAPLOCK_SHIFT dependencies</span>
<span class="p_add">+ * 24-31	XFS_ILOCK_SHIFT dependencies</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * IOLOCK values</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * 0-3		subclass value</span>
<span class="p_add">+ * 4-7		PARENT subclass values</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * MMAPLOCK values</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * 0-3		subclass value</span>
<span class="p_add">+ * 4-7		unused</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * ILOCK values</span>
<span class="p_add">+ * 0-4		subclass values</span>
<span class="p_add">+ * 5		PARENT subclass (not nestable)</span>
<span class="p_add">+ * 6		RTBITMAP subclass (not nestable)</span>
<span class="p_add">+ * 7		RTSUM subclass (not nestable)</span>
<span class="p_add">+ *</span>
  */
<span class="p_del">-#define XFS_LOCK_PARENT		1</span>
<span class="p_del">-#define XFS_LOCK_RTBITMAP	2</span>
<span class="p_del">-#define XFS_LOCK_RTSUM		3</span>
<span class="p_del">-#define XFS_LOCK_INUMORDER	4</span>
<span class="p_del">-</span>
<span class="p_del">-#define XFS_IOLOCK_SHIFT	16</span>
<span class="p_del">-#define	XFS_IOLOCK_PARENT	(XFS_LOCK_PARENT &lt;&lt; XFS_IOLOCK_SHIFT)</span>
<span class="p_del">-</span>
<span class="p_del">-#define XFS_MMAPLOCK_SHIFT	20</span>
<span class="p_del">-</span>
<span class="p_del">-#define XFS_ILOCK_SHIFT		24</span>
<span class="p_del">-#define	XFS_ILOCK_PARENT	(XFS_LOCK_PARENT &lt;&lt; XFS_ILOCK_SHIFT)</span>
<span class="p_del">-#define	XFS_ILOCK_RTBITMAP	(XFS_LOCK_RTBITMAP &lt;&lt; XFS_ILOCK_SHIFT)</span>
<span class="p_del">-#define	XFS_ILOCK_RTSUM		(XFS_LOCK_RTSUM &lt;&lt; XFS_ILOCK_SHIFT)</span>
<span class="p_del">-</span>
<span class="p_del">-#define XFS_IOLOCK_DEP_MASK	0x000f0000</span>
<span class="p_del">-#define XFS_MMAPLOCK_DEP_MASK	0x00f00000</span>
<span class="p_del">-#define XFS_ILOCK_DEP_MASK	0xff000000</span>
<span class="p_del">-#define XFS_LOCK_DEP_MASK	(XFS_IOLOCK_DEP_MASK | \</span>
<span class="p_add">+#define XFS_IOLOCK_SHIFT		16</span>
<span class="p_add">+#define XFS_IOLOCK_PARENT_VAL		4</span>
<span class="p_add">+#define XFS_IOLOCK_MAX_SUBCLASS		(XFS_IOLOCK_PARENT_VAL - 1)</span>
<span class="p_add">+#define XFS_IOLOCK_DEP_MASK		0x000f0000</span>
<span class="p_add">+#define	XFS_IOLOCK_PARENT		(XFS_IOLOCK_PARENT_VAL &lt;&lt; XFS_IOLOCK_SHIFT)</span>
<span class="p_add">+</span>
<span class="p_add">+#define XFS_MMAPLOCK_SHIFT		20</span>
<span class="p_add">+#define XFS_MMAPLOCK_NUMORDER		0</span>
<span class="p_add">+#define XFS_MMAPLOCK_MAX_SUBCLASS	3</span>
<span class="p_add">+#define XFS_MMAPLOCK_DEP_MASK		0x00f00000</span>
<span class="p_add">+</span>
<span class="p_add">+#define XFS_ILOCK_SHIFT			24</span>
<span class="p_add">+#define XFS_ILOCK_PARENT_VAL		5</span>
<span class="p_add">+#define XFS_ILOCK_MAX_SUBCLASS		(XFS_ILOCK_PARENT_VAL - 1)</span>
<span class="p_add">+#define XFS_ILOCK_RTBITMAP_VAL		6</span>
<span class="p_add">+#define XFS_ILOCK_RTSUM_VAL		7</span>
<span class="p_add">+#define XFS_ILOCK_DEP_MASK		0xff000000</span>
<span class="p_add">+#define	XFS_ILOCK_PARENT		(XFS_ILOCK_PARENT_VAL &lt;&lt; XFS_ILOCK_SHIFT)</span>
<span class="p_add">+#define	XFS_ILOCK_RTBITMAP		(XFS_ILOCK_RTBITMAP_VAL &lt;&lt; XFS_ILOCK_SHIFT)</span>
<span class="p_add">+#define	XFS_ILOCK_RTSUM			(XFS_ILOCK_RTSUM_VAL &lt;&lt; XFS_ILOCK_SHIFT)</span>
<span class="p_add">+</span>
<span class="p_add">+#define XFS_LOCK_SUBCLASS_MASK	(XFS_IOLOCK_DEP_MASK | \</span>
 				 XFS_MMAPLOCK_DEP_MASK | \
 				 XFS_ILOCK_DEP_MASK)
 
<span class="p_header">diff --git a/include/linux/highmem.h b/include/linux/highmem.h</span>
<span class="p_header">index d89b5e083c35..06bae5a6761d 100644</span>
<span class="p_header">--- a/include/linux/highmem.h</span>
<span class="p_header">+++ b/include/linux/highmem.h</span>
<span class="p_chunk">@@ -66,7 +66,7 @@</span> <span class="p_context"> static inline void kunmap(struct page *page)</span>
 
 static inline void *kmap_atomic(struct page *page)
 {
<span class="p_del">-	preempt_disable();</span>
<span class="p_add">+	preempt_disable_nort();</span>
 	pagefault_disable();
 	return page_address(page);
 }
<span class="p_chunk">@@ -75,7 +75,7 @@</span> <span class="p_context"> static inline void *kmap_atomic(struct page *page)</span>
 static inline void __kunmap_atomic(void *addr)
 {
 	pagefault_enable();
<span class="p_del">-	preempt_enable();</span>
<span class="p_add">+	preempt_enable_nort();</span>
 }
 
 #define kmap_atomic_pfn(pfn)	kmap_atomic(pfn_to_page(pfn))
<span class="p_header">diff --git a/include/linux/interrupt.h b/include/linux/interrupt.h</span>
<span class="p_header">index 67f2af8c0cd5..fe254555cf95 100644</span>
<span class="p_header">--- a/include/linux/interrupt.h</span>
<span class="p_header">+++ b/include/linux/interrupt.h</span>
<span class="p_chunk">@@ -104,6 +104,7 @@</span> <span class="p_context"> typedef irqreturn_t (*irq_handler_t)(int, void *);</span>
  * @flags:	flags (see IRQF_* above)
  * @thread_fn:	interrupt handler function for threaded interrupts
  * @thread:	thread pointer for threaded interrupts
<span class="p_add">+ * @secondary:	pointer to secondary irqaction (force threading)</span>
  * @thread_flags:	flags related to @thread
  * @thread_mask:	bitmask for keeping track of @thread activity
  * @dir:	pointer to the proc/irq/NN/name entry
<span class="p_chunk">@@ -115,6 +116,7 @@</span> <span class="p_context"> struct irqaction {</span>
 	struct irqaction	*next;
 	irq_handler_t		thread_fn;
 	struct task_struct	*thread;
<span class="p_add">+	struct irqaction	*secondary;</span>
 	unsigned int		irq;
 	unsigned int		flags;
 	unsigned long		thread_flags;
<span class="p_header">diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c</span>
<span class="p_header">index 1b5c50a68e23..79c55c26eaee 100644</span>
<span class="p_header">--- a/kernel/irq/manage.c</span>
<span class="p_header">+++ b/kernel/irq/manage.c</span>
<span class="p_chunk">@@ -772,6 +772,12 @@</span> <span class="p_context"> static irqreturn_t irq_nested_primary_handler(int irq, void *dev_id)</span>
 	return IRQ_NONE;
 }
 
<span class="p_add">+static irqreturn_t irq_forced_secondary_handler(int irq, void *dev_id)</span>
<span class="p_add">+{</span>
<span class="p_add">+	WARN(1, &quot;Secondary action handler called for irq %d\n&quot;, irq);</span>
<span class="p_add">+	return IRQ_NONE;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static int irq_wait_for_interrupt(struct irqaction *action)
 {
 	set_current_state(TASK_INTERRUPTIBLE);
<span class="p_chunk">@@ -798,7 +804,8 @@</span> <span class="p_context"> static int irq_wait_for_interrupt(struct irqaction *action)</span>
 static void irq_finalize_oneshot(struct irq_desc *desc,
 				 struct irqaction *action)
 {
<span class="p_del">-	if (!(desc-&gt;istate &amp; IRQS_ONESHOT))</span>
<span class="p_add">+	if (!(desc-&gt;istate &amp; IRQS_ONESHOT) ||</span>
<span class="p_add">+	    action-&gt;handler == irq_forced_secondary_handler)</span>
 		return;
 again:
 	chip_bus_lock(desc);
<span class="p_chunk">@@ -960,6 +967,18 @@</span> <span class="p_context"> static void irq_thread_dtor(struct callback_head *unused)</span>
 	irq_finalize_oneshot(desc, action);
 }
 
<span class="p_add">+static void irq_wake_secondary(struct irq_desc *desc, struct irqaction *action)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct irqaction *secondary = action-&gt;secondary;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (WARN_ON_ONCE(!secondary))</span>
<span class="p_add">+		return;</span>
<span class="p_add">+</span>
<span class="p_add">+	raw_spin_lock_irq(&amp;desc-&gt;lock);</span>
<span class="p_add">+	__irq_wake_thread(desc, secondary);</span>
<span class="p_add">+	raw_spin_unlock_irq(&amp;desc-&gt;lock);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 /*
  * Interrupt handler thread
  */
<span class="p_chunk">@@ -990,6 +1009,8 @@</span> <span class="p_context"> static int irq_thread(void *data)</span>
 		action_ret = handler_fn(desc, action);
 		if (action_ret == IRQ_HANDLED)
 			atomic_inc(&amp;desc-&gt;threads_handled);
<span class="p_add">+		if (action_ret == IRQ_WAKE_THREAD)</span>
<span class="p_add">+			irq_wake_secondary(desc, action);</span>
 
 #ifdef CONFIG_PREEMPT_RT_FULL
 		migrate_disable();
<span class="p_chunk">@@ -1040,20 +1061,36 @@</span> <span class="p_context"> void irq_wake_thread(unsigned int irq, void *dev_id)</span>
 }
 EXPORT_SYMBOL_GPL(irq_wake_thread);
 
<span class="p_del">-static void irq_setup_forced_threading(struct irqaction *new)</span>
<span class="p_add">+static int irq_setup_forced_threading(struct irqaction *new)</span>
 {
 	if (!force_irqthreads)
<span class="p_del">-		return;</span>
<span class="p_add">+		return 0;</span>
 	if (new-&gt;flags &amp; (IRQF_NO_THREAD | IRQF_PERCPU | IRQF_ONESHOT))
<span class="p_del">-		return;</span>
<span class="p_add">+		return 0;</span>
 
 	new-&gt;flags |= IRQF_ONESHOT;
 
<span class="p_del">-	if (!new-&gt;thread_fn) {</span>
<span class="p_del">-		set_bit(IRQTF_FORCED_THREAD, &amp;new-&gt;thread_flags);</span>
<span class="p_del">-		new-&gt;thread_fn = new-&gt;handler;</span>
<span class="p_del">-		new-&gt;handler = irq_default_primary_handler;</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Handle the case where we have a real primary handler and a</span>
<span class="p_add">+	 * thread handler. We force thread them as well by creating a</span>
<span class="p_add">+	 * secondary action.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	if (new-&gt;handler != irq_default_primary_handler &amp;&amp; new-&gt;thread_fn) {</span>
<span class="p_add">+		/* Allocate the secondary action */</span>
<span class="p_add">+		new-&gt;secondary = kzalloc(sizeof(struct irqaction), GFP_KERNEL);</span>
<span class="p_add">+		if (!new-&gt;secondary)</span>
<span class="p_add">+			return -ENOMEM;</span>
<span class="p_add">+		new-&gt;secondary-&gt;handler = irq_forced_secondary_handler;</span>
<span class="p_add">+		new-&gt;secondary-&gt;thread_fn = new-&gt;thread_fn;</span>
<span class="p_add">+		new-&gt;secondary-&gt;dev_id = new-&gt;dev_id;</span>
<span class="p_add">+		new-&gt;secondary-&gt;irq = new-&gt;irq;</span>
<span class="p_add">+		new-&gt;secondary-&gt;name = new-&gt;name;</span>
 	}
<span class="p_add">+	/* Deal with the primary handler */</span>
<span class="p_add">+	set_bit(IRQTF_FORCED_THREAD, &amp;new-&gt;thread_flags);</span>
<span class="p_add">+	new-&gt;thread_fn = new-&gt;handler;</span>
<span class="p_add">+	new-&gt;handler = irq_default_primary_handler;</span>
<span class="p_add">+	return 0;</span>
 }
 
 static int irq_request_resources(struct irq_desc *desc)
<span class="p_chunk">@@ -1073,6 +1110,48 @@</span> <span class="p_context"> static void irq_release_resources(struct irq_desc *desc)</span>
 		c-&gt;irq_release_resources(d);
 }
 
<span class="p_add">+static int</span>
<span class="p_add">+setup_irq_thread(struct irqaction *new, unsigned int irq, bool secondary)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct task_struct *t;</span>
<span class="p_add">+	struct sched_param param = {</span>
<span class="p_add">+		.sched_priority = MAX_USER_RT_PRIO/2,</span>
<span class="p_add">+	};</span>
<span class="p_add">+</span>
<span class="p_add">+	if (!secondary) {</span>
<span class="p_add">+		t = kthread_create(irq_thread, new, &quot;irq/%d-%s&quot;, irq,</span>
<span class="p_add">+				   new-&gt;name);</span>
<span class="p_add">+	} else {</span>
<span class="p_add">+		t = kthread_create(irq_thread, new, &quot;irq/%d-s-%s&quot;, irq,</span>
<span class="p_add">+				   new-&gt;name);</span>
<span class="p_add">+		param.sched_priority += 1;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	if (IS_ERR(t))</span>
<span class="p_add">+		return PTR_ERR(t);</span>
<span class="p_add">+</span>
<span class="p_add">+	sched_setscheduler_nocheck(t, SCHED_FIFO, &amp;param);</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * We keep the reference to the task struct even if</span>
<span class="p_add">+	 * the thread dies to avoid that the interrupt code</span>
<span class="p_add">+	 * references an already freed task_struct.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	get_task_struct(t);</span>
<span class="p_add">+	new-&gt;thread = t;</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Tell the thread to set its affinity. This is</span>
<span class="p_add">+	 * important for shared interrupt handlers as we do</span>
<span class="p_add">+	 * not invoke setup_affinity() for the secondary</span>
<span class="p_add">+	 * handlers as everything is already set up. Even for</span>
<span class="p_add">+	 * interrupts marked with IRQF_NO_BALANCE this is</span>
<span class="p_add">+	 * correct as we want the thread to move to the cpu(s)</span>
<span class="p_add">+	 * on which the requesting code placed the interrupt.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	set_bit(IRQTF_AFFINITY, &amp;new-&gt;thread_flags);</span>
<span class="p_add">+	return 0;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 /*
  * Internal function to register an irqaction - typically used to
  * allocate special interrupts that are part of the architecture.
<span class="p_chunk">@@ -1093,6 +1172,8 @@</span> <span class="p_context"> __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)</span>
 	if (!try_module_get(desc-&gt;owner))
 		return -ENODEV;
 
<span class="p_add">+	new-&gt;irq = irq;</span>
<span class="p_add">+</span>
 	/*
 	 * Check whether the interrupt nests into another interrupt
 	 * thread.
<span class="p_chunk">@@ -1110,8 +1191,11 @@</span> <span class="p_context"> __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)</span>
 		 */
 		new-&gt;handler = irq_nested_primary_handler;
 	} else {
<span class="p_del">-		if (irq_settings_can_thread(desc))</span>
<span class="p_del">-			irq_setup_forced_threading(new);</span>
<span class="p_add">+		if (irq_settings_can_thread(desc)) {</span>
<span class="p_add">+			ret = irq_setup_forced_threading(new);</span>
<span class="p_add">+			if (ret)</span>
<span class="p_add">+				goto out_mput;</span>
<span class="p_add">+		}</span>
 	}
 
 	/*
<span class="p_chunk">@@ -1120,37 +1204,14 @@</span> <span class="p_context"> __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)</span>
 	 * thread.
 	 */
 	if (new-&gt;thread_fn &amp;&amp; !nested) {
<span class="p_del">-		struct task_struct *t;</span>
<span class="p_del">-		static const struct sched_param param = {</span>
<span class="p_del">-			.sched_priority = MAX_USER_RT_PRIO/2,</span>
<span class="p_del">-		};</span>
<span class="p_del">-</span>
<span class="p_del">-		t = kthread_create(irq_thread, new, &quot;irq/%d-%s&quot;, irq,</span>
<span class="p_del">-				   new-&gt;name);</span>
<span class="p_del">-		if (IS_ERR(t)) {</span>
<span class="p_del">-			ret = PTR_ERR(t);</span>
<span class="p_add">+		ret = setup_irq_thread(new, irq, false);</span>
<span class="p_add">+		if (ret)</span>
 			goto out_mput;
<span class="p_add">+		if (new-&gt;secondary) {</span>
<span class="p_add">+			ret = setup_irq_thread(new-&gt;secondary, irq, true);</span>
<span class="p_add">+			if (ret)</span>
<span class="p_add">+				goto out_thread;</span>
 		}
<span class="p_del">-</span>
<span class="p_del">-		sched_setscheduler_nocheck(t, SCHED_FIFO, &amp;param);</span>
<span class="p_del">-</span>
<span class="p_del">-		/*</span>
<span class="p_del">-		 * We keep the reference to the task struct even if</span>
<span class="p_del">-		 * the thread dies to avoid that the interrupt code</span>
<span class="p_del">-		 * references an already freed task_struct.</span>
<span class="p_del">-		 */</span>
<span class="p_del">-		get_task_struct(t);</span>
<span class="p_del">-		new-&gt;thread = t;</span>
<span class="p_del">-		/*</span>
<span class="p_del">-		 * Tell the thread to set its affinity. This is</span>
<span class="p_del">-		 * important for shared interrupt handlers as we do</span>
<span class="p_del">-		 * not invoke setup_affinity() for the secondary</span>
<span class="p_del">-		 * handlers as everything is already set up. Even for</span>
<span class="p_del">-		 * interrupts marked with IRQF_NO_BALANCE this is</span>
<span class="p_del">-		 * correct as we want the thread to move to the cpu(s)</span>
<span class="p_del">-		 * on which the requesting code placed the interrupt.</span>
<span class="p_del">-		 */</span>
<span class="p_del">-		set_bit(IRQTF_AFFINITY, &amp;new-&gt;thread_flags);</span>
 	}
 
 	if (!alloc_cpumask_var(&amp;mask, GFP_KERNEL)) {
<span class="p_chunk">@@ -1326,7 +1387,6 @@</span> <span class="p_context"> __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)</span>
 				   irq, nmsk, omsk);
 	}
 
<span class="p_del">-	new-&gt;irq = irq;</span>
 	*old_ptr = new;
 
 	irq_pm_install_action(desc, new);
<span class="p_chunk">@@ -1352,6 +1412,8 @@</span> <span class="p_context"> __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)</span>
 	 */
 	if (new-&gt;thread)
 		wake_up_process(new-&gt;thread);
<span class="p_add">+	if (new-&gt;secondary)</span>
<span class="p_add">+		wake_up_process(new-&gt;secondary-&gt;thread);</span>
 
 	register_irq_proc(irq, desc);
 	new-&gt;dir = NULL;
<span class="p_chunk">@@ -1382,6 +1444,13 @@</span> <span class="p_context"> out_thread:</span>
 		kthread_stop(t);
 		put_task_struct(t);
 	}
<span class="p_add">+	if (new-&gt;secondary &amp;&amp; new-&gt;secondary-&gt;thread) {</span>
<span class="p_add">+		struct task_struct *t = new-&gt;secondary-&gt;thread;</span>
<span class="p_add">+</span>
<span class="p_add">+		new-&gt;secondary-&gt;thread = NULL;</span>
<span class="p_add">+		kthread_stop(t);</span>
<span class="p_add">+		put_task_struct(t);</span>
<span class="p_add">+	}</span>
 out_mput:
 	module_put(desc-&gt;owner);
 	return ret;
<span class="p_chunk">@@ -1489,9 +1558,14 @@</span> <span class="p_context"> static struct irqaction *__free_irq(unsigned int irq, void *dev_id)</span>
 	if (action-&gt;thread) {
 		kthread_stop(action-&gt;thread);
 		put_task_struct(action-&gt;thread);
<span class="p_add">+		if (action-&gt;secondary &amp;&amp; action-&gt;secondary-&gt;thread) {</span>
<span class="p_add">+			kthread_stop(action-&gt;secondary-&gt;thread);</span>
<span class="p_add">+			put_task_struct(action-&gt;secondary-&gt;thread);</span>
<span class="p_add">+		}</span>
 	}
 
 	module_put(desc-&gt;owner);
<span class="p_add">+	kfree(action-&gt;secondary);</span>
 	return action;
 }
 
<span class="p_chunk">@@ -1635,8 +1709,10 @@</span> <span class="p_context"> int request_threaded_irq(unsigned int irq, irq_handler_t handler,</span>
 	retval = __setup_irq(irq, desc, action);
 	chip_bus_sync_unlock(desc);
 
<span class="p_del">-	if (retval)</span>
<span class="p_add">+	if (retval) {</span>
<span class="p_add">+		kfree(action-&gt;secondary);</span>
 		kfree(action);
<span class="p_add">+	}</span>
 
 #ifdef CONFIG_DEBUG_SHIRQ_FIXME
 	if (!retval &amp;&amp; (irqflags &amp; IRQF_SHARED)) {
<span class="p_header">diff --git a/kernel/trace/trace_irqsoff.c b/kernel/trace/trace_irqsoff.c</span>
<span class="p_header">index aaade2efc560..d0e1d0e48640 100644</span>
<span class="p_header">--- a/kernel/trace/trace_irqsoff.c</span>
<span class="p_header">+++ b/kernel/trace/trace_irqsoff.c</span>
<span class="p_chunk">@@ -450,7 +450,7 @@</span> <span class="p_context"> EXPORT_SYMBOL_GPL(stop_critical_timings);</span>
 #ifdef CONFIG_PROVE_LOCKING
 void time_hardirqs_on(unsigned long a0, unsigned long a1)
 {
<span class="p_del">-	trace_preemptirqsoff_hist(IRQS_ON, 0);</span>
<span class="p_add">+	trace_preemptirqsoff_hist_rcuidle(IRQS_ON, 0);</span>
 	if (!preempt_trace() &amp;&amp; irq_trace())
 		stop_critical_timing(a0, a1);
 }
<span class="p_chunk">@@ -459,7 +459,7 @@</span> <span class="p_context"> void time_hardirqs_off(unsigned long a0, unsigned long a1)</span>
 {
 	if (!preempt_trace() &amp;&amp; irq_trace())
 		start_critical_timing(a0, a1);
<span class="p_del">-	trace_preemptirqsoff_hist(IRQS_OFF, 1);</span>
<span class="p_add">+	trace_preemptirqsoff_hist_rcuidle(IRQS_OFF, 1);</span>
 }
 
 #else /* !CONFIG_PROVE_LOCKING */
<span class="p_header">diff --git a/localversion-rt b/localversion-rt</span>
<span class="p_header">index 045478966e9f..700c857efd9b 100644</span>
<span class="p_header">--- a/localversion-rt</span>
<span class="p_header">+++ b/localversion-rt</span>
<span class="p_chunk">@@ -1 +1 @@</span> <span class="p_context"></span>
<span class="p_del">--rt7</span>
<span class="p_add">+-rt8</span>

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



