
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>[3/3] IPI: Avoid to use 2 cache lines for one call_single_data - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    [3/3] IPI: Avoid to use 2 cache lines for one call_single_data</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=137">Peter Zijlstra</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>Aug. 3, 2017, 8:57 a.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;20170803085752.yrqox3kwrvkj544a@hirez.programming.kicks-ass.net&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/9878489/mbox/"
   >mbox</a>
|
   <a href="/patch/9878489/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/9878489/">/patch/9878489/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
	[172.30.200.125])
	by pdx-korg-patchwork.web.codeaurora.org (Postfix) with ESMTP id
	988D4603B4 for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Thu,  3 Aug 2017 08:58:10 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 7A17F2888E
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Thu,  3 Aug 2017 08:58:10 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id 6E996288A0; Thu,  3 Aug 2017 08:58:10 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-6.8 required=2.0 tests=BAYES_00,DKIM_SIGNED,
	RCVD_IN_DNSWL_HI,T_DKIM_INVALID autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 5F6B62888E
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Thu,  3 Aug 2017 08:58:09 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1751883AbdHCI6F (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Thu, 3 Aug 2017 04:58:05 -0400
Received: from bombadil.infradead.org ([65.50.211.133]:59056 &quot;EHLO
	bombadil.infradead.org&quot; rhost-flags-OK-OK-OK-OK) by vger.kernel.org
	with ESMTP id S1751251AbdHCI6C (ORCPT
	&lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Thu, 3 Aug 2017 04:58:02 -0400
DKIM-Signature: v=1; a=rsa-sha256; q=dns/txt; c=relaxed/relaxed;
	d=infradead.org; s=bombadil.20170209;
	h=In-Reply-To:Content-Type:MIME-Version
	:References:Message-ID:Subject:Cc:To:From:Date:Sender:Reply-To:
	Content-Transfer-Encoding:Content-ID:Content-Description:Resent-Date:
	Resent-From:Resent-Sender:Resent-To:Resent-Cc:Resent-Message-ID:List-Id:
	List-Help:List-Unsubscribe:List-Subscribe:List-Post:List-Owner:List-Archive;
	bh=MVAsHvmdOFO9nEX67Kguh+qkT3Mhh0Hd5pt9GQ1S1u8=;
	b=pcG68t0Wk3sgp71WlOIMXdNvT
	N40jYUigdsJ7uvy6dtKAWkyxG0ZA0blXUFhHwl/GmyHN+/vKK8IHzvHGJZy5OVEpgQm+Vc/1T9tpp
	EyOO+SIHTDZl7+ogq3hJjCwewxdO92PNDeqIPb+518vB+KOP9NnfQtVNW4aubAxodpznEvUdpvouD
	R28KULqI8J0lctbYIWqqEScF2CAq2sPWo2r5TTiNVBMCFuSufCyaXDxcjqj6nVdrBpKClvkV1LD0F
	GzKj7lPwU7HMGMzI7VlaebL5PCV5q/ekl1E/sq2PCQULCHTwGRh7MucX5oI8gMYYYTA4Ngfz6qRCh
	1+pAkmdbw==;
Received: from j217100.upc-j.chello.nl ([24.132.217.100]
	helo=hirez.programming.kicks-ass.net)
	by bombadil.infradead.org with esmtpsa (Exim 4.87 #1 (Red Hat Linux))
	id 1ddBx4-0000rm-CF; Thu, 03 Aug 2017 08:57:54 +0000
Received: by hirez.programming.kicks-ass.net (Postfix, from userid 1000)
	id 7835520197470; Thu,  3 Aug 2017 10:57:52 +0200 (CEST)
Date: Thu, 3 Aug 2017 10:57:52 +0200
From: Peter Zijlstra &lt;peterz@infradead.org&gt;
To: &quot;Huang, Ying&quot; &lt;ying.huang@intel.com&gt;
Cc: Eric Dumazet &lt;eric.dumazet@gmail.com&gt;,
	linux-kernel@vger.kernel.org, Ingo Molnar &lt;mingo@kernel.org&gt;,
	Michael Ellerman &lt;mpe@ellerman.id.au&gt;, Borislav Petkov &lt;bp@suse.de&gt;,
	Thomas Gleixner &lt;tglx@linutronix.de&gt;,
	Juergen Gross &lt;jgross@suse.com&gt;, Aaron Lu &lt;aaron.lu@intel.com&gt;
Subject: Re: [PATCH 3/3] IPI: Avoid to use 2 cache lines for one
	call_single_data
Message-ID: &lt;20170803085752.yrqox3kwrvkj544a@hirez.programming.kicks-ass.net&gt;
References: &lt;20170802085220.4315-1-ying.huang@intel.com&gt;
	&lt;20170802085220.4315-4-ying.huang@intel.com&gt;
	&lt;1501669138.25002.20.camel@edumazet-glaptop3.roam.corp.google.com&gt;
	&lt;87d18d122e.fsf@yhuang-dev.intel.com&gt;
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Disposition: inline
In-Reply-To: &lt;87d18d122e.fsf@yhuang-dev.intel.com&gt;
User-Agent: NeoMutt/20170609 (1.8.3)
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=137">Peter Zijlstra</a> - Aug. 3, 2017, 8:57 a.m.</div>
<pre class="content">
On Thu, Aug 03, 2017 at 04:35:21PM +0800, Huang, Ying wrote:
<span class="quote">&gt; diff --git a/include/linux/smp.h b/include/linux/smp.h</span>
<span class="quote">&gt; index 68123c1fe549..4d3b372d50b0 100644</span>
<span class="quote">&gt; --- a/include/linux/smp.h</span>
<span class="quote">&gt; +++ b/include/linux/smp.h</span>
<span class="quote">&gt; @@ -13,13 +13,22 @@</span>
<span class="quote">&gt;  #include &lt;linux/init.h&gt;</span>
<span class="quote">&gt;  #include &lt;linux/llist.h&gt;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; +#define CSD_ALIGNMENT	(4 * sizeof(void *))</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt;  typedef void (*smp_call_func_t)(void *info);</span>
<span class="quote">&gt;  struct call_single_data {</span>
<span class="quote">&gt;  	struct llist_node llist;</span>
<span class="quote">&gt;  	smp_call_func_t func;</span>
<span class="quote">&gt;  	void *info;</span>
<span class="quote">&gt;  	unsigned int flags;</span>
<span class="quote">&gt; -};</span>
<span class="quote">&gt; +} __aligned(CSD_ALIGNMENT);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +/* To avoid allocate csd across 2 cache lines */</span>
<span class="quote">&gt; +static inline void check_alignment_of_csd(void)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	BUILD_BUG_ON((CSD_ALIGNMENT &amp; (CSD_ALIGNMENT - 1)) != 0);</span>
<span class="quote">&gt; +	BUILD_BUG_ON(sizeof(struct call_single_data) &gt; CSD_ALIGNMENT);</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  /* total number of cpus in this system (may exceed NR_CPUS) */</span>
<span class="quote">&gt;  extern unsigned int total_cpus;</span>

Bah, C sucks.. a much larger but possibly nicer patch 

---
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=294">Huang Ying</a> - Aug. 4, 2017, 1:28 a.m.</div>
<pre class="content">
Peter Zijlstra &lt;peterz@infradead.org&gt; writes:
[snip]
<span class="quote">&gt; diff --git a/include/linux/smp.h b/include/linux/smp.h</span>
<span class="quote">&gt; index 68123c1fe549..8d817cb80a38 100644</span>
<span class="quote">&gt; --- a/include/linux/smp.h</span>
<span class="quote">&gt; +++ b/include/linux/smp.h</span>
<span class="quote">&gt; @@ -14,13 +14,16 @@</span>
<span class="quote">&gt;  #include &lt;linux/llist.h&gt;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  typedef void (*smp_call_func_t)(void *info);</span>
<span class="quote">&gt; -struct call_single_data {</span>
<span class="quote">&gt; +struct __call_single_data {</span>
<span class="quote">&gt;  	struct llist_node llist;</span>
<span class="quote">&gt;  	smp_call_func_t func;</span>
<span class="quote">&gt;  	void *info;</span>
<span class="quote">&gt;  	unsigned int flags;</span>
<span class="quote">&gt;  };</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; +typedef struct __call_single_data call_single_data_t</span>
<span class="quote">&gt; +	__aligned(sizeof(struct __call_single_data));</span>
<span class="quote">&gt; +</span>

Another requirement of the alignment is that it should be the power of
2.  Otherwise, for example, if someone adds a field to struct, so that
the size becomes 40 on x86_64.  The alignment should be 64 instead of
40.

Best Regards,
Huang, Ying
<span class="quote">
&gt;  /* total number of cpus in this system (may exceed NR_CPUS) */</span>
<span class="quote">&gt;  extern unsigned int total_cpus;</span>
<span class="quote">&gt;  </span>
[snip]
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=294">Huang Ying</a> - Aug. 4, 2017, 2:05 a.m.</div>
<pre class="content">
&quot;Huang, Ying&quot; &lt;ying.huang@intel.com&gt; writes:
<span class="quote">
&gt; Peter Zijlstra &lt;peterz@infradead.org&gt; writes:</span>
<span class="quote">&gt; [snip]</span>
<span class="quote">&gt;&gt; diff --git a/include/linux/smp.h b/include/linux/smp.h</span>
<span class="quote">&gt;&gt; index 68123c1fe549..8d817cb80a38 100644</span>
<span class="quote">&gt;&gt; --- a/include/linux/smp.h</span>
<span class="quote">&gt;&gt; +++ b/include/linux/smp.h</span>
<span class="quote">&gt;&gt; @@ -14,13 +14,16 @@</span>
<span class="quote">&gt;&gt;  #include &lt;linux/llist.h&gt;</span>
<span class="quote">&gt;&gt;  </span>
<span class="quote">&gt;&gt;  typedef void (*smp_call_func_t)(void *info);</span>
<span class="quote">&gt;&gt; -struct call_single_data {</span>
<span class="quote">&gt;&gt; +struct __call_single_data {</span>
<span class="quote">&gt;&gt;  	struct llist_node llist;</span>
<span class="quote">&gt;&gt;  	smp_call_func_t func;</span>
<span class="quote">&gt;&gt;  	void *info;</span>
<span class="quote">&gt;&gt;  	unsigned int flags;</span>
<span class="quote">&gt;&gt;  };</span>
<span class="quote">&gt;&gt;  </span>
<span class="quote">&gt;&gt; +typedef struct __call_single_data call_single_data_t</span>
<span class="quote">&gt;&gt; +	__aligned(sizeof(struct __call_single_data));</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; Another requirement of the alignment is that it should be the power of</span>
<span class="quote">&gt; 2.  Otherwise, for example, if someone adds a field to struct, so that</span>
<span class="quote">&gt; the size becomes 40 on x86_64.  The alignment should be 64 instead of</span>
<span class="quote">&gt; 40.</span>

Thanks Aaron, he reminded me that there is a roundup_pow_of_two().  So
the typedef could be,

typedef struct __call_single_data call_single_data_t
	__aligned(roundup_pow_of_two(sizeof(struct __call_single_data));

Best Regards,
Huang, Ying
<span class="quote">
&gt; Best Regards,</span>
<span class="quote">&gt; Huang, Ying</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;&gt;  /* total number of cpus in this system (may exceed NR_CPUS) */</span>
<span class="quote">&gt;&gt;  extern unsigned int total_cpus;</span>
<span class="quote">&gt;&gt;  </span>
<span class="quote">&gt; [snip]</span>
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=137">Peter Zijlstra</a> - Aug. 4, 2017, 9:20 a.m.</div>
<pre class="content">
On Fri, Aug 04, 2017 at 09:28:17AM +0800, Huang, Ying wrote:
<span class="quote">&gt; Peter Zijlstra &lt;peterz@infradead.org&gt; writes:</span>
<span class="quote">&gt; [snip]</span>
<span class="quote">&gt; &gt; diff --git a/include/linux/smp.h b/include/linux/smp.h</span>
<span class="quote">&gt; &gt; index 68123c1fe549..8d817cb80a38 100644</span>
<span class="quote">&gt; &gt; --- a/include/linux/smp.h</span>
<span class="quote">&gt; &gt; +++ b/include/linux/smp.h</span>
<span class="quote">&gt; &gt; @@ -14,13 +14,16 @@</span>
<span class="quote">&gt; &gt;  #include &lt;linux/llist.h&gt;</span>
<span class="quote">&gt; &gt;  </span>
<span class="quote">&gt; &gt;  typedef void (*smp_call_func_t)(void *info);</span>
<span class="quote">&gt; &gt; -struct call_single_data {</span>
<span class="quote">&gt; &gt; +struct __call_single_data {</span>
<span class="quote">&gt; &gt;  	struct llist_node llist;</span>
<span class="quote">&gt; &gt;  	smp_call_func_t func;</span>
<span class="quote">&gt; &gt;  	void *info;</span>
<span class="quote">&gt; &gt;  	unsigned int flags;</span>
<span class="quote">&gt; &gt;  };</span>
<span class="quote">&gt; &gt;  </span>
<span class="quote">&gt; &gt; +typedef struct __call_single_data call_single_data_t</span>
<span class="quote">&gt; &gt; +	__aligned(sizeof(struct __call_single_data));</span>
<span class="quote">&gt; &gt; +</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Another requirement of the alignment is that it should be the power of</span>
<span class="quote">&gt; 2.  Otherwise, for example, if someone adds a field to struct, so that</span>
<span class="quote">&gt; the size becomes 40 on x86_64.  The alignment should be 64 instead of</span>
<span class="quote">&gt; 40.</span>

Yes I know. This generates a compiler error if sizeof() isn&#39;t a
power of 2. That&#39;s similar to the BUILD_BUG_ON() you added.
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=137">Peter Zijlstra</a> - Aug. 4, 2017, 9:27 a.m.</div>
<pre class="content">
On Fri, Aug 04, 2017 at 10:05:55AM +0800, Huang, Ying wrote:
<span class="quote">&gt; &quot;Huang, Ying&quot; &lt;ying.huang@intel.com&gt; writes:</span>
<span class="quote">&gt; &gt; Peter Zijlstra &lt;peterz@infradead.org&gt; writes:</span>
<span class="quote">
&gt; &gt;&gt; +struct __call_single_data {</span>
<span class="quote">&gt; &gt;&gt;  	struct llist_node llist;</span>
<span class="quote">&gt; &gt;&gt;  	smp_call_func_t func;</span>
<span class="quote">&gt; &gt;&gt;  	void *info;</span>
<span class="quote">&gt; &gt;&gt;  	unsigned int flags;</span>
<span class="quote">&gt; &gt;&gt;  };</span>
<span class="quote">&gt; &gt;&gt;  </span>
<span class="quote">&gt; &gt;&gt; +typedef struct __call_single_data call_single_data_t</span>
<span class="quote">&gt; &gt;&gt; +	__aligned(sizeof(struct __call_single_data));</span>
<span class="quote">&gt; &gt;&gt; +</span>
<span class="quote">&gt; &gt;</span>
<span class="quote">&gt; &gt; Another requirement of the alignment is that it should be the power of</span>
<span class="quote">&gt; &gt; 2.  Otherwise, for example, if someone adds a field to struct, so that</span>
<span class="quote">&gt; &gt; the size becomes 40 on x86_64.  The alignment should be 64 instead of</span>
<span class="quote">&gt; &gt; 40.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Thanks Aaron, he reminded me that there is a roundup_pow_of_two().  So</span>
<span class="quote">&gt; the typedef could be,</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; typedef struct __call_single_data call_single_data_t</span>
<span class="quote">&gt; 	__aligned(roundup_pow_of_two(sizeof(struct __call_single_data));</span>
<span class="quote">&gt; </span>

Yes, that would take away the requirement to play padding games with the
struct. Then again, maybe its a good thing to have to be explicit about
it.

If you see:

struct __call_single_data {
	struct llist_node llist;
	smp_call_func_t func;
	void *info
	int flags;
	void *extra_field;

	unsigned long __padding[3]; /* make align work */
};

that makes it very clear what is going on. In any case, we can delay
this part because the current structure is a power-of-2 for both ILP32
and LP64. So only the person growing this will have to deal with it ;-)
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=294">Huang Ying</a> - Aug. 5, 2017, 12:47 a.m.</div>
<pre class="content">
Peter Zijlstra &lt;peterz@infradead.org&gt; writes:
<span class="quote">
&gt; On Fri, Aug 04, 2017 at 10:05:55AM +0800, Huang, Ying wrote:</span>
<span class="quote">&gt;&gt; &quot;Huang, Ying&quot; &lt;ying.huang@intel.com&gt; writes:</span>
<span class="quote">&gt;&gt; &gt; Peter Zijlstra &lt;peterz@infradead.org&gt; writes:</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;&gt; &gt;&gt; +struct __call_single_data {</span>
<span class="quote">&gt;&gt; &gt;&gt;  	struct llist_node llist;</span>
<span class="quote">&gt;&gt; &gt;&gt;  	smp_call_func_t func;</span>
<span class="quote">&gt;&gt; &gt;&gt;  	void *info;</span>
<span class="quote">&gt;&gt; &gt;&gt;  	unsigned int flags;</span>
<span class="quote">&gt;&gt; &gt;&gt;  };</span>
<span class="quote">&gt;&gt; &gt;&gt;  </span>
<span class="quote">&gt;&gt; &gt;&gt; +typedef struct __call_single_data call_single_data_t</span>
<span class="quote">&gt;&gt; &gt;&gt; +	__aligned(sizeof(struct __call_single_data));</span>
<span class="quote">&gt;&gt; &gt;&gt; +</span>
<span class="quote">&gt;&gt; &gt;</span>
<span class="quote">&gt;&gt; &gt; Another requirement of the alignment is that it should be the power of</span>
<span class="quote">&gt;&gt; &gt; 2.  Otherwise, for example, if someone adds a field to struct, so that</span>
<span class="quote">&gt;&gt; &gt; the size becomes 40 on x86_64.  The alignment should be 64 instead of</span>
<span class="quote">&gt;&gt; &gt; 40.</span>
<span class="quote">&gt;&gt; </span>
<span class="quote">&gt;&gt; Thanks Aaron, he reminded me that there is a roundup_pow_of_two().  So</span>
<span class="quote">&gt;&gt; the typedef could be,</span>
<span class="quote">&gt;&gt; </span>
<span class="quote">&gt;&gt; typedef struct __call_single_data call_single_data_t</span>
<span class="quote">&gt;&gt; 	__aligned(roundup_pow_of_two(sizeof(struct __call_single_data));</span>
<span class="quote">&gt;&gt; </span>
<span class="quote">&gt;</span>
<span class="quote">&gt; Yes, that would take away the requirement to play padding games with the</span>
<span class="quote">&gt; struct. Then again, maybe its a good thing to have to be explicit about</span>
<span class="quote">&gt; it.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; If you see:</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; struct __call_single_data {</span>
<span class="quote">&gt; 	struct llist_node llist;</span>
<span class="quote">&gt; 	smp_call_func_t func;</span>
<span class="quote">&gt; 	void *info</span>
<span class="quote">&gt; 	int flags;</span>
<span class="quote">&gt; 	void *extra_field;</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; 	unsigned long __padding[3]; /* make align work */</span>
<span class="quote">&gt; };</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; that makes it very clear what is going on. In any case, we can delay</span>
<span class="quote">&gt; this part because the current structure is a power-of-2 for both ILP32</span>
<span class="quote">&gt; and LP64. So only the person growing this will have to deal with it ;-)</span>

Yes.  That looks good.  So you will prepare the final patch?  Or you
hope me to do that?

Best Regards,
Huang, Ying
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=137">Peter Zijlstra</a> - Aug. 7, 2017, 8:28 a.m.</div>
<pre class="content">
On Sat, Aug 05, 2017 at 08:47:02AM +0800, Huang, Ying wrote:
<span class="quote">&gt; Yes.  That looks good.  So you will prepare the final patch?  Or you</span>
<span class="quote">&gt; hope me to do that?</span>

I was hoping you&#39;d do it ;-)
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/arch/mips/kernel/smp.c b/arch/mips/kernel/smp.c</span>
<span class="p_header">index 770d4d1516cb..bd8ba5472bca 100644</span>
<span class="p_header">--- a/arch/mips/kernel/smp.c</span>
<span class="p_header">+++ b/arch/mips/kernel/smp.c</span>
<span class="p_chunk">@@ -648,12 +648,12 @@</span> <span class="p_context"> EXPORT_SYMBOL(flush_tlb_one);</span>
 #ifdef CONFIG_GENERIC_CLOCKEVENTS_BROADCAST
 
 static DEFINE_PER_CPU(atomic_t, tick_broadcast_count);
<span class="p_del">-static DEFINE_PER_CPU(struct call_single_data, tick_broadcast_csd);</span>
<span class="p_add">+static DEFINE_PER_CPU(call_single_data_t, tick_broadcast_csd);</span>
 
 void tick_broadcast(const struct cpumask *mask)
 {
 	atomic_t *count;
<span class="p_del">-	struct call_single_data *csd;</span>
<span class="p_add">+	call_single_data_t *csd;</span>
 	int cpu;
 
 	for_each_cpu(cpu, mask) {
<span class="p_chunk">@@ -674,7 +674,7 @@</span> <span class="p_context"> static void tick_broadcast_callee(void *info)</span>
 
 static int __init tick_broadcast_init(void)
 {
<span class="p_del">-	struct call_single_data *csd;</span>
<span class="p_add">+	call_single_data_t *csd;</span>
 	int cpu;
 
 	for (cpu = 0; cpu &lt; NR_CPUS; cpu++) {
<span class="p_header">diff --git a/block/blk-softirq.c b/block/blk-softirq.c</span>
<span class="p_header">index 87b7df4851bf..07125e7941f4 100644</span>
<span class="p_header">--- a/block/blk-softirq.c</span>
<span class="p_header">+++ b/block/blk-softirq.c</span>
<span class="p_chunk">@@ -60,7 +60,7 @@</span> <span class="p_context"> static void trigger_softirq(void *data)</span>
 static int raise_blk_irq(int cpu, struct request *rq)
 {
 	if (cpu_online(cpu)) {
<span class="p_del">-		struct call_single_data *data = &amp;rq-&gt;csd;</span>
<span class="p_add">+		call_single_data_t *data = &amp;rq-&gt;csd;</span>
 
 		data-&gt;func = trigger_softirq;
 		data-&gt;info = rq;
<span class="p_header">diff --git a/drivers/block/null_blk.c b/drivers/block/null_blk.c</span>
<span class="p_header">index 85c24cace973..81142ce781da 100644</span>
<span class="p_header">--- a/drivers/block/null_blk.c</span>
<span class="p_header">+++ b/drivers/block/null_blk.c</span>
<span class="p_chunk">@@ -13,7 +13,7 @@</span> <span class="p_context"></span>
 struct nullb_cmd {
 	struct list_head list;
 	struct llist_node ll_list;
<span class="p_del">-	struct call_single_data csd;</span>
<span class="p_add">+	call_single_data_t csd;</span>
 	struct request *rq;
 	struct bio *bio;
 	unsigned int tag;
<span class="p_header">diff --git a/drivers/cpuidle/coupled.c b/drivers/cpuidle/coupled.c</span>
<span class="p_header">index 71e586d7df71..e54be79b2084 100644</span>
<span class="p_header">--- a/drivers/cpuidle/coupled.c</span>
<span class="p_header">+++ b/drivers/cpuidle/coupled.c</span>
<span class="p_chunk">@@ -119,7 +119,7 @@</span> <span class="p_context"> struct cpuidle_coupled {</span>
 
 #define CPUIDLE_COUPLED_NOT_IDLE	(-1)
 
<span class="p_del">-static DEFINE_PER_CPU(struct call_single_data, cpuidle_coupled_poke_cb);</span>
<span class="p_add">+static DEFINE_PER_CPU(call_single_data_t, cpuidle_coupled_poke_cb);</span>
 
 /*
  * The cpuidle_coupled_poke_pending mask is used to avoid calling
<span class="p_chunk">@@ -339,7 +339,7 @@</span> <span class="p_context"> static void cpuidle_coupled_handle_poke(void *info)</span>
  */
 static void cpuidle_coupled_poke(int cpu)
 {
<span class="p_del">-	struct call_single_data *csd = &amp;per_cpu(cpuidle_coupled_poke_cb, cpu);</span>
<span class="p_add">+	call_single_data_t *csd = &amp;per_cpu(cpuidle_coupled_poke_cb, cpu);</span>
 
 	if (!cpumask_test_and_set_cpu(cpu, &amp;cpuidle_coupled_poke_pending))
 		smp_call_function_single_async(cpu, csd);
<span class="p_chunk">@@ -651,7 +651,7 @@</span> <span class="p_context"> int cpuidle_coupled_register_device(struct cpuidle_device *dev)</span>
 {
 	int cpu;
 	struct cpuidle_device *other_dev;
<span class="p_del">-	struct call_single_data *csd;</span>
<span class="p_add">+	call_single_data_t *csd;</span>
 	struct cpuidle_coupled *coupled;
 
 	if (cpumask_empty(&amp;dev-&gt;coupled_cpus))
<span class="p_header">diff --git a/drivers/net/ethernet/cavium/liquidio/lio_main.c b/drivers/net/ethernet/cavium/liquidio/lio_main.c</span>
<span class="p_header">index 51583ae4b1eb..120b6e537b28 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/cavium/liquidio/lio_main.c</span>
<span class="p_header">+++ b/drivers/net/ethernet/cavium/liquidio/lio_main.c</span>
<span class="p_chunk">@@ -2468,7 +2468,7 @@</span> <span class="p_context"> static void liquidio_napi_drv_callback(void *arg)</span>
 	if (OCTEON_CN23XX_PF(oct) || droq-&gt;cpu_id == this_cpu) {
 		napi_schedule_irqoff(&amp;droq-&gt;napi);
 	} else {
<span class="p_del">-		struct call_single_data *csd = &amp;droq-&gt;csd;</span>
<span class="p_add">+		call_single_data_t *csd = &amp;droq-&gt;csd;</span>
 
 		csd-&gt;func = napi_schedule_wrapper;
 		csd-&gt;info = &amp;droq-&gt;napi;
<span class="p_header">diff --git a/drivers/net/ethernet/cavium/liquidio/octeon_droq.h b/drivers/net/ethernet/cavium/liquidio/octeon_droq.h</span>
<span class="p_header">index 6efd139b894d..f91bc84d1719 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/cavium/liquidio/octeon_droq.h</span>
<span class="p_header">+++ b/drivers/net/ethernet/cavium/liquidio/octeon_droq.h</span>
<span class="p_chunk">@@ -328,7 +328,7 @@</span> <span class="p_context"> struct octeon_droq {</span>
 
 	u32 cpu_id;
 
<span class="p_del">-	struct call_single_data csd;</span>
<span class="p_add">+	call_single_data_t csd;</span>
 };
 
 #define OCT_DROQ_SIZE   (sizeof(struct octeon_droq))
<span class="p_header">diff --git a/include/linux/blkdev.h b/include/linux/blkdev.h</span>
<span class="p_header">index 25f6a0cb27d3..006fa09a641e 100644</span>
<span class="p_header">--- a/include/linux/blkdev.h</span>
<span class="p_header">+++ b/include/linux/blkdev.h</span>
<span class="p_chunk">@@ -134,7 +134,7 @@</span> <span class="p_context"> typedef __u32 __bitwise req_flags_t;</span>
 struct request {
 	struct list_head queuelist;
 	union {
<span class="p_del">-		struct call_single_data csd;</span>
<span class="p_add">+		call_single_data_t csd;</span>
 		u64 fifo_time;
 	};
 
<span class="p_header">diff --git a/include/linux/netdevice.h b/include/linux/netdevice.h</span>
<span class="p_header">index 779b23595596..6557f320b66e 100644</span>
<span class="p_header">--- a/include/linux/netdevice.h</span>
<span class="p_header">+++ b/include/linux/netdevice.h</span>
<span class="p_chunk">@@ -2774,7 +2774,7 @@</span> <span class="p_context"> struct softnet_data {</span>
 	unsigned int		input_queue_head ____cacheline_aligned_in_smp;
 
 	/* Elements below can be accessed between CPUs for RPS/RFS */
<span class="p_del">-	struct call_single_data	csd ____cacheline_aligned_in_smp;</span>
<span class="p_add">+	call_single_data_t	csd ____cacheline_aligned_in_smp;</span>
 	struct softnet_data	*rps_ipi_next;
 	unsigned int		cpu;
 	unsigned int		input_queue_tail;
<span class="p_header">diff --git a/include/linux/smp.h b/include/linux/smp.h</span>
<span class="p_header">index 68123c1fe549..8d817cb80a38 100644</span>
<span class="p_header">--- a/include/linux/smp.h</span>
<span class="p_header">+++ b/include/linux/smp.h</span>
<span class="p_chunk">@@ -14,13 +14,16 @@</span> <span class="p_context"></span>
 #include &lt;linux/llist.h&gt;
 
 typedef void (*smp_call_func_t)(void *info);
<span class="p_del">-struct call_single_data {</span>
<span class="p_add">+struct __call_single_data {</span>
 	struct llist_node llist;
 	smp_call_func_t func;
 	void *info;
 	unsigned int flags;
 };
 
<span class="p_add">+typedef struct __call_single_data call_single_data_t</span>
<span class="p_add">+	__aligned(sizeof(struct __call_single_data));</span>
<span class="p_add">+</span>
 /* total number of cpus in this system (may exceed NR_CPUS) */
 extern unsigned int total_cpus;
 
<span class="p_chunk">@@ -48,7 +51,7 @@</span> <span class="p_context"> void on_each_cpu_cond(bool (*cond_func)(int cpu, void *info),</span>
 		smp_call_func_t func, void *info, bool wait,
 		gfp_t gfp_flags);
 
<span class="p_del">-int smp_call_function_single_async(int cpu, struct call_single_data *csd);</span>
<span class="p_add">+int smp_call_function_single_async(int cpu, call_single_data_t *csd);</span>
 
 #ifdef CONFIG_SMP
 
<span class="p_header">diff --git a/kernel/sched/sched.h b/kernel/sched/sched.h</span>
<span class="p_header">index b2f9c9f7c0ee..39f9cc47eb1c 100644</span>
<span class="p_header">--- a/kernel/sched/sched.h</span>
<span class="p_header">+++ b/kernel/sched/sched.h</span>
<span class="p_chunk">@@ -769,7 +769,7 @@</span> <span class="p_context"> struct rq {</span>
 #ifdef CONFIG_SCHED_HRTICK
 #ifdef CONFIG_SMP
 	int hrtick_csd_pending;
<span class="p_del">-	struct call_single_data hrtick_csd;</span>
<span class="p_add">+	call_single_data_t hrtick_csd;</span>
 #endif
 	struct hrtimer hrtick_timer;
 #endif
<span class="p_header">diff --git a/kernel/smp.c b/kernel/smp.c</span>
<span class="p_header">index 3061483cb3ad..1fb84b6db429 100644</span>
<span class="p_header">--- a/kernel/smp.c</span>
<span class="p_header">+++ b/kernel/smp.c</span>
<span class="p_chunk">@@ -28,7 +28,7 @@</span> <span class="p_context"> enum {</span>
 };
 
 struct call_function_data {
<span class="p_del">-	struct call_single_data	__percpu *csd;</span>
<span class="p_add">+	call_single_data_t	__percpu *csd;</span>
 	cpumask_var_t		cpumask;
 	cpumask_var_t		cpumask_ipi;
 };
<span class="p_chunk">@@ -51,7 +51,7 @@</span> <span class="p_context"> int smpcfd_prepare_cpu(unsigned int cpu)</span>
 		free_cpumask_var(cfd-&gt;cpumask);
 		return -ENOMEM;
 	}
<span class="p_del">-	cfd-&gt;csd = alloc_percpu(struct call_single_data);</span>
<span class="p_add">+	cfd-&gt;csd = alloc_percpu(call_single_data_t);</span>
 	if (!cfd-&gt;csd) {
 		free_cpumask_var(cfd-&gt;cpumask);
 		free_cpumask_var(cfd-&gt;cpumask_ipi);
<span class="p_chunk">@@ -103,12 +103,12 @@</span> <span class="p_context"> void __init call_function_init(void)</span>
  * previous function call. For multi-cpu calls its even more interesting
  * as we&#39;ll have to ensure no other cpu is observing our csd.
  */
<span class="p_del">-static __always_inline void csd_lock_wait(struct call_single_data *csd)</span>
<span class="p_add">+static __always_inline void csd_lock_wait(call_single_data_t *csd)</span>
 {
 	smp_cond_load_acquire(&amp;csd-&gt;flags, !(VAL &amp; CSD_FLAG_LOCK));
 }
 
<span class="p_del">-static __always_inline void csd_lock(struct call_single_data *csd)</span>
<span class="p_add">+static __always_inline void csd_lock(call_single_data_t *csd)</span>
 {
 	csd_lock_wait(csd);
 	csd-&gt;flags |= CSD_FLAG_LOCK;
<span class="p_chunk">@@ -121,7 +121,7 @@</span> <span class="p_context"> static __always_inline void csd_lock(struct call_single_data *csd)</span>
 	smp_wmb();
 }
 
<span class="p_del">-static __always_inline void csd_unlock(struct call_single_data *csd)</span>
<span class="p_add">+static __always_inline void csd_unlock(call_single_data_t *csd)</span>
 {
 	WARN_ON(!(csd-&gt;flags &amp; CSD_FLAG_LOCK));
 
<span class="p_chunk">@@ -131,14 +131,14 @@</span> <span class="p_context"> static __always_inline void csd_unlock(struct call_single_data *csd)</span>
 	smp_store_release(&amp;csd-&gt;flags, 0);
 }
 
<span class="p_del">-static DEFINE_PER_CPU_SHARED_ALIGNED(struct call_single_data, csd_data);</span>
<span class="p_add">+static DEFINE_PER_CPU_SHARED_ALIGNED(call_single_data_t, csd_data);</span>
 
 /*
  * Insert a previously allocated call_single_data element
  * for execution on the given CPU. data must already have
  * -&gt;func, -&gt;info, and -&gt;flags set.
  */
<span class="p_del">-static int generic_exec_single(int cpu, struct call_single_data *csd,</span>
<span class="p_add">+static int generic_exec_single(int cpu, call_single_data_t *csd,</span>
 			       smp_call_func_t func, void *info)
 {
 	if (cpu == smp_processor_id()) {
<span class="p_chunk">@@ -210,7 +210,7 @@</span> <span class="p_context"> static void flush_smp_call_function_queue(bool warn_cpu_offline)</span>
 {
 	struct llist_head *head;
 	struct llist_node *entry;
<span class="p_del">-	struct call_single_data *csd, *csd_next;</span>
<span class="p_add">+	call_single_data_t *csd, *csd_next;</span>
 	static bool warned;
 
 	WARN_ON(!irqs_disabled());
<span class="p_chunk">@@ -268,8 +268,8 @@</span> <span class="p_context"> static void flush_smp_call_function_queue(bool warn_cpu_offline)</span>
 int smp_call_function_single(int cpu, smp_call_func_t func, void *info,
 			     int wait)
 {
<span class="p_del">-	struct call_single_data *csd;</span>
<span class="p_del">-	struct call_single_data csd_stack = { .flags = CSD_FLAG_LOCK | CSD_FLAG_SYNCHRONOUS };</span>
<span class="p_add">+	call_single_data_t *csd;</span>
<span class="p_add">+	call_single_data_t csd_stack = { .flags = CSD_FLAG_LOCK | CSD_FLAG_SYNCHRONOUS };</span>
 	int this_cpu;
 	int err;
 
<span class="p_chunk">@@ -321,7 +321,7 @@</span> <span class="p_context"> EXPORT_SYMBOL(smp_call_function_single);</span>
  * NOTE: Be careful, there is unfortunately no current debugging facility to
  * validate the correctness of this serialization.
  */
<span class="p_del">-int smp_call_function_single_async(int cpu, struct call_single_data *csd)</span>
<span class="p_add">+int smp_call_function_single_async(int cpu, call_single_data_t *csd)</span>
 {
 	int err = 0;
 
<span class="p_chunk">@@ -444,7 +444,7 @@</span> <span class="p_context"> void smp_call_function_many(const struct cpumask *mask,</span>
 
 	cpumask_clear(cfd-&gt;cpumask_ipi);
 	for_each_cpu(cpu, cfd-&gt;cpumask) {
<span class="p_del">-		struct call_single_data *csd = per_cpu_ptr(cfd-&gt;csd, cpu);</span>
<span class="p_add">+		call_single_data_t *csd = per_cpu_ptr(cfd-&gt;csd, cpu);</span>
 
 		csd_lock(csd);
 		if (wait)
<span class="p_chunk">@@ -460,7 +460,7 @@</span> <span class="p_context"> void smp_call_function_many(const struct cpumask *mask,</span>
 
 	if (wait) {
 		for_each_cpu(cpu, cfd-&gt;cpumask) {
<span class="p_del">-			struct call_single_data *csd;</span>
<span class="p_add">+			call_single_data_t *csd;</span>
 
 			csd = per_cpu_ptr(cfd-&gt;csd, cpu);
 			csd_lock_wait(csd);
<span class="p_header">diff --git a/kernel/up.c b/kernel/up.c</span>
<span class="p_header">index ee81ac9af4ca..42c46bf3e0a5 100644</span>
<span class="p_header">--- a/kernel/up.c</span>
<span class="p_header">+++ b/kernel/up.c</span>
<span class="p_chunk">@@ -23,7 +23,7 @@</span> <span class="p_context"> int smp_call_function_single(int cpu, void (*func) (void *info), void *info,</span>
 }
 EXPORT_SYMBOL(smp_call_function_single);
 
<span class="p_del">-int smp_call_function_single_async(int cpu, struct call_single_data *csd)</span>
<span class="p_add">+int smp_call_function_single_async(int cpu, call_single_data_t *csd)</span>
 {
 	unsigned long flags;
 

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



