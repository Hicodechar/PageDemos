
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>[v2,3/3] pagemap: switch to the new format and do some cleanup - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    [v2,3/3] pagemap: switch to the new format and do some cleanup</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=120261">Konstantin Khebnikov</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>May 12, 2015, 9:43 a.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;20150512094306.24768.51325.stgit@buzz&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/6386981/mbox/"
   >mbox</a>
|
   <a href="/patch/6386981/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/6386981/">/patch/6386981/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
X-Original-To: patchwork-LKML@patchwork.kernel.org
Delivered-To: patchwork-parsemail@patchwork1.web.kernel.org
Received: from mail.kernel.org (mail.kernel.org [198.145.29.136])
	by patchwork1.web.kernel.org (Postfix) with ESMTP id B58939F32E
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Tue, 12 May 2015 09:43:36 +0000 (UTC)
Received: from mail.kernel.org (localhost [127.0.0.1])
	by mail.kernel.org (Postfix) with ESMTP id 5798820303
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Tue, 12 May 2015 09:43:35 +0000 (UTC)
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.kernel.org (Postfix) with ESMTP id BE0FF2025B
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Tue, 12 May 2015 09:43:33 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S932473AbbELJnU (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Tue, 12 May 2015 05:43:20 -0400
Received: from forward-corp1g.mail.yandex.net ([95.108.253.251]:55066 &quot;EHLO
	forward-corp1g.mail.yandex.net&quot; rhost-flags-OK-OK-OK-OK)
	by vger.kernel.org with ESMTP id S1753220AbbELJnM (ORCPT
	&lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Tue, 12 May 2015 05:43:12 -0400
Received: from smtpcorp1m.mail.yandex.net (smtpcorp1m.mail.yandex.net
	[77.88.61.150])
	by forward-corp1g.mail.yandex.net (Yandex) with ESMTP id E0C74366020A;
	Tue, 12 May 2015 12:43:06 +0300 (MSK)
Received: from smtpcorp1m.mail.yandex.net (localhost [127.0.0.1])
	by smtpcorp1m.mail.yandex.net (Yandex) with ESMTP id AB4C92CA03BC;
	Tue, 12 May 2015 12:43:06 +0300 (MSK)
Received: from unknown (unknown [2a02:6b8:0:408:2979:8b83:fd17:6b18])
	by smtpcorp1m.mail.yandex.net (nwsmtp/Yandex) with ESMTPSA id
	Mwn0IQZAEs-h6c81Wae; Tue, 12 May 2015 12:43:06 +0300
	(using TLSv1.2 with cipher AES128-GCM-SHA256 (128/128 bits))
	(Client certificate not present)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed; d=yandex-team.ru;
	s=default; 
	t=1431423786; bh=s78BwxWKFnikTSdj3YUu+Bahimyk3slnHAUMUIlA5n8=;
	h=Subject:From:To:Cc:Date:Message-ID:In-Reply-To:References:
	User-Agent:MIME-Version:Content-Type:Content-Transfer-Encoding;
	b=ls17pKYWJMCmYzT25b8yyFhFHWJj6oaXQqzmOoG1jLWhENRYUB4XhGyD1/mqNDDWM
	LPLxUmeakS38K3HDsB+GkInY/Fd4SI8tqVn9XyUGr3fNTHWLoaKRxfPmrAaUWwuxmu
	EgVcI/TSt6paSzHEOdpZ3thBDMSKHxS3gO8B4xyI=
Authentication-Results: smtpcorp1m.mail.yandex.net;
	dkim=pass header.i=@yandex-team.ru
Subject: [PATCH v2 3/3] pagemap: switch to the new format and do some cleanup
From: Konstantin Khlebnikov &lt;khlebnikov@yandex-team.ru&gt;
To: linux-mm@kvack.org, Naoya Horiguchi &lt;n-horiguchi@ah.jp.nec.com&gt;,
	linux-kernel@vger.kernel.org, Andrew Morton &lt;akpm@linux-foundation.org&gt;
Cc: Mark Williamson &lt;mwilliamson@undo-software.com&gt;,
	Pavel Emelyanov &lt;xemul@parallels.com&gt;,
	linux-api@vger.kernel.org, Andy Lutomirski &lt;luto@amacapital.net&gt;,
	Vlastimil Babka &lt;vbabka@suse.cz&gt;, Pavel Machek &lt;pavel@ucw.cz&gt;,
	Mark Seaborn &lt;mseaborn@chromium.org&gt;,
	&quot;Kirill A. Shutemov&quot; &lt;kirill@shutemov.name&gt;,
	Linus Torvalds &lt;torvalds@linux-foundation.org&gt;,
	Daniel James &lt;djames@undo-software.com&gt;,
	Finn Grimwood &lt;fgrimwood@undo-software.com&gt;
Date: Tue, 12 May 2015 12:43:06 +0300
Message-ID: &lt;20150512094306.24768.51325.stgit@buzz&gt;
In-Reply-To: &lt;20150512090156.24768.2521.stgit@buzz&gt;
References: &lt;20150512090156.24768.2521.stgit@buzz&gt;
User-Agent: StGit/0.17.1-dirty
MIME-Version: 1.0
Content-Type: text/plain; charset=&quot;utf-8&quot;
Content-Transfer-Encoding: 7bit
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Spam-Status: No, score=-6.8 required=5.0 tests=BAYES_00,DKIM_SIGNED,
	RCVD_IN_DNSWL_HI,T_DKIM_INVALID,T_RP_MATCHES_RCVD,UNPARSEABLE_RELAY
	autolearn=unavailable version=3.3.1
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on mail.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=120261">Konstantin Khebnikov</a> - May 12, 2015, 9:43 a.m.</div>
<pre class="content">
This patch removes page-shift bits (scheduled to remove since 3.11) and
completes migration to the new bit layout. Also it cleans messy macro.
<span class="signed-off-by">
Signed-off-by: Konstantin Khlebnikov &lt;khlebnikov@yandex-team.ru&gt;</span>
---
 fs/proc/task_mmu.c    |  152 ++++++++++++++++---------------------------------
 tools/vm/page-types.c |   29 +++------
 2 files changed, 58 insertions(+), 123 deletions(-)


--
To unsubscribe from this list: send the line &quot;unsubscribe linux-kernel&quot; in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
Please read the FAQ at  http://www.tux.org/lkml/
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=874">Kirill A. Shutemov</a> - May 12, 2015, 10:54 a.m.</div>
<pre class="content">
On Tue, May 12, 2015 at 12:43:06PM +0300, Konstantin Khlebnikov wrote:
<span class="quote">&gt; This patch removes page-shift bits (scheduled to remove since 3.11) and</span>
<span class="quote">&gt; completes migration to the new bit layout. Also it cleans messy macro.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Signed-off-by: Konstantin Khlebnikov &lt;khlebnikov@yandex-team.ru&gt;</span>
<span class="quote">&gt; ---</span>
<span class="quote">&gt;  fs/proc/task_mmu.c    |  152 ++++++++++++++++---------------------------------</span>
<span class="quote">&gt;  tools/vm/page-types.c |   29 +++------</span>
<span class="quote">&gt;  2 files changed, 58 insertions(+), 123 deletions(-)</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; diff --git a/fs/proc/task_mmu.c b/fs/proc/task_mmu.c</span>
<span class="quote">&gt; index 0b7a8ffec95f..66bc7207ce90 100644</span>
<span class="quote">&gt; --- a/fs/proc/task_mmu.c</span>
<span class="quote">&gt; +++ b/fs/proc/task_mmu.c</span>
<span class="quote">&gt; @@ -710,23 +710,6 @@ const struct file_operations proc_tid_smaps_operations = {</span>
<span class="quote">&gt;  	.release	= proc_map_release,</span>
<span class="quote">&gt;  };</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; -/*</span>
<span class="quote">&gt; - * We do not want to have constant page-shift bits sitting in</span>
<span class="quote">&gt; - * pagemap entries and are about to reuse them some time soon.</span>
<span class="quote">&gt; - *</span>
<span class="quote">&gt; - * Here&#39;s the &quot;migration strategy&quot;:</span>
<span class="quote">&gt; - * 1. when the system boots these bits remain what they are,</span>
<span class="quote">&gt; - *    but a warning about future change is printed in log;</span>
<span class="quote">&gt; - * 2. once anyone clears soft-dirty bits via clear_refs file,</span>
<span class="quote">&gt; - *    these flag is set to denote, that user is aware of the</span>
<span class="quote">&gt; - *    new API and those page-shift bits change their meaning.</span>
<span class="quote">&gt; - *    The respective warning is printed in dmesg;</span>
<span class="quote">&gt; - * 3. In a couple of releases we will remove all the mentions</span>
<span class="quote">&gt; - *    of page-shift in pagemap entries.</span>
<span class="quote">&gt; - */</span>

Wouldn&#39;t it be better to just have v2=1 by default for couple releases to
see if anything breaks? This way we can revert easily if regression reported.
I guess someone could miss this change coming if he didn&#39;t touch clear_refs.
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=120261">Konstantin Khebnikov</a> - May 13, 2015, 11:39 a.m.</div>
<pre class="content">
On 12.05.2015 13:54, Kirill A. Shutemov wrote:
<span class="quote">&gt; On Tue, May 12, 2015 at 12:43:06PM +0300, Konstantin Khlebnikov wrote:</span>
<span class="quote">&gt;&gt; This patch removes page-shift bits (scheduled to remove since 3.11) and</span>
<span class="quote">&gt;&gt; completes migration to the new bit layout. Also it cleans messy macro.</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; Signed-off-by: Konstantin Khlebnikov &lt;khlebnikov@yandex-team.ru&gt;</span>
<span class="quote">&gt;&gt; ---</span>
<span class="quote">&gt;&gt;   fs/proc/task_mmu.c    |  152 ++++++++++++++++---------------------------------</span>
<span class="quote">&gt;&gt;   tools/vm/page-types.c |   29 +++------</span>
<span class="quote">&gt;&gt;   2 files changed, 58 insertions(+), 123 deletions(-)</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; diff --git a/fs/proc/task_mmu.c b/fs/proc/task_mmu.c</span>
<span class="quote">&gt;&gt; index 0b7a8ffec95f..66bc7207ce90 100644</span>
<span class="quote">&gt;&gt; --- a/fs/proc/task_mmu.c</span>
<span class="quote">&gt;&gt; +++ b/fs/proc/task_mmu.c</span>
<span class="quote">&gt;&gt; @@ -710,23 +710,6 @@ const struct file_operations proc_tid_smaps_operations = {</span>
<span class="quote">&gt;&gt;   	.release	= proc_map_release,</span>
<span class="quote">&gt;&gt;   };</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; -/*</span>
<span class="quote">&gt;&gt; - * We do not want to have constant page-shift bits sitting in</span>
<span class="quote">&gt;&gt; - * pagemap entries and are about to reuse them some time soon.</span>
<span class="quote">&gt;&gt; - *</span>
<span class="quote">&gt;&gt; - * Here&#39;s the &quot;migration strategy&quot;:</span>
<span class="quote">&gt;&gt; - * 1. when the system boots these bits remain what they are,</span>
<span class="quote">&gt;&gt; - *    but a warning about future change is printed in log;</span>
<span class="quote">&gt;&gt; - * 2. once anyone clears soft-dirty bits via clear_refs file,</span>
<span class="quote">&gt;&gt; - *    these flag is set to denote, that user is aware of the</span>
<span class="quote">&gt;&gt; - *    new API and those page-shift bits change their meaning.</span>
<span class="quote">&gt;&gt; - *    The respective warning is printed in dmesg;</span>
<span class="quote">&gt;&gt; - * 3. In a couple of releases we will remove all the mentions</span>
<span class="quote">&gt;&gt; - *    of page-shift in pagemap entries.</span>
<span class="quote">&gt;&gt; - */</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; Wouldn&#39;t it be better to just have v2=1 by default for couple releases to</span>
<span class="quote">&gt; see if anything breaks? This way we can revert easily if regression reported.</span>
<span class="quote">&gt; I guess someone could miss this change coming if he didn&#39;t touch clear_refs.</span>
<span class="quote">&gt;</span>

I don&#39;t believe that constant PAGE_SHIFT bits are used by anybody. 
Recent change of permissions was much more destructive and there is just
one report about that. Kernel prints message at first pagemap open for
ten releases. I think that&#39;s enough.
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/fs/proc/task_mmu.c b/fs/proc/task_mmu.c</span>
<span class="p_header">index 0b7a8ffec95f..66bc7207ce90 100644</span>
<span class="p_header">--- a/fs/proc/task_mmu.c</span>
<span class="p_header">+++ b/fs/proc/task_mmu.c</span>
<span class="p_chunk">@@ -710,23 +710,6 @@</span> <span class="p_context"> const struct file_operations proc_tid_smaps_operations = {</span>
 	.release	= proc_map_release,
 };
 
<span class="p_del">-/*</span>
<span class="p_del">- * We do not want to have constant page-shift bits sitting in</span>
<span class="p_del">- * pagemap entries and are about to reuse them some time soon.</span>
<span class="p_del">- *</span>
<span class="p_del">- * Here&#39;s the &quot;migration strategy&quot;:</span>
<span class="p_del">- * 1. when the system boots these bits remain what they are,</span>
<span class="p_del">- *    but a warning about future change is printed in log;</span>
<span class="p_del">- * 2. once anyone clears soft-dirty bits via clear_refs file,</span>
<span class="p_del">- *    these flag is set to denote, that user is aware of the</span>
<span class="p_del">- *    new API and those page-shift bits change their meaning.</span>
<span class="p_del">- *    The respective warning is printed in dmesg;</span>
<span class="p_del">- * 3. In a couple of releases we will remove all the mentions</span>
<span class="p_del">- *    of page-shift in pagemap entries.</span>
<span class="p_del">- */</span>
<span class="p_del">-</span>
<span class="p_del">-static bool soft_dirty_cleared __read_mostly;</span>
<span class="p_del">-</span>
 enum clear_refs_types {
 	CLEAR_REFS_ALL = 1,
 	CLEAR_REFS_ANON,
<span class="p_chunk">@@ -887,13 +870,6 @@</span> <span class="p_context"> static ssize_t clear_refs_write(struct file *file, const char __user *buf,</span>
 	if (type &lt; CLEAR_REFS_ALL || type &gt;= CLEAR_REFS_LAST)
 		return -EINVAL;
 
<span class="p_del">-	if (type == CLEAR_REFS_SOFT_DIRTY) {</span>
<span class="p_del">-		soft_dirty_cleared = true;</span>
<span class="p_del">-		pr_warn_once(&quot;The pagemap bits 55-60 has changed their meaning!&quot;</span>
<span class="p_del">-			     &quot; See the linux/Documentation/vm/pagemap.txt for &quot;</span>
<span class="p_del">-			     &quot;details.\n&quot;);</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
 	task = get_proc_task(file_inode(file));
 	if (!task)
 		return -ESRCH;
<span class="p_chunk">@@ -961,38 +937,26 @@</span> <span class="p_context"> typedef struct {</span>
 struct pagemapread {
 	int pos, len;		/* units: PM_ENTRY_BYTES, not bytes */
 	pagemap_entry_t *buffer;
<span class="p_del">-	bool v2;</span>
 	bool show_pfn;
 };
 
 #define PAGEMAP_WALK_SIZE	(PMD_SIZE)
 #define PAGEMAP_WALK_MASK	(PMD_MASK)
 
<span class="p_del">-#define PM_ENTRY_BYTES      sizeof(pagemap_entry_t)</span>
<span class="p_del">-#define PM_STATUS_BITS      3</span>
<span class="p_del">-#define PM_STATUS_OFFSET    (64 - PM_STATUS_BITS)</span>
<span class="p_del">-#define PM_STATUS_MASK      (((1LL &lt;&lt; PM_STATUS_BITS) - 1) &lt;&lt; PM_STATUS_OFFSET)</span>
<span class="p_del">-#define PM_STATUS(nr)       (((nr) &lt;&lt; PM_STATUS_OFFSET) &amp; PM_STATUS_MASK)</span>
<span class="p_del">-#define PM_PSHIFT_BITS      6</span>
<span class="p_del">-#define PM_PSHIFT_OFFSET    (PM_STATUS_OFFSET - PM_PSHIFT_BITS)</span>
<span class="p_del">-#define PM_PSHIFT_MASK      (((1LL &lt;&lt; PM_PSHIFT_BITS) - 1) &lt;&lt; PM_PSHIFT_OFFSET)</span>
<span class="p_del">-#define __PM_PSHIFT(x)      (((u64) (x) &lt;&lt; PM_PSHIFT_OFFSET) &amp; PM_PSHIFT_MASK)</span>
<span class="p_del">-#define PM_PFRAME_MASK      ((1LL &lt;&lt; PM_PSHIFT_OFFSET) - 1)</span>
<span class="p_del">-#define PM_PFRAME(x)        ((x) &amp; PM_PFRAME_MASK)</span>
<span class="p_del">-/* in &quot;new&quot; pagemap pshift bits are occupied with more status bits */</span>
<span class="p_del">-#define PM_STATUS2(v2, x)   (__PM_PSHIFT(v2 ? x : PAGE_SHIFT))</span>
<span class="p_del">-</span>
<span class="p_del">-#define __PM_SOFT_DIRTY      (1LL)</span>
<span class="p_del">-#define __PM_MMAP_EXCLUSIVE  (2LL)</span>
<span class="p_del">-#define PM_PRESENT          PM_STATUS(4LL)</span>
<span class="p_del">-#define PM_SWAP             PM_STATUS(2LL)</span>
<span class="p_del">-#define PM_FILE             PM_STATUS(1LL)</span>
<span class="p_del">-#define PM_NOT_PRESENT(v2)  PM_STATUS2(v2, 0)</span>
<span class="p_add">+#define PM_ENTRY_BYTES		sizeof(pagemap_entry_t)</span>
<span class="p_add">+#define PM_PFEAME_BITS		54</span>
<span class="p_add">+#define PM_PFRAME_MASK		GENMASK_ULL(PM_PFEAME_BITS - 1, 0)</span>
<span class="p_add">+#define PM_SOFT_DIRTY		BIT_ULL(55)</span>
<span class="p_add">+#define PM_MMAP_EXCLUSIVE	BIT_ULL(56)</span>
<span class="p_add">+#define PM_FILE			BIT_ULL(61)</span>
<span class="p_add">+#define PM_SWAP			BIT_ULL(62)</span>
<span class="p_add">+#define PM_PRESENT		BIT_ULL(63)</span>
<span class="p_add">+</span>
 #define PM_END_OF_BUFFER    1
 
<span class="p_del">-static inline pagemap_entry_t make_pme(u64 val)</span>
<span class="p_add">+static inline pagemap_entry_t make_pme(u64 frame, u64 flags)</span>
 {
<span class="p_del">-	return (pagemap_entry_t) { .pme = val };</span>
<span class="p_add">+	return (pagemap_entry_t) { .pme = (frame &amp; PM_PFRAME_MASK) | flags };</span>
 }
 
 static int add_to_pagemap(unsigned long addr, pagemap_entry_t *pme,
<span class="p_chunk">@@ -1013,7 +977,7 @@</span> <span class="p_context"> static int pagemap_pte_hole(unsigned long start, unsigned long end,</span>
 
 	while (addr &lt; end) {
 		struct vm_area_struct *vma = find_vma(walk-&gt;mm, addr);
<span class="p_del">-		pagemap_entry_t pme = make_pme(PM_NOT_PRESENT(pm-&gt;v2));</span>
<span class="p_add">+		pagemap_entry_t pme = make_pme(0, 0);</span>
 		/* End of address space hole, which we mark as non-present. */
 		unsigned long hole_end;
 
<span class="p_chunk">@@ -1033,7 +997,7 @@</span> <span class="p_context"> static int pagemap_pte_hole(unsigned long start, unsigned long end,</span>
 
 		/* Addresses in the VMA. */
 		if (vma-&gt;vm_flags &amp; VM_SOFTDIRTY)
<span class="p_del">-			pme.pme |= PM_STATUS2(pm-&gt;v2, __PM_SOFT_DIRTY);</span>
<span class="p_add">+			pme = make_pme(0, PM_SOFT_DIRTY);</span>
 		for (; addr &lt; min(end, vma-&gt;vm_end); addr += PAGE_SIZE) {
 			err = add_to_pagemap(addr, &amp;pme, pm);
 			if (err)
<span class="p_chunk">@@ -1044,50 +1008,44 @@</span> <span class="p_context"> out:</span>
 	return err;
 }
 
<span class="p_del">-static void pte_to_pagemap_entry(pagemap_entry_t *pme, struct pagemapread *pm,</span>
<span class="p_add">+static pagemap_entry_t pte_to_pagemap_entry(struct pagemapread *pm,</span>
 		struct vm_area_struct *vma, unsigned long addr, pte_t pte)
 {
<span class="p_del">-	u64 frame = 0, flags;</span>
<span class="p_add">+	u64 frame = 0, flags = 0;</span>
 	struct page *page = NULL;
<span class="p_del">-	int flags2 = 0;</span>
 
 	if (pte_present(pte)) {
 		if (pm-&gt;show_pfn)
 			frame = pte_pfn(pte);
<span class="p_del">-		flags = PM_PRESENT;</span>
<span class="p_add">+		flags |= PM_PRESENT;</span>
 		page = vm_normal_page(vma, addr, pte);
 		if (pte_soft_dirty(pte))
<span class="p_del">-			flags2 |= __PM_SOFT_DIRTY;</span>
<span class="p_add">+			flags |= PM_SOFT_DIRTY;</span>
 	} else if (is_swap_pte(pte)) {
 		swp_entry_t entry;
 		if (pte_swp_soft_dirty(pte))
<span class="p_del">-			flags2 |= __PM_SOFT_DIRTY;</span>
<span class="p_add">+			flags |= PM_SOFT_DIRTY;</span>
 		entry = pte_to_swp_entry(pte);
 		frame = swp_type(entry) |
 			(swp_offset(entry) &lt;&lt; MAX_SWAPFILES_SHIFT);
<span class="p_del">-		flags = PM_SWAP;</span>
<span class="p_add">+		flags |= PM_SWAP;</span>
 		if (is_migration_entry(entry))
 			page = migration_entry_to_page(entry);
<span class="p_del">-	} else {</span>
<span class="p_del">-		if (vma-&gt;vm_flags &amp; VM_SOFTDIRTY)</span>
<span class="p_del">-			flags2 |= __PM_SOFT_DIRTY;</span>
<span class="p_del">-		*pme = make_pme(PM_NOT_PRESENT(pm-&gt;v2) | PM_STATUS2(pm-&gt;v2, flags2));</span>
<span class="p_del">-		return;</span>
 	}
 
 	if (page &amp;&amp; !PageAnon(page))
 		flags |= PM_FILE;
 	if (page &amp;&amp; page_mapcount(page) == 1)
<span class="p_del">-		flags2 |= __PM_MMAP_EXCLUSIVE;</span>
<span class="p_del">-	if ((vma-&gt;vm_flags &amp; VM_SOFTDIRTY))</span>
<span class="p_del">-		flags2 |= __PM_SOFT_DIRTY;</span>
<span class="p_add">+		flags |= PM_MMAP_EXCLUSIVE;</span>
<span class="p_add">+	if (vma-&gt;vm_flags &amp; VM_SOFTDIRTY)</span>
<span class="p_add">+		flags |= PM_SOFT_DIRTY;</span>
 
<span class="p_del">-	*pme = make_pme(PM_PFRAME(frame) | PM_STATUS2(pm-&gt;v2, flags2) | flags);</span>
<span class="p_add">+	return make_pme(frame, flags);</span>
 }
 
 #ifdef CONFIG_TRANSPARENT_HUGEPAGE
<span class="p_del">-static void thp_pmd_to_pagemap_entry(pagemap_entry_t *pme, struct pagemapread *pm,</span>
<span class="p_del">-		pmd_t pmd, int offset, int pmd_flags2)</span>
<span class="p_add">+static pagemap_entry_t thp_pmd_to_pagemap_entry(struct pagemapread *pm,</span>
<span class="p_add">+		pmd_t pmd, int offset, u64 flags)</span>
 {
 	u64 frame = 0;
 
<span class="p_chunk">@@ -1099,15 +1057,16 @@</span> <span class="p_context"> static void thp_pmd_to_pagemap_entry(pagemap_entry_t *pme, struct pagemapread *p</span>
 	if (pmd_present(pmd)) {
 		if (pm-&gt;show_pfn)
 			frame = pmd_pfn(pmd) + offset;
<span class="p_del">-		*pme = make_pme(PM_PFRAME(frame) | PM_PRESENT |</span>
<span class="p_del">-				PM_STATUS2(pm-&gt;v2, pmd_flags2));</span>
<span class="p_del">-	} else</span>
<span class="p_del">-		*pme = make_pme(PM_NOT_PRESENT(pm-&gt;v2) | PM_STATUS2(pm-&gt;v2, pmd_flags2));</span>
<span class="p_add">+		flags |= PM_PRESENT;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	return make_pme(frame, flags);</span>
 }
 #else
<span class="p_del">-static inline void thp_pmd_to_pagemap_entry(pagemap_entry_t *pme, struct pagemapread *pm,</span>
<span class="p_del">-		pmd_t pmd, int offset, int pmd_flags2)</span>
<span class="p_add">+static pagemap_entry_t thp_pmd_to_pagemap_entry(struct pagemapread *pm,</span>
<span class="p_add">+		pmd_t pmd, int offset, u64 flags)</span>
 {
<span class="p_add">+	return make_pme(0, 0);</span>
 }
 #endif
 
<span class="p_chunk">@@ -1121,18 +1080,16 @@</span> <span class="p_context"> static int pagemap_pte_range(pmd_t *pmd, unsigned long addr, unsigned long end,</span>
 	int err = 0;
 
 	if (pmd_trans_huge_lock(pmd, vma, &amp;ptl) == 1) {
<span class="p_del">-		int pmd_flags2;</span>
<span class="p_add">+		u64 flags = 0;</span>
 
 		if ((vma-&gt;vm_flags &amp; VM_SOFTDIRTY) || pmd_soft_dirty(*pmd))
<span class="p_del">-			pmd_flags2 = __PM_SOFT_DIRTY;</span>
<span class="p_del">-		else</span>
<span class="p_del">-			pmd_flags2 = 0;</span>
<span class="p_add">+			flags |= PM_SOFT_DIRTY;</span>
 
 		if (pmd_present(*pmd)) {
 			struct page *page = pmd_page(*pmd);
 
 			if (page_mapcount(page) == 1)
<span class="p_del">-				pmd_flags2 |= __PM_MMAP_EXCLUSIVE;</span>
<span class="p_add">+				flags |= PM_MMAP_EXCLUSIVE;</span>
 		}
 
 		for (; addr != end; addr += PAGE_SIZE) {
<span class="p_chunk">@@ -1141,7 +1098,7 @@</span> <span class="p_context"> static int pagemap_pte_range(pmd_t *pmd, unsigned long addr, unsigned long end,</span>
 
 			offset = (addr &amp; ~PAGEMAP_WALK_MASK) &gt;&gt;
 					PAGE_SHIFT;
<span class="p_del">-			thp_pmd_to_pagemap_entry(&amp;pme, pm, *pmd, offset, pmd_flags2);</span>
<span class="p_add">+			pme = thp_pmd_to_pagemap_entry(pm, *pmd, offset, flags);</span>
 			err = add_to_pagemap(addr, &amp;pme, pm);
 			if (err)
 				break;
<span class="p_chunk">@@ -1161,7 +1118,7 @@</span> <span class="p_context"> static int pagemap_pte_range(pmd_t *pmd, unsigned long addr, unsigned long end,</span>
 	for (; addr &lt; end; pte++, addr += PAGE_SIZE) {
 		pagemap_entry_t pme;
 
<span class="p_del">-		pte_to_pagemap_entry(&amp;pme, pm, vma, addr, *pte);</span>
<span class="p_add">+		pme = pte_to_pagemap_entry(pm, vma, addr, *pte);</span>
 		err = add_to_pagemap(addr, &amp;pme, pm);
 		if (err)
 			break;
<span class="p_chunk">@@ -1174,19 +1131,18 @@</span> <span class="p_context"> static int pagemap_pte_range(pmd_t *pmd, unsigned long addr, unsigned long end,</span>
 }
 
 #ifdef CONFIG_HUGETLB_PAGE
<span class="p_del">-static void huge_pte_to_pagemap_entry(pagemap_entry_t *pme, struct pagemapread *pm,</span>
<span class="p_del">-					pte_t pte, int offset, int flags2)</span>
<span class="p_add">+static pagemap_entry_t huge_pte_to_pagemap_entry(struct pagemapread *pm,</span>
<span class="p_add">+					pte_t pte, int offset, u64 flags)</span>
 {
 	u64 frame = 0;
 
 	if (pte_present(pte)) {
 		if (pm-&gt;show_pfn)
 			frame = pte_pfn(pte) + offset;
<span class="p_del">-		*pme = make_pme(PM_PFRAME(frame) | PM_PRESENT |</span>
<span class="p_del">-				PM_STATUS2(pm-&gt;v2, flags2));</span>
<span class="p_del">-	} else</span>
<span class="p_del">-		*pme = make_pme(PM_NOT_PRESENT(pm-&gt;v2)			|</span>
<span class="p_del">-				PM_STATUS2(pm-&gt;v2, flags2));</span>
<span class="p_add">+		flags |= PM_PRESENT;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	return make_pme(frame, flags);</span>
 }
 
 /* This function walks within one hugetlb entry in the single call */
<span class="p_chunk">@@ -1197,17 +1153,15 @@</span> <span class="p_context"> static int pagemap_hugetlb_range(pte_t *pte, unsigned long hmask,</span>
 	struct pagemapread *pm = walk-&gt;private;
 	struct vm_area_struct *vma = walk-&gt;vma;
 	int err = 0;
<span class="p_del">-	int flags2;</span>
<span class="p_add">+	u64 flags = 0;</span>
 	pagemap_entry_t pme;
 
 	if (vma-&gt;vm_flags &amp; VM_SOFTDIRTY)
<span class="p_del">-		flags2 = __PM_SOFT_DIRTY;</span>
<span class="p_del">-	else</span>
<span class="p_del">-		flags2 = 0;</span>
<span class="p_add">+		flags |= PM_SOFT_DIRTY;</span>
 
 	for (; addr != end; addr += PAGE_SIZE) {
 		int offset = (addr &amp; ~hmask) &gt;&gt; PAGE_SHIFT;
<span class="p_del">-		huge_pte_to_pagemap_entry(&amp;pme, pm, *pte, offset, flags2);</span>
<span class="p_add">+		pme = huge_pte_to_pagemap_entry(pm, *pte, offset, flags);</span>
 		err = add_to_pagemap(addr, &amp;pme, pm);
 		if (err)
 			return err;
<span class="p_chunk">@@ -1228,7 +1182,9 @@</span> <span class="p_context"> static int pagemap_hugetlb_range(pte_t *pte, unsigned long hmask,</span>
  * Bits 0-54  page frame number (PFN) if present
  * Bits 0-4   swap type if swapped
  * Bits 5-54  swap offset if swapped
<span class="p_del">- * Bits 55-60 page shift (page size = 1&lt;&lt;page shift)</span>
<span class="p_add">+ * Bit  55    pte is soft-dirty (see Documentation/vm/soft-dirty.txt)</span>
<span class="p_add">+ * Bit  56    page exclusively mapped</span>
<span class="p_add">+ * Bits 57-60 zero</span>
  * Bit  61    page is file-page or shared-anon
  * Bit  62    page swapped
  * Bit  63    page present
<span class="p_chunk">@@ -1271,7 +1227,6 @@</span> <span class="p_context"> static ssize_t pagemap_read(struct file *file, char __user *buf,</span>
 
 	/* do not disclose physical addresses: attack vector */
 	pm.show_pfn = capable(CAP_SYS_ADMIN);
<span class="p_del">-	pm.v2 = soft_dirty_cleared;</span>
 	pm.len = (PAGEMAP_WALK_SIZE &gt;&gt; PAGE_SHIFT);
 	pm.buffer = kmalloc(pm.len * PM_ENTRY_BYTES, GFP_TEMPORARY);
 	ret = -ENOMEM;
<span class="p_chunk">@@ -1344,18 +1299,9 @@</span> <span class="p_context"> out:</span>
 	return ret;
 }
 
<span class="p_del">-static int pagemap_open(struct inode *inode, struct file *file)</span>
<span class="p_del">-{</span>
<span class="p_del">-	pr_warn_once(&quot;Bits 55-60 of /proc/PID/pagemap entries are about &quot;</span>
<span class="p_del">-			&quot;to stop being page-shift some time soon. See the &quot;</span>
<span class="p_del">-			&quot;linux/Documentation/vm/pagemap.txt for details.\n&quot;);</span>
<span class="p_del">-	return 0;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
 const struct file_operations proc_pagemap_operations = {
 	.llseek		= mem_lseek, /* borrow this */
 	.read		= pagemap_read,
<span class="p_del">-	.open		= pagemap_open,</span>
 };
 #endif /* CONFIG_PROC_PAGE_MONITOR */
 
<span class="p_header">diff --git a/tools/vm/page-types.c b/tools/vm/page-types.c</span>
<span class="p_header">index 3a9f193526ee..1fa872e58238 100644</span>
<span class="p_header">--- a/tools/vm/page-types.c</span>
<span class="p_header">+++ b/tools/vm/page-types.c</span>
<span class="p_chunk">@@ -57,26 +57,15 @@</span> <span class="p_context"></span>
  * pagemap kernel ABI bits
  */
 
<span class="p_del">-#define PM_ENTRY_BYTES      sizeof(uint64_t)</span>
<span class="p_del">-#define PM_STATUS_BITS      3</span>
<span class="p_del">-#define PM_STATUS_OFFSET    (64 - PM_STATUS_BITS)</span>
<span class="p_del">-#define PM_STATUS_MASK      (((1LL &lt;&lt; PM_STATUS_BITS) - 1) &lt;&lt; PM_STATUS_OFFSET)</span>
<span class="p_del">-#define PM_STATUS(nr)       (((nr) &lt;&lt; PM_STATUS_OFFSET) &amp; PM_STATUS_MASK)</span>
<span class="p_del">-#define PM_PSHIFT_BITS      6</span>
<span class="p_del">-#define PM_PSHIFT_OFFSET    (PM_STATUS_OFFSET - PM_PSHIFT_BITS)</span>
<span class="p_del">-#define PM_PSHIFT_MASK      (((1LL &lt;&lt; PM_PSHIFT_BITS) - 1) &lt;&lt; PM_PSHIFT_OFFSET)</span>
<span class="p_del">-#define __PM_PSHIFT(x)      (((uint64_t) (x) &lt;&lt; PM_PSHIFT_OFFSET) &amp; PM_PSHIFT_MASK)</span>
<span class="p_del">-#define PM_PFRAME_MASK      ((1LL &lt;&lt; PM_PSHIFT_OFFSET) - 1)</span>
<span class="p_del">-#define PM_PFRAME(x)        ((x) &amp; PM_PFRAME_MASK)</span>
<span class="p_del">-</span>
<span class="p_del">-#define __PM_SOFT_DIRTY      (1LL)</span>
<span class="p_del">-#define __PM_MMAP_EXCLUSIVE  (2LL)</span>
<span class="p_del">-#define PM_PRESENT          PM_STATUS(4LL)</span>
<span class="p_del">-#define PM_SWAP             PM_STATUS(2LL)</span>
<span class="p_del">-#define PM_FILE             PM_STATUS(1LL)</span>
<span class="p_del">-#define PM_SOFT_DIRTY       __PM_PSHIFT(__PM_SOFT_DIRTY)</span>
<span class="p_del">-#define PM_MMAP_EXCLUSIVE   __PM_PSHIFT(__PM_MMAP_EXCLUSIVE)</span>
<span class="p_del">-</span>
<span class="p_add">+#define PM_ENTRY_BYTES		8</span>
<span class="p_add">+#define PM_PFEAME_BITS		54</span>
<span class="p_add">+#define PM_PFRAME_MASK		((1LL &lt;&lt; PM_PFEAME_BITS) - 1)</span>
<span class="p_add">+#define PM_PFRAME(x)		((x) &amp; PM_PFRAME_MASK)</span>
<span class="p_add">+#define PM_SOFT_DIRTY		(1ULL &lt;&lt; 55)</span>
<span class="p_add">+#define PM_MMAP_EXCLUSIVE	(1ULL &lt;&lt; 56)</span>
<span class="p_add">+#define PM_FILE			(1ULL &lt;&lt; 61)</span>
<span class="p_add">+#define PM_SWAP			(1ULL &lt;&lt; 62)</span>
<span class="p_add">+#define PM_PRESENT		(1ULL &lt;&lt; 63)</span>
 
 /*
  * kernel page flags

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



