
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>[V2] mm/hugetlb: Avoid soft lockup in set_max_huge_pages() - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    [V2] mm/hugetlb: Avoid soft lockup in set_max_huge_pages()</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=111121">Jia He</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>July 28, 2016, 2:54 a.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;1469674442-14848-1-git-send-email-hejianet@gmail.com&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/9250581/mbox/"
   >mbox</a>
|
   <a href="/patch/9250581/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/9250581/">/patch/9250581/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
	[172.30.200.125])
	by pdx-korg-patchwork.web.codeaurora.org (Postfix) with ESMTP id
	1605C607D8 for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Thu, 28 Jul 2016 02:54:31 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id F1D6325223
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Thu, 28 Jul 2016 02:54:30 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id E5FE326861; Thu, 28 Jul 2016 02:54:30 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-7.0 required=2.0 tests=BAYES_00,DKIM_SIGNED,
	DKIM_VALID, DKIM_VALID_AU, FREEMAIL_FROM,
	RCVD_IN_DNSWL_HI autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 4819425223
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Thu, 28 Jul 2016 02:54:29 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1759255AbcG1Cy0 (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Wed, 27 Jul 2016 22:54:26 -0400
Received: from mail-it0-f66.google.com ([209.85.214.66]:36184 &quot;EHLO
	mail-it0-f66.google.com&quot; rhost-flags-OK-OK-OK-OK) by vger.kernel.org
	with ESMTP id S1755892AbcG1CyR (ORCPT
	&lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Wed, 27 Jul 2016 22:54:17 -0400
Received: by mail-it0-f66.google.com with SMTP id j124so4053752ith.3
	for &lt;linux-kernel@vger.kernel.org&gt;;
	Wed, 27 Jul 2016 19:54:17 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
	d=gmail.com; s=20120113;
	h=from:to:cc:subject:date:message-id;
	bh=lNPNvipTeaYVpqZsr9elekUO3rs+BkyvH3ASnb7Dwkw=;
	b=vRZvZ3N42rbRsozCLSiWOOdR8vMI5FYkhikikKDigQ8WB3KcR6sVphbI3DSn+JB+DI
	i0C3svqAme3W00gw9t85/ggwyAdvT3McxNGgMJarUdCEQU1ibDcqu/rA41Q7wLlSsP9f
	Kn787cG2KWg99bWg5m4F7k2CGPKQGGVLzi9egKbXBrXsEO96vVDyWhR3yNA8pxDJMc8v
	huHIVpL3lV3/DiYVHhb+yuSGaTn271jT9VKw5fsyT1LVVQYrFJWqiJrvY1DXO63KAJ7G
	XfxFyxvLCqfewc8nGVduzVOdFePpaQUNv+x/HZtMOKXFnAyyD2XtZrNyk9c/3Ind5JYM
	F5Mw==
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
	d=1e100.net; s=20130820;
	h=x-gm-message-state:from:to:cc:subject:date:message-id;
	bh=lNPNvipTeaYVpqZsr9elekUO3rs+BkyvH3ASnb7Dwkw=;
	b=HR1v2nxQn6hKTGtgtJ8jonZZ4JnQ9DOcRfE9EM/l8EMUK23+LumZK5H7dVYRM8Fhre
	DAvUw528O9DtOC8CUidtAD9qDV4UohC0EiNGlnTeK11TgiF/4dmpcDf4ijrT58273enz
	/O7VJdsZyZnLinQTnwoxUSI9R6d5J5+GPY8KUNNqDMwPg9x0ajtaRAwKRoIBPbRHqvQx
	BS0WyWNDSpjsUh3sRKvrhwA+SbIAs+rUgjykBxBZjxl3NMvOusFUfHS3F3hukKz70n2n
	lXK1FAZ63GNexpvWkg5IyOwYtBuz+Wgt4s46S0J2g4glZQZsw9JnNAfsW7lb6ev4uSvp
	N3wQ==
X-Gm-Message-State: ALyK8tIMtl/bxy33DyonoDB1BfJWzYGD8BufuyFsgB7WDcbRwK9j4F8agMpUQMIbI2Gtag==
X-Received: by 10.36.77.145 with SMTP id l139mr53437411itb.19.1469674456764; 
	Wed, 27 Jul 2016 19:54:16 -0700 (PDT)
Received: from localhost.localdomain.localdomain ([106.38.0.85])
	by smtp.gmail.com with ESMTPSA id
	j129sm4116092iof.35.2016.07.27.19.54.08
	(version=TLS1_2 cipher=ECDHE-RSA-AES128-GCM-SHA256 bits=128/128);
	Wed, 27 Jul 2016 19:54:15 -0700 (PDT)
From: Jia He &lt;hejianet@gmail.com&gt;
To: linux-mm@kvack.org
Cc: linux-kernel@vger.kernel.org, Jia He &lt;hejianet@gmail.com&gt;,
	Andrew Morton &lt;akpm@linux-foundation.org&gt;,
	Naoya Horiguchi &lt;n-horiguchi@ah.jp.nec.com&gt;,
	Mike Kravetz &lt;mike.kravetz@oracle.com&gt;,
	&quot;Kirill A. Shutemov&quot; &lt;kirill.shutemov@linux.intel.com&gt;,
	Michal Hocko &lt;mhocko@suse.com&gt;,
	Dave Hansen &lt;dave.hansen@linux.intel.com&gt;,
	Paul Gortmaker &lt;paul.gortmaker@windriver.com&gt;
Subject: [PATCH V2] mm/hugetlb: Avoid soft lockup in set_max_huge_pages()
Date: Thu, 28 Jul 2016 10:54:02 +0800
Message-Id: &lt;1469674442-14848-1-git-send-email-hejianet@gmail.com&gt;
X-Mailer: git-send-email 2.5.0
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=111121">Jia He</a> - July 28, 2016, 2:54 a.m.</div>
<pre class="content">
In powerpc servers with large memory(32TB), we watched several soft
lockups for hugepage under stress tests.
The call trace are as follows:
1.
get_page_from_freelist+0x2d8/0xd50  
__alloc_pages_nodemask+0x180/0xc20  
alloc_fresh_huge_page+0xb0/0x190    
set_max_huge_pages+0x164/0x3b0      

2.
prep_new_huge_page+0x5c/0x100             
alloc_fresh_huge_page+0xc8/0x190          
set_max_huge_pages+0x164/0x3b0

This patch is to fix such soft lockups. It is safe to call cond_resched() 
there because it is out of spin_lock/unlock section.
<span class="signed-off-by">
Signed-off-by: Jia He &lt;hejianet@gmail.com&gt;</span>
Cc: Andrew Morton &lt;akpm@linux-foundation.org&gt;
Cc: Naoya Horiguchi &lt;n-horiguchi@ah.jp.nec.com&gt;
Cc: Mike Kravetz &lt;mike.kravetz@oracle.com&gt;
Cc: &quot;Kirill A. Shutemov&quot; &lt;kirill.shutemov@linux.intel.com&gt;
Cc: Michal Hocko &lt;mhocko@suse.com&gt;
Cc: Dave Hansen &lt;dave.hansen@linux.intel.com&gt;
Cc: Paul Gortmaker &lt;paul.gortmaker@windriver.com&gt;

---
Changes in V2: move cond_resched to a common calling site in set_max_huge_pages

 mm/hugetlb.c | 4 ++++
 1 file changed, 4 insertions(+)
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=4407">Naoya Horiguchi</a> - July 28, 2016, 6:41 a.m.</div>
<pre class="content">
On Thu, Jul 28, 2016 at 10:54:02AM +0800, Jia He wrote:
<span class="quote">&gt; In powerpc servers with large memory(32TB), we watched several soft</span>
<span class="quote">&gt; lockups for hugepage under stress tests.</span>
<span class="quote">&gt; The call trace are as follows:</span>
<span class="quote">&gt; 1.</span>
<span class="quote">&gt; get_page_from_freelist+0x2d8/0xd50  </span>
<span class="quote">&gt; __alloc_pages_nodemask+0x180/0xc20  </span>
<span class="quote">&gt; alloc_fresh_huge_page+0xb0/0x190    </span>
<span class="quote">&gt; set_max_huge_pages+0x164/0x3b0      </span>
<span class="quote">&gt; </span>
<span class="quote">&gt; 2.</span>
<span class="quote">&gt; prep_new_huge_page+0x5c/0x100             </span>
<span class="quote">&gt; alloc_fresh_huge_page+0xc8/0x190          </span>
<span class="quote">&gt; set_max_huge_pages+0x164/0x3b0</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; This patch is to fix such soft lockups. It is safe to call cond_resched() </span>
<span class="quote">&gt; there because it is out of spin_lock/unlock section.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Signed-off-by: Jia He &lt;hejianet@gmail.com&gt;</span>
<span class="quote">&gt; Cc: Andrew Morton &lt;akpm@linux-foundation.org&gt;</span>
<span class="quote">&gt; Cc: Naoya Horiguchi &lt;n-horiguchi@ah.jp.nec.com&gt;</span>
<span class="quote">&gt; Cc: Mike Kravetz &lt;mike.kravetz@oracle.com&gt;</span>
<span class="quote">&gt; Cc: &quot;Kirill A. Shutemov&quot; &lt;kirill.shutemov@linux.intel.com&gt;</span>
<span class="quote">&gt; Cc: Michal Hocko &lt;mhocko@suse.com&gt;</span>
<span class="quote">&gt; Cc: Dave Hansen &lt;dave.hansen@linux.intel.com&gt;</span>
<span class="quote">&gt; Cc: Paul Gortmaker &lt;paul.gortmaker@windriver.com&gt;</span>

Looks good to me.
<span class="reviewed-by">
Reviewed-by: Naoya Horiguchi &lt;n-horiguchi@ah.jp.nec.com&gt;</span>

Thanks,
Naoya Horiguchi
<span class="quote">
&gt; </span>
<span class="quote">&gt; ---</span>
<span class="quote">&gt; Changes in V2: move cond_resched to a common calling site in set_max_huge_pages</span>
<span class="quote">&gt; </span>
<span class="quote">&gt;  mm/hugetlb.c | 4 ++++</span>
<span class="quote">&gt;  1 file changed, 4 insertions(+)</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; diff --git a/mm/hugetlb.c b/mm/hugetlb.c</span>
<span class="quote">&gt; index abc1c5f..9284280 100644</span>
<span class="quote">&gt; --- a/mm/hugetlb.c</span>
<span class="quote">&gt; +++ b/mm/hugetlb.c</span>
<span class="quote">&gt; @@ -2216,6 +2216,10 @@ static unsigned long set_max_huge_pages(struct hstate *h, unsigned long count,</span>
<span class="quote">&gt;  		 * and reducing the surplus.</span>
<span class="quote">&gt;  		 */</span>
<span class="quote">&gt;  		spin_unlock(&amp;hugetlb_lock);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +		/* yield cpu to avoid soft lockup */</span>
<span class="quote">&gt; +		cond_resched();</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt;  		if (hstate_is_gigantic(h))</span>
<span class="quote">&gt;  			ret = alloc_fresh_gigantic_page(h, nodes_allowed);</span>
<span class="quote">&gt;  		else</span>
<span class="quote">&gt; -- </span>
<span class="quote">&gt; 2.5.0</span>
<span class="quote">&gt;</span>
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=137061">Michal Hocko</a> - July 28, 2016, 7:09 a.m.</div>
<pre class="content">
On Thu 28-07-16 10:54:02, Jia He wrote:
<span class="quote">&gt; In powerpc servers with large memory(32TB), we watched several soft</span>
<span class="quote">&gt; lockups for hugepage under stress tests.</span>
<span class="quote">&gt; The call trace are as follows:</span>
<span class="quote">&gt; 1.</span>
<span class="quote">&gt; get_page_from_freelist+0x2d8/0xd50  </span>
<span class="quote">&gt; __alloc_pages_nodemask+0x180/0xc20  </span>
<span class="quote">&gt; alloc_fresh_huge_page+0xb0/0x190    </span>
<span class="quote">&gt; set_max_huge_pages+0x164/0x3b0      </span>
<span class="quote">&gt; </span>
<span class="quote">&gt; 2.</span>
<span class="quote">&gt; prep_new_huge_page+0x5c/0x100             </span>
<span class="quote">&gt; alloc_fresh_huge_page+0xc8/0x190          </span>
<span class="quote">&gt; set_max_huge_pages+0x164/0x3b0</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; This patch is to fix such soft lockups. It is safe to call cond_resched() </span>
<span class="quote">&gt; there because it is out of spin_lock/unlock section.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Signed-off-by: Jia He &lt;hejianet@gmail.com&gt;</span>
<span class="quote">&gt; Cc: Andrew Morton &lt;akpm@linux-foundation.org&gt;</span>
<span class="quote">&gt; Cc: Naoya Horiguchi &lt;n-horiguchi@ah.jp.nec.com&gt;</span>
<span class="quote">&gt; Cc: Mike Kravetz &lt;mike.kravetz@oracle.com&gt;</span>
<span class="quote">&gt; Cc: &quot;Kirill A. Shutemov&quot; &lt;kirill.shutemov@linux.intel.com&gt;</span>
<span class="quote">&gt; Cc: Michal Hocko &lt;mhocko@suse.com&gt;</span>
<span class="quote">&gt; Cc: Dave Hansen &lt;dave.hansen@linux.intel.com&gt;</span>
<span class="quote">&gt; Cc: Paul Gortmaker &lt;paul.gortmaker@windriver.com&gt;</span>
<span class="acked-by">
Acked-by: Michal Hocko &lt;mhocko@suse.com&gt;</span>
<span class="quote">
&gt; </span>
<span class="quote">&gt; ---</span>
<span class="quote">&gt; Changes in V2: move cond_resched to a common calling site in set_max_huge_pages</span>
<span class="quote">&gt; </span>
<span class="quote">&gt;  mm/hugetlb.c | 4 ++++</span>
<span class="quote">&gt;  1 file changed, 4 insertions(+)</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; diff --git a/mm/hugetlb.c b/mm/hugetlb.c</span>
<span class="quote">&gt; index abc1c5f..9284280 100644</span>
<span class="quote">&gt; --- a/mm/hugetlb.c</span>
<span class="quote">&gt; +++ b/mm/hugetlb.c</span>
<span class="quote">&gt; @@ -2216,6 +2216,10 @@ static unsigned long set_max_huge_pages(struct hstate *h, unsigned long count,</span>
<span class="quote">&gt;  		 * and reducing the surplus.</span>
<span class="quote">&gt;  		 */</span>
<span class="quote">&gt;  		spin_unlock(&amp;hugetlb_lock);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +		/* yield cpu to avoid soft lockup */</span>
<span class="quote">&gt; +		cond_resched();</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt;  		if (hstate_is_gigantic(h))</span>
<span class="quote">&gt;  			ret = alloc_fresh_gigantic_page(h, nodes_allowed);</span>
<span class="quote">&gt;  		else</span>
<span class="quote">&gt; -- </span>
<span class="quote">&gt; 2.5.0</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; --</span>
<span class="quote">&gt; To unsubscribe, send a message with &#39;unsubscribe linux-mm&#39; in</span>
<span class="quote">&gt; the body to majordomo@kvack.org.  For more info on Linux MM,</span>
<span class="quote">&gt; see: http://www.linux-mm.org/ .</span>
<span class="quote">&gt; Don&#39;t email: &lt;a href=mailto:&quot;dont@kvack.org&quot;&gt; email@kvack.org &lt;/a&gt;</span>
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=64071">Dave Hansen</a> - July 28, 2016, 4:42 p.m.</div>
<pre class="content">
Looks fine to me.
<span class="acked-by">
Acked-by: Dave Hansen &lt;dave.hansen@linux.intel.com&gt;</span>
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/mm/hugetlb.c b/mm/hugetlb.c</span>
<span class="p_header">index abc1c5f..9284280 100644</span>
<span class="p_header">--- a/mm/hugetlb.c</span>
<span class="p_header">+++ b/mm/hugetlb.c</span>
<span class="p_chunk">@@ -2216,6 +2216,10 @@</span> <span class="p_context"> static unsigned long set_max_huge_pages(struct hstate *h, unsigned long count,</span>
 		 * and reducing the surplus.
 		 */
 		spin_unlock(&amp;hugetlb_lock);
<span class="p_add">+</span>
<span class="p_add">+		/* yield cpu to avoid soft lockup */</span>
<span class="p_add">+		cond_resched();</span>
<span class="p_add">+</span>
 		if (hstate_is_gigantic(h))
 			ret = alloc_fresh_gigantic_page(h, nodes_allowed);
 		else

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



