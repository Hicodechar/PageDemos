
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>[v10,4/5] iommu/mediatek: Add mt8173 IOMMU driver - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    [v10,4/5] iommu/mediatek: Add mt8173 IOMMU driver</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=123111">Yong Wu</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>Feb. 22, 2016, 5:20 p.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;1456161651-6136-5-git-send-email-yong.wu@mediatek.com&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/8385691/mbox/"
   >mbox</a>
|
   <a href="/patch/8385691/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/8385691/">/patch/8385691/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
X-Original-To: patchwork-LKML@patchwork.kernel.org
Delivered-To: patchwork-parsemail@patchwork2.web.kernel.org
Received: from mail.kernel.org (mail.kernel.org [198.145.29.136])
	by patchwork2.web.kernel.org (Postfix) with ESMTP id 33307C0553
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Tue, 23 Feb 2016 01:22:36 +0000 (UTC)
Received: from mail.kernel.org (localhost [127.0.0.1])
	by mail.kernel.org (Postfix) with ESMTP id 95C0720383
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Tue, 23 Feb 2016 01:22:34 +0000 (UTC)
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.kernel.org (Postfix) with ESMTP id AAF8820166
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Tue, 23 Feb 2016 01:22:32 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1756767AbcBWBW1 (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Mon, 22 Feb 2016 20:22:27 -0500
Received: from mailgw01.mediatek.com ([210.61.82.183]:24601 &quot;EHLO
	mailgw01.mediatek.com&quot; rhost-flags-OK-FAIL-OK-FAIL) by
	vger.kernel.org with ESMTP id S1756718AbcBWBWU (ORCPT
	&lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Mon, 22 Feb 2016 20:22:20 -0500
Received: from mtkhts09.mediatek.inc [(172.21.101.70)] by
	mailgw01.mediatek.com (envelope-from &lt;yong.wu@mediatek.com&gt;)
	(mhqrelay.mediatek.com ESMTP with TLS)
	with ESMTP id 2128748548; Tue, 23 Feb 2016 09:22:17 +0800
Received: from localhost.localdomain (10.17.3.153) by mtkhts09.mediatek.inc
	(172.21.101.73) with Microsoft SMTP Server id 14.3.266.1;
	Tue, 23 Feb 2016 09:22:15 +0800
From: Yong Wu &lt;yong.wu@mediatek.com&gt;
To: Joerg Roedel &lt;joro@8bytes.org&gt;, Thierry Reding &lt;treding@nvidia.com&gt;,
	Mark Rutland &lt;mark.rutland@arm.com&gt;,
	Matthias Brugger &lt;matthias.bgg@gmail.com&gt;
CC: Robin Murphy &lt;robin.murphy@arm.com&gt;, Will Deacon &lt;will.deacon@arm.com&gt;,
	Daniel Kurtz &lt;djkurtz@google.com&gt;, Tomasz Figa &lt;tfiga@google.com&gt;,
	Lucas Stach &lt;l.stach@pengutronix.de&gt;, Rob Herring &lt;robh+dt@kernel.org&gt;,
	Catalin Marinas &lt;catalin.marinas@arm.com&gt;,
	&lt;linux-mediatek@lists.infradead.org&gt;,
	Sasha Hauer &lt;kernel@pengutronix.de&gt;,
	&lt;srv_heupstream@mediatek.com&gt;, &lt;devicetree@vger.kernel.org&gt;,
	&lt;linux-kernel@vger.kernel.org&gt;, &lt;linux-arm-kernel@lists.infradead.org&gt;,
	&lt;iommu@lists.linux-foundation.org&gt;, &lt;pebolle@tiscali.nl&gt;,
	&lt;arnd@arndb.de&gt;, &lt;mitchelh@codeaurora.org&gt;,
	&lt;p.zabel@pengutronix.de&gt;, &lt;youhua.li@mediatek.com&gt;,
	&lt;kendrick.hsu@mediatek.com&gt;, Yong Wu &lt;yong.wu@mediatek.com&gt;
Subject: [PATCH v10 4/5] iommu/mediatek: Add mt8173 IOMMU driver
Date: Tue, 23 Feb 2016 01:20:50 +0800
Message-ID: &lt;1456161651-6136-5-git-send-email-yong.wu@mediatek.com&gt;
X-Mailer: git-send-email 1.8.1.1.dirty
In-Reply-To: &lt;1456161651-6136-1-git-send-email-yong.wu@mediatek.com&gt;
References: &lt;1456161651-6136-1-git-send-email-yong.wu@mediatek.com&gt;
MIME-Version: 1.0
Content-Type: text/plain
X-MTK: N
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Spam-Status: No, score=-5.4 required=5.0 tests=BAYES_00, DATE_IN_PAST_06_12,
	RCVD_IN_DNSWL_HI, RP_MATCHES_RCVD,
	UNPARSEABLE_RELAY autolearn=unavailable version=3.3.1
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on mail.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=123111">Yong Wu</a> - Feb. 22, 2016, 5:20 p.m.</div>
<pre class="content">
This patch adds support for mediatek m4u (MultiMedia Memory Management
Unit).
<span class="signed-off-by">
Signed-off-by: Yong Wu &lt;yong.wu@mediatek.com&gt;</span>
<span class="reviewed-by">Reviewed-by: Robin Murphy &lt;robin.murphy@arm.com&gt;</span>
---
 drivers/iommu/Kconfig     |  16 +
 drivers/iommu/Makefile    |   1 +
 drivers/iommu/mtk_iommu.c | 737 ++++++++++++++++++++++++++++++++++++++++++++++
 3 files changed, 754 insertions(+)
 create mode 100644 drivers/iommu/mtk_iommu.c
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/drivers/iommu/Kconfig b/drivers/iommu/Kconfig</span>
<span class="p_header">index a1e75cb..4922aa8 100644</span>
<span class="p_header">--- a/drivers/iommu/Kconfig</span>
<span class="p_header">+++ b/drivers/iommu/Kconfig</span>
<span class="p_chunk">@@ -318,4 +318,20 @@</span> <span class="p_context"> config S390_IOMMU</span>
 	help
 	  Support for the IOMMU API for s390 PCI devices.
 
<span class="p_add">+config MTK_IOMMU</span>
<span class="p_add">+	bool &quot;MTK IOMMU Support&quot;</span>
<span class="p_add">+	depends on ARM || ARM64</span>
<span class="p_add">+	depends on ARCH_MEDIATEK || COMPILE_TEST</span>
<span class="p_add">+	select IOMMU_API</span>
<span class="p_add">+	select IOMMU_DMA</span>
<span class="p_add">+	select IOMMU_IO_PGTABLE_ARMV7S</span>
<span class="p_add">+	select MEMORY</span>
<span class="p_add">+	select MTK_SMI</span>
<span class="p_add">+	help</span>
<span class="p_add">+	  Support for the M4U on certain Mediatek SOCs. M4U is MultiMedia</span>
<span class="p_add">+	  Memory Management Unit. This option enables remapping of DMA memory</span>
<span class="p_add">+	  accesses for the multimedia subsystem.</span>
<span class="p_add">+</span>
<span class="p_add">+	  If unsure, say N here.</span>
<span class="p_add">+</span>
 endif # IOMMU_SUPPORT
<span class="p_header">diff --git a/drivers/iommu/Makefile b/drivers/iommu/Makefile</span>
<span class="p_header">index 42fc0c2..44ae2e0 100644</span>
<span class="p_header">--- a/drivers/iommu/Makefile</span>
<span class="p_header">+++ b/drivers/iommu/Makefile</span>
<span class="p_chunk">@@ -16,6 +16,7 @@</span> <span class="p_context"> obj-$(CONFIG_INTEL_IOMMU) += intel-iommu.o</span>
 obj-$(CONFIG_INTEL_IOMMU_SVM) += intel-svm.o
 obj-$(CONFIG_IPMMU_VMSA) += ipmmu-vmsa.o
 obj-$(CONFIG_IRQ_REMAP) += intel_irq_remapping.o irq_remapping.o
<span class="p_add">+obj-$(CONFIG_MTK_IOMMU) += mtk_iommu.o</span>
 obj-$(CONFIG_OMAP_IOMMU) += omap-iommu.o
 obj-$(CONFIG_OMAP_IOMMU_DEBUG) += omap-iommu-debug.o
 obj-$(CONFIG_ROCKCHIP_IOMMU) += rockchip-iommu.o
<span class="p_header">diff --git a/drivers/iommu/mtk_iommu.c b/drivers/iommu/mtk_iommu.c</span>
new file mode 100644
<span class="p_header">index 0000000..721ffdb</span>
<span class="p_header">--- /dev/null</span>
<span class="p_header">+++ b/drivers/iommu/mtk_iommu.c</span>
<span class="p_chunk">@@ -0,0 +1,737 @@</span> <span class="p_context"></span>
<span class="p_add">+/*</span>
<span class="p_add">+ * Copyright (c) 2015-2016 MediaTek Inc.</span>
<span class="p_add">+ * Author: Yong Wu &lt;yong.wu@mediatek.com&gt;</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * This program is free software; you can redistribute it and/or modify</span>
<span class="p_add">+ * it under the terms of the GNU General Public License version 2 as</span>
<span class="p_add">+ * published by the Free Software Foundation.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * This program is distributed in the hope that it will be useful,</span>
<span class="p_add">+ * but WITHOUT ANY WARRANTY; without even the implied warranty of</span>
<span class="p_add">+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the</span>
<span class="p_add">+ * GNU General Public License for more details.</span>
<span class="p_add">+ */</span>
<span class="p_add">+#include &lt;linux/bug.h&gt;</span>
<span class="p_add">+#include &lt;linux/clk.h&gt;</span>
<span class="p_add">+#include &lt;linux/component.h&gt;</span>
<span class="p_add">+#include &lt;linux/device.h&gt;</span>
<span class="p_add">+#include &lt;linux/dma-iommu.h&gt;</span>
<span class="p_add">+#include &lt;linux/err.h&gt;</span>
<span class="p_add">+#include &lt;linux/interrupt.h&gt;</span>
<span class="p_add">+#include &lt;linux/io.h&gt;</span>
<span class="p_add">+#include &lt;linux/iommu.h&gt;</span>
<span class="p_add">+#include &lt;linux/iopoll.h&gt;</span>
<span class="p_add">+#include &lt;linux/list.h&gt;</span>
<span class="p_add">+#include &lt;linux/of_address.h&gt;</span>
<span class="p_add">+#include &lt;linux/of_iommu.h&gt;</span>
<span class="p_add">+#include &lt;linux/of_irq.h&gt;</span>
<span class="p_add">+#include &lt;linux/of_platform.h&gt;</span>
<span class="p_add">+#include &lt;linux/platform_device.h&gt;</span>
<span class="p_add">+#include &lt;linux/slab.h&gt;</span>
<span class="p_add">+#include &lt;linux/spinlock.h&gt;</span>
<span class="p_add">+#include &lt;asm/barrier.h&gt;</span>
<span class="p_add">+#include &lt;dt-bindings/memory/mt8173-larb-port.h&gt;</span>
<span class="p_add">+#include &lt;soc/mediatek/smi.h&gt;</span>
<span class="p_add">+</span>
<span class="p_add">+#include &quot;io-pgtable.h&quot;</span>
<span class="p_add">+</span>
<span class="p_add">+#define REG_MMU_PT_BASE_ADDR			0x000</span>
<span class="p_add">+</span>
<span class="p_add">+#define REG_MMU_INVALIDATE			0x020</span>
<span class="p_add">+#define F_ALL_INVLD				0x2</span>
<span class="p_add">+#define F_MMU_INV_RANGE				0x1</span>
<span class="p_add">+</span>
<span class="p_add">+#define REG_MMU_INVLD_START_A			0x024</span>
<span class="p_add">+#define REG_MMU_INVLD_END_A			0x028</span>
<span class="p_add">+</span>
<span class="p_add">+#define REG_MMU_INV_SEL				0x038</span>
<span class="p_add">+#define F_INVLD_EN0				BIT(0)</span>
<span class="p_add">+#define F_INVLD_EN1				BIT(1)</span>
<span class="p_add">+</span>
<span class="p_add">+#define REG_MMU_STANDARD_AXI_MODE		0x048</span>
<span class="p_add">+#define REG_MMU_DCM_DIS				0x050</span>
<span class="p_add">+</span>
<span class="p_add">+#define REG_MMU_CTRL_REG			0x110</span>
<span class="p_add">+#define F_MMU_PREFETCH_RT_REPLACE_MOD		BIT(4)</span>
<span class="p_add">+#define F_MMU_TF_PROTECT_SEL(prot)		(((prot) &amp; 0x3) &lt;&lt; 5)</span>
<span class="p_add">+</span>
<span class="p_add">+#define REG_MMU_IVRP_PADDR			0x114</span>
<span class="p_add">+#define F_MMU_IVRP_PA_SET(pa)			((pa) &gt;&gt; 1)</span>
<span class="p_add">+</span>
<span class="p_add">+#define REG_MMU_INT_CONTROL0			0x120</span>
<span class="p_add">+#define F_L2_MULIT_HIT_EN			BIT(0)</span>
<span class="p_add">+#define F_TABLE_WALK_FAULT_INT_EN		BIT(1)</span>
<span class="p_add">+#define F_PREETCH_FIFO_OVERFLOW_INT_EN		BIT(2)</span>
<span class="p_add">+#define F_MISS_FIFO_OVERFLOW_INT_EN		BIT(3)</span>
<span class="p_add">+#define F_PREFETCH_FIFO_ERR_INT_EN		BIT(5)</span>
<span class="p_add">+#define F_MISS_FIFO_ERR_INT_EN			BIT(6)</span>
<span class="p_add">+#define F_INT_CLR_BIT				BIT(12)</span>
<span class="p_add">+</span>
<span class="p_add">+#define REG_MMU_INT_MAIN_CONTROL		0x124</span>
<span class="p_add">+#define F_INT_TRANSLATION_FAULT			BIT(0)</span>
<span class="p_add">+#define F_INT_MAIN_MULTI_HIT_FAULT		BIT(1)</span>
<span class="p_add">+#define F_INT_INVALID_PA_FAULT			BIT(2)</span>
<span class="p_add">+#define F_INT_ENTRY_REPLACEMENT_FAULT		BIT(3)</span>
<span class="p_add">+#define F_INT_TLB_MISS_FAULT			BIT(4)</span>
<span class="p_add">+#define F_INT_MISS_TRANSACTION_FIFO_FAULT	BIT(5)</span>
<span class="p_add">+#define F_INT_PRETETCH_TRANSATION_FIFO_FAULT	BIT(6)</span>
<span class="p_add">+</span>
<span class="p_add">+#define REG_MMU_CPE_DONE			0x12C</span>
<span class="p_add">+</span>
<span class="p_add">+#define REG_MMU_FAULT_ST1			0x134</span>
<span class="p_add">+</span>
<span class="p_add">+#define REG_MMU_FAULT_VA			0x13c</span>
<span class="p_add">+#define F_MMU_FAULT_VA_MSK			0xfffff000</span>
<span class="p_add">+#define F_MMU_FAULT_VA_WRITE_BIT		BIT(1)</span>
<span class="p_add">+#define F_MMU_FAULT_VA_LAYER_BIT		BIT(0)</span>
<span class="p_add">+</span>
<span class="p_add">+#define REG_MMU_INVLD_PA			0x140</span>
<span class="p_add">+#define REG_MMU_INT_ID				0x150</span>
<span class="p_add">+#define F_MMU0_INT_ID_LARB_ID(a)		(((a) &gt;&gt; 7) &amp; 0x7)</span>
<span class="p_add">+#define F_MMU0_INT_ID_PORT_ID(a)		(((a) &gt;&gt; 2) &amp; 0x1f)</span>
<span class="p_add">+</span>
<span class="p_add">+#define MTK_PROTECT_PA_ALIGN			128</span>
<span class="p_add">+</span>
<span class="p_add">+struct mtk_iommu_suspend_reg {</span>
<span class="p_add">+	u32				standard_axi_mode;</span>
<span class="p_add">+	u32				dcm_dis;</span>
<span class="p_add">+	u32				ctrl_reg;</span>
<span class="p_add">+	u32				int_control0;</span>
<span class="p_add">+	u32				int_main_control;</span>
<span class="p_add">+};</span>
<span class="p_add">+</span>
<span class="p_add">+struct mtk_iommu_client_priv {</span>
<span class="p_add">+	struct list_head		client;</span>
<span class="p_add">+	unsigned int			mtk_m4u_id;</span>
<span class="p_add">+	struct device			*m4udev;</span>
<span class="p_add">+};</span>
<span class="p_add">+</span>
<span class="p_add">+struct mtk_iommu_domain {</span>
<span class="p_add">+	spinlock_t			pgtlock; /* lock for page table */</span>
<span class="p_add">+</span>
<span class="p_add">+	struct io_pgtable_cfg		cfg;</span>
<span class="p_add">+	struct io_pgtable_ops		*iop;</span>
<span class="p_add">+</span>
<span class="p_add">+	struct iommu_domain		domain;</span>
<span class="p_add">+};</span>
<span class="p_add">+</span>
<span class="p_add">+struct mtk_iommu_data {</span>
<span class="p_add">+	void __iomem			*base;</span>
<span class="p_add">+	int				irq;</span>
<span class="p_add">+	struct device			*dev;</span>
<span class="p_add">+	struct clk			*bclk;</span>
<span class="p_add">+	phys_addr_t			protect_base; /* protect memory base */</span>
<span class="p_add">+	struct mtk_iommu_suspend_reg	reg;</span>
<span class="p_add">+	struct mtk_iommu_domain		*m4u_dom;</span>
<span class="p_add">+	struct iommu_group		*m4u_group;</span>
<span class="p_add">+	struct mtk_smi_iommu		smi_imu;      /* SMI larb iommu info */</span>
<span class="p_add">+};</span>
<span class="p_add">+</span>
<span class="p_add">+static struct iommu_ops mtk_iommu_ops;</span>
<span class="p_add">+</span>
<span class="p_add">+static struct mtk_iommu_domain *to_mtk_domain(struct iommu_domain *dom)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return container_of(dom, struct mtk_iommu_domain, domain);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static void mtk_iommu_tlb_flush_all(void *cookie)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct mtk_iommu_data *data = cookie;</span>
<span class="p_add">+</span>
<span class="p_add">+	writel_relaxed(F_INVLD_EN1 | F_INVLD_EN0, data-&gt;base + REG_MMU_INV_SEL);</span>
<span class="p_add">+	writel_relaxed(F_ALL_INVLD, data-&gt;base + REG_MMU_INVALIDATE);</span>
<span class="p_add">+	wmb(); /* Make sure the tlb flush all done */</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static void mtk_iommu_tlb_add_flush_nosync(unsigned long iova, size_t size,</span>
<span class="p_add">+					   size_t granule, bool leaf,</span>
<span class="p_add">+					   void *cookie)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct mtk_iommu_data *data = cookie;</span>
<span class="p_add">+</span>
<span class="p_add">+	writel_relaxed(F_INVLD_EN1 | F_INVLD_EN0, data-&gt;base + REG_MMU_INV_SEL);</span>
<span class="p_add">+</span>
<span class="p_add">+	writel_relaxed(iova, data-&gt;base + REG_MMU_INVLD_START_A);</span>
<span class="p_add">+	writel_relaxed(iova + size - 1, data-&gt;base + REG_MMU_INVLD_END_A);</span>
<span class="p_add">+	writel_relaxed(F_MMU_INV_RANGE, data-&gt;base + REG_MMU_INVALIDATE);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static void mtk_iommu_tlb_sync(void *cookie)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct mtk_iommu_data *data = cookie;</span>
<span class="p_add">+	int ret;</span>
<span class="p_add">+	u32 tmp;</span>
<span class="p_add">+</span>
<span class="p_add">+	ret = readl_poll_timeout_atomic(data-&gt;base + REG_MMU_CPE_DONE, tmp,</span>
<span class="p_add">+					tmp != 0, 10, 100000);</span>
<span class="p_add">+	if (ret) {</span>
<span class="p_add">+		dev_warn(data-&gt;dev,</span>
<span class="p_add">+			 &quot;Partial TLB flush timed out, falling back to full flush\n&quot;);</span>
<span class="p_add">+		mtk_iommu_tlb_flush_all(cookie);</span>
<span class="p_add">+	}</span>
<span class="p_add">+	/* Clear the CPE status */</span>
<span class="p_add">+	writel_relaxed(0, data-&gt;base + REG_MMU_CPE_DONE);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static const struct iommu_gather_ops mtk_iommu_gather_ops = {</span>
<span class="p_add">+	.tlb_flush_all = mtk_iommu_tlb_flush_all,</span>
<span class="p_add">+	.tlb_add_flush = mtk_iommu_tlb_add_flush_nosync,</span>
<span class="p_add">+	.tlb_sync = mtk_iommu_tlb_sync,</span>
<span class="p_add">+};</span>
<span class="p_add">+</span>
<span class="p_add">+static irqreturn_t mtk_iommu_isr(int irq, void *dev_id)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct mtk_iommu_data *data = dev_id;</span>
<span class="p_add">+	struct mtk_iommu_domain *dom = data-&gt;m4u_dom;</span>
<span class="p_add">+	u32 int_state, regval, fault_iova, fault_pa;</span>
<span class="p_add">+	unsigned int fault_larb, fault_port;</span>
<span class="p_add">+	bool layer, write;</span>
<span class="p_add">+</span>
<span class="p_add">+	/* Read error info from registers */</span>
<span class="p_add">+	int_state = readl_relaxed(data-&gt;base + REG_MMU_FAULT_ST1);</span>
<span class="p_add">+	fault_iova = readl_relaxed(data-&gt;base + REG_MMU_FAULT_VA);</span>
<span class="p_add">+	layer = fault_iova &amp; F_MMU_FAULT_VA_LAYER_BIT;</span>
<span class="p_add">+	write = fault_iova &amp; F_MMU_FAULT_VA_WRITE_BIT;</span>
<span class="p_add">+	fault_iova &amp;= F_MMU_FAULT_VA_MSK;</span>
<span class="p_add">+	fault_pa = readl_relaxed(data-&gt;base + REG_MMU_INVLD_PA);</span>
<span class="p_add">+	regval = readl_relaxed(data-&gt;base + REG_MMU_INT_ID);</span>
<span class="p_add">+	fault_larb = F_MMU0_INT_ID_LARB_ID(regval);</span>
<span class="p_add">+	fault_port = F_MMU0_INT_ID_PORT_ID(regval);</span>
<span class="p_add">+</span>
<span class="p_add">+	if (report_iommu_fault(&amp;dom-&gt;domain, data-&gt;dev, fault_iova,</span>
<span class="p_add">+			       write ? IOMMU_FAULT_WRITE : IOMMU_FAULT_READ)) {</span>
<span class="p_add">+		dev_err_ratelimited(</span>
<span class="p_add">+			data-&gt;dev,</span>
<span class="p_add">+			&quot;fault type=0x%x iova=0x%x pa=0x%x larb=%d port=%d layer=%d %s\n&quot;,</span>
<span class="p_add">+			int_state, fault_iova, fault_pa, fault_larb, fault_port,</span>
<span class="p_add">+			layer, write ? &quot;write&quot; : &quot;read&quot;);</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	/* Interrupt clear */</span>
<span class="p_add">+	regval = readl_relaxed(data-&gt;base + REG_MMU_INT_CONTROL0);</span>
<span class="p_add">+	regval |= F_INT_CLR_BIT;</span>
<span class="p_add">+	writel_relaxed(regval, data-&gt;base + REG_MMU_INT_CONTROL0);</span>
<span class="p_add">+</span>
<span class="p_add">+	mtk_iommu_tlb_flush_all(data);</span>
<span class="p_add">+</span>
<span class="p_add">+	return IRQ_HANDLED;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static void mtk_iommu_config(struct mtk_iommu_data *data,</span>
<span class="p_add">+			     struct device *dev, bool enable)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct mtk_iommu_client_priv *head, *cur, *next;</span>
<span class="p_add">+	struct mtk_smi_larb_iommu    *larb_mmu;</span>
<span class="p_add">+	unsigned int                 larbid, portid;</span>
<span class="p_add">+</span>
<span class="p_add">+	head = dev-&gt;archdata.iommu;</span>
<span class="p_add">+	list_for_each_entry_safe(cur, next, &amp;head-&gt;client, client) {</span>
<span class="p_add">+		larbid = MTK_M4U_TO_LARB(cur-&gt;mtk_m4u_id);</span>
<span class="p_add">+		portid = MTK_M4U_TO_PORT(cur-&gt;mtk_m4u_id);</span>
<span class="p_add">+		larb_mmu = &amp;data-&gt;smi_imu.larb_imu[larbid];</span>
<span class="p_add">+</span>
<span class="p_add">+		dev_dbg(dev, &quot;%s iommu port: %d\n&quot;,</span>
<span class="p_add">+			enable ? &quot;enable&quot; : &quot;disable&quot;, portid);</span>
<span class="p_add">+</span>
<span class="p_add">+		if (enable)</span>
<span class="p_add">+			larb_mmu-&gt;mmu |= MTK_SMI_MMU_EN(portid);</span>
<span class="p_add">+		else</span>
<span class="p_add">+			larb_mmu-&gt;mmu &amp;= ~MTK_SMI_MMU_EN(portid);</span>
<span class="p_add">+	}</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static int mtk_iommu_domain_finalise(struct mtk_iommu_data *data)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct mtk_iommu_domain *dom = data-&gt;m4u_dom;</span>
<span class="p_add">+</span>
<span class="p_add">+	spin_lock_init(&amp;dom-&gt;pgtlock);</span>
<span class="p_add">+</span>
<span class="p_add">+	dom-&gt;cfg = (struct io_pgtable_cfg) {</span>
<span class="p_add">+		.quirks = IO_PGTABLE_QUIRK_ARM_NS |</span>
<span class="p_add">+			IO_PGTABLE_QUIRK_NO_PERMS |</span>
<span class="p_add">+			IO_PGTABLE_QUIRK_TLBI_ON_MAP,</span>
<span class="p_add">+		.pgsize_bitmap = mtk_iommu_ops.pgsize_bitmap,</span>
<span class="p_add">+		.ias = 32,</span>
<span class="p_add">+		.oas = 32,</span>
<span class="p_add">+		.tlb = &amp;mtk_iommu_gather_ops,</span>
<span class="p_add">+		.iommu_dev = data-&gt;dev,</span>
<span class="p_add">+	};</span>
<span class="p_add">+</span>
<span class="p_add">+	dom-&gt;iop = alloc_io_pgtable_ops(ARM_V7S, &amp;dom-&gt;cfg, data);</span>
<span class="p_add">+	if (!dom-&gt;iop) {</span>
<span class="p_add">+		dev_err(data-&gt;dev, &quot;Failed to alloc io pgtable\n&quot;);</span>
<span class="p_add">+		return -EINVAL;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	/* Update our support page sizes bitmap */</span>
<span class="p_add">+	mtk_iommu_ops.pgsize_bitmap = dom-&gt;cfg.pgsize_bitmap;</span>
<span class="p_add">+</span>
<span class="p_add">+	writel(data-&gt;m4u_dom-&gt;cfg.arm_v7s_cfg.ttbr[0],</span>
<span class="p_add">+	       data-&gt;base + REG_MMU_PT_BASE_ADDR);</span>
<span class="p_add">+	return 0;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static struct iommu_domain *mtk_iommu_domain_alloc(unsigned type)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct mtk_iommu_domain *dom;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (type != IOMMU_DOMAIN_DMA)</span>
<span class="p_add">+		return NULL;</span>
<span class="p_add">+</span>
<span class="p_add">+	dom = kzalloc(sizeof(*dom), GFP_KERNEL);</span>
<span class="p_add">+	if (!dom)</span>
<span class="p_add">+		return NULL;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (iommu_get_dma_cookie(&amp;dom-&gt;domain)) {</span>
<span class="p_add">+		kfree(dom);</span>
<span class="p_add">+		return NULL;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	dom-&gt;domain.geometry.aperture_start = 0;</span>
<span class="p_add">+	dom-&gt;domain.geometry.aperture_end = DMA_BIT_MASK(32);</span>
<span class="p_add">+	dom-&gt;domain.geometry.force_aperture = true;</span>
<span class="p_add">+</span>
<span class="p_add">+	return &amp;dom-&gt;domain;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static void mtk_iommu_domain_free(struct iommu_domain *domain)</span>
<span class="p_add">+{</span>
<span class="p_add">+	iommu_put_dma_cookie(domain);</span>
<span class="p_add">+	kfree(to_mtk_domain(domain));</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static int mtk_iommu_attach_device(struct iommu_domain *domain,</span>
<span class="p_add">+				   struct device *dev)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct mtk_iommu_domain *dom = to_mtk_domain(domain);</span>
<span class="p_add">+	struct mtk_iommu_client_priv *priv = dev-&gt;archdata.iommu;</span>
<span class="p_add">+	struct mtk_iommu_data *data;</span>
<span class="p_add">+	int ret;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (!priv)</span>
<span class="p_add">+		return -ENODEV;</span>
<span class="p_add">+</span>
<span class="p_add">+	data = dev_get_drvdata(priv-&gt;m4udev);</span>
<span class="p_add">+	if (!data-&gt;m4u_dom) {</span>
<span class="p_add">+		data-&gt;m4u_dom = dom;</span>
<span class="p_add">+		ret = mtk_iommu_domain_finalise(data);</span>
<span class="p_add">+		if (ret) {</span>
<span class="p_add">+			data-&gt;m4u_dom = NULL;</span>
<span class="p_add">+			return ret;</span>
<span class="p_add">+		}</span>
<span class="p_add">+	} else if (data-&gt;m4u_dom != dom) {</span>
<span class="p_add">+		/* All the client devices should be in the same m4u domain */</span>
<span class="p_add">+		dev_err(dev, &quot;try to attach into the error iommu domain\n&quot;);</span>
<span class="p_add">+		return -EPERM;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	mtk_iommu_config(data, dev, true);</span>
<span class="p_add">+	return 0;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static void mtk_iommu_detach_device(struct iommu_domain *domain,</span>
<span class="p_add">+				    struct device *dev)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct mtk_iommu_client_priv *priv = dev-&gt;archdata.iommu;</span>
<span class="p_add">+	struct mtk_iommu_data *data;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (!priv)</span>
<span class="p_add">+		return;</span>
<span class="p_add">+</span>
<span class="p_add">+	data = dev_get_drvdata(priv-&gt;m4udev);</span>
<span class="p_add">+	mtk_iommu_config(data, dev, false);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static int mtk_iommu_map(struct iommu_domain *domain, unsigned long iova,</span>
<span class="p_add">+			 phys_addr_t paddr, size_t size, int prot)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct mtk_iommu_domain *dom = to_mtk_domain(domain);</span>
<span class="p_add">+	unsigned long flags;</span>
<span class="p_add">+	int ret;</span>
<span class="p_add">+</span>
<span class="p_add">+	spin_lock_irqsave(&amp;dom-&gt;pgtlock, flags);</span>
<span class="p_add">+	ret = dom-&gt;iop-&gt;map(dom-&gt;iop, iova, paddr, size, prot);</span>
<span class="p_add">+	spin_unlock_irqrestore(&amp;dom-&gt;pgtlock, flags);</span>
<span class="p_add">+</span>
<span class="p_add">+	return ret;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static size_t mtk_iommu_unmap(struct iommu_domain *domain,</span>
<span class="p_add">+			      unsigned long iova, size_t size)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct mtk_iommu_domain *dom = to_mtk_domain(domain);</span>
<span class="p_add">+	unsigned long flags;</span>
<span class="p_add">+	size_t unmapsz;</span>
<span class="p_add">+</span>
<span class="p_add">+	spin_lock_irqsave(&amp;dom-&gt;pgtlock, flags);</span>
<span class="p_add">+	unmapsz = dom-&gt;iop-&gt;unmap(dom-&gt;iop, iova, size);</span>
<span class="p_add">+	spin_unlock_irqrestore(&amp;dom-&gt;pgtlock, flags);</span>
<span class="p_add">+</span>
<span class="p_add">+	return unmapsz;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static phys_addr_t mtk_iommu_iova_to_phys(struct iommu_domain *domain,</span>
<span class="p_add">+					  dma_addr_t iova)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct mtk_iommu_domain *dom = to_mtk_domain(domain);</span>
<span class="p_add">+	unsigned long flags;</span>
<span class="p_add">+	phys_addr_t pa;</span>
<span class="p_add">+</span>
<span class="p_add">+	spin_lock_irqsave(&amp;dom-&gt;pgtlock, flags);</span>
<span class="p_add">+	pa = dom-&gt;iop-&gt;iova_to_phys(dom-&gt;iop, iova);</span>
<span class="p_add">+	spin_unlock_irqrestore(&amp;dom-&gt;pgtlock, flags);</span>
<span class="p_add">+</span>
<span class="p_add">+	return pa;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static int mtk_iommu_add_device(struct device *dev)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct iommu_group *group;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (!dev-&gt;archdata.iommu) /* Not a iommu client device */</span>
<span class="p_add">+		return -ENODEV;</span>
<span class="p_add">+</span>
<span class="p_add">+	group = iommu_group_get_for_dev(dev);</span>
<span class="p_add">+	if (IS_ERR(group))</span>
<span class="p_add">+		return PTR_ERR(group);</span>
<span class="p_add">+</span>
<span class="p_add">+	iommu_group_put(group);</span>
<span class="p_add">+	return 0;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static void mtk_iommu_remove_device(struct device *dev)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct mtk_iommu_client_priv *head, *cur, *next;</span>
<span class="p_add">+</span>
<span class="p_add">+	head = dev-&gt;archdata.iommu;</span>
<span class="p_add">+	if (!head)</span>
<span class="p_add">+		return;</span>
<span class="p_add">+</span>
<span class="p_add">+	list_for_each_entry_safe(cur, next, &amp;head-&gt;client, client) {</span>
<span class="p_add">+		list_del(&amp;cur-&gt;client);</span>
<span class="p_add">+		kfree(cur);</span>
<span class="p_add">+	}</span>
<span class="p_add">+	kfree(head);</span>
<span class="p_add">+	dev-&gt;archdata.iommu = NULL;</span>
<span class="p_add">+</span>
<span class="p_add">+	iommu_group_remove_device(dev);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static struct iommu_group *mtk_iommu_device_group(struct device *dev)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct mtk_iommu_data *data;</span>
<span class="p_add">+	struct mtk_iommu_client_priv *priv;</span>
<span class="p_add">+</span>
<span class="p_add">+	priv = dev-&gt;archdata.iommu;</span>
<span class="p_add">+	if (!priv)</span>
<span class="p_add">+		return ERR_PTR(-ENODEV);</span>
<span class="p_add">+</span>
<span class="p_add">+	/* All the client devices are in the same m4u iommu-group */</span>
<span class="p_add">+	data = dev_get_drvdata(priv-&gt;m4udev);</span>
<span class="p_add">+	if (!data-&gt;m4u_group) {</span>
<span class="p_add">+		data-&gt;m4u_group = iommu_group_alloc();</span>
<span class="p_add">+		if (IS_ERR(data-&gt;m4u_group))</span>
<span class="p_add">+			dev_err(dev, &quot;Failed to allocate M4U IOMMU group\n&quot;);</span>
<span class="p_add">+	}</span>
<span class="p_add">+	return data-&gt;m4u_group;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static int mtk_iommu_of_xlate(struct device *dev, struct of_phandle_args *args)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct mtk_iommu_client_priv *head, *priv, *next;</span>
<span class="p_add">+	struct platform_device *m4updev;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (args-&gt;args_count != 1) {</span>
<span class="p_add">+		dev_err(dev, &quot;invalid #iommu-cells(%d) property for IOMMU\n&quot;,</span>
<span class="p_add">+			args-&gt;args_count);</span>
<span class="p_add">+		return -EINVAL;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	if (!dev-&gt;archdata.iommu) {</span>
<span class="p_add">+		/* Get the m4u device */</span>
<span class="p_add">+		m4updev = of_find_device_by_node(args-&gt;np);</span>
<span class="p_add">+		of_node_put(args-&gt;np);</span>
<span class="p_add">+		if (WARN_ON(!m4updev))</span>
<span class="p_add">+			return -EINVAL;</span>
<span class="p_add">+</span>
<span class="p_add">+		head = kzalloc(sizeof(*head), GFP_KERNEL);</span>
<span class="p_add">+		if (!head)</span>
<span class="p_add">+			return -ENOMEM;</span>
<span class="p_add">+</span>
<span class="p_add">+		dev-&gt;archdata.iommu = head;</span>
<span class="p_add">+		INIT_LIST_HEAD(&amp;head-&gt;client);</span>
<span class="p_add">+		head-&gt;m4udev = &amp;m4updev-&gt;dev;</span>
<span class="p_add">+	} else {</span>
<span class="p_add">+		head = dev-&gt;archdata.iommu;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	priv = kzalloc(sizeof(*priv), GFP_KERNEL);</span>
<span class="p_add">+	if (!priv)</span>
<span class="p_add">+		goto err_free_mem;</span>
<span class="p_add">+</span>
<span class="p_add">+	priv-&gt;mtk_m4u_id = args-&gt;args[0];</span>
<span class="p_add">+	list_add_tail(&amp;priv-&gt;client, &amp;head-&gt;client);</span>
<span class="p_add">+</span>
<span class="p_add">+	return 0;</span>
<span class="p_add">+</span>
<span class="p_add">+err_free_mem:</span>
<span class="p_add">+	list_for_each_entry_safe(priv, next, &amp;head-&gt;client, client)</span>
<span class="p_add">+		kfree(priv);</span>
<span class="p_add">+	kfree(head);</span>
<span class="p_add">+	dev-&gt;archdata.iommu = NULL;</span>
<span class="p_add">+	return -ENOMEM;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static struct iommu_ops mtk_iommu_ops = {</span>
<span class="p_add">+	.domain_alloc	= mtk_iommu_domain_alloc,</span>
<span class="p_add">+	.domain_free	= mtk_iommu_domain_free,</span>
<span class="p_add">+	.attach_dev	= mtk_iommu_attach_device,</span>
<span class="p_add">+	.detach_dev	= mtk_iommu_detach_device,</span>
<span class="p_add">+	.map		= mtk_iommu_map,</span>
<span class="p_add">+	.unmap		= mtk_iommu_unmap,</span>
<span class="p_add">+	.map_sg		= default_iommu_map_sg,</span>
<span class="p_add">+	.iova_to_phys	= mtk_iommu_iova_to_phys,</span>
<span class="p_add">+	.add_device	= mtk_iommu_add_device,</span>
<span class="p_add">+	.remove_device	= mtk_iommu_remove_device,</span>
<span class="p_add">+	.device_group	= mtk_iommu_device_group,</span>
<span class="p_add">+	.of_xlate	= mtk_iommu_of_xlate,</span>
<span class="p_add">+	.pgsize_bitmap	= SZ_4K | SZ_64K | SZ_1M | SZ_16M,</span>
<span class="p_add">+};</span>
<span class="p_add">+</span>
<span class="p_add">+static int mtk_iommu_hw_init(const struct mtk_iommu_data *data)</span>
<span class="p_add">+{</span>
<span class="p_add">+	u32 regval;</span>
<span class="p_add">+	int ret;</span>
<span class="p_add">+</span>
<span class="p_add">+	ret = clk_prepare_enable(data-&gt;bclk);</span>
<span class="p_add">+	if (ret) {</span>
<span class="p_add">+		dev_err(data-&gt;dev, &quot;Failed to enable iommu bclk(%d)\n&quot;, ret);</span>
<span class="p_add">+		return ret;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	regval = F_MMU_PREFETCH_RT_REPLACE_MOD |</span>
<span class="p_add">+		F_MMU_TF_PROTECT_SEL(2);</span>
<span class="p_add">+	writel_relaxed(regval, data-&gt;base + REG_MMU_CTRL_REG);</span>
<span class="p_add">+</span>
<span class="p_add">+	regval = F_L2_MULIT_HIT_EN |</span>
<span class="p_add">+		F_TABLE_WALK_FAULT_INT_EN |</span>
<span class="p_add">+		F_PREETCH_FIFO_OVERFLOW_INT_EN |</span>
<span class="p_add">+		F_MISS_FIFO_OVERFLOW_INT_EN |</span>
<span class="p_add">+		F_PREFETCH_FIFO_ERR_INT_EN |</span>
<span class="p_add">+		F_MISS_FIFO_ERR_INT_EN;</span>
<span class="p_add">+	writel_relaxed(regval, data-&gt;base + REG_MMU_INT_CONTROL0);</span>
<span class="p_add">+</span>
<span class="p_add">+	regval = F_INT_TRANSLATION_FAULT |</span>
<span class="p_add">+		F_INT_MAIN_MULTI_HIT_FAULT |</span>
<span class="p_add">+		F_INT_INVALID_PA_FAULT |</span>
<span class="p_add">+		F_INT_ENTRY_REPLACEMENT_FAULT |</span>
<span class="p_add">+		F_INT_TLB_MISS_FAULT |</span>
<span class="p_add">+		F_INT_MISS_TRANSACTION_FIFO_FAULT |</span>
<span class="p_add">+		F_INT_PRETETCH_TRANSATION_FIFO_FAULT;</span>
<span class="p_add">+	writel_relaxed(regval, data-&gt;base + REG_MMU_INT_MAIN_CONTROL);</span>
<span class="p_add">+</span>
<span class="p_add">+	writel_relaxed(F_MMU_IVRP_PA_SET(data-&gt;protect_base),</span>
<span class="p_add">+		       data-&gt;base + REG_MMU_IVRP_PADDR);</span>
<span class="p_add">+</span>
<span class="p_add">+	writel_relaxed(0, data-&gt;base + REG_MMU_DCM_DIS);</span>
<span class="p_add">+	writel_relaxed(0, data-&gt;base + REG_MMU_STANDARD_AXI_MODE);</span>
<span class="p_add">+</span>
<span class="p_add">+	if (devm_request_irq(data-&gt;dev, data-&gt;irq, mtk_iommu_isr, 0,</span>
<span class="p_add">+			     dev_name(data-&gt;dev), (void *)data)) {</span>
<span class="p_add">+		writel_relaxed(0, data-&gt;base + REG_MMU_PT_BASE_ADDR);</span>
<span class="p_add">+		clk_disable_unprepare(data-&gt;bclk);</span>
<span class="p_add">+		dev_err(data-&gt;dev, &quot;Failed @ IRQ-%d Request\n&quot;, data-&gt;irq);</span>
<span class="p_add">+		return -ENODEV;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	return 0;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static int compare_of(struct device *dev, void *data)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return dev-&gt;of_node == data;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static int mtk_iommu_bind(struct device *dev)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct mtk_iommu_data *data = dev_get_drvdata(dev);</span>
<span class="p_add">+</span>
<span class="p_add">+	return component_bind_all(dev, &amp;data-&gt;smi_imu);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static void mtk_iommu_unbind(struct device *dev)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct mtk_iommu_data *data = dev_get_drvdata(dev);</span>
<span class="p_add">+</span>
<span class="p_add">+	component_unbind_all(dev, &amp;data-&gt;smi_imu);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static const struct component_master_ops mtk_iommu_com_ops = {</span>
<span class="p_add">+	.bind		= mtk_iommu_bind,</span>
<span class="p_add">+	.unbind		= mtk_iommu_unbind,</span>
<span class="p_add">+};</span>
<span class="p_add">+</span>
<span class="p_add">+static int mtk_iommu_probe(struct platform_device *pdev)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct mtk_iommu_data   *data;</span>
<span class="p_add">+	struct device           *dev = &amp;pdev-&gt;dev;</span>
<span class="p_add">+	struct resource         *res;</span>
<span class="p_add">+	struct component_match  *match = NULL;</span>
<span class="p_add">+	void                    *protect;</span>
<span class="p_add">+	unsigned int            i, larb_nr;</span>
<span class="p_add">+	int                     ret;</span>
<span class="p_add">+</span>
<span class="p_add">+	data = devm_kzalloc(dev, sizeof(*data), GFP_KERNEL);</span>
<span class="p_add">+	if (!data)</span>
<span class="p_add">+		return -ENOMEM;</span>
<span class="p_add">+	data-&gt;dev = dev;</span>
<span class="p_add">+</span>
<span class="p_add">+	/* Protect memory. HW will access here while translation fault.*/</span>
<span class="p_add">+	protect = devm_kzalloc(dev, MTK_PROTECT_PA_ALIGN * 2, GFP_KERNEL);</span>
<span class="p_add">+	if (!protect)</span>
<span class="p_add">+		return -ENOMEM;</span>
<span class="p_add">+	data-&gt;protect_base = ALIGN(virt_to_phys(protect), MTK_PROTECT_PA_ALIGN);</span>
<span class="p_add">+</span>
<span class="p_add">+	res = platform_get_resource(pdev, IORESOURCE_MEM, 0);</span>
<span class="p_add">+	data-&gt;base = devm_ioremap_resource(dev, res);</span>
<span class="p_add">+	if (IS_ERR(data-&gt;base))</span>
<span class="p_add">+		return PTR_ERR(data-&gt;base);</span>
<span class="p_add">+</span>
<span class="p_add">+	data-&gt;irq = platform_get_irq(pdev, 0);</span>
<span class="p_add">+	if (data-&gt;irq &lt; 0)</span>
<span class="p_add">+		return data-&gt;irq;</span>
<span class="p_add">+</span>
<span class="p_add">+	data-&gt;bclk = devm_clk_get(dev, &quot;bclk&quot;);</span>
<span class="p_add">+	if (IS_ERR(data-&gt;bclk))</span>
<span class="p_add">+		return PTR_ERR(data-&gt;bclk);</span>
<span class="p_add">+</span>
<span class="p_add">+	larb_nr = of_count_phandle_with_args(dev-&gt;of_node,</span>
<span class="p_add">+					     &quot;mediatek,larbs&quot;, NULL);</span>
<span class="p_add">+	if (larb_nr &lt; 0)</span>
<span class="p_add">+		return larb_nr;</span>
<span class="p_add">+	data-&gt;smi_imu.larb_nr = larb_nr;</span>
<span class="p_add">+</span>
<span class="p_add">+	for (i = 0; i &lt; larb_nr; i++) {</span>
<span class="p_add">+		struct device_node *larbnode;</span>
<span class="p_add">+		struct platform_device *plarbdev;</span>
<span class="p_add">+</span>
<span class="p_add">+		larbnode = of_parse_phandle(dev-&gt;of_node, &quot;mediatek,larbs&quot;, i);</span>
<span class="p_add">+		if (!larbnode)</span>
<span class="p_add">+			return -EINVAL;</span>
<span class="p_add">+</span>
<span class="p_add">+		if (!of_device_is_available(larbnode))</span>
<span class="p_add">+			continue;</span>
<span class="p_add">+</span>
<span class="p_add">+		plarbdev = of_find_device_by_node(larbnode);</span>
<span class="p_add">+		of_node_put(larbnode);</span>
<span class="p_add">+		if (!plarbdev) {</span>
<span class="p_add">+			plarbdev = of_platform_device_create(</span>
<span class="p_add">+						larbnode, NULL,</span>
<span class="p_add">+						platform_bus_type.dev_root);</span>
<span class="p_add">+			if (IS_ERR(plarbdev))</span>
<span class="p_add">+				return -EPROBE_DEFER;</span>
<span class="p_add">+		}</span>
<span class="p_add">+		data-&gt;smi_imu.larb_imu[i].dev = &amp;plarbdev-&gt;dev;</span>
<span class="p_add">+</span>
<span class="p_add">+		component_match_add(dev, &amp;match, compare_of, larbnode);</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	platform_set_drvdata(pdev, data);</span>
<span class="p_add">+</span>
<span class="p_add">+	ret = mtk_iommu_hw_init(data);</span>
<span class="p_add">+	if (ret)</span>
<span class="p_add">+		return ret;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (!iommu_present(&amp;platform_bus_type))</span>
<span class="p_add">+		bus_set_iommu(&amp;platform_bus_type, &amp;mtk_iommu_ops);</span>
<span class="p_add">+</span>
<span class="p_add">+	return component_master_add_with_match(dev, &amp;mtk_iommu_com_ops, match);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static int mtk_iommu_remove(struct platform_device *pdev)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct mtk_iommu_data *data = platform_get_drvdata(pdev);</span>
<span class="p_add">+</span>
<span class="p_add">+	if (iommu_present(&amp;platform_bus_type))</span>
<span class="p_add">+		bus_set_iommu(&amp;platform_bus_type, NULL);</span>
<span class="p_add">+</span>
<span class="p_add">+	free_io_pgtable_ops(data-&gt;m4u_dom-&gt;iop);</span>
<span class="p_add">+	clk_disable_unprepare(data-&gt;bclk);</span>
<span class="p_add">+	devm_free_irq(&amp;pdev-&gt;dev, data-&gt;irq, data);</span>
<span class="p_add">+	component_master_del(&amp;pdev-&gt;dev, &amp;mtk_iommu_com_ops);</span>
<span class="p_add">+	return 0;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static int mtk_iommu_suspend(struct device *dev)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct mtk_iommu_data *data = dev_get_drvdata(dev);</span>
<span class="p_add">+	struct mtk_iommu_suspend_reg *reg = &amp;data-&gt;reg;</span>
<span class="p_add">+	void __iomem *base = data-&gt;base;</span>
<span class="p_add">+</span>
<span class="p_add">+	reg-&gt;standard_axi_mode = readl_relaxed(base +</span>
<span class="p_add">+					       REG_MMU_STANDARD_AXI_MODE);</span>
<span class="p_add">+	reg-&gt;dcm_dis = readl_relaxed(base + REG_MMU_DCM_DIS);</span>
<span class="p_add">+	reg-&gt;ctrl_reg = readl_relaxed(base + REG_MMU_CTRL_REG);</span>
<span class="p_add">+	reg-&gt;int_control0 = readl_relaxed(base + REG_MMU_INT_CONTROL0);</span>
<span class="p_add">+	reg-&gt;int_main_control = readl_relaxed(base + REG_MMU_INT_MAIN_CONTROL);</span>
<span class="p_add">+	return 0;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static int mtk_iommu_resume(struct device *dev)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct mtk_iommu_data *data = dev_get_drvdata(dev);</span>
<span class="p_add">+	struct mtk_iommu_suspend_reg *reg = &amp;data-&gt;reg;</span>
<span class="p_add">+	void __iomem *base = data-&gt;base;</span>
<span class="p_add">+</span>
<span class="p_add">+	writel_relaxed(data-&gt;m4u_dom-&gt;cfg.arm_v7s_cfg.ttbr[0],</span>
<span class="p_add">+		       base + REG_MMU_PT_BASE_ADDR);</span>
<span class="p_add">+	writel_relaxed(reg-&gt;standard_axi_mode,</span>
<span class="p_add">+		       base + REG_MMU_STANDARD_AXI_MODE);</span>
<span class="p_add">+	writel_relaxed(reg-&gt;dcm_dis, base + REG_MMU_DCM_DIS);</span>
<span class="p_add">+	writel_relaxed(reg-&gt;ctrl_reg, base + REG_MMU_CTRL_REG);</span>
<span class="p_add">+	writel_relaxed(reg-&gt;int_control0, base + REG_MMU_INT_CONTROL0);</span>
<span class="p_add">+	writel_relaxed(reg-&gt;int_main_control, base + REG_MMU_INT_MAIN_CONTROL);</span>
<span class="p_add">+	writel_relaxed(F_MMU_IVRP_PA_SET(data-&gt;protect_base),</span>
<span class="p_add">+		       base + REG_MMU_IVRP_PADDR);</span>
<span class="p_add">+	return 0;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+const struct dev_pm_ops mtk_iommu_pm_ops = {</span>
<span class="p_add">+	SET_SYSTEM_SLEEP_PM_OPS(mtk_iommu_suspend, mtk_iommu_resume)</span>
<span class="p_add">+};</span>
<span class="p_add">+</span>
<span class="p_add">+static const struct of_device_id mtk_iommu_of_ids[] = {</span>
<span class="p_add">+	{ .compatible = &quot;mediatek,mt8173-m4u&quot;, },</span>
<span class="p_add">+	{}</span>
<span class="p_add">+};</span>
<span class="p_add">+</span>
<span class="p_add">+static struct platform_driver mtk_iommu_driver = {</span>
<span class="p_add">+	.probe	= mtk_iommu_probe,</span>
<span class="p_add">+	.remove	= mtk_iommu_remove,</span>
<span class="p_add">+	.driver	= {</span>
<span class="p_add">+		.name = &quot;mtk-iommu&quot;,</span>
<span class="p_add">+		.of_match_table = mtk_iommu_of_ids,</span>
<span class="p_add">+		.pm = &amp;mtk_iommu_pm_ops,</span>
<span class="p_add">+	}</span>
<span class="p_add">+};</span>
<span class="p_add">+</span>
<span class="p_add">+static int mtk_iommu_init_fn(struct device_node *np)</span>
<span class="p_add">+{</span>
<span class="p_add">+	int ret;</span>
<span class="p_add">+	struct platform_device *pdev;</span>
<span class="p_add">+</span>
<span class="p_add">+	pdev = of_platform_device_create(np, NULL, platform_bus_type.dev_root);</span>
<span class="p_add">+	if (IS_ERR(pdev))</span>
<span class="p_add">+		return PTR_ERR(pdev);</span>
<span class="p_add">+</span>
<span class="p_add">+	ret = platform_driver_register(&amp;mtk_iommu_driver);</span>
<span class="p_add">+	if (ret) {</span>
<span class="p_add">+		pr_err(&quot;%s: Failed to register driver\n&quot;, __func__);</span>
<span class="p_add">+		return ret;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	of_iommu_set_ops(np, &amp;mtk_iommu_ops);</span>
<span class="p_add">+	return 0;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+IOMMU_OF_DECLARE(mtkm4u, &quot;mediatek,mt8173-m4u&quot;, mtk_iommu_init_fn);</span>

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



