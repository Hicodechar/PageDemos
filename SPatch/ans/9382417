
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>mm/hugetlb: Use the right pte val for compare in hugetlb_cow - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    mm/hugetlb: Use the right pte val for compare in hugetlb_cow</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=1141">Aneesh Kumar K.V</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>Oct. 18, 2016, 3:42 p.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;20161018154245.18023-1-aneesh.kumar@linux.vnet.ibm.com&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/9382417/mbox/"
   >mbox</a>
|
   <a href="/patch/9382417/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/9382417/">/patch/9382417/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
	[172.30.200.125])
	by pdx-korg-patchwork.web.codeaurora.org (Postfix) with ESMTP id
	AF2B2600CA for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Tue, 18 Oct 2016 15:43:50 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id A052529669
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Tue, 18 Oct 2016 15:43:50 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id 94F492966B; Tue, 18 Oct 2016 15:43:50 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-6.9 required=2.0 tests=BAYES_00,RCVD_IN_DNSWL_HI
	autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id AC4F829669
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Tue, 18 Oct 2016 15:43:48 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1030348AbcJRPnh (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Tue, 18 Oct 2016 11:43:37 -0400
Received: from mx0a-001b2d01.pphosted.com ([148.163.156.1]:46264 &quot;EHLO
	mx0a-001b2d01.pphosted.com&quot; rhost-flags-OK-OK-OK-OK)
	by vger.kernel.org with ESMTP id S1030226AbcJRPnG (ORCPT
	&lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Tue, 18 Oct 2016 11:43:06 -0400
Received: from pps.filterd (m0098396.ppops.net [127.0.0.1])
	by mx0a-001b2d01.pphosted.com (8.16.0.17/8.16.0.17) with SMTP id
	u9IFcvOn124790
	for &lt;linux-kernel@vger.kernel.org&gt;; Tue, 18 Oct 2016 11:43:06 -0400
Received: from e17.ny.us.ibm.com (e17.ny.us.ibm.com [129.33.205.207])
	by mx0a-001b2d01.pphosted.com with ESMTP id 265p26hx5a-1
	(version=TLSv1.2 cipher=AES256-SHA bits=256 verify=NOT)
	for &lt;linux-kernel@vger.kernel.org&gt;; Tue, 18 Oct 2016 11:43:05 -0400
Received: from localhost
	by e17.ny.us.ibm.com with IBM ESMTP SMTP Gateway: Authorized Use
	Only! Violators will be prosecuted
	for &lt;linux-kernel@vger.kernel.org&gt; from
	&lt;aneesh.kumar@linux.vnet.ibm.com&gt;; Tue, 18 Oct 2016 11:43:04 -0400
Received: from d01dlp03.pok.ibm.com (9.56.250.168)
	by e17.ny.us.ibm.com (146.89.104.204) with IBM ESMTP SMTP Gateway:
	Authorized Use Only! Violators will be prosecuted; 
	Tue, 18 Oct 2016 11:43:02 -0400
Received: from b01cxnp22034.gho.pok.ibm.com (b01cxnp22034.gho.pok.ibm.com
	[9.57.198.24])
	by d01dlp03.pok.ibm.com (Postfix) with ESMTP id 685D4C90046;
	Tue, 18 Oct 2016 11:42:47 -0400 (EDT)
Received: from b01ledav03.gho.pok.ibm.com (b01ledav003.gho.pok.ibm.com
	[9.57.199.108])
	by b01cxnp22034.gho.pok.ibm.com (8.14.9/8.14.9/NCO v10.0) with ESMTP
	id u9IFgrDB10224088; Tue, 18 Oct 2016 15:43:01 GMT
Received: from b01ledav03.gho.pok.ibm.com (unknown [127.0.0.1])
	by IMSVA (Postfix) with ESMTP id 83D91B205F;
	Tue, 18 Oct 2016 11:43:01 -0400 (EDT)
Received: from skywalker.in.ibm.com (unknown [9.199.60.42])
	by b01ledav03.gho.pok.ibm.com (Postfix) with ESMTP id 9DA28B2046;
	Tue, 18 Oct 2016 11:42:59 -0400 (EDT)
From: &quot;Aneesh Kumar K.V&quot; &lt;aneesh.kumar@linux.vnet.ibm.com&gt;
To: akpm@linux-foundation.org, Jan Stancek &lt;jstancek@redhat.com&gt;,
	Mike Kravetz &lt;mike.kravetz@oracle.com&gt;
Cc: linux-mm@kvack.org, linux-kernel@vger.kernel.org,
	linuxppc-dev@lists.ozlabs.org,
	&quot;Aneesh Kumar K.V&quot; &lt;aneesh.kumar@linux.vnet.ibm.com&gt;
Subject: [PATCH] mm/hugetlb: Use the right pte val for compare in hugetlb_cow
Date: Tue, 18 Oct 2016 21:12:45 +0530
X-Mailer: git-send-email 2.10.1
X-TM-AS-GCONF: 00
X-Content-Scanned: Fidelis XPS MAILER
x-cbid: 16101815-0040-0000-0000-0000019E64C1
X-IBM-SpamModules-Scores: 
X-IBM-SpamModules-Versions: BY=3.00005934; HX=3.00000240; KW=3.00000007;
	PH=3.00000004; SC=3.00000187; SDB=6.00769831; UDB=6.00368881;
	IPR=6.00546261; 
	BA=6.00004815; NDR=6.00000001; ZLA=6.00000005; ZF=6.00000009;
	ZB=6.00000000; 
	ZP=6.00000000; ZH=6.00000000; ZU=6.00000002; MB=3.00013030;
	XFM=3.00000011; UTC=2016-10-18 15:43:03
X-IBM-AV-DETECTION: SAVI=unused REMOTE=unused XFE=unused
x-cbparentid: 16101815-0041-0000-0000-000005916B01
Message-Id: &lt;20161018154245.18023-1-aneesh.kumar@linux.vnet.ibm.com&gt;
X-Proofpoint-Virus-Version: vendor=fsecure engine=2.50.10432:, ,
	definitions=2016-10-18_08:, , signatures=0
X-Proofpoint-Spam-Details: rule=outbound_notspam policy=outbound score=0
	spamscore=0 suspectscore=0
	malwarescore=0 phishscore=0 adultscore=0 bulkscore=0 classifier=spam
	adjust=0 reason=mlx scancount=1 engine=8.0.1-1609300000
	definitions=main-1610180261
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=1141">Aneesh Kumar K.V</a> - Oct. 18, 2016, 3:42 p.m.</div>
<pre class="content">
We cannot use the pte value used in set_pte_at for pte_same comparison,
because archs like ppc64, filter/add new pte flag in set_pte_at. Instead
fetch the pte value inside hugetlb_cow. We are comparing pte value to
make sure the pte didn&#39;t change since we dropped the page table lock.
hugetlb_cow get called with page table lock held, and we can take a copy
of the pte value before we drop the page table lock.

With hugetlbfs, we optimize the MAP_PRIVATE write fault path with no
previous mapping (huge_pte_none entries), by forcing a cow in the fault
path. This avoid take an addition fault to covert a read-only mapping
to read/write. Here we were comparing a recently instantiated pte (via
set_pte_at) to the pte values from linux page table. As explained above
on ppc64 such pte_same check returned wrong result, resulting in us
taking an additional fault on ppc64.

Fixes: 6a119eae942c (&quot;powerpc/mm: Add a _PAGE_PTE bit&quot;)

Reported-by: Jan Stancek &lt;jstancek@redhat.com&gt;
<span class="signed-off-by">Signed-off-by: Aneesh Kumar K.V &lt;aneesh.kumar@linux.vnet.ibm.com&gt;</span>
---
 mm/hugetlb.c | 12 +++++++-----
 1 file changed, 7 insertions(+), 5 deletions(-)
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=41">Andrew Morton</a> - Oct. 18, 2016, 6:33 p.m.</div>
<pre class="content">
On Tue, 18 Oct 2016 21:12:45 +0530 &quot;Aneesh Kumar K.V&quot; &lt;aneesh.kumar@linux.vnet.ibm.com&gt; wrote:
<span class="quote">
&gt; We cannot use the pte value used in set_pte_at for pte_same comparison,</span>
<span class="quote">&gt; because archs like ppc64, filter/add new pte flag in set_pte_at. Instead</span>
<span class="quote">&gt; fetch the pte value inside hugetlb_cow. We are comparing pte value to</span>
<span class="quote">&gt; make sure the pte didn&#39;t change since we dropped the page table lock.</span>
<span class="quote">&gt; hugetlb_cow get called with page table lock held, and we can take a copy</span>
<span class="quote">&gt; of the pte value before we drop the page table lock.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; With hugetlbfs, we optimize the MAP_PRIVATE write fault path with no</span>
<span class="quote">&gt; previous mapping (huge_pte_none entries), by forcing a cow in the fault</span>
<span class="quote">&gt; path. This avoid take an addition fault to covert a read-only mapping</span>
<span class="quote">&gt; to read/write. Here we were comparing a recently instantiated pte (via</span>
<span class="quote">&gt; set_pte_at) to the pte values from linux page table. As explained above</span>
<span class="quote">&gt; on ppc64 such pte_same check returned wrong result, resulting in us</span>
<span class="quote">&gt; taking an additional fault on ppc64.</span>

From my reading this is a minor performance improvement and a -stable
backport isn&#39;t needed.  But it is unclear whether the impact warrants a
4.9 merge.

Please be careful about describing end-user visible impacts when fixing
bugs, thanks.
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=113021">Hillf Danton</a> - Oct. 19, 2016, 3:22 a.m.</div>
<pre class="content">
On Tuesday, October 18, 2016 11:43 PM Aneesh Kumar K.V wrote:
<span class="quote">&gt; </span>
<span class="quote">&gt; We cannot use the pte value used in set_pte_at for pte_same comparison,</span>
<span class="quote">&gt; because archs like ppc64, filter/add new pte flag in set_pte_at. Instead</span>
<span class="quote">&gt; fetch the pte value inside hugetlb_cow. We are comparing pte value to</span>
<span class="quote">&gt; make sure the pte didn&#39;t change since we dropped the page table lock.</span>
<span class="quote">&gt; hugetlb_cow get called with page table lock held, and we can take a copy</span>
<span class="quote">&gt; of the pte value before we drop the page table lock.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; With hugetlbfs, we optimize the MAP_PRIVATE write fault path with no</span>
<span class="quote">&gt; previous mapping (huge_pte_none entries), by forcing a cow in the fault</span>
<span class="quote">&gt; path. This avoid take an addition fault to covert a read-only mapping</span>
<span class="quote">&gt; to read/write. Here we were comparing a recently instantiated pte (via</span>
<span class="quote">&gt; set_pte_at) to the pte values from linux page table. As explained above</span>
<span class="quote">&gt; on ppc64 such pte_same check returned wrong result, resulting in us</span>
<span class="quote">&gt; taking an additional fault on ppc64.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Fixes: 6a119eae942c (&quot;powerpc/mm: Add a _PAGE_PTE bit&quot;)</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Reported-by: Jan Stancek &lt;jstancek@redhat.com&gt;</span>
<span class="quote">&gt; Signed-off-by: Aneesh Kumar K.V &lt;aneesh.kumar@linux.vnet.ibm.com&gt;</span>
<span class="quote">&gt; ---</span>
<span class="acked-by">
Acked-by: Hillf Danton &lt;hillf.zj@alibaba-inc.com&gt;</span>
<span class="quote">
&gt;  mm/hugetlb.c | 12 +++++++-----</span>
<span class="quote">&gt;  1 file changed, 7 insertions(+), 5 deletions(-)</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; diff --git a/mm/hugetlb.c b/mm/hugetlb.c</span>
<span class="quote">&gt; index ec49d9ef1eef..da8fbd02b92e 100644</span>
<span class="quote">&gt; --- a/mm/hugetlb.c</span>
<span class="quote">&gt; +++ b/mm/hugetlb.c</span>
<span class="quote">&gt; @@ -3386,15 +3386,17 @@ static void unmap_ref_private(struct mm_struct *mm, struct vm_area_struct *vma,</span>
<span class="quote">&gt;   * Keep the pte_same checks anyway to make transition from the mutex easier.</span>
<span class="quote">&gt;   */</span>
<span class="quote">&gt;  static int hugetlb_cow(struct mm_struct *mm, struct vm_area_struct *vma,</span>
<span class="quote">&gt; -			unsigned long address, pte_t *ptep, pte_t pte,</span>
<span class="quote">&gt; -			struct page *pagecache_page, spinlock_t *ptl)</span>
<span class="quote">&gt; +		       unsigned long address, pte_t *ptep,</span>
<span class="quote">&gt; +		       struct page *pagecache_page, spinlock_t *ptl)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt; +	pte_t pte;</span>
<span class="quote">&gt;  	struct hstate *h = hstate_vma(vma);</span>
<span class="quote">&gt;  	struct page *old_page, *new_page;</span>
<span class="quote">&gt;  	int ret = 0, outside_reserve = 0;</span>
<span class="quote">&gt;  	unsigned long mmun_start;	/* For mmu_notifiers */</span>
<span class="quote">&gt;  	unsigned long mmun_end;		/* For mmu_notifiers */</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; +	pte = huge_ptep_get(ptep);</span>
<span class="quote">&gt;  	old_page = pte_page(pte);</span>
<span class="quote">&gt; </span>
<span class="quote">&gt;  retry_avoidcopy:</span>
<span class="quote">&gt; @@ -3668,7 +3670,7 @@ static int hugetlb_no_page(struct mm_struct *mm, struct vm_area_struct *vma,</span>
<span class="quote">&gt;  	hugetlb_count_add(pages_per_huge_page(h), mm);</span>
<span class="quote">&gt;  	if ((flags &amp; FAULT_FLAG_WRITE) &amp;&amp; !(vma-&gt;vm_flags &amp; VM_SHARED)) {</span>
<span class="quote">&gt;  		/* Optimization, do the COW without a second fault */</span>
<span class="quote">&gt; -		ret = hugetlb_cow(mm, vma, address, ptep, new_pte, page, ptl);</span>
<span class="quote">&gt; +		ret = hugetlb_cow(mm, vma, address, ptep, page, ptl);</span>
<span class="quote">&gt;  	}</span>
<span class="quote">&gt; </span>
<span class="quote">&gt;  	spin_unlock(ptl);</span>
<span class="quote">&gt; @@ -3822,8 +3824,8 @@ int hugetlb_fault(struct mm_struct *mm, struct vm_area_struct *vma,</span>
<span class="quote">&gt; </span>
<span class="quote">&gt;  	if (flags &amp; FAULT_FLAG_WRITE) {</span>
<span class="quote">&gt;  		if (!huge_pte_write(entry)) {</span>
<span class="quote">&gt; -			ret = hugetlb_cow(mm, vma, address, ptep, entry,</span>
<span class="quote">&gt; -					pagecache_page, ptl);</span>
<span class="quote">&gt; +			ret = hugetlb_cow(mm, vma, address, ptep,</span>
<span class="quote">&gt; +					  pagecache_page, ptl);</span>
<span class="quote">&gt;  			goto out_put_page;</span>
<span class="quote">&gt;  		}</span>
<span class="quote">&gt;  		entry = huge_pte_mkdirty(entry);</span>
<span class="quote">&gt; --</span>
<span class="quote">&gt; 2.10.1</span>
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=1141">Aneesh Kumar K.V</a> - Oct. 19, 2016, 5:11 a.m.</div>
<pre class="content">
Andrew Morton &lt;akpm@linux-foundation.org&gt; writes:
<span class="quote">
&gt; On Tue, 18 Oct 2016 21:12:45 +0530 &quot;Aneesh Kumar K.V&quot; &lt;aneesh.kumar@linux.vnet.ibm.com&gt; wrote:</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;&gt; We cannot use the pte value used in set_pte_at for pte_same comparison,</span>
<span class="quote">&gt;&gt; because archs like ppc64, filter/add new pte flag in set_pte_at. Instead</span>
<span class="quote">&gt;&gt; fetch the pte value inside hugetlb_cow. We are comparing pte value to</span>
<span class="quote">&gt;&gt; make sure the pte didn&#39;t change since we dropped the page table lock.</span>
<span class="quote">&gt;&gt; hugetlb_cow get called with page table lock held, and we can take a copy</span>
<span class="quote">&gt;&gt; of the pte value before we drop the page table lock.</span>
<span class="quote">&gt;&gt; </span>
<span class="quote">&gt;&gt; With hugetlbfs, we optimize the MAP_PRIVATE write fault path with no</span>
<span class="quote">&gt;&gt; previous mapping (huge_pte_none entries), by forcing a cow in the fault</span>
<span class="quote">&gt;&gt; path. This avoid take an addition fault to covert a read-only mapping</span>
<span class="quote">&gt;&gt; to read/write. Here we were comparing a recently instantiated pte (via</span>
<span class="quote">&gt;&gt; set_pte_at) to the pte values from linux page table. As explained above</span>
<span class="quote">&gt;&gt; on ppc64 such pte_same check returned wrong result, resulting in us</span>
<span class="quote">&gt;&gt; taking an additional fault on ppc64.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; From my reading this is a minor performance improvement and a -stable</span>
<span class="quote">&gt; backport isn&#39;t needed.  But it is unclear whether the impact warrants a</span>
<span class="quote">&gt; 4.9 merge.</span>

This patch workaround the issue reported at https://lkml.kernel.org/r/57FF7BB4.1070202@redhat.com
The reason for that OOM was a reserve count accounting issue which
happens in the error path of hugetlb_cow. Not this patch avoid us taking
the error path and hence we don&#39;t have the reported OOM.

An actual fix for that issue is being worked on by Mike Kravetz.
<span class="quote">
&gt;</span>
<span class="quote">&gt; Please be careful about describing end-user visible impacts when fixing</span>
<span class="quote">&gt; bugs, thanks.</span>

-aneesh
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/mm/hugetlb.c b/mm/hugetlb.c</span>
<span class="p_header">index ec49d9ef1eef..da8fbd02b92e 100644</span>
<span class="p_header">--- a/mm/hugetlb.c</span>
<span class="p_header">+++ b/mm/hugetlb.c</span>
<span class="p_chunk">@@ -3386,15 +3386,17 @@</span> <span class="p_context"> static void unmap_ref_private(struct mm_struct *mm, struct vm_area_struct *vma,</span>
  * Keep the pte_same checks anyway to make transition from the mutex easier.
  */
 static int hugetlb_cow(struct mm_struct *mm, struct vm_area_struct *vma,
<span class="p_del">-			unsigned long address, pte_t *ptep, pte_t pte,</span>
<span class="p_del">-			struct page *pagecache_page, spinlock_t *ptl)</span>
<span class="p_add">+		       unsigned long address, pte_t *ptep,</span>
<span class="p_add">+		       struct page *pagecache_page, spinlock_t *ptl)</span>
 {
<span class="p_add">+	pte_t pte;</span>
 	struct hstate *h = hstate_vma(vma);
 	struct page *old_page, *new_page;
 	int ret = 0, outside_reserve = 0;
 	unsigned long mmun_start;	/* For mmu_notifiers */
 	unsigned long mmun_end;		/* For mmu_notifiers */
 
<span class="p_add">+	pte = huge_ptep_get(ptep);</span>
 	old_page = pte_page(pte);
 
 retry_avoidcopy:
<span class="p_chunk">@@ -3668,7 +3670,7 @@</span> <span class="p_context"> static int hugetlb_no_page(struct mm_struct *mm, struct vm_area_struct *vma,</span>
 	hugetlb_count_add(pages_per_huge_page(h), mm);
 	if ((flags &amp; FAULT_FLAG_WRITE) &amp;&amp; !(vma-&gt;vm_flags &amp; VM_SHARED)) {
 		/* Optimization, do the COW without a second fault */
<span class="p_del">-		ret = hugetlb_cow(mm, vma, address, ptep, new_pte, page, ptl);</span>
<span class="p_add">+		ret = hugetlb_cow(mm, vma, address, ptep, page, ptl);</span>
 	}
 
 	spin_unlock(ptl);
<span class="p_chunk">@@ -3822,8 +3824,8 @@</span> <span class="p_context"> int hugetlb_fault(struct mm_struct *mm, struct vm_area_struct *vma,</span>
 
 	if (flags &amp; FAULT_FLAG_WRITE) {
 		if (!huge_pte_write(entry)) {
<span class="p_del">-			ret = hugetlb_cow(mm, vma, address, ptep, entry,</span>
<span class="p_del">-					pagecache_page, ptl);</span>
<span class="p_add">+			ret = hugetlb_cow(mm, vma, address, ptep,</span>
<span class="p_add">+					  pagecache_page, ptl);</span>
 			goto out_put_page;
 		}
 		entry = huge_pte_mkdirty(entry);

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



