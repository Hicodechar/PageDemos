
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>[5/9] mm, memory_hotplug: split up register_one_node - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    [5/9] mm, memory_hotplug: split up register_one_node</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=137061">Michal Hocko</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>April 10, 2017, 11:03 a.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;20170410110351.12215-6-mhocko@kernel.org&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/9672327/mbox/"
   >mbox</a>
|
   <a href="/patch/9672327/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/9672327/">/patch/9672327/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
	[172.30.200.125])
	by pdx-korg-patchwork.web.codeaurora.org (Postfix) with ESMTP id
	1D42F60381 for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Mon, 10 Apr 2017 11:04:49 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 0EE2E26E75
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Mon, 10 Apr 2017 11:04:49 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id 0323128408; Mon, 10 Apr 2017 11:04:48 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-6.4 required=2.0 tests=BAYES_00, RCVD_IN_DNSWL_HI, 
	RCVD_IN_SORBS_SPAM autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 72EBF27D4D
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Mon, 10 Apr 2017 11:04:48 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1753461AbdDJLEl (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Mon, 10 Apr 2017 07:04:41 -0400
Received: from mail-wm0-f67.google.com ([74.125.82.67]:36314 &quot;EHLO
	mail-wm0-f67.google.com&quot; rhost-flags-OK-OK-OK-OK) by vger.kernel.org
	with ESMTP id S1753421AbdDJLEh (ORCPT
	&lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Mon, 10 Apr 2017 07:04:37 -0400
Received: by mail-wm0-f67.google.com with SMTP id q125so8992152wmd.3
	for &lt;linux-kernel@vger.kernel.org&gt;;
	Mon, 10 Apr 2017 04:04:31 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
	d=1e100.net; s=20161025;
	h=x-gm-message-state:from:to:cc:subject:date:message-id:in-reply-to
	:references;
	bh=mySpfZNscAHKHFu664RtwYVbT5hsP0W64XXTDi1Cjbk=;
	b=NkhMeLpqDbh4pZQ16igubnchfehIEhHYf5pgj7IEzHRF9bh5+FRzKQdGiDQ4lmNGLz
	7PBvmDpAUXLKofjdQdWy9N8Ze8khzCAMKoKrzd2vep+zu4RSGMUhr/04ofAuscdWr6n8
	rqKLmSYyd/lYvZpd0+mDtJxPEVTyYO1aaPhaYdIteKw3DENGH3QVD5TAFpuUECYwWsF5
	StApRZV5I13TE5FVrUzcUkfM6V9K3hQW1jwf09ro2axRECJ8wbkW02V3R/YxnNoHIAif
	xg0uh8oDO8Pwriax9y6uv8e5srVIO7eDumAN7Pdo9CpezEZrcir+nDzOHueT/hCt5+8s
	TqQQ==
X-Gm-Message-State: AN3rC/7eyBDkucDgZJrA3WzSvIo7MglomnUdV1A+fVXnHUbRf8Zz8rhD
	G5XOjZ+1p59oWQ==
X-Received: by 10.28.16.148 with SMTP id 142mr9477649wmq.75.1491822260957;
	Mon, 10 Apr 2017 04:04:20 -0700 (PDT)
Received: from tiehlicka.suse.cz (bband-dyn22.95-103-123.t-com.sk.
	[95.103.123.22]) by smtp.gmail.com with ESMTPSA id
	33sm16697997wrd.40.2017.04.10.04.04.19
	(version=TLS1_2 cipher=ECDHE-RSA-AES128-GCM-SHA256 bits=128/128);
	Mon, 10 Apr 2017 04:04:20 -0700 (PDT)
From: Michal Hocko &lt;mhocko@kernel.org&gt;
To: linux-mm@kvack.org
Cc: Andrew Morton &lt;akpm@linux-foundation.org&gt;,
	Mel Gorman &lt;mgorman@suse.de&gt;, Vlastimil Babka &lt;vbabka@suse.cz&gt;,
	Andrea Arcangeli &lt;aarcange@redhat.com&gt;,
	Jerome Glisse &lt;jglisse@redhat.com&gt;,
	Reza Arbab &lt;arbab@linux.vnet.ibm.com&gt;,
	Yasuaki Ishimatsu &lt;yasu.isimatu@gmail.com&gt;,
	qiuxishi@huawei.com, Kani Toshimitsu &lt;toshi.kani@hpe.com&gt;,
	slaoub@gmail.com, Joonsoo Kim &lt;js1304@gmail.com&gt;,
	Andi Kleen &lt;ak@linux.intel.com&gt;, David Rientjes &lt;rientjes@google.com&gt;,
	Daniel Kiper &lt;daniel.kiper@oracle.com&gt;,
	Igor Mammedov &lt;imammedo@redhat.com&gt;,
	Vitaly Kuznetsov &lt;vkuznets@redhat.com&gt;,
	LKML &lt;linux-kernel@vger.kernel.org&gt;, Michal Hocko &lt;mhocko@suse.com&gt;
Subject: [PATCH 5/9] mm, memory_hotplug: split up register_one_node
Date: Mon, 10 Apr 2017 13:03:47 +0200
Message-Id: &lt;20170410110351.12215-6-mhocko@kernel.org&gt;
X-Mailer: git-send-email 2.11.0
In-Reply-To: &lt;20170410110351.12215-1-mhocko@kernel.org&gt;
References: &lt;20170410110351.12215-1-mhocko@kernel.org&gt;
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=137061">Michal Hocko</a> - April 10, 2017, 11:03 a.m.</div>
<pre class="content">
<span class="from">From: Michal Hocko &lt;mhocko@suse.com&gt;</span>

Memory hotplug (add_memory_resource) has to reinitialize node
infrastructure if the node is offline (one which went through the
complete add_memory(); remove_memory() cycle). That involves node
registration to the kobj infrastructure (register_node), the proper
association with cpus (register_cpu_under_node) and finally creation of
node&lt;-&gt;memblock symlinks (link_mem_sections).

The last part requires to know node_start_pfn and node_spanned_pages
which we currently have but a leter patch will postpone this
initialization to the onlining phase which happens later. In fact we do
not need to rely on the early pgdat initialization even now because the
currently hot added pfn range is currently known.

Split register_one_node into core which does all the common work for
the boot time NUMA initialization and the hotplug (__register_one_node).
register_one_node keeps the full initialization while hotplug calls
__register_one_node and manually calls link_mem_sections for the proper
range.

This shouldn&#39;t introduce any functional change.
<span class="signed-off-by">
Signed-off-by: Michal Hocko &lt;mhocko@suse.com&gt;</span>
---
 drivers/base/node.c  | 51 ++++++++++++++++++++-------------------------------
 include/linux/node.h | 35 ++++++++++++++++++++++++++++++++++-
 mm/memory_hotplug.c  | 17 ++++++++++++++++-
 3 files changed, 70 insertions(+), 33 deletions(-)
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=72672">Vlastimil Babka</a> - April 13, 2017, 2:05 p.m.</div>
<pre class="content">
On 04/10/2017 01:03 PM, Michal Hocko wrote:
<span class="quote">&gt; From: Michal Hocko &lt;mhocko@suse.com&gt;</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Memory hotplug (add_memory_resource) has to reinitialize node</span>
<span class="quote">&gt; infrastructure if the node is offline (one which went through the</span>
<span class="quote">&gt; complete add_memory(); remove_memory() cycle). That involves node</span>
<span class="quote">&gt; registration to the kobj infrastructure (register_node), the proper</span>
<span class="quote">&gt; association with cpus (register_cpu_under_node) and finally creation of</span>
<span class="quote">&gt; node&lt;-&gt;memblock symlinks (link_mem_sections).</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; The last part requires to know node_start_pfn and node_spanned_pages</span>
<span class="quote">&gt; which we currently have but a leter patch will postpone this</span>
<span class="quote">&gt; initialization to the onlining phase which happens later. In fact we do</span>
<span class="quote">&gt; not need to rely on the early pgdat initialization even now because the</span>
<span class="quote">&gt; currently hot added pfn range is currently known.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Split register_one_node into core which does all the common work for</span>
<span class="quote">&gt; the boot time NUMA initialization and the hotplug (__register_one_node).</span>
<span class="quote">&gt; register_one_node keeps the full initialization while hotplug calls</span>
<span class="quote">&gt; __register_one_node and manually calls link_mem_sections for the proper</span>
<span class="quote">&gt; range.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; This shouldn&#39;t introduce any functional change.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Signed-off-by: Michal Hocko &lt;mhocko@suse.com&gt;</span>
<span class="acked-by">
Acked-by: Vlastimil Babka &lt;vbabka@suse.cz&gt;</span>

nit:
<span class="quote">&gt; @@ -1387,7 +1387,22 @@ int __ref add_memory_resource(int nid, struct resource *res, bool online)</span>
<span class="quote">&gt;  	node_set_online(nid);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	if (new_node) {</span>
<span class="quote">&gt; -		ret = register_one_node(nid);</span>
<span class="quote">&gt; +		unsigned long start_pfn = start &gt;&gt; PAGE_SHIFT;</span>
<span class="quote">&gt; +		unsigned long nr_pages = size &gt;&gt; PAGE_SHIFT;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +		ret = __register_one_node(nid);</span>
<span class="quote">&gt; +		if (ret)</span>
<span class="quote">&gt; +			goto register_fail;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +		/*</span>
<span class="quote">&gt; +		 * link memory sections under this node. This is already</span>
<span class="quote">&gt; +		 * done when creatig memory section in register_new_memory</span>
<span class="quote">&gt; +		 * but that depends to have the node registered so offline</span>
<span class="quote">&gt; +		 * nodes have to go through register_node.</span>
<span class="quote">&gt; +		 * TODO clean up this mess.</span>

Is this a work-in-progress or final TODO? :)
<span class="quote">
&gt; +		 */</span>
<span class="quote">&gt; +		ret = link_mem_sections(nid, start_pfn, nr_pages);</span>
<span class="quote">&gt; +register_fail:</span>
<span class="quote">&gt;  		/*</span>
<span class="quote">&gt;  		 * If sysfs file of new node can&#39;t create, cpu on the node</span>
<span class="quote">&gt;  		 * can&#39;t be hot-added. There is no rollback way now.</span>
<span class="quote">&gt;</span>
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=137061">Michal Hocko</a> - April 13, 2017, 2:13 p.m.</div>
<pre class="content">
On Thu 13-04-17 16:05:17, Vlastimil Babka wrote:
<span class="quote">&gt; On 04/10/2017 01:03 PM, Michal Hocko wrote:</span>
<span class="quote">&gt; &gt; From: Michal Hocko &lt;mhocko@suse.com&gt;</span>
<span class="quote">&gt; &gt; </span>
<span class="quote">&gt; &gt; Memory hotplug (add_memory_resource) has to reinitialize node</span>
<span class="quote">&gt; &gt; infrastructure if the node is offline (one which went through the</span>
<span class="quote">&gt; &gt; complete add_memory(); remove_memory() cycle). That involves node</span>
<span class="quote">&gt; &gt; registration to the kobj infrastructure (register_node), the proper</span>
<span class="quote">&gt; &gt; association with cpus (register_cpu_under_node) and finally creation of</span>
<span class="quote">&gt; &gt; node&lt;-&gt;memblock symlinks (link_mem_sections).</span>
<span class="quote">&gt; &gt; </span>
<span class="quote">&gt; &gt; The last part requires to know node_start_pfn and node_spanned_pages</span>
<span class="quote">&gt; &gt; which we currently have but a leter patch will postpone this</span>
<span class="quote">&gt; &gt; initialization to the onlining phase which happens later. In fact we do</span>
<span class="quote">&gt; &gt; not need to rely on the early pgdat initialization even now because the</span>
<span class="quote">&gt; &gt; currently hot added pfn range is currently known.</span>
<span class="quote">&gt; &gt; </span>
<span class="quote">&gt; &gt; Split register_one_node into core which does all the common work for</span>
<span class="quote">&gt; &gt; the boot time NUMA initialization and the hotplug (__register_one_node).</span>
<span class="quote">&gt; &gt; register_one_node keeps the full initialization while hotplug calls</span>
<span class="quote">&gt; &gt; __register_one_node and manually calls link_mem_sections for the proper</span>
<span class="quote">&gt; &gt; range.</span>
<span class="quote">&gt; &gt; </span>
<span class="quote">&gt; &gt; This shouldn&#39;t introduce any functional change.</span>
<span class="quote">&gt; &gt; </span>
<span class="quote">&gt; &gt; Signed-off-by: Michal Hocko &lt;mhocko@suse.com&gt;</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Acked-by: Vlastimil Babka &lt;vbabka@suse.cz&gt;</span>

Thanks!
<span class="quote">
&gt; nit:</span>
<span class="quote">&gt; &gt; @@ -1387,7 +1387,22 @@ int __ref add_memory_resource(int nid, struct resource *res, bool online)</span>
<span class="quote">&gt; &gt;  	node_set_online(nid);</span>
<span class="quote">&gt; &gt;  </span>
<span class="quote">&gt; &gt;  	if (new_node) {</span>
<span class="quote">&gt; &gt; -		ret = register_one_node(nid);</span>
<span class="quote">&gt; &gt; +		unsigned long start_pfn = start &gt;&gt; PAGE_SHIFT;</span>
<span class="quote">&gt; &gt; +		unsigned long nr_pages = size &gt;&gt; PAGE_SHIFT;</span>
<span class="quote">&gt; &gt; +</span>
<span class="quote">&gt; &gt; +		ret = __register_one_node(nid);</span>
<span class="quote">&gt; &gt; +		if (ret)</span>
<span class="quote">&gt; &gt; +			goto register_fail;</span>
<span class="quote">&gt; &gt; +</span>
<span class="quote">&gt; &gt; +		/*</span>
<span class="quote">&gt; &gt; +		 * link memory sections under this node. This is already</span>
<span class="quote">&gt; &gt; +		 * done when creatig memory section in register_new_memory</span>
<span class="quote">&gt; &gt; +		 * but that depends to have the node registered so offline</span>
<span class="quote">&gt; &gt; +		 * nodes have to go through register_node.</span>
<span class="quote">&gt; &gt; +		 * TODO clean up this mess.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Is this a work-in-progress or final TODO? :)</span>

I do not plan to address it in this series, but I will revisit it later.
There are more like this in other patches.
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/drivers/base/node.c b/drivers/base/node.c</span>
<span class="p_header">index 06294d69779b..dff5b53f7905 100644</span>
<span class="p_header">--- a/drivers/base/node.c</span>
<span class="p_header">+++ b/drivers/base/node.c</span>
<span class="p_chunk">@@ -461,10 +461,9 @@</span> <span class="p_context"> int unregister_mem_sect_under_nodes(struct memory_block *mem_blk,</span>
 	return 0;
 }
 
<span class="p_del">-static int link_mem_sections(int nid)</span>
<span class="p_add">+int link_mem_sections(int nid, unsigned long start_pfn, unsigned long nr_pages)</span>
 {
<span class="p_del">-	unsigned long start_pfn = NODE_DATA(nid)-&gt;node_start_pfn;</span>
<span class="p_del">-	unsigned long end_pfn = start_pfn + NODE_DATA(nid)-&gt;node_spanned_pages;</span>
<span class="p_add">+	unsigned long end_pfn = start_pfn + nr_pages;</span>
 	unsigned long pfn;
 	struct memory_block *mem_blk = NULL;
 	int err = 0;
<span class="p_chunk">@@ -552,10 +551,7 @@</span> <span class="p_context"> static int node_memory_callback(struct notifier_block *self,</span>
 	return NOTIFY_OK;
 }
 #endif	/* CONFIG_HUGETLBFS */
<span class="p_del">-#else	/* !CONFIG_MEMORY_HOTPLUG_SPARSE */</span>
<span class="p_del">-</span>
<span class="p_del">-static int link_mem_sections(int nid) { return 0; }</span>
<span class="p_del">-#endif	/* CONFIG_MEMORY_HOTPLUG_SPARSE */</span>
<span class="p_add">+#endif /* CONFIG_MEMORY_HOTPLUG_SPARSE */</span>
 
 #if !defined(CONFIG_MEMORY_HOTPLUG_SPARSE) || \
     !defined(CONFIG_HUGETLBFS)
<span class="p_chunk">@@ -569,39 +565,32 @@</span> <span class="p_context"> static void init_node_hugetlb_work(int nid) { }</span>
 
 #endif
 
<span class="p_del">-int register_one_node(int nid)</span>
<span class="p_add">+int __register_one_node(int nid)</span>
 {
<span class="p_del">-	int error = 0;</span>
<span class="p_add">+	int p_node = parent_node(nid);</span>
<span class="p_add">+	struct node *parent = NULL;</span>
<span class="p_add">+	int error;</span>
 	int cpu;
 
<span class="p_del">-	if (node_online(nid)) {</span>
<span class="p_del">-		int p_node = parent_node(nid);</span>
<span class="p_del">-		struct node *parent = NULL;</span>
<span class="p_del">-</span>
<span class="p_del">-		if (p_node != nid)</span>
<span class="p_del">-			parent = node_devices[p_node];</span>
<span class="p_del">-</span>
<span class="p_del">-		node_devices[nid] = kzalloc(sizeof(struct node), GFP_KERNEL);</span>
<span class="p_del">-		if (!node_devices[nid])</span>
<span class="p_del">-			return -ENOMEM;</span>
<span class="p_del">-</span>
<span class="p_del">-		error = register_node(node_devices[nid], nid, parent);</span>
<span class="p_add">+	if (p_node != nid)</span>
<span class="p_add">+		parent = node_devices[p_node];</span>
 
<span class="p_del">-		/* link cpu under this node */</span>
<span class="p_del">-		for_each_present_cpu(cpu) {</span>
<span class="p_del">-			if (cpu_to_node(cpu) == nid)</span>
<span class="p_del">-				register_cpu_under_node(cpu, nid);</span>
<span class="p_del">-		}</span>
<span class="p_add">+	node_devices[nid] = kzalloc(sizeof(struct node), GFP_KERNEL);</span>
<span class="p_add">+	if (!node_devices[nid])</span>
<span class="p_add">+		return -ENOMEM;</span>
 
<span class="p_del">-		/* link memory sections under this node */</span>
<span class="p_del">-		error = link_mem_sections(nid);</span>
<span class="p_add">+	error = register_node(node_devices[nid], nid, parent);</span>
 
<span class="p_del">-		/* initialize work queue for memory hot plug */</span>
<span class="p_del">-		init_node_hugetlb_work(nid);</span>
<span class="p_add">+	/* link cpu under this node */</span>
<span class="p_add">+	for_each_present_cpu(cpu) {</span>
<span class="p_add">+		if (cpu_to_node(cpu) == nid)</span>
<span class="p_add">+			register_cpu_under_node(cpu, nid);</span>
 	}
 
<span class="p_del">-	return error;</span>
<span class="p_add">+	/* initialize work queue for memory hot plug */</span>
<span class="p_add">+	init_node_hugetlb_work(nid);</span>
 
<span class="p_add">+	return error;</span>
 }
 
 void unregister_one_node(int nid)
<span class="p_header">diff --git a/include/linux/node.h b/include/linux/node.h</span>
<span class="p_header">index 2115ad5d6f19..d1751beb462c 100644</span>
<span class="p_header">--- a/include/linux/node.h</span>
<span class="p_header">+++ b/include/linux/node.h</span>
<span class="p_chunk">@@ -30,9 +30,38 @@</span> <span class="p_context"> struct memory_block;</span>
 extern struct node *node_devices[];
 typedef  void (*node_registration_func_t)(struct node *);
 
<span class="p_add">+#if defined(CONFIG_MEMORY_HOTPLUG_SPARSE) &amp;&amp; defined(CONFIG_NUMA)</span>
<span class="p_add">+extern int link_mem_sections(int nid, unsigned long start_pfn, unsigned long nr_pages);</span>
<span class="p_add">+#else</span>
<span class="p_add">+static inline int link_mem_sections(int nid, unsigned long start_pfn, unsigned long nr_pages)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return 0;</span>
<span class="p_add">+}</span>
<span class="p_add">+#endif</span>
<span class="p_add">+</span>
 extern void unregister_node(struct node *node);
 #ifdef CONFIG_NUMA
<span class="p_del">-extern int register_one_node(int nid);</span>
<span class="p_add">+/* Core of the node registration - only memory hotplug should use this */</span>
<span class="p_add">+extern int __register_one_node(int nid);</span>
<span class="p_add">+</span>
<span class="p_add">+/* Registers an online node */</span>
<span class="p_add">+static inline int register_one_node(int nid)</span>
<span class="p_add">+{</span>
<span class="p_add">+	int error = 0;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (node_online(nid)) {</span>
<span class="p_add">+		struct pglist_data *pgdat = NODE_DATA(nid);</span>
<span class="p_add">+</span>
<span class="p_add">+		error = __register_one_node(nid);</span>
<span class="p_add">+		if (error)</span>
<span class="p_add">+			return error;</span>
<span class="p_add">+		/* link memory sections under this node */</span>
<span class="p_add">+		error = link_mem_sections(nid, pgdat-&gt;node_start_pfn, pgdat-&gt;node_spanned_pages);</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	return error;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 extern void unregister_one_node(int nid);
 extern int register_cpu_under_node(unsigned int cpu, unsigned int nid);
 extern int unregister_cpu_under_node(unsigned int cpu, unsigned int nid);
<span class="p_chunk">@@ -46,6 +75,10 @@</span> <span class="p_context"> extern void register_hugetlbfs_with_node(node_registration_func_t doregister,</span>
 					 node_registration_func_t unregister);
 #endif
 #else
<span class="p_add">+static inline int __register_one_node(int nid)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return 0;</span>
<span class="p_add">+}</span>
 static inline int register_one_node(int nid)
 {
 	return 0;
<span class="p_header">diff --git a/mm/memory_hotplug.c b/mm/memory_hotplug.c</span>
<span class="p_header">index 1570b3eea493..f5df0fe15ddf 100644</span>
<span class="p_header">--- a/mm/memory_hotplug.c</span>
<span class="p_header">+++ b/mm/memory_hotplug.c</span>
<span class="p_chunk">@@ -1387,7 +1387,22 @@</span> <span class="p_context"> int __ref add_memory_resource(int nid, struct resource *res, bool online)</span>
 	node_set_online(nid);
 
 	if (new_node) {
<span class="p_del">-		ret = register_one_node(nid);</span>
<span class="p_add">+		unsigned long start_pfn = start &gt;&gt; PAGE_SHIFT;</span>
<span class="p_add">+		unsigned long nr_pages = size &gt;&gt; PAGE_SHIFT;</span>
<span class="p_add">+</span>
<span class="p_add">+		ret = __register_one_node(nid);</span>
<span class="p_add">+		if (ret)</span>
<span class="p_add">+			goto register_fail;</span>
<span class="p_add">+</span>
<span class="p_add">+		/*</span>
<span class="p_add">+		 * link memory sections under this node. This is already</span>
<span class="p_add">+		 * done when creatig memory section in register_new_memory</span>
<span class="p_add">+		 * but that depends to have the node registered so offline</span>
<span class="p_add">+		 * nodes have to go through register_node.</span>
<span class="p_add">+		 * TODO clean up this mess.</span>
<span class="p_add">+		 */</span>
<span class="p_add">+		ret = link_mem_sections(nid, start_pfn, nr_pages);</span>
<span class="p_add">+register_fail:</span>
 		/*
 		 * If sysfs file of new node can&#39;t create, cpu on the node
 		 * can&#39;t be hot-added. There is no rollback way now.

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



