
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>mm: kill kmemcheck again - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    mm: kill kmemcheck again</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=728">Vegard Nossum</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>Sept. 30, 2017, 1:57 p.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;CAOMGZ=FHDXRLZbq20zAFh+0w4zk4F4dUxsDd0amsyMo3Cb2ZrA@mail.gmail.com&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/9979497/mbox/"
   >mbox</a>
|
   <a href="/patch/9979497/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/9979497/">/patch/9979497/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
	[172.30.200.125])
	by pdx-korg-patchwork.web.codeaurora.org (Postfix) with ESMTP id
	D44406034B for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Sat, 30 Sep 2017 13:57:46 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id B342229219
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Sat, 30 Sep 2017 13:57:46 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id A6A0029232; Sat, 30 Sep 2017 13:57:46 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-6.5 required=2.0 tests=BAYES_00,DKIM_SIGNED,
	DKIM_VALID, DKIM_VALID_AU, FREEMAIL_FROM, RCVD_IN_DNSWL_HI,
	RCVD_IN_SORBS_SPAM autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 9817829219
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Sat, 30 Sep 2017 13:57:41 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1751644AbdI3N5f (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Sat, 30 Sep 2017 09:57:35 -0400
Received: from mail-wm0-f49.google.com ([74.125.82.49]:45156 &quot;EHLO
	mail-wm0-f49.google.com&quot; rhost-flags-OK-OK-OK-OK) by vger.kernel.org
	with ESMTP id S1751028AbdI3N5a (ORCPT
	&lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Sat, 30 Sep 2017 09:57:30 -0400
Received: by mail-wm0-f49.google.com with SMTP id q124so3696442wmb.0
	for &lt;linux-kernel@vger.kernel.org&gt;;
	Sat, 30 Sep 2017 06:57:29 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
	d=gmail.com; s=20161025;
	h=mime-version:in-reply-to:references:from:date:message-id:subject:to
	:cc; bh=fHJLSo1mD2gaJtGv8jsqk0rv+Cu2rDY15mTihuqlFcM=;
	b=LbIrfaQ8DDsmodUuqAglnPBevCgd4WVdpP5hr+lnx4kMYIRql3/B2cFVsrhR70bhgz
	wuZ2Gei9PptBdYhGlqE8KO+zE3R4tzVS4DDRPN5GlesJaVk2JNUP9YpFQm6rwUZL4YFq
	UADSTSgyutqFfnT/BXdWaN/bi2MNklbvXxNfNvFE+qE5T4YTNzi6q7vv7Qeu32G54kcb
	8lm3AtHJ009SLj0WYJ2AA4Uwj0ro6YHyWa1jxWNFP7/NKNxtd2SdR6itLYsRcDhLJX9L
	82Sfzwv136w8mIKXzN8lQjeMdCNZ3refD186EHEfjGL3NQJYRCPMhzPeI308uM2YWZ0+
	pcfA==
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
	d=1e100.net; s=20161025;
	h=x-gm-message-state:mime-version:in-reply-to:references:from:date
	:message-id:subject:to:cc;
	bh=fHJLSo1mD2gaJtGv8jsqk0rv+Cu2rDY15mTihuqlFcM=;
	b=r7dSc7o6NBZ1nhxujHNYk1chRNGLFbVWwunCGYTnd+MPp7l+gQzi2+GPyfwdwjuMi0
	UG6nA6G22hm+YbWqk8fJVgj/NPj7ODIa01HpXI/gnm9g16rddfgVTSkXAanlziEmcAX+
	QXydZzr9wQD9C7dGxy5mFogSzLUzt4AXGMUKLD3N4l/y5R52A7nyyUycTp204p3jksnN
	FnoIh8YgYaNKC1QPUxQf90gwBqMjHowrDx9WPtpgosx3/icURYJ6vKNbmKoBs3xaZ9FG
	77HWDrGjXge2vBK92pfG7TEQzdWt0U15uH9yXPg0ann4S0JyoSHrOE4PiAHPqaHwWenT
	KUvA==
X-Gm-Message-State: AMCzsaXrDq3ErHPNPfOfDjAhYjl4Jx5de90jYvxKkfDX2qffZVioKcD2
	VfsUiMURaFSznnmOcbNjA66pppKPZ/izcNtxKeE=
X-Google-Smtp-Source: AOwi7QADFFQngnXv5l3PtBc6BnMRzNRbeC+J86TAbi7ozVqOFPOm35jEwDtRk29cx8OsXV6ewB63awT8pJOU9q9chCg=
X-Received: by 10.28.145.72 with SMTP id t69mr6520424wmd.113.1506779848623; 
	Sat, 30 Sep 2017 06:57:28 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.223.133.38 with HTTP; Sat, 30 Sep 2017 06:57:27 -0700 (PDT)
In-Reply-To: &lt;20170930054815.0e2c182f@vmware.local.home&gt;
References: &lt;20170927112723.16862-1-alexander.levin@verizon.com&gt;
	&lt;20170927150207.swmcarc4lqlklohr@dhcp22.suse.cz&gt;
	&lt;20170930054815.0e2c182f@vmware.local.home&gt;
From: Vegard Nossum &lt;vegard.nossum@gmail.com&gt;
Date: Sat, 30 Sep 2017 15:57:27 +0200
Message-ID: &lt;CAOMGZ=FHDXRLZbq20zAFh+0w4zk4F4dUxsDd0amsyMo3Cb2ZrA@mail.gmail.com&gt;
Subject: Re: [PATCH] mm: kill kmemcheck again
To: Steven Rostedt &lt;rostedt@goodmis.org&gt;
Cc: Michal Hocko &lt;mhocko@kernel.org&gt;,
	&quot;Levin, Alexander (Sasha Levin)&quot; &lt;alexander.levin@verizon.com&gt;,
	&quot;akpm@linux-foundation.org&quot; &lt;akpm@linux-foundation.org&gt;,
	&quot;linux-kernel@vger.kernel.org&quot; &lt;linux-kernel@vger.kernel.org&gt;,
	&quot;David S . Miller&quot; &lt;davem@davemloft.net&gt;,
	Alexander Potapenko &lt;glider@google.com&gt;,
	Andrey Ryabinin &lt;aryabinin@virtuozzo.com&gt;,
	Dmitry Vyukov &lt;dvyukov@google.com&gt;
Content-Type: multipart/mixed; boundary=&quot;001a1145b084a20317055a6885ba&quot;
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=728">Vegard Nossum</a> - Sept. 30, 2017, 1:57 p.m.</div>
<pre class="content">
On 30 September 2017 at 11:48, Steven Rostedt &lt;rostedt@goodmis.org&gt; wrote:
<span class="quote">&gt; On Wed, 27 Sep 2017 17:02:07 +0200</span>
<span class="quote">&gt; Michal Hocko &lt;mhocko@kernel.org&gt; wrote:</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;&gt; &gt; Now that 2 years have passed, and all distros provide gcc that supports</span>
<span class="quote">&gt;&gt; &gt; KASAN, kill kmemcheck again for the very same reasons.</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; This is just too large to review manually. How have you generated the</span>
<span class="quote">&gt;&gt; patch?</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; I agree. This needs to be taken out piece by piece, not in one go,</span>
<span class="quote">&gt; where there could be unexpected fallout.</span>

I have a patch from earlier this year that starts by removing the core
code and defining all the helpers/flags as no-ops so they can be
removed bit by bit at a later time. See the attachment. Pekka signed
off on it too.

I never actually submitted this because I was waiting for MSAN to be
merged in the kernel. It has been compile and run tested on x86_64.


Vegard
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=169497">Levin, Alexander</a> - Sept. 30, 2017, 8:02 p.m.</div>
<pre class="content">
On Sat, Sep 30, 2017 at 03:57:27PM +0200, Vegard Nossum wrote:
<span class="quote">&gt;On 30 September 2017 at 11:48, Steven Rostedt &lt;rostedt@goodmis.org&gt; wrote:</span>
<span class="quote">&gt;&gt; On Wed, 27 Sep 2017 17:02:07 +0200</span>
<span class="quote">&gt;&gt; Michal Hocko &lt;mhocko@kernel.org&gt; wrote:</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt; &gt; Now that 2 years have passed, and all distros provide gcc that supports</span>
<span class="quote">&gt;&gt;&gt; &gt; KASAN, kill kmemcheck again for the very same reasons.</span>
<span class="quote">&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt; This is just too large to review manually. How have you generated the</span>
<span class="quote">&gt;&gt;&gt; patch?</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; I agree. This needs to be taken out piece by piece, not in one go,</span>
<span class="quote">&gt;&gt; where there could be unexpected fallout.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;I have a patch from earlier this year that starts by removing the core</span>
<span class="quote">&gt;code and defining all the helpers/flags as no-ops so they can be</span>
<span class="quote">&gt;removed bit by bit at a later time. See the attachment. Pekka signed</span>
<span class="quote">&gt;off on it too.</span>
<span class="quote">&gt;e</span>
<span class="quote">&gt;I never actually submitted this because I was waiting for MSAN to be</span>

I&#39;m not sure how much value there is in doing it this way. I agree that the patch is big, but most of it is simply removing code under arch/x86/mm/kmemcheck.

The difference between Vegard&#39;s patch and mine is about 300 lines (out of 2800+), where those 300 lines are simply removing calls to kmemcheck. There are no logic changes. (so something very similar to &#39;s/*kmemcheck*//g&#39; would do the trick).

--

Thanks,
Sasha
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=137061">Michal Hocko</a> - Oct. 2, 2017, 7:29 a.m.</div>
<pre class="content">
On Sat 30-09-17 20:02:41, Sasha Levin wrote:
<span class="quote">&gt; On Sat, Sep 30, 2017 at 03:57:27PM +0200, Vegard Nossum wrote:</span>
<span class="quote">&gt; &gt;On 30 September 2017 at 11:48, Steven Rostedt &lt;rostedt@goodmis.org&gt; wrote:</span>
<span class="quote">&gt; &gt;&gt; On Wed, 27 Sep 2017 17:02:07 +0200</span>
<span class="quote">&gt; &gt;&gt; Michal Hocko &lt;mhocko@kernel.org&gt; wrote:</span>
<span class="quote">&gt; &gt;&gt;</span>
<span class="quote">&gt; &gt;&gt;&gt; &gt; Now that 2 years have passed, and all distros provide gcc that supports</span>
<span class="quote">&gt; &gt;&gt;&gt; &gt; KASAN, kill kmemcheck again for the very same reasons.</span>
<span class="quote">&gt; &gt;&gt;&gt;</span>
<span class="quote">&gt; &gt;&gt;&gt; This is just too large to review manually. How have you generated the</span>
<span class="quote">&gt; &gt;&gt;&gt; patch?</span>
<span class="quote">&gt; &gt;&gt;</span>
<span class="quote">&gt; &gt;&gt; I agree. This needs to be taken out piece by piece, not in one go,</span>
<span class="quote">&gt; &gt;&gt; where there could be unexpected fallout.</span>
<span class="quote">&gt; &gt;</span>
<span class="quote">&gt; &gt;I have a patch from earlier this year that starts by removing the core</span>
<span class="quote">&gt; &gt;code and defining all the helpers/flags as no-ops so they can be</span>
<span class="quote">&gt; &gt;removed bit by bit at a later time. See the attachment. Pekka signed</span>
<span class="quote">&gt; &gt;off on it too.</span>
<span class="quote">&gt; &gt;e</span>
<span class="quote">&gt; &gt;I never actually submitted this because I was waiting for MSAN to be</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; I&#39;m not sure how much value there is in doing it this way. I agree</span>
<span class="quote">&gt; that the patch is big, but most of it is simply removing code under</span>
<span class="quote">&gt; arch/x86/mm/kmemcheck.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; The difference between Vegard&#39;s patch and mine is about 300 lines</span>
<span class="quote">&gt; (out of 2800+), where those 300 lines are simply removing calls to</span>
<span class="quote">&gt; kmemcheck. There are no logic changes. (so something very similar to</span>
<span class="quote">&gt; &#39;s/*kmemcheck*//g&#39; would do the trick).</span>

Maybe splitting the patch into three: 1) remove all callers of kmemleak
API and 2) remove arch/x86/mm/kmemcheck/ and 3) remove leftovers would
be slightly easier to review. Maybe 2 and 3 would have some dependencies
so they would have to end up in the same path.

Just my 2c
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=310">Steven Rostedt</a> - Oct. 3, 2017, 9:02 p.m.</div>
<pre class="content">
On Mon, 2 Oct 2017 09:29:04 +0200
Michal Hocko &lt;mhocko@kernel.org&gt; wrote:
<span class="quote">
&gt; Maybe splitting the patch into three: 1) remove all callers of kmemleak</span>
<span class="quote">&gt; API and 2) remove arch/x86/mm/kmemcheck/ and 3) remove leftovers would</span>
<span class="quote">&gt; be slightly easier to review. Maybe 2 and 3 would have some dependencies</span>
<span class="quote">&gt; so they would have to end up in the same path.</span>

Perhaps start with just marking kmemcheck broken to prevent new users
as well. Let that go in for a release, and then start removing it
afterward.

-- Steve
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
From b06e2b3b833b02ecb0afb9dd92422e89c7fbb6d9 Mon Sep 17 00:00:00 2001
From: Vegard Nossum &lt;vegard.nossum@oracle.com&gt;
Date: Thu, 30 Mar 2017 13:26:15 +0200
Subject: [PATCH] kmemcheck: remove core (x86 + mm) code

With KASAN/KMSAN and compiler-based instrumentation, this code is way past
its expiry date. There is zero reason to be using kmemcheck at this point,
as KASAN/KMSAN will be much faster, support SMP, and catch any bug that
kmemcheck would have caught. See the additional rationale and past
discussion at &lt;https://lkml.org/lkml/2015/3/11/435&gt;.

I take the approach of first removing all the core x86 and mm code, leaving
behind only include/linux/kmemcheck.h which provides some helpers (now only
dummies as for the !KMEMCHECK case previously) used in e.g. networking code
for special annotations.

We can then send individual (smaller, more reviewable) patches for removing
kmemcheck annotations in other subsystems.

Once there are no users of the kmemcheck helpers, we can kill off the dummy
helpers as well in a final patch.

Cc: Ingo Molnar &lt;mingo@kernel.org&gt;
Cc: Andrew Morton &lt;akpm@linux-foundation.org&gt;
Cc: Sasha Levin &lt;alexander.levin@verizon.com&gt;
Cc: Steven Rostedt &lt;rostedt@goodmis.org&gt;
Signed-off-by: Vegard Nossum &lt;vegard.nossum@oracle.com&gt;
Signed-off-by: Pekka Enberg &lt;penberg@kernel.org&gt;
<span class="p_del">---</span>
 Documentation/admin-guide/kernel-parameters.txt |   7 -
 Documentation/dev-tools/index.rst               |   1 -
 Documentation/dev-tools/kmemcheck.rst           | 733 ------------------------
 MAINTAINERS                                     |  10 -
 arch/arm/include/asm/dma-iommu.h                |   1 -
 arch/openrisc/include/asm/dma-mapping.h         |   1 -
 arch/x86/Kconfig                                |   3 +-
 arch/x86/Makefile                               |   5 -
 arch/x86/include/asm/dma-mapping.h              |   1 -
 arch/x86/include/asm/kmemcheck.h                |  42 --
 arch/x86/include/asm/pgtable_types.h            |   8 +-
 arch/x86/include/asm/string_32.h                |   9 -
 arch/x86/include/asm/string_64.h                |   8 -
 arch/x86/include/asm/xor.h                      |   5 +-
 arch/x86/kernel/cpu/intel.c                     |  15 -
 arch/x86/kernel/traps.c                         |   5 -
 arch/x86/mm/Makefile                            |   2 -
 arch/x86/mm/fault.c                             |   6 -
 arch/x86/mm/init.c                              |   5 +-
 arch/x86/mm/kmemcheck/Makefile                  |   1 -
 arch/x86/mm/kmemcheck/error.c                   | 227 --------
 arch/x86/mm/kmemcheck/error.h                   |  15 -
 arch/x86/mm/kmemcheck/kmemcheck.c               | 658 ---------------------
 arch/x86/mm/kmemcheck/opcode.c                  | 106 ----
 arch/x86/mm/kmemcheck/opcode.h                  |   9 -
 arch/x86/mm/kmemcheck/pte.c                     |  22 -
 arch/x86/mm/kmemcheck/pte.h                     |  10 -
 arch/x86/mm/kmemcheck/selftest.c                |  70 ---
 arch/x86/mm/kmemcheck/selftest.h                |   6 -
 arch/x86/mm/kmemcheck/shadow.c                  | 173 ------
 arch/x86/mm/kmemcheck/shadow.h                  |  18 -
 include/linux/dma-mapping.h                     |   8 +-
 include/linux/gfp.h                             |   2 -
 include/linux/kmemcheck.h                       |  59 --
 include/linux/mm_types.h                        |   8 -
 include/linux/slab.h                            |  12 +-
 init/main.c                                     |   1 -
 kernel/sysctl.c                                 |  10 -
 lib/Kconfig.debug                               |   6 +-
 lib/Kconfig.kmemcheck                           |  94 ---
 mm/Kconfig.debug                                |   1 -
 mm/Makefile                                     |   2 -
 mm/kmemcheck.c                                  | 125 ----
 mm/page_alloc.c                                 |  14 -
 mm/slab.c                                       |  14 -
 mm/slab.h                                       |   2 -
 mm/slub.c                                       |  25 +-
 47 files changed, 18 insertions(+), 2547 deletions(-)
 delete mode 100644 Documentation/dev-tools/kmemcheck.rst
 delete mode 100644 arch/x86/include/asm/kmemcheck.h
 delete mode 100644 arch/x86/mm/kmemcheck/Makefile
 delete mode 100644 arch/x86/mm/kmemcheck/error.c
 delete mode 100644 arch/x86/mm/kmemcheck/error.h
 delete mode 100644 arch/x86/mm/kmemcheck/kmemcheck.c
 delete mode 100644 arch/x86/mm/kmemcheck/opcode.c
 delete mode 100644 arch/x86/mm/kmemcheck/opcode.h
 delete mode 100644 arch/x86/mm/kmemcheck/pte.c
 delete mode 100644 arch/x86/mm/kmemcheck/pte.h
 delete mode 100644 arch/x86/mm/kmemcheck/selftest.c
 delete mode 100644 arch/x86/mm/kmemcheck/selftest.h
 delete mode 100644 arch/x86/mm/kmemcheck/shadow.c
 delete mode 100644 arch/x86/mm/kmemcheck/shadow.h
 delete mode 100644 lib/Kconfig.kmemcheck
 delete mode 100644 mm/kmemcheck.c

<span class="p_header">diff --git a/Documentation/admin-guide/kernel-parameters.txt b/Documentation/admin-guide/kernel-parameters.txt</span>
<span class="p_header">index facc20a3f962..c3a1a7edfcfc 100644</span>
<span class="p_header">--- a/Documentation/admin-guide/kernel-parameters.txt</span>
<span class="p_header">+++ b/Documentation/admin-guide/kernel-parameters.txt</span>
<span class="p_chunk">@@ -1793,13 +1793,6 @@</span> <span class="p_context"></span>
 			Built with CONFIG_DEBUG_KMEMLEAK_DEFAULT_OFF=y,
 			the default is off.
 
<span class="p_del">-	kmemcheck=	[X86] Boot-time kmemcheck enable/disable/one-shot mode</span>
<span class="p_del">-			Valid arguments: 0, 1, 2</span>
<span class="p_del">-			kmemcheck=0 (disabled)</span>
<span class="p_del">-			kmemcheck=1 (enabled)</span>
<span class="p_del">-			kmemcheck=2 (one-shot mode)</span>
<span class="p_del">-			Default: 2 (one-shot mode)</span>
<span class="p_del">-</span>
 	kvm.ignore_msrs=[KVM] Ignore guest accesses to unhandled MSRs.
 			Default is 0 (don&#39;t ignore, but inject #GP)
 
<span class="p_header">diff --git a/Documentation/dev-tools/index.rst b/Documentation/dev-tools/index.rst</span>
<span class="p_header">index 07d881147ef3..0196fcf8a7a5 100644</span>
<span class="p_header">--- a/Documentation/dev-tools/index.rst</span>
<span class="p_header">+++ b/Documentation/dev-tools/index.rst</span>
<span class="p_chunk">@@ -21,7 +21,6 @@</span> <span class="p_context"> whole; patches welcome!</span>
    kasan
    ubsan
    kmemleak
<span class="p_del">-   kmemcheck</span>
    gdb-kernel-debugging
 
 
<span class="p_header">diff --git a/Documentation/dev-tools/kmemcheck.rst b/Documentation/dev-tools/kmemcheck.rst</span>
deleted file mode 100644
<span class="p_header">index 7f3d1985de74..000000000000</span>
<span class="p_header">--- a/Documentation/dev-tools/kmemcheck.rst</span>
<span class="p_header">+++ /dev/null</span>
<span class="p_chunk">@@ -1,733 +0,0 @@</span> <span class="p_context"></span>
<span class="p_del">-Getting started with kmemcheck</span>
<span class="p_del">-==============================</span>
<span class="p_del">-</span>
<span class="p_del">-Vegard Nossum &lt;vegardno@ifi.uio.no&gt;</span>
<span class="p_del">-</span>
<span class="p_del">-</span>
<span class="p_del">-Introduction</span>
<span class="p_del">-------------</span>
<span class="p_del">-</span>
<span class="p_del">-kmemcheck is a debugging feature for the Linux Kernel. More specifically, it</span>
<span class="p_del">-is a dynamic checker that detects and warns about some uses of uninitialized</span>
<span class="p_del">-memory.</span>
<span class="p_del">-</span>
<span class="p_del">-Userspace programmers might be familiar with Valgrind&#39;s memcheck. The main</span>
<span class="p_del">-difference between memcheck and kmemcheck is that memcheck works for userspace</span>
<span class="p_del">-programs only, and kmemcheck works for the kernel only. The implementations</span>
<span class="p_del">-are of course vastly different. Because of this, kmemcheck is not as accurate</span>
<span class="p_del">-as memcheck, but it turns out to be good enough in practice to discover real</span>
<span class="p_del">-programmer errors that the compiler is not able to find through static</span>
<span class="p_del">-analysis.</span>
<span class="p_del">-</span>
<span class="p_del">-Enabling kmemcheck on a kernel will probably slow it down to the extent that</span>
<span class="p_del">-the machine will not be usable for normal workloads such as e.g. an</span>
<span class="p_del">-interactive desktop. kmemcheck will also cause the kernel to use about twice</span>
<span class="p_del">-as much memory as normal. For this reason, kmemcheck is strictly a debugging</span>
<span class="p_del">-feature.</span>
<span class="p_del">-</span>
<span class="p_del">-</span>
<span class="p_del">-Downloading</span>
<span class="p_del">------------</span>
<span class="p_del">-</span>
<span class="p_del">-As of version 2.6.31-rc1, kmemcheck is included in the mainline kernel.</span>
<span class="p_del">-</span>
<span class="p_del">-</span>
<span class="p_del">-Configuring and compiling</span>
<span class="p_del">--------------------------</span>
<span class="p_del">-</span>
<span class="p_del">-kmemcheck only works for the x86 (both 32- and 64-bit) platform. A number of</span>
<span class="p_del">-configuration variables must have specific settings in order for the kmemcheck</span>
<span class="p_del">-menu to even appear in &quot;menuconfig&quot;. These are:</span>
<span class="p_del">-</span>
<span class="p_del">-- ``CONFIG_CC_OPTIMIZE_FOR_SIZE=n``</span>
<span class="p_del">-	This option is located under &quot;General setup&quot; / &quot;Optimize for size&quot;.</span>
<span class="p_del">-</span>
<span class="p_del">-	Without this, gcc will use certain optimizations that usually lead to</span>
<span class="p_del">-	false positive warnings from kmemcheck. An example of this is a 16-bit</span>
<span class="p_del">-	field in a struct, where gcc may load 32 bits, then discard the upper</span>
<span class="p_del">-	16 bits. kmemcheck sees only the 32-bit load, and may trigger a</span>
<span class="p_del">-	warning for the upper 16 bits (if they&#39;re uninitialized).</span>
<span class="p_del">-</span>
<span class="p_del">-- ``CONFIG_SLAB=y`` or ``CONFIG_SLUB=y``</span>
<span class="p_del">-	This option is located under &quot;General setup&quot; / &quot;Choose SLAB</span>
<span class="p_del">-	allocator&quot;.</span>
<span class="p_del">-</span>
<span class="p_del">-- ``CONFIG_FUNCTION_TRACER=n``</span>
<span class="p_del">-	This option is located under &quot;Kernel hacking&quot; / &quot;Tracers&quot; / &quot;Kernel</span>
<span class="p_del">-	Function Tracer&quot;</span>
<span class="p_del">-</span>
<span class="p_del">-	When function tracing is compiled in, gcc emits a call to another</span>
<span class="p_del">-	function at the beginning of every function. This means that when the</span>
<span class="p_del">-	page fault handler is called, the ftrace framework will be called</span>
<span class="p_del">-	before kmemcheck has had a chance to handle the fault. If ftrace then</span>
<span class="p_del">-	modifies memory that was tracked by kmemcheck, the result is an</span>
<span class="p_del">-	endless recursive page fault.</span>
<span class="p_del">-</span>
<span class="p_del">-- ``CONFIG_DEBUG_PAGEALLOC=n``</span>
<span class="p_del">-	This option is located under &quot;Kernel hacking&quot; / &quot;Memory Debugging&quot;</span>
<span class="p_del">-	/ &quot;Debug page memory allocations&quot;.</span>
<span class="p_del">-</span>
<span class="p_del">-In addition, I highly recommend turning on ``CONFIG_DEBUG_INFO=y``. This is also</span>
<span class="p_del">-located under &quot;Kernel hacking&quot;. With this, you will be able to get line number</span>
<span class="p_del">-information from the kmemcheck warnings, which is extremely valuable in</span>
<span class="p_del">-debugging a problem. This option is not mandatory, however, because it slows</span>
<span class="p_del">-down the compilation process and produces a much bigger kernel image.</span>
<span class="p_del">-</span>
<span class="p_del">-Now the kmemcheck menu should be visible (under &quot;Kernel hacking&quot; / &quot;Memory</span>
<span class="p_del">-Debugging&quot; / &quot;kmemcheck: trap use of uninitialized memory&quot;). Here follows</span>
<span class="p_del">-a description of the kmemcheck configuration variables:</span>
<span class="p_del">-</span>
<span class="p_del">-- ``CONFIG_KMEMCHECK``</span>
<span class="p_del">-	This must be enabled in order to use kmemcheck at all...</span>
<span class="p_del">-</span>
<span class="p_del">-- ``CONFIG_KMEMCHECK_``[``DISABLED`` | ``ENABLED`` | ``ONESHOT``]``_BY_DEFAULT``</span>
<span class="p_del">-	This option controls the status of kmemcheck at boot-time. &quot;Enabled&quot;</span>
<span class="p_del">-	will enable kmemcheck right from the start, &quot;disabled&quot; will boot the</span>
<span class="p_del">-	kernel as normal (but with the kmemcheck code compiled in, so it can</span>
<span class="p_del">-	be enabled at run-time after the kernel has booted), and &quot;one-shot&quot; is</span>
<span class="p_del">-	a special mode which will turn kmemcheck off automatically after</span>
<span class="p_del">-	detecting the first use of uninitialized memory.</span>
<span class="p_del">-</span>
<span class="p_del">-	If you are using kmemcheck to actively debug a problem, then you</span>
<span class="p_del">-	probably want to choose &quot;enabled&quot; here.</span>
<span class="p_del">-</span>
<span class="p_del">-	The one-shot mode is mostly useful in automated test setups because it</span>
<span class="p_del">-	can prevent floods of warnings and increase the chances of the machine</span>
<span class="p_del">-	surviving in case something is really wrong. In other cases, the one-</span>
<span class="p_del">-	shot mode could actually be counter-productive because it would turn</span>
<span class="p_del">-	itself off at the very first error -- in the case of a false positive</span>
<span class="p_del">-	too -- and this would come in the way of debugging the specific</span>
<span class="p_del">-	problem you were interested in.</span>
<span class="p_del">-</span>
<span class="p_del">-	If you would like to use your kernel as normal, but with a chance to</span>
<span class="p_del">-	enable kmemcheck in case of some problem, it might be a good idea to</span>
<span class="p_del">-	choose &quot;disabled&quot; here. When kmemcheck is disabled, most of the run-</span>
<span class="p_del">-	time overhead is not incurred, and the kernel will be almost as fast</span>
<span class="p_del">-	as normal.</span>
<span class="p_del">-</span>
<span class="p_del">-- ``CONFIG_KMEMCHECK_QUEUE_SIZE``</span>
<span class="p_del">-	Select the maximum number of error reports to store in an internal</span>
<span class="p_del">-	(fixed-size) buffer. Since errors can occur virtually anywhere and in</span>
<span class="p_del">-	any context, we need a temporary storage area which is guaranteed not</span>
<span class="p_del">-	to generate any other page faults when accessed. The queue will be</span>
<span class="p_del">-	emptied as soon as a tasklet may be scheduled. If the queue is full,</span>
<span class="p_del">-	new error reports will be lost.</span>
<span class="p_del">-</span>
<span class="p_del">-	The default value of 64 is probably fine. If some code produces more</span>
<span class="p_del">-	than 64 errors within an irqs-off section, then the code is likely to</span>
<span class="p_del">-	produce many, many more, too, and these additional reports seldom give</span>
<span class="p_del">-	any more information (the first report is usually the most valuable</span>
<span class="p_del">-	anyway).</span>
<span class="p_del">-</span>
<span class="p_del">-	This number might have to be adjusted if you are not using serial</span>
<span class="p_del">-	console or similar to capture the kernel log. If you are using the</span>
<span class="p_del">-	&quot;dmesg&quot; command to save the log, then getting a lot of kmemcheck</span>
<span class="p_del">-	warnings might overflow the kernel log itself, and the earlier reports</span>
<span class="p_del">-	will get lost in that way instead. Try setting this to 10 or so on</span>
<span class="p_del">-	such a setup.</span>
<span class="p_del">-</span>
<span class="p_del">-- ``CONFIG_KMEMCHECK_SHADOW_COPY_SHIFT``</span>
<span class="p_del">-	Select the number of shadow bytes to save along with each entry of the</span>
<span class="p_del">-	error-report queue. These bytes indicate what parts of an allocation</span>
<span class="p_del">-	are initialized, uninitialized, etc. and will be displayed when an</span>
<span class="p_del">-	error is detected to help the debugging of a particular problem.</span>
<span class="p_del">-</span>
<span class="p_del">-	The number entered here is actually the logarithm of the number of</span>
<span class="p_del">-	bytes that will be saved. So if you pick for example 5 here, kmemcheck</span>
<span class="p_del">-	will save 2^5 = 32 bytes.</span>
<span class="p_del">-</span>
<span class="p_del">-	The default value should be fine for debugging most problems. It also</span>
<span class="p_del">-	fits nicely within 80 columns.</span>
<span class="p_del">-</span>
<span class="p_del">-- ``CONFIG_KMEMCHECK_PARTIAL_OK``</span>
<span class="p_del">-	This option (when enabled) works around certain GCC optimizations that</span>
<span class="p_del">-	produce 32-bit reads from 16-bit variables where the upper 16 bits are</span>
<span class="p_del">-	thrown away afterwards.</span>
<span class="p_del">-</span>
<span class="p_del">-	The default value (enabled) is recommended. This may of course hide</span>
<span class="p_del">-	some real errors, but disabling it would probably produce a lot of</span>
<span class="p_del">-	false positives.</span>
<span class="p_del">-</span>
<span class="p_del">-- ``CONFIG_KMEMCHECK_BITOPS_OK``</span>
<span class="p_del">-	This option silences warnings that would be generated for bit-field</span>
<span class="p_del">-	accesses where not all the bits are initialized at the same time. This</span>
<span class="p_del">-	may also hide some real bugs.</span>
<span class="p_del">-</span>
<span class="p_del">-	This option is probably obsolete, or it should be replaced with</span>
<span class="p_del">-	the kmemcheck-/bitfield-annotations for the code in question. The</span>
<span class="p_del">-	default value is therefore fine.</span>
<span class="p_del">-</span>
<span class="p_del">-Now compile the kernel as usual.</span>
<span class="p_del">-</span>
<span class="p_del">-</span>
<span class="p_del">-How to use</span>
<span class="p_del">-----------</span>
<span class="p_del">-</span>
<span class="p_del">-Booting</span>
<span class="p_del">-~~~~~~~</span>
<span class="p_del">-</span>
<span class="p_del">-First some information about the command-line options. There is only one</span>
<span class="p_del">-option specific to kmemcheck, and this is called &quot;kmemcheck&quot;. It can be used</span>
<span class="p_del">-to override the default mode as chosen by the ``CONFIG_KMEMCHECK_*_BY_DEFAULT``</span>
<span class="p_del">-option. Its possible settings are:</span>
<span class="p_del">-</span>
<span class="p_del">-- ``kmemcheck=0`` (disabled)</span>
<span class="p_del">-- ``kmemcheck=1`` (enabled)</span>
<span class="p_del">-- ``kmemcheck=2`` (one-shot mode)</span>
<span class="p_del">-</span>
<span class="p_del">-If SLUB debugging has been enabled in the kernel, it may take precedence over</span>
<span class="p_del">-kmemcheck in such a way that the slab caches which are under SLUB debugging</span>
<span class="p_del">-will not be tracked by kmemcheck. In order to ensure that this doesn&#39;t happen</span>
<span class="p_del">-(even though it shouldn&#39;t by default), use SLUB&#39;s boot option ``slub_debug``,</span>
<span class="p_del">-like this: ``slub_debug=-``</span>
<span class="p_del">-</span>
<span class="p_del">-In fact, this option may also be used for fine-grained control over SLUB vs.</span>
<span class="p_del">-kmemcheck. For example, if the command line includes</span>
<span class="p_del">-``kmemcheck=1 slub_debug=,dentry``, then SLUB debugging will be used only</span>
<span class="p_del">-for the &quot;dentry&quot; slab cache, and with kmemcheck tracking all the other</span>
<span class="p_del">-caches. This is advanced usage, however, and is not generally recommended.</span>
<span class="p_del">-</span>
<span class="p_del">-</span>
<span class="p_del">-Run-time enable/disable</span>
<span class="p_del">-~~~~~~~~~~~~~~~~~~~~~~~</span>
<span class="p_del">-</span>
<span class="p_del">-When the kernel has booted, it is possible to enable or disable kmemcheck at</span>
<span class="p_del">-run-time. WARNING: This feature is still experimental and may cause false</span>
<span class="p_del">-positive warnings to appear. Therefore, try not to use this. If you find that</span>
<span class="p_del">-it doesn&#39;t work properly (e.g. you see an unreasonable amount of warnings), I</span>
<span class="p_del">-will be happy to take bug reports.</span>
<span class="p_del">-</span>
<span class="p_del">-Use the file ``/proc/sys/kernel/kmemcheck`` for this purpose, e.g.::</span>
<span class="p_del">-</span>
<span class="p_del">-	$ echo 0 &gt; /proc/sys/kernel/kmemcheck # disables kmemcheck</span>
<span class="p_del">-</span>
<span class="p_del">-The numbers are the same as for the ``kmemcheck=`` command-line option.</span>
<span class="p_del">-</span>
<span class="p_del">-</span>
<span class="p_del">-Debugging</span>
<span class="p_del">-~~~~~~~~~</span>
<span class="p_del">-</span>
<span class="p_del">-A typical report will look something like this::</span>
<span class="p_del">-</span>
<span class="p_del">-    WARNING: kmemcheck: Caught 32-bit read from uninitialized memory (ffff88003e4a2024)</span>
<span class="p_del">-    80000000000000000000000000000000000000000088ffff0000000000000000</span>
<span class="p_del">-     i i i i u u u u i i i i i i i i u u u u u u u u u u u u u u u u</span>
<span class="p_del">-             ^</span>
<span class="p_del">-</span>
<span class="p_del">-    Pid: 1856, comm: ntpdate Not tainted 2.6.29-rc5 #264 945P-A</span>
<span class="p_del">-    RIP: 0010:[&lt;ffffffff8104ede8&gt;]  [&lt;ffffffff8104ede8&gt;] __dequeue_signal+0xc8/0x190</span>
<span class="p_del">-    RSP: 0018:ffff88003cdf7d98  EFLAGS: 00210002</span>
<span class="p_del">-    RAX: 0000000000000030 RBX: ffff88003d4ea968 RCX: 0000000000000009</span>
<span class="p_del">-    RDX: ffff88003e5d6018 RSI: ffff88003e5d6024 RDI: ffff88003cdf7e84</span>
<span class="p_del">-    RBP: ffff88003cdf7db8 R08: ffff88003e5d6000 R09: 0000000000000000</span>
<span class="p_del">-    R10: 0000000000000080 R11: 0000000000000000 R12: 000000000000000e</span>
<span class="p_del">-    R13: ffff88003cdf7e78 R14: ffff88003d530710 R15: ffff88003d5a98c8</span>
<span class="p_del">-    FS:  0000000000000000(0000) GS:ffff880001982000(0063) knlGS:00000</span>
<span class="p_del">-    CS:  0010 DS: 002b ES: 002b CR0: 0000000080050033</span>
<span class="p_del">-    CR2: ffff88003f806ea0 CR3: 000000003c036000 CR4: 00000000000006a0</span>
<span class="p_del">-    DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000</span>
<span class="p_del">-    DR3: 0000000000000000 DR6: 00000000ffff4ff0 DR7: 0000000000000400</span>
<span class="p_del">-     [&lt;ffffffff8104f04e&gt;] dequeue_signal+0x8e/0x170</span>
<span class="p_del">-     [&lt;ffffffff81050bd8&gt;] get_signal_to_deliver+0x98/0x390</span>
<span class="p_del">-     [&lt;ffffffff8100b87d&gt;] do_notify_resume+0xad/0x7d0</span>
<span class="p_del">-     [&lt;ffffffff8100c7b5&gt;] int_signal+0x12/0x17</span>
<span class="p_del">-     [&lt;ffffffffffffffff&gt;] 0xffffffffffffffff</span>
<span class="p_del">-</span>
<span class="p_del">-The single most valuable information in this report is the RIP (or EIP on 32-</span>
<span class="p_del">-bit) value. This will help us pinpoint exactly which instruction that caused</span>
<span class="p_del">-the warning.</span>
<span class="p_del">-</span>
<span class="p_del">-If your kernel was compiled with ``CONFIG_DEBUG_INFO=y``, then all we have to do</span>
<span class="p_del">-is give this address to the addr2line program, like this::</span>
<span class="p_del">-</span>
<span class="p_del">-	$ addr2line -e vmlinux -i ffffffff8104ede8</span>
<span class="p_del">-	arch/x86/include/asm/string_64.h:12</span>
<span class="p_del">-	include/asm-generic/siginfo.h:287</span>
<span class="p_del">-	kernel/signal.c:380</span>
<span class="p_del">-	kernel/signal.c:410</span>
<span class="p_del">-</span>
<span class="p_del">-The &quot;``-e vmlinux``&quot; tells addr2line which file to look in. **IMPORTANT:**</span>
<span class="p_del">-This must be the vmlinux of the kernel that produced the warning in the</span>
<span class="p_del">-first place! If not, the line number information will almost certainly be</span>
<span class="p_del">-wrong.</span>
<span class="p_del">-</span>
<span class="p_del">-The &quot;``-i``&quot; tells addr2line to also print the line numbers of inlined</span>
<span class="p_del">-functions.  In this case, the flag was very important, because otherwise,</span>
<span class="p_del">-it would only have printed the first line, which is just a call to</span>
<span class="p_del">-``memcpy()``, which could be called from a thousand places in the kernel, and</span>
<span class="p_del">-is therefore not very useful.  These inlined functions would not show up in</span>
<span class="p_del">-the stack trace above, simply because the kernel doesn&#39;t load the extra</span>
<span class="p_del">-debugging information. This technique can of course be used with ordinary</span>
<span class="p_del">-kernel oopses as well.</span>
<span class="p_del">-</span>
<span class="p_del">-In this case, it&#39;s the caller of ``memcpy()`` that is interesting, and it can be</span>
<span class="p_del">-found in ``include/asm-generic/siginfo.h``, line 287::</span>
<span class="p_del">-</span>
<span class="p_del">-    281 static inline void copy_siginfo(struct siginfo *to, struct siginfo *from)</span>
<span class="p_del">-    282 {</span>
<span class="p_del">-    283         if (from-&gt;si_code &lt; 0)</span>
<span class="p_del">-    284                 memcpy(to, from, sizeof(*to));</span>
<span class="p_del">-    285         else</span>
<span class="p_del">-    286                 /* _sigchld is currently the largest know union member */</span>
<span class="p_del">-    287                 memcpy(to, from, __ARCH_SI_PREAMBLE_SIZE + sizeof(from-&gt;_sifields._sigchld));</span>
<span class="p_del">-    288 }</span>
<span class="p_del">-</span>
<span class="p_del">-Since this was a read (kmemcheck usually warns about reads only, though it can</span>
<span class="p_del">-warn about writes to unallocated or freed memory as well), it was probably the</span>
<span class="p_del">-&quot;from&quot; argument which contained some uninitialized bytes. Following the chain</span>
<span class="p_del">-of calls, we move upwards to see where &quot;from&quot; was allocated or initialized,</span>
<span class="p_del">-``kernel/signal.c``, line 380::</span>
<span class="p_del">-</span>
<span class="p_del">-    359 static void collect_signal(int sig, struct sigpending *list, siginfo_t *info)</span>
<span class="p_del">-    360 {</span>
<span class="p_del">-    ...</span>
<span class="p_del">-    367         list_for_each_entry(q, &amp;list-&gt;list, list) {</span>
<span class="p_del">-    368                 if (q-&gt;info.si_signo == sig) {</span>
<span class="p_del">-    369                         if (first)</span>
<span class="p_del">-    370                                 goto still_pending;</span>
<span class="p_del">-    371                         first = q;</span>
<span class="p_del">-    ...</span>
<span class="p_del">-    377         if (first) {</span>
<span class="p_del">-    378 still_pending:</span>
<span class="p_del">-    379                 list_del_init(&amp;first-&gt;list);</span>
<span class="p_del">-    380                 copy_siginfo(info, &amp;first-&gt;info);</span>
<span class="p_del">-    381                 __sigqueue_free(first);</span>
<span class="p_del">-    ...</span>
<span class="p_del">-    392         }</span>
<span class="p_del">-    393 }</span>
<span class="p_del">-</span>
<span class="p_del">-Here, it is ``&amp;first-&gt;info`` that is being passed on to ``copy_siginfo()``. The</span>
<span class="p_del">-variable ``first`` was found on a list -- passed in as the second argument to</span>
<span class="p_del">-``collect_signal()``. We  continue our journey through the stack, to figure out</span>
<span class="p_del">-where the item on &quot;list&quot; was allocated or initialized. We move to line 410::</span>
<span class="p_del">-</span>
<span class="p_del">-    395 static int __dequeue_signal(struct sigpending *pending, sigset_t *mask,</span>
<span class="p_del">-    396                         siginfo_t *info)</span>
<span class="p_del">-    397 {</span>
<span class="p_del">-    ...</span>
<span class="p_del">-    410                 collect_signal(sig, pending, info);</span>
<span class="p_del">-    ...</span>
<span class="p_del">-    414 }</span>
<span class="p_del">-</span>
<span class="p_del">-Now we need to follow the ``pending`` pointer, since that is being passed on to</span>
<span class="p_del">-``collect_signal()`` as ``list``. At this point, we&#39;ve run out of lines from the</span>
<span class="p_del">-&quot;addr2line&quot; output. Not to worry, we just paste the next addresses from the</span>
<span class="p_del">-kmemcheck stack dump, i.e.::</span>
<span class="p_del">-</span>
<span class="p_del">-     [&lt;ffffffff8104f04e&gt;] dequeue_signal+0x8e/0x170</span>
<span class="p_del">-     [&lt;ffffffff81050bd8&gt;] get_signal_to_deliver+0x98/0x390</span>
<span class="p_del">-     [&lt;ffffffff8100b87d&gt;] do_notify_resume+0xad/0x7d0</span>
<span class="p_del">-     [&lt;ffffffff8100c7b5&gt;] int_signal+0x12/0x17</span>
<span class="p_del">-</span>
<span class="p_del">-	$ addr2line -e vmlinux -i ffffffff8104f04e ffffffff81050bd8 \</span>
<span class="p_del">-		ffffffff8100b87d ffffffff8100c7b5</span>
<span class="p_del">-	kernel/signal.c:446</span>
<span class="p_del">-	kernel/signal.c:1806</span>
<span class="p_del">-	arch/x86/kernel/signal.c:805</span>
<span class="p_del">-	arch/x86/kernel/signal.c:871</span>
<span class="p_del">-	arch/x86/kernel/entry_64.S:694</span>
<span class="p_del">-</span>
<span class="p_del">-Remember that since these addresses were found on the stack and not as the</span>
<span class="p_del">-RIP value, they actually point to the _next_ instruction (they are return</span>
<span class="p_del">-addresses). This becomes obvious when we look at the code for line 446::</span>
<span class="p_del">-</span>
<span class="p_del">-    422 int dequeue_signal(struct task_struct *tsk, sigset_t *mask, siginfo_t *info)</span>
<span class="p_del">-    423 {</span>
<span class="p_del">-    ...</span>
<span class="p_del">-    431                 signr = __dequeue_signal(&amp;tsk-&gt;signal-&gt;shared_pending,</span>
<span class="p_del">-    432						 mask, info);</span>
<span class="p_del">-    433			/*</span>
<span class="p_del">-    434			 * itimer signal ?</span>
<span class="p_del">-    435			 *</span>
<span class="p_del">-    436			 * itimers are process shared and we restart periodic</span>
<span class="p_del">-    437			 * itimers in the signal delivery path to prevent DoS</span>
<span class="p_del">-    438			 * attacks in the high resolution timer case. This is</span>
<span class="p_del">-    439			 * compliant with the old way of self restarting</span>
<span class="p_del">-    440			 * itimers, as the SIGALRM is a legacy signal and only</span>
<span class="p_del">-    441			 * queued once. Changing the restart behaviour to</span>
<span class="p_del">-    442			 * restart the timer in the signal dequeue path is</span>
<span class="p_del">-    443			 * reducing the timer noise on heavy loaded !highres</span>
<span class="p_del">-    444			 * systems too.</span>
<span class="p_del">-    445			 */</span>
<span class="p_del">-    446			if (unlikely(signr == SIGALRM)) {</span>
<span class="p_del">-    ...</span>
<span class="p_del">-    489 }</span>
<span class="p_del">-</span>
<span class="p_del">-So instead of looking at 446, we should be looking at 431, which is the line</span>
<span class="p_del">-that executes just before 446. Here we see that what we are looking for is</span>
<span class="p_del">-``&amp;tsk-&gt;signal-&gt;shared_pending``.</span>
<span class="p_del">-</span>
<span class="p_del">-Our next task is now to figure out which function that puts items on this</span>
<span class="p_del">-``shared_pending`` list. A crude, but efficient tool, is ``git grep``::</span>
<span class="p_del">-</span>
<span class="p_del">-	$ git grep -n &#39;shared_pending&#39; kernel/</span>
<span class="p_del">-	...</span>
<span class="p_del">-	kernel/signal.c:828:	pending = group ? &amp;t-&gt;signal-&gt;shared_pending : &amp;t-&gt;pending;</span>
<span class="p_del">-	kernel/signal.c:1339:	pending = group ? &amp;t-&gt;signal-&gt;shared_pending : &amp;t-&gt;pending;</span>
<span class="p_del">-	...</span>
<span class="p_del">-</span>
<span class="p_del">-There were more results, but none of them were related to list operations,</span>
<span class="p_del">-and these were the only assignments. We inspect the line numbers more closely</span>
<span class="p_del">-and find that this is indeed where items are being added to the list::</span>
<span class="p_del">-</span>
<span class="p_del">-    816 static int send_signal(int sig, struct siginfo *info, struct task_struct *t,</span>
<span class="p_del">-    817				int group)</span>
<span class="p_del">-    818 {</span>
<span class="p_del">-    ...</span>
<span class="p_del">-    828		pending = group ? &amp;t-&gt;signal-&gt;shared_pending : &amp;t-&gt;pending;</span>
<span class="p_del">-    ...</span>
<span class="p_del">-    851		q = __sigqueue_alloc(t, GFP_ATOMIC, (sig &lt; SIGRTMIN &amp;&amp;</span>
<span class="p_del">-    852						     (is_si_special(info) ||</span>
<span class="p_del">-    853						      info-&gt;si_code &gt;= 0)));</span>
<span class="p_del">-    854		if (q) {</span>
<span class="p_del">-    855			list_add_tail(&amp;q-&gt;list, &amp;pending-&gt;list);</span>
<span class="p_del">-    ...</span>
<span class="p_del">-    890 }</span>
<span class="p_del">-</span>
<span class="p_del">-and::</span>
<span class="p_del">-</span>
<span class="p_del">-    1309 int send_sigqueue(struct sigqueue *q, struct task_struct *t, int group)</span>
<span class="p_del">-    1310 {</span>
<span class="p_del">-    ....</span>
<span class="p_del">-    1339	 pending = group ? &amp;t-&gt;signal-&gt;shared_pending : &amp;t-&gt;pending;</span>
<span class="p_del">-    1340	 list_add_tail(&amp;q-&gt;list, &amp;pending-&gt;list);</span>
<span class="p_del">-    ....</span>
<span class="p_del">-    1347 }</span>
<span class="p_del">-</span>
<span class="p_del">-In the first case, the list element we are looking for, ``q``, is being</span>
<span class="p_del">-returned from the function ``__sigqueue_alloc()``, which looks like an</span>
<span class="p_del">-allocation function.  Let&#39;s take a look at it::</span>
<span class="p_del">-</span>
<span class="p_del">-    187 static struct sigqueue *__sigqueue_alloc(struct task_struct *t, gfp_t flags,</span>
<span class="p_del">-    188						 int override_rlimit)</span>
<span class="p_del">-    189 {</span>
<span class="p_del">-    190		struct sigqueue *q = NULL;</span>
<span class="p_del">-    191		struct user_struct *user;</span>
<span class="p_del">-    192</span>
<span class="p_del">-    193		/*</span>
<span class="p_del">-    194		 * We won&#39;t get problems with the target&#39;s UID changing under us</span>
<span class="p_del">-    195		 * because changing it requires RCU be used, and if t != current, the</span>
<span class="p_del">-    196		 * caller must be holding the RCU readlock (by way of a spinlock) and</span>
<span class="p_del">-    197		 * we use RCU protection here</span>
<span class="p_del">-    198		 */</span>
<span class="p_del">-    199		user = get_uid(__task_cred(t)-&gt;user);</span>
<span class="p_del">-    200		atomic_inc(&amp;user-&gt;sigpending);</span>
<span class="p_del">-    201		if (override_rlimit ||</span>
<span class="p_del">-    202		    atomic_read(&amp;user-&gt;sigpending) &lt;=</span>
<span class="p_del">-    203				t-&gt;signal-&gt;rlim[RLIMIT_SIGPENDING].rlim_cur)</span>
<span class="p_del">-    204			q = kmem_cache_alloc(sigqueue_cachep, flags);</span>
<span class="p_del">-    205		if (unlikely(q == NULL)) {</span>
<span class="p_del">-    206			atomic_dec(&amp;user-&gt;sigpending);</span>
<span class="p_del">-    207			free_uid(user);</span>
<span class="p_del">-    208		} else {</span>
<span class="p_del">-    209			INIT_LIST_HEAD(&amp;q-&gt;list);</span>
<span class="p_del">-    210			q-&gt;flags = 0;</span>
<span class="p_del">-    211			q-&gt;user = user;</span>
<span class="p_del">-    212		}</span>
<span class="p_del">-    213</span>
<span class="p_del">-    214		return q;</span>
<span class="p_del">-    215 }</span>
<span class="p_del">-</span>
<span class="p_del">-We see that this function initializes ``q-&gt;list``, ``q-&gt;flags``, and</span>
<span class="p_del">-``q-&gt;user``. It seems that now is the time to look at the definition of</span>
<span class="p_del">-``struct sigqueue``, e.g.::</span>
<span class="p_del">-</span>
<span class="p_del">-    14 struct sigqueue {</span>
<span class="p_del">-    15	       struct list_head list;</span>
<span class="p_del">-    16	       int flags;</span>
<span class="p_del">-    17	       siginfo_t info;</span>
<span class="p_del">-    18	       struct user_struct *user;</span>
<span class="p_del">-    19 };</span>
<span class="p_del">-</span>
<span class="p_del">-And, you might remember, it was a ``memcpy()`` on ``&amp;first-&gt;info`` that</span>
<span class="p_del">-caused the warning, so this makes perfect sense. It also seems reasonable</span>
<span class="p_del">-to assume that it is the caller of ``__sigqueue_alloc()`` that has the</span>
<span class="p_del">-responsibility of filling out (initializing) this member.</span>
<span class="p_del">-</span>
<span class="p_del">-But just which fields of the struct were uninitialized? Let&#39;s look at</span>
<span class="p_del">-kmemcheck&#39;s report again::</span>
<span class="p_del">-</span>
<span class="p_del">-    WARNING: kmemcheck: Caught 32-bit read from uninitialized memory (ffff88003e4a2024)</span>
<span class="p_del">-    80000000000000000000000000000000000000000088ffff0000000000000000</span>
<span class="p_del">-     i i i i u u u u i i i i i i i i u u u u u u u u u u u u u u u u</span>
<span class="p_del">-	     ^</span>
<span class="p_del">-</span>
<span class="p_del">-These first two lines are the memory dump of the memory object itself, and</span>
<span class="p_del">-the shadow bytemap, respectively. The memory object itself is in this case</span>
<span class="p_del">-``&amp;first-&gt;info``. Just beware that the start of this dump is NOT the start</span>
<span class="p_del">-of the object itself! The position of the caret (^) corresponds with the</span>
<span class="p_del">-address of the read (ffff88003e4a2024).</span>
<span class="p_del">-</span>
<span class="p_del">-The shadow bytemap dump legend is as follows:</span>
<span class="p_del">-</span>
<span class="p_del">-- i: initialized</span>
<span class="p_del">-- u: uninitialized</span>
<span class="p_del">-- a: unallocated (memory has been allocated by the slab layer, but has not</span>
<span class="p_del">-  yet been handed off to anybody)</span>
<span class="p_del">-- f: freed (memory has been allocated by the slab layer, but has been freed</span>
<span class="p_del">-  by the previous owner)</span>
<span class="p_del">-</span>
<span class="p_del">-In order to figure out where (relative to the start of the object) the</span>
<span class="p_del">-uninitialized memory was located, we have to look at the disassembly. For</span>
<span class="p_del">-that, we&#39;ll need the RIP address again::</span>
<span class="p_del">-</span>
<span class="p_del">-    RIP: 0010:[&lt;ffffffff8104ede8&gt;]  [&lt;ffffffff8104ede8&gt;] __dequeue_signal+0xc8/0x190</span>
<span class="p_del">-</span>
<span class="p_del">-	$ objdump -d --no-show-raw-insn vmlinux | grep -C 8 ffffffff8104ede8:</span>
<span class="p_del">-	ffffffff8104edc8:	mov    %r8,0x8(%r8)</span>
<span class="p_del">-	ffffffff8104edcc:	test   %r10d,%r10d</span>
<span class="p_del">-	ffffffff8104edcf:	js     ffffffff8104ee88 &lt;__dequeue_signal+0x168&gt;</span>
<span class="p_del">-	ffffffff8104edd5:	mov    %rax,%rdx</span>
<span class="p_del">-	ffffffff8104edd8:	mov    $0xc,%ecx</span>
<span class="p_del">-	ffffffff8104eddd:	mov    %r13,%rdi</span>
<span class="p_del">-	ffffffff8104ede0:	mov    $0x30,%eax</span>
<span class="p_del">-	ffffffff8104ede5:	mov    %rdx,%rsi</span>
<span class="p_del">-	ffffffff8104ede8:	rep movsl %ds:(%rsi),%es:(%rdi)</span>
<span class="p_del">-	ffffffff8104edea:	test   $0x2,%al</span>
<span class="p_del">-	ffffffff8104edec:	je     ffffffff8104edf0 &lt;__dequeue_signal+0xd0&gt;</span>
<span class="p_del">-	ffffffff8104edee:	movsw  %ds:(%rsi),%es:(%rdi)</span>
<span class="p_del">-	ffffffff8104edf0:	test   $0x1,%al</span>
<span class="p_del">-	ffffffff8104edf2:	je     ffffffff8104edf5 &lt;__dequeue_signal+0xd5&gt;</span>
<span class="p_del">-	ffffffff8104edf4:	movsb  %ds:(%rsi),%es:(%rdi)</span>
<span class="p_del">-	ffffffff8104edf5:	mov    %r8,%rdi</span>
<span class="p_del">-	ffffffff8104edf8:	callq  ffffffff8104de60 &lt;__sigqueue_free&gt;</span>
<span class="p_del">-</span>
<span class="p_del">-As expected, it&#39;s the &quot;``rep movsl``&quot; instruction from the ``memcpy()``</span>
<span class="p_del">-that causes the warning. We know about ``REP MOVSL`` that it uses the register</span>
<span class="p_del">-``RCX`` to count the number of remaining iterations. By taking a look at the</span>
<span class="p_del">-register dump again (from the kmemcheck report), we can figure out how many</span>
<span class="p_del">-bytes were left to copy::</span>
<span class="p_del">-</span>
<span class="p_del">-    RAX: 0000000000000030 RBX: ffff88003d4ea968 RCX: 0000000000000009</span>
<span class="p_del">-</span>
<span class="p_del">-By looking at the disassembly, we also see that ``%ecx`` is being loaded</span>
<span class="p_del">-with the value ``$0xc`` just before (ffffffff8104edd8), so we are very</span>
<span class="p_del">-lucky. Keep in mind that this is the number of iterations, not bytes. And</span>
<span class="p_del">-since this is a &quot;long&quot; operation, we need to multiply by 4 to get the</span>
<span class="p_del">-number of bytes. So this means that the uninitialized value was encountered</span>
<span class="p_del">-at 4 * (0xc - 0x9) = 12 bytes from the start of the object.</span>
<span class="p_del">-</span>
<span class="p_del">-We can now try to figure out which field of the &quot;``struct siginfo``&quot; that</span>
<span class="p_del">-was not initialized. This is the beginning of the struct::</span>
<span class="p_del">-</span>
<span class="p_del">-    40 typedef struct siginfo {</span>
<span class="p_del">-    41	       int si_signo;</span>
<span class="p_del">-    42	       int si_errno;</span>
<span class="p_del">-    43	       int si_code;</span>
<span class="p_del">-    44</span>
<span class="p_del">-    45	       union {</span>
<span class="p_del">-    ..</span>
<span class="p_del">-    92	       } _sifields;</span>
<span class="p_del">-    93 } siginfo_t;</span>
<span class="p_del">-</span>
<span class="p_del">-On 64-bit, the int is 4 bytes long, so it must the union member that has</span>
<span class="p_del">-not been initialized. We can verify this using gdb::</span>
<span class="p_del">-</span>
<span class="p_del">-	$ gdb vmlinux</span>
<span class="p_del">-	...</span>
<span class="p_del">-	(gdb) p &amp;((struct siginfo *) 0)-&gt;_sifields</span>
<span class="p_del">-	$1 = (union {...} *) 0x10</span>
<span class="p_del">-</span>
<span class="p_del">-Actually, it seems that the union member is located at offset 0x10 -- which</span>
<span class="p_del">-means that gcc has inserted 4 bytes of padding between the members ``si_code``</span>
<span class="p_del">-and ``_sifields``. We can now get a fuller picture of the memory dump::</span>
<span class="p_del">-</span>
<span class="p_del">-		 _----------------------------=&gt; si_code</span>
<span class="p_del">-		/	 _--------------------=&gt; (padding)</span>
<span class="p_del">-	       |	/	 _------------=&gt; _sifields(._kill._pid)</span>
<span class="p_del">-	       |       |	/	 _----=&gt; _sifields(._kill._uid)</span>
<span class="p_del">-	       |       |       |	/</span>
<span class="p_del">-	-------|-------|-------|-------|</span>
<span class="p_del">-	80000000000000000000000000000000000000000088ffff0000000000000000</span>
<span class="p_del">-	 i i i i u u u u i i i i i i i i u u u u u u u u u u u u u u u u</span>
<span class="p_del">-</span>
<span class="p_del">-This allows us to realize another important fact: ``si_code`` contains the</span>
<span class="p_del">-value 0x80. Remember that x86 is little endian, so the first 4 bytes</span>
<span class="p_del">-&quot;80000000&quot; are really the number 0x00000080. With a bit of research, we</span>
<span class="p_del">-find that this is actually the constant ``SI_KERNEL`` defined in</span>
<span class="p_del">-``include/asm-generic/siginfo.h``::</span>
<span class="p_del">-</span>
<span class="p_del">-    144 #define SI_KERNEL	0x80		/* sent by the kernel from somewhere	 */</span>
<span class="p_del">-</span>
<span class="p_del">-This macro is used in exactly one place in the x86 kernel: In ``send_signal()``</span>
<span class="p_del">-in ``kernel/signal.c``::</span>
<span class="p_del">-</span>
<span class="p_del">-    816 static int send_signal(int sig, struct siginfo *info, struct task_struct *t,</span>
<span class="p_del">-    817				int group)</span>
<span class="p_del">-    818 {</span>
<span class="p_del">-    ...</span>
<span class="p_del">-    828		pending = group ? &amp;t-&gt;signal-&gt;shared_pending : &amp;t-&gt;pending;</span>
<span class="p_del">-    ...</span>
<span class="p_del">-    851		q = __sigqueue_alloc(t, GFP_ATOMIC, (sig &lt; SIGRTMIN &amp;&amp;</span>
<span class="p_del">-    852						     (is_si_special(info) ||</span>
<span class="p_del">-    853						      info-&gt;si_code &gt;= 0)));</span>
<span class="p_del">-    854		if (q) {</span>
<span class="p_del">-    855			list_add_tail(&amp;q-&gt;list, &amp;pending-&gt;list);</span>
<span class="p_del">-    856			switch ((unsigned long) info) {</span>
<span class="p_del">-    ...</span>
<span class="p_del">-    865			case (unsigned long) SEND_SIG_PRIV:</span>
<span class="p_del">-    866				q-&gt;info.si_signo = sig;</span>
<span class="p_del">-    867				q-&gt;info.si_errno = 0;</span>
<span class="p_del">-    868				q-&gt;info.si_code = SI_KERNEL;</span>
<span class="p_del">-    869				q-&gt;info.si_pid = 0;</span>
<span class="p_del">-    870				q-&gt;info.si_uid = 0;</span>
<span class="p_del">-    871				break;</span>
<span class="p_del">-    ...</span>
<span class="p_del">-    890 }</span>
<span class="p_del">-</span>
<span class="p_del">-Not only does this match with the ``.si_code`` member, it also matches the place</span>
<span class="p_del">-we found earlier when looking for where siginfo_t objects are enqueued on the</span>
<span class="p_del">-``shared_pending`` list.</span>
<span class="p_del">-</span>
<span class="p_del">-So to sum up: It seems that it is the padding introduced by the compiler</span>
<span class="p_del">-between two struct fields that is uninitialized, and this gets reported when</span>
<span class="p_del">-we do a ``memcpy()`` on the struct. This means that we have identified a false</span>
<span class="p_del">-positive warning.</span>
<span class="p_del">-</span>
<span class="p_del">-Normally, kmemcheck will not report uninitialized accesses in ``memcpy()`` calls</span>
<span class="p_del">-when both the source and destination addresses are tracked. (Instead, we copy</span>
<span class="p_del">-the shadow bytemap as well). In this case, the destination address clearly</span>
<span class="p_del">-was not tracked. We can dig a little deeper into the stack trace from above::</span>
<span class="p_del">-</span>
<span class="p_del">-	arch/x86/kernel/signal.c:805</span>
<span class="p_del">-	arch/x86/kernel/signal.c:871</span>
<span class="p_del">-	arch/x86/kernel/entry_64.S:694</span>
<span class="p_del">-</span>
<span class="p_del">-And we clearly see that the destination siginfo object is located on the</span>
<span class="p_del">-stack::</span>
<span class="p_del">-</span>
<span class="p_del">-    782 static void do_signal(struct pt_regs *regs)</span>
<span class="p_del">-    783 {</span>
<span class="p_del">-    784		struct k_sigaction ka;</span>
<span class="p_del">-    785		siginfo_t info;</span>
<span class="p_del">-    ...</span>
<span class="p_del">-    804		signr = get_signal_to_deliver(&amp;info, &amp;ka, regs, NULL);</span>
<span class="p_del">-    ...</span>
<span class="p_del">-    854 }</span>
<span class="p_del">-</span>
<span class="p_del">-And this ``&amp;info`` is what eventually gets passed to ``copy_siginfo()`` as the</span>
<span class="p_del">-destination argument.</span>
<span class="p_del">-</span>
<span class="p_del">-Now, even though we didn&#39;t find an actual error here, the example is still a</span>
<span class="p_del">-good one, because it shows how one would go about to find out what the report</span>
<span class="p_del">-was all about.</span>
<span class="p_del">-</span>
<span class="p_del">-</span>
<span class="p_del">-Annotating false positives</span>
<span class="p_del">-~~~~~~~~~~~~~~~~~~~~~~~~~~</span>
<span class="p_del">-</span>
<span class="p_del">-There are a few different ways to make annotations in the source code that</span>
<span class="p_del">-will keep kmemcheck from checking and reporting certain allocations. Here</span>
<span class="p_del">-they are:</span>
<span class="p_del">-</span>
<span class="p_del">-- ``__GFP_NOTRACK_FALSE_POSITIVE``</span>
<span class="p_del">-	This flag can be passed to ``kmalloc()`` or ``kmem_cache_alloc()``</span>
<span class="p_del">-	(therefore also to other functions that end up calling one of</span>
<span class="p_del">-	these) to indicate that the allocation should not be tracked</span>
<span class="p_del">-	because it would lead to a false positive report. This is a &quot;big</span>
<span class="p_del">-	hammer&quot; way of silencing kmemcheck; after all, even if the false</span>
<span class="p_del">-	positive pertains to particular field in a struct, for example, we</span>
<span class="p_del">-	will now lose the ability to find (real) errors in other parts of</span>
<span class="p_del">-	the same struct.</span>
<span class="p_del">-</span>
<span class="p_del">-	Example::</span>
<span class="p_del">-</span>
<span class="p_del">-	    /* No warnings will ever trigger on accessing any part of x */</span>
<span class="p_del">-	    x = kmalloc(sizeof *x, GFP_KERNEL | __GFP_NOTRACK_FALSE_POSITIVE);</span>
<span class="p_del">-</span>
<span class="p_del">-- ``kmemcheck_bitfield_begin(name)``/``kmemcheck_bitfield_end(name)`` and</span>
<span class="p_del">-	``kmemcheck_annotate_bitfield(ptr, name)``</span>
<span class="p_del">-	The first two of these three macros can be used inside struct</span>
<span class="p_del">-	definitions to signal, respectively, the beginning and end of a</span>
<span class="p_del">-	bitfield. Additionally, this will assign the bitfield a name, which</span>
<span class="p_del">-	is given as an argument to the macros.</span>
<span class="p_del">-</span>
<span class="p_del">-	Having used these markers, one can later use</span>
<span class="p_del">-	kmemcheck_annotate_bitfield() at the point of allocation, to indicate</span>
<span class="p_del">-	which parts of the allocation is part of a bitfield.</span>
<span class="p_del">-</span>
<span class="p_del">-	Example::</span>
<span class="p_del">-</span>
<span class="p_del">-	    struct foo {</span>
<span class="p_del">-		int x;</span>
<span class="p_del">-</span>
<span class="p_del">-		kmemcheck_bitfield_begin(flags);</span>
<span class="p_del">-		int flag_a:1;</span>
<span class="p_del">-		int flag_b:1;</span>
<span class="p_del">-		kmemcheck_bitfield_end(flags);</span>
<span class="p_del">-</span>
<span class="p_del">-		int y;</span>
<span class="p_del">-	    };</span>
<span class="p_del">-</span>
<span class="p_del">-	    struct foo *x = kmalloc(sizeof *x);</span>
<span class="p_del">-</span>
<span class="p_del">-	    /* No warnings will trigger on accessing the bitfield of x */</span>
<span class="p_del">-	    kmemcheck_annotate_bitfield(x, flags);</span>
<span class="p_del">-</span>
<span class="p_del">-	Note that ``kmemcheck_annotate_bitfield()`` can be used even before the</span>
<span class="p_del">-	return value of ``kmalloc()`` is checked -- in other words, passing NULL</span>
<span class="p_del">-	as the first argument is legal (and will do nothing).</span>
<span class="p_del">-</span>
<span class="p_del">-</span>
<span class="p_del">-Reporting errors</span>
<span class="p_del">-----------------</span>
<span class="p_del">-</span>
<span class="p_del">-As we have seen, kmemcheck will produce false positive reports. Therefore, it</span>
<span class="p_del">-is not very wise to blindly post kmemcheck warnings to mailing lists and</span>
<span class="p_del">-maintainers. Instead, I encourage maintainers and developers to find errors</span>
<span class="p_del">-in their own code. If you get a warning, you can try to work around it, try</span>
<span class="p_del">-to figure out if it&#39;s a real error or not, or simply ignore it. Most</span>
<span class="p_del">-developers know their own code and will quickly and efficiently determine the</span>
<span class="p_del">-root cause of a kmemcheck report. This is therefore also the most efficient</span>
<span class="p_del">-way to work with kmemcheck.</span>
<span class="p_del">-</span>
<span class="p_del">-That said, we (the kmemcheck maintainers) will always be on the lookout for</span>
<span class="p_del">-false positives that we can annotate and silence. So whatever you find,</span>
<span class="p_del">-please drop us a note privately! Kernel configs and steps to reproduce (if</span>
<span class="p_del">-available) are of course a great help too.</span>
<span class="p_del">-</span>
<span class="p_del">-Happy hacking!</span>
<span class="p_del">-</span>
<span class="p_del">-</span>
<span class="p_del">-Technical description</span>
<span class="p_del">----------------------</span>
<span class="p_del">-</span>
<span class="p_del">-kmemcheck works by marking memory pages non-present. This means that whenever</span>
<span class="p_del">-somebody attempts to access the page, a page fault is generated. The page</span>
<span class="p_del">-fault handler notices that the page was in fact only hidden, and so it calls</span>
<span class="p_del">-on the kmemcheck code to make further investigations.</span>
<span class="p_del">-</span>
<span class="p_del">-When the investigations are completed, kmemcheck &quot;shows&quot; the page by marking</span>
<span class="p_del">-it present (as it would be under normal circumstances). This way, the</span>
<span class="p_del">-interrupted code can continue as usual.</span>
<span class="p_del">-</span>
<span class="p_del">-But after the instruction has been executed, we should hide the page again, so</span>
<span class="p_del">-that we can catch the next access too! Now kmemcheck makes use of a debugging</span>
<span class="p_del">-feature of the processor, namely single-stepping. When the processor has</span>
<span class="p_del">-finished the one instruction that generated the memory access, a debug</span>
<span class="p_del">-exception is raised. From here, we simply hide the page again and continue</span>
<span class="p_del">-execution, this time with the single-stepping feature turned off.</span>
<span class="p_del">-</span>
<span class="p_del">-kmemcheck requires some assistance from the memory allocator in order to work.</span>
<span class="p_del">-The memory allocator needs to</span>
<span class="p_del">-</span>
<span class="p_del">-  1. Tell kmemcheck about newly allocated pages and pages that are about to</span>
<span class="p_del">-     be freed. This allows kmemcheck to set up and tear down the shadow memory</span>
<span class="p_del">-     for the pages in question. The shadow memory stores the status of each</span>
<span class="p_del">-     byte in the allocation proper, e.g. whether it is initialized or</span>
<span class="p_del">-     uninitialized.</span>
<span class="p_del">-</span>
<span class="p_del">-  2. Tell kmemcheck which parts of memory should be marked uninitialized.</span>
<span class="p_del">-     There are actually a few more states, such as &quot;not yet allocated&quot; and</span>
<span class="p_del">-     &quot;recently freed&quot;.</span>
<span class="p_del">-</span>
<span class="p_del">-If a slab cache is set up using the SLAB_NOTRACK flag, it will never return</span>
<span class="p_del">-memory that can take page faults because of kmemcheck.</span>
<span class="p_del">-</span>
<span class="p_del">-If a slab cache is NOT set up using the SLAB_NOTRACK flag, callers can still</span>
<span class="p_del">-request memory with the __GFP_NOTRACK or __GFP_NOTRACK_FALSE_POSITIVE flags.</span>
<span class="p_del">-This does not prevent the page faults from occurring, however, but marks the</span>
<span class="p_del">-object in question as being initialized so that no warnings will ever be</span>
<span class="p_del">-produced for this object.</span>
<span class="p_del">-</span>
<span class="p_del">-Currently, the SLAB and SLUB allocators are supported by kmemcheck.</span>
<span class="p_header">diff --git a/MAINTAINERS b/MAINTAINERS</span>
<span class="p_header">index 38d3e4ed7208..b3b7a8c99567 100644</span>
<span class="p_header">--- a/MAINTAINERS</span>
<span class="p_header">+++ b/MAINTAINERS</span>
<span class="p_chunk">@@ -7285,16 +7285,6 @@</span> <span class="p_context"> F:	include/linux/kdb.h</span>
 F:	include/linux/kgdb.h
 F:	kernel/debug/
 
<span class="p_del">-KMEMCHECK</span>
<span class="p_del">-M:	Vegard Nossum &lt;vegardno@ifi.uio.no&gt;</span>
<span class="p_del">-M:	Pekka Enberg &lt;penberg@kernel.org&gt;</span>
<span class="p_del">-S:	Maintained</span>
<span class="p_del">-F:	Documentation/dev-tools/kmemcheck.rst</span>
<span class="p_del">-F:	arch/x86/include/asm/kmemcheck.h</span>
<span class="p_del">-F:	arch/x86/mm/kmemcheck/</span>
<span class="p_del">-F:	include/linux/kmemcheck.h</span>
<span class="p_del">-F:	mm/kmemcheck.c</span>
<span class="p_del">-</span>
 KMEMLEAK
 M:	Catalin Marinas &lt;catalin.marinas@arm.com&gt;
 S:	Maintained
<span class="p_header">diff --git a/arch/arm/include/asm/dma-iommu.h b/arch/arm/include/asm/dma-iommu.h</span>
<span class="p_header">index 2ef282f96651..1a6a870b8fd6 100644</span>
<span class="p_header">--- a/arch/arm/include/asm/dma-iommu.h</span>
<span class="p_header">+++ b/arch/arm/include/asm/dma-iommu.h</span>
<span class="p_chunk">@@ -6,7 +6,6 @@</span> <span class="p_context"></span>
 #include &lt;linux/mm_types.h&gt;
 #include &lt;linux/scatterlist.h&gt;
 #include &lt;linux/dma-debug.h&gt;
<span class="p_del">-#include &lt;linux/kmemcheck.h&gt;</span>
 #include &lt;linux/kref.h&gt;
 
 struct dma_iommu_mapping {
<span class="p_header">diff --git a/arch/openrisc/include/asm/dma-mapping.h b/arch/openrisc/include/asm/dma-mapping.h</span>
<span class="p_header">index 0c0075f17145..f18899b9993d 100644</span>
<span class="p_header">--- a/arch/openrisc/include/asm/dma-mapping.h</span>
<span class="p_header">+++ b/arch/openrisc/include/asm/dma-mapping.h</span>
<span class="p_chunk">@@ -23,7 +23,6 @@</span> <span class="p_context"></span>
  */
 
 #include &lt;linux/dma-debug.h&gt;
<span class="p_del">-#include &lt;linux/kmemcheck.h&gt;</span>
 #include &lt;linux/dma-mapping.h&gt;
 
 #define DMA_ERROR_CODE		(~(dma_addr_t)0x0)
<span class="p_header">diff --git a/arch/x86/Kconfig b/arch/x86/Kconfig</span>
<span class="p_header">index cc98d5a294ee..cc155b9175bc 100644</span>
<span class="p_header">--- a/arch/x86/Kconfig</span>
<span class="p_header">+++ b/arch/x86/Kconfig</span>
<span class="p_chunk">@@ -103,7 +103,6 @@</span> <span class="p_context"> config X86</span>
 	select HAVE_ARCH_JUMP_LABEL
 	select HAVE_ARCH_KASAN			if X86_64 &amp;&amp; SPARSEMEM_VMEMMAP
 	select HAVE_ARCH_KGDB
<span class="p_del">-	select HAVE_ARCH_KMEMCHECK</span>
 	select HAVE_ARCH_MMAP_RND_BITS		if MMU
 	select HAVE_ARCH_MMAP_RND_COMPAT_BITS	if MMU &amp;&amp; COMPAT
 	select HAVE_ARCH_SECCOMP_FILTER
<span class="p_chunk">@@ -1390,7 +1389,7 @@</span> <span class="p_context"> config ARCH_DMA_ADDR_T_64BIT</span>
 
 config X86_DIRECT_GBPAGES
 	def_bool y
<span class="p_del">-	depends on X86_64 &amp;&amp; !DEBUG_PAGEALLOC &amp;&amp; !KMEMCHECK</span>
<span class="p_add">+	depends on X86_64 &amp;&amp; !DEBUG_PAGEALLOC</span>
 	---help---
 	  Certain kernel features effectively disable kernel
 	  linear 1 GB mappings (even if the CPU otherwise
<span class="p_header">diff --git a/arch/x86/Makefile b/arch/x86/Makefile</span>
<span class="p_header">index 49d160b781f0..d7926124378d 100644</span>
<span class="p_header">--- a/arch/x86/Makefile</span>
<span class="p_header">+++ b/arch/x86/Makefile</span>
<span class="p_chunk">@@ -138,11 +138,6 @@</span> <span class="p_context"> ifdef CONFIG_X86_X32</span>
 endif
 export CONFIG_X86_X32_ABI
 
<span class="p_del">-# Don&#39;t unroll struct assignments with kmemcheck enabled</span>
<span class="p_del">-ifeq ($(CONFIG_KMEMCHECK),y)</span>
<span class="p_del">-	KBUILD_CFLAGS += $(call cc-option,-fno-builtin-memcpy)</span>
<span class="p_del">-endif</span>
<span class="p_del">-</span>
 #
 # If the function graph tracer is used with mcount instead of fentry,
 # &#39;-maccumulate-outgoing-args&#39; is needed to prevent a GCC bug
<span class="p_header">diff --git a/arch/x86/include/asm/dma-mapping.h b/arch/x86/include/asm/dma-mapping.h</span>
<span class="p_header">index 08a0838b83fb..c6558462953a 100644</span>
<span class="p_header">--- a/arch/x86/include/asm/dma-mapping.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/dma-mapping.h</span>
<span class="p_chunk">@@ -6,7 +6,6 @@</span> <span class="p_context"></span>
  * Documentation/DMA-API.txt for documentation.
  */
 
<span class="p_del">-#include &lt;linux/kmemcheck.h&gt;</span>
 #include &lt;linux/scatterlist.h&gt;
 #include &lt;linux/dma-debug.h&gt;
 #include &lt;asm/io.h&gt;
<span class="p_header">diff --git a/arch/x86/include/asm/kmemcheck.h b/arch/x86/include/asm/kmemcheck.h</span>
deleted file mode 100644
<span class="p_header">index ed01518f297e..000000000000</span>
<span class="p_header">--- a/arch/x86/include/asm/kmemcheck.h</span>
<span class="p_header">+++ /dev/null</span>
<span class="p_chunk">@@ -1,42 +0,0 @@</span> <span class="p_context"></span>
<span class="p_del">-#ifndef ASM_X86_KMEMCHECK_H</span>
<span class="p_del">-#define ASM_X86_KMEMCHECK_H</span>
<span class="p_del">-</span>
<span class="p_del">-#include &lt;linux/types.h&gt;</span>
<span class="p_del">-#include &lt;asm/ptrace.h&gt;</span>
<span class="p_del">-</span>
<span class="p_del">-#ifdef CONFIG_KMEMCHECK</span>
<span class="p_del">-bool kmemcheck_active(struct pt_regs *regs);</span>
<span class="p_del">-</span>
<span class="p_del">-void kmemcheck_show(struct pt_regs *regs);</span>
<span class="p_del">-void kmemcheck_hide(struct pt_regs *regs);</span>
<span class="p_del">-</span>
<span class="p_del">-bool kmemcheck_fault(struct pt_regs *regs,</span>
<span class="p_del">-	unsigned long address, unsigned long error_code);</span>
<span class="p_del">-bool kmemcheck_trap(struct pt_regs *regs);</span>
<span class="p_del">-#else</span>
<span class="p_del">-static inline bool kmemcheck_active(struct pt_regs *regs)</span>
<span class="p_del">-{</span>
<span class="p_del">-	return false;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static inline void kmemcheck_show(struct pt_regs *regs)</span>
<span class="p_del">-{</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static inline void kmemcheck_hide(struct pt_regs *regs)</span>
<span class="p_del">-{</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static inline bool kmemcheck_fault(struct pt_regs *regs,</span>
<span class="p_del">-	unsigned long address, unsigned long error_code)</span>
<span class="p_del">-{</span>
<span class="p_del">-	return false;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static inline bool kmemcheck_trap(struct pt_regs *regs)</span>
<span class="p_del">-{</span>
<span class="p_del">-	return false;</span>
<span class="p_del">-}</span>
<span class="p_del">-#endif /* CONFIG_KMEMCHECK */</span>
<span class="p_del">-</span>
<span class="p_del">-#endif</span>
<span class="p_header">diff --git a/arch/x86/include/asm/pgtable_types.h b/arch/x86/include/asm/pgtable_types.h</span>
<span class="p_header">index 62484333673d..baf03bc24c4e 100644</span>
<span class="p_header">--- a/arch/x86/include/asm/pgtable_types.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/pgtable_types.h</span>
<span class="p_chunk">@@ -76,11 +76,11 @@</span> <span class="p_context"></span>
 #define _PAGE_KNL_ERRATUM_MASK 0
 #endif
 
<span class="p_del">-#ifdef CONFIG_KMEMCHECK</span>
<span class="p_del">-#define _PAGE_HIDDEN	(_AT(pteval_t, 1) &lt;&lt; _PAGE_BIT_HIDDEN)</span>
<span class="p_del">-#else</span>
<span class="p_add">+/*</span>
<span class="p_add">+ * Used by kmemcheck in the past; obsolete, but kept for the sake of</span>
<span class="p_add">+ * out-of-tree module source backwards compatibility.</span>
<span class="p_add">+ */</span>
 #define _PAGE_HIDDEN	(_AT(pteval_t, 0))
<span class="p_del">-#endif</span>
 
 /*
  * The same hidden bit is used by kmemcheck, but since kmemcheck
<span class="p_header">diff --git a/arch/x86/include/asm/string_32.h b/arch/x86/include/asm/string_32.h</span>
<span class="p_header">index 3d3e8353ee5c..8a4f6fa41d07 100644</span>
<span class="p_header">--- a/arch/x86/include/asm/string_32.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/string_32.h</span>
<span class="p_chunk">@@ -176,8 +176,6 @@</span> <span class="p_context"> static inline void *__memcpy3d(void *to, const void *from, size_t len)</span>
  *	No 3D Now!
  */
 
<span class="p_del">-#ifndef CONFIG_KMEMCHECK</span>
<span class="p_del">-</span>
 #if (__GNUC__ &gt;= 4)
 #define memcpy(t, f, n) __builtin_memcpy(t, f, n)
 #else
<span class="p_chunk">@@ -186,13 +184,6 @@</span> <span class="p_context"> static inline void *__memcpy3d(void *to, const void *from, size_t len)</span>
 	 ? __constant_memcpy((t), (f), (n))	\
 	 : __memcpy((t), (f), (n)))
 #endif
<span class="p_del">-#else</span>
<span class="p_del">-/*</span>
<span class="p_del">- * kmemcheck becomes very happy if we use the REP instructions unconditionally,</span>
<span class="p_del">- * because it means that we know both memory operands in advance.</span>
<span class="p_del">- */</span>
<span class="p_del">-#define memcpy(t, f, n) __memcpy((t), (f), (n))</span>
<span class="p_del">-#endif</span>
 
 #endif
 
<span class="p_header">diff --git a/arch/x86/include/asm/string_64.h b/arch/x86/include/asm/string_64.h</span>
<span class="p_header">index a164862d77e3..709f41c0a461 100644</span>
<span class="p_header">--- a/arch/x86/include/asm/string_64.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/string_64.h</span>
<span class="p_chunk">@@ -31,7 +31,6 @@</span> <span class="p_context"> static __always_inline void *__inline_memcpy(void *to, const void *from, size_t</span>
 extern void *memcpy(void *to, const void *from, size_t len);
 extern void *__memcpy(void *to, const void *from, size_t len);
 
<span class="p_del">-#ifndef CONFIG_KMEMCHECK</span>
 #if (__GNUC__ == 4 &amp;&amp; __GNUC_MINOR__ &lt; 3) || __GNUC__ &lt; 4
 #define memcpy(dst, src, len)					\
 ({								\
<span class="p_chunk">@@ -44,13 +43,6 @@</span> <span class="p_context"> extern void *__memcpy(void *to, const void *from, size_t len);</span>
 	__ret;							\
 })
 #endif
<span class="p_del">-#else</span>
<span class="p_del">-/*</span>
<span class="p_del">- * kmemcheck becomes very happy if we use the REP instructions unconditionally,</span>
<span class="p_del">- * because it means that we know both memory operands in advance.</span>
<span class="p_del">- */</span>
<span class="p_del">-#define memcpy(dst, src, len) __inline_memcpy((dst), (src), (len))</span>
<span class="p_del">-#endif</span>
 
 #define __HAVE_ARCH_MEMSET
 void *memset(void *s, int c, size_t n);
<span class="p_header">diff --git a/arch/x86/include/asm/xor.h b/arch/x86/include/asm/xor.h</span>
<span class="p_header">index 1f5c5161ead6..45c8605467f1 100644</span>
<span class="p_header">--- a/arch/x86/include/asm/xor.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/xor.h</span>
<span class="p_chunk">@@ -1,7 +1,4 @@</span> <span class="p_context"></span>
<span class="p_del">-#ifdef CONFIG_KMEMCHECK</span>
<span class="p_del">-/* kmemcheck doesn&#39;t handle MMX/SSE/SSE2 instructions */</span>
<span class="p_del">-# include &lt;asm-generic/xor.h&gt;</span>
<span class="p_del">-#elif !defined(_ASM_X86_XOR_H)</span>
<span class="p_add">+#ifndef _ASM_X86_XOR_H</span>
 #define _ASM_X86_XOR_H
 
 /*
<span class="p_header">diff --git a/arch/x86/kernel/cpu/intel.c b/arch/x86/kernel/cpu/intel.c</span>
<span class="p_header">index 063197771b8d..4ab65638170f 100644</span>
<span class="p_header">--- a/arch/x86/kernel/cpu/intel.c</span>
<span class="p_header">+++ b/arch/x86/kernel/cpu/intel.c</span>
<span class="p_chunk">@@ -190,21 +190,6 @@</span> <span class="p_context"> static void early_init_intel(struct cpuinfo_x86 *c)</span>
 	if (c-&gt;x86 == 6 &amp;&amp; c-&gt;x86_model &lt; 15)
 		clear_cpu_cap(c, X86_FEATURE_PAT);
 
<span class="p_del">-#ifdef CONFIG_KMEMCHECK</span>
<span class="p_del">-	/*</span>
<span class="p_del">-	 * P4s have a &quot;fast strings&quot; feature which causes single-</span>
<span class="p_del">-	 * stepping REP instructions to only generate a #DB on</span>
<span class="p_del">-	 * cache-line boundaries.</span>
<span class="p_del">-	 *</span>
<span class="p_del">-	 * Ingo Molnar reported a Pentium D (model 6) and a Xeon</span>
<span class="p_del">-	 * (model 2) with the same problem.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	if (c-&gt;x86 == 15)</span>
<span class="p_del">-		if (msr_clear_bit(MSR_IA32_MISC_ENABLE,</span>
<span class="p_del">-				  MSR_IA32_MISC_ENABLE_FAST_STRING_BIT) &gt; 0)</span>
<span class="p_del">-			pr_info(&quot;kmemcheck: Disabling fast string operations\n&quot;);</span>
<span class="p_del">-#endif</span>
<span class="p_del">-</span>
 	/*
 	 * If fast string is not enabled in IA32_MISC_ENABLE for any reason,
 	 * clear the fast string and enhanced fast string CPU capabilities.
<span class="p_header">diff --git a/arch/x86/kernel/traps.c b/arch/x86/kernel/traps.c</span>
<span class="p_header">index 4e496379a871..d7007257ae72 100644</span>
<span class="p_header">--- a/arch/x86/kernel/traps.c</span>
<span class="p_header">+++ b/arch/x86/kernel/traps.c</span>
<span class="p_chunk">@@ -47,7 +47,6 @@</span> <span class="p_context"></span>
 #include &lt;linux/edac.h&gt;
 #endif
 
<span class="p_del">-#include &lt;asm/kmemcheck.h&gt;</span>
 #include &lt;asm/stacktrace.h&gt;
 #include &lt;asm/processor.h&gt;
 #include &lt;asm/debugreg.h&gt;
<span class="p_chunk">@@ -718,10 +717,6 @@</span> <span class="p_context"> dotraplinkage void do_debug(struct pt_regs *regs, long error_code)</span>
 	if (!dr6 &amp;&amp; user_mode(regs))
 		user_icebp = 1;
 
<span class="p_del">-	/* Catch kmemcheck conditions! */</span>
<span class="p_del">-	if ((dr6 &amp; DR_STEP) &amp;&amp; kmemcheck_trap(regs))</span>
<span class="p_del">-		goto exit;</span>
<span class="p_del">-</span>
 	/* Store the virtualized DR6 value */
 	tsk-&gt;thread.debugreg6 = dr6;
 
<span class="p_header">diff --git a/arch/x86/mm/Makefile b/arch/x86/mm/Makefile</span>
<span class="p_header">index 96d2b847e09e..b90fdfb79201 100644</span>
<span class="p_header">--- a/arch/x86/mm/Makefile</span>
<span class="p_header">+++ b/arch/x86/mm/Makefile</span>
<span class="p_chunk">@@ -21,8 +21,6 @@</span> <span class="p_context"> obj-$(CONFIG_X86_PTDUMP)	+= debug_pagetables.o</span>
 
 obj-$(CONFIG_HIGHMEM)		+= highmem_32.o
 
<span class="p_del">-obj-$(CONFIG_KMEMCHECK)		+= kmemcheck/</span>
<span class="p_del">-</span>
 KASAN_SANITIZE_kasan_init_$(BITS).o := n
 obj-$(CONFIG_KASAN)		+= kasan_init_$(BITS).o
 
<span class="p_header">diff --git a/arch/x86/mm/fault.c b/arch/x86/mm/fault.c</span>
<span class="p_header">index 428e31763cb9..099c256c37a1 100644</span>
<span class="p_header">--- a/arch/x86/mm/fault.c</span>
<span class="p_header">+++ b/arch/x86/mm/fault.c</span>
<span class="p_chunk">@@ -19,7 +19,6 @@</span> <span class="p_context"></span>
 #include &lt;asm/cpufeature.h&gt;		/* boot_cpu_has, ...		*/
 #include &lt;asm/traps.h&gt;			/* dotraplinkage, ...		*/
 #include &lt;asm/pgalloc.h&gt;		/* pgd_*(), ...			*/
<span class="p_del">-#include &lt;asm/kmemcheck.h&gt;		/* kmemcheck_*(), ...		*/</span>
 #include &lt;asm/fixmap.h&gt;			/* VSYSCALL_ADDR		*/
 #include &lt;asm/vsyscall.h&gt;		/* emulate_vsyscall		*/
 #include &lt;asm/vm86.h&gt;			/* struct vm86			*/
<span class="p_chunk">@@ -1228,8 +1227,6 @@</span> <span class="p_context"> __do_page_fault(struct pt_regs *regs, unsigned long error_code,</span>
 	 * Detect and handle instructions that would cause a page fault for
 	 * both a tracked kernel page and a userspace page.
 	 */
<span class="p_del">-	if (kmemcheck_active(regs))</span>
<span class="p_del">-		kmemcheck_hide(regs);</span>
 	prefetchw(&amp;mm-&gt;mmap_sem);
 
 	if (unlikely(kmmio_fault(regs, address)))
<span class="p_chunk">@@ -1252,9 +1249,6 @@</span> <span class="p_context"> __do_page_fault(struct pt_regs *regs, unsigned long error_code,</span>
 		if (!(error_code &amp; (PF_RSVD | PF_USER | PF_PROT))) {
 			if (vmalloc_fault(address) &gt;= 0)
 				return;
<span class="p_del">-</span>
<span class="p_del">-			if (kmemcheck_fault(regs, address, error_code))</span>
<span class="p_del">-				return;</span>
 		}
 
 		/* Can handle a stale RO-&gt;RW TLB: */
<span class="p_header">diff --git a/arch/x86/mm/init.c b/arch/x86/mm/init.c</span>
<span class="p_header">index 889e7619a091..9cfa27385c29 100644</span>
<span class="p_header">--- a/arch/x86/mm/init.c</span>
<span class="p_header">+++ b/arch/x86/mm/init.c</span>
<span class="p_chunk">@@ -161,16 +161,13 @@</span> <span class="p_context"> static int page_size_mask;</span>
 
 static void __init probe_page_size_mask(void)
 {
<span class="p_del">-#if !defined(CONFIG_KMEMCHECK)</span>
 	/*
<span class="p_del">-	 * For CONFIG_KMEMCHECK or pagealloc debugging, identity mapping will</span>
<span class="p_del">-	 * use small pages.</span>
<span class="p_add">+	 * For pagealloc debugging, identity mapping will use small pages.</span>
 	 * This will simplify cpa(), which otherwise needs to support splitting
 	 * large pages into small in interrupt context, etc.
 	 */
 	if (boot_cpu_has(X86_FEATURE_PSE) &amp;&amp; !debug_pagealloc_enabled())
 		page_size_mask |= 1 &lt;&lt; PG_LEVEL_2M;
<span class="p_del">-#endif</span>
 
 	/* Enable PSE if available */
 	if (boot_cpu_has(X86_FEATURE_PSE))
<span class="p_header">diff --git a/arch/x86/mm/kmemcheck/Makefile b/arch/x86/mm/kmemcheck/Makefile</span>
deleted file mode 100644
<span class="p_header">index 520b3bce4095..000000000000</span>
<span class="p_header">--- a/arch/x86/mm/kmemcheck/Makefile</span>
<span class="p_header">+++ /dev/null</span>
<span class="p_chunk">@@ -1 +0,0 @@</span> <span class="p_context"></span>
<span class="p_del">-obj-y := error.o kmemcheck.o opcode.o pte.o selftest.o shadow.o</span>
<span class="p_header">diff --git a/arch/x86/mm/kmemcheck/error.c b/arch/x86/mm/kmemcheck/error.c</span>
deleted file mode 100644
<span class="p_header">index dab41876cdd5..000000000000</span>
<span class="p_header">--- a/arch/x86/mm/kmemcheck/error.c</span>
<span class="p_header">+++ /dev/null</span>
<span class="p_chunk">@@ -1,227 +0,0 @@</span> <span class="p_context"></span>
<span class="p_del">-#include &lt;linux/interrupt.h&gt;</span>
<span class="p_del">-#include &lt;linux/kdebug.h&gt;</span>
<span class="p_del">-#include &lt;linux/kmemcheck.h&gt;</span>
<span class="p_del">-#include &lt;linux/kernel.h&gt;</span>
<span class="p_del">-#include &lt;linux/types.h&gt;</span>
<span class="p_del">-#include &lt;linux/ptrace.h&gt;</span>
<span class="p_del">-#include &lt;linux/stacktrace.h&gt;</span>
<span class="p_del">-#include &lt;linux/string.h&gt;</span>
<span class="p_del">-</span>
<span class="p_del">-#include &quot;error.h&quot;</span>
<span class="p_del">-#include &quot;shadow.h&quot;</span>
<span class="p_del">-</span>
<span class="p_del">-enum kmemcheck_error_type {</span>
<span class="p_del">-	KMEMCHECK_ERROR_INVALID_ACCESS,</span>
<span class="p_del">-	KMEMCHECK_ERROR_BUG,</span>
<span class="p_del">-};</span>
<span class="p_del">-</span>
<span class="p_del">-#define SHADOW_COPY_SIZE (1 &lt;&lt; CONFIG_KMEMCHECK_SHADOW_COPY_SHIFT)</span>
<span class="p_del">-</span>
<span class="p_del">-struct kmemcheck_error {</span>
<span class="p_del">-	enum kmemcheck_error_type type;</span>
<span class="p_del">-</span>
<span class="p_del">-	union {</span>
<span class="p_del">-		/* KMEMCHECK_ERROR_INVALID_ACCESS */</span>
<span class="p_del">-		struct {</span>
<span class="p_del">-			/* Kind of access that caused the error */</span>
<span class="p_del">-			enum kmemcheck_shadow state;</span>
<span class="p_del">-			/* Address and size of the erroneous read */</span>
<span class="p_del">-			unsigned long	address;</span>
<span class="p_del">-			unsigned int	size;</span>
<span class="p_del">-		};</span>
<span class="p_del">-	};</span>
<span class="p_del">-</span>
<span class="p_del">-	struct pt_regs		regs;</span>
<span class="p_del">-	struct stack_trace	trace;</span>
<span class="p_del">-	unsigned long		trace_entries[32];</span>
<span class="p_del">-</span>
<span class="p_del">-	/* We compress it to a char. */</span>
<span class="p_del">-	unsigned char		shadow_copy[SHADOW_COPY_SIZE];</span>
<span class="p_del">-	unsigned char		memory_copy[SHADOW_COPY_SIZE];</span>
<span class="p_del">-};</span>
<span class="p_del">-</span>
<span class="p_del">-/*</span>
<span class="p_del">- * Create a ring queue of errors to output. We can&#39;t call printk() directly</span>
<span class="p_del">- * from the kmemcheck traps, since this may call the console drivers and</span>
<span class="p_del">- * result in a recursive fault.</span>
<span class="p_del">- */</span>
<span class="p_del">-static struct kmemcheck_error error_fifo[CONFIG_KMEMCHECK_QUEUE_SIZE];</span>
<span class="p_del">-static unsigned int error_count;</span>
<span class="p_del">-static unsigned int error_rd;</span>
<span class="p_del">-static unsigned int error_wr;</span>
<span class="p_del">-static unsigned int error_missed_count;</span>
<span class="p_del">-</span>
<span class="p_del">-static struct kmemcheck_error *error_next_wr(void)</span>
<span class="p_del">-{</span>
<span class="p_del">-	struct kmemcheck_error *e;</span>
<span class="p_del">-</span>
<span class="p_del">-	if (error_count == ARRAY_SIZE(error_fifo)) {</span>
<span class="p_del">-		++error_missed_count;</span>
<span class="p_del">-		return NULL;</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">-	e = &amp;error_fifo[error_wr];</span>
<span class="p_del">-	if (++error_wr == ARRAY_SIZE(error_fifo))</span>
<span class="p_del">-		error_wr = 0;</span>
<span class="p_del">-	++error_count;</span>
<span class="p_del">-	return e;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static struct kmemcheck_error *error_next_rd(void)</span>
<span class="p_del">-{</span>
<span class="p_del">-	struct kmemcheck_error *e;</span>
<span class="p_del">-</span>
<span class="p_del">-	if (error_count == 0)</span>
<span class="p_del">-		return NULL;</span>
<span class="p_del">-</span>
<span class="p_del">-	e = &amp;error_fifo[error_rd];</span>
<span class="p_del">-	if (++error_rd == ARRAY_SIZE(error_fifo))</span>
<span class="p_del">-		error_rd = 0;</span>
<span class="p_del">-	--error_count;</span>
<span class="p_del">-	return e;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-void kmemcheck_error_recall(void)</span>
<span class="p_del">-{</span>
<span class="p_del">-	static const char *desc[] = {</span>
<span class="p_del">-		[KMEMCHECK_SHADOW_UNALLOCATED]		= &quot;unallocated&quot;,</span>
<span class="p_del">-		[KMEMCHECK_SHADOW_UNINITIALIZED]	= &quot;uninitialized&quot;,</span>
<span class="p_del">-		[KMEMCHECK_SHADOW_INITIALIZED]		= &quot;initialized&quot;,</span>
<span class="p_del">-		[KMEMCHECK_SHADOW_FREED]		= &quot;freed&quot;,</span>
<span class="p_del">-	};</span>
<span class="p_del">-</span>
<span class="p_del">-	static const char short_desc[] = {</span>
<span class="p_del">-		[KMEMCHECK_SHADOW_UNALLOCATED]		= &#39;a&#39;,</span>
<span class="p_del">-		[KMEMCHECK_SHADOW_UNINITIALIZED]	= &#39;u&#39;,</span>
<span class="p_del">-		[KMEMCHECK_SHADOW_INITIALIZED]		= &#39;i&#39;,</span>
<span class="p_del">-		[KMEMCHECK_SHADOW_FREED]		= &#39;f&#39;,</span>
<span class="p_del">-	};</span>
<span class="p_del">-</span>
<span class="p_del">-	struct kmemcheck_error *e;</span>
<span class="p_del">-	unsigned int i;</span>
<span class="p_del">-</span>
<span class="p_del">-	e = error_next_rd();</span>
<span class="p_del">-	if (!e)</span>
<span class="p_del">-		return;</span>
<span class="p_del">-</span>
<span class="p_del">-	switch (e-&gt;type) {</span>
<span class="p_del">-	case KMEMCHECK_ERROR_INVALID_ACCESS:</span>
<span class="p_del">-		printk(KERN_WARNING &quot;WARNING: kmemcheck: Caught %d-bit read from %s memory (%p)\n&quot;,</span>
<span class="p_del">-			8 * e-&gt;size, e-&gt;state &lt; ARRAY_SIZE(desc) ?</span>
<span class="p_del">-				desc[e-&gt;state] : &quot;(invalid shadow state)&quot;,</span>
<span class="p_del">-			(void *) e-&gt;address);</span>
<span class="p_del">-</span>
<span class="p_del">-		printk(KERN_WARNING);</span>
<span class="p_del">-		for (i = 0; i &lt; SHADOW_COPY_SIZE; ++i)</span>
<span class="p_del">-			printk(KERN_CONT &quot;%02x&quot;, e-&gt;memory_copy[i]);</span>
<span class="p_del">-		printk(KERN_CONT &quot;\n&quot;);</span>
<span class="p_del">-</span>
<span class="p_del">-		printk(KERN_WARNING);</span>
<span class="p_del">-		for (i = 0; i &lt; SHADOW_COPY_SIZE; ++i) {</span>
<span class="p_del">-			if (e-&gt;shadow_copy[i] &lt; ARRAY_SIZE(short_desc))</span>
<span class="p_del">-				printk(KERN_CONT &quot; %c&quot;, short_desc[e-&gt;shadow_copy[i]]);</span>
<span class="p_del">-			else</span>
<span class="p_del">-				printk(KERN_CONT &quot; ?&quot;);</span>
<span class="p_del">-		}</span>
<span class="p_del">-		printk(KERN_CONT &quot;\n&quot;);</span>
<span class="p_del">-		printk(KERN_WARNING &quot;%*c\n&quot;, 2 + 2</span>
<span class="p_del">-			* (int) (e-&gt;address &amp; (SHADOW_COPY_SIZE - 1)), &#39;^&#39;);</span>
<span class="p_del">-		break;</span>
<span class="p_del">-	case KMEMCHECK_ERROR_BUG:</span>
<span class="p_del">-		printk(KERN_EMERG &quot;ERROR: kmemcheck: Fatal error\n&quot;);</span>
<span class="p_del">-		break;</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">-	__show_regs(&amp;e-&gt;regs, 1);</span>
<span class="p_del">-	print_stack_trace(&amp;e-&gt;trace, 0);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static void do_wakeup(unsigned long data)</span>
<span class="p_del">-{</span>
<span class="p_del">-	while (error_count &gt; 0)</span>
<span class="p_del">-		kmemcheck_error_recall();</span>
<span class="p_del">-</span>
<span class="p_del">-	if (error_missed_count &gt; 0) {</span>
<span class="p_del">-		printk(KERN_WARNING &quot;kmemcheck: Lost %d error reports because &quot;</span>
<span class="p_del">-			&quot;the queue was too small\n&quot;, error_missed_count);</span>
<span class="p_del">-		error_missed_count = 0;</span>
<span class="p_del">-	}</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static DECLARE_TASKLET(kmemcheck_tasklet, &amp;do_wakeup, 0);</span>
<span class="p_del">-</span>
<span class="p_del">-/*</span>
<span class="p_del">- * Save the context of an error report.</span>
<span class="p_del">- */</span>
<span class="p_del">-void kmemcheck_error_save(enum kmemcheck_shadow state,</span>
<span class="p_del">-	unsigned long address, unsigned int size, struct pt_regs *regs)</span>
<span class="p_del">-{</span>
<span class="p_del">-	static unsigned long prev_ip;</span>
<span class="p_del">-</span>
<span class="p_del">-	struct kmemcheck_error *e;</span>
<span class="p_del">-	void *shadow_copy;</span>
<span class="p_del">-	void *memory_copy;</span>
<span class="p_del">-</span>
<span class="p_del">-	/* Don&#39;t report several adjacent errors from the same EIP. */</span>
<span class="p_del">-	if (regs-&gt;ip == prev_ip)</span>
<span class="p_del">-		return;</span>
<span class="p_del">-	prev_ip = regs-&gt;ip;</span>
<span class="p_del">-</span>
<span class="p_del">-	e = error_next_wr();</span>
<span class="p_del">-	if (!e)</span>
<span class="p_del">-		return;</span>
<span class="p_del">-</span>
<span class="p_del">-	e-&gt;type = KMEMCHECK_ERROR_INVALID_ACCESS;</span>
<span class="p_del">-</span>
<span class="p_del">-	e-&gt;state = state;</span>
<span class="p_del">-	e-&gt;address = address;</span>
<span class="p_del">-	e-&gt;size = size;</span>
<span class="p_del">-</span>
<span class="p_del">-	/* Save regs */</span>
<span class="p_del">-	memcpy(&amp;e-&gt;regs, regs, sizeof(*regs));</span>
<span class="p_del">-</span>
<span class="p_del">-	/* Save stack trace */</span>
<span class="p_del">-	e-&gt;trace.nr_entries = 0;</span>
<span class="p_del">-	e-&gt;trace.entries = e-&gt;trace_entries;</span>
<span class="p_del">-	e-&gt;trace.max_entries = ARRAY_SIZE(e-&gt;trace_entries);</span>
<span class="p_del">-	e-&gt;trace.skip = 0;</span>
<span class="p_del">-	save_stack_trace_regs(regs, &amp;e-&gt;trace);</span>
<span class="p_del">-</span>
<span class="p_del">-	/* Round address down to nearest 16 bytes */</span>
<span class="p_del">-	shadow_copy = kmemcheck_shadow_lookup(address</span>
<span class="p_del">-		&amp; ~(SHADOW_COPY_SIZE - 1));</span>
<span class="p_del">-	BUG_ON(!shadow_copy);</span>
<span class="p_del">-</span>
<span class="p_del">-	memcpy(e-&gt;shadow_copy, shadow_copy, SHADOW_COPY_SIZE);</span>
<span class="p_del">-</span>
<span class="p_del">-	kmemcheck_show_addr(address);</span>
<span class="p_del">-	memory_copy = (void *) (address &amp; ~(SHADOW_COPY_SIZE - 1));</span>
<span class="p_del">-	memcpy(e-&gt;memory_copy, memory_copy, SHADOW_COPY_SIZE);</span>
<span class="p_del">-	kmemcheck_hide_addr(address);</span>
<span class="p_del">-</span>
<span class="p_del">-	tasklet_hi_schedule_first(&amp;kmemcheck_tasklet);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-/*</span>
<span class="p_del">- * Save the context of a kmemcheck bug.</span>
<span class="p_del">- */</span>
<span class="p_del">-void kmemcheck_error_save_bug(struct pt_regs *regs)</span>
<span class="p_del">-{</span>
<span class="p_del">-	struct kmemcheck_error *e;</span>
<span class="p_del">-</span>
<span class="p_del">-	e = error_next_wr();</span>
<span class="p_del">-	if (!e)</span>
<span class="p_del">-		return;</span>
<span class="p_del">-</span>
<span class="p_del">-	e-&gt;type = KMEMCHECK_ERROR_BUG;</span>
<span class="p_del">-</span>
<span class="p_del">-	memcpy(&amp;e-&gt;regs, regs, sizeof(*regs));</span>
<span class="p_del">-</span>
<span class="p_del">-	e-&gt;trace.nr_entries = 0;</span>
<span class="p_del">-	e-&gt;trace.entries = e-&gt;trace_entries;</span>
<span class="p_del">-	e-&gt;trace.max_entries = ARRAY_SIZE(e-&gt;trace_entries);</span>
<span class="p_del">-	e-&gt;trace.skip = 1;</span>
<span class="p_del">-	save_stack_trace(&amp;e-&gt;trace);</span>
<span class="p_del">-</span>
<span class="p_del">-	tasklet_hi_schedule_first(&amp;kmemcheck_tasklet);</span>
<span class="p_del">-}</span>
<span class="p_header">diff --git a/arch/x86/mm/kmemcheck/error.h b/arch/x86/mm/kmemcheck/error.h</span>
deleted file mode 100644
<span class="p_header">index 0efc2e8d0a20..000000000000</span>
<span class="p_header">--- a/arch/x86/mm/kmemcheck/error.h</span>
<span class="p_header">+++ /dev/null</span>
<span class="p_chunk">@@ -1,15 +0,0 @@</span> <span class="p_context"></span>
<span class="p_del">-#ifndef ARCH__X86__MM__KMEMCHECK__ERROR_H</span>
<span class="p_del">-#define ARCH__X86__MM__KMEMCHECK__ERROR_H</span>
<span class="p_del">-</span>
<span class="p_del">-#include &lt;linux/ptrace.h&gt;</span>
<span class="p_del">-</span>
<span class="p_del">-#include &quot;shadow.h&quot;</span>
<span class="p_del">-</span>
<span class="p_del">-void kmemcheck_error_save(enum kmemcheck_shadow state,</span>
<span class="p_del">-	unsigned long address, unsigned int size, struct pt_regs *regs);</span>
<span class="p_del">-</span>
<span class="p_del">-void kmemcheck_error_save_bug(struct pt_regs *regs);</span>
<span class="p_del">-</span>
<span class="p_del">-void kmemcheck_error_recall(void);</span>
<span class="p_del">-</span>
<span class="p_del">-#endif</span>
<span class="p_header">diff --git a/arch/x86/mm/kmemcheck/kmemcheck.c b/arch/x86/mm/kmemcheck/kmemcheck.c</span>
deleted file mode 100644
<span class="p_header">index 4515bae36bbe..000000000000</span>
<span class="p_header">--- a/arch/x86/mm/kmemcheck/kmemcheck.c</span>
<span class="p_header">+++ /dev/null</span>
<span class="p_chunk">@@ -1,658 +0,0 @@</span> <span class="p_context"></span>
<span class="p_del">-/**</span>
<span class="p_del">- * kmemcheck - a heavyweight memory checker for the linux kernel</span>
<span class="p_del">- * Copyright (C) 2007, 2008  Vegard Nossum &lt;vegardno@ifi.uio.no&gt;</span>
<span class="p_del">- * (With a lot of help from Ingo Molnar and Pekka Enberg.)</span>
<span class="p_del">- *</span>
<span class="p_del">- * This program is free software; you can redistribute it and/or modify</span>
<span class="p_del">- * it under the terms of the GNU General Public License (version 2) as</span>
<span class="p_del">- * published by the Free Software Foundation.</span>
<span class="p_del">- */</span>
<span class="p_del">-</span>
<span class="p_del">-#include &lt;linux/init.h&gt;</span>
<span class="p_del">-#include &lt;linux/interrupt.h&gt;</span>
<span class="p_del">-#include &lt;linux/kallsyms.h&gt;</span>
<span class="p_del">-#include &lt;linux/kernel.h&gt;</span>
<span class="p_del">-#include &lt;linux/kmemcheck.h&gt;</span>
<span class="p_del">-#include &lt;linux/mm.h&gt;</span>
<span class="p_del">-#include &lt;linux/page-flags.h&gt;</span>
<span class="p_del">-#include &lt;linux/percpu.h&gt;</span>
<span class="p_del">-#include &lt;linux/ptrace.h&gt;</span>
<span class="p_del">-#include &lt;linux/string.h&gt;</span>
<span class="p_del">-#include &lt;linux/types.h&gt;</span>
<span class="p_del">-</span>
<span class="p_del">-#include &lt;asm/cacheflush.h&gt;</span>
<span class="p_del">-#include &lt;asm/kmemcheck.h&gt;</span>
<span class="p_del">-#include &lt;asm/pgtable.h&gt;</span>
<span class="p_del">-#include &lt;asm/tlbflush.h&gt;</span>
<span class="p_del">-</span>
<span class="p_del">-#include &quot;error.h&quot;</span>
<span class="p_del">-#include &quot;opcode.h&quot;</span>
<span class="p_del">-#include &quot;pte.h&quot;</span>
<span class="p_del">-#include &quot;selftest.h&quot;</span>
<span class="p_del">-#include &quot;shadow.h&quot;</span>
<span class="p_del">-</span>
<span class="p_del">-</span>
<span class="p_del">-#ifdef CONFIG_KMEMCHECK_DISABLED_BY_DEFAULT</span>
<span class="p_del">-#  define KMEMCHECK_ENABLED 0</span>
<span class="p_del">-#endif</span>
<span class="p_del">-</span>
<span class="p_del">-#ifdef CONFIG_KMEMCHECK_ENABLED_BY_DEFAULT</span>
<span class="p_del">-#  define KMEMCHECK_ENABLED 1</span>
<span class="p_del">-#endif</span>
<span class="p_del">-</span>
<span class="p_del">-#ifdef CONFIG_KMEMCHECK_ONESHOT_BY_DEFAULT</span>
<span class="p_del">-#  define KMEMCHECK_ENABLED 2</span>
<span class="p_del">-#endif</span>
<span class="p_del">-</span>
<span class="p_del">-int kmemcheck_enabled = KMEMCHECK_ENABLED;</span>
<span class="p_del">-</span>
<span class="p_del">-int __init kmemcheck_init(void)</span>
<span class="p_del">-{</span>
<span class="p_del">-#ifdef CONFIG_SMP</span>
<span class="p_del">-	/*</span>
<span class="p_del">-	 * Limit SMP to use a single CPU. We rely on the fact that this code</span>
<span class="p_del">-	 * runs before SMP is set up.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	if (setup_max_cpus &gt; 1) {</span>
<span class="p_del">-		printk(KERN_INFO</span>
<span class="p_del">-			&quot;kmemcheck: Limiting number of CPUs to 1.\n&quot;);</span>
<span class="p_del">-		setup_max_cpus = 1;</span>
<span class="p_del">-	}</span>
<span class="p_del">-#endif</span>
<span class="p_del">-</span>
<span class="p_del">-	if (!kmemcheck_selftest()) {</span>
<span class="p_del">-		printk(KERN_INFO &quot;kmemcheck: self-tests failed; disabling\n&quot;);</span>
<span class="p_del">-		kmemcheck_enabled = 0;</span>
<span class="p_del">-		return -EINVAL;</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">-	printk(KERN_INFO &quot;kmemcheck: Initialized\n&quot;);</span>
<span class="p_del">-	return 0;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-early_initcall(kmemcheck_init);</span>
<span class="p_del">-</span>
<span class="p_del">-/*</span>
<span class="p_del">- * We need to parse the kmemcheck= option before any memory is allocated.</span>
<span class="p_del">- */</span>
<span class="p_del">-static int __init param_kmemcheck(char *str)</span>
<span class="p_del">-{</span>
<span class="p_del">-	int val;</span>
<span class="p_del">-	int ret;</span>
<span class="p_del">-</span>
<span class="p_del">-	if (!str)</span>
<span class="p_del">-		return -EINVAL;</span>
<span class="p_del">-</span>
<span class="p_del">-	ret = kstrtoint(str, 0, &amp;val);</span>
<span class="p_del">-	if (ret)</span>
<span class="p_del">-		return ret;</span>
<span class="p_del">-	kmemcheck_enabled = val;</span>
<span class="p_del">-	return 0;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-early_param(&quot;kmemcheck&quot;, param_kmemcheck);</span>
<span class="p_del">-</span>
<span class="p_del">-int kmemcheck_show_addr(unsigned long address)</span>
<span class="p_del">-{</span>
<span class="p_del">-	pte_t *pte;</span>
<span class="p_del">-</span>
<span class="p_del">-	pte = kmemcheck_pte_lookup(address);</span>
<span class="p_del">-	if (!pte)</span>
<span class="p_del">-		return 0;</span>
<span class="p_del">-</span>
<span class="p_del">-	set_pte(pte, __pte(pte_val(*pte) | _PAGE_PRESENT));</span>
<span class="p_del">-	__flush_tlb_one(address);</span>
<span class="p_del">-	return 1;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-int kmemcheck_hide_addr(unsigned long address)</span>
<span class="p_del">-{</span>
<span class="p_del">-	pte_t *pte;</span>
<span class="p_del">-</span>
<span class="p_del">-	pte = kmemcheck_pte_lookup(address);</span>
<span class="p_del">-	if (!pte)</span>
<span class="p_del">-		return 0;</span>
<span class="p_del">-</span>
<span class="p_del">-	set_pte(pte, __pte(pte_val(*pte) &amp; ~_PAGE_PRESENT));</span>
<span class="p_del">-	__flush_tlb_one(address);</span>
<span class="p_del">-	return 1;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-struct kmemcheck_context {</span>
<span class="p_del">-	bool busy;</span>
<span class="p_del">-	int balance;</span>
<span class="p_del">-</span>
<span class="p_del">-	/*</span>
<span class="p_del">-	 * There can be at most two memory operands to an instruction, but</span>
<span class="p_del">-	 * each address can cross a page boundary -- so we may need up to</span>
<span class="p_del">-	 * four addresses that must be hidden/revealed for each fault.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	unsigned long addr[4];</span>
<span class="p_del">-	unsigned long n_addrs;</span>
<span class="p_del">-	unsigned long flags;</span>
<span class="p_del">-</span>
<span class="p_del">-	/* Data size of the instruction that caused a fault. */</span>
<span class="p_del">-	unsigned int size;</span>
<span class="p_del">-};</span>
<span class="p_del">-</span>
<span class="p_del">-static DEFINE_PER_CPU(struct kmemcheck_context, kmemcheck_context);</span>
<span class="p_del">-</span>
<span class="p_del">-bool kmemcheck_active(struct pt_regs *regs)</span>
<span class="p_del">-{</span>
<span class="p_del">-	struct kmemcheck_context *data = this_cpu_ptr(&amp;kmemcheck_context);</span>
<span class="p_del">-</span>
<span class="p_del">-	return data-&gt;balance &gt; 0;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-/* Save an address that needs to be shown/hidden */</span>
<span class="p_del">-static void kmemcheck_save_addr(unsigned long addr)</span>
<span class="p_del">-{</span>
<span class="p_del">-	struct kmemcheck_context *data = this_cpu_ptr(&amp;kmemcheck_context);</span>
<span class="p_del">-</span>
<span class="p_del">-	BUG_ON(data-&gt;n_addrs &gt;= ARRAY_SIZE(data-&gt;addr));</span>
<span class="p_del">-	data-&gt;addr[data-&gt;n_addrs++] = addr;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static unsigned int kmemcheck_show_all(void)</span>
<span class="p_del">-{</span>
<span class="p_del">-	struct kmemcheck_context *data = this_cpu_ptr(&amp;kmemcheck_context);</span>
<span class="p_del">-	unsigned int i;</span>
<span class="p_del">-	unsigned int n;</span>
<span class="p_del">-</span>
<span class="p_del">-	n = 0;</span>
<span class="p_del">-	for (i = 0; i &lt; data-&gt;n_addrs; ++i)</span>
<span class="p_del">-		n += kmemcheck_show_addr(data-&gt;addr[i]);</span>
<span class="p_del">-</span>
<span class="p_del">-	return n;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static unsigned int kmemcheck_hide_all(void)</span>
<span class="p_del">-{</span>
<span class="p_del">-	struct kmemcheck_context *data = this_cpu_ptr(&amp;kmemcheck_context);</span>
<span class="p_del">-	unsigned int i;</span>
<span class="p_del">-	unsigned int n;</span>
<span class="p_del">-</span>
<span class="p_del">-	n = 0;</span>
<span class="p_del">-	for (i = 0; i &lt; data-&gt;n_addrs; ++i)</span>
<span class="p_del">-		n += kmemcheck_hide_addr(data-&gt;addr[i]);</span>
<span class="p_del">-</span>
<span class="p_del">-	return n;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-/*</span>
<span class="p_del">- * Called from the #PF handler.</span>
<span class="p_del">- */</span>
<span class="p_del">-void kmemcheck_show(struct pt_regs *regs)</span>
<span class="p_del">-{</span>
<span class="p_del">-	struct kmemcheck_context *data = this_cpu_ptr(&amp;kmemcheck_context);</span>
<span class="p_del">-</span>
<span class="p_del">-	BUG_ON(!irqs_disabled());</span>
<span class="p_del">-</span>
<span class="p_del">-	if (unlikely(data-&gt;balance != 0)) {</span>
<span class="p_del">-		kmemcheck_show_all();</span>
<span class="p_del">-		kmemcheck_error_save_bug(regs);</span>
<span class="p_del">-		data-&gt;balance = 0;</span>
<span class="p_del">-		return;</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">-	/*</span>
<span class="p_del">-	 * None of the addresses actually belonged to kmemcheck. Note that</span>
<span class="p_del">-	 * this is not an error.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	if (kmemcheck_show_all() == 0)</span>
<span class="p_del">-		return;</span>
<span class="p_del">-</span>
<span class="p_del">-	++data-&gt;balance;</span>
<span class="p_del">-</span>
<span class="p_del">-	/*</span>
<span class="p_del">-	 * The IF needs to be cleared as well, so that the faulting</span>
<span class="p_del">-	 * instruction can run &quot;uninterrupted&quot;. Otherwise, we might take</span>
<span class="p_del">-	 * an interrupt and start executing that before we&#39;ve had a chance</span>
<span class="p_del">-	 * to hide the page again.</span>
<span class="p_del">-	 *</span>
<span class="p_del">-	 * NOTE: In the rare case of multiple faults, we must not override</span>
<span class="p_del">-	 * the original flags:</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	if (!(regs-&gt;flags &amp; X86_EFLAGS_TF))</span>
<span class="p_del">-		data-&gt;flags = regs-&gt;flags;</span>
<span class="p_del">-</span>
<span class="p_del">-	regs-&gt;flags |= X86_EFLAGS_TF;</span>
<span class="p_del">-	regs-&gt;flags &amp;= ~X86_EFLAGS_IF;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-/*</span>
<span class="p_del">- * Called from the #DB handler.</span>
<span class="p_del">- */</span>
<span class="p_del">-void kmemcheck_hide(struct pt_regs *regs)</span>
<span class="p_del">-{</span>
<span class="p_del">-	struct kmemcheck_context *data = this_cpu_ptr(&amp;kmemcheck_context);</span>
<span class="p_del">-	int n;</span>
<span class="p_del">-</span>
<span class="p_del">-	BUG_ON(!irqs_disabled());</span>
<span class="p_del">-</span>
<span class="p_del">-	if (unlikely(data-&gt;balance != 1)) {</span>
<span class="p_del">-		kmemcheck_show_all();</span>
<span class="p_del">-		kmemcheck_error_save_bug(regs);</span>
<span class="p_del">-		data-&gt;n_addrs = 0;</span>
<span class="p_del">-		data-&gt;balance = 0;</span>
<span class="p_del">-</span>
<span class="p_del">-		if (!(data-&gt;flags &amp; X86_EFLAGS_TF))</span>
<span class="p_del">-			regs-&gt;flags &amp;= ~X86_EFLAGS_TF;</span>
<span class="p_del">-		if (data-&gt;flags &amp; X86_EFLAGS_IF)</span>
<span class="p_del">-			regs-&gt;flags |= X86_EFLAGS_IF;</span>
<span class="p_del">-		return;</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">-	if (kmemcheck_enabled)</span>
<span class="p_del">-		n = kmemcheck_hide_all();</span>
<span class="p_del">-	else</span>
<span class="p_del">-		n = kmemcheck_show_all();</span>
<span class="p_del">-</span>
<span class="p_del">-	if (n == 0)</span>
<span class="p_del">-		return;</span>
<span class="p_del">-</span>
<span class="p_del">-	--data-&gt;balance;</span>
<span class="p_del">-</span>
<span class="p_del">-	data-&gt;n_addrs = 0;</span>
<span class="p_del">-</span>
<span class="p_del">-	if (!(data-&gt;flags &amp; X86_EFLAGS_TF))</span>
<span class="p_del">-		regs-&gt;flags &amp;= ~X86_EFLAGS_TF;</span>
<span class="p_del">-	if (data-&gt;flags &amp; X86_EFLAGS_IF)</span>
<span class="p_del">-		regs-&gt;flags |= X86_EFLAGS_IF;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-void kmemcheck_show_pages(struct page *p, unsigned int n)</span>
<span class="p_del">-{</span>
<span class="p_del">-	unsigned int i;</span>
<span class="p_del">-</span>
<span class="p_del">-	for (i = 0; i &lt; n; ++i) {</span>
<span class="p_del">-		unsigned long address;</span>
<span class="p_del">-		pte_t *pte;</span>
<span class="p_del">-		unsigned int level;</span>
<span class="p_del">-</span>
<span class="p_del">-		address = (unsigned long) page_address(&amp;p[i]);</span>
<span class="p_del">-		pte = lookup_address(address, &amp;level);</span>
<span class="p_del">-		BUG_ON(!pte);</span>
<span class="p_del">-		BUG_ON(level != PG_LEVEL_4K);</span>
<span class="p_del">-</span>
<span class="p_del">-		set_pte(pte, __pte(pte_val(*pte) | _PAGE_PRESENT));</span>
<span class="p_del">-		set_pte(pte, __pte(pte_val(*pte) &amp; ~_PAGE_HIDDEN));</span>
<span class="p_del">-		__flush_tlb_one(address);</span>
<span class="p_del">-	}</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-bool kmemcheck_page_is_tracked(struct page *p)</span>
<span class="p_del">-{</span>
<span class="p_del">-	/* This will also check the &quot;hidden&quot; flag of the PTE. */</span>
<span class="p_del">-	return kmemcheck_pte_lookup((unsigned long) page_address(p));</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-void kmemcheck_hide_pages(struct page *p, unsigned int n)</span>
<span class="p_del">-{</span>
<span class="p_del">-	unsigned int i;</span>
<span class="p_del">-</span>
<span class="p_del">-	for (i = 0; i &lt; n; ++i) {</span>
<span class="p_del">-		unsigned long address;</span>
<span class="p_del">-		pte_t *pte;</span>
<span class="p_del">-		unsigned int level;</span>
<span class="p_del">-</span>
<span class="p_del">-		address = (unsigned long) page_address(&amp;p[i]);</span>
<span class="p_del">-		pte = lookup_address(address, &amp;level);</span>
<span class="p_del">-		BUG_ON(!pte);</span>
<span class="p_del">-		BUG_ON(level != PG_LEVEL_4K);</span>
<span class="p_del">-</span>
<span class="p_del">-		set_pte(pte, __pte(pte_val(*pte) &amp; ~_PAGE_PRESENT));</span>
<span class="p_del">-		set_pte(pte, __pte(pte_val(*pte) | _PAGE_HIDDEN));</span>
<span class="p_del">-		__flush_tlb_one(address);</span>
<span class="p_del">-	}</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-/* Access may NOT cross page boundary */</span>
<span class="p_del">-static void kmemcheck_read_strict(struct pt_regs *regs,</span>
<span class="p_del">-	unsigned long addr, unsigned int size)</span>
<span class="p_del">-{</span>
<span class="p_del">-	void *shadow;</span>
<span class="p_del">-	enum kmemcheck_shadow status;</span>
<span class="p_del">-</span>
<span class="p_del">-	shadow = kmemcheck_shadow_lookup(addr);</span>
<span class="p_del">-	if (!shadow)</span>
<span class="p_del">-		return;</span>
<span class="p_del">-</span>
<span class="p_del">-	kmemcheck_save_addr(addr);</span>
<span class="p_del">-	status = kmemcheck_shadow_test(shadow, size);</span>
<span class="p_del">-	if (status == KMEMCHECK_SHADOW_INITIALIZED)</span>
<span class="p_del">-		return;</span>
<span class="p_del">-</span>
<span class="p_del">-	if (kmemcheck_enabled)</span>
<span class="p_del">-		kmemcheck_error_save(status, addr, size, regs);</span>
<span class="p_del">-</span>
<span class="p_del">-	if (kmemcheck_enabled == 2)</span>
<span class="p_del">-		kmemcheck_enabled = 0;</span>
<span class="p_del">-</span>
<span class="p_del">-	/* Don&#39;t warn about it again. */</span>
<span class="p_del">-	kmemcheck_shadow_set(shadow, size);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-bool kmemcheck_is_obj_initialized(unsigned long addr, size_t size)</span>
<span class="p_del">-{</span>
<span class="p_del">-	enum kmemcheck_shadow status;</span>
<span class="p_del">-	void *shadow;</span>
<span class="p_del">-</span>
<span class="p_del">-	shadow = kmemcheck_shadow_lookup(addr);</span>
<span class="p_del">-	if (!shadow)</span>
<span class="p_del">-		return true;</span>
<span class="p_del">-</span>
<span class="p_del">-	status = kmemcheck_shadow_test_all(shadow, size);</span>
<span class="p_del">-</span>
<span class="p_del">-	return status == KMEMCHECK_SHADOW_INITIALIZED;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-/* Access may cross page boundary */</span>
<span class="p_del">-static void kmemcheck_read(struct pt_regs *regs,</span>
<span class="p_del">-	unsigned long addr, unsigned int size)</span>
<span class="p_del">-{</span>
<span class="p_del">-	unsigned long page = addr &amp; PAGE_MASK;</span>
<span class="p_del">-	unsigned long next_addr = addr + size - 1;</span>
<span class="p_del">-	unsigned long next_page = next_addr &amp; PAGE_MASK;</span>
<span class="p_del">-</span>
<span class="p_del">-	if (likely(page == next_page)) {</span>
<span class="p_del">-		kmemcheck_read_strict(regs, addr, size);</span>
<span class="p_del">-		return;</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">-	/*</span>
<span class="p_del">-	 * What we do is basically to split the access across the</span>
<span class="p_del">-	 * two pages and handle each part separately. Yes, this means</span>
<span class="p_del">-	 * that we may now see reads that are 3 + 5 bytes, for</span>
<span class="p_del">-	 * example (and if both are uninitialized, there will be two</span>
<span class="p_del">-	 * reports), but it makes the code a lot simpler.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	kmemcheck_read_strict(regs, addr, next_page - addr);</span>
<span class="p_del">-	kmemcheck_read_strict(regs, next_page, next_addr - next_page);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static void kmemcheck_write_strict(struct pt_regs *regs,</span>
<span class="p_del">-	unsigned long addr, unsigned int size)</span>
<span class="p_del">-{</span>
<span class="p_del">-	void *shadow;</span>
<span class="p_del">-</span>
<span class="p_del">-	shadow = kmemcheck_shadow_lookup(addr);</span>
<span class="p_del">-	if (!shadow)</span>
<span class="p_del">-		return;</span>
<span class="p_del">-</span>
<span class="p_del">-	kmemcheck_save_addr(addr);</span>
<span class="p_del">-	kmemcheck_shadow_set(shadow, size);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static void kmemcheck_write(struct pt_regs *regs,</span>
<span class="p_del">-	unsigned long addr, unsigned int size)</span>
<span class="p_del">-{</span>
<span class="p_del">-	unsigned long page = addr &amp; PAGE_MASK;</span>
<span class="p_del">-	unsigned long next_addr = addr + size - 1;</span>
<span class="p_del">-	unsigned long next_page = next_addr &amp; PAGE_MASK;</span>
<span class="p_del">-</span>
<span class="p_del">-	if (likely(page == next_page)) {</span>
<span class="p_del">-		kmemcheck_write_strict(regs, addr, size);</span>
<span class="p_del">-		return;</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">-	/* See comment in kmemcheck_read(). */</span>
<span class="p_del">-	kmemcheck_write_strict(regs, addr, next_page - addr);</span>
<span class="p_del">-	kmemcheck_write_strict(regs, next_page, next_addr - next_page);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-/*</span>
<span class="p_del">- * Copying is hard. We have two addresses, each of which may be split across</span>
<span class="p_del">- * a page (and each page will have different shadow addresses).</span>
<span class="p_del">- */</span>
<span class="p_del">-static void kmemcheck_copy(struct pt_regs *regs,</span>
<span class="p_del">-	unsigned long src_addr, unsigned long dst_addr, unsigned int size)</span>
<span class="p_del">-{</span>
<span class="p_del">-	uint8_t shadow[8];</span>
<span class="p_del">-	enum kmemcheck_shadow status;</span>
<span class="p_del">-</span>
<span class="p_del">-	unsigned long page;</span>
<span class="p_del">-	unsigned long next_addr;</span>
<span class="p_del">-	unsigned long next_page;</span>
<span class="p_del">-</span>
<span class="p_del">-	uint8_t *x;</span>
<span class="p_del">-	unsigned int i;</span>
<span class="p_del">-	unsigned int n;</span>
<span class="p_del">-</span>
<span class="p_del">-	BUG_ON(size &gt; sizeof(shadow));</span>
<span class="p_del">-</span>
<span class="p_del">-	page = src_addr &amp; PAGE_MASK;</span>
<span class="p_del">-	next_addr = src_addr + size - 1;</span>
<span class="p_del">-	next_page = next_addr &amp; PAGE_MASK;</span>
<span class="p_del">-</span>
<span class="p_del">-	if (likely(page == next_page)) {</span>
<span class="p_del">-		/* Same page */</span>
<span class="p_del">-		x = kmemcheck_shadow_lookup(src_addr);</span>
<span class="p_del">-		if (x) {</span>
<span class="p_del">-			kmemcheck_save_addr(src_addr);</span>
<span class="p_del">-			for (i = 0; i &lt; size; ++i)</span>
<span class="p_del">-				shadow[i] = x[i];</span>
<span class="p_del">-		} else {</span>
<span class="p_del">-			for (i = 0; i &lt; size; ++i)</span>
<span class="p_del">-				shadow[i] = KMEMCHECK_SHADOW_INITIALIZED;</span>
<span class="p_del">-		}</span>
<span class="p_del">-	} else {</span>
<span class="p_del">-		n = next_page - src_addr;</span>
<span class="p_del">-		BUG_ON(n &gt; sizeof(shadow));</span>
<span class="p_del">-</span>
<span class="p_del">-		/* First page */</span>
<span class="p_del">-		x = kmemcheck_shadow_lookup(src_addr);</span>
<span class="p_del">-		if (x) {</span>
<span class="p_del">-			kmemcheck_save_addr(src_addr);</span>
<span class="p_del">-			for (i = 0; i &lt; n; ++i)</span>
<span class="p_del">-				shadow[i] = x[i];</span>
<span class="p_del">-		} else {</span>
<span class="p_del">-			/* Not tracked */</span>
<span class="p_del">-			for (i = 0; i &lt; n; ++i)</span>
<span class="p_del">-				shadow[i] = KMEMCHECK_SHADOW_INITIALIZED;</span>
<span class="p_del">-		}</span>
<span class="p_del">-</span>
<span class="p_del">-		/* Second page */</span>
<span class="p_del">-		x = kmemcheck_shadow_lookup(next_page);</span>
<span class="p_del">-		if (x) {</span>
<span class="p_del">-			kmemcheck_save_addr(next_page);</span>
<span class="p_del">-			for (i = n; i &lt; size; ++i)</span>
<span class="p_del">-				shadow[i] = x[i - n];</span>
<span class="p_del">-		} else {</span>
<span class="p_del">-			/* Not tracked */</span>
<span class="p_del">-			for (i = n; i &lt; size; ++i)</span>
<span class="p_del">-				shadow[i] = KMEMCHECK_SHADOW_INITIALIZED;</span>
<span class="p_del">-		}</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">-	page = dst_addr &amp; PAGE_MASK;</span>
<span class="p_del">-	next_addr = dst_addr + size - 1;</span>
<span class="p_del">-	next_page = next_addr &amp; PAGE_MASK;</span>
<span class="p_del">-</span>
<span class="p_del">-	if (likely(page == next_page)) {</span>
<span class="p_del">-		/* Same page */</span>
<span class="p_del">-		x = kmemcheck_shadow_lookup(dst_addr);</span>
<span class="p_del">-		if (x) {</span>
<span class="p_del">-			kmemcheck_save_addr(dst_addr);</span>
<span class="p_del">-			for (i = 0; i &lt; size; ++i) {</span>
<span class="p_del">-				x[i] = shadow[i];</span>
<span class="p_del">-				shadow[i] = KMEMCHECK_SHADOW_INITIALIZED;</span>
<span class="p_del">-			}</span>
<span class="p_del">-		}</span>
<span class="p_del">-	} else {</span>
<span class="p_del">-		n = next_page - dst_addr;</span>
<span class="p_del">-		BUG_ON(n &gt; sizeof(shadow));</span>
<span class="p_del">-</span>
<span class="p_del">-		/* First page */</span>
<span class="p_del">-		x = kmemcheck_shadow_lookup(dst_addr);</span>
<span class="p_del">-		if (x) {</span>
<span class="p_del">-			kmemcheck_save_addr(dst_addr);</span>
<span class="p_del">-			for (i = 0; i &lt; n; ++i) {</span>
<span class="p_del">-				x[i] = shadow[i];</span>
<span class="p_del">-				shadow[i] = KMEMCHECK_SHADOW_INITIALIZED;</span>
<span class="p_del">-			}</span>
<span class="p_del">-		}</span>
<span class="p_del">-</span>
<span class="p_del">-		/* Second page */</span>
<span class="p_del">-		x = kmemcheck_shadow_lookup(next_page);</span>
<span class="p_del">-		if (x) {</span>
<span class="p_del">-			kmemcheck_save_addr(next_page);</span>
<span class="p_del">-			for (i = n; i &lt; size; ++i) {</span>
<span class="p_del">-				x[i - n] = shadow[i];</span>
<span class="p_del">-				shadow[i] = KMEMCHECK_SHADOW_INITIALIZED;</span>
<span class="p_del">-			}</span>
<span class="p_del">-		}</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">-	status = kmemcheck_shadow_test(shadow, size);</span>
<span class="p_del">-	if (status == KMEMCHECK_SHADOW_INITIALIZED)</span>
<span class="p_del">-		return;</span>
<span class="p_del">-</span>
<span class="p_del">-	if (kmemcheck_enabled)</span>
<span class="p_del">-		kmemcheck_error_save(status, src_addr, size, regs);</span>
<span class="p_del">-</span>
<span class="p_del">-	if (kmemcheck_enabled == 2)</span>
<span class="p_del">-		kmemcheck_enabled = 0;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-enum kmemcheck_method {</span>
<span class="p_del">-	KMEMCHECK_READ,</span>
<span class="p_del">-	KMEMCHECK_WRITE,</span>
<span class="p_del">-};</span>
<span class="p_del">-</span>
<span class="p_del">-static void kmemcheck_access(struct pt_regs *regs,</span>
<span class="p_del">-	unsigned long fallback_address, enum kmemcheck_method fallback_method)</span>
<span class="p_del">-{</span>
<span class="p_del">-	const uint8_t *insn;</span>
<span class="p_del">-	const uint8_t *insn_primary;</span>
<span class="p_del">-	unsigned int size;</span>
<span class="p_del">-</span>
<span class="p_del">-	struct kmemcheck_context *data = this_cpu_ptr(&amp;kmemcheck_context);</span>
<span class="p_del">-</span>
<span class="p_del">-	/* Recursive fault -- ouch. */</span>
<span class="p_del">-	if (data-&gt;busy) {</span>
<span class="p_del">-		kmemcheck_show_addr(fallback_address);</span>
<span class="p_del">-		kmemcheck_error_save_bug(regs);</span>
<span class="p_del">-		return;</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">-	data-&gt;busy = true;</span>
<span class="p_del">-</span>
<span class="p_del">-	insn = (const uint8_t *) regs-&gt;ip;</span>
<span class="p_del">-	insn_primary = kmemcheck_opcode_get_primary(insn);</span>
<span class="p_del">-</span>
<span class="p_del">-	kmemcheck_opcode_decode(insn, &amp;size);</span>
<span class="p_del">-</span>
<span class="p_del">-	switch (insn_primary[0]) {</span>
<span class="p_del">-#ifdef CONFIG_KMEMCHECK_BITOPS_OK</span>
<span class="p_del">-		/* AND, OR, XOR */</span>
<span class="p_del">-		/*</span>
<span class="p_del">-		 * Unfortunately, these instructions have to be excluded from</span>
<span class="p_del">-		 * our regular checking since they access only some (and not</span>
<span class="p_del">-		 * all) bits. This clears out &quot;bogus&quot; bitfield-access warnings.</span>
<span class="p_del">-		 */</span>
<span class="p_del">-	case 0x80:</span>
<span class="p_del">-	case 0x81:</span>
<span class="p_del">-	case 0x82:</span>
<span class="p_del">-	case 0x83:</span>
<span class="p_del">-		switch ((insn_primary[1] &gt;&gt; 3) &amp; 7) {</span>
<span class="p_del">-			/* OR */</span>
<span class="p_del">-		case 1:</span>
<span class="p_del">-			/* AND */</span>
<span class="p_del">-		case 4:</span>
<span class="p_del">-			/* XOR */</span>
<span class="p_del">-		case 6:</span>
<span class="p_del">-			kmemcheck_write(regs, fallback_address, size);</span>
<span class="p_del">-			goto out;</span>
<span class="p_del">-</span>
<span class="p_del">-			/* ADD */</span>
<span class="p_del">-		case 0:</span>
<span class="p_del">-			/* ADC */</span>
<span class="p_del">-		case 2:</span>
<span class="p_del">-			/* SBB */</span>
<span class="p_del">-		case 3:</span>
<span class="p_del">-			/* SUB */</span>
<span class="p_del">-		case 5:</span>
<span class="p_del">-			/* CMP */</span>
<span class="p_del">-		case 7:</span>
<span class="p_del">-			break;</span>
<span class="p_del">-		}</span>
<span class="p_del">-		break;</span>
<span class="p_del">-#endif</span>
<span class="p_del">-</span>
<span class="p_del">-		/* MOVS, MOVSB, MOVSW, MOVSD */</span>
<span class="p_del">-	case 0xa4:</span>
<span class="p_del">-	case 0xa5:</span>
<span class="p_del">-		/*</span>
<span class="p_del">-		 * These instructions are special because they take two</span>
<span class="p_del">-		 * addresses, but we only get one page fault.</span>
<span class="p_del">-		 */</span>
<span class="p_del">-		kmemcheck_copy(regs, regs-&gt;si, regs-&gt;di, size);</span>
<span class="p_del">-		goto out;</span>
<span class="p_del">-</span>
<span class="p_del">-		/* CMPS, CMPSB, CMPSW, CMPSD */</span>
<span class="p_del">-	case 0xa6:</span>
<span class="p_del">-	case 0xa7:</span>
<span class="p_del">-		kmemcheck_read(regs, regs-&gt;si, size);</span>
<span class="p_del">-		kmemcheck_read(regs, regs-&gt;di, size);</span>
<span class="p_del">-		goto out;</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">-	/*</span>
<span class="p_del">-	 * If the opcode isn&#39;t special in any way, we use the data from the</span>
<span class="p_del">-	 * page fault handler to determine the address and type of memory</span>
<span class="p_del">-	 * access.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	switch (fallback_method) {</span>
<span class="p_del">-	case KMEMCHECK_READ:</span>
<span class="p_del">-		kmemcheck_read(regs, fallback_address, size);</span>
<span class="p_del">-		goto out;</span>
<span class="p_del">-	case KMEMCHECK_WRITE:</span>
<span class="p_del">-		kmemcheck_write(regs, fallback_address, size);</span>
<span class="p_del">-		goto out;</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">-out:</span>
<span class="p_del">-	data-&gt;busy = false;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-bool kmemcheck_fault(struct pt_regs *regs, unsigned long address,</span>
<span class="p_del">-	unsigned long error_code)</span>
<span class="p_del">-{</span>
<span class="p_del">-	pte_t *pte;</span>
<span class="p_del">-</span>
<span class="p_del">-	/*</span>
<span class="p_del">-	 * XXX: Is it safe to assume that memory accesses from virtual 86</span>
<span class="p_del">-	 * mode or non-kernel code segments will _never_ access kernel</span>
<span class="p_del">-	 * memory (e.g. tracked pages)? For now, we need this to avoid</span>
<span class="p_del">-	 * invoking kmemcheck for PnP BIOS calls.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	if (regs-&gt;flags &amp; X86_VM_MASK)</span>
<span class="p_del">-		return false;</span>
<span class="p_del">-	if (regs-&gt;cs != __KERNEL_CS)</span>
<span class="p_del">-		return false;</span>
<span class="p_del">-</span>
<span class="p_del">-	pte = kmemcheck_pte_lookup(address);</span>
<span class="p_del">-	if (!pte)</span>
<span class="p_del">-		return false;</span>
<span class="p_del">-</span>
<span class="p_del">-	WARN_ON_ONCE(in_nmi());</span>
<span class="p_del">-</span>
<span class="p_del">-	if (error_code &amp; 2)</span>
<span class="p_del">-		kmemcheck_access(regs, address, KMEMCHECK_WRITE);</span>
<span class="p_del">-	else</span>
<span class="p_del">-		kmemcheck_access(regs, address, KMEMCHECK_READ);</span>
<span class="p_del">-</span>
<span class="p_del">-	kmemcheck_show(regs);</span>
<span class="p_del">-	return true;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-bool kmemcheck_trap(struct pt_regs *regs)</span>
<span class="p_del">-{</span>
<span class="p_del">-	if (!kmemcheck_active(regs))</span>
<span class="p_del">-		return false;</span>
<span class="p_del">-</span>
<span class="p_del">-	/* We&#39;re done. */</span>
<span class="p_del">-	kmemcheck_hide(regs);</span>
<span class="p_del">-	return true;</span>
<span class="p_del">-}</span>
<span class="p_header">diff --git a/arch/x86/mm/kmemcheck/opcode.c b/arch/x86/mm/kmemcheck/opcode.c</span>
deleted file mode 100644
<span class="p_header">index 324aa3f07237..000000000000</span>
<span class="p_header">--- a/arch/x86/mm/kmemcheck/opcode.c</span>
<span class="p_header">+++ /dev/null</span>
<span class="p_chunk">@@ -1,106 +0,0 @@</span> <span class="p_context"></span>
<span class="p_del">-#include &lt;linux/types.h&gt;</span>
<span class="p_del">-</span>
<span class="p_del">-#include &quot;opcode.h&quot;</span>
<span class="p_del">-</span>
<span class="p_del">-static bool opcode_is_prefix(uint8_t b)</span>
<span class="p_del">-{</span>
<span class="p_del">-	return</span>
<span class="p_del">-		/* Group 1 */</span>
<span class="p_del">-		b == 0xf0 || b == 0xf2 || b == 0xf3</span>
<span class="p_del">-		/* Group 2 */</span>
<span class="p_del">-		|| b == 0x2e || b == 0x36 || b == 0x3e || b == 0x26</span>
<span class="p_del">-		|| b == 0x64 || b == 0x65</span>
<span class="p_del">-		/* Group 3 */</span>
<span class="p_del">-		|| b == 0x66</span>
<span class="p_del">-		/* Group 4 */</span>
<span class="p_del">-		|| b == 0x67;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-#ifdef CONFIG_X86_64</span>
<span class="p_del">-static bool opcode_is_rex_prefix(uint8_t b)</span>
<span class="p_del">-{</span>
<span class="p_del">-	return (b &amp; 0xf0) == 0x40;</span>
<span class="p_del">-}</span>
<span class="p_del">-#else</span>
<span class="p_del">-static bool opcode_is_rex_prefix(uint8_t b)</span>
<span class="p_del">-{</span>
<span class="p_del">-	return false;</span>
<span class="p_del">-}</span>
<span class="p_del">-#endif</span>
<span class="p_del">-</span>
<span class="p_del">-#define REX_W (1 &lt;&lt; 3)</span>
<span class="p_del">-</span>
<span class="p_del">-/*</span>
<span class="p_del">- * This is a VERY crude opcode decoder. We only need to find the size of the</span>
<span class="p_del">- * load/store that caused our #PF and this should work for all the opcodes</span>
<span class="p_del">- * that we care about. Moreover, the ones who invented this instruction set</span>
<span class="p_del">- * should be shot.</span>
<span class="p_del">- */</span>
<span class="p_del">-void kmemcheck_opcode_decode(const uint8_t *op, unsigned int *size)</span>
<span class="p_del">-{</span>
<span class="p_del">-	/* Default operand size */</span>
<span class="p_del">-	int operand_size_override = 4;</span>
<span class="p_del">-</span>
<span class="p_del">-	/* prefixes */</span>
<span class="p_del">-	for (; opcode_is_prefix(*op); ++op) {</span>
<span class="p_del">-		if (*op == 0x66)</span>
<span class="p_del">-			operand_size_override = 2;</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">-	/* REX prefix */</span>
<span class="p_del">-	if (opcode_is_rex_prefix(*op)) {</span>
<span class="p_del">-		uint8_t rex = *op;</span>
<span class="p_del">-</span>
<span class="p_del">-		++op;</span>
<span class="p_del">-		if (rex &amp; REX_W) {</span>
<span class="p_del">-			switch (*op) {</span>
<span class="p_del">-			case 0x63:</span>
<span class="p_del">-				*size = 4;</span>
<span class="p_del">-				return;</span>
<span class="p_del">-			case 0x0f:</span>
<span class="p_del">-				++op;</span>
<span class="p_del">-</span>
<span class="p_del">-				switch (*op) {</span>
<span class="p_del">-				case 0xb6:</span>
<span class="p_del">-				case 0xbe:</span>
<span class="p_del">-					*size = 1;</span>
<span class="p_del">-					return;</span>
<span class="p_del">-				case 0xb7:</span>
<span class="p_del">-				case 0xbf:</span>
<span class="p_del">-					*size = 2;</span>
<span class="p_del">-					return;</span>
<span class="p_del">-				}</span>
<span class="p_del">-</span>
<span class="p_del">-				break;</span>
<span class="p_del">-			}</span>
<span class="p_del">-</span>
<span class="p_del">-			*size = 8;</span>
<span class="p_del">-			return;</span>
<span class="p_del">-		}</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">-	/* escape opcode */</span>
<span class="p_del">-	if (*op == 0x0f) {</span>
<span class="p_del">-		++op;</span>
<span class="p_del">-</span>
<span class="p_del">-		/*</span>
<span class="p_del">-		 * This is move with zero-extend and sign-extend, respectively;</span>
<span class="p_del">-		 * we don&#39;t have to think about 0xb6/0xbe, because this is</span>
<span class="p_del">-		 * already handled in the conditional below.</span>
<span class="p_del">-		 */</span>
<span class="p_del">-		if (*op == 0xb7 || *op == 0xbf)</span>
<span class="p_del">-			operand_size_override = 2;</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">-	*size = (*op &amp; 1) ? operand_size_override : 1;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-const uint8_t *kmemcheck_opcode_get_primary(const uint8_t *op)</span>
<span class="p_del">-{</span>
<span class="p_del">-	/* skip prefixes */</span>
<span class="p_del">-	while (opcode_is_prefix(*op))</span>
<span class="p_del">-		++op;</span>
<span class="p_del">-	if (opcode_is_rex_prefix(*op))</span>
<span class="p_del">-		++op;</span>
<span class="p_del">-	return op;</span>
<span class="p_del">-}</span>
<span class="p_header">diff --git a/arch/x86/mm/kmemcheck/opcode.h b/arch/x86/mm/kmemcheck/opcode.h</span>
deleted file mode 100644
<span class="p_header">index 6956aad66b5b..000000000000</span>
<span class="p_header">--- a/arch/x86/mm/kmemcheck/opcode.h</span>
<span class="p_header">+++ /dev/null</span>
<span class="p_chunk">@@ -1,9 +0,0 @@</span> <span class="p_context"></span>
<span class="p_del">-#ifndef ARCH__X86__MM__KMEMCHECK__OPCODE_H</span>
<span class="p_del">-#define ARCH__X86__MM__KMEMCHECK__OPCODE_H</span>
<span class="p_del">-</span>
<span class="p_del">-#include &lt;linux/types.h&gt;</span>
<span class="p_del">-</span>
<span class="p_del">-void kmemcheck_opcode_decode(const uint8_t *op, unsigned int *size);</span>
<span class="p_del">-const uint8_t *kmemcheck_opcode_get_primary(const uint8_t *op);</span>
<span class="p_del">-</span>
<span class="p_del">-#endif</span>
<span class="p_header">diff --git a/arch/x86/mm/kmemcheck/pte.c b/arch/x86/mm/kmemcheck/pte.c</span>
deleted file mode 100644
<span class="p_header">index 4ead26eeaf96..000000000000</span>
<span class="p_header">--- a/arch/x86/mm/kmemcheck/pte.c</span>
<span class="p_header">+++ /dev/null</span>
<span class="p_chunk">@@ -1,22 +0,0 @@</span> <span class="p_context"></span>
<span class="p_del">-#include &lt;linux/mm.h&gt;</span>
<span class="p_del">-</span>
<span class="p_del">-#include &lt;asm/pgtable.h&gt;</span>
<span class="p_del">-</span>
<span class="p_del">-#include &quot;pte.h&quot;</span>
<span class="p_del">-</span>
<span class="p_del">-pte_t *kmemcheck_pte_lookup(unsigned long address)</span>
<span class="p_del">-{</span>
<span class="p_del">-	pte_t *pte;</span>
<span class="p_del">-	unsigned int level;</span>
<span class="p_del">-</span>
<span class="p_del">-	pte = lookup_address(address, &amp;level);</span>
<span class="p_del">-	if (!pte)</span>
<span class="p_del">-		return NULL;</span>
<span class="p_del">-	if (level != PG_LEVEL_4K)</span>
<span class="p_del">-		return NULL;</span>
<span class="p_del">-	if (!pte_hidden(*pte))</span>
<span class="p_del">-		return NULL;</span>
<span class="p_del">-</span>
<span class="p_del">-	return pte;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_header">diff --git a/arch/x86/mm/kmemcheck/pte.h b/arch/x86/mm/kmemcheck/pte.h</span>
deleted file mode 100644
<span class="p_header">index 9f5966456492..000000000000</span>
<span class="p_header">--- a/arch/x86/mm/kmemcheck/pte.h</span>
<span class="p_header">+++ /dev/null</span>
<span class="p_chunk">@@ -1,10 +0,0 @@</span> <span class="p_context"></span>
<span class="p_del">-#ifndef ARCH__X86__MM__KMEMCHECK__PTE_H</span>
<span class="p_del">-#define ARCH__X86__MM__KMEMCHECK__PTE_H</span>
<span class="p_del">-</span>
<span class="p_del">-#include &lt;linux/mm.h&gt;</span>
<span class="p_del">-</span>
<span class="p_del">-#include &lt;asm/pgtable.h&gt;</span>
<span class="p_del">-</span>
<span class="p_del">-pte_t *kmemcheck_pte_lookup(unsigned long address);</span>
<span class="p_del">-</span>
<span class="p_del">-#endif</span>
<span class="p_header">diff --git a/arch/x86/mm/kmemcheck/selftest.c b/arch/x86/mm/kmemcheck/selftest.c</span>
deleted file mode 100644
<span class="p_header">index aef7140c0063..000000000000</span>
<span class="p_header">--- a/arch/x86/mm/kmemcheck/selftest.c</span>
<span class="p_header">+++ /dev/null</span>
<span class="p_chunk">@@ -1,70 +0,0 @@</span> <span class="p_context"></span>
<span class="p_del">-#include &lt;linux/bug.h&gt;</span>
<span class="p_del">-#include &lt;linux/kernel.h&gt;</span>
<span class="p_del">-</span>
<span class="p_del">-#include &quot;opcode.h&quot;</span>
<span class="p_del">-#include &quot;selftest.h&quot;</span>
<span class="p_del">-</span>
<span class="p_del">-struct selftest_opcode {</span>
<span class="p_del">-	unsigned int expected_size;</span>
<span class="p_del">-	const uint8_t *insn;</span>
<span class="p_del">-	const char *desc;</span>
<span class="p_del">-};</span>
<span class="p_del">-</span>
<span class="p_del">-static const struct selftest_opcode selftest_opcodes[] = {</span>
<span class="p_del">-	/* REP MOVS */</span>
<span class="p_del">-	{1, &quot;\xf3\xa4&quot;, 		&quot;rep movsb &lt;mem8&gt;, &lt;mem8&gt;&quot;},</span>
<span class="p_del">-	{4, &quot;\xf3\xa5&quot;,			&quot;rep movsl &lt;mem32&gt;, &lt;mem32&gt;&quot;},</span>
<span class="p_del">-</span>
<span class="p_del">-	/* MOVZX / MOVZXD */</span>
<span class="p_del">-	{1, &quot;\x66\x0f\xb6\x51\xf8&quot;,	&quot;movzwq &lt;mem8&gt;, &lt;reg16&gt;&quot;},</span>
<span class="p_del">-	{1, &quot;\x0f\xb6\x51\xf8&quot;,		&quot;movzwq &lt;mem8&gt;, &lt;reg32&gt;&quot;},</span>
<span class="p_del">-</span>
<span class="p_del">-	/* MOVSX / MOVSXD */</span>
<span class="p_del">-	{1, &quot;\x66\x0f\xbe\x51\xf8&quot;,	&quot;movswq &lt;mem8&gt;, &lt;reg16&gt;&quot;},</span>
<span class="p_del">-	{1, &quot;\x0f\xbe\x51\xf8&quot;,		&quot;movswq &lt;mem8&gt;, &lt;reg32&gt;&quot;},</span>
<span class="p_del">-</span>
<span class="p_del">-#ifdef CONFIG_X86_64</span>
<span class="p_del">-	/* MOVZX / MOVZXD */</span>
<span class="p_del">-	{1, &quot;\x49\x0f\xb6\x51\xf8&quot;,	&quot;movzbq &lt;mem8&gt;, &lt;reg64&gt;&quot;},</span>
<span class="p_del">-	{2, &quot;\x49\x0f\xb7\x51\xf8&quot;,	&quot;movzbq &lt;mem16&gt;, &lt;reg64&gt;&quot;},</span>
<span class="p_del">-</span>
<span class="p_del">-	/* MOVSX / MOVSXD */</span>
<span class="p_del">-	{1, &quot;\x49\x0f\xbe\x51\xf8&quot;,	&quot;movsbq &lt;mem8&gt;, &lt;reg64&gt;&quot;},</span>
<span class="p_del">-	{2, &quot;\x49\x0f\xbf\x51\xf8&quot;,	&quot;movsbq &lt;mem16&gt;, &lt;reg64&gt;&quot;},</span>
<span class="p_del">-	{4, &quot;\x49\x63\x51\xf8&quot;,		&quot;movslq &lt;mem32&gt;, &lt;reg64&gt;&quot;},</span>
<span class="p_del">-#endif</span>
<span class="p_del">-};</span>
<span class="p_del">-</span>
<span class="p_del">-static bool selftest_opcode_one(const struct selftest_opcode *op)</span>
<span class="p_del">-{</span>
<span class="p_del">-	unsigned size;</span>
<span class="p_del">-</span>
<span class="p_del">-	kmemcheck_opcode_decode(op-&gt;insn, &amp;size);</span>
<span class="p_del">-</span>
<span class="p_del">-	if (size == op-&gt;expected_size)</span>
<span class="p_del">-		return true;</span>
<span class="p_del">-</span>
<span class="p_del">-	printk(KERN_WARNING &quot;kmemcheck: opcode %s: expected size %d, got %d\n&quot;,</span>
<span class="p_del">-		op-&gt;desc, op-&gt;expected_size, size);</span>
<span class="p_del">-	return false;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static bool selftest_opcodes_all(void)</span>
<span class="p_del">-{</span>
<span class="p_del">-	bool pass = true;</span>
<span class="p_del">-	unsigned int i;</span>
<span class="p_del">-</span>
<span class="p_del">-	for (i = 0; i &lt; ARRAY_SIZE(selftest_opcodes); ++i)</span>
<span class="p_del">-		pass = pass &amp;&amp; selftest_opcode_one(&amp;selftest_opcodes[i]);</span>
<span class="p_del">-</span>
<span class="p_del">-	return pass;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-bool kmemcheck_selftest(void)</span>
<span class="p_del">-{</span>
<span class="p_del">-	bool pass = true;</span>
<span class="p_del">-</span>
<span class="p_del">-	pass = pass &amp;&amp; selftest_opcodes_all();</span>
<span class="p_del">-</span>
<span class="p_del">-	return pass;</span>
<span class="p_del">-}</span>
<span class="p_header">diff --git a/arch/x86/mm/kmemcheck/selftest.h b/arch/x86/mm/kmemcheck/selftest.h</span>
deleted file mode 100644
<span class="p_header">index 8fed4fe11f95..000000000000</span>
<span class="p_header">--- a/arch/x86/mm/kmemcheck/selftest.h</span>
<span class="p_header">+++ /dev/null</span>
<span class="p_chunk">@@ -1,6 +0,0 @@</span> <span class="p_context"></span>
<span class="p_del">-#ifndef ARCH_X86_MM_KMEMCHECK_SELFTEST_H</span>
<span class="p_del">-#define ARCH_X86_MM_KMEMCHECK_SELFTEST_H</span>
<span class="p_del">-</span>
<span class="p_del">-bool kmemcheck_selftest(void);</span>
<span class="p_del">-</span>
<span class="p_del">-#endif</span>
<span class="p_header">diff --git a/arch/x86/mm/kmemcheck/shadow.c b/arch/x86/mm/kmemcheck/shadow.c</span>
deleted file mode 100644
<span class="p_header">index c2638a7d2c10..000000000000</span>
<span class="p_header">--- a/arch/x86/mm/kmemcheck/shadow.c</span>
<span class="p_header">+++ /dev/null</span>
<span class="p_chunk">@@ -1,173 +0,0 @@</span> <span class="p_context"></span>
<span class="p_del">-#include &lt;linux/kmemcheck.h&gt;</span>
<span class="p_del">-#include &lt;linux/export.h&gt;</span>
<span class="p_del">-#include &lt;linux/mm.h&gt;</span>
<span class="p_del">-</span>
<span class="p_del">-#include &lt;asm/page.h&gt;</span>
<span class="p_del">-#include &lt;asm/pgtable.h&gt;</span>
<span class="p_del">-</span>
<span class="p_del">-#include &quot;pte.h&quot;</span>
<span class="p_del">-#include &quot;shadow.h&quot;</span>
<span class="p_del">-</span>
<span class="p_del">-/*</span>
<span class="p_del">- * Return the shadow address for the given address. Returns NULL if the</span>
<span class="p_del">- * address is not tracked.</span>
<span class="p_del">- *</span>
<span class="p_del">- * We need to be extremely careful not to follow any invalid pointers,</span>
<span class="p_del">- * because this function can be called for *any* possible address.</span>
<span class="p_del">- */</span>
<span class="p_del">-void *kmemcheck_shadow_lookup(unsigned long address)</span>
<span class="p_del">-{</span>
<span class="p_del">-	pte_t *pte;</span>
<span class="p_del">-	struct page *page;</span>
<span class="p_del">-</span>
<span class="p_del">-	if (!virt_addr_valid(address))</span>
<span class="p_del">-		return NULL;</span>
<span class="p_del">-</span>
<span class="p_del">-	pte = kmemcheck_pte_lookup(address);</span>
<span class="p_del">-	if (!pte)</span>
<span class="p_del">-		return NULL;</span>
<span class="p_del">-</span>
<span class="p_del">-	page = virt_to_page(address);</span>
<span class="p_del">-	if (!page-&gt;shadow)</span>
<span class="p_del">-		return NULL;</span>
<span class="p_del">-	return page-&gt;shadow + (address &amp; (PAGE_SIZE - 1));</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static void mark_shadow(void *address, unsigned int n,</span>
<span class="p_del">-	enum kmemcheck_shadow status)</span>
<span class="p_del">-{</span>
<span class="p_del">-	unsigned long addr = (unsigned long) address;</span>
<span class="p_del">-	unsigned long last_addr = addr + n - 1;</span>
<span class="p_del">-	unsigned long page = addr &amp; PAGE_MASK;</span>
<span class="p_del">-	unsigned long last_page = last_addr &amp; PAGE_MASK;</span>
<span class="p_del">-	unsigned int first_n;</span>
<span class="p_del">-	void *shadow;</span>
<span class="p_del">-</span>
<span class="p_del">-	/* If the memory range crosses a page boundary, stop there. */</span>
<span class="p_del">-	if (page == last_page)</span>
<span class="p_del">-		first_n = n;</span>
<span class="p_del">-	else</span>
<span class="p_del">-		first_n = page + PAGE_SIZE - addr;</span>
<span class="p_del">-</span>
<span class="p_del">-	shadow = kmemcheck_shadow_lookup(addr);</span>
<span class="p_del">-	if (shadow)</span>
<span class="p_del">-		memset(shadow, status, first_n);</span>
<span class="p_del">-</span>
<span class="p_del">-	addr += first_n;</span>
<span class="p_del">-	n -= first_n;</span>
<span class="p_del">-</span>
<span class="p_del">-	/* Do full-page memset()s. */</span>
<span class="p_del">-	while (n &gt;= PAGE_SIZE) {</span>
<span class="p_del">-		shadow = kmemcheck_shadow_lookup(addr);</span>
<span class="p_del">-		if (shadow)</span>
<span class="p_del">-			memset(shadow, status, PAGE_SIZE);</span>
<span class="p_del">-</span>
<span class="p_del">-		addr += PAGE_SIZE;</span>
<span class="p_del">-		n -= PAGE_SIZE;</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">-	/* Do the remaining page, if any. */</span>
<span class="p_del">-	if (n &gt; 0) {</span>
<span class="p_del">-		shadow = kmemcheck_shadow_lookup(addr);</span>
<span class="p_del">-		if (shadow)</span>
<span class="p_del">-			memset(shadow, status, n);</span>
<span class="p_del">-	}</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-void kmemcheck_mark_unallocated(void *address, unsigned int n)</span>
<span class="p_del">-{</span>
<span class="p_del">-	mark_shadow(address, n, KMEMCHECK_SHADOW_UNALLOCATED);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-void kmemcheck_mark_uninitialized(void *address, unsigned int n)</span>
<span class="p_del">-{</span>
<span class="p_del">-	mark_shadow(address, n, KMEMCHECK_SHADOW_UNINITIALIZED);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-/*</span>
<span class="p_del">- * Fill the shadow memory of the given address such that the memory at that</span>
<span class="p_del">- * address is marked as being initialized.</span>
<span class="p_del">- */</span>
<span class="p_del">-void kmemcheck_mark_initialized(void *address, unsigned int n)</span>
<span class="p_del">-{</span>
<span class="p_del">-	mark_shadow(address, n, KMEMCHECK_SHADOW_INITIALIZED);</span>
<span class="p_del">-}</span>
<span class="p_del">-EXPORT_SYMBOL_GPL(kmemcheck_mark_initialized);</span>
<span class="p_del">-</span>
<span class="p_del">-void kmemcheck_mark_freed(void *address, unsigned int n)</span>
<span class="p_del">-{</span>
<span class="p_del">-	mark_shadow(address, n, KMEMCHECK_SHADOW_FREED);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-void kmemcheck_mark_unallocated_pages(struct page *p, unsigned int n)</span>
<span class="p_del">-{</span>
<span class="p_del">-	unsigned int i;</span>
<span class="p_del">-</span>
<span class="p_del">-	for (i = 0; i &lt; n; ++i)</span>
<span class="p_del">-		kmemcheck_mark_unallocated(page_address(&amp;p[i]), PAGE_SIZE);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-void kmemcheck_mark_uninitialized_pages(struct page *p, unsigned int n)</span>
<span class="p_del">-{</span>
<span class="p_del">-	unsigned int i;</span>
<span class="p_del">-</span>
<span class="p_del">-	for (i = 0; i &lt; n; ++i)</span>
<span class="p_del">-		kmemcheck_mark_uninitialized(page_address(&amp;p[i]), PAGE_SIZE);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-void kmemcheck_mark_initialized_pages(struct page *p, unsigned int n)</span>
<span class="p_del">-{</span>
<span class="p_del">-	unsigned int i;</span>
<span class="p_del">-</span>
<span class="p_del">-	for (i = 0; i &lt; n; ++i)</span>
<span class="p_del">-		kmemcheck_mark_initialized(page_address(&amp;p[i]), PAGE_SIZE);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-enum kmemcheck_shadow kmemcheck_shadow_test(void *shadow, unsigned int size)</span>
<span class="p_del">-{</span>
<span class="p_del">-#ifdef CONFIG_KMEMCHECK_PARTIAL_OK</span>
<span class="p_del">-	uint8_t *x;</span>
<span class="p_del">-	unsigned int i;</span>
<span class="p_del">-</span>
<span class="p_del">-	x = shadow;</span>
<span class="p_del">-</span>
<span class="p_del">-	/*</span>
<span class="p_del">-	 * Make sure _some_ bytes are initialized. Gcc frequently generates</span>
<span class="p_del">-	 * code to access neighboring bytes.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	for (i = 0; i &lt; size; ++i) {</span>
<span class="p_del">-		if (x[i] == KMEMCHECK_SHADOW_INITIALIZED)</span>
<span class="p_del">-			return x[i];</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">-	return x[0];</span>
<span class="p_del">-#else</span>
<span class="p_del">-	return kmemcheck_shadow_test_all(shadow, size);</span>
<span class="p_del">-#endif</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-enum kmemcheck_shadow kmemcheck_shadow_test_all(void *shadow, unsigned int size)</span>
<span class="p_del">-{</span>
<span class="p_del">-	uint8_t *x;</span>
<span class="p_del">-	unsigned int i;</span>
<span class="p_del">-</span>
<span class="p_del">-	x = shadow;</span>
<span class="p_del">-</span>
<span class="p_del">-	/* All bytes must be initialized. */</span>
<span class="p_del">-	for (i = 0; i &lt; size; ++i) {</span>
<span class="p_del">-		if (x[i] != KMEMCHECK_SHADOW_INITIALIZED)</span>
<span class="p_del">-			return x[i];</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">-	return x[0];</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-void kmemcheck_shadow_set(void *shadow, unsigned int size)</span>
<span class="p_del">-{</span>
<span class="p_del">-	uint8_t *x;</span>
<span class="p_del">-	unsigned int i;</span>
<span class="p_del">-</span>
<span class="p_del">-	x = shadow;</span>
<span class="p_del">-	for (i = 0; i &lt; size; ++i)</span>
<span class="p_del">-		x[i] = KMEMCHECK_SHADOW_INITIALIZED;</span>
<span class="p_del">-}</span>
<span class="p_header">diff --git a/arch/x86/mm/kmemcheck/shadow.h b/arch/x86/mm/kmemcheck/shadow.h</span>
deleted file mode 100644
<span class="p_header">index ff0b2f70fbcb..000000000000</span>
<span class="p_header">--- a/arch/x86/mm/kmemcheck/shadow.h</span>
<span class="p_header">+++ /dev/null</span>
<span class="p_chunk">@@ -1,18 +0,0 @@</span> <span class="p_context"></span>
<span class="p_del">-#ifndef ARCH__X86__MM__KMEMCHECK__SHADOW_H</span>
<span class="p_del">-#define ARCH__X86__MM__KMEMCHECK__SHADOW_H</span>
<span class="p_del">-</span>
<span class="p_del">-enum kmemcheck_shadow {</span>
<span class="p_del">-	KMEMCHECK_SHADOW_UNALLOCATED,</span>
<span class="p_del">-	KMEMCHECK_SHADOW_UNINITIALIZED,</span>
<span class="p_del">-	KMEMCHECK_SHADOW_INITIALIZED,</span>
<span class="p_del">-	KMEMCHECK_SHADOW_FREED,</span>
<span class="p_del">-};</span>
<span class="p_del">-</span>
<span class="p_del">-void *kmemcheck_shadow_lookup(unsigned long address);</span>
<span class="p_del">-</span>
<span class="p_del">-enum kmemcheck_shadow kmemcheck_shadow_test(void *shadow, unsigned int size);</span>
<span class="p_del">-enum kmemcheck_shadow kmemcheck_shadow_test_all(void *shadow,</span>
<span class="p_del">-						unsigned int size);</span>
<span class="p_del">-void kmemcheck_shadow_set(void *shadow, unsigned int size);</span>
<span class="p_del">-</span>
<span class="p_del">-#endif</span>
<span class="p_header">diff --git a/include/linux/dma-mapping.h b/include/linux/dma-mapping.h</span>
<span class="p_header">index 0977317c6835..25695c3e8904 100644</span>
<span class="p_header">--- a/include/linux/dma-mapping.h</span>
<span class="p_header">+++ b/include/linux/dma-mapping.h</span>
<span class="p_chunk">@@ -8,7 +8,6 @@</span> <span class="p_context"></span>
 #include &lt;linux/dma-debug.h&gt;
 #include &lt;linux/dma-direction.h&gt;
 #include &lt;linux/scatterlist.h&gt;
<span class="p_del">-#include &lt;linux/kmemcheck.h&gt;</span>
 #include &lt;linux/bug.h&gt;
 
 /**
<span class="p_chunk">@@ -205,7 +204,6 @@</span> <span class="p_context"> static inline dma_addr_t dma_map_single_attrs(struct device *dev, void *ptr,</span>
 	const struct dma_map_ops *ops = get_dma_ops(dev);
 	dma_addr_t addr;
 
<span class="p_del">-	kmemcheck_mark_initialized(ptr, size);</span>
 	BUG_ON(!valid_dma_direction(dir));
 	addr = ops-&gt;map_page(dev, virt_to_page(ptr),
 			     offset_in_page(ptr), size,
<span class="p_chunk">@@ -238,11 +236,8 @@</span> <span class="p_context"> static inline int dma_map_sg_attrs(struct device *dev, struct scatterlist *sg,</span>
 				   unsigned long attrs)
 {
 	const struct dma_map_ops *ops = get_dma_ops(dev);
<span class="p_del">-	int i, ents;</span>
<span class="p_del">-	struct scatterlist *s;</span>
<span class="p_add">+	int ents;</span>
 
<span class="p_del">-	for_each_sg(sg, s, nents, i)</span>
<span class="p_del">-		kmemcheck_mark_initialized(sg_virt(s), s-&gt;length);</span>
 	BUG_ON(!valid_dma_direction(dir));
 	ents = ops-&gt;map_sg(dev, sg, nents, dir, attrs);
 	BUG_ON(ents &lt; 0);
<span class="p_chunk">@@ -272,7 +267,6 @@</span> <span class="p_context"> static inline dma_addr_t dma_map_page_attrs(struct device *dev,</span>
 	const struct dma_map_ops *ops = get_dma_ops(dev);
 	dma_addr_t addr;
 
<span class="p_del">-	kmemcheck_mark_initialized(page_address(page) + offset, size);</span>
 	BUG_ON(!valid_dma_direction(dir));
 	addr = ops-&gt;map_page(dev, page, offset, size, dir, attrs);
 	debug_dma_map_page(dev, page, offset, size, dir, addr, false);
<span class="p_header">diff --git a/include/linux/gfp.h b/include/linux/gfp.h</span>
<span class="p_header">index db373b9d3223..c76c89586fff 100644</span>
<span class="p_header">--- a/include/linux/gfp.h</span>
<span class="p_header">+++ b/include/linux/gfp.h</span>
<span class="p_chunk">@@ -166,8 +166,6 @@</span> <span class="p_context"> struct vm_area_struct;</span>
  *
  * __GFP_ZERO returns a zeroed page on success.
  *
<span class="p_del">- * __GFP_NOTRACK avoids tracking with kmemcheck.</span>
<span class="p_del">- *</span>
  * __GFP_NOTRACK_FALSE_POSITIVE is an alias of __GFP_NOTRACK. It&#39;s a means of
  *   distinguishing in the source between false positives and allocations that
  *   cannot be supported (e.g. page tables).
<span class="p_header">diff --git a/include/linux/kmemcheck.h b/include/linux/kmemcheck.h</span>
<span class="p_header">index 39f8453239f7..00a371c5a50f 100644</span>
<span class="p_header">--- a/include/linux/kmemcheck.h</span>
<span class="p_header">+++ b/include/linux/kmemcheck.h</span>
<span class="p_chunk">@@ -4,38 +4,6 @@</span> <span class="p_context"></span>
 #include &lt;linux/mm_types.h&gt;
 #include &lt;linux/types.h&gt;
 
<span class="p_del">-#ifdef CONFIG_KMEMCHECK</span>
<span class="p_del">-extern int kmemcheck_enabled;</span>
<span class="p_del">-</span>
<span class="p_del">-/* The slab-related functions. */</span>
<span class="p_del">-void kmemcheck_alloc_shadow(struct page *page, int order, gfp_t flags, int node);</span>
<span class="p_del">-void kmemcheck_free_shadow(struct page *page, int order);</span>
<span class="p_del">-void kmemcheck_slab_alloc(struct kmem_cache *s, gfp_t gfpflags, void *object,</span>
<span class="p_del">-			  size_t size);</span>
<span class="p_del">-void kmemcheck_slab_free(struct kmem_cache *s, void *object, size_t size);</span>
<span class="p_del">-</span>
<span class="p_del">-void kmemcheck_pagealloc_alloc(struct page *p, unsigned int order,</span>
<span class="p_del">-			       gfp_t gfpflags);</span>
<span class="p_del">-</span>
<span class="p_del">-void kmemcheck_show_pages(struct page *p, unsigned int n);</span>
<span class="p_del">-void kmemcheck_hide_pages(struct page *p, unsigned int n);</span>
<span class="p_del">-</span>
<span class="p_del">-bool kmemcheck_page_is_tracked(struct page *p);</span>
<span class="p_del">-</span>
<span class="p_del">-void kmemcheck_mark_unallocated(void *address, unsigned int n);</span>
<span class="p_del">-void kmemcheck_mark_uninitialized(void *address, unsigned int n);</span>
<span class="p_del">-void kmemcheck_mark_initialized(void *address, unsigned int n);</span>
<span class="p_del">-void kmemcheck_mark_freed(void *address, unsigned int n);</span>
<span class="p_del">-</span>
<span class="p_del">-void kmemcheck_mark_unallocated_pages(struct page *p, unsigned int n);</span>
<span class="p_del">-void kmemcheck_mark_uninitialized_pages(struct page *p, unsigned int n);</span>
<span class="p_del">-void kmemcheck_mark_initialized_pages(struct page *p, unsigned int n);</span>
<span class="p_del">-</span>
<span class="p_del">-int kmemcheck_show_addr(unsigned long address);</span>
<span class="p_del">-int kmemcheck_hide_addr(unsigned long address);</span>
<span class="p_del">-</span>
<span class="p_del">-bool kmemcheck_is_obj_initialized(unsigned long addr, size_t size);</span>
<span class="p_del">-</span>
 /*
  * Bitfield annotations
  *
<span class="p_chunk">@@ -61,32 +29,7 @@</span> <span class="p_context"> bool kmemcheck_is_obj_initialized(unsigned long addr, size_t size);</span>
  *     struct a *a = kmalloc(sizeof(struct a), GFP_KERNEL);
  *     kmemcheck_annotate_bitfield(a, flags);
  */
<span class="p_del">-#define kmemcheck_bitfield_begin(name)	\</span>
<span class="p_del">-	int name##_begin[0];</span>
<span class="p_del">-</span>
<span class="p_del">-#define kmemcheck_bitfield_end(name)	\</span>
<span class="p_del">-	int name##_end[0];</span>
<span class="p_del">-</span>
<span class="p_del">-#define kmemcheck_annotate_bitfield(ptr, name)				\</span>
<span class="p_del">-	do {								\</span>
<span class="p_del">-		int _n;							\</span>
<span class="p_del">-									\</span>
<span class="p_del">-		if (!ptr)						\</span>
<span class="p_del">-			break;						\</span>
<span class="p_del">-									\</span>
<span class="p_del">-		_n = (long) &amp;((ptr)-&gt;name##_end)			\</span>
<span class="p_del">-			- (long) &amp;((ptr)-&gt;name##_begin);		\</span>
<span class="p_del">-		BUILD_BUG_ON(_n &lt; 0);					\</span>
<span class="p_del">-									\</span>
<span class="p_del">-		kmemcheck_mark_initialized(&amp;((ptr)-&gt;name##_begin), _n);	\</span>
<span class="p_del">-	} while (0)</span>
<span class="p_del">-</span>
<span class="p_del">-#define kmemcheck_annotate_variable(var)				\</span>
<span class="p_del">-	do {								\</span>
<span class="p_del">-		kmemcheck_mark_initialized(&amp;(var), sizeof(var));	\</span>
<span class="p_del">-	} while (0)							\</span>
 
<span class="p_del">-#else</span>
 #define kmemcheck_enabled 0
 
 static inline void
<span class="p_chunk">@@ -166,6 +109,4 @@</span> <span class="p_context"> static inline bool kmemcheck_is_obj_initialized(unsigned long addr, size_t size)</span>
 	do {					\
 	} while (0)
 
<span class="p_del">-#endif /* CONFIG_KMEMCHECK */</span>
<span class="p_del">-</span>
 #endif /* LINUX_KMEMCHECK_H */
<span class="p_header">diff --git a/include/linux/mm_types.h b/include/linux/mm_types.h</span>
<span class="p_header">index f60f45fe226f..3f4c2f982f78 100644</span>
<span class="p_header">--- a/include/linux/mm_types.h</span>
<span class="p_header">+++ b/include/linux/mm_types.h</span>
<span class="p_chunk">@@ -205,14 +205,6 @@</span> <span class="p_context"> struct page {</span>
 					   not kmapped, ie. highmem) */
 #endif /* WANT_PAGE_VIRTUAL */
 
<span class="p_del">-#ifdef CONFIG_KMEMCHECK</span>
<span class="p_del">-	/*</span>
<span class="p_del">-	 * kmemcheck wants to track the status of each byte in a page; this</span>
<span class="p_del">-	 * is a pointer to such a status block. NULL if not tracked.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	void *shadow;</span>
<span class="p_del">-#endif</span>
<span class="p_del">-</span>
 #ifdef LAST_CPUPID_NOT_IN_PAGE_FLAGS
 	int _last_cpupid;
 #endif
<span class="p_header">diff --git a/include/linux/slab.h b/include/linux/slab.h</span>
<span class="p_header">index 3c37a8c51921..378b51588178 100644</span>
<span class="p_header">--- a/include/linux/slab.h</span>
<span class="p_header">+++ b/include/linux/slab.h</span>
<span class="p_chunk">@@ -75,12 +75,12 @@</span> <span class="p_context"></span>
 
 #define SLAB_NOLEAKTRACE	0x00800000UL	/* Avoid kmemleak tracing */
 
<span class="p_del">-/* Don&#39;t track use of uninitialized memory */</span>
<span class="p_del">-#ifdef CONFIG_KMEMCHECK</span>
<span class="p_del">-# define SLAB_NOTRACK		0x01000000UL</span>
<span class="p_del">-#else</span>
<span class="p_del">-# define SLAB_NOTRACK		0x00000000UL</span>
<span class="p_del">-#endif</span>
<span class="p_add">+/*</span>
<span class="p_add">+ * Used by kmemcheck in the past; obsolete, but kept for the sake of</span>
<span class="p_add">+ * out-of-tree module source backwards compatibility.</span>
<span class="p_add">+ */</span>
<span class="p_add">+#define SLAB_NOTRACK		0</span>
<span class="p_add">+</span>
 #ifdef CONFIG_FAILSLAB
 # define SLAB_FAILSLAB		0x02000000UL	/* Fault injection mark */
 #else
<span class="p_header">diff --git a/init/main.c b/init/main.c</span>
<span class="p_header">index b0c11cbf5ddf..266210a551e5 100644</span>
<span class="p_header">--- a/init/main.c</span>
<span class="p_header">+++ b/init/main.c</span>
<span class="p_chunk">@@ -69,7 +69,6 @@</span> <span class="p_context"></span>
 #include &lt;linux/kgdb.h&gt;
 #include &lt;linux/ftrace.h&gt;
 #include &lt;linux/async.h&gt;
<span class="p_del">-#include &lt;linux/kmemcheck.h&gt;</span>
 #include &lt;linux/sfi.h&gt;
 #include &lt;linux/shmem_fs.h&gt;
 #include &lt;linux/slab.h&gt;
<span class="p_header">diff --git a/kernel/sysctl.c b/kernel/sysctl.c</span>
<span class="p_header">index 8c8714fcb53c..e4fe29cea4ae 100644</span>
<span class="p_header">--- a/kernel/sysctl.c</span>
<span class="p_header">+++ b/kernel/sysctl.c</span>
<span class="p_chunk">@@ -30,7 +30,6 @@</span> <span class="p_context"></span>
 #include &lt;linux/proc_fs.h&gt;
 #include &lt;linux/security.h&gt;
 #include &lt;linux/ctype.h&gt;
<span class="p_del">-#include &lt;linux/kmemcheck.h&gt;</span>
 #include &lt;linux/kmemleak.h&gt;
 #include &lt;linux/fs.h&gt;
 #include &lt;linux/init.h&gt;
<span class="p_chunk">@@ -1151,15 +1150,6 @@</span> <span class="p_context"> static struct ctl_table kern_table[] = {</span>
 		.extra2		= &amp;one_thousand,
 	},
 #endif
<span class="p_del">-#ifdef CONFIG_KMEMCHECK</span>
<span class="p_del">-	{</span>
<span class="p_del">-		.procname	= &quot;kmemcheck&quot;,</span>
<span class="p_del">-		.data		= &amp;kmemcheck_enabled,</span>
<span class="p_del">-		.maxlen		= sizeof(int),</span>
<span class="p_del">-		.mode		= 0644,</span>
<span class="p_del">-		.proc_handler	= proc_dointvec,</span>
<span class="p_del">-	},</span>
<span class="p_del">-#endif</span>
 	{
 		.procname	= &quot;panic_on_warn&quot;,
 		.data		= &amp;panic_on_warn,
<span class="p_header">diff --git a/lib/Kconfig.debug b/lib/Kconfig.debug</span>
<span class="p_header">index fa16c0f82d6e..ad81261e83db 100644</span>
<span class="p_header">--- a/lib/Kconfig.debug</span>
<span class="p_header">+++ b/lib/Kconfig.debug</span>
<span class="p_chunk">@@ -499,7 +499,7 @@</span> <span class="p_context"> config DEBUG_OBJECTS_ENABLE_DEFAULT</span>
 
 config DEBUG_SLAB
 	bool &quot;Debug slab memory allocations&quot;
<span class="p_del">-	depends on DEBUG_KERNEL &amp;&amp; SLAB &amp;&amp; !KMEMCHECK</span>
<span class="p_add">+	depends on DEBUG_KERNEL &amp;&amp; SLAB</span>
 	help
 	  Say Y here to have the kernel do limited verification on memory
 	  allocation as well as poisoning memory on free to catch use of freed
<span class="p_chunk">@@ -511,7 +511,7 @@</span> <span class="p_context"> config DEBUG_SLAB_LEAK</span>
 
 config SLUB_DEBUG_ON
 	bool &quot;SLUB debugging on by default&quot;
<span class="p_del">-	depends on SLUB &amp;&amp; SLUB_DEBUG &amp;&amp; !KMEMCHECK</span>
<span class="p_add">+	depends on SLUB &amp;&amp; SLUB_DEBUG</span>
 	default n
 	help
 	  Boot with debugging on by default. SLUB boots by default with
<span class="p_chunk">@@ -725,8 +725,6 @@</span> <span class="p_context"> config DEBUG_STACKOVERFLOW</span>
 
 	  If in doubt, say &quot;N&quot;.
 
<span class="p_del">-source &quot;lib/Kconfig.kmemcheck&quot;</span>
<span class="p_del">-</span>
 source &quot;lib/Kconfig.kasan&quot;
 
 endmenu # &quot;Memory Debugging&quot;
<span class="p_header">diff --git a/lib/Kconfig.kmemcheck b/lib/Kconfig.kmemcheck</span>
deleted file mode 100644
<span class="p_header">index 846e039a86b4..000000000000</span>
<span class="p_header">--- a/lib/Kconfig.kmemcheck</span>
<span class="p_header">+++ /dev/null</span>
<span class="p_chunk">@@ -1,94 +0,0 @@</span> <span class="p_context"></span>
<span class="p_del">-config HAVE_ARCH_KMEMCHECK</span>
<span class="p_del">-	bool</span>
<span class="p_del">-</span>
<span class="p_del">-if HAVE_ARCH_KMEMCHECK</span>
<span class="p_del">-</span>
<span class="p_del">-menuconfig KMEMCHECK</span>
<span class="p_del">-	bool &quot;kmemcheck: trap use of uninitialized memory&quot;</span>
<span class="p_del">-	depends on DEBUG_KERNEL</span>
<span class="p_del">-	depends on !X86_USE_3DNOW</span>
<span class="p_del">-	depends on SLUB || SLAB</span>
<span class="p_del">-	depends on !CC_OPTIMIZE_FOR_SIZE</span>
<span class="p_del">-	depends on !FUNCTION_TRACER</span>
<span class="p_del">-	select FRAME_POINTER</span>
<span class="p_del">-	select STACKTRACE</span>
<span class="p_del">-	default n</span>
<span class="p_del">-	help</span>
<span class="p_del">-	  This option enables tracing of dynamically allocated kernel memory</span>
<span class="p_del">-	  to see if memory is used before it has been given an initial value.</span>
<span class="p_del">-	  Be aware that this requires half of your memory for bookkeeping and</span>
<span class="p_del">-	  will insert extra code at *every* read and write to tracked memory</span>
<span class="p_del">-	  thus slow down the kernel code (but user code is unaffected).</span>
<span class="p_del">-</span>
<span class="p_del">-	  The kernel may be started with kmemcheck=0 or kmemcheck=1 to disable</span>
<span class="p_del">-	  or enable kmemcheck at boot-time. If the kernel is started with</span>
<span class="p_del">-	  kmemcheck=0, the large memory and CPU overhead is not incurred.</span>
<span class="p_del">-</span>
<span class="p_del">-choice</span>
<span class="p_del">-	prompt &quot;kmemcheck: default mode at boot&quot;</span>
<span class="p_del">-	depends on KMEMCHECK</span>
<span class="p_del">-	default KMEMCHECK_ONESHOT_BY_DEFAULT</span>
<span class="p_del">-	help</span>
<span class="p_del">-	  This option controls the default behaviour of kmemcheck when the</span>
<span class="p_del">-	  kernel boots and no kmemcheck= parameter is given.</span>
<span class="p_del">-</span>
<span class="p_del">-config KMEMCHECK_DISABLED_BY_DEFAULT</span>
<span class="p_del">-	bool &quot;disabled&quot;</span>
<span class="p_del">-	depends on KMEMCHECK</span>
<span class="p_del">-</span>
<span class="p_del">-config KMEMCHECK_ENABLED_BY_DEFAULT</span>
<span class="p_del">-	bool &quot;enabled&quot;</span>
<span class="p_del">-	depends on KMEMCHECK</span>
<span class="p_del">-</span>
<span class="p_del">-config KMEMCHECK_ONESHOT_BY_DEFAULT</span>
<span class="p_del">-	bool &quot;one-shot&quot;</span>
<span class="p_del">-	depends on KMEMCHECK</span>
<span class="p_del">-	help</span>
<span class="p_del">-	  In one-shot mode, only the first error detected is reported before</span>
<span class="p_del">-	  kmemcheck is disabled.</span>
<span class="p_del">-</span>
<span class="p_del">-endchoice</span>
<span class="p_del">-</span>
<span class="p_del">-config KMEMCHECK_QUEUE_SIZE</span>
<span class="p_del">-	int &quot;kmemcheck: error queue size&quot;</span>
<span class="p_del">-	depends on KMEMCHECK</span>
<span class="p_del">-	default 64</span>
<span class="p_del">-	help</span>
<span class="p_del">-	  Select the maximum number of errors to store in the queue. Since</span>
<span class="p_del">-	  errors can occur virtually anywhere and in any context, we need a</span>
<span class="p_del">-	  temporary storage area which is guarantueed not to generate any</span>
<span class="p_del">-	  other faults. The queue will be emptied as soon as a tasklet may</span>
<span class="p_del">-	  be scheduled. If the queue is full, new error reports will be</span>
<span class="p_del">-	  lost.</span>
<span class="p_del">-</span>
<span class="p_del">-config KMEMCHECK_SHADOW_COPY_SHIFT</span>
<span class="p_del">-	int &quot;kmemcheck: shadow copy size (5 =&gt; 32 bytes, 6 =&gt; 64 bytes)&quot;</span>
<span class="p_del">-	depends on KMEMCHECK</span>
<span class="p_del">-	range 2 8</span>
<span class="p_del">-	default 5</span>
<span class="p_del">-	help</span>
<span class="p_del">-	  Select the number of shadow bytes to save along with each entry of</span>
<span class="p_del">-	  the queue. These bytes indicate what parts of an allocation are</span>
<span class="p_del">-	  initialized, uninitialized, etc. and will be displayed when an</span>
<span class="p_del">-	  error is detected to help the debugging of a particular problem.</span>
<span class="p_del">-</span>
<span class="p_del">-config KMEMCHECK_PARTIAL_OK</span>
<span class="p_del">-	bool &quot;kmemcheck: allow partially uninitialized memory&quot;</span>
<span class="p_del">-	depends on KMEMCHECK</span>
<span class="p_del">-	default y</span>
<span class="p_del">-	help</span>
<span class="p_del">-	  This option works around certain GCC optimizations that produce</span>
<span class="p_del">-	  32-bit reads from 16-bit variables where the upper 16 bits are</span>
<span class="p_del">-	  thrown away afterwards. This may of course also hide some real</span>
<span class="p_del">-	  bugs.</span>
<span class="p_del">-</span>
<span class="p_del">-config KMEMCHECK_BITOPS_OK</span>
<span class="p_del">-	bool &quot;kmemcheck: allow bit-field manipulation&quot;</span>
<span class="p_del">-	depends on KMEMCHECK</span>
<span class="p_del">-	default n</span>
<span class="p_del">-	help</span>
<span class="p_del">-	  This option silences warnings that would be generated for bit-field</span>
<span class="p_del">-	  accesses where not all the bits are initialized at the same time.</span>
<span class="p_del">-	  This may also hide some real bugs.</span>
<span class="p_del">-</span>
<span class="p_del">-endif</span>
<span class="p_header">diff --git a/mm/Kconfig.debug b/mm/Kconfig.debug</span>
<span class="p_header">index 79d0fd13b5b3..65b24c33186d 100644</span>
<span class="p_header">--- a/mm/Kconfig.debug</span>
<span class="p_header">+++ b/mm/Kconfig.debug</span>
<span class="p_chunk">@@ -11,7 +11,6 @@</span> <span class="p_context"> config DEBUG_PAGEALLOC</span>
 	bool &quot;Debug page memory allocations&quot;
 	depends on DEBUG_KERNEL
 	depends on !HIBERNATION || ARCH_SUPPORTS_DEBUG_PAGEALLOC &amp;&amp; !PPC &amp;&amp; !SPARC
<span class="p_del">-	depends on !KMEMCHECK</span>
 	select PAGE_EXTENSION
 	select PAGE_POISONING if !ARCH_SUPPORTS_DEBUG_PAGEALLOC
 	---help---
<span class="p_header">diff --git a/mm/Makefile b/mm/Makefile</span>
<span class="p_header">index 026f6a828a50..543311e74494 100644</span>
<span class="p_header">--- a/mm/Makefile</span>
<span class="p_header">+++ b/mm/Makefile</span>
<span class="p_chunk">@@ -16,7 +16,6 @@</span> <span class="p_context"> KCOV_INSTRUMENT_slub.o := n</span>
 KCOV_INSTRUMENT_page_alloc.o := n
 KCOV_INSTRUMENT_debug-pagealloc.o := n
 KCOV_INSTRUMENT_kmemleak.o := n
<span class="p_del">-KCOV_INSTRUMENT_kmemcheck.o := n</span>
 KCOV_INSTRUMENT_memcontrol.o := n
 KCOV_INSTRUMENT_mmzone.o := n
 KCOV_INSTRUMENT_vmstat.o := n
<span class="p_chunk">@@ -69,7 +68,6 @@</span> <span class="p_context"> obj-$(CONFIG_KSM) += ksm.o</span>
 obj-$(CONFIG_PAGE_POISONING) += page_poison.o
 obj-$(CONFIG_SLAB) += slab.o
 obj-$(CONFIG_SLUB) += slub.o
<span class="p_del">-obj-$(CONFIG_KMEMCHECK) += kmemcheck.o</span>
 obj-$(CONFIG_KASAN)	+= kasan/
 obj-$(CONFIG_FAILSLAB) += failslab.o
 obj-$(CONFIG_MEMORY_HOTPLUG) += memory_hotplug.o
<span class="p_header">diff --git a/mm/kmemcheck.c b/mm/kmemcheck.c</span>
deleted file mode 100644
<span class="p_header">index 5bf191756a4a..000000000000</span>
<span class="p_header">--- a/mm/kmemcheck.c</span>
<span class="p_header">+++ /dev/null</span>
<span class="p_chunk">@@ -1,125 +0,0 @@</span> <span class="p_context"></span>
<span class="p_del">-#include &lt;linux/gfp.h&gt;</span>
<span class="p_del">-#include &lt;linux/mm_types.h&gt;</span>
<span class="p_del">-#include &lt;linux/mm.h&gt;</span>
<span class="p_del">-#include &lt;linux/slab.h&gt;</span>
<span class="p_del">-#include &quot;slab.h&quot;</span>
<span class="p_del">-#include &lt;linux/kmemcheck.h&gt;</span>
<span class="p_del">-</span>
<span class="p_del">-void kmemcheck_alloc_shadow(struct page *page, int order, gfp_t flags, int node)</span>
<span class="p_del">-{</span>
<span class="p_del">-	struct page *shadow;</span>
<span class="p_del">-	int pages;</span>
<span class="p_del">-	int i;</span>
<span class="p_del">-</span>
<span class="p_del">-	pages = 1 &lt;&lt; order;</span>
<span class="p_del">-</span>
<span class="p_del">-	/*</span>
<span class="p_del">-	 * With kmemcheck enabled, we need to allocate a memory area for the</span>
<span class="p_del">-	 * shadow bits as well.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	shadow = alloc_pages_node(node, flags | __GFP_NOTRACK, order);</span>
<span class="p_del">-	if (!shadow) {</span>
<span class="p_del">-		if (printk_ratelimit())</span>
<span class="p_del">-			pr_err(&quot;kmemcheck: failed to allocate shadow bitmap\n&quot;);</span>
<span class="p_del">-		return;</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">-	for(i = 0; i &lt; pages; ++i)</span>
<span class="p_del">-		page[i].shadow = page_address(&amp;shadow[i]);</span>
<span class="p_del">-</span>
<span class="p_del">-	/*</span>
<span class="p_del">-	 * Mark it as non-present for the MMU so that our accesses to</span>
<span class="p_del">-	 * this memory will trigger a page fault and let us analyze</span>
<span class="p_del">-	 * the memory accesses.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	kmemcheck_hide_pages(page, pages);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-void kmemcheck_free_shadow(struct page *page, int order)</span>
<span class="p_del">-{</span>
<span class="p_del">-	struct page *shadow;</span>
<span class="p_del">-	int pages;</span>
<span class="p_del">-	int i;</span>
<span class="p_del">-</span>
<span class="p_del">-	if (!kmemcheck_page_is_tracked(page))</span>
<span class="p_del">-		return;</span>
<span class="p_del">-</span>
<span class="p_del">-	pages = 1 &lt;&lt; order;</span>
<span class="p_del">-</span>
<span class="p_del">-	kmemcheck_show_pages(page, pages);</span>
<span class="p_del">-</span>
<span class="p_del">-	shadow = virt_to_page(page[0].shadow);</span>
<span class="p_del">-</span>
<span class="p_del">-	for(i = 0; i &lt; pages; ++i)</span>
<span class="p_del">-		page[i].shadow = NULL;</span>
<span class="p_del">-</span>
<span class="p_del">-	__free_pages(shadow, order);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-void kmemcheck_slab_alloc(struct kmem_cache *s, gfp_t gfpflags, void *object,</span>
<span class="p_del">-			  size_t size)</span>
<span class="p_del">-{</span>
<span class="p_del">-	if (unlikely(!object)) /* Skip object if allocation failed */</span>
<span class="p_del">-		return;</span>
<span class="p_del">-</span>
<span class="p_del">-	/*</span>
<span class="p_del">-	 * Has already been memset(), which initializes the shadow for us</span>
<span class="p_del">-	 * as well.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	if (gfpflags &amp; __GFP_ZERO)</span>
<span class="p_del">-		return;</span>
<span class="p_del">-</span>
<span class="p_del">-	/* No need to initialize the shadow of a non-tracked slab. */</span>
<span class="p_del">-	if (s-&gt;flags &amp; SLAB_NOTRACK)</span>
<span class="p_del">-		return;</span>
<span class="p_del">-</span>
<span class="p_del">-	if (!kmemcheck_enabled || gfpflags &amp; __GFP_NOTRACK) {</span>
<span class="p_del">-		/*</span>
<span class="p_del">-		 * Allow notracked objects to be allocated from</span>
<span class="p_del">-		 * tracked caches. Note however that these objects</span>
<span class="p_del">-		 * will still get page faults on access, they just</span>
<span class="p_del">-		 * won&#39;t ever be flagged as uninitialized. If page</span>
<span class="p_del">-		 * faults are not acceptable, the slab cache itself</span>
<span class="p_del">-		 * should be marked NOTRACK.</span>
<span class="p_del">-		 */</span>
<span class="p_del">-		kmemcheck_mark_initialized(object, size);</span>
<span class="p_del">-	} else if (!s-&gt;ctor) {</span>
<span class="p_del">-		/*</span>
<span class="p_del">-		 * New objects should be marked uninitialized before</span>
<span class="p_del">-		 * they&#39;re returned to the called.</span>
<span class="p_del">-		 */</span>
<span class="p_del">-		kmemcheck_mark_uninitialized(object, size);</span>
<span class="p_del">-	}</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-void kmemcheck_slab_free(struct kmem_cache *s, void *object, size_t size)</span>
<span class="p_del">-{</span>
<span class="p_del">-	/* TODO: RCU freeing is unsupported for now; hide false positives. */</span>
<span class="p_del">-	if (!s-&gt;ctor &amp;&amp; !(s-&gt;flags &amp; SLAB_DESTROY_BY_RCU))</span>
<span class="p_del">-		kmemcheck_mark_freed(object, size);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-void kmemcheck_pagealloc_alloc(struct page *page, unsigned int order,</span>
<span class="p_del">-			       gfp_t gfpflags)</span>
<span class="p_del">-{</span>
<span class="p_del">-	int pages;</span>
<span class="p_del">-</span>
<span class="p_del">-	if (gfpflags &amp; (__GFP_HIGHMEM | __GFP_NOTRACK))</span>
<span class="p_del">-		return;</span>
<span class="p_del">-</span>
<span class="p_del">-	pages = 1 &lt;&lt; order;</span>
<span class="p_del">-</span>
<span class="p_del">-	/*</span>
<span class="p_del">-	 * NOTE: We choose to track GFP_ZERO pages too; in fact, they</span>
<span class="p_del">-	 * can become uninitialized by copying uninitialized memory</span>
<span class="p_del">-	 * into them.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-</span>
<span class="p_del">-	/* XXX: Can use zone-&gt;node for node? */</span>
<span class="p_del">-	kmemcheck_alloc_shadow(page, order, gfpflags, -1);</span>
<span class="p_del">-</span>
<span class="p_del">-	if (gfpflags &amp; __GFP_ZERO)</span>
<span class="p_del">-		kmemcheck_mark_initialized_pages(page, pages);</span>
<span class="p_del">-	else</span>
<span class="p_del">-		kmemcheck_mark_uninitialized_pages(page, pages);</span>
<span class="p_del">-}</span>
<span class="p_header">diff --git a/mm/page_alloc.c b/mm/page_alloc.c</span>
<span class="p_header">index 07efbc3a8656..9c51972f4168 100644</span>
<span class="p_header">--- a/mm/page_alloc.c</span>
<span class="p_header">+++ b/mm/page_alloc.c</span>
<span class="p_chunk">@@ -24,7 +24,6 @@</span> <span class="p_context"></span>
 #include &lt;linux/memblock.h&gt;
 #include &lt;linux/compiler.h&gt;
 #include &lt;linux/kernel.h&gt;
<span class="p_del">-#include &lt;linux/kmemcheck.h&gt;</span>
 #include &lt;linux/kasan.h&gt;
 #include &lt;linux/module.h&gt;
 #include &lt;linux/suspend.h&gt;
<span class="p_chunk">@@ -1001,7 +1000,6 @@</span> <span class="p_context"> static __always_inline bool free_pages_prepare(struct page *page,</span>
 	VM_BUG_ON_PAGE(PageTail(page), page);
 
 	trace_mm_page_free(page, order);
<span class="p_del">-	kmemcheck_free_shadow(page, order);</span>
 
 	/*
 	 * Check tail pages before head page information is cleared to
<span class="p_chunk">@@ -2558,15 +2556,6 @@</span> <span class="p_context"> void split_page(struct page *page, unsigned int order)</span>
 	VM_BUG_ON_PAGE(PageCompound(page), page);
 	VM_BUG_ON_PAGE(!page_count(page), page);
 
<span class="p_del">-#ifdef CONFIG_KMEMCHECK</span>
<span class="p_del">-	/*</span>
<span class="p_del">-	 * Split shadow pages too, because free(page[0]) would</span>
<span class="p_del">-	 * otherwise free the whole shadow.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	if (kmemcheck_page_is_tracked(page))</span>
<span class="p_del">-		split_page(virt_to_page(page[0].shadow), order);</span>
<span class="p_del">-#endif</span>
<span class="p_del">-</span>
 	for (i = 1; i &lt; (1 &lt;&lt; order); i++)
 		set_page_refcounted(page + i);
 	split_page_owner(page, order);
<span class="p_chunk">@@ -3993,9 +3982,6 @@</span> <span class="p_context"> __alloc_pages_nodemask(gfp_t gfp_mask, unsigned int order,</span>
 		page = NULL;
 	}
 
<span class="p_del">-	if (kmemcheck_enabled &amp;&amp; page)</span>
<span class="p_del">-		kmemcheck_pagealloc_alloc(page, order, gfp_mask);</span>
<span class="p_del">-</span>
 	trace_mm_page_alloc(page, order, alloc_mask, ac.migratetype);
 
 	return page;
<span class="p_header">diff --git a/mm/slab.c b/mm/slab.c</span>
<span class="p_header">index 807d86c76908..2a20911622dd 100644</span>
<span class="p_header">--- a/mm/slab.c</span>
<span class="p_header">+++ b/mm/slab.c</span>
<span class="p_chunk">@@ -113,7 +113,6 @@</span> <span class="p_context"></span>
 #include	&lt;linux/rtmutex.h&gt;
 #include	&lt;linux/reciprocal_div.h&gt;
 #include	&lt;linux/debugobjects.h&gt;
<span class="p_del">-#include	&lt;linux/kmemcheck.h&gt;</span>
 #include	&lt;linux/memory.h&gt;
 #include	&lt;linux/prefetch.h&gt;
 #include	&lt;linux/sched/task_stack.h&gt;
<span class="p_chunk">@@ -1436,15 +1435,6 @@</span> <span class="p_context"> static struct page *kmem_getpages(struct kmem_cache *cachep, gfp_t flags,</span>
 	if (sk_memalloc_socks() &amp;&amp; page_is_pfmemalloc(page))
 		SetPageSlabPfmemalloc(page);
 
<span class="p_del">-	if (kmemcheck_enabled &amp;&amp; !(cachep-&gt;flags &amp; SLAB_NOTRACK)) {</span>
<span class="p_del">-		kmemcheck_alloc_shadow(page, cachep-&gt;gfporder, flags, nodeid);</span>
<span class="p_del">-</span>
<span class="p_del">-		if (cachep-&gt;ctor)</span>
<span class="p_del">-			kmemcheck_mark_uninitialized_pages(page, nr_pages);</span>
<span class="p_del">-		else</span>
<span class="p_del">-			kmemcheck_mark_unallocated_pages(page, nr_pages);</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
 	return page;
 }
 
<span class="p_chunk">@@ -1456,8 +1446,6 @@</span> <span class="p_context"> static void kmem_freepages(struct kmem_cache *cachep, struct page *page)</span>
 	int order = cachep-&gt;gfporder;
 	unsigned long nr_freed = (1 &lt;&lt; order);
 
<span class="p_del">-	kmemcheck_free_shadow(page, order);</span>
<span class="p_del">-</span>
 	if (cachep-&gt;flags &amp; SLAB_RECLAIM_ACCOUNT)
 		sub_zone_page_state(page_zone(page),
 				NR_SLAB_RECLAIMABLE, nr_freed);
<span class="p_chunk">@@ -3523,8 +3511,6 @@</span> <span class="p_context"> void ___cache_free(struct kmem_cache *cachep, void *objp,</span>
 	kmemleak_free_recursive(objp, cachep-&gt;flags);
 	objp = cache_free_debugcheck(cachep, objp, caller);
 
<span class="p_del">-	kmemcheck_slab_free(cachep, objp, cachep-&gt;object_size);</span>
<span class="p_del">-</span>
 	/*
 	 * Skip calling cache_free_alien() when the platform is not numa.
 	 * This will avoid cache misses that happen while accessing slabp (which
<span class="p_header">diff --git a/mm/slab.h b/mm/slab.h</span>
<span class="p_header">index 65e7c3fcac72..f701ab7e0107 100644</span>
<span class="p_header">--- a/mm/slab.h</span>
<span class="p_header">+++ b/mm/slab.h</span>
<span class="p_chunk">@@ -39,7 +39,6 @@</span> <span class="p_context"> struct kmem_cache {</span>
 
 #include &lt;linux/memcontrol.h&gt;
 #include &lt;linux/fault-inject.h&gt;
<span class="p_del">-#include &lt;linux/kmemcheck.h&gt;</span>
 #include &lt;linux/kasan.h&gt;
 #include &lt;linux/kmemleak.h&gt;
 #include &lt;linux/random.h&gt;
<span class="p_chunk">@@ -450,7 +449,6 @@</span> <span class="p_context"> static inline void slab_post_alloc_hook(struct kmem_cache *s, gfp_t flags,</span>
 	for (i = 0; i &lt; size; i++) {
 		void *object = p[i];
 
<span class="p_del">-		kmemcheck_slab_alloc(s, flags, object, slab_ksize(s));</span>
 		kmemleak_alloc_recursive(object, s-&gt;object_size, 1,
 					 s-&gt;flags, flags);
 		kasan_slab_alloc(s, object, flags);
<span class="p_header">diff --git a/mm/slub.c b/mm/slub.c</span>
<span class="p_header">index 7f4bc7027ed5..f77d0ac055ea 100644</span>
<span class="p_header">--- a/mm/slub.c</span>
<span class="p_header">+++ b/mm/slub.c</span>
<span class="p_chunk">@@ -21,7 +21,6 @@</span> <span class="p_context"></span>
 #include &lt;linux/notifier.h&gt;
 #include &lt;linux/seq_file.h&gt;
 #include &lt;linux/kasan.h&gt;
<span class="p_del">-#include &lt;linux/kmemcheck.h&gt;</span>
 #include &lt;linux/cpu.h&gt;
 #include &lt;linux/cpuset.h&gt;
 #include &lt;linux/mempolicy.h&gt;
<span class="p_chunk">@@ -1336,12 +1335,11 @@</span> <span class="p_context"> static inline void *slab_free_hook(struct kmem_cache *s, void *x)</span>
 	 * So in order to make the debug calls that expect irqs to be
 	 * disabled we need to disable interrupts temporarily.
 	 */
<span class="p_del">-#if defined(CONFIG_KMEMCHECK) || defined(CONFIG_LOCKDEP)</span>
<span class="p_add">+#if defined(CONFIG_LOCKDEP)</span>
 	{
 		unsigned long flags;
 
 		local_irq_save(flags);
<span class="p_del">-		kmemcheck_slab_free(s, x, s-&gt;object_size);</span>
 		debug_check_no_locks_freed(x, s-&gt;object_size);
 		local_irq_restore(flags);
 	}
<span class="p_chunk">@@ -1365,8 +1363,7 @@</span> <span class="p_context"> static inline void slab_free_freelist_hook(struct kmem_cache *s,</span>
  * Compiler cannot detect this function can be removed if slab_free_hook()
  * evaluates to nothing.  Thus, catch all relevant config debug options here.
  */
<span class="p_del">-#if defined(CONFIG_KMEMCHECK) ||		\</span>
<span class="p_del">-	defined(CONFIG_LOCKDEP)	||		\</span>
<span class="p_add">+#if	defined(CONFIG_LOCKDEP)	||		\</span>
 	defined(CONFIG_DEBUG_KMEMLEAK) ||	\
 	defined(CONFIG_DEBUG_OBJECTS_FREE) ||	\
 	defined(CONFIG_KASAN)
<span class="p_chunk">@@ -1562,22 +1559,6 @@</span> <span class="p_context"> static struct page *allocate_slab(struct kmem_cache *s, gfp_t flags, int node)</span>
 		stat(s, ORDER_FALLBACK);
 	}
 
<span class="p_del">-	if (kmemcheck_enabled &amp;&amp;</span>
<span class="p_del">-	    !(s-&gt;flags &amp; (SLAB_NOTRACK | DEBUG_DEFAULT_FLAGS))) {</span>
<span class="p_del">-		int pages = 1 &lt;&lt; oo_order(oo);</span>
<span class="p_del">-</span>
<span class="p_del">-		kmemcheck_alloc_shadow(page, oo_order(oo), alloc_gfp, node);</span>
<span class="p_del">-</span>
<span class="p_del">-		/*</span>
<span class="p_del">-		 * Objects from caches that have a constructor don&#39;t get</span>
<span class="p_del">-		 * cleared when they&#39;re allocated, so we need to do it here.</span>
<span class="p_del">-		 */</span>
<span class="p_del">-		if (s-&gt;ctor)</span>
<span class="p_del">-			kmemcheck_mark_uninitialized_pages(page, pages);</span>
<span class="p_del">-		else</span>
<span class="p_del">-			kmemcheck_mark_unallocated_pages(page, pages);</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
 	page-&gt;objects = oo_objects(oo);
 
 	order = compound_order(page);
<span class="p_chunk">@@ -1653,8 +1634,6 @@</span> <span class="p_context"> static void __free_slab(struct kmem_cache *s, struct page *page)</span>
 			check_object(s, page, p, SLUB_RED_INACTIVE);
 	}
 
<span class="p_del">-	kmemcheck_free_shadow(page, compound_order(page));</span>
<span class="p_del">-</span>
 	mod_zone_page_state(page_zone(page),
 		(s-&gt;flags &amp; SLAB_RECLAIM_ACCOUNT) ?
 		NR_SLAB_RECLAIMABLE : NR_SLAB_UNRECLAIMABLE,
<span class="p_del">-- </span>
2.12.0.rc0


</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



