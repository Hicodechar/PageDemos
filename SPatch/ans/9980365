
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>[PATCHv3] mm: Account pud page tables - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    [PATCHv3] mm: Account pud page tables</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=40781">Kirill A. Shutemov</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>Oct. 2, 2017, 8:04 a.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;20171002080427.3320-1-kirill.shutemov@linux.intel.com&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/9980365/mbox/"
   >mbox</a>
|
   <a href="/patch/9980365/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/9980365/">/patch/9980365/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
	[172.30.200.125])
	by pdx-korg-patchwork.web.codeaurora.org (Postfix) with ESMTP id
	73169602A0 for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Mon,  2 Oct 2017 08:04:54 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 5C70B1FFDA
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Mon,  2 Oct 2017 08:04:54 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id 511982876E; Mon,  2 Oct 2017 08:04:54 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-6.9 required=2.0 tests=BAYES_00,RCVD_IN_DNSWL_HI
	autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 448071FFDA
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Mon,  2 Oct 2017 08:04:53 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1751106AbdJBIEu (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Mon, 2 Oct 2017 04:04:50 -0400
Received: from mga14.intel.com ([192.55.52.115]:20821 &quot;EHLO mga14.intel.com&quot;
	rhost-flags-OK-OK-OK-OK) by vger.kernel.org with ESMTP
	id S1750846AbdJBIEs (ORCPT &lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Mon, 2 Oct 2017 04:04:48 -0400
Received: from orsmga001.jf.intel.com ([10.7.209.18])
	by fmsmga103.fm.intel.com with ESMTP/TLS/DHE-RSA-AES256-GCM-SHA384;
	02 Oct 2017 01:04:33 -0700
X-ExtLoop1: 1
X-IronPort-AV: E=Sophos;i=&quot;5.42,468,1500966000&quot;; d=&quot;scan&#39;208&quot;;a=&quot;1177686081&quot;
Received: from black.fi.intel.com ([10.237.72.28])
	by orsmga001.jf.intel.com with ESMTP; 02 Oct 2017 01:04:31 -0700
Received: by black.fi.intel.com (Postfix, from userid 1000)
	id 1C60F1C3; Mon,  2 Oct 2017 11:04:29 +0300 (EEST)
From: &quot;Kirill A. Shutemov&quot; &lt;kirill.shutemov@linux.intel.com&gt;
To: Andrew Morton &lt;akpm@linux-foundation.org&gt;
Cc: linux-mm@kvack.org, linux-kernel@vger.kernel.org,
	&quot;Kirill A. Shutemov&quot; &lt;kirill.shutemov@linux.intel.com&gt;,
	Michal Hocko &lt;mhocko@suse.com&gt;, Vlastimil Babka &lt;vbabka@suse.cz&gt;
Subject: [PATCHv3] mm: Account pud page tables
Date: Mon,  2 Oct 2017 11:04:27 +0300
Message-Id: &lt;20171002080427.3320-1-kirill.shutemov@linux.intel.com&gt;
X-Mailer: git-send-email 2.14.2
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=40781">Kirill A. Shutemov</a> - Oct. 2, 2017, 8:04 a.m.</div>
<pre class="content">
On machine with 5-level paging support a process can allocate
significant amount of memory and stay unnoticed by oom-killer and
memory cgroup. The trick is to allocate a lot of PUD page tables.
We don&#39;t account PUD page tables, only PMD and PTE.

We already addressed the same issue for PMD page tables, see
dc6c9a35b66b (&quot;mm: account pmd page tables to the process&quot;).
Introduction 5-level paging bring the same issue for PUD page tables.

The patch expands accounting to PUD level.
<span class="signed-off-by">
Signed-off-by: Kirill A. Shutemov &lt;kirill.shutemov@linux.intel.com&gt;</span>
Cc: Michal Hocko &lt;mhocko@suse.com&gt;
Cc: Vlastimil Babka &lt;vbabka@suse.cz&gt;
---

 v3:
   - Fix build errors;

---
 Documentation/sysctl/vm.txt   |  8 ++++----
 arch/powerpc/mm/hugetlbpage.c |  1 +
 arch/sparc/mm/hugetlbpage.c   |  1 +
 fs/proc/task_mmu.c            |  5 ++++-
 include/linux/mm.h            | 36 +++++++++++++++++++++++++++++++++---
 include/linux/mm_types.h      |  3 +++
 kernel/fork.c                 |  4 ++++
 mm/debug.c                    |  6 ++++--
 mm/memory.c                   | 15 +++++++++------
 mm/oom_kill.c                 |  8 +++++---
 10 files changed, 68 insertions(+), 19 deletions(-)
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=181">Rik van Riel</a> - Oct. 3, 2017, 7:59 p.m.</div>
<pre class="content">
On Mon, 2017-10-02 at 11:04 +0300, Kirill A. Shutemov wrote:
<span class="quote">&gt; On machine with 5-level paging support a process can allocate</span>
<span class="quote">&gt; significant amount of memory and stay unnoticed by oom-killer and</span>
<span class="quote">&gt; memory cgroup. The trick is to allocate a lot of PUD page tables.</span>
<span class="quote">&gt; We don&#39;t account PUD page tables, only PMD and PTE.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; We already addressed the same issue for PMD page tables, see</span>
<span class="quote">&gt; dc6c9a35b66b (&quot;mm: account pmd page tables to the process&quot;).</span>
<span class="quote">&gt; Introduction 5-level paging bring the same issue for PUD page tables.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; The patch expands accounting to PUD level.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Signed-off-by: Kirill A. Shutemov &lt;kirill.shutemov@linux.intel.com&gt;</span>
<span class="quote">&gt; Cc: Michal Hocko &lt;mhocko@suse.com&gt;</span>
<span class="quote">&gt; Cc: Vlastimil Babka &lt;vbabka@suse.cz&gt;</span>
<span class="quote">&gt; </span>
<span class="acked-by">
Acked-by: Rik van Riel &lt;riel@redhat.com&gt;</span>
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=72672">Vlastimil Babka</a> - Oct. 4, 2017, 6:03 a.m.</div>
<pre class="content">
On 10/02/2017 10:04 AM, Kirill A. Shutemov wrote:
<span class="quote">&gt; On machine with 5-level paging support a process can allocate</span>
<span class="quote">&gt; significant amount of memory and stay unnoticed by oom-killer and</span>
<span class="quote">&gt; memory cgroup. The trick is to allocate a lot of PUD page tables.</span>
<span class="quote">&gt; We don&#39;t account PUD page tables, only PMD and PTE.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; We already addressed the same issue for PMD page tables, see</span>
<span class="quote">&gt; dc6c9a35b66b (&quot;mm: account pmd page tables to the process&quot;).</span>
<span class="quote">&gt; Introduction 5-level paging bring the same issue for PUD page tables.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; The patch expands accounting to PUD level.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Signed-off-by: Kirill A. Shutemov &lt;kirill.shutemov@linux.intel.com&gt;</span>
<span class="quote">&gt; Cc: Michal Hocko &lt;mhocko@suse.com&gt;</span>
<span class="quote">&gt; Cc: Vlastimil Babka &lt;vbabka@suse.cz&gt;</span>
<span class="acked-by">
Acked-by: Vlastimil Babka &lt;vbabka@suse.cz&gt;</span>

Small fix below:
<span class="quote">
&gt; --- a/fs/proc/task_mmu.c</span>
<span class="quote">&gt; +++ b/fs/proc/task_mmu.c</span>
<span class="quote">&gt; @@ -25,7 +25,7 @@</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  void task_mem(struct seq_file *m, struct mm_struct *mm)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt; -	unsigned long text, lib, swap, ptes, pmds, anon, file, shmem;</span>
<span class="quote">&gt; +	unsigned long text, lib, swap, ptes, pmds, puds, anon, file, shmem;</span>
<span class="quote">&gt;  	unsigned long hiwater_vm, total_vm, hiwater_rss, total_rss;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	anon = get_mm_counter(mm, MM_ANONPAGES);</span>
<span class="quote">&gt; @@ -51,6 +51,7 @@ void task_mem(struct seq_file *m, struct mm_struct *mm)</span>
<span class="quote">&gt;  	swap = get_mm_counter(mm, MM_SWAPENTS);</span>
<span class="quote">&gt;  	ptes = PTRS_PER_PTE * sizeof(pte_t) * atomic_long_read(&amp;mm-&gt;nr_ptes);</span>
<span class="quote">&gt;  	pmds = PTRS_PER_PMD * sizeof(pmd_t) * mm_nr_pmds(mm);</span>
<span class="quote">&gt; +	puds = PTRS_PER_PUD * sizeof(pmd_t) * mm_nr_puds(mm);</span>

				     ^ pud_t ?
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=137061">Michal Hocko</a> - Oct. 4, 2017, 1:48 p.m.</div>
<pre class="content">
On Mon 02-10-17 11:04:27, Kirill A. Shutemov wrote:
<span class="quote">&gt; On machine with 5-level paging support a process can allocate</span>
<span class="quote">&gt; significant amount of memory and stay unnoticed by oom-killer and</span>
<span class="quote">&gt; memory cgroup. The trick is to allocate a lot of PUD page tables.</span>
<span class="quote">&gt; We don&#39;t account PUD page tables, only PMD and PTE.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; We already addressed the same issue for PMD page tables, see</span>
<span class="quote">&gt; dc6c9a35b66b (&quot;mm: account pmd page tables to the process&quot;).</span>
<span class="quote">&gt; Introduction 5-level paging bring the same issue for PUD page tables.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; The patch expands accounting to PUD level.</span>

Can we skip the VmPUD part and reporting puds in the oom report please?
I would like to consolidate all levels into a single counter and carying
about one less user visible change will make it slightly easier. Or does
anybody need this exported to the userspace?
<span class="quote">
&gt; Signed-off-by: Kirill A. Shutemov &lt;kirill.shutemov@linux.intel.com&gt;</span>
<span class="quote">&gt; Cc: Michal Hocko &lt;mhocko@suse.com&gt;</span>
<span class="quote">&gt; Cc: Vlastimil Babka &lt;vbabka@suse.cz&gt;</span>

Other than that and including the follow up fix pointed by Vlastimil
<span class="acked-by">Acked-by: Michal Hocko &lt;mhocko@suse.com&gt;</span>
<span class="quote">
&gt; ---</span>
<span class="quote">&gt; </span>
<span class="quote">&gt;  v3:</span>
<span class="quote">&gt;    - Fix build errors;</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; ---</span>
<span class="quote">&gt;  Documentation/sysctl/vm.txt   |  8 ++++----</span>
<span class="quote">&gt;  arch/powerpc/mm/hugetlbpage.c |  1 +</span>
<span class="quote">&gt;  arch/sparc/mm/hugetlbpage.c   |  1 +</span>
<span class="quote">&gt;  fs/proc/task_mmu.c            |  5 ++++-</span>
<span class="quote">&gt;  include/linux/mm.h            | 36 +++++++++++++++++++++++++++++++++---</span>
<span class="quote">&gt;  include/linux/mm_types.h      |  3 +++</span>
<span class="quote">&gt;  kernel/fork.c                 |  4 ++++</span>
<span class="quote">&gt;  mm/debug.c                    |  6 ++++--</span>
<span class="quote">&gt;  mm/memory.c                   | 15 +++++++++------</span>
<span class="quote">&gt;  mm/oom_kill.c                 |  8 +++++---</span>
<span class="quote">&gt;  10 files changed, 68 insertions(+), 19 deletions(-)</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; diff --git a/Documentation/sysctl/vm.txt b/Documentation/sysctl/vm.txt</span>
<span class="quote">&gt; index 9baf66a9ef4e..2717b6f2d706 100644</span>
<span class="quote">&gt; --- a/Documentation/sysctl/vm.txt</span>
<span class="quote">&gt; +++ b/Documentation/sysctl/vm.txt</span>
<span class="quote">&gt; @@ -622,10 +622,10 @@ oom_dump_tasks</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  Enables a system-wide task dump (excluding kernel threads) to be produced</span>
<span class="quote">&gt;  when the kernel performs an OOM-killing and includes such information as</span>
<span class="quote">&gt; -pid, uid, tgid, vm size, rss, nr_ptes, nr_pmds, swapents, oom_score_adj</span>
<span class="quote">&gt; -score, and name.  This is helpful to determine why the OOM killer was</span>
<span class="quote">&gt; -invoked, to identify the rogue task that caused it, and to determine why</span>
<span class="quote">&gt; -the OOM killer chose the task it did to kill.</span>
<span class="quote">&gt; +pid, uid, tgid, vm size, rss, nr_ptes, nr_pmds, nr_puds, swapents,</span>
<span class="quote">&gt; +oom_score_adj score, and name.  This is helpful to determine why the OOM</span>
<span class="quote">&gt; +killer was invoked, to identify the rogue task that caused it, and to</span>
<span class="quote">&gt; +determine why the OOM killer chose the task it did to kill.</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  If this is set to zero, this information is suppressed.  On very</span>
<span class="quote">&gt;  large systems with thousands of tasks it may not be feasible to dump</span>
<span class="quote">&gt; diff --git a/arch/powerpc/mm/hugetlbpage.c b/arch/powerpc/mm/hugetlbpage.c</span>
<span class="quote">&gt; index 1571a498a33f..a9b9083c5e49 100644</span>
<span class="quote">&gt; --- a/arch/powerpc/mm/hugetlbpage.c</span>
<span class="quote">&gt; +++ b/arch/powerpc/mm/hugetlbpage.c</span>
<span class="quote">&gt; @@ -433,6 +433,7 @@ static void hugetlb_free_pud_range(struct mmu_gather *tlb, pgd_t *pgd,</span>
<span class="quote">&gt;  	pud = pud_offset(pgd, start);</span>
<span class="quote">&gt;  	pgd_clear(pgd);</span>
<span class="quote">&gt;  	pud_free_tlb(tlb, pud, start);</span>
<span class="quote">&gt; +	mm_dec_nr_puds(tlb-&gt;mm);</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  /*</span>
<span class="quote">&gt; diff --git a/arch/sparc/mm/hugetlbpage.c b/arch/sparc/mm/hugetlbpage.c</span>
<span class="quote">&gt; index bcd8cdbc377f..fd0d85808828 100644</span>
<span class="quote">&gt; --- a/arch/sparc/mm/hugetlbpage.c</span>
<span class="quote">&gt; +++ b/arch/sparc/mm/hugetlbpage.c</span>
<span class="quote">&gt; @@ -471,6 +471,7 @@ static void hugetlb_free_pud_range(struct mmu_gather *tlb, pgd_t *pgd,</span>
<span class="quote">&gt;  	pud = pud_offset(pgd, start);</span>
<span class="quote">&gt;  	pgd_clear(pgd);</span>
<span class="quote">&gt;  	pud_free_tlb(tlb, pud, start);</span>
<span class="quote">&gt; +	mm_dec_nr_puds(tlb-&gt;mm);</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  void hugetlb_free_pgd_range(struct mmu_gather *tlb,</span>
<span class="quote">&gt; diff --git a/fs/proc/task_mmu.c b/fs/proc/task_mmu.c</span>
<span class="quote">&gt; index 5589b4bd4b85..0bf9e423aa99 100644</span>
<span class="quote">&gt; --- a/fs/proc/task_mmu.c</span>
<span class="quote">&gt; +++ b/fs/proc/task_mmu.c</span>
<span class="quote">&gt; @@ -25,7 +25,7 @@</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  void task_mem(struct seq_file *m, struct mm_struct *mm)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt; -	unsigned long text, lib, swap, ptes, pmds, anon, file, shmem;</span>
<span class="quote">&gt; +	unsigned long text, lib, swap, ptes, pmds, puds, anon, file, shmem;</span>
<span class="quote">&gt;  	unsigned long hiwater_vm, total_vm, hiwater_rss, total_rss;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	anon = get_mm_counter(mm, MM_ANONPAGES);</span>
<span class="quote">&gt; @@ -51,6 +51,7 @@ void task_mem(struct seq_file *m, struct mm_struct *mm)</span>
<span class="quote">&gt;  	swap = get_mm_counter(mm, MM_SWAPENTS);</span>
<span class="quote">&gt;  	ptes = PTRS_PER_PTE * sizeof(pte_t) * atomic_long_read(&amp;mm-&gt;nr_ptes);</span>
<span class="quote">&gt;  	pmds = PTRS_PER_PMD * sizeof(pmd_t) * mm_nr_pmds(mm);</span>
<span class="quote">&gt; +	puds = PTRS_PER_PUD * sizeof(pmd_t) * mm_nr_puds(mm);</span>
<span class="quote">&gt;  	seq_printf(m,</span>
<span class="quote">&gt;  		&quot;VmPeak:\t%8lu kB\n&quot;</span>
<span class="quote">&gt;  		&quot;VmSize:\t%8lu kB\n&quot;</span>
<span class="quote">&gt; @@ -67,6 +68,7 @@ void task_mem(struct seq_file *m, struct mm_struct *mm)</span>
<span class="quote">&gt;  		&quot;VmLib:\t%8lu kB\n&quot;</span>
<span class="quote">&gt;  		&quot;VmPTE:\t%8lu kB\n&quot;</span>
<span class="quote">&gt;  		&quot;VmPMD:\t%8lu kB\n&quot;</span>
<span class="quote">&gt; +		&quot;VmPUD:\t%8lu kB\n&quot;</span>
<span class="quote">&gt;  		&quot;VmSwap:\t%8lu kB\n&quot;,</span>
<span class="quote">&gt;  		hiwater_vm &lt;&lt; (PAGE_SHIFT-10),</span>
<span class="quote">&gt;  		total_vm &lt;&lt; (PAGE_SHIFT-10),</span>
<span class="quote">&gt; @@ -81,6 +83,7 @@ void task_mem(struct seq_file *m, struct mm_struct *mm)</span>
<span class="quote">&gt;  		mm-&gt;stack_vm &lt;&lt; (PAGE_SHIFT-10), text, lib,</span>
<span class="quote">&gt;  		ptes &gt;&gt; 10,</span>
<span class="quote">&gt;  		pmds &gt;&gt; 10,</span>
<span class="quote">&gt; +		puds &gt;&gt; 10,</span>
<span class="quote">&gt;  		swap &lt;&lt; (PAGE_SHIFT-10));</span>
<span class="quote">&gt;  	hugetlb_report_usage(m, mm);</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt; diff --git a/include/linux/mm.h b/include/linux/mm.h</span>
<span class="quote">&gt; index f8c10d336e42..5125c51c9c35 100644</span>
<span class="quote">&gt; --- a/include/linux/mm.h</span>
<span class="quote">&gt; +++ b/include/linux/mm.h</span>
<span class="quote">&gt; @@ -1598,14 +1598,44 @@ static inline int __p4d_alloc(struct mm_struct *mm, pgd_t *pgd,</span>
<span class="quote">&gt;  int __p4d_alloc(struct mm_struct *mm, pgd_t *pgd, unsigned long address);</span>
<span class="quote">&gt;  #endif</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; -#ifdef __PAGETABLE_PUD_FOLDED</span>
<span class="quote">&gt; +#if defined(__PAGETABLE_PUD_FOLDED) || !defined(CONFIG_MMU)</span>
<span class="quote">&gt;  static inline int __pud_alloc(struct mm_struct *mm, p4d_t *p4d,</span>
<span class="quote">&gt;  						unsigned long address)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	return 0;</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +static inline unsigned long mm_nr_puds(const struct mm_struct *mm)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	return 0;</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +static inline void mm_nr_puds_init(struct mm_struct *mm) {}</span>
<span class="quote">&gt; +static inline void mm_inc_nr_puds(struct mm_struct *mm) {}</span>
<span class="quote">&gt; +static inline void mm_dec_nr_puds(struct mm_struct *mm) {}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt;  #else</span>
<span class="quote">&gt;  int __pud_alloc(struct mm_struct *mm, p4d_t *p4d, unsigned long address);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +static inline void mm_nr_puds_init(struct mm_struct *mm)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	atomic_long_set(&amp;mm-&gt;nr_puds, 0);</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +static inline unsigned long mm_nr_puds(const struct mm_struct *mm)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	return atomic_long_read(&amp;mm-&gt;nr_puds);</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +static inline void mm_inc_nr_puds(struct mm_struct *mm)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	atomic_long_inc(&amp;mm-&gt;nr_puds);</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +static inline void mm_dec_nr_puds(struct mm_struct *mm)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	atomic_long_dec(&amp;mm-&gt;nr_puds);</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt;  #endif</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  #if defined(__PAGETABLE_PMD_FOLDED) || !defined(CONFIG_MMU)</span>
<span class="quote">&gt; @@ -1617,7 +1647,7 @@ static inline int __pmd_alloc(struct mm_struct *mm, pud_t *pud,</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  static inline void mm_nr_pmds_init(struct mm_struct *mm) {}</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; -static inline unsigned long mm_nr_pmds(struct mm_struct *mm)</span>
<span class="quote">&gt; +static inline unsigned long mm_nr_pmds(const struct mm_struct *mm)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	return 0;</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt; @@ -1633,7 +1663,7 @@ static inline void mm_nr_pmds_init(struct mm_struct *mm)</span>
<span class="quote">&gt;  	atomic_long_set(&amp;mm-&gt;nr_pmds, 0);</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; -static inline unsigned long mm_nr_pmds(struct mm_struct *mm)</span>
<span class="quote">&gt; +static inline unsigned long mm_nr_pmds(const struct mm_struct *mm)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	return atomic_long_read(&amp;mm-&gt;nr_pmds);</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt; diff --git a/include/linux/mm_types.h b/include/linux/mm_types.h</span>
<span class="quote">&gt; index 46f4ecf5479a..6c8c2bb9e5a1 100644</span>
<span class="quote">&gt; --- a/include/linux/mm_types.h</span>
<span class="quote">&gt; +++ b/include/linux/mm_types.h</span>
<span class="quote">&gt; @@ -401,6 +401,9 @@ struct mm_struct {</span>
<span class="quote">&gt;  	atomic_long_t nr_ptes;			/* PTE page table pages */</span>
<span class="quote">&gt;  #if CONFIG_PGTABLE_LEVELS &gt; 2</span>
<span class="quote">&gt;  	atomic_long_t nr_pmds;			/* PMD page table pages */</span>
<span class="quote">&gt; +#endif</span>
<span class="quote">&gt; +#if CONFIG_PGTABLE_LEVELS &gt; 3</span>
<span class="quote">&gt; +	atomic_long_t nr_puds;			/* PUD page table pages */</span>
<span class="quote">&gt;  #endif</span>
<span class="quote">&gt;  	int map_count;				/* number of VMAs */</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; diff --git a/kernel/fork.c b/kernel/fork.c</span>
<span class="quote">&gt; index 10646182440f..5624918154db 100644</span>
<span class="quote">&gt; --- a/kernel/fork.c</span>
<span class="quote">&gt; +++ b/kernel/fork.c</span>
<span class="quote">&gt; @@ -815,6 +815,7 @@ static struct mm_struct *mm_init(struct mm_struct *mm, struct task_struct *p,</span>
<span class="quote">&gt;  	mm-&gt;core_state = NULL;</span>
<span class="quote">&gt;  	atomic_long_set(&amp;mm-&gt;nr_ptes, 0);</span>
<span class="quote">&gt;  	mm_nr_pmds_init(mm);</span>
<span class="quote">&gt; +	mm_nr_puds_init(mm);</span>
<span class="quote">&gt;  	mm-&gt;map_count = 0;</span>
<span class="quote">&gt;  	mm-&gt;locked_vm = 0;</span>
<span class="quote">&gt;  	mm-&gt;pinned_vm = 0;</span>
<span class="quote">&gt; @@ -874,6 +875,9 @@ static void check_mm(struct mm_struct *mm)</span>
<span class="quote">&gt;  	if (mm_nr_pmds(mm))</span>
<span class="quote">&gt;  		pr_alert(&quot;BUG: non-zero nr_pmds on freeing mm: %ld\n&quot;,</span>
<span class="quote">&gt;  				mm_nr_pmds(mm));</span>
<span class="quote">&gt; +	if (mm_nr_puds(mm))</span>
<span class="quote">&gt; +		pr_alert(&quot;BUG: non-zero nr_puds on freeing mm: %ld\n&quot;,</span>
<span class="quote">&gt; +				mm_nr_puds(mm));</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  #if defined(CONFIG_TRANSPARENT_HUGEPAGE) &amp;&amp; !USE_SPLIT_PMD_PTLOCKS</span>
<span class="quote">&gt;  	VM_BUG_ON_MM(mm-&gt;pmd_huge_pte, mm);</span>
<span class="quote">&gt; diff --git a/mm/debug.c b/mm/debug.c</span>
<span class="quote">&gt; index 5715448ab0b5..afccb2565269 100644</span>
<span class="quote">&gt; --- a/mm/debug.c</span>
<span class="quote">&gt; +++ b/mm/debug.c</span>
<span class="quote">&gt; @@ -104,7 +104,8 @@ void dump_mm(const struct mm_struct *mm)</span>
<span class="quote">&gt;  		&quot;get_unmapped_area %p\n&quot;</span>
<span class="quote">&gt;  #endif</span>
<span class="quote">&gt;  		&quot;mmap_base %lu mmap_legacy_base %lu highest_vm_end %lu\n&quot;</span>
<span class="quote">&gt; -		&quot;pgd %p mm_users %d mm_count %d nr_ptes %lu nr_pmds %lu map_count %d\n&quot;</span>
<span class="quote">&gt; +		&quot;pgd %p mm_users %d mm_count %d\n&quot;</span>
<span class="quote">&gt; +		&quot;nr_ptes %lu nr_pmds %lu nr_puds %lu map_count %d\n&quot;</span>
<span class="quote">&gt;  		&quot;hiwater_rss %lx hiwater_vm %lx total_vm %lx locked_vm %lx\n&quot;</span>
<span class="quote">&gt;  		&quot;pinned_vm %lx data_vm %lx exec_vm %lx stack_vm %lx\n&quot;</span>
<span class="quote">&gt;  		&quot;start_code %lx end_code %lx start_data %lx end_data %lx\n&quot;</span>
<span class="quote">&gt; @@ -135,7 +136,8 @@ void dump_mm(const struct mm_struct *mm)</span>
<span class="quote">&gt;  		mm-&gt;pgd, atomic_read(&amp;mm-&gt;mm_users),</span>
<span class="quote">&gt;  		atomic_read(&amp;mm-&gt;mm_count),</span>
<span class="quote">&gt;  		atomic_long_read((atomic_long_t *)&amp;mm-&gt;nr_ptes),</span>
<span class="quote">&gt; -		mm_nr_pmds((struct mm_struct *)mm),</span>
<span class="quote">&gt; +		mm_nr_pmds(mm),</span>
<span class="quote">&gt; +		mm_nr_puds(mm),</span>
<span class="quote">&gt;  		mm-&gt;map_count,</span>
<span class="quote">&gt;  		mm-&gt;hiwater_rss, mm-&gt;hiwater_vm, mm-&gt;total_vm, mm-&gt;locked_vm,</span>
<span class="quote">&gt;  		mm-&gt;pinned_vm, mm-&gt;data_vm, mm-&gt;exec_vm, mm-&gt;stack_vm,</span>
<span class="quote">&gt; diff --git a/mm/memory.c b/mm/memory.c</span>
<span class="quote">&gt; index ec4e15494901..291d4984b417 100644</span>
<span class="quote">&gt; --- a/mm/memory.c</span>
<span class="quote">&gt; +++ b/mm/memory.c</span>
<span class="quote">&gt; @@ -506,6 +506,7 @@ static inline void free_pud_range(struct mmu_gather *tlb, p4d_t *p4d,</span>
<span class="quote">&gt;  	pud = pud_offset(p4d, start);</span>
<span class="quote">&gt;  	p4d_clear(p4d);</span>
<span class="quote">&gt;  	pud_free_tlb(tlb, pud, start);</span>
<span class="quote">&gt; +	mm_dec_nr_puds(tlb-&gt;mm);</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  static inline void free_p4d_range(struct mmu_gather *tlb, pgd_t *pgd,</span>
<span class="quote">&gt; @@ -4124,15 +4125,17 @@ int __pud_alloc(struct mm_struct *mm, p4d_t *p4d, unsigned long address)</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	spin_lock(&amp;mm-&gt;page_table_lock);</span>
<span class="quote">&gt;  #ifndef __ARCH_HAS_5LEVEL_HACK</span>
<span class="quote">&gt; -	if (p4d_present(*p4d))		/* Another has populated it */</span>
<span class="quote">&gt; -		pud_free(mm, new);</span>
<span class="quote">&gt; -	else</span>
<span class="quote">&gt; +	if (!p4d_present(*p4d)) {</span>
<span class="quote">&gt; +		mm_inc_nr_puds(mm);</span>
<span class="quote">&gt;  		p4d_populate(mm, p4d, new);</span>
<span class="quote">&gt; -#else</span>
<span class="quote">&gt; -	if (pgd_present(*p4d))		/* Another has populated it */</span>
<span class="quote">&gt; +	} else	/* Another has populated it */</span>
<span class="quote">&gt;  		pud_free(mm, new);</span>
<span class="quote">&gt; -	else</span>
<span class="quote">&gt; +#else</span>
<span class="quote">&gt; +	if (!pgd_present(*p4d)) {</span>
<span class="quote">&gt; +		mm_inc_nr_puds(mm);</span>
<span class="quote">&gt;  		pgd_populate(mm, p4d, new);</span>
<span class="quote">&gt; +	} else	/* Another has populated it */</span>
<span class="quote">&gt; +		pud_free(mm, new);</span>
<span class="quote">&gt;  #endif /* __ARCH_HAS_5LEVEL_HACK */</span>
<span class="quote">&gt;  	spin_unlock(&amp;mm-&gt;page_table_lock);</span>
<span class="quote">&gt;  	return 0;</span>
<span class="quote">&gt; diff --git a/mm/oom_kill.c b/mm/oom_kill.c</span>
<span class="quote">&gt; index 99736e026712..4bee6968885d 100644</span>
<span class="quote">&gt; --- a/mm/oom_kill.c</span>
<span class="quote">&gt; +++ b/mm/oom_kill.c</span>
<span class="quote">&gt; @@ -200,7 +200,8 @@ unsigned long oom_badness(struct task_struct *p, struct mem_cgroup *memcg,</span>
<span class="quote">&gt;  	 * task&#39;s rss, pagetable and swap space use.</span>
<span class="quote">&gt;  	 */</span>
<span class="quote">&gt;  	points = get_mm_rss(p-&gt;mm) + get_mm_counter(p-&gt;mm, MM_SWAPENTS) +</span>
<span class="quote">&gt; -		atomic_long_read(&amp;p-&gt;mm-&gt;nr_ptes) + mm_nr_pmds(p-&gt;mm);</span>
<span class="quote">&gt; +		atomic_long_read(&amp;p-&gt;mm-&gt;nr_ptes) + mm_nr_pmds(p-&gt;mm) +</span>
<span class="quote">&gt; +		mm_nr_puds(p-&gt;mm);</span>
<span class="quote">&gt;  	task_unlock(p);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	/*</span>
<span class="quote">&gt; @@ -376,7 +377,7 @@ static void dump_tasks(struct mem_cgroup *memcg, const nodemask_t *nodemask)</span>
<span class="quote">&gt;  	struct task_struct *p;</span>
<span class="quote">&gt;  	struct task_struct *task;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; -	pr_info(&quot;[ pid ]   uid  tgid total_vm      rss nr_ptes nr_pmds swapents oom_score_adj name\n&quot;);</span>
<span class="quote">&gt; +	pr_info(&quot;[ pid ]   uid  tgid total_vm      rss nr_ptes nr_pmds nr_puds swapents oom_score_adj name\n&quot;);</span>
<span class="quote">&gt;  	rcu_read_lock();</span>
<span class="quote">&gt;  	for_each_process(p) {</span>
<span class="quote">&gt;  		if (oom_unkillable_task(p, memcg, nodemask))</span>
<span class="quote">&gt; @@ -392,11 +393,12 @@ static void dump_tasks(struct mem_cgroup *memcg, const nodemask_t *nodemask)</span>
<span class="quote">&gt;  			continue;</span>
<span class="quote">&gt;  		}</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; -		pr_info(&quot;[%5d] %5d %5d %8lu %8lu %7ld %7ld %8lu         %5hd %s\n&quot;,</span>
<span class="quote">&gt; +		pr_info(&quot;[%5d] %5d %5d %8lu %8lu %7ld %7ld %7ld %8lu         %5hd %s\n&quot;,</span>
<span class="quote">&gt;  			task-&gt;pid, from_kuid(&amp;init_user_ns, task_uid(task)),</span>
<span class="quote">&gt;  			task-&gt;tgid, task-&gt;mm-&gt;total_vm, get_mm_rss(task-&gt;mm),</span>
<span class="quote">&gt;  			atomic_long_read(&amp;task-&gt;mm-&gt;nr_ptes),</span>
<span class="quote">&gt;  			mm_nr_pmds(task-&gt;mm),</span>
<span class="quote">&gt; +			mm_nr_puds(task-&gt;mm),</span>
<span class="quote">&gt;  			get_mm_counter(task-&gt;mm, MM_SWAPENTS),</span>
<span class="quote">&gt;  			task-&gt;signal-&gt;oom_score_adj, task-&gt;comm);</span>
<span class="quote">&gt;  		task_unlock(task);</span>
<span class="quote">&gt; -- </span>
<span class="quote">&gt; 2.14.2</span>
<span class="quote">&gt;</span>
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=874">Kirill A. Shutemov</a> - Oct. 4, 2017, 2:16 p.m.</div>
<pre class="content">
On Wed, Oct 04, 2017 at 03:48:53PM +0200, Michal Hocko wrote:
<span class="quote">&gt; On Mon 02-10-17 11:04:27, Kirill A. Shutemov wrote:</span>
<span class="quote">&gt; &gt; On machine with 5-level paging support a process can allocate</span>
<span class="quote">&gt; &gt; significant amount of memory and stay unnoticed by oom-killer and</span>
<span class="quote">&gt; &gt; memory cgroup. The trick is to allocate a lot of PUD page tables.</span>
<span class="quote">&gt; &gt; We don&#39;t account PUD page tables, only PMD and PTE.</span>
<span class="quote">&gt; &gt; </span>
<span class="quote">&gt; &gt; We already addressed the same issue for PMD page tables, see</span>
<span class="quote">&gt; &gt; dc6c9a35b66b (&quot;mm: account pmd page tables to the process&quot;).</span>
<span class="quote">&gt; &gt; Introduction 5-level paging bring the same issue for PUD page tables.</span>
<span class="quote">&gt; &gt; </span>
<span class="quote">&gt; &gt; The patch expands accounting to PUD level.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Can we skip the VmPUD part and reporting puds in the oom report please?</span>
<span class="quote">&gt; I would like to consolidate all levels into a single counter and carying</span>
<span class="quote">&gt; about one less user visible change will make it slightly easier. Or does</span>
<span class="quote">&gt; anybody need this exported to the userspace?</span>

Let me do this as a separate patch. I will also fold VmPMD into VmPTE.
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=137061">Michal Hocko</a> - Oct. 4, 2017, 2:28 p.m.</div>
<pre class="content">
On Wed 04-10-17 17:16:20, Kirill A. Shutemov wrote:
<span class="quote">&gt; On Wed, Oct 04, 2017 at 03:48:53PM +0200, Michal Hocko wrote:</span>
<span class="quote">&gt; &gt; On Mon 02-10-17 11:04:27, Kirill A. Shutemov wrote:</span>
<span class="quote">&gt; &gt; &gt; On machine with 5-level paging support a process can allocate</span>
<span class="quote">&gt; &gt; &gt; significant amount of memory and stay unnoticed by oom-killer and</span>
<span class="quote">&gt; &gt; &gt; memory cgroup. The trick is to allocate a lot of PUD page tables.</span>
<span class="quote">&gt; &gt; &gt; We don&#39;t account PUD page tables, only PMD and PTE.</span>
<span class="quote">&gt; &gt; &gt; </span>
<span class="quote">&gt; &gt; &gt; We already addressed the same issue for PMD page tables, see</span>
<span class="quote">&gt; &gt; &gt; dc6c9a35b66b (&quot;mm: account pmd page tables to the process&quot;).</span>
<span class="quote">&gt; &gt; &gt; Introduction 5-level paging bring the same issue for PUD page tables.</span>
<span class="quote">&gt; &gt; &gt; </span>
<span class="quote">&gt; &gt; &gt; The patch expands accounting to PUD level.</span>
<span class="quote">&gt; &gt; </span>
<span class="quote">&gt; &gt; Can we skip the VmPUD part and reporting puds in the oom report please?</span>
<span class="quote">&gt; &gt; I would like to consolidate all levels into a single counter and carying</span>
<span class="quote">&gt; &gt; about one less user visible change will make it slightly easier. Or does</span>
<span class="quote">&gt; &gt; anybody need this exported to the userspace?</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Let me do this as a separate patch. I will also fold VmPMD into VmPTE.</span>

Thanks!
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/Documentation/sysctl/vm.txt b/Documentation/sysctl/vm.txt</span>
<span class="p_header">index 9baf66a9ef4e..2717b6f2d706 100644</span>
<span class="p_header">--- a/Documentation/sysctl/vm.txt</span>
<span class="p_header">+++ b/Documentation/sysctl/vm.txt</span>
<span class="p_chunk">@@ -622,10 +622,10 @@</span> <span class="p_context"> oom_dump_tasks</span>
 
 Enables a system-wide task dump (excluding kernel threads) to be produced
 when the kernel performs an OOM-killing and includes such information as
<span class="p_del">-pid, uid, tgid, vm size, rss, nr_ptes, nr_pmds, swapents, oom_score_adj</span>
<span class="p_del">-score, and name.  This is helpful to determine why the OOM killer was</span>
<span class="p_del">-invoked, to identify the rogue task that caused it, and to determine why</span>
<span class="p_del">-the OOM killer chose the task it did to kill.</span>
<span class="p_add">+pid, uid, tgid, vm size, rss, nr_ptes, nr_pmds, nr_puds, swapents,</span>
<span class="p_add">+oom_score_adj score, and name.  This is helpful to determine why the OOM</span>
<span class="p_add">+killer was invoked, to identify the rogue task that caused it, and to</span>
<span class="p_add">+determine why the OOM killer chose the task it did to kill.</span>
 
 If this is set to zero, this information is suppressed.  On very
 large systems with thousands of tasks it may not be feasible to dump
<span class="p_header">diff --git a/arch/powerpc/mm/hugetlbpage.c b/arch/powerpc/mm/hugetlbpage.c</span>
<span class="p_header">index 1571a498a33f..a9b9083c5e49 100644</span>
<span class="p_header">--- a/arch/powerpc/mm/hugetlbpage.c</span>
<span class="p_header">+++ b/arch/powerpc/mm/hugetlbpage.c</span>
<span class="p_chunk">@@ -433,6 +433,7 @@</span> <span class="p_context"> static void hugetlb_free_pud_range(struct mmu_gather *tlb, pgd_t *pgd,</span>
 	pud = pud_offset(pgd, start);
 	pgd_clear(pgd);
 	pud_free_tlb(tlb, pud, start);
<span class="p_add">+	mm_dec_nr_puds(tlb-&gt;mm);</span>
 }
 
 /*
<span class="p_header">diff --git a/arch/sparc/mm/hugetlbpage.c b/arch/sparc/mm/hugetlbpage.c</span>
<span class="p_header">index bcd8cdbc377f..fd0d85808828 100644</span>
<span class="p_header">--- a/arch/sparc/mm/hugetlbpage.c</span>
<span class="p_header">+++ b/arch/sparc/mm/hugetlbpage.c</span>
<span class="p_chunk">@@ -471,6 +471,7 @@</span> <span class="p_context"> static void hugetlb_free_pud_range(struct mmu_gather *tlb, pgd_t *pgd,</span>
 	pud = pud_offset(pgd, start);
 	pgd_clear(pgd);
 	pud_free_tlb(tlb, pud, start);
<span class="p_add">+	mm_dec_nr_puds(tlb-&gt;mm);</span>
 }
 
 void hugetlb_free_pgd_range(struct mmu_gather *tlb,
<span class="p_header">diff --git a/fs/proc/task_mmu.c b/fs/proc/task_mmu.c</span>
<span class="p_header">index 5589b4bd4b85..0bf9e423aa99 100644</span>
<span class="p_header">--- a/fs/proc/task_mmu.c</span>
<span class="p_header">+++ b/fs/proc/task_mmu.c</span>
<span class="p_chunk">@@ -25,7 +25,7 @@</span> <span class="p_context"></span>
 
 void task_mem(struct seq_file *m, struct mm_struct *mm)
 {
<span class="p_del">-	unsigned long text, lib, swap, ptes, pmds, anon, file, shmem;</span>
<span class="p_add">+	unsigned long text, lib, swap, ptes, pmds, puds, anon, file, shmem;</span>
 	unsigned long hiwater_vm, total_vm, hiwater_rss, total_rss;
 
 	anon = get_mm_counter(mm, MM_ANONPAGES);
<span class="p_chunk">@@ -51,6 +51,7 @@</span> <span class="p_context"> void task_mem(struct seq_file *m, struct mm_struct *mm)</span>
 	swap = get_mm_counter(mm, MM_SWAPENTS);
 	ptes = PTRS_PER_PTE * sizeof(pte_t) * atomic_long_read(&amp;mm-&gt;nr_ptes);
 	pmds = PTRS_PER_PMD * sizeof(pmd_t) * mm_nr_pmds(mm);
<span class="p_add">+	puds = PTRS_PER_PUD * sizeof(pmd_t) * mm_nr_puds(mm);</span>
 	seq_printf(m,
 		&quot;VmPeak:\t%8lu kB\n&quot;
 		&quot;VmSize:\t%8lu kB\n&quot;
<span class="p_chunk">@@ -67,6 +68,7 @@</span> <span class="p_context"> void task_mem(struct seq_file *m, struct mm_struct *mm)</span>
 		&quot;VmLib:\t%8lu kB\n&quot;
 		&quot;VmPTE:\t%8lu kB\n&quot;
 		&quot;VmPMD:\t%8lu kB\n&quot;
<span class="p_add">+		&quot;VmPUD:\t%8lu kB\n&quot;</span>
 		&quot;VmSwap:\t%8lu kB\n&quot;,
 		hiwater_vm &lt;&lt; (PAGE_SHIFT-10),
 		total_vm &lt;&lt; (PAGE_SHIFT-10),
<span class="p_chunk">@@ -81,6 +83,7 @@</span> <span class="p_context"> void task_mem(struct seq_file *m, struct mm_struct *mm)</span>
 		mm-&gt;stack_vm &lt;&lt; (PAGE_SHIFT-10), text, lib,
 		ptes &gt;&gt; 10,
 		pmds &gt;&gt; 10,
<span class="p_add">+		puds &gt;&gt; 10,</span>
 		swap &lt;&lt; (PAGE_SHIFT-10));
 	hugetlb_report_usage(m, mm);
 }
<span class="p_header">diff --git a/include/linux/mm.h b/include/linux/mm.h</span>
<span class="p_header">index f8c10d336e42..5125c51c9c35 100644</span>
<span class="p_header">--- a/include/linux/mm.h</span>
<span class="p_header">+++ b/include/linux/mm.h</span>
<span class="p_chunk">@@ -1598,14 +1598,44 @@</span> <span class="p_context"> static inline int __p4d_alloc(struct mm_struct *mm, pgd_t *pgd,</span>
 int __p4d_alloc(struct mm_struct *mm, pgd_t *pgd, unsigned long address);
 #endif
 
<span class="p_del">-#ifdef __PAGETABLE_PUD_FOLDED</span>
<span class="p_add">+#if defined(__PAGETABLE_PUD_FOLDED) || !defined(CONFIG_MMU)</span>
 static inline int __pud_alloc(struct mm_struct *mm, p4d_t *p4d,
 						unsigned long address)
 {
 	return 0;
 }
<span class="p_add">+</span>
<span class="p_add">+static inline unsigned long mm_nr_puds(const struct mm_struct *mm)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return 0;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline void mm_nr_puds_init(struct mm_struct *mm) {}</span>
<span class="p_add">+static inline void mm_inc_nr_puds(struct mm_struct *mm) {}</span>
<span class="p_add">+static inline void mm_dec_nr_puds(struct mm_struct *mm) {}</span>
<span class="p_add">+</span>
 #else
 int __pud_alloc(struct mm_struct *mm, p4d_t *p4d, unsigned long address);
<span class="p_add">+</span>
<span class="p_add">+static inline void mm_nr_puds_init(struct mm_struct *mm)</span>
<span class="p_add">+{</span>
<span class="p_add">+	atomic_long_set(&amp;mm-&gt;nr_puds, 0);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline unsigned long mm_nr_puds(const struct mm_struct *mm)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return atomic_long_read(&amp;mm-&gt;nr_puds);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline void mm_inc_nr_puds(struct mm_struct *mm)</span>
<span class="p_add">+{</span>
<span class="p_add">+	atomic_long_inc(&amp;mm-&gt;nr_puds);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline void mm_dec_nr_puds(struct mm_struct *mm)</span>
<span class="p_add">+{</span>
<span class="p_add">+	atomic_long_dec(&amp;mm-&gt;nr_puds);</span>
<span class="p_add">+}</span>
 #endif
 
 #if defined(__PAGETABLE_PMD_FOLDED) || !defined(CONFIG_MMU)
<span class="p_chunk">@@ -1617,7 +1647,7 @@</span> <span class="p_context"> static inline int __pmd_alloc(struct mm_struct *mm, pud_t *pud,</span>
 
 static inline void mm_nr_pmds_init(struct mm_struct *mm) {}
 
<span class="p_del">-static inline unsigned long mm_nr_pmds(struct mm_struct *mm)</span>
<span class="p_add">+static inline unsigned long mm_nr_pmds(const struct mm_struct *mm)</span>
 {
 	return 0;
 }
<span class="p_chunk">@@ -1633,7 +1663,7 @@</span> <span class="p_context"> static inline void mm_nr_pmds_init(struct mm_struct *mm)</span>
 	atomic_long_set(&amp;mm-&gt;nr_pmds, 0);
 }
 
<span class="p_del">-static inline unsigned long mm_nr_pmds(struct mm_struct *mm)</span>
<span class="p_add">+static inline unsigned long mm_nr_pmds(const struct mm_struct *mm)</span>
 {
 	return atomic_long_read(&amp;mm-&gt;nr_pmds);
 }
<span class="p_header">diff --git a/include/linux/mm_types.h b/include/linux/mm_types.h</span>
<span class="p_header">index 46f4ecf5479a..6c8c2bb9e5a1 100644</span>
<span class="p_header">--- a/include/linux/mm_types.h</span>
<span class="p_header">+++ b/include/linux/mm_types.h</span>
<span class="p_chunk">@@ -401,6 +401,9 @@</span> <span class="p_context"> struct mm_struct {</span>
 	atomic_long_t nr_ptes;			/* PTE page table pages */
 #if CONFIG_PGTABLE_LEVELS &gt; 2
 	atomic_long_t nr_pmds;			/* PMD page table pages */
<span class="p_add">+#endif</span>
<span class="p_add">+#if CONFIG_PGTABLE_LEVELS &gt; 3</span>
<span class="p_add">+	atomic_long_t nr_puds;			/* PUD page table pages */</span>
 #endif
 	int map_count;				/* number of VMAs */
 
<span class="p_header">diff --git a/kernel/fork.c b/kernel/fork.c</span>
<span class="p_header">index 10646182440f..5624918154db 100644</span>
<span class="p_header">--- a/kernel/fork.c</span>
<span class="p_header">+++ b/kernel/fork.c</span>
<span class="p_chunk">@@ -815,6 +815,7 @@</span> <span class="p_context"> static struct mm_struct *mm_init(struct mm_struct *mm, struct task_struct *p,</span>
 	mm-&gt;core_state = NULL;
 	atomic_long_set(&amp;mm-&gt;nr_ptes, 0);
 	mm_nr_pmds_init(mm);
<span class="p_add">+	mm_nr_puds_init(mm);</span>
 	mm-&gt;map_count = 0;
 	mm-&gt;locked_vm = 0;
 	mm-&gt;pinned_vm = 0;
<span class="p_chunk">@@ -874,6 +875,9 @@</span> <span class="p_context"> static void check_mm(struct mm_struct *mm)</span>
 	if (mm_nr_pmds(mm))
 		pr_alert(&quot;BUG: non-zero nr_pmds on freeing mm: %ld\n&quot;,
 				mm_nr_pmds(mm));
<span class="p_add">+	if (mm_nr_puds(mm))</span>
<span class="p_add">+		pr_alert(&quot;BUG: non-zero nr_puds on freeing mm: %ld\n&quot;,</span>
<span class="p_add">+				mm_nr_puds(mm));</span>
 
 #if defined(CONFIG_TRANSPARENT_HUGEPAGE) &amp;&amp; !USE_SPLIT_PMD_PTLOCKS
 	VM_BUG_ON_MM(mm-&gt;pmd_huge_pte, mm);
<span class="p_header">diff --git a/mm/debug.c b/mm/debug.c</span>
<span class="p_header">index 5715448ab0b5..afccb2565269 100644</span>
<span class="p_header">--- a/mm/debug.c</span>
<span class="p_header">+++ b/mm/debug.c</span>
<span class="p_chunk">@@ -104,7 +104,8 @@</span> <span class="p_context"> void dump_mm(const struct mm_struct *mm)</span>
 		&quot;get_unmapped_area %p\n&quot;
 #endif
 		&quot;mmap_base %lu mmap_legacy_base %lu highest_vm_end %lu\n&quot;
<span class="p_del">-		&quot;pgd %p mm_users %d mm_count %d nr_ptes %lu nr_pmds %lu map_count %d\n&quot;</span>
<span class="p_add">+		&quot;pgd %p mm_users %d mm_count %d\n&quot;</span>
<span class="p_add">+		&quot;nr_ptes %lu nr_pmds %lu nr_puds %lu map_count %d\n&quot;</span>
 		&quot;hiwater_rss %lx hiwater_vm %lx total_vm %lx locked_vm %lx\n&quot;
 		&quot;pinned_vm %lx data_vm %lx exec_vm %lx stack_vm %lx\n&quot;
 		&quot;start_code %lx end_code %lx start_data %lx end_data %lx\n&quot;
<span class="p_chunk">@@ -135,7 +136,8 @@</span> <span class="p_context"> void dump_mm(const struct mm_struct *mm)</span>
 		mm-&gt;pgd, atomic_read(&amp;mm-&gt;mm_users),
 		atomic_read(&amp;mm-&gt;mm_count),
 		atomic_long_read((atomic_long_t *)&amp;mm-&gt;nr_ptes),
<span class="p_del">-		mm_nr_pmds((struct mm_struct *)mm),</span>
<span class="p_add">+		mm_nr_pmds(mm),</span>
<span class="p_add">+		mm_nr_puds(mm),</span>
 		mm-&gt;map_count,
 		mm-&gt;hiwater_rss, mm-&gt;hiwater_vm, mm-&gt;total_vm, mm-&gt;locked_vm,
 		mm-&gt;pinned_vm, mm-&gt;data_vm, mm-&gt;exec_vm, mm-&gt;stack_vm,
<span class="p_header">diff --git a/mm/memory.c b/mm/memory.c</span>
<span class="p_header">index ec4e15494901..291d4984b417 100644</span>
<span class="p_header">--- a/mm/memory.c</span>
<span class="p_header">+++ b/mm/memory.c</span>
<span class="p_chunk">@@ -506,6 +506,7 @@</span> <span class="p_context"> static inline void free_pud_range(struct mmu_gather *tlb, p4d_t *p4d,</span>
 	pud = pud_offset(p4d, start);
 	p4d_clear(p4d);
 	pud_free_tlb(tlb, pud, start);
<span class="p_add">+	mm_dec_nr_puds(tlb-&gt;mm);</span>
 }
 
 static inline void free_p4d_range(struct mmu_gather *tlb, pgd_t *pgd,
<span class="p_chunk">@@ -4124,15 +4125,17 @@</span> <span class="p_context"> int __pud_alloc(struct mm_struct *mm, p4d_t *p4d, unsigned long address)</span>
 
 	spin_lock(&amp;mm-&gt;page_table_lock);
 #ifndef __ARCH_HAS_5LEVEL_HACK
<span class="p_del">-	if (p4d_present(*p4d))		/* Another has populated it */</span>
<span class="p_del">-		pud_free(mm, new);</span>
<span class="p_del">-	else</span>
<span class="p_add">+	if (!p4d_present(*p4d)) {</span>
<span class="p_add">+		mm_inc_nr_puds(mm);</span>
 		p4d_populate(mm, p4d, new);
<span class="p_del">-#else</span>
<span class="p_del">-	if (pgd_present(*p4d))		/* Another has populated it */</span>
<span class="p_add">+	} else	/* Another has populated it */</span>
 		pud_free(mm, new);
<span class="p_del">-	else</span>
<span class="p_add">+#else</span>
<span class="p_add">+	if (!pgd_present(*p4d)) {</span>
<span class="p_add">+		mm_inc_nr_puds(mm);</span>
 		pgd_populate(mm, p4d, new);
<span class="p_add">+	} else	/* Another has populated it */</span>
<span class="p_add">+		pud_free(mm, new);</span>
 #endif /* __ARCH_HAS_5LEVEL_HACK */
 	spin_unlock(&amp;mm-&gt;page_table_lock);
 	return 0;
<span class="p_header">diff --git a/mm/oom_kill.c b/mm/oom_kill.c</span>
<span class="p_header">index 99736e026712..4bee6968885d 100644</span>
<span class="p_header">--- a/mm/oom_kill.c</span>
<span class="p_header">+++ b/mm/oom_kill.c</span>
<span class="p_chunk">@@ -200,7 +200,8 @@</span> <span class="p_context"> unsigned long oom_badness(struct task_struct *p, struct mem_cgroup *memcg,</span>
 	 * task&#39;s rss, pagetable and swap space use.
 	 */
 	points = get_mm_rss(p-&gt;mm) + get_mm_counter(p-&gt;mm, MM_SWAPENTS) +
<span class="p_del">-		atomic_long_read(&amp;p-&gt;mm-&gt;nr_ptes) + mm_nr_pmds(p-&gt;mm);</span>
<span class="p_add">+		atomic_long_read(&amp;p-&gt;mm-&gt;nr_ptes) + mm_nr_pmds(p-&gt;mm) +</span>
<span class="p_add">+		mm_nr_puds(p-&gt;mm);</span>
 	task_unlock(p);
 
 	/*
<span class="p_chunk">@@ -376,7 +377,7 @@</span> <span class="p_context"> static void dump_tasks(struct mem_cgroup *memcg, const nodemask_t *nodemask)</span>
 	struct task_struct *p;
 	struct task_struct *task;
 
<span class="p_del">-	pr_info(&quot;[ pid ]   uid  tgid total_vm      rss nr_ptes nr_pmds swapents oom_score_adj name\n&quot;);</span>
<span class="p_add">+	pr_info(&quot;[ pid ]   uid  tgid total_vm      rss nr_ptes nr_pmds nr_puds swapents oom_score_adj name\n&quot;);</span>
 	rcu_read_lock();
 	for_each_process(p) {
 		if (oom_unkillable_task(p, memcg, nodemask))
<span class="p_chunk">@@ -392,11 +393,12 @@</span> <span class="p_context"> static void dump_tasks(struct mem_cgroup *memcg, const nodemask_t *nodemask)</span>
 			continue;
 		}
 
<span class="p_del">-		pr_info(&quot;[%5d] %5d %5d %8lu %8lu %7ld %7ld %8lu         %5hd %s\n&quot;,</span>
<span class="p_add">+		pr_info(&quot;[%5d] %5d %5d %8lu %8lu %7ld %7ld %7ld %8lu         %5hd %s\n&quot;,</span>
 			task-&gt;pid, from_kuid(&amp;init_user_ns, task_uid(task)),
 			task-&gt;tgid, task-&gt;mm-&gt;total_vm, get_mm_rss(task-&gt;mm),
 			atomic_long_read(&amp;task-&gt;mm-&gt;nr_ptes),
 			mm_nr_pmds(task-&gt;mm),
<span class="p_add">+			mm_nr_puds(task-&gt;mm),</span>
 			get_mm_counter(task-&gt;mm, MM_SWAPENTS),
 			task-&gt;signal-&gt;oom_score_adj, task-&gt;comm);
 		task_unlock(task);

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



