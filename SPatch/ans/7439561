
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>[v2] arm64: Add support for PTE contiguous bit. - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    [v2] arm64: Add support for PTE contiguous bit.</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=142331">David Woods</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>Oct. 19, 2015, 8:09 p.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;1445285349-13242-1-git-send-email-dwoods@ezchip.com&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/7439561/mbox/"
   >mbox</a>
|
   <a href="/patch/7439561/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/7439561/">/patch/7439561/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
X-Original-To: patchwork-LKML@patchwork.kernel.org
Delivered-To: patchwork-parsemail@patchwork2.web.kernel.org
Received: from mail.kernel.org (mail.kernel.org [198.145.29.136])
	by patchwork2.web.kernel.org (Postfix) with ESMTP id 76C8FBEEA4
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Mon, 19 Oct 2015 20:09:42 +0000 (UTC)
Received: from mail.kernel.org (localhost [127.0.0.1])
	by mail.kernel.org (Postfix) with ESMTP id 1F802206D2
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Mon, 19 Oct 2015 20:09:41 +0000 (UTC)
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.kernel.org (Postfix) with ESMTP id 7B42C206D9
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Mon, 19 Oct 2015 20:09:39 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1753677AbbJSUJf (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Mon, 19 Oct 2015 16:09:35 -0400
Received: from mail-db3on0078.outbound.protection.outlook.com
	([157.55.234.78]:12987
	&quot;EHLO emea01-db3-obe.outbound.protection.outlook.com&quot;
	rhost-flags-OK-OK-OK-FAIL) by vger.kernel.org with ESMTP
	id S1751358AbbJSUJd (ORCPT &lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Mon, 19 Oct 2015 16:09:33 -0400
Received: from DB3PR02MB0441.eurprd02.prod.outlook.com (10.160.50.145) by
	DB3PR02MB026.eurprd02.prod.outlook.com (10.242.128.22) with Microsoft
	SMTP Server (TLS) id 15.1.300.14; Mon, 19 Oct 2015 20:09:31 +0000
Received: from DB3PR02CA0004.eurprd02.prod.outlook.com (10.242.134.14) by
	DB3PR02MB0441.eurprd02.prod.outlook.com (10.160.50.145) with
	Microsoft SMTP
	Server (TLS) id 15.1.300.14; Mon, 19 Oct 2015 20:09:29 +0000
Received: from DB3FFO11FD006.protection.gbl (2a01:111:f400:7e04::117) by
	DB3PR02CA0004.outlook.office365.com (2a01:111:e400:9814::14) with
	Microsoft SMTP Server (TLS) id 15.1.300.14 via Frontend Transport;
	Mon, 19 Oct 2015 20:09:29 +0000
Authentication-Results: spf=fail (sender IP is 12.216.194.146)
	smtp.mailfrom=ezchip.com; ezchip.com; dkim=none (message not signed)
	header.d=none; ezchip.com;
	dmarc=none action=none header.from=ezchip.com; 
Received-SPF: Fail (protection.outlook.com: domain of ezchip.com does not
	designate 12.216.194.146 as permitted sender)
	receiver=protection.outlook.com; client-ip=12.216.194.146;
	helo=ld-2.internal.tilera.com;
Received: from ld-2.internal.tilera.com (12.216.194.146) by
	DB3FFO11FD006.mail.protection.outlook.com (10.47.216.95) with
	Microsoft SMTP Server (TLS) id 15.1.300.4 via Frontend Transport;
	Mon, 19 Oct 2015 20:09:28 +0000
Received: (from dwoods@localhost)
	by ld-2.internal.tilera.com (8.14.4/8.14.4/Submit) id t9JK9RZo013288; 
	Mon, 19 Oct 2015 16:09:27 -0400
From: David Woods &lt;dwoods@ezchip.com&gt;
To: &lt;dwoods@ezchip.com&gt;
CC: &lt;catalin.marinas@arm.com&gt;, &lt;will.deacon@arm.com&gt;,
	&lt;steve.capper@linaro.org&gt;, &lt;jeremy.linton@arm.com&gt;,
	&lt;linux-arm-kernel@lists.infradead.org&gt;,
	&lt;linux-kernel@vger.kernel.org&gt;, &lt;linux-mm@kvack.org&gt;,
	&lt;cmetcalf@ezchip.com&gt;
Subject: [PATCH v2] arm64: Add support for PTE contiguous bit.
Date: Mon, 19 Oct 2015 16:09:09 -0400
Message-ID: &lt;1445285349-13242-1-git-send-email-dwoods@ezchip.com&gt;
X-Mailer: git-send-email 2.1.2
X-EOPAttributedMessage: 0
X-Microsoft-Exchange-Diagnostics: 1; DB3FFO11FD006;
	1:Bd9MztA+yuxJn/cYgyXnMzMgLobU/w8pLdAIMy9vpXXFROkHA7nNYrZW9uVBORrtHl0lsK5/S/nrSSS2I9RKA5KPhhjFpILFUCfuw6bqs4NNCD3EdLtr4uzNFquQneyrXKAQLRXP4HubMmkn7z9mQ2Im+oPnqo2o2A8fpju9YI+E5gGAL5D4Fytg/87Payph8sXVaBC1VmML4g1xKfix6hxSHCqc8Rm5iEdsYNi8wY22anu0iJfNNHnB29r29gOa/e7T9ZmBGFPbRy5fhs8VDZpmSyrC/NZLji8A1Qmt/okDySK4x7KlNY7MEDqodL8AlOM4S/l9xqIntwPebYua1vcod21dY45eR8V8x5V4by4=
X-Forefront-Antispam-Report: CIP:12.216.194.146; CTRY:US; IPV:NLI; EFV:NLI;
	SFV:NSPM;
	SFS:(10009020)(6009001)(2980300002)(1110001)(1109001)(339900001)(199003)(189002)(33646002)(46102003)(64706001)(5007970100001)(11100500001)(19580405001)(42186005)(6200100001)(5001960100002)(110136002)(107886002)(19580395003)(189998001)(50226001)(50986999)(47776003)(85426001)(36756003)(86362001)(50466002)(4001450100002)(48376002)(2351001)(5008740100001)(229853001)(6806005)(106476002)(106356001)(106466001)(104016004)(81156007)(7049001)(5003940100001)(92566002)(87936001)(97736004)(105606002)(9376005)(4001430100001);
	DIR:OUT; SFP:1101; SCL:1; SRVR:DB3PR02MB0441;
	H:ld-2.internal.tilera.com; FPR:; SPF:Fail; PTR:InfoNoRecords;
	A:1; MX:1; LANG:en; 
MIME-Version: 1.0
Content-Type: text/plain
X-Microsoft-Exchange-Diagnostics: 1; DB3PR02MB0441;
	2:1StRUDRzICcDGYWlqDfGqNeW7rZBWxzX7tEv+CJ4PE6v3YQ0P13g3zLvhNdcD+AAsDB+XYk9iUDh6lR2rBp5TKtu1Q0fUC7Of2Dh2ikFEyOPxJyJ1ZYXuOXVLYUxBnPYGrT5I4nfJuJ7rCYbj8Nqv0Q1brbWFNLHPeHDsJJ5CSA=;
	3:gjKPbXT9LslmVzeNSyifl6gC3N+FsdkgpGJnRuo9709IJfD4pv3B9nXENRTNVU6pXQUfpwGDD6DSkgvoIFiGGwET+GlvPU7kutanguOmAZOpdIOh1izTpbiIjD3XjGlwqUBgal24UjGiuGV+1ETetpnnj+8KCZpFb1zf3z8mr8dh4AYsLP5ajTE6jMuyjXrPio51WErQyFnVMISMP2esJQ6Cs46PPxQBbjmrn23ZHMVz6PfP/Qi4uM4CQngpJrYs;
	25:mf4CHMy/zhEzPkQH5fiTgVOJVh5PNoayPn/cyx+o32fp+5u+dG6k2MHmkU+/JsxCe8QAjgd9QTI0lmQrTRJFsuXu0lU8bq5LTuWlib+yrY8ueYCklG2xrnrLDAuWQh6M6EYHst1vB31+3ygYUQ48DdXH8v+pOx133fs9FO3MC4lo8d469CpRrPFClwNuKPgBC/genK8BOau8gZbdwEkOszHg9NVxkursbXpQyBmeuawnDOQMUmE9hdg3iBYKwYOK;
	20:wQKSF51KcKQBm4CgmBXKGIwJpN28oenaOiITlRYyheW0svvkUZzTbXqdr10SdE6mtTp6zrRA8y3Iw6snNZ+UhQlxB2+I1OpZutNkSN139J/lq8Ty7hC4ycAWgNgU+IvKgvahDgfcWAg6ZjEIXujU5rmkKy2sBPNm0QWVntIgre4=
X-Microsoft-Antispam: UriScan:;BCL:0;PCL:0;RULEID:;SRVR:DB3PR02MB0441;
X-Microsoft-Antispam-PRVS: &lt;DB3PR02MB0441AAC7C1EC5E2A5D03F505BC3A0@DB3PR02MB0441.eurprd02.prod.outlook.com&gt;
X-Exchange-Antispam-Report-Test: UriScan:(121898900299872);
X-Exchange-Antispam-Report-CFA-Test: BCL:0; PCL:0;
	RULEID:(601004)(2401047)(5005006)(520078)(8121501046)(3002001);
	SRVR:DB3PR02MB0441; BCL:0; PCL:0; RULEID:; SRVR:DB3PR02MB0441;
X-Microsoft-Exchange-Diagnostics: 1; DB3PR02MB0441;
	4:52O0cO7kuNcI5HRU19D6a/imG8d+p+otQNuspH62irBExbh2caruXUzs67Wje/oa3CSExRxcG38zKbHH3pkv9ED6ALFQjFrQPZ7nF/6W7YxQRctuboSmROMcoth8MWp7lTKs4xmJ/jdwJ4HdAWP0/bJgV1HTlhbi0M05AYKaSpoKNWa6h55Ek1OUd8+RJwqS9ve0VJ7ZbNOtTnQ1x7kmKVWKuiju7xVqAmrUjLNMMJjbm+V8Bg2bfTVkIxek3N/TonduOHoUzHuhBiFWvpXSVx6c7CXxVAVy72Iai02d8+3+eQMUXxqY57X7x0hZYoGruiLoq3oFMSta0OS2X57lc26GQkypdS3AFe/fjr/D77I=
X-Forefront-PRVS: 07349BFAD2
X-Microsoft-Exchange-Diagnostics: =?us-ascii?Q?1; DB3PR02MB0441;
	23:yE1jI1EuUxyKA3ApG3lSNwYera5TSNiyht0SI3bXM?=
	=?us-ascii?Q?tTM2Y46aC1CWj6sEShOg2xn4B1ldjeabfloYk7FXrgTaO6I9tB/Oq4MmmYGY?=
	=?us-ascii?Q?GyRCqt4rwj5DNSNeOAg93enD+zGLH4u6FBPQLI8TDq20+pSQCXaANgkaAu1l?=
	=?us-ascii?Q?OVY79i8DtF49t1L6rMsR5s9kBNyHf8Y9k5/AUdry9hCQchqfhYr6CNwZkCcI?=
	=?us-ascii?Q?qhxbDKu0/zjS5xk0AQ8hRNTmb8+OUb5GSeJGyS6oZdvfzF8XsmQ8dtc+F7yL?=
	=?us-ascii?Q?k8l+QYt6uMUJd2+xdnWIOlKhAGFnSa6qkeSjWcWnsLWE8LXdlSvPAVJglazW?=
	=?us-ascii?Q?PMGKRDrmv65f0WYTaSBv1g7b1IjYkDHfMa9Qeg3Id9OTXJ2KKYbu4zN7wtqr?=
	=?us-ascii?Q?D2yO5YYZlYXEYC5xg4aebsOVHxqrBqZQwA7q1Mfdv10dz7uJTpSZQAxtmJsK?=
	=?us-ascii?Q?7sU8TrMWzWeuL+W7kulOVKgTPDrrCfrucI71Em8v6sB6z1AsNHudBSiaQA28?=
	=?us-ascii?Q?UzbwecKukWVgqgliqatwqLVch00plhVklfYK49fgLJCKSrGHTGl8UixYOwW6?=
	=?us-ascii?Q?MX11uQaN9li/WHhnUSg1wp8soQhk+AJiI0NcxU25sS/qWkpTAr4Z0UX1VYQ1?=
	=?us-ascii?Q?6QbrxJF45V9NZAIG8YIYyETxofXm8Cfr2AmSowKCRRZmHVaUMrzaRetCj/ic?=
	=?us-ascii?Q?a6oSB/TECFucnIGiaW4HgvLJ1nXGLJYWb4tPPFOi3ZAJD0rid6K5iyCk3sh6?=
	=?us-ascii?Q?Nhbi4zv9hjErz2jpP9UckXpNMvJWdWKVygoSAVrM3gElJIRfx7qJpizraWAf?=
	=?us-ascii?Q?VAIyCaXvJoBsfu/qqrZKxyhb9tziAYe6jyB0Kya+3Zczp+QkUbt3NMOBsxSu?=
	=?us-ascii?Q?PEFbxc9mTEk+5DTSrCTsEh2yOC+bvcgxStSctvrgpTYTflgOjQ4FajbI60uv?=
	=?us-ascii?Q?Frfcb2iLD9ADm4twN/aKQwH0aMrkMSo9Zwxdz8PMeKBPB6JVth/v87EJDteO?=
	=?us-ascii?Q?nUUrUeeH/89F0n4oiy3tK3SYvZAmMaegvDeUDgsY8xmEJnwdqjPsFjJ4wdBS?=
	=?us-ascii?Q?1BP98RtoG5LKjUKmzZbXhJeHrENw9aYCEvQ1xKAwoBcHgt3o14dLkr0Xq0BB?=
	=?us-ascii?Q?lwBgA8/dxli7KexHGRltG9Iw3kAm5QJ9xPRAUuoYgHtkhTva2G+0Ka7SH158?=
	=?us-ascii?Q?E3+3LgVcFCWdC6/yJVvhNR1DuFB0RErKigG4Tj5Opf0gNKv/9ke5NZm8A=3D?=
	=?us-ascii?Q?=3D?=
X-Microsoft-Exchange-Diagnostics: 1; DB3PR02MB0441;
	5:HiQbq1Kul+HpGnEcmMDq0TCfJ1loJjcI1jfyLK94k0PESpj2rRCN5E016U8U1cMjU+gjFCZpcgoUwLR2LBfxybU7ing/19YSb2d2m/V3sCTcjKpW5vR16o5VMOIwkcy0E9Pjhs7cSMNRTnxmcUB2zg==;
	24:NdBGcFuNc73SKP9L3SDoQOBb4x4AS4fA3Corm98jxVQZgl9MM9DIH9nT5c+Sr7Verw3scqLBQUvhgqnpnKvkRX66LTs21KNTyjqqFNsEvIA=;
	20:HvLfN723iiwOpyGp0fn1kZIYnEK1lfCwSlnYI1LiH3jCMV2n+bF1chcTPqM3XiKm4e7Be2uEyHT+QRzFYWfAgw==
SpamDiagnosticOutput: 1:23
SpamDiagnosticMetadata: NSPM
X-MS-Exchange-CrossTenant-OriginalArrivalTime: 19 Oct 2015 20:09:28.7922
	(UTC)
X-MS-Exchange-CrossTenant-Id: 0fc16e0a-3cd3-4092-8b2f-0a42cff122c3
X-MS-Exchange-CrossTenant-OriginalAttributedTenantConnectingIp: TenantId=0fc16e0a-3cd3-4092-8b2f-0a42cff122c3;
	Ip=[12.216.194.146]; Helo=[ld-2.internal.tilera.com]
X-MS-Exchange-CrossTenant-FromEntityHeader: HybridOnPrem
X-MS-Exchange-Transport-CrossTenantHeadersStamped: DB3PR02MB0441
X-Microsoft-Exchange-Diagnostics: 1; DB3PR02MB026;
	2:8HSHADTr4NS1W69VH9/bfHUoIC/4VM7TVbiAO7J7HPZMVhrTpQqO7YqolryhA37/Rs+iJPQo/MY/BWQ6ZuEYZbuqr6O2hknFTKZmQexStPCyl0muVWFeB85Bj7whCKxtJUEm5Z/xIBVM3oFipeGsUutY4XBy7zBTaV3c6suwZxE=;
	23:FsVDLT3JxCMTHXSxFiXCTNLauAY6xrD1bbRCJfmThddptfsxf3a1Bh87J2Q026fQekpa0L2MqnvdwIVxfmqCJOmmRCcx9IJ41RU/LDtySF76/ydi/TJyWwknj6ZjnX15JJ4H5+sGiM3NOFSMDekbAi+diQhlV3Ed4LWphWHM6JI4HKRpiRHfxZ1eUOegvq/L
X-OriginatorOrg: ezchip.com
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Spam-Status: No, score=-6.9 required=5.0 tests=BAYES_00, RCVD_IN_DNSWL_HI, 
	RP_MATCHES_RCVD,
	UNPARSEABLE_RELAY autolearn=unavailable version=3.3.1
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on mail.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=142331">David Woods</a> - Oct. 19, 2015, 8:09 p.m.</div>
<pre class="content">
The arm64 MMU supports a Contiguous bit which is a hint that the TTE
is one of a set of contiguous entries which can be cached in a single
TLB entry.  Supporting this bit adds new intermediate huge page sizes.

The set of huge page sizes available depends on the base page size.
Without using contiguous pages the huge page sizes are as follows.

 4KB:   2MB  1GB
64KB: 512MB

With a 4KB granule, the contiguous bit groups together sets of 16 pages
and with a 64KB granule it groups sets of 32 pages.  This enables two new
huge page sizes in each case, so that the full set of available sizes
is as follows.

 4KB:  64KB   2MB  32MB  1GB
64KB:   2MB 512MB  16GB

If a 16KB granule is used then the contiguous bit groups 128 pages
at the PTE level and 32 pages at the PMD level.

If the base page size is set to 64KB then 2MB pages are enabled by
default.  It is possible in the future to make 2MB the default huge
page size for both 4KB and 64KB granules.
<span class="signed-off-by">
Signed-off-by: David Woods &lt;dwoods@ezchip.com&gt;</span>
<span class="reviewed-by">Reviewed-by: Chris Metcalf &lt;cmetcalf@ezchip.com&gt;</span>
---
 arch/arm64/Kconfig                     |   3 -
 arch/arm64/include/asm/hugetlb.h       |  30 ++---
 arch/arm64/include/asm/pgtable-hwdef.h |  20 ++++
 arch/arm64/include/asm/pgtable.h       |  33 +++++-
 arch/arm64/mm/hugetlbpage.c            | 211 ++++++++++++++++++++++++++++++++-
 5 files changed, 272 insertions(+), 25 deletions(-)
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=64911">Steve Capper</a> - Oct. 20, 2015, 12:16 p.m.</div>
<pre class="content">
On Mon, Oct 19, 2015 at 04:09:09PM -0400, David Woods wrote:
<span class="quote">&gt; The arm64 MMU supports a Contiguous bit which is a hint that the TTE</span>
<span class="quote">&gt; is one of a set of contiguous entries which can be cached in a single</span>
<span class="quote">&gt; TLB entry.  Supporting this bit adds new intermediate huge page sizes.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; The set of huge page sizes available depends on the base page size.</span>
<span class="quote">&gt; Without using contiguous pages the huge page sizes are as follows.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt;  4KB:   2MB  1GB</span>
<span class="quote">&gt; 64KB: 512MB</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; With a 4KB granule, the contiguous bit groups together sets of 16 pages</span>
<span class="quote">&gt; and with a 64KB granule it groups sets of 32 pages.  This enables two new</span>
<span class="quote">&gt; huge page sizes in each case, so that the full set of available sizes</span>
<span class="quote">&gt; is as follows.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt;  4KB:  64KB   2MB  32MB  1GB</span>
<span class="quote">&gt; 64KB:   2MB 512MB  16GB</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; If a 16KB granule is used then the contiguous bit groups 128 pages</span>
<span class="quote">&gt; at the PTE level and 32 pages at the PMD level.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; If the base page size is set to 64KB then 2MB pages are enabled by</span>
<span class="quote">&gt; default.  It is possible in the future to make 2MB the default huge</span>
<span class="quote">&gt; page size for both 4KB and 64KB granules.</span>

Thank you for the V2 David,
I have some comments below.

I would recommend running the next version of this series through
the libhugetlbfs test suite, as that may pick up a few things too.

Cheers,
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=142331">David Woods</a> - Nov. 18, 2015, 8:33 p.m.</div>
<pre class="content">
On 10/20/2015 08:16 AM, Steve Capper wrote:
<span class="quote">&gt; On Mon, Oct 19, 2015 at 04:09:09PM -0400, David Woods wrote:</span>
<span class="quote">&gt;&gt; &gt;The arm64 MMU supports a Contiguous bit which is a hint that the TTE</span>
<span class="quote">&gt;&gt; &gt;is one of a set of contiguous entries which can be cached in a single</span>
<span class="quote">&gt;&gt; &gt;TLB entry.  Supporting this bit adds new intermediate huge page sizes.</span>
<span class="quote">&gt;&gt; &gt;</span>
<span class="quote">&gt;&gt; &gt;The set of huge page sizes available depends on the base page size.</span>
<span class="quote">&gt;&gt; &gt;Without using contiguous pages the huge page sizes are as follows.</span>
<span class="quote">&gt;&gt; &gt;</span>
<span class="quote">&gt;&gt; &gt;  4KB:   2MB  1GB</span>
<span class="quote">&gt;&gt; &gt;64KB: 512MB</span>
<span class="quote">&gt;&gt; &gt;</span>
<span class="quote">&gt;&gt; &gt;With a 4KB granule, the contiguous bit groups together sets of 16 pages</span>
<span class="quote">&gt;&gt; &gt;and with a 64KB granule it groups sets of 32 pages.  This enables two new</span>
<span class="quote">&gt;&gt; &gt;huge page sizes in each case, so that the full set of available sizes</span>
<span class="quote">&gt;&gt; &gt;is as follows.</span>
<span class="quote">&gt;&gt; &gt;</span>
<span class="quote">&gt;&gt; &gt;  4KB:  64KB   2MB  32MB  1GB</span>
<span class="quote">&gt;&gt; &gt;64KB:   2MB 512MB  16GB</span>
<span class="quote">&gt;&gt; &gt;</span>
<span class="quote">&gt;&gt; &gt;If a 16KB granule is used then the contiguous bit groups 128 pages</span>
<span class="quote">&gt;&gt; &gt;at the PTE level and 32 pages at the PMD level.</span>
<span class="quote">&gt;&gt; &gt;</span>
<span class="quote">&gt;&gt; &gt;If the base page size is set to 64KB then 2MB pages are enabled by</span>
<span class="quote">&gt;&gt; &gt;default.  It is possible in the future to make 2MB the default huge</span>
<span class="quote">&gt;&gt; &gt;page size for both 4KB and 64KB granules.</span>
<span class="quote">&gt; Thank you for the V2 David,</span>
<span class="quote">&gt; I have some comments below.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; I would recommend running the next version of this series through</span>
<span class="quote">&gt; the libhugetlbfs test suite, as that may pick up a few things too.</span>

Thanks Steve, for your detailed review.  I did run the libhugetlbfs test 
suite
and it turned up a bug which I&#39;ll point out below.  I&#39;ll post a V3 shortly.
<span class="quote">
&gt;</span>
<span class="quote">&gt; Cheers,</span>
<span class="quote">&gt; -- Steve</span>
<span class="quote">&gt; &gt;  </span>
<span class="quote">&gt; &gt;+static inline pte_t pte_mkcont(pte_t pte)</span>
<span class="quote">&gt; &gt;+{</span>
<span class="quote">&gt; &gt;+	pte = set_pte_bit(pte, __pgprot(PTE_CONT));</span>
<span class="quote">&gt; &gt;+	return set_pte_bit(pte, __pgprot(PTE_TYPE_PAGE));</span>
<span class="quote">&gt; &gt;+	return pte;</span>
<span class="quote">&gt; The second return should be removed.</span>

Done.
<span class="quote">&gt;</span>
<span class="quote">&gt; &gt;  /*</span>
<span class="quote">&gt; &gt;   * Hugetlb definitions.</span>
<span class="quote">&gt; &gt;   */</span>
<span class="quote">&gt; &gt;-#define HUGE_MAX_HSTATE		2</span>
<span class="quote">&gt; &gt;+#define HUGE_MAX_HSTATE		((2 * CONFIG_PGTABLE_LEVELS) - 1)</span>
<span class="quote">&gt; Not sure about this definition. I would just go with the maximum possible</span>
<span class="quote">&gt; which is for a 4KB granule:</span>
<span class="quote">&gt; 1 x 1GB pud</span>
<span class="quote">&gt; 1 x 2MB pmd</span>
<span class="quote">&gt; 16 x 2MB pmds</span>
<span class="quote">&gt; 16 x 4KB ptes</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; So 4 for now?</span>

This made some sense when I was thinking of supporting contiguous
PUDs.  I&#39;ve changed it to 4 as you suggest.
<span class="quote">&gt;&gt; &gt;  #define HPAGE_SHIFT		PMD_SHIFT</span>
<span class="quote">&gt;&gt; &gt;  #define HPAGE_SIZE		(_AC(1, UL) &lt;&lt; HPAGE_SHIFT)</span>
<span class="quote">&gt;&gt; &gt;  #define HPAGE_MASK		(~(HPAGE_SIZE - 1))</span>
<span class="quote">&gt;&gt; &gt;@@ -496,7 +509,7 @@ static inline pud_t *pud_offset(pgd_t *pgd, unsigned long addr)</span>
<span class="quote">&gt;&gt; &gt;  static inline pte_t pte_modify(pte_t pte, pgprot_t newprot)</span>
<span class="quote">&gt;&gt; &gt;  {</span>
<span class="quote">&gt;&gt; &gt;  	const pteval_t mask = PTE_USER | PTE_PXN | PTE_UXN | PTE_RDONLY |</span>
<span class="quote">&gt;&gt; &gt;-			      PTE_PROT_NONE | PTE_VALID | PTE_WRITE;</span>
<span class="quote">&gt;&gt; &gt;+			      PTE_PROT_NONE | PTE_VALID | PTE_WRITE | PTE_CONT;</span>
<span class="quote">&gt; Why has PTE_CONT been added to the pte_modify mask? This will allow</span>
<span class="quote">&gt; functions such as mprotect to remove the PTE_CONT bit.</span>
Right, this is not needed anymore.
<span class="quote">&gt;</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; &gt;  </span>
<span class="quote">&gt; &gt;+static inline pte_t pte_modify_pfn(pte_t pte, unsigned long newpfn)</span>
<span class="quote">&gt; &gt;+{</span>
<span class="quote">&gt; &gt;+	const pteval_t mask = PHYS_MASK &amp; PAGE_MASK;</span>
<span class="quote">&gt; &gt;+</span>
<span class="quote">&gt; &gt;+	pte_val(pte) = pfn_pte(newpfn, (pte_val(pte) &amp; ~mask));</span>
<span class="quote">&gt; &gt;+	return pte;</span>
<span class="quote">&gt; &gt;+}</span>
<span class="quote">&gt; &gt;+</span>
<span class="quote">&gt; &gt;+static inline pmd_t pmd_modify_pfn(pmd_t pmd, unsigned long newpfn)</span>
<span class="quote">&gt; &gt;+{</span>
<span class="quote">&gt; &gt;+	const pmdval_t mask = PHYS_MASK &amp; PAGE_MASK;</span>
<span class="quote">&gt; &gt;+</span>
<span class="quote">&gt; &gt;+	pmd = pfn_pmd(newpfn, (pmd_val(pmd) &amp; ~mask));</span>
<span class="quote">&gt; &gt;+	return pmd;</span>
<span class="quote">&gt; &gt;+}</span>
<span class="quote">&gt; pte_modify_pfn and pmd_modify_pfn aren&#39;t referenced anywhere in the</span>
<span class="quote">&gt; patch so should be removed.</span>
Removed.
<span class="quote">&gt;</span>
<span class="quote">&gt;&gt; &gt;  </span>
<span class="quote">&gt;&gt; &gt;+static int find_num_contig(struct mm_struct *mm, unsigned long addr,</span>
<span class="quote">&gt;&gt; &gt;+			   pte_t *ptep, pte_t pte, size_t *pgsize)</span>
<span class="quote">&gt;&gt; &gt;+{</span>
<span class="quote">&gt;&gt; &gt;+	pgd_t *pgd = pgd_offset(mm, addr);</span>
<span class="quote">&gt;&gt; &gt;+	pud_t *pud;</span>
<span class="quote">&gt;&gt; &gt;+	pmd_t *pmd;</span>
<span class="quote">&gt;&gt; &gt;+</span>
<span class="quote">&gt;&gt; &gt;+	if (!pte_cont(pte))</span>
<span class="quote">&gt;&gt; &gt;+		return 1;</span>
<span class="quote">&gt;&gt; &gt;+</span>
<span class="quote">&gt;&gt; &gt;+	pud = pud_offset(pgd, addr);</span>
<span class="quote">&gt;&gt; &gt;+	pmd = pmd_offset(pud, addr);</span>
<span class="quote">&gt; We need to check for pgd_present and pud_present as we walk.</span>
<span class="quote">&gt; I would be tempted to VM_BUG_ON if they are in an unexpected state.</span>
Ok.
<span class="quote">&gt;</span>
<span class="quote">&gt;&gt; &gt;+	if ((pte_t *)pmd == ptep) {</span>
<span class="quote">&gt;&gt; &gt;+		*pgsize = PMD_SIZE;</span>
<span class="quote">&gt;&gt; &gt;+		return CONT_PMDS;</span>
<span class="quote">&gt;&gt; &gt;+	}</span>
<span class="quote">&gt; I would check for pmd_present and VM_BUG_ON if it wasn&#39;t in an expected</span>
<span class="quote">&gt; state.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;&gt; &gt;+	*pgsize = PAGE_SIZE;</span>
<span class="quote">&gt;&gt; &gt;+	return CONT_PTES;</span>
<span class="quote">&gt;&gt; &gt;+}</span>
<span class="quote">&gt; Another approach would be something like:</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; struct vm_area_struct *vma = find_vma(mm, addr);</span>
<span class="quote">&gt; struct hstate *h = hstate_vma(vma);</span>
<span class="quote">&gt; size_t size = hpage_size(h);</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; But I think looking at the page table entries like you&#39;ve done (with</span>
<span class="quote">&gt; some checking) may be a little better as it can supply some more robust</span>
<span class="quote">&gt; debugging with DEBUG_VM selected (and it doesn&#39;t need to find_vma).</span>

I left it as-is with the appropriate checks added.
<span class="quote">&gt;&gt; &gt;+</span>
<span class="quote">&gt;&gt; &gt;+extern void set_huge_pte_at(struct mm_struct *mm, unsigned long addr,</span>
<span class="quote">&gt;&gt; &gt;+			    pte_t *ptep, pte_t pte)</span>
<span class="quote">&gt; We don&#39;t need this extern.</span>

Ok.
<span class="quote">&gt;&gt; &gt;+{</span>
<span class="quote">&gt;&gt; &gt;+	size_t pgsize;</span>
<span class="quote">&gt;&gt; &gt;+	int ncontig = find_num_contig(mm, addr, ptep, pte, &amp;pgsize);</span>
<span class="quote">&gt;&gt; &gt;+</span>
<span class="quote">&gt;&gt; &gt;+	if (ncontig == 1) {</span>
<span class="quote">&gt;&gt; &gt;+		set_pte_at(mm, addr, ptep, pte);</span>
<span class="quote">&gt; We can return early here and avoid a level of indentation below.</span>
Ok.
<span class="quote">
&gt;&gt; &gt;+	} else {</span>
<span class="quote">&gt;&gt; &gt;+		int i;</span>
<span class="quote">&gt;&gt; &gt;+		unsigned long pfn = pte_pfn(pte);</span>
<span class="quote">&gt;&gt; &gt;+		pgprot_t hugeprot =</span>
<span class="quote">&gt;&gt; &gt;+			__pgprot(pte_val(pfn_pte(pfn, 0) ^ pte_val(pte)));</span>
<span class="quote">&gt;&gt; &gt;+		for (i = 0; i &lt; ncontig; i++) {</span>
<span class="quote">&gt;&gt; &gt;+			pr_debug(&quot;%s: set pte %p to 0x%llx\n&quot;, __func__, ptep,</span>
<span class="quote">&gt;&gt; &gt;+				 pfn_pte(pfn, hugeprot));</span>
<span class="quote">&gt;&gt; &gt;+			set_pte_at(mm, addr, ptep, pfn_pte(pfn, hugeprot));</span>
<span class="quote">&gt;&gt; &gt;+			ptep++;</span>
<span class="quote">&gt;&gt; &gt;+			pfn += pgsize / PAGE_SIZE;</span>
<span class="quote">&gt; nit: pgsize &gt;&gt; PAGE_SHIFT</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;&gt; &gt;+			addr += pgsize;</span>
<span class="quote">&gt;&gt; &gt;+		}</span>
<span class="quote">&gt;&gt; &gt;+	}</span>
<span class="quote">&gt;&gt; &gt;+}</span>
<span class="quote">&gt; I see... so the contiguous pte and pmd cases are folded together.</span>
<span class="quote">&gt; The pgsize variable name could be changed, perhaps something like blocksize?</span>
<span class="quote">&gt; (I am terrible at picking names though :-)).</span>

Well, isn&#39;t it still called a page even it it happens to be a
pmd level/huge page?
<span class="quote">
&gt;</span>
<span class="quote">&gt;&gt; &gt;+</span>
<span class="quote">&gt;&gt; &gt;+pte_t *huge_pte_alloc(struct mm_struct *mm,</span>
<span class="quote">&gt;&gt; &gt;+		      unsigned long addr, unsigned long sz)</span>
<span class="quote">&gt;&gt; &gt;+{</span>
<span class="quote">&gt;&gt; &gt;+	pgd_t *pgd;</span>
<span class="quote">&gt;&gt; &gt;+	pud_t *pud;</span>
<span class="quote">&gt;&gt; &gt;+	pte_t *pte = NULL;</span>
<span class="quote">&gt;&gt; &gt;+</span>
<span class="quote">&gt;&gt; &gt;+	pr_debug(&quot;%s: addr:0x%lx sz:0x%lx\n&quot;, __func__, addr, sz);</span>
<span class="quote">&gt;&gt; &gt;+	pgd = pgd_offset(mm, addr);</span>
<span class="quote">&gt;&gt; &gt;+	pud = pud_alloc(mm, pgd, addr);</span>
<span class="quote">&gt; Probably better to simplify the levels of indentation with:</span>
<span class="quote">&gt; 	if (!pud)</span>
<span class="quote">&gt; 		return NULL;</span>
<span class="quote">&gt; (or goto out before your pr_debug)</span>

Ok.
<span class="quote">&gt;</span>
<span class="quote">&gt;&gt; &gt;+	if (pud) {</span>
<span class="quote">&gt; Perhaps better to do something with switch(sz) below?</span>

The problem with using switch is that depending on the number of
page table levels, some of the cases degenerate to the same value.
So we end up with compile time errors because of duplicate case
statements.
<span class="quote">&gt;</span>
<span class="quote">&gt;&gt; &gt;+		if (sz == PUD_SIZE) {</span>
<span class="quote">&gt;&gt; &gt;+			pte = (pte_t *)pud;</span>
<span class="quote">&gt;&gt; &gt;+		} else if (sz == (PAGE_SIZE * CONT_PTES)) {</span>
<span class="quote">&gt;&gt; &gt;+			pmd_t *pmd = pmd_alloc(mm, pud, addr);</span>
<span class="quote">&gt;&gt; &gt;+</span>
<span class="quote">&gt;&gt; &gt;+			WARN_ON(addr &amp; (sz - 1));</span>
<span class="quote">&gt;&gt; &gt;+			pte = pte_alloc_map(mm, NULL, pmd, addr);</span>
<span class="quote">&gt;&gt; &gt;+		} else if (sz == PMD_SIZE) {</span>
<span class="quote">&gt;&gt; &gt;+#ifdef CONFIG_ARCH_WANT_HUGE_PMD_SHARE</span>
<span class="quote">&gt;&gt; &gt;+			if (pud_none(*pud))</span>
<span class="quote">&gt;&gt; &gt;+				pte = huge_pmd_share(mm, addr, pud);</span>
<span class="quote">&gt;&gt; &gt;+			else</span>
<span class="quote">&gt;&gt; &gt;+#endif</span>
<span class="quote">&gt; This can be simplified to something like:</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; if (IS_ENABLED(CONFIG_ARCH_WANT_HUGE_PMD_SHARE)</span>
<span class="quote">&gt; 	&amp;&amp; pud_none(*pud))</span>
<span class="quote">&gt; else</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; So we can remove the preprocessor macros.</span>
Ok.
<span class="quote">&gt; &gt;+</span>
<span class="quote">&gt; &gt;+pte_t *huge_pte_offset(struct mm_struct *mm, unsigned long addr)</span>
<span class="quote">&gt; &gt;+{</span>
<span class="quote">&gt; &gt;+	pgd_t *pgd;</span>
<span class="quote">&gt; &gt;+	pud_t *pud;</span>
<span class="quote">&gt; &gt;+	pmd_t *pmd = NULL;</span>
<span class="quote">&gt; &gt;+	pte_t *pte = NULL;</span>
<span class="quote">&gt; &gt;+</span>
<span class="quote">&gt; &gt;+	pgd = pgd_offset(mm, addr);</span>
<span class="quote">&gt; &gt;+	pr_debug(&quot;%s: addr:0x%lx pgd:%p\n&quot;, __func__, addr, pgd);</span>
<span class="quote">&gt; &gt;+	if (pgd_present(*pgd)) {</span>
<span class="quote">&gt; Again drop a level of indentation with:</span>
<span class="quote">&gt; if (!pgd_present(*pgd))</span>
<span class="quote">&gt; 	return NULL;</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; Similarly for pud_present and pmd_present.</span>
Ok.
<span class="quote">&gt;</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; &gt;+}</span>
<span class="quote">&gt; &gt;+</span>
<span class="quote">&gt; &gt;+pte_t arch_make_huge_pte(pte_t entry, struct vm_area_struct *vma,</span>
<span class="quote">&gt; &gt;+			 struct page *page, int writable)</span>
<span class="quote">&gt; &gt;+{</span>
<span class="quote">&gt; &gt;+	size_t pagesize = huge_page_size(hstate_vma(vma));</span>
<span class="quote">&gt; &gt;+</span>
<span class="quote">&gt; I would go for switch(pagesize) here.</span>
Same as above.
<span class="quote">&gt;</span>
<span class="quote">&gt;&gt; &gt;+	if (pagesize == CONT_PTE_SIZE) {</span>
<span class="quote">&gt;&gt; &gt;+		entry = pte_mkcont(entry);</span>
<span class="quote">&gt;&gt; &gt;+	} else if (pagesize == CONT_PMD_SIZE) {</span>
<span class="quote">&gt;&gt; &gt;+		entry = pmd_pte(pmd_mkcont(pte_pmd(entry)));</span>
<span class="quote">&gt;&gt; &gt;+	} else if (pagesize != PUD_SIZE &amp;&amp; pagesize != PMD_SIZE) {</span>
<span class="quote">&gt;&gt; &gt;+		pr_warn(&quot;%s: unrecognized huge page size 0x%lx\n&quot;,</span>
<span class="quote">&gt;&gt; &gt;+		       __func__, pagesize);</span>
<span class="quote">&gt;&gt; &gt;+	}</span>
<span class="quote">&gt;&gt; &gt;+	return entry;</span>
<span class="quote">&gt;&gt; &gt;+}</span>
<span class="quote">&gt;&gt; &gt;+</span>
<span class="quote">&gt;&gt; &gt;+extern pte_t huge_ptep_get_and_clear(struct mm_struct *mm,</span>
<span class="quote">&gt;&gt; &gt;+				     unsigned long addr, pte_t *ptep)</span>
<span class="quote">&gt;&gt; &gt;+{</span>
<span class="quote">&gt;&gt; &gt;+	pte_t pte = {0};</span>
<span class="quote">&gt; nit: Do we need an initial value for pte?</span>

No, it&#39;s not necessary.
<span class="quote">&gt;</span>
<span class="quote">&gt;&gt; &gt;+</span>
<span class="quote">&gt;&gt; &gt;+	if (pte_cont(*ptep)) {</span>
<span class="quote">&gt;&gt; &gt;+		int ncontig, i;</span>
<span class="quote">&gt;&gt; &gt;+		size_t pgsize;</span>
<span class="quote">&gt;&gt; &gt;+		pte_t *cpte;</span>
<span class="quote">&gt;&gt; &gt;+		bool is_dirty = false;</span>
<span class="quote">&gt;&gt; &gt;+</span>
<span class="quote">&gt;&gt; &gt;+		cpte = huge_pte_offset(mm, addr);</span>
<span class="quote">&gt;&gt; &gt;+		ncontig = find_num_contig(mm, addr, cpte,</span>
<span class="quote">&gt;&gt; &gt;+					  pte_val(*cpte), &amp;pgsize);</span>
<span class="quote">&gt;&gt; &gt;+		/* save the 1st pte to return */</span>
<span class="quote">&gt;&gt; &gt;+		pte = ptep_get_and_clear(mm, addr, cpte);</span>
<span class="quote">&gt;&gt; &gt;+		for (i = 1; i &lt; ncontig; ++i) {</span>
<span class="quote">&gt;&gt; &gt;+			if (pte_dirty(ptep_get_and_clear(mm, addr, ++cpte)))</span>
<span class="quote">&gt;&gt; &gt;+				is_dirty = true;</span>
<span class="quote">&gt;&gt; &gt;+		}</span>
This is the bug I mentioned above which was caught by the test suite.
If CONFIG_ARM64_HW_AFDBM is defined then pte_dirty() becomes a
macro which evaluates its argument twice.  I&#39;ve got a side-effect in there
(++cpte) so it ends up clearing ptes that it shouldn&#39;t.
<span class="quote">
&gt; Nice, we are keeping track of the dirty state. This looks to me like</span>
<span class="quote">&gt; it*should*  work well with the dirty bit management patch that Catalin</span>
<span class="quote">&gt; introduced:</span>
<span class="quote">&gt; 2f4b829 arm64: Add support for hardware updates of the access and dirty pte bits</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; Because ptep_get_and_clear will atomically get and clear the pte with</span>
<span class="quote">&gt; respect to the hardware dirty bit management thus we don&#39;t lose any</span>
<span class="quote">&gt; dirty information. huge_pte_dirty is then called on the extracted pte</span>
<span class="quote">&gt; by core code.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; For a contiguous set of ptes/pmds the individual entry will be dirtied</span>
<span class="quote">&gt; by DBM rather than the complete set so it&#39;s good to check them all for</span>
<span class="quote">&gt; dirty when going through a get and clear.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; Technically we don&#39;t need to track dirty if CONFIG_ARM64_HW_AFDBM is</span>
<span class="quote">&gt; not defined as the core code will fault and modify the entire set of</span>
<span class="quote">&gt; ptes otherwise.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; I would be tempted to keep this code as is, but add a comment that</span>
<span class="quote">&gt; tracking the dirty variable here helps for when we switch on</span>
<span class="quote">&gt; CONFIG_ARM64_HW_AFDBM.</span>
I added a comment to try to make all this more clear.
<span class="quote">&gt;&gt; &gt;+</span>
<span class="quote">&gt;&gt; &gt;+#ifdef CONFIG_ARM64_64K_PAGES</span>
<span class="quote">&gt;&gt; &gt;+static __init int add_default_hugepagesz(void)</span>
<span class="quote">&gt;&gt; &gt;+{</span>
<span class="quote">&gt;&gt; &gt;+	if (size_to_hstate(CONT_PTES * PAGE_SIZE) == NULL)</span>
<span class="quote">&gt;&gt; &gt;+		hugetlb_add_hstate(CONT_PMD_SHIFT);</span>
<span class="quote">&gt;&gt; &gt;+	return 0;</span>
<span class="quote">&gt;&gt; &gt;+}</span>
<span class="quote">&gt;&gt; &gt;+arch_initcall(add_default_hugepagesz);</span>
<span class="quote">&gt;&gt; &gt;+#endif</span>
<span class="quote">&gt; Why is this initcall defined? Was it for testing?</span>
This is intentional and in a way, the motivation for these changes. We&#39;re
expecting most of our customers to run with a 64K granule, but 512M is
too big as a huge page size in many cases.  2M is a lot more useful for
these applications and it&#39;s convenient because it is also the default huge
page size with a 4K granule.  We think it&#39;s useful enough to enable by
default, but are interested to know your thoughts on that.
<span class="quote">
&gt;</span>
<span class="quote">&gt; I think we are missing a few functions:</span>
<span class="quote">&gt; huge_ptep_set_access_flags</span>
<span class="quote">&gt; huge_ptep_set_wrprotect</span>
<span class="quote">&gt; huge_ptep_clear_flush</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; These functions need to loop through the contiguous set of ptes</span>
<span class="quote">&gt; or pmds. They should call into the ptep_ equivalents as they will</span>
<span class="quote">&gt; then work with the DBM patch.</span>
huge_ptep_set_access_flags() was there already, but I&#39;ve added
the other two.
<span class="quote">&gt;</span>
<span class="quote">&gt;&gt;</span>

--
To unsubscribe from this list: send the line &quot;unsubscribe linux-kernel&quot; in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
Please read the FAQ at  http://www.tux.org/lkml/
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/arch/arm64/Kconfig b/arch/arm64/Kconfig</span>
<span class="p_header">index 07d1811..3aa151d 100644</span>
<span class="p_header">--- a/arch/arm64/Kconfig</span>
<span class="p_header">+++ b/arch/arm64/Kconfig</span>
<span class="p_chunk">@@ -464,9 +464,6 @@</span> <span class="p_context"> config HW_PERF_EVENTS</span>
 config SYS_SUPPORTS_HUGETLBFS
 	def_bool y
 
<span class="p_del">-config ARCH_WANT_GENERAL_HUGETLB</span>
<span class="p_del">-	def_bool y</span>
<span class="p_del">-</span>
 config ARCH_WANT_HUGE_PMD_SHARE
 	def_bool y if !ARM64_64K_PAGES
 
<span class="p_header">diff --git a/arch/arm64/include/asm/hugetlb.h b/arch/arm64/include/asm/hugetlb.h</span>
<span class="p_header">index bb4052e..2b153a9 100644</span>
<span class="p_header">--- a/arch/arm64/include/asm/hugetlb.h</span>
<span class="p_header">+++ b/arch/arm64/include/asm/hugetlb.h</span>
<span class="p_chunk">@@ -26,12 +26,6 @@</span> <span class="p_context"> static inline pte_t huge_ptep_get(pte_t *ptep)</span>
 	return *ptep;
 }
 
<span class="p_del">-static inline void set_huge_pte_at(struct mm_struct *mm, unsigned long addr,</span>
<span class="p_del">-				   pte_t *ptep, pte_t pte)</span>
<span class="p_del">-{</span>
<span class="p_del">-	set_pte_at(mm, addr, ptep, pte);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
 static inline void huge_ptep_clear_flush(struct vm_area_struct *vma,
 					 unsigned long addr, pte_t *ptep)
 {
<span class="p_chunk">@@ -44,19 +38,6 @@</span> <span class="p_context"> static inline void huge_ptep_set_wrprotect(struct mm_struct *mm,</span>
 	ptep_set_wrprotect(mm, addr, ptep);
 }
 
<span class="p_del">-static inline pte_t huge_ptep_get_and_clear(struct mm_struct *mm,</span>
<span class="p_del">-					    unsigned long addr, pte_t *ptep)</span>
<span class="p_del">-{</span>
<span class="p_del">-	return ptep_get_and_clear(mm, addr, ptep);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static inline int huge_ptep_set_access_flags(struct vm_area_struct *vma,</span>
<span class="p_del">-					     unsigned long addr, pte_t *ptep,</span>
<span class="p_del">-					     pte_t pte, int dirty)</span>
<span class="p_del">-{</span>
<span class="p_del">-	return ptep_set_access_flags(vma, addr, ptep, pte, dirty);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
 static inline void hugetlb_free_pgd_range(struct mmu_gather *tlb,
 					  unsigned long addr, unsigned long end,
 					  unsigned long floor,
<span class="p_chunk">@@ -97,4 +78,15 @@</span> <span class="p_context"> static inline void arch_clear_hugepage_flags(struct page *page)</span>
 	clear_bit(PG_dcache_clean, &amp;page-&gt;flags);
 }
 
<span class="p_add">+extern pte_t arch_make_huge_pte(pte_t entry, struct vm_area_struct *vma,</span>
<span class="p_add">+				struct page *page, int writable);</span>
<span class="p_add">+#define arch_make_huge_pte arch_make_huge_pte</span>
<span class="p_add">+extern void set_huge_pte_at(struct mm_struct *mm, unsigned long addr,</span>
<span class="p_add">+			    pte_t *ptep, pte_t pte);</span>
<span class="p_add">+extern int huge_ptep_set_access_flags(struct vm_area_struct *vma,</span>
<span class="p_add">+				      unsigned long addr, pte_t *ptep,</span>
<span class="p_add">+				      pte_t pte, int dirty);</span>
<span class="p_add">+extern pte_t huge_ptep_get_and_clear(struct mm_struct *mm,</span>
<span class="p_add">+				     unsigned long addr, pte_t *ptep);</span>
<span class="p_add">+</span>
 #endif /* __ASM_HUGETLB_H */
<span class="p_header">diff --git a/arch/arm64/include/asm/pgtable-hwdef.h b/arch/arm64/include/asm/pgtable-hwdef.h</span>
<span class="p_header">index 24154b0..1b921a5 100644</span>
<span class="p_header">--- a/arch/arm64/include/asm/pgtable-hwdef.h</span>
<span class="p_header">+++ b/arch/arm64/include/asm/pgtable-hwdef.h</span>
<span class="p_chunk">@@ -55,6 +55,24 @@</span> <span class="p_context"></span>
 #define SECTION_MASK		(~(SECTION_SIZE-1))
 
 /*
<span class="p_add">+ * Contiguous page definitions.</span>
<span class="p_add">+ */</span>
<span class="p_add">+#ifdef CONFIG_ARM64_64K_PAGES</span>
<span class="p_add">+#define CONT_PTE_SHIFT		5</span>
<span class="p_add">+#define CONT_PMD_SHIFT		5</span>
<span class="p_add">+#else</span>
<span class="p_add">+#define CONT_PTE_SHIFT		4</span>
<span class="p_add">+#define CONT_PMD_SHIFT		4</span>
<span class="p_add">+#endif</span>
<span class="p_add">+</span>
<span class="p_add">+#define CONT_PTES		(1 &lt;&lt; CONT_PTE_SHIFT)</span>
<span class="p_add">+#define CONT_PTE_SIZE		(CONT_PTES * PAGE_SIZE)</span>
<span class="p_add">+#define CONT_PTE_MASK		(~(CONT_PTE_SIZE - 1))</span>
<span class="p_add">+#define CONT_PMDS		(1 &lt;&lt; CONT_PMD_SHIFT)</span>
<span class="p_add">+#define CONT_PMD_SIZE		(CONT_PMDS * PMD_SIZE)</span>
<span class="p_add">+#define CONT_PMD_MASK		(~(CONT_PMD_SIZE - 1))</span>
<span class="p_add">+</span>
<span class="p_add">+/*</span>
  * Hardware page table definitions.
  *
  * Level 1 descriptor (PUD).
<span class="p_chunk">@@ -83,6 +101,7 @@</span> <span class="p_context"></span>
 #define PMD_SECT_S		(_AT(pmdval_t, 3) &lt;&lt; 8)
 #define PMD_SECT_AF		(_AT(pmdval_t, 1) &lt;&lt; 10)
 #define PMD_SECT_NG		(_AT(pmdval_t, 1) &lt;&lt; 11)
<span class="p_add">+#define PMD_SECT_CONT		(_AT(pmdval_t, 1) &lt;&lt; 52)</span>
 #define PMD_SECT_PXN		(_AT(pmdval_t, 1) &lt;&lt; 53)
 #define PMD_SECT_UXN		(_AT(pmdval_t, 1) &lt;&lt; 54)
 
<span class="p_chunk">@@ -105,6 +124,7 @@</span> <span class="p_context"></span>
 #define PTE_AF			(_AT(pteval_t, 1) &lt;&lt; 10)	/* Access Flag */
 #define PTE_NG			(_AT(pteval_t, 1) &lt;&lt; 11)	/* nG */
 #define PTE_DBM			(_AT(pteval_t, 1) &lt;&lt; 51)	/* Dirty Bit Management */
<span class="p_add">+#define PTE_CONT		(_AT(pteval_t, 1) &lt;&lt; 52)	/* Contiguous */</span>
 #define PTE_PXN			(_AT(pteval_t, 1) &lt;&lt; 53)	/* Privileged XN */
 #define PTE_UXN			(_AT(pteval_t, 1) &lt;&lt; 54)	/* User XN */
 
<span class="p_header">diff --git a/arch/arm64/include/asm/pgtable.h b/arch/arm64/include/asm/pgtable.h</span>
<span class="p_header">index 26b0666..cf079a1 100644</span>
<span class="p_header">--- a/arch/arm64/include/asm/pgtable.h</span>
<span class="p_header">+++ b/arch/arm64/include/asm/pgtable.h</span>
<span class="p_chunk">@@ -140,6 +140,7 @@</span> <span class="p_context"> extern struct page *empty_zero_page;</span>
 #define pte_special(pte)	(!!(pte_val(pte) &amp; PTE_SPECIAL))
 #define pte_write(pte)		(!!(pte_val(pte) &amp; PTE_WRITE))
 #define pte_exec(pte)		(!(pte_val(pte) &amp; PTE_UXN))
<span class="p_add">+#define pte_cont(pte)		(!!(pte_val(pte) &amp; PTE_CONT))</span>
 
 #ifdef CONFIG_ARM64_HW_AFDBM
 #define pte_hw_dirty(pte)	(pte_write(pte) &amp;&amp; !(pte_val(pte) &amp; PTE_RDONLY))
<span class="p_chunk">@@ -202,6 +203,18 @@</span> <span class="p_context"> static inline pte_t pte_mkspecial(pte_t pte)</span>
 	return set_pte_bit(pte, __pgprot(PTE_SPECIAL));
 }
 
<span class="p_add">+static inline pte_t pte_mkcont(pte_t pte)</span>
<span class="p_add">+{</span>
<span class="p_add">+	pte = set_pte_bit(pte, __pgprot(PTE_CONT));</span>
<span class="p_add">+	return set_pte_bit(pte, __pgprot(PTE_TYPE_PAGE));</span>
<span class="p_add">+	return pte;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline pmd_t pmd_mkcont(pmd_t pmd)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return __pmd(pmd_val(pmd) | PMD_SECT_CONT);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static inline void set_pte(pte_t *ptep, pte_t pte)
 {
 	*ptep = pte;
<span class="p_chunk">@@ -271,7 +284,7 @@</span> <span class="p_context"> static inline void set_pte_at(struct mm_struct *mm, unsigned long addr,</span>
 /*
  * Hugetlb definitions.
  */
<span class="p_del">-#define HUGE_MAX_HSTATE		2</span>
<span class="p_add">+#define HUGE_MAX_HSTATE		((2 * CONFIG_PGTABLE_LEVELS) - 1)</span>
 #define HPAGE_SHIFT		PMD_SHIFT
 #define HPAGE_SIZE		(_AC(1, UL) &lt;&lt; HPAGE_SHIFT)
 #define HPAGE_MASK		(~(HPAGE_SIZE - 1))
<span class="p_chunk">@@ -496,7 +509,7 @@</span> <span class="p_context"> static inline pud_t *pud_offset(pgd_t *pgd, unsigned long addr)</span>
 static inline pte_t pte_modify(pte_t pte, pgprot_t newprot)
 {
 	const pteval_t mask = PTE_USER | PTE_PXN | PTE_UXN | PTE_RDONLY |
<span class="p_del">-			      PTE_PROT_NONE | PTE_VALID | PTE_WRITE;</span>
<span class="p_add">+			      PTE_PROT_NONE | PTE_VALID | PTE_WRITE | PTE_CONT;</span>
 	/* preserve the hardware dirty information */
 	if (pte_hw_dirty(pte))
 		pte = pte_mkdirty(pte);
<span class="p_chunk">@@ -509,6 +522,22 @@</span> <span class="p_context"> static inline pmd_t pmd_modify(pmd_t pmd, pgprot_t newprot)</span>
 	return pte_pmd(pte_modify(pmd_pte(pmd), newprot));
 }
 
<span class="p_add">+static inline pte_t pte_modify_pfn(pte_t pte, unsigned long newpfn)</span>
<span class="p_add">+{</span>
<span class="p_add">+	const pteval_t mask = PHYS_MASK &amp; PAGE_MASK;</span>
<span class="p_add">+</span>
<span class="p_add">+	pte_val(pte) = pfn_pte(newpfn, (pte_val(pte) &amp; ~mask));</span>
<span class="p_add">+	return pte;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline pmd_t pmd_modify_pfn(pmd_t pmd, unsigned long newpfn)</span>
<span class="p_add">+{</span>
<span class="p_add">+	const pmdval_t mask = PHYS_MASK &amp; PAGE_MASK;</span>
<span class="p_add">+</span>
<span class="p_add">+	pmd = pfn_pmd(newpfn, (pmd_val(pmd) &amp; ~mask));</span>
<span class="p_add">+	return pmd;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 #ifdef CONFIG_ARM64_HW_AFDBM
 /*
  * Atomic pte/pmd modifications.
<span class="p_header">diff --git a/arch/arm64/mm/hugetlbpage.c b/arch/arm64/mm/hugetlbpage.c</span>
<span class="p_header">index 383b03f..20fd34c 100644</span>
<span class="p_header">--- a/arch/arm64/mm/hugetlbpage.c</span>
<span class="p_header">+++ b/arch/arm64/mm/hugetlbpage.c</span>
<span class="p_chunk">@@ -41,6 +41,201 @@</span> <span class="p_context"> int pud_huge(pud_t pud)</span>
 #endif
 }
 
<span class="p_add">+static int find_num_contig(struct mm_struct *mm, unsigned long addr,</span>
<span class="p_add">+			   pte_t *ptep, pte_t pte, size_t *pgsize)</span>
<span class="p_add">+{</span>
<span class="p_add">+	pgd_t *pgd = pgd_offset(mm, addr);</span>
<span class="p_add">+	pud_t *pud;</span>
<span class="p_add">+	pmd_t *pmd;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (!pte_cont(pte))</span>
<span class="p_add">+		return 1;</span>
<span class="p_add">+</span>
<span class="p_add">+	pud = pud_offset(pgd, addr);</span>
<span class="p_add">+	pmd = pmd_offset(pud, addr);</span>
<span class="p_add">+	if ((pte_t *)pmd == ptep) {</span>
<span class="p_add">+		*pgsize = PMD_SIZE;</span>
<span class="p_add">+		return CONT_PMDS;</span>
<span class="p_add">+	}</span>
<span class="p_add">+	*pgsize = PAGE_SIZE;</span>
<span class="p_add">+	return CONT_PTES;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+extern void set_huge_pte_at(struct mm_struct *mm, unsigned long addr,</span>
<span class="p_add">+			    pte_t *ptep, pte_t pte)</span>
<span class="p_add">+{</span>
<span class="p_add">+	size_t pgsize;</span>
<span class="p_add">+	int ncontig = find_num_contig(mm, addr, ptep, pte, &amp;pgsize);</span>
<span class="p_add">+</span>
<span class="p_add">+	if (ncontig == 1) {</span>
<span class="p_add">+		set_pte_at(mm, addr, ptep, pte);</span>
<span class="p_add">+	} else {</span>
<span class="p_add">+		int i;</span>
<span class="p_add">+		unsigned long pfn = pte_pfn(pte);</span>
<span class="p_add">+		pgprot_t hugeprot =</span>
<span class="p_add">+			__pgprot(pte_val(pfn_pte(pfn, 0) ^ pte_val(pte)));</span>
<span class="p_add">+		for (i = 0; i &lt; ncontig; i++) {</span>
<span class="p_add">+			pr_debug(&quot;%s: set pte %p to 0x%llx\n&quot;, __func__, ptep,</span>
<span class="p_add">+				 pfn_pte(pfn, hugeprot));</span>
<span class="p_add">+			set_pte_at(mm, addr, ptep, pfn_pte(pfn, hugeprot));</span>
<span class="p_add">+			ptep++;</span>
<span class="p_add">+			pfn += pgsize / PAGE_SIZE;</span>
<span class="p_add">+			addr += pgsize;</span>
<span class="p_add">+		}</span>
<span class="p_add">+	}</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+pte_t *huge_pte_alloc(struct mm_struct *mm,</span>
<span class="p_add">+		      unsigned long addr, unsigned long sz)</span>
<span class="p_add">+{</span>
<span class="p_add">+	pgd_t *pgd;</span>
<span class="p_add">+	pud_t *pud;</span>
<span class="p_add">+	pte_t *pte = NULL;</span>
<span class="p_add">+</span>
<span class="p_add">+	pr_debug(&quot;%s: addr:0x%lx sz:0x%lx\n&quot;, __func__, addr, sz);</span>
<span class="p_add">+	pgd = pgd_offset(mm, addr);</span>
<span class="p_add">+	pud = pud_alloc(mm, pgd, addr);</span>
<span class="p_add">+	if (pud) {</span>
<span class="p_add">+		if (sz == PUD_SIZE) {</span>
<span class="p_add">+			pte = (pte_t *)pud;</span>
<span class="p_add">+		} else if (sz == (PAGE_SIZE * CONT_PTES)) {</span>
<span class="p_add">+			pmd_t *pmd = pmd_alloc(mm, pud, addr);</span>
<span class="p_add">+</span>
<span class="p_add">+			WARN_ON(addr &amp; (sz - 1));</span>
<span class="p_add">+			pte = pte_alloc_map(mm, NULL, pmd, addr);</span>
<span class="p_add">+		} else if (sz == PMD_SIZE) {</span>
<span class="p_add">+#ifdef CONFIG_ARCH_WANT_HUGE_PMD_SHARE</span>
<span class="p_add">+			if (pud_none(*pud))</span>
<span class="p_add">+				pte = huge_pmd_share(mm, addr, pud);</span>
<span class="p_add">+			else</span>
<span class="p_add">+#endif</span>
<span class="p_add">+				pte = (pte_t *)pmd_alloc(mm, pud, addr);</span>
<span class="p_add">+		} else if (sz == (PMD_SIZE * CONT_PMDS)) {</span>
<span class="p_add">+			pmd_t *pmd;</span>
<span class="p_add">+</span>
<span class="p_add">+			pmd = pmd_alloc(mm, pud, addr);</span>
<span class="p_add">+			WARN_ON(addr &amp; (sz - 1));</span>
<span class="p_add">+			return (pte_t *)pmd;</span>
<span class="p_add">+		}</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	pr_debug(&quot;%s: addr:0x%lx sz:0x%lx ret pte=%p/0x%llx\n&quot;, __func__, addr,</span>
<span class="p_add">+	       sz, pte, pte_val(*pte));</span>
<span class="p_add">+	return pte;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+pte_t *huge_pte_offset(struct mm_struct *mm, unsigned long addr)</span>
<span class="p_add">+{</span>
<span class="p_add">+	pgd_t *pgd;</span>
<span class="p_add">+	pud_t *pud;</span>
<span class="p_add">+	pmd_t *pmd = NULL;</span>
<span class="p_add">+	pte_t *pte = NULL;</span>
<span class="p_add">+</span>
<span class="p_add">+	pgd = pgd_offset(mm, addr);</span>
<span class="p_add">+	pr_debug(&quot;%s: addr:0x%lx pgd:%p\n&quot;, __func__, addr, pgd);</span>
<span class="p_add">+	if (pgd_present(*pgd)) {</span>
<span class="p_add">+		pud = pud_offset(pgd, addr);</span>
<span class="p_add">+		if (pud_present(*pud)) {</span>
<span class="p_add">+			if (pud_huge(*pud))</span>
<span class="p_add">+				return (pte_t *)pud;</span>
<span class="p_add">+			pmd = pmd_offset(pud, addr);</span>
<span class="p_add">+			if (pmd_present(*pmd)) {</span>
<span class="p_add">+				if (pte_cont(pmd_pte(*pmd))) {</span>
<span class="p_add">+					pmd = pmd_offset(</span>
<span class="p_add">+						pud, (addr &amp; CONT_PMD_MASK));</span>
<span class="p_add">+					return (pte_t *)pmd;</span>
<span class="p_add">+				}</span>
<span class="p_add">+				if (pmd_huge(*pmd))</span>
<span class="p_add">+					return (pte_t *)pmd;</span>
<span class="p_add">+				pte = pte_offset_kernel(pmd, addr);</span>
<span class="p_add">+				if (pte_present(*pte) &amp;&amp; pte_cont(*pte)) {</span>
<span class="p_add">+					pte = pte_offset_kernel(</span>
<span class="p_add">+						pmd, (addr &amp; CONT_PTE_MASK));</span>
<span class="p_add">+				}</span>
<span class="p_add">+				return pte;</span>
<span class="p_add">+			}</span>
<span class="p_add">+		}</span>
<span class="p_add">+	}</span>
<span class="p_add">+	return (pte_t *) NULL;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+pte_t arch_make_huge_pte(pte_t entry, struct vm_area_struct *vma,</span>
<span class="p_add">+			 struct page *page, int writable)</span>
<span class="p_add">+{</span>
<span class="p_add">+	size_t pagesize = huge_page_size(hstate_vma(vma));</span>
<span class="p_add">+</span>
<span class="p_add">+	if (pagesize == CONT_PTE_SIZE) {</span>
<span class="p_add">+		entry = pte_mkcont(entry);</span>
<span class="p_add">+	} else if (pagesize == CONT_PMD_SIZE) {</span>
<span class="p_add">+		entry = pmd_pte(pmd_mkcont(pte_pmd(entry)));</span>
<span class="p_add">+	} else if (pagesize != PUD_SIZE &amp;&amp; pagesize != PMD_SIZE) {</span>
<span class="p_add">+		pr_warn(&quot;%s: unrecognized huge page size 0x%lx\n&quot;,</span>
<span class="p_add">+		       __func__, pagesize);</span>
<span class="p_add">+	}</span>
<span class="p_add">+	return entry;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+extern pte_t huge_ptep_get_and_clear(struct mm_struct *mm,</span>
<span class="p_add">+				     unsigned long addr, pte_t *ptep)</span>
<span class="p_add">+{</span>
<span class="p_add">+	pte_t pte = {0};</span>
<span class="p_add">+</span>
<span class="p_add">+	if (pte_cont(*ptep)) {</span>
<span class="p_add">+		int ncontig, i;</span>
<span class="p_add">+		size_t pgsize;</span>
<span class="p_add">+		pte_t *cpte;</span>
<span class="p_add">+		bool is_dirty = false;</span>
<span class="p_add">+</span>
<span class="p_add">+		cpte = huge_pte_offset(mm, addr);</span>
<span class="p_add">+		ncontig = find_num_contig(mm, addr, cpte,</span>
<span class="p_add">+					  pte_val(*cpte), &amp;pgsize);</span>
<span class="p_add">+		/* save the 1st pte to return */</span>
<span class="p_add">+		pte = ptep_get_and_clear(mm, addr, cpte);</span>
<span class="p_add">+		for (i = 1; i &lt; ncontig; ++i) {</span>
<span class="p_add">+			if (pte_dirty(ptep_get_and_clear(mm, addr, ++cpte)))</span>
<span class="p_add">+				is_dirty = true;</span>
<span class="p_add">+		}</span>
<span class="p_add">+		if (is_dirty)</span>
<span class="p_add">+			return pte_mkdirty(pte);</span>
<span class="p_add">+		else</span>
<span class="p_add">+			return pte;</span>
<span class="p_add">+	} else {</span>
<span class="p_add">+		return ptep_get_and_clear(mm, addr, ptep);</span>
<span class="p_add">+	}</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+int huge_ptep_set_access_flags(struct vm_area_struct *vma,</span>
<span class="p_add">+			       unsigned long addr, pte_t *ptep,</span>
<span class="p_add">+			       pte_t pte, int dirty)</span>
<span class="p_add">+{</span>
<span class="p_add">+	pte_t *cpte;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (pte_cont(pte)) {</span>
<span class="p_add">+		int ncontig, i, changed = 0;</span>
<span class="p_add">+		size_t pgsize = 0;</span>
<span class="p_add">+		unsigned long pfn = pte_pfn(pte);</span>
<span class="p_add">+		/* Select all bits except the pfn */</span>
<span class="p_add">+		pgprot_t hugeprot =</span>
<span class="p_add">+			__pgprot(pte_val(pfn_pte(pfn, 0) ^ pte_val(pte)));</span>
<span class="p_add">+</span>
<span class="p_add">+		cpte = huge_pte_offset(vma-&gt;vm_mm, addr);</span>
<span class="p_add">+		pfn = pte_pfn(*cpte);</span>
<span class="p_add">+		ncontig = find_num_contig(vma-&gt;vm_mm, addr, cpte,</span>
<span class="p_add">+					  pte_val(*cpte), &amp;pgsize);</span>
<span class="p_add">+		for (i = 0; i &lt; ncontig; ++i, ++cpte) {</span>
<span class="p_add">+			changed = ptep_set_access_flags(vma, addr, cpte,</span>
<span class="p_add">+							pfn_pte(pfn,</span>
<span class="p_add">+								hugeprot),</span>
<span class="p_add">+							dirty);</span>
<span class="p_add">+			pfn += pgsize / PAGE_SIZE;</span>
<span class="p_add">+		}</span>
<span class="p_add">+		return changed;</span>
<span class="p_add">+	} else {</span>
<span class="p_add">+		return ptep_set_access_flags(vma, addr, ptep, pte, dirty);</span>
<span class="p_add">+	}</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+</span>
 static __init int setup_hugepagesz(char *opt)
 {
 	unsigned long ps = memparse(opt, &amp;opt);
<span class="p_chunk">@@ -48,10 +243,24 @@</span> <span class="p_context"> static __init int setup_hugepagesz(char *opt)</span>
 		hugetlb_add_hstate(PMD_SHIFT - PAGE_SHIFT);
 	} else if (ps == PUD_SIZE) {
 		hugetlb_add_hstate(PUD_SHIFT - PAGE_SHIFT);
<span class="p_add">+	} else if (ps == (PAGE_SIZE * CONT_PTES)) {</span>
<span class="p_add">+		hugetlb_add_hstate(CONT_PTE_SHIFT);</span>
<span class="p_add">+	} else if (ps == (PMD_SIZE * CONT_PMDS)) {</span>
<span class="p_add">+		hugetlb_add_hstate((PMD_SHIFT + CONT_PMD_SHIFT) - PAGE_SHIFT);</span>
 	} else {
<span class="p_del">-		pr_err(&quot;hugepagesz: Unsupported page size %lu M\n&quot;, ps &gt;&gt; 20);</span>
<span class="p_add">+		pr_err(&quot;hugepagesz: Unsupported page size %lu K\n&quot;, ps &gt;&gt; 10);</span>
 		return 0;
 	}
 	return 1;
 }
 __setup(&quot;hugepagesz=&quot;, setup_hugepagesz);
<span class="p_add">+</span>
<span class="p_add">+#ifdef CONFIG_ARM64_64K_PAGES</span>
<span class="p_add">+static __init int add_default_hugepagesz(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	if (size_to_hstate(CONT_PTES * PAGE_SIZE) == NULL)</span>
<span class="p_add">+		hugetlb_add_hstate(CONT_PMD_SHIFT);</span>
<span class="p_add">+	return 0;</span>
<span class="p_add">+}</span>
<span class="p_add">+arch_initcall(add_default_hugepagesz);</span>
<span class="p_add">+#endif</span>

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



