
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>[4.14,082/167] kmemcheck: rip it out - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    [4.14,082/167] kmemcheck: rip it out</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=37061">gregkh@linuxfoundation.org</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>Feb. 21, 2018, 12:48 p.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;20180221124528.916956382@linuxfoundation.org&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/10232309/mbox/"
   >mbox</a>
|
   <a href="/patch/10232309/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/10232309/">/patch/10232309/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
	[172.30.200.125])
	by pdx-korg-patchwork.web.codeaurora.org (Postfix) with ESMTP id
	B5CF960392 for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Wed, 21 Feb 2018 13:02:02 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 9FCFA28B56
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Wed, 21 Feb 2018 13:02:02 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id 9377C28B5F; Wed, 21 Feb 2018 13:02:02 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-6.9 required=2.0 tests=BAYES_00,RCVD_IN_DNSWL_HI
	autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 4106E28B56
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Wed, 21 Feb 2018 13:01:58 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S935497AbeBUNBx (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Wed, 21 Feb 2018 08:01:53 -0500
Received: from mail.linuxfoundation.org ([140.211.169.12]:38560 &quot;EHLO
	mail.linuxfoundation.org&quot; rhost-flags-OK-OK-OK-OK) by vger.kernel.org
	with ESMTP id S932807AbeBUNBq (ORCPT
	&lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Wed, 21 Feb 2018 08:01:46 -0500
Received: from localhost (LFbn-1-12258-90.w90-92.abo.wanadoo.fr
	[90.92.71.90])
	by mail.linuxfoundation.org (Postfix) with ESMTPSA id DA55729;
	Wed, 21 Feb 2018 13:01:18 +0000 (UTC)
From: Greg Kroah-Hartman &lt;gregkh@linuxfoundation.org&gt;
To: linux-kernel@vger.kernel.org
Cc: Greg Kroah-Hartman &lt;gregkh@linuxfoundation.org&gt;,
	stable@vger.kernel.org, Sasha Levin &lt;alexander.levin@verizon.com&gt;,
	Steven Rostedt &lt;rostedt@goodmis.org&gt;,
	Vegard Nossum &lt;vegardno@ifi.uio.no&gt;, Pekka Enberg &lt;penberg@kernel.org&gt;,
	Michal Hocko &lt;mhocko@kernel.org&gt;,
	&quot;Eric W. Biederman&quot; &lt;ebiederm@xmission.com&gt;,
	Alexander Potapenko &lt;glider@google.com&gt;,
	Tim Hansen &lt;devtimhansen@gmail.com&gt;,
	Andrew Morton &lt;akpm@linux-foundation.org&gt;,
	Linus Torvalds &lt;torvalds@linux-foundation.org&gt;
Subject: [PATCH 4.14 082/167] kmemcheck: rip it out
Date: Wed, 21 Feb 2018 13:48:13 +0100
Message-Id: &lt;20180221124528.916956382@linuxfoundation.org&gt;
X-Mailer: git-send-email 2.16.2
In-Reply-To: &lt;20180221124524.639039577@linuxfoundation.org&gt;
References: &lt;20180221124524.639039577@linuxfoundation.org&gt;
User-Agent: quilt/0.65
X-stable: review
MIME-Version: 1.0
Content-Type: text/plain; charset=UTF-8
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=37061">gregkh@linuxfoundation.org</a> - Feb. 21, 2018, 12:48 p.m.</div>
<pre class="content">
4.14-stable review patch.  If anyone has any objections, please let me know.

------------------
<span class="from">
From: Levin, Alexander (Sasha Levin) &lt;alexander.levin@verizon.com&gt;</span>

commit 4675ff05de2d76d167336b368bd07f3fef6ed5a6 upstream.

Fix up makefiles, remove references, and git rm kmemcheck.

Link: http://lkml.kernel.org/r/20171007030159.22241-4-alexander.levin@verizon.com
<span class="signed-off-by">Signed-off-by: Sasha Levin &lt;alexander.levin@verizon.com&gt;</span>
Cc: Steven Rostedt &lt;rostedt@goodmis.org&gt;
Cc: Vegard Nossum &lt;vegardno@ifi.uio.no&gt;
Cc: Pekka Enberg &lt;penberg@kernel.org&gt;
Cc: Michal Hocko &lt;mhocko@kernel.org&gt;
Cc: Eric W. Biederman &lt;ebiederm@xmission.com&gt;
Cc: Alexander Potapenko &lt;glider@google.com&gt;
Cc: Tim Hansen &lt;devtimhansen@gmail.com&gt;
<span class="signed-off-by">Signed-off-by: Andrew Morton &lt;akpm@linux-foundation.org&gt;</span>
<span class="signed-off-by">Signed-off-by: Linus Torvalds &lt;torvalds@linux-foundation.org&gt;</span>
<span class="signed-off-by">Signed-off-by: Greg Kroah-Hartman &lt;gregkh@linuxfoundation.org&gt;</span>

---
 Documentation/admin-guide/kernel-parameters.txt |    7 
 Documentation/dev-tools/index.rst               |    1 
 Documentation/dev-tools/kmemcheck.rst           |  733 ------------------------
 MAINTAINERS                                     |   10 
 arch/x86/Kconfig                                |    3 
 arch/x86/include/asm/kmemcheck.h                |   42 -
 arch/x86/include/asm/string_32.h                |    9 
 arch/x86/include/asm/string_64.h                |    8 
 arch/x86/kernel/cpu/intel.c                     |   15 
 arch/x86/mm/Makefile                            |    2 
 arch/x86/mm/init.c                              |    5 
 arch/x86/mm/kmemcheck/Makefile                  |    1 
 arch/x86/mm/kmemcheck/error.c                   |  227 -------
 arch/x86/mm/kmemcheck/error.h                   |   15 
 arch/x86/mm/kmemcheck/kmemcheck.c               |  658 ---------------------
 arch/x86/mm/kmemcheck/opcode.c                  |  106 ---
 arch/x86/mm/kmemcheck/opcode.h                  |    9 
 arch/x86/mm/kmemcheck/pte.c                     |   22 
 arch/x86/mm/kmemcheck/pte.h                     |   10 
 arch/x86/mm/kmemcheck/selftest.c                |   70 --
 arch/x86/mm/kmemcheck/selftest.h                |    6 
 arch/x86/mm/kmemcheck/shadow.c                  |  173 -----
 arch/x86/mm/kmemcheck/shadow.h                  |   18 
 include/linux/interrupt.h                       |   15 
 include/linux/kmemcheck.h                       |  171 -----
 kernel/softirq.c                                |   10 
 kernel/sysctl.c                                 |   10 
 lib/Kconfig.debug                               |    6 
 lib/Kconfig.kmemcheck                           |   94 ---
 mm/Kconfig.debug                                |    1 
 mm/Makefile                                     |    2 
 mm/kmemcheck.c                                  |  125 ----
 mm/slub.c                                       |    5 
 scripts/kernel-doc                              |    2 
 tools/include/linux/kmemcheck.h                 |    8 
 35 files changed, 7 insertions(+), 2592 deletions(-)
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">--- a/Documentation/admin-guide/kernel-parameters.txt</span>
<span class="p_header">+++ b/Documentation/admin-guide/kernel-parameters.txt</span>
<span class="p_chunk">@@ -1841,13 +1841,6 @@</span> <span class="p_context"></span>
 			Built with CONFIG_DEBUG_KMEMLEAK_DEFAULT_OFF=y,
 			the default is off.
 
<span class="p_del">-	kmemcheck=	[X86] Boot-time kmemcheck enable/disable/one-shot mode</span>
<span class="p_del">-			Valid arguments: 0, 1, 2</span>
<span class="p_del">-			kmemcheck=0 (disabled)</span>
<span class="p_del">-			kmemcheck=1 (enabled)</span>
<span class="p_del">-			kmemcheck=2 (one-shot mode)</span>
<span class="p_del">-			Default: 2 (one-shot mode)</span>
<span class="p_del">-</span>
 	kvm.ignore_msrs=[KVM] Ignore guest accesses to unhandled MSRs.
 			Default is 0 (don&#39;t ignore, but inject #GP)
 
<span class="p_header">--- a/Documentation/dev-tools/index.rst</span>
<span class="p_header">+++ b/Documentation/dev-tools/index.rst</span>
<span class="p_chunk">@@ -21,7 +21,6 @@</span> <span class="p_context"> whole; patches welcome!</span>
    kasan
    ubsan
    kmemleak
<span class="p_del">-   kmemcheck</span>
    gdb-kernel-debugging
    kgdb
    kselftest
<span class="p_header">--- a/Documentation/dev-tools/kmemcheck.rst</span>
<span class="p_header">+++ /dev/null</span>
<span class="p_chunk">@@ -1,733 +0,0 @@</span> <span class="p_context"></span>
<span class="p_del">-Getting started with kmemcheck</span>
<span class="p_del">-==============================</span>
<span class="p_del">-</span>
<span class="p_del">-Vegard Nossum &lt;vegardno@ifi.uio.no&gt;</span>
<span class="p_del">-</span>
<span class="p_del">-</span>
<span class="p_del">-Introduction</span>
<span class="p_del">-------------</span>
<span class="p_del">-</span>
<span class="p_del">-kmemcheck is a debugging feature for the Linux Kernel. More specifically, it</span>
<span class="p_del">-is a dynamic checker that detects and warns about some uses of uninitialized</span>
<span class="p_del">-memory.</span>
<span class="p_del">-</span>
<span class="p_del">-Userspace programmers might be familiar with Valgrind&#39;s memcheck. The main</span>
<span class="p_del">-difference between memcheck and kmemcheck is that memcheck works for userspace</span>
<span class="p_del">-programs only, and kmemcheck works for the kernel only. The implementations</span>
<span class="p_del">-are of course vastly different. Because of this, kmemcheck is not as accurate</span>
<span class="p_del">-as memcheck, but it turns out to be good enough in practice to discover real</span>
<span class="p_del">-programmer errors that the compiler is not able to find through static</span>
<span class="p_del">-analysis.</span>
<span class="p_del">-</span>
<span class="p_del">-Enabling kmemcheck on a kernel will probably slow it down to the extent that</span>
<span class="p_del">-the machine will not be usable for normal workloads such as e.g. an</span>
<span class="p_del">-interactive desktop. kmemcheck will also cause the kernel to use about twice</span>
<span class="p_del">-as much memory as normal. For this reason, kmemcheck is strictly a debugging</span>
<span class="p_del">-feature.</span>
<span class="p_del">-</span>
<span class="p_del">-</span>
<span class="p_del">-Downloading</span>
<span class="p_del">------------</span>
<span class="p_del">-</span>
<span class="p_del">-As of version 2.6.31-rc1, kmemcheck is included in the mainline kernel.</span>
<span class="p_del">-</span>
<span class="p_del">-</span>
<span class="p_del">-Configuring and compiling</span>
<span class="p_del">--------------------------</span>
<span class="p_del">-</span>
<span class="p_del">-kmemcheck only works for the x86 (both 32- and 64-bit) platform. A number of</span>
<span class="p_del">-configuration variables must have specific settings in order for the kmemcheck</span>
<span class="p_del">-menu to even appear in &quot;menuconfig&quot;. These are:</span>
<span class="p_del">-</span>
<span class="p_del">-- ``CONFIG_CC_OPTIMIZE_FOR_SIZE=n``</span>
<span class="p_del">-	This option is located under &quot;General setup&quot; / &quot;Optimize for size&quot;.</span>
<span class="p_del">-</span>
<span class="p_del">-	Without this, gcc will use certain optimizations that usually lead to</span>
<span class="p_del">-	false positive warnings from kmemcheck. An example of this is a 16-bit</span>
<span class="p_del">-	field in a struct, where gcc may load 32 bits, then discard the upper</span>
<span class="p_del">-	16 bits. kmemcheck sees only the 32-bit load, and may trigger a</span>
<span class="p_del">-	warning for the upper 16 bits (if they&#39;re uninitialized).</span>
<span class="p_del">-</span>
<span class="p_del">-- ``CONFIG_SLAB=y`` or ``CONFIG_SLUB=y``</span>
<span class="p_del">-	This option is located under &quot;General setup&quot; / &quot;Choose SLAB</span>
<span class="p_del">-	allocator&quot;.</span>
<span class="p_del">-</span>
<span class="p_del">-- ``CONFIG_FUNCTION_TRACER=n``</span>
<span class="p_del">-	This option is located under &quot;Kernel hacking&quot; / &quot;Tracers&quot; / &quot;Kernel</span>
<span class="p_del">-	Function Tracer&quot;</span>
<span class="p_del">-</span>
<span class="p_del">-	When function tracing is compiled in, gcc emits a call to another</span>
<span class="p_del">-	function at the beginning of every function. This means that when the</span>
<span class="p_del">-	page fault handler is called, the ftrace framework will be called</span>
<span class="p_del">-	before kmemcheck has had a chance to handle the fault. If ftrace then</span>
<span class="p_del">-	modifies memory that was tracked by kmemcheck, the result is an</span>
<span class="p_del">-	endless recursive page fault.</span>
<span class="p_del">-</span>
<span class="p_del">-- ``CONFIG_DEBUG_PAGEALLOC=n``</span>
<span class="p_del">-	This option is located under &quot;Kernel hacking&quot; / &quot;Memory Debugging&quot;</span>
<span class="p_del">-	/ &quot;Debug page memory allocations&quot;.</span>
<span class="p_del">-</span>
<span class="p_del">-In addition, I highly recommend turning on ``CONFIG_DEBUG_INFO=y``. This is also</span>
<span class="p_del">-located under &quot;Kernel hacking&quot;. With this, you will be able to get line number</span>
<span class="p_del">-information from the kmemcheck warnings, which is extremely valuable in</span>
<span class="p_del">-debugging a problem. This option is not mandatory, however, because it slows</span>
<span class="p_del">-down the compilation process and produces a much bigger kernel image.</span>
<span class="p_del">-</span>
<span class="p_del">-Now the kmemcheck menu should be visible (under &quot;Kernel hacking&quot; / &quot;Memory</span>
<span class="p_del">-Debugging&quot; / &quot;kmemcheck: trap use of uninitialized memory&quot;). Here follows</span>
<span class="p_del">-a description of the kmemcheck configuration variables:</span>
<span class="p_del">-</span>
<span class="p_del">-- ``CONFIG_KMEMCHECK``</span>
<span class="p_del">-	This must be enabled in order to use kmemcheck at all...</span>
<span class="p_del">-</span>
<span class="p_del">-- ``CONFIG_KMEMCHECK_``[``DISABLED`` | ``ENABLED`` | ``ONESHOT``]``_BY_DEFAULT``</span>
<span class="p_del">-	This option controls the status of kmemcheck at boot-time. &quot;Enabled&quot;</span>
<span class="p_del">-	will enable kmemcheck right from the start, &quot;disabled&quot; will boot the</span>
<span class="p_del">-	kernel as normal (but with the kmemcheck code compiled in, so it can</span>
<span class="p_del">-	be enabled at run-time after the kernel has booted), and &quot;one-shot&quot; is</span>
<span class="p_del">-	a special mode which will turn kmemcheck off automatically after</span>
<span class="p_del">-	detecting the first use of uninitialized memory.</span>
<span class="p_del">-</span>
<span class="p_del">-	If you are using kmemcheck to actively debug a problem, then you</span>
<span class="p_del">-	probably want to choose &quot;enabled&quot; here.</span>
<span class="p_del">-</span>
<span class="p_del">-	The one-shot mode is mostly useful in automated test setups because it</span>
<span class="p_del">-	can prevent floods of warnings and increase the chances of the machine</span>
<span class="p_del">-	surviving in case something is really wrong. In other cases, the one-</span>
<span class="p_del">-	shot mode could actually be counter-productive because it would turn</span>
<span class="p_del">-	itself off at the very first error -- in the case of a false positive</span>
<span class="p_del">-	too -- and this would come in the way of debugging the specific</span>
<span class="p_del">-	problem you were interested in.</span>
<span class="p_del">-</span>
<span class="p_del">-	If you would like to use your kernel as normal, but with a chance to</span>
<span class="p_del">-	enable kmemcheck in case of some problem, it might be a good idea to</span>
<span class="p_del">-	choose &quot;disabled&quot; here. When kmemcheck is disabled, most of the run-</span>
<span class="p_del">-	time overhead is not incurred, and the kernel will be almost as fast</span>
<span class="p_del">-	as normal.</span>
<span class="p_del">-</span>
<span class="p_del">-- ``CONFIG_KMEMCHECK_QUEUE_SIZE``</span>
<span class="p_del">-	Select the maximum number of error reports to store in an internal</span>
<span class="p_del">-	(fixed-size) buffer. Since errors can occur virtually anywhere and in</span>
<span class="p_del">-	any context, we need a temporary storage area which is guaranteed not</span>
<span class="p_del">-	to generate any other page faults when accessed. The queue will be</span>
<span class="p_del">-	emptied as soon as a tasklet may be scheduled. If the queue is full,</span>
<span class="p_del">-	new error reports will be lost.</span>
<span class="p_del">-</span>
<span class="p_del">-	The default value of 64 is probably fine. If some code produces more</span>
<span class="p_del">-	than 64 errors within an irqs-off section, then the code is likely to</span>
<span class="p_del">-	produce many, many more, too, and these additional reports seldom give</span>
<span class="p_del">-	any more information (the first report is usually the most valuable</span>
<span class="p_del">-	anyway).</span>
<span class="p_del">-</span>
<span class="p_del">-	This number might have to be adjusted if you are not using serial</span>
<span class="p_del">-	console or similar to capture the kernel log. If you are using the</span>
<span class="p_del">-	&quot;dmesg&quot; command to save the log, then getting a lot of kmemcheck</span>
<span class="p_del">-	warnings might overflow the kernel log itself, and the earlier reports</span>
<span class="p_del">-	will get lost in that way instead. Try setting this to 10 or so on</span>
<span class="p_del">-	such a setup.</span>
<span class="p_del">-</span>
<span class="p_del">-- ``CONFIG_KMEMCHECK_SHADOW_COPY_SHIFT``</span>
<span class="p_del">-	Select the number of shadow bytes to save along with each entry of the</span>
<span class="p_del">-	error-report queue. These bytes indicate what parts of an allocation</span>
<span class="p_del">-	are initialized, uninitialized, etc. and will be displayed when an</span>
<span class="p_del">-	error is detected to help the debugging of a particular problem.</span>
<span class="p_del">-</span>
<span class="p_del">-	The number entered here is actually the logarithm of the number of</span>
<span class="p_del">-	bytes that will be saved. So if you pick for example 5 here, kmemcheck</span>
<span class="p_del">-	will save 2^5 = 32 bytes.</span>
<span class="p_del">-</span>
<span class="p_del">-	The default value should be fine for debugging most problems. It also</span>
<span class="p_del">-	fits nicely within 80 columns.</span>
<span class="p_del">-</span>
<span class="p_del">-- ``CONFIG_KMEMCHECK_PARTIAL_OK``</span>
<span class="p_del">-	This option (when enabled) works around certain GCC optimizations that</span>
<span class="p_del">-	produce 32-bit reads from 16-bit variables where the upper 16 bits are</span>
<span class="p_del">-	thrown away afterwards.</span>
<span class="p_del">-</span>
<span class="p_del">-	The default value (enabled) is recommended. This may of course hide</span>
<span class="p_del">-	some real errors, but disabling it would probably produce a lot of</span>
<span class="p_del">-	false positives.</span>
<span class="p_del">-</span>
<span class="p_del">-- ``CONFIG_KMEMCHECK_BITOPS_OK``</span>
<span class="p_del">-	This option silences warnings that would be generated for bit-field</span>
<span class="p_del">-	accesses where not all the bits are initialized at the same time. This</span>
<span class="p_del">-	may also hide some real bugs.</span>
<span class="p_del">-</span>
<span class="p_del">-	This option is probably obsolete, or it should be replaced with</span>
<span class="p_del">-	the kmemcheck-/bitfield-annotations for the code in question. The</span>
<span class="p_del">-	default value is therefore fine.</span>
<span class="p_del">-</span>
<span class="p_del">-Now compile the kernel as usual.</span>
<span class="p_del">-</span>
<span class="p_del">-</span>
<span class="p_del">-How to use</span>
<span class="p_del">-----------</span>
<span class="p_del">-</span>
<span class="p_del">-Booting</span>
<span class="p_del">-~~~~~~~</span>
<span class="p_del">-</span>
<span class="p_del">-First some information about the command-line options. There is only one</span>
<span class="p_del">-option specific to kmemcheck, and this is called &quot;kmemcheck&quot;. It can be used</span>
<span class="p_del">-to override the default mode as chosen by the ``CONFIG_KMEMCHECK_*_BY_DEFAULT``</span>
<span class="p_del">-option. Its possible settings are:</span>
<span class="p_del">-</span>
<span class="p_del">-- ``kmemcheck=0`` (disabled)</span>
<span class="p_del">-- ``kmemcheck=1`` (enabled)</span>
<span class="p_del">-- ``kmemcheck=2`` (one-shot mode)</span>
<span class="p_del">-</span>
<span class="p_del">-If SLUB debugging has been enabled in the kernel, it may take precedence over</span>
<span class="p_del">-kmemcheck in such a way that the slab caches which are under SLUB debugging</span>
<span class="p_del">-will not be tracked by kmemcheck. In order to ensure that this doesn&#39;t happen</span>
<span class="p_del">-(even though it shouldn&#39;t by default), use SLUB&#39;s boot option ``slub_debug``,</span>
<span class="p_del">-like this: ``slub_debug=-``</span>
<span class="p_del">-</span>
<span class="p_del">-In fact, this option may also be used for fine-grained control over SLUB vs.</span>
<span class="p_del">-kmemcheck. For example, if the command line includes</span>
<span class="p_del">-``kmemcheck=1 slub_debug=,dentry``, then SLUB debugging will be used only</span>
<span class="p_del">-for the &quot;dentry&quot; slab cache, and with kmemcheck tracking all the other</span>
<span class="p_del">-caches. This is advanced usage, however, and is not generally recommended.</span>
<span class="p_del">-</span>
<span class="p_del">-</span>
<span class="p_del">-Run-time enable/disable</span>
<span class="p_del">-~~~~~~~~~~~~~~~~~~~~~~~</span>
<span class="p_del">-</span>
<span class="p_del">-When the kernel has booted, it is possible to enable or disable kmemcheck at</span>
<span class="p_del">-run-time. WARNING: This feature is still experimental and may cause false</span>
<span class="p_del">-positive warnings to appear. Therefore, try not to use this. If you find that</span>
<span class="p_del">-it doesn&#39;t work properly (e.g. you see an unreasonable amount of warnings), I</span>
<span class="p_del">-will be happy to take bug reports.</span>
<span class="p_del">-</span>
<span class="p_del">-Use the file ``/proc/sys/kernel/kmemcheck`` for this purpose, e.g.::</span>
<span class="p_del">-</span>
<span class="p_del">-	$ echo 0 &gt; /proc/sys/kernel/kmemcheck # disables kmemcheck</span>
<span class="p_del">-</span>
<span class="p_del">-The numbers are the same as for the ``kmemcheck=`` command-line option.</span>
<span class="p_del">-</span>
<span class="p_del">-</span>
<span class="p_del">-Debugging</span>
<span class="p_del">-~~~~~~~~~</span>
<span class="p_del">-</span>
<span class="p_del">-A typical report will look something like this::</span>
<span class="p_del">-</span>
<span class="p_del">-    WARNING: kmemcheck: Caught 32-bit read from uninitialized memory (ffff88003e4a2024)</span>
<span class="p_del">-    80000000000000000000000000000000000000000088ffff0000000000000000</span>
<span class="p_del">-     i i i i u u u u i i i i i i i i u u u u u u u u u u u u u u u u</span>
<span class="p_del">-             ^</span>
<span class="p_del">-</span>
<span class="p_del">-    Pid: 1856, comm: ntpdate Not tainted 2.6.29-rc5 #264 945P-A</span>
<span class="p_del">-    RIP: 0010:[&lt;ffffffff8104ede8&gt;]  [&lt;ffffffff8104ede8&gt;] __dequeue_signal+0xc8/0x190</span>
<span class="p_del">-    RSP: 0018:ffff88003cdf7d98  EFLAGS: 00210002</span>
<span class="p_del">-    RAX: 0000000000000030 RBX: ffff88003d4ea968 RCX: 0000000000000009</span>
<span class="p_del">-    RDX: ffff88003e5d6018 RSI: ffff88003e5d6024 RDI: ffff88003cdf7e84</span>
<span class="p_del">-    RBP: ffff88003cdf7db8 R08: ffff88003e5d6000 R09: 0000000000000000</span>
<span class="p_del">-    R10: 0000000000000080 R11: 0000000000000000 R12: 000000000000000e</span>
<span class="p_del">-    R13: ffff88003cdf7e78 R14: ffff88003d530710 R15: ffff88003d5a98c8</span>
<span class="p_del">-    FS:  0000000000000000(0000) GS:ffff880001982000(0063) knlGS:00000</span>
<span class="p_del">-    CS:  0010 DS: 002b ES: 002b CR0: 0000000080050033</span>
<span class="p_del">-    CR2: ffff88003f806ea0 CR3: 000000003c036000 CR4: 00000000000006a0</span>
<span class="p_del">-    DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000</span>
<span class="p_del">-    DR3: 0000000000000000 DR6: 00000000ffff4ff0 DR7: 0000000000000400</span>
<span class="p_del">-     [&lt;ffffffff8104f04e&gt;] dequeue_signal+0x8e/0x170</span>
<span class="p_del">-     [&lt;ffffffff81050bd8&gt;] get_signal_to_deliver+0x98/0x390</span>
<span class="p_del">-     [&lt;ffffffff8100b87d&gt;] do_notify_resume+0xad/0x7d0</span>
<span class="p_del">-     [&lt;ffffffff8100c7b5&gt;] int_signal+0x12/0x17</span>
<span class="p_del">-     [&lt;ffffffffffffffff&gt;] 0xffffffffffffffff</span>
<span class="p_del">-</span>
<span class="p_del">-The single most valuable information in this report is the RIP (or EIP on 32-</span>
<span class="p_del">-bit) value. This will help us pinpoint exactly which instruction that caused</span>
<span class="p_del">-the warning.</span>
<span class="p_del">-</span>
<span class="p_del">-If your kernel was compiled with ``CONFIG_DEBUG_INFO=y``, then all we have to do</span>
<span class="p_del">-is give this address to the addr2line program, like this::</span>
<span class="p_del">-</span>
<span class="p_del">-	$ addr2line -e vmlinux -i ffffffff8104ede8</span>
<span class="p_del">-	arch/x86/include/asm/string_64.h:12</span>
<span class="p_del">-	include/asm-generic/siginfo.h:287</span>
<span class="p_del">-	kernel/signal.c:380</span>
<span class="p_del">-	kernel/signal.c:410</span>
<span class="p_del">-</span>
<span class="p_del">-The &quot;``-e vmlinux``&quot; tells addr2line which file to look in. **IMPORTANT:**</span>
<span class="p_del">-This must be the vmlinux of the kernel that produced the warning in the</span>
<span class="p_del">-first place! If not, the line number information will almost certainly be</span>
<span class="p_del">-wrong.</span>
<span class="p_del">-</span>
<span class="p_del">-The &quot;``-i``&quot; tells addr2line to also print the line numbers of inlined</span>
<span class="p_del">-functions.  In this case, the flag was very important, because otherwise,</span>
<span class="p_del">-it would only have printed the first line, which is just a call to</span>
<span class="p_del">-``memcpy()``, which could be called from a thousand places in the kernel, and</span>
<span class="p_del">-is therefore not very useful.  These inlined functions would not show up in</span>
<span class="p_del">-the stack trace above, simply because the kernel doesn&#39;t load the extra</span>
<span class="p_del">-debugging information. This technique can of course be used with ordinary</span>
<span class="p_del">-kernel oopses as well.</span>
<span class="p_del">-</span>
<span class="p_del">-In this case, it&#39;s the caller of ``memcpy()`` that is interesting, and it can be</span>
<span class="p_del">-found in ``include/asm-generic/siginfo.h``, line 287::</span>
<span class="p_del">-</span>
<span class="p_del">-    281 static inline void copy_siginfo(struct siginfo *to, struct siginfo *from)</span>
<span class="p_del">-    282 {</span>
<span class="p_del">-    283         if (from-&gt;si_code &lt; 0)</span>
<span class="p_del">-    284                 memcpy(to, from, sizeof(*to));</span>
<span class="p_del">-    285         else</span>
<span class="p_del">-    286                 /* _sigchld is currently the largest know union member */</span>
<span class="p_del">-    287                 memcpy(to, from, __ARCH_SI_PREAMBLE_SIZE + sizeof(from-&gt;_sifields._sigchld));</span>
<span class="p_del">-    288 }</span>
<span class="p_del">-</span>
<span class="p_del">-Since this was a read (kmemcheck usually warns about reads only, though it can</span>
<span class="p_del">-warn about writes to unallocated or freed memory as well), it was probably the</span>
<span class="p_del">-&quot;from&quot; argument which contained some uninitialized bytes. Following the chain</span>
<span class="p_del">-of calls, we move upwards to see where &quot;from&quot; was allocated or initialized,</span>
<span class="p_del">-``kernel/signal.c``, line 380::</span>
<span class="p_del">-</span>
<span class="p_del">-    359 static void collect_signal(int sig, struct sigpending *list, siginfo_t *info)</span>
<span class="p_del">-    360 {</span>
<span class="p_del">-    ...</span>
<span class="p_del">-    367         list_for_each_entry(q, &amp;list-&gt;list, list) {</span>
<span class="p_del">-    368                 if (q-&gt;info.si_signo == sig) {</span>
<span class="p_del">-    369                         if (first)</span>
<span class="p_del">-    370                                 goto still_pending;</span>
<span class="p_del">-    371                         first = q;</span>
<span class="p_del">-    ...</span>
<span class="p_del">-    377         if (first) {</span>
<span class="p_del">-    378 still_pending:</span>
<span class="p_del">-    379                 list_del_init(&amp;first-&gt;list);</span>
<span class="p_del">-    380                 copy_siginfo(info, &amp;first-&gt;info);</span>
<span class="p_del">-    381                 __sigqueue_free(first);</span>
<span class="p_del">-    ...</span>
<span class="p_del">-    392         }</span>
<span class="p_del">-    393 }</span>
<span class="p_del">-</span>
<span class="p_del">-Here, it is ``&amp;first-&gt;info`` that is being passed on to ``copy_siginfo()``. The</span>
<span class="p_del">-variable ``first`` was found on a list -- passed in as the second argument to</span>
<span class="p_del">-``collect_signal()``. We  continue our journey through the stack, to figure out</span>
<span class="p_del">-where the item on &quot;list&quot; was allocated or initialized. We move to line 410::</span>
<span class="p_del">-</span>
<span class="p_del">-    395 static int __dequeue_signal(struct sigpending *pending, sigset_t *mask,</span>
<span class="p_del">-    396                         siginfo_t *info)</span>
<span class="p_del">-    397 {</span>
<span class="p_del">-    ...</span>
<span class="p_del">-    410                 collect_signal(sig, pending, info);</span>
<span class="p_del">-    ...</span>
<span class="p_del">-    414 }</span>
<span class="p_del">-</span>
<span class="p_del">-Now we need to follow the ``pending`` pointer, since that is being passed on to</span>
<span class="p_del">-``collect_signal()`` as ``list``. At this point, we&#39;ve run out of lines from the</span>
<span class="p_del">-&quot;addr2line&quot; output. Not to worry, we just paste the next addresses from the</span>
<span class="p_del">-kmemcheck stack dump, i.e.::</span>
<span class="p_del">-</span>
<span class="p_del">-     [&lt;ffffffff8104f04e&gt;] dequeue_signal+0x8e/0x170</span>
<span class="p_del">-     [&lt;ffffffff81050bd8&gt;] get_signal_to_deliver+0x98/0x390</span>
<span class="p_del">-     [&lt;ffffffff8100b87d&gt;] do_notify_resume+0xad/0x7d0</span>
<span class="p_del">-     [&lt;ffffffff8100c7b5&gt;] int_signal+0x12/0x17</span>
<span class="p_del">-</span>
<span class="p_del">-	$ addr2line -e vmlinux -i ffffffff8104f04e ffffffff81050bd8 \</span>
<span class="p_del">-		ffffffff8100b87d ffffffff8100c7b5</span>
<span class="p_del">-	kernel/signal.c:446</span>
<span class="p_del">-	kernel/signal.c:1806</span>
<span class="p_del">-	arch/x86/kernel/signal.c:805</span>
<span class="p_del">-	arch/x86/kernel/signal.c:871</span>
<span class="p_del">-	arch/x86/kernel/entry_64.S:694</span>
<span class="p_del">-</span>
<span class="p_del">-Remember that since these addresses were found on the stack and not as the</span>
<span class="p_del">-RIP value, they actually point to the _next_ instruction (they are return</span>
<span class="p_del">-addresses). This becomes obvious when we look at the code for line 446::</span>
<span class="p_del">-</span>
<span class="p_del">-    422 int dequeue_signal(struct task_struct *tsk, sigset_t *mask, siginfo_t *info)</span>
<span class="p_del">-    423 {</span>
<span class="p_del">-    ...</span>
<span class="p_del">-    431                 signr = __dequeue_signal(&amp;tsk-&gt;signal-&gt;shared_pending,</span>
<span class="p_del">-    432						 mask, info);</span>
<span class="p_del">-    433			/*</span>
<span class="p_del">-    434			 * itimer signal ?</span>
<span class="p_del">-    435			 *</span>
<span class="p_del">-    436			 * itimers are process shared and we restart periodic</span>
<span class="p_del">-    437			 * itimers in the signal delivery path to prevent DoS</span>
<span class="p_del">-    438			 * attacks in the high resolution timer case. This is</span>
<span class="p_del">-    439			 * compliant with the old way of self restarting</span>
<span class="p_del">-    440			 * itimers, as the SIGALRM is a legacy signal and only</span>
<span class="p_del">-    441			 * queued once. Changing the restart behaviour to</span>
<span class="p_del">-    442			 * restart the timer in the signal dequeue path is</span>
<span class="p_del">-    443			 * reducing the timer noise on heavy loaded !highres</span>
<span class="p_del">-    444			 * systems too.</span>
<span class="p_del">-    445			 */</span>
<span class="p_del">-    446			if (unlikely(signr == SIGALRM)) {</span>
<span class="p_del">-    ...</span>
<span class="p_del">-    489 }</span>
<span class="p_del">-</span>
<span class="p_del">-So instead of looking at 446, we should be looking at 431, which is the line</span>
<span class="p_del">-that executes just before 446. Here we see that what we are looking for is</span>
<span class="p_del">-``&amp;tsk-&gt;signal-&gt;shared_pending``.</span>
<span class="p_del">-</span>
<span class="p_del">-Our next task is now to figure out which function that puts items on this</span>
<span class="p_del">-``shared_pending`` list. A crude, but efficient tool, is ``git grep``::</span>
<span class="p_del">-</span>
<span class="p_del">-	$ git grep -n &#39;shared_pending&#39; kernel/</span>
<span class="p_del">-	...</span>
<span class="p_del">-	kernel/signal.c:828:	pending = group ? &amp;t-&gt;signal-&gt;shared_pending : &amp;t-&gt;pending;</span>
<span class="p_del">-	kernel/signal.c:1339:	pending = group ? &amp;t-&gt;signal-&gt;shared_pending : &amp;t-&gt;pending;</span>
<span class="p_del">-	...</span>
<span class="p_del">-</span>
<span class="p_del">-There were more results, but none of them were related to list operations,</span>
<span class="p_del">-and these were the only assignments. We inspect the line numbers more closely</span>
<span class="p_del">-and find that this is indeed where items are being added to the list::</span>
<span class="p_del">-</span>
<span class="p_del">-    816 static int send_signal(int sig, struct siginfo *info, struct task_struct *t,</span>
<span class="p_del">-    817				int group)</span>
<span class="p_del">-    818 {</span>
<span class="p_del">-    ...</span>
<span class="p_del">-    828		pending = group ? &amp;t-&gt;signal-&gt;shared_pending : &amp;t-&gt;pending;</span>
<span class="p_del">-    ...</span>
<span class="p_del">-    851		q = __sigqueue_alloc(t, GFP_ATOMIC, (sig &lt; SIGRTMIN &amp;&amp;</span>
<span class="p_del">-    852						     (is_si_special(info) ||</span>
<span class="p_del">-    853						      info-&gt;si_code &gt;= 0)));</span>
<span class="p_del">-    854		if (q) {</span>
<span class="p_del">-    855			list_add_tail(&amp;q-&gt;list, &amp;pending-&gt;list);</span>
<span class="p_del">-    ...</span>
<span class="p_del">-    890 }</span>
<span class="p_del">-</span>
<span class="p_del">-and::</span>
<span class="p_del">-</span>
<span class="p_del">-    1309 int send_sigqueue(struct sigqueue *q, struct task_struct *t, int group)</span>
<span class="p_del">-    1310 {</span>
<span class="p_del">-    ....</span>
<span class="p_del">-    1339	 pending = group ? &amp;t-&gt;signal-&gt;shared_pending : &amp;t-&gt;pending;</span>
<span class="p_del">-    1340	 list_add_tail(&amp;q-&gt;list, &amp;pending-&gt;list);</span>
<span class="p_del">-    ....</span>
<span class="p_del">-    1347 }</span>
<span class="p_del">-</span>
<span class="p_del">-In the first case, the list element we are looking for, ``q``, is being</span>
<span class="p_del">-returned from the function ``__sigqueue_alloc()``, which looks like an</span>
<span class="p_del">-allocation function.  Let&#39;s take a look at it::</span>
<span class="p_del">-</span>
<span class="p_del">-    187 static struct sigqueue *__sigqueue_alloc(struct task_struct *t, gfp_t flags,</span>
<span class="p_del">-    188						 int override_rlimit)</span>
<span class="p_del">-    189 {</span>
<span class="p_del">-    190		struct sigqueue *q = NULL;</span>
<span class="p_del">-    191		struct user_struct *user;</span>
<span class="p_del">-    192</span>
<span class="p_del">-    193		/*</span>
<span class="p_del">-    194		 * We won&#39;t get problems with the target&#39;s UID changing under us</span>
<span class="p_del">-    195		 * because changing it requires RCU be used, and if t != current, the</span>
<span class="p_del">-    196		 * caller must be holding the RCU readlock (by way of a spinlock) and</span>
<span class="p_del">-    197		 * we use RCU protection here</span>
<span class="p_del">-    198		 */</span>
<span class="p_del">-    199		user = get_uid(__task_cred(t)-&gt;user);</span>
<span class="p_del">-    200		atomic_inc(&amp;user-&gt;sigpending);</span>
<span class="p_del">-    201		if (override_rlimit ||</span>
<span class="p_del">-    202		    atomic_read(&amp;user-&gt;sigpending) &lt;=</span>
<span class="p_del">-    203				t-&gt;signal-&gt;rlim[RLIMIT_SIGPENDING].rlim_cur)</span>
<span class="p_del">-    204			q = kmem_cache_alloc(sigqueue_cachep, flags);</span>
<span class="p_del">-    205		if (unlikely(q == NULL)) {</span>
<span class="p_del">-    206			atomic_dec(&amp;user-&gt;sigpending);</span>
<span class="p_del">-    207			free_uid(user);</span>
<span class="p_del">-    208		} else {</span>
<span class="p_del">-    209			INIT_LIST_HEAD(&amp;q-&gt;list);</span>
<span class="p_del">-    210			q-&gt;flags = 0;</span>
<span class="p_del">-    211			q-&gt;user = user;</span>
<span class="p_del">-    212		}</span>
<span class="p_del">-    213</span>
<span class="p_del">-    214		return q;</span>
<span class="p_del">-    215 }</span>
<span class="p_del">-</span>
<span class="p_del">-We see that this function initializes ``q-&gt;list``, ``q-&gt;flags``, and</span>
<span class="p_del">-``q-&gt;user``. It seems that now is the time to look at the definition of</span>
<span class="p_del">-``struct sigqueue``, e.g.::</span>
<span class="p_del">-</span>
<span class="p_del">-    14 struct sigqueue {</span>
<span class="p_del">-    15	       struct list_head list;</span>
<span class="p_del">-    16	       int flags;</span>
<span class="p_del">-    17	       siginfo_t info;</span>
<span class="p_del">-    18	       struct user_struct *user;</span>
<span class="p_del">-    19 };</span>
<span class="p_del">-</span>
<span class="p_del">-And, you might remember, it was a ``memcpy()`` on ``&amp;first-&gt;info`` that</span>
<span class="p_del">-caused the warning, so this makes perfect sense. It also seems reasonable</span>
<span class="p_del">-to assume that it is the caller of ``__sigqueue_alloc()`` that has the</span>
<span class="p_del">-responsibility of filling out (initializing) this member.</span>
<span class="p_del">-</span>
<span class="p_del">-But just which fields of the struct were uninitialized? Let&#39;s look at</span>
<span class="p_del">-kmemcheck&#39;s report again::</span>
<span class="p_del">-</span>
<span class="p_del">-    WARNING: kmemcheck: Caught 32-bit read from uninitialized memory (ffff88003e4a2024)</span>
<span class="p_del">-    80000000000000000000000000000000000000000088ffff0000000000000000</span>
<span class="p_del">-     i i i i u u u u i i i i i i i i u u u u u u u u u u u u u u u u</span>
<span class="p_del">-	     ^</span>
<span class="p_del">-</span>
<span class="p_del">-These first two lines are the memory dump of the memory object itself, and</span>
<span class="p_del">-the shadow bytemap, respectively. The memory object itself is in this case</span>
<span class="p_del">-``&amp;first-&gt;info``. Just beware that the start of this dump is NOT the start</span>
<span class="p_del">-of the object itself! The position of the caret (^) corresponds with the</span>
<span class="p_del">-address of the read (ffff88003e4a2024).</span>
<span class="p_del">-</span>
<span class="p_del">-The shadow bytemap dump legend is as follows:</span>
<span class="p_del">-</span>
<span class="p_del">-- i: initialized</span>
<span class="p_del">-- u: uninitialized</span>
<span class="p_del">-- a: unallocated (memory has been allocated by the slab layer, but has not</span>
<span class="p_del">-  yet been handed off to anybody)</span>
<span class="p_del">-- f: freed (memory has been allocated by the slab layer, but has been freed</span>
<span class="p_del">-  by the previous owner)</span>
<span class="p_del">-</span>
<span class="p_del">-In order to figure out where (relative to the start of the object) the</span>
<span class="p_del">-uninitialized memory was located, we have to look at the disassembly. For</span>
<span class="p_del">-that, we&#39;ll need the RIP address again::</span>
<span class="p_del">-</span>
<span class="p_del">-    RIP: 0010:[&lt;ffffffff8104ede8&gt;]  [&lt;ffffffff8104ede8&gt;] __dequeue_signal+0xc8/0x190</span>
<span class="p_del">-</span>
<span class="p_del">-	$ objdump -d --no-show-raw-insn vmlinux | grep -C 8 ffffffff8104ede8:</span>
<span class="p_del">-	ffffffff8104edc8:	mov    %r8,0x8(%r8)</span>
<span class="p_del">-	ffffffff8104edcc:	test   %r10d,%r10d</span>
<span class="p_del">-	ffffffff8104edcf:	js     ffffffff8104ee88 &lt;__dequeue_signal+0x168&gt;</span>
<span class="p_del">-	ffffffff8104edd5:	mov    %rax,%rdx</span>
<span class="p_del">-	ffffffff8104edd8:	mov    $0xc,%ecx</span>
<span class="p_del">-	ffffffff8104eddd:	mov    %r13,%rdi</span>
<span class="p_del">-	ffffffff8104ede0:	mov    $0x30,%eax</span>
<span class="p_del">-	ffffffff8104ede5:	mov    %rdx,%rsi</span>
<span class="p_del">-	ffffffff8104ede8:	rep movsl %ds:(%rsi),%es:(%rdi)</span>
<span class="p_del">-	ffffffff8104edea:	test   $0x2,%al</span>
<span class="p_del">-	ffffffff8104edec:	je     ffffffff8104edf0 &lt;__dequeue_signal+0xd0&gt;</span>
<span class="p_del">-	ffffffff8104edee:	movsw  %ds:(%rsi),%es:(%rdi)</span>
<span class="p_del">-	ffffffff8104edf0:	test   $0x1,%al</span>
<span class="p_del">-	ffffffff8104edf2:	je     ffffffff8104edf5 &lt;__dequeue_signal+0xd5&gt;</span>
<span class="p_del">-	ffffffff8104edf4:	movsb  %ds:(%rsi),%es:(%rdi)</span>
<span class="p_del">-	ffffffff8104edf5:	mov    %r8,%rdi</span>
<span class="p_del">-	ffffffff8104edf8:	callq  ffffffff8104de60 &lt;__sigqueue_free&gt;</span>
<span class="p_del">-</span>
<span class="p_del">-As expected, it&#39;s the &quot;``rep movsl``&quot; instruction from the ``memcpy()``</span>
<span class="p_del">-that causes the warning. We know about ``REP MOVSL`` that it uses the register</span>
<span class="p_del">-``RCX`` to count the number of remaining iterations. By taking a look at the</span>
<span class="p_del">-register dump again (from the kmemcheck report), we can figure out how many</span>
<span class="p_del">-bytes were left to copy::</span>
<span class="p_del">-</span>
<span class="p_del">-    RAX: 0000000000000030 RBX: ffff88003d4ea968 RCX: 0000000000000009</span>
<span class="p_del">-</span>
<span class="p_del">-By looking at the disassembly, we also see that ``%ecx`` is being loaded</span>
<span class="p_del">-with the value ``$0xc`` just before (ffffffff8104edd8), so we are very</span>
<span class="p_del">-lucky. Keep in mind that this is the number of iterations, not bytes. And</span>
<span class="p_del">-since this is a &quot;long&quot; operation, we need to multiply by 4 to get the</span>
<span class="p_del">-number of bytes. So this means that the uninitialized value was encountered</span>
<span class="p_del">-at 4 * (0xc - 0x9) = 12 bytes from the start of the object.</span>
<span class="p_del">-</span>
<span class="p_del">-We can now try to figure out which field of the &quot;``struct siginfo``&quot; that</span>
<span class="p_del">-was not initialized. This is the beginning of the struct::</span>
<span class="p_del">-</span>
<span class="p_del">-    40 typedef struct siginfo {</span>
<span class="p_del">-    41	       int si_signo;</span>
<span class="p_del">-    42	       int si_errno;</span>
<span class="p_del">-    43	       int si_code;</span>
<span class="p_del">-    44</span>
<span class="p_del">-    45	       union {</span>
<span class="p_del">-    ..</span>
<span class="p_del">-    92	       } _sifields;</span>
<span class="p_del">-    93 } siginfo_t;</span>
<span class="p_del">-</span>
<span class="p_del">-On 64-bit, the int is 4 bytes long, so it must the union member that has</span>
<span class="p_del">-not been initialized. We can verify this using gdb::</span>
<span class="p_del">-</span>
<span class="p_del">-	$ gdb vmlinux</span>
<span class="p_del">-	...</span>
<span class="p_del">-	(gdb) p &amp;((struct siginfo *) 0)-&gt;_sifields</span>
<span class="p_del">-	$1 = (union {...} *) 0x10</span>
<span class="p_del">-</span>
<span class="p_del">-Actually, it seems that the union member is located at offset 0x10 -- which</span>
<span class="p_del">-means that gcc has inserted 4 bytes of padding between the members ``si_code``</span>
<span class="p_del">-and ``_sifields``. We can now get a fuller picture of the memory dump::</span>
<span class="p_del">-</span>
<span class="p_del">-		 _----------------------------=&gt; si_code</span>
<span class="p_del">-		/	 _--------------------=&gt; (padding)</span>
<span class="p_del">-	       |	/	 _------------=&gt; _sifields(._kill._pid)</span>
<span class="p_del">-	       |       |	/	 _----=&gt; _sifields(._kill._uid)</span>
<span class="p_del">-	       |       |       |	/</span>
<span class="p_del">-	-------|-------|-------|-------|</span>
<span class="p_del">-	80000000000000000000000000000000000000000088ffff0000000000000000</span>
<span class="p_del">-	 i i i i u u u u i i i i i i i i u u u u u u u u u u u u u u u u</span>
<span class="p_del">-</span>
<span class="p_del">-This allows us to realize another important fact: ``si_code`` contains the</span>
<span class="p_del">-value 0x80. Remember that x86 is little endian, so the first 4 bytes</span>
<span class="p_del">-&quot;80000000&quot; are really the number 0x00000080. With a bit of research, we</span>
<span class="p_del">-find that this is actually the constant ``SI_KERNEL`` defined in</span>
<span class="p_del">-``include/asm-generic/siginfo.h``::</span>
<span class="p_del">-</span>
<span class="p_del">-    144 #define SI_KERNEL	0x80		/* sent by the kernel from somewhere	 */</span>
<span class="p_del">-</span>
<span class="p_del">-This macro is used in exactly one place in the x86 kernel: In ``send_signal()``</span>
<span class="p_del">-in ``kernel/signal.c``::</span>
<span class="p_del">-</span>
<span class="p_del">-    816 static int send_signal(int sig, struct siginfo *info, struct task_struct *t,</span>
<span class="p_del">-    817				int group)</span>
<span class="p_del">-    818 {</span>
<span class="p_del">-    ...</span>
<span class="p_del">-    828		pending = group ? &amp;t-&gt;signal-&gt;shared_pending : &amp;t-&gt;pending;</span>
<span class="p_del">-    ...</span>
<span class="p_del">-    851		q = __sigqueue_alloc(t, GFP_ATOMIC, (sig &lt; SIGRTMIN &amp;&amp;</span>
<span class="p_del">-    852						     (is_si_special(info) ||</span>
<span class="p_del">-    853						      info-&gt;si_code &gt;= 0)));</span>
<span class="p_del">-    854		if (q) {</span>
<span class="p_del">-    855			list_add_tail(&amp;q-&gt;list, &amp;pending-&gt;list);</span>
<span class="p_del">-    856			switch ((unsigned long) info) {</span>
<span class="p_del">-    ...</span>
<span class="p_del">-    865			case (unsigned long) SEND_SIG_PRIV:</span>
<span class="p_del">-    866				q-&gt;info.si_signo = sig;</span>
<span class="p_del">-    867				q-&gt;info.si_errno = 0;</span>
<span class="p_del">-    868				q-&gt;info.si_code = SI_KERNEL;</span>
<span class="p_del">-    869				q-&gt;info.si_pid = 0;</span>
<span class="p_del">-    870				q-&gt;info.si_uid = 0;</span>
<span class="p_del">-    871				break;</span>
<span class="p_del">-    ...</span>
<span class="p_del">-    890 }</span>
<span class="p_del">-</span>
<span class="p_del">-Not only does this match with the ``.si_code`` member, it also matches the place</span>
<span class="p_del">-we found earlier when looking for where siginfo_t objects are enqueued on the</span>
<span class="p_del">-``shared_pending`` list.</span>
<span class="p_del">-</span>
<span class="p_del">-So to sum up: It seems that it is the padding introduced by the compiler</span>
<span class="p_del">-between two struct fields that is uninitialized, and this gets reported when</span>
<span class="p_del">-we do a ``memcpy()`` on the struct. This means that we have identified a false</span>
<span class="p_del">-positive warning.</span>
<span class="p_del">-</span>
<span class="p_del">-Normally, kmemcheck will not report uninitialized accesses in ``memcpy()`` calls</span>
<span class="p_del">-when both the source and destination addresses are tracked. (Instead, we copy</span>
<span class="p_del">-the shadow bytemap as well). In this case, the destination address clearly</span>
<span class="p_del">-was not tracked. We can dig a little deeper into the stack trace from above::</span>
<span class="p_del">-</span>
<span class="p_del">-	arch/x86/kernel/signal.c:805</span>
<span class="p_del">-	arch/x86/kernel/signal.c:871</span>
<span class="p_del">-	arch/x86/kernel/entry_64.S:694</span>
<span class="p_del">-</span>
<span class="p_del">-And we clearly see that the destination siginfo object is located on the</span>
<span class="p_del">-stack::</span>
<span class="p_del">-</span>
<span class="p_del">-    782 static void do_signal(struct pt_regs *regs)</span>
<span class="p_del">-    783 {</span>
<span class="p_del">-    784		struct k_sigaction ka;</span>
<span class="p_del">-    785		siginfo_t info;</span>
<span class="p_del">-    ...</span>
<span class="p_del">-    804		signr = get_signal_to_deliver(&amp;info, &amp;ka, regs, NULL);</span>
<span class="p_del">-    ...</span>
<span class="p_del">-    854 }</span>
<span class="p_del">-</span>
<span class="p_del">-And this ``&amp;info`` is what eventually gets passed to ``copy_siginfo()`` as the</span>
<span class="p_del">-destination argument.</span>
<span class="p_del">-</span>
<span class="p_del">-Now, even though we didn&#39;t find an actual error here, the example is still a</span>
<span class="p_del">-good one, because it shows how one would go about to find out what the report</span>
<span class="p_del">-was all about.</span>
<span class="p_del">-</span>
<span class="p_del">-</span>
<span class="p_del">-Annotating false positives</span>
<span class="p_del">-~~~~~~~~~~~~~~~~~~~~~~~~~~</span>
<span class="p_del">-</span>
<span class="p_del">-There are a few different ways to make annotations in the source code that</span>
<span class="p_del">-will keep kmemcheck from checking and reporting certain allocations. Here</span>
<span class="p_del">-they are:</span>
<span class="p_del">-</span>
<span class="p_del">-- ``__GFP_NOTRACK_FALSE_POSITIVE``</span>
<span class="p_del">-	This flag can be passed to ``kmalloc()`` or ``kmem_cache_alloc()``</span>
<span class="p_del">-	(therefore also to other functions that end up calling one of</span>
<span class="p_del">-	these) to indicate that the allocation should not be tracked</span>
<span class="p_del">-	because it would lead to a false positive report. This is a &quot;big</span>
<span class="p_del">-	hammer&quot; way of silencing kmemcheck; after all, even if the false</span>
<span class="p_del">-	positive pertains to particular field in a struct, for example, we</span>
<span class="p_del">-	will now lose the ability to find (real) errors in other parts of</span>
<span class="p_del">-	the same struct.</span>
<span class="p_del">-</span>
<span class="p_del">-	Example::</span>
<span class="p_del">-</span>
<span class="p_del">-	    /* No warnings will ever trigger on accessing any part of x */</span>
<span class="p_del">-	    x = kmalloc(sizeof *x, GFP_KERNEL | __GFP_NOTRACK_FALSE_POSITIVE);</span>
<span class="p_del">-</span>
<span class="p_del">-- ``kmemcheck_bitfield_begin(name)``/``kmemcheck_bitfield_end(name)`` and</span>
<span class="p_del">-	``kmemcheck_annotate_bitfield(ptr, name)``</span>
<span class="p_del">-	The first two of these three macros can be used inside struct</span>
<span class="p_del">-	definitions to signal, respectively, the beginning and end of a</span>
<span class="p_del">-	bitfield. Additionally, this will assign the bitfield a name, which</span>
<span class="p_del">-	is given as an argument to the macros.</span>
<span class="p_del">-</span>
<span class="p_del">-	Having used these markers, one can later use</span>
<span class="p_del">-	kmemcheck_annotate_bitfield() at the point of allocation, to indicate</span>
<span class="p_del">-	which parts of the allocation is part of a bitfield.</span>
<span class="p_del">-</span>
<span class="p_del">-	Example::</span>
<span class="p_del">-</span>
<span class="p_del">-	    struct foo {</span>
<span class="p_del">-		int x;</span>
<span class="p_del">-</span>
<span class="p_del">-		kmemcheck_bitfield_begin(flags);</span>
<span class="p_del">-		int flag_a:1;</span>
<span class="p_del">-		int flag_b:1;</span>
<span class="p_del">-		kmemcheck_bitfield_end(flags);</span>
<span class="p_del">-</span>
<span class="p_del">-		int y;</span>
<span class="p_del">-	    };</span>
<span class="p_del">-</span>
<span class="p_del">-	    struct foo *x = kmalloc(sizeof *x);</span>
<span class="p_del">-</span>
<span class="p_del">-	    /* No warnings will trigger on accessing the bitfield of x */</span>
<span class="p_del">-	    kmemcheck_annotate_bitfield(x, flags);</span>
<span class="p_del">-</span>
<span class="p_del">-	Note that ``kmemcheck_annotate_bitfield()`` can be used even before the</span>
<span class="p_del">-	return value of ``kmalloc()`` is checked -- in other words, passing NULL</span>
<span class="p_del">-	as the first argument is legal (and will do nothing).</span>
<span class="p_del">-</span>
<span class="p_del">-</span>
<span class="p_del">-Reporting errors</span>
<span class="p_del">-----------------</span>
<span class="p_del">-</span>
<span class="p_del">-As we have seen, kmemcheck will produce false positive reports. Therefore, it</span>
<span class="p_del">-is not very wise to blindly post kmemcheck warnings to mailing lists and</span>
<span class="p_del">-maintainers. Instead, I encourage maintainers and developers to find errors</span>
<span class="p_del">-in their own code. If you get a warning, you can try to work around it, try</span>
<span class="p_del">-to figure out if it&#39;s a real error or not, or simply ignore it. Most</span>
<span class="p_del">-developers know their own code and will quickly and efficiently determine the</span>
<span class="p_del">-root cause of a kmemcheck report. This is therefore also the most efficient</span>
<span class="p_del">-way to work with kmemcheck.</span>
<span class="p_del">-</span>
<span class="p_del">-That said, we (the kmemcheck maintainers) will always be on the lookout for</span>
<span class="p_del">-false positives that we can annotate and silence. So whatever you find,</span>
<span class="p_del">-please drop us a note privately! Kernel configs and steps to reproduce (if</span>
<span class="p_del">-available) are of course a great help too.</span>
<span class="p_del">-</span>
<span class="p_del">-Happy hacking!</span>
<span class="p_del">-</span>
<span class="p_del">-</span>
<span class="p_del">-Technical description</span>
<span class="p_del">----------------------</span>
<span class="p_del">-</span>
<span class="p_del">-kmemcheck works by marking memory pages non-present. This means that whenever</span>
<span class="p_del">-somebody attempts to access the page, a page fault is generated. The page</span>
<span class="p_del">-fault handler notices that the page was in fact only hidden, and so it calls</span>
<span class="p_del">-on the kmemcheck code to make further investigations.</span>
<span class="p_del">-</span>
<span class="p_del">-When the investigations are completed, kmemcheck &quot;shows&quot; the page by marking</span>
<span class="p_del">-it present (as it would be under normal circumstances). This way, the</span>
<span class="p_del">-interrupted code can continue as usual.</span>
<span class="p_del">-</span>
<span class="p_del">-But after the instruction has been executed, we should hide the page again, so</span>
<span class="p_del">-that we can catch the next access too! Now kmemcheck makes use of a debugging</span>
<span class="p_del">-feature of the processor, namely single-stepping. When the processor has</span>
<span class="p_del">-finished the one instruction that generated the memory access, a debug</span>
<span class="p_del">-exception is raised. From here, we simply hide the page again and continue</span>
<span class="p_del">-execution, this time with the single-stepping feature turned off.</span>
<span class="p_del">-</span>
<span class="p_del">-kmemcheck requires some assistance from the memory allocator in order to work.</span>
<span class="p_del">-The memory allocator needs to</span>
<span class="p_del">-</span>
<span class="p_del">-  1. Tell kmemcheck about newly allocated pages and pages that are about to</span>
<span class="p_del">-     be freed. This allows kmemcheck to set up and tear down the shadow memory</span>
<span class="p_del">-     for the pages in question. The shadow memory stores the status of each</span>
<span class="p_del">-     byte in the allocation proper, e.g. whether it is initialized or</span>
<span class="p_del">-     uninitialized.</span>
<span class="p_del">-</span>
<span class="p_del">-  2. Tell kmemcheck which parts of memory should be marked uninitialized.</span>
<span class="p_del">-     There are actually a few more states, such as &quot;not yet allocated&quot; and</span>
<span class="p_del">-     &quot;recently freed&quot;.</span>
<span class="p_del">-</span>
<span class="p_del">-If a slab cache is set up using the SLAB_NOTRACK flag, it will never return</span>
<span class="p_del">-memory that can take page faults because of kmemcheck.</span>
<span class="p_del">-</span>
<span class="p_del">-If a slab cache is NOT set up using the SLAB_NOTRACK flag, callers can still</span>
<span class="p_del">-request memory with the __GFP_NOTRACK or __GFP_NOTRACK_FALSE_POSITIVE flags.</span>
<span class="p_del">-This does not prevent the page faults from occurring, however, but marks the</span>
<span class="p_del">-object in question as being initialized so that no warnings will ever be</span>
<span class="p_del">-produced for this object.</span>
<span class="p_del">-</span>
<span class="p_del">-Currently, the SLAB and SLUB allocators are supported by kmemcheck.</span>
<span class="p_header">--- a/MAINTAINERS</span>
<span class="p_header">+++ b/MAINTAINERS</span>
<span class="p_chunk">@@ -7670,16 +7670,6 @@</span> <span class="p_context"> F:	include/linux/kdb.h</span>
 F:	include/linux/kgdb.h
 F:	kernel/debug/
 
<span class="p_del">-KMEMCHECK</span>
<span class="p_del">-M:	Vegard Nossum &lt;vegardno@ifi.uio.no&gt;</span>
<span class="p_del">-M:	Pekka Enberg &lt;penberg@kernel.org&gt;</span>
<span class="p_del">-S:	Maintained</span>
<span class="p_del">-F:	Documentation/dev-tools/kmemcheck.rst</span>
<span class="p_del">-F:	arch/x86/include/asm/kmemcheck.h</span>
<span class="p_del">-F:	arch/x86/mm/kmemcheck/</span>
<span class="p_del">-F:	include/linux/kmemcheck.h</span>
<span class="p_del">-F:	mm/kmemcheck.c</span>
<span class="p_del">-</span>
 KMEMLEAK
 M:	Catalin Marinas &lt;catalin.marinas@arm.com&gt;
 S:	Maintained
<span class="p_header">--- a/arch/x86/Kconfig</span>
<span class="p_header">+++ b/arch/x86/Kconfig</span>
<span class="p_chunk">@@ -111,7 +111,6 @@</span> <span class="p_context"> config X86</span>
 	select HAVE_ARCH_JUMP_LABEL
 	select HAVE_ARCH_KASAN			if X86_64
 	select HAVE_ARCH_KGDB
<span class="p_del">-	select HAVE_ARCH_KMEMCHECK</span>
 	select HAVE_ARCH_MMAP_RND_BITS		if MMU
 	select HAVE_ARCH_MMAP_RND_COMPAT_BITS	if MMU &amp;&amp; COMPAT
 	select HAVE_ARCH_COMPAT_MMAP_BASES	if MMU &amp;&amp; COMPAT
<span class="p_chunk">@@ -1443,7 +1442,7 @@</span> <span class="p_context"> config ARCH_DMA_ADDR_T_64BIT</span>
 
 config X86_DIRECT_GBPAGES
 	def_bool y
<span class="p_del">-	depends on X86_64 &amp;&amp; !DEBUG_PAGEALLOC &amp;&amp; !KMEMCHECK</span>
<span class="p_add">+	depends on X86_64 &amp;&amp; !DEBUG_PAGEALLOC</span>
 	---help---
 	  Certain kernel features effectively disable kernel
 	  linear 1 GB mappings (even if the CPU otherwise
<span class="p_header">--- a/arch/x86/include/asm/kmemcheck.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/kmemcheck.h</span>
<span class="p_chunk">@@ -1,43 +1 @@</span> <span class="p_context"></span>
 /* SPDX-License-Identifier: GPL-2.0 */
<span class="p_del">-#ifndef ASM_X86_KMEMCHECK_H</span>
<span class="p_del">-#define ASM_X86_KMEMCHECK_H</span>
<span class="p_del">-</span>
<span class="p_del">-#include &lt;linux/types.h&gt;</span>
<span class="p_del">-#include &lt;asm/ptrace.h&gt;</span>
<span class="p_del">-</span>
<span class="p_del">-#ifdef CONFIG_KMEMCHECK</span>
<span class="p_del">-bool kmemcheck_active(struct pt_regs *regs);</span>
<span class="p_del">-</span>
<span class="p_del">-void kmemcheck_show(struct pt_regs *regs);</span>
<span class="p_del">-void kmemcheck_hide(struct pt_regs *regs);</span>
<span class="p_del">-</span>
<span class="p_del">-bool kmemcheck_fault(struct pt_regs *regs,</span>
<span class="p_del">-	unsigned long address, unsigned long error_code);</span>
<span class="p_del">-bool kmemcheck_trap(struct pt_regs *regs);</span>
<span class="p_del">-#else</span>
<span class="p_del">-static inline bool kmemcheck_active(struct pt_regs *regs)</span>
<span class="p_del">-{</span>
<span class="p_del">-	return false;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static inline void kmemcheck_show(struct pt_regs *regs)</span>
<span class="p_del">-{</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static inline void kmemcheck_hide(struct pt_regs *regs)</span>
<span class="p_del">-{</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static inline bool kmemcheck_fault(struct pt_regs *regs,</span>
<span class="p_del">-	unsigned long address, unsigned long error_code)</span>
<span class="p_del">-{</span>
<span class="p_del">-	return false;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static inline bool kmemcheck_trap(struct pt_regs *regs)</span>
<span class="p_del">-{</span>
<span class="p_del">-	return false;</span>
<span class="p_del">-}</span>
<span class="p_del">-#endif /* CONFIG_KMEMCHECK */</span>
<span class="p_del">-</span>
<span class="p_del">-#endif</span>
<span class="p_header">--- a/arch/x86/include/asm/string_32.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/string_32.h</span>
<span class="p_chunk">@@ -179,8 +179,6 @@</span> <span class="p_context"> static inline void *__memcpy3d(void *to,</span>
  *	No 3D Now!
  */
 
<span class="p_del">-#ifndef CONFIG_KMEMCHECK</span>
<span class="p_del">-</span>
 #if (__GNUC__ &gt;= 4)
 #define memcpy(t, f, n) __builtin_memcpy(t, f, n)
 #else
<span class="p_chunk">@@ -189,13 +187,6 @@</span> <span class="p_context"> static inline void *__memcpy3d(void *to,</span>
 	 ? __constant_memcpy((t), (f), (n))	\
 	 : __memcpy((t), (f), (n)))
 #endif
<span class="p_del">-#else</span>
<span class="p_del">-/*</span>
<span class="p_del">- * kmemcheck becomes very happy if we use the REP instructions unconditionally,</span>
<span class="p_del">- * because it means that we know both memory operands in advance.</span>
<span class="p_del">- */</span>
<span class="p_del">-#define memcpy(t, f, n) __memcpy((t), (f), (n))</span>
<span class="p_del">-#endif</span>
 
 #endif
 #endif /* !CONFIG_FORTIFY_SOURCE */
<span class="p_header">--- a/arch/x86/include/asm/string_64.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/string_64.h</span>
<span class="p_chunk">@@ -33,7 +33,6 @@</span> <span class="p_context"> extern void *memcpy(void *to, const void</span>
 extern void *__memcpy(void *to, const void *from, size_t len);
 
 #ifndef CONFIG_FORTIFY_SOURCE
<span class="p_del">-#ifndef CONFIG_KMEMCHECK</span>
 #if (__GNUC__ == 4 &amp;&amp; __GNUC_MINOR__ &lt; 3) || __GNUC__ &lt; 4
 #define memcpy(dst, src, len)					\
 ({								\
<span class="p_chunk">@@ -46,13 +45,6 @@</span> <span class="p_context"> extern void *__memcpy(void *to, const vo</span>
 	__ret;							\
 })
 #endif
<span class="p_del">-#else</span>
<span class="p_del">-/*</span>
<span class="p_del">- * kmemcheck becomes very happy if we use the REP instructions unconditionally,</span>
<span class="p_del">- * because it means that we know both memory operands in advance.</span>
<span class="p_del">- */</span>
<span class="p_del">-#define memcpy(dst, src, len) __inline_memcpy((dst), (src), (len))</span>
<span class="p_del">-#endif</span>
 #endif /* !CONFIG_FORTIFY_SOURCE */
 
 #define __HAVE_ARCH_MEMSET
<span class="p_header">--- a/arch/x86/kernel/cpu/intel.c</span>
<span class="p_header">+++ b/arch/x86/kernel/cpu/intel.c</span>
<span class="p_chunk">@@ -250,21 +250,6 @@</span> <span class="p_context"> static void early_init_intel(struct cpui</span>
 	if (c-&gt;x86 == 6 &amp;&amp; c-&gt;x86_model &lt; 15)
 		clear_cpu_cap(c, X86_FEATURE_PAT);
 
<span class="p_del">-#ifdef CONFIG_KMEMCHECK</span>
<span class="p_del">-	/*</span>
<span class="p_del">-	 * P4s have a &quot;fast strings&quot; feature which causes single-</span>
<span class="p_del">-	 * stepping REP instructions to only generate a #DB on</span>
<span class="p_del">-	 * cache-line boundaries.</span>
<span class="p_del">-	 *</span>
<span class="p_del">-	 * Ingo Molnar reported a Pentium D (model 6) and a Xeon</span>
<span class="p_del">-	 * (model 2) with the same problem.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	if (c-&gt;x86 == 15)</span>
<span class="p_del">-		if (msr_clear_bit(MSR_IA32_MISC_ENABLE,</span>
<span class="p_del">-				  MSR_IA32_MISC_ENABLE_FAST_STRING_BIT) &gt; 0)</span>
<span class="p_del">-			pr_info(&quot;kmemcheck: Disabling fast string operations\n&quot;);</span>
<span class="p_del">-#endif</span>
<span class="p_del">-</span>
 	/*
 	 * If fast string is not enabled in IA32_MISC_ENABLE for any reason,
 	 * clear the fast string and enhanced fast string CPU capabilities.
<span class="p_header">--- a/arch/x86/mm/Makefile</span>
<span class="p_header">+++ b/arch/x86/mm/Makefile</span>
<span class="p_chunk">@@ -29,8 +29,6 @@</span> <span class="p_context"> obj-$(CONFIG_X86_PTDUMP)	+= debug_pageta</span>
 
 obj-$(CONFIG_HIGHMEM)		+= highmem_32.o
 
<span class="p_del">-obj-$(CONFIG_KMEMCHECK)		+= kmemcheck/</span>
<span class="p_del">-</span>
 KASAN_SANITIZE_kasan_init_$(BITS).o := n
 obj-$(CONFIG_KASAN)		+= kasan_init_$(BITS).o
 
<span class="p_header">--- a/arch/x86/mm/init.c</span>
<span class="p_header">+++ b/arch/x86/mm/init.c</span>
<span class="p_chunk">@@ -170,12 +170,11 @@</span> <span class="p_context"> static void enable_global_pages(void)</span>
 static void __init probe_page_size_mask(void)
 {
 	/*
<span class="p_del">-	 * For CONFIG_KMEMCHECK or pagealloc debugging, identity mapping will</span>
<span class="p_del">-	 * use small pages.</span>
<span class="p_add">+	 * For pagealloc debugging, identity mapping will use small pages.</span>
 	 * This will simplify cpa(), which otherwise needs to support splitting
 	 * large pages into small in interrupt context, etc.
 	 */
<span class="p_del">-	if (boot_cpu_has(X86_FEATURE_PSE) &amp;&amp; !debug_pagealloc_enabled() &amp;&amp; !IS_ENABLED(CONFIG_KMEMCHECK))</span>
<span class="p_add">+	if (boot_cpu_has(X86_FEATURE_PSE) &amp;&amp; !debug_pagealloc_enabled())</span>
 		page_size_mask |= 1 &lt;&lt; PG_LEVEL_2M;
 	else
 		direct_gbpages = 0;
<span class="p_header">--- a/arch/x86/mm/kmemcheck/Makefile</span>
<span class="p_header">+++ /dev/null</span>
<span class="p_chunk">@@ -1 +0,0 @@</span> <span class="p_context"></span>
<span class="p_del">-obj-y := error.o kmemcheck.o opcode.o pte.o selftest.o shadow.o</span>
<span class="p_header">--- a/arch/x86/mm/kmemcheck/error.c</span>
<span class="p_header">+++ b/arch/x86/mm/kmemcheck/error.c</span>
<span class="p_chunk">@@ -1,228 +1 @@</span> <span class="p_context"></span>
 // SPDX-License-Identifier: GPL-2.0
<span class="p_del">-#include &lt;linux/interrupt.h&gt;</span>
<span class="p_del">-#include &lt;linux/kdebug.h&gt;</span>
<span class="p_del">-#include &lt;linux/kmemcheck.h&gt;</span>
<span class="p_del">-#include &lt;linux/kernel.h&gt;</span>
<span class="p_del">-#include &lt;linux/types.h&gt;</span>
<span class="p_del">-#include &lt;linux/ptrace.h&gt;</span>
<span class="p_del">-#include &lt;linux/stacktrace.h&gt;</span>
<span class="p_del">-#include &lt;linux/string.h&gt;</span>
<span class="p_del">-</span>
<span class="p_del">-#include &quot;error.h&quot;</span>
<span class="p_del">-#include &quot;shadow.h&quot;</span>
<span class="p_del">-</span>
<span class="p_del">-enum kmemcheck_error_type {</span>
<span class="p_del">-	KMEMCHECK_ERROR_INVALID_ACCESS,</span>
<span class="p_del">-	KMEMCHECK_ERROR_BUG,</span>
<span class="p_del">-};</span>
<span class="p_del">-</span>
<span class="p_del">-#define SHADOW_COPY_SIZE (1 &lt;&lt; CONFIG_KMEMCHECK_SHADOW_COPY_SHIFT)</span>
<span class="p_del">-</span>
<span class="p_del">-struct kmemcheck_error {</span>
<span class="p_del">-	enum kmemcheck_error_type type;</span>
<span class="p_del">-</span>
<span class="p_del">-	union {</span>
<span class="p_del">-		/* KMEMCHECK_ERROR_INVALID_ACCESS */</span>
<span class="p_del">-		struct {</span>
<span class="p_del">-			/* Kind of access that caused the error */</span>
<span class="p_del">-			enum kmemcheck_shadow state;</span>
<span class="p_del">-			/* Address and size of the erroneous read */</span>
<span class="p_del">-			unsigned long	address;</span>
<span class="p_del">-			unsigned int	size;</span>
<span class="p_del">-		};</span>
<span class="p_del">-	};</span>
<span class="p_del">-</span>
<span class="p_del">-	struct pt_regs		regs;</span>
<span class="p_del">-	struct stack_trace	trace;</span>
<span class="p_del">-	unsigned long		trace_entries[32];</span>
<span class="p_del">-</span>
<span class="p_del">-	/* We compress it to a char. */</span>
<span class="p_del">-	unsigned char		shadow_copy[SHADOW_COPY_SIZE];</span>
<span class="p_del">-	unsigned char		memory_copy[SHADOW_COPY_SIZE];</span>
<span class="p_del">-};</span>
<span class="p_del">-</span>
<span class="p_del">-/*</span>
<span class="p_del">- * Create a ring queue of errors to output. We can&#39;t call printk() directly</span>
<span class="p_del">- * from the kmemcheck traps, since this may call the console drivers and</span>
<span class="p_del">- * result in a recursive fault.</span>
<span class="p_del">- */</span>
<span class="p_del">-static struct kmemcheck_error error_fifo[CONFIG_KMEMCHECK_QUEUE_SIZE];</span>
<span class="p_del">-static unsigned int error_count;</span>
<span class="p_del">-static unsigned int error_rd;</span>
<span class="p_del">-static unsigned int error_wr;</span>
<span class="p_del">-static unsigned int error_missed_count;</span>
<span class="p_del">-</span>
<span class="p_del">-static struct kmemcheck_error *error_next_wr(void)</span>
<span class="p_del">-{</span>
<span class="p_del">-	struct kmemcheck_error *e;</span>
<span class="p_del">-</span>
<span class="p_del">-	if (error_count == ARRAY_SIZE(error_fifo)) {</span>
<span class="p_del">-		++error_missed_count;</span>
<span class="p_del">-		return NULL;</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">-	e = &amp;error_fifo[error_wr];</span>
<span class="p_del">-	if (++error_wr == ARRAY_SIZE(error_fifo))</span>
<span class="p_del">-		error_wr = 0;</span>
<span class="p_del">-	++error_count;</span>
<span class="p_del">-	return e;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static struct kmemcheck_error *error_next_rd(void)</span>
<span class="p_del">-{</span>
<span class="p_del">-	struct kmemcheck_error *e;</span>
<span class="p_del">-</span>
<span class="p_del">-	if (error_count == 0)</span>
<span class="p_del">-		return NULL;</span>
<span class="p_del">-</span>
<span class="p_del">-	e = &amp;error_fifo[error_rd];</span>
<span class="p_del">-	if (++error_rd == ARRAY_SIZE(error_fifo))</span>
<span class="p_del">-		error_rd = 0;</span>
<span class="p_del">-	--error_count;</span>
<span class="p_del">-	return e;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-void kmemcheck_error_recall(void)</span>
<span class="p_del">-{</span>
<span class="p_del">-	static const char *desc[] = {</span>
<span class="p_del">-		[KMEMCHECK_SHADOW_UNALLOCATED]		= &quot;unallocated&quot;,</span>
<span class="p_del">-		[KMEMCHECK_SHADOW_UNINITIALIZED]	= &quot;uninitialized&quot;,</span>
<span class="p_del">-		[KMEMCHECK_SHADOW_INITIALIZED]		= &quot;initialized&quot;,</span>
<span class="p_del">-		[KMEMCHECK_SHADOW_FREED]		= &quot;freed&quot;,</span>
<span class="p_del">-	};</span>
<span class="p_del">-</span>
<span class="p_del">-	static const char short_desc[] = {</span>
<span class="p_del">-		[KMEMCHECK_SHADOW_UNALLOCATED]		= &#39;a&#39;,</span>
<span class="p_del">-		[KMEMCHECK_SHADOW_UNINITIALIZED]	= &#39;u&#39;,</span>
<span class="p_del">-		[KMEMCHECK_SHADOW_INITIALIZED]		= &#39;i&#39;,</span>
<span class="p_del">-		[KMEMCHECK_SHADOW_FREED]		= &#39;f&#39;,</span>
<span class="p_del">-	};</span>
<span class="p_del">-</span>
<span class="p_del">-	struct kmemcheck_error *e;</span>
<span class="p_del">-	unsigned int i;</span>
<span class="p_del">-</span>
<span class="p_del">-	e = error_next_rd();</span>
<span class="p_del">-	if (!e)</span>
<span class="p_del">-		return;</span>
<span class="p_del">-</span>
<span class="p_del">-	switch (e-&gt;type) {</span>
<span class="p_del">-	case KMEMCHECK_ERROR_INVALID_ACCESS:</span>
<span class="p_del">-		printk(KERN_WARNING &quot;WARNING: kmemcheck: Caught %d-bit read from %s memory (%p)\n&quot;,</span>
<span class="p_del">-			8 * e-&gt;size, e-&gt;state &lt; ARRAY_SIZE(desc) ?</span>
<span class="p_del">-				desc[e-&gt;state] : &quot;(invalid shadow state)&quot;,</span>
<span class="p_del">-			(void *) e-&gt;address);</span>
<span class="p_del">-</span>
<span class="p_del">-		printk(KERN_WARNING);</span>
<span class="p_del">-		for (i = 0; i &lt; SHADOW_COPY_SIZE; ++i)</span>
<span class="p_del">-			printk(KERN_CONT &quot;%02x&quot;, e-&gt;memory_copy[i]);</span>
<span class="p_del">-		printk(KERN_CONT &quot;\n&quot;);</span>
<span class="p_del">-</span>
<span class="p_del">-		printk(KERN_WARNING);</span>
<span class="p_del">-		for (i = 0; i &lt; SHADOW_COPY_SIZE; ++i) {</span>
<span class="p_del">-			if (e-&gt;shadow_copy[i] &lt; ARRAY_SIZE(short_desc))</span>
<span class="p_del">-				printk(KERN_CONT &quot; %c&quot;, short_desc[e-&gt;shadow_copy[i]]);</span>
<span class="p_del">-			else</span>
<span class="p_del">-				printk(KERN_CONT &quot; ?&quot;);</span>
<span class="p_del">-		}</span>
<span class="p_del">-		printk(KERN_CONT &quot;\n&quot;);</span>
<span class="p_del">-		printk(KERN_WARNING &quot;%*c\n&quot;, 2 + 2</span>
<span class="p_del">-			* (int) (e-&gt;address &amp; (SHADOW_COPY_SIZE - 1)), &#39;^&#39;);</span>
<span class="p_del">-		break;</span>
<span class="p_del">-	case KMEMCHECK_ERROR_BUG:</span>
<span class="p_del">-		printk(KERN_EMERG &quot;ERROR: kmemcheck: Fatal error\n&quot;);</span>
<span class="p_del">-		break;</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">-	__show_regs(&amp;e-&gt;regs, 1);</span>
<span class="p_del">-	print_stack_trace(&amp;e-&gt;trace, 0);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static void do_wakeup(unsigned long data)</span>
<span class="p_del">-{</span>
<span class="p_del">-	while (error_count &gt; 0)</span>
<span class="p_del">-		kmemcheck_error_recall();</span>
<span class="p_del">-</span>
<span class="p_del">-	if (error_missed_count &gt; 0) {</span>
<span class="p_del">-		printk(KERN_WARNING &quot;kmemcheck: Lost %d error reports because &quot;</span>
<span class="p_del">-			&quot;the queue was too small\n&quot;, error_missed_count);</span>
<span class="p_del">-		error_missed_count = 0;</span>
<span class="p_del">-	}</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static DECLARE_TASKLET(kmemcheck_tasklet, &amp;do_wakeup, 0);</span>
<span class="p_del">-</span>
<span class="p_del">-/*</span>
<span class="p_del">- * Save the context of an error report.</span>
<span class="p_del">- */</span>
<span class="p_del">-void kmemcheck_error_save(enum kmemcheck_shadow state,</span>
<span class="p_del">-	unsigned long address, unsigned int size, struct pt_regs *regs)</span>
<span class="p_del">-{</span>
<span class="p_del">-	static unsigned long prev_ip;</span>
<span class="p_del">-</span>
<span class="p_del">-	struct kmemcheck_error *e;</span>
<span class="p_del">-	void *shadow_copy;</span>
<span class="p_del">-	void *memory_copy;</span>
<span class="p_del">-</span>
<span class="p_del">-	/* Don&#39;t report several adjacent errors from the same EIP. */</span>
<span class="p_del">-	if (regs-&gt;ip == prev_ip)</span>
<span class="p_del">-		return;</span>
<span class="p_del">-	prev_ip = regs-&gt;ip;</span>
<span class="p_del">-</span>
<span class="p_del">-	e = error_next_wr();</span>
<span class="p_del">-	if (!e)</span>
<span class="p_del">-		return;</span>
<span class="p_del">-</span>
<span class="p_del">-	e-&gt;type = KMEMCHECK_ERROR_INVALID_ACCESS;</span>
<span class="p_del">-</span>
<span class="p_del">-	e-&gt;state = state;</span>
<span class="p_del">-	e-&gt;address = address;</span>
<span class="p_del">-	e-&gt;size = size;</span>
<span class="p_del">-</span>
<span class="p_del">-	/* Save regs */</span>
<span class="p_del">-	memcpy(&amp;e-&gt;regs, regs, sizeof(*regs));</span>
<span class="p_del">-</span>
<span class="p_del">-	/* Save stack trace */</span>
<span class="p_del">-	e-&gt;trace.nr_entries = 0;</span>
<span class="p_del">-	e-&gt;trace.entries = e-&gt;trace_entries;</span>
<span class="p_del">-	e-&gt;trace.max_entries = ARRAY_SIZE(e-&gt;trace_entries);</span>
<span class="p_del">-	e-&gt;trace.skip = 0;</span>
<span class="p_del">-	save_stack_trace_regs(regs, &amp;e-&gt;trace);</span>
<span class="p_del">-</span>
<span class="p_del">-	/* Round address down to nearest 16 bytes */</span>
<span class="p_del">-	shadow_copy = kmemcheck_shadow_lookup(address</span>
<span class="p_del">-		&amp; ~(SHADOW_COPY_SIZE - 1));</span>
<span class="p_del">-	BUG_ON(!shadow_copy);</span>
<span class="p_del">-</span>
<span class="p_del">-	memcpy(e-&gt;shadow_copy, shadow_copy, SHADOW_COPY_SIZE);</span>
<span class="p_del">-</span>
<span class="p_del">-	kmemcheck_show_addr(address);</span>
<span class="p_del">-	memory_copy = (void *) (address &amp; ~(SHADOW_COPY_SIZE - 1));</span>
<span class="p_del">-	memcpy(e-&gt;memory_copy, memory_copy, SHADOW_COPY_SIZE);</span>
<span class="p_del">-	kmemcheck_hide_addr(address);</span>
<span class="p_del">-</span>
<span class="p_del">-	tasklet_hi_schedule_first(&amp;kmemcheck_tasklet);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-/*</span>
<span class="p_del">- * Save the context of a kmemcheck bug.</span>
<span class="p_del">- */</span>
<span class="p_del">-void kmemcheck_error_save_bug(struct pt_regs *regs)</span>
<span class="p_del">-{</span>
<span class="p_del">-	struct kmemcheck_error *e;</span>
<span class="p_del">-</span>
<span class="p_del">-	e = error_next_wr();</span>
<span class="p_del">-	if (!e)</span>
<span class="p_del">-		return;</span>
<span class="p_del">-</span>
<span class="p_del">-	e-&gt;type = KMEMCHECK_ERROR_BUG;</span>
<span class="p_del">-</span>
<span class="p_del">-	memcpy(&amp;e-&gt;regs, regs, sizeof(*regs));</span>
<span class="p_del">-</span>
<span class="p_del">-	e-&gt;trace.nr_entries = 0;</span>
<span class="p_del">-	e-&gt;trace.entries = e-&gt;trace_entries;</span>
<span class="p_del">-	e-&gt;trace.max_entries = ARRAY_SIZE(e-&gt;trace_entries);</span>
<span class="p_del">-	e-&gt;trace.skip = 1;</span>
<span class="p_del">-	save_stack_trace(&amp;e-&gt;trace);</span>
<span class="p_del">-</span>
<span class="p_del">-	tasklet_hi_schedule_first(&amp;kmemcheck_tasklet);</span>
<span class="p_del">-}</span>
<span class="p_header">--- a/arch/x86/mm/kmemcheck/error.h</span>
<span class="p_header">+++ b/arch/x86/mm/kmemcheck/error.h</span>
<span class="p_chunk">@@ -1,16 +1 @@</span> <span class="p_context"></span>
 /* SPDX-License-Identifier: GPL-2.0 */
<span class="p_del">-#ifndef ARCH__X86__MM__KMEMCHECK__ERROR_H</span>
<span class="p_del">-#define ARCH__X86__MM__KMEMCHECK__ERROR_H</span>
<span class="p_del">-</span>
<span class="p_del">-#include &lt;linux/ptrace.h&gt;</span>
<span class="p_del">-</span>
<span class="p_del">-#include &quot;shadow.h&quot;</span>
<span class="p_del">-</span>
<span class="p_del">-void kmemcheck_error_save(enum kmemcheck_shadow state,</span>
<span class="p_del">-	unsigned long address, unsigned int size, struct pt_regs *regs);</span>
<span class="p_del">-</span>
<span class="p_del">-void kmemcheck_error_save_bug(struct pt_regs *regs);</span>
<span class="p_del">-</span>
<span class="p_del">-void kmemcheck_error_recall(void);</span>
<span class="p_del">-</span>
<span class="p_del">-#endif</span>
<span class="p_header">--- a/arch/x86/mm/kmemcheck/kmemcheck.c</span>
<span class="p_header">+++ /dev/null</span>
<span class="p_chunk">@@ -1,658 +0,0 @@</span> <span class="p_context"></span>
<span class="p_del">-/**</span>
<span class="p_del">- * kmemcheck - a heavyweight memory checker for the linux kernel</span>
<span class="p_del">- * Copyright (C) 2007, 2008  Vegard Nossum &lt;vegardno@ifi.uio.no&gt;</span>
<span class="p_del">- * (With a lot of help from Ingo Molnar and Pekka Enberg.)</span>
<span class="p_del">- *</span>
<span class="p_del">- * This program is free software; you can redistribute it and/or modify</span>
<span class="p_del">- * it under the terms of the GNU General Public License (version 2) as</span>
<span class="p_del">- * published by the Free Software Foundation.</span>
<span class="p_del">- */</span>
<span class="p_del">-</span>
<span class="p_del">-#include &lt;linux/init.h&gt;</span>
<span class="p_del">-#include &lt;linux/interrupt.h&gt;</span>
<span class="p_del">-#include &lt;linux/kallsyms.h&gt;</span>
<span class="p_del">-#include &lt;linux/kernel.h&gt;</span>
<span class="p_del">-#include &lt;linux/kmemcheck.h&gt;</span>
<span class="p_del">-#include &lt;linux/mm.h&gt;</span>
<span class="p_del">-#include &lt;linux/page-flags.h&gt;</span>
<span class="p_del">-#include &lt;linux/percpu.h&gt;</span>
<span class="p_del">-#include &lt;linux/ptrace.h&gt;</span>
<span class="p_del">-#include &lt;linux/string.h&gt;</span>
<span class="p_del">-#include &lt;linux/types.h&gt;</span>
<span class="p_del">-</span>
<span class="p_del">-#include &lt;asm/cacheflush.h&gt;</span>
<span class="p_del">-#include &lt;asm/kmemcheck.h&gt;</span>
<span class="p_del">-#include &lt;asm/pgtable.h&gt;</span>
<span class="p_del">-#include &lt;asm/tlbflush.h&gt;</span>
<span class="p_del">-</span>
<span class="p_del">-#include &quot;error.h&quot;</span>
<span class="p_del">-#include &quot;opcode.h&quot;</span>
<span class="p_del">-#include &quot;pte.h&quot;</span>
<span class="p_del">-#include &quot;selftest.h&quot;</span>
<span class="p_del">-#include &quot;shadow.h&quot;</span>
<span class="p_del">-</span>
<span class="p_del">-</span>
<span class="p_del">-#ifdef CONFIG_KMEMCHECK_DISABLED_BY_DEFAULT</span>
<span class="p_del">-#  define KMEMCHECK_ENABLED 0</span>
<span class="p_del">-#endif</span>
<span class="p_del">-</span>
<span class="p_del">-#ifdef CONFIG_KMEMCHECK_ENABLED_BY_DEFAULT</span>
<span class="p_del">-#  define KMEMCHECK_ENABLED 1</span>
<span class="p_del">-#endif</span>
<span class="p_del">-</span>
<span class="p_del">-#ifdef CONFIG_KMEMCHECK_ONESHOT_BY_DEFAULT</span>
<span class="p_del">-#  define KMEMCHECK_ENABLED 2</span>
<span class="p_del">-#endif</span>
<span class="p_del">-</span>
<span class="p_del">-int kmemcheck_enabled = KMEMCHECK_ENABLED;</span>
<span class="p_del">-</span>
<span class="p_del">-int __init kmemcheck_init(void)</span>
<span class="p_del">-{</span>
<span class="p_del">-#ifdef CONFIG_SMP</span>
<span class="p_del">-	/*</span>
<span class="p_del">-	 * Limit SMP to use a single CPU. We rely on the fact that this code</span>
<span class="p_del">-	 * runs before SMP is set up.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	if (setup_max_cpus &gt; 1) {</span>
<span class="p_del">-		printk(KERN_INFO</span>
<span class="p_del">-			&quot;kmemcheck: Limiting number of CPUs to 1.\n&quot;);</span>
<span class="p_del">-		setup_max_cpus = 1;</span>
<span class="p_del">-	}</span>
<span class="p_del">-#endif</span>
<span class="p_del">-</span>
<span class="p_del">-	if (!kmemcheck_selftest()) {</span>
<span class="p_del">-		printk(KERN_INFO &quot;kmemcheck: self-tests failed; disabling\n&quot;);</span>
<span class="p_del">-		kmemcheck_enabled = 0;</span>
<span class="p_del">-		return -EINVAL;</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">-	printk(KERN_INFO &quot;kmemcheck: Initialized\n&quot;);</span>
<span class="p_del">-	return 0;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-early_initcall(kmemcheck_init);</span>
<span class="p_del">-</span>
<span class="p_del">-/*</span>
<span class="p_del">- * We need to parse the kmemcheck= option before any memory is allocated.</span>
<span class="p_del">- */</span>
<span class="p_del">-static int __init param_kmemcheck(char *str)</span>
<span class="p_del">-{</span>
<span class="p_del">-	int val;</span>
<span class="p_del">-	int ret;</span>
<span class="p_del">-</span>
<span class="p_del">-	if (!str)</span>
<span class="p_del">-		return -EINVAL;</span>
<span class="p_del">-</span>
<span class="p_del">-	ret = kstrtoint(str, 0, &amp;val);</span>
<span class="p_del">-	if (ret)</span>
<span class="p_del">-		return ret;</span>
<span class="p_del">-	kmemcheck_enabled = val;</span>
<span class="p_del">-	return 0;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-early_param(&quot;kmemcheck&quot;, param_kmemcheck);</span>
<span class="p_del">-</span>
<span class="p_del">-int kmemcheck_show_addr(unsigned long address)</span>
<span class="p_del">-{</span>
<span class="p_del">-	pte_t *pte;</span>
<span class="p_del">-</span>
<span class="p_del">-	pte = kmemcheck_pte_lookup(address);</span>
<span class="p_del">-	if (!pte)</span>
<span class="p_del">-		return 0;</span>
<span class="p_del">-</span>
<span class="p_del">-	set_pte(pte, __pte(pte_val(*pte) | _PAGE_PRESENT));</span>
<span class="p_del">-	__flush_tlb_one(address);</span>
<span class="p_del">-	return 1;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-int kmemcheck_hide_addr(unsigned long address)</span>
<span class="p_del">-{</span>
<span class="p_del">-	pte_t *pte;</span>
<span class="p_del">-</span>
<span class="p_del">-	pte = kmemcheck_pte_lookup(address);</span>
<span class="p_del">-	if (!pte)</span>
<span class="p_del">-		return 0;</span>
<span class="p_del">-</span>
<span class="p_del">-	set_pte(pte, __pte(pte_val(*pte) &amp; ~_PAGE_PRESENT));</span>
<span class="p_del">-	__flush_tlb_one(address);</span>
<span class="p_del">-	return 1;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-struct kmemcheck_context {</span>
<span class="p_del">-	bool busy;</span>
<span class="p_del">-	int balance;</span>
<span class="p_del">-</span>
<span class="p_del">-	/*</span>
<span class="p_del">-	 * There can be at most two memory operands to an instruction, but</span>
<span class="p_del">-	 * each address can cross a page boundary -- so we may need up to</span>
<span class="p_del">-	 * four addresses that must be hidden/revealed for each fault.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	unsigned long addr[4];</span>
<span class="p_del">-	unsigned long n_addrs;</span>
<span class="p_del">-	unsigned long flags;</span>
<span class="p_del">-</span>
<span class="p_del">-	/* Data size of the instruction that caused a fault. */</span>
<span class="p_del">-	unsigned int size;</span>
<span class="p_del">-};</span>
<span class="p_del">-</span>
<span class="p_del">-static DEFINE_PER_CPU(struct kmemcheck_context, kmemcheck_context);</span>
<span class="p_del">-</span>
<span class="p_del">-bool kmemcheck_active(struct pt_regs *regs)</span>
<span class="p_del">-{</span>
<span class="p_del">-	struct kmemcheck_context *data = this_cpu_ptr(&amp;kmemcheck_context);</span>
<span class="p_del">-</span>
<span class="p_del">-	return data-&gt;balance &gt; 0;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-/* Save an address that needs to be shown/hidden */</span>
<span class="p_del">-static void kmemcheck_save_addr(unsigned long addr)</span>
<span class="p_del">-{</span>
<span class="p_del">-	struct kmemcheck_context *data = this_cpu_ptr(&amp;kmemcheck_context);</span>
<span class="p_del">-</span>
<span class="p_del">-	BUG_ON(data-&gt;n_addrs &gt;= ARRAY_SIZE(data-&gt;addr));</span>
<span class="p_del">-	data-&gt;addr[data-&gt;n_addrs++] = addr;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static unsigned int kmemcheck_show_all(void)</span>
<span class="p_del">-{</span>
<span class="p_del">-	struct kmemcheck_context *data = this_cpu_ptr(&amp;kmemcheck_context);</span>
<span class="p_del">-	unsigned int i;</span>
<span class="p_del">-	unsigned int n;</span>
<span class="p_del">-</span>
<span class="p_del">-	n = 0;</span>
<span class="p_del">-	for (i = 0; i &lt; data-&gt;n_addrs; ++i)</span>
<span class="p_del">-		n += kmemcheck_show_addr(data-&gt;addr[i]);</span>
<span class="p_del">-</span>
<span class="p_del">-	return n;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static unsigned int kmemcheck_hide_all(void)</span>
<span class="p_del">-{</span>
<span class="p_del">-	struct kmemcheck_context *data = this_cpu_ptr(&amp;kmemcheck_context);</span>
<span class="p_del">-	unsigned int i;</span>
<span class="p_del">-	unsigned int n;</span>
<span class="p_del">-</span>
<span class="p_del">-	n = 0;</span>
<span class="p_del">-	for (i = 0; i &lt; data-&gt;n_addrs; ++i)</span>
<span class="p_del">-		n += kmemcheck_hide_addr(data-&gt;addr[i]);</span>
<span class="p_del">-</span>
<span class="p_del">-	return n;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-/*</span>
<span class="p_del">- * Called from the #PF handler.</span>
<span class="p_del">- */</span>
<span class="p_del">-void kmemcheck_show(struct pt_regs *regs)</span>
<span class="p_del">-{</span>
<span class="p_del">-	struct kmemcheck_context *data = this_cpu_ptr(&amp;kmemcheck_context);</span>
<span class="p_del">-</span>
<span class="p_del">-	BUG_ON(!irqs_disabled());</span>
<span class="p_del">-</span>
<span class="p_del">-	if (unlikely(data-&gt;balance != 0)) {</span>
<span class="p_del">-		kmemcheck_show_all();</span>
<span class="p_del">-		kmemcheck_error_save_bug(regs);</span>
<span class="p_del">-		data-&gt;balance = 0;</span>
<span class="p_del">-		return;</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">-	/*</span>
<span class="p_del">-	 * None of the addresses actually belonged to kmemcheck. Note that</span>
<span class="p_del">-	 * this is not an error.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	if (kmemcheck_show_all() == 0)</span>
<span class="p_del">-		return;</span>
<span class="p_del">-</span>
<span class="p_del">-	++data-&gt;balance;</span>
<span class="p_del">-</span>
<span class="p_del">-	/*</span>
<span class="p_del">-	 * The IF needs to be cleared as well, so that the faulting</span>
<span class="p_del">-	 * instruction can run &quot;uninterrupted&quot;. Otherwise, we might take</span>
<span class="p_del">-	 * an interrupt and start executing that before we&#39;ve had a chance</span>
<span class="p_del">-	 * to hide the page again.</span>
<span class="p_del">-	 *</span>
<span class="p_del">-	 * NOTE: In the rare case of multiple faults, we must not override</span>
<span class="p_del">-	 * the original flags:</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	if (!(regs-&gt;flags &amp; X86_EFLAGS_TF))</span>
<span class="p_del">-		data-&gt;flags = regs-&gt;flags;</span>
<span class="p_del">-</span>
<span class="p_del">-	regs-&gt;flags |= X86_EFLAGS_TF;</span>
<span class="p_del">-	regs-&gt;flags &amp;= ~X86_EFLAGS_IF;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-/*</span>
<span class="p_del">- * Called from the #DB handler.</span>
<span class="p_del">- */</span>
<span class="p_del">-void kmemcheck_hide(struct pt_regs *regs)</span>
<span class="p_del">-{</span>
<span class="p_del">-	struct kmemcheck_context *data = this_cpu_ptr(&amp;kmemcheck_context);</span>
<span class="p_del">-	int n;</span>
<span class="p_del">-</span>
<span class="p_del">-	BUG_ON(!irqs_disabled());</span>
<span class="p_del">-</span>
<span class="p_del">-	if (unlikely(data-&gt;balance != 1)) {</span>
<span class="p_del">-		kmemcheck_show_all();</span>
<span class="p_del">-		kmemcheck_error_save_bug(regs);</span>
<span class="p_del">-		data-&gt;n_addrs = 0;</span>
<span class="p_del">-		data-&gt;balance = 0;</span>
<span class="p_del">-</span>
<span class="p_del">-		if (!(data-&gt;flags &amp; X86_EFLAGS_TF))</span>
<span class="p_del">-			regs-&gt;flags &amp;= ~X86_EFLAGS_TF;</span>
<span class="p_del">-		if (data-&gt;flags &amp; X86_EFLAGS_IF)</span>
<span class="p_del">-			regs-&gt;flags |= X86_EFLAGS_IF;</span>
<span class="p_del">-		return;</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">-	if (kmemcheck_enabled)</span>
<span class="p_del">-		n = kmemcheck_hide_all();</span>
<span class="p_del">-	else</span>
<span class="p_del">-		n = kmemcheck_show_all();</span>
<span class="p_del">-</span>
<span class="p_del">-	if (n == 0)</span>
<span class="p_del">-		return;</span>
<span class="p_del">-</span>
<span class="p_del">-	--data-&gt;balance;</span>
<span class="p_del">-</span>
<span class="p_del">-	data-&gt;n_addrs = 0;</span>
<span class="p_del">-</span>
<span class="p_del">-	if (!(data-&gt;flags &amp; X86_EFLAGS_TF))</span>
<span class="p_del">-		regs-&gt;flags &amp;= ~X86_EFLAGS_TF;</span>
<span class="p_del">-	if (data-&gt;flags &amp; X86_EFLAGS_IF)</span>
<span class="p_del">-		regs-&gt;flags |= X86_EFLAGS_IF;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-void kmemcheck_show_pages(struct page *p, unsigned int n)</span>
<span class="p_del">-{</span>
<span class="p_del">-	unsigned int i;</span>
<span class="p_del">-</span>
<span class="p_del">-	for (i = 0; i &lt; n; ++i) {</span>
<span class="p_del">-		unsigned long address;</span>
<span class="p_del">-		pte_t *pte;</span>
<span class="p_del">-		unsigned int level;</span>
<span class="p_del">-</span>
<span class="p_del">-		address = (unsigned long) page_address(&amp;p[i]);</span>
<span class="p_del">-		pte = lookup_address(address, &amp;level);</span>
<span class="p_del">-		BUG_ON(!pte);</span>
<span class="p_del">-		BUG_ON(level != PG_LEVEL_4K);</span>
<span class="p_del">-</span>
<span class="p_del">-		set_pte(pte, __pte(pte_val(*pte) | _PAGE_PRESENT));</span>
<span class="p_del">-		set_pte(pte, __pte(pte_val(*pte) &amp; ~_PAGE_HIDDEN));</span>
<span class="p_del">-		__flush_tlb_one(address);</span>
<span class="p_del">-	}</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-bool kmemcheck_page_is_tracked(struct page *p)</span>
<span class="p_del">-{</span>
<span class="p_del">-	/* This will also check the &quot;hidden&quot; flag of the PTE. */</span>
<span class="p_del">-	return kmemcheck_pte_lookup((unsigned long) page_address(p));</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-void kmemcheck_hide_pages(struct page *p, unsigned int n)</span>
<span class="p_del">-{</span>
<span class="p_del">-	unsigned int i;</span>
<span class="p_del">-</span>
<span class="p_del">-	for (i = 0; i &lt; n; ++i) {</span>
<span class="p_del">-		unsigned long address;</span>
<span class="p_del">-		pte_t *pte;</span>
<span class="p_del">-		unsigned int level;</span>
<span class="p_del">-</span>
<span class="p_del">-		address = (unsigned long) page_address(&amp;p[i]);</span>
<span class="p_del">-		pte = lookup_address(address, &amp;level);</span>
<span class="p_del">-		BUG_ON(!pte);</span>
<span class="p_del">-		BUG_ON(level != PG_LEVEL_4K);</span>
<span class="p_del">-</span>
<span class="p_del">-		set_pte(pte, __pte(pte_val(*pte) &amp; ~_PAGE_PRESENT));</span>
<span class="p_del">-		set_pte(pte, __pte(pte_val(*pte) | _PAGE_HIDDEN));</span>
<span class="p_del">-		__flush_tlb_one(address);</span>
<span class="p_del">-	}</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-/* Access may NOT cross page boundary */</span>
<span class="p_del">-static void kmemcheck_read_strict(struct pt_regs *regs,</span>
<span class="p_del">-	unsigned long addr, unsigned int size)</span>
<span class="p_del">-{</span>
<span class="p_del">-	void *shadow;</span>
<span class="p_del">-	enum kmemcheck_shadow status;</span>
<span class="p_del">-</span>
<span class="p_del">-	shadow = kmemcheck_shadow_lookup(addr);</span>
<span class="p_del">-	if (!shadow)</span>
<span class="p_del">-		return;</span>
<span class="p_del">-</span>
<span class="p_del">-	kmemcheck_save_addr(addr);</span>
<span class="p_del">-	status = kmemcheck_shadow_test(shadow, size);</span>
<span class="p_del">-	if (status == KMEMCHECK_SHADOW_INITIALIZED)</span>
<span class="p_del">-		return;</span>
<span class="p_del">-</span>
<span class="p_del">-	if (kmemcheck_enabled)</span>
<span class="p_del">-		kmemcheck_error_save(status, addr, size, regs);</span>
<span class="p_del">-</span>
<span class="p_del">-	if (kmemcheck_enabled == 2)</span>
<span class="p_del">-		kmemcheck_enabled = 0;</span>
<span class="p_del">-</span>
<span class="p_del">-	/* Don&#39;t warn about it again. */</span>
<span class="p_del">-	kmemcheck_shadow_set(shadow, size);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-bool kmemcheck_is_obj_initialized(unsigned long addr, size_t size)</span>
<span class="p_del">-{</span>
<span class="p_del">-	enum kmemcheck_shadow status;</span>
<span class="p_del">-	void *shadow;</span>
<span class="p_del">-</span>
<span class="p_del">-	shadow = kmemcheck_shadow_lookup(addr);</span>
<span class="p_del">-	if (!shadow)</span>
<span class="p_del">-		return true;</span>
<span class="p_del">-</span>
<span class="p_del">-	status = kmemcheck_shadow_test_all(shadow, size);</span>
<span class="p_del">-</span>
<span class="p_del">-	return status == KMEMCHECK_SHADOW_INITIALIZED;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-/* Access may cross page boundary */</span>
<span class="p_del">-static void kmemcheck_read(struct pt_regs *regs,</span>
<span class="p_del">-	unsigned long addr, unsigned int size)</span>
<span class="p_del">-{</span>
<span class="p_del">-	unsigned long page = addr &amp; PAGE_MASK;</span>
<span class="p_del">-	unsigned long next_addr = addr + size - 1;</span>
<span class="p_del">-	unsigned long next_page = next_addr &amp; PAGE_MASK;</span>
<span class="p_del">-</span>
<span class="p_del">-	if (likely(page == next_page)) {</span>
<span class="p_del">-		kmemcheck_read_strict(regs, addr, size);</span>
<span class="p_del">-		return;</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">-	/*</span>
<span class="p_del">-	 * What we do is basically to split the access across the</span>
<span class="p_del">-	 * two pages and handle each part separately. Yes, this means</span>
<span class="p_del">-	 * that we may now see reads that are 3 + 5 bytes, for</span>
<span class="p_del">-	 * example (and if both are uninitialized, there will be two</span>
<span class="p_del">-	 * reports), but it makes the code a lot simpler.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	kmemcheck_read_strict(regs, addr, next_page - addr);</span>
<span class="p_del">-	kmemcheck_read_strict(regs, next_page, next_addr - next_page);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static void kmemcheck_write_strict(struct pt_regs *regs,</span>
<span class="p_del">-	unsigned long addr, unsigned int size)</span>
<span class="p_del">-{</span>
<span class="p_del">-	void *shadow;</span>
<span class="p_del">-</span>
<span class="p_del">-	shadow = kmemcheck_shadow_lookup(addr);</span>
<span class="p_del">-	if (!shadow)</span>
<span class="p_del">-		return;</span>
<span class="p_del">-</span>
<span class="p_del">-	kmemcheck_save_addr(addr);</span>
<span class="p_del">-	kmemcheck_shadow_set(shadow, size);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static void kmemcheck_write(struct pt_regs *regs,</span>
<span class="p_del">-	unsigned long addr, unsigned int size)</span>
<span class="p_del">-{</span>
<span class="p_del">-	unsigned long page = addr &amp; PAGE_MASK;</span>
<span class="p_del">-	unsigned long next_addr = addr + size - 1;</span>
<span class="p_del">-	unsigned long next_page = next_addr &amp; PAGE_MASK;</span>
<span class="p_del">-</span>
<span class="p_del">-	if (likely(page == next_page)) {</span>
<span class="p_del">-		kmemcheck_write_strict(regs, addr, size);</span>
<span class="p_del">-		return;</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">-	/* See comment in kmemcheck_read(). */</span>
<span class="p_del">-	kmemcheck_write_strict(regs, addr, next_page - addr);</span>
<span class="p_del">-	kmemcheck_write_strict(regs, next_page, next_addr - next_page);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-/*</span>
<span class="p_del">- * Copying is hard. We have two addresses, each of which may be split across</span>
<span class="p_del">- * a page (and each page will have different shadow addresses).</span>
<span class="p_del">- */</span>
<span class="p_del">-static void kmemcheck_copy(struct pt_regs *regs,</span>
<span class="p_del">-	unsigned long src_addr, unsigned long dst_addr, unsigned int size)</span>
<span class="p_del">-{</span>
<span class="p_del">-	uint8_t shadow[8];</span>
<span class="p_del">-	enum kmemcheck_shadow status;</span>
<span class="p_del">-</span>
<span class="p_del">-	unsigned long page;</span>
<span class="p_del">-	unsigned long next_addr;</span>
<span class="p_del">-	unsigned long next_page;</span>
<span class="p_del">-</span>
<span class="p_del">-	uint8_t *x;</span>
<span class="p_del">-	unsigned int i;</span>
<span class="p_del">-	unsigned int n;</span>
<span class="p_del">-</span>
<span class="p_del">-	BUG_ON(size &gt; sizeof(shadow));</span>
<span class="p_del">-</span>
<span class="p_del">-	page = src_addr &amp; PAGE_MASK;</span>
<span class="p_del">-	next_addr = src_addr + size - 1;</span>
<span class="p_del">-	next_page = next_addr &amp; PAGE_MASK;</span>
<span class="p_del">-</span>
<span class="p_del">-	if (likely(page == next_page)) {</span>
<span class="p_del">-		/* Same page */</span>
<span class="p_del">-		x = kmemcheck_shadow_lookup(src_addr);</span>
<span class="p_del">-		if (x) {</span>
<span class="p_del">-			kmemcheck_save_addr(src_addr);</span>
<span class="p_del">-			for (i = 0; i &lt; size; ++i)</span>
<span class="p_del">-				shadow[i] = x[i];</span>
<span class="p_del">-		} else {</span>
<span class="p_del">-			for (i = 0; i &lt; size; ++i)</span>
<span class="p_del">-				shadow[i] = KMEMCHECK_SHADOW_INITIALIZED;</span>
<span class="p_del">-		}</span>
<span class="p_del">-	} else {</span>
<span class="p_del">-		n = next_page - src_addr;</span>
<span class="p_del">-		BUG_ON(n &gt; sizeof(shadow));</span>
<span class="p_del">-</span>
<span class="p_del">-		/* First page */</span>
<span class="p_del">-		x = kmemcheck_shadow_lookup(src_addr);</span>
<span class="p_del">-		if (x) {</span>
<span class="p_del">-			kmemcheck_save_addr(src_addr);</span>
<span class="p_del">-			for (i = 0; i &lt; n; ++i)</span>
<span class="p_del">-				shadow[i] = x[i];</span>
<span class="p_del">-		} else {</span>
<span class="p_del">-			/* Not tracked */</span>
<span class="p_del">-			for (i = 0; i &lt; n; ++i)</span>
<span class="p_del">-				shadow[i] = KMEMCHECK_SHADOW_INITIALIZED;</span>
<span class="p_del">-		}</span>
<span class="p_del">-</span>
<span class="p_del">-		/* Second page */</span>
<span class="p_del">-		x = kmemcheck_shadow_lookup(next_page);</span>
<span class="p_del">-		if (x) {</span>
<span class="p_del">-			kmemcheck_save_addr(next_page);</span>
<span class="p_del">-			for (i = n; i &lt; size; ++i)</span>
<span class="p_del">-				shadow[i] = x[i - n];</span>
<span class="p_del">-		} else {</span>
<span class="p_del">-			/* Not tracked */</span>
<span class="p_del">-			for (i = n; i &lt; size; ++i)</span>
<span class="p_del">-				shadow[i] = KMEMCHECK_SHADOW_INITIALIZED;</span>
<span class="p_del">-		}</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">-	page = dst_addr &amp; PAGE_MASK;</span>
<span class="p_del">-	next_addr = dst_addr + size - 1;</span>
<span class="p_del">-	next_page = next_addr &amp; PAGE_MASK;</span>
<span class="p_del">-</span>
<span class="p_del">-	if (likely(page == next_page)) {</span>
<span class="p_del">-		/* Same page */</span>
<span class="p_del">-		x = kmemcheck_shadow_lookup(dst_addr);</span>
<span class="p_del">-		if (x) {</span>
<span class="p_del">-			kmemcheck_save_addr(dst_addr);</span>
<span class="p_del">-			for (i = 0; i &lt; size; ++i) {</span>
<span class="p_del">-				x[i] = shadow[i];</span>
<span class="p_del">-				shadow[i] = KMEMCHECK_SHADOW_INITIALIZED;</span>
<span class="p_del">-			}</span>
<span class="p_del">-		}</span>
<span class="p_del">-	} else {</span>
<span class="p_del">-		n = next_page - dst_addr;</span>
<span class="p_del">-		BUG_ON(n &gt; sizeof(shadow));</span>
<span class="p_del">-</span>
<span class="p_del">-		/* First page */</span>
<span class="p_del">-		x = kmemcheck_shadow_lookup(dst_addr);</span>
<span class="p_del">-		if (x) {</span>
<span class="p_del">-			kmemcheck_save_addr(dst_addr);</span>
<span class="p_del">-			for (i = 0; i &lt; n; ++i) {</span>
<span class="p_del">-				x[i] = shadow[i];</span>
<span class="p_del">-				shadow[i] = KMEMCHECK_SHADOW_INITIALIZED;</span>
<span class="p_del">-			}</span>
<span class="p_del">-		}</span>
<span class="p_del">-</span>
<span class="p_del">-		/* Second page */</span>
<span class="p_del">-		x = kmemcheck_shadow_lookup(next_page);</span>
<span class="p_del">-		if (x) {</span>
<span class="p_del">-			kmemcheck_save_addr(next_page);</span>
<span class="p_del">-			for (i = n; i &lt; size; ++i) {</span>
<span class="p_del">-				x[i - n] = shadow[i];</span>
<span class="p_del">-				shadow[i] = KMEMCHECK_SHADOW_INITIALIZED;</span>
<span class="p_del">-			}</span>
<span class="p_del">-		}</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">-	status = kmemcheck_shadow_test(shadow, size);</span>
<span class="p_del">-	if (status == KMEMCHECK_SHADOW_INITIALIZED)</span>
<span class="p_del">-		return;</span>
<span class="p_del">-</span>
<span class="p_del">-	if (kmemcheck_enabled)</span>
<span class="p_del">-		kmemcheck_error_save(status, src_addr, size, regs);</span>
<span class="p_del">-</span>
<span class="p_del">-	if (kmemcheck_enabled == 2)</span>
<span class="p_del">-		kmemcheck_enabled = 0;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-enum kmemcheck_method {</span>
<span class="p_del">-	KMEMCHECK_READ,</span>
<span class="p_del">-	KMEMCHECK_WRITE,</span>
<span class="p_del">-};</span>
<span class="p_del">-</span>
<span class="p_del">-static void kmemcheck_access(struct pt_regs *regs,</span>
<span class="p_del">-	unsigned long fallback_address, enum kmemcheck_method fallback_method)</span>
<span class="p_del">-{</span>
<span class="p_del">-	const uint8_t *insn;</span>
<span class="p_del">-	const uint8_t *insn_primary;</span>
<span class="p_del">-	unsigned int size;</span>
<span class="p_del">-</span>
<span class="p_del">-	struct kmemcheck_context *data = this_cpu_ptr(&amp;kmemcheck_context);</span>
<span class="p_del">-</span>
<span class="p_del">-	/* Recursive fault -- ouch. */</span>
<span class="p_del">-	if (data-&gt;busy) {</span>
<span class="p_del">-		kmemcheck_show_addr(fallback_address);</span>
<span class="p_del">-		kmemcheck_error_save_bug(regs);</span>
<span class="p_del">-		return;</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">-	data-&gt;busy = true;</span>
<span class="p_del">-</span>
<span class="p_del">-	insn = (const uint8_t *) regs-&gt;ip;</span>
<span class="p_del">-	insn_primary = kmemcheck_opcode_get_primary(insn);</span>
<span class="p_del">-</span>
<span class="p_del">-	kmemcheck_opcode_decode(insn, &amp;size);</span>
<span class="p_del">-</span>
<span class="p_del">-	switch (insn_primary[0]) {</span>
<span class="p_del">-#ifdef CONFIG_KMEMCHECK_BITOPS_OK</span>
<span class="p_del">-		/* AND, OR, XOR */</span>
<span class="p_del">-		/*</span>
<span class="p_del">-		 * Unfortunately, these instructions have to be excluded from</span>
<span class="p_del">-		 * our regular checking since they access only some (and not</span>
<span class="p_del">-		 * all) bits. This clears out &quot;bogus&quot; bitfield-access warnings.</span>
<span class="p_del">-		 */</span>
<span class="p_del">-	case 0x80:</span>
<span class="p_del">-	case 0x81:</span>
<span class="p_del">-	case 0x82:</span>
<span class="p_del">-	case 0x83:</span>
<span class="p_del">-		switch ((insn_primary[1] &gt;&gt; 3) &amp; 7) {</span>
<span class="p_del">-			/* OR */</span>
<span class="p_del">-		case 1:</span>
<span class="p_del">-			/* AND */</span>
<span class="p_del">-		case 4:</span>
<span class="p_del">-			/* XOR */</span>
<span class="p_del">-		case 6:</span>
<span class="p_del">-			kmemcheck_write(regs, fallback_address, size);</span>
<span class="p_del">-			goto out;</span>
<span class="p_del">-</span>
<span class="p_del">-			/* ADD */</span>
<span class="p_del">-		case 0:</span>
<span class="p_del">-			/* ADC */</span>
<span class="p_del">-		case 2:</span>
<span class="p_del">-			/* SBB */</span>
<span class="p_del">-		case 3:</span>
<span class="p_del">-			/* SUB */</span>
<span class="p_del">-		case 5:</span>
<span class="p_del">-			/* CMP */</span>
<span class="p_del">-		case 7:</span>
<span class="p_del">-			break;</span>
<span class="p_del">-		}</span>
<span class="p_del">-		break;</span>
<span class="p_del">-#endif</span>
<span class="p_del">-</span>
<span class="p_del">-		/* MOVS, MOVSB, MOVSW, MOVSD */</span>
<span class="p_del">-	case 0xa4:</span>
<span class="p_del">-	case 0xa5:</span>
<span class="p_del">-		/*</span>
<span class="p_del">-		 * These instructions are special because they take two</span>
<span class="p_del">-		 * addresses, but we only get one page fault.</span>
<span class="p_del">-		 */</span>
<span class="p_del">-		kmemcheck_copy(regs, regs-&gt;si, regs-&gt;di, size);</span>
<span class="p_del">-		goto out;</span>
<span class="p_del">-</span>
<span class="p_del">-		/* CMPS, CMPSB, CMPSW, CMPSD */</span>
<span class="p_del">-	case 0xa6:</span>
<span class="p_del">-	case 0xa7:</span>
<span class="p_del">-		kmemcheck_read(regs, regs-&gt;si, size);</span>
<span class="p_del">-		kmemcheck_read(regs, regs-&gt;di, size);</span>
<span class="p_del">-		goto out;</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">-	/*</span>
<span class="p_del">-	 * If the opcode isn&#39;t special in any way, we use the data from the</span>
<span class="p_del">-	 * page fault handler to determine the address and type of memory</span>
<span class="p_del">-	 * access.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	switch (fallback_method) {</span>
<span class="p_del">-	case KMEMCHECK_READ:</span>
<span class="p_del">-		kmemcheck_read(regs, fallback_address, size);</span>
<span class="p_del">-		goto out;</span>
<span class="p_del">-	case KMEMCHECK_WRITE:</span>
<span class="p_del">-		kmemcheck_write(regs, fallback_address, size);</span>
<span class="p_del">-		goto out;</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">-out:</span>
<span class="p_del">-	data-&gt;busy = false;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-bool kmemcheck_fault(struct pt_regs *regs, unsigned long address,</span>
<span class="p_del">-	unsigned long error_code)</span>
<span class="p_del">-{</span>
<span class="p_del">-	pte_t *pte;</span>
<span class="p_del">-</span>
<span class="p_del">-	/*</span>
<span class="p_del">-	 * XXX: Is it safe to assume that memory accesses from virtual 86</span>
<span class="p_del">-	 * mode or non-kernel code segments will _never_ access kernel</span>
<span class="p_del">-	 * memory (e.g. tracked pages)? For now, we need this to avoid</span>
<span class="p_del">-	 * invoking kmemcheck for PnP BIOS calls.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	if (regs-&gt;flags &amp; X86_VM_MASK)</span>
<span class="p_del">-		return false;</span>
<span class="p_del">-	if (regs-&gt;cs != __KERNEL_CS)</span>
<span class="p_del">-		return false;</span>
<span class="p_del">-</span>
<span class="p_del">-	pte = kmemcheck_pte_lookup(address);</span>
<span class="p_del">-	if (!pte)</span>
<span class="p_del">-		return false;</span>
<span class="p_del">-</span>
<span class="p_del">-	WARN_ON_ONCE(in_nmi());</span>
<span class="p_del">-</span>
<span class="p_del">-	if (error_code &amp; 2)</span>
<span class="p_del">-		kmemcheck_access(regs, address, KMEMCHECK_WRITE);</span>
<span class="p_del">-	else</span>
<span class="p_del">-		kmemcheck_access(regs, address, KMEMCHECK_READ);</span>
<span class="p_del">-</span>
<span class="p_del">-	kmemcheck_show(regs);</span>
<span class="p_del">-	return true;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-bool kmemcheck_trap(struct pt_regs *regs)</span>
<span class="p_del">-{</span>
<span class="p_del">-	if (!kmemcheck_active(regs))</span>
<span class="p_del">-		return false;</span>
<span class="p_del">-</span>
<span class="p_del">-	/* We&#39;re done. */</span>
<span class="p_del">-	kmemcheck_hide(regs);</span>
<span class="p_del">-	return true;</span>
<span class="p_del">-}</span>
<span class="p_header">--- a/arch/x86/mm/kmemcheck/opcode.c</span>
<span class="p_header">+++ b/arch/x86/mm/kmemcheck/opcode.c</span>
<span class="p_chunk">@@ -1,107 +1 @@</span> <span class="p_context"></span>
 // SPDX-License-Identifier: GPL-2.0
<span class="p_del">-#include &lt;linux/types.h&gt;</span>
<span class="p_del">-</span>
<span class="p_del">-#include &quot;opcode.h&quot;</span>
<span class="p_del">-</span>
<span class="p_del">-static bool opcode_is_prefix(uint8_t b)</span>
<span class="p_del">-{</span>
<span class="p_del">-	return</span>
<span class="p_del">-		/* Group 1 */</span>
<span class="p_del">-		b == 0xf0 || b == 0xf2 || b == 0xf3</span>
<span class="p_del">-		/* Group 2 */</span>
<span class="p_del">-		|| b == 0x2e || b == 0x36 || b == 0x3e || b == 0x26</span>
<span class="p_del">-		|| b == 0x64 || b == 0x65</span>
<span class="p_del">-		/* Group 3 */</span>
<span class="p_del">-		|| b == 0x66</span>
<span class="p_del">-		/* Group 4 */</span>
<span class="p_del">-		|| b == 0x67;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-#ifdef CONFIG_X86_64</span>
<span class="p_del">-static bool opcode_is_rex_prefix(uint8_t b)</span>
<span class="p_del">-{</span>
<span class="p_del">-	return (b &amp; 0xf0) == 0x40;</span>
<span class="p_del">-}</span>
<span class="p_del">-#else</span>
<span class="p_del">-static bool opcode_is_rex_prefix(uint8_t b)</span>
<span class="p_del">-{</span>
<span class="p_del">-	return false;</span>
<span class="p_del">-}</span>
<span class="p_del">-#endif</span>
<span class="p_del">-</span>
<span class="p_del">-#define REX_W (1 &lt;&lt; 3)</span>
<span class="p_del">-</span>
<span class="p_del">-/*</span>
<span class="p_del">- * This is a VERY crude opcode decoder. We only need to find the size of the</span>
<span class="p_del">- * load/store that caused our #PF and this should work for all the opcodes</span>
<span class="p_del">- * that we care about. Moreover, the ones who invented this instruction set</span>
<span class="p_del">- * should be shot.</span>
<span class="p_del">- */</span>
<span class="p_del">-void kmemcheck_opcode_decode(const uint8_t *op, unsigned int *size)</span>
<span class="p_del">-{</span>
<span class="p_del">-	/* Default operand size */</span>
<span class="p_del">-	int operand_size_override = 4;</span>
<span class="p_del">-</span>
<span class="p_del">-	/* prefixes */</span>
<span class="p_del">-	for (; opcode_is_prefix(*op); ++op) {</span>
<span class="p_del">-		if (*op == 0x66)</span>
<span class="p_del">-			operand_size_override = 2;</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">-	/* REX prefix */</span>
<span class="p_del">-	if (opcode_is_rex_prefix(*op)) {</span>
<span class="p_del">-		uint8_t rex = *op;</span>
<span class="p_del">-</span>
<span class="p_del">-		++op;</span>
<span class="p_del">-		if (rex &amp; REX_W) {</span>
<span class="p_del">-			switch (*op) {</span>
<span class="p_del">-			case 0x63:</span>
<span class="p_del">-				*size = 4;</span>
<span class="p_del">-				return;</span>
<span class="p_del">-			case 0x0f:</span>
<span class="p_del">-				++op;</span>
<span class="p_del">-</span>
<span class="p_del">-				switch (*op) {</span>
<span class="p_del">-				case 0xb6:</span>
<span class="p_del">-				case 0xbe:</span>
<span class="p_del">-					*size = 1;</span>
<span class="p_del">-					return;</span>
<span class="p_del">-				case 0xb7:</span>
<span class="p_del">-				case 0xbf:</span>
<span class="p_del">-					*size = 2;</span>
<span class="p_del">-					return;</span>
<span class="p_del">-				}</span>
<span class="p_del">-</span>
<span class="p_del">-				break;</span>
<span class="p_del">-			}</span>
<span class="p_del">-</span>
<span class="p_del">-			*size = 8;</span>
<span class="p_del">-			return;</span>
<span class="p_del">-		}</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">-	/* escape opcode */</span>
<span class="p_del">-	if (*op == 0x0f) {</span>
<span class="p_del">-		++op;</span>
<span class="p_del">-</span>
<span class="p_del">-		/*</span>
<span class="p_del">-		 * This is move with zero-extend and sign-extend, respectively;</span>
<span class="p_del">-		 * we don&#39;t have to think about 0xb6/0xbe, because this is</span>
<span class="p_del">-		 * already handled in the conditional below.</span>
<span class="p_del">-		 */</span>
<span class="p_del">-		if (*op == 0xb7 || *op == 0xbf)</span>
<span class="p_del">-			operand_size_override = 2;</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">-	*size = (*op &amp; 1) ? operand_size_override : 1;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-const uint8_t *kmemcheck_opcode_get_primary(const uint8_t *op)</span>
<span class="p_del">-{</span>
<span class="p_del">-	/* skip prefixes */</span>
<span class="p_del">-	while (opcode_is_prefix(*op))</span>
<span class="p_del">-		++op;</span>
<span class="p_del">-	if (opcode_is_rex_prefix(*op))</span>
<span class="p_del">-		++op;</span>
<span class="p_del">-	return op;</span>
<span class="p_del">-}</span>
<span class="p_header">--- a/arch/x86/mm/kmemcheck/opcode.h</span>
<span class="p_header">+++ b/arch/x86/mm/kmemcheck/opcode.h</span>
<span class="p_chunk">@@ -1,10 +1 @@</span> <span class="p_context"></span>
 /* SPDX-License-Identifier: GPL-2.0 */
<span class="p_del">-#ifndef ARCH__X86__MM__KMEMCHECK__OPCODE_H</span>
<span class="p_del">-#define ARCH__X86__MM__KMEMCHECK__OPCODE_H</span>
<span class="p_del">-</span>
<span class="p_del">-#include &lt;linux/types.h&gt;</span>
<span class="p_del">-</span>
<span class="p_del">-void kmemcheck_opcode_decode(const uint8_t *op, unsigned int *size);</span>
<span class="p_del">-const uint8_t *kmemcheck_opcode_get_primary(const uint8_t *op);</span>
<span class="p_del">-</span>
<span class="p_del">-#endif</span>
<span class="p_header">--- a/arch/x86/mm/kmemcheck/pte.c</span>
<span class="p_header">+++ b/arch/x86/mm/kmemcheck/pte.c</span>
<span class="p_chunk">@@ -1,23 +1 @@</span> <span class="p_context"></span>
 // SPDX-License-Identifier: GPL-2.0
<span class="p_del">-#include &lt;linux/mm.h&gt;</span>
<span class="p_del">-</span>
<span class="p_del">-#include &lt;asm/pgtable.h&gt;</span>
<span class="p_del">-</span>
<span class="p_del">-#include &quot;pte.h&quot;</span>
<span class="p_del">-</span>
<span class="p_del">-pte_t *kmemcheck_pte_lookup(unsigned long address)</span>
<span class="p_del">-{</span>
<span class="p_del">-	pte_t *pte;</span>
<span class="p_del">-	unsigned int level;</span>
<span class="p_del">-</span>
<span class="p_del">-	pte = lookup_address(address, &amp;level);</span>
<span class="p_del">-	if (!pte)</span>
<span class="p_del">-		return NULL;</span>
<span class="p_del">-	if (level != PG_LEVEL_4K)</span>
<span class="p_del">-		return NULL;</span>
<span class="p_del">-	if (!pte_hidden(*pte))</span>
<span class="p_del">-		return NULL;</span>
<span class="p_del">-</span>
<span class="p_del">-	return pte;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_header">--- a/arch/x86/mm/kmemcheck/pte.h</span>
<span class="p_header">+++ b/arch/x86/mm/kmemcheck/pte.h</span>
<span class="p_chunk">@@ -1,11 +1 @@</span> <span class="p_context"></span>
 /* SPDX-License-Identifier: GPL-2.0 */
<span class="p_del">-#ifndef ARCH__X86__MM__KMEMCHECK__PTE_H</span>
<span class="p_del">-#define ARCH__X86__MM__KMEMCHECK__PTE_H</span>
<span class="p_del">-</span>
<span class="p_del">-#include &lt;linux/mm.h&gt;</span>
<span class="p_del">-</span>
<span class="p_del">-#include &lt;asm/pgtable.h&gt;</span>
<span class="p_del">-</span>
<span class="p_del">-pte_t *kmemcheck_pte_lookup(unsigned long address);</span>
<span class="p_del">-</span>
<span class="p_del">-#endif</span>
<span class="p_header">--- a/arch/x86/mm/kmemcheck/selftest.c</span>
<span class="p_header">+++ b/arch/x86/mm/kmemcheck/selftest.c</span>
<span class="p_chunk">@@ -1,71 +1 @@</span> <span class="p_context"></span>
 // SPDX-License-Identifier: GPL-2.0
<span class="p_del">-#include &lt;linux/bug.h&gt;</span>
<span class="p_del">-#include &lt;linux/kernel.h&gt;</span>
<span class="p_del">-</span>
<span class="p_del">-#include &quot;opcode.h&quot;</span>
<span class="p_del">-#include &quot;selftest.h&quot;</span>
<span class="p_del">-</span>
<span class="p_del">-struct selftest_opcode {</span>
<span class="p_del">-	unsigned int expected_size;</span>
<span class="p_del">-	const uint8_t *insn;</span>
<span class="p_del">-	const char *desc;</span>
<span class="p_del">-};</span>
<span class="p_del">-</span>
<span class="p_del">-static const struct selftest_opcode selftest_opcodes[] = {</span>
<span class="p_del">-	/* REP MOVS */</span>
<span class="p_del">-	{1, &quot;\xf3\xa4&quot;, 		&quot;rep movsb &lt;mem8&gt;, &lt;mem8&gt;&quot;},</span>
<span class="p_del">-	{4, &quot;\xf3\xa5&quot;,			&quot;rep movsl &lt;mem32&gt;, &lt;mem32&gt;&quot;},</span>
<span class="p_del">-</span>
<span class="p_del">-	/* MOVZX / MOVZXD */</span>
<span class="p_del">-	{1, &quot;\x66\x0f\xb6\x51\xf8&quot;,	&quot;movzwq &lt;mem8&gt;, &lt;reg16&gt;&quot;},</span>
<span class="p_del">-	{1, &quot;\x0f\xb6\x51\xf8&quot;,		&quot;movzwq &lt;mem8&gt;, &lt;reg32&gt;&quot;},</span>
<span class="p_del">-</span>
<span class="p_del">-	/* MOVSX / MOVSXD */</span>
<span class="p_del">-	{1, &quot;\x66\x0f\xbe\x51\xf8&quot;,	&quot;movswq &lt;mem8&gt;, &lt;reg16&gt;&quot;},</span>
<span class="p_del">-	{1, &quot;\x0f\xbe\x51\xf8&quot;,		&quot;movswq &lt;mem8&gt;, &lt;reg32&gt;&quot;},</span>
<span class="p_del">-</span>
<span class="p_del">-#ifdef CONFIG_X86_64</span>
<span class="p_del">-	/* MOVZX / MOVZXD */</span>
<span class="p_del">-	{1, &quot;\x49\x0f\xb6\x51\xf8&quot;,	&quot;movzbq &lt;mem8&gt;, &lt;reg64&gt;&quot;},</span>
<span class="p_del">-	{2, &quot;\x49\x0f\xb7\x51\xf8&quot;,	&quot;movzbq &lt;mem16&gt;, &lt;reg64&gt;&quot;},</span>
<span class="p_del">-</span>
<span class="p_del">-	/* MOVSX / MOVSXD */</span>
<span class="p_del">-	{1, &quot;\x49\x0f\xbe\x51\xf8&quot;,	&quot;movsbq &lt;mem8&gt;, &lt;reg64&gt;&quot;},</span>
<span class="p_del">-	{2, &quot;\x49\x0f\xbf\x51\xf8&quot;,	&quot;movsbq &lt;mem16&gt;, &lt;reg64&gt;&quot;},</span>
<span class="p_del">-	{4, &quot;\x49\x63\x51\xf8&quot;,		&quot;movslq &lt;mem32&gt;, &lt;reg64&gt;&quot;},</span>
<span class="p_del">-#endif</span>
<span class="p_del">-};</span>
<span class="p_del">-</span>
<span class="p_del">-static bool selftest_opcode_one(const struct selftest_opcode *op)</span>
<span class="p_del">-{</span>
<span class="p_del">-	unsigned size;</span>
<span class="p_del">-</span>
<span class="p_del">-	kmemcheck_opcode_decode(op-&gt;insn, &amp;size);</span>
<span class="p_del">-</span>
<span class="p_del">-	if (size == op-&gt;expected_size)</span>
<span class="p_del">-		return true;</span>
<span class="p_del">-</span>
<span class="p_del">-	printk(KERN_WARNING &quot;kmemcheck: opcode %s: expected size %d, got %d\n&quot;,</span>
<span class="p_del">-		op-&gt;desc, op-&gt;expected_size, size);</span>
<span class="p_del">-	return false;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static bool selftest_opcodes_all(void)</span>
<span class="p_del">-{</span>
<span class="p_del">-	bool pass = true;</span>
<span class="p_del">-	unsigned int i;</span>
<span class="p_del">-</span>
<span class="p_del">-	for (i = 0; i &lt; ARRAY_SIZE(selftest_opcodes); ++i)</span>
<span class="p_del">-		pass = pass &amp;&amp; selftest_opcode_one(&amp;selftest_opcodes[i]);</span>
<span class="p_del">-</span>
<span class="p_del">-	return pass;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-bool kmemcheck_selftest(void)</span>
<span class="p_del">-{</span>
<span class="p_del">-	bool pass = true;</span>
<span class="p_del">-</span>
<span class="p_del">-	pass = pass &amp;&amp; selftest_opcodes_all();</span>
<span class="p_del">-</span>
<span class="p_del">-	return pass;</span>
<span class="p_del">-}</span>
<span class="p_header">--- a/arch/x86/mm/kmemcheck/selftest.h</span>
<span class="p_header">+++ b/arch/x86/mm/kmemcheck/selftest.h</span>
<span class="p_chunk">@@ -1,7 +1 @@</span> <span class="p_context"></span>
 /* SPDX-License-Identifier: GPL-2.0 */
<span class="p_del">-#ifndef ARCH_X86_MM_KMEMCHECK_SELFTEST_H</span>
<span class="p_del">-#define ARCH_X86_MM_KMEMCHECK_SELFTEST_H</span>
<span class="p_del">-</span>
<span class="p_del">-bool kmemcheck_selftest(void);</span>
<span class="p_del">-</span>
<span class="p_del">-#endif</span>
<span class="p_header">--- a/arch/x86/mm/kmemcheck/shadow.c</span>
<span class="p_header">+++ /dev/null</span>
<span class="p_chunk">@@ -1,173 +0,0 @@</span> <span class="p_context"></span>
<span class="p_del">-#include &lt;linux/kmemcheck.h&gt;</span>
<span class="p_del">-#include &lt;linux/export.h&gt;</span>
<span class="p_del">-#include &lt;linux/mm.h&gt;</span>
<span class="p_del">-</span>
<span class="p_del">-#include &lt;asm/page.h&gt;</span>
<span class="p_del">-#include &lt;asm/pgtable.h&gt;</span>
<span class="p_del">-</span>
<span class="p_del">-#include &quot;pte.h&quot;</span>
<span class="p_del">-#include &quot;shadow.h&quot;</span>
<span class="p_del">-</span>
<span class="p_del">-/*</span>
<span class="p_del">- * Return the shadow address for the given address. Returns NULL if the</span>
<span class="p_del">- * address is not tracked.</span>
<span class="p_del">- *</span>
<span class="p_del">- * We need to be extremely careful not to follow any invalid pointers,</span>
<span class="p_del">- * because this function can be called for *any* possible address.</span>
<span class="p_del">- */</span>
<span class="p_del">-void *kmemcheck_shadow_lookup(unsigned long address)</span>
<span class="p_del">-{</span>
<span class="p_del">-	pte_t *pte;</span>
<span class="p_del">-	struct page *page;</span>
<span class="p_del">-</span>
<span class="p_del">-	if (!virt_addr_valid(address))</span>
<span class="p_del">-		return NULL;</span>
<span class="p_del">-</span>
<span class="p_del">-	pte = kmemcheck_pte_lookup(address);</span>
<span class="p_del">-	if (!pte)</span>
<span class="p_del">-		return NULL;</span>
<span class="p_del">-</span>
<span class="p_del">-	page = virt_to_page(address);</span>
<span class="p_del">-	if (!page-&gt;shadow)</span>
<span class="p_del">-		return NULL;</span>
<span class="p_del">-	return page-&gt;shadow + (address &amp; (PAGE_SIZE - 1));</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static void mark_shadow(void *address, unsigned int n,</span>
<span class="p_del">-	enum kmemcheck_shadow status)</span>
<span class="p_del">-{</span>
<span class="p_del">-	unsigned long addr = (unsigned long) address;</span>
<span class="p_del">-	unsigned long last_addr = addr + n - 1;</span>
<span class="p_del">-	unsigned long page = addr &amp; PAGE_MASK;</span>
<span class="p_del">-	unsigned long last_page = last_addr &amp; PAGE_MASK;</span>
<span class="p_del">-	unsigned int first_n;</span>
<span class="p_del">-	void *shadow;</span>
<span class="p_del">-</span>
<span class="p_del">-	/* If the memory range crosses a page boundary, stop there. */</span>
<span class="p_del">-	if (page == last_page)</span>
<span class="p_del">-		first_n = n;</span>
<span class="p_del">-	else</span>
<span class="p_del">-		first_n = page + PAGE_SIZE - addr;</span>
<span class="p_del">-</span>
<span class="p_del">-	shadow = kmemcheck_shadow_lookup(addr);</span>
<span class="p_del">-	if (shadow)</span>
<span class="p_del">-		memset(shadow, status, first_n);</span>
<span class="p_del">-</span>
<span class="p_del">-	addr += first_n;</span>
<span class="p_del">-	n -= first_n;</span>
<span class="p_del">-</span>
<span class="p_del">-	/* Do full-page memset()s. */</span>
<span class="p_del">-	while (n &gt;= PAGE_SIZE) {</span>
<span class="p_del">-		shadow = kmemcheck_shadow_lookup(addr);</span>
<span class="p_del">-		if (shadow)</span>
<span class="p_del">-			memset(shadow, status, PAGE_SIZE);</span>
<span class="p_del">-</span>
<span class="p_del">-		addr += PAGE_SIZE;</span>
<span class="p_del">-		n -= PAGE_SIZE;</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">-	/* Do the remaining page, if any. */</span>
<span class="p_del">-	if (n &gt; 0) {</span>
<span class="p_del">-		shadow = kmemcheck_shadow_lookup(addr);</span>
<span class="p_del">-		if (shadow)</span>
<span class="p_del">-			memset(shadow, status, n);</span>
<span class="p_del">-	}</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-void kmemcheck_mark_unallocated(void *address, unsigned int n)</span>
<span class="p_del">-{</span>
<span class="p_del">-	mark_shadow(address, n, KMEMCHECK_SHADOW_UNALLOCATED);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-void kmemcheck_mark_uninitialized(void *address, unsigned int n)</span>
<span class="p_del">-{</span>
<span class="p_del">-	mark_shadow(address, n, KMEMCHECK_SHADOW_UNINITIALIZED);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-/*</span>
<span class="p_del">- * Fill the shadow memory of the given address such that the memory at that</span>
<span class="p_del">- * address is marked as being initialized.</span>
<span class="p_del">- */</span>
<span class="p_del">-void kmemcheck_mark_initialized(void *address, unsigned int n)</span>
<span class="p_del">-{</span>
<span class="p_del">-	mark_shadow(address, n, KMEMCHECK_SHADOW_INITIALIZED);</span>
<span class="p_del">-}</span>
<span class="p_del">-EXPORT_SYMBOL_GPL(kmemcheck_mark_initialized);</span>
<span class="p_del">-</span>
<span class="p_del">-void kmemcheck_mark_freed(void *address, unsigned int n)</span>
<span class="p_del">-{</span>
<span class="p_del">-	mark_shadow(address, n, KMEMCHECK_SHADOW_FREED);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-void kmemcheck_mark_unallocated_pages(struct page *p, unsigned int n)</span>
<span class="p_del">-{</span>
<span class="p_del">-	unsigned int i;</span>
<span class="p_del">-</span>
<span class="p_del">-	for (i = 0; i &lt; n; ++i)</span>
<span class="p_del">-		kmemcheck_mark_unallocated(page_address(&amp;p[i]), PAGE_SIZE);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-void kmemcheck_mark_uninitialized_pages(struct page *p, unsigned int n)</span>
<span class="p_del">-{</span>
<span class="p_del">-	unsigned int i;</span>
<span class="p_del">-</span>
<span class="p_del">-	for (i = 0; i &lt; n; ++i)</span>
<span class="p_del">-		kmemcheck_mark_uninitialized(page_address(&amp;p[i]), PAGE_SIZE);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-void kmemcheck_mark_initialized_pages(struct page *p, unsigned int n)</span>
<span class="p_del">-{</span>
<span class="p_del">-	unsigned int i;</span>
<span class="p_del">-</span>
<span class="p_del">-	for (i = 0; i &lt; n; ++i)</span>
<span class="p_del">-		kmemcheck_mark_initialized(page_address(&amp;p[i]), PAGE_SIZE);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-enum kmemcheck_shadow kmemcheck_shadow_test(void *shadow, unsigned int size)</span>
<span class="p_del">-{</span>
<span class="p_del">-#ifdef CONFIG_KMEMCHECK_PARTIAL_OK</span>
<span class="p_del">-	uint8_t *x;</span>
<span class="p_del">-	unsigned int i;</span>
<span class="p_del">-</span>
<span class="p_del">-	x = shadow;</span>
<span class="p_del">-</span>
<span class="p_del">-	/*</span>
<span class="p_del">-	 * Make sure _some_ bytes are initialized. Gcc frequently generates</span>
<span class="p_del">-	 * code to access neighboring bytes.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	for (i = 0; i &lt; size; ++i) {</span>
<span class="p_del">-		if (x[i] == KMEMCHECK_SHADOW_INITIALIZED)</span>
<span class="p_del">-			return x[i];</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">-	return x[0];</span>
<span class="p_del">-#else</span>
<span class="p_del">-	return kmemcheck_shadow_test_all(shadow, size);</span>
<span class="p_del">-#endif</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-enum kmemcheck_shadow kmemcheck_shadow_test_all(void *shadow, unsigned int size)</span>
<span class="p_del">-{</span>
<span class="p_del">-	uint8_t *x;</span>
<span class="p_del">-	unsigned int i;</span>
<span class="p_del">-</span>
<span class="p_del">-	x = shadow;</span>
<span class="p_del">-</span>
<span class="p_del">-	/* All bytes must be initialized. */</span>
<span class="p_del">-	for (i = 0; i &lt; size; ++i) {</span>
<span class="p_del">-		if (x[i] != KMEMCHECK_SHADOW_INITIALIZED)</span>
<span class="p_del">-			return x[i];</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">-	return x[0];</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-void kmemcheck_shadow_set(void *shadow, unsigned int size)</span>
<span class="p_del">-{</span>
<span class="p_del">-	uint8_t *x;</span>
<span class="p_del">-	unsigned int i;</span>
<span class="p_del">-</span>
<span class="p_del">-	x = shadow;</span>
<span class="p_del">-	for (i = 0; i &lt; size; ++i)</span>
<span class="p_del">-		x[i] = KMEMCHECK_SHADOW_INITIALIZED;</span>
<span class="p_del">-}</span>
<span class="p_header">--- a/arch/x86/mm/kmemcheck/shadow.h</span>
<span class="p_header">+++ b/arch/x86/mm/kmemcheck/shadow.h</span>
<span class="p_chunk">@@ -1,19 +1 @@</span> <span class="p_context"></span>
 /* SPDX-License-Identifier: GPL-2.0 */
<span class="p_del">-#ifndef ARCH__X86__MM__KMEMCHECK__SHADOW_H</span>
<span class="p_del">-#define ARCH__X86__MM__KMEMCHECK__SHADOW_H</span>
<span class="p_del">-</span>
<span class="p_del">-enum kmemcheck_shadow {</span>
<span class="p_del">-	KMEMCHECK_SHADOW_UNALLOCATED,</span>
<span class="p_del">-	KMEMCHECK_SHADOW_UNINITIALIZED,</span>
<span class="p_del">-	KMEMCHECK_SHADOW_INITIALIZED,</span>
<span class="p_del">-	KMEMCHECK_SHADOW_FREED,</span>
<span class="p_del">-};</span>
<span class="p_del">-</span>
<span class="p_del">-void *kmemcheck_shadow_lookup(unsigned long address);</span>
<span class="p_del">-</span>
<span class="p_del">-enum kmemcheck_shadow kmemcheck_shadow_test(void *shadow, unsigned int size);</span>
<span class="p_del">-enum kmemcheck_shadow kmemcheck_shadow_test_all(void *shadow,</span>
<span class="p_del">-						unsigned int size);</span>
<span class="p_del">-void kmemcheck_shadow_set(void *shadow, unsigned int size);</span>
<span class="p_del">-</span>
<span class="p_del">-#endif</span>
<span class="p_header">--- a/include/linux/interrupt.h</span>
<span class="p_header">+++ b/include/linux/interrupt.h</span>
<span class="p_chunk">@@ -594,21 +594,6 @@</span> <span class="p_context"> static inline void tasklet_hi_schedule(s</span>
 		__tasklet_hi_schedule(t);
 }
 
<span class="p_del">-extern void __tasklet_hi_schedule_first(struct tasklet_struct *t);</span>
<span class="p_del">-</span>
<span class="p_del">-/*</span>
<span class="p_del">- * This version avoids touching any other tasklets. Needed for kmemcheck</span>
<span class="p_del">- * in order not to take any page faults while enqueueing this tasklet;</span>
<span class="p_del">- * consider VERY carefully whether you really need this or</span>
<span class="p_del">- * tasklet_hi_schedule()...</span>
<span class="p_del">- */</span>
<span class="p_del">-static inline void tasklet_hi_schedule_first(struct tasklet_struct *t)</span>
<span class="p_del">-{</span>
<span class="p_del">-	if (!test_and_set_bit(TASKLET_STATE_SCHED, &amp;t-&gt;state))</span>
<span class="p_del">-		__tasklet_hi_schedule_first(t);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-</span>
 static inline void tasklet_disable_nosync(struct tasklet_struct *t)
 {
 	atomic_inc(&amp;t-&gt;count);
<span class="p_header">--- a/include/linux/kmemcheck.h</span>
<span class="p_header">+++ b/include/linux/kmemcheck.h</span>
<span class="p_chunk">@@ -1,172 +1 @@</span> <span class="p_context"></span>
 /* SPDX-License-Identifier: GPL-2.0 */
<span class="p_del">-#ifndef LINUX_KMEMCHECK_H</span>
<span class="p_del">-#define LINUX_KMEMCHECK_H</span>
<span class="p_del">-</span>
<span class="p_del">-#include &lt;linux/mm_types.h&gt;</span>
<span class="p_del">-#include &lt;linux/types.h&gt;</span>
<span class="p_del">-</span>
<span class="p_del">-#ifdef CONFIG_KMEMCHECK</span>
<span class="p_del">-extern int kmemcheck_enabled;</span>
<span class="p_del">-</span>
<span class="p_del">-/* The slab-related functions. */</span>
<span class="p_del">-void kmemcheck_alloc_shadow(struct page *page, int order, gfp_t flags, int node);</span>
<span class="p_del">-void kmemcheck_free_shadow(struct page *page, int order);</span>
<span class="p_del">-void kmemcheck_slab_alloc(struct kmem_cache *s, gfp_t gfpflags, void *object,</span>
<span class="p_del">-			  size_t size);</span>
<span class="p_del">-void kmemcheck_slab_free(struct kmem_cache *s, void *object, size_t size);</span>
<span class="p_del">-</span>
<span class="p_del">-void kmemcheck_pagealloc_alloc(struct page *p, unsigned int order,</span>
<span class="p_del">-			       gfp_t gfpflags);</span>
<span class="p_del">-</span>
<span class="p_del">-void kmemcheck_show_pages(struct page *p, unsigned int n);</span>
<span class="p_del">-void kmemcheck_hide_pages(struct page *p, unsigned int n);</span>
<span class="p_del">-</span>
<span class="p_del">-bool kmemcheck_page_is_tracked(struct page *p);</span>
<span class="p_del">-</span>
<span class="p_del">-void kmemcheck_mark_unallocated(void *address, unsigned int n);</span>
<span class="p_del">-void kmemcheck_mark_uninitialized(void *address, unsigned int n);</span>
<span class="p_del">-void kmemcheck_mark_initialized(void *address, unsigned int n);</span>
<span class="p_del">-void kmemcheck_mark_freed(void *address, unsigned int n);</span>
<span class="p_del">-</span>
<span class="p_del">-void kmemcheck_mark_unallocated_pages(struct page *p, unsigned int n);</span>
<span class="p_del">-void kmemcheck_mark_uninitialized_pages(struct page *p, unsigned int n);</span>
<span class="p_del">-void kmemcheck_mark_initialized_pages(struct page *p, unsigned int n);</span>
<span class="p_del">-</span>
<span class="p_del">-int kmemcheck_show_addr(unsigned long address);</span>
<span class="p_del">-int kmemcheck_hide_addr(unsigned long address);</span>
<span class="p_del">-</span>
<span class="p_del">-bool kmemcheck_is_obj_initialized(unsigned long addr, size_t size);</span>
<span class="p_del">-</span>
<span class="p_del">-/*</span>
<span class="p_del">- * Bitfield annotations</span>
<span class="p_del">- *</span>
<span class="p_del">- * How to use: If you have a struct using bitfields, for example</span>
<span class="p_del">- *</span>
<span class="p_del">- *     struct a {</span>
<span class="p_del">- *             int x:8, y:8;</span>
<span class="p_del">- *     };</span>
<span class="p_del">- *</span>
<span class="p_del">- * then this should be rewritten as</span>
<span class="p_del">- *</span>
<span class="p_del">- *     struct a {</span>
<span class="p_del">- *             kmemcheck_bitfield_begin(flags);</span>
<span class="p_del">- *             int x:8, y:8;</span>
<span class="p_del">- *             kmemcheck_bitfield_end(flags);</span>
<span class="p_del">- *     };</span>
<span class="p_del">- *</span>
<span class="p_del">- * Now the &quot;flags_begin&quot; and &quot;flags_end&quot; members may be used to refer to the</span>
<span class="p_del">- * beginning and end, respectively, of the bitfield (and things like</span>
<span class="p_del">- * &amp;x.flags_begin is allowed). As soon as the struct is allocated, the bit-</span>
<span class="p_del">- * fields should be annotated:</span>
<span class="p_del">- *</span>
<span class="p_del">- *     struct a *a = kmalloc(sizeof(struct a), GFP_KERNEL);</span>
<span class="p_del">- *     kmemcheck_annotate_bitfield(a, flags);</span>
<span class="p_del">- */</span>
<span class="p_del">-#define kmemcheck_bitfield_begin(name)	\</span>
<span class="p_del">-	int name##_begin[0];</span>
<span class="p_del">-</span>
<span class="p_del">-#define kmemcheck_bitfield_end(name)	\</span>
<span class="p_del">-	int name##_end[0];</span>
<span class="p_del">-</span>
<span class="p_del">-#define kmemcheck_annotate_bitfield(ptr, name)				\</span>
<span class="p_del">-	do {								\</span>
<span class="p_del">-		int _n;							\</span>
<span class="p_del">-									\</span>
<span class="p_del">-		if (!ptr)						\</span>
<span class="p_del">-			break;						\</span>
<span class="p_del">-									\</span>
<span class="p_del">-		_n = (long) &amp;((ptr)-&gt;name##_end)			\</span>
<span class="p_del">-			- (long) &amp;((ptr)-&gt;name##_begin);		\</span>
<span class="p_del">-		BUILD_BUG_ON(_n &lt; 0);					\</span>
<span class="p_del">-									\</span>
<span class="p_del">-		kmemcheck_mark_initialized(&amp;((ptr)-&gt;name##_begin), _n);	\</span>
<span class="p_del">-	} while (0)</span>
<span class="p_del">-</span>
<span class="p_del">-#define kmemcheck_annotate_variable(var)				\</span>
<span class="p_del">-	do {								\</span>
<span class="p_del">-		kmemcheck_mark_initialized(&amp;(var), sizeof(var));	\</span>
<span class="p_del">-	} while (0)							\</span>
<span class="p_del">-</span>
<span class="p_del">-#else</span>
<span class="p_del">-#define kmemcheck_enabled 0</span>
<span class="p_del">-</span>
<span class="p_del">-static inline void</span>
<span class="p_del">-kmemcheck_alloc_shadow(struct page *page, int order, gfp_t flags, int node)</span>
<span class="p_del">-{</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static inline void</span>
<span class="p_del">-kmemcheck_free_shadow(struct page *page, int order)</span>
<span class="p_del">-{</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static inline void</span>
<span class="p_del">-kmemcheck_slab_alloc(struct kmem_cache *s, gfp_t gfpflags, void *object,</span>
<span class="p_del">-		     size_t size)</span>
<span class="p_del">-{</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static inline void kmemcheck_slab_free(struct kmem_cache *s, void *object,</span>
<span class="p_del">-				       size_t size)</span>
<span class="p_del">-{</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static inline void kmemcheck_pagealloc_alloc(struct page *p,</span>
<span class="p_del">-	unsigned int order, gfp_t gfpflags)</span>
<span class="p_del">-{</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static inline bool kmemcheck_page_is_tracked(struct page *p)</span>
<span class="p_del">-{</span>
<span class="p_del">-	return false;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static inline void kmemcheck_mark_unallocated(void *address, unsigned int n)</span>
<span class="p_del">-{</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static inline void kmemcheck_mark_uninitialized(void *address, unsigned int n)</span>
<span class="p_del">-{</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static inline void kmemcheck_mark_initialized(void *address, unsigned int n)</span>
<span class="p_del">-{</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static inline void kmemcheck_mark_freed(void *address, unsigned int n)</span>
<span class="p_del">-{</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static inline void kmemcheck_mark_unallocated_pages(struct page *p,</span>
<span class="p_del">-						    unsigned int n)</span>
<span class="p_del">-{</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static inline void kmemcheck_mark_uninitialized_pages(struct page *p,</span>
<span class="p_del">-						      unsigned int n)</span>
<span class="p_del">-{</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static inline void kmemcheck_mark_initialized_pages(struct page *p,</span>
<span class="p_del">-						    unsigned int n)</span>
<span class="p_del">-{</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static inline bool kmemcheck_is_obj_initialized(unsigned long addr, size_t size)</span>
<span class="p_del">-{</span>
<span class="p_del">-	return true;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-#define kmemcheck_bitfield_begin(name)</span>
<span class="p_del">-#define kmemcheck_bitfield_end(name)</span>
<span class="p_del">-#define kmemcheck_annotate_bitfield(ptr, name)	\</span>
<span class="p_del">-	do {					\</span>
<span class="p_del">-	} while (0)</span>
<span class="p_del">-</span>
<span class="p_del">-#define kmemcheck_annotate_variable(var)	\</span>
<span class="p_del">-	do {					\</span>
<span class="p_del">-	} while (0)</span>
<span class="p_del">-</span>
<span class="p_del">-#endif /* CONFIG_KMEMCHECK */</span>
<span class="p_del">-</span>
<span class="p_del">-#endif /* LINUX_KMEMCHECK_H */</span>
<span class="p_header">--- a/kernel/softirq.c</span>
<span class="p_header">+++ b/kernel/softirq.c</span>
<span class="p_chunk">@@ -486,16 +486,6 @@</span> <span class="p_context"> void __tasklet_hi_schedule(struct taskle</span>
 }
 EXPORT_SYMBOL(__tasklet_hi_schedule);
 
<span class="p_del">-void __tasklet_hi_schedule_first(struct tasklet_struct *t)</span>
<span class="p_del">-{</span>
<span class="p_del">-	BUG_ON(!irqs_disabled());</span>
<span class="p_del">-</span>
<span class="p_del">-	t-&gt;next = __this_cpu_read(tasklet_hi_vec.head);</span>
<span class="p_del">-	__this_cpu_write(tasklet_hi_vec.head, t);</span>
<span class="p_del">-	__raise_softirq_irqoff(HI_SOFTIRQ);</span>
<span class="p_del">-}</span>
<span class="p_del">-EXPORT_SYMBOL(__tasklet_hi_schedule_first);</span>
<span class="p_del">-</span>
 static __latent_entropy void tasklet_action(struct softirq_action *a)
 {
 	struct tasklet_struct *list;
<span class="p_header">--- a/kernel/sysctl.c</span>
<span class="p_header">+++ b/kernel/sysctl.c</span>
<span class="p_chunk">@@ -30,7 +30,6 @@</span> <span class="p_context"></span>
 #include &lt;linux/proc_fs.h&gt;
 #include &lt;linux/security.h&gt;
 #include &lt;linux/ctype.h&gt;
<span class="p_del">-#include &lt;linux/kmemcheck.h&gt;</span>
 #include &lt;linux/kmemleak.h&gt;
 #include &lt;linux/fs.h&gt;
 #include &lt;linux/init.h&gt;
<span class="p_chunk">@@ -1174,15 +1173,6 @@</span> <span class="p_context"> static struct ctl_table kern_table[] = {</span>
 		.extra2		= &amp;one_thousand,
 	},
 #endif
<span class="p_del">-#ifdef CONFIG_KMEMCHECK</span>
<span class="p_del">-	{</span>
<span class="p_del">-		.procname	= &quot;kmemcheck&quot;,</span>
<span class="p_del">-		.data		= &amp;kmemcheck_enabled,</span>
<span class="p_del">-		.maxlen		= sizeof(int),</span>
<span class="p_del">-		.mode		= 0644,</span>
<span class="p_del">-		.proc_handler	= proc_dointvec,</span>
<span class="p_del">-	},</span>
<span class="p_del">-#endif</span>
 	{
 		.procname	= &quot;panic_on_warn&quot;,
 		.data		= &amp;panic_on_warn,
<span class="p_header">--- a/lib/Kconfig.debug</span>
<span class="p_header">+++ b/lib/Kconfig.debug</span>
<span class="p_chunk">@@ -504,7 +504,7 @@</span> <span class="p_context"> config DEBUG_OBJECTS_ENABLE_DEFAULT</span>
 
 config DEBUG_SLAB
 	bool &quot;Debug slab memory allocations&quot;
<span class="p_del">-	depends on DEBUG_KERNEL &amp;&amp; SLAB &amp;&amp; !KMEMCHECK</span>
<span class="p_add">+	depends on DEBUG_KERNEL &amp;&amp; SLAB</span>
 	help
 	  Say Y here to have the kernel do limited verification on memory
 	  allocation as well as poisoning memory on free to catch use of freed
<span class="p_chunk">@@ -516,7 +516,7 @@</span> <span class="p_context"> config DEBUG_SLAB_LEAK</span>
 
 config SLUB_DEBUG_ON
 	bool &quot;SLUB debugging on by default&quot;
<span class="p_del">-	depends on SLUB &amp;&amp; SLUB_DEBUG &amp;&amp; !KMEMCHECK</span>
<span class="p_add">+	depends on SLUB &amp;&amp; SLUB_DEBUG</span>
 	default n
 	help
 	  Boot with debugging on by default. SLUB boots by default with
<span class="p_chunk">@@ -730,8 +730,6 @@</span> <span class="p_context"> config DEBUG_STACKOVERFLOW</span>
 
 	  If in doubt, say &quot;N&quot;.
 
<span class="p_del">-source &quot;lib/Kconfig.kmemcheck&quot;</span>
<span class="p_del">-</span>
 source &quot;lib/Kconfig.kasan&quot;
 
 endmenu # &quot;Memory Debugging&quot;
<span class="p_header">--- a/lib/Kconfig.kmemcheck</span>
<span class="p_header">+++ /dev/null</span>
<span class="p_chunk">@@ -1,94 +0,0 @@</span> <span class="p_context"></span>
<span class="p_del">-config HAVE_ARCH_KMEMCHECK</span>
<span class="p_del">-	bool</span>
<span class="p_del">-</span>
<span class="p_del">-if HAVE_ARCH_KMEMCHECK</span>
<span class="p_del">-</span>
<span class="p_del">-menuconfig KMEMCHECK</span>
<span class="p_del">-	bool &quot;kmemcheck: trap use of uninitialized memory&quot;</span>
<span class="p_del">-	depends on DEBUG_KERNEL</span>
<span class="p_del">-	depends on !X86_USE_3DNOW</span>
<span class="p_del">-	depends on SLUB || SLAB</span>
<span class="p_del">-	depends on !CC_OPTIMIZE_FOR_SIZE</span>
<span class="p_del">-	depends on !FUNCTION_TRACER</span>
<span class="p_del">-	select FRAME_POINTER</span>
<span class="p_del">-	select STACKTRACE</span>
<span class="p_del">-	default n</span>
<span class="p_del">-	help</span>
<span class="p_del">-	  This option enables tracing of dynamically allocated kernel memory</span>
<span class="p_del">-	  to see if memory is used before it has been given an initial value.</span>
<span class="p_del">-	  Be aware that this requires half of your memory for bookkeeping and</span>
<span class="p_del">-	  will insert extra code at *every* read and write to tracked memory</span>
<span class="p_del">-	  thus slow down the kernel code (but user code is unaffected).</span>
<span class="p_del">-</span>
<span class="p_del">-	  The kernel may be started with kmemcheck=0 or kmemcheck=1 to disable</span>
<span class="p_del">-	  or enable kmemcheck at boot-time. If the kernel is started with</span>
<span class="p_del">-	  kmemcheck=0, the large memory and CPU overhead is not incurred.</span>
<span class="p_del">-</span>
<span class="p_del">-choice</span>
<span class="p_del">-	prompt &quot;kmemcheck: default mode at boot&quot;</span>
<span class="p_del">-	depends on KMEMCHECK</span>
<span class="p_del">-	default KMEMCHECK_ONESHOT_BY_DEFAULT</span>
<span class="p_del">-	help</span>
<span class="p_del">-	  This option controls the default behaviour of kmemcheck when the</span>
<span class="p_del">-	  kernel boots and no kmemcheck= parameter is given.</span>
<span class="p_del">-</span>
<span class="p_del">-config KMEMCHECK_DISABLED_BY_DEFAULT</span>
<span class="p_del">-	bool &quot;disabled&quot;</span>
<span class="p_del">-	depends on KMEMCHECK</span>
<span class="p_del">-</span>
<span class="p_del">-config KMEMCHECK_ENABLED_BY_DEFAULT</span>
<span class="p_del">-	bool &quot;enabled&quot;</span>
<span class="p_del">-	depends on KMEMCHECK</span>
<span class="p_del">-</span>
<span class="p_del">-config KMEMCHECK_ONESHOT_BY_DEFAULT</span>
<span class="p_del">-	bool &quot;one-shot&quot;</span>
<span class="p_del">-	depends on KMEMCHECK</span>
<span class="p_del">-	help</span>
<span class="p_del">-	  In one-shot mode, only the first error detected is reported before</span>
<span class="p_del">-	  kmemcheck is disabled.</span>
<span class="p_del">-</span>
<span class="p_del">-endchoice</span>
<span class="p_del">-</span>
<span class="p_del">-config KMEMCHECK_QUEUE_SIZE</span>
<span class="p_del">-	int &quot;kmemcheck: error queue size&quot;</span>
<span class="p_del">-	depends on KMEMCHECK</span>
<span class="p_del">-	default 64</span>
<span class="p_del">-	help</span>
<span class="p_del">-	  Select the maximum number of errors to store in the queue. Since</span>
<span class="p_del">-	  errors can occur virtually anywhere and in any context, we need a</span>
<span class="p_del">-	  temporary storage area which is guarantueed not to generate any</span>
<span class="p_del">-	  other faults. The queue will be emptied as soon as a tasklet may</span>
<span class="p_del">-	  be scheduled. If the queue is full, new error reports will be</span>
<span class="p_del">-	  lost.</span>
<span class="p_del">-</span>
<span class="p_del">-config KMEMCHECK_SHADOW_COPY_SHIFT</span>
<span class="p_del">-	int &quot;kmemcheck: shadow copy size (5 =&gt; 32 bytes, 6 =&gt; 64 bytes)&quot;</span>
<span class="p_del">-	depends on KMEMCHECK</span>
<span class="p_del">-	range 2 8</span>
<span class="p_del">-	default 5</span>
<span class="p_del">-	help</span>
<span class="p_del">-	  Select the number of shadow bytes to save along with each entry of</span>
<span class="p_del">-	  the queue. These bytes indicate what parts of an allocation are</span>
<span class="p_del">-	  initialized, uninitialized, etc. and will be displayed when an</span>
<span class="p_del">-	  error is detected to help the debugging of a particular problem.</span>
<span class="p_del">-</span>
<span class="p_del">-config KMEMCHECK_PARTIAL_OK</span>
<span class="p_del">-	bool &quot;kmemcheck: allow partially uninitialized memory&quot;</span>
<span class="p_del">-	depends on KMEMCHECK</span>
<span class="p_del">-	default y</span>
<span class="p_del">-	help</span>
<span class="p_del">-	  This option works around certain GCC optimizations that produce</span>
<span class="p_del">-	  32-bit reads from 16-bit variables where the upper 16 bits are</span>
<span class="p_del">-	  thrown away afterwards. This may of course also hide some real</span>
<span class="p_del">-	  bugs.</span>
<span class="p_del">-</span>
<span class="p_del">-config KMEMCHECK_BITOPS_OK</span>
<span class="p_del">-	bool &quot;kmemcheck: allow bit-field manipulation&quot;</span>
<span class="p_del">-	depends on KMEMCHECK</span>
<span class="p_del">-	default n</span>
<span class="p_del">-	help</span>
<span class="p_del">-	  This option silences warnings that would be generated for bit-field</span>
<span class="p_del">-	  accesses where not all the bits are initialized at the same time.</span>
<span class="p_del">-	  This may also hide some real bugs.</span>
<span class="p_del">-</span>
<span class="p_del">-endif</span>
<span class="p_header">--- a/mm/Kconfig.debug</span>
<span class="p_header">+++ b/mm/Kconfig.debug</span>
<span class="p_chunk">@@ -11,7 +11,6 @@</span> <span class="p_context"> config DEBUG_PAGEALLOC</span>
 	bool &quot;Debug page memory allocations&quot;
 	depends on DEBUG_KERNEL
 	depends on !HIBERNATION || ARCH_SUPPORTS_DEBUG_PAGEALLOC &amp;&amp; !PPC &amp;&amp; !SPARC
<span class="p_del">-	depends on !KMEMCHECK</span>
 	select PAGE_EXTENSION
 	select PAGE_POISONING if !ARCH_SUPPORTS_DEBUG_PAGEALLOC
 	---help---
<span class="p_header">--- a/mm/Makefile</span>
<span class="p_header">+++ b/mm/Makefile</span>
<span class="p_chunk">@@ -17,7 +17,6 @@</span> <span class="p_context"> KCOV_INSTRUMENT_slub.o := n</span>
 KCOV_INSTRUMENT_page_alloc.o := n
 KCOV_INSTRUMENT_debug-pagealloc.o := n
 KCOV_INSTRUMENT_kmemleak.o := n
<span class="p_del">-KCOV_INSTRUMENT_kmemcheck.o := n</span>
 KCOV_INSTRUMENT_memcontrol.o := n
 KCOV_INSTRUMENT_mmzone.o := n
 KCOV_INSTRUMENT_vmstat.o := n
<span class="p_chunk">@@ -70,7 +69,6 @@</span> <span class="p_context"> obj-$(CONFIG_KSM) += ksm.o</span>
 obj-$(CONFIG_PAGE_POISONING) += page_poison.o
 obj-$(CONFIG_SLAB) += slab.o
 obj-$(CONFIG_SLUB) += slub.o
<span class="p_del">-obj-$(CONFIG_KMEMCHECK) += kmemcheck.o</span>
 obj-$(CONFIG_KASAN)	+= kasan/
 obj-$(CONFIG_FAILSLAB) += failslab.o
 obj-$(CONFIG_MEMORY_HOTPLUG) += memory_hotplug.o
<span class="p_header">--- a/mm/kmemcheck.c</span>
<span class="p_header">+++ b/mm/kmemcheck.c</span>
<span class="p_chunk">@@ -1,126 +1 @@</span> <span class="p_context"></span>
 // SPDX-License-Identifier: GPL-2.0
<span class="p_del">-#include &lt;linux/gfp.h&gt;</span>
<span class="p_del">-#include &lt;linux/mm_types.h&gt;</span>
<span class="p_del">-#include &lt;linux/mm.h&gt;</span>
<span class="p_del">-#include &lt;linux/slab.h&gt;</span>
<span class="p_del">-#include &quot;slab.h&quot;</span>
<span class="p_del">-#include &lt;linux/kmemcheck.h&gt;</span>
<span class="p_del">-</span>
<span class="p_del">-void kmemcheck_alloc_shadow(struct page *page, int order, gfp_t flags, int node)</span>
<span class="p_del">-{</span>
<span class="p_del">-	struct page *shadow;</span>
<span class="p_del">-	int pages;</span>
<span class="p_del">-	int i;</span>
<span class="p_del">-</span>
<span class="p_del">-	pages = 1 &lt;&lt; order;</span>
<span class="p_del">-</span>
<span class="p_del">-	/*</span>
<span class="p_del">-	 * With kmemcheck enabled, we need to allocate a memory area for the</span>
<span class="p_del">-	 * shadow bits as well.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	shadow = alloc_pages_node(node, flags, order);</span>
<span class="p_del">-	if (!shadow) {</span>
<span class="p_del">-		if (printk_ratelimit())</span>
<span class="p_del">-			pr_err(&quot;kmemcheck: failed to allocate shadow bitmap\n&quot;);</span>
<span class="p_del">-		return;</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">-	for(i = 0; i &lt; pages; ++i)</span>
<span class="p_del">-		page[i].shadow = page_address(&amp;shadow[i]);</span>
<span class="p_del">-</span>
<span class="p_del">-	/*</span>
<span class="p_del">-	 * Mark it as non-present for the MMU so that our accesses to</span>
<span class="p_del">-	 * this memory will trigger a page fault and let us analyze</span>
<span class="p_del">-	 * the memory accesses.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	kmemcheck_hide_pages(page, pages);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-void kmemcheck_free_shadow(struct page *page, int order)</span>
<span class="p_del">-{</span>
<span class="p_del">-	struct page *shadow;</span>
<span class="p_del">-	int pages;</span>
<span class="p_del">-	int i;</span>
<span class="p_del">-</span>
<span class="p_del">-	if (!kmemcheck_page_is_tracked(page))</span>
<span class="p_del">-		return;</span>
<span class="p_del">-</span>
<span class="p_del">-	pages = 1 &lt;&lt; order;</span>
<span class="p_del">-</span>
<span class="p_del">-	kmemcheck_show_pages(page, pages);</span>
<span class="p_del">-</span>
<span class="p_del">-	shadow = virt_to_page(page[0].shadow);</span>
<span class="p_del">-</span>
<span class="p_del">-	for(i = 0; i &lt; pages; ++i)</span>
<span class="p_del">-		page[i].shadow = NULL;</span>
<span class="p_del">-</span>
<span class="p_del">-	__free_pages(shadow, order);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-void kmemcheck_slab_alloc(struct kmem_cache *s, gfp_t gfpflags, void *object,</span>
<span class="p_del">-			  size_t size)</span>
<span class="p_del">-{</span>
<span class="p_del">-	if (unlikely(!object)) /* Skip object if allocation failed */</span>
<span class="p_del">-		return;</span>
<span class="p_del">-</span>
<span class="p_del">-	/*</span>
<span class="p_del">-	 * Has already been memset(), which initializes the shadow for us</span>
<span class="p_del">-	 * as well.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	if (gfpflags &amp; __GFP_ZERO)</span>
<span class="p_del">-		return;</span>
<span class="p_del">-</span>
<span class="p_del">-	/* No need to initialize the shadow of a non-tracked slab. */</span>
<span class="p_del">-	if (s-&gt;flags &amp; SLAB_NOTRACK)</span>
<span class="p_del">-		return;</span>
<span class="p_del">-</span>
<span class="p_del">-	if (!kmemcheck_enabled || gfpflags &amp; __GFP_NOTRACK) {</span>
<span class="p_del">-		/*</span>
<span class="p_del">-		 * Allow notracked objects to be allocated from</span>
<span class="p_del">-		 * tracked caches. Note however that these objects</span>
<span class="p_del">-		 * will still get page faults on access, they just</span>
<span class="p_del">-		 * won&#39;t ever be flagged as uninitialized. If page</span>
<span class="p_del">-		 * faults are not acceptable, the slab cache itself</span>
<span class="p_del">-		 * should be marked NOTRACK.</span>
<span class="p_del">-		 */</span>
<span class="p_del">-		kmemcheck_mark_initialized(object, size);</span>
<span class="p_del">-	} else if (!s-&gt;ctor) {</span>
<span class="p_del">-		/*</span>
<span class="p_del">-		 * New objects should be marked uninitialized before</span>
<span class="p_del">-		 * they&#39;re returned to the called.</span>
<span class="p_del">-		 */</span>
<span class="p_del">-		kmemcheck_mark_uninitialized(object, size);</span>
<span class="p_del">-	}</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-void kmemcheck_slab_free(struct kmem_cache *s, void *object, size_t size)</span>
<span class="p_del">-{</span>
<span class="p_del">-	/* TODO: RCU freeing is unsupported for now; hide false positives. */</span>
<span class="p_del">-	if (!s-&gt;ctor &amp;&amp; !(s-&gt;flags &amp; SLAB_TYPESAFE_BY_RCU))</span>
<span class="p_del">-		kmemcheck_mark_freed(object, size);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-void kmemcheck_pagealloc_alloc(struct page *page, unsigned int order,</span>
<span class="p_del">-			       gfp_t gfpflags)</span>
<span class="p_del">-{</span>
<span class="p_del">-	int pages;</span>
<span class="p_del">-</span>
<span class="p_del">-	if (gfpflags &amp; (__GFP_HIGHMEM | __GFP_NOTRACK))</span>
<span class="p_del">-		return;</span>
<span class="p_del">-</span>
<span class="p_del">-	pages = 1 &lt;&lt; order;</span>
<span class="p_del">-</span>
<span class="p_del">-	/*</span>
<span class="p_del">-	 * NOTE: We choose to track GFP_ZERO pages too; in fact, they</span>
<span class="p_del">-	 * can become uninitialized by copying uninitialized memory</span>
<span class="p_del">-	 * into them.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-</span>
<span class="p_del">-	/* XXX: Can use zone-&gt;node for node? */</span>
<span class="p_del">-	kmemcheck_alloc_shadow(page, order, gfpflags, -1);</span>
<span class="p_del">-</span>
<span class="p_del">-	if (gfpflags &amp; __GFP_ZERO)</span>
<span class="p_del">-		kmemcheck_mark_initialized_pages(page, pages);</span>
<span class="p_del">-	else</span>
<span class="p_del">-		kmemcheck_mark_uninitialized_pages(page, pages);</span>
<span class="p_del">-}</span>
<span class="p_header">--- a/mm/slub.c</span>
<span class="p_header">+++ b/mm/slub.c</span>
<span class="p_chunk">@@ -1369,7 +1369,7 @@</span> <span class="p_context"> static inline void *slab_free_hook(struc</span>
 	 * So in order to make the debug calls that expect irqs to be
 	 * disabled we need to disable interrupts temporarily.
 	 */
<span class="p_del">-#if defined(CONFIG_KMEMCHECK) || defined(CONFIG_LOCKDEP)</span>
<span class="p_add">+#ifdef CONFIG_LOCKDEP</span>
 	{
 		unsigned long flags;
 
<span class="p_chunk">@@ -1397,8 +1397,7 @@</span> <span class="p_context"> static inline void slab_free_freelist_ho</span>
  * Compiler cannot detect this function can be removed if slab_free_hook()
  * evaluates to nothing.  Thus, catch all relevant config debug options here.
  */
<span class="p_del">-#if defined(CONFIG_KMEMCHECK) ||		\</span>
<span class="p_del">-	defined(CONFIG_LOCKDEP)	||		\</span>
<span class="p_add">+#if defined(CONFIG_LOCKDEP)	||		\</span>
 	defined(CONFIG_DEBUG_KMEMLEAK) ||	\
 	defined(CONFIG_DEBUG_OBJECTS_FREE) ||	\
 	defined(CONFIG_KASAN)
<span class="p_header">--- a/scripts/kernel-doc</span>
<span class="p_header">+++ b/scripts/kernel-doc</span>
<span class="p_chunk">@@ -2182,8 +2182,6 @@</span> <span class="p_context"> sub dump_struct($$) {</span>
 	# strip comments:
 	$members =~ s/\/\*.*?\*\///gos;
 	$nested =~ s/\/\*.*?\*\///gos;
<span class="p_del">-	# strip kmemcheck_bitfield_{begin,end}.*;</span>
<span class="p_del">-	$members =~ s/kmemcheck_bitfield_.*?;//gos;</span>
 	# strip attributes
 	$members =~ s/__attribute__\s*\(\([a-z,_\*\s\(\)]*\)\)//i;
 	$members =~ s/__aligned\s*\([^;]*\)//gos;
<span class="p_header">--- a/tools/include/linux/kmemcheck.h</span>
<span class="p_header">+++ b/tools/include/linux/kmemcheck.h</span>
<span class="p_chunk">@@ -1,9 +1 @@</span> <span class="p_context"></span>
 /* SPDX-License-Identifier: GPL-2.0 */
<span class="p_del">-#ifndef _LIBLOCKDEP_LINUX_KMEMCHECK_H_</span>
<span class="p_del">-#define _LIBLOCKDEP_LINUX_KMEMCHECK_H_</span>
<span class="p_del">-</span>
<span class="p_del">-static inline void kmemcheck_mark_initialized(void *address, unsigned int n)</span>
<span class="p_del">-{</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-#endif</span>

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



