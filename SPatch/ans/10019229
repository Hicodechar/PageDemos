
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>[v2,2/2] mm: rename page dtor functions to {compound,huge,transhuge}_page__dtor - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    [v2,2/2] mm: rename page dtor functions to {compound,huge,transhuge}_page__dtor</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=125281">Du, Changbin</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>Oct. 20, 2017, 8:36 a.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;1508488588-23539-3-git-send-email-changbin.du@intel.com&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/10019229/mbox/"
   >mbox</a>
|
   <a href="/patch/10019229/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/10019229/">/patch/10019229/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
	[172.30.200.125])
	by pdx-korg-patchwork.web.codeaurora.org (Postfix) with ESMTP id
	63D5F60211 for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Fri, 20 Oct 2017 08:44:42 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 4F68828647
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Fri, 20 Oct 2017 08:44:42 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id 4452C28EC0; Fri, 20 Oct 2017 08:44:42 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-6.9 required=2.0 tests=BAYES_00,RCVD_IN_DNSWL_HI
	autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 5636528647
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Fri, 20 Oct 2017 08:44:41 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1752652AbdJTIoi (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Fri, 20 Oct 2017 04:44:38 -0400
Received: from mga05.intel.com ([192.55.52.43]:65289 &quot;EHLO mga05.intel.com&quot;
	rhost-flags-OK-OK-OK-OK) by vger.kernel.org with ESMTP
	id S1752158AbdJTIoM (ORCPT &lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Fri, 20 Oct 2017 04:44:12 -0400
Received: from fmsmga005.fm.intel.com ([10.253.24.32])
	by fmsmga105.fm.intel.com with ESMTP; 20 Oct 2017 01:44:12 -0700
X-ExtLoop1: 1
X-IronPort-AV: E=Sophos;i=&quot;5.43,405,1503385200&quot;; d=&quot;scan&#39;208&quot;;a=&quot;164912362&quot;
Received: from gvt-dell.bj.intel.com (HELO gvt-dell-host.bj.intel.com)
	([10.238.154.59])
	by fmsmga005.fm.intel.com with ESMTP; 20 Oct 2017 01:44:10 -0700
From: changbin.du@intel.com
To: akpm@linux-foundation.org, corbet@lwn.net, hughd@google.com
Cc: linux-doc@vger.kernel.org, linux-kernel@vger.kernel.org,
	linux-mm@kvack.org, khandual@linux.vnet.ibm.com,
	kirill@shutemov.name, Changbin Du &lt;changbin.du@intel.com&gt;
Subject: [PATCH v2 2/2] mm: rename page dtor functions to {compound, huge,
	transhuge}_page__dtor
Date: Fri, 20 Oct 2017 16:36:28 +0800
Message-Id: &lt;1508488588-23539-3-git-send-email-changbin.du@intel.com&gt;
X-Mailer: git-send-email 2.7.4
In-Reply-To: &lt;1508488588-23539-1-git-send-email-changbin.du@intel.com&gt;
References: &lt;1508488588-23539-1-git-send-email-changbin.du@intel.com&gt;
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=125281">Du, Changbin</a> - Oct. 20, 2017, 8:36 a.m.</div>
<pre class="content">
<span class="from">From: Changbin Du &lt;changbin.du@intel.com&gt;</span>

The current name free_{huge,transhuge}_page are paired with
alloc_{huge,transhuge}_page functions, but the actual page free
function is still free_page() which will indirectly call
free_{huge,transhuge}_page.

So this patch removes this confusion by renaming all the
compound page dtors to {compound,huge,transhuge}_page__dtor.
And since we already have a typedef compound_page_dtor,
rename it to compound_page_dtor_t to avoid name conflict.
<span class="signed-off-by">
Signed-off-by: Changbin Du &lt;changbin.du@intel.com&gt;</span>

---
v2: Improve commit message.
---
 Documentation/vm/hugetlbfs_reserv.txt |  4 ++--
 include/linux/huge_mm.h               |  2 +-
 include/linux/hugetlb.h               |  2 +-
 include/linux/mm.h                    |  8 ++++----
 mm/huge_memory.c                      |  4 ++--
 mm/hugetlb.c                          | 14 +++++++-------
 mm/page_alloc.c                       | 10 +++++-----
 mm/swap.c                             |  2 +-
 mm/userfaultfd.c                      |  2 +-
 9 files changed, 24 insertions(+), 24 deletions(-)
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/Documentation/vm/hugetlbfs_reserv.txt b/Documentation/vm/hugetlbfs_reserv.txt</span>
<span class="p_header">index 9aca09a..b3ffa3e 100644</span>
<span class="p_header">--- a/Documentation/vm/hugetlbfs_reserv.txt</span>
<span class="p_header">+++ b/Documentation/vm/hugetlbfs_reserv.txt</span>
<span class="p_chunk">@@ -238,7 +238,7 @@</span> <span class="p_context"> to the global reservation count (resv_huge_pages).</span>
 
 Freeing Huge Pages
 ------------------
<span class="p_del">-Huge page freeing is performed by the routine free_huge_page().  This routine</span>
<span class="p_add">+Huge page freeing is performed by the routine huge_page_dtor().  This routine</span>
 is the destructor for hugetlbfs compound pages.  As a result, it is only
 passed a pointer to the page struct.  When a huge page is freed, reservation
 accounting may need to be performed.  This would be the case if the page was
<span class="p_chunk">@@ -468,7 +468,7 @@</span> <span class="p_context"> However, there are several instances where errors are encountered after a huge</span>
 page is allocated but before it is instantiated.  In this case, the page
 allocation has consumed the reservation and made the appropriate subpool,
 reservation map and global count adjustments.  If the page is freed at this
<span class="p_del">-time (before instantiation and clearing of PagePrivate), then free_huge_page</span>
<span class="p_add">+time (before instantiation and clearing of PagePrivate), then huge_page_dtor</span>
 will increment the global reservation count.  However, the reservation map
 indicates the reservation was consumed.  This resulting inconsistent state
 will cause the &#39;leak&#39; of a reserved huge page.  The global reserve count will
<span class="p_header">diff --git a/include/linux/huge_mm.h b/include/linux/huge_mm.h</span>
<span class="p_header">index 184eb38..bd05bc7 100644</span>
<span class="p_header">--- a/include/linux/huge_mm.h</span>
<span class="p_header">+++ b/include/linux/huge_mm.h</span>
<span class="p_chunk">@@ -130,7 +130,7 @@</span> <span class="p_context"> extern unsigned long thp_get_unmapped_area(struct file *filp,</span>
 		unsigned long addr, unsigned long len, unsigned long pgoff,
 		unsigned long flags);
 
<span class="p_del">-extern void free_transhuge_page(struct page *page);</span>
<span class="p_add">+extern void transhuge_page_dtor(struct page *page);</span>
 
 extern struct page *alloc_transhuge_page_vma(gfp_t gfp_mask,
 		struct vm_area_struct *vma, unsigned long addr);
<span class="p_header">diff --git a/include/linux/hugetlb.h b/include/linux/hugetlb.h</span>
<span class="p_header">index 8bbbd37..24492c5 100644</span>
<span class="p_header">--- a/include/linux/hugetlb.h</span>
<span class="p_header">+++ b/include/linux/hugetlb.h</span>
<span class="p_chunk">@@ -118,7 +118,7 @@</span> <span class="p_context"> long hugetlb_unreserve_pages(struct inode *inode, long start, long end,</span>
 						long freed);
 bool isolate_huge_page(struct page *page, struct list_head *list);
 void putback_active_hugepage(struct page *page);
<span class="p_del">-void free_huge_page(struct page *page);</span>
<span class="p_add">+void huge_page_dtor(struct page *page);</span>
 void hugetlb_fix_reserve_counts(struct inode *inode);
 extern struct mutex *hugetlb_fault_mutex_table;
 u32 hugetlb_fault_mutex_hash(struct hstate *h, struct mm_struct *mm,
<span class="p_header">diff --git a/include/linux/mm.h b/include/linux/mm.h</span>
<span class="p_header">index 065d99d..adfa906 100644</span>
<span class="p_header">--- a/include/linux/mm.h</span>
<span class="p_header">+++ b/include/linux/mm.h</span>
<span class="p_chunk">@@ -616,7 +616,7 @@</span> <span class="p_context"> void split_page(struct page *page, unsigned int order);</span>
  * prototype for that function and accessor functions.
  * These are _only_ valid on the head of a compound page.
  */
<span class="p_del">-typedef void compound_page_dtor(struct page *);</span>
<span class="p_add">+typedef void compound_page_dtor_t(struct page *);</span>
 
 /* Keep the enum in sync with compound_page_dtors array in mm/page_alloc.c */
 enum compound_dtor_id {
<span class="p_chunk">@@ -630,7 +630,7 @@</span> <span class="p_context"> enum compound_dtor_id {</span>
 #endif
 	NR_COMPOUND_DTORS,
 };
<span class="p_del">-extern compound_page_dtor * const compound_page_dtors[];</span>
<span class="p_add">+extern compound_page_dtor_t * const compound_page_dtors[];</span>
 
 static inline void set_compound_page_dtor(struct page *page,
 		enum compound_dtor_id compound_dtor)
<span class="p_chunk">@@ -639,7 +639,7 @@</span> <span class="p_context"> static inline void set_compound_page_dtor(struct page *page,</span>
 	page[1].compound_dtor = compound_dtor;
 }
 
<span class="p_del">-static inline compound_page_dtor *get_compound_page_dtor(struct page *page)</span>
<span class="p_add">+static inline compound_page_dtor_t *get_compound_page_dtor(struct page *page)</span>
 {
 	VM_BUG_ON_PAGE(page[1].compound_dtor &gt;= NR_COMPOUND_DTORS, page);
 	return compound_page_dtors[page[1].compound_dtor];
<span class="p_chunk">@@ -657,7 +657,7 @@</span> <span class="p_context"> static inline void set_compound_order(struct page *page, unsigned int order)</span>
 	page[1].compound_order = order;
 }
 
<span class="p_del">-void free_compound_page(struct page *page);</span>
<span class="p_add">+void compound_page_dtor(struct page *page);</span>
 
 #ifdef CONFIG_MMU
 /*
<span class="p_header">diff --git a/mm/huge_memory.c b/mm/huge_memory.c</span>
<span class="p_header">index 2a960fc..692ea1e 100644</span>
<span class="p_header">--- a/mm/huge_memory.c</span>
<span class="p_header">+++ b/mm/huge_memory.c</span>
<span class="p_chunk">@@ -2715,7 +2715,7 @@</span> <span class="p_context"> fail:		if (mapping)</span>
 	return ret;
 }
 
<span class="p_del">-void free_transhuge_page(struct page *page)</span>
<span class="p_add">+void transhuge_page_dtor(struct page *page)</span>
 {
 	struct pglist_data *pgdata = NODE_DATA(page_to_nid(page));
 	unsigned long flags;
<span class="p_chunk">@@ -2726,7 +2726,7 @@</span> <span class="p_context"> void free_transhuge_page(struct page *page)</span>
 		list_del(page_deferred_list(page));
 	}
 	spin_unlock_irqrestore(&amp;pgdata-&gt;split_queue_lock, flags);
<span class="p_del">-	free_compound_page(page);</span>
<span class="p_add">+	compound_page_dtor(page);</span>
 }
 
 void deferred_split_huge_page(struct page *page)
<span class="p_header">diff --git a/mm/hugetlb.c b/mm/hugetlb.c</span>
<span class="p_header">index 424b0ef..1af2c4e7 100644</span>
<span class="p_header">--- a/mm/hugetlb.c</span>
<span class="p_header">+++ b/mm/hugetlb.c</span>
<span class="p_chunk">@@ -1250,7 +1250,7 @@</span> <span class="p_context"> static void clear_page_huge_active(struct page *page)</span>
 	ClearPagePrivate(&amp;page[1]);
 }
 
<span class="p_del">-void free_huge_page(struct page *page)</span>
<span class="p_add">+void huge_page_dtor(struct page *page)</span>
 {
 	/*
 	 * Can&#39;t pass hstate in here because it is called from the
<span class="p_chunk">@@ -1363,7 +1363,7 @@</span> <span class="p_context"> int PageHeadHuge(struct page *page_head)</span>
 	if (!PageHead(page_head))
 		return 0;
 
<span class="p_del">-	return get_compound_page_dtor(page_head) == free_huge_page;</span>
<span class="p_add">+	return get_compound_page_dtor(page_head) == huge_page_dtor;</span>
 }
 
 pgoff_t __basepage_index(struct page *page)
<span class="p_chunk">@@ -1932,11 +1932,11 @@</span> <span class="p_context"> static long vma_add_reservation(struct hstate *h,</span>
  * specific error paths, a huge page was allocated (via alloc_huge_page)
  * and is about to be freed.  If a reservation for the page existed,
  * alloc_huge_page would have consumed the reservation and set PagePrivate
<span class="p_del">- * in the newly allocated page.  When the page is freed via free_huge_page,</span>
<span class="p_add">+ * in the newly allocated page.  When the page is freed via huge_page_dtor,</span>
  * the global reservation count will be incremented if PagePrivate is set.
<span class="p_del">- * However, free_huge_page can not adjust the reserve map.  Adjust the</span>
<span class="p_add">+ * However, huge_page_dtor can not adjust the reserve map.  Adjust the</span>
  * reserve map here to be consistent with global reserve count adjustments
<span class="p_del">- * to be made by free_huge_page.</span>
<span class="p_add">+ * to be made by huge_page_dtor.</span>
  */
 static void restore_reserve_on_error(struct hstate *h,
 			struct vm_area_struct *vma, unsigned long address,
<span class="p_chunk">@@ -1950,7 +1950,7 @@</span> <span class="p_context"> static void restore_reserve_on_error(struct hstate *h,</span>
 			 * Rare out of memory condition in reserve map
 			 * manipulation.  Clear PagePrivate so that
 			 * global reserve count will not be incremented
<span class="p_del">-			 * by free_huge_page.  This will make it appear</span>
<span class="p_add">+			 * by huge_page_dtor.  This will make it appear</span>
 			 * as though the reservation for this page was
 			 * consumed.  This may prevent the task from
 			 * faulting in the page at a later time.  This
<span class="p_chunk">@@ -2304,7 +2304,7 @@</span> <span class="p_context"> static unsigned long set_max_huge_pages(struct hstate *h, unsigned long count,</span>
 	while (count &gt; persistent_huge_pages(h)) {
 		/*
 		 * If this allocation races such that we no longer need the
<span class="p_del">-		 * page, free_huge_page will handle it by freeing the page</span>
<span class="p_add">+		 * page, huge_page_dtor will handle it by freeing the page</span>
 		 * and reducing the surplus.
 		 */
 		spin_unlock(&amp;hugetlb_lock);
<span class="p_header">diff --git a/mm/page_alloc.c b/mm/page_alloc.c</span>
<span class="p_header">index 77e4d3c..b31205c 100644</span>
<span class="p_header">--- a/mm/page_alloc.c</span>
<span class="p_header">+++ b/mm/page_alloc.c</span>
<span class="p_chunk">@@ -248,14 +248,14 @@</span> <span class="p_context"> char * const migratetype_names[MIGRATE_TYPES] = {</span>
 #endif
 };
 
<span class="p_del">-compound_page_dtor * const compound_page_dtors[] = {</span>
<span class="p_add">+compound_page_dtor_t * const compound_page_dtors[] = {</span>
 	NULL,
<span class="p_del">-	free_compound_page,</span>
<span class="p_add">+	compound_page_dtor,</span>
 #ifdef CONFIG_HUGETLB_PAGE
<span class="p_del">-	free_huge_page,</span>
<span class="p_add">+	huge_page_dtor,</span>
 #endif
 #ifdef CONFIG_TRANSPARENT_HUGEPAGE
<span class="p_del">-	free_transhuge_page,</span>
<span class="p_add">+	transhuge_page_dtor,</span>
 #endif
 };
 
<span class="p_chunk">@@ -586,7 +586,7 @@</span> <span class="p_context"> static void bad_page(struct page *page, const char *reason,</span>
  * This usage means that zero-order pages may not be compound.
  */
 
<span class="p_del">-void free_compound_page(struct page *page)</span>
<span class="p_add">+void compound_page_dtor(struct page *page)</span>
 {
 	__free_pages_ok(page, compound_order(page));
 }
<span class="p_header">diff --git a/mm/swap.c b/mm/swap.c</span>
<span class="p_header">index a77d68f..8f98caf 100644</span>
<span class="p_header">--- a/mm/swap.c</span>
<span class="p_header">+++ b/mm/swap.c</span>
<span class="p_chunk">@@ -81,7 +81,7 @@</span> <span class="p_context"> static void __put_single_page(struct page *page)</span>
 
 static void __put_compound_page(struct page *page)
 {
<span class="p_del">-	compound_page_dtor *dtor;</span>
<span class="p_add">+	compound_page_dtor_t *dtor;</span>
 
 	/*
 	 * __page_cache_release() is supposed to be called for thp, not for
<span class="p_header">diff --git a/mm/userfaultfd.c b/mm/userfaultfd.c</span>
<span class="p_header">index 8119270..91d9045 100644</span>
<span class="p_header">--- a/mm/userfaultfd.c</span>
<span class="p_header">+++ b/mm/userfaultfd.c</span>
<span class="p_chunk">@@ -323,7 +323,7 @@</span> <span class="p_context"> static __always_inline ssize_t __mcopy_atomic_hugetlb(struct mm_struct *dst_mm,</span>
 		 * map of a private mapping, the map was modified to indicate
 		 * the reservation was consumed when the page was allocated.
 		 * We clear the PagePrivate flag now so that the global
<span class="p_del">-		 * reserve count will not be incremented in free_huge_page.</span>
<span class="p_add">+		 * reserve count will not be incremented in huge_page_dtor.</span>
 		 * The reservation map will still indicate the reservation
 		 * was consumed and possibly prevent later page allocation.
 		 * This is better than leaking a global reservation.  If no

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



