
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>x86/mm/kaiser: Flush the correct ASID in __native_flush_tlb_single() - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    x86/mm/kaiser: Flush the correct ASID in __native_flush_tlb_single()</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=137">Peter Zijlstra</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>Nov. 29, 2017, 2:35 p.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;20171129143526.GP3326@worktop&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/10082461/mbox/"
   >mbox</a>
|
   <a href="/patch/10082461/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/10082461/">/patch/10082461/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
	[172.30.200.125])
	by pdx-korg-patchwork.web.codeaurora.org (Postfix) with ESMTP id
	E54D76020B for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Wed, 29 Nov 2017 14:35:52 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id D33FD298CC
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Wed, 29 Nov 2017 14:35:52 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id C6EFE2990F; Wed, 29 Nov 2017 14:35:52 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-6.8 required=2.0 tests=BAYES_00,DKIM_SIGNED,
	RCVD_IN_DNSWL_HI,T_DKIM_INVALID autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 34367298CC
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Wed, 29 Nov 2017 14:35:52 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1754181AbdK2Ofq (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Wed, 29 Nov 2017 09:35:46 -0500
Received: from merlin.infradead.org ([205.233.59.134]:42280 &quot;EHLO
	merlin.infradead.org&quot; rhost-flags-OK-OK-OK-OK) by vger.kernel.org
	with ESMTP id S1752025AbdK2Ofp (ORCPT
	&lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Wed, 29 Nov 2017 09:35:45 -0500
DKIM-Signature: v=1; a=rsa-sha256; q=dns/txt; c=relaxed/relaxed;
	d=infradead.org; s=merlin.20170209;
	h=In-Reply-To:Content-Type:MIME-Version:
	References:Message-ID:Subject:Cc:To:From:Date:Sender:Reply-To:
	Content-Transfer-Encoding:Content-ID:Content-Description:Resent-Date:
	Resent-From:Resent-Sender:Resent-To:Resent-Cc:Resent-Message-ID:List-Id:
	List-Help:List-Unsubscribe:List-Subscribe:List-Post:List-Owner:List-Archive;
	bh=a1EkJCR+GB2sIqF7Q+9TRaxrGFxpnBQ1Tf/RRgZ01lk=;
	b=xxpiln5CPFBoutqM2QcN8nx7N
	hEZdsqYuMdnJiBdP1DGokyfY9kHDzg7m9LEGYeSSHes1426zpIxMAGXw3fHOiXAKg44m4WFC+oo/L
	z3tzam0HSxxi3uHpzvvM5RysDiov3H6WeNwdDiURxcoRc1ruNnnk0E2EevoGfwjWHrV4+UVGs0lKF
	dAFhxTVwe/WzcbSMlmEg5dzNcyrYpifFDIN19fY39x4wXeNch0nOBYUKdH85zbWgH0Jfn8KayXLua
	8WNAL0IgwmbD6vVFTfk9/IWqctrvGqNznLjlM/d2hau4E592svItwA8/hIIt3+Yt1YK6GXEfywKHU
	4KmeVALYQ==;
Received: from [188.203.160.170] (helo=worktop)
	by merlin.infradead.org with esmtpsa (Exim 4.87 #1 (Red Hat Linux))
	id 1eK3SU-0000Km-J4; Wed, 29 Nov 2017 14:35:30 +0000
Received: by worktop (Postfix, from userid 1000)
	id A70AE6E082E; Wed, 29 Nov 2017 15:35:26 +0100 (CET)
Date: Wed, 29 Nov 2017 15:35:26 +0100
From: Peter Zijlstra &lt;peterz@infradead.org&gt;
To: Dave Hansen &lt;dave.hansen@linux.intel.com&gt;
Cc: linux-kernel@vger.kernel.org, linux-mm@kvack.org,
	tglx@linutronix.de, richard.fellner@student.tugraz.at,
	moritz.lipp@iaik.tugraz.at, daniel.gruss@iaik.tugraz.at,
	michael.schwarz@iaik.tugraz.at, luto@kernel.org,
	torvalds@linux-foundation.org, keescook@google.com,
	hughd@google.com, bp@alien8.de, x86@kernel.org
Subject: Re: [PATCH] x86/mm/kaiser: Flush the correct ASID in
	__native_flush_tlb_single()
Message-ID: &lt;20171129143526.GP3326@worktop&gt;
References: &lt;20171128095531.F32E1BC7@viggo.jf.intel.com&gt;
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Disposition: inline
In-Reply-To: &lt;20171128095531.F32E1BC7@viggo.jf.intel.com&gt;
User-Agent: Mutt/1.5.22.1 (2013-10-16)
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=137">Peter Zijlstra</a> - Nov. 29, 2017, 2:35 p.m.</div>
<pre class="content">
On Tue, Nov 28, 2017 at 01:55:31AM -0800, Dave Hansen wrote:
<span class="quote">&gt;  static inline void __native_flush_tlb_single(unsigned long addr)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt; +	u16 loaded_mm_asid = this_cpu_read(cpu_tlbstate.loaded_mm_asid);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	/*</span>
<span class="quote">&gt; +	 * Handle systems that do not support PCIDs.  This will also</span>
<span class="quote">&gt; +	 * get used in cases where this is called before PCID detection</span>
<span class="quote">&gt; +	 * is done.</span>
<span class="quote">&gt;  	 */</span>
<span class="quote">&gt;  	if (!this_cpu_has(X86_FEATURE_INVPCID_SINGLE)) {</span>
<span class="quote">&gt; +		__invlpg(addr);</span>
<span class="quote">&gt;  		return;</span>
<span class="quote">&gt;  	}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	/*</span>
<span class="quote">&gt; +	 * An &quot;invalid&quot; loaded_mm_asid means that we have not</span>
<span class="quote">&gt; +	 * initialized &#39;cpu_tlbstate&#39; and are not using PCIDs.</span>
<span class="quote">&gt; +	 * Just flush the TLB as if PCIDs were not present.</span>
<span class="quote">&gt; +	 */</span>
<span class="quote">&gt; +	if (loaded_mm_asid == INVALID_HW_ASID) {</span>
<span class="quote">&gt; +		__invlpg(addr);</span>
<span class="quote">&gt; +		return;</span>
<span class="quote">&gt; +	}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt;  	/* Flush the address out of both PCIDs. */</span>
<span class="quote">&gt;  	/*</span>
<span class="quote">&gt;  	 * An optimization here might be to determine addresses</span>
<span class="quote">&gt; @@ -451,6 +474,9 @@ static inline void __native_flush_tlb_si</span>
<span class="quote">&gt;  	if (kern_asid(loaded_mm_asid) != user_asid(loaded_mm_asid))</span>
<span class="quote">&gt;  		invpcid_flush_one(user_asid(loaded_mm_asid), addr);</span>
<span class="quote">&gt;  	invpcid_flush_one(kern_asid(loaded_mm_asid), addr);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	/* Check that we are flushing the active ASID: */</span>
<span class="quote">&gt; +	VM_WARN_ON_ONCE(kern_asid(loaded_mm_asid) != cr3_asid());</span>
<span class="quote">&gt;  }</span>

Can&#39;t we do this differently (after my recent patches)? It appears to me
we can unconditionally do INVLPG to shoot down the kernel mapping, and
then, depending on INVPCID support we can either use that to shoot down
a single page or simply invalidate the entire user mapping.

---
 arch/x86/include/asm/tlbflush.h | 23 +++++++----------------
 1 file changed, 7 insertions(+), 16 deletions(-)
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=64071">Dave Hansen</a> - Nov. 29, 2017, 3:21 p.m.</div>
<pre class="content">
On 11/29/2017 06:35 AM, Peter Zijlstra wrote:
<span class="quote">&gt;&gt; @@ -451,6 +474,9 @@ static inline void __native_flush_tlb_si</span>
<span class="quote">&gt;&gt;  	if (kern_asid(loaded_mm_asid) != user_asid(loaded_mm_asid))</span>
<span class="quote">&gt;&gt;  		invpcid_flush_one(user_asid(loaded_mm_asid), addr);</span>
<span class="quote">&gt;&gt;  	invpcid_flush_one(kern_asid(loaded_mm_asid), addr);</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +	/* Check that we are flushing the active ASID: */</span>
<span class="quote">&gt;&gt; +	VM_WARN_ON_ONCE(kern_asid(loaded_mm_asid) != cr3_asid());</span>
<span class="quote">&gt;&gt;  }</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Can&#39;t we do this differently (after my recent patches)? It appears to me</span>
<span class="quote">&gt; we can unconditionally do INVLPG to shoot down the kernel mapping, and</span>
<span class="quote">&gt; then, depending on INVPCID support we can either use that to shoot down</span>
<span class="quote">&gt; a single page or simply invalidate the entire user mapping.</span>

Yes, that works.  Also, as I think about it, INVLPG is a safer
(bug-resistant) instruction to use too.  INVPCID _can_ get the current
(kernel) ASID wrong, as we saw.  But INVLPG always uses the current one
and can&#39;t be wrong about flushing the *current* ASID.

I think Andy measured it to be faster than INVPCID too.

So, maybe we should just remove INVPCID&#39;s use entirely.
<span class="quote">
&gt;  arch/x86/include/asm/tlbflush.h | 23 +++++++----------------</span>
<span class="quote">&gt;  1 file changed, 7 insertions(+), 16 deletions(-)</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; diff --git a/arch/x86/include/asm/tlbflush.h b/arch/x86/include/asm/tlbflush.h</span>
<span class="quote">&gt; index 481d5094559e..9587722162ee 100644</span>
<span class="quote">&gt; --- a/arch/x86/include/asm/tlbflush.h</span>
<span class="quote">&gt; +++ b/arch/x86/include/asm/tlbflush.h</span>
<span class="quote">&gt; @@ -438,29 +438,20 @@ static inline void __native_flush_tlb_single(unsigned long addr)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	u32 loaded_mm_asid = this_cpu_read(cpu_tlbstate.loaded_mm_asid);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; +	asm volatile(&quot;invlpg (%0)&quot; ::&quot;r&quot; (addr) : &quot;memory&quot;);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	if (!kaiser_enabled)</span>
<span class="quote">&gt; +		return;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt;  	/*</span>
<span class="quote">&gt;  	 * Some platforms #GP if we call invpcid(type=1/2) before</span>
<span class="quote">&gt;  	 * CR4.PCIDE=1.  Just call invpcid in the case we are called</span>
<span class="quote">&gt;  	 * early.</span>
<span class="quote">&gt;  	 */</span>
<span class="quote">&gt; -	if (!this_cpu_has(X86_FEATURE_INVPCID_SINGLE)) {</span>
<span class="quote">&gt; +	if (!this_cpu_has(X86_FEATURE_INVPCID_SINGLE))</span>
<span class="quote">&gt;  		flush_user_asid(loaded_mm_asid);</span>
<span class="quote">&gt; -		asm volatile(&quot;invlpg (%0)&quot; ::&quot;r&quot; (addr) : &quot;memory&quot;);</span>
<span class="quote">&gt; -		return;</span>
<span class="quote">&gt; -	}</span>
<span class="quote">&gt; -	/* Flush the address out of both PCIDs. */</span>
<span class="quote">&gt; -	/*</span>
<span class="quote">&gt; -	 * An optimization here might be to determine addresses</span>
<span class="quote">&gt; -	 * that are only kernel-mapped and only flush the kernel</span>
<span class="quote">&gt; -	 * ASID.  But, userspace flushes are probably much more</span>
<span class="quote">&gt; -	 * important performance-wise.</span>
<span class="quote">&gt; -	 *</span>
<span class="quote">&gt; -	 * Make sure to do only a single invpcid when KAISER is</span>
<span class="quote">&gt; -	 * disabled and we have only a single ASID.</span>
<span class="quote">&gt; -	 */</span>
<span class="quote">&gt; -	if (kern_asid(loaded_mm_asid) != user_asid(loaded_mm_asid))</span>
<span class="quote">&gt; +	else</span>
<span class="quote">&gt;  		invpcid_flush_one(user_asid(loaded_mm_asid), addr);</span>
<span class="quote">&gt; -	invpcid_flush_one(kern_asid(loaded_mm_asid), addr);</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  static inline void __flush_tlb_all(void)</span>
<span class="quote">&gt;</span>
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=137">Peter Zijlstra</a> - Nov. 29, 2017, 3:26 p.m.</div>
<pre class="content">
On Wed, Nov 29, 2017 at 07:21:23AM -0800, Dave Hansen wrote:
<span class="quote">&gt; Yes, that works.  Also, as I think about it, INVLPG is a safer</span>
<span class="quote">&gt; (bug-resistant) instruction to use too.  INVPCID _can_ get the current</span>
<span class="quote">&gt; (kernel) ASID wrong, as we saw.  But INVLPG always uses the current one</span>
<span class="quote">&gt; and can&#39;t be wrong about flushing the *current* ASID.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; I think Andy measured it to be faster than INVPCID too.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; So, maybe we should just remove INVPCID&#39;s use entirely.</span>

With my patches the below invpcid_flush_one() is the only remaining user
(not counting flush_tlb_global).

I know Andy hates on INVPCID, but I could not convince myself that doing
a full user invalidate makes sense for flush_tlb_single(), then again
maybe it does, the patch is trivial after this.
<span class="quote">
&gt; &gt;  arch/x86/include/asm/tlbflush.h | 23 +++++++----------------</span>
<span class="quote">&gt; &gt;  1 file changed, 7 insertions(+), 16 deletions(-)</span>
<span class="quote">&gt; &gt; </span>
<span class="quote">&gt; &gt; diff --git a/arch/x86/include/asm/tlbflush.h b/arch/x86/include/asm/tlbflush.h</span>
<span class="quote">&gt; &gt; index 481d5094559e..9587722162ee 100644</span>
<span class="quote">&gt; &gt; --- a/arch/x86/include/asm/tlbflush.h</span>
<span class="quote">&gt; &gt; +++ b/arch/x86/include/asm/tlbflush.h</span>
<span class="quote">&gt; &gt; @@ -438,29 +438,20 @@ static inline void __native_flush_tlb_single(unsigned long addr)</span>
<span class="quote">&gt; &gt;  {</span>
<span class="quote">&gt; &gt;  	u32 loaded_mm_asid = this_cpu_read(cpu_tlbstate.loaded_mm_asid);</span>
<span class="quote">&gt; &gt;  </span>
<span class="quote">&gt; &gt; +	asm volatile(&quot;invlpg (%0)&quot; ::&quot;r&quot; (addr) : &quot;memory&quot;);</span>
<span class="quote">&gt; &gt; +</span>
<span class="quote">&gt; &gt; +	if (!kaiser_enabled)</span>
<span class="quote">&gt; &gt; +		return;</span>
<span class="quote">&gt; &gt; +</span>
<span class="quote">&gt; &gt;  	/*</span>
<span class="quote">&gt; &gt;  	 * Some platforms #GP if we call invpcid(type=1/2) before</span>
<span class="quote">&gt; &gt;  	 * CR4.PCIDE=1.  Just call invpcid in the case we are called</span>
<span class="quote">&gt; &gt;  	 * early.</span>
<span class="quote">&gt; &gt;  	 */</span>
<span class="quote">&gt; &gt; +	if (!this_cpu_has(X86_FEATURE_INVPCID_SINGLE))</span>
<span class="quote">&gt; &gt;  		flush_user_asid(loaded_mm_asid);</span>
<span class="quote">&gt; &gt; +	else</span>
<span class="quote">&gt; &gt;  		invpcid_flush_one(user_asid(loaded_mm_asid), addr);</span>
<span class="quote">&gt; &gt;  }</span>
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/arch/x86/include/asm/tlbflush.h b/arch/x86/include/asm/tlbflush.h</span>
<span class="p_header">index 481d5094559e..9587722162ee 100644</span>
<span class="p_header">--- a/arch/x86/include/asm/tlbflush.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/tlbflush.h</span>
<span class="p_chunk">@@ -438,29 +438,20 @@</span> <span class="p_context"> static inline void __native_flush_tlb_single(unsigned long addr)</span>
 {
 	u32 loaded_mm_asid = this_cpu_read(cpu_tlbstate.loaded_mm_asid);
 
<span class="p_add">+	asm volatile(&quot;invlpg (%0)&quot; ::&quot;r&quot; (addr) : &quot;memory&quot;);</span>
<span class="p_add">+</span>
<span class="p_add">+	if (!kaiser_enabled)</span>
<span class="p_add">+		return;</span>
<span class="p_add">+</span>
 	/*
 	 * Some platforms #GP if we call invpcid(type=1/2) before
 	 * CR4.PCIDE=1.  Just call invpcid in the case we are called
 	 * early.
 	 */
<span class="p_del">-	if (!this_cpu_has(X86_FEATURE_INVPCID_SINGLE)) {</span>
<span class="p_add">+	if (!this_cpu_has(X86_FEATURE_INVPCID_SINGLE))</span>
 		flush_user_asid(loaded_mm_asid);
<span class="p_del">-		asm volatile(&quot;invlpg (%0)&quot; ::&quot;r&quot; (addr) : &quot;memory&quot;);</span>
<span class="p_del">-		return;</span>
<span class="p_del">-	}</span>
<span class="p_del">-	/* Flush the address out of both PCIDs. */</span>
<span class="p_del">-	/*</span>
<span class="p_del">-	 * An optimization here might be to determine addresses</span>
<span class="p_del">-	 * that are only kernel-mapped and only flush the kernel</span>
<span class="p_del">-	 * ASID.  But, userspace flushes are probably much more</span>
<span class="p_del">-	 * important performance-wise.</span>
<span class="p_del">-	 *</span>
<span class="p_del">-	 * Make sure to do only a single invpcid when KAISER is</span>
<span class="p_del">-	 * disabled and we have only a single ASID.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	if (kern_asid(loaded_mm_asid) != user_asid(loaded_mm_asid))</span>
<span class="p_add">+	else</span>
 		invpcid_flush_one(user_asid(loaded_mm_asid), addr);
<span class="p_del">-	invpcid_flush_one(kern_asid(loaded_mm_asid), addr);</span>
 }
 
 static inline void __flush_tlb_all(void)

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



