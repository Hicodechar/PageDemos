
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>[3.19.y-ckt,stable] Linux 3.19.8-ckt7 - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    [3.19.y-ckt,stable] Linux 3.19.8-ckt7</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=7718">Kamal Mostafa</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>Sept. 25, 2015, 2:56 p.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;1443193011-9288-2-git-send-email-kamal@canonical.com&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/7265761/mbox/"
   >mbox</a>
|
   <a href="/patch/7265761/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/7265761/">/patch/7265761/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
X-Original-To: patchwork-LKML@patchwork.kernel.org
Delivered-To: patchwork-parsemail@patchwork2.web.kernel.org
Received: from mail.kernel.org (mail.kernel.org [198.145.29.136])
	by patchwork2.web.kernel.org (Postfix) with ESMTP id E297FBEEC1
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Fri, 25 Sep 2015 14:58:11 +0000 (UTC)
Received: from mail.kernel.org (localhost [127.0.0.1])
	by mail.kernel.org (Postfix) with ESMTP id 87C4720A3F
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Fri, 25 Sep 2015 14:58:04 +0000 (UTC)
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.kernel.org (Postfix) with ESMTP id 90D6520B58
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Fri, 25 Sep 2015 14:57:55 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S932385AbbIYO5l (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Fri, 25 Sep 2015 10:57:41 -0400
Received: from youngberry.canonical.com ([91.189.89.112]:47881 &quot;EHLO
	youngberry.canonical.com&quot; rhost-flags-OK-OK-OK-OK) by vger.kernel.org
	with ESMTP id S1756029AbbIYO45 (ORCPT
	&lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Fri, 25 Sep 2015 10:56:57 -0400
Received: from 1.general.kamal.us.vpn ([10.172.68.52] helo=fourier)
	by youngberry.canonical.com with esmtpsa
	(TLS1.0:DHE_RSA_AES_128_CBC_SHA1:16) (Exim 4.76)
	(envelope-from &lt;kamal@canonical.com&gt;)
	id 1ZfUQh-000853-5R; Fri, 25 Sep 2015 14:56:56 +0000
Received: from kamal by fourier with local (Exim 4.82)
	(envelope-from &lt;kamal@whence.com&gt;)
	id 1ZfUQe-0002Qd-VM; Fri, 25 Sep 2015 07:56:52 -0700
From: Kamal Mostafa &lt;kamal@canonical.com&gt;
To: linux-kernel@vger.kernel.org, stable@vger.kernel.org,
	kernel-team@lists.ubuntu.com
Cc: lwn@lwn.net
Subject: Re: [3.19.y-ckt stable] Linux 3.19.8-ckt7
Date: Fri, 25 Sep 2015 07:56:51 -0700
Message-Id: &lt;1443193011-9288-2-git-send-email-kamal@canonical.com&gt;
X-Mailer: git-send-email 1.9.1
In-Reply-To: &lt;1443193011-9288-1-git-send-email-kamal@canonical.com&gt;
References: &lt;1443193011-9288-1-git-send-email-kamal@canonical.com&gt;
X-Extended-Stable: 3.19
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Spam-Status: No, score=-6.9 required=5.0 tests=BAYES_00, RCVD_IN_DNSWL_HI, 
	RP_MATCHES_RCVD,
	UNPARSEABLE_RELAY autolearn=unavailable version=3.3.1
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on mail.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=7718">Kamal Mostafa</a> - Sept. 25, 2015, 2:56 p.m.</div>
<pre class="content">
--
To unsubscribe from this list: send the line &quot;unsubscribe linux-kernel&quot; in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
Please read the FAQ at  http://www.tux.org/lkml/
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/Makefile b/Makefile</span>
<span class="p_header">index 535f2bd..57fe105 100644</span>
<span class="p_header">--- a/Makefile</span>
<span class="p_header">+++ b/Makefile</span>
<span class="p_chunk">@@ -1,7 +1,7 @@</span> <span class="p_context"></span>
 VERSION = 3
 PATCHLEVEL = 19
 SUBLEVEL = 8
<span class="p_del">-EXTRAVERSION = -ckt6</span>
<span class="p_add">+EXTRAVERSION = -ckt7</span>
 NAME = Sedated Swine
 
 # *DOCUMENTATION*
<span class="p_header">diff --git a/arch/arm64/kvm/inject_fault.c b/arch/arm64/kvm/inject_fault.c</span>
<span class="p_header">index 81a02a8..86825f88 100644</span>
<span class="p_header">--- a/arch/arm64/kvm/inject_fault.c</span>
<span class="p_header">+++ b/arch/arm64/kvm/inject_fault.c</span>
<span class="p_chunk">@@ -168,8 +168,8 @@</span> <span class="p_context"> void kvm_inject_dabt(struct kvm_vcpu *vcpu, unsigned long addr)</span>
 {
 	if (!(vcpu-&gt;arch.hcr_el2 &amp; HCR_RW))
 		inject_abt32(vcpu, false, addr);
<span class="p_del">-</span>
<span class="p_del">-	inject_abt64(vcpu, false, addr);</span>
<span class="p_add">+	else</span>
<span class="p_add">+		inject_abt64(vcpu, false, addr);</span>
 }
 
 /**
<span class="p_chunk">@@ -184,8 +184,8 @@</span> <span class="p_context"> void kvm_inject_pabt(struct kvm_vcpu *vcpu, unsigned long addr)</span>
 {
 	if (!(vcpu-&gt;arch.hcr_el2 &amp; HCR_RW))
 		inject_abt32(vcpu, true, addr);
<span class="p_del">-</span>
<span class="p_del">-	inject_abt64(vcpu, true, addr);</span>
<span class="p_add">+	else</span>
<span class="p_add">+		inject_abt64(vcpu, true, addr);</span>
 }
 
 /**
<span class="p_chunk">@@ -198,6 +198,6 @@</span> <span class="p_context"> void kvm_inject_undefined(struct kvm_vcpu *vcpu)</span>
 {
 	if (!(vcpu-&gt;arch.hcr_el2 &amp; HCR_RW))
 		inject_undef32(vcpu);
<span class="p_del">-</span>
<span class="p_del">-	inject_undef64(vcpu);</span>
<span class="p_add">+	else</span>
<span class="p_add">+		inject_undef64(vcpu);</span>
 }
<span class="p_header">diff --git a/arch/mips/ath79/setup.c b/arch/mips/ath79/setup.c</span>
<span class="p_header">index a73c93c..c0277e9 100644</span>
<span class="p_header">--- a/arch/mips/ath79/setup.c</span>
<span class="p_header">+++ b/arch/mips/ath79/setup.c</span>
<span class="p_chunk">@@ -186,6 +186,7 @@</span> <span class="p_context"> int get_c0_perfcount_int(void)</span>
 {
 	return ATH79_MISC_IRQ(5);
 }
<span class="p_add">+EXPORT_SYMBOL_GPL(get_c0_perfcount_int);</span>
 
 unsigned int get_c0_compare_int(void)
 {
<span class="p_header">diff --git a/arch/mips/include/asm/pgtable.h b/arch/mips/include/asm/pgtable.h</span>
<span class="p_header">index 845016d..4ec91d5 100644</span>
<span class="p_header">--- a/arch/mips/include/asm/pgtable.h</span>
<span class="p_header">+++ b/arch/mips/include/asm/pgtable.h</span>
<span class="p_chunk">@@ -187,8 +187,39 @@</span> <span class="p_context"> static inline void set_pte(pte_t *ptep, pte_t pteval)</span>
 		 * Make sure the buddy is global too (if it&#39;s !none,
 		 * it better already be global)
 		 */
<span class="p_add">+#ifdef CONFIG_SMP</span>
<span class="p_add">+		/*</span>
<span class="p_add">+		 * For SMP, multiple CPUs can race, so we need to do</span>
<span class="p_add">+		 * this atomically.</span>
<span class="p_add">+		 */</span>
<span class="p_add">+#ifdef CONFIG_64BIT</span>
<span class="p_add">+#define LL_INSN &quot;lld&quot;</span>
<span class="p_add">+#define SC_INSN &quot;scd&quot;</span>
<span class="p_add">+#else /* CONFIG_32BIT */</span>
<span class="p_add">+#define LL_INSN &quot;ll&quot;</span>
<span class="p_add">+#define SC_INSN &quot;sc&quot;</span>
<span class="p_add">+#endif</span>
<span class="p_add">+		unsigned long page_global = _PAGE_GLOBAL;</span>
<span class="p_add">+		unsigned long tmp;</span>
<span class="p_add">+</span>
<span class="p_add">+		__asm__ __volatile__ (</span>
<span class="p_add">+			&quot;	.set	push\n&quot;</span>
<span class="p_add">+			&quot;	.set	noreorder\n&quot;</span>
<span class="p_add">+			&quot;1:	&quot; LL_INSN &quot;	%[tmp], %[buddy]\n&quot;</span>
<span class="p_add">+			&quot;	bnez	%[tmp], 2f\n&quot;</span>
<span class="p_add">+			&quot;	 or	%[tmp], %[tmp], %[global]\n&quot;</span>
<span class="p_add">+			&quot;	&quot; SC_INSN &quot;	%[tmp], %[buddy]\n&quot;</span>
<span class="p_add">+			&quot;	beqz	%[tmp], 1b\n&quot;</span>
<span class="p_add">+			&quot;	 nop\n&quot;</span>
<span class="p_add">+			&quot;2:\n&quot;</span>
<span class="p_add">+			&quot;	.set pop&quot;</span>
<span class="p_add">+			: [buddy] &quot;+m&quot; (buddy-&gt;pte),</span>
<span class="p_add">+			  [tmp] &quot;=&amp;r&quot; (tmp)</span>
<span class="p_add">+			: [global] &quot;r&quot; (page_global));</span>
<span class="p_add">+#else /* !CONFIG_SMP */</span>
 		if (pte_none(*buddy))
 			pte_val(*buddy) = pte_val(*buddy) | _PAGE_GLOBAL;
<span class="p_add">+#endif /* CONFIG_SMP */</span>
 	}
 #endif
 }
<span class="p_header">diff --git a/arch/mips/include/asm/stackframe.h b/arch/mips/include/asm/stackframe.h</span>
<span class="p_header">index b188c79..0562a24 100644</span>
<span class="p_header">--- a/arch/mips/include/asm/stackframe.h</span>
<span class="p_header">+++ b/arch/mips/include/asm/stackframe.h</span>
<span class="p_chunk">@@ -152,6 +152,31 @@</span> <span class="p_context"></span>
 		.set	noreorder
 		bltz	k0, 8f
 		 move	k1, sp
<span class="p_add">+#ifdef CONFIG_EVA</span>
<span class="p_add">+		/*</span>
<span class="p_add">+		 * Flush interAptiv&#39;s Return Prediction Stack (RPS) by writing</span>
<span class="p_add">+		 * EntryHi. Toggling Config7.RPS is slower and less portable.</span>
<span class="p_add">+		 *</span>
<span class="p_add">+		 * The RPS isn&#39;t automatically flushed when exceptions are</span>
<span class="p_add">+		 * taken, which can result in kernel mode speculative accesses</span>
<span class="p_add">+		 * to user addresses if the RPS mispredicts. That&#39;s harmless</span>
<span class="p_add">+		 * when user and kernel share the same address space, but with</span>
<span class="p_add">+		 * EVA the same user segments may be unmapped to kernel mode,</span>
<span class="p_add">+		 * even containing sensitive MMIO regions or invalid memory.</span>
<span class="p_add">+		 *</span>
<span class="p_add">+		 * This can happen when the kernel sets the return address to</span>
<span class="p_add">+		 * ret_from_* and jr&#39;s to the exception handler, which looks</span>
<span class="p_add">+		 * more like a tail call than a function call. If nested calls</span>
<span class="p_add">+		 * don&#39;t evict the last user address in the RPS, it will</span>
<span class="p_add">+		 * mispredict the return and fetch from a user controlled</span>
<span class="p_add">+		 * address into the icache.</span>
<span class="p_add">+		 *</span>
<span class="p_add">+		 * More recent EVA-capable cores with MAAR to restrict</span>
<span class="p_add">+		 * speculative accesses aren&#39;t affected.</span>
<span class="p_add">+		 */</span>
<span class="p_add">+		MFC0	k0, CP0_ENTRYHI</span>
<span class="p_add">+		MTC0	k0, CP0_ENTRYHI</span>
<span class="p_add">+#endif</span>
 		.set	reorder
 		/* Called from user mode, new stack. */
 		get_saved_sp
<span class="p_header">diff --git a/arch/mips/kernel/mips-mt-fpaff.c b/arch/mips/kernel/mips-mt-fpaff.c</span>
<span class="p_header">index 362bb37..116c67a 100644</span>
<span class="p_header">--- a/arch/mips/kernel/mips-mt-fpaff.c</span>
<span class="p_header">+++ b/arch/mips/kernel/mips-mt-fpaff.c</span>
<span class="p_chunk">@@ -154,7 +154,7 @@</span> <span class="p_context"> asmlinkage long mipsmt_sys_sched_getaffinity(pid_t pid, unsigned int len,</span>
 				      unsigned long __user *user_mask_ptr)
 {
 	unsigned int real_len;
<span class="p_del">-	cpumask_t mask;</span>
<span class="p_add">+	cpumask_t allowed, mask;</span>
 	int retval;
 	struct task_struct *p;
 
<span class="p_chunk">@@ -173,7 +173,8 @@</span> <span class="p_context"> asmlinkage long mipsmt_sys_sched_getaffinity(pid_t pid, unsigned int len,</span>
 	if (retval)
 		goto out_unlock;
 
<span class="p_del">-	cpumask_and(&amp;mask, &amp;p-&gt;thread.user_cpus_allowed, cpu_possible_mask);</span>
<span class="p_add">+	cpumask_or(&amp;allowed, &amp;p-&gt;thread.user_cpus_allowed, &amp;p-&gt;cpus_allowed);</span>
<span class="p_add">+	cpumask_and(&amp;mask, &amp;allowed, cpu_active_mask);</span>
 
 out_unlock:
 	read_unlock(&amp;tasklist_lock);
<span class="p_header">diff --git a/arch/mips/kernel/scall64-64.S b/arch/mips/kernel/scall64-64.S</span>
<span class="p_header">index ad4d4463..a6f6b76 100644</span>
<span class="p_header">--- a/arch/mips/kernel/scall64-64.S</span>
<span class="p_header">+++ b/arch/mips/kernel/scall64-64.S</span>
<span class="p_chunk">@@ -80,7 +80,7 @@</span> <span class="p_context"> syscall_trace_entry:</span>
 	SAVE_STATIC
 	move	s0, t2
 	move	a0, sp
<span class="p_del">-	daddiu	a1, v0, __NR_64_Linux</span>
<span class="p_add">+	move	a1, v0</span>
 	jal	syscall_trace_enter
 
 	bltz	v0, 2f			# seccomp failed? Skip syscall
<span class="p_header">diff --git a/arch/mips/kernel/scall64-n32.S b/arch/mips/kernel/scall64-n32.S</span>
<span class="p_header">index 446cc65..4b20106 100644</span>
<span class="p_header">--- a/arch/mips/kernel/scall64-n32.S</span>
<span class="p_header">+++ b/arch/mips/kernel/scall64-n32.S</span>
<span class="p_chunk">@@ -72,7 +72,7 @@</span> <span class="p_context"> n32_syscall_trace_entry:</span>
 	SAVE_STATIC
 	move	s0, t2
 	move	a0, sp
<span class="p_del">-	daddiu	a1, v0, __NR_N32_Linux</span>
<span class="p_add">+	move	a1, v0</span>
 	jal	syscall_trace_enter
 
 	bltz	v0, 2f			# seccomp failed? Skip syscall
<span class="p_header">diff --git a/arch/mips/kernel/traps.c b/arch/mips/kernel/traps.c</span>
<span class="p_header">index c3b41e2..3e0e61f 100644</span>
<span class="p_header">--- a/arch/mips/kernel/traps.c</span>
<span class="p_header">+++ b/arch/mips/kernel/traps.c</span>
<span class="p_chunk">@@ -190,6 +190,7 @@</span> <span class="p_context"> static void show_stacktrace(struct task_struct *task,</span>
 void show_stack(struct task_struct *task, unsigned long *sp)
 {
 	struct pt_regs regs;
<span class="p_add">+	mm_segment_t old_fs = get_fs();</span>
 	if (sp) {
 		regs.regs[29] = (unsigned long)sp;
 		regs.regs[31] = 0;
<span class="p_chunk">@@ -208,7 +209,13 @@</span> <span class="p_context"> void show_stack(struct task_struct *task, unsigned long *sp)</span>
 			prepare_frametrace(&amp;regs);
 		}
 	}
<span class="p_add">+	/*</span>
<span class="p_add">+	 * show_stack() deals exclusively with kernel mode, so be sure to access</span>
<span class="p_add">+	 * the stack in the kernel (not user) address space.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	set_fs(KERNEL_DS);</span>
 	show_stacktrace(task, &amp;regs);
<span class="p_add">+	set_fs(old_fs);</span>
 }
 
 static void show_code(unsigned int __user *pc)
<span class="p_chunk">@@ -1423,6 +1430,7 @@</span> <span class="p_context"> asmlinkage void do_mcheck(struct pt_regs *regs)</span>
 	const int field = 2 * sizeof(unsigned long);
 	int multi_match = regs-&gt;cp0_status &amp; ST0_TS;
 	enum ctx_state prev_state;
<span class="p_add">+	mm_segment_t old_fs = get_fs();</span>
 
 	prev_state = exception_enter();
 	show_regs(regs);
<span class="p_chunk">@@ -1444,8 +1452,13 @@</span> <span class="p_context"> asmlinkage void do_mcheck(struct pt_regs *regs)</span>
 		dump_tlb_all();
 	}
 
<span class="p_add">+	if (!user_mode(regs))</span>
<span class="p_add">+		set_fs(KERNEL_DS);</span>
<span class="p_add">+</span>
 	show_code((unsigned int __user *) regs-&gt;cp0_epc);
 
<span class="p_add">+	set_fs(old_fs);</span>
<span class="p_add">+</span>
 	/*
 	 * Some chips may have other causes of machine check (e.g. SB1
 	 * graduation timer)
<span class="p_header">diff --git a/arch/mips/lantiq/irq.c b/arch/mips/lantiq/irq.c</span>
<span class="p_header">index 6ab1057..d01ade6 100644</span>
<span class="p_header">--- a/arch/mips/lantiq/irq.c</span>
<span class="p_header">+++ b/arch/mips/lantiq/irq.c</span>
<span class="p_chunk">@@ -466,6 +466,7 @@</span> <span class="p_context"> int get_c0_perfcount_int(void)</span>
 {
 	return ltq_perfcount_irq;
 }
<span class="p_add">+EXPORT_SYMBOL_GPL(get_c0_perfcount_int);</span>
 
 unsigned int get_c0_compare_int(void)
 {
<span class="p_header">diff --git a/arch/mips/mti-malta/malta-time.c b/arch/mips/mti-malta/malta-time.c</span>
<span class="p_header">index ce02dbd..a6cc3ef 100644</span>
<span class="p_header">--- a/arch/mips/mti-malta/malta-time.c</span>
<span class="p_header">+++ b/arch/mips/mti-malta/malta-time.c</span>
<span class="p_chunk">@@ -130,6 +130,7 @@</span> <span class="p_context"> int get_c0_perfcount_int(void)</span>
 
 	return mips_cpu_perf_irq;
 }
<span class="p_add">+EXPORT_SYMBOL_GPL(get_c0_perfcount_int);</span>
 
 unsigned int get_c0_compare_int(void)
 {
<span class="p_chunk">@@ -147,14 +148,17 @@</span> <span class="p_context"> unsigned int get_c0_compare_int(void)</span>
 
 static void __init init_rtc(void)
 {
<span class="p_del">-	/* stop the clock whilst setting it up */</span>
<span class="p_del">-	CMOS_WRITE(RTC_SET | RTC_24H, RTC_CONTROL);</span>
<span class="p_add">+	unsigned char freq, ctrl;</span>
 
<span class="p_del">-	/* 32KHz time base */</span>
<span class="p_del">-	CMOS_WRITE(RTC_REF_CLCK_32KHZ, RTC_FREQ_SELECT);</span>
<span class="p_add">+	/* Set 32KHz time base if not already set */</span>
<span class="p_add">+	freq = CMOS_READ(RTC_FREQ_SELECT);</span>
<span class="p_add">+	if ((freq &amp; RTC_DIV_CTL) != RTC_REF_CLCK_32KHZ)</span>
<span class="p_add">+		CMOS_WRITE(RTC_REF_CLCK_32KHZ, RTC_FREQ_SELECT);</span>
 
<span class="p_del">-	/* start the clock */</span>
<span class="p_del">-	CMOS_WRITE(RTC_24H, RTC_CONTROL);</span>
<span class="p_add">+	/* Ensure SET bit is clear so RTC can run */</span>
<span class="p_add">+	ctrl = CMOS_READ(RTC_CONTROL);</span>
<span class="p_add">+	if (ctrl &amp; RTC_SET)</span>
<span class="p_add">+		CMOS_WRITE(ctrl &amp; ~RTC_SET, RTC_CONTROL);</span>
 }
 
 void __init plat_time_init(void)
<span class="p_header">diff --git a/arch/mips/mti-sead3/sead3-time.c b/arch/mips/mti-sead3/sead3-time.c</span>
<span class="p_header">index ec1dd24..90e303e 100644</span>
<span class="p_header">--- a/arch/mips/mti-sead3/sead3-time.c</span>
<span class="p_header">+++ b/arch/mips/mti-sead3/sead3-time.c</span>
<span class="p_chunk">@@ -77,6 +77,7 @@</span> <span class="p_context"> int get_c0_perfcount_int(void)</span>
 		return MIPS_CPU_IRQ_BASE + cp0_perfcount_irq;
 	return -1;
 }
<span class="p_add">+EXPORT_SYMBOL_GPL(get_c0_perfcount_int);</span>
 
 unsigned int get_c0_compare_int(void)
 {
<span class="p_header">diff --git a/arch/mips/ralink/irq.c b/arch/mips/ralink/irq.c</span>
<span class="p_header">index 7cf91b9..199ace4 100644</span>
<span class="p_header">--- a/arch/mips/ralink/irq.c</span>
<span class="p_header">+++ b/arch/mips/ralink/irq.c</span>
<span class="p_chunk">@@ -89,6 +89,7 @@</span> <span class="p_context"> int get_c0_perfcount_int(void)</span>
 {
 	return rt_perfcount_irq;
 }
<span class="p_add">+EXPORT_SYMBOL_GPL(get_c0_perfcount_int);</span>
 
 unsigned int get_c0_compare_int(void)
 {
<span class="p_header">diff --git a/arch/sparc/include/asm/visasm.h b/arch/sparc/include/asm/visasm.h</span>
<span class="p_header">index 1f0aa20..6424249 100644</span>
<span class="p_header">--- a/arch/sparc/include/asm/visasm.h</span>
<span class="p_header">+++ b/arch/sparc/include/asm/visasm.h</span>
<span class="p_chunk">@@ -28,16 +28,10 @@</span> <span class="p_context"></span>
  * Must preserve %o5 between VISEntryHalf and VISExitHalf */
 
 #define VISEntryHalf					\
<span class="p_del">-	rd		%fprs, %o5;			\</span>
<span class="p_del">-	andcc		%o5, FPRS_FEF, %g0;		\</span>
<span class="p_del">-	be,pt		%icc, 297f;			\</span>
<span class="p_del">-	 sethi		%hi(298f), %g7;			\</span>
<span class="p_del">-	sethi		%hi(VISenterhalf), %g1;		\</span>
<span class="p_del">-	jmpl		%g1 + %lo(VISenterhalf), %g0;	\</span>
<span class="p_del">-	 or		%g7, %lo(298f), %g7;		\</span>
<span class="p_del">-	clr		%o5;				\</span>
<span class="p_del">-297:	wr		%o5, FPRS_FEF, %fprs;		\</span>
<span class="p_del">-298:</span>
<span class="p_add">+	VISEntry</span>
<span class="p_add">+</span>
<span class="p_add">+#define VISExitHalf					\</span>
<span class="p_add">+	VISExit</span>
 
 #define VISEntryHalfFast(fail_label)			\
 	rd		%fprs, %o5;			\
<span class="p_chunk">@@ -47,7 +41,7 @@</span> <span class="p_context"></span>
 	ba,a,pt		%xcc, fail_label;		\
 297:	wr		%o5, FPRS_FEF, %fprs;
 
<span class="p_del">-#define VISExitHalf					\</span>
<span class="p_add">+#define VISExitHalfFast					\</span>
 	wr		%o5, 0, %fprs;
 
 #ifndef __ASSEMBLY__
<span class="p_header">diff --git a/arch/sparc/lib/NG4memcpy.S b/arch/sparc/lib/NG4memcpy.S</span>
<span class="p_header">index 140527a..83aeeb1 100644</span>
<span class="p_header">--- a/arch/sparc/lib/NG4memcpy.S</span>
<span class="p_header">+++ b/arch/sparc/lib/NG4memcpy.S</span>
<span class="p_chunk">@@ -240,8 +240,11 @@</span> <span class="p_context"> FUNC_NAME:	/* %o0=dst, %o1=src, %o2=len */</span>
 	add		%o0, 0x40, %o0
 	bne,pt		%icc, 1b
 	 LOAD(prefetch, %g1 + 0x200, #n_reads_strong)
<span class="p_add">+#ifdef NON_USER_COPY</span>
<span class="p_add">+	VISExitHalfFast</span>
<span class="p_add">+#else</span>
 	VISExitHalf
<span class="p_del">-</span>
<span class="p_add">+#endif</span>
 	brz,pn		%o2, .Lexit
 	 cmp		%o2, 19
 	ble,pn		%icc, .Lsmall_unaligned
<span class="p_header">diff --git a/arch/sparc/lib/VISsave.S b/arch/sparc/lib/VISsave.S</span>
<span class="p_header">index b320ae9..a063d84 100644</span>
<span class="p_header">--- a/arch/sparc/lib/VISsave.S</span>
<span class="p_header">+++ b/arch/sparc/lib/VISsave.S</span>
<span class="p_chunk">@@ -44,9 +44,8 @@</span> <span class="p_context"> vis1:	ldub		[%g6 + TI_FPSAVED], %g3</span>
 
 	 stx		%g3, [%g6 + TI_GSR]
 2:	add		%g6, %g1, %g3
<span class="p_del">-	cmp		%o5, FPRS_DU</span>
<span class="p_del">-	be,pn		%icc, 6f</span>
<span class="p_del">-	 sll		%g1, 3, %g1</span>
<span class="p_add">+	mov		FPRS_DU | FPRS_DL | FPRS_FEF, %o5</span>
<span class="p_add">+	sll		%g1, 3, %g1</span>
 	stb		%o5, [%g3 + TI_FPSAVED]
 	rd		%gsr, %g2
 	add		%g6, %g1, %g3
<span class="p_chunk">@@ -80,65 +79,3 @@</span> <span class="p_context"> vis1:	ldub		[%g6 + TI_FPSAVED], %g3</span>
 	.align		32
 80:	jmpl		%g7 + %g0, %g0
 	 nop
<span class="p_del">-</span>
<span class="p_del">-6:	ldub		[%g3 + TI_FPSAVED], %o5</span>
<span class="p_del">-	or		%o5, FPRS_DU, %o5</span>
<span class="p_del">-	add		%g6, TI_FPREGS+0x80, %g2</span>
<span class="p_del">-	stb		%o5, [%g3 + TI_FPSAVED]</span>
<span class="p_del">-</span>
<span class="p_del">-	sll		%g1, 5, %g1</span>
<span class="p_del">-	add		%g6, TI_FPREGS+0xc0, %g3</span>
<span class="p_del">-	wr		%g0, FPRS_FEF, %fprs</span>
<span class="p_del">-	membar		#Sync</span>
<span class="p_del">-	stda		%f32, [%g2 + %g1] ASI_BLK_P</span>
<span class="p_del">-	stda		%f48, [%g3 + %g1] ASI_BLK_P</span>
<span class="p_del">-	membar		#Sync</span>
<span class="p_del">-	ba,pt		%xcc, 80f</span>
<span class="p_del">-	 nop</span>
<span class="p_del">-</span>
<span class="p_del">-	.align		32</span>
<span class="p_del">-80:	jmpl		%g7 + %g0, %g0</span>
<span class="p_del">-	 nop</span>
<span class="p_del">-</span>
<span class="p_del">-	.align		32</span>
<span class="p_del">-VISenterhalf:</span>
<span class="p_del">-	ldub		[%g6 + TI_FPDEPTH], %g1</span>
<span class="p_del">-	brnz,a,pn	%g1, 1f</span>
<span class="p_del">-	 cmp		%g1, 1</span>
<span class="p_del">-	stb		%g0, [%g6 + TI_FPSAVED]</span>
<span class="p_del">-	stx		%fsr, [%g6 + TI_XFSR]</span>
<span class="p_del">-	clr		%o5</span>
<span class="p_del">-	jmpl		%g7 + %g0, %g0</span>
<span class="p_del">-	 wr		%g0, FPRS_FEF, %fprs</span>
<span class="p_del">-</span>
<span class="p_del">-1:	bne,pn		%icc, 2f</span>
<span class="p_del">-	 srl		%g1, 1, %g1</span>
<span class="p_del">-	ba,pt		%xcc, vis1</span>
<span class="p_del">-	 sub		%g7, 8, %g7</span>
<span class="p_del">-2:	addcc		%g6, %g1, %g3</span>
<span class="p_del">-	sll		%g1, 3, %g1</span>
<span class="p_del">-	andn		%o5, FPRS_DU, %g2</span>
<span class="p_del">-	stb		%g2, [%g3 + TI_FPSAVED]</span>
<span class="p_del">-</span>
<span class="p_del">-	rd		%gsr, %g2</span>
<span class="p_del">-	add		%g6, %g1, %g3</span>
<span class="p_del">-	stx		%g2, [%g3 + TI_GSR]</span>
<span class="p_del">-	add		%g6, %g1, %g2</span>
<span class="p_del">-	stx		%fsr, [%g2 + TI_XFSR]</span>
<span class="p_del">-	sll		%g1, 5, %g1</span>
<span class="p_del">-3:	andcc		%o5, FPRS_DL, %g0</span>
<span class="p_del">-	be,pn		%icc, 4f</span>
<span class="p_del">-	 add		%g6, TI_FPREGS, %g2</span>
<span class="p_del">-</span>
<span class="p_del">-	add		%g6, TI_FPREGS+0x40, %g3</span>
<span class="p_del">-	membar		#Sync</span>
<span class="p_del">-	stda		%f0, [%g2 + %g1] ASI_BLK_P</span>
<span class="p_del">-	stda		%f16, [%g3 + %g1] ASI_BLK_P</span>
<span class="p_del">-	membar		#Sync</span>
<span class="p_del">-	ba,pt		%xcc, 4f</span>
<span class="p_del">-	 nop</span>
<span class="p_del">-</span>
<span class="p_del">-	.align		32</span>
<span class="p_del">-4:	and		%o5, FPRS_DU, %o5</span>
<span class="p_del">-	jmpl		%g7 + %g0, %g0</span>
<span class="p_del">-	 wr		%o5, FPRS_FEF, %fprs</span>
<span class="p_header">diff --git a/arch/sparc/lib/ksyms.c b/arch/sparc/lib/ksyms.c</span>
<span class="p_header">index 1d649a9..8069ce1 100644</span>
<span class="p_header">--- a/arch/sparc/lib/ksyms.c</span>
<span class="p_header">+++ b/arch/sparc/lib/ksyms.c</span>
<span class="p_chunk">@@ -135,10 +135,6 @@</span> <span class="p_context"> EXPORT_SYMBOL(copy_user_page);</span>
 void VISenter(void);
 EXPORT_SYMBOL(VISenter);
 
<span class="p_del">-/* CRYPTO code needs this */</span>
<span class="p_del">-void VISenterhalf(void);</span>
<span class="p_del">-EXPORT_SYMBOL(VISenterhalf);</span>
<span class="p_del">-</span>
 extern void xor_vis_2(unsigned long, unsigned long *, unsigned long *);
 extern void xor_vis_3(unsigned long, unsigned long *, unsigned long *,
 		unsigned long *);
<span class="p_header">diff --git a/arch/x86/include/asm/desc.h b/arch/x86/include/asm/desc.h</span>
<span class="p_header">index a94b82e..6912618 100644</span>
<span class="p_header">--- a/arch/x86/include/asm/desc.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/desc.h</span>
<span class="p_chunk">@@ -280,21 +280,6 @@</span> <span class="p_context"> static inline void clear_LDT(void)</span>
 	set_ldt(NULL, 0);
 }
 
<span class="p_del">-/*</span>
<span class="p_del">- * load one particular LDT into the current CPU</span>
<span class="p_del">- */</span>
<span class="p_del">-static inline void load_LDT_nolock(mm_context_t *pc)</span>
<span class="p_del">-{</span>
<span class="p_del">-	set_ldt(pc-&gt;ldt, pc-&gt;size);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static inline void load_LDT(mm_context_t *pc)</span>
<span class="p_del">-{</span>
<span class="p_del">-	preempt_disable();</span>
<span class="p_del">-	load_LDT_nolock(pc);</span>
<span class="p_del">-	preempt_enable();</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
 static inline unsigned long get_desc_base(const struct desc_struct *desc)
 {
 	return (unsigned)(desc-&gt;base0 | ((desc-&gt;base1) &lt;&lt; 16) | ((desc-&gt;base2) &lt;&lt; 24));
<span class="p_header">diff --git a/arch/x86/include/asm/mmu.h b/arch/x86/include/asm/mmu.h</span>
<span class="p_header">index 876e74e..b6b7bc3 100644</span>
<span class="p_header">--- a/arch/x86/include/asm/mmu.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/mmu.h</span>
<span class="p_chunk">@@ -9,8 +9,7 @@</span> <span class="p_context"></span>
  * we put the segment information here.
  */
 typedef struct {
<span class="p_del">-	void *ldt;</span>
<span class="p_del">-	int size;</span>
<span class="p_add">+	struct ldt_struct *ldt;</span>
 
 #ifdef CONFIG_X86_64
 	/* True if mm supports a task running in 32 bit compatibility mode. */
<span class="p_header">diff --git a/arch/x86/include/asm/mmu_context.h b/arch/x86/include/asm/mmu_context.h</span>
<span class="p_header">index 4b75d59..1ab38a4 100644</span>
<span class="p_header">--- a/arch/x86/include/asm/mmu_context.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/mmu_context.h</span>
<span class="p_chunk">@@ -19,6 +19,50 @@</span> <span class="p_context"> static inline void paravirt_activate_mm(struct mm_struct *prev,</span>
 #endif	/* !CONFIG_PARAVIRT */
 
 /*
<span class="p_add">+ * ldt_structs can be allocated, used, and freed, but they are never</span>
<span class="p_add">+ * modified while live.</span>
<span class="p_add">+ */</span>
<span class="p_add">+struct ldt_struct {</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Xen requires page-aligned LDTs with special permissions.  This is</span>
<span class="p_add">+	 * needed to prevent us from installing evil descriptors such as</span>
<span class="p_add">+	 * call gates.  On native, we could merge the ldt_struct and LDT</span>
<span class="p_add">+	 * allocations, but it&#39;s not worth trying to optimize.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	struct desc_struct *entries;</span>
<span class="p_add">+	int size;</span>
<span class="p_add">+};</span>
<span class="p_add">+</span>
<span class="p_add">+static inline void load_mm_ldt(struct mm_struct *mm)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct ldt_struct *ldt;</span>
<span class="p_add">+</span>
<span class="p_add">+	/* lockless_dereference synchronizes with smp_store_release */</span>
<span class="p_add">+	ldt = lockless_dereference(mm-&gt;context.ldt);</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Any change to mm-&gt;context.ldt is followed by an IPI to all</span>
<span class="p_add">+	 * CPUs with the mm active.  The LDT will not be freed until</span>
<span class="p_add">+	 * after the IPI is handled by all such CPUs.  This means that,</span>
<span class="p_add">+	 * if the ldt_struct changes before we return, the values we see</span>
<span class="p_add">+	 * will be safe, and the new values will be loaded before we run</span>
<span class="p_add">+	 * any user code.</span>
<span class="p_add">+	 *</span>
<span class="p_add">+	 * NB: don&#39;t try to convert this to use RCU without extreme care.</span>
<span class="p_add">+	 * We would still need IRQs off, because we don&#39;t want to change</span>
<span class="p_add">+	 * the local LDT after an IPI loaded a newer value than the one</span>
<span class="p_add">+	 * that we can see.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+</span>
<span class="p_add">+	if (unlikely(ldt))</span>
<span class="p_add">+		set_ldt(ldt-&gt;entries, ldt-&gt;size);</span>
<span class="p_add">+	else</span>
<span class="p_add">+		clear_LDT();</span>
<span class="p_add">+</span>
<span class="p_add">+	DEBUG_LOCKS_WARN_ON(preemptible());</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+/*</span>
  * Used for LDT copy/destruction.
  */
 int init_new_context(struct task_struct *tsk, struct mm_struct *mm);
<span class="p_chunk">@@ -63,7 +107,7 @@</span> <span class="p_context"> static inline void switch_mm(struct mm_struct *prev, struct mm_struct *next,</span>
 		 * prev-&gt;context.ldt won&#39;t be equal to next-&gt;context.ldt.
 		 */
 		if (unlikely(prev-&gt;context.ldt != next-&gt;context.ldt))
<span class="p_del">-			load_LDT_nolock(&amp;next-&gt;context);</span>
<span class="p_add">+			load_mm_ldt(next);</span>
 	}
 #ifdef CONFIG_SMP
 	  else {
<span class="p_chunk">@@ -85,7 +129,7 @@</span> <span class="p_context"> static inline void switch_mm(struct mm_struct *prev, struct mm_struct *next,</span>
 			 */
 			load_cr3(next-&gt;pgd);
 			trace_tlb_flush(TLB_FLUSH_ON_TASK_SWITCH, TLB_FLUSH_ALL);
<span class="p_del">-			load_LDT_nolock(&amp;next-&gt;context);</span>
<span class="p_add">+			load_mm_ldt(next);</span>
 		}
 	}
 #endif
<span class="p_header">diff --git a/arch/x86/kernel/acpi/boot.c b/arch/x86/kernel/acpi/boot.c</span>
<span class="p_header">index b5ddc96..a74f4b7 100644</span>
<span class="p_header">--- a/arch/x86/kernel/acpi/boot.c</span>
<span class="p_header">+++ b/arch/x86/kernel/acpi/boot.c</span>
<span class="p_chunk">@@ -489,6 +489,7 @@</span> <span class="p_context"> static void __init acpi_sci_ioapic_setup(u8 bus_irq, u16 polarity, u16 trigger,</span>
 		polarity = acpi_sci_flags &amp; ACPI_MADT_POLARITY_MASK;
 
 	mp_override_legacy_irq(bus_irq, polarity, trigger, gsi);
<span class="p_add">+	acpi_penalize_sci_irq(bus_irq, trigger, polarity);</span>
 
 	/*
 	 * stash over-ride to indicate we&#39;ve been here
<span class="p_header">diff --git a/arch/x86/kernel/cpu/common.c b/arch/x86/kernel/cpu/common.c</span>
<span class="p_header">index c604965..382a097 100644</span>
<span class="p_header">--- a/arch/x86/kernel/cpu/common.c</span>
<span class="p_header">+++ b/arch/x86/kernel/cpu/common.c</span>
<span class="p_chunk">@@ -1366,7 +1366,7 @@</span> <span class="p_context"> void cpu_init(void)</span>
 	load_sp0(t, &amp;current-&gt;thread);
 	set_tss_desc(cpu, t);
 	load_TR_desc();
<span class="p_del">-	load_LDT(&amp;init_mm.context);</span>
<span class="p_add">+	load_mm_ldt(&amp;init_mm);</span>
 
 	clear_all_debug_regs();
 	dbg_restore_debug_regs();
<span class="p_chunk">@@ -1409,7 +1409,7 @@</span> <span class="p_context"> void cpu_init(void)</span>
 	load_sp0(t, thread);
 	set_tss_desc(cpu, t);
 	load_TR_desc();
<span class="p_del">-	load_LDT(&amp;init_mm.context);</span>
<span class="p_add">+	load_mm_ldt(&amp;init_mm);</span>
 
 	t-&gt;x86_tss.io_bitmap_base = offsetof(struct tss_struct, io_bitmap);
 
<span class="p_header">diff --git a/arch/x86/kernel/cpu/perf_event.c b/arch/x86/kernel/cpu/perf_event.c</span>
<span class="p_header">index 143e5f5..82adb1a 100644</span>
<span class="p_header">--- a/arch/x86/kernel/cpu/perf_event.c</span>
<span class="p_header">+++ b/arch/x86/kernel/cpu/perf_event.c</span>
<span class="p_chunk">@@ -31,6 +31,7 @@</span> <span class="p_context"></span>
 #include &lt;asm/nmi.h&gt;
 #include &lt;asm/smp.h&gt;
 #include &lt;asm/alternative.h&gt;
<span class="p_add">+#include &lt;asm/mmu_context.h&gt;</span>
 #include &lt;asm/timer.h&gt;
 #include &lt;asm/desc.h&gt;
 #include &lt;asm/ldt.h&gt;
<span class="p_chunk">@@ -1986,21 +1987,25 @@</span> <span class="p_context"> static unsigned long get_segment_base(unsigned int segment)</span>
 	int idx = segment &gt;&gt; 3;
 
 	if ((segment &amp; SEGMENT_TI_MASK) == SEGMENT_LDT) {
<span class="p_add">+		struct ldt_struct *ldt;</span>
<span class="p_add">+</span>
 		if (idx &gt; LDT_ENTRIES)
 			return 0;
 
<span class="p_del">-		if (idx &gt; current-&gt;active_mm-&gt;context.size)</span>
<span class="p_add">+		/* IRQs are off, so this synchronizes with smp_store_release */</span>
<span class="p_add">+		ldt = lockless_dereference(current-&gt;active_mm-&gt;context.ldt);</span>
<span class="p_add">+		if (!ldt || idx &gt; ldt-&gt;size)</span>
 			return 0;
 
<span class="p_del">-		desc = current-&gt;active_mm-&gt;context.ldt;</span>
<span class="p_add">+		desc = &amp;ldt-&gt;entries[idx];</span>
 	} else {
 		if (idx &gt; GDT_ENTRIES)
 			return 0;
 
<span class="p_del">-		desc = raw_cpu_ptr(gdt_page.gdt);</span>
<span class="p_add">+		desc = raw_cpu_ptr(gdt_page.gdt) + idx;</span>
 	}
 
<span class="p_del">-	return get_desc_base(desc + idx);</span>
<span class="p_add">+	return get_desc_base(desc);</span>
 }
 
 #ifdef CONFIG_COMPAT
<span class="p_header">diff --git a/arch/x86/kernel/ldt.c b/arch/x86/kernel/ldt.c</span>
<span class="p_header">index c37886d..2bcc052 100644</span>
<span class="p_header">--- a/arch/x86/kernel/ldt.c</span>
<span class="p_header">+++ b/arch/x86/kernel/ldt.c</span>
<span class="p_chunk">@@ -12,6 +12,7 @@</span> <span class="p_context"></span>
 #include &lt;linux/string.h&gt;
 #include &lt;linux/mm.h&gt;
 #include &lt;linux/smp.h&gt;
<span class="p_add">+#include &lt;linux/slab.h&gt;</span>
 #include &lt;linux/vmalloc.h&gt;
 #include &lt;linux/uaccess.h&gt;
 
<span class="p_chunk">@@ -20,82 +21,82 @@</span> <span class="p_context"></span>
 #include &lt;asm/mmu_context.h&gt;
 #include &lt;asm/syscalls.h&gt;
 
<span class="p_del">-#ifdef CONFIG_SMP</span>
<span class="p_add">+/* context.lock is held for us, so we don&#39;t need any locking. */</span>
 static void flush_ldt(void *current_mm)
 {
<span class="p_del">-	if (current-&gt;active_mm == current_mm)</span>
<span class="p_del">-		load_LDT(&amp;current-&gt;active_mm-&gt;context);</span>
<span class="p_add">+	mm_context_t *pc;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (current-&gt;active_mm != current_mm)</span>
<span class="p_add">+		return;</span>
<span class="p_add">+</span>
<span class="p_add">+	pc = &amp;current-&gt;active_mm-&gt;context;</span>
<span class="p_add">+	set_ldt(pc-&gt;ldt-&gt;entries, pc-&gt;ldt-&gt;size);</span>
 }
<span class="p_del">-#endif</span>
 
<span class="p_del">-static int alloc_ldt(mm_context_t *pc, int mincount, int reload)</span>
<span class="p_add">+/* The caller must call finalize_ldt_struct on the result. LDT starts zeroed. */</span>
<span class="p_add">+static struct ldt_struct *alloc_ldt_struct(int size)</span>
 {
<span class="p_del">-	void *oldldt, *newldt;</span>
<span class="p_del">-	int oldsize;</span>
<span class="p_del">-</span>
<span class="p_del">-	if (mincount &lt;= pc-&gt;size)</span>
<span class="p_del">-		return 0;</span>
<span class="p_del">-	oldsize = pc-&gt;size;</span>
<span class="p_del">-	mincount = (mincount + (PAGE_SIZE / LDT_ENTRY_SIZE - 1)) &amp;</span>
<span class="p_del">-			(~(PAGE_SIZE / LDT_ENTRY_SIZE - 1));</span>
<span class="p_del">-	if (mincount * LDT_ENTRY_SIZE &gt; PAGE_SIZE)</span>
<span class="p_del">-		newldt = vmalloc(mincount * LDT_ENTRY_SIZE);</span>
<span class="p_add">+	struct ldt_struct *new_ldt;</span>
<span class="p_add">+	int alloc_size;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (size &gt; LDT_ENTRIES)</span>
<span class="p_add">+		return NULL;</span>
<span class="p_add">+</span>
<span class="p_add">+	new_ldt = kmalloc(sizeof(struct ldt_struct), GFP_KERNEL);</span>
<span class="p_add">+	if (!new_ldt)</span>
<span class="p_add">+		return NULL;</span>
<span class="p_add">+</span>
<span class="p_add">+	BUILD_BUG_ON(LDT_ENTRY_SIZE != sizeof(struct desc_struct));</span>
<span class="p_add">+	alloc_size = size * LDT_ENTRY_SIZE;</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Xen is very picky: it requires a page-aligned LDT that has no</span>
<span class="p_add">+	 * trailing nonzero bytes in any page that contains LDT descriptors.</span>
<span class="p_add">+	 * Keep it simple: zero the whole allocation and never allocate less</span>
<span class="p_add">+	 * than PAGE_SIZE.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	if (alloc_size &gt; PAGE_SIZE)</span>
<span class="p_add">+		new_ldt-&gt;entries = vzalloc(alloc_size);</span>
 	else
<span class="p_del">-		newldt = (void *)__get_free_page(GFP_KERNEL);</span>
<span class="p_del">-</span>
<span class="p_del">-	if (!newldt)</span>
<span class="p_del">-		return -ENOMEM;</span>
<span class="p_add">+		new_ldt-&gt;entries = kzalloc(PAGE_SIZE, GFP_KERNEL);</span>
 
<span class="p_del">-	if (oldsize)</span>
<span class="p_del">-		memcpy(newldt, pc-&gt;ldt, oldsize * LDT_ENTRY_SIZE);</span>
<span class="p_del">-	oldldt = pc-&gt;ldt;</span>
<span class="p_del">-	memset(newldt + oldsize * LDT_ENTRY_SIZE, 0,</span>
<span class="p_del">-	       (mincount - oldsize) * LDT_ENTRY_SIZE);</span>
<span class="p_add">+	if (!new_ldt-&gt;entries) {</span>
<span class="p_add">+		kfree(new_ldt);</span>
<span class="p_add">+		return NULL;</span>
<span class="p_add">+	}</span>
 
<span class="p_del">-	paravirt_alloc_ldt(newldt, mincount);</span>
<span class="p_add">+	new_ldt-&gt;size = size;</span>
<span class="p_add">+	return new_ldt;</span>
<span class="p_add">+}</span>
 
<span class="p_del">-#ifdef CONFIG_X86_64</span>
<span class="p_del">-	/* CHECKME: Do we really need this ? */</span>
<span class="p_del">-	wmb();</span>
<span class="p_del">-#endif</span>
<span class="p_del">-	pc-&gt;ldt = newldt;</span>
<span class="p_del">-	wmb();</span>
<span class="p_del">-	pc-&gt;size = mincount;</span>
<span class="p_del">-	wmb();</span>
<span class="p_del">-</span>
<span class="p_del">-	if (reload) {</span>
<span class="p_del">-#ifdef CONFIG_SMP</span>
<span class="p_del">-		preempt_disable();</span>
<span class="p_del">-		load_LDT(pc);</span>
<span class="p_del">-		if (!cpumask_equal(mm_cpumask(current-&gt;mm),</span>
<span class="p_del">-				   cpumask_of(smp_processor_id())))</span>
<span class="p_del">-			smp_call_function(flush_ldt, current-&gt;mm, 1);</span>
<span class="p_del">-		preempt_enable();</span>
<span class="p_del">-#else</span>
<span class="p_del">-		load_LDT(pc);</span>
<span class="p_del">-#endif</span>
<span class="p_del">-	}</span>
<span class="p_del">-	if (oldsize) {</span>
<span class="p_del">-		paravirt_free_ldt(oldldt, oldsize);</span>
<span class="p_del">-		if (oldsize * LDT_ENTRY_SIZE &gt; PAGE_SIZE)</span>
<span class="p_del">-			vfree(oldldt);</span>
<span class="p_del">-		else</span>
<span class="p_del">-			put_page(virt_to_page(oldldt));</span>
<span class="p_del">-	}</span>
<span class="p_del">-	return 0;</span>
<span class="p_add">+/* After calling this, the LDT is immutable. */</span>
<span class="p_add">+static void finalize_ldt_struct(struct ldt_struct *ldt)</span>
<span class="p_add">+{</span>
<span class="p_add">+	paravirt_alloc_ldt(ldt-&gt;entries, ldt-&gt;size);</span>
 }
 
<span class="p_del">-static inline int copy_ldt(mm_context_t *new, mm_context_t *old)</span>
<span class="p_add">+/* context.lock is held */</span>
<span class="p_add">+static void install_ldt(struct mm_struct *current_mm,</span>
<span class="p_add">+			struct ldt_struct *ldt)</span>
 {
<span class="p_del">-	int err = alloc_ldt(new, old-&gt;size, 0);</span>
<span class="p_del">-	int i;</span>
<span class="p_add">+	/* Synchronizes with lockless_dereference in load_mm_ldt. */</span>
<span class="p_add">+	smp_store_release(&amp;current_mm-&gt;context.ldt, ldt);</span>
<span class="p_add">+</span>
<span class="p_add">+	/* Activate the LDT for all CPUs using current_mm. */</span>
<span class="p_add">+	on_each_cpu_mask(mm_cpumask(current_mm), flush_ldt, current_mm, true);</span>
<span class="p_add">+}</span>
 
<span class="p_del">-	if (err &lt; 0)</span>
<span class="p_del">-		return err;</span>
<span class="p_add">+static void free_ldt_struct(struct ldt_struct *ldt)</span>
<span class="p_add">+{</span>
<span class="p_add">+	if (likely(!ldt))</span>
<span class="p_add">+		return;</span>
 
<span class="p_del">-	for (i = 0; i &lt; old-&gt;size; i++)</span>
<span class="p_del">-		write_ldt_entry(new-&gt;ldt, i, old-&gt;ldt + i * LDT_ENTRY_SIZE);</span>
<span class="p_del">-	return 0;</span>
<span class="p_add">+	paravirt_free_ldt(ldt-&gt;entries, ldt-&gt;size);</span>
<span class="p_add">+	if (ldt-&gt;size * LDT_ENTRY_SIZE &gt; PAGE_SIZE)</span>
<span class="p_add">+		vfree(ldt-&gt;entries);</span>
<span class="p_add">+	else</span>
<span class="p_add">+		kfree(ldt-&gt;entries);</span>
<span class="p_add">+	kfree(ldt);</span>
 }
 
 /*
<span class="p_chunk">@@ -104,17 +105,37 @@</span> <span class="p_context"> static inline int copy_ldt(mm_context_t *new, mm_context_t *old)</span>
  */
 int init_new_context(struct task_struct *tsk, struct mm_struct *mm)
 {
<span class="p_add">+	struct ldt_struct *new_ldt;</span>
 	struct mm_struct *old_mm;
 	int retval = 0;
 
 	mutex_init(&amp;mm-&gt;context.lock);
<span class="p_del">-	mm-&gt;context.size = 0;</span>
 	old_mm = current-&gt;mm;
<span class="p_del">-	if (old_mm &amp;&amp; old_mm-&gt;context.size &gt; 0) {</span>
<span class="p_del">-		mutex_lock(&amp;old_mm-&gt;context.lock);</span>
<span class="p_del">-		retval = copy_ldt(&amp;mm-&gt;context, &amp;old_mm-&gt;context);</span>
<span class="p_del">-		mutex_unlock(&amp;old_mm-&gt;context.lock);</span>
<span class="p_add">+	if (!old_mm) {</span>
<span class="p_add">+		mm-&gt;context.ldt = NULL;</span>
<span class="p_add">+		return 0;</span>
 	}
<span class="p_add">+</span>
<span class="p_add">+	mutex_lock(&amp;old_mm-&gt;context.lock);</span>
<span class="p_add">+	if (!old_mm-&gt;context.ldt) {</span>
<span class="p_add">+		mm-&gt;context.ldt = NULL;</span>
<span class="p_add">+		goto out_unlock;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	new_ldt = alloc_ldt_struct(old_mm-&gt;context.ldt-&gt;size);</span>
<span class="p_add">+	if (!new_ldt) {</span>
<span class="p_add">+		retval = -ENOMEM;</span>
<span class="p_add">+		goto out_unlock;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	memcpy(new_ldt-&gt;entries, old_mm-&gt;context.ldt-&gt;entries,</span>
<span class="p_add">+	       new_ldt-&gt;size * LDT_ENTRY_SIZE);</span>
<span class="p_add">+	finalize_ldt_struct(new_ldt);</span>
<span class="p_add">+</span>
<span class="p_add">+	mm-&gt;context.ldt = new_ldt;</span>
<span class="p_add">+</span>
<span class="p_add">+out_unlock:</span>
<span class="p_add">+	mutex_unlock(&amp;old_mm-&gt;context.lock);</span>
 	return retval;
 }
 
<span class="p_chunk">@@ -125,53 +146,47 @@</span> <span class="p_context"> int init_new_context(struct task_struct *tsk, struct mm_struct *mm)</span>
  */
 void destroy_context(struct mm_struct *mm)
 {
<span class="p_del">-	if (mm-&gt;context.size) {</span>
<span class="p_del">-#ifdef CONFIG_X86_32</span>
<span class="p_del">-		/* CHECKME: Can this ever happen ? */</span>
<span class="p_del">-		if (mm == current-&gt;active_mm)</span>
<span class="p_del">-			clear_LDT();</span>
<span class="p_del">-#endif</span>
<span class="p_del">-		paravirt_free_ldt(mm-&gt;context.ldt, mm-&gt;context.size);</span>
<span class="p_del">-		if (mm-&gt;context.size * LDT_ENTRY_SIZE &gt; PAGE_SIZE)</span>
<span class="p_del">-			vfree(mm-&gt;context.ldt);</span>
<span class="p_del">-		else</span>
<span class="p_del">-			put_page(virt_to_page(mm-&gt;context.ldt));</span>
<span class="p_del">-		mm-&gt;context.size = 0;</span>
<span class="p_del">-	}</span>
<span class="p_add">+	free_ldt_struct(mm-&gt;context.ldt);</span>
<span class="p_add">+	mm-&gt;context.ldt = NULL;</span>
 }
 
 static int read_ldt(void __user *ptr, unsigned long bytecount)
 {
<span class="p_del">-	int err;</span>
<span class="p_add">+	int retval;</span>
 	unsigned long size;
 	struct mm_struct *mm = current-&gt;mm;
 
<span class="p_del">-	if (!mm-&gt;context.size)</span>
<span class="p_del">-		return 0;</span>
<span class="p_add">+	mutex_lock(&amp;mm-&gt;context.lock);</span>
<span class="p_add">+</span>
<span class="p_add">+	if (!mm-&gt;context.ldt) {</span>
<span class="p_add">+		retval = 0;</span>
<span class="p_add">+		goto out_unlock;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
 	if (bytecount &gt; LDT_ENTRY_SIZE * LDT_ENTRIES)
 		bytecount = LDT_ENTRY_SIZE * LDT_ENTRIES;
 
<span class="p_del">-	mutex_lock(&amp;mm-&gt;context.lock);</span>
<span class="p_del">-	size = mm-&gt;context.size * LDT_ENTRY_SIZE;</span>
<span class="p_add">+	size = mm-&gt;context.ldt-&gt;size * LDT_ENTRY_SIZE;</span>
 	if (size &gt; bytecount)
 		size = bytecount;
 
<span class="p_del">-	err = 0;</span>
<span class="p_del">-	if (copy_to_user(ptr, mm-&gt;context.ldt, size))</span>
<span class="p_del">-		err = -EFAULT;</span>
<span class="p_del">-	mutex_unlock(&amp;mm-&gt;context.lock);</span>
<span class="p_del">-	if (err &lt; 0)</span>
<span class="p_del">-		goto error_return;</span>
<span class="p_add">+	if (copy_to_user(ptr, mm-&gt;context.ldt-&gt;entries, size)) {</span>
<span class="p_add">+		retval = -EFAULT;</span>
<span class="p_add">+		goto out_unlock;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
 	if (size != bytecount) {
<span class="p_del">-		/* zero-fill the rest */</span>
<span class="p_del">-		if (clear_user(ptr + size, bytecount - size) != 0) {</span>
<span class="p_del">-			err = -EFAULT;</span>
<span class="p_del">-			goto error_return;</span>
<span class="p_add">+		/* Zero-fill the rest and pretend we read bytecount bytes. */</span>
<span class="p_add">+		if (clear_user(ptr + size, bytecount - size)) {</span>
<span class="p_add">+			retval = -EFAULT;</span>
<span class="p_add">+			goto out_unlock;</span>
 		}
 	}
<span class="p_del">-	return bytecount;</span>
<span class="p_del">-error_return:</span>
<span class="p_del">-	return err;</span>
<span class="p_add">+	retval = bytecount;</span>
<span class="p_add">+</span>
<span class="p_add">+out_unlock:</span>
<span class="p_add">+	mutex_unlock(&amp;mm-&gt;context.lock);</span>
<span class="p_add">+	return retval;</span>
 }
 
 static int read_default_ldt(void __user *ptr, unsigned long bytecount)
<span class="p_chunk">@@ -195,6 +210,8 @@</span> <span class="p_context"> static int write_ldt(void __user *ptr, unsigned long bytecount, int oldmode)</span>
 	struct desc_struct ldt;
 	int error;
 	struct user_desc ldt_info;
<span class="p_add">+	int oldsize, newsize;</span>
<span class="p_add">+	struct ldt_struct *new_ldt, *old_ldt;</span>
 
 	error = -EINVAL;
 	if (bytecount != sizeof(ldt_info))
<span class="p_chunk">@@ -213,34 +230,39 @@</span> <span class="p_context"> static int write_ldt(void __user *ptr, unsigned long bytecount, int oldmode)</span>
 			goto out;
 	}
 
<span class="p_del">-	mutex_lock(&amp;mm-&gt;context.lock);</span>
<span class="p_del">-	if (ldt_info.entry_number &gt;= mm-&gt;context.size) {</span>
<span class="p_del">-		error = alloc_ldt(&amp;current-&gt;mm-&gt;context,</span>
<span class="p_del">-				  ldt_info.entry_number + 1, 1);</span>
<span class="p_del">-		if (error &lt; 0)</span>
<span class="p_del">-			goto out_unlock;</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">-	/* Allow LDTs to be cleared by the user. */</span>
<span class="p_del">-	if (ldt_info.base_addr == 0 &amp;&amp; ldt_info.limit == 0) {</span>
<span class="p_del">-		if (oldmode || LDT_empty(&amp;ldt_info)) {</span>
<span class="p_del">-			memset(&amp;ldt, 0, sizeof(ldt));</span>
<span class="p_del">-			goto install;</span>
<span class="p_add">+	if ((oldmode &amp;&amp; !ldt_info.base_addr &amp;&amp; !ldt_info.limit) ||</span>
<span class="p_add">+	    LDT_empty(&amp;ldt_info)) {</span>
<span class="p_add">+		/* The user wants to clear the entry. */</span>
<span class="p_add">+		memset(&amp;ldt, 0, sizeof(ldt));</span>
<span class="p_add">+	} else {</span>
<span class="p_add">+		if (!IS_ENABLED(CONFIG_X86_16BIT) &amp;&amp; !ldt_info.seg_32bit) {</span>
<span class="p_add">+			error = -EINVAL;</span>
<span class="p_add">+			goto out;</span>
 		}
<span class="p_add">+</span>
<span class="p_add">+		fill_ldt(&amp;ldt, &amp;ldt_info);</span>
<span class="p_add">+		if (oldmode)</span>
<span class="p_add">+			ldt.avl = 0;</span>
 	}
 
<span class="p_del">-	if (!IS_ENABLED(CONFIG_X86_16BIT) &amp;&amp; !ldt_info.seg_32bit) {</span>
<span class="p_del">-		error = -EINVAL;</span>
<span class="p_add">+	mutex_lock(&amp;mm-&gt;context.lock);</span>
<span class="p_add">+</span>
<span class="p_add">+	old_ldt = mm-&gt;context.ldt;</span>
<span class="p_add">+	oldsize = old_ldt ? old_ldt-&gt;size : 0;</span>
<span class="p_add">+	newsize = max((int)(ldt_info.entry_number + 1), oldsize);</span>
<span class="p_add">+</span>
<span class="p_add">+	error = -ENOMEM;</span>
<span class="p_add">+	new_ldt = alloc_ldt_struct(newsize);</span>
<span class="p_add">+	if (!new_ldt)</span>
 		goto out_unlock;
<span class="p_del">-	}</span>
 
<span class="p_del">-	fill_ldt(&amp;ldt, &amp;ldt_info);</span>
<span class="p_del">-	if (oldmode)</span>
<span class="p_del">-		ldt.avl = 0;</span>
<span class="p_add">+	if (old_ldt)</span>
<span class="p_add">+		memcpy(new_ldt-&gt;entries, old_ldt-&gt;entries, oldsize * LDT_ENTRY_SIZE);</span>
<span class="p_add">+	new_ldt-&gt;entries[ldt_info.entry_number] = ldt;</span>
<span class="p_add">+	finalize_ldt_struct(new_ldt);</span>
 
<span class="p_del">-	/* Install the new entry ...  */</span>
<span class="p_del">-install:</span>
<span class="p_del">-	write_ldt_entry(mm-&gt;context.ldt, ldt_info.entry_number, &amp;ldt);</span>
<span class="p_add">+	install_ldt(mm, new_ldt);</span>
<span class="p_add">+	free_ldt_struct(old_ldt);</span>
 	error = 0;
 
 out_unlock:
<span class="p_header">diff --git a/arch/x86/kernel/process_64.c b/arch/x86/kernel/process_64.c</span>
<span class="p_header">index 5a2c029..ec03938 100644</span>
<span class="p_header">--- a/arch/x86/kernel/process_64.c</span>
<span class="p_header">+++ b/arch/x86/kernel/process_64.c</span>
<span class="p_chunk">@@ -122,11 +122,11 @@</span> <span class="p_context"> void __show_regs(struct pt_regs *regs, int all)</span>
 void release_thread(struct task_struct *dead_task)
 {
 	if (dead_task-&gt;mm) {
<span class="p_del">-		if (dead_task-&gt;mm-&gt;context.size) {</span>
<span class="p_add">+		if (dead_task-&gt;mm-&gt;context.ldt) {</span>
 			pr_warn(&quot;WARNING: dead process %s still has LDT? &lt;%p/%d&gt;\n&quot;,
 				dead_task-&gt;comm,
 				dead_task-&gt;mm-&gt;context.ldt,
<span class="p_del">-				dead_task-&gt;mm-&gt;context.size);</span>
<span class="p_add">+				dead_task-&gt;mm-&gt;context.ldt-&gt;size);</span>
 			BUG();
 		}
 	}
<span class="p_header">diff --git a/arch/x86/kernel/step.c b/arch/x86/kernel/step.c</span>
<span class="p_header">index 9b4d51d..0ccb53a 100644</span>
<span class="p_header">--- a/arch/x86/kernel/step.c</span>
<span class="p_header">+++ b/arch/x86/kernel/step.c</span>
<span class="p_chunk">@@ -5,6 +5,7 @@</span> <span class="p_context"></span>
 #include &lt;linux/mm.h&gt;
 #include &lt;linux/ptrace.h&gt;
 #include &lt;asm/desc.h&gt;
<span class="p_add">+#include &lt;asm/mmu_context.h&gt;</span>
 
 unsigned long convert_ip_to_linear(struct task_struct *child, struct pt_regs *regs)
 {
<span class="p_chunk">@@ -27,13 +28,14 @@</span> <span class="p_context"> unsigned long convert_ip_to_linear(struct task_struct *child, struct pt_regs *re</span>
 		struct desc_struct *desc;
 		unsigned long base;
 
<span class="p_del">-		seg &amp;= ~7UL;</span>
<span class="p_add">+		seg &gt;&gt;= 3;</span>
 
 		mutex_lock(&amp;child-&gt;mm-&gt;context.lock);
<span class="p_del">-		if (unlikely((seg &gt;&gt; 3) &gt;= child-&gt;mm-&gt;context.size))</span>
<span class="p_add">+		if (unlikely(!child-&gt;mm-&gt;context.ldt ||</span>
<span class="p_add">+			     seg &gt;= child-&gt;mm-&gt;context.ldt-&gt;size))</span>
 			addr = -1L; /* bogus selector, access would fault */
 		else {
<span class="p_del">-			desc = child-&gt;mm-&gt;context.ldt + seg;</span>
<span class="p_add">+			desc = &amp;child-&gt;mm-&gt;context.ldt-&gt;entries[seg];</span>
 			base = get_desc_base(desc);
 
 			/* 16-bit code segment? */
<span class="p_header">diff --git a/arch/x86/kvm/x86.c b/arch/x86/kvm/x86.c</span>
<span class="p_header">index a692f1c..57d5915 100644</span>
<span class="p_header">--- a/arch/x86/kvm/x86.c</span>
<span class="p_header">+++ b/arch/x86/kvm/x86.c</span>
<span class="p_chunk">@@ -2143,7 +2143,7 @@</span> <span class="p_context"> int kvm_set_msr_common(struct kvm_vcpu *vcpu, struct msr_data *msr_info)</span>
 		if (guest_cpuid_has_tsc_adjust(vcpu)) {
 			if (!msr_info-&gt;host_initiated) {
 				s64 adj = data - vcpu-&gt;arch.ia32_tsc_adjust_msr;
<span class="p_del">-				kvm_x86_ops-&gt;adjust_tsc_offset(vcpu, adj, true);</span>
<span class="p_add">+				adjust_tsc_offset_guest(vcpu, adj);</span>
 			}
 			vcpu-&gt;arch.ia32_tsc_adjust_msr = data;
 		}
<span class="p_header">diff --git a/arch/x86/math-emu/fpu_entry.c b/arch/x86/math-emu/fpu_entry.c</span>
<span class="p_header">index 9b86812..274a52b 100644</span>
<span class="p_header">--- a/arch/x86/math-emu/fpu_entry.c</span>
<span class="p_header">+++ b/arch/x86/math-emu/fpu_entry.c</span>
<span class="p_chunk">@@ -29,7 +29,6 @@</span> <span class="p_context"></span>
 
 #include &lt;asm/uaccess.h&gt;
 #include &lt;asm/traps.h&gt;
<span class="p_del">-#include &lt;asm/desc.h&gt;</span>
 #include &lt;asm/user.h&gt;
 #include &lt;asm/i387.h&gt;
 
<span class="p_chunk">@@ -185,7 +184,7 @@</span> <span class="p_context"> void math_emulate(struct math_emu_info *info)</span>
 			math_abort(FPU_info, SIGILL);
 		}
 
<span class="p_del">-		code_descriptor = LDT_DESCRIPTOR(FPU_CS);</span>
<span class="p_add">+		code_descriptor = FPU_get_ldt_descriptor(FPU_CS);</span>
 		if (SEG_D_SIZE(code_descriptor)) {
 			/* The above test may be wrong, the book is not clear */
 			/* Segmented 32 bit protected mode */
<span class="p_header">diff --git a/arch/x86/math-emu/fpu_system.h b/arch/x86/math-emu/fpu_system.h</span>
<span class="p_header">index 2c61441..d342fce 100644</span>
<span class="p_header">--- a/arch/x86/math-emu/fpu_system.h</span>
<span class="p_header">+++ b/arch/x86/math-emu/fpu_system.h</span>
<span class="p_chunk">@@ -16,9 +16,24 @@</span> <span class="p_context"></span>
 #include &lt;linux/kernel.h&gt;
 #include &lt;linux/mm.h&gt;
 
<span class="p_del">-/* s is always from a cpu register, and the cpu does bounds checking</span>
<span class="p_del">- * during register load --&gt; no further bounds checks needed */</span>
<span class="p_del">-#define LDT_DESCRIPTOR(s)	(((struct desc_struct *)current-&gt;mm-&gt;context.ldt)[(s) &gt;&gt; 3])</span>
<span class="p_add">+#include &lt;asm/desc.h&gt;</span>
<span class="p_add">+#include &lt;asm/mmu_context.h&gt;</span>
<span class="p_add">+</span>
<span class="p_add">+static inline struct desc_struct FPU_get_ldt_descriptor(unsigned seg)</span>
<span class="p_add">+{</span>
<span class="p_add">+	static struct desc_struct zero_desc;</span>
<span class="p_add">+	struct desc_struct ret = zero_desc;</span>
<span class="p_add">+</span>
<span class="p_add">+#ifdef CONFIG_MODIFY_LDT_SYSCALL</span>
<span class="p_add">+	seg &gt;&gt;= 3;</span>
<span class="p_add">+	mutex_lock(&amp;current-&gt;mm-&gt;context.lock);</span>
<span class="p_add">+	if (current-&gt;mm-&gt;context.ldt &amp;&amp; seg &lt; current-&gt;mm-&gt;context.ldt-&gt;size)</span>
<span class="p_add">+		ret = current-&gt;mm-&gt;context.ldt-&gt;entries[seg];</span>
<span class="p_add">+	mutex_unlock(&amp;current-&gt;mm-&gt;context.lock);</span>
<span class="p_add">+#endif</span>
<span class="p_add">+	return ret;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 #define SEG_D_SIZE(x)		((x).b &amp; (3 &lt;&lt; 21))
 #define SEG_G_BIT(x)		((x).b &amp; (1 &lt;&lt; 23))
 #define SEG_GRANULARITY(x)	(((x).b &amp; (1 &lt;&lt; 23)) ? 4096 : 1)
<span class="p_header">diff --git a/arch/x86/math-emu/get_address.c b/arch/x86/math-emu/get_address.c</span>
<span class="p_header">index 6ef5e99..8300db7 100644</span>
<span class="p_header">--- a/arch/x86/math-emu/get_address.c</span>
<span class="p_header">+++ b/arch/x86/math-emu/get_address.c</span>
<span class="p_chunk">@@ -20,7 +20,6 @@</span> <span class="p_context"></span>
 #include &lt;linux/stddef.h&gt;
 
 #include &lt;asm/uaccess.h&gt;
<span class="p_del">-#include &lt;asm/desc.h&gt;</span>
 
 #include &quot;fpu_system.h&quot;
 #include &quot;exception.h&quot;
<span class="p_chunk">@@ -158,7 +157,7 @@</span> <span class="p_context"> static long pm_address(u_char FPU_modrm, u_char segment,</span>
 		addr-&gt;selector = PM_REG_(segment);
 	}
 
<span class="p_del">-	descriptor = LDT_DESCRIPTOR(PM_REG_(segment));</span>
<span class="p_add">+	descriptor = FPU_get_ldt_descriptor(addr-&gt;selector);</span>
 	base_address = SEG_BASE_ADDR(descriptor);
 	address = base_address + offset;
 	limit = base_address
<span class="p_header">diff --git a/arch/x86/power/cpu.c b/arch/x86/power/cpu.c</span>
<span class="p_header">index 6ec7910..f846180 100644</span>
<span class="p_header">--- a/arch/x86/power/cpu.c</span>
<span class="p_header">+++ b/arch/x86/power/cpu.c</span>
<span class="p_chunk">@@ -23,6 +23,7 @@</span> <span class="p_context"></span>
 #include &lt;asm/debugreg.h&gt;
 #include &lt;asm/fpu-internal.h&gt; /* pcntxt_mask */
 #include &lt;asm/cpu.h&gt;
<span class="p_add">+#include &lt;asm/mmu_context.h&gt;</span>
 
 #ifdef CONFIG_X86_32
 __visible unsigned long saved_context_ebx;
<span class="p_chunk">@@ -157,7 +158,7 @@</span> <span class="p_context"> static void fix_processor_context(void)</span>
 	syscall_init();				/* This sets MSR_*STAR and related */
 #endif
 	load_TR_desc();				/* This does ltr */
<span class="p_del">-	load_LDT(&amp;current-&gt;active_mm-&gt;context);	/* This does lldt */</span>
<span class="p_add">+	load_mm_ldt(current-&gt;active_mm);	/* This does lldt */</span>
 }
 
 /**
<span class="p_header">diff --git a/arch/x86/xen/Kconfig b/arch/x86/xen/Kconfig</span>
<span class="p_header">index e88fda8..4841453 100644</span>
<span class="p_header">--- a/arch/x86/xen/Kconfig</span>
<span class="p_header">+++ b/arch/x86/xen/Kconfig</span>
<span class="p_chunk">@@ -8,7 +8,7 @@</span> <span class="p_context"> config XEN</span>
 	select PARAVIRT_CLOCK
 	select XEN_HAVE_PVMMU
 	depends on X86_64 || (X86_32 &amp;&amp; X86_PAE)
<span class="p_del">-	depends on X86_TSC</span>
<span class="p_add">+	depends on X86_LOCAL_APIC &amp;&amp; X86_TSC</span>
 	help
 	  This is the Linux Xen port.  Enabling this will allow the
 	  kernel to boot in a paravirtualized environment under the
<span class="p_chunk">@@ -17,7 +17,7 @@</span> <span class="p_context"> config XEN</span>
 config XEN_DOM0
 	def_bool y
 	depends on XEN &amp;&amp; PCI_XEN &amp;&amp; SWIOTLB_XEN
<span class="p_del">-	depends on X86_LOCAL_APIC &amp;&amp; X86_IO_APIC &amp;&amp; ACPI &amp;&amp; PCI</span>
<span class="p_add">+	depends on X86_IO_APIC &amp;&amp; ACPI &amp;&amp; PCI</span>
 
 config XEN_PVHVM
 	def_bool y
<span class="p_header">diff --git a/arch/x86/xen/Makefile b/arch/x86/xen/Makefile</span>
<span class="p_header">index 7322755..4b6e29a 100644</span>
<span class="p_header">--- a/arch/x86/xen/Makefile</span>
<span class="p_header">+++ b/arch/x86/xen/Makefile</span>
<span class="p_chunk">@@ -13,13 +13,13 @@</span> <span class="p_context"> CFLAGS_mmu.o			:= $(nostackp)</span>
 obj-y		:= enlighten.o setup.o multicalls.o mmu.o irq.o \
 			time.o xen-asm.o xen-asm_$(BITS).o \
 			grant-table.o suspend.o platform-pci-unplug.o \
<span class="p_del">-			p2m.o</span>
<span class="p_add">+			p2m.o apic.o</span>
 
 obj-$(CONFIG_EVENT_TRACING) += trace.o
 
 obj-$(CONFIG_SMP)		+= smp.o
 obj-$(CONFIG_PARAVIRT_SPINLOCKS)+= spinlock.o
 obj-$(CONFIG_XEN_DEBUG_FS)	+= debugfs.o
<span class="p_del">-obj-$(CONFIG_XEN_DOM0)		+= apic.o vga.o</span>
<span class="p_add">+obj-$(CONFIG_XEN_DOM0)		+= vga.o</span>
 obj-$(CONFIG_SWIOTLB_XEN)	+= pci-swiotlb-xen.o
 obj-$(CONFIG_XEN_EFI)		+= efi.o
<span class="p_header">diff --git a/arch/x86/xen/xen-ops.h b/arch/x86/xen/xen-ops.h</span>
<span class="p_header">index 5686bd9..68bf9bc 100644</span>
<span class="p_header">--- a/arch/x86/xen/xen-ops.h</span>
<span class="p_header">+++ b/arch/x86/xen/xen-ops.h</span>
<span class="p_chunk">@@ -95,17 +95,15 @@</span> <span class="p_context"> struct dom0_vga_console_info;</span>
 
 #ifdef CONFIG_XEN_DOM0
 void __init xen_init_vga(const struct dom0_vga_console_info *, size_t size);
<span class="p_del">-void __init xen_init_apic(void);</span>
 #else
 static inline void __init xen_init_vga(const struct dom0_vga_console_info *info,
 				       size_t size)
 {
 }
<span class="p_del">-static inline void __init xen_init_apic(void)</span>
<span class="p_del">-{</span>
<span class="p_del">-}</span>
 #endif
 
<span class="p_add">+void __init xen_init_apic(void);</span>
<span class="p_add">+</span>
 #ifdef CONFIG_XEN_EFI
 extern void xen_efi_init(void);
 #else
<span class="p_header">diff --git a/block/blk-settings.c b/block/blk-settings.c</span>
<span class="p_header">index 12600bf..e0057d0 100644</span>
<span class="p_header">--- a/block/blk-settings.c</span>
<span class="p_header">+++ b/block/blk-settings.c</span>
<span class="p_chunk">@@ -241,8 +241,8 @@</span> <span class="p_context"> EXPORT_SYMBOL(blk_queue_bounce_limit);</span>
  * Description:
  *    Enables a low level driver to set a hard upper limit,
  *    max_hw_sectors, on the size of requests.  max_hw_sectors is set by
<span class="p_del">- *    the device driver based upon the combined capabilities of I/O</span>
<span class="p_del">- *    controller and storage device.</span>
<span class="p_add">+ *    the device driver based upon the capabilities of the I/O</span>
<span class="p_add">+ *    controller.</span>
  *
  *    max_sectors is a soft limit imposed by the block layer for
  *    filesystem type requests.  This value can be overridden on a
<span class="p_header">diff --git a/drivers/acpi/pci_link.c b/drivers/acpi/pci_link.c</span>
<span class="p_header">index cfd7581..b09ad55 100644</span>
<span class="p_header">--- a/drivers/acpi/pci_link.c</span>
<span class="p_header">+++ b/drivers/acpi/pci_link.c</span>
<span class="p_chunk">@@ -826,6 +826,22 @@</span> <span class="p_context"> void acpi_penalize_isa_irq(int irq, int active)</span>
 }
 
 /*
<span class="p_add">+ * Penalize IRQ used by ACPI SCI. If ACPI SCI pin attributes conflict with</span>
<span class="p_add">+ * PCI IRQ attributes, mark ACPI SCI as ISA_ALWAYS so it won&#39;t be use for</span>
<span class="p_add">+ * PCI IRQs.</span>
<span class="p_add">+ */</span>
<span class="p_add">+void acpi_penalize_sci_irq(int irq, int trigger, int polarity)</span>
<span class="p_add">+{</span>
<span class="p_add">+	if (irq &gt;= 0 &amp;&amp; irq &lt; ARRAY_SIZE(acpi_irq_penalty)) {</span>
<span class="p_add">+		if (trigger != ACPI_MADT_TRIGGER_LEVEL ||</span>
<span class="p_add">+		    polarity != ACPI_MADT_POLARITY_ACTIVE_LOW)</span>
<span class="p_add">+			acpi_irq_penalty[irq] += PIRQ_PENALTY_ISA_ALWAYS;</span>
<span class="p_add">+		else</span>
<span class="p_add">+			acpi_irq_penalty[irq] += PIRQ_PENALTY_PCI_USING;</span>
<span class="p_add">+	}</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+/*</span>
  * Over-ride default table to reserve additional IRQs for use by ISA
  * e.g. acpi_irq_isa=5
  * Useful for telling ACPI how not to interfere with your ISA sound card.
<span class="p_header">diff --git a/drivers/ata/libata-core.c b/drivers/ata/libata-core.c</span>
<span class="p_header">index da7d05e..e097efe 100644</span>
<span class="p_header">--- a/drivers/ata/libata-core.c</span>
<span class="p_header">+++ b/drivers/ata/libata-core.c</span>
<span class="p_chunk">@@ -4256,6 +4256,8 @@</span> <span class="p_context"> static const struct ata_blacklist_entry ata_device_blacklist [] = {</span>
 						ATA_HORKAGE_ZERO_AFTER_TRIM, },
 	{ &quot;Samsung SSD 8*&quot;,		NULL,	ATA_HORKAGE_NO_NCQ_TRIM |
 						ATA_HORKAGE_ZERO_AFTER_TRIM, },
<span class="p_add">+	{ &quot;FCCT*M500*&quot;,			NULL,	ATA_HORKAGE_NO_NCQ_TRIM |</span>
<span class="p_add">+						ATA_HORKAGE_ZERO_AFTER_TRIM, },</span>
 
 	/* devices that don&#39;t properly handle TRIM commands */
 	{ &quot;SuperSSpeed S238*&quot;,		NULL,	ATA_HORKAGE_NOTRIM, },
<span class="p_header">diff --git a/drivers/base/regmap/regcache-rbtree.c b/drivers/base/regmap/regcache-rbtree.c</span>
<span class="p_header">index 81751a4..56486d9 100644</span>
<span class="p_header">--- a/drivers/base/regmap/regcache-rbtree.c</span>
<span class="p_header">+++ b/drivers/base/regmap/regcache-rbtree.c</span>
<span class="p_chunk">@@ -296,11 +296,20 @@</span> <span class="p_context"> static int regcache_rbtree_insert_to_block(struct regmap *map,</span>
 	if (!blk)
 		return -ENOMEM;
 
<span class="p_del">-	present = krealloc(rbnode-&gt;cache_present,</span>
<span class="p_del">-		    BITS_TO_LONGS(blklen) * sizeof(*present), GFP_KERNEL);</span>
<span class="p_del">-	if (!present) {</span>
<span class="p_del">-		kfree(blk);</span>
<span class="p_del">-		return -ENOMEM;</span>
<span class="p_add">+	if (BITS_TO_LONGS(blklen) &gt; BITS_TO_LONGS(rbnode-&gt;blklen)) {</span>
<span class="p_add">+		present = krealloc(rbnode-&gt;cache_present,</span>
<span class="p_add">+				   BITS_TO_LONGS(blklen) * sizeof(*present),</span>
<span class="p_add">+				   GFP_KERNEL);</span>
<span class="p_add">+		if (!present) {</span>
<span class="p_add">+			kfree(blk);</span>
<span class="p_add">+			return -ENOMEM;</span>
<span class="p_add">+		}</span>
<span class="p_add">+</span>
<span class="p_add">+		memset(present + BITS_TO_LONGS(rbnode-&gt;blklen), 0,</span>
<span class="p_add">+		       (BITS_TO_LONGS(blklen) - BITS_TO_LONGS(rbnode-&gt;blklen))</span>
<span class="p_add">+		       * sizeof(*present));</span>
<span class="p_add">+	} else {</span>
<span class="p_add">+		present = rbnode-&gt;cache_present;</span>
 	}
 
 	/* insert the register value in the correct place in the rbnode block */
<span class="p_header">diff --git a/drivers/block/rbd.c b/drivers/block/rbd.c</span>
<span class="p_header">index 0c4ede9..f33ff6c 100644</span>
<span class="p_header">--- a/drivers/block/rbd.c</span>
<span class="p_header">+++ b/drivers/block/rbd.c</span>
<span class="p_chunk">@@ -520,6 +520,7 @@</span> <span class="p_context"> void rbd_warn(struct rbd_device *rbd_dev, const char *fmt, ...)</span>
 #  define rbd_assert(expr)	((void) 0)
 #endif /* !RBD_DEBUG */
 
<span class="p_add">+static void rbd_osd_copyup_callback(struct rbd_obj_request *obj_request);</span>
 static int rbd_img_obj_request_submit(struct rbd_obj_request *obj_request);
 static void rbd_img_parent_read(struct rbd_obj_request *obj_request);
 static void rbd_dev_remove_parent(struct rbd_device *rbd_dev);
<span class="p_chunk">@@ -1795,6 +1796,16 @@</span> <span class="p_context"> static void rbd_osd_stat_callback(struct rbd_obj_request *obj_request)</span>
 	obj_request_done_set(obj_request);
 }
 
<span class="p_add">+static void rbd_osd_call_callback(struct rbd_obj_request *obj_request)</span>
<span class="p_add">+{</span>
<span class="p_add">+	dout(&quot;%s: obj %p\n&quot;, __func__, obj_request);</span>
<span class="p_add">+</span>
<span class="p_add">+	if (obj_request_img_data_test(obj_request))</span>
<span class="p_add">+		rbd_osd_copyup_callback(obj_request);</span>
<span class="p_add">+	else</span>
<span class="p_add">+		obj_request_done_set(obj_request);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static void rbd_osd_req_callback(struct ceph_osd_request *osd_req,
 				struct ceph_msg *msg)
 {
<span class="p_chunk">@@ -1842,6 +1853,8 @@</span> <span class="p_context"> static void rbd_osd_req_callback(struct ceph_osd_request *osd_req,</span>
 		rbd_osd_discard_callback(obj_request);
 		break;
 	case CEPH_OSD_OP_CALL:
<span class="p_add">+		rbd_osd_call_callback(obj_request);</span>
<span class="p_add">+		break;</span>
 	case CEPH_OSD_OP_NOTIFY_ACK:
 	case CEPH_OSD_OP_WATCH:
 		rbd_osd_trivial_callback(obj_request);
<span class="p_chunk">@@ -2503,13 +2516,15 @@</span> <span class="p_context"> out_unwind:</span>
 }
 
 static void
<span class="p_del">-rbd_img_obj_copyup_callback(struct rbd_obj_request *obj_request)</span>
<span class="p_add">+rbd_osd_copyup_callback(struct rbd_obj_request *obj_request)</span>
 {
 	struct rbd_img_request *img_request;
 	struct rbd_device *rbd_dev;
 	struct page **pages;
 	u32 page_count;
 
<span class="p_add">+	dout(&quot;%s: obj %p\n&quot;, __func__, obj_request);</span>
<span class="p_add">+</span>
 	rbd_assert(obj_request-&gt;type == OBJ_REQUEST_BIO ||
 		obj_request-&gt;type == OBJ_REQUEST_NODATA);
 	rbd_assert(obj_request_img_data_test(obj_request));
<span class="p_chunk">@@ -2536,9 +2551,7 @@</span> <span class="p_context"> rbd_img_obj_copyup_callback(struct rbd_obj_request *obj_request)</span>
 	if (!obj_request-&gt;result)
 		obj_request-&gt;xferred = obj_request-&gt;length;
 
<span class="p_del">-	/* Finish up with the normal image object callback */</span>
<span class="p_del">-</span>
<span class="p_del">-	rbd_img_obj_callback(obj_request);</span>
<span class="p_add">+	obj_request_done_set(obj_request);</span>
 }
 
 static void
<span class="p_chunk">@@ -2623,7 +2636,6 @@</span> <span class="p_context"> rbd_img_obj_parent_read_full_callback(struct rbd_img_request *img_request)</span>
 
 	/* All set, send it off. */
 
<span class="p_del">-	orig_request-&gt;callback = rbd_img_obj_copyup_callback;</span>
 	osdc = &amp;rbd_dev-&gt;rbd_client-&gt;client-&gt;osdc;
 	img_result = rbd_obj_request_submit(osdc, orig_request);
 	if (!img_result)
<span class="p_header">diff --git a/drivers/block/xen-blkback/blkback.c b/drivers/block/xen-blkback/blkback.c</span>
<span class="p_header">index 63fc7f0..02004e1 100644</span>
<span class="p_header">--- a/drivers/block/xen-blkback/blkback.c</span>
<span class="p_header">+++ b/drivers/block/xen-blkback/blkback.c</span>
<span class="p_chunk">@@ -350,8 +350,8 @@</span> <span class="p_context"> static void purge_persistent_gnt(struct xen_blkif *blkif)</span>
 		return;
 	}
 
<span class="p_del">-	if (work_pending(&amp;blkif-&gt;persistent_purge_work)) {</span>
<span class="p_del">-		pr_alert_ratelimited(DRV_PFX &quot;Scheduled work from previous purge is still pending, cannot purge list\n&quot;);</span>
<span class="p_add">+	if (work_busy(&amp;blkif-&gt;persistent_purge_work)) {</span>
<span class="p_add">+		pr_alert_ratelimited(DRV_PFX &quot;Scheduled work from previous purge is still busy, cannot purge list\n&quot;);</span>
 		return;
 	}
 
<span class="p_header">diff --git a/drivers/block/xen-blkfront.c b/drivers/block/xen-blkfront.c</span>
<span class="p_header">index 2236c6f..7afb9ed 100644</span>
<span class="p_header">--- a/drivers/block/xen-blkfront.c</span>
<span class="p_header">+++ b/drivers/block/xen-blkfront.c</span>
<span class="p_chunk">@@ -1118,8 +1118,10 @@</span> <span class="p_context"> static void blkif_completion(struct blk_shadow *s, struct blkfront_info *info,</span>
 				 * Add the used indirect page back to the list of
 				 * available pages for indirect grefs.
 				 */
<span class="p_del">-				indirect_page = pfn_to_page(s-&gt;indirect_grants[i]-&gt;pfn);</span>
<span class="p_del">-				list_add(&amp;indirect_page-&gt;lru, &amp;info-&gt;indirect_pages);</span>
<span class="p_add">+				if (!info-&gt;feature_persistent) {</span>
<span class="p_add">+					indirect_page = pfn_to_page(s-&gt;indirect_grants[i]-&gt;pfn);</span>
<span class="p_add">+					list_add(&amp;indirect_page-&gt;lru, &amp;info-&gt;indirect_pages);</span>
<span class="p_add">+				}</span>
 				s-&gt;indirect_grants[i]-&gt;gref = GRANT_INVALID_REF;
 				list_add_tail(&amp;s-&gt;indirect_grants[i]-&gt;node, &amp;info-&gt;grants);
 			}
<span class="p_header">diff --git a/drivers/char/hw_random/core.c b/drivers/char/hw_random/core.c</span>
<span class="p_header">index 1500cfd..b98fb25 100644</span>
<span class="p_header">--- a/drivers/char/hw_random/core.c</span>
<span class="p_header">+++ b/drivers/char/hw_random/core.c</span>
<span class="p_chunk">@@ -361,7 +361,7 @@</span> <span class="p_context"> static int hwrng_fillfn(void *unused)</span>
 static void start_khwrngd(void)
 {
 	hwrng_fill = kthread_run(hwrng_fillfn, NULL, &quot;hwrng&quot;);
<span class="p_del">-	if (hwrng_fill == ERR_PTR(-ENOMEM)) {</span>
<span class="p_add">+	if (IS_ERR(hwrng_fill)) {</span>
 		pr_err(&quot;hwrng_fill thread creation failed&quot;);
 		hwrng_fill = NULL;
 	}
<span class="p_header">diff --git a/drivers/char/ipmi/ipmi_powernv.c b/drivers/char/ipmi/ipmi_powernv.c</span>
<span class="p_header">index 79524ed..8753b0f 100644</span>
<span class="p_header">--- a/drivers/char/ipmi/ipmi_powernv.c</span>
<span class="p_header">+++ b/drivers/char/ipmi/ipmi_powernv.c</span>
<span class="p_chunk">@@ -125,6 +125,7 @@</span> <span class="p_context"> static int ipmi_powernv_recv(struct ipmi_smi_powernv *smi)</span>
 	spin_lock_irqsave(&amp;smi-&gt;msg_lock, flags);
 
 	if (!smi-&gt;cur_msg) {
<span class="p_add">+		spin_unlock_irqrestore(&amp;smi-&gt;msg_lock, flags);</span>
 		pr_warn(&quot;no current message?\n&quot;);
 		return 0;
 	}
<span class="p_header">diff --git a/drivers/crypto/caam/caamhash.c b/drivers/crypto/caam/caamhash.c</span>
<span class="p_header">index 08b0da2..5408450 100644</span>
<span class="p_header">--- a/drivers/crypto/caam/caamhash.c</span>
<span class="p_header">+++ b/drivers/crypto/caam/caamhash.c</span>
<span class="p_chunk">@@ -909,13 +909,14 @@</span> <span class="p_context"> static int ahash_final_ctx(struct ahash_request *req)</span>
 			  state-&gt;buflen_1;
 	u32 *sh_desc = ctx-&gt;sh_desc_fin, *desc;
 	dma_addr_t ptr = ctx-&gt;sh_desc_fin_dma;
<span class="p_del">-	int sec4_sg_bytes;</span>
<span class="p_add">+	int sec4_sg_bytes, sec4_sg_src_index;</span>
 	int digestsize = crypto_ahash_digestsize(ahash);
 	struct ahash_edesc *edesc;
 	int ret = 0;
 	int sh_len;
 
<span class="p_del">-	sec4_sg_bytes = (1 + (buflen ? 1 : 0)) * sizeof(struct sec4_sg_entry);</span>
<span class="p_add">+	sec4_sg_src_index = 1 + (buflen ? 1 : 0);</span>
<span class="p_add">+	sec4_sg_bytes = sec4_sg_src_index * sizeof(struct sec4_sg_entry);</span>
 
 	/* allocate space for base edesc and hw desc commands, link tables */
 	edesc = kmalloc(sizeof(struct ahash_edesc) + DESC_JOB_IO_LEN +
<span class="p_chunk">@@ -942,7 +943,7 @@</span> <span class="p_context"> static int ahash_final_ctx(struct ahash_request *req)</span>
 	state-&gt;buf_dma = try_buf_map_to_sec4_sg(jrdev, edesc-&gt;sec4_sg + 1,
 						buf, state-&gt;buf_dma, buflen,
 						last_buflen);
<span class="p_del">-	(edesc-&gt;sec4_sg + sec4_sg_bytes - 1)-&gt;len |= SEC4_SG_LEN_FIN;</span>
<span class="p_add">+	(edesc-&gt;sec4_sg + sec4_sg_src_index - 1)-&gt;len |= SEC4_SG_LEN_FIN;</span>
 
 	edesc-&gt;sec4_sg_dma = dma_map_single(jrdev, edesc-&gt;sec4_sg,
 					    sec4_sg_bytes, DMA_TO_DEVICE);
<span class="p_header">diff --git a/drivers/crypto/ixp4xx_crypto.c b/drivers/crypto/ixp4xx_crypto.c</span>
<span class="p_header">index f757a0f..3beed38 100644</span>
<span class="p_header">--- a/drivers/crypto/ixp4xx_crypto.c</span>
<span class="p_header">+++ b/drivers/crypto/ixp4xx_crypto.c</span>
<span class="p_chunk">@@ -904,7 +904,6 @@</span> <span class="p_context"> static int ablk_perform(struct ablkcipher_request *req, int encrypt)</span>
 		crypt-&gt;mode |= NPE_OP_NOT_IN_PLACE;
 		/* This was never tested by Intel
 		 * for more than one dst buffer, I think. */
<span class="p_del">-		BUG_ON(req-&gt;dst-&gt;length &lt; nbytes);</span>
 		req_ctx-&gt;dst = NULL;
 		if (!chainup_buffers(dev, req-&gt;dst, nbytes, &amp;dst_hook,
 					flags, DMA_FROM_DEVICE))
<span class="p_header">diff --git a/drivers/crypto/qat/qat_common/qat_algs.c b/drivers/crypto/qat/qat_common/qat_algs.c</span>
<span class="p_header">index 19eea1c..8f4b6f1 100644</span>
<span class="p_header">--- a/drivers/crypto/qat/qat_common/qat_algs.c</span>
<span class="p_header">+++ b/drivers/crypto/qat/qat_common/qat_algs.c</span>
<span class="p_chunk">@@ -73,7 +73,8 @@</span> <span class="p_context"></span>
 			ICP_QAT_HW_CIPHER_KEY_CONVERT, \
 			ICP_QAT_HW_CIPHER_DECRYPT)
 
<span class="p_del">-static atomic_t active_dev;</span>
<span class="p_add">+static DEFINE_MUTEX(algs_lock);</span>
<span class="p_add">+static unsigned int active_devs;</span>
 
 struct qat_alg_buf {
 	uint32_t len;
<span class="p_chunk">@@ -962,27 +963,34 @@</span> <span class="p_context"> static struct crypto_alg qat_algs[] = { {</span>
 
 int qat_algs_register(void)
 {
<span class="p_del">-	if (atomic_add_return(1, &amp;active_dev) == 1) {</span>
<span class="p_add">+	int ret = 0;</span>
<span class="p_add">+</span>
<span class="p_add">+	mutex_lock(&amp;algs_lock);</span>
<span class="p_add">+	if (++active_devs == 1) {</span>
 		int i;
 
 		for (i = 0; i &lt; ARRAY_SIZE(qat_algs); i++)
 			qat_algs[i].cra_flags =	CRYPTO_ALG_TYPE_AEAD |
 						CRYPTO_ALG_ASYNC;
<span class="p_del">-		return crypto_register_algs(qat_algs, ARRAY_SIZE(qat_algs));</span>
<span class="p_add">+		ret = crypto_register_algs(qat_algs, ARRAY_SIZE(qat_algs));</span>
 	}
<span class="p_del">-	return 0;</span>
<span class="p_add">+	mutex_unlock(&amp;algs_lock);</span>
<span class="p_add">+	return ret;</span>
 }
 
 int qat_algs_unregister(void)
 {
<span class="p_del">-	if (atomic_sub_return(1, &amp;active_dev) == 0)</span>
<span class="p_del">-		return crypto_unregister_algs(qat_algs, ARRAY_SIZE(qat_algs));</span>
<span class="p_del">-	return 0;</span>
<span class="p_add">+	int ret = 0;</span>
<span class="p_add">+</span>
<span class="p_add">+	mutex_lock(&amp;algs_lock);</span>
<span class="p_add">+	if (--active_devs == 0)</span>
<span class="p_add">+		ret = crypto_unregister_algs(qat_algs, ARRAY_SIZE(qat_algs));</span>
<span class="p_add">+	mutex_unlock(&amp;algs_lock);</span>
<span class="p_add">+	return ret;</span>
 }
 
 int qat_algs_init(void)
 {
<span class="p_del">-	atomic_set(&amp;active_dev, 0);</span>
 	crypto_get_default_rng();
 	return 0;
 }
<span class="p_header">diff --git a/drivers/dma/pl330.c b/drivers/dma/pl330.c</span>
<span class="p_header">index c068ef1..bdf40b5 100644</span>
<span class="p_header">--- a/drivers/dma/pl330.c</span>
<span class="p_header">+++ b/drivers/dma/pl330.c</span>
<span class="p_chunk">@@ -2521,7 +2521,6 @@</span> <span class="p_context"> pl330_prep_dma_memcpy(struct dma_chan *chan, dma_addr_t dst,</span>
 		desc-&gt;rqcfg.brst_len = 1;
 
 	desc-&gt;rqcfg.brst_len = get_burst_len(desc, len);
<span class="p_del">-	desc-&gt;bytes_requested = len;</span>
 
 	desc-&gt;txd.flags = flags;
 
<span class="p_header">diff --git a/drivers/edac/ppc4xx_edac.c b/drivers/edac/ppc4xx_edac.c</span>
<span class="p_header">index 1b64fd0..e73d384 100644</span>
<span class="p_header">--- a/drivers/edac/ppc4xx_edac.c</span>
<span class="p_header">+++ b/drivers/edac/ppc4xx_edac.c</span>
<span class="p_chunk">@@ -920,7 +920,7 @@</span> <span class="p_context"> static int ppc4xx_edac_init_csrows(struct mem_ctl_info *mci, u32 mcopt1)</span>
 	 */
 
 	for (row = 0; row &lt; mci-&gt;nr_csrows; row++) {
<span class="p_del">-		struct csrow_info *csi = &amp;mci-&gt;csrows[row];</span>
<span class="p_add">+		struct csrow_info *csi = mci-&gt;csrows[row];</span>
 
 		/*
 		 * Get the configuration settings for this
<span class="p_header">diff --git a/drivers/gpu/drm/drm_dp_mst_topology.c b/drivers/gpu/drm/drm_dp_mst_topology.c</span>
<span class="p_header">index 30308ab..6c0a1b0 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/drm_dp_mst_topology.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/drm_dp_mst_topology.c</span>
<span class="p_chunk">@@ -869,9 +869,10 @@</span> <span class="p_context"> static void drm_dp_destroy_port(struct kref *kref)</span>
 		   from an EDID retrieval */
 		if (port-&gt;connector) {
 			mutex_lock(&amp;mgr-&gt;destroy_connector_lock);
<span class="p_del">-			list_add(&amp;port-&gt;connector-&gt;destroy_list, &amp;mgr-&gt;destroy_connector_list);</span>
<span class="p_add">+			list_add(&amp;port-&gt;next, &amp;mgr-&gt;destroy_connector_list);</span>
 			mutex_unlock(&amp;mgr-&gt;destroy_connector_lock);
 			schedule_work(&amp;mgr-&gt;destroy_connector_work);
<span class="p_add">+			return;</span>
 		}
 		drm_dp_port_teardown_pdt(port, port-&gt;pdt);
 
<span class="p_chunk">@@ -1290,7 +1291,6 @@</span> <span class="p_context"> retry:</span>
 				goto retry;
 			}
 			DRM_DEBUG_KMS(&quot;failed to dpcd write %d %d\n&quot;, tosend, ret);
<span class="p_del">-			WARN(1, &quot;fail\n&quot;);</span>
 
 			return -EIO;
 		}
<span class="p_chunk">@@ -2642,7 +2642,7 @@</span> <span class="p_context"> static void drm_dp_tx_work(struct work_struct *work)</span>
 static void drm_dp_destroy_connector_work(struct work_struct *work)
 {
 	struct drm_dp_mst_topology_mgr *mgr = container_of(work, struct drm_dp_mst_topology_mgr, destroy_connector_work);
<span class="p_del">-	struct drm_connector *connector;</span>
<span class="p_add">+	struct drm_dp_mst_port *port;</span>
 
 	/*
 	 * Not a regular list traverse as we have to drop the destroy
<span class="p_chunk">@@ -2651,15 +2651,21 @@</span> <span class="p_context"> static void drm_dp_destroy_connector_work(struct work_struct *work)</span>
 	 */
 	for (;;) {
 		mutex_lock(&amp;mgr-&gt;destroy_connector_lock);
<span class="p_del">-		connector = list_first_entry_or_null(&amp;mgr-&gt;destroy_connector_list, struct drm_connector, destroy_list);</span>
<span class="p_del">-		if (!connector) {</span>
<span class="p_add">+		port = list_first_entry_or_null(&amp;mgr-&gt;destroy_connector_list, struct drm_dp_mst_port, next);</span>
<span class="p_add">+		if (!port) {</span>
 			mutex_unlock(&amp;mgr-&gt;destroy_connector_lock);
 			break;
 		}
<span class="p_del">-		list_del(&amp;connector-&gt;destroy_list);</span>
<span class="p_add">+		list_del(&amp;port-&gt;next);</span>
 		mutex_unlock(&amp;mgr-&gt;destroy_connector_lock);
 
<span class="p_del">-		mgr-&gt;cbs-&gt;destroy_connector(mgr, connector);</span>
<span class="p_add">+		mgr-&gt;cbs-&gt;destroy_connector(mgr, port-&gt;connector);</span>
<span class="p_add">+</span>
<span class="p_add">+		drm_dp_port_teardown_pdt(port, port-&gt;pdt);</span>
<span class="p_add">+</span>
<span class="p_add">+		if (!port-&gt;input &amp;&amp; port-&gt;vcpi.vcpi &gt; 0)</span>
<span class="p_add">+			drm_dp_mst_put_payload_id(mgr, port-&gt;vcpi.vcpi);</span>
<span class="p_add">+		kfree(port);</span>
 	}
 }
 
<span class="p_header">diff --git a/drivers/gpu/drm/i915/intel_lrc.c b/drivers/gpu/drm/i915/intel_lrc.c</span>
<span class="p_header">index 5ebe805..2c5c00c 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/i915/intel_lrc.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/i915/intel_lrc.c</span>
<span class="p_chunk">@@ -849,6 +849,8 @@</span> <span class="p_context"> static int intel_lr_context_pin(struct intel_engine_cs *ring,</span>
 		ret = intel_pin_and_map_ringbuffer_obj(ring-&gt;dev, ringbuf);
 		if (ret)
 			goto unpin_ctx_obj;
<span class="p_add">+</span>
<span class="p_add">+		ctx_obj-&gt;dirty = true;</span>
 	}
 
 	return ret;
<span class="p_header">diff --git a/drivers/gpu/drm/vmwgfx/vmwgfx_execbuf.c b/drivers/gpu/drm/vmwgfx/vmwgfx_execbuf.c</span>
<span class="p_header">index 1e11489..2711b09 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/vmwgfx/vmwgfx_execbuf.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/vmwgfx/vmwgfx_execbuf.c</span>
<span class="p_chunk">@@ -2490,7 +2490,7 @@</span> <span class="p_context"> int vmw_execbuf_process(struct drm_file *file_priv,</span>
 	ret = ttm_eu_reserve_buffers(&amp;ticket, &amp;sw_context-&gt;validate_nodes,
 				     true, NULL);
 	if (unlikely(ret != 0))
<span class="p_del">-		goto out_err;</span>
<span class="p_add">+		goto out_err_nores;</span>
 
 	ret = vmw_validate_buffers(dev_priv, sw_context);
 	if (unlikely(ret != 0))
<span class="p_chunk">@@ -2534,6 +2534,7 @@</span> <span class="p_context"> int vmw_execbuf_process(struct drm_file *file_priv,</span>
 	vmw_resource_relocations_free(&amp;sw_context-&gt;res_relocations);
 
 	vmw_fifo_commit(dev_priv, command_size);
<span class="p_add">+	mutex_unlock(&amp;dev_priv-&gt;binding_mutex);</span>
 
 	vmw_query_bo_switch_commit(dev_priv, sw_context);
 	ret = vmw_execbuf_fence_commands(file_priv, dev_priv,
<span class="p_chunk">@@ -2549,7 +2550,6 @@</span> <span class="p_context"> int vmw_execbuf_process(struct drm_file *file_priv,</span>
 		DRM_ERROR(&quot;Fence submission error. Syncing.\n&quot;);
 
 	vmw_resource_list_unreserve(&amp;sw_context-&gt;resource_list, false);
<span class="p_del">-	mutex_unlock(&amp;dev_priv-&gt;binding_mutex);</span>
 
 	ttm_eu_fence_buffer_objects(&amp;ticket, &amp;sw_context-&gt;validate_nodes,
 				    (void *) fence);
<span class="p_header">diff --git a/drivers/input/keyboard/gpio_keys_polled.c b/drivers/input/keyboard/gpio_keys_polled.c</span>
<span class="p_header">index 90df4df..959b826 100644</span>
<span class="p_header">--- a/drivers/input/keyboard/gpio_keys_polled.c</span>
<span class="p_header">+++ b/drivers/input/keyboard/gpio_keys_polled.c</span>
<span class="p_chunk">@@ -246,7 +246,7 @@</span> <span class="p_context"> static int gpio_keys_polled_probe(struct platform_device *pdev)</span>
 		 * convert it to descriptor.
 		 */
 		if (!button-&gt;gpiod &amp;&amp; gpio_is_valid(button-&gt;gpio)) {
<span class="p_del">-			unsigned flags = 0;</span>
<span class="p_add">+			unsigned flags = GPIOF_IN;</span>
 
 			if (button-&gt;active_low)
 				flags |= GPIOF_ACTIVE_LOW;
<span class="p_header">diff --git a/drivers/md/dm-thin-metadata.c b/drivers/md/dm-thin-metadata.c</span>
<span class="p_header">index 43adbb8..0eea5e7 100644</span>
<span class="p_header">--- a/drivers/md/dm-thin-metadata.c</span>
<span class="p_header">+++ b/drivers/md/dm-thin-metadata.c</span>
<span class="p_chunk">@@ -1295,8 +1295,8 @@</span> <span class="p_context"> static int __release_metadata_snap(struct dm_pool_metadata *pmd)</span>
 		return r;
 
 	disk_super = dm_block_data(copy);
<span class="p_del">-	dm_sm_dec_block(pmd-&gt;metadata_sm, le64_to_cpu(disk_super-&gt;data_mapping_root));</span>
<span class="p_del">-	dm_sm_dec_block(pmd-&gt;metadata_sm, le64_to_cpu(disk_super-&gt;device_details_root));</span>
<span class="p_add">+	dm_btree_del(&amp;pmd-&gt;info, le64_to_cpu(disk_super-&gt;data_mapping_root));</span>
<span class="p_add">+	dm_btree_del(&amp;pmd-&gt;details_info, le64_to_cpu(disk_super-&gt;device_details_root));</span>
 	dm_sm_dec_block(pmd-&gt;metadata_sm, held_root);
 
 	return dm_tm_unlock(pmd-&gt;tm, copy);
<span class="p_header">diff --git a/drivers/md/dm.c b/drivers/md/dm.c</span>
<span class="p_header">index a367a17..82fe47d 100644</span>
<span class="p_header">--- a/drivers/md/dm.c</span>
<span class="p_header">+++ b/drivers/md/dm.c</span>
<span class="p_chunk">@@ -1596,7 +1596,8 @@</span> <span class="p_context"> static int dm_merge_bvec(struct request_queue *q,</span>
 	struct mapped_device *md = q-&gt;queuedata;
 	struct dm_table *map = dm_get_live_table_fast(md);
 	struct dm_target *ti;
<span class="p_del">-	sector_t max_sectors, max_size = 0;</span>
<span class="p_add">+	sector_t max_sectors;</span>
<span class="p_add">+	int max_size = 0;</span>
 
 	if (unlikely(!map))
 		goto out;
<span class="p_chunk">@@ -1609,18 +1610,10 @@</span> <span class="p_context"> static int dm_merge_bvec(struct request_queue *q,</span>
 	 * Find maximum amount of I/O that won&#39;t need splitting
 	 */
 	max_sectors = min(max_io_len(bvm-&gt;bi_sector, ti),
<span class="p_del">-			  (sector_t) queue_max_sectors(q));</span>
<span class="p_add">+			  (sector_t) BIO_MAX_SECTORS);</span>
 	max_size = (max_sectors &lt;&lt; SECTOR_SHIFT) - bvm-&gt;bi_size;
<span class="p_del">-</span>
<span class="p_del">-	/*</span>
<span class="p_del">-	 * FIXME: this stop-gap fix _must_ be cleaned up (by passing a sector_t</span>
<span class="p_del">-	 * to the targets&#39; merge function since it holds sectors not bytes).</span>
<span class="p_del">-	 * Just doing this as an interim fix for stable@ because the more</span>
<span class="p_del">-	 * comprehensive cleanup of switching to sector_t will impact every</span>
<span class="p_del">-	 * DM target that implements a -&gt;merge hook.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	if (max_size &gt; INT_MAX)</span>
<span class="p_del">-		max_size = INT_MAX;</span>
<span class="p_add">+	if (max_size &lt; 0)</span>
<span class="p_add">+		max_size = 0;</span>
 
 	/*
 	 * merge_bvec_fn() returns number of bytes
<span class="p_chunk">@@ -1628,13 +1621,13 @@</span> <span class="p_context"> static int dm_merge_bvec(struct request_queue *q,</span>
 	 * max is precomputed maximal io size
 	 */
 	if (max_size &amp;&amp; ti-&gt;type-&gt;merge)
<span class="p_del">-		max_size = ti-&gt;type-&gt;merge(ti, bvm, biovec, (int) max_size);</span>
<span class="p_add">+		max_size = ti-&gt;type-&gt;merge(ti, bvm, biovec, max_size);</span>
 	/*
 	 * If the target doesn&#39;t support merge method and some of the devices
<span class="p_del">-	 * provided their merge_bvec method (we know this by looking for the</span>
<span class="p_del">-	 * max_hw_sectors that dm_set_device_limits may set), then we can&#39;t</span>
<span class="p_del">-	 * allow bios with multiple vector entries.  So always set max_size</span>
<span class="p_del">-	 * to 0, and the code below allows just one page.</span>
<span class="p_add">+	 * provided their merge_bvec method (we know this by looking at</span>
<span class="p_add">+	 * queue_max_hw_sectors), then we can&#39;t allow bios with multiple vector</span>
<span class="p_add">+	 * entries.  So always set max_size to 0, and the code below allows</span>
<span class="p_add">+	 * just one page.</span>
 	 */
 	else if (queue_max_hw_sectors(q) &lt;= PAGE_SIZE &gt;&gt; 9)
 		max_size = 0;
<span class="p_header">diff --git a/drivers/md/md.c b/drivers/md/md.c</span>
<span class="p_header">index a31e15b..d7f0a56 100644</span>
<span class="p_header">--- a/drivers/md/md.c</span>
<span class="p_header">+++ b/drivers/md/md.c</span>
<span class="p_chunk">@@ -5076,6 +5076,8 @@</span> <span class="p_context"> EXPORT_SYMBOL_GPL(md_stop_writes);</span>
 
 static void __md_stop(struct mddev *mddev)
 {
<span class="p_add">+	/* Ensure -&gt;event_work is done */</span>
<span class="p_add">+	flush_workqueue(md_misc_wq);</span>
 	mddev-&gt;ready = 0;
 	mddev-&gt;pers-&gt;stop(mddev);
 	if (mddev-&gt;pers-&gt;sync_request &amp;&amp; mddev-&gt;to_remove == NULL)
<span class="p_header">diff --git a/drivers/md/persistent-data/dm-btree-internal.h b/drivers/md/persistent-data/dm-btree-internal.h</span>
<span class="p_header">index bf2b80d..8731b6e 100644</span>
<span class="p_header">--- a/drivers/md/persistent-data/dm-btree-internal.h</span>
<span class="p_header">+++ b/drivers/md/persistent-data/dm-btree-internal.h</span>
<span class="p_chunk">@@ -138,4 +138,10 @@</span> <span class="p_context"> int lower_bound(struct btree_node *n, uint64_t key);</span>
 
 extern struct dm_block_validator btree_node_validator;
 
<span class="p_add">+/*</span>
<span class="p_add">+ * Value type for upper levels of multi-level btrees.</span>
<span class="p_add">+ */</span>
<span class="p_add">+extern void init_le64_type(struct dm_transaction_manager *tm,</span>
<span class="p_add">+			   struct dm_btree_value_type *vt);</span>
<span class="p_add">+</span>
 #endif	/* DM_BTREE_INTERNAL_H */
<span class="p_header">diff --git a/drivers/md/persistent-data/dm-btree-remove.c b/drivers/md/persistent-data/dm-btree-remove.c</span>
<span class="p_header">index a03178e..7c0d755 100644</span>
<span class="p_header">--- a/drivers/md/persistent-data/dm-btree-remove.c</span>
<span class="p_header">+++ b/drivers/md/persistent-data/dm-btree-remove.c</span>
<span class="p_chunk">@@ -544,14 +544,6 @@</span> <span class="p_context"> static int remove_raw(struct shadow_spine *s, struct dm_btree_info *info,</span>
 	return r;
 }
 
<span class="p_del">-static struct dm_btree_value_type le64_type = {</span>
<span class="p_del">-	.context = NULL,</span>
<span class="p_del">-	.size = sizeof(__le64),</span>
<span class="p_del">-	.inc = NULL,</span>
<span class="p_del">-	.dec = NULL,</span>
<span class="p_del">-	.equal = NULL</span>
<span class="p_del">-};</span>
<span class="p_del">-</span>
 int dm_btree_remove(struct dm_btree_info *info, dm_block_t root,
 		    uint64_t *keys, dm_block_t *new_root)
 {
<span class="p_chunk">@@ -559,12 +551,14 @@</span> <span class="p_context"> int dm_btree_remove(struct dm_btree_info *info, dm_block_t root,</span>
 	int index = 0, r = 0;
 	struct shadow_spine spine;
 	struct btree_node *n;
<span class="p_add">+	struct dm_btree_value_type le64_vt;</span>
 
<span class="p_add">+	init_le64_type(info-&gt;tm, &amp;le64_vt);</span>
 	init_shadow_spine(&amp;spine, info);
 	for (level = 0; level &lt; info-&gt;levels; level++) {
 		r = remove_raw(&amp;spine, info,
 			       (level == last_level ?
<span class="p_del">-				&amp;info-&gt;value_type : &amp;le64_type),</span>
<span class="p_add">+				&amp;info-&gt;value_type : &amp;le64_vt),</span>
 			       root, keys[level], (unsigned *)&amp;index);
 		if (r &lt; 0)
 			break;
<span class="p_header">diff --git a/drivers/md/persistent-data/dm-btree-spine.c b/drivers/md/persistent-data/dm-btree-spine.c</span>
<span class="p_header">index 1b5e13e..0dee514 100644</span>
<span class="p_header">--- a/drivers/md/persistent-data/dm-btree-spine.c</span>
<span class="p_header">+++ b/drivers/md/persistent-data/dm-btree-spine.c</span>
<span class="p_chunk">@@ -249,3 +249,40 @@</span> <span class="p_context"> int shadow_root(struct shadow_spine *s)</span>
 {
 	return s-&gt;root;
 }
<span class="p_add">+</span>
<span class="p_add">+static void le64_inc(void *context, const void *value_le)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct dm_transaction_manager *tm = context;</span>
<span class="p_add">+	__le64 v_le;</span>
<span class="p_add">+</span>
<span class="p_add">+	memcpy(&amp;v_le, value_le, sizeof(v_le));</span>
<span class="p_add">+	dm_tm_inc(tm, le64_to_cpu(v_le));</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static void le64_dec(void *context, const void *value_le)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct dm_transaction_manager *tm = context;</span>
<span class="p_add">+	__le64 v_le;</span>
<span class="p_add">+</span>
<span class="p_add">+	memcpy(&amp;v_le, value_le, sizeof(v_le));</span>
<span class="p_add">+	dm_tm_dec(tm, le64_to_cpu(v_le));</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static int le64_equal(void *context, const void *value1_le, const void *value2_le)</span>
<span class="p_add">+{</span>
<span class="p_add">+	__le64 v1_le, v2_le;</span>
<span class="p_add">+</span>
<span class="p_add">+	memcpy(&amp;v1_le, value1_le, sizeof(v1_le));</span>
<span class="p_add">+	memcpy(&amp;v2_le, value2_le, sizeof(v2_le));</span>
<span class="p_add">+	return v1_le == v2_le;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void init_le64_type(struct dm_transaction_manager *tm,</span>
<span class="p_add">+		    struct dm_btree_value_type *vt)</span>
<span class="p_add">+{</span>
<span class="p_add">+	vt-&gt;context = tm;</span>
<span class="p_add">+	vt-&gt;size = sizeof(__le64);</span>
<span class="p_add">+	vt-&gt;inc = le64_inc;</span>
<span class="p_add">+	vt-&gt;dec = le64_dec;</span>
<span class="p_add">+	vt-&gt;equal = le64_equal;</span>
<span class="p_add">+}</span>
<span class="p_header">diff --git a/drivers/md/persistent-data/dm-btree.c b/drivers/md/persistent-data/dm-btree.c</span>
<span class="p_header">index fdd3793..c7726ce 100644</span>
<span class="p_header">--- a/drivers/md/persistent-data/dm-btree.c</span>
<span class="p_header">+++ b/drivers/md/persistent-data/dm-btree.c</span>
<span class="p_chunk">@@ -667,12 +667,7 @@</span> <span class="p_context"> static int insert(struct dm_btree_info *info, dm_block_t root,</span>
 	struct btree_node *n;
 	struct dm_btree_value_type le64_type;
 
<span class="p_del">-	le64_type.context = NULL;</span>
<span class="p_del">-	le64_type.size = sizeof(__le64);</span>
<span class="p_del">-	le64_type.inc = NULL;</span>
<span class="p_del">-	le64_type.dec = NULL;</span>
<span class="p_del">-	le64_type.equal = NULL;</span>
<span class="p_del">-</span>
<span class="p_add">+	init_le64_type(info-&gt;tm, &amp;le64_type);</span>
 	init_shadow_spine(&amp;spine, info);
 
 	for (level = 0; level &lt; (info-&gt;levels - 1); level++) {
<span class="p_header">diff --git a/drivers/md/raid1.c b/drivers/md/raid1.c</span>
<span class="p_header">index 8d9110f..d24245c 100644</span>
<span class="p_header">--- a/drivers/md/raid1.c</span>
<span class="p_header">+++ b/drivers/md/raid1.c</span>
<span class="p_chunk">@@ -1474,6 +1474,7 @@</span> <span class="p_context"> static void error(struct mddev *mddev, struct md_rdev *rdev)</span>
 {
 	char b[BDEVNAME_SIZE];
 	struct r1conf *conf = mddev-&gt;private;
<span class="p_add">+	unsigned long flags;</span>
 
 	/*
 	 * If it is not operational, then we have already marked it as dead
<span class="p_chunk">@@ -1493,14 +1494,13 @@</span> <span class="p_context"> static void error(struct mddev *mddev, struct md_rdev *rdev)</span>
 		return;
 	}
 	set_bit(Blocked, &amp;rdev-&gt;flags);
<span class="p_add">+	spin_lock_irqsave(&amp;conf-&gt;device_lock, flags);</span>
 	if (test_and_clear_bit(In_sync, &amp;rdev-&gt;flags)) {
<span class="p_del">-		unsigned long flags;</span>
<span class="p_del">-		spin_lock_irqsave(&amp;conf-&gt;device_lock, flags);</span>
 		mddev-&gt;degraded++;
 		set_bit(Faulty, &amp;rdev-&gt;flags);
<span class="p_del">-		spin_unlock_irqrestore(&amp;conf-&gt;device_lock, flags);</span>
 	} else
 		set_bit(Faulty, &amp;rdev-&gt;flags);
<span class="p_add">+	spin_unlock_irqrestore(&amp;conf-&gt;device_lock, flags);</span>
 	/*
 	 * if recovery is running, make sure it aborts.
 	 */
<span class="p_chunk">@@ -1566,7 +1566,10 @@</span> <span class="p_context"> static int raid1_spare_active(struct mddev *mddev)</span>
 	 * Find all failed disks within the RAID1 configuration
 	 * and mark them readable.
 	 * Called under mddev lock, so rcu protection not needed.
<span class="p_add">+	 * device_lock used to avoid races with raid1_end_read_request</span>
<span class="p_add">+	 * which expects &#39;In_sync&#39; flags and -&gt;degraded to be consistent.</span>
 	 */
<span class="p_add">+	spin_lock_irqsave(&amp;conf-&gt;device_lock, flags);</span>
 	for (i = 0; i &lt; conf-&gt;raid_disks; i++) {
 		struct md_rdev *rdev = conf-&gt;mirrors[i].rdev;
 		struct md_rdev *repl = conf-&gt;mirrors[conf-&gt;raid_disks + i].rdev;
<span class="p_chunk">@@ -1596,7 +1599,6 @@</span> <span class="p_context"> static int raid1_spare_active(struct mddev *mddev)</span>
 			sysfs_notify_dirent_safe(rdev-&gt;sysfs_state);
 		}
 	}
<span class="p_del">-	spin_lock_irqsave(&amp;conf-&gt;device_lock, flags);</span>
 	mddev-&gt;degraded -= count;
 	spin_unlock_irqrestore(&amp;conf-&gt;device_lock, flags);
 
<span class="p_header">diff --git a/drivers/mfd/arizona-core.c b/drivers/mfd/arizona-core.c</span>
<span class="p_header">index 09ba8f1..be357a6 100644</span>
<span class="p_header">--- a/drivers/mfd/arizona-core.c</span>
<span class="p_header">+++ b/drivers/mfd/arizona-core.c</span>
<span class="p_chunk">@@ -892,10 +892,6 @@</span> <span class="p_context"> int arizona_dev_init(struct arizona *arizona)</span>
 			     arizona-&gt;pdata.gpio_defaults[i]);
 	}
 
<span class="p_del">-	pm_runtime_set_autosuspend_delay(arizona-&gt;dev, 100);</span>
<span class="p_del">-	pm_runtime_use_autosuspend(arizona-&gt;dev);</span>
<span class="p_del">-	pm_runtime_enable(arizona-&gt;dev);</span>
<span class="p_del">-</span>
 	/* Chip default */
 	if (!arizona-&gt;pdata.clk32k_src)
 		arizona-&gt;pdata.clk32k_src = ARIZONA_32KZ_MCLK2;
<span class="p_chunk">@@ -992,11 +988,17 @@</span> <span class="p_context"> int arizona_dev_init(struct arizona *arizona)</span>
 					   arizona-&gt;pdata.spk_fmt[i]);
 	}
 
<span class="p_add">+	pm_runtime_set_active(arizona-&gt;dev);</span>
<span class="p_add">+	pm_runtime_enable(arizona-&gt;dev);</span>
<span class="p_add">+</span>
 	/* Set up for interrupts */
 	ret = arizona_irq_init(arizona);
 	if (ret != 0)
 		goto err_reset;
 
<span class="p_add">+	pm_runtime_set_autosuspend_delay(arizona-&gt;dev, 100);</span>
<span class="p_add">+	pm_runtime_use_autosuspend(arizona-&gt;dev);</span>
<span class="p_add">+</span>
 	arizona_request_irq(arizona, ARIZONA_IRQ_CLKGEN_ERR, &quot;CLKGEN error&quot;,
 			    arizona_clkgen_err, arizona);
 	arizona_request_irq(arizona, ARIZONA_IRQ_OVERCLOCKED, &quot;Overclocked&quot;,
<span class="p_chunk">@@ -1024,10 +1026,6 @@</span> <span class="p_context"> int arizona_dev_init(struct arizona *arizona)</span>
 		goto err_irq;
 	}
 
<span class="p_del">-#ifdef CONFIG_PM</span>
<span class="p_del">-	regulator_disable(arizona-&gt;dcvdd);</span>
<span class="p_del">-#endif</span>
<span class="p_del">-</span>
 	return 0;
 
 err_irq:
<span class="p_header">diff --git a/drivers/net/bonding/bond_main.c b/drivers/net/bonding/bond_main.c</span>
<span class="p_header">index 58b687c..d3b9436 100644</span>
<span class="p_header">--- a/drivers/net/bonding/bond_main.c</span>
<span class="p_header">+++ b/drivers/net/bonding/bond_main.c</span>
<span class="p_chunk">@@ -622,6 +622,23 @@</span> <span class="p_context"> static void bond_set_dev_addr(struct net_device *bond_dev,</span>
 	call_netdevice_notifiers(NETDEV_CHANGEADDR, bond_dev);
 }
 
<span class="p_add">+static struct slave *bond_get_old_active(struct bonding *bond,</span>
<span class="p_add">+					 struct slave *new_active)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct slave *slave;</span>
<span class="p_add">+	struct list_head *iter;</span>
<span class="p_add">+</span>
<span class="p_add">+	bond_for_each_slave(bond, slave, iter) {</span>
<span class="p_add">+		if (slave == new_active)</span>
<span class="p_add">+			continue;</span>
<span class="p_add">+</span>
<span class="p_add">+		if (ether_addr_equal(bond-&gt;dev-&gt;dev_addr, slave-&gt;dev-&gt;dev_addr))</span>
<span class="p_add">+			return slave;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	return NULL;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 /* bond_do_fail_over_mac
  *
  * Perform special MAC address swapping for fail_over_mac settings
<span class="p_chunk">@@ -649,6 +666,9 @@</span> <span class="p_context"> static void bond_do_fail_over_mac(struct bonding *bond,</span>
 		if (!new_active)
 			return;
 
<span class="p_add">+		if (!old_active)</span>
<span class="p_add">+			old_active = bond_get_old_active(bond, new_active);</span>
<span class="p_add">+</span>
 		if (old_active) {
 			ether_addr_copy(tmp_mac, new_active-&gt;dev-&gt;dev_addr);
 			ether_addr_copy(saddr.sa_data,
<span class="p_header">diff --git a/drivers/net/ethernet/brocade/bna/bnad.c b/drivers/net/ethernet/brocade/bna/bnad.c</span>
<span class="p_header">index 3237218..a29e5a6 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/brocade/bna/bnad.c</span>
<span class="p_header">+++ b/drivers/net/ethernet/brocade/bna/bnad.c</span>
<span class="p_chunk">@@ -674,6 +674,7 @@</span> <span class="p_context"> bnad_cq_process(struct bnad *bnad, struct bna_ccb *ccb, int budget)</span>
 			if (!next_cmpl-&gt;valid)
 				break;
 		}
<span class="p_add">+		packets++;</span>
 
 		/* TODO: BNA_CQ_EF_LOCAL ? */
 		if (unlikely(flags &amp; (BNA_CQ_EF_MAC_ERROR |
<span class="p_chunk">@@ -690,7 +691,6 @@</span> <span class="p_context"> bnad_cq_process(struct bnad *bnad, struct bna_ccb *ccb, int budget)</span>
 		else
 			bnad_cq_setup_skb_frags(rcb, skb, sop_ci, nvecs, len);
 
<span class="p_del">-		packets++;</span>
 		rcb-&gt;rxq-&gt;rx_packets++;
 		rcb-&gt;rxq-&gt;rx_bytes += totlen;
 		ccb-&gt;bytes_per_intr += totlen;
<span class="p_header">diff --git a/drivers/net/ethernet/rocker/rocker.c b/drivers/net/ethernet/rocker/rocker.c</span>
<span class="p_header">index 24c0284..5f8645d 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/rocker/rocker.c</span>
<span class="p_header">+++ b/drivers/net/ethernet/rocker/rocker.c</span>
<span class="p_chunk">@@ -3960,6 +3960,7 @@</span> <span class="p_context"> static void rocker_remove_ports(struct rocker *rocker)</span>
 		rocker_port = rocker-&gt;ports[i];
 		rocker_port_ig_tbl(rocker_port, ROCKER_OP_FLAG_REMOVE);
 		unregister_netdev(rocker_port-&gt;dev);
<span class="p_add">+		free_netdev(rocker_port-&gt;dev);</span>
 	}
 	kfree(rocker-&gt;ports);
 }
<span class="p_header">diff --git a/drivers/net/phy/phy.c b/drivers/net/phy/phy.c</span>
<span class="p_header">index 91d6d03..15a7387 100644</span>
<span class="p_header">--- a/drivers/net/phy/phy.c</span>
<span class="p_header">+++ b/drivers/net/phy/phy.c</span>
<span class="p_chunk">@@ -993,10 +993,14 @@</span> <span class="p_context"> int phy_read_mmd_indirect(struct phy_device *phydev, int prtad,</span>
 	int value = -1;
 
 	if (phydrv-&gt;read_mmd_indirect == NULL) {
<span class="p_del">-		mmd_phy_indirect(phydev-&gt;bus, prtad, devad, addr);</span>
<span class="p_add">+		struct mii_bus *bus = phydev-&gt;bus;</span>
<span class="p_add">+</span>
<span class="p_add">+		mutex_lock(&amp;bus-&gt;mdio_lock);</span>
<span class="p_add">+		mmd_phy_indirect(bus, prtad, devad, addr);</span>
 
 		/* Read the content of the MMD&#39;s selected register */
<span class="p_del">-		value = phydev-&gt;bus-&gt;read(phydev-&gt;bus, addr, MII_MMD_DATA);</span>
<span class="p_add">+		value = bus-&gt;read(bus, addr, MII_MMD_DATA);</span>
<span class="p_add">+		mutex_unlock(&amp;bus-&gt;mdio_lock);</span>
 	} else {
 		value = phydrv-&gt;read_mmd_indirect(phydev, prtad, devad, addr);
 	}
<span class="p_chunk">@@ -1026,10 +1030,14 @@</span> <span class="p_context"> void phy_write_mmd_indirect(struct phy_device *phydev, int prtad,</span>
 	struct phy_driver *phydrv = phydev-&gt;drv;
 
 	if (phydrv-&gt;write_mmd_indirect == NULL) {
<span class="p_del">-		mmd_phy_indirect(phydev-&gt;bus, prtad, devad, addr);</span>
<span class="p_add">+		struct mii_bus *bus = phydev-&gt;bus;</span>
<span class="p_add">+</span>
<span class="p_add">+		mutex_lock(&amp;bus-&gt;mdio_lock);</span>
<span class="p_add">+		mmd_phy_indirect(bus, prtad, devad, addr);</span>
 
 		/* Write the data into MMD&#39;s selected register */
<span class="p_del">-		phydev-&gt;bus-&gt;write(phydev-&gt;bus, addr, MII_MMD_DATA, data);</span>
<span class="p_add">+		bus-&gt;write(bus, addr, MII_MMD_DATA, data);</span>
<span class="p_add">+		mutex_unlock(&amp;bus-&gt;mdio_lock);</span>
 	} else {
 		phydrv-&gt;write_mmd_indirect(phydev, prtad, devad, addr, data);
 	}
<span class="p_header">diff --git a/drivers/net/virtio_net.c b/drivers/net/virtio_net.c</span>
<span class="p_header">index 0ad6c0c..46976f4 100644</span>
<span class="p_header">--- a/drivers/net/virtio_net.c</span>
<span class="p_header">+++ b/drivers/net/virtio_net.c</span>
<span class="p_chunk">@@ -1738,9 +1738,9 @@</span> <span class="p_context"> static int virtnet_probe(struct virtio_device *vdev)</span>
 	/* Do we support &quot;hardware&quot; checksums? */
 	if (virtio_has_feature(vdev, VIRTIO_NET_F_CSUM)) {
 		/* This opens up the world of extra features. */
<span class="p_del">-		dev-&gt;hw_features |= NETIF_F_HW_CSUM|NETIF_F_SG|NETIF_F_FRAGLIST;</span>
<span class="p_add">+		dev-&gt;hw_features |= NETIF_F_HW_CSUM | NETIF_F_SG;</span>
 		if (csum)
<span class="p_del">-			dev-&gt;features |= NETIF_F_HW_CSUM|NETIF_F_SG|NETIF_F_FRAGLIST;</span>
<span class="p_add">+			dev-&gt;features |= NETIF_F_HW_CSUM | NETIF_F_SG;</span>
 
 		if (virtio_has_feature(vdev, VIRTIO_NET_F_GSO)) {
 			dev-&gt;hw_features |= NETIF_F_TSO | NETIF_F_UFO
<span class="p_header">diff --git a/drivers/net/wireless/rtlwifi/rtl8723be/sw.c b/drivers/net/wireless/rtlwifi/rtl8723be/sw.c</span>
<span class="p_header">index 223eb42..775e7bc 100644</span>
<span class="p_header">--- a/drivers/net/wireless/rtlwifi/rtl8723be/sw.c</span>
<span class="p_header">+++ b/drivers/net/wireless/rtlwifi/rtl8723be/sw.c</span>
<span class="p_chunk">@@ -385,6 +385,7 @@</span> <span class="p_context"> module_param_named(debug, rtl8723be_mod_params.debug, int, 0444);</span>
 module_param_named(ips, rtl8723be_mod_params.inactiveps, bool, 0444);
 module_param_named(swlps, rtl8723be_mod_params.swctrl_lps, bool, 0444);
 module_param_named(fwlps, rtl8723be_mod_params.fwctrl_lps, bool, 0444);
<span class="p_add">+module_param_named(msi, rtl8723be_mod_params.msi_support, bool, 0444);</span>
 module_param_named(disable_watchdog, rtl8723be_mod_params.disable_watchdog,
 		   bool, 0444);
 MODULE_PARM_DESC(swenc, &quot;using hardware crypto (default 0 [hardware])\n&quot;);
<span class="p_header">diff --git a/drivers/pci/Kconfig b/drivers/pci/Kconfig</span>
<span class="p_header">index 73de4ef..944f500 100644</span>
<span class="p_header">--- a/drivers/pci/Kconfig</span>
<span class="p_header">+++ b/drivers/pci/Kconfig</span>
<span class="p_chunk">@@ -2,7 +2,7 @@</span> <span class="p_context"></span>
 # PCI configuration
 #
 config PCI_BUS_ADDR_T_64BIT
<span class="p_del">-	def_bool y if (ARCH_DMA_ADDR_T_64BIT || 64BIT)</span>
<span class="p_add">+	def_bool y if (ARCH_DMA_ADDR_T_64BIT || (64BIT &amp;&amp; !PARISC))</span>
 	depends on PCI
 
 config PCI_MSI
<span class="p_header">diff --git a/drivers/scsi/fnic/fnic.h b/drivers/scsi/fnic/fnic.h</span>
<span class="p_header">index 26270c3..ce129e5 100644</span>
<span class="p_header">--- a/drivers/scsi/fnic/fnic.h</span>
<span class="p_header">+++ b/drivers/scsi/fnic/fnic.h</span>
<span class="p_chunk">@@ -39,7 +39,7 @@</span> <span class="p_context"></span>
 
 #define DRV_NAME		&quot;fnic&quot;
 #define DRV_DESCRIPTION		&quot;Cisco FCoE HBA Driver&quot;
<span class="p_del">-#define DRV_VERSION		&quot;1.6.0.17&quot;</span>
<span class="p_add">+#define DRV_VERSION		&quot;1.6.0.17a&quot;</span>
 #define PFX			DRV_NAME &quot;: &quot;
 #define DFX                     DRV_NAME &quot;%d: &quot;
 
<span class="p_header">diff --git a/drivers/scsi/fnic/fnic_scsi.c b/drivers/scsi/fnic/fnic_scsi.c</span>
<span class="p_header">index 155b286..25436cd 100644</span>
<span class="p_header">--- a/drivers/scsi/fnic/fnic_scsi.c</span>
<span class="p_header">+++ b/drivers/scsi/fnic/fnic_scsi.c</span>
<span class="p_chunk">@@ -425,6 +425,7 @@</span> <span class="p_context"> static int fnic_queuecommand_lck(struct scsi_cmnd *sc, void (*done)(struct scsi_</span>
 	unsigned long ptr;
 	struct fc_rport_priv *rdata;
 	spinlock_t *io_lock = NULL;
<span class="p_add">+	int io_lock_acquired = 0;</span>
 
 	if (unlikely(fnic_chk_state_flags_locked(fnic, FNIC_FLAGS_IO_BLOCKED)))
 		return SCSI_MLQUEUE_HOST_BUSY;
<span class="p_chunk">@@ -518,6 +519,7 @@</span> <span class="p_context"> static int fnic_queuecommand_lck(struct scsi_cmnd *sc, void (*done)(struct scsi_</span>
 	spin_lock_irqsave(io_lock, flags);
 
 	/* initialize rest of io_req */
<span class="p_add">+	io_lock_acquired = 1;</span>
 	io_req-&gt;port_id = rport-&gt;port_id;
 	io_req-&gt;start_time = jiffies;
 	CMD_STATE(sc) = FNIC_IOREQ_CMD_PENDING;
<span class="p_chunk">@@ -571,7 +573,7 @@</span> <span class="p_context"> out:</span>
 		  (((u64)CMD_FLAGS(sc) &gt;&gt; 32) | CMD_STATE(sc)));
 
 	/* if only we issued IO, will we have the io lock */
<span class="p_del">-	if (CMD_FLAGS(sc) &amp; FNIC_IO_INITIALIZED)</span>
<span class="p_add">+	if (io_lock_acquired)</span>
 		spin_unlock_irqrestore(io_lock, flags);
 
 	atomic_dec(&amp;fnic-&gt;in_flight);
<span class="p_header">diff --git a/drivers/scsi/libfc/fc_exch.c b/drivers/scsi/libfc/fc_exch.c</span>
<span class="p_header">index 1b3a094..30f9ef0 100644</span>
<span class="p_header">--- a/drivers/scsi/libfc/fc_exch.c</span>
<span class="p_header">+++ b/drivers/scsi/libfc/fc_exch.c</span>
<span class="p_chunk">@@ -733,8 +733,6 @@</span> <span class="p_context"> static bool fc_invoke_resp(struct fc_exch *ep, struct fc_seq *sp,</span>
 	if (resp) {
 		resp(sp, fp, arg);
 		res = true;
<span class="p_del">-	} else if (!IS_ERR(fp)) {</span>
<span class="p_del">-		fc_frame_free(fp);</span>
 	}
 
 	spin_lock_bh(&amp;ep-&gt;ex_lock);
<span class="p_chunk">@@ -1596,7 +1594,8 @@</span> <span class="p_context"> static void fc_exch_recv_seq_resp(struct fc_exch_mgr *mp, struct fc_frame *fp)</span>
 	 * If new exch resp handler is valid then call that
 	 * first.
 	 */
<span class="p_del">-	fc_invoke_resp(ep, sp, fp);</span>
<span class="p_add">+	if (!fc_invoke_resp(ep, sp, fp))</span>
<span class="p_add">+		fc_frame_free(fp);</span>
 
 	fc_exch_release(ep);
 	return;
<span class="p_chunk">@@ -1695,7 +1694,8 @@</span> <span class="p_context"> static void fc_exch_abts_resp(struct fc_exch *ep, struct fc_frame *fp)</span>
 	fc_exch_hold(ep);
 	if (!rc)
 		fc_exch_delete(ep);
<span class="p_del">-	fc_invoke_resp(ep, sp, fp);</span>
<span class="p_add">+	if (!fc_invoke_resp(ep, sp, fp))</span>
<span class="p_add">+		fc_frame_free(fp);</span>
 	if (has_rec)
 		fc_exch_timer_set(ep, ep-&gt;r_a_tov);
 	fc_exch_release(ep);
<span class="p_header">diff --git a/drivers/scsi/libfc/fc_fcp.c b/drivers/scsi/libfc/fc_fcp.c</span>
<span class="p_header">index c679594..2d5909c 100644</span>
<span class="p_header">--- a/drivers/scsi/libfc/fc_fcp.c</span>
<span class="p_header">+++ b/drivers/scsi/libfc/fc_fcp.c</span>
<span class="p_chunk">@@ -1039,11 +1039,26 @@</span> <span class="p_context"> restart:</span>
 		fc_fcp_pkt_hold(fsp);
 		spin_unlock_irqrestore(&amp;si-&gt;scsi_queue_lock, flags);
 
<span class="p_del">-		if (!fc_fcp_lock_pkt(fsp)) {</span>
<span class="p_add">+		spin_lock_bh(&amp;fsp-&gt;scsi_pkt_lock);</span>
<span class="p_add">+		if (!(fsp-&gt;state &amp; FC_SRB_COMPL)) {</span>
<span class="p_add">+			fsp-&gt;state |= FC_SRB_COMPL;</span>
<span class="p_add">+			/*</span>
<span class="p_add">+			 * TODO: dropping scsi_pkt_lock and then reacquiring</span>
<span class="p_add">+			 * again around fc_fcp_cleanup_cmd() is required,</span>
<span class="p_add">+			 * since fc_fcp_cleanup_cmd() calls into</span>
<span class="p_add">+			 * fc_seq_set_resp() and that func preempts cpu using</span>
<span class="p_add">+			 * schedule. May be schedule and related code should be</span>
<span class="p_add">+			 * removed instead of unlocking here to avoid scheduling</span>
<span class="p_add">+			 * while atomic bug.</span>
<span class="p_add">+			 */</span>
<span class="p_add">+			spin_unlock_bh(&amp;fsp-&gt;scsi_pkt_lock);</span>
<span class="p_add">+</span>
 			fc_fcp_cleanup_cmd(fsp, error);
<span class="p_add">+</span>
<span class="p_add">+			spin_lock_bh(&amp;fsp-&gt;scsi_pkt_lock);</span>
 			fc_io_compl(fsp);
<span class="p_del">-			fc_fcp_unlock_pkt(fsp);</span>
 		}
<span class="p_add">+		spin_unlock_bh(&amp;fsp-&gt;scsi_pkt_lock);</span>
 
 		fc_fcp_pkt_release(fsp);
 		spin_lock_irqsave(&amp;si-&gt;scsi_queue_lock, flags);
<span class="p_header">diff --git a/drivers/scsi/libiscsi.c b/drivers/scsi/libiscsi.c</span>
<span class="p_header">index 8053f24..98d9bb6 100644</span>
<span class="p_header">--- a/drivers/scsi/libiscsi.c</span>
<span class="p_header">+++ b/drivers/scsi/libiscsi.c</span>
<span class="p_chunk">@@ -2941,10 +2941,10 @@</span> <span class="p_context"> void iscsi_conn_teardown(struct iscsi_cls_conn *cls_conn)</span>
 {
 	struct iscsi_conn *conn = cls_conn-&gt;dd_data;
 	struct iscsi_session *session = conn-&gt;session;
<span class="p_del">-	unsigned long flags;</span>
 
 	del_timer_sync(&amp;conn-&gt;transport_timer);
 
<span class="p_add">+	mutex_lock(&amp;session-&gt;eh_mutex);</span>
 	spin_lock_bh(&amp;session-&gt;frwd_lock);
 	conn-&gt;c_stage = ISCSI_CONN_CLEANUP_WAIT;
 	if (session-&gt;leadconn == conn) {
<span class="p_chunk">@@ -2956,28 +2956,6 @@</span> <span class="p_context"> void iscsi_conn_teardown(struct iscsi_cls_conn *cls_conn)</span>
 	}
 	spin_unlock_bh(&amp;session-&gt;frwd_lock);
 
<span class="p_del">-	/*</span>
<span class="p_del">-	 * Block until all in-progress commands for this connection</span>
<span class="p_del">-	 * time out or fail.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	for (;;) {</span>
<span class="p_del">-		spin_lock_irqsave(session-&gt;host-&gt;host_lock, flags);</span>
<span class="p_del">-		if (!atomic_read(&amp;session-&gt;host-&gt;host_busy)) { /* OK for ERL == 0 */</span>
<span class="p_del">-			spin_unlock_irqrestore(session-&gt;host-&gt;host_lock, flags);</span>
<span class="p_del">-			break;</span>
<span class="p_del">-		}</span>
<span class="p_del">-		spin_unlock_irqrestore(session-&gt;host-&gt;host_lock, flags);</span>
<span class="p_del">-		msleep_interruptible(500);</span>
<span class="p_del">-		iscsi_conn_printk(KERN_INFO, conn, &quot;iscsi conn_destroy(): &quot;</span>
<span class="p_del">-				  &quot;host_busy %d host_failed %d\n&quot;,</span>
<span class="p_del">-				  atomic_read(&amp;session-&gt;host-&gt;host_busy),</span>
<span class="p_del">-				  session-&gt;host-&gt;host_failed);</span>
<span class="p_del">-		/*</span>
<span class="p_del">-		 * force eh_abort() to unblock</span>
<span class="p_del">-		 */</span>
<span class="p_del">-		wake_up(&amp;conn-&gt;ehwait);</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
 	/* flush queued up work because we free the connection below */
 	iscsi_suspend_tx(conn);
 
<span class="p_chunk">@@ -2994,6 +2972,7 @@</span> <span class="p_context"> void iscsi_conn_teardown(struct iscsi_cls_conn *cls_conn)</span>
 	if (session-&gt;leadconn == conn)
 		session-&gt;leadconn = NULL;
 	spin_unlock_bh(&amp;session-&gt;frwd_lock);
<span class="p_add">+	mutex_unlock(&amp;session-&gt;eh_mutex);</span>
 
 	iscsi_destroy_conn(cls_conn);
 }
<span class="p_header">diff --git a/drivers/scsi/scsi_pm.c b/drivers/scsi/scsi_pm.c</span>
<span class="p_header">index 9e43ae1..e4b7998 100644</span>
<span class="p_header">--- a/drivers/scsi/scsi_pm.c</span>
<span class="p_header">+++ b/drivers/scsi/scsi_pm.c</span>
<span class="p_chunk">@@ -217,15 +217,15 @@</span> <span class="p_context"> static int sdev_runtime_suspend(struct device *dev)</span>
 {
 	const struct dev_pm_ops *pm = dev-&gt;driver ? dev-&gt;driver-&gt;pm : NULL;
 	struct scsi_device *sdev = to_scsi_device(dev);
<span class="p_del">-	int err;</span>
<span class="p_add">+	int err = 0;</span>
 
<span class="p_del">-	err = blk_pre_runtime_suspend(sdev-&gt;request_queue);</span>
<span class="p_del">-	if (err)</span>
<span class="p_del">-		return err;</span>
<span class="p_del">-	if (pm &amp;&amp; pm-&gt;runtime_suspend)</span>
<span class="p_add">+	if (pm &amp;&amp; pm-&gt;runtime_suspend) {</span>
<span class="p_add">+		err = blk_pre_runtime_suspend(sdev-&gt;request_queue);</span>
<span class="p_add">+		if (err)</span>
<span class="p_add">+			return err;</span>
 		err = pm-&gt;runtime_suspend(dev);
<span class="p_del">-	blk_post_runtime_suspend(sdev-&gt;request_queue, err);</span>
<span class="p_del">-</span>
<span class="p_add">+		blk_post_runtime_suspend(sdev-&gt;request_queue, err);</span>
<span class="p_add">+	}</span>
 	return err;
 }
 
<span class="p_chunk">@@ -248,11 +248,11 @@</span> <span class="p_context"> static int sdev_runtime_resume(struct device *dev)</span>
 	const struct dev_pm_ops *pm = dev-&gt;driver ? dev-&gt;driver-&gt;pm : NULL;
 	int err = 0;
 
<span class="p_del">-	blk_pre_runtime_resume(sdev-&gt;request_queue);</span>
<span class="p_del">-	if (pm &amp;&amp; pm-&gt;runtime_resume)</span>
<span class="p_add">+	if (pm &amp;&amp; pm-&gt;runtime_resume) {</span>
<span class="p_add">+		blk_pre_runtime_resume(sdev-&gt;request_queue);</span>
 		err = pm-&gt;runtime_resume(dev);
<span class="p_del">-	blk_post_runtime_resume(sdev-&gt;request_queue, err);</span>
<span class="p_del">-</span>
<span class="p_add">+		blk_post_runtime_resume(sdev-&gt;request_queue, err);</span>
<span class="p_add">+	}</span>
 	return err;
 }
 
<span class="p_header">diff --git a/drivers/scsi/sd.c b/drivers/scsi/sd.c</span>
<span class="p_header">index 7f71d7d..c80e1fe 100644</span>
<span class="p_header">--- a/drivers/scsi/sd.c</span>
<span class="p_header">+++ b/drivers/scsi/sd.c</span>
<span class="p_chunk">@@ -2794,9 +2794,9 @@</span> <span class="p_context"> static int sd_revalidate_disk(struct gendisk *disk)</span>
 	max_xfer = sdkp-&gt;max_xfer_blocks;
 	max_xfer &lt;&lt;= ilog2(sdp-&gt;sector_size) - 9;
 
<span class="p_del">-	max_xfer = min_not_zero(queue_max_hw_sectors(sdkp-&gt;disk-&gt;queue),</span>
<span class="p_del">-				max_xfer);</span>
<span class="p_del">-	blk_queue_max_hw_sectors(sdkp-&gt;disk-&gt;queue, max_xfer);</span>
<span class="p_add">+	sdkp-&gt;disk-&gt;queue-&gt;limits.max_sectors =</span>
<span class="p_add">+		min_not_zero(queue_max_hw_sectors(sdkp-&gt;disk-&gt;queue), max_xfer);</span>
<span class="p_add">+</span>
 	set_capacity(disk, sdkp-&gt;capacity);
 	sd_config_write_same(sdkp);
 	kfree(buffer);
<span class="p_header">diff --git a/drivers/staging/vt6655/device_main.c b/drivers/staging/vt6655/device_main.c</span>
<span class="p_header">index 4968d8a..2e5de62 100644</span>
<span class="p_header">--- a/drivers/staging/vt6655/device_main.c</span>
<span class="p_header">+++ b/drivers/staging/vt6655/device_main.c</span>
<span class="p_chunk">@@ -1516,8 +1516,9 @@</span> <span class="p_context"> static void vnt_bss_info_changed(struct ieee80211_hw *hw,</span>
 		}
 	}
 
<span class="p_del">-	if (changed &amp; BSS_CHANGED_ASSOC &amp;&amp; priv-&gt;op_mode != NL80211_IFTYPE_AP) {</span>
<span class="p_del">-		if (conf-&gt;assoc) {</span>
<span class="p_add">+	if (changed &amp; (BSS_CHANGED_ASSOC | BSS_CHANGED_BEACON_INFO) &amp;&amp;</span>
<span class="p_add">+	    priv-&gt;op_mode != NL80211_IFTYPE_AP) {</span>
<span class="p_add">+		if (conf-&gt;assoc &amp;&amp; conf-&gt;beacon_rate) {</span>
 			CARDbUpdateTSF(priv, conf-&gt;beacon_rate-&gt;hw_value,
 				       conf-&gt;sync_device_ts, conf-&gt;sync_tsf);
 
<span class="p_header">diff --git a/drivers/target/iscsi/iscsi_target.c b/drivers/target/iscsi/iscsi_target.c</span>
<span class="p_header">index 4e08d63..0c508a4 100644</span>
<span class="p_header">--- a/drivers/target/iscsi/iscsi_target.c</span>
<span class="p_header">+++ b/drivers/target/iscsi/iscsi_target.c</span>
<span class="p_chunk">@@ -967,7 +967,7 @@</span> <span class="p_context"> int iscsit_setup_scsi_cmd(struct iscsi_conn *conn, struct iscsi_cmd *cmd,</span>
 		if (cmd-&gt;targ_xfer_tag == 0xFFFFFFFF)
 			cmd-&gt;targ_xfer_tag = conn-&gt;sess-&gt;targ_xfer_tag++;
 		spin_unlock_bh(&amp;conn-&gt;sess-&gt;ttt_lock);
<span class="p_del">-	} else if (hdr-&gt;flags &amp; ISCSI_FLAG_CMD_WRITE)</span>
<span class="p_add">+	} else</span>
 		cmd-&gt;targ_xfer_tag = 0xFFFFFFFF;
 	cmd-&gt;cmd_sn		= be32_to_cpu(hdr-&gt;cmdsn);
 	cmd-&gt;exp_stat_sn	= be32_to_cpu(hdr-&gt;exp_statsn);
<span class="p_header">diff --git a/drivers/target/target_core_spc.c b/drivers/target/target_core_spc.c</span>
<span class="p_header">index 4c71657..0bac24f 100644</span>
<span class="p_header">--- a/drivers/target/target_core_spc.c</span>
<span class="p_header">+++ b/drivers/target/target_core_spc.c</span>
<span class="p_chunk">@@ -1238,11 +1238,8 @@</span> <span class="p_context"> sense_reason_t spc_emulate_report_luns(struct se_cmd *cmd)</span>
 	 * coming via a target_core_mod PASSTHROUGH op, and not through
 	 * a $FABRIC_MOD.  In that case, report LUN=0 only.
 	 */
<span class="p_del">-	if (!sess) {</span>
<span class="p_del">-		int_to_scsilun(0, (struct scsi_lun *)&amp;buf[offset]);</span>
<span class="p_del">-		lun_count = 1;</span>
<span class="p_add">+	if (!sess)</span>
 		goto done;
<span class="p_del">-	}</span>
 
 	spin_lock_irq(&amp;sess-&gt;se_node_acl-&gt;device_list_lock);
 	for (i = 0; i &lt; TRANSPORT_MAX_LUNS_PER_TPG; i++) {
<span class="p_chunk">@@ -1267,6 +1264,14 @@</span> <span class="p_context"> sense_reason_t spc_emulate_report_luns(struct se_cmd *cmd)</span>
 	 * See SPC3 r07, page 159.
 	 */
 done:
<span class="p_add">+	/*</span>
<span class="p_add">+	 * If no LUNs are accessible, report virtual LUN 0.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	if (lun_count == 0) {</span>
<span class="p_add">+		int_to_scsilun(0, (struct scsi_lun *)&amp;buf[offset]);</span>
<span class="p_add">+		lun_count = 1;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
 	lun_count *= 8;
 	buf[0] = ((lun_count &gt;&gt; 24) &amp; 0xff);
 	buf[1] = ((lun_count &gt;&gt; 16) &amp; 0xff);
<span class="p_header">diff --git a/drivers/usb/chipidea/core.c b/drivers/usb/chipidea/core.c</span>
<span class="p_header">index a57dc88..714da17 100644</span>
<span class="p_header">--- a/drivers/usb/chipidea/core.c</span>
<span class="p_header">+++ b/drivers/usb/chipidea/core.c</span>
<span class="p_chunk">@@ -871,7 +871,18 @@</span> <span class="p_context"> static struct platform_driver ci_hdrc_driver = {</span>
 	},
 };
 
<span class="p_del">-module_platform_driver(ci_hdrc_driver);</span>
<span class="p_add">+static int __init ci_hdrc_platform_register(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	ci_hdrc_host_driver_init();</span>
<span class="p_add">+	return platform_driver_register(&amp;ci_hdrc_driver);</span>
<span class="p_add">+}</span>
<span class="p_add">+module_init(ci_hdrc_platform_register);</span>
<span class="p_add">+</span>
<span class="p_add">+static void __exit ci_hdrc_platform_unregister(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	platform_driver_unregister(&amp;ci_hdrc_driver);</span>
<span class="p_add">+}</span>
<span class="p_add">+module_exit(ci_hdrc_platform_unregister);</span>
 
 MODULE_ALIAS(&quot;platform:ci_hdrc&quot;);
 MODULE_LICENSE(&quot;GPL v2&quot;);
<span class="p_header">diff --git a/drivers/usb/chipidea/host.c b/drivers/usb/chipidea/host.c</span>
<span class="p_header">index 48731d0..d0162d3 100644</span>
<span class="p_header">--- a/drivers/usb/chipidea/host.c</span>
<span class="p_header">+++ b/drivers/usb/chipidea/host.c</span>
<span class="p_chunk">@@ -175,7 +175,10 @@</span> <span class="p_context"> int ci_hdrc_host_init(struct ci_hdrc *ci)</span>
 	rdrv-&gt;name	= &quot;host&quot;;
 	ci-&gt;roles[CI_ROLE_HOST] = rdrv;
 
<span class="p_del">-	ehci_init_driver(&amp;ci_ehci_hc_driver, &amp;ehci_ci_overrides);</span>
<span class="p_del">-</span>
 	return 0;
 }
<span class="p_add">+</span>
<span class="p_add">+void ci_hdrc_host_driver_init(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	ehci_init_driver(&amp;ci_ehci_hc_driver, &amp;ehci_ci_overrides);</span>
<span class="p_add">+}</span>
<span class="p_header">diff --git a/drivers/usb/chipidea/host.h b/drivers/usb/chipidea/host.h</span>
<span class="p_header">index 5707bf3..0f12f13 100644</span>
<span class="p_header">--- a/drivers/usb/chipidea/host.h</span>
<span class="p_header">+++ b/drivers/usb/chipidea/host.h</span>
<span class="p_chunk">@@ -5,6 +5,7 @@</span> <span class="p_context"></span>
 
 int ci_hdrc_host_init(struct ci_hdrc *ci);
 void ci_hdrc_host_destroy(struct ci_hdrc *ci);
<span class="p_add">+void ci_hdrc_host_driver_init(void);</span>
 
 #else
 
<span class="p_chunk">@@ -18,6 +19,11 @@</span> <span class="p_context"> static inline void ci_hdrc_host_destroy(struct ci_hdrc *ci)</span>
 
 }
 
<span class="p_add">+static void ci_hdrc_host_driver_init(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 #endif
 
 #endif /* __DRIVERS_USB_CHIPIDEA_HOST_H */
<span class="p_header">diff --git a/drivers/usb/gadget/function/f_uac2.c b/drivers/usb/gadget/function/f_uac2.c</span>
<span class="p_header">index 33e1665..df02947 100644</span>
<span class="p_header">--- a/drivers/usb/gadget/function/f_uac2.c</span>
<span class="p_header">+++ b/drivers/usb/gadget/function/f_uac2.c</span>
<span class="p_chunk">@@ -1162,14 +1162,14 @@</span> <span class="p_context"> afunc_set_alt(struct usb_function *fn, unsigned intf, unsigned alt)</span>
 			factor = 1000;
 		} else {
 			ep_desc = &amp;hs_epin_desc;
<span class="p_del">-			factor = 125;</span>
<span class="p_add">+			factor = 8000;</span>
 		}
 
 		/* pre-compute some values for iso_complete() */
 		uac2-&gt;p_framesize = opts-&gt;p_ssize *
 				    num_channels(opts-&gt;p_chmask);
 		rate = opts-&gt;p_srate * uac2-&gt;p_framesize;
<span class="p_del">-		uac2-&gt;p_interval = (1 &lt;&lt; (ep_desc-&gt;bInterval - 1)) * factor;</span>
<span class="p_add">+		uac2-&gt;p_interval = factor / (1 &lt;&lt; (ep_desc-&gt;bInterval - 1));</span>
 		uac2-&gt;p_pktsize = min_t(unsigned int, rate / uac2-&gt;p_interval,
 					prm-&gt;max_psize);
 
<span class="p_header">diff --git a/drivers/usb/gadget/udc/udc-core.c b/drivers/usb/gadget/udc/udc-core.c</span>
<span class="p_header">index e31d574..a1f46b0 100644</span>
<span class="p_header">--- a/drivers/usb/gadget/udc/udc-core.c</span>
<span class="p_header">+++ b/drivers/usb/gadget/udc/udc-core.c</span>
<span class="p_chunk">@@ -298,6 +298,7 @@</span> <span class="p_context"> err4:</span>
 
 err3:
 	put_device(&amp;udc-&gt;dev);
<span class="p_add">+	device_del(&amp;gadget-&gt;dev);</span>
 
 err2:
 	put_device(&amp;gadget-&gt;dev);
<span class="p_header">diff --git a/drivers/usb/host/xhci-mem.c b/drivers/usb/host/xhci-mem.c</span>
<span class="p_header">index a67018e..d44c904 100644</span>
<span class="p_header">--- a/drivers/usb/host/xhci-mem.c</span>
<span class="p_header">+++ b/drivers/usb/host/xhci-mem.c</span>
<span class="p_chunk">@@ -1796,7 +1796,8 @@</span> <span class="p_context"> void xhci_mem_cleanup(struct xhci_hcd *xhci)</span>
 	int size;
 	int i, j, num_ports;
 
<span class="p_del">-	del_timer_sync(&amp;xhci-&gt;cmd_timer);</span>
<span class="p_add">+	if (timer_pending(&amp;xhci-&gt;cmd_timer))</span>
<span class="p_add">+		del_timer_sync(&amp;xhci-&gt;cmd_timer);</span>
 
 	/* Free the Event Ring Segment Table and the actual Event Ring */
 	size = sizeof(struct xhci_erst_entry)*(xhci-&gt;erst.num_entries);
<span class="p_header">diff --git a/drivers/usb/host/xhci-ring.c b/drivers/usb/host/xhci-ring.c</span>
<span class="p_header">index ea19ba3..95c340c 100644</span>
<span class="p_header">--- a/drivers/usb/host/xhci-ring.c</span>
<span class="p_header">+++ b/drivers/usb/host/xhci-ring.c</span>
<span class="p_chunk">@@ -82,7 +82,7 @@</span> <span class="p_context"> dma_addr_t xhci_trb_virt_to_dma(struct xhci_segment *seg,</span>
 		return 0;
 	/* offset in TRBs */
 	segment_offset = trb - seg-&gt;trbs;
<span class="p_del">-	if (segment_offset &gt; TRBS_PER_SEGMENT)</span>
<span class="p_add">+	if (segment_offset &gt;= TRBS_PER_SEGMENT)</span>
 		return 0;
 	return seg-&gt;dma + (segment_offset * sizeof(*trb));
 }
<span class="p_header">diff --git a/drivers/usb/serial/option.c b/drivers/usb/serial/option.c</span>
<span class="p_header">index c8c4e50..463feb8 100644</span>
<span class="p_header">--- a/drivers/usb/serial/option.c</span>
<span class="p_header">+++ b/drivers/usb/serial/option.c</span>
<span class="p_chunk">@@ -1107,6 +1107,8 @@</span> <span class="p_context"> static const struct usb_device_id option_ids[] = {</span>
 	{ USB_DEVICE(QUALCOMM_VENDOR_ID, 0x9000)}, /* SIMCom SIM5218 */
 	{ USB_DEVICE_INTERFACE_CLASS(SIERRA_VENDOR_ID, 0x68c0, 0xff),
 	  .driver_info = (kernel_ulong_t)&amp;sierra_mc73xx_blacklist }, /* MC73xx */
<span class="p_add">+	{ USB_DEVICE_INTERFACE_CLASS(SIERRA_VENDOR_ID, 0x9041, 0xff),</span>
<span class="p_add">+	  .driver_info = (kernel_ulong_t)&amp;sierra_mc73xx_blacklist }, /* MC7305/MC7355 */</span>
 	{ USB_DEVICE(CMOTECH_VENDOR_ID, CMOTECH_PRODUCT_6001) },
 	{ USB_DEVICE(CMOTECH_VENDOR_ID, CMOTECH_PRODUCT_CMU_300) },
 	{ USB_DEVICE(CMOTECH_VENDOR_ID, CMOTECH_PRODUCT_6003),
<span class="p_header">diff --git a/drivers/usb/serial/qcserial.c b/drivers/usb/serial/qcserial.c</span>
<span class="p_header">index 9c63897..d156545 100644</span>
<span class="p_header">--- a/drivers/usb/serial/qcserial.c</span>
<span class="p_header">+++ b/drivers/usb/serial/qcserial.c</span>
<span class="p_chunk">@@ -145,7 +145,6 @@</span> <span class="p_context"> static const struct usb_device_id id_table[] = {</span>
 	{DEVICE_SWI(0x1199, 0x901c)},	/* Sierra Wireless EM7700 */
 	{DEVICE_SWI(0x1199, 0x901f)},	/* Sierra Wireless EM7355 */
 	{DEVICE_SWI(0x1199, 0x9040)},	/* Sierra Wireless Modem */
<span class="p_del">-	{DEVICE_SWI(0x1199, 0x9041)},	/* Sierra Wireless MC7305/MC7355 */</span>
 	{DEVICE_SWI(0x1199, 0x9051)},	/* Netgear AirCard 340U */
 	{DEVICE_SWI(0x1199, 0x9053)},	/* Sierra Wireless Modem */
 	{DEVICE_SWI(0x1199, 0x9054)},	/* Sierra Wireless Modem */
<span class="p_chunk">@@ -158,6 +157,7 @@</span> <span class="p_context"> static const struct usb_device_id id_table[] = {</span>
 	{DEVICE_SWI(0x413c, 0x81a4)},	/* Dell Wireless 5570e HSPA+ (42Mbps) Mobile Broadband Card */
 	{DEVICE_SWI(0x413c, 0x81a8)},	/* Dell Wireless 5808 Gobi(TM) 4G LTE Mobile Broadband Card */
 	{DEVICE_SWI(0x413c, 0x81a9)},	/* Dell Wireless 5808e Gobi(TM) 4G LTE Mobile Broadband Card */
<span class="p_add">+	{DEVICE_SWI(0x413c, 0x81b1)},	/* Dell Wireless 5809e Gobi(TM) 4G LTE Mobile Broadband Card */</span>
 
 	/* Huawei devices */
 	{DEVICE_HWI(0x03f0, 0x581d)},	/* HP lt4112 LTE/HSPA+ Gobi 4G Modem (Huawei me906e) */
<span class="p_header">diff --git a/drivers/usb/serial/sierra.c b/drivers/usb/serial/sierra.c</span>
<span class="p_header">index 46179a0..07d1ecd 100644</span>
<span class="p_header">--- a/drivers/usb/serial/sierra.c</span>
<span class="p_header">+++ b/drivers/usb/serial/sierra.c</span>
<span class="p_chunk">@@ -289,6 +289,7 @@</span> <span class="p_context"> static const struct usb_device_id id_table[] = {</span>
 	{ USB_DEVICE_AND_INTERFACE_INFO(0x1199, 0x68AA, 0xFF, 0xFF, 0xFF),
 	  .driver_info = (kernel_ulong_t)&amp;direct_ip_interface_blacklist
 	},
<span class="p_add">+	{ USB_DEVICE(0x1199, 0x68AB) }, /* Sierra Wireless AR8550 */</span>
 	/* AT&amp;T Direct IP LTE modems */
 	{ USB_DEVICE_AND_INTERFACE_INFO(0x0F3D, 0x68AA, 0xFF, 0xFF, 0xFF),
 	  .driver_info = (kernel_ulong_t)&amp;direct_ip_interface_blacklist
<span class="p_header">diff --git a/drivers/video/fbdev/Kconfig b/drivers/video/fbdev/Kconfig</span>
<span class="p_header">index 4916c97..dc2406a 100644</span>
<span class="p_header">--- a/drivers/video/fbdev/Kconfig</span>
<span class="p_header">+++ b/drivers/video/fbdev/Kconfig</span>
<span class="p_chunk">@@ -298,7 +298,7 @@</span> <span class="p_context"> config FB_ARMCLCD</span>
 
 # Helper logic selected only by the ARM Versatile platform family.
 config PLAT_VERSATILE_CLCD
<span class="p_del">-	def_bool ARCH_VERSATILE || ARCH_REALVIEW || ARCH_VEXPRESS</span>
<span class="p_add">+	def_bool ARCH_VERSATILE || ARCH_REALVIEW || ARCH_VEXPRESS || ARCH_INTEGRATOR</span>
 	depends on ARM
 	depends on FB_ARMCLCD &amp;&amp; FB=y
 
<span class="p_header">diff --git a/drivers/xen/gntdev.c b/drivers/xen/gntdev.c</span>
<span class="p_header">index 073b4a1..91cc446 100644</span>
<span class="p_header">--- a/drivers/xen/gntdev.c</span>
<span class="p_header">+++ b/drivers/xen/gntdev.c</span>
<span class="p_chunk">@@ -67,7 +67,7 @@</span> <span class="p_context"> struct gntdev_priv {</span>
 	 * Only populated if populate_freeable_maps == 1 */
 	struct list_head freeable_maps;
 	/* lock protects maps and freeable_maps */
<span class="p_del">-	spinlock_t lock;</span>
<span class="p_add">+	struct mutex lock;</span>
 	struct mm_struct *mm;
 	struct mmu_notifier mn;
 };
<span class="p_chunk">@@ -216,9 +216,9 @@</span> <span class="p_context"> static void gntdev_put_map(struct gntdev_priv *priv, struct grant_map *map)</span>
 	}
 
 	if (populate_freeable_maps &amp;&amp; priv) {
<span class="p_del">-		spin_lock(&amp;priv-&gt;lock);</span>
<span class="p_add">+		mutex_lock(&amp;priv-&gt;lock);</span>
 		list_del(&amp;map-&gt;next);
<span class="p_del">-		spin_unlock(&amp;priv-&gt;lock);</span>
<span class="p_add">+		mutex_unlock(&amp;priv-&gt;lock);</span>
 	}
 
 	if (map-&gt;pages &amp;&amp; !use_ptemod)
<span class="p_chunk">@@ -387,9 +387,9 @@</span> <span class="p_context"> static void gntdev_vma_close(struct vm_area_struct *vma)</span>
 		 * not do any unmapping, since that has been done prior to
 		 * closing the vma, but it may still iterate the unmap_ops list.
 		 */
<span class="p_del">-		spin_lock(&amp;priv-&gt;lock);</span>
<span class="p_add">+		mutex_lock(&amp;priv-&gt;lock);</span>
 		map-&gt;vma = NULL;
<span class="p_del">-		spin_unlock(&amp;priv-&gt;lock);</span>
<span class="p_add">+		mutex_unlock(&amp;priv-&gt;lock);</span>
 	}
 	vma-&gt;vm_private_data = NULL;
 	gntdev_put_map(priv, map);
<span class="p_chunk">@@ -433,14 +433,14 @@</span> <span class="p_context"> static void mn_invl_range_start(struct mmu_notifier *mn,</span>
 	struct gntdev_priv *priv = container_of(mn, struct gntdev_priv, mn);
 	struct grant_map *map;
 
<span class="p_del">-	spin_lock(&amp;priv-&gt;lock);</span>
<span class="p_add">+	mutex_lock(&amp;priv-&gt;lock);</span>
 	list_for_each_entry(map, &amp;priv-&gt;maps, next) {
 		unmap_if_in_range(map, start, end);
 	}
 	list_for_each_entry(map, &amp;priv-&gt;freeable_maps, next) {
 		unmap_if_in_range(map, start, end);
 	}
<span class="p_del">-	spin_unlock(&amp;priv-&gt;lock);</span>
<span class="p_add">+	mutex_unlock(&amp;priv-&gt;lock);</span>
 }
 
 static void mn_invl_page(struct mmu_notifier *mn,
<span class="p_chunk">@@ -457,7 +457,7 @@</span> <span class="p_context"> static void mn_release(struct mmu_notifier *mn,</span>
 	struct grant_map *map;
 	int err;
 
<span class="p_del">-	spin_lock(&amp;priv-&gt;lock);</span>
<span class="p_add">+	mutex_lock(&amp;priv-&gt;lock);</span>
 	list_for_each_entry(map, &amp;priv-&gt;maps, next) {
 		if (!map-&gt;vma)
 			continue;
<span class="p_chunk">@@ -476,7 +476,7 @@</span> <span class="p_context"> static void mn_release(struct mmu_notifier *mn,</span>
 		err = unmap_grant_pages(map, /* offset */ 0, map-&gt;count);
 		WARN_ON(err);
 	}
<span class="p_del">-	spin_unlock(&amp;priv-&gt;lock);</span>
<span class="p_add">+	mutex_unlock(&amp;priv-&gt;lock);</span>
 }
 
 static struct mmu_notifier_ops gntdev_mmu_ops = {
<span class="p_chunk">@@ -498,7 +498,7 @@</span> <span class="p_context"> static int gntdev_open(struct inode *inode, struct file *flip)</span>
 
 	INIT_LIST_HEAD(&amp;priv-&gt;maps);
 	INIT_LIST_HEAD(&amp;priv-&gt;freeable_maps);
<span class="p_del">-	spin_lock_init(&amp;priv-&gt;lock);</span>
<span class="p_add">+	mutex_init(&amp;priv-&gt;lock);</span>
 
 	if (use_ptemod) {
 		priv-&gt;mm = get_task_mm(current);
<span class="p_chunk">@@ -529,12 +529,14 @@</span> <span class="p_context"> static int gntdev_release(struct inode *inode, struct file *flip)</span>
 
 	pr_debug(&quot;priv %p\n&quot;, priv);
 
<span class="p_add">+	mutex_lock(&amp;priv-&gt;lock);</span>
 	while (!list_empty(&amp;priv-&gt;maps)) {
 		map = list_entry(priv-&gt;maps.next, struct grant_map, next);
 		list_del(&amp;map-&gt;next);
 		gntdev_put_map(NULL /* already removed */, map);
 	}
 	WARN_ON(!list_empty(&amp;priv-&gt;freeable_maps));
<span class="p_add">+	mutex_unlock(&amp;priv-&gt;lock);</span>
 
 	if (use_ptemod)
 		mmu_notifier_unregister(&amp;priv-&gt;mn, priv-&gt;mm);
<span class="p_chunk">@@ -572,10 +574,10 @@</span> <span class="p_context"> static long gntdev_ioctl_map_grant_ref(struct gntdev_priv *priv,</span>
 		return -EFAULT;
 	}
 
<span class="p_del">-	spin_lock(&amp;priv-&gt;lock);</span>
<span class="p_add">+	mutex_lock(&amp;priv-&gt;lock);</span>
 	gntdev_add_map(priv, map);
 	op.index = map-&gt;index &lt;&lt; PAGE_SHIFT;
<span class="p_del">-	spin_unlock(&amp;priv-&gt;lock);</span>
<span class="p_add">+	mutex_unlock(&amp;priv-&gt;lock);</span>
 
 	if (copy_to_user(u, &amp;op, sizeof(op)) != 0)
 		return -EFAULT;
<span class="p_chunk">@@ -594,7 +596,7 @@</span> <span class="p_context"> static long gntdev_ioctl_unmap_grant_ref(struct gntdev_priv *priv,</span>
 		return -EFAULT;
 	pr_debug(&quot;priv %p, del %d+%d\n&quot;, priv, (int)op.index, (int)op.count);
 
<span class="p_del">-	spin_lock(&amp;priv-&gt;lock);</span>
<span class="p_add">+	mutex_lock(&amp;priv-&gt;lock);</span>
 	map = gntdev_find_map_index(priv, op.index &gt;&gt; PAGE_SHIFT, op.count);
 	if (map) {
 		list_del(&amp;map-&gt;next);
<span class="p_chunk">@@ -602,7 +604,7 @@</span> <span class="p_context"> static long gntdev_ioctl_unmap_grant_ref(struct gntdev_priv *priv,</span>
 			list_add_tail(&amp;map-&gt;next, &amp;priv-&gt;freeable_maps);
 		err = 0;
 	}
<span class="p_del">-	spin_unlock(&amp;priv-&gt;lock);</span>
<span class="p_add">+	mutex_unlock(&amp;priv-&gt;lock);</span>
 	if (map)
 		gntdev_put_map(priv, map);
 	return err;
<span class="p_chunk">@@ -670,7 +672,7 @@</span> <span class="p_context"> static long gntdev_ioctl_notify(struct gntdev_priv *priv, void __user *u)</span>
 	out_flags = op.action;
 	out_event = op.event_channel_port;
 
<span class="p_del">-	spin_lock(&amp;priv-&gt;lock);</span>
<span class="p_add">+	mutex_lock(&amp;priv-&gt;lock);</span>
 
 	list_for_each_entry(map, &amp;priv-&gt;maps, next) {
 		uint64_t begin = map-&gt;index &lt;&lt; PAGE_SHIFT;
<span class="p_chunk">@@ -698,7 +700,7 @@</span> <span class="p_context"> static long gntdev_ioctl_notify(struct gntdev_priv *priv, void __user *u)</span>
 	rc = 0;
 
  unlock_out:
<span class="p_del">-	spin_unlock(&amp;priv-&gt;lock);</span>
<span class="p_add">+	mutex_unlock(&amp;priv-&gt;lock);</span>
 
 	/* Drop the reference to the event channel we did not save in the map */
 	if (out_flags &amp; UNMAP_NOTIFY_SEND_EVENT)
<span class="p_chunk">@@ -748,7 +750,7 @@</span> <span class="p_context"> static int gntdev_mmap(struct file *flip, struct vm_area_struct *vma)</span>
 	pr_debug(&quot;map %d+%d at %lx (pgoff %lx)\n&quot;,
 			index, count, vma-&gt;vm_start, vma-&gt;vm_pgoff);
 
<span class="p_del">-	spin_lock(&amp;priv-&gt;lock);</span>
<span class="p_add">+	mutex_lock(&amp;priv-&gt;lock);</span>
 	map = gntdev_find_map_index(priv, index, count);
 	if (!map)
 		goto unlock_out;
<span class="p_chunk">@@ -783,7 +785,7 @@</span> <span class="p_context"> static int gntdev_mmap(struct file *flip, struct vm_area_struct *vma)</span>
 			map-&gt;flags |= GNTMAP_readonly;
 	}
 
<span class="p_del">-	spin_unlock(&amp;priv-&gt;lock);</span>
<span class="p_add">+	mutex_unlock(&amp;priv-&gt;lock);</span>
 
 	if (use_ptemod) {
 		err = apply_to_page_range(vma-&gt;vm_mm, vma-&gt;vm_start,
<span class="p_chunk">@@ -811,11 +813,11 @@</span> <span class="p_context"> static int gntdev_mmap(struct file *flip, struct vm_area_struct *vma)</span>
 	return 0;
 
 unlock_out:
<span class="p_del">-	spin_unlock(&amp;priv-&gt;lock);</span>
<span class="p_add">+	mutex_unlock(&amp;priv-&gt;lock);</span>
 	return err;
 
 out_unlock_put:
<span class="p_del">-	spin_unlock(&amp;priv-&gt;lock);</span>
<span class="p_add">+	mutex_unlock(&amp;priv-&gt;lock);</span>
 out_put_map:
 	if (use_ptemod)
 		map-&gt;vma = NULL;
<span class="p_header">diff --git a/fs/ext4/extents.c b/fs/ext4/extents.c</span>
<span class="p_header">index 4252860..3292cd9 100644</span>
<span class="p_header">--- a/fs/ext4/extents.c</span>
<span class="p_header">+++ b/fs/ext4/extents.c</span>
<span class="p_chunk">@@ -4854,19 +4854,6 @@</span> <span class="p_context"> static long ext4_zero_range(struct file *file, loff_t offset,</span>
 					     flags, mode);
 		if (ret)
 			goto out_dio;
<span class="p_del">-		/*</span>
<span class="p_del">-		 * Remove entire range from the extent status tree.</span>
<span class="p_del">-		 *</span>
<span class="p_del">-		 * ext4_es_remove_extent(inode, lblk, max_blocks) is</span>
<span class="p_del">-		 * NOT sufficient.  I&#39;m not sure why this is the case,</span>
<span class="p_del">-		 * but let&#39;s be conservative and remove the extent</span>
<span class="p_del">-		 * status tree for the entire inode.  There should be</span>
<span class="p_del">-		 * no outstanding delalloc extents thanks to the</span>
<span class="p_del">-		 * filemap_write_and_wait_range() call above.</span>
<span class="p_del">-		 */</span>
<span class="p_del">-		ret = ext4_es_remove_extent(inode, 0, EXT_MAX_BLOCKS);</span>
<span class="p_del">-		if (ret)</span>
<span class="p_del">-			goto out_dio;</span>
 	}
 	if (!partial_begin &amp;&amp; !partial_end)
 		goto out_dio;
<span class="p_header">diff --git a/fs/nfsd/nfs4xdr.c b/fs/nfsd/nfs4xdr.c</span>
<span class="p_header">index 281d126..043ed3f 100644</span>
<span class="p_header">--- a/fs/nfsd/nfs4xdr.c</span>
<span class="p_header">+++ b/fs/nfsd/nfs4xdr.c</span>
<span class="p_chunk">@@ -1991,6 +1991,7 @@</span> <span class="p_context"> nfsd4_encode_aclname(struct xdr_stream *xdr, struct svc_rqst *rqstp,</span>
 #define WORD0_ABSENT_FS_ATTRS (FATTR4_WORD0_FS_LOCATIONS | FATTR4_WORD0_FSID | \
 			      FATTR4_WORD0_RDATTR_ERROR)
 #define WORD1_ABSENT_FS_ATTRS FATTR4_WORD1_MOUNTED_ON_FILEID
<span class="p_add">+#define WORD2_ABSENT_FS_ATTRS 0</span>
 
 #ifdef CONFIG_NFSD_V4_SECURITY_LABEL
 static inline __be32
<span class="p_chunk">@@ -2019,7 +2020,7 @@</span> <span class="p_context"> nfsd4_encode_security_label(struct xdr_stream *xdr, struct svc_rqst *rqstp,</span>
 { return 0; }
 #endif
 
<span class="p_del">-static __be32 fattr_handle_absent_fs(u32 *bmval0, u32 *bmval1, u32 *rdattr_err)</span>
<span class="p_add">+static __be32 fattr_handle_absent_fs(u32 *bmval0, u32 *bmval1, u32 *bmval2, u32 *rdattr_err)</span>
 {
 	/* As per referral draft:  */
 	if (*bmval0 &amp; ~WORD0_ABSENT_FS_ATTRS ||
<span class="p_chunk">@@ -2032,6 +2033,7 @@</span> <span class="p_context"> static __be32 fattr_handle_absent_fs(u32 *bmval0, u32 *bmval1, u32 *rdattr_err)</span>
 	}
 	*bmval0 &amp;= WORD0_ABSENT_FS_ATTRS;
 	*bmval1 &amp;= WORD1_ABSENT_FS_ATTRS;
<span class="p_add">+	*bmval2 &amp;= WORD2_ABSENT_FS_ATTRS;</span>
 	return 0;
 }
 
<span class="p_chunk">@@ -2095,8 +2097,7 @@</span> <span class="p_context"> nfsd4_encode_fattr(struct xdr_stream *xdr, struct svc_fh *fhp,</span>
 	BUG_ON(bmval2 &amp; ~nfsd_suppattrs2(minorversion));
 
 	if (exp-&gt;ex_fslocs.migrated) {
<span class="p_del">-		BUG_ON(bmval[2]);</span>
<span class="p_del">-		status = fattr_handle_absent_fs(&amp;bmval0, &amp;bmval1, &amp;rdattr_err);</span>
<span class="p_add">+		status = fattr_handle_absent_fs(&amp;bmval0, &amp;bmval1, &amp;bmval2, &amp;rdattr_err);</span>
 		if (status)
 			goto out;
 	}
<span class="p_chunk">@@ -2139,8 +2140,8 @@</span> <span class="p_context"> nfsd4_encode_fattr(struct xdr_stream *xdr, struct svc_fh *fhp,</span>
 	}
 
 #ifdef CONFIG_NFSD_V4_SECURITY_LABEL
<span class="p_del">-	if ((bmval[2] &amp; FATTR4_WORD2_SECURITY_LABEL) ||</span>
<span class="p_del">-			bmval[0] &amp; FATTR4_WORD0_SUPPORTED_ATTRS) {</span>
<span class="p_add">+	if ((bmval2 &amp; FATTR4_WORD2_SECURITY_LABEL) ||</span>
<span class="p_add">+	     bmval0 &amp; FATTR4_WORD0_SUPPORTED_ATTRS) {</span>
 		err = security_inode_getsecctx(dentry-&gt;d_inode,
 						&amp;context, &amp;contextlen);
 		contextsupport = (err == 0);
<span class="p_header">diff --git a/fs/notify/mark.c b/fs/notify/mark.c</span>
<span class="p_header">index 92e48c7..39ddcaf 100644</span>
<span class="p_header">--- a/fs/notify/mark.c</span>
<span class="p_header">+++ b/fs/notify/mark.c</span>
<span class="p_chunk">@@ -412,16 +412,36 @@</span> <span class="p_context"> void fsnotify_clear_marks_by_group_flags(struct fsnotify_group *group,</span>
 					 unsigned int flags)
 {
 	struct fsnotify_mark *lmark, *mark;
<span class="p_add">+	LIST_HEAD(to_free);</span>
 
<span class="p_add">+	/*</span>
<span class="p_add">+	 * We have to be really careful here. Anytime we drop mark_mutex, e.g.</span>
<span class="p_add">+	 * fsnotify_clear_marks_by_inode() can come and free marks. Even in our</span>
<span class="p_add">+	 * to_free list so we have to use mark_mutex even when accessing that</span>
<span class="p_add">+	 * list. And freeing mark requires us to drop mark_mutex. So we can</span>
<span class="p_add">+	 * reliably free only the first mark in the list. That&#39;s why we first</span>
<span class="p_add">+	 * move marks to free to to_free list in one go and then free marks in</span>
<span class="p_add">+	 * to_free list one by one.</span>
<span class="p_add">+	 */</span>
 	mutex_lock_nested(&amp;group-&gt;mark_mutex, SINGLE_DEPTH_NESTING);
 	list_for_each_entry_safe(mark, lmark, &amp;group-&gt;marks_list, g_list) {
<span class="p_del">-		if (mark-&gt;flags &amp; flags) {</span>
<span class="p_del">-			fsnotify_get_mark(mark);</span>
<span class="p_del">-			fsnotify_destroy_mark_locked(mark, group);</span>
<span class="p_del">-			fsnotify_put_mark(mark);</span>
<span class="p_del">-		}</span>
<span class="p_add">+		if (mark-&gt;flags &amp; flags)</span>
<span class="p_add">+			list_move(&amp;mark-&gt;g_list, &amp;to_free);</span>
 	}
 	mutex_unlock(&amp;group-&gt;mark_mutex);
<span class="p_add">+</span>
<span class="p_add">+	while (1) {</span>
<span class="p_add">+		mutex_lock_nested(&amp;group-&gt;mark_mutex, SINGLE_DEPTH_NESTING);</span>
<span class="p_add">+		if (list_empty(&amp;to_free)) {</span>
<span class="p_add">+			mutex_unlock(&amp;group-&gt;mark_mutex);</span>
<span class="p_add">+			break;</span>
<span class="p_add">+		}</span>
<span class="p_add">+		mark = list_first_entry(&amp;to_free, struct fsnotify_mark, g_list);</span>
<span class="p_add">+		fsnotify_get_mark(mark);</span>
<span class="p_add">+		fsnotify_destroy_mark_locked(mark, group);</span>
<span class="p_add">+		mutex_unlock(&amp;group-&gt;mark_mutex);</span>
<span class="p_add">+		fsnotify_put_mark(mark);</span>
<span class="p_add">+	}</span>
 }
 
 /*
<span class="p_header">diff --git a/fs/ocfs2/dlmglue.c b/fs/ocfs2/dlmglue.c</span>
<span class="p_header">index 1c423af..ba6c538 100644</span>
<span class="p_header">--- a/fs/ocfs2/dlmglue.c</span>
<span class="p_header">+++ b/fs/ocfs2/dlmglue.c</span>
<span class="p_chunk">@@ -4017,9 +4017,13 @@</span> <span class="p_context"> static void ocfs2_downconvert_thread_do_work(struct ocfs2_super *osb)</span>
 	osb-&gt;dc_work_sequence = osb-&gt;dc_wake_sequence;
 
 	processed = osb-&gt;blocked_lock_count;
<span class="p_del">-	while (processed) {</span>
<span class="p_del">-		BUG_ON(list_empty(&amp;osb-&gt;blocked_lock_list));</span>
<span class="p_del">-</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * blocked lock processing in this loop might call iput which can</span>
<span class="p_add">+	 * remove items off osb-&gt;blocked_lock_list. Downconvert up to</span>
<span class="p_add">+	 * &#39;processed&#39; number of locks, but stop short if we had some</span>
<span class="p_add">+	 * removed in ocfs2_mark_lockres_freeing when downconverting.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	while (processed &amp;&amp; !list_empty(&amp;osb-&gt;blocked_lock_list)) {</span>
 		lockres = list_entry(osb-&gt;blocked_lock_list.next,
 				     struct ocfs2_lock_res, l_blocked_list);
 		list_del_init(&amp;lockres-&gt;l_blocked_list);
<span class="p_header">diff --git a/include/drm/drm_crtc.h b/include/drm/drm_crtc.h</span>
<span class="p_header">index 3dab77c..b863298 100644</span>
<span class="p_header">--- a/include/drm/drm_crtc.h</span>
<span class="p_header">+++ b/include/drm/drm_crtc.h</span>
<span class="p_chunk">@@ -689,8 +689,6 @@</span> <span class="p_context"> struct drm_connector {</span>
 	uint8_t num_h_tile, num_v_tile;
 	uint8_t tile_h_loc, tile_v_loc;
 	uint16_t tile_h_size, tile_v_size;
<span class="p_del">-</span>
<span class="p_del">-	struct list_head destroy_list;</span>
 };
 
 /**
<span class="p_header">diff --git a/include/drm/drm_pciids.h b/include/drm/drm_pciids.h</span>
<span class="p_header">index 45c39a3..8bc073d 100644</span>
<span class="p_header">--- a/include/drm/drm_pciids.h</span>
<span class="p_header">+++ b/include/drm/drm_pciids.h</span>
<span class="p_chunk">@@ -172,6 +172,7 @@</span> <span class="p_context"></span>
 	{0x1002, 0x6610, PCI_ANY_ID, PCI_ANY_ID, 0, 0, CHIP_OLAND|RADEON_NEW_MEMMAP}, \
 	{0x1002, 0x6611, PCI_ANY_ID, PCI_ANY_ID, 0, 0, CHIP_OLAND|RADEON_NEW_MEMMAP}, \
 	{0x1002, 0x6613, PCI_ANY_ID, PCI_ANY_ID, 0, 0, CHIP_OLAND|RADEON_NEW_MEMMAP}, \
<span class="p_add">+	{0x1002, 0x6617, PCI_ANY_ID, PCI_ANY_ID, 0, 0, CHIP_OLAND|RADEON_IS_MOBILITY|RADEON_NEW_MEMMAP}, \</span>
 	{0x1002, 0x6620, PCI_ANY_ID, PCI_ANY_ID, 0, 0, CHIP_OLAND|RADEON_IS_MOBILITY|RADEON_NEW_MEMMAP}, \
 	{0x1002, 0x6621, PCI_ANY_ID, PCI_ANY_ID, 0, 0, CHIP_OLAND|RADEON_IS_MOBILITY|RADEON_NEW_MEMMAP}, \
 	{0x1002, 0x6623, PCI_ANY_ID, PCI_ANY_ID, 0, 0, CHIP_OLAND|RADEON_IS_MOBILITY|RADEON_NEW_MEMMAP}, \
<span class="p_header">diff --git a/include/linux/acpi.h b/include/linux/acpi.h</span>
<span class="p_header">index 0e73e05..77d4941 100644</span>
<span class="p_header">--- a/include/linux/acpi.h</span>
<span class="p_header">+++ b/include/linux/acpi.h</span>
<span class="p_chunk">@@ -181,7 +181,7 @@</span> <span class="p_context"> struct pci_dev;</span>
 
 int acpi_pci_irq_enable (struct pci_dev *dev);
 void acpi_penalize_isa_irq(int irq, int active);
<span class="p_del">-</span>
<span class="p_add">+void acpi_penalize_sci_irq(int irq, int trigger, int polarity);</span>
 void acpi_pci_irq_disable (struct pci_dev *dev);
 
 extern int ec_read(u8 addr, u8 *val);
<span class="p_header">diff --git a/include/net/ip.h b/include/net/ip.h</span>
<span class="p_header">index c0c26c3..d00ebdf 100644</span>
<span class="p_header">--- a/include/net/ip.h</span>
<span class="p_header">+++ b/include/net/ip.h</span>
<span class="p_chunk">@@ -160,6 +160,7 @@</span> <span class="p_context"> static inline __u8 get_rtconn_flags(struct ipcm_cookie* ipc, struct sock* sk)</span>
 }
 
 /* datagram.c */
<span class="p_add">+int __ip4_datagram_connect(struct sock *sk, struct sockaddr *uaddr, int addr_len);</span>
 int ip4_datagram_connect(struct sock *sk, struct sockaddr *uaddr, int addr_len);
 
 void ip4_datagram_release_cb(struct sock *sk);
<span class="p_header">diff --git a/include/uapi/linux/pci_regs.h b/include/uapi/linux/pci_regs.h</span>
<span class="p_header">index 4a1d0cc..7dd8d80 100644</span>
<span class="p_header">--- a/include/uapi/linux/pci_regs.h</span>
<span class="p_header">+++ b/include/uapi/linux/pci_regs.h</span>
<span class="p_chunk">@@ -319,6 +319,7 @@</span> <span class="p_context"></span>
 #define PCI_MSIX_PBA		8	/* Pending Bit Array offset */
 #define  PCI_MSIX_PBA_BIR	0x00000007 /* BAR index */
 #define  PCI_MSIX_PBA_OFFSET	0xfffffff8 /* Offset into specified BAR */
<span class="p_add">+#define PCI_MSIX_FLAGS_BIRMASK	PCI_MSIX_PBA_BIR /* deprecated */</span>
 #define PCI_CAP_MSIX_SIZEOF	12	/* size of MSIX registers */
 
 /* MSI-X Table entry format */
<span class="p_header">diff --git a/ipc/mqueue.c b/ipc/mqueue.c</span>
<span class="p_header">index 7635a1c..182ed02 100644</span>
<span class="p_header">--- a/ipc/mqueue.c</span>
<span class="p_header">+++ b/ipc/mqueue.c</span>
<span class="p_chunk">@@ -143,7 +143,6 @@</span> <span class="p_context"> static int msg_insert(struct msg_msg *msg, struct mqueue_inode_info *info)</span>
 		if (!leaf)
 			return -ENOMEM;
 		INIT_LIST_HEAD(&amp;leaf-&gt;msg_list);
<span class="p_del">-		info-&gt;qsize += sizeof(*leaf);</span>
 	}
 	leaf-&gt;priority = msg-&gt;m_type;
 	rb_link_node(&amp;leaf-&gt;rb_node, parent, p);
<span class="p_chunk">@@ -188,7 +187,6 @@</span> <span class="p_context"> try_again:</span>
 			     &quot;lazy leaf delete!\n&quot;);
 		rb_erase(&amp;leaf-&gt;rb_node, &amp;info-&gt;msg_tree);
 		if (info-&gt;node_cache) {
<span class="p_del">-			info-&gt;qsize -= sizeof(*leaf);</span>
 			kfree(leaf);
 		} else {
 			info-&gt;node_cache = leaf;
<span class="p_chunk">@@ -201,7 +199,6 @@</span> <span class="p_context"> try_again:</span>
 		if (list_empty(&amp;leaf-&gt;msg_list)) {
 			rb_erase(&amp;leaf-&gt;rb_node, &amp;info-&gt;msg_tree);
 			if (info-&gt;node_cache) {
<span class="p_del">-				info-&gt;qsize -= sizeof(*leaf);</span>
 				kfree(leaf);
 			} else {
 				info-&gt;node_cache = leaf;
<span class="p_chunk">@@ -1026,7 +1023,6 @@</span> <span class="p_context"> SYSCALL_DEFINE5(mq_timedsend, mqd_t, mqdes, const char __user *, u_msg_ptr,</span>
 		/* Save our speculative allocation into the cache */
 		INIT_LIST_HEAD(&amp;new_leaf-&gt;msg_list);
 		info-&gt;node_cache = new_leaf;
<span class="p_del">-		info-&gt;qsize += sizeof(*new_leaf);</span>
 		new_leaf = NULL;
 	} else {
 		kfree(new_leaf);
<span class="p_chunk">@@ -1133,7 +1129,6 @@</span> <span class="p_context"> SYSCALL_DEFINE5(mq_timedreceive, mqd_t, mqdes, char __user *, u_msg_ptr,</span>
 		/* Save our speculative allocation into the cache */
 		INIT_LIST_HEAD(&amp;new_leaf-&gt;msg_list);
 		info-&gt;node_cache = new_leaf;
<span class="p_del">-		info-&gt;qsize += sizeof(*new_leaf);</span>
 	} else {
 		kfree(new_leaf);
 	}
<span class="p_header">diff --git a/ipc/sem.c b/ipc/sem.c</span>
<span class="p_header">index 6115146..541cb0f 100644</span>
<span class="p_header">--- a/ipc/sem.c</span>
<span class="p_header">+++ b/ipc/sem.c</span>
<span class="p_chunk">@@ -253,6 +253,16 @@</span> <span class="p_context"> static void sem_rcu_free(struct rcu_head *head)</span>
 }
 
 /*
<span class="p_add">+ * spin_unlock_wait() and !spin_is_locked() are not memory barriers, they</span>
<span class="p_add">+ * are only control barriers.</span>
<span class="p_add">+ * The code must pair with spin_unlock(&amp;sem-&gt;lock) or</span>
<span class="p_add">+ * spin_unlock(&amp;sem_perm.lock), thus just the control barrier is insufficient.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * smp_rmb() is sufficient, as writes cannot pass the control barrier.</span>
<span class="p_add">+ */</span>
<span class="p_add">+#define ipc_smp_acquire__after_spin_is_unlocked()	smp_rmb()</span>
<span class="p_add">+</span>
<span class="p_add">+/*</span>
  * Wait until all currently ongoing simple ops have completed.
  * Caller must own sem_perm.lock.
  * New simple ops cannot start, because simple ops first check
<span class="p_chunk">@@ -275,6 +285,7 @@</span> <span class="p_context"> static void sem_wait_array(struct sem_array *sma)</span>
 		sem = sma-&gt;sem_base + i;
 		spin_unlock_wait(&amp;sem-&gt;lock);
 	}
<span class="p_add">+	ipc_smp_acquire__after_spin_is_unlocked();</span>
 }
 
 /*
<span class="p_chunk">@@ -327,13 +338,12 @@</span> <span class="p_context"> static inline int sem_lock(struct sem_array *sma, struct sembuf *sops,</span>
 		/* Then check that the global lock is free */
 		if (!spin_is_locked(&amp;sma-&gt;sem_perm.lock)) {
 			/*
<span class="p_del">-			 * The ipc object lock check must be visible on all</span>
<span class="p_del">-			 * cores before rechecking the complex count.  Otherwise</span>
<span class="p_del">-			 * we can race with  another thread that does:</span>
<span class="p_add">+			 * We need a memory barrier with acquire semantics,</span>
<span class="p_add">+			 * otherwise we can race with another thread that does:</span>
 			 *	complex_count++;
 			 *	spin_unlock(sem_perm.lock);
 			 */
<span class="p_del">-			smp_rmb();</span>
<span class="p_add">+			ipc_smp_acquire__after_spin_is_unlocked();</span>
 
 			/*
 			 * Now repeat the test of complex_count:
<span class="p_chunk">@@ -2074,17 +2084,28 @@</span> <span class="p_context"> void exit_sem(struct task_struct *tsk)</span>
 		rcu_read_lock();
 		un = list_entry_rcu(ulp-&gt;list_proc.next,
 				    struct sem_undo, list_proc);
<span class="p_del">-		if (&amp;un-&gt;list_proc == &amp;ulp-&gt;list_proc)</span>
<span class="p_del">-			semid = -1;</span>
<span class="p_del">-		 else</span>
<span class="p_del">-			semid = un-&gt;semid;</span>
<span class="p_add">+		if (&amp;un-&gt;list_proc == &amp;ulp-&gt;list_proc) {</span>
<span class="p_add">+			/*</span>
<span class="p_add">+			 * We must wait for freeary() before freeing this ulp,</span>
<span class="p_add">+			 * in case we raced with last sem_undo. There is a small</span>
<span class="p_add">+			 * possibility where we exit while freeary() didn&#39;t</span>
<span class="p_add">+			 * finish unlocking sem_undo_list.</span>
<span class="p_add">+			 */</span>
<span class="p_add">+			spin_unlock_wait(&amp;ulp-&gt;lock);</span>
<span class="p_add">+			rcu_read_unlock();</span>
<span class="p_add">+			break;</span>
<span class="p_add">+		}</span>
<span class="p_add">+		spin_lock(&amp;ulp-&gt;lock);</span>
<span class="p_add">+		semid = un-&gt;semid;</span>
<span class="p_add">+		spin_unlock(&amp;ulp-&gt;lock);</span>
 
<span class="p_add">+		/* exit_sem raced with IPC_RMID, nothing to do */</span>
 		if (semid == -1) {
 			rcu_read_unlock();
<span class="p_del">-			break;</span>
<span class="p_add">+			continue;</span>
 		}
 
<span class="p_del">-		sma = sem_obtain_object_check(tsk-&gt;nsproxy-&gt;ipc_ns, un-&gt;semid);</span>
<span class="p_add">+		sma = sem_obtain_object_check(tsk-&gt;nsproxy-&gt;ipc_ns, semid);</span>
 		/* exit_sem raced with IPC_RMID, nothing to do */
 		if (IS_ERR(sma)) {
 			rcu_read_unlock();
<span class="p_header">diff --git a/kernel/cpuset.c b/kernel/cpuset.c</span>
<span class="p_header">index 9e25599..c90edf6 100644</span>
<span class="p_header">--- a/kernel/cpuset.c</span>
<span class="p_header">+++ b/kernel/cpuset.c</span>
<span class="p_chunk">@@ -1214,7 +1214,7 @@</span> <span class="p_context"> static int update_nodemask(struct cpuset *cs, struct cpuset *trialcs,</span>
 	spin_unlock_irq(&amp;callback_lock);
 
 	/* use trialcs-&gt;mems_allowed as a temp variable */
<span class="p_del">-	update_nodemasks_hier(cs, &amp;cs-&gt;mems_allowed);</span>
<span class="p_add">+	update_nodemasks_hier(cs, &amp;trialcs-&gt;mems_allowed);</span>
 done:
 	return retval;
 }
<span class="p_header">diff --git a/kernel/events/core.c b/kernel/events/core.c</span>
<span class="p_header">index b59b7b0..3527176 100644</span>
<span class="p_header">--- a/kernel/events/core.c</span>
<span class="p_header">+++ b/kernel/events/core.c</span>
<span class="p_chunk">@@ -3729,28 +3729,21 @@</span> <span class="p_context"> static void perf_event_for_each(struct perf_event *event,</span>
 	mutex_unlock(&amp;ctx-&gt;mutex);
 }
 
<span class="p_del">-static int perf_event_period(struct perf_event *event, u64 __user *arg)</span>
<span class="p_del">-{</span>
<span class="p_del">-	struct perf_event_context *ctx = event-&gt;ctx;</span>
<span class="p_del">-	int ret = 0, active;</span>
<span class="p_add">+struct period_event {</span>
<span class="p_add">+	struct perf_event *event;</span>
 	u64 value;
<span class="p_add">+};</span>
 
<span class="p_del">-	if (!is_sampling_event(event))</span>
<span class="p_del">-		return -EINVAL;</span>
<span class="p_del">-</span>
<span class="p_del">-	if (copy_from_user(&amp;value, arg, sizeof(value)))</span>
<span class="p_del">-		return -EFAULT;</span>
<span class="p_del">-</span>
<span class="p_del">-	if (!value)</span>
<span class="p_del">-		return -EINVAL;</span>
<span class="p_add">+static int __perf_event_period(void *info)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct period_event *pe = info;</span>
<span class="p_add">+	struct perf_event *event = pe-&gt;event;</span>
<span class="p_add">+	struct perf_event_context *ctx = event-&gt;ctx;</span>
<span class="p_add">+	u64 value = pe-&gt;value;</span>
<span class="p_add">+	bool active;</span>
 
<span class="p_del">-	raw_spin_lock_irq(&amp;ctx-&gt;lock);</span>
<span class="p_add">+	raw_spin_lock(&amp;ctx-&gt;lock);</span>
 	if (event-&gt;attr.freq) {
<span class="p_del">-		if (value &gt; sysctl_perf_event_sample_rate) {</span>
<span class="p_del">-			ret = -EINVAL;</span>
<span class="p_del">-			goto unlock;</span>
<span class="p_del">-		}</span>
<span class="p_del">-</span>
 		event-&gt;attr.sample_freq = value;
 	} else {
 		event-&gt;attr.sample_period = value;
<span class="p_chunk">@@ -3769,11 +3762,53 @@</span> <span class="p_context"> static int perf_event_period(struct perf_event *event, u64 __user *arg)</span>
 		event-&gt;pmu-&gt;start(event, PERF_EF_RELOAD);
 		perf_pmu_enable(ctx-&gt;pmu);
 	}
<span class="p_add">+	raw_spin_unlock(&amp;ctx-&gt;lock);</span>
 
<span class="p_del">-unlock:</span>
<span class="p_add">+	return 0;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static int perf_event_period(struct perf_event *event, u64 __user *arg)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct period_event pe = { .event = event, };</span>
<span class="p_add">+	struct perf_event_context *ctx = event-&gt;ctx;</span>
<span class="p_add">+	struct task_struct *task;</span>
<span class="p_add">+	u64 value;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (!is_sampling_event(event))</span>
<span class="p_add">+		return -EINVAL;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (copy_from_user(&amp;value, arg, sizeof(value)))</span>
<span class="p_add">+		return -EFAULT;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (!value)</span>
<span class="p_add">+		return -EINVAL;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (event-&gt;attr.freq &amp;&amp; value &gt; sysctl_perf_event_sample_rate)</span>
<span class="p_add">+		return -EINVAL;</span>
<span class="p_add">+</span>
<span class="p_add">+	task = ctx-&gt;task;</span>
<span class="p_add">+	pe.value = value;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (!task) {</span>
<span class="p_add">+		cpu_function_call(event-&gt;cpu, __perf_event_period, &amp;pe);</span>
<span class="p_add">+		return 0;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+retry:</span>
<span class="p_add">+	if (!task_function_call(task, __perf_event_period, &amp;pe))</span>
<span class="p_add">+		return 0;</span>
<span class="p_add">+</span>
<span class="p_add">+	raw_spin_lock_irq(&amp;ctx-&gt;lock);</span>
<span class="p_add">+	if (ctx-&gt;is_active) {</span>
<span class="p_add">+		raw_spin_unlock_irq(&amp;ctx-&gt;lock);</span>
<span class="p_add">+		task = ctx-&gt;task;</span>
<span class="p_add">+		goto retry;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	__perf_event_period(&amp;pe);</span>
 	raw_spin_unlock_irq(&amp;ctx-&gt;lock);
 
<span class="p_del">-	return ret;</span>
<span class="p_add">+	return 0;</span>
 }
 
 static const struct file_operations perf_fops;
<span class="p_chunk">@@ -4398,12 +4433,20 @@</span> <span class="p_context"> static const struct file_operations perf_fops = {</span>
  * to user-space before waking everybody up.
  */
 
<span class="p_add">+static inline struct fasync_struct **perf_event_fasync(struct perf_event *event)</span>
<span class="p_add">+{</span>
<span class="p_add">+	/* only the parent has fasync state */</span>
<span class="p_add">+	if (event-&gt;parent)</span>
<span class="p_add">+		event = event-&gt;parent;</span>
<span class="p_add">+	return &amp;event-&gt;fasync;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 void perf_event_wakeup(struct perf_event *event)
 {
 	ring_buffer_wakeup(event);
 
 	if (event-&gt;pending_kill) {
<span class="p_del">-		kill_fasync(&amp;event-&gt;fasync, SIGIO, event-&gt;pending_kill);</span>
<span class="p_add">+		kill_fasync(perf_event_fasync(event), SIGIO, event-&gt;pending_kill);</span>
 		event-&gt;pending_kill = 0;
 	}
 }
<span class="p_chunk">@@ -5675,7 +5718,7 @@</span> <span class="p_context"> static int __perf_event_overflow(struct perf_event *event,</span>
 	else
 		perf_event_output(event, data, regs);
 
<span class="p_del">-	if (event-&gt;fasync &amp;&amp; event-&gt;pending_kill) {</span>
<span class="p_add">+	if (*perf_event_fasync(event) &amp;&amp; event-&gt;pending_kill) {</span>
 		event-&gt;pending_wakeup = 1;
 		irq_work_queue(&amp;event-&gt;pending);
 	}
<span class="p_header">diff --git a/mm/memory-failure.c b/mm/memory-failure.c</span>
<span class="p_header">index dc29bec..1e2f7ff 100644</span>
<span class="p_header">--- a/mm/memory-failure.c</span>
<span class="p_header">+++ b/mm/memory-failure.c</span>
<span class="p_chunk">@@ -1519,6 +1519,8 @@</span> <span class="p_context"> static int get_any_page(struct page *page, unsigned long pfn, int flags)</span>
 		 */
 		ret = __get_any_page(page, pfn, 0);
 		if (!PageLRU(page)) {
<span class="p_add">+			/* Drop page reference which is from __get_any_page() */</span>
<span class="p_add">+			put_page(page);</span>
 			pr_info(&quot;soft_offline: %#lx: unknown non LRU page type %lx\n&quot;,
 				pfn, page-&gt;flags);
 			return -EIO;
<span class="p_header">diff --git a/mm/vmscan.c b/mm/vmscan.c</span>
<span class="p_header">index dcd90c8..566cc3d0 100644</span>
<span class="p_header">--- a/mm/vmscan.c</span>
<span class="p_header">+++ b/mm/vmscan.c</span>
<span class="p_chunk">@@ -896,21 +896,17 @@</span> <span class="p_context"> static unsigned long shrink_page_list(struct list_head *page_list,</span>
 		 *
 		 * 2) Global reclaim encounters a page, memcg encounters a
 		 *    page that is not marked for immediate reclaim or
<span class="p_del">-		 *    the caller does not have __GFP_IO. In this case mark</span>
<span class="p_add">+		 *    the caller does not have __GFP_FS (or __GFP_IO if it&#39;s</span>
<span class="p_add">+		 *    simply going to swap, not to fs). In this case mark</span>
 		 *    the page for immediate reclaim and continue scanning.
 		 *
<span class="p_del">-		 *    __GFP_IO is checked  because a loop driver thread might</span>
<span class="p_add">+		 *    Require may_enter_fs because we would wait on fs, which</span>
<span class="p_add">+		 *    may not have submitted IO yet. And the loop driver might</span>
 		 *    enter reclaim, and deadlock if it waits on a page for
 		 *    which it is needed to do the write (loop masks off
 		 *    __GFP_IO|__GFP_FS for this reason); but more thought
 		 *    would probably show more reasons.
 		 *
<span class="p_del">-		 *    Don&#39;t require __GFP_FS, since we&#39;re not going into the</span>
<span class="p_del">-		 *    FS, just waiting on its writeback completion. Worryingly,</span>
<span class="p_del">-		 *    ext4 gfs2 and xfs allocate pages with</span>
<span class="p_del">-		 *    grab_cache_page_write_begin(,,AOP_FLAG_NOFS), so testing</span>
<span class="p_del">-		 *    may_enter_fs here is liable to OOM on them.</span>
<span class="p_del">-		 *</span>
 		 * 3) memcg encounters a page that is not already marked
 		 *    PageReclaim. memcg does not have any dirty pages
 		 *    throttling so we could easily OOM just because too many
<span class="p_chunk">@@ -927,7 +923,7 @@</span> <span class="p_context"> static unsigned long shrink_page_list(struct list_head *page_list,</span>
 
 			/* Case 2 above */
 			} else if (global_reclaim(sc) ||
<span class="p_del">-			    !PageReclaim(page) || !(sc-&gt;gfp_mask &amp; __GFP_IO)) {</span>
<span class="p_add">+			    !PageReclaim(page) || !may_enter_fs) {</span>
 				/*
 				 * This is slightly racy - end_page_writeback()
 				 * might have just cleared PageReclaim, then
<span class="p_header">diff --git a/net/batman-adv/soft-interface.c b/net/batman-adv/soft-interface.c</span>
<span class="p_header">index 5467955..8e66b01 100644</span>
<span class="p_header">--- a/net/batman-adv/soft-interface.c</span>
<span class="p_header">+++ b/net/batman-adv/soft-interface.c</span>
<span class="p_chunk">@@ -450,6 +450,9 @@</span> <span class="p_context"> out:</span>
  */
 void batadv_softif_vlan_free_ref(struct batadv_softif_vlan *vlan)
 {
<span class="p_add">+	if (!vlan)</span>
<span class="p_add">+		return;</span>
<span class="p_add">+</span>
 	if (atomic_dec_and_test(&amp;vlan-&gt;refcount)) {
 		spin_lock_bh(&amp;vlan-&gt;bat_priv-&gt;softif_vlan_list_lock);
 		hlist_del_rcu(&amp;vlan-&gt;list);
<span class="p_header">diff --git a/net/batman-adv/translation-table.c b/net/batman-adv/translation-table.c</span>
<span class="p_header">index 5f59e7f..4503069 100644</span>
<span class="p_header">--- a/net/batman-adv/translation-table.c</span>
<span class="p_header">+++ b/net/batman-adv/translation-table.c</span>
<span class="p_chunk">@@ -575,6 +575,9 @@</span> <span class="p_context"> bool batadv_tt_local_add(struct net_device *soft_iface, const uint8_t *addr,</span>
 
 	/* increase the refcounter of the related vlan */
 	vlan = batadv_softif_vlan_get(bat_priv, vid);
<span class="p_add">+	if (WARN(!vlan, &quot;adding TT local entry %pM to non-existent VLAN %d&quot;,</span>
<span class="p_add">+		 addr, BATADV_PRINT_VID(vid)))</span>
<span class="p_add">+		goto out;</span>
 
 	batadv_dbg(BATADV_DBG_TT, bat_priv,
 		   &quot;Creating new local tt entry: %pM (vid: %d, ttvn: %d)\n&quot;,
<span class="p_chunk">@@ -1015,6 +1018,7 @@</span> <span class="p_context"> uint16_t batadv_tt_local_remove(struct batadv_priv *bat_priv,</span>
 	struct batadv_tt_local_entry *tt_local_entry;
 	uint16_t flags, curr_flags = BATADV_NO_FLAGS;
 	struct batadv_softif_vlan *vlan;
<span class="p_add">+	void *tt_entry_exists;</span>
 
 	tt_local_entry = batadv_tt_local_hash_find(bat_priv, addr, vid);
 	if (!tt_local_entry)
<span class="p_chunk">@@ -1042,11 +1046,22 @@</span> <span class="p_context"> uint16_t batadv_tt_local_remove(struct batadv_priv *bat_priv,</span>
 	 * immediately purge it
 	 */
 	batadv_tt_local_event(bat_priv, tt_local_entry, BATADV_TT_CLIENT_DEL);
<span class="p_del">-	hlist_del_rcu(&amp;tt_local_entry-&gt;common.hash_entry);</span>
<span class="p_add">+</span>
<span class="p_add">+	tt_entry_exists = batadv_hash_remove(bat_priv-&gt;tt.local_hash,</span>
<span class="p_add">+					     batadv_compare_tt,</span>
<span class="p_add">+					     batadv_choose_tt,</span>
<span class="p_add">+					     &amp;tt_local_entry-&gt;common);</span>
<span class="p_add">+	if (!tt_entry_exists)</span>
<span class="p_add">+		goto out;</span>
<span class="p_add">+</span>
<span class="p_add">+	/* extra call to free the local tt entry */</span>
 	batadv_tt_local_entry_free_ref(tt_local_entry);
 
 	/* decrease the reference held for this vlan */
 	vlan = batadv_softif_vlan_get(bat_priv, vid);
<span class="p_add">+	if (!vlan)</span>
<span class="p_add">+		goto out;</span>
<span class="p_add">+</span>
 	batadv_softif_vlan_free_ref(vlan);
 	batadv_softif_vlan_free_ref(vlan);
 
<span class="p_chunk">@@ -1147,8 +1162,10 @@</span> <span class="p_context"> static void batadv_tt_local_table_free(struct batadv_priv *bat_priv)</span>
 			/* decrease the reference held for this vlan */
 			vlan = batadv_softif_vlan_get(bat_priv,
 						      tt_common_entry-&gt;vid);
<span class="p_del">-			batadv_softif_vlan_free_ref(vlan);</span>
<span class="p_del">-			batadv_softif_vlan_free_ref(vlan);</span>
<span class="p_add">+			if (vlan) {</span>
<span class="p_add">+				batadv_softif_vlan_free_ref(vlan);</span>
<span class="p_add">+				batadv_softif_vlan_free_ref(vlan);</span>
<span class="p_add">+			}</span>
 
 			batadv_tt_local_entry_free_ref(tt_local);
 		}
<span class="p_chunk">@@ -3190,8 +3207,10 @@</span> <span class="p_context"> static void batadv_tt_local_purge_pending_clients(struct batadv_priv *bat_priv)</span>
 
 			/* decrease the reference held for this vlan */
 			vlan = batadv_softif_vlan_get(bat_priv, tt_common-&gt;vid);
<span class="p_del">-			batadv_softif_vlan_free_ref(vlan);</span>
<span class="p_del">-			batadv_softif_vlan_free_ref(vlan);</span>
<span class="p_add">+			if (vlan) {</span>
<span class="p_add">+				batadv_softif_vlan_free_ref(vlan);</span>
<span class="p_add">+				batadv_softif_vlan_free_ref(vlan);</span>
<span class="p_add">+			}</span>
 
 			batadv_tt_local_entry_free_ref(tt_local);
 		}
<span class="p_header">diff --git a/net/bridge/br_netlink.c b/net/bridge/br_netlink.c</span>
<span class="p_header">index 36e56a9..dca5049 100644</span>
<span class="p_header">--- a/net/bridge/br_netlink.c</span>
<span class="p_header">+++ b/net/bridge/br_netlink.c</span>
<span class="p_chunk">@@ -32,6 +32,7 @@</span> <span class="p_context"> static inline size_t br_port_info_size(void)</span>
 		+ nla_total_size(1)	/* IFLA_BRPORT_FAST_LEAVE */
 		+ nla_total_size(1)	/* IFLA_BRPORT_LEARNING */
 		+ nla_total_size(1)	/* IFLA_BRPORT_UNICAST_FLOOD */
<span class="p_add">+		+ nla_total_size(1)	/* IFLA_BRPORT_PROXYARP */</span>
 		+ 0;
 }
 
<span class="p_chunk">@@ -284,6 +285,7 @@</span> <span class="p_context"> static const struct nla_policy br_port_policy[IFLA_BRPORT_MAX + 1] = {</span>
 	[IFLA_BRPORT_FAST_LEAVE]= { .type = NLA_U8 },
 	[IFLA_BRPORT_LEARNING]	= { .type = NLA_U8 },
 	[IFLA_BRPORT_UNICAST_FLOOD] = { .type = NLA_U8 },
<span class="p_add">+	[IFLA_BRPORT_PROXYARP]	= { .type = NLA_U8 },</span>
 };
 
 /* Change the state of the port and notify spanning tree */
<span class="p_header">diff --git a/net/core/datagram.c b/net/core/datagram.c</span>
<span class="p_header">index 91dbcfa..e0a31cc 100644</span>
<span class="p_header">--- a/net/core/datagram.c</span>
<span class="p_header">+++ b/net/core/datagram.c</span>
<span class="p_chunk">@@ -131,12 +131,12 @@</span> <span class="p_context"> out_noerr:</span>
 	goto out;
 }
 
<span class="p_del">-static int skb_set_peeked(struct sk_buff *skb)</span>
<span class="p_add">+static struct sk_buff *skb_set_peeked(struct sk_buff *skb)</span>
 {
 	struct sk_buff *nskb;
 
 	if (skb-&gt;peeked)
<span class="p_del">-		return 0;</span>
<span class="p_add">+		return skb;</span>
 
 	/* We have to unshare an skb before modifying it. */
 	if (!skb_shared(skb))
<span class="p_chunk">@@ -144,7 +144,7 @@</span> <span class="p_context"> static int skb_set_peeked(struct sk_buff *skb)</span>
 
 	nskb = skb_clone(skb, GFP_ATOMIC);
 	if (!nskb)
<span class="p_del">-		return -ENOMEM;</span>
<span class="p_add">+		return ERR_PTR(-ENOMEM);</span>
 
 	skb-&gt;prev-&gt;next = nskb;
 	skb-&gt;next-&gt;prev = nskb;
<span class="p_chunk">@@ -157,7 +157,7 @@</span> <span class="p_context"> static int skb_set_peeked(struct sk_buff *skb)</span>
 done:
 	skb-&gt;peeked = 1;
 
<span class="p_del">-	return 0;</span>
<span class="p_add">+	return skb;</span>
 }
 
 /**
<span class="p_chunk">@@ -229,8 +229,9 @@</span> <span class="p_context"> struct sk_buff *__skb_recv_datagram(struct sock *sk, unsigned int flags,</span>
 					continue;
 				}
 
<span class="p_del">-				error = skb_set_peeked(skb);</span>
<span class="p_del">-				if (error)</span>
<span class="p_add">+				skb = skb_set_peeked(skb);</span>
<span class="p_add">+				error = PTR_ERR(skb);</span>
<span class="p_add">+				if (IS_ERR(skb))</span>
 					goto unlock_err;
 
 				atomic_inc(&amp;skb-&gt;users);
<span class="p_chunk">@@ -657,7 +658,8 @@</span> <span class="p_context"> __sum16 __skb_checksum_complete_head(struct sk_buff *skb, int len)</span>
 		    !skb-&gt;csum_complete_sw)
 			netdev_rx_csum_fault(skb-&gt;dev);
 	}
<span class="p_del">-	skb-&gt;csum_valid = !sum;</span>
<span class="p_add">+	if (!skb_shared(skb))</span>
<span class="p_add">+		skb-&gt;csum_valid = !sum;</span>
 	return sum;
 }
 EXPORT_SYMBOL(__skb_checksum_complete_head);
<span class="p_chunk">@@ -677,11 +679,13 @@</span> <span class="p_context"> __sum16 __skb_checksum_complete(struct sk_buff *skb)</span>
 			netdev_rx_csum_fault(skb-&gt;dev);
 	}
 
<span class="p_del">-	/* Save full packet checksum */</span>
<span class="p_del">-	skb-&gt;csum = csum;</span>
<span class="p_del">-	skb-&gt;ip_summed = CHECKSUM_COMPLETE;</span>
<span class="p_del">-	skb-&gt;csum_complete_sw = 1;</span>
<span class="p_del">-	skb-&gt;csum_valid = !sum;</span>
<span class="p_add">+	if (!skb_shared(skb)) {</span>
<span class="p_add">+		/* Save full packet checksum */</span>
<span class="p_add">+		skb-&gt;csum = csum;</span>
<span class="p_add">+		skb-&gt;ip_summed = CHECKSUM_COMPLETE;</span>
<span class="p_add">+		skb-&gt;csum_complete_sw = 1;</span>
<span class="p_add">+		skb-&gt;csum_valid = !sum;</span>
<span class="p_add">+	}</span>
 
 	return sum;
 }
<span class="p_header">diff --git a/net/core/pktgen.c b/net/core/pktgen.c</span>
<span class="p_header">index de4dc84..0fab2c4 100644</span>
<span class="p_header">--- a/net/core/pktgen.c</span>
<span class="p_header">+++ b/net/core/pktgen.c</span>
<span class="p_chunk">@@ -3493,8 +3493,10 @@</span> <span class="p_context"> static int pktgen_thread_worker(void *arg)</span>
 	pktgen_rem_thread(t);
 
 	/* Wait for kthread_stop */
<span class="p_del">-	while (!kthread_should_stop()) {</span>
<span class="p_add">+	for (;;) {</span>
 		set_current_state(TASK_INTERRUPTIBLE);
<span class="p_add">+		if (kthread_should_stop())</span>
<span class="p_add">+			break;</span>
 		schedule();
 	}
 	__set_current_state(TASK_RUNNING);
<span class="p_header">diff --git a/net/core/rtnetlink.c b/net/core/rtnetlink.c</span>
<span class="p_header">index b73d29c..e732b7e 100644</span>
<span class="p_header">--- a/net/core/rtnetlink.c</span>
<span class="p_header">+++ b/net/core/rtnetlink.c</span>
<span class="p_chunk">@@ -1232,10 +1232,6 @@</span> <span class="p_context"> static const struct nla_policy ifla_info_policy[IFLA_INFO_MAX+1] = {</span>
 	[IFLA_INFO_SLAVE_DATA]	= { .type = NLA_NESTED },
 };
 
<span class="p_del">-static const struct nla_policy ifla_vfinfo_policy[IFLA_VF_INFO_MAX+1] = {</span>
<span class="p_del">-	[IFLA_VF_INFO]		= { .type = NLA_NESTED },</span>
<span class="p_del">-};</span>
<span class="p_del">-</span>
 static const struct nla_policy ifla_vf_policy[IFLA_VF_MAX+1] = {
 	[IFLA_VF_MAC]		= { .len = sizeof(struct ifla_vf_mac) },
 	[IFLA_VF_VLAN]		= { .len = sizeof(struct ifla_vf_vlan) },
<span class="p_chunk">@@ -1381,85 +1377,86 @@</span> <span class="p_context"> static int validate_linkmsg(struct net_device *dev, struct nlattr *tb[])</span>
 	return 0;
 }
 
<span class="p_del">-static int do_setvfinfo(struct net_device *dev, struct nlattr *attr)</span>
<span class="p_add">+static int do_setvfinfo(struct net_device *dev, struct nlattr **tb)</span>
 {
<span class="p_del">-	int rem, err = -EINVAL;</span>
<span class="p_del">-	struct nlattr *vf;</span>
 	const struct net_device_ops *ops = dev-&gt;netdev_ops;
<span class="p_add">+	int err = -EINVAL;</span>
 
<span class="p_del">-	nla_for_each_nested(vf, attr, rem) {</span>
<span class="p_del">-		switch (nla_type(vf)) {</span>
<span class="p_del">-		case IFLA_VF_MAC: {</span>
<span class="p_del">-			struct ifla_vf_mac *ivm;</span>
<span class="p_del">-			ivm = nla_data(vf);</span>
<span class="p_del">-			err = -EOPNOTSUPP;</span>
<span class="p_del">-			if (ops-&gt;ndo_set_vf_mac)</span>
<span class="p_del">-				err = ops-&gt;ndo_set_vf_mac(dev, ivm-&gt;vf,</span>
<span class="p_del">-							  ivm-&gt;mac);</span>
<span class="p_del">-			break;</span>
<span class="p_del">-		}</span>
<span class="p_del">-		case IFLA_VF_VLAN: {</span>
<span class="p_del">-			struct ifla_vf_vlan *ivv;</span>
<span class="p_del">-			ivv = nla_data(vf);</span>
<span class="p_del">-			err = -EOPNOTSUPP;</span>
<span class="p_del">-			if (ops-&gt;ndo_set_vf_vlan)</span>
<span class="p_del">-				err = ops-&gt;ndo_set_vf_vlan(dev, ivv-&gt;vf,</span>
<span class="p_del">-							   ivv-&gt;vlan,</span>
<span class="p_del">-							   ivv-&gt;qos);</span>
<span class="p_del">-			break;</span>
<span class="p_del">-		}</span>
<span class="p_del">-		case IFLA_VF_TX_RATE: {</span>
<span class="p_del">-			struct ifla_vf_tx_rate *ivt;</span>
<span class="p_del">-			struct ifla_vf_info ivf;</span>
<span class="p_del">-			ivt = nla_data(vf);</span>
<span class="p_del">-			err = -EOPNOTSUPP;</span>
<span class="p_del">-			if (ops-&gt;ndo_get_vf_config)</span>
<span class="p_del">-				err = ops-&gt;ndo_get_vf_config(dev, ivt-&gt;vf,</span>
<span class="p_del">-							     &amp;ivf);</span>
<span class="p_del">-			if (err)</span>
<span class="p_del">-				break;</span>
<span class="p_del">-			err = -EOPNOTSUPP;</span>
<span class="p_del">-			if (ops-&gt;ndo_set_vf_rate)</span>
<span class="p_del">-				err = ops-&gt;ndo_set_vf_rate(dev, ivt-&gt;vf,</span>
<span class="p_del">-							   ivf.min_tx_rate,</span>
<span class="p_del">-							   ivt-&gt;rate);</span>
<span class="p_del">-			break;</span>
<span class="p_del">-		}</span>
<span class="p_del">-		case IFLA_VF_RATE: {</span>
<span class="p_del">-			struct ifla_vf_rate *ivt;</span>
<span class="p_del">-			ivt = nla_data(vf);</span>
<span class="p_del">-			err = -EOPNOTSUPP;</span>
<span class="p_del">-			if (ops-&gt;ndo_set_vf_rate)</span>
<span class="p_del">-				err = ops-&gt;ndo_set_vf_rate(dev, ivt-&gt;vf,</span>
<span class="p_del">-							   ivt-&gt;min_tx_rate,</span>
<span class="p_del">-							   ivt-&gt;max_tx_rate);</span>
<span class="p_del">-			break;</span>
<span class="p_del">-		}</span>
<span class="p_del">-		case IFLA_VF_SPOOFCHK: {</span>
<span class="p_del">-			struct ifla_vf_spoofchk *ivs;</span>
<span class="p_del">-			ivs = nla_data(vf);</span>
<span class="p_del">-			err = -EOPNOTSUPP;</span>
<span class="p_del">-			if (ops-&gt;ndo_set_vf_spoofchk)</span>
<span class="p_del">-				err = ops-&gt;ndo_set_vf_spoofchk(dev, ivs-&gt;vf,</span>
<span class="p_del">-							       ivs-&gt;setting);</span>
<span class="p_del">-			break;</span>
<span class="p_del">-		}</span>
<span class="p_del">-		case IFLA_VF_LINK_STATE: {</span>
<span class="p_del">-			struct ifla_vf_link_state *ivl;</span>
<span class="p_del">-			ivl = nla_data(vf);</span>
<span class="p_del">-			err = -EOPNOTSUPP;</span>
<span class="p_del">-			if (ops-&gt;ndo_set_vf_link_state)</span>
<span class="p_del">-				err = ops-&gt;ndo_set_vf_link_state(dev, ivl-&gt;vf,</span>
<span class="p_del">-								 ivl-&gt;link_state);</span>
<span class="p_del">-			break;</span>
<span class="p_del">-		}</span>
<span class="p_del">-		default:</span>
<span class="p_del">-			err = -EINVAL;</span>
<span class="p_del">-			break;</span>
<span class="p_del">-		}</span>
<span class="p_del">-		if (err)</span>
<span class="p_del">-			break;</span>
<span class="p_add">+	if (tb[IFLA_VF_MAC]) {</span>
<span class="p_add">+		struct ifla_vf_mac *ivm = nla_data(tb[IFLA_VF_MAC]);</span>
<span class="p_add">+</span>
<span class="p_add">+		err = -EOPNOTSUPP;</span>
<span class="p_add">+		if (ops-&gt;ndo_set_vf_mac)</span>
<span class="p_add">+			err = ops-&gt;ndo_set_vf_mac(dev, ivm-&gt;vf,</span>
<span class="p_add">+						  ivm-&gt;mac);</span>
<span class="p_add">+		if (err &lt; 0)</span>
<span class="p_add">+			return err;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	if (tb[IFLA_VF_VLAN]) {</span>
<span class="p_add">+		struct ifla_vf_vlan *ivv = nla_data(tb[IFLA_VF_VLAN]);</span>
<span class="p_add">+</span>
<span class="p_add">+		err = -EOPNOTSUPP;</span>
<span class="p_add">+		if (ops-&gt;ndo_set_vf_vlan)</span>
<span class="p_add">+			err = ops-&gt;ndo_set_vf_vlan(dev, ivv-&gt;vf, ivv-&gt;vlan,</span>
<span class="p_add">+						   ivv-&gt;qos);</span>
<span class="p_add">+		if (err &lt; 0)</span>
<span class="p_add">+			return err;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	if (tb[IFLA_VF_TX_RATE]) {</span>
<span class="p_add">+		struct ifla_vf_tx_rate *ivt = nla_data(tb[IFLA_VF_TX_RATE]);</span>
<span class="p_add">+		struct ifla_vf_info ivf;</span>
<span class="p_add">+</span>
<span class="p_add">+		err = -EOPNOTSUPP;</span>
<span class="p_add">+		if (ops-&gt;ndo_get_vf_config)</span>
<span class="p_add">+			err = ops-&gt;ndo_get_vf_config(dev, ivt-&gt;vf, &amp;ivf);</span>
<span class="p_add">+		if (err &lt; 0)</span>
<span class="p_add">+			return err;</span>
<span class="p_add">+</span>
<span class="p_add">+		err = -EOPNOTSUPP;</span>
<span class="p_add">+		if (ops-&gt;ndo_set_vf_rate)</span>
<span class="p_add">+			err = ops-&gt;ndo_set_vf_rate(dev, ivt-&gt;vf,</span>
<span class="p_add">+						   ivf.min_tx_rate,</span>
<span class="p_add">+						   ivt-&gt;rate);</span>
<span class="p_add">+		if (err &lt; 0)</span>
<span class="p_add">+			return err;</span>
 	}
<span class="p_add">+</span>
<span class="p_add">+	if (tb[IFLA_VF_RATE]) {</span>
<span class="p_add">+		struct ifla_vf_rate *ivt = nla_data(tb[IFLA_VF_RATE]);</span>
<span class="p_add">+</span>
<span class="p_add">+		err = -EOPNOTSUPP;</span>
<span class="p_add">+		if (ops-&gt;ndo_set_vf_rate)</span>
<span class="p_add">+			err = ops-&gt;ndo_set_vf_rate(dev, ivt-&gt;vf,</span>
<span class="p_add">+						   ivt-&gt;min_tx_rate,</span>
<span class="p_add">+						   ivt-&gt;max_tx_rate);</span>
<span class="p_add">+		if (err &lt; 0)</span>
<span class="p_add">+			return err;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	if (tb[IFLA_VF_SPOOFCHK]) {</span>
<span class="p_add">+		struct ifla_vf_spoofchk *ivs = nla_data(tb[IFLA_VF_SPOOFCHK]);</span>
<span class="p_add">+</span>
<span class="p_add">+		err = -EOPNOTSUPP;</span>
<span class="p_add">+		if (ops-&gt;ndo_set_vf_spoofchk)</span>
<span class="p_add">+			err = ops-&gt;ndo_set_vf_spoofchk(dev, ivs-&gt;vf,</span>
<span class="p_add">+						       ivs-&gt;setting);</span>
<span class="p_add">+		if (err &lt; 0)</span>
<span class="p_add">+			return err;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	if (tb[IFLA_VF_LINK_STATE]) {</span>
<span class="p_add">+		struct ifla_vf_link_state *ivl = nla_data(tb[IFLA_VF_LINK_STATE]);</span>
<span class="p_add">+</span>
<span class="p_add">+		err = -EOPNOTSUPP;</span>
<span class="p_add">+		if (ops-&gt;ndo_set_vf_link_state)</span>
<span class="p_add">+			err = ops-&gt;ndo_set_vf_link_state(dev, ivl-&gt;vf,</span>
<span class="p_add">+							 ivl-&gt;link_state);</span>
<span class="p_add">+		if (err &lt; 0)</span>
<span class="p_add">+			return err;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
 	return err;
 }
 
<span class="p_chunk">@@ -1655,14 +1652,21 @@</span> <span class="p_context"> static int do_setlink(const struct sk_buff *skb,</span>
 	}
 
 	if (tb[IFLA_VFINFO_LIST]) {
<span class="p_add">+		struct nlattr *vfinfo[IFLA_VF_MAX + 1];</span>
 		struct nlattr *attr;
 		int rem;
<span class="p_add">+</span>
 		nla_for_each_nested(attr, tb[IFLA_VFINFO_LIST], rem) {
<span class="p_del">-			if (nla_type(attr) != IFLA_VF_INFO) {</span>
<span class="p_add">+			if (nla_type(attr) != IFLA_VF_INFO ||</span>
<span class="p_add">+			    nla_len(attr) &lt; NLA_HDRLEN) {</span>
 				err = -EINVAL;
 				goto errout;
 			}
<span class="p_del">-			err = do_setvfinfo(dev, attr);</span>
<span class="p_add">+			err = nla_parse_nested(vfinfo, IFLA_VF_MAX, attr,</span>
<span class="p_add">+					       ifla_vf_policy);</span>
<span class="p_add">+			if (err &lt; 0)</span>
<span class="p_add">+				goto errout;</span>
<span class="p_add">+			err = do_setvfinfo(dev, vfinfo);</span>
 			if (err &lt; 0)
 				goto errout;
 			status |= DO_SETLINK_NOTIFY;
<span class="p_header">diff --git a/net/ipv4/datagram.c b/net/ipv4/datagram.c</span>
<span class="p_header">index 90c0e83..574fad9 100644</span>
<span class="p_header">--- a/net/ipv4/datagram.c</span>
<span class="p_header">+++ b/net/ipv4/datagram.c</span>
<span class="p_chunk">@@ -20,7 +20,7 @@</span> <span class="p_context"></span>
 #include &lt;net/route.h&gt;
 #include &lt;net/tcp_states.h&gt;
 
<span class="p_del">-int ip4_datagram_connect(struct sock *sk, struct sockaddr *uaddr, int addr_len)</span>
<span class="p_add">+int __ip4_datagram_connect(struct sock *sk, struct sockaddr *uaddr, int addr_len)</span>
 {
 	struct inet_sock *inet = inet_sk(sk);
 	struct sockaddr_in *usin = (struct sockaddr_in *) uaddr;
<span class="p_chunk">@@ -39,8 +39,6 @@</span> <span class="p_context"> int ip4_datagram_connect(struct sock *sk, struct sockaddr *uaddr, int addr_len)</span>
 
 	sk_dst_reset(sk);
 
<span class="p_del">-	lock_sock(sk);</span>
<span class="p_del">-</span>
 	oif = sk-&gt;sk_bound_dev_if;
 	saddr = inet-&gt;inet_saddr;
 	if (ipv4_is_multicast(usin-&gt;sin_addr.s_addr)) {
<span class="p_chunk">@@ -82,9 +80,19 @@</span> <span class="p_context"> int ip4_datagram_connect(struct sock *sk, struct sockaddr *uaddr, int addr_len)</span>
 	sk_dst_set(sk, &amp;rt-&gt;dst);
 	err = 0;
 out:
<span class="p_del">-	release_sock(sk);</span>
 	return err;
 }
<span class="p_add">+EXPORT_SYMBOL(__ip4_datagram_connect);</span>
<span class="p_add">+</span>
<span class="p_add">+int ip4_datagram_connect(struct sock *sk, struct sockaddr *uaddr, int addr_len)</span>
<span class="p_add">+{</span>
<span class="p_add">+	int res;</span>
<span class="p_add">+</span>
<span class="p_add">+	lock_sock(sk);</span>
<span class="p_add">+	res = __ip4_datagram_connect(sk, uaddr, addr_len);</span>
<span class="p_add">+	release_sock(sk);</span>
<span class="p_add">+	return res;</span>
<span class="p_add">+}</span>
 EXPORT_SYMBOL(ip4_datagram_connect);
 
 /* Because UDP xmit path can manipulate sk_dst_cache without holding
<span class="p_header">diff --git a/net/ipv4/udp.c b/net/ipv4/udp.c</span>
<span class="p_header">index e0737ac..75f76d7 100644</span>
<span class="p_header">--- a/net/ipv4/udp.c</span>
<span class="p_header">+++ b/net/ipv4/udp.c</span>
<span class="p_chunk">@@ -2001,12 +2001,19 @@</span> <span class="p_context"> void udp_v4_early_demux(struct sk_buff *skb)</span>
 
 	skb-&gt;sk = sk;
 	skb-&gt;destructor = sock_efree;
<span class="p_del">-	dst = sk-&gt;sk_rx_dst;</span>
<span class="p_add">+	dst = READ_ONCE(sk-&gt;sk_rx_dst);</span>
 
 	if (dst)
 		dst = dst_check(dst, 0);
<span class="p_del">-	if (dst)</span>
<span class="p_del">-		skb_dst_set_noref(skb, dst);</span>
<span class="p_add">+	if (dst) {</span>
<span class="p_add">+		/* DST_NOCACHE can not be used without taking a reference */</span>
<span class="p_add">+		if (dst-&gt;flags &amp; DST_NOCACHE) {</span>
<span class="p_add">+			if (likely(atomic_inc_not_zero(&amp;dst-&gt;__refcnt)))</span>
<span class="p_add">+				skb_dst_set(skb, dst);</span>
<span class="p_add">+		} else {</span>
<span class="p_add">+			skb_dst_set_noref(skb, dst);</span>
<span class="p_add">+		}</span>
<span class="p_add">+	}</span>
 }
 
 int udp_rcv(struct sk_buff *skb)
<span class="p_header">diff --git a/net/ipv6/addrconf.c b/net/ipv6/addrconf.c</span>
<span class="p_header">index dac9419..167d23e 100644</span>
<span class="p_header">--- a/net/ipv6/addrconf.c</span>
<span class="p_header">+++ b/net/ipv6/addrconf.c</span>
<span class="p_chunk">@@ -4879,6 +4879,21 @@</span> <span class="p_context"> int addrconf_sysctl_forward(struct ctl_table *ctl, int write,</span>
 	return ret;
 }
 
<span class="p_add">+static</span>
<span class="p_add">+int addrconf_sysctl_mtu(struct ctl_table *ctl, int write,</span>
<span class="p_add">+			void __user *buffer, size_t *lenp, loff_t *ppos)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct inet6_dev *idev = ctl-&gt;extra1;</span>
<span class="p_add">+	int min_mtu = IPV6_MIN_MTU;</span>
<span class="p_add">+	struct ctl_table lctl;</span>
<span class="p_add">+</span>
<span class="p_add">+	lctl = *ctl;</span>
<span class="p_add">+	lctl.extra1 = &amp;min_mtu;</span>
<span class="p_add">+	lctl.extra2 = idev ? &amp;idev-&gt;dev-&gt;mtu : NULL;</span>
<span class="p_add">+</span>
<span class="p_add">+	return proc_dointvec_minmax(&amp;lctl, write, buffer, lenp, ppos);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static void dev_disable_change(struct inet6_dev *idev)
 {
 	struct netdev_notifier_info info;
<span class="p_chunk">@@ -5030,7 +5045,7 @@</span> <span class="p_context"> static struct addrconf_sysctl_table</span>
 			.data		= &amp;ipv6_devconf.mtu6,
 			.maxlen		= sizeof(int),
 			.mode		= 0644,
<span class="p_del">-			.proc_handler	= proc_dointvec,</span>
<span class="p_add">+			.proc_handler	= addrconf_sysctl_mtu,</span>
 		},
 		{
 			.procname	= &quot;accept_ra&quot;,
<span class="p_header">diff --git a/net/ipv6/datagram.c b/net/ipv6/datagram.c</span>
<span class="p_header">index 49f5e73..31fb5da 100644</span>
<span class="p_header">--- a/net/ipv6/datagram.c</span>
<span class="p_header">+++ b/net/ipv6/datagram.c</span>
<span class="p_chunk">@@ -40,7 +40,7 @@</span> <span class="p_context"> static bool ipv6_mapped_addr_any(const struct in6_addr *a)</span>
 	return ipv6_addr_v4mapped(a) &amp;&amp; (a-&gt;s6_addr32[3] == 0);
 }
 
<span class="p_del">-int ip6_datagram_connect(struct sock *sk, struct sockaddr *uaddr, int addr_len)</span>
<span class="p_add">+static int __ip6_datagram_connect(struct sock *sk, struct sockaddr *uaddr, int addr_len)</span>
 {
 	struct sockaddr_in6	*usin = (struct sockaddr_in6 *) uaddr;
 	struct inet_sock	*inet = inet_sk(sk);
<span class="p_chunk">@@ -56,7 +56,7 @@</span> <span class="p_context"> int ip6_datagram_connect(struct sock *sk, struct sockaddr *uaddr, int addr_len)</span>
 	if (usin-&gt;sin6_family == AF_INET) {
 		if (__ipv6_only_sock(sk))
 			return -EAFNOSUPPORT;
<span class="p_del">-		err = ip4_datagram_connect(sk, uaddr, addr_len);</span>
<span class="p_add">+		err = __ip4_datagram_connect(sk, uaddr, addr_len);</span>
 		goto ipv4_connected;
 	}
 
<span class="p_chunk">@@ -98,9 +98,9 @@</span> <span class="p_context"> int ip6_datagram_connect(struct sock *sk, struct sockaddr *uaddr, int addr_len)</span>
 		sin.sin_addr.s_addr = daddr-&gt;s6_addr32[3];
 		sin.sin_port = usin-&gt;sin6_port;
 
<span class="p_del">-		err = ip4_datagram_connect(sk,</span>
<span class="p_del">-					   (struct sockaddr *) &amp;sin,</span>
<span class="p_del">-					   sizeof(sin));</span>
<span class="p_add">+		err = __ip4_datagram_connect(sk,</span>
<span class="p_add">+					     (struct sockaddr *) &amp;sin,</span>
<span class="p_add">+					     sizeof(sin));</span>
 
 ipv4_connected:
 		if (err)
<span class="p_chunk">@@ -204,6 +204,16 @@</span> <span class="p_context"> out:</span>
 	fl6_sock_release(flowlabel);
 	return err;
 }
<span class="p_add">+</span>
<span class="p_add">+int ip6_datagram_connect(struct sock *sk, struct sockaddr *uaddr, int addr_len)</span>
<span class="p_add">+{</span>
<span class="p_add">+	int res;</span>
<span class="p_add">+</span>
<span class="p_add">+	lock_sock(sk);</span>
<span class="p_add">+	res = __ip6_datagram_connect(sk, uaddr, addr_len);</span>
<span class="p_add">+	release_sock(sk);</span>
<span class="p_add">+	return res;</span>
<span class="p_add">+}</span>
 EXPORT_SYMBOL_GPL(ip6_datagram_connect);
 
 int ip6_datagram_connect_v6_only(struct sock *sk, struct sockaddr *uaddr,
<span class="p_header">diff --git a/net/ipv6/ip6_gre.c b/net/ipv6/ip6_gre.c</span>
<span class="p_header">index 01ccc28..d1b83a3 100644</span>
<span class="p_header">--- a/net/ipv6/ip6_gre.c</span>
<span class="p_header">+++ b/net/ipv6/ip6_gre.c</span>
<span class="p_chunk">@@ -361,6 +361,7 @@</span> <span class="p_context"> static void ip6gre_tunnel_uninit(struct net_device *dev)</span>
 	struct ip6gre_net *ign = net_generic(t-&gt;net, ip6gre_net_id);
 
 	ip6gre_tunnel_unlink(ign, t);
<span class="p_add">+	ip6_tnl_dst_reset(t);</span>
 	dev_put(dev);
 }
 
<span class="p_header">diff --git a/net/ipv6/ip6_offload.c b/net/ipv6/ip6_offload.c</span>
<span class="p_header">index 46d452a..2f83e33 100644</span>
<span class="p_header">--- a/net/ipv6/ip6_offload.c</span>
<span class="p_header">+++ b/net/ipv6/ip6_offload.c</span>
<span class="p_chunk">@@ -292,8 +292,6 @@</span> <span class="p_context"> static struct packet_offload ipv6_packet_offload __read_mostly = {</span>
 static const struct net_offload sit_offload = {
 	.callbacks = {
 		.gso_segment	= ipv6_gso_segment,
<span class="p_del">-		.gro_receive	= ipv6_gro_receive,</span>
<span class="p_del">-		.gro_complete	= ipv6_gro_complete,</span>
 	},
 };
 
<span class="p_header">diff --git a/net/key/af_key.c b/net/key/af_key.c</span>
<span class="p_header">index f8ac939..4bfc5e5 100644</span>
<span class="p_header">--- a/net/key/af_key.c</span>
<span class="p_header">+++ b/net/key/af_key.c</span>
<span class="p_chunk">@@ -219,7 +219,7 @@</span> <span class="p_context"> static int pfkey_broadcast_one(struct sk_buff *skb, struct sk_buff **skb2,</span>
 #define BROADCAST_ONE		1
 #define BROADCAST_REGISTERED	2
 #define BROADCAST_PROMISC_ONLY	4
<span class="p_del">-static int pfkey_broadcast(struct sk_buff *skb, gfp_t allocation,</span>
<span class="p_add">+static int pfkey_broadcast(struct sk_buff *skb,</span>
 			   int broadcast_flags, struct sock *one_sk,
 			   struct net *net)
 {
<span class="p_chunk">@@ -244,7 +244,7 @@</span> <span class="p_context"> static int pfkey_broadcast(struct sk_buff *skb, gfp_t allocation,</span>
 		 * socket.
 		 */
 		if (pfk-&gt;promisc)
<span class="p_del">-			pfkey_broadcast_one(skb, &amp;skb2, allocation, sk);</span>
<span class="p_add">+			pfkey_broadcast_one(skb, &amp;skb2, GFP_ATOMIC, sk);</span>
 
 		/* the exact target will be processed later */
 		if (sk == one_sk)
<span class="p_chunk">@@ -259,7 +259,7 @@</span> <span class="p_context"> static int pfkey_broadcast(struct sk_buff *skb, gfp_t allocation,</span>
 				continue;
 		}
 
<span class="p_del">-		err2 = pfkey_broadcast_one(skb, &amp;skb2, allocation, sk);</span>
<span class="p_add">+		err2 = pfkey_broadcast_one(skb, &amp;skb2, GFP_ATOMIC, sk);</span>
 
 		/* Error is cleare after succecful sending to at least one
 		 * registered KM */
<span class="p_chunk">@@ -269,7 +269,7 @@</span> <span class="p_context"> static int pfkey_broadcast(struct sk_buff *skb, gfp_t allocation,</span>
 	rcu_read_unlock();
 
 	if (one_sk != NULL)
<span class="p_del">-		err = pfkey_broadcast_one(skb, &amp;skb2, allocation, one_sk);</span>
<span class="p_add">+		err = pfkey_broadcast_one(skb, &amp;skb2, GFP_KERNEL, one_sk);</span>
 
 	kfree_skb(skb2);
 	kfree_skb(skb);
<span class="p_chunk">@@ -292,7 +292,7 @@</span> <span class="p_context"> static int pfkey_do_dump(struct pfkey_sock *pfk)</span>
 		hdr = (struct sadb_msg *) pfk-&gt;dump.skb-&gt;data;
 		hdr-&gt;sadb_msg_seq = 0;
 		hdr-&gt;sadb_msg_errno = rc;
<span class="p_del">-		pfkey_broadcast(pfk-&gt;dump.skb, GFP_ATOMIC, BROADCAST_ONE,</span>
<span class="p_add">+		pfkey_broadcast(pfk-&gt;dump.skb, BROADCAST_ONE,</span>
 				&amp;pfk-&gt;sk, sock_net(&amp;pfk-&gt;sk));
 		pfk-&gt;dump.skb = NULL;
 	}
<span class="p_chunk">@@ -333,7 +333,7 @@</span> <span class="p_context"> static int pfkey_error(const struct sadb_msg *orig, int err, struct sock *sk)</span>
 	hdr-&gt;sadb_msg_len = (sizeof(struct sadb_msg) /
 			     sizeof(uint64_t));
 
<span class="p_del">-	pfkey_broadcast(skb, GFP_KERNEL, BROADCAST_ONE, sk, sock_net(sk));</span>
<span class="p_add">+	pfkey_broadcast(skb, BROADCAST_ONE, sk, sock_net(sk));</span>
 
 	return 0;
 }
<span class="p_chunk">@@ -1364,7 +1364,7 @@</span> <span class="p_context"> static int pfkey_getspi(struct sock *sk, struct sk_buff *skb, const struct sadb_</span>
 
 	xfrm_state_put(x);
 
<span class="p_del">-	pfkey_broadcast(resp_skb, GFP_KERNEL, BROADCAST_ONE, sk, net);</span>
<span class="p_add">+	pfkey_broadcast(resp_skb, BROADCAST_ONE, sk, net);</span>
 
 	return 0;
 }
<span class="p_chunk">@@ -1451,7 +1451,7 @@</span> <span class="p_context"> static int key_notify_sa(struct xfrm_state *x, const struct km_event *c)</span>
 	hdr-&gt;sadb_msg_seq = c-&gt;seq;
 	hdr-&gt;sadb_msg_pid = c-&gt;portid;
 
<span class="p_del">-	pfkey_broadcast(skb, GFP_ATOMIC, BROADCAST_ALL, NULL, xs_net(x));</span>
<span class="p_add">+	pfkey_broadcast(skb, BROADCAST_ALL, NULL, xs_net(x));</span>
 
 	return 0;
 }
<span class="p_chunk">@@ -1564,7 +1564,7 @@</span> <span class="p_context"> static int pfkey_get(struct sock *sk, struct sk_buff *skb, const struct sadb_msg</span>
 	out_hdr-&gt;sadb_msg_reserved = 0;
 	out_hdr-&gt;sadb_msg_seq = hdr-&gt;sadb_msg_seq;
 	out_hdr-&gt;sadb_msg_pid = hdr-&gt;sadb_msg_pid;
<span class="p_del">-	pfkey_broadcast(out_skb, GFP_ATOMIC, BROADCAST_ONE, sk, sock_net(sk));</span>
<span class="p_add">+	pfkey_broadcast(out_skb, BROADCAST_ONE, sk, sock_net(sk));</span>
 
 	return 0;
 }
<span class="p_chunk">@@ -1669,7 +1669,7 @@</span> <span class="p_context"> static int pfkey_register(struct sock *sk, struct sk_buff *skb, const struct sad</span>
 		return -ENOBUFS;
 	}
 
<span class="p_del">-	pfkey_broadcast(supp_skb, GFP_KERNEL, BROADCAST_REGISTERED, sk, sock_net(sk));</span>
<span class="p_add">+	pfkey_broadcast(supp_skb, BROADCAST_REGISTERED, sk, sock_net(sk));</span>
 
 	return 0;
 }
<span class="p_chunk">@@ -1688,7 +1688,7 @@</span> <span class="p_context"> static int unicast_flush_resp(struct sock *sk, const struct sadb_msg *ihdr)</span>
 	hdr-&gt;sadb_msg_errno = (uint8_t) 0;
 	hdr-&gt;sadb_msg_len = (sizeof(struct sadb_msg) / sizeof(uint64_t));
 
<span class="p_del">-	return pfkey_broadcast(skb, GFP_ATOMIC, BROADCAST_ONE, sk, sock_net(sk));</span>
<span class="p_add">+	return pfkey_broadcast(skb, BROADCAST_ONE, sk, sock_net(sk));</span>
 }
 
 static int key_notify_sa_flush(const struct km_event *c)
<span class="p_chunk">@@ -1709,7 +1709,7 @@</span> <span class="p_context"> static int key_notify_sa_flush(const struct km_event *c)</span>
 	hdr-&gt;sadb_msg_len = (sizeof(struct sadb_msg) / sizeof(uint64_t));
 	hdr-&gt;sadb_msg_reserved = 0;
 
<span class="p_del">-	pfkey_broadcast(skb, GFP_ATOMIC, BROADCAST_ALL, NULL, c-&gt;net);</span>
<span class="p_add">+	pfkey_broadcast(skb, BROADCAST_ALL, NULL, c-&gt;net);</span>
 
 	return 0;
 }
<span class="p_chunk">@@ -1766,7 +1766,7 @@</span> <span class="p_context"> static int dump_sa(struct xfrm_state *x, int count, void *ptr)</span>
 	out_hdr-&gt;sadb_msg_pid = pfk-&gt;dump.msg_portid;
 
 	if (pfk-&gt;dump.skb)
<span class="p_del">-		pfkey_broadcast(pfk-&gt;dump.skb, GFP_ATOMIC, BROADCAST_ONE,</span>
<span class="p_add">+		pfkey_broadcast(pfk-&gt;dump.skb, BROADCAST_ONE,</span>
 				&amp;pfk-&gt;sk, sock_net(&amp;pfk-&gt;sk));
 	pfk-&gt;dump.skb = out_skb;
 
<span class="p_chunk">@@ -1846,7 +1846,7 @@</span> <span class="p_context"> static int pfkey_promisc(struct sock *sk, struct sk_buff *skb, const struct sadb</span>
 		new_hdr-&gt;sadb_msg_errno = 0;
 	}
 
<span class="p_del">-	pfkey_broadcast(skb, GFP_KERNEL, BROADCAST_ALL, NULL, sock_net(sk));</span>
<span class="p_add">+	pfkey_broadcast(skb, BROADCAST_ALL, NULL, sock_net(sk));</span>
 	return 0;
 }
 
<span class="p_chunk">@@ -2180,7 +2180,7 @@</span> <span class="p_context"> static int key_notify_policy(struct xfrm_policy *xp, int dir, const struct km_ev</span>
 	out_hdr-&gt;sadb_msg_errno = 0;
 	out_hdr-&gt;sadb_msg_seq = c-&gt;seq;
 	out_hdr-&gt;sadb_msg_pid = c-&gt;portid;
<span class="p_del">-	pfkey_broadcast(out_skb, GFP_ATOMIC, BROADCAST_ALL, NULL, xp_net(xp));</span>
<span class="p_add">+	pfkey_broadcast(out_skb, BROADCAST_ALL, NULL, xp_net(xp));</span>
 	return 0;
 
 }
<span class="p_chunk">@@ -2400,7 +2400,7 @@</span> <span class="p_context"> static int key_pol_get_resp(struct sock *sk, struct xfrm_policy *xp, const struc</span>
 	out_hdr-&gt;sadb_msg_errno = 0;
 	out_hdr-&gt;sadb_msg_seq = hdr-&gt;sadb_msg_seq;
 	out_hdr-&gt;sadb_msg_pid = hdr-&gt;sadb_msg_pid;
<span class="p_del">-	pfkey_broadcast(out_skb, GFP_ATOMIC, BROADCAST_ONE, sk, xp_net(xp));</span>
<span class="p_add">+	pfkey_broadcast(out_skb, BROADCAST_ONE, sk, xp_net(xp));</span>
 	err = 0;
 
 out:
<span class="p_chunk">@@ -2654,7 +2654,7 @@</span> <span class="p_context"> static int dump_sp(struct xfrm_policy *xp, int dir, int count, void *ptr)</span>
 	out_hdr-&gt;sadb_msg_pid = pfk-&gt;dump.msg_portid;
 
 	if (pfk-&gt;dump.skb)
<span class="p_del">-		pfkey_broadcast(pfk-&gt;dump.skb, GFP_ATOMIC, BROADCAST_ONE,</span>
<span class="p_add">+		pfkey_broadcast(pfk-&gt;dump.skb, BROADCAST_ONE,</span>
 				&amp;pfk-&gt;sk, sock_net(&amp;pfk-&gt;sk));
 	pfk-&gt;dump.skb = out_skb;
 
<span class="p_chunk">@@ -2707,7 +2707,7 @@</span> <span class="p_context"> static int key_notify_policy_flush(const struct km_event *c)</span>
 	hdr-&gt;sadb_msg_satype = SADB_SATYPE_UNSPEC;
 	hdr-&gt;sadb_msg_len = (sizeof(struct sadb_msg) / sizeof(uint64_t));
 	hdr-&gt;sadb_msg_reserved = 0;
<span class="p_del">-	pfkey_broadcast(skb_out, GFP_ATOMIC, BROADCAST_ALL, NULL, c-&gt;net);</span>
<span class="p_add">+	pfkey_broadcast(skb_out, BROADCAST_ALL, NULL, c-&gt;net);</span>
 	return 0;
 
 }
<span class="p_chunk">@@ -2769,7 +2769,7 @@</span> <span class="p_context"> static int pfkey_process(struct sock *sk, struct sk_buff *skb, const struct sadb</span>
 	void *ext_hdrs[SADB_EXT_MAX];
 	int err;
 
<span class="p_del">-	pfkey_broadcast(skb_clone(skb, GFP_KERNEL), GFP_KERNEL,</span>
<span class="p_add">+	pfkey_broadcast(skb_clone(skb, GFP_KERNEL),</span>
 			BROADCAST_PROMISC_ONLY, NULL, sock_net(sk));
 
 	memset(ext_hdrs, 0, sizeof(ext_hdrs));
<span class="p_chunk">@@ -2991,7 +2991,7 @@</span> <span class="p_context"> static int key_notify_sa_expire(struct xfrm_state *x, const struct km_event *c)</span>
 	out_hdr-&gt;sadb_msg_seq = 0;
 	out_hdr-&gt;sadb_msg_pid = 0;
 
<span class="p_del">-	pfkey_broadcast(out_skb, GFP_ATOMIC, BROADCAST_REGISTERED, NULL, xs_net(x));</span>
<span class="p_add">+	pfkey_broadcast(out_skb, BROADCAST_REGISTERED, NULL, xs_net(x));</span>
 	return 0;
 }
 
<span class="p_chunk">@@ -3181,7 +3181,7 @@</span> <span class="p_context"> static int pfkey_send_acquire(struct xfrm_state *x, struct xfrm_tmpl *t, struct</span>
 		       xfrm_ctx-&gt;ctx_len);
 	}
 
<span class="p_del">-	return pfkey_broadcast(skb, GFP_ATOMIC, BROADCAST_REGISTERED, NULL, xs_net(x));</span>
<span class="p_add">+	return pfkey_broadcast(skb, BROADCAST_REGISTERED, NULL, xs_net(x));</span>
 }
 
 static struct xfrm_policy *pfkey_compile_policy(struct sock *sk, int opt,
<span class="p_chunk">@@ -3379,7 +3379,7 @@</span> <span class="p_context"> static int pfkey_send_new_mapping(struct xfrm_state *x, xfrm_address_t *ipaddr,</span>
 	n_port-&gt;sadb_x_nat_t_port_port = sport;
 	n_port-&gt;sadb_x_nat_t_port_reserved = 0;
 
<span class="p_del">-	return pfkey_broadcast(skb, GFP_ATOMIC, BROADCAST_REGISTERED, NULL, xs_net(x));</span>
<span class="p_add">+	return pfkey_broadcast(skb, BROADCAST_REGISTERED, NULL, xs_net(x));</span>
 }
 
 #ifdef CONFIG_NET_KEY_MIGRATE
<span class="p_chunk">@@ -3571,7 +3571,7 @@</span> <span class="p_context"> static int pfkey_send_migrate(const struct xfrm_selector *sel, u8 dir, u8 type,</span>
 	}
 
 	/* broadcast migrate message to sockets */
<span class="p_del">-	pfkey_broadcast(skb, GFP_ATOMIC, BROADCAST_ALL, NULL, &amp;init_net);</span>
<span class="p_add">+	pfkey_broadcast(skb, BROADCAST_ALL, NULL, &amp;init_net);</span>
 
 	return 0;
 
<span class="p_header">diff --git a/net/netlink/af_netlink.c b/net/netlink/af_netlink.c</span>
<span class="p_header">index 4b4a2a4..c47affe 100644</span>
<span class="p_header">--- a/net/netlink/af_netlink.c</span>
<span class="p_header">+++ b/net/netlink/af_netlink.c</span>
<span class="p_chunk">@@ -366,25 +366,52 @@</span> <span class="p_context"> err1:</span>
 	return NULL;
 }
 
<span class="p_add">+</span>
<span class="p_add">+static void</span>
<span class="p_add">+__netlink_set_ring(struct sock *sk, struct nl_mmap_req *req, bool tx_ring, void **pg_vec,</span>
<span class="p_add">+		   unsigned int order)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct netlink_sock *nlk = nlk_sk(sk);</span>
<span class="p_add">+	struct sk_buff_head *queue;</span>
<span class="p_add">+	struct netlink_ring *ring;</span>
<span class="p_add">+</span>
<span class="p_add">+	queue = tx_ring ? &amp;sk-&gt;sk_write_queue : &amp;sk-&gt;sk_receive_queue;</span>
<span class="p_add">+	ring  = tx_ring ? &amp;nlk-&gt;tx_ring : &amp;nlk-&gt;rx_ring;</span>
<span class="p_add">+</span>
<span class="p_add">+	spin_lock_bh(&amp;queue-&gt;lock);</span>
<span class="p_add">+</span>
<span class="p_add">+	ring-&gt;frame_max		= req-&gt;nm_frame_nr - 1;</span>
<span class="p_add">+	ring-&gt;head		= 0;</span>
<span class="p_add">+	ring-&gt;frame_size	= req-&gt;nm_frame_size;</span>
<span class="p_add">+	ring-&gt;pg_vec_pages	= req-&gt;nm_block_size / PAGE_SIZE;</span>
<span class="p_add">+</span>
<span class="p_add">+	swap(ring-&gt;pg_vec_len, req-&gt;nm_block_nr);</span>
<span class="p_add">+	swap(ring-&gt;pg_vec_order, order);</span>
<span class="p_add">+	swap(ring-&gt;pg_vec, pg_vec);</span>
<span class="p_add">+</span>
<span class="p_add">+	__skb_queue_purge(queue);</span>
<span class="p_add">+	spin_unlock_bh(&amp;queue-&gt;lock);</span>
<span class="p_add">+</span>
<span class="p_add">+	WARN_ON(atomic_read(&amp;nlk-&gt;mapped));</span>
<span class="p_add">+</span>
<span class="p_add">+	if (pg_vec)</span>
<span class="p_add">+		free_pg_vec(pg_vec, order, req-&gt;nm_block_nr);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static int netlink_set_ring(struct sock *sk, struct nl_mmap_req *req,
<span class="p_del">-			    bool closing, bool tx_ring)</span>
<span class="p_add">+			    bool tx_ring)</span>
 {
 	struct netlink_sock *nlk = nlk_sk(sk);
 	struct netlink_ring *ring;
<span class="p_del">-	struct sk_buff_head *queue;</span>
 	void **pg_vec = NULL;
 	unsigned int order = 0;
<span class="p_del">-	int err;</span>
 
 	ring  = tx_ring ? &amp;nlk-&gt;tx_ring : &amp;nlk-&gt;rx_ring;
<span class="p_del">-	queue = tx_ring ? &amp;sk-&gt;sk_write_queue : &amp;sk-&gt;sk_receive_queue;</span>
 
<span class="p_del">-	if (!closing) {</span>
<span class="p_del">-		if (atomic_read(&amp;nlk-&gt;mapped))</span>
<span class="p_del">-			return -EBUSY;</span>
<span class="p_del">-		if (atomic_read(&amp;ring-&gt;pending))</span>
<span class="p_del">-			return -EBUSY;</span>
<span class="p_del">-	}</span>
<span class="p_add">+	if (atomic_read(&amp;nlk-&gt;mapped))</span>
<span class="p_add">+		return -EBUSY;</span>
<span class="p_add">+	if (atomic_read(&amp;ring-&gt;pending))</span>
<span class="p_add">+		return -EBUSY;</span>
 
 	if (req-&gt;nm_block_nr) {
 		if (ring-&gt;pg_vec != NULL)
<span class="p_chunk">@@ -416,31 +443,19 @@</span> <span class="p_context"> static int netlink_set_ring(struct sock *sk, struct nl_mmap_req *req,</span>
 			return -EINVAL;
 	}
 
<span class="p_del">-	err = -EBUSY;</span>
 	mutex_lock(&amp;nlk-&gt;pg_vec_lock);
<span class="p_del">-	if (closing || atomic_read(&amp;nlk-&gt;mapped) == 0) {</span>
<span class="p_del">-		err = 0;</span>
<span class="p_del">-		spin_lock_bh(&amp;queue-&gt;lock);</span>
<span class="p_del">-</span>
<span class="p_del">-		ring-&gt;frame_max		= req-&gt;nm_frame_nr - 1;</span>
<span class="p_del">-		ring-&gt;head		= 0;</span>
<span class="p_del">-		ring-&gt;frame_size	= req-&gt;nm_frame_size;</span>
<span class="p_del">-		ring-&gt;pg_vec_pages	= req-&gt;nm_block_size / PAGE_SIZE;</span>
<span class="p_del">-</span>
<span class="p_del">-		swap(ring-&gt;pg_vec_len, req-&gt;nm_block_nr);</span>
<span class="p_del">-		swap(ring-&gt;pg_vec_order, order);</span>
<span class="p_del">-		swap(ring-&gt;pg_vec, pg_vec);</span>
<span class="p_del">-</span>
<span class="p_del">-		__skb_queue_purge(queue);</span>
<span class="p_del">-		spin_unlock_bh(&amp;queue-&gt;lock);</span>
<span class="p_del">-</span>
<span class="p_del">-		WARN_ON(atomic_read(&amp;nlk-&gt;mapped));</span>
<span class="p_add">+	if (atomic_read(&amp;nlk-&gt;mapped) == 0) {</span>
<span class="p_add">+		__netlink_set_ring(sk, req, tx_ring, pg_vec, order);</span>
<span class="p_add">+		mutex_unlock(&amp;nlk-&gt;pg_vec_lock);</span>
<span class="p_add">+		return 0;</span>
 	}
<span class="p_add">+</span>
 	mutex_unlock(&amp;nlk-&gt;pg_vec_lock);
 
 	if (pg_vec)
 		free_pg_vec(pg_vec, order, req-&gt;nm_block_nr);
<span class="p_del">-	return err;</span>
<span class="p_add">+</span>
<span class="p_add">+	return -EBUSY;</span>
 }
 
 static void netlink_mm_open(struct vm_area_struct *vma)
<span class="p_chunk">@@ -909,10 +924,10 @@</span> <span class="p_context"> static void netlink_sock_destruct(struct sock *sk)</span>
 
 		memset(&amp;req, 0, sizeof(req));
 		if (nlk-&gt;rx_ring.pg_vec)
<span class="p_del">-			netlink_set_ring(sk, &amp;req, true, false);</span>
<span class="p_add">+			__netlink_set_ring(sk, &amp;req, false, NULL, 0);</span>
 		memset(&amp;req, 0, sizeof(req));
 		if (nlk-&gt;tx_ring.pg_vec)
<span class="p_del">-			netlink_set_ring(sk, &amp;req, true, true);</span>
<span class="p_add">+			__netlink_set_ring(sk, &amp;req, true, NULL, 0);</span>
 	}
 #endif /* CONFIG_NETLINK_MMAP */
 
<span class="p_chunk">@@ -2183,7 +2198,7 @@</span> <span class="p_context"> static int netlink_setsockopt(struct socket *sock, int level, int optname,</span>
 			return -EINVAL;
 		if (copy_from_user(&amp;req, optval, sizeof(req)))
 			return -EFAULT;
<span class="p_del">-		err = netlink_set_ring(sk, &amp;req, false,</span>
<span class="p_add">+		err = netlink_set_ring(sk, &amp;req,</span>
 				       optname == NETLINK_TX_RING);
 		break;
 	}
<span class="p_header">diff --git a/net/rds/connection.c b/net/rds/connection.c</span>
<span class="p_header">index 378c3a6..f5fb7d6 100644</span>
<span class="p_header">--- a/net/rds/connection.c</span>
<span class="p_header">+++ b/net/rds/connection.c</span>
<span class="p_chunk">@@ -183,6 +183,12 @@</span> <span class="p_context"> static struct rds_connection *__rds_conn_create(__be32 laddr, __be32 faddr,</span>
 		}
 	}
 
<span class="p_add">+	if (trans == NULL) {</span>
<span class="p_add">+		kmem_cache_free(rds_conn_slab, conn);</span>
<span class="p_add">+		conn = ERR_PTR(-ENODEV);</span>
<span class="p_add">+		goto out;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
 	conn-&gt;c_trans = trans;
 
 	ret = trans-&gt;conn_alloc(conn, gfp);
<span class="p_header">diff --git a/net/rds/info.c b/net/rds/info.c</span>
<span class="p_header">index 9a6b4f6..140a44a 100644</span>
<span class="p_header">--- a/net/rds/info.c</span>
<span class="p_header">+++ b/net/rds/info.c</span>
<span class="p_chunk">@@ -176,7 +176,7 @@</span> <span class="p_context"> int rds_info_getsockopt(struct socket *sock, int optname, char __user *optval,</span>
 
 	/* check for all kinds of wrapping and the like */
 	start = (unsigned long)optval;
<span class="p_del">-	if (len &lt; 0 || len + PAGE_SIZE - 1 &lt; len || start + len &lt; start) {</span>
<span class="p_add">+	if (len &lt; 0 || len &gt; INT_MAX - PAGE_SIZE + 1 || start + len &lt; start) {</span>
 		ret = -EINVAL;
 		goto out;
 	}
<span class="p_header">diff --git a/net/sched/sch_fq_codel.c b/net/sched/sch_fq_codel.c</span>
<span class="p_header">index b61fd84..398484c 100644</span>
<span class="p_header">--- a/net/sched/sch_fq_codel.c</span>
<span class="p_header">+++ b/net/sched/sch_fq_codel.c</span>
<span class="p_chunk">@@ -286,10 +286,26 @@</span> <span class="p_context"> begin:</span>
 
 static void fq_codel_reset(struct Qdisc *sch)
 {
<span class="p_del">-	struct sk_buff *skb;</span>
<span class="p_add">+	struct fq_codel_sched_data *q = qdisc_priv(sch);</span>
<span class="p_add">+	int i;</span>
 
<span class="p_del">-	while ((skb = fq_codel_dequeue(sch)) != NULL)</span>
<span class="p_del">-		kfree_skb(skb);</span>
<span class="p_add">+	INIT_LIST_HEAD(&amp;q-&gt;new_flows);</span>
<span class="p_add">+	INIT_LIST_HEAD(&amp;q-&gt;old_flows);</span>
<span class="p_add">+	for (i = 0; i &lt; q-&gt;flows_cnt; i++) {</span>
<span class="p_add">+		struct fq_codel_flow *flow = q-&gt;flows + i;</span>
<span class="p_add">+</span>
<span class="p_add">+		while (flow-&gt;head) {</span>
<span class="p_add">+			struct sk_buff *skb = dequeue_head(flow);</span>
<span class="p_add">+</span>
<span class="p_add">+			qdisc_qstats_backlog_dec(sch, skb);</span>
<span class="p_add">+			kfree_skb(skb);</span>
<span class="p_add">+		}</span>
<span class="p_add">+</span>
<span class="p_add">+		INIT_LIST_HEAD(&amp;flow-&gt;flowchain);</span>
<span class="p_add">+		codel_vars_init(&amp;flow-&gt;cvars);</span>
<span class="p_add">+	}</span>
<span class="p_add">+	memset(q-&gt;backlogs, 0, q-&gt;flows_cnt * sizeof(u32));</span>
<span class="p_add">+	sch-&gt;q.qlen = 0;</span>
 }
 
 static const struct nla_policy fq_codel_policy[TCA_FQ_CODEL_MAX + 1] = {
<span class="p_header">diff --git a/net/tipc/socket.c b/net/tipc/socket.c</span>
<span class="p_header">index 4731cad..84cf2f8 100644</span>
<span class="p_header">--- a/net/tipc/socket.c</span>
<span class="p_header">+++ b/net/tipc/socket.c</span>
<span class="p_chunk">@@ -1971,6 +1971,7 @@</span> <span class="p_context"> static int tipc_accept(struct socket *sock, struct socket *new_sock, int flags)</span>
 	res = tipc_sk_create(sock_net(sock-&gt;sk), new_sock, 0, 1);
 	if (res)
 		goto exit;
<span class="p_add">+	security_sk_clone(sock-&gt;sk, new_sock-&gt;sk);</span>
 
 	new_sk = new_sock-&gt;sk;
 	new_tsock = tipc_sk(new_sk);
<span class="p_header">diff --git a/scripts/kconfig/streamline_config.pl b/scripts/kconfig/streamline_config.pl</span>
<span class="p_header">index 9cb8522..f3d3fb4 100755</span>
<span class="p_header">--- a/scripts/kconfig/streamline_config.pl</span>
<span class="p_header">+++ b/scripts/kconfig/streamline_config.pl</span>
<span class="p_chunk">@@ -137,7 +137,7 @@</span> <span class="p_context"> my $ksource = ($ARGV[0] ? $ARGV[0] : &#39;.&#39;);</span>
 my $kconfig = $ARGV[1];
 my $lsmod_file = $ENV{&#39;LSMOD&#39;};
 
<span class="p_del">-my @makefiles = `find $ksource -name Makefile 2&gt;/dev/null`;</span>
<span class="p_add">+my @makefiles = `find $ksource -name Makefile -or -name Kbuild 2&gt;/dev/null`;</span>
 chomp @makefiles;
 
 my %depends;
<span class="p_header">diff --git a/sound/firewire/amdtp.c b/sound/firewire/amdtp.c</span>
<span class="p_header">index 911341b..508cdb8 100644</span>
<span class="p_header">--- a/sound/firewire/amdtp.c</span>
<span class="p_header">+++ b/sound/firewire/amdtp.c</span>
<span class="p_chunk">@@ -730,8 +730,9 @@</span> <span class="p_context"> static void handle_in_packet(struct amdtp_stream *s,</span>
 	    s-&gt;data_block_counter != UINT_MAX)
 		data_block_counter = s-&gt;data_block_counter;
 
<span class="p_del">-	if (((s-&gt;flags &amp; CIP_SKIP_DBC_ZERO_CHECK) &amp;&amp; data_block_counter == 0) ||</span>
<span class="p_del">-	    (s-&gt;data_block_counter == UINT_MAX)) {</span>
<span class="p_add">+	if (((s-&gt;flags &amp; CIP_SKIP_DBC_ZERO_CHECK) &amp;&amp;</span>
<span class="p_add">+	     data_block_counter == s-&gt;tx_first_dbc) ||</span>
<span class="p_add">+	    s-&gt;data_block_counter == UINT_MAX) {</span>
 		lost = false;
 	} else if (!(s-&gt;flags &amp; CIP_DBC_IS_END_EVENT)) {
 		lost = data_block_counter != s-&gt;data_block_counter;
<span class="p_header">diff --git a/sound/firewire/amdtp.h b/sound/firewire/amdtp.h</span>
<span class="p_header">index 8a03a91..25c9055 100644</span>
<span class="p_header">--- a/sound/firewire/amdtp.h</span>
<span class="p_header">+++ b/sound/firewire/amdtp.h</span>
<span class="p_chunk">@@ -153,6 +153,8 @@</span> <span class="p_context"> struct amdtp_stream {</span>
 
 	/* quirk: fixed interval of dbc between previos/current packets. */
 	unsigned int tx_dbc_interval;
<span class="p_add">+	/* quirk: indicate the value of dbc field in a first packet. */</span>
<span class="p_add">+	unsigned int tx_first_dbc;</span>
 
 	bool callbacked;
 	wait_queue_head_t callback_wait;
<span class="p_header">diff --git a/sound/firewire/fireworks/fireworks.c b/sound/firewire/fireworks/fireworks.c</span>
<span class="p_header">index 2682e7e..c94a432 100644</span>
<span class="p_header">--- a/sound/firewire/fireworks/fireworks.c</span>
<span class="p_header">+++ b/sound/firewire/fireworks/fireworks.c</span>
<span class="p_chunk">@@ -248,8 +248,16 @@</span> <span class="p_context"> efw_probe(struct fw_unit *unit,</span>
 	err = get_hardware_info(efw);
 	if (err &lt; 0)
 		goto error;
<span class="p_add">+	/* AudioFire8 (since 2009) and AudioFirePre8 */</span>
 	if (entry-&gt;model_id == MODEL_ECHO_AUDIOFIRE_9)
 		efw-&gt;is_af9 = true;
<span class="p_add">+	/* These models uses the same firmware. */</span>
<span class="p_add">+	if (entry-&gt;model_id == MODEL_ECHO_AUDIOFIRE_2 ||</span>
<span class="p_add">+	    entry-&gt;model_id == MODEL_ECHO_AUDIOFIRE_4 ||</span>
<span class="p_add">+	    entry-&gt;model_id == MODEL_ECHO_AUDIOFIRE_9 ||</span>
<span class="p_add">+	    entry-&gt;model_id == MODEL_GIBSON_RIP ||</span>
<span class="p_add">+	    entry-&gt;model_id == MODEL_GIBSON_GOLDTOP)</span>
<span class="p_add">+		efw-&gt;is_fireworks3 = true;</span>
 
 	snd_efw_proc_init(efw);
 
<span class="p_header">diff --git a/sound/firewire/fireworks/fireworks.h b/sound/firewire/fireworks/fireworks.h</span>
<span class="p_header">index 4f0201a..084d414 100644</span>
<span class="p_header">--- a/sound/firewire/fireworks/fireworks.h</span>
<span class="p_header">+++ b/sound/firewire/fireworks/fireworks.h</span>
<span class="p_chunk">@@ -71,6 +71,7 @@</span> <span class="p_context"> struct snd_efw {</span>
 
 	/* for quirks */
 	bool is_af9;
<span class="p_add">+	bool is_fireworks3;</span>
 	u32 firmware_version;
 
 	unsigned int midi_in_ports;
<span class="p_header">diff --git a/sound/firewire/fireworks/fireworks_stream.c b/sound/firewire/fireworks/fireworks_stream.c</span>
<span class="p_header">index c55db1b..7e353f1 100644</span>
<span class="p_header">--- a/sound/firewire/fireworks/fireworks_stream.c</span>
<span class="p_header">+++ b/sound/firewire/fireworks/fireworks_stream.c</span>
<span class="p_chunk">@@ -172,6 +172,15 @@</span> <span class="p_context"> int snd_efw_stream_init_duplex(struct snd_efw *efw)</span>
 	efw-&gt;tx_stream.flags |= CIP_DBC_IS_END_EVENT;
 	/* Fireworks reset dbc at bus reset. */
 	efw-&gt;tx_stream.flags |= CIP_SKIP_DBC_ZERO_CHECK;
<span class="p_add">+	/*</span>
<span class="p_add">+	 * But Recent firmwares starts packets with non-zero dbc.</span>
<span class="p_add">+	 * Driver version 5.7.6 installs firmware version 5.7.3.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	if (efw-&gt;is_fireworks3 &amp;&amp;</span>
<span class="p_add">+	    (efw-&gt;firmware_version == 0x5070000 ||</span>
<span class="p_add">+	     efw-&gt;firmware_version == 0x5070300 ||</span>
<span class="p_add">+	     efw-&gt;firmware_version == 0x5080000))</span>
<span class="p_add">+		efw-&gt;tx_stream.tx_first_dbc = 0x02;</span>
 	/* AudioFire9 always reports wrong dbs. */
 	if (efw-&gt;is_af9)
 		efw-&gt;tx_stream.flags |= CIP_WRONG_DBS;
<span class="p_header">diff --git a/sound/usb/card.c b/sound/usb/card.c</span>
<span class="p_header">index 1fab977..0450593 100644</span>
<span class="p_header">--- a/sound/usb/card.c</span>
<span class="p_header">+++ b/sound/usb/card.c</span>
<span class="p_chunk">@@ -638,7 +638,7 @@</span> <span class="p_context"> int snd_usb_autoresume(struct snd_usb_audio *chip)</span>
 	int err = -ENODEV;
 
 	down_read(&amp;chip-&gt;shutdown_rwsem);
<span class="p_del">-	if (chip-&gt;probing &amp;&amp; chip-&gt;in_pm)</span>
<span class="p_add">+	if (chip-&gt;probing || chip-&gt;in_pm)</span>
 		err = 0;
 	else if (!chip-&gt;shutdown)
 		err = usb_autopm_get_interface(chip-&gt;pm_intf);
<span class="p_header">diff --git a/sound/usb/quirks.c b/sound/usb/quirks.c</span>
<span class="p_header">index 1b195af..aa98e08 100644</span>
<span class="p_header">--- a/sound/usb/quirks.c</span>
<span class="p_header">+++ b/sound/usb/quirks.c</span>
<span class="p_chunk">@@ -1254,6 +1254,7 @@</span> <span class="p_context"> u64 snd_usb_interface_dsd_format_quirks(struct snd_usb_audio *chip,</span>
 			return SNDRV_PCM_FMTBIT_DSD_U32_BE;
 		break;
 
<span class="p_add">+	case USB_ID(0x20b1, 0x000a): /* Gustard DAC-X20U */</span>
 	case USB_ID(0x20b1, 0x2009): /* DIYINHK DSD DXD 384kHz USB to I2S/DSD */
 	case USB_ID(0x20b1, 0x2023): /* JLsounds I2SoverUSB */
 		if (fp-&gt;altsetting == 3)

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



