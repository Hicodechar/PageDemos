
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>[2/5] oom reaper: handle mlocked pages - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    [2/5] oom reaper: handle mlocked pages</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=137061">Michal Hocko</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>Feb. 3, 2016, 1:13 p.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;1454505240-23446-3-git-send-email-mhocko@kernel.org&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/8202621/mbox/"
   >mbox</a>
|
   <a href="/patch/8202621/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/8202621/">/patch/8202621/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
X-Original-To: patchwork-LKML@patchwork.kernel.org
Delivered-To: patchwork-parsemail@patchwork1.web.kernel.org
Received: from mail.kernel.org (mail.kernel.org [198.145.29.136])
	by patchwork1.web.kernel.org (Postfix) with ESMTP id E9F839F1C0
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Wed,  3 Feb 2016 13:15:23 +0000 (UTC)
Received: from mail.kernel.org (localhost [127.0.0.1])
	by mail.kernel.org (Postfix) with ESMTP id 518A8200DE
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Wed,  3 Feb 2016 13:15:23 +0000 (UTC)
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.kernel.org (Postfix) with ESMTP id 9F9F62027D
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Wed,  3 Feb 2016 13:15:21 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1755859AbcBCNPR (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Wed, 3 Feb 2016 08:15:17 -0500
Received: from mail-wm0-f66.google.com ([74.125.82.66]:36318 &quot;EHLO
	mail-wm0-f66.google.com&quot; rhost-flags-OK-OK-OK-OK) by vger.kernel.org
	with ESMTP id S1752251AbcBCNOJ (ORCPT
	&lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Wed, 3 Feb 2016 08:14:09 -0500
Received: by mail-wm0-f66.google.com with SMTP id 128so7363665wmz.3
	for &lt;linux-kernel@vger.kernel.org&gt;;
	Wed, 03 Feb 2016 05:14:09 -0800 (PST)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
	d=1e100.net; s=20130820;
	h=x-gm-message-state:from:to:cc:subject:date:message-id:in-reply-to
	:references;
	bh=C0FsGEvJobxW3l62Fp9erIfK48Ow8kCX4noxL5r2xJ4=;
	b=GCRZkOMxIbOOIMu7PKKLp1Reu5cdaLwT6vR6/XNxwIQtKcZKcg+fB1OB7Sja9PnFtL
	jzUD6tZPkeUoL7NyUmRPXABootYMXfRfr9kWSxDJ8E8V7GVpQ+y4J30zL4DOxlp0h3Zg
	ZykdXezPidb1NwKeTCTfwVSxbyvXWodanPhHs5RewxoOVWQoNyzZmVI+2h41gtEORPYt
	nVQQ5hn3CPWFf9joKXo7uTk2EVmiFGdd7Hbe5Znql7wq5OgBULK2EVWMBYpKCbY5dvgT
	sBMFrZW2Vz0tgcMjQhYwUfb2IzNZgGNpBJdyzGgA4CvwaARzTddY9COrrq1lXJ4njhS4
	s9xg==
X-Gm-Message-State: AG10YOQpVfTzdHZrCP5SiQxcOEYz0q41b46x5qT9o66uiLaDl/UIq+rEYSB5IZ5hD0ZtQw==
X-Received: by 10.194.201.134 with SMTP id ka6mr1885924wjc.116.1454505248642;
	Wed, 03 Feb 2016 05:14:08 -0800 (PST)
Received: from tiehlicka.suse.cz (nat1.scz.suse.com. [213.151.88.250])
	by smtp.gmail.com with ESMTPSA id
	v22sm7890597wmv.12.2016.02.03.05.14.07
	(version=TLS1_2 cipher=ECDHE-RSA-AES128-SHA bits=128/128);
	Wed, 03 Feb 2016 05:14:08 -0800 (PST)
From: Michal Hocko &lt;mhocko@kernel.org&gt;
To: Andrew Morton &lt;akpm@linux-foundation.org&gt;
Cc: David Rientjes &lt;rientjes@google.com&gt;, Mel Gorman &lt;mgorman@suse.de&gt;,
	Tetsuo Handa &lt;penguin-kernel@I-love.SAKURA.ne.jp&gt;,
	Oleg Nesterov &lt;oleg@redhat.com&gt;,
	Linus Torvalds &lt;torvalds@linux-foundation.org&gt;,
	Hugh Dickins &lt;hughd@google.com&gt;, Andrea Argangeli &lt;andrea@kernel.org&gt;,
	Rik van Riel &lt;riel@redhat.com&gt;, &lt;linux-mm@kvack.org&gt;,
	LKML &lt;linux-kernel@vger.kernel.org&gt;, Michal Hocko &lt;mhocko@suse.com&gt;
Subject: [PATCH 2/5] oom reaper: handle mlocked pages
Date: Wed,  3 Feb 2016 14:13:57 +0100
Message-Id: &lt;1454505240-23446-3-git-send-email-mhocko@kernel.org&gt;
X-Mailer: git-send-email 2.7.0
In-Reply-To: &lt;1454505240-23446-1-git-send-email-mhocko@kernel.org&gt;
References: &lt;1454505240-23446-1-git-send-email-mhocko@kernel.org&gt;
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Spam-Status: No, score=-7.3 required=5.0 tests=BAYES_00, RCVD_IN_DNSWL_HI, 
	RP_MATCHES_RCVD,
	UNPARSEABLE_RELAY autolearn=unavailable version=3.3.1
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on mail.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=137061">Michal Hocko</a> - Feb. 3, 2016, 1:13 p.m.</div>
<pre class="content">
<span class="from">From: Michal Hocko &lt;mhocko@suse.com&gt;</span>

__oom_reap_vmas current skips over all mlocked vmas because they need a
special treatment before they are unmapped. This is primarily done for
simplicity. There is no reason to skip over them and reduce the amount
of reclaimed memory. This is safe from the semantic point of view
because try_to_unmap_one during rmap walk would keep tell the reclaim
to cull the page back and mlock it again.

munlock_vma_pages_all is also safe to be called from the oom reaper
context because it doesn&#39;t sit on any locks but mmap_sem (for read).
<span class="signed-off-by">
Signed-off-by: Michal Hocko &lt;mhocko@suse.com&gt;</span>
---
 mm/oom_kill.c | 12 ++++--------
 1 file changed, 4 insertions(+), 8 deletions(-)
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=579">David Rientjes</a> - Feb. 3, 2016, 11:57 p.m.</div>
<pre class="content">
On Wed, 3 Feb 2016, Michal Hocko wrote:
<span class="quote">
&gt; From: Michal Hocko &lt;mhocko@suse.com&gt;</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; __oom_reap_vmas current skips over all mlocked vmas because they need a</span>
<span class="quote">&gt; special treatment before they are unmapped. This is primarily done for</span>
<span class="quote">&gt; simplicity. There is no reason to skip over them and reduce the amount</span>
<span class="quote">&gt; of reclaimed memory. This is safe from the semantic point of view</span>
<span class="quote">&gt; because try_to_unmap_one during rmap walk would keep tell the reclaim</span>
<span class="quote">&gt; to cull the page back and mlock it again.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; munlock_vma_pages_all is also safe to be called from the oom reaper</span>
<span class="quote">&gt; context because it doesn&#39;t sit on any locks but mmap_sem (for read).</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Signed-off-by: Michal Hocko &lt;mhocko@suse.com&gt;</span>
<span class="acked-by">
Acked-by: David Rientjes &lt;rientjes@google.com&gt;</span>
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=579">David Rientjes</a> - Feb. 23, 2016, 1:36 a.m.</div>
<pre class="content">
On Wed, 3 Feb 2016, Michal Hocko wrote:
<span class="quote">
&gt; diff --git a/mm/oom_kill.c b/mm/oom_kill.c</span>
<span class="quote">&gt; index 9a0e4e5f50b4..840e03986497 100644</span>
<span class="quote">&gt; --- a/mm/oom_kill.c</span>
<span class="quote">&gt; +++ b/mm/oom_kill.c</span>
<span class="quote">&gt; @@ -443,13 +443,6 @@ static bool __oom_reap_vmas(struct mm_struct *mm)</span>
<span class="quote">&gt;  			continue;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  		/*</span>
<span class="quote">&gt; -		 * mlocked VMAs require explicit munlocking before unmap.</span>
<span class="quote">&gt; -		 * Let&#39;s keep it simple here and skip such VMAs.</span>
<span class="quote">&gt; -		 */</span>
<span class="quote">&gt; -		if (vma-&gt;vm_flags &amp; VM_LOCKED)</span>
<span class="quote">&gt; -			continue;</span>
<span class="quote">&gt; -</span>
<span class="quote">&gt; -		/*</span>
<span class="quote">&gt;  		 * Only anonymous pages have a good chance to be dropped</span>
<span class="quote">&gt;  		 * without additional steps which we cannot afford as we</span>
<span class="quote">&gt;  		 * are OOM already.</span>
<span class="quote">&gt; @@ -459,9 +452,12 @@ static bool __oom_reap_vmas(struct mm_struct *mm)</span>
<span class="quote">&gt;  		 * we do not want to block exit_mmap by keeping mm ref</span>
<span class="quote">&gt;  		 * count elevated without a good reason.</span>
<span class="quote">&gt;  		 */</span>
<span class="quote">&gt; -		if (vma_is_anonymous(vma) || !(vma-&gt;vm_flags &amp; VM_SHARED))</span>
<span class="quote">&gt; +		if (vma_is_anonymous(vma) || !(vma-&gt;vm_flags &amp; VM_SHARED)) {</span>
<span class="quote">&gt; +			if (vma-&gt;vm_flags &amp; VM_LOCKED)</span>
<span class="quote">&gt; +				munlock_vma_pages_all(vma);</span>
<span class="quote">&gt;  			unmap_page_range(&amp;tlb, vma, vma-&gt;vm_start, vma-&gt;vm_end,</span>
<span class="quote">&gt;  					 &amp;details);</span>
<span class="quote">&gt; +		}</span>
<span class="quote">&gt;  	}</span>
<span class="quote">&gt;  	tlb_finish_mmu(&amp;tlb, 0, -1);</span>
<span class="quote">&gt;  	up_read(&amp;mm-&gt;mmap_sem);</span>

Are we concerned about munlock_vma_pages_all() taking lock_page() and 
perhaps stalling forever, the same way it would stall in exit_mmap() for 
VM_LOCKED vmas, if another thread has locked the same page and is doing an 
allocation?  I&#39;m wondering if in that case it would be better to do a 
best-effort munlock_vma_pages_all() with trylock_page() and just give up 
on releasing memory from that particular vma.  In that case, there may be 
other memory that can be freed with unmap_page_range() that would handle 
this livelock.
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/mm/oom_kill.c b/mm/oom_kill.c</span>
<span class="p_header">index 9a0e4e5f50b4..840e03986497 100644</span>
<span class="p_header">--- a/mm/oom_kill.c</span>
<span class="p_header">+++ b/mm/oom_kill.c</span>
<span class="p_chunk">@@ -443,13 +443,6 @@</span> <span class="p_context"> static bool __oom_reap_vmas(struct mm_struct *mm)</span>
 			continue;
 
 		/*
<span class="p_del">-		 * mlocked VMAs require explicit munlocking before unmap.</span>
<span class="p_del">-		 * Let&#39;s keep it simple here and skip such VMAs.</span>
<span class="p_del">-		 */</span>
<span class="p_del">-		if (vma-&gt;vm_flags &amp; VM_LOCKED)</span>
<span class="p_del">-			continue;</span>
<span class="p_del">-</span>
<span class="p_del">-		/*</span>
 		 * Only anonymous pages have a good chance to be dropped
 		 * without additional steps which we cannot afford as we
 		 * are OOM already.
<span class="p_chunk">@@ -459,9 +452,12 @@</span> <span class="p_context"> static bool __oom_reap_vmas(struct mm_struct *mm)</span>
 		 * we do not want to block exit_mmap by keeping mm ref
 		 * count elevated without a good reason.
 		 */
<span class="p_del">-		if (vma_is_anonymous(vma) || !(vma-&gt;vm_flags &amp; VM_SHARED))</span>
<span class="p_add">+		if (vma_is_anonymous(vma) || !(vma-&gt;vm_flags &amp; VM_SHARED)) {</span>
<span class="p_add">+			if (vma-&gt;vm_flags &amp; VM_LOCKED)</span>
<span class="p_add">+				munlock_vma_pages_all(vma);</span>
 			unmap_page_range(&amp;tlb, vma, vma-&gt;vm_start, vma-&gt;vm_end,
 					 &amp;details);
<span class="p_add">+		}</span>
 	}
 	tlb_finish_mmu(&amp;tlb, 0, -1);
 	up_read(&amp;mm-&gt;mmap_sem);

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



