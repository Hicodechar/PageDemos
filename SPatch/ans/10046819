
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>[tip:x86/asm] x86: Add support for changing memory encryption attribute in early boot - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    [tip:x86/asm] x86: Add support for changing memory encryption attribute in early boot</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=60001">tip-bot for Jacob Shin</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>Nov. 7, 2017, 2:48 p.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;tip-dfaaec9033b80d71056e21cda920752e55f2c514@git.kernel.org&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/10046819/mbox/"
   >mbox</a>
|
   <a href="/patch/10046819/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/10046819/">/patch/10046819/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
	[172.30.200.125])
	by pdx-korg-patchwork.web.codeaurora.org (Postfix) with ESMTP id
	C9FF860247 for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Tue,  7 Nov 2017 14:50:46 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id B960D28F60
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Tue,  7 Nov 2017 14:50:46 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id ADE842A140; Tue,  7 Nov 2017 14:50:46 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-6.9 required=2.0 tests=BAYES_00,RCVD_IN_DNSWL_HI
	autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id EAE7229D69
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Tue,  7 Nov 2017 14:50:45 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S934517AbdKGOul (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Tue, 7 Nov 2017 09:50:41 -0500
Received: from terminus.zytor.com ([65.50.211.136]:46035 &quot;EHLO
	terminus.zytor.com&quot; rhost-flags-OK-OK-OK-OK) by vger.kernel.org
	with ESMTP id S933842AbdKGOuj (ORCPT
	&lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Tue, 7 Nov 2017 09:50:39 -0500
Received: from terminus.zytor.com (localhost [127.0.0.1])
	by terminus.zytor.com (8.15.2/8.15.2) with ESMTP id vA7EmH09028379;
	Tue, 7 Nov 2017 06:48:17 -0800
Received: (from tipbot@localhost)
	by terminus.zytor.com (8.15.2/8.15.2/Submit) id vA7EmH2l028375;
	Tue, 7 Nov 2017 06:48:17 -0800
Date: Tue, 7 Nov 2017 06:48:17 -0800
X-Authentication-Warning: terminus.zytor.com: tipbot set sender to
	tipbot@zytor.com using -f
From: tip-bot for Brijesh Singh &lt;tipbot@zytor.com&gt;
Message-ID: &lt;tip-dfaaec9033b80d71056e21cda920752e55f2c514@git.kernel.org&gt;
Cc: linux-kernel@vger.kernel.org, tglx@linutronix.de, bp@alien8.de,
	hpa@zytor.com, mingo@kernel.org, thomas.lendacky@amd.com,
	brijesh.singh@amd.com, bp@suse.de
Reply-To: linux-kernel@vger.kernel.org, tglx@linutronix.de, bp@alien8.de,
	hpa@zytor.com, mingo@kernel.org, thomas.lendacky@amd.com,
	bp@suse.de, brijesh.singh@amd.com
In-Reply-To: &lt;20171020143059.3291-15-brijesh.singh@amd.com&gt;
References: &lt;20171020143059.3291-15-brijesh.singh@amd.com&gt;
To: linux-tip-commits@vger.kernel.org
Subject: [tip:x86/asm] x86: Add support for changing memory encryption
	attribute in early boot
Git-Commit-ID: dfaaec9033b80d71056e21cda920752e55f2c514
X-Mailer: tip-git-log-daemon
Robot-ID: &lt;tip-bot.git.kernel.org&gt;
Robot-Unsubscribe: Contact &lt;mailto:hpa@kernel.org&gt; to get blacklisted from
	these emails
MIME-Version: 1.0
Content-Transfer-Encoding: 8bit
Content-Type: text/plain; charset=UTF-8
Content-Disposition: inline
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=60001">tip-bot for Jacob Shin</a> - Nov. 7, 2017, 2:48 p.m.</div>
<pre class="content">
Commit-ID:  dfaaec9033b80d71056e21cda920752e55f2c514
Gitweb:     https://git.kernel.org/tip/dfaaec9033b80d71056e21cda920752e55f2c514
Author:     Brijesh Singh &lt;brijesh.singh@amd.com&gt;
AuthorDate: Fri, 20 Oct 2017 09:30:56 -0500
Committer:  Thomas Gleixner &lt;tglx@linutronix.de&gt;
CommitDate: Tue, 7 Nov 2017 15:35:59 +0100

x86: Add support for changing memory encryption attribute in early boot

Some KVM-specific custom MSRs share the guest physical address with the
hypervisor in early boot. When SEV is active, the shared physical address
must be mapped with memory encryption attribute cleared so that both
hypervisor and guest can access the data.

Add APIs to change the memory encryption attribute in early boot code.
<span class="signed-off-by">
Signed-off-by: Brijesh Singh &lt;brijesh.singh@amd.com&gt;</span>
<span class="signed-off-by">Signed-off-by: Thomas Gleixner &lt;tglx@linutronix.de&gt;</span>
<span class="reviewed-by">Reviewed-by: Borislav Petkov &lt;bp@suse.de&gt;</span>
<span class="tested-by">Tested-by: Borislav Petkov &lt;bp@suse.de&gt;</span>
Cc: Tom Lendacky &lt;thomas.lendacky@amd.com&gt;
Cc: kvm@vger.kernel.org
Cc: Borislav Petkov &lt;bp@alien8.de&gt;
Link: https://lkml.kernel.org/r/20171020143059.3291-15-brijesh.singh@amd.com

---
 arch/x86/include/asm/mem_encrypt.h |   8 +++
 arch/x86/mm/mem_encrypt.c          | 130 +++++++++++++++++++++++++++++++++++++
 2 files changed, 138 insertions(+)
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/arch/x86/include/asm/mem_encrypt.h b/arch/x86/include/asm/mem_encrypt.h</span>
<span class="p_header">index 2b02474..c9459a4 100644</span>
<span class="p_header">--- a/arch/x86/include/asm/mem_encrypt.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/mem_encrypt.h</span>
<span class="p_chunk">@@ -42,6 +42,9 @@</span> <span class="p_context"> void __init sme_early_init(void);</span>
 void __init sme_encrypt_kernel(void);
 void __init sme_enable(struct boot_params *bp);
 
<span class="p_add">+int __init early_set_memory_decrypted(unsigned long vaddr, unsigned long size);</span>
<span class="p_add">+int __init early_set_memory_encrypted(unsigned long vaddr, unsigned long size);</span>
<span class="p_add">+</span>
 /* Architecture __weak replacement functions */
 void __init mem_encrypt_init(void);
 
<span class="p_chunk">@@ -70,6 +73,11 @@</span> <span class="p_context"> static inline void __init sme_enable(struct boot_params *bp) { }</span>
 static inline bool sme_active(void) { return false; }
 static inline bool sev_active(void) { return false; }
 
<span class="p_add">+static inline int __init</span>
<span class="p_add">+early_set_memory_decrypted(unsigned long vaddr, unsigned long size) { return 0; }</span>
<span class="p_add">+static inline int __init</span>
<span class="p_add">+early_set_memory_encrypted(unsigned long vaddr, unsigned long size) { return 0; }</span>
<span class="p_add">+</span>
 #endif	/* CONFIG_AMD_MEM_ENCRYPT */
 
 /*
<span class="p_header">diff --git a/arch/x86/mm/mem_encrypt.c b/arch/x86/mm/mem_encrypt.c</span>
<span class="p_header">index d29b783..5049b8b 100644</span>
<span class="p_header">--- a/arch/x86/mm/mem_encrypt.c</span>
<span class="p_header">+++ b/arch/x86/mm/mem_encrypt.c</span>
<span class="p_chunk">@@ -30,6 +30,8 @@</span> <span class="p_context"></span>
 #include &lt;asm/msr.h&gt;
 #include &lt;asm/cmdline.h&gt;
 
<span class="p_add">+#include &quot;mm_internal.h&quot;</span>
<span class="p_add">+</span>
 static char sme_cmdline_arg[] __initdata = &quot;mem_encrypt&quot;;
 static char sme_cmdline_on[]  __initdata = &quot;on&quot;;
 static char sme_cmdline_off[] __initdata = &quot;off&quot;;
<span class="p_chunk">@@ -260,6 +262,134 @@</span> <span class="p_context"> static void sev_free(struct device *dev, size_t size, void *vaddr,</span>
 	swiotlb_free_coherent(dev, size, vaddr, dma_handle);
 }
 
<span class="p_add">+static void __init __set_clr_pte_enc(pte_t *kpte, int level, bool enc)</span>
<span class="p_add">+{</span>
<span class="p_add">+	pgprot_t old_prot, new_prot;</span>
<span class="p_add">+	unsigned long pfn, pa, size;</span>
<span class="p_add">+	pte_t new_pte;</span>
<span class="p_add">+</span>
<span class="p_add">+	switch (level) {</span>
<span class="p_add">+	case PG_LEVEL_4K:</span>
<span class="p_add">+		pfn = pte_pfn(*kpte);</span>
<span class="p_add">+		old_prot = pte_pgprot(*kpte);</span>
<span class="p_add">+		break;</span>
<span class="p_add">+	case PG_LEVEL_2M:</span>
<span class="p_add">+		pfn = pmd_pfn(*(pmd_t *)kpte);</span>
<span class="p_add">+		old_prot = pmd_pgprot(*(pmd_t *)kpte);</span>
<span class="p_add">+		break;</span>
<span class="p_add">+	case PG_LEVEL_1G:</span>
<span class="p_add">+		pfn = pud_pfn(*(pud_t *)kpte);</span>
<span class="p_add">+		old_prot = pud_pgprot(*(pud_t *)kpte);</span>
<span class="p_add">+		break;</span>
<span class="p_add">+	default:</span>
<span class="p_add">+		return;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	new_prot = old_prot;</span>
<span class="p_add">+	if (enc)</span>
<span class="p_add">+		pgprot_val(new_prot) |= _PAGE_ENC;</span>
<span class="p_add">+	else</span>
<span class="p_add">+		pgprot_val(new_prot) &amp;= ~_PAGE_ENC;</span>
<span class="p_add">+</span>
<span class="p_add">+	/* If prot is same then do nothing. */</span>
<span class="p_add">+	if (pgprot_val(old_prot) == pgprot_val(new_prot))</span>
<span class="p_add">+		return;</span>
<span class="p_add">+</span>
<span class="p_add">+	pa = pfn &lt;&lt; page_level_shift(level);</span>
<span class="p_add">+	size = page_level_size(level);</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * We are going to perform in-place en-/decryption and change the</span>
<span class="p_add">+	 * physical page attribute from C=1 to C=0 or vice versa. Flush the</span>
<span class="p_add">+	 * caches to ensure that data gets accessed with the correct C-bit.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	clflush_cache_range(__va(pa), size);</span>
<span class="p_add">+</span>
<span class="p_add">+	/* Encrypt/decrypt the contents in-place */</span>
<span class="p_add">+	if (enc)</span>
<span class="p_add">+		sme_early_encrypt(pa, size);</span>
<span class="p_add">+	else</span>
<span class="p_add">+		sme_early_decrypt(pa, size);</span>
<span class="p_add">+</span>
<span class="p_add">+	/* Change the page encryption mask. */</span>
<span class="p_add">+	new_pte = pfn_pte(pfn, new_prot);</span>
<span class="p_add">+	set_pte_atomic(kpte, new_pte);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static int __init early_set_memory_enc_dec(unsigned long vaddr,</span>
<span class="p_add">+					   unsigned long size, bool enc)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long vaddr_end, vaddr_next;</span>
<span class="p_add">+	unsigned long psize, pmask;</span>
<span class="p_add">+	int split_page_size_mask;</span>
<span class="p_add">+	int level, ret;</span>
<span class="p_add">+	pte_t *kpte;</span>
<span class="p_add">+</span>
<span class="p_add">+	vaddr_next = vaddr;</span>
<span class="p_add">+	vaddr_end = vaddr + size;</span>
<span class="p_add">+</span>
<span class="p_add">+	for (; vaddr &lt; vaddr_end; vaddr = vaddr_next) {</span>
<span class="p_add">+		kpte = lookup_address(vaddr, &amp;level);</span>
<span class="p_add">+		if (!kpte || pte_none(*kpte)) {</span>
<span class="p_add">+			ret = 1;</span>
<span class="p_add">+			goto out;</span>
<span class="p_add">+		}</span>
<span class="p_add">+</span>
<span class="p_add">+		if (level == PG_LEVEL_4K) {</span>
<span class="p_add">+			__set_clr_pte_enc(kpte, level, enc);</span>
<span class="p_add">+			vaddr_next = (vaddr &amp; PAGE_MASK) + PAGE_SIZE;</span>
<span class="p_add">+			continue;</span>
<span class="p_add">+		}</span>
<span class="p_add">+</span>
<span class="p_add">+		psize = page_level_size(level);</span>
<span class="p_add">+		pmask = page_level_mask(level);</span>
<span class="p_add">+</span>
<span class="p_add">+		/*</span>
<span class="p_add">+		 * Check whether we can change the large page in one go.</span>
<span class="p_add">+		 * We request a split when the address is not aligned and</span>
<span class="p_add">+		 * the number of pages to set/clear encryption bit is smaller</span>
<span class="p_add">+		 * than the number of pages in the large page.</span>
<span class="p_add">+		 */</span>
<span class="p_add">+		if (vaddr == (vaddr &amp; pmask) &amp;&amp;</span>
<span class="p_add">+		    ((vaddr_end - vaddr) &gt;= psize)) {</span>
<span class="p_add">+			__set_clr_pte_enc(kpte, level, enc);</span>
<span class="p_add">+			vaddr_next = (vaddr &amp; pmask) + psize;</span>
<span class="p_add">+			continue;</span>
<span class="p_add">+		}</span>
<span class="p_add">+</span>
<span class="p_add">+		/*</span>
<span class="p_add">+		 * The virtual address is part of a larger page, create the next</span>
<span class="p_add">+		 * level page table mapping (4K or 2M). If it is part of a 2M</span>
<span class="p_add">+		 * page then we request a split of the large page into 4K</span>
<span class="p_add">+		 * chunks. A 1GB large page is split into 2M pages, resp.</span>
<span class="p_add">+		 */</span>
<span class="p_add">+		if (level == PG_LEVEL_2M)</span>
<span class="p_add">+			split_page_size_mask = 0;</span>
<span class="p_add">+		else</span>
<span class="p_add">+			split_page_size_mask = 1 &lt;&lt; PG_LEVEL_2M;</span>
<span class="p_add">+</span>
<span class="p_add">+		kernel_physical_mapping_init(__pa(vaddr &amp; pmask),</span>
<span class="p_add">+					     __pa((vaddr_end &amp; pmask) + psize),</span>
<span class="p_add">+					     split_page_size_mask);</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	ret = 0;</span>
<span class="p_add">+</span>
<span class="p_add">+out:</span>
<span class="p_add">+	__flush_tlb_all();</span>
<span class="p_add">+	return ret;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+int __init early_set_memory_decrypted(unsigned long vaddr, unsigned long size)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return early_set_memory_enc_dec(vaddr, size, false);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+int __init early_set_memory_encrypted(unsigned long vaddr, unsigned long size)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return early_set_memory_enc_dec(vaddr, size, true);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 /*
  * SME and SEV are very similar but they are not the same, so there are
  * times that the kernel will need to distinguish between SME and SEV. The

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



