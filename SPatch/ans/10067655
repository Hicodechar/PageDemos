
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>4.4.86-rt99: fix sync breakage between nr_cpus_allowed and cpus_allowed - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    4.4.86-rt99: fix sync breakage between nr_cpus_allowed and cpus_allowed</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=310">Steven Rostedt</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>Nov. 21, 2017, 4:57 a.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;20171120235751.0424cf23@vmware.local.home&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/10067655/mbox/"
   >mbox</a>
|
   <a href="/patch/10067655/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/10067655/">/patch/10067655/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
	[172.30.200.125])
	by pdx-korg-patchwork.web.codeaurora.org (Postfix) with ESMTP id
	19A156038F for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Tue, 21 Nov 2017 04:58:11 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 151AB28BF3
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Tue, 21 Nov 2017 04:58:11 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id 0852028E65; Tue, 21 Nov 2017 04:58:11 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-6.9 required=2.0 tests=BAYES_00,RCVD_IN_DNSWL_HI
	autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 2463528BF3
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Tue, 21 Nov 2017 04:58:09 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1752867AbdKUE6A convert rfc822-to-8bit (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Mon, 20 Nov 2017 23:58:00 -0500
Received: from smtprelay0199.hostedemail.com ([216.40.44.199]:42688 &quot;EHLO
	smtprelay.hostedemail.com&quot; rhost-flags-OK-OK-OK-FAIL)
	by vger.kernel.org with ESMTP id S1752358AbdKUE57 (ORCPT
	&lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Mon, 20 Nov 2017 23:57:59 -0500
Received: from filter.hostedemail.com (clb03-v110.bra.tucows.net
	[216.40.38.60])
	by smtprelay04.hostedemail.com (Postfix) with ESMTP id 7E070180A813E; 
	Tue, 21 Nov 2017 04:57:58 +0000 (UTC)
X-Session-Marker: 726F737465647440676F6F646D69732E6F7267
X-HE-Tag: farm40_286a840c5211c
X-Filterd-Recvd-Size: 6046
Received: from vmware.local.home (cpe-172-100-180-131.stny.res.rr.com
	[172.100.180.131]) (Authenticated sender: rostedt@goodmis.org)
	by omf06.hostedemail.com (Postfix) with ESMTPA;
	Tue, 21 Nov 2017 04:57:57 +0000 (UTC)
Date: Mon, 20 Nov 2017 23:57:51 -0500
From: Steven Rostedt &lt;rostedt@goodmis.org&gt;
To: joe.korty@concurrent-rt.com
Cc: Thomas Gleixner &lt;tglx@linutronix.de&gt;,
	Peter Zijlstra &lt;a.p.zijlstra@chello.nl&gt;,
	Linux Kernel Mailing List &lt;linux-kernel@vger.kernel.org&gt;
Subject: Re: [PATCH] 4.4.86-rt99: fix sync breakage between nr_cpus_allowed
	and cpus_allowed
Message-ID: &lt;20171120235751.0424cf23@vmware.local.home&gt;
In-Reply-To: &lt;20171120230207.19a4bc14@vmware.local.home&gt;
References: &lt;20171115192529.GA14158@zipoli.concurrent-rt.com&gt;
	&lt;20171117174851.2a253785@gandalf.local.home&gt;
	&lt;20171120163040.GA25993@zipoli.concurrent-rt.com&gt;
	&lt;20171120230207.19a4bc14@vmware.local.home&gt;
X-Mailer: Claws Mail 3.15.1 (GTK+ 2.24.31; x86_64-pc-linux-gnu)
MIME-Version: 1.0
Content-Type: text/plain; charset=US-ASCII
Content-Transfer-Encoding: 8BIT
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=310">Steven Rostedt</a> - Nov. 21, 2017, 4:57 a.m.</div>
<pre class="content">
On Mon, 20 Nov 2017 23:02:07 -0500
Steven Rostedt &lt;rostedt@goodmis.org&gt; wrote:
<span class="quote">

&gt; Ideally, I would like to stay close to what upstream -rt does. Would</span>
<span class="quote">&gt; you be able to backport the 4.11-rt patch?</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; I&#39;m currently working on releasing 4.9-rt and 4.4-rt with the latest</span>
<span class="quote">&gt; backports. I could easily add this one too.</span>

Speaking of which. I just backported this patch to 4.4-rt. Is this what
you are talking about?

-- Steve

From 1dc89be37874bfc7bb4a0ea7c45492d7db39f62b Mon Sep 17 00:00:00 2001
<span class="from">From: Sebastian Andrzej Siewior &lt;bigeasy@linutronix.de&gt;</span>
Date: Mon, 19 Jun 2017 09:55:47 +0200
Subject: [PATCH] sched/migrate disable: handle updated task-mask mg-dis
 section

If task&#39;s cpumask changes while in the task is in a migrate_disable()
section then we don&#39;t react on it after a migrate_enable(). It matters
however if current CPU is no longer part of the cpumask. We also miss
the -&gt;set_cpus_allowed() callback.
This patch fixes it by setting task-&gt;migrate_disable_update once we this
&quot;delayed&quot; hook.
This bug was introduced while fixing unrelated issue in
migrate_disable() in v4.4-rt3 (update_migrate_disable() got removed
during that).

Cc: stable-rt@vger.kernel.org
<span class="signed-off-by">Signed-off-by: Sebastian Andrzej Siewior &lt;bigeasy@linutronix.de&gt;</span>
<span class="signed-off-by">Signed-off-by: Steven Rostedt (VMware) &lt;rostedt@goodmis.org&gt;</span>
---
 include/linux/sched.h |    1 
 kernel/sched/core.c   |   59 ++++++++++++++++++++++++++++++++++++++++++++------
 2 files changed, 54 insertions(+), 6 deletions(-)
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=176227">joe.korty@concurrent-rt.com</a> - Nov. 21, 2017, 2:33 p.m.</div>
<pre class="content">
On Mon, Nov 20, 2017 at 11:57:51PM -0500, Steven Rostedt wrote:
<span class="quote">&gt; On Mon, 20 Nov 2017 23:02:07 -0500</span>
<span class="quote">&gt; Steven Rostedt &lt;rostedt@goodmis.org&gt; wrote:</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; </span>
<span class="quote">&gt; &gt; Ideally, I would like to stay close to what upstream -rt does. Would</span>
<span class="quote">&gt; &gt; you be able to backport the 4.11-rt patch?</span>
<span class="quote">&gt; &gt; </span>
<span class="quote">&gt; &gt; I&#39;m currently working on releasing 4.9-rt and 4.4-rt with the latest</span>
<span class="quote">&gt; &gt; backports. I could easily add this one too.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Speaking of which. I just backported this patch to 4.4-rt. Is this what</span>
<span class="quote">&gt; you are talking about?</span>

Yes it is.
Thanks for finding that!
Joe
<span class="quote">
&gt; &gt;From 1dc89be37874bfc7bb4a0ea7c45492d7db39f62b Mon Sep 17 00:00:00 2001</span>
<span class="quote">&gt; From: Sebastian Andrzej Siewior &lt;bigeasy@linutronix.de&gt;</span>
<span class="quote">&gt; Date: Mon, 19 Jun 2017 09:55:47 +0200</span>
<span class="quote">&gt; Subject: [PATCH] sched/migrate disable: handle updated task-mask mg-dis</span>
<span class="quote">&gt;  section</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; If task&#39;s cpumask changes while in the task is in a migrate_disable()</span>
<span class="quote">&gt; section then we don&#39;t react on it after a migrate_enable(). It matters</span>
<span class="quote">&gt; however if current CPU is no longer part of the cpumask. We also miss</span>
<span class="quote">&gt; the -&gt;set_cpus_allowed() callback.</span>
<span class="quote">&gt; This patch fixes it by setting task-&gt;migrate_disable_update once we this</span>
<span class="quote">&gt; &quot;delayed&quot; hook.</span>
<span class="quote">&gt; This bug was introduced while fixing unrelated issue in</span>
<span class="quote">&gt; migrate_disable() in v4.4-rt3 (update_migrate_disable() got removed</span>
<span class="quote">&gt; during that).</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Cc: stable-rt@vger.kernel.org</span>
<span class="quote">&gt; Signed-off-by: Sebastian Andrzej Siewior &lt;bigeasy@linutronix.de&gt;</span>
<span class="quote">&gt; Signed-off-by: Steven Rostedt (VMware) &lt;rostedt@goodmis.org&gt;</span>
<span class="quote">&gt; ---</span>
<span class="quote">&gt;  include/linux/sched.h |    1 </span>
<span class="quote">&gt;  kernel/sched/core.c   |   59 ++++++++++++++++++++++++++++++++++++++++++++------</span>
<span class="quote">&gt;  2 files changed, 54 insertions(+), 6 deletions(-)</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Index: stable-rt.git/include/linux/sched.h</span>
<span class="quote">&gt; ===================================================================</span>
<span class="quote">&gt; --- stable-rt.git.orig/include/linux/sched.h	2017-11-20 23:43:24.214077537 -0500</span>
<span class="quote">&gt; +++ stable-rt.git/include/linux/sched.h	2017-11-20 23:43:24.154079278 -0500</span>
<span class="quote">&gt; @@ -1438,6 +1438,7 @@ struct task_struct {</span>
<span class="quote">&gt;  	unsigned int policy;</span>
<span class="quote">&gt;  #ifdef CONFIG_PREEMPT_RT_FULL</span>
<span class="quote">&gt;  	int migrate_disable;</span>
<span class="quote">&gt; +	int migrate_disable_update;</span>
<span class="quote">&gt;  # ifdef CONFIG_SCHED_DEBUG</span>
<span class="quote">&gt;  	int migrate_disable_atomic;</span>
<span class="quote">&gt;  # endif</span>
<span class="quote">&gt; Index: stable-rt.git/kernel/sched/core.c</span>
<span class="quote">&gt; ===================================================================</span>
<span class="quote">&gt; --- stable-rt.git.orig/kernel/sched/core.c	2017-11-20 23:43:24.214077537 -0500</span>
<span class="quote">&gt; +++ stable-rt.git/kernel/sched/core.c	2017-11-20 23:56:05.071687323 -0500</span>
<span class="quote">&gt; @@ -1212,18 +1212,14 @@ void set_cpus_allowed_common(struct task</span>
<span class="quote">&gt;  	p-&gt;nr_cpus_allowed = cpumask_weight(new_mask);</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; -void do_set_cpus_allowed(struct task_struct *p, const struct cpumask *new_mask)</span>
<span class="quote">&gt; +static void __do_set_cpus_allowed_tail(struct task_struct *p,</span>
<span class="quote">&gt; +				       const struct cpumask *new_mask)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	struct rq *rq = task_rq(p);</span>
<span class="quote">&gt;  	bool queued, running;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	lockdep_assert_held(&amp;p-&gt;pi_lock);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; -	if (__migrate_disabled(p)) {</span>
<span class="quote">&gt; -		cpumask_copy(&amp;p-&gt;cpus_allowed, new_mask);</span>
<span class="quote">&gt; -		return;</span>
<span class="quote">&gt; -	}</span>
<span class="quote">&gt; -</span>
<span class="quote">&gt;  	queued = task_on_rq_queued(p);</span>
<span class="quote">&gt;  	running = task_current(rq, p);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; @@ -1246,6 +1242,20 @@ void do_set_cpus_allowed(struct task_str</span>
<span class="quote">&gt;  		enqueue_task(rq, p, ENQUEUE_RESTORE);</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; +void do_set_cpus_allowed(struct task_struct *p, const struct cpumask *new_mask)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	if (__migrate_disabled(p)) {</span>
<span class="quote">&gt; +		lockdep_assert_held(&amp;p-&gt;pi_lock);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +		cpumask_copy(&amp;p-&gt;cpus_allowed, new_mask);</span>
<span class="quote">&gt; +#if defined(CONFIG_PREEMPT_RT_FULL) &amp;&amp; defined(CONFIG_SMP)</span>
<span class="quote">&gt; +		p-&gt;migrate_disable_update = 1;</span>
<span class="quote">&gt; +#endif</span>
<span class="quote">&gt; +		return;</span>
<span class="quote">&gt; +	}</span>
<span class="quote">&gt; +	__do_set_cpus_allowed_tail(p, new_mask);</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt;  static DEFINE_PER_CPU(struct cpumask, sched_cpumasks);</span>
<span class="quote">&gt;  static DEFINE_MUTEX(sched_down_mutex);</span>
<span class="quote">&gt;  static cpumask_t sched_down_cpumask;</span>
<span class="quote">&gt; @@ -3231,6 +3241,43 @@ void migrate_enable(void)</span>
<span class="quote">&gt;  	 */</span>
<span class="quote">&gt;  	p-&gt;migrate_disable = 0;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; +	if (p-&gt;migrate_disable_update) {</span>
<span class="quote">&gt; +		unsigned long flags;</span>
<span class="quote">&gt; +		struct rq *rq;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +		rq = task_rq_lock(p, &amp;flags);</span>
<span class="quote">&gt; +		update_rq_clock(rq);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +		__do_set_cpus_allowed_tail(p, &amp;p-&gt;cpus_allowed);</span>
<span class="quote">&gt; +		task_rq_unlock(rq, p, &amp;flags);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +		p-&gt;migrate_disable_update = 0;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +		WARN_ON(smp_processor_id() != task_cpu(p));</span>
<span class="quote">&gt; +		if (!cpumask_test_cpu(task_cpu(p), &amp;p-&gt;cpus_allowed)) {</span>
<span class="quote">&gt; +			const struct cpumask *cpu_valid_mask = cpu_active_mask;</span>
<span class="quote">&gt; +			struct migration_arg arg;</span>
<span class="quote">&gt; +			unsigned int dest_cpu;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +			if (p-&gt;flags &amp; PF_KTHREAD) {</span>
<span class="quote">&gt; +				/*</span>
<span class="quote">&gt; +				 * Kernel threads are allowed on online &amp;&amp; !active CPUs</span>
<span class="quote">&gt; +				 */</span>
<span class="quote">&gt; +				cpu_valid_mask = cpu_online_mask;</span>
<span class="quote">&gt; +			}</span>
<span class="quote">&gt; +			dest_cpu = cpumask_any_and(cpu_valid_mask, &amp;p-&gt;cpus_allowed);</span>
<span class="quote">&gt; +			arg.task = p;</span>
<span class="quote">&gt; +			arg.dest_cpu = dest_cpu;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +			unpin_current_cpu();</span>
<span class="quote">&gt; +			preempt_lazy_enable();</span>
<span class="quote">&gt; +			preempt_enable();</span>
<span class="quote">&gt; +			stop_one_cpu(task_cpu(p), migration_cpu_stop, &amp;arg);</span>
<span class="quote">&gt; +			tlb_migrate_finish(p-&gt;mm);</span>
<span class="quote">&gt; +			return;</span>
<span class="quote">&gt; +		}</span>
<span class="quote">&gt; +	}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt;  	unpin_current_cpu();</span>
<span class="quote">&gt;  	preempt_enable();</span>
<span class="quote">&gt;  	preempt_lazy_enable();</span>
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=176227">joe.korty@concurrent-rt.com</a> - Nov. 21, 2017, 3:33 p.m.</div>
<pre class="content">
On Tue, Nov 21, 2017 at 09:33:52AM -0500, joe.korty@concurrent-rt.com wrote:
<span class="quote">&gt; On Mon, Nov 20, 2017 at 11:57:51PM -0500, Steven Rostedt wrote:</span>
<span class="quote">&gt; &gt; On Mon, 20 Nov 2017 23:02:07 -0500</span>
<span class="quote">&gt; &gt; Steven Rostedt &lt;rostedt@goodmis.org&gt; wrote:</span>
<span class="quote">&gt; &gt; </span>
<span class="quote">&gt; &gt; </span>
<span class="quote">&gt; &gt; &gt; Ideally, I would like to stay close to what upstream -rt does. Would</span>
<span class="quote">&gt; &gt; &gt; you be able to backport the 4.11-rt patch?</span>
<span class="quote">&gt; &gt; &gt; </span>
<span class="quote">&gt; &gt; &gt; I&#39;m currently working on releasing 4.9-rt and 4.4-rt with the latest</span>
<span class="quote">&gt; &gt; &gt; backports. I could easily add this one too.</span>
<span class="quote">&gt; &gt; </span>
<span class="quote">&gt; &gt; Speaking of which. I just backported this patch to 4.4-rt. Is this what</span>
<span class="quote">&gt; &gt; you are talking about?</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Yes it is.</span>
<span class="quote">&gt; Thanks for finding that!</span>
<span class="quote">&gt; Joe</span>

I spoke too fast.  You will a variant of my one-liner fix
when you backport the 4.11.12-r16 patch:

    rt-Increase-decrease-the-nr-of-migratory-tasks-when-.patch

to 4.9-rt and 4.4-rt.  The fix of interest is the introduction of

    p-&gt;nr_cpus_allowed = cpumask_weight(&amp;p-&gt;cpus_mask);

to migrate_enable_update_cpus_allowed().

Regards,
Joe
<span class="quote">
&gt; </span>
<span class="quote">&gt; &gt; &gt;From 1dc89be37874bfc7bb4a0ea7c45492d7db39f62b Mon Sep 17 00:00:00 2001</span>
<span class="quote">&gt; &gt; From: Sebastian Andrzej Siewior &lt;bigeasy@linutronix.de&gt;</span>
<span class="quote">&gt; &gt; Date: Mon, 19 Jun 2017 09:55:47 +0200</span>
<span class="quote">&gt; &gt; Subject: [PATCH] sched/migrate disable: handle updated task-mask mg-dis</span>
<span class="quote">&gt; &gt;  section</span>
<span class="quote">&gt; &gt; </span>
<span class="quote">&gt; &gt; If task&#39;s cpumask changes while in the task is in a migrate_disable()</span>
<span class="quote">&gt; &gt; section then we don&#39;t react on it after a migrate_enable(). It matters</span>
<span class="quote">&gt; &gt; however if current CPU is no longer part of the cpumask. We also miss</span>
<span class="quote">&gt; &gt; the -&gt;set_cpus_allowed() callback.</span>
<span class="quote">&gt; &gt; This patch fixes it by setting task-&gt;migrate_disable_update once we this</span>
<span class="quote">&gt; &gt; &quot;delayed&quot; hook.</span>
<span class="quote">&gt; &gt; This bug was introduced while fixing unrelated issue in</span>
<span class="quote">&gt; &gt; migrate_disable() in v4.4-rt3 (update_migrate_disable() got removed</span>
<span class="quote">&gt; &gt; during that).</span>
<span class="quote">&gt; &gt; </span>
<span class="quote">&gt; &gt; Cc: stable-rt@vger.kernel.org</span>
<span class="quote">&gt; &gt; Signed-off-by: Sebastian Andrzej Siewior &lt;bigeasy@linutronix.de&gt;</span>
<span class="quote">&gt; &gt; Signed-off-by: Steven Rostedt (VMware) &lt;rostedt@goodmis.org&gt;</span>
<span class="quote">&gt; &gt; ---</span>
<span class="quote">&gt; &gt;  include/linux/sched.h |    1 </span>
<span class="quote">&gt; &gt;  kernel/sched/core.c   |   59 ++++++++++++++++++++++++++++++++++++++++++++------</span>
<span class="quote">&gt; &gt;  2 files changed, 54 insertions(+), 6 deletions(-)</span>
<span class="quote">&gt; &gt; </span>
<span class="quote">&gt; &gt; Index: stable-rt.git/include/linux/sched.h</span>
<span class="quote">&gt; &gt; ===================================================================</span>
<span class="quote">&gt; &gt; --- stable-rt.git.orig/include/linux/sched.h	2017-11-20 23:43:24.214077537 -0500</span>
<span class="quote">&gt; &gt; +++ stable-rt.git/include/linux/sched.h	2017-11-20 23:43:24.154079278 -0500</span>
<span class="quote">&gt; &gt; @@ -1438,6 +1438,7 @@ struct task_struct {</span>
<span class="quote">&gt; &gt;  	unsigned int policy;</span>
<span class="quote">&gt; &gt;  #ifdef CONFIG_PREEMPT_RT_FULL</span>
<span class="quote">&gt; &gt;  	int migrate_disable;</span>
<span class="quote">&gt; &gt; +	int migrate_disable_update;</span>
<span class="quote">&gt; &gt;  # ifdef CONFIG_SCHED_DEBUG</span>
<span class="quote">&gt; &gt;  	int migrate_disable_atomic;</span>
<span class="quote">&gt; &gt;  # endif</span>
<span class="quote">&gt; &gt; Index: stable-rt.git/kernel/sched/core.c</span>
<span class="quote">&gt; &gt; ===================================================================</span>
<span class="quote">&gt; &gt; --- stable-rt.git.orig/kernel/sched/core.c	2017-11-20 23:43:24.214077537 -0500</span>
<span class="quote">&gt; &gt; +++ stable-rt.git/kernel/sched/core.c	2017-11-20 23:56:05.071687323 -0500</span>
<span class="quote">&gt; &gt; @@ -1212,18 +1212,14 @@ void set_cpus_allowed_common(struct task</span>
<span class="quote">&gt; &gt;  	p-&gt;nr_cpus_allowed = cpumask_weight(new_mask);</span>
<span class="quote">&gt; &gt;  }</span>
<span class="quote">&gt; &gt;  </span>
<span class="quote">&gt; &gt; -void do_set_cpus_allowed(struct task_struct *p, const struct cpumask *new_mask)</span>
<span class="quote">&gt; &gt; +static void __do_set_cpus_allowed_tail(struct task_struct *p,</span>
<span class="quote">&gt; &gt; +				       const struct cpumask *new_mask)</span>
<span class="quote">&gt; &gt;  {</span>
<span class="quote">&gt; &gt;  	struct rq *rq = task_rq(p);</span>
<span class="quote">&gt; &gt;  	bool queued, running;</span>
<span class="quote">&gt; &gt;  </span>
<span class="quote">&gt; &gt;  	lockdep_assert_held(&amp;p-&gt;pi_lock);</span>
<span class="quote">&gt; &gt;  </span>
<span class="quote">&gt; &gt; -	if (__migrate_disabled(p)) {</span>
<span class="quote">&gt; &gt; -		cpumask_copy(&amp;p-&gt;cpus_allowed, new_mask);</span>
<span class="quote">&gt; &gt; -		return;</span>
<span class="quote">&gt; &gt; -	}</span>
<span class="quote">&gt; &gt; -</span>
<span class="quote">&gt; &gt;  	queued = task_on_rq_queued(p);</span>
<span class="quote">&gt; &gt;  	running = task_current(rq, p);</span>
<span class="quote">&gt; &gt;  </span>
<span class="quote">&gt; &gt; @@ -1246,6 +1242,20 @@ void do_set_cpus_allowed(struct task_str</span>
<span class="quote">&gt; &gt;  		enqueue_task(rq, p, ENQUEUE_RESTORE);</span>
<span class="quote">&gt; &gt;  }</span>
<span class="quote">&gt; &gt;  </span>
<span class="quote">&gt; &gt; +void do_set_cpus_allowed(struct task_struct *p, const struct cpumask *new_mask)</span>
<span class="quote">&gt; &gt; +{</span>
<span class="quote">&gt; &gt; +	if (__migrate_disabled(p)) {</span>
<span class="quote">&gt; &gt; +		lockdep_assert_held(&amp;p-&gt;pi_lock);</span>
<span class="quote">&gt; &gt; +</span>
<span class="quote">&gt; &gt; +		cpumask_copy(&amp;p-&gt;cpus_allowed, new_mask);</span>
<span class="quote">&gt; &gt; +#if defined(CONFIG_PREEMPT_RT_FULL) &amp;&amp; defined(CONFIG_SMP)</span>
<span class="quote">&gt; &gt; +		p-&gt;migrate_disable_update = 1;</span>
<span class="quote">&gt; &gt; +#endif</span>
<span class="quote">&gt; &gt; +		return;</span>
<span class="quote">&gt; &gt; +	}</span>
<span class="quote">&gt; &gt; +	__do_set_cpus_allowed_tail(p, new_mask);</span>
<span class="quote">&gt; &gt; +}</span>
<span class="quote">&gt; &gt; +</span>
<span class="quote">&gt; &gt;  static DEFINE_PER_CPU(struct cpumask, sched_cpumasks);</span>
<span class="quote">&gt; &gt;  static DEFINE_MUTEX(sched_down_mutex);</span>
<span class="quote">&gt; &gt;  static cpumask_t sched_down_cpumask;</span>
<span class="quote">&gt; &gt; @@ -3231,6 +3241,43 @@ void migrate_enable(void)</span>
<span class="quote">&gt; &gt;  	 */</span>
<span class="quote">&gt; &gt;  	p-&gt;migrate_disable = 0;</span>
<span class="quote">&gt; &gt;  </span>
<span class="quote">&gt; &gt; +	if (p-&gt;migrate_disable_update) {</span>
<span class="quote">&gt; &gt; +		unsigned long flags;</span>
<span class="quote">&gt; &gt; +		struct rq *rq;</span>
<span class="quote">&gt; &gt; +</span>
<span class="quote">&gt; &gt; +		rq = task_rq_lock(p, &amp;flags);</span>
<span class="quote">&gt; &gt; +		update_rq_clock(rq);</span>
<span class="quote">&gt; &gt; +</span>
<span class="quote">&gt; &gt; +		__do_set_cpus_allowed_tail(p, &amp;p-&gt;cpus_allowed);</span>
<span class="quote">&gt; &gt; +		task_rq_unlock(rq, p, &amp;flags);</span>
<span class="quote">&gt; &gt; +</span>
<span class="quote">&gt; &gt; +		p-&gt;migrate_disable_update = 0;</span>
<span class="quote">&gt; &gt; +</span>
<span class="quote">&gt; &gt; +		WARN_ON(smp_processor_id() != task_cpu(p));</span>
<span class="quote">&gt; &gt; +		if (!cpumask_test_cpu(task_cpu(p), &amp;p-&gt;cpus_allowed)) {</span>
<span class="quote">&gt; &gt; +			const struct cpumask *cpu_valid_mask = cpu_active_mask;</span>
<span class="quote">&gt; &gt; +			struct migration_arg arg;</span>
<span class="quote">&gt; &gt; +			unsigned int dest_cpu;</span>
<span class="quote">&gt; &gt; +</span>
<span class="quote">&gt; &gt; +			if (p-&gt;flags &amp; PF_KTHREAD) {</span>
<span class="quote">&gt; &gt; +				/*</span>
<span class="quote">&gt; &gt; +				 * Kernel threads are allowed on online &amp;&amp; !active CPUs</span>
<span class="quote">&gt; &gt; +				 */</span>
<span class="quote">&gt; &gt; +				cpu_valid_mask = cpu_online_mask;</span>
<span class="quote">&gt; &gt; +			}</span>
<span class="quote">&gt; &gt; +			dest_cpu = cpumask_any_and(cpu_valid_mask, &amp;p-&gt;cpus_allowed);</span>
<span class="quote">&gt; &gt; +			arg.task = p;</span>
<span class="quote">&gt; &gt; +			arg.dest_cpu = dest_cpu;</span>
<span class="quote">&gt; &gt; +</span>
<span class="quote">&gt; &gt; +			unpin_current_cpu();</span>
<span class="quote">&gt; &gt; +			preempt_lazy_enable();</span>
<span class="quote">&gt; &gt; +			preempt_enable();</span>
<span class="quote">&gt; &gt; +			stop_one_cpu(task_cpu(p), migration_cpu_stop, &amp;arg);</span>
<span class="quote">&gt; &gt; +			tlb_migrate_finish(p-&gt;mm);</span>
<span class="quote">&gt; &gt; +			return;</span>
<span class="quote">&gt; &gt; +		}</span>
<span class="quote">&gt; &gt; +	}</span>
<span class="quote">&gt; &gt; +</span>
<span class="quote">&gt; &gt;  	unpin_current_cpu();</span>
<span class="quote">&gt; &gt;  	preempt_enable();</span>
<span class="quote">&gt; &gt;  	preempt_lazy_enable();</span>
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=310">Steven Rostedt</a> - Nov. 29, 2017, 12:22 a.m.</div>
<pre class="content">
On Tue, 21 Nov 2017 10:33:17 -0500
joe.korty@concurrent-rt.com wrote:
<span class="quote">
&gt; On Tue, Nov 21, 2017 at 09:33:52AM -0500, joe.korty@concurrent-rt.com wrote:</span>
<span class="quote">&gt; &gt; On Mon, Nov 20, 2017 at 11:57:51PM -0500, Steven Rostedt wrote:  </span>
<span class="quote">&gt; &gt; &gt; On Mon, 20 Nov 2017 23:02:07 -0500</span>
<span class="quote">&gt; &gt; &gt; Steven Rostedt &lt;rostedt@goodmis.org&gt; wrote:</span>
<span class="quote">&gt; &gt; &gt; </span>
<span class="quote">&gt; &gt; &gt;   </span>
<span class="quote">&gt; &gt; &gt; &gt; Ideally, I would like to stay close to what upstream -rt does. Would</span>
<span class="quote">&gt; &gt; &gt; &gt; you be able to backport the 4.11-rt patch?</span>
<span class="quote">&gt; &gt; &gt; &gt; </span>
<span class="quote">&gt; &gt; &gt; &gt; I&#39;m currently working on releasing 4.9-rt and 4.4-rt with the latest</span>
<span class="quote">&gt; &gt; &gt; &gt; backports. I could easily add this one too.  </span>
<span class="quote">&gt; &gt; &gt; </span>
<span class="quote">&gt; &gt; &gt; Speaking of which. I just backported this patch to 4.4-rt. Is this what</span>
<span class="quote">&gt; &gt; &gt; you are talking about?  </span>
<span class="quote">&gt; &gt; </span>
<span class="quote">&gt; &gt; Yes it is.</span>
<span class="quote">&gt; &gt; Thanks for finding that!</span>
<span class="quote">&gt; &gt; Joe  </span>
<span class="quote">&gt; </span>
<span class="quote">&gt; I spoke too fast.  You will a variant of my one-liner fix</span>
<span class="quote">&gt; when you backport the 4.11.12-r16 patch:</span>
<span class="quote">&gt; </span>
<span class="quote">&gt;     rt-Increase-decrease-the-nr-of-migratory-tasks-when-.patch</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; to 4.9-rt and 4.4-rt.  The fix of interest is the introduction of</span>
<span class="quote">&gt; </span>
<span class="quote">&gt;     p-&gt;nr_cpus_allowed = cpumask_weight(&amp;p-&gt;cpus_mask);</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; to migrate_enable_update_cpus_allowed().</span>

You totally confused me here.

Hmm, that patch isn&#39;t marked for stable. I&#39;m guessing that it should be
backported.

Now are you saying your patch still needs to be applied if we backport
this patch? Or does your patch need to be applied to what I have
already done?

I want to release 4.4-rt (and 4.9-rt) this week so let me know.

-- Steve
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=176227">joe.korty@concurrent-rt.com</a> - Nov. 29, 2017, 2:24 p.m.</div>
<pre class="content">
On Tue, Nov 28, 2017 at 07:22:34PM -0500, Steven Rostedt wrote:
<span class="quote">&gt; On Tue, 21 Nov 2017 10:33:17 -0500</span>
<span class="quote">&gt; joe.korty@concurrent-rt.com wrote:</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; &gt; On Tue, Nov 21, 2017 at 09:33:52AM -0500, joe.korty@concurrent-rt.com wrote:</span>
<span class="quote">&gt; &gt; &gt; On Mon, Nov 20, 2017 at 11:57:51PM -0500, Steven Rostedt wrote:  </span>
<span class="quote">&gt; &gt; &gt; &gt; On Mon, 20 Nov 2017 23:02:07 -0500</span>
<span class="quote">&gt; &gt; &gt; &gt; Steven Rostedt &lt;rostedt@goodmis.org&gt; wrote:</span>
<span class="quote">&gt; &gt; &gt; &gt; </span>
<span class="quote">&gt; &gt; &gt; &gt;   </span>
<span class="quote">&gt; &gt; &gt; &gt; &gt; Ideally, I would like to stay close to what upstream -rt does. Would</span>
<span class="quote">&gt; &gt; &gt; &gt; &gt; you be able to backport the 4.11-rt patch?</span>
<span class="quote">&gt; &gt; &gt; &gt; &gt; </span>
<span class="quote">&gt; &gt; &gt; &gt; &gt; I&#39;m currently working on releasing 4.9-rt and 4.4-rt with the latest</span>
<span class="quote">&gt; &gt; &gt; &gt; &gt; backports. I could easily add this one too.  </span>
<span class="quote">&gt; &gt; &gt; &gt; </span>
<span class="quote">&gt; &gt; &gt; &gt; Speaking of which. I just backported this patch to 4.4-rt. Is this what</span>
<span class="quote">&gt; &gt; &gt; &gt; you are talking about?  </span>
<span class="quote">&gt; &gt; &gt; </span>
<span class="quote">&gt; &gt; &gt; Yes it is.</span>
<span class="quote">&gt; &gt; &gt; Thanks for finding that!</span>
<span class="quote">&gt; &gt; &gt; Joe  </span>
<span class="quote">&gt; &gt; </span>
<span class="quote">&gt; &gt; I spoke too fast.  You will a variant of my one-liner fix</span>
<span class="quote">&gt; &gt; when you backport the 4.11.12-r16 patch:</span>
<span class="quote">&gt; &gt; </span>
<span class="quote">&gt; &gt;     rt-Increase-decrease-the-nr-of-migratory-tasks-when-.patch</span>
<span class="quote">&gt; &gt; </span>
<span class="quote">&gt; &gt; to 4.9-rt and 4.4-rt.  The fix of interest is the introduction of</span>
<span class="quote">&gt; &gt; </span>
<span class="quote">&gt; &gt;     p-&gt;nr_cpus_allowed = cpumask_weight(&amp;p-&gt;cpus_mask);</span>
<span class="quote">&gt; &gt; </span>
<span class="quote">&gt; &gt; to migrate_enable_update_cpus_allowed().</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; You totally confused me here.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Hmm, that patch isn&#39;t marked for stable. I&#39;m guessing that it should be</span>
<span class="quote">&gt; backported.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Now are you saying your patch still needs to be applied if we backport</span>
<span class="quote">&gt; this patch? Or does your patch need to be applied to what I have</span>
<span class="quote">&gt; already done?</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; I want to release 4.4-rt (and 4.9-rt) this week so let me know.</span>



Hi Steve,
Just porting that other patch should do the trick.  Or you can just apply
my patch, I know that one works as it has actually been tested.

Joe
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">Index: stable-rt.git/include/linux/sched.h</span>
===================================================================
<span class="p_header">--- stable-rt.git.orig/include/linux/sched.h	2017-11-20 23:43:24.214077537 -0500</span>
<span class="p_header">+++ stable-rt.git/include/linux/sched.h	2017-11-20 23:43:24.154079278 -0500</span>
<span class="p_chunk">@@ -1438,6 +1438,7 @@</span> <span class="p_context"> struct task_struct {</span>
 	unsigned int policy;
 #ifdef CONFIG_PREEMPT_RT_FULL
 	int migrate_disable;
<span class="p_add">+	int migrate_disable_update;</span>
 # ifdef CONFIG_SCHED_DEBUG
 	int migrate_disable_atomic;
 # endif
<span class="p_header">Index: stable-rt.git/kernel/sched/core.c</span>
===================================================================
<span class="p_header">--- stable-rt.git.orig/kernel/sched/core.c	2017-11-20 23:43:24.214077537 -0500</span>
<span class="p_header">+++ stable-rt.git/kernel/sched/core.c	2017-11-20 23:56:05.071687323 -0500</span>
<span class="p_chunk">@@ -1212,18 +1212,14 @@</span> <span class="p_context"> void set_cpus_allowed_common(struct task</span>
 	p-&gt;nr_cpus_allowed = cpumask_weight(new_mask);
 }
 
<span class="p_del">-void do_set_cpus_allowed(struct task_struct *p, const struct cpumask *new_mask)</span>
<span class="p_add">+static void __do_set_cpus_allowed_tail(struct task_struct *p,</span>
<span class="p_add">+				       const struct cpumask *new_mask)</span>
 {
 	struct rq *rq = task_rq(p);
 	bool queued, running;
 
 	lockdep_assert_held(&amp;p-&gt;pi_lock);
 
<span class="p_del">-	if (__migrate_disabled(p)) {</span>
<span class="p_del">-		cpumask_copy(&amp;p-&gt;cpus_allowed, new_mask);</span>
<span class="p_del">-		return;</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
 	queued = task_on_rq_queued(p);
 	running = task_current(rq, p);
 
<span class="p_chunk">@@ -1246,6 +1242,20 @@</span> <span class="p_context"> void do_set_cpus_allowed(struct task_str</span>
 		enqueue_task(rq, p, ENQUEUE_RESTORE);
 }
 
<span class="p_add">+void do_set_cpus_allowed(struct task_struct *p, const struct cpumask *new_mask)</span>
<span class="p_add">+{</span>
<span class="p_add">+	if (__migrate_disabled(p)) {</span>
<span class="p_add">+		lockdep_assert_held(&amp;p-&gt;pi_lock);</span>
<span class="p_add">+</span>
<span class="p_add">+		cpumask_copy(&amp;p-&gt;cpus_allowed, new_mask);</span>
<span class="p_add">+#if defined(CONFIG_PREEMPT_RT_FULL) &amp;&amp; defined(CONFIG_SMP)</span>
<span class="p_add">+		p-&gt;migrate_disable_update = 1;</span>
<span class="p_add">+#endif</span>
<span class="p_add">+		return;</span>
<span class="p_add">+	}</span>
<span class="p_add">+	__do_set_cpus_allowed_tail(p, new_mask);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static DEFINE_PER_CPU(struct cpumask, sched_cpumasks);
 static DEFINE_MUTEX(sched_down_mutex);
 static cpumask_t sched_down_cpumask;
<span class="p_chunk">@@ -3231,6 +3241,43 @@</span> <span class="p_context"> void migrate_enable(void)</span>
 	 */
 	p-&gt;migrate_disable = 0;
 
<span class="p_add">+	if (p-&gt;migrate_disable_update) {</span>
<span class="p_add">+		unsigned long flags;</span>
<span class="p_add">+		struct rq *rq;</span>
<span class="p_add">+</span>
<span class="p_add">+		rq = task_rq_lock(p, &amp;flags);</span>
<span class="p_add">+		update_rq_clock(rq);</span>
<span class="p_add">+</span>
<span class="p_add">+		__do_set_cpus_allowed_tail(p, &amp;p-&gt;cpus_allowed);</span>
<span class="p_add">+		task_rq_unlock(rq, p, &amp;flags);</span>
<span class="p_add">+</span>
<span class="p_add">+		p-&gt;migrate_disable_update = 0;</span>
<span class="p_add">+</span>
<span class="p_add">+		WARN_ON(smp_processor_id() != task_cpu(p));</span>
<span class="p_add">+		if (!cpumask_test_cpu(task_cpu(p), &amp;p-&gt;cpus_allowed)) {</span>
<span class="p_add">+			const struct cpumask *cpu_valid_mask = cpu_active_mask;</span>
<span class="p_add">+			struct migration_arg arg;</span>
<span class="p_add">+			unsigned int dest_cpu;</span>
<span class="p_add">+</span>
<span class="p_add">+			if (p-&gt;flags &amp; PF_KTHREAD) {</span>
<span class="p_add">+				/*</span>
<span class="p_add">+				 * Kernel threads are allowed on online &amp;&amp; !active CPUs</span>
<span class="p_add">+				 */</span>
<span class="p_add">+				cpu_valid_mask = cpu_online_mask;</span>
<span class="p_add">+			}</span>
<span class="p_add">+			dest_cpu = cpumask_any_and(cpu_valid_mask, &amp;p-&gt;cpus_allowed);</span>
<span class="p_add">+			arg.task = p;</span>
<span class="p_add">+			arg.dest_cpu = dest_cpu;</span>
<span class="p_add">+</span>
<span class="p_add">+			unpin_current_cpu();</span>
<span class="p_add">+			preempt_lazy_enable();</span>
<span class="p_add">+			preempt_enable();</span>
<span class="p_add">+			stop_one_cpu(task_cpu(p), migration_cpu_stop, &amp;arg);</span>
<span class="p_add">+			tlb_migrate_finish(p-&gt;mm);</span>
<span class="p_add">+			return;</span>
<span class="p_add">+		}</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
 	unpin_current_cpu();
 	preempt_enable();
 	preempt_lazy_enable();

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



