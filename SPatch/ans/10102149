
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>[v3,07/33] nds32: MMU initialization - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    [v3,07/33] nds32: MMU initialization</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=171217">Greentime Hu</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>Dec. 8, 2017, 9:11 a.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;0964714c3dcac46ac700085717b0f414b7978112.1512723245.git.green.hu@gmail.com&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/10102149/mbox/"
   >mbox</a>
|
   <a href="/patch/10102149/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/10102149/">/patch/10102149/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
	[172.30.200.125])
	by pdx-korg-patchwork.web.codeaurora.org (Postfix) with ESMTP id
	B7F6160325 for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Fri,  8 Dec 2017 10:03:30 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 919BE28696
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Fri,  8 Dec 2017 10:03:30 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id 8470B28942; Fri,  8 Dec 2017 10:03:30 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-7.0 required=2.0 tests=BAYES_00,DKIM_SIGNED,
	DKIM_VALID, DKIM_VALID_AU, FREEMAIL_FROM,
	RCVD_IN_DNSWL_HI autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 3D80128696
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Fri,  8 Dec 2017 10:03:29 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1753611AbdLHKC0 (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Fri, 8 Dec 2017 05:02:26 -0500
Received: from mail-pg0-f68.google.com ([74.125.83.68]:44986 &quot;EHLO
	mail-pg0-f68.google.com&quot; rhost-flags-OK-OK-OK-OK) by vger.kernel.org
	with ESMTP id S1753219AbdLHJiS (ORCPT
	&lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Fri, 8 Dec 2017 04:38:18 -0500
Received: by mail-pg0-f68.google.com with SMTP id j9so6523118pgc.11;
	Fri, 08 Dec 2017 01:38:17 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
	d=gmail.com; s=20161025;
	h=from:to:cc:subject:date:message-id:in-reply-to:references
	:in-reply-to:references;
	bh=B+Puo1CCrdzURlx2TDNG/UoLBukUT5vZcsAlRTMlVD8=;
	b=gDmuKLewBhSmS861MAHFkXCdihL1YbzUZHkBrx2ruXNFsFLDyAM3V55UXNu3ssF+Ya
	XS4FQiJFgRn0TGt1kZq9FQq0YHpPoFLTMc0jT075tlYUInrdOP0u4gL745M74FYC9ey9
	cEA8WTduR6ggETQLjRBxEySA4VqO76y5hsc3UcbU9YDH89ncd4OaDdxmI8qrGrneMsmK
	dlqC8HjXHBdtgVljvkphcQ6EBXMdxh0nG8CIPm6h/P5Y6mPETJF6+tWDcObC3hWpFD0W
	oQfEVgk6Y0wXsdFMHzM2Mia9tsRpLgnAiEOJwzYv68Yci113GeBblVTBe2LAqKJd2LKI
	/zLA==
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
	d=1e100.net; s=20161025;
	h=x-gm-message-state:from:to:cc:subject:date:message-id:in-reply-to
	:references:in-reply-to:references;
	bh=B+Puo1CCrdzURlx2TDNG/UoLBukUT5vZcsAlRTMlVD8=;
	b=RBFQ2zXoKtYwDskNIUDiE6bwxM03yc0KpOjV/Cgx3I2SSakUZqAHgxtqNEBnb6HFN0
	tBO3aI95G2uAkXi/uujbIhM8HFdWfR1qaI1/Tc7pj0zpwO+9kmbB62mqvlDd/YI87mkv
	dVrdhJGDtrtxhbuS6309evX7Iftj8jDUqp/EpbJXJqbsKP4MEdFDkV6PKDyDix9jfVBO
	+SudziNgsSs5mmp3PEw9G2EiK3ohIcC6LoM35cFdutCOjS6RKjWZqxBQYDJSELjWpX3C
	ZuBnLnlC7Xlh13Bsc/2DfEbYpc6MsHNQf5akTMu1Mr7OwRQPjZkLc4YOY/Iu19NLs46m
	tmAA==
X-Gm-Message-State: AJaThX737oj33uYdJ8Ae2MvB5NFnIIe/A1L8jfi76rm/qzm/jKfshIQL
	5BmujpzWqqmbMwWJTiMkZjA=
X-Google-Smtp-Source: AGs4zMZWnV5vivwtYzzDTv4AepPHcBC/YBx7/HnspfyH249HP9tDTrDv659qCU+IW90kUEADjdYbyA==
X-Received: by 10.99.113.83 with SMTP id b19mr28586938pgn.41.1512725897035; 
	Fri, 08 Dec 2017 01:38:17 -0800 (PST)
Received: from app09.andestech.com ([118.163.51.199])
	by smtp.gmail.com with ESMTPSA id
	g10sm14827405pfe.77.2017.12.08.01.38.13
	(version=TLS1_2 cipher=ECDHE-RSA-AES128-GCM-SHA256 bits=128/128);
	Fri, 08 Dec 2017 01:38:16 -0800 (PST)
From: Greentime Hu &lt;green.hu@gmail.com&gt;
To: greentime@andestech.com, linux-kernel@vger.kernel.org,
	arnd@arndb.de, linux-arch@vger.kernel.org, tglx@linutronix.de,
	jason@lakedaemon.net, marc.zyngier@arm.com, robh+dt@kernel.org,
	netdev@vger.kernel.org, deanbo422@gmail.com,
	devicetree@vger.kernel.org, viro@zeniv.linux.org.uk,
	dhowells@redhat.com, will.deacon@arm.com,
	daniel.lezcano@linaro.org, linux-serial@vger.kernel.org,
	geert.uytterhoeven@gmail.com, linus.walleij@linaro.org,
	mark.rutland@arm.com, greg@kroah.com
Cc: green.hu@gmail.com, Vincent Chen &lt;vincentc@andestech.com&gt;
Subject: [PATCH v3 07/33] nds32: MMU initialization
Date: Fri,  8 Dec 2017 17:11:50 +0800
Message-Id: &lt;0964714c3dcac46ac700085717b0f414b7978112.1512723245.git.green.hu@gmail.com&gt;
X-Mailer: git-send-email 1.7.9.5
In-Reply-To: &lt;cover.1512723245.git.green.hu@gmail.com&gt;
References: &lt;cover.1512723245.git.green.hu@gmail.com&gt;
In-Reply-To: &lt;cover.1512723245.git.green.hu@gmail.com&gt;
References: &lt;cover.1512723245.git.green.hu@gmail.com&gt;
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=171217">Greentime Hu</a> - Dec. 8, 2017, 9:11 a.m.</div>
<pre class="content">
<span class="from">From: Greentime Hu &lt;greentime@andestech.com&gt;</span>

This patch includes memory initializations and highmem supporting.
<span class="signed-off-by">
Signed-off-by: Vincent Chen &lt;vincentc@andestech.com&gt;</span>
<span class="signed-off-by">Signed-off-by: Greentime Hu &lt;greentime@andestech.com&gt;</span>
---
 arch/nds32/mm/highmem.c  |   92 +++++++++++++++
 arch/nds32/mm/init.c     |  290 ++++++++++++++++++++++++++++++++++++++++++++++
 arch/nds32/mm/mm-nds32.c |  103 ++++++++++++++++
 3 files changed, 485 insertions(+)
 create mode 100644 arch/nds32/mm/highmem.c
 create mode 100644 arch/nds32/mm/init.c
 create mode 100644 arch/nds32/mm/mm-nds32.c
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=177875">Guo Ren</a> - Dec. 18, 2017, 9:08 a.m.</div>
<pre class="content">
Hi Greentime,

On Fri, Dec 08, 2017 at 05:11:50PM +0800, Greentime Hu wrote:
[...]
<span class="quote">&gt; </span>
<span class="quote">&gt; diff --git a/arch/nds32/mm/highmem.c b/arch/nds32/mm/highmem.c</span>
[...]
<span class="quote">&gt; +void *kmap(struct page *page)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	unsigned long vaddr;</span>
<span class="quote">&gt; +	might_sleep();</span>
<span class="quote">&gt; +	if (!PageHighMem(page))</span>
<span class="quote">&gt; +		return page_address(page);</span>
<span class="quote">&gt; +	vaddr = (unsigned long)kmap_high(page);</span>
Here should invalid the cpu_mmu_tlb&#39;s entry, Or invalid it in the
set_pte().

eg:
vaddr0 = kmap(page0)
*vaddr0 = val0 //It will cause tlb-miss, and hard-refill to MMU-tlb
kunmap(page0)
vaddr1 = kmap(page1) // Mostly vaddr1 = vaddr0
val = vaddr1; //No tlb-miss and it will get page0&#39;s val not page1, because
		last expired vaddr0&#39;s entry is left in CPU-MMU-tlb.

Best Regards
 Guo Ren
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=171217">Greentime Hu</a> - Dec. 18, 2017, 11:21 a.m.</div>
<pre class="content">
Hi, Guo Ren:

2017-12-18 17:08 GMT+08:00 Guo Ren &lt;ren_guo@c-sky.com&gt;:
<span class="quote">&gt; Hi Greentime,</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; On Fri, Dec 08, 2017 at 05:11:50PM +0800, Greentime Hu wrote:</span>
<span class="quote">&gt; [...]</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; diff --git a/arch/nds32/mm/highmem.c b/arch/nds32/mm/highmem.c</span>
<span class="quote">&gt; [...]</span>
<span class="quote">&gt;&gt; +void *kmap(struct page *page)</span>
<span class="quote">&gt;&gt; +{</span>
<span class="quote">&gt;&gt; +     unsigned long vaddr;</span>
<span class="quote">&gt;&gt; +     might_sleep();</span>
<span class="quote">&gt;&gt; +     if (!PageHighMem(page))</span>
<span class="quote">&gt;&gt; +             return page_address(page);</span>
<span class="quote">&gt;&gt; +     vaddr = (unsigned long)kmap_high(page);</span>
<span class="quote">&gt; Here should invalid the cpu_mmu_tlb&#39;s entry, Or invalid it in the</span>
<span class="quote">&gt; set_pte().</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; eg:</span>
<span class="quote">&gt; vaddr0 = kmap(page0)</span>
<span class="quote">&gt; *vaddr0 = val0 //It will cause tlb-miss, and hard-refill to MMU-tlb</span>
<span class="quote">&gt; kunmap(page0)</span>
<span class="quote">&gt; vaddr1 = kmap(page1) // Mostly vaddr1 = vaddr0</span>
<span class="quote">&gt; val = vaddr1; //No tlb-miss and it will get page0&#39;s val not page1, because</span>
<span class="quote">&gt;                 last expired vaddr0&#39;s entry is left in CPU-MMU-tlb.</span>
<span class="quote">&gt;</span>

Thanks.
I will add __nds32__tlbop_inv(vaddr); to invalidate this mapping
before retrun vaddr.
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=177875">Guo Ren</a> - Dec. 18, 2017, 12:22 p.m.</div>
<pre class="content">
On Mon, Dec 18, 2017 at 07:21:30PM +0800, Greentime Hu wrote:
<span class="quote">&gt; Hi, Guo Ren:</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; 2017-12-18 17:08 GMT+08:00 Guo Ren &lt;ren_guo@c-sky.com&gt;:</span>
<span class="quote">&gt; &gt; Hi Greentime,</span>
<span class="quote">&gt; &gt;</span>
<span class="quote">&gt; &gt; On Fri, Dec 08, 2017 at 05:11:50PM +0800, Greentime Hu wrote:</span>
<span class="quote">&gt; &gt; [...]</span>
<span class="quote">&gt; &gt;&gt;</span>
<span class="quote">&gt; &gt;&gt; diff --git a/arch/nds32/mm/highmem.c b/arch/nds32/mm/highmem.c</span>
<span class="quote">&gt; &gt; [...]</span>
<span class="quote">&gt; &gt;&gt; +void *kmap(struct page *page)</span>
<span class="quote">&gt; &gt;&gt; +{</span>
<span class="quote">&gt; &gt;&gt; +     unsigned long vaddr;</span>
<span class="quote">&gt; &gt;&gt; +     might_sleep();</span>
<span class="quote">&gt; &gt;&gt; +     if (!PageHighMem(page))</span>
<span class="quote">&gt; &gt;&gt; +             return page_address(page);</span>
<span class="quote">&gt; &gt;&gt; +     vaddr = (unsigned long)kmap_high(page);</span>
<span class="quote">&gt; &gt; Here should invalid the cpu_mmu_tlb&#39;s entry, Or invalid it in the</span>
<span class="quote">&gt; &gt; set_pte().</span>
<span class="quote">&gt; &gt;</span>
<span class="quote">&gt; &gt; eg:</span>
<span class="quote">&gt; &gt; vaddr0 = kmap(page0)</span>
<span class="quote">&gt; &gt; *vaddr0 = val0 //It will cause tlb-miss, and hard-refill to MMU-tlb</span>
<span class="quote">&gt; &gt; kunmap(page0)</span>
<span class="quote">&gt; &gt; vaddr1 = kmap(page1) // Mostly vaddr1 = vaddr0</span>
<span class="quote">&gt; &gt; val = vaddr1; //No tlb-miss and it will get page0&#39;s val not page1, because</span>
<span class="quote">&gt; &gt;                 last expired vaddr0&#39;s entry is left in CPU-MMU-tlb.</span>
<span class="quote">&gt; &gt;</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Thanks.</span>
<span class="quote">&gt; I will add __nds32__tlbop_inv(vaddr); to invalidate this mapping</span>
<span class="quote">&gt; before retrun vaddr.</span>

Sorry, perhaps I&#39;m wrong. See
kmap-&gt;kmap_high-&gt;map_new_virtual-&gt;get_next_pkmap_nr(color).

Seems pkmap will return the vaddr by vaddr + 1 until
no_more_pkmaps(), and then flush_all_zero_pkmaps.
Just kmap_atomic need it, and you&#39;ve done.

But I don&#39;t know why mips need flush_tlb_one in
arch/mips/mm/highmem.c:kmap(). VIPT? but kmap give the get_pkmap_color
for aliasing.

Best Regards
 Guo Ren
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=171217">Greentime Hu</a> - Dec. 19, 2017, 6:56 a.m.</div>
<pre class="content">
Hi, Guo Ren:

2017-12-18 20:22 GMT+08:00 Guo Ren &lt;ren_guo@c-sky.com&gt;:
<span class="quote">&gt; On Mon, Dec 18, 2017 at 07:21:30PM +0800, Greentime Hu wrote:</span>
<span class="quote">&gt;&gt; Hi, Guo Ren:</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; 2017-12-18 17:08 GMT+08:00 Guo Ren &lt;ren_guo@c-sky.com&gt;:</span>
<span class="quote">&gt;&gt; &gt; Hi Greentime,</span>
<span class="quote">&gt;&gt; &gt;</span>
<span class="quote">&gt;&gt; &gt; On Fri, Dec 08, 2017 at 05:11:50PM +0800, Greentime Hu wrote:</span>
<span class="quote">&gt;&gt; &gt; [...]</span>
<span class="quote">&gt;&gt; &gt;&gt;</span>
<span class="quote">&gt;&gt; &gt;&gt; diff --git a/arch/nds32/mm/highmem.c b/arch/nds32/mm/highmem.c</span>
<span class="quote">&gt;&gt; &gt; [...]</span>
<span class="quote">&gt;&gt; &gt;&gt; +void *kmap(struct page *page)</span>
<span class="quote">&gt;&gt; &gt;&gt; +{</span>
<span class="quote">&gt;&gt; &gt;&gt; +     unsigned long vaddr;</span>
<span class="quote">&gt;&gt; &gt;&gt; +     might_sleep();</span>
<span class="quote">&gt;&gt; &gt;&gt; +     if (!PageHighMem(page))</span>
<span class="quote">&gt;&gt; &gt;&gt; +             return page_address(page);</span>
<span class="quote">&gt;&gt; &gt;&gt; +     vaddr = (unsigned long)kmap_high(page);</span>
<span class="quote">&gt;&gt; &gt; Here should invalid the cpu_mmu_tlb&#39;s entry, Or invalid it in the</span>
<span class="quote">&gt;&gt; &gt; set_pte().</span>
<span class="quote">&gt;&gt; &gt;</span>
<span class="quote">&gt;&gt; &gt; eg:</span>
<span class="quote">&gt;&gt; &gt; vaddr0 = kmap(page0)</span>
<span class="quote">&gt;&gt; &gt; *vaddr0 = val0 //It will cause tlb-miss, and hard-refill to MMU-tlb</span>
<span class="quote">&gt;&gt; &gt; kunmap(page0)</span>
<span class="quote">&gt;&gt; &gt; vaddr1 = kmap(page1) // Mostly vaddr1 = vaddr0</span>
<span class="quote">&gt;&gt; &gt; val = vaddr1; //No tlb-miss and it will get page0&#39;s val not page1, because</span>
<span class="quote">&gt;&gt; &gt;                 last expired vaddr0&#39;s entry is left in CPU-MMU-tlb.</span>
<span class="quote">&gt;&gt; &gt;</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; Thanks.</span>
<span class="quote">&gt;&gt; I will add __nds32__tlbop_inv(vaddr); to invalidate this mapping</span>
<span class="quote">&gt;&gt; before retrun vaddr.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; Sorry, perhaps I&#39;m wrong. See</span>
<span class="quote">&gt; kmap-&gt;kmap_high-&gt;map_new_virtual-&gt;get_next_pkmap_nr(color).</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; Seems pkmap will return the vaddr by vaddr + 1 until</span>
<span class="quote">&gt; no_more_pkmaps(), and then flush_all_zero_pkmaps.</span>
<span class="quote">&gt; Just kmap_atomic need it, and you&#39;ve done.</span>

Thanks for double checking this case. :)
As you said, it will flush tlb in the generic code flow.
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/arch/nds32/mm/highmem.c b/arch/nds32/mm/highmem.c</span>
new file mode 100644
<span class="p_header">index 0000000..d5101bd</span>
<span class="p_header">--- /dev/null</span>
<span class="p_header">+++ b/arch/nds32/mm/highmem.c</span>
<span class="p_chunk">@@ -0,0 +1,92 @@</span> <span class="p_context"></span>
<span class="p_add">+/*</span>
<span class="p_add">+ * Copyright (C) 2005-2017 Andes Technology Corporation</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * This program is free software; you can redistribute it and/or modify</span>
<span class="p_add">+ * it under the terms of the GNU General Public License version 2 as</span>
<span class="p_add">+ * published by the Free Software Foundation.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * This program is distributed in the hope that it will be useful,</span>
<span class="p_add">+ * but WITHOUT ANY WARRANTY; without even the implied warranty of</span>
<span class="p_add">+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the</span>
<span class="p_add">+ * GNU General Public License for more details.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * You should have received a copy of the GNU General Public License</span>
<span class="p_add">+ * along with this program.  If not, see &lt;http://www.gnu.org/licenses/&gt;.</span>
<span class="p_add">+ */</span>
<span class="p_add">+</span>
<span class="p_add">+#include &lt;linux/export.h&gt;</span>
<span class="p_add">+#include &lt;linux/highmem.h&gt;</span>
<span class="p_add">+#include &lt;linux/sched.h&gt;</span>
<span class="p_add">+#include &lt;linux/smp.h&gt;</span>
<span class="p_add">+#include &lt;linux/interrupt.h&gt;</span>
<span class="p_add">+#include &lt;linux/bootmem.h&gt;</span>
<span class="p_add">+#include &lt;asm/fixmap.h&gt;</span>
<span class="p_add">+#include &lt;asm/tlbflush.h&gt;</span>
<span class="p_add">+</span>
<span class="p_add">+void *kmap(struct page *page)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long vaddr;</span>
<span class="p_add">+	might_sleep();</span>
<span class="p_add">+	if (!PageHighMem(page))</span>
<span class="p_add">+		return page_address(page);</span>
<span class="p_add">+	vaddr = (unsigned long)kmap_high(page);</span>
<span class="p_add">+	return (void *)vaddr;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+EXPORT_SYMBOL(kmap);</span>
<span class="p_add">+</span>
<span class="p_add">+void kunmap(struct page *page)</span>
<span class="p_add">+{</span>
<span class="p_add">+	BUG_ON(in_interrupt());</span>
<span class="p_add">+	if (!PageHighMem(page))</span>
<span class="p_add">+		return;</span>
<span class="p_add">+	kunmap_high(page);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+EXPORT_SYMBOL(kunmap);</span>
<span class="p_add">+</span>
<span class="p_add">+void *kmap_atomic(struct page *page)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned int idx;</span>
<span class="p_add">+	unsigned long vaddr, pte;</span>
<span class="p_add">+	int type;</span>
<span class="p_add">+	pte_t *ptep;</span>
<span class="p_add">+</span>
<span class="p_add">+	preempt_disable();</span>
<span class="p_add">+	pagefault_disable();</span>
<span class="p_add">+	if (!PageHighMem(page))</span>
<span class="p_add">+		return page_address(page);</span>
<span class="p_add">+</span>
<span class="p_add">+	type = kmap_atomic_idx_push();</span>
<span class="p_add">+</span>
<span class="p_add">+	idx = type + KM_TYPE_NR * smp_processor_id();</span>
<span class="p_add">+	vaddr = __fix_to_virt(FIX_KMAP_BEGIN + idx);</span>
<span class="p_add">+	pte = (page_to_pfn(page) &lt;&lt; PAGE_SHIFT) | (PAGE_KERNEL);</span>
<span class="p_add">+	ptep = pte_offset_kernel(pmd_off_k(vaddr), vaddr);</span>
<span class="p_add">+	set_pte(ptep, pte);</span>
<span class="p_add">+</span>
<span class="p_add">+	__nds32__tlbop_inv(vaddr);</span>
<span class="p_add">+	__nds32__mtsr_dsb(vaddr, NDS32_SR_TLB_VPN);</span>
<span class="p_add">+	__nds32__tlbop_rwr(pte);</span>
<span class="p_add">+	__nds32__isb();</span>
<span class="p_add">+	return (void *)vaddr;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+EXPORT_SYMBOL(kmap_atomic);</span>
<span class="p_add">+</span>
<span class="p_add">+void __kunmap_atomic(void *kvaddr)</span>
<span class="p_add">+{</span>
<span class="p_add">+	if (kvaddr &gt;= (void *)FIXADDR_START) {</span>
<span class="p_add">+		unsigned long vaddr = (unsigned long)kvaddr;</span>
<span class="p_add">+		pte_t *ptep;</span>
<span class="p_add">+		kmap_atomic_idx_pop();</span>
<span class="p_add">+		__nds32__tlbop_inv(vaddr);</span>
<span class="p_add">+		__nds32__isb();</span>
<span class="p_add">+		ptep = pte_offset_kernel(pmd_off_k(vaddr), vaddr);</span>
<span class="p_add">+		set_pte(ptep, 0);</span>
<span class="p_add">+	}</span>
<span class="p_add">+	pagefault_enable();</span>
<span class="p_add">+	preempt_enable();</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+EXPORT_SYMBOL(__kunmap_atomic);</span>
<span class="p_header">diff --git a/arch/nds32/mm/init.c b/arch/nds32/mm/init.c</span>
new file mode 100644
<span class="p_header">index 0000000..05e072a</span>
<span class="p_header">--- /dev/null</span>
<span class="p_header">+++ b/arch/nds32/mm/init.c</span>
<span class="p_chunk">@@ -0,0 +1,290 @@</span> <span class="p_context"></span>
<span class="p_add">+/*</span>
<span class="p_add">+ * Copyright (C) 1995-2005 Russell King</span>
<span class="p_add">+ * Copyright (C) 2012 ARM Ltd.</span>
<span class="p_add">+ * Copyright (C) 2013-2017 Andes Technology Corporation</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * This program is free software; you can redistribute it and/or modify</span>
<span class="p_add">+ * it under the terms of the GNU General Public License version 2 as</span>
<span class="p_add">+ * published by the Free Software Foundation.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * This program is distributed in the hope that it will be useful,</span>
<span class="p_add">+ * but WITHOUT ANY WARRANTY; without even the implied warranty of</span>
<span class="p_add">+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the</span>
<span class="p_add">+ * GNU General Public License for more details.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * You should have received a copy of the GNU General Public License</span>
<span class="p_add">+ * along with this program.  If not, see &lt;http://www.gnu.org/licenses/&gt;.</span>
<span class="p_add">+ */</span>
<span class="p_add">+</span>
<span class="p_add">+#include &lt;linux/kernel.h&gt;</span>
<span class="p_add">+#include &lt;linux/errno.h&gt;</span>
<span class="p_add">+#include &lt;linux/swap.h&gt;</span>
<span class="p_add">+#include &lt;linux/init.h&gt;</span>
<span class="p_add">+#include &lt;linux/bootmem.h&gt;</span>
<span class="p_add">+#include &lt;linux/mman.h&gt;</span>
<span class="p_add">+#include &lt;linux/nodemask.h&gt;</span>
<span class="p_add">+#include &lt;linux/initrd.h&gt;</span>
<span class="p_add">+#include &lt;linux/highmem.h&gt;</span>
<span class="p_add">+#include &lt;linux/memblock.h&gt;</span>
<span class="p_add">+</span>
<span class="p_add">+#include &lt;asm/sections.h&gt;</span>
<span class="p_add">+#include &lt;asm/setup.h&gt;</span>
<span class="p_add">+#include &lt;asm/tlb.h&gt;</span>
<span class="p_add">+#include &lt;asm/page.h&gt;</span>
<span class="p_add">+</span>
<span class="p_add">+DEFINE_PER_CPU(struct mmu_gather, mmu_gathers);</span>
<span class="p_add">+DEFINE_SPINLOCK(anon_alias_lock);</span>
<span class="p_add">+extern pgd_t swapper_pg_dir[PTRS_PER_PGD];</span>
<span class="p_add">+extern unsigned long phys_initrd_start;</span>
<span class="p_add">+extern unsigned long phys_initrd_size;</span>
<span class="p_add">+</span>
<span class="p_add">+/*</span>
<span class="p_add">+ * empty_zero_page is a special page that is used for</span>
<span class="p_add">+ * zero-initialized data and COW.</span>
<span class="p_add">+ */</span>
<span class="p_add">+struct page *empty_zero_page;</span>
<span class="p_add">+</span>
<span class="p_add">+static void __init zone_sizes_init(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long zones_size[MAX_NR_ZONES];</span>
<span class="p_add">+</span>
<span class="p_add">+	/* Clear the zone sizes */</span>
<span class="p_add">+	memset(zones_size, 0, sizeof(zones_size));</span>
<span class="p_add">+</span>
<span class="p_add">+	zones_size[ZONE_NORMAL] = max_low_pfn;</span>
<span class="p_add">+#ifdef CONFIG_HIGHMEM</span>
<span class="p_add">+	zones_size[ZONE_HIGHMEM] = max_pfn;</span>
<span class="p_add">+#endif</span>
<span class="p_add">+	free_area_init(zones_size);</span>
<span class="p_add">+</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+/*</span>
<span class="p_add">+ * Map all physical memory under high_memory into kernel&#39;s address space.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * This is explicitly coded for two-level page tables, so if you need</span>
<span class="p_add">+ * something else then this needs to change.</span>
<span class="p_add">+ */</span>
<span class="p_add">+static void __init map_ram(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long v, p, e;</span>
<span class="p_add">+	pgd_t *pge;</span>
<span class="p_add">+	pud_t *pue;</span>
<span class="p_add">+	pmd_t *pme;</span>
<span class="p_add">+	pte_t *pte;</span>
<span class="p_add">+	/* These mark extents of read-only kernel pages...</span>
<span class="p_add">+	 * ...from vmlinux.lds.S</span>
<span class="p_add">+	 */</span>
<span class="p_add">+</span>
<span class="p_add">+	p = (u32) memblock_start_of_DRAM() &amp; PAGE_MASK;</span>
<span class="p_add">+	e = min((u32) memblock_end_of_DRAM(), (u32) __pa(high_memory));</span>
<span class="p_add">+</span>
<span class="p_add">+	v = (u32) __va(p);</span>
<span class="p_add">+	pge = pgd_offset_k(v);</span>
<span class="p_add">+</span>
<span class="p_add">+	while (p &lt; e) {</span>
<span class="p_add">+		int j;</span>
<span class="p_add">+		pue = pud_offset(pge, v);</span>
<span class="p_add">+		pme = pmd_offset(pue, v);</span>
<span class="p_add">+</span>
<span class="p_add">+		if ((u32) pue != (u32) pge || (u32) pme != (u32) pge) {</span>
<span class="p_add">+			panic(&quot;%s: Kernel hardcoded for &quot;</span>
<span class="p_add">+			      &quot;two-level page tables&quot;, __func__);</span>
<span class="p_add">+		}</span>
<span class="p_add">+</span>
<span class="p_add">+		/* Alloc one page for holding PTE&#39;s... */</span>
<span class="p_add">+		pte = (pte_t *) __va(memblock_alloc(PAGE_SIZE, PAGE_SIZE));</span>
<span class="p_add">+		memset(pte, 0, PAGE_SIZE);</span>
<span class="p_add">+		set_pmd(pme, __pmd(__pa(pte) + _PAGE_KERNEL_TABLE));</span>
<span class="p_add">+</span>
<span class="p_add">+		/* Fill the newly allocated page with PTE&#39;S */</span>
<span class="p_add">+		for (j = 0; p &lt; e &amp;&amp; j &lt; PTRS_PER_PTE;</span>
<span class="p_add">+		     v += PAGE_SIZE, p += PAGE_SIZE, j++, pte++) {</span>
<span class="p_add">+			/* Create mapping between p and v. */</span>
<span class="p_add">+			/* TODO: more fine grant for page access permission */</span>
<span class="p_add">+			set_pte(pte, __pte(p + pgprot_val(PAGE_KERNEL)));</span>
<span class="p_add">+		}</span>
<span class="p_add">+</span>
<span class="p_add">+		pge++;</span>
<span class="p_add">+	}</span>
<span class="p_add">+}</span>
<span class="p_add">+static pmd_t *fixmap_pmd_p;</span>
<span class="p_add">+static void __init fixedrange_init(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long vaddr;</span>
<span class="p_add">+	pgd_t *pgd;</span>
<span class="p_add">+	pud_t *pud;</span>
<span class="p_add">+	pmd_t *pmd;</span>
<span class="p_add">+#ifdef CONFIG_HIGHMEM</span>
<span class="p_add">+	pte_t *pte;</span>
<span class="p_add">+#endif /* CONFIG_HIGHMEM */</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Fixed mappings:</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	vaddr = __fix_to_virt(__end_of_fixed_addresses - 1);</span>
<span class="p_add">+	pgd = swapper_pg_dir + pgd_index(vaddr);</span>
<span class="p_add">+	pud = pud_offset(pgd, vaddr);</span>
<span class="p_add">+	pmd = pmd_offset(pud, vaddr);</span>
<span class="p_add">+	fixmap_pmd_p = (pmd_t *) __va(memblock_alloc(PAGE_SIZE, PAGE_SIZE));</span>
<span class="p_add">+	memset(fixmap_pmd_p, 0, PAGE_SIZE);</span>
<span class="p_add">+	set_pmd(pmd, __pmd(__pa(fixmap_pmd_p) + _PAGE_KERNEL_TABLE));</span>
<span class="p_add">+</span>
<span class="p_add">+#ifdef CONFIG_HIGHMEM</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Permanent kmaps:</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	vaddr = PKMAP_BASE;</span>
<span class="p_add">+</span>
<span class="p_add">+	pgd = swapper_pg_dir + pgd_index(vaddr);</span>
<span class="p_add">+	pud = pud_offset(pgd, vaddr);</span>
<span class="p_add">+	pmd = pmd_offset(pud, vaddr);</span>
<span class="p_add">+	pte = (pte_t *) __va(memblock_alloc(PAGE_SIZE, PAGE_SIZE));</span>
<span class="p_add">+	memset(pte, 0, PAGE_SIZE);</span>
<span class="p_add">+	set_pmd(pmd, __pmd(__pa(pte) + _PAGE_KERNEL_TABLE));</span>
<span class="p_add">+	pkmap_page_table = pte;</span>
<span class="p_add">+#endif /* CONFIG_HIGHMEM */</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+/*</span>
<span class="p_add">+ * paging_init() sets up the page tables, initialises the zone memory</span>
<span class="p_add">+ * maps, and sets up the zero page, bad page and bad page tables.</span>
<span class="p_add">+ */</span>
<span class="p_add">+void __init paging_init(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	int i;</span>
<span class="p_add">+	void *zero_page;</span>
<span class="p_add">+</span>
<span class="p_add">+	pr_info(&quot;Setting up paging and PTEs.\n&quot;);</span>
<span class="p_add">+	/* clear out the init_mm.pgd that will contain the kernel&#39;s mappings */</span>
<span class="p_add">+	for (i = 0; i &lt; PTRS_PER_PGD; i++)</span>
<span class="p_add">+		swapper_pg_dir[i] = __pgd(1);</span>
<span class="p_add">+</span>
<span class="p_add">+	map_ram();</span>
<span class="p_add">+</span>
<span class="p_add">+	fixedrange_init();</span>
<span class="p_add">+</span>
<span class="p_add">+	/* allocate space for empty_zero_page */</span>
<span class="p_add">+	zero_page = __va(memblock_alloc(PAGE_SIZE, PAGE_SIZE));</span>
<span class="p_add">+	memset(zero_page, 0, PAGE_SIZE);</span>
<span class="p_add">+	zone_sizes_init();</span>
<span class="p_add">+</span>
<span class="p_add">+	empty_zero_page = virt_to_page(zero_page);</span>
<span class="p_add">+	flush_dcache_page(empty_zero_page);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline void __init free_highmem(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+#ifdef CONFIG_HIGHMEM</span>
<span class="p_add">+	unsigned long pfn;</span>
<span class="p_add">+	for (pfn = PFN_UP(__pa(high_memory)); pfn &lt; max_pfn; pfn++) {</span>
<span class="p_add">+		phys_addr_t paddr = (phys_addr_t) pfn &lt;&lt; PAGE_SHIFT;</span>
<span class="p_add">+		if (!memblock_is_reserved(paddr))</span>
<span class="p_add">+			free_highmem_page(pfn_to_page(pfn));</span>
<span class="p_add">+	}</span>
<span class="p_add">+#endif</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static void __init set_max_mapnr_init(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	max_mapnr = max_pfn;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+/*</span>
<span class="p_add">+ * mem_init() marks the free areas in the mem_map and tells us how much</span>
<span class="p_add">+ * memory is free.  This is done after various parts of the system have</span>
<span class="p_add">+ * claimed their memory after the kernel image.</span>
<span class="p_add">+ */</span>
<span class="p_add">+void __init mem_init(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	phys_addr_t memory_start = memblock_start_of_DRAM();</span>
<span class="p_add">+	BUG_ON(!mem_map);</span>
<span class="p_add">+	set_max_mapnr_init();</span>
<span class="p_add">+</span>
<span class="p_add">+	free_highmem();</span>
<span class="p_add">+</span>
<span class="p_add">+	/* this will put all low memory onto the freelists */</span>
<span class="p_add">+	free_all_bootmem();</span>
<span class="p_add">+	mem_init_print_info(NULL);</span>
<span class="p_add">+</span>
<span class="p_add">+	pr_info(&quot;virtual kernel memory layout:\n&quot;</span>
<span class="p_add">+		&quot;    fixmap  : 0x%08lx - 0x%08lx   (%4ld kB)\n&quot;</span>
<span class="p_add">+#ifdef CONFIG_HIGHMEM</span>
<span class="p_add">+		&quot;    pkmap   : 0x%08lx - 0x%08lx   (%4ld kB)\n&quot;</span>
<span class="p_add">+#endif</span>
<span class="p_add">+		&quot;    consist : 0x%08lx - 0x%08lx   (%4ld MB)\n&quot;</span>
<span class="p_add">+		&quot;    vmalloc : 0x%08lx - 0x%08lx   (%4ld MB)\n&quot;</span>
<span class="p_add">+		&quot;    lowmem  : 0x%08lx - 0x%08lx   (%4ld MB)\n&quot;</span>
<span class="p_add">+		&quot;      .init : 0x%08lx - 0x%08lx   (%4ld kB)\n&quot;</span>
<span class="p_add">+		&quot;      .data : 0x%08lx - 0x%08lx   (%4ld kB)\n&quot;</span>
<span class="p_add">+		&quot;      .text : 0x%08lx - 0x%08lx   (%4ld kB)\n&quot;,</span>
<span class="p_add">+		FIXADDR_START, FIXADDR_TOP, (FIXADDR_TOP - FIXADDR_START) &gt;&gt; 10,</span>
<span class="p_add">+#ifdef CONFIG_HIGHMEM</span>
<span class="p_add">+		PKMAP_BASE, PKMAP_BASE + LAST_PKMAP * PAGE_SIZE,</span>
<span class="p_add">+		(LAST_PKMAP * PAGE_SIZE) &gt;&gt; 10,</span>
<span class="p_add">+#endif</span>
<span class="p_add">+		CONSISTENT_BASE, CONSISTENT_END,</span>
<span class="p_add">+		((CONSISTENT_END) - (CONSISTENT_BASE)) &gt;&gt; 20, VMALLOC_START,</span>
<span class="p_add">+		(unsigned long)VMALLOC_END, (VMALLOC_END - VMALLOC_START) &gt;&gt; 20,</span>
<span class="p_add">+		(unsigned long)__va(memory_start), (unsigned long)high_memory,</span>
<span class="p_add">+		((unsigned long)high_memory -</span>
<span class="p_add">+		 (unsigned long)__va(memory_start)) &gt;&gt; 20,</span>
<span class="p_add">+		(unsigned long)&amp;__init_begin, (unsigned long)&amp;__init_end,</span>
<span class="p_add">+		((unsigned long)&amp;__init_end -</span>
<span class="p_add">+		 (unsigned long)&amp;__init_begin) &gt;&gt; 10, (unsigned long)&amp;_etext,</span>
<span class="p_add">+		(unsigned long)&amp;_edata,</span>
<span class="p_add">+		((unsigned long)&amp;_edata - (unsigned long)&amp;_etext) &gt;&gt; 10,</span>
<span class="p_add">+		(unsigned long)&amp;_text, (unsigned long)&amp;_etext,</span>
<span class="p_add">+		((unsigned long)&amp;_etext - (unsigned long)&amp;_text) &gt;&gt; 10);</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Check boundaries twice: Some fundamental inconsistencies can</span>
<span class="p_add">+	 * be detected at build time already.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+#ifdef CONFIG_HIGHMEM</span>
<span class="p_add">+	BUILD_BUG_ON(PKMAP_BASE + LAST_PKMAP * PAGE_SIZE &gt; FIXADDR_START);</span>
<span class="p_add">+	BUILD_BUG_ON((CONSISTENT_END) &gt; PKMAP_BASE);</span>
<span class="p_add">+#endif</span>
<span class="p_add">+	BUILD_BUG_ON(VMALLOC_END &gt; CONSISTENT_BASE);</span>
<span class="p_add">+	BUILD_BUG_ON(VMALLOC_START &gt;= VMALLOC_END);</span>
<span class="p_add">+</span>
<span class="p_add">+#ifdef CONFIG_HIGHMEM</span>
<span class="p_add">+	BUG_ON(PKMAP_BASE + LAST_PKMAP * PAGE_SIZE &gt; FIXADDR_START);</span>
<span class="p_add">+	BUG_ON(CONSISTENT_END &gt; PKMAP_BASE);</span>
<span class="p_add">+#endif</span>
<span class="p_add">+	BUG_ON(VMALLOC_END &gt; CONSISTENT_BASE);</span>
<span class="p_add">+	BUG_ON(VMALLOC_START &gt;= VMALLOC_END);</span>
<span class="p_add">+	BUG_ON((unsigned long)high_memory &gt; VMALLOC_START);</span>
<span class="p_add">+</span>
<span class="p_add">+	return;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void free_initmem(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	free_initmem_default(-1);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+#ifdef CONFIG_BLK_DEV_INITRD</span>
<span class="p_add">+void free_initrd_mem(unsigned long start, unsigned long end)</span>
<span class="p_add">+{</span>
<span class="p_add">+	free_reserved_area((void *)start, (void *)end, -1, &quot;initrd&quot;);</span>
<span class="p_add">+}</span>
<span class="p_add">+#endif</span>
<span class="p_add">+</span>
<span class="p_add">+void __set_fixmap(enum fixed_addresses idx,</span>
<span class="p_add">+			       phys_addr_t phys, pgprot_t flags)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long addr = __fix_to_virt(idx);</span>
<span class="p_add">+	pte_t *pte;</span>
<span class="p_add">+</span>
<span class="p_add">+	BUG_ON(idx &lt;= FIX_HOLE || idx &gt;= __end_of_fixed_addresses);</span>
<span class="p_add">+</span>
<span class="p_add">+	pte = (pte_t *)&amp;fixmap_pmd_p[pte_index(addr)];;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (pgprot_val(flags)) {</span>
<span class="p_add">+		set_pte(pte, pfn_pte(phys &gt;&gt; PAGE_SHIFT, flags));</span>
<span class="p_add">+	} else {</span>
<span class="p_add">+		pte_clear(&amp;init_mm, addr, pte);</span>
<span class="p_add">+		flush_tlb_kernel_range(addr, addr + PAGE_SIZE);</span>
<span class="p_add">+	}</span>
<span class="p_add">+}</span>
<span class="p_header">diff --git a/arch/nds32/mm/mm-nds32.c b/arch/nds32/mm/mm-nds32.c</span>
new file mode 100644
<span class="p_header">index 0000000..2801496</span>
<span class="p_header">--- /dev/null</span>
<span class="p_header">+++ b/arch/nds32/mm/mm-nds32.c</span>
<span class="p_chunk">@@ -0,0 +1,103 @@</span> <span class="p_context"></span>
<span class="p_add">+/*</span>
<span class="p_add">+ * Copyright (C) 2005-2017 Andes Technology Corporation</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * This program is free software; you can redistribute it and/or modify</span>
<span class="p_add">+ * it under the terms of the GNU General Public License version 2 as</span>
<span class="p_add">+ * published by the Free Software Foundation.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * This program is distributed in the hope that it will be useful,</span>
<span class="p_add">+ * but WITHOUT ANY WARRANTY; without even the implied warranty of</span>
<span class="p_add">+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the</span>
<span class="p_add">+ * GNU General Public License for more details.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * You should have received a copy of the GNU General Public License</span>
<span class="p_add">+ * along with this program.  If not, see &lt;http://www.gnu.org/licenses/&gt;.</span>
<span class="p_add">+ */</span>
<span class="p_add">+</span>
<span class="p_add">+#include &lt;linux/init_task.h&gt;</span>
<span class="p_add">+#include &lt;asm/pgalloc.h&gt;</span>
<span class="p_add">+</span>
<span class="p_add">+#define FIRST_KERNEL_PGD_NR	(USER_PTRS_PER_PGD)</span>
<span class="p_add">+</span>
<span class="p_add">+/*</span>
<span class="p_add">+ * need to get a page for level 1</span>
<span class="p_add">+ */</span>
<span class="p_add">+</span>
<span class="p_add">+pgd_t *pgd_alloc(struct mm_struct *mm)</span>
<span class="p_add">+{</span>
<span class="p_add">+	pgd_t *new_pgd, *init_pgd;</span>
<span class="p_add">+	int i;</span>
<span class="p_add">+</span>
<span class="p_add">+	new_pgd = (pgd_t *) __get_free_pages(GFP_KERNEL, 0);</span>
<span class="p_add">+	if (!new_pgd)</span>
<span class="p_add">+		return NULL;</span>
<span class="p_add">+	for (i = 0; i &lt; PTRS_PER_PGD; i++) {</span>
<span class="p_add">+		(*new_pgd) = 1;</span>
<span class="p_add">+		new_pgd++;</span>
<span class="p_add">+	}</span>
<span class="p_add">+	new_pgd -= PTRS_PER_PGD;</span>
<span class="p_add">+</span>
<span class="p_add">+	init_pgd = pgd_offset_k(0);</span>
<span class="p_add">+</span>
<span class="p_add">+	memcpy(new_pgd + FIRST_KERNEL_PGD_NR, init_pgd + FIRST_KERNEL_PGD_NR,</span>
<span class="p_add">+	       (PTRS_PER_PGD - FIRST_KERNEL_PGD_NR) * sizeof(pgd_t));</span>
<span class="p_add">+</span>
<span class="p_add">+	cpu_dcache_wb_range((unsigned long)new_pgd,</span>
<span class="p_add">+			    (unsigned long)new_pgd +</span>
<span class="p_add">+			    PTRS_PER_PGD * sizeof(pgd_t));</span>
<span class="p_add">+	inc_zone_page_state(virt_to_page((unsigned long *)new_pgd),</span>
<span class="p_add">+			    NR_PAGETABLE);</span>
<span class="p_add">+</span>
<span class="p_add">+	return new_pgd;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void pgd_free(struct mm_struct *mm, pgd_t * pgd)</span>
<span class="p_add">+{</span>
<span class="p_add">+	pmd_t *pmd;</span>
<span class="p_add">+	struct page *pte;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (!pgd)</span>
<span class="p_add">+		return;</span>
<span class="p_add">+</span>
<span class="p_add">+	pmd = (pmd_t *) pgd;</span>
<span class="p_add">+	if (pmd_none(*pmd))</span>
<span class="p_add">+		goto free;</span>
<span class="p_add">+	if (pmd_bad(*pmd)) {</span>
<span class="p_add">+		pmd_ERROR(*pmd);</span>
<span class="p_add">+		pmd_clear(pmd);</span>
<span class="p_add">+		goto free;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	pte = pmd_page(*pmd);</span>
<span class="p_add">+	pmd_clear(pmd);</span>
<span class="p_add">+	dec_zone_page_state(virt_to_page((unsigned long *)pgd), NR_PAGETABLE);</span>
<span class="p_add">+	pte_free(mm, pte);</span>
<span class="p_add">+	atomic_long_dec(&amp;mm-&gt;nr_ptes);</span>
<span class="p_add">+	pmd_free(mm, pmd);</span>
<span class="p_add">+free:</span>
<span class="p_add">+	free_pages((unsigned long)pgd, 0);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+/*</span>
<span class="p_add">+ * In order to soft-boot, we need to insert a 1:1 mapping in place of</span>
<span class="p_add">+ * the user-mode pages.  This will then ensure that we have predictable</span>
<span class="p_add">+ * results when turning the mmu off</span>
<span class="p_add">+ */</span>
<span class="p_add">+void setup_mm_for_reboot(char mode)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long pmdval;</span>
<span class="p_add">+	pgd_t *pgd;</span>
<span class="p_add">+	pmd_t *pmd;</span>
<span class="p_add">+	int i;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (current-&gt;mm &amp;&amp; current-&gt;mm-&gt;pgd)</span>
<span class="p_add">+		pgd = current-&gt;mm-&gt;pgd;</span>
<span class="p_add">+	else</span>
<span class="p_add">+		pgd = init_mm.pgd;</span>
<span class="p_add">+</span>
<span class="p_add">+	for (i = 0; i &lt; USER_PTRS_PER_PGD; i++) {</span>
<span class="p_add">+		pmdval = (i &lt;&lt; PGDIR_SHIFT);</span>
<span class="p_add">+		pmd = pmd_offset(pgd + i, i &lt;&lt; PGDIR_SHIFT);</span>
<span class="p_add">+		set_pmd(pmd, __pmd(pmdval));</span>
<span class="p_add">+	}</span>
<span class="p_add">+}</span>

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



