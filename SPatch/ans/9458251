
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>Linux 4.8.12 - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    Linux 4.8.12</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=37061">gregkh@linuxfoundation.org</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>Dec. 2, 2016, 11:19 a.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;20161202111942.GB11970@kroah.com&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/9458251/mbox/"
   >mbox</a>
|
   <a href="/patch/9458251/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/9458251/">/patch/9458251/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
	[172.30.200.125])
	by pdx-korg-patchwork.web.codeaurora.org (Postfix) with ESMTP id
	E6B3D60515 for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Fri,  2 Dec 2016 11:19:48 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id D1C92284F0
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Fri,  2 Dec 2016 11:19:48 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id BD8DC28533; Fri,  2 Dec 2016 11:19:48 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-6.9 required=2.0 tests=BAYES_00,RCVD_IN_DNSWL_HI
	autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 1BCF52852E
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Fri,  2 Dec 2016 11:19:46 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1760285AbcLBLTl (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Fri, 2 Dec 2016 06:19:41 -0500
Received: from mail.linuxfoundation.org ([140.211.169.12]:46716 &quot;EHLO
	mail.linuxfoundation.org&quot; rhost-flags-OK-OK-OK-OK) by vger.kernel.org
	with ESMTP id S1758753AbcLBLTg (ORCPT
	&lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Fri, 2 Dec 2016 06:19:36 -0500
Received: from localhost (unknown [37.166.252.87])
	by mail.linuxfoundation.org (Postfix) with ESMTPSA id E15E29C;
	Fri,  2 Dec 2016 11:19:33 +0000 (UTC)
Date: Fri, 2 Dec 2016 12:19:42 +0100
From: Greg KH &lt;gregkh@linuxfoundation.org&gt;
To: linux-kernel@vger.kernel.org, Andrew Morton &lt;akpm@linux-foundation.org&gt;,
	torvalds@linux-foundation.org, stable@vger.kernel.org
Cc: lwn@lwn.net, Jiri Slaby &lt;jslaby@suse.cz&gt;
Subject: Re: Linux 4.8.12
Message-ID: &lt;20161202111942.GB11970@kroah.com&gt;
References: &lt;20161202111937.GA11970@kroah.com&gt;
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Disposition: inline
In-Reply-To: &lt;20161202111937.GA11970@kroah.com&gt;
User-Agent: Mutt/1.7.1 (2016-10-04)
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=37061">gregkh@linuxfoundation.org</a> - Dec. 2, 2016, 11:19 a.m.</div>
<pre class="content">

</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/Makefile b/Makefile</span>
<span class="p_header">index 2b1bcbacebcd..7b0c92f53169 100644</span>
<span class="p_header">--- a/Makefile</span>
<span class="p_header">+++ b/Makefile</span>
<span class="p_chunk">@@ -1,6 +1,6 @@</span> <span class="p_context"></span>
 VERSION = 4
 PATCHLEVEL = 8
<span class="p_del">-SUBLEVEL = 11</span>
<span class="p_add">+SUBLEVEL = 12</span>
 EXTRAVERSION =
 NAME = Psychotic Stoned Sheep
 
<span class="p_header">diff --git a/arch/parisc/Kconfig b/arch/parisc/Kconfig</span>
<span class="p_header">index af12c2db9bb8..81c11a62b1fa 100644</span>
<span class="p_header">--- a/arch/parisc/Kconfig</span>
<span class="p_header">+++ b/arch/parisc/Kconfig</span>
<span class="p_chunk">@@ -33,7 +33,9 @@</span> <span class="p_context"> config PARISC</span>
 	select HAVE_ARCH_HASH
 	select HAVE_ARCH_SECCOMP_FILTER
 	select HAVE_ARCH_TRACEHOOK
<span class="p_del">-	select HAVE_UNSTABLE_SCHED_CLOCK if (SMP || !64BIT)</span>
<span class="p_add">+	select GENERIC_SCHED_CLOCK</span>
<span class="p_add">+	select HAVE_UNSTABLE_SCHED_CLOCK if SMP</span>
<span class="p_add">+	select GENERIC_CLOCKEVENTS</span>
 	select ARCH_NO_COHERENT_DMA_MMAP
 	select CPU_NO_EFFICIENT_FFS
 
<span class="p_header">diff --git a/arch/parisc/kernel/cache.c b/arch/parisc/kernel/cache.c</span>
<span class="p_header">index 67001277256c..c2259d4a3c33 100644</span>
<span class="p_header">--- a/arch/parisc/kernel/cache.c</span>
<span class="p_header">+++ b/arch/parisc/kernel/cache.c</span>
<span class="p_chunk">@@ -369,6 +369,7 @@</span> <span class="p_context"> void __init parisc_setup_cache_timing(void)</span>
 {
 	unsigned long rangetime, alltime;
 	unsigned long size, start;
<span class="p_add">+	unsigned long threshold;</span>
 
 	alltime = mfctl(16);
 	flush_data_cache();
<span class="p_chunk">@@ -382,17 +383,12 @@</span> <span class="p_context"> void __init parisc_setup_cache_timing(void)</span>
 	printk(KERN_DEBUG &quot;Whole cache flush %lu cycles, flushing %lu bytes %lu cycles\n&quot;,
 		alltime, size, rangetime);
 
<span class="p_del">-	/* Racy, but if we see an intermediate value, it&#39;s ok too... */</span>
<span class="p_del">-	parisc_cache_flush_threshold = size * alltime / rangetime;</span>
<span class="p_del">-</span>
<span class="p_del">-	parisc_cache_flush_threshold = L1_CACHE_ALIGN(parisc_cache_flush_threshold);</span>
<span class="p_del">-	if (!parisc_cache_flush_threshold)</span>
<span class="p_del">-		parisc_cache_flush_threshold = FLUSH_THRESHOLD;</span>
<span class="p_del">-</span>
<span class="p_del">-	if (parisc_cache_flush_threshold &gt; cache_info.dc_size)</span>
<span class="p_del">-		parisc_cache_flush_threshold = cache_info.dc_size;</span>
<span class="p_del">-</span>
<span class="p_del">-	printk(KERN_INFO &quot;Setting cache flush threshold to %lu kB\n&quot;,</span>
<span class="p_add">+	threshold = L1_CACHE_ALIGN(size * alltime / rangetime);</span>
<span class="p_add">+	if (threshold &gt; cache_info.dc_size)</span>
<span class="p_add">+		threshold = cache_info.dc_size;</span>
<span class="p_add">+	if (threshold)</span>
<span class="p_add">+		parisc_cache_flush_threshold = threshold;</span>
<span class="p_add">+	printk(KERN_INFO &quot;Cache flush threshold set to %lu KiB\n&quot;,</span>
 		parisc_cache_flush_threshold/1024);
 
 	/* calculate TLB flush threshold */
<span class="p_chunk">@@ -401,7 +397,7 @@</span> <span class="p_context"> void __init parisc_setup_cache_timing(void)</span>
 	flush_tlb_all();
 	alltime = mfctl(16) - alltime;
 
<span class="p_del">-	size = PAGE_SIZE;</span>
<span class="p_add">+	size = 0;</span>
 	start = (unsigned long) _text;
 	rangetime = mfctl(16);
 	while (start &lt; (unsigned long) _end) {
<span class="p_chunk">@@ -414,13 +410,10 @@</span> <span class="p_context"> void __init parisc_setup_cache_timing(void)</span>
 	printk(KERN_DEBUG &quot;Whole TLB flush %lu cycles, flushing %lu bytes %lu cycles\n&quot;,
 		alltime, size, rangetime);
 
<span class="p_del">-	parisc_tlb_flush_threshold = size * alltime / rangetime;</span>
<span class="p_del">-	parisc_tlb_flush_threshold *= num_online_cpus();</span>
<span class="p_del">-	parisc_tlb_flush_threshold = PAGE_ALIGN(parisc_tlb_flush_threshold);</span>
<span class="p_del">-	if (!parisc_tlb_flush_threshold)</span>
<span class="p_del">-		parisc_tlb_flush_threshold = FLUSH_TLB_THRESHOLD;</span>
<span class="p_del">-</span>
<span class="p_del">-	printk(KERN_INFO &quot;Setting TLB flush threshold to %lu kB\n&quot;,</span>
<span class="p_add">+	threshold = PAGE_ALIGN(num_online_cpus() * size * alltime / rangetime);</span>
<span class="p_add">+	if (threshold)</span>
<span class="p_add">+		parisc_tlb_flush_threshold = threshold;</span>
<span class="p_add">+	printk(KERN_INFO &quot;TLB flush threshold set to %lu KiB\n&quot;,</span>
 		parisc_tlb_flush_threshold/1024);
 }
 
<span class="p_header">diff --git a/arch/parisc/kernel/pacache.S b/arch/parisc/kernel/pacache.S</span>
<span class="p_header">index b743a80eaba0..675521919229 100644</span>
<span class="p_header">--- a/arch/parisc/kernel/pacache.S</span>
<span class="p_header">+++ b/arch/parisc/kernel/pacache.S</span>
<span class="p_chunk">@@ -96,7 +96,7 @@</span> <span class="p_context"> fitmanyloop:					/* Loop if LOOP &gt;= 2 */</span>
 
 fitmanymiddle:					/* Loop if LOOP &gt;= 2 */
 	addib,COND(&gt;)		-1, %r31, fitmanymiddle	/* Adjusted inner loop decr */
<span class="p_del">-	pitlbe		0(%sr1, %r28)</span>
<span class="p_add">+	pitlbe		%r0(%sr1, %r28)</span>
 	pitlbe,m	%arg1(%sr1, %r28)	/* Last pitlbe and addr adjust */
 	addib,COND(&gt;)		-1, %r29, fitmanymiddle	/* Middle loop decr */
 	copy		%arg3, %r31		/* Re-init inner loop count */
<span class="p_chunk">@@ -139,7 +139,7 @@</span> <span class="p_context"> fdtmanyloop:					/* Loop if LOOP &gt;= 2 */</span>
 
 fdtmanymiddle:					/* Loop if LOOP &gt;= 2 */
 	addib,COND(&gt;)		-1, %r31, fdtmanymiddle	/* Adjusted inner loop decr */
<span class="p_del">-	pdtlbe		0(%sr1, %r28)</span>
<span class="p_add">+	pdtlbe		%r0(%sr1, %r28)</span>
 	pdtlbe,m	%arg1(%sr1, %r28)	/* Last pdtlbe and addr adjust */
 	addib,COND(&gt;)		-1, %r29, fdtmanymiddle	/* Middle loop decr */
 	copy		%arg3, %r31		/* Re-init inner loop count */
<span class="p_chunk">@@ -620,12 +620,12 @@</span> <span class="p_context"> ENTRY(copy_user_page_asm)</span>
 	/* Purge any old translations */
 
 #ifdef CONFIG_PA20
<span class="p_del">-	pdtlb,l		0(%r28)</span>
<span class="p_del">-	pdtlb,l		0(%r29)</span>
<span class="p_add">+	pdtlb,l		%r0(%r28)</span>
<span class="p_add">+	pdtlb,l		%r0(%r29)</span>
 #else
 	tlb_lock	%r20,%r21,%r22
<span class="p_del">-	pdtlb		0(%r28)</span>
<span class="p_del">-	pdtlb		0(%r29)</span>
<span class="p_add">+	pdtlb		%r0(%r28)</span>
<span class="p_add">+	pdtlb		%r0(%r29)</span>
 	tlb_unlock	%r20,%r21,%r22
 #endif
 
<span class="p_chunk">@@ -768,10 +768,10 @@</span> <span class="p_context"> ENTRY(clear_user_page_asm)</span>
 	/* Purge any old translation */
 
 #ifdef CONFIG_PA20
<span class="p_del">-	pdtlb,l		0(%r28)</span>
<span class="p_add">+	pdtlb,l		%r0(%r28)</span>
 #else
 	tlb_lock	%r20,%r21,%r22
<span class="p_del">-	pdtlb		0(%r28)</span>
<span class="p_add">+	pdtlb		%r0(%r28)</span>
 	tlb_unlock	%r20,%r21,%r22
 #endif
 
<span class="p_chunk">@@ -852,10 +852,10 @@</span> <span class="p_context"> ENTRY(flush_dcache_page_asm)</span>
 	/* Purge any old translation */
 
 #ifdef CONFIG_PA20
<span class="p_del">-	pdtlb,l		0(%r28)</span>
<span class="p_add">+	pdtlb,l		%r0(%r28)</span>
 #else
 	tlb_lock	%r20,%r21,%r22
<span class="p_del">-	pdtlb		0(%r28)</span>
<span class="p_add">+	pdtlb		%r0(%r28)</span>
 	tlb_unlock	%r20,%r21,%r22
 #endif
 
<span class="p_chunk">@@ -892,10 +892,10 @@</span> <span class="p_context"> ENTRY(flush_dcache_page_asm)</span>
 	sync
 
 #ifdef CONFIG_PA20
<span class="p_del">-	pdtlb,l		0(%r25)</span>
<span class="p_add">+	pdtlb,l		%r0(%r25)</span>
 #else
 	tlb_lock	%r20,%r21,%r22
<span class="p_del">-	pdtlb		0(%r25)</span>
<span class="p_add">+	pdtlb		%r0(%r25)</span>
 	tlb_unlock	%r20,%r21,%r22
 #endif
 
<span class="p_chunk">@@ -925,13 +925,18 @@</span> <span class="p_context"> ENTRY(flush_icache_page_asm)</span>
 	depwi		0, 31,PAGE_SHIFT, %r28	/* Clear any offset bits */
 #endif
 
<span class="p_del">-	/* Purge any old translation */</span>
<span class="p_add">+	/* Purge any old translation.  Note that the FIC instruction</span>
<span class="p_add">+	 * may use either the instruction or data TLB.  Given that we</span>
<span class="p_add">+	 * have a flat address space, it&#39;s not clear which TLB will be</span>
<span class="p_add">+	 * used.  So, we purge both entries.  */</span>
 
 #ifdef CONFIG_PA20
<span class="p_add">+	pdtlb,l		%r0(%r28)</span>
 	pitlb,l         %r0(%sr4,%r28)
 #else
 	tlb_lock        %r20,%r21,%r22
<span class="p_del">-	pitlb           (%sr4,%r28)</span>
<span class="p_add">+	pdtlb		%r0(%r28)</span>
<span class="p_add">+	pitlb           %r0(%sr4,%r28)</span>
 	tlb_unlock      %r20,%r21,%r22
 #endif
 
<span class="p_chunk">@@ -970,10 +975,12 @@</span> <span class="p_context"> ENTRY(flush_icache_page_asm)</span>
 	sync
 
 #ifdef CONFIG_PA20
<span class="p_add">+	pdtlb,l		%r0(%r28)</span>
 	pitlb,l         %r0(%sr4,%r25)
 #else
 	tlb_lock        %r20,%r21,%r22
<span class="p_del">-	pitlb           (%sr4,%r25)</span>
<span class="p_add">+	pdtlb		%r0(%r28)</span>
<span class="p_add">+	pitlb           %r0(%sr4,%r25)</span>
 	tlb_unlock      %r20,%r21,%r22
 #endif
 
<span class="p_header">diff --git a/arch/parisc/kernel/pci-dma.c b/arch/parisc/kernel/pci-dma.c</span>
<span class="p_header">index 02d9ed0f3949..494ff6e8c88a 100644</span>
<span class="p_header">--- a/arch/parisc/kernel/pci-dma.c</span>
<span class="p_header">+++ b/arch/parisc/kernel/pci-dma.c</span>
<span class="p_chunk">@@ -95,8 +95,8 @@</span> <span class="p_context"> static inline int map_pte_uncached(pte_t * pte,</span>
 
 		if (!pte_none(*pte))
 			printk(KERN_ERR &quot;map_pte_uncached: page already exists\n&quot;);
<span class="p_del">-		set_pte(pte, __mk_pte(*paddr_ptr, PAGE_KERNEL_UNC));</span>
 		purge_tlb_start(flags);
<span class="p_add">+		set_pte(pte, __mk_pte(*paddr_ptr, PAGE_KERNEL_UNC));</span>
 		pdtlb_kernel(orig_vaddr);
 		purge_tlb_end(flags);
 		vaddr += PAGE_SIZE;
<span class="p_header">diff --git a/arch/parisc/kernel/setup.c b/arch/parisc/kernel/setup.c</span>
<span class="p_header">index 81d6f6391944..2e66a887788e 100644</span>
<span class="p_header">--- a/arch/parisc/kernel/setup.c</span>
<span class="p_header">+++ b/arch/parisc/kernel/setup.c</span>
<span class="p_chunk">@@ -334,6 +334,10 @@</span> <span class="p_context"> static int __init parisc_init(void)</span>
 	/* tell PDC we&#39;re Linux. Nevermind failure. */
 	pdc_stable_write(0x40, &amp;osid, sizeof(osid));
 	
<span class="p_add">+	/* start with known state */</span>
<span class="p_add">+	flush_cache_all_local();</span>
<span class="p_add">+	flush_tlb_all_local(NULL);</span>
<span class="p_add">+</span>
 	processor_init();
 #ifdef CONFIG_SMP
 	pr_info(&quot;CPU(s): %d out of %d %s at %d.%06d MHz online\n&quot;,
<span class="p_header">diff --git a/arch/parisc/kernel/time.c b/arch/parisc/kernel/time.c</span>
<span class="p_header">index 9b63b876a13a..325f30d82b64 100644</span>
<span class="p_header">--- a/arch/parisc/kernel/time.c</span>
<span class="p_header">+++ b/arch/parisc/kernel/time.c</span>
<span class="p_chunk">@@ -14,6 +14,7 @@</span> <span class="p_context"></span>
 #include &lt;linux/module.h&gt;
 #include &lt;linux/rtc.h&gt;
 #include &lt;linux/sched.h&gt;
<span class="p_add">+#include &lt;linux/sched_clock.h&gt;</span>
 #include &lt;linux/kernel.h&gt;
 #include &lt;linux/param.h&gt;
 #include &lt;linux/string.h&gt;
<span class="p_chunk">@@ -39,18 +40,6 @@</span> <span class="p_context"></span>
 
 static unsigned long clocktick __read_mostly;	/* timer cycles per tick */
 
<span class="p_del">-#ifndef CONFIG_64BIT</span>
<span class="p_del">-/*</span>
<span class="p_del">- * The processor-internal cycle counter (Control Register 16) is used as time</span>
<span class="p_del">- * source for the sched_clock() function.  This register is 64bit wide on a</span>
<span class="p_del">- * 64-bit kernel and 32bit on a 32-bit kernel. Since sched_clock() always</span>
<span class="p_del">- * requires a 64bit counter we emulate on the 32-bit kernel the higher 32bits</span>
<span class="p_del">- * with a per-cpu variable which we increase every time the counter</span>
<span class="p_del">- * wraps-around (which happens every ~4 secounds).</span>
<span class="p_del">- */</span>
<span class="p_del">-static DEFINE_PER_CPU(unsigned long, cr16_high_32_bits);</span>
<span class="p_del">-#endif</span>
<span class="p_del">-</span>
 /*
  * We keep time on PA-RISC Linux by using the Interval Timer which is
  * a pair of registers; one is read-only and one is write-only; both
<span class="p_chunk">@@ -121,12 +110,6 @@</span> <span class="p_context"> irqreturn_t __irq_entry timer_interrupt(int irq, void *dev_id)</span>
 	 */
 	mtctl(next_tick, 16);
 
<span class="p_del">-#if !defined(CONFIG_64BIT)</span>
<span class="p_del">-	/* check for overflow on a 32bit kernel (every ~4 seconds). */</span>
<span class="p_del">-	if (unlikely(next_tick &lt; now))</span>
<span class="p_del">-		this_cpu_inc(cr16_high_32_bits);</span>
<span class="p_del">-#endif</span>
<span class="p_del">-</span>
 	/* Skip one clocktick on purpose if we missed next_tick.
 	 * The new CR16 must be &quot;later&quot; than current CR16 otherwise
 	 * itimer would not fire until CR16 wrapped - e.g 4 seconds
<span class="p_chunk">@@ -208,7 +191,7 @@</span> <span class="p_context"> EXPORT_SYMBOL(profile_pc);</span>
 
 /* clock source code */
 
<span class="p_del">-static cycle_t read_cr16(struct clocksource *cs)</span>
<span class="p_add">+static cycle_t notrace read_cr16(struct clocksource *cs)</span>
 {
 	return get_cycles();
 }
<span class="p_chunk">@@ -287,26 +270,9 @@</span> <span class="p_context"> void read_persistent_clock(struct timespec *ts)</span>
 }
 
 
<span class="p_del">-/*</span>
<span class="p_del">- * sched_clock() framework</span>
<span class="p_del">- */</span>
<span class="p_del">-</span>
<span class="p_del">-static u32 cyc2ns_mul __read_mostly;</span>
<span class="p_del">-static u32 cyc2ns_shift __read_mostly;</span>
<span class="p_del">-</span>
<span class="p_del">-u64 sched_clock(void)</span>
<span class="p_add">+static u64 notrace read_cr16_sched_clock(void)</span>
 {
<span class="p_del">-	u64 now;</span>
<span class="p_del">-</span>
<span class="p_del">-	/* Get current cycle counter (Control Register 16). */</span>
<span class="p_del">-#ifdef CONFIG_64BIT</span>
<span class="p_del">-	now = mfctl(16);</span>
<span class="p_del">-#else</span>
<span class="p_del">-	now = mfctl(16) + (((u64) this_cpu_read(cr16_high_32_bits)) &lt;&lt; 32);</span>
<span class="p_del">-#endif</span>
<span class="p_del">-</span>
<span class="p_del">-	/* return the value in ns (cycles_2_ns) */</span>
<span class="p_del">-	return mul_u64_u32_shr(now, cyc2ns_mul, cyc2ns_shift);</span>
<span class="p_add">+	return get_cycles();</span>
 }
 
 
<span class="p_chunk">@@ -316,17 +282,16 @@</span> <span class="p_context"> u64 sched_clock(void)</span>
 
 void __init time_init(void)
 {
<span class="p_del">-	unsigned long current_cr16_khz;</span>
<span class="p_add">+	unsigned long cr16_hz;</span>
 
<span class="p_del">-	current_cr16_khz = PAGE0-&gt;mem_10msec/10;  /* kHz */</span>
 	clocktick = (100 * PAGE0-&gt;mem_10msec) / HZ;
<span class="p_del">-</span>
<span class="p_del">-	/* calculate mult/shift values for cr16 */</span>
<span class="p_del">-	clocks_calc_mult_shift(&amp;cyc2ns_mul, &amp;cyc2ns_shift, current_cr16_khz,</span>
<span class="p_del">-				NSEC_PER_MSEC, 0);</span>
<span class="p_del">-</span>
 	start_cpu_itimer();	/* get CPU 0 started */
 
<span class="p_add">+	cr16_hz = 100 * PAGE0-&gt;mem_10msec;  /* Hz */</span>
<span class="p_add">+</span>
 	/* register at clocksource framework */
<span class="p_del">-	clocksource_register_khz(&amp;clocksource_cr16, current_cr16_khz);</span>
<span class="p_add">+	clocksource_register_hz(&amp;clocksource_cr16, cr16_hz);</span>
<span class="p_add">+</span>
<span class="p_add">+	/* register as sched_clock source */</span>
<span class="p_add">+	sched_clock_register(read_cr16_sched_clock, BITS_PER_LONG, cr16_hz);</span>
 }
<span class="p_header">diff --git a/arch/powerpc/boot/main.c b/arch/powerpc/boot/main.c</span>
<span class="p_header">index d80161b633f4..60522d22a428 100644</span>
<span class="p_header">--- a/arch/powerpc/boot/main.c</span>
<span class="p_header">+++ b/arch/powerpc/boot/main.c</span>
<span class="p_chunk">@@ -217,8 +217,12 @@</span> <span class="p_context"> void start(void)</span>
 		console_ops.close();
 
 	kentry = (kernel_entry_t) vmlinux.addr;
<span class="p_del">-	if (ft_addr)</span>
<span class="p_del">-		kentry(ft_addr, 0, NULL);</span>
<span class="p_add">+	if (ft_addr) {</span>
<span class="p_add">+		if(platform_ops.kentry)</span>
<span class="p_add">+			platform_ops.kentry(ft_addr, vmlinux.addr);</span>
<span class="p_add">+		else</span>
<span class="p_add">+			kentry(ft_addr, 0, NULL);</span>
<span class="p_add">+	}</span>
 	else
 		kentry((unsigned long)initrd.addr, initrd.size,
 		       loader_info.promptr);
<span class="p_header">diff --git a/arch/powerpc/boot/opal-calls.S b/arch/powerpc/boot/opal-calls.S</span>
<span class="p_header">index ff2f1b97bc53..2a99fc9a3ccf 100644</span>
<span class="p_header">--- a/arch/powerpc/boot/opal-calls.S</span>
<span class="p_header">+++ b/arch/powerpc/boot/opal-calls.S</span>
<span class="p_chunk">@@ -12,6 +12,19 @@</span> <span class="p_context"></span>
 
 	.text
 
<span class="p_add">+	.globl opal_kentry</span>
<span class="p_add">+opal_kentry:</span>
<span class="p_add">+	/* r3 is the fdt ptr */</span>
<span class="p_add">+	mtctr r4</span>
<span class="p_add">+	li	r4, 0</span>
<span class="p_add">+	li	r5, 0</span>
<span class="p_add">+	li	r6, 0</span>
<span class="p_add">+	li	r7, 0</span>
<span class="p_add">+	ld	r11,opal@got(r2)</span>
<span class="p_add">+	ld	r8,0(r11)</span>
<span class="p_add">+	ld	r9,8(r11)</span>
<span class="p_add">+	bctr</span>
<span class="p_add">+</span>
 #define OPAL_CALL(name, token)				\
 	.globl name;					\
 name:							\
<span class="p_header">diff --git a/arch/powerpc/boot/opal.c b/arch/powerpc/boot/opal.c</span>
<span class="p_header">index 1f37e1c1d6d8..d7b4fd47eb44 100644</span>
<span class="p_header">--- a/arch/powerpc/boot/opal.c</span>
<span class="p_header">+++ b/arch/powerpc/boot/opal.c</span>
<span class="p_chunk">@@ -23,14 +23,25 @@</span> <span class="p_context"> struct opal {</span>
 
 static u32 opal_con_id;
 
<span class="p_add">+/* see opal-wrappers.S */</span>
 int64_t opal_console_write(int64_t term_number, u64 *length, const u8 *buffer);
 int64_t opal_console_read(int64_t term_number, uint64_t *length, u8 *buffer);
 int64_t opal_console_write_buffer_space(uint64_t term_number, uint64_t *length);
 int64_t opal_console_flush(uint64_t term_number);
 int64_t opal_poll_events(uint64_t *outstanding_event_mask);
 
<span class="p_add">+void opal_kentry(unsigned long fdt_addr, void *vmlinux_addr);</span>
<span class="p_add">+</span>
 static int opal_con_open(void)
 {
<span class="p_add">+	/*</span>
<span class="p_add">+	 * When OPAL loads the boot kernel it stashes the OPAL base and entry</span>
<span class="p_add">+	 * address in r8 and r9 so the kernel can use the OPAL console</span>
<span class="p_add">+	 * before unflattening the devicetree. While executing the wrapper will</span>
<span class="p_add">+	 * probably trash r8 and r9 so this kentry hook restores them before</span>
<span class="p_add">+	 * entering the decompressed kernel.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	platform_ops.kentry = opal_kentry;</span>
 	return 0;
 }
 
<span class="p_header">diff --git a/arch/powerpc/boot/ops.h b/arch/powerpc/boot/ops.h</span>
<span class="p_header">index e19b64ef977a..deeae6f6ba9c 100644</span>
<span class="p_header">--- a/arch/powerpc/boot/ops.h</span>
<span class="p_header">+++ b/arch/powerpc/boot/ops.h</span>
<span class="p_chunk">@@ -30,6 +30,7 @@</span> <span class="p_context"> struct platform_ops {</span>
 	void *	(*realloc)(void *ptr, unsigned long size);
 	void	(*exit)(void);
 	void *	(*vmlinux_alloc)(unsigned long size);
<span class="p_add">+	void  	(*kentry)(unsigned long fdt_addr, void *vmlinux_addr);</span>
 };
 extern struct platform_ops platform_ops;
 
<span class="p_header">diff --git a/arch/powerpc/include/asm/mmu.h b/arch/powerpc/include/asm/mmu.h</span>
<span class="p_header">index e2fb408f8398..fd10b582fb2d 100644</span>
<span class="p_header">--- a/arch/powerpc/include/asm/mmu.h</span>
<span class="p_header">+++ b/arch/powerpc/include/asm/mmu.h</span>
<span class="p_chunk">@@ -29,6 +29,12 @@</span> <span class="p_context"></span>
  */
 
 /*
<span class="p_add">+ * Kernel read only support.</span>
<span class="p_add">+ * We added the ppp value 0b110 in ISA 2.04.</span>
<span class="p_add">+ */</span>
<span class="p_add">+#define MMU_FTR_KERNEL_RO		ASM_CONST(0x00004000)</span>
<span class="p_add">+</span>
<span class="p_add">+/*</span>
  * We need to clear top 16bits of va (from the remaining 64 bits )in
  * tlbie* instructions
  */
<span class="p_chunk">@@ -103,10 +109,10 @@</span> <span class="p_context"></span>
 #define MMU_FTRS_POWER4		MMU_FTRS_DEFAULT_HPTE_ARCH_V2
 #define MMU_FTRS_PPC970		MMU_FTRS_POWER4 | MMU_FTR_TLBIE_CROP_VA
 #define MMU_FTRS_POWER5		MMU_FTRS_POWER4 | MMU_FTR_LOCKLESS_TLBIE
<span class="p_del">-#define MMU_FTRS_POWER6		MMU_FTRS_POWER4 | MMU_FTR_LOCKLESS_TLBIE</span>
<span class="p_del">-#define MMU_FTRS_POWER7		MMU_FTRS_POWER4 | MMU_FTR_LOCKLESS_TLBIE</span>
<span class="p_del">-#define MMU_FTRS_POWER8		MMU_FTRS_POWER4 | MMU_FTR_LOCKLESS_TLBIE</span>
<span class="p_del">-#define MMU_FTRS_POWER9		MMU_FTRS_POWER4 | MMU_FTR_LOCKLESS_TLBIE</span>
<span class="p_add">+#define MMU_FTRS_POWER6		MMU_FTRS_POWER4 | MMU_FTR_LOCKLESS_TLBIE | MMU_FTR_KERNEL_RO</span>
<span class="p_add">+#define MMU_FTRS_POWER7		MMU_FTRS_POWER4 | MMU_FTR_LOCKLESS_TLBIE | MMU_FTR_KERNEL_RO</span>
<span class="p_add">+#define MMU_FTRS_POWER8		MMU_FTRS_POWER4 | MMU_FTR_LOCKLESS_TLBIE | MMU_FTR_KERNEL_RO</span>
<span class="p_add">+#define MMU_FTRS_POWER9		MMU_FTRS_POWER4 | MMU_FTR_LOCKLESS_TLBIE | MMU_FTR_KERNEL_RO</span>
 #define MMU_FTRS_CELL		MMU_FTRS_DEFAULT_HPTE_ARCH_V2 | \
 				MMU_FTR_CI_LARGE_PAGE
 #define MMU_FTRS_PA6T		MMU_FTRS_DEFAULT_HPTE_ARCH_V2 | \
<span class="p_header">diff --git a/arch/powerpc/include/asm/reg.h b/arch/powerpc/include/asm/reg.h</span>
<span class="p_header">index 978dada662ae..52cbf043e960 100644</span>
<span class="p_header">--- a/arch/powerpc/include/asm/reg.h</span>
<span class="p_header">+++ b/arch/powerpc/include/asm/reg.h</span>
<span class="p_chunk">@@ -355,6 +355,7 @@</span> <span class="p_context"></span>
 #define     LPCR_PECE0		ASM_CONST(0x0000000000004000)	/* ext. exceptions can cause exit */
 #define     LPCR_PECE1		ASM_CONST(0x0000000000002000)	/* decrementer can cause exit */
 #define     LPCR_PECE2		ASM_CONST(0x0000000000001000)	/* machine check etc can cause exit */
<span class="p_add">+#define     LPCR_PECE_HVEE	ASM_CONST(0x0000400000000000)	/* P9 Wakeup on HV interrupts */</span>
 #define   LPCR_MER		ASM_CONST(0x0000000000000800)	/* Mediated External Exception */
 #define   LPCR_MER_SH		11
 #define   LPCR_TC		ASM_CONST(0x0000000000000200)	/* Translation control */
<span class="p_header">diff --git a/arch/powerpc/kernel/cpu_setup_power.S b/arch/powerpc/kernel/cpu_setup_power.S</span>
<span class="p_header">index 52ff3f025437..37c027ca83b2 100644</span>
<span class="p_header">--- a/arch/powerpc/kernel/cpu_setup_power.S</span>
<span class="p_header">+++ b/arch/powerpc/kernel/cpu_setup_power.S</span>
<span class="p_chunk">@@ -98,8 +98,8 @@</span> <span class="p_context"> _GLOBAL(__setup_cpu_power9)</span>
 	li	r0,0
 	mtspr	SPRN_LPID,r0
 	mfspr	r3,SPRN_LPCR
<span class="p_del">-	ori	r3, r3, LPCR_PECEDH</span>
<span class="p_del">-	ori	r3, r3, LPCR_HVICE</span>
<span class="p_add">+	LOAD_REG_IMMEDIATE(r4, LPCR_PECEDH | LPCR_PECE_HVEE | LPCR_HVICE)</span>
<span class="p_add">+	or	r3, r3, r4</span>
 	bl	__init_LPCR
 	bl	__init_HFSCR
 	bl	__init_tlb_power9
<span class="p_chunk">@@ -118,8 +118,8 @@</span> <span class="p_context"> _GLOBAL(__restore_cpu_power9)</span>
 	li	r0,0
 	mtspr	SPRN_LPID,r0
 	mfspr   r3,SPRN_LPCR
<span class="p_del">-	ori	r3, r3, LPCR_PECEDH</span>
<span class="p_del">-	ori	r3, r3, LPCR_HVICE</span>
<span class="p_add">+	LOAD_REG_IMMEDIATE(r4, LPCR_PECEDH | LPCR_PECE_HVEE | LPCR_HVICE)</span>
<span class="p_add">+	or	r3, r3, r4</span>
 	bl	__init_LPCR
 	bl	__init_HFSCR
 	bl	__init_tlb_power9
<span class="p_header">diff --git a/arch/powerpc/mm/hash_utils_64.c b/arch/powerpc/mm/hash_utils_64.c</span>
<span class="p_header">index 28923b2e2df1..8dff9ce6fbc1 100644</span>
<span class="p_header">--- a/arch/powerpc/mm/hash_utils_64.c</span>
<span class="p_header">+++ b/arch/powerpc/mm/hash_utils_64.c</span>
<span class="p_chunk">@@ -190,8 +190,12 @@</span> <span class="p_context"> unsigned long htab_convert_pte_flags(unsigned long pteflags)</span>
 		/*
 		 * Kernel read only mapped with ppp bits 0b110
 		 */
<span class="p_del">-		if (!(pteflags &amp; _PAGE_WRITE))</span>
<span class="p_del">-			rflags |= (HPTE_R_PP0 | 0x2);</span>
<span class="p_add">+		if (!(pteflags &amp; _PAGE_WRITE)) {</span>
<span class="p_add">+			if (mmu_has_feature(MMU_FTR_KERNEL_RO))</span>
<span class="p_add">+				rflags |= (HPTE_R_PP0 | 0x2);</span>
<span class="p_add">+			else</span>
<span class="p_add">+				rflags |= 0x3;</span>
<span class="p_add">+		}</span>
 	} else {
 		if (pteflags &amp; _PAGE_RWX)
 			rflags |= 0x2;
<span class="p_header">diff --git a/arch/tile/kernel/time.c b/arch/tile/kernel/time.c</span>
<span class="p_header">index 178989e6d3e3..ea960d660917 100644</span>
<span class="p_header">--- a/arch/tile/kernel/time.c</span>
<span class="p_header">+++ b/arch/tile/kernel/time.c</span>
<span class="p_chunk">@@ -218,8 +218,8 @@</span> <span class="p_context"> void do_timer_interrupt(struct pt_regs *regs, int fault_num)</span>
  */
 unsigned long long sched_clock(void)
 {
<span class="p_del">-	return clocksource_cyc2ns(get_cycles(),</span>
<span class="p_del">-				  sched_clock_mult, SCHED_CLOCK_SHIFT);</span>
<span class="p_add">+	return mult_frac(get_cycles(),</span>
<span class="p_add">+			 sched_clock_mult, 1ULL &lt;&lt; SCHED_CLOCK_SHIFT);</span>
 }
 
 int setup_profiling_timer(unsigned int multiplier)
<span class="p_header">diff --git a/arch/x86/events/intel/ds.c b/arch/x86/events/intel/ds.c</span>
<span class="p_header">index 9b983a474253..8fc714b4f18a 100644</span>
<span class="p_header">--- a/arch/x86/events/intel/ds.c</span>
<span class="p_header">+++ b/arch/x86/events/intel/ds.c</span>
<span class="p_chunk">@@ -1070,20 +1070,20 @@</span> <span class="p_context"> static void setup_pebs_sample_data(struct perf_event *event,</span>
 	}
 
 	/*
<span class="p_del">-	 * We use the interrupt regs as a base because the PEBS record</span>
<span class="p_del">-	 * does not contain a full regs set, specifically it seems to</span>
<span class="p_del">-	 * lack segment descriptors, which get used by things like</span>
<span class="p_del">-	 * user_mode().</span>
<span class="p_add">+	 * We use the interrupt regs as a base because the PEBS record does not</span>
<span class="p_add">+	 * contain a full regs set, specifically it seems to lack segment</span>
<span class="p_add">+	 * descriptors, which get used by things like user_mode().</span>
 	 *
<span class="p_del">-	 * In the simple case fix up only the IP and BP,SP regs, for</span>
<span class="p_del">-	 * PERF_SAMPLE_IP and PERF_SAMPLE_CALLCHAIN to function properly.</span>
<span class="p_del">-	 * A possible PERF_SAMPLE_REGS will have to transfer all regs.</span>
<span class="p_add">+	 * In the simple case fix up only the IP for PERF_SAMPLE_IP.</span>
<span class="p_add">+	 *</span>
<span class="p_add">+	 * We must however always use BP,SP from iregs for the unwinder to stay</span>
<span class="p_add">+	 * sane; the record BP,SP can point into thin air when the record is</span>
<span class="p_add">+	 * from a previous PMI context or an (I)RET happend between the record</span>
<span class="p_add">+	 * and PMI.</span>
 	 */
 	*regs = *iregs;
 	regs-&gt;flags = pebs-&gt;flags;
 	set_linear_ip(regs, pebs-&gt;ip);
<span class="p_del">-	regs-&gt;bp = pebs-&gt;bp;</span>
<span class="p_del">-	regs-&gt;sp = pebs-&gt;sp;</span>
 
 	if (sample_type &amp; PERF_SAMPLE_REGS_INTR) {
 		regs-&gt;ax = pebs-&gt;ax;
<span class="p_chunk">@@ -1092,10 +1092,21 @@</span> <span class="p_context"> static void setup_pebs_sample_data(struct perf_event *event,</span>
 		regs-&gt;dx = pebs-&gt;dx;
 		regs-&gt;si = pebs-&gt;si;
 		regs-&gt;di = pebs-&gt;di;
<span class="p_del">-		regs-&gt;bp = pebs-&gt;bp;</span>
<span class="p_del">-		regs-&gt;sp = pebs-&gt;sp;</span>
 
<span class="p_del">-		regs-&gt;flags = pebs-&gt;flags;</span>
<span class="p_add">+		/*</span>
<span class="p_add">+		 * Per the above; only set BP,SP if we don&#39;t need callchains.</span>
<span class="p_add">+		 *</span>
<span class="p_add">+		 * XXX: does this make sense?</span>
<span class="p_add">+		 */</span>
<span class="p_add">+		if (!(sample_type &amp; PERF_SAMPLE_CALLCHAIN)) {</span>
<span class="p_add">+			regs-&gt;bp = pebs-&gt;bp;</span>
<span class="p_add">+			regs-&gt;sp = pebs-&gt;sp;</span>
<span class="p_add">+		}</span>
<span class="p_add">+</span>
<span class="p_add">+		/*</span>
<span class="p_add">+		 * Preserve PERF_EFLAGS_VM from set_linear_ip().</span>
<span class="p_add">+		 */</span>
<span class="p_add">+		regs-&gt;flags = pebs-&gt;flags | (regs-&gt;flags &amp; PERF_EFLAGS_VM);</span>
 #ifndef CONFIG_X86_32
 		regs-&gt;r8 = pebs-&gt;r8;
 		regs-&gt;r9 = pebs-&gt;r9;
<span class="p_header">diff --git a/arch/x86/events/perf_event.h b/arch/x86/events/perf_event.h</span>
<span class="p_header">index 8c4a47706296..181c238d4df9 100644</span>
<span class="p_header">--- a/arch/x86/events/perf_event.h</span>
<span class="p_header">+++ b/arch/x86/events/perf_event.h</span>
<span class="p_chunk">@@ -113,7 +113,7 @@</span> <span class="p_context"> struct debug_store {</span>
  * Per register state.
  */
 struct er_account {
<span class="p_del">-	raw_spinlock_t		lock;	/* per-core: protect structure */</span>
<span class="p_add">+	raw_spinlock_t      lock;	/* per-core: protect structure */</span>
 	u64                 config;	/* extra MSR config */
 	u64                 reg;	/* extra MSR number */
 	atomic_t            ref;	/* reference count */
<span class="p_header">diff --git a/arch/x86/kernel/fpu/core.c b/arch/x86/kernel/fpu/core.c</span>
<span class="p_header">index 3fc03a09a93b..c289e2f4a6e5 100644</span>
<span class="p_header">--- a/arch/x86/kernel/fpu/core.c</span>
<span class="p_header">+++ b/arch/x86/kernel/fpu/core.c</span>
<span class="p_chunk">@@ -517,14 +517,14 @@</span> <span class="p_context"> void fpu__clear(struct fpu *fpu)</span>
 {
 	WARN_ON_FPU(fpu != &amp;current-&gt;thread.fpu); /* Almost certainly an anomaly */
 
<span class="p_del">-	if (!use_eager_fpu() || !static_cpu_has(X86_FEATURE_FPU)) {</span>
<span class="p_del">-		/* FPU state will be reallocated lazily at the first use. */</span>
<span class="p_del">-		fpu__drop(fpu);</span>
<span class="p_del">-	} else {</span>
<span class="p_del">-		if (!fpu-&gt;fpstate_active) {</span>
<span class="p_del">-			fpu__activate_curr(fpu);</span>
<span class="p_del">-			user_fpu_begin();</span>
<span class="p_del">-		}</span>
<span class="p_add">+	fpu__drop(fpu);</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Make sure fpstate is cleared and initialized.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	if (static_cpu_has(X86_FEATURE_FPU)) {</span>
<span class="p_add">+		fpu__activate_curr(fpu);</span>
<span class="p_add">+		user_fpu_begin();</span>
 		copy_init_fpstate_to_fpregs();
 	}
 }
<span class="p_header">diff --git a/arch/x86/kvm/emulate.c b/arch/x86/kvm/emulate.c</span>
<span class="p_header">index cbd7b92585bb..a3ce9d260d68 100644</span>
<span class="p_header">--- a/arch/x86/kvm/emulate.c</span>
<span class="p_header">+++ b/arch/x86/kvm/emulate.c</span>
<span class="p_chunk">@@ -2105,16 +2105,10 @@</span> <span class="p_context"> static int em_iret(struct x86_emulate_ctxt *ctxt)</span>
 static int em_jmp_far(struct x86_emulate_ctxt *ctxt)
 {
 	int rc;
<span class="p_del">-	unsigned short sel, old_sel;</span>
<span class="p_del">-	struct desc_struct old_desc, new_desc;</span>
<span class="p_del">-	const struct x86_emulate_ops *ops = ctxt-&gt;ops;</span>
<span class="p_add">+	unsigned short sel;</span>
<span class="p_add">+	struct desc_struct new_desc;</span>
 	u8 cpl = ctxt-&gt;ops-&gt;cpl(ctxt);
 
<span class="p_del">-	/* Assignment of RIP may only fail in 64-bit mode */</span>
<span class="p_del">-	if (ctxt-&gt;mode == X86EMUL_MODE_PROT64)</span>
<span class="p_del">-		ops-&gt;get_segment(ctxt, &amp;old_sel, &amp;old_desc, NULL,</span>
<span class="p_del">-				 VCPU_SREG_CS);</span>
<span class="p_del">-</span>
 	memcpy(&amp;sel, ctxt-&gt;src.valptr + ctxt-&gt;op_bytes, 2);
 
 	rc = __load_segment_descriptor(ctxt, sel, VCPU_SREG_CS, cpl,
<span class="p_chunk">@@ -2124,12 +2118,10 @@</span> <span class="p_context"> static int em_jmp_far(struct x86_emulate_ctxt *ctxt)</span>
 		return rc;
 
 	rc = assign_eip_far(ctxt, ctxt-&gt;src.val, &amp;new_desc);
<span class="p_del">-	if (rc != X86EMUL_CONTINUE) {</span>
<span class="p_del">-		WARN_ON(ctxt-&gt;mode != X86EMUL_MODE_PROT64);</span>
<span class="p_del">-		/* assigning eip failed; restore the old cs */</span>
<span class="p_del">-		ops-&gt;set_segment(ctxt, old_sel, &amp;old_desc, 0, VCPU_SREG_CS);</span>
<span class="p_del">-		return rc;</span>
<span class="p_del">-	}</span>
<span class="p_add">+	/* Error handling is not implemented. */</span>
<span class="p_add">+	if (rc != X86EMUL_CONTINUE)</span>
<span class="p_add">+		return X86EMUL_UNHANDLEABLE;</span>
<span class="p_add">+</span>
 	return rc;
 }
 
<span class="p_chunk">@@ -2189,14 +2181,8 @@</span> <span class="p_context"> static int em_ret_far(struct x86_emulate_ctxt *ctxt)</span>
 {
 	int rc;
 	unsigned long eip, cs;
<span class="p_del">-	u16 old_cs;</span>
 	int cpl = ctxt-&gt;ops-&gt;cpl(ctxt);
<span class="p_del">-	struct desc_struct old_desc, new_desc;</span>
<span class="p_del">-	const struct x86_emulate_ops *ops = ctxt-&gt;ops;</span>
<span class="p_del">-</span>
<span class="p_del">-	if (ctxt-&gt;mode == X86EMUL_MODE_PROT64)</span>
<span class="p_del">-		ops-&gt;get_segment(ctxt, &amp;old_cs, &amp;old_desc, NULL,</span>
<span class="p_del">-				 VCPU_SREG_CS);</span>
<span class="p_add">+	struct desc_struct new_desc;</span>
 
 	rc = emulate_pop(ctxt, &amp;eip, ctxt-&gt;op_bytes);
 	if (rc != X86EMUL_CONTINUE)
<span class="p_chunk">@@ -2213,10 +2199,10 @@</span> <span class="p_context"> static int em_ret_far(struct x86_emulate_ctxt *ctxt)</span>
 	if (rc != X86EMUL_CONTINUE)
 		return rc;
 	rc = assign_eip_far(ctxt, eip, &amp;new_desc);
<span class="p_del">-	if (rc != X86EMUL_CONTINUE) {</span>
<span class="p_del">-		WARN_ON(ctxt-&gt;mode != X86EMUL_MODE_PROT64);</span>
<span class="p_del">-		ops-&gt;set_segment(ctxt, old_cs, &amp;old_desc, 0, VCPU_SREG_CS);</span>
<span class="p_del">-	}</span>
<span class="p_add">+	/* Error handling is not implemented. */</span>
<span class="p_add">+	if (rc != X86EMUL_CONTINUE)</span>
<span class="p_add">+		return X86EMUL_UNHANDLEABLE;</span>
<span class="p_add">+</span>
 	return rc;
 }
 
<span class="p_header">diff --git a/arch/x86/kvm/ioapic.c b/arch/x86/kvm/ioapic.c</span>
<span class="p_header">index 1a22de70f7f7..6e219e5c07d2 100644</span>
<span class="p_header">--- a/arch/x86/kvm/ioapic.c</span>
<span class="p_header">+++ b/arch/x86/kvm/ioapic.c</span>
<span class="p_chunk">@@ -94,7 +94,7 @@</span> <span class="p_context"> static unsigned long ioapic_read_indirect(struct kvm_ioapic *ioapic,</span>
 static void rtc_irq_eoi_tracking_reset(struct kvm_ioapic *ioapic)
 {
 	ioapic-&gt;rtc_status.pending_eoi = 0;
<span class="p_del">-	bitmap_zero(ioapic-&gt;rtc_status.dest_map.map, KVM_MAX_VCPUS);</span>
<span class="p_add">+	bitmap_zero(ioapic-&gt;rtc_status.dest_map.map, KVM_MAX_VCPU_ID);</span>
 }
 
 static void kvm_rtc_eoi_tracking_restore_all(struct kvm_ioapic *ioapic);
<span class="p_header">diff --git a/arch/x86/kvm/ioapic.h b/arch/x86/kvm/ioapic.h</span>
<span class="p_header">index 7d2692a49657..1cc6e54436db 100644</span>
<span class="p_header">--- a/arch/x86/kvm/ioapic.h</span>
<span class="p_header">+++ b/arch/x86/kvm/ioapic.h</span>
<span class="p_chunk">@@ -42,13 +42,13 @@</span> <span class="p_context"> struct kvm_vcpu;</span>
 
 struct dest_map {
 	/* vcpu bitmap where IRQ has been sent */
<span class="p_del">-	DECLARE_BITMAP(map, KVM_MAX_VCPUS);</span>
<span class="p_add">+	DECLARE_BITMAP(map, KVM_MAX_VCPU_ID);</span>
 
 	/*
 	 * Vector sent to a given vcpu, only valid when
 	 * the vcpu&#39;s bit in map is set
 	 */
<span class="p_del">-	u8 vectors[KVM_MAX_VCPUS];</span>
<span class="p_add">+	u8 vectors[KVM_MAX_VCPU_ID];</span>
 };
 
 
<span class="p_header">diff --git a/arch/x86/kvm/irq_comm.c b/arch/x86/kvm/irq_comm.c</span>
<span class="p_header">index 25810b144b58..e7a112ac51a8 100644</span>
<span class="p_header">--- a/arch/x86/kvm/irq_comm.c</span>
<span class="p_header">+++ b/arch/x86/kvm/irq_comm.c</span>
<span class="p_chunk">@@ -41,6 +41,15 @@</span> <span class="p_context"> static int kvm_set_pic_irq(struct kvm_kernel_irq_routing_entry *e,</span>
 			   bool line_status)
 {
 	struct kvm_pic *pic = pic_irqchip(kvm);
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * XXX: rejecting pic routes when pic isn&#39;t in use would be better,</span>
<span class="p_add">+	 * but the default routing table is installed while kvm-&gt;arch.vpic is</span>
<span class="p_add">+	 * NULL and KVM_CREATE_IRQCHIP can race with KVM_IRQ_LINE.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	if (!pic)</span>
<span class="p_add">+		return -1;</span>
<span class="p_add">+</span>
 	return kvm_pic_set_irq(pic, e-&gt;irqchip.pin, irq_source_id, level);
 }
 
<span class="p_chunk">@@ -49,6 +58,10 @@</span> <span class="p_context"> static int kvm_set_ioapic_irq(struct kvm_kernel_irq_routing_entry *e,</span>
 			      bool line_status)
 {
 	struct kvm_ioapic *ioapic = kvm-&gt;arch.vioapic;
<span class="p_add">+</span>
<span class="p_add">+	if (!ioapic)</span>
<span class="p_add">+		return -1;</span>
<span class="p_add">+</span>
 	return kvm_ioapic_set_irq(ioapic, e-&gt;irqchip.pin, irq_source_id, level,
 				line_status);
 }
<span class="p_header">diff --git a/arch/x86/kvm/lapic.c b/arch/x86/kvm/lapic.c</span>
<span class="p_header">index b62c85229711..d2255e4f9589 100644</span>
<span class="p_header">--- a/arch/x86/kvm/lapic.c</span>
<span class="p_header">+++ b/arch/x86/kvm/lapic.c</span>
<span class="p_chunk">@@ -138,7 +138,7 @@</span> <span class="p_context"> static inline bool kvm_apic_map_get_logical_dest(struct kvm_apic_map *map,</span>
 		*mask = dest_id &amp; 0xff;
 		return true;
 	case KVM_APIC_MODE_XAPIC_CLUSTER:
<span class="p_del">-		*cluster = map-&gt;xapic_cluster_map[dest_id &gt;&gt; 4];</span>
<span class="p_add">+		*cluster = map-&gt;xapic_cluster_map[(dest_id &gt;&gt; 4) &amp; 0xf];</span>
 		*mask = dest_id &amp; 0xf;
 		return true;
 	default:
<span class="p_header">diff --git a/arch/x86/mm/extable.c b/arch/x86/mm/extable.c</span>
<span class="p_header">index 832b98f822be..a3a983fd4248 100644</span>
<span class="p_header">--- a/arch/x86/mm/extable.c</span>
<span class="p_header">+++ b/arch/x86/mm/extable.c</span>
<span class="p_chunk">@@ -135,7 +135,12 @@</span> <span class="p_context"> void __init early_fixup_exception(struct pt_regs *regs, int trapnr)</span>
 	if (early_recursion_flag &gt; 2)
 		goto halt_loop;
 
<span class="p_del">-	if (regs-&gt;cs != __KERNEL_CS)</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Old CPUs leave the high bits of CS on the stack</span>
<span class="p_add">+	 * undefined.  I&#39;m not sure which CPUs do this, but at least</span>
<span class="p_add">+	 * the 486 DX works this way.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	if ((regs-&gt;cs &amp; 0xFFFF) != __KERNEL_CS)</span>
 		goto fail;
 
 	/*
<span class="p_header">diff --git a/crypto/asymmetric_keys/x509_cert_parser.c b/crypto/asymmetric_keys/x509_cert_parser.c</span>
<span class="p_header">index 865f46ea724f..c80765b211cf 100644</span>
<span class="p_header">--- a/crypto/asymmetric_keys/x509_cert_parser.c</span>
<span class="p_header">+++ b/crypto/asymmetric_keys/x509_cert_parser.c</span>
<span class="p_chunk">@@ -133,7 +133,6 @@</span> <span class="p_context"> struct x509_certificate *x509_cert_parse(const void *data, size_t datalen)</span>
 	return cert;
 
 error_decode:
<span class="p_del">-	kfree(cert-&gt;pub-&gt;key);</span>
 	kfree(ctx);
 error_no_ctx:
 	x509_free_certificate(cert);
<span class="p_header">diff --git a/drivers/dax/dax.c b/drivers/dax/dax.c</span>
<span class="p_header">index 29f600f2c447..ff64313770bd 100644</span>
<span class="p_header">--- a/drivers/dax/dax.c</span>
<span class="p_header">+++ b/drivers/dax/dax.c</span>
<span class="p_chunk">@@ -323,8 +323,8 @@</span> <span class="p_context"> static int check_vma(struct dax_dev *dax_dev, struct vm_area_struct *vma,</span>
 	if (!dax_dev-&gt;alive)
 		return -ENXIO;
 
<span class="p_del">-	/* prevent private / writable mappings from being established */</span>
<span class="p_del">-	if ((vma-&gt;vm_flags &amp; (VM_NORESERVE|VM_SHARED|VM_WRITE)) == VM_WRITE) {</span>
<span class="p_add">+	/* prevent private mappings from being established */</span>
<span class="p_add">+	if ((vma-&gt;vm_flags &amp; VM_SHARED) != VM_SHARED) {</span>
 		dev_info(dev, &quot;%s: %s: fail, attempted private mapping\n&quot;,
 				current-&gt;comm, func);
 		return -EINVAL;
<span class="p_header">diff --git a/drivers/dax/pmem.c b/drivers/dax/pmem.c</span>
<span class="p_header">index 73ae849f5170..76dd42dd7088 100644</span>
<span class="p_header">--- a/drivers/dax/pmem.c</span>
<span class="p_header">+++ b/drivers/dax/pmem.c</span>
<span class="p_chunk">@@ -77,7 +77,9 @@</span> <span class="p_context"> static int dax_pmem_probe(struct device *dev)</span>
 	nsio = to_nd_namespace_io(&amp;ndns-&gt;dev);
 
 	/* parse the &#39;pfn&#39; info block via -&gt;rw_bytes */
<span class="p_del">-	devm_nsio_enable(dev, nsio);</span>
<span class="p_add">+	rc = devm_nsio_enable(dev, nsio);</span>
<span class="p_add">+	if (rc)</span>
<span class="p_add">+		return rc;</span>
 	altmap = nvdimm_setup_pfn(nd_pfn, &amp;res, &amp;__altmap);
 	if (IS_ERR(altmap))
 		return PTR_ERR(altmap);
<span class="p_header">diff --git a/drivers/iommu/dmar.c b/drivers/iommu/dmar.c</span>
<span class="p_header">index 58470f5ced04..8c53748a769d 100644</span>
<span class="p_header">--- a/drivers/iommu/dmar.c</span>
<span class="p_header">+++ b/drivers/iommu/dmar.c</span>
<span class="p_chunk">@@ -338,7 +338,9 @@</span> <span class="p_context"> static int dmar_pci_bus_notifier(struct notifier_block *nb,</span>
 	struct pci_dev *pdev = to_pci_dev(data);
 	struct dmar_pci_notify_info *info;
 
<span class="p_del">-	/* Only care about add/remove events for physical functions */</span>
<span class="p_add">+	/* Only care about add/remove events for physical functions.</span>
<span class="p_add">+	 * For VFs we actually do the lookup based on the corresponding</span>
<span class="p_add">+	 * PF in device_to_iommu() anyway. */</span>
 	if (pdev-&gt;is_virtfn)
 		return NOTIFY_DONE;
 	if (action != BUS_NOTIFY_ADD_DEVICE &amp;&amp;
<span class="p_header">diff --git a/drivers/iommu/intel-iommu.c b/drivers/iommu/intel-iommu.c</span>
<span class="p_header">index 1257b0b80296..7fb538708cec 100644</span>
<span class="p_header">--- a/drivers/iommu/intel-iommu.c</span>
<span class="p_header">+++ b/drivers/iommu/intel-iommu.c</span>
<span class="p_chunk">@@ -892,7 +892,13 @@</span> <span class="p_context"> static struct intel_iommu *device_to_iommu(struct device *dev, u8 *bus, u8 *devf</span>
 		return NULL;
 
 	if (dev_is_pci(dev)) {
<span class="p_add">+		struct pci_dev *pf_pdev;</span>
<span class="p_add">+</span>
 		pdev = to_pci_dev(dev);
<span class="p_add">+		/* VFs aren&#39;t listed in scope tables; we need to look up</span>
<span class="p_add">+		 * the PF instead to find the IOMMU. */</span>
<span class="p_add">+		pf_pdev = pci_physfn(pdev);</span>
<span class="p_add">+		dev = &amp;pf_pdev-&gt;dev;</span>
 		segment = pci_domain_nr(pdev-&gt;bus);
 	} else if (has_acpi_companion(dev))
 		dev = &amp;ACPI_COMPANION(dev)-&gt;dev;
<span class="p_chunk">@@ -905,6 +911,13 @@</span> <span class="p_context"> static struct intel_iommu *device_to_iommu(struct device *dev, u8 *bus, u8 *devf</span>
 		for_each_active_dev_scope(drhd-&gt;devices,
 					  drhd-&gt;devices_cnt, i, tmp) {
 			if (tmp == dev) {
<span class="p_add">+				/* For a VF use its original BDF# not that of the PF</span>
<span class="p_add">+				 * which we used for the IOMMU lookup. Strictly speaking</span>
<span class="p_add">+				 * we could do this for all PCI devices; we only need to</span>
<span class="p_add">+				 * get the BDF# from the scope table for ACPI matches. */</span>
<span class="p_add">+				if (pdev-&gt;is_virtfn)</span>
<span class="p_add">+					goto got_pdev;</span>
<span class="p_add">+</span>
 				*bus = drhd-&gt;devices[i].bus;
 				*devfn = drhd-&gt;devices[i].devfn;
 				goto out;
<span class="p_header">diff --git a/drivers/iommu/intel-svm.c b/drivers/iommu/intel-svm.c</span>
<span class="p_header">index 8ebb3530afa7..cb72e0011310 100644</span>
<span class="p_header">--- a/drivers/iommu/intel-svm.c</span>
<span class="p_header">+++ b/drivers/iommu/intel-svm.c</span>
<span class="p_chunk">@@ -39,10 +39,18 @@</span> <span class="p_context"> int intel_svm_alloc_pasid_tables(struct intel_iommu *iommu)</span>
 	struct page *pages;
 	int order;
 
<span class="p_del">-	order = ecap_pss(iommu-&gt;ecap) + 7 - PAGE_SHIFT;</span>
<span class="p_del">-	if (order &lt; 0)</span>
<span class="p_del">-		order = 0;</span>
<span class="p_del">-</span>
<span class="p_add">+	/* Start at 2 because it&#39;s defined as 2^(1+PSS) */</span>
<span class="p_add">+	iommu-&gt;pasid_max = 2 &lt;&lt; ecap_pss(iommu-&gt;ecap);</span>
<span class="p_add">+</span>
<span class="p_add">+	/* Eventually I&#39;m promised we will get a multi-level PASID table</span>
<span class="p_add">+	 * and it won&#39;t have to be physically contiguous. Until then,</span>
<span class="p_add">+	 * limit the size because 8MiB contiguous allocations can be hard</span>
<span class="p_add">+	 * to come by. The limit of 0x20000, which is 1MiB for each of</span>
<span class="p_add">+	 * the PASID and PASID-state tables, is somewhat arbitrary. */</span>
<span class="p_add">+	if (iommu-&gt;pasid_max &gt; 0x20000)</span>
<span class="p_add">+		iommu-&gt;pasid_max = 0x20000;</span>
<span class="p_add">+</span>
<span class="p_add">+	order = get_order(sizeof(struct pasid_entry) * iommu-&gt;pasid_max);</span>
 	pages = alloc_pages(GFP_KERNEL | __GFP_ZERO, order);
 	if (!pages) {
 		pr_warn(&quot;IOMMU: %s: Failed to allocate PASID table\n&quot;,
<span class="p_chunk">@@ -53,6 +61,8 @@</span> <span class="p_context"> int intel_svm_alloc_pasid_tables(struct intel_iommu *iommu)</span>
 	pr_info(&quot;%s: Allocated order %d PASID table.\n&quot;, iommu-&gt;name, order);
 
 	if (ecap_dis(iommu-&gt;ecap)) {
<span class="p_add">+		/* Just making it explicit... */</span>
<span class="p_add">+		BUILD_BUG_ON(sizeof(struct pasid_entry) != sizeof(struct pasid_state_entry));</span>
 		pages = alloc_pages(GFP_KERNEL | __GFP_ZERO, order);
 		if (pages)
 			iommu-&gt;pasid_state_table = page_address(pages);
<span class="p_chunk">@@ -68,11 +78,7 @@</span> <span class="p_context"> int intel_svm_alloc_pasid_tables(struct intel_iommu *iommu)</span>
 
 int intel_svm_free_pasid_tables(struct intel_iommu *iommu)
 {
<span class="p_del">-	int order;</span>
<span class="p_del">-</span>
<span class="p_del">-	order = ecap_pss(iommu-&gt;ecap) + 7 - PAGE_SHIFT;</span>
<span class="p_del">-	if (order &lt; 0)</span>
<span class="p_del">-		order = 0;</span>
<span class="p_add">+	int order = get_order(sizeof(struct pasid_entry) * iommu-&gt;pasid_max);</span>
 
 	if (iommu-&gt;pasid_table) {
 		free_pages((unsigned long)iommu-&gt;pasid_table, order);
<span class="p_chunk">@@ -371,8 +377,8 @@</span> <span class="p_context"> int intel_svm_bind_mm(struct device *dev, int *pasid, int flags, struct svm_dev_</span>
 		}
 		svm-&gt;iommu = iommu;
 
<span class="p_del">-		if (pasid_max &gt; 2 &lt;&lt; ecap_pss(iommu-&gt;ecap))</span>
<span class="p_del">-			pasid_max = 2 &lt;&lt; ecap_pss(iommu-&gt;ecap);</span>
<span class="p_add">+		if (pasid_max &gt; iommu-&gt;pasid_max)</span>
<span class="p_add">+			pasid_max = iommu-&gt;pasid_max;</span>
 
 		/* Do not use PASID 0 in caching mode (virtualised IOMMU) */
 		ret = idr_alloc(&amp;iommu-&gt;pasid_idr, svm,
<span class="p_header">diff --git a/drivers/media/tuners/tuner-xc2028.c b/drivers/media/tuners/tuner-xc2028.c</span>
<span class="p_header">index 317ef63ee789..8d96a22647b3 100644</span>
<span class="p_header">--- a/drivers/media/tuners/tuner-xc2028.c</span>
<span class="p_header">+++ b/drivers/media/tuners/tuner-xc2028.c</span>
<span class="p_chunk">@@ -281,6 +281,14 @@</span> <span class="p_context"> static void free_firmware(struct xc2028_data *priv)</span>
 	int i;
 	tuner_dbg(&quot;%s called\n&quot;, __func__);
 
<span class="p_add">+	/* free allocated f/w string */</span>
<span class="p_add">+	if (priv-&gt;fname != firmware_name)</span>
<span class="p_add">+		kfree(priv-&gt;fname);</span>
<span class="p_add">+	priv-&gt;fname = NULL;</span>
<span class="p_add">+</span>
<span class="p_add">+	priv-&gt;state = XC2028_NO_FIRMWARE;</span>
<span class="p_add">+	memset(&amp;priv-&gt;cur_fw, 0, sizeof(priv-&gt;cur_fw));</span>
<span class="p_add">+</span>
 	if (!priv-&gt;firm)
 		return;
 
<span class="p_chunk">@@ -291,9 +299,6 @@</span> <span class="p_context"> static void free_firmware(struct xc2028_data *priv)</span>
 
 	priv-&gt;firm = NULL;
 	priv-&gt;firm_size = 0;
<span class="p_del">-	priv-&gt;state = XC2028_NO_FIRMWARE;</span>
<span class="p_del">-</span>
<span class="p_del">-	memset(&amp;priv-&gt;cur_fw, 0, sizeof(priv-&gt;cur_fw));</span>
 }
 
 static int load_all_firmwares(struct dvb_frontend *fe,
<span class="p_chunk">@@ -884,9 +889,8 @@</span> <span class="p_context"> read_not_reliable:</span>
 	return 0;
 
 fail:
<span class="p_del">-	priv-&gt;state = XC2028_NO_FIRMWARE;</span>
<span class="p_add">+	free_firmware(priv);</span>
 
<span class="p_del">-	memset(&amp;priv-&gt;cur_fw, 0, sizeof(priv-&gt;cur_fw));</span>
 	if (retry_count &lt; 8) {
 		msleep(50);
 		retry_count++;
<span class="p_chunk">@@ -1332,11 +1336,8 @@</span> <span class="p_context"> static int xc2028_dvb_release(struct dvb_frontend *fe)</span>
 	mutex_lock(&amp;xc2028_list_mutex);
 
 	/* only perform final cleanup if this is the last instance */
<span class="p_del">-	if (hybrid_tuner_report_instance_count(priv) == 1) {</span>
<span class="p_add">+	if (hybrid_tuner_report_instance_count(priv) == 1)</span>
 		free_firmware(priv);
<span class="p_del">-		kfree(priv-&gt;ctrl.fname);</span>
<span class="p_del">-		priv-&gt;ctrl.fname = NULL;</span>
<span class="p_del">-	}</span>
 
 	if (priv)
 		hybrid_tuner_release_state(priv);
<span class="p_chunk">@@ -1399,19 +1400,8 @@</span> <span class="p_context"> static int xc2028_set_config(struct dvb_frontend *fe, void *priv_cfg)</span>
 
 	/*
 	 * Copy the config data.
<span class="p_del">-	 * For the firmware name, keep a local copy of the string,</span>
<span class="p_del">-	 * in order to avoid troubles during device release.</span>
 	 */
<span class="p_del">-	kfree(priv-&gt;ctrl.fname);</span>
<span class="p_del">-	priv-&gt;ctrl.fname = NULL;</span>
 	memcpy(&amp;priv-&gt;ctrl, p, sizeof(priv-&gt;ctrl));
<span class="p_del">-	if (p-&gt;fname) {</span>
<span class="p_del">-		priv-&gt;ctrl.fname = kstrdup(p-&gt;fname, GFP_KERNEL);</span>
<span class="p_del">-		if (priv-&gt;ctrl.fname == NULL) {</span>
<span class="p_del">-			rc = -ENOMEM;</span>
<span class="p_del">-			goto unlock;</span>
<span class="p_del">-		}</span>
<span class="p_del">-	}</span>
 
 	/*
 	 * If firmware name changed, frees firmware. As free_firmware will
<span class="p_chunk">@@ -1426,10 +1416,15 @@</span> <span class="p_context"> static int xc2028_set_config(struct dvb_frontend *fe, void *priv_cfg)</span>
 
 	if (priv-&gt;state == XC2028_NO_FIRMWARE) {
 		if (!firmware_name[0])
<span class="p_del">-			priv-&gt;fname = priv-&gt;ctrl.fname;</span>
<span class="p_add">+			priv-&gt;fname = kstrdup(p-&gt;fname, GFP_KERNEL);</span>
 		else
 			priv-&gt;fname = firmware_name;
 
<span class="p_add">+		if (!priv-&gt;fname) {</span>
<span class="p_add">+			rc = -ENOMEM;</span>
<span class="p_add">+			goto unlock;</span>
<span class="p_add">+		}</span>
<span class="p_add">+</span>
 		rc = request_firmware_nowait(THIS_MODULE, 1,
 					     priv-&gt;fname,
 					     priv-&gt;i2c_props.adap-&gt;dev.parent,
<span class="p_header">diff --git a/drivers/mmc/host/sdhci-of-esdhc.c b/drivers/mmc/host/sdhci-of-esdhc.c</span>
<span class="p_header">index 239be2fde242..2267601f0ac1 100644</span>
<span class="p_header">--- a/drivers/mmc/host/sdhci-of-esdhc.c</span>
<span class="p_header">+++ b/drivers/mmc/host/sdhci-of-esdhc.c</span>
<span class="p_chunk">@@ -66,6 +66,20 @@</span> <span class="p_context"> static u32 esdhc_readl_fixup(struct sdhci_host *host,</span>
 			return ret;
 		}
 	}
<span class="p_add">+	/*</span>
<span class="p_add">+	 * The DAT[3:0] line signal levels and the CMD line signal level are</span>
<span class="p_add">+	 * not compatible with standard SDHC register. The line signal levels</span>
<span class="p_add">+	 * DAT[7:0] are at bits 31:24 and the command line signal level is at</span>
<span class="p_add">+	 * bit 23. All other bits are the same as in the standard SDHC</span>
<span class="p_add">+	 * register.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	if (spec_reg == SDHCI_PRESENT_STATE) {</span>
<span class="p_add">+		ret = value &amp; 0x000fffff;</span>
<span class="p_add">+		ret |= (value &gt;&gt; 4) &amp; SDHCI_DATA_LVL_MASK;</span>
<span class="p_add">+		ret |= (value &lt;&lt; 1) &amp; SDHCI_CMD_LVL;</span>
<span class="p_add">+		return ret;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
 	ret = value;
 	return ret;
 }
<span class="p_header">diff --git a/drivers/mmc/host/sdhci.h b/drivers/mmc/host/sdhci.h</span>
<span class="p_header">index 0411c9f36461..1b3bd1c7f4f6 100644</span>
<span class="p_header">--- a/drivers/mmc/host/sdhci.h</span>
<span class="p_header">+++ b/drivers/mmc/host/sdhci.h</span>
<span class="p_chunk">@@ -73,6 +73,7 @@</span> <span class="p_context"></span>
 #define  SDHCI_DATA_LVL_MASK	0x00F00000
 #define   SDHCI_DATA_LVL_SHIFT	20
 #define   SDHCI_DATA_0_LVL_MASK	0x00100000
<span class="p_add">+#define  SDHCI_CMD_LVL		0x01000000</span>
 
 #define SDHCI_HOST_CONTROL	0x28
 #define  SDHCI_CTRL_LED		0x01
<span class="p_header">diff --git a/drivers/scsi/mpt3sas/mpt3sas_scsih.c b/drivers/scsi/mpt3sas/mpt3sas_scsih.c</span>
<span class="p_header">index 46c0f5ecd99d..58e60298a360 100644</span>
<span class="p_header">--- a/drivers/scsi/mpt3sas/mpt3sas_scsih.c</span>
<span class="p_header">+++ b/drivers/scsi/mpt3sas/mpt3sas_scsih.c</span>
<span class="p_chunk">@@ -3894,6 +3894,11 @@</span> <span class="p_context"> _scsih_temp_threshold_events(struct MPT3SAS_ADAPTER *ioc,</span>
 	}
 }
 
<span class="p_add">+static inline bool ata_12_16_cmd(struct scsi_cmnd *scmd)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return (scmd-&gt;cmnd[0] == ATA_12 || scmd-&gt;cmnd[0] == ATA_16);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 /**
  * _scsih_flush_running_cmds - completing outstanding commands.
  * @ioc: per adapter object
<span class="p_chunk">@@ -3915,6 +3920,9 @@</span> <span class="p_context"> _scsih_flush_running_cmds(struct MPT3SAS_ADAPTER *ioc)</span>
 		if (!scmd)
 			continue;
 		count++;
<span class="p_add">+		if (ata_12_16_cmd(scmd))</span>
<span class="p_add">+			scsi_internal_device_unblock(scmd-&gt;device,</span>
<span class="p_add">+							SDEV_RUNNING);</span>
 		mpt3sas_base_free_smid(ioc, smid);
 		scsi_dma_unmap(scmd);
 		if (ioc-&gt;pci_error_recovery)
<span class="p_chunk">@@ -4019,8 +4027,6 @@</span> <span class="p_context"> _scsih_eedp_error_handling(struct scsi_cmnd *scmd, u16 ioc_status)</span>
 	    SAM_STAT_CHECK_CONDITION;
 }
 
<span class="p_del">-</span>
<span class="p_del">-</span>
 /**
  * scsih_qcmd - main scsi request entry point
  * @scmd: pointer to scsi command object
<span class="p_chunk">@@ -4047,6 +4053,13 @@</span> <span class="p_context"> scsih_qcmd(struct Scsi_Host *shost, struct scsi_cmnd *scmd)</span>
 	if (ioc-&gt;logging_level &amp; MPT_DEBUG_SCSI)
 		scsi_print_command(scmd);
 
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Lock the device for any subsequent command until command is</span>
<span class="p_add">+	 * done.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	if (ata_12_16_cmd(scmd))</span>
<span class="p_add">+		scsi_internal_device_block(scmd-&gt;device);</span>
<span class="p_add">+</span>
 	sas_device_priv_data = scmd-&gt;device-&gt;hostdata;
 	if (!sas_device_priv_data || !sas_device_priv_data-&gt;sas_target) {
 		scmd-&gt;result = DID_NO_CONNECT &lt;&lt; 16;
<span class="p_chunk">@@ -4622,6 +4635,9 @@</span> <span class="p_context"> _scsih_io_done(struct MPT3SAS_ADAPTER *ioc, u16 smid, u8 msix_index, u32 reply)</span>
 	if (scmd == NULL)
 		return 1;
 
<span class="p_add">+	if (ata_12_16_cmd(scmd))</span>
<span class="p_add">+		scsi_internal_device_unblock(scmd-&gt;device, SDEV_RUNNING);</span>
<span class="p_add">+</span>
 	mpi_request = mpt3sas_base_get_msg_frame(ioc, smid);
 
 	if (mpi_reply == NULL) {
<span class="p_header">diff --git a/drivers/thermal/intel_powerclamp.c b/drivers/thermal/intel_powerclamp.c</span>
<span class="p_header">index 7a223074df3d..afada655f861 100644</span>
<span class="p_header">--- a/drivers/thermal/intel_powerclamp.c</span>
<span class="p_header">+++ b/drivers/thermal/intel_powerclamp.c</span>
<span class="p_chunk">@@ -669,9 +669,16 @@</span> <span class="p_context"> static struct thermal_cooling_device_ops powerclamp_cooling_ops = {</span>
 	.set_cur_state = powerclamp_set_cur_state,
 };
 
<span class="p_add">+static const struct x86_cpu_id __initconst intel_powerclamp_ids[] = {</span>
<span class="p_add">+	{ X86_VENDOR_INTEL, X86_FAMILY_ANY, X86_MODEL_ANY, X86_FEATURE_MWAIT },</span>
<span class="p_add">+	{}</span>
<span class="p_add">+};</span>
<span class="p_add">+MODULE_DEVICE_TABLE(x86cpu, intel_powerclamp_ids);</span>
<span class="p_add">+</span>
 static int __init powerclamp_probe(void)
 {
<span class="p_del">-	if (!boot_cpu_has(X86_FEATURE_MWAIT)) {</span>
<span class="p_add">+</span>
<span class="p_add">+	if (!x86_match_cpu(intel_powerclamp_ids)) {</span>
 		pr_err(&quot;CPU does not support MWAIT&quot;);
 		return -ENODEV;
 	}
<span class="p_header">diff --git a/drivers/usb/chipidea/core.c b/drivers/usb/chipidea/core.c</span>
<span class="p_header">index 69426e644d17..3dbb4a21ab44 100644</span>
<span class="p_header">--- a/drivers/usb/chipidea/core.c</span>
<span class="p_header">+++ b/drivers/usb/chipidea/core.c</span>
<span class="p_chunk">@@ -914,6 +914,7 @@</span> <span class="p_context"> static int ci_hdrc_probe(struct platform_device *pdev)</span>
 	if (!ci)
 		return -ENOMEM;
 
<span class="p_add">+	spin_lock_init(&amp;ci-&gt;lock);</span>
 	ci-&gt;dev = dev;
 	ci-&gt;platdata = dev_get_platdata(dev);
 	ci-&gt;imx28_write_fix = !!(ci-&gt;platdata-&gt;flags &amp;
<span class="p_header">diff --git a/drivers/usb/chipidea/udc.c b/drivers/usb/chipidea/udc.c</span>
<span class="p_header">index b93356834bb5..bced28fa1cbd 100644</span>
<span class="p_header">--- a/drivers/usb/chipidea/udc.c</span>
<span class="p_header">+++ b/drivers/usb/chipidea/udc.c</span>
<span class="p_chunk">@@ -1895,8 +1895,6 @@</span> <span class="p_context"> static int udc_start(struct ci_hdrc *ci)</span>
 	struct usb_otg_caps *otg_caps = &amp;ci-&gt;platdata-&gt;ci_otg_caps;
 	int retval = 0;
 
<span class="p_del">-	spin_lock_init(&amp;ci-&gt;lock);</span>
<span class="p_del">-</span>
 	ci-&gt;gadget.ops          = &amp;usb_gadget_ops;
 	ci-&gt;gadget.speed        = USB_SPEED_UNKNOWN;
 	ci-&gt;gadget.max_speed    = USB_SPEED_HIGH;
<span class="p_header">diff --git a/drivers/usb/serial/cp210x.c b/drivers/usb/serial/cp210x.c</span>
<span class="p_header">index f61477bed3a8..243ac5ebe46a 100644</span>
<span class="p_header">--- a/drivers/usb/serial/cp210x.c</span>
<span class="p_header">+++ b/drivers/usb/serial/cp210x.c</span>
<span class="p_chunk">@@ -131,6 +131,7 @@</span> <span class="p_context"> static const struct usb_device_id id_table[] = {</span>
 	{ USB_DEVICE(0x10C4, 0x88A4) }, /* MMB Networks ZigBee USB Device */
 	{ USB_DEVICE(0x10C4, 0x88A5) }, /* Planet Innovation Ingeni ZigBee USB Device */
 	{ USB_DEVICE(0x10C4, 0x8946) }, /* Ketra N1 Wireless Interface */
<span class="p_add">+	{ USB_DEVICE(0x10C4, 0x8962) }, /* Brim Brothers charging dock */</span>
 	{ USB_DEVICE(0x10C4, 0x8977) },	/* CEL MeshWorks DevKit Device */
 	{ USB_DEVICE(0x10C4, 0x8998) }, /* KCF Technologies PRN */
 	{ USB_DEVICE(0x10C4, 0x8A2A) }, /* HubZ dual ZigBee and Z-Wave dongle */
<span class="p_header">diff --git a/drivers/usb/serial/ftdi_sio.c b/drivers/usb/serial/ftdi_sio.c</span>
<span class="p_header">index 0ff7f38d7800..6e9fc8bcc285 100644</span>
<span class="p_header">--- a/drivers/usb/serial/ftdi_sio.c</span>
<span class="p_header">+++ b/drivers/usb/serial/ftdi_sio.c</span>
<span class="p_chunk">@@ -1012,6 +1012,8 @@</span> <span class="p_context"> static const struct usb_device_id id_table_combined[] = {</span>
 	{ USB_DEVICE(ICPDAS_VID, ICPDAS_I7561U_PID) },
 	{ USB_DEVICE(ICPDAS_VID, ICPDAS_I7563U_PID) },
 	{ USB_DEVICE(WICED_VID, WICED_USB20706V2_PID) },
<span class="p_add">+	{ USB_DEVICE(TI_VID, TI_CC3200_LAUNCHPAD_PID),</span>
<span class="p_add">+		.driver_info = (kernel_ulong_t)&amp;ftdi_jtag_quirk },</span>
 	{ }					/* Terminating entry */
 };
 
<span class="p_header">diff --git a/drivers/usb/serial/ftdi_sio_ids.h b/drivers/usb/serial/ftdi_sio_ids.h</span>
<span class="p_header">index 21011c0a4c64..48ee04c94a75 100644</span>
<span class="p_header">--- a/drivers/usb/serial/ftdi_sio_ids.h</span>
<span class="p_header">+++ b/drivers/usb/serial/ftdi_sio_ids.h</span>
<span class="p_chunk">@@ -596,6 +596,12 @@</span> <span class="p_context"></span>
 #define STK541_PID		0x2109 /* Zigbee Controller */
 
 /*
<span class="p_add">+ * Texas Instruments</span>
<span class="p_add">+ */</span>
<span class="p_add">+#define TI_VID			0x0451</span>
<span class="p_add">+#define TI_CC3200_LAUNCHPAD_PID	0xC32A /* SimpleLink Wi-Fi CC3200 LaunchPad */</span>
<span class="p_add">+</span>
<span class="p_add">+/*</span>
  * Blackfin gnICE JTAG
  * http://docs.blackfin.uclinux.org/doku.php?id=hw:jtag:gnice
  */
<span class="p_header">diff --git a/drivers/usb/storage/transport.c b/drivers/usb/storage/transport.c</span>
<span class="p_header">index ffd086733421..1a59f335b063 100644</span>
<span class="p_header">--- a/drivers/usb/storage/transport.c</span>
<span class="p_header">+++ b/drivers/usb/storage/transport.c</span>
<span class="p_chunk">@@ -954,10 +954,15 @@</span> <span class="p_context"> int usb_stor_CB_transport(struct scsi_cmnd *srb, struct us_data *us)</span>
 
 	/* COMMAND STAGE */
 	/* let&#39;s send the command via the control pipe */
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Command is sometime (f.e. after scsi_eh_prep_cmnd) on the stack.</span>
<span class="p_add">+	 * Stack may be vmallocated.  So no DMA for us.  Make a copy.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	memcpy(us-&gt;iobuf, srb-&gt;cmnd, srb-&gt;cmd_len);</span>
 	result = usb_stor_ctrl_transfer(us, us-&gt;send_ctrl_pipe,
 				      US_CBI_ADSC, 
 				      USB_TYPE_CLASS | USB_RECIP_INTERFACE, 0, 
<span class="p_del">-				      us-&gt;ifnum, srb-&gt;cmnd, srb-&gt;cmd_len);</span>
<span class="p_add">+				      us-&gt;ifnum, us-&gt;iobuf, srb-&gt;cmd_len);</span>
 
 	/* check the return code for the command */
 	usb_stor_dbg(us, &quot;Call to usb_stor_ctrl_transfer() returned %d\n&quot;,
<span class="p_header">diff --git a/fs/nfs/callback.c b/fs/nfs/callback.c</span>
<span class="p_header">index 52a28311e2a4..48efe62e1302 100644</span>
<span class="p_header">--- a/fs/nfs/callback.c</span>
<span class="p_header">+++ b/fs/nfs/callback.c</span>
<span class="p_chunk">@@ -261,7 +261,7 @@</span> <span class="p_context"> static int nfs_callback_up_net(int minorversion, struct svc_serv *serv,</span>
 	}
 
 	ret = -EPROTONOSUPPORT;
<span class="p_del">-	if (minorversion == 0)</span>
<span class="p_add">+	if (!IS_ENABLED(CONFIG_NFS_V4_1) || minorversion == 0)</span>
 		ret = nfs4_callback_up_net(serv, net);
 	else if (xprt-&gt;ops-&gt;bc_up)
 		ret = xprt-&gt;ops-&gt;bc_up(serv, net);
<span class="p_header">diff --git a/include/linux/intel-iommu.h b/include/linux/intel-iommu.h</span>
<span class="p_header">index 2d9b650047a5..d49e26c6cdc7 100644</span>
<span class="p_header">--- a/include/linux/intel-iommu.h</span>
<span class="p_header">+++ b/include/linux/intel-iommu.h</span>
<span class="p_chunk">@@ -429,6 +429,7 @@</span> <span class="p_context"> struct intel_iommu {</span>
 	struct page_req_dsc *prq;
 	unsigned char prq_name[16];    /* Name for PRQ interrupt */
 	struct idr pasid_idr;
<span class="p_add">+	u32 pasid_max;</span>
 #endif
 	struct q_inval  *qi;            /* Queued invalidation info */
 	u32 *iommu_state; /* Store iommu states between suspend and resume.*/
<span class="p_header">diff --git a/kernel/events/core.c b/kernel/events/core.c</span>
<span class="p_header">index fc9bb2225291..f8c5f5ec666e 100644</span>
<span class="p_header">--- a/kernel/events/core.c</span>
<span class="p_header">+++ b/kernel/events/core.c</span>
<span class="p_chunk">@@ -7908,6 +7908,7 @@</span> <span class="p_context"> restart:</span>
  * if &lt;size&gt; is not specified, the range is treated as a single address.
  */
 enum {
<span class="p_add">+	IF_ACT_NONE = -1,</span>
 	IF_ACT_FILTER,
 	IF_ACT_START,
 	IF_ACT_STOP,
<span class="p_chunk">@@ -7931,6 +7932,7 @@</span> <span class="p_context"> static const match_table_t if_tokens = {</span>
 	{ IF_SRC_KERNEL,	&quot;%u/%u&quot; },
 	{ IF_SRC_FILEADDR,	&quot;%u@%s&quot; },
 	{ IF_SRC_KERNELADDR,	&quot;%u&quot; },
<span class="p_add">+	{ IF_ACT_NONE,		NULL },</span>
 };
 
 /*
<span class="p_header">diff --git a/lib/mpi/mpi-pow.c b/lib/mpi/mpi-pow.c</span>
<span class="p_header">index 5464c8744ea9..e24388a863a7 100644</span>
<span class="p_header">--- a/lib/mpi/mpi-pow.c</span>
<span class="p_header">+++ b/lib/mpi/mpi-pow.c</span>
<span class="p_chunk">@@ -64,8 +64,13 @@</span> <span class="p_context"> int mpi_powm(MPI res, MPI base, MPI exp, MPI mod)</span>
 	if (!esize) {
 		/* Exponent is zero, result is 1 mod MOD, i.e., 1 or 0
 		 * depending on if MOD equals 1.  */
<span class="p_del">-		rp[0] = 1;</span>
 		res-&gt;nlimbs = (msize == 1 &amp;&amp; mod-&gt;d[0] == 1) ? 0 : 1;
<span class="p_add">+		if (res-&gt;nlimbs) {</span>
<span class="p_add">+			if (mpi_resize(res, 1) &lt; 0)</span>
<span class="p_add">+				goto enomem;</span>
<span class="p_add">+			rp = res-&gt;d;</span>
<span class="p_add">+			rp[0] = 1;</span>
<span class="p_add">+		}</span>
 		res-&gt;sign = 0;
 		goto leave;
 	}
<span class="p_header">diff --git a/mm/page_alloc.c b/mm/page_alloc.c</span>
<span class="p_header">index a2214c64ed3c..7401e996009a 100644</span>
<span class="p_header">--- a/mm/page_alloc.c</span>
<span class="p_header">+++ b/mm/page_alloc.c</span>
<span class="p_chunk">@@ -3161,6 +3161,16 @@</span> <span class="p_context"> should_compact_retry(struct alloc_context *ac, unsigned int order, int alloc_fla</span>
 	if (!order || order &gt; PAGE_ALLOC_COSTLY_ORDER)
 		return false;
 
<span class="p_add">+#ifdef CONFIG_COMPACTION</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * This is a gross workaround to compensate a lack of reliable compaction</span>
<span class="p_add">+	 * operation. We cannot simply go OOM with the current state of the compaction</span>
<span class="p_add">+	 * code because this can lead to pre mature OOM declaration.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	if (order &lt;= PAGE_ALLOC_COSTLY_ORDER)</span>
<span class="p_add">+		return true;</span>
<span class="p_add">+#endif</span>
<span class="p_add">+</span>
 	/*
 	 * There are setups with compaction disabled which would prefer to loop
 	 * inside the allocator rather than hit the oom killer prematurely.
<span class="p_header">diff --git a/net/can/bcm.c b/net/can/bcm.c</span>
<span class="p_header">index 8af9d25ff988..436a7537e6a9 100644</span>
<span class="p_header">--- a/net/can/bcm.c</span>
<span class="p_header">+++ b/net/can/bcm.c</span>
<span class="p_chunk">@@ -77,7 +77,7 @@</span> <span class="p_context"></span>
 		     (CAN_EFF_MASK | CAN_EFF_FLAG | CAN_RTR_FLAG) : \
 		     (CAN_SFF_MASK | CAN_EFF_FLAG | CAN_RTR_FLAG))
 
<span class="p_del">-#define CAN_BCM_VERSION &quot;20160617&quot;</span>
<span class="p_add">+#define CAN_BCM_VERSION &quot;20161123&quot;</span>
 
 MODULE_DESCRIPTION(&quot;PF_CAN broadcast manager protocol&quot;);
 MODULE_LICENSE(&quot;Dual BSD/GPL&quot;);
<span class="p_chunk">@@ -109,8 +109,9 @@</span> <span class="p_context"> struct bcm_op {</span>
 	u32 count;
 	u32 nframes;
 	u32 currframe;
<span class="p_del">-	struct canfd_frame *frames;</span>
<span class="p_del">-	struct canfd_frame *last_frames;</span>
<span class="p_add">+	/* void pointers to arrays of struct can[fd]_frame */</span>
<span class="p_add">+	void *frames;</span>
<span class="p_add">+	void *last_frames;</span>
 	struct canfd_frame sframe;
 	struct canfd_frame last_sframe;
 	struct sock *sk;
<span class="p_chunk">@@ -681,7 +682,7 @@</span> <span class="p_context"> static void bcm_rx_handler(struct sk_buff *skb, void *data)</span>
 
 	if (op-&gt;flags &amp; RX_FILTER_ID) {
 		/* the easiest case */
<span class="p_del">-		bcm_rx_update_and_send(op, &amp;op-&gt;last_frames[0], rxframe);</span>
<span class="p_add">+		bcm_rx_update_and_send(op, op-&gt;last_frames, rxframe);</span>
 		goto rx_starttimer;
 	}
 
<span class="p_chunk">@@ -1068,7 +1069,7 @@</span> <span class="p_context"> static int bcm_rx_setup(struct bcm_msg_head *msg_head, struct msghdr *msg,</span>
 
 		if (msg_head-&gt;nframes) {
 			/* update CAN frames content */
<span class="p_del">-			err = memcpy_from_msg((u8 *)op-&gt;frames, msg,</span>
<span class="p_add">+			err = memcpy_from_msg(op-&gt;frames, msg,</span>
 					      msg_head-&gt;nframes * op-&gt;cfsiz);
 			if (err &lt; 0)
 				return err;
<span class="p_chunk">@@ -1118,7 +1119,7 @@</span> <span class="p_context"> static int bcm_rx_setup(struct bcm_msg_head *msg_head, struct msghdr *msg,</span>
 		}
 
 		if (msg_head-&gt;nframes) {
<span class="p_del">-			err = memcpy_from_msg((u8 *)op-&gt;frames, msg,</span>
<span class="p_add">+			err = memcpy_from_msg(op-&gt;frames, msg,</span>
 					      msg_head-&gt;nframes * op-&gt;cfsiz);
 			if (err &lt; 0) {
 				if (op-&gt;frames != &amp;op-&gt;sframe)
<span class="p_chunk">@@ -1163,6 +1164,7 @@</span> <span class="p_context"> static int bcm_rx_setup(struct bcm_msg_head *msg_head, struct msghdr *msg,</span>
 	/* check flags */
 
 	if (op-&gt;flags &amp; RX_RTR_FRAME) {
<span class="p_add">+		struct canfd_frame *frame0 = op-&gt;frames;</span>
 
 		/* no timers in RTR-mode */
 		hrtimer_cancel(&amp;op-&gt;thrtimer);
<span class="p_chunk">@@ -1174,8 +1176,8 @@</span> <span class="p_context"> static int bcm_rx_setup(struct bcm_msg_head *msg_head, struct msghdr *msg,</span>
 		 * prevent a full-load-loopback-test ... ;-]
 		 */
 		if ((op-&gt;flags &amp; TX_CP_CAN_ID) ||
<span class="p_del">-		    (op-&gt;frames[0].can_id == op-&gt;can_id))</span>
<span class="p_del">-			op-&gt;frames[0].can_id = op-&gt;can_id &amp; ~CAN_RTR_FLAG;</span>
<span class="p_add">+		    (frame0-&gt;can_id == op-&gt;can_id))</span>
<span class="p_add">+			frame0-&gt;can_id = op-&gt;can_id &amp; ~CAN_RTR_FLAG;</span>
 
 	} else {
 		if (op-&gt;flags &amp; SETTIMER) {
<span class="p_header">diff --git a/net/core/flow_dissector.c b/net/core/flow_dissector.c</span>
<span class="p_header">index 5550a86f7264..396aac7e6e79 100644</span>
<span class="p_header">--- a/net/core/flow_dissector.c</span>
<span class="p_header">+++ b/net/core/flow_dissector.c</span>
<span class="p_chunk">@@ -945,4 +945,4 @@</span> <span class="p_context"> static int __init init_default_flow_dissectors(void)</span>
 	return 0;
 }
 
<span class="p_del">-late_initcall_sync(init_default_flow_dissectors);</span>
<span class="p_add">+core_initcall(init_default_flow_dissectors);</span>
<span class="p_header">diff --git a/net/wireless/core.h b/net/wireless/core.h</span>
<span class="p_header">index eee91443924d..66f2a1145d7c 100644</span>
<span class="p_header">--- a/net/wireless/core.h</span>
<span class="p_header">+++ b/net/wireless/core.h</span>
<span class="p_chunk">@@ -71,6 +71,7 @@</span> <span class="p_context"> struct cfg80211_registered_device {</span>
 	struct list_head bss_list;
 	struct rb_root bss_tree;
 	u32 bss_generation;
<span class="p_add">+	u32 bss_entries;</span>
 	struct cfg80211_scan_request *scan_req; /* protected by RTNL */
 	struct sk_buff *scan_msg;
 	struct cfg80211_sched_scan_request __rcu *sched_scan_req;
<span class="p_header">diff --git a/net/wireless/scan.c b/net/wireless/scan.c</span>
<span class="p_header">index 0358e12be54b..438143a3827d 100644</span>
<span class="p_header">--- a/net/wireless/scan.c</span>
<span class="p_header">+++ b/net/wireless/scan.c</span>
<span class="p_chunk">@@ -57,6 +57,19 @@</span> <span class="p_context"></span>
  * also linked into the probe response struct.
  */
 
<span class="p_add">+/*</span>
<span class="p_add">+ * Limit the number of BSS entries stored in mac80211. Each one is</span>
<span class="p_add">+ * a bit over 4k at most, so this limits to roughly 4-5M of memory.</span>
<span class="p_add">+ * If somebody wants to really attack this though, they&#39;d likely</span>
<span class="p_add">+ * use small beacons, and only one type of frame, limiting each of</span>
<span class="p_add">+ * the entries to a much smaller size (in order to generate more</span>
<span class="p_add">+ * entries in total, so overhead is bigger.)</span>
<span class="p_add">+ */</span>
<span class="p_add">+static int bss_entries_limit = 1000;</span>
<span class="p_add">+module_param(bss_entries_limit, int, 0644);</span>
<span class="p_add">+MODULE_PARM_DESC(bss_entries_limit,</span>
<span class="p_add">+                 &quot;limit to number of scan BSS entries (per wiphy, default 1000)&quot;);</span>
<span class="p_add">+</span>
 #define IEEE80211_SCAN_RESULT_EXPIRE	(30 * HZ)
 
 static void bss_free(struct cfg80211_internal_bss *bss)
<span class="p_chunk">@@ -137,6 +150,10 @@</span> <span class="p_context"> static bool __cfg80211_unlink_bss(struct cfg80211_registered_device *rdev,</span>
 
 	list_del_init(&amp;bss-&gt;list);
 	rb_erase(&amp;bss-&gt;rbn, &amp;rdev-&gt;bss_tree);
<span class="p_add">+	rdev-&gt;bss_entries--;</span>
<span class="p_add">+	WARN_ONCE((rdev-&gt;bss_entries == 0) ^ list_empty(&amp;rdev-&gt;bss_list),</span>
<span class="p_add">+		  &quot;rdev bss entries[%d]/list[empty:%d] corruption\n&quot;,</span>
<span class="p_add">+		  rdev-&gt;bss_entries, list_empty(&amp;rdev-&gt;bss_list));</span>
 	bss_ref_put(rdev, bss);
 	return true;
 }
<span class="p_chunk">@@ -163,6 +180,40 @@</span> <span class="p_context"> static void __cfg80211_bss_expire(struct cfg80211_registered_device *rdev,</span>
 		rdev-&gt;bss_generation++;
 }
 
<span class="p_add">+static bool cfg80211_bss_expire_oldest(struct cfg80211_registered_device *rdev)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct cfg80211_internal_bss *bss, *oldest = NULL;</span>
<span class="p_add">+	bool ret;</span>
<span class="p_add">+</span>
<span class="p_add">+	lockdep_assert_held(&amp;rdev-&gt;bss_lock);</span>
<span class="p_add">+</span>
<span class="p_add">+	list_for_each_entry(bss, &amp;rdev-&gt;bss_list, list) {</span>
<span class="p_add">+		if (atomic_read(&amp;bss-&gt;hold))</span>
<span class="p_add">+			continue;</span>
<span class="p_add">+</span>
<span class="p_add">+		if (!list_empty(&amp;bss-&gt;hidden_list) &amp;&amp;</span>
<span class="p_add">+		    !bss-&gt;pub.hidden_beacon_bss)</span>
<span class="p_add">+			continue;</span>
<span class="p_add">+</span>
<span class="p_add">+		if (oldest &amp;&amp; time_before(oldest-&gt;ts, bss-&gt;ts))</span>
<span class="p_add">+			continue;</span>
<span class="p_add">+		oldest = bss;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	if (WARN_ON(!oldest))</span>
<span class="p_add">+		return false;</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * The callers make sure to increase rdev-&gt;bss_generation if anything</span>
<span class="p_add">+	 * gets removed (and a new entry added), so there&#39;s no need to also do</span>
<span class="p_add">+	 * it here.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+</span>
<span class="p_add">+	ret = __cfg80211_unlink_bss(rdev, oldest);</span>
<span class="p_add">+	WARN_ON(!ret);</span>
<span class="p_add">+	return ret;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 void ___cfg80211_scan_done(struct cfg80211_registered_device *rdev,
 			   bool send_message)
 {
<span class="p_chunk">@@ -693,6 +744,7 @@</span> <span class="p_context"> static bool cfg80211_combine_bsses(struct cfg80211_registered_device *rdev,</span>
 	const u8 *ie;
 	int i, ssidlen;
 	u8 fold = 0;
<span class="p_add">+	u32 n_entries = 0;</span>
 
 	ies = rcu_access_pointer(new-&gt;pub.beacon_ies);
 	if (WARN_ON(!ies))
<span class="p_chunk">@@ -716,6 +768,12 @@</span> <span class="p_context"> static bool cfg80211_combine_bsses(struct cfg80211_registered_device *rdev,</span>
 	/* This is the bad part ... */
 
 	list_for_each_entry(bss, &amp;rdev-&gt;bss_list, list) {
<span class="p_add">+		/*</span>
<span class="p_add">+		 * we&#39;re iterating all the entries anyway, so take the</span>
<span class="p_add">+		 * opportunity to validate the list length accounting</span>
<span class="p_add">+		 */</span>
<span class="p_add">+		n_entries++;</span>
<span class="p_add">+</span>
 		if (!ether_addr_equal(bss-&gt;pub.bssid, new-&gt;pub.bssid))
 			continue;
 		if (bss-&gt;pub.channel != new-&gt;pub.channel)
<span class="p_chunk">@@ -744,6 +802,10 @@</span> <span class="p_context"> static bool cfg80211_combine_bsses(struct cfg80211_registered_device *rdev,</span>
 				   new-&gt;pub.beacon_ies);
 	}
 
<span class="p_add">+	WARN_ONCE(n_entries != rdev-&gt;bss_entries,</span>
<span class="p_add">+		  &quot;rdev bss entries[%d]/list[len:%d] corruption\n&quot;,</span>
<span class="p_add">+		  rdev-&gt;bss_entries, n_entries);</span>
<span class="p_add">+</span>
 	return true;
 }
 
<span class="p_chunk">@@ -898,7 +960,14 @@</span> <span class="p_context"> cfg80211_bss_update(struct cfg80211_registered_device *rdev,</span>
 			}
 		}
 
<span class="p_add">+		if (rdev-&gt;bss_entries &gt;= bss_entries_limit &amp;&amp;</span>
<span class="p_add">+		    !cfg80211_bss_expire_oldest(rdev)) {</span>
<span class="p_add">+			kfree(new);</span>
<span class="p_add">+			goto drop;</span>
<span class="p_add">+		}</span>
<span class="p_add">+</span>
 		list_add_tail(&amp;new-&gt;list, &amp;rdev-&gt;bss_list);
<span class="p_add">+		rdev-&gt;bss_entries++;</span>
 		rb_insert_bss(rdev, new);
 		found = new;
 	}
<span class="p_header">diff --git a/security/apparmor/domain.c b/security/apparmor/domain.c</span>
<span class="p_header">index fc3036b34e51..a4d90aa1045a 100644</span>
<span class="p_header">--- a/security/apparmor/domain.c</span>
<span class="p_header">+++ b/security/apparmor/domain.c</span>
<span class="p_chunk">@@ -621,8 +621,8 @@</span> <span class="p_context"> int aa_change_hat(const char *hats[], int count, u64 token, bool permtest)</span>
 	/* released below */
 	cred = get_current_cred();
 	cxt = cred_cxt(cred);
<span class="p_del">-	profile = aa_cred_profile(cred);</span>
<span class="p_del">-	previous_profile = cxt-&gt;previous;</span>
<span class="p_add">+	profile = aa_get_newest_profile(aa_cred_profile(cred));</span>
<span class="p_add">+	previous_profile = aa_get_newest_profile(cxt-&gt;previous);</span>
 
 	if (unconfined(profile)) {
 		info = &quot;unconfined&quot;;
<span class="p_chunk">@@ -718,6 +718,8 @@</span> <span class="p_context"> audit:</span>
 out:
 	aa_put_profile(hat);
 	kfree(name);
<span class="p_add">+	aa_put_profile(profile);</span>
<span class="p_add">+	aa_put_profile(previous_profile);</span>
 	put_cred(cred);
 
 	return error;

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



