
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>[v1,10/16] kvm: arm/arm64: Prepare for VM specific stage2 translations - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    [v1,10/16] kvm: arm/arm64: Prepare for VM specific stage2 translations</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=114661">Suzuki K. Poulose</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>Jan. 9, 2018, 7:04 p.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;20180109190414.4017-11-suzuki.poulose@arm.com&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/10153161/mbox/"
   >mbox</a>
|
   <a href="/patch/10153161/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/10153161/">/patch/10153161/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
	[172.30.200.125])
	by pdx-korg-patchwork.web.codeaurora.org (Postfix) with ESMTP id
	691BC60596 for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Tue,  9 Jan 2018 19:08:17 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 5BEDF2858F
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Tue,  9 Jan 2018 19:08:17 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id 4FB8F28578; Tue,  9 Jan 2018 19:08:17 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-6.9 required=2.0 tests=BAYES_00,RCVD_IN_DNSWL_HI
	autolearn=unavailable version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id E7A5428578
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Tue,  9 Jan 2018 19:08:15 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S964809AbeAITFU (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Tue, 9 Jan 2018 14:05:20 -0500
Received: from usa-sjc-mx-foss1.foss.arm.com ([217.140.101.70]:59874 &quot;EHLO
	foss.arm.com&quot; rhost-flags-OK-OK-OK-OK) by vger.kernel.org with ESMTP
	id S935023AbeAITFQ (ORCPT &lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Tue, 9 Jan 2018 14:05:16 -0500
Received: from usa-sjc-imap-foss1.foss.arm.com (unknown [10.72.51.249])
	by usa-sjc-mx-foss1.foss.arm.com (Postfix) with ESMTP id 6B078165D;
	Tue,  9 Jan 2018 11:05:16 -0800 (PST)
Received: from e107814-lin.cambridge.arm.com (e107814-lin.cambridge.arm.com
	[10.1.206.28])
	by usa-sjc-imap-foss1.foss.arm.com (Postfix) with ESMTPA id
	9B8B93F318; Tue,  9 Jan 2018 11:05:13 -0800 (PST)
From: Suzuki K Poulose &lt;suzuki.poulose@arm.com&gt;
To: linux-arm-kernel@lists.infradead.org
Cc: kvm@vger.kernel.org, kvmarm@lists.cs.columbia.edu,
	christoffer.dall@linaro.org, marc.zyngier@arm.com,
	linux-kernel@vger.kernel.org, kristina.martsenko@arm.com,
	peter.maydell@linaro.org, suzuki.poulose@arm.com,
	pbonzini@redhat.com, rkrcmar@redhat.com, will.deacon@arm.com,
	ard.biesheuvel@linaro.org, mark.rutland@arm.com,
	catalin.marinas@arm.com, Christoffer Dall &lt;cdall@linaro.org&gt;
Subject: [PATCH v1 10/16] kvm: arm/arm64: Prepare for VM specific stage2
	translations
Date: Tue,  9 Jan 2018 19:04:05 +0000
Message-Id: &lt;20180109190414.4017-11-suzuki.poulose@arm.com&gt;
X-Mailer: git-send-email 2.13.6
In-Reply-To: &lt;20180109190414.4017-1-suzuki.poulose@arm.com&gt;
References: &lt;20180109190414.4017-1-suzuki.poulose@arm.com&gt;
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=114661">Suzuki K. Poulose</a> - Jan. 9, 2018, 7:04 p.m.</div>
<pre class="content">
Right now the stage2 page table for a VM is hard coded, assuming
an IPA of 40bits. As we are about to add support for per VM IPA,
prepare the stage2 page table helpers to accept the kvm instance
to make the right decision. No functional changes.

Cc: Marc Zyngier &lt;marc.zyngier@arm.com&gt;
Cc: Christoffer Dall &lt;cdall@linaro.org&gt;
<span class="signed-off-by">Signed-off-by: Suzuki K Poulose &lt;suzuki.poulose@arm.com&gt;</span>
---
 arch/arm/include/asm/kvm_arm.h                |   2 -
 arch/arm/include/asm/kvm_mmu.h                |  11 ++-
 arch/arm/include/asm/stage2_pgtable.h         |  46 ++++++-----
 arch/arm64/include/asm/kvm_mmu.h              |   6 +-
 arch/arm64/include/asm/pgtable.h              |   2 +-
 arch/arm64/include/asm/stage2_pgtable-nopmd.h |  18 ++--
 arch/arm64/include/asm/stage2_pgtable-nopud.h |  16 ++--
 arch/arm64/include/asm/stage2_pgtable.h       |  49 ++++++-----
 virt/kvm/arm/mmu.c                            | 114 +++++++++++++-------------
 virt/kvm/arm/vgic/vgic-kvm-device.c           |   2 +-
 10 files changed, 140 insertions(+), 126 deletions(-)
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/arch/arm/include/asm/kvm_arm.h b/arch/arm/include/asm/kvm_arm.h</span>
<span class="p_header">index 3ab8b3781bfe..4ebaf0c29723 100644</span>
<span class="p_header">--- a/arch/arm/include/asm/kvm_arm.h</span>
<span class="p_header">+++ b/arch/arm/include/asm/kvm_arm.h</span>
<span class="p_chunk">@@ -133,8 +133,6 @@</span> <span class="p_context"></span>
  * space.
  */
 #define KVM_PHYS_SHIFT	(40)
<span class="p_del">-#define KVM_PHYS_SIZE	(_AC(1, ULL) &lt;&lt; KVM_PHYS_SHIFT)</span>
<span class="p_del">-#define KVM_PHYS_MASK	(KVM_PHYS_SIZE - _AC(1, ULL))</span>
 #define PTRS_PER_S2_PGD	(_AC(1, ULL) &lt;&lt; (KVM_PHYS_SHIFT - 30))
 
 /* Virtualization Translation Control Register (VTCR) bits */
<span class="p_header">diff --git a/arch/arm/include/asm/kvm_mmu.h b/arch/arm/include/asm/kvm_mmu.h</span>
<span class="p_header">index 8c5643e2eea4..a3312f87a6e0 100644</span>
<span class="p_header">--- a/arch/arm/include/asm/kvm_mmu.h</span>
<span class="p_header">+++ b/arch/arm/include/asm/kvm_mmu.h</span>
<span class="p_chunk">@@ -29,17 +29,24 @@</span> <span class="p_context"></span>
 #define kern_hyp_va(kva)	(kva)
 
 /*
<span class="p_del">- * KVM_MMU_CACHE_MIN_PAGES is the number of stage2 page table translation levels.</span>
<span class="p_add">+ * kvm_mmu_cache_min_pages is the number of stage2 page table</span>
<span class="p_add">+ * translation levels excluding the top level.</span>
  */
<span class="p_del">-#define KVM_MMU_CACHE_MIN_PAGES	2</span>
<span class="p_add">+#define kvm_mmu_cache_min_pages(kvm)	2</span>
 
 #ifndef __ASSEMBLY__
 
 #include &lt;linux/highmem.h&gt;
 #include &lt;asm/cacheflush.h&gt;
<span class="p_add">+#include &lt;asm/kvm_arm.h&gt;</span>
 #include &lt;asm/pgalloc.h&gt;
 #include &lt;asm/stage2_pgtable.h&gt;
 
<span class="p_add">+#define kvm_phys_shift(kvm)		KVM_PHYS_SHIFT</span>
<span class="p_add">+#define kvm_phys_size(kvm)		(_AC(1, ULL) &lt;&lt; kvm_phys_shift(kvm))</span>
<span class="p_add">+#define kvm_phys_mask(kvm)		(kvm_phys_size(kvm) - _AC(1, ULL))</span>
<span class="p_add">+</span>
<span class="p_add">+#define stage2_pgd_size(kvm)	(PTRS_PER_S2_PGD * sizeof(pgd_t))</span>
 int create_hyp_mappings(void *from, void *to, pgprot_t prot);
 int create_hyp_io_mappings(void *from, void *to, phys_addr_t);
 void free_hyp_pgds(void);
<span class="p_header">diff --git a/arch/arm/include/asm/stage2_pgtable.h b/arch/arm/include/asm/stage2_pgtable.h</span>
<span class="p_header">index 460d616bb2d6..e22ae94f0bf9 100644</span>
<span class="p_header">--- a/arch/arm/include/asm/stage2_pgtable.h</span>
<span class="p_header">+++ b/arch/arm/include/asm/stage2_pgtable.h</span>
<span class="p_chunk">@@ -19,43 +19,45 @@</span> <span class="p_context"></span>
 #ifndef __ARM_S2_PGTABLE_H_
 #define __ARM_S2_PGTABLE_H_
 
<span class="p_del">-#define stage2_pgd_none(pgd)			pgd_none(pgd)</span>
<span class="p_del">-#define stage2_pgd_clear(pgd)			pgd_clear(pgd)</span>
<span class="p_del">-#define stage2_pgd_present(pgd)			pgd_present(pgd)</span>
<span class="p_del">-#define stage2_pgd_populate(pgd, pud)		pgd_populate(NULL, pgd, pud)</span>
<span class="p_del">-#define stage2_pud_offset(pgd, address)		pud_offset(pgd, address)</span>
<span class="p_del">-#define stage2_pud_free(pud)			pud_free(NULL, pud)</span>
<span class="p_del">-</span>
<span class="p_del">-#define stage2_pud_none(pud)			pud_none(pud)</span>
<span class="p_del">-#define stage2_pud_clear(pud)			pud_clear(pud)</span>
<span class="p_del">-#define stage2_pud_present(pud)			pud_present(pud)</span>
<span class="p_del">-#define stage2_pud_populate(pud, pmd)		pud_populate(NULL, pud, pmd)</span>
<span class="p_del">-#define stage2_pmd_offset(pud, address)		pmd_offset(pud, address)</span>
<span class="p_del">-#define stage2_pmd_free(pmd)			pmd_free(NULL, pmd)</span>
<span class="p_del">-</span>
<span class="p_del">-#define stage2_pud_huge(pud)			pud_huge(pud)</span>
<span class="p_add">+#define stage2_pgd_none(kvm, pgd)		pgd_none(pgd)</span>
<span class="p_add">+#define stage2_pgd_clear(kvm, pgd)		pgd_clear(pgd)</span>
<span class="p_add">+#define stage2_pgd_present(kvm, pgd)		pgd_present(pgd)</span>
<span class="p_add">+#define stage2_pgd_populate(kvm, pgd, pud)	pgd_populate(NULL, pgd, pud)</span>
<span class="p_add">+#define stage2_pud_offset(kvm, pgd, address)	pud_offset(pgd, address)</span>
<span class="p_add">+#define stage2_pud_free(kvm, pud)		pud_free(NULL, pud)</span>
<span class="p_add">+</span>
<span class="p_add">+#define stage2_pud_none(kvm, pud)		pud_none(pud)</span>
<span class="p_add">+#define stage2_pud_clear(kvm, pud)		pud_clear(pud)</span>
<span class="p_add">+#define stage2_pud_present(kvm, pud)		pud_present(pud)</span>
<span class="p_add">+#define stage2_pud_populate(kvm, pud, pmd)	pud_populate(NULL, pud, pmd)</span>
<span class="p_add">+#define stage2_pmd_offset(kvm, pud, address)	pmd_offset(pud, address)</span>
<span class="p_add">+#define stage2_pmd_free(kvm, pmd)		pmd_free(NULL, pmd)</span>
<span class="p_add">+</span>
<span class="p_add">+#define stage2_pud_huge(kvm, pud)		pud_huge(pud)</span>
 
 /* Open coded p*d_addr_end that can deal with 64bit addresses */
<span class="p_del">-static inline phys_addr_t stage2_pgd_addr_end(phys_addr_t addr, phys_addr_t end)</span>
<span class="p_add">+static inline phys_addr_t</span>
<span class="p_add">+stage2_pgd_addr_end(struct kvm *kvm, phys_addr_t addr, phys_addr_t end)</span>
 {
 	phys_addr_t boundary = (addr + PGDIR_SIZE) &amp; PGDIR_MASK;
 
 	return (boundary - 1 &lt; end - 1) ? boundary : end;
 }
 
<span class="p_del">-#define stage2_pud_addr_end(addr, end)		(end)</span>
<span class="p_add">+#define stage2_pud_addr_end(kvm, addr, end)	(end)</span>
 
<span class="p_del">-static inline phys_addr_t stage2_pmd_addr_end(phys_addr_t addr, phys_addr_t end)</span>
<span class="p_add">+static inline phys_addr_t</span>
<span class="p_add">+stage2_pmd_addr_end(struct kvm *kvm, phys_addr_t addr, phys_addr_t end)</span>
 {
 	phys_addr_t boundary = (addr + PMD_SIZE) &amp; PMD_MASK;
 
 	return (boundary - 1 &lt; end - 1) ? boundary : end;
 }
 
<span class="p_del">-#define stage2_pgd_index(addr)				pgd_index(addr)</span>
<span class="p_add">+#define stage2_pgd_index(kvm, addr)		pgd_index(addr)</span>
 
<span class="p_del">-#define stage2_pte_table_empty(ptep)			kvm_page_empty(ptep)</span>
<span class="p_del">-#define stage2_pmd_table_empty(pmdp)			kvm_page_empty(pmdp)</span>
<span class="p_del">-#define stage2_pud_table_empty(pudp)			false</span>
<span class="p_add">+#define stage2_pte_table_empty(kvm, ptep)	kvm_page_empty(ptep)</span>
<span class="p_add">+#define stage2_pmd_table_empty(kvm, pmdp)	kvm_page_empty(pmdp)</span>
<span class="p_add">+#define stage2_pud_table_empty(kvm, pudp)	false</span>
 
 #endif	/* __ARM_S2_PGTABLE_H_ */
<span class="p_header">diff --git a/arch/arm64/include/asm/kvm_mmu.h b/arch/arm64/include/asm/kvm_mmu.h</span>
<span class="p_header">index b33bdb5eeb3d..de542aa72d80 100644</span>
<span class="p_header">--- a/arch/arm64/include/asm/kvm_mmu.h</span>
<span class="p_header">+++ b/arch/arm64/include/asm/kvm_mmu.h</span>
<span class="p_chunk">@@ -134,8 +134,10 @@</span> <span class="p_context"> static inline unsigned long __kern_hyp_va(unsigned long v)</span>
  * We currently only support a 40bit IPA.
  */
 #define KVM_PHYS_SHIFT	(40)
<span class="p_del">-#define KVM_PHYS_SIZE	(1UL &lt;&lt; KVM_PHYS_SHIFT)</span>
<span class="p_del">-#define KVM_PHYS_MASK	(KVM_PHYS_SIZE - 1UL)</span>
<span class="p_add">+</span>
<span class="p_add">+#define kvm_phys_shift(kvm)		KVM_PHYS_SHIFT</span>
<span class="p_add">+#define kvm_phys_size(kvm)		(_AC(1, ULL) &lt;&lt; kvm_phys_shift(kvm))</span>
<span class="p_add">+#define kvm_phys_mask(kvm)		(kvm_phys_size(kvm) - _AC(1, ULL))</span>
 
 #include &lt;asm/stage2_pgtable.h&gt;
 
<span class="p_header">diff --git a/arch/arm64/include/asm/pgtable.h b/arch/arm64/include/asm/pgtable.h</span>
<span class="p_header">index a1c6e93a1a11..50d72be469ca 100644</span>
<span class="p_header">--- a/arch/arm64/include/asm/pgtable.h</span>
<span class="p_header">+++ b/arch/arm64/include/asm/pgtable.h</span>
<span class="p_chunk">@@ -467,7 +467,7 @@</span> <span class="p_context"> static inline phys_addr_t pmd_page_paddr(pmd_t pmd)</span>
 
 #define __raw_pud_none(pud)		(!pud_val((pud)))
 #define __raw_pud_bad(pud)		(!(pud_val((pud)) &amp; PUD_TABLE_BIT))
<span class="p_del">-#define __raw_pud_present(pud)	pte_present(pud_pte((pud)))</span>
<span class="p_add">+#define __raw_pud_present(pud)		pte_present(pud_pte((pud)))</span>
 
 static inline int __raw_pud_huge(pud_t pud)
 {
<span class="p_header">diff --git a/arch/arm64/include/asm/stage2_pgtable-nopmd.h b/arch/arm64/include/asm/stage2_pgtable-nopmd.h</span>
<span class="p_header">index 2656a0fd05a6..0280dedbf75f 100644</span>
<span class="p_header">--- a/arch/arm64/include/asm/stage2_pgtable-nopmd.h</span>
<span class="p_header">+++ b/arch/arm64/include/asm/stage2_pgtable-nopmd.h</span>
<span class="p_chunk">@@ -26,17 +26,17 @@</span> <span class="p_context"></span>
 #define S2_PMD_SIZE		(1UL &lt;&lt; S2_PMD_SHIFT)
 #define S2_PMD_MASK		(~(S2_PMD_SIZE-1))
 
<span class="p_del">-#define stage2_pud_none(pud)			(0)</span>
<span class="p_del">-#define stage2_pud_present(pud)			(1)</span>
<span class="p_del">-#define stage2_pud_clear(pud)			do { } while (0)</span>
<span class="p_del">-#define stage2_pud_populate(pud, pmd)		do { } while (0)</span>
<span class="p_del">-#define stage2_pmd_offset(pud, address)		((pmd_t *)(pud))</span>
<span class="p_add">+#define stage2_pud_none(kvm, pud)		(0)</span>
<span class="p_add">+#define stage2_pud_present(kvm, pud)		(1)</span>
<span class="p_add">+#define stage2_pud_clear(kvm, pud)		do { } while (0)</span>
<span class="p_add">+#define stage2_pud_populate(kvm, pud, pmd)	do { } while (0)</span>
<span class="p_add">+#define stage2_pmd_offset(kvm, pud, address)	((pmd_t *)(pud))</span>
 
<span class="p_del">-#define stage2_pmd_free(pmd)			do { } while (0)</span>
<span class="p_add">+#define stage2_pmd_free(kvm, pmd)		do { } while (0)</span>
 
<span class="p_del">-#define stage2_pmd_addr_end(addr, end)		(end)</span>
<span class="p_add">+#define stage2_pmd_addr_end(kvm, addr, end)	(end)</span>
 
<span class="p_del">-#define stage2_pud_huge(pud)			(0)</span>
<span class="p_del">-#define stage2_pmd_table_empty(pmdp)		(0)</span>
<span class="p_add">+#define stage2_pud_huge(kvm, pud)		(0)</span>
<span class="p_add">+#define stage2_pmd_table_empty(kvm, pmdp)	(0)</span>
 
 #endif
<span class="p_header">diff --git a/arch/arm64/include/asm/stage2_pgtable-nopud.h b/arch/arm64/include/asm/stage2_pgtable-nopud.h</span>
<span class="p_header">index 5ee87b54ebf3..cd6304e203be 100644</span>
<span class="p_header">--- a/arch/arm64/include/asm/stage2_pgtable-nopud.h</span>
<span class="p_header">+++ b/arch/arm64/include/asm/stage2_pgtable-nopud.h</span>
<span class="p_chunk">@@ -24,16 +24,16 @@</span> <span class="p_context"></span>
 #define S2_PUD_SIZE		(_AC(1, UL) &lt;&lt; S2_PUD_SHIFT)
 #define S2_PUD_MASK		(~(S2_PUD_SIZE-1))
 
<span class="p_del">-#define stage2_pgd_none(pgd)			(0)</span>
<span class="p_del">-#define stage2_pgd_present(pgd)			(1)</span>
<span class="p_del">-#define stage2_pgd_clear(pgd)			do { } while (0)</span>
<span class="p_del">-#define stage2_pgd_populate(pgd, pud)	do { } while (0)</span>
<span class="p_add">+#define stage2_pgd_none(kvm, pgd)		(0)</span>
<span class="p_add">+#define stage2_pgd_present(kvm, pgd)		(1)</span>
<span class="p_add">+#define stage2_pgd_clear(kvm, pgd)		do { } while (0)</span>
<span class="p_add">+#define stage2_pgd_populate(kvm, pgd, pud)	do { } while (0)</span>
 
<span class="p_del">-#define stage2_pud_offset(pgd, address)		((pud_t *)(pgd))</span>
<span class="p_add">+#define stage2_pud_offset(kvm, pgd, address)	((pud_t *)(pgd))</span>
 
<span class="p_del">-#define stage2_pud_free(x)			do { } while (0)</span>
<span class="p_add">+#define stage2_pud_free(kvm, x)			do { } while (0)</span>
 
<span class="p_del">-#define stage2_pud_addr_end(addr, end)		(end)</span>
<span class="p_del">-#define stage2_pud_table_empty(pmdp)		(0)</span>
<span class="p_add">+#define stage2_pud_addr_end(kvm, addr, end)	(end)</span>
<span class="p_add">+#define stage2_pud_table_empty(kvm, pmdp)	(0)</span>
 
 #endif
<span class="p_header">diff --git a/arch/arm64/include/asm/stage2_pgtable.h b/arch/arm64/include/asm/stage2_pgtable.h</span>
<span class="p_header">index 8b68099348e5..057a405fa727 100644</span>
<span class="p_header">--- a/arch/arm64/include/asm/stage2_pgtable.h</span>
<span class="p_header">+++ b/arch/arm64/include/asm/stage2_pgtable.h</span>
<span class="p_chunk">@@ -65,10 +65,10 @@</span> <span class="p_context"></span>
 #define PTRS_PER_S2_PGD			(1 &lt;&lt; (KVM_PHYS_SHIFT - S2_PGDIR_SHIFT))
 
 /*
<span class="p_del">- * KVM_MMU_CACHE_MIN_PAGES is the number of stage2 page table translation</span>
<span class="p_add">+ * kvm_mmmu_cache_min_pages is the number of stage2 page table translation</span>
  * levels in addition to the PGD.
  */
<span class="p_del">-#define KVM_MMU_CACHE_MIN_PAGES		(STAGE2_PGTABLE_LEVELS - 1)</span>
<span class="p_add">+#define kvm_mmu_cache_min_pages(kvm)	(STAGE2_PGTABLE_LEVELS - 1)</span>
 
 
 #if STAGE2_PGTABLE_LEVELS &gt; 3
<span class="p_chunk">@@ -77,16 +77,17 @@</span> <span class="p_context"></span>
 #define S2_PUD_SIZE			(_AC(1, UL) &lt;&lt; S2_PUD_SHIFT)
 #define S2_PUD_MASK			(~(S2_PUD_SIZE - 1))
 
<span class="p_del">-#define stage2_pgd_none(pgd)				pgd_none(pgd)</span>
<span class="p_del">-#define stage2_pgd_clear(pgd)				pgd_clear(pgd)</span>
<span class="p_del">-#define stage2_pgd_present(pgd)				pgd_present(pgd)</span>
<span class="p_del">-#define stage2_pgd_populate(pgd, pud)			pgd_populate(NULL, pgd, pud)</span>
<span class="p_del">-#define stage2_pud_offset(pgd, address)			pud_offset(pgd, address)</span>
<span class="p_del">-#define stage2_pud_free(pud)				pud_free(NULL, pud)</span>
<span class="p_add">+#define stage2_pgd_none(kvm, pgd)		pgd_none(pgd)</span>
<span class="p_add">+#define stage2_pgd_clear(kvm, pgd)		pgd_clear(pgd)</span>
<span class="p_add">+#define stage2_pgd_present(kvm, pgd)		pgd_present(pgd)</span>
<span class="p_add">+#define stage2_pgd_populate(kvm, pgd, pud)	pgd_populate(NULL, pgd, pud)</span>
<span class="p_add">+#define stage2_pud_offset(kvm, pgd, address)	pud_offset(pgd, address)</span>
<span class="p_add">+#define stage2_pud_free(kvm, pud)		pud_free(NULL, pud)</span>
 
<span class="p_del">-#define stage2_pud_table_empty(pudp)			kvm_page_empty(pudp)</span>
<span class="p_add">+#define stage2_pud_table_empty(kvm, pudp)	kvm_page_empty(pudp)</span>
 
<span class="p_del">-static inline phys_addr_t stage2_pud_addr_end(phys_addr_t addr, phys_addr_t end)</span>
<span class="p_add">+static inline phys_addr_t</span>
<span class="p_add">+stage2_pud_addr_end(struct kvm *kvm, phys_addr_t addr, phys_addr_t end)</span>
 {
 	phys_addr_t boundary = (addr + S2_PUD_SIZE) &amp; S2_PUD_MASK;
 
<span class="p_chunk">@@ -102,17 +103,18 @@</span> <span class="p_context"> static inline phys_addr_t stage2_pud_addr_end(phys_addr_t addr, phys_addr_t end)</span>
 #define S2_PMD_SIZE			(_AC(1, UL) &lt;&lt; S2_PMD_SHIFT)
 #define S2_PMD_MASK			(~(S2_PMD_SIZE - 1))
 
<span class="p_del">-#define stage2_pud_none(pud)				pud_none(pud)</span>
<span class="p_del">-#define stage2_pud_clear(pud)				pud_clear(pud)</span>
<span class="p_del">-#define stage2_pud_present(pud)				pud_present(pud)</span>
<span class="p_del">-#define stage2_pud_populate(pud, pmd)			pud_populate(NULL, pud, pmd)</span>
<span class="p_del">-#define stage2_pmd_offset(pud, address)			pmd_offset(pud, address)</span>
<span class="p_del">-#define stage2_pmd_free(pmd)				pmd_free(NULL, pmd)</span>
<span class="p_add">+#define stage2_pud_none(kvm, pud)		pud_none(pud)</span>
<span class="p_add">+#define stage2_pud_clear(kvm, pud)		pud_clear(pud)</span>
<span class="p_add">+#define stage2_pud_present(kvm, pud)		pud_present(pud)</span>
<span class="p_add">+#define stage2_pud_populate(kvm, pud, pmd)	pud_populate(NULL, pud, pmd)</span>
<span class="p_add">+#define stage2_pmd_offset(kvm, pud, address)	pmd_offset(pud, address)</span>
<span class="p_add">+#define stage2_pmd_free(kvm, pmd)		pmd_free(NULL, pmd)</span>
 
<span class="p_del">-#define stage2_pud_huge(pud)				pud_huge(pud)</span>
<span class="p_del">-#define stage2_pmd_table_empty(pmdp)			kvm_page_empty(pmdp)</span>
<span class="p_add">+#define stage2_pud_huge(kvm, pud)		pud_huge(pud)</span>
<span class="p_add">+#define stage2_pmd_table_empty(kvm, pmdp)	kvm_page_empty(pmdp)</span>
 
<span class="p_del">-static inline phys_addr_t stage2_pmd_addr_end(phys_addr_t addr, phys_addr_t end)</span>
<span class="p_add">+static inline phys_addr_t</span>
<span class="p_add">+stage2_pmd_addr_end(struct kvm *kvm, phys_addr_t addr, phys_addr_t end)</span>
 {
 	phys_addr_t boundary = (addr + S2_PMD_SIZE) &amp; S2_PMD_MASK;
 
<span class="p_chunk">@@ -121,7 +123,7 @@</span> <span class="p_context"> static inline phys_addr_t stage2_pmd_addr_end(phys_addr_t addr, phys_addr_t end)</span>
 
 #endif		/* STAGE2_PGTABLE_LEVELS &gt; 2 */
 
<span class="p_del">-#define stage2_pte_table_empty(ptep)			kvm_page_empty(ptep)</span>
<span class="p_add">+#define stage2_pte_table_empty(kvm, ptep)	kvm_page_empty(ptep)</span>
 
 #if STAGE2_PGTABLE_LEVELS == 2
 #include &lt;asm/stage2_pgtable-nopmd.h&gt;
<span class="p_chunk">@@ -129,10 +131,13 @@</span> <span class="p_context"> static inline phys_addr_t stage2_pmd_addr_end(phys_addr_t addr, phys_addr_t end)</span>
 #include &lt;asm/stage2_pgtable-nopud.h&gt;
 #endif
 
<span class="p_add">+#define stage2_pgd_size(kvm)	(PTRS_PER_S2_PGD * sizeof(pgd_t))</span>
 
<span class="p_del">-#define stage2_pgd_index(addr)				(((addr) &gt;&gt; S2_PGDIR_SHIFT) &amp; (PTRS_PER_S2_PGD - 1))</span>
<span class="p_add">+#define stage2_pgd_index(kvm, addr) \</span>
<span class="p_add">+	(((addr) &gt;&gt; S2_PGDIR_SHIFT) &amp; (PTRS_PER_S2_PGD - 1))</span>
 
<span class="p_del">-static inline phys_addr_t stage2_pgd_addr_end(phys_addr_t addr, phys_addr_t end)</span>
<span class="p_add">+static inline phys_addr_t</span>
<span class="p_add">+stage2_pgd_addr_end(struct kvm *kvm, phys_addr_t addr, phys_addr_t end)</span>
 {
 	phys_addr_t boundary = (addr + S2_PGDIR_SIZE) &amp; S2_PGDIR_MASK;
 
<span class="p_header">diff --git a/virt/kvm/arm/mmu.c b/virt/kvm/arm/mmu.c</span>
<span class="p_header">index 257f2a8ccfc7..cd355aa70c61 100644</span>
<span class="p_header">--- a/virt/kvm/arm/mmu.c</span>
<span class="p_header">+++ b/virt/kvm/arm/mmu.c</span>
<span class="p_chunk">@@ -43,7 +43,6 @@</span> <span class="p_context"> static unsigned long hyp_idmap_start;</span>
 static unsigned long hyp_idmap_end;
 static phys_addr_t hyp_idmap_vector;
 
<span class="p_del">-#define S2_PGD_SIZE	(PTRS_PER_S2_PGD * sizeof(pgd_t))</span>
 #define hyp_pgd_order get_order(PTRS_PER_PGD * sizeof(pgd_t))
 
 #define KVM_S2PTE_FLAG_IS_IOMAP		(1UL &lt;&lt; 0)
<span class="p_chunk">@@ -148,20 +147,20 @@</span> <span class="p_context"> static void *mmu_memory_cache_alloc(struct kvm_mmu_memory_cache *mc)</span>
 
 static void clear_stage2_pgd_entry(struct kvm *kvm, pgd_t *pgd, phys_addr_t addr)
 {
<span class="p_del">-	pud_t *pud_table __maybe_unused = stage2_pud_offset(pgd, 0UL);</span>
<span class="p_del">-	stage2_pgd_clear(pgd);</span>
<span class="p_add">+	pud_t *pud_table __maybe_unused = stage2_pud_offset(kvm, pgd, 0UL);</span>
<span class="p_add">+	stage2_pgd_clear(kvm, pgd);</span>
 	kvm_tlb_flush_vmid_ipa(kvm, addr);
<span class="p_del">-	stage2_pud_free(pud_table);</span>
<span class="p_add">+	stage2_pud_free(kvm, pud_table);</span>
 	put_page(virt_to_page(pgd));
 }
 
 static void clear_stage2_pud_entry(struct kvm *kvm, pud_t *pud, phys_addr_t addr)
 {
<span class="p_del">-	pmd_t *pmd_table __maybe_unused = stage2_pmd_offset(pud, 0);</span>
<span class="p_del">-	VM_BUG_ON(stage2_pud_huge(*pud));</span>
<span class="p_del">-	stage2_pud_clear(pud);</span>
<span class="p_add">+	pmd_t *pmd_table __maybe_unused = stage2_pmd_offset(kvm, pud, 0);</span>
<span class="p_add">+	VM_BUG_ON(stage2_pud_huge(kvm, *pud));</span>
<span class="p_add">+	stage2_pud_clear(kvm, pud);</span>
 	kvm_tlb_flush_vmid_ipa(kvm, addr);
<span class="p_del">-	stage2_pmd_free(pmd_table);</span>
<span class="p_add">+	stage2_pmd_free(kvm, pmd_table);</span>
 	put_page(virt_to_page(pud));
 }
 
<span class="p_chunk">@@ -217,7 +216,7 @@</span> <span class="p_context"> static void unmap_stage2_ptes(struct kvm *kvm, pmd_t *pmd,</span>
 		}
 	} while (pte++, addr += PAGE_SIZE, addr != end);
 
<span class="p_del">-	if (stage2_pte_table_empty(start_pte))</span>
<span class="p_add">+	if (stage2_pte_table_empty(kvm, start_pte))</span>
 		clear_stage2_pmd_entry(kvm, pmd, start_addr);
 }
 
<span class="p_chunk">@@ -227,9 +226,9 @@</span> <span class="p_context"> static void unmap_stage2_pmds(struct kvm *kvm, pud_t *pud,</span>
 	phys_addr_t next, start_addr = addr;
 	pmd_t *pmd, *start_pmd;
 
<span class="p_del">-	start_pmd = pmd = stage2_pmd_offset(pud, addr);</span>
<span class="p_add">+	start_pmd = pmd = stage2_pmd_offset(kvm, pud, addr);</span>
 	do {
<span class="p_del">-		next = stage2_pmd_addr_end(addr, end);</span>
<span class="p_add">+		next = stage2_pmd_addr_end(kvm, addr, end);</span>
 		if (!pmd_none(*pmd)) {
 			if (pmd_thp_or_huge(*pmd)) {
 				pmd_t old_pmd = *pmd;
<span class="p_chunk">@@ -246,7 +245,7 @@</span> <span class="p_context"> static void unmap_stage2_pmds(struct kvm *kvm, pud_t *pud,</span>
 		}
 	} while (pmd++, addr = next, addr != end);
 
<span class="p_del">-	if (stage2_pmd_table_empty(start_pmd))</span>
<span class="p_add">+	if (stage2_pmd_table_empty(kvm, start_pmd))</span>
 		clear_stage2_pud_entry(kvm, pud, start_addr);
 }
 
<span class="p_chunk">@@ -256,14 +255,14 @@</span> <span class="p_context"> static void unmap_stage2_puds(struct kvm *kvm, pgd_t *pgd,</span>
 	phys_addr_t next, start_addr = addr;
 	pud_t *pud, *start_pud;
 
<span class="p_del">-	start_pud = pud = stage2_pud_offset(pgd, addr);</span>
<span class="p_add">+	start_pud = pud = stage2_pud_offset(kvm, pgd, addr);</span>
 	do {
<span class="p_del">-		next = stage2_pud_addr_end(addr, end);</span>
<span class="p_del">-		if (!stage2_pud_none(*pud)) {</span>
<span class="p_del">-			if (stage2_pud_huge(*pud)) {</span>
<span class="p_add">+		next = stage2_pud_addr_end(kvm, addr, end);</span>
<span class="p_add">+		if (!stage2_pud_none(kvm, *pud)) {</span>
<span class="p_add">+			if (stage2_pud_huge(kvm, *pud)) {</span>
 				pud_t old_pud = *pud;
 
<span class="p_del">-				stage2_pud_clear(pud);</span>
<span class="p_add">+				stage2_pud_clear(kvm, pud);</span>
 				kvm_tlb_flush_vmid_ipa(kvm, addr);
 				kvm_flush_dcache_pud(old_pud);
 				put_page(virt_to_page(pud));
<span class="p_chunk">@@ -273,7 +272,7 @@</span> <span class="p_context"> static void unmap_stage2_puds(struct kvm *kvm, pgd_t *pgd,</span>
 		}
 	} while (pud++, addr = next, addr != end);
 
<span class="p_del">-	if (stage2_pud_table_empty(start_pud))</span>
<span class="p_add">+	if (stage2_pud_table_empty(kvm, start_pud))</span>
 		clear_stage2_pgd_entry(kvm, pgd, start_addr);
 }
 
<span class="p_chunk">@@ -295,7 +294,7 @@</span> <span class="p_context"> static void unmap_stage2_range(struct kvm *kvm, phys_addr_t start, u64 size)</span>
 	phys_addr_t next;
 
 	assert_spin_locked(&amp;kvm-&gt;mmu_lock);
<span class="p_del">-	pgd = kvm-&gt;arch.pgd + stage2_pgd_index(addr);</span>
<span class="p_add">+	pgd = kvm-&gt;arch.pgd + stage2_pgd_index(kvm, addr);</span>
 	do {
 		/*
 		 * The page table shouldn&#39;t be free&#39;d as we still hold a reference
<span class="p_chunk">@@ -303,8 +302,8 @@</span> <span class="p_context"> static void unmap_stage2_range(struct kvm *kvm, phys_addr_t start, u64 size)</span>
 		 */
 		if (WARN_ON(!READ_ONCE(kvm-&gt;arch.pgd)))
 			break;
<span class="p_del">-		next = stage2_pgd_addr_end(addr, end);</span>
<span class="p_del">-		if (!stage2_pgd_none(*pgd))</span>
<span class="p_add">+		next = stage2_pgd_addr_end(kvm, addr, end);</span>
<span class="p_add">+		if (!stage2_pgd_none(kvm, *pgd))</span>
 			unmap_stage2_puds(kvm, pgd, addr, next);
 		/*
 		 * If the range is too large, release the kvm-&gt;mmu_lock
<span class="p_chunk">@@ -333,9 +332,9 @@</span> <span class="p_context"> static void stage2_flush_pmds(struct kvm *kvm, pud_t *pud,</span>
 	pmd_t *pmd;
 	phys_addr_t next;
 
<span class="p_del">-	pmd = stage2_pmd_offset(pud, addr);</span>
<span class="p_add">+	pmd = stage2_pmd_offset(kvm, pud, addr);</span>
 	do {
<span class="p_del">-		next = stage2_pmd_addr_end(addr, end);</span>
<span class="p_add">+		next = stage2_pmd_addr_end(kvm, addr, end);</span>
 		if (!pmd_none(*pmd)) {
 			if (pmd_thp_or_huge(*pmd))
 				kvm_flush_dcache_pmd(*pmd);
<span class="p_chunk">@@ -351,11 +350,11 @@</span> <span class="p_context"> static void stage2_flush_puds(struct kvm *kvm, pgd_t *pgd,</span>
 	pud_t *pud;
 	phys_addr_t next;
 
<span class="p_del">-	pud = stage2_pud_offset(pgd, addr);</span>
<span class="p_add">+	pud = stage2_pud_offset(kvm, pgd, addr);</span>
 	do {
<span class="p_del">-		next = stage2_pud_addr_end(addr, end);</span>
<span class="p_del">-		if (!stage2_pud_none(*pud)) {</span>
<span class="p_del">-			if (stage2_pud_huge(*pud))</span>
<span class="p_add">+		next = stage2_pud_addr_end(kvm, addr, end);</span>
<span class="p_add">+		if (!stage2_pud_none(kvm, *pud)) {</span>
<span class="p_add">+			if (stage2_pud_huge(kvm, *pud))</span>
 				kvm_flush_dcache_pud(*pud);
 			else
 				stage2_flush_pmds(kvm, pud, addr, next);
<span class="p_chunk">@@ -371,10 +370,10 @@</span> <span class="p_context"> static void stage2_flush_memslot(struct kvm *kvm,</span>
 	phys_addr_t next;
 	pgd_t *pgd;
 
<span class="p_del">-	pgd = kvm-&gt;arch.pgd + stage2_pgd_index(addr);</span>
<span class="p_add">+	pgd = kvm-&gt;arch.pgd + stage2_pgd_index(kvm, addr);</span>
 	do {
<span class="p_del">-		next = stage2_pgd_addr_end(addr, end);</span>
<span class="p_del">-		if (!stage2_pgd_none(*pgd))</span>
<span class="p_add">+		next = stage2_pgd_addr_end(kvm, addr, end);</span>
<span class="p_add">+		if (!stage2_pgd_none(kvm, *pgd))</span>
 			stage2_flush_puds(kvm, pgd, addr, next);
 	} while (pgd++, addr = next, addr != end);
 }
<span class="p_chunk">@@ -762,7 +761,7 @@</span> <span class="p_context"> int kvm_alloc_stage2_pgd(struct kvm *kvm)</span>
 	}
 
 	/* Allocate the HW PGD, making sure that each page gets its own refcount */
<span class="p_del">-	pgd = alloc_pages_exact(S2_PGD_SIZE, GFP_KERNEL | __GFP_ZERO);</span>
<span class="p_add">+	pgd = alloc_pages_exact(stage2_pgd_size(kvm), GFP_KERNEL | __GFP_ZERO);</span>
 	if (!pgd)
 		return -ENOMEM;
 
<span class="p_chunk">@@ -844,7 +843,7 @@</span> <span class="p_context"> static void kvm_flush_stage2_all(struct kvm *kvm)</span>
 {
 	spin_lock(&amp;kvm-&gt;mmu_lock);
 	if (kvm-&gt;arch.pgd)
<span class="p_del">-		unmap_stage2_range(kvm, 0, KVM_PHYS_SIZE);</span>
<span class="p_add">+		unmap_stage2_range(kvm, 0, kvm_phys_size(kvm));</span>
 	spin_unlock(&amp;kvm-&gt;mmu_lock);
 }
 
<span class="p_chunk">@@ -861,7 +860,7 @@</span> <span class="p_context"> static void kvm_flush_stage2_all(struct kvm *kvm)</span>
 void kvm_free_stage2_pgd(struct kvm *kvm)
 {
 	kvm_flush_stage2_all(kvm);
<span class="p_del">-	free_pages_exact(kvm-&gt;arch.pgd, S2_PGD_SIZE);</span>
<span class="p_add">+	free_pages_exact(kvm-&gt;arch.pgd, stage2_pgd_size(kvm));</span>
 	kvm-&gt;arch.pgd = NULL;
 }
 
<span class="p_chunk">@@ -871,16 +870,16 @@</span> <span class="p_context"> static pud_t *stage2_get_pud(struct kvm *kvm, struct kvm_mmu_memory_cache *cache</span>
 	pgd_t *pgd;
 	pud_t *pud;
 
<span class="p_del">-	pgd = kvm-&gt;arch.pgd + stage2_pgd_index(addr);</span>
<span class="p_del">-	if (stage2_pgd_none(*pgd)) {</span>
<span class="p_add">+	pgd = kvm-&gt;arch.pgd + stage2_pgd_index(kvm, addr);</span>
<span class="p_add">+	if (stage2_pgd_none(kvm, *pgd)) {</span>
 		if (!cache)
 			return NULL;
 		pud = mmu_memory_cache_alloc(cache);
<span class="p_del">-		stage2_pgd_populate(pgd, pud);</span>
<span class="p_add">+		stage2_pgd_populate(kvm, pgd, pud);</span>
 		get_page(virt_to_page(pgd));
 	}
 
<span class="p_del">-	return stage2_pud_offset(pgd, addr);</span>
<span class="p_add">+	return stage2_pud_offset(kvm, pgd, addr);</span>
 }
 
 static pmd_t *stage2_get_pmd(struct kvm *kvm, struct kvm_mmu_memory_cache *cache,
<span class="p_chunk">@@ -893,15 +892,15 @@</span> <span class="p_context"> static pmd_t *stage2_get_pmd(struct kvm *kvm, struct kvm_mmu_memory_cache *cache</span>
 	if (!pud)
 		return NULL;
 
<span class="p_del">-	if (stage2_pud_none(*pud)) {</span>
<span class="p_add">+	if (stage2_pud_none(kvm, *pud)) {</span>
 		if (!cache)
 			return NULL;
 		pmd = mmu_memory_cache_alloc(cache);
<span class="p_del">-		stage2_pud_populate(pud, pmd);</span>
<span class="p_add">+		stage2_pud_populate(kvm, pud, pmd);</span>
 		get_page(virt_to_page(pud));
 	}
 
<span class="p_del">-	return stage2_pmd_offset(pud, addr);</span>
<span class="p_add">+	return stage2_pmd_offset(kvm, pud, addr);</span>
 }
 
 static int stage2_set_pmd_huge(struct kvm *kvm, struct kvm_mmu_memory_cache
<span class="p_chunk">@@ -1060,7 +1059,7 @@</span> <span class="p_context"> static int __kvm_phys_addr_ioremap(struct kvm *kvm, phys_addr_t guest_ipa,</span>
 		if (writable)
 			pte = kvm_s2pte_mkwrite(pte);
 
<span class="p_del">-		ret = mmu_topup_memory_cache(&amp;cache, KVM_MMU_CACHE_MIN_PAGES,</span>
<span class="p_add">+		ret = mmu_topup_memory_cache(&amp;cache, kvm_mmu_cache_min_pages(kvm),</span>
 						KVM_NR_MEM_OBJS);
 		if (ret)
 			goto out;
<span class="p_chunk">@@ -1166,19 +1165,20 @@</span> <span class="p_context"> static void stage2_wp_ptes(pmd_t *pmd, phys_addr_t addr, phys_addr_t end)</span>
 
 /**
  * stage2_wp_pmds - write protect PUD range
<span class="p_add">+ * kvm:		kvm instance for the VM</span>
  * @pud:	pointer to pud entry
  * @addr:	range start address
  * @end:	range end address
  */
<span class="p_del">-static void stage2_wp_pmds(pud_t *pud, phys_addr_t addr, phys_addr_t end)</span>
<span class="p_add">+static void stage2_wp_pmds(struct kvm *kvm, pud_t *pud, phys_addr_t addr, phys_addr_t end)</span>
 {
 	pmd_t *pmd;
 	phys_addr_t next;
 
<span class="p_del">-	pmd = stage2_pmd_offset(pud, addr);</span>
<span class="p_add">+	pmd = stage2_pmd_offset(kvm, pud, addr);</span>
 
 	do {
<span class="p_del">-		next = stage2_pmd_addr_end(addr, end);</span>
<span class="p_add">+		next = stage2_pmd_addr_end(kvm, addr, end);</span>
 		if (!pmd_none(*pmd)) {
 			if (pmd_thp_or_huge(*pmd)) {
 				if (!kvm_s2pmd_readonly(pmd))
<span class="p_chunk">@@ -1198,18 +1198,18 @@</span> <span class="p_context"> static void stage2_wp_pmds(pud_t *pud, phys_addr_t addr, phys_addr_t end)</span>
   *
   * Process PUD entries, for a huge PUD we cause a panic.
   */
<span class="p_del">-static void  stage2_wp_puds(pgd_t *pgd, phys_addr_t addr, phys_addr_t end)</span>
<span class="p_add">+static void  stage2_wp_puds(struct kvm *kvm, pgd_t *pgd, phys_addr_t addr, phys_addr_t end)</span>
 {
 	pud_t *pud;
 	phys_addr_t next;
 
<span class="p_del">-	pud = stage2_pud_offset(pgd, addr);</span>
<span class="p_add">+	pud = stage2_pud_offset(kvm, pgd, addr);</span>
 	do {
<span class="p_del">-		next = stage2_pud_addr_end(addr, end);</span>
<span class="p_del">-		if (!stage2_pud_none(*pud)) {</span>
<span class="p_add">+		next = stage2_pud_addr_end(kvm, addr, end);</span>
<span class="p_add">+		if (!stage2_pud_none(kvm, *pud)) {</span>
 			/* TODO:PUD not supported, revisit later if supported */
<span class="p_del">-			BUG_ON(stage2_pud_huge(*pud));</span>
<span class="p_del">-			stage2_wp_pmds(pud, addr, next);</span>
<span class="p_add">+			BUG_ON(stage2_pud_huge(kvm, *pud));</span>
<span class="p_add">+			stage2_wp_pmds(kvm, pud, addr, next);</span>
 		}
 	} while (pud++, addr = next, addr != end);
 }
<span class="p_chunk">@@ -1225,7 +1225,7 @@</span> <span class="p_context"> static void stage2_wp_range(struct kvm *kvm, phys_addr_t addr, phys_addr_t end)</span>
 	pgd_t *pgd;
 	phys_addr_t next;
 
<span class="p_del">-	pgd = kvm-&gt;arch.pgd + stage2_pgd_index(addr);</span>
<span class="p_add">+	pgd = kvm-&gt;arch.pgd + stage2_pgd_index(kvm, addr);</span>
 	do {
 		/*
 		 * Release kvm_mmu_lock periodically if the memory region is
<span class="p_chunk">@@ -1239,9 +1239,9 @@</span> <span class="p_context"> static void stage2_wp_range(struct kvm *kvm, phys_addr_t addr, phys_addr_t end)</span>
 		cond_resched_lock(&amp;kvm-&gt;mmu_lock);
 		if (WARN_ON(!READ_ONCE(kvm-&gt;arch.pgd)))
 			break;
<span class="p_del">-		next = stage2_pgd_addr_end(addr, end);</span>
<span class="p_del">-		if (stage2_pgd_present(*pgd))</span>
<span class="p_del">-			stage2_wp_puds(pgd, addr, next);</span>
<span class="p_add">+		next = stage2_pgd_addr_end(kvm, addr, end);</span>
<span class="p_add">+		if (stage2_pgd_present(kvm, *pgd))</span>
<span class="p_add">+			stage2_wp_puds(kvm, pgd, addr, next);</span>
 	} while (pgd++, addr = next, addr != end);
 }
 
<span class="p_chunk">@@ -1382,7 +1382,7 @@</span> <span class="p_context"> static int user_mem_abort(struct kvm_vcpu *vcpu, phys_addr_t fault_ipa,</span>
 	up_read(&amp;current-&gt;mm-&gt;mmap_sem);
 
 	/* We need minimum second+third level pages */
<span class="p_del">-	ret = mmu_topup_memory_cache(memcache, KVM_MMU_CACHE_MIN_PAGES,</span>
<span class="p_add">+	ret = mmu_topup_memory_cache(memcache, kvm_mmu_cache_min_pages(kvm),</span>
 				     KVM_NR_MEM_OBJS);
 	if (ret)
 		return ret;
<span class="p_chunk">@@ -1601,7 +1601,7 @@</span> <span class="p_context"> int kvm_handle_guest_abort(struct kvm_vcpu *vcpu, struct kvm_run *run)</span>
 	}
 
 	/* Userspace should not be able to register out-of-bounds IPAs */
<span class="p_del">-	VM_BUG_ON(fault_ipa &gt;= KVM_PHYS_SIZE);</span>
<span class="p_add">+	VM_BUG_ON(fault_ipa &gt;= kvm_phys_size(vcpu-&gt;kvm));</span>
 
 	if (fault_status == FSC_ACCESS) {
 		handle_access_fault(vcpu, fault_ipa);
<span class="p_chunk">@@ -1901,7 +1901,7 @@</span> <span class="p_context"> int kvm_arch_prepare_memory_region(struct kvm *kvm,</span>
 	 * space addressable by the KVM guest IPA space.
 	 */
 	if (memslot-&gt;base_gfn + memslot-&gt;npages &gt;=
<span class="p_del">-	    (KVM_PHYS_SIZE &gt;&gt; PAGE_SHIFT))</span>
<span class="p_add">+	    (kvm_phys_size(kvm) &gt;&gt; PAGE_SHIFT))</span>
 		return -EFAULT;
 
 	down_read(&amp;current-&gt;mm-&gt;mmap_sem);
<span class="p_header">diff --git a/virt/kvm/arm/vgic/vgic-kvm-device.c b/virt/kvm/arm/vgic/vgic-kvm-device.c</span>
<span class="p_header">index 10ae6f394b71..613ff4abcad5 100644</span>
<span class="p_header">--- a/virt/kvm/arm/vgic/vgic-kvm-device.c</span>
<span class="p_header">+++ b/virt/kvm/arm/vgic/vgic-kvm-device.c</span>
<span class="p_chunk">@@ -25,7 +25,7 @@</span> <span class="p_context"></span>
 int vgic_check_ioaddr(struct kvm *kvm, phys_addr_t *ioaddr,
 		      phys_addr_t addr, phys_addr_t alignment)
 {
<span class="p_del">-	if (addr &amp; ~KVM_PHYS_MASK)</span>
<span class="p_add">+	if (addr &amp; ~kvm_phys_mask(kvm))</span>
 		return -E2BIG;
 
 	if (!IS_ALIGNED(addr, alignment))

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



