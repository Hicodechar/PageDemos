
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>[RFC,6/6] MIPS: BMIPS: Add support for eXtended KSEG0/1 (XKS01) - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    [RFC,6/6] MIPS: BMIPS: Add support for eXtended KSEG0/1 (XKS01)</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=4640">Florian Fainelli</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>Jan. 24, 2018, 1:47 a.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;1516758426-8127-7-git-send-email-f.fainelli@gmail.com&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/10181233/mbox/"
   >mbox</a>
|
   <a href="/patch/10181233/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/10181233/">/patch/10181233/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
	[172.30.200.125])
	by pdx-korg-patchwork.web.codeaurora.org (Postfix) with ESMTP id
	190DC601D5 for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Wed, 24 Jan 2018 01:48:10 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 05429286E1
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Wed, 24 Jan 2018 01:48:10 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id ED48A2871B; Wed, 24 Jan 2018 01:48:09 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-7.0 required=2.0 tests=BAYES_00,DKIM_SIGNED,
	DKIM_VALID, DKIM_VALID_AU, FREEMAIL_FROM,
	RCVD_IN_DNSWL_HI autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 8A8D8286E1
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Wed, 24 Jan 2018 01:48:08 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1752377AbeAXBsH (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Tue, 23 Jan 2018 20:48:07 -0500
Received: from mail-qt0-f193.google.com ([209.85.216.193]:35275 &quot;EHLO
	mail-qt0-f193.google.com&quot; rhost-flags-OK-OK-OK-OK) by vger.kernel.org
	with ESMTP id S1752246AbeAXBrv (ORCPT
	&lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Tue, 23 Jan 2018 20:47:51 -0500
Received: by mail-qt0-f193.google.com with SMTP id g14so6617991qti.2
	for &lt;linux-kernel@vger.kernel.org&gt;;
	Tue, 23 Jan 2018 17:47:50 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
	d=gmail.com; s=20161025;
	h=from:to:cc:subject:date:message-id:in-reply-to:references;
	bh=ICsCgEcDt8tjlteN8C6JSxkSX44pAkjb4q7ArvYpt5M=;
	b=Aj3diXS9vKzKN2F1tnOPlmIHWkhQUDEpG0jNkIkKQzXJIc4VQVDT2UBGJXBV19oZh8
	rXaa+hzPD2iGk8KvFn1WS64qPSvZANgBqGAIkzfPQVXF5Fcnc9gm8jbIdubX5g97uiMY
	olR3ZoWKN+hMvKCN+4PNED0LeaeGcyhUrrebWJ8ebuYoDY/gbUioSS7ZkcAne+xwjZYK
	CoJLHN9HJfs4YIEXbX4LPDuUatxLeTTIXV+D6dQbLKpETLfNqayRb1pE0oVmKlE072q7
	QShMY7Fyk/Bf2zuNPr2Cm/dBiYUCDJe68cWrZrwV0H0jUcYmE5HFQZ4ghq6G5Mf6f+qk
	J8Lg==
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
	d=1e100.net; s=20161025;
	h=x-gm-message-state:from:to:cc:subject:date:message-id:in-reply-to
	:references;
	bh=ICsCgEcDt8tjlteN8C6JSxkSX44pAkjb4q7ArvYpt5M=;
	b=eOPOVufm/H/j6e9B0WsmOgupIyhl3y1pKPyr3yty9BBlUlLX7vv32YIdouxMQZQ8th
	/ya36JXyCM7tfP2/BYv07G/waVsX5Bf4aVBM/7J9uCW+p3ETA2INDMQVei3lqfv0VV9i
	IcxEmlcv3Zk1XpWMEcCXH1h+nZtzw5SYkSaF9MKvk8+TH29f3ox9c9klXlC9no/AuRYJ
	mJC/EuyqOkntAIW2tn1HZG3iyiVVtWzJIqBLu37dAgI4vgC79ohhem7be+PtH55a9Huu
	l9kaSe2pSy0uh0J4l0ctg6yZUApp05XCtKWMSuSbQhQy19v+0xiABfEJtduYH+uAutad
	ggGQ==
X-Gm-Message-State: AKwxytcgSln8ozs6sKfI0sRAF33P5VyyrKaC57yXUJUOKWZ6Wm2k6Q9P
	MkLB5uHSjROchUDmJbDYgrEIKY3L
X-Google-Smtp-Source: AH8x226OFf406h1hC+kbclfYCgZqW/UlLY+eUqO4SIWij+nqQJtuNZ+QqciLeMNY6nqmDXuMvmAHRw==
X-Received: by 10.200.49.231 with SMTP id i36mr6527110qte.116.1516758470223; 
	Tue, 23 Jan 2018 17:47:50 -0800 (PST)
Received: from stbirv-lnx-1.igp.broadcom.net ([192.19.223.250])
	by smtp.gmail.com with ESMTPSA id
	x7sm1465605qtx.51.2018.01.23.17.47.46
	(version=TLS1_2 cipher=ECDHE-RSA-AES128-SHA bits=128/128);
	Tue, 23 Jan 2018 17:47:49 -0800 (PST)
From: Florian Fainelli &lt;f.fainelli@gmail.com&gt;
To: linux-mips@linux-mips.org
Cc: Florian Fainelli &lt;florian.fainelli@broadcom.com&gt;,
	Ralf Baechle &lt;ralf@linux-mips.org&gt;, Kevin Cernekee &lt;cernekee@gmail.com&gt;,
	Florian Fainelli &lt;f.fainelli@gmail.com&gt;, James Hogan &lt;jhogan@kernel.org&gt;,
	Paul Burton &lt;paul.burton@mips.com&gt;,
	Matt Redfearn &lt;matt.redfearn@mips.com&gt;,
	&quot;Maciej W. Rozycki&quot; &lt;macro@mips.com&gt;, Huacai Chen &lt;chenhc@lemote.com&gt;,
	Kate Stewart &lt;kstewart@linuxfoundation.org&gt;,
	Greg Kroah-Hartman &lt;gregkh@linuxfoundation.org&gt;,
	Marcin Nowakowski &lt;marcin.nowakowski@mips.com&gt;,
	Andrew Morton &lt;akpm@linux-foundation.org&gt;,
	&quot;Eric W. Biederman&quot; &lt;ebiederm@xmission.com&gt;,
	Ingo Molnar &lt;mingo@kernel.org&gt;, David Howells &lt;dhowells@redhat.com&gt;,
	Kees Cook &lt;keescook@chromium.org&gt;, Thomas Meyer &lt;thomas@m3y3r.de&gt;,
	&quot;Bryan O&#39;Donoghue&quot; &lt;pure.logic@nexus-software.ie&gt;,
	Robin Murphy &lt;robin.murphy@arm.com&gt;, Michal Hocko &lt;mhocko@suse.com&gt;,
	Lucas Stach &lt;l.stach@pengutronix.de&gt;,
	Vladimir Murzin &lt;vladimir.murzin@arm.com&gt;,
	Bart Van Assche &lt;bart.vanassche@sandisk.com&gt;,
	linux-kernel@vger.kernel.org (open list)
Subject: [PATCH RFC 6/6] MIPS: BMIPS: Add support for eXtended KSEG0/1
	(XKS01)
Date: Tue, 23 Jan 2018 17:47:06 -0800
Message-Id: &lt;1516758426-8127-7-git-send-email-f.fainelli@gmail.com&gt;
X-Mailer: git-send-email 2.7.4
In-Reply-To: &lt;1516758426-8127-1-git-send-email-f.fainelli@gmail.com&gt;
References: &lt;1516758426-8127-1-git-send-email-f.fainelli@gmail.com&gt;
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=4640">Florian Fainelli</a> - Jan. 24, 2018, 1:47 a.m.</div>
<pre class="content">
<span class="from">From: Florian Fainelli &lt;florian.fainelli@broadcom.com&gt;</span>

We need to implement a few things in order for XKS01 to work:

- a coherent allocator is needed for some portions of the memory space,
  this is loosely inspired from an old ARM implementation
- we need to obtain how much DRAM we have on our first memory controller
  (MEMC0) which is what govers how big the extended region can be
- a bunch of ioremap and dma-coherent functions need to be re-defined to
  take our special ranges into account
<span class="signed-off-by">
Signed-off-by: Florian Fainelli &lt;florian.fainelli@broadcom.com&gt;</span>
---
 arch/mips/Kconfig                                  |   2 +
 arch/mips/bmips/Makefile                           |   2 +-
 arch/mips/bmips/memory.c                           | 427 +++++++++++++++++++++
 arch/mips/bmips/setup.c                            |  35 ++
 arch/mips/include/asm/addrspace.h                  |   8 +
 arch/mips/include/asm/mach-bmips/dma-coherence.h   |   6 +
 arch/mips/include/asm/mach-bmips/ioremap.h         |  26 +-
 .../include/asm/mach-bmips/kernel-entry-init.h     |  18 +
 arch/mips/include/asm/mach-bmips/spaces.h          | 102 +++++
 9 files changed, 603 insertions(+), 23 deletions(-)
 create mode 100644 arch/mips/bmips/memory.c
 create mode 100644 arch/mips/include/asm/mach-bmips/kernel-entry-init.h
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/arch/mips/Kconfig b/arch/mips/Kconfig</span>
<span class="p_header">index 659e0079487f..b7c0306c9051 100644</span>
<span class="p_header">--- a/arch/mips/Kconfig</span>
<span class="p_header">+++ b/arch/mips/Kconfig</span>
<span class="p_chunk">@@ -234,6 +234,7 @@</span> <span class="p_context"> config BMIPS_GENERIC</span>
 	select USB_OHCI_BIG_ENDIAN_DESC if CPU_BIG_ENDIAN
 	select USB_OHCI_BIG_ENDIAN_MMIO if CPU_BIG_ENDIAN
 	select HARDIRQS_SW_RESEND
<span class="p_add">+	select FW_CFE</span>
 	help
 	  Build a generic DT-based kernel image that boots on select
 	  BCM33xx cable modem chips, BCM63xx DSL chips, and BCM7xxx set-top
<span class="p_chunk">@@ -1690,6 +1691,7 @@</span> <span class="p_context"> config CPU_BMIPS</span>
 	select CPU_HAS_PREFETCH
 	select CPU_SUPPORTS_CPUFREQ
 	select MIPS_EXTERNAL_TIMER
<span class="p_add">+	select XKS01</span>
 	help
 	  Support for BMIPS32/3300/4350/4380 and BMIPS5000 processors.
 
<span class="p_header">diff --git a/arch/mips/bmips/Makefile b/arch/mips/bmips/Makefile</span>
<span class="p_header">index a393955cba08..990dc814b7d8 100644</span>
<span class="p_header">--- a/arch/mips/bmips/Makefile</span>
<span class="p_header">+++ b/arch/mips/bmips/Makefile</span>
<span class="p_chunk">@@ -1 +1 @@</span> <span class="p_context"></span>
<span class="p_del">-obj-y		+= setup.o irq.o dma.o</span>
<span class="p_add">+obj-y		+= setup.o irq.o dma.o memory.o</span>
<span class="p_header">diff --git a/arch/mips/bmips/memory.c b/arch/mips/bmips/memory.c</span>
new file mode 100644
<span class="p_header">index 000000000000..847954b8686e</span>
<span class="p_header">--- /dev/null</span>
<span class="p_header">+++ b/arch/mips/bmips/memory.c</span>
<span class="p_chunk">@@ -0,0 +1,427 @@</span> <span class="p_context"></span>
<span class="p_add">+// SPDX-License-Identifier: GPL-2.0</span>
<span class="p_add">+#include &lt;linux/bootmem.h&gt;</span>
<span class="p_add">+#include &lt;linux/spinlock.h&gt;</span>
<span class="p_add">+#include &lt;linux/mm.h&gt;</span>
<span class="p_add">+#include &lt;linux/kernel.h&gt;</span>
<span class="p_add">+#include &lt;linux/pci.h&gt;</span>
<span class="p_add">+#include &lt;linux/ioport.h&gt;</span>
<span class="p_add">+#include &lt;linux/list.h&gt;</span>
<span class="p_add">+#include &lt;linux/vmalloc.h&gt;</span>
<span class="p_add">+#include &lt;linux/compiler.h&gt;</span>
<span class="p_add">+#include &lt;linux/atomic.h&gt;</span>
<span class="p_add">+#include &lt;linux/printk.h&gt;</span>
<span class="p_add">+#include &lt;linux/module.h&gt;</span>
<span class="p_add">+#include &lt;linux/init_task.h&gt;</span>
<span class="p_add">+</span>
<span class="p_add">+#include &lt;asm/page.h&gt;</span>
<span class="p_add">+#include &lt;asm/pgtable-32.h&gt;</span>
<span class="p_add">+#include &lt;asm/pgtable-bits.h&gt;</span>
<span class="p_add">+#include &lt;asm/addrspace.h&gt;</span>
<span class="p_add">+#include &lt;asm/tlbflush.h&gt;</span>
<span class="p_add">+#include &lt;asm/r4kcache.h&gt;</span>
<span class="p_add">+</span>
<span class="p_add">+#include &lt;spaces.h&gt;</span>
<span class="p_add">+</span>
<span class="p_add">+/*</span>
<span class="p_add">+ * Override default behavior to allow cached access to all valid DRAM ranges</span>
<span class="p_add">+ */</span>
<span class="p_add">+int __uncached_access(struct file *file, unsigned long addr)</span>
<span class="p_add">+{</span>
<span class="p_add">+	if (file-&gt;f_flags &amp; O_SYNC)</span>
<span class="p_add">+		return 1;</span>
<span class="p_add">+	if (addr &gt;= 0x10000000 &amp;&amp; addr &lt; UPPERMEM_START)</span>
<span class="p_add">+		return 1;</span>
<span class="p_add">+	if (addr &gt;= 0xa0000000)</span>
<span class="p_add">+		return 1;</span>
<span class="p_add">+	return 0;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+/***********************************************************************</span>
<span class="p_add">+ * Wired TLB mappings for upper memory support</span>
<span class="p_add">+ ***********************************************************************/</span>
<span class="p_add">+</span>
<span class="p_add">+#define UNIQUE_ENTRYHI(idx) (CKSEG0 + ((idx) &lt;&lt; (PAGE_SHIFT + 1)))</span>
<span class="p_add">+</span>
<span class="p_add">+/* (PFN &lt;&lt; 6) | GLOBAL | VALID | DIRTY | cacheability */</span>
<span class="p_add">+#define ENTRYLO_CACHED(paddr)	(((paddr) &gt;&gt; 6) | (0x07) | (0x03 &lt;&lt; 3))</span>
<span class="p_add">+#define ENTRYLO_UNCACHED(paddr)	(((paddr) &gt;&gt; 6) | (0x07) | (0x02 &lt;&lt; 3))</span>
<span class="p_add">+</span>
<span class="p_add">+/* GLOBAL | !VALID */</span>
<span class="p_add">+#define ENTRYLO_INVALID()	(0x01)</span>
<span class="p_add">+</span>
<span class="p_add">+struct tlb_entry {</span>
<span class="p_add">+	unsigned long entrylo0;</span>
<span class="p_add">+	unsigned long entrylo1;</span>
<span class="p_add">+	unsigned long entryhi;</span>
<span class="p_add">+	unsigned long pagemask;</span>
<span class="p_add">+};</span>
<span class="p_add">+</span>
<span class="p_add">+static struct tlb_entry __maybe_unused uppermem_mappings[] = {</span>
<span class="p_add">+{</span>
<span class="p_add">+	.entrylo0		= ENTRYLO_CACHED(TLB_UPPERMEM_PA),</span>
<span class="p_add">+	.entrylo1		= ENTRYLO_INVALID(),</span>
<span class="p_add">+	.entryhi		= TLB_UPPERMEM_VA,</span>
<span class="p_add">+	.pagemask		= PM_256M,</span>
<span class="p_add">+},</span>
<span class="p_add">+};</span>
<span class="p_add">+</span>
<span class="p_add">+static inline void brcm_write_tlb_entry(int idx, unsigned long entrylo0,</span>
<span class="p_add">+					unsigned long entrylo1,</span>
<span class="p_add">+					unsigned long entryhi,</span>
<span class="p_add">+					unsigned long pagemask)</span>
<span class="p_add">+{</span>
<span class="p_add">+	write_c0_entrylo0(entrylo0);</span>
<span class="p_add">+	write_c0_entrylo1(entrylo1);</span>
<span class="p_add">+	write_c0_entryhi(entryhi);</span>
<span class="p_add">+	write_c0_pagemask(pagemask);</span>
<span class="p_add">+	write_c0_index(idx);</span>
<span class="p_add">+	mtc0_tlbw_hazard();</span>
<span class="p_add">+	tlb_write_indexed();</span>
<span class="p_add">+	tlbw_use_hazard();</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+/*</span>
<span class="p_add">+ * This function is used instead of add_wired_entry(), because it does not</span>
<span class="p_add">+ * have any external dependencies and is not marked __init</span>
<span class="p_add">+ */</span>
<span class="p_add">+static inline void brcm_add_wired_entry(unsigned long entrylo0,</span>
<span class="p_add">+					unsigned long entrylo1,</span>
<span class="p_add">+					unsigned long entryhi,</span>
<span class="p_add">+					unsigned long pagemask)</span>
<span class="p_add">+{</span>
<span class="p_add">+	int i = read_c0_wired();</span>
<span class="p_add">+	write_c0_wired(i + 1);</span>
<span class="p_add">+	brcm_write_tlb_entry(i, entrylo0, entrylo1, entryhi, pagemask);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+extern void build_tlb_refill_handler(void);</span>
<span class="p_add">+extern void tlb_init(void);</span>
<span class="p_add">+</span>
<span class="p_add">+void bmips_tlb_init(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	if (!cpu_has_xks01) {</span>
<span class="p_add">+		tlb_init();</span>
<span class="p_add">+		return;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	if (smp_processor_id() == 0) {</span>
<span class="p_add">+		int i;</span>
<span class="p_add">+		struct tlb_entry *e = uppermem_mappings;</span>
<span class="p_add">+</span>
<span class="p_add">+		tlb_init();</span>
<span class="p_add">+		for (i = 0; i &lt; ARRAY_SIZE(uppermem_mappings); i++, e++)</span>
<span class="p_add">+			brcm_add_wired_entry(e-&gt;entrylo0, e-&gt;entrylo1,</span>
<span class="p_add">+				e-&gt;entryhi, e-&gt;pagemask);</span>
<span class="p_add">+		write_c0_pagemask(PM_DEFAULT_MASK);</span>
<span class="p_add">+	} else {</span>
<span class="p_add">+		/* bypass tlb_init() / probe_tlb() for secondary CPU */</span>
<span class="p_add">+		cpu_data[smp_processor_id()].tlbsize = cpu_data[0].tlbsize;</span>
<span class="p_add">+		build_tlb_refill_handler();</span>
<span class="p_add">+	}</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+/*</span>
<span class="p_add">+ * Initialize upper memory TLB entries</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * On TP1 this must happen before we set up $sp/$gp .  It is always</span>
<span class="p_add">+ * possible for stacks, task_structs, thread_info&#39;s, and other</span>
<span class="p_add">+ * important structures to be allocated out of upper memory so</span>
<span class="p_add">+ * this happens early on.</span>
<span class="p_add">+ */</span>
<span class="p_add">+asmlinkage void plat_wired_tlb_setup(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	int __maybe_unused i, tlbsz;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (!cpu_has_xks01)</span>
<span class="p_add">+		return;</span>
<span class="p_add">+</span>
<span class="p_add">+	/* Flush TLB.  local_flush_tlb_all() is not available yet. */</span>
<span class="p_add">+	write_c0_entrylo0(0);</span>
<span class="p_add">+	write_c0_entrylo1(0);</span>
<span class="p_add">+	write_c0_pagemask(PM_DEFAULT_MASK);</span>
<span class="p_add">+	write_c0_wired(0);</span>
<span class="p_add">+</span>
<span class="p_add">+	tlbsz = (read_c0_config1() &gt;&gt; 25) &amp; 0x3f;</span>
<span class="p_add">+	for (i = 0; i &lt;= tlbsz; i++) {</span>
<span class="p_add">+		write_c0_entryhi(UNIQUE_ENTRYHI(i));</span>
<span class="p_add">+		write_c0_index(i);</span>
<span class="p_add">+		mtc0_tlbw_hazard();</span>
<span class="p_add">+		tlb_write_indexed();</span>
<span class="p_add">+		tlbw_use_hazard();</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	write_c0_wired(0);</span>
<span class="p_add">+	mtc0_tlbw_hazard();</span>
<span class="p_add">+</span>
<span class="p_add">+	for (i = 0; i &lt; ARRAY_SIZE(uppermem_mappings); i++) {</span>
<span class="p_add">+		struct tlb_entry *e = &amp;uppermem_mappings[i];</span>
<span class="p_add">+		brcm_add_wired_entry(e-&gt;entrylo0, e-&gt;entrylo1, e-&gt;entryhi,</span>
<span class="p_add">+			e-&gt;pagemask);</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	write_c0_pagemask(PM_DEFAULT_MASK);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+/***********************************************************************</span>
<span class="p_add">+ * Special allocator for coherent (uncached) memory</span>
<span class="p_add">+ * (Required for &gt;256MB upper memory)</span>
<span class="p_add">+ ***********************************************************************/</span>
<span class="p_add">+</span>
<span class="p_add">+#define CONSISTENT_DMA_SIZE	(CONSISTENT_END - CONSISTENT_BASE)</span>
<span class="p_add">+#define CONSISTENT_OFFSET(x)	(((unsigned long)(x) - CONSISTENT_BASE) &gt;&gt; \</span>
<span class="p_add">+	PAGE_SHIFT)</span>
<span class="p_add">+#define CONSISTENT_PTE_INDEX(x) (((unsigned long)(x) - CONSISTENT_BASE) &gt;&gt; \</span>
<span class="p_add">+	PGDIR_SHIFT)</span>
<span class="p_add">+#define NUM_CONSISTENT_PTES	(CONSISTENT_DMA_SIZE &gt;&gt; PGDIR_SHIFT)</span>
<span class="p_add">+</span>
<span class="p_add">+/*</span>
<span class="p_add">+ * These are the page tables (4MB each) covering uncached, DMA consistent</span>
<span class="p_add">+ * allocations</span>
<span class="p_add">+ */</span>
<span class="p_add">+static pte_t *consistent_pte[NUM_CONSISTENT_PTES];</span>
<span class="p_add">+static DEFINE_SPINLOCK(consistent_lock);</span>
<span class="p_add">+</span>
<span class="p_add">+struct bmips_vm_region {</span>
<span class="p_add">+	struct list_head	vm_list;</span>
<span class="p_add">+	unsigned long		vm_start;</span>
<span class="p_add">+	unsigned long		vm_end;</span>
<span class="p_add">+	void			*vm_cac_va;</span>
<span class="p_add">+	int			vm_active;</span>
<span class="p_add">+};</span>
<span class="p_add">+</span>
<span class="p_add">+static struct bmips_vm_region consistent_head = {</span>
<span class="p_add">+	.vm_list	= LIST_HEAD_INIT(consistent_head.vm_list),</span>
<span class="p_add">+	.vm_start	= CONSISTENT_BASE,</span>
<span class="p_add">+	.vm_end		= CONSISTENT_END,</span>
<span class="p_add">+};</span>
<span class="p_add">+</span>
<span class="p_add">+static struct bmips_vm_region *</span>
<span class="p_add">+bmips_vm_region_alloc(struct bmips_vm_region *head, size_t size, gfp_t gfp)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long addr = head-&gt;vm_start, end = head-&gt;vm_end - size;</span>
<span class="p_add">+	unsigned long flags;</span>
<span class="p_add">+	struct bmips_vm_region *c, *new;</span>
<span class="p_add">+</span>
<span class="p_add">+	new = kmalloc(sizeof(struct bmips_vm_region), gfp);</span>
<span class="p_add">+	if (!new)</span>
<span class="p_add">+		goto out;</span>
<span class="p_add">+</span>
<span class="p_add">+	spin_lock_irqsave(&amp;consistent_lock, flags);</span>
<span class="p_add">+</span>
<span class="p_add">+	list_for_each_entry(c, &amp;head-&gt;vm_list, vm_list) {</span>
<span class="p_add">+		if ((addr + size) &lt; addr)</span>
<span class="p_add">+			goto nospc;</span>
<span class="p_add">+		if ((addr + size) &lt;= c-&gt;vm_start)</span>
<span class="p_add">+			goto found;</span>
<span class="p_add">+		addr = c-&gt;vm_end;</span>
<span class="p_add">+		if (addr &gt; end)</span>
<span class="p_add">+			goto nospc;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+found:</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Insert this entry _before_ the one we found.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	list_add_tail(&amp;new-&gt;vm_list, &amp;c-&gt;vm_list);</span>
<span class="p_add">+	new-&gt;vm_start = addr;</span>
<span class="p_add">+	new-&gt;vm_end = addr + size;</span>
<span class="p_add">+	new-&gt;vm_active = 1;</span>
<span class="p_add">+</span>
<span class="p_add">+	spin_unlock_irqrestore(&amp;consistent_lock, flags);</span>
<span class="p_add">+	return new;</span>
<span class="p_add">+</span>
<span class="p_add">+nospc:</span>
<span class="p_add">+	spin_unlock_irqrestore(&amp;consistent_lock, flags);</span>
<span class="p_add">+	kfree(new);</span>
<span class="p_add">+out:</span>
<span class="p_add">+	return NULL;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static struct bmips_vm_region *bmips_vm_region_find(struct bmips_vm_region *head,</span>
<span class="p_add">+	unsigned long addr)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct bmips_vm_region *c;</span>
<span class="p_add">+</span>
<span class="p_add">+	list_for_each_entry(c, &amp;head-&gt;vm_list, vm_list) {</span>
<span class="p_add">+		if (c-&gt;vm_active &amp;&amp; c-&gt;vm_start == addr)</span>
<span class="p_add">+			goto out;</span>
<span class="p_add">+	}</span>
<span class="p_add">+	c = NULL;</span>
<span class="p_add">+out:</span>
<span class="p_add">+	return c;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static int __init consistent_init(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	pgd_t *pgd;</span>
<span class="p_add">+	pud_t *pud;</span>
<span class="p_add">+	pmd_t *pmd;</span>
<span class="p_add">+	pte_t *pte;</span>
<span class="p_add">+	int ret = 0, i = 0;</span>
<span class="p_add">+	u32 base = CONSISTENT_BASE;</span>
<span class="p_add">+</span>
<span class="p_add">+	do {</span>
<span class="p_add">+		pgd = pgd_offset(&amp;init_mm, base);</span>
<span class="p_add">+		pud = pud_alloc(&amp;init_mm, pgd, base);</span>
<span class="p_add">+		if (!pud) {</span>
<span class="p_add">+			pr_err(&quot;%s: no pud tables\n&quot;, __func__);</span>
<span class="p_add">+			ret = -ENOMEM;</span>
<span class="p_add">+			break;</span>
<span class="p_add">+		}</span>
<span class="p_add">+		pmd = pmd_alloc(&amp;init_mm, pud, base);</span>
<span class="p_add">+		if (!pmd) {</span>
<span class="p_add">+			pr_err(&quot;%s: no pmd tables\n&quot;, __func__);</span>
<span class="p_add">+			ret = -ENOMEM;</span>
<span class="p_add">+			break;</span>
<span class="p_add">+		}</span>
<span class="p_add">+</span>
<span class="p_add">+		pte = pte_alloc_kernel(pmd, base);</span>
<span class="p_add">+		if (!pte) {</span>
<span class="p_add">+			pr_err(&quot;%s: no pte tables\n&quot;, __func__);</span>
<span class="p_add">+			ret = -ENOMEM;</span>
<span class="p_add">+			break;</span>
<span class="p_add">+		}</span>
<span class="p_add">+</span>
<span class="p_add">+		consistent_pte[i++] = pte;</span>
<span class="p_add">+		base += (1 &lt;&lt; PGDIR_SHIFT);</span>
<span class="p_add">+	} while (base &lt; CONSISTENT_END);</span>
<span class="p_add">+</span>
<span class="p_add">+	return ret;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+core_initcall(consistent_init);</span>
<span class="p_add">+</span>
<span class="p_add">+int plat_map_coherent(dma_addr_t dma_handle, void *cac_va, size_t size,</span>
<span class="p_add">+		      void **uncac_va, gfp_t gfp)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct bmips_vm_region *c;</span>
<span class="p_add">+	struct page *page;</span>
<span class="p_add">+	pte_t *pte;</span>
<span class="p_add">+	int idx;</span>
<span class="p_add">+	u32 off;</span>
<span class="p_add">+</span>
<span class="p_add">+	c = bmips_vm_region_alloc(&amp;consistent_head, size, gfp);</span>
<span class="p_add">+	if (!c)</span>
<span class="p_add">+		return -EINVAL;</span>
<span class="p_add">+</span>
<span class="p_add">+	c-&gt;vm_cac_va = cac_va;</span>
<span class="p_add">+</span>
<span class="p_add">+	page = virt_to_page(cac_va);</span>
<span class="p_add">+	idx = CONSISTENT_PTE_INDEX(c-&gt;vm_start);</span>
<span class="p_add">+	off = CONSISTENT_OFFSET(c-&gt;vm_start) &amp; (PTRS_PER_PTE-1);</span>
<span class="p_add">+	pte = consistent_pte[idx] + off;</span>
<span class="p_add">+</span>
<span class="p_add">+	pr_debug(&quot;map addr %08lx idx %x off %x pte %p\n&quot;,</span>
<span class="p_add">+		c-&gt;vm_start, idx, off, pte);</span>
<span class="p_add">+</span>
<span class="p_add">+	do {</span>
<span class="p_add">+		if (off &gt;= PTRS_PER_PTE) {</span>
<span class="p_add">+			off = 0;</span>
<span class="p_add">+			BUG_ON(idx &gt;= NUM_CONSISTENT_PTES - 1);</span>
<span class="p_add">+			pte = consistent_pte[++idx];</span>
<span class="p_add">+		}</span>
<span class="p_add">+</span>
<span class="p_add">+		BUG_ON(!pte_none(*pte));</span>
<span class="p_add">+		set_pte(pte, mk_pte(page, PAGE_KERNEL_UNCACHED));</span>
<span class="p_add">+		page++;</span>
<span class="p_add">+		pte++;</span>
<span class="p_add">+		off++;</span>
<span class="p_add">+	} while (size -= PAGE_SIZE);</span>
<span class="p_add">+</span>
<span class="p_add">+	*uncac_va = (void *)c-&gt;vm_start;</span>
<span class="p_add">+	return 0;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void *plat_unmap_coherent(void *vaddr)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct bmips_vm_region *c;</span>
<span class="p_add">+	unsigned long flags, addr;</span>
<span class="p_add">+	void *ret = NULL;</span>
<span class="p_add">+	pte_t *pte;</span>
<span class="p_add">+	int idx;</span>
<span class="p_add">+	u32 off;</span>
<span class="p_add">+</span>
<span class="p_add">+	spin_lock_irqsave(&amp;consistent_lock, flags);</span>
<span class="p_add">+	c = bmips_vm_region_find(&amp;consistent_head, (unsigned long)vaddr);</span>
<span class="p_add">+	if (!c) {</span>
<span class="p_add">+		spin_unlock_irqrestore(&amp;consistent_lock, flags);</span>
<span class="p_add">+		pr_err(&quot;%s: invalid VA %p\n&quot;, __func__, vaddr);</span>
<span class="p_add">+		return NULL;</span>
<span class="p_add">+	}</span>
<span class="p_add">+	c-&gt;vm_active = 0;</span>
<span class="p_add">+	spin_unlock_irqrestore(&amp;consistent_lock, flags);</span>
<span class="p_add">+</span>
<span class="p_add">+	ret = c-&gt;vm_cac_va;</span>
<span class="p_add">+	addr = c-&gt;vm_start;</span>
<span class="p_add">+</span>
<span class="p_add">+	idx = CONSISTENT_PTE_INDEX(addr);</span>
<span class="p_add">+	off = CONSISTENT_OFFSET(addr) &amp; (PTRS_PER_PTE-1);</span>
<span class="p_add">+	pte = consistent_pte[idx] + off;</span>
<span class="p_add">+</span>
<span class="p_add">+	pr_debug(&quot;unmap addr %08lx idx %x off %x pte %p\n&quot;,</span>
<span class="p_add">+		addr, idx, off, pte);</span>
<span class="p_add">+</span>
<span class="p_add">+	do {</span>
<span class="p_add">+		if (off &gt;= PTRS_PER_PTE) {</span>
<span class="p_add">+			off = 0;</span>
<span class="p_add">+			BUG_ON(idx &gt;= NUM_CONSISTENT_PTES - 1);</span>
<span class="p_add">+			pte = consistent_pte[++idx];</span>
<span class="p_add">+		}</span>
<span class="p_add">+</span>
<span class="p_add">+		pte_clear(&amp;init_mm, addr, pte);</span>
<span class="p_add">+		pte++;</span>
<span class="p_add">+		off++;</span>
<span class="p_add">+		addr += PAGE_SIZE;</span>
<span class="p_add">+	} while (addr &lt; c-&gt;vm_end);</span>
<span class="p_add">+	flush_tlb_kernel_range(c-&gt;vm_start, c-&gt;vm_end);</span>
<span class="p_add">+</span>
<span class="p_add">+	spin_lock_irqsave(&amp;consistent_lock, flags);</span>
<span class="p_add">+	list_del(&amp;c-&gt;vm_list);</span>
<span class="p_add">+	spin_unlock_irqrestore(&amp;consistent_lock, flags);</span>
<span class="p_add">+</span>
<span class="p_add">+	kfree(c);</span>
<span class="p_add">+</span>
<span class="p_add">+	return ret;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void __iomem *plat_ioremap(phys_addr_t offset, unsigned long size,</span>
<span class="p_add">+	unsigned long flags)</span>
<span class="p_add">+{</span>
<span class="p_add">+	/* sanity check */</span>
<span class="p_add">+	if ((offset + size - 1) &lt; offset ||</span>
<span class="p_add">+	    !size ||</span>
<span class="p_add">+	    offset &gt; max(KSEG0_SIZE, KSEG1_SIZE))</span>
<span class="p_add">+		return NULL;</span>
<span class="p_add">+</span>
<span class="p_add">+	/* !XKS01, XKS01: uncached access to EBI/registers @ PA 1000_0000 */</span>
<span class="p_add">+	if (offset &gt;= 0x10000000 &amp;&amp;</span>
<span class="p_add">+	    (offset + size) &lt;= 0x20000000 &amp;&amp;</span>
<span class="p_add">+	    flags == _CACHE_UNCACHED)</span>
<span class="p_add">+		return (void *)(KSEG1 + offset);</span>
<span class="p_add">+</span>
<span class="p_add">+	/* !XKS01, XKS01: easy cached access to some DRAM */</span>
<span class="p_add">+	if ((offset + size) &lt;= KSEG0_SIZE &amp;&amp;</span>
<span class="p_add">+	    flags == _CACHE_CACHABLE_NONCOHERENT)</span>
<span class="p_add">+		return (void *)(KSEG0 + offset);</span>
<span class="p_add">+</span>
<span class="p_add">+	/* !XKS01 only: easy uncached access to some DRAM */</span>
<span class="p_add">+	if ((offset + size) &lt;= KSEG1_SIZE &amp;&amp;</span>
<span class="p_add">+	    flags == _CACHE_UNCACHED)</span>
<span class="p_add">+		return (void *)(KSEG1 + offset);</span>
<span class="p_add">+</span>
<span class="p_add">+	/* anything else gets mapped using page tables */</span>
<span class="p_add">+	return NULL;</span>
<span class="p_add">+}</span>
<span class="p_add">+EXPORT_SYMBOL(plat_ioremap);</span>
<span class="p_add">+</span>
<span class="p_add">+int plat_iounmap(const volatile void __iomem *addr)</span>
<span class="p_add">+{</span>
<span class="p_add">+	phys_addr_t va = (unsigned long)addr;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (va &gt;= KSEG0 &amp;&amp; va &lt; (KSEG0 + KSEG0_SIZE))</span>
<span class="p_add">+		return 1;</span>
<span class="p_add">+	if (va &gt;= KSEG1 &amp;&amp; va &lt; (KSEG1 + KSEG1_SIZE))</span>
<span class="p_add">+		return 1;</span>
<span class="p_add">+	return 0;</span>
<span class="p_add">+}</span>
<span class="p_add">+EXPORT_SYMBOL(plat_iounmap);</span>
<span class="p_header">diff --git a/arch/mips/bmips/setup.c b/arch/mips/bmips/setup.c</span>
<span class="p_header">index d1b7b8b82ae1..4f565f2df977 100644</span>
<span class="p_header">--- a/arch/mips/bmips/setup.c</span>
<span class="p_header">+++ b/arch/mips/bmips/setup.c</span>
<span class="p_chunk">@@ -134,6 +134,39 @@</span> <span class="p_context"> static unsigned long dram0_size_mb;</span>
 
 extern void bmips_tlb_init(void);
 
<span class="p_add">+static void bmips_add_memory_regions(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	board_tlb_init = bmips_tlb_init;</span>
<span class="p_add">+</span>
<span class="p_add">+	do {</span>
<span class="p_add">+		unsigned long dram0_mb = dram0_size_mb, mb;</span>
<span class="p_add">+</span>
<span class="p_add">+		mb = min(dram0_mb, BRCM_MAX_LOWER_MB);</span>
<span class="p_add">+		dram0_mb -= mb;</span>
<span class="p_add">+</span>
<span class="p_add">+		add_memory_region(0, mb &lt;&lt; 20, BOOT_MEM_RAM);</span>
<span class="p_add">+		if (!dram0_mb)</span>
<span class="p_add">+			break;</span>
<span class="p_add">+</span>
<span class="p_add">+		if (cpu_has_xks01) {</span>
<span class="p_add">+			mb = min(dram0_mb, BRCM_MAX_UPPER_MB);</span>
<span class="p_add">+			dram0_mb -= mb;</span>
<span class="p_add">+</span>
<span class="p_add">+			plat_wired_tlb_setup();</span>
<span class="p_add">+			add_memory_region(UPPERMEM_START, mb &lt;&lt; 20, BOOT_MEM_RAM);</span>
<span class="p_add">+			if (!dram0_mb)</span>
<span class="p_add">+				break;</span>
<span class="p_add">+		}</span>
<span class="p_add">+</span>
<span class="p_add">+#ifdef CONFIG_HIGHMEM</span>
<span class="p_add">+		add_memory_region(HIGHMEM_START, dram0_mb &lt;&lt; 20, BOOT_MEM_RAM);</span>
<span class="p_add">+		break;</span>
<span class="p_add">+#endif</span>
<span class="p_add">+		/* Linux memory */</span>
<span class="p_add">+		mb = dram0_size_mb - dram0_mb;</span>
<span class="p_add">+	} while (0);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static char __initdata cfe_buf[COMMAND_LINE_SIZE];
 
 static inline int __init parse_ulong(const char *buf, unsigned long *val)
<span class="p_chunk">@@ -230,6 +263,8 @@</span> <span class="p_context"> void __init plat_mem_setup(void)</span>
 			q-&gt;quirk_fn();
 		}
 	}
<span class="p_add">+</span>
<span class="p_add">+	bmips_add_memory_regions();</span>
 }
 
 void __init device_tree_init(void)
<span class="p_header">diff --git a/arch/mips/include/asm/addrspace.h b/arch/mips/include/asm/addrspace.h</span>
<span class="p_header">index 4856adc8906e..f66e2f90c604 100644</span>
<span class="p_header">--- a/arch/mips/include/asm/addrspace.h</span>
<span class="p_header">+++ b/arch/mips/include/asm/addrspace.h</span>
<span class="p_chunk">@@ -96,13 +96,21 @@</span> <span class="p_context"></span>
  */
 #define KUSEG			0x00000000
 #define KSEG0			0x80000000
<span class="p_add">+#ifdef CONFIG_XKS01</span>
<span class="p_add">+#define KSEG1			plat_kseg1()</span>
<span class="p_add">+#else</span>
 #define KSEG1			0xa0000000
<span class="p_add">+#endif</span>
 #define KSEG2			0xc0000000
 #define KSEG3			0xe0000000
 
 #define CKUSEG			0x00000000
 #define CKSEG0			0x80000000
<span class="p_add">+#ifdef CONFIG_XKS01</span>
<span class="p_add">+#define CKSEG1			plat_kseg1()</span>
<span class="p_add">+#else</span>
 #define CKSEG1			0xa0000000
<span class="p_add">+#endif</span>
 #define CKSEG2			0xc0000000
 #define CKSEG3			0xe0000000
 
<span class="p_header">diff --git a/arch/mips/include/asm/mach-bmips/dma-coherence.h b/arch/mips/include/asm/mach-bmips/dma-coherence.h</span>
<span class="p_header">index b56380066573..9fbb6355fd8d 100644</span>
<span class="p_header">--- a/arch/mips/include/asm/mach-bmips/dma-coherence.h</span>
<span class="p_header">+++ b/arch/mips/include/asm/mach-bmips/dma-coherence.h</span>
<span class="p_chunk">@@ -37,6 +37,12 @@</span> <span class="p_context"> static inline int plat_device_is_coherent(struct device *dev)</span>
 
 #define plat_post_dma_flush	bmips_post_dma_flush
 
<span class="p_add">+#define plat_map_coherent	plat_map_coherent</span>
<span class="p_add">+extern int plat_map_coherent(dma_addr_t handle, void *cac_va, size_t size,</span>
<span class="p_add">+			     void **uncac_va, gfp_t gfp);</span>
<span class="p_add">+#define plat_unmap_coherent	plat_unmap_coherent</span>
<span class="p_add">+extern void *plat_unmap_coherent(void *addr);</span>
<span class="p_add">+</span>
 #include &lt;asm/mach-generic/dma-coherence.h&gt;
 
 #endif /* __ASM_MACH_BMIPS_DMA_COHERENCE_H */
<span class="p_header">diff --git a/arch/mips/include/asm/mach-bmips/ioremap.h b/arch/mips/include/asm/mach-bmips/ioremap.h</span>
<span class="p_header">index 52632ebc705f..e3333d1e52c6 100644</span>
<span class="p_header">--- a/arch/mips/include/asm/mach-bmips/ioremap.h</span>
<span class="p_header">+++ b/arch/mips/include/asm/mach-bmips/ioremap.h</span>
<span class="p_chunk">@@ -9,26 +9,8 @@</span> <span class="p_context"> static inline phys_addr_t fixup_bigphys_addr(phys_addr_t phys_addr, phys_addr_t</span>
 	return phys_addr;
 }
 
<span class="p_del">-static inline int is_bmips_internal_registers(phys_addr_t offset)</span>
<span class="p_del">-{</span>
<span class="p_del">-	if (offset &gt;= 0xfff80000)</span>
<span class="p_del">-		return 1;</span>
<span class="p_del">-</span>
<span class="p_del">-	return 0;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static inline void __iomem *plat_ioremap(phys_addr_t offset, unsigned long size,</span>
<span class="p_del">-					 unsigned long flags)</span>
<span class="p_del">-{</span>
<span class="p_del">-	if (is_bmips_internal_registers(offset))</span>
<span class="p_del">-		return (void __iomem *)offset;</span>
<span class="p_del">-</span>
<span class="p_del">-	return NULL;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static inline int plat_iounmap(const volatile void __iomem *addr)</span>
<span class="p_del">-{</span>
<span class="p_del">-	return is_bmips_internal_registers((unsigned long)addr);</span>
<span class="p_del">-}</span>
<span class="p_add">+extern void __iomem *plat_ioremap(phys_addr_t offset, unsigned long size,</span>
<span class="p_add">+		        unsigned long flags);</span>
<span class="p_add">+extern int plat_iounmap(const volatile void __iomem *addr);</span>
 
<span class="p_del">-#endif /* __ASM_MACH_BMIPS_IOREMAP_H */</span>
<span class="p_add">+#endif /* __ASM_MACH_BMIPS_GENERIC_IOREMAP_H */</span>
<span class="p_header">diff --git a/arch/mips/include/asm/mach-bmips/kernel-entry-init.h b/arch/mips/include/asm/mach-bmips/kernel-entry-init.h</span>
new file mode 100644
<span class="p_header">index 000000000000..48a6768cd664</span>
<span class="p_header">--- /dev/null</span>
<span class="p_header">+++ b/arch/mips/include/asm/mach-bmips/kernel-entry-init.h</span>
<span class="p_chunk">@@ -0,0 +1,18 @@</span> <span class="p_context"></span>
<span class="p_add">+#ifndef __ASM_MACH_BMIPS_GENERIC_KERNEL_ENTRY_H</span>
<span class="p_add">+#define __ASM_MACH_BMIPS_GENERIC_KERNEL_ENTRY_H</span>
<span class="p_add">+</span>
<span class="p_add">+	.macro kernel_entry_setup</span>
<span class="p_add">+</span>
<span class="p_add">+	# save arguments for CFE callback</span>
<span class="p_add">+	sw      a0, cfe_handle</span>
<span class="p_add">+	sw      a2, cfe_entry</span>
<span class="p_add">+	sw      a3, cfe_seal</span>
<span class="p_add">+</span>
<span class="p_add">+	jal     bmips_enable_xks01</span>
<span class="p_add">+</span>
<span class="p_add">+	.endm</span>
<span class="p_add">+</span>
<span class="p_add">+	.macro  smp_slave_setup</span>
<span class="p_add">+	.endm</span>
<span class="p_add">+</span>
<span class="p_add">+#endif /* __ASM_MACH_BMIPS_GENERIC_KERNEL_ENTRY_H */</span>
<span class="p_header">diff --git a/arch/mips/include/asm/mach-bmips/spaces.h b/arch/mips/include/asm/mach-bmips/spaces.h</span>
<span class="p_header">index c59b28fd9e1d..439e05a80ac9 100644</span>
<span class="p_header">--- a/arch/mips/include/asm/mach-bmips/spaces.h</span>
<span class="p_header">+++ b/arch/mips/include/asm/mach-bmips/spaces.h</span>
<span class="p_chunk">@@ -13,6 +13,108 @@</span> <span class="p_context"></span>
 /* Avoid collisions with system base register (SBR) region on BMIPS3300 */
 #include &lt;asm/bmips-spaces.h&gt;
 
<span class="p_add">+#include &lt;linux/const.h&gt;</span>
<span class="p_add">+#include &lt;asm/mipsregs.h&gt;</span>
<span class="p_add">+#include &lt;asm/addrspace.h&gt;</span>
<span class="p_add">+#include &lt;asm/cpu.h&gt;</span>
<span class="p_add">+</span>
<span class="p_add">+/*</span>
<span class="p_add">+ * 1024MB Broadcom 256+768 virtual address map</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * 8000_0000 - 8fff_ffff: 256MB RAM @ 0000_0000, cached</span>
<span class="p_add">+ * 9000_0000 - 9fff_ffff: 256MB EBI/Registers @ 1000_0000, uncached</span>
<span class="p_add">+ * a000_0000 - cfff_ffff: 768MB RAM @ 2000_0000, cached</span>
<span class="p_add">+ * d000_0000 - dfff_ffff: TBD</span>
<span class="p_add">+ * e000_0000 - ff1f_7fff: vmalloc region</span>
<span class="p_add">+ * ff1f_8000 - ff1f_ffff: FIXMAP</span>
<span class="p_add">+ * ff40_0000 - ff7f_ffff: CONSISTENT region</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * PA 5000_0000 and above are accessed through HIGHMEM (BMIPS5000 only).</span>
<span class="p_add">+ */</span>
<span class="p_add">+#define TLB_UPPERMEM_VA         _AC(0xc0000000, UL)</span>
<span class="p_add">+#define TLB_UPPERMEM_PA         _AC(0x40000000, UL)</span>
<span class="p_add">+</span>
<span class="p_add">+#ifndef __ASSEMBLY__</span>
<span class="p_add">+static inline unsigned long kseg0_size(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	switch (read_c0_prid() &amp; PRID_IMP_MASK) {</span>
<span class="p_add">+	case PRID_IMP_BMIPS5000:</span>
<span class="p_add">+	case PRID_IMP_BMIPS5200:</span>
<span class="p_add">+		return _AC(0x40000000, UL);</span>
<span class="p_add">+	default:</span>
<span class="p_add">+		return _AC(0x20000000, UL);</span>
<span class="p_add">+	}</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline unsigned long kseg1_size(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	switch (read_c0_prid() &amp; PRID_IMP_MASK) {</span>
<span class="p_add">+	case PRID_IMP_BMIPS5000:</span>
<span class="p_add">+	case PRID_IMP_BMIPS5200:</span>
<span class="p_add">+		return _AC(0x0, UL);</span>
<span class="p_add">+	default:</span>
<span class="p_add">+		return _AC(0x20000000, UL);</span>
<span class="p_add">+	}</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline unsigned long map_base(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	switch (read_c0_prid() &amp; PRID_IMP_MASK) {</span>
<span class="p_add">+	case PRID_IMP_BMIPS5000:</span>
<span class="p_add">+	case PRID_IMP_BMIPS5200:</span>
<span class="p_add">+		return _AC(0xe0000000, UL);</span>
<span class="p_add">+	default:</span>
<span class="p_add">+		return _AC(0xc0000000, UL);</span>
<span class="p_add">+	}</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline unsigned long brcm_max_upper_mb(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	switch (read_c0_prid() &amp; PRID_IMP_MASK) {</span>
<span class="p_add">+	case PRID_IMP_BMIPS5000:</span>
<span class="p_add">+	case PRID_IMP_BMIPS5200:</span>
<span class="p_add">+		return _AC(768, UL);</span>
<span class="p_add">+	default:</span>
<span class="p_add">+		return _AC(0, UL);</span>
<span class="p_add">+	}</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline unsigned long plat_kseg1(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	switch (read_c0_prid() &amp; PRID_IMP_MASK) {</span>
<span class="p_add">+	case PRID_IMP_BMIPS5000:</span>
<span class="p_add">+	case PRID_IMP_BMIPS5200:</span>
<span class="p_add">+		return 0x80000000;</span>
<span class="p_add">+	default:</span>
<span class="p_add">+		return 0xa0000000;</span>
<span class="p_add">+	}</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+#define KSEG0_SIZE              kseg0_size()</span>
<span class="p_add">+#define KSEG1_SIZE		kseg1_size()</span>
<span class="p_add">+#define MAP_BASE		map_base()</span>
<span class="p_add">+/* BASE and END must be 4MB-aligned (PGDIR_SIZE) */</span>
<span class="p_add">+#define CONSISTENT_BASE         _AC(0xff400000, UL)</span>
<span class="p_add">+#define CONSISTENT_END          _AC(0xff800000, UL)</span>
<span class="p_add">+#define BRCM_MAX_UPPER_MB       brcm_max_upper_mb()</span>
<span class="p_add">+#else</span>
<span class="p_add">+</span>
<span class="p_add">+#define TLB_UPPERMEM_VA         _AC(0xc0000000, UL)</span>
<span class="p_add">+#define TLB_UPPERMEM_PA         _AC(0x40000000, UL)</span>
<span class="p_add">+#define KSEG0_SIZE              _AC(0x40000000, UL)</span>
<span class="p_add">+#define KSEG1_SIZE              _AC(0x00000000, UL)</span>
<span class="p_add">+#define MAP_BASE                _AC(0xe0000000, UL)</span>
<span class="p_add">+/* BASE and END must be 4MB-aligned (PGDIR_SIZE) */</span>
<span class="p_add">+#define CONSISTENT_BASE         _AC(0xff400000, UL)</span>
<span class="p_add">+#define CONSISTENT_END          _AC(0xff800000, UL)</span>
<span class="p_add">+#define BRCM_MAX_UPPER_MB       _AC(768, UL)</span>
<span class="p_add">+#endif</span>
<span class="p_add">+</span>
<span class="p_add">+#define BRCM_MAX_LOWER_MB	_AC(256, UL)</span>
<span class="p_add">+</span>
<span class="p_add">+#define UPPERMEM_START		_AC(0x20000000, UL)</span>
<span class="p_add">+#define HIGHMEM_START		(UPPERMEM_START + (BRCM_MAX_UPPER_MB &lt;&lt; 20))</span>
<span class="p_add">+</span>
 #include &lt;asm/mach-generic/spaces.h&gt;
 
 #endif /* __ASM_BMIPS_SPACES_H */

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



