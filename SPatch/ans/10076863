
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>[v2,07/35] nds32: Cache and TLB routines - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    [v2,07/35] nds32: Cache and TLB routines</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=171217">Greentime Hu</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>Nov. 27, 2017, 12:27 p.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;8e7c0bc03415bade418f626109f1bd0fd83ba354.1511785528.git.green.hu@gmail.com&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/10076863/mbox/"
   >mbox</a>
|
   <a href="/patch/10076863/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/10076863/">/patch/10076863/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
	[172.30.200.125])
	by pdx-korg-patchwork.web.codeaurora.org (Postfix) with ESMTP id
	EB20460353 for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Mon, 27 Nov 2017 13:08:07 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id D3FB628AFD
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Mon, 27 Nov 2017 13:08:07 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id C829328DAC; Mon, 27 Nov 2017 13:08:07 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-7.0 required=2.0 tests=BAYES_00,DKIM_SIGNED,
	DKIM_VALID, DKIM_VALID_AU, FREEMAIL_FROM,
	RCVD_IN_DNSWL_HI autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 7FF9428AFD
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Mon, 27 Nov 2017 13:08:05 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1752684AbdK0NIE (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Mon, 27 Nov 2017 08:08:04 -0500
Received: from mail-pl0-f67.google.com ([209.85.160.67]:41062 &quot;EHLO
	mail-pl0-f67.google.com&quot; rhost-flags-OK-OK-OK-OK) by vger.kernel.org
	with ESMTP id S1752331AbdK0Mxr (ORCPT
	&lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Mon, 27 Nov 2017 07:53:47 -0500
Received: by mail-pl0-f67.google.com with SMTP id u14so8424122plm.8;
	Mon, 27 Nov 2017 04:53:46 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
	d=gmail.com; s=20161025;
	h=from:to:cc:subject:date:message-id:in-reply-to:references
	:in-reply-to:references;
	bh=4ngRAmLL6ccaFAic1apTIdSOQoOa+cMr2XIyaKqzH6Y=;
	b=m/7SM2+b0c5R8Hj+IZd006fyKiLrNIxLV1Rc0JDbjqx4swLDwrdYJJ9swAUuu1fADf
	1BWWi6trogWYqK/gSRNKXm4Ghwq+IV85D3xJz5Qx9VkIEx3P1dA10cMBZDFaaDtWN41X
	it/ttToOHlGmADJibKRDp/2VnC5gG/+zsrtoe70pwQc9glvIPet4VNkWPG7CwAztxjG8
	00ywZvZz/o1Ij7EHXU3h2tjpun+hxH3UlN0BVO060yzT5Bev0olY8KfaftPsercnXE4Q
	5tVeFl9L1cHdtBP/APi0sHB2yVOUKUl4h1wATVY1G+y7xQwRTZwyfE/KHLKrrj6HO+G1
	VltA==
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
	d=1e100.net; s=20161025;
	h=x-gm-message-state:from:to:cc:subject:date:message-id:in-reply-to
	:references:in-reply-to:references;
	bh=4ngRAmLL6ccaFAic1apTIdSOQoOa+cMr2XIyaKqzH6Y=;
	b=DUoCqxBlZV1KGRC2MW9h8uxwvPLoGk4Gh598NiHy+FD17Z4+wFZWFrUpH3SE5H1StL
	qm4Vvt75pi4PuMeBRAUWQgRAvY/IiZn0oXCpvPAaBQRC5SAJaZSfqvQX69/2Px+lmswk
	Axn1mwYRboaJi2ugRAlCy3KMl4dLHRU/73ydZROpFnTuLJIpV2QOBDUMwdRNG/nVSnbM
	1xJv2PNCcTKAo984fDJv0YjCarixR02WzR/N5mJM4J6yAF8LpyUG8xRcVaHwOAsb6Pi/
	F4kn7mEPL/z91FxMyVZgZ1FBTZSTIdEcrjJDPuypTDNWBElhb6iGSHUQAwPjrF8EgU7c
	w3yw==
X-Gm-Message-State: AJaThX4iffxfoqIne0IHZS2/uqV7bci13Qp2KZVPXoRPbVRlowj7HIMj
	+v/GwG1i+cUS8dc2aayXFrQ=
X-Google-Smtp-Source: AGs4zMaqbSNYibzhVFXJf6TU4tZnY37RuOOMZcfL/cbunkgn1ZQ9biwWCtWCVYeePp83lTSY4gNGRQ==
X-Received: by 10.159.230.16 with SMTP id u16mr909857plq.41.1511787225866;
	Mon, 27 Nov 2017 04:53:45 -0800 (PST)
Received: from app09.andestech.com ([118.163.51.199])
	by smtp.gmail.com with ESMTPSA id
	w64sm55225459pfj.62.2017.11.27.04.53.42
	(version=TLS1_2 cipher=ECDHE-RSA-AES128-GCM-SHA256 bits=128/128);
	Mon, 27 Nov 2017 04:53:45 -0800 (PST)
From: Greentime Hu &lt;green.hu@gmail.com&gt;
To: greentime@andestech.com, linux-kernel@vger.kernel.org,
	arnd@arndb.de, linux-arch@vger.kernel.org, tglx@linutronix.de,
	jason@lakedaemon.net, marc.zyngier@arm.com, robh+dt@kernel.org,
	netdev@vger.kernel.org, deanbo422@gmail.com,
	devicetree@vger.kernel.org, viro@zeniv.linux.org.uk,
	dhowells@redhat.com, will.deacon@arm.com,
	daniel.lezcano@linaro.org, linux-serial@vger.kernel.org
Cc: green.hu@gmail.com, Vincent Chen &lt;vincentc@andestech.com&gt;
Subject: [PATCH v2 07/35] nds32: Cache and TLB routines
Date: Mon, 27 Nov 2017 20:27:54 +0800
Message-Id: &lt;8e7c0bc03415bade418f626109f1bd0fd83ba354.1511785528.git.green.hu@gmail.com&gt;
X-Mailer: git-send-email 1.7.9.5
In-Reply-To: &lt;cover.1511785528.git.green.hu@gmail.com&gt;
References: &lt;cover.1511785528.git.green.hu@gmail.com&gt;
In-Reply-To: &lt;cover.1511785528.git.green.hu@gmail.com&gt;
References: &lt;cover.1511785528.git.green.hu@gmail.com&gt;
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=171217">Greentime Hu</a> - Nov. 27, 2017, 12:27 p.m.</div>
<pre class="content">
<span class="from">From: Greentime Hu &lt;greentime@andestech.com&gt;</span>

This patch contains cache and TLB maintenance functions.
<span class="signed-off-by">
Signed-off-by: Vincent Chen &lt;vincentc@andestech.com&gt;</span>
<span class="signed-off-by">Signed-off-by: Greentime Hu &lt;greentime@andestech.com&gt;</span>
---
 arch/nds32/include/asm/cache.h         |   25 ++
 arch/nds32/include/asm/cache_info.h    |   26 ++
 arch/nds32/include/asm/cacheflush.h    |   57 +++
 arch/nds32/include/asm/mmu_context.h   |   81 +++++
 arch/nds32/include/asm/proc-fns.h      |   57 +++
 arch/nds32/include/asm/tlb.h           |   41 +++
 arch/nds32/include/asm/tlbflush.h      |   60 ++++
 arch/nds32/include/uapi/asm/cachectl.h |   19 +
 arch/nds32/kernel/cacheinfo.c          |   62 ++++
 arch/nds32/mm/cacheflush.c             |  331 ++++++++++++++++++
 arch/nds32/mm/proc.c                   |  601 ++++++++++++++++++++++++++++++++
 arch/nds32/mm/tlb.c                    |   63 ++++
 12 files changed, 1423 insertions(+)
 create mode 100644 arch/nds32/include/asm/cache.h
 create mode 100644 arch/nds32/include/asm/cache_info.h
 create mode 100644 arch/nds32/include/asm/cacheflush.h
 create mode 100644 arch/nds32/include/asm/mmu_context.h
 create mode 100644 arch/nds32/include/asm/proc-fns.h
 create mode 100644 arch/nds32/include/asm/tlb.h
 create mode 100644 arch/nds32/include/asm/tlbflush.h
 create mode 100644 arch/nds32/include/uapi/asm/cachectl.h
 create mode 100644 arch/nds32/kernel/cacheinfo.c
 create mode 100644 arch/nds32/mm/cacheflush.c
 create mode 100644 arch/nds32/mm/proc.c
 create mode 100644 arch/nds32/mm/tlb.c
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/arch/nds32/include/asm/cache.h b/arch/nds32/include/asm/cache.h</span>
new file mode 100644
<span class="p_header">index 0000000..36ec549</span>
<span class="p_header">--- /dev/null</span>
<span class="p_header">+++ b/arch/nds32/include/asm/cache.h</span>
<span class="p_chunk">@@ -0,0 +1,25 @@</span> <span class="p_context"></span>
<span class="p_add">+/*</span>
<span class="p_add">+ * Copyright (C) 2005-2017 Andes Technology Corporation</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * This program is free software; you can redistribute it and/or modify</span>
<span class="p_add">+ * it under the terms of the GNU General Public License version 2 as</span>
<span class="p_add">+ * published by the Free Software Foundation.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * This program is distributed in the hope that it will be useful,</span>
<span class="p_add">+ * but WITHOUT ANY WARRANTY; without even the implied warranty of</span>
<span class="p_add">+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the</span>
<span class="p_add">+ * GNU General Public License for more details.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * You should have received a copy of the GNU General Public License</span>
<span class="p_add">+ * along with this program.  If not, see &lt;http://www.gnu.org/licenses/&gt;.</span>
<span class="p_add">+ */</span>
<span class="p_add">+</span>
<span class="p_add">+#ifndef __NDS32_CACHE_H__</span>
<span class="p_add">+#define __NDS32_CACHE_H__</span>
<span class="p_add">+</span>
<span class="p_add">+#define L1_CACHE_BYTES	32</span>
<span class="p_add">+#define L1_CACHE_SHIFT	5</span>
<span class="p_add">+</span>
<span class="p_add">+#define ARCH_DMA_MINALIGN   L1_CACHE_BYTES</span>
<span class="p_add">+</span>
<span class="p_add">+#endif /* __NDS32_CACHE_H__ */</span>
<span class="p_header">diff --git a/arch/nds32/include/asm/cache_info.h b/arch/nds32/include/asm/cache_info.h</span>
new file mode 100644
<span class="p_header">index 0000000..a59d73d</span>
<span class="p_header">--- /dev/null</span>
<span class="p_header">+++ b/arch/nds32/include/asm/cache_info.h</span>
<span class="p_chunk">@@ -0,0 +1,26 @@</span> <span class="p_context"></span>
<span class="p_add">+/*</span>
<span class="p_add">+ * Copyright (C) 2005-2017 Andes Technology Corporation</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * This program is free software; you can redistribute it and/or modify</span>
<span class="p_add">+ * it under the terms of the GNU General Public License version 2 as</span>
<span class="p_add">+ * published by the Free Software Foundation.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * This program is distributed in the hope that it will be useful,</span>
<span class="p_add">+ * but WITHOUT ANY WARRANTY; without even the implied warranty of</span>
<span class="p_add">+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the</span>
<span class="p_add">+ * GNU General Public License for more details.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * You should have received a copy of the GNU General Public License</span>
<span class="p_add">+ * along with this program.  If not, see &lt;http://www.gnu.org/licenses/&gt;.</span>
<span class="p_add">+ */</span>
<span class="p_add">+</span>
<span class="p_add">+struct cache_info {</span>
<span class="p_add">+	unsigned char ways;</span>
<span class="p_add">+	unsigned char line_size;</span>
<span class="p_add">+	unsigned short sets;</span>
<span class="p_add">+	unsigned short size;</span>
<span class="p_add">+#if !defined(CONFIG_CPU_CACHE_NONALIASING)</span>
<span class="p_add">+	unsigned short aliasing_num;</span>
<span class="p_add">+	unsigned int aliasing_mask;</span>
<span class="p_add">+#endif</span>
<span class="p_add">+};</span>
<span class="p_header">diff --git a/arch/nds32/include/asm/cacheflush.h b/arch/nds32/include/asm/cacheflush.h</span>
new file mode 100644
<span class="p_header">index 0000000..0c7c9db</span>
<span class="p_header">--- /dev/null</span>
<span class="p_header">+++ b/arch/nds32/include/asm/cacheflush.h</span>
<span class="p_chunk">@@ -0,0 +1,57 @@</span> <span class="p_context"></span>
<span class="p_add">+/*</span>
<span class="p_add">+ * Copyright (C) 2005-2017 Andes Technology Corporation</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * This program is free software; you can redistribute it and/or modify</span>
<span class="p_add">+ * it under the terms of the GNU General Public License version 2 as</span>
<span class="p_add">+ * published by the Free Software Foundation.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * This program is distributed in the hope that it will be useful,</span>
<span class="p_add">+ * but WITHOUT ANY WARRANTY; without even the implied warranty of</span>
<span class="p_add">+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the</span>
<span class="p_add">+ * GNU General Public License for more details.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * You should have received a copy of the GNU General Public License</span>
<span class="p_add">+ * along with this program.  If not, see &lt;http://www.gnu.org/licenses/&gt;.</span>
<span class="p_add">+ */</span>
<span class="p_add">+</span>
<span class="p_add">+#ifndef __NDS32_CACHEFLUSH_H__</span>
<span class="p_add">+#define __NDS32_CACHEFLUSH_H__</span>
<span class="p_add">+</span>
<span class="p_add">+#include &lt;linux/mm.h&gt;</span>
<span class="p_add">+</span>
<span class="p_add">+#define PG_dcache_dirty PG_arch_1</span>
<span class="p_add">+</span>
<span class="p_add">+#ifndef CONFIG_CPU_CACHE_NONALIASING</span>
<span class="p_add">+void flush_cache_mm(struct mm_struct *mm);</span>
<span class="p_add">+void flush_cache_dup_mm(struct mm_struct *mm);</span>
<span class="p_add">+void flush_cache_range(struct vm_area_struct *vma,</span>
<span class="p_add">+		       unsigned long start, unsigned long end);</span>
<span class="p_add">+void flush_cache_page(struct vm_area_struct *vma,</span>
<span class="p_add">+		      unsigned long addr, unsigned long pfn);</span>
<span class="p_add">+void flush_cache_kmaps(void);</span>
<span class="p_add">+void flush_cache_vmap(unsigned long start, unsigned long end);</span>
<span class="p_add">+void flush_cache_vunmap(unsigned long start, unsigned long end);</span>
<span class="p_add">+</span>
<span class="p_add">+#define ARCH_IMPLEMENTS_FLUSH_DCACHE_PAGE 1</span>
<span class="p_add">+void flush_dcache_page(struct page *page);</span>
<span class="p_add">+void copy_to_user_page(struct vm_area_struct *vma, struct page *page,</span>
<span class="p_add">+		       unsigned long vaddr, void *dst, void *src, int len);</span>
<span class="p_add">+void copy_from_user_page(struct vm_area_struct *vma, struct page *page,</span>
<span class="p_add">+			 unsigned long vaddr, void *dst, void *src, int len);</span>
<span class="p_add">+</span>
<span class="p_add">+#define ARCH_HAS_FLUSH_ANON_PAGE</span>
<span class="p_add">+void flush_anon_page(struct vm_area_struct *vma,</span>
<span class="p_add">+		     struct page *page, unsigned long vaddr);</span>
<span class="p_add">+</span>
<span class="p_add">+#define ARCH_HAS_FLUSH_KERNEL_DCACHE_PAGE</span>
<span class="p_add">+void flush_kernel_dcache_page(struct page *page);</span>
<span class="p_add">+void flush_icache_range(unsigned long start, unsigned long end);</span>
<span class="p_add">+void flush_icache_page(struct vm_area_struct *vma, struct page *page);</span>
<span class="p_add">+#define flush_dcache_mmap_lock(mapping)   spin_lock_irq(&amp;(mapping)-&gt;tree_lock)</span>
<span class="p_add">+#define flush_dcache_mmap_unlock(mapping) spin_unlock_irq(&amp;(mapping)-&gt;tree_lock)</span>
<span class="p_add">+</span>
<span class="p_add">+#else</span>
<span class="p_add">+#include &lt;asm-generic/cacheflush.h&gt;</span>
<span class="p_add">+#endif</span>
<span class="p_add">+</span>
<span class="p_add">+#endif /* __NDS32_CACHEFLUSH_H__ */</span>
<span class="p_header">diff --git a/arch/nds32/include/asm/mmu_context.h b/arch/nds32/include/asm/mmu_context.h</span>
new file mode 100644
<span class="p_header">index 0000000..4a59b5d</span>
<span class="p_header">--- /dev/null</span>
<span class="p_header">+++ b/arch/nds32/include/asm/mmu_context.h</span>
<span class="p_chunk">@@ -0,0 +1,81 @@</span> <span class="p_context"></span>
<span class="p_add">+/*</span>
<span class="p_add">+ * Copyright (C) 2005-2017 Andes Technology Corporation</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * This program is free software; you can redistribute it and/or modify</span>
<span class="p_add">+ * it under the terms of the GNU General Public License version 2 as</span>
<span class="p_add">+ * published by the Free Software Foundation.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * This program is distributed in the hope that it will be useful,</span>
<span class="p_add">+ * but WITHOUT ANY WARRANTY; without even the implied warranty of</span>
<span class="p_add">+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the</span>
<span class="p_add">+ * GNU General Public License for more details.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * You should have received a copy of the GNU General Public License</span>
<span class="p_add">+ * along with this program.  If not, see &lt;http://www.gnu.org/licenses/&gt;.</span>
<span class="p_add">+ */</span>
<span class="p_add">+</span>
<span class="p_add">+#ifndef __ASM_NDS32_MMU_CONTEXT_H</span>
<span class="p_add">+#define __ASM_NDS32_MMU_CONTEXT_H</span>
<span class="p_add">+</span>
<span class="p_add">+#include &lt;linux/spinlock.h&gt;</span>
<span class="p_add">+#include &lt;asm/tlbflush.h&gt;</span>
<span class="p_add">+#include &lt;asm/proc-fns.h&gt;</span>
<span class="p_add">+#include &lt;asm-generic/mm_hooks.h&gt;</span>
<span class="p_add">+</span>
<span class="p_add">+static inline int</span>
<span class="p_add">+init_new_context(struct task_struct *tsk, struct mm_struct *mm)</span>
<span class="p_add">+{</span>
<span class="p_add">+	mm-&gt;context.id = 0;</span>
<span class="p_add">+	return 0;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+#define destroy_context(mm)	do { } while(0)</span>
<span class="p_add">+</span>
<span class="p_add">+#define CID_BITS	9</span>
<span class="p_add">+extern spinlock_t cid_lock;</span>
<span class="p_add">+extern unsigned int cpu_last_cid;</span>
<span class="p_add">+</span>
<span class="p_add">+static inline void __new_context(struct mm_struct *mm)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned int cid;</span>
<span class="p_add">+	unsigned long flags;</span>
<span class="p_add">+</span>
<span class="p_add">+	spin_lock_irqsave(&amp;cid_lock, flags);</span>
<span class="p_add">+	cid = cpu_last_cid;</span>
<span class="p_add">+	cpu_last_cid += 1 &lt;&lt; TLB_MISC_offCID;</span>
<span class="p_add">+	if (cpu_last_cid == 0)</span>
<span class="p_add">+		cpu_last_cid = 1 &lt;&lt; TLB_MISC_offCID &lt;&lt; CID_BITS;</span>
<span class="p_add">+</span>
<span class="p_add">+	if ((cid &amp; TLB_MISC_mskCID) == 0)</span>
<span class="p_add">+		flush_tlb_all();</span>
<span class="p_add">+	spin_unlock_irqrestore(&amp;cid_lock, flags);</span>
<span class="p_add">+</span>
<span class="p_add">+	mm-&gt;context.id = cid;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline void check_context(struct mm_struct *mm)</span>
<span class="p_add">+{</span>
<span class="p_add">+	if (unlikely</span>
<span class="p_add">+	    ((mm-&gt;context.id ^ cpu_last_cid) &gt;&gt; TLB_MISC_offCID &gt;&gt; CID_BITS))</span>
<span class="p_add">+		__new_context(mm);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline void enter_lazy_tlb(struct mm_struct *mm, struct task_struct *tsk)</span>
<span class="p_add">+{</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline void switch_mm(struct mm_struct *prev, struct mm_struct *next,</span>
<span class="p_add">+			     struct task_struct *tsk)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned int cpu = smp_processor_id();</span>
<span class="p_add">+</span>
<span class="p_add">+	if (!cpumask_test_and_set_cpu(cpu, mm_cpumask(next)) || prev != next) {</span>
<span class="p_add">+		check_context(next);</span>
<span class="p_add">+		cpu_switch_mm(next);</span>
<span class="p_add">+	}</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+#define deactivate_mm(tsk,mm)	do { } while (0)</span>
<span class="p_add">+#define activate_mm(prev,next)	switch_mm(prev, next, NULL)</span>
<span class="p_add">+</span>
<span class="p_add">+#endif</span>
<span class="p_header">diff --git a/arch/nds32/include/asm/proc-fns.h b/arch/nds32/include/asm/proc-fns.h</span>
new file mode 100644
<span class="p_header">index 0000000..b1a56d2</span>
<span class="p_header">--- /dev/null</span>
<span class="p_header">+++ b/arch/nds32/include/asm/proc-fns.h</span>
<span class="p_chunk">@@ -0,0 +1,57 @@</span> <span class="p_context"></span>
<span class="p_add">+/*</span>
<span class="p_add">+ * Copyright (C) 2005-2017 Andes Technology Corporation</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * This program is free software; you can redistribute it and/or modify</span>
<span class="p_add">+ * it under the terms of the GNU General Public License version 2 as</span>
<span class="p_add">+ * published by the Free Software Foundation.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * This program is distributed in the hope that it will be useful,</span>
<span class="p_add">+ * but WITHOUT ANY WARRANTY; without even the implied warranty of</span>
<span class="p_add">+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the</span>
<span class="p_add">+ * GNU General Public License for more details.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * You should have received a copy of the GNU General Public License</span>
<span class="p_add">+ * along with this program.  If not, see &lt;http://www.gnu.org/licenses/&gt;.</span>
<span class="p_add">+ */</span>
<span class="p_add">+</span>
<span class="p_add">+#ifndef __NDS32_PROCFNS_H__</span>
<span class="p_add">+#define __NDS32_PROCFNS_H__</span>
<span class="p_add">+</span>
<span class="p_add">+#ifdef __KERNEL__</span>
<span class="p_add">+#include &lt;asm/page.h&gt;</span>
<span class="p_add">+</span>
<span class="p_add">+struct mm_struct;</span>
<span class="p_add">+struct vm_area_struct;</span>
<span class="p_add">+extern void cpu_proc_init(void);</span>
<span class="p_add">+extern void cpu_proc_fin(void);</span>
<span class="p_add">+extern void cpu_do_idle(void);</span>
<span class="p_add">+extern void cpu_reset(unsigned long reset);</span>
<span class="p_add">+extern void cpu_switch_mm(struct mm_struct *mm);</span>
<span class="p_add">+</span>
<span class="p_add">+extern void cpu_dcache_inval_all(void);</span>
<span class="p_add">+extern void cpu_dcache_wbinval_all(void);</span>
<span class="p_add">+extern void cpu_dcache_inval_page(unsigned long page);</span>
<span class="p_add">+extern void cpu_dcache_wb_page(unsigned long page);</span>
<span class="p_add">+extern void cpu_dcache_wbinval_page(unsigned long page);</span>
<span class="p_add">+extern void cpu_dcache_inval_range(unsigned long start, unsigned long end);</span>
<span class="p_add">+extern void cpu_dcache_wb_range(unsigned long start, unsigned long end);</span>
<span class="p_add">+extern void cpu_dcache_wbinval_range(unsigned long start, unsigned long end);</span>
<span class="p_add">+</span>
<span class="p_add">+extern void cpu_icache_inval_all(void);</span>
<span class="p_add">+extern void cpu_icache_inval_page(unsigned long page);</span>
<span class="p_add">+extern void cpu_icache_inval_range(unsigned long start, unsigned long end);</span>
<span class="p_add">+</span>
<span class="p_add">+extern void cpu_cache_wbinval_page(unsigned long page, int flushi);</span>
<span class="p_add">+extern void cpu_cache_wbinval_range(unsigned long start,</span>
<span class="p_add">+				    unsigned long end, int flushi);</span>
<span class="p_add">+extern void cpu_cache_wbinval_range_check(struct vm_area_struct *vma,</span>
<span class="p_add">+					  unsigned long start,</span>
<span class="p_add">+					  unsigned long end, bool flushi,</span>
<span class="p_add">+					  bool wbd);</span>
<span class="p_add">+</span>
<span class="p_add">+extern void cpu_dma_wb_range(unsigned long start, unsigned long end);</span>
<span class="p_add">+extern void cpu_dma_inval_range(unsigned long start, unsigned long end);</span>
<span class="p_add">+extern void cpu_dma_wbinval_range(unsigned long start, unsigned long end);</span>
<span class="p_add">+</span>
<span class="p_add">+#endif /* __KERNEL__ */</span>
<span class="p_add">+#endif /* __NDS32_PROCFNS_H__ */</span>
<span class="p_header">diff --git a/arch/nds32/include/asm/tlb.h b/arch/nds32/include/asm/tlb.h</span>
new file mode 100644
<span class="p_header">index 0000000..c599827</span>
<span class="p_header">--- /dev/null</span>
<span class="p_header">+++ b/arch/nds32/include/asm/tlb.h</span>
<span class="p_chunk">@@ -0,0 +1,41 @@</span> <span class="p_context"></span>
<span class="p_add">+/*</span>
<span class="p_add">+ * Copyright (C) 2005-2017 Andes Technology Corporation</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * This program is free software; you can redistribute it and/or modify</span>
<span class="p_add">+ * it under the terms of the GNU General Public License version 2 as</span>
<span class="p_add">+ * published by the Free Software Foundation.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * This program is distributed in the hope that it will be useful,</span>
<span class="p_add">+ * but WITHOUT ANY WARRANTY; without even the implied warranty of</span>
<span class="p_add">+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the</span>
<span class="p_add">+ * GNU General Public License for more details.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * You should have received a copy of the GNU General Public License</span>
<span class="p_add">+ * along with this program.  If not, see &lt;http://www.gnu.org/licenses/&gt;.</span>
<span class="p_add">+ */</span>
<span class="p_add">+</span>
<span class="p_add">+#ifndef __ASMNDS32_TLB_H</span>
<span class="p_add">+#define __ASMNDS32_TLB_H</span>
<span class="p_add">+</span>
<span class="p_add">+#define tlb_start_vma(tlb,vma)						\</span>
<span class="p_add">+	do {								\</span>
<span class="p_add">+		if (!tlb-&gt;fullmm)					\</span>
<span class="p_add">+			flush_cache_range(vma, vma-&gt;vm_start, vma-&gt;vm_end); \</span>
<span class="p_add">+	} while (0)</span>
<span class="p_add">+</span>
<span class="p_add">+#define tlb_end_vma(tlb,vma)				\</span>
<span class="p_add">+	do { 						\</span>
<span class="p_add">+		if(!tlb-&gt;fullmm)			\</span>
<span class="p_add">+			flush_tlb_range(vma, vma-&gt;vm_start, vma-&gt;vm_end); \</span>
<span class="p_add">+	} while (0)</span>
<span class="p_add">+</span>
<span class="p_add">+#define __tlb_remove_tlb_entry(tlb, pte, addr) do { } while (0)</span>
<span class="p_add">+</span>
<span class="p_add">+#define tlb_flush(tlb)	flush_tlb_mm((tlb)-&gt;mm)</span>
<span class="p_add">+</span>
<span class="p_add">+#include &lt;asm-generic/tlb.h&gt;</span>
<span class="p_add">+</span>
<span class="p_add">+#define __pte_free_tlb(tlb, pte, addr)	pte_free((tlb)-&gt;mm, pte)</span>
<span class="p_add">+#define __pmd_free_tlb(tlb, pmd, addr)	pmd_free((tln)-&gt;mm, pmd)</span>
<span class="p_add">+</span>
<span class="p_add">+#endif</span>
<span class="p_header">diff --git a/arch/nds32/include/asm/tlbflush.h b/arch/nds32/include/asm/tlbflush.h</span>
new file mode 100644
<span class="p_header">index 0000000..680aeb3</span>
<span class="p_header">--- /dev/null</span>
<span class="p_header">+++ b/arch/nds32/include/asm/tlbflush.h</span>
<span class="p_chunk">@@ -0,0 +1,60 @@</span> <span class="p_context"></span>
<span class="p_add">+/*</span>
<span class="p_add">+ * Copyright (C) 2005-2017 Andes Technology Corporation</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * This program is free software; you can redistribute it and/or modify</span>
<span class="p_add">+ * it under the terms of the GNU General Public License version 2 as</span>
<span class="p_add">+ * published by the Free Software Foundation.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * This program is distributed in the hope that it will be useful,</span>
<span class="p_add">+ * but WITHOUT ANY WARRANTY; without even the implied warranty of</span>
<span class="p_add">+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the</span>
<span class="p_add">+ * GNU General Public License for more details.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * You should have received a copy of the GNU General Public License</span>
<span class="p_add">+ * along with this program.  If not, see &lt;http://www.gnu.org/licenses/&gt;.</span>
<span class="p_add">+ */</span>
<span class="p_add">+</span>
<span class="p_add">+#ifndef _ASMNDS32_TLBFLUSH_H</span>
<span class="p_add">+#define _ASMNDS32_TLBFLUSH_H</span>
<span class="p_add">+</span>
<span class="p_add">+#include &lt;linux/spinlock.h&gt;</span>
<span class="p_add">+#include &lt;linux/mm.h&gt;</span>
<span class="p_add">+#include &lt;nds32_intrinsic.h&gt;</span>
<span class="p_add">+</span>
<span class="p_add">+static inline void local_flush_tlb_all(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	__nds32__tlbop_flua();</span>
<span class="p_add">+	__nds32__isb();</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline void local_flush_tlb_mm(struct mm_struct *mm)</span>
<span class="p_add">+{</span>
<span class="p_add">+	__nds32__tlbop_flua();</span>
<span class="p_add">+	__nds32__isb();</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline void local_flush_tlb_kernel_range(unsigned long start,</span>
<span class="p_add">+						unsigned long end)</span>
<span class="p_add">+{</span>
<span class="p_add">+	while (start &lt; end) {</span>
<span class="p_add">+		__nds32__tlbop_inv(start);</span>
<span class="p_add">+		__nds32__isb();</span>
<span class="p_add">+		start += PAGE_SIZE;</span>
<span class="p_add">+	}</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void local_flush_tlb_range(struct vm_area_struct *vma,</span>
<span class="p_add">+			   unsigned long start, unsigned long end);</span>
<span class="p_add">+void local_flush_tlb_page(struct vm_area_struct *vma, unsigned long addr);</span>
<span class="p_add">+</span>
<span class="p_add">+#define flush_tlb_all		local_flush_tlb_all</span>
<span class="p_add">+#define flush_tlb_mm		local_flush_tlb_mm</span>
<span class="p_add">+#define flush_tlb_range		local_flush_tlb_range</span>
<span class="p_add">+#define flush_tlb_page		local_flush_tlb_page</span>
<span class="p_add">+#define flush_tlb_kernel_range	local_flush_tlb_kernel_range</span>
<span class="p_add">+</span>
<span class="p_add">+void update_mmu_cache(struct vm_area_struct *vma,</span>
<span class="p_add">+		      unsigned long address, pte_t * pte);</span>
<span class="p_add">+void tlb_migrate_finish(struct mm_struct *mm);</span>
<span class="p_add">+</span>
<span class="p_add">+#endif</span>
<span class="p_header">diff --git a/arch/nds32/include/uapi/asm/cachectl.h b/arch/nds32/include/uapi/asm/cachectl.h</span>
new file mode 100644
<span class="p_header">index 0000000..a56a37d</span>
<span class="p_header">--- /dev/null</span>
<span class="p_header">+++ b/arch/nds32/include/uapi/asm/cachectl.h</span>
<span class="p_chunk">@@ -0,0 +1,19 @@</span> <span class="p_context"></span>
<span class="p_add">+/*</span>
<span class="p_add">+ * This file is subject to the terms and conditions of the GNU General Public</span>
<span class="p_add">+ * License.  See the file &quot;COPYING&quot; in the main directory of this archive</span>
<span class="p_add">+ * for more details.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * Copyright (C) 1994, 1995, 1996 by Ralf Baechle</span>
<span class="p_add">+ * Copyright (C) 2005-2017 Andes Technology Corporation</span>
<span class="p_add">+ */</span>
<span class="p_add">+#ifndef	_ASM_CACHECTL</span>
<span class="p_add">+#define	_ASM_CACHECTL</span>
<span class="p_add">+</span>
<span class="p_add">+/*</span>
<span class="p_add">+ * Options for cacheflush system call</span>
<span class="p_add">+ */</span>
<span class="p_add">+#define	ICACHE	0		/* flush instruction cache        */</span>
<span class="p_add">+#define	DCACHE	1		/* writeback and flush data cache */</span>
<span class="p_add">+#define	BCACHE	2		/* flush instruction cache + writeback and flush data cache */</span>
<span class="p_add">+</span>
<span class="p_add">+#endif /* _ASM_CACHECTL */</span>
<span class="p_header">diff --git a/arch/nds32/kernel/cacheinfo.c b/arch/nds32/kernel/cacheinfo.c</span>
new file mode 100644
<span class="p_header">index 0000000..edc0fda</span>
<span class="p_header">--- /dev/null</span>
<span class="p_header">+++ b/arch/nds32/kernel/cacheinfo.c</span>
<span class="p_chunk">@@ -0,0 +1,62 @@</span> <span class="p_context"></span>
<span class="p_add">+/*</span>
<span class="p_add">+ * Copyright (C) 2005-2017 Andes Technology Corporation</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * This program is free software; you can redistribute it and/or modify</span>
<span class="p_add">+ * it under the terms of the GNU General Public License version 2 as</span>
<span class="p_add">+ * published by the Free Software Foundation.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * This program is distributed in the hope that it will be useful,</span>
<span class="p_add">+ * but WITHOUT ANY WARRANTY; without even the implied warranty of</span>
<span class="p_add">+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the</span>
<span class="p_add">+ * GNU General Public License for more details.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * You should have received a copy of the GNU General Public License</span>
<span class="p_add">+ * along with this program.  If not, see &lt;http://www.gnu.org/licenses/&gt;.</span>
<span class="p_add">+ */</span>
<span class="p_add">+</span>
<span class="p_add">+#include &lt;linux/bitops.h&gt;</span>
<span class="p_add">+#include &lt;linux/cacheinfo.h&gt;</span>
<span class="p_add">+#include &lt;linux/cpu.h&gt;</span>
<span class="p_add">+</span>
<span class="p_add">+static void ci_leaf_init(struct cacheinfo *this_leaf,</span>
<span class="p_add">+			 enum cache_type type, unsigned int level)</span>
<span class="p_add">+{</span>
<span class="p_add">+	char cache_type = (type &amp; CACHE_TYPE_INST ? ICACHE : DCACHE);</span>
<span class="p_add">+</span>
<span class="p_add">+	this_leaf-&gt;level = level;</span>
<span class="p_add">+	this_leaf-&gt;type = type;</span>
<span class="p_add">+	this_leaf-&gt;coherency_line_size = CACHE_LINE_SIZE(cache_type);</span>
<span class="p_add">+	this_leaf-&gt;number_of_sets = CACHE_SET(cache_type);;</span>
<span class="p_add">+	this_leaf-&gt;ways_of_associativity = CACHE_WAY(cache_type);</span>
<span class="p_add">+	this_leaf-&gt;size = this_leaf-&gt;number_of_sets *</span>
<span class="p_add">+	    this_leaf-&gt;coherency_line_size * this_leaf-&gt;ways_of_associativity;</span>
<span class="p_add">+#if defined(CONFIG_CPU_DCACHE_WRITETHROUGH)</span>
<span class="p_add">+	this_leaf-&gt;attributes = CACHE_WRITE_THROUGH;</span>
<span class="p_add">+#else</span>
<span class="p_add">+	this_leaf-&gt;attributes = CACHE_WRITE_BACK;</span>
<span class="p_add">+#endif</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+int init_cache_level(unsigned int cpu)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct cpu_cacheinfo *this_cpu_ci = get_cpu_cacheinfo(cpu);</span>
<span class="p_add">+</span>
<span class="p_add">+	/* Only 1 level and I/D cache seperate. */</span>
<span class="p_add">+	this_cpu_ci-&gt;num_levels = 1;</span>
<span class="p_add">+	this_cpu_ci-&gt;num_leaves = 2;</span>
<span class="p_add">+	return 0;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+int populate_cache_leaves(unsigned int cpu)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned int level, idx;</span>
<span class="p_add">+	struct cpu_cacheinfo *this_cpu_ci = get_cpu_cacheinfo(cpu);</span>
<span class="p_add">+	struct cacheinfo *this_leaf = this_cpu_ci-&gt;info_list;</span>
<span class="p_add">+</span>
<span class="p_add">+	for (idx = 0, level = 1; level &lt;= this_cpu_ci-&gt;num_levels &amp;&amp;</span>
<span class="p_add">+	     idx &lt; this_cpu_ci-&gt;num_leaves; idx++, level++) {</span>
<span class="p_add">+		ci_leaf_init(this_leaf++, CACHE_TYPE_DATA, level);</span>
<span class="p_add">+		ci_leaf_init(this_leaf++, CACHE_TYPE_INST, level);</span>
<span class="p_add">+	}</span>
<span class="p_add">+	return 0;</span>
<span class="p_add">+}</span>
<span class="p_header">diff --git a/arch/nds32/mm/cacheflush.c b/arch/nds32/mm/cacheflush.c</span>
new file mode 100644
<span class="p_header">index 0000000..ef733b2</span>
<span class="p_header">--- /dev/null</span>
<span class="p_header">+++ b/arch/nds32/mm/cacheflush.c</span>
<span class="p_chunk">@@ -0,0 +1,331 @@</span> <span class="p_context"></span>
<span class="p_add">+/*</span>
<span class="p_add">+ * Copyright (C) 2005-2017 Andes Technology Corporation</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * This program is free software; you can redistribute it and/or modify</span>
<span class="p_add">+ * it under the terms of the GNU General Public License version 2 as</span>
<span class="p_add">+ * published by the Free Software Foundation.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * This program is distributed in the hope that it will be useful,</span>
<span class="p_add">+ * but WITHOUT ANY WARRANTY; without even the implied warranty of</span>
<span class="p_add">+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the</span>
<span class="p_add">+ * GNU General Public License for more details.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * You should have received a copy of the GNU General Public License</span>
<span class="p_add">+ * along with this program.  If not, see &lt;http://www.gnu.org/licenses/&gt;.</span>
<span class="p_add">+ */</span>
<span class="p_add">+</span>
<span class="p_add">+#include &lt;linux/mm.h&gt;</span>
<span class="p_add">+#include &lt;linux/sched.h&gt;</span>
<span class="p_add">+#include &lt;linux/fs.h&gt;</span>
<span class="p_add">+#include &lt;linux/pagemap.h&gt;</span>
<span class="p_add">+#include &lt;linux/module.h&gt;</span>
<span class="p_add">+#include &lt;asm/cacheflush.h&gt;</span>
<span class="p_add">+#include &lt;asm/proc-fns.h&gt;</span>
<span class="p_add">+#include &lt;asm/shmparam.h&gt;</span>
<span class="p_add">+#include &lt;asm/cache_info.h&gt;</span>
<span class="p_add">+</span>
<span class="p_add">+extern struct cache_info L1_cache_info[2];</span>
<span class="p_add">+</span>
<span class="p_add">+#ifdef CONFIG_CPU_CACHE_NONALIASING</span>
<span class="p_add">+void update_mmu_cache(struct vm_area_struct *vma, unsigned long addr,</span>
<span class="p_add">+		      pte_t * pte)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct page *page;</span>
<span class="p_add">+	unsigned long pfn = pte_pfn(*pte);</span>
<span class="p_add">+</span>
<span class="p_add">+	if (!pfn_valid(pfn))</span>
<span class="p_add">+		return;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (vma-&gt;vm_mm == current-&gt;active_mm) {</span>
<span class="p_add">+</span>
<span class="p_add">+		__nds32__mtsr_dsb(addr, NDS32_SR_TLB_VPN);</span>
<span class="p_add">+		__nds32__tlbop_rwr(*pte);</span>
<span class="p_add">+		__nds32__isb();</span>
<span class="p_add">+	}</span>
<span class="p_add">+	page = pfn_to_page(pfn);</span>
<span class="p_add">+</span>
<span class="p_add">+	if ((test_and_clear_bit(PG_dcache_dirty, &amp;page-&gt;flags)) ||</span>
<span class="p_add">+	    (vma-&gt;vm_flags &amp; VM_EXEC)) {</span>
<span class="p_add">+</span>
<span class="p_add">+		if (!PageHighMem(page)) {</span>
<span class="p_add">+			cpu_cache_wbinval_page((unsigned long)</span>
<span class="p_add">+					       page_address(page),</span>
<span class="p_add">+					       vma-&gt;vm_flags &amp; VM_EXEC);</span>
<span class="p_add">+		} else {</span>
<span class="p_add">+			unsigned long kaddr = (unsigned long)kmap_atomic(page);</span>
<span class="p_add">+			cpu_cache_wbinval_page(kaddr, vma-&gt;vm_flags &amp; VM_EXEC);</span>
<span class="p_add">+			kunmap_atomic((void *)kaddr);</span>
<span class="p_add">+		}</span>
<span class="p_add">+	}</span>
<span class="p_add">+}</span>
<span class="p_add">+#else</span>
<span class="p_add">+extern pte_t va_present(struct mm_struct *mm, unsigned long addr);</span>
<span class="p_add">+</span>
<span class="p_add">+static inline unsigned long aliasing(unsigned long addr, unsigned long page)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return ((addr &amp; PAGE_MASK) ^ page) &amp; (SHMLBA - 1);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline unsigned long kremap0(unsigned long uaddr, unsigned long pa)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long kaddr, pte;</span>
<span class="p_add">+</span>
<span class="p_add">+#define BASE_ADDR0 0xffffc000</span>
<span class="p_add">+	kaddr = BASE_ADDR0 | (uaddr &amp; L1_cache_info[DCACHE].aliasing_mask);</span>
<span class="p_add">+	pte = (pa | PAGE_KERNEL);</span>
<span class="p_add">+	__nds32__mtsr_dsb(kaddr, NDS32_SR_TLB_VPN);</span>
<span class="p_add">+	__nds32__tlbop_rwlk(pte);</span>
<span class="p_add">+	__nds32__isb();</span>
<span class="p_add">+	return kaddr;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline void kunmap01(unsigned long kaddr)</span>
<span class="p_add">+{</span>
<span class="p_add">+	__nds32__tlbop_unlk(kaddr);</span>
<span class="p_add">+	__nds32__tlbop_inv(kaddr);</span>
<span class="p_add">+	__nds32__isb();</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline unsigned long kremap1(unsigned long uaddr, unsigned long pa)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long kaddr, pte;</span>
<span class="p_add">+</span>
<span class="p_add">+#define BASE_ADDR1 0xffff8000</span>
<span class="p_add">+	kaddr = BASE_ADDR1 | (uaddr &amp; L1_cache_info[DCACHE].aliasing_mask);</span>
<span class="p_add">+	pte = (pa | PAGE_KERNEL);</span>
<span class="p_add">+	__nds32__mtsr_dsb(kaddr, NDS32_SR_TLB_VPN);</span>
<span class="p_add">+	__nds32__tlbop_rwlk(pte);</span>
<span class="p_add">+	__nds32__isb();</span>
<span class="p_add">+	return kaddr;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void flush_cache_mm(struct mm_struct *mm)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long flags;</span>
<span class="p_add">+</span>
<span class="p_add">+	local_irq_save(flags);</span>
<span class="p_add">+	cpu_dcache_wbinval_all();</span>
<span class="p_add">+	cpu_icache_inval_all();</span>
<span class="p_add">+	local_irq_restore(flags);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void flush_cache_dup_mm(struct mm_struct *mm)</span>
<span class="p_add">+{</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void flush_cache_range(struct vm_area_struct *vma,</span>
<span class="p_add">+		       unsigned long start, unsigned long end)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long flags;</span>
<span class="p_add">+</span>
<span class="p_add">+	if ((end - start) &gt; 8 * PAGE_SIZE) {</span>
<span class="p_add">+		cpu_dcache_wbinval_all();</span>
<span class="p_add">+		if (vma-&gt;vm_flags &amp; VM_EXEC)</span>
<span class="p_add">+			cpu_icache_inval_all();</span>
<span class="p_add">+		return;</span>
<span class="p_add">+	}</span>
<span class="p_add">+	local_irq_save(flags);</span>
<span class="p_add">+	while (start &lt; end) {</span>
<span class="p_add">+		if (va_present(vma-&gt;vm_mm, start))</span>
<span class="p_add">+			cpu_cache_wbinval_page(start, vma-&gt;vm_flags &amp; VM_EXEC);</span>
<span class="p_add">+		start += PAGE_SIZE;</span>
<span class="p_add">+	}</span>
<span class="p_add">+	local_irq_restore(flags);</span>
<span class="p_add">+	return;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void flush_cache_page(struct vm_area_struct *vma,</span>
<span class="p_add">+		      unsigned long addr, unsigned long pfn)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long vto, flags;</span>
<span class="p_add">+</span>
<span class="p_add">+	local_irq_save(flags);</span>
<span class="p_add">+	vto = kremap0(addr, pfn &lt;&lt; PAGE_SHIFT);</span>
<span class="p_add">+	cpu_cache_wbinval_page(vto, vma-&gt;vm_flags &amp; VM_EXEC);</span>
<span class="p_add">+	kunmap01(vto);</span>
<span class="p_add">+	local_irq_restore(flags);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void flush_cache_vmap(unsigned long start, unsigned long end)</span>
<span class="p_add">+{</span>
<span class="p_add">+	cpu_dcache_wbinval_all();</span>
<span class="p_add">+	cpu_icache_inval_all();</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void flush_cache_vunmap(unsigned long start, unsigned long end)</span>
<span class="p_add">+{</span>
<span class="p_add">+	cpu_dcache_wbinval_all();</span>
<span class="p_add">+	cpu_icache_inval_all();</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void copy_user_highpage(struct page *to, struct page *from,</span>
<span class="p_add">+			unsigned long vaddr, struct vm_area_struct *vma)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long vto, vfrom, flags, kto, kfrom, pfrom, pto;</span>
<span class="p_add">+	kto = ((unsigned long)page_address(to) &amp; PAGE_MASK);</span>
<span class="p_add">+	kfrom = ((unsigned long)page_address(from) &amp; PAGE_MASK);</span>
<span class="p_add">+	pto = page_to_phys(to);</span>
<span class="p_add">+	pfrom = page_to_phys(from);</span>
<span class="p_add">+</span>
<span class="p_add">+	if (aliasing(vaddr, (unsigned long)kfrom))</span>
<span class="p_add">+		cpu_dcache_wb_page((unsigned long)kfrom);</span>
<span class="p_add">+	if (aliasing(vaddr, (unsigned long)kto))</span>
<span class="p_add">+		cpu_dcache_inval_page((unsigned long)kto);</span>
<span class="p_add">+	local_irq_save(flags);</span>
<span class="p_add">+	vto = kremap0(vaddr, pto);</span>
<span class="p_add">+	vfrom = kremap1(vaddr, pfrom);</span>
<span class="p_add">+	copy_page((void *)vto, (void *)vfrom);</span>
<span class="p_add">+	kunmap01(vfrom);</span>
<span class="p_add">+	kunmap01(vto);</span>
<span class="p_add">+	local_irq_restore(flags);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+EXPORT_SYMBOL(copy_user_highpage);</span>
<span class="p_add">+</span>
<span class="p_add">+void clear_user_highpage(struct page *page, unsigned long vaddr)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long vto, flags, kto;</span>
<span class="p_add">+</span>
<span class="p_add">+	kto = ((unsigned long)page_address(page) &amp; PAGE_MASK);</span>
<span class="p_add">+</span>
<span class="p_add">+	local_irq_save(flags);</span>
<span class="p_add">+	if (aliasing(kto, vaddr) &amp;&amp; kto != 0) {</span>
<span class="p_add">+		cpu_dcache_inval_page(kto);</span>
<span class="p_add">+		cpu_icache_inval_page(kto);</span>
<span class="p_add">+	}</span>
<span class="p_add">+	vto = kremap0(vaddr, page_to_phys(page));</span>
<span class="p_add">+	clear_page((void *)vto);</span>
<span class="p_add">+	kunmap01(vto);</span>
<span class="p_add">+	local_irq_restore(flags);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+EXPORT_SYMBOL(clear_user_highpage);</span>
<span class="p_add">+</span>
<span class="p_add">+void flush_dcache_page(struct page *page)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct address_space *mapping;</span>
<span class="p_add">+</span>
<span class="p_add">+	mapping = page_mapping(page);</span>
<span class="p_add">+	if (mapping &amp;&amp; !mapping_mapped(mapping))</span>
<span class="p_add">+		set_bit(PG_dcache_dirty, &amp;page-&gt;flags);</span>
<span class="p_add">+	else {</span>
<span class="p_add">+		int i, pc;</span>
<span class="p_add">+		unsigned long vto, kaddr, flags;</span>
<span class="p_add">+		kaddr = (unsigned long)page_address(page);</span>
<span class="p_add">+		cpu_dcache_wbinval_page(kaddr);</span>
<span class="p_add">+		pc = CACHE_SET(DCACHE) * CACHE_LINE_SIZE(DCACHE) / PAGE_SIZE;</span>
<span class="p_add">+		local_irq_save(flags);</span>
<span class="p_add">+		for (i = 0; i &lt; pc; i++) {</span>
<span class="p_add">+			vto =</span>
<span class="p_add">+			    kremap0(kaddr + i * PAGE_SIZE, page_to_phys(page));</span>
<span class="p_add">+			cpu_dcache_wbinval_page(vto);</span>
<span class="p_add">+			kunmap01(vto);</span>
<span class="p_add">+		}</span>
<span class="p_add">+		local_irq_restore(flags);</span>
<span class="p_add">+	}</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void copy_to_user_page(struct vm_area_struct *vma, struct page *page,</span>
<span class="p_add">+		       unsigned long vaddr, void *dst, void *src, int len)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long line_size, start, end, vto, flags;</span>
<span class="p_add">+</span>
<span class="p_add">+	local_irq_save(flags);</span>
<span class="p_add">+	vto = kremap0(vaddr, page_to_phys(page));</span>
<span class="p_add">+	dst = (void *)(vto | (vaddr &amp; (PAGE_SIZE - 1)));</span>
<span class="p_add">+	memcpy(dst, src, len);</span>
<span class="p_add">+	if (vma-&gt;vm_flags &amp; VM_EXEC) {</span>
<span class="p_add">+		line_size = L1_cache_info[DCACHE].line_size;</span>
<span class="p_add">+		start = (unsigned long)dst &amp; ~(line_size - 1);</span>
<span class="p_add">+		end =</span>
<span class="p_add">+		    ((unsigned long)dst + len + line_size - 1) &amp; ~(line_size -</span>
<span class="p_add">+								   1);</span>
<span class="p_add">+		cpu_cache_wbinval_range(start, end, 1);</span>
<span class="p_add">+	}</span>
<span class="p_add">+	kunmap01(vto);</span>
<span class="p_add">+	local_irq_restore(flags);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void copy_from_user_page(struct vm_area_struct *vma, struct page *page,</span>
<span class="p_add">+			 unsigned long vaddr, void *dst, void *src, int len)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long vto, flags;</span>
<span class="p_add">+</span>
<span class="p_add">+	local_irq_save(flags);</span>
<span class="p_add">+	vto = kremap0(vaddr, page_to_phys(page));</span>
<span class="p_add">+	src = (void *)(vto | (vaddr &amp; (PAGE_SIZE - 1)));</span>
<span class="p_add">+	memcpy(dst, src, len);</span>
<span class="p_add">+	kunmap01(vto);</span>
<span class="p_add">+	local_irq_restore(flags);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void flush_anon_page(struct vm_area_struct *vma,</span>
<span class="p_add">+		     struct page *page, unsigned long vaddr)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long flags;</span>
<span class="p_add">+	if (!PageAnon(page))</span>
<span class="p_add">+		return;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (vma-&gt;vm_mm != current-&gt;active_mm)</span>
<span class="p_add">+		return;</span>
<span class="p_add">+</span>
<span class="p_add">+	local_irq_save(flags);</span>
<span class="p_add">+	if (vma-&gt;vm_flags &amp; VM_EXEC)</span>
<span class="p_add">+		cpu_icache_inval_page(vaddr &amp; PAGE_MASK);</span>
<span class="p_add">+	cpu_dcache_wbinval_page((unsigned long)page_address(page));</span>
<span class="p_add">+	local_irq_restore(flags);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void flush_kernel_dcache_page(struct page *page)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long flags;</span>
<span class="p_add">+	local_irq_save(flags);</span>
<span class="p_add">+	cpu_dcache_wbinval_page((unsigned long)page_address(page));</span>
<span class="p_add">+	local_irq_restore(flags);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void flush_icache_range(unsigned long start, unsigned long end)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long line_size, flags;</span>
<span class="p_add">+	line_size = L1_cache_info[DCACHE].line_size;</span>
<span class="p_add">+	start = start &amp; ~(line_size - 1);</span>
<span class="p_add">+	end = (end + line_size - 1) &amp; ~(line_size - 1);</span>
<span class="p_add">+	local_irq_save(flags);</span>
<span class="p_add">+	cpu_cache_wbinval_range(start, end, 1);</span>
<span class="p_add">+	local_irq_restore(flags);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void flush_icache_page(struct vm_area_struct *vma, struct page *page)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long flags;</span>
<span class="p_add">+	local_irq_save(flags);</span>
<span class="p_add">+	cpu_cache_wbinval_page((unsigned long)page_address(page),</span>
<span class="p_add">+			       vma-&gt;vm_flags &amp; VM_EXEC);</span>
<span class="p_add">+	local_irq_restore(flags);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void update_mmu_cache(struct vm_area_struct *vma, unsigned long addr,</span>
<span class="p_add">+		      pte_t * pte)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct page *page;</span>
<span class="p_add">+	unsigned long flags;</span>
<span class="p_add">+	unsigned long pfn = pte_pfn(*pte);</span>
<span class="p_add">+</span>
<span class="p_add">+	if (!pfn_valid(pfn))</span>
<span class="p_add">+		return;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (vma-&gt;vm_mm == current-&gt;active_mm) {</span>
<span class="p_add">+		__nds32__mtsr_dsb(addr, NDS32_SR_TLB_VPN);</span>
<span class="p_add">+		__nds32__tlbop_rwr(*pte);</span>
<span class="p_add">+		__nds32__isb();</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	page = pfn_to_page(pfn);</span>
<span class="p_add">+	if (test_and_clear_bit(PG_dcache_dirty, &amp;page-&gt;flags) ||</span>
<span class="p_add">+	    (vma-&gt;vm_flags &amp; VM_EXEC)) {</span>
<span class="p_add">+		local_irq_save(flags);</span>
<span class="p_add">+		cpu_dcache_wbinval_page((unsigned long)page_address(page));</span>
<span class="p_add">+		local_irq_restore(flags);</span>
<span class="p_add">+	}</span>
<span class="p_add">+}</span>
<span class="p_add">+#endif</span>
<span class="p_header">diff --git a/arch/nds32/mm/proc.c b/arch/nds32/mm/proc.c</span>
new file mode 100644
<span class="p_header">index 0000000..58a41b9</span>
<span class="p_header">--- /dev/null</span>
<span class="p_header">+++ b/arch/nds32/mm/proc.c</span>
<span class="p_chunk">@@ -0,0 +1,601 @@</span> <span class="p_context"></span>
<span class="p_add">+/*</span>
<span class="p_add">+ * Copyright (C) 2005-2017 Andes Technology Corporation</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * This program is free software; you can redistribute it and/or modify</span>
<span class="p_add">+ * it under the terms of the GNU General Public License version 2 as</span>
<span class="p_add">+ * published by the Free Software Foundation.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * This program is distributed in the hope that it will be useful,</span>
<span class="p_add">+ * but WITHOUT ANY WARRANTY; without even the implied warranty of</span>
<span class="p_add">+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the</span>
<span class="p_add">+ * GNU General Public License for more details.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * You should have received a copy of the GNU General Public License</span>
<span class="p_add">+ * along with this program.  If not, see &lt;http://www.gnu.org/licenses/&gt;.</span>
<span class="p_add">+ */</span>
<span class="p_add">+</span>
<span class="p_add">+#include &lt;linux/module.h&gt;</span>
<span class="p_add">+#include &lt;linux/sched.h&gt;</span>
<span class="p_add">+#include &lt;linux/mm.h&gt;</span>
<span class="p_add">+#include &lt;asm/nds32.h&gt;</span>
<span class="p_add">+#include &lt;asm/pgtable.h&gt;</span>
<span class="p_add">+#include &lt;asm/tlbflush.h&gt;</span>
<span class="p_add">+#include &lt;asm/cacheflush.h&gt;</span>
<span class="p_add">+#ifdef CONFIG_CACHE_L2</span>
<span class="p_add">+#include &lt;asm/l2_cache.h&gt;</span>
<span class="p_add">+#endif</span>
<span class="p_add">+#include &lt;nds32_intrinsic.h&gt;</span>
<span class="p_add">+</span>
<span class="p_add">+#include &lt;asm/cache_info.h&gt;</span>
<span class="p_add">+extern struct cache_info L1_cache_info[2];</span>
<span class="p_add">+</span>
<span class="p_add">+int va_kernel_present(unsigned long addr)</span>
<span class="p_add">+{</span>
<span class="p_add">+	pmd_t *pmd;</span>
<span class="p_add">+	pte_t *ptep, pte;</span>
<span class="p_add">+</span>
<span class="p_add">+	pmd = pmd_offset(pgd_offset_k(addr), addr);</span>
<span class="p_add">+	if (!pmd_none(*pmd)) {</span>
<span class="p_add">+		ptep = pte_offset_map(pmd, addr);</span>
<span class="p_add">+		pte = *ptep;</span>
<span class="p_add">+		if (pte_present(pte))</span>
<span class="p_add">+			return pte;</span>
<span class="p_add">+	}</span>
<span class="p_add">+	return 0;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+pte_t va_present(struct mm_struct * mm, unsigned long addr)</span>
<span class="p_add">+{</span>
<span class="p_add">+	pgd_t *pgd;</span>
<span class="p_add">+	pud_t *pud;</span>
<span class="p_add">+	pmd_t *pmd;</span>
<span class="p_add">+	pte_t *ptep, pte;</span>
<span class="p_add">+</span>
<span class="p_add">+	pgd = pgd_offset(mm, addr);</span>
<span class="p_add">+	if (!pgd_none(*pgd)) {</span>
<span class="p_add">+		pud = pud_offset(pgd, addr);</span>
<span class="p_add">+		if (!pud_none(*pud)) {</span>
<span class="p_add">+			pmd = pmd_offset(pud, addr);</span>
<span class="p_add">+			if (!pmd_none(*pmd)) {</span>
<span class="p_add">+				ptep = pte_offset_map(pmd, addr);</span>
<span class="p_add">+				pte = *ptep;</span>
<span class="p_add">+				if (pte_present(pte))</span>
<span class="p_add">+					return pte;</span>
<span class="p_add">+			}</span>
<span class="p_add">+		}</span>
<span class="p_add">+	}</span>
<span class="p_add">+	return 0;</span>
<span class="p_add">+</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+int va_readable(struct pt_regs *regs, unsigned long addr)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct mm_struct *mm = current-&gt;mm;</span>
<span class="p_add">+	pte_t pte;</span>
<span class="p_add">+	int ret = 0;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (user_mode(regs)) {</span>
<span class="p_add">+		/* user mode */</span>
<span class="p_add">+		pte = va_present(mm, addr);</span>
<span class="p_add">+		if (!pte &amp;&amp; pte_read(pte))</span>
<span class="p_add">+			ret = 1;</span>
<span class="p_add">+	} else {</span>
<span class="p_add">+		/* superuser mode is always readable, so we can only</span>
<span class="p_add">+		 * check it is present or not*/</span>
<span class="p_add">+		return (! !va_kernel_present(addr));</span>
<span class="p_add">+	}</span>
<span class="p_add">+	return ret;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+int va_writable(struct pt_regs *regs, unsigned long addr)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct mm_struct *mm = current-&gt;mm;</span>
<span class="p_add">+	pte_t pte;</span>
<span class="p_add">+	int ret = 0;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (user_mode(regs)) {</span>
<span class="p_add">+		/* user mode */</span>
<span class="p_add">+		pte = va_present(mm, addr);</span>
<span class="p_add">+		if (!pte &amp;&amp; pte_write(pte))</span>
<span class="p_add">+			ret = 1;</span>
<span class="p_add">+	} else {</span>
<span class="p_add">+		/* superuser mode */</span>
<span class="p_add">+		pte = va_kernel_present(addr);</span>
<span class="p_add">+		if (!pte &amp;&amp; pte_kernel_write(pte))</span>
<span class="p_add">+			ret = 1;</span>
<span class="p_add">+	}</span>
<span class="p_add">+	return ret;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+/*</span>
<span class="p_add">+ * All</span>
<span class="p_add">+ */</span>
<span class="p_add">+void cpu_icache_inval_all(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long end, line_size;</span>
<span class="p_add">+</span>
<span class="p_add">+	line_size = L1_cache_info[ICACHE].line_size;</span>
<span class="p_add">+	end =</span>
<span class="p_add">+	    line_size * L1_cache_info[ICACHE].ways * L1_cache_info[ICACHE].sets;</span>
<span class="p_add">+</span>
<span class="p_add">+	do {</span>
<span class="p_add">+		end -= line_size;</span>
<span class="p_add">+		__asm__ volatile (&quot;\n\tcctl %0, L1I_IX_INVAL&quot;::&quot;r&quot; (end));</span>
<span class="p_add">+		end -= line_size;</span>
<span class="p_add">+		__asm__ volatile (&quot;\n\tcctl %0, L1I_IX_INVAL&quot;::&quot;r&quot; (end));</span>
<span class="p_add">+		end -= line_size;</span>
<span class="p_add">+		__asm__ volatile (&quot;\n\tcctl %0, L1I_IX_INVAL&quot;::&quot;r&quot; (end));</span>
<span class="p_add">+		end -= line_size;</span>
<span class="p_add">+		__asm__ volatile (&quot;\n\tcctl %0, L1I_IX_INVAL&quot;::&quot;r&quot; (end));</span>
<span class="p_add">+	} while (end &gt; 0);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void cpu_dcache_inval_all(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	__nds32__cctl_l1d_invalall();</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void cpu_dcache_wb_all(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	if (IS_ENABLED(CONFIG_CACHE_L2)) {</span>
<span class="p_add">+		if (atl2c_base)</span>
<span class="p_add">+			__nds32__cctl_l1d_wball_alvl();</span>
<span class="p_add">+		else</span>
<span class="p_add">+			__nds32__cctl_l1d_wball_one_lvl();</span>
<span class="p_add">+	} else</span>
<span class="p_add">+		__nds32__cctl_l1d_wball_one_lvl();</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void cpu_dcache_wbinval_all(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+#ifndef CONFIG_CPU_DCACHE_WRITETHROUGH</span>
<span class="p_add">+	unsigned long flags;</span>
<span class="p_add">+	local_irq_save(flags);</span>
<span class="p_add">+#endif</span>
<span class="p_add">+	if (IS_ENABLED(CONFIG_CACHE_L2)) {</span>
<span class="p_add">+		if (atl2c_base)</span>
<span class="p_add">+			__nds32__cctl_l1d_wball_alvl();</span>
<span class="p_add">+		else</span>
<span class="p_add">+			__nds32__cctl_l1d_wball_one_lvl();</span>
<span class="p_add">+	} else</span>
<span class="p_add">+		__nds32__cctl_l1d_wball_one_lvl();</span>
<span class="p_add">+	__nds32__cctl_l1d_invalall();</span>
<span class="p_add">+#ifndef CONFIG_CPU_DCACHE_WRITETHROUGH</span>
<span class="p_add">+	local_irq_restore(flags);</span>
<span class="p_add">+#endif</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+/*</span>
<span class="p_add">+ * Page</span>
<span class="p_add">+ */</span>
<span class="p_add">+void cpu_icache_inval_page(unsigned long start)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long line_size, end;</span>
<span class="p_add">+</span>
<span class="p_add">+	line_size = L1_cache_info[ICACHE].line_size;</span>
<span class="p_add">+	end = start + PAGE_SIZE;</span>
<span class="p_add">+</span>
<span class="p_add">+	do {</span>
<span class="p_add">+		end -= line_size;</span>
<span class="p_add">+		__asm__ volatile (&quot;\n\tcctl %0, L1I_VA_INVAL&quot;::&quot;r&quot; (end));</span>
<span class="p_add">+		end -= line_size;</span>
<span class="p_add">+		__asm__ volatile (&quot;\n\tcctl %0, L1I_VA_INVAL&quot;::&quot;r&quot; (end));</span>
<span class="p_add">+		end -= line_size;</span>
<span class="p_add">+		__asm__ volatile (&quot;\n\tcctl %0, L1I_VA_INVAL&quot;::&quot;r&quot; (end));</span>
<span class="p_add">+		end -= line_size;</span>
<span class="p_add">+		__asm__ volatile (&quot;\n\tcctl %0, L1I_VA_INVAL&quot;::&quot;r&quot; (end));</span>
<span class="p_add">+	} while (end != start);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void cpu_dcache_inval_page(unsigned long start)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long line_size, end;</span>
<span class="p_add">+</span>
<span class="p_add">+	line_size = L1_cache_info[DCACHE].line_size;</span>
<span class="p_add">+	end = start + PAGE_SIZE;</span>
<span class="p_add">+</span>
<span class="p_add">+	do {</span>
<span class="p_add">+		end -= line_size;</span>
<span class="p_add">+		__asm__ volatile (&quot;\n\tcctl %0, L1D_VA_INVAL&quot;::&quot;r&quot; (end));</span>
<span class="p_add">+		end -= line_size;</span>
<span class="p_add">+		__asm__ volatile (&quot;\n\tcctl %0, L1D_VA_INVAL&quot;::&quot;r&quot; (end));</span>
<span class="p_add">+		end -= line_size;</span>
<span class="p_add">+		__asm__ volatile (&quot;\n\tcctl %0, L1D_VA_INVAL&quot;::&quot;r&quot; (end));</span>
<span class="p_add">+		end -= line_size;</span>
<span class="p_add">+		__asm__ volatile (&quot;\n\tcctl %0, L1D_VA_INVAL&quot;::&quot;r&quot; (end));</span>
<span class="p_add">+	} while (end != start);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void cpu_dcache_wb_page(unsigned long start)</span>
<span class="p_add">+{</span>
<span class="p_add">+#ifndef CONFIG_CPU_DCACHE_WRITETHROUGH</span>
<span class="p_add">+	unsigned long line_size, end;</span>
<span class="p_add">+</span>
<span class="p_add">+	line_size = L1_cache_info[DCACHE].line_size;</span>
<span class="p_add">+	end = start + PAGE_SIZE;</span>
<span class="p_add">+</span>
<span class="p_add">+	do {</span>
<span class="p_add">+		end -= line_size;</span>
<span class="p_add">+		__asm__ volatile (&quot;\n\tcctl %0, L1D_VA_WB&quot;::&quot;r&quot; (end));</span>
<span class="p_add">+		end -= line_size;</span>
<span class="p_add">+		__asm__ volatile (&quot;\n\tcctl %0, L1D_VA_WB&quot;::&quot;r&quot; (end));</span>
<span class="p_add">+		end -= line_size;</span>
<span class="p_add">+		__asm__ volatile (&quot;\n\tcctl %0, L1D_VA_WB&quot;::&quot;r&quot; (end));</span>
<span class="p_add">+		end -= line_size;</span>
<span class="p_add">+		__asm__ volatile (&quot;\n\tcctl %0, L1D_VA_WB&quot;::&quot;r&quot; (end));</span>
<span class="p_add">+	} while (end != start);</span>
<span class="p_add">+#endif</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void cpu_dcache_wbinval_page(unsigned long start)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long line_size, end;</span>
<span class="p_add">+</span>
<span class="p_add">+	line_size = L1_cache_info[DCACHE].line_size;</span>
<span class="p_add">+	end = start + PAGE_SIZE;</span>
<span class="p_add">+</span>
<span class="p_add">+	do {</span>
<span class="p_add">+		end -= line_size;</span>
<span class="p_add">+#ifndef CONFIG_CPU_DCACHE_WRITETHROUGH</span>
<span class="p_add">+		__asm__ volatile (&quot;\n\tcctl %0, L1D_VA_WB&quot;::&quot;r&quot; (end));</span>
<span class="p_add">+#endif</span>
<span class="p_add">+		__asm__ volatile (&quot;\n\tcctl %0, L1D_VA_INVAL&quot;::&quot;r&quot; (end));</span>
<span class="p_add">+		end -= line_size;</span>
<span class="p_add">+#ifndef CONFIG_CPU_DCACHE_WRITETHROUGH</span>
<span class="p_add">+		__asm__ volatile (&quot;\n\tcctl %0, L1D_VA_WB&quot;::&quot;r&quot; (end));</span>
<span class="p_add">+#endif</span>
<span class="p_add">+		__asm__ volatile (&quot;\n\tcctl %0, L1D_VA_INVAL&quot;::&quot;r&quot; (end));</span>
<span class="p_add">+		end -= line_size;</span>
<span class="p_add">+#ifndef CONFIG_CPU_DCACHE_WRITETHROUGH</span>
<span class="p_add">+		__asm__ volatile (&quot;\n\tcctl %0, L1D_VA_WB&quot;::&quot;r&quot; (end));</span>
<span class="p_add">+#endif</span>
<span class="p_add">+		__asm__ volatile (&quot;\n\tcctl %0, L1D_VA_INVAL&quot;::&quot;r&quot; (end));</span>
<span class="p_add">+		end -= line_size;</span>
<span class="p_add">+#ifndef CONFIG_CPU_DCACHE_WRITETHROUGH</span>
<span class="p_add">+		__asm__ volatile (&quot;\n\tcctl %0, L1D_VA_WB&quot;::&quot;r&quot; (end));</span>
<span class="p_add">+#endif</span>
<span class="p_add">+		__asm__ volatile (&quot;\n\tcctl %0, L1D_VA_INVAL&quot;::&quot;r&quot; (end));</span>
<span class="p_add">+	} while (end != start);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void cpu_cache_wbinval_page(unsigned long page, int flushi)</span>
<span class="p_add">+{</span>
<span class="p_add">+	cpu_dcache_wbinval_page(page);</span>
<span class="p_add">+	if (flushi)</span>
<span class="p_add">+		cpu_icache_inval_page(page);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+/*</span>
<span class="p_add">+ * Range</span>
<span class="p_add">+ */</span>
<span class="p_add">+void cpu_icache_inval_range(unsigned long start, unsigned long end)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long line_size;</span>
<span class="p_add">+</span>
<span class="p_add">+	line_size = L1_cache_info[ICACHE].line_size;</span>
<span class="p_add">+</span>
<span class="p_add">+	while (end &gt; start) {</span>
<span class="p_add">+		__asm__ volatile (&quot;\n\tcctl %0, L1I_VA_INVAL&quot;::&quot;r&quot; (start));</span>
<span class="p_add">+		start += line_size;</span>
<span class="p_add">+	}</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void cpu_dcache_inval_range(unsigned long start, unsigned long end)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long line_size;</span>
<span class="p_add">+</span>
<span class="p_add">+	line_size = L1_cache_info[DCACHE].line_size;</span>
<span class="p_add">+</span>
<span class="p_add">+	while (end &gt; start) {</span>
<span class="p_add">+		__asm__ volatile (&quot;\n\tcctl %0, L1D_VA_INVAL&quot;::&quot;r&quot; (start));</span>
<span class="p_add">+		start += line_size;</span>
<span class="p_add">+	}</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void cpu_dcache_wb_range(unsigned long start, unsigned long end)</span>
<span class="p_add">+{</span>
<span class="p_add">+#ifndef CONFIG_CPU_DCACHE_WRITETHROUGH</span>
<span class="p_add">+	unsigned long line_size;</span>
<span class="p_add">+</span>
<span class="p_add">+	line_size = L1_cache_info[DCACHE].line_size;</span>
<span class="p_add">+</span>
<span class="p_add">+	while (end &gt; start) {</span>
<span class="p_add">+		__asm__ volatile (&quot;\n\tcctl %0, L1D_VA_WB&quot;::&quot;r&quot; (start));</span>
<span class="p_add">+		start += line_size;</span>
<span class="p_add">+	}</span>
<span class="p_add">+#endif</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void cpu_dcache_wbinval_range(unsigned long start, unsigned long end)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long line_size;</span>
<span class="p_add">+</span>
<span class="p_add">+	line_size = L1_cache_info[DCACHE].line_size;</span>
<span class="p_add">+</span>
<span class="p_add">+	while (end &gt; start) {</span>
<span class="p_add">+#ifndef CONFIG_CPU_DCACHE_WRITETHROUGH</span>
<span class="p_add">+		__asm__ volatile (&quot;\n\tcctl %0, L1D_VA_WB&quot;::&quot;r&quot; (start));</span>
<span class="p_add">+#endif</span>
<span class="p_add">+		__asm__ volatile (&quot;\n\tcctl %0, L1D_VA_INVAL&quot;::&quot;r&quot; (start));</span>
<span class="p_add">+		start += line_size;</span>
<span class="p_add">+	}</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void cpu_cache_wbinval_range(unsigned long start, unsigned long end, int flushi)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long line_size, align_start, align_end;</span>
<span class="p_add">+</span>
<span class="p_add">+	line_size = L1_cache_info[DCACHE].line_size;</span>
<span class="p_add">+	align_start = start &amp; ~(line_size - 1);</span>
<span class="p_add">+	align_end = (end + line_size - 1) &amp; ~(line_size - 1);</span>
<span class="p_add">+	cpu_dcache_wbinval_range(align_start, align_end);</span>
<span class="p_add">+</span>
<span class="p_add">+	if (flushi) {</span>
<span class="p_add">+		line_size = L1_cache_info[ICACHE].line_size;</span>
<span class="p_add">+		align_start = start &amp; ~(line_size - 1);</span>
<span class="p_add">+		align_end = (end + line_size - 1) &amp; ~(line_size - 1);</span>
<span class="p_add">+		cpu_icache_inval_range(align_start, align_end);</span>
<span class="p_add">+	}</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void cpu_cache_wbinval_range_check(struct vm_area_struct *vma,</span>
<span class="p_add">+				   unsigned long start, unsigned long end,</span>
<span class="p_add">+				   bool flushi, bool wbd)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long line_size, t_start, t_end;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (!flushi &amp;&amp; !wbd)</span>
<span class="p_add">+		return;</span>
<span class="p_add">+	line_size = L1_cache_info[DCACHE].line_size;</span>
<span class="p_add">+	start = start &amp; ~(line_size - 1);</span>
<span class="p_add">+	end = (end + line_size - 1) &amp; ~(line_size - 1);</span>
<span class="p_add">+</span>
<span class="p_add">+	if ((end - start) &gt; (8 * PAGE_SIZE)) {</span>
<span class="p_add">+		if (wbd)</span>
<span class="p_add">+			cpu_dcache_wbinval_all();</span>
<span class="p_add">+		if (flushi)</span>
<span class="p_add">+			cpu_icache_inval_all();</span>
<span class="p_add">+		return;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	t_start = (start + PAGE_SIZE) &amp; PAGE_MASK;</span>
<span class="p_add">+	t_end = ((end - 1) &amp; PAGE_MASK);</span>
<span class="p_add">+</span>
<span class="p_add">+	if ((start &amp; PAGE_MASK) == t_end) {</span>
<span class="p_add">+		if (va_present(vma-&gt;vm_mm, start)) {</span>
<span class="p_add">+			if (wbd)</span>
<span class="p_add">+				cpu_dcache_wbinval_range(start, end);</span>
<span class="p_add">+			if (flushi)</span>
<span class="p_add">+				cpu_icache_inval_range(start, end);</span>
<span class="p_add">+		}</span>
<span class="p_add">+		return;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	if (va_present(vma-&gt;vm_mm, start)) {</span>
<span class="p_add">+		if (wbd)</span>
<span class="p_add">+			cpu_dcache_wbinval_range(start, end);</span>
<span class="p_add">+		if (flushi)</span>
<span class="p_add">+			cpu_icache_inval_range(start, end);</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	if (va_present(vma-&gt;vm_mm, end - 1)) {</span>
<span class="p_add">+		if (wbd)</span>
<span class="p_add">+			cpu_dcache_wbinval_range(start, end);</span>
<span class="p_add">+		if (flushi)</span>
<span class="p_add">+			cpu_icache_inval_range(start, end);</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	while (t_start &lt; t_end) {</span>
<span class="p_add">+		if (va_present(vma-&gt;vm_mm, t_start)) {</span>
<span class="p_add">+			if (wbd)</span>
<span class="p_add">+				cpu_dcache_wbinval_page(t_start);</span>
<span class="p_add">+			if (flushi)</span>
<span class="p_add">+				cpu_icache_inval_page(t_start);</span>
<span class="p_add">+		}</span>
<span class="p_add">+		t_start += PAGE_SIZE;</span>
<span class="p_add">+	}</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+/*</span>
<span class="p_add">+ * DMA</span>
<span class="p_add">+ */</span>
<span class="p_add">+void cpu_dma_wb_range(unsigned long start, unsigned long end)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long line_size;</span>
<span class="p_add">+	unsigned long flags;</span>
<span class="p_add">+	line_size = L1_cache_info[DCACHE].line_size;</span>
<span class="p_add">+	start = start &amp; (~(line_size - 1));</span>
<span class="p_add">+	end = (end + line_size - 1) &amp; (~(line_size - 1));</span>
<span class="p_add">+	if (unlikely(start == end))</span>
<span class="p_add">+		return;</span>
<span class="p_add">+</span>
<span class="p_add">+	local_irq_save(flags);</span>
<span class="p_add">+	cpu_dcache_wb_range(start, end);</span>
<span class="p_add">+</span>
<span class="p_add">+	if (IS_ENABLED(CONFIG_CACHE_L2)) {</span>
<span class="p_add">+		if (atl2c_base) {</span>
<span class="p_add">+			unsigned long p_start = __pa(start);</span>
<span class="p_add">+			unsigned long p_end = __pa(end);</span>
<span class="p_add">+			unsigned long cmd;</span>
<span class="p_add">+			/* TODO Can Use PAGE Mode to optimize if range large than PAGE_SIZE */</span>
<span class="p_add">+			line_size = L2_CACHE_LINE_SIZE();</span>
<span class="p_add">+			p_start = p_start &amp; (~(line_size - 1));</span>
<span class="p_add">+			p_end = (p_end + line_size - 1) &amp; (~(line_size - 1));</span>
<span class="p_add">+			cmd =</span>
<span class="p_add">+			    (p_start &amp; ~(line_size - 1)) | CCTL_CMD_L2_PA_WB |</span>
<span class="p_add">+			    CCTL_SINGLE_CMD;</span>
<span class="p_add">+			do {</span>
<span class="p_add">+				L2_CMD_RDY();</span>
<span class="p_add">+				L2C_W_REG(L2_CCTL_CMD_OFF, cmd);</span>
<span class="p_add">+				cmd += line_size;</span>
<span class="p_add">+				p_start += line_size;</span>
<span class="p_add">+			} while (p_end &gt; p_start);</span>
<span class="p_add">+			cmd = CCTL_CMD_L2_SYNC;</span>
<span class="p_add">+			L2_CMD_RDY();</span>
<span class="p_add">+			L2C_W_REG(L2_CCTL_CMD_OFF, cmd);</span>
<span class="p_add">+			L2_CMD_RDY();</span>
<span class="p_add">+		}</span>
<span class="p_add">+	}</span>
<span class="p_add">+	local_irq_restore(flags);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+#ifdef CONFIG_CACHE_L2</span>
<span class="p_add">+void cpu_l2dcache_wbinval_range(unsigned long start, unsigned long end)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long p_start;</span>
<span class="p_add">+	unsigned long p_end;</span>
<span class="p_add">+	unsigned long cmd;</span>
<span class="p_add">+	unsigned long line_size;</span>
<span class="p_add">+</span>
<span class="p_add">+	p_start = __pa(start);</span>
<span class="p_add">+	p_end = __pa(end);</span>
<span class="p_add">+	/* TODO Can Use PAGE Mode to optimize if range large than PAGE_SIZE */</span>
<span class="p_add">+	line_size = L2_CACHE_LINE_SIZE();</span>
<span class="p_add">+	p_start = p_start &amp; (~(line_size - 1));</span>
<span class="p_add">+	p_end = (p_end + line_size - 1) &amp; (~(line_size - 1));</span>
<span class="p_add">+	cmd =</span>
<span class="p_add">+	    (p_start &amp; ~(line_size - 1)) | CCTL_CMD_L2_PA_WBINVAL |</span>
<span class="p_add">+	    CCTL_SINGLE_CMD;</span>
<span class="p_add">+	do {</span>
<span class="p_add">+		L2_CMD_RDY();</span>
<span class="p_add">+		L2C_W_REG(L2_CCTL_CMD_OFF, cmd);</span>
<span class="p_add">+		cmd += line_size;</span>
<span class="p_add">+		p_start += line_size;</span>
<span class="p_add">+	} while (p_end &gt; p_start);</span>
<span class="p_add">+	cmd = CCTL_CMD_L2_SYNC;</span>
<span class="p_add">+	L2_CMD_RDY();</span>
<span class="p_add">+	L2C_W_REG(L2_CCTL_CMD_OFF, cmd);</span>
<span class="p_add">+	L2_CMD_RDY();</span>
<span class="p_add">+</span>
<span class="p_add">+}</span>
<span class="p_add">+#endif</span>
<span class="p_add">+</span>
<span class="p_add">+void cpu_dma_inval_range(unsigned long start, unsigned long end)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long line_size;</span>
<span class="p_add">+	unsigned long old_start = start;</span>
<span class="p_add">+	unsigned long old_end = end;</span>
<span class="p_add">+	unsigned long flags;</span>
<span class="p_add">+	line_size = L1_cache_info[DCACHE].line_size;</span>
<span class="p_add">+	start = start &amp; (~(line_size - 1));</span>
<span class="p_add">+	end = (end + line_size - 1) &amp; (~(line_size - 1));</span>
<span class="p_add">+	if (unlikely(start == end))</span>
<span class="p_add">+		return;</span>
<span class="p_add">+	local_irq_save(flags);</span>
<span class="p_add">+	if (start != old_start) {</span>
<span class="p_add">+		cpu_dcache_wbinval_range(start, start + line_size);</span>
<span class="p_add">+		if (IS_ENABLED(CONFIG_CACHE_L2)) {</span>
<span class="p_add">+			if (atl2c_base)</span>
<span class="p_add">+				cpu_l2dcache_wbinval_range(start, start + line_size);</span>
<span class="p_add">+		}</span>
<span class="p_add">+	}</span>
<span class="p_add">+	if (end != old_end) {</span>
<span class="p_add">+		cpu_dcache_wbinval_range(end - line_size, end);</span>
<span class="p_add">+		if (IS_ENABLED(CONFIG_CACHE_L2)) {</span>
<span class="p_add">+			if (atl2c_base)</span>
<span class="p_add">+				cpu_l2dcache_wbinval_range(end - line_size, end);</span>
<span class="p_add">+		}</span>
<span class="p_add">+	}</span>
<span class="p_add">+	cpu_dcache_inval_range(start, end);</span>
<span class="p_add">+	if (IS_ENABLED(CONFIG_CACHE_L2)) {</span>
<span class="p_add">+		if (atl2c_base) {</span>
<span class="p_add">+			unsigned long p_start = __pa(start);</span>
<span class="p_add">+			unsigned long p_end = __pa(end);</span>
<span class="p_add">+			unsigned long cmd;</span>
<span class="p_add">+			/* TODO Can Use PAGE Mode to optimize if range large than PAGE_SIZE */</span>
<span class="p_add">+			line_size = L2_CACHE_LINE_SIZE();</span>
<span class="p_add">+			p_start = p_start &amp; (~(line_size - 1));</span>
<span class="p_add">+			p_end = (p_end + line_size - 1) &amp; (~(line_size - 1));</span>
<span class="p_add">+			cmd =</span>
<span class="p_add">+			    (p_start &amp; ~(line_size - 1)) | CCTL_CMD_L2_PA_INVAL |</span>
<span class="p_add">+			    CCTL_SINGLE_CMD;</span>
<span class="p_add">+			do {</span>
<span class="p_add">+				L2_CMD_RDY();</span>
<span class="p_add">+				L2C_W_REG(L2_CCTL_CMD_OFF, cmd);</span>
<span class="p_add">+				cmd += line_size;</span>
<span class="p_add">+				p_start += line_size;</span>
<span class="p_add">+			} while (p_end &gt; p_start);</span>
<span class="p_add">+			cmd = CCTL_CMD_L2_SYNC;</span>
<span class="p_add">+			L2_CMD_RDY();</span>
<span class="p_add">+			L2C_W_REG(L2_CCTL_CMD_OFF, cmd);</span>
<span class="p_add">+			L2_CMD_RDY();</span>
<span class="p_add">+		}</span>
<span class="p_add">+	}</span>
<span class="p_add">+	local_irq_restore(flags);</span>
<span class="p_add">+</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void cpu_dma_wbinval_range(unsigned long start, unsigned long end)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long line_size;</span>
<span class="p_add">+	unsigned long flags;</span>
<span class="p_add">+	line_size = L1_cache_info[DCACHE].line_size;</span>
<span class="p_add">+	start = start &amp; (~(line_size - 1));</span>
<span class="p_add">+	end = (end + line_size - 1) &amp; (~(line_size - 1));</span>
<span class="p_add">+	if (unlikely(start == end))</span>
<span class="p_add">+		return;</span>
<span class="p_add">+</span>
<span class="p_add">+	local_irq_save(flags);</span>
<span class="p_add">+	cpu_dcache_wbinval_range(start, end);</span>
<span class="p_add">+	if (IS_ENABLED(CONFIG_CACHE_L2)) {</span>
<span class="p_add">+		if (atl2c_base) {</span>
<span class="p_add">+			unsigned long p_start = __pa(start);</span>
<span class="p_add">+			unsigned long p_end = __pa(end);</span>
<span class="p_add">+			unsigned long cmd;</span>
<span class="p_add">+</span>
<span class="p_add">+			/* TODO Can Use PAGE Mode to optimize if range large than PAGE_SIZE */</span>
<span class="p_add">+			line_size = L2_CACHE_LINE_SIZE();</span>
<span class="p_add">+			p_start = p_start &amp; (~(line_size - 1));</span>
<span class="p_add">+			p_end = (p_end + line_size - 1) &amp; (~(line_size - 1));</span>
<span class="p_add">+			cmd =</span>
<span class="p_add">+			    (p_start &amp; ~(line_size - 1)) | CCTL_CMD_L2_PA_WBINVAL |</span>
<span class="p_add">+			    CCTL_SINGLE_CMD;</span>
<span class="p_add">+			do {</span>
<span class="p_add">+				L2_CMD_RDY();</span>
<span class="p_add">+				L2C_W_REG(L2_CCTL_CMD_OFF, cmd);</span>
<span class="p_add">+				cmd += line_size;</span>
<span class="p_add">+				p_start += line_size;</span>
<span class="p_add">+			} while (p_end &gt; p_start);</span>
<span class="p_add">+			cmd = CCTL_CMD_L2_SYNC;</span>
<span class="p_add">+			L2_CMD_RDY();</span>
<span class="p_add">+			L2C_W_REG(L2_CCTL_CMD_OFF, cmd);</span>
<span class="p_add">+			L2_CMD_RDY();</span>
<span class="p_add">+		}</span>
<span class="p_add">+	}</span>
<span class="p_add">+	local_irq_restore(flags);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void cpu_proc_init(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void cpu_proc_fin(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void cpu_do_idle(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	__nds32__standby_no_wake_grant();</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void cpu_reset(unsigned long reset)</span>
<span class="p_add">+{</span>
<span class="p_add">+	u32 tmp;</span>
<span class="p_add">+	GIE_DISABLE();</span>
<span class="p_add">+	tmp = __nds32__mfsr(NDS32_SR_CACHE_CTL);</span>
<span class="p_add">+	tmp &amp;= ~(CACHE_CTL_mskIC_EN | CACHE_CTL_mskDC_EN);</span>
<span class="p_add">+	__nds32__mtsr_isb(tmp, NDS32_SR_CACHE_CTL);</span>
<span class="p_add">+	cpu_dcache_wbinval_all();</span>
<span class="p_add">+	cpu_icache_inval_all();</span>
<span class="p_add">+</span>
<span class="p_add">+	__asm__ __volatile__(&quot;jr.toff %0\n\t&quot;::&quot;r&quot;(reset));</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void cpu_switch_mm(struct mm_struct *mm)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long cid;</span>
<span class="p_add">+	cid = __nds32__mfsr(NDS32_SR_TLB_MISC);</span>
<span class="p_add">+	cid = (cid &amp; ~TLB_MISC_mskCID) | mm-&gt;context.id;</span>
<span class="p_add">+	__nds32__mtsr_dsb(cid, NDS32_SR_TLB_MISC);</span>
<span class="p_add">+	__nds32__mtsr_isb(__pa(mm-&gt;pgd), NDS32_SR_L1_PPTB);</span>
<span class="p_add">+}</span>
<span class="p_header">diff --git a/arch/nds32/mm/tlb.c b/arch/nds32/mm/tlb.c</span>
new file mode 100644
<span class="p_header">index 0000000..b397b9f</span>
<span class="p_header">--- /dev/null</span>
<span class="p_header">+++ b/arch/nds32/mm/tlb.c</span>
<span class="p_chunk">@@ -0,0 +1,63 @@</span> <span class="p_context"></span>
<span class="p_add">+/*</span>
<span class="p_add">+ * Copyright (C) 2005-2017 Andes Technology Corporation</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * This program is free software; you can redistribute it and/or modify</span>
<span class="p_add">+ * it under the terms of the GNU General Public License version 2 as</span>
<span class="p_add">+ * published by the Free Software Foundation.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * This program is distributed in the hope that it will be useful,</span>
<span class="p_add">+ * but WITHOUT ANY WARRANTY; without even the implied warranty of</span>
<span class="p_add">+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the</span>
<span class="p_add">+ * GNU General Public License for more details.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * You should have received a copy of the GNU General Public License</span>
<span class="p_add">+ * along with this program.  If not, see &lt;http://www.gnu.org/licenses/&gt;.</span>
<span class="p_add">+ */</span>
<span class="p_add">+</span>
<span class="p_add">+#include &lt;linux/spinlock_types.h&gt;</span>
<span class="p_add">+#include &lt;linux/mm.h&gt;</span>
<span class="p_add">+#include &lt;linux/sched.h&gt;</span>
<span class="p_add">+#include &lt;asm/nds32.h&gt;</span>
<span class="p_add">+#include &lt;nds32_intrinsic.h&gt;</span>
<span class="p_add">+</span>
<span class="p_add">+unsigned int cpu_last_cid = { TLB_MISC_mskCID + (2 &lt;&lt; TLB_MISC_offCID) };</span>
<span class="p_add">+</span>
<span class="p_add">+DEFINE_SPINLOCK(cid_lock);</span>
<span class="p_add">+</span>
<span class="p_add">+void local_flush_tlb_range(struct vm_area_struct *vma,</span>
<span class="p_add">+			   unsigned long start, unsigned long end)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long flags, ocid, ncid;</span>
<span class="p_add">+</span>
<span class="p_add">+	if ((end - start) &gt; 0x400000) {</span>
<span class="p_add">+		__nds32__tlbop_flua();</span>
<span class="p_add">+		__nds32__isb();</span>
<span class="p_add">+		return;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	spin_lock_irqsave(&amp;cid_lock, flags);</span>
<span class="p_add">+	ocid = __nds32__mfsr(NDS32_SR_TLB_MISC);</span>
<span class="p_add">+	ncid = (ocid &amp; ~TLB_MISC_mskCID) | vma-&gt;vm_mm-&gt;context.id;</span>
<span class="p_add">+	__nds32__mtsr_dsb(ncid, NDS32_SR_TLB_MISC);</span>
<span class="p_add">+	while (start &lt; end) {</span>
<span class="p_add">+		__nds32__tlbop_inv(start);</span>
<span class="p_add">+		__nds32__isb();</span>
<span class="p_add">+		start += PAGE_SIZE;</span>
<span class="p_add">+	}</span>
<span class="p_add">+	__nds32__mtsr_dsb(ocid, NDS32_SR_TLB_MISC);</span>
<span class="p_add">+	spin_unlock_irqrestore(&amp;cid_lock, flags);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void local_flush_tlb_page(struct vm_area_struct *vma, unsigned long addr)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long flags, ocid, ncid;</span>
<span class="p_add">+</span>
<span class="p_add">+	spin_lock_irqsave(&amp;cid_lock, flags);</span>
<span class="p_add">+	ocid = __nds32__mfsr(NDS32_SR_TLB_MISC);</span>
<span class="p_add">+	ncid = (ocid &amp; ~TLB_MISC_mskCID) | vma-&gt;vm_mm-&gt;context.id;</span>
<span class="p_add">+	__nds32__mtsr_dsb(ncid, NDS32_SR_TLB_MISC);</span>
<span class="p_add">+	__nds32__tlbop_inv(addr);</span>
<span class="p_add">+	__nds32__isb();</span>
<span class="p_add">+	__nds32__mtsr_dsb(ocid, NDS32_SR_TLB_MISC);</span>
<span class="p_add">+	spin_unlock_irqrestore(&amp;cid_lock, flags);</span>
<span class="p_add">+}</span>

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



