
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>[v4,2/5] pagemap: switch to the new format and do some cleanup - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    [v4,2/5] pagemap: switch to the new format and do some cleanup</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=120261">Konstantin Khebnikov</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>July 14, 2015, 3:37 p.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;20150714153737.29844.33895.stgit@buzz&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/6787991/mbox/"
   >mbox</a>
|
   <a href="/patch/6787991/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/6787991/">/patch/6787991/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
X-Original-To: patchwork-LKML@patchwork.kernel.org
Delivered-To: patchwork-parsemail@patchwork1.web.kernel.org
Received: from mail.kernel.org (mail.kernel.org [198.145.29.136])
	by patchwork1.web.kernel.org (Postfix) with ESMTP id 863909F2F0
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Tue, 14 Jul 2015 15:46:28 +0000 (UTC)
Received: from mail.kernel.org (localhost [127.0.0.1])
	by mail.kernel.org (Postfix) with ESMTP id 3CD762072F
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Tue, 14 Jul 2015 15:46:27 +0000 (UTC)
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.kernel.org (Postfix) with ESMTP id BE0A520729
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Tue, 14 Jul 2015 15:46:25 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1753315AbbGNPqQ (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Tue, 14 Jul 2015 11:46:16 -0400
Received: from forward-corp1f.mail.yandex.net ([95.108.130.40]:60048 &quot;EHLO
	forward-corp1f.mail.yandex.net&quot; rhost-flags-OK-OK-OK-OK)
	by vger.kernel.org with ESMTP id S1752633AbbGNPqO (ORCPT
	&lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Tue, 14 Jul 2015 11:46:14 -0400
X-Greylist: delayed 509 seconds by postgrey-1.27 at vger.kernel.org;
	Tue, 14 Jul 2015 11:46:13 EDT
Received: from smtpcorp4.mail.yandex.net (smtpcorp4.mail.yandex.net
	[95.108.252.2])
	by forward-corp1f.mail.yandex.net (Yandex) with ESMTP id 1CBA92420575;
	Tue, 14 Jul 2015 18:37:37 +0300 (MSK)
Received: from smtpcorp4.mail.yandex.net (localhost [127.0.0.1])
	by smtpcorp4.mail.yandex.net (Yandex) with ESMTP id D6C472C031F;
	Tue, 14 Jul 2015 18:37:37 +0300 (MSK)
Received: from unknown (unknown [2a02:6b8:0:40c:1811:5890:3243:c9ea])
	by smtpcorp4.mail.yandex.net (nwsmtp/Yandex) with ESMTPSA id
	NVVs5gnb6s-bbs4wkqU; Tue, 14 Jul 2015 18:37:37 +0300
	(using TLSv1.2 with cipher ECDHE-RSA-AES128-GCM-SHA256 (128/128
	bits)) (Client certificate not present)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed; d=yandex-team.ru;
	s=default; 
	t=1436888257; bh=iwM5k7BIF8uhNURy2uSFxaZM5N/l2qHNU89xrQejtmg=;
	h=Subject:From:To:Cc:Date:Message-ID:In-Reply-To:References:
	User-Agent:MIME-Version:Content-Type:Content-Transfer-Encoding;
	b=tm1fIKOEb8zp7VIVHmQ+wYGShfQriPaMsSighM9PBW55bSjndoh6QSLzTExCKQjt4
	nYwnDn4UcOV3LBeGm0U5XfUj9PjwW2uQ4A3g8qdrkXy1l3IwOmactd6FfXtTjkzyDb
	SBI5DT49+i/NBD9HocVqlis232aJkBlc2h0rRIxw=
Authentication-Results: smtpcorp4.mail.yandex.net;
	dkim=pass header.i=@yandex-team.ru
Subject: [PATCH v4 2/5] pagemap: switch to the new format and do some cleanup
From: Konstantin Khlebnikov &lt;khlebnikov@yandex-team.ru&gt;
To: linux-mm@kvack.org, Andrew Morton &lt;akpm@linux-foundation.org&gt;,
	Naoya Horiguchi &lt;n-horiguchi@ah.jp.nec.com&gt;
Cc: &quot;Kirill A. Shutemov&quot; &lt;kirill@shutemov.name&gt;,
	Mark Williamson &lt;mwilliamson@undo-software.com&gt;,
	linux-kernel@vger.kernel.org, linux-api@vger.kernel.org
Date: Tue, 14 Jul 2015 18:37:37 +0300
Message-ID: &lt;20150714153737.29844.33895.stgit@buzz&gt;
In-Reply-To: &lt;20150714152516.29844.69929.stgit@buzz&gt;
References: &lt;20150714152516.29844.69929.stgit@buzz&gt;
User-Agent: StGit/0.17.1-dirty
MIME-Version: 1.0
Content-Type: text/plain; charset=&quot;utf-8&quot;
Content-Transfer-Encoding: 7bit
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Spam-Status: No, score=-8.2 required=5.0 tests=BAYES_00,DKIM_SIGNED,
	RCVD_IN_DNSWL_HI,RP_MATCHES_RCVD,T_DKIM_INVALID,UNPARSEABLE_RELAY
	autolearn=unavailable version=3.3.1
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on mail.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=120261">Konstantin Khebnikov</a> - July 14, 2015, 3:37 p.m.</div>
<pre class="content">
This patch removes page-shift bits (scheduled to remove since 3.11) and
completes migration to the new bit layout. Also it cleans messy macro.
<span class="signed-off-by">
Signed-off-by: Konstantin Khlebnikov &lt;khlebnikov@yandex-team.ru&gt;</span>
---
 fs/proc/task_mmu.c    |  150 +++++++++++++++++--------------------------------
 tools/vm/page-types.c |   25 +++-----
 2 files changed, 61 insertions(+), 114 deletions(-)


--
To unsubscribe from this list: send the line &quot;unsubscribe linux-kernel&quot; in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
Please read the FAQ at  http://www.tux.org/lkml/
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=4407">Naoya Horiguchi</a> - July 21, 2015, 7:44 a.m.</div>
<pre class="content">
On Tue, Jul 14, 2015 at 06:37:37PM +0300, Konstantin Khlebnikov wrote:
<span class="quote">&gt; This patch removes page-shift bits (scheduled to remove since 3.11) and</span>
<span class="quote">&gt; completes migration to the new bit layout. Also it cleans messy macro.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Signed-off-by: Konstantin Khlebnikov &lt;khlebnikov@yandex-team.ru&gt;</span>
<span class="reviewed-by">
Reviewed-by: Naoya Horiguchi &lt;n-horiguchi@ah.jp.nec.com&gt;--</span>
To unsubscribe from this list: send the line &quot;unsubscribe linux-kernel&quot; in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
Please read the FAQ at  http://www.tux.org/lkml/
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/fs/proc/task_mmu.c b/fs/proc/task_mmu.c</span>
<span class="p_header">index 270bf7cbc8a5..c05db6acdc35 100644</span>
<span class="p_header">--- a/fs/proc/task_mmu.c</span>
<span class="p_header">+++ b/fs/proc/task_mmu.c</span>
<span class="p_chunk">@@ -710,23 +710,6 @@</span> <span class="p_context"> const struct file_operations proc_tid_smaps_operations = {</span>
 	.release	= proc_map_release,
 };
 
<span class="p_del">-/*</span>
<span class="p_del">- * We do not want to have constant page-shift bits sitting in</span>
<span class="p_del">- * pagemap entries and are about to reuse them some time soon.</span>
<span class="p_del">- *</span>
<span class="p_del">- * Here&#39;s the &quot;migration strategy&quot;:</span>
<span class="p_del">- * 1. when the system boots these bits remain what they are,</span>
<span class="p_del">- *    but a warning about future change is printed in log;</span>
<span class="p_del">- * 2. once anyone clears soft-dirty bits via clear_refs file,</span>
<span class="p_del">- *    these flag is set to denote, that user is aware of the</span>
<span class="p_del">- *    new API and those page-shift bits change their meaning.</span>
<span class="p_del">- *    The respective warning is printed in dmesg;</span>
<span class="p_del">- * 3. In a couple of releases we will remove all the mentions</span>
<span class="p_del">- *    of page-shift in pagemap entries.</span>
<span class="p_del">- */</span>
<span class="p_del">-</span>
<span class="p_del">-static bool soft_dirty_cleared __read_mostly;</span>
<span class="p_del">-</span>
 enum clear_refs_types {
 	CLEAR_REFS_ALL = 1,
 	CLEAR_REFS_ANON,
<span class="p_chunk">@@ -887,13 +870,6 @@</span> <span class="p_context"> static ssize_t clear_refs_write(struct file *file, const char __user *buf,</span>
 	if (type &lt; CLEAR_REFS_ALL || type &gt;= CLEAR_REFS_LAST)
 		return -EINVAL;
 
<span class="p_del">-	if (type == CLEAR_REFS_SOFT_DIRTY) {</span>
<span class="p_del">-		soft_dirty_cleared = true;</span>
<span class="p_del">-		pr_warn_once(&quot;The pagemap bits 55-60 has changed their meaning!&quot;</span>
<span class="p_del">-			     &quot; See the linux/Documentation/vm/pagemap.txt for &quot;</span>
<span class="p_del">-			     &quot;details.\n&quot;);</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
 	task = get_proc_task(file_inode(file));
 	if (!task)
 		return -ESRCH;
<span class="p_chunk">@@ -961,36 +937,24 @@</span> <span class="p_context"> typedef struct {</span>
 struct pagemapread {
 	int pos, len;		/* units: PM_ENTRY_BYTES, not bytes */
 	pagemap_entry_t *buffer;
<span class="p_del">-	bool v2;</span>
 };
 
 #define PAGEMAP_WALK_SIZE	(PMD_SIZE)
 #define PAGEMAP_WALK_MASK	(PMD_MASK)
 
<span class="p_del">-#define PM_ENTRY_BYTES      sizeof(pagemap_entry_t)</span>
<span class="p_del">-#define PM_STATUS_BITS      3</span>
<span class="p_del">-#define PM_STATUS_OFFSET    (64 - PM_STATUS_BITS)</span>
<span class="p_del">-#define PM_STATUS_MASK      (((1LL &lt;&lt; PM_STATUS_BITS) - 1) &lt;&lt; PM_STATUS_OFFSET)</span>
<span class="p_del">-#define PM_STATUS(nr)       (((nr) &lt;&lt; PM_STATUS_OFFSET) &amp; PM_STATUS_MASK)</span>
<span class="p_del">-#define PM_PSHIFT_BITS      6</span>
<span class="p_del">-#define PM_PSHIFT_OFFSET    (PM_STATUS_OFFSET - PM_PSHIFT_BITS)</span>
<span class="p_del">-#define PM_PSHIFT_MASK      (((1LL &lt;&lt; PM_PSHIFT_BITS) - 1) &lt;&lt; PM_PSHIFT_OFFSET)</span>
<span class="p_del">-#define __PM_PSHIFT(x)      (((u64) (x) &lt;&lt; PM_PSHIFT_OFFSET) &amp; PM_PSHIFT_MASK)</span>
<span class="p_del">-#define PM_PFRAME_MASK      ((1LL &lt;&lt; PM_PSHIFT_OFFSET) - 1)</span>
<span class="p_del">-#define PM_PFRAME(x)        ((x) &amp; PM_PFRAME_MASK)</span>
<span class="p_del">-/* in &quot;new&quot; pagemap pshift bits are occupied with more status bits */</span>
<span class="p_del">-#define PM_STATUS2(v2, x)   (__PM_PSHIFT(v2 ? x : PAGE_SHIFT))</span>
<span class="p_del">-</span>
<span class="p_del">-#define __PM_SOFT_DIRTY      (1LL)</span>
<span class="p_del">-#define PM_PRESENT          PM_STATUS(4LL)</span>
<span class="p_del">-#define PM_SWAP             PM_STATUS(2LL)</span>
<span class="p_del">-#define PM_FILE             PM_STATUS(1LL)</span>
<span class="p_del">-#define PM_NOT_PRESENT(v2)  PM_STATUS2(v2, 0)</span>
<span class="p_add">+#define PM_ENTRY_BYTES		sizeof(pagemap_entry_t)</span>
<span class="p_add">+#define PM_PFRAME_BITS		55</span>
<span class="p_add">+#define PM_PFRAME_MASK		GENMASK_ULL(PM_PFRAME_BITS - 1, 0)</span>
<span class="p_add">+#define PM_SOFT_DIRTY		BIT_ULL(55)</span>
<span class="p_add">+#define PM_FILE			BIT_ULL(61)</span>
<span class="p_add">+#define PM_SWAP			BIT_ULL(62)</span>
<span class="p_add">+#define PM_PRESENT		BIT_ULL(63)</span>
<span class="p_add">+</span>
 #define PM_END_OF_BUFFER    1
 
<span class="p_del">-static inline pagemap_entry_t make_pme(u64 val)</span>
<span class="p_add">+static inline pagemap_entry_t make_pme(u64 frame, u64 flags)</span>
 {
<span class="p_del">-	return (pagemap_entry_t) { .pme = val };</span>
<span class="p_add">+	return (pagemap_entry_t) { .pme = (frame &amp; PM_PFRAME_MASK) | flags };</span>
 }
 
 static int add_to_pagemap(unsigned long addr, pagemap_entry_t *pme,
<span class="p_chunk">@@ -1011,7 +975,7 @@</span> <span class="p_context"> static int pagemap_pte_hole(unsigned long start, unsigned long end,</span>
 
 	while (addr &lt; end) {
 		struct vm_area_struct *vma = find_vma(walk-&gt;mm, addr);
<span class="p_del">-		pagemap_entry_t pme = make_pme(PM_NOT_PRESENT(pm-&gt;v2));</span>
<span class="p_add">+		pagemap_entry_t pme = make_pme(0, 0);</span>
 		/* End of address space hole, which we mark as non-present. */
 		unsigned long hole_end;
 
<span class="p_chunk">@@ -1031,7 +995,7 @@</span> <span class="p_context"> static int pagemap_pte_hole(unsigned long start, unsigned long end,</span>
 
 		/* Addresses in the VMA. */
 		if (vma-&gt;vm_flags &amp; VM_SOFTDIRTY)
<span class="p_del">-			pme.pme |= PM_STATUS2(pm-&gt;v2, __PM_SOFT_DIRTY);</span>
<span class="p_add">+			pme = make_pme(0, PM_SOFT_DIRTY);</span>
 		for (; addr &lt; min(end, vma-&gt;vm_end); addr += PAGE_SIZE) {
 			err = add_to_pagemap(addr, &amp;pme, pm);
 			if (err)
<span class="p_chunk">@@ -1042,63 +1006,61 @@</span> <span class="p_context"> out:</span>
 	return err;
 }
 
<span class="p_del">-static void pte_to_pagemap_entry(pagemap_entry_t *pme, struct pagemapread *pm,</span>
<span class="p_add">+static pagemap_entry_t pte_to_pagemap_entry(struct pagemapread *pm,</span>
 		struct vm_area_struct *vma, unsigned long addr, pte_t pte)
 {
<span class="p_del">-	u64 frame, flags;</span>
<span class="p_add">+	u64 frame = 0, flags = 0;</span>
 	struct page *page = NULL;
<span class="p_del">-	int flags2 = 0;</span>
 
 	if (pte_present(pte)) {
 		frame = pte_pfn(pte);
<span class="p_del">-		flags = PM_PRESENT;</span>
<span class="p_add">+		flags |= PM_PRESENT;</span>
 		page = vm_normal_page(vma, addr, pte);
 		if (pte_soft_dirty(pte))
<span class="p_del">-			flags2 |= __PM_SOFT_DIRTY;</span>
<span class="p_add">+			flags |= PM_SOFT_DIRTY;</span>
 	} else if (is_swap_pte(pte)) {
 		swp_entry_t entry;
 		if (pte_swp_soft_dirty(pte))
<span class="p_del">-			flags2 |= __PM_SOFT_DIRTY;</span>
<span class="p_add">+			flags |= PM_SOFT_DIRTY;</span>
 		entry = pte_to_swp_entry(pte);
 		frame = swp_type(entry) |
 			(swp_offset(entry) &lt;&lt; MAX_SWAPFILES_SHIFT);
<span class="p_del">-		flags = PM_SWAP;</span>
<span class="p_add">+		flags |= PM_SWAP;</span>
 		if (is_migration_entry(entry))
 			page = migration_entry_to_page(entry);
<span class="p_del">-	} else {</span>
<span class="p_del">-		if (vma-&gt;vm_flags &amp; VM_SOFTDIRTY)</span>
<span class="p_del">-			flags2 |= __PM_SOFT_DIRTY;</span>
<span class="p_del">-		*pme = make_pme(PM_NOT_PRESENT(pm-&gt;v2) | PM_STATUS2(pm-&gt;v2, flags2));</span>
<span class="p_del">-		return;</span>
 	}
 
 	if (page &amp;&amp; !PageAnon(page))
 		flags |= PM_FILE;
<span class="p_del">-	if ((vma-&gt;vm_flags &amp; VM_SOFTDIRTY))</span>
<span class="p_del">-		flags2 |= __PM_SOFT_DIRTY;</span>
<span class="p_add">+	if (vma-&gt;vm_flags &amp; VM_SOFTDIRTY)</span>
<span class="p_add">+		flags |= PM_SOFT_DIRTY;</span>
 
<span class="p_del">-	*pme = make_pme(PM_PFRAME(frame) | PM_STATUS2(pm-&gt;v2, flags2) | flags);</span>
<span class="p_add">+	return make_pme(frame, flags);</span>
 }
 
 #ifdef CONFIG_TRANSPARENT_HUGEPAGE
<span class="p_del">-static void thp_pmd_to_pagemap_entry(pagemap_entry_t *pme, struct pagemapread *pm,</span>
<span class="p_del">-		pmd_t pmd, int offset, int pmd_flags2)</span>
<span class="p_add">+static pagemap_entry_t thp_pmd_to_pagemap_entry(struct pagemapread *pm,</span>
<span class="p_add">+		pmd_t pmd, int offset, u64 flags)</span>
 {
<span class="p_add">+	u64 frame = 0;</span>
<span class="p_add">+</span>
 	/*
 	 * Currently pmd for thp is always present because thp can not be
 	 * swapped-out, migrated, or HWPOISONed (split in such cases instead.)
 	 * This if-check is just to prepare for future implementation.
 	 */
<span class="p_del">-	if (pmd_present(pmd))</span>
<span class="p_del">-		*pme = make_pme(PM_PFRAME(pmd_pfn(pmd) + offset)</span>
<span class="p_del">-				| PM_STATUS2(pm-&gt;v2, pmd_flags2) | PM_PRESENT);</span>
<span class="p_del">-	else</span>
<span class="p_del">-		*pme = make_pme(PM_NOT_PRESENT(pm-&gt;v2) | PM_STATUS2(pm-&gt;v2, pmd_flags2));</span>
<span class="p_add">+	if (pmd_present(pmd)) {</span>
<span class="p_add">+		frame = pmd_pfn(pmd) + offset;</span>
<span class="p_add">+		flags |= PM_PRESENT;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	return make_pme(frame, flags);</span>
 }
 #else
<span class="p_del">-static inline void thp_pmd_to_pagemap_entry(pagemap_entry_t *pme, struct pagemapread *pm,</span>
<span class="p_del">-		pmd_t pmd, int offset, int pmd_flags2)</span>
<span class="p_add">+static pagemap_entry_t thp_pmd_to_pagemap_entry(struct pagemapread *pm,</span>
<span class="p_add">+		pmd_t pmd, int offset, u64 flags)</span>
 {
<span class="p_add">+	return make_pme(0, 0);</span>
 }
 #endif
 
<span class="p_chunk">@@ -1112,12 +1074,10 @@</span> <span class="p_context"> static int pagemap_pte_range(pmd_t *pmd, unsigned long addr, unsigned long end,</span>
 	int err = 0;
 
 	if (pmd_trans_huge_lock(pmd, vma, &amp;ptl) == 1) {
<span class="p_del">-		int pmd_flags2;</span>
<span class="p_add">+		u64 flags = 0;</span>
 
 		if ((vma-&gt;vm_flags &amp; VM_SOFTDIRTY) || pmd_soft_dirty(*pmd))
<span class="p_del">-			pmd_flags2 = __PM_SOFT_DIRTY;</span>
<span class="p_del">-		else</span>
<span class="p_del">-			pmd_flags2 = 0;</span>
<span class="p_add">+			flags |= PM_SOFT_DIRTY;</span>
 
 		for (; addr != end; addr += PAGE_SIZE) {
 			unsigned long offset;
<span class="p_chunk">@@ -1125,7 +1085,7 @@</span> <span class="p_context"> static int pagemap_pte_range(pmd_t *pmd, unsigned long addr, unsigned long end,</span>
 
 			offset = (addr &amp; ~PAGEMAP_WALK_MASK) &gt;&gt;
 					PAGE_SHIFT;
<span class="p_del">-			thp_pmd_to_pagemap_entry(&amp;pme, pm, *pmd, offset, pmd_flags2);</span>
<span class="p_add">+			pme = thp_pmd_to_pagemap_entry(pm, *pmd, offset, flags);</span>
 			err = add_to_pagemap(addr, &amp;pme, pm);
 			if (err)
 				break;
<span class="p_chunk">@@ -1145,7 +1105,7 @@</span> <span class="p_context"> static int pagemap_pte_range(pmd_t *pmd, unsigned long addr, unsigned long end,</span>
 	for (; addr &lt; end; pte++, addr += PAGE_SIZE) {
 		pagemap_entry_t pme;
 
<span class="p_del">-		pte_to_pagemap_entry(&amp;pme, pm, vma, addr, *pte);</span>
<span class="p_add">+		pme = pte_to_pagemap_entry(pm, vma, addr, *pte);</span>
 		err = add_to_pagemap(addr, &amp;pme, pm);
 		if (err)
 			break;
<span class="p_chunk">@@ -1158,16 +1118,17 @@</span> <span class="p_context"> static int pagemap_pte_range(pmd_t *pmd, unsigned long addr, unsigned long end,</span>
 }
 
 #ifdef CONFIG_HUGETLB_PAGE
<span class="p_del">-static void huge_pte_to_pagemap_entry(pagemap_entry_t *pme, struct pagemapread *pm,</span>
<span class="p_del">-					pte_t pte, int offset, int flags2)</span>
<span class="p_add">+static pagemap_entry_t huge_pte_to_pagemap_entry(struct pagemapread *pm,</span>
<span class="p_add">+					pte_t pte, int offset, u64 flags)</span>
 {
<span class="p_del">-	if (pte_present(pte))</span>
<span class="p_del">-		*pme = make_pme(PM_PFRAME(pte_pfn(pte) + offset)	|</span>
<span class="p_del">-				PM_STATUS2(pm-&gt;v2, flags2)		|</span>
<span class="p_del">-				PM_PRESENT);</span>
<span class="p_del">-	else</span>
<span class="p_del">-		*pme = make_pme(PM_NOT_PRESENT(pm-&gt;v2)			|</span>
<span class="p_del">-				PM_STATUS2(pm-&gt;v2, flags2));</span>
<span class="p_add">+	u64 frame = 0;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (pte_present(pte)) {</span>
<span class="p_add">+		frame = pte_pfn(pte) + offset;</span>
<span class="p_add">+		flags |= PM_PRESENT;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	return make_pme(frame, flags);</span>
 }
 
 /* This function walks within one hugetlb entry in the single call */
<span class="p_chunk">@@ -1178,17 +1139,15 @@</span> <span class="p_context"> static int pagemap_hugetlb_range(pte_t *pte, unsigned long hmask,</span>
 	struct pagemapread *pm = walk-&gt;private;
 	struct vm_area_struct *vma = walk-&gt;vma;
 	int err = 0;
<span class="p_del">-	int flags2;</span>
<span class="p_add">+	u64 flags = 0;</span>
 	pagemap_entry_t pme;
 
 	if (vma-&gt;vm_flags &amp; VM_SOFTDIRTY)
<span class="p_del">-		flags2 = __PM_SOFT_DIRTY;</span>
<span class="p_del">-	else</span>
<span class="p_del">-		flags2 = 0;</span>
<span class="p_add">+		flags |= PM_SOFT_DIRTY;</span>
 
 	for (; addr != end; addr += PAGE_SIZE) {
 		int offset = (addr &amp; ~hmask) &gt;&gt; PAGE_SHIFT;
<span class="p_del">-		huge_pte_to_pagemap_entry(&amp;pme, pm, *pte, offset, flags2);</span>
<span class="p_add">+		pme = huge_pte_to_pagemap_entry(pm, *pte, offset, flags);</span>
 		err = add_to_pagemap(addr, &amp;pme, pm);
 		if (err)
 			return err;
<span class="p_chunk">@@ -1209,7 +1168,8 @@</span> <span class="p_context"> static int pagemap_hugetlb_range(pte_t *pte, unsigned long hmask,</span>
  * Bits 0-54  page frame number (PFN) if present
  * Bits 0-4   swap type if swapped
  * Bits 5-54  swap offset if swapped
<span class="p_del">- * Bits 55-60 page shift (page size = 1&lt;&lt;page shift)</span>
<span class="p_add">+ * Bit  55    pte is soft-dirty (see Documentation/vm/soft-dirty.txt)</span>
<span class="p_add">+ * Bits 56-60 zero</span>
  * Bit  61    page is file-page or shared-anon
  * Bit  62    page swapped
  * Bit  63    page present
<span class="p_chunk">@@ -1248,7 +1208,6 @@</span> <span class="p_context"> static ssize_t pagemap_read(struct file *file, char __user *buf,</span>
 	if (!count)
 		goto out_mm;
 
<span class="p_del">-	pm.v2 = soft_dirty_cleared;</span>
 	pm.len = (PAGEMAP_WALK_SIZE &gt;&gt; PAGE_SHIFT);
 	pm.buffer = kmalloc(pm.len * PM_ENTRY_BYTES, GFP_TEMPORARY);
 	ret = -ENOMEM;
<span class="p_chunk">@@ -1321,9 +1280,6 @@</span> <span class="p_context"> static int pagemap_open(struct inode *inode, struct file *file)</span>
 	/* do not disclose physical addresses: attack vector */
 	if (!capable(CAP_SYS_ADMIN))
 		return -EPERM;
<span class="p_del">-	pr_warn_once(&quot;Bits 55-60 of /proc/PID/pagemap entries are about &quot;</span>
<span class="p_del">-			&quot;to stop being page-shift some time soon. See the &quot;</span>
<span class="p_del">-			&quot;linux/Documentation/vm/pagemap.txt for details.\n&quot;);</span>
 
 	mm = proc_mem_open(inode, PTRACE_MODE_READ);
 	if (IS_ERR(mm))
<span class="p_header">diff --git a/tools/vm/page-types.c b/tools/vm/page-types.c</span>
<span class="p_header">index 8bdf16b8ba60..603ec916716b 100644</span>
<span class="p_header">--- a/tools/vm/page-types.c</span>
<span class="p_header">+++ b/tools/vm/page-types.c</span>
<span class="p_chunk">@@ -57,23 +57,14 @@</span> <span class="p_context"></span>
  * pagemap kernel ABI bits
  */
 
<span class="p_del">-#define PM_ENTRY_BYTES      sizeof(uint64_t)</span>
<span class="p_del">-#define PM_STATUS_BITS      3</span>
<span class="p_del">-#define PM_STATUS_OFFSET    (64 - PM_STATUS_BITS)</span>
<span class="p_del">-#define PM_STATUS_MASK      (((1LL &lt;&lt; PM_STATUS_BITS) - 1) &lt;&lt; PM_STATUS_OFFSET)</span>
<span class="p_del">-#define PM_STATUS(nr)       (((nr) &lt;&lt; PM_STATUS_OFFSET) &amp; PM_STATUS_MASK)</span>
<span class="p_del">-#define PM_PSHIFT_BITS      6</span>
<span class="p_del">-#define PM_PSHIFT_OFFSET    (PM_STATUS_OFFSET - PM_PSHIFT_BITS)</span>
<span class="p_del">-#define PM_PSHIFT_MASK      (((1LL &lt;&lt; PM_PSHIFT_BITS) - 1) &lt;&lt; PM_PSHIFT_OFFSET)</span>
<span class="p_del">-#define __PM_PSHIFT(x)      (((uint64_t) (x) &lt;&lt; PM_PSHIFT_OFFSET) &amp; PM_PSHIFT_MASK)</span>
<span class="p_del">-#define PM_PFRAME_MASK      ((1LL &lt;&lt; PM_PSHIFT_OFFSET) - 1)</span>
<span class="p_del">-#define PM_PFRAME(x)        ((x) &amp; PM_PFRAME_MASK)</span>
<span class="p_del">-</span>
<span class="p_del">-#define __PM_SOFT_DIRTY      (1LL)</span>
<span class="p_del">-#define PM_PRESENT          PM_STATUS(4LL)</span>
<span class="p_del">-#define PM_SWAP             PM_STATUS(2LL)</span>
<span class="p_del">-#define PM_SOFT_DIRTY       __PM_PSHIFT(__PM_SOFT_DIRTY)</span>
<span class="p_del">-</span>
<span class="p_add">+#define PM_ENTRY_BYTES		8</span>
<span class="p_add">+#define PM_PFRAME_BITS		55</span>
<span class="p_add">+#define PM_PFRAME_MASK		((1LL &lt;&lt; PM_PFRAME_BITS) - 1)</span>
<span class="p_add">+#define PM_PFRAME(x)		((x) &amp; PM_PFRAME_MASK)</span>
<span class="p_add">+#define PM_SOFT_DIRTY		(1ULL &lt;&lt; 55)</span>
<span class="p_add">+#define PM_FILE			(1ULL &lt;&lt; 61)</span>
<span class="p_add">+#define PM_SWAP			(1ULL &lt;&lt; 62)</span>
<span class="p_add">+#define PM_PRESENT		(1ULL &lt;&lt; 63)</span>
 
 /*
  * kernel page flags

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



