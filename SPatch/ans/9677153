
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>Linux 4.4.61 - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    Linux 4.4.61</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=37061">gregkh@linuxfoundation.org</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>April 12, 2017, 11:06 a.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;20170412110640.GB27250@kroah.com&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/9677153/mbox/"
   >mbox</a>
|
   <a href="/patch/9677153/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/9677153/">/patch/9677153/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
	[172.30.200.125])
	by pdx-korg-patchwork.web.codeaurora.org (Postfix) with ESMTP id
	98201601C3 for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Wed, 12 Apr 2017 11:07:06 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 83D1B28249
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Wed, 12 Apr 2017 11:07:06 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id 74C9428338; Wed, 12 Apr 2017 11:07:06 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-6.9 required=2.0 tests=BAYES_00,RCVD_IN_DNSWL_HI
	autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 8388F28249
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Wed, 12 Apr 2017 11:07:03 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1753434AbdDLLGz (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Wed, 12 Apr 2017 07:06:55 -0400
Received: from mail.linuxfoundation.org ([140.211.169.12]:44406 &quot;EHLO
	mail.linuxfoundation.org&quot; rhost-flags-OK-OK-OK-OK) by vger.kernel.org
	with ESMTP id S1753262AbdDLLGv (ORCPT
	&lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Wed, 12 Apr 2017 07:06:51 -0400
Received: from localhost (084035110146.static.ipv4.infopact.nl
	[84.35.110.146])
	by mail.linuxfoundation.org (Postfix) with ESMTPSA id C249E7A8;
	Wed, 12 Apr 2017 11:06:49 +0000 (UTC)
Date: Wed, 12 Apr 2017 13:06:40 +0200
From: Greg KH &lt;gregkh@linuxfoundation.org&gt;
To: linux-kernel@vger.kernel.org, Andrew Morton &lt;akpm@linux-foundation.org&gt;,
	torvalds@linux-foundation.org, stable@vger.kernel.org
Cc: lwn@lwn.net, Jiri Slaby &lt;jslaby@suse.cz&gt;
Subject: Re: Linux 4.4.61
Message-ID: &lt;20170412110640.GB27250@kroah.com&gt;
References: &lt;20170412110636.GA27250@kroah.com&gt;
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Disposition: inline
In-Reply-To: &lt;20170412110636.GA27250@kroah.com&gt;
User-Agent: Mutt/1.8.0 (2017-02-23)
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=37061">gregkh@linuxfoundation.org</a> - April 12, 2017, 11:06 a.m.</div>
<pre class="content">

</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/Makefile b/Makefile</span>
<span class="p_header">index fb7c2b40753d..ef5045b8201d 100644</span>
<span class="p_header">--- a/Makefile</span>
<span class="p_header">+++ b/Makefile</span>
<span class="p_chunk">@@ -1,6 +1,6 @@</span> <span class="p_context"></span>
 VERSION = 4
 PATCHLEVEL = 4
<span class="p_del">-SUBLEVEL = 60</span>
<span class="p_add">+SUBLEVEL = 61</span>
 EXTRAVERSION =
 NAME = Blurry Fish Butt
 
<span class="p_header">diff --git a/arch/arm/kvm/mmu.c b/arch/arm/kvm/mmu.c</span>
<span class="p_header">index 11b6595c2672..f91ee2f27b41 100644</span>
<span class="p_header">--- a/arch/arm/kvm/mmu.c</span>
<span class="p_header">+++ b/arch/arm/kvm/mmu.c</span>
<span class="p_chunk">@@ -796,6 +796,7 @@</span> <span class="p_context"> void stage2_unmap_vm(struct kvm *kvm)</span>
 	int idx;
 
 	idx = srcu_read_lock(&amp;kvm-&gt;srcu);
<span class="p_add">+	down_read(&amp;current-&gt;mm-&gt;mmap_sem);</span>
 	spin_lock(&amp;kvm-&gt;mmu_lock);
 
 	slots = kvm_memslots(kvm);
<span class="p_chunk">@@ -803,6 +804,7 @@</span> <span class="p_context"> void stage2_unmap_vm(struct kvm *kvm)</span>
 		stage2_unmap_memslot(kvm, memslot);
 
 	spin_unlock(&amp;kvm-&gt;mmu_lock);
<span class="p_add">+	up_read(&amp;current-&gt;mm-&gt;mmap_sem);</span>
 	srcu_read_unlock(&amp;kvm-&gt;srcu, idx);
 }
 
<span class="p_chunk">@@ -1759,6 +1761,7 @@</span> <span class="p_context"> int kvm_arch_prepare_memory_region(struct kvm *kvm,</span>
 	    (KVM_PHYS_SIZE &gt;&gt; PAGE_SHIFT))
 		return -EFAULT;
 
<span class="p_add">+	down_read(&amp;current-&gt;mm-&gt;mmap_sem);</span>
 	/*
 	 * A memory region could potentially cover multiple VMAs, and any holes
 	 * between them, so iterate over all of them to find out if we can map
<span class="p_chunk">@@ -1802,8 +1805,10 @@</span> <span class="p_context"> int kvm_arch_prepare_memory_region(struct kvm *kvm,</span>
 			pa += vm_start - vma-&gt;vm_start;
 
 			/* IO region dirty page logging not allowed */
<span class="p_del">-			if (memslot-&gt;flags &amp; KVM_MEM_LOG_DIRTY_PAGES)</span>
<span class="p_del">-				return -EINVAL;</span>
<span class="p_add">+			if (memslot-&gt;flags &amp; KVM_MEM_LOG_DIRTY_PAGES) {</span>
<span class="p_add">+				ret = -EINVAL;</span>
<span class="p_add">+				goto out;</span>
<span class="p_add">+			}</span>
 
 			ret = kvm_phys_addr_ioremap(kvm, gpa, pa,
 						    vm_end - vm_start,
<span class="p_chunk">@@ -1815,7 +1820,7 @@</span> <span class="p_context"> int kvm_arch_prepare_memory_region(struct kvm *kvm,</span>
 	} while (hva &lt; reg_end);
 
 	if (change == KVM_MR_FLAGS_ONLY)
<span class="p_del">-		return ret;</span>
<span class="p_add">+		goto out;</span>
 
 	spin_lock(&amp;kvm-&gt;mmu_lock);
 	if (ret)
<span class="p_chunk">@@ -1823,6 +1828,8 @@</span> <span class="p_context"> int kvm_arch_prepare_memory_region(struct kvm *kvm,</span>
 	else
 		stage2_flush_memslot(kvm, memslot);
 	spin_unlock(&amp;kvm-&gt;mmu_lock);
<span class="p_add">+out:</span>
<span class="p_add">+	up_read(&amp;current-&gt;mm-&gt;mmap_sem);</span>
 	return ret;
 }
 
<span class="p_header">diff --git a/arch/metag/include/asm/uaccess.h b/arch/metag/include/asm/uaccess.h</span>
<span class="p_header">index 273e61225c27..07238b39638c 100644</span>
<span class="p_header">--- a/arch/metag/include/asm/uaccess.h</span>
<span class="p_header">+++ b/arch/metag/include/asm/uaccess.h</span>
<span class="p_chunk">@@ -197,20 +197,21 @@</span> <span class="p_context"> extern long __must_check strnlen_user(const char __user *src, long count);</span>
 
 #define strlen_user(str) strnlen_user(str, 32767)
 
<span class="p_del">-extern unsigned long __must_check __copy_user_zeroing(void *to,</span>
<span class="p_del">-						      const void __user *from,</span>
<span class="p_del">-						      unsigned long n);</span>
<span class="p_add">+extern unsigned long raw_copy_from_user(void *to, const void __user *from,</span>
<span class="p_add">+					unsigned long n);</span>
 
 static inline unsigned long
 copy_from_user(void *to, const void __user *from, unsigned long n)
 {
<span class="p_add">+	unsigned long res = n;</span>
 	if (likely(access_ok(VERIFY_READ, from, n)))
<span class="p_del">-		return __copy_user_zeroing(to, from, n);</span>
<span class="p_del">-	memset(to, 0, n);</span>
<span class="p_del">-	return n;</span>
<span class="p_add">+		res = raw_copy_from_user(to, from, n);</span>
<span class="p_add">+	if (unlikely(res))</span>
<span class="p_add">+		memset(to + (n - res), 0, res);</span>
<span class="p_add">+	return res;</span>
 }
 
<span class="p_del">-#define __copy_from_user(to, from, n) __copy_user_zeroing(to, from, n)</span>
<span class="p_add">+#define __copy_from_user(to, from, n) raw_copy_from_user(to, from, n)</span>
 #define __copy_from_user_inatomic __copy_from_user
 
 extern unsigned long __must_check __copy_user(void __user *to,
<span class="p_header">diff --git a/arch/metag/lib/usercopy.c b/arch/metag/lib/usercopy.c</span>
<span class="p_header">index b3ebfe9c8e88..2792fc621088 100644</span>
<span class="p_header">--- a/arch/metag/lib/usercopy.c</span>
<span class="p_header">+++ b/arch/metag/lib/usercopy.c</span>
<span class="p_chunk">@@ -29,7 +29,6 @@</span> <span class="p_context"></span>
 		COPY						 \
 		&quot;1:\n&quot;						 \
 		&quot;	.section .fixup,\&quot;ax\&quot;\n&quot;		 \
<span class="p_del">-		&quot;	MOV D1Ar1,#0\n&quot;				 \</span>
 		FIXUP						 \
 		&quot;	MOVT    D1Ar1,#HI(1b)\n&quot;		 \
 		&quot;	JUMP    D1Ar1,#LO(1b)\n&quot;		 \
<span class="p_chunk">@@ -260,27 +259,31 @@</span> <span class="p_context"></span>
 		&quot;MGETL	D0FrT, D0.5, D0.6, D0.7, [%1++]\n&quot;		\
 		&quot;22:\n&quot;							\
 		&quot;MSETL	[%0++], D0FrT, D0.5, D0.6, D0.7\n&quot;		\
<span class="p_del">-		&quot;SUB	%3, %3, #32\n&quot;					\</span>
 		&quot;23:\n&quot;							\
<span class="p_del">-		&quot;MGETL	D0FrT, D0.5, D0.6, D0.7, [%1++]\n&quot;		\</span>
<span class="p_add">+		&quot;SUB	%3, %3, #32\n&quot;					\</span>
 		&quot;24:\n&quot;							\
<span class="p_add">+		&quot;MGETL	D0FrT, D0.5, D0.6, D0.7, [%1++]\n&quot;		\</span>
<span class="p_add">+		&quot;25:\n&quot;							\</span>
 		&quot;MSETL	[%0++], D0FrT, D0.5, D0.6, D0.7\n&quot;		\
<span class="p_add">+		&quot;26:\n&quot;							\</span>
 		&quot;SUB	%3, %3, #32\n&quot;					\
 		&quot;DCACHE	[%1+#-64], D0Ar6\n&quot;				\
 		&quot;BR	$Lloop&quot;id&quot;\n&quot;					\
 									\
 		&quot;MOV	RAPF, %1\n&quot;					\
<span class="p_del">-		&quot;25:\n&quot;							\</span>
<span class="p_add">+		&quot;27:\n&quot;							\</span>
 		&quot;MGETL	D0FrT, D0.5, D0.6, D0.7, [%1++]\n&quot;		\
<span class="p_del">-		&quot;26:\n&quot;							\</span>
<span class="p_add">+		&quot;28:\n&quot;							\</span>
 		&quot;MSETL	[%0++], D0FrT, D0.5, D0.6, D0.7\n&quot;		\
<span class="p_add">+		&quot;29:\n&quot;							\</span>
 		&quot;SUB	%3, %3, #32\n&quot;					\
<span class="p_del">-		&quot;27:\n&quot;							\</span>
<span class="p_add">+		&quot;30:\n&quot;							\</span>
 		&quot;MGETL	D0FrT, D0.5, D0.6, D0.7, [%1++]\n&quot;		\
<span class="p_del">-		&quot;28:\n&quot;							\</span>
<span class="p_add">+		&quot;31:\n&quot;							\</span>
 		&quot;MSETL	[%0++], D0FrT, D0.5, D0.6, D0.7\n&quot;		\
<span class="p_add">+		&quot;32:\n&quot;							\</span>
 		&quot;SUB	%0, %0, #8\n&quot;					\
<span class="p_del">-		&quot;29:\n&quot;							\</span>
<span class="p_add">+		&quot;33:\n&quot;							\</span>
 		&quot;SETL	[%0++], D0.7, D1.7\n&quot;				\
 		&quot;SUB	%3, %3, #32\n&quot;					\
 		&quot;1:&quot;							\
<span class="p_chunk">@@ -312,11 +315,15 @@</span> <span class="p_context"></span>
 		&quot;	.long 26b,3b\n&quot;					\
 		&quot;	.long 27b,3b\n&quot;					\
 		&quot;	.long 28b,3b\n&quot;					\
<span class="p_del">-		&quot;	.long 29b,4b\n&quot;					\</span>
<span class="p_add">+		&quot;	.long 29b,3b\n&quot;					\</span>
<span class="p_add">+		&quot;	.long 30b,3b\n&quot;					\</span>
<span class="p_add">+		&quot;	.long 31b,3b\n&quot;					\</span>
<span class="p_add">+		&quot;	.long 32b,3b\n&quot;					\</span>
<span class="p_add">+		&quot;	.long 33b,4b\n&quot;					\</span>
 		&quot;	.previous\n&quot;					\
 		: &quot;=r&quot; (to), &quot;=r&quot; (from), &quot;=r&quot; (ret), &quot;=d&quot; (n)		\
 		: &quot;0&quot; (to), &quot;1&quot; (from), &quot;2&quot; (ret), &quot;3&quot; (n)		\
<span class="p_del">-		: &quot;D1Ar1&quot;, &quot;D0Ar2&quot;, &quot;memory&quot;)</span>
<span class="p_add">+		: &quot;D1Ar1&quot;, &quot;D0Ar2&quot;, &quot;cc&quot;, &quot;memory&quot;)</span>
 
 /*	rewind &#39;to&#39; and &#39;from&#39;  pointers when a fault occurs
  *
<span class="p_chunk">@@ -342,7 +349,7 @@</span> <span class="p_context"></span>
 #define __asm_copy_to_user_64bit_rapf_loop(to,	from, ret, n, id)\
 	__asm_copy_user_64bit_rapf_loop(to, from, ret, n, id,		\
 		&quot;LSR	D0Ar2, D0Ar2, #8\n&quot;				\
<span class="p_del">-		&quot;AND	D0Ar2, D0Ar2, #0x7\n&quot;				\</span>
<span class="p_add">+		&quot;ANDS	D0Ar2, D0Ar2, #0x7\n&quot;				\</span>
 		&quot;ADDZ	D0Ar2, D0Ar2, #4\n&quot;				\
 		&quot;SUB	D0Ar2, D0Ar2, #1\n&quot;				\
 		&quot;MOV	D1Ar1, #4\n&quot;					\
<span class="p_chunk">@@ -403,47 +410,55 @@</span> <span class="p_context"></span>
 		&quot;MGETD	D0FrT, D0.5, D0.6, D0.7, [%1++]\n&quot;		\
 		&quot;22:\n&quot;							\
 		&quot;MSETD	[%0++], D0FrT, D0.5, D0.6, D0.7\n&quot;		\
<span class="p_del">-		&quot;SUB	%3, %3, #16\n&quot;					\</span>
 		&quot;23:\n&quot;							\
<span class="p_del">-		&quot;MGETD	D0FrT, D0.5, D0.6, D0.7, [%1++]\n&quot;		\</span>
<span class="p_del">-		&quot;24:\n&quot;							\</span>
<span class="p_del">-		&quot;MSETD	[%0++], D0FrT, D0.5, D0.6, D0.7\n&quot;		\</span>
 		&quot;SUB	%3, %3, #16\n&quot;					\
<span class="p_del">-		&quot;25:\n&quot;							\</span>
<span class="p_add">+		&quot;24:\n&quot;							\</span>
 		&quot;MGETD	D0FrT, D0.5, D0.6, D0.7, [%1++]\n&quot;		\
<span class="p_del">-		&quot;26:\n&quot;							\</span>
<span class="p_add">+		&quot;25:\n&quot;							\</span>
 		&quot;MSETD	[%0++], D0FrT, D0.5, D0.6, D0.7\n&quot;		\
<span class="p_add">+		&quot;26:\n&quot;							\</span>
 		&quot;SUB	%3, %3, #16\n&quot;					\
 		&quot;27:\n&quot;							\
 		&quot;MGETD	D0FrT, D0.5, D0.6, D0.7, [%1++]\n&quot;		\
 		&quot;28:\n&quot;							\
 		&quot;MSETD	[%0++], D0FrT, D0.5, D0.6, D0.7\n&quot;		\
<span class="p_add">+		&quot;29:\n&quot;							\</span>
<span class="p_add">+		&quot;SUB	%3, %3, #16\n&quot;					\</span>
<span class="p_add">+		&quot;30:\n&quot;							\</span>
<span class="p_add">+		&quot;MGETD	D0FrT, D0.5, D0.6, D0.7, [%1++]\n&quot;		\</span>
<span class="p_add">+		&quot;31:\n&quot;							\</span>
<span class="p_add">+		&quot;MSETD	[%0++], D0FrT, D0.5, D0.6, D0.7\n&quot;		\</span>
<span class="p_add">+		&quot;32:\n&quot;							\</span>
 		&quot;SUB	%3, %3, #16\n&quot;					\
 		&quot;DCACHE	[%1+#-64], D0Ar6\n&quot;				\
 		&quot;BR	$Lloop&quot;id&quot;\n&quot;					\
 									\
 		&quot;MOV	RAPF, %1\n&quot;					\
<span class="p_del">-		&quot;29:\n&quot;							\</span>
<span class="p_add">+		&quot;33:\n&quot;							\</span>
 		&quot;MGETD	D0FrT, D0.5, D0.6, D0.7, [%1++]\n&quot;		\
<span class="p_del">-		&quot;30:\n&quot;							\</span>
<span class="p_add">+		&quot;34:\n&quot;							\</span>
 		&quot;MSETD	[%0++], D0FrT, D0.5, D0.6, D0.7\n&quot;		\
<span class="p_add">+		&quot;35:\n&quot;							\</span>
 		&quot;SUB	%3, %3, #16\n&quot;					\
<span class="p_del">-		&quot;31:\n&quot;							\</span>
<span class="p_add">+		&quot;36:\n&quot;							\</span>
 		&quot;MGETD	D0FrT, D0.5, D0.6, D0.7, [%1++]\n&quot;		\
<span class="p_del">-		&quot;32:\n&quot;							\</span>
<span class="p_add">+		&quot;37:\n&quot;							\</span>
 		&quot;MSETD	[%0++], D0FrT, D0.5, D0.6, D0.7\n&quot;		\
<span class="p_add">+		&quot;38:\n&quot;							\</span>
 		&quot;SUB	%3, %3, #16\n&quot;					\
<span class="p_del">-		&quot;33:\n&quot;							\</span>
<span class="p_add">+		&quot;39:\n&quot;							\</span>
 		&quot;MGETD	D0FrT, D0.5, D0.6, D0.7, [%1++]\n&quot;		\
<span class="p_del">-		&quot;34:\n&quot;							\</span>
<span class="p_add">+		&quot;40:\n&quot;							\</span>
 		&quot;MSETD	[%0++], D0FrT, D0.5, D0.6, D0.7\n&quot;		\
<span class="p_add">+		&quot;41:\n&quot;							\</span>
 		&quot;SUB	%3, %3, #16\n&quot;					\
<span class="p_del">-		&quot;35:\n&quot;							\</span>
<span class="p_add">+		&quot;42:\n&quot;							\</span>
 		&quot;MGETD	D0FrT, D0.5, D0.6, D0.7, [%1++]\n&quot;		\
<span class="p_del">-		&quot;36:\n&quot;							\</span>
<span class="p_add">+		&quot;43:\n&quot;							\</span>
 		&quot;MSETD	[%0++], D0FrT, D0.5, D0.6, D0.7\n&quot;		\
<span class="p_add">+		&quot;44:\n&quot;							\</span>
 		&quot;SUB	%0, %0, #4\n&quot;					\
<span class="p_del">-		&quot;37:\n&quot;							\</span>
<span class="p_add">+		&quot;45:\n&quot;							\</span>
 		&quot;SETD	[%0++], D0.7\n&quot;					\
 		&quot;SUB	%3, %3, #16\n&quot;					\
 		&quot;1:&quot;							\
<span class="p_chunk">@@ -483,11 +498,19 @@</span> <span class="p_context"></span>
 		&quot;	.long 34b,3b\n&quot;					\
 		&quot;	.long 35b,3b\n&quot;					\
 		&quot;	.long 36b,3b\n&quot;					\
<span class="p_del">-		&quot;	.long 37b,4b\n&quot;					\</span>
<span class="p_add">+		&quot;	.long 37b,3b\n&quot;					\</span>
<span class="p_add">+		&quot;	.long 38b,3b\n&quot;					\</span>
<span class="p_add">+		&quot;	.long 39b,3b\n&quot;					\</span>
<span class="p_add">+		&quot;	.long 40b,3b\n&quot;					\</span>
<span class="p_add">+		&quot;	.long 41b,3b\n&quot;					\</span>
<span class="p_add">+		&quot;	.long 42b,3b\n&quot;					\</span>
<span class="p_add">+		&quot;	.long 43b,3b\n&quot;					\</span>
<span class="p_add">+		&quot;	.long 44b,3b\n&quot;					\</span>
<span class="p_add">+		&quot;	.long 45b,4b\n&quot;					\</span>
 		&quot;	.previous\n&quot;					\
 		: &quot;=r&quot; (to), &quot;=r&quot; (from), &quot;=r&quot; (ret), &quot;=d&quot; (n)		\
 		: &quot;0&quot; (to), &quot;1&quot; (from), &quot;2&quot; (ret), &quot;3&quot; (n)		\
<span class="p_del">-		: &quot;D1Ar1&quot;, &quot;D0Ar2&quot;, &quot;memory&quot;)</span>
<span class="p_add">+		: &quot;D1Ar1&quot;, &quot;D0Ar2&quot;, &quot;cc&quot;, &quot;memory&quot;)</span>
 
 /*	rewind &#39;to&#39; and &#39;from&#39;  pointers when a fault occurs
  *
<span class="p_chunk">@@ -513,7 +536,7 @@</span> <span class="p_context"></span>
 #define __asm_copy_to_user_32bit_rapf_loop(to, from, ret, n, id)\
 	__asm_copy_user_32bit_rapf_loop(to, from, ret, n, id,		\
 		&quot;LSR	D0Ar2, D0Ar2, #8\n&quot;				\
<span class="p_del">-		&quot;AND	D0Ar2, D0Ar2, #0x7\n&quot;				\</span>
<span class="p_add">+		&quot;ANDS	D0Ar2, D0Ar2, #0x7\n&quot;				\</span>
 		&quot;ADDZ	D0Ar2, D0Ar2, #4\n&quot;				\
 		&quot;SUB	D0Ar2, D0Ar2, #1\n&quot;				\
 		&quot;MOV	D1Ar1, #4\n&quot;					\
<span class="p_chunk">@@ -538,23 +561,31 @@</span> <span class="p_context"> unsigned long __copy_user(void __user *pdst, const void *psrc,</span>
 	if ((unsigned long) src &amp; 1) {
 		__asm_copy_to_user_1(dst, src, retn);
 		n--;
<span class="p_add">+		if (retn)</span>
<span class="p_add">+			return retn + n;</span>
 	}
 	if ((unsigned long) dst &amp; 1) {
 		/* Worst case - byte copy */
 		while (n &gt; 0) {
 			__asm_copy_to_user_1(dst, src, retn);
 			n--;
<span class="p_add">+			if (retn)</span>
<span class="p_add">+				return retn + n;</span>
 		}
 	}
 	if (((unsigned long) src &amp; 2) &amp;&amp; n &gt;= 2) {
 		__asm_copy_to_user_2(dst, src, retn);
 		n -= 2;
<span class="p_add">+		if (retn)</span>
<span class="p_add">+			return retn + n;</span>
 	}
 	if ((unsigned long) dst &amp; 2) {
 		/* Second worst case - word copy */
 		while (n &gt;= 2) {
 			__asm_copy_to_user_2(dst, src, retn);
 			n -= 2;
<span class="p_add">+			if (retn)</span>
<span class="p_add">+				return retn + n;</span>
 		}
 	}
 
<span class="p_chunk">@@ -569,6 +600,8 @@</span> <span class="p_context"> unsigned long __copy_user(void __user *pdst, const void *psrc,</span>
 		while (n &gt;= 8) {
 			__asm_copy_to_user_8x64(dst, src, retn);
 			n -= 8;
<span class="p_add">+			if (retn)</span>
<span class="p_add">+				return retn + n;</span>
 		}
 	}
 	if (n &gt;= RAPF_MIN_BUF_SIZE) {
<span class="p_chunk">@@ -581,6 +614,8 @@</span> <span class="p_context"> unsigned long __copy_user(void __user *pdst, const void *psrc,</span>
 		while (n &gt;= 8) {
 			__asm_copy_to_user_8x64(dst, src, retn);
 			n -= 8;
<span class="p_add">+			if (retn)</span>
<span class="p_add">+				return retn + n;</span>
 		}
 	}
 #endif
<span class="p_chunk">@@ -588,11 +623,15 @@</span> <span class="p_context"> unsigned long __copy_user(void __user *pdst, const void *psrc,</span>
 	while (n &gt;= 16) {
 		__asm_copy_to_user_16(dst, src, retn);
 		n -= 16;
<span class="p_add">+		if (retn)</span>
<span class="p_add">+			return retn + n;</span>
 	}
 
 	while (n &gt;= 4) {
 		__asm_copy_to_user_4(dst, src, retn);
 		n -= 4;
<span class="p_add">+		if (retn)</span>
<span class="p_add">+			return retn + n;</span>
 	}
 
 	switch (n) {
<span class="p_chunk">@@ -609,6 +648,10 @@</span> <span class="p_context"> unsigned long __copy_user(void __user *pdst, const void *psrc,</span>
 		break;
 	}
 
<span class="p_add">+	/*</span>
<span class="p_add">+	 * If we get here, retn correctly reflects the number of failing</span>
<span class="p_add">+	 * bytes.</span>
<span class="p_add">+	 */</span>
 	return retn;
 }
 EXPORT_SYMBOL(__copy_user);
<span class="p_chunk">@@ -617,16 +660,14 @@</span> <span class="p_context"> EXPORT_SYMBOL(__copy_user);</span>
 	__asm_copy_user_cont(to, from, ret,	\
 		&quot;	GETB D1Ar1,[%1++]\n&quot;	\
 		&quot;2:	SETB [%0++],D1Ar1\n&quot;,	\
<span class="p_del">-		&quot;3:	ADD  %2,%2,#1\n&quot;	\</span>
<span class="p_del">-		&quot;	SETB [%0++],D1Ar1\n&quot;,	\</span>
<span class="p_add">+		&quot;3:	ADD  %2,%2,#1\n&quot;,	\</span>
 		&quot;	.long 2b,3b\n&quot;)
 
 #define __asm_copy_from_user_2x_cont(to, from, ret, COPY, FIXUP, TENTRY) \
 	__asm_copy_user_cont(to, from, ret,		\
 		&quot;	GETW D1Ar1,[%1++]\n&quot;		\
 		&quot;2:	SETW [%0++],D1Ar1\n&quot; COPY,	\
<span class="p_del">-		&quot;3:	ADD  %2,%2,#2\n&quot;		\</span>
<span class="p_del">-		&quot;	SETW [%0++],D1Ar1\n&quot; FIXUP,	\</span>
<span class="p_add">+		&quot;3:	ADD  %2,%2,#2\n&quot; FIXUP,		\</span>
 		&quot;	.long 2b,3b\n&quot; TENTRY)
 
 #define __asm_copy_from_user_2(to, from, ret) \
<span class="p_chunk">@@ -636,145 +677,26 @@</span> <span class="p_context"> EXPORT_SYMBOL(__copy_user);</span>
 	__asm_copy_from_user_2x_cont(to, from, ret,	\
 		&quot;	GETB D1Ar1,[%1++]\n&quot;		\
 		&quot;4:	SETB [%0++],D1Ar1\n&quot;,		\
<span class="p_del">-		&quot;5:	ADD  %2,%2,#1\n&quot;		\</span>
<span class="p_del">-		&quot;	SETB [%0++],D1Ar1\n&quot;,		\</span>
<span class="p_add">+		&quot;5:	ADD  %2,%2,#1\n&quot;,		\</span>
 		&quot;	.long 4b,5b\n&quot;)
 
 #define __asm_copy_from_user_4x_cont(to, from, ret, COPY, FIXUP, TENTRY) \
 	__asm_copy_user_cont(to, from, ret,		\
 		&quot;	GETD D1Ar1,[%1++]\n&quot;		\
 		&quot;2:	SETD [%0++],D1Ar1\n&quot; COPY,	\
<span class="p_del">-		&quot;3:	ADD  %2,%2,#4\n&quot;		\</span>
<span class="p_del">-		&quot;	SETD [%0++],D1Ar1\n&quot; FIXUP,	\</span>
<span class="p_add">+		&quot;3:	ADD  %2,%2,#4\n&quot; FIXUP,		\</span>
 		&quot;	.long 2b,3b\n&quot; TENTRY)
 
 #define __asm_copy_from_user_4(to, from, ret) \
 	__asm_copy_from_user_4x_cont(to, from, ret, &quot;&quot;, &quot;&quot;, &quot;&quot;)
 
<span class="p_del">-#define __asm_copy_from_user_5(to, from, ret) \</span>
<span class="p_del">-	__asm_copy_from_user_4x_cont(to, from, ret,	\</span>
<span class="p_del">-		&quot;	GETB D1Ar1,[%1++]\n&quot;		\</span>
<span class="p_del">-		&quot;4:	SETB [%0++],D1Ar1\n&quot;,		\</span>
<span class="p_del">-		&quot;5:	ADD  %2,%2,#1\n&quot;		\</span>
<span class="p_del">-		&quot;	SETB [%0++],D1Ar1\n&quot;,		\</span>
<span class="p_del">-		&quot;	.long 4b,5b\n&quot;)</span>
<span class="p_del">-</span>
<span class="p_del">-#define __asm_copy_from_user_6x_cont(to, from, ret, COPY, FIXUP, TENTRY) \</span>
<span class="p_del">-	__asm_copy_from_user_4x_cont(to, from, ret,	\</span>
<span class="p_del">-		&quot;	GETW D1Ar1,[%1++]\n&quot;		\</span>
<span class="p_del">-		&quot;4:	SETW [%0++],D1Ar1\n&quot; COPY,	\</span>
<span class="p_del">-		&quot;5:	ADD  %2,%2,#2\n&quot;		\</span>
<span class="p_del">-		&quot;	SETW [%0++],D1Ar1\n&quot; FIXUP,	\</span>
<span class="p_del">-		&quot;	.long 4b,5b\n&quot; TENTRY)</span>
<span class="p_del">-</span>
<span class="p_del">-#define __asm_copy_from_user_6(to, from, ret) \</span>
<span class="p_del">-	__asm_copy_from_user_6x_cont(to, from, ret, &quot;&quot;, &quot;&quot;, &quot;&quot;)</span>
<span class="p_del">-</span>
<span class="p_del">-#define __asm_copy_from_user_7(to, from, ret) \</span>
<span class="p_del">-	__asm_copy_from_user_6x_cont(to, from, ret,	\</span>
<span class="p_del">-		&quot;	GETB D1Ar1,[%1++]\n&quot;		\</span>
<span class="p_del">-		&quot;6:	SETB [%0++],D1Ar1\n&quot;,		\</span>
<span class="p_del">-		&quot;7:	ADD  %2,%2,#1\n&quot;		\</span>
<span class="p_del">-		&quot;	SETB [%0++],D1Ar1\n&quot;,		\</span>
<span class="p_del">-		&quot;	.long 6b,7b\n&quot;)</span>
<span class="p_del">-</span>
<span class="p_del">-#define __asm_copy_from_user_8x_cont(to, from, ret, COPY, FIXUP, TENTRY) \</span>
<span class="p_del">-	__asm_copy_from_user_4x_cont(to, from, ret,	\</span>
<span class="p_del">-		&quot;	GETD D1Ar1,[%1++]\n&quot;		\</span>
<span class="p_del">-		&quot;4:	SETD [%0++],D1Ar1\n&quot; COPY,	\</span>
<span class="p_del">-		&quot;5:	ADD  %2,%2,#4\n&quot;			\</span>
<span class="p_del">-		&quot;	SETD [%0++],D1Ar1\n&quot; FIXUP,		\</span>
<span class="p_del">-		&quot;	.long 4b,5b\n&quot; TENTRY)</span>
<span class="p_del">-</span>
<span class="p_del">-#define __asm_copy_from_user_8(to, from, ret) \</span>
<span class="p_del">-	__asm_copy_from_user_8x_cont(to, from, ret, &quot;&quot;, &quot;&quot;, &quot;&quot;)</span>
<span class="p_del">-</span>
<span class="p_del">-#define __asm_copy_from_user_9(to, from, ret) \</span>
<span class="p_del">-	__asm_copy_from_user_8x_cont(to, from, ret,	\</span>
<span class="p_del">-		&quot;	GETB D1Ar1,[%1++]\n&quot;		\</span>
<span class="p_del">-		&quot;6:	SETB [%0++],D1Ar1\n&quot;,		\</span>
<span class="p_del">-		&quot;7:	ADD  %2,%2,#1\n&quot;		\</span>
<span class="p_del">-		&quot;	SETB [%0++],D1Ar1\n&quot;,		\</span>
<span class="p_del">-		&quot;	.long 6b,7b\n&quot;)</span>
<span class="p_del">-</span>
<span class="p_del">-#define __asm_copy_from_user_10x_cont(to, from, ret, COPY, FIXUP, TENTRY) \</span>
<span class="p_del">-	__asm_copy_from_user_8x_cont(to, from, ret,	\</span>
<span class="p_del">-		&quot;	GETW D1Ar1,[%1++]\n&quot;		\</span>
<span class="p_del">-		&quot;6:	SETW [%0++],D1Ar1\n&quot; COPY,	\</span>
<span class="p_del">-		&quot;7:	ADD  %2,%2,#2\n&quot;		\</span>
<span class="p_del">-		&quot;	SETW [%0++],D1Ar1\n&quot; FIXUP,	\</span>
<span class="p_del">-		&quot;	.long 6b,7b\n&quot; TENTRY)</span>
<span class="p_del">-</span>
<span class="p_del">-#define __asm_copy_from_user_10(to, from, ret) \</span>
<span class="p_del">-	__asm_copy_from_user_10x_cont(to, from, ret, &quot;&quot;, &quot;&quot;, &quot;&quot;)</span>
<span class="p_del">-</span>
<span class="p_del">-#define __asm_copy_from_user_11(to, from, ret)		\</span>
<span class="p_del">-	__asm_copy_from_user_10x_cont(to, from, ret,	\</span>
<span class="p_del">-		&quot;	GETB D1Ar1,[%1++]\n&quot;		\</span>
<span class="p_del">-		&quot;8:	SETB [%0++],D1Ar1\n&quot;,		\</span>
<span class="p_del">-		&quot;9:	ADD  %2,%2,#1\n&quot;		\</span>
<span class="p_del">-		&quot;	SETB [%0++],D1Ar1\n&quot;,		\</span>
<span class="p_del">-		&quot;	.long 8b,9b\n&quot;)</span>
<span class="p_del">-</span>
<span class="p_del">-#define __asm_copy_from_user_12x_cont(to, from, ret, COPY, FIXUP, TENTRY) \</span>
<span class="p_del">-	__asm_copy_from_user_8x_cont(to, from, ret,	\</span>
<span class="p_del">-		&quot;	GETD D1Ar1,[%1++]\n&quot;		\</span>
<span class="p_del">-		&quot;6:	SETD [%0++],D1Ar1\n&quot; COPY,	\</span>
<span class="p_del">-		&quot;7:	ADD  %2,%2,#4\n&quot;		\</span>
<span class="p_del">-		&quot;	SETD [%0++],D1Ar1\n&quot; FIXUP,	\</span>
<span class="p_del">-		&quot;	.long 6b,7b\n&quot; TENTRY)</span>
<span class="p_del">-</span>
<span class="p_del">-#define __asm_copy_from_user_12(to, from, ret) \</span>
<span class="p_del">-	__asm_copy_from_user_12x_cont(to, from, ret, &quot;&quot;, &quot;&quot;, &quot;&quot;)</span>
<span class="p_del">-</span>
<span class="p_del">-#define __asm_copy_from_user_13(to, from, ret) \</span>
<span class="p_del">-	__asm_copy_from_user_12x_cont(to, from, ret,	\</span>
<span class="p_del">-		&quot;	GETB D1Ar1,[%1++]\n&quot;		\</span>
<span class="p_del">-		&quot;8:	SETB [%0++],D1Ar1\n&quot;,		\</span>
<span class="p_del">-		&quot;9:	ADD  %2,%2,#1\n&quot;		\</span>
<span class="p_del">-		&quot;	SETB [%0++],D1Ar1\n&quot;,		\</span>
<span class="p_del">-		&quot;	.long 8b,9b\n&quot;)</span>
<span class="p_del">-</span>
<span class="p_del">-#define __asm_copy_from_user_14x_cont(to, from, ret, COPY, FIXUP, TENTRY) \</span>
<span class="p_del">-	__asm_copy_from_user_12x_cont(to, from, ret,	\</span>
<span class="p_del">-		&quot;	GETW D1Ar1,[%1++]\n&quot;		\</span>
<span class="p_del">-		&quot;8:	SETW [%0++],D1Ar1\n&quot; COPY,	\</span>
<span class="p_del">-		&quot;9:	ADD  %2,%2,#2\n&quot;		\</span>
<span class="p_del">-		&quot;	SETW [%0++],D1Ar1\n&quot; FIXUP,	\</span>
<span class="p_del">-		&quot;	.long 8b,9b\n&quot; TENTRY)</span>
<span class="p_del">-</span>
<span class="p_del">-#define __asm_copy_from_user_14(to, from, ret) \</span>
<span class="p_del">-	__asm_copy_from_user_14x_cont(to, from, ret, &quot;&quot;, &quot;&quot;, &quot;&quot;)</span>
<span class="p_del">-</span>
<span class="p_del">-#define __asm_copy_from_user_15(to, from, ret) \</span>
<span class="p_del">-	__asm_copy_from_user_14x_cont(to, from, ret,	\</span>
<span class="p_del">-		&quot;	GETB D1Ar1,[%1++]\n&quot;		\</span>
<span class="p_del">-		&quot;10:	SETB [%0++],D1Ar1\n&quot;,		\</span>
<span class="p_del">-		&quot;11:	ADD  %2,%2,#1\n&quot;		\</span>
<span class="p_del">-		&quot;	SETB [%0++],D1Ar1\n&quot;,		\</span>
<span class="p_del">-		&quot;	.long 10b,11b\n&quot;)</span>
<span class="p_del">-</span>
<span class="p_del">-#define __asm_copy_from_user_16x_cont(to, from, ret, COPY, FIXUP, TENTRY) \</span>
<span class="p_del">-	__asm_copy_from_user_12x_cont(to, from, ret,	\</span>
<span class="p_del">-		&quot;	GETD D1Ar1,[%1++]\n&quot;		\</span>
<span class="p_del">-		&quot;8:	SETD [%0++],D1Ar1\n&quot; COPY,	\</span>
<span class="p_del">-		&quot;9:	ADD  %2,%2,#4\n&quot;		\</span>
<span class="p_del">-		&quot;	SETD [%0++],D1Ar1\n&quot; FIXUP,	\</span>
<span class="p_del">-		&quot;	.long 8b,9b\n&quot; TENTRY)</span>
<span class="p_del">-</span>
<span class="p_del">-#define __asm_copy_from_user_16(to, from, ret) \</span>
<span class="p_del">-	__asm_copy_from_user_16x_cont(to, from, ret, &quot;&quot;, &quot;&quot;, &quot;&quot;)</span>
<span class="p_del">-</span>
 #define __asm_copy_from_user_8x64(to, from, ret) \
 	asm volatile (				\
 		&quot;	GETL D0Ar2,D1Ar1,[%1++]\n&quot;	\
 		&quot;2:	SETL [%0++],D0Ar2,D1Ar1\n&quot;	\
 		&quot;1:\n&quot;					\
 		&quot;	.section .fixup,\&quot;ax\&quot;\n&quot;	\
<span class="p_del">-		&quot;	MOV D1Ar1,#0\n&quot;			\</span>
<span class="p_del">-		&quot;	MOV D0Ar2,#0\n&quot;			\</span>
 		&quot;3:	ADD  %2,%2,#8\n&quot;		\
<span class="p_del">-		&quot;	SETL [%0++],D0Ar2,D1Ar1\n&quot;	\</span>
 		&quot;	MOVT    D0Ar2,#HI(1b)\n&quot;	\
 		&quot;	JUMP    D0Ar2,#LO(1b)\n&quot;	\
 		&quot;	.previous\n&quot;			\
<span class="p_chunk">@@ -789,36 +711,57 @@</span> <span class="p_context"> EXPORT_SYMBOL(__copy_user);</span>
  *
  *	Rationale:
  *		A fault occurs while reading from user buffer, which is the
<span class="p_del">- *		source. Since the fault is at a single address, we only</span>
<span class="p_del">- *		need to rewind by 8 bytes.</span>
<span class="p_add">+ *		source.</span>
  *		Since we don&#39;t write to kernel buffer until we read first,
  *		the kernel buffer is at the right state and needn&#39;t be
<span class="p_del">- *		corrected.</span>
<span class="p_add">+ *		corrected, but the source must be rewound to the beginning of</span>
<span class="p_add">+ *		the block, which is LSM_STEP*8 bytes.</span>
<span class="p_add">+ *		LSM_STEP is bits 10:8 in TXSTATUS which is already read</span>
<span class="p_add">+ *		and stored in D0Ar2</span>
<span class="p_add">+ *</span>
<span class="p_add">+ *		NOTE: If a fault occurs at the last operation in M{G,S}ETL</span>
<span class="p_add">+ *			LSM_STEP will be 0. ie: we do 4 writes in our case, if</span>
<span class="p_add">+ *			a fault happens at the 4th write, LSM_STEP will be 0</span>
<span class="p_add">+ *			instead of 4. The code copes with that.</span>
  */
 #define __asm_copy_from_user_64bit_rapf_loop(to, from, ret, n, id)	\
 	__asm_copy_user_64bit_rapf_loop(to, from, ret, n, id,		\
<span class="p_del">-		&quot;SUB	%1, %1, #8\n&quot;)</span>
<span class="p_add">+		&quot;LSR	D0Ar2, D0Ar2, #5\n&quot;				\</span>
<span class="p_add">+		&quot;ANDS	D0Ar2, D0Ar2, #0x38\n&quot;				\</span>
<span class="p_add">+		&quot;ADDZ	D0Ar2, D0Ar2, #32\n&quot;				\</span>
<span class="p_add">+		&quot;SUB	%1, %1, D0Ar2\n&quot;)</span>
 
 /*	rewind &#39;from&#39; pointer when a fault occurs
  *
  *	Rationale:
  *		A fault occurs while reading from user buffer, which is the
<span class="p_del">- *		source. Since the fault is at a single address, we only</span>
<span class="p_del">- *		need to rewind by 4 bytes.</span>
<span class="p_add">+ *		source.</span>
  *		Since we don&#39;t write to kernel buffer until we read first,
  *		the kernel buffer is at the right state and needn&#39;t be
<span class="p_del">- *		corrected.</span>
<span class="p_add">+ *		corrected, but the source must be rewound to the beginning of</span>
<span class="p_add">+ *		the block, which is LSM_STEP*4 bytes.</span>
<span class="p_add">+ *		LSM_STEP is bits 10:8 in TXSTATUS which is already read</span>
<span class="p_add">+ *		and stored in D0Ar2</span>
<span class="p_add">+ *</span>
<span class="p_add">+ *		NOTE: If a fault occurs at the last operation in M{G,S}ETL</span>
<span class="p_add">+ *			LSM_STEP will be 0. ie: we do 4 writes in our case, if</span>
<span class="p_add">+ *			a fault happens at the 4th write, LSM_STEP will be 0</span>
<span class="p_add">+ *			instead of 4. The code copes with that.</span>
  */
 #define __asm_copy_from_user_32bit_rapf_loop(to, from, ret, n, id)	\
 	__asm_copy_user_32bit_rapf_loop(to, from, ret, n, id,		\
<span class="p_del">-		&quot;SUB	%1, %1, #4\n&quot;)</span>
<span class="p_add">+		&quot;LSR	D0Ar2, D0Ar2, #6\n&quot;				\</span>
<span class="p_add">+		&quot;ANDS	D0Ar2, D0Ar2, #0x1c\n&quot;				\</span>
<span class="p_add">+		&quot;ADDZ	D0Ar2, D0Ar2, #16\n&quot;				\</span>
<span class="p_add">+		&quot;SUB	%1, %1, D0Ar2\n&quot;)</span>
 
 
<span class="p_del">-/* Copy from user to kernel, zeroing the bytes that were inaccessible in</span>
<span class="p_del">-   userland.  The return-value is the number of bytes that were</span>
<span class="p_del">-   inaccessible.  */</span>
<span class="p_del">-unsigned long __copy_user_zeroing(void *pdst, const void __user *psrc,</span>
<span class="p_del">-				  unsigned long n)</span>
<span class="p_add">+/*</span>
<span class="p_add">+ * Copy from user to kernel. The return-value is the number of bytes that were</span>
<span class="p_add">+ * inaccessible.</span>
<span class="p_add">+ */</span>
<span class="p_add">+unsigned long raw_copy_from_user(void *pdst, const void __user *psrc,</span>
<span class="p_add">+				 unsigned long n)</span>
 {
 	register char *dst asm (&quot;A0.2&quot;) = pdst;
 	register const char __user *src asm (&quot;A1.2&quot;) = psrc;
<span class="p_chunk">@@ -830,6 +773,8 @@</span> <span class="p_context"> unsigned long __copy_user_zeroing(void *pdst, const void __user *psrc,</span>
 	if ((unsigned long) src &amp; 1) {
 		__asm_copy_from_user_1(dst, src, retn);
 		n--;
<span class="p_add">+		if (retn)</span>
<span class="p_add">+			return retn + n;</span>
 	}
 	if ((unsigned long) dst &amp; 1) {
 		/* Worst case - byte copy */
<span class="p_chunk">@@ -837,12 +782,14 @@</span> <span class="p_context"> unsigned long __copy_user_zeroing(void *pdst, const void __user *psrc,</span>
 			__asm_copy_from_user_1(dst, src, retn);
 			n--;
 			if (retn)
<span class="p_del">-				goto copy_exception_bytes;</span>
<span class="p_add">+				return retn + n;</span>
 		}
 	}
 	if (((unsigned long) src &amp; 2) &amp;&amp; n &gt;= 2) {
 		__asm_copy_from_user_2(dst, src, retn);
 		n -= 2;
<span class="p_add">+		if (retn)</span>
<span class="p_add">+			return retn + n;</span>
 	}
 	if ((unsigned long) dst &amp; 2) {
 		/* Second worst case - word copy */
<span class="p_chunk">@@ -850,16 +797,10 @@</span> <span class="p_context"> unsigned long __copy_user_zeroing(void *pdst, const void __user *psrc,</span>
 			__asm_copy_from_user_2(dst, src, retn);
 			n -= 2;
 			if (retn)
<span class="p_del">-				goto copy_exception_bytes;</span>
<span class="p_add">+				return retn + n;</span>
 		}
 	}
 
<span class="p_del">-	/* We only need one check after the unalignment-adjustments,</span>
<span class="p_del">-	   because if both adjustments were done, either both or</span>
<span class="p_del">-	   neither reference had an exception.  */</span>
<span class="p_del">-	if (retn != 0)</span>
<span class="p_del">-		goto copy_exception_bytes;</span>
<span class="p_del">-</span>
 #ifdef USE_RAPF
 	/* 64 bit copy loop */
 	if (!(((unsigned long) src | (unsigned long) dst) &amp; 7)) {
<span class="p_chunk">@@ -872,7 +813,7 @@</span> <span class="p_context"> unsigned long __copy_user_zeroing(void *pdst, const void __user *psrc,</span>
 			__asm_copy_from_user_8x64(dst, src, retn);
 			n -= 8;
 			if (retn)
<span class="p_del">-				goto copy_exception_bytes;</span>
<span class="p_add">+				return retn + n;</span>
 		}
 	}
 
<span class="p_chunk">@@ -888,7 +829,7 @@</span> <span class="p_context"> unsigned long __copy_user_zeroing(void *pdst, const void __user *psrc,</span>
 			__asm_copy_from_user_8x64(dst, src, retn);
 			n -= 8;
 			if (retn)
<span class="p_del">-				goto copy_exception_bytes;</span>
<span class="p_add">+				return retn + n;</span>
 		}
 	}
 #endif
<span class="p_chunk">@@ -898,7 +839,7 @@</span> <span class="p_context"> unsigned long __copy_user_zeroing(void *pdst, const void __user *psrc,</span>
 		n -= 4;
 
 		if (retn)
<span class="p_del">-			goto copy_exception_bytes;</span>
<span class="p_add">+			return retn + n;</span>
 	}
 
 	/* If we get here, there were no memory read faults.  */
<span class="p_chunk">@@ -924,21 +865,8 @@</span> <span class="p_context"> unsigned long __copy_user_zeroing(void *pdst, const void __user *psrc,</span>
 	/* If we get here, retn correctly reflects the number of failing
 	   bytes.  */
 	return retn;
<span class="p_del">-</span>
<span class="p_del">- copy_exception_bytes:</span>
<span class="p_del">-	/* We already have &quot;retn&quot; bytes cleared, and need to clear the</span>
<span class="p_del">-	   remaining &quot;n&quot; bytes.  A non-optimized simple byte-for-byte in-line</span>
<span class="p_del">-	   memset is preferred here, since this isn&#39;t speed-critical code and</span>
<span class="p_del">-	   we&#39;d rather have this a leaf-function than calling memset.  */</span>
<span class="p_del">-	{</span>
<span class="p_del">-		char *endp;</span>
<span class="p_del">-		for (endp = dst + n; dst &lt; endp; dst++)</span>
<span class="p_del">-			*dst = 0;</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">-	return retn + n;</span>
 }
<span class="p_del">-EXPORT_SYMBOL(__copy_user_zeroing);</span>
<span class="p_add">+EXPORT_SYMBOL(raw_copy_from_user);</span>
 
 #define __asm_clear_8x64(to, ret) \
 	asm volatile (					\
<span class="p_header">diff --git a/arch/mips/Kconfig b/arch/mips/Kconfig</span>
<span class="p_header">index db459612de44..75bfca69e418 100644</span>
<span class="p_header">--- a/arch/mips/Kconfig</span>
<span class="p_header">+++ b/arch/mips/Kconfig</span>
<span class="p_chunk">@@ -1412,7 +1412,7 @@</span> <span class="p_context"> config CPU_MIPS32_R6</span>
 	select CPU_SUPPORTS_MSA
 	select GENERIC_CSUM
 	select HAVE_KVM
<span class="p_del">-	select MIPS_O32_FP64_SUPPORT</span>
<span class="p_add">+	select MIPS_O32_FP64_SUPPORT if 32BIT</span>
 	help
 	  Choose this option to build a kernel for release 6 or later of the
 	  MIPS32 architecture.  New MIPS processors, starting with the Warrior
<span class="p_header">diff --git a/arch/mips/include/asm/spinlock.h b/arch/mips/include/asm/spinlock.h</span>
<span class="p_header">index 40196bebe849..2365ce0ad8f2 100644</span>
<span class="p_header">--- a/arch/mips/include/asm/spinlock.h</span>
<span class="p_header">+++ b/arch/mips/include/asm/spinlock.h</span>
<span class="p_chunk">@@ -112,7 +112,7 @@</span> <span class="p_context"> static inline void arch_spin_lock(arch_spinlock_t *lock)</span>
 		&quot;	andi	%[ticket], %[ticket], 0xffff		\n&quot;
 		&quot;	bne	%[ticket], %[my_ticket], 4f		\n&quot;
 		&quot;	 subu	%[ticket], %[my_ticket], %[ticket]	\n&quot;
<span class="p_del">-		&quot;2:							\n&quot;</span>
<span class="p_add">+		&quot;2:	.insn						\n&quot;</span>
 		&quot;	.subsection 2					\n&quot;
 		&quot;4:	andi	%[ticket], %[ticket], 0xffff		\n&quot;
 		&quot;	sll	%[ticket], 5				\n&quot;
<span class="p_chunk">@@ -187,7 +187,7 @@</span> <span class="p_context"> static inline unsigned int arch_spin_trylock(arch_spinlock_t *lock)</span>
 		&quot;	sc	%[ticket], %[ticket_ptr]		\n&quot;
 		&quot;	beqz	%[ticket], 1b				\n&quot;
 		&quot;	 li	%[ticket], 1				\n&quot;
<span class="p_del">-		&quot;2:							\n&quot;</span>
<span class="p_add">+		&quot;2:	.insn						\n&quot;</span>
 		&quot;	.subsection 2					\n&quot;
 		&quot;3:	b	2b					\n&quot;
 		&quot;	 li	%[ticket], 0				\n&quot;
<span class="p_chunk">@@ -367,7 +367,7 @@</span> <span class="p_context"> static inline int arch_read_trylock(arch_rwlock_t *rw)</span>
 		&quot;	.set	reorder					\n&quot;
 		__WEAK_LLSC_MB
 		&quot;	li	%2, 1					\n&quot;
<span class="p_del">-		&quot;2:							\n&quot;</span>
<span class="p_add">+		&quot;2:	.insn						\n&quot;</span>
 		: &quot;=&quot; GCC_OFF_SMALL_ASM() (rw-&gt;lock), &quot;=&amp;r&quot; (tmp), &quot;=&amp;r&quot; (ret)
 		: GCC_OFF_SMALL_ASM() (rw-&gt;lock)
 		: &quot;memory&quot;);
<span class="p_chunk">@@ -407,7 +407,7 @@</span> <span class="p_context"> static inline int arch_write_trylock(arch_rwlock_t *rw)</span>
 			&quot;	lui	%1, 0x8000			\n&quot;
 			&quot;	sc	%1, %0				\n&quot;
 			&quot;	li	%2, 1				\n&quot;
<span class="p_del">-			&quot;2:						\n&quot;</span>
<span class="p_add">+			&quot;2:	.insn					\n&quot;</span>
 			: &quot;=&quot; GCC_OFF_SMALL_ASM() (rw-&gt;lock), &quot;=&amp;r&quot; (tmp),
 			  &quot;=&amp;r&quot; (ret)
 			: GCC_OFF_SMALL_ASM() (rw-&gt;lock)
<span class="p_header">diff --git a/arch/mips/lantiq/xway/sysctrl.c b/arch/mips/lantiq/xway/sysctrl.c</span>
<span class="p_header">index 3e390a4e3897..daf580ce5ca2 100644</span>
<span class="p_header">--- a/arch/mips/lantiq/xway/sysctrl.c</span>
<span class="p_header">+++ b/arch/mips/lantiq/xway/sysctrl.c</span>
<span class="p_chunk">@@ -467,7 +467,7 @@</span> <span class="p_context"> void __init ltq_soc_init(void)</span>
 
 		if (!np_xbar)
 			panic(&quot;Failed to load xbar nodes from devicetree&quot;);
<span class="p_del">-		if (of_address_to_resource(np_pmu, 0, &amp;res_xbar))</span>
<span class="p_add">+		if (of_address_to_resource(np_xbar, 0, &amp;res_xbar))</span>
 			panic(&quot;Failed to get xbar resources&quot;);
 		if (request_mem_region(res_xbar.start, resource_size(&amp;res_xbar),
 			res_xbar.name) &lt; 0)
<span class="p_header">diff --git a/arch/mips/mm/tlbex.c b/arch/mips/mm/tlbex.c</span>
<span class="p_header">index 29f73e00253d..63b7d6f82d24 100644</span>
<span class="p_header">--- a/arch/mips/mm/tlbex.c</span>
<span class="p_header">+++ b/arch/mips/mm/tlbex.c</span>
<span class="p_chunk">@@ -757,7 +757,8 @@</span> <span class="p_context"> static void build_huge_update_entries(u32 **p, unsigned int pte,</span>
 static void build_huge_handler_tail(u32 **p, struct uasm_reloc **r,
 				    struct uasm_label **l,
 				    unsigned int pte,
<span class="p_del">-				    unsigned int ptr)</span>
<span class="p_add">+				    unsigned int ptr,</span>
<span class="p_add">+				    unsigned int flush)</span>
 {
 #ifdef CONFIG_SMP
 	UASM_i_SC(p, pte, 0, ptr);
<span class="p_chunk">@@ -766,6 +767,22 @@</span> <span class="p_context"> static void build_huge_handler_tail(u32 **p, struct uasm_reloc **r,</span>
 #else
 	UASM_i_SW(p, pte, 0, ptr);
 #endif
<span class="p_add">+	if (cpu_has_ftlb &amp;&amp; flush) {</span>
<span class="p_add">+		BUG_ON(!cpu_has_tlbinv);</span>
<span class="p_add">+</span>
<span class="p_add">+		UASM_i_MFC0(p, ptr, C0_ENTRYHI);</span>
<span class="p_add">+		uasm_i_ori(p, ptr, ptr, MIPS_ENTRYHI_EHINV);</span>
<span class="p_add">+		UASM_i_MTC0(p, ptr, C0_ENTRYHI);</span>
<span class="p_add">+		build_tlb_write_entry(p, l, r, tlb_indexed);</span>
<span class="p_add">+</span>
<span class="p_add">+		uasm_i_xori(p, ptr, ptr, MIPS_ENTRYHI_EHINV);</span>
<span class="p_add">+		UASM_i_MTC0(p, ptr, C0_ENTRYHI);</span>
<span class="p_add">+		build_huge_update_entries(p, pte, ptr);</span>
<span class="p_add">+		build_huge_tlb_write_entry(p, l, r, pte, tlb_random, 0);</span>
<span class="p_add">+</span>
<span class="p_add">+		return;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
 	build_huge_update_entries(p, pte, ptr);
 	build_huge_tlb_write_entry(p, l, r, pte, tlb_indexed, 0);
 }
<span class="p_chunk">@@ -2082,7 +2099,7 @@</span> <span class="p_context"> static void build_r4000_tlb_load_handler(void)</span>
 		uasm_l_tlbl_goaround2(&amp;l, p);
 	}
 	uasm_i_ori(&amp;p, wr.r1, wr.r1, (_PAGE_ACCESSED | _PAGE_VALID));
<span class="p_del">-	build_huge_handler_tail(&amp;p, &amp;r, &amp;l, wr.r1, wr.r2);</span>
<span class="p_add">+	build_huge_handler_tail(&amp;p, &amp;r, &amp;l, wr.r1, wr.r2, 1);</span>
 #endif
 
 	uasm_l_nopage_tlbl(&amp;l, p);
<span class="p_chunk">@@ -2137,7 +2154,7 @@</span> <span class="p_context"> static void build_r4000_tlb_store_handler(void)</span>
 	build_tlb_probe_entry(&amp;p);
 	uasm_i_ori(&amp;p, wr.r1, wr.r1,
 		   _PAGE_ACCESSED | _PAGE_MODIFIED | _PAGE_VALID | _PAGE_DIRTY);
<span class="p_del">-	build_huge_handler_tail(&amp;p, &amp;r, &amp;l, wr.r1, wr.r2);</span>
<span class="p_add">+	build_huge_handler_tail(&amp;p, &amp;r, &amp;l, wr.r1, wr.r2, 1);</span>
 #endif
 
 	uasm_l_nopage_tlbs(&amp;l, p);
<span class="p_chunk">@@ -2193,7 +2210,7 @@</span> <span class="p_context"> static void build_r4000_tlb_modify_handler(void)</span>
 	build_tlb_probe_entry(&amp;p);
 	uasm_i_ori(&amp;p, wr.r1, wr.r1,
 		   _PAGE_ACCESSED | _PAGE_MODIFIED | _PAGE_VALID | _PAGE_DIRTY);
<span class="p_del">-	build_huge_handler_tail(&amp;p, &amp;r, &amp;l, wr.r1, wr.r2);</span>
<span class="p_add">+	build_huge_handler_tail(&amp;p, &amp;r, &amp;l, wr.r1, wr.r2, 0);</span>
 #endif
 
 	uasm_l_nopage_tlbm(&amp;l, p);
<span class="p_header">diff --git a/arch/mips/ralink/rt3883.c b/arch/mips/ralink/rt3883.c</span>
<span class="p_header">index f42834c7f007..3c575093f8f1 100644</span>
<span class="p_header">--- a/arch/mips/ralink/rt3883.c</span>
<span class="p_header">+++ b/arch/mips/ralink/rt3883.c</span>
<span class="p_chunk">@@ -36,7 +36,7 @@</span> <span class="p_context"> static struct rt2880_pmx_func uartlite_func[] = { FUNC(&quot;uartlite&quot;, 0, 15, 2) };</span>
 static struct rt2880_pmx_func jtag_func[] = { FUNC(&quot;jtag&quot;, 0, 17, 5) };
 static struct rt2880_pmx_func mdio_func[] = { FUNC(&quot;mdio&quot;, 0, 22, 2) };
 static struct rt2880_pmx_func lna_a_func[] = { FUNC(&quot;lna a&quot;, 0, 32, 3) };
<span class="p_del">-static struct rt2880_pmx_func lna_g_func[] = { FUNC(&quot;lna a&quot;, 0, 35, 3) };</span>
<span class="p_add">+static struct rt2880_pmx_func lna_g_func[] = { FUNC(&quot;lna g&quot;, 0, 35, 3) };</span>
 static struct rt2880_pmx_func pci_func[] = {
 	FUNC(&quot;pci-dev&quot;, 0, 40, 32),
 	FUNC(&quot;pci-host2&quot;, 1, 40, 32),
<span class="p_chunk">@@ -44,7 +44,7 @@</span> <span class="p_context"> static struct rt2880_pmx_func pci_func[] = {</span>
 	FUNC(&quot;pci-fnc&quot;, 3, 40, 32)
 };
 static struct rt2880_pmx_func ge1_func[] = { FUNC(&quot;ge1&quot;, 0, 72, 12) };
<span class="p_del">-static struct rt2880_pmx_func ge2_func[] = { FUNC(&quot;ge1&quot;, 0, 84, 12) };</span>
<span class="p_add">+static struct rt2880_pmx_func ge2_func[] = { FUNC(&quot;ge2&quot;, 0, 84, 12) };</span>
 
 static struct rt2880_pmx_group rt3883_pinmux_data[] = {
 	GRP(&quot;i2c&quot;, i2c_func, 1, RT3883_GPIO_MODE_I2C),
<span class="p_header">diff --git a/arch/nios2/kernel/prom.c b/arch/nios2/kernel/prom.c</span>
<span class="p_header">index 718dd197909f..de73beb36910 100644</span>
<span class="p_header">--- a/arch/nios2/kernel/prom.c</span>
<span class="p_header">+++ b/arch/nios2/kernel/prom.c</span>
<span class="p_chunk">@@ -48,6 +48,13 @@</span> <span class="p_context"> void * __init early_init_dt_alloc_memory_arch(u64 size, u64 align)</span>
 	return alloc_bootmem_align(size, align);
 }
 
<span class="p_add">+int __init early_init_dt_reserve_memory_arch(phys_addr_t base, phys_addr_t size,</span>
<span class="p_add">+					     bool nomap)</span>
<span class="p_add">+{</span>
<span class="p_add">+	reserve_bootmem(base, size, BOOTMEM_DEFAULT);</span>
<span class="p_add">+	return 0;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 void __init early_init_devtree(void *params)
 {
 	__be32 *dtb = (u32 *)__dtb_start;
<span class="p_header">diff --git a/arch/nios2/kernel/setup.c b/arch/nios2/kernel/setup.c</span>
<span class="p_header">index a4ff86d58d5c..6c4e351a7930 100644</span>
<span class="p_header">--- a/arch/nios2/kernel/setup.c</span>
<span class="p_header">+++ b/arch/nios2/kernel/setup.c</span>
<span class="p_chunk">@@ -195,6 +195,9 @@</span> <span class="p_context"> void __init setup_arch(char **cmdline_p)</span>
 	}
 #endif /* CONFIG_BLK_DEV_INITRD */
 
<span class="p_add">+	early_init_fdt_reserve_self();</span>
<span class="p_add">+	early_init_fdt_scan_reserved_mem();</span>
<span class="p_add">+</span>
 	unflatten_and_copy_device_tree();
 
 	setup_cpuinfo();
<span class="p_header">diff --git a/arch/powerpc/kernel/align.c b/arch/powerpc/kernel/align.c</span>
<span class="p_header">index 86150fbb42c3..91e5c1758b5c 100644</span>
<span class="p_header">--- a/arch/powerpc/kernel/align.c</span>
<span class="p_header">+++ b/arch/powerpc/kernel/align.c</span>
<span class="p_chunk">@@ -808,14 +808,25 @@</span> <span class="p_context"> int fix_alignment(struct pt_regs *regs)</span>
 	nb = aligninfo[instr].len;
 	flags = aligninfo[instr].flags;
 
<span class="p_del">-	/* ldbrx/stdbrx overlap lfs/stfs in the DSISR unfortunately */</span>
<span class="p_del">-	if (IS_XFORM(instruction) &amp;&amp; ((instruction &gt;&gt; 1) &amp; 0x3ff) == 532) {</span>
<span class="p_del">-		nb = 8;</span>
<span class="p_del">-		flags = LD+SW;</span>
<span class="p_del">-	} else if (IS_XFORM(instruction) &amp;&amp;</span>
<span class="p_del">-		   ((instruction &gt;&gt; 1) &amp; 0x3ff) == 660) {</span>
<span class="p_del">-		nb = 8;</span>
<span class="p_del">-		flags = ST+SW;</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Handle some cases which give overlaps in the DSISR values.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	if (IS_XFORM(instruction)) {</span>
<span class="p_add">+		switch (get_xop(instruction)) {</span>
<span class="p_add">+		case 532:	/* ldbrx */</span>
<span class="p_add">+			nb = 8;</span>
<span class="p_add">+			flags = LD+SW;</span>
<span class="p_add">+			break;</span>
<span class="p_add">+		case 660:	/* stdbrx */</span>
<span class="p_add">+			nb = 8;</span>
<span class="p_add">+			flags = ST+SW;</span>
<span class="p_add">+			break;</span>
<span class="p_add">+		case 20:	/* lwarx */</span>
<span class="p_add">+		case 84:	/* ldarx */</span>
<span class="p_add">+		case 116:	/* lharx */</span>
<span class="p_add">+		case 276:	/* lqarx */</span>
<span class="p_add">+			return 0;	/* not emulated ever */</span>
<span class="p_add">+		}</span>
 	}
 
 	/* Byteswap little endian loads and stores */
<span class="p_header">diff --git a/arch/powerpc/mm/hash_native_64.c b/arch/powerpc/mm/hash_native_64.c</span>
<span class="p_header">index c8822af10a58..19d9b2d2d212 100644</span>
<span class="p_header">--- a/arch/powerpc/mm/hash_native_64.c</span>
<span class="p_header">+++ b/arch/powerpc/mm/hash_native_64.c</span>
<span class="p_chunk">@@ -645,6 +645,10 @@</span> <span class="p_context"> static void native_flush_hash_range(unsigned long number, int local)</span>
 	unsigned long psize = batch-&gt;psize;
 	int ssize = batch-&gt;ssize;
 	int i;
<span class="p_add">+	unsigned int use_local;</span>
<span class="p_add">+</span>
<span class="p_add">+	use_local = local &amp;&amp; mmu_has_feature(MMU_FTR_TLBIEL) &amp;&amp;</span>
<span class="p_add">+		mmu_psize_defs[psize].tlbiel &amp;&amp; !cxl_ctx_in_use();</span>
 
 	local_irq_save(flags);
 
<span class="p_chunk">@@ -671,8 +675,7 @@</span> <span class="p_context"> static void native_flush_hash_range(unsigned long number, int local)</span>
 		} pte_iterate_hashed_end();
 	}
 
<span class="p_del">-	if (mmu_has_feature(MMU_FTR_TLBIEL) &amp;&amp;</span>
<span class="p_del">-	    mmu_psize_defs[psize].tlbiel &amp;&amp; local) {</span>
<span class="p_add">+	if (use_local) {</span>
 		asm volatile(&quot;ptesync&quot;:::&quot;memory&quot;);
 		for (i = 0; i &lt; number; i++) {
 			vpn = batch-&gt;vpn[i];
<span class="p_header">diff --git a/arch/s390/boot/compressed/misc.c b/arch/s390/boot/compressed/misc.c</span>
<span class="p_header">index 4da604ebf6fd..ca15613eaaa4 100644</span>
<span class="p_header">--- a/arch/s390/boot/compressed/misc.c</span>
<span class="p_header">+++ b/arch/s390/boot/compressed/misc.c</span>
<span class="p_chunk">@@ -141,31 +141,34 @@</span> <span class="p_context"> static void check_ipl_parmblock(void *start, unsigned long size)</span>
 
 unsigned long decompress_kernel(void)
 {
<span class="p_del">-	unsigned long output_addr;</span>
<span class="p_del">-	unsigned char *output;</span>
<span class="p_add">+	void *output, *kernel_end;</span>
 
<span class="p_del">-	output_addr = ((unsigned long) &amp;_end + HEAP_SIZE + 4095UL) &amp; -4096UL;</span>
<span class="p_del">-	check_ipl_parmblock((void *) 0, output_addr + SZ__bss_start);</span>
<span class="p_del">-	memset(&amp;_bss, 0, &amp;_ebss - &amp;_bss);</span>
<span class="p_del">-	free_mem_ptr = (unsigned long)&amp;_end;</span>
<span class="p_del">-	free_mem_end_ptr = free_mem_ptr + HEAP_SIZE;</span>
<span class="p_del">-	output = (unsigned char *) output_addr;</span>
<span class="p_add">+	output = (void *) ALIGN((unsigned long) &amp;_end + HEAP_SIZE, PAGE_SIZE);</span>
<span class="p_add">+	kernel_end = output + SZ__bss_start;</span>
<span class="p_add">+	check_ipl_parmblock((void *) 0, (unsigned long) kernel_end);</span>
 
 #ifdef CONFIG_BLK_DEV_INITRD
 	/*
 	 * Move the initrd right behind the end of the decompressed
<span class="p_del">-	 * kernel image.</span>
<span class="p_add">+	 * kernel image. This also prevents initrd corruption caused by</span>
<span class="p_add">+	 * bss clearing since kernel_end will always be located behind the</span>
<span class="p_add">+	 * current bss section..</span>
 	 */
<span class="p_del">-	if (INITRD_START &amp;&amp; INITRD_SIZE &amp;&amp;</span>
<span class="p_del">-	    INITRD_START &lt; (unsigned long) output + SZ__bss_start) {</span>
<span class="p_del">-		check_ipl_parmblock(output + SZ__bss_start,</span>
<span class="p_del">-				    INITRD_START + INITRD_SIZE);</span>
<span class="p_del">-		memmove(output + SZ__bss_start,</span>
<span class="p_del">-			(void *) INITRD_START, INITRD_SIZE);</span>
<span class="p_del">-		INITRD_START = (unsigned long) output + SZ__bss_start;</span>
<span class="p_add">+	if (INITRD_START &amp;&amp; INITRD_SIZE &amp;&amp; kernel_end &gt; (void *) INITRD_START) {</span>
<span class="p_add">+		check_ipl_parmblock(kernel_end, INITRD_SIZE);</span>
<span class="p_add">+		memmove(kernel_end, (void *) INITRD_START, INITRD_SIZE);</span>
<span class="p_add">+		INITRD_START = (unsigned long) kernel_end;</span>
 	}
 #endif
 
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Clear bss section. free_mem_ptr and free_mem_end_ptr need to be</span>
<span class="p_add">+	 * initialized afterwards since they reside in bss.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	memset(&amp;_bss, 0, &amp;_ebss - &amp;_bss);</span>
<span class="p_add">+	free_mem_ptr = (unsigned long) &amp;_end;</span>
<span class="p_add">+	free_mem_end_ptr = free_mem_ptr + HEAP_SIZE;</span>
<span class="p_add">+</span>
 	puts(&quot;Uncompressing Linux... &quot;);
 	__decompress(input_data, input_len, NULL, NULL, output, 0, NULL, error);
 	puts(&quot;Ok, booting the kernel.\n&quot;);
<span class="p_header">diff --git a/arch/s390/include/asm/uaccess.h b/arch/s390/include/asm/uaccess.h</span>
<span class="p_header">index 5c7381c5ad7f..c8d837f0fbbc 100644</span>
<span class="p_header">--- a/arch/s390/include/asm/uaccess.h</span>
<span class="p_header">+++ b/arch/s390/include/asm/uaccess.h</span>
<span class="p_chunk">@@ -150,7 +150,7 @@</span> <span class="p_context"> unsigned long __must_check __copy_to_user(void __user *to, const void *from,</span>
 		&quot;	jg	2b\n&quot;				\
 		&quot;.popsection\n&quot;					\
 		EX_TABLE(0b,3b) EX_TABLE(1b,3b)			\
<span class="p_del">-		: &quot;=d&quot; (__rc), &quot;=Q&quot; (*(to))			\</span>
<span class="p_add">+		: &quot;=d&quot; (__rc), &quot;+Q&quot; (*(to))			\</span>
 		: &quot;d&quot; (size), &quot;Q&quot; (*(from)),			\
 		  &quot;d&quot; (__reg0), &quot;K&quot; (-EFAULT)			\
 		: &quot;cc&quot;);					\
<span class="p_header">diff --git a/drivers/gpu/drm/ttm/ttm_object.c b/drivers/gpu/drm/ttm/ttm_object.c</span>
<span class="p_header">index 4f5fa8d65fe9..144367c0c28f 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/ttm/ttm_object.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/ttm/ttm_object.c</span>
<span class="p_chunk">@@ -179,7 +179,7 @@</span> <span class="p_context"> int ttm_base_object_init(struct ttm_object_file *tfile,</span>
 	if (unlikely(ret != 0))
 		goto out_err0;
 
<span class="p_del">-	ret = ttm_ref_object_add(tfile, base, TTM_REF_USAGE, NULL);</span>
<span class="p_add">+	ret = ttm_ref_object_add(tfile, base, TTM_REF_USAGE, NULL, false);</span>
 	if (unlikely(ret != 0))
 		goto out_err1;
 
<span class="p_chunk">@@ -318,7 +318,8 @@</span> <span class="p_context"> EXPORT_SYMBOL(ttm_ref_object_exists);</span>
 
 int ttm_ref_object_add(struct ttm_object_file *tfile,
 		       struct ttm_base_object *base,
<span class="p_del">-		       enum ttm_ref_type ref_type, bool *existed)</span>
<span class="p_add">+		       enum ttm_ref_type ref_type, bool *existed,</span>
<span class="p_add">+		       bool require_existed)</span>
 {
 	struct drm_open_hash *ht = &amp;tfile-&gt;ref_hash[ref_type];
 	struct ttm_ref_object *ref;
<span class="p_chunk">@@ -345,6 +346,9 @@</span> <span class="p_context"> int ttm_ref_object_add(struct ttm_object_file *tfile,</span>
 		}
 
 		rcu_read_unlock();
<span class="p_add">+		if (require_existed)</span>
<span class="p_add">+			return -EPERM;</span>
<span class="p_add">+</span>
 		ret = ttm_mem_global_alloc(mem_glob, sizeof(*ref),
 					   false, false);
 		if (unlikely(ret != 0))
<span class="p_chunk">@@ -635,7 +639,7 @@</span> <span class="p_context"> int ttm_prime_fd_to_handle(struct ttm_object_file *tfile,</span>
 	prime = (struct ttm_prime_object *) dma_buf-&gt;priv;
 	base = &amp;prime-&gt;base;
 	*handle = base-&gt;hash.key;
<span class="p_del">-	ret = ttm_ref_object_add(tfile, base, TTM_REF_USAGE, NULL);</span>
<span class="p_add">+	ret = ttm_ref_object_add(tfile, base, TTM_REF_USAGE, NULL, false);</span>
 
 	dma_buf_put(dma_buf);
 
<span class="p_header">diff --git a/drivers/gpu/drm/vmwgfx/vmwgfx_fence.c b/drivers/gpu/drm/vmwgfx/vmwgfx_fence.c</span>
<span class="p_header">index 8e689b439890..6c649f7b5929 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/vmwgfx/vmwgfx_fence.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/vmwgfx/vmwgfx_fence.c</span>
<span class="p_chunk">@@ -539,7 +539,7 @@</span> <span class="p_context"> int vmw_fence_create(struct vmw_fence_manager *fman,</span>
 		     struct vmw_fence_obj **p_fence)
 {
 	struct vmw_fence_obj *fence;
<span class="p_del">-	int ret;</span>
<span class="p_add">+ 	int ret;</span>
 
 	fence = kzalloc(sizeof(*fence), GFP_KERNEL);
 	if (unlikely(fence == NULL))
<span class="p_chunk">@@ -702,6 +702,41 @@</span> <span class="p_context"> void vmw_fence_fifo_up(struct vmw_fence_manager *fman)</span>
 }
 
 
<span class="p_add">+/**</span>
<span class="p_add">+ * vmw_fence_obj_lookup - Look up a user-space fence object</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * @tfile: A struct ttm_object_file identifying the caller.</span>
<span class="p_add">+ * @handle: A handle identifying the fence object.</span>
<span class="p_add">+ * @return: A struct vmw_user_fence base ttm object on success or</span>
<span class="p_add">+ * an error pointer on failure.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * The fence object is looked up and type-checked. The caller needs</span>
<span class="p_add">+ * to have opened the fence object first, but since that happens on</span>
<span class="p_add">+ * creation and fence objects aren&#39;t shareable, that&#39;s not an</span>
<span class="p_add">+ * issue currently.</span>
<span class="p_add">+ */</span>
<span class="p_add">+static struct ttm_base_object *</span>
<span class="p_add">+vmw_fence_obj_lookup(struct ttm_object_file *tfile, u32 handle)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct ttm_base_object *base = ttm_base_object_lookup(tfile, handle);</span>
<span class="p_add">+</span>
<span class="p_add">+	if (!base) {</span>
<span class="p_add">+		pr_err(&quot;Invalid fence object handle 0x%08lx.\n&quot;,</span>
<span class="p_add">+		       (unsigned long)handle);</span>
<span class="p_add">+		return ERR_PTR(-EINVAL);</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	if (base-&gt;refcount_release != vmw_user_fence_base_release) {</span>
<span class="p_add">+		pr_err(&quot;Invalid fence object handle 0x%08lx.\n&quot;,</span>
<span class="p_add">+		       (unsigned long)handle);</span>
<span class="p_add">+		ttm_base_object_unref(&amp;base);</span>
<span class="p_add">+		return ERR_PTR(-EINVAL);</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	return base;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+</span>
 int vmw_fence_obj_wait_ioctl(struct drm_device *dev, void *data,
 			     struct drm_file *file_priv)
 {
<span class="p_chunk">@@ -727,13 +762,9 @@</span> <span class="p_context"> int vmw_fence_obj_wait_ioctl(struct drm_device *dev, void *data,</span>
 		arg-&gt;kernel_cookie = jiffies + wait_timeout;
 	}
 
<span class="p_del">-	base = ttm_base_object_lookup(tfile, arg-&gt;handle);</span>
<span class="p_del">-	if (unlikely(base == NULL)) {</span>
<span class="p_del">-		printk(KERN_ERR &quot;Wait invalid fence object handle &quot;</span>
<span class="p_del">-		       &quot;0x%08lx.\n&quot;,</span>
<span class="p_del">-		       (unsigned long)arg-&gt;handle);</span>
<span class="p_del">-		return -EINVAL;</span>
<span class="p_del">-	}</span>
<span class="p_add">+	base = vmw_fence_obj_lookup(tfile, arg-&gt;handle);</span>
<span class="p_add">+	if (IS_ERR(base))</span>
<span class="p_add">+		return PTR_ERR(base);</span>
 
 	fence = &amp;(container_of(base, struct vmw_user_fence, base)-&gt;fence);
 
<span class="p_chunk">@@ -772,13 +803,9 @@</span> <span class="p_context"> int vmw_fence_obj_signaled_ioctl(struct drm_device *dev, void *data,</span>
 	struct ttm_object_file *tfile = vmw_fpriv(file_priv)-&gt;tfile;
 	struct vmw_private *dev_priv = vmw_priv(dev);
 
<span class="p_del">-	base = ttm_base_object_lookup(tfile, arg-&gt;handle);</span>
<span class="p_del">-	if (unlikely(base == NULL)) {</span>
<span class="p_del">-		printk(KERN_ERR &quot;Fence signaled invalid fence object handle &quot;</span>
<span class="p_del">-		       &quot;0x%08lx.\n&quot;,</span>
<span class="p_del">-		       (unsigned long)arg-&gt;handle);</span>
<span class="p_del">-		return -EINVAL;</span>
<span class="p_del">-	}</span>
<span class="p_add">+	base = vmw_fence_obj_lookup(tfile, arg-&gt;handle);</span>
<span class="p_add">+	if (IS_ERR(base))</span>
<span class="p_add">+		return PTR_ERR(base);</span>
 
 	fence = &amp;(container_of(base, struct vmw_user_fence, base)-&gt;fence);
 	fman = fman_from_fence(fence);
<span class="p_chunk">@@ -1093,6 +1120,7 @@</span> <span class="p_context"> int vmw_fence_event_ioctl(struct drm_device *dev, void *data,</span>
 		(struct drm_vmw_fence_event_arg *) data;
 	struct vmw_fence_obj *fence = NULL;
 	struct vmw_fpriv *vmw_fp = vmw_fpriv(file_priv);
<span class="p_add">+	struct ttm_object_file *tfile = vmw_fp-&gt;tfile;</span>
 	struct drm_vmw_fence_rep __user *user_fence_rep =
 		(struct drm_vmw_fence_rep __user *)(unsigned long)
 		arg-&gt;fence_rep;
<span class="p_chunk">@@ -1106,24 +1134,18 @@</span> <span class="p_context"> int vmw_fence_event_ioctl(struct drm_device *dev, void *data,</span>
 	 */
 	if (arg-&gt;handle) {
 		struct ttm_base_object *base =
<span class="p_del">-			ttm_base_object_lookup_for_ref(dev_priv-&gt;tdev,</span>
<span class="p_del">-						       arg-&gt;handle);</span>
<span class="p_del">-</span>
<span class="p_del">-		if (unlikely(base == NULL)) {</span>
<span class="p_del">-			DRM_ERROR(&quot;Fence event invalid fence object handle &quot;</span>
<span class="p_del">-				  &quot;0x%08lx.\n&quot;,</span>
<span class="p_del">-				  (unsigned long)arg-&gt;handle);</span>
<span class="p_del">-			return -EINVAL;</span>
<span class="p_del">-		}</span>
<span class="p_add">+			vmw_fence_obj_lookup(tfile, arg-&gt;handle);</span>
<span class="p_add">+</span>
<span class="p_add">+		if (IS_ERR(base))</span>
<span class="p_add">+			return PTR_ERR(base);</span>
<span class="p_add">+</span>
 		fence = &amp;(container_of(base, struct vmw_user_fence,
 				       base)-&gt;fence);
 		(void) vmw_fence_obj_reference(fence);
 
 		if (user_fence_rep != NULL) {
<span class="p_del">-			bool existed;</span>
<span class="p_del">-</span>
 			ret = ttm_ref_object_add(vmw_fp-&gt;tfile, base,
<span class="p_del">-						 TTM_REF_USAGE, &amp;existed);</span>
<span class="p_add">+						 TTM_REF_USAGE, NULL, false);</span>
 			if (unlikely(ret != 0)) {
 				DRM_ERROR(&quot;Failed to reference a fence &quot;
 					  &quot;object.\n&quot;);
<span class="p_chunk">@@ -1166,8 +1188,7 @@</span> <span class="p_context"> int vmw_fence_event_ioctl(struct drm_device *dev, void *data,</span>
 	return 0;
 out_no_create:
 	if (user_fence_rep != NULL)
<span class="p_del">-		ttm_ref_object_base_unref(vmw_fpriv(file_priv)-&gt;tfile,</span>
<span class="p_del">-					  handle, TTM_REF_USAGE);</span>
<span class="p_add">+		ttm_ref_object_base_unref(tfile, handle, TTM_REF_USAGE);</span>
 out_no_ref_obj:
 	vmw_fence_obj_unreference(&amp;fence);
 	return ret;
<span class="p_header">diff --git a/drivers/gpu/drm/vmwgfx/vmwgfx_ioctl.c b/drivers/gpu/drm/vmwgfx/vmwgfx_ioctl.c</span>
<span class="p_header">index b8c6a03c8c54..5ec24fd801cd 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/vmwgfx/vmwgfx_ioctl.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/vmwgfx/vmwgfx_ioctl.c</span>
<span class="p_chunk">@@ -114,8 +114,6 @@</span> <span class="p_context"> int vmw_getparam_ioctl(struct drm_device *dev, void *data,</span>
 		param-&gt;value = dev_priv-&gt;has_dx;
 		break;
 	default:
<span class="p_del">-		DRM_ERROR(&quot;Illegal vmwgfx get param request: %d\n&quot;,</span>
<span class="p_del">-			  param-&gt;param);</span>
 		return -EINVAL;
 	}
 
<span class="p_chunk">@@ -186,7 +184,7 @@</span> <span class="p_context"> int vmw_get_cap_3d_ioctl(struct drm_device *dev, void *data,</span>
 	bool gb_objects = !!(dev_priv-&gt;capabilities &amp; SVGA_CAP_GBOBJECTS);
 	struct vmw_fpriv *vmw_fp = vmw_fpriv(file_priv);
 
<span class="p_del">-	if (unlikely(arg-&gt;pad64 != 0)) {</span>
<span class="p_add">+	if (unlikely(arg-&gt;pad64 != 0 || arg-&gt;max_size == 0)) {</span>
 		DRM_ERROR(&quot;Illegal GET_3D_CAP argument.\n&quot;);
 		return -EINVAL;
 	}
<span class="p_header">diff --git a/drivers/gpu/drm/vmwgfx/vmwgfx_resource.c b/drivers/gpu/drm/vmwgfx/vmwgfx_resource.c</span>
<span class="p_header">index e57667ca7557..dbca128a9aa6 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/vmwgfx/vmwgfx_resource.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/vmwgfx/vmwgfx_resource.c</span>
<span class="p_chunk">@@ -591,7 +591,7 @@</span> <span class="p_context"> static int vmw_user_dmabuf_synccpu_grab(struct vmw_user_dma_buffer *user_bo,</span>
 		return ret;
 
 	ret = ttm_ref_object_add(tfile, &amp;user_bo-&gt;prime.base,
<span class="p_del">-				 TTM_REF_SYNCCPU_WRITE, &amp;existed);</span>
<span class="p_add">+				 TTM_REF_SYNCCPU_WRITE, &amp;existed, false);</span>
 	if (ret != 0 || existed)
 		ttm_bo_synccpu_write_release(&amp;user_bo-&gt;dma.base);
 
<span class="p_chunk">@@ -775,7 +775,7 @@</span> <span class="p_context"> int vmw_user_dmabuf_reference(struct ttm_object_file *tfile,</span>
 
 	*handle = user_bo-&gt;prime.base.hash.key;
 	return ttm_ref_object_add(tfile, &amp;user_bo-&gt;prime.base,
<span class="p_del">-				  TTM_REF_USAGE, NULL);</span>
<span class="p_add">+				  TTM_REF_USAGE, NULL, false);</span>
 }
 
 /*
<span class="p_header">diff --git a/drivers/gpu/drm/vmwgfx/vmwgfx_surface.c b/drivers/gpu/drm/vmwgfx/vmwgfx_surface.c</span>
<span class="p_header">index 7d620e82e000..c9c04ccccdd9 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/vmwgfx/vmwgfx_surface.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/vmwgfx/vmwgfx_surface.c</span>
<span class="p_chunk">@@ -715,11 +715,14 @@</span> <span class="p_context"> int vmw_surface_define_ioctl(struct drm_device *dev, void *data,</span>
 			128;
 
 	num_sizes = 0;
<span class="p_del">-	for (i = 0; i &lt; DRM_VMW_MAX_SURFACE_FACES; ++i)</span>
<span class="p_add">+	for (i = 0; i &lt; DRM_VMW_MAX_SURFACE_FACES; ++i) {</span>
<span class="p_add">+		if (req-&gt;mip_levels[i] &gt; DRM_VMW_MAX_MIP_LEVELS)</span>
<span class="p_add">+			return -EINVAL;</span>
 		num_sizes += req-&gt;mip_levels[i];
<span class="p_add">+	}</span>
 
<span class="p_del">-	if (num_sizes &gt; DRM_VMW_MAX_SURFACE_FACES *</span>
<span class="p_del">-	    DRM_VMW_MAX_MIP_LEVELS)</span>
<span class="p_add">+	if (num_sizes &gt; DRM_VMW_MAX_SURFACE_FACES * DRM_VMW_MAX_MIP_LEVELS ||</span>
<span class="p_add">+	    num_sizes == 0)</span>
 		return -EINVAL;
 
 	size = vmw_user_surface_size + 128 +
<span class="p_chunk">@@ -904,17 +907,16 @@</span> <span class="p_context"> vmw_surface_handle_reference(struct vmw_private *dev_priv,</span>
 	uint32_t handle;
 	struct ttm_base_object *base;
 	int ret;
<span class="p_add">+	bool require_exist = false;</span>
 
 	if (handle_type == DRM_VMW_HANDLE_PRIME) {
 		ret = ttm_prime_fd_to_handle(tfile, u_handle, &amp;handle);
 		if (unlikely(ret != 0))
 			return ret;
 	} else {
<span class="p_del">-		if (unlikely(drm_is_render_client(file_priv))) {</span>
<span class="p_del">-			DRM_ERROR(&quot;Render client refused legacy &quot;</span>
<span class="p_del">-				  &quot;surface reference.\n&quot;);</span>
<span class="p_del">-			return -EACCES;</span>
<span class="p_del">-		}</span>
<span class="p_add">+		if (unlikely(drm_is_render_client(file_priv)))</span>
<span class="p_add">+			require_exist = true;</span>
<span class="p_add">+</span>
 		if (ACCESS_ONCE(vmw_fpriv(file_priv)-&gt;locked_master)) {
 			DRM_ERROR(&quot;Locked master refused legacy &quot;
 				  &quot;surface reference.\n&quot;);
<span class="p_chunk">@@ -942,17 +944,14 @@</span> <span class="p_context"> vmw_surface_handle_reference(struct vmw_private *dev_priv,</span>
 
 		/*
 		 * Make sure the surface creator has the same
<span class="p_del">-		 * authenticating master.</span>
<span class="p_add">+		 * authenticating master, or is already registered with us.</span>
 		 */
 		if (drm_is_primary_client(file_priv) &amp;&amp;
<span class="p_del">-		    user_srf-&gt;master != file_priv-&gt;master) {</span>
<span class="p_del">-			DRM_ERROR(&quot;Trying to reference surface outside of&quot;</span>
<span class="p_del">-				  &quot; master domain.\n&quot;);</span>
<span class="p_del">-			ret = -EACCES;</span>
<span class="p_del">-			goto out_bad_resource;</span>
<span class="p_del">-		}</span>
<span class="p_add">+		    user_srf-&gt;master != file_priv-&gt;master)</span>
<span class="p_add">+			require_exist = true;</span>
 
<span class="p_del">-		ret = ttm_ref_object_add(tfile, base, TTM_REF_USAGE, NULL);</span>
<span class="p_add">+		ret = ttm_ref_object_add(tfile, base, TTM_REF_USAGE, NULL,</span>
<span class="p_add">+					 require_exist);</span>
 		if (unlikely(ret != 0)) {
 			DRM_ERROR(&quot;Could not add a reference to a surface.\n&quot;);
 			goto out_bad_resource;
<span class="p_header">diff --git a/drivers/iio/gyro/bmg160_core.c b/drivers/iio/gyro/bmg160_core.c</span>
<span class="p_header">index acb3b303d800..90841abd3ce4 100644</span>
<span class="p_header">--- a/drivers/iio/gyro/bmg160_core.c</span>
<span class="p_header">+++ b/drivers/iio/gyro/bmg160_core.c</span>
<span class="p_chunk">@@ -28,6 +28,7 @@</span> <span class="p_context"></span>
 #include &lt;linux/iio/trigger_consumer.h&gt;
 #include &lt;linux/iio/triggered_buffer.h&gt;
 #include &lt;linux/regmap.h&gt;
<span class="p_add">+#include &lt;linux/delay.h&gt;</span>
 #include &quot;bmg160.h&quot;
 
 #define BMG160_IRQ_NAME		&quot;bmg160_event&quot;
<span class="p_chunk">@@ -53,6 +54,9 @@</span> <span class="p_context"></span>
 #define BMG160_NO_FILTER		0
 #define BMG160_DEF_BW			100
 
<span class="p_add">+#define BMG160_GYRO_REG_RESET		0x14</span>
<span class="p_add">+#define BMG160_GYRO_RESET_VAL		0xb6</span>
<span class="p_add">+</span>
 #define BMG160_REG_INT_MAP_0		0x17
 #define BMG160_INT_MAP_0_BIT_ANY	BIT(1)
 
<span class="p_chunk">@@ -186,6 +190,14 @@</span> <span class="p_context"> static int bmg160_chip_init(struct bmg160_data *data)</span>
 	int ret;
 	unsigned int val;
 
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Reset chip to get it in a known good state. A delay of 30ms after</span>
<span class="p_add">+	 * reset is required according to the datasheet.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	regmap_write(data-&gt;regmap, BMG160_GYRO_REG_RESET,</span>
<span class="p_add">+		     BMG160_GYRO_RESET_VAL);</span>
<span class="p_add">+	usleep_range(30000, 30700);</span>
<span class="p_add">+</span>
 	ret = regmap_read(data-&gt;regmap, BMG160_REG_CHIP_ID, &amp;val);
 	if (ret &lt; 0) {
 		dev_err(data-&gt;dev, &quot;Error reading reg_chip_id\n&quot;);
<span class="p_header">diff --git a/drivers/staging/android/ashmem.c b/drivers/staging/android/ashmem.c</span>
<span class="p_header">index 3f2a3d611e4b..9c6357c03905 100644</span>
<span class="p_header">--- a/drivers/staging/android/ashmem.c</span>
<span class="p_header">+++ b/drivers/staging/android/ashmem.c</span>
<span class="p_chunk">@@ -392,6 +392,7 @@</span> <span class="p_context"> static int ashmem_mmap(struct file *file, struct vm_area_struct *vma)</span>
 			ret = PTR_ERR(vmfile);
 			goto out;
 		}
<span class="p_add">+		vmfile-&gt;f_mode |= FMODE_LSEEK;</span>
 		asma-&gt;file = vmfile;
 	}
 	get_file(asma-&gt;file);
<span class="p_header">diff --git a/fs/cifs/smb2pdu.c b/fs/cifs/smb2pdu.c</span>
<span class="p_header">index 2fa754c5fd62..6cb5c4b30e78 100644</span>
<span class="p_header">--- a/fs/cifs/smb2pdu.c</span>
<span class="p_header">+++ b/fs/cifs/smb2pdu.c</span>
<span class="p_chunk">@@ -952,6 +952,10 @@</span> <span class="p_context"> SMB2_tcon(const unsigned int xid, struct cifs_ses *ses, const char *tree,</span>
 		return -EINVAL;
 	}
 
<span class="p_add">+	/* SMB2 TREE_CONNECT request must be called with TreeId == 0 */</span>
<span class="p_add">+	if (tcon)</span>
<span class="p_add">+		tcon-&gt;tid = 0;</span>
<span class="p_add">+</span>
 	rc = small_smb2_init(SMB2_TREE_CONNECT, tcon, (void **) &amp;req);
 	if (rc) {
 		kfree(unc_path);
<span class="p_header">diff --git a/fs/sysfs/file.c b/fs/sysfs/file.c</span>
<span class="p_header">index b803213d1307..39c75a86c67f 100644</span>
<span class="p_header">--- a/fs/sysfs/file.c</span>
<span class="p_header">+++ b/fs/sysfs/file.c</span>
<span class="p_chunk">@@ -108,7 +108,7 @@</span> <span class="p_context"> static ssize_t sysfs_kf_read(struct kernfs_open_file *of, char *buf,</span>
 {
 	const struct sysfs_ops *ops = sysfs_file_ops(of-&gt;kn);
 	struct kobject *kobj = of-&gt;kn-&gt;parent-&gt;priv;
<span class="p_del">-	size_t len;</span>
<span class="p_add">+	ssize_t len;</span>
 
 	/*
 	 * If buf != of-&gt;prealloc_buf, we don&#39;t know how
<span class="p_chunk">@@ -117,13 +117,15 @@</span> <span class="p_context"> static ssize_t sysfs_kf_read(struct kernfs_open_file *of, char *buf,</span>
 	if (WARN_ON_ONCE(buf != of-&gt;prealloc_buf))
 		return 0;
 	len = ops-&gt;show(kobj, of-&gt;kn-&gt;priv, buf);
<span class="p_add">+	if (len &lt; 0)</span>
<span class="p_add">+		return len;</span>
 	if (pos) {
 		if (len &lt;= pos)
 			return 0;
 		len -= pos;
 		memmove(buf, buf + pos, len);
 	}
<span class="p_del">-	return min(count, len);</span>
<span class="p_add">+	return min_t(ssize_t, count, len);</span>
 }
 
 /* kernfs write callback for regular sysfs files */
<span class="p_header">diff --git a/include/drm/ttm/ttm_object.h b/include/drm/ttm/ttm_object.h</span>
<span class="p_header">index ed953f98f0e1..1487011fe057 100644</span>
<span class="p_header">--- a/include/drm/ttm/ttm_object.h</span>
<span class="p_header">+++ b/include/drm/ttm/ttm_object.h</span>
<span class="p_chunk">@@ -229,6 +229,8 @@</span> <span class="p_context"> extern void ttm_base_object_unref(struct ttm_base_object **p_base);</span>
  * @ref_type: The type of reference.
  * @existed: Upon completion, indicates that an identical reference object
  * already existed, and the refcount was upped on that object instead.
<span class="p_add">+ * @require_existed: Fail with -EPERM if an identical ref object didn&#39;t</span>
<span class="p_add">+ * already exist.</span>
  *
  * Checks that the base object is shareable and adds a ref object to it.
  *
<span class="p_chunk">@@ -243,7 +245,8 @@</span> <span class="p_context"> extern void ttm_base_object_unref(struct ttm_base_object **p_base);</span>
  */
 extern int ttm_ref_object_add(struct ttm_object_file *tfile,
 			      struct ttm_base_object *base,
<span class="p_del">-			      enum ttm_ref_type ref_type, bool *existed);</span>
<span class="p_add">+			      enum ttm_ref_type ref_type, bool *existed,</span>
<span class="p_add">+			      bool require_existed);</span>
 
 extern bool ttm_ref_object_exists(struct ttm_object_file *tfile,
 				  struct ttm_base_object *base);
<span class="p_header">diff --git a/kernel/ptrace.c b/kernel/ptrace.c</span>
<span class="p_header">index a46c40bfb5f6..c7e8ed99c953 100644</span>
<span class="p_header">--- a/kernel/ptrace.c</span>
<span class="p_header">+++ b/kernel/ptrace.c</span>
<span class="p_chunk">@@ -151,11 +151,17 @@</span> <span class="p_context"> static void ptrace_unfreeze_traced(struct task_struct *task)</span>
 
 	WARN_ON(!task-&gt;ptrace || task-&gt;parent != current);
 
<span class="p_add">+	/*</span>
<span class="p_add">+	 * PTRACE_LISTEN can allow ptrace_trap_notify to wake us up remotely.</span>
<span class="p_add">+	 * Recheck state under the lock to close this race.</span>
<span class="p_add">+	 */</span>
 	spin_lock_irq(&amp;task-&gt;sighand-&gt;siglock);
<span class="p_del">-	if (__fatal_signal_pending(task))</span>
<span class="p_del">-		wake_up_state(task, __TASK_TRACED);</span>
<span class="p_del">-	else</span>
<span class="p_del">-		task-&gt;state = TASK_TRACED;</span>
<span class="p_add">+	if (task-&gt;state == __TASK_TRACED) {</span>
<span class="p_add">+		if (__fatal_signal_pending(task))</span>
<span class="p_add">+			wake_up_state(task, __TASK_TRACED);</span>
<span class="p_add">+		else</span>
<span class="p_add">+			task-&gt;state = TASK_TRACED;</span>
<span class="p_add">+	}</span>
 	spin_unlock_irq(&amp;task-&gt;sighand-&gt;siglock);
 }
 
<span class="p_header">diff --git a/kernel/trace/ring_buffer.c b/kernel/trace/ring_buffer.c</span>
<span class="p_header">index acbb0e73d3a2..7d7f99b0db47 100644</span>
<span class="p_header">--- a/kernel/trace/ring_buffer.c</span>
<span class="p_header">+++ b/kernel/trace/ring_buffer.c</span>
<span class="p_chunk">@@ -4875,9 +4875,9 @@</span> <span class="p_context"> static __init int test_ringbuffer(void)</span>
 		rb_data[cpu].cnt = cpu;
 		rb_threads[cpu] = kthread_create(rb_test, &amp;rb_data[cpu],
 						 &quot;rbtester/%d&quot;, cpu);
<span class="p_del">-		if (WARN_ON(!rb_threads[cpu])) {</span>
<span class="p_add">+		if (WARN_ON(IS_ERR(rb_threads[cpu]))) {</span>
 			pr_cont(&quot;FAILED\n&quot;);
<span class="p_del">-			ret = -1;</span>
<span class="p_add">+			ret = PTR_ERR(rb_threads[cpu]);</span>
 			goto out_free;
 		}
 
<span class="p_chunk">@@ -4887,9 +4887,9 @@</span> <span class="p_context"> static __init int test_ringbuffer(void)</span>
 
 	/* Now create the rb hammer! */
 	rb_hammer = kthread_run(rb_hammer_test, NULL, &quot;rbhammer&quot;);
<span class="p_del">-	if (WARN_ON(!rb_hammer)) {</span>
<span class="p_add">+	if (WARN_ON(IS_ERR(rb_hammer))) {</span>
 		pr_cont(&quot;FAILED\n&quot;);
<span class="p_del">-		ret = -1;</span>
<span class="p_add">+		ret = PTR_ERR(rb_hammer);</span>
 		goto out_free;
 	}
 
<span class="p_header">diff --git a/mm/mempolicy.c b/mm/mempolicy.c</span>
<span class="p_header">index a4217fe60dff..e09b1a0e2cfe 100644</span>
<span class="p_header">--- a/mm/mempolicy.c</span>
<span class="p_header">+++ b/mm/mempolicy.c</span>
<span class="p_chunk">@@ -1492,7 +1492,6 @@</span> <span class="p_context"> COMPAT_SYSCALL_DEFINE5(get_mempolicy, int __user *, policy,</span>
 COMPAT_SYSCALL_DEFINE3(set_mempolicy, int, mode, compat_ulong_t __user *, nmask,
 		       compat_ulong_t, maxnode)
 {
<span class="p_del">-	long err = 0;</span>
 	unsigned long __user *nm = NULL;
 	unsigned long nr_bits, alloc_size;
 	DECLARE_BITMAP(bm, MAX_NUMNODES);
<span class="p_chunk">@@ -1501,14 +1500,13 @@</span> <span class="p_context"> COMPAT_SYSCALL_DEFINE3(set_mempolicy, int, mode, compat_ulong_t __user *, nmask,</span>
 	alloc_size = ALIGN(nr_bits, BITS_PER_LONG) / 8;
 
 	if (nmask) {
<span class="p_del">-		err = compat_get_bitmap(bm, nmask, nr_bits);</span>
<span class="p_add">+		if (compat_get_bitmap(bm, nmask, nr_bits))</span>
<span class="p_add">+			return -EFAULT;</span>
 		nm = compat_alloc_user_space(alloc_size);
<span class="p_del">-		err |= copy_to_user(nm, bm, alloc_size);</span>
<span class="p_add">+		if (copy_to_user(nm, bm, alloc_size))</span>
<span class="p_add">+			return -EFAULT;</span>
 	}
 
<span class="p_del">-	if (err)</span>
<span class="p_del">-		return -EFAULT;</span>
<span class="p_del">-</span>
 	return sys_set_mempolicy(mode, nm, nr_bits+1);
 }
 
<span class="p_chunk">@@ -1516,7 +1514,6 @@</span> <span class="p_context"> COMPAT_SYSCALL_DEFINE6(mbind, compat_ulong_t, start, compat_ulong_t, len,</span>
 		       compat_ulong_t, mode, compat_ulong_t __user *, nmask,
 		       compat_ulong_t, maxnode, compat_ulong_t, flags)
 {
<span class="p_del">-	long err = 0;</span>
 	unsigned long __user *nm = NULL;
 	unsigned long nr_bits, alloc_size;
 	nodemask_t bm;
<span class="p_chunk">@@ -1525,14 +1522,13 @@</span> <span class="p_context"> COMPAT_SYSCALL_DEFINE6(mbind, compat_ulong_t, start, compat_ulong_t, len,</span>
 	alloc_size = ALIGN(nr_bits, BITS_PER_LONG) / 8;
 
 	if (nmask) {
<span class="p_del">-		err = compat_get_bitmap(nodes_addr(bm), nmask, nr_bits);</span>
<span class="p_add">+		if (compat_get_bitmap(nodes_addr(bm), nmask, nr_bits))</span>
<span class="p_add">+			return -EFAULT;</span>
 		nm = compat_alloc_user_space(alloc_size);
<span class="p_del">-		err |= copy_to_user(nm, nodes_addr(bm), alloc_size);</span>
<span class="p_add">+		if (copy_to_user(nm, nodes_addr(bm), alloc_size))</span>
<span class="p_add">+			return -EFAULT;</span>
 	}
 
<span class="p_del">-	if (err)</span>
<span class="p_del">-		return -EFAULT;</span>
<span class="p_del">-</span>
 	return sys_mbind(start, len, mode, nm, nr_bits+1, flags);
 }
 

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



