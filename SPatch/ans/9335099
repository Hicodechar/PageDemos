
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>[v2,3/3] powerpc/8xx: Implement support of hugepages - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    [v2,3/3] powerpc/8xx: Implement support of hugepages</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=11492">LEROY Christophe</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>Sept. 16, 2016, 7:40 a.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;0610fb75ed003fab8d9747167a1f06b117d8e8f4.1474009019.git.christophe.leroy@c-s.fr&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/9335099/mbox/"
   >mbox</a>
|
   <a href="/patch/9335099/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/9335099/">/patch/9335099/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
	[172.30.200.125])
	by pdx-korg-patchwork.web.codeaurora.org (Postfix) with ESMTP id
	4B77C60839 for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Fri, 16 Sep 2016 07:40:44 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 3E2B029E66
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Fri, 16 Sep 2016 07:40:44 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id 32CE229EE3; Fri, 16 Sep 2016 07:40:44 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-6.9 required=2.0 tests=BAYES_00,RCVD_IN_DNSWL_HI
	autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id B76DA29E66
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Fri, 16 Sep 2016 07:40:42 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1757813AbcIPHkd (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Fri, 16 Sep 2016 03:40:33 -0400
Received: from pegase1.c-s.fr ([93.17.236.30]:60786 &quot;EHLO pegase1.c-s.fr&quot;
	rhost-flags-OK-OK-OK-OK) by vger.kernel.org with ESMTP
	id S1757968AbcIPHkL (ORCPT &lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Fri, 16 Sep 2016 03:40:11 -0400
Received: from localhost (unknown [192.168.12.234])
	by localhost (Postfix) with ESMTP id 3sb6d51sVkz9ttFW;
	Fri, 16 Sep 2016 09:40:09 +0200 (CEST)
X-Virus-Scanned: Debian amavisd-new at c-s.fr
Received: from pegase1.c-s.fr ([192.168.12.234])
	by localhost (pegase1.c-s.fr [192.168.12.234]) (amavisd-new,
	port 10024)
	with ESMTP id giYzMLu3oDit; Fri, 16 Sep 2016 09:40:09 +0200 (CEST)
Received: from messagerie.si.c-s.fr (messagerie.si.c-s.fr [192.168.25.192])
	by pegase1.c-s.fr (Postfix) with ESMTP id 3sb6d46yr6z9ttFQ;
	Fri, 16 Sep 2016 09:40:08 +0200 (CEST)
Received: from localhost (localhost [127.0.0.1])
	by messagerie.si.c-s.fr (Postfix) with ESMTP id 2C2B18B96F;
	Fri, 16 Sep 2016 09:40:09 +0200 (CEST)
X-Virus-Scanned: amavisd-new at c-s.fr
Received: from messagerie.si.c-s.fr ([127.0.0.1])
	by localhost (messagerie.si.c-s.fr [127.0.0.1]) (amavisd-new,
	port 10023)
	with ESMTP id 983wRol_POSE; Fri, 16 Sep 2016 09:40:09 +0200 (CEST)
Received: from PO10863.localdomain (po10863.idsi0.si.c-s.fr [172.25.231.27])
	by messagerie.si.c-s.fr (Postfix) with ESMTP id 053A48B96D;
	Fri, 16 Sep 2016 09:40:09 +0200 (CEST)
Received: by localhost.localdomain (Postfix, from userid 0)
	id B576C1A2455; Fri, 16 Sep 2016 09:40:08 +0200 (CEST)
Message-Id: &lt;0610fb75ed003fab8d9747167a1f06b117d8e8f4.1474009019.git.christophe.leroy@c-s.fr&gt;
In-Reply-To: &lt;cover.1474009019.git.christophe.leroy@c-s.fr&gt;
References: &lt;cover.1474009019.git.christophe.leroy@c-s.fr&gt;
From: Christophe Leroy &lt;christophe.leroy@c-s.fr&gt;
Subject: [PATCH v2 3/3] powerpc/8xx: Implement support of hugepages
To: Benjamin Herrenschmidt &lt;benh@kernel.crashing.org&gt;,
	Paul Mackerras &lt;paulus@samba.org&gt;, Michael Ellerman &lt;mpe@ellerman.id.au&gt;,
	Scott Wood &lt;oss@buserror.net&gt;
Cc: linux-kernel@vger.kernel.org, linuxppc-dev@lists.ozlabs.org
Date: Fri, 16 Sep 2016 09:40:08 +0200 (CEST)
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=11492">LEROY Christophe</a> - Sept. 16, 2016, 7:40 a.m.</div>
<pre class="content">
8xx uses a two level page table with two different linux page size
support (4k and 16k). 8xx also support two different hugepage sizes
512k and 8M. In order to support them on linux we define two different
page table layout.

The size of pages is in the PGD entry, using PS field (bits 28-29):
00 : Small pages (4k or 16k)
01 : 512k pages
10 : reserved
11 : 8M pages

For 512K hugepage size a pgd entry have the below format
[&lt;hugepte address &gt;0101] . The hugepte table allocated will contain 8
entries pointing to 512K huge pte in 4k pages mode and 64 entries in
16k pages mode.

For 8M in 16k mode, a pgd entry have the below format
[&lt;hugepte address &gt;1101] . The hugepte table allocated will contain 8
entries pointing to 8M huge pte.

For 8M in 4k mode, multiple pgd entries point to the same hugepte
address and pgd entry will have the below format
[&lt;hugepte address&gt;1101]. The hugepte table allocated will only have one
entry.

For the time being, we do not support CPU15 ERRATA when HUGETLB is
selected
<span class="signed-off-by">
Signed-off-by: Christophe Leroy &lt;christophe.leroy@c-s.fr&gt;</span>
---
v2: This v1 was split in two parts. This part focuses on adding the
support on 8xx. It also fixes an error in TLBmiss handlers in the
case of 8M hugepages in 16k pages mode.

 arch/powerpc/include/asm/hugetlb.h           |  19 ++++-
 arch/powerpc/include/asm/mmu-8xx.h           |  35 ++++++++
 arch/powerpc/include/asm/mmu.h               |  23 +++---
 arch/powerpc/include/asm/nohash/32/pte-8xx.h |   1 +
 arch/powerpc/include/asm/nohash/pgtable.h    |   4 +
 arch/powerpc/include/asm/reg_8xx.h           |   2 +-
 arch/powerpc/kernel/head_8xx.S               | 119 +++++++++++++++++++++++++--
 arch/powerpc/mm/hugetlbpage.c                |  25 ++++--
 arch/powerpc/mm/tlb_nohash.c                 |  21 ++++-
 arch/powerpc/platforms/8xx/Kconfig           |   1 +
 arch/powerpc/platforms/Kconfig.cputype       |   1 +
 11 files changed, 223 insertions(+), 28 deletions(-)
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/arch/powerpc/include/asm/hugetlb.h b/arch/powerpc/include/asm/hugetlb.h</span>
<span class="p_header">index c5517f4..3facdd4 100644</span>
<span class="p_header">--- a/arch/powerpc/include/asm/hugetlb.h</span>
<span class="p_header">+++ b/arch/powerpc/include/asm/hugetlb.h</span>
<span class="p_chunk">@@ -51,12 +51,20 @@</span> <span class="p_context"> static inline void __local_flush_hugetlb_page(struct vm_area_struct *vma,</span>
 static inline pte_t *hugepd_page(hugepd_t hpd)
 {
 	BUG_ON(!hugepd_ok(hpd));
<span class="p_add">+#ifdef CONFIG_PPC_8xx</span>
<span class="p_add">+	return (pte_t *)__va(hpd.pd &amp; ~(_PMD_PAGE_MASK | _PMD_PRESENT_MASK));</span>
<span class="p_add">+#else</span>
 	return (pte_t *)((hpd.pd &amp; ~HUGEPD_SHIFT_MASK) | PD_HUGE);
<span class="p_add">+#endif</span>
 }
 
 static inline unsigned int hugepd_shift(hugepd_t hpd)
 {
<span class="p_add">+#ifdef CONFIG_PPC_8xx</span>
<span class="p_add">+	return ((hpd.pd &amp; _PMD_PAGE_MASK) &gt;&gt; 1) + 17;</span>
<span class="p_add">+#else</span>
 	return hpd.pd &amp; HUGEPD_SHIFT_MASK;
<span class="p_add">+#endif</span>
 }
 
 #endif /* CONFIG_PPC_BOOK3S_64 */
<span class="p_chunk">@@ -99,7 +107,15 @@</span> <span class="p_context"> static inline int is_hugepage_only_range(struct mm_struct *mm,</span>
 
 void book3e_hugetlb_preload(struct vm_area_struct *vma, unsigned long ea,
 			    pte_t pte);
<span class="p_add">+#ifdef CONFIG_PPC_8xx</span>
<span class="p_add">+static inline void flush_hugetlb_page(struct vm_area_struct *vma,</span>
<span class="p_add">+				      unsigned long vmaddr)</span>
<span class="p_add">+{</span>
<span class="p_add">+	flush_tlb_page(vma, vmaddr);</span>
<span class="p_add">+}</span>
<span class="p_add">+#else</span>
 void flush_hugetlb_page(struct vm_area_struct *vma, unsigned long vmaddr);
<span class="p_add">+#endif</span>
 
 void hugetlb_free_pgd_range(struct mmu_gather *tlb, unsigned long addr,
 			    unsigned long end, unsigned long floor,
<span class="p_chunk">@@ -205,7 +221,8 @@</span> <span class="p_context"> static inline pte_t *hugepte_offset(hugepd_t hpd, unsigned long addr,</span>
  * are reserved early in the boot process by memblock instead of via
  * the .dts as on IBM platforms.
  */
<span class="p_del">-#if defined(CONFIG_HUGETLB_PAGE) &amp;&amp; defined(CONFIG_PPC_FSL_BOOK3E)</span>
<span class="p_add">+#if defined(CONFIG_HUGETLB_PAGE) &amp;&amp; (defined(CONFIG_PPC_FSL_BOOK3E) || \</span>
<span class="p_add">+    defined(CONFIG_PPC_8xx))</span>
 extern void __init reserve_hugetlb_gpages(void);
 #else
 static inline void reserve_hugetlb_gpages(void)
<span class="p_header">diff --git a/arch/powerpc/include/asm/mmu-8xx.h b/arch/powerpc/include/asm/mmu-8xx.h</span>
<span class="p_header">index 3e0e492..798b5bf 100644</span>
<span class="p_header">--- a/arch/powerpc/include/asm/mmu-8xx.h</span>
<span class="p_header">+++ b/arch/powerpc/include/asm/mmu-8xx.h</span>
<span class="p_chunk">@@ -172,6 +172,41 @@</span> <span class="p_context"> typedef struct {</span>
 
 #define PHYS_IMMR_BASE (mfspr(SPRN_IMMR) &amp; 0xfff80000)
 #define VIRT_IMMR_BASE (__fix_to_virt(FIX_IMMR_BASE))
<span class="p_add">+</span>
<span class="p_add">+/* Page size definitions, common between 32 and 64-bit</span>
<span class="p_add">+ *</span>
<span class="p_add">+ *    shift : is the &quot;PAGE_SHIFT&quot; value for that page size</span>
<span class="p_add">+ *    penc  : is the pte encoding mask</span>
<span class="p_add">+ *</span>
<span class="p_add">+ */</span>
<span class="p_add">+struct mmu_psize_def {</span>
<span class="p_add">+	unsigned int	shift;	/* number of bits */</span>
<span class="p_add">+	unsigned int	enc;	/* PTE encoding */</span>
<span class="p_add">+	unsigned int    ind;    /* Corresponding indirect page size shift */</span>
<span class="p_add">+	unsigned int	flags;</span>
<span class="p_add">+#define MMU_PAGE_SIZE_DIRECT	0x1	/* Supported as a direct size */</span>
<span class="p_add">+#define MMU_PAGE_SIZE_INDIRECT	0x2	/* Supported as an indirect size */</span>
<span class="p_add">+};</span>
<span class="p_add">+</span>
<span class="p_add">+extern struct mmu_psize_def mmu_psize_defs[MMU_PAGE_COUNT];</span>
<span class="p_add">+</span>
<span class="p_add">+static inline int shift_to_mmu_psize(unsigned int shift)</span>
<span class="p_add">+{</span>
<span class="p_add">+	int psize;</span>
<span class="p_add">+</span>
<span class="p_add">+	for (psize = 0; psize &lt; MMU_PAGE_COUNT; ++psize)</span>
<span class="p_add">+		if (mmu_psize_defs[psize].shift == shift)</span>
<span class="p_add">+			return psize;</span>
<span class="p_add">+	return -1;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline unsigned int mmu_psize_to_shift(unsigned int mmu_psize)</span>
<span class="p_add">+{</span>
<span class="p_add">+	if (mmu_psize_defs[mmu_psize].shift)</span>
<span class="p_add">+		return mmu_psize_defs[mmu_psize].shift;</span>
<span class="p_add">+	BUG();</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 #endif /* !__ASSEMBLY__ */
 
 #if defined(CONFIG_PPC_4K_PAGES)
<span class="p_header">diff --git a/arch/powerpc/include/asm/mmu.h b/arch/powerpc/include/asm/mmu.h</span>
<span class="p_header">index b78e8d3..c81aafc 100644</span>
<span class="p_header">--- a/arch/powerpc/include/asm/mmu.h</span>
<span class="p_header">+++ b/arch/powerpc/include/asm/mmu.h</span>
<span class="p_chunk">@@ -260,19 +260,20 @@</span> <span class="p_context"> static inline bool early_radix_enabled(void)</span>
 #define MMU_PAGE_64K	2
 #define MMU_PAGE_64K_AP	3	/* &quot;Admixed pages&quot; (hash64 only) */
 #define MMU_PAGE_256K	4
<span class="p_del">-#define MMU_PAGE_1M	5</span>
<span class="p_del">-#define MMU_PAGE_2M	6</span>
<span class="p_del">-#define MMU_PAGE_4M	7</span>
<span class="p_del">-#define MMU_PAGE_8M	8</span>
<span class="p_del">-#define MMU_PAGE_16M	9</span>
<span class="p_del">-#define MMU_PAGE_64M	10</span>
<span class="p_del">-#define MMU_PAGE_256M	11</span>
<span class="p_del">-#define MMU_PAGE_1G	12</span>
<span class="p_del">-#define MMU_PAGE_16G	13</span>
<span class="p_del">-#define MMU_PAGE_64G	14</span>
<span class="p_add">+#define MMU_PAGE_512K	5</span>
<span class="p_add">+#define MMU_PAGE_1M	6</span>
<span class="p_add">+#define MMU_PAGE_2M	7</span>
<span class="p_add">+#define MMU_PAGE_4M	8</span>
<span class="p_add">+#define MMU_PAGE_8M	9</span>
<span class="p_add">+#define MMU_PAGE_16M	10</span>
<span class="p_add">+#define MMU_PAGE_64M	11</span>
<span class="p_add">+#define MMU_PAGE_256M	12</span>
<span class="p_add">+#define MMU_PAGE_1G	13</span>
<span class="p_add">+#define MMU_PAGE_16G	14</span>
<span class="p_add">+#define MMU_PAGE_64G	15</span>
 
 /* N.B. we need to change the type of hpte_page_sizes if this gets to be &gt; 16 */
<span class="p_del">-#define MMU_PAGE_COUNT	15</span>
<span class="p_add">+#define MMU_PAGE_COUNT	16</span>
 
 #ifdef CONFIG_PPC_BOOK3S_64
 #include &lt;asm/book3s/64/mmu.h&gt;
<span class="p_header">diff --git a/arch/powerpc/include/asm/nohash/32/pte-8xx.h b/arch/powerpc/include/asm/nohash/32/pte-8xx.h</span>
<span class="p_header">index 3742b19..b4df273 100644</span>
<span class="p_header">--- a/arch/powerpc/include/asm/nohash/32/pte-8xx.h</span>
<span class="p_header">+++ b/arch/powerpc/include/asm/nohash/32/pte-8xx.h</span>
<span class="p_chunk">@@ -49,6 +49,7 @@</span> <span class="p_context"></span>
 #define _PMD_BAD	0x0ff0
 #define _PMD_PAGE_MASK	0x000c
 #define _PMD_PAGE_8M	0x000c
<span class="p_add">+#define _PMD_PAGE_512K	0x0004</span>
 
 /* Until my rework is finished, 8xx still needs atomic PTE updates */
 #define PTE_ATOMIC_UPDATES	1
<span class="p_header">diff --git a/arch/powerpc/include/asm/nohash/pgtable.h b/arch/powerpc/include/asm/nohash/pgtable.h</span>
<span class="p_header">index 1263c22..1728497 100644</span>
<span class="p_header">--- a/arch/powerpc/include/asm/nohash/pgtable.h</span>
<span class="p_header">+++ b/arch/powerpc/include/asm/nohash/pgtable.h</span>
<span class="p_chunk">@@ -226,7 +226,11 @@</span> <span class="p_context"> extern pgprot_t phys_mem_access_prot(struct file *file, unsigned long pfn,</span>
 #ifdef CONFIG_HUGETLB_PAGE
 static inline int hugepd_ok(hugepd_t hpd)
 {
<span class="p_add">+#ifdef CONFIG_PPC_8xx</span>
<span class="p_add">+	return ((hpd.pd &amp; 0x4) != 0);</span>
<span class="p_add">+#else</span>
 	return (hpd.pd &gt; 0);
<span class="p_add">+#endif</span>
 }
 
 static inline int pmd_huge(pmd_t pmd)
<span class="p_header">diff --git a/arch/powerpc/include/asm/reg_8xx.h b/arch/powerpc/include/asm/reg_8xx.h</span>
<span class="p_header">index 94d01f8..feaf641 100644</span>
<span class="p_header">--- a/arch/powerpc/include/asm/reg_8xx.h</span>
<span class="p_header">+++ b/arch/powerpc/include/asm/reg_8xx.h</span>
<span class="p_chunk">@@ -4,7 +4,7 @@</span> <span class="p_context"></span>
 #ifndef _ASM_POWERPC_REG_8xx_H
 #define _ASM_POWERPC_REG_8xx_H
 
<span class="p_del">-#include &lt;asm/mmu-8xx.h&gt;</span>
<span class="p_add">+#include &lt;asm/mmu.h&gt;</span>
 
 /* Cache control on the MPC8xx is provided through some additional
  * special purpose registers.
<span class="p_header">diff --git a/arch/powerpc/kernel/head_8xx.S b/arch/powerpc/kernel/head_8xx.S</span>
<span class="p_header">index bfe4907..82d43dd 100644</span>
<span class="p_header">--- a/arch/powerpc/kernel/head_8xx.S</span>
<span class="p_header">+++ b/arch/powerpc/kernel/head_8xx.S</span>
<span class="p_chunk">@@ -73,6 +73,9 @@</span> <span class="p_context"></span>
 #define RPN_PATTERN	0x00f0
 #endif
 
<span class="p_add">+#define PAGE_SHIFT_512K		19</span>
<span class="p_add">+#define PAGE_SHIFT_8M		23</span>
<span class="p_add">+</span>
 	__HEAD
 _ENTRY(_stext);
 _ENTRY(_start);
<span class="p_chunk">@@ -323,7 +326,7 @@</span> <span class="p_context"> SystemCall:</span>
 #endif
 
 InstructionTLBMiss:
<span class="p_del">-#if defined(CONFIG_8xx_CPU6) || defined(CONFIG_MODULES) || defined (CONFIG_DEBUG_PAGEALLOC)</span>
<span class="p_add">+#if defined(CONFIG_8xx_CPU6) || defined(CONFIG_MODULES) || defined (CONFIG_DEBUG_PAGEALLOC) || defined (CONFIG_HUGETLB_PAGE)</span>
 	mtspr	SPRN_SPRG_SCRATCH2, r3
 #endif
 	EXCEPTION_PROLOG_0
<span class="p_chunk">@@ -333,10 +336,12 @@</span> <span class="p_context"> InstructionTLBMiss:</span>
 	 */
 	mfspr	r10, SPRN_SRR0	/* Get effective address of fault */
 	INVALIDATE_ADJACENT_PAGES_CPU15(r11, r10)
<span class="p_del">-#if defined(CONFIG_MODULES) || defined (CONFIG_DEBUG_PAGEALLOC)</span>
 	/* Only modules will cause ITLB Misses as we always
 	 * pin the first 8MB of kernel memory */
<span class="p_add">+#if defined(CONFIG_MODULES) || defined (CONFIG_DEBUG_PAGEALLOC) || defined (CONFIG_HUGETLB_PAGE)</span>
 	mfcr	r3
<span class="p_add">+#endif</span>
<span class="p_add">+#if defined(CONFIG_MODULES) || defined (CONFIG_DEBUG_PAGEALLOC)</span>
 	IS_KERNEL(r11, r10)
 #endif
 	mfspr	r11, SPRN_M_TW	/* Get level 1 table */
<span class="p_chunk">@@ -344,7 +349,6 @@</span> <span class="p_context"> InstructionTLBMiss:</span>
 	BRANCH_UNLESS_KERNEL(3f)
 	lis	r11, (swapper_pg_dir-PAGE_OFFSET)@ha
 3:
<span class="p_del">-	mtcr	r3</span>
 #endif
 	/* Insert level 1 index */
 	rlwimi	r11, r10, 32 - ((PAGE_SHIFT - 2) &lt;&lt; 1), (PAGE_SHIFT - 2) &lt;&lt; 1, 29
<span class="p_chunk">@@ -352,14 +356,25 @@</span> <span class="p_context"> InstructionTLBMiss:</span>
 
 	/* Extract level 2 index */
 	rlwinm	r10, r10, 32 - (PAGE_SHIFT - 2), 32 - PAGE_SHIFT, 29
<span class="p_add">+#ifdef CONFIG_HUGETLB_PAGE</span>
<span class="p_add">+	mtcr	r11</span>
<span class="p_add">+	bt-	28, 10f		/* bit 28 = Large page (8M) */</span>
<span class="p_add">+	bt-	29, 20f		/* bit 29 = Large page (8M or 512k) */</span>
<span class="p_add">+#endif</span>
 	rlwimi	r10, r11, 0, 0, 32 - PAGE_SHIFT - 1	/* Add level 2 base */
 	lwz	r10, 0(r10)	/* Get the pte */
<span class="p_del">-</span>
<span class="p_add">+4:</span>
<span class="p_add">+#if defined(CONFIG_MODULES) || defined (CONFIG_DEBUG_PAGEALLOC) || defined (CONFIG_HUGETLB_PAGE)</span>
<span class="p_add">+	mtcr	r3</span>
<span class="p_add">+#endif</span>
 	/* Insert the APG into the TWC from the Linux PTE. */
 	rlwimi	r11, r10, 0, 25, 26
 	/* Load the MI_TWC with the attributes for this &quot;segment.&quot; */
 	MTSPR_CPU6(SPRN_MI_TWC, r11, r3)	/* Set segment attributes */
 
<span class="p_add">+#if defined (CONFIG_HUGETLB_PAGE) &amp;&amp; defined (CONFIG_PPC_4K_PAGES)</span>
<span class="p_add">+	rlwimi	r10, r11, 1, MI_SPS16K</span>
<span class="p_add">+#endif</span>
 #ifdef CONFIG_SWAP
 	rlwinm	r11, r10, 32-5, _PAGE_PRESENT
 	and	r11, r11, r10
<span class="p_chunk">@@ -372,16 +387,45 @@</span> <span class="p_context"> InstructionTLBMiss:</span>
 	 * set.  All other Linux PTE bits control the behavior
 	 * of the MMU.
 	 */
<span class="p_add">+#if defined (CONFIG_HUGETLB_PAGE) &amp;&amp; defined (CONFIG_PPC_4K_PAGES)</span>
<span class="p_add">+	rlwimi	r10, r11, 0, 0x0ff0	/* Set 24-27, clear 20-23 */</span>
<span class="p_add">+#else</span>
 	rlwimi	r10, r11, 0, 0x0ff8	/* Set 24-27, clear 20-23,28 */
<span class="p_add">+#endif</span>
 	MTSPR_CPU6(SPRN_MI_RPN, r10, r3)	/* Update TLB entry */
 
 	/* Restore registers */
<span class="p_del">-#if defined(CONFIG_8xx_CPU6) || defined(CONFIG_MODULES) || defined (CONFIG_DEBUG_PAGEALLOC)</span>
<span class="p_add">+#if defined(CONFIG_8xx_CPU6) || defined(CONFIG_MODULES) || defined (CONFIG_DEBUG_PAGEALLOC) || defined (CONFIG_HUGETLB_PAGE)</span>
 	mfspr	r3, SPRN_SPRG_SCRATCH2
 #endif
 	EXCEPTION_EPILOG_0
 	rfi
 
<span class="p_add">+#ifdef CONFIG_HUGETLB_PAGE</span>
<span class="p_add">+10:	/* 8M pages */</span>
<span class="p_add">+#ifdef CONFIG_PPC_16K_PAGES</span>
<span class="p_add">+	/* Extract level 2 index */</span>
<span class="p_add">+	rlwinm	r10, r10, 32 - (PAGE_SHIFT_8M - PAGE_SHIFT), 32 + PAGE_SHIFT_8M - (PAGE_SHIFT &lt;&lt; 1), 29</span>
<span class="p_add">+	/* Add level 2 base */</span>
<span class="p_add">+	rlwimi	r10, r11, 0, 0, 32 + PAGE_SHIFT_8M - (PAGE_SHIFT &lt;&lt; 1) - 1</span>
<span class="p_add">+#else</span>
<span class="p_add">+	/* Level 2 base */</span>
<span class="p_add">+	rlwinm	r10, r11, 0, ~HUGEPD_SHIFT_MASK</span>
<span class="p_add">+#endif</span>
<span class="p_add">+	lwz	r10, 0(r10)	/* Get the pte */</span>
<span class="p_add">+	rlwinm	r11, r11, 0, 0xf</span>
<span class="p_add">+	b	4b</span>
<span class="p_add">+</span>
<span class="p_add">+20:	/* 512k pages */</span>
<span class="p_add">+	/* Extract level 2 index */</span>
<span class="p_add">+	rlwinm	r10, r10, 32 - (PAGE_SHIFT_512K - PAGE_SHIFT), 32 + PAGE_SHIFT_512K - (PAGE_SHIFT &lt;&lt; 1), 29</span>
<span class="p_add">+	/* Add level 2 base */</span>
<span class="p_add">+	rlwimi	r10, r11, 0, 0, 32 + PAGE_SHIFT_512K - (PAGE_SHIFT &lt;&lt; 1) - 1</span>
<span class="p_add">+	lwz	r10, 0(r10)	/* Get the pte */</span>
<span class="p_add">+	rlwinm	r11, r11, 0, 0xf</span>
<span class="p_add">+	b	4b</span>
<span class="p_add">+#endif</span>
<span class="p_add">+</span>
 	. = 0x1200
 DataStoreTLBMiss:
 	mtspr	SPRN_SPRG_SCRATCH2, r3
<span class="p_chunk">@@ -408,7 +452,6 @@</span> <span class="p_context"> _ENTRY(DTLBMiss_jmp)</span>
 #endif
 	blt	cr7, DTLBMissLinear
 3:
<span class="p_del">-	mtcr	r3</span>
 	mfspr	r10, SPRN_MD_EPN
 
 	/* Insert level 1 index */
<span class="p_chunk">@@ -419,8 +462,15 @@</span> <span class="p_context"> _ENTRY(DTLBMiss_jmp)</span>
 	 */
 	/* Extract level 2 index */
 	rlwinm	r10, r10, 32 - (PAGE_SHIFT - 2), 32 - PAGE_SHIFT, 29
<span class="p_add">+#ifdef CONFIG_HUGETLB_PAGE</span>
<span class="p_add">+	mtcr	r11</span>
<span class="p_add">+	bt-	28, 10f		/* bit 28 = Large page (8M) */</span>
<span class="p_add">+	bt-	29, 20f		/* bit 29 = Large page (8M or 512k) */</span>
<span class="p_add">+#endif</span>
 	rlwimi	r10, r11, 0, 0, 32 - PAGE_SHIFT - 1	/* Add level 2 base */
 	lwz	r10, 0(r10)	/* Get the pte */
<span class="p_add">+4:</span>
<span class="p_add">+	mtcr	r3</span>
 
 	/* Insert the Guarded flag and APG into the TWC from the Linux PTE.
 	 * It is bit 26-27 of both the Linux PTE and the TWC (at least
<span class="p_chunk">@@ -435,6 +485,11 @@</span> <span class="p_context"> _ENTRY(DTLBMiss_jmp)</span>
 	rlwimi	r11, r10, 32-5, 30, 30
 	MTSPR_CPU6(SPRN_MD_TWC, r11, r3)
 
<span class="p_add">+	/* In 4k pages mode, SPS (bit 28) in RPN must match PS[1] (bit 29)</span>
<span class="p_add">+	 * In 16k pages mode, SPS is always 1 */</span>
<span class="p_add">+#if defined (CONFIG_HUGETLB_PAGE) &amp;&amp; defined (CONFIG_PPC_4K_PAGES)</span>
<span class="p_add">+	rlwimi	r10, r11, 1, MD_SPS16K</span>
<span class="p_add">+#endif</span>
 	/* Both _PAGE_ACCESSED and _PAGE_PRESENT has to be set.
 	 * We also need to know if the insn is a load/store, so:
 	 * Clear _PAGE_PRESENT and load that which will
<span class="p_chunk">@@ -456,7 +511,11 @@</span> <span class="p_context"> _ENTRY(DTLBMiss_jmp)</span>
 	 * of the MMU.
 	 */
 	li	r11, RPN_PATTERN
<span class="p_add">+#if defined (CONFIG_HUGETLB_PAGE) &amp;&amp; defined (CONFIG_PPC_4K_PAGES)</span>
<span class="p_add">+	rlwimi	r10, r11, 0, 24, 27	/* Set 24-27 */</span>
<span class="p_add">+#else</span>
 	rlwimi	r10, r11, 0, 24, 28	/* Set 24-27, clear 28 */
<span class="p_add">+#endif</span>
 	rlwimi	r10, r11, 0, 20, 20	/* clear 20 */
 	MTSPR_CPU6(SPRN_MD_RPN, r10, r3)	/* Update TLB entry */
 
<span class="p_chunk">@@ -466,6 +525,30 @@</span> <span class="p_context"> _ENTRY(DTLBMiss_jmp)</span>
 	EXCEPTION_EPILOG_0
 	rfi
 
<span class="p_add">+#ifdef CONFIG_HUGETLB_PAGE</span>
<span class="p_add">+10:	/* 8M pages */</span>
<span class="p_add">+	/* Extract level 2 index */</span>
<span class="p_add">+#ifdef CONFIG_PPC_16K_PAGES</span>
<span class="p_add">+	rlwinm	r10, r10, 32 - (PAGE_SHIFT_8M - PAGE_SHIFT), 32 + PAGE_SHIFT_8M - (PAGE_SHIFT &lt;&lt; 1), 29</span>
<span class="p_add">+	/* Add level 2 base */</span>
<span class="p_add">+	rlwimi	r10, r11, 0, 0, 32 + PAGE_SHIFT_8M - (PAGE_SHIFT &lt;&lt; 1) - 1</span>
<span class="p_add">+#else</span>
<span class="p_add">+	/* Level 2 base */</span>
<span class="p_add">+	rlwinm	r10, r11, 0, ~HUGEPD_SHIFT_MASK</span>
<span class="p_add">+#endif</span>
<span class="p_add">+	lwz	r10, 0(r10)	/* Get the pte */</span>
<span class="p_add">+	rlwinm	r11, r11, 0, 0xf</span>
<span class="p_add">+	b	4b</span>
<span class="p_add">+</span>
<span class="p_add">+20:	/* 512k pages */</span>
<span class="p_add">+	/* Extract level 2 index */</span>
<span class="p_add">+	rlwinm	r10, r10, 32 - (PAGE_SHIFT_512K - PAGE_SHIFT), 32 + PAGE_SHIFT_512K - (PAGE_SHIFT &lt;&lt; 1), 29</span>
<span class="p_add">+	/* Add level 2 base */</span>
<span class="p_add">+	rlwimi	r10, r11, 0, 0, 32 + PAGE_SHIFT_512K - (PAGE_SHIFT &lt;&lt; 1) - 1</span>
<span class="p_add">+	lwz	r10, 0(r10)	/* Get the pte */</span>
<span class="p_add">+	rlwinm	r11, r11, 0, 0xf</span>
<span class="p_add">+	b	4b</span>
<span class="p_add">+#endif</span>
 
 /* This is an instruction TLB error on the MPC8xx.  This could be due
  * to many reasons, such as executing guarded memory or illegal instruction
<span class="p_chunk">@@ -587,6 +670,9 @@</span> <span class="p_context"> _ENTRY(FixupDAR_cmp)</span>
 	/* Insert level 1 index */
 3:	rlwimi	r11, r10, 32 - ((PAGE_SHIFT - 2) &lt;&lt; 1), (PAGE_SHIFT - 2) &lt;&lt; 1, 29
 	lwz	r11, (swapper_pg_dir-PAGE_OFFSET)@l(r11)	/* Get the level 1 entry */
<span class="p_add">+	mtcr	r11</span>
<span class="p_add">+	bt	28,200f		/* bit 28 = Large page (8M) */</span>
<span class="p_add">+	bt	29,202f		/* bit 29 = Large page (8M or 512K) */</span>
 	rlwinm	r11, r11,0,0,19	/* Extract page descriptor page address */
 	/* Insert level 2 index */
 	rlwimi	r11, r10, 32 - (PAGE_SHIFT - 2), 32 - PAGE_SHIFT, 29
<span class="p_chunk">@@ -612,6 +698,27 @@</span> <span class="p_context"> _ENTRY(FixupDAR_cmp)</span>
 141:	mfspr	r10,SPRN_SPRG_SCRATCH2
 	b	DARFixed	/* Nope, go back to normal TLB processing */
 
<span class="p_add">+	/* concat physical page address(r11) and page offset(r10) */</span>
<span class="p_add">+200:</span>
<span class="p_add">+#ifdef CONFIG_PPC_16K_PAGES</span>
<span class="p_add">+	rlwinm	r11, r11, 0, 0, 32 + PAGE_SHIFT_8M - (PAGE_SHIFT &lt;&lt; 1) - 1</span>
<span class="p_add">+	rlwimi	r11, r10, 32 - (PAGE_SHIFT_8M - 2), 32 + PAGE_SHIFT_8M - (PAGE_SHIFT &lt;&lt; 1), 29</span>
<span class="p_add">+#else</span>
<span class="p_add">+	rlwinm	r11, r10, 0, ~HUGEPD_SHIFT_MASK</span>
<span class="p_add">+#endif</span>
<span class="p_add">+	lwz	r11, 0(r11)	/* Get the pte */</span>
<span class="p_add">+	/* concat physical page address(r11) and page offset(r10) */</span>
<span class="p_add">+	rlwimi	r11, r10, 0, 32 - PAGE_SHIFT_8M, 31</span>
<span class="p_add">+	b	201b</span>
<span class="p_add">+</span>
<span class="p_add">+202:</span>
<span class="p_add">+	rlwinm	r11, r11, 0, 0, 32 + PAGE_SHIFT_512K - (PAGE_SHIFT &lt;&lt; 1) - 1</span>
<span class="p_add">+	rlwimi	r11, r10, 32 - (PAGE_SHIFT_512K - 2), 32 + PAGE_SHIFT_512K - (PAGE_SHIFT &lt;&lt; 1), 29</span>
<span class="p_add">+	lwz	r11, 0(r11)	/* Get the pte */</span>
<span class="p_add">+	/* concat physical page address(r11) and page offset(r10) */</span>
<span class="p_add">+	rlwimi	r11, r10, 0, 32 - PAGE_SHIFT_512K, 31</span>
<span class="p_add">+	b	201b</span>
<span class="p_add">+</span>
 144:	mfspr	r10, SPRN_DSISR
 	rlwinm	r10, r10,0,7,5	/* Clear store bit for buggy dcbst insn */
 	mtspr	SPRN_DSISR, r10
<span class="p_header">diff --git a/arch/powerpc/mm/hugetlbpage.c b/arch/powerpc/mm/hugetlbpage.c</span>
<span class="p_header">index 2119f00..8001821 100644</span>
<span class="p_header">--- a/arch/powerpc/mm/hugetlbpage.c</span>
<span class="p_header">+++ b/arch/powerpc/mm/hugetlbpage.c</span>
<span class="p_chunk">@@ -26,6 +26,8 @@</span> <span class="p_context"></span>
 #ifdef CONFIG_HUGETLB_PAGE
 
 #define PAGE_SHIFT_64K	16
<span class="p_add">+#define PAGE_SHIFT_512K	19</span>
<span class="p_add">+#define PAGE_SHIFT_8M	23</span>
 #define PAGE_SHIFT_16M	24
 #define PAGE_SHIFT_16G	34
 
<span class="p_chunk">@@ -38,7 +40,7 @@</span> <span class="p_context"> unsigned int HPAGE_SHIFT;</span>
  * implementations may have more than one gpage size, so we need multiple
  * arrays
  */
<span class="p_del">-#ifdef CONFIG_PPC_FSL_BOOK3E</span>
<span class="p_add">+#if defined(CONFIG_PPC_FSL_BOOK3E) || defined(CONFIG_PPC_8xx)</span>
 #define MAX_NUMBER_GPAGES	128
 struct psize_gpages {
 	u64 gpage_list[MAX_NUMBER_GPAGES];
<span class="p_chunk">@@ -105,6 +107,11 @@</span> <span class="p_context"> static int __hugepte_alloc(struct mm_struct *mm, hugepd_t *hpdp,</span>
 #ifdef CONFIG_PPC_BOOK3S_64
 			hpdp-&gt;pd = __pa(new) |
 				   (shift_to_mmu_psize(pshift) &lt;&lt; 2);
<span class="p_add">+#elif defined(CONFIG_PPC_8xx)</span>
<span class="p_add">+			hpdp-&gt;pd = __pa(new) |</span>
<span class="p_add">+				   (pshift == PAGE_SHIFT_8M ? _PMD_PAGE_8M :</span>
<span class="p_add">+							      _PMD_PAGE_512K) |</span>
<span class="p_add">+				   _PMD_PRESENT;</span>
 #else
 			/* We use the old format for PPC_FSL_BOOK3E */
 			hpdp-&gt;pd = ((unsigned long)new &amp; ~PD_HUGE) | pshift;
<span class="p_chunk">@@ -124,7 +131,7 @@</span> <span class="p_context"> static int __hugepte_alloc(struct mm_struct *mm, hugepd_t *hpdp,</span>
  * These macros define how to determine which level of the page table holds
  * the hpdp.
  */
<span class="p_del">-#ifdef CONFIG_PPC_FSL_BOOK3E</span>
<span class="p_add">+#if defined(CONFIG_PPC_FSL_BOOK3E) || defined(CONFIG_PPC_8xx)</span>
 #define HUGEPD_PGD_SHIFT PGDIR_SHIFT
 #define HUGEPD_PUD_SHIFT PUD_SHIFT
 #else
<span class="p_chunk">@@ -200,7 +207,7 @@</span> <span class="p_context"> pte_t *huge_pte_alloc(struct mm_struct *mm, unsigned long addr, unsigned long sz</span>
 	return hugepte_offset(*hpdp, addr, pdshift);
 }
 
<span class="p_del">-#ifdef CONFIG_PPC_FSL_BOOK3E</span>
<span class="p_add">+#if defined(CONFIG_PPC_FSL_BOOK3E) || defined(CONFIG_PPC_8xx)</span>
 /* Build list of addresses of gigantic pages.  This function is used in early
  * boot before the buddy allocator is setup.
  */
<span class="p_chunk">@@ -366,7 +373,7 @@</span> <span class="p_context"> int alloc_bootmem_huge_page(struct hstate *hstate)</span>
 }
 #endif
 
<span class="p_del">-#ifdef CONFIG_PPC_FSL_BOOK3E</span>
<span class="p_add">+#if defined(CONFIG_PPC_FSL_BOOK3E) || defined(CONFIG_PPC_8xx)</span>
 #define HUGEPD_FREELIST_SIZE \
 	((PAGE_SIZE - sizeof(struct hugepd_freelist)) / sizeof(pte_t))
 
<span class="p_chunk">@@ -739,10 +746,10 @@</span> <span class="p_context"> static int __init add_huge_page_size(unsigned long long size)</span>
 	 * that it fits within pagetable and slice limits. */
 	if (size &lt;= PAGE_SIZE)
 		return -EINVAL;
<span class="p_del">-#ifdef CONFIG_PPC_FSL_BOOK3E</span>
<span class="p_add">+#if defined(CONFIG_PPC_FSL_BOOK3E)</span>
 	if (!is_power_of_4(size))
 		return -EINVAL;
<span class="p_del">-#else</span>
<span class="p_add">+#elif !defined(CONFIG_PPC_8xx)</span>
 	if (!is_power_of_2(size) || (shift &gt; SLICE_HIGH_SHIFT))
 		return -EINVAL;
 #endif
<span class="p_chunk">@@ -781,7 +788,7 @@</span> <span class="p_context"> static int __init hugetlbpage_init(void)</span>
 {
 	int psize;
 
<span class="p_del">-#if !defined(CONFIG_PPC_FSL_BOOK3E)</span>
<span class="p_add">+#if !defined(CONFIG_PPC_FSL_BOOK3E) &amp;&amp; !defined(CONFIG_PPC_8xx)</span>
 	if (!radix_enabled() &amp;&amp; !mmu_has_feature(MMU_FTR_16M_PAGE))
 		return -ENODEV;
 #endif
<span class="p_chunk">@@ -830,7 +837,7 @@</span> <span class="p_context"> static int __init hugetlbpage_init(void)</span>
 	}
 
 	/* Set default large page size. Currently, we pick 16M or 1M
<span class="p_del">-	 * depending on what is available</span>
<span class="p_add">+	 * depending on what is available. On PPC_8xx we select 512K.</span>
 	 * We select 4M on other ones.
 	 */
 	if (mmu_psize_defs[MMU_PAGE_16M].shift)
<span class="p_chunk">@@ -841,6 +848,8 @@</span> <span class="p_context"> static int __init hugetlbpage_init(void)</span>
 		HPAGE_SHIFT = mmu_psize_defs[MMU_PAGE_2M].shift;
 	else if (mmu_psize_defs[MMU_PAGE_4M].shift)
 		HPAGE_SHIFT = mmu_psize_defs[MMU_PAGE_4M].shift;
<span class="p_add">+	else if (mmu_psize_defs[MMU_PAGE_512K].shift)</span>
<span class="p_add">+		HPAGE_SHIFT = mmu_psize_defs[MMU_PAGE_512K].shift;</span>
 	else
 		panic(&quot;%s: Unable to set default huge page size\n&quot;, __func__);
 
<span class="p_header">diff --git a/arch/powerpc/mm/tlb_nohash.c b/arch/powerpc/mm/tlb_nohash.c</span>
<span class="p_header">index 050badc..ba28fcb 100644</span>
<span class="p_header">--- a/arch/powerpc/mm/tlb_nohash.c</span>
<span class="p_header">+++ b/arch/powerpc/mm/tlb_nohash.c</span>
<span class="p_chunk">@@ -53,7 +53,7 @@</span> <span class="p_context"></span>
  * other sizes not listed here.   The .ind field is only used on MMUs that have
  * indirect page table entries.
  */
<span class="p_del">-#ifdef CONFIG_PPC_BOOK3E_MMU</span>
<span class="p_add">+#if defined(CONFIG_PPC_BOOK3E_MMU) || defined(CONFIG_PPC_8xx)</span>
 #ifdef CONFIG_PPC_FSL_BOOK3E
 struct mmu_psize_def mmu_psize_defs[MMU_PAGE_COUNT] = {
 	[MMU_PAGE_4K] = {
<span class="p_chunk">@@ -85,6 +85,25 @@</span> <span class="p_context"> struct mmu_psize_def mmu_psize_defs[MMU_PAGE_COUNT] = {</span>
 		.enc	= BOOK3E_PAGESZ_1GB,
 	},
 };
<span class="p_add">+#elif defined(CONFIG_PPC_8xx)</span>
<span class="p_add">+struct mmu_psize_def mmu_psize_defs[MMU_PAGE_COUNT] = {</span>
<span class="p_add">+	/* we only manage 4k and 16k pages as normal pages */</span>
<span class="p_add">+#ifdef CONFIG_PPC_4K_PAGES</span>
<span class="p_add">+	[MMU_PAGE_4K] = {</span>
<span class="p_add">+		.shift	= 12,</span>
<span class="p_add">+	},</span>
<span class="p_add">+#else</span>
<span class="p_add">+	[MMU_PAGE_16K] = {</span>
<span class="p_add">+		.shift	= 14,</span>
<span class="p_add">+	},</span>
<span class="p_add">+#endif</span>
<span class="p_add">+	[MMU_PAGE_512K] = {</span>
<span class="p_add">+		.shift	= 19,</span>
<span class="p_add">+	},</span>
<span class="p_add">+	[MMU_PAGE_8M] = {</span>
<span class="p_add">+		.shift	= 23,</span>
<span class="p_add">+	},</span>
<span class="p_add">+};</span>
 #else
 struct mmu_psize_def mmu_psize_defs[MMU_PAGE_COUNT] = {
 	[MMU_PAGE_4K] = {
<span class="p_header">diff --git a/arch/powerpc/platforms/8xx/Kconfig b/arch/powerpc/platforms/8xx/Kconfig</span>
<span class="p_header">index 564d99b..80cbcb0 100644</span>
<span class="p_header">--- a/arch/powerpc/platforms/8xx/Kconfig</span>
<span class="p_header">+++ b/arch/powerpc/platforms/8xx/Kconfig</span>
<span class="p_chunk">@@ -130,6 +130,7 @@</span> <span class="p_context"> config 8xx_CPU6</span>
 
 config 8xx_CPU15
 	bool &quot;CPU15 Silicon Errata&quot;
<span class="p_add">+	depends on !HUGETLB_PAGE</span>
 	default y
 	help
 	  This enables a workaround for erratum CPU15 on MPC8xx chips.
<span class="p_header">diff --git a/arch/powerpc/platforms/Kconfig.cputype b/arch/powerpc/platforms/Kconfig.cputype</span>
<span class="p_header">index f32edec..59887ad 100644</span>
<span class="p_header">--- a/arch/powerpc/platforms/Kconfig.cputype</span>
<span class="p_header">+++ b/arch/powerpc/platforms/Kconfig.cputype</span>
<span class="p_chunk">@@ -34,6 +34,7 @@</span> <span class="p_context"> config PPC_8xx</span>
 	select FSL_SOC
 	select 8xx
 	select PPC_LIB_RHEAP
<span class="p_add">+	select SYS_SUPPORTS_HUGETLBFS</span>
 
 config 40x
 	bool &quot;AMCC 40x&quot;

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



