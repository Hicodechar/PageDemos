
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>[2/3] mm/hugetlb: Setup hugetlb_falloc during fallocate hole punch - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    [2/3] mm/hugetlb: Setup hugetlb_falloc during fallocate hole punch</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=41">Andrew Morton</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>Oct. 19, 2015, 11:16 p.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;20151019161642.68e787103cacb613d372b5c4@linux-foundation.org&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/7440501/mbox/"
   >mbox</a>
|
   <a href="/patch/7440501/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/7440501/">/patch/7440501/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
X-Original-To: patchwork-LKML@patchwork.kernel.org
Delivered-To: patchwork-parsemail@patchwork2.web.kernel.org
Received: from mail.kernel.org (mail.kernel.org [198.145.29.136])
	by patchwork2.web.kernel.org (Postfix) with ESMTP id 8A350BEEA4
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Mon, 19 Oct 2015 23:16:51 +0000 (UTC)
Received: from mail.kernel.org (localhost [127.0.0.1])
	by mail.kernel.org (Postfix) with ESMTP id A337C2062A
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Mon, 19 Oct 2015 23:16:50 +0000 (UTC)
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.kernel.org (Postfix) with ESMTP id 87CE32065D
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Mon, 19 Oct 2015 23:16:49 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1751725AbbJSXQq (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Mon, 19 Oct 2015 19:16:46 -0400
Received: from mail.linuxfoundation.org ([140.211.169.12]:48274 &quot;EHLO
	mail.linuxfoundation.org&quot; rhost-flags-OK-OK-OK-OK) by vger.kernel.org
	with ESMTP id S1751182AbbJSXQn (ORCPT
	&lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Mon, 19 Oct 2015 19:16:43 -0400
Received: from akpm3.mtv.corp.google.com (unknown [216.239.45.65])
	by mail.linuxfoundation.org (Postfix) with ESMTPSA id CC314412;
	Mon, 19 Oct 2015 23:16:42 +0000 (UTC)
Date: Mon, 19 Oct 2015 16:16:42 -0700
From: Andrew Morton &lt;akpm@linux-foundation.org&gt;
To: Mike Kravetz &lt;mike.kravetz@oracle.com&gt;
Cc: linux-mm@kvack.org, linux-kernel@vger.kernel.org,
	Dave Hansen &lt;dave.hansen@linux.intel.com&gt;,
	Naoya Horiguchi &lt;n-horiguchi@ah.jp.nec.com&gt;,
	Hugh Dickins &lt;hughd@google.com&gt;, Davidlohr Bueso &lt;dave@stgolabs.net&gt;
Subject: Re: [PATCH 2/3] mm/hugetlb: Setup hugetlb_falloc during fallocate
	hole punch
Message-Id: &lt;20151019161642.68e787103cacb613d372b5c4@linux-foundation.org&gt;
In-Reply-To: &lt;1445033310-13155-3-git-send-email-mike.kravetz@oracle.com&gt;
References: &lt;1445033310-13155-1-git-send-email-mike.kravetz@oracle.com&gt;
	&lt;1445033310-13155-3-git-send-email-mike.kravetz@oracle.com&gt;
X-Mailer: Sylpheed 3.4.1 (GTK+ 2.24.23; x86_64-pc-linux-gnu)
Mime-Version: 1.0
Content-Type: text/plain; charset=US-ASCII
Content-Transfer-Encoding: 7bit
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Spam-Status: No, score=-6.9 required=5.0 tests=BAYES_00, RCVD_IN_DNSWL_HI, 
	RP_MATCHES_RCVD,
	UNPARSEABLE_RELAY autolearn=unavailable version=3.3.1
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on mail.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=41">Andrew Morton</a> - Oct. 19, 2015, 11:16 p.m.</div>
<pre class="content">
On Fri, 16 Oct 2015 15:08:29 -0700 Mike Kravetz &lt;mike.kravetz@oracle.com&gt; wrote:
<span class="quote">
&gt; When performing a fallocate hole punch, set up a hugetlb_falloc struct</span>
<span class="quote">&gt; and make i_private point to it.  i_private will point to this struct for</span>
<span class="quote">&gt; the duration of the operation.  At the end of the operation, wake up</span>
<span class="quote">&gt; anyone who faulted on the hole and is on the waitq.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; ...</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; --- a/fs/hugetlbfs/inode.c</span>
<span class="quote">&gt; +++ b/fs/hugetlbfs/inode.c</span>
<span class="quote">&gt; @@ -507,7 +507,9 @@ static long hugetlbfs_punch_hole(struct inode *inode, loff_t offset, loff_t len)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	struct hstate *h = hstate_inode(inode);</span>
<span class="quote">&gt;  	loff_t hpage_size = huge_page_size(h);</span>
<span class="quote">&gt; +	unsigned long hpage_shift = huge_page_shift(h);</span>
<span class="quote">&gt;  	loff_t hole_start, hole_end;</span>
<span class="quote">&gt; +	struct hugetlb_falloc hugetlb_falloc;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	/*</span>
<span class="quote">&gt;  	 * For hole punch round up the beginning offset of the hole and</span>
<span class="quote">&gt; @@ -518,8 +520,23 @@ static long hugetlbfs_punch_hole(struct inode *inode, loff_t offset, loff_t len)</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	if (hole_end &gt; hole_start) {</span>
<span class="quote">&gt;  		struct address_space *mapping = inode-&gt;i_mapping;</span>
<span class="quote">&gt; +		DECLARE_WAIT_QUEUE_HEAD_ONSTACK(hugetlb_falloc_waitq);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +		/*</span>
<span class="quote">&gt; +		 * Page faults on the area to be hole punched must be</span>
<span class="quote">&gt; +		 * stopped during the operation.  Initialize struct and</span>
<span class="quote">&gt; +		 * have inode-&gt;i_private point to it.</span>
<span class="quote">&gt; +		 */</span>
<span class="quote">&gt; +		hugetlb_falloc.waitq = &amp;hugetlb_falloc_waitq;</span>
<span class="quote">&gt; +		hugetlb_falloc.start = hole_start &gt;&gt; hpage_shift;</span>
<span class="quote">&gt; +		hugetlb_falloc.end = hole_end &gt;&gt; hpage_shift;</span>

This is a bit neater:
<span class="quote">

&gt;  		mutex_lock(&amp;inode-&gt;i_mutex);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +		spin_lock(&amp;inode-&gt;i_lock);</span>
<span class="quote">&gt; +		inode-&gt;i_private = &amp;hugetlb_falloc;</span>
<span class="quote">&gt; +		spin_unlock(&amp;inode-&gt;i_lock);</span>

Locking around a single atomic assignment is a bit peculiar.  I can
kinda see that it kinda protects the logic in hugetlb_fault(), but I
would like to hear (in comment form) your description of how this logic
works?
<span class="quote">
&gt;  		i_mmap_lock_write(mapping);</span>
<span class="quote">&gt;  		if (!RB_EMPTY_ROOT(&amp;mapping-&gt;i_mmap))</span>
<span class="quote">&gt;  			hugetlb_vmdelete_list(&amp;mapping-&gt;i_mmap,</span>

--
To unsubscribe from this list: send the line &quot;unsubscribe linux-kernel&quot; in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
Please read the FAQ at  http://www.tux.org/lkml/
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=124511">Mike Kravetz</a> - Oct. 20, 2015, 1:41 a.m.</div>
<pre class="content">
On 10/19/2015 04:16 PM, Andrew Morton wrote:
<span class="quote">&gt; On Fri, 16 Oct 2015 15:08:29 -0700 Mike Kravetz &lt;mike.kravetz@oracle.com&gt; wrote:</span>
<span class="quote">&gt; </span>
<span class="quote">&gt;&gt; When performing a fallocate hole punch, set up a hugetlb_falloc struct</span>
<span class="quote">&gt;&gt; and make i_private point to it.  i_private will point to this struct for</span>
<span class="quote">&gt;&gt; the duration of the operation.  At the end of the operation, wake up</span>
<span class="quote">&gt;&gt; anyone who faulted on the hole and is on the waitq.</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; ...</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; --- a/fs/hugetlbfs/inode.c</span>
<span class="quote">&gt;&gt; +++ b/fs/hugetlbfs/inode.c</span>
<span class="quote">&gt;&gt; @@ -507,7 +507,9 @@ static long hugetlbfs_punch_hole(struct inode *inode, loff_t offset, loff_t len)</span>
<span class="quote">&gt;&gt;  {</span>
<span class="quote">&gt;&gt;  	struct hstate *h = hstate_inode(inode);</span>
<span class="quote">&gt;&gt;  	loff_t hpage_size = huge_page_size(h);</span>
<span class="quote">&gt;&gt; +	unsigned long hpage_shift = huge_page_shift(h);</span>
<span class="quote">&gt;&gt;  	loff_t hole_start, hole_end;</span>
<span class="quote">&gt;&gt; +	struct hugetlb_falloc hugetlb_falloc;</span>
<span class="quote">&gt;&gt;  </span>
<span class="quote">&gt;&gt;  	/*</span>
<span class="quote">&gt;&gt;  	 * For hole punch round up the beginning offset of the hole and</span>
<span class="quote">&gt;&gt; @@ -518,8 +520,23 @@ static long hugetlbfs_punch_hole(struct inode *inode, loff_t offset, loff_t len)</span>
<span class="quote">&gt;&gt;  </span>
<span class="quote">&gt;&gt;  	if (hole_end &gt; hole_start) {</span>
<span class="quote">&gt;&gt;  		struct address_space *mapping = inode-&gt;i_mapping;</span>
<span class="quote">&gt;&gt; +		DECLARE_WAIT_QUEUE_HEAD_ONSTACK(hugetlb_falloc_waitq);</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +		/*</span>
<span class="quote">&gt;&gt; +		 * Page faults on the area to be hole punched must be</span>
<span class="quote">&gt;&gt; +		 * stopped during the operation.  Initialize struct and</span>
<span class="quote">&gt;&gt; +		 * have inode-&gt;i_private point to it.</span>
<span class="quote">&gt;&gt; +		 */</span>
<span class="quote">&gt;&gt; +		hugetlb_falloc.waitq = &amp;hugetlb_falloc_waitq;</span>
<span class="quote">&gt;&gt; +		hugetlb_falloc.start = hole_start &gt;&gt; hpage_shift;</span>
<span class="quote">&gt;&gt; +		hugetlb_falloc.end = hole_end &gt;&gt; hpage_shift;</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; This is a bit neater:</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; --- a/fs/hugetlbfs/inode.c~mm-hugetlb-setup-hugetlb_falloc-during-fallocate-hole-punch-fix</span>
<span class="quote">&gt; +++ a/fs/hugetlbfs/inode.c</span>
<span class="quote">&gt; @@ -509,7 +509,6 @@ static long hugetlbfs_punch_hole(struct</span>
<span class="quote">&gt;  	loff_t hpage_size = huge_page_size(h);</span>
<span class="quote">&gt;  	unsigned long hpage_shift = huge_page_shift(h);</span>
<span class="quote">&gt;  	loff_t hole_start, hole_end;</span>
<span class="quote">&gt; -	struct hugetlb_falloc hugetlb_falloc;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	/*</span>
<span class="quote">&gt;  	 * For hole punch round up the beginning offset of the hole and</span>
<span class="quote">&gt; @@ -521,15 +520,16 @@ static long hugetlbfs_punch_hole(struct</span>
<span class="quote">&gt;  	if (hole_end &gt; hole_start) {</span>
<span class="quote">&gt;  		struct address_space *mapping = inode-&gt;i_mapping;</span>
<span class="quote">&gt;  		DECLARE_WAIT_QUEUE_HEAD_ONSTACK(hugetlb_falloc_waitq);</span>
<span class="quote">&gt; -</span>
<span class="quote">&gt;  		/*</span>
<span class="quote">&gt; -		 * Page faults on the area to be hole punched must be</span>
<span class="quote">&gt; -		 * stopped during the operation.  Initialize struct and</span>
<span class="quote">&gt; -		 * have inode-&gt;i_private point to it.</span>
<span class="quote">&gt; +		 * Page faults on the area to be hole punched must be stopped</span>
<span class="quote">&gt; +		 * during the operation.  Initialize struct and have</span>
<span class="quote">&gt; +		 * inode-&gt;i_private point to it.</span>
<span class="quote">&gt;  		 */</span>
<span class="quote">&gt; -		hugetlb_falloc.waitq = &amp;hugetlb_falloc_waitq;</span>
<span class="quote">&gt; -		hugetlb_falloc.start = hole_start &gt;&gt; hpage_shift;</span>
<span class="quote">&gt; -		hugetlb_falloc.end = hole_end &gt;&gt; hpage_shift;</span>
<span class="quote">&gt; +		struct hugetlb_falloc hugetlb_falloc = {</span>
<span class="quote">&gt; +			.waitq = &amp;hugetlb_falloc_waitq,</span>
<span class="quote">&gt; +			.start = hole_start &gt;&gt; hpage_shift,</span>
<span class="quote">&gt; +			.end = hole_end &gt;&gt; hpage_shift</span>
<span class="quote">&gt; +		};</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  		mutex_lock(&amp;inode-&gt;i_mutex);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; </span>

Thanks!
<span class="quote">
&gt;&gt;  		mutex_lock(&amp;inode-&gt;i_mutex);</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +		spin_lock(&amp;inode-&gt;i_lock);</span>
<span class="quote">&gt;&gt; +		inode-&gt;i_private = &amp;hugetlb_falloc;</span>
<span class="quote">&gt;&gt; +		spin_unlock(&amp;inode-&gt;i_lock);</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Locking around a single atomic assignment is a bit peculiar.  I can</span>
<span class="quote">&gt; kinda see that it kinda protects the logic in hugetlb_fault(), but I</span>
<span class="quote">&gt; would like to hear (in comment form) your description of how this logic</span>
<span class="quote">&gt; works?</span>

To be honest, this code/scheme was copied from shmem as it addresses
the same situation there.  I did not notice how strange this looks until
you pointed it out.  At first glance, the locking does appear to be
unnecessary.  The fault code initially checks this value outside the
lock.  However, the fault code (on another CPU) will take the lock
and access values within the structure.  Without the locking or some other
type of memory barrier here, there is no guarantee that the structure
will be initialized before setting i_private.  So, the faulting code
could see invalid values in the structure.

Hugh, is that accurate?  You provided the shmem code.
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=7851">Hugh Dickins</a> - Oct. 20, 2015, 2:22 a.m.</div>
<pre class="content">
On Mon, 19 Oct 2015, Mike Kravetz wrote:
<span class="quote">&gt; On 10/19/2015 04:16 PM, Andrew Morton wrote:</span>
<span class="quote">&gt; &gt; On Fri, 16 Oct 2015 15:08:29 -0700 Mike Kravetz &lt;mike.kravetz@oracle.com&gt; wrote:</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; &gt;&gt;  		mutex_lock(&amp;inode-&gt;i_mutex);</span>
<span class="quote">&gt; &gt;&gt; +</span>
<span class="quote">&gt; &gt;&gt; +		spin_lock(&amp;inode-&gt;i_lock);</span>
<span class="quote">&gt; &gt;&gt; +		inode-&gt;i_private = &amp;hugetlb_falloc;</span>
<span class="quote">&gt; &gt;&gt; +		spin_unlock(&amp;inode-&gt;i_lock);</span>
<span class="quote">&gt; &gt; </span>
<span class="quote">&gt; &gt; Locking around a single atomic assignment is a bit peculiar.  I can</span>
<span class="quote">&gt; &gt; kinda see that it kinda protects the logic in hugetlb_fault(), but I</span>
<span class="quote">&gt; &gt; would like to hear (in comment form) your description of how this logic</span>
<span class="quote">&gt; &gt; works?</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; To be honest, this code/scheme was copied from shmem as it addresses</span>
<span class="quote">&gt; the same situation there.  I did not notice how strange this looks until</span>
<span class="quote">&gt; you pointed it out.  At first glance, the locking does appear to be</span>
<span class="quote">&gt; unnecessary.  The fault code initially checks this value outside the</span>
<span class="quote">&gt; lock.  However, the fault code (on another CPU) will take the lock</span>
<span class="quote">&gt; and access values within the structure.  Without the locking or some other</span>
<span class="quote">&gt; type of memory barrier here, there is no guarantee that the structure</span>
<span class="quote">&gt; will be initialized before setting i_private.  So, the faulting code</span>
<span class="quote">&gt; could see invalid values in the structure.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Hugh, is that accurate?  You provided the shmem code.</span>

Yes, I think that&#39;s accurate; but confess I&#39;m replying now for the
sake of replying in a rare timely fashion, before having spent any
time looking through your hugetlbfs reimplementation of the same.

The peculiar thing in the shmem case, was that the structure being
pointed to is on the kernel stack of the fallocating task (with
i_mutex guaranteeing only one at a time per file could be doing this):
so the faulting end has to be careful that it&#39;s not accessing the
stale memory after the fallocator has retreated back up its stack.

And in the shmem case, this &quot;temporary inode extension&quot; also had to
communicate to shmem_writepage(), the swapout end of things.  Which
is not a complication you have with hugetlbfs: perhaps it could be
simpler if just between fallocate and fault, or perhaps not.

Whilst it does all work for tmpfs, it looks as if tmpfs was ahead of
the pack (or trinity was attacking tmpfs before other filesystems),
and the issue of faulting versus holepunching (and DAX) has captured
wider interest recently, with Dave Chinner formulating answers in XFS,
and hoping to set an example for other filesystems.

If that work were further along, and if I had had time to digest any
of what he is doing about it, I would point you in his direction rather
than this; but since this does work for tmpfs, I shouldn&#39;t discourage you.

I&#39;ll try to take a look through yours in the coming days, but there&#39;s
several other patchsets I need to look through too, plus a few more
patches from me, if I can find time to send them in: juggling priorities.

Hugh
--
To unsubscribe from this list: send the line &quot;unsubscribe linux-kernel&quot; in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
Please read the FAQ at  http://www.tux.org/lkml/
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=124511">Mike Kravetz</a> - Oct. 20, 2015, 3:12 a.m.</div>
<pre class="content">
On 10/19/2015 07:22 PM, Hugh Dickins wrote:
<span class="quote">&gt; On Mon, 19 Oct 2015, Mike Kravetz wrote:</span>
<span class="quote">&gt;&gt; On 10/19/2015 04:16 PM, Andrew Morton wrote:</span>
<span class="quote">&gt;&gt;&gt; On Fri, 16 Oct 2015 15:08:29 -0700 Mike Kravetz &lt;mike.kravetz@oracle.com&gt; wrote:</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt;&gt;  		mutex_lock(&amp;inode-&gt;i_mutex);</span>
<span class="quote">&gt;&gt;&gt;&gt; +</span>
<span class="quote">&gt;&gt;&gt;&gt; +		spin_lock(&amp;inode-&gt;i_lock);</span>
<span class="quote">&gt;&gt;&gt;&gt; +		inode-&gt;i_private = &amp;hugetlb_falloc;</span>
<span class="quote">&gt;&gt;&gt;&gt; +		spin_unlock(&amp;inode-&gt;i_lock);</span>
<span class="quote">&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt; Locking around a single atomic assignment is a bit peculiar.  I can</span>
<span class="quote">&gt;&gt;&gt; kinda see that it kinda protects the logic in hugetlb_fault(), but I</span>
<span class="quote">&gt;&gt;&gt; would like to hear (in comment form) your description of how this logic</span>
<span class="quote">&gt;&gt;&gt; works?</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; To be honest, this code/scheme was copied from shmem as it addresses</span>
<span class="quote">&gt;&gt; the same situation there.  I did not notice how strange this looks until</span>
<span class="quote">&gt;&gt; you pointed it out.  At first glance, the locking does appear to be</span>
<span class="quote">&gt;&gt; unnecessary.  The fault code initially checks this value outside the</span>
<span class="quote">&gt;&gt; lock.  However, the fault code (on another CPU) will take the lock</span>
<span class="quote">&gt;&gt; and access values within the structure.  Without the locking or some other</span>
<span class="quote">&gt;&gt; type of memory barrier here, there is no guarantee that the structure</span>
<span class="quote">&gt;&gt; will be initialized before setting i_private.  So, the faulting code</span>
<span class="quote">&gt;&gt; could see invalid values in the structure.</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; Hugh, is that accurate?  You provided the shmem code.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Yes, I think that&#39;s accurate; but confess I&#39;m replying now for the</span>
<span class="quote">&gt; sake of replying in a rare timely fashion, before having spent any</span>
<span class="quote">&gt; time looking through your hugetlbfs reimplementation of the same.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; The peculiar thing in the shmem case, was that the structure being</span>
<span class="quote">&gt; pointed to is on the kernel stack of the fallocating task (with</span>
<span class="quote">&gt; i_mutex guaranteeing only one at a time per file could be doing this):</span>
<span class="quote">&gt; so the faulting end has to be careful that it&#39;s not accessing the</span>
<span class="quote">&gt; stale memory after the fallocator has retreated back up its stack.</span>

I used the same code/scheme for hugetlbfs.
<span class="quote">
&gt; And in the shmem case, this &quot;temporary inode extension&quot; also had to</span>
<span class="quote">&gt; communicate to shmem_writepage(), the swapout end of things.  Which</span>
<span class="quote">&gt; is not a complication you have with hugetlbfs: perhaps it could be</span>
<span class="quote">&gt; simpler if just between fallocate and fault, or perhaps not.</span>

Yes, I think it is simpler.  At first I was excited because hugetlbfs
already has a table of mutex&#39;es to synchronize page faults. and I
thought about using those.  If the hole being punched is small this
works fine.  But, for large holes you could end up taking all mutexes
and prevent all huge page faults. :(  So, I went back to the scheme
employed by shmem.
<span class="quote">
&gt; Whilst it does all work for tmpfs, it looks as if tmpfs was ahead of</span>
<span class="quote">&gt; the pack (or trinity was attacking tmpfs before other filesystems),</span>
<span class="quote">&gt; and the issue of faulting versus holepunching (and DAX) has captured</span>
<span class="quote">&gt; wider interest recently, with Dave Chinner formulating answers in XFS,</span>
<span class="quote">&gt; and hoping to set an example for other filesystems.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; If that work were further along, and if I had had time to digest any</span>
<span class="quote">&gt; of what he is doing about it, I would point you in his direction rather</span>
<span class="quote">&gt; than this; but since this does work for tmpfs, I shouldn&#39;t discourage you.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; I&#39;ll try to take a look through yours in the coming days, but there&#39;s</span>
<span class="quote">&gt; several other patchsets I need to look through too, plus a few more</span>
<span class="quote">&gt; patches from me, if I can find time to send them in: juggling priorities.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Hugh</span>

Thanks, and no hurry.  I need to add a little more code to this this patch
set to completely handle the race.  A new patch will be out in a day or two.
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">--- a/fs/hugetlbfs/inode.c~mm-hugetlb-setup-hugetlb_falloc-during-fallocate-hole-punch-fix</span>
<span class="p_header">+++ a/fs/hugetlbfs/inode.c</span>
<span class="p_chunk">@@ -509,7 +509,6 @@</span> <span class="p_context"> static long hugetlbfs_punch_hole(struct</span>
 	loff_t hpage_size = huge_page_size(h);
 	unsigned long hpage_shift = huge_page_shift(h);
 	loff_t hole_start, hole_end;
<span class="p_del">-	struct hugetlb_falloc hugetlb_falloc;</span>
 
 	/*
 	 * For hole punch round up the beginning offset of the hole and
<span class="p_chunk">@@ -521,15 +520,16 @@</span> <span class="p_context"> static long hugetlbfs_punch_hole(struct</span>
 	if (hole_end &gt; hole_start) {
 		struct address_space *mapping = inode-&gt;i_mapping;
 		DECLARE_WAIT_QUEUE_HEAD_ONSTACK(hugetlb_falloc_waitq);
<span class="p_del">-</span>
 		/*
<span class="p_del">-		 * Page faults on the area to be hole punched must be</span>
<span class="p_del">-		 * stopped during the operation.  Initialize struct and</span>
<span class="p_del">-		 * have inode-&gt;i_private point to it.</span>
<span class="p_add">+		 * Page faults on the area to be hole punched must be stopped</span>
<span class="p_add">+		 * during the operation.  Initialize struct and have</span>
<span class="p_add">+		 * inode-&gt;i_private point to it.</span>
 		 */
<span class="p_del">-		hugetlb_falloc.waitq = &amp;hugetlb_falloc_waitq;</span>
<span class="p_del">-		hugetlb_falloc.start = hole_start &gt;&gt; hpage_shift;</span>
<span class="p_del">-		hugetlb_falloc.end = hole_end &gt;&gt; hpage_shift;</span>
<span class="p_add">+		struct hugetlb_falloc hugetlb_falloc = {</span>
<span class="p_add">+			.waitq = &amp;hugetlb_falloc_waitq,</span>
<span class="p_add">+			.start = hole_start &gt;&gt; hpage_shift,</span>
<span class="p_add">+			.end = hole_end &gt;&gt; hpage_shift</span>
<span class="p_add">+		};</span>
 
 		mutex_lock(&amp;inode-&gt;i_mutex);
 

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



