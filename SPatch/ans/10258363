
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>[-V2,-mm] mm: Fix races between swapoff and flush dcache - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    [-V2,-mm] mm: Fix races between swapoff and flush dcache</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=294">Huang Ying</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>March 5, 2018, 8:36 a.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;20180305083634.15174-1-ying.huang@intel.com&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/10258363/mbox/"
   >mbox</a>
|
   <a href="/patch/10258363/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/10258363/">/patch/10258363/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
	[172.30.200.125])
	by pdx-korg-patchwork.web.codeaurora.org (Postfix) with ESMTP id
	47FC760211 for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Mon,  5 Mar 2018 08:37:11 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 355CF2894B
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Mon,  5 Mar 2018 08:37:11 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id 297BC2897D; Mon,  5 Mar 2018 08:37:11 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-6.9 required=2.0 tests=BAYES_00,RCVD_IN_DNSWL_HI
	autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id B12F32894B
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Mon,  5 Mar 2018 08:37:09 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S933058AbeCEIhG (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Mon, 5 Mar 2018 03:37:06 -0500
Received: from mga11.intel.com ([192.55.52.93]:50052 &quot;EHLO mga11.intel.com&quot;
	rhost-flags-OK-OK-OK-OK) by vger.kernel.org with ESMTP
	id S1752390AbeCEIhD (ORCPT &lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Mon, 5 Mar 2018 03:37:03 -0500
X-Amp-Result: SKIPPED(no attachment in message)
X-Amp-File-Uploaded: False
Received: from orsmga005.jf.intel.com ([10.7.209.41])
	by fmsmga102.fm.intel.com with ESMTP/TLS/DHE-RSA-AES256-GCM-SHA384;
	05 Mar 2018 00:37:02 -0800
X-ExtLoop1: 1
X-IronPort-AV: E=Sophos;i=&quot;5.47,426,1515484800&quot;; d=&quot;scan&#39;208&quot;;a=&quot;205540984&quot;
Received: from yhuang-dev.sh.intel.com ([10.239.13.10])
	by orsmga005.jf.intel.com with ESMTP; 05 Mar 2018 00:36:58 -0800
From: &quot;Huang, Ying&quot; &lt;ying.huang@intel.com&gt;
To: Andrew Morton &lt;akpm@linux-foundation.org&gt;
Cc: linux-mm@kvack.org, linux-kernel@vger.kernel.org,
	Huang Ying &lt;ying.huang@intel.com&gt;, Minchan Kim &lt;minchan@kernel.org&gt;,
	Michal Hocko &lt;mhocko@suse.com&gt;, Johannes Weiner &lt;hannes@cmpxchg.org&gt;,
	Mel Gorman &lt;mgorman@techsingularity.net&gt;,
	Dave Hansen &lt;dave.hansen@intel.com&gt;, Chen Liqin &lt;liqin.linux@gmail.com&gt;,
	Russell King &lt;linux@armlinux.org.uk&gt;,
	Yoshinori Sato &lt;ysato@users.sourceforge.jp&gt;,
	&quot;James E.J. Bottomley&quot; &lt;jejb@parisc-linux.org&gt;,
	Guan Xuetao &lt;gxt@mprc.pku.edu.cn&gt;,
	&quot;David S. Miller&quot; &lt;davem@davemloft.net&gt;, Chris Zankel &lt;chris@zankel.net&gt;,
	Vineet Gupta &lt;vgupta@synopsys.com&gt;, Ley Foon Tan &lt;lftan@altera.com&gt;,
	Ralf Baechle &lt;ralf@linux-mips.org&gt;, Andi Kleen &lt;ak@linux.intel.com&gt;
Subject: [PATCH -V2 -mm] mm: Fix races between swapoff and flush dcache
Date: Mon,  5 Mar 2018 16:36:34 +0800
Message-Id: &lt;20180305083634.15174-1-ying.huang@intel.com&gt;
X-Mailer: git-send-email 2.15.1
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=294">Huang Ying</a> - March 5, 2018, 8:36 a.m.</div>
<pre class="content">
<span class="from">From: Huang Ying &lt;ying.huang@intel.com&gt;</span>

From commit 4b3ef9daa4fc (&quot;mm/swap: split swap cache into 64MB
trunks&quot;) on, after swapoff, the address_space associated with the swap
device will be freed.  So page_mapping() users which may touch the
address_space need some kind of mechanism to prevent the address_space
from being freed during accessing.

The dcache flushing functions (flush_dcache_page(), etc) in
architecture specific code may access the address_space of swap device
for anonymous pages in swap cache via page_mapping() function.  But in
some cases there are no mechanisms to prevent the swap device from
being swapoff, for example,

CPU1					CPU2
__get_user_pages()			swapoff()
  flush_dcache_page()
    mapping = page_mapping()
      ...				  exit_swap_address_space()
      ...				    kvfree(spaces)
      mapping_mapped(mapping)

The address space may be accessed after being freed.

But from cachetlb.txt and Russell King, flush_dcache_page() only care
about file cache pages, for anonymous pages, flush_anon_page() should
be used.  The implementation of flush_dcache_page() in all
architectures follows this too.  They will check whether
page_mapping() is NULL and whether mapping_mapped() is true to
determine whether to flush the dcache immediately.  And they will use
interval tree (mapping-&gt;i_mmap) to find all user space mappings.
While mapping_mapped() and mapping-&gt;i_mmap isn&#39;t used by anonymous
pages in swap cache at all.

So, to fix the race between swapoff and flush dcache, __page_mapping()
is add to return the address_space for file cache pages and NULL
otherwise.  All page_mapping() invoking in flush dcache functions are
replaced with __page_mapping().
<span class="signed-off-by">
Signed-off-by: &quot;Huang, Ying&quot; &lt;ying.huang@intel.com&gt;</span>
Cc: Minchan Kim &lt;minchan@kernel.org&gt;
Cc: Michal Hocko &lt;mhocko@suse.com&gt;
Cc: Johannes Weiner &lt;hannes@cmpxchg.org&gt;
Cc: Mel Gorman &lt;mgorman@techsingularity.net&gt;
Cc: Dave Hansen &lt;dave.hansen@intel.com&gt;
Cc: Chen Liqin &lt;liqin.linux@gmail.com&gt;
Cc: Russell King &lt;linux@armlinux.org.uk&gt;
Cc: Yoshinori Sato &lt;ysato@users.sourceforge.jp&gt;
Cc: &quot;James E.J. Bottomley&quot; &lt;jejb@parisc-linux.org&gt;
Cc: Guan Xuetao &lt;gxt@mprc.pku.edu.cn&gt;
Cc: &quot;David S. Miller&quot; &lt;davem@davemloft.net&gt;
Cc: Chris Zankel &lt;chris@zankel.net&gt;
Cc: Vineet Gupta &lt;vgupta@synopsys.com&gt;
Cc: Ley Foon Tan &lt;lftan@altera.com&gt;
Cc: Ralf Baechle &lt;ralf@linux-mips.org&gt;
Cc: Andi Kleen &lt;ak@linux.intel.com&gt;

Changes:

v2:

- Rename __page_mapping() to page_mapping_file() and simplified
  implementation as suggested by Andrew Morton.
---
 arch/arc/mm/cache.c           |  2 +-
 arch/arm/mm/copypage-v4mc.c   |  2 +-
 arch/arm/mm/copypage-v6.c     |  2 +-
 arch/arm/mm/copypage-xscale.c |  2 +-
 arch/arm/mm/fault-armv.c      |  2 +-
 arch/arm/mm/flush.c           |  6 +++---
 arch/mips/mm/cache.c          |  2 +-
 arch/nios2/mm/cacheflush.c    |  4 ++--
 arch/parisc/kernel/cache.c    |  5 +++--
 arch/score/mm/cache.c         |  5 +++--
 arch/sh/mm/cache-sh4.c        |  2 +-
 arch/sh/mm/cache-sh7705.c     |  2 +-
 arch/sparc/kernel/smp_64.c    |  8 ++++----
 arch/sparc/mm/init_64.c       |  6 +++---
 arch/sparc/mm/tlb.c           |  2 +-
 arch/unicore32/mm/flush.c     |  2 +-
 arch/unicore32/mm/mmu.c       |  2 +-
 arch/xtensa/mm/cache.c        |  2 +-
 include/linux/mm.h            |  1 +
 mm/util.c                     | 11 +++++++++++
 20 files changed, 42 insertions(+), 28 deletions(-)
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=165241">Mike Rapoport</a> - March 5, 2018, 9:46 a.m.</div>
<pre class="content">
On Mon, Mar 05, 2018 at 04:36:34PM +0800, Huang, Ying wrote:
<span class="quote">&gt; From: Huang Ying &lt;ying.huang@intel.com&gt;</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; From commit 4b3ef9daa4fc (&quot;mm/swap: split swap cache into 64MB</span>
<span class="quote">&gt; trunks&quot;) on, after swapoff, the address_space associated with the swap</span>
<span class="quote">&gt; device will be freed.  So page_mapping() users which may touch the</span>
<span class="quote">&gt; address_space need some kind of mechanism to prevent the address_space</span>
<span class="quote">&gt; from being freed during accessing.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; The dcache flushing functions (flush_dcache_page(), etc) in</span>
<span class="quote">&gt; architecture specific code may access the address_space of swap device</span>
<span class="quote">&gt; for anonymous pages in swap cache via page_mapping() function.  But in</span>
<span class="quote">&gt; some cases there are no mechanisms to prevent the swap device from</span>
<span class="quote">&gt; being swapoff, for example,</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; CPU1					CPU2</span>
<span class="quote">&gt; __get_user_pages()			swapoff()</span>
<span class="quote">&gt;   flush_dcache_page()</span>
<span class="quote">&gt;     mapping = page_mapping()</span>
<span class="quote">&gt;       ...				  exit_swap_address_space()</span>
<span class="quote">&gt;       ...				    kvfree(spaces)</span>
<span class="quote">&gt;       mapping_mapped(mapping)</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; The address space may be accessed after being freed.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; But from cachetlb.txt and Russell King, flush_dcache_page() only care</span>
<span class="quote">&gt; about file cache pages, for anonymous pages, flush_anon_page() should</span>
<span class="quote">&gt; be used.  The implementation of flush_dcache_page() in all</span>
<span class="quote">&gt; architectures follows this too.  They will check whether</span>
<span class="quote">&gt; page_mapping() is NULL and whether mapping_mapped() is true to</span>
<span class="quote">&gt; determine whether to flush the dcache immediately.  And they will use</span>
<span class="quote">&gt; interval tree (mapping-&gt;i_mmap) to find all user space mappings.</span>
<span class="quote">&gt; While mapping_mapped() and mapping-&gt;i_mmap isn&#39;t used by anonymous</span>
<span class="quote">&gt; pages in swap cache at all.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; So, to fix the race between swapoff and flush dcache, __page_mapping()</span>
<span class="quote">&gt; is add to return the address_space for file cache pages and NULL</span>
<span class="quote">&gt; otherwise.  All page_mapping() invoking in flush dcache functions are</span>
<span class="quote">&gt; replaced with __page_mapping().</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Signed-off-by: &quot;Huang, Ying&quot; &lt;ying.huang@intel.com&gt;</span>
<span class="quote">&gt; Cc: Minchan Kim &lt;minchan@kernel.org&gt;</span>
<span class="quote">&gt; Cc: Michal Hocko &lt;mhocko@suse.com&gt;</span>
<span class="quote">&gt; Cc: Johannes Weiner &lt;hannes@cmpxchg.org&gt;</span>
<span class="quote">&gt; Cc: Mel Gorman &lt;mgorman@techsingularity.net&gt;</span>
<span class="quote">&gt; Cc: Dave Hansen &lt;dave.hansen@intel.com&gt;</span>
<span class="quote">&gt; Cc: Chen Liqin &lt;liqin.linux@gmail.com&gt;</span>
<span class="quote">&gt; Cc: Russell King &lt;linux@armlinux.org.uk&gt;</span>
<span class="quote">&gt; Cc: Yoshinori Sato &lt;ysato@users.sourceforge.jp&gt;</span>
<span class="quote">&gt; Cc: &quot;James E.J. Bottomley&quot; &lt;jejb@parisc-linux.org&gt;</span>
<span class="quote">&gt; Cc: Guan Xuetao &lt;gxt@mprc.pku.edu.cn&gt;</span>
<span class="quote">&gt; Cc: &quot;David S. Miller&quot; &lt;davem@davemloft.net&gt;</span>
<span class="quote">&gt; Cc: Chris Zankel &lt;chris@zankel.net&gt;</span>
<span class="quote">&gt; Cc: Vineet Gupta &lt;vgupta@synopsys.com&gt;</span>
<span class="quote">&gt; Cc: Ley Foon Tan &lt;lftan@altera.com&gt;</span>
<span class="quote">&gt; Cc: Ralf Baechle &lt;ralf@linux-mips.org&gt;</span>
<span class="quote">&gt; Cc: Andi Kleen &lt;ak@linux.intel.com&gt;</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Changes:</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; v2:</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; - Rename __page_mapping() to page_mapping_file() and simplified</span>
<span class="quote">&gt;   implementation as suggested by Andrew Morton.</span>
<span class="quote">&gt; ---</span>
<span class="quote">&gt;  arch/arc/mm/cache.c           |  2 +-</span>
<span class="quote">&gt;  arch/arm/mm/copypage-v4mc.c   |  2 +-</span>
<span class="quote">&gt;  arch/arm/mm/copypage-v6.c     |  2 +-</span>
<span class="quote">&gt;  arch/arm/mm/copypage-xscale.c |  2 +-</span>
<span class="quote">&gt;  arch/arm/mm/fault-armv.c      |  2 +-</span>
<span class="quote">&gt;  arch/arm/mm/flush.c           |  6 +++---</span>
<span class="quote">&gt;  arch/mips/mm/cache.c          |  2 +-</span>
<span class="quote">&gt;  arch/nios2/mm/cacheflush.c    |  4 ++--</span>
<span class="quote">&gt;  arch/parisc/kernel/cache.c    |  5 +++--</span>
<span class="quote">&gt;  arch/score/mm/cache.c         |  5 +++--</span>
<span class="quote">&gt;  arch/sh/mm/cache-sh4.c        |  2 +-</span>
<span class="quote">&gt;  arch/sh/mm/cache-sh7705.c     |  2 +-</span>
<span class="quote">&gt;  arch/sparc/kernel/smp_64.c    |  8 ++++----</span>
<span class="quote">&gt;  arch/sparc/mm/init_64.c       |  6 +++---</span>
<span class="quote">&gt;  arch/sparc/mm/tlb.c           |  2 +-</span>
<span class="quote">&gt;  arch/unicore32/mm/flush.c     |  2 +-</span>
<span class="quote">&gt;  arch/unicore32/mm/mmu.c       |  2 +-</span>
<span class="quote">&gt;  arch/xtensa/mm/cache.c        |  2 +-</span>
<span class="quote">&gt;  include/linux/mm.h            |  1 +</span>
<span class="quote">&gt;  mm/util.c                     | 11 +++++++++++</span>
<span class="quote">&gt;  20 files changed, 42 insertions(+), 28 deletions(-)</span>
 
...
<span class="quote">
&gt; diff --git a/mm/util.c b/mm/util.c</span>
<span class="quote">&gt; index d800ce40816c..252f4748f00b 100644</span>
<span class="quote">&gt; --- a/mm/util.c</span>
<span class="quote">&gt; +++ b/mm/util.c</span>
<span class="quote">&gt; @@ -515,6 +515,17 @@ struct address_space *page_mapping(struct page *page)</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;  EXPORT_SYMBOL(page_mapping);</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; +/*</span>
<span class="quote">&gt; + * For file cache pages, return the address_space, otherwise return NULL</span>
<span class="quote">&gt; + */</span>
<span class="quote">&gt; +struct address_space *page_mapping_file(struct page *page)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	if (unlikely(PageSwapCache(page)))</span>
<span class="quote">&gt; +		return NULL;</span>
<span class="quote">&gt; +	else</span>

Nit: you can drop the &#39;else&#39; and just fall through to return
page_mapping(page).
<span class="quote">
&gt; +		return page_mapping(page);</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt;  /* Slow path of page_mapcount() for compound pages */</span>
<span class="quote">&gt;  int __page_mapcount(struct page *page)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt; -- </span>
<span class="quote">&gt; 2.15.1</span>
<span class="quote">&gt;</span>
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=294">Huang Ying</a> - March 6, 2018, 12:47 a.m.</div>
<pre class="content">
&quot;Huang, Ying&quot; &lt;ying.huang@intel.com&gt; writes:
<span class="quote">
&gt; From: Huang Ying &lt;ying.huang@intel.com&gt;</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; From commit 4b3ef9daa4fc (&quot;mm/swap: split swap cache into 64MB</span>
<span class="quote">&gt; trunks&quot;) on, after swapoff, the address_space associated with the swap</span>
<span class="quote">&gt; device will be freed.  So page_mapping() users which may touch the</span>
<span class="quote">&gt; address_space need some kind of mechanism to prevent the address_space</span>
<span class="quote">&gt; from being freed during accessing.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; The dcache flushing functions (flush_dcache_page(), etc) in</span>
<span class="quote">&gt; architecture specific code may access the address_space of swap device</span>
<span class="quote">&gt; for anonymous pages in swap cache via page_mapping() function.  But in</span>
<span class="quote">&gt; some cases there are no mechanisms to prevent the swap device from</span>
<span class="quote">&gt; being swapoff, for example,</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; CPU1					CPU2</span>
<span class="quote">&gt; __get_user_pages()			swapoff()</span>
<span class="quote">&gt;   flush_dcache_page()</span>
<span class="quote">&gt;     mapping = page_mapping()</span>
<span class="quote">&gt;       ...				  exit_swap_address_space()</span>
<span class="quote">&gt;       ...				    kvfree(spaces)</span>
<span class="quote">&gt;       mapping_mapped(mapping)</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; The address space may be accessed after being freed.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; But from cachetlb.txt and Russell King, flush_dcache_page() only care</span>
<span class="quote">&gt; about file cache pages, for anonymous pages, flush_anon_page() should</span>
<span class="quote">&gt; be used.  The implementation of flush_dcache_page() in all</span>
<span class="quote">&gt; architectures follows this too.  They will check whether</span>
<span class="quote">&gt; page_mapping() is NULL and whether mapping_mapped() is true to</span>
<span class="quote">&gt; determine whether to flush the dcache immediately.  And they will use</span>
<span class="quote">&gt; interval tree (mapping-&gt;i_mmap) to find all user space mappings.</span>
<span class="quote">&gt; While mapping_mapped() and mapping-&gt;i_mmap isn&#39;t used by anonymous</span>
<span class="quote">&gt; pages in swap cache at all.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; So, to fix the race between swapoff and flush dcache, __page_mapping()</span>
<span class="quote">&gt; is add to return the address_space for file cache pages and NULL</span>
<span class="quote">&gt; otherwise.  All page_mapping() invoking in flush dcache functions are</span>
<span class="quote">&gt; replaced with __page_mapping().</span>

Sorry, I just found I forgot replacing __page_mapping() to
page_mapping_file() in the above paragraph.  Could you help me to change
it in place?  Or I should resend the patch with the updated description?

Best Regards,
Huang, Ying

[snip]
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/arch/arc/mm/cache.c b/arch/arc/mm/cache.c</span>
<span class="p_header">index 2072f3451e9c..9dbe645ee127 100644</span>
<span class="p_header">--- a/arch/arc/mm/cache.c</span>
<span class="p_header">+++ b/arch/arc/mm/cache.c</span>
<span class="p_chunk">@@ -833,7 +833,7 @@</span> <span class="p_context"> void flush_dcache_page(struct page *page)</span>
 	}
 
 	/* don&#39;t handle anon pages here */
<span class="p_del">-	mapping = page_mapping(page);</span>
<span class="p_add">+	mapping = page_mapping_file(page);</span>
 	if (!mapping)
 		return;
 
<span class="p_header">diff --git a/arch/arm/mm/copypage-v4mc.c b/arch/arm/mm/copypage-v4mc.c</span>
<span class="p_header">index 1267e64133b9..0224416cba3c 100644</span>
<span class="p_header">--- a/arch/arm/mm/copypage-v4mc.c</span>
<span class="p_header">+++ b/arch/arm/mm/copypage-v4mc.c</span>
<span class="p_chunk">@@ -70,7 +70,7 @@</span> <span class="p_context"> void v4_mc_copy_user_highpage(struct page *to, struct page *from,</span>
 	void *kto = kmap_atomic(to);
 
 	if (!test_and_set_bit(PG_dcache_clean, &amp;from-&gt;flags))
<span class="p_del">-		__flush_dcache_page(page_mapping(from), from);</span>
<span class="p_add">+		__flush_dcache_page(page_mapping_file(from), from);</span>
 
 	raw_spin_lock(&amp;minicache_lock);
 
<span class="p_header">diff --git a/arch/arm/mm/copypage-v6.c b/arch/arm/mm/copypage-v6.c</span>
<span class="p_header">index 70423345da26..a698e575e321 100644</span>
<span class="p_header">--- a/arch/arm/mm/copypage-v6.c</span>
<span class="p_header">+++ b/arch/arm/mm/copypage-v6.c</span>
<span class="p_chunk">@@ -76,7 +76,7 @@</span> <span class="p_context"> static void v6_copy_user_highpage_aliasing(struct page *to,</span>
 	unsigned long kfrom, kto;
 
 	if (!test_and_set_bit(PG_dcache_clean, &amp;from-&gt;flags))
<span class="p_del">-		__flush_dcache_page(page_mapping(from), from);</span>
<span class="p_add">+		__flush_dcache_page(page_mapping_file(from), from);</span>
 
 	/* FIXME: not highmem safe */
 	discard_old_kernel_data(page_address(to));
<span class="p_header">diff --git a/arch/arm/mm/copypage-xscale.c b/arch/arm/mm/copypage-xscale.c</span>
<span class="p_header">index 0fb85025344d..97972379f4d6 100644</span>
<span class="p_header">--- a/arch/arm/mm/copypage-xscale.c</span>
<span class="p_header">+++ b/arch/arm/mm/copypage-xscale.c</span>
<span class="p_chunk">@@ -90,7 +90,7 @@</span> <span class="p_context"> void xscale_mc_copy_user_highpage(struct page *to, struct page *from,</span>
 	void *kto = kmap_atomic(to);
 
 	if (!test_and_set_bit(PG_dcache_clean, &amp;from-&gt;flags))
<span class="p_del">-		__flush_dcache_page(page_mapping(from), from);</span>
<span class="p_add">+		__flush_dcache_page(page_mapping_file(from), from);</span>
 
 	raw_spin_lock(&amp;minicache_lock);
 
<span class="p_header">diff --git a/arch/arm/mm/fault-armv.c b/arch/arm/mm/fault-armv.c</span>
<span class="p_header">index d9e0d00a6699..4d75dae5ac96 100644</span>
<span class="p_header">--- a/arch/arm/mm/fault-armv.c</span>
<span class="p_header">+++ b/arch/arm/mm/fault-armv.c</span>
<span class="p_chunk">@@ -195,7 +195,7 @@</span> <span class="p_context"> void update_mmu_cache(struct vm_area_struct *vma, unsigned long addr,</span>
 	if (page == ZERO_PAGE(0))
 		return;
 
<span class="p_del">-	mapping = page_mapping(page);</span>
<span class="p_add">+	mapping = page_mapping_file(page);</span>
 	if (!test_and_set_bit(PG_dcache_clean, &amp;page-&gt;flags))
 		__flush_dcache_page(mapping, page);
 	if (mapping) {
<span class="p_header">diff --git a/arch/arm/mm/flush.c b/arch/arm/mm/flush.c</span>
<span class="p_header">index f1e6190aa7ea..58469623b015 100644</span>
<span class="p_header">--- a/arch/arm/mm/flush.c</span>
<span class="p_header">+++ b/arch/arm/mm/flush.c</span>
<span class="p_chunk">@@ -285,7 +285,7 @@</span> <span class="p_context"> void __sync_icache_dcache(pte_t pteval)</span>
 
 	page = pfn_to_page(pfn);
 	if (cache_is_vipt_aliasing())
<span class="p_del">-		mapping = page_mapping(page);</span>
<span class="p_add">+		mapping = page_mapping_file(page);</span>
 	else
 		mapping = NULL;
 
<span class="p_chunk">@@ -333,7 +333,7 @@</span> <span class="p_context"> void flush_dcache_page(struct page *page)</span>
 		return;
 	}
 
<span class="p_del">-	mapping = page_mapping(page);</span>
<span class="p_add">+	mapping = page_mapping_file(page);</span>
 
 	if (!cache_ops_need_broadcast() &amp;&amp;
 	    mapping &amp;&amp; !page_mapcount(page))
<span class="p_chunk">@@ -363,7 +363,7 @@</span> <span class="p_context"> void flush_kernel_dcache_page(struct page *page)</span>
 	if (cache_is_vivt() || cache_is_vipt_aliasing()) {
 		struct address_space *mapping;
 
<span class="p_del">-		mapping = page_mapping(page);</span>
<span class="p_add">+		mapping = page_mapping_file(page);</span>
 
 		if (!mapping || mapping_mapped(mapping)) {
 			void *addr;
<span class="p_header">diff --git a/arch/mips/mm/cache.c b/arch/mips/mm/cache.c</span>
<span class="p_header">index 44ac64d51827..0d3c656feba0 100644</span>
<span class="p_header">--- a/arch/mips/mm/cache.c</span>
<span class="p_header">+++ b/arch/mips/mm/cache.c</span>
<span class="p_chunk">@@ -86,7 +86,7 @@</span> <span class="p_context"> SYSCALL_DEFINE3(cacheflush, unsigned long, addr, unsigned long, bytes,</span>
 
 void __flush_dcache_page(struct page *page)
 {
<span class="p_del">-	struct address_space *mapping = page_mapping(page);</span>
<span class="p_add">+	struct address_space *mapping = page_mapping_file(page);</span>
 	unsigned long addr;
 
 	if (mapping &amp;&amp; !mapping_mapped(mapping)) {
<span class="p_header">diff --git a/arch/nios2/mm/cacheflush.c b/arch/nios2/mm/cacheflush.c</span>
<span class="p_header">index 87bf88ed04c6..506f6e1c86d5 100644</span>
<span class="p_header">--- a/arch/nios2/mm/cacheflush.c</span>
<span class="p_header">+++ b/arch/nios2/mm/cacheflush.c</span>
<span class="p_chunk">@@ -180,7 +180,7 @@</span> <span class="p_context"> void flush_dcache_page(struct page *page)</span>
 	if (page == ZERO_PAGE(0))
 		return;
 
<span class="p_del">-	mapping = page_mapping(page);</span>
<span class="p_add">+	mapping = page_mapping_file(page);</span>
 
 	/* Flush this page if there are aliases. */
 	if (mapping &amp;&amp; !mapping_mapped(mapping)) {
<span class="p_chunk">@@ -215,7 +215,7 @@</span> <span class="p_context"> void update_mmu_cache(struct vm_area_struct *vma,</span>
 	if (page == ZERO_PAGE(0))
 		return;
 
<span class="p_del">-	mapping = page_mapping(page);</span>
<span class="p_add">+	mapping = page_mapping_file(page);</span>
 	if (!test_and_set_bit(PG_dcache_clean, &amp;page-&gt;flags))
 		__flush_dcache_page(mapping, page);
 
<span class="p_header">diff --git a/arch/parisc/kernel/cache.c b/arch/parisc/kernel/cache.c</span>
<span class="p_header">index 7c1bde80ada4..d3a0f139a6e9 100644</span>
<span class="p_header">--- a/arch/parisc/kernel/cache.c</span>
<span class="p_header">+++ b/arch/parisc/kernel/cache.c</span>
<span class="p_chunk">@@ -88,7 +88,8 @@</span> <span class="p_context"> update_mmu_cache(struct vm_area_struct *vma, unsigned long address, pte_t *ptep)</span>
 		return;
 
 	page = pfn_to_page(pfn);
<span class="p_del">-	if (page_mapping(page) &amp;&amp; test_bit(PG_dcache_dirty, &amp;page-&gt;flags)) {</span>
<span class="p_add">+	if (page_mapping_file(page) &amp;&amp;</span>
<span class="p_add">+	    test_bit(PG_dcache_dirty, &amp;page-&gt;flags)) {</span>
 		flush_kernel_dcache_page_addr(pfn_va(pfn));
 		clear_bit(PG_dcache_dirty, &amp;page-&gt;flags);
 	} else if (parisc_requires_coherency())
<span class="p_chunk">@@ -304,7 +305,7 @@</span> <span class="p_context"> __flush_cache_page(struct vm_area_struct *vma, unsigned long vmaddr,</span>
 
 void flush_dcache_page(struct page *page)
 {
<span class="p_del">-	struct address_space *mapping = page_mapping(page);</span>
<span class="p_add">+	struct address_space *mapping = page_mapping_file(page);</span>
 	struct vm_area_struct *mpnt;
 	unsigned long offset;
 	unsigned long addr, old_addr = 0;
<span class="p_header">diff --git a/arch/score/mm/cache.c b/arch/score/mm/cache.c</span>
<span class="p_header">index b4bcfd3e8393..1ddbd3bc9b57 100644</span>
<span class="p_header">--- a/arch/score/mm/cache.c</span>
<span class="p_header">+++ b/arch/score/mm/cache.c</span>
<span class="p_chunk">@@ -54,7 +54,7 @@</span> <span class="p_context"> static void flush_data_cache_page(unsigned long addr)</span>
 
 void flush_dcache_page(struct page *page)
 {
<span class="p_del">-	struct address_space *mapping = page_mapping(page);</span>
<span class="p_add">+	struct address_space *mapping = page_mapping_file(page);</span>
 	unsigned long addr;
 
 	if (PageHighMem(page))
<span class="p_chunk">@@ -86,7 +86,8 @@</span> <span class="p_context"> void __update_cache(struct vm_area_struct *vma, unsigned long address,</span>
 	if (unlikely(!pfn_valid(pfn)))
 		return;
 	page = pfn_to_page(pfn);
<span class="p_del">-	if (page_mapping(page) &amp;&amp; test_bit(PG_dcache_dirty, &amp;(page)-&gt;flags)) {</span>
<span class="p_add">+	if (page_mapping_file(page) &amp;&amp;</span>
<span class="p_add">+	    test_bit(PG_dcache_dirty, &amp;(page)-&gt;flags)) {</span>
 		addr = (unsigned long) page_address(page);
 		if (exec)
 			flush_data_cache_page(addr);
<span class="p_header">diff --git a/arch/sh/mm/cache-sh4.c b/arch/sh/mm/cache-sh4.c</span>
<span class="p_header">index 58aaa4f33b81..eee911422cf9 100644</span>
<span class="p_header">--- a/arch/sh/mm/cache-sh4.c</span>
<span class="p_header">+++ b/arch/sh/mm/cache-sh4.c</span>
<span class="p_chunk">@@ -112,7 +112,7 @@</span> <span class="p_context"> static void sh4_flush_dcache_page(void *arg)</span>
 	struct page *page = arg;
 	unsigned long addr = (unsigned long)page_address(page);
 #ifndef CONFIG_SMP
<span class="p_del">-	struct address_space *mapping = page_mapping(page);</span>
<span class="p_add">+	struct address_space *mapping = page_mapping_file(page);</span>
 
 	if (mapping &amp;&amp; !mapping_mapped(mapping))
 		clear_bit(PG_dcache_clean, &amp;page-&gt;flags);
<span class="p_header">diff --git a/arch/sh/mm/cache-sh7705.c b/arch/sh/mm/cache-sh7705.c</span>
<span class="p_header">index 6cd2aa395817..ed25eba80667 100644</span>
<span class="p_header">--- a/arch/sh/mm/cache-sh7705.c</span>
<span class="p_header">+++ b/arch/sh/mm/cache-sh7705.c</span>
<span class="p_chunk">@@ -136,7 +136,7 @@</span> <span class="p_context"> static void __flush_dcache_page(unsigned long phys)</span>
 static void sh7705_flush_dcache_page(void *arg)
 {
 	struct page *page = arg;
<span class="p_del">-	struct address_space *mapping = page_mapping(page);</span>
<span class="p_add">+	struct address_space *mapping = page_mapping_file(page);</span>
 
 	if (mapping &amp;&amp; !mapping_mapped(mapping))
 		clear_bit(PG_dcache_clean, &amp;page-&gt;flags);
<span class="p_header">diff --git a/arch/sparc/kernel/smp_64.c b/arch/sparc/kernel/smp_64.c</span>
<span class="p_header">index c50182cd2f64..d3ea1f3c06a0 100644</span>
<span class="p_header">--- a/arch/sparc/kernel/smp_64.c</span>
<span class="p_header">+++ b/arch/sparc/kernel/smp_64.c</span>
<span class="p_chunk">@@ -929,9 +929,9 @@</span> <span class="p_context"> static inline void __local_flush_dcache_page(struct page *page)</span>
 #ifdef DCACHE_ALIASING_POSSIBLE
 	__flush_dcache_page(page_address(page),
 			    ((tlb_type == spitfire) &amp;&amp;
<span class="p_del">-			     page_mapping(page) != NULL));</span>
<span class="p_add">+			     page_mapping_file(page) != NULL));</span>
 #else
<span class="p_del">-	if (page_mapping(page) != NULL &amp;&amp;</span>
<span class="p_add">+	if (page_mapping_file(page) != NULL &amp;&amp;</span>
 	    tlb_type == spitfire)
 		__flush_icache_page(__pa(page_address(page)));
 #endif
<span class="p_chunk">@@ -958,7 +958,7 @@</span> <span class="p_context"> void smp_flush_dcache_page_impl(struct page *page, int cpu)</span>
 
 		if (tlb_type == spitfire) {
 			data0 = ((u64)&amp;xcall_flush_dcache_page_spitfire);
<span class="p_del">-			if (page_mapping(page) != NULL)</span>
<span class="p_add">+			if (page_mapping_file(page) != NULL)</span>
 				data0 |= ((u64)1 &lt;&lt; 32);
 		} else if (tlb_type == cheetah || tlb_type == cheetah_plus) {
 #ifdef DCACHE_ALIASING_POSSIBLE
<span class="p_chunk">@@ -994,7 +994,7 @@</span> <span class="p_context"> void flush_dcache_page_all(struct mm_struct *mm, struct page *page)</span>
 	pg_addr = page_address(page);
 	if (tlb_type == spitfire) {
 		data0 = ((u64)&amp;xcall_flush_dcache_page_spitfire);
<span class="p_del">-		if (page_mapping(page) != NULL)</span>
<span class="p_add">+		if (page_mapping_file(page) != NULL)</span>
 			data0 |= ((u64)1 &lt;&lt; 32);
 	} else if (tlb_type == cheetah || tlb_type == cheetah_plus) {
 #ifdef DCACHE_ALIASING_POSSIBLE
<span class="p_header">diff --git a/arch/sparc/mm/init_64.c b/arch/sparc/mm/init_64.c</span>
<span class="p_header">index a9f94e911e0a..a977901d4f9d 100644</span>
<span class="p_header">--- a/arch/sparc/mm/init_64.c</span>
<span class="p_header">+++ b/arch/sparc/mm/init_64.c</span>
<span class="p_chunk">@@ -206,9 +206,9 @@</span> <span class="p_context"> inline void flush_dcache_page_impl(struct page *page)</span>
 #ifdef DCACHE_ALIASING_POSSIBLE
 	__flush_dcache_page(page_address(page),
 			    ((tlb_type == spitfire) &amp;&amp;
<span class="p_del">-			     page_mapping(page) != NULL));</span>
<span class="p_add">+			     page_mapping_file(page) != NULL));</span>
 #else
<span class="p_del">-	if (page_mapping(page) != NULL &amp;&amp;</span>
<span class="p_add">+	if (page_mapping_file(page) != NULL &amp;&amp;</span>
 	    tlb_type == spitfire)
 		__flush_icache_page(__pa(page_address(page)));
 #endif
<span class="p_chunk">@@ -490,7 +490,7 @@</span> <span class="p_context"> void flush_dcache_page(struct page *page)</span>
 
 	this_cpu = get_cpu();
 
<span class="p_del">-	mapping = page_mapping(page);</span>
<span class="p_add">+	mapping = page_mapping_file(page);</span>
 	if (mapping &amp;&amp; !mapping_mapped(mapping)) {
 		int dirty = test_bit(PG_dcache_dirty, &amp;page-&gt;flags);
 		if (dirty) {
<span class="p_header">diff --git a/arch/sparc/mm/tlb.c b/arch/sparc/mm/tlb.c</span>
<span class="p_header">index 847ddffbf38a..8cfb6aac8fb8 100644</span>
<span class="p_header">--- a/arch/sparc/mm/tlb.c</span>
<span class="p_header">+++ b/arch/sparc/mm/tlb.c</span>
<span class="p_chunk">@@ -128,7 +128,7 @@</span> <span class="p_context"> void tlb_batch_add(struct mm_struct *mm, unsigned long vaddr,</span>
 			goto no_cache_flush;
 
 		/* A real file page? */
<span class="p_del">-		mapping = page_mapping(page);</span>
<span class="p_add">+		mapping = page_mapping_file(page);</span>
 		if (!mapping)
 			goto no_cache_flush;
 
<span class="p_header">diff --git a/arch/unicore32/mm/flush.c b/arch/unicore32/mm/flush.c</span>
<span class="p_header">index 6d4c096ffa2a..74f4d636df2d 100644</span>
<span class="p_header">--- a/arch/unicore32/mm/flush.c</span>
<span class="p_header">+++ b/arch/unicore32/mm/flush.c</span>
<span class="p_chunk">@@ -83,7 +83,7 @@</span> <span class="p_context"> void flush_dcache_page(struct page *page)</span>
 	if (page == ZERO_PAGE(0))
 		return;
 
<span class="p_del">-	mapping = page_mapping(page);</span>
<span class="p_add">+	mapping = page_mapping_file(page);</span>
 
 	if (mapping &amp;&amp; !mapping_mapped(mapping))
 		clear_bit(PG_dcache_clean, &amp;page-&gt;flags);
<span class="p_header">diff --git a/arch/unicore32/mm/mmu.c b/arch/unicore32/mm/mmu.c</span>
<span class="p_header">index 4f5a532bee13..0c94b7b4514d 100644</span>
<span class="p_header">--- a/arch/unicore32/mm/mmu.c</span>
<span class="p_header">+++ b/arch/unicore32/mm/mmu.c</span>
<span class="p_chunk">@@ -503,7 +503,7 @@</span> <span class="p_context"> void update_mmu_cache(struct vm_area_struct *vma, unsigned long addr,</span>
 	if (page == ZERO_PAGE(0))
 		return;
 
<span class="p_del">-	mapping = page_mapping(page);</span>
<span class="p_add">+	mapping = page_mapping_file(page);</span>
 	if (!test_and_set_bit(PG_dcache_clean, &amp;page-&gt;flags))
 		__flush_dcache_page(mapping, page);
 	if (mapping)
<span class="p_header">diff --git a/arch/xtensa/mm/cache.c b/arch/xtensa/mm/cache.c</span>
<span class="p_header">index 57dc231a0709..9220dcde7520 100644</span>
<span class="p_header">--- a/arch/xtensa/mm/cache.c</span>
<span class="p_header">+++ b/arch/xtensa/mm/cache.c</span>
<span class="p_chunk">@@ -127,7 +127,7 @@</span> <span class="p_context"> EXPORT_SYMBOL(copy_user_highpage);</span>
 
 void flush_dcache_page(struct page *page)
 {
<span class="p_del">-	struct address_space *mapping = page_mapping(page);</span>
<span class="p_add">+	struct address_space *mapping = page_mapping_file(page);</span>
 
 	/*
 	 * If we have a mapping but the page is not mapped to user-space
<span class="p_header">diff --git a/include/linux/mm.h b/include/linux/mm.h</span>
<span class="p_header">index c500bdfadf79..0ed3ae922af0 100644</span>
<span class="p_header">--- a/include/linux/mm.h</span>
<span class="p_header">+++ b/include/linux/mm.h</span>
<span class="p_chunk">@@ -1147,6 +1147,7 @@</span> <span class="p_context"> static inline pgoff_t page_index(struct page *page)</span>
 
 bool page_mapped(struct page *page);
 struct address_space *page_mapping(struct page *page);
<span class="p_add">+struct address_space *page_mapping_file(struct page *page);</span>
 
 /*
  * Return true only if the page has been allocated with
<span class="p_header">diff --git a/mm/util.c b/mm/util.c</span>
<span class="p_header">index d800ce40816c..252f4748f00b 100644</span>
<span class="p_header">--- a/mm/util.c</span>
<span class="p_header">+++ b/mm/util.c</span>
<span class="p_chunk">@@ -515,6 +515,17 @@</span> <span class="p_context"> struct address_space *page_mapping(struct page *page)</span>
 }
 EXPORT_SYMBOL(page_mapping);
 
<span class="p_add">+/*</span>
<span class="p_add">+ * For file cache pages, return the address_space, otherwise return NULL</span>
<span class="p_add">+ */</span>
<span class="p_add">+struct address_space *page_mapping_file(struct page *page)</span>
<span class="p_add">+{</span>
<span class="p_add">+	if (unlikely(PageSwapCache(page)))</span>
<span class="p_add">+		return NULL;</span>
<span class="p_add">+	else</span>
<span class="p_add">+		return page_mapping(page);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 /* Slow path of page_mapcount() for compound pages */
 int __page_mapcount(struct page *page)
 {

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



