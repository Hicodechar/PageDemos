
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>[HMM,v16,06/15] mm/hmm: heterogeneous memory management (HMM for short) - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    [HMM,v16,06/15] mm/hmm: heterogeneous memory management (HMM for short)</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=2554">Jerome Glisse</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>Jan. 12, 2017, 4:30 p.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;1484238642-10674-7-git-send-email-jglisse@redhat.com&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/9513445/mbox/"
   >mbox</a>
|
   <a href="/patch/9513445/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/9513445/">/patch/9513445/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
	[172.30.200.125])
	by pdx-korg-patchwork.web.codeaurora.org (Postfix) with ESMTP id
	3EF8560710 for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Thu, 12 Jan 2017 15:33:11 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 309E9286DB
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Thu, 12 Jan 2017 15:33:11 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id 2574A286E2; Thu, 12 Jan 2017 15:33:11 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-6.9 required=2.0 tests=BAYES_00,RCVD_IN_DNSWL_HI
	autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 1B80C286DB
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Thu, 12 Jan 2017 15:33:10 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1751375AbdALPdI (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Thu, 12 Jan 2017 10:33:08 -0500
Received: from mx1.redhat.com ([209.132.183.28]:56122 &quot;EHLO mx1.redhat.com&quot;
	rhost-flags-OK-OK-OK-OK) by vger.kernel.org with ESMTP
	id S1751017AbdALP3m (ORCPT &lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Thu, 12 Jan 2017 10:29:42 -0500
Received: from int-mx10.intmail.prod.int.phx2.redhat.com
	(int-mx10.intmail.prod.int.phx2.redhat.com [10.5.11.23])
	(using TLSv1.2 with cipher ECDHE-RSA-AES256-GCM-SHA384 (256/256
	bits)) (No client certificate requested)
	by mx1.redhat.com (Postfix) with ESMTPS id DD02281240;
	Thu, 12 Jan 2017 15:29:37 +0000 (UTC)
Received: from xgl-cortex.ml2.eng.bos.redhat.com
	(xgl-cortex.ml2.eng.bos.redhat.com [10.19.160.80])
	by int-mx10.intmail.prod.int.phx2.redhat.com (8.14.4/8.14.4) with
	ESMTP id v0CFTStT025430; Thu, 12 Jan 2017 10:29:36 -0500
From: =?UTF-8?q?J=C3=A9r=C3=B4me=20Glisse?= &lt;jglisse@redhat.com&gt;
To: akpm@linux-foundation.org, &lt;linux-kernel@vger.kernel.org&gt;,
	linux-mm@kvack.org
Cc: John Hubbard &lt;jhubbard@nvidia.com&gt;,
	=?UTF-8?q?J=C3=A9r=C3=B4me=20Glisse?= &lt;jglisse@redhat.com&gt;,
	Evgeny Baskakov &lt;ebaskakov@nvidia.com&gt;,
	Mark Hairgrove &lt;mhairgrove@nvidia.com&gt;,
	Sherry Cheung &lt;SCheung@nvidia.com&gt;, Subhash Gutti &lt;sgutti@nvidia.com&gt;
Subject: [HMM v16 06/15] mm/hmm: heterogeneous memory management (HMM for
	short)
Date: Thu, 12 Jan 2017 11:30:33 -0500
Message-Id: &lt;1484238642-10674-7-git-send-email-jglisse@redhat.com&gt;
In-Reply-To: &lt;1484238642-10674-1-git-send-email-jglisse@redhat.com&gt;
References: &lt;1484238642-10674-1-git-send-email-jglisse@redhat.com&gt;
MIME-Version: 1.0
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 8bit
X-Scanned-By: MIMEDefang 2.68 on 10.5.11.23
X-Greylist: Sender IP whitelisted, not delayed by milter-greylist-4.5.16
	(mx1.redhat.com [10.5.110.25]);
	Thu, 12 Jan 2017 15:29:37 +0000 (UTC)
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=2554">Jerome Glisse</a> - Jan. 12, 2017, 4:30 p.m.</div>
<pre class="content">
HMM provides 3 separate functionality :
    - Mirroring: synchronize CPU page table and device page table
    - Device memory: allocating struct page for device memory
    - Migration: migrating regular memory to device memory

This patch introduces some common helpers and definitions to all of
those 3 functionality.
<span class="signed-off-by">
Signed-off-by: Jérôme Glisse &lt;jglisse@redhat.com&gt;</span>
<span class="signed-off-by">Signed-off-by: Evgeny Baskakov &lt;ebaskakov@nvidia.com&gt;</span>
<span class="signed-off-by">Signed-off-by: John Hubbard &lt;jhubbard@nvidia.com&gt;</span>
<span class="signed-off-by">Signed-off-by: Mark Hairgrove &lt;mhairgrove@nvidia.com&gt;</span>
<span class="signed-off-by">Signed-off-by: Sherry Cheung &lt;SCheung@nvidia.com&gt;</span>
<span class="signed-off-by">Signed-off-by: Subhash Gutti &lt;sgutti@nvidia.com&gt;</span>
---
 MAINTAINERS              |   7 +++
 include/linux/hmm.h      | 150 +++++++++++++++++++++++++++++++++++++++++++++++
 include/linux/mm_types.h |   5 ++
 kernel/fork.c            |   2 +
 mm/Kconfig               |   4 ++
 mm/Makefile              |   1 +
 mm/hmm.c                 |  82 ++++++++++++++++++++++++++
 7 files changed, 251 insertions(+)
 create mode 100644 include/linux/hmm.h
 create mode 100644 mm/hmm.c
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/MAINTAINERS b/MAINTAINERS</span>
<span class="p_header">index 606c43e..f119a0c 100644</span>
<span class="p_header">--- a/MAINTAINERS</span>
<span class="p_header">+++ b/MAINTAINERS</span>
<span class="p_chunk">@@ -5762,6 +5762,13 @@</span> <span class="p_context"> S:	Supported</span>
 F:	drivers/scsi/hisi_sas/
 F:	Documentation/devicetree/bindings/scsi/hisilicon-sas.txt
 
<span class="p_add">+HMM - Heterogeneous Memory Management</span>
<span class="p_add">+M:	Jérôme Glisse &lt;jglisse@redhat.com&gt;</span>
<span class="p_add">+L:	linux-mm@kvack.org</span>
<span class="p_add">+S:	Maintained</span>
<span class="p_add">+F:	mm/hmm*</span>
<span class="p_add">+F:	include/linux/hmm*</span>
<span class="p_add">+</span>
 HOST AP DRIVER
 M:	Jouni Malinen &lt;j@w1.fi&gt;
 L:	linux-wireless@vger.kernel.org
<span class="p_header">diff --git a/include/linux/hmm.h b/include/linux/hmm.h</span>
new file mode 100644
<span class="p_header">index 0000000..f00d519</span>
<span class="p_header">--- /dev/null</span>
<span class="p_header">+++ b/include/linux/hmm.h</span>
<span class="p_chunk">@@ -0,0 +1,150 @@</span> <span class="p_context"></span>
<span class="p_add">+/*</span>
<span class="p_add">+ * Copyright 2013 Red Hat Inc.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * This program is free software; you can redistribute it and/or modify</span>
<span class="p_add">+ * it under the terms of the GNU General Public License as published by</span>
<span class="p_add">+ * the Free Software Foundation; either version 2 of the License, or</span>
<span class="p_add">+ * (at your option) any later version.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * This program is distributed in the hope that it will be useful,</span>
<span class="p_add">+ * but WITHOUT ANY WARRANTY; without even the implied warranty of</span>
<span class="p_add">+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the</span>
<span class="p_add">+ * GNU General Public License for more details.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * Authors: Jérôme Glisse &lt;jglisse@redhat.com&gt;</span>
<span class="p_add">+ */</span>
<span class="p_add">+/*</span>
<span class="p_add">+ * HMM provides 3 separate functionality :</span>
<span class="p_add">+ *   - Mirroring: synchronize CPU page table and device page table</span>
<span class="p_add">+ *   - Device memory: allocating struct page for device memory</span>
<span class="p_add">+ *   - Migration: migrating regular memory to device memory</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * Each can be used independently from the others.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * Mirroring:</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * HMM provide helpers to mirror process address space on a device. For this it</span>
<span class="p_add">+ * provides several helpers to order device page table update in respect to CPU</span>
<span class="p_add">+ * page table update. Requirement is that for any given virtual address the CPU</span>
<span class="p_add">+ * and device page table can not point to different physical page. It uses the</span>
<span class="p_add">+ * mmu_notifier API behind the scene.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * Device memory:</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * HMM provides helpers to help leverage device memory either addressable like</span>
<span class="p_add">+ * regular memory by the CPU or un-addressable at all. In both case the device</span>
<span class="p_add">+ * memory is associated to dedicated structs page (which are allocated like for</span>
<span class="p_add">+ * hotplug memory). Device memory management is under the responsibility of the</span>
<span class="p_add">+ * device driver. HMM only allocate and initialize the struct pages associated</span>
<span class="p_add">+ * with the device memory by hotpluging a ZONE_DEVICE memory range.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * Allocating struct page for device memory allow to use device memory allmost</span>
<span class="p_add">+ * like any regular memory. Unlike regular memory it can not be added to the</span>
<span class="p_add">+ * lru, nor can any memory allocation can use device memory directly. Device</span>
<span class="p_add">+ * memory will only end up to be use in a process if device driver migrate some</span>
<span class="p_add">+ * of the process memory from regular memory to device memory.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * Migration:</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * Existing memory migration mechanism (mm/migrate.c) does not allow to use</span>
<span class="p_add">+ * something else than the CPU to copy from source to destination memory. More</span>
<span class="p_add">+ * over existing code is not tailor to drive migration from process virtual</span>
<span class="p_add">+ * address rather than from list of pages. Finaly the migration flow does not</span>
<span class="p_add">+ * allow for graceful failure at different step of the migration process.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * HMM solves all of the above through simple API :</span>
<span class="p_add">+ *</span>
<span class="p_add">+ *      hmm_vma_migrate(ops, vma, src_pfns, dst_pfns, start, end, private);</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * With ops struct providing 2 callback alloc_and_copy() which allocated the</span>
<span class="p_add">+ * destination memory and initialize it using source memory. Migration can fail</span>
<span class="p_add">+ * after this step and thus last callback finalize_and_map() allow the device</span>
<span class="p_add">+ * driver to know which page were successfully migrated and which were not.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * This can easily be use outside of HMM intended use case.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * This header file contain all the API related to this 3 functionality and</span>
<span class="p_add">+ * each functions and struct are more thoroughly documented in below comments.</span>
<span class="p_add">+ */</span>
<span class="p_add">+#ifndef LINUX_HMM_H</span>
<span class="p_add">+#define LINUX_HMM_H</span>
<span class="p_add">+</span>
<span class="p_add">+#include &lt;linux/kconfig.h&gt;</span>
<span class="p_add">+</span>
<span class="p_add">+#if IS_ENABLED(CONFIG_HMM)</span>
<span class="p_add">+</span>
<span class="p_add">+</span>
<span class="p_add">+/*</span>
<span class="p_add">+ * hmm_pfn_t - HMM use its own pfn type to keep several flags per page</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * Flags:</span>
<span class="p_add">+ * HMM_PFN_VALID: pfn is valid</span>
<span class="p_add">+ * HMM_PFN_WRITE: CPU page table have the write permission set</span>
<span class="p_add">+ */</span>
<span class="p_add">+typedef unsigned long hmm_pfn_t;</span>
<span class="p_add">+</span>
<span class="p_add">+#define HMM_PFN_VALID (1 &lt;&lt; 0)</span>
<span class="p_add">+#define HMM_PFN_WRITE (1 &lt;&lt; 1)</span>
<span class="p_add">+#define HMM_PFN_SHIFT 2</span>
<span class="p_add">+</span>
<span class="p_add">+/*</span>
<span class="p_add">+ * hmm_pfn_to_page() - return struct page pointed to by a valid hmm_pfn_t</span>
<span class="p_add">+ * @pfn: hmm_pfn_t to convert to struct page</span>
<span class="p_add">+ * Returns: struct page pointer if pfn is a valid hmm_pfn_t, NULL otherwise</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * If the hmm_pfn_t is valid (ie valid flag set) then return the struct page</span>
<span class="p_add">+ * matching the pfn value store in the hmm_pfn_t. Otherwise return NULL.</span>
<span class="p_add">+ */</span>
<span class="p_add">+static inline struct page *hmm_pfn_to_page(hmm_pfn_t pfn)</span>
<span class="p_add">+{</span>
<span class="p_add">+	if (!(pfn &amp; HMM_PFN_VALID))</span>
<span class="p_add">+		return NULL;</span>
<span class="p_add">+	return pfn_to_page(pfn &gt;&gt; HMM_PFN_SHIFT);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+/*</span>
<span class="p_add">+ * hmm_pfn_to_pfn() - return pfn value store in a hmm_pfn_t</span>
<span class="p_add">+ * @pfn: hmm_pfn_t to extract pfn from</span>
<span class="p_add">+ * Returns: pfn value if hmm_pfn_t is valid, -1UL otherwise</span>
<span class="p_add">+ */</span>
<span class="p_add">+static inline unsigned long hmm_pfn_to_pfn(hmm_pfn_t pfn)</span>
<span class="p_add">+{</span>
<span class="p_add">+	if (!(pfn &amp; HMM_PFN_VALID))</span>
<span class="p_add">+		return -1UL;</span>
<span class="p_add">+	return (pfn &gt;&gt; HMM_PFN_SHIFT);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+/*</span>
<span class="p_add">+ * hmm_pfn_from_page() - create a valid hmm_pfn_t value from struct page</span>
<span class="p_add">+ * @page: struct page pointer for which to create the hmm_pfn_t</span>
<span class="p_add">+ * Returns: valid hmm_pfn_t for the page</span>
<span class="p_add">+ */</span>
<span class="p_add">+static inline hmm_pfn_t hmm_pfn_from_page(struct page *page)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return (page_to_pfn(page) &lt;&lt; HMM_PFN_SHIFT) | HMM_PFN_VALID;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+/*</span>
<span class="p_add">+ * hmm_pfn_from_pfn() - create a valid hmm_pfn_t value from pfn</span>
<span class="p_add">+ * @pfn: pfn value for which to create the hmm_pfn_t</span>
<span class="p_add">+ * Returns: valid hmm_pfn_t for the pfn</span>
<span class="p_add">+ */</span>
<span class="p_add">+static inline hmm_pfn_t hmm_pfn_from_pfn(unsigned long pfn)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return (pfn &lt;&lt; HMM_PFN_SHIFT) | HMM_PFN_VALID;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+</span>
<span class="p_add">+/* Below are for HMM internal use only ! Not to be used by device driver ! */</span>
<span class="p_add">+void hmm_mm_destroy(struct mm_struct *mm);</span>
<span class="p_add">+</span>
<span class="p_add">+#else /* IS_ENABLED(CONFIG_HMM) */</span>
<span class="p_add">+</span>
<span class="p_add">+/* Below are for HMM internal use only ! Not to be used by device driver ! */</span>
<span class="p_add">+static inline void hmm_mm_destroy(struct mm_struct *mm) {}</span>
<span class="p_add">+</span>
<span class="p_add">+#endif /* IS_ENABLED(CONFIG_HMM) */</span>
<span class="p_add">+#endif /* LINUX_HMM_H */</span>
<span class="p_header">diff --git a/include/linux/mm_types.h b/include/linux/mm_types.h</span>
<span class="p_header">index 4a8aced..4effdbf 100644</span>
<span class="p_header">--- a/include/linux/mm_types.h</span>
<span class="p_header">+++ b/include/linux/mm_types.h</span>
<span class="p_chunk">@@ -23,6 +23,7 @@</span> <span class="p_context"></span>
 
 struct address_space;
 struct mem_cgroup;
<span class="p_add">+struct hmm;</span>
 
 #define USE_SPLIT_PTE_PTLOCKS	(NR_CPUS &gt;= CONFIG_SPLIT_PTLOCK_CPUS)
 #define USE_SPLIT_PMD_PTLOCKS	(USE_SPLIT_PTE_PTLOCKS &amp;&amp; \
<span class="p_chunk">@@ -516,6 +517,10 @@</span> <span class="p_context"> struct mm_struct {</span>
 	atomic_long_t hugetlb_usage;
 #endif
 	struct work_struct async_put_work;
<span class="p_add">+#if IS_ENABLED(CONFIG_HMM)</span>
<span class="p_add">+	/* HMM need to track few things per mm */</span>
<span class="p_add">+	struct hmm *hmm;</span>
<span class="p_add">+#endif</span>
 };
 
 static inline void mm_init_cpumask(struct mm_struct *mm)
<span class="p_header">diff --git a/kernel/fork.c b/kernel/fork.c</span>
<span class="p_header">index cfee5ec..98a297f 100644</span>
<span class="p_header">--- a/kernel/fork.c</span>
<span class="p_header">+++ b/kernel/fork.c</span>
<span class="p_chunk">@@ -27,6 +27,7 @@</span> <span class="p_context"></span>
 #include &lt;linux/binfmts.h&gt;
 #include &lt;linux/mman.h&gt;
 #include &lt;linux/mmu_notifier.h&gt;
<span class="p_add">+#include &lt;linux/hmm.h&gt;</span>
 #include &lt;linux/fs.h&gt;
 #include &lt;linux/mm.h&gt;
 #include &lt;linux/vmacache.h&gt;
<span class="p_chunk">@@ -843,6 +844,7 @@</span> <span class="p_context"> void __mmdrop(struct mm_struct *mm)</span>
 	BUG_ON(mm == &amp;init_mm);
 	mm_free_pgd(mm);
 	destroy_context(mm);
<span class="p_add">+	hmm_mm_destroy(mm);</span>
 	mmu_notifier_mm_destroy(mm);
 	check_mm(mm);
 	free_mm(mm);
<span class="p_header">diff --git a/mm/Kconfig b/mm/Kconfig</span>
<span class="p_header">index 0c33f46..9cdf361e 100644</span>
<span class="p_header">--- a/mm/Kconfig</span>
<span class="p_header">+++ b/mm/Kconfig</span>
<span class="p_chunk">@@ -289,6 +289,10 @@</span> <span class="p_context"> config MIGRATION</span>
 config ARCH_ENABLE_HUGEPAGE_MIGRATION
 	bool
 
<span class="p_add">+config HMM</span>
<span class="p_add">+	bool</span>
<span class="p_add">+	depends on MMU</span>
<span class="p_add">+</span>
 config PHYS_ADDR_T_64BIT
 	def_bool 64BIT || ARCH_PHYS_ADDR_T_64BIT
 
<span class="p_header">diff --git a/mm/Makefile b/mm/Makefile</span>
<span class="p_header">index 295bd7a..e4d9f48 100644</span>
<span class="p_header">--- a/mm/Makefile</span>
<span class="p_header">+++ b/mm/Makefile</span>
<span class="p_chunk">@@ -73,6 +73,7 @@</span> <span class="p_context"> obj-$(CONFIG_FAILSLAB) += failslab.o</span>
 obj-$(CONFIG_MEMORY_HOTPLUG) += memory_hotplug.o
 obj-$(CONFIG_MEMTEST)		+= memtest.o
 obj-$(CONFIG_MIGRATION) += migrate.o
<span class="p_add">+obj-$(CONFIG_HMM) += hmm.o</span>
 obj-$(CONFIG_QUICKLIST) += quicklist.o
 obj-$(CONFIG_TRANSPARENT_HUGEPAGE) += huge_memory.o khugepaged.o
 obj-$(CONFIG_PAGE_COUNTER) += page_counter.o
<span class="p_header">diff --git a/mm/hmm.c b/mm/hmm.c</span>
new file mode 100644
<span class="p_header">index 0000000..e891fdd</span>
<span class="p_header">--- /dev/null</span>
<span class="p_header">+++ b/mm/hmm.c</span>
<span class="p_chunk">@@ -0,0 +1,82 @@</span> <span class="p_context"></span>
<span class="p_add">+/*</span>
<span class="p_add">+ * Copyright 2013 Red Hat Inc.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * This program is free software; you can redistribute it and/or modify</span>
<span class="p_add">+ * it under the terms of the GNU General Public License as published by</span>
<span class="p_add">+ * the Free Software Foundation; either version 2 of the License, or</span>
<span class="p_add">+ * (at your option) any later version.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * This program is distributed in the hope that it will be useful,</span>
<span class="p_add">+ * but WITHOUT ANY WARRANTY; without even the implied warranty of</span>
<span class="p_add">+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the</span>
<span class="p_add">+ * GNU General Public License for more details.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * Authors: Jérôme Glisse &lt;jglisse@redhat.com&gt;</span>
<span class="p_add">+ */</span>
<span class="p_add">+/*</span>
<span class="p_add">+ * Refer to include/linux/hmm.h for information about heterogeneous memory</span>
<span class="p_add">+ * management or HMM for short.</span>
<span class="p_add">+ */</span>
<span class="p_add">+#include &lt;linux/mm.h&gt;</span>
<span class="p_add">+#include &lt;linux/hmm.h&gt;</span>
<span class="p_add">+#include &lt;linux/slab.h&gt;</span>
<span class="p_add">+#include &lt;linux/sched.h&gt;</span>
<span class="p_add">+</span>
<span class="p_add">+/*</span>
<span class="p_add">+ * struct hmm - HMM per mm struct</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * @mm: mm struct this HMM struct is bound to</span>
<span class="p_add">+ */</span>
<span class="p_add">+struct hmm {</span>
<span class="p_add">+	struct mm_struct	*mm;</span>
<span class="p_add">+};</span>
<span class="p_add">+</span>
<span class="p_add">+/*</span>
<span class="p_add">+ * hmm_register - register HMM against an mm (HMM internal)</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * @mm: mm struct to attach to</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * This is not intended to be use directly by device driver but by other HMM</span>
<span class="p_add">+ * component. It allocates an HMM struct if mm does not have one and initialize</span>
<span class="p_add">+ * it.</span>
<span class="p_add">+ */</span>
<span class="p_add">+static struct hmm *hmm_register(struct mm_struct *mm)</span>
<span class="p_add">+{</span>
<span class="p_add">+	if (!mm-&gt;hmm) {</span>
<span class="p_add">+		struct hmm *hmm = NULL;</span>
<span class="p_add">+</span>
<span class="p_add">+		hmm = kmalloc(sizeof(*hmm), GFP_KERNEL);</span>
<span class="p_add">+		if (!hmm)</span>
<span class="p_add">+			return NULL;</span>
<span class="p_add">+		hmm-&gt;mm = mm;</span>
<span class="p_add">+</span>
<span class="p_add">+		spin_lock(&amp;mm-&gt;page_table_lock);</span>
<span class="p_add">+		if (!mm-&gt;hmm)</span>
<span class="p_add">+			mm-&gt;hmm = hmm;</span>
<span class="p_add">+		else</span>
<span class="p_add">+			kfree(hmm);</span>
<span class="p_add">+		spin_unlock(&amp;mm-&gt;page_table_lock);</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * The hmm struct can only be free once mm_struct goes away</span>
<span class="p_add">+	 * hence we should always have pre-allocated an new hmm struct</span>
<span class="p_add">+	 * above.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	return mm-&gt;hmm;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void hmm_mm_destroy(struct mm_struct *mm)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct hmm *hmm;</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * We should not need to lock here as no one should be able to register</span>
<span class="p_add">+	 * a new HMM while an mm is being destroy. But just to be safe ...</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	spin_lock(&amp;mm-&gt;page_table_lock);</span>
<span class="p_add">+	hmm = mm-&gt;hmm;</span>
<span class="p_add">+	mm-&gt;hmm = NULL;</span>
<span class="p_add">+	spin_unlock(&amp;mm-&gt;page_table_lock);</span>
<span class="p_add">+	kfree(hmm);</span>
<span class="p_add">+}</span>

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



