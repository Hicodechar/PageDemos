
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>[2/3] swiotlb: prefix dma_to_phys and phys_to_dma functions - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    [2/3] swiotlb: prefix dma_to_phys and phys_to_dma functions</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=145491">Sinan Kaya</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>March 17, 2016, 10:02 p.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;1458252137-24497-2-git-send-email-okaya@codeaurora.org&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/8614571/mbox/"
   >mbox</a>
|
   <a href="/patch/8614571/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/8614571/">/patch/8614571/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
X-Original-To: patchwork-LKML@patchwork.kernel.org
Delivered-To: patchwork-parsemail@patchwork1.web.kernel.org
Received: from mail.kernel.org (mail.kernel.org [198.145.29.136])
	by patchwork1.web.kernel.org (Postfix) with ESMTP id 4B6799F6E1
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Thu, 17 Mar 2016 22:03:24 +0000 (UTC)
Received: from mail.kernel.org (localhost [127.0.0.1])
	by mail.kernel.org (Postfix) with ESMTP id 6DE10202AE
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Thu, 17 Mar 2016 22:03:22 +0000 (UTC)
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.kernel.org (Postfix) with ESMTP id 70DDE202FE
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Thu, 17 Mar 2016 22:03:20 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1031609AbcCQWDP (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Thu, 17 Mar 2016 18:03:15 -0400
Received: from smtp.codeaurora.org ([198.145.29.96]:43869 &quot;EHLO
	smtp.codeaurora.org&quot; rhost-flags-OK-OK-OK-OK) by vger.kernel.org
	with ESMTP id S1031410AbcCQWDB (ORCPT
	&lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Thu, 17 Mar 2016 18:03:01 -0400
Received: from smtp.codeaurora.org (localhost [127.0.0.1])
	by smtp.codeaurora.org (Postfix) with ESMTP id 97397611E2;
	Thu, 17 Mar 2016 22:03:00 +0000 (UTC)
Received: by smtp.codeaurora.org (Postfix, from userid 1000)
	id 8E9BF611F6; Thu, 17 Mar 2016 22:03:00 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on mail.kernel.org
X-Spam-Level: 
X-Spam-Status: No, score=-6.9 required=5.0 tests=BAYES_00, RCVD_IN_DNSWL_HI, 
	RP_MATCHES_RCVD,
	UNPARSEABLE_RELAY autolearn=unavailable version=3.3.1
Received: from drakthul.qualcomm.com (global_nat1_iad_fw.qualcomm.com
	[129.46.232.65])
	(using TLSv1.2 with cipher ECDHE-RSA-AES256-GCM-SHA384 (256/256
	bits)) (No client certificate requested)
	(Authenticated sender: okaya@smtp.codeaurora.org)
	by smtp.codeaurora.org (Postfix) with ESMTPSA id 3188E60316;
	Thu, 17 Mar 2016 22:02:51 +0000 (UTC)
From: Sinan Kaya &lt;okaya@codeaurora.org&gt;
To: linux-arm-kernel@lists.infradead.org, timur@codeaurora.org,
	cov@codeaurora.org, nwatters@codeaurora.org
Cc: Sinan Kaya &lt;okaya@codeaurora.org&gt;, Russell King &lt;linux@arm.linux.org.uk&gt;,
	Catalin Marinas &lt;catalin.marinas@arm.com&gt;,
	Will Deacon &lt;will.deacon@arm.com&gt;, Tony Luck &lt;tony.luck@intel.com&gt;,
	Fenghua Yu &lt;fenghua.yu@intel.com&gt;, Ralf Baechle &lt;ralf@linux-mips.org&gt;,
	Benjamin Herrenschmidt &lt;benh@kernel.crashing.org&gt;,
	Paul Mackerras &lt;paulus@samba.org&gt;, Michael Ellerman &lt;mpe@ellerman.id.au&gt;,
	Chris Metcalf &lt;cmetcalf@ezchip.com&gt;, Guan Xuetao &lt;gxt@mprc.pku.edu.cn&gt;,
	Thomas Gleixner &lt;tglx@linutronix.de&gt;, Ingo Molnar &lt;mingo@redhat.com&gt;,
	&quot;H. Peter Anvin&quot; &lt;hpa@zytor.com&gt;, x86@kernel.org,
	Konrad Rzeszutek Wilk &lt;konrad.wilk@oracle.com&gt;,
	Bjorn Helgaas &lt;bhelgaas@google.com&gt;, Chris Zankel &lt;chris@zankel.net&gt;,
	Max Filippov &lt;jcmvbkbc@gmail.com&gt;,
	Andrew Morton &lt;akpm@linux-foundation.org&gt;,
	Valentin Rothberg &lt;valentinrothberg@gmail.com&gt;,
	Marek Szyprowski &lt;m.szyprowski@samsung.com&gt;,
	Joe Perches &lt;joe@perches.com&gt;,
	&quot;Suthikulpanit, Suravee&quot; &lt;Suravee.Suthikulpanit@amd.com&gt;,
	Robin Murphy &lt;robin.murphy@arm.com&gt;, Arnd Bergmann &lt;arnd@arndb.de&gt;,
	Jisheng Zhang &lt;jszhang@marvell.com&gt;, Dean Nelson &lt;dnelson@redhat.com&gt;,
	Guenter Roeck &lt;linux@roeck-us.net&gt;, Aaro Koskinen &lt;aaro.koskinen@iki.fi&gt;,
	Florian Fainelli &lt;f.fainelli@gmail.com&gt;, Huacai Chen &lt;chenhc@lemote.com&gt;,
	Denys Vlasenko &lt;dvlasenk@redhat.com&gt;,
	Akinobu Mita &lt;akinobu.mita@gmail.com&gt;,
	linux-kernel@vger.kernel.org, linux-ia64@vger.kernel.org,
	linux-mips@linux-mips.org, linuxppc-dev@lists.ozlabs.org,
	linux-pci@vger.kernel.org, linux-xtensa@linux-xtensa.org
Subject: [PATCH 2/3] swiotlb: prefix dma_to_phys and phys_to_dma functions
Date: Thu, 17 Mar 2016 18:02:16 -0400
Message-Id: &lt;1458252137-24497-2-git-send-email-okaya@codeaurora.org&gt;
X-Mailer: git-send-email 1.8.2.1
In-Reply-To: &lt;1458252137-24497-1-git-send-email-okaya@codeaurora.org&gt;
References: &lt;1458252137-24497-1-git-send-email-okaya@codeaurora.org&gt;
X-Virus-Scanned: ClamAV using ClamSMTP
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=145491">Sinan Kaya</a> - March 17, 2016, 10:02 p.m.</div>
<pre class="content">
Prefixing dma_to_phys and phys_to_dma API with swiotlb so that
they are no longer part of the DMA API. These APIs do not exist
on all architectures and breaks compatibility.

In preparation for the clean up, also make the ARCH implementation
known by defining swiotlb_phys_do_dma and swiotlb_dma_to_phys.
<span class="signed-off-by">
Signed-off-by: Sinan Kaya &lt;okaya@codeaurora.org&gt;</span>
---
 arch/arm/include/asm/dma-mapping.h                 |  8 ++-
 arch/arm64/include/asm/dma-mapping.h               |  9 ++-
 arch/arm64/mm/dma-mapping.c                        | 75 ++++++++++++++--------
 arch/ia64/include/asm/dma-mapping.h                |  8 ++-
 arch/mips/cavium-octeon/dma-octeon.c               |  8 +--
 .../include/asm/mach-cavium-octeon/dma-coherence.h |  7 +-
 arch/mips/include/asm/mach-generic/dma-coherence.h |  8 ++-
 .../include/asm/mach-loongson64/dma-coherence.h    | 14 ++--
 arch/mips/loongson64/common/dma-swiotlb.c          |  4 +-
 arch/powerpc/include/asm/dma-mapping.h             |  8 ++-
 arch/tile/include/asm/dma-mapping.h                |  8 ++-
 arch/unicore32/include/asm/dma-mapping.h           |  8 ++-
 arch/x86/include/asm/dma-mapping.h                 | 15 +++--
 arch/x86/kernel/pci-swiotlb.c                      |  2 +-
 arch/x86/pci/sta2x11-fixup.c                       | 10 +--
 arch/xtensa/include/asm/dma-mapping.h              |  8 ++-
 lib/swiotlb.c                                      | 28 ++++----
 17 files changed, 150 insertions(+), 78 deletions(-)
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=77581">Robin Murphy</a> - March 18, 2016, 12:12 p.m.</div>
<pre class="content">
On 17/03/16 22:02, Sinan Kaya wrote:
<span class="quote">&gt; Prefixing dma_to_phys and phys_to_dma API with swiotlb so that</span>
<span class="quote">&gt; they are no longer part of the DMA API. These APIs do not exist</span>
<span class="quote">&gt; on all architectures and breaks compatibility.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; In preparation for the clean up, also make the ARCH implementation</span>
<span class="quote">&gt; known by defining swiotlb_phys_do_dma and swiotlb_dma_to_phys.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; Signed-off-by: Sinan Kaya &lt;okaya@codeaurora.org&gt;</span>
<span class="quote">&gt; ---</span>
<span class="quote">&gt;   arch/arm/include/asm/dma-mapping.h                 |  8 ++-</span>
<span class="quote">&gt;   arch/arm64/include/asm/dma-mapping.h               |  9 ++-</span>
<span class="quote">&gt;   arch/arm64/mm/dma-mapping.c                        | 75 ++++++++++++++--------</span>

[...]
<span class="quote">
&gt; diff --git a/arch/arm64/mm/dma-mapping.c b/arch/arm64/mm/dma-mapping.c</span>
<span class="quote">&gt; index a6e757c..ada00c3 100644</span>
<span class="quote">&gt; --- a/arch/arm64/mm/dma-mapping.c</span>
<span class="quote">&gt; +++ b/arch/arm64/mm/dma-mapping.c</span>
<span class="quote">&gt; @@ -107,7 +107,7 @@ static void *__dma_alloc_coherent(struct device *dev, size_t size,</span>
<span class="quote">&gt;   		if (!page)</span>
<span class="quote">&gt;   			return NULL;</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; -		*dma_handle = phys_to_dma(dev, page_to_phys(page));</span>
<span class="quote">&gt; +		*dma_handle = swiotlb_phys_to_dma(dev, page_to_phys(page));</span>
<span class="quote">&gt;   		addr = page_address(page);</span>
<span class="quote">&gt;   		memset(addr, 0, size);</span>
<span class="quote">&gt;   		return addr;</span>
<span class="quote">&gt; @@ -121,7 +121,7 @@ static void __dma_free_coherent(struct device *dev, size_t size,</span>
<span class="quote">&gt;   				struct dma_attrs *attrs)</span>
<span class="quote">&gt;   {</span>
<span class="quote">&gt;   	bool freed;</span>
<span class="quote">&gt; -	phys_addr_t paddr = dma_to_phys(dev, dma_handle);</span>
<span class="quote">&gt; +	phys_addr_t paddr = swiotlb_dma_to_phys(dev, dma_handle);</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;   	if (dev == NULL) {</span>
<span class="quote">&gt;   		WARN_ONCE(1, &quot;Use an actual device structure for DMA allocation\n&quot;);</span>
<span class="quote">&gt; @@ -151,7 +151,8 @@ static void *__dma_alloc(struct device *dev, size_t size,</span>
<span class="quote">&gt;   		void *addr = __alloc_from_pool(size, &amp;page, flags);</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;   		if (addr)</span>
<span class="quote">&gt; -			*dma_handle = phys_to_dma(dev, page_to_phys(page));</span>
<span class="quote">&gt; +			*dma_handle = swiotlb_phys_to_dma(dev,</span>
<span class="quote">&gt; +							  page_to_phys(page));</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;   		return addr;</span>
<span class="quote">&gt;   	}</span>
<span class="quote">&gt; @@ -187,7 +188,7 @@ static void __dma_free(struct device *dev, size_t size,</span>
<span class="quote">&gt;   		       void *vaddr, dma_addr_t dma_handle,</span>
<span class="quote">&gt;   		       struct dma_attrs *attrs)</span>
<span class="quote">&gt;   {</span>
<span class="quote">&gt; -	void *swiotlb_addr = phys_to_virt(dma_to_phys(dev, dma_handle));</span>
<span class="quote">&gt; +	void *swiotlb_addr = phys_to_virt(swiotlb_dma_to_phys(dev, dma_handle));</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;   	size = PAGE_ALIGN(size);</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; @@ -208,7 +209,8 @@ static dma_addr_t __swiotlb_map_page(struct device *dev, struct page *page,</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;   	dev_addr = swiotlb_map_page(dev, page, offset, size, dir, attrs);</span>
<span class="quote">&gt;   	if (!is_device_dma_coherent(dev))</span>
<span class="quote">&gt; -		__dma_map_area(phys_to_virt(dma_to_phys(dev, dev_addr)), size, dir);</span>
<span class="quote">&gt; +		__dma_map_area(phys_to_virt(swiotlb_dma_to_phys(dev, dev_addr)),</span>
<span class="quote">&gt; +			       size, dir);</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;   	return dev_addr;</span>
<span class="quote">&gt;   }</span>
<span class="quote">&gt; @@ -218,8 +220,11 @@ static void __swiotlb_unmap_page(struct device *dev, dma_addr_t dev_addr,</span>
<span class="quote">&gt;   				 size_t size, enum dma_data_direction dir,</span>
<span class="quote">&gt;   				 struct dma_attrs *attrs)</span>
<span class="quote">&gt;   {</span>
<span class="quote">&gt; -	if (!is_device_dma_coherent(dev))</span>
<span class="quote">&gt; -		__dma_unmap_area(phys_to_virt(dma_to_phys(dev, dev_addr)), size, dir);</span>
<span class="quote">&gt; +	if (!is_device_dma_coherent(dev)) {</span>
<span class="quote">&gt; +		phys_addr_t phys = swiotlb_dma_to_phys(dev, dev_addr);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +		__dma_unmap_area(phys_to_virt(phys), size, dir);</span>
<span class="quote">&gt; +	}</span>
<span class="quote">&gt;   	swiotlb_unmap_page(dev, dev_addr, size, dir, attrs);</span>
<span class="quote">&gt;   }</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; @@ -232,9 +237,12 @@ static int __swiotlb_map_sg_attrs(struct device *dev, struct scatterlist *sgl,</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;   	ret = swiotlb_map_sg_attrs(dev, sgl, nelems, dir, attrs);</span>
<span class="quote">&gt;   	if (!is_device_dma_coherent(dev))</span>
<span class="quote">&gt; -		for_each_sg(sgl, sg, ret, i)</span>
<span class="quote">&gt; -			__dma_map_area(phys_to_virt(dma_to_phys(dev, sg-&gt;dma_address)),</span>
<span class="quote">&gt; -				       sg-&gt;length, dir);</span>
<span class="quote">&gt; +		for_each_sg(sgl, sg, ret, i) {</span>
<span class="quote">&gt; +			dma_addr_t dma = sg-&gt;dma_address;</span>
<span class="quote">&gt; +			phys_addr_t phys = swiotlb_dma_to_phys(dev, dma);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +			__dma_map_area(phys_to_virt(phys), sg-&gt;length, dir);</span>
<span class="quote">&gt; +		}</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;   	return ret;</span>
<span class="quote">&gt;   }</span>
<span class="quote">&gt; @@ -248,9 +256,12 @@ static void __swiotlb_unmap_sg_attrs(struct device *dev,</span>
<span class="quote">&gt;   	int i;</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;   	if (!is_device_dma_coherent(dev))</span>
<span class="quote">&gt; -		for_each_sg(sgl, sg, nelems, i)</span>
<span class="quote">&gt; -			__dma_unmap_area(phys_to_virt(dma_to_phys(dev, sg-&gt;dma_address)),</span>
<span class="quote">&gt; -					 sg-&gt;length, dir);</span>
<span class="quote">&gt; +		for_each_sg(sgl, sg, nelems, i) {</span>
<span class="quote">&gt; +			dma_addr_t dma = sg-&gt;dma_address;</span>
<span class="quote">&gt; +			phys_addr_t phys = swiotlb_dma_to_phys(dev, dma);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +			__dma_unmap_area(phys_to_virt(phys), sg-&gt;length, dir);</span>
<span class="quote">&gt; +		}</span>
<span class="quote">&gt;   	swiotlb_unmap_sg_attrs(dev, sgl, nelems, dir, attrs);</span>
<span class="quote">&gt;   }</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; @@ -258,8 +269,11 @@ static void __swiotlb_sync_single_for_cpu(struct device *dev,</span>
<span class="quote">&gt;   					  dma_addr_t dev_addr, size_t size,</span>
<span class="quote">&gt;   					  enum dma_data_direction dir)</span>
<span class="quote">&gt;   {</span>
<span class="quote">&gt; -	if (!is_device_dma_coherent(dev))</span>
<span class="quote">&gt; -		__dma_unmap_area(phys_to_virt(dma_to_phys(dev, dev_addr)), size, dir);</span>
<span class="quote">&gt; +	if (!is_device_dma_coherent(dev)) {</span>
<span class="quote">&gt; +		phys_addr_t phys = swiotlb_dma_to_phys(dev, dev_addr);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +		__dma_unmap_area(phys_to_virt(phys), size, dir);</span>
<span class="quote">&gt; +	}</span>
<span class="quote">&gt;   	swiotlb_sync_single_for_cpu(dev, dev_addr, size, dir);</span>
<span class="quote">&gt;   }</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; @@ -269,7 +283,8 @@ static void __swiotlb_sync_single_for_device(struct device *dev,</span>
<span class="quote">&gt;   {</span>
<span class="quote">&gt;   	swiotlb_sync_single_for_device(dev, dev_addr, size, dir);</span>
<span class="quote">&gt;   	if (!is_device_dma_coherent(dev))</span>
<span class="quote">&gt; -		__dma_map_area(phys_to_virt(dma_to_phys(dev, dev_addr)), size, dir);</span>
<span class="quote">&gt; +		__dma_map_area(phys_to_virt(swiotlb_dma_to_phys(dev, dev_addr)),</span>
<span class="quote">&gt; +			       size, dir);</span>
<span class="quote">&gt;   }</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;   static void __swiotlb_sync_sg_for_cpu(struct device *dev,</span>
<span class="quote">&gt; @@ -280,9 +295,12 @@ static void __swiotlb_sync_sg_for_cpu(struct device *dev,</span>
<span class="quote">&gt;   	int i;</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;   	if (!is_device_dma_coherent(dev))</span>
<span class="quote">&gt; -		for_each_sg(sgl, sg, nelems, i)</span>
<span class="quote">&gt; -			__dma_unmap_area(phys_to_virt(dma_to_phys(dev, sg-&gt;dma_address)),</span>
<span class="quote">&gt; -					 sg-&gt;length, dir);</span>
<span class="quote">&gt; +		for_each_sg(sgl, sg, nelems, i) {</span>
<span class="quote">&gt; +			dma_addr_t dma = sg-&gt;dma_address;</span>
<span class="quote">&gt; +			phys_addr_t phys = swiotlb_dma_to_phys(dev, dma);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +			__dma_unmap_area(phys_to_virt(phys), sg-&gt;length, dir);</span>
<span class="quote">&gt; +		}</span>
<span class="quote">&gt;   	swiotlb_sync_sg_for_cpu(dev, sgl, nelems, dir);</span>
<span class="quote">&gt;   }</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; @@ -295,9 +313,12 @@ static void __swiotlb_sync_sg_for_device(struct device *dev,</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;   	swiotlb_sync_sg_for_device(dev, sgl, nelems, dir);</span>
<span class="quote">&gt;   	if (!is_device_dma_coherent(dev))</span>
<span class="quote">&gt; -		for_each_sg(sgl, sg, nelems, i)</span>
<span class="quote">&gt; -			__dma_map_area(phys_to_virt(dma_to_phys(dev, sg-&gt;dma_address)),</span>
<span class="quote">&gt; -				       sg-&gt;length, dir);</span>
<span class="quote">&gt; +		for_each_sg(sgl, sg, nelems, i) {</span>
<span class="quote">&gt; +			dma_addr_t dma = sg-&gt;dma_address;</span>
<span class="quote">&gt; +			phys_addr_t phys = swiotlb_dma_to_phys(dev, dma);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +			__dma_map_area(phys_to_virt(phys), sg-&gt;length, dir);</span>
<span class="quote">&gt; +		}</span>
<span class="quote">&gt;   }</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;   static int __swiotlb_mmap(struct device *dev,</span>
<span class="quote">&gt; @@ -309,7 +330,7 @@ static int __swiotlb_mmap(struct device *dev,</span>
<span class="quote">&gt;   	unsigned long nr_vma_pages = (vma-&gt;vm_end - vma-&gt;vm_start) &gt;&gt;</span>
<span class="quote">&gt;   					PAGE_SHIFT;</span>
<span class="quote">&gt;   	unsigned long nr_pages = PAGE_ALIGN(size) &gt;&gt; PAGE_SHIFT;</span>
<span class="quote">&gt; -	unsigned long pfn = dma_to_phys(dev, dma_addr) &gt;&gt; PAGE_SHIFT;</span>
<span class="quote">&gt; +	unsigned long pfn = swiotlb_dma_to_phys(dev, dma_addr) &gt;&gt; PAGE_SHIFT;</span>
<span class="quote">&gt;   	unsigned long off = vma-&gt;vm_pgoff;</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;   	vma-&gt;vm_page_prot = __get_dma_pgprot(attrs, vma-&gt;vm_page_prot,</span>
<span class="quote">&gt; @@ -334,9 +355,11 @@ static int __swiotlb_get_sgtable(struct device *dev, struct sg_table *sgt,</span>
<span class="quote">&gt;   {</span>
<span class="quote">&gt;   	int ret = sg_alloc_table(sgt, 1, GFP_KERNEL);</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; -	if (!ret)</span>
<span class="quote">&gt; -		sg_set_page(sgt-&gt;sgl, phys_to_page(dma_to_phys(dev, handle)),</span>
<span class="quote">&gt; -			    PAGE_ALIGN(size), 0);</span>
<span class="quote">&gt; +	if (!ret) {</span>
<span class="quote">&gt; +		phys_addr_t phys = swiotlb_dma_to_phys(dev, handle);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +		sg_set_page(sgt-&gt;sgl, phys_to_page(phys), PAGE_ALIGN(size), 0);</span>
<span class="quote">&gt; +	}</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;   	return ret;</span>
<span class="quote">&gt;   }</span>

Since we know for sure that swiotlb_to_phys is a no-op on arm64, it 
might be cleaner to simply not reference it at all. I suppose we could 
have some private local wrappers, e.g.:

#define swiotlb_to_virt(addr) phys_to_virt((phys_addr_t)(addr))

to keep the intent of the code clear (and just in case anyone ever 
builds a system mad enough to warrant switching out that definition, but 
I&#39;d hope that never happens).

Otherwise, looks good - thanks for doing this!

Robin.
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/arch/arm/include/asm/dma-mapping.h b/arch/arm/include/asm/dma-mapping.h</span>
<span class="p_header">index 6ad1ced..e176689 100644</span>
<span class="p_header">--- a/arch/arm/include/asm/dma-mapping.h</span>
<span class="p_header">+++ b/arch/arm/include/asm/dma-mapping.h</span>
<span class="p_chunk">@@ -129,17 +129,21 @@</span> <span class="p_context"> static inline bool is_device_dma_coherent(struct device *dev)</span>
 	return dev-&gt;archdata.dma_coherent;
 }
 
<span class="p_del">-static inline dma_addr_t phys_to_dma(struct device *dev, phys_addr_t paddr)</span>
<span class="p_add">+static inline dma_addr_t swiotlb_phys_to_dma(struct device *dev,</span>
<span class="p_add">+					     phys_addr_t paddr)</span>
 {
 	unsigned int offset = paddr &amp; ~PAGE_MASK;
 	return pfn_to_dma(dev, __phys_to_pfn(paddr)) + offset;
 }
<span class="p_add">+#define swiotlb_phys_to_dma swiotlb_phys_to_dma</span>
 
<span class="p_del">-static inline phys_addr_t dma_to_phys(struct device *dev, dma_addr_t dev_addr)</span>
<span class="p_add">+static inline phys_addr_t swiotlb_dma_to_phys(struct device *dev,</span>
<span class="p_add">+					      dma_addr_t dev_addr)</span>
 {
 	unsigned int offset = dev_addr &amp; ~PAGE_MASK;
 	return __pfn_to_phys(dma_to_pfn(dev, dev_addr)) + offset;
 }
<span class="p_add">+#define swiotlb_dma_to_phys swiotlb_dma_to_phys</span>
 
 static inline bool dma_capable(struct device *dev, dma_addr_t addr, size_t size)
 {
<span class="p_header">diff --git a/arch/arm64/include/asm/dma-mapping.h b/arch/arm64/include/asm/dma-mapping.h</span>
<span class="p_header">index ba437f0..39f21e8 100644</span>
<span class="p_header">--- a/arch/arm64/include/asm/dma-mapping.h</span>
<span class="p_header">+++ b/arch/arm64/include/asm/dma-mapping.h</span>
<span class="p_chunk">@@ -64,15 +64,19 @@</span> <span class="p_context"> static inline bool is_device_dma_coherent(struct device *dev)</span>
 	return dev-&gt;archdata.dma_coherent;
 }
 
<span class="p_del">-static inline dma_addr_t phys_to_dma(struct device *dev, phys_addr_t paddr)</span>
<span class="p_add">+static inline dma_addr_t swiotlb_phys_to_dma(struct device *dev,</span>
<span class="p_add">+					     phys_addr_t paddr)</span>
 {
 	return (dma_addr_t)paddr;
 }
<span class="p_add">+#define swiotlb_phys_to_dma swiotlb_phys_to_dma</span>
 
<span class="p_del">-static inline phys_addr_t dma_to_phys(struct device *dev, dma_addr_t dev_addr)</span>
<span class="p_add">+static inline phys_addr_t swiotlb_dma_to_phys(struct device *dev,</span>
<span class="p_add">+					      dma_addr_t dev_addr)</span>
 {
 	return (phys_addr_t)dev_addr;
 }
<span class="p_add">+#define swiotlb_dma_to_phys swiotlb_dma_to_phys</span>
 
 static inline bool dma_capable(struct device *dev, dma_addr_t addr, size_t size)
 {
<span class="p_chunk">@@ -88,3 +92,4 @@</span> <span class="p_context"> static inline void dma_mark_clean(void *addr, size_t size)</span>
 
 #endif	/* __KERNEL__ */
 #endif	/* __ASM_DMA_MAPPING_H */
<span class="p_add">+</span>
<span class="p_header">diff --git a/arch/arm64/mm/dma-mapping.c b/arch/arm64/mm/dma-mapping.c</span>
<span class="p_header">index a6e757c..ada00c3 100644</span>
<span class="p_header">--- a/arch/arm64/mm/dma-mapping.c</span>
<span class="p_header">+++ b/arch/arm64/mm/dma-mapping.c</span>
<span class="p_chunk">@@ -107,7 +107,7 @@</span> <span class="p_context"> static void *__dma_alloc_coherent(struct device *dev, size_t size,</span>
 		if (!page)
 			return NULL;
 
<span class="p_del">-		*dma_handle = phys_to_dma(dev, page_to_phys(page));</span>
<span class="p_add">+		*dma_handle = swiotlb_phys_to_dma(dev, page_to_phys(page));</span>
 		addr = page_address(page);
 		memset(addr, 0, size);
 		return addr;
<span class="p_chunk">@@ -121,7 +121,7 @@</span> <span class="p_context"> static void __dma_free_coherent(struct device *dev, size_t size,</span>
 				struct dma_attrs *attrs)
 {
 	bool freed;
<span class="p_del">-	phys_addr_t paddr = dma_to_phys(dev, dma_handle);</span>
<span class="p_add">+	phys_addr_t paddr = swiotlb_dma_to_phys(dev, dma_handle);</span>
 
 	if (dev == NULL) {
 		WARN_ONCE(1, &quot;Use an actual device structure for DMA allocation\n&quot;);
<span class="p_chunk">@@ -151,7 +151,8 @@</span> <span class="p_context"> static void *__dma_alloc(struct device *dev, size_t size,</span>
 		void *addr = __alloc_from_pool(size, &amp;page, flags);
 
 		if (addr)
<span class="p_del">-			*dma_handle = phys_to_dma(dev, page_to_phys(page));</span>
<span class="p_add">+			*dma_handle = swiotlb_phys_to_dma(dev,</span>
<span class="p_add">+							  page_to_phys(page));</span>
 
 		return addr;
 	}
<span class="p_chunk">@@ -187,7 +188,7 @@</span> <span class="p_context"> static void __dma_free(struct device *dev, size_t size,</span>
 		       void *vaddr, dma_addr_t dma_handle,
 		       struct dma_attrs *attrs)
 {
<span class="p_del">-	void *swiotlb_addr = phys_to_virt(dma_to_phys(dev, dma_handle));</span>
<span class="p_add">+	void *swiotlb_addr = phys_to_virt(swiotlb_dma_to_phys(dev, dma_handle));</span>
 
 	size = PAGE_ALIGN(size);
 
<span class="p_chunk">@@ -208,7 +209,8 @@</span> <span class="p_context"> static dma_addr_t __swiotlb_map_page(struct device *dev, struct page *page,</span>
 
 	dev_addr = swiotlb_map_page(dev, page, offset, size, dir, attrs);
 	if (!is_device_dma_coherent(dev))
<span class="p_del">-		__dma_map_area(phys_to_virt(dma_to_phys(dev, dev_addr)), size, dir);</span>
<span class="p_add">+		__dma_map_area(phys_to_virt(swiotlb_dma_to_phys(dev, dev_addr)),</span>
<span class="p_add">+			       size, dir);</span>
 
 	return dev_addr;
 }
<span class="p_chunk">@@ -218,8 +220,11 @@</span> <span class="p_context"> static void __swiotlb_unmap_page(struct device *dev, dma_addr_t dev_addr,</span>
 				 size_t size, enum dma_data_direction dir,
 				 struct dma_attrs *attrs)
 {
<span class="p_del">-	if (!is_device_dma_coherent(dev))</span>
<span class="p_del">-		__dma_unmap_area(phys_to_virt(dma_to_phys(dev, dev_addr)), size, dir);</span>
<span class="p_add">+	if (!is_device_dma_coherent(dev)) {</span>
<span class="p_add">+		phys_addr_t phys = swiotlb_dma_to_phys(dev, dev_addr);</span>
<span class="p_add">+</span>
<span class="p_add">+		__dma_unmap_area(phys_to_virt(phys), size, dir);</span>
<span class="p_add">+	}</span>
 	swiotlb_unmap_page(dev, dev_addr, size, dir, attrs);
 }
 
<span class="p_chunk">@@ -232,9 +237,12 @@</span> <span class="p_context"> static int __swiotlb_map_sg_attrs(struct device *dev, struct scatterlist *sgl,</span>
 
 	ret = swiotlb_map_sg_attrs(dev, sgl, nelems, dir, attrs);
 	if (!is_device_dma_coherent(dev))
<span class="p_del">-		for_each_sg(sgl, sg, ret, i)</span>
<span class="p_del">-			__dma_map_area(phys_to_virt(dma_to_phys(dev, sg-&gt;dma_address)),</span>
<span class="p_del">-				       sg-&gt;length, dir);</span>
<span class="p_add">+		for_each_sg(sgl, sg, ret, i) {</span>
<span class="p_add">+			dma_addr_t dma = sg-&gt;dma_address;</span>
<span class="p_add">+			phys_addr_t phys = swiotlb_dma_to_phys(dev, dma);</span>
<span class="p_add">+</span>
<span class="p_add">+			__dma_map_area(phys_to_virt(phys), sg-&gt;length, dir);</span>
<span class="p_add">+		}</span>
 
 	return ret;
 }
<span class="p_chunk">@@ -248,9 +256,12 @@</span> <span class="p_context"> static void __swiotlb_unmap_sg_attrs(struct device *dev,</span>
 	int i;
 
 	if (!is_device_dma_coherent(dev))
<span class="p_del">-		for_each_sg(sgl, sg, nelems, i)</span>
<span class="p_del">-			__dma_unmap_area(phys_to_virt(dma_to_phys(dev, sg-&gt;dma_address)),</span>
<span class="p_del">-					 sg-&gt;length, dir);</span>
<span class="p_add">+		for_each_sg(sgl, sg, nelems, i) {</span>
<span class="p_add">+			dma_addr_t dma = sg-&gt;dma_address;</span>
<span class="p_add">+			phys_addr_t phys = swiotlb_dma_to_phys(dev, dma);</span>
<span class="p_add">+</span>
<span class="p_add">+			__dma_unmap_area(phys_to_virt(phys), sg-&gt;length, dir);</span>
<span class="p_add">+		}</span>
 	swiotlb_unmap_sg_attrs(dev, sgl, nelems, dir, attrs);
 }
 
<span class="p_chunk">@@ -258,8 +269,11 @@</span> <span class="p_context"> static void __swiotlb_sync_single_for_cpu(struct device *dev,</span>
 					  dma_addr_t dev_addr, size_t size,
 					  enum dma_data_direction dir)
 {
<span class="p_del">-	if (!is_device_dma_coherent(dev))</span>
<span class="p_del">-		__dma_unmap_area(phys_to_virt(dma_to_phys(dev, dev_addr)), size, dir);</span>
<span class="p_add">+	if (!is_device_dma_coherent(dev)) {</span>
<span class="p_add">+		phys_addr_t phys = swiotlb_dma_to_phys(dev, dev_addr);</span>
<span class="p_add">+</span>
<span class="p_add">+		__dma_unmap_area(phys_to_virt(phys), size, dir);</span>
<span class="p_add">+	}</span>
 	swiotlb_sync_single_for_cpu(dev, dev_addr, size, dir);
 }
 
<span class="p_chunk">@@ -269,7 +283,8 @@</span> <span class="p_context"> static void __swiotlb_sync_single_for_device(struct device *dev,</span>
 {
 	swiotlb_sync_single_for_device(dev, dev_addr, size, dir);
 	if (!is_device_dma_coherent(dev))
<span class="p_del">-		__dma_map_area(phys_to_virt(dma_to_phys(dev, dev_addr)), size, dir);</span>
<span class="p_add">+		__dma_map_area(phys_to_virt(swiotlb_dma_to_phys(dev, dev_addr)),</span>
<span class="p_add">+			       size, dir);</span>
 }
 
 static void __swiotlb_sync_sg_for_cpu(struct device *dev,
<span class="p_chunk">@@ -280,9 +295,12 @@</span> <span class="p_context"> static void __swiotlb_sync_sg_for_cpu(struct device *dev,</span>
 	int i;
 
 	if (!is_device_dma_coherent(dev))
<span class="p_del">-		for_each_sg(sgl, sg, nelems, i)</span>
<span class="p_del">-			__dma_unmap_area(phys_to_virt(dma_to_phys(dev, sg-&gt;dma_address)),</span>
<span class="p_del">-					 sg-&gt;length, dir);</span>
<span class="p_add">+		for_each_sg(sgl, sg, nelems, i) {</span>
<span class="p_add">+			dma_addr_t dma = sg-&gt;dma_address;</span>
<span class="p_add">+			phys_addr_t phys = swiotlb_dma_to_phys(dev, dma);</span>
<span class="p_add">+</span>
<span class="p_add">+			__dma_unmap_area(phys_to_virt(phys), sg-&gt;length, dir);</span>
<span class="p_add">+		}</span>
 	swiotlb_sync_sg_for_cpu(dev, sgl, nelems, dir);
 }
 
<span class="p_chunk">@@ -295,9 +313,12 @@</span> <span class="p_context"> static void __swiotlb_sync_sg_for_device(struct device *dev,</span>
 
 	swiotlb_sync_sg_for_device(dev, sgl, nelems, dir);
 	if (!is_device_dma_coherent(dev))
<span class="p_del">-		for_each_sg(sgl, sg, nelems, i)</span>
<span class="p_del">-			__dma_map_area(phys_to_virt(dma_to_phys(dev, sg-&gt;dma_address)),</span>
<span class="p_del">-				       sg-&gt;length, dir);</span>
<span class="p_add">+		for_each_sg(sgl, sg, nelems, i) {</span>
<span class="p_add">+			dma_addr_t dma = sg-&gt;dma_address;</span>
<span class="p_add">+			phys_addr_t phys = swiotlb_dma_to_phys(dev, dma);</span>
<span class="p_add">+</span>
<span class="p_add">+			__dma_map_area(phys_to_virt(phys), sg-&gt;length, dir);</span>
<span class="p_add">+		}</span>
 }
 
 static int __swiotlb_mmap(struct device *dev,
<span class="p_chunk">@@ -309,7 +330,7 @@</span> <span class="p_context"> static int __swiotlb_mmap(struct device *dev,</span>
 	unsigned long nr_vma_pages = (vma-&gt;vm_end - vma-&gt;vm_start) &gt;&gt;
 					PAGE_SHIFT;
 	unsigned long nr_pages = PAGE_ALIGN(size) &gt;&gt; PAGE_SHIFT;
<span class="p_del">-	unsigned long pfn = dma_to_phys(dev, dma_addr) &gt;&gt; PAGE_SHIFT;</span>
<span class="p_add">+	unsigned long pfn = swiotlb_dma_to_phys(dev, dma_addr) &gt;&gt; PAGE_SHIFT;</span>
 	unsigned long off = vma-&gt;vm_pgoff;
 
 	vma-&gt;vm_page_prot = __get_dma_pgprot(attrs, vma-&gt;vm_page_prot,
<span class="p_chunk">@@ -334,9 +355,11 @@</span> <span class="p_context"> static int __swiotlb_get_sgtable(struct device *dev, struct sg_table *sgt,</span>
 {
 	int ret = sg_alloc_table(sgt, 1, GFP_KERNEL);
 
<span class="p_del">-	if (!ret)</span>
<span class="p_del">-		sg_set_page(sgt-&gt;sgl, phys_to_page(dma_to_phys(dev, handle)),</span>
<span class="p_del">-			    PAGE_ALIGN(size), 0);</span>
<span class="p_add">+	if (!ret) {</span>
<span class="p_add">+		phys_addr_t phys = swiotlb_dma_to_phys(dev, handle);</span>
<span class="p_add">+</span>
<span class="p_add">+		sg_set_page(sgt-&gt;sgl, phys_to_page(phys), PAGE_ALIGN(size), 0);</span>
<span class="p_add">+	}</span>
 
 	return ret;
 }
<span class="p_header">diff --git a/arch/ia64/include/asm/dma-mapping.h b/arch/ia64/include/asm/dma-mapping.h</span>
<span class="p_header">index d472805..a8736b9 100644</span>
<span class="p_header">--- a/arch/ia64/include/asm/dma-mapping.h</span>
<span class="p_header">+++ b/arch/ia64/include/asm/dma-mapping.h</span>
<span class="p_chunk">@@ -33,15 +33,19 @@</span> <span class="p_context"> static inline bool dma_capable(struct device *dev, dma_addr_t addr, size_t size)</span>
 	return addr + size - 1 &lt;= *dev-&gt;dma_mask;
 }
 
<span class="p_del">-static inline dma_addr_t phys_to_dma(struct device *dev, phys_addr_t paddr)</span>
<span class="p_add">+static inline dma_addr_t swiotlb_phys_to_dma(struct device *dev,</span>
<span class="p_add">+					     phys_addr_t paddr)</span>
 {
 	return paddr;
 }
<span class="p_add">+#define swiotlb_phys_to_dma swiotlb_phys_to_dma</span>
 
<span class="p_del">-static inline phys_addr_t dma_to_phys(struct device *dev, dma_addr_t daddr)</span>
<span class="p_add">+static inline phys_addr_t swiotlb_dma_to_phys(struct device *dev,</span>
<span class="p_add">+					      dma_addr_t daddr)</span>
 {
 	return daddr;
 }
<span class="p_add">+#define swiotlb_dma_to_phys swiotlb_dma_to_phys</span>
 
 static inline void
 dma_cache_sync (struct device *dev, void *vaddr, size_t size,
<span class="p_header">diff --git a/arch/mips/cavium-octeon/dma-octeon.c b/arch/mips/cavium-octeon/dma-octeon.c</span>
<span class="p_header">index 2cd45f5..9ea7e9b 100644</span>
<span class="p_header">--- a/arch/mips/cavium-octeon/dma-octeon.c</span>
<span class="p_header">+++ b/arch/mips/cavium-octeon/dma-octeon.c</span>
<span class="p_chunk">@@ -210,7 +210,7 @@</span> <span class="p_context"> struct octeon_dma_map_ops {</span>
 	phys_addr_t (*dma_to_phys)(struct device *dev, dma_addr_t daddr);
 };
 
<span class="p_del">-dma_addr_t phys_to_dma(struct device *dev, phys_addr_t paddr)</span>
<span class="p_add">+dma_addr_t swiotlb_phys_to_dma(struct device *dev, phys_addr_t paddr)</span>
 {
 	struct octeon_dma_map_ops *ops = container_of(get_dma_ops(dev),
 						      struct octeon_dma_map_ops,
<span class="p_chunk">@@ -218,9 +218,9 @@</span> <span class="p_context"> dma_addr_t phys_to_dma(struct device *dev, phys_addr_t paddr)</span>
 
 	return ops-&gt;phys_to_dma(dev, paddr);
 }
<span class="p_del">-EXPORT_SYMBOL(phys_to_dma);</span>
<span class="p_add">+EXPORT_SYMBOL(swiotlb_phys_to_dma);</span>
 
<span class="p_del">-phys_addr_t dma_to_phys(struct device *dev, dma_addr_t daddr)</span>
<span class="p_add">+phys_addr_t swiotlb_dma_to_phys(struct device *dev, dma_addr_t daddr)</span>
 {
 	struct octeon_dma_map_ops *ops = container_of(get_dma_ops(dev),
 						      struct octeon_dma_map_ops,
<span class="p_chunk">@@ -228,7 +228,7 @@</span> <span class="p_context"> phys_addr_t dma_to_phys(struct device *dev, dma_addr_t daddr)</span>
 
 	return ops-&gt;dma_to_phys(dev, daddr);
 }
<span class="p_del">-EXPORT_SYMBOL(dma_to_phys);</span>
<span class="p_add">+EXPORT_SYMBOL(swiotlb_dma_to_phys);</span>
 
 static struct octeon_dma_map_ops octeon_linear_dma_map_ops = {
 	.dma_map_ops = {
<span class="p_header">diff --git a/arch/mips/include/asm/mach-cavium-octeon/dma-coherence.h b/arch/mips/include/asm/mach-cavium-octeon/dma-coherence.h</span>
<span class="p_header">index 460042e..5f0f13a 100644</span>
<span class="p_header">--- a/arch/mips/include/asm/mach-cavium-octeon/dma-coherence.h</span>
<span class="p_header">+++ b/arch/mips/include/asm/mach-cavium-octeon/dma-coherence.h</span>
<span class="p_chunk">@@ -61,8 +61,11 @@</span> <span class="p_context"> static inline void plat_post_dma_flush(struct device *dev)</span>
 {
 }
 
<span class="p_del">-dma_addr_t phys_to_dma(struct device *dev, phys_addr_t paddr);</span>
<span class="p_del">-phys_addr_t dma_to_phys(struct device *dev, dma_addr_t daddr);</span>
<span class="p_add">+dma_addr_t swiotlb_phys_to_dma(struct device *dev, phys_addr_t paddr);</span>
<span class="p_add">+#define swiotlb_phys_to_dma swiotlb_phys_to_dma</span>
<span class="p_add">+</span>
<span class="p_add">+phys_addr_t swiotlb_dma_to_phys(struct device *dev, dma_addr_t daddr);</span>
<span class="p_add">+#define swiotlb_dma_to_phys swiotlb_dma_to_phys</span>
 
 struct dma_map_ops;
 extern struct dma_map_ops *octeon_pci_dma_map_ops;
<span class="p_header">diff --git a/arch/mips/include/asm/mach-generic/dma-coherence.h b/arch/mips/include/asm/mach-generic/dma-coherence.h</span>
<span class="p_header">index 0f8a354..54fde22 100644</span>
<span class="p_header">--- a/arch/mips/include/asm/mach-generic/dma-coherence.h</span>
<span class="p_header">+++ b/arch/mips/include/asm/mach-generic/dma-coherence.h</span>
<span class="p_chunk">@@ -59,15 +59,19 @@</span> <span class="p_context"> static inline void plat_post_dma_flush(struct device *dev)</span>
 #endif
 
 #ifdef CONFIG_SWIOTLB
<span class="p_del">-static inline dma_addr_t phys_to_dma(struct device *dev, phys_addr_t paddr)</span>
<span class="p_add">+static inline dma_addr_t swiotlb_phys_to_dma(struct device *dev,</span>
<span class="p_add">+					     phys_addr_t paddr)</span>
 {
 	return paddr;
 }
<span class="p_add">+#define swiotlb_phys_to_dma swiotlb_phys_to_dma</span>
 
<span class="p_del">-static inline phys_addr_t dma_to_phys(struct device *dev, dma_addr_t daddr)</span>
<span class="p_add">+static inline phys_addr_t swiotlb_dma_to_phys(struct device *dev,</span>
<span class="p_add">+					      dma_addr_t daddr)</span>
 {
 	return daddr;
 }
<span class="p_add">+#define swiotlb_dma_to_phys swiotlb_dma_to_phys</span>
 #endif
 
 #endif /* __ASM_MACH_GENERIC_DMA_COHERENCE_H */
<span class="p_header">diff --git a/arch/mips/include/asm/mach-loongson64/dma-coherence.h b/arch/mips/include/asm/mach-loongson64/dma-coherence.h</span>
<span class="p_header">index 1602a9e..26fe763 100644</span>
<span class="p_header">--- a/arch/mips/include/asm/mach-loongson64/dma-coherence.h</span>
<span class="p_header">+++ b/arch/mips/include/asm/mach-loongson64/dma-coherence.h</span>
<span class="p_chunk">@@ -17,13 +17,17 @@</span> <span class="p_context"></span>
 
 struct device;
 
<span class="p_del">-extern dma_addr_t phys_to_dma(struct device *dev, phys_addr_t paddr);</span>
<span class="p_del">-extern phys_addr_t dma_to_phys(struct device *dev, dma_addr_t daddr);</span>
<span class="p_add">+extern dma_addr_t swiotlb_phys_to_dma(struct device *dev, phys_addr_t paddr);</span>
<span class="p_add">+#define swiotlb_phys_to_dma swiotlb_phys_to_dma</span>
<span class="p_add">+</span>
<span class="p_add">+extern phys_addr_t swiotlb_dma_to_phys(struct device *dev, dma_addr_t daddr);</span>
<span class="p_add">+#define swiotlb_dma_to_phys swiotlb_dma_to_phys</span>
<span class="p_add">+</span>
 static inline dma_addr_t plat_map_dma_mem(struct device *dev, void *addr,
 					  size_t size)
 {
 #ifdef CONFIG_CPU_LOONGSON3
<span class="p_del">-	return phys_to_dma(dev, virt_to_phys(addr));</span>
<span class="p_add">+	return swiotlb_phys_to_dma(dev, virt_to_phys(addr));</span>
 #else
 	return virt_to_phys(addr) | 0x80000000;
 #endif
<span class="p_chunk">@@ -33,7 +37,7 @@</span> <span class="p_context"> static inline dma_addr_t plat_map_dma_mem_page(struct device *dev,</span>
 					       struct page *page)
 {
 #ifdef CONFIG_CPU_LOONGSON3
<span class="p_del">-	return phys_to_dma(dev, page_to_phys(page));</span>
<span class="p_add">+	return swiotlb_phys_to_dma(dev, page_to_phys(page));</span>
 #else
 	return page_to_phys(page) | 0x80000000;
 #endif
<span class="p_chunk">@@ -43,7 +47,7 @@</span> <span class="p_context"> static inline unsigned long plat_dma_addr_to_phys(struct device *dev,</span>
 	dma_addr_t dma_addr)
 {
 #if defined(CONFIG_CPU_LOONGSON3) &amp;&amp; defined(CONFIG_64BIT)
<span class="p_del">-	return dma_to_phys(dev, dma_addr);</span>
<span class="p_add">+	return swiotlb_dma_to_phys(dev, dma_addr);</span>
 #elif defined(CONFIG_CPU_LOONGSON2F) &amp;&amp; defined(CONFIG_64BIT)
 	return (dma_addr &gt; 0x8fffffff) ? dma_addr : (dma_addr &amp; 0x0fffffff);
 #else
<span class="p_header">diff --git a/arch/mips/loongson64/common/dma-swiotlb.c b/arch/mips/loongson64/common/dma-swiotlb.c</span>
<span class="p_header">index 4ffa6fc..88ef4cf 100644</span>
<span class="p_header">--- a/arch/mips/loongson64/common/dma-swiotlb.c</span>
<span class="p_header">+++ b/arch/mips/loongson64/common/dma-swiotlb.c</span>
<span class="p_chunk">@@ -98,7 +98,7 @@</span> <span class="p_context"> static int loongson_dma_set_mask(struct device *dev, u64 mask)</span>
 	return 0;
 }
 
<span class="p_del">-dma_addr_t phys_to_dma(struct device *dev, phys_addr_t paddr)</span>
<span class="p_add">+dma_addr_t swiotlb_phys_to_dma(struct device *dev, phys_addr_t paddr)</span>
 {
 	long nid;
 #ifdef CONFIG_PHYS48_TO_HT40
<span class="p_chunk">@@ -110,7 +110,7 @@</span> <span class="p_context"> dma_addr_t phys_to_dma(struct device *dev, phys_addr_t paddr)</span>
 	return paddr;
 }
 
<span class="p_del">-phys_addr_t dma_to_phys(struct device *dev, dma_addr_t daddr)</span>
<span class="p_add">+phys_addr_t swiotlb_dma_to_phys(struct device *dev, dma_addr_t daddr)</span>
 {
 	long nid;
 #ifdef CONFIG_PHYS48_TO_HT40
<span class="p_header">diff --git a/arch/powerpc/include/asm/dma-mapping.h b/arch/powerpc/include/asm/dma-mapping.h</span>
<span class="p_header">index 77816ac..3a9d6f2 100644</span>
<span class="p_header">--- a/arch/powerpc/include/asm/dma-mapping.h</span>
<span class="p_header">+++ b/arch/powerpc/include/asm/dma-mapping.h</span>
<span class="p_chunk">@@ -143,15 +143,19 @@</span> <span class="p_context"> static inline bool dma_capable(struct device *dev, dma_addr_t addr, size_t size)</span>
 	return addr + size - 1 &lt;= *dev-&gt;dma_mask;
 }
 
<span class="p_del">-static inline dma_addr_t phys_to_dma(struct device *dev, phys_addr_t paddr)</span>
<span class="p_add">+static inline dma_addr_t swiotlb_phys_to_dma(struct device *dev,</span>
<span class="p_add">+					     phys_addr_t paddr)</span>
 {
 	return paddr + get_dma_offset(dev);
 }
<span class="p_add">+#define swiotlb_phys_to_dma swiotlb_phys_to_dma</span>
 
<span class="p_del">-static inline phys_addr_t dma_to_phys(struct device *dev, dma_addr_t daddr)</span>
<span class="p_add">+static inline phys_addr_t swiotlb_dma_to_phys(struct device *dev,</span>
<span class="p_add">+					      dma_addr_t daddr)</span>
 {
 	return daddr - get_dma_offset(dev);
 }
<span class="p_add">+#define swiotlb_dma_to_phys swiotlb_dma_to_phys</span>
 
 #define ARCH_HAS_DMA_MMAP_COHERENT
 
<span class="p_header">diff --git a/arch/tile/include/asm/dma-mapping.h b/arch/tile/include/asm/dma-mapping.h</span>
<span class="p_header">index 01ceb4a..87c205a 100644</span>
<span class="p_header">--- a/arch/tile/include/asm/dma-mapping.h</span>
<span class="p_header">+++ b/arch/tile/include/asm/dma-mapping.h</span>
<span class="p_chunk">@@ -47,15 +47,19 @@</span> <span class="p_context"> static inline void set_dma_offset(struct device *dev, dma_addr_t off)</span>
 	dev-&gt;archdata.dma_offset = off;
 }
 
<span class="p_del">-static inline dma_addr_t phys_to_dma(struct device *dev, phys_addr_t paddr)</span>
<span class="p_add">+static inline dma_addr_t swiotlb_phys_to_dma(struct device *dev,</span>
<span class="p_add">+					     phys_addr_t paddr)</span>
 {
 	return paddr;
 }
<span class="p_add">+#define swiotlb_phys_to_dma swiotlb_phys_to_dma</span>
 
<span class="p_del">-static inline phys_addr_t dma_to_phys(struct device *dev, dma_addr_t daddr)</span>
<span class="p_add">+static inline phys_addr_t swiotlb_dma_to_phys(struct device *dev,</span>
<span class="p_add">+					      dma_addr_t daddr)</span>
 {
 	return daddr;
 }
<span class="p_add">+#define swiotlb_dma_to_phys swiotlb_dma_to_phys</span>
 
 static inline void dma_mark_clean(void *addr, size_t size) {}
 
<span class="p_header">diff --git a/arch/unicore32/include/asm/dma-mapping.h b/arch/unicore32/include/asm/dma-mapping.h</span>
<span class="p_header">index 4749854..762cdd8 100644</span>
<span class="p_header">--- a/arch/unicore32/include/asm/dma-mapping.h</span>
<span class="p_header">+++ b/arch/unicore32/include/asm/dma-mapping.h</span>
<span class="p_chunk">@@ -36,15 +36,19 @@</span> <span class="p_context"> static inline bool dma_capable(struct device *dev, dma_addr_t addr, size_t size)</span>
 	return 1;
 }
 
<span class="p_del">-static inline dma_addr_t phys_to_dma(struct device *dev, phys_addr_t paddr)</span>
<span class="p_add">+static inline dma_addr_t swiotlb_phys_to_dma(struct device *dev,</span>
<span class="p_add">+					     phys_addr_t paddr)</span>
 {
 	return paddr;
 }
<span class="p_add">+#define swiotlb_phys_to_dma swiotlb_phys_to_dma</span>
 
<span class="p_del">-static inline phys_addr_t dma_to_phys(struct device *dev, dma_addr_t daddr)</span>
<span class="p_add">+static inline phys_addr_t swiotlb_dma_to_phys(struct device *dev,</span>
<span class="p_add">+					      dma_addr_t daddr)</span>
 {
 	return daddr;
 }
<span class="p_add">+#define swiotlb_dma_to_phys swiotlb_dma_to_phys</span>
 
 static inline void dma_mark_clean(void *addr, size_t size) {}
 
<span class="p_header">diff --git a/arch/x86/include/asm/dma-mapping.h b/arch/x86/include/asm/dma-mapping.h</span>
<span class="p_header">index 3a27b93..be8b76e 100644</span>
<span class="p_header">--- a/arch/x86/include/asm/dma-mapping.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/dma-mapping.h</span>
<span class="p_chunk">@@ -56,8 +56,11 @@</span> <span class="p_context"> extern void dma_generic_free_coherent(struct device *dev, size_t size,</span>
 
 #ifdef CONFIG_X86_DMA_REMAP /* Platform code defines bridge-specific code */
 extern bool dma_capable(struct device *dev, dma_addr_t addr, size_t size);
<span class="p_del">-extern dma_addr_t phys_to_dma(struct device *dev, phys_addr_t paddr);</span>
<span class="p_del">-extern phys_addr_t dma_to_phys(struct device *dev, dma_addr_t daddr);</span>
<span class="p_add">+extern dma_addr_t swiotlb_phys_to_dma(struct device *dev, phys_addr_t paddr);</span>
<span class="p_add">+#define swiotlb_phys_to_dma swiotlb_phys_to_dma</span>
<span class="p_add">+</span>
<span class="p_add">+extern phys_addr_t swiotlb_dma_to_phys(struct device *dev, dma_addr_t daddr);</span>
<span class="p_add">+#define swiotlb_dma_to_phys swiotlb_dma_to_phys</span>
 #else
 
 static inline bool dma_capable(struct device *dev, dma_addr_t addr, size_t size)
<span class="p_chunk">@@ -68,15 +71,19 @@</span> <span class="p_context"> static inline bool dma_capable(struct device *dev, dma_addr_t addr, size_t size)</span>
 	return addr + size - 1 &lt;= *dev-&gt;dma_mask;
 }
 
<span class="p_del">-static inline dma_addr_t phys_to_dma(struct device *dev, phys_addr_t paddr)</span>
<span class="p_add">+static inline dma_addr_t swiotlb_phys_to_dma(struct device *dev,</span>
<span class="p_add">+					     phys_addr_t paddr)</span>
 {
 	return paddr;
 }
<span class="p_add">+#define swiotlb_phys_to_dma swiotlb_phys_to_dma</span>
 
<span class="p_del">-static inline phys_addr_t dma_to_phys(struct device *dev, dma_addr_t daddr)</span>
<span class="p_add">+static inline phys_addr_t swiotlb_dma_to_phys(struct device *dev,</span>
<span class="p_add">+					      dma_addr_t daddr)</span>
 {
 	return daddr;
 }
<span class="p_add">+#define swiotlb_dma_to_phys swiotlb_dma_to_phys</span>
 #endif /* CONFIG_X86_DMA_REMAP */
 
 static inline void
<span class="p_header">diff --git a/arch/x86/kernel/pci-swiotlb.c b/arch/x86/kernel/pci-swiotlb.c</span>
<span class="p_header">index 7c577a1..9333fbd 100644</span>
<span class="p_header">--- a/arch/x86/kernel/pci-swiotlb.c</span>
<span class="p_header">+++ b/arch/x86/kernel/pci-swiotlb.c</span>
<span class="p_chunk">@@ -39,7 +39,7 @@</span> <span class="p_context"> void x86_swiotlb_free_coherent(struct device *dev, size_t size,</span>
 				      void *vaddr, dma_addr_t dma_addr,
 				      struct dma_attrs *attrs)
 {
<span class="p_del">-	if (is_swiotlb_buffer(dma_to_phys(dev, dma_addr)))</span>
<span class="p_add">+	if (is_swiotlb_buffer(swiotlb_dma_to_phys(dev, dma_addr)))</span>
 		swiotlb_free_coherent(dev, size, vaddr, dma_addr);
 	else
 		dma_generic_free_coherent(dev, size, vaddr, dma_addr, attrs);
<span class="p_header">diff --git a/arch/x86/pci/sta2x11-fixup.c b/arch/x86/pci/sta2x11-fixup.c</span>
<span class="p_header">index 5ceda85..6df3eb4 100644</span>
<span class="p_header">--- a/arch/x86/pci/sta2x11-fixup.c</span>
<span class="p_header">+++ b/arch/x86/pci/sta2x11-fixup.c</span>
<span class="p_chunk">@@ -241,11 +241,12 @@</span> <span class="p_context"> bool dma_capable(struct device *dev, dma_addr_t addr, size_t size)</span>
 }
 
 /**
<span class="p_del">- * phys_to_dma - Return the DMA AMBA address used for this STA2x11 device</span>
<span class="p_add">+ * swiotlb_phys_to_dma - Return the DMA AMBA address used for this</span>
<span class="p_add">+ *	STA2x11 device</span>
  * @dev: device for a PCI device
  * @paddr: Physical address
  */
<span class="p_del">-dma_addr_t phys_to_dma(struct device *dev, phys_addr_t paddr)</span>
<span class="p_add">+dma_addr_t swiotlb_phys_to_dma(struct device *dev, phys_addr_t paddr)</span>
 {
 	if (dev-&gt;archdata.dma_ops != &amp;sta2x11_dma_ops)
 		return paddr;
<span class="p_chunk">@@ -253,11 +254,12 @@</span> <span class="p_context"> dma_addr_t phys_to_dma(struct device *dev, phys_addr_t paddr)</span>
 }
 
 /**
<span class="p_del">- * dma_to_phys - Return the physical address used for this STA2x11 DMA address</span>
<span class="p_add">+ * swiotlb_dma_to_phys - Return the physical address used for this</span>
<span class="p_add">+ *	STA2x11 DMA address</span>
  * @dev: device for a PCI device
  * @daddr: STA2x11 AMBA DMA address
  */
<span class="p_del">-phys_addr_t dma_to_phys(struct device *dev, dma_addr_t daddr)</span>
<span class="p_add">+phys_addr_t swiotlb_dma_to_phys(struct device *dev, dma_addr_t daddr)</span>
 {
 	if (dev-&gt;archdata.dma_ops != &amp;sta2x11_dma_ops)
 		return daddr;
<span class="p_header">diff --git a/arch/xtensa/include/asm/dma-mapping.h b/arch/xtensa/include/asm/dma-mapping.h</span>
<span class="p_header">index 3fc1170..b0d725d 100644</span>
<span class="p_header">--- a/arch/xtensa/include/asm/dma-mapping.h</span>
<span class="p_header">+++ b/arch/xtensa/include/asm/dma-mapping.h</span>
<span class="p_chunk">@@ -31,14 +31,18 @@</span> <span class="p_context"> static inline struct dma_map_ops *get_dma_ops(struct device *dev)</span>
 void dma_cache_sync(struct device *dev, void *vaddr, size_t size,
 		    enum dma_data_direction direction);
 
<span class="p_del">-static inline dma_addr_t phys_to_dma(struct device *dev, phys_addr_t paddr)</span>
<span class="p_add">+static inline dma_addr_t swiotlb_phys_to_dma(struct device *dev,</span>
<span class="p_add">+					     phys_addr_t paddr)</span>
 {
 	return (dma_addr_t)paddr;
 }
<span class="p_add">+#define swiotlb_phys_to_dma swiotlb_phys_to_dma</span>
 
<span class="p_del">-static inline phys_addr_t dma_to_phys(struct device *dev, dma_addr_t daddr)</span>
<span class="p_add">+static inline phys_addr_t swiotlb_dma_to_phys(struct device *dev,</span>
<span class="p_add">+					      dma_addr_t daddr)</span>
 {
 	return (phys_addr_t)daddr;
 }
<span class="p_add">+#define swiotlb_dma_to_phys swiotlb_dma_to_phys</span>
 
 #endif	/* _XTENSA_DMA_MAPPING_H */
<span class="p_header">diff --git a/lib/swiotlb.c b/lib/swiotlb.c</span>
<span class="p_header">index 76f29ec..5aadeca 100644</span>
<span class="p_header">--- a/lib/swiotlb.c</span>
<span class="p_header">+++ b/lib/swiotlb.c</span>
<span class="p_chunk">@@ -135,7 +135,7 @@</span> <span class="p_context"> unsigned long swiotlb_size_or_default(void)</span>
 static dma_addr_t swiotlb_virt_to_bus(struct device *hwdev,
 				      volatile void *address)
 {
<span class="p_del">-	return phys_to_dma(hwdev, virt_to_phys(address));</span>
<span class="p_add">+	return swiotlb_phys_to_dma(hwdev, virt_to_phys(address));</span>
 }
 
 static bool no_iotlb_memory;
<span class="p_chunk">@@ -541,7 +541,7 @@</span> <span class="p_context"> static phys_addr_t</span>
 map_single(struct device *hwdev, phys_addr_t phys, size_t size,
 	   enum dma_data_direction dir)
 {
<span class="p_del">-	dma_addr_t start_dma_addr = phys_to_dma(hwdev, io_tlb_start);</span>
<span class="p_add">+	dma_addr_t start_dma_addr = swiotlb_phys_to_dma(hwdev, io_tlb_start);</span>
 
 	return swiotlb_tbl_map_single(hwdev, start_dma_addr, phys, size, dir);
 }
<span class="p_chunk">@@ -659,7 +659,7 @@</span> <span class="p_context"> swiotlb_alloc_coherent(struct device *hwdev, size_t size,</span>
 			goto err_warn;
 
 		ret = phys_to_virt(paddr);
<span class="p_del">-		dev_addr = phys_to_dma(hwdev, paddr);</span>
<span class="p_add">+		dev_addr = swiotlb_phys_to_dma(hwdev, paddr);</span>
 
 		/* Confirm address can be DMA&#39;d by device */
 		if (dev_addr + size - 1 &gt; dma_mask) {
<span class="p_chunk">@@ -692,7 +692,7 @@</span> <span class="p_context"> void</span>
 swiotlb_free_coherent(struct device *hwdev, size_t size, void *vaddr,
 		      dma_addr_t dev_addr)
 {
<span class="p_del">-	phys_addr_t paddr = dma_to_phys(hwdev, dev_addr);</span>
<span class="p_add">+	phys_addr_t paddr = swiotlb_dma_to_phys(hwdev, dev_addr);</span>
 
 	WARN_ON(irqs_disabled());
 	if (!is_swiotlb_buffer(paddr))
<span class="p_chunk">@@ -741,7 +741,7 @@</span> <span class="p_context"> dma_addr_t swiotlb_map_page(struct device *dev, struct page *page,</span>
 			    struct dma_attrs *attrs)
 {
 	phys_addr_t map, phys = page_to_phys(page) + offset;
<span class="p_del">-	dma_addr_t dev_addr = phys_to_dma(dev, phys);</span>
<span class="p_add">+	dma_addr_t dev_addr = swiotlb_phys_to_dma(dev, phys);</span>
 
 	BUG_ON(dir == DMA_NONE);
 	/*
<span class="p_chunk">@@ -758,15 +758,15 @@</span> <span class="p_context"> dma_addr_t swiotlb_map_page(struct device *dev, struct page *page,</span>
 	map = map_single(dev, phys, size, dir);
 	if (map == SWIOTLB_MAP_ERROR) {
 		swiotlb_full(dev, size, dir, 1);
<span class="p_del">-		return phys_to_dma(dev, io_tlb_overflow_buffer);</span>
<span class="p_add">+		return swiotlb_phys_to_dma(dev, io_tlb_overflow_buffer);</span>
 	}
 
<span class="p_del">-	dev_addr = phys_to_dma(dev, map);</span>
<span class="p_add">+	dev_addr = swiotlb_phys_to_dma(dev, map);</span>
 
 	/* Ensure that the address returned is DMA&#39;ble */
 	if (!dma_capable(dev, dev_addr, size)) {
 		swiotlb_tbl_unmap_single(dev, map, size, dir);
<span class="p_del">-		return phys_to_dma(dev, io_tlb_overflow_buffer);</span>
<span class="p_add">+		return swiotlb_phys_to_dma(dev, io_tlb_overflow_buffer);</span>
 	}
 
 	return dev_addr;
<span class="p_chunk">@@ -784,7 +784,7 @@</span> <span class="p_context"> EXPORT_SYMBOL_GPL(swiotlb_map_page);</span>
 static void unmap_single(struct device *hwdev, dma_addr_t dev_addr,
 			 size_t size, enum dma_data_direction dir)
 {
<span class="p_del">-	phys_addr_t paddr = dma_to_phys(hwdev, dev_addr);</span>
<span class="p_add">+	phys_addr_t paddr = swiotlb_dma_to_phys(hwdev, dev_addr);</span>
 
 	BUG_ON(dir == DMA_NONE);
 
<span class="p_chunk">@@ -828,7 +828,7 @@</span> <span class="p_context"> swiotlb_sync_single(struct device *hwdev, dma_addr_t dev_addr,</span>
 		    size_t size, enum dma_data_direction dir,
 		    enum dma_sync_target target)
 {
<span class="p_del">-	phys_addr_t paddr = dma_to_phys(hwdev, dev_addr);</span>
<span class="p_add">+	phys_addr_t paddr = swiotlb_dma_to_phys(hwdev, dev_addr);</span>
 
 	BUG_ON(dir == DMA_NONE);
 
<span class="p_chunk">@@ -886,7 +886,7 @@</span> <span class="p_context"> swiotlb_map_sg_attrs(struct device *hwdev, struct scatterlist *sgl, int nelems,</span>
 
 	for_each_sg(sgl, sg, nelems, i) {
 		phys_addr_t paddr = sg_phys(sg);
<span class="p_del">-		dma_addr_t dev_addr = phys_to_dma(hwdev, paddr);</span>
<span class="p_add">+		dma_addr_t dev_addr = swiotlb_phys_to_dma(hwdev, paddr);</span>
 
 		if (swiotlb_force ||
 		    !dma_capable(hwdev, dev_addr, sg-&gt;length)) {
<span class="p_chunk">@@ -901,7 +901,7 @@</span> <span class="p_context"> swiotlb_map_sg_attrs(struct device *hwdev, struct scatterlist *sgl, int nelems,</span>
 				sg_dma_len(sgl) = 0;
 				return 0;
 			}
<span class="p_del">-			sg-&gt;dma_address = phys_to_dma(hwdev, map);</span>
<span class="p_add">+			sg-&gt;dma_address = swiotlb_phys_to_dma(hwdev, map);</span>
 		} else
 			sg-&gt;dma_address = dev_addr;
 		sg_dma_len(sg) = sg-&gt;length;
<span class="p_chunk">@@ -984,7 +984,7 @@</span> <span class="p_context"> EXPORT_SYMBOL(swiotlb_sync_sg_for_device);</span>
 int
 swiotlb_dma_mapping_error(struct device *hwdev, dma_addr_t dma_addr)
 {
<span class="p_del">-	return (dma_addr == phys_to_dma(hwdev, io_tlb_overflow_buffer));</span>
<span class="p_add">+	return (dma_addr == swiotlb_phys_to_dma(hwdev, io_tlb_overflow_buffer));</span>
 }
 EXPORT_SYMBOL(swiotlb_dma_mapping_error);
 
<span class="p_chunk">@@ -997,6 +997,6 @@</span> <span class="p_context"> EXPORT_SYMBOL(swiotlb_dma_mapping_error);</span>
 int
 swiotlb_dma_supported(struct device *hwdev, u64 mask)
 {
<span class="p_del">-	return phys_to_dma(hwdev, io_tlb_end - 1) &lt;= mask;</span>
<span class="p_add">+	return swiotlb_phys_to_dma(hwdev, io_tlb_end - 1) &lt;= mask;</span>
 }
 EXPORT_SYMBOL(swiotlb_dma_supported);

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



