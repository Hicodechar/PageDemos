
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>[PATCHv5,6/7] mm: use &#39;unsigned int&#39; for page order - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    [PATCHv5,6/7] mm: use &#39;unsigned int&#39; for page order</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=40781">Kirill A. Shutemov</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>Sept. 3, 2015, 12:35 p.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;1441283758-92774-7-git-send-email-kirill.shutemov@linux.intel.com&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/7116651/mbox/"
   >mbox</a>
|
   <a href="/patch/7116651/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/7116651/">/patch/7116651/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
X-Original-To: patchwork-LKML@patchwork.kernel.org
Delivered-To: patchwork-parsemail@patchwork2.web.kernel.org
Received: from mail.kernel.org (mail.kernel.org [198.145.29.136])
	by patchwork2.web.kernel.org (Postfix) with ESMTP id 38149BEEC1
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Thu,  3 Sep 2015 12:36:36 +0000 (UTC)
Received: from mail.kernel.org (localhost [127.0.0.1])
	by mail.kernel.org (Postfix) with ESMTP id 638812039C
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Thu,  3 Sep 2015 12:36:30 +0000 (UTC)
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.kernel.org (Postfix) with ESMTP id EB6F020847
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Thu,  3 Sep 2015 12:36:28 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1755392AbbICMgV (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Thu, 3 Sep 2015 08:36:21 -0400
Received: from mga09.intel.com ([134.134.136.24]:12863 &quot;EHLO mga09.intel.com&quot;
	rhost-flags-OK-OK-OK-OK) by vger.kernel.org with ESMTP
	id S1753906AbbICMgS (ORCPT &lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Thu, 3 Sep 2015 08:36:18 -0400
Received: from fmsmga001.fm.intel.com ([10.253.24.23])
	by orsmga102.jf.intel.com with ESMTP; 03 Sep 2015 05:36:18 -0700
X-ExtLoop1: 1
X-IronPort-AV: E=Sophos;i=&quot;5.17,461,1437462000&quot;; d=&quot;scan&#39;208&quot;;a=&quot;781889646&quot;
Received: from black.fi.intel.com ([10.237.72.213])
	by fmsmga001.fm.intel.com with ESMTP; 03 Sep 2015 05:36:08 -0700
Received: by black.fi.intel.com (Postfix, from userid 1000)
	id 76C671F1; Thu,  3 Sep 2015 15:36:03 +0300 (EEST)
From: &quot;Kirill A. Shutemov&quot; &lt;kirill.shutemov@linux.intel.com&gt;
To: Andrew Morton &lt;akpm@linux-foundation.org&gt;,
	Hugh Dickins &lt;hughd@google.com&gt;
Cc: Andrea Arcangeli &lt;aarcange@redhat.com&gt;,
	Dave Hansen &lt;dave.hansen@intel.com&gt;, Vlastimil Babka &lt;vbabka@suse.cz&gt;,
	Johannes Weiner &lt;hannes@cmpxchg.org&gt;, Michal Hocko &lt;mhocko@suse.cz&gt;,
	David Rientjes &lt;rientjes@google.com&gt;,
	&quot;Aneesh Kumar K.V&quot; &lt;aneesh.kumar@linux.vnet.ibm.com&gt;,
	linux-kernel@vger.kernel.org, linux-mm@kvack.org,
	&quot;Kirill A. Shutemov&quot; &lt;kirill.shutemov@linux.intel.com&gt;
Subject: [PATCHv5 6/7] mm: use &#39;unsigned int&#39; for page order
Date: Thu,  3 Sep 2015 15:35:57 +0300
Message-Id: &lt;1441283758-92774-7-git-send-email-kirill.shutemov@linux.intel.com&gt;
X-Mailer: git-send-email 2.5.0
In-Reply-To: &lt;1441283758-92774-1-git-send-email-kirill.shutemov@linux.intel.com&gt;
References: &lt;1441283758-92774-1-git-send-email-kirill.shutemov@linux.intel.com&gt;
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Spam-Status: No, score=-6.9 required=5.0 tests=BAYES_00, RCVD_IN_DNSWL_HI, 
	T_RP_MATCHES_RCVD,
	UNPARSEABLE_RELAY autolearn=unavailable version=3.3.1
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on mail.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=40781">Kirill A. Shutemov</a> - Sept. 3, 2015, 12:35 p.m.</div>
<pre class="content">
Let&#39;s try to be consistent about data type of page order.
<span class="signed-off-by">
Signed-off-by: Kirill A. Shutemov &lt;kirill.shutemov@linux.intel.com&gt;</span>
<span class="acked-by">Acked-by: Michal Hocko &lt;mhocko@suse.com&gt;</span>
---
 include/linux/mm.h |  5 +++--
 mm/hugetlb.c       | 19 ++++++++++---------
 mm/internal.h      |  4 ++--
 mm/page_alloc.c    | 27 +++++++++++++++------------
 4 files changed, 30 insertions(+), 25 deletions(-)
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=72672">Vlastimil Babka</a> - Sept. 10, 2015, 11:04 a.m.</div>
<pre class="content">
On 09/03/2015 02:35 PM, Kirill A. Shutemov wrote:
<span class="quote">&gt; Let&#39;s try to be consistent about data type of page order.</span>

Long overdue I&#39;d say :) Thanks.
<span class="quote">
&gt; Signed-off-by: Kirill A. Shutemov &lt;kirill.shutemov@linux.intel.com&gt;</span>
<span class="quote">&gt; Acked-by: Michal Hocko &lt;mhocko@suse.com&gt;</span>
<span class="acked-by">
Acked-by: Vlastimil Babka &lt;vbabka@suse.cz&gt;</span>

--
To unsubscribe from this list: send the line &quot;unsubscribe linux-kernel&quot; in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
Please read the FAQ at  http://www.tux.org/lkml/
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/include/linux/mm.h b/include/linux/mm.h</span>
<span class="p_header">index 9fc7dc8a49af..00a78439f392 100644</span>
<span class="p_header">--- a/include/linux/mm.h</span>
<span class="p_header">+++ b/include/linux/mm.h</span>
<span class="p_chunk">@@ -557,7 +557,7 @@</span> <span class="p_context"> static inline compound_page_dtor *get_compound_page_dtor(struct page *page)</span>
 	return compound_page_dtors[page[1].compound_dtor];
 }
 
<span class="p_del">-static inline int compound_order(struct page *page)</span>
<span class="p_add">+static inline unsigned int compound_order(struct page *page)</span>
 {
 	if (!PageHead(page))
 		return 0;
<span class="p_chunk">@@ -1718,7 +1718,8 @@</span> <span class="p_context"> extern void si_meminfo(struct sysinfo * val);</span>
 extern void si_meminfo_node(struct sysinfo *val, int nid);
 
 extern __printf(3, 4)
<span class="p_del">-void warn_alloc_failed(gfp_t gfp_mask, int order, const char *fmt, ...);</span>
<span class="p_add">+void warn_alloc_failed(gfp_t gfp_mask, unsigned int order,</span>
<span class="p_add">+		const char *fmt, ...);</span>
 
 extern void setup_per_cpu_pageset(void);
 
<span class="p_header">diff --git a/mm/hugetlb.c b/mm/hugetlb.c</span>
<span class="p_header">index 53c0709fd87b..bf64bfebc473 100644</span>
<span class="p_header">--- a/mm/hugetlb.c</span>
<span class="p_header">+++ b/mm/hugetlb.c</span>
<span class="p_chunk">@@ -817,7 +817,7 @@</span> <span class="p_context"> static int hstate_next_node_to_free(struct hstate *h, nodemask_t *nodes_allowed)</span>
 
 #if defined(CONFIG_CMA) &amp;&amp; defined(CONFIG_X86_64)
 static void destroy_compound_gigantic_page(struct page *page,
<span class="p_del">-					unsigned long order)</span>
<span class="p_add">+					unsigned int order)</span>
 {
 	int i;
 	int nr_pages = 1 &lt;&lt; order;
<span class="p_chunk">@@ -832,7 +832,7 @@</span> <span class="p_context"> static void destroy_compound_gigantic_page(struct page *page,</span>
 	__ClearPageHead(page);
 }
 
<span class="p_del">-static void free_gigantic_page(struct page *page, unsigned order)</span>
<span class="p_add">+static void free_gigantic_page(struct page *page, unsigned int order)</span>
 {
 	free_contig_range(page_to_pfn(page), 1 &lt;&lt; order);
 }
<span class="p_chunk">@@ -876,7 +876,7 @@</span> <span class="p_context"> static bool zone_spans_last_pfn(const struct zone *zone,</span>
 	return zone_spans_pfn(zone, last_pfn);
 }
 
<span class="p_del">-static struct page *alloc_gigantic_page(int nid, unsigned order)</span>
<span class="p_add">+static struct page *alloc_gigantic_page(int nid, unsigned int order)</span>
 {
 	unsigned long nr_pages = 1 &lt;&lt; order;
 	unsigned long ret, pfn, flags;
<span class="p_chunk">@@ -912,7 +912,7 @@</span> <span class="p_context"> static struct page *alloc_gigantic_page(int nid, unsigned order)</span>
 }
 
 static void prep_new_huge_page(struct hstate *h, struct page *page, int nid);
<span class="p_del">-static void prep_compound_gigantic_page(struct page *page, unsigned long order);</span>
<span class="p_add">+static void prep_compound_gigantic_page(struct page *page, unsigned int order);</span>
 
 static struct page *alloc_fresh_gigantic_page_node(struct hstate *h, int nid)
 {
<span class="p_chunk">@@ -945,9 +945,9 @@</span> <span class="p_context"> static int alloc_fresh_gigantic_page(struct hstate *h,</span>
 static inline bool gigantic_page_supported(void) { return true; }
 #else
 static inline bool gigantic_page_supported(void) { return false; }
<span class="p_del">-static inline void free_gigantic_page(struct page *page, unsigned order) { }</span>
<span class="p_add">+static inline void free_gigantic_page(struct page *page, unsigned int order) { }</span>
 static inline void destroy_compound_gigantic_page(struct page *page,
<span class="p_del">-						unsigned long order) { }</span>
<span class="p_add">+						unsigned int order) { }</span>
 static inline int alloc_fresh_gigantic_page(struct hstate *h,
 					nodemask_t *nodes_allowed) { return 0; }
 #endif
<span class="p_chunk">@@ -1073,7 +1073,7 @@</span> <span class="p_context"> static void prep_new_huge_page(struct hstate *h, struct page *page, int nid)</span>
 	put_page(page); /* free it into the hugepage allocator */
 }
 
<span class="p_del">-static void prep_compound_gigantic_page(struct page *page, unsigned long order)</span>
<span class="p_add">+static void prep_compound_gigantic_page(struct page *page, unsigned int order)</span>
 {
 	int i;
 	int nr_pages = 1 &lt;&lt; order;
<span class="p_chunk">@@ -1640,7 +1640,8 @@</span> <span class="p_context"> found:</span>
 	return 1;
 }
 
<span class="p_del">-static void __init prep_compound_huge_page(struct page *page, int order)</span>
<span class="p_add">+static void __init prep_compound_huge_page(struct page *page,</span>
<span class="p_add">+		unsigned int order)</span>
 {
 	if (unlikely(order &gt; (MAX_ORDER - 1)))
 		prep_compound_gigantic_page(page, order);
<span class="p_chunk">@@ -2351,7 +2352,7 @@</span> <span class="p_context"> static int __init hugetlb_init(void)</span>
 module_init(hugetlb_init);
 
 /* Should be called on processing a hugepagesz=... option */
<span class="p_del">-void __init hugetlb_add_hstate(unsigned order)</span>
<span class="p_add">+void __init hugetlb_add_hstate(unsigned int order)</span>
 {
 	struct hstate *h;
 	unsigned long i;
<span class="p_header">diff --git a/mm/internal.h b/mm/internal.h</span>
<span class="p_header">index 89e21a07080a..9a9fc497593f 100644</span>
<span class="p_header">--- a/mm/internal.h</span>
<span class="p_header">+++ b/mm/internal.h</span>
<span class="p_chunk">@@ -157,7 +157,7 @@</span> <span class="p_context"> __find_buddy_index(unsigned long page_idx, unsigned int order)</span>
 extern int __isolate_free_page(struct page *page, unsigned int order);
 extern void __free_pages_bootmem(struct page *page, unsigned long pfn,
 					unsigned int order);
<span class="p_del">-extern void prep_compound_page(struct page *page, unsigned long order);</span>
<span class="p_add">+extern void prep_compound_page(struct page *page, unsigned int order);</span>
 #ifdef CONFIG_MEMORY_FAILURE
 extern bool is_free_buddy_page(struct page *page);
 #endif
<span class="p_chunk">@@ -214,7 +214,7 @@</span> <span class="p_context"> int find_suitable_fallback(struct free_area *area, unsigned int order,</span>
  * page cannot be allocated or merged in parallel. Alternatively, it must
  * handle invalid values gracefully, and use page_order_unsafe() below.
  */
<span class="p_del">-static inline unsigned long page_order(struct page *page)</span>
<span class="p_add">+static inline unsigned int page_order(struct page *page)</span>
 {
 	/* PageBuddy() must be checked by the caller */
 	return page_private(page);
<span class="p_header">diff --git a/mm/page_alloc.c b/mm/page_alloc.c</span>
<span class="p_header">index a56ad53ff553..81cfaca6b9fe 100644</span>
<span class="p_header">--- a/mm/page_alloc.c</span>
<span class="p_header">+++ b/mm/page_alloc.c</span>
<span class="p_chunk">@@ -163,7 +163,7 @@</span> <span class="p_context"> bool pm_suspended_storage(void)</span>
 #endif /* CONFIG_PM_SLEEP */
 
 #ifdef CONFIG_HUGETLB_PAGE_SIZE_VARIABLE
<span class="p_del">-int pageblock_order __read_mostly;</span>
<span class="p_add">+unsigned int pageblock_order __read_mostly;</span>
 #endif
 
 static void __free_pages_ok(struct page *page, unsigned int order);
<span class="p_chunk">@@ -441,7 +441,7 @@</span> <span class="p_context"> static void free_compound_page(struct page *page)</span>
 	__free_pages_ok(page, compound_order(page));
 }
 
<span class="p_del">-void prep_compound_page(struct page *page, unsigned long order)</span>
<span class="p_add">+void prep_compound_page(struct page *page, unsigned int order)</span>
 {
 	int i;
 	int nr_pages = 1 &lt;&lt; order;
<span class="p_chunk">@@ -641,7 +641,7 @@</span> <span class="p_context"> static inline void __free_one_page(struct page *page,</span>
 	unsigned long combined_idx;
 	unsigned long uninitialized_var(buddy_idx);
 	struct page *buddy;
<span class="p_del">-	int max_order = MAX_ORDER;</span>
<span class="p_add">+	unsigned int max_order = MAX_ORDER;</span>
 
 	VM_BUG_ON(!zone_is_initialized(zone));
 	VM_BUG_ON_PAGE(page-&gt;flags &amp; PAGE_FLAGS_CHECK_AT_PREP, page);
<span class="p_chunk">@@ -1444,7 +1444,7 @@</span> <span class="p_context"> int move_freepages(struct zone *zone,</span>
 			  int migratetype)
 {
 	struct page *page;
<span class="p_del">-	unsigned long order;</span>
<span class="p_add">+	unsigned int order;</span>
 	int pages_moved = 0;
 
 #ifndef CONFIG_HOLES_IN_ZONE
<span class="p_chunk">@@ -1558,7 +1558,7 @@</span> <span class="p_context"> static bool can_steal_fallback(unsigned int order, int start_mt)</span>
 static void steal_suitable_fallback(struct zone *zone, struct page *page,
 							  int start_type)
 {
<span class="p_del">-	int current_order = page_order(page);</span>
<span class="p_add">+	unsigned int current_order = page_order(page);</span>
 	int pages;
 
 	/* Take ownership for orders &gt;= pageblock_order */
<span class="p_chunk">@@ -2665,7 +2665,7 @@</span> <span class="p_context"> static DEFINE_RATELIMIT_STATE(nopage_rs,</span>
 		DEFAULT_RATELIMIT_INTERVAL,
 		DEFAULT_RATELIMIT_BURST);
 
<span class="p_del">-void warn_alloc_failed(gfp_t gfp_mask, int order, const char *fmt, ...)</span>
<span class="p_add">+void warn_alloc_failed(gfp_t gfp_mask, unsigned int order, const char *fmt, ...)</span>
 {
 	unsigned int filter = SHOW_MEM_FILTER_NODES;
 
<span class="p_chunk">@@ -2699,7 +2699,7 @@</span> <span class="p_context"> void warn_alloc_failed(gfp_t gfp_mask, int order, const char *fmt, ...)</span>
 		va_end(args);
 	}
 
<span class="p_del">-	pr_warn(&quot;%s: page allocation failure: order:%d, mode:0x%x\n&quot;,</span>
<span class="p_add">+	pr_warn(&quot;%s: page allocation failure: order:%u, mode:0x%x\n&quot;,</span>
 		current-&gt;comm, order, gfp_mask);
 
 	dump_stack();
<span class="p_chunk">@@ -3458,7 +3458,8 @@</span> <span class="p_context"> void free_kmem_pages(unsigned long addr, unsigned int order)</span>
 	}
 }
 
<span class="p_del">-static void *make_alloc_exact(unsigned long addr, unsigned order, size_t size)</span>
<span class="p_add">+static void *make_alloc_exact(unsigned long addr, unsigned int order,</span>
<span class="p_add">+		size_t size)</span>
 {
 	if (addr) {
 		unsigned long alloc_end = addr + (PAGE_SIZE &lt;&lt; order);
<span class="p_chunk">@@ -3510,7 +3511,7 @@</span> <span class="p_context"> EXPORT_SYMBOL(alloc_pages_exact);</span>
  */
 void * __meminit alloc_pages_exact_nid(int nid, size_t size, gfp_t gfp_mask)
 {
<span class="p_del">-	unsigned order = get_order(size);</span>
<span class="p_add">+	unsigned int order = get_order(size);</span>
 	struct page *p = alloc_pages_node(nid, gfp_mask, order);
 	if (!p)
 		return NULL;
<span class="p_chunk">@@ -3812,7 +3813,8 @@</span> <span class="p_context"> void show_free_areas(unsigned int filter)</span>
 	}
 
 	for_each_populated_zone(zone) {
<span class="p_del">-		unsigned long nr[MAX_ORDER], flags, order, total = 0;</span>
<span class="p_add">+		unsigned int order;</span>
<span class="p_add">+		unsigned long nr[MAX_ORDER], flags, total = 0;</span>
 		unsigned char types[MAX_ORDER];
 
 		if (skip_free_areas_node(filter, zone_to_nid(zone)))
<span class="p_chunk">@@ -4161,7 +4163,7 @@</span> <span class="p_context"> static void build_zonelists(pg_data_t *pgdat)</span>
 	nodemask_t used_mask;
 	int local_node, prev_node;
 	struct zonelist *zonelist;
<span class="p_del">-	int order = current_zonelist_order;</span>
<span class="p_add">+	unsigned int order = current_zonelist_order;</span>
 
 	/* initialize zonelists */
 	for (i = 0; i &lt; MAX_ZONELISTS; i++) {
<span class="p_chunk">@@ -6826,7 +6828,8 @@</span> <span class="p_context"> int alloc_contig_range(unsigned long start, unsigned long end,</span>
 		       unsigned migratetype)
 {
 	unsigned long outer_start, outer_end;
<span class="p_del">-	int ret = 0, order;</span>
<span class="p_add">+	unsigned int order;</span>
<span class="p_add">+	int ret = 0;</span>
 
 	struct compact_control cc = {
 		.nr_migratepages = 0,

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



