
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>[v1,7/9] mm: hwpoison: dissolve in-use hugepage in unrecoverable memory error - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    [v1,7/9] mm: hwpoison: dissolve in-use hugepage in unrecoverable memory error</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=4407">Naoya Horiguchi</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>June 1, 2017, 8:16 a.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;1496305019-5493-8-git-send-email-n-horiguchi@ah.jp.nec.com&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/9758827/mbox/"
   >mbox</a>
|
   <a href="/patch/9758827/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/9758827/">/patch/9758827/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
	[172.30.200.125])
	by pdx-korg-patchwork.web.codeaurora.org (Postfix) with ESMTP id
	8A9A76038E for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Thu,  1 Jun 2017 08:17:40 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 78BFB28503
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Thu,  1 Jun 2017 08:17:40 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id 6D83328509; Thu,  1 Jun 2017 08:17:40 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-6.3 required=2.0 tests=BAYES_00,DKIM_SIGNED,
	RCVD_IN_DNSWL_HI, RCVD_IN_SORBS_SPAM,
	T_DKIM_INVALID autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id ABA1A28503
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Thu,  1 Jun 2017 08:17:39 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1751593AbdFAIRf (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Thu, 1 Jun 2017 04:17:35 -0400
Received: from mail-io0-f195.google.com ([209.85.223.195]:36797 &quot;EHLO
	mail-io0-f195.google.com&quot; rhost-flags-OK-OK-OK-OK) by vger.kernel.org
	with ESMTP id S1751572AbdFAIRc (ORCPT
	&lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Thu, 1 Jun 2017 04:17:32 -0400
Received: by mail-io0-f195.google.com with SMTP id f102so4171788ioi.3
	for &lt;linux-kernel@vger.kernel.org&gt;;
	Thu, 01 Jun 2017 01:17:31 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
	d=gmail.com; s=20161025;
	h=sender:from:to:cc:subject:date:message-id:in-reply-to:references;
	bh=jGWKYew7HLaajxDNsPAvsgZ12xbEM8Ra9pkv/fyHv6k=;
	b=rZiHA6QNaJNNfO5jj4F5zkuqg8rnMfq2FWnieGdZkNYZFTNhvyV+tXImZHZ7rzdgK0
	17iPoSixPV8EYvCj+owAUqJCOcbIdXtYNNm27cflgznIwlJCkfxvAAgz5WUUe09MiLMZ
	i71JVR9mdkdsDjkzXu7uHjt+nSZxVfJYT0vuiu9uyQFb3jSWG9acpSByo1Joxz1VK9k4
	FkM3Q/4Fb4CBMuH4+cyZpU7rR2x1byojdDNibUZ/SCEAuu9YYBFQtFKTtAKL2nWe7DxP
	4GDz+xmH2V0w8Ta1+XL9SwTd/dIjP512V44HrXt7Ev4K0uskxWpCmbDLhUH+FDxyNMII
	z+3Q==
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
	d=1e100.net; s=20161025;
	h=x-gm-message-state:sender:from:to:cc:subject:date:message-id
	:in-reply-to:references;
	bh=jGWKYew7HLaajxDNsPAvsgZ12xbEM8Ra9pkv/fyHv6k=;
	b=smiWHZHe5a28mv69947KVQuo8lOGrPeMH0wdui0Ts7L5nP0M5TvUGKL2G0I1KVAO0v
	zXqV1sXF0vaqVKeV3ogDyiYnookGSqiZeU+opV/oxwsy5CnDByhMktaebk8TVxpOJ3Xj
	Uib7lnx7doNwwi766SILSMOad6ZGSpjQ6Uua9pEf9hcqF5wFU6vDu2Y0+J8pCl5d68Zo
	mEo7YV/PC0y0YqHOg1ZIiCROEU66fw76p01QPPh3xXDkk7sVGBogSqacfdCNg2PmDIVj
	rGovTd/YHiz+l18+DKlyRd4HaKqfDVqDeBUu7fvKVB48wpEnL8tFXzaMmz19En6Sau16
	4Xww==
X-Gm-Message-State: AODbwcDBRA8KWUXKroL+Gzbk83Wpp2tY61JoN2RyQu+RMortAqG37up3
	jrJDUKqAaCiJIg==
X-Received: by 10.98.204.87 with SMTP id a84mr171745pfg.6.1496305041073;
	Thu, 01 Jun 2017 01:17:21 -0700 (PDT)
Received: from www9186uo.sakura.ne.jp (www9186uo.sakura.ne.jp.
	[153.121.56.200]) by smtp.gmail.com with ESMTPSA id
	n24sm33553022pfb.14.2017.06.01.01.17.19
	(version=TLS1_2 cipher=ECDHE-RSA-AES128-GCM-SHA256 bits=128/128);
	Thu, 01 Jun 2017 01:17:20 -0700 (PDT)
From: Naoya Horiguchi &lt;n-horiguchi@ah.jp.nec.com&gt;
To: linux-mm@kvack.org
Cc: Andrew Morton &lt;akpm@linux-foundation.org&gt;,
	Michal Hocko &lt;mhocko@kernel.org&gt;,
	&quot;Aneesh Kumar K.V&quot; &lt;aneesh.kumar@linux.vnet.ibm.com&gt;,
	Anshuman Khandual &lt;khandual@linux.vnet.ibm.com&gt;,
	linux-kernel@vger.kernel.org, Naoya Horiguchi &lt;n-horiguchi@ah.jp.nec.com&gt;
Subject: [PATCH v1 7/9] mm: hwpoison: dissolve in-use hugepage in
	unrecoverable memory error
Date: Thu,  1 Jun 2017 17:16:57 +0900
Message-Id: &lt;1496305019-5493-8-git-send-email-n-horiguchi@ah.jp.nec.com&gt;
X-Mailer: git-send-email 2.7.0
In-Reply-To: &lt;1496305019-5493-1-git-send-email-n-horiguchi@ah.jp.nec.com&gt;
References: &lt;1496305019-5493-1-git-send-email-n-horiguchi@ah.jp.nec.com&gt;
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=4407">Naoya Horiguchi</a> - June 1, 2017, 8:16 a.m.</div>
<pre class="content">
Currently me_huge_page() relies on dequeue_hwpoisoned_huge_page() to
keep the error hugepage away from the system, which is OK but not good
enough because the hugepage still has a refcount and unpoison doesn&#39;t
work on the error hugepage (PageHWPoison flags are cleared but pages
are still leaked.)  And there&#39;s &quot;wasting health subpages&quot; issue too.
This patch reworks on me_huge_page() to solve these issues.

For hugetlb file, recently we have truncating code so let&#39;s use it
in hugetlbfs specific -&gt;error_remove_page().

For anonymous hugepage, it&#39;s helpful to dissolve the error page after
freeing it into free hugepage list. Migration entry and PageHWPoison
in the head page prevent the access to it.

TODO: dissolve_free_huge_page() can fail but we don&#39;t considered it
yet.  It&#39;s not critical (and at least no worse that now) because in
such case the error hugepage just stays in free hugepage list without
being dissolved.  By virtue of PageHWPoison in head page, it&#39;s never
allocated to processes.

Fixes: 23a003bfd23ea9ea0b7756b920e51f64b284b468 (&quot;mm/madvise: pass return code of memory_failure() to userspace&quot;)
Link: http://lkml.kernel.org/r/20170417055948.GM31394@yexl-desktop
Reported-by: kernel test robot &lt;lkp@intel.com&gt;
<span class="signed-off-by">Signed-off-by: Naoya Horiguchi &lt;n-horiguchi@ah.jp.nec.com&gt;</span>
---
 fs/hugetlbfs/inode.c | 11 ++++++
 mm/memory-failure.c  | 94 ++++++++++++++++++++++++++++++----------------------
 2 files changed, 66 insertions(+), 39 deletions(-)
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git v4.12-rc3/fs/hugetlbfs/inode.c v4.12-rc3_patched/fs/hugetlbfs/inode.c</span>
<span class="p_header">index dde8613..33b33ec 100644</span>
<span class="p_header">--- v4.12-rc3/fs/hugetlbfs/inode.c</span>
<span class="p_header">+++ v4.12-rc3_patched/fs/hugetlbfs/inode.c</span>
<span class="p_chunk">@@ -851,6 +851,16 @@</span> <span class="p_context"> static int hugetlbfs_migrate_page(struct address_space *mapping,</span>
 	return MIGRATEPAGE_SUCCESS;
 }
 
<span class="p_add">+static int hugetlbfs_error_remove_page(struct address_space *mapping,</span>
<span class="p_add">+				struct page *page)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct inode *inode = mapping-&gt;host;</span>
<span class="p_add">+</span>
<span class="p_add">+	remove_huge_page(page);</span>
<span class="p_add">+	hugetlb_fix_reserve_counts(inode);</span>
<span class="p_add">+	return 0;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static int hugetlbfs_statfs(struct dentry *dentry, struct kstatfs *buf)
 {
 	struct hugetlbfs_sb_info *sbinfo = HUGETLBFS_SB(dentry-&gt;d_sb);
<span class="p_chunk">@@ -966,6 +976,7 @@</span> <span class="p_context"> static const struct address_space_operations hugetlbfs_aops = {</span>
 	.write_end	= hugetlbfs_write_end,
 	.set_page_dirty	= hugetlbfs_set_page_dirty,
 	.migratepage    = hugetlbfs_migrate_page,
<span class="p_add">+	.error_remove_page	= hugetlbfs_error_remove_page,</span>
 };
 
 
<span class="p_header">diff --git v4.12-rc3/mm/memory-failure.c v4.12-rc3_patched/mm/memory-failure.c</span>
<span class="p_header">index 31b761a..047867b 100644</span>
<span class="p_header">--- v4.12-rc3/mm/memory-failure.c</span>
<span class="p_header">+++ v4.12-rc3_patched/mm/memory-failure.c</span>
<span class="p_chunk">@@ -554,6 +554,39 @@</span> <span class="p_context"> static int delete_from_lru_cache(struct page *p)</span>
 	return -EIO;
 }
 
<span class="p_add">+static int truncate_error_page(struct page *p, unsigned long pfn,</span>
<span class="p_add">+				struct address_space *mapping)</span>
<span class="p_add">+{</span>
<span class="p_add">+	int ret = MF_FAILED;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (mapping-&gt;a_ops-&gt;error_remove_page) {</span>
<span class="p_add">+		int err = mapping-&gt;a_ops-&gt;error_remove_page(mapping, p);</span>
<span class="p_add">+</span>
<span class="p_add">+		if (err != 0) {</span>
<span class="p_add">+			pr_info(&quot;Memory failure: %#lx: Failed to punch page: %d\n&quot;,</span>
<span class="p_add">+				pfn, err);</span>
<span class="p_add">+		} else if (page_has_private(p) &amp;&amp;</span>
<span class="p_add">+			   !try_to_release_page(p, GFP_NOIO)) {</span>
<span class="p_add">+			pr_info(&quot;Memory failure: %#lx: failed to release buffers\n&quot;,</span>
<span class="p_add">+				pfn);</span>
<span class="p_add">+		} else {</span>
<span class="p_add">+			ret = MF_RECOVERED;</span>
<span class="p_add">+		}</span>
<span class="p_add">+	} else {</span>
<span class="p_add">+		/*</span>
<span class="p_add">+		 * If the file system doesn&#39;t support it just invalidate</span>
<span class="p_add">+		 * This fails on dirty or anything with private pages</span>
<span class="p_add">+		 */</span>
<span class="p_add">+		if (invalidate_inode_page(p))</span>
<span class="p_add">+			ret = MF_RECOVERED;</span>
<span class="p_add">+		else</span>
<span class="p_add">+			pr_info(&quot;Memory failure: %#lx: Failed to invalidate\n&quot;,</span>
<span class="p_add">+				pfn);</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	return ret;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 /*
  * Error hit kernel page.
  * Do nothing, try to be lucky and not touch this instead. For a few cases we
<span class="p_chunk">@@ -579,7 +612,6 @@</span> <span class="p_context"> static int me_unknown(struct page *p, unsigned long pfn)</span>
 static int me_pagecache_clean(struct page *p, unsigned long pfn)
 {
 	int err;
<span class="p_del">-	int ret = MF_FAILED;</span>
 	struct address_space *mapping;
 
 	delete_from_lru_cache(p);
<span class="p_chunk">@@ -611,30 +643,7 @@</span> <span class="p_context"> static int me_pagecache_clean(struct page *p, unsigned long pfn)</span>
 	 *
 	 * Open: to take i_mutex or not for this? Right now we don&#39;t.
 	 */
<span class="p_del">-	if (mapping-&gt;a_ops-&gt;error_remove_page) {</span>
<span class="p_del">-		err = mapping-&gt;a_ops-&gt;error_remove_page(mapping, p);</span>
<span class="p_del">-		if (err != 0) {</span>
<span class="p_del">-			pr_info(&quot;Memory failure: %#lx: Failed to punch page: %d\n&quot;,</span>
<span class="p_del">-				pfn, err);</span>
<span class="p_del">-		} else if (page_has_private(p) &amp;&amp;</span>
<span class="p_del">-				!try_to_release_page(p, GFP_NOIO)) {</span>
<span class="p_del">-			pr_info(&quot;Memory failure: %#lx: failed to release buffers\n&quot;,</span>
<span class="p_del">-				pfn);</span>
<span class="p_del">-		} else {</span>
<span class="p_del">-			ret = MF_RECOVERED;</span>
<span class="p_del">-		}</span>
<span class="p_del">-	} else {</span>
<span class="p_del">-		/*</span>
<span class="p_del">-		 * If the file system doesn&#39;t support it just invalidate</span>
<span class="p_del">-		 * This fails on dirty or anything with private pages</span>
<span class="p_del">-		 */</span>
<span class="p_del">-		if (invalidate_inode_page(p))</span>
<span class="p_del">-			ret = MF_RECOVERED;</span>
<span class="p_del">-		else</span>
<span class="p_del">-			pr_info(&quot;Memory failure: %#lx: Failed to invalidate\n&quot;,</span>
<span class="p_del">-				pfn);</span>
<span class="p_del">-	}</span>
<span class="p_del">-	return ret;</span>
<span class="p_add">+	return truncate_error_page(p, pfn, mapping);</span>
 }
 
 /*
<span class="p_chunk">@@ -740,24 +749,31 @@</span> <span class="p_context"> static int me_huge_page(struct page *p, unsigned long pfn)</span>
 {
 	int res = 0;
 	struct page *hpage = compound_head(p);
<span class="p_add">+	struct address_space *mapping;</span>
 
 	if (!PageHuge(hpage))
 		return MF_DELAYED;
 
<span class="p_del">-	/*</span>
<span class="p_del">-	 * We can safely recover from error on free or reserved (i.e.</span>
<span class="p_del">-	 * not in-use) hugepage by dequeuing it from freelist.</span>
<span class="p_del">-	 * To check whether a hugepage is in-use or not, we can&#39;t use</span>
<span class="p_del">-	 * page-&gt;lru because it can be used in other hugepage operations,</span>
<span class="p_del">-	 * such as __unmap_hugepage_range() and gather_surplus_pages().</span>
<span class="p_del">-	 * So instead we use page_mapping() and PageAnon().</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	if (!(page_mapping(hpage) || PageAnon(hpage))) {</span>
<span class="p_del">-		res = dequeue_hwpoisoned_huge_page(hpage);</span>
<span class="p_del">-		if (!res)</span>
<span class="p_del">-			return MF_RECOVERED;</span>
<span class="p_add">+	mapping = page_mapping(hpage);</span>
<span class="p_add">+	if (mapping) {</span>
<span class="p_add">+		res = truncate_error_page(hpage, pfn, mapping);</span>
<span class="p_add">+	} else {</span>
<span class="p_add">+		int dissolve_ret;</span>
<span class="p_add">+</span>
<span class="p_add">+		unlock_page(hpage);</span>
<span class="p_add">+		/*</span>
<span class="p_add">+		 * migration entry prevents later access on error anonymous</span>
<span class="p_add">+		 * hugepage, so we can free and dissolve it into buddy to</span>
<span class="p_add">+		 * save healthy subpages.</span>
<span class="p_add">+		 */</span>
<span class="p_add">+		if (PageAnon(hpage))</span>
<span class="p_add">+			put_page(hpage);</span>
<span class="p_add">+		dissolve_free_huge_page(p);</span>
<span class="p_add">+		res = MF_RECOVERED;</span>
<span class="p_add">+		lock_page(hpage);</span>
 	}
<span class="p_del">-	return MF_DELAYED;</span>
<span class="p_add">+</span>
<span class="p_add">+	return res;</span>
 }
 
 /*
<span class="p_chunk">@@ -856,7 +872,7 @@</span> <span class="p_context"> static int page_action(struct page_state *ps, struct page *p,</span>
 	count = page_count(p) - 1;
 	if (ps-&gt;action == me_swapcache_dirty &amp;&amp; result == MF_DELAYED)
 		count--;
<span class="p_del">-	if (count != 0) {</span>
<span class="p_add">+	if (count &gt; 0) {</span>
 		pr_err(&quot;Memory failure: %#lx: %s still referenced by %d users\n&quot;,
 		       pfn, action_page_types[ps-&gt;type], count);
 		result = MF_FAILED;

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



