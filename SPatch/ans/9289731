
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>[3.12,001/100] x86/mm: Add barriers and document switch_mm()-vs-flush synchronization - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    [3.12,001/100] x86/mm: Add barriers and document switch_mm()-vs-flush synchronization</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=887">Jiri Slaby</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>Aug. 19, 2016, 7:08 a.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;aa8f21d06e61b029341c51b17edd68ba15fe0e47.1471589700.git.jslaby@suse.cz&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/9289731/mbox/"
   >mbox</a>
|
   <a href="/patch/9289731/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/9289731/">/patch/9289731/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
	[172.30.200.125])
	by pdx-korg-patchwork.web.codeaurora.org (Postfix) with ESMTP id
	07BB2607FF for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Fri, 19 Aug 2016 07:35:38 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id F0CE7292E2
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Fri, 19 Aug 2016 07:35:37 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id E507D29317; Fri, 19 Aug 2016 07:35:37 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-6.9 required=2.0 tests=BAYES_00,RCVD_IN_DNSWL_HI
	autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 32090292E2
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Fri, 19 Aug 2016 07:35:37 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1755383AbcHSHfY (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Fri, 19 Aug 2016 03:35:24 -0400
Received: from mx2.suse.de ([195.135.220.15]:49477 &quot;EHLO mx2.suse.de&quot;
	rhost-flags-OK-OK-OK-OK) by vger.kernel.org with ESMTP
	id S1754290AbcHSHK3 (ORCPT &lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Fri, 19 Aug 2016 03:10:29 -0400
X-Virus-Scanned: by amavisd-new at test-mx.suse.de
Received: from relay1.suse.de (charybdis-ext.suse.de [195.135.220.254])
	by mx2.suse.de (Postfix) with ESMTP id 913DCAAF1;
	Fri, 19 Aug 2016 07:10:04 +0000 (UTC)
From: Jiri Slaby &lt;jslaby@suse.cz&gt;
To: stable@vger.kernel.org
Cc: linux-kernel@vger.kernel.org, Andy Lutomirski &lt;luto@kernel.org&gt;,
	Andrew Morton &lt;akpm@linux-foundation.org&gt;,
	Andy Lutomirski &lt;luto@amacapital.net&gt;, Borislav Petkov &lt;bp@alien8.de&gt;,
	Brian Gerst &lt;brgerst@gmail.com&gt;,
	Dave Hansen &lt;dave.hansen@linux.intel.com&gt;,
	Denys Vlasenko &lt;dvlasenk@redhat.com&gt;, &quot;H . Peter Anvin&quot; &lt;hpa@zytor.com&gt;,
	Linus Torvalds &lt;torvalds@linux-foundation.org&gt;,
	Peter Zijlstra &lt;peterz@infradead.org&gt;, Rik van Riel &lt;riel@redhat.com&gt;,
	Thomas Gleixner &lt;tglx@linutronix.de&gt;, linux-mm@kvack.org,
	Ingo Molnar &lt;mingo@kernel.org&gt;, Charles Williams &lt;ciwillia@brocade.com&gt;,
	Jiri Slaby &lt;jslaby@suse.cz&gt;
Subject: [PATCH 3.12 001/100] x86/mm: Add barriers and document
	switch_mm()-vs-flush synchronization
Date: Fri, 19 Aug 2016 09:08:23 +0200
Message-Id: &lt;aa8f21d06e61b029341c51b17edd68ba15fe0e47.1471589700.git.jslaby@suse.cz&gt;
X-Mailer: git-send-email 2.9.3
In-Reply-To: &lt;cover.1471589700.git.jslaby@suse.cz&gt;
References: &lt;cover.1471589700.git.jslaby@suse.cz&gt;
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=887">Jiri Slaby</a> - Aug. 19, 2016, 7:08 a.m.</div>
<pre class="content">
<span class="from">From: Andy Lutomirski &lt;luto@kernel.org&gt;</span>

3.12-stable review patch.  If anyone has any objections, please let me know.
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
===============

commit 71b3c126e61177eb693423f2e18a1914205b165e upstream.

When switch_mm() activates a new PGD, it also sets a bit that
tells other CPUs that the PGD is in use so that TLB flush IPIs
will be sent.  In order for that to work correctly, the bit
needs to be visible prior to loading the PGD and therefore
starting to fill the local TLB.

Document all the barriers that make this work correctly and add
a couple that were missing.

Signed-off-by: Andy Lutomirski &lt;luto@kernel.org&gt;
Cc: Andrew Morton &lt;akpm@linux-foundation.org&gt;
Cc: Andy Lutomirski &lt;luto@amacapital.net&gt;
Cc: Borislav Petkov &lt;bp@alien8.de&gt;
Cc: Brian Gerst &lt;brgerst@gmail.com&gt;
Cc: Dave Hansen &lt;dave.hansen@linux.intel.com&gt;
Cc: Denys Vlasenko &lt;dvlasenk@redhat.com&gt;
Cc: H. Peter Anvin &lt;hpa@zytor.com&gt;
Cc: Linus Torvalds &lt;torvalds@linux-foundation.org&gt;
Cc: Peter Zijlstra &lt;peterz@infradead.org&gt;
Cc: Rik van Riel &lt;riel@redhat.com&gt;
Cc: Thomas Gleixner &lt;tglx@linutronix.de&gt;
Cc: linux-mm@kvack.org
Signed-off-by: Ingo Molnar &lt;mingo@kernel.org&gt;
Cc: Charles (Chas) Williams &lt;ciwillia@brocade.com&gt;
Signed-off-by: Jiri Slaby &lt;jslaby@suse.cz&gt;
<span class="p_del">---</span>
 arch/x86/include/asm/mmu_context.h | 32 +++++++++++++++++++++++++++++++-
 arch/x86/mm/tlb.c                  | 28 +++++++++++++++++++++++++---
 2 files changed, 56 insertions(+), 4 deletions(-)

<span class="p_header">diff --git a/arch/x86/include/asm/mmu_context.h b/arch/x86/include/asm/mmu_context.h</span>
<span class="p_header">index 86fef96f4eca..20cf2c4e1872 100644</span>
<span class="p_header">--- a/arch/x86/include/asm/mmu_context.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/mmu_context.h</span>
<span class="p_chunk">@@ -86,7 +86,32 @@</span> <span class="p_context"> static inline void switch_mm(struct mm_struct *prev, struct mm_struct *next,</span>
 #endif
 		cpumask_set_cpu(cpu, mm_cpumask(next));
 
<span class="p_del">-		/* Re-load page tables */</span>
<span class="p_add">+		/*</span>
<span class="p_add">+		 * Re-load page tables.</span>
<span class="p_add">+		 *</span>
<span class="p_add">+		 * This logic has an ordering constraint:</span>
<span class="p_add">+		 *</span>
<span class="p_add">+		 *  CPU 0: Write to a PTE for &#39;next&#39;</span>
<span class="p_add">+		 *  CPU 0: load bit 1 in mm_cpumask.  if nonzero, send IPI.</span>
<span class="p_add">+		 *  CPU 1: set bit 1 in next&#39;s mm_cpumask</span>
<span class="p_add">+		 *  CPU 1: load from the PTE that CPU 0 writes (implicit)</span>
<span class="p_add">+		 *</span>
<span class="p_add">+		 * We need to prevent an outcome in which CPU 1 observes</span>
<span class="p_add">+		 * the new PTE value and CPU 0 observes bit 1 clear in</span>
<span class="p_add">+		 * mm_cpumask.  (If that occurs, then the IPI will never</span>
<span class="p_add">+		 * be sent, and CPU 0&#39;s TLB will contain a stale entry.)</span>
<span class="p_add">+		 *</span>
<span class="p_add">+		 * The bad outcome can occur if either CPU&#39;s load is</span>
<span class="p_add">+		 * reordered before that CPU&#39;s store, so both CPUs much</span>
<span class="p_add">+		 * execute full barriers to prevent this from happening.</span>
<span class="p_add">+		 *</span>
<span class="p_add">+		 * Thus, switch_mm needs a full barrier between the</span>
<span class="p_add">+		 * store to mm_cpumask and any operation that could load</span>
<span class="p_add">+		 * from next-&gt;pgd.  This barrier synchronizes with</span>
<span class="p_add">+		 * remote TLB flushers.  Fortunately, load_cr3 is</span>
<span class="p_add">+		 * serializing and thus acts as a full barrier.</span>
<span class="p_add">+		 *</span>
<span class="p_add">+		 */</span>
 		load_cr3(next-&gt;pgd);
 
 		/* Stop flush ipis for the previous mm */
<span class="p_chunk">@@ -109,10 +134,15 @@</span> <span class="p_context"> static inline void switch_mm(struct mm_struct *prev, struct mm_struct *next,</span>
 			 * schedule, protecting us from simultaneous changes.
 			 */
 			cpumask_set_cpu(cpu, mm_cpumask(next));
<span class="p_add">+</span>
 			/*
 			 * We were in lazy tlb mode and leave_mm disabled
 			 * tlb flush IPI delivery. We must reload CR3
 			 * to make sure to use no freed page tables.
<span class="p_add">+			 *</span>
<span class="p_add">+			 * As above, this is a barrier that forces</span>
<span class="p_add">+			 * TLB repopulation to be ordered after the</span>
<span class="p_add">+			 * store to mm_cpumask.</span>
 			 */
 			load_cr3(next-&gt;pgd);
 			load_mm_ldt(next);
<span class="p_header">diff --git a/arch/x86/mm/tlb.c b/arch/x86/mm/tlb.c</span>
<span class="p_header">index dd8dda167a24..fc042eeb6e6c 100644</span>
<span class="p_header">--- a/arch/x86/mm/tlb.c</span>
<span class="p_header">+++ b/arch/x86/mm/tlb.c</span>
<span class="p_chunk">@@ -152,6 +152,8 @@</span> <span class="p_context"> void flush_tlb_current_task(void)</span>
 	preempt_disable();
 
 	count_vm_tlb_event(NR_TLB_LOCAL_FLUSH_ALL);
<span class="p_add">+</span>
<span class="p_add">+	/* This is an implicit full barrier that synchronizes with switch_mm. */</span>
 	local_flush_tlb();
 	if (cpumask_any_but(mm_cpumask(mm), smp_processor_id()) &lt; nr_cpu_ids)
 		flush_tlb_others(mm_cpumask(mm), mm, 0UL, TLB_FLUSH_ALL);
<span class="p_chunk">@@ -166,11 +168,19 @@</span> <span class="p_context"> void flush_tlb_mm_range(struct mm_struct *mm, unsigned long start,</span>
 	unsigned long nr_base_pages;
 
 	preempt_disable();
<span class="p_del">-	if (current-&gt;active_mm != mm)</span>
<span class="p_add">+	if (current-&gt;active_mm != mm) {</span>
<span class="p_add">+		/* Synchronize with switch_mm. */</span>
<span class="p_add">+		smp_mb();</span>
<span class="p_add">+</span>
 		goto flush_all;
<span class="p_add">+	}</span>
 
 	if (!current-&gt;mm) {
 		leave_mm(smp_processor_id());
<span class="p_add">+</span>
<span class="p_add">+		/* Synchronize with switch_mm. */</span>
<span class="p_add">+		smp_mb();</span>
<span class="p_add">+</span>
 		goto flush_all;
 	}
 
<span class="p_chunk">@@ -191,6 +201,10 @@</span> <span class="p_context"> void flush_tlb_mm_range(struct mm_struct *mm, unsigned long start,</span>
 	act_entries = mm-&gt;total_vm &gt; act_entries ? act_entries : mm-&gt;total_vm;
 	nr_base_pages = (end - start) &gt;&gt; PAGE_SHIFT;
 
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Both branches below are implicit full barriers (MOV to CR or</span>
<span class="p_add">+	 * INVLPG) that synchronize with switch_mm.</span>
<span class="p_add">+	 */</span>
 	/* tlb_flushall_shift is on balance point, details in commit log */
 	if (nr_base_pages &gt; act_entries) {
 		count_vm_tlb_event(NR_TLB_LOCAL_FLUSH_ALL);
<span class="p_chunk">@@ -222,10 +236,18 @@</span> <span class="p_context"> void flush_tlb_page(struct vm_area_struct *vma, unsigned long start)</span>
 	preempt_disable();
 
 	if (current-&gt;active_mm == mm) {
<span class="p_del">-		if (current-&gt;mm)</span>
<span class="p_add">+		if (current-&gt;mm) {</span>
<span class="p_add">+			/*</span>
<span class="p_add">+			 * Implicit full barrier (INVLPG) that synchronizes</span>
<span class="p_add">+			 * with switch_mm.</span>
<span class="p_add">+			 */</span>
 			__flush_tlb_one(start);
<span class="p_del">-		else</span>
<span class="p_add">+		} else {</span>
 			leave_mm(smp_processor_id());
<span class="p_add">+</span>
<span class="p_add">+			/* Synchronize with switch_mm. */</span>
<span class="p_add">+			smp_mb();</span>
<span class="p_add">+		}</span>
 	}
 
 	if (cpumask_any_but(mm_cpumask(mm), smp_processor_id()) &lt; nr_cpu_ids)

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



