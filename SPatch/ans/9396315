
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>[4/5] mm: Add tlb_remove_check_page_size_change to track page size change - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    [4/5] mm: Add tlb_remove_check_page_size_change to track page size change</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=1141">Aneesh Kumar K.V</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>Oct. 26, 2016, 8:48 a.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;20161026084839.27299-5-aneesh.kumar@linux.vnet.ibm.com&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/9396315/mbox/"
   >mbox</a>
|
   <a href="/patch/9396315/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/9396315/">/patch/9396315/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
	[172.30.200.125])
	by pdx-korg-patchwork.web.codeaurora.org (Postfix) with ESMTP id
	D7B4360236 for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Wed, 26 Oct 2016 08:50:03 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 968D6298CE
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Wed, 26 Oct 2016 08:50:03 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id 8B50129901; Wed, 26 Oct 2016 08:50:03 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-6.4 required=2.0 tests=BAYES_00, RCVD_IN_DNSWL_HI, 
	RCVD_IN_SORBS_SPAM autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 6DCFF29904
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Wed, 26 Oct 2016 08:50:01 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1754582AbcJZIth (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Wed, 26 Oct 2016 04:49:37 -0400
Received: from mx0b-001b2d01.pphosted.com ([148.163.158.5]:60758 &quot;EHLO
	mx0a-001b2d01.pphosted.com&quot; rhost-flags-OK-OK-OK-FAIL)
	by vger.kernel.org with ESMTP id S1754418AbcJZIte (ORCPT
	&lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Wed, 26 Oct 2016 04:49:34 -0400
Received: from pps.filterd (m0098417.ppops.net [127.0.0.1])
	by mx0a-001b2d01.pphosted.com (8.16.0.17/8.16.0.17) with SMTP id
	u9Q8n5pg042584
	for &lt;linux-kernel@vger.kernel.org&gt;; Wed, 26 Oct 2016 04:49:33 -0400
Received: from e37.co.us.ibm.com (e37.co.us.ibm.com [32.97.110.158])
	by mx0a-001b2d01.pphosted.com with ESMTP id 26apt4fpqd-1
	(version=TLSv1.2 cipher=AES256-SHA bits=256 verify=NOT)
	for &lt;linux-kernel@vger.kernel.org&gt;; Wed, 26 Oct 2016 04:49:33 -0400
Received: from localhost
	by e37.co.us.ibm.com with IBM ESMTP SMTP Gateway: Authorized Use
	Only! Violators will be prosecuted
	for &lt;linux-kernel@vger.kernel.org&gt; from
	&lt;aneesh.kumar@linux.vnet.ibm.com&gt;; Wed, 26 Oct 2016 02:49:32 -0600
Received: from d03dlp01.boulder.ibm.com (9.17.202.177)
	by e37.co.us.ibm.com (192.168.1.137) with IBM ESMTP SMTP Gateway:
	Authorized Use Only! Violators will be prosecuted; 
	Wed, 26 Oct 2016 02:49:29 -0600
Received: from b03cxnp08026.gho.boulder.ibm.com
	(b03cxnp08026.gho.boulder.ibm.com [9.17.130.18])
	by d03dlp01.boulder.ibm.com (Postfix) with ESMTP id 3B7CD1FF001F;
	Wed, 26 Oct 2016 02:49:09 -0600 (MDT)
Received: from b03ledav003.gho.boulder.ibm.com
	(b03ledav003.gho.boulder.ibm.com [9.17.130.234])
	by b03cxnp08026.gho.boulder.ibm.com (8.14.9/8.14.9/NCO v10.0) with
	ESMTP id u9Q8nTxS10027430; Wed, 26 Oct 2016 01:49:29 -0700
Received: from b03ledav003.gho.boulder.ibm.com (unknown [127.0.0.1])
	by IMSVA (Postfix) with ESMTP id E5E0B6A03B;
	Wed, 26 Oct 2016 02:49:28 -0600 (MDT)
Received: from skywalker.in.ibm.com (unknown [9.199.45.199])
	by b03ledav003.gho.boulder.ibm.com (Postfix) with ESMTP id 582FB6A03C;
	Wed, 26 Oct 2016 02:49:27 -0600 (MDT)
From: &quot;Aneesh Kumar K.V&quot; &lt;aneesh.kumar@linux.vnet.ibm.com&gt;
To: akpm@linux-foundation.org
Cc: linux-mm@kvack.org, linux-kernel@vger.kernel.org,
	&quot;Aneesh Kumar K.V&quot; &lt;aneesh.kumar@linux.vnet.ibm.com&gt;
Subject: [PATCH 4/5] mm: Add tlb_remove_check_page_size_change to track page
	size change
Date: Wed, 26 Oct 2016 14:18:38 +0530
X-Mailer: git-send-email 2.10.1
In-Reply-To: &lt;20161026084839.27299-1-aneesh.kumar@linux.vnet.ibm.com&gt;
References: &lt;20161026084839.27299-1-aneesh.kumar@linux.vnet.ibm.com&gt;
X-TM-AS-GCONF: 00
X-Content-Scanned: Fidelis XPS MAILER
x-cbid: 16102608-0024-0000-0000-000014DD7C6D
X-IBM-SpamModules-Scores: 
X-IBM-SpamModules-Versions: BY=3.00005981; HX=3.00000240; KW=3.00000007;
	PH=3.00000004; SC=3.00000188; SDB=6.00772924; UDB=6.00371059;
	IPR=6.00549749; 
	BA=6.00004834; NDR=6.00000001; ZLA=6.00000005; ZF=6.00000009;
	ZB=6.00000000; 
	ZP=6.00000000; ZH=6.00000000; ZU=6.00000002; MB=3.00013106;
	XFM=3.00000011; UTC=2016-10-26 08:49:31
X-IBM-AV-DETECTION: SAVI=unused REMOTE=unused XFE=unused
x-cbparentid: 16102608-0025-0000-0000-0000459C37A4
Message-Id: &lt;20161026084839.27299-5-aneesh.kumar@linux.vnet.ibm.com&gt;
X-Proofpoint-Virus-Version: vendor=fsecure engine=2.50.10432:, ,
	definitions=2016-10-26_01:, , signatures=0
X-Proofpoint-Spam-Details: rule=outbound_notspam policy=outbound score=0
	spamscore=0 suspectscore=3
	malwarescore=0 phishscore=0 adultscore=0 bulkscore=0 classifier=spam
	adjust=0 reason=mlx scancount=1 engine=8.0.1-1609300000
	definitions=main-1610260153
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=1141">Aneesh Kumar K.V</a> - Oct. 26, 2016, 8:48 a.m.</div>
<pre class="content">
With commit e77b0852b551 (&quot;mm/mmu_gather: track page size with mmu gather and force flush if page size change&quot;)
we added the ability to force a tlb flush when the page size change in
a mmu_gather loop. We did that by checking for a page size change
every time we added a page to mmu_gather for lazy flush/remove. We can
improve that by moving the page size change check early and not doing
it every time we add a page.

This also help us to do tlb flush when invalidating a range covering
dax mapping. W.r.t dax mapping we don&#39;t have a backing struct page and
hence we don&#39;t call tlb_remove_page, which earlier forced the tlb flush
on page size change. Moving the page size change check earlier means
we will do the same even for dax mapping.

We also avoid doing this check on architecture other than powerpc.

In the later patch we will remove page size check from tlb_remove_page().
<span class="signed-off-by">
Signed-off-by: Aneesh Kumar K.V &lt;aneesh.kumar@linux.vnet.ibm.com&gt;</span>
---
 arch/arm/include/asm/tlb.h     |  6 ++++++
 arch/ia64/include/asm/tlb.h    |  6 ++++++
 arch/powerpc/include/asm/tlb.h | 16 ++++++++++++++++
 arch/s390/include/asm/tlb.h    |  6 ++++++
 arch/sh/include/asm/tlb.h      |  6 ++++++
 arch/um/include/asm/tlb.h      |  6 ++++++
 include/asm-generic/tlb.h      | 16 ++++++++++++++++
 mm/huge_memory.c               |  4 ++++
 mm/hugetlb.c                   |  5 +++++
 mm/madvise.c                   |  1 +
 mm/memory.c                    |  7 ++++++-
 11 files changed, 78 insertions(+), 1 deletion(-)
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/arch/arm/include/asm/tlb.h b/arch/arm/include/asm/tlb.h</span>
<span class="p_header">index 82841ba1f51f..a9d6de4746ea 100644</span>
<span class="p_header">--- a/arch/arm/include/asm/tlb.h</span>
<span class="p_header">+++ b/arch/arm/include/asm/tlb.h</span>
<span class="p_chunk">@@ -286,5 +286,11 @@</span> <span class="p_context"> tlb_remove_pmd_tlb_entry(struct mmu_gather *tlb, pmd_t *pmdp, unsigned long addr</span>
 
 #define tlb_migrate_finish(mm)		do { } while (0)
 
<span class="p_add">+#define tlb_remove_check_page_size_change tlb_remove_check_page_size_change</span>
<span class="p_add">+static inline void tlb_remove_check_page_size_change(struct mmu_gather *tlb,</span>
<span class="p_add">+						     unsigned int page_size)</span>
<span class="p_add">+{</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 #endif /* CONFIG_MMU */
 #endif
<span class="p_header">diff --git a/arch/ia64/include/asm/tlb.h b/arch/ia64/include/asm/tlb.h</span>
<span class="p_header">index b3f369ab844d..bfe6295aa746 100644</span>
<span class="p_header">--- a/arch/ia64/include/asm/tlb.h</span>
<span class="p_header">+++ b/arch/ia64/include/asm/tlb.h</span>
<span class="p_chunk">@@ -286,6 +286,12 @@</span> <span class="p_context"> do {							\</span>
 #define tlb_remove_huge_tlb_entry(h, tlb, ptep, address)	\
 	tlb_remove_tlb_entry(tlb, ptep, address)
 
<span class="p_add">+#define tlb_remove_check_page_size_change tlb_remove_check_page_size_change</span>
<span class="p_add">+static inline void tlb_remove_check_page_size_change(struct mmu_gather *tlb,</span>
<span class="p_add">+						     unsigned int page_size)</span>
<span class="p_add">+{</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 #define pte_free_tlb(tlb, ptep, address)		\
 do {							\
 	tlb-&gt;need_flush = 1;				\
<span class="p_header">diff --git a/arch/powerpc/include/asm/tlb.h b/arch/powerpc/include/asm/tlb.h</span>
<span class="p_header">index f6f68f73e858..c54e9f2cec87 100644</span>
<span class="p_header">--- a/arch/powerpc/include/asm/tlb.h</span>
<span class="p_header">+++ b/arch/powerpc/include/asm/tlb.h</span>
<span class="p_chunk">@@ -28,6 +28,7 @@</span> <span class="p_context"></span>
 #define tlb_start_vma(tlb, vma)	do { } while (0)
 #define tlb_end_vma(tlb, vma)	do { } while (0)
 #define __tlb_remove_tlb_entry	__tlb_remove_tlb_entry
<span class="p_add">+#define tlb_remove_check_page_size_change tlb_remove_check_page_size_change</span>
 
 extern void tlb_flush(struct mmu_gather *tlb);
 
<span class="p_chunk">@@ -46,6 +47,21 @@</span> <span class="p_context"> static inline void __tlb_remove_tlb_entry(struct mmu_gather *tlb, pte_t *ptep,</span>
 #endif
 }
 
<span class="p_add">+static inline void tlb_remove_check_page_size_change(struct mmu_gather *tlb,</span>
<span class="p_add">+						     unsigned int page_size)</span>
<span class="p_add">+{</span>
<span class="p_add">+	if (!tlb-&gt;page_size)</span>
<span class="p_add">+		tlb-&gt;page_size = page_size;</span>
<span class="p_add">+	else if (tlb-&gt;page_size != page_size) {</span>
<span class="p_add">+		tlb_flush_mmu(tlb);</span>
<span class="p_add">+		/*</span>
<span class="p_add">+		 * update the page size after flush for the new</span>
<span class="p_add">+		 * mmu_gather.</span>
<span class="p_add">+		 */</span>
<span class="p_add">+		tlb-&gt;page_size = page_size;</span>
<span class="p_add">+	}</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 #ifdef CONFIG_SMP
 static inline int mm_is_core_local(struct mm_struct *mm)
 {
<span class="p_header">diff --git a/arch/s390/include/asm/tlb.h b/arch/s390/include/asm/tlb.h</span>
<span class="p_header">index 094440b59f9e..28b159c87c38 100644</span>
<span class="p_header">--- a/arch/s390/include/asm/tlb.h</span>
<span class="p_header">+++ b/arch/s390/include/asm/tlb.h</span>
<span class="p_chunk">@@ -165,4 +165,10 @@</span> <span class="p_context"> static inline void pud_free_tlb(struct mmu_gather *tlb, pud_t *pud,</span>
 #define tlb_remove_huge_tlb_entry(h, tlb, ptep, address)	\
 	tlb_remove_tlb_entry(tlb, ptep, address)
 
<span class="p_add">+#define tlb_remove_check_page_size_change tlb_remove_check_page_size_change</span>
<span class="p_add">+static inline void tlb_remove_check_page_size_change(struct mmu_gather *tlb,</span>
<span class="p_add">+						     unsigned int page_size)</span>
<span class="p_add">+{</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 #endif /* _S390_TLB_H */
<span class="p_header">diff --git a/arch/sh/include/asm/tlb.h b/arch/sh/include/asm/tlb.h</span>
<span class="p_header">index e7d15e8c75c1..0f988b3e484b 100644</span>
<span class="p_header">--- a/arch/sh/include/asm/tlb.h</span>
<span class="p_header">+++ b/arch/sh/include/asm/tlb.h</span>
<span class="p_chunk">@@ -130,6 +130,12 @@</span> <span class="p_context"> static inline void tlb_remove_page_size(struct mmu_gather *tlb,</span>
 	return tlb_remove_page(tlb, page);
 }
 
<span class="p_add">+#define tlb_remove_check_page_size_change tlb_remove_check_page_size_change</span>
<span class="p_add">+static inline void tlb_remove_check_page_size_change(struct mmu_gather *tlb,</span>
<span class="p_add">+						     unsigned int page_size)</span>
<span class="p_add">+{</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 #define pte_free_tlb(tlb, ptep, addr)	pte_free((tlb)-&gt;mm, ptep)
 #define pmd_free_tlb(tlb, pmdp, addr)	pmd_free((tlb)-&gt;mm, pmdp)
 #define pud_free_tlb(tlb, pudp, addr)	pud_free((tlb)-&gt;mm, pudp)
<span class="p_header">diff --git a/arch/um/include/asm/tlb.h b/arch/um/include/asm/tlb.h</span>
<span class="p_header">index a4427029c3c8..8258dd4bb13c 100644</span>
<span class="p_header">--- a/arch/um/include/asm/tlb.h</span>
<span class="p_header">+++ b/arch/um/include/asm/tlb.h</span>
<span class="p_chunk">@@ -144,6 +144,12 @@</span> <span class="p_context"> static inline void tlb_remove_page_size(struct mmu_gather *tlb,</span>
 #define tlb_remove_huge_tlb_entry(h, tlb, ptep, address)	\
 	tlb_remove_tlb_entry(tlb, ptep, address)
 
<span class="p_add">+#define tlb_remove_check_page_size_change tlb_remove_check_page_size_change</span>
<span class="p_add">+static inline void tlb_remove_check_page_size_change(struct mmu_gather *tlb,</span>
<span class="p_add">+						     unsigned int page_size)</span>
<span class="p_add">+{</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 #define pte_free_tlb(tlb, ptep, addr) __pte_free_tlb(tlb, ptep, addr)
 
 #define pud_free_tlb(tlb, pudp, addr) __pud_free_tlb(tlb, pudp, addr)
<span class="p_header">diff --git a/include/asm-generic/tlb.h b/include/asm-generic/tlb.h</span>
<span class="p_header">index 38c2b708df6e..256c9de71fdb 100644</span>
<span class="p_header">--- a/include/asm-generic/tlb.h</span>
<span class="p_header">+++ b/include/asm-generic/tlb.h</span>
<span class="p_chunk">@@ -182,6 +182,22 @@</span> <span class="p_context"> static inline bool __tlb_remove_pte_page(struct mmu_gather *tlb, struct page *pa</span>
 	return __tlb_remove_page(tlb, page);
 }
 
<span class="p_add">+#ifndef tlb_remove_check_page_size_change</span>
<span class="p_add">+#define tlb_remove_check_page_size_change tlb_remove_check_page_size_change</span>
<span class="p_add">+static inline void tlb_remove_check_page_size_change(struct mmu_gather *tlb,</span>
<span class="p_add">+						     unsigned int page_size)</span>
<span class="p_add">+{</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * We don&#39;t care about page size change, just update</span>
<span class="p_add">+	 * mmu_gather page size here so that debug checks</span>
<span class="p_add">+	 * doesn&#39;t throw false warning.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+#ifdef CONFIG_DEBUG_VM</span>
<span class="p_add">+	tlb-&gt;page_size = page_size;</span>
<span class="p_add">+#endif</span>
<span class="p_add">+}</span>
<span class="p_add">+#endif</span>
<span class="p_add">+</span>
 /*
  * In the case of tlb vma handling, we can optimise these away in the
  * case where we&#39;re doing a full MM flush.  When we&#39;re doing a munmap,
<span class="p_header">diff --git a/mm/huge_memory.c b/mm/huge_memory.c</span>
<span class="p_header">index 12c6685d4e97..2d1d6bb9534b 100644</span>
<span class="p_header">--- a/mm/huge_memory.c</span>
<span class="p_header">+++ b/mm/huge_memory.c</span>
<span class="p_chunk">@@ -1322,6 +1322,8 @@</span> <span class="p_context"> bool madvise_free_huge_pmd(struct mmu_gather *tlb, struct vm_area_struct *vma,</span>
 	struct mm_struct *mm = tlb-&gt;mm;
 	bool ret = false;
 
<span class="p_add">+	tlb_remove_check_page_size_change(tlb, HPAGE_PMD_SIZE);</span>
<span class="p_add">+</span>
 	ptl = pmd_trans_huge_lock(pmd, vma);
 	if (!ptl)
 		goto out_unlocked;
<span class="p_chunk">@@ -1383,6 +1385,8 @@</span> <span class="p_context"> int zap_huge_pmd(struct mmu_gather *tlb, struct vm_area_struct *vma,</span>
 	pmd_t orig_pmd;
 	spinlock_t *ptl;
 
<span class="p_add">+	tlb_remove_check_page_size_change(tlb, HPAGE_PMD_SIZE);</span>
<span class="p_add">+</span>
 	ptl = __pmd_trans_huge_lock(pmd, vma);
 	if (!ptl)
 		return 0;
<span class="p_header">diff --git a/mm/hugetlb.c b/mm/hugetlb.c</span>
<span class="p_header">index 655d3cf05551..958ba1d87d20 100644</span>
<span class="p_header">--- a/mm/hugetlb.c</span>
<span class="p_header">+++ b/mm/hugetlb.c</span>
<span class="p_chunk">@@ -3222,6 +3222,11 @@</span> <span class="p_context"> void __unmap_hugepage_range(struct mmu_gather *tlb, struct vm_area_struct *vma,</span>
 	BUG_ON(start &amp; ~huge_page_mask(h));
 	BUG_ON(end &amp; ~huge_page_mask(h));
 
<span class="p_add">+	/*</span>
<span class="p_add">+	 * This is a hugetlb vma, all the pte entries should point</span>
<span class="p_add">+	 * to huge page.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	tlb_remove_check_page_size_change(tlb, sz);</span>
 	tlb_start_vma(tlb, vma);
 	mmu_notifier_invalidate_range_start(mm, mmun_start, mmun_end);
 	address = start;
<span class="p_header">diff --git a/mm/madvise.c b/mm/madvise.c</span>
<span class="p_header">index 93fb63e88b5e..0e3828eae9f8 100644</span>
<span class="p_header">--- a/mm/madvise.c</span>
<span class="p_header">+++ b/mm/madvise.c</span>
<span class="p_chunk">@@ -281,6 +281,7 @@</span> <span class="p_context"> static int madvise_free_pte_range(pmd_t *pmd, unsigned long addr,</span>
 	if (pmd_trans_unstable(pmd))
 		return 0;
 
<span class="p_add">+	tlb_remove_check_page_size_change(tlb, PAGE_SIZE);</span>
 	orig_pte = pte = pte_offset_map_lock(mm, pmd, addr, &amp;ptl);
 	arch_enter_lazy_mmu_mode();
 	for (; addr != end; pte++, addr += PAGE_SIZE) {
<span class="p_header">diff --git a/mm/memory.c b/mm/memory.c</span>
<span class="p_header">index e18c57bdc75c..40752dc7750f 100644</span>
<span class="p_header">--- a/mm/memory.c</span>
<span class="p_header">+++ b/mm/memory.c</span>
<span class="p_chunk">@@ -528,7 +528,11 @@</span> <span class="p_context"> void free_pgd_range(struct mmu_gather *tlb,</span>
 		end -= PMD_SIZE;
 	if (addr &gt; end - 1)
 		return;
<span class="p_del">-</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * We add page table cache pages with PAGE_SIZE,</span>
<span class="p_add">+	 * (see pte_free_tlb()), flush the tlb if we need</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	tlb_remove_check_page_size_change(tlb, PAGE_SIZE);</span>
 	pgd = pgd_offset(tlb-&gt;mm, addr);
 	do {
 		next = pgd_addr_end(addr, end);
<span class="p_chunk">@@ -1120,6 +1124,7 @@</span> <span class="p_context"> static unsigned long zap_pte_range(struct mmu_gather *tlb,</span>
 	swp_entry_t entry;
 	struct page *pending_page = NULL;
 
<span class="p_add">+	tlb_remove_check_page_size_change(tlb, PAGE_SIZE);</span>
 again:
 	init_rss_vec(rss);
 	start_pte = pte_offset_map_lock(mm, pmd, addr, &amp;ptl);

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



