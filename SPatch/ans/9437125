
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>[HMM,v13,06/18] mm/ZONE_DEVICE/unaddressable: add special swap for unaddressable - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    [HMM,v13,06/18] mm/ZONE_DEVICE/unaddressable: add special swap for unaddressable</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=2554">Jerome Glisse</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>Nov. 18, 2016, 6:18 p.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;1479493107-982-7-git-send-email-jglisse@redhat.com&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/9437125/mbox/"
   >mbox</a>
|
   <a href="/patch/9437125/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/9437125/">/patch/9437125/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
	[172.30.200.125])
	by pdx-korg-patchwork.web.codeaurora.org (Postfix) with ESMTP id
	506A860237 for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Fri, 18 Nov 2016 17:20:47 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id C3549299C7
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Fri, 18 Nov 2016 17:20:39 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id B80F0299CC; Fri, 18 Nov 2016 17:20:39 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-6.9 required=2.0 tests=BAYES_00,RCVD_IN_DNSWL_HI
	autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 0F5B6299C7
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Fri, 18 Nov 2016 17:20:39 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S932667AbcKRRUW (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Fri, 18 Nov 2016 12:20:22 -0500
Received: from mx1.redhat.com ([209.132.183.28]:49944 &quot;EHLO mx1.redhat.com&quot;
	rhost-flags-OK-OK-OK-OK) by vger.kernel.org with ESMTP
	id S932352AbcKRRRs (ORCPT &lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Fri, 18 Nov 2016 12:17:48 -0500
Received: from int-mx09.intmail.prod.int.phx2.redhat.com
	(int-mx09.intmail.prod.int.phx2.redhat.com [10.5.11.22])
	(using TLSv1.2 with cipher ECDHE-RSA-AES256-GCM-SHA384 (256/256
	bits)) (No client certificate requested)
	by mx1.redhat.com (Postfix) with ESMTPS id 195D14AE94;
	Fri, 18 Nov 2016 17:17:48 +0000 (UTC)
Received: from xgl-cortex.ml2.eng.bos.redhat.com
	(xgl-cortex.ml2.eng.bos.redhat.com [10.19.160.80])
	by int-mx09.intmail.prod.int.phx2.redhat.com (8.14.4/8.14.4) with
	ESMTP id uAIHHd92016767; Fri, 18 Nov 2016 12:17:47 -0500
From: =?UTF-8?q?J=C3=A9r=C3=B4me=20Glisse?= &lt;jglisse@redhat.com&gt;
To: akpm@linux-foundation.org, &lt;linux-kernel@vger.kernel.org&gt;,
	linux-mm@kvack.org
Cc: John Hubbard &lt;jhubbard@nvidia.com&gt;,
	=?UTF-8?q?J=C3=A9r=C3=B4me=20Glisse?= &lt;jglisse@redhat.com&gt;,
	Dan Williams &lt;dan.j.williams@intel.com&gt;,
	Ross Zwisler &lt;ross.zwisler@linux.intel.com&gt;
Subject: [HMM v13 06/18] mm/ZONE_DEVICE/unaddressable: add special swap for
	unaddressable
Date: Fri, 18 Nov 2016 13:18:15 -0500
Message-Id: &lt;1479493107-982-7-git-send-email-jglisse@redhat.com&gt;
In-Reply-To: &lt;1479493107-982-1-git-send-email-jglisse@redhat.com&gt;
References: &lt;1479493107-982-1-git-send-email-jglisse@redhat.com&gt;
MIME-Version: 1.0
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 8bit
X-Scanned-By: MIMEDefang 2.68 on 10.5.11.22
X-Greylist: Sender IP whitelisted, not delayed by milter-greylist-4.5.16
	(mx1.redhat.com [10.5.110.39]);
	Fri, 18 Nov 2016 17:17:48 +0000 (UTC)
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=2554">Jerome Glisse</a> - Nov. 18, 2016, 6:18 p.m.</div>
<pre class="content">
To allow use of device un-addressable memory inside a process add a
special swap type. Also add a new callback to handle page fault on
such entry.
<span class="signed-off-by">
Signed-off-by: Jérôme Glisse &lt;jglisse@redhat.com&gt;</span>
Cc: Dan Williams &lt;dan.j.williams@intel.com&gt;
Cc: Ross Zwisler &lt;ross.zwisler@linux.intel.com&gt;
---
 fs/proc/task_mmu.c       | 10 +++++++-
 include/linux/memremap.h |  5 ++++
 include/linux/swap.h     | 18 ++++++++++---
 include/linux/swapops.h  | 67 ++++++++++++++++++++++++++++++++++++++++++++++++
 kernel/memremap.c        | 14 ++++++++++
 mm/Kconfig               | 12 +++++++++
 mm/memory.c              | 24 +++++++++++++++++
 mm/mprotect.c            | 12 +++++++++
 8 files changed, 158 insertions(+), 4 deletions(-)
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=4745">Balbir Singh</a> - Nov. 21, 2016, 2:06 a.m.</div>
<pre class="content">
On 19/11/16 05:18, Jérôme Glisse wrote:
<span class="quote">&gt; To allow use of device un-addressable memory inside a process add a</span>
<span class="quote">&gt; special swap type. Also add a new callback to handle page fault on</span>
<span class="quote">&gt; such entry.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Signed-off-by: Jérôme Glisse &lt;jglisse@redhat.com&gt;</span>
<span class="quote">&gt; Cc: Dan Williams &lt;dan.j.williams@intel.com&gt;</span>
<span class="quote">&gt; Cc: Ross Zwisler &lt;ross.zwisler@linux.intel.com&gt;</span>
<span class="quote">&gt; ---</span>
<span class="quote">&gt;  fs/proc/task_mmu.c       | 10 +++++++-</span>
<span class="quote">&gt;  include/linux/memremap.h |  5 ++++</span>
<span class="quote">&gt;  include/linux/swap.h     | 18 ++++++++++---</span>
<span class="quote">&gt;  include/linux/swapops.h  | 67 ++++++++++++++++++++++++++++++++++++++++++++++++</span>
<span class="quote">&gt;  kernel/memremap.c        | 14 ++++++++++</span>
<span class="quote">&gt;  mm/Kconfig               | 12 +++++++++</span>
<span class="quote">&gt;  mm/memory.c              | 24 +++++++++++++++++</span>
<span class="quote">&gt;  mm/mprotect.c            | 12 +++++++++</span>
<span class="quote">&gt;  8 files changed, 158 insertions(+), 4 deletions(-)</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; diff --git a/fs/proc/task_mmu.c b/fs/proc/task_mmu.c</span>
<span class="quote">&gt; index 6909582..0726d39 100644</span>
<span class="quote">&gt; --- a/fs/proc/task_mmu.c</span>
<span class="quote">&gt; +++ b/fs/proc/task_mmu.c</span>
<span class="quote">&gt; @@ -544,8 +544,11 @@ static void smaps_pte_entry(pte_t *pte, unsigned long addr,</span>
<span class="quote">&gt;  			} else {</span>
<span class="quote">&gt;  				mss-&gt;swap_pss += (u64)PAGE_SIZE &lt;&lt; PSS_SHIFT;</span>
<span class="quote">&gt;  			}</span>
<span class="quote">&gt; -		} else if (is_migration_entry(swpent))</span>
<span class="quote">&gt; +		} else if (is_migration_entry(swpent)) {</span>
<span class="quote">&gt;  			page = migration_entry_to_page(swpent);</span>
<span class="quote">&gt; +		} else if (is_device_entry(swpent)) {</span>
<span class="quote">&gt; +			page = device_entry_to_page(swpent);</span>
<span class="quote">&gt; +		}</span>


So the reason there is a device swap entry for a page belonging to a user process is
that it is in the middle of migration or is it always that a swap entry represents
unaddressable memory belonging to a GPU device, but its tracked in the page table
entries of the process.
<span class="quote">
&gt;  	} else if (unlikely(IS_ENABLED(CONFIG_SHMEM) &amp;&amp; mss-&gt;check_shmem_swap</span>
<span class="quote">&gt;  							&amp;&amp; pte_none(*pte))) {</span>
<span class="quote">&gt;  		page = find_get_entry(vma-&gt;vm_file-&gt;f_mapping,</span>
<span class="quote">&gt; @@ -708,6 +711,8 @@ static int smaps_hugetlb_range(pte_t *pte, unsigned long hmask,</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  		if (is_migration_entry(swpent))</span>
<span class="quote">&gt;  			page = migration_entry_to_page(swpent);</span>
<span class="quote">&gt; +		if (is_device_entry(swpent))</span>
<span class="quote">&gt; +			page = device_entry_to_page(swpent);</span>
<span class="quote">&gt;  	}</span>
<span class="quote">&gt;  	if (page) {</span>
<span class="quote">&gt;  		int mapcount = page_mapcount(page);</span>
<span class="quote">&gt; @@ -1191,6 +1196,9 @@ static pagemap_entry_t pte_to_pagemap_entry(struct pagemapread *pm,</span>
<span class="quote">&gt;  		flags |= PM_SWAP;</span>
<span class="quote">&gt;  		if (is_migration_entry(entry))</span>
<span class="quote">&gt;  			page = migration_entry_to_page(entry);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +		if (is_device_entry(entry))</span>
<span class="quote">&gt; +			page = device_entry_to_page(entry);</span>
<span class="quote">&gt;  	}</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	if (page &amp;&amp; !PageAnon(page))</span>
<span class="quote">&gt; diff --git a/include/linux/memremap.h b/include/linux/memremap.h</span>
<span class="quote">&gt; index b6f03e9..d584c74 100644</span>
<span class="quote">&gt; --- a/include/linux/memremap.h</span>
<span class="quote">&gt; +++ b/include/linux/memremap.h</span>
<span class="quote">&gt; @@ -47,6 +47,11 @@ static inline struct vmem_altmap *to_vmem_altmap(unsigned long memmap_start)</span>
<span class="quote">&gt;   */</span>
<span class="quote">&gt;  struct dev_pagemap {</span>
<span class="quote">&gt;  	void (*free_devpage)(struct page *page, void *data);</span>
<span class="quote">&gt; +	int (*fault)(struct vm_area_struct *vma,</span>
<span class="quote">&gt; +		     unsigned long addr,</span>
<span class="quote">&gt; +		     struct page *page,</span>
<span class="quote">&gt; +		     unsigned flags,</span>
<span class="quote">&gt; +		     pmd_t *pmdp);</span>
<span class="quote">&gt;  	struct vmem_altmap *altmap;</span>
<span class="quote">&gt;  	const struct resource *res;</span>
<span class="quote">&gt;  	struct percpu_ref *ref;</span>
<span class="quote">&gt; diff --git a/include/linux/swap.h b/include/linux/swap.h</span>
<span class="quote">&gt; index 7e553e1..599cb54 100644</span>
<span class="quote">&gt; --- a/include/linux/swap.h</span>
<span class="quote">&gt; +++ b/include/linux/swap.h</span>
<span class="quote">&gt; @@ -50,6 +50,17 @@ static inline int current_is_kswapd(void)</span>
<span class="quote">&gt;   */</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  /*</span>
<span class="quote">&gt; + * Un-addressable device memory support</span>
<span class="quote">&gt; + */</span>
<span class="quote">&gt; +#ifdef CONFIG_DEVICE_UNADDRESSABLE</span>
<span class="quote">&gt; +#define SWP_DEVICE_NUM 2</span>
<span class="quote">&gt; +#define SWP_DEVICE_WRITE (MAX_SWAPFILES + SWP_HWPOISON_NUM + SWP_MIGRATION_NUM)</span>
<span class="quote">&gt; +#define SWP_DEVICE (MAX_SWAPFILES + SWP_HWPOISON_NUM + SWP_MIGRATION_NUM + 1)</span>
<span class="quote">&gt; +#else</span>
<span class="quote">&gt; +#define SWP_DEVICE_NUM 0</span>
<span class="quote">&gt; +#endif</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +/*</span>
<span class="quote">&gt;   * NUMA node memory migration support</span>
<span class="quote">&gt;   */</span>
<span class="quote">&gt;  #ifdef CONFIG_MIGRATION</span>
<span class="quote">&gt; @@ -71,7 +82,8 @@ static inline int current_is_kswapd(void)</span>
<span class="quote">&gt;  #endif</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  #define MAX_SWAPFILES \</span>
<span class="quote">&gt; -	((1 &lt;&lt; MAX_SWAPFILES_SHIFT) - SWP_MIGRATION_NUM - SWP_HWPOISON_NUM)</span>
<span class="quote">&gt; +	((1 &lt;&lt; MAX_SWAPFILES_SHIFT) - SWP_DEVICE_NUM - \</span>
<span class="quote">&gt; +	SWP_MIGRATION_NUM - SWP_HWPOISON_NUM)</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  /*</span>
<span class="quote">&gt;   * Magic header for a swap area. The first part of the union is</span>
<span class="quote">&gt; @@ -442,8 +454,8 @@ static inline void show_swap_cache_info(void)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; -#define free_swap_and_cache(swp)	is_migration_entry(swp)</span>
<span class="quote">&gt; -#define swapcache_prepare(swp)		is_migration_entry(swp)</span>
<span class="quote">&gt; +#define free_swap_and_cache(e) (is_migration_entry(e) || is_device_entry(e))</span>
<span class="quote">&gt; +#define swapcache_prepare(e) (is_migration_entry(e) || is_device_entry(e))</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  static inline int add_swap_count_continuation(swp_entry_t swp, gfp_t gfp_mask)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt; diff --git a/include/linux/swapops.h b/include/linux/swapops.h</span>
<span class="quote">&gt; index 5c3a5f3..d1aa425 100644</span>
<span class="quote">&gt; --- a/include/linux/swapops.h</span>
<span class="quote">&gt; +++ b/include/linux/swapops.h</span>
<span class="quote">&gt; @@ -100,6 +100,73 @@ static inline void *swp_to_radix_entry(swp_entry_t entry)</span>
<span class="quote">&gt;  	return (void *)(value | RADIX_TREE_EXCEPTIONAL_ENTRY);</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; +#ifdef CONFIG_DEVICE_UNADDRESSABLE</span>
<span class="quote">&gt; +static inline swp_entry_t make_device_entry(struct page *page, bool write)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	return swp_entry(write?SWP_DEVICE_WRITE:SWP_DEVICE, page_to_pfn(page));</span>

Code style checks
<span class="quote">
&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +static inline bool is_device_entry(swp_entry_t entry)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	int type = swp_type(entry);</span>
<span class="quote">&gt; +	return type == SWP_DEVICE || type == SWP_DEVICE_WRITE;</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +static inline void make_device_entry_read(swp_entry_t *entry)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	*entry = swp_entry(SWP_DEVICE, swp_offset(*entry));</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +static inline bool is_write_device_entry(swp_entry_t entry)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	return unlikely(swp_type(entry) == SWP_DEVICE_WRITE);</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +static inline struct page *device_entry_to_page(swp_entry_t entry)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	return pfn_to_page(swp_offset(entry));</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +int device_entry_fault(struct vm_area_struct *vma,</span>
<span class="quote">&gt; +		       unsigned long addr,</span>
<span class="quote">&gt; +		       swp_entry_t entry,</span>
<span class="quote">&gt; +		       unsigned flags,</span>
<span class="quote">&gt; +		       pmd_t *pmdp);</span>
<span class="quote">&gt; +#else /* CONFIG_DEVICE_UNADDRESSABLE */</span>
<span class="quote">&gt; +static inline swp_entry_t make_device_entry(struct page *page, bool write)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	return swp_entry(0, 0);</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +static inline void make_device_entry_read(swp_entry_t *entry)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +static inline bool is_device_entry(swp_entry_t entry)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	return false;</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +static inline bool is_write_device_entry(swp_entry_t entry)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	return false;</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +static inline struct page *device_entry_to_page(swp_entry_t entry)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	return NULL;</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +static inline int device_entry_fault(struct vm_area_struct *vma,</span>
<span class="quote">&gt; +				     unsigned long addr,</span>
<span class="quote">&gt; +				     swp_entry_t entry,</span>
<span class="quote">&gt; +				     unsigned flags,</span>
<span class="quote">&gt; +				     pmd_t *pmdp)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	return VM_FAULT_SIGBUS;</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +#endif /* CONFIG_DEVICE_UNADDRESSABLE */</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt;  #ifdef CONFIG_MIGRATION</span>
<span class="quote">&gt;  static inline swp_entry_t make_migration_entry(struct page *page, int write)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt; diff --git a/kernel/memremap.c b/kernel/memremap.c</span>
<span class="quote">&gt; index cf83928..0670015 100644</span>
<span class="quote">&gt; --- a/kernel/memremap.c</span>
<span class="quote">&gt; +++ b/kernel/memremap.c</span>
<span class="quote">&gt; @@ -18,6 +18,8 @@</span>
<span class="quote">&gt;  #include &lt;linux/io.h&gt;</span>
<span class="quote">&gt;  #include &lt;linux/mm.h&gt;</span>
<span class="quote">&gt;  #include &lt;linux/memory_hotplug.h&gt;</span>
<span class="quote">&gt; +#include &lt;linux/swap.h&gt;</span>
<span class="quote">&gt; +#include &lt;linux/swapops.h&gt;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  #ifndef ioremap_cache</span>
<span class="quote">&gt;  /* temporary while we convert existing ioremap_cache users to memremap */</span>
<span class="quote">&gt; @@ -200,6 +202,18 @@ void put_zone_device_page(struct page *page)</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;  EXPORT_SYMBOL(put_zone_device_page);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; +int device_entry_fault(struct vm_area_struct *vma,</span>
<span class="quote">&gt; +		       unsigned long addr,</span>
<span class="quote">&gt; +		       swp_entry_t entry,</span>
<span class="quote">&gt; +		       unsigned flags,</span>
<span class="quote">&gt; +		       pmd_t *pmdp)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	struct page *page = device_entry_to_page(entry);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	return page-&gt;pgmap-&gt;fault(vma, addr, page, flags, pmdp);</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +EXPORT_SYMBOL(device_entry_fault);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt;  static void pgmap_radix_release(struct resource *res)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	resource_size_t key, align_start, align_size, align_end;</span>
<span class="quote">&gt; diff --git a/mm/Kconfig b/mm/Kconfig</span>
<span class="quote">&gt; index be0ee11..0a21411 100644</span>
<span class="quote">&gt; --- a/mm/Kconfig</span>
<span class="quote">&gt; +++ b/mm/Kconfig</span>
<span class="quote">&gt; @@ -704,6 +704,18 @@ config ZONE_DEVICE</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	  If FS_DAX is enabled, then say Y.</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; +config DEVICE_UNADDRESSABLE</span>
<span class="quote">&gt; +	bool &quot;Un-addressable device memory (GPU memory, ...)&quot;</span>
<span class="quote">&gt; +	depends on ZONE_DEVICE</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	help</span>
<span class="quote">&gt; +	  Allow to create struct page for un-addressable device memory</span>
<span class="quote">&gt; +	  ie memory that is only accessible by the device (or group of</span>
<span class="quote">&gt; +	  devices).</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	  This allow to migrate chunk of process memory to device memory</span>
<span class="quote">&gt; +	  while that memory is use by the device.</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt;  config FRAME_VECTOR</span>
<span class="quote">&gt;  	bool</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; diff --git a/mm/memory.c b/mm/memory.c</span>
<span class="quote">&gt; index 15f2908..a83d690 100644</span>
<span class="quote">&gt; --- a/mm/memory.c</span>
<span class="quote">&gt; +++ b/mm/memory.c</span>
<span class="quote">&gt; @@ -889,6 +889,21 @@ copy_one_pte(struct mm_struct *dst_mm, struct mm_struct *src_mm,</span>
<span class="quote">&gt;  					pte = pte_swp_mksoft_dirty(pte);</span>
<span class="quote">&gt;  				set_pte_at(src_mm, addr, src_pte, pte);</span>
<span class="quote">&gt;  			}</span>
<span class="quote">&gt; +		} else if (is_device_entry(entry)) {</span>
<span class="quote">&gt; +			page = device_entry_to_page(entry);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +			get_page(page);</span>
<span class="quote">&gt; +			rss[mm_counter(page)]++;</span>

Why does rss count go up?
<span class="quote">
&gt; +			page_dup_rmap(page, false);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +			if (is_write_device_entry(entry) &amp;&amp;</span>
<span class="quote">&gt; +			    is_cow_mapping(vm_flags)) {</span>
<span class="quote">&gt; +				make_device_entry_read(&amp;entry);</span>
<span class="quote">&gt; +				pte = swp_entry_to_pte(entry);</span>
<span class="quote">&gt; +				if (pte_swp_soft_dirty(*src_pte))</span>
<span class="quote">&gt; +					pte = pte_swp_mksoft_dirty(pte);</span>
<span class="quote">&gt; +				set_pte_at(src_mm, addr, src_pte, pte);</span>
<span class="quote">&gt; +			}</span>
<span class="quote">&gt;  		}</span>
<span class="quote">&gt;  		goto out_set_pte;</span>
<span class="quote">&gt;  	}</span>
<span class="quote">&gt; @@ -1191,6 +1206,12 @@ again:</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  			page = migration_entry_to_page(entry);</span>
<span class="quote">&gt;  			rss[mm_counter(page)]--;</span>
<span class="quote">&gt; +		} else if (is_device_entry(entry)) {</span>
<span class="quote">&gt; +			struct page *page = device_entry_to_page(entry);</span>
<span class="quote">&gt; +			rss[mm_counter(page)]--;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +			page_remove_rmap(page, false);</span>
<span class="quote">&gt; +			put_page(page);</span>
<span class="quote">&gt;  		}</span>
<span class="quote">&gt;  		if (unlikely(!free_swap_and_cache(entry)))</span>
<span class="quote">&gt;  			print_bad_pte(vma, addr, ptent, NULL);</span>
<span class="quote">&gt; @@ -2536,6 +2557,9 @@ int do_swap_page(struct fault_env *fe, pte_t orig_pte)</span>
<span class="quote">&gt;  	if (unlikely(non_swap_entry(entry))) {</span>
<span class="quote">&gt;  		if (is_migration_entry(entry)) {</span>
<span class="quote">&gt;  			migration_entry_wait(vma-&gt;vm_mm, fe-&gt;pmd, fe-&gt;address);</span>
<span class="quote">&gt; +		} else if (is_device_entry(entry)) {</span>
<span class="quote">&gt; +			ret = device_entry_fault(vma, fe-&gt;address, entry,</span>
<span class="quote">&gt; +						 fe-&gt;flags, fe-&gt;pmd);</span>

What does device_entry_fault() actually do here?
<span class="quote">
&gt;  		} else if (is_hwpoison_entry(entry)) {</span>
<span class="quote">&gt;  			ret = VM_FAULT_HWPOISON;</span>
<span class="quote">&gt;  		} else {</span>
<span class="quote">&gt; diff --git a/mm/mprotect.c b/mm/mprotect.c</span>
<span class="quote">&gt; index 1bc1eb3..70aff3a 100644</span>
<span class="quote">&gt; --- a/mm/mprotect.c</span>
<span class="quote">&gt; +++ b/mm/mprotect.c</span>
<span class="quote">&gt; @@ -139,6 +139,18 @@ static unsigned long change_pte_range(struct vm_area_struct *vma, pmd_t *pmd,</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  				pages++;</span>
<span class="quote">&gt;  			}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +			if (is_write_device_entry(entry)) {</span>
<span class="quote">&gt; +				pte_t newpte;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +				make_device_entry_read(&amp;entry);</span>
<span class="quote">&gt; +				newpte = swp_entry_to_pte(entry);</span>
<span class="quote">&gt; +				if (pte_swp_soft_dirty(oldpte))</span>
<span class="quote">&gt; +					newpte = pte_swp_mksoft_dirty(newpte);</span>
<span class="quote">&gt; +				set_pte_at(mm, addr, pte, newpte);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +				pages++;</span>
<span class="quote">&gt; +			}</span>

Does it make sense to call mprotect() on device memory ranges?
<span class="quote">
&gt;  		}</span>
<span class="quote">&gt;  	} while (pte++, addr += PAGE_SIZE, addr != end);</span>
<span class="quote">&gt;  	arch_leave_lazy_mmu_mode();</span>
<span class="quote">&gt;</span>
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=2554">Jerome Glisse</a> - Nov. 21, 2016, 5:05 a.m.</div>
<pre class="content">
On Mon, Nov 21, 2016 at 01:06:45PM +1100, Balbir Singh wrote:
<span class="quote">&gt; </span>
<span class="quote">&gt; </span>
<span class="quote">&gt; On 19/11/16 05:18, Jérôme Glisse wrote:</span>
<span class="quote">&gt; &gt; To allow use of device un-addressable memory inside a process add a</span>
<span class="quote">&gt; &gt; special swap type. Also add a new callback to handle page fault on</span>
<span class="quote">&gt; &gt; such entry.</span>
<span class="quote">&gt; &gt; </span>
<span class="quote">&gt; &gt; Signed-off-by: Jérôme Glisse &lt;jglisse@redhat.com&gt;</span>
<span class="quote">&gt; &gt; Cc: Dan Williams &lt;dan.j.williams@intel.com&gt;</span>
<span class="quote">&gt; &gt; Cc: Ross Zwisler &lt;ross.zwisler@linux.intel.com&gt;</span>
<span class="quote">&gt; &gt; ---</span>
<span class="quote">&gt; &gt;  fs/proc/task_mmu.c       | 10 +++++++-</span>
<span class="quote">&gt; &gt;  include/linux/memremap.h |  5 ++++</span>
<span class="quote">&gt; &gt;  include/linux/swap.h     | 18 ++++++++++---</span>
<span class="quote">&gt; &gt;  include/linux/swapops.h  | 67 ++++++++++++++++++++++++++++++++++++++++++++++++</span>
<span class="quote">&gt; &gt;  kernel/memremap.c        | 14 ++++++++++</span>
<span class="quote">&gt; &gt;  mm/Kconfig               | 12 +++++++++</span>
<span class="quote">&gt; &gt;  mm/memory.c              | 24 +++++++++++++++++</span>
<span class="quote">&gt; &gt;  mm/mprotect.c            | 12 +++++++++</span>
<span class="quote">&gt; &gt;  8 files changed, 158 insertions(+), 4 deletions(-)</span>
<span class="quote">&gt; &gt; </span>
<span class="quote">&gt; &gt; diff --git a/fs/proc/task_mmu.c b/fs/proc/task_mmu.c</span>
<span class="quote">&gt; &gt; index 6909582..0726d39 100644</span>
<span class="quote">&gt; &gt; --- a/fs/proc/task_mmu.c</span>
<span class="quote">&gt; &gt; +++ b/fs/proc/task_mmu.c</span>
<span class="quote">&gt; &gt; @@ -544,8 +544,11 @@ static void smaps_pte_entry(pte_t *pte, unsigned long addr,</span>
<span class="quote">&gt; &gt;  			} else {</span>
<span class="quote">&gt; &gt;  				mss-&gt;swap_pss += (u64)PAGE_SIZE &lt;&lt; PSS_SHIFT;</span>
<span class="quote">&gt; &gt;  			}</span>
<span class="quote">&gt; &gt; -		} else if (is_migration_entry(swpent))</span>
<span class="quote">&gt; &gt; +		} else if (is_migration_entry(swpent)) {</span>
<span class="quote">&gt; &gt;  			page = migration_entry_to_page(swpent);</span>
<span class="quote">&gt; &gt; +		} else if (is_device_entry(swpent)) {</span>
<span class="quote">&gt; &gt; +			page = device_entry_to_page(swpent);</span>
<span class="quote">&gt; &gt; +		}</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; </span>
<span class="quote">&gt; So the reason there is a device swap entry for a page belonging to a user process is</span>
<span class="quote">&gt; that it is in the middle of migration or is it always that a swap entry represents</span>
<span class="quote">&gt; unaddressable memory belonging to a GPU device, but its tracked in the page table</span>
<span class="quote">&gt; entries of the process.</span>

For page being migrated i use the existing special migration pte entry. This new device
special swap entry is only for unaddressable memory belonging to a device (GPU or any
else). We need to keep track of those inside the CPU page table. Using a new special
swap entry is the easiest way with the minimum amount of change to core mm.

[...]
<span class="quote">
&gt; &gt; +#ifdef CONFIG_DEVICE_UNADDRESSABLE</span>
<span class="quote">&gt; &gt; +static inline swp_entry_t make_device_entry(struct page *page, bool write)</span>
<span class="quote">&gt; &gt; +{</span>
<span class="quote">&gt; &gt; +	return swp_entry(write?SWP_DEVICE_WRITE:SWP_DEVICE, page_to_pfn(page));</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Code style checks</span>

I was trying to balance against 79 columns break rule :)

[...]
<span class="quote">
&gt; &gt; +		} else if (is_device_entry(entry)) {</span>
<span class="quote">&gt; &gt; +			page = device_entry_to_page(entry);</span>
<span class="quote">&gt; &gt; +</span>
<span class="quote">&gt; &gt; +			get_page(page);</span>
<span class="quote">&gt; &gt; +			rss[mm_counter(page)]++;</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Why does rss count go up?</span>

I wanted the device page to be treated like any other page. There is an argument
to be made against and for doing that. Do you have strong argument for not doing
this ?

[...]
<span class="quote">
&gt; &gt; @@ -2536,6 +2557,9 @@ int do_swap_page(struct fault_env *fe, pte_t orig_pte)</span>
<span class="quote">&gt; &gt;  	if (unlikely(non_swap_entry(entry))) {</span>
<span class="quote">&gt; &gt;  		if (is_migration_entry(entry)) {</span>
<span class="quote">&gt; &gt;  			migration_entry_wait(vma-&gt;vm_mm, fe-&gt;pmd, fe-&gt;address);</span>
<span class="quote">&gt; &gt; +		} else if (is_device_entry(entry)) {</span>
<span class="quote">&gt; &gt; +			ret = device_entry_fault(vma, fe-&gt;address, entry,</span>
<span class="quote">&gt; &gt; +						 fe-&gt;flags, fe-&gt;pmd);</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; What does device_entry_fault() actually do here?</span>

Well it is a special fault handler, it must migrate the memory back to some place
where the CPU can access it. It only matter for unaddressable memory.
<span class="quote">
&gt; &gt;  		} else if (is_hwpoison_entry(entry)) {</span>
<span class="quote">&gt; &gt;  			ret = VM_FAULT_HWPOISON;</span>
<span class="quote">&gt; &gt;  		} else {</span>
<span class="quote">&gt; &gt; diff --git a/mm/mprotect.c b/mm/mprotect.c</span>
<span class="quote">&gt; &gt; index 1bc1eb3..70aff3a 100644</span>
<span class="quote">&gt; &gt; --- a/mm/mprotect.c</span>
<span class="quote">&gt; &gt; +++ b/mm/mprotect.c</span>
<span class="quote">&gt; &gt; @@ -139,6 +139,18 @@ static unsigned long change_pte_range(struct vm_area_struct *vma, pmd_t *pmd,</span>
<span class="quote">&gt; &gt;  </span>
<span class="quote">&gt; &gt;  				pages++;</span>
<span class="quote">&gt; &gt;  			}</span>
<span class="quote">&gt; &gt; +</span>
<span class="quote">&gt; &gt; +			if (is_write_device_entry(entry)) {</span>
<span class="quote">&gt; &gt; +				pte_t newpte;</span>
<span class="quote">&gt; &gt; +</span>
<span class="quote">&gt; &gt; +				make_device_entry_read(&amp;entry);</span>
<span class="quote">&gt; &gt; +				newpte = swp_entry_to_pte(entry);</span>
<span class="quote">&gt; &gt; +				if (pte_swp_soft_dirty(oldpte))</span>
<span class="quote">&gt; &gt; +					newpte = pte_swp_mksoft_dirty(newpte);</span>
<span class="quote">&gt; &gt; +				set_pte_at(mm, addr, pte, newpte);</span>
<span class="quote">&gt; &gt; +</span>
<span class="quote">&gt; &gt; +				pages++;</span>
<span class="quote">&gt; &gt; +			}</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Does it make sense to call mprotect() on device memory ranges?</span>

There is nothing special about vma that containt device memory. They can be
private anonymous, share, file back ... So any existing memory syscall must
behave as expected. This is really just like any other page except that CPU
can not access it.

Cheers,
Jérôme
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=36302">Anshuman Khandual</a> - Nov. 21, 2016, 10:58 a.m.</div>
<pre class="content">
On 11/18/2016 11:48 PM, Jérôme Glisse wrote:
<span class="quote">&gt; To allow use of device un-addressable memory inside a process add a</span>
<span class="quote">&gt; special swap type. Also add a new callback to handle page fault on</span>
<span class="quote">&gt; such entry.</span>

IIUC this swap type is required only for the mirror cases and its
not a requirement for migration. If it&#39;s required for mirroring
purpose where we intercept each page fault, the commit message
here should clearly elaborate on that more.
<span class="quote">
&gt; </span>
<span class="quote">&gt; Signed-off-by: Jérôme Glisse &lt;jglisse@redhat.com&gt;</span>
<span class="quote">&gt; Cc: Dan Williams &lt;dan.j.williams@intel.com&gt;</span>
<span class="quote">&gt; Cc: Ross Zwisler &lt;ross.zwisler@linux.intel.com&gt;</span>
<span class="quote">&gt; ---</span>
<span class="quote">&gt;  fs/proc/task_mmu.c       | 10 +++++++-</span>
<span class="quote">&gt;  include/linux/memremap.h |  5 ++++</span>
<span class="quote">&gt;  include/linux/swap.h     | 18 ++++++++++---</span>
<span class="quote">&gt;  include/linux/swapops.h  | 67 ++++++++++++++++++++++++++++++++++++++++++++++++</span>
<span class="quote">&gt;  kernel/memremap.c        | 14 ++++++++++</span>
<span class="quote">&gt;  mm/Kconfig               | 12 +++++++++</span>
<span class="quote">&gt;  mm/memory.c              | 24 +++++++++++++++++</span>
<span class="quote">&gt;  mm/mprotect.c            | 12 +++++++++</span>
<span class="quote">&gt;  8 files changed, 158 insertions(+), 4 deletions(-)</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; diff --git a/fs/proc/task_mmu.c b/fs/proc/task_mmu.c</span>
<span class="quote">&gt; index 6909582..0726d39 100644</span>
<span class="quote">&gt; --- a/fs/proc/task_mmu.c</span>
<span class="quote">&gt; +++ b/fs/proc/task_mmu.c</span>
<span class="quote">&gt; @@ -544,8 +544,11 @@ static void smaps_pte_entry(pte_t *pte, unsigned long addr,</span>
<span class="quote">&gt;  			} else {</span>
<span class="quote">&gt;  				mss-&gt;swap_pss += (u64)PAGE_SIZE &lt;&lt; PSS_SHIFT;</span>
<span class="quote">&gt;  			}</span>
<span class="quote">&gt; -		} else if (is_migration_entry(swpent))</span>
<span class="quote">&gt; +		} else if (is_migration_entry(swpent)) {</span>
<span class="quote">&gt;  			page = migration_entry_to_page(swpent);</span>
<span class="quote">&gt; +		} else if (is_device_entry(swpent)) {</span>
<span class="quote">&gt; +			page = device_entry_to_page(swpent);</span>
<span class="quote">&gt; +		}</span>
<span class="quote">&gt;  	} else if (unlikely(IS_ENABLED(CONFIG_SHMEM) &amp;&amp; mss-&gt;check_shmem_swap</span>
<span class="quote">&gt;  							&amp;&amp; pte_none(*pte))) {</span>
<span class="quote">&gt;  		page = find_get_entry(vma-&gt;vm_file-&gt;f_mapping,</span>
<span class="quote">&gt; @@ -708,6 +711,8 @@ static int smaps_hugetlb_range(pte_t *pte, unsigned long hmask,</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  		if (is_migration_entry(swpent))</span>
<span class="quote">&gt;  			page = migration_entry_to_page(swpent);</span>
<span class="quote">&gt; +		if (is_device_entry(swpent))</span>
<span class="quote">&gt; +			page = device_entry_to_page(swpent);</span>
<span class="quote">&gt;  	}</span>
<span class="quote">&gt;  	if (page) {</span>
<span class="quote">&gt;  		int mapcount = page_mapcount(page);</span>
<span class="quote">&gt; @@ -1191,6 +1196,9 @@ static pagemap_entry_t pte_to_pagemap_entry(struct pagemapread *pm,</span>
<span class="quote">&gt;  		flags |= PM_SWAP;</span>
<span class="quote">&gt;  		if (is_migration_entry(entry))</span>
<span class="quote">&gt;  			page = migration_entry_to_page(entry);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +		if (is_device_entry(entry))</span>
<span class="quote">&gt; +			page = device_entry_to_page(entry);</span>
<span class="quote">&gt;  	}</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	if (page &amp;&amp; !PageAnon(page))</span>
<span class="quote">&gt; diff --git a/include/linux/memremap.h b/include/linux/memremap.h</span>
<span class="quote">&gt; index b6f03e9..d584c74 100644</span>
<span class="quote">&gt; --- a/include/linux/memremap.h</span>
<span class="quote">&gt; +++ b/include/linux/memremap.h</span>
<span class="quote">&gt; @@ -47,6 +47,11 @@ static inline struct vmem_altmap *to_vmem_altmap(unsigned long memmap_start)</span>
<span class="quote">&gt;   */</span>
<span class="quote">&gt;  struct dev_pagemap {</span>
<span class="quote">&gt;  	void (*free_devpage)(struct page *page, void *data);</span>
<span class="quote">&gt; +	int (*fault)(struct vm_area_struct *vma,</span>
<span class="quote">&gt; +		     unsigned long addr,</span>
<span class="quote">&gt; +		     struct page *page,</span>
<span class="quote">&gt; +		     unsigned flags,</span>
<span class="quote">&gt; +		     pmd_t *pmdp);</span>

We are extending the dev_pagemap once again to accommodate device driver
specific fault routines for these pages. Wondering if this extension and
the new swap type should be in the same patch.
<span class="quote">
&gt;  	struct vmem_altmap *altmap;</span>
<span class="quote">&gt;  	const struct resource *res;</span>
<span class="quote">&gt;  	struct percpu_ref *ref;</span>
<span class="quote">&gt; diff --git a/include/linux/swap.h b/include/linux/swap.h</span>
<span class="quote">&gt; index 7e553e1..599cb54 100644</span>
<span class="quote">&gt; --- a/include/linux/swap.h</span>
<span class="quote">&gt; +++ b/include/linux/swap.h</span>
<span class="quote">&gt; @@ -50,6 +50,17 @@ static inline int current_is_kswapd(void)</span>
<span class="quote">&gt;   */</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  /*</span>
<span class="quote">&gt; + * Un-addressable device memory support</span>
<span class="quote">&gt; + */</span>
<span class="quote">&gt; +#ifdef CONFIG_DEVICE_UNADDRESSABLE</span>
<span class="quote">&gt; +#define SWP_DEVICE_NUM 2</span>
<span class="quote">&gt; +#define SWP_DEVICE_WRITE (MAX_SWAPFILES + SWP_HWPOISON_NUM + SWP_MIGRATION_NUM)</span>
<span class="quote">&gt; +#define SWP_DEVICE (MAX_SWAPFILES + SWP_HWPOISON_NUM + SWP_MIGRATION_NUM + 1)</span>
<span class="quote">&gt; +#else</span>
<span class="quote">&gt; +#define SWP_DEVICE_NUM 0</span>
<span class="quote">&gt; +#endif</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +/*</span>
<span class="quote">&gt;   * NUMA node memory migration support</span>
<span class="quote">&gt;   */</span>
<span class="quote">&gt;  #ifdef CONFIG_MIGRATION</span>
<span class="quote">&gt; @@ -71,7 +82,8 @@ static inline int current_is_kswapd(void)</span>
<span class="quote">&gt;  #endif</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  #define MAX_SWAPFILES \</span>
<span class="quote">&gt; -	((1 &lt;&lt; MAX_SWAPFILES_SHIFT) - SWP_MIGRATION_NUM - SWP_HWPOISON_NUM)</span>
<span class="quote">&gt; +	((1 &lt;&lt; MAX_SWAPFILES_SHIFT) - SWP_DEVICE_NUM - \</span>
<span class="quote">&gt; +	SWP_MIGRATION_NUM - SWP_HWPOISON_NUM)</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  /*</span>
<span class="quote">&gt;   * Magic header for a swap area. The first part of the union is</span>
<span class="quote">&gt; @@ -442,8 +454,8 @@ static inline void show_swap_cache_info(void)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; -#define free_swap_and_cache(swp)	is_migration_entry(swp)</span>
<span class="quote">&gt; -#define swapcache_prepare(swp)		is_migration_entry(swp)</span>
<span class="quote">&gt; +#define free_swap_and_cache(e) (is_migration_entry(e) || is_device_entry(e))</span>
<span class="quote">&gt; +#define swapcache_prepare(e) (is_migration_entry(e) || is_device_entry(e))</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  static inline int add_swap_count_continuation(swp_entry_t swp, gfp_t gfp_mask)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt; diff --git a/include/linux/swapops.h b/include/linux/swapops.h</span>
<span class="quote">&gt; index 5c3a5f3..d1aa425 100644</span>
<span class="quote">&gt; --- a/include/linux/swapops.h</span>
<span class="quote">&gt; +++ b/include/linux/swapops.h</span>
<span class="quote">&gt; @@ -100,6 +100,73 @@ static inline void *swp_to_radix_entry(swp_entry_t entry)</span>
<span class="quote">&gt;  	return (void *)(value | RADIX_TREE_EXCEPTIONAL_ENTRY);</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; +#ifdef CONFIG_DEVICE_UNADDRESSABLE</span>
<span class="quote">&gt; +static inline swp_entry_t make_device_entry(struct page *page, bool write)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	return swp_entry(write?SWP_DEVICE_WRITE:SWP_DEVICE, page_to_pfn(page));</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +static inline bool is_device_entry(swp_entry_t entry)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	int type = swp_type(entry);</span>
<span class="quote">&gt; +	return type == SWP_DEVICE || type == SWP_DEVICE_WRITE;</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +static inline void make_device_entry_read(swp_entry_t *entry)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	*entry = swp_entry(SWP_DEVICE, swp_offset(*entry));</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +static inline bool is_write_device_entry(swp_entry_t entry)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	return unlikely(swp_type(entry) == SWP_DEVICE_WRITE);</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +static inline struct page *device_entry_to_page(swp_entry_t entry)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	return pfn_to_page(swp_offset(entry));</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +int device_entry_fault(struct vm_area_struct *vma,</span>
<span class="quote">&gt; +		       unsigned long addr,</span>
<span class="quote">&gt; +		       swp_entry_t entry,</span>
<span class="quote">&gt; +		       unsigned flags,</span>
<span class="quote">&gt; +		       pmd_t *pmdp);</span>
<span class="quote">&gt; +#else /* CONFIG_DEVICE_UNADDRESSABLE */</span>
<span class="quote">&gt; +static inline swp_entry_t make_device_entry(struct page *page, bool write)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	return swp_entry(0, 0);</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +static inline void make_device_entry_read(swp_entry_t *entry)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +static inline bool is_device_entry(swp_entry_t entry)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	return false;</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +static inline bool is_write_device_entry(swp_entry_t entry)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	return false;</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +static inline struct page *device_entry_to_page(swp_entry_t entry)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	return NULL;</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +static inline int device_entry_fault(struct vm_area_struct *vma,</span>
<span class="quote">&gt; +				     unsigned long addr,</span>
<span class="quote">&gt; +				     swp_entry_t entry,</span>
<span class="quote">&gt; +				     unsigned flags,</span>
<span class="quote">&gt; +				     pmd_t *pmdp)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	return VM_FAULT_SIGBUS;</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +#endif /* CONFIG_DEVICE_UNADDRESSABLE */</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt;  #ifdef CONFIG_MIGRATION</span>
<span class="quote">&gt;  static inline swp_entry_t make_migration_entry(struct page *page, int write)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt; diff --git a/kernel/memremap.c b/kernel/memremap.c</span>
<span class="quote">&gt; index cf83928..0670015 100644</span>
<span class="quote">&gt; --- a/kernel/memremap.c</span>
<span class="quote">&gt; +++ b/kernel/memremap.c</span>
<span class="quote">&gt; @@ -18,6 +18,8 @@</span>
<span class="quote">&gt;  #include &lt;linux/io.h&gt;</span>
<span class="quote">&gt;  #include &lt;linux/mm.h&gt;</span>
<span class="quote">&gt;  #include &lt;linux/memory_hotplug.h&gt;</span>
<span class="quote">&gt; +#include &lt;linux/swap.h&gt;</span>
<span class="quote">&gt; +#include &lt;linux/swapops.h&gt;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  #ifndef ioremap_cache</span>
<span class="quote">&gt;  /* temporary while we convert existing ioremap_cache users to memremap */</span>
<span class="quote">&gt; @@ -200,6 +202,18 @@ void put_zone_device_page(struct page *page)</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;  EXPORT_SYMBOL(put_zone_device_page);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; +int device_entry_fault(struct vm_area_struct *vma,</span>
<span class="quote">&gt; +		       unsigned long addr,</span>
<span class="quote">&gt; +		       swp_entry_t entry,</span>
<span class="quote">&gt; +		       unsigned flags,</span>
<span class="quote">&gt; +		       pmd_t *pmdp)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	struct page *page = device_entry_to_page(entry);</span>
<span class="quote">&gt; +</span>

A BUG_ON() if page-&gt;pgmap-&gt;fault has not been populated by the driver.
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=36302">Anshuman Khandual</a> - Nov. 21, 2016, 11:10 a.m.</div>
<pre class="content">
On 11/21/2016 07:36 AM, Balbir Singh wrote:
<span class="quote">&gt; </span>
<span class="quote">&gt; </span>
<span class="quote">&gt; On 19/11/16 05:18, Jérôme Glisse wrote:</span>
<span class="quote">&gt;&gt; To allow use of device un-addressable memory inside a process add a</span>
<span class="quote">&gt;&gt; special swap type. Also add a new callback to handle page fault on</span>
<span class="quote">&gt;&gt; such entry.</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; Signed-off-by: Jérôme Glisse &lt;jglisse@redhat.com&gt;</span>
<span class="quote">&gt;&gt; Cc: Dan Williams &lt;dan.j.williams@intel.com&gt;</span>
<span class="quote">&gt;&gt; Cc: Ross Zwisler &lt;ross.zwisler@linux.intel.com&gt;</span>
<span class="quote">&gt;&gt; ---</span>
<span class="quote">&gt;&gt;  fs/proc/task_mmu.c       | 10 +++++++-</span>
<span class="quote">&gt;&gt;  include/linux/memremap.h |  5 ++++</span>
<span class="quote">&gt;&gt;  include/linux/swap.h     | 18 ++++++++++---</span>
<span class="quote">&gt;&gt;  include/linux/swapops.h  | 67 ++++++++++++++++++++++++++++++++++++++++++++++++</span>
<span class="quote">&gt;&gt;  kernel/memremap.c        | 14 ++++++++++</span>
<span class="quote">&gt;&gt;  mm/Kconfig               | 12 +++++++++</span>
<span class="quote">&gt;&gt;  mm/memory.c              | 24 +++++++++++++++++</span>
<span class="quote">&gt;&gt;  mm/mprotect.c            | 12 +++++++++</span>
<span class="quote">&gt;&gt;  8 files changed, 158 insertions(+), 4 deletions(-)</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; diff --git a/fs/proc/task_mmu.c b/fs/proc/task_mmu.c</span>
<span class="quote">&gt;&gt; index 6909582..0726d39 100644</span>
<span class="quote">&gt;&gt; --- a/fs/proc/task_mmu.c</span>
<span class="quote">&gt;&gt; +++ b/fs/proc/task_mmu.c</span>
<span class="quote">&gt;&gt; @@ -544,8 +544,11 @@ static void smaps_pte_entry(pte_t *pte, unsigned long addr,</span>
<span class="quote">&gt;&gt;  			} else {</span>
<span class="quote">&gt;&gt;  				mss-&gt;swap_pss += (u64)PAGE_SIZE &lt;&lt; PSS_SHIFT;</span>
<span class="quote">&gt;&gt;  			}</span>
<span class="quote">&gt;&gt; -		} else if (is_migration_entry(swpent))</span>
<span class="quote">&gt;&gt; +		} else if (is_migration_entry(swpent)) {</span>
<span class="quote">&gt;&gt;  			page = migration_entry_to_page(swpent);</span>
<span class="quote">&gt;&gt; +		} else if (is_device_entry(swpent)) {</span>
<span class="quote">&gt;&gt; +			page = device_entry_to_page(swpent);</span>
<span class="quote">&gt;&gt; +		}</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; </span>
<span class="quote">&gt; So the reason there is a device swap entry for a page belonging to a user process is</span>
<span class="quote">&gt; that it is in the middle of migration or is it always that a swap entry represents</span>
<span class="quote">&gt; unaddressable memory belonging to a GPU device, but its tracked in the page table</span>
<span class="quote">&gt; entries of the process.</span>

I guess the later is the case and its used for the page table mirroring
purpose after intercepting the page faults. But will leave upto Jerome
to explain more on this.
<span class="quote">
&gt; </span>
<span class="quote">&gt;&gt;  	} else if (unlikely(IS_ENABLED(CONFIG_SHMEM) &amp;&amp; mss-&gt;check_shmem_swap</span>
<span class="quote">&gt;&gt;  							&amp;&amp; pte_none(*pte))) {</span>
<span class="quote">&gt;&gt;  		page = find_get_entry(vma-&gt;vm_file-&gt;f_mapping,</span>
<span class="quote">&gt;&gt; @@ -708,6 +711,8 @@ static int smaps_hugetlb_range(pte_t *pte, unsigned long hmask,</span>
<span class="quote">&gt;&gt;  </span>
<span class="quote">&gt;&gt;  		if (is_migration_entry(swpent))</span>
<span class="quote">&gt;&gt;  			page = migration_entry_to_page(swpent);</span>
<span class="quote">&gt;&gt; +		if (is_device_entry(swpent))</span>
<span class="quote">&gt;&gt; +			page = device_entry_to_page(swpent);</span>
<span class="quote">&gt;&gt;  	}</span>
<span class="quote">&gt;&gt;  	if (page) {</span>
<span class="quote">&gt;&gt;  		int mapcount = page_mapcount(page);</span>
<span class="quote">&gt;&gt; @@ -1191,6 +1196,9 @@ static pagemap_entry_t pte_to_pagemap_entry(struct pagemapread *pm,</span>
<span class="quote">&gt;&gt;  		flags |= PM_SWAP;</span>
<span class="quote">&gt;&gt;  		if (is_migration_entry(entry))</span>
<span class="quote">&gt;&gt;  			page = migration_entry_to_page(entry);</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +		if (is_device_entry(entry))</span>
<span class="quote">&gt;&gt; +			page = device_entry_to_page(entry);</span>
<span class="quote">&gt;&gt;  	}</span>
<span class="quote">&gt;&gt;  </span>
<span class="quote">&gt;&gt;  	if (page &amp;&amp; !PageAnon(page))</span>
<span class="quote">&gt;&gt; diff --git a/include/linux/memremap.h b/include/linux/memremap.h</span>
<span class="quote">&gt;&gt; index b6f03e9..d584c74 100644</span>
<span class="quote">&gt;&gt; --- a/include/linux/memremap.h</span>
<span class="quote">&gt;&gt; +++ b/include/linux/memremap.h</span>
<span class="quote">&gt;&gt; @@ -47,6 +47,11 @@ static inline struct vmem_altmap *to_vmem_altmap(unsigned long memmap_start)</span>
<span class="quote">&gt;&gt;   */</span>
<span class="quote">&gt;&gt;  struct dev_pagemap {</span>
<span class="quote">&gt;&gt;  	void (*free_devpage)(struct page *page, void *data);</span>
<span class="quote">&gt;&gt; +	int (*fault)(struct vm_area_struct *vma,</span>
<span class="quote">&gt;&gt; +		     unsigned long addr,</span>
<span class="quote">&gt;&gt; +		     struct page *page,</span>
<span class="quote">&gt;&gt; +		     unsigned flags,</span>
<span class="quote">&gt;&gt; +		     pmd_t *pmdp);</span>
<span class="quote">&gt;&gt;  	struct vmem_altmap *altmap;</span>
<span class="quote">&gt;&gt;  	const struct resource *res;</span>
<span class="quote">&gt;&gt;  	struct percpu_ref *ref;</span>
<span class="quote">&gt;&gt; diff --git a/include/linux/swap.h b/include/linux/swap.h</span>
<span class="quote">&gt;&gt; index 7e553e1..599cb54 100644</span>
<span class="quote">&gt;&gt; --- a/include/linux/swap.h</span>
<span class="quote">&gt;&gt; +++ b/include/linux/swap.h</span>
<span class="quote">&gt;&gt; @@ -50,6 +50,17 @@ static inline int current_is_kswapd(void)</span>
<span class="quote">&gt;&gt;   */</span>
<span class="quote">&gt;&gt;  </span>
<span class="quote">&gt;&gt;  /*</span>
<span class="quote">&gt;&gt; + * Un-addressable device memory support</span>
<span class="quote">&gt;&gt; + */</span>
<span class="quote">&gt;&gt; +#ifdef CONFIG_DEVICE_UNADDRESSABLE</span>
<span class="quote">&gt;&gt; +#define SWP_DEVICE_NUM 2</span>
<span class="quote">&gt;&gt; +#define SWP_DEVICE_WRITE (MAX_SWAPFILES + SWP_HWPOISON_NUM + SWP_MIGRATION_NUM)</span>
<span class="quote">&gt;&gt; +#define SWP_DEVICE (MAX_SWAPFILES + SWP_HWPOISON_NUM + SWP_MIGRATION_NUM + 1)</span>
<span class="quote">&gt;&gt; +#else</span>
<span class="quote">&gt;&gt; +#define SWP_DEVICE_NUM 0</span>
<span class="quote">&gt;&gt; +#endif</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +/*</span>
<span class="quote">&gt;&gt;   * NUMA node memory migration support</span>
<span class="quote">&gt;&gt;   */</span>
<span class="quote">&gt;&gt;  #ifdef CONFIG_MIGRATION</span>
<span class="quote">&gt;&gt; @@ -71,7 +82,8 @@ static inline int current_is_kswapd(void)</span>
<span class="quote">&gt;&gt;  #endif</span>
<span class="quote">&gt;&gt;  </span>
<span class="quote">&gt;&gt;  #define MAX_SWAPFILES \</span>
<span class="quote">&gt;&gt; -	((1 &lt;&lt; MAX_SWAPFILES_SHIFT) - SWP_MIGRATION_NUM - SWP_HWPOISON_NUM)</span>
<span class="quote">&gt;&gt; +	((1 &lt;&lt; MAX_SWAPFILES_SHIFT) - SWP_DEVICE_NUM - \</span>
<span class="quote">&gt;&gt; +	SWP_MIGRATION_NUM - SWP_HWPOISON_NUM)</span>
<span class="quote">&gt;&gt;  </span>
<span class="quote">&gt;&gt;  /*</span>
<span class="quote">&gt;&gt;   * Magic header for a swap area. The first part of the union is</span>
<span class="quote">&gt;&gt; @@ -442,8 +454,8 @@ static inline void show_swap_cache_info(void)</span>
<span class="quote">&gt;&gt;  {</span>
<span class="quote">&gt;&gt;  }</span>
<span class="quote">&gt;&gt;  </span>
<span class="quote">&gt;&gt; -#define free_swap_and_cache(swp)	is_migration_entry(swp)</span>
<span class="quote">&gt;&gt; -#define swapcache_prepare(swp)		is_migration_entry(swp)</span>
<span class="quote">&gt;&gt; +#define free_swap_and_cache(e) (is_migration_entry(e) || is_device_entry(e))</span>
<span class="quote">&gt;&gt; +#define swapcache_prepare(e) (is_migration_entry(e) || is_device_entry(e))</span>
<span class="quote">&gt;&gt;  </span>
<span class="quote">&gt;&gt;  static inline int add_swap_count_continuation(swp_entry_t swp, gfp_t gfp_mask)</span>
<span class="quote">&gt;&gt;  {</span>
<span class="quote">&gt;&gt; diff --git a/include/linux/swapops.h b/include/linux/swapops.h</span>
<span class="quote">&gt;&gt; index 5c3a5f3..d1aa425 100644</span>
<span class="quote">&gt;&gt; --- a/include/linux/swapops.h</span>
<span class="quote">&gt;&gt; +++ b/include/linux/swapops.h</span>
<span class="quote">&gt;&gt; @@ -100,6 +100,73 @@ static inline void *swp_to_radix_entry(swp_entry_t entry)</span>
<span class="quote">&gt;&gt;  	return (void *)(value | RADIX_TREE_EXCEPTIONAL_ENTRY);</span>
<span class="quote">&gt;&gt;  }</span>
<span class="quote">&gt;&gt;  </span>
<span class="quote">&gt;&gt; +#ifdef CONFIG_DEVICE_UNADDRESSABLE</span>
<span class="quote">&gt;&gt; +static inline swp_entry_t make_device_entry(struct page *page, bool write)</span>
<span class="quote">&gt;&gt; +{</span>
<span class="quote">&gt;&gt; +	return swp_entry(write?SWP_DEVICE_WRITE:SWP_DEVICE, page_to_pfn(page));</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Code style checks</span>
<span class="quote">&gt; </span>
<span class="quote">&gt;&gt; +}</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +static inline bool is_device_entry(swp_entry_t entry)</span>
<span class="quote">&gt;&gt; +{</span>
<span class="quote">&gt;&gt; +	int type = swp_type(entry);</span>
<span class="quote">&gt;&gt; +	return type == SWP_DEVICE || type == SWP_DEVICE_WRITE;</span>
<span class="quote">&gt;&gt; +}</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +static inline void make_device_entry_read(swp_entry_t *entry)</span>
<span class="quote">&gt;&gt; +{</span>
<span class="quote">&gt;&gt; +	*entry = swp_entry(SWP_DEVICE, swp_offset(*entry));</span>
<span class="quote">&gt;&gt; +}</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +static inline bool is_write_device_entry(swp_entry_t entry)</span>
<span class="quote">&gt;&gt; +{</span>
<span class="quote">&gt;&gt; +	return unlikely(swp_type(entry) == SWP_DEVICE_WRITE);</span>
<span class="quote">&gt;&gt; +}</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +static inline struct page *device_entry_to_page(swp_entry_t entry)</span>
<span class="quote">&gt;&gt; +{</span>
<span class="quote">&gt;&gt; +	return pfn_to_page(swp_offset(entry));</span>
<span class="quote">&gt;&gt; +}</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +int device_entry_fault(struct vm_area_struct *vma,</span>
<span class="quote">&gt;&gt; +		       unsigned long addr,</span>
<span class="quote">&gt;&gt; +		       swp_entry_t entry,</span>
<span class="quote">&gt;&gt; +		       unsigned flags,</span>
<span class="quote">&gt;&gt; +		       pmd_t *pmdp);</span>
<span class="quote">&gt;&gt; +#else /* CONFIG_DEVICE_UNADDRESSABLE */</span>
<span class="quote">&gt;&gt; +static inline swp_entry_t make_device_entry(struct page *page, bool write)</span>
<span class="quote">&gt;&gt; +{</span>
<span class="quote">&gt;&gt; +	return swp_entry(0, 0);</span>
<span class="quote">&gt;&gt; +}</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +static inline void make_device_entry_read(swp_entry_t *entry)</span>
<span class="quote">&gt;&gt; +{</span>
<span class="quote">&gt;&gt; +}</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +static inline bool is_device_entry(swp_entry_t entry)</span>
<span class="quote">&gt;&gt; +{</span>
<span class="quote">&gt;&gt; +	return false;</span>
<span class="quote">&gt;&gt; +}</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +static inline bool is_write_device_entry(swp_entry_t entry)</span>
<span class="quote">&gt;&gt; +{</span>
<span class="quote">&gt;&gt; +	return false;</span>
<span class="quote">&gt;&gt; +}</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +static inline struct page *device_entry_to_page(swp_entry_t entry)</span>
<span class="quote">&gt;&gt; +{</span>
<span class="quote">&gt;&gt; +	return NULL;</span>
<span class="quote">&gt;&gt; +}</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +static inline int device_entry_fault(struct vm_area_struct *vma,</span>
<span class="quote">&gt;&gt; +				     unsigned long addr,</span>
<span class="quote">&gt;&gt; +				     swp_entry_t entry,</span>
<span class="quote">&gt;&gt; +				     unsigned flags,</span>
<span class="quote">&gt;&gt; +				     pmd_t *pmdp)</span>
<span class="quote">&gt;&gt; +{</span>
<span class="quote">&gt;&gt; +	return VM_FAULT_SIGBUS;</span>
<span class="quote">&gt;&gt; +}</span>
<span class="quote">&gt;&gt; +#endif /* CONFIG_DEVICE_UNADDRESSABLE */</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt;  #ifdef CONFIG_MIGRATION</span>
<span class="quote">&gt;&gt;  static inline swp_entry_t make_migration_entry(struct page *page, int write)</span>
<span class="quote">&gt;&gt;  {</span>
<span class="quote">&gt;&gt; diff --git a/kernel/memremap.c b/kernel/memremap.c</span>
<span class="quote">&gt;&gt; index cf83928..0670015 100644</span>
<span class="quote">&gt;&gt; --- a/kernel/memremap.c</span>
<span class="quote">&gt;&gt; +++ b/kernel/memremap.c</span>
<span class="quote">&gt;&gt; @@ -18,6 +18,8 @@</span>
<span class="quote">&gt;&gt;  #include &lt;linux/io.h&gt;</span>
<span class="quote">&gt;&gt;  #include &lt;linux/mm.h&gt;</span>
<span class="quote">&gt;&gt;  #include &lt;linux/memory_hotplug.h&gt;</span>
<span class="quote">&gt;&gt; +#include &lt;linux/swap.h&gt;</span>
<span class="quote">&gt;&gt; +#include &lt;linux/swapops.h&gt;</span>
<span class="quote">&gt;&gt;  </span>
<span class="quote">&gt;&gt;  #ifndef ioremap_cache</span>
<span class="quote">&gt;&gt;  /* temporary while we convert existing ioremap_cache users to memremap */</span>
<span class="quote">&gt;&gt; @@ -200,6 +202,18 @@ void put_zone_device_page(struct page *page)</span>
<span class="quote">&gt;&gt;  }</span>
<span class="quote">&gt;&gt;  EXPORT_SYMBOL(put_zone_device_page);</span>
<span class="quote">&gt;&gt;  </span>
<span class="quote">&gt;&gt; +int device_entry_fault(struct vm_area_struct *vma,</span>
<span class="quote">&gt;&gt; +		       unsigned long addr,</span>
<span class="quote">&gt;&gt; +		       swp_entry_t entry,</span>
<span class="quote">&gt;&gt; +		       unsigned flags,</span>
<span class="quote">&gt;&gt; +		       pmd_t *pmdp)</span>
<span class="quote">&gt;&gt; +{</span>
<span class="quote">&gt;&gt; +	struct page *page = device_entry_to_page(entry);</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +	return page-&gt;pgmap-&gt;fault(vma, addr, page, flags, pmdp);</span>
<span class="quote">&gt;&gt; +}</span>
<span class="quote">&gt;&gt; +EXPORT_SYMBOL(device_entry_fault);</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt;  static void pgmap_radix_release(struct resource *res)</span>
<span class="quote">&gt;&gt;  {</span>
<span class="quote">&gt;&gt;  	resource_size_t key, align_start, align_size, align_end;</span>
<span class="quote">&gt;&gt; diff --git a/mm/Kconfig b/mm/Kconfig</span>
<span class="quote">&gt;&gt; index be0ee11..0a21411 100644</span>
<span class="quote">&gt;&gt; --- a/mm/Kconfig</span>
<span class="quote">&gt;&gt; +++ b/mm/Kconfig</span>
<span class="quote">&gt;&gt; @@ -704,6 +704,18 @@ config ZONE_DEVICE</span>
<span class="quote">&gt;&gt;  </span>
<span class="quote">&gt;&gt;  	  If FS_DAX is enabled, then say Y.</span>
<span class="quote">&gt;&gt;  </span>
<span class="quote">&gt;&gt; +config DEVICE_UNADDRESSABLE</span>
<span class="quote">&gt;&gt; +	bool &quot;Un-addressable device memory (GPU memory, ...)&quot;</span>
<span class="quote">&gt;&gt; +	depends on ZONE_DEVICE</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +	help</span>
<span class="quote">&gt;&gt; +	  Allow to create struct page for un-addressable device memory</span>
<span class="quote">&gt;&gt; +	  ie memory that is only accessible by the device (or group of</span>
<span class="quote">&gt;&gt; +	  devices).</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +	  This allow to migrate chunk of process memory to device memory</span>
<span class="quote">&gt;&gt; +	  while that memory is use by the device.</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt;  config FRAME_VECTOR</span>
<span class="quote">&gt;&gt;  	bool</span>
<span class="quote">&gt;&gt;  </span>
<span class="quote">&gt;&gt; diff --git a/mm/memory.c b/mm/memory.c</span>
<span class="quote">&gt;&gt; index 15f2908..a83d690 100644</span>
<span class="quote">&gt;&gt; --- a/mm/memory.c</span>
<span class="quote">&gt;&gt; +++ b/mm/memory.c</span>
<span class="quote">&gt;&gt; @@ -889,6 +889,21 @@ copy_one_pte(struct mm_struct *dst_mm, struct mm_struct *src_mm,</span>
<span class="quote">&gt;&gt;  					pte = pte_swp_mksoft_dirty(pte);</span>
<span class="quote">&gt;&gt;  				set_pte_at(src_mm, addr, src_pte, pte);</span>
<span class="quote">&gt;&gt;  			}</span>
<span class="quote">&gt;&gt; +		} else if (is_device_entry(entry)) {</span>
<span class="quote">&gt;&gt; +			page = device_entry_to_page(entry);</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +			get_page(page);</span>
<span class="quote">&gt;&gt; +			rss[mm_counter(page)]++;</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Why does rss count go up?</span>
<span class="quote">&gt; </span>
<span class="quote">&gt;&gt; +			page_dup_rmap(page, false);</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +			if (is_write_device_entry(entry) &amp;&amp;</span>
<span class="quote">&gt;&gt; +			    is_cow_mapping(vm_flags)) {</span>
<span class="quote">&gt;&gt; +				make_device_entry_read(&amp;entry);</span>
<span class="quote">&gt;&gt; +				pte = swp_entry_to_pte(entry);</span>
<span class="quote">&gt;&gt; +				if (pte_swp_soft_dirty(*src_pte))</span>
<span class="quote">&gt;&gt; +					pte = pte_swp_mksoft_dirty(pte);</span>
<span class="quote">&gt;&gt; +				set_pte_at(src_mm, addr, src_pte, pte);</span>
<span class="quote">&gt;&gt; +			}</span>
<span class="quote">&gt;&gt;  		}</span>
<span class="quote">&gt;&gt;  		goto out_set_pte;</span>
<span class="quote">&gt;&gt;  	}</span>
<span class="quote">&gt;&gt; @@ -1191,6 +1206,12 @@ again:</span>
<span class="quote">&gt;&gt;  </span>
<span class="quote">&gt;&gt;  			page = migration_entry_to_page(entry);</span>
<span class="quote">&gt;&gt;  			rss[mm_counter(page)]--;</span>
<span class="quote">&gt;&gt; +		} else if (is_device_entry(entry)) {</span>
<span class="quote">&gt;&gt; +			struct page *page = device_entry_to_page(entry);</span>
<span class="quote">&gt;&gt; +			rss[mm_counter(page)]--;</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +			page_remove_rmap(page, false);</span>
<span class="quote">&gt;&gt; +			put_page(page);</span>
<span class="quote">&gt;&gt;  		}</span>
<span class="quote">&gt;&gt;  		if (unlikely(!free_swap_and_cache(entry)))</span>
<span class="quote">&gt;&gt;  			print_bad_pte(vma, addr, ptent, NULL);</span>
<span class="quote">&gt;&gt; @@ -2536,6 +2557,9 @@ int do_swap_page(struct fault_env *fe, pte_t orig_pte)</span>
<span class="quote">&gt;&gt;  	if (unlikely(non_swap_entry(entry))) {</span>
<span class="quote">&gt;&gt;  		if (is_migration_entry(entry)) {</span>
<span class="quote">&gt;&gt;  			migration_entry_wait(vma-&gt;vm_mm, fe-&gt;pmd, fe-&gt;address);</span>
<span class="quote">&gt;&gt; +		} else if (is_device_entry(entry)) {</span>
<span class="quote">&gt;&gt; +			ret = device_entry_fault(vma, fe-&gt;address, entry,</span>
<span class="quote">&gt;&gt; +						 fe-&gt;flags, fe-&gt;pmd);</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; What does device_entry_fault() actually do here?</span>

IIUC it calls page-&gt;pgmap-&gt;fault() which is device specific page fault for
the page and thats how the control reaches device driver from the core VM.
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=2554">Jerome Glisse</a> - Nov. 21, 2016, 12:42 p.m.</div>
<pre class="content">
On Mon, Nov 21, 2016 at 04:28:04PM +0530, Anshuman Khandual wrote:
<span class="quote">&gt; On 11/18/2016 11:48 PM, Jérôme Glisse wrote:</span>
<span class="quote">&gt; &gt; To allow use of device un-addressable memory inside a process add a</span>
<span class="quote">&gt; &gt; special swap type. Also add a new callback to handle page fault on</span>
<span class="quote">&gt; &gt; such entry.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; IIUC this swap type is required only for the mirror cases and its</span>
<span class="quote">&gt; not a requirement for migration. If it&#39;s required for mirroring</span>
<span class="quote">&gt; purpose where we intercept each page fault, the commit message</span>
<span class="quote">&gt; here should clearly elaborate on that more.</span>

It is only require for un-addressable memory. The mirroring has nothing to do
with it. I will clarify commit message.

[...]
<span class="quote">
&gt; &gt; diff --git a/include/linux/memremap.h b/include/linux/memremap.h</span>
<span class="quote">&gt; &gt; index b6f03e9..d584c74 100644</span>
<span class="quote">&gt; &gt; --- a/include/linux/memremap.h</span>
<span class="quote">&gt; &gt; +++ b/include/linux/memremap.h</span>
<span class="quote">&gt; &gt; @@ -47,6 +47,11 @@ static inline struct vmem_altmap *to_vmem_altmap(unsigned long memmap_start)</span>
<span class="quote">&gt; &gt;   */</span>
<span class="quote">&gt; &gt;  struct dev_pagemap {</span>
<span class="quote">&gt; &gt;  	void (*free_devpage)(struct page *page, void *data);</span>
<span class="quote">&gt; &gt; +	int (*fault)(struct vm_area_struct *vma,</span>
<span class="quote">&gt; &gt; +		     unsigned long addr,</span>
<span class="quote">&gt; &gt; +		     struct page *page,</span>
<span class="quote">&gt; &gt; +		     unsigned flags,</span>
<span class="quote">&gt; &gt; +		     pmd_t *pmdp);</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; We are extending the dev_pagemap once again to accommodate device driver</span>
<span class="quote">&gt; specific fault routines for these pages. Wondering if this extension and</span>
<span class="quote">&gt; the new swap type should be in the same patch.</span>

It make sense to have it in one single patch as i also change page fault code
path to deal with the new special swap entry and those make use of this new
callback.
<span class="quote">

&gt; &gt; +int device_entry_fault(struct vm_area_struct *vma,</span>
<span class="quote">&gt; &gt; +		       unsigned long addr,</span>
<span class="quote">&gt; &gt; +		       swp_entry_t entry,</span>
<span class="quote">&gt; &gt; +		       unsigned flags,</span>
<span class="quote">&gt; &gt; +		       pmd_t *pmdp)</span>
<span class="quote">&gt; &gt; +{</span>
<span class="quote">&gt; &gt; +	struct page *page = device_entry_to_page(entry);</span>
<span class="quote">&gt; &gt; +</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; A BUG_ON() if page-&gt;pgmap-&gt;fault has not been populated by the driver.</span>
<span class="quote">&gt; </span>

Ok

Cheers,
Jérôme
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=4745">Balbir Singh</a> - Nov. 22, 2016, 2:19 a.m.</div>
<pre class="content">
On 21/11/16 16:05, Jerome Glisse wrote:
<span class="quote">&gt; On Mon, Nov 21, 2016 at 01:06:45PM +1100, Balbir Singh wrote:</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; On 19/11/16 05:18, Jérôme Glisse wrote:</span>
<span class="quote">&gt;&gt;&gt; To allow use of device un-addressable memory inside a process add a</span>
<span class="quote">&gt;&gt;&gt; special swap type. Also add a new callback to handle page fault on</span>
<span class="quote">&gt;&gt;&gt; such entry.</span>
<span class="quote">&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt; Signed-off-by: Jérôme Glisse &lt;jglisse@redhat.com&gt;</span>
<span class="quote">&gt;&gt;&gt; Cc: Dan Williams &lt;dan.j.williams@intel.com&gt;</span>
<span class="quote">&gt;&gt;&gt; Cc: Ross Zwisler &lt;ross.zwisler@linux.intel.com&gt;</span>
<span class="quote">&gt;&gt;&gt; ---</span>
<span class="quote">&gt;&gt;&gt;  fs/proc/task_mmu.c       | 10 +++++++-</span>
<span class="quote">&gt;&gt;&gt;  include/linux/memremap.h |  5 ++++</span>
<span class="quote">&gt;&gt;&gt;  include/linux/swap.h     | 18 ++++++++++---</span>
<span class="quote">&gt;&gt;&gt;  include/linux/swapops.h  | 67 ++++++++++++++++++++++++++++++++++++++++++++++++</span>
<span class="quote">&gt;&gt;&gt;  kernel/memremap.c        | 14 ++++++++++</span>
<span class="quote">&gt;&gt;&gt;  mm/Kconfig               | 12 +++++++++</span>
<span class="quote">&gt;&gt;&gt;  mm/memory.c              | 24 +++++++++++++++++</span>
<span class="quote">&gt;&gt;&gt;  mm/mprotect.c            | 12 +++++++++</span>
<span class="quote">&gt;&gt;&gt;  8 files changed, 158 insertions(+), 4 deletions(-)</span>
<span class="quote">&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt; diff --git a/fs/proc/task_mmu.c b/fs/proc/task_mmu.c</span>
<span class="quote">&gt;&gt;&gt; index 6909582..0726d39 100644</span>
<span class="quote">&gt;&gt;&gt; --- a/fs/proc/task_mmu.c</span>
<span class="quote">&gt;&gt;&gt; +++ b/fs/proc/task_mmu.c</span>
<span class="quote">&gt;&gt;&gt; @@ -544,8 +544,11 @@ static void smaps_pte_entry(pte_t *pte, unsigned long addr,</span>
<span class="quote">&gt;&gt;&gt;  			} else {</span>
<span class="quote">&gt;&gt;&gt;  				mss-&gt;swap_pss += (u64)PAGE_SIZE &lt;&lt; PSS_SHIFT;</span>
<span class="quote">&gt;&gt;&gt;  			}</span>
<span class="quote">&gt;&gt;&gt; -		} else if (is_migration_entry(swpent))</span>
<span class="quote">&gt;&gt;&gt; +		} else if (is_migration_entry(swpent)) {</span>
<span class="quote">&gt;&gt;&gt;  			page = migration_entry_to_page(swpent);</span>
<span class="quote">&gt;&gt;&gt; +		} else if (is_device_entry(swpent)) {</span>
<span class="quote">&gt;&gt;&gt; +			page = device_entry_to_page(swpent);</span>
<span class="quote">&gt;&gt;&gt; +		}</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; So the reason there is a device swap entry for a page belonging to a user process is</span>
<span class="quote">&gt;&gt; that it is in the middle of migration or is it always that a swap entry represents</span>
<span class="quote">&gt;&gt; unaddressable memory belonging to a GPU device, but its tracked in the page table</span>
<span class="quote">&gt;&gt; entries of the process.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; For page being migrated i use the existing special migration pte entry. This new device</span>
<span class="quote">&gt; special swap entry is only for unaddressable memory belonging to a device (GPU or any</span>
<span class="quote">&gt; else). We need to keep track of those inside the CPU page table. Using a new special</span>
<span class="quote">&gt; swap entry is the easiest way with the minimum amount of change to core mm.</span>
<span class="quote">&gt; </span>

Thanks, makes sense
<span class="quote">
&gt; [...]</span>
<span class="quote">&gt; </span>
<span class="quote">&gt;&gt;&gt; +#ifdef CONFIG_DEVICE_UNADDRESSABLE</span>
<span class="quote">&gt;&gt;&gt; +static inline swp_entry_t make_device_entry(struct page *page, bool write)</span>
<span class="quote">&gt;&gt;&gt; +{</span>
<span class="quote">&gt;&gt;&gt; +	return swp_entry(write?SWP_DEVICE_WRITE:SWP_DEVICE, page_to_pfn(page));</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; Code style checks</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; I was trying to balance against 79 columns break rule :)</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; [...]</span>
<span class="quote">&gt; </span>
<span class="quote">&gt;&gt;&gt; +		} else if (is_device_entry(entry)) {</span>
<span class="quote">&gt;&gt;&gt; +			page = device_entry_to_page(entry);</span>
<span class="quote">&gt;&gt;&gt; +</span>
<span class="quote">&gt;&gt;&gt; +			get_page(page);</span>
<span class="quote">&gt;&gt;&gt; +			rss[mm_counter(page)]++;</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; Why does rss count go up?</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; I wanted the device page to be treated like any other page. There is an argument</span>
<span class="quote">&gt; to be made against and for doing that. Do you have strong argument for not doing</span>
<span class="quote">&gt; this ?</span>
<span class="quote">&gt; </span>

Yes, It will end up confusing rss accounting IMHO. If a task is using a lot of
pages on the GPU, should be it a candidate for OOM based on it&#39;s RSS for example?
<span class="quote">
&gt; [...]</span>
<span class="quote">&gt; </span>
<span class="quote">&gt;&gt;&gt; @@ -2536,6 +2557,9 @@ int do_swap_page(struct fault_env *fe, pte_t orig_pte)</span>
<span class="quote">&gt;&gt;&gt;  	if (unlikely(non_swap_entry(entry))) {</span>
<span class="quote">&gt;&gt;&gt;  		if (is_migration_entry(entry)) {</span>
<span class="quote">&gt;&gt;&gt;  			migration_entry_wait(vma-&gt;vm_mm, fe-&gt;pmd, fe-&gt;address);</span>
<span class="quote">&gt;&gt;&gt; +		} else if (is_device_entry(entry)) {</span>
<span class="quote">&gt;&gt;&gt; +			ret = device_entry_fault(vma, fe-&gt;address, entry,</span>
<span class="quote">&gt;&gt;&gt; +						 fe-&gt;flags, fe-&gt;pmd);</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; What does device_entry_fault() actually do here?</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Well it is a special fault handler, it must migrate the memory back to some place</span>
<span class="quote">&gt; where the CPU can access it. It only matter for unaddressable memory.</span>

So effectively swap the page back in, chances are it can ping pong ...but I was wondering if we can
tell the GPU that the CPU is accessing these pages as well. I presume any operation that causes
memory access - core dump will swap back in things from the HMM side onto the CPU side.
<span class="quote">
&gt; </span>
<span class="quote">&gt;&gt;&gt;  		} else if (is_hwpoison_entry(entry)) {</span>
<span class="quote">&gt;&gt;&gt;  			ret = VM_FAULT_HWPOISON;</span>
<span class="quote">&gt;&gt;&gt;  		} else {</span>
<span class="quote">&gt;&gt;&gt; diff --git a/mm/mprotect.c b/mm/mprotect.c</span>
<span class="quote">&gt;&gt;&gt; index 1bc1eb3..70aff3a 100644</span>
<span class="quote">&gt;&gt;&gt; --- a/mm/mprotect.c</span>
<span class="quote">&gt;&gt;&gt; +++ b/mm/mprotect.c</span>
<span class="quote">&gt;&gt;&gt; @@ -139,6 +139,18 @@ static unsigned long change_pte_range(struct vm_area_struct *vma, pmd_t *pmd,</span>
<span class="quote">&gt;&gt;&gt;  </span>
<span class="quote">&gt;&gt;&gt;  				pages++;</span>
<span class="quote">&gt;&gt;&gt;  			}</span>
<span class="quote">&gt;&gt;&gt; +</span>
<span class="quote">&gt;&gt;&gt; +			if (is_write_device_entry(entry)) {</span>
<span class="quote">&gt;&gt;&gt; +				pte_t newpte;</span>
<span class="quote">&gt;&gt;&gt; +</span>
<span class="quote">&gt;&gt;&gt; +				make_device_entry_read(&amp;entry);</span>
<span class="quote">&gt;&gt;&gt; +				newpte = swp_entry_to_pte(entry);</span>
<span class="quote">&gt;&gt;&gt; +				if (pte_swp_soft_dirty(oldpte))</span>
<span class="quote">&gt;&gt;&gt; +					newpte = pte_swp_mksoft_dirty(newpte);</span>
<span class="quote">&gt;&gt;&gt; +				set_pte_at(mm, addr, pte, newpte);</span>
<span class="quote">&gt;&gt;&gt; +</span>
<span class="quote">&gt;&gt;&gt; +				pages++;</span>
<span class="quote">&gt;&gt;&gt; +			}</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; Does it make sense to call mprotect() on device memory ranges?</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; There is nothing special about vma that containt device memory. They can be</span>
<span class="quote">&gt; private anonymous, share, file back ... So any existing memory syscall must</span>
<span class="quote">&gt; behave as expected. This is really just like any other page except that CPU</span>
<span class="quote">&gt; can not access it.</span>

I understand that, but what would marking it as R/O when the GPU is in the middle
of write mean? I would also worry about passing &quot;executable&quot; pages over to the
other side.

Balbir Singh.
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=36302">Anshuman Khandual</a> - Nov. 22, 2016, 4:48 a.m.</div>
<pre class="content">
On 11/21/2016 06:12 PM, Jerome Glisse wrote:
<span class="quote">&gt; On Mon, Nov 21, 2016 at 04:28:04PM +0530, Anshuman Khandual wrote:</span>
<span class="quote">&gt;&gt; On 11/18/2016 11:48 PM, Jérôme Glisse wrote:</span>
<span class="quote">&gt;&gt;&gt; To allow use of device un-addressable memory inside a process add a</span>
<span class="quote">&gt;&gt;&gt; special swap type. Also add a new callback to handle page fault on</span>
<span class="quote">&gt;&gt;&gt; such entry.</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; IIUC this swap type is required only for the mirror cases and its</span>
<span class="quote">&gt;&gt; not a requirement for migration. If it&#39;s required for mirroring</span>
<span class="quote">&gt;&gt; purpose where we intercept each page fault, the commit message</span>
<span class="quote">&gt;&gt; here should clearly elaborate on that more.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; It is only require for un-addressable memory. The mirroring has nothing to do</span>
<span class="quote">&gt; with it. I will clarify commit message.</span>

One thing though. I dont recall how persistent memory ZONE_DEVICE
pages are handled inside the page tables, point here is it should
be part of the same code block. We should catch that its a device
memory page and then figure out addressable or not and act
accordingly. Because persistent memory are CPU addressable, there
might not been special code block but dealing with device pages 
should be handled in a more holistic manner.
<span class="quote">
&gt; </span>
<span class="quote">&gt; [...]</span>
<span class="quote">&gt; </span>
<span class="quote">&gt;&gt;&gt; diff --git a/include/linux/memremap.h b/include/linux/memremap.h</span>
<span class="quote">&gt;&gt;&gt; index b6f03e9..d584c74 100644</span>
<span class="quote">&gt;&gt;&gt; --- a/include/linux/memremap.h</span>
<span class="quote">&gt;&gt;&gt; +++ b/include/linux/memremap.h</span>
<span class="quote">&gt;&gt;&gt; @@ -47,6 +47,11 @@ static inline struct vmem_altmap *to_vmem_altmap(unsigned long memmap_start)</span>
<span class="quote">&gt;&gt;&gt;   */</span>
<span class="quote">&gt;&gt;&gt;  struct dev_pagemap {</span>
<span class="quote">&gt;&gt;&gt;  	void (*free_devpage)(struct page *page, void *data);</span>
<span class="quote">&gt;&gt;&gt; +	int (*fault)(struct vm_area_struct *vma,</span>
<span class="quote">&gt;&gt;&gt; +		     unsigned long addr,</span>
<span class="quote">&gt;&gt;&gt; +		     struct page *page,</span>
<span class="quote">&gt;&gt;&gt; +		     unsigned flags,</span>
<span class="quote">&gt;&gt;&gt; +		     pmd_t *pmdp);</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; We are extending the dev_pagemap once again to accommodate device driver</span>
<span class="quote">&gt;&gt; specific fault routines for these pages. Wondering if this extension and</span>
<span class="quote">&gt;&gt; the new swap type should be in the same patch.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; It make sense to have it in one single patch as i also change page fault code</span>
<span class="quote">&gt; path to deal with the new special swap entry and those make use of this new</span>
<span class="quote">&gt; callback.</span>
<span class="quote">&gt; </span>

Okay.
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=2554">Jerome Glisse</a> - Nov. 22, 2016, 1:59 p.m.</div>
<pre class="content">
On Tue, Nov 22, 2016 at 01:19:42PM +1100, Balbir Singh wrote:
<span class="quote">&gt; </span>
<span class="quote">&gt; </span>
<span class="quote">&gt; On 21/11/16 16:05, Jerome Glisse wrote:</span>
<span class="quote">&gt; &gt; On Mon, Nov 21, 2016 at 01:06:45PM +1100, Balbir Singh wrote:</span>
<span class="quote">&gt; &gt;&gt;</span>
<span class="quote">&gt; &gt;&gt;</span>
<span class="quote">&gt; &gt;&gt; On 19/11/16 05:18, Jérôme Glisse wrote:</span>
<span class="quote">&gt; &gt;&gt;&gt; To allow use of device un-addressable memory inside a process add a</span>
<span class="quote">&gt; &gt;&gt;&gt; special swap type. Also add a new callback to handle page fault on</span>
<span class="quote">&gt; &gt;&gt;&gt; such entry.</span>
<span class="quote">&gt; &gt;&gt;&gt;</span>
<span class="quote">&gt; &gt;&gt;&gt; Signed-off-by: Jérôme Glisse &lt;jglisse@redhat.com&gt;</span>
<span class="quote">&gt; &gt;&gt;&gt; Cc: Dan Williams &lt;dan.j.williams@intel.com&gt;</span>
<span class="quote">&gt; &gt;&gt;&gt; Cc: Ross Zwisler &lt;ross.zwisler@linux.intel.com&gt;</span>
<span class="quote">&gt; &gt;&gt;&gt; ---</span>
<span class="quote">&gt; &gt;&gt;&gt;  fs/proc/task_mmu.c       | 10 +++++++-</span>
<span class="quote">&gt; &gt;&gt;&gt;  include/linux/memremap.h |  5 ++++</span>
<span class="quote">&gt; &gt;&gt;&gt;  include/linux/swap.h     | 18 ++++++++++---</span>
<span class="quote">&gt; &gt;&gt;&gt;  include/linux/swapops.h  | 67 ++++++++++++++++++++++++++++++++++++++++++++++++</span>
<span class="quote">&gt; &gt;&gt;&gt;  kernel/memremap.c        | 14 ++++++++++</span>
<span class="quote">&gt; &gt;&gt;&gt;  mm/Kconfig               | 12 +++++++++</span>
<span class="quote">&gt; &gt;&gt;&gt;  mm/memory.c              | 24 +++++++++++++++++</span>
<span class="quote">&gt; &gt;&gt;&gt;  mm/mprotect.c            | 12 +++++++++</span>
<span class="quote">&gt; &gt;&gt;&gt;  8 files changed, 158 insertions(+), 4 deletions(-)</span>
<span class="quote">&gt; &gt;&gt;&gt;</span>
<span class="quote">&gt; &gt;&gt;&gt; diff --git a/fs/proc/task_mmu.c b/fs/proc/task_mmu.c</span>
<span class="quote">&gt; &gt;&gt;&gt; index 6909582..0726d39 100644</span>
<span class="quote">&gt; &gt;&gt;&gt; --- a/fs/proc/task_mmu.c</span>
<span class="quote">&gt; &gt;&gt;&gt; +++ b/fs/proc/task_mmu.c</span>
<span class="quote">&gt; &gt;&gt;&gt; @@ -544,8 +544,11 @@ static void smaps_pte_entry(pte_t *pte, unsigned long addr,</span>
<span class="quote">&gt; &gt;&gt;&gt;  			} else {</span>
<span class="quote">&gt; &gt;&gt;&gt;  				mss-&gt;swap_pss += (u64)PAGE_SIZE &lt;&lt; PSS_SHIFT;</span>
<span class="quote">&gt; &gt;&gt;&gt;  			}</span>
<span class="quote">&gt; &gt;&gt;&gt; -		} else if (is_migration_entry(swpent))</span>
<span class="quote">&gt; &gt;&gt;&gt; +		} else if (is_migration_entry(swpent)) {</span>
<span class="quote">&gt; &gt;&gt;&gt;  			page = migration_entry_to_page(swpent);</span>
<span class="quote">&gt; &gt;&gt;&gt; +		} else if (is_device_entry(swpent)) {</span>
<span class="quote">&gt; &gt;&gt;&gt; +			page = device_entry_to_page(swpent);</span>
<span class="quote">&gt; &gt;&gt;&gt; +		}</span>
<span class="quote">&gt; &gt;&gt;</span>
<span class="quote">&gt; &gt;&gt;</span>
<span class="quote">&gt; &gt;&gt; So the reason there is a device swap entry for a page belonging to a user process is</span>
<span class="quote">&gt; &gt;&gt; that it is in the middle of migration or is it always that a swap entry represents</span>
<span class="quote">&gt; &gt;&gt; unaddressable memory belonging to a GPU device, but its tracked in the page table</span>
<span class="quote">&gt; &gt;&gt; entries of the process.</span>
<span class="quote">&gt; &gt; </span>
<span class="quote">&gt; &gt; For page being migrated i use the existing special migration pte entry. This new device</span>
<span class="quote">&gt; &gt; special swap entry is only for unaddressable memory belonging to a device (GPU or any</span>
<span class="quote">&gt; &gt; else). We need to keep track of those inside the CPU page table. Using a new special</span>
<span class="quote">&gt; &gt; swap entry is the easiest way with the minimum amount of change to core mm.</span>
<span class="quote">&gt; &gt; </span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Thanks, makes sense</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; &gt; [...]</span>
<span class="quote">&gt; &gt; </span>
<span class="quote">&gt; &gt;&gt;&gt; +#ifdef CONFIG_DEVICE_UNADDRESSABLE</span>
<span class="quote">&gt; &gt;&gt;&gt; +static inline swp_entry_t make_device_entry(struct page *page, bool write)</span>
<span class="quote">&gt; &gt;&gt;&gt; +{</span>
<span class="quote">&gt; &gt;&gt;&gt; +	return swp_entry(write?SWP_DEVICE_WRITE:SWP_DEVICE, page_to_pfn(page));</span>
<span class="quote">&gt; &gt;&gt;</span>
<span class="quote">&gt; &gt;&gt; Code style checks</span>
<span class="quote">&gt; &gt; </span>
<span class="quote">&gt; &gt; I was trying to balance against 79 columns break rule :)</span>
<span class="quote">&gt; &gt; </span>
<span class="quote">&gt; &gt; [...]</span>
<span class="quote">&gt; &gt; </span>
<span class="quote">&gt; &gt;&gt;&gt; +		} else if (is_device_entry(entry)) {</span>
<span class="quote">&gt; &gt;&gt;&gt; +			page = device_entry_to_page(entry);</span>
<span class="quote">&gt; &gt;&gt;&gt; +</span>
<span class="quote">&gt; &gt;&gt;&gt; +			get_page(page);</span>
<span class="quote">&gt; &gt;&gt;&gt; +			rss[mm_counter(page)]++;</span>
<span class="quote">&gt; &gt;&gt;</span>
<span class="quote">&gt; &gt;&gt; Why does rss count go up?</span>
<span class="quote">&gt; &gt; </span>
<span class="quote">&gt; &gt; I wanted the device page to be treated like any other page. There is an argument</span>
<span class="quote">&gt; &gt; to be made against and for doing that. Do you have strong argument for not doing</span>
<span class="quote">&gt; &gt; this ?</span>
<span class="quote">&gt; &gt; </span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Yes, It will end up confusing rss accounting IMHO. If a task is using a lot of</span>
<span class="quote">&gt; pages on the GPU, should be it a candidate for OOM based on it&#39;s RSS for example?</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; &gt; [...]</span>
<span class="quote">&gt; &gt; </span>
<span class="quote">&gt; &gt;&gt;&gt; @@ -2536,6 +2557,9 @@ int do_swap_page(struct fault_env *fe, pte_t orig_pte)</span>
<span class="quote">&gt; &gt;&gt;&gt;  	if (unlikely(non_swap_entry(entry))) {</span>
<span class="quote">&gt; &gt;&gt;&gt;  		if (is_migration_entry(entry)) {</span>
<span class="quote">&gt; &gt;&gt;&gt;  			migration_entry_wait(vma-&gt;vm_mm, fe-&gt;pmd, fe-&gt;address);</span>
<span class="quote">&gt; &gt;&gt;&gt; +		} else if (is_device_entry(entry)) {</span>
<span class="quote">&gt; &gt;&gt;&gt; +			ret = device_entry_fault(vma, fe-&gt;address, entry,</span>
<span class="quote">&gt; &gt;&gt;&gt; +						 fe-&gt;flags, fe-&gt;pmd);</span>
<span class="quote">&gt; &gt;&gt;</span>
<span class="quote">&gt; &gt;&gt; What does device_entry_fault() actually do here?</span>
<span class="quote">&gt; &gt; </span>
<span class="quote">&gt; &gt; Well it is a special fault handler, it must migrate the memory back to some place</span>
<span class="quote">&gt; &gt; where the CPU can access it. It only matter for unaddressable memory.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; So effectively swap the page back in, chances are it can ping pong ...but I was wondering if we can</span>
<span class="quote">&gt; tell the GPU that the CPU is accessing these pages as well. I presume any operation that causes</span>
<span class="quote">&gt; memory access - core dump will swap back in things from the HMM side onto the CPU side.</span>

Well it is up to device driver to gather statistic on what can/should be inside device memory.
My expectation is that they will detect ping pong and stop asking to migrate a given address/
range to device memory.
<span class="quote">
&gt; </span>
<span class="quote">&gt; &gt; </span>
<span class="quote">&gt; &gt;&gt;&gt;  		} else if (is_hwpoison_entry(entry)) {</span>
<span class="quote">&gt; &gt;&gt;&gt;  			ret = VM_FAULT_HWPOISON;</span>
<span class="quote">&gt; &gt;&gt;&gt;  		} else {</span>
<span class="quote">&gt; &gt;&gt;&gt; diff --git a/mm/mprotect.c b/mm/mprotect.c</span>
<span class="quote">&gt; &gt;&gt;&gt; index 1bc1eb3..70aff3a 100644</span>
<span class="quote">&gt; &gt;&gt;&gt; --- a/mm/mprotect.c</span>
<span class="quote">&gt; &gt;&gt;&gt; +++ b/mm/mprotect.c</span>
<span class="quote">&gt; &gt;&gt;&gt; @@ -139,6 +139,18 @@ static unsigned long change_pte_range(struct vm_area_struct *vma, pmd_t *pmd,</span>
<span class="quote">&gt; &gt;&gt;&gt;  </span>
<span class="quote">&gt; &gt;&gt;&gt;  				pages++;</span>
<span class="quote">&gt; &gt;&gt;&gt;  			}</span>
<span class="quote">&gt; &gt;&gt;&gt; +</span>
<span class="quote">&gt; &gt;&gt;&gt; +			if (is_write_device_entry(entry)) {</span>
<span class="quote">&gt; &gt;&gt;&gt; +				pte_t newpte;</span>
<span class="quote">&gt; &gt;&gt;&gt; +</span>
<span class="quote">&gt; &gt;&gt;&gt; +				make_device_entry_read(&amp;entry);</span>
<span class="quote">&gt; &gt;&gt;&gt; +				newpte = swp_entry_to_pte(entry);</span>
<span class="quote">&gt; &gt;&gt;&gt; +				if (pte_swp_soft_dirty(oldpte))</span>
<span class="quote">&gt; &gt;&gt;&gt; +					newpte = pte_swp_mksoft_dirty(newpte);</span>
<span class="quote">&gt; &gt;&gt;&gt; +				set_pte_at(mm, addr, pte, newpte);</span>
<span class="quote">&gt; &gt;&gt;&gt; +</span>
<span class="quote">&gt; &gt;&gt;&gt; +				pages++;</span>
<span class="quote">&gt; &gt;&gt;&gt; +			}</span>
<span class="quote">&gt; &gt;&gt;</span>
<span class="quote">&gt; &gt;&gt; Does it make sense to call mprotect() on device memory ranges?</span>
<span class="quote">&gt; &gt; </span>
<span class="quote">&gt; &gt; There is nothing special about vma that containt device memory. They can be</span>
<span class="quote">&gt; &gt; private anonymous, share, file back ... So any existing memory syscall must</span>
<span class="quote">&gt; &gt; behave as expected. This is really just like any other page except that CPU</span>
<span class="quote">&gt; &gt; can not access it.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; I understand that, but what would marking it as R/O when the GPU is in the middle</span>
<span class="quote">&gt; of write mean? I would also worry about passing &quot;executable&quot; pages over to the</span>
<span class="quote">&gt; other side.</span>
<span class="quote">&gt; </span>

Any memory protection change will trigger an mmu_notifier calls which in turn will
update the device page table accordingly. So R/O status will also happen on the GPU.

We assume here that the device driver is not doing evil thing and that device driver
obey memory protection for all range it mirrors. Upstream driver are easy to check.
Close driver might be more problematic, in NVidia case this part if open source and
is easily checkable.

Cheers,
Jérôme
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=2554">Jerome Glisse</a> - Nov. 24, 2016, 1:56 p.m.</div>
<pre class="content">
On Tue, Nov 22, 2016 at 10:18:27AM +0530, Anshuman Khandual wrote:
<span class="quote">&gt; On 11/21/2016 06:12 PM, Jerome Glisse wrote:</span>
<span class="quote">&gt; &gt; On Mon, Nov 21, 2016 at 04:28:04PM +0530, Anshuman Khandual wrote:</span>
<span class="quote">&gt; &gt;&gt; On 11/18/2016 11:48 PM, Jérôme Glisse wrote:</span>
<span class="quote">&gt; &gt;&gt;&gt; To allow use of device un-addressable memory inside a process add a</span>
<span class="quote">&gt; &gt;&gt;&gt; special swap type. Also add a new callback to handle page fault on</span>
<span class="quote">&gt; &gt;&gt;&gt; such entry.</span>
<span class="quote">&gt; &gt;&gt;</span>
<span class="quote">&gt; &gt;&gt; IIUC this swap type is required only for the mirror cases and its</span>
<span class="quote">&gt; &gt;&gt; not a requirement for migration. If it&#39;s required for mirroring</span>
<span class="quote">&gt; &gt;&gt; purpose where we intercept each page fault, the commit message</span>
<span class="quote">&gt; &gt;&gt; here should clearly elaborate on that more.</span>
<span class="quote">&gt; &gt; </span>
<span class="quote">&gt; &gt; It is only require for un-addressable memory. The mirroring has nothing to do</span>
<span class="quote">&gt; &gt; with it. I will clarify commit message.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; One thing though. I dont recall how persistent memory ZONE_DEVICE</span>
<span class="quote">&gt; pages are handled inside the page tables, point here is it should</span>
<span class="quote">&gt; be part of the same code block. We should catch that its a device</span>
<span class="quote">&gt; memory page and then figure out addressable or not and act</span>
<span class="quote">&gt; accordingly. Because persistent memory are CPU addressable, there</span>
<span class="quote">&gt; might not been special code block but dealing with device pages </span>
<span class="quote">&gt; should be handled in a more holistic manner.</span>

Before i repost updated patchset i should stress that dealing with un-addressable
device page and addressable one in same block is not do-able without re-doing once
again the whole mm page fault code path. Because i use special swap entry the 
logical place for me to handle it is with where swap entry are handled.

Regular device page are handle bit simpler that other page because they can&#39;t be
evicted/swaped so they are always present once faulted. I think right now they
are always populated through fs page fault callback (well dax one).

So not much reasons to consolidate all device page handling in one place. We are
looking at different use case in the end.

Cheers,
Jérôme
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/fs/proc/task_mmu.c b/fs/proc/task_mmu.c</span>
<span class="p_header">index 6909582..0726d39 100644</span>
<span class="p_header">--- a/fs/proc/task_mmu.c</span>
<span class="p_header">+++ b/fs/proc/task_mmu.c</span>
<span class="p_chunk">@@ -544,8 +544,11 @@</span> <span class="p_context"> static void smaps_pte_entry(pte_t *pte, unsigned long addr,</span>
 			} else {
 				mss-&gt;swap_pss += (u64)PAGE_SIZE &lt;&lt; PSS_SHIFT;
 			}
<span class="p_del">-		} else if (is_migration_entry(swpent))</span>
<span class="p_add">+		} else if (is_migration_entry(swpent)) {</span>
 			page = migration_entry_to_page(swpent);
<span class="p_add">+		} else if (is_device_entry(swpent)) {</span>
<span class="p_add">+			page = device_entry_to_page(swpent);</span>
<span class="p_add">+		}</span>
 	} else if (unlikely(IS_ENABLED(CONFIG_SHMEM) &amp;&amp; mss-&gt;check_shmem_swap
 							&amp;&amp; pte_none(*pte))) {
 		page = find_get_entry(vma-&gt;vm_file-&gt;f_mapping,
<span class="p_chunk">@@ -708,6 +711,8 @@</span> <span class="p_context"> static int smaps_hugetlb_range(pte_t *pte, unsigned long hmask,</span>
 
 		if (is_migration_entry(swpent))
 			page = migration_entry_to_page(swpent);
<span class="p_add">+		if (is_device_entry(swpent))</span>
<span class="p_add">+			page = device_entry_to_page(swpent);</span>
 	}
 	if (page) {
 		int mapcount = page_mapcount(page);
<span class="p_chunk">@@ -1191,6 +1196,9 @@</span> <span class="p_context"> static pagemap_entry_t pte_to_pagemap_entry(struct pagemapread *pm,</span>
 		flags |= PM_SWAP;
 		if (is_migration_entry(entry))
 			page = migration_entry_to_page(entry);
<span class="p_add">+</span>
<span class="p_add">+		if (is_device_entry(entry))</span>
<span class="p_add">+			page = device_entry_to_page(entry);</span>
 	}
 
 	if (page &amp;&amp; !PageAnon(page))
<span class="p_header">diff --git a/include/linux/memremap.h b/include/linux/memremap.h</span>
<span class="p_header">index b6f03e9..d584c74 100644</span>
<span class="p_header">--- a/include/linux/memremap.h</span>
<span class="p_header">+++ b/include/linux/memremap.h</span>
<span class="p_chunk">@@ -47,6 +47,11 @@</span> <span class="p_context"> static inline struct vmem_altmap *to_vmem_altmap(unsigned long memmap_start)</span>
  */
 struct dev_pagemap {
 	void (*free_devpage)(struct page *page, void *data);
<span class="p_add">+	int (*fault)(struct vm_area_struct *vma,</span>
<span class="p_add">+		     unsigned long addr,</span>
<span class="p_add">+		     struct page *page,</span>
<span class="p_add">+		     unsigned flags,</span>
<span class="p_add">+		     pmd_t *pmdp);</span>
 	struct vmem_altmap *altmap;
 	const struct resource *res;
 	struct percpu_ref *ref;
<span class="p_header">diff --git a/include/linux/swap.h b/include/linux/swap.h</span>
<span class="p_header">index 7e553e1..599cb54 100644</span>
<span class="p_header">--- a/include/linux/swap.h</span>
<span class="p_header">+++ b/include/linux/swap.h</span>
<span class="p_chunk">@@ -50,6 +50,17 @@</span> <span class="p_context"> static inline int current_is_kswapd(void)</span>
  */
 
 /*
<span class="p_add">+ * Un-addressable device memory support</span>
<span class="p_add">+ */</span>
<span class="p_add">+#ifdef CONFIG_DEVICE_UNADDRESSABLE</span>
<span class="p_add">+#define SWP_DEVICE_NUM 2</span>
<span class="p_add">+#define SWP_DEVICE_WRITE (MAX_SWAPFILES + SWP_HWPOISON_NUM + SWP_MIGRATION_NUM)</span>
<span class="p_add">+#define SWP_DEVICE (MAX_SWAPFILES + SWP_HWPOISON_NUM + SWP_MIGRATION_NUM + 1)</span>
<span class="p_add">+#else</span>
<span class="p_add">+#define SWP_DEVICE_NUM 0</span>
<span class="p_add">+#endif</span>
<span class="p_add">+</span>
<span class="p_add">+/*</span>
  * NUMA node memory migration support
  */
 #ifdef CONFIG_MIGRATION
<span class="p_chunk">@@ -71,7 +82,8 @@</span> <span class="p_context"> static inline int current_is_kswapd(void)</span>
 #endif
 
 #define MAX_SWAPFILES \
<span class="p_del">-	((1 &lt;&lt; MAX_SWAPFILES_SHIFT) - SWP_MIGRATION_NUM - SWP_HWPOISON_NUM)</span>
<span class="p_add">+	((1 &lt;&lt; MAX_SWAPFILES_SHIFT) - SWP_DEVICE_NUM - \</span>
<span class="p_add">+	SWP_MIGRATION_NUM - SWP_HWPOISON_NUM)</span>
 
 /*
  * Magic header for a swap area. The first part of the union is
<span class="p_chunk">@@ -442,8 +454,8 @@</span> <span class="p_context"> static inline void show_swap_cache_info(void)</span>
 {
 }
 
<span class="p_del">-#define free_swap_and_cache(swp)	is_migration_entry(swp)</span>
<span class="p_del">-#define swapcache_prepare(swp)		is_migration_entry(swp)</span>
<span class="p_add">+#define free_swap_and_cache(e) (is_migration_entry(e) || is_device_entry(e))</span>
<span class="p_add">+#define swapcache_prepare(e) (is_migration_entry(e) || is_device_entry(e))</span>
 
 static inline int add_swap_count_continuation(swp_entry_t swp, gfp_t gfp_mask)
 {
<span class="p_header">diff --git a/include/linux/swapops.h b/include/linux/swapops.h</span>
<span class="p_header">index 5c3a5f3..d1aa425 100644</span>
<span class="p_header">--- a/include/linux/swapops.h</span>
<span class="p_header">+++ b/include/linux/swapops.h</span>
<span class="p_chunk">@@ -100,6 +100,73 @@</span> <span class="p_context"> static inline void *swp_to_radix_entry(swp_entry_t entry)</span>
 	return (void *)(value | RADIX_TREE_EXCEPTIONAL_ENTRY);
 }
 
<span class="p_add">+#ifdef CONFIG_DEVICE_UNADDRESSABLE</span>
<span class="p_add">+static inline swp_entry_t make_device_entry(struct page *page, bool write)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return swp_entry(write?SWP_DEVICE_WRITE:SWP_DEVICE, page_to_pfn(page));</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline bool is_device_entry(swp_entry_t entry)</span>
<span class="p_add">+{</span>
<span class="p_add">+	int type = swp_type(entry);</span>
<span class="p_add">+	return type == SWP_DEVICE || type == SWP_DEVICE_WRITE;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline void make_device_entry_read(swp_entry_t *entry)</span>
<span class="p_add">+{</span>
<span class="p_add">+	*entry = swp_entry(SWP_DEVICE, swp_offset(*entry));</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline bool is_write_device_entry(swp_entry_t entry)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return unlikely(swp_type(entry) == SWP_DEVICE_WRITE);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline struct page *device_entry_to_page(swp_entry_t entry)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return pfn_to_page(swp_offset(entry));</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+int device_entry_fault(struct vm_area_struct *vma,</span>
<span class="p_add">+		       unsigned long addr,</span>
<span class="p_add">+		       swp_entry_t entry,</span>
<span class="p_add">+		       unsigned flags,</span>
<span class="p_add">+		       pmd_t *pmdp);</span>
<span class="p_add">+#else /* CONFIG_DEVICE_UNADDRESSABLE */</span>
<span class="p_add">+static inline swp_entry_t make_device_entry(struct page *page, bool write)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return swp_entry(0, 0);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline void make_device_entry_read(swp_entry_t *entry)</span>
<span class="p_add">+{</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline bool is_device_entry(swp_entry_t entry)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return false;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline bool is_write_device_entry(swp_entry_t entry)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return false;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline struct page *device_entry_to_page(swp_entry_t entry)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return NULL;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline int device_entry_fault(struct vm_area_struct *vma,</span>
<span class="p_add">+				     unsigned long addr,</span>
<span class="p_add">+				     swp_entry_t entry,</span>
<span class="p_add">+				     unsigned flags,</span>
<span class="p_add">+				     pmd_t *pmdp)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return VM_FAULT_SIGBUS;</span>
<span class="p_add">+}</span>
<span class="p_add">+#endif /* CONFIG_DEVICE_UNADDRESSABLE */</span>
<span class="p_add">+</span>
 #ifdef CONFIG_MIGRATION
 static inline swp_entry_t make_migration_entry(struct page *page, int write)
 {
<span class="p_header">diff --git a/kernel/memremap.c b/kernel/memremap.c</span>
<span class="p_header">index cf83928..0670015 100644</span>
<span class="p_header">--- a/kernel/memremap.c</span>
<span class="p_header">+++ b/kernel/memremap.c</span>
<span class="p_chunk">@@ -18,6 +18,8 @@</span> <span class="p_context"></span>
 #include &lt;linux/io.h&gt;
 #include &lt;linux/mm.h&gt;
 #include &lt;linux/memory_hotplug.h&gt;
<span class="p_add">+#include &lt;linux/swap.h&gt;</span>
<span class="p_add">+#include &lt;linux/swapops.h&gt;</span>
 
 #ifndef ioremap_cache
 /* temporary while we convert existing ioremap_cache users to memremap */
<span class="p_chunk">@@ -200,6 +202,18 @@</span> <span class="p_context"> void put_zone_device_page(struct page *page)</span>
 }
 EXPORT_SYMBOL(put_zone_device_page);
 
<span class="p_add">+int device_entry_fault(struct vm_area_struct *vma,</span>
<span class="p_add">+		       unsigned long addr,</span>
<span class="p_add">+		       swp_entry_t entry,</span>
<span class="p_add">+		       unsigned flags,</span>
<span class="p_add">+		       pmd_t *pmdp)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct page *page = device_entry_to_page(entry);</span>
<span class="p_add">+</span>
<span class="p_add">+	return page-&gt;pgmap-&gt;fault(vma, addr, page, flags, pmdp);</span>
<span class="p_add">+}</span>
<span class="p_add">+EXPORT_SYMBOL(device_entry_fault);</span>
<span class="p_add">+</span>
 static void pgmap_radix_release(struct resource *res)
 {
 	resource_size_t key, align_start, align_size, align_end;
<span class="p_header">diff --git a/mm/Kconfig b/mm/Kconfig</span>
<span class="p_header">index be0ee11..0a21411 100644</span>
<span class="p_header">--- a/mm/Kconfig</span>
<span class="p_header">+++ b/mm/Kconfig</span>
<span class="p_chunk">@@ -704,6 +704,18 @@</span> <span class="p_context"> config ZONE_DEVICE</span>
 
 	  If FS_DAX is enabled, then say Y.
 
<span class="p_add">+config DEVICE_UNADDRESSABLE</span>
<span class="p_add">+	bool &quot;Un-addressable device memory (GPU memory, ...)&quot;</span>
<span class="p_add">+	depends on ZONE_DEVICE</span>
<span class="p_add">+</span>
<span class="p_add">+	help</span>
<span class="p_add">+	  Allow to create struct page for un-addressable device memory</span>
<span class="p_add">+	  ie memory that is only accessible by the device (or group of</span>
<span class="p_add">+	  devices).</span>
<span class="p_add">+</span>
<span class="p_add">+	  This allow to migrate chunk of process memory to device memory</span>
<span class="p_add">+	  while that memory is use by the device.</span>
<span class="p_add">+</span>
 config FRAME_VECTOR
 	bool
 
<span class="p_header">diff --git a/mm/memory.c b/mm/memory.c</span>
<span class="p_header">index 15f2908..a83d690 100644</span>
<span class="p_header">--- a/mm/memory.c</span>
<span class="p_header">+++ b/mm/memory.c</span>
<span class="p_chunk">@@ -889,6 +889,21 @@</span> <span class="p_context"> copy_one_pte(struct mm_struct *dst_mm, struct mm_struct *src_mm,</span>
 					pte = pte_swp_mksoft_dirty(pte);
 				set_pte_at(src_mm, addr, src_pte, pte);
 			}
<span class="p_add">+		} else if (is_device_entry(entry)) {</span>
<span class="p_add">+			page = device_entry_to_page(entry);</span>
<span class="p_add">+</span>
<span class="p_add">+			get_page(page);</span>
<span class="p_add">+			rss[mm_counter(page)]++;</span>
<span class="p_add">+			page_dup_rmap(page, false);</span>
<span class="p_add">+</span>
<span class="p_add">+			if (is_write_device_entry(entry) &amp;&amp;</span>
<span class="p_add">+			    is_cow_mapping(vm_flags)) {</span>
<span class="p_add">+				make_device_entry_read(&amp;entry);</span>
<span class="p_add">+				pte = swp_entry_to_pte(entry);</span>
<span class="p_add">+				if (pte_swp_soft_dirty(*src_pte))</span>
<span class="p_add">+					pte = pte_swp_mksoft_dirty(pte);</span>
<span class="p_add">+				set_pte_at(src_mm, addr, src_pte, pte);</span>
<span class="p_add">+			}</span>
 		}
 		goto out_set_pte;
 	}
<span class="p_chunk">@@ -1191,6 +1206,12 @@</span> <span class="p_context"> again:</span>
 
 			page = migration_entry_to_page(entry);
 			rss[mm_counter(page)]--;
<span class="p_add">+		} else if (is_device_entry(entry)) {</span>
<span class="p_add">+			struct page *page = device_entry_to_page(entry);</span>
<span class="p_add">+			rss[mm_counter(page)]--;</span>
<span class="p_add">+</span>
<span class="p_add">+			page_remove_rmap(page, false);</span>
<span class="p_add">+			put_page(page);</span>
 		}
 		if (unlikely(!free_swap_and_cache(entry)))
 			print_bad_pte(vma, addr, ptent, NULL);
<span class="p_chunk">@@ -2536,6 +2557,9 @@</span> <span class="p_context"> int do_swap_page(struct fault_env *fe, pte_t orig_pte)</span>
 	if (unlikely(non_swap_entry(entry))) {
 		if (is_migration_entry(entry)) {
 			migration_entry_wait(vma-&gt;vm_mm, fe-&gt;pmd, fe-&gt;address);
<span class="p_add">+		} else if (is_device_entry(entry)) {</span>
<span class="p_add">+			ret = device_entry_fault(vma, fe-&gt;address, entry,</span>
<span class="p_add">+						 fe-&gt;flags, fe-&gt;pmd);</span>
 		} else if (is_hwpoison_entry(entry)) {
 			ret = VM_FAULT_HWPOISON;
 		} else {
<span class="p_header">diff --git a/mm/mprotect.c b/mm/mprotect.c</span>
<span class="p_header">index 1bc1eb3..70aff3a 100644</span>
<span class="p_header">--- a/mm/mprotect.c</span>
<span class="p_header">+++ b/mm/mprotect.c</span>
<span class="p_chunk">@@ -139,6 +139,18 @@</span> <span class="p_context"> static unsigned long change_pte_range(struct vm_area_struct *vma, pmd_t *pmd,</span>
 
 				pages++;
 			}
<span class="p_add">+</span>
<span class="p_add">+			if (is_write_device_entry(entry)) {</span>
<span class="p_add">+				pte_t newpte;</span>
<span class="p_add">+</span>
<span class="p_add">+				make_device_entry_read(&amp;entry);</span>
<span class="p_add">+				newpte = swp_entry_to_pte(entry);</span>
<span class="p_add">+				if (pte_swp_soft_dirty(oldpte))</span>
<span class="p_add">+					newpte = pte_swp_mksoft_dirty(newpte);</span>
<span class="p_add">+				set_pte_at(mm, addr, pte, newpte);</span>
<span class="p_add">+</span>
<span class="p_add">+				pages++;</span>
<span class="p_add">+			}</span>
 		}
 	} while (pte++, addr += PAGE_SIZE, addr != end);
 	arch_leave_lazy_mmu_mode();

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



