
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>[v5,09/10] x86/hyper-v: support extended CPU ranges for TLB flush hypercalls - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    [v5,09/10] x86/hyper-v: support extended CPU ranges for TLB flush hypercalls</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=99981">Vitaly Kuznetsov</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>May 30, 2017, 11:34 a.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;20170530113424.15687-10-vkuznets@redhat.com&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/9754361/mbox/"
   >mbox</a>
|
   <a href="/patch/9754361/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/9754361/">/patch/9754361/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
	[172.30.200.125])
	by pdx-korg-patchwork.web.codeaurora.org (Postfix) with ESMTP id
	AF00D602F0 for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Tue, 30 May 2017 11:35:32 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id A19A826B39
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Tue, 30 May 2017 11:35:32 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id 9643D27F7F; Tue, 30 May 2017 11:35:32 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-6.9 required=2.0 tests=BAYES_00,RCVD_IN_DNSWL_HI
	autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 016CD26B39
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Tue, 30 May 2017 11:35:32 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1751704AbdE3LfN (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Tue, 30 May 2017 07:35:13 -0400
Received: from mx1.redhat.com ([209.132.183.28]:45304 &quot;EHLO mx1.redhat.com&quot;
	rhost-flags-OK-OK-OK-OK) by vger.kernel.org with ESMTP
	id S1751668AbdE3LfH (ORCPT &lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Tue, 30 May 2017 07:35:07 -0400
Received: from smtp.corp.redhat.com
	(int-mx01.intmail.prod.int.phx2.redhat.com [10.5.11.11])
	(using TLSv1.2 with cipher AECDH-AES256-SHA (256/256 bits))
	(No client certificate requested)
	by mx1.redhat.com (Postfix) with ESMTPS id 5E59D80F7D;
	Tue, 30 May 2017 11:34:56 +0000 (UTC)
DMARC-Filter: OpenDMARC Filter v1.3.2 mx1.redhat.com 5E59D80F7D
Authentication-Results: ext-mx03.extmail.prod.ext.phx2.redhat.com;
	dmarc=none (p=none dis=none) header.from=redhat.com
Authentication-Results: ext-mx03.extmail.prod.ext.phx2.redhat.com;
	spf=pass smtp.mailfrom=vkuznets@redhat.com
DKIM-Filter: OpenDKIM Filter v2.11.0 mx1.redhat.com 5E59D80F7D
Received: from vitty.brq.redhat.com (vitty.brq.redhat.com [10.34.26.3])
	by smtp.corp.redhat.com (Postfix) with ESMTP id 90D0D5C7A5;
	Tue, 30 May 2017 11:34:53 +0000 (UTC)
From: Vitaly Kuznetsov &lt;vkuznets@redhat.com&gt;
To: x86@kernel.org, devel@linuxdriverproject.org
Cc: linux-kernel@vger.kernel.org, &quot;K. Y. Srinivasan&quot; &lt;kys@microsoft.com&gt;,
	Haiyang Zhang &lt;haiyangz@microsoft.com&gt;,
	Stephen Hemminger &lt;sthemmin@microsoft.com&gt;,
	Thomas Gleixner &lt;tglx@linutronix.de&gt;, Ingo Molnar &lt;mingo@redhat.com&gt;,
	&quot;H. Peter Anvin&quot; &lt;hpa@zytor.com&gt;, Steven Rostedt &lt;rostedt@goodmis.org&gt;,
	Jork Loeser &lt;Jork.Loeser@microsoft.com&gt;,
	Simon Xiao &lt;sixiao@microsoft.com&gt;, Andy Lutomirski &lt;luto@kernel.org&gt;,
	Andy Shevchenko &lt;andy.shevchenko@gmail.com&gt;
Subject: [PATCH v5 09/10] x86/hyper-v: support extended CPU ranges for TLB
	flush hypercalls
Date: Tue, 30 May 2017 13:34:23 +0200
Message-Id: &lt;20170530113424.15687-10-vkuznets@redhat.com&gt;
In-Reply-To: &lt;20170530113424.15687-1-vkuznets@redhat.com&gt;
References: &lt;20170530113424.15687-1-vkuznets@redhat.com&gt;
X-Scanned-By: MIMEDefang 2.79 on 10.5.11.11
X-Greylist: Sender IP whitelisted, not delayed by milter-greylist-4.5.16
	(mx1.redhat.com [10.5.110.27]);
	Tue, 30 May 2017 11:34:56 +0000 (UTC)
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=99981">Vitaly Kuznetsov</a> - May 30, 2017, 11:34 a.m.</div>
<pre class="content">
Hyper-V hosts may support more than 64 vCPUs, we need to use
HVCALL_FLUSH_VIRTUAL_ADDRESS_SPACE_EX/LIST_EX hypercalls in this
case.
<span class="signed-off-by">
Signed-off-by: Vitaly Kuznetsov &lt;vkuznets@redhat.com&gt;</span>
<span class="acked-by">Acked-by: K. Y. Srinivasan &lt;kys@microsoft.com&gt;</span>
---
Changes since v4:
- Use __set_bit(), minor code style changes [Andy Shevchenko]
---
 arch/x86/hyperv/mmu.c              | 150 ++++++++++++++++++++++++++++++++++++-
 arch/x86/include/uapi/asm/hyperv.h |  10 +++
 2 files changed, 158 insertions(+), 2 deletions(-)
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=3211">Andy Shevchenko</a> - May 30, 2017, 5:02 p.m.</div>
<pre class="content">
On Tue, May 30, 2017 at 2:34 PM, Vitaly Kuznetsov &lt;vkuznets@redhat.com&gt; wrote:
<span class="quote">&gt; Hyper-V hosts may support more than 64 vCPUs, we need to use</span>
<span class="quote">&gt; HVCALL_FLUSH_VIRTUAL_ADDRESS_SPACE_EX/LIST_EX hypercalls in this</span>
<span class="quote">&gt; case.</span>
<span class="quote">
&gt; +/* HvFlushVirtualAddressSpaceEx, HvFlushVirtualAddressListEx hypercalls */</span>
<span class="quote">&gt; +struct hv_flush_pcpu_ex {</span>
<span class="quote">&gt; +       __u64 address_space;</span>
<span class="quote">&gt; +       __u64 flags;</span>
<span class="quote">&gt; +       struct {</span>
<span class="quote">&gt; +               __u64 format;</span>
<span class="quote">&gt; +               __u64 valid_bank_mask;</span>
<span class="quote">&gt; +               __u64 bank_contents[];</span>
<span class="quote">&gt; +       } hv_vp_set;</span>
<span class="quote">&gt; +       __u64 gva_list[];</span>
<span class="quote">&gt; +};</span>

Same question about use of uXX vs __uXX types.
<span class="quote">
&gt; +static void hyperv_flush_tlb_others_ex(const struct cpumask *cpus,</span>
<span class="quote">&gt; +                                      struct mm_struct *mm,</span>
<span class="quote">&gt; +                                      unsigned long start,</span>
<span class="quote">&gt; +                                      unsigned long end)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +       struct hv_flush_pcpu_ex *flush;</span>
<span class="quote">&gt; +       unsigned long cur, flags;</span>
<span class="quote">&gt; +       u64 status = U64_MAX;</span>
<span class="quote">&gt; +       int nr_bank = 0, max_gvas, gva_n;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +       if (!pcpu_flush_ex || !hv_hypercall_pg)</span>
<span class="quote">&gt; +               goto do_native;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +       if (cpumask_empty(cpus))</span>
<span class="quote">&gt; +               return;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +       local_irq_save(flags);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +       flush = this_cpu_ptr(pcpu_flush_ex);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +       if (mm) {</span>
<span class="quote">&gt; +               flush-&gt;address_space = virt_to_phys(mm-&gt;pgd);</span>

(u64), phys_addr_t is arch-dependent.
<span class="quote">
&gt; +               flush-&gt;flags = 0;</span>
<span class="quote">&gt; +       } else {</span>
<span class="quote">&gt; +               flush-&gt;address_space = 0;</span>
<span class="quote">&gt; +               flush-&gt;flags = HV_FLUSH_ALL_VIRTUAL_ADDRESS_SPACES;</span>
<span class="quote">&gt; +       }</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +       flush-&gt;hv_vp_set.valid_bank_mask = 0;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +       if (cpumask_equal(cpus, cpu_present_mask)) {</span>
<span class="quote">&gt; +               flush-&gt;hv_vp_set.format = HV_GENERIC_SET_ALL;</span>
<span class="quote">&gt; +               flush-&gt;flags |= HV_FLUSH_ALL_PROCESSORS;</span>
<span class="quote">&gt; +       } else {</span>
<span class="quote">&gt; +               flush-&gt;hv_vp_set.format = HV_GENERIC_SET_SPARCE_4K;</span>
<span class="quote">&gt; +               nr_bank = cpumask_to_vp_set(flush, cpus);</span>
<span class="quote">&gt; +       }</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +       /*</span>
<span class="quote">&gt; +        * We can flush not more than max_gvas with one hypercall. Flush the</span>
<span class="quote">&gt; +        * whole address space if we were asked to do more.</span>
<span class="quote">&gt; +        */</span>
<span class="quote">&gt; +       max_gvas = (PAGE_SIZE - sizeof(*flush) - nr_bank*8) / 8;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +       if (end == TLB_FLUSH_ALL) {</span>
<span class="quote">&gt; +               flush-&gt;flags |= HV_FLUSH_NON_GLOBAL_MAPPINGS_ONLY;</span>
<span class="quote">&gt; +               status = hv_do_rep_hypercall(</span>
<span class="quote">&gt; +                       HVCALL_FLUSH_VIRTUAL_ADDRESS_SPACE_EX,</span>
<span class="quote">&gt; +                       0, nr_bank + 2, flush, NULL);</span>
<span class="quote">&gt; +       } else if (end &amp;&amp; ((end - start)/HV_TLB_FLUSH_UNIT) &gt; max_gvas) {</span>
<span class="quote">&gt; +               status = hv_do_rep_hypercall(</span>
<span class="quote">&gt; +                       HVCALL_FLUSH_VIRTUAL_ADDRESS_SPACE_EX,</span>
<span class="quote">&gt; +                       0, nr_bank + 2, flush, NULL);</span>
<span class="quote">&gt; +       } else {</span>
<span class="quote">&gt; +               cur = start;</span>
<span class="quote">&gt; +               gva_n = nr_bank;</span>
<span class="quote">&gt; +               do {</span>
<span class="quote">&gt; +                       flush-&gt;gva_list[gva_n] = cur &amp; PAGE_MASK;</span>
<span class="quote">&gt; +                       /*</span>
<span class="quote">&gt; +                        * Lower 12 bits encode the number of additional</span>
<span class="quote">&gt; +                        * pages to flush (in addition to the &#39;cur&#39; page).</span>
<span class="quote">&gt; +                        */</span>
<span class="quote">&gt; +                       if (end &gt;= cur + HV_TLB_FLUSH_UNIT)</span>
<span class="quote">&gt; +                               flush-&gt;gva_list[gva_n] |= ~PAGE_MASK;</span>
<span class="quote">&gt; +                       else if (end &gt; cur)</span>
<span class="quote">&gt; +                               flush-&gt;gva_list[gva_n] |=</span>
<span class="quote">&gt; +                                       (end - cur - 1) &gt;&gt; PAGE_SHIFT;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +                       cur += HV_TLB_FLUSH_UNIT;</span>
<span class="quote">&gt; +                       ++gva_n;</span>

Same comments as per previous similar code.

Moreover, since it&#39;s similar, can it have some common code shared?
<span class="quote">
&gt; +</span>
<span class="quote">&gt; +               } while (cur &lt; end);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +               status = hv_do_rep_hypercall(</span>
<span class="quote">&gt; +                       HVCALL_FLUSH_VIRTUAL_ADDRESS_LIST_EX,</span>
<span class="quote">&gt; +                       gva_n, nr_bank + 2, flush, NULL);</span>
<span class="quote">&gt; +       }</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +       local_irq_restore(flags);</span>
<span class="quote">&gt; +</span>
<span class="quote">
&gt; +       if (!(status &amp; 0xffff))</span>

Magic.
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=173691">Jork Loeser</a> - May 30, 2017, 7:13 p.m.</div>
<pre class="content">
<span class="quote">&gt; -----Original Message-----</span>
<span class="quote">&gt; From: Vitaly Kuznetsov [mailto:vkuznets@redhat.com]</span>
<span class="quote">&gt; Sent: Tuesday, May 30, 2017 04:34</span>
<span class="quote">&gt; To: x86@kernel.org; devel@linuxdriverproject.org</span>
<span class="quote">&gt; Cc: linux-kernel@vger.kernel.org; KY Srinivasan &lt;kys@microsoft.com&gt;; Haiyang</span>
<span class="quote">&gt; Zhang &lt;haiyangz@microsoft.com&gt;; Stephen Hemminger</span>
<span class="quote">&gt; &lt;sthemmin@microsoft.com&gt;; Thomas Gleixner &lt;tglx@linutronix.de&gt;; Ingo</span>
<span class="quote">&gt; Molnar &lt;mingo@redhat.com&gt;; H. Peter Anvin &lt;hpa@zytor.com&gt;; Steven</span>
<span class="quote">&gt; Rostedt &lt;rostedt@goodmis.org&gt;; Jork Loeser &lt;Jork.Loeser@microsoft.com&gt;;</span>
<span class="quote">&gt; Simon Xiao &lt;sixiao@microsoft.com&gt;; Andy Lutomirski &lt;luto@kernel.org&gt;; Andy</span>
<span class="quote">&gt; Shevchenko &lt;andy.shevchenko@gmail.com&gt;</span>
<span class="quote">&gt; Subject: [PATCH v5 09/10] x86/hyper-v: support extended CPU ranges for TLB</span>
<span class="quote">&gt; flush hypercalls</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Hyper-V hosts may support more than 64 vCPUs, we need to use</span>
<span class="quote">&gt; HVCALL_FLUSH_VIRTUAL_ADDRESS_SPACE_EX/LIST_EX hypercalls in this case.</span>
<span class="quote">

&gt; +static inline int cpumask_to_vp_set(struct hv_flush_pcpu_ex *flush,</span>
<span class="quote">&gt; +				    const struct cpumask *cpus)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	int cpu, vcpu, vcpu_bank, vcpu_offset, cur_bank, nr_bank = 0;</span>
<span class="quote">&gt; +	bool has_cpus;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	/*</span>
<span class="quote">&gt; +	 * We can&#39;t be sure that translated vCPU numbers will always be</span>
<span class="quote">&gt; +	 * in ascending order, so iterate over all possible banks and</span>
<span class="quote">&gt; +	 * check all vCPUs in it instead.</span>
<span class="quote">&gt; +	 */</span>
<span class="quote">&gt; +	for (cur_bank = 0; cur_bank &lt; ms_hyperv.max_vp_index/64;</span>
<span class="quote">&gt; cur_bank++) {</span>
<span class="quote">&gt; +		has_cpus = false;</span>
<span class="quote">&gt; +		for_each_cpu(cpu, cpus) {</span>
<span class="quote">&gt; +			vcpu = hv_cpu_number_to_vp_number(cpu);</span>
<span class="quote">&gt; +			vcpu_bank = vcpu / 64;</span>
<span class="quote">&gt; +			vcpu_offset = vcpu % 64;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +			if (vcpu_bank != cur_bank)</span>
<span class="quote">&gt; +				continue;</span>
<span class="quote">&gt; +			__set_bit(vcpu_offset, (unsigned long *)</span>
<span class="quote">&gt; +				  &amp;flush-&gt;hv_vp_set.bank_contents[nr_bank]);</span>
<span class="quote">&gt; +			if (!has_cpus) {</span>
<span class="quote">&gt; +				__set_bit(vcpu_bank, (unsigned long *)</span>
<span class="quote">&gt; +					  &amp;flush-&gt;hv_vp_set.valid_bank_mask);</span>
<span class="quote">&gt; +				has_cpus = true;</span>
<span class="quote">&gt; +			}</span>
<span class="quote">&gt; +		}</span>
<span class="quote">&gt; +		if (has_cpus)</span>
<span class="quote">&gt; +			nr_bank++;</span>
<span class="quote">&gt; +	}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	return nr_bank;</span>
<span class="quote">&gt; +}</span>

Note that the HV_VP_SET may contain empty banks. As such, consider enabling all (5) bits in the valid_bank_mask, and a single for_each(cpu, cpus) pass - setting the bits as per hv_cpu_number_to_vp_number(cpu).

Regards,
Jork
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=99981">Vitaly Kuznetsov</a> - May 31, 2017, 3:06 p.m.</div>
<pre class="content">
Jork Loeser &lt;Jork.Loeser@microsoft.com&gt; writes:
<span class="quote">
&gt;&gt; -----Original Message-----</span>
<span class="quote">&gt;&gt; From: Vitaly Kuznetsov [mailto:vkuznets@redhat.com]</span>
<span class="quote">&gt;&gt; Sent: Tuesday, May 30, 2017 04:34</span>
<span class="quote">&gt;&gt; To: x86@kernel.org; devel@linuxdriverproject.org</span>
<span class="quote">&gt;&gt; Cc: linux-kernel@vger.kernel.org; KY Srinivasan &lt;kys@microsoft.com&gt;; Haiyang</span>
<span class="quote">&gt;&gt; Zhang &lt;haiyangz@microsoft.com&gt;; Stephen Hemminger</span>
<span class="quote">&gt;&gt; &lt;sthemmin@microsoft.com&gt;; Thomas Gleixner &lt;tglx@linutronix.de&gt;; Ingo</span>
<span class="quote">&gt;&gt; Molnar &lt;mingo@redhat.com&gt;; H. Peter Anvin &lt;hpa@zytor.com&gt;; Steven</span>
<span class="quote">&gt;&gt; Rostedt &lt;rostedt@goodmis.org&gt;; Jork Loeser &lt;Jork.Loeser@microsoft.com&gt;;</span>
<span class="quote">&gt;&gt; Simon Xiao &lt;sixiao@microsoft.com&gt;; Andy Lutomirski &lt;luto@kernel.org&gt;; Andy</span>
<span class="quote">&gt;&gt; Shevchenko &lt;andy.shevchenko@gmail.com&gt;</span>
<span class="quote">&gt;&gt; Subject: [PATCH v5 09/10] x86/hyper-v: support extended CPU ranges for TLB</span>
<span class="quote">&gt;&gt; flush hypercalls</span>
<span class="quote">&gt;&gt; </span>
<span class="quote">&gt;&gt; Hyper-V hosts may support more than 64 vCPUs, we need to use</span>
<span class="quote">&gt;&gt; HVCALL_FLUSH_VIRTUAL_ADDRESS_SPACE_EX/LIST_EX hypercalls in this case.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;&gt; +static inline int cpumask_to_vp_set(struct hv_flush_pcpu_ex *flush,</span>
<span class="quote">&gt;&gt; +				    const struct cpumask *cpus)</span>
<span class="quote">&gt;&gt; +{</span>
<span class="quote">&gt;&gt; +	int cpu, vcpu, vcpu_bank, vcpu_offset, cur_bank, nr_bank = 0;</span>
<span class="quote">&gt;&gt; +	bool has_cpus;</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +	/*</span>
<span class="quote">&gt;&gt; +	 * We can&#39;t be sure that translated vCPU numbers will always be</span>
<span class="quote">&gt;&gt; +	 * in ascending order, so iterate over all possible banks and</span>
<span class="quote">&gt;&gt; +	 * check all vCPUs in it instead.</span>
<span class="quote">&gt;&gt; +	 */</span>
<span class="quote">&gt;&gt; +	for (cur_bank = 0; cur_bank &lt; ms_hyperv.max_vp_index/64;</span>
<span class="quote">&gt;&gt; cur_bank++) {</span>
<span class="quote">&gt;&gt; +		has_cpus = false;</span>
<span class="quote">&gt;&gt; +		for_each_cpu(cpu, cpus) {</span>
<span class="quote">&gt;&gt; +			vcpu = hv_cpu_number_to_vp_number(cpu);</span>
<span class="quote">&gt;&gt; +			vcpu_bank = vcpu / 64;</span>
<span class="quote">&gt;&gt; +			vcpu_offset = vcpu % 64;</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +			if (vcpu_bank != cur_bank)</span>
<span class="quote">&gt;&gt; +				continue;</span>
<span class="quote">&gt;&gt; +			__set_bit(vcpu_offset, (unsigned long *)</span>
<span class="quote">&gt;&gt; +				  &amp;flush-&gt;hv_vp_set.bank_contents[nr_bank]);</span>
<span class="quote">&gt;&gt; +			if (!has_cpus) {</span>
<span class="quote">&gt;&gt; +				__set_bit(vcpu_bank, (unsigned long *)</span>
<span class="quote">&gt;&gt; +					  &amp;flush-&gt;hv_vp_set.valid_bank_mask);</span>
<span class="quote">&gt;&gt; +				has_cpus = true;</span>
<span class="quote">&gt;&gt; +			}</span>
<span class="quote">&gt;&gt; +		}</span>
<span class="quote">&gt;&gt; +		if (has_cpus)</span>
<span class="quote">&gt;&gt; +			nr_bank++;</span>
<span class="quote">&gt;&gt; +	}</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +	return nr_bank;</span>
<span class="quote">&gt;&gt; +}</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; Note that the HV_VP_SET may contain empty banks. As such, consider</span>
<span class="quote">&gt; enabling all (5) bits in the valid_bank_mask, and a single</span>
<span class="quote">&gt; for_each(cpu, cpus) pass - setting the bits as per</span>
<span class="quote">&gt; hv_cpu_number_to_vp_number(cpu).</span>
<span class="quote">&gt;</span>

Oh, I didn&#39;t know that! I&#39;ll switch to doing a single
pass. Unfortunately I have no Hyper-V setup with &gt; 64 vCPUs so I can&#39;t
really test if it works or not (I mean empty banks, *_EX hypercalls
work).
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/arch/x86/hyperv/mmu.c b/arch/x86/hyperv/mmu.c</span>
<span class="p_header">index 8ccd680..b08e7ca 100644</span>
<span class="p_header">--- a/arch/x86/hyperv/mmu.c</span>
<span class="p_header">+++ b/arch/x86/hyperv/mmu.c</span>
<span class="p_chunk">@@ -15,11 +15,60 @@</span> <span class="p_context"> struct hv_flush_pcpu {</span>
 	__u64 gva_list[];
 };
 
<span class="p_add">+/* HvFlushVirtualAddressSpaceEx, HvFlushVirtualAddressListEx hypercalls */</span>
<span class="p_add">+struct hv_flush_pcpu_ex {</span>
<span class="p_add">+	__u64 address_space;</span>
<span class="p_add">+	__u64 flags;</span>
<span class="p_add">+	struct {</span>
<span class="p_add">+		__u64 format;</span>
<span class="p_add">+		__u64 valid_bank_mask;</span>
<span class="p_add">+		__u64 bank_contents[];</span>
<span class="p_add">+	} hv_vp_set;</span>
<span class="p_add">+	__u64 gva_list[];</span>
<span class="p_add">+};</span>
<span class="p_add">+</span>
 /* Each gva in gva_list encodes up to 4096 pages to flush */
 #define HV_TLB_FLUSH_UNIT (PAGE_SIZE * PAGE_SIZE)
 
 static struct hv_flush_pcpu __percpu *pcpu_flush;
 
<span class="p_add">+static struct hv_flush_pcpu_ex __percpu *pcpu_flush_ex;</span>
<span class="p_add">+</span>
<span class="p_add">+static inline int cpumask_to_vp_set(struct hv_flush_pcpu_ex *flush,</span>
<span class="p_add">+				    const struct cpumask *cpus)</span>
<span class="p_add">+{</span>
<span class="p_add">+	int cpu, vcpu, vcpu_bank, vcpu_offset, cur_bank, nr_bank = 0;</span>
<span class="p_add">+	bool has_cpus;</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * We can&#39;t be sure that translated vCPU numbers will always be</span>
<span class="p_add">+	 * in ascending order, so iterate over all possible banks and</span>
<span class="p_add">+	 * check all vCPUs in it instead.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	for (cur_bank = 0; cur_bank &lt; ms_hyperv.max_vp_index/64; cur_bank++) {</span>
<span class="p_add">+		has_cpus = false;</span>
<span class="p_add">+		for_each_cpu(cpu, cpus) {</span>
<span class="p_add">+			vcpu = hv_cpu_number_to_vp_number(cpu);</span>
<span class="p_add">+			vcpu_bank = vcpu / 64;</span>
<span class="p_add">+			vcpu_offset = vcpu % 64;</span>
<span class="p_add">+</span>
<span class="p_add">+			if (vcpu_bank != cur_bank)</span>
<span class="p_add">+				continue;</span>
<span class="p_add">+			__set_bit(vcpu_offset, (unsigned long *)</span>
<span class="p_add">+				  &amp;flush-&gt;hv_vp_set.bank_contents[nr_bank]);</span>
<span class="p_add">+			if (!has_cpus) {</span>
<span class="p_add">+				__set_bit(vcpu_bank, (unsigned long *)</span>
<span class="p_add">+					  &amp;flush-&gt;hv_vp_set.valid_bank_mask);</span>
<span class="p_add">+				has_cpus = true;</span>
<span class="p_add">+			}</span>
<span class="p_add">+		}</span>
<span class="p_add">+		if (has_cpus)</span>
<span class="p_add">+			nr_bank++;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	return nr_bank;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static void hyperv_flush_tlb_others(const struct cpumask *cpus,
 				    struct mm_struct *mm, unsigned long start,
 				    unsigned long end)
<span class="p_chunk">@@ -106,16 +155,113 @@</span> <span class="p_context"> static void hyperv_flush_tlb_others(const struct cpumask *cpus,</span>
 	native_flush_tlb_others(cpus, mm, start, end);
 }
 
<span class="p_add">+static void hyperv_flush_tlb_others_ex(const struct cpumask *cpus,</span>
<span class="p_add">+				       struct mm_struct *mm,</span>
<span class="p_add">+				       unsigned long start,</span>
<span class="p_add">+				       unsigned long end)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct hv_flush_pcpu_ex *flush;</span>
<span class="p_add">+	unsigned long cur, flags;</span>
<span class="p_add">+	u64 status = U64_MAX;</span>
<span class="p_add">+	int nr_bank = 0, max_gvas, gva_n;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (!pcpu_flush_ex || !hv_hypercall_pg)</span>
<span class="p_add">+		goto do_native;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (cpumask_empty(cpus))</span>
<span class="p_add">+		return;</span>
<span class="p_add">+</span>
<span class="p_add">+	local_irq_save(flags);</span>
<span class="p_add">+</span>
<span class="p_add">+	flush = this_cpu_ptr(pcpu_flush_ex);</span>
<span class="p_add">+</span>
<span class="p_add">+	if (mm) {</span>
<span class="p_add">+		flush-&gt;address_space = virt_to_phys(mm-&gt;pgd);</span>
<span class="p_add">+		flush-&gt;flags = 0;</span>
<span class="p_add">+	} else {</span>
<span class="p_add">+		flush-&gt;address_space = 0;</span>
<span class="p_add">+		flush-&gt;flags = HV_FLUSH_ALL_VIRTUAL_ADDRESS_SPACES;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	flush-&gt;hv_vp_set.valid_bank_mask = 0;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (cpumask_equal(cpus, cpu_present_mask)) {</span>
<span class="p_add">+		flush-&gt;hv_vp_set.format = HV_GENERIC_SET_ALL;</span>
<span class="p_add">+		flush-&gt;flags |= HV_FLUSH_ALL_PROCESSORS;</span>
<span class="p_add">+	} else {</span>
<span class="p_add">+		flush-&gt;hv_vp_set.format = HV_GENERIC_SET_SPARCE_4K;</span>
<span class="p_add">+		nr_bank = cpumask_to_vp_set(flush, cpus);</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * We can flush not more than max_gvas with one hypercall. Flush the</span>
<span class="p_add">+	 * whole address space if we were asked to do more.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	max_gvas = (PAGE_SIZE - sizeof(*flush) - nr_bank*8) / 8;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (end == TLB_FLUSH_ALL) {</span>
<span class="p_add">+		flush-&gt;flags |= HV_FLUSH_NON_GLOBAL_MAPPINGS_ONLY;</span>
<span class="p_add">+		status = hv_do_rep_hypercall(</span>
<span class="p_add">+			HVCALL_FLUSH_VIRTUAL_ADDRESS_SPACE_EX,</span>
<span class="p_add">+			0, nr_bank + 2, flush, NULL);</span>
<span class="p_add">+	} else if (end &amp;&amp; ((end - start)/HV_TLB_FLUSH_UNIT) &gt; max_gvas) {</span>
<span class="p_add">+		status = hv_do_rep_hypercall(</span>
<span class="p_add">+			HVCALL_FLUSH_VIRTUAL_ADDRESS_SPACE_EX,</span>
<span class="p_add">+			0, nr_bank + 2, flush, NULL);</span>
<span class="p_add">+	} else {</span>
<span class="p_add">+		cur = start;</span>
<span class="p_add">+		gva_n = nr_bank;</span>
<span class="p_add">+		do {</span>
<span class="p_add">+			flush-&gt;gva_list[gva_n] = cur &amp; PAGE_MASK;</span>
<span class="p_add">+			/*</span>
<span class="p_add">+			 * Lower 12 bits encode the number of additional</span>
<span class="p_add">+			 * pages to flush (in addition to the &#39;cur&#39; page).</span>
<span class="p_add">+			 */</span>
<span class="p_add">+			if (end &gt;= cur + HV_TLB_FLUSH_UNIT)</span>
<span class="p_add">+				flush-&gt;gva_list[gva_n] |= ~PAGE_MASK;</span>
<span class="p_add">+			else if (end &gt; cur)</span>
<span class="p_add">+				flush-&gt;gva_list[gva_n] |=</span>
<span class="p_add">+					(end - cur - 1) &gt;&gt; PAGE_SHIFT;</span>
<span class="p_add">+</span>
<span class="p_add">+			cur += HV_TLB_FLUSH_UNIT;</span>
<span class="p_add">+			++gva_n;</span>
<span class="p_add">+</span>
<span class="p_add">+		} while (cur &lt; end);</span>
<span class="p_add">+</span>
<span class="p_add">+		status = hv_do_rep_hypercall(</span>
<span class="p_add">+			HVCALL_FLUSH_VIRTUAL_ADDRESS_LIST_EX,</span>
<span class="p_add">+			gva_n, nr_bank + 2, flush, NULL);</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	local_irq_restore(flags);</span>
<span class="p_add">+</span>
<span class="p_add">+	if (!(status &amp; 0xffff))</span>
<span class="p_add">+		return;</span>
<span class="p_add">+do_native:</span>
<span class="p_add">+	native_flush_tlb_others(cpus, mm, start, end);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 void hyperv_setup_mmu_ops(void)
 {
<span class="p_del">-	if (ms_hyperv.hints &amp; HV_X64_REMOTE_TLB_FLUSH_RECOMMENDED) {</span>
<span class="p_add">+	if (!(ms_hyperv.hints &amp; HV_X64_REMOTE_TLB_FLUSH_RECOMMENDED))</span>
<span class="p_add">+		return;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (!(ms_hyperv.hints &amp; HV_X64_EX_PROCESSOR_MASKS_RECOMMENDED)) {</span>
 		pr_info(&quot;Hyper-V: Using hypercall for remote TLB flush\n&quot;);
 		pv_mmu_ops.flush_tlb_others = hyperv_flush_tlb_others;
<span class="p_add">+	} else {</span>
<span class="p_add">+		pr_info(&quot;Hyper-V: Using ext hypercall for remote TLB flush\n&quot;);</span>
<span class="p_add">+		pv_mmu_ops.flush_tlb_others = hyperv_flush_tlb_others_ex;</span>
 	}
 }
 
 void hyper_alloc_mmu(void)
 {
<span class="p_del">-	if (ms_hyperv.hints &amp; HV_X64_REMOTE_TLB_FLUSH_RECOMMENDED)</span>
<span class="p_add">+	if (!(ms_hyperv.hints &amp; HV_X64_REMOTE_TLB_FLUSH_RECOMMENDED))</span>
<span class="p_add">+		return;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (!(ms_hyperv.hints &amp; HV_X64_EX_PROCESSOR_MASKS_RECOMMENDED))</span>
 		pcpu_flush = __alloc_percpu(PAGE_SIZE, PAGE_SIZE);
<span class="p_add">+	else</span>
<span class="p_add">+		pcpu_flush_ex = __alloc_percpu(PAGE_SIZE, PAGE_SIZE);</span>
 }
<span class="p_header">diff --git a/arch/x86/include/uapi/asm/hyperv.h b/arch/x86/include/uapi/asm/hyperv.h</span>
<span class="p_header">index 38808f1..a177517 100644</span>
<span class="p_header">--- a/arch/x86/include/uapi/asm/hyperv.h</span>
<span class="p_header">+++ b/arch/x86/include/uapi/asm/hyperv.h</span>
<span class="p_chunk">@@ -152,6 +152,9 @@</span> <span class="p_context"></span>
  */
 #define HV_X64_DEPRECATING_AEOI_RECOMMENDED	(1 &lt;&lt; 9)
 
<span class="p_add">+/* Recommend using the newer ExProcessorMasks interface */</span>
<span class="p_add">+#define HV_X64_EX_PROCESSOR_MASKS_RECOMMENDED	(1 &lt;&lt; 11)</span>
<span class="p_add">+</span>
 /*
  * Crash notification flag.
  */
<span class="p_chunk">@@ -242,6 +245,8 @@</span> <span class="p_context"></span>
 #define HVCALL_FLUSH_VIRTUAL_ADDRESS_SPACE	0x0002
 #define HVCALL_FLUSH_VIRTUAL_ADDRESS_LIST	0x0003
 #define HVCALL_NOTIFY_LONG_SPIN_WAIT		0x0008
<span class="p_add">+#define HVCALL_FLUSH_VIRTUAL_ADDRESS_SPACE_EX  0x0013</span>
<span class="p_add">+#define HVCALL_FLUSH_VIRTUAL_ADDRESS_LIST_EX   0x0014</span>
 #define HVCALL_POST_MESSAGE			0x005c
 #define HVCALL_SIGNAL_EVENT			0x005d
 
<span class="p_chunk">@@ -263,6 +268,11 @@</span> <span class="p_context"></span>
 #define HV_FLUSH_NON_GLOBAL_MAPPINGS_ONLY	0x00000004
 #define HV_FLUSH_USE_EXTENDED_RANGE_FORMAT	0x00000008
 
<span class="p_add">+enum HV_GENERIC_SET_FORMAT {</span>
<span class="p_add">+	HV_GENERIC_SET_SPARCE_4K,</span>
<span class="p_add">+	HV_GENERIC_SET_ALL,</span>
<span class="p_add">+};</span>
<span class="p_add">+</span>
 /* hypercall status code */
 #define HV_STATUS_SUCCESS			0
 #define HV_STATUS_INVALID_HYPERCALL_CODE	2

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



