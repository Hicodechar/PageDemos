
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>[RFC,v2] dma-mapping: Use unsigned long for dma_attrs - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    [RFC,v2] dma-mapping: Use unsigned long for dma_attrs</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=72608">Krzysztof Kozlowski</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>May 30, 2016, 11:54 a.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;1464609246-6948-2-git-send-email-k.kozlowski@samsung.com&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/9141103/mbox/"
   >mbox</a>
|
   <a href="/patch/9141103/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/9141103/">/patch/9141103/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
	[172.30.200.125])
	by pdx-korg-patchwork.web.codeaurora.org (Postfix) with ESMTP id
	9C3C160754 for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Mon, 30 May 2016 11:55:58 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 82DF728066
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Mon, 30 May 2016 11:55:58 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id 7721D281C2; Mon, 30 May 2016 11:55:58 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-6.9 required=2.0 tests=BAYES_00,RCVD_IN_DNSWL_HI
	autolearn=unavailable version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id B948B28066
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Mon, 30 May 2016 11:55:55 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S933231AbcE3Lzu (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Mon, 30 May 2016 07:55:50 -0400
Received: from mailout3.w1.samsung.com ([210.118.77.13]:32499 &quot;EHLO
	mailout3.w1.samsung.com&quot; rhost-flags-OK-OK-OK-OK) by vger.kernel.org
	with ESMTP id S932899AbcE3Lzr (ORCPT
	&lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Mon, 30 May 2016 07:55:47 -0400
Received: from eucpsbgm2.samsung.com (unknown [203.254.199.245])
	by mailout3.w1.samsung.com
	(Oracle Communications Messaging Server 7.0.5.31.0 64bit (built May 5
	2014))
	with ESMTP id &lt;0O7Z00A27NSUWW10@mailout3.w1.samsung.com&gt;; Mon,
	30 May 2016 12:55:43 +0100 (BST)
X-AuditID: cbfec7f5-f792a6d000001302-24-574c2a3e072f
Received: from eusync1.samsung.com ( [203.254.199.211])
	by eucpsbgm2.samsung.com (EUCPMTA) with SMTP id CB.A5.04866.E3A2C475;
	Mon, 30 May 2016 12:55:42 +0100 (BST)
Received: from AMDC2174.DIGITAL.local ([106.120.53.17])
	by eusync1.samsung.com (Oracle Communications Messaging Server
	7.0.5.31.0 64bit (built May  5 2014))
	with ESMTPA id &lt;0O7Z00GJFNQECGB0@eusync1.samsung.com&gt;; Mon,
	30 May 2016 12:55:42 +0100 (BST)
From: Krzysztof Kozlowski &lt;k.kozlowski@samsung.com&gt;
To: Russell King &lt;linux@armlinux.org.uk&gt;,
	Catalin Marinas &lt;catalin.marinas@arm.com&gt;,
	Will Deacon &lt;will.deacon@arm.com&gt;, Joerg Roedel &lt;joro@8bytes.org&gt;,
	Andrew Morton &lt;akpm@linux-foundation.org&gt;,
	Marek Szyprowski &lt;m.szyprowski@samsung.com&gt;,
	Michal Hocko &lt;mhocko@suse.com&gt;, Mel Gorman &lt;mgorman@techsingularity.net&gt;,
	Arnd Bergmann &lt;arnd@arndb.de&gt;,
	Andy Lutomirski &lt;luto@kernel.org&gt;, linux-doc@vger.kernel.org,
	linux-kernel@vger.kernel.org, linux-arm-kernel@lists.infradead.org,
	xen-devel@lists.xenproject.org, dri-devel@lists.freedesktop.org,
	linux-samsung-soc@vger.kernel.org, iommu@lists.linux-foundation.org
Cc: hch@infradead.org, sstabellini@kernel.org,
	Krzysztof Kozlowski &lt;k.kozlowski@samsung.com&gt;,
	Bartlomiej Zolnierkiewicz &lt;b.zolnierkie@samsung.com&gt;
Subject: [RFC v2] dma-mapping: Use unsigned long for dma_attrs
Date: Mon, 30 May 2016 13:54:06 +0200
Message-id: &lt;1464609246-6948-2-git-send-email-k.kozlowski@samsung.com&gt;
X-Mailer: git-send-email 1.9.1
In-reply-to: &lt;1464609246-6948-1-git-send-email-k.kozlowski@samsung.com&gt;
References: &lt;1464609246-6948-1-git-send-email-k.kozlowski@samsung.com&gt;
X-Brightmail-Tracker: H4sIAAAAAAAAA+NgFmpjkeLIzCtJLcpLzFFi42I5/e/4ZV07LZ9wg9ZVShZz1q9hs/g76Ri7
	xcYZ61kt3i/rYbS48vU9m8XpCYuYLBbst7bonL2B3eL1C0OLTY+vsVosbFvCYnF51xw2ixnn
	9zFZHJq6l9Hi/K61rBZrj9xlt9ixFCh2v8/BYvW6eIuXH0+wWHzfMpnJQdTjycF5TB5r5q1h
	9Lh87SKzx+9fkxg9Nq/Q8ti0qpPN48SM3ywe97uPM3lsXlLvMfnGckaPwx+usHj0bVnF6LF+
	y1UWj62/7Dw+b5IL4I/isklJzcksSy3St0vgytjfs4il4NVT5ooZ116yNTAuaGfuYuTkkBAw
	kVjw7AArhC0mceHeerYuRi4OIYGljBK3L7azQDiNTBIdn/6DdbAJGEtsXr4ErEpE4D2LxNf1
	N8HamQWmMUrs3SAOYgsL2El8OfuDCcRmEVCVWHr8DSOIzSvgJnG0ez0LxDo5iZPHJgP1snNw
	CrhLvJUDiQoBVWz9c419AiPvAkaGVYyiqaXJBcVJ6blGesWJucWleel6yfm5mxghsfN1B+PS
	Y1aHGAU4GJV4eAs0vcOFWBPLiitzDzFKcDArifDuVPMJF+JNSaysSi3Kjy8qzUktPsQozcGi
	JM47c9f7ECGB9MSS1OzU1ILUIpgsEwenVAPjbb+Sh/PXWM+IDXKapFWp8+pBQenqA2UZN7Zy
	Lt5hs7xf9+jl/m9Kb7I6WQIW7RZzVkn/3tB8NTyVi/3airbeJS2eBj7chvV88X2O54/P1fQ6
	vIsvr8Xwr+ohuxkv1XsmyU0xPpkcsNtZUbNSf43JhM9/py/SrZ313rYwdwl76xod/kNSX+8q
	sRRnJBpqMRcVJwIATgxpUpkCAAA=
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=72608">Krzysztof Kozlowski</a> - May 30, 2016, 11:54 a.m.</div>
<pre class="content">
The dma-mapping core and the implementations do not change the
DMA attributes passed by pointer.  Thus the pointer can point to const
data.  However the attributes do not have to be a bitfield. Instead
unsigned long will do fine:

1. This is just simpler.  Both in terms of reading the code and setting
   attributes.  Instead of initializing local attributes on the stack and
   passing pointer to it to dma_set_attr(), just set the bits.

2. It brings safeness and checking for const correctness because the
   attributes are passed by value.

Please have in mind that this is RFC, not finished yet.  Only ARM and
ARM64 are fixed (and not everywhere).
However other API users also have to be converted which is quite
intrusive.  I would rather avoid it until the overall approach is
accepted.
<span class="signed-off-by">
Signed-off-by: Krzysztof Kozlowski &lt;k.kozlowski@samsung.com&gt;</span>
---
 Documentation/DMA-API.txt                 |   2 +-
 Documentation/DMA-attributes.txt          |   2 +-
 arch/arm/include/asm/dma-mapping.h        |  13 ++--
 arch/arm/include/asm/xen/page-coherent.h  |  16 ++---
 arch/arm/mm/dma-mapping.c                 |  82 +++++++++++------------
 arch/arm/xen/mm.c                         |   4 +-
 arch/arm64/mm/dma-mapping.c               |  57 ++++++++--------
 drivers/gpu/drm/exynos/exynos_drm_fbdev.c |   2 +-
 drivers/gpu/drm/exynos/exynos_drm_g2d.c   |   1 -
 drivers/gpu/drm/exynos/exynos_drm_gem.c   |  20 +++---
 drivers/gpu/drm/exynos/exynos_drm_gem.h   |   2 +-
 drivers/iommu/dma-iommu.c                 |   6 +-
 drivers/xen/swiotlb-xen.c                 |  14 ++--
 include/linux/dma-attrs.h                 |  71 --------------------
 include/linux/dma-iommu.h                 |   6 +-
 include/linux/dma-mapping.h               | 105 +++++++++++++++++-------------
 include/linux/swiotlb.h                   |  10 +--
 include/xen/swiotlb-xen.h                 |  12 ++--
 lib/dma-noop.c                            |   9 +--
 lib/swiotlb.c                             |  13 ++--
 20 files changed, 195 insertions(+), 252 deletions(-)
 delete mode 100644 include/linux/dma-attrs.h
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=101">Christoph Hellwig</a> - May 31, 2016, 5:04 p.m.</div>
<pre class="content">
On Mon, May 30, 2016 at 01:54:06PM +0200, Krzysztof Kozlowski wrote:
<span class="quote">&gt; The dma-mapping core and the implementations do not change the</span>
<span class="quote">&gt; DMA attributes passed by pointer.  Thus the pointer can point to const</span>
<span class="quote">&gt; data.  However the attributes do not have to be a bitfield. Instead</span>
<span class="quote">&gt; unsigned long will do fine:</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; 1. This is just simpler.  Both in terms of reading the code and setting</span>
<span class="quote">&gt;    attributes.  Instead of initializing local attributes on the stack and</span>
<span class="quote">&gt;    passing pointer to it to dma_set_attr(), just set the bits.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; 2. It brings safeness and checking for const correctness because the</span>
<span class="quote">&gt;    attributes are passed by value.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Please have in mind that this is RFC, not finished yet.  Only ARM and</span>
<span class="quote">&gt; ARM64 are fixed (and not everywhere).</span>
<span class="quote">&gt; However other API users also have to be converted which is quite</span>
<span class="quote">&gt; intrusive.  I would rather avoid it until the overall approach is</span>
<span class="quote">&gt; accepted.</span>

This looks great!  Please continue doing the full conversion.
<span class="quote">
&gt; +/**</span>
<span class="quote">&gt; + * List of possible attributes associated with a DMA mapping. The semantics</span>
<span class="quote">&gt; + * of each attribute should be defined in Documentation/DMA-attributes.txt.</span>
<span class="quote">&gt; + */</span>
<span class="quote">&gt; +#define DMA_ATTR_WRITE_BARRIER		BIT(1)</span>
<span class="quote">&gt; +#define DMA_ATTR_WEAK_ORDERING		BIT(2)</span>
<span class="quote">&gt; +#define DMA_ATTR_WRITE_COMBINE		BIT(3)</span>
<span class="quote">&gt; +#define DMA_ATTR_NON_CONSISTENT		BIT(4)</span>
<span class="quote">&gt; +#define DMA_ATTR_NO_KERNEL_MAPPING	BIT(5)</span>
<span class="quote">&gt; +#define DMA_ATTR_SKIP_CPU_SYNC		BIT(6)</span>
<span class="quote">&gt; +#define DMA_ATTR_FORCE_CONTIGUOUS	BIT(7)</span>
<span class="quote">&gt; +#define DMA_ATTR_ALLOC_SINGLE_PAGES	BIT(8)</span>

No really for this patch, but I would much prefer to document them next
to the code in the long run.  Also I really think these BIT() macros
are a distraction compared to the (1 &lt;&lt; N) notation.
<span class="quote">
&gt; +/**</span>
<span class="quote">&gt; + * dma_get_attr - check for a specific attribute</span>
<span class="quote">&gt; + * @attr: attribute to look for</span>
<span class="quote">&gt; + * @attrs: attributes to check within</span>
<span class="quote">&gt; + */</span>
<span class="quote">&gt; +static inline bool dma_get_attr(unsigned long attr, unsigned long attrs)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	return !!(attr &amp; attrs);</span>
<span class="quote">&gt; +}</span>

I&#39;d just kill this helper, much easier to simply open code it in the
caller.
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=3407">Konrad Rzeszutek Wilk</a> - May 31, 2016, 6:15 p.m.</div>
<pre class="content">
On Mon, May 30, 2016 at 01:54:06PM +0200, Krzysztof Kozlowski wrote:
<span class="quote">&gt; The dma-mapping core and the implementations do not change the</span>
<span class="quote">&gt; DMA attributes passed by pointer.  Thus the pointer can point to const</span>
<span class="quote">&gt; data.  However the attributes do not have to be a bitfield. Instead</span>
<span class="quote">&gt; unsigned long will do fine:</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; 1. This is just simpler.  Both in terms of reading the code and setting</span>
<span class="quote">&gt;    attributes.  Instead of initializing local attributes on the stack and</span>
<span class="quote">&gt;    passing pointer to it to dma_set_attr(), just set the bits.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; 2. It brings safeness and checking for const correctness because the</span>
<span class="quote">&gt;    attributes are passed by value.</span>


.. why not go the next step a do an enum? Perhaps that should be mentioned
as part of the description?

Thanks.
<span class="quote">&gt; </span>
<span class="quote">&gt; Please have in mind that this is RFC, not finished yet.  Only ARM and</span>
<span class="quote">&gt; ARM64 are fixed (and not everywhere).</span>
<span class="quote">&gt; However other API users also have to be converted which is quite</span>
<span class="quote">&gt; intrusive.  I would rather avoid it until the overall approach is</span>
<span class="quote">&gt; accepted.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Signed-off-by: Krzysztof Kozlowski &lt;k.kozlowski@samsung.com&gt;</span>
<span class="quote">&gt; ---</span>
<span class="quote">&gt;  Documentation/DMA-API.txt                 |   2 +-</span>
<span class="quote">&gt;  Documentation/DMA-attributes.txt          |   2 +-</span>
<span class="quote">&gt;  arch/arm/include/asm/dma-mapping.h        |  13 ++--</span>
<span class="quote">&gt;  arch/arm/include/asm/xen/page-coherent.h  |  16 ++---</span>
<span class="quote">&gt;  arch/arm/mm/dma-mapping.c                 |  82 +++++++++++------------</span>
<span class="quote">&gt;  arch/arm/xen/mm.c                         |   4 +-</span>
<span class="quote">&gt;  arch/arm64/mm/dma-mapping.c               |  57 ++++++++--------</span>
<span class="quote">&gt;  drivers/gpu/drm/exynos/exynos_drm_fbdev.c |   2 +-</span>
<span class="quote">&gt;  drivers/gpu/drm/exynos/exynos_drm_g2d.c   |   1 -</span>
<span class="quote">&gt;  drivers/gpu/drm/exynos/exynos_drm_gem.c   |  20 +++---</span>
<span class="quote">&gt;  drivers/gpu/drm/exynos/exynos_drm_gem.h   |   2 +-</span>
<span class="quote">&gt;  drivers/iommu/dma-iommu.c                 |   6 +-</span>
<span class="quote">&gt;  drivers/xen/swiotlb-xen.c                 |  14 ++--</span>
<span class="quote">&gt;  include/linux/dma-attrs.h                 |  71 --------------------</span>
<span class="quote">&gt;  include/linux/dma-iommu.h                 |   6 +-</span>
<span class="quote">&gt;  include/linux/dma-mapping.h               | 105 +++++++++++++++++-------------</span>
<span class="quote">&gt;  include/linux/swiotlb.h                   |  10 +--</span>
<span class="quote">&gt;  include/xen/swiotlb-xen.h                 |  12 ++--</span>
<span class="quote">&gt;  lib/dma-noop.c                            |   9 +--</span>
<span class="quote">&gt;  lib/swiotlb.c                             |  13 ++--</span>
<span class="quote">&gt;  20 files changed, 195 insertions(+), 252 deletions(-)</span>
<span class="quote">&gt;  delete mode 100644 include/linux/dma-attrs.h</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; diff --git a/Documentation/DMA-API.txt b/Documentation/DMA-API.txt</span>
<span class="quote">&gt; index 45ef3f279c3b..0b55cb7c5aaa 100644</span>
<span class="quote">&gt; --- a/Documentation/DMA-API.txt</span>
<span class="quote">&gt; +++ b/Documentation/DMA-API.txt</span>
<span class="quote">&gt; @@ -391,7 +391,7 @@ without the _attrs suffixes, except that they pass an optional</span>
<span class="quote">&gt;  struct dma_attrs*.</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  struct dma_attrs encapsulates a set of &quot;DMA attributes&quot;. For the</span>
<span class="quote">&gt; -definition of struct dma_attrs see linux/dma-attrs.h.</span>
<span class="quote">&gt; +definition of struct dma_attrs see linux/dma-mapping.h.</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  The interpretation of DMA attributes is architecture-specific, and</span>
<span class="quote">&gt;  each attribute should be documented in Documentation/DMA-attributes.txt.</span>
<span class="quote">&gt; diff --git a/Documentation/DMA-attributes.txt b/Documentation/DMA-attributes.txt</span>
<span class="quote">&gt; index e8cf9cf873b3..2d455a5cf671 100644</span>
<span class="quote">&gt; --- a/Documentation/DMA-attributes.txt</span>
<span class="quote">&gt; +++ b/Documentation/DMA-attributes.txt</span>
<span class="quote">&gt; @@ -2,7 +2,7 @@</span>
<span class="quote">&gt;  			==============</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  This document describes the semantics of the DMA attributes that are</span>
<span class="quote">&gt; -defined in linux/dma-attrs.h.</span>
<span class="quote">&gt; +defined in linux/dma-mapping.h.</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  DMA_ATTR_WRITE_BARRIER</span>
<span class="quote">&gt;  ----------------------</span>
<span class="quote">&gt; diff --git a/arch/arm/include/asm/dma-mapping.h b/arch/arm/include/asm/dma-mapping.h</span>
<span class="quote">&gt; index a83570f10124..d009f7911ffc 100644</span>
<span class="quote">&gt; --- a/arch/arm/include/asm/dma-mapping.h</span>
<span class="quote">&gt; +++ b/arch/arm/include/asm/dma-mapping.h</span>
<span class="quote">&gt; @@ -5,7 +5,6 @@</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  #include &lt;linux/mm_types.h&gt;</span>
<span class="quote">&gt;  #include &lt;linux/scatterlist.h&gt;</span>
<span class="quote">&gt; -#include &lt;linux/dma-attrs.h&gt;</span>
<span class="quote">&gt;  #include &lt;linux/dma-debug.h&gt;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  #include &lt;asm/memory.h&gt;</span>
<span class="quote">&gt; @@ -174,7 +173,7 @@ static inline void dma_mark_clean(void *addr, size_t size) { }</span>
<span class="quote">&gt;   * to be the device-viewed address.</span>
<span class="quote">&gt;   */</span>
<span class="quote">&gt;  extern void *arm_dma_alloc(struct device *dev, size_t size, dma_addr_t *handle,</span>
<span class="quote">&gt; -			   gfp_t gfp, struct dma_attrs *attrs);</span>
<span class="quote">&gt; +			   gfp_t gfp, unsigned long attrs);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  /**</span>
<span class="quote">&gt;   * arm_dma_free - free memory allocated by arm_dma_alloc</span>
<span class="quote">&gt; @@ -191,7 +190,7 @@ extern void *arm_dma_alloc(struct device *dev, size_t size, dma_addr_t *handle,</span>
<span class="quote">&gt;   * during and after this call executing are illegal.</span>
<span class="quote">&gt;   */</span>
<span class="quote">&gt;  extern void arm_dma_free(struct device *dev, size_t size, void *cpu_addr,</span>
<span class="quote">&gt; -			 dma_addr_t handle, struct dma_attrs *attrs);</span>
<span class="quote">&gt; +			 dma_addr_t handle, unsigned long attrs);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  /**</span>
<span class="quote">&gt;   * arm_dma_mmap - map a coherent DMA allocation into user space</span>
<span class="quote">&gt; @@ -208,7 +207,7 @@ extern void arm_dma_free(struct device *dev, size_t size, void *cpu_addr,</span>
<span class="quote">&gt;   */</span>
<span class="quote">&gt;  extern int arm_dma_mmap(struct device *dev, struct vm_area_struct *vma,</span>
<span class="quote">&gt;  			void *cpu_addr, dma_addr_t dma_addr, size_t size,</span>
<span class="quote">&gt; -			struct dma_attrs *attrs);</span>
<span class="quote">&gt; +			unsigned long attrs);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  /*</span>
<span class="quote">&gt;   * This can be called during early boot to increase the size of the atomic</span>
<span class="quote">&gt; @@ -262,16 +261,16 @@ extern void dmabounce_unregister_dev(struct device *);</span>
<span class="quote">&gt;   * The scatter list versions of the above methods.</span>
<span class="quote">&gt;   */</span>
<span class="quote">&gt;  extern int arm_dma_map_sg(struct device *, struct scatterlist *, int,</span>
<span class="quote">&gt; -		enum dma_data_direction, struct dma_attrs *attrs);</span>
<span class="quote">&gt; +		enum dma_data_direction, unsigned long attrs);</span>
<span class="quote">&gt;  extern void arm_dma_unmap_sg(struct device *, struct scatterlist *, int,</span>
<span class="quote">&gt; -		enum dma_data_direction, struct dma_attrs *attrs);</span>
<span class="quote">&gt; +		enum dma_data_direction, unsigned long attrs);</span>
<span class="quote">&gt;  extern void arm_dma_sync_sg_for_cpu(struct device *, struct scatterlist *, int,</span>
<span class="quote">&gt;  		enum dma_data_direction);</span>
<span class="quote">&gt;  extern void arm_dma_sync_sg_for_device(struct device *, struct scatterlist *, int,</span>
<span class="quote">&gt;  		enum dma_data_direction);</span>
<span class="quote">&gt;  extern int arm_dma_get_sgtable(struct device *dev, struct sg_table *sgt,</span>
<span class="quote">&gt;  		void *cpu_addr, dma_addr_t dma_addr, size_t size,</span>
<span class="quote">&gt; -		struct dma_attrs *attrs);</span>
<span class="quote">&gt; +		unsigned long attrs);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  #endif /* __KERNEL__ */</span>
<span class="quote">&gt;  #endif</span>
<span class="quote">&gt; diff --git a/arch/arm/include/asm/xen/page-coherent.h b/arch/arm/include/asm/xen/page-coherent.h</span>
<span class="quote">&gt; index 9408a994cc91..95ce6ac3a971 100644</span>
<span class="quote">&gt; --- a/arch/arm/include/asm/xen/page-coherent.h</span>
<span class="quote">&gt; +++ b/arch/arm/include/asm/xen/page-coherent.h</span>
<span class="quote">&gt; @@ -2,15 +2,14 @@</span>
<span class="quote">&gt;  #define _ASM_ARM_XEN_PAGE_COHERENT_H</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  #include &lt;asm/page.h&gt;</span>
<span class="quote">&gt; -#include &lt;linux/dma-attrs.h&gt;</span>
<span class="quote">&gt;  #include &lt;linux/dma-mapping.h&gt;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  void __xen_dma_map_page(struct device *hwdev, struct page *page,</span>
<span class="quote">&gt;  	     dma_addr_t dev_addr, unsigned long offset, size_t size,</span>
<span class="quote">&gt; -	     enum dma_data_direction dir, struct dma_attrs *attrs);</span>
<span class="quote">&gt; +	     enum dma_data_direction dir, unsigned long attrs);</span>
<span class="quote">&gt;  void __xen_dma_unmap_page(struct device *hwdev, dma_addr_t handle,</span>
<span class="quote">&gt;  		size_t size, enum dma_data_direction dir,</span>
<span class="quote">&gt; -		struct dma_attrs *attrs);</span>
<span class="quote">&gt; +		unsigned long attrs);</span>
<span class="quote">&gt;  void __xen_dma_sync_single_for_cpu(struct device *hwdev,</span>
<span class="quote">&gt;  		dma_addr_t handle, size_t size, enum dma_data_direction dir);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; @@ -18,22 +17,20 @@ void __xen_dma_sync_single_for_device(struct device *hwdev,</span>
<span class="quote">&gt;  		dma_addr_t handle, size_t size, enum dma_data_direction dir);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  static inline void *xen_alloc_coherent_pages(struct device *hwdev, size_t size,</span>
<span class="quote">&gt; -		dma_addr_t *dma_handle, gfp_t flags,</span>
<span class="quote">&gt; -		struct dma_attrs *attrs)</span>
<span class="quote">&gt; +		dma_addr_t *dma_handle, gfp_t flags, unsigned long attrs)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	return __generic_dma_ops(hwdev)-&gt;alloc(hwdev, size, dma_handle, flags, attrs);</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  static inline void xen_free_coherent_pages(struct device *hwdev, size_t size,</span>
<span class="quote">&gt; -		void *cpu_addr, dma_addr_t dma_handle,</span>
<span class="quote">&gt; -		struct dma_attrs *attrs)</span>
<span class="quote">&gt; +		void *cpu_addr, dma_addr_t dma_handle, unsigned long attrs)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	__generic_dma_ops(hwdev)-&gt;free(hwdev, size, cpu_addr, dma_handle, attrs);</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  static inline void xen_dma_map_page(struct device *hwdev, struct page *page,</span>
<span class="quote">&gt;  	     dma_addr_t dev_addr, unsigned long offset, size_t size,</span>
<span class="quote">&gt; -	     enum dma_data_direction dir, struct dma_attrs *attrs)</span>
<span class="quote">&gt; +	     enum dma_data_direction dir, unsigned long attrs)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	unsigned long page_pfn = page_to_xen_pfn(page);</span>
<span class="quote">&gt;  	unsigned long dev_pfn = XEN_PFN_DOWN(dev_addr);</span>
<span class="quote">&gt; @@ -58,8 +55,7 @@ static inline void xen_dma_map_page(struct device *hwdev, struct page *page,</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  static inline void xen_dma_unmap_page(struct device *hwdev, dma_addr_t handle,</span>
<span class="quote">&gt; -		size_t size, enum dma_data_direction dir,</span>
<span class="quote">&gt; -		struct dma_attrs *attrs)</span>
<span class="quote">&gt; +		size_t size, enum dma_data_direction dir, unsigned long attrs)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	unsigned long pfn = PFN_DOWN(handle);</span>
<span class="quote">&gt;  	/*</span>
<span class="quote">&gt; diff --git a/arch/arm/mm/dma-mapping.c b/arch/arm/mm/dma-mapping.c</span>
<span class="quote">&gt; index ff7ed5697d3e..fe31fbfd926d 100644</span>
<span class="quote">&gt; --- a/arch/arm/mm/dma-mapping.c</span>
<span class="quote">&gt; +++ b/arch/arm/mm/dma-mapping.c</span>
<span class="quote">&gt; @@ -124,7 +124,7 @@ static void __dma_page_dev_to_cpu(struct page *, unsigned long,</span>
<span class="quote">&gt;   */</span>
<span class="quote">&gt;  static dma_addr_t arm_dma_map_page(struct device *dev, struct page *page,</span>
<span class="quote">&gt;  	     unsigned long offset, size_t size, enum dma_data_direction dir,</span>
<span class="quote">&gt; -	     struct dma_attrs *attrs)</span>
<span class="quote">&gt; +	     unsigned long attrs)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	if (!dma_get_attr(DMA_ATTR_SKIP_CPU_SYNC, attrs))</span>
<span class="quote">&gt;  		__dma_page_cpu_to_dev(page, offset, size, dir);</span>
<span class="quote">&gt; @@ -133,7 +133,7 @@ static dma_addr_t arm_dma_map_page(struct device *dev, struct page *page,</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  static dma_addr_t arm_coherent_dma_map_page(struct device *dev, struct page *page,</span>
<span class="quote">&gt;  	     unsigned long offset, size_t size, enum dma_data_direction dir,</span>
<span class="quote">&gt; -	     struct dma_attrs *attrs)</span>
<span class="quote">&gt; +	     unsigned long attrs)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	return pfn_to_dma(dev, page_to_pfn(page)) + offset;</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt; @@ -153,8 +153,7 @@ static dma_addr_t arm_coherent_dma_map_page(struct device *dev, struct page *pag</span>
<span class="quote">&gt;   * whatever the device wrote there.</span>
<span class="quote">&gt;   */</span>
<span class="quote">&gt;  static void arm_dma_unmap_page(struct device *dev, dma_addr_t handle,</span>
<span class="quote">&gt; -		size_t size, enum dma_data_direction dir,</span>
<span class="quote">&gt; -		struct dma_attrs *attrs)</span>
<span class="quote">&gt; +		size_t size, enum dma_data_direction dir, unsigned long attrs)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	if (!dma_get_attr(DMA_ATTR_SKIP_CPU_SYNC, attrs))</span>
<span class="quote">&gt;  		__dma_page_dev_to_cpu(pfn_to_page(dma_to_pfn(dev, handle)),</span>
<span class="quote">&gt; @@ -194,12 +193,12 @@ struct dma_map_ops arm_dma_ops = {</span>
<span class="quote">&gt;  EXPORT_SYMBOL(arm_dma_ops);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  static void *arm_coherent_dma_alloc(struct device *dev, size_t size,</span>
<span class="quote">&gt; -	dma_addr_t *handle, gfp_t gfp, struct dma_attrs *attrs);</span>
<span class="quote">&gt; +	dma_addr_t *handle, gfp_t gfp, unsigned long attrs);</span>
<span class="quote">&gt;  static void arm_coherent_dma_free(struct device *dev, size_t size, void *cpu_addr,</span>
<span class="quote">&gt; -				  dma_addr_t handle, struct dma_attrs *attrs);</span>
<span class="quote">&gt; +				  dma_addr_t handle, unsigned long attrs);</span>
<span class="quote">&gt;  static int arm_coherent_dma_mmap(struct device *dev, struct vm_area_struct *vma,</span>
<span class="quote">&gt;  		 void *cpu_addr, dma_addr_t dma_addr, size_t size,</span>
<span class="quote">&gt; -		 struct dma_attrs *attrs);</span>
<span class="quote">&gt; +		 unsigned long attrs);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  struct dma_map_ops arm_coherent_dma_ops = {</span>
<span class="quote">&gt;  	.alloc			= arm_coherent_dma_alloc,</span>
<span class="quote">&gt; @@ -621,7 +620,7 @@ static void __free_from_contiguous(struct device *dev, struct page *page,</span>
<span class="quote">&gt;  	dma_release_from_contiguous(dev, page, size &gt;&gt; PAGE_SHIFT);</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; -static inline pgprot_t __get_dma_pgprot(struct dma_attrs *attrs, pgprot_t prot)</span>
<span class="quote">&gt; +static inline pgprot_t __get_dma_pgprot(unsigned long attrs, pgprot_t prot)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	prot = dma_get_attr(DMA_ATTR_WRITE_COMBINE, attrs) ?</span>
<span class="quote">&gt;  			    pgprot_writecombine(prot) :</span>
<span class="quote">&gt; @@ -732,7 +731,7 @@ static struct arm_dma_allocator remap_allocator = {</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  static void *__dma_alloc(struct device *dev, size_t size, dma_addr_t *handle,</span>
<span class="quote">&gt;  			 gfp_t gfp, pgprot_t prot, bool is_coherent,</span>
<span class="quote">&gt; -			 struct dma_attrs *attrs, const void *caller)</span>
<span class="quote">&gt; +			 unsigned long attrs, const void *caller)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	u64 mask = get_coherent_dma_mask(dev);</span>
<span class="quote">&gt;  	struct page *page = NULL;</span>
<span class="quote">&gt; @@ -814,7 +813,7 @@ static void *__dma_alloc(struct device *dev, size_t size, dma_addr_t *handle,</span>
<span class="quote">&gt;   * virtual and bus address for that space.</span>
<span class="quote">&gt;   */</span>
<span class="quote">&gt;  void *arm_dma_alloc(struct device *dev, size_t size, dma_addr_t *handle,</span>
<span class="quote">&gt; -		    gfp_t gfp, struct dma_attrs *attrs)</span>
<span class="quote">&gt; +		    gfp_t gfp, unsigned long attrs)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	pgprot_t prot = __get_dma_pgprot(attrs, PAGE_KERNEL);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; @@ -823,7 +822,7 @@ void *arm_dma_alloc(struct device *dev, size_t size, dma_addr_t *handle,</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  static void *arm_coherent_dma_alloc(struct device *dev, size_t size,</span>
<span class="quote">&gt; -	dma_addr_t *handle, gfp_t gfp, struct dma_attrs *attrs)</span>
<span class="quote">&gt; +	dma_addr_t *handle, gfp_t gfp, unsigned long attrs)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	return __dma_alloc(dev, size, handle, gfp, PAGE_KERNEL, true,</span>
<span class="quote">&gt;  			   attrs, __builtin_return_address(0));</span>
<span class="quote">&gt; @@ -831,7 +830,7 @@ static void *arm_coherent_dma_alloc(struct device *dev, size_t size,</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  static int __arm_dma_mmap(struct device *dev, struct vm_area_struct *vma,</span>
<span class="quote">&gt;  		 void *cpu_addr, dma_addr_t dma_addr, size_t size,</span>
<span class="quote">&gt; -		 struct dma_attrs *attrs)</span>
<span class="quote">&gt; +		 unsigned long attrs)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	int ret = -ENXIO;</span>
<span class="quote">&gt;  #ifdef CONFIG_MMU</span>
<span class="quote">&gt; @@ -859,14 +858,14 @@ static int __arm_dma_mmap(struct device *dev, struct vm_area_struct *vma,</span>
<span class="quote">&gt;   */</span>
<span class="quote">&gt;  static int arm_coherent_dma_mmap(struct device *dev, struct vm_area_struct *vma,</span>
<span class="quote">&gt;  		 void *cpu_addr, dma_addr_t dma_addr, size_t size,</span>
<span class="quote">&gt; -		 struct dma_attrs *attrs)</span>
<span class="quote">&gt; +		 unsigned long attrs)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	return __arm_dma_mmap(dev, vma, cpu_addr, dma_addr, size, attrs);</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  int arm_dma_mmap(struct device *dev, struct vm_area_struct *vma,</span>
<span class="quote">&gt;  		 void *cpu_addr, dma_addr_t dma_addr, size_t size,</span>
<span class="quote">&gt; -		 struct dma_attrs *attrs)</span>
<span class="quote">&gt; +		 unsigned long attrs)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  #ifdef CONFIG_MMU</span>
<span class="quote">&gt;  	vma-&gt;vm_page_prot = __get_dma_pgprot(attrs, vma-&gt;vm_page_prot);</span>
<span class="quote">&gt; @@ -878,7 +877,7 @@ int arm_dma_mmap(struct device *dev, struct vm_area_struct *vma,</span>
<span class="quote">&gt;   * Free a buffer as defined by the above mapping.</span>
<span class="quote">&gt;   */</span>
<span class="quote">&gt;  static void __arm_dma_free(struct device *dev, size_t size, void *cpu_addr,</span>
<span class="quote">&gt; -			   dma_addr_t handle, struct dma_attrs *attrs,</span>
<span class="quote">&gt; +			   dma_addr_t handle, unsigned long attrs,</span>
<span class="quote">&gt;  			   bool is_coherent)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	struct page *page = pfn_to_page(dma_to_pfn(dev, handle));</span>
<span class="quote">&gt; @@ -900,20 +899,20 @@ static void __arm_dma_free(struct device *dev, size_t size, void *cpu_addr,</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  void arm_dma_free(struct device *dev, size_t size, void *cpu_addr,</span>
<span class="quote">&gt; -		  dma_addr_t handle, struct dma_attrs *attrs)</span>
<span class="quote">&gt; +		  dma_addr_t handle, unsigned long attrs)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	__arm_dma_free(dev, size, cpu_addr, handle, attrs, false);</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  static void arm_coherent_dma_free(struct device *dev, size_t size, void *cpu_addr,</span>
<span class="quote">&gt; -				  dma_addr_t handle, struct dma_attrs *attrs)</span>
<span class="quote">&gt; +				  dma_addr_t handle, unsigned long attrs)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	__arm_dma_free(dev, size, cpu_addr, handle, attrs, true);</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  int arm_dma_get_sgtable(struct device *dev, struct sg_table *sgt,</span>
<span class="quote">&gt;  		 void *cpu_addr, dma_addr_t handle, size_t size,</span>
<span class="quote">&gt; -		 struct dma_attrs *attrs)</span>
<span class="quote">&gt; +		 unsigned long attrs)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	struct page *page = pfn_to_page(dma_to_pfn(dev, handle));</span>
<span class="quote">&gt;  	int ret;</span>
<span class="quote">&gt; @@ -1046,7 +1045,7 @@ static void __dma_page_dev_to_cpu(struct page *page, unsigned long off,</span>
<span class="quote">&gt;   * here.</span>
<span class="quote">&gt;   */</span>
<span class="quote">&gt;  int arm_dma_map_sg(struct device *dev, struct scatterlist *sg, int nents,</span>
<span class="quote">&gt; -		enum dma_data_direction dir, struct dma_attrs *attrs)</span>
<span class="quote">&gt; +		enum dma_data_direction dir, unsigned long attrs)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	struct dma_map_ops *ops = get_dma_ops(dev);</span>
<span class="quote">&gt;  	struct scatterlist *s;</span>
<span class="quote">&gt; @@ -1080,7 +1079,7 @@ int arm_dma_map_sg(struct device *dev, struct scatterlist *sg, int nents,</span>
<span class="quote">&gt;   * rules concerning calls here are the same as for dma_unmap_single().</span>
<span class="quote">&gt;   */</span>
<span class="quote">&gt;  void arm_dma_unmap_sg(struct device *dev, struct scatterlist *sg, int nents,</span>
<span class="quote">&gt; -		enum dma_data_direction dir, struct dma_attrs *attrs)</span>
<span class="quote">&gt; +		enum dma_data_direction dir, unsigned long attrs)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	struct dma_map_ops *ops = get_dma_ops(dev);</span>
<span class="quote">&gt;  	struct scatterlist *s;</span>
<span class="quote">&gt; @@ -1253,7 +1252,7 @@ static inline void __free_iova(struct dma_iommu_mapping *mapping,</span>
<span class="quote">&gt;  static const int iommu_order_array[] = { 9, 8, 4, 0 };</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  static struct page **__iommu_alloc_buffer(struct device *dev, size_t size,</span>
<span class="quote">&gt; -					  gfp_t gfp, struct dma_attrs *attrs)</span>
<span class="quote">&gt; +					  gfp_t gfp, unsigned long attrs)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	struct page **pages;</span>
<span class="quote">&gt;  	int count = size &gt;&gt; PAGE_SHIFT;</span>
<span class="quote">&gt; @@ -1342,7 +1341,7 @@ error:</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  static int __iommu_free_buffer(struct device *dev, struct page **pages,</span>
<span class="quote">&gt; -			       size_t size, struct dma_attrs *attrs)</span>
<span class="quote">&gt; +			       size_t size, unsigned long attrs)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	int count = size &gt;&gt; PAGE_SHIFT;</span>
<span class="quote">&gt;  	int i;</span>
<span class="quote">&gt; @@ -1439,7 +1438,7 @@ static struct page **__atomic_get_pages(void *addr)</span>
<span class="quote">&gt;  	return (struct page **)page;</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; -static struct page **__iommu_get_pages(void *cpu_addr, struct dma_attrs *attrs)</span>
<span class="quote">&gt; +static struct page **__iommu_get_pages(void *cpu_addr, unsigned long attrs)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	struct vm_struct *area;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; @@ -1484,7 +1483,7 @@ static void __iommu_free_atomic(struct device *dev, void *cpu_addr,</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  static void *arm_iommu_alloc_attrs(struct device *dev, size_t size,</span>
<span class="quote">&gt; -	    dma_addr_t *handle, gfp_t gfp, struct dma_attrs *attrs)</span>
<span class="quote">&gt; +	    dma_addr_t *handle, gfp_t gfp, unsigned long attrs)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	pgprot_t prot = __get_dma_pgprot(attrs, PAGE_KERNEL);</span>
<span class="quote">&gt;  	struct page **pages;</span>
<span class="quote">&gt; @@ -1532,7 +1531,7 @@ err_buffer:</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  static int arm_iommu_mmap_attrs(struct device *dev, struct vm_area_struct *vma,</span>
<span class="quote">&gt;  		    void *cpu_addr, dma_addr_t dma_addr, size_t size,</span>
<span class="quote">&gt; -		    struct dma_attrs *attrs)</span>
<span class="quote">&gt; +		    unsigned long attrs)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	unsigned long uaddr = vma-&gt;vm_start;</span>
<span class="quote">&gt;  	unsigned long usize = vma-&gt;vm_end - vma-&gt;vm_start;</span>
<span class="quote">&gt; @@ -1568,7 +1567,7 @@ static int arm_iommu_mmap_attrs(struct device *dev, struct vm_area_struct *vma,</span>
<span class="quote">&gt;   * Must not be called with IRQs disabled.</span>
<span class="quote">&gt;   */</span>
<span class="quote">&gt;  void arm_iommu_free_attrs(struct device *dev, size_t size, void *cpu_addr,</span>
<span class="quote">&gt; -			  dma_addr_t handle, struct dma_attrs *attrs)</span>
<span class="quote">&gt; +			  dma_addr_t handle, unsigned long attrs)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	struct page **pages;</span>
<span class="quote">&gt;  	size = PAGE_ALIGN(size);</span>
<span class="quote">&gt; @@ -1595,7 +1594,7 @@ void arm_iommu_free_attrs(struct device *dev, size_t size, void *cpu_addr,</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  static int arm_iommu_get_sgtable(struct device *dev, struct sg_table *sgt,</span>
<span class="quote">&gt;  				 void *cpu_addr, dma_addr_t dma_addr,</span>
<span class="quote">&gt; -				 size_t size, struct dma_attrs *attrs)</span>
<span class="quote">&gt; +				 size_t size, unsigned long attrs)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	unsigned int count = PAGE_ALIGN(size) &gt;&gt; PAGE_SHIFT;</span>
<span class="quote">&gt;  	struct page **pages = __iommu_get_pages(cpu_addr, attrs);</span>
<span class="quote">&gt; @@ -1633,7 +1632,7 @@ static int __dma_direction_to_prot(enum dma_data_direction dir)</span>
<span class="quote">&gt;   */</span>
<span class="quote">&gt;  static int __map_sg_chunk(struct device *dev, struct scatterlist *sg,</span>
<span class="quote">&gt;  			  size_t size, dma_addr_t *handle,</span>
<span class="quote">&gt; -			  enum dma_data_direction dir, struct dma_attrs *attrs,</span>
<span class="quote">&gt; +			  enum dma_data_direction dir, unsigned long attrs,</span>
<span class="quote">&gt;  			  bool is_coherent)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	struct dma_iommu_mapping *mapping = to_dma_iommu_mapping(dev);</span>
<span class="quote">&gt; @@ -1676,7 +1675,7 @@ fail:</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  static int __iommu_map_sg(struct device *dev, struct scatterlist *sg, int nents,</span>
<span class="quote">&gt; -		     enum dma_data_direction dir, struct dma_attrs *attrs,</span>
<span class="quote">&gt; +		     enum dma_data_direction dir, unsigned long attrs,</span>
<span class="quote">&gt;  		     bool is_coherent)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	struct scatterlist *s = sg, *dma = sg, *start = sg;</span>
<span class="quote">&gt; @@ -1734,7 +1733,7 @@ bad_mapping:</span>
<span class="quote">&gt;   * obtained via sg_dma_{address,length}.</span>
<span class="quote">&gt;   */</span>
<span class="quote">&gt;  int arm_coherent_iommu_map_sg(struct device *dev, struct scatterlist *sg,</span>
<span class="quote">&gt; -		int nents, enum dma_data_direction dir, struct dma_attrs *attrs)</span>
<span class="quote">&gt; +		int nents, enum dma_data_direction dir, unsigned long attrs)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	return __iommu_map_sg(dev, sg, nents, dir, attrs, true);</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt; @@ -1752,14 +1751,14 @@ int arm_coherent_iommu_map_sg(struct device *dev, struct scatterlist *sg,</span>
<span class="quote">&gt;   * sg_dma_{address,length}.</span>
<span class="quote">&gt;   */</span>
<span class="quote">&gt;  int arm_iommu_map_sg(struct device *dev, struct scatterlist *sg,</span>
<span class="quote">&gt; -		int nents, enum dma_data_direction dir, struct dma_attrs *attrs)</span>
<span class="quote">&gt; +		int nents, enum dma_data_direction dir, unsigned long attrs)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	return __iommu_map_sg(dev, sg, nents, dir, attrs, false);</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  static void __iommu_unmap_sg(struct device *dev, struct scatterlist *sg,</span>
<span class="quote">&gt; -		int nents, enum dma_data_direction dir, struct dma_attrs *attrs,</span>
<span class="quote">&gt; -		bool is_coherent)</span>
<span class="quote">&gt; +		int nents, enum dma_data_direction dir,</span>
<span class="quote">&gt; +		unsigned long attrs, bool is_coherent)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	struct scatterlist *s;</span>
<span class="quote">&gt;  	int i;</span>
<span class="quote">&gt; @@ -1786,7 +1785,8 @@ static void __iommu_unmap_sg(struct device *dev, struct scatterlist *sg,</span>
<span class="quote">&gt;   * rules concerning calls here are the same as for dma_unmap_single().</span>
<span class="quote">&gt;   */</span>
<span class="quote">&gt;  void arm_coherent_iommu_unmap_sg(struct device *dev, struct scatterlist *sg,</span>
<span class="quote">&gt; -		int nents, enum dma_data_direction dir, struct dma_attrs *attrs)</span>
<span class="quote">&gt; +		int nents, enum dma_data_direction dir,</span>
<span class="quote">&gt; +		unsigned long attrs)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	__iommu_unmap_sg(dev, sg, nents, dir, attrs, true);</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt; @@ -1802,7 +1802,8 @@ void arm_coherent_iommu_unmap_sg(struct device *dev, struct scatterlist *sg,</span>
<span class="quote">&gt;   * rules concerning calls here are the same as for dma_unmap_single().</span>
<span class="quote">&gt;   */</span>
<span class="quote">&gt;  void arm_iommu_unmap_sg(struct device *dev, struct scatterlist *sg, int nents,</span>
<span class="quote">&gt; -			enum dma_data_direction dir, struct dma_attrs *attrs)</span>
<span class="quote">&gt; +			enum dma_data_direction dir,</span>
<span class="quote">&gt; +			unsigned long attrs)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	__iommu_unmap_sg(dev, sg, nents, dir, attrs, false);</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt; @@ -1855,7 +1856,7 @@ void arm_iommu_sync_sg_for_device(struct device *dev, struct scatterlist *sg,</span>
<span class="quote">&gt;   */</span>
<span class="quote">&gt;  static dma_addr_t arm_coherent_iommu_map_page(struct device *dev, struct page *page,</span>
<span class="quote">&gt;  	     unsigned long offset, size_t size, enum dma_data_direction dir,</span>
<span class="quote">&gt; -	     struct dma_attrs *attrs)</span>
<span class="quote">&gt; +	     unsigned long attrs)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	struct dma_iommu_mapping *mapping = to_dma_iommu_mapping(dev);</span>
<span class="quote">&gt;  	dma_addr_t dma_addr;</span>
<span class="quote">&gt; @@ -1889,7 +1890,7 @@ fail:</span>
<span class="quote">&gt;   */</span>
<span class="quote">&gt;  static dma_addr_t arm_iommu_map_page(struct device *dev, struct page *page,</span>
<span class="quote">&gt;  	     unsigned long offset, size_t size, enum dma_data_direction dir,</span>
<span class="quote">&gt; -	     struct dma_attrs *attrs)</span>
<span class="quote">&gt; +	     unsigned long attrs)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	if (!dma_get_attr(DMA_ATTR_SKIP_CPU_SYNC, attrs))</span>
<span class="quote">&gt;  		__dma_page_cpu_to_dev(page, offset, size, dir);</span>
<span class="quote">&gt; @@ -1907,8 +1908,7 @@ static dma_addr_t arm_iommu_map_page(struct device *dev, struct page *page,</span>
<span class="quote">&gt;   * Coherent IOMMU aware version of arm_dma_unmap_page()</span>
<span class="quote">&gt;   */</span>
<span class="quote">&gt;  static void arm_coherent_iommu_unmap_page(struct device *dev, dma_addr_t handle,</span>
<span class="quote">&gt; -		size_t size, enum dma_data_direction dir,</span>
<span class="quote">&gt; -		struct dma_attrs *attrs)</span>
<span class="quote">&gt; +		size_t size, enum dma_data_direction dir, unsigned long attrs)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	struct dma_iommu_mapping *mapping = to_dma_iommu_mapping(dev);</span>
<span class="quote">&gt;  	dma_addr_t iova = handle &amp; PAGE_MASK;</span>
<span class="quote">&gt; @@ -1932,8 +1932,7 @@ static void arm_coherent_iommu_unmap_page(struct device *dev, dma_addr_t handle,</span>
<span class="quote">&gt;   * IOMMU aware version of arm_dma_unmap_page()</span>
<span class="quote">&gt;   */</span>
<span class="quote">&gt;  static void arm_iommu_unmap_page(struct device *dev, dma_addr_t handle,</span>
<span class="quote">&gt; -		size_t size, enum dma_data_direction dir,</span>
<span class="quote">&gt; -		struct dma_attrs *attrs)</span>
<span class="quote">&gt; +		size_t size, enum dma_data_direction dir, unsigned long attrs)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	struct dma_iommu_mapping *mapping = to_dma_iommu_mapping(dev);</span>
<span class="quote">&gt;  	dma_addr_t iova = handle &amp; PAGE_MASK;</span>
<span class="quote">&gt; @@ -1944,6 +1943,7 @@ static void arm_iommu_unmap_page(struct device *dev, dma_addr_t handle,</span>
<span class="quote">&gt;  	if (!iova)</span>
<span class="quote">&gt;  		return;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; +	// FIXME: replace get with simple check</span>
<span class="quote">&gt;  	if (!dma_get_attr(DMA_ATTR_SKIP_CPU_SYNC, attrs))</span>
<span class="quote">&gt;  		__dma_page_dev_to_cpu(page, offset, size, dir);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; diff --git a/arch/arm/xen/mm.c b/arch/arm/xen/mm.c</span>
<span class="quote">&gt; index c5f9a9e3d1f3..fc67ed236a10 100644</span>
<span class="quote">&gt; --- a/arch/arm/xen/mm.c</span>
<span class="quote">&gt; +++ b/arch/arm/xen/mm.c</span>
<span class="quote">&gt; @@ -98,7 +98,7 @@ static void __xen_dma_page_cpu_to_dev(struct device *hwdev, dma_addr_t handle,</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  void __xen_dma_map_page(struct device *hwdev, struct page *page,</span>
<span class="quote">&gt;  	     dma_addr_t dev_addr, unsigned long offset, size_t size,</span>
<span class="quote">&gt; -	     enum dma_data_direction dir, struct dma_attrs *attrs)</span>
<span class="quote">&gt; +	     enum dma_data_direction dir, unsigned long attrs)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	if (is_device_dma_coherent(hwdev))</span>
<span class="quote">&gt;  		return;</span>
<span class="quote">&gt; @@ -110,7 +110,7 @@ void __xen_dma_map_page(struct device *hwdev, struct page *page,</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  void __xen_dma_unmap_page(struct device *hwdev, dma_addr_t handle,</span>
<span class="quote">&gt;  		size_t size, enum dma_data_direction dir,</span>
<span class="quote">&gt; -		struct dma_attrs *attrs)</span>
<span class="quote">&gt; +		unsigned long attrs)</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	if (is_device_dma_coherent(hwdev))</span>
<span class="quote">&gt; diff --git a/arch/arm64/mm/dma-mapping.c b/arch/arm64/mm/dma-mapping.c</span>
<span class="quote">&gt; index c566ec83719f..a7686028dfeb 100644</span>
<span class="quote">&gt; --- a/arch/arm64/mm/dma-mapping.c</span>
<span class="quote">&gt; +++ b/arch/arm64/mm/dma-mapping.c</span>
<span class="quote">&gt; @@ -29,7 +29,7 @@</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  #include &lt;asm/cacheflush.h&gt;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; -static pgprot_t __get_dma_pgprot(struct dma_attrs *attrs, pgprot_t prot,</span>
<span class="quote">&gt; +static pgprot_t __get_dma_pgprot(unsigned long attrs, pgprot_t prot,</span>
<span class="quote">&gt;  				 bool coherent)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	if (!coherent || dma_get_attr(DMA_ATTR_WRITE_COMBINE, attrs))</span>
<span class="quote">&gt; @@ -88,7 +88,7 @@ static int __free_from_pool(void *start, size_t size)</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  static void *__dma_alloc_coherent(struct device *dev, size_t size,</span>
<span class="quote">&gt;  				  dma_addr_t *dma_handle, gfp_t flags,</span>
<span class="quote">&gt; -				  struct dma_attrs *attrs)</span>
<span class="quote">&gt; +				  unsigned long attrs)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	if (dev == NULL) {</span>
<span class="quote">&gt;  		WARN_ONCE(1, &quot;Use an actual device structure for DMA allocation\n&quot;);</span>
<span class="quote">&gt; @@ -118,7 +118,7 @@ static void *__dma_alloc_coherent(struct device *dev, size_t size,</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  static void __dma_free_coherent(struct device *dev, size_t size,</span>
<span class="quote">&gt;  				void *vaddr, dma_addr_t dma_handle,</span>
<span class="quote">&gt; -				struct dma_attrs *attrs)</span>
<span class="quote">&gt; +				unsigned long attrs)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	bool freed;</span>
<span class="quote">&gt;  	phys_addr_t paddr = dma_to_phys(dev, dma_handle);</span>
<span class="quote">&gt; @@ -137,7 +137,7 @@ static void __dma_free_coherent(struct device *dev, size_t size,</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  static void *__dma_alloc(struct device *dev, size_t size,</span>
<span class="quote">&gt;  			 dma_addr_t *dma_handle, gfp_t flags,</span>
<span class="quote">&gt; -			 struct dma_attrs *attrs)</span>
<span class="quote">&gt; +			 unsigned long attrs)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	struct page *page;</span>
<span class="quote">&gt;  	void *ptr, *coherent_ptr;</span>
<span class="quote">&gt; @@ -185,7 +185,7 @@ no_mem:</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  static void __dma_free(struct device *dev, size_t size,</span>
<span class="quote">&gt;  		       void *vaddr, dma_addr_t dma_handle,</span>
<span class="quote">&gt; -		       struct dma_attrs *attrs)</span>
<span class="quote">&gt; +		       unsigned long attrs)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	void *swiotlb_addr = phys_to_virt(dma_to_phys(dev, dma_handle));</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; @@ -202,7 +202,7 @@ static void __dma_free(struct device *dev, size_t size,</span>
<span class="quote">&gt;  static dma_addr_t __swiotlb_map_page(struct device *dev, struct page *page,</span>
<span class="quote">&gt;  				     unsigned long offset, size_t size,</span>
<span class="quote">&gt;  				     enum dma_data_direction dir,</span>
<span class="quote">&gt; -				     struct dma_attrs *attrs)</span>
<span class="quote">&gt; +				     unsigned long attrs)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	dma_addr_t dev_addr;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; @@ -216,7 +216,7 @@ static dma_addr_t __swiotlb_map_page(struct device *dev, struct page *page,</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  static void __swiotlb_unmap_page(struct device *dev, dma_addr_t dev_addr,</span>
<span class="quote">&gt;  				 size_t size, enum dma_data_direction dir,</span>
<span class="quote">&gt; -				 struct dma_attrs *attrs)</span>
<span class="quote">&gt; +				 unsigned long attrs)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	if (!is_device_dma_coherent(dev))</span>
<span class="quote">&gt;  		__dma_unmap_area(phys_to_virt(dma_to_phys(dev, dev_addr)), size, dir);</span>
<span class="quote">&gt; @@ -225,7 +225,7 @@ static void __swiotlb_unmap_page(struct device *dev, dma_addr_t dev_addr,</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  static int __swiotlb_map_sg_attrs(struct device *dev, struct scatterlist *sgl,</span>
<span class="quote">&gt;  				  int nelems, enum dma_data_direction dir,</span>
<span class="quote">&gt; -				  struct dma_attrs *attrs)</span>
<span class="quote">&gt; +				  unsigned long attrs)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	struct scatterlist *sg;</span>
<span class="quote">&gt;  	int i, ret;</span>
<span class="quote">&gt; @@ -242,7 +242,7 @@ static int __swiotlb_map_sg_attrs(struct device *dev, struct scatterlist *sgl,</span>
<span class="quote">&gt;  static void __swiotlb_unmap_sg_attrs(struct device *dev,</span>
<span class="quote">&gt;  				     struct scatterlist *sgl, int nelems,</span>
<span class="quote">&gt;  				     enum dma_data_direction dir,</span>
<span class="quote">&gt; -				     struct dma_attrs *attrs)</span>
<span class="quote">&gt; +				     unsigned long attrs)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	struct scatterlist *sg;</span>
<span class="quote">&gt;  	int i;</span>
<span class="quote">&gt; @@ -303,7 +303,7 @@ static void __swiotlb_sync_sg_for_device(struct device *dev,</span>
<span class="quote">&gt;  static int __swiotlb_mmap(struct device *dev,</span>
<span class="quote">&gt;  			  struct vm_area_struct *vma,</span>
<span class="quote">&gt;  			  void *cpu_addr, dma_addr_t dma_addr, size_t size,</span>
<span class="quote">&gt; -			  struct dma_attrs *attrs)</span>
<span class="quote">&gt; +			  unsigned long attrs)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	int ret = -ENXIO;</span>
<span class="quote">&gt;  	unsigned long nr_vma_pages = (vma-&gt;vm_end - vma-&gt;vm_start) &gt;&gt;</span>
<span class="quote">&gt; @@ -330,7 +330,7 @@ static int __swiotlb_mmap(struct device *dev,</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  static int __swiotlb_get_sgtable(struct device *dev, struct sg_table *sgt,</span>
<span class="quote">&gt;  				 void *cpu_addr, dma_addr_t handle, size_t size,</span>
<span class="quote">&gt; -				 struct dma_attrs *attrs)</span>
<span class="quote">&gt; +				 unsigned long attrs)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	int ret = sg_alloc_table(sgt, 1, GFP_KERNEL);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; @@ -425,21 +425,21 @@ out:</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  static void *__dummy_alloc(struct device *dev, size_t size,</span>
<span class="quote">&gt;  			   dma_addr_t *dma_handle, gfp_t flags,</span>
<span class="quote">&gt; -			   struct dma_attrs *attrs)</span>
<span class="quote">&gt; +			   unsigned long attrs)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	return NULL;</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  static void __dummy_free(struct device *dev, size_t size,</span>
<span class="quote">&gt;  			 void *vaddr, dma_addr_t dma_handle,</span>
<span class="quote">&gt; -			 struct dma_attrs *attrs)</span>
<span class="quote">&gt; +			 unsigned long attrs)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  static int __dummy_mmap(struct device *dev,</span>
<span class="quote">&gt;  			struct vm_area_struct *vma,</span>
<span class="quote">&gt;  			void *cpu_addr, dma_addr_t dma_addr, size_t size,</span>
<span class="quote">&gt; -			struct dma_attrs *attrs)</span>
<span class="quote">&gt; +			unsigned long attrs)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	return -ENXIO;</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt; @@ -447,20 +447,20 @@ static int __dummy_mmap(struct device *dev,</span>
<span class="quote">&gt;  static dma_addr_t __dummy_map_page(struct device *dev, struct page *page,</span>
<span class="quote">&gt;  				   unsigned long offset, size_t size,</span>
<span class="quote">&gt;  				   enum dma_data_direction dir,</span>
<span class="quote">&gt; -				   struct dma_attrs *attrs)</span>
<span class="quote">&gt; +				   unsigned long attrs)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	return DMA_ERROR_CODE;</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  static void __dummy_unmap_page(struct device *dev, dma_addr_t dev_addr,</span>
<span class="quote">&gt;  			       size_t size, enum dma_data_direction dir,</span>
<span class="quote">&gt; -			       struct dma_attrs *attrs)</span>
<span class="quote">&gt; +			       unsigned long attrs)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  static int __dummy_map_sg(struct device *dev, struct scatterlist *sgl,</span>
<span class="quote">&gt;  			  int nelems, enum dma_data_direction dir,</span>
<span class="quote">&gt; -			  struct dma_attrs *attrs)</span>
<span class="quote">&gt; +			  unsigned long attrs)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	return 0;</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt; @@ -468,7 +468,7 @@ static int __dummy_map_sg(struct device *dev, struct scatterlist *sgl,</span>
<span class="quote">&gt;  static void __dummy_unmap_sg(struct device *dev,</span>
<span class="quote">&gt;  			     struct scatterlist *sgl, int nelems,</span>
<span class="quote">&gt;  			     enum dma_data_direction dir,</span>
<span class="quote">&gt; -			     struct dma_attrs *attrs)</span>
<span class="quote">&gt; +			     unsigned long attrs)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; @@ -540,7 +540,7 @@ static void flush_page(struct device *dev, const void *virt, phys_addr_t phys)</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  static void *__iommu_alloc_attrs(struct device *dev, size_t size,</span>
<span class="quote">&gt;  				 dma_addr_t *handle, gfp_t gfp,</span>
<span class="quote">&gt; -				 struct dma_attrs *attrs)</span>
<span class="quote">&gt; +				 unsigned long attrs)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	bool coherent = is_device_dma_coherent(dev);</span>
<span class="quote">&gt;  	int ioprot = dma_direction_to_prot(DMA_BIDIRECTIONAL, coherent);</span>
<span class="quote">&gt; @@ -600,7 +600,8 @@ static void *__iommu_alloc_attrs(struct device *dev, size_t size,</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  static void __iommu_free_attrs(struct device *dev, size_t size, void *cpu_addr,</span>
<span class="quote">&gt; -			       dma_addr_t handle, struct dma_attrs *attrs)</span>
<span class="quote">&gt; +			       dma_addr_t handle,</span>
<span class="quote">&gt; +			       unsigned long attrs)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	size_t iosize = size;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; @@ -616,7 +617,7 @@ static void __iommu_free_attrs(struct device *dev, size_t size, void *cpu_addr,</span>
<span class="quote">&gt;  	 * Hence how dodgy the below logic looks...</span>
<span class="quote">&gt;  	 */</span>
<span class="quote">&gt;  	if (__in_atomic_pool(cpu_addr, size)) {</span>
<span class="quote">&gt; -		iommu_dma_unmap_page(dev, handle, iosize, 0, NULL);</span>
<span class="quote">&gt; +		iommu_dma_unmap_page(dev, handle, iosize, 0, 0);</span>
<span class="quote">&gt;  		__free_from_pool(cpu_addr, size);</span>
<span class="quote">&gt;  	} else if (is_vmalloc_addr(cpu_addr)){</span>
<span class="quote">&gt;  		struct vm_struct *area = find_vm_area(cpu_addr);</span>
<span class="quote">&gt; @@ -626,14 +627,14 @@ static void __iommu_free_attrs(struct device *dev, size_t size, void *cpu_addr,</span>
<span class="quote">&gt;  		iommu_dma_free(dev, area-&gt;pages, iosize, &amp;handle);</span>
<span class="quote">&gt;  		dma_common_free_remap(cpu_addr, size, VM_USERMAP);</span>
<span class="quote">&gt;  	} else {</span>
<span class="quote">&gt; -		iommu_dma_unmap_page(dev, handle, iosize, 0, NULL);</span>
<span class="quote">&gt; +		iommu_dma_unmap_page(dev, handle, iosize, 0, 0);</span>
<span class="quote">&gt;  		__free_pages(virt_to_page(cpu_addr), get_order(size));</span>
<span class="quote">&gt;  	}</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  static int __iommu_mmap_attrs(struct device *dev, struct vm_area_struct *vma,</span>
<span class="quote">&gt;  			      void *cpu_addr, dma_addr_t dma_addr, size_t size,</span>
<span class="quote">&gt; -			      struct dma_attrs *attrs)</span>
<span class="quote">&gt; +			      unsigned long attrs)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	struct vm_struct *area;</span>
<span class="quote">&gt;  	int ret;</span>
<span class="quote">&gt; @@ -653,7 +654,7 @@ static int __iommu_mmap_attrs(struct device *dev, struct vm_area_struct *vma,</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  static int __iommu_get_sgtable(struct device *dev, struct sg_table *sgt,</span>
<span class="quote">&gt;  			       void *cpu_addr, dma_addr_t dma_addr,</span>
<span class="quote">&gt; -			       size_t size, struct dma_attrs *attrs)</span>
<span class="quote">&gt; +			       size_t size, unsigned long attrs)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	unsigned int count = PAGE_ALIGN(size) &gt;&gt; PAGE_SHIFT;</span>
<span class="quote">&gt;  	struct vm_struct *area = find_vm_area(cpu_addr);</span>
<span class="quote">&gt; @@ -694,7 +695,7 @@ static void __iommu_sync_single_for_device(struct device *dev,</span>
<span class="quote">&gt;  static dma_addr_t __iommu_map_page(struct device *dev, struct page *page,</span>
<span class="quote">&gt;  				   unsigned long offset, size_t size,</span>
<span class="quote">&gt;  				   enum dma_data_direction dir,</span>
<span class="quote">&gt; -				   struct dma_attrs *attrs)</span>
<span class="quote">&gt; +				   unsigned long attrs)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	bool coherent = is_device_dma_coherent(dev);</span>
<span class="quote">&gt;  	int prot = dma_direction_to_prot(dir, coherent);</span>
<span class="quote">&gt; @@ -709,7 +710,7 @@ static dma_addr_t __iommu_map_page(struct device *dev, struct page *page,</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  static void __iommu_unmap_page(struct device *dev, dma_addr_t dev_addr,</span>
<span class="quote">&gt;  			       size_t size, enum dma_data_direction dir,</span>
<span class="quote">&gt; -			       struct dma_attrs *attrs)</span>
<span class="quote">&gt; +			       unsigned long attrs)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	if (!dma_get_attr(DMA_ATTR_SKIP_CPU_SYNC, attrs))</span>
<span class="quote">&gt;  		__iommu_sync_single_for_cpu(dev, dev_addr, size, dir);</span>
<span class="quote">&gt; @@ -747,7 +748,7 @@ static void __iommu_sync_sg_for_device(struct device *dev,</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  static int __iommu_map_sg_attrs(struct device *dev, struct scatterlist *sgl,</span>
<span class="quote">&gt;  				int nelems, enum dma_data_direction dir,</span>
<span class="quote">&gt; -				struct dma_attrs *attrs)</span>
<span class="quote">&gt; +				unsigned long attrs)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	bool coherent = is_device_dma_coherent(dev);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; @@ -761,7 +762,7 @@ static int __iommu_map_sg_attrs(struct device *dev, struct scatterlist *sgl,</span>
<span class="quote">&gt;  static void __iommu_unmap_sg_attrs(struct device *dev,</span>
<span class="quote">&gt;  				   struct scatterlist *sgl, int nelems,</span>
<span class="quote">&gt;  				   enum dma_data_direction dir,</span>
<span class="quote">&gt; -				   struct dma_attrs *attrs)</span>
<span class="quote">&gt; +				   unsigned long attrs)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	if (!dma_get_attr(DMA_ATTR_SKIP_CPU_SYNC, attrs))</span>
<span class="quote">&gt;  		__iommu_sync_sg_for_cpu(dev, sgl, nelems, dir);</span>
<span class="quote">&gt; diff --git a/drivers/gpu/drm/exynos/exynos_drm_fbdev.c b/drivers/gpu/drm/exynos/exynos_drm_fbdev.c</span>
<span class="quote">&gt; index 67dcd6831291..dd091175fc2d 100644</span>
<span class="quote">&gt; --- a/drivers/gpu/drm/exynos/exynos_drm_fbdev.c</span>
<span class="quote">&gt; +++ b/drivers/gpu/drm/exynos/exynos_drm_fbdev.c</span>
<span class="quote">&gt; @@ -52,7 +52,7 @@ static int exynos_drm_fb_mmap(struct fb_info *info,</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	ret = dma_mmap_attrs(to_dma_dev(helper-&gt;dev), vma, exynos_gem-&gt;cookie,</span>
<span class="quote">&gt;  			     exynos_gem-&gt;dma_addr, exynos_gem-&gt;size,</span>
<span class="quote">&gt; -			     &amp;exynos_gem-&gt;dma_attrs);</span>
<span class="quote">&gt; +			     exynos_gem-&gt;dma_attrs);</span>
<span class="quote">&gt;  	if (ret &lt; 0) {</span>
<span class="quote">&gt;  		DRM_ERROR(&quot;failed to mmap.\n&quot;);</span>
<span class="quote">&gt;  		return ret;</span>
<span class="quote">&gt; diff --git a/drivers/gpu/drm/exynos/exynos_drm_g2d.c b/drivers/gpu/drm/exynos/exynos_drm_g2d.c</span>
<span class="quote">&gt; index 493552368295..f65e6b7ef93b 100644</span>
<span class="quote">&gt; --- a/drivers/gpu/drm/exynos/exynos_drm_g2d.c</span>
<span class="quote">&gt; +++ b/drivers/gpu/drm/exynos/exynos_drm_g2d.c</span>
<span class="quote">&gt; @@ -17,7 +17,6 @@</span>
<span class="quote">&gt;  #include &lt;linux/slab.h&gt;</span>
<span class="quote">&gt;  #include &lt;linux/workqueue.h&gt;</span>
<span class="quote">&gt;  #include &lt;linux/dma-mapping.h&gt;</span>
<span class="quote">&gt; -#include &lt;linux/dma-attrs.h&gt;</span>
<span class="quote">&gt;  #include &lt;linux/of.h&gt;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  #include &lt;drm/drmP.h&gt;</span>
<span class="quote">&gt; diff --git a/drivers/gpu/drm/exynos/exynos_drm_gem.c b/drivers/gpu/drm/exynos/exynos_drm_gem.c</span>
<span class="quote">&gt; index cdf9f1af4347..f2ae72ba7d5a 100644</span>
<span class="quote">&gt; --- a/drivers/gpu/drm/exynos/exynos_drm_gem.c</span>
<span class="quote">&gt; +++ b/drivers/gpu/drm/exynos/exynos_drm_gem.c</span>
<span class="quote">&gt; @@ -24,7 +24,7 @@</span>
<span class="quote">&gt;  static int exynos_drm_alloc_buf(struct exynos_drm_gem *exynos_gem)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	struct drm_device *dev = exynos_gem-&gt;base.dev;</span>
<span class="quote">&gt; -	enum dma_attr attr;</span>
<span class="quote">&gt; +	unsigned long attr;</span>
<span class="quote">&gt;  	unsigned int nr_pages;</span>
<span class="quote">&gt;  	struct sg_table sgt;</span>
<span class="quote">&gt;  	int ret = -ENOMEM;</span>
<span class="quote">&gt; @@ -34,7 +34,7 @@ static int exynos_drm_alloc_buf(struct exynos_drm_gem *exynos_gem)</span>
<span class="quote">&gt;  		return 0;</span>
<span class="quote">&gt;  	}</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; -	init_dma_attrs(&amp;exynos_gem-&gt;dma_attrs);</span>
<span class="quote">&gt; +	exynos_gem-&gt;dma_attrs = 0;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	/*</span>
<span class="quote">&gt;  	 * if EXYNOS_BO_CONTIG, fully physically contiguous memory</span>
<span class="quote">&gt; @@ -42,7 +42,7 @@ static int exynos_drm_alloc_buf(struct exynos_drm_gem *exynos_gem)</span>
<span class="quote">&gt;  	 * as possible.</span>
<span class="quote">&gt;  	 */</span>
<span class="quote">&gt;  	if (!(exynos_gem-&gt;flags &amp; EXYNOS_BO_NONCONTIG))</span>
<span class="quote">&gt; -		dma_set_attr(DMA_ATTR_FORCE_CONTIGUOUS, &amp;exynos_gem-&gt;dma_attrs);</span>
<span class="quote">&gt; +		exynos_gem-&gt;dma_attrs |= DMA_ATTR_FORCE_CONTIGUOUS;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	/*</span>
<span class="quote">&gt;  	 * if EXYNOS_BO_WC or EXYNOS_BO_NONCACHABLE, writecombine mapping</span>
<span class="quote">&gt; @@ -54,8 +54,8 @@ static int exynos_drm_alloc_buf(struct exynos_drm_gem *exynos_gem)</span>
<span class="quote">&gt;  	else</span>
<span class="quote">&gt;  		attr = DMA_ATTR_NON_CONSISTENT;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; -	dma_set_attr(attr, &amp;exynos_gem-&gt;dma_attrs);</span>
<span class="quote">&gt; -	dma_set_attr(DMA_ATTR_NO_KERNEL_MAPPING, &amp;exynos_gem-&gt;dma_attrs);</span>
<span class="quote">&gt; +	exynos_gem-&gt;dma_attrs |= attr;</span>
<span class="quote">&gt; +	exynos_gem-&gt;dma_attrs |= DMA_ATTR_NO_KERNEL_MAPPING;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	nr_pages = exynos_gem-&gt;size &gt;&gt; PAGE_SHIFT;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; @@ -67,7 +67,7 @@ static int exynos_drm_alloc_buf(struct exynos_drm_gem *exynos_gem)</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	exynos_gem-&gt;cookie = dma_alloc_attrs(to_dma_dev(dev), exynos_gem-&gt;size,</span>
<span class="quote">&gt;  					     &amp;exynos_gem-&gt;dma_addr, GFP_KERNEL,</span>
<span class="quote">&gt; -					     &amp;exynos_gem-&gt;dma_attrs);</span>
<span class="quote">&gt; +					     exynos_gem-&gt;dma_attrs);</span>
<span class="quote">&gt;  	if (!exynos_gem-&gt;cookie) {</span>
<span class="quote">&gt;  		DRM_ERROR(&quot;failed to allocate buffer.\n&quot;);</span>
<span class="quote">&gt;  		goto err_free;</span>
<span class="quote">&gt; @@ -75,7 +75,7 @@ static int exynos_drm_alloc_buf(struct exynos_drm_gem *exynos_gem)</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	ret = dma_get_sgtable_attrs(to_dma_dev(dev), &amp;sgt, exynos_gem-&gt;cookie,</span>
<span class="quote">&gt;  				    exynos_gem-&gt;dma_addr, exynos_gem-&gt;size,</span>
<span class="quote">&gt; -				    &amp;exynos_gem-&gt;dma_attrs);</span>
<span class="quote">&gt; +				    exynos_gem-&gt;dma_attrs);</span>
<span class="quote">&gt;  	if (ret &lt; 0) {</span>
<span class="quote">&gt;  		DRM_ERROR(&quot;failed to get sgtable.\n&quot;);</span>
<span class="quote">&gt;  		goto err_dma_free;</span>
<span class="quote">&gt; @@ -99,7 +99,7 @@ err_sgt_free:</span>
<span class="quote">&gt;  	sg_free_table(&amp;sgt);</span>
<span class="quote">&gt;  err_dma_free:</span>
<span class="quote">&gt;  	dma_free_attrs(to_dma_dev(dev), exynos_gem-&gt;size, exynos_gem-&gt;cookie,</span>
<span class="quote">&gt; -		       exynos_gem-&gt;dma_addr, &amp;exynos_gem-&gt;dma_attrs);</span>
<span class="quote">&gt; +		       exynos_gem-&gt;dma_addr, exynos_gem-&gt;dma_attrs);</span>
<span class="quote">&gt;  err_free:</span>
<span class="quote">&gt;  	drm_free_large(exynos_gem-&gt;pages);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; @@ -120,7 +120,7 @@ static void exynos_drm_free_buf(struct exynos_drm_gem *exynos_gem)</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	dma_free_attrs(to_dma_dev(dev), exynos_gem-&gt;size, exynos_gem-&gt;cookie,</span>
<span class="quote">&gt;  			(dma_addr_t)exynos_gem-&gt;dma_addr,</span>
<span class="quote">&gt; -			&amp;exynos_gem-&gt;dma_attrs);</span>
<span class="quote">&gt; +			exynos_gem-&gt;dma_attrs);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	drm_free_large(exynos_gem-&gt;pages);</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt; @@ -346,7 +346,7 @@ static int exynos_drm_gem_mmap_buffer(struct exynos_drm_gem *exynos_gem,</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	ret = dma_mmap_attrs(to_dma_dev(drm_dev), vma, exynos_gem-&gt;cookie,</span>
<span class="quote">&gt;  			     exynos_gem-&gt;dma_addr, exynos_gem-&gt;size,</span>
<span class="quote">&gt; -			     &amp;exynos_gem-&gt;dma_attrs);</span>
<span class="quote">&gt; +			     exynos_gem-&gt;dma_attrs);</span>
<span class="quote">&gt;  	if (ret &lt; 0) {</span>
<span class="quote">&gt;  		DRM_ERROR(&quot;failed to mmap.\n&quot;);</span>
<span class="quote">&gt;  		return ret;</span>
<span class="quote">&gt; diff --git a/drivers/gpu/drm/exynos/exynos_drm_gem.h b/drivers/gpu/drm/exynos/exynos_drm_gem.h</span>
<span class="quote">&gt; index 78100742281d..df7c543d6558 100644</span>
<span class="quote">&gt; --- a/drivers/gpu/drm/exynos/exynos_drm_gem.h</span>
<span class="quote">&gt; +++ b/drivers/gpu/drm/exynos/exynos_drm_gem.h</span>
<span class="quote">&gt; @@ -50,7 +50,7 @@ struct exynos_drm_gem {</span>
<span class="quote">&gt;  	void			*cookie;</span>
<span class="quote">&gt;  	void __iomem		*kvaddr;</span>
<span class="quote">&gt;  	dma_addr_t		dma_addr;</span>
<span class="quote">&gt; -	struct dma_attrs	dma_attrs;</span>
<span class="quote">&gt; +	unsigned long		dma_attrs;</span>
<span class="quote">&gt;  	struct page		**pages;</span>
<span class="quote">&gt;  	struct sg_table		*sgt;</span>
<span class="quote">&gt;  };</span>
<span class="quote">&gt; diff --git a/drivers/iommu/dma-iommu.c b/drivers/iommu/dma-iommu.c</span>
<span class="quote">&gt; index ea5a9ebf0f78..6c1bda504fb1 100644</span>
<span class="quote">&gt; --- a/drivers/iommu/dma-iommu.c</span>
<span class="quote">&gt; +++ b/drivers/iommu/dma-iommu.c</span>
<span class="quote">&gt; @@ -286,7 +286,7 @@ void iommu_dma_free(struct device *dev, struct page **pages, size_t size,</span>
<span class="quote">&gt;   *	   or NULL on failure.</span>
<span class="quote">&gt;   */</span>
<span class="quote">&gt;  struct page **iommu_dma_alloc(struct device *dev, size_t size, gfp_t gfp,</span>
<span class="quote">&gt; -		struct dma_attrs *attrs, int prot, dma_addr_t *handle,</span>
<span class="quote">&gt; +		unsigned long attrs, int prot, dma_addr_t *handle,</span>
<span class="quote">&gt;  		void (*flush_page)(struct device *, const void *, phys_addr_t))</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	struct iommu_domain *domain = iommu_get_domain_for_dev(dev);</span>
<span class="quote">&gt; @@ -400,7 +400,7 @@ dma_addr_t iommu_dma_map_page(struct device *dev, struct page *page,</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  void iommu_dma_unmap_page(struct device *dev, dma_addr_t handle, size_t size,</span>
<span class="quote">&gt; -		enum dma_data_direction dir, struct dma_attrs *attrs)</span>
<span class="quote">&gt; +		enum dma_data_direction dir, unsigned long attrs)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	__iommu_dma_unmap(iommu_get_domain_for_dev(dev), handle);</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt; @@ -560,7 +560,7 @@ out_restore_sg:</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  void iommu_dma_unmap_sg(struct device *dev, struct scatterlist *sg, int nents,</span>
<span class="quote">&gt; -		enum dma_data_direction dir, struct dma_attrs *attrs)</span>
<span class="quote">&gt; +		enum dma_data_direction dir, unsigned long attrs)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	/*</span>
<span class="quote">&gt;  	 * The scatterlist segments are mapped into a single</span>
<span class="quote">&gt; diff --git a/drivers/xen/swiotlb-xen.c b/drivers/xen/swiotlb-xen.c</span>
<span class="quote">&gt; index 7399782c0998..87e6035c9e81 100644</span>
<span class="quote">&gt; --- a/drivers/xen/swiotlb-xen.c</span>
<span class="quote">&gt; +++ b/drivers/xen/swiotlb-xen.c</span>
<span class="quote">&gt; @@ -294,7 +294,7 @@ error:</span>
<span class="quote">&gt;  void *</span>
<span class="quote">&gt;  xen_swiotlb_alloc_coherent(struct device *hwdev, size_t size,</span>
<span class="quote">&gt;  			   dma_addr_t *dma_handle, gfp_t flags,</span>
<span class="quote">&gt; -			   struct dma_attrs *attrs)</span>
<span class="quote">&gt; +			   unsigned long attrs)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	void *ret;</span>
<span class="quote">&gt;  	int order = get_order(size);</span>
<span class="quote">&gt; @@ -346,7 +346,7 @@ EXPORT_SYMBOL_GPL(xen_swiotlb_alloc_coherent);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  void</span>
<span class="quote">&gt;  xen_swiotlb_free_coherent(struct device *hwdev, size_t size, void *vaddr,</span>
<span class="quote">&gt; -			  dma_addr_t dev_addr, struct dma_attrs *attrs)</span>
<span class="quote">&gt; +			  dma_addr_t dev_addr, unsigned long attrs)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	int order = get_order(size);</span>
<span class="quote">&gt;  	phys_addr_t phys;</span>
<span class="quote">&gt; @@ -378,7 +378,7 @@ EXPORT_SYMBOL_GPL(xen_swiotlb_free_coherent);</span>
<span class="quote">&gt;  dma_addr_t xen_swiotlb_map_page(struct device *dev, struct page *page,</span>
<span class="quote">&gt;  				unsigned long offset, size_t size,</span>
<span class="quote">&gt;  				enum dma_data_direction dir,</span>
<span class="quote">&gt; -				struct dma_attrs *attrs)</span>
<span class="quote">&gt; +				unsigned long attrs)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	phys_addr_t map, phys = page_to_phys(page) + offset;</span>
<span class="quote">&gt;  	dma_addr_t dev_addr = xen_phys_to_bus(phys);</span>
<span class="quote">&gt; @@ -434,7 +434,7 @@ EXPORT_SYMBOL_GPL(xen_swiotlb_map_page);</span>
<span class="quote">&gt;   */</span>
<span class="quote">&gt;  static void xen_unmap_single(struct device *hwdev, dma_addr_t dev_addr,</span>
<span class="quote">&gt;  			     size_t size, enum dma_data_direction dir,</span>
<span class="quote">&gt; -				 struct dma_attrs *attrs)</span>
<span class="quote">&gt; +			     unsigned long attrs)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	phys_addr_t paddr = xen_bus_to_phys(dev_addr);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; @@ -462,7 +462,7 @@ static void xen_unmap_single(struct device *hwdev, dma_addr_t dev_addr,</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  void xen_swiotlb_unmap_page(struct device *hwdev, dma_addr_t dev_addr,</span>
<span class="quote">&gt;  			    size_t size, enum dma_data_direction dir,</span>
<span class="quote">&gt; -			    struct dma_attrs *attrs)</span>
<span class="quote">&gt; +			    unsigned long attrs)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	xen_unmap_single(hwdev, dev_addr, size, dir, attrs);</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt; @@ -538,7 +538,7 @@ EXPORT_SYMBOL_GPL(xen_swiotlb_sync_single_for_device);</span>
<span class="quote">&gt;  int</span>
<span class="quote">&gt;  xen_swiotlb_map_sg_attrs(struct device *hwdev, struct scatterlist *sgl,</span>
<span class="quote">&gt;  			 int nelems, enum dma_data_direction dir,</span>
<span class="quote">&gt; -			 struct dma_attrs *attrs)</span>
<span class="quote">&gt; +			 unsigned long attrs)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	struct scatterlist *sg;</span>
<span class="quote">&gt;  	int i;</span>
<span class="quote">&gt; @@ -599,7 +599,7 @@ EXPORT_SYMBOL_GPL(xen_swiotlb_map_sg_attrs);</span>
<span class="quote">&gt;  void</span>
<span class="quote">&gt;  xen_swiotlb_unmap_sg_attrs(struct device *hwdev, struct scatterlist *sgl,</span>
<span class="quote">&gt;  			   int nelems, enum dma_data_direction dir,</span>
<span class="quote">&gt; -			   struct dma_attrs *attrs)</span>
<span class="quote">&gt; +			   unsigned long attrs)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	struct scatterlist *sg;</span>
<span class="quote">&gt;  	int i;</span>
<span class="quote">&gt; diff --git a/include/linux/dma-attrs.h b/include/linux/dma-attrs.h</span>
<span class="quote">&gt; deleted file mode 100644</span>
<span class="quote">&gt; index 5246239a4953..000000000000</span>
<span class="quote">&gt; --- a/include/linux/dma-attrs.h</span>
<span class="quote">&gt; +++ /dev/null</span>
<span class="quote">&gt; @@ -1,71 +0,0 @@</span>
<span class="quote">&gt; -#ifndef _DMA_ATTR_H</span>
<span class="quote">&gt; -#define _DMA_ATTR_H</span>
<span class="quote">&gt; -</span>
<span class="quote">&gt; -#include &lt;linux/bitmap.h&gt;</span>
<span class="quote">&gt; -#include &lt;linux/bitops.h&gt;</span>
<span class="quote">&gt; -#include &lt;linux/bug.h&gt;</span>
<span class="quote">&gt; -</span>
<span class="quote">&gt; -/**</span>
<span class="quote">&gt; - * an enum dma_attr represents an attribute associated with a DMA</span>
<span class="quote">&gt; - * mapping. The semantics of each attribute should be defined in</span>
<span class="quote">&gt; - * Documentation/DMA-attributes.txt.</span>
<span class="quote">&gt; - */</span>
<span class="quote">&gt; -enum dma_attr {</span>
<span class="quote">&gt; -	DMA_ATTR_WRITE_BARRIER,</span>
<span class="quote">&gt; -	DMA_ATTR_WEAK_ORDERING,</span>
<span class="quote">&gt; -	DMA_ATTR_WRITE_COMBINE,</span>
<span class="quote">&gt; -	DMA_ATTR_NON_CONSISTENT,</span>
<span class="quote">&gt; -	DMA_ATTR_NO_KERNEL_MAPPING,</span>
<span class="quote">&gt; -	DMA_ATTR_SKIP_CPU_SYNC,</span>
<span class="quote">&gt; -	DMA_ATTR_FORCE_CONTIGUOUS,</span>
<span class="quote">&gt; -	DMA_ATTR_ALLOC_SINGLE_PAGES,</span>
<span class="quote">&gt; -	DMA_ATTR_MAX,</span>
<span class="quote">&gt; -};</span>
<span class="quote">&gt; -</span>
<span class="quote">&gt; -#define __DMA_ATTRS_LONGS BITS_TO_LONGS(DMA_ATTR_MAX)</span>
<span class="quote">&gt; -</span>
<span class="quote">&gt; -/**</span>
<span class="quote">&gt; - * struct dma_attrs - an opaque container for DMA attributes</span>
<span class="quote">&gt; - * @flags - bitmask representing a collection of enum dma_attr</span>
<span class="quote">&gt; - */</span>
<span class="quote">&gt; -struct dma_attrs {</span>
<span class="quote">&gt; -	unsigned long flags[__DMA_ATTRS_LONGS];</span>
<span class="quote">&gt; -};</span>
<span class="quote">&gt; -</span>
<span class="quote">&gt; -#define DEFINE_DMA_ATTRS(x) 					\</span>
<span class="quote">&gt; -	struct dma_attrs x = {					\</span>
<span class="quote">&gt; -		.flags = { [0 ... __DMA_ATTRS_LONGS-1] = 0 },	\</span>
<span class="quote">&gt; -	}</span>
<span class="quote">&gt; -</span>
<span class="quote">&gt; -static inline void init_dma_attrs(struct dma_attrs *attrs)</span>
<span class="quote">&gt; -{</span>
<span class="quote">&gt; -	bitmap_zero(attrs-&gt;flags, __DMA_ATTRS_LONGS);</span>
<span class="quote">&gt; -}</span>
<span class="quote">&gt; -</span>
<span class="quote">&gt; -/**</span>
<span class="quote">&gt; - * dma_set_attr - set a specific attribute</span>
<span class="quote">&gt; - * @attr: attribute to set</span>
<span class="quote">&gt; - * @attrs: struct dma_attrs (may be NULL)</span>
<span class="quote">&gt; - */</span>
<span class="quote">&gt; -static inline void dma_set_attr(enum dma_attr attr, struct dma_attrs *attrs)</span>
<span class="quote">&gt; -{</span>
<span class="quote">&gt; -	if (attrs == NULL)</span>
<span class="quote">&gt; -		return;</span>
<span class="quote">&gt; -	BUG_ON(attr &gt;= DMA_ATTR_MAX);</span>
<span class="quote">&gt; -	__set_bit(attr, attrs-&gt;flags);</span>
<span class="quote">&gt; -}</span>
<span class="quote">&gt; -</span>
<span class="quote">&gt; -/**</span>
<span class="quote">&gt; - * dma_get_attr - check for a specific attribute</span>
<span class="quote">&gt; - * @attr: attribute to set</span>
<span class="quote">&gt; - * @attrs: struct dma_attrs (may be NULL)</span>
<span class="quote">&gt; - */</span>
<span class="quote">&gt; -static inline int dma_get_attr(enum dma_attr attr, struct dma_attrs *attrs)</span>
<span class="quote">&gt; -{</span>
<span class="quote">&gt; -	if (attrs == NULL)</span>
<span class="quote">&gt; -		return 0;</span>
<span class="quote">&gt; -	BUG_ON(attr &gt;= DMA_ATTR_MAX);</span>
<span class="quote">&gt; -	return test_bit(attr, attrs-&gt;flags);</span>
<span class="quote">&gt; -}</span>
<span class="quote">&gt; -</span>
<span class="quote">&gt; -#endif /* _DMA_ATTR_H */</span>
<span class="quote">&gt; diff --git a/include/linux/dma-iommu.h b/include/linux/dma-iommu.h</span>
<span class="quote">&gt; index 8443bbb5c071..81c5c8d167ad 100644</span>
<span class="quote">&gt; --- a/include/linux/dma-iommu.h</span>
<span class="quote">&gt; +++ b/include/linux/dma-iommu.h</span>
<span class="quote">&gt; @@ -39,7 +39,7 @@ int dma_direction_to_prot(enum dma_data_direction dir, bool coherent);</span>
<span class="quote">&gt;   * the arch code to take care of attributes and cache maintenance</span>
<span class="quote">&gt;   */</span>
<span class="quote">&gt;  struct page **iommu_dma_alloc(struct device *dev, size_t size, gfp_t gfp,</span>
<span class="quote">&gt; -		struct dma_attrs *attrs, int prot, dma_addr_t *handle,</span>
<span class="quote">&gt; +		unsigned long attrs, int prot, dma_addr_t *handle,</span>
<span class="quote">&gt;  		void (*flush_page)(struct device *, const void *, phys_addr_t));</span>
<span class="quote">&gt;  void iommu_dma_free(struct device *dev, struct page **pages, size_t size,</span>
<span class="quote">&gt;  		dma_addr_t *handle);</span>
<span class="quote">&gt; @@ -56,9 +56,9 @@ int iommu_dma_map_sg(struct device *dev, struct scatterlist *sg,</span>
<span class="quote">&gt;   * directly as DMA mapping callbacks for simplicity</span>
<span class="quote">&gt;   */</span>
<span class="quote">&gt;  void iommu_dma_unmap_page(struct device *dev, dma_addr_t handle, size_t size,</span>
<span class="quote">&gt; -		enum dma_data_direction dir, struct dma_attrs *attrs);</span>
<span class="quote">&gt; +		enum dma_data_direction dir, unsigned long attrs);</span>
<span class="quote">&gt;  void iommu_dma_unmap_sg(struct device *dev, struct scatterlist *sg, int nents,</span>
<span class="quote">&gt; -		enum dma_data_direction dir, struct dma_attrs *attrs);</span>
<span class="quote">&gt; +		enum dma_data_direction dir, unsigned long attrs);</span>
<span class="quote">&gt;  int iommu_dma_supported(struct device *dev, u64 mask);</span>
<span class="quote">&gt;  int iommu_dma_mapping_error(struct device *dev, dma_addr_t dma_addr);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; diff --git a/include/linux/dma-mapping.h b/include/linux/dma-mapping.h</span>
<span class="quote">&gt; index 71c1b215ef66..19e581d5f8b4 100644</span>
<span class="quote">&gt; --- a/include/linux/dma-mapping.h</span>
<span class="quote">&gt; +++ b/include/linux/dma-mapping.h</span>
<span class="quote">&gt; @@ -5,13 +5,25 @@</span>
<span class="quote">&gt;  #include &lt;linux/string.h&gt;</span>
<span class="quote">&gt;  #include &lt;linux/device.h&gt;</span>
<span class="quote">&gt;  #include &lt;linux/err.h&gt;</span>
<span class="quote">&gt; -#include &lt;linux/dma-attrs.h&gt;</span>
<span class="quote">&gt;  #include &lt;linux/dma-debug.h&gt;</span>
<span class="quote">&gt;  #include &lt;linux/dma-direction.h&gt;</span>
<span class="quote">&gt;  #include &lt;linux/scatterlist.h&gt;</span>
<span class="quote">&gt;  #include &lt;linux/kmemcheck.h&gt;</span>
<span class="quote">&gt;  #include &lt;linux/bug.h&gt;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; +/**</span>
<span class="quote">&gt; + * List of possible attributes associated with a DMA mapping. The semantics</span>
<span class="quote">&gt; + * of each attribute should be defined in Documentation/DMA-attributes.txt.</span>
<span class="quote">&gt; + */</span>
<span class="quote">&gt; +#define DMA_ATTR_WRITE_BARRIER		BIT(1)</span>
<span class="quote">&gt; +#define DMA_ATTR_WEAK_ORDERING		BIT(2)</span>
<span class="quote">&gt; +#define DMA_ATTR_WRITE_COMBINE		BIT(3)</span>
<span class="quote">&gt; +#define DMA_ATTR_NON_CONSISTENT		BIT(4)</span>
<span class="quote">&gt; +#define DMA_ATTR_NO_KERNEL_MAPPING	BIT(5)</span>
<span class="quote">&gt; +#define DMA_ATTR_SKIP_CPU_SYNC		BIT(6)</span>
<span class="quote">&gt; +#define DMA_ATTR_FORCE_CONTIGUOUS	BIT(7)</span>
<span class="quote">&gt; +#define DMA_ATTR_ALLOC_SINGLE_PAGES	BIT(8)</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt;  /*</span>
<span class="quote">&gt;   * A dma_addr_t can hold any valid DMA or bus address for the platform.</span>
<span class="quote">&gt;   * It can be given to a device to use as a DMA source or target.  A CPU cannot</span>
<span class="quote">&gt; @@ -21,34 +33,35 @@</span>
<span class="quote">&gt;  struct dma_map_ops {</span>
<span class="quote">&gt;  	void* (*alloc)(struct device *dev, size_t size,</span>
<span class="quote">&gt;  				dma_addr_t *dma_handle, gfp_t gfp,</span>
<span class="quote">&gt; -				struct dma_attrs *attrs);</span>
<span class="quote">&gt; +				unsigned long attrs);</span>
<span class="quote">&gt;  	void (*free)(struct device *dev, size_t size,</span>
<span class="quote">&gt;  			      void *vaddr, dma_addr_t dma_handle,</span>
<span class="quote">&gt; -			      struct dma_attrs *attrs);</span>
<span class="quote">&gt; +			      unsigned long attrs);</span>
<span class="quote">&gt;  	int (*mmap)(struct device *, struct vm_area_struct *,</span>
<span class="quote">&gt; -			  void *, dma_addr_t, size_t, struct dma_attrs *attrs);</span>
<span class="quote">&gt; +			  void *, dma_addr_t, size_t,</span>
<span class="quote">&gt; +			  unsigned long attrs);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	int (*get_sgtable)(struct device *dev, struct sg_table *sgt, void *,</span>
<span class="quote">&gt; -			   dma_addr_t, size_t, struct dma_attrs *attrs);</span>
<span class="quote">&gt; +			   dma_addr_t, size_t, unsigned long attrs);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	dma_addr_t (*map_page)(struct device *dev, struct page *page,</span>
<span class="quote">&gt;  			       unsigned long offset, size_t size,</span>
<span class="quote">&gt;  			       enum dma_data_direction dir,</span>
<span class="quote">&gt; -			       struct dma_attrs *attrs);</span>
<span class="quote">&gt; +			       unsigned long attrs);</span>
<span class="quote">&gt;  	void (*unmap_page)(struct device *dev, dma_addr_t dma_handle,</span>
<span class="quote">&gt;  			   size_t size, enum dma_data_direction dir,</span>
<span class="quote">&gt; -			   struct dma_attrs *attrs);</span>
<span class="quote">&gt; +			   unsigned long attrs);</span>
<span class="quote">&gt;  	/*</span>
<span class="quote">&gt;  	 * map_sg returns 0 on error and a value &gt; 0 on success.</span>
<span class="quote">&gt;  	 * It should never return a value &lt; 0.</span>
<span class="quote">&gt;  	 */</span>
<span class="quote">&gt;  	int (*map_sg)(struct device *dev, struct scatterlist *sg,</span>
<span class="quote">&gt;  		      int nents, enum dma_data_direction dir,</span>
<span class="quote">&gt; -		      struct dma_attrs *attrs);</span>
<span class="quote">&gt; +		      unsigned long attrs);</span>
<span class="quote">&gt;  	void (*unmap_sg)(struct device *dev,</span>
<span class="quote">&gt;  			 struct scatterlist *sg, int nents,</span>
<span class="quote">&gt;  			 enum dma_data_direction dir,</span>
<span class="quote">&gt; -			 struct dma_attrs *attrs);</span>
<span class="quote">&gt; +			 unsigned long attrs);</span>
<span class="quote">&gt;  	void (*sync_single_for_cpu)(struct device *dev,</span>
<span class="quote">&gt;  				    dma_addr_t dma_handle, size_t size,</span>
<span class="quote">&gt;  				    enum dma_data_direction dir);</span>
<span class="quote">&gt; @@ -88,6 +101,16 @@ static inline int is_device_dma_capable(struct device *dev)</span>
<span class="quote">&gt;  	return dev-&gt;dma_mask != NULL &amp;&amp; *dev-&gt;dma_mask != DMA_MASK_NONE;</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; +/**</span>
<span class="quote">&gt; + * dma_get_attr - check for a specific attribute</span>
<span class="quote">&gt; + * @attr: attribute to look for</span>
<span class="quote">&gt; + * @attrs: attributes to check within</span>
<span class="quote">&gt; + */</span>
<span class="quote">&gt; +static inline bool dma_get_attr(unsigned long attr, unsigned long attrs)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	return !!(attr &amp; attrs);</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt;  #ifdef CONFIG_HAVE_GENERIC_DMA_COHERENT</span>
<span class="quote">&gt;  /*</span>
<span class="quote">&gt;   * These three functions are only for dma allocator.</span>
<span class="quote">&gt; @@ -123,7 +146,7 @@ static inline struct dma_map_ops *get_dma_ops(struct device *dev)</span>
<span class="quote">&gt;  static inline dma_addr_t dma_map_single_attrs(struct device *dev, void *ptr,</span>
<span class="quote">&gt;  					      size_t size,</span>
<span class="quote">&gt;  					      enum dma_data_direction dir,</span>
<span class="quote">&gt; -					      struct dma_attrs *attrs)</span>
<span class="quote">&gt; +					      unsigned long attrs)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	struct dma_map_ops *ops = get_dma_ops(dev);</span>
<span class="quote">&gt;  	dma_addr_t addr;</span>
<span class="quote">&gt; @@ -142,7 +165,7 @@ static inline dma_addr_t dma_map_single_attrs(struct device *dev, void *ptr,</span>
<span class="quote">&gt;  static inline void dma_unmap_single_attrs(struct device *dev, dma_addr_t addr,</span>
<span class="quote">&gt;  					  size_t size,</span>
<span class="quote">&gt;  					  enum dma_data_direction dir,</span>
<span class="quote">&gt; -					  struct dma_attrs *attrs)</span>
<span class="quote">&gt; +					  unsigned long attrs)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	struct dma_map_ops *ops = get_dma_ops(dev);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; @@ -158,7 +181,7 @@ static inline void dma_unmap_single_attrs(struct device *dev, dma_addr_t addr,</span>
<span class="quote">&gt;   */</span>
<span class="quote">&gt;  static inline int dma_map_sg_attrs(struct device *dev, struct scatterlist *sg,</span>
<span class="quote">&gt;  				   int nents, enum dma_data_direction dir,</span>
<span class="quote">&gt; -				   struct dma_attrs *attrs)</span>
<span class="quote">&gt; +				   unsigned long attrs)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	struct dma_map_ops *ops = get_dma_ops(dev);</span>
<span class="quote">&gt;  	int i, ents;</span>
<span class="quote">&gt; @@ -176,7 +199,7 @@ static inline int dma_map_sg_attrs(struct device *dev, struct scatterlist *sg,</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  static inline void dma_unmap_sg_attrs(struct device *dev, struct scatterlist *sg,</span>
<span class="quote">&gt;  				      int nents, enum dma_data_direction dir,</span>
<span class="quote">&gt; -				      struct dma_attrs *attrs)</span>
<span class="quote">&gt; +				      unsigned long attrs)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	struct dma_map_ops *ops = get_dma_ops(dev);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; @@ -195,7 +218,7 @@ static inline dma_addr_t dma_map_page(struct device *dev, struct page *page,</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	kmemcheck_mark_initialized(page_address(page) + offset, size);</span>
<span class="quote">&gt;  	BUG_ON(!valid_dma_direction(dir));</span>
<span class="quote">&gt; -	addr = ops-&gt;map_page(dev, page, offset, size, dir, NULL);</span>
<span class="quote">&gt; +	addr = ops-&gt;map_page(dev, page, offset, size, dir, 0);</span>
<span class="quote">&gt;  	debug_dma_map_page(dev, page, offset, size, dir, addr, false);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	return addr;</span>
<span class="quote">&gt; @@ -208,7 +231,7 @@ static inline void dma_unmap_page(struct device *dev, dma_addr_t addr,</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	BUG_ON(!valid_dma_direction(dir));</span>
<span class="quote">&gt;  	if (ops-&gt;unmap_page)</span>
<span class="quote">&gt; -		ops-&gt;unmap_page(dev, addr, size, dir, NULL);</span>
<span class="quote">&gt; +		ops-&gt;unmap_page(dev, addr, size, dir, 0);</span>
<span class="quote">&gt;  	debug_dma_unmap_page(dev, addr, size, dir, false);</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; @@ -289,10 +312,10 @@ dma_sync_sg_for_device(struct device *dev, struct scatterlist *sg,</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; -#define dma_map_single(d, a, s, r) dma_map_single_attrs(d, a, s, r, NULL)</span>
<span class="quote">&gt; -#define dma_unmap_single(d, a, s, r) dma_unmap_single_attrs(d, a, s, r, NULL)</span>
<span class="quote">&gt; -#define dma_map_sg(d, s, n, r) dma_map_sg_attrs(d, s, n, r, NULL)</span>
<span class="quote">&gt; -#define dma_unmap_sg(d, s, n, r) dma_unmap_sg_attrs(d, s, n, r, NULL)</span>
<span class="quote">&gt; +#define dma_map_single(d, a, s, r) dma_map_single_attrs(d, a, s, r, 0)</span>
<span class="quote">&gt; +#define dma_unmap_single(d, a, s, r) dma_unmap_single_attrs(d, a, s, r, 0)</span>
<span class="quote">&gt; +#define dma_map_sg(d, s, n, r) dma_map_sg_attrs(d, s, n, r, 0)</span>
<span class="quote">&gt; +#define dma_unmap_sg(d, s, n, r) dma_unmap_sg_attrs(d, s, n, r, 0)</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  extern int dma_common_mmap(struct device *dev, struct vm_area_struct *vma,</span>
<span class="quote">&gt;  			   void *cpu_addr, dma_addr_t dma_addr, size_t size);</span>
<span class="quote">&gt; @@ -321,7 +344,7 @@ void dma_common_free_remap(void *cpu_addr, size_t size, unsigned long vm_flags);</span>
<span class="quote">&gt;   */</span>
<span class="quote">&gt;  static inline int</span>
<span class="quote">&gt;  dma_mmap_attrs(struct device *dev, struct vm_area_struct *vma, void *cpu_addr,</span>
<span class="quote">&gt; -	       dma_addr_t dma_addr, size_t size, struct dma_attrs *attrs)</span>
<span class="quote">&gt; +	       dma_addr_t dma_addr, size_t size, unsigned long attrs)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	struct dma_map_ops *ops = get_dma_ops(dev);</span>
<span class="quote">&gt;  	BUG_ON(!ops);</span>
<span class="quote">&gt; @@ -330,7 +353,7 @@ dma_mmap_attrs(struct device *dev, struct vm_area_struct *vma, void *cpu_addr,</span>
<span class="quote">&gt;  	return dma_common_mmap(dev, vma, cpu_addr, dma_addr, size);</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; -#define dma_mmap_coherent(d, v, c, h, s) dma_mmap_attrs(d, v, c, h, s, NULL)</span>
<span class="quote">&gt; +#define dma_mmap_coherent(d, v, c, h, s) dma_mmap_attrs(d, v, c, h, s, 0)</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  int</span>
<span class="quote">&gt;  dma_common_get_sgtable(struct device *dev, struct sg_table *sgt,</span>
<span class="quote">&gt; @@ -338,7 +361,8 @@ dma_common_get_sgtable(struct device *dev, struct sg_table *sgt,</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  static inline int</span>
<span class="quote">&gt;  dma_get_sgtable_attrs(struct device *dev, struct sg_table *sgt, void *cpu_addr,</span>
<span class="quote">&gt; -		      dma_addr_t dma_addr, size_t size, struct dma_attrs *attrs)</span>
<span class="quote">&gt; +		      dma_addr_t dma_addr, size_t size,</span>
<span class="quote">&gt; +		      unsigned long attrs)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	struct dma_map_ops *ops = get_dma_ops(dev);</span>
<span class="quote">&gt;  	BUG_ON(!ops);</span>
<span class="quote">&gt; @@ -348,7 +372,7 @@ dma_get_sgtable_attrs(struct device *dev, struct sg_table *sgt, void *cpu_addr,</span>
<span class="quote">&gt;  	return dma_common_get_sgtable(dev, sgt, cpu_addr, dma_addr, size);</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; -#define dma_get_sgtable(d, t, v, h, s) dma_get_sgtable_attrs(d, t, v, h, s, NULL)</span>
<span class="quote">&gt; +#define dma_get_sgtable(d, t, v, h, s) dma_get_sgtable_attrs(d, t, v, h, s, 0)</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  #ifndef arch_dma_alloc_attrs</span>
<span class="quote">&gt;  #define arch_dma_alloc_attrs(dev, flag)	(true)</span>
<span class="quote">&gt; @@ -356,7 +380,7 @@ dma_get_sgtable_attrs(struct device *dev, struct sg_table *sgt, void *cpu_addr,</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  static inline void *dma_alloc_attrs(struct device *dev, size_t size,</span>
<span class="quote">&gt;  				       dma_addr_t *dma_handle, gfp_t flag,</span>
<span class="quote">&gt; -				       struct dma_attrs *attrs)</span>
<span class="quote">&gt; +				       unsigned long attrs)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	struct dma_map_ops *ops = get_dma_ops(dev);</span>
<span class="quote">&gt;  	void *cpu_addr;</span>
<span class="quote">&gt; @@ -378,7 +402,7 @@ static inline void *dma_alloc_attrs(struct device *dev, size_t size,</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  static inline void dma_free_attrs(struct device *dev, size_t size,</span>
<span class="quote">&gt;  				     void *cpu_addr, dma_addr_t dma_handle,</span>
<span class="quote">&gt; -				     struct dma_attrs *attrs)</span>
<span class="quote">&gt; +				     unsigned long attrs)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	struct dma_map_ops *ops = get_dma_ops(dev);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; @@ -398,31 +422,27 @@ static inline void dma_free_attrs(struct device *dev, size_t size,</span>
<span class="quote">&gt;  static inline void *dma_alloc_coherent(struct device *dev, size_t size,</span>
<span class="quote">&gt;  		dma_addr_t *dma_handle, gfp_t flag)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt; -	return dma_alloc_attrs(dev, size, dma_handle, flag, NULL);</span>
<span class="quote">&gt; +	return dma_alloc_attrs(dev, size, dma_handle, flag, 0);</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  static inline void dma_free_coherent(struct device *dev, size_t size,</span>
<span class="quote">&gt;  		void *cpu_addr, dma_addr_t dma_handle)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt; -	return dma_free_attrs(dev, size, cpu_addr, dma_handle, NULL);</span>
<span class="quote">&gt; +	return dma_free_attrs(dev, size, cpu_addr, dma_handle, 0);</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  static inline void *dma_alloc_noncoherent(struct device *dev, size_t size,</span>
<span class="quote">&gt;  		dma_addr_t *dma_handle, gfp_t gfp)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt; -	DEFINE_DMA_ATTRS(attrs);</span>
<span class="quote">&gt; -</span>
<span class="quote">&gt; -	dma_set_attr(DMA_ATTR_NON_CONSISTENT, &amp;attrs);</span>
<span class="quote">&gt; -	return dma_alloc_attrs(dev, size, dma_handle, gfp, &amp;attrs);</span>
<span class="quote">&gt; +	return dma_alloc_attrs(dev, size, dma_handle, gfp,</span>
<span class="quote">&gt; +			       DMA_ATTR_NON_CONSISTENT);</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  static inline void dma_free_noncoherent(struct device *dev, size_t size,</span>
<span class="quote">&gt;  		void *cpu_addr, dma_addr_t dma_handle)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt; -	DEFINE_DMA_ATTRS(attrs);</span>
<span class="quote">&gt; -</span>
<span class="quote">&gt; -	dma_set_attr(DMA_ATTR_NON_CONSISTENT, &amp;attrs);</span>
<span class="quote">&gt; -	dma_free_attrs(dev, size, cpu_addr, dma_handle, &amp;attrs);</span>
<span class="quote">&gt; +	dma_free_attrs(dev, size, cpu_addr, dma_handle,</span>
<span class="quote">&gt; +		       DMA_ATTR_NON_CONSISTENT);</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  static inline int dma_mapping_error(struct device *dev, dma_addr_t dma_addr)</span>
<span class="quote">&gt; @@ -646,9 +666,8 @@ static inline void dmam_release_declared_memory(struct device *dev)</span>
<span class="quote">&gt;  static inline void *dma_alloc_wc(struct device *dev, size_t size,</span>
<span class="quote">&gt;  				 dma_addr_t *dma_addr, gfp_t gfp)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt; -	DEFINE_DMA_ATTRS(attrs);</span>
<span class="quote">&gt; -	dma_set_attr(DMA_ATTR_WRITE_COMBINE, &amp;attrs);</span>
<span class="quote">&gt; -	return dma_alloc_attrs(dev, size, dma_addr, gfp, &amp;attrs);</span>
<span class="quote">&gt; +	return dma_alloc_attrs(dev, size, dma_addr, gfp,</span>
<span class="quote">&gt; +			       DMA_ATTR_WRITE_COMBINE);</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;  #ifndef dma_alloc_writecombine</span>
<span class="quote">&gt;  #define dma_alloc_writecombine dma_alloc_wc</span>
<span class="quote">&gt; @@ -657,9 +676,8 @@ static inline void *dma_alloc_wc(struct device *dev, size_t size,</span>
<span class="quote">&gt;  static inline void dma_free_wc(struct device *dev, size_t size,</span>
<span class="quote">&gt;  			       void *cpu_addr, dma_addr_t dma_addr)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt; -	DEFINE_DMA_ATTRS(attrs);</span>
<span class="quote">&gt; -	dma_set_attr(DMA_ATTR_WRITE_COMBINE, &amp;attrs);</span>
<span class="quote">&gt; -	return dma_free_attrs(dev, size, cpu_addr, dma_addr, &amp;attrs);</span>
<span class="quote">&gt; +	return dma_free_attrs(dev, size, cpu_addr, dma_addr,</span>
<span class="quote">&gt; +			      DMA_ATTR_WRITE_COMBINE);</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;  #ifndef dma_free_writecombine</span>
<span class="quote">&gt;  #define dma_free_writecombine dma_free_wc</span>
<span class="quote">&gt; @@ -670,9 +688,8 @@ static inline int dma_mmap_wc(struct device *dev,</span>
<span class="quote">&gt;  			      void *cpu_addr, dma_addr_t dma_addr,</span>
<span class="quote">&gt;  			      size_t size)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt; -	DEFINE_DMA_ATTRS(attrs);</span>
<span class="quote">&gt; -	dma_set_attr(DMA_ATTR_WRITE_COMBINE, &amp;attrs);</span>
<span class="quote">&gt; -	return dma_mmap_attrs(dev, vma, cpu_addr, dma_addr, size, &amp;attrs);</span>
<span class="quote">&gt; +	return dma_mmap_attrs(dev, vma, cpu_addr, dma_addr, size,</span>
<span class="quote">&gt; +			      DMA_ATTR_WRITE_COMBINE);</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;  #ifndef dma_mmap_writecombine</span>
<span class="quote">&gt;  #define dma_mmap_writecombine dma_mmap_wc</span>
<span class="quote">&gt; diff --git a/include/linux/swiotlb.h b/include/linux/swiotlb.h</span>
<span class="quote">&gt; index 017fced60242..5f81f8a187f2 100644</span>
<span class="quote">&gt; --- a/include/linux/swiotlb.h</span>
<span class="quote">&gt; +++ b/include/linux/swiotlb.h</span>
<span class="quote">&gt; @@ -6,7 +6,6 @@</span>
<span class="quote">&gt;  #include &lt;linux/types.h&gt;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  struct device;</span>
<span class="quote">&gt; -struct dma_attrs;</span>
<span class="quote">&gt;  struct page;</span>
<span class="quote">&gt;  struct scatterlist;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; @@ -68,10 +67,10 @@ swiotlb_free_coherent(struct device *hwdev, size_t size,</span>
<span class="quote">&gt;  extern dma_addr_t swiotlb_map_page(struct device *dev, struct page *page,</span>
<span class="quote">&gt;  				   unsigned long offset, size_t size,</span>
<span class="quote">&gt;  				   enum dma_data_direction dir,</span>
<span class="quote">&gt; -				   struct dma_attrs *attrs);</span>
<span class="quote">&gt; +				   unsigned long attrs);</span>
<span class="quote">&gt;  extern void swiotlb_unmap_page(struct device *hwdev, dma_addr_t dev_addr,</span>
<span class="quote">&gt;  			       size_t size, enum dma_data_direction dir,</span>
<span class="quote">&gt; -			       struct dma_attrs *attrs);</span>
<span class="quote">&gt; +			       unsigned long attrs);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  extern int</span>
<span class="quote">&gt;  swiotlb_map_sg(struct device *hwdev, struct scatterlist *sg, int nents,</span>
<span class="quote">&gt; @@ -83,12 +82,13 @@ swiotlb_unmap_sg(struct device *hwdev, struct scatterlist *sg, int nents,</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  extern int</span>
<span class="quote">&gt;  swiotlb_map_sg_attrs(struct device *hwdev, struct scatterlist *sgl, int nelems,</span>
<span class="quote">&gt; -		     enum dma_data_direction dir, struct dma_attrs *attrs);</span>
<span class="quote">&gt; +		     enum dma_data_direction dir,</span>
<span class="quote">&gt; +		     unsigned long attrs);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  extern void</span>
<span class="quote">&gt;  swiotlb_unmap_sg_attrs(struct device *hwdev, struct scatterlist *sgl,</span>
<span class="quote">&gt;  		       int nelems, enum dma_data_direction dir,</span>
<span class="quote">&gt; -		       struct dma_attrs *attrs);</span>
<span class="quote">&gt; +		       unsigned long attrs);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  extern void</span>
<span class="quote">&gt;  swiotlb_sync_single_for_cpu(struct device *hwdev, dma_addr_t dev_addr,</span>
<span class="quote">&gt; diff --git a/include/xen/swiotlb-xen.h b/include/xen/swiotlb-xen.h</span>
<span class="quote">&gt; index 8b2eb93ae8ba..7c35e279d1e3 100644</span>
<span class="quote">&gt; --- a/include/xen/swiotlb-xen.h</span>
<span class="quote">&gt; +++ b/include/xen/swiotlb-xen.h</span>
<span class="quote">&gt; @@ -9,30 +9,30 @@ extern int xen_swiotlb_init(int verbose, bool early);</span>
<span class="quote">&gt;  extern void</span>
<span class="quote">&gt;  *xen_swiotlb_alloc_coherent(struct device *hwdev, size_t size,</span>
<span class="quote">&gt;  			    dma_addr_t *dma_handle, gfp_t flags,</span>
<span class="quote">&gt; -			    struct dma_attrs *attrs);</span>
<span class="quote">&gt; +			    unsigned long attrs);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  extern void</span>
<span class="quote">&gt;  xen_swiotlb_free_coherent(struct device *hwdev, size_t size,</span>
<span class="quote">&gt;  			  void *vaddr, dma_addr_t dma_handle,</span>
<span class="quote">&gt; -			  struct dma_attrs *attrs);</span>
<span class="quote">&gt; +			  unsigned long attrs);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  extern dma_addr_t xen_swiotlb_map_page(struct device *dev, struct page *page,</span>
<span class="quote">&gt;  				       unsigned long offset, size_t size,</span>
<span class="quote">&gt;  				       enum dma_data_direction dir,</span>
<span class="quote">&gt; -				       struct dma_attrs *attrs);</span>
<span class="quote">&gt; +				       unsigned long attrs);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  extern void xen_swiotlb_unmap_page(struct device *hwdev, dma_addr_t dev_addr,</span>
<span class="quote">&gt;  				   size_t size, enum dma_data_direction dir,</span>
<span class="quote">&gt; -				   struct dma_attrs *attrs);</span>
<span class="quote">&gt; +				   unsigned long attrs);</span>
<span class="quote">&gt;  extern int</span>
<span class="quote">&gt;  xen_swiotlb_map_sg_attrs(struct device *hwdev, struct scatterlist *sgl,</span>
<span class="quote">&gt;  			 int nelems, enum dma_data_direction dir,</span>
<span class="quote">&gt; -			 struct dma_attrs *attrs);</span>
<span class="quote">&gt; +			 unsigned long attrs);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  extern void</span>
<span class="quote">&gt;  xen_swiotlb_unmap_sg_attrs(struct device *hwdev, struct scatterlist *sgl,</span>
<span class="quote">&gt;  			   int nelems, enum dma_data_direction dir,</span>
<span class="quote">&gt; -			   struct dma_attrs *attrs);</span>
<span class="quote">&gt; +			   unsigned long attrs);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  extern void</span>
<span class="quote">&gt;  xen_swiotlb_sync_single_for_cpu(struct device *hwdev, dma_addr_t dev_addr,</span>
<span class="quote">&gt; diff --git a/lib/dma-noop.c b/lib/dma-noop.c</span>
<span class="quote">&gt; index 72145646857e..3d766e78fbe2 100644</span>
<span class="quote">&gt; --- a/lib/dma-noop.c</span>
<span class="quote">&gt; +++ b/lib/dma-noop.c</span>
<span class="quote">&gt; @@ -10,7 +10,7 @@</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  static void *dma_noop_alloc(struct device *dev, size_t size,</span>
<span class="quote">&gt;  			    dma_addr_t *dma_handle, gfp_t gfp,</span>
<span class="quote">&gt; -			    struct dma_attrs *attrs)</span>
<span class="quote">&gt; +			    unsigned long attrs)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	void *ret;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; @@ -22,7 +22,7 @@ static void *dma_noop_alloc(struct device *dev, size_t size,</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  static void dma_noop_free(struct device *dev, size_t size,</span>
<span class="quote">&gt;  			  void *cpu_addr, dma_addr_t dma_addr,</span>
<span class="quote">&gt; -			  struct dma_attrs *attrs)</span>
<span class="quote">&gt; +			  unsigned long attrs)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	free_pages((unsigned long)cpu_addr, get_order(size));</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt; @@ -30,13 +30,14 @@ static void dma_noop_free(struct device *dev, size_t size,</span>
<span class="quote">&gt;  static dma_addr_t dma_noop_map_page(struct device *dev, struct page *page,</span>
<span class="quote">&gt;  				      unsigned long offset, size_t size,</span>
<span class="quote">&gt;  				      enum dma_data_direction dir,</span>
<span class="quote">&gt; -				      struct dma_attrs *attrs)</span>
<span class="quote">&gt; +				      unsigned long attrs)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	return page_to_phys(page) + offset;</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  static int dma_noop_map_sg(struct device *dev, struct scatterlist *sgl, int nents,</span>
<span class="quote">&gt; -			     enum dma_data_direction dir, struct dma_attrs *attrs)</span>
<span class="quote">&gt; +			     enum dma_data_direction dir,</span>
<span class="quote">&gt; +			     unsigned long attrs)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	int i;</span>
<span class="quote">&gt;  	struct scatterlist *sg;</span>
<span class="quote">&gt; diff --git a/lib/swiotlb.c b/lib/swiotlb.c</span>
<span class="quote">&gt; index 76f29ecba8f4..22e13a0e19d7 100644</span>
<span class="quote">&gt; --- a/lib/swiotlb.c</span>
<span class="quote">&gt; +++ b/lib/swiotlb.c</span>
<span class="quote">&gt; @@ -738,7 +738,7 @@ swiotlb_full(struct device *dev, size_t size, enum dma_data_direction dir,</span>
<span class="quote">&gt;  dma_addr_t swiotlb_map_page(struct device *dev, struct page *page,</span>
<span class="quote">&gt;  			    unsigned long offset, size_t size,</span>
<span class="quote">&gt;  			    enum dma_data_direction dir,</span>
<span class="quote">&gt; -			    struct dma_attrs *attrs)</span>
<span class="quote">&gt; +			    unsigned long attrs)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	phys_addr_t map, phys = page_to_phys(page) + offset;</span>
<span class="quote">&gt;  	dma_addr_t dev_addr = phys_to_dma(dev, phys);</span>
<span class="quote">&gt; @@ -807,7 +807,7 @@ static void unmap_single(struct device *hwdev, dma_addr_t dev_addr,</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  void swiotlb_unmap_page(struct device *hwdev, dma_addr_t dev_addr,</span>
<span class="quote">&gt;  			size_t size, enum dma_data_direction dir,</span>
<span class="quote">&gt; -			struct dma_attrs *attrs)</span>
<span class="quote">&gt; +			unsigned long attrs)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	unmap_single(hwdev, dev_addr, size, dir);</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt; @@ -877,7 +877,7 @@ EXPORT_SYMBOL(swiotlb_sync_single_for_device);</span>
<span class="quote">&gt;   */</span>
<span class="quote">&gt;  int</span>
<span class="quote">&gt;  swiotlb_map_sg_attrs(struct device *hwdev, struct scatterlist *sgl, int nelems,</span>
<span class="quote">&gt; -		     enum dma_data_direction dir, struct dma_attrs *attrs)</span>
<span class="quote">&gt; +		     enum dma_data_direction dir, unsigned long attrs)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	struct scatterlist *sg;</span>
<span class="quote">&gt;  	int i;</span>
<span class="quote">&gt; @@ -914,7 +914,7 @@ int</span>
<span class="quote">&gt;  swiotlb_map_sg(struct device *hwdev, struct scatterlist *sgl, int nelems,</span>
<span class="quote">&gt;  	       enum dma_data_direction dir)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt; -	return swiotlb_map_sg_attrs(hwdev, sgl, nelems, dir, NULL);</span>
<span class="quote">&gt; +	return swiotlb_map_sg_attrs(hwdev, sgl, nelems, dir, 0);</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;  EXPORT_SYMBOL(swiotlb_map_sg);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; @@ -924,7 +924,8 @@ EXPORT_SYMBOL(swiotlb_map_sg);</span>
<span class="quote">&gt;   */</span>
<span class="quote">&gt;  void</span>
<span class="quote">&gt;  swiotlb_unmap_sg_attrs(struct device *hwdev, struct scatterlist *sgl,</span>
<span class="quote">&gt; -		       int nelems, enum dma_data_direction dir, struct dma_attrs *attrs)</span>
<span class="quote">&gt; +		       int nelems, enum dma_data_direction dir,</span>
<span class="quote">&gt; +		       unsigned long attrs)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	struct scatterlist *sg;</span>
<span class="quote">&gt;  	int i;</span>
<span class="quote">&gt; @@ -941,7 +942,7 @@ void</span>
<span class="quote">&gt;  swiotlb_unmap_sg(struct device *hwdev, struct scatterlist *sgl, int nelems,</span>
<span class="quote">&gt;  		 enum dma_data_direction dir)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt; -	return swiotlb_unmap_sg_attrs(hwdev, sgl, nelems, dir, NULL);</span>
<span class="quote">&gt; +	return swiotlb_unmap_sg_attrs(hwdev, sgl, nelems, dir, 0);</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;  EXPORT_SYMBOL(swiotlb_unmap_sg);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; -- </span>
<span class="quote">&gt; 1.9.1</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; _______________________________________________</span>
<span class="quote">&gt; iommu mailing list</span>
<span class="quote">&gt; iommu@lists.linux-foundation.org</span>
<span class="quote">&gt; https://lists.linuxfoundation.org/mailman/listinfo/iommu</span>
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=72608">Krzysztof Kozlowski</a> - June 1, 2016, 5:36 a.m.</div>
<pre class="content">
On 05/31/2016 07:04 PM, Christoph Hellwig wrote:
<span class="quote">&gt; On Mon, May 30, 2016 at 01:54:06PM +0200, Krzysztof Kozlowski wrote:</span>
<span class="quote">&gt;&gt; The dma-mapping core and the implementations do not change the</span>
<span class="quote">&gt;&gt; DMA attributes passed by pointer.  Thus the pointer can point to const</span>
<span class="quote">&gt;&gt; data.  However the attributes do not have to be a bitfield. Instead</span>
<span class="quote">&gt;&gt; unsigned long will do fine:</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; 1. This is just simpler.  Both in terms of reading the code and setting</span>
<span class="quote">&gt;&gt;    attributes.  Instead of initializing local attributes on the stack and</span>
<span class="quote">&gt;&gt;    passing pointer to it to dma_set_attr(), just set the bits.</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; 2. It brings safeness and checking for const correctness because the</span>
<span class="quote">&gt;&gt;    attributes are passed by value.</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; Please have in mind that this is RFC, not finished yet.  Only ARM and</span>
<span class="quote">&gt;&gt; ARM64 are fixed (and not everywhere).</span>
<span class="quote">&gt;&gt; However other API users also have to be converted which is quite</span>
<span class="quote">&gt;&gt; intrusive.  I would rather avoid it until the overall approach is</span>
<span class="quote">&gt;&gt; accepted.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; This looks great!  Please continue doing the full conversion.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt;&gt; +/**</span>
<span class="quote">&gt;&gt; + * List of possible attributes associated with a DMA mapping. The semantics</span>
<span class="quote">&gt;&gt; + * of each attribute should be defined in Documentation/DMA-attributes.txt.</span>
<span class="quote">&gt;&gt; + */</span>
<span class="quote">&gt;&gt; +#define DMA_ATTR_WRITE_BARRIER		BIT(1)</span>
<span class="quote">&gt;&gt; +#define DMA_ATTR_WEAK_ORDERING		BIT(2)</span>
<span class="quote">&gt;&gt; +#define DMA_ATTR_WRITE_COMBINE		BIT(3)</span>
<span class="quote">&gt;&gt; +#define DMA_ATTR_NON_CONSISTENT		BIT(4)</span>
<span class="quote">&gt;&gt; +#define DMA_ATTR_NO_KERNEL_MAPPING	BIT(5)</span>
<span class="quote">&gt;&gt; +#define DMA_ATTR_SKIP_CPU_SYNC		BIT(6)</span>
<span class="quote">&gt;&gt; +#define DMA_ATTR_FORCE_CONTIGUOUS	BIT(7)</span>
<span class="quote">&gt;&gt; +#define DMA_ATTR_ALLOC_SINGLE_PAGES	BIT(8)</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; No really for this patch, but I would much prefer to document them next</span>
<span class="quote">&gt; to the code in the long run.  Also I really think these BIT() macros</span>
<span class="quote">&gt; are a distraction compared to the (1 &lt;&lt; N) notation.</span>

Not much difference to me but maybe plain number:
...	0x01u
...	0x02u
?
<span class="quote">
&gt; </span>
<span class="quote">&gt;&gt; +/**</span>
<span class="quote">&gt;&gt; + * dma_get_attr - check for a specific attribute</span>
<span class="quote">&gt;&gt; + * @attr: attribute to look for</span>
<span class="quote">&gt;&gt; + * @attrs: attributes to check within</span>
<span class="quote">&gt;&gt; + */</span>
<span class="quote">&gt;&gt; +static inline bool dma_get_attr(unsigned long attr, unsigned long attrs)</span>
<span class="quote">&gt;&gt; +{</span>
<span class="quote">&gt;&gt; +	return !!(attr &amp; attrs);</span>
<span class="quote">&gt;&gt; +}</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; I&#39;d just kill this helper, much easier to simply open code it in the</span>
<span class="quote">&gt; caller.</span>

Keeping it for now helps reducing the number of changes in the patch.
The patch will be quite big as it has to replace all the uses atomically.

I can get rid of the helper in consecutive patch.

Best regards,
Krzysztof
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=72608">Krzysztof Kozlowski</a> - June 1, 2016, 6:08 a.m.</div>
<pre class="content">
On 05/31/2016 08:15 PM, Konrad Rzeszutek Wilk wrote:
<span class="quote">&gt; On Mon, May 30, 2016 at 01:54:06PM +0200, Krzysztof Kozlowski wrote:</span>
<span class="quote">&gt;&gt; The dma-mapping core and the implementations do not change the</span>
<span class="quote">&gt;&gt; DMA attributes passed by pointer.  Thus the pointer can point to const</span>
<span class="quote">&gt;&gt; data.  However the attributes do not have to be a bitfield. Instead</span>
<span class="quote">&gt;&gt; unsigned long will do fine:</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; 1. This is just simpler.  Both in terms of reading the code and setting</span>
<span class="quote">&gt;&gt;    attributes.  Instead of initializing local attributes on the stack and</span>
<span class="quote">&gt;&gt;    passing pointer to it to dma_set_attr(), just set the bits.</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; 2. It brings safeness and checking for const correctness because the</span>
<span class="quote">&gt;&gt;    attributes are passed by value.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; </span>
<span class="quote">&gt; .. why not go the next step a do an enum? Perhaps that should be mentioned</span>
<span class="quote">&gt; as part of the description?</span>

These are additive flags so to me this would look a little bit weird:
enum dma_attr {
	DMA_ATTR_WRITE_BARRIER	= 0x1,
	DMA_ATTR_WEAK_ORDERING	= 0x2,
	DMA_ATTR_WRITE_COMBINE	= 0x4,
	DMA_ATTR_NON_CONSISTENT	= 0x8,
	...
}

It doesn&#39;t really look like enumeration.

Best regards,
Krzysztof
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=101">Christoph Hellwig</a> - June 1, 2016, 7:51 a.m.</div>
<pre class="content">
On Wed, Jun 01, 2016 at 07:36:42AM +0200, Krzysztof Kozlowski wrote:
<span class="quote">&gt; &gt; No really for this patch, but I would much prefer to document them next</span>
<span class="quote">&gt; &gt; to the code in the long run.  Also I really think these BIT() macros</span>
<span class="quote">&gt; &gt; are a distraction compared to the (1 &lt;&lt; N) notation.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Not much difference to me but maybe plain number:</span>
<span class="quote">&gt; ...	0x01u</span>
<span class="quote">&gt; ...	0x02u</span>
<span class="quote">&gt; ?</span>

I prefer the little bit shifts, but even the explicit values are much
better than the obsfucating macros :)  Anyway, your patch and in the end
all three methods will get the work done.
<span class="quote">
&gt; &gt; I&#39;d just kill this helper, much easier to simply open code it in the</span>
<span class="quote">&gt; &gt; caller.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Keeping it for now helps reducing the number of changes in the patch.</span>
<span class="quote">&gt; The patch will be quite big as it has to replace all the uses atomically.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; I can get rid of the helper in consecutive patch.</span>

Sounds fine.
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/Documentation/DMA-API.txt b/Documentation/DMA-API.txt</span>
<span class="p_header">index 45ef3f279c3b..0b55cb7c5aaa 100644</span>
<span class="p_header">--- a/Documentation/DMA-API.txt</span>
<span class="p_header">+++ b/Documentation/DMA-API.txt</span>
<span class="p_chunk">@@ -391,7 +391,7 @@</span> <span class="p_context"> without the _attrs suffixes, except that they pass an optional</span>
 struct dma_attrs*.
 
 struct dma_attrs encapsulates a set of &quot;DMA attributes&quot;. For the
<span class="p_del">-definition of struct dma_attrs see linux/dma-attrs.h.</span>
<span class="p_add">+definition of struct dma_attrs see linux/dma-mapping.h.</span>
 
 The interpretation of DMA attributes is architecture-specific, and
 each attribute should be documented in Documentation/DMA-attributes.txt.
<span class="p_header">diff --git a/Documentation/DMA-attributes.txt b/Documentation/DMA-attributes.txt</span>
<span class="p_header">index e8cf9cf873b3..2d455a5cf671 100644</span>
<span class="p_header">--- a/Documentation/DMA-attributes.txt</span>
<span class="p_header">+++ b/Documentation/DMA-attributes.txt</span>
<span class="p_chunk">@@ -2,7 +2,7 @@</span> <span class="p_context"></span>
 			==============
 
 This document describes the semantics of the DMA attributes that are
<span class="p_del">-defined in linux/dma-attrs.h.</span>
<span class="p_add">+defined in linux/dma-mapping.h.</span>
 
 DMA_ATTR_WRITE_BARRIER
 ----------------------
<span class="p_header">diff --git a/arch/arm/include/asm/dma-mapping.h b/arch/arm/include/asm/dma-mapping.h</span>
<span class="p_header">index a83570f10124..d009f7911ffc 100644</span>
<span class="p_header">--- a/arch/arm/include/asm/dma-mapping.h</span>
<span class="p_header">+++ b/arch/arm/include/asm/dma-mapping.h</span>
<span class="p_chunk">@@ -5,7 +5,6 @@</span> <span class="p_context"></span>
 
 #include &lt;linux/mm_types.h&gt;
 #include &lt;linux/scatterlist.h&gt;
<span class="p_del">-#include &lt;linux/dma-attrs.h&gt;</span>
 #include &lt;linux/dma-debug.h&gt;
 
 #include &lt;asm/memory.h&gt;
<span class="p_chunk">@@ -174,7 +173,7 @@</span> <span class="p_context"> static inline void dma_mark_clean(void *addr, size_t size) { }</span>
  * to be the device-viewed address.
  */
 extern void *arm_dma_alloc(struct device *dev, size_t size, dma_addr_t *handle,
<span class="p_del">-			   gfp_t gfp, struct dma_attrs *attrs);</span>
<span class="p_add">+			   gfp_t gfp, unsigned long attrs);</span>
 
 /**
  * arm_dma_free - free memory allocated by arm_dma_alloc
<span class="p_chunk">@@ -191,7 +190,7 @@</span> <span class="p_context"> extern void *arm_dma_alloc(struct device *dev, size_t size, dma_addr_t *handle,</span>
  * during and after this call executing are illegal.
  */
 extern void arm_dma_free(struct device *dev, size_t size, void *cpu_addr,
<span class="p_del">-			 dma_addr_t handle, struct dma_attrs *attrs);</span>
<span class="p_add">+			 dma_addr_t handle, unsigned long attrs);</span>
 
 /**
  * arm_dma_mmap - map a coherent DMA allocation into user space
<span class="p_chunk">@@ -208,7 +207,7 @@</span> <span class="p_context"> extern void arm_dma_free(struct device *dev, size_t size, void *cpu_addr,</span>
  */
 extern int arm_dma_mmap(struct device *dev, struct vm_area_struct *vma,
 			void *cpu_addr, dma_addr_t dma_addr, size_t size,
<span class="p_del">-			struct dma_attrs *attrs);</span>
<span class="p_add">+			unsigned long attrs);</span>
 
 /*
  * This can be called during early boot to increase the size of the atomic
<span class="p_chunk">@@ -262,16 +261,16 @@</span> <span class="p_context"> extern void dmabounce_unregister_dev(struct device *);</span>
  * The scatter list versions of the above methods.
  */
 extern int arm_dma_map_sg(struct device *, struct scatterlist *, int,
<span class="p_del">-		enum dma_data_direction, struct dma_attrs *attrs);</span>
<span class="p_add">+		enum dma_data_direction, unsigned long attrs);</span>
 extern void arm_dma_unmap_sg(struct device *, struct scatterlist *, int,
<span class="p_del">-		enum dma_data_direction, struct dma_attrs *attrs);</span>
<span class="p_add">+		enum dma_data_direction, unsigned long attrs);</span>
 extern void arm_dma_sync_sg_for_cpu(struct device *, struct scatterlist *, int,
 		enum dma_data_direction);
 extern void arm_dma_sync_sg_for_device(struct device *, struct scatterlist *, int,
 		enum dma_data_direction);
 extern int arm_dma_get_sgtable(struct device *dev, struct sg_table *sgt,
 		void *cpu_addr, dma_addr_t dma_addr, size_t size,
<span class="p_del">-		struct dma_attrs *attrs);</span>
<span class="p_add">+		unsigned long attrs);</span>
 
 #endif /* __KERNEL__ */
 #endif
<span class="p_header">diff --git a/arch/arm/include/asm/xen/page-coherent.h b/arch/arm/include/asm/xen/page-coherent.h</span>
<span class="p_header">index 9408a994cc91..95ce6ac3a971 100644</span>
<span class="p_header">--- a/arch/arm/include/asm/xen/page-coherent.h</span>
<span class="p_header">+++ b/arch/arm/include/asm/xen/page-coherent.h</span>
<span class="p_chunk">@@ -2,15 +2,14 @@</span> <span class="p_context"></span>
 #define _ASM_ARM_XEN_PAGE_COHERENT_H
 
 #include &lt;asm/page.h&gt;
<span class="p_del">-#include &lt;linux/dma-attrs.h&gt;</span>
 #include &lt;linux/dma-mapping.h&gt;
 
 void __xen_dma_map_page(struct device *hwdev, struct page *page,
 	     dma_addr_t dev_addr, unsigned long offset, size_t size,
<span class="p_del">-	     enum dma_data_direction dir, struct dma_attrs *attrs);</span>
<span class="p_add">+	     enum dma_data_direction dir, unsigned long attrs);</span>
 void __xen_dma_unmap_page(struct device *hwdev, dma_addr_t handle,
 		size_t size, enum dma_data_direction dir,
<span class="p_del">-		struct dma_attrs *attrs);</span>
<span class="p_add">+		unsigned long attrs);</span>
 void __xen_dma_sync_single_for_cpu(struct device *hwdev,
 		dma_addr_t handle, size_t size, enum dma_data_direction dir);
 
<span class="p_chunk">@@ -18,22 +17,20 @@</span> <span class="p_context"> void __xen_dma_sync_single_for_device(struct device *hwdev,</span>
 		dma_addr_t handle, size_t size, enum dma_data_direction dir);
 
 static inline void *xen_alloc_coherent_pages(struct device *hwdev, size_t size,
<span class="p_del">-		dma_addr_t *dma_handle, gfp_t flags,</span>
<span class="p_del">-		struct dma_attrs *attrs)</span>
<span class="p_add">+		dma_addr_t *dma_handle, gfp_t flags, unsigned long attrs)</span>
 {
 	return __generic_dma_ops(hwdev)-&gt;alloc(hwdev, size, dma_handle, flags, attrs);
 }
 
 static inline void xen_free_coherent_pages(struct device *hwdev, size_t size,
<span class="p_del">-		void *cpu_addr, dma_addr_t dma_handle,</span>
<span class="p_del">-		struct dma_attrs *attrs)</span>
<span class="p_add">+		void *cpu_addr, dma_addr_t dma_handle, unsigned long attrs)</span>
 {
 	__generic_dma_ops(hwdev)-&gt;free(hwdev, size, cpu_addr, dma_handle, attrs);
 }
 
 static inline void xen_dma_map_page(struct device *hwdev, struct page *page,
 	     dma_addr_t dev_addr, unsigned long offset, size_t size,
<span class="p_del">-	     enum dma_data_direction dir, struct dma_attrs *attrs)</span>
<span class="p_add">+	     enum dma_data_direction dir, unsigned long attrs)</span>
 {
 	unsigned long page_pfn = page_to_xen_pfn(page);
 	unsigned long dev_pfn = XEN_PFN_DOWN(dev_addr);
<span class="p_chunk">@@ -58,8 +55,7 @@</span> <span class="p_context"> static inline void xen_dma_map_page(struct device *hwdev, struct page *page,</span>
 }
 
 static inline void xen_dma_unmap_page(struct device *hwdev, dma_addr_t handle,
<span class="p_del">-		size_t size, enum dma_data_direction dir,</span>
<span class="p_del">-		struct dma_attrs *attrs)</span>
<span class="p_add">+		size_t size, enum dma_data_direction dir, unsigned long attrs)</span>
 {
 	unsigned long pfn = PFN_DOWN(handle);
 	/*
<span class="p_header">diff --git a/arch/arm/mm/dma-mapping.c b/arch/arm/mm/dma-mapping.c</span>
<span class="p_header">index ff7ed5697d3e..fe31fbfd926d 100644</span>
<span class="p_header">--- a/arch/arm/mm/dma-mapping.c</span>
<span class="p_header">+++ b/arch/arm/mm/dma-mapping.c</span>
<span class="p_chunk">@@ -124,7 +124,7 @@</span> <span class="p_context"> static void __dma_page_dev_to_cpu(struct page *, unsigned long,</span>
  */
 static dma_addr_t arm_dma_map_page(struct device *dev, struct page *page,
 	     unsigned long offset, size_t size, enum dma_data_direction dir,
<span class="p_del">-	     struct dma_attrs *attrs)</span>
<span class="p_add">+	     unsigned long attrs)</span>
 {
 	if (!dma_get_attr(DMA_ATTR_SKIP_CPU_SYNC, attrs))
 		__dma_page_cpu_to_dev(page, offset, size, dir);
<span class="p_chunk">@@ -133,7 +133,7 @@</span> <span class="p_context"> static dma_addr_t arm_dma_map_page(struct device *dev, struct page *page,</span>
 
 static dma_addr_t arm_coherent_dma_map_page(struct device *dev, struct page *page,
 	     unsigned long offset, size_t size, enum dma_data_direction dir,
<span class="p_del">-	     struct dma_attrs *attrs)</span>
<span class="p_add">+	     unsigned long attrs)</span>
 {
 	return pfn_to_dma(dev, page_to_pfn(page)) + offset;
 }
<span class="p_chunk">@@ -153,8 +153,7 @@</span> <span class="p_context"> static dma_addr_t arm_coherent_dma_map_page(struct device *dev, struct page *pag</span>
  * whatever the device wrote there.
  */
 static void arm_dma_unmap_page(struct device *dev, dma_addr_t handle,
<span class="p_del">-		size_t size, enum dma_data_direction dir,</span>
<span class="p_del">-		struct dma_attrs *attrs)</span>
<span class="p_add">+		size_t size, enum dma_data_direction dir, unsigned long attrs)</span>
 {
 	if (!dma_get_attr(DMA_ATTR_SKIP_CPU_SYNC, attrs))
 		__dma_page_dev_to_cpu(pfn_to_page(dma_to_pfn(dev, handle)),
<span class="p_chunk">@@ -194,12 +193,12 @@</span> <span class="p_context"> struct dma_map_ops arm_dma_ops = {</span>
 EXPORT_SYMBOL(arm_dma_ops);
 
 static void *arm_coherent_dma_alloc(struct device *dev, size_t size,
<span class="p_del">-	dma_addr_t *handle, gfp_t gfp, struct dma_attrs *attrs);</span>
<span class="p_add">+	dma_addr_t *handle, gfp_t gfp, unsigned long attrs);</span>
 static void arm_coherent_dma_free(struct device *dev, size_t size, void *cpu_addr,
<span class="p_del">-				  dma_addr_t handle, struct dma_attrs *attrs);</span>
<span class="p_add">+				  dma_addr_t handle, unsigned long attrs);</span>
 static int arm_coherent_dma_mmap(struct device *dev, struct vm_area_struct *vma,
 		 void *cpu_addr, dma_addr_t dma_addr, size_t size,
<span class="p_del">-		 struct dma_attrs *attrs);</span>
<span class="p_add">+		 unsigned long attrs);</span>
 
 struct dma_map_ops arm_coherent_dma_ops = {
 	.alloc			= arm_coherent_dma_alloc,
<span class="p_chunk">@@ -621,7 +620,7 @@</span> <span class="p_context"> static void __free_from_contiguous(struct device *dev, struct page *page,</span>
 	dma_release_from_contiguous(dev, page, size &gt;&gt; PAGE_SHIFT);
 }
 
<span class="p_del">-static inline pgprot_t __get_dma_pgprot(struct dma_attrs *attrs, pgprot_t prot)</span>
<span class="p_add">+static inline pgprot_t __get_dma_pgprot(unsigned long attrs, pgprot_t prot)</span>
 {
 	prot = dma_get_attr(DMA_ATTR_WRITE_COMBINE, attrs) ?
 			    pgprot_writecombine(prot) :
<span class="p_chunk">@@ -732,7 +731,7 @@</span> <span class="p_context"> static struct arm_dma_allocator remap_allocator = {</span>
 
 static void *__dma_alloc(struct device *dev, size_t size, dma_addr_t *handle,
 			 gfp_t gfp, pgprot_t prot, bool is_coherent,
<span class="p_del">-			 struct dma_attrs *attrs, const void *caller)</span>
<span class="p_add">+			 unsigned long attrs, const void *caller)</span>
 {
 	u64 mask = get_coherent_dma_mask(dev);
 	struct page *page = NULL;
<span class="p_chunk">@@ -814,7 +813,7 @@</span> <span class="p_context"> static void *__dma_alloc(struct device *dev, size_t size, dma_addr_t *handle,</span>
  * virtual and bus address for that space.
  */
 void *arm_dma_alloc(struct device *dev, size_t size, dma_addr_t *handle,
<span class="p_del">-		    gfp_t gfp, struct dma_attrs *attrs)</span>
<span class="p_add">+		    gfp_t gfp, unsigned long attrs)</span>
 {
 	pgprot_t prot = __get_dma_pgprot(attrs, PAGE_KERNEL);
 
<span class="p_chunk">@@ -823,7 +822,7 @@</span> <span class="p_context"> void *arm_dma_alloc(struct device *dev, size_t size, dma_addr_t *handle,</span>
 }
 
 static void *arm_coherent_dma_alloc(struct device *dev, size_t size,
<span class="p_del">-	dma_addr_t *handle, gfp_t gfp, struct dma_attrs *attrs)</span>
<span class="p_add">+	dma_addr_t *handle, gfp_t gfp, unsigned long attrs)</span>
 {
 	return __dma_alloc(dev, size, handle, gfp, PAGE_KERNEL, true,
 			   attrs, __builtin_return_address(0));
<span class="p_chunk">@@ -831,7 +830,7 @@</span> <span class="p_context"> static void *arm_coherent_dma_alloc(struct device *dev, size_t size,</span>
 
 static int __arm_dma_mmap(struct device *dev, struct vm_area_struct *vma,
 		 void *cpu_addr, dma_addr_t dma_addr, size_t size,
<span class="p_del">-		 struct dma_attrs *attrs)</span>
<span class="p_add">+		 unsigned long attrs)</span>
 {
 	int ret = -ENXIO;
 #ifdef CONFIG_MMU
<span class="p_chunk">@@ -859,14 +858,14 @@</span> <span class="p_context"> static int __arm_dma_mmap(struct device *dev, struct vm_area_struct *vma,</span>
  */
 static int arm_coherent_dma_mmap(struct device *dev, struct vm_area_struct *vma,
 		 void *cpu_addr, dma_addr_t dma_addr, size_t size,
<span class="p_del">-		 struct dma_attrs *attrs)</span>
<span class="p_add">+		 unsigned long attrs)</span>
 {
 	return __arm_dma_mmap(dev, vma, cpu_addr, dma_addr, size, attrs);
 }
 
 int arm_dma_mmap(struct device *dev, struct vm_area_struct *vma,
 		 void *cpu_addr, dma_addr_t dma_addr, size_t size,
<span class="p_del">-		 struct dma_attrs *attrs)</span>
<span class="p_add">+		 unsigned long attrs)</span>
 {
 #ifdef CONFIG_MMU
 	vma-&gt;vm_page_prot = __get_dma_pgprot(attrs, vma-&gt;vm_page_prot);
<span class="p_chunk">@@ -878,7 +877,7 @@</span> <span class="p_context"> int arm_dma_mmap(struct device *dev, struct vm_area_struct *vma,</span>
  * Free a buffer as defined by the above mapping.
  */
 static void __arm_dma_free(struct device *dev, size_t size, void *cpu_addr,
<span class="p_del">-			   dma_addr_t handle, struct dma_attrs *attrs,</span>
<span class="p_add">+			   dma_addr_t handle, unsigned long attrs,</span>
 			   bool is_coherent)
 {
 	struct page *page = pfn_to_page(dma_to_pfn(dev, handle));
<span class="p_chunk">@@ -900,20 +899,20 @@</span> <span class="p_context"> static void __arm_dma_free(struct device *dev, size_t size, void *cpu_addr,</span>
 }
 
 void arm_dma_free(struct device *dev, size_t size, void *cpu_addr,
<span class="p_del">-		  dma_addr_t handle, struct dma_attrs *attrs)</span>
<span class="p_add">+		  dma_addr_t handle, unsigned long attrs)</span>
 {
 	__arm_dma_free(dev, size, cpu_addr, handle, attrs, false);
 }
 
 static void arm_coherent_dma_free(struct device *dev, size_t size, void *cpu_addr,
<span class="p_del">-				  dma_addr_t handle, struct dma_attrs *attrs)</span>
<span class="p_add">+				  dma_addr_t handle, unsigned long attrs)</span>
 {
 	__arm_dma_free(dev, size, cpu_addr, handle, attrs, true);
 }
 
 int arm_dma_get_sgtable(struct device *dev, struct sg_table *sgt,
 		 void *cpu_addr, dma_addr_t handle, size_t size,
<span class="p_del">-		 struct dma_attrs *attrs)</span>
<span class="p_add">+		 unsigned long attrs)</span>
 {
 	struct page *page = pfn_to_page(dma_to_pfn(dev, handle));
 	int ret;
<span class="p_chunk">@@ -1046,7 +1045,7 @@</span> <span class="p_context"> static void __dma_page_dev_to_cpu(struct page *page, unsigned long off,</span>
  * here.
  */
 int arm_dma_map_sg(struct device *dev, struct scatterlist *sg, int nents,
<span class="p_del">-		enum dma_data_direction dir, struct dma_attrs *attrs)</span>
<span class="p_add">+		enum dma_data_direction dir, unsigned long attrs)</span>
 {
 	struct dma_map_ops *ops = get_dma_ops(dev);
 	struct scatterlist *s;
<span class="p_chunk">@@ -1080,7 +1079,7 @@</span> <span class="p_context"> int arm_dma_map_sg(struct device *dev, struct scatterlist *sg, int nents,</span>
  * rules concerning calls here are the same as for dma_unmap_single().
  */
 void arm_dma_unmap_sg(struct device *dev, struct scatterlist *sg, int nents,
<span class="p_del">-		enum dma_data_direction dir, struct dma_attrs *attrs)</span>
<span class="p_add">+		enum dma_data_direction dir, unsigned long attrs)</span>
 {
 	struct dma_map_ops *ops = get_dma_ops(dev);
 	struct scatterlist *s;
<span class="p_chunk">@@ -1253,7 +1252,7 @@</span> <span class="p_context"> static inline void __free_iova(struct dma_iommu_mapping *mapping,</span>
 static const int iommu_order_array[] = { 9, 8, 4, 0 };
 
 static struct page **__iommu_alloc_buffer(struct device *dev, size_t size,
<span class="p_del">-					  gfp_t gfp, struct dma_attrs *attrs)</span>
<span class="p_add">+					  gfp_t gfp, unsigned long attrs)</span>
 {
 	struct page **pages;
 	int count = size &gt;&gt; PAGE_SHIFT;
<span class="p_chunk">@@ -1342,7 +1341,7 @@</span> <span class="p_context"> error:</span>
 }
 
 static int __iommu_free_buffer(struct device *dev, struct page **pages,
<span class="p_del">-			       size_t size, struct dma_attrs *attrs)</span>
<span class="p_add">+			       size_t size, unsigned long attrs)</span>
 {
 	int count = size &gt;&gt; PAGE_SHIFT;
 	int i;
<span class="p_chunk">@@ -1439,7 +1438,7 @@</span> <span class="p_context"> static struct page **__atomic_get_pages(void *addr)</span>
 	return (struct page **)page;
 }
 
<span class="p_del">-static struct page **__iommu_get_pages(void *cpu_addr, struct dma_attrs *attrs)</span>
<span class="p_add">+static struct page **__iommu_get_pages(void *cpu_addr, unsigned long attrs)</span>
 {
 	struct vm_struct *area;
 
<span class="p_chunk">@@ -1484,7 +1483,7 @@</span> <span class="p_context"> static void __iommu_free_atomic(struct device *dev, void *cpu_addr,</span>
 }
 
 static void *arm_iommu_alloc_attrs(struct device *dev, size_t size,
<span class="p_del">-	    dma_addr_t *handle, gfp_t gfp, struct dma_attrs *attrs)</span>
<span class="p_add">+	    dma_addr_t *handle, gfp_t gfp, unsigned long attrs)</span>
 {
 	pgprot_t prot = __get_dma_pgprot(attrs, PAGE_KERNEL);
 	struct page **pages;
<span class="p_chunk">@@ -1532,7 +1531,7 @@</span> <span class="p_context"> err_buffer:</span>
 
 static int arm_iommu_mmap_attrs(struct device *dev, struct vm_area_struct *vma,
 		    void *cpu_addr, dma_addr_t dma_addr, size_t size,
<span class="p_del">-		    struct dma_attrs *attrs)</span>
<span class="p_add">+		    unsigned long attrs)</span>
 {
 	unsigned long uaddr = vma-&gt;vm_start;
 	unsigned long usize = vma-&gt;vm_end - vma-&gt;vm_start;
<span class="p_chunk">@@ -1568,7 +1567,7 @@</span> <span class="p_context"> static int arm_iommu_mmap_attrs(struct device *dev, struct vm_area_struct *vma,</span>
  * Must not be called with IRQs disabled.
  */
 void arm_iommu_free_attrs(struct device *dev, size_t size, void *cpu_addr,
<span class="p_del">-			  dma_addr_t handle, struct dma_attrs *attrs)</span>
<span class="p_add">+			  dma_addr_t handle, unsigned long attrs)</span>
 {
 	struct page **pages;
 	size = PAGE_ALIGN(size);
<span class="p_chunk">@@ -1595,7 +1594,7 @@</span> <span class="p_context"> void arm_iommu_free_attrs(struct device *dev, size_t size, void *cpu_addr,</span>
 
 static int arm_iommu_get_sgtable(struct device *dev, struct sg_table *sgt,
 				 void *cpu_addr, dma_addr_t dma_addr,
<span class="p_del">-				 size_t size, struct dma_attrs *attrs)</span>
<span class="p_add">+				 size_t size, unsigned long attrs)</span>
 {
 	unsigned int count = PAGE_ALIGN(size) &gt;&gt; PAGE_SHIFT;
 	struct page **pages = __iommu_get_pages(cpu_addr, attrs);
<span class="p_chunk">@@ -1633,7 +1632,7 @@</span> <span class="p_context"> static int __dma_direction_to_prot(enum dma_data_direction dir)</span>
  */
 static int __map_sg_chunk(struct device *dev, struct scatterlist *sg,
 			  size_t size, dma_addr_t *handle,
<span class="p_del">-			  enum dma_data_direction dir, struct dma_attrs *attrs,</span>
<span class="p_add">+			  enum dma_data_direction dir, unsigned long attrs,</span>
 			  bool is_coherent)
 {
 	struct dma_iommu_mapping *mapping = to_dma_iommu_mapping(dev);
<span class="p_chunk">@@ -1676,7 +1675,7 @@</span> <span class="p_context"> fail:</span>
 }
 
 static int __iommu_map_sg(struct device *dev, struct scatterlist *sg, int nents,
<span class="p_del">-		     enum dma_data_direction dir, struct dma_attrs *attrs,</span>
<span class="p_add">+		     enum dma_data_direction dir, unsigned long attrs,</span>
 		     bool is_coherent)
 {
 	struct scatterlist *s = sg, *dma = sg, *start = sg;
<span class="p_chunk">@@ -1734,7 +1733,7 @@</span> <span class="p_context"> bad_mapping:</span>
  * obtained via sg_dma_{address,length}.
  */
 int arm_coherent_iommu_map_sg(struct device *dev, struct scatterlist *sg,
<span class="p_del">-		int nents, enum dma_data_direction dir, struct dma_attrs *attrs)</span>
<span class="p_add">+		int nents, enum dma_data_direction dir, unsigned long attrs)</span>
 {
 	return __iommu_map_sg(dev, sg, nents, dir, attrs, true);
 }
<span class="p_chunk">@@ -1752,14 +1751,14 @@</span> <span class="p_context"> int arm_coherent_iommu_map_sg(struct device *dev, struct scatterlist *sg,</span>
  * sg_dma_{address,length}.
  */
 int arm_iommu_map_sg(struct device *dev, struct scatterlist *sg,
<span class="p_del">-		int nents, enum dma_data_direction dir, struct dma_attrs *attrs)</span>
<span class="p_add">+		int nents, enum dma_data_direction dir, unsigned long attrs)</span>
 {
 	return __iommu_map_sg(dev, sg, nents, dir, attrs, false);
 }
 
 static void __iommu_unmap_sg(struct device *dev, struct scatterlist *sg,
<span class="p_del">-		int nents, enum dma_data_direction dir, struct dma_attrs *attrs,</span>
<span class="p_del">-		bool is_coherent)</span>
<span class="p_add">+		int nents, enum dma_data_direction dir,</span>
<span class="p_add">+		unsigned long attrs, bool is_coherent)</span>
 {
 	struct scatterlist *s;
 	int i;
<span class="p_chunk">@@ -1786,7 +1785,8 @@</span> <span class="p_context"> static void __iommu_unmap_sg(struct device *dev, struct scatterlist *sg,</span>
  * rules concerning calls here are the same as for dma_unmap_single().
  */
 void arm_coherent_iommu_unmap_sg(struct device *dev, struct scatterlist *sg,
<span class="p_del">-		int nents, enum dma_data_direction dir, struct dma_attrs *attrs)</span>
<span class="p_add">+		int nents, enum dma_data_direction dir,</span>
<span class="p_add">+		unsigned long attrs)</span>
 {
 	__iommu_unmap_sg(dev, sg, nents, dir, attrs, true);
 }
<span class="p_chunk">@@ -1802,7 +1802,8 @@</span> <span class="p_context"> void arm_coherent_iommu_unmap_sg(struct device *dev, struct scatterlist *sg,</span>
  * rules concerning calls here are the same as for dma_unmap_single().
  */
 void arm_iommu_unmap_sg(struct device *dev, struct scatterlist *sg, int nents,
<span class="p_del">-			enum dma_data_direction dir, struct dma_attrs *attrs)</span>
<span class="p_add">+			enum dma_data_direction dir,</span>
<span class="p_add">+			unsigned long attrs)</span>
 {
 	__iommu_unmap_sg(dev, sg, nents, dir, attrs, false);
 }
<span class="p_chunk">@@ -1855,7 +1856,7 @@</span> <span class="p_context"> void arm_iommu_sync_sg_for_device(struct device *dev, struct scatterlist *sg,</span>
  */
 static dma_addr_t arm_coherent_iommu_map_page(struct device *dev, struct page *page,
 	     unsigned long offset, size_t size, enum dma_data_direction dir,
<span class="p_del">-	     struct dma_attrs *attrs)</span>
<span class="p_add">+	     unsigned long attrs)</span>
 {
 	struct dma_iommu_mapping *mapping = to_dma_iommu_mapping(dev);
 	dma_addr_t dma_addr;
<span class="p_chunk">@@ -1889,7 +1890,7 @@</span> <span class="p_context"> fail:</span>
  */
 static dma_addr_t arm_iommu_map_page(struct device *dev, struct page *page,
 	     unsigned long offset, size_t size, enum dma_data_direction dir,
<span class="p_del">-	     struct dma_attrs *attrs)</span>
<span class="p_add">+	     unsigned long attrs)</span>
 {
 	if (!dma_get_attr(DMA_ATTR_SKIP_CPU_SYNC, attrs))
 		__dma_page_cpu_to_dev(page, offset, size, dir);
<span class="p_chunk">@@ -1907,8 +1908,7 @@</span> <span class="p_context"> static dma_addr_t arm_iommu_map_page(struct device *dev, struct page *page,</span>
  * Coherent IOMMU aware version of arm_dma_unmap_page()
  */
 static void arm_coherent_iommu_unmap_page(struct device *dev, dma_addr_t handle,
<span class="p_del">-		size_t size, enum dma_data_direction dir,</span>
<span class="p_del">-		struct dma_attrs *attrs)</span>
<span class="p_add">+		size_t size, enum dma_data_direction dir, unsigned long attrs)</span>
 {
 	struct dma_iommu_mapping *mapping = to_dma_iommu_mapping(dev);
 	dma_addr_t iova = handle &amp; PAGE_MASK;
<span class="p_chunk">@@ -1932,8 +1932,7 @@</span> <span class="p_context"> static void arm_coherent_iommu_unmap_page(struct device *dev, dma_addr_t handle,</span>
  * IOMMU aware version of arm_dma_unmap_page()
  */
 static void arm_iommu_unmap_page(struct device *dev, dma_addr_t handle,
<span class="p_del">-		size_t size, enum dma_data_direction dir,</span>
<span class="p_del">-		struct dma_attrs *attrs)</span>
<span class="p_add">+		size_t size, enum dma_data_direction dir, unsigned long attrs)</span>
 {
 	struct dma_iommu_mapping *mapping = to_dma_iommu_mapping(dev);
 	dma_addr_t iova = handle &amp; PAGE_MASK;
<span class="p_chunk">@@ -1944,6 +1943,7 @@</span> <span class="p_context"> static void arm_iommu_unmap_page(struct device *dev, dma_addr_t handle,</span>
 	if (!iova)
 		return;
 
<span class="p_add">+	// FIXME: replace get with simple check</span>
 	if (!dma_get_attr(DMA_ATTR_SKIP_CPU_SYNC, attrs))
 		__dma_page_dev_to_cpu(page, offset, size, dir);
 
<span class="p_header">diff --git a/arch/arm/xen/mm.c b/arch/arm/xen/mm.c</span>
<span class="p_header">index c5f9a9e3d1f3..fc67ed236a10 100644</span>
<span class="p_header">--- a/arch/arm/xen/mm.c</span>
<span class="p_header">+++ b/arch/arm/xen/mm.c</span>
<span class="p_chunk">@@ -98,7 +98,7 @@</span> <span class="p_context"> static void __xen_dma_page_cpu_to_dev(struct device *hwdev, dma_addr_t handle,</span>
 
 void __xen_dma_map_page(struct device *hwdev, struct page *page,
 	     dma_addr_t dev_addr, unsigned long offset, size_t size,
<span class="p_del">-	     enum dma_data_direction dir, struct dma_attrs *attrs)</span>
<span class="p_add">+	     enum dma_data_direction dir, unsigned long attrs)</span>
 {
 	if (is_device_dma_coherent(hwdev))
 		return;
<span class="p_chunk">@@ -110,7 +110,7 @@</span> <span class="p_context"> void __xen_dma_map_page(struct device *hwdev, struct page *page,</span>
 
 void __xen_dma_unmap_page(struct device *hwdev, dma_addr_t handle,
 		size_t size, enum dma_data_direction dir,
<span class="p_del">-		struct dma_attrs *attrs)</span>
<span class="p_add">+		unsigned long attrs)</span>
 
 {
 	if (is_device_dma_coherent(hwdev))
<span class="p_header">diff --git a/arch/arm64/mm/dma-mapping.c b/arch/arm64/mm/dma-mapping.c</span>
<span class="p_header">index c566ec83719f..a7686028dfeb 100644</span>
<span class="p_header">--- a/arch/arm64/mm/dma-mapping.c</span>
<span class="p_header">+++ b/arch/arm64/mm/dma-mapping.c</span>
<span class="p_chunk">@@ -29,7 +29,7 @@</span> <span class="p_context"></span>
 
 #include &lt;asm/cacheflush.h&gt;
 
<span class="p_del">-static pgprot_t __get_dma_pgprot(struct dma_attrs *attrs, pgprot_t prot,</span>
<span class="p_add">+static pgprot_t __get_dma_pgprot(unsigned long attrs, pgprot_t prot,</span>
 				 bool coherent)
 {
 	if (!coherent || dma_get_attr(DMA_ATTR_WRITE_COMBINE, attrs))
<span class="p_chunk">@@ -88,7 +88,7 @@</span> <span class="p_context"> static int __free_from_pool(void *start, size_t size)</span>
 
 static void *__dma_alloc_coherent(struct device *dev, size_t size,
 				  dma_addr_t *dma_handle, gfp_t flags,
<span class="p_del">-				  struct dma_attrs *attrs)</span>
<span class="p_add">+				  unsigned long attrs)</span>
 {
 	if (dev == NULL) {
 		WARN_ONCE(1, &quot;Use an actual device structure for DMA allocation\n&quot;);
<span class="p_chunk">@@ -118,7 +118,7 @@</span> <span class="p_context"> static void *__dma_alloc_coherent(struct device *dev, size_t size,</span>
 
 static void __dma_free_coherent(struct device *dev, size_t size,
 				void *vaddr, dma_addr_t dma_handle,
<span class="p_del">-				struct dma_attrs *attrs)</span>
<span class="p_add">+				unsigned long attrs)</span>
 {
 	bool freed;
 	phys_addr_t paddr = dma_to_phys(dev, dma_handle);
<span class="p_chunk">@@ -137,7 +137,7 @@</span> <span class="p_context"> static void __dma_free_coherent(struct device *dev, size_t size,</span>
 
 static void *__dma_alloc(struct device *dev, size_t size,
 			 dma_addr_t *dma_handle, gfp_t flags,
<span class="p_del">-			 struct dma_attrs *attrs)</span>
<span class="p_add">+			 unsigned long attrs)</span>
 {
 	struct page *page;
 	void *ptr, *coherent_ptr;
<span class="p_chunk">@@ -185,7 +185,7 @@</span> <span class="p_context"> no_mem:</span>
 
 static void __dma_free(struct device *dev, size_t size,
 		       void *vaddr, dma_addr_t dma_handle,
<span class="p_del">-		       struct dma_attrs *attrs)</span>
<span class="p_add">+		       unsigned long attrs)</span>
 {
 	void *swiotlb_addr = phys_to_virt(dma_to_phys(dev, dma_handle));
 
<span class="p_chunk">@@ -202,7 +202,7 @@</span> <span class="p_context"> static void __dma_free(struct device *dev, size_t size,</span>
 static dma_addr_t __swiotlb_map_page(struct device *dev, struct page *page,
 				     unsigned long offset, size_t size,
 				     enum dma_data_direction dir,
<span class="p_del">-				     struct dma_attrs *attrs)</span>
<span class="p_add">+				     unsigned long attrs)</span>
 {
 	dma_addr_t dev_addr;
 
<span class="p_chunk">@@ -216,7 +216,7 @@</span> <span class="p_context"> static dma_addr_t __swiotlb_map_page(struct device *dev, struct page *page,</span>
 
 static void __swiotlb_unmap_page(struct device *dev, dma_addr_t dev_addr,
 				 size_t size, enum dma_data_direction dir,
<span class="p_del">-				 struct dma_attrs *attrs)</span>
<span class="p_add">+				 unsigned long attrs)</span>
 {
 	if (!is_device_dma_coherent(dev))
 		__dma_unmap_area(phys_to_virt(dma_to_phys(dev, dev_addr)), size, dir);
<span class="p_chunk">@@ -225,7 +225,7 @@</span> <span class="p_context"> static void __swiotlb_unmap_page(struct device *dev, dma_addr_t dev_addr,</span>
 
 static int __swiotlb_map_sg_attrs(struct device *dev, struct scatterlist *sgl,
 				  int nelems, enum dma_data_direction dir,
<span class="p_del">-				  struct dma_attrs *attrs)</span>
<span class="p_add">+				  unsigned long attrs)</span>
 {
 	struct scatterlist *sg;
 	int i, ret;
<span class="p_chunk">@@ -242,7 +242,7 @@</span> <span class="p_context"> static int __swiotlb_map_sg_attrs(struct device *dev, struct scatterlist *sgl,</span>
 static void __swiotlb_unmap_sg_attrs(struct device *dev,
 				     struct scatterlist *sgl, int nelems,
 				     enum dma_data_direction dir,
<span class="p_del">-				     struct dma_attrs *attrs)</span>
<span class="p_add">+				     unsigned long attrs)</span>
 {
 	struct scatterlist *sg;
 	int i;
<span class="p_chunk">@@ -303,7 +303,7 @@</span> <span class="p_context"> static void __swiotlb_sync_sg_for_device(struct device *dev,</span>
 static int __swiotlb_mmap(struct device *dev,
 			  struct vm_area_struct *vma,
 			  void *cpu_addr, dma_addr_t dma_addr, size_t size,
<span class="p_del">-			  struct dma_attrs *attrs)</span>
<span class="p_add">+			  unsigned long attrs)</span>
 {
 	int ret = -ENXIO;
 	unsigned long nr_vma_pages = (vma-&gt;vm_end - vma-&gt;vm_start) &gt;&gt;
<span class="p_chunk">@@ -330,7 +330,7 @@</span> <span class="p_context"> static int __swiotlb_mmap(struct device *dev,</span>
 
 static int __swiotlb_get_sgtable(struct device *dev, struct sg_table *sgt,
 				 void *cpu_addr, dma_addr_t handle, size_t size,
<span class="p_del">-				 struct dma_attrs *attrs)</span>
<span class="p_add">+				 unsigned long attrs)</span>
 {
 	int ret = sg_alloc_table(sgt, 1, GFP_KERNEL);
 
<span class="p_chunk">@@ -425,21 +425,21 @@</span> <span class="p_context"> out:</span>
 
 static void *__dummy_alloc(struct device *dev, size_t size,
 			   dma_addr_t *dma_handle, gfp_t flags,
<span class="p_del">-			   struct dma_attrs *attrs)</span>
<span class="p_add">+			   unsigned long attrs)</span>
 {
 	return NULL;
 }
 
 static void __dummy_free(struct device *dev, size_t size,
 			 void *vaddr, dma_addr_t dma_handle,
<span class="p_del">-			 struct dma_attrs *attrs)</span>
<span class="p_add">+			 unsigned long attrs)</span>
 {
 }
 
 static int __dummy_mmap(struct device *dev,
 			struct vm_area_struct *vma,
 			void *cpu_addr, dma_addr_t dma_addr, size_t size,
<span class="p_del">-			struct dma_attrs *attrs)</span>
<span class="p_add">+			unsigned long attrs)</span>
 {
 	return -ENXIO;
 }
<span class="p_chunk">@@ -447,20 +447,20 @@</span> <span class="p_context"> static int __dummy_mmap(struct device *dev,</span>
 static dma_addr_t __dummy_map_page(struct device *dev, struct page *page,
 				   unsigned long offset, size_t size,
 				   enum dma_data_direction dir,
<span class="p_del">-				   struct dma_attrs *attrs)</span>
<span class="p_add">+				   unsigned long attrs)</span>
 {
 	return DMA_ERROR_CODE;
 }
 
 static void __dummy_unmap_page(struct device *dev, dma_addr_t dev_addr,
 			       size_t size, enum dma_data_direction dir,
<span class="p_del">-			       struct dma_attrs *attrs)</span>
<span class="p_add">+			       unsigned long attrs)</span>
 {
 }
 
 static int __dummy_map_sg(struct device *dev, struct scatterlist *sgl,
 			  int nelems, enum dma_data_direction dir,
<span class="p_del">-			  struct dma_attrs *attrs)</span>
<span class="p_add">+			  unsigned long attrs)</span>
 {
 	return 0;
 }
<span class="p_chunk">@@ -468,7 +468,7 @@</span> <span class="p_context"> static int __dummy_map_sg(struct device *dev, struct scatterlist *sgl,</span>
 static void __dummy_unmap_sg(struct device *dev,
 			     struct scatterlist *sgl, int nelems,
 			     enum dma_data_direction dir,
<span class="p_del">-			     struct dma_attrs *attrs)</span>
<span class="p_add">+			     unsigned long attrs)</span>
 {
 }
 
<span class="p_chunk">@@ -540,7 +540,7 @@</span> <span class="p_context"> static void flush_page(struct device *dev, const void *virt, phys_addr_t phys)</span>
 
 static void *__iommu_alloc_attrs(struct device *dev, size_t size,
 				 dma_addr_t *handle, gfp_t gfp,
<span class="p_del">-				 struct dma_attrs *attrs)</span>
<span class="p_add">+				 unsigned long attrs)</span>
 {
 	bool coherent = is_device_dma_coherent(dev);
 	int ioprot = dma_direction_to_prot(DMA_BIDIRECTIONAL, coherent);
<span class="p_chunk">@@ -600,7 +600,8 @@</span> <span class="p_context"> static void *__iommu_alloc_attrs(struct device *dev, size_t size,</span>
 }
 
 static void __iommu_free_attrs(struct device *dev, size_t size, void *cpu_addr,
<span class="p_del">-			       dma_addr_t handle, struct dma_attrs *attrs)</span>
<span class="p_add">+			       dma_addr_t handle,</span>
<span class="p_add">+			       unsigned long attrs)</span>
 {
 	size_t iosize = size;
 
<span class="p_chunk">@@ -616,7 +617,7 @@</span> <span class="p_context"> static void __iommu_free_attrs(struct device *dev, size_t size, void *cpu_addr,</span>
 	 * Hence how dodgy the below logic looks...
 	 */
 	if (__in_atomic_pool(cpu_addr, size)) {
<span class="p_del">-		iommu_dma_unmap_page(dev, handle, iosize, 0, NULL);</span>
<span class="p_add">+		iommu_dma_unmap_page(dev, handle, iosize, 0, 0);</span>
 		__free_from_pool(cpu_addr, size);
 	} else if (is_vmalloc_addr(cpu_addr)){
 		struct vm_struct *area = find_vm_area(cpu_addr);
<span class="p_chunk">@@ -626,14 +627,14 @@</span> <span class="p_context"> static void __iommu_free_attrs(struct device *dev, size_t size, void *cpu_addr,</span>
 		iommu_dma_free(dev, area-&gt;pages, iosize, &amp;handle);
 		dma_common_free_remap(cpu_addr, size, VM_USERMAP);
 	} else {
<span class="p_del">-		iommu_dma_unmap_page(dev, handle, iosize, 0, NULL);</span>
<span class="p_add">+		iommu_dma_unmap_page(dev, handle, iosize, 0, 0);</span>
 		__free_pages(virt_to_page(cpu_addr), get_order(size));
 	}
 }
 
 static int __iommu_mmap_attrs(struct device *dev, struct vm_area_struct *vma,
 			      void *cpu_addr, dma_addr_t dma_addr, size_t size,
<span class="p_del">-			      struct dma_attrs *attrs)</span>
<span class="p_add">+			      unsigned long attrs)</span>
 {
 	struct vm_struct *area;
 	int ret;
<span class="p_chunk">@@ -653,7 +654,7 @@</span> <span class="p_context"> static int __iommu_mmap_attrs(struct device *dev, struct vm_area_struct *vma,</span>
 
 static int __iommu_get_sgtable(struct device *dev, struct sg_table *sgt,
 			       void *cpu_addr, dma_addr_t dma_addr,
<span class="p_del">-			       size_t size, struct dma_attrs *attrs)</span>
<span class="p_add">+			       size_t size, unsigned long attrs)</span>
 {
 	unsigned int count = PAGE_ALIGN(size) &gt;&gt; PAGE_SHIFT;
 	struct vm_struct *area = find_vm_area(cpu_addr);
<span class="p_chunk">@@ -694,7 +695,7 @@</span> <span class="p_context"> static void __iommu_sync_single_for_device(struct device *dev,</span>
 static dma_addr_t __iommu_map_page(struct device *dev, struct page *page,
 				   unsigned long offset, size_t size,
 				   enum dma_data_direction dir,
<span class="p_del">-				   struct dma_attrs *attrs)</span>
<span class="p_add">+				   unsigned long attrs)</span>
 {
 	bool coherent = is_device_dma_coherent(dev);
 	int prot = dma_direction_to_prot(dir, coherent);
<span class="p_chunk">@@ -709,7 +710,7 @@</span> <span class="p_context"> static dma_addr_t __iommu_map_page(struct device *dev, struct page *page,</span>
 
 static void __iommu_unmap_page(struct device *dev, dma_addr_t dev_addr,
 			       size_t size, enum dma_data_direction dir,
<span class="p_del">-			       struct dma_attrs *attrs)</span>
<span class="p_add">+			       unsigned long attrs)</span>
 {
 	if (!dma_get_attr(DMA_ATTR_SKIP_CPU_SYNC, attrs))
 		__iommu_sync_single_for_cpu(dev, dev_addr, size, dir);
<span class="p_chunk">@@ -747,7 +748,7 @@</span> <span class="p_context"> static void __iommu_sync_sg_for_device(struct device *dev,</span>
 
 static int __iommu_map_sg_attrs(struct device *dev, struct scatterlist *sgl,
 				int nelems, enum dma_data_direction dir,
<span class="p_del">-				struct dma_attrs *attrs)</span>
<span class="p_add">+				unsigned long attrs)</span>
 {
 	bool coherent = is_device_dma_coherent(dev);
 
<span class="p_chunk">@@ -761,7 +762,7 @@</span> <span class="p_context"> static int __iommu_map_sg_attrs(struct device *dev, struct scatterlist *sgl,</span>
 static void __iommu_unmap_sg_attrs(struct device *dev,
 				   struct scatterlist *sgl, int nelems,
 				   enum dma_data_direction dir,
<span class="p_del">-				   struct dma_attrs *attrs)</span>
<span class="p_add">+				   unsigned long attrs)</span>
 {
 	if (!dma_get_attr(DMA_ATTR_SKIP_CPU_SYNC, attrs))
 		__iommu_sync_sg_for_cpu(dev, sgl, nelems, dir);
<span class="p_header">diff --git a/drivers/gpu/drm/exynos/exynos_drm_fbdev.c b/drivers/gpu/drm/exynos/exynos_drm_fbdev.c</span>
<span class="p_header">index 67dcd6831291..dd091175fc2d 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/exynos/exynos_drm_fbdev.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/exynos/exynos_drm_fbdev.c</span>
<span class="p_chunk">@@ -52,7 +52,7 @@</span> <span class="p_context"> static int exynos_drm_fb_mmap(struct fb_info *info,</span>
 
 	ret = dma_mmap_attrs(to_dma_dev(helper-&gt;dev), vma, exynos_gem-&gt;cookie,
 			     exynos_gem-&gt;dma_addr, exynos_gem-&gt;size,
<span class="p_del">-			     &amp;exynos_gem-&gt;dma_attrs);</span>
<span class="p_add">+			     exynos_gem-&gt;dma_attrs);</span>
 	if (ret &lt; 0) {
 		DRM_ERROR(&quot;failed to mmap.\n&quot;);
 		return ret;
<span class="p_header">diff --git a/drivers/gpu/drm/exynos/exynos_drm_g2d.c b/drivers/gpu/drm/exynos/exynos_drm_g2d.c</span>
<span class="p_header">index 493552368295..f65e6b7ef93b 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/exynos/exynos_drm_g2d.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/exynos/exynos_drm_g2d.c</span>
<span class="p_chunk">@@ -17,7 +17,6 @@</span> <span class="p_context"></span>
 #include &lt;linux/slab.h&gt;
 #include &lt;linux/workqueue.h&gt;
 #include &lt;linux/dma-mapping.h&gt;
<span class="p_del">-#include &lt;linux/dma-attrs.h&gt;</span>
 #include &lt;linux/of.h&gt;
 
 #include &lt;drm/drmP.h&gt;
<span class="p_header">diff --git a/drivers/gpu/drm/exynos/exynos_drm_gem.c b/drivers/gpu/drm/exynos/exynos_drm_gem.c</span>
<span class="p_header">index cdf9f1af4347..f2ae72ba7d5a 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/exynos/exynos_drm_gem.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/exynos/exynos_drm_gem.c</span>
<span class="p_chunk">@@ -24,7 +24,7 @@</span> <span class="p_context"></span>
 static int exynos_drm_alloc_buf(struct exynos_drm_gem *exynos_gem)
 {
 	struct drm_device *dev = exynos_gem-&gt;base.dev;
<span class="p_del">-	enum dma_attr attr;</span>
<span class="p_add">+	unsigned long attr;</span>
 	unsigned int nr_pages;
 	struct sg_table sgt;
 	int ret = -ENOMEM;
<span class="p_chunk">@@ -34,7 +34,7 @@</span> <span class="p_context"> static int exynos_drm_alloc_buf(struct exynos_drm_gem *exynos_gem)</span>
 		return 0;
 	}
 
<span class="p_del">-	init_dma_attrs(&amp;exynos_gem-&gt;dma_attrs);</span>
<span class="p_add">+	exynos_gem-&gt;dma_attrs = 0;</span>
 
 	/*
 	 * if EXYNOS_BO_CONTIG, fully physically contiguous memory
<span class="p_chunk">@@ -42,7 +42,7 @@</span> <span class="p_context"> static int exynos_drm_alloc_buf(struct exynos_drm_gem *exynos_gem)</span>
 	 * as possible.
 	 */
 	if (!(exynos_gem-&gt;flags &amp; EXYNOS_BO_NONCONTIG))
<span class="p_del">-		dma_set_attr(DMA_ATTR_FORCE_CONTIGUOUS, &amp;exynos_gem-&gt;dma_attrs);</span>
<span class="p_add">+		exynos_gem-&gt;dma_attrs |= DMA_ATTR_FORCE_CONTIGUOUS;</span>
 
 	/*
 	 * if EXYNOS_BO_WC or EXYNOS_BO_NONCACHABLE, writecombine mapping
<span class="p_chunk">@@ -54,8 +54,8 @@</span> <span class="p_context"> static int exynos_drm_alloc_buf(struct exynos_drm_gem *exynos_gem)</span>
 	else
 		attr = DMA_ATTR_NON_CONSISTENT;
 
<span class="p_del">-	dma_set_attr(attr, &amp;exynos_gem-&gt;dma_attrs);</span>
<span class="p_del">-	dma_set_attr(DMA_ATTR_NO_KERNEL_MAPPING, &amp;exynos_gem-&gt;dma_attrs);</span>
<span class="p_add">+	exynos_gem-&gt;dma_attrs |= attr;</span>
<span class="p_add">+	exynos_gem-&gt;dma_attrs |= DMA_ATTR_NO_KERNEL_MAPPING;</span>
 
 	nr_pages = exynos_gem-&gt;size &gt;&gt; PAGE_SHIFT;
 
<span class="p_chunk">@@ -67,7 +67,7 @@</span> <span class="p_context"> static int exynos_drm_alloc_buf(struct exynos_drm_gem *exynos_gem)</span>
 
 	exynos_gem-&gt;cookie = dma_alloc_attrs(to_dma_dev(dev), exynos_gem-&gt;size,
 					     &amp;exynos_gem-&gt;dma_addr, GFP_KERNEL,
<span class="p_del">-					     &amp;exynos_gem-&gt;dma_attrs);</span>
<span class="p_add">+					     exynos_gem-&gt;dma_attrs);</span>
 	if (!exynos_gem-&gt;cookie) {
 		DRM_ERROR(&quot;failed to allocate buffer.\n&quot;);
 		goto err_free;
<span class="p_chunk">@@ -75,7 +75,7 @@</span> <span class="p_context"> static int exynos_drm_alloc_buf(struct exynos_drm_gem *exynos_gem)</span>
 
 	ret = dma_get_sgtable_attrs(to_dma_dev(dev), &amp;sgt, exynos_gem-&gt;cookie,
 				    exynos_gem-&gt;dma_addr, exynos_gem-&gt;size,
<span class="p_del">-				    &amp;exynos_gem-&gt;dma_attrs);</span>
<span class="p_add">+				    exynos_gem-&gt;dma_attrs);</span>
 	if (ret &lt; 0) {
 		DRM_ERROR(&quot;failed to get sgtable.\n&quot;);
 		goto err_dma_free;
<span class="p_chunk">@@ -99,7 +99,7 @@</span> <span class="p_context"> err_sgt_free:</span>
 	sg_free_table(&amp;sgt);
 err_dma_free:
 	dma_free_attrs(to_dma_dev(dev), exynos_gem-&gt;size, exynos_gem-&gt;cookie,
<span class="p_del">-		       exynos_gem-&gt;dma_addr, &amp;exynos_gem-&gt;dma_attrs);</span>
<span class="p_add">+		       exynos_gem-&gt;dma_addr, exynos_gem-&gt;dma_attrs);</span>
 err_free:
 	drm_free_large(exynos_gem-&gt;pages);
 
<span class="p_chunk">@@ -120,7 +120,7 @@</span> <span class="p_context"> static void exynos_drm_free_buf(struct exynos_drm_gem *exynos_gem)</span>
 
 	dma_free_attrs(to_dma_dev(dev), exynos_gem-&gt;size, exynos_gem-&gt;cookie,
 			(dma_addr_t)exynos_gem-&gt;dma_addr,
<span class="p_del">-			&amp;exynos_gem-&gt;dma_attrs);</span>
<span class="p_add">+			exynos_gem-&gt;dma_attrs);</span>
 
 	drm_free_large(exynos_gem-&gt;pages);
 }
<span class="p_chunk">@@ -346,7 +346,7 @@</span> <span class="p_context"> static int exynos_drm_gem_mmap_buffer(struct exynos_drm_gem *exynos_gem,</span>
 
 	ret = dma_mmap_attrs(to_dma_dev(drm_dev), vma, exynos_gem-&gt;cookie,
 			     exynos_gem-&gt;dma_addr, exynos_gem-&gt;size,
<span class="p_del">-			     &amp;exynos_gem-&gt;dma_attrs);</span>
<span class="p_add">+			     exynos_gem-&gt;dma_attrs);</span>
 	if (ret &lt; 0) {
 		DRM_ERROR(&quot;failed to mmap.\n&quot;);
 		return ret;
<span class="p_header">diff --git a/drivers/gpu/drm/exynos/exynos_drm_gem.h b/drivers/gpu/drm/exynos/exynos_drm_gem.h</span>
<span class="p_header">index 78100742281d..df7c543d6558 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/exynos/exynos_drm_gem.h</span>
<span class="p_header">+++ b/drivers/gpu/drm/exynos/exynos_drm_gem.h</span>
<span class="p_chunk">@@ -50,7 +50,7 @@</span> <span class="p_context"> struct exynos_drm_gem {</span>
 	void			*cookie;
 	void __iomem		*kvaddr;
 	dma_addr_t		dma_addr;
<span class="p_del">-	struct dma_attrs	dma_attrs;</span>
<span class="p_add">+	unsigned long		dma_attrs;</span>
 	struct page		**pages;
 	struct sg_table		*sgt;
 };
<span class="p_header">diff --git a/drivers/iommu/dma-iommu.c b/drivers/iommu/dma-iommu.c</span>
<span class="p_header">index ea5a9ebf0f78..6c1bda504fb1 100644</span>
<span class="p_header">--- a/drivers/iommu/dma-iommu.c</span>
<span class="p_header">+++ b/drivers/iommu/dma-iommu.c</span>
<span class="p_chunk">@@ -286,7 +286,7 @@</span> <span class="p_context"> void iommu_dma_free(struct device *dev, struct page **pages, size_t size,</span>
  *	   or NULL on failure.
  */
 struct page **iommu_dma_alloc(struct device *dev, size_t size, gfp_t gfp,
<span class="p_del">-		struct dma_attrs *attrs, int prot, dma_addr_t *handle,</span>
<span class="p_add">+		unsigned long attrs, int prot, dma_addr_t *handle,</span>
 		void (*flush_page)(struct device *, const void *, phys_addr_t))
 {
 	struct iommu_domain *domain = iommu_get_domain_for_dev(dev);
<span class="p_chunk">@@ -400,7 +400,7 @@</span> <span class="p_context"> dma_addr_t iommu_dma_map_page(struct device *dev, struct page *page,</span>
 }
 
 void iommu_dma_unmap_page(struct device *dev, dma_addr_t handle, size_t size,
<span class="p_del">-		enum dma_data_direction dir, struct dma_attrs *attrs)</span>
<span class="p_add">+		enum dma_data_direction dir, unsigned long attrs)</span>
 {
 	__iommu_dma_unmap(iommu_get_domain_for_dev(dev), handle);
 }
<span class="p_chunk">@@ -560,7 +560,7 @@</span> <span class="p_context"> out_restore_sg:</span>
 }
 
 void iommu_dma_unmap_sg(struct device *dev, struct scatterlist *sg, int nents,
<span class="p_del">-		enum dma_data_direction dir, struct dma_attrs *attrs)</span>
<span class="p_add">+		enum dma_data_direction dir, unsigned long attrs)</span>
 {
 	/*
 	 * The scatterlist segments are mapped into a single
<span class="p_header">diff --git a/drivers/xen/swiotlb-xen.c b/drivers/xen/swiotlb-xen.c</span>
<span class="p_header">index 7399782c0998..87e6035c9e81 100644</span>
<span class="p_header">--- a/drivers/xen/swiotlb-xen.c</span>
<span class="p_header">+++ b/drivers/xen/swiotlb-xen.c</span>
<span class="p_chunk">@@ -294,7 +294,7 @@</span> <span class="p_context"> error:</span>
 void *
 xen_swiotlb_alloc_coherent(struct device *hwdev, size_t size,
 			   dma_addr_t *dma_handle, gfp_t flags,
<span class="p_del">-			   struct dma_attrs *attrs)</span>
<span class="p_add">+			   unsigned long attrs)</span>
 {
 	void *ret;
 	int order = get_order(size);
<span class="p_chunk">@@ -346,7 +346,7 @@</span> <span class="p_context"> EXPORT_SYMBOL_GPL(xen_swiotlb_alloc_coherent);</span>
 
 void
 xen_swiotlb_free_coherent(struct device *hwdev, size_t size, void *vaddr,
<span class="p_del">-			  dma_addr_t dev_addr, struct dma_attrs *attrs)</span>
<span class="p_add">+			  dma_addr_t dev_addr, unsigned long attrs)</span>
 {
 	int order = get_order(size);
 	phys_addr_t phys;
<span class="p_chunk">@@ -378,7 +378,7 @@</span> <span class="p_context"> EXPORT_SYMBOL_GPL(xen_swiotlb_free_coherent);</span>
 dma_addr_t xen_swiotlb_map_page(struct device *dev, struct page *page,
 				unsigned long offset, size_t size,
 				enum dma_data_direction dir,
<span class="p_del">-				struct dma_attrs *attrs)</span>
<span class="p_add">+				unsigned long attrs)</span>
 {
 	phys_addr_t map, phys = page_to_phys(page) + offset;
 	dma_addr_t dev_addr = xen_phys_to_bus(phys);
<span class="p_chunk">@@ -434,7 +434,7 @@</span> <span class="p_context"> EXPORT_SYMBOL_GPL(xen_swiotlb_map_page);</span>
  */
 static void xen_unmap_single(struct device *hwdev, dma_addr_t dev_addr,
 			     size_t size, enum dma_data_direction dir,
<span class="p_del">-				 struct dma_attrs *attrs)</span>
<span class="p_add">+			     unsigned long attrs)</span>
 {
 	phys_addr_t paddr = xen_bus_to_phys(dev_addr);
 
<span class="p_chunk">@@ -462,7 +462,7 @@</span> <span class="p_context"> static void xen_unmap_single(struct device *hwdev, dma_addr_t dev_addr,</span>
 
 void xen_swiotlb_unmap_page(struct device *hwdev, dma_addr_t dev_addr,
 			    size_t size, enum dma_data_direction dir,
<span class="p_del">-			    struct dma_attrs *attrs)</span>
<span class="p_add">+			    unsigned long attrs)</span>
 {
 	xen_unmap_single(hwdev, dev_addr, size, dir, attrs);
 }
<span class="p_chunk">@@ -538,7 +538,7 @@</span> <span class="p_context"> EXPORT_SYMBOL_GPL(xen_swiotlb_sync_single_for_device);</span>
 int
 xen_swiotlb_map_sg_attrs(struct device *hwdev, struct scatterlist *sgl,
 			 int nelems, enum dma_data_direction dir,
<span class="p_del">-			 struct dma_attrs *attrs)</span>
<span class="p_add">+			 unsigned long attrs)</span>
 {
 	struct scatterlist *sg;
 	int i;
<span class="p_chunk">@@ -599,7 +599,7 @@</span> <span class="p_context"> EXPORT_SYMBOL_GPL(xen_swiotlb_map_sg_attrs);</span>
 void
 xen_swiotlb_unmap_sg_attrs(struct device *hwdev, struct scatterlist *sgl,
 			   int nelems, enum dma_data_direction dir,
<span class="p_del">-			   struct dma_attrs *attrs)</span>
<span class="p_add">+			   unsigned long attrs)</span>
 {
 	struct scatterlist *sg;
 	int i;
<span class="p_header">diff --git a/include/linux/dma-attrs.h b/include/linux/dma-attrs.h</span>
deleted file mode 100644
<span class="p_header">index 5246239a4953..000000000000</span>
<span class="p_header">--- a/include/linux/dma-attrs.h</span>
<span class="p_header">+++ /dev/null</span>
<span class="p_chunk">@@ -1,71 +0,0 @@</span> <span class="p_context"></span>
<span class="p_del">-#ifndef _DMA_ATTR_H</span>
<span class="p_del">-#define _DMA_ATTR_H</span>
<span class="p_del">-</span>
<span class="p_del">-#include &lt;linux/bitmap.h&gt;</span>
<span class="p_del">-#include &lt;linux/bitops.h&gt;</span>
<span class="p_del">-#include &lt;linux/bug.h&gt;</span>
<span class="p_del">-</span>
<span class="p_del">-/**</span>
<span class="p_del">- * an enum dma_attr represents an attribute associated with a DMA</span>
<span class="p_del">- * mapping. The semantics of each attribute should be defined in</span>
<span class="p_del">- * Documentation/DMA-attributes.txt.</span>
<span class="p_del">- */</span>
<span class="p_del">-enum dma_attr {</span>
<span class="p_del">-	DMA_ATTR_WRITE_BARRIER,</span>
<span class="p_del">-	DMA_ATTR_WEAK_ORDERING,</span>
<span class="p_del">-	DMA_ATTR_WRITE_COMBINE,</span>
<span class="p_del">-	DMA_ATTR_NON_CONSISTENT,</span>
<span class="p_del">-	DMA_ATTR_NO_KERNEL_MAPPING,</span>
<span class="p_del">-	DMA_ATTR_SKIP_CPU_SYNC,</span>
<span class="p_del">-	DMA_ATTR_FORCE_CONTIGUOUS,</span>
<span class="p_del">-	DMA_ATTR_ALLOC_SINGLE_PAGES,</span>
<span class="p_del">-	DMA_ATTR_MAX,</span>
<span class="p_del">-};</span>
<span class="p_del">-</span>
<span class="p_del">-#define __DMA_ATTRS_LONGS BITS_TO_LONGS(DMA_ATTR_MAX)</span>
<span class="p_del">-</span>
<span class="p_del">-/**</span>
<span class="p_del">- * struct dma_attrs - an opaque container for DMA attributes</span>
<span class="p_del">- * @flags - bitmask representing a collection of enum dma_attr</span>
<span class="p_del">- */</span>
<span class="p_del">-struct dma_attrs {</span>
<span class="p_del">-	unsigned long flags[__DMA_ATTRS_LONGS];</span>
<span class="p_del">-};</span>
<span class="p_del">-</span>
<span class="p_del">-#define DEFINE_DMA_ATTRS(x) 					\</span>
<span class="p_del">-	struct dma_attrs x = {					\</span>
<span class="p_del">-		.flags = { [0 ... __DMA_ATTRS_LONGS-1] = 0 },	\</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">-static inline void init_dma_attrs(struct dma_attrs *attrs)</span>
<span class="p_del">-{</span>
<span class="p_del">-	bitmap_zero(attrs-&gt;flags, __DMA_ATTRS_LONGS);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-/**</span>
<span class="p_del">- * dma_set_attr - set a specific attribute</span>
<span class="p_del">- * @attr: attribute to set</span>
<span class="p_del">- * @attrs: struct dma_attrs (may be NULL)</span>
<span class="p_del">- */</span>
<span class="p_del">-static inline void dma_set_attr(enum dma_attr attr, struct dma_attrs *attrs)</span>
<span class="p_del">-{</span>
<span class="p_del">-	if (attrs == NULL)</span>
<span class="p_del">-		return;</span>
<span class="p_del">-	BUG_ON(attr &gt;= DMA_ATTR_MAX);</span>
<span class="p_del">-	__set_bit(attr, attrs-&gt;flags);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-/**</span>
<span class="p_del">- * dma_get_attr - check for a specific attribute</span>
<span class="p_del">- * @attr: attribute to set</span>
<span class="p_del">- * @attrs: struct dma_attrs (may be NULL)</span>
<span class="p_del">- */</span>
<span class="p_del">-static inline int dma_get_attr(enum dma_attr attr, struct dma_attrs *attrs)</span>
<span class="p_del">-{</span>
<span class="p_del">-	if (attrs == NULL)</span>
<span class="p_del">-		return 0;</span>
<span class="p_del">-	BUG_ON(attr &gt;= DMA_ATTR_MAX);</span>
<span class="p_del">-	return test_bit(attr, attrs-&gt;flags);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-#endif /* _DMA_ATTR_H */</span>
<span class="p_header">diff --git a/include/linux/dma-iommu.h b/include/linux/dma-iommu.h</span>
<span class="p_header">index 8443bbb5c071..81c5c8d167ad 100644</span>
<span class="p_header">--- a/include/linux/dma-iommu.h</span>
<span class="p_header">+++ b/include/linux/dma-iommu.h</span>
<span class="p_chunk">@@ -39,7 +39,7 @@</span> <span class="p_context"> int dma_direction_to_prot(enum dma_data_direction dir, bool coherent);</span>
  * the arch code to take care of attributes and cache maintenance
  */
 struct page **iommu_dma_alloc(struct device *dev, size_t size, gfp_t gfp,
<span class="p_del">-		struct dma_attrs *attrs, int prot, dma_addr_t *handle,</span>
<span class="p_add">+		unsigned long attrs, int prot, dma_addr_t *handle,</span>
 		void (*flush_page)(struct device *, const void *, phys_addr_t));
 void iommu_dma_free(struct device *dev, struct page **pages, size_t size,
 		dma_addr_t *handle);
<span class="p_chunk">@@ -56,9 +56,9 @@</span> <span class="p_context"> int iommu_dma_map_sg(struct device *dev, struct scatterlist *sg,</span>
  * directly as DMA mapping callbacks for simplicity
  */
 void iommu_dma_unmap_page(struct device *dev, dma_addr_t handle, size_t size,
<span class="p_del">-		enum dma_data_direction dir, struct dma_attrs *attrs);</span>
<span class="p_add">+		enum dma_data_direction dir, unsigned long attrs);</span>
 void iommu_dma_unmap_sg(struct device *dev, struct scatterlist *sg, int nents,
<span class="p_del">-		enum dma_data_direction dir, struct dma_attrs *attrs);</span>
<span class="p_add">+		enum dma_data_direction dir, unsigned long attrs);</span>
 int iommu_dma_supported(struct device *dev, u64 mask);
 int iommu_dma_mapping_error(struct device *dev, dma_addr_t dma_addr);
 
<span class="p_header">diff --git a/include/linux/dma-mapping.h b/include/linux/dma-mapping.h</span>
<span class="p_header">index 71c1b215ef66..19e581d5f8b4 100644</span>
<span class="p_header">--- a/include/linux/dma-mapping.h</span>
<span class="p_header">+++ b/include/linux/dma-mapping.h</span>
<span class="p_chunk">@@ -5,13 +5,25 @@</span> <span class="p_context"></span>
 #include &lt;linux/string.h&gt;
 #include &lt;linux/device.h&gt;
 #include &lt;linux/err.h&gt;
<span class="p_del">-#include &lt;linux/dma-attrs.h&gt;</span>
 #include &lt;linux/dma-debug.h&gt;
 #include &lt;linux/dma-direction.h&gt;
 #include &lt;linux/scatterlist.h&gt;
 #include &lt;linux/kmemcheck.h&gt;
 #include &lt;linux/bug.h&gt;
 
<span class="p_add">+/**</span>
<span class="p_add">+ * List of possible attributes associated with a DMA mapping. The semantics</span>
<span class="p_add">+ * of each attribute should be defined in Documentation/DMA-attributes.txt.</span>
<span class="p_add">+ */</span>
<span class="p_add">+#define DMA_ATTR_WRITE_BARRIER		BIT(1)</span>
<span class="p_add">+#define DMA_ATTR_WEAK_ORDERING		BIT(2)</span>
<span class="p_add">+#define DMA_ATTR_WRITE_COMBINE		BIT(3)</span>
<span class="p_add">+#define DMA_ATTR_NON_CONSISTENT		BIT(4)</span>
<span class="p_add">+#define DMA_ATTR_NO_KERNEL_MAPPING	BIT(5)</span>
<span class="p_add">+#define DMA_ATTR_SKIP_CPU_SYNC		BIT(6)</span>
<span class="p_add">+#define DMA_ATTR_FORCE_CONTIGUOUS	BIT(7)</span>
<span class="p_add">+#define DMA_ATTR_ALLOC_SINGLE_PAGES	BIT(8)</span>
<span class="p_add">+</span>
 /*
  * A dma_addr_t can hold any valid DMA or bus address for the platform.
  * It can be given to a device to use as a DMA source or target.  A CPU cannot
<span class="p_chunk">@@ -21,34 +33,35 @@</span> <span class="p_context"></span>
 struct dma_map_ops {
 	void* (*alloc)(struct device *dev, size_t size,
 				dma_addr_t *dma_handle, gfp_t gfp,
<span class="p_del">-				struct dma_attrs *attrs);</span>
<span class="p_add">+				unsigned long attrs);</span>
 	void (*free)(struct device *dev, size_t size,
 			      void *vaddr, dma_addr_t dma_handle,
<span class="p_del">-			      struct dma_attrs *attrs);</span>
<span class="p_add">+			      unsigned long attrs);</span>
 	int (*mmap)(struct device *, struct vm_area_struct *,
<span class="p_del">-			  void *, dma_addr_t, size_t, struct dma_attrs *attrs);</span>
<span class="p_add">+			  void *, dma_addr_t, size_t,</span>
<span class="p_add">+			  unsigned long attrs);</span>
 
 	int (*get_sgtable)(struct device *dev, struct sg_table *sgt, void *,
<span class="p_del">-			   dma_addr_t, size_t, struct dma_attrs *attrs);</span>
<span class="p_add">+			   dma_addr_t, size_t, unsigned long attrs);</span>
 
 	dma_addr_t (*map_page)(struct device *dev, struct page *page,
 			       unsigned long offset, size_t size,
 			       enum dma_data_direction dir,
<span class="p_del">-			       struct dma_attrs *attrs);</span>
<span class="p_add">+			       unsigned long attrs);</span>
 	void (*unmap_page)(struct device *dev, dma_addr_t dma_handle,
 			   size_t size, enum dma_data_direction dir,
<span class="p_del">-			   struct dma_attrs *attrs);</span>
<span class="p_add">+			   unsigned long attrs);</span>
 	/*
 	 * map_sg returns 0 on error and a value &gt; 0 on success.
 	 * It should never return a value &lt; 0.
 	 */
 	int (*map_sg)(struct device *dev, struct scatterlist *sg,
 		      int nents, enum dma_data_direction dir,
<span class="p_del">-		      struct dma_attrs *attrs);</span>
<span class="p_add">+		      unsigned long attrs);</span>
 	void (*unmap_sg)(struct device *dev,
 			 struct scatterlist *sg, int nents,
 			 enum dma_data_direction dir,
<span class="p_del">-			 struct dma_attrs *attrs);</span>
<span class="p_add">+			 unsigned long attrs);</span>
 	void (*sync_single_for_cpu)(struct device *dev,
 				    dma_addr_t dma_handle, size_t size,
 				    enum dma_data_direction dir);
<span class="p_chunk">@@ -88,6 +101,16 @@</span> <span class="p_context"> static inline int is_device_dma_capable(struct device *dev)</span>
 	return dev-&gt;dma_mask != NULL &amp;&amp; *dev-&gt;dma_mask != DMA_MASK_NONE;
 }
 
<span class="p_add">+/**</span>
<span class="p_add">+ * dma_get_attr - check for a specific attribute</span>
<span class="p_add">+ * @attr: attribute to look for</span>
<span class="p_add">+ * @attrs: attributes to check within</span>
<span class="p_add">+ */</span>
<span class="p_add">+static inline bool dma_get_attr(unsigned long attr, unsigned long attrs)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return !!(attr &amp; attrs);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 #ifdef CONFIG_HAVE_GENERIC_DMA_COHERENT
 /*
  * These three functions are only for dma allocator.
<span class="p_chunk">@@ -123,7 +146,7 @@</span> <span class="p_context"> static inline struct dma_map_ops *get_dma_ops(struct device *dev)</span>
 static inline dma_addr_t dma_map_single_attrs(struct device *dev, void *ptr,
 					      size_t size,
 					      enum dma_data_direction dir,
<span class="p_del">-					      struct dma_attrs *attrs)</span>
<span class="p_add">+					      unsigned long attrs)</span>
 {
 	struct dma_map_ops *ops = get_dma_ops(dev);
 	dma_addr_t addr;
<span class="p_chunk">@@ -142,7 +165,7 @@</span> <span class="p_context"> static inline dma_addr_t dma_map_single_attrs(struct device *dev, void *ptr,</span>
 static inline void dma_unmap_single_attrs(struct device *dev, dma_addr_t addr,
 					  size_t size,
 					  enum dma_data_direction dir,
<span class="p_del">-					  struct dma_attrs *attrs)</span>
<span class="p_add">+					  unsigned long attrs)</span>
 {
 	struct dma_map_ops *ops = get_dma_ops(dev);
 
<span class="p_chunk">@@ -158,7 +181,7 @@</span> <span class="p_context"> static inline void dma_unmap_single_attrs(struct device *dev, dma_addr_t addr,</span>
  */
 static inline int dma_map_sg_attrs(struct device *dev, struct scatterlist *sg,
 				   int nents, enum dma_data_direction dir,
<span class="p_del">-				   struct dma_attrs *attrs)</span>
<span class="p_add">+				   unsigned long attrs)</span>
 {
 	struct dma_map_ops *ops = get_dma_ops(dev);
 	int i, ents;
<span class="p_chunk">@@ -176,7 +199,7 @@</span> <span class="p_context"> static inline int dma_map_sg_attrs(struct device *dev, struct scatterlist *sg,</span>
 
 static inline void dma_unmap_sg_attrs(struct device *dev, struct scatterlist *sg,
 				      int nents, enum dma_data_direction dir,
<span class="p_del">-				      struct dma_attrs *attrs)</span>
<span class="p_add">+				      unsigned long attrs)</span>
 {
 	struct dma_map_ops *ops = get_dma_ops(dev);
 
<span class="p_chunk">@@ -195,7 +218,7 @@</span> <span class="p_context"> static inline dma_addr_t dma_map_page(struct device *dev, struct page *page,</span>
 
 	kmemcheck_mark_initialized(page_address(page) + offset, size);
 	BUG_ON(!valid_dma_direction(dir));
<span class="p_del">-	addr = ops-&gt;map_page(dev, page, offset, size, dir, NULL);</span>
<span class="p_add">+	addr = ops-&gt;map_page(dev, page, offset, size, dir, 0);</span>
 	debug_dma_map_page(dev, page, offset, size, dir, addr, false);
 
 	return addr;
<span class="p_chunk">@@ -208,7 +231,7 @@</span> <span class="p_context"> static inline void dma_unmap_page(struct device *dev, dma_addr_t addr,</span>
 
 	BUG_ON(!valid_dma_direction(dir));
 	if (ops-&gt;unmap_page)
<span class="p_del">-		ops-&gt;unmap_page(dev, addr, size, dir, NULL);</span>
<span class="p_add">+		ops-&gt;unmap_page(dev, addr, size, dir, 0);</span>
 	debug_dma_unmap_page(dev, addr, size, dir, false);
 }
 
<span class="p_chunk">@@ -289,10 +312,10 @@</span> <span class="p_context"> dma_sync_sg_for_device(struct device *dev, struct scatterlist *sg,</span>
 
 }
 
<span class="p_del">-#define dma_map_single(d, a, s, r) dma_map_single_attrs(d, a, s, r, NULL)</span>
<span class="p_del">-#define dma_unmap_single(d, a, s, r) dma_unmap_single_attrs(d, a, s, r, NULL)</span>
<span class="p_del">-#define dma_map_sg(d, s, n, r) dma_map_sg_attrs(d, s, n, r, NULL)</span>
<span class="p_del">-#define dma_unmap_sg(d, s, n, r) dma_unmap_sg_attrs(d, s, n, r, NULL)</span>
<span class="p_add">+#define dma_map_single(d, a, s, r) dma_map_single_attrs(d, a, s, r, 0)</span>
<span class="p_add">+#define dma_unmap_single(d, a, s, r) dma_unmap_single_attrs(d, a, s, r, 0)</span>
<span class="p_add">+#define dma_map_sg(d, s, n, r) dma_map_sg_attrs(d, s, n, r, 0)</span>
<span class="p_add">+#define dma_unmap_sg(d, s, n, r) dma_unmap_sg_attrs(d, s, n, r, 0)</span>
 
 extern int dma_common_mmap(struct device *dev, struct vm_area_struct *vma,
 			   void *cpu_addr, dma_addr_t dma_addr, size_t size);
<span class="p_chunk">@@ -321,7 +344,7 @@</span> <span class="p_context"> void dma_common_free_remap(void *cpu_addr, size_t size, unsigned long vm_flags);</span>
  */
 static inline int
 dma_mmap_attrs(struct device *dev, struct vm_area_struct *vma, void *cpu_addr,
<span class="p_del">-	       dma_addr_t dma_addr, size_t size, struct dma_attrs *attrs)</span>
<span class="p_add">+	       dma_addr_t dma_addr, size_t size, unsigned long attrs)</span>
 {
 	struct dma_map_ops *ops = get_dma_ops(dev);
 	BUG_ON(!ops);
<span class="p_chunk">@@ -330,7 +353,7 @@</span> <span class="p_context"> dma_mmap_attrs(struct device *dev, struct vm_area_struct *vma, void *cpu_addr,</span>
 	return dma_common_mmap(dev, vma, cpu_addr, dma_addr, size);
 }
 
<span class="p_del">-#define dma_mmap_coherent(d, v, c, h, s) dma_mmap_attrs(d, v, c, h, s, NULL)</span>
<span class="p_add">+#define dma_mmap_coherent(d, v, c, h, s) dma_mmap_attrs(d, v, c, h, s, 0)</span>
 
 int
 dma_common_get_sgtable(struct device *dev, struct sg_table *sgt,
<span class="p_chunk">@@ -338,7 +361,8 @@</span> <span class="p_context"> dma_common_get_sgtable(struct device *dev, struct sg_table *sgt,</span>
 
 static inline int
 dma_get_sgtable_attrs(struct device *dev, struct sg_table *sgt, void *cpu_addr,
<span class="p_del">-		      dma_addr_t dma_addr, size_t size, struct dma_attrs *attrs)</span>
<span class="p_add">+		      dma_addr_t dma_addr, size_t size,</span>
<span class="p_add">+		      unsigned long attrs)</span>
 {
 	struct dma_map_ops *ops = get_dma_ops(dev);
 	BUG_ON(!ops);
<span class="p_chunk">@@ -348,7 +372,7 @@</span> <span class="p_context"> dma_get_sgtable_attrs(struct device *dev, struct sg_table *sgt, void *cpu_addr,</span>
 	return dma_common_get_sgtable(dev, sgt, cpu_addr, dma_addr, size);
 }
 
<span class="p_del">-#define dma_get_sgtable(d, t, v, h, s) dma_get_sgtable_attrs(d, t, v, h, s, NULL)</span>
<span class="p_add">+#define dma_get_sgtable(d, t, v, h, s) dma_get_sgtable_attrs(d, t, v, h, s, 0)</span>
 
 #ifndef arch_dma_alloc_attrs
 #define arch_dma_alloc_attrs(dev, flag)	(true)
<span class="p_chunk">@@ -356,7 +380,7 @@</span> <span class="p_context"> dma_get_sgtable_attrs(struct device *dev, struct sg_table *sgt, void *cpu_addr,</span>
 
 static inline void *dma_alloc_attrs(struct device *dev, size_t size,
 				       dma_addr_t *dma_handle, gfp_t flag,
<span class="p_del">-				       struct dma_attrs *attrs)</span>
<span class="p_add">+				       unsigned long attrs)</span>
 {
 	struct dma_map_ops *ops = get_dma_ops(dev);
 	void *cpu_addr;
<span class="p_chunk">@@ -378,7 +402,7 @@</span> <span class="p_context"> static inline void *dma_alloc_attrs(struct device *dev, size_t size,</span>
 
 static inline void dma_free_attrs(struct device *dev, size_t size,
 				     void *cpu_addr, dma_addr_t dma_handle,
<span class="p_del">-				     struct dma_attrs *attrs)</span>
<span class="p_add">+				     unsigned long attrs)</span>
 {
 	struct dma_map_ops *ops = get_dma_ops(dev);
 
<span class="p_chunk">@@ -398,31 +422,27 @@</span> <span class="p_context"> static inline void dma_free_attrs(struct device *dev, size_t size,</span>
 static inline void *dma_alloc_coherent(struct device *dev, size_t size,
 		dma_addr_t *dma_handle, gfp_t flag)
 {
<span class="p_del">-	return dma_alloc_attrs(dev, size, dma_handle, flag, NULL);</span>
<span class="p_add">+	return dma_alloc_attrs(dev, size, dma_handle, flag, 0);</span>
 }
 
 static inline void dma_free_coherent(struct device *dev, size_t size,
 		void *cpu_addr, dma_addr_t dma_handle)
 {
<span class="p_del">-	return dma_free_attrs(dev, size, cpu_addr, dma_handle, NULL);</span>
<span class="p_add">+	return dma_free_attrs(dev, size, cpu_addr, dma_handle, 0);</span>
 }
 
 static inline void *dma_alloc_noncoherent(struct device *dev, size_t size,
 		dma_addr_t *dma_handle, gfp_t gfp)
 {
<span class="p_del">-	DEFINE_DMA_ATTRS(attrs);</span>
<span class="p_del">-</span>
<span class="p_del">-	dma_set_attr(DMA_ATTR_NON_CONSISTENT, &amp;attrs);</span>
<span class="p_del">-	return dma_alloc_attrs(dev, size, dma_handle, gfp, &amp;attrs);</span>
<span class="p_add">+	return dma_alloc_attrs(dev, size, dma_handle, gfp,</span>
<span class="p_add">+			       DMA_ATTR_NON_CONSISTENT);</span>
 }
 
 static inline void dma_free_noncoherent(struct device *dev, size_t size,
 		void *cpu_addr, dma_addr_t dma_handle)
 {
<span class="p_del">-	DEFINE_DMA_ATTRS(attrs);</span>
<span class="p_del">-</span>
<span class="p_del">-	dma_set_attr(DMA_ATTR_NON_CONSISTENT, &amp;attrs);</span>
<span class="p_del">-	dma_free_attrs(dev, size, cpu_addr, dma_handle, &amp;attrs);</span>
<span class="p_add">+	dma_free_attrs(dev, size, cpu_addr, dma_handle,</span>
<span class="p_add">+		       DMA_ATTR_NON_CONSISTENT);</span>
 }
 
 static inline int dma_mapping_error(struct device *dev, dma_addr_t dma_addr)
<span class="p_chunk">@@ -646,9 +666,8 @@</span> <span class="p_context"> static inline void dmam_release_declared_memory(struct device *dev)</span>
 static inline void *dma_alloc_wc(struct device *dev, size_t size,
 				 dma_addr_t *dma_addr, gfp_t gfp)
 {
<span class="p_del">-	DEFINE_DMA_ATTRS(attrs);</span>
<span class="p_del">-	dma_set_attr(DMA_ATTR_WRITE_COMBINE, &amp;attrs);</span>
<span class="p_del">-	return dma_alloc_attrs(dev, size, dma_addr, gfp, &amp;attrs);</span>
<span class="p_add">+	return dma_alloc_attrs(dev, size, dma_addr, gfp,</span>
<span class="p_add">+			       DMA_ATTR_WRITE_COMBINE);</span>
 }
 #ifndef dma_alloc_writecombine
 #define dma_alloc_writecombine dma_alloc_wc
<span class="p_chunk">@@ -657,9 +676,8 @@</span> <span class="p_context"> static inline void *dma_alloc_wc(struct device *dev, size_t size,</span>
 static inline void dma_free_wc(struct device *dev, size_t size,
 			       void *cpu_addr, dma_addr_t dma_addr)
 {
<span class="p_del">-	DEFINE_DMA_ATTRS(attrs);</span>
<span class="p_del">-	dma_set_attr(DMA_ATTR_WRITE_COMBINE, &amp;attrs);</span>
<span class="p_del">-	return dma_free_attrs(dev, size, cpu_addr, dma_addr, &amp;attrs);</span>
<span class="p_add">+	return dma_free_attrs(dev, size, cpu_addr, dma_addr,</span>
<span class="p_add">+			      DMA_ATTR_WRITE_COMBINE);</span>
 }
 #ifndef dma_free_writecombine
 #define dma_free_writecombine dma_free_wc
<span class="p_chunk">@@ -670,9 +688,8 @@</span> <span class="p_context"> static inline int dma_mmap_wc(struct device *dev,</span>
 			      void *cpu_addr, dma_addr_t dma_addr,
 			      size_t size)
 {
<span class="p_del">-	DEFINE_DMA_ATTRS(attrs);</span>
<span class="p_del">-	dma_set_attr(DMA_ATTR_WRITE_COMBINE, &amp;attrs);</span>
<span class="p_del">-	return dma_mmap_attrs(dev, vma, cpu_addr, dma_addr, size, &amp;attrs);</span>
<span class="p_add">+	return dma_mmap_attrs(dev, vma, cpu_addr, dma_addr, size,</span>
<span class="p_add">+			      DMA_ATTR_WRITE_COMBINE);</span>
 }
 #ifndef dma_mmap_writecombine
 #define dma_mmap_writecombine dma_mmap_wc
<span class="p_header">diff --git a/include/linux/swiotlb.h b/include/linux/swiotlb.h</span>
<span class="p_header">index 017fced60242..5f81f8a187f2 100644</span>
<span class="p_header">--- a/include/linux/swiotlb.h</span>
<span class="p_header">+++ b/include/linux/swiotlb.h</span>
<span class="p_chunk">@@ -6,7 +6,6 @@</span> <span class="p_context"></span>
 #include &lt;linux/types.h&gt;
 
 struct device;
<span class="p_del">-struct dma_attrs;</span>
 struct page;
 struct scatterlist;
 
<span class="p_chunk">@@ -68,10 +67,10 @@</span> <span class="p_context"> swiotlb_free_coherent(struct device *hwdev, size_t size,</span>
 extern dma_addr_t swiotlb_map_page(struct device *dev, struct page *page,
 				   unsigned long offset, size_t size,
 				   enum dma_data_direction dir,
<span class="p_del">-				   struct dma_attrs *attrs);</span>
<span class="p_add">+				   unsigned long attrs);</span>
 extern void swiotlb_unmap_page(struct device *hwdev, dma_addr_t dev_addr,
 			       size_t size, enum dma_data_direction dir,
<span class="p_del">-			       struct dma_attrs *attrs);</span>
<span class="p_add">+			       unsigned long attrs);</span>
 
 extern int
 swiotlb_map_sg(struct device *hwdev, struct scatterlist *sg, int nents,
<span class="p_chunk">@@ -83,12 +82,13 @@</span> <span class="p_context"> swiotlb_unmap_sg(struct device *hwdev, struct scatterlist *sg, int nents,</span>
 
 extern int
 swiotlb_map_sg_attrs(struct device *hwdev, struct scatterlist *sgl, int nelems,
<span class="p_del">-		     enum dma_data_direction dir, struct dma_attrs *attrs);</span>
<span class="p_add">+		     enum dma_data_direction dir,</span>
<span class="p_add">+		     unsigned long attrs);</span>
 
 extern void
 swiotlb_unmap_sg_attrs(struct device *hwdev, struct scatterlist *sgl,
 		       int nelems, enum dma_data_direction dir,
<span class="p_del">-		       struct dma_attrs *attrs);</span>
<span class="p_add">+		       unsigned long attrs);</span>
 
 extern void
 swiotlb_sync_single_for_cpu(struct device *hwdev, dma_addr_t dev_addr,
<span class="p_header">diff --git a/include/xen/swiotlb-xen.h b/include/xen/swiotlb-xen.h</span>
<span class="p_header">index 8b2eb93ae8ba..7c35e279d1e3 100644</span>
<span class="p_header">--- a/include/xen/swiotlb-xen.h</span>
<span class="p_header">+++ b/include/xen/swiotlb-xen.h</span>
<span class="p_chunk">@@ -9,30 +9,30 @@</span> <span class="p_context"> extern int xen_swiotlb_init(int verbose, bool early);</span>
 extern void
 *xen_swiotlb_alloc_coherent(struct device *hwdev, size_t size,
 			    dma_addr_t *dma_handle, gfp_t flags,
<span class="p_del">-			    struct dma_attrs *attrs);</span>
<span class="p_add">+			    unsigned long attrs);</span>
 
 extern void
 xen_swiotlb_free_coherent(struct device *hwdev, size_t size,
 			  void *vaddr, dma_addr_t dma_handle,
<span class="p_del">-			  struct dma_attrs *attrs);</span>
<span class="p_add">+			  unsigned long attrs);</span>
 
 extern dma_addr_t xen_swiotlb_map_page(struct device *dev, struct page *page,
 				       unsigned long offset, size_t size,
 				       enum dma_data_direction dir,
<span class="p_del">-				       struct dma_attrs *attrs);</span>
<span class="p_add">+				       unsigned long attrs);</span>
 
 extern void xen_swiotlb_unmap_page(struct device *hwdev, dma_addr_t dev_addr,
 				   size_t size, enum dma_data_direction dir,
<span class="p_del">-				   struct dma_attrs *attrs);</span>
<span class="p_add">+				   unsigned long attrs);</span>
 extern int
 xen_swiotlb_map_sg_attrs(struct device *hwdev, struct scatterlist *sgl,
 			 int nelems, enum dma_data_direction dir,
<span class="p_del">-			 struct dma_attrs *attrs);</span>
<span class="p_add">+			 unsigned long attrs);</span>
 
 extern void
 xen_swiotlb_unmap_sg_attrs(struct device *hwdev, struct scatterlist *sgl,
 			   int nelems, enum dma_data_direction dir,
<span class="p_del">-			   struct dma_attrs *attrs);</span>
<span class="p_add">+			   unsigned long attrs);</span>
 
 extern void
 xen_swiotlb_sync_single_for_cpu(struct device *hwdev, dma_addr_t dev_addr,
<span class="p_header">diff --git a/lib/dma-noop.c b/lib/dma-noop.c</span>
<span class="p_header">index 72145646857e..3d766e78fbe2 100644</span>
<span class="p_header">--- a/lib/dma-noop.c</span>
<span class="p_header">+++ b/lib/dma-noop.c</span>
<span class="p_chunk">@@ -10,7 +10,7 @@</span> <span class="p_context"></span>
 
 static void *dma_noop_alloc(struct device *dev, size_t size,
 			    dma_addr_t *dma_handle, gfp_t gfp,
<span class="p_del">-			    struct dma_attrs *attrs)</span>
<span class="p_add">+			    unsigned long attrs)</span>
 {
 	void *ret;
 
<span class="p_chunk">@@ -22,7 +22,7 @@</span> <span class="p_context"> static void *dma_noop_alloc(struct device *dev, size_t size,</span>
 
 static void dma_noop_free(struct device *dev, size_t size,
 			  void *cpu_addr, dma_addr_t dma_addr,
<span class="p_del">-			  struct dma_attrs *attrs)</span>
<span class="p_add">+			  unsigned long attrs)</span>
 {
 	free_pages((unsigned long)cpu_addr, get_order(size));
 }
<span class="p_chunk">@@ -30,13 +30,14 @@</span> <span class="p_context"> static void dma_noop_free(struct device *dev, size_t size,</span>
 static dma_addr_t dma_noop_map_page(struct device *dev, struct page *page,
 				      unsigned long offset, size_t size,
 				      enum dma_data_direction dir,
<span class="p_del">-				      struct dma_attrs *attrs)</span>
<span class="p_add">+				      unsigned long attrs)</span>
 {
 	return page_to_phys(page) + offset;
 }
 
 static int dma_noop_map_sg(struct device *dev, struct scatterlist *sgl, int nents,
<span class="p_del">-			     enum dma_data_direction dir, struct dma_attrs *attrs)</span>
<span class="p_add">+			     enum dma_data_direction dir,</span>
<span class="p_add">+			     unsigned long attrs)</span>
 {
 	int i;
 	struct scatterlist *sg;
<span class="p_header">diff --git a/lib/swiotlb.c b/lib/swiotlb.c</span>
<span class="p_header">index 76f29ecba8f4..22e13a0e19d7 100644</span>
<span class="p_header">--- a/lib/swiotlb.c</span>
<span class="p_header">+++ b/lib/swiotlb.c</span>
<span class="p_chunk">@@ -738,7 +738,7 @@</span> <span class="p_context"> swiotlb_full(struct device *dev, size_t size, enum dma_data_direction dir,</span>
 dma_addr_t swiotlb_map_page(struct device *dev, struct page *page,
 			    unsigned long offset, size_t size,
 			    enum dma_data_direction dir,
<span class="p_del">-			    struct dma_attrs *attrs)</span>
<span class="p_add">+			    unsigned long attrs)</span>
 {
 	phys_addr_t map, phys = page_to_phys(page) + offset;
 	dma_addr_t dev_addr = phys_to_dma(dev, phys);
<span class="p_chunk">@@ -807,7 +807,7 @@</span> <span class="p_context"> static void unmap_single(struct device *hwdev, dma_addr_t dev_addr,</span>
 
 void swiotlb_unmap_page(struct device *hwdev, dma_addr_t dev_addr,
 			size_t size, enum dma_data_direction dir,
<span class="p_del">-			struct dma_attrs *attrs)</span>
<span class="p_add">+			unsigned long attrs)</span>
 {
 	unmap_single(hwdev, dev_addr, size, dir);
 }
<span class="p_chunk">@@ -877,7 +877,7 @@</span> <span class="p_context"> EXPORT_SYMBOL(swiotlb_sync_single_for_device);</span>
  */
 int
 swiotlb_map_sg_attrs(struct device *hwdev, struct scatterlist *sgl, int nelems,
<span class="p_del">-		     enum dma_data_direction dir, struct dma_attrs *attrs)</span>
<span class="p_add">+		     enum dma_data_direction dir, unsigned long attrs)</span>
 {
 	struct scatterlist *sg;
 	int i;
<span class="p_chunk">@@ -914,7 +914,7 @@</span> <span class="p_context"> int</span>
 swiotlb_map_sg(struct device *hwdev, struct scatterlist *sgl, int nelems,
 	       enum dma_data_direction dir)
 {
<span class="p_del">-	return swiotlb_map_sg_attrs(hwdev, sgl, nelems, dir, NULL);</span>
<span class="p_add">+	return swiotlb_map_sg_attrs(hwdev, sgl, nelems, dir, 0);</span>
 }
 EXPORT_SYMBOL(swiotlb_map_sg);
 
<span class="p_chunk">@@ -924,7 +924,8 @@</span> <span class="p_context"> EXPORT_SYMBOL(swiotlb_map_sg);</span>
  */
 void
 swiotlb_unmap_sg_attrs(struct device *hwdev, struct scatterlist *sgl,
<span class="p_del">-		       int nelems, enum dma_data_direction dir, struct dma_attrs *attrs)</span>
<span class="p_add">+		       int nelems, enum dma_data_direction dir,</span>
<span class="p_add">+		       unsigned long attrs)</span>
 {
 	struct scatterlist *sg;
 	int i;
<span class="p_chunk">@@ -941,7 +942,7 @@</span> <span class="p_context"> void</span>
 swiotlb_unmap_sg(struct device *hwdev, struct scatterlist *sgl, int nelems,
 		 enum dma_data_direction dir)
 {
<span class="p_del">-	return swiotlb_unmap_sg_attrs(hwdev, sgl, nelems, dir, NULL);</span>
<span class="p_add">+	return swiotlb_unmap_sg_attrs(hwdev, sgl, nelems, dir, 0);</span>
 }
 EXPORT_SYMBOL(swiotlb_unmap_sg);
 

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



