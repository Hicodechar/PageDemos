
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>[RFC,v2,14/20] x86: DMA support for memory encryption - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    [RFC,v2,14/20] x86: DMA support for memory encryption</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=80801">Tom Lendacky</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>Aug. 22, 2016, 10:38 p.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;20160822223807.29880.69294.stgit@tlendack-t1.amdoffice.net&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/9294535/mbox/"
   >mbox</a>
|
   <a href="/patch/9294535/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/9294535/">/patch/9294535/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
	[172.30.200.125])
	by pdx-korg-patchwork.web.codeaurora.org (Postfix) with ESMTP id
	9E45160574 for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Mon, 22 Aug 2016 22:55:09 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 8B549286DA
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Mon, 22 Aug 2016 22:55:09 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id 7F303286E3; Mon, 22 Aug 2016 22:55:09 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-6.9 required=2.0 tests=BAYES_00,DKIM_SIGNED,
	DKIM_VALID,RCVD_IN_DNSWL_HI autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 1325D287B8
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Mon, 22 Aug 2016 22:55:07 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S932969AbcHVWyo (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Mon, 22 Aug 2016 18:54:44 -0400
Received: from mail-dm3nam03on0045.outbound.protection.outlook.com
	([104.47.41.45]:39352
	&quot;EHLO NAM03-DM3-obe.outbound.protection.outlook.com&quot;
	rhost-flags-OK-OK-OK-FAIL) by vger.kernel.org with ESMTP
	id S932828AbcHVWyg (ORCPT &lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Mon, 22 Aug 2016 18:54:36 -0400
X-Greylist: delayed 1127 seconds by postgrey-1.27 at vger.kernel.org;
	Mon, 22 Aug 2016 18:54:35 EDT
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
	d=amdcloud.onmicrosoft.com; s=selector1-amd-com;
	h=From:Date:Subject:Message-ID:Content-Type:MIME-Version;
	bh=Kx31PW9qzMMFxtBhqqCwfchnaPNnwKmvHp1PwG4E1WQ=;
	b=MR0JHOtQeWUcR+0JTaGF4eQzuwLYVtl7hB8zpKAnDgerxt2NQdPK5e6Aq3vV5NjdWvzw8cGtXWfSBSPBkNJzPC/17jLbbibjDuhuPmyGfMzZw9DmgL4Rl01x9Aa1H7LAs9sMq7Bqhzje1mgB0FEEXxzfeH9DwdRQtijQki8oVm4=
Authentication-Results: spf=none (sender IP is )
	smtp.mailfrom=Thomas.Lendacky@amd.com; 
Received: from tlendack-t1.amdoffice.net (165.204.77.1) by
	DM5PR12MB1146.namprd12.prod.outlook.com (10.168.236.141) with
	Microsoft SMTP Server (version=TLS1_0,
	cipher=TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA_P384) id
	15.1.587.9; Mon, 22 Aug 2016 22:38:11 +0000
From: Tom Lendacky &lt;thomas.lendacky@amd.com&gt;
Subject: [RFC PATCH v2 14/20] x86: DMA support for memory encryption
To: &lt;linux-arch@vger.kernel.org&gt;, &lt;linux-efi@vger.kernel.org&gt;,
	&lt;kvm@vger.kernel.org&gt;, &lt;linux-doc@vger.kernel.org&gt;,
	&lt;x86@kernel.org&gt;, &lt;linux-kernel@vger.kernel.org&gt;,
	&lt;kasan-dev@googlegroups.com&gt;, &lt;linux-mm@kvack.org&gt;,
	&lt;iommu@lists.linux-foundation.org&gt;
CC: Radim =?utf-8?b?S3LEjW3DocWZ?= &lt;rkrcmar@redhat.com&gt;,
	Arnd Bergmann &lt;arnd@arndb.de&gt;, Jonathan Corbet &lt;corbet@lwn.net&gt;,
	Matt Fleming &lt;matt@codeblueprint.co.uk&gt;, Joerg Roedel &lt;joro@8bytes.org&gt;,
	&quot;Konrad Rzeszutek Wilk&quot; &lt;konrad.wilk@oracle.com&gt;,
	Andrey Ryabinin &lt;aryabinin@virtuozzo.com&gt;,
	Ingo Molnar &lt;mingo@redhat.com&gt;, Borislav Petkov &lt;bp@alien8.de&gt;,
	&quot;Andy Lutomirski&quot; &lt;luto@kernel.org&gt;, &quot;H. Peter Anvin&quot; &lt;hpa@zytor.com&gt;,
	Paolo Bonzini &lt;pbonzini@redhat.com&gt;,
	Alexander Potapenko &lt;glider@google.com&gt;,
	&quot;Thomas Gleixner&quot; &lt;tglx@linutronix.de&gt;,
	Dmitry Vyukov &lt;dvyukov@google.com&gt;
Date: Mon, 22 Aug 2016 17:38:07 -0500
Message-ID: &lt;20160822223807.29880.69294.stgit@tlendack-t1.amdoffice.net&gt;
In-Reply-To: &lt;20160822223529.29880.50884.stgit@tlendack-t1.amdoffice.net&gt;
References: &lt;20160822223529.29880.50884.stgit@tlendack-t1.amdoffice.net&gt;
User-Agent: StGit/0.17.1-dirty
MIME-Version: 1.0
Content-Type: text/plain; charset=&quot;utf-8&quot;
Content-Transfer-Encoding: 7bit
X-Originating-IP: [165.204.77.1]
X-ClientProxiedBy: BN6PR17CA0011.namprd17.prod.outlook.com (10.173.147.21) To
	DM5PR12MB1146.namprd12.prod.outlook.com (10.168.236.141)
X-MS-Office365-Filtering-Correlation-Id: ba91281e-348b-417c-3072-08d3cadd00c1
X-Microsoft-Exchange-Diagnostics: 1; DM5PR12MB1146;
	2:0WzW6RpLHdwh7lHyW4gj0FwRRKxMPxCd/vyibLfG82fu2QCOpvjB3H75HLQK1cyRrkkPjgSLmISZYWObAK+cgsb1P3LU2aoNzCnSUuiHEkZBh09fVJkeoC5pRL4Z0irbf35chE3KF20Y4jppBNrRO4vNNv26qfej2yUlNIYSLeWlK9yZodO7hR7MnPa2dhTr;
	3:8zHOAZpy+24hoAVnynXakpStW2mVtGLr4J6h4oXxxZSOa2JToZyKyI+Wzmgi2f8z2876I5RcglBcWjq/phBJVQdMJbC+SVfv62vMawrx8wwDLK8lvDywA5Ag8RixOplV;
	25:Q3aVihWoWZetRUa3sxZ1L5I9SXQfvDh+Ccv3ztlvUG6+EakK4p2qtCXJMIAPnrOHhgJsq+GfKMmFblYYvCEGGvwUj35nVN6IUM4gC8NUtHy1nfAovkXiy3G7g7lnwANU7lQNBA1fXmnQJ3kM/39AWbxcHoppMBlAmzfBWNXJGfoN8ZDCO2JrvTCwts0yyaZveuOhfPfpdxWAijTHDHAoWmpiuuqaMN1mErZUA3uvXUIkfvSXJsprUMsDF9zS89N5+b4RO2pINvjquBdBx/JFStWc47C/vitRZ5jABl3E4E/65SYukPpp+phuCWzTldByHUSrbSbkFqSY52NChtHkwE1JFzIF8arp5slW8aLhvaA9OTr8oB85JI95Bzgqy8JH8SMuC39gHu27hFGuAZU3fHQM4a0ENIIdOHb54LNMKhY=
X-Microsoft-Antispam: UriScan:;BCL:0;PCL:0;RULEID:;SRVR:DM5PR12MB1146;
X-Microsoft-Exchange-Diagnostics: 1; DM5PR12MB1146;
	31:iMQD3wpkKkbrMIERJQw0fGCEuwHimaiRyEAZY2G6nI9+Lr6Gd2ZLHNLEgW60EL/AH7PZ090CYleDi+Z5KNx1oUR+CVZq0xxJj/bCaYaDzQTfcOmYAahhMoq0ORJcJ1+Ja2/J32TmYuSfdrxnNAmEGbhDIueZJ+30UWFfdoJ327kRntziWsjqKEl4F4UpfiA2z9jl+ykQ62Fe6QQ3wLSPIU3O7/nCIbpmHV/LsnhXOtE=;
	20:dbQdTy8K0wN+uqVWeGqqARkTGBZYo4X1NGTqxSVvJ6nJNdb9/pmAwmNPpPTwq1WzoCVJ1edsM7rATzzkStIrritAFw2OCF9QkThK46b7JE8WezZgIPnXffRAonADqooEN4N9F7KeOy6x6RY6BoBgwFgBattDvYWPUohYryGc4ZEQdsBEBBFVBhjkWzTulxCx3naD5yylBeuDNzh6x6H1H7V/T4BxiTEMhsrc7f5B69l/xnBBC7oUGt7g0NyuwfBwEEhu39zbm7dcauy6oWEIJNGdank4hsv7uTewlMl7vrscLZiDsewnThOtZwYTEXN3/FWrxzGLSOVyllxpOJIqnWxFRzMVQ/FViVJrIh+N4HpAljfL841hIO+BwKNyc47ACdCDfmhH5N2N9PZ1oRB6mCFHQbchotA0FkeTtRanyVYuS5IeT6OQkJZnaFL2OThd4z8anZNDLmslzQk13oLbaGl59IQ3xagDrSClAmASj8Kx/0St8ZeH1lAR7LFvNDGs
X-Microsoft-Antispam-PRVS: &lt;DM5PR12MB1146EDA6F3771841DA59CE91ECE80@DM5PR12MB1146.namprd12.prod.outlook.com&gt;
X-Exchange-Antispam-Report-Test: UriScan:(767451399110);
X-Exchange-Antispam-Report-CFA-Test: BCL:0; PCL:0;
	RULEID:(6040176)(601004)(2401047)(5005006)(8121501046)(3002001)(10201501046)(6055026);
	SRVR:DM5PR12MB1146; BCL:0; PCL:0; RULEID:; SRVR:DM5PR12MB1146;
X-Microsoft-Exchange-Diagnostics: 1; DM5PR12MB1146;
	4:0/drkYWIAhDe14g94J7rqHaR7MB2UTcLsAP7k40GOgoT2clrauP4L3ziqwQmMrWJPUsJxWQuI81seGwuplmyssrpLbDUH9HkJ2YOXOmyWe5JAvf4sZ7Ne4NcVC4CCqr6p8DHyuNy+9HitOU0Q8rpDDUQLtFrPBsX/MhEadUeBwvMEl4ZdnAwNsgtT27Pg32XeLwh1kMIQUYLS/ZUBxVxOYtmOTOGCP8N9bQGscWmM4KjorcSWEtU6QJldae8LPpfniNp4NcSVvS52H6UQ0PswqpI2WvRRFzeHLzrbIPBEYF6iruj2mbbi8xx6/Tlvp3MGX7CHPCsfxss2wlpediWWT32hPH1DilFLMvd2hSglGVDybPkXiPxzy8FAi2MCG0Wgms1Cylj6aSdZJZTS9fcU6tcdPOl94rnilDAddpiUtZh8cYX7K6eFsbzUhxHoW6h
X-Forefront-PRVS: 00429279BA
X-Forefront-Antispam-Report: SFV:NSPM;
	SFS:(10009020)(4630300001)(6009001)(7916002)(199003)(189002)(77096005)(229853001)(106356001)(101416001)(97736004)(103116003)(47776003)(2950100001)(5001770100001)(586003)(97746001)(92566002)(54356999)(50986999)(76176999)(8676002)(189998001)(5660300001)(33646002)(230700001)(4326007)(7416002)(4001350100001)(3846002)(81156014)(68736007)(81166006)(66066001)(50466002)(7846002)(9686002)(1076002)(6116002)(2906002)(69596002)(19580405001)(83506001)(105586002)(305945005)(575784001)(2201001)(42186005)(53416004)(86362001)(23676002)(19580395003)(7736002)(71626007)(217873001);
	DIR:OUT; SFP:1101; SCL:1; SRVR:DM5PR12MB1146;
	H:tlendack-t1.amdoffice.net; FPR:; SPF:None; PTR:InfoNoRecords;
	A:1; MX:1; LANG:en; 
Received-SPF: None (protection.outlook.com: amd.com does not designate
	permitted sender hosts)
X-Microsoft-Exchange-Diagnostics: =?utf-8?B?MTtETTVQUjEyTUIxMTQ2OzIzOkZ4bHVTcWhjRWZLdlMwSUY1bERUZEtzaW1H?=
	=?utf-8?B?V01UR3MybUk3M3JDS1ZKTnkvYXNCUU9jaFVPVDBlV25KNktHaHdPTi9Ob2lF?=
	=?utf-8?B?d0pqWnc4MW5jUUxjd0JZdVQ0UWlKYlZYZ3g1aEk3dnZybEpqdUtsc2dHQ3py?=
	=?utf-8?B?U2tWQi8zQUliQnRzL0t4M0tCdkVmci9uL3c1c2xJemk2UVpSUndsbHM0NndI?=
	=?utf-8?B?R3JjczlXd0tnY21FUEpvZ3dZVHUrTnBCT1h2REx2NnVUdU1DR3RrcUpDL1Fh?=
	=?utf-8?B?YlF1MWFJRXloUVV6RTI0KzBHYUhmM28waUdNZzFEZDhuVE80NnJNeUt6Sjg0?=
	=?utf-8?B?b3d6T0pWbU1oTjJST01zTzRIVEFUN0s3aHNVcHFwdEh6TDN0NzQvbkVrNnZK?=
	=?utf-8?B?R0VpN0RNZnMzbmVuS0drYTJLWGxabXJXNHdvbkRWNTI3N1pJU0p5M1VjSllh?=
	=?utf-8?B?M0hXQWFHbGxjaTRDc3ZjZ050akcyVmRHSXBIcGsxWG1uU3NZOThOS3FvcHZ1?=
	=?utf-8?B?cUJBb2pOaGk2OHpEVlBFbnZTa1VWcnJRNnp4VHpPcWxhK2UzWHNrWVh0V3ky?=
	=?utf-8?B?UEw4a1ZNR2JZamY5a3YrcHQrTm9DaDJSWjN4U3g2ejBpbEZ5RFg1V2tHaVl3?=
	=?utf-8?B?Rmd5U3dQQ1NPcVZLbWVzQUwxQnlrVmU4WDBVa01NcjkzQkI5U1FNMjJxZGk3?=
	=?utf-8?B?UnhzWC9IZHBtZmJBOVh5Mnl6eVl2aWplUDAzNEZhbHl0dFVnbzdZQzFldVc0?=
	=?utf-8?B?dDltd1VlZEtTamI4SzhHeEZFYU1jRStjcUdaMlZ0SVhNVnoxaVZTYmFJNk1L?=
	=?utf-8?B?R012eFZ6WXQ3djk4SVBzN3E1M21weTFkbEY2VlpJY3grUEszQ2RrV3FWU0xV?=
	=?utf-8?B?RG1rSVJGanlibzdTc2R0YkF6bHZkWDVQcVE1OHlnSUNTdlRyREZYVko0bW14?=
	=?utf-8?B?ckFnOTRwMUdQdXpmVEpTU3RHdjVLSjBPWmQ1L1FHNjNJZjZ3OEdZOFZwWTJx?=
	=?utf-8?B?bi9mMi9kSkpWZEpKUkhOVDVGKzhrZXplVy9WbnRzZGcvelV2UlE2KzJqbTFU?=
	=?utf-8?B?bjBrcnlubXFYNkFsZVFkNWpWVC9yeEhmTjFwOFY3aDNvVW01OVloYTBxWitu?=
	=?utf-8?B?MTg4R0c3ajJEN3o4S25pajg5MEEyMThvajFaenBPSFo3NVpqRmRucWRGUWRD?=
	=?utf-8?B?ZVd3SmZCWGF0SUs2SFRZYmhHUm1jMmJxM0ZoWmxjQXF1UzRnSzg0YmgrWHJN?=
	=?utf-8?B?VlF3bkVhZ1dsaEdSeXUrbGovTHpRVzhZa2dqeVVwZkRQNVZUa0Znd2RGQ1lK?=
	=?utf-8?B?YzdwSGtST3Z2eEp2SDduVmMzSUVvcy9rUmNHNVZTSWdkeVdMVlVKVGFTem9q?=
	=?utf-8?B?ZXRGY2QzUkZYN3ZuOEVSNVR5SCt2SGlWY1V2ZFpEUTE0OEh6OWNRZXo5ZU1Y?=
	=?utf-8?B?bEh1NGFYcW5SWG80aldOOG9GRUVkNHAvK0F3ZzB5dlU0RXVmcThZUjZ3Z3lo?=
	=?utf-8?B?VUVabWI2bUtJbVozeXBKVzJYeUMxWTRDaGozNm52N0o4ZFhxanlRQnI3dm5s?=
	=?utf-8?B?blhDSWxYTHRBT1NTdW9FQjhibERFRG5JQzJ4L1hiZGR0NTFHQktNMWVFbUxY?=
	=?utf-8?B?dzczV3E2OVlEOUpvMjZ3c0ZhZjh2dGl4cFFZUlBvOVhwNWU5QU5Sa2tQY3cy?=
	=?utf-8?B?UzhnRXdNUXJxOGZwRFdpZ0w2emZxS3pjeE9mdDY1bEhEZFdONzB1Y1hlemlI?=
	=?utf-8?B?SjJ3bWw2Q0xaOC92T0RNWmg0Skh2bjJ3RG1jTjUvUG1YcWFhNGpQWkhuQVQv?=
	=?utf-8?Q?5oCsSfQg9yUHp?=
X-Microsoft-Exchange-Diagnostics: 1; DM5PR12MB1146;
	6:QJWxtz2a//FnNGgfGyOBpFm7ALwpfBJJmt/c69FDGZUeksLcydefTekYieBq0d/cOLXCn6sM34hm06f88cVLlPUTYYC5/4W27RsMRsg4U1/f1zNsB0Tw4/x5z28zTJK+X881uHt1Yy8uiU80ZDfw2hFyH0kjCGXUbvzjL0rBoPJpIXgXU8HVtdcQKO6vJTngfAnTtap0BE6KQ9i3CAmeDmj37KZCQQs/AIYqlYzmZD4N9Eg5UF6+gz/HvrBEFLYfIGXAi/BOzd3B1VOGtT8kU7Vd/9n39kQ2zUMmyGibHdwVy12QUleKrDouRNrjrJjuWP7LAF/Kfc4Gt++XBGh2MA==;
	5:STip7Vy+lEcQm+TLaVbiTu7a40n2DkbqPWMyKBaC8fCxxBdpwz5QftPP7rvcjzxmFMkrAutvJEpyKRZMkKlPAA66Ejr5Fp31SFO+8g9RQpDT6vz8TLDIKxS0I8nf4NrE0Mmsi7fChhlZsrLO0TeRbQ==;
	24:h2tBxx2Ab3p2v0eRNMKQJl/1oYSgqv314ld4CqGj54Q17YoR+v8vBZ+Crn+9vIB/1R6kyDi5U40P506+Y/F55yGwwu+U7DY7LYTD0D8Tw2M=;
	7:9BCa1Jc9zaMCDlqE9cU8utwa29JH+n3MgYBVHFtDcqmGHhWVUTrLvgHzvEXm0VDccLFLD2jQm4cpqDVCyfDs8nlTdpsuxLXAH8CrdlS1F5QJTAjnCUGdZw/TbTwLrYT5/LaIhfBtU2fTXdKgajYRpT5gnBOBlkinn1u582keWtPpHh17bSnEbfS7DsTHYeoTPIGJziOFttH3v+VfTiZfNWdzaCt0OpAtbr7fn4C4gkQGRx1+KX3exmPbVWp0DTpV
SpamDiagnosticOutput: 1:99
SpamDiagnosticMetadata: NSPM
X-Microsoft-Exchange-Diagnostics: 1; DM5PR12MB1146;
	20:SmXAj6I6pB9nFloUp2ZxQAKqDpy45m559QOcKcuvnh3xPpDQFZZgQwgEXaJm4/wdnlFNMFpBIlwBT7EYqzGHruJm2SGui6GYIChLkdWdKULl9mPuW9eSRNhvPiDOIWvAsSqel0Zj7hQ07tdCmeyVY8T2RlTK+2ctLIOHVmaALcGRERM0BU5Iozj5RX0BYi5ENXjRDMVGNDRoW0ACYCHGxyZztvDVhlgJIGY2ZSykkLKpBQp2BnFqfkS1RtGbL6pM
X-OriginatorOrg: amd.com
X-MS-Exchange-CrossTenant-OriginalArrivalTime: 22 Aug 2016 22:38:11.6897
	(UTC)
X-MS-Exchange-CrossTenant-FromEntityHeader: Hosted
X-MS-Exchange-Transport-CrossTenantHeadersStamped: DM5PR12MB1146
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=80801">Tom Lendacky</a> - Aug. 22, 2016, 10:38 p.m.</div>
<pre class="content">
Since DMA addresses will effectively look like 48-bit addresses when the
memory encryption mask is set, SWIOTLB is needed if the DMA mask of the
device performing the DMA does not support 48-bits. SWIOTLB will be
initialized to create un-encrypted bounce buffers for use by these devices.
<span class="signed-off-by">
Signed-off-by: Tom Lendacky &lt;thomas.lendacky@amd.com&gt;</span>
---
 arch/x86/include/asm/dma-mapping.h |    5 ++-
 arch/x86/include/asm/mem_encrypt.h |    6 +++
 arch/x86/kernel/pci-dma.c          |   11 ++++--
 arch/x86/kernel/pci-nommu.c        |    2 +
 arch/x86/kernel/pci-swiotlb.c      |    8 +++--
 arch/x86/mm/mem_encrypt.c          |   22 ++++++++++++
 include/linux/swiotlb.h            |    1 +
 init/main.c                        |   13 +++++++
 lib/swiotlb.c                      |   64 ++++++++++++++++++++++++++++++++----
 9 files changed, 115 insertions(+), 17 deletions(-)
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=7500">Borislav Petkov</a> - Sept. 12, 2016, 10:58 a.m.</div>
<pre class="content">
On Mon, Aug 22, 2016 at 05:38:07PM -0500, Tom Lendacky wrote:
<span class="quote">&gt; Since DMA addresses will effectively look like 48-bit addresses when the</span>
<span class="quote">&gt; memory encryption mask is set, SWIOTLB is needed if the DMA mask of the</span>
<span class="quote">&gt; device performing the DMA does not support 48-bits. SWIOTLB will be</span>
<span class="quote">&gt; initialized to create un-encrypted bounce buffers for use by these devices.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Signed-off-by: Tom Lendacky &lt;thomas.lendacky@amd.com&gt;</span>
<span class="quote">&gt; ---</span>
<span class="quote">&gt;  arch/x86/include/asm/dma-mapping.h |    5 ++-</span>
<span class="quote">&gt;  arch/x86/include/asm/mem_encrypt.h |    6 +++</span>
<span class="quote">&gt;  arch/x86/kernel/pci-dma.c          |   11 ++++--</span>
<span class="quote">&gt;  arch/x86/kernel/pci-nommu.c        |    2 +</span>
<span class="quote">&gt;  arch/x86/kernel/pci-swiotlb.c      |    8 +++--</span>
<span class="quote">&gt;  arch/x86/mm/mem_encrypt.c          |   22 ++++++++++++</span>
<span class="quote">&gt;  include/linux/swiotlb.h            |    1 +</span>
<span class="quote">&gt;  init/main.c                        |   13 +++++++</span>
<span class="quote">&gt;  lib/swiotlb.c                      |   64 ++++++++++++++++++++++++++++++++----</span>
<span class="quote">&gt;  9 files changed, 115 insertions(+), 17 deletions(-)</span>

...
<span class="quote">
&gt; @@ -172,3 +174,23 @@ void __init sme_early_init(void)</span>
<span class="quote">&gt;  	for (i = 0; i &lt; ARRAY_SIZE(protection_map); i++)</span>
<span class="quote">&gt;  		protection_map[i] = __pgprot(pgprot_val(protection_map[i]) | sme_me_mask);</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +/* Architecture __weak replacement functions */</span>
<span class="quote">&gt; +void __init mem_encrypt_init(void)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	if (!sme_me_mask)</span>
<span class="quote">&gt; +		return;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	/* Make SWIOTLB use an unencrypted DMA area */</span>
<span class="quote">&gt; +	swiotlb_clear_encryption();</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +unsigned long swiotlb_get_me_mask(void)</span>

This could just as well be named to something more generic:

swiotlb_get_clear_dma_mask() or so which basically means the mask of
bits which get cleared before returning DMA addresses...
<span class="quote">
&gt; +{</span>
<span class="quote">&gt; +	return sme_me_mask;</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +void swiotlb_set_mem_dec(void *vaddr, unsigned long size)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	sme_set_mem_dec(vaddr, size);</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; diff --git a/include/linux/swiotlb.h b/include/linux/swiotlb.h</span>
<span class="quote">&gt; index 5f81f8a..5c909fc 100644</span>
<span class="quote">&gt; --- a/include/linux/swiotlb.h</span>
<span class="quote">&gt; +++ b/include/linux/swiotlb.h</span>
<span class="quote">&gt; @@ -29,6 +29,7 @@ int swiotlb_init_with_tbl(char *tlb, unsigned long nslabs, int verbose);</span>
<span class="quote">&gt;  extern unsigned long swiotlb_nr_tbl(void);</span>
<span class="quote">&gt;  unsigned long swiotlb_size_or_default(void);</span>
<span class="quote">&gt;  extern int swiotlb_late_init_with_tbl(char *tlb, unsigned long nslabs);</span>
<span class="quote">&gt; +extern void __init swiotlb_clear_encryption(void);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  /*</span>
<span class="quote">&gt;   * Enumeration for sync targets</span>
<span class="quote">&gt; diff --git a/init/main.c b/init/main.c</span>
<span class="quote">&gt; index a8a58e2..82c7cd9 100644</span>
<span class="quote">&gt; --- a/init/main.c</span>
<span class="quote">&gt; +++ b/init/main.c</span>
<span class="quote">&gt; @@ -458,6 +458,10 @@ void __init __weak thread_stack_cache_init(void)</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;  #endif</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; +void __init __weak mem_encrypt_init(void)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt;  /*</span>
<span class="quote">&gt;   * Set up kernel memory allocators</span>
<span class="quote">&gt;   */</span>
<span class="quote">&gt; @@ -598,6 +602,15 @@ asmlinkage __visible void __init start_kernel(void)</span>
<span class="quote">&gt;  	 */</span>
<span class="quote">&gt;  	locking_selftest();</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; +	/*</span>
<span class="quote">&gt; +	 * This needs to be called before any devices perform DMA</span>
<span class="quote">&gt; +	 * operations that might use the swiotlb bounce buffers.</span>
<span class="quote">&gt; +	 * This call will mark the bounce buffers as un-encrypted so</span>
<span class="quote">&gt; +	 * that the usage of them will not cause &quot;plain-text&quot; data</span>

	...that their usage will not cause ...
<span class="quote">
&gt; +	 * to be decrypted when accessed.</span>
<span class="quote">&gt; +	 */</span>
<span class="quote">&gt; +	mem_encrypt_init();</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt;  #ifdef CONFIG_BLK_DEV_INITRD</span>
<span class="quote">&gt;  	if (initrd_start &amp;&amp; !initrd_below_start_ok &amp;&amp;</span>
<span class="quote">&gt;  	    page_to_pfn(virt_to_page((void *)initrd_start)) &lt; min_low_pfn) {</span>
<span class="quote">&gt; diff --git a/lib/swiotlb.c b/lib/swiotlb.c</span>
<span class="quote">&gt; index 22e13a0..15d5741 100644</span>
<span class="quote">&gt; --- a/lib/swiotlb.c</span>
<span class="quote">&gt; +++ b/lib/swiotlb.c</span>
<span class="quote">&gt; @@ -131,6 +131,26 @@ unsigned long swiotlb_size_or_default(void)</span>
<span class="quote">&gt;  	return size ? size : (IO_TLB_DEFAULT_SIZE);</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; +/*</span>
<span class="quote">&gt; + * Support for memory encryption. If memory encryption is supported, then an</span>
<span class="quote">&gt; + * override to these functions will be provided.</span>
<span class="quote">&gt; + */</span>

No need for that comment.
<span class="quote">
&gt; +unsigned long __weak swiotlb_get_me_mask(void)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	return 0;</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +void __weak swiotlb_set_mem_dec(void *vaddr, unsigned long size)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +/* For swiotlb, clear memory encryption mask from dma addresses */</span>
<span class="quote">&gt; +static dma_addr_t swiotlb_phys_to_dma(struct device *hwdev,</span>
<span class="quote">&gt; +				      phys_addr_t address)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	return phys_to_dma(hwdev, address) &amp; ~swiotlb_get_me_mask();</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt;  /* Note that this doesn&#39;t work with highmem page */</span>
<span class="quote">&gt;  static dma_addr_t swiotlb_virt_to_bus(struct device *hwdev,</span>
<span class="quote">&gt;  				      volatile void *address)</span>
<span class="quote">&gt; @@ -159,6 +179,30 @@ void swiotlb_print_info(void)</span>
<span class="quote">&gt;  	       bytes &gt;&gt; 20, vstart, vend - 1);</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; +/*</span>
<span class="quote">&gt; + * If memory encryption is active, the DMA address for an encrypted page may</span>
<span class="quote">&gt; + * be beyond the range of the device. If bounce buffers are required be sure</span>
<span class="quote">&gt; + * that they are not on an encrypted page. This should be called before the</span>
<span class="quote">&gt; + * iotlb area is used.</span>
<span class="quote">&gt; + */</span>
<span class="quote">&gt; +void __init swiotlb_clear_encryption(void)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	void *vaddr;</span>
<span class="quote">&gt; +	unsigned long bytes;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	if (no_iotlb_memory || !io_tlb_start || late_alloc)</span>
<span class="quote">&gt; +		return;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	vaddr = phys_to_virt(io_tlb_start);</span>
<span class="quote">&gt; +	bytes = PAGE_ALIGN(io_tlb_nslabs &lt;&lt; IO_TLB_SHIFT);</span>
<span class="quote">&gt; +	swiotlb_set_mem_dec(vaddr, bytes);</span>
<span class="quote">&gt; +	memset(vaddr, 0, bytes);</span>

io_tlb_start is cleared...
<span class="quote">
&gt; +</span>
<span class="quote">&gt; +	vaddr = phys_to_virt(io_tlb_overflow_buffer);</span>
<span class="quote">&gt; +	bytes = PAGE_ALIGN(io_tlb_overflow);</span>
<span class="quote">&gt; +	swiotlb_set_mem_dec(vaddr, bytes);</span>

... but io_tlb_overflow_buffer isn&#39;t? I don&#39;t see the difference here.
<span class="quote">
&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt;  int __init swiotlb_init_with_tbl(char *tlb, unsigned long nslabs, int verbose)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	void *v_overflow_buffer;</span>
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=80801">Tom Lendacky</a> - Sept. 14, 2016, 1:36 p.m.</div>
<pre class="content">
On 09/12/2016 05:58 AM, Borislav Petkov wrote:
<span class="quote">&gt; On Mon, Aug 22, 2016 at 05:38:07PM -0500, Tom Lendacky wrote:</span>
<span class="quote">&gt;&gt; Since DMA addresses will effectively look like 48-bit addresses when the</span>
<span class="quote">&gt;&gt; memory encryption mask is set, SWIOTLB is needed if the DMA mask of the</span>
<span class="quote">&gt;&gt; device performing the DMA does not support 48-bits. SWIOTLB will be</span>
<span class="quote">&gt;&gt; initialized to create un-encrypted bounce buffers for use by these devices.</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; Signed-off-by: Tom Lendacky &lt;thomas.lendacky@amd.com&gt;</span>
<span class="quote">&gt;&gt; ---</span>
<span class="quote">&gt;&gt;  arch/x86/include/asm/dma-mapping.h |    5 ++-</span>
<span class="quote">&gt;&gt;  arch/x86/include/asm/mem_encrypt.h |    6 +++</span>
<span class="quote">&gt;&gt;  arch/x86/kernel/pci-dma.c          |   11 ++++--</span>
<span class="quote">&gt;&gt;  arch/x86/kernel/pci-nommu.c        |    2 +</span>
<span class="quote">&gt;&gt;  arch/x86/kernel/pci-swiotlb.c      |    8 +++--</span>
<span class="quote">&gt;&gt;  arch/x86/mm/mem_encrypt.c          |   22 ++++++++++++</span>
<span class="quote">&gt;&gt;  include/linux/swiotlb.h            |    1 +</span>
<span class="quote">&gt;&gt;  init/main.c                        |   13 +++++++</span>
<span class="quote">&gt;&gt;  lib/swiotlb.c                      |   64 ++++++++++++++++++++++++++++++++----</span>
<span class="quote">&gt;&gt;  9 files changed, 115 insertions(+), 17 deletions(-)</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; ...</span>
<span class="quote">&gt; </span>
<span class="quote">&gt;&gt; @@ -172,3 +174,23 @@ void __init sme_early_init(void)</span>
<span class="quote">&gt;&gt;  	for (i = 0; i &lt; ARRAY_SIZE(protection_map); i++)</span>
<span class="quote">&gt;&gt;  		protection_map[i] = __pgprot(pgprot_val(protection_map[i]) | sme_me_mask);</span>
<span class="quote">&gt;&gt;  }</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +/* Architecture __weak replacement functions */</span>
<span class="quote">&gt;&gt; +void __init mem_encrypt_init(void)</span>
<span class="quote">&gt;&gt; +{</span>
<span class="quote">&gt;&gt; +	if (!sme_me_mask)</span>
<span class="quote">&gt;&gt; +		return;</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +	/* Make SWIOTLB use an unencrypted DMA area */</span>
<span class="quote">&gt;&gt; +	swiotlb_clear_encryption();</span>
<span class="quote">&gt;&gt; +}</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +unsigned long swiotlb_get_me_mask(void)</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; This could just as well be named to something more generic:</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; swiotlb_get_clear_dma_mask() or so which basically means the mask of</span>
<span class="quote">&gt; bits which get cleared before returning DMA addresses...</span>

Ok.
<span class="quote">
&gt; </span>
<span class="quote">&gt;&gt; +{</span>
<span class="quote">&gt;&gt; +	return sme_me_mask;</span>
<span class="quote">&gt;&gt; +}</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +void swiotlb_set_mem_dec(void *vaddr, unsigned long size)</span>
<span class="quote">&gt;&gt; +{</span>
<span class="quote">&gt;&gt; +	sme_set_mem_dec(vaddr, size);</span>
<span class="quote">&gt;&gt; +}</span>
<span class="quote">&gt;&gt; diff --git a/include/linux/swiotlb.h b/include/linux/swiotlb.h</span>
<span class="quote">&gt;&gt; index 5f81f8a..5c909fc 100644</span>
<span class="quote">&gt;&gt; --- a/include/linux/swiotlb.h</span>
<span class="quote">&gt;&gt; +++ b/include/linux/swiotlb.h</span>
<span class="quote">&gt;&gt; @@ -29,6 +29,7 @@ int swiotlb_init_with_tbl(char *tlb, unsigned long nslabs, int verbose);</span>
<span class="quote">&gt;&gt;  extern unsigned long swiotlb_nr_tbl(void);</span>
<span class="quote">&gt;&gt;  unsigned long swiotlb_size_or_default(void);</span>
<span class="quote">&gt;&gt;  extern int swiotlb_late_init_with_tbl(char *tlb, unsigned long nslabs);</span>
<span class="quote">&gt;&gt; +extern void __init swiotlb_clear_encryption(void);</span>
<span class="quote">&gt;&gt;  </span>
<span class="quote">&gt;&gt;  /*</span>
<span class="quote">&gt;&gt;   * Enumeration for sync targets</span>
<span class="quote">&gt;&gt; diff --git a/init/main.c b/init/main.c</span>
<span class="quote">&gt;&gt; index a8a58e2..82c7cd9 100644</span>
<span class="quote">&gt;&gt; --- a/init/main.c</span>
<span class="quote">&gt;&gt; +++ b/init/main.c</span>
<span class="quote">&gt;&gt; @@ -458,6 +458,10 @@ void __init __weak thread_stack_cache_init(void)</span>
<span class="quote">&gt;&gt;  }</span>
<span class="quote">&gt;&gt;  #endif</span>
<span class="quote">&gt;&gt;  </span>
<span class="quote">&gt;&gt; +void __init __weak mem_encrypt_init(void)</span>
<span class="quote">&gt;&gt; +{</span>
<span class="quote">&gt;&gt; +}</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt;  /*</span>
<span class="quote">&gt;&gt;   * Set up kernel memory allocators</span>
<span class="quote">&gt;&gt;   */</span>
<span class="quote">&gt;&gt; @@ -598,6 +602,15 @@ asmlinkage __visible void __init start_kernel(void)</span>
<span class="quote">&gt;&gt;  	 */</span>
<span class="quote">&gt;&gt;  	locking_selftest();</span>
<span class="quote">&gt;&gt;  </span>
<span class="quote">&gt;&gt; +	/*</span>
<span class="quote">&gt;&gt; +	 * This needs to be called before any devices perform DMA</span>
<span class="quote">&gt;&gt; +	 * operations that might use the swiotlb bounce buffers.</span>
<span class="quote">&gt;&gt; +	 * This call will mark the bounce buffers as un-encrypted so</span>
<span class="quote">&gt;&gt; +	 * that the usage of them will not cause &quot;plain-text&quot; data</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; 	...that their usage will not cause ...</span>

Ok.
<span class="quote">
&gt; </span>
<span class="quote">&gt;&gt; +	 * to be decrypted when accessed.</span>
<span class="quote">&gt;&gt; +	 */</span>
<span class="quote">&gt;&gt; +	mem_encrypt_init();</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt;  #ifdef CONFIG_BLK_DEV_INITRD</span>
<span class="quote">&gt;&gt;  	if (initrd_start &amp;&amp; !initrd_below_start_ok &amp;&amp;</span>
<span class="quote">&gt;&gt;  	    page_to_pfn(virt_to_page((void *)initrd_start)) &lt; min_low_pfn) {</span>
<span class="quote">&gt;&gt; diff --git a/lib/swiotlb.c b/lib/swiotlb.c</span>
<span class="quote">&gt;&gt; index 22e13a0..15d5741 100644</span>
<span class="quote">&gt;&gt; --- a/lib/swiotlb.c</span>
<span class="quote">&gt;&gt; +++ b/lib/swiotlb.c</span>
<span class="quote">&gt;&gt; @@ -131,6 +131,26 @@ unsigned long swiotlb_size_or_default(void)</span>
<span class="quote">&gt;&gt;  	return size ? size : (IO_TLB_DEFAULT_SIZE);</span>
<span class="quote">&gt;&gt;  }</span>
<span class="quote">&gt;&gt;  </span>
<span class="quote">&gt;&gt; +/*</span>
<span class="quote">&gt;&gt; + * Support for memory encryption. If memory encryption is supported, then an</span>
<span class="quote">&gt;&gt; + * override to these functions will be provided.</span>
<span class="quote">&gt;&gt; + */</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; No need for that comment.</span>

Ok.
<span class="quote">
&gt; </span>
<span class="quote">&gt;&gt; +unsigned long __weak swiotlb_get_me_mask(void)</span>
<span class="quote">&gt;&gt; +{</span>
<span class="quote">&gt;&gt; +	return 0;</span>
<span class="quote">&gt;&gt; +}</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +void __weak swiotlb_set_mem_dec(void *vaddr, unsigned long size)</span>
<span class="quote">&gt;&gt; +{</span>
<span class="quote">&gt;&gt; +}</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +/* For swiotlb, clear memory encryption mask from dma addresses */</span>
<span class="quote">&gt;&gt; +static dma_addr_t swiotlb_phys_to_dma(struct device *hwdev,</span>
<span class="quote">&gt;&gt; +				      phys_addr_t address)</span>
<span class="quote">&gt;&gt; +{</span>
<span class="quote">&gt;&gt; +	return phys_to_dma(hwdev, address) &amp; ~swiotlb_get_me_mask();</span>
<span class="quote">&gt;&gt; +}</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt;  /* Note that this doesn&#39;t work with highmem page */</span>
<span class="quote">&gt;&gt;  static dma_addr_t swiotlb_virt_to_bus(struct device *hwdev,</span>
<span class="quote">&gt;&gt;  				      volatile void *address)</span>
<span class="quote">&gt;&gt; @@ -159,6 +179,30 @@ void swiotlb_print_info(void)</span>
<span class="quote">&gt;&gt;  	       bytes &gt;&gt; 20, vstart, vend - 1);</span>
<span class="quote">&gt;&gt;  }</span>
<span class="quote">&gt;&gt;  </span>
<span class="quote">&gt;&gt; +/*</span>
<span class="quote">&gt;&gt; + * If memory encryption is active, the DMA address for an encrypted page may</span>
<span class="quote">&gt;&gt; + * be beyond the range of the device. If bounce buffers are required be sure</span>
<span class="quote">&gt;&gt; + * that they are not on an encrypted page. This should be called before the</span>
<span class="quote">&gt;&gt; + * iotlb area is used.</span>
<span class="quote">&gt;&gt; + */</span>
<span class="quote">&gt;&gt; +void __init swiotlb_clear_encryption(void)</span>
<span class="quote">&gt;&gt; +{</span>
<span class="quote">&gt;&gt; +	void *vaddr;</span>
<span class="quote">&gt;&gt; +	unsigned long bytes;</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +	if (no_iotlb_memory || !io_tlb_start || late_alloc)</span>
<span class="quote">&gt;&gt; +		return;</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +	vaddr = phys_to_virt(io_tlb_start);</span>
<span class="quote">&gt;&gt; +	bytes = PAGE_ALIGN(io_tlb_nslabs &lt;&lt; IO_TLB_SHIFT);</span>
<span class="quote">&gt;&gt; +	swiotlb_set_mem_dec(vaddr, bytes);</span>
<span class="quote">&gt;&gt; +	memset(vaddr, 0, bytes);</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; io_tlb_start is cleared...</span>
<span class="quote">&gt; </span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +	vaddr = phys_to_virt(io_tlb_overflow_buffer);</span>
<span class="quote">&gt;&gt; +	bytes = PAGE_ALIGN(io_tlb_overflow);</span>
<span class="quote">&gt;&gt; +	swiotlb_set_mem_dec(vaddr, bytes);</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; ... but io_tlb_overflow_buffer isn&#39;t? I don&#39;t see the difference here.</span>

Yup, I missed that one.  Will memset this as well.

Thanks,
Tom
<span class="quote">
&gt; </span>
<span class="quote">&gt;&gt; +}</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt;  int __init swiotlb_init_with_tbl(char *tlb, unsigned long nslabs, int verbose)</span>
<span class="quote">&gt;&gt;  {</span>
<span class="quote">&gt;&gt;  	void *v_overflow_buffer;</span>
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/arch/x86/include/asm/dma-mapping.h b/arch/x86/include/asm/dma-mapping.h</span>
<span class="p_header">index 4446162..c9cdcae 100644</span>
<span class="p_header">--- a/arch/x86/include/asm/dma-mapping.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/dma-mapping.h</span>
<span class="p_chunk">@@ -12,6 +12,7 @@</span> <span class="p_context"></span>
 #include &lt;asm/io.h&gt;
 #include &lt;asm/swiotlb.h&gt;
 #include &lt;linux/dma-contiguous.h&gt;
<span class="p_add">+#include &lt;asm/mem_encrypt.h&gt;</span>
 
 #ifdef CONFIG_ISA
 # define ISA_DMA_BIT_MASK DMA_BIT_MASK(24)
<span class="p_chunk">@@ -69,12 +70,12 @@</span> <span class="p_context"> static inline bool dma_capable(struct device *dev, dma_addr_t addr, size_t size)</span>
 
 static inline dma_addr_t phys_to_dma(struct device *dev, phys_addr_t paddr)
 {
<span class="p_del">-	return paddr;</span>
<span class="p_add">+	return paddr | sme_me_mask;</span>
 }
 
 static inline phys_addr_t dma_to_phys(struct device *dev, dma_addr_t daddr)
 {
<span class="p_del">-	return daddr;</span>
<span class="p_add">+	return daddr &amp; ~sme_me_mask;</span>
 }
 #endif /* CONFIG_X86_DMA_REMAP */
 
<span class="p_header">diff --git a/arch/x86/include/asm/mem_encrypt.h b/arch/x86/include/asm/mem_encrypt.h</span>
<span class="p_header">index 5616ed1..384fdfb 100644</span>
<span class="p_header">--- a/arch/x86/include/asm/mem_encrypt.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/mem_encrypt.h</span>
<span class="p_chunk">@@ -33,6 +33,12 @@</span> <span class="p_context"> void __init sme_early_mem_dec(resource_size_t paddr,</span>
 
 void __init sme_early_init(void);
 
<span class="p_add">+/* Architecture __weak replacement functions */</span>
<span class="p_add">+void __init mem_encrypt_init(void);</span>
<span class="p_add">+</span>
<span class="p_add">+unsigned long swiotlb_get_me_mask(void);</span>
<span class="p_add">+void swiotlb_set_mem_dec(void *vaddr, unsigned long size);</span>
<span class="p_add">+</span>
 #define __sme_pa(x)		(__pa((x)) | sme_me_mask)
 #define __sme_pa_nodebug(x)	(__pa_nodebug((x)) | sme_me_mask)
 
<span class="p_header">diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c</span>
<span class="p_header">index d30c377..0ce28df 100644</span>
<span class="p_header">--- a/arch/x86/kernel/pci-dma.c</span>
<span class="p_header">+++ b/arch/x86/kernel/pci-dma.c</span>
<span class="p_chunk">@@ -92,9 +92,12 @@</span> <span class="p_context"> again:</span>
 	/* CMA can be used only in the context which permits sleeping */
 	if (gfpflags_allow_blocking(flag)) {
 		page = dma_alloc_from_contiguous(dev, count, get_order(size));
<span class="p_del">-		if (page &amp;&amp; page_to_phys(page) + size &gt; dma_mask) {</span>
<span class="p_del">-			dma_release_from_contiguous(dev, page, count);</span>
<span class="p_del">-			page = NULL;</span>
<span class="p_add">+		if (page) {</span>
<span class="p_add">+			addr = phys_to_dma(dev, page_to_phys(page));</span>
<span class="p_add">+			if (addr + size &gt; dma_mask) {</span>
<span class="p_add">+				dma_release_from_contiguous(dev, page, count);</span>
<span class="p_add">+				page = NULL;</span>
<span class="p_add">+			}</span>
 		}
 	}
 	/* fallback */
<span class="p_chunk">@@ -103,7 +106,7 @@</span> <span class="p_context"> again:</span>
 	if (!page)
 		return NULL;
 
<span class="p_del">-	addr = page_to_phys(page);</span>
<span class="p_add">+	addr = phys_to_dma(dev, page_to_phys(page));</span>
 	if (addr + size &gt; dma_mask) {
 		__free_pages(page, get_order(size));
 
<span class="p_header">diff --git a/arch/x86/kernel/pci-nommu.c b/arch/x86/kernel/pci-nommu.c</span>
<span class="p_header">index 00e71ce..922c10d 100644</span>
<span class="p_header">--- a/arch/x86/kernel/pci-nommu.c</span>
<span class="p_header">+++ b/arch/x86/kernel/pci-nommu.c</span>
<span class="p_chunk">@@ -30,7 +30,7 @@</span> <span class="p_context"> static dma_addr_t nommu_map_page(struct device *dev, struct page *page,</span>
 				 enum dma_data_direction dir,
 				 unsigned long attrs)
 {
<span class="p_del">-	dma_addr_t bus = page_to_phys(page) + offset;</span>
<span class="p_add">+	dma_addr_t bus = phys_to_dma(dev, page_to_phys(page)) + offset;</span>
 	WARN_ON(size == 0);
 	if (!check_addr(&quot;map_single&quot;, dev, bus, size))
 		return DMA_ERROR_CODE;
<span class="p_header">diff --git a/arch/x86/kernel/pci-swiotlb.c b/arch/x86/kernel/pci-swiotlb.c</span>
<span class="p_header">index b47edb8..34a9e524 100644</span>
<span class="p_header">--- a/arch/x86/kernel/pci-swiotlb.c</span>
<span class="p_header">+++ b/arch/x86/kernel/pci-swiotlb.c</span>
<span class="p_chunk">@@ -12,6 +12,8 @@</span> <span class="p_context"></span>
 #include &lt;asm/dma.h&gt;
 #include &lt;asm/xen/swiotlb-xen.h&gt;
 #include &lt;asm/iommu_table.h&gt;
<span class="p_add">+#include &lt;asm/mem_encrypt.h&gt;</span>
<span class="p_add">+</span>
 int swiotlb __read_mostly;
 
 void *x86_swiotlb_alloc_coherent(struct device *hwdev, size_t size,
<span class="p_chunk">@@ -64,13 +66,15 @@</span> <span class="p_context"> static struct dma_map_ops swiotlb_dma_ops = {</span>
  * pci_swiotlb_detect_override - set swiotlb to 1 if necessary
  *
  * This returns non-zero if we are forced to use swiotlb (by the boot
<span class="p_del">- * option).</span>
<span class="p_add">+ * option). If memory encryption is enabled then swiotlb will be set</span>
<span class="p_add">+ * to 1 so that bounce buffers are allocated and used for devices that</span>
<span class="p_add">+ * do not support the addressing range required for the encryption mask.</span>
  */
 int __init pci_swiotlb_detect_override(void)
 {
 	int use_swiotlb = swiotlb | swiotlb_force;
 
<span class="p_del">-	if (swiotlb_force)</span>
<span class="p_add">+	if (swiotlb_force || sme_me_mask)</span>
 		swiotlb = 1;
 
 	return use_swiotlb;
<span class="p_header">diff --git a/arch/x86/mm/mem_encrypt.c b/arch/x86/mm/mem_encrypt.c</span>
<span class="p_header">index b0f39c5..6b2e8bf 100644</span>
<span class="p_header">--- a/arch/x86/mm/mem_encrypt.c</span>
<span class="p_header">+++ b/arch/x86/mm/mem_encrypt.c</span>
<span class="p_chunk">@@ -12,6 +12,8 @@</span> <span class="p_context"></span>
 
 #include &lt;linux/init.h&gt;
 #include &lt;linux/mm.h&gt;
<span class="p_add">+#include &lt;linux/dma-mapping.h&gt;</span>
<span class="p_add">+#include &lt;linux/swiotlb.h&gt;</span>
 
 #include &lt;asm/mem_encrypt.h&gt;
 #include &lt;asm/cacheflush.h&gt;
<span class="p_chunk">@@ -172,3 +174,23 @@</span> <span class="p_context"> void __init sme_early_init(void)</span>
 	for (i = 0; i &lt; ARRAY_SIZE(protection_map); i++)
 		protection_map[i] = __pgprot(pgprot_val(protection_map[i]) | sme_me_mask);
 }
<span class="p_add">+</span>
<span class="p_add">+/* Architecture __weak replacement functions */</span>
<span class="p_add">+void __init mem_encrypt_init(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	if (!sme_me_mask)</span>
<span class="p_add">+		return;</span>
<span class="p_add">+</span>
<span class="p_add">+	/* Make SWIOTLB use an unencrypted DMA area */</span>
<span class="p_add">+	swiotlb_clear_encryption();</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+unsigned long swiotlb_get_me_mask(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return sme_me_mask;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void swiotlb_set_mem_dec(void *vaddr, unsigned long size)</span>
<span class="p_add">+{</span>
<span class="p_add">+	sme_set_mem_dec(vaddr, size);</span>
<span class="p_add">+}</span>
<span class="p_header">diff --git a/include/linux/swiotlb.h b/include/linux/swiotlb.h</span>
<span class="p_header">index 5f81f8a..5c909fc 100644</span>
<span class="p_header">--- a/include/linux/swiotlb.h</span>
<span class="p_header">+++ b/include/linux/swiotlb.h</span>
<span class="p_chunk">@@ -29,6 +29,7 @@</span> <span class="p_context"> int swiotlb_init_with_tbl(char *tlb, unsigned long nslabs, int verbose);</span>
 extern unsigned long swiotlb_nr_tbl(void);
 unsigned long swiotlb_size_or_default(void);
 extern int swiotlb_late_init_with_tbl(char *tlb, unsigned long nslabs);
<span class="p_add">+extern void __init swiotlb_clear_encryption(void);</span>
 
 /*
  * Enumeration for sync targets
<span class="p_header">diff --git a/init/main.c b/init/main.c</span>
<span class="p_header">index a8a58e2..82c7cd9 100644</span>
<span class="p_header">--- a/init/main.c</span>
<span class="p_header">+++ b/init/main.c</span>
<span class="p_chunk">@@ -458,6 +458,10 @@</span> <span class="p_context"> void __init __weak thread_stack_cache_init(void)</span>
 }
 #endif
 
<span class="p_add">+void __init __weak mem_encrypt_init(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 /*
  * Set up kernel memory allocators
  */
<span class="p_chunk">@@ -598,6 +602,15 @@</span> <span class="p_context"> asmlinkage __visible void __init start_kernel(void)</span>
 	 */
 	locking_selftest();
 
<span class="p_add">+	/*</span>
<span class="p_add">+	 * This needs to be called before any devices perform DMA</span>
<span class="p_add">+	 * operations that might use the swiotlb bounce buffers.</span>
<span class="p_add">+	 * This call will mark the bounce buffers as un-encrypted so</span>
<span class="p_add">+	 * that the usage of them will not cause &quot;plain-text&quot; data</span>
<span class="p_add">+	 * to be decrypted when accessed.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	mem_encrypt_init();</span>
<span class="p_add">+</span>
 #ifdef CONFIG_BLK_DEV_INITRD
 	if (initrd_start &amp;&amp; !initrd_below_start_ok &amp;&amp;
 	    page_to_pfn(virt_to_page((void *)initrd_start)) &lt; min_low_pfn) {
<span class="p_header">diff --git a/lib/swiotlb.c b/lib/swiotlb.c</span>
<span class="p_header">index 22e13a0..15d5741 100644</span>
<span class="p_header">--- a/lib/swiotlb.c</span>
<span class="p_header">+++ b/lib/swiotlb.c</span>
<span class="p_chunk">@@ -131,6 +131,26 @@</span> <span class="p_context"> unsigned long swiotlb_size_or_default(void)</span>
 	return size ? size : (IO_TLB_DEFAULT_SIZE);
 }
 
<span class="p_add">+/*</span>
<span class="p_add">+ * Support for memory encryption. If memory encryption is supported, then an</span>
<span class="p_add">+ * override to these functions will be provided.</span>
<span class="p_add">+ */</span>
<span class="p_add">+unsigned long __weak swiotlb_get_me_mask(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return 0;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void __weak swiotlb_set_mem_dec(void *vaddr, unsigned long size)</span>
<span class="p_add">+{</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+/* For swiotlb, clear memory encryption mask from dma addresses */</span>
<span class="p_add">+static dma_addr_t swiotlb_phys_to_dma(struct device *hwdev,</span>
<span class="p_add">+				      phys_addr_t address)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return phys_to_dma(hwdev, address) &amp; ~swiotlb_get_me_mask();</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 /* Note that this doesn&#39;t work with highmem page */
 static dma_addr_t swiotlb_virt_to_bus(struct device *hwdev,
 				      volatile void *address)
<span class="p_chunk">@@ -159,6 +179,30 @@</span> <span class="p_context"> void swiotlb_print_info(void)</span>
 	       bytes &gt;&gt; 20, vstart, vend - 1);
 }
 
<span class="p_add">+/*</span>
<span class="p_add">+ * If memory encryption is active, the DMA address for an encrypted page may</span>
<span class="p_add">+ * be beyond the range of the device. If bounce buffers are required be sure</span>
<span class="p_add">+ * that they are not on an encrypted page. This should be called before the</span>
<span class="p_add">+ * iotlb area is used.</span>
<span class="p_add">+ */</span>
<span class="p_add">+void __init swiotlb_clear_encryption(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	void *vaddr;</span>
<span class="p_add">+	unsigned long bytes;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (no_iotlb_memory || !io_tlb_start || late_alloc)</span>
<span class="p_add">+		return;</span>
<span class="p_add">+</span>
<span class="p_add">+	vaddr = phys_to_virt(io_tlb_start);</span>
<span class="p_add">+	bytes = PAGE_ALIGN(io_tlb_nslabs &lt;&lt; IO_TLB_SHIFT);</span>
<span class="p_add">+	swiotlb_set_mem_dec(vaddr, bytes);</span>
<span class="p_add">+	memset(vaddr, 0, bytes);</span>
<span class="p_add">+</span>
<span class="p_add">+	vaddr = phys_to_virt(io_tlb_overflow_buffer);</span>
<span class="p_add">+	bytes = PAGE_ALIGN(io_tlb_overflow);</span>
<span class="p_add">+	swiotlb_set_mem_dec(vaddr, bytes);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 int __init swiotlb_init_with_tbl(char *tlb, unsigned long nslabs, int verbose)
 {
 	void *v_overflow_buffer;
<span class="p_chunk">@@ -294,6 +338,8 @@</span> <span class="p_context"> swiotlb_late_init_with_tbl(char *tlb, unsigned long nslabs)</span>
 	io_tlb_start = virt_to_phys(tlb);
 	io_tlb_end = io_tlb_start + bytes;
 
<span class="p_add">+	/* Keep TLB in unencrypted memory if memory encryption is active */</span>
<span class="p_add">+	swiotlb_set_mem_dec(tlb, bytes);</span>
 	memset(tlb, 0, bytes);
 
 	/*
<span class="p_chunk">@@ -304,6 +350,8 @@</span> <span class="p_context"> swiotlb_late_init_with_tbl(char *tlb, unsigned long nslabs)</span>
 	if (!v_overflow_buffer)
 		goto cleanup2;
 
<span class="p_add">+	/* Keep overflow in unencrypted memory if memory encryption is active */</span>
<span class="p_add">+	swiotlb_set_mem_dec(v_overflow_buffer, io_tlb_overflow);</span>
 	io_tlb_overflow_buffer = virt_to_phys(v_overflow_buffer);
 
 	/*
<span class="p_chunk">@@ -541,7 +589,7 @@</span> <span class="p_context"> static phys_addr_t</span>
 map_single(struct device *hwdev, phys_addr_t phys, size_t size,
 	   enum dma_data_direction dir)
 {
<span class="p_del">-	dma_addr_t start_dma_addr = phys_to_dma(hwdev, io_tlb_start);</span>
<span class="p_add">+	dma_addr_t start_dma_addr = swiotlb_phys_to_dma(hwdev, io_tlb_start);</span>
 
 	return swiotlb_tbl_map_single(hwdev, start_dma_addr, phys, size, dir);
 }
<span class="p_chunk">@@ -659,7 +707,7 @@</span> <span class="p_context"> swiotlb_alloc_coherent(struct device *hwdev, size_t size,</span>
 			goto err_warn;
 
 		ret = phys_to_virt(paddr);
<span class="p_del">-		dev_addr = phys_to_dma(hwdev, paddr);</span>
<span class="p_add">+		dev_addr = swiotlb_phys_to_dma(hwdev, paddr);</span>
 
 		/* Confirm address can be DMA&#39;d by device */
 		if (dev_addr + size - 1 &gt; dma_mask) {
<span class="p_chunk">@@ -758,15 +806,15 @@</span> <span class="p_context"> dma_addr_t swiotlb_map_page(struct device *dev, struct page *page,</span>
 	map = map_single(dev, phys, size, dir);
 	if (map == SWIOTLB_MAP_ERROR) {
 		swiotlb_full(dev, size, dir, 1);
<span class="p_del">-		return phys_to_dma(dev, io_tlb_overflow_buffer);</span>
<span class="p_add">+		return swiotlb_phys_to_dma(dev, io_tlb_overflow_buffer);</span>
 	}
 
<span class="p_del">-	dev_addr = phys_to_dma(dev, map);</span>
<span class="p_add">+	dev_addr = swiotlb_phys_to_dma(dev, map);</span>
 
 	/* Ensure that the address returned is DMA&#39;ble */
 	if (!dma_capable(dev, dev_addr, size)) {
 		swiotlb_tbl_unmap_single(dev, map, size, dir);
<span class="p_del">-		return phys_to_dma(dev, io_tlb_overflow_buffer);</span>
<span class="p_add">+		return swiotlb_phys_to_dma(dev, io_tlb_overflow_buffer);</span>
 	}
 
 	return dev_addr;
<span class="p_chunk">@@ -901,7 +949,7 @@</span> <span class="p_context"> swiotlb_map_sg_attrs(struct device *hwdev, struct scatterlist *sgl, int nelems,</span>
 				sg_dma_len(sgl) = 0;
 				return 0;
 			}
<span class="p_del">-			sg-&gt;dma_address = phys_to_dma(hwdev, map);</span>
<span class="p_add">+			sg-&gt;dma_address = swiotlb_phys_to_dma(hwdev, map);</span>
 		} else
 			sg-&gt;dma_address = dev_addr;
 		sg_dma_len(sg) = sg-&gt;length;
<span class="p_chunk">@@ -985,7 +1033,7 @@</span> <span class="p_context"> EXPORT_SYMBOL(swiotlb_sync_sg_for_device);</span>
 int
 swiotlb_dma_mapping_error(struct device *hwdev, dma_addr_t dma_addr)
 {
<span class="p_del">-	return (dma_addr == phys_to_dma(hwdev, io_tlb_overflow_buffer));</span>
<span class="p_add">+	return (dma_addr == swiotlb_phys_to_dma(hwdev, io_tlb_overflow_buffer));</span>
 }
 EXPORT_SYMBOL(swiotlb_dma_mapping_error);
 
<span class="p_chunk">@@ -998,6 +1046,6 @@</span> <span class="p_context"> EXPORT_SYMBOL(swiotlb_dma_mapping_error);</span>
 int
 swiotlb_dma_supported(struct device *hwdev, u64 mask)
 {
<span class="p_del">-	return phys_to_dma(hwdev, io_tlb_end - 1) &lt;= mask;</span>
<span class="p_add">+	return swiotlb_phys_to_dma(hwdev, io_tlb_end - 1) &lt;= mask;</span>
 }
 EXPORT_SYMBOL(swiotlb_dma_supported);

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



