
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>porting kcov to android - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    porting kcov to android</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=159351">Baozeng</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>July 6, 2016, 5:08 a.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;7156fdff-2ad9-b1f9-ff13-eb51e22e9261@gmail.com&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/9215367/mbox/"
   >mbox</a>
|
   <a href="/patch/9215367/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/9215367/">/patch/9215367/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
	[172.30.200.125])
	by pdx-korg-patchwork.web.codeaurora.org (Postfix) with ESMTP id
	D5600607D9 for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Wed,  6 Jul 2016 05:09:10 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id BFD0C2861A
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Wed,  6 Jul 2016 05:09:10 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id B0446286A0; Wed,  6 Jul 2016 05:09:10 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-7.0 required=2.0 tests=BAYES_00,DKIM_SIGNED,
	DKIM_VALID, DKIM_VALID_AU, FREEMAIL_FROM,
	RCVD_IN_DNSWL_HI autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 068FA2861A
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Wed,  6 Jul 2016 05:09:04 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1752097AbcGFFIq (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Wed, 6 Jul 2016 01:08:46 -0400
Received: from mail-pf0-f173.google.com ([209.85.192.173]:33772 &quot;EHLO
	mail-pf0-f173.google.com&quot; rhost-flags-OK-OK-OK-OK) by vger.kernel.org
	with ESMTP id S1750752AbcGFFId (ORCPT
	&lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Wed, 6 Jul 2016 01:08:33 -0400
Received: by mail-pf0-f173.google.com with SMTP id i123so76477897pfg.0
	for &lt;linux-kernel@vger.kernel.org&gt;;
	Tue, 05 Jul 2016 22:08:32 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
	d=gmail.com; s=20120113;
	h=subject:to:references:cc:from:message-id:date:user-agent
	:mime-version:in-reply-to;
	bh=lfv8J9dqMzMp9jUAPbG8cLf8V78jl70e4mczrkyqa4o=;
	b=s1RzvUFmw2a+57+0vicyfQoQhzBh2hHRgeMtiLYc+ZmWb0ldRJ7vGEqnrHPpIu4CJl
	vAZRjZwd1J9hPDqOGCd+FA4wso8L5FmJ+BhPiRoVU3hLh44v++M0EKYuKjt8jJj/z5rt
	OU07IX4KgdU/mageyChindAYqUtHnUHuu8Ef6RkGfzbf60FgFIgai3ZskodsndPhqcSW
	KbenkgRKqLdqChfTAaNN2jzGF2yg28QtyMNzmAXB8sRqzWpEnQoImxb2gbuZFLnyqR7j
	OrSoBveGIS734qbvoG5a/ULN0i70iUmcDD90gk2J20jPaHNSywteIKkpae0B7AlIIbPG
	IWIg==
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
	d=1e100.net; s=20130820;
	h=x-gm-message-state:subject:to:references:cc:from:message-id:date
	:user-agent:mime-version:in-reply-to;
	bh=lfv8J9dqMzMp9jUAPbG8cLf8V78jl70e4mczrkyqa4o=;
	b=fUnyS3yHUudSAk7CMBIOw16+YhimMPoRJwybZ3pkrb9xPLj3szyt1JegJhV6DsmCyu
	Y7wqv5KJwHOqo5WmJqLXJ11/N5albGVDjbtQaV/XkFzaV3mK8gNcIaPX9UPBZ6lv79Pj
	1IDgQ5e6lLubjdpge9ZhYhxnA7AArrJhXqUQPQzklJO6wRDv/EHSLC1s4MAdAPY5WsMq
	e7KBjes54CHySgj6IWGRmnJlr6TcR/4ha5HK6mVf7eHiRwUUUEHn722o7N7XmPFAAf2B
	A821zybxry6/Kx1cQUUyMSFtY0FyLs+bB4/hk8plprBz6MXtxRkQt1DhTu7QygD52Cpn
	yJHA==
X-Gm-Message-State: ALyK8tJGum/kuLBqEpWPOuiysWoXePxp3FGyWFMAEg+bVakEXne+1duVOuILWUcNs9MeMQ==
X-Received: by 10.98.19.133 with SMTP id 5mr38389845pft.17.1467781711438;
	Tue, 05 Jul 2016 22:08:31 -0700 (PDT)
Received: from [10.8.0.4] ([104.156.239.137])
	by smtp.gmail.com with ESMTPSA id
	f2sm918202pfb.76.2016.07.05.22.08.25
	(version=TLS1_2 cipher=ECDHE-RSA-AES128-GCM-SHA256 bits=128/128);
	Tue, 05 Jul 2016 22:08:30 -0700 (PDT)
Subject: Re: porting kcov to android
To: Kuthonuzo Luruo &lt;poll.stdin@gmail.com&gt;
References: &lt;CAP=GMUEYftGABYfQCFGvg9tL1arEaxK+XLL72boZzfAx=Qp7sw@mail.gmail.com&gt;
	&lt;CAEeQi3uFcaHh-e5013fSdXahV-MFzb0UP5WOAdgORpLH2UnQGA@mail.gmail.com&gt;
	&lt;CAG_fn=W6gGbs4UWB2tKtRH24xiTuH20qEey6v41eoE10xesk_w@mail.gmail.com&gt;
	&lt;CAP=GMUHt1E=iLvF6L_XgaD72dhLn-BYkoC_-CHgBk==8hi_1yA@mail.gmail.com&gt;
	&lt;CAG_fn=Xr_5gMZzHDRyRU_5FUPZ5vTOj6QrwvmFfLQG1RLBdVxQ@mail.gmail.com&gt;
	&lt;CAP=GMUGpbfkGEH6vyjq6d6-qjqq509EbYGqWPXhpicERpZEfow@mail.gmail.com&gt;
	&lt;CAG_fn=XeA-wN5Q9+pDS5bfMXxYPR71Dc-0NN-Qj5UzQi+MT_LQ@mail.gmail.com&gt;
	&lt;CAHPzcFk-7C9i9ixXxHN=-o=MmPhLD-hzLpEmUo+eDnyVpNH2TA@mail.gmail.com&gt;
	&lt;CAP=GMUHdQAamsADXvamyR6+fgWkutPh-bhpzaAh-xpbcr8Fh7Q@mail.gmail.com&gt;
Cc: syzkaller &lt;syzkaller@googlegroups.com&gt;,
	Dmitry Vyukov &lt;dvyukov@google.com&gt;, aryabinin@virtuozzo.com,
	linux-kernel@vger.kernel.org, gregkh@linuxfoundation.org
From: Baozeng Ding &lt;sploving1@gmail.com&gt;
Message-ID: &lt;7156fdff-2ad9-b1f9-ff13-eb51e22e9261@gmail.com&gt;
Date: Wed, 6 Jul 2016 13:08:17 +0800
User-Agent: Mozilla/5.0 (Windows NT 6.1; WOW64; rv:45.0) Gecko/20100101
	Thunderbird/45.1.1
MIME-Version: 1.0
In-Reply-To: &lt;CAP=GMUHdQAamsADXvamyR6+fgWkutPh-bhpzaAh-xpbcr8Fh7Q@mail.gmail.com&gt;
Content-Type: multipart/mixed;
	boundary=&quot;------------D749C89E1B1801D4F95CE083&quot;
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=159351">Baozeng</a> - July 6, 2016, 5:08 a.m.</div>
<pre class="content">
+ attachment for the patch.
On 2016/7/6 12:57, Baozeng wrote:
<span class="quote">&gt; Hello all,</span>
<span class="quote">&gt;     I backported KASAN to 3.10.102 stable kerenl (ca1199fccf14540e86f6da955333e31d6fec5f3e), based on Andrey Ryabinin&#39;s work (backport KASAN to RHEL7-based (3.10 based) OpenVZ kernel). I met the following kernel panic when starting the kernel using the following command:</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; qemu-system-x86_64 -hda ./wheezy.img -snapshot -m 2048 -net nic -net user,host=10.0.2.10,hostfwd=tcp::51727-:22 -nographic -enable-kvm -numa node,nodeid=0,cpus=0-1 -numa node,nodeid=1,cpus=2-3 -smp sockets=2,cores=2,threads=1 -usb -usbdevice mouse -usbdevice tablet -soundhw all -kernel ./bzImage -append console=ttyS0 root=/dev/sda debug earlyprintk=serial slub_debug=UZ</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; any suggestions?</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; ==================================================================</span>
<span class="quote">&gt; BUG: KASan: out of bounds access in usage_match+0x63/0x70 at addr ffff88002c81ff40</span>
<span class="quote">&gt; Read of size 8 by task khubd/923</span>
<span class="quote">&gt; =============================================================================</span>
<span class="quote">&gt; BUG kmalloc-4096 (Not tainted): kasan: bad access detected</span>
<span class="quote">&gt; -----------------------------------------------------------------------------</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Disabling lock debugging due to kernel taint</span>
<span class="quote">&gt; INFO: Allocated in input_dev_pm_ops+0x520/0x5e0 age=131944943344261 cpu=0 pid=-536871936</span>
<span class="quote">&gt;     0x41b58ab3</span>
<span class="quote">&gt; [&lt;      none      &gt;] vsock_dgram_ops+0x337bd3/0x3a5a50 ??:?</span>
<span class="quote">&gt; [&lt;      none      &gt;] sysfs_new_dirent+0x0/0x410 /linux-stable/fs/sysfs/dir.c:1027</span>
<span class="quote">&gt;     0xffff88002c8209d8</span>
<span class="quote">&gt;     0xffffed000590413c</span>
<span class="quote">&gt;     0xdffffc0000000000</span>
<span class="quote">&gt;     0xffff88002c8209e0</span>
<span class="quote">&gt;     0xffff88002c820920</span>
<span class="quote">&gt; [&lt;      none      &gt;] mutex_unlock+0x15/0x20 /linux-stable/kernel/mutex.c:252</span>
<span class="quote">&gt;     0x1ffff1000590412f</span>
<span class="quote">&gt;     0xffff88002c820958</span>
<span class="quote">&gt; [&lt;      none      &gt;] sysfs_attr_ns+0x162/0x260 /linux-stable/fs/sysfs/file.c:522</span>
<span class="quote">&gt;     0x1ffff1000590412f</span>
<span class="quote">&gt;     0xffff88002c820a18</span>
<span class="quote">&gt; [&lt;      none      &gt;] dev_attr_uniq+0x0/0x60 arch/x86/crypto/sha512-avx2-asm.o:?</span>
<span class="quote">&gt;     0xffff8800280feae0</span>
<span class="quote">&gt; INFO: Freed in sysfs_add_file_mode+0x141/0x2d0 age=6421765850 cpu=746719736 pid=-30720</span>
<span class="quote">&gt;     0x1242cf991f0</span>
<span class="quote">&gt;     0xffffffff00000002</span>
<span class="quote">&gt;     0x41b58ab3</span>
<span class="quote">&gt; [&lt;      none      &gt;] vsock_dgram_ops+0x337b87/0x3a5a50 ??:?</span>
<span class="quote">&gt; [&lt;      none      &gt;] sysfs_add_file_mode+0x0/0x2d0 /linux-stable/fs/sysfs/file.c:693</span>
<span class="quote">&gt;     0xffff88002cf998c8</span>
<span class="quote">&gt; INFO: Slab 0xffffea0000b20600 objects=7 used=0 fp=0xffff88002c818000 flags=0x1fc000000004080</span>
<span class="quote">&gt; INFO: Object 0xffff88002c81f8c0 @offset=30912 fp=0x0000000000000002</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Redzone ffff88002c8208c0: 1a 41 90 05 00 f1 ff 1f                          .A......</span>
<span class="quote">&gt; Padding ffff88002c8209f8: 40 0a 82 2c 00 88 ff ff                          @..,....</span>
<span class="quote">&gt; CPU: 0 PID: 923 Comm: khubd Tainted: G    B        3.10.102+ #2</span>
<span class="quote">&gt; Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS rel-1.8.2-0-g33fbe13 by qemu-project.org &lt;http://qemu-project.org&gt; 04/01/2014</span>
<span class="quote">&gt;  ffff88002c818000 ffff88002c81fc60 ffffffff850cbe98 ffff88002c81fc90</span>
<span class="quote">&gt;  ffffffff81584f48 ffff88002d806f40 ffffea0000b20600 ffff88002c81f8c0</span>
<span class="quote">&gt;  0000000000000000 ffff88002c81fcb8 ffffffff8158b731 ffffed0005903fe8</span>
<span class="quote">&gt; Call Trace:</span>
<span class="quote">&gt; Memory state around the buggy address:</span>
<span class="quote">&gt;  ffff88002c81fe00: fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc</span>
<span class="quote">&gt;  ffff88002c81fe80: fc fc f1 f1 f1 f1 00 f4 f4 f4 f2 f2 f2 f2 00 f4</span>
<span class="quote">&gt;&gt;ffff88002c81ff00: f4 f4 f2 f2 f2 f2 fc fc fc fc fc fc fc fc f2 f2</span>
<span class="quote">&gt;                                            ^</span>
<span class="quote">&gt;  ffff88002c81ff80: f2 f2 fc fc fc fc fc fc fc fc f3 f3 f3 f3 fc fc</span>
<span class="quote">&gt;  ffff88002c820000: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00</span>
<span class="quote">&gt; ==================================================================</span>
<span class="quote">&gt; kasan: CONFIG_KASAN_INLINE enabled</span>
<span class="quote">&gt; kasan: GPF could be caused by NULL-ptr deref or user memory accessgeneral protection fault: 0000 [#1] SMP KASAN</span>
<span class="quote">&gt; Modules linked in:</span>
<span class="quote">&gt; CPU: 0 PID: 923 Comm: khubd Tainted: G    B        3.10.102+ #2</span>
<span class="quote">&gt; Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS rel-1.8.2-0-g33fbe13 by qemu-project.org &lt;http://qemu-project.org&gt; 04/01/2014</span>
<span class="quote">&gt; task: ffff88002cf991f0 ti: ffff88002c820000 task.ti: ffff88002c820000</span>
<span class="quote">&gt; RIP: 0010:[&lt;ffffffff8134328b&gt;]  [&lt;ffffffff8134328b&gt;] cpuacct_charge+0x1ab/0x490</span>
<span class="quote">&gt; RSP: 0000:ffff88002de03be0  EFLAGS: 00010046</span>
<span class="quote">&gt; RAX: dffffc001d5585dc RBX: 000000000000c5a0 RCX: 00000000eaac2ee0</span>
<span class="quote">&gt; RDX: ffffffff869c2c60 RSI: 1ffffffff0c1a6c0 RDI: ffffffff860d3600</span>
<span class="quote">&gt; RBP: ffff88002de03c28 R08: 0000000000000001 R09: 0000000000000001</span>
<span class="quote">&gt; R10: 0000000000000020 R11: ffffed000fffb001 R12: ffffffff860d35a0</span>
<span class="quote">&gt; R13: dffffc0000000000 R14: 00000000134c2dae R15: 000000002c820050</span>
<span class="quote">&gt; FS:  0000000000000000(0000) GS:ffff88002de00000(0000) knlGS:0000000000000000</span>
<span class="quote">&gt; CS:  0010 DS: 0000 ES: 0000 CR0: 000000008005003b</span>
<span class="quote">&gt; CR2: 00000000ffffffff CR3: 000000000600d000 CR4: 00000000000006f0</span>
<span class="quote">&gt; DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000</span>
<span class="quote">&gt; DR3: 0000000000000000 DR6: 00000000ffff0ff0 DR7: 0000000000000400</span>
<span class="quote">&gt; Stack:</span>
<span class="quote">&gt;  ffffffff81343182 00000000146efbea ffff88007ffd8008 ffff88007ffd801c</span>
<span class="quote">&gt;  ffff88002cf99238 ffff88002de124a8 0000000ee4d60d04 00000000134c2dae</span>
<span class="quote">&gt;  ffff88002cf99278 ffff88002de03c78 ffffffff81317811 ffffffff8119be42</span>
<span class="quote">&gt; Call Trace:</span>
<span class="quote">&gt;  &lt;IRQ&gt;</span>
<span class="quote">&gt;  [&lt;     inline     &gt;] ? __rcu_read_lock /linux-stable/include/linux/rcupdate.h:198</span>
<span class="quote">&gt;  [&lt;     inline     &gt;] ? rcu_read_lock /linux-stable/include/linux/rcupdate.h:776</span>
<span class="quote">&gt;  [&lt;ffffffff81343182&gt;] ? cpuacct_charge+0xa2/0x490 /linux-stable/kernel/sched/cpuacct.c:253</span>
<span class="quote">&gt;  [&lt;ffffffff81317811&gt;] update_curr+0x291/0x610 /linux-stable/kernel/sched/fair.c:711</span>
<span class="quote">&gt;  [&lt;ffffffff8119be42&gt;] ? kvm_clock_read+0x62/0xc0 /linux-stable/arch/x86/kernel/kvmclock.c:88</span>
<span class="quote">&gt;  [&lt;     inline     &gt;] entity_tick /linux-stable/kernel/sched/fair.c:1987</span>
<span class="quote">&gt;  [&lt;ffffffff8131c070&gt;] task_tick_fair+0x60/0x1430 /linux-stable/kernel/sched/fair.c:5778</span>
<span class="quote">&gt;  [&lt;ffffffff81309e68&gt;] ? sched_clock_cpu+0x108/0x1b0 /linux-stable/kernel/sched/clock.c:258</span>
<span class="quote">&gt;  [&lt;ffffffff812ff07a&gt;] scheduler_tick+0x29a/0x510 /linux-stable/kernel/sched/core.c:2748</span>
<span class="quote">&gt;  [&lt;ffffffff81281971&gt;] update_process_times+0xa1/0xc0 /linux-stable/kernel/timer.c:1362</span>
<span class="quote">&gt;  [&lt;ffffffff81372528&gt;] tick_sched_handle.isra.14+0xb8/0xf0 /linux-stable/kernel/time/tick-sched.c:146</span>
<span class="quote">&gt;  [&lt;ffffffff813725d0&gt;] tick_sched_timer+0x70/0xa0 /linux-stable/kernel/time/tick-sched.c:1100</span>
<span class="quote">&gt;  [&lt;ffffffff812d39f7&gt;] __run_hrtimer+0x127/0xd90 /linux-stable/kernel/hrtimer.c:1276</span>
<span class="quote">&gt;  [&lt;ffffffff81372560&gt;] ? tick_sched_handle.isra.14+0xf0/0xf0 /linux-stable/kernel/time/tick-sched.c:143</span>
<span class="quote">&gt;  [&lt;ffffffff812d637d&gt;] hrtimer_interrupt+0x32d/0x780 /linux-stable/kernel/hrtimer.c:1365</span>
<span class="quote">&gt;  [&lt;ffffffff812d6050&gt;] ? hrtimer_get_next_event+0x150/0x150 /linux-stable/kernel/hrtimer.c:1183</span>
<span class="quote">&gt;  [&lt;ffffffff81377c52&gt;] ? trace_hardirqs_off+0x12/0x20 /linux-stable/kernel/lockdep.c:2642</span>
<span class="quote">&gt;  [&lt;ffffffff81424e79&gt;] ? rcu_irq_enter+0xb9/0x120 /linux-stable/kernel/rcutree.c:627</span>
<span class="quote">&gt;  [&lt;     inline     &gt;] local_apic_timer_interrupt /linux-stable/arch/x86/kernel/apic/apic.c:911</span>
<span class="quote">&gt;  [&lt;ffffffff81186547&gt;] smp_apic_timer_interrupt+0xe7/0x180 /linux-stable/arch/x86/kernel/apic/apic.c:938</span>
<span class="quote">&gt;  [&lt;ffffffff8510a0b2&gt;] apic_timer_interrupt+0x72/0x80 /linux-stable/arch/x86/kernel/entry_64.S:1188</span>
<span class="quote">&gt;  &lt;EOI&gt;</span>
<span class="quote">&gt;  [&lt;     inline     &gt;] ? arch_local_irq_restore /linux-stable/arch/x86/include/asm/paravirt.h:829</span>
<span class="quote">&gt;  [&lt;     inline     &gt;] ? buffered_rmqueue /linux-stable/mm/page_alloc.c:1536</span>
<span class="quote">&gt;  [&lt;ffffffff814d809e&gt;] ? get_page_from_freelist+0x91e/0x19b0 /linux-stable/mm/page_alloc.c:1974</span>
<span class="quote">&gt;  [&lt;ffffffff81377f19&gt;] ? check_chain_key+0x2b9/0x4d0 /linux-stable/kernel/lockdep.c:2177</span>
<span class="quote">&gt;  [&lt;ffffffff81377f19&gt;] ? check_chain_key+0x2b9/0x4d0 /linux-stable/kernel/lockdep.c:2177</span>
<span class="quote">&gt;  [&lt;ffffffff814d7780&gt;] ? free_reserved_area+0x1a0/0x1a0 /linux-stable/arch/x86/include/asm/page_64.h:17</span>
<span class="quote">&gt;  [&lt;     inline     &gt;] ? arch_local_irq_restore /linux-stable/arch/x86/include/asm/paravirt.h:829</span>
<span class="quote">&gt;  [&lt;ffffffff813813f3&gt;] ? lock_is_held+0x153/0x1c0 /linux-stable/kernel/lockdep.c:3640</span>
<span class="quote">&gt;  [&lt;ffffffff814d994e&gt;] __alloc_pages_nodemask+0x28e/0x14e0 /linux-stable/mm/page_alloc.c:2663</span>
<span class="quote">&gt;  [&lt;ffffffff813818e0&gt;] ? debug_show_all_locks+0x480/0x480 /linux-stable/kernel/lockdep.c:4162</span>
<span class="quote">&gt;  [&lt;ffffffff81377f19&gt;] ? check_chain_key+0x2b9/0x4d0 /linux-stable/kernel/lockdep.c:2177</span>
<span class="quote">&gt;  [&lt;ffffffff813a1303&gt;] ? __module_text_address+0x13/0x150 /linux-stable/kernel/module.c:3845</span>
<span class="quote">&gt;  [&lt;ffffffff8158df07&gt;] ? __asan_report_store8_noabort+0x17/0x20 /linux-stable/mm/kasan/report.c:272</span>
<span class="quote">&gt;  [&lt;ffffffff814d96c0&gt;] ? __alloc_pages_direct_compact+0x590/0x590 /linux-stable/include/linux/compaction.h:59</span>
<span class="quote">&gt;  [&lt;ffffffff813823a8&gt;] ? __lock_acquire+0xac8/0x49c0 /linux-stable/kernel/lockdep.c:3081</span>
<span class="quote">&gt;  [&lt;     inline     &gt;] ? debug_spin_unlock /linux-stable/lib/spinlock_debug.c:102</span>
<span class="quote">&gt;  [&lt;ffffffff82668db0&gt;] ? do_raw_spin_unlock+0x100/0x260 /linux-stable/lib/spinlock_debug.c:158</span>
<span class="quote">&gt;  [&lt;ffffffff813818e0&gt;] ? debug_show_all_locks+0x480/0x480 /linux-stable/kernel/lockdep.c:4162</span>
<span class="quote">&gt;  [&lt;ffffffff81377f19&gt;] ? check_chain_key+0x2b9/0x4d0 /linux-stable/kernel/lockdep.c:2177</span>
<span class="quote">&gt;  [&lt;ffffffff813823a8&gt;] ? __lock_acquire+0xac8/0x49c0 /linux-stable/kernel/lockdep.c:3081</span>
<span class="quote">&gt;  [&lt;ffffffff815789c1&gt;] alloc_pages_current+0x181/0x390 /linux-stable/mm/mempolicy.c:2051</span>
<span class="quote">&gt;  [&lt;     inline     &gt;] ? allocate_slab /linux-stable/mm/slub.c:1312</span>
<span class="quote">&gt;  [&lt;ffffffff81586895&gt;] ? new_slab+0x2e5/0x370 /linux-stable/mm/slub.c:1386</span>
<span class="quote">&gt;  [&lt;     inline     &gt;] alloc_pages /linux-stable/include/linux/gfp.h:334</span>
<span class="quote">&gt;  [&lt;     inline     &gt;] alloc_slab_page /linux-stable/mm/slub.c:1298</span>
<span class="quote">&gt;  [&lt;     inline     &gt;] allocate_slab /linux-stable/mm/slub.c:1322</span>
<span class="quote">&gt;  [&lt;ffffffff815868bc&gt;] new_slab+0x30c/0x370 /linux-stable/mm/slub.c:1386</span>
<span class="quote">&gt;  [&lt;     inline     &gt;] new_slab_objects /linux-stable/mm/slub.c:2162</span>
<span class="quote">&gt;  [&lt;ffffffff81589364&gt;] __slab_alloc+0x4b4/0x5d0 /linux-stable/mm/slub.c:2323</span>
<span class="quote">&gt;  [&lt;     inline     &gt;] ? kmem_cache_zalloc /linux-stable/include/linux/slab.h:509</span>
<span class="quote">&gt;  [&lt;ffffffff8171b778&gt;] ? sysfs_new_dirent+0xf8/0x410 /linux-stable/fs/sysfs/dir.c:381</span>
<span class="quote">&gt;  [&lt;     inline     &gt;] ? kmem_cache_zalloc /linux-stable/include/linux/slab.h:509</span>
<span class="quote">&gt;  [&lt;ffffffff8171b778&gt;] ? sysfs_new_dirent+0xf8/0x410 /linux-stable/fs/sysfs/dir.c:381</span>
<span class="quote">&gt;  [&lt;     inline     &gt;] ? arch_local_irq_restore /linux-stable/arch/x86/include/asm/paravirt.h:829</span>
<span class="quote">&gt;  [&lt;ffffffff813813f3&gt;] ? lock_is_held+0x153/0x1c0 /linux-stable/kernel/lockdep.c:3640</span>
<span class="quote">&gt;  [&lt;     inline     &gt;] ? kmem_cache_zalloc /linux-stable/include/linux/slab.h:509</span>
<span class="quote">&gt;  [&lt;ffffffff8171b778&gt;] ? sysfs_new_dirent+0xf8/0x410 /linux-stable/fs/sysfs/dir.c:381</span>
<span class="quote">&gt;  [&lt;     inline     &gt;] slab_alloc_node /linux-stable/mm/slub.c:2397</span>
<span class="quote">&gt;  [&lt;     inline     &gt;] slab_alloc /linux-stable/mm/slub.c:2437</span>
<span class="quote">&gt;  [&lt;ffffffff81589663&gt;] kmem_cache_alloc+0x1e3/0x220 /linux-stable/mm/slub.c:2442</span>
<span class="quote">&gt;  [&lt;     inline     &gt;] ? __mutex_unlock_common_slowpath /linux-stable/kernel/mutex.c:479</span>
<span class="quote">&gt;  [&lt;ffffffff850e6a87&gt;] ? __mutex_unlock_slowpath+0x257/0x410 /linux-stable/kernel/mutex.c:488</span>
<span class="quote">&gt;  [&lt;     inline     &gt;] kmem_cache_zalloc /linux-stable/include/linux/slab.h:509</span>
<span class="quote">&gt;  [&lt;ffffffff8171b778&gt;] sysfs_new_dirent+0xf8/0x410 /linux-stable/fs/sysfs/dir.c:381</span>
<span class="quote">&gt;  [&lt;ffffffff8171b680&gt;] ? sysfs_readdir+0x7d0/0x7d0 /linux-stable/fs/sysfs/dir.c:1027</span>
<span class="quote">&gt;  [&lt;ffffffff850e6c55&gt;] ? mutex_unlock+0x15/0x20 /linux-stable/kernel/mutex.c:252</span>
<span class="quote">&gt;  [&lt;ffffffff81717412&gt;] ? sysfs_attr_ns+0x162/0x260 /linux-stable/fs/sysfs/file.c:522</span>
<span class="quote">&gt;  [&lt;ffffffff81719161&gt;] sysfs_add_file_mode+0x141/0x2d0 /linux-stable/fs/sysfs/file.c:539</span>
<span class="quote">&gt;  [&lt;ffffffff81719020&gt;] ? sysfs_remove_file_from_group+0x170/0x170 /linux-stable/fs/sysfs/file.c:693</span>
<span class="quote">&gt;  [&lt;     inline     &gt;] ? __mutex_unlock_common_slowpath /linux-stable/kernel/mutex.c:479</span>
<span class="quote">&gt;  [&lt;ffffffff850e6a87&gt;] ? __mutex_unlock_slowpath+0x257/0x410 /linux-stable/kernel/mutex.c:488</span>
<span class="quote">&gt;  [&lt;ffffffff8138025a&gt;] ? trace_hardirqs_on_caller+0x30a/0x690 /linux-stable/kernel/lockdep.c:2598</span>
<span class="quote">&gt;  [&lt;ffffffff813805f2&gt;] ? trace_hardirqs_on+0x12/0x20 /linux-stable/kernel/lockdep.c:2604</span>
<span class="quote">&gt;  [&lt;ffffffff850e6a97&gt;] ? __mutex_unlock_slowpath+0x267/0x410 /linux-stable/kernel/mutex.c:489</span>
<span class="quote">&gt;  [&lt;     inline     &gt;] create_files /linux-stable/fs/sysfs/group.c:48</span>
<span class="quote">&gt;  [&lt;ffffffff81721b7f&gt;] internal_create_group+0x31f/0x7b0 /linux-stable/fs/sysfs/group.c:82</span>
<span class="quote">&gt;  [&lt;ffffffff81721860&gt;] ? unmap_bin_file+0x1b0/0x1b0 ??:?</span>
<span class="quote">&gt;  [&lt;ffffffff8171e330&gt;] ? sysfs_rename_link+0x2d0/0x2d0 /linux-stable/fs/sysfs/symlink.c:214</span>
<span class="quote">&gt;  [&lt;ffffffff8172202f&gt;] sysfs_create_group+0x1f/0x30 /linux-stable/fs/sysfs/group.c:104</span>
<span class="quote">&gt;  [&lt;ffffffff82c2d9ab&gt;] device_add_groups+0xab/0x150 /linux-stable/drivers/base/core.c:472</span>
<span class="quote">&gt;  [&lt;     inline     &gt;] device_add_attrs /linux-stable/drivers/base/core.c:510</span>
<span class="quote">&gt;  [&lt;ffffffff82c3218b&gt;] device_add+0xd1b/0x1710 /linux-stable/drivers/base/core.c:1080</span>
<span class="quote">&gt;  [&lt;ffffffff82c31470&gt;] ? device_private_init+0x190/0x190 /linux-stable/drivers/base/core.c:975</span>
<span class="quote">&gt;  [&lt;     inline     &gt;] ? do_init_timer /linux-stable/kernel/timer.c:634</span>
<span class="quote">&gt;  [&lt;ffffffff8127cad7&gt;] ? init_timer_key+0x157/0x4b0 /linux-stable/kernel/timer.c:652</span>
<span class="quote">&gt;  [&lt;ffffffff83717713&gt;] input_register_device+0x503/0xc90 /linux-stable/drivers/input/input.c:2085</span>
<span class="quote">&gt;  [&lt;ffffffff83ef6dfa&gt;] hidinput_connect+0xe4a/0xb550 /linux-stable/drivers/hid/hid-input.c:1385</span>
<span class="quote">&gt;  [&lt;ffffffff83ef5fb0&gt;] ? hid_map_usage_clear.constprop.5+0x160/0x160 /linux-stable/include/linux/hid.h:817</span>
<span class="quote">&gt;  [&lt;ffffffff83f24520&gt;] ? hid_irq_out+0x2e0/0x2e0 /linux-stable/drivers/hid/usbhid/hid-core.c:458</span>
<span class="quote">&gt;  [&lt;ffffffff812ca250&gt;] ? wake_up_bit+0xf0/0xf0 /linux-stable/include/linux/list.h:188</span>
<span class="quote">&gt;  [&lt;ffffffff813805f2&gt;] ? trace_hardirqs_on+0x12/0x20 /linux-stable/kernel/lockdep.c:2604</span>
<span class="quote">&gt;  [&lt;     inline     &gt;] ? __raw_spin_unlock_irqrestore /linux-stable/include/linux/spinlock_api_smp.h:162</span>
<span class="quote">&gt;  [&lt;ffffffff850ef48b&gt;] ? _raw_spin_unlock_irqrestore+0x4b/0xb0 /linux-stable/kernel/spinlock.c:177</span>
<span class="quote">&gt;  [&lt;     inline     &gt;] ? spin_unlock_irqrestore /linux-stable/include/linux/spinlock.h:348</span>
<span class="quote">&gt;  [&lt;ffffffff83f2991e&gt;] ? usbhid_submit_report+0x6e/0x80 /linux-stable/drivers/hid/usbhid/hid-core.c:648</span>
<span class="quote">&gt;  [&lt;ffffffff83eeb2b3&gt;] hid_connect+0x923/0xc70 /linux-stable/drivers/hid/hid-core.c:1479</span>
<span class="quote">&gt;  [&lt;ffffffff8158d3b1&gt;] ? memset+0x31/0x40 /linux-stable/mm/kasan/kasan.c:278</span>
<span class="quote">&gt;  [&lt;ffffffff83eea990&gt;] ? extract+0xc0/0xc0 /linux-stable/drivers/hid/hid-core.c:998</span>
<span class="quote">&gt;  [&lt;     inline     &gt;] hid_hw_start /linux-stable/include/linux/hid.h:886</span>
<span class="quote">&gt;  [&lt;ffffffff83eef381&gt;] hid_device_probe+0x301/0x500 /linux-stable/drivers/hid/hid-core.c:1955</span>
<span class="quote">&gt;  [&lt;ffffffff83eef080&gt;] ? hid_add_device+0x9e0/0x9e0 /linux-stable/drivers/hid/hid-core.c:685</span>
<span class="quote">&gt;  [&lt;     inline     &gt;] really_probe /linux-stable/drivers/base/dd.c:302</span>
<span class="quote">&gt;  [&lt;ffffffff82c3a8aa&gt;] driver_probe_device+0x15a/0xad0 /linux-stable/drivers/base/dd.c:399</span>
<span class="quote">&gt;  [&lt;ffffffff82c3b220&gt;] ? driver_probe_device+0xad0/0xad0 /linux-stable/drivers/base/dd.c:313</span>
<span class="quote">&gt;  [&lt;ffffffff82c3b2b0&gt;] __device_attach+0x90/0xc0 /linux-stable/drivers/base/dd.c:412</span>
<span class="quote">&gt;  [&lt;ffffffff82c34b7a&gt;] bus_for_each_drv+0x13a/0x1d0 /linux-stable/drivers/base/bus.c:451</span>
<span class="quote">&gt;  [&lt;ffffffff82c34a40&gt;] ? bus_rescan_devices+0x30/0x30 /linux-stable/drivers/base/bus.c:797</span>
<span class="quote">&gt;  [&lt;ffffffff82c3a68b&gt;] device_attach+0x12b/0x180 /linux-stable/drivers/base/dd.c:447</span>
<span class="quote">&gt;  [&lt;ffffffff82c38166&gt;] bus_probe_device+0x1e6/0x2d0 /linux-stable/drivers/base/bus.c:541</span>
<span class="quote">&gt;  [&lt;ffffffff82c323aa&gt;] device_add+0xf3a/0x1710 /linux-stable/drivers/base/core.c:1099</span>
<span class="quote">&gt;  [&lt;ffffffff850e6c55&gt;] ? mutex_unlock+0x15/0x20 /linux-stable/kernel/mutex.c:252</span>
<span class="quote">&gt;  [&lt;ffffffff82c31470&gt;] ? device_private_init+0x190/0x190 /linux-stable/drivers/base/core.c:975</span>
<span class="quote">&gt;  [&lt;ffffffff820a0d01&gt;] ? debugfs_create_file+0x51/0x70 /linux-stable/fs/debugfs/inode.c:403</span>
<span class="quote">&gt;  [&lt;ffffffff83eee98b&gt;] hid_add_device+0x2eb/0x9e0 /linux-stable/drivers/hid/hid-core.c:2406</span>
<span class="quote">&gt;  [&lt;ffffffff83eee6a0&gt;] ? hid_ignore+0x80/0x80 /linux-stable/drivers/hid/hid-core.c:2295</span>
<span class="quote">&gt;  [&lt;ffffffff83f2bc6a&gt;] usbhid_probe+0xb1a/0x1100 /linux-stable/drivers/hid/usbhid/hid-core.c:1364</span>
<span class="quote">&gt;  [&lt;ffffffff8355e649&gt;] usb_probe_interface+0x319/0x6e0 /linux-stable/drivers/usb/core/driver.c:335</span>
<span class="quote">&gt;  [&lt;ffffffff8355e330&gt;] ? usb_match_dynamic_id+0x100/0x100 /linux-stable/drivers/usb/core/driver.c:202</span>
<span class="quote">&gt;  [&lt;     inline     &gt;] really_probe /linux-stable/drivers/base/dd.c:302</span>
<span class="quote">&gt;  [&lt;ffffffff82c3a8aa&gt;] driver_probe_device+0x15a/0xad0 /linux-stable/drivers/base/dd.c:399</span>
<span class="quote">&gt;  [&lt;ffffffff82c3b220&gt;] ? driver_probe_device+0xad0/0xad0 /linux-stable/drivers/base/dd.c:313</span>
<span class="quote">&gt;  [&lt;ffffffff82c3b2b0&gt;] __device_attach+0x90/0xc0 /linux-stable/drivers/base/dd.c:412</span>
<span class="quote">&gt;  [&lt;ffffffff82c34b7a&gt;] bus_for_each_drv+0x13a/0x1d0 /linux-stable/drivers/base/bus.c:451</span>
<span class="quote">&gt;  [&lt;ffffffff82c34a40&gt;] ? bus_rescan_devices+0x30/0x30 /linux-stable/drivers/base/bus.c:797</span>
<span class="quote">&gt;  [&lt;ffffffff82c3a68b&gt;] device_attach+0x12b/0x180 /linux-stable/drivers/base/dd.c:447</span>
<span class="quote">&gt;  [&lt;ffffffff82c38166&gt;] bus_probe_device+0x1e6/0x2d0 /linux-stable/drivers/base/bus.c:541</span>
<span class="quote">&gt;  [&lt;ffffffff82c323aa&gt;] device_add+0xf3a/0x1710 /linux-stable/drivers/base/core.c:1099</span>
<span class="quote">&gt;  [&lt;     inline     &gt;] ? __mutex_unlock_common_slowpath /linux-stable/kernel/mutex.c:479</span>
<span class="quote">&gt;  [&lt;ffffffff850e6a87&gt;] ? __mutex_unlock_slowpath+0x257/0x410 /linux-stable/kernel/mutex.c:488</span>
<span class="quote">&gt;  [&lt;ffffffff82c31470&gt;] ? device_private_init+0x190/0x190 /linux-stable/drivers/base/core.c:975</span>
<span class="quote">&gt;  [&lt;ffffffff850e6c55&gt;] ? mutex_unlock+0x15/0x20 /linux-stable/kernel/mutex.c:252</span>
<span class="quote">&gt;  [&lt;     inline     &gt;] ? usb_device_supports_ltm /linux-stable/include/linux/usb.h:699</span>
<span class="quote">&gt;  [&lt;ffffffff83531e87&gt;] ? usb_enable_ltm+0x97/0x350 /linux-stable/drivers/usb/core/hub.c:2855</span>
<span class="quote">&gt;  [&lt;ffffffff8355a6d9&gt;] usb_set_configuration+0xce9/0x17c0 /linux-stable/drivers/usb/core/message.c:1898</span>
<span class="quote">&gt;  [&lt;ffffffff83576afc&gt;] generic_probe+0x6c/0xe0 /linux-stable/drivers/usb/core/generic.c:171</span>
<span class="quote">&gt;  [&lt;ffffffff8355c20f&gt;] usb_probe_device+0x6f/0xc0 /linux-stable/drivers/usb/core/driver.c:231</span>
<span class="quote">&gt;  [&lt;ffffffff8355c1a0&gt;] ? usb_register_device_driver+0x2a0/0x2a0 /linux-stable/drivers/usb/core/driver.c:841</span>
<span class="quote">&gt;  [&lt;     inline     &gt;] really_probe /linux-stable/drivers/base/dd.c:302</span>
<span class="quote">&gt;  [&lt;ffffffff82c3a8aa&gt;] driver_probe_device+0x15a/0xad0 /linux-stable/drivers/base/dd.c:399</span>
<span class="quote">&gt;  [&lt;ffffffff82c3b220&gt;] ? driver_probe_device+0xad0/0xad0 /linux-stable/drivers/base/dd.c:313</span>
<span class="quote">&gt;  [&lt;ffffffff82c3b2b0&gt;] __device_attach+0x90/0xc0 /linux-stable/drivers/base/dd.c:412</span>
<span class="quote">&gt;  [&lt;ffffffff82c34b7a&gt;] bus_for_each_drv+0x13a/0x1d0 /linux-stable/drivers/base/bus.c:451</span>
<span class="quote">&gt;  [&lt;ffffffff82c34a40&gt;] ? bus_rescan_devices+0x30/0x30 /linux-stable/drivers/base/bus.c:797</span>
<span class="quote">&gt;  [&lt;ffffffff82c3a68b&gt;] device_attach+0x12b/0x180 /linux-stable/drivers/base/dd.c:447</span>
<span class="quote">&gt;  [&lt;ffffffff82c38166&gt;] bus_probe_device+0x1e6/0x2d0 /linux-stable/drivers/base/bus.c:541</span>
<span class="quote">&gt;  [&lt;ffffffff82c323aa&gt;] device_add+0xf3a/0x1710 /linux-stable/drivers/base/core.c:1099</span>
<span class="quote">&gt;  [&lt;ffffffff82c2fd70&gt;] ? dev_notice+0xf0/0xf0 /linux-stable/drivers/base/core.c:2039</span>
<span class="quote">&gt;  [&lt;ffffffff829ea425&gt;] ? add_device_randomness+0xe5/0x130 /linux-stable/drivers/char/random.c:651</span>
<span class="quote">&gt;  [&lt;ffffffff82c31470&gt;] ? device_private_init+0x190/0x190 /linux-stable/drivers/base/core.c:975</span>
<span class="quote">&gt;  [&lt;     inline     &gt;] ? slab_free /linux-stable/mm/slub.c:2661</span>
<span class="quote">&gt;  [&lt;ffffffff81588681&gt;] ? kfree+0x271/0x290 /linux-stable/mm/slub.c:3411</span>
<span class="quote">&gt;  [&lt;ffffffff82c393ea&gt;] ? dev_get_drvdata+0x6a/0x90 /linux-stable/drivers/base/dd.c:598</span>
<span class="quote">&gt;  [&lt;ffffffff8353c5bd&gt;] usb_new_device+0x76d/0xd20 /linux-stable/drivers/usb/core/hub.c:2399</span>
<span class="quote">&gt;  [&lt;     inline     &gt;] hub_port_connect_change /linux-stable/drivers/usb/core/hub.c:4604</span>
<span class="quote">&gt;  [&lt;     inline     &gt;] hub_events /linux-stable/drivers/usb/core/hub.c:4893</span>
<span class="quote">&gt;  [&lt;ffffffff835402bb&gt;] hub_thread+0x138b/0x3ea0 /linux-stable/drivers/usb/core/hub.c:4953</span>
<span class="quote">&gt;  [&lt;ffffffff8353ef30&gt;] ? hub_port_debounce+0x310/0x310 /linux-stable/drivers/usb/core/hub.c:3965</span>
<span class="quote">&gt;  [&lt;     inline     &gt;] ? arch_local_irq_restore /linux-stable/arch/x86/include/asm/paravirt.h:829</span>
<span class="quote">&gt;  [&lt;ffffffff813885d0&gt;] ? lock_acquire+0x1b0/0x520 /linux-stable/kernel/lockdep.c:3604</span>
<span class="quote">&gt;  [&lt;ffffffff8132a34b&gt;] ? idle_balance+0x45b/0x6e0 /linux-stable/kernel/sched/fair.c:5306</span>
<span class="quote">&gt;  [&lt;     inline     &gt;] ? debug_spin_lock_after /linux-stable/lib/spinlock_debug.c:91</span>
<span class="quote">&gt;  [&lt;ffffffff826689ab&gt;] ? do_raw_spin_lock+0x20b/0x400 /linux-stable/lib/spinlock_debug.c:138</span>
<span class="quote">&gt;  [&lt;ffffffff812f3960&gt;] ? perf_trace_sched_process_exec+0x460/0x460 /linux-stable/arch/x86/include/asm/stacktrace.h:112</span>
<span class="quote">&gt;  [&lt;ffffffff81377f19&gt;] ? check_chain_key+0x2b9/0x4d0 /linux-stable/kernel/lockdep.c:2177</span>
<span class="quote">&gt;  [&lt;ffffffff8137fecd&gt;] ? mark_held_locks+0x2ad/0x330 /linux-stable/kernel/lockdep.c:2525</span>
<span class="quote">&gt;  [&lt;     inline     &gt;] ? __raw_spin_unlock_irq /linux-stable/include/linux/spinlock_api_smp.h:169</span>
<span class="quote">&gt;  [&lt;ffffffff850ef3ec&gt;] ? _raw_spin_unlock_irq+0x2c/0x80 /linux-stable/kernel/spinlock.c:185</span>
<span class="quote">&gt;  [&lt;ffffffff8138025a&gt;] ? trace_hardirqs_on_caller+0x30a/0x690 /linux-stable/kernel/lockdep.c:2598</span>
<span class="quote">&gt;  [&lt;ffffffff813805f2&gt;] ? trace_hardirqs_on+0x12/0x20 /linux-stable/kernel/lockdep.c:2604</span>
<span class="quote">&gt;  [&lt;     inline     &gt;] ? __raw_spin_unlock_irq /linux-stable/include/linux/spinlock_api_smp.h:169</span>
<span class="quote">&gt;  [&lt;ffffffff850ef3ec&gt;] ? _raw_spin_unlock_irq+0x2c/0x80 /linux-stable/kernel/spinlock.c:185</span>
<span class="quote">&gt;  [&lt;     inline     &gt;] ? finish_lock_switch /linux-stable/kernel/sched/sched.h:848</span>
<span class="quote">&gt;  [&lt;ffffffff812ed159&gt;] ? finish_task_switch+0xf9/0x260 /linux-stable/kernel/sched/core.c:1900</span>
<span class="quote">&gt;  [&lt;     inline     &gt;] ? finish_lock_switch /linux-stable/kernel/sched/sched.h:839</span>
<span class="quote">&gt;  [&lt;ffffffff812ed12d&gt;] ? finish_task_switch+0xcd/0x260 /linux-stable/kernel/sched/core.c:1900</span>
<span class="quote">&gt;  [&lt;ffffffff812ca250&gt;] ? wake_up_bit+0xf0/0xf0 /linux-stable/include/linux/list.h:188</span>
<span class="quote">&gt;  [&lt;ffffffff812c72ed&gt;] ? __kthread_parkme+0xed/0x170 /linux-stable/kernel/kthread.c:162</span>
<span class="quote">&gt;  [&lt;ffffffff8353ef30&gt;] ? hub_port_debounce+0x310/0x310 /linux-stable/drivers/usb/core/hub.c:3965</span>
<span class="quote">&gt;  [&lt;ffffffff812c8283&gt;] kthread+0x1d3/0x240 /linux-stable/drivers/block/aoe/aoecmd.c:1303</span>
<span class="quote">&gt;  [&lt;ffffffff812c80b0&gt;] ? kthread_worker_fn+0x530/0x530 /linux-stable/include/linux/list.h:27</span>
<span class="quote">&gt;  [&lt;ffffffff812fda31&gt;] ? schedule_tail+0x31/0x210 /linux-stable/kernel/sched/core.c:1963</span>
<span class="quote">&gt;  [&lt;ffffffff812c80b0&gt;] ? kthread_worker_fn+0x530/0x530 /linux-stable/include/linux/list.h:27</span>
<span class="quote">&gt;  [&lt;ffffffff85109218&gt;] ret_from_fork+0x58/0x90 /linux-stable/arch/x86/kernel/entry_64.S:573</span>
<span class="quote">&gt;  [&lt;ffffffff812c80b0&gt;] ? kthread_worker_fn+0x530/0x530 /linux-stable/include/linux/list.h:27</span>
<span class="quote">&gt; Code: 0f 85 17 02 00 00 4c 8b 63 68 4d 85 e4 74 77 49 8d 7c 24 60 48 89 fe 48 c1 ee 03 42 80 3c 2e 00 0f 85 2d 02 00 00 49 8b 5c 24 60 &lt;80&gt; 38 00 0f 85 b7 02 00 00 4a 03 1c fa 48 89 de 48 c1 ee 03 42</span>
<span class="quote">&gt; RIP  [&lt;ffffffff8134328b&gt;] cpuacct_charge+0x1ab/0x490 /linux-stable/kernel/sched/cpuacct.c:258</span>
<span class="quote">&gt;  RSP &lt;ffff88002de03be0&gt;</span>
<span class="quote">&gt; ---[ end trace 4d690b5b318b4d40 ]---</span>
<span class="quote">&gt; Kernel panic - not syncing: Fatal exception in interrupt</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; </span>
<span class="quote">&gt; </span>
<span class="quote">&gt; 2016-06-20 22:06 GMT+08:00 Kuthonuzo Luruo &lt;poll.stdin@gmail.com &lt;mailto:poll.stdin@gmail.com&gt;&gt;:</span>
<span class="quote">&gt; </span>
<span class="quote">&gt;     Heh, I backported KASAN to 2.6.32 kernel. Biggest difficulty was shadow memory inititialization due to differences in early boot code with 4.x kernel.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt;     Kuthonuzo</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; </span>
<span class="quote">&gt;     On Mon, Jun 20, 2016 at 7:10 PM, &#39;Alexander Potapenko&#39; via syzkaller &lt;syzkaller@googlegroups.com &lt;mailto:syzkaller@googlegroups.com&gt;&gt; wrote:</span>
<span class="quote">&gt; </span>
<span class="quote">&gt;         Hi,</span>
<span class="quote">&gt; </span>
<span class="quote">&gt;         On Mon, Jun 20, 2016 at 3:36 PM, Baozeng &lt;sploving1@gmail.com &lt;mailto:sploving1@gmail.com&gt;&gt; wrote:</span>
<span class="quote">&gt;         &gt; Hello all,</span>
<span class="quote">&gt;         &gt;      As we know syzkaller could use KASAN to find more memory bugs. Has</span>
<span class="quote">&gt;         &gt; anyone ported KASAN to older version of  kernel,  for instance 3.10 ?  (Most</span>
<span class="quote">&gt;         &gt; of current android&#39;s kernel version is 3.10 or evern older). Thanks.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt;         I&#39;ve ported KASAN to 3.14 and 3.18, but I wouldn&#39;t call that a</span>
<span class="quote">&gt;         pleasant experience. Feel free to ask your questions though.</span>
<span class="quote">&gt;         &gt; Best Regards,</span>
<span class="quote">&gt;         &gt; Baozeng</span>
<span class="quote">&gt;         &gt;</span>
<span class="quote">&gt;         &gt; 2016-06-15 17:02 GMT+08:00 Alexander Potapenko &lt;glider@google.com &lt;mailto:glider@google.com&gt;&gt;:</span>
<span class="quote">&gt;         &gt;&gt;</span>
<span class="quote">&gt;         &gt;&gt; Baozeng,</span>
<span class="quote">&gt;         &gt;&gt;</span>
<span class="quote">&gt;         &gt;&gt; In order to use ConsoleDev you&#39;ll need a serial port support in the</span>
<span class="quote">&gt;         &gt;&gt; kernel, and an external serial port attached to the Android device.</span>
<span class="quote">&gt;         &gt;&gt; If you don&#39;t have a serial port, you&#39;ll probably need to change adb.go</span>
<span class="quote">&gt;         &gt;&gt; to read the dmesg output from adb shell.</span>
<span class="quote">&gt;         &gt;&gt;</span>
<span class="quote">&gt;         &gt;&gt; HTH,</span>
<span class="quote">&gt;         &gt;&gt; Alex</span>
<span class="quote">&gt;         &gt;&gt;</span>
<span class="quote">&gt;         &gt;&gt; On Wed, Jun 15, 2016 at 2:46 AM, Baozeng &lt;sploving1@gmail.com &lt;mailto:sploving1@gmail.com&gt;&gt; wrote:</span>
<span class="quote">&gt;         &gt;&gt; &gt; Thank you Alexander. We will have a try.</span>
<span class="quote">&gt;         &gt;&gt; &gt; Dmitry, I have another stupid question. I took a look at the adb.go, and</span>
<span class="quote">&gt;         &gt;&gt; &gt; find a ConsoleDev config. Could you give me an example how to use it?</span>
<span class="quote">&gt;         &gt;&gt; &gt; how</span>
<span class="quote">&gt;         &gt;&gt; &gt; to use a &quot;cat &quot; command to get the log from the console device. Does it</span>
<span class="quote">&gt;         &gt;&gt; &gt; need</span>
<span class="quote">&gt;         &gt;&gt; &gt; to install any other tool to debug the android device, like this</span>
<span class="quote">&gt;         &gt;&gt; &gt; https://developer.chrome.com/devtools/docs/remote-debugging?  Thank you</span>
<span class="quote">&gt;         &gt;&gt; &gt; in</span>
<span class="quote">&gt;         &gt;&gt; &gt; advance.</span>
<span class="quote">&gt;         &gt;&gt; &gt;</span>
<span class="quote">&gt;         &gt;&gt; &gt; 2016-06-14 21:32 GMT+08:00 Alexander Potapenko &lt;glider@google.com &lt;mailto:glider@google.com&gt;&gt;:</span>
<span class="quote">&gt;         &gt;&gt; &gt;&gt;</span>
<span class="quote">&gt;         &gt;&gt; &gt;&gt; Hi Baozeng,</span>
<span class="quote">&gt;         &gt;&gt; &gt;&gt;</span>
<span class="quote">&gt;         &gt;&gt; &gt;&gt; You may want to take a look at the discussion at</span>
<span class="quote">&gt;         &gt;&gt; &gt;&gt;</span>
<span class="quote">&gt;         &gt;&gt; &gt;&gt;</span>
<span class="quote">&gt;         &gt;&gt; &gt;&gt; http://lists.infradead.org/pipermail/linux-arm-kernel/2016-March/419034.html,</span>
<span class="quote">&gt;         &gt;&gt; &gt;&gt; namely at the list of files for which kcov instrumentation should be</span>
<span class="quote">&gt;         &gt;&gt; &gt;&gt; disabled.</span>
<span class="quote">&gt;         &gt;&gt; &gt;&gt; If your kernel doesn&#39;t boot, try carpet-disabling  arch/arm64/boot/*</span>
<span class="quote">&gt;         &gt;&gt; &gt;&gt; and arch/arm64/kernel/*, and then you can bisect further.</span>
<span class="quote">&gt;         &gt;&gt; &gt;&gt;</span>
<span class="quote">&gt;         &gt;&gt; &gt;&gt; Alex</span>
<span class="quote">&gt;         &gt;&gt; &gt;&gt;</span>
<span class="quote">&gt;         &gt;&gt; &gt;&gt; On Tue, Jun 14, 2016 at 11:31 AM, Dmitry Vyukov &lt;dvyukov@gmail.com &lt;mailto:dvyukov@gmail.com&gt;&gt;</span>
<span class="quote">&gt;         &gt;&gt; &gt;&gt; wrote:</span>
<span class="quote">&gt;         &gt;&gt; &gt;&gt; &gt; On Tue, Jun 14, 2016 at 11:21 AM, Baozeng &lt;sploving1@gmail.com &lt;mailto:sploving1@gmail.com&gt;&gt;</span>
<span class="quote">&gt;         &gt;&gt; &gt;&gt; &gt; wrote:</span>
<span class="quote">&gt;         &gt;&gt; &gt;&gt; &gt;&gt; Hi Dmitry,</span>
<span class="quote">&gt;         &gt;&gt; &gt;&gt; &gt;&gt;      We&#39;ve ported kcov to arm64 android kernel  (nexus 6P device).</span>
<span class="quote">&gt;         &gt;&gt; &gt;&gt; &gt;&gt; But</span>
<span class="quote">&gt;         &gt;&gt; &gt;&gt; &gt;&gt; it</span>
<span class="quote">&gt;         &gt;&gt; &gt;&gt; &gt;&gt; cannot boot. The size of the kernel is 1.3 M larger than the origin</span>
<span class="quote">&gt;         &gt;&gt; &gt;&gt; &gt;&gt; one</span>
<span class="quote">&gt;         &gt;&gt; &gt;&gt; &gt;&gt; without kcov. Does this affect the booting of the android device?</span>
<span class="quote">&gt;         &gt;&gt; &gt;&gt; &gt;</span>
<span class="quote">&gt;         &gt;&gt; &gt;&gt; &gt; +syzkaller mailing list</span>
<span class="quote">&gt;         &gt;&gt; &gt;&gt; &gt;</span>
<span class="quote">&gt;         &gt;&gt; &gt;&gt; &gt; Hi Baozeng,</span>
<span class="quote">&gt;         &gt;&gt; &gt;&gt; &gt;</span>
<span class="quote">&gt;         &gt;&gt; &gt;&gt; &gt; We&#39;ve ported kcov to arm64 and use it with some Android devices.</span>
<span class="quote">&gt;         &gt;&gt; &gt;&gt; &gt; +Alexander knows more. Did we mail the patches upstream?</span>
<span class="quote">&gt;         &gt;&gt; &gt;&gt; &gt;</span>
<span class="quote">&gt;         &gt;&gt; &gt;&gt; &gt; The boot issue is most likely to bad interaction of kcov</span>
<span class="quote">&gt;         &gt;&gt; &gt;&gt; &gt; instrumentation with some early bootstrap files. Most likely you need</span>
<span class="quote">&gt;         &gt;&gt; &gt;&gt; &gt; to disable instrumentation of some boot files.</span>
<span class="quote">&gt;         &gt;&gt; &gt;&gt; &gt;</span>
<span class="quote">&gt;         &gt;&gt; &gt;&gt; &gt; --</span>
<span class="quote">&gt;         &gt;&gt; &gt;&gt; &gt; You received this message because you are subscribed to the Google</span>
<span class="quote">&gt;         &gt;&gt; &gt;&gt; &gt; Groups &quot;syzkaller&quot; group.</span>
<span class="quote">&gt;         &gt;&gt; &gt;&gt; &gt; To unsubscribe from this group and stop receiving emails from it,</span>
<span class="quote">&gt;         &gt;&gt; &gt;&gt; &gt; send</span>
<span class="quote">&gt;         &gt;&gt; &gt;&gt; &gt; an email to syzkaller+unsubscribe@googlegroups.com &lt;mailto:syzkaller%2Bunsubscribe@googlegroups.com&gt;.</span>
<span class="quote">&gt;         &gt;&gt; &gt;&gt; &gt; For more options, visit https://groups.google.com/d/optout.</span>
<span class="quote">&gt;         &gt;&gt; &gt;&gt;</span>
<span class="quote">&gt;         &gt;&gt; &gt;&gt;</span>
<span class="quote">&gt;         &gt;&gt; &gt;&gt;</span>
<span class="quote">&gt;         &gt;&gt; &gt;&gt; --</span>
<span class="quote">&gt;         &gt;&gt; &gt;&gt; Alexander Potapenko</span>
<span class="quote">&gt;         &gt;&gt; &gt;&gt; Software Engineer</span>
<span class="quote">&gt;         &gt;&gt; &gt;&gt;</span>
<span class="quote">&gt;         &gt;&gt; &gt;&gt; Google Germany GmbH</span>
<span class="quote">&gt;         &gt;&gt; &gt;&gt; Erika-Mann-Straße, 33</span>
<span class="quote">&gt;         &gt;&gt; &gt;&gt; 80636 München</span>
<span class="quote">&gt;         &gt;&gt; &gt;&gt;</span>
<span class="quote">&gt;         &gt;&gt; &gt;&gt; Geschäftsführer: Matthew Scott Sucherman, Paul Terence Manicle</span>
<span class="quote">&gt;         &gt;&gt; &gt;&gt; Registergericht und -nummer: Hamburg, HRB 86891</span>
<span class="quote">&gt;         &gt;&gt; &gt;&gt; Sitz der Gesellschaft: Hamburg</span>
<span class="quote">&gt;         &gt;&gt; &gt;</span>
<span class="quote">&gt;         &gt;&gt; &gt;</span>
<span class="quote">&gt;         &gt;&gt; &gt;</span>
<span class="quote">&gt;         &gt;&gt; &gt;</span>
<span class="quote">&gt;         &gt;&gt; &gt; --</span>
<span class="quote">&gt;         &gt;&gt; &gt;      Best Regards,</span>
<span class="quote">&gt;         &gt;&gt; &gt;      Baozeng Ding</span>
<span class="quote">&gt;         &gt;&gt; &gt;</span>
<span class="quote">&gt;         &gt;&gt;</span>
<span class="quote">&gt;         &gt;&gt;</span>
<span class="quote">&gt;         &gt;&gt;</span>
<span class="quote">&gt;         &gt;&gt; --</span>
<span class="quote">&gt;         &gt;&gt; Alexander Potapenko</span>
<span class="quote">&gt;         &gt;&gt; Software Engineer</span>
<span class="quote">&gt;         &gt;&gt;</span>
<span class="quote">&gt;         &gt;&gt; Google Germany GmbH</span>
<span class="quote">&gt;         &gt;&gt; Erika-Mann-Straße, 33</span>
<span class="quote">&gt;         &gt;&gt; 80636 München</span>
<span class="quote">&gt;         &gt;&gt;</span>
<span class="quote">&gt;         &gt;&gt; Geschäftsführer: Matthew Scott Sucherman, Paul Terence Manicle</span>
<span class="quote">&gt;         &gt;&gt; Registergericht und -nummer: Hamburg, HRB 86891</span>
<span class="quote">&gt;         &gt;&gt; Sitz der Gesellschaft: Hamburg</span>
<span class="quote">&gt;         &gt;</span>
<span class="quote">&gt;         &gt;</span>
<span class="quote">&gt;         &gt;</span>
<span class="quote">&gt;         &gt;</span>
<span class="quote">&gt;         &gt; --</span>
<span class="quote">&gt;         &gt;      Best Regards,</span>
<span class="quote">&gt;         &gt;      Baozeng Ding</span>
<span class="quote">&gt;         &gt;</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; </span>
<span class="quote">&gt; </span>
<span class="quote">&gt;         --</span>
<span class="quote">&gt;         Alexander Potapenko</span>
<span class="quote">&gt;         Software Engineer</span>
<span class="quote">&gt; </span>
<span class="quote">&gt;         Google Germany GmbH</span>
<span class="quote">&gt;         Erika-Mann-Straße, 33</span>
<span class="quote">&gt;         80636 München</span>
<span class="quote">&gt; </span>
<span class="quote">&gt;         Geschäftsführer: Matthew Scott Sucherman, Paul Terence Manicle</span>
<span class="quote">&gt;         Registergericht und -nummer: Hamburg, HRB 86891</span>
<span class="quote">&gt;         Sitz der Gesellschaft: Hamburg</span>
<span class="quote">&gt; </span>
<span class="quote">&gt;         --</span>
<span class="quote">&gt;         You received this message because you are subscribed to the Google Groups &quot;syzkaller&quot; group.</span>
<span class="quote">&gt;         To unsubscribe from this group and stop receiving emails from it, send an email to syzkaller+unsubscribe@googlegroups.com &lt;mailto:syzkaller%2Bunsubscribe@googlegroups.com&gt;.</span>
<span class="quote">&gt;         For more options, visit https://groups.google.com/d/optout.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; </span>
<span class="quote">&gt; </span>
<span class="quote">&gt; </span>
<span class="quote">&gt; </span>
<span class="quote">&gt; -- </span>
<span class="quote">&gt;      Best Regards,</span>
<span class="quote">&gt;      Baozeng Ding</span>
<span class="quote">&gt;</span>
commit 5ca47dfed22e5bae58d6c61f0a48487970d1e7ed
Author: Baozeng Ding &lt;sploving1@gmail.com&gt;
Date:   Sun Jul 3 12:01:19 2016 +0800

    3.10.102+: Support KASAN for x86_64
    
    Borrowed Andrey Ryabinin&#39;s work: KASAN backport for vzkernel:
    https://lists.openvz.org/pipermail/devel/2015-August/066379.html
    This patch adds support KASAN for 3.10.1022+ (x86_64)
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/Documentation/kasan.txt b/Documentation/kasan.txt</span>
new file mode 100644
<span class="p_header">index 0000000..ee36ef1</span>
<span class="p_header">--- /dev/null</span>
<span class="p_header">+++ b/Documentation/kasan.txt</span>
<span class="p_chunk">@@ -0,0 +1,169 @@</span> <span class="p_context"></span>
<span class="p_add">+Kernel address sanitizer</span>
<span class="p_add">+================</span>
<span class="p_add">+</span>
<span class="p_add">+0. Overview</span>
<span class="p_add">+===========</span>
<span class="p_add">+</span>
<span class="p_add">+Kernel Address sanitizer (KASan) is a dynamic memory error detector. It provides</span>
<span class="p_add">+a fast and comprehensive solution for finding use-after-free and out-of-bounds</span>
<span class="p_add">+bugs.</span>
<span class="p_add">+</span>
<span class="p_add">+KASan uses compile-time instrumentation for checking every memory access,</span>
<span class="p_add">+therefore you will need a certain version of GCC &gt; 4.9.2</span>
<span class="p_add">+</span>
<span class="p_add">+Currently KASan is supported only for x86_64 architecture and requires that the</span>
<span class="p_add">+kernel be built with the SLUB allocator.</span>
<span class="p_add">+</span>
<span class="p_add">+1. Usage</span>
<span class="p_add">+=========</span>
<span class="p_add">+</span>
<span class="p_add">+To enable KASAN configure kernel with:</span>
<span class="p_add">+</span>
<span class="p_add">+	  CONFIG_KASAN = y</span>
<span class="p_add">+</span>
<span class="p_add">+and choose between CONFIG_KASAN_OUTLINE and CONFIG_KASAN_INLINE. Outline/inline</span>
<span class="p_add">+is compiler instrumentation types. The former produces smaller binary the</span>
<span class="p_add">+latter is 1.1 - 2 times faster. Inline instrumentation requires GCC 5.0 or</span>
<span class="p_add">+latter.</span>
<span class="p_add">+</span>
<span class="p_add">+Currently KASAN works only with the SLUB memory allocator.</span>
<span class="p_add">+For better bug detection and nicer report and enable CONFIG_STACKTRACE.</span>
<span class="p_add">+</span>
<span class="p_add">+To disable instrumentation for specific files or directories, add a line</span>
<span class="p_add">+similar to the following to the respective kernel Makefile:</span>
<span class="p_add">+</span>
<span class="p_add">+        For a single file (e.g. main.o):</span>
<span class="p_add">+                KASAN_SANITIZE_main.o := n</span>
<span class="p_add">+</span>
<span class="p_add">+        For all files in one directory:</span>
<span class="p_add">+                KASAN_SANITIZE := n</span>
<span class="p_add">+</span>
<span class="p_add">+1.1 Error reports</span>
<span class="p_add">+==========</span>
<span class="p_add">+</span>
<span class="p_add">+A typical out of bounds access report looks like this:</span>
<span class="p_add">+</span>
<span class="p_add">+==================================================================</span>
<span class="p_add">+BUG: AddressSanitizer: out of bounds access in kmalloc_oob_right+0x65/0x75 [test_kasan] at addr ffff8800693bc5d3</span>
<span class="p_add">+Write of size 1 by task modprobe/1689</span>
<span class="p_add">+=============================================================================</span>
<span class="p_add">+BUG kmalloc-128 (Not tainted): kasan error</span>
<span class="p_add">+-----------------------------------------------------------------------------</span>
<span class="p_add">+</span>
<span class="p_add">+Disabling lock debugging due to kernel taint</span>
<span class="p_add">+INFO: Allocated in kmalloc_oob_right+0x3d/0x75 [test_kasan] age=0 cpu=0 pid=1689</span>
<span class="p_add">+ __slab_alloc+0x4b4/0x4f0</span>
<span class="p_add">+ kmem_cache_alloc_trace+0x10b/0x190</span>
<span class="p_add">+ kmalloc_oob_right+0x3d/0x75 [test_kasan]</span>
<span class="p_add">+ init_module+0x9/0x47 [test_kasan]</span>
<span class="p_add">+ do_one_initcall+0x99/0x200</span>
<span class="p_add">+ load_module+0x2cb3/0x3b20</span>
<span class="p_add">+ SyS_finit_module+0x76/0x80</span>
<span class="p_add">+ system_call_fastpath+0x12/0x17</span>
<span class="p_add">+INFO: Slab 0xffffea0001a4ef00 objects=17 used=7 fp=0xffff8800693bd728 flags=0x100000000004080</span>
<span class="p_add">+INFO: Object 0xffff8800693bc558 @offset=1368 fp=0xffff8800693bc720</span>
<span class="p_add">+</span>
<span class="p_add">+Bytes b4 ffff8800693bc548: 00 00 00 00 00 00 00 00 5a 5a 5a 5a 5a 5a 5a 5a  ........ZZZZZZZZ</span>
<span class="p_add">+Object ffff8800693bc558: 6b 6b 6b 6b 6b 6b 6b 6b 6b 6b 6b 6b 6b 6b 6b 6b  kkkkkkkkkkkkkkkk</span>
<span class="p_add">+Object ffff8800693bc568: 6b 6b 6b 6b 6b 6b 6b 6b 6b 6b 6b 6b 6b 6b 6b 6b  kkkkkkkkkkkkkkkk</span>
<span class="p_add">+Object ffff8800693bc578: 6b 6b 6b 6b 6b 6b 6b 6b 6b 6b 6b 6b 6b 6b 6b 6b  kkkkkkkkkkkkkkkk</span>
<span class="p_add">+Object ffff8800693bc588: 6b 6b 6b 6b 6b 6b 6b 6b 6b 6b 6b 6b 6b 6b 6b 6b  kkkkkkkkkkkkkkkk</span>
<span class="p_add">+Object ffff8800693bc598: 6b 6b 6b 6b 6b 6b 6b 6b 6b 6b 6b 6b 6b 6b 6b 6b  kkkkkkkkkkkkkkkk</span>
<span class="p_add">+Object ffff8800693bc5a8: 6b 6b 6b 6b 6b 6b 6b 6b 6b 6b 6b 6b 6b 6b 6b 6b  kkkkkkkkkkkkkkkk</span>
<span class="p_add">+Object ffff8800693bc5b8: 6b 6b 6b 6b 6b 6b 6b 6b 6b 6b 6b 6b 6b 6b 6b 6b  kkkkkkkkkkkkkkkk</span>
<span class="p_add">+Object ffff8800693bc5c8: 6b 6b 6b 6b 6b 6b 6b 6b 6b 6b 6b 6b 6b 6b 6b a5  kkkkkkkkkkkkkkk.</span>
<span class="p_add">+Redzone ffff8800693bc5d8: cc cc cc cc cc cc cc cc                          ........</span>
<span class="p_add">+Padding ffff8800693bc718: 5a 5a 5a 5a 5a 5a 5a 5a                          ZZZZZZZZ</span>
<span class="p_add">+CPU: 0 PID: 1689 Comm: modprobe Tainted: G    B          3.18.0-rc1-mm1+ #98</span>
<span class="p_add">+Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS rel-1.7.5-0-ge51488c-20140602_164612-nilsson.home.kraxel.org 04/01/2014</span>
<span class="p_add">+ ffff8800693bc000 0000000000000000 ffff8800693bc558 ffff88006923bb78</span>
<span class="p_add">+ ffffffff81cc68ae 00000000000000f3 ffff88006d407600 ffff88006923bba8</span>
<span class="p_add">+ ffffffff811fd848 ffff88006d407600 ffffea0001a4ef00 ffff8800693bc558</span>
<span class="p_add">+Call Trace:</span>
<span class="p_add">+ [&lt;ffffffff81cc68ae&gt;] dump_stack+0x46/0x58</span>
<span class="p_add">+ [&lt;ffffffff811fd848&gt;] print_trailer+0xf8/0x160</span>
<span class="p_add">+ [&lt;ffffffffa00026a7&gt;] ? kmem_cache_oob+0xc3/0xc3 [test_kasan]</span>
<span class="p_add">+ [&lt;ffffffff811ff0f5&gt;] object_err+0x35/0x40</span>
<span class="p_add">+ [&lt;ffffffffa0002065&gt;] ? kmalloc_oob_right+0x65/0x75 [test_kasan]</span>
<span class="p_add">+ [&lt;ffffffff8120b9fa&gt;] kasan_report_error+0x38a/0x3f0</span>
<span class="p_add">+ [&lt;ffffffff8120a79f&gt;] ? kasan_poison_shadow+0x2f/0x40</span>
<span class="p_add">+ [&lt;ffffffff8120b344&gt;] ? kasan_unpoison_shadow+0x14/0x40</span>
<span class="p_add">+ [&lt;ffffffff8120a79f&gt;] ? kasan_poison_shadow+0x2f/0x40</span>
<span class="p_add">+ [&lt;ffffffffa00026a7&gt;] ? kmem_cache_oob+0xc3/0xc3 [test_kasan]</span>
<span class="p_add">+ [&lt;ffffffff8120a995&gt;] __asan_store1+0x75/0xb0</span>
<span class="p_add">+ [&lt;ffffffffa0002601&gt;] ? kmem_cache_oob+0x1d/0xc3 [test_kasan]</span>
<span class="p_add">+ [&lt;ffffffffa0002065&gt;] ? kmalloc_oob_right+0x65/0x75 [test_kasan]</span>
<span class="p_add">+ [&lt;ffffffffa0002065&gt;] kmalloc_oob_right+0x65/0x75 [test_kasan]</span>
<span class="p_add">+ [&lt;ffffffffa00026b0&gt;] init_module+0x9/0x47 [test_kasan]</span>
<span class="p_add">+ [&lt;ffffffff810002d9&gt;] do_one_initcall+0x99/0x200</span>
<span class="p_add">+ [&lt;ffffffff811e4e5c&gt;] ? __vunmap+0xec/0x160</span>
<span class="p_add">+ [&lt;ffffffff81114f63&gt;] load_module+0x2cb3/0x3b20</span>
<span class="p_add">+ [&lt;ffffffff8110fd70&gt;] ? m_show+0x240/0x240</span>
<span class="p_add">+ [&lt;ffffffff81115f06&gt;] SyS_finit_module+0x76/0x80</span>
<span class="p_add">+ [&lt;ffffffff81cd3129&gt;] system_call_fastpath+0x12/0x17</span>
<span class="p_add">+Memory state around the buggy address:</span>
<span class="p_add">+ ffff8800693bc300: fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc</span>
<span class="p_add">+ ffff8800693bc380: fc fc 00 00 00 00 00 00 00 00 00 00 00 00 00 fc</span>
<span class="p_add">+ ffff8800693bc400: fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc</span>
<span class="p_add">+ ffff8800693bc480: fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc</span>
<span class="p_add">+ ffff8800693bc500: fc fc fc fc fc fc fc fc fc fc fc 00 00 00 00 00</span>
<span class="p_add">+&gt;ffff8800693bc580: 00 00 00 00 00 00 00 00 00 00 03 fc fc fc fc fc</span>
<span class="p_add">+                                                 ^</span>
<span class="p_add">+ ffff8800693bc600: fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc</span>
<span class="p_add">+ ffff8800693bc680: fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc</span>
<span class="p_add">+ ffff8800693bc700: fc fc fc fc fb fb fb fb fb fb fb fb fb fb fb fb</span>
<span class="p_add">+ ffff8800693bc780: fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb</span>
<span class="p_add">+ ffff8800693bc800: fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb</span>
<span class="p_add">+==================================================================</span>
<span class="p_add">+</span>
<span class="p_add">+First sections describe slub object where bad access happened.</span>
<span class="p_add">+See &#39;SLUB Debug output&#39; section in Documentation/vm/slub.txt for details.</span>
<span class="p_add">+</span>
<span class="p_add">+In the last section the report shows memory state around the accessed address.</span>
<span class="p_add">+Reading this part requires some more understanding of how KASAN works.</span>
<span class="p_add">+</span>
<span class="p_add">+Each 8 bytes of memory are encoded in one shadow byte as accessible,</span>
<span class="p_add">+partially accessible, freed or they can be part of a redzone.</span>
<span class="p_add">+We use the following encoding for each shadow byte: 0 means that all 8 bytes</span>
<span class="p_add">+of the corresponding memory region are accessible; number N (1 &lt;= N &lt;= 7) means</span>
<span class="p_add">+that the first N bytes are accessible, and other (8 - N) bytes are not;</span>
<span class="p_add">+any negative value indicates that the entire 8-byte word is inaccessible.</span>
<span class="p_add">+We use different negative values to distinguish between different kinds of</span>
<span class="p_add">+inaccessible memory like redzones or freed memory (see mm/kasan/kasan.h).</span>
<span class="p_add">+</span>
<span class="p_add">+In the report above the arrows point to the shadow byte 03, which means that</span>
<span class="p_add">+the accessed address is partially accessible.</span>
<span class="p_add">+</span>
<span class="p_add">+</span>
<span class="p_add">+2. Implementation details</span>
<span class="p_add">+========================</span>
<span class="p_add">+</span>
<span class="p_add">+From a high level, our approach to memory error detection is similar to that</span>
<span class="p_add">+of kmemcheck: use shadow memory to record whether each byte of memory is safe</span>
<span class="p_add">+to access, and use compile-time instrumentation to check shadow memory on each</span>
<span class="p_add">+memory access.</span>
<span class="p_add">+</span>
<span class="p_add">+AddressSanitizer dedicates 1/8 of kernel memory to its shadow memory</span>
<span class="p_add">+(e.g. 16TB to cover 128TB on x86_64) and uses direct mapping with a scale and</span>
<span class="p_add">+offset to translate a memory address to its corresponding shadow address.</span>
<span class="p_add">+</span>
<span class="p_add">+Here is the function witch translate an address to its corresponding shadow</span>
<span class="p_add">+address:</span>
<span class="p_add">+</span>
<span class="p_add">+static inline void *kasan_mem_to_shadow(const void *addr)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return ((unsigned long)addr &gt;&gt; KASAN_SHADOW_SCALE_SHIFT)</span>
<span class="p_add">+		+ KASAN_SHADOW_OFFSET;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+where KASAN_SHADOW_SCALE_SHIFT = 3.</span>
<span class="p_add">+</span>
<span class="p_add">+Compile-time instrumentation used for checking memory accesses. Compiler inserts</span>
<span class="p_add">+function calls (__asan_load*(addr), __asan_store*(addr)) before each memory</span>
<span class="p_add">+access of size 1, 2, 4, 8 or 16. These functions check whether memory access is</span>
<span class="p_add">+valid or not by checking corresponding shadow memory.</span>
<span class="p_add">+</span>
<span class="p_add">+GCC 5.0 has possibility to perform inline instrumentation. Instead of making</span>
<span class="p_add">+function calls GCC directly inserts the code to check the shadow memory.</span>
<span class="p_add">+This option significantly enlarges kernel but it gives x1.1-x2 performance</span>
<span class="p_add">+boost over outline instrumented kernel.</span>
<span class="p_header">diff --git a/Documentation/x86/x86_64/mm.txt b/Documentation/x86/x86_64/mm.txt</span>
<span class="p_header">index bd43704..b054443 100644</span>
<span class="p_header">--- a/Documentation/x86/x86_64/mm.txt</span>
<span class="p_header">+++ b/Documentation/x86/x86_64/mm.txt</span>
<span class="p_chunk">@@ -14,6 +14,9 @@</span> <span class="p_context"> ffffea0000000000 - ffffeaffffffffff (=40 bits) virtual memory map (1TB)</span>
 ... unused hole ...
 ffffff0000000000 - ffffff7fffffffff (=39 bits) %esp fixup stacks
 ... unused hole ...
<span class="p_add">+ ... unused hole ...</span>
<span class="p_add">+ffffec0000000000 - fffffc0000000000 (=44 bits) kasan shadow memory (16TB)</span>
<span class="p_add">+... unused hole ...</span>
 ffffffff80000000 - ffffffffa0000000 (=512 MB)  kernel text mapping, from phys 0
 ffffffffa0000000 - ffffffffff5fffff (=1525 MB) module mapping space
 ffffffffff600000 - ffffffffffdfffff (=8 MB) vsyscalls
<span class="p_header">diff --git a/Makefile b/Makefile</span>
<span class="p_header">index 868093c..73cff1c 100644</span>
<span class="p_header">--- a/Makefile</span>
<span class="p_header">+++ b/Makefile</span>
<span class="p_chunk">@@ -394,7 +394,7 @@</span> <span class="p_context"> export MAKE AWK GENKSYMS INSTALLKERNEL PERL UTS_MACHINE</span>
 export HOSTCXX HOSTCXXFLAGS LDFLAGS_MODULE CHECK CHECKFLAGS
 
 export KBUILD_CPPFLAGS NOSTDINC_FLAGS LINUXINCLUDE OBJCOPYFLAGS LDFLAGS
<span class="p_del">-export KBUILD_CFLAGS CFLAGS_KERNEL CFLAGS_MODULE CFLAGS_GCOV</span>
<span class="p_add">+export KBUILD_CFLAGS CFLAGS_KERNEL CFLAGS_MODULE CFLAGS_GCOV CFLAGS_KASAN</span>
 export KBUILD_AFLAGS AFLAGS_KERNEL AFLAGS_MODULE
 export KBUILD_AFLAGS_MODULE KBUILD_CFLAGS_MODULE KBUILD_LDFLAGS_MODULE
 export KBUILD_AFLAGS_KERNEL KBUILD_CFLAGS_KERNEL
<span class="p_chunk">@@ -671,6 +671,8 @@</span> <span class="p_context"> ifeq ($(shell $(CONFIG_SHELL) $(srctree)/scripts/gcc-goto.sh $(CC)), y)</span>
 	KBUILD_CFLAGS += -DCC_HAVE_ASM_GOTO
 endif
 
<span class="p_add">+include $(srctree)/scripts/Makefile.kasan</span>
<span class="p_add">+</span>
 # Add user supplied CPPFLAGS, AFLAGS and CFLAGS as the last assignments
 KBUILD_CPPFLAGS += $(KCPPFLAGS)
 KBUILD_AFLAGS += $(KAFLAGS)
<span class="p_header">diff --git a/arch/arm/kernel/module.c b/arch/arm/kernel/module.c</span>
<span class="p_header">index af60478..2824951 100644</span>
<span class="p_header">--- a/arch/arm/kernel/module.c</span>
<span class="p_header">+++ b/arch/arm/kernel/module.c</span>
<span class="p_chunk">@@ -40,7 +40,7 @@</span> <span class="p_context"></span>
 void *module_alloc(unsigned long size)
 {
 	return __vmalloc_node_range(size, 1, MODULES_VADDR, MODULES_END,
<span class="p_del">-				GFP_KERNEL, PAGE_KERNEL_EXEC, -1,</span>
<span class="p_add">+				GFP_KERNEL, PAGE_KERNEL_EXEC, 0, NUMA_NO_NODE,</span>
 				__builtin_return_address(0));
 }
 #endif
<span class="p_header">diff --git a/arch/arm64/kernel/module.c b/arch/arm64/kernel/module.c</span>
<span class="p_header">index ca0e3d5..c7bc3e6 100644</span>
<span class="p_header">--- a/arch/arm64/kernel/module.c</span>
<span class="p_header">+++ b/arch/arm64/kernel/module.c</span>
<span class="p_chunk">@@ -29,8 +29,8 @@</span> <span class="p_context"></span>
 void *module_alloc(unsigned long size)
 {
 	return __vmalloc_node_range(size, 1, MODULES_VADDR, MODULES_END,
<span class="p_del">-				    GFP_KERNEL, PAGE_KERNEL_EXEC, -1,</span>
<span class="p_del">-				    __builtin_return_address(0));</span>
<span class="p_add">+				    GFP_KERNEL, PAGE_KERNEL_EXEC, 0,</span>
<span class="p_add">+				    NUMA_NO_NODE, __builtin_return_address(0));</span>
 }
 
 enum aarch64_reloc_op {
<span class="p_header">diff --git a/arch/mips/kernel/module.c b/arch/mips/kernel/module.c</span>
<span class="p_header">index 977a623..1833f51 100644</span>
<span class="p_header">--- a/arch/mips/kernel/module.c</span>
<span class="p_header">+++ b/arch/mips/kernel/module.c</span>
<span class="p_chunk">@@ -23,6 +23,7 @@</span> <span class="p_context"></span>
 #include &lt;linux/moduleloader.h&gt;
 #include &lt;linux/elf.h&gt;
 #include &lt;linux/mm.h&gt;
<span class="p_add">+#include &lt;linux/numa.h&gt;</span>
 #include &lt;linux/vmalloc.h&gt;
 #include &lt;linux/slab.h&gt;
 #include &lt;linux/fs.h&gt;
<span class="p_chunk">@@ -46,7 +47,7 @@</span> <span class="p_context"> static DEFINE_SPINLOCK(dbe_lock);</span>
 void *module_alloc(unsigned long size)
 {
 	return __vmalloc_node_range(size, 1, MODULE_START, MODULE_END,
<span class="p_del">-				GFP_KERNEL, PAGE_KERNEL, -1,</span>
<span class="p_add">+				GFP_KERNEL, PAGE_KERNEL, 0, NUMA_NO_NODE,</span>
 				__builtin_return_address(0));
 }
 #endif
<span class="p_header">diff --git a/arch/parisc/kernel/module.c b/arch/parisc/kernel/module.c</span>
<span class="p_header">index 2a625fb..0d498ef 100644</span>
<span class="p_header">--- a/arch/parisc/kernel/module.c</span>
<span class="p_header">+++ b/arch/parisc/kernel/module.c</span>
<span class="p_chunk">@@ -219,7 +219,7 @@</span> <span class="p_context"> void *module_alloc(unsigned long size)</span>
 	 * init_data correctly */
 	return __vmalloc_node_range(size, 1, VMALLOC_START, VMALLOC_END,
 				    GFP_KERNEL | __GFP_HIGHMEM,
<span class="p_del">-				    PAGE_KERNEL_RWX, -1,</span>
<span class="p_add">+				    PAGE_KERNEL_RWX, 0, NUMA_NO_NODE,</span>
 				    __builtin_return_address(0));
 }
 
<span class="p_header">diff --git a/arch/s390/kernel/module.c b/arch/s390/kernel/module.c</span>
<span class="p_header">index 7845e15..411a7ee 100644</span>
<span class="p_header">--- a/arch/s390/kernel/module.c</span>
<span class="p_header">+++ b/arch/s390/kernel/module.c</span>
<span class="p_chunk">@@ -50,7 +50,7 @@</span> <span class="p_context"> void *module_alloc(unsigned long size)</span>
 	if (PAGE_ALIGN(size) &gt; MODULES_LEN)
 		return NULL;
 	return __vmalloc_node_range(size, 1, MODULES_VADDR, MODULES_END,
<span class="p_del">-				    GFP_KERNEL, PAGE_KERNEL, -1,</span>
<span class="p_add">+				    GFP_KERNEL, PAGE_KERNEL, 0, NUMA_NO_NODE,</span>
 				    __builtin_return_address(0));
 }
 #endif
<span class="p_header">diff --git a/arch/sparc/kernel/module.c b/arch/sparc/kernel/module.c</span>
<span class="p_header">index 4435488..192a617 100644</span>
<span class="p_header">--- a/arch/sparc/kernel/module.c</span>
<span class="p_header">+++ b/arch/sparc/kernel/module.c</span>
<span class="p_chunk">@@ -29,7 +29,7 @@</span> <span class="p_context"> static void *module_map(unsigned long size)</span>
 	if (PAGE_ALIGN(size) &gt; MODULES_LEN)
 		return NULL;
 	return __vmalloc_node_range(size, 1, MODULES_VADDR, MODULES_END,
<span class="p_del">-				GFP_KERNEL, PAGE_KERNEL, -1,</span>
<span class="p_add">+				GFP_KERNEL, PAGE_KERNEL, 0, NUMA_NO_NODE,</span>
 				__builtin_return_address(0));
 }
 #else
<span class="p_header">diff --git a/arch/x86/Kconfig b/arch/x86/Kconfig</span>
<span class="p_header">index 105ae30..c8de68d 100644</span>
<span class="p_header">--- a/arch/x86/Kconfig</span>
<span class="p_header">+++ b/arch/x86/Kconfig</span>
<span class="p_chunk">@@ -77,6 +77,7 @@</span> <span class="p_context"> config X86</span>
 	select HAVE_CMPXCHG_LOCAL
 	select HAVE_CMPXCHG_DOUBLE
 	select HAVE_ARCH_KMEMCHECK
<span class="p_add">+	select HAVE_ARCH_KASAN if X86_64 &amp;&amp; SPARSEMEM_VMEMMAP</span>
 	select HAVE_USER_RETURN_NOTIFIER
 	select ARCH_BINFMT_ELF_RANDOMIZE_PIE
 	select HAVE_ARCH_JUMP_LABEL
<span class="p_header">diff --git a/arch/x86/boot/Makefile b/arch/x86/boot/Makefile</span>
<span class="p_header">index 6cf0111..262eec5 100644</span>
<span class="p_header">--- a/arch/x86/boot/Makefile</span>
<span class="p_header">+++ b/arch/x86/boot/Makefile</span>
<span class="p_chunk">@@ -14,6 +14,8 @@</span> <span class="p_context"></span>
 # Set it to -DSVGA_MODE=NORMAL_VGA if you just want the EGA/VGA mode.
 # The number is the same as you would ordinarily press at bootup.
 
<span class="p_add">+KASAN_SANITIZE := n</span>
<span class="p_add">+</span>
 SVGA_MODE	:= -DSVGA_MODE=NORMAL_VGA
 
 targets		:= vmlinux.bin setup.bin setup.elf bzImage
<span class="p_header">diff --git a/arch/x86/boot/compressed/Makefile b/arch/x86/boot/compressed/Makefile</span>
<span class="p_header">index 7194d9f..e126f6b 100644</span>
<span class="p_header">--- a/arch/x86/boot/compressed/Makefile</span>
<span class="p_header">+++ b/arch/x86/boot/compressed/Makefile</span>
<span class="p_chunk">@@ -18,6 +18,7 @@</span> <span class="p_context"> KBUILD_CFLAGS += $(call cc-option,-fno-stack-protector)</span>
 
 KBUILD_AFLAGS  := $(KBUILD_CFLAGS) -D__ASSEMBLY__
 GCOV_PROFILE := n
<span class="p_add">+KASAN_SANITIZE := n</span>
 
 LDFLAGS := -m elf_$(UTS_MACHINE)
 LDFLAGS_vmlinux := -T
<span class="p_header">diff --git a/arch/x86/boot/compressed/eboot.c b/arch/x86/boot/compressed/eboot.c</span>
<span class="p_header">index 1308bee..2a64063 100644</span>
<span class="p_header">--- a/arch/x86/boot/compressed/eboot.c</span>
<span class="p_header">+++ b/arch/x86/boot/compressed/eboot.c</span>
<span class="p_chunk">@@ -7,14 +7,15 @@</span> <span class="p_context"></span>
  *
  * ----------------------------------------------------------------------- */
 
<span class="p_add">+#include &quot;misc.h&quot;</span>
<span class="p_add">+#include &lt;linux/types.h&gt;</span>
<span class="p_add">+#include &quot;../string.h&quot;</span>
 #include &lt;linux/efi.h&gt;
 #include &lt;linux/pci.h&gt;
 #include &lt;asm/efi.h&gt;
 #include &lt;asm/setup.h&gt;
 #include &lt;asm/desc.h&gt;
 
<span class="p_del">-#undef memcpy			/* Use memcpy from misc.c */</span>
<span class="p_del">-</span>
 #include &quot;eboot.h&quot;
 
 static efi_system_table_t *sys_table;
<span class="p_header">diff --git a/arch/x86/boot/compressed/misc.h b/arch/x86/boot/compressed/misc.h</span>
<span class="p_header">index 674019d..768b889 100644</span>
<span class="p_header">--- a/arch/x86/boot/compressed/misc.h</span>
<span class="p_header">+++ b/arch/x86/boot/compressed/misc.h</span>
<span class="p_chunk">@@ -7,6 +7,7 @@</span> <span class="p_context"></span>
  * we just keep it from happening
  */
 #undef CONFIG_PARAVIRT
<span class="p_add">+#undef CONFIG_KASAN</span>
 #ifdef CONFIG_X86_32
 #define _ASM_X86_DESC_H 1
 #endif
<span class="p_header">diff --git a/arch/x86/include/asm/kasan.h b/arch/x86/include/asm/kasan.h</span>
new file mode 100644
<span class="p_header">index 0000000..74a2a8d</span>
<span class="p_header">--- /dev/null</span>
<span class="p_header">+++ b/arch/x86/include/asm/kasan.h</span>
<span class="p_chunk">@@ -0,0 +1,27 @@</span> <span class="p_context"></span>
<span class="p_add">+#ifndef _ASM_X86_KASAN_H</span>
<span class="p_add">+#define _ASM_X86_KASAN_H</span>
<span class="p_add">+</span>
<span class="p_add">+/*</span>
<span class="p_add">+ * Compiler uses shadow offset assuming that addresses start</span>
<span class="p_add">+ * from 0. Kernel addresses don&#39;t start from 0, so shadow</span>
<span class="p_add">+ * for kernel really starts from compiler&#39;s shadow offset +</span>
<span class="p_add">+ * &#39;kernel address space start&#39; &gt;&gt; KASAN_SHADOW_SCALE_SHIFT</span>
<span class="p_add">+ */</span>
<span class="p_add">+#define KASAN_SHADOW_START      (KASAN_SHADOW_OFFSET + \</span>
<span class="p_add">+					(0xffff800000000000ULL &gt;&gt; 3))</span>
<span class="p_add">+/* 47 bits for kernel address -&gt; (47 - 3) bits for shadow */</span>
<span class="p_add">+#define KASAN_SHADOW_END        (KASAN_SHADOW_START + (1ULL &lt;&lt; (47 - 3)))</span>
<span class="p_add">+</span>
<span class="p_add">+#ifndef __ASSEMBLY__</span>
<span class="p_add">+</span>
<span class="p_add">+#ifdef CONFIG_KASAN</span>
<span class="p_add">+void __init kasan_early_init(void);</span>
<span class="p_add">+void __init kasan_init(void);</span>
<span class="p_add">+#else</span>
<span class="p_add">+static inline void kasan_early_init(void) { }</span>
<span class="p_add">+static inline void kasan_init(void) { }</span>
<span class="p_add">+#endif</span>
<span class="p_add">+</span>
<span class="p_add">+#endif</span>
<span class="p_add">+</span>
<span class="p_add">+#endif</span>
<span class="p_header">diff --git a/arch/x86/include/asm/string_64.h b/arch/x86/include/asm/string_64.h</span>
<span class="p_header">index 19e2c46..e466119 100644</span>
<span class="p_header">--- a/arch/x86/include/asm/string_64.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/string_64.h</span>
<span class="p_chunk">@@ -27,11 +27,12 @@</span> <span class="p_context"> static __always_inline void *__inline_memcpy(void *to, const void *from, size_t</span>
    function. */
 
 #define __HAVE_ARCH_MEMCPY 1
<span class="p_add">+extern void *__memcpy(void *to, const void *from, size_t len);</span>
<span class="p_add">+</span>
 #ifndef CONFIG_KMEMCHECK
 #if (__GNUC__ == 4 &amp;&amp; __GNUC_MINOR__ &gt;= 3) || __GNUC__ &gt; 4
 extern void *memcpy(void *to, const void *from, size_t len);
 #else
<span class="p_del">-extern void *__memcpy(void *to, const void *from, size_t len);</span>
 #define memcpy(dst, src, len)					\
 ({								\
 	size_t __len = (len);					\
<span class="p_chunk">@@ -53,9 +54,11 @@</span> <span class="p_context"> extern void *__memcpy(void *to, const void *from, size_t len);</span>
 
 #define __HAVE_ARCH_MEMSET
 void *memset(void *s, int c, size_t n);
<span class="p_add">+void *__memset(void *s, int c, size_t n);</span>
 
 #define __HAVE_ARCH_MEMMOVE
 void *memmove(void *dest, const void *src, size_t count);
<span class="p_add">+void *__memmove(void *dest, const void *src, size_t count);</span>
 
 int memcmp(const void *cs, const void *ct, size_t count);
 size_t strlen(const char *s);
<span class="p_chunk">@@ -63,6 +66,19 @@</span> <span class="p_context"> char *strcpy(char *dest, const char *src);</span>
 char *strcat(char *dest, const char *src);
 int strcmp(const char *cs, const char *ct);
 
<span class="p_add">+#if defined(CONFIG_KASAN) &amp;&amp; !defined(__SANITIZE_ADDRESS__)</span>
<span class="p_add">+</span>
<span class="p_add">+/*</span>
<span class="p_add">+ * For files that not instrumented (e.g. mm/slub.c) we</span>
<span class="p_add">+ * should use not instrumented version of mem* functions.</span>
<span class="p_add">+ */</span>
<span class="p_add">+</span>
<span class="p_add">+#undef memcpy</span>
<span class="p_add">+#define memcpy(dst, src, len) __memcpy(dst, src, len)</span>
<span class="p_add">+#define memmove(dst, src, len) __memmove(dst, src, len)</span>
<span class="p_add">+#define memset(s, c, n) __memset(s, c, n)</span>
<span class="p_add">+#endif</span>
<span class="p_add">+</span>
 #endif /* __KERNEL__ */
 
 #endif /* _ASM_X86_STRING_64_H */
<span class="p_header">diff --git a/arch/x86/include/asm/uaccess.h b/arch/x86/include/asm/uaccess.h</span>
<span class="p_header">index 5ee2687..854b048 100644</span>
<span class="p_header">--- a/arch/x86/include/asm/uaccess.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/uaccess.h</span>
<span class="p_chunk">@@ -5,6 +5,7 @@</span> <span class="p_context"></span>
  */
 #include &lt;linux/errno.h&gt;
 #include &lt;linux/compiler.h&gt;
<span class="p_add">+#include &lt;linux/kasan-checks.h&gt;</span>
 #include &lt;linux/thread_info.h&gt;
 #include &lt;linux/string.h&gt;
 #include &lt;asm/asm.h&gt;
<span class="p_header">diff --git a/arch/x86/include/asm/uaccess_64.h b/arch/x86/include/asm/uaccess_64.h</span>
<span class="p_header">index 34df5c2..a2e1844 100644</span>
<span class="p_header">--- a/arch/x86/include/asm/uaccess_64.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/uaccess_64.h</span>
<span class="p_chunk">@@ -7,6 +7,7 @@</span> <span class="p_context"></span>
 #include &lt;linux/compiler.h&gt;
 #include &lt;linux/errno.h&gt;
 #include &lt;linux/lockdep.h&gt;
<span class="p_add">+#include &lt;linux/kasan-checks.h&gt;</span>
 #include &lt;asm/alternative.h&gt;
 #include &lt;asm/cpufeature.h&gt;
 #include &lt;asm/page.h&gt;
<span class="p_chunk">@@ -59,6 +60,7 @@</span> <span class="p_context"> static inline unsigned long __must_check copy_from_user(void *to,</span>
 	int sz = __compiletime_object_size(to);
 
 	might_fault();
<span class="p_add">+	kasan_check_write(to, n);</span>
 	if (likely(sz == -1 || sz &gt;= n))
 		n = _copy_from_user(to, from, n);
 #ifdef CONFIG_DEBUG_VM
<span class="p_chunk">@@ -72,7 +74,7 @@</span> <span class="p_context"> static __always_inline __must_check</span>
 int copy_to_user(void __user *dst, const void *src, unsigned size)
 {
 	might_fault();
<span class="p_del">-</span>
<span class="p_add">+	kasan_check_read(src, size);</span>
 	return _copy_to_user(dst, src, size);
 }
 
<span class="p_chunk">@@ -122,6 +124,7 @@</span> <span class="p_context"> int __copy_from_user_nocheck(void *dst, const void __user *src, unsigned size)</span>
 static __always_inline __must_check
 int __copy_from_user(void *dst, const void __user *src, unsigned size)
 {
<span class="p_add">+	kasan_check_read(src, size);</span>
 	might_fault();
 	return __copy_from_user_nocheck(dst, src, size);
 }
<span class="p_chunk">@@ -181,6 +184,7 @@</span> <span class="p_context"> int __copy_in_user(void __user *dst, const void __user *src, unsigned size)</span>
 {
 	int ret = 0;
 
<span class="p_add">+	kasan_check_write(dst, size);</span>
 	might_fault();
 	if (!__builtin_constant_p(size))
 		return copy_user_generic((__force void *)dst,
<span class="p_chunk">@@ -232,12 +236,14 @@</span> <span class="p_context"> int __copy_in_user(void __user *dst, const void __user *src, unsigned size)</span>
 static __must_check __always_inline int
 __copy_from_user_inatomic(void *dst, const void __user *src, unsigned size)
 {
<span class="p_add">+	kasan_check_write(dst, size);</span>
 	return __copy_from_user_nocheck(dst, (__force const void *)src, size);
 }
 
 static __must_check __always_inline int
 __copy_to_user_inatomic(void __user *dst, const void *src, unsigned size)
 {
<span class="p_add">+	kasan_check_read(src, size);</span>
 	return __copy_to_user_nocheck((__force void *)dst, src, size);
 }
 
<span class="p_chunk">@@ -248,6 +254,7 @@</span> <span class="p_context"> static inline int</span>
 __copy_from_user_nocache(void *dst, const void __user *src, unsigned size)
 {
 	might_sleep();
<span class="p_add">+	kasan_check_write(dst, size);</span>
 	return __copy_user_nocache(dst, src, size, 1);
 }
 
<span class="p_chunk">@@ -255,6 +262,7 @@</span> <span class="p_context"> static inline int</span>
 __copy_from_user_inatomic_nocache(void *dst, const void __user *src,
 				  unsigned size)
 {
<span class="p_add">+	kasan_check_write(dst, size);</span>
 	return __copy_user_nocache(dst, src, size, 0);
 }
 
<span class="p_header">diff --git a/arch/x86/kernel/Makefile b/arch/x86/kernel/Makefile</span>
<span class="p_header">index 111eb35..c6fd092 100644</span>
<span class="p_header">--- a/arch/x86/kernel/Makefile</span>
<span class="p_header">+++ b/arch/x86/kernel/Makefile</span>
<span class="p_chunk">@@ -3,6 +3,9 @@</span> <span class="p_context"></span>
 #
 
 extra-y                := head_$(BITS).o head$(BITS).o head.o vmlinux.lds
<span class="p_add">+KASAN_SANITIZE_head$(BITS).o := n</span>
<span class="p_add">+KASAN_SANITIZE_dumpstack.o := n</span>
<span class="p_add">+KASAN_SANITIZE_dumpstack_$(BITS).o := n</span>
 
 CPPFLAGS_vmlinux.lds += -U$(UTS_MACHINE)
 
<span class="p_header">diff --git a/arch/x86/kernel/dumpstack.c b/arch/x86/kernel/dumpstack.c</span>
<span class="p_header">index deb6421..b10f70a 100644</span>
<span class="p_header">--- a/arch/x86/kernel/dumpstack.c</span>
<span class="p_header">+++ b/arch/x86/kernel/dumpstack.c</span>
<span class="p_chunk">@@ -258,7 +258,10 @@</span> <span class="p_context"> int __kprobes __die(const char *str, struct pt_regs *regs, long err)</span>
 	printk(&quot;SMP &quot;);
 #endif
 #ifdef CONFIG_DEBUG_PAGEALLOC
<span class="p_del">-	printk(&quot;DEBUG_PAGEALLOC&quot;);</span>
<span class="p_add">+	printk(&quot;DEBUG_PAGEALLOC &quot;);</span>
<span class="p_add">+#endif</span>
<span class="p_add">+#ifdef CONFIG_KASAN</span>
<span class="p_add">+	printk(&quot;KASAN&quot;);</span>
 #endif
 	printk(&quot;\n&quot;);
 	if (notify_die(DIE_OOPS, str, regs, err,
<span class="p_header">diff --git a/arch/x86/kernel/head64.c b/arch/x86/kernel/head64.c</span>
<span class="p_header">index 3b861b7..55b7b06 100644</span>
<span class="p_header">--- a/arch/x86/kernel/head64.c</span>
<span class="p_header">+++ b/arch/x86/kernel/head64.c</span>
<span class="p_chunk">@@ -27,6 +27,7 @@</span> <span class="p_context"></span>
 #include &lt;asm/bios_ebda.h&gt;
 #include &lt;asm/bootparam_utils.h&gt;
 #include &lt;asm/microcode.h&gt;
<span class="p_add">+#include &lt;asm/kasan.h&gt;</span>
 
 /*
  * Manage page tables very early on.
<span class="p_chunk">@@ -46,7 +47,7 @@</span> <span class="p_context"> static void __init reset_early_page_tables(void)</span>
 
 	next_early_pgt = 0;
 
<span class="p_del">-	write_cr3(__pa(early_level4_pgt));</span>
<span class="p_add">+	write_cr3(__pa_nodebug(early_level4_pgt));</span>
 }
 
 /* Create a new PMD entry */
<span class="p_chunk">@@ -59,7 +60,7 @@</span> <span class="p_context"> int __init early_make_pgtable(unsigned long address)</span>
 	pmdval_t pmd, *pmd_p;
 
 	/* Invalid address or early pgt is done ?  */
<span class="p_del">-	if (physaddr &gt;= MAXMEM || read_cr3() != __pa(early_level4_pgt))</span>
<span class="p_add">+	if (physaddr &gt;= MAXMEM || read_cr3() != __pa_nodebug(early_level4_pgt))</span>
 		return -1;
 
 again:
<span class="p_chunk">@@ -158,9 +159,12 @@</span> <span class="p_context"> void __init x86_64_start_kernel(char * real_mode_data)</span>
 	/* Kill off the identity-map trampoline */
 	reset_early_page_tables();
 
<span class="p_del">-	/* clear bss before set_intr_gate with early_idt_handler */</span>
 	clear_bss();
 
<span class="p_add">+	clear_page(init_level4_pgt);</span>
<span class="p_add">+</span>
<span class="p_add">+	kasan_early_init();</span>
<span class="p_add">+</span>
 	for (i = 0; i &lt; NUM_EXCEPTION_VECTORS; i++)
 		set_intr_gate(i, &amp;early_idt_handler_array[i]);
 	load_idt((const struct desc_ptr *)&amp;idt_descr);
<span class="p_chunk">@@ -175,7 +179,6 @@</span> <span class="p_context"> void __init x86_64_start_kernel(char * real_mode_data)</span>
 	if (console_loglevel == 10)
 		early_printk(&quot;Kernel alive\n&quot;);
 
<span class="p_del">-	clear_page(init_level4_pgt);</span>
 	/* set init_level4_pgt kernel high mapping*/
 	init_level4_pgt[511] = early_level4_pgt[511];
 
<span class="p_header">diff --git a/arch/x86/kernel/head_64.S b/arch/x86/kernel/head_64.S</span>
<span class="p_header">index 54bf9c2..848e11a 100644</span>
<span class="p_header">--- a/arch/x86/kernel/head_64.S</span>
<span class="p_header">+++ b/arch/x86/kernel/head_64.S</span>
<span class="p_chunk">@@ -538,3 +538,4 @@</span> <span class="p_context"> ENTRY(nmi_idt_table)</span>
 	__PAGE_ALIGNED_BSS
 NEXT_PAGE(empty_zero_page)
 	.skip PAGE_SIZE
<span class="p_add">+</span>
<span class="p_header">diff --git a/arch/x86/kernel/module.c b/arch/x86/kernel/module.c</span>
<span class="p_header">index 216a4d7..5a7c1ce 100644</span>
<span class="p_header">--- a/arch/x86/kernel/module.c</span>
<span class="p_header">+++ b/arch/x86/kernel/module.c</span>
<span class="p_chunk">@@ -24,6 +24,7 @@</span> <span class="p_context"></span>
 #include &lt;linux/fs.h&gt;
 #include &lt;linux/string.h&gt;
 #include &lt;linux/kernel.h&gt;
<span class="p_add">+#include &lt;linux/kasan.h&gt;</span>
 #include &lt;linux/bug.h&gt;
 #include &lt;linux/mm.h&gt;
 #include &lt;linux/gfp.h&gt;
<span class="p_chunk">@@ -45,11 +46,18 @@</span> <span class="p_context"> do {							\</span>
 
 void *module_alloc(unsigned long size)
 {
<span class="p_add">+	void *p;</span>
<span class="p_add">+</span>
 	if (PAGE_ALIGN(size) &gt; MODULES_LEN)
 		return NULL;
<span class="p_del">-	return __vmalloc_node_range(size, 1, MODULES_VADDR, MODULES_END,</span>
<span class="p_add">+	p =  __vmalloc_node_range(size, MODULE_ALIGN, MODULES_VADDR, MODULES_END,</span>
 				GFP_KERNEL | __GFP_HIGHMEM, PAGE_KERNEL_EXEC,
<span class="p_del">-				-1, __builtin_return_address(0));</span>
<span class="p_add">+				0, NUMA_NO_NODE, __builtin_return_address(0));</span>
<span class="p_add">+	if (p &amp;&amp; (kasan_module_alloc(p, size) &lt; 0)) {</span>
<span class="p_add">+		vfree(p);</span>
<span class="p_add">+		return NULL;</span>
<span class="p_add">+	}</span>
<span class="p_add">+	return p;</span>
 }
 
 #ifdef CONFIG_X86_32
<span class="p_header">diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c</span>
<span class="p_header">index 935aff3..ce3cb66 100644</span>
<span class="p_header">--- a/arch/x86/kernel/setup.c</span>
<span class="p_header">+++ b/arch/x86/kernel/setup.c</span>
<span class="p_chunk">@@ -89,6 +89,7 @@</span> <span class="p_context"></span>
 #include &lt;asm/cacheflush.h&gt;
 #include &lt;asm/processor.h&gt;
 #include &lt;asm/bugs.h&gt;
<span class="p_add">+#include &lt;asm/kasan.h&gt;</span>
 
 #include &lt;asm/vsyscall.h&gt;
 #include &lt;asm/cpu.h&gt;
<span class="p_chunk">@@ -1144,6 +1145,8 @@</span> <span class="p_context"> void __init setup_arch(char **cmdline_p)</span>
 
 	x86_init.paging.pagetable_init();
 
<span class="p_add">+	kasan_init();</span>
<span class="p_add">+</span>
 	if (boot_cpu_data.cpuid_level &gt;= 0) {
 		/* A CPU has %cr4 if and only if it has CPUID */
 		mmu_cr4_features = read_cr4();
<span class="p_header">diff --git a/arch/x86/kernel/x8664_ksyms_64.c b/arch/x86/kernel/x8664_ksyms_64.c</span>
<span class="p_header">index b014d94..9c9079c 100644</span>
<span class="p_header">--- a/arch/x86/kernel/x8664_ksyms_64.c</span>
<span class="p_header">+++ b/arch/x86/kernel/x8664_ksyms_64.c</span>
<span class="p_chunk">@@ -50,13 +50,19 @@</span> <span class="p_context"> EXPORT_SYMBOL(csum_partial);</span>
 #undef memset
 #undef memmove
 
<span class="p_add">+extern void *__memset(void *, int, __kernel_size_t);</span>
<span class="p_add">+extern void *__memcpy(void *, const void *, __kernel_size_t);</span>
<span class="p_add">+extern void *__memmove(void *, const void *, __kernel_size_t);</span>
 extern void *memset(void *, int, __kernel_size_t);
 extern void *memcpy(void *, const void *, __kernel_size_t);
<span class="p_del">-extern void *__memcpy(void *, const void *, __kernel_size_t);</span>
<span class="p_add">+extern void *memmove(void *, const void *, __kernel_size_t);</span>
<span class="p_add">+</span>
<span class="p_add">+EXPORT_SYMBOL(__memset);</span>
<span class="p_add">+EXPORT_SYMBOL(__memcpy);</span>
<span class="p_add">+EXPORT_SYMBOL(__memmove);</span>
 
 EXPORT_SYMBOL(memset);
 EXPORT_SYMBOL(memcpy);
<span class="p_del">-EXPORT_SYMBOL(__memcpy);</span>
 EXPORT_SYMBOL(memmove);
 
 #ifndef CONFIG_DEBUG_VIRTUAL
<span class="p_header">diff --git a/arch/x86/lib/memcpy_64.S b/arch/x86/lib/memcpy_64.S</span>
<span class="p_header">index 56313a3..89b53c9 100644</span>
<span class="p_header">--- a/arch/x86/lib/memcpy_64.S</span>
<span class="p_header">+++ b/arch/x86/lib/memcpy_64.S</span>
<span class="p_chunk">@@ -53,6 +53,8 @@</span> <span class="p_context"></span>
 .Lmemcpy_e_e:
 	.previous
 
<span class="p_add">+.weak memcpy</span>
<span class="p_add">+</span>
 ENTRY(__memcpy)
 ENTRY(memcpy)
 	CFI_STARTPROC
<span class="p_chunk">@@ -199,8 +201,8 @@</span> <span class="p_context"> ENDPROC(__memcpy)</span>
 	 * only outcome...
 	 */
 	.section .altinstructions, &quot;a&quot;
<span class="p_del">-	altinstruction_entry memcpy,.Lmemcpy_c,X86_FEATURE_REP_GOOD,\</span>
<span class="p_add">+	altinstruction_entry __memcpy,.Lmemcpy_c,X86_FEATURE_REP_GOOD,\</span>
 			     .Lmemcpy_e-.Lmemcpy_c,.Lmemcpy_e-.Lmemcpy_c
<span class="p_del">-	altinstruction_entry memcpy,.Lmemcpy_c_e,X86_FEATURE_ERMS, \</span>
<span class="p_add">+	altinstruction_entry __memcpy,.Lmemcpy_c_e,X86_FEATURE_ERMS, \</span>
 			     .Lmemcpy_e_e-.Lmemcpy_c_e,.Lmemcpy_e_e-.Lmemcpy_c_e
 	.previous
<span class="p_header">diff --git a/arch/x86/lib/memmove_64.S b/arch/x86/lib/memmove_64.S</span>
<span class="p_header">index 65268a6..9c4b530 100644</span>
<span class="p_header">--- a/arch/x86/lib/memmove_64.S</span>
<span class="p_header">+++ b/arch/x86/lib/memmove_64.S</span>
<span class="p_chunk">@@ -24,7 +24,10 @@</span> <span class="p_context"></span>
  * Output:
  * rax: dest
  */
<span class="p_add">+.weak memmove</span>
<span class="p_add">+</span>
 ENTRY(memmove)
<span class="p_add">+ENTRY(__memmove)</span>
 	CFI_STARTPROC
 
 	/* Handle more 32 bytes in loop */
<span class="p_chunk">@@ -220,4 +223,5 @@</span> <span class="p_context"> ENTRY(memmove)</span>
 		.Lmemmove_end_forward-.Lmemmove_begin_forward,	\
 		.Lmemmove_end_forward_efs-.Lmemmove_begin_forward_efs
 	.previous
<span class="p_add">+ENDPROC(__memmove)</span>
 ENDPROC(memmove)
<span class="p_header">diff --git a/arch/x86/lib/memset_64.S b/arch/x86/lib/memset_64.S</span>
<span class="p_header">index 2dcb380..6f44935 100644</span>
<span class="p_header">--- a/arch/x86/lib/memset_64.S</span>
<span class="p_header">+++ b/arch/x86/lib/memset_64.S</span>
<span class="p_chunk">@@ -56,6 +56,8 @@</span> <span class="p_context"></span>
 .Lmemset_e_e:
 	.previous
 
<span class="p_add">+.weak memset</span>
<span class="p_add">+</span>
 ENTRY(memset)
 ENTRY(__memset)
 	CFI_STARTPROC
<span class="p_chunk">@@ -147,8 +149,8 @@</span> <span class="p_context"> ENDPROC(__memset)</span>
          * feature to implement the right patch order.
 	 */
 	.section .altinstructions,&quot;a&quot;
<span class="p_del">-	altinstruction_entry memset,.Lmemset_c,X86_FEATURE_REP_GOOD,\</span>
<span class="p_del">-			     .Lfinal-memset,.Lmemset_e-.Lmemset_c</span>
<span class="p_del">-	altinstruction_entry memset,.Lmemset_c_e,X86_FEATURE_ERMS, \</span>
<span class="p_del">-			     .Lfinal-memset,.Lmemset_e_e-.Lmemset_c_e</span>
<span class="p_add">+	altinstruction_entry __memset,.Lmemset_c,X86_FEATURE_REP_GOOD,\</span>
<span class="p_add">+			     .Lfinal-__memset,.Lmemset_e-.Lmemset_c</span>
<span class="p_add">+	altinstruction_entry __memset,.Lmemset_c_e,X86_FEATURE_ERMS, \</span>
<span class="p_add">+			     .Lfinal-__memset,.Lmemset_e_e-.Lmemset_c_e</span>
 	.previous
<span class="p_header">diff --git a/arch/x86/mm/Makefile b/arch/x86/mm/Makefile</span>
<span class="p_header">index 23d8e5f..9cec934 100644</span>
<span class="p_header">--- a/arch/x86/mm/Makefile</span>
<span class="p_header">+++ b/arch/x86/mm/Makefile</span>
<span class="p_chunk">@@ -18,6 +18,9 @@</span> <span class="p_context"> obj-$(CONFIG_HIGHMEM)		+= highmem_32.o</span>
 
 obj-$(CONFIG_KMEMCHECK)		+= kmemcheck/
 
<span class="p_add">+KASAN_SANITIZE_kasan_init_$(BITS).o := n</span>
<span class="p_add">+obj-$(CONFIG_KASAN)		+= kasan_init_$(BITS).o</span>
<span class="p_add">+</span>
 obj-$(CONFIG_MMIOTRACE)		+= mmiotrace.o
 mmiotrace-y			:= kmmio.o pf_in.o mmio-mod.o
 obj-$(CONFIG_MMIOTRACE_TEST)	+= testmmiotrace.o
<span class="p_header">diff --git a/arch/x86/mm/kasan_init_64.c b/arch/x86/mm/kasan_init_64.c</span>
new file mode 100644
<span class="p_header">index 0000000..f9fb08e</span>
<span class="p_header">--- /dev/null</span>
<span class="p_header">+++ b/arch/x86/mm/kasan_init_64.c</span>
<span class="p_chunk">@@ -0,0 +1,243 @@</span> <span class="p_context"></span>
<span class="p_add">+#define pr_fmt(fmt) &quot;kasan: &quot; fmt</span>
<span class="p_add">+#include &lt;linux/bootmem.h&gt;</span>
<span class="p_add">+#include &lt;linux/kasan.h&gt;</span>
<span class="p_add">+#include &lt;linux/kdebug.h&gt;</span>
<span class="p_add">+#include &lt;linux/mm.h&gt;</span>
<span class="p_add">+#include &lt;linux/sched.h&gt;</span>
<span class="p_add">+#include &lt;linux/vmalloc.h&gt;</span>
<span class="p_add">+</span>
<span class="p_add">+#include &lt;asm/tlbflush.h&gt;</span>
<span class="p_add">+#include &lt;asm/sections.h&gt;</span>
<span class="p_add">+</span>
<span class="p_add">+extern pgd_t early_level4_pgt[PTRS_PER_PGD];</span>
<span class="p_add">+extern struct range pfn_mapped[E820_X_MAX];</span>
<span class="p_add">+</span>
<span class="p_add">+static pud_t kasan_zero_pud[PTRS_PER_PUD] __page_aligned_bss;</span>
<span class="p_add">+static pmd_t kasan_zero_pmd[PTRS_PER_PMD] __page_aligned_bss;</span>
<span class="p_add">+static pte_t kasan_zero_pte[PTRS_PER_PTE] __page_aligned_bss;</span>
<span class="p_add">+</span>
<span class="p_add">+/*</span>
<span class="p_add">+ * This page used as early shadow. We don&#39;t use empty_zero_page</span>
<span class="p_add">+ * at early stages, stack instrumentation could write some garbage</span>
<span class="p_add">+ * to this page.</span>
<span class="p_add">+ * Latter we reuse it as zero shadow for large ranges of memory</span>
<span class="p_add">+ * that allowed to access, but not instrumented by kasan</span>
<span class="p_add">+ * (vmalloc/vmemmap ...).</span>
<span class="p_add">+ */</span>
<span class="p_add">+static unsigned char kasan_zero_page[PAGE_SIZE] __page_aligned_bss;</span>
<span class="p_add">+</span>
<span class="p_add">+static int __init map_range(struct range *range)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long start;</span>
<span class="p_add">+	unsigned long end;</span>
<span class="p_add">+</span>
<span class="p_add">+	start = (unsigned long)kasan_mem_to_shadow(pfn_to_kaddr(range-&gt;start));</span>
<span class="p_add">+	end = (unsigned long)kasan_mem_to_shadow(pfn_to_kaddr(range-&gt;end));</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * end + 1 here is intentional. We check several shadow bytes in advance</span>
<span class="p_add">+	 * to slightly speed up fastpath. In some rare cases we could cross</span>
<span class="p_add">+	 * boundary of mapped shadow, so we just map some more here.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	return vmemmap_populate(start, end + 1, pfn_to_nid(range-&gt;start));</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static void __init clear_pgds(unsigned long start,</span>
<span class="p_add">+			unsigned long end)</span>
<span class="p_add">+{</span>
<span class="p_add">+	for (; start &lt; end; start += PGDIR_SIZE)</span>
<span class="p_add">+		pgd_clear(pgd_offset_k(start));</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static void __init kasan_map_early_shadow(pgd_t *pgd)</span>
<span class="p_add">+{</span>
<span class="p_add">+	int i;</span>
<span class="p_add">+	unsigned long start = KASAN_SHADOW_START;</span>
<span class="p_add">+	unsigned long end = KASAN_SHADOW_END;</span>
<span class="p_add">+</span>
<span class="p_add">+	for (i = pgd_index(start); start &lt; end; i++) {</span>
<span class="p_add">+		pgd[i] = __pgd(__pa_nodebug(kasan_zero_pud)</span>
<span class="p_add">+				| _KERNPG_TABLE);</span>
<span class="p_add">+		start += PGDIR_SIZE;</span>
<span class="p_add">+	}</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static int __init zero_pte_populate(pmd_t *pmd, unsigned long addr,</span>
<span class="p_add">+				unsigned long end)</span>
<span class="p_add">+{</span>
<span class="p_add">+	pte_t *pte = pte_offset_kernel(pmd, addr);</span>
<span class="p_add">+</span>
<span class="p_add">+	while (addr + PAGE_SIZE &lt;= end) {</span>
<span class="p_add">+		WARN_ON(!pte_none(*pte));</span>
<span class="p_add">+		set_pte(pte, __pte(__pa_nodebug(kasan_zero_page)</span>
<span class="p_add">+					| __PAGE_KERNEL_RO));</span>
<span class="p_add">+		addr += PAGE_SIZE;</span>
<span class="p_add">+		pte = pte_offset_kernel(pmd, addr);</span>
<span class="p_add">+	}</span>
<span class="p_add">+	return 0;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static int __init zero_pmd_populate(pud_t *pud, unsigned long addr,</span>
<span class="p_add">+				unsigned long end)</span>
<span class="p_add">+{</span>
<span class="p_add">+	int ret = 0;</span>
<span class="p_add">+	pmd_t *pmd = pmd_offset(pud, addr);</span>
<span class="p_add">+</span>
<span class="p_add">+	while (IS_ALIGNED(addr, PMD_SIZE) &amp;&amp; addr + PMD_SIZE &lt;= end) {</span>
<span class="p_add">+		WARN_ON(!pmd_none(*pmd));</span>
<span class="p_add">+		set_pmd(pmd, __pmd(__pa_nodebug(kasan_zero_pte)</span>
<span class="p_add">+					| _KERNPG_TABLE));</span>
<span class="p_add">+		addr += PMD_SIZE;</span>
<span class="p_add">+		pmd = pmd_offset(pud, addr);</span>
<span class="p_add">+	}</span>
<span class="p_add">+	if (addr &lt; end) {</span>
<span class="p_add">+		if (pmd_none(*pmd)) {</span>
<span class="p_add">+			void *p = vmemmap_alloc_block(PAGE_SIZE, 0);</span>
<span class="p_add">+			if (!p)</span>
<span class="p_add">+				return -ENOMEM;</span>
<span class="p_add">+			set_pmd(pmd, __pmd(__pa_nodebug(p) | _KERNPG_TABLE));</span>
<span class="p_add">+		}</span>
<span class="p_add">+		ret = zero_pte_populate(pmd, addr, end);</span>
<span class="p_add">+	}</span>
<span class="p_add">+	return ret;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+</span>
<span class="p_add">+static int __init zero_pud_populate(pgd_t *pgd, unsigned long addr,</span>
<span class="p_add">+				unsigned long end)</span>
<span class="p_add">+{</span>
<span class="p_add">+	int ret = 0;</span>
<span class="p_add">+	pud_t *pud = pud_offset(pgd, addr);</span>
<span class="p_add">+</span>
<span class="p_add">+	while (IS_ALIGNED(addr, PUD_SIZE) &amp;&amp; addr + PUD_SIZE &lt;= end) {</span>
<span class="p_add">+		WARN_ON(!pud_none(*pud));</span>
<span class="p_add">+		set_pud(pud, __pud(__pa_nodebug(kasan_zero_pmd)</span>
<span class="p_add">+					| _KERNPG_TABLE));</span>
<span class="p_add">+		addr += PUD_SIZE;</span>
<span class="p_add">+		pud = pud_offset(pgd, addr);</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	if (addr &lt; end) {</span>
<span class="p_add">+		if (pud_none(*pud)) {</span>
<span class="p_add">+			void *p = vmemmap_alloc_block(PAGE_SIZE, 0);</span>
<span class="p_add">+			if (!p)</span>
<span class="p_add">+				return -ENOMEM;</span>
<span class="p_add">+			set_pud(pud, __pud(__pa_nodebug(p) | _KERNPG_TABLE));</span>
<span class="p_add">+		}</span>
<span class="p_add">+		ret = zero_pmd_populate(pud, addr, end);</span>
<span class="p_add">+	}</span>
<span class="p_add">+	return ret;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static int __init zero_pgd_populate(unsigned long addr, unsigned long end)</span>
<span class="p_add">+{</span>
<span class="p_add">+	int ret = 0;</span>
<span class="p_add">+	pgd_t *pgd = pgd_offset_k(addr);</span>
<span class="p_add">+</span>
<span class="p_add">+	while (IS_ALIGNED(addr, PGDIR_SIZE) &amp;&amp; addr + PGDIR_SIZE &lt;= end) {</span>
<span class="p_add">+		WARN_ON(!pgd_none(*pgd));</span>
<span class="p_add">+		set_pgd(pgd, __pgd(__pa_nodebug(kasan_zero_pud)</span>
<span class="p_add">+					| _KERNPG_TABLE));</span>
<span class="p_add">+		addr += PGDIR_SIZE;</span>
<span class="p_add">+		pgd = pgd_offset_k(addr);</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	if (addr &lt; end) {</span>
<span class="p_add">+		if (pgd_none(*pgd)) {</span>
<span class="p_add">+			void *p = vmemmap_alloc_block(PAGE_SIZE, 0);</span>
<span class="p_add">+			if (!p)</span>
<span class="p_add">+				return -ENOMEM;</span>
<span class="p_add">+			set_pgd(pgd, __pgd(__pa_nodebug(p) | _KERNPG_TABLE));</span>
<span class="p_add">+		}</span>
<span class="p_add">+		ret = zero_pud_populate(pgd, addr, end);</span>
<span class="p_add">+	}</span>
<span class="p_add">+	return ret;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+</span>
<span class="p_add">+static void __init populate_zero_shadow(const void *start, const void *end)</span>
<span class="p_add">+{</span>
<span class="p_add">+	if (zero_pgd_populate((unsigned long)start, (unsigned long)end))</span>
<span class="p_add">+		panic(&quot;kasan: unable to map zero shadow!&quot;);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+</span>
<span class="p_add">+#ifdef CONFIG_KASAN_INLINE</span>
<span class="p_add">+static int kasan_die_handler(struct notifier_block *self,</span>
<span class="p_add">+			     unsigned long val,</span>
<span class="p_add">+			     void *data)</span>
<span class="p_add">+{</span>
<span class="p_add">+	if (val == DIE_GPF) {</span>
<span class="p_add">+		pr_emerg(&quot;CONFIG_KASAN_INLINE enabled&quot;);</span>
<span class="p_add">+		pr_emerg(&quot;GPF could be caused by NULL-ptr deref or user memory access&quot;);</span>
<span class="p_add">+	}</span>
<span class="p_add">+	return NOTIFY_OK;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static struct notifier_block kasan_die_notifier = {</span>
<span class="p_add">+	.notifier_call = kasan_die_handler,</span>
<span class="p_add">+};</span>
<span class="p_add">+#endif</span>
<span class="p_add">+</span>
<span class="p_add">+void __init kasan_early_init(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	int i;</span>
<span class="p_add">+	pteval_t pte_val = __pa_nodebug(kasan_zero_page) | __PAGE_KERNEL;</span>
<span class="p_add">+	pmdval_t pmd_val = __pa_nodebug(kasan_zero_pte) | _KERNPG_TABLE;</span>
<span class="p_add">+	pudval_t pud_val = __pa_nodebug(kasan_zero_pmd) | _KERNPG_TABLE;</span>
<span class="p_add">+</span>
<span class="p_add">+	for (i = 0; i &lt; PTRS_PER_PTE; i++)</span>
<span class="p_add">+		kasan_zero_pte[i] = __pte(pte_val);</span>
<span class="p_add">+</span>
<span class="p_add">+	for (i = 0; i &lt; PTRS_PER_PMD; i++)</span>
<span class="p_add">+		kasan_zero_pmd[i] = __pmd(pmd_val);</span>
<span class="p_add">+</span>
<span class="p_add">+	for (i = 0; i &lt; PTRS_PER_PUD; i++)</span>
<span class="p_add">+		kasan_zero_pud[i] = __pud(pud_val);</span>
<span class="p_add">+</span>
<span class="p_add">+	kasan_map_early_shadow(early_level4_pgt);</span>
<span class="p_add">+	kasan_map_early_shadow(init_level4_pgt);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void __init kasan_init(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	int i;</span>
<span class="p_add">+</span>
<span class="p_add">+#ifdef CONFIG_KASAN_INLINE</span>
<span class="p_add">+	register_die_notifier(&amp;kasan_die_notifier);</span>
<span class="p_add">+#endif</span>
<span class="p_add">+</span>
<span class="p_add">+	memcpy(early_level4_pgt, init_level4_pgt, sizeof(early_level4_pgt));</span>
<span class="p_add">+	load_cr3(early_level4_pgt);</span>
<span class="p_add">+	__flush_tlb_all();</span>
<span class="p_add">+</span>
<span class="p_add">+	clear_pgds(KASAN_SHADOW_START, KASAN_SHADOW_END);</span>
<span class="p_add">+</span>
<span class="p_add">+	populate_zero_shadow((void *)KASAN_SHADOW_START,</span>
<span class="p_add">+			kasan_mem_to_shadow((void *)PAGE_OFFSET));</span>
<span class="p_add">+</span>
<span class="p_add">+	for (i = 0; i &lt; E820_X_MAX; i++) {</span>
<span class="p_add">+		if (pfn_mapped[i].end == 0)</span>
<span class="p_add">+			break;</span>
<span class="p_add">+</span>
<span class="p_add">+		if (map_range(&amp;pfn_mapped[i]))</span>
<span class="p_add">+			panic(&quot;kasan: unable to allocate shadow!&quot;);</span>
<span class="p_add">+	}</span>
<span class="p_add">+	populate_zero_shadow(kasan_mem_to_shadow((void *)PAGE_OFFSET + MAXMEM),</span>
<span class="p_add">+			kasan_mem_to_shadow((void *)__START_KERNEL_map));</span>
<span class="p_add">+</span>
<span class="p_add">+	vmemmap_populate((unsigned long)kasan_mem_to_shadow(_stext),</span>
<span class="p_add">+			(unsigned long)kasan_mem_to_shadow(_end),</span>
<span class="p_add">+			0);</span>
<span class="p_add">+</span>
<span class="p_add">+	populate_zero_shadow(kasan_mem_to_shadow((void *)MODULES_END),</span>
<span class="p_add">+			(void *)KASAN_SHADOW_END);</span>
<span class="p_add">+</span>
<span class="p_add">+	memset(kasan_zero_page, 0, PAGE_SIZE);</span>
<span class="p_add">+</span>
<span class="p_add">+	load_cr3(init_level4_pgt);</span>
<span class="p_add">+	__flush_tlb_all();</span>
<span class="p_add">+	init_task.kasan_depth = 0;</span>
<span class="p_add">+</span>
<span class="p_add">+	pr_info(&quot;Kernel address sanitizer initialized\n&quot;);</span>
<span class="p_add">+}</span>
<span class="p_header">diff --git a/arch/x86/realmode/Makefile b/arch/x86/realmode/Makefile</span>
<span class="p_header">index 94f7fbe..e02c2c6 100644</span>
<span class="p_header">--- a/arch/x86/realmode/Makefile</span>
<span class="p_header">+++ b/arch/x86/realmode/Makefile</span>
<span class="p_chunk">@@ -6,7 +6,7 @@</span> <span class="p_context"></span>
 # for more details.
 #
 #
<span class="p_del">-</span>
<span class="p_add">+KASAN_SANITIZE := n</span>
 subdir- := rm
 
 obj-y += init.o
<span class="p_header">diff --git a/arch/x86/realmode/rm/Makefile b/arch/x86/realmode/rm/Makefile</span>
<span class="p_header">index 9cac825..53c6b65 100644</span>
<span class="p_header">--- a/arch/x86/realmode/rm/Makefile</span>
<span class="p_header">+++ b/arch/x86/realmode/rm/Makefile</span>
<span class="p_chunk">@@ -6,6 +6,7 @@</span> <span class="p_context"></span>
 # for more details.
 #
 #
<span class="p_add">+KASAN_SANITIZE := n</span>
 
 always := realmode.bin realmode.relocs
 
<span class="p_header">diff --git a/arch/x86/vdso/Makefile b/arch/x86/vdso/Makefile</span>
<span class="p_header">index fd14be1..d211772 100644</span>
<span class="p_header">--- a/arch/x86/vdso/Makefile</span>
<span class="p_header">+++ b/arch/x86/vdso/Makefile</span>
<span class="p_chunk">@@ -183,6 +183,7 @@</span> <span class="p_context"> quiet_cmd_vdso = VDSO    $@</span>
 
 VDSO_LDFLAGS = -fPIC -shared $(call cc-ldoption, -Wl$(comma)--hash-style=sysv)
 GCOV_PROFILE := n
<span class="p_add">+KASAN_SANITIZE := n</span>
 
 #
 # Install the unstripped copy of vdso*.so listed in $(vdso-install-y).
<span class="p_header">diff --git a/drivers/net/ethernet/emulex/benet/be_main.c b/drivers/net/ethernet/emulex/benet/be_main.c</span>
<span class="p_header">index 88e85cb..7ae5a8b 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/emulex/benet/be_main.c</span>
<span class="p_header">+++ b/drivers/net/ethernet/emulex/benet/be_main.c</span>
<span class="p_chunk">@@ -23,7 +23,6 @@</span> <span class="p_context"></span>
 #include &lt;linux/aer.h&gt;
 
 MODULE_VERSION(DRV_VER);
<span class="p_del">-MODULE_DEVICE_TABLE(pci, be_dev_ids);</span>
 MODULE_DESCRIPTION(DRV_DESC &quot; &quot; DRV_VER);
 MODULE_AUTHOR(&quot;Emulex Corporation&quot;);
 MODULE_LICENSE(&quot;GPL&quot;);
<span class="p_header">diff --git a/drivers/scsi/be2iscsi/be_main.c b/drivers/scsi/be2iscsi/be_main.c</span>
<span class="p_header">index a683a83..4300fd2 100644</span>
<span class="p_header">--- a/drivers/scsi/be2iscsi/be_main.c</span>
<span class="p_header">+++ b/drivers/scsi/be2iscsi/be_main.c</span>
<span class="p_chunk">@@ -48,7 +48,6 @@</span> <span class="p_context"> static unsigned int be_iopoll_budget = 10;</span>
 static unsigned int be_max_phys_size = 64;
 static unsigned int enable_msix = 1;
 
<span class="p_del">-MODULE_DEVICE_TABLE(pci, beiscsi_pci_id_table);</span>
 MODULE_DESCRIPTION(DRV_DESC &quot; &quot; BUILD_STR);
 MODULE_VERSION(BUILD_STR);
 MODULE_AUTHOR(&quot;Emulex Corporation&quot;);
<span class="p_header">diff --git a/fs/dcache.c b/fs/dcache.c</span>
<span class="p_header">index 17222fa..1d04914 100644</span>
<span class="p_header">--- a/fs/dcache.c</span>
<span class="p_header">+++ b/fs/dcache.c</span>
<span class="p_chunk">@@ -35,11 +35,13 @@</span> <span class="p_context"></span>
 #include &lt;linux/hardirq.h&gt;
 #include &lt;linux/bit_spinlock.h&gt;
 #include &lt;linux/rculist_bl.h&gt;
<span class="p_add">+#include &lt;linux/kasan.h&gt;</span>
 #include &lt;linux/prefetch.h&gt;
 #include &lt;linux/ratelimit.h&gt;
 #include &quot;internal.h&quot;
 #include &quot;mount.h&quot;
 
<span class="p_add">+</span>
 /*
  * Usage:
  * dcache-&gt;d_inode-&gt;i_lock protects:
<span class="p_chunk">@@ -1263,6 +1265,11 @@</span> <span class="p_context"> struct dentry *__d_alloc(struct super_block *sb, const struct qstr *name)</span>
 			kmem_cache_free(dentry_cache, dentry); 
 			return NULL;
 		}
<span class="p_add">+		if (IS_ENABLED(CONFIG_DCACHE_WORD_ACCESS))</span>
<span class="p_add">+			kasan_unpoison_shadow(dname,</span>
<span class="p_add">+					round_up(name-&gt;len + 1,</span>
<span class="p_add">+						sizeof(unsigned long)));</span>
<span class="p_add">+</span>
 	} else  {
 		dname = dentry-&gt;d_iname;
 	}	
<span class="p_header">diff --git a/include/linux/compiler-gcc.h b/include/linux/compiler-gcc.h</span>
<span class="p_header">index 953cd121..082c0ec 100644</span>
<span class="p_header">--- a/include/linux/compiler-gcc.h</span>
<span class="p_header">+++ b/include/linux/compiler-gcc.h</span>
<span class="p_chunk">@@ -66,6 +66,7 @@</span> <span class="p_context"></span>
 #define __deprecated			__attribute__((deprecated))
 #define __packed			__attribute__((packed))
 #define __weak				__attribute__((weak))
<span class="p_add">+#define __alias(symbol)		__attribute__((alias(#symbol)))</span>
 
 /*
  * it doesn&#39;t make sense on ARM (currently the only user of __naked) to trace
<span class="p_header">diff --git a/include/linux/compiler-gcc3.h b/include/linux/compiler-gcc3.h</span>
new file mode 100644
<span class="p_header">index 0000000..e69de29</span>
<span class="p_header">diff --git a/include/linux/init_task.h b/include/linux/init_task.h</span>
<span class="p_header">index 998f4df..b71688b 100644</span>
<span class="p_header">--- a/include/linux/init_task.h</span>
<span class="p_header">+++ b/include/linux/init_task.h</span>
<span class="p_chunk">@@ -155,6 +155,13 @@</span> <span class="p_context"> extern struct task_group root_task_group;</span>
 
 #define INIT_TASK_COMM &quot;swapper&quot;
 
<span class="p_add">+#ifdef CONFIG_KASAN</span>
<span class="p_add">+# define INIT_KASAN(tsk)						\</span>
<span class="p_add">+	.kasan_depth = 1,</span>
<span class="p_add">+#else</span>
<span class="p_add">+# define INIT_KASAN(tsk)</span>
<span class="p_add">+#endif</span>
<span class="p_add">+</span>
 /*
  *  INIT_TASK is used to set up the first task table, touch at
  * your own risk!. Base=0, limit=0x1fffff (=2MB)
<span class="p_chunk">@@ -224,6 +231,7 @@</span> <span class="p_context"> extern struct task_group root_task_group;</span>
 	INIT_TASK_RCU_PREEMPT(tsk)					\
 	INIT_CPUSET_SEQ							\
 	INIT_VTIME(tsk)							\
<span class="p_add">+	INIT_KASAN(tsk)							\</span>
 }
 
 
<span class="p_header">diff --git a/include/linux/kasan-checks.h b/include/linux/kasan-checks.h</span>
new file mode 100644
<span class="p_header">index 0000000..b7f8ace</span>
<span class="p_header">--- /dev/null</span>
<span class="p_header">+++ b/include/linux/kasan-checks.h</span>
<span class="p_chunk">@@ -0,0 +1,12 @@</span> <span class="p_context"></span>
<span class="p_add">+#ifndef _LINUX_KASAN_CHECKS_H</span>
<span class="p_add">+#define _LINUX_KASAN_CHECKS_H</span>
<span class="p_add">+</span>
<span class="p_add">+#ifdef CONFIG_KASAN</span>
<span class="p_add">+void kasan_check_read(const void *p, unsigned int size);</span>
<span class="p_add">+void kasan_check_write(const void *p, unsigned int size);</span>
<span class="p_add">+#else</span>
<span class="p_add">+static inline void kasan_check_read(const void *p, unsigned int size) { }</span>
<span class="p_add">+static inline void kasan_check_write(const void *p, unsigned int size) { }</span>
<span class="p_add">+#endif</span>
<span class="p_add">+</span>
<span class="p_add">+#endif</span>
<span class="p_header">diff --git a/include/linux/kasan.h b/include/linux/kasan.h</span>
new file mode 100644
<span class="p_header">index 0000000..5bb0744</span>
<span class="p_header">--- /dev/null</span>
<span class="p_header">+++ b/include/linux/kasan.h</span>
<span class="p_chunk">@@ -0,0 +1,86 @@</span> <span class="p_context"></span>
<span class="p_add">+#ifndef _LINUX_KASAN_H</span>
<span class="p_add">+#define _LINUX_KASAN_H</span>
<span class="p_add">+</span>
<span class="p_add">+#include &lt;linux/types.h&gt;</span>
<span class="p_add">+</span>
<span class="p_add">+struct kmem_cache;</span>
<span class="p_add">+struct page;</span>
<span class="p_add">+struct vm_struct;</span>
<span class="p_add">+</span>
<span class="p_add">+#ifdef CONFIG_KASAN</span>
<span class="p_add">+</span>
<span class="p_add">+#define KASAN_SHADOW_SCALE_SHIFT 3</span>
<span class="p_add">+#define KASAN_SHADOW_OFFSET _AC(CONFIG_KASAN_SHADOW_OFFSET, UL)</span>
<span class="p_add">+</span>
<span class="p_add">+#include &lt;asm/kasan.h&gt;</span>
<span class="p_add">+#include &lt;linux/sched.h&gt;</span>
<span class="p_add">+</span>
<span class="p_add">+static inline void *kasan_mem_to_shadow(const void *addr)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return (void *)((unsigned long)addr &gt;&gt; KASAN_SHADOW_SCALE_SHIFT)</span>
<span class="p_add">+		+ KASAN_SHADOW_OFFSET;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+/* Enable reporting bugs after kasan_disable_current() */</span>
<span class="p_add">+static inline void kasan_enable_current(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	current-&gt;kasan_depth++;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+/* Disable reporting bugs for current task */</span>
<span class="p_add">+static inline void kasan_disable_current(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	current-&gt;kasan_depth--;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void kasan_unpoison_shadow(const void *address, size_t size);</span>
<span class="p_add">+</span>
<span class="p_add">+void kasan_alloc_pages(struct page *page, unsigned int order);</span>
<span class="p_add">+void kasan_free_pages(struct page *page, unsigned int order);</span>
<span class="p_add">+</span>
<span class="p_add">+void kasan_poison_slab(struct page *page);</span>
<span class="p_add">+void kasan_unpoison_object_data(struct kmem_cache *cache, void *object);</span>
<span class="p_add">+void kasan_poison_object_data(struct kmem_cache *cache, void *object);</span>
<span class="p_add">+</span>
<span class="p_add">+void kasan_kmalloc_large(const void *ptr, size_t size);</span>
<span class="p_add">+void kasan_kfree_large(const void *ptr);</span>
<span class="p_add">+void kasan_kmalloc(struct kmem_cache *s, const void *object, size_t size);</span>
<span class="p_add">+void kasan_krealloc(const void *object, size_t new_size);</span>
<span class="p_add">+</span>
<span class="p_add">+void kasan_slab_alloc(struct kmem_cache *s, void *object);</span>
<span class="p_add">+void kasan_slab_free(struct kmem_cache *s, void *object);</span>
<span class="p_add">+</span>
<span class="p_add">+int kasan_module_alloc(void *addr, size_t size);</span>
<span class="p_add">+void kasan_free_shadow(const struct vm_struct *vm);</span>
<span class="p_add">+</span>
<span class="p_add">+#else /* CONFIG_KASAN */</span>
<span class="p_add">+</span>
<span class="p_add">+static inline void kasan_unpoison_shadow(const void *address, size_t size) {}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline void kasan_enable_current(void) {}</span>
<span class="p_add">+static inline void kasan_disable_current(void) {}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline void kasan_alloc_pages(struct page *page, unsigned int order) {}</span>
<span class="p_add">+static inline void kasan_free_pages(struct page *page, unsigned int order) {}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline void kasan_poison_slab(struct page *page) {}</span>
<span class="p_add">+static inline void kasan_unpoison_object_data(struct kmem_cache *cache,</span>
<span class="p_add">+					void *object) {}</span>
<span class="p_add">+static inline void kasan_poison_object_data(struct kmem_cache *cache,</span>
<span class="p_add">+					void *object) {}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline void kasan_kmalloc_large(void *ptr, size_t size) {}</span>
<span class="p_add">+static inline void kasan_kfree_large(const void *ptr) {}</span>
<span class="p_add">+static inline void kasan_kmalloc(struct kmem_cache *s, const void *object,</span>
<span class="p_add">+				size_t size) {}</span>
<span class="p_add">+static inline void kasan_krealloc(const void *object, size_t new_size) {}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline void kasan_slab_alloc(struct kmem_cache *s, void *object) {}</span>
<span class="p_add">+static inline void kasan_slab_free(struct kmem_cache *s, void *object) {}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline int kasan_module_alloc(void *addr, size_t size) { return 0; }</span>
<span class="p_add">+static inline void kasan_free_shadow(const struct vm_struct *vm) {}</span>
<span class="p_add">+</span>
<span class="p_add">+#endif /* CONFIG_KASAN */</span>
<span class="p_add">+</span>
<span class="p_add">+#endif /* LINUX_KASAN_H */</span>
<span class="p_header">diff --git a/include/linux/module.h b/include/linux/module.h</span>
<span class="p_header">index 761dc28..f0b8750 100644</span>
<span class="p_header">--- a/include/linux/module.h</span>
<span class="p_header">+++ b/include/linux/module.h</span>
<span class="p_chunk">@@ -84,7 +84,7 @@</span> <span class="p_context"> void trim_init_extable(struct module *m);</span>
 
 #ifdef MODULE
 #define MODULE_GENERIC_TABLE(gtype,name)			\
<span class="p_del">-extern const struct gtype##_id __mod_##gtype##_table		\</span>
<span class="p_add">+extern const typeof(name) __mod_##gtype##_table			\</span>
   __attribute__ ((unused, alias(__stringify(name))))
 
 #else  /* !MODULE */
<span class="p_header">diff --git a/include/linux/moduleloader.h b/include/linux/moduleloader.h</span>
<span class="p_header">index 560ca53..8405769 100644</span>
<span class="p_header">--- a/include/linux/moduleloader.h</span>
<span class="p_header">+++ b/include/linux/moduleloader.h</span>
<span class="p_chunk">@@ -80,4 +80,11 @@</span> <span class="p_context"> int module_finalize(const Elf_Ehdr *hdr,</span>
 /* Any cleanup needed when module leaves. */
 void module_arch_cleanup(struct module *mod);
 
<span class="p_add">+#ifdef CONFIG_KASAN</span>
<span class="p_add">+#include &lt;linux/kasan.h&gt;</span>
<span class="p_add">+#define MODULE_ALIGN (PAGE_SIZE &lt;&lt; KASAN_SHADOW_SCALE_SHIFT)</span>
<span class="p_add">+#else</span>
<span class="p_add">+#define MODULE_ALIGN PAGE_SIZE</span>
<span class="p_add">+#endif</span>
<span class="p_add">+</span>
 #endif
<span class="p_header">diff --git a/include/linux/sched.h b/include/linux/sched.h</span>
<span class="p_header">index 4781332..843e99d 100644</span>
<span class="p_header">--- a/include/linux/sched.h</span>
<span class="p_header">+++ b/include/linux/sched.h</span>
<span class="p_chunk">@@ -1383,6 +1383,9 @@</span> <span class="p_context"> struct task_struct {</span>
 	unsigned long timer_slack_ns;
 	unsigned long default_timer_slack_ns;
 
<span class="p_add">+#ifdef CONFIG_KASAN</span>
<span class="p_add">+	unsigned int kasan_depth;</span>
<span class="p_add">+#endif</span>
 #ifdef CONFIG_FUNCTION_GRAPH_TRACER
 	/* Index of current stored address in ret_stack */
 	int curr_ret_stack;
<span class="p_header">diff --git a/include/linux/slub_def.h b/include/linux/slub_def.h</span>
<span class="p_header">index 027276f..d8fde5d 100644</span>
<span class="p_header">--- a/include/linux/slub_def.h</span>
<span class="p_header">+++ b/include/linux/slub_def.h</span>
<span class="p_chunk">@@ -208,4 +208,23 @@</span> <span class="p_context"> static __always_inline void *kmalloc_node(size_t size, gfp_t flags, int node)</span>
 }
 #endif
 
<span class="p_add">+</span>
<span class="p_add">+/**</span>
<span class="p_add">+ * virt_to_obj - returns address of the beginning of object.</span>
<span class="p_add">+ * @s: object&#39;s kmem_cache</span>
<span class="p_add">+ * @slab_page: address of slab page</span>
<span class="p_add">+ * @x: address within object memory range</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * Returns address of the beginning of object</span>
<span class="p_add">+ */</span>
<span class="p_add">+static inline void *virt_to_obj(struct kmem_cache *s,</span>
<span class="p_add">+				const void *slab_page,</span>
<span class="p_add">+				const void *x)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return (void *)x - ((x - slab_page) % s-&gt;size);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void object_err(struct kmem_cache *s, struct page *page,</span>
<span class="p_add">+		u8 *object, char *reason);</span>
<span class="p_add">+</span>
 #endif /* _LINUX_SLUB_DEF_H */
<span class="p_header">diff --git a/include/linux/vmalloc.h b/include/linux/vmalloc.h</span>
<span class="p_header">index 7d5773a..638c673 100644</span>
<span class="p_header">--- a/include/linux/vmalloc.h</span>
<span class="p_header">+++ b/include/linux/vmalloc.h</span>
<span class="p_chunk">@@ -16,6 +16,8 @@</span> <span class="p_context"> struct vm_area_struct;		/* vma defining user mapping in mm_types.h */</span>
 #define VM_USERMAP	0x00000008	/* suitable for remap_vmalloc_range */
 #define VM_VPAGES	0x00000010	/* buffer for pages was vmalloc&#39;ed */
 #define VM_UNLIST	0x00000020	/* vm_struct is not listed in vmlist */
<span class="p_add">+#define VM_NO_GUARD	0x00000040      /* don&#39;t add guard page */</span>
<span class="p_add">+#define VM_KASAN	0x00000080      /* has allocated kasan shadow memory */</span>
 /* bits [20..32] reserved for arch specific ioremap internals */
 
 /*
<span class="p_chunk">@@ -75,7 +77,9 @@</span> <span class="p_context"> extern void *vmalloc_32_user(unsigned long size);</span>
 extern void *__vmalloc(unsigned long size, gfp_t gfp_mask, pgprot_t prot);
 extern void *__vmalloc_node_range(unsigned long size, unsigned long align,
 			unsigned long start, unsigned long end, gfp_t gfp_mask,
<span class="p_del">-			pgprot_t prot, int node, const void *caller);</span>
<span class="p_add">+			pgprot_t prot, unsigned long vm_flags, int node,</span>
<span class="p_add">+			const void *caller);</span>
<span class="p_add">+</span>
 extern void vfree(const void *addr);
 
 extern void *vmap(struct page **pages, unsigned int count,
<span class="p_chunk">@@ -92,8 +96,12 @@</span> <span class="p_context"> void vmalloc_sync_all(void);</span>
 
 static inline size_t get_vm_area_size(const struct vm_struct *area)
 {
<span class="p_del">-	/* return actual size without guard page */</span>
<span class="p_del">-	return area-&gt;size - PAGE_SIZE;</span>
<span class="p_add">+	if (!(area-&gt;flags &amp; VM_NO_GUARD))</span>
<span class="p_add">+		/* return actual size without guard page */</span>
<span class="p_add">+		return area-&gt;size - PAGE_SIZE;</span>
<span class="p_add">+	else</span>
<span class="p_add">+		return area-&gt;size;</span>
<span class="p_add">+</span>
 }
 
 extern struct vm_struct *get_vm_area(unsigned long size, unsigned long flags);
<span class="p_header">diff --git a/lib/Kconfig.debug b/lib/Kconfig.debug</span>
<span class="p_header">index 74fdc5c..818bf1c 100644</span>
<span class="p_header">--- a/lib/Kconfig.debug</span>
<span class="p_header">+++ b/lib/Kconfig.debug</span>
<span class="p_chunk">@@ -1481,6 +1481,8 @@</span> <span class="p_context"> source &quot;lib/Kconfig.kgdb&quot;</span>
 
 source &quot;lib/Kconfig.kmemcheck&quot;
 
<span class="p_add">+source &quot;lib/Kconfig.kasan&quot;</span>
<span class="p_add">+</span>
 config TEST_STRING_HELPERS
 	tristate &quot;Test functions located in the string_helpers module at runtime&quot;
 
<span class="p_header">diff --git a/lib/Kconfig.kasan b/lib/Kconfig.kasan</span>
new file mode 100644
<span class="p_header">index 0000000..4fecaedc</span>
<span class="p_header">--- /dev/null</span>
<span class="p_header">+++ b/lib/Kconfig.kasan</span>
<span class="p_chunk">@@ -0,0 +1,54 @@</span> <span class="p_context"></span>
<span class="p_add">+config HAVE_ARCH_KASAN</span>
<span class="p_add">+	bool</span>
<span class="p_add">+</span>
<span class="p_add">+if HAVE_ARCH_KASAN</span>
<span class="p_add">+</span>
<span class="p_add">+config KASAN</span>
<span class="p_add">+	bool &quot;KASan: runtime memory debugger&quot;</span>
<span class="p_add">+	depends on SLUB_DEBUG</span>
<span class="p_add">+	select CONSTRUCTORS</span>
<span class="p_add">+	help</span>
<span class="p_add">+	  Enables kernel address sanitizer - runtime memory debugger,</span>
<span class="p_add">+	  designed to find out-of-bounds accesses and use-after-free bugs.</span>
<span class="p_add">+	  This is strictly debugging feature. It consumes about 1/8</span>
<span class="p_add">+	  of available memory and brings about ~x3 performance slowdown.</span>
<span class="p_add">+	  For better error detection enable CONFIG_STACKTRACE,</span>
<span class="p_add">+	  and add slub_debug=U to boot cmdline.</span>
<span class="p_add">+</span>
<span class="p_add">+config KASAN_SHADOW_OFFSET</span>
<span class="p_add">+	hex</span>
<span class="p_add">+	default 0xdffffc0000000000 if X86_64</span>
<span class="p_add">+</span>
<span class="p_add">+choice</span>
<span class="p_add">+	prompt &quot;Instrumentation type&quot;</span>
<span class="p_add">+	depends on KASAN</span>
<span class="p_add">+	default KASAN_OUTLINE</span>
<span class="p_add">+</span>
<span class="p_add">+config KASAN_OUTLINE</span>
<span class="p_add">+	bool &quot;Outline instrumentation&quot;</span>
<span class="p_add">+	help</span>
<span class="p_add">+	  Before every memory access compiler insert function call</span>
<span class="p_add">+	  __asan_load*/__asan_store*. These functions performs check</span>
<span class="p_add">+	  of shadow memory. This is slower than inline instrumentation,</span>
<span class="p_add">+	  however it doesn&#39;t bloat size of kernel&#39;s .text section so</span>
<span class="p_add">+	  much as inline does.</span>
<span class="p_add">+</span>
<span class="p_add">+config KASAN_INLINE</span>
<span class="p_add">+	bool &quot;Inline instrumentation&quot;</span>
<span class="p_add">+	help</span>
<span class="p_add">+	  Compiler directly inserts code checking shadow memory before</span>
<span class="p_add">+	  memory accesses. This is faster than outline (in some workloads</span>
<span class="p_add">+	  it gives about x2 boost over outline instrumentation), but</span>
<span class="p_add">+	  make kernel&#39;s .text size much bigger.</span>
<span class="p_add">+</span>
<span class="p_add">+endchoice</span>
<span class="p_add">+</span>
<span class="p_add">+config TEST_KASAN</span>
<span class="p_add">+	tristate &quot;Module for testing kasan for bug detection&quot;</span>
<span class="p_add">+	depends on m &amp;&amp; KASAN</span>
<span class="p_add">+	help</span>
<span class="p_add">+	  This is a test module doing various nasty things like</span>
<span class="p_add">+	  out of bounds accesses, use after free. It is useful for testing</span>
<span class="p_add">+	  kernel debugging features like kernel address sanitizer.</span>
<span class="p_add">+</span>
<span class="p_add">+endif</span>
<span class="p_header">diff --git a/lib/Makefile b/lib/Makefile</span>
<span class="p_header">index 9efe480..8bd332a 100644</span>
<span class="p_header">--- a/lib/Makefile</span>
<span class="p_header">+++ b/lib/Makefile</span>
<span class="p_chunk">@@ -29,6 +29,7 @@</span> <span class="p_context"> obj-y += string_helpers.o</span>
 obj-$(CONFIG_TEST_STRING_HELPERS) += test-string_helpers.o
 obj-y += kstrtox.o
 obj-$(CONFIG_TEST_KSTRTOX) += test-kstrtox.o
<span class="p_add">+obj-$(CONFIG_TEST_KASAN) += test_kasan.o</span>
 
 ifeq ($(CONFIG_DEBUG_KOBJECT),y)
 CFLAGS_kobject.o += -DDEBUG
<span class="p_header">diff --git a/lib/idr.c b/lib/idr.c</span>
<span class="p_header">index a3bfde8..dd06ccb 100644</span>
<span class="p_header">--- a/lib/idr.c</span>
<span class="p_header">+++ b/lib/idr.c</span>
<span class="p_chunk">@@ -618,26 +618,27 @@</span> <span class="p_context"> void __idr_remove_all(struct idr *idp)</span>
 	struct idr_layer **paa = &amp;pa[0];
 
 	n = idp-&gt;layers * IDR_BITS;
<span class="p_del">-	p = idp-&gt;top;</span>
<span class="p_add">+	*paa = idp-&gt;top;</span>
 	rcu_assign_pointer(idp-&gt;top, NULL);
 	max = idr_max(idp-&gt;layers);
 
 	id = 0;
 	while (id &gt;= 0 &amp;&amp; id &lt;= max) {
<span class="p_add">+		p = *paa;</span>
 		while (n &gt; IDR_BITS &amp;&amp; p) {
 			n -= IDR_BITS;
<span class="p_del">-			*paa++ = p;</span>
 			p = p-&gt;ary[(id &gt;&gt; n) &amp; IDR_MASK];
<span class="p_add">+			*++paa = p;</span>
 		}
 
 		bt_mask = id;
 		id += 1 &lt;&lt; n;
 		/* Get the highest bit that the above add changed from 0-&gt;1. */
 		while (n &lt; fls(id ^ bt_mask)) {
<span class="p_del">-			if (p)</span>
<span class="p_del">-				free_layer(idp, p);</span>
<span class="p_add">+			if (*paa)</span>
<span class="p_add">+				free_layer(idp, *paa);</span>
 			n += IDR_BITS;
<span class="p_del">-			p = *--paa;</span>
<span class="p_add">+			--paa;</span>
 		}
 	}
 	idp-&gt;layers = 0;
<span class="p_chunk">@@ -721,15 +722,16 @@</span> <span class="p_context"> int idr_for_each(struct idr *idp,</span>
 	struct idr_layer **paa = &amp;pa[0];
 
 	n = idp-&gt;layers * IDR_BITS;
<span class="p_del">-	p = rcu_dereference_raw(idp-&gt;top);</span>
<span class="p_add">+	*paa = rcu_dereference_raw(idp-&gt;top);</span>
 	max = idr_max(idp-&gt;layers);
 
 	id = 0;
 	while (id &gt;= 0 &amp;&amp; id &lt;= max) {
<span class="p_add">+		p = *paa;</span>
 		while (n &gt; 0 &amp;&amp; p) {
 			n -= IDR_BITS;
<span class="p_del">-			*paa++ = p;</span>
 			p = rcu_dereference_raw(p-&gt;ary[(id &gt;&gt; n) &amp; IDR_MASK]);
<span class="p_add">+			*++paa = p;</span>
 		}
 
 		if (p) {
<span class="p_chunk">@@ -741,7 +743,7 @@</span> <span class="p_context"> int idr_for_each(struct idr *idp,</span>
 		id += 1 &lt;&lt; n;
 		while (n &lt; fls(id)) {
 			n += IDR_BITS;
<span class="p_del">-			p = *--paa;</span>
<span class="p_add">+			--paa;</span>
 		}
 	}
 
<span class="p_chunk">@@ -769,17 +771,18 @@</span> <span class="p_context"> void *idr_get_next(struct idr *idp, int *nextidp)</span>
 	int n, max;
 
 	/* find first ent */
<span class="p_del">-	p = rcu_dereference_raw(idp-&gt;top);</span>
<span class="p_add">+	p = *paa = rcu_dereference_raw(idp-&gt;top);</span>
 	if (!p)
 		return NULL;
 	n = (p-&gt;layer + 1) * IDR_BITS;
 	max = idr_max(p-&gt;layer + 1);
 
 	while (id &gt;= 0 &amp;&amp; id &lt;= max) {
<span class="p_add">+		p = *paa;</span>
 		while (n &gt; 0 &amp;&amp; p) {
 			n -= IDR_BITS;
<span class="p_del">-			*paa++ = p;</span>
 			p = rcu_dereference_raw(p-&gt;ary[(id &gt;&gt; n) &amp; IDR_MASK]);
<span class="p_add">+			*++paa = p;</span>
 		}
 
 		if (p) {
<span class="p_chunk">@@ -797,7 +800,7 @@</span> <span class="p_context"> void *idr_get_next(struct idr *idp, int *nextidp)</span>
 		id = round_up(id + 1, 1 &lt;&lt; n);
 		while (n &lt; fls(id)) {
 			n += IDR_BITS;
<span class="p_del">-			p = *--paa;</span>
<span class="p_add">+			--paa;</span>
 		}
 	}
 	return NULL;
<span class="p_header">diff --git a/lib/strncpy_from_user.c b/lib/strncpy_from_user.c</span>
<span class="p_header">index bb2b201..b5e2ad8 100644</span>
<span class="p_header">--- a/lib/strncpy_from_user.c</span>
<span class="p_header">+++ b/lib/strncpy_from_user.c</span>
<span class="p_chunk">@@ -1,5 +1,6 @@</span> <span class="p_context"></span>
 #include &lt;linux/module.h&gt;
 #include &lt;linux/uaccess.h&gt;
<span class="p_add">+#include &lt;linux/kasan-checks.h&gt;</span>
 #include &lt;linux/kernel.h&gt;
 #include &lt;linux/errno.h&gt;
 
<span class="p_chunk">@@ -106,6 +107,7 @@</span> <span class="p_context"> long strncpy_from_user(char *dst, const char __user *src, long count)</span>
 	src_addr = (unsigned long)src;
 	if (likely(src_addr &lt; max_addr)) {
 		unsigned long max = max_addr - src_addr;
<span class="p_add">+		kasan_check_write(dst, count);</span>
 		return do_strncpy_from_user(dst, src, count, max);
 	}
 	return -EFAULT;
<span class="p_header">diff --git a/lib/test_kasan.c b/lib/test_kasan.c</span>
new file mode 100644
<span class="p_header">index 0000000..1740caf</span>
<span class="p_header">--- /dev/null</span>
<span class="p_header">+++ b/lib/test_kasan.c</span>
<span class="p_chunk">@@ -0,0 +1,277 @@</span> <span class="p_context"></span>
<span class="p_add">+/*</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * Copyright (c) 2014 Samsung Electronics Co., Ltd.</span>
<span class="p_add">+ * Author: Andrey Ryabinin &lt;a.ryabinin at samsung.com&gt;</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * This program is free software; you can redistribute it and/or modify</span>
<span class="p_add">+ * it under the terms of the GNU General Public License version 2 as</span>
<span class="p_add">+ * published by the Free Software Foundation.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ */</span>
<span class="p_add">+</span>
<span class="p_add">+#define pr_fmt(fmt) &quot;kasan test: %s &quot; fmt, __func__</span>
<span class="p_add">+</span>
<span class="p_add">+#include &lt;linux/kernel.h&gt;</span>
<span class="p_add">+#include &lt;linux/printk.h&gt;</span>
<span class="p_add">+#include &lt;linux/slab.h&gt;</span>
<span class="p_add">+#include &lt;linux/string.h&gt;</span>
<span class="p_add">+#include &lt;linux/module.h&gt;</span>
<span class="p_add">+</span>
<span class="p_add">+static noinline void __init kmalloc_oob_right(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	char *ptr;</span>
<span class="p_add">+	size_t size = 123;</span>
<span class="p_add">+</span>
<span class="p_add">+	pr_info(&quot;out-of-bounds to right\n&quot;);</span>
<span class="p_add">+	ptr = kmalloc(size, GFP_KERNEL);</span>
<span class="p_add">+	if (!ptr) {</span>
<span class="p_add">+		pr_err(&quot;Allocation failed\n&quot;);</span>
<span class="p_add">+		return;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	ptr[size] = &#39;x&#39;;</span>
<span class="p_add">+	kfree(ptr);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static noinline void __init kmalloc_oob_left(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	char *ptr;</span>
<span class="p_add">+	size_t size = 15;</span>
<span class="p_add">+</span>
<span class="p_add">+	pr_info(&quot;out-of-bounds to left\n&quot;);</span>
<span class="p_add">+	ptr = kmalloc(size, GFP_KERNEL);</span>
<span class="p_add">+	if (!ptr) {</span>
<span class="p_add">+		pr_err(&quot;Allocation failed\n&quot;);</span>
<span class="p_add">+		return;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	*ptr = *(ptr - 1);</span>
<span class="p_add">+	kfree(ptr);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static noinline void __init kmalloc_node_oob_right(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	char *ptr;</span>
<span class="p_add">+	size_t size = 4096;</span>
<span class="p_add">+</span>
<span class="p_add">+	pr_info(&quot;kmalloc_node(): out-of-bounds to right\n&quot;);</span>
<span class="p_add">+	ptr = kmalloc_node(size, GFP_KERNEL, 0);</span>
<span class="p_add">+	if (!ptr) {</span>
<span class="p_add">+		pr_err(&quot;Allocation failed\n&quot;);</span>
<span class="p_add">+		return;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	ptr[size] = 0;</span>
<span class="p_add">+	kfree(ptr);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static noinline void __init kmalloc_large_oob_rigth(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	char *ptr;</span>
<span class="p_add">+	size_t size = KMALLOC_MAX_CACHE_SIZE + 10;</span>
<span class="p_add">+</span>
<span class="p_add">+	pr_info(&quot;kmalloc large allocation: out-of-bounds to right\n&quot;);</span>
<span class="p_add">+	ptr = kmalloc(size, GFP_KERNEL);</span>
<span class="p_add">+	if (!ptr) {</span>
<span class="p_add">+		pr_err(&quot;Allocation failed\n&quot;);</span>
<span class="p_add">+		return;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	ptr[size] = 0;</span>
<span class="p_add">+	kfree(ptr);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static noinline void __init kmalloc_oob_krealloc_more(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	char *ptr1, *ptr2;</span>
<span class="p_add">+	size_t size1 = 17;</span>
<span class="p_add">+	size_t size2 = 19;</span>
<span class="p_add">+</span>
<span class="p_add">+	pr_info(&quot;out-of-bounds after krealloc more\n&quot;);</span>
<span class="p_add">+	ptr1 = kmalloc(size1, GFP_KERNEL);</span>
<span class="p_add">+	ptr2 = krealloc(ptr1, size2, GFP_KERNEL);</span>
<span class="p_add">+	if (!ptr1 || !ptr2) {</span>
<span class="p_add">+		pr_err(&quot;Allocation failed\n&quot;);</span>
<span class="p_add">+		kfree(ptr1);</span>
<span class="p_add">+		return;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	ptr2[size2] = &#39;x&#39;;</span>
<span class="p_add">+	kfree(ptr2);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static noinline void __init kmalloc_oob_krealloc_less(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	char *ptr1, *ptr2;</span>
<span class="p_add">+	size_t size1 = 17;</span>
<span class="p_add">+	size_t size2 = 15;</span>
<span class="p_add">+</span>
<span class="p_add">+	pr_info(&quot;out-of-bounds after krealloc less\n&quot;);</span>
<span class="p_add">+	ptr1 = kmalloc(size1, GFP_KERNEL);</span>
<span class="p_add">+	ptr2 = krealloc(ptr1, size2, GFP_KERNEL);</span>
<span class="p_add">+	if (!ptr1 || !ptr2) {</span>
<span class="p_add">+		pr_err(&quot;Allocation failed\n&quot;);</span>
<span class="p_add">+		kfree(ptr1);</span>
<span class="p_add">+		return;</span>
<span class="p_add">+	}</span>
<span class="p_add">+	ptr2[size1] = &#39;x&#39;;</span>
<span class="p_add">+	kfree(ptr2);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static noinline void __init kmalloc_oob_16(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct {</span>
<span class="p_add">+		u64 words[2];</span>
<span class="p_add">+	} *ptr1, *ptr2;</span>
<span class="p_add">+</span>
<span class="p_add">+	pr_info(&quot;kmalloc out-of-bounds for 16-bytes access\n&quot;);</span>
<span class="p_add">+	ptr1 = kmalloc(sizeof(*ptr1) - 3, GFP_KERNEL);</span>
<span class="p_add">+	ptr2 = kmalloc(sizeof(*ptr2), GFP_KERNEL);</span>
<span class="p_add">+	if (!ptr1 || !ptr2) {</span>
<span class="p_add">+		pr_err(&quot;Allocation failed\n&quot;);</span>
<span class="p_add">+		kfree(ptr1);</span>
<span class="p_add">+		kfree(ptr2);</span>
<span class="p_add">+		return;</span>
<span class="p_add">+	}</span>
<span class="p_add">+	*ptr1 = *ptr2;</span>
<span class="p_add">+	kfree(ptr1);</span>
<span class="p_add">+	kfree(ptr2);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static noinline void __init kmalloc_oob_in_memset(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	char *ptr;</span>
<span class="p_add">+	size_t size = 666;</span>
<span class="p_add">+</span>
<span class="p_add">+	pr_info(&quot;out-of-bounds in memset\n&quot;);</span>
<span class="p_add">+	ptr = kmalloc(size, GFP_KERNEL);</span>
<span class="p_add">+	if (!ptr) {</span>
<span class="p_add">+		pr_err(&quot;Allocation failed\n&quot;);</span>
<span class="p_add">+		return;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	memset(ptr, 0, size+5);</span>
<span class="p_add">+	kfree(ptr);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static noinline void __init kmalloc_uaf(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	char *ptr;</span>
<span class="p_add">+	size_t size = 10;</span>
<span class="p_add">+</span>
<span class="p_add">+	pr_info(&quot;use-after-free\n&quot;);</span>
<span class="p_add">+	ptr = kmalloc(size, GFP_KERNEL);</span>
<span class="p_add">+	if (!ptr) {</span>
<span class="p_add">+		pr_err(&quot;Allocation failed\n&quot;);</span>
<span class="p_add">+		return;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	kfree(ptr);</span>
<span class="p_add">+	*(ptr + 8) = &#39;x&#39;;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static noinline void __init kmalloc_uaf_memset(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	char *ptr;</span>
<span class="p_add">+	size_t size = 33;</span>
<span class="p_add">+</span>
<span class="p_add">+	pr_info(&quot;use-after-free in memset\n&quot;);</span>
<span class="p_add">+	ptr = kmalloc(size, GFP_KERNEL);</span>
<span class="p_add">+	if (!ptr) {</span>
<span class="p_add">+		pr_err(&quot;Allocation failed\n&quot;);</span>
<span class="p_add">+		return;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	kfree(ptr);</span>
<span class="p_add">+	memset(ptr, 0, size);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static noinline void __init kmalloc_uaf2(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	char *ptr1, *ptr2;</span>
<span class="p_add">+	size_t size = 43;</span>
<span class="p_add">+</span>
<span class="p_add">+	pr_info(&quot;use-after-free after another kmalloc\n&quot;);</span>
<span class="p_add">+	ptr1 = kmalloc(size, GFP_KERNEL);</span>
<span class="p_add">+	if (!ptr1) {</span>
<span class="p_add">+		pr_err(&quot;Allocation failed\n&quot;);</span>
<span class="p_add">+		return;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	kfree(ptr1);</span>
<span class="p_add">+	ptr2 = kmalloc(size, GFP_KERNEL);</span>
<span class="p_add">+	if (!ptr2) {</span>
<span class="p_add">+		pr_err(&quot;Allocation failed\n&quot;);</span>
<span class="p_add">+		return;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	ptr1[40] = &#39;x&#39;;</span>
<span class="p_add">+	kfree(ptr2);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static noinline void __init kmem_cache_oob(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	char *p;</span>
<span class="p_add">+	size_t size = 200;</span>
<span class="p_add">+	struct kmem_cache *cache = kmem_cache_create(&quot;test_cache&quot;,</span>
<span class="p_add">+						size, 0,</span>
<span class="p_add">+						0, NULL);</span>
<span class="p_add">+	if (!cache) {</span>
<span class="p_add">+		pr_err(&quot;Cache allocation failed\n&quot;);</span>
<span class="p_add">+		return;</span>
<span class="p_add">+	}</span>
<span class="p_add">+	pr_info(&quot;out-of-bounds in kmem_cache_alloc\n&quot;);</span>
<span class="p_add">+	p = kmem_cache_alloc(cache, GFP_KERNEL);</span>
<span class="p_add">+	if (!p) {</span>
<span class="p_add">+		pr_err(&quot;Allocation failed\n&quot;);</span>
<span class="p_add">+		kmem_cache_destroy(cache);</span>
<span class="p_add">+		return;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	*p = p[size];</span>
<span class="p_add">+	kmem_cache_free(cache, p);</span>
<span class="p_add">+	kmem_cache_destroy(cache);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static char global_array[10];</span>
<span class="p_add">+</span>
<span class="p_add">+static noinline void __init kasan_global_oob(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	volatile int i = 3;</span>
<span class="p_add">+	char *p = &amp;global_array[ARRAY_SIZE(global_array) + i];</span>
<span class="p_add">+</span>
<span class="p_add">+	pr_info(&quot;out-of-bounds global variable\n&quot;);</span>
<span class="p_add">+	*(volatile char *)p;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static noinline void __init kasan_stack_oob(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	char stack_array[10];</span>
<span class="p_add">+	volatile int i = 0;</span>
<span class="p_add">+	char *p = &amp;stack_array[ARRAY_SIZE(stack_array) + i];</span>
<span class="p_add">+</span>
<span class="p_add">+	pr_info(&quot;out-of-bounds on stack\n&quot;);</span>
<span class="p_add">+	*(volatile char *)p;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static int __init kmalloc_tests_init(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	kmalloc_oob_right();</span>
<span class="p_add">+	kmalloc_oob_left();</span>
<span class="p_add">+	kmalloc_node_oob_right();</span>
<span class="p_add">+	kmalloc_large_oob_rigth();</span>
<span class="p_add">+	kmalloc_oob_krealloc_more();</span>
<span class="p_add">+	kmalloc_oob_krealloc_less();</span>
<span class="p_add">+	kmalloc_oob_16();</span>
<span class="p_add">+	kmalloc_oob_in_memset();</span>
<span class="p_add">+	kmalloc_uaf();</span>
<span class="p_add">+	kmalloc_uaf_memset();</span>
<span class="p_add">+	kmalloc_uaf2();</span>
<span class="p_add">+	kmem_cache_oob();</span>
<span class="p_add">+	kasan_stack_oob();</span>
<span class="p_add">+	kasan_global_oob();</span>
<span class="p_add">+	return -EAGAIN;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+module_init(kmalloc_tests_init);</span>
<span class="p_add">+MODULE_LICENSE(&quot;GPL&quot;);</span>
<span class="p_header">diff --git a/mm/Makefile b/mm/Makefile</span>
<span class="p_header">index 72c5acb..a4c706a 100644</span>
<span class="p_header">--- a/mm/Makefile</span>
<span class="p_header">+++ b/mm/Makefile</span>
<span class="p_chunk">@@ -2,6 +2,9 @@</span> <span class="p_context"></span>
 # Makefile for the linux memory manager.
 #
 
<span class="p_add">+KASAN_SANITIZE_slab_common.o := n</span>
<span class="p_add">+KASAN_SANITIZE_slub.o := n</span>
<span class="p_add">+</span>
 mmu-y			:= nommu.o
 mmu-$(CONFIG_MMU)	:= fremap.o highmem.o madvise.o memory.o mincore.o \
 			   mlock.o mmap.o mprotect.o mremap.o msync.o rmap.o \
<span class="p_chunk">@@ -44,6 +47,7 @@</span> <span class="p_context"> obj-$(CONFIG_PAGE_POISONING) += debug-pagealloc.o</span>
 obj-$(CONFIG_SLAB) += slab.o
 obj-$(CONFIG_SLUB) += slub.o
 obj-$(CONFIG_KMEMCHECK) += kmemcheck.o
<span class="p_add">+obj-$(CONFIG_KASAN)	+= kasan/</span>
 obj-$(CONFIG_FAILSLAB) += failslab.o
 obj-$(CONFIG_MEMORY_HOTPLUG) += memory_hotplug.o
 obj-$(CONFIG_FS_XIP) += filemap_xip.o
<span class="p_header">diff --git a/mm/compaction.c b/mm/compaction.c</span>
<span class="p_header">index eeaaa92..ea4a300 100644</span>
<span class="p_header">--- a/mm/compaction.c</span>
<span class="p_header">+++ b/mm/compaction.c</span>
<span class="p_chunk">@@ -16,6 +16,7 @@</span> <span class="p_context"></span>
 #include &lt;linux/sysfs.h&gt;
 #include &lt;linux/balloon_compaction.h&gt;
 #include &lt;linux/page-isolation.h&gt;
<span class="p_add">+#include &lt;linux/kasan.h&gt;</span>
 #include &quot;internal.h&quot;
 
 #ifdef CONFIG_COMPACTION
<span class="p_chunk">@@ -59,6 +60,7 @@</span> <span class="p_context"> static void map_pages(struct list_head *list)</span>
 	list_for_each_entry(page, list, lru) {
 		arch_alloc_page(page, 0);
 		kernel_map_pages(page, 1, 1);
<span class="p_add">+		kasan_alloc_pages(page, 0);</span>
 	}
 }
 
<span class="p_header">diff --git a/mm/kasan/Makefile b/mm/kasan/Makefile</span>
new file mode 100644
<span class="p_header">index 0000000..bd837b8</span>
<span class="p_header">--- /dev/null</span>
<span class="p_header">+++ b/mm/kasan/Makefile</span>
<span class="p_chunk">@@ -0,0 +1,8 @@</span> <span class="p_context"></span>
<span class="p_add">+KASAN_SANITIZE := n</span>
<span class="p_add">+</span>
<span class="p_add">+CFLAGS_REMOVE_kasan.o = -pg</span>
<span class="p_add">+# Function splitter causes unnecessary splits in __asan_load1/__asan_store1</span>
<span class="p_add">+# see: https://gcc.gnu.org/bugzilla/show_bug.cgi?id=63533</span>
<span class="p_add">+CFLAGS_kasan.o := $(call cc-option, -fno-conserve-stack -fno-stack-protector)</span>
<span class="p_add">+</span>
<span class="p_add">+obj-y := kasan.o report.o</span>
<span class="p_header">diff --git a/mm/kasan/kasan.c b/mm/kasan/kasan.c</span>
new file mode 100644
<span class="p_header">index 0000000..a9f91cc</span>
<span class="p_header">--- /dev/null</span>
<span class="p_header">+++ b/mm/kasan/kasan.c</span>
<span class="p_chunk">@@ -0,0 +1,532 @@</span> <span class="p_context"></span>
<span class="p_add">+/*</span>
<span class="p_add">+ * This file contains shadow memory manipulation code.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * Copyright (c) 2014 Samsung Electronics Co., Ltd.</span>
<span class="p_add">+ * Author: Andrey Ryabinin &lt;a.ryabinin at samsung.com&gt;</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * Some of code borrowed from https://github.com/xairy/linux by</span>
<span class="p_add">+ *        Andrey Konovalov &lt;adech.fo at gmail.com&gt;</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * This program is free software; you can redistribute it and/or modify</span>
<span class="p_add">+ * it under the terms of the GNU General Public License version 2 as</span>
<span class="p_add">+ * published by the Free Software Foundation.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ */</span>
<span class="p_add">+</span>
<span class="p_add">+#define pr_fmt(fmt) KBUILD_MODNAME &quot;: &quot; fmt</span>
<span class="p_add">+#define DISABLE_BRANCH_PROFILING</span>
<span class="p_add">+</span>
<span class="p_add">+#include &lt;linux/export.h&gt;</span>
<span class="p_add">+#include &lt;linux/init.h&gt;</span>
<span class="p_add">+#include &lt;linux/kernel.h&gt;</span>
<span class="p_add">+#include &lt;linux/memblock.h&gt;</span>
<span class="p_add">+#include &lt;linux/memory.h&gt;</span>
<span class="p_add">+#include &lt;linux/mm.h&gt;</span>
<span class="p_add">+#include &lt;linux/module.h&gt;</span>
<span class="p_add">+#include &lt;linux/printk.h&gt;</span>
<span class="p_add">+#include &lt;linux/sched.h&gt;</span>
<span class="p_add">+#include &lt;linux/slab.h&gt;</span>
<span class="p_add">+#include &lt;linux/stacktrace.h&gt;</span>
<span class="p_add">+#include &lt;linux/string.h&gt;</span>
<span class="p_add">+#include &lt;linux/types.h&gt;</span>
<span class="p_add">+#include &lt;linux/vmalloc.h&gt;</span>
<span class="p_add">+#include &lt;linux/kasan.h&gt;</span>
<span class="p_add">+</span>
<span class="p_add">+#include &quot;kasan.h&quot;</span>
<span class="p_add">+#include &quot;../slab.h&quot;</span>
<span class="p_add">+</span>
<span class="p_add">+/*</span>
<span class="p_add">+ * Poisons the shadow memory for &#39;size&#39; bytes starting from &#39;addr&#39;.</span>
<span class="p_add">+ * Memory addresses should be aligned to KASAN_SHADOW_SCALE_SIZE.</span>
<span class="p_add">+ */</span>
<span class="p_add">+static void kasan_poison_shadow(const void *address, size_t size, u8 value)</span>
<span class="p_add">+{</span>
<span class="p_add">+	void *shadow_start, *shadow_end;</span>
<span class="p_add">+</span>
<span class="p_add">+	shadow_start = kasan_mem_to_shadow(address);</span>
<span class="p_add">+	shadow_end = kasan_mem_to_shadow(address + size);</span>
<span class="p_add">+</span>
<span class="p_add">+	memset(shadow_start, value, shadow_end - shadow_start);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void kasan_unpoison_shadow(const void *address, size_t size)</span>
<span class="p_add">+{</span>
<span class="p_add">+	kasan_poison_shadow(address, size, 0);</span>
<span class="p_add">+</span>
<span class="p_add">+	if (size &amp; KASAN_SHADOW_MASK) {</span>
<span class="p_add">+		u8 *shadow = (u8 *)kasan_mem_to_shadow(address + size);</span>
<span class="p_add">+		*shadow = size &amp; KASAN_SHADOW_MASK;</span>
<span class="p_add">+	}</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+</span>
<span class="p_add">+/*</span>
<span class="p_add">+ * All functions below always inlined so compiler could</span>
<span class="p_add">+ * perform better optimizations in each of __asan_loadX/__assn_storeX</span>
<span class="p_add">+ * depending on memory access size X.</span>
<span class="p_add">+ */</span>
<span class="p_add">+</span>
<span class="p_add">+static __always_inline bool memory_is_poisoned_1(unsigned long addr)</span>
<span class="p_add">+{</span>
<span class="p_add">+	s8 shadow_value = *(s8 *)kasan_mem_to_shadow((void *)addr);</span>
<span class="p_add">+</span>
<span class="p_add">+	if (unlikely(shadow_value)) {</span>
<span class="p_add">+		s8 last_accessible_byte = addr &amp; KASAN_SHADOW_MASK;</span>
<span class="p_add">+		return unlikely(last_accessible_byte &gt;= shadow_value);</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	return false;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static __always_inline bool memory_is_poisoned_2(unsigned long addr)</span>
<span class="p_add">+{</span>
<span class="p_add">+	u16 *shadow_addr = (u16 *)kasan_mem_to_shadow((void *)addr);</span>
<span class="p_add">+</span>
<span class="p_add">+	if (unlikely(*shadow_addr)) {</span>
<span class="p_add">+		if (memory_is_poisoned_1(addr + 1))</span>
<span class="p_add">+			return true;</span>
<span class="p_add">+</span>
<span class="p_add">+		if (likely(((addr + 1) &amp; KASAN_SHADOW_MASK) != 0))</span>
<span class="p_add">+			return false;</span>
<span class="p_add">+</span>
<span class="p_add">+		return unlikely(*(u8 *)shadow_addr);</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	return false;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static __always_inline bool memory_is_poisoned_4(unsigned long addr)</span>
<span class="p_add">+{</span>
<span class="p_add">+	u16 *shadow_addr = (u16 *)kasan_mem_to_shadow((void *)addr);</span>
<span class="p_add">+</span>
<span class="p_add">+	if (unlikely(*shadow_addr)) {</span>
<span class="p_add">+		if (memory_is_poisoned_1(addr + 3))</span>
<span class="p_add">+			return true;</span>
<span class="p_add">+</span>
<span class="p_add">+		if (likely(((addr + 3) &amp; KASAN_SHADOW_MASK) &gt;= 3))</span>
<span class="p_add">+			return false;</span>
<span class="p_add">+</span>
<span class="p_add">+		return unlikely(*(u8 *)shadow_addr);</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	return false;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static __always_inline bool memory_is_poisoned_8(unsigned long addr)</span>
<span class="p_add">+{</span>
<span class="p_add">+	u16 *shadow_addr = (u16 *)kasan_mem_to_shadow((void *)addr);</span>
<span class="p_add">+</span>
<span class="p_add">+	if (unlikely(*shadow_addr)) {</span>
<span class="p_add">+		if (memory_is_poisoned_1(addr + 7))</span>
<span class="p_add">+			return true;</span>
<span class="p_add">+</span>
<span class="p_add">+		if (likely(((addr + 7) &amp; KASAN_SHADOW_MASK) &gt;= 7))</span>
<span class="p_add">+			return false;</span>
<span class="p_add">+</span>
<span class="p_add">+		return unlikely(*(u8 *)shadow_addr);</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	return false;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static __always_inline bool memory_is_poisoned_16(unsigned long addr)</span>
<span class="p_add">+{</span>
<span class="p_add">+	u32 *shadow_addr = (u32 *)kasan_mem_to_shadow((void *)addr);</span>
<span class="p_add">+</span>
<span class="p_add">+	if (unlikely(*shadow_addr)) {</span>
<span class="p_add">+		u16 shadow_first_bytes = *(u16 *)shadow_addr;</span>
<span class="p_add">+		s8 last_byte = (addr + 15) &amp; KASAN_SHADOW_MASK;</span>
<span class="p_add">+</span>
<span class="p_add">+		if (unlikely(shadow_first_bytes))</span>
<span class="p_add">+			return true;</span>
<span class="p_add">+</span>
<span class="p_add">+		if (likely(!last_byte))</span>
<span class="p_add">+			return false;</span>
<span class="p_add">+</span>
<span class="p_add">+		return memory_is_poisoned_1(addr + 15);</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	return false;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static __always_inline unsigned long bytes_is_zero(const u8 *start,</span>
<span class="p_add">+					size_t size)</span>
<span class="p_add">+{</span>
<span class="p_add">+	while (size) {</span>
<span class="p_add">+		if (unlikely(*start))</span>
<span class="p_add">+			return (unsigned long)start;</span>
<span class="p_add">+		start++;</span>
<span class="p_add">+		size--;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	return 0;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static __always_inline unsigned long memory_is_zero(const void *start,</span>
<span class="p_add">+						const void *end)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned int words;</span>
<span class="p_add">+	unsigned long ret;</span>
<span class="p_add">+	unsigned int prefix = (unsigned long)start % 8;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (end - start &lt;= 16)</span>
<span class="p_add">+		return bytes_is_zero(start, end - start);</span>
<span class="p_add">+</span>
<span class="p_add">+	if (prefix) {</span>
<span class="p_add">+		prefix = 8 - prefix;</span>
<span class="p_add">+		ret = bytes_is_zero(start, prefix);</span>
<span class="p_add">+		if (unlikely(ret))</span>
<span class="p_add">+			return ret;</span>
<span class="p_add">+		start += prefix;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	words = (end - start) / 8;</span>
<span class="p_add">+	while (words) {</span>
<span class="p_add">+		if (unlikely(*(u64 *)start))</span>
<span class="p_add">+			return bytes_is_zero(start, 8);</span>
<span class="p_add">+		start += 8;</span>
<span class="p_add">+		words--;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	return bytes_is_zero(start, (end - start) % 8);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static __always_inline bool memory_is_poisoned_n(unsigned long addr,</span>
<span class="p_add">+						size_t size)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long ret;</span>
<span class="p_add">+</span>
<span class="p_add">+	ret = memory_is_zero(kasan_mem_to_shadow((void *)addr),</span>
<span class="p_add">+			kasan_mem_to_shadow((void *)addr + size - 1) + 1);</span>
<span class="p_add">+</span>
<span class="p_add">+	if (unlikely(ret)) {</span>
<span class="p_add">+		unsigned long last_byte = addr + size - 1;</span>
<span class="p_add">+		s8 *last_shadow = (s8 *)kasan_mem_to_shadow((void *)last_byte);</span>
<span class="p_add">+</span>
<span class="p_add">+		if (unlikely(ret != (unsigned long)last_shadow ||</span>
<span class="p_add">+			((last_byte &amp; KASAN_SHADOW_MASK) &gt;= *last_shadow)))</span>
<span class="p_add">+			return true;</span>
<span class="p_add">+	}</span>
<span class="p_add">+	return false;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static __always_inline bool memory_is_poisoned(unsigned long addr, size_t size)</span>
<span class="p_add">+{</span>
<span class="p_add">+	if (__builtin_constant_p(size)) {</span>
<span class="p_add">+		switch (size) {</span>
<span class="p_add">+		case 1:</span>
<span class="p_add">+			return memory_is_poisoned_1(addr);</span>
<span class="p_add">+		case 2:</span>
<span class="p_add">+			return memory_is_poisoned_2(addr);</span>
<span class="p_add">+		case 4:</span>
<span class="p_add">+			return memory_is_poisoned_4(addr);</span>
<span class="p_add">+		case 8:</span>
<span class="p_add">+			return memory_is_poisoned_8(addr);</span>
<span class="p_add">+		case 16:</span>
<span class="p_add">+			return memory_is_poisoned_16(addr);</span>
<span class="p_add">+		default:</span>
<span class="p_add">+			BUILD_BUG();</span>
<span class="p_add">+		}</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	return memory_is_poisoned_n(addr, size);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static __always_inline void check_memory_region_inline(unsigned long addr,</span>
<span class="p_add">+						size_t size, bool write,</span>
<span class="p_add">+						unsigned long ret_ip)</span>
<span class="p_add">+{</span>
<span class="p_add">+	if (unlikely(size == 0))</span>
<span class="p_add">+		return;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (unlikely((void *)addr &lt;</span>
<span class="p_add">+		kasan_shadow_to_mem((void *)KASAN_SHADOW_START))) {</span>
<span class="p_add">+		kasan_report(addr, size, write, ret_ip);</span>
<span class="p_add">+		return;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	if (likely(!memory_is_poisoned(addr, size)))</span>
<span class="p_add">+		return;</span>
<span class="p_add">+</span>
<span class="p_add">+	kasan_report(addr, size, write, ret_ip);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static void check_memory_region(unsigned long addr,</span>
<span class="p_add">+				size_t size, bool write,</span>
<span class="p_add">+				unsigned long ret_ip)</span>
<span class="p_add">+{</span>
<span class="p_add">+	check_memory_region_inline(addr, size, write, ret_ip);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void kasan_check_read(const void *p, unsigned int size)</span>
<span class="p_add">+{</span>
<span class="p_add">+	check_memory_region((unsigned long)p, size, false, _RET_IP_);</span>
<span class="p_add">+}</span>
<span class="p_add">+EXPORT_SYMBOL(kasan_check_read);</span>
<span class="p_add">+</span>
<span class="p_add">+void kasan_check_write(const void *p, unsigned int size)</span>
<span class="p_add">+{</span>
<span class="p_add">+	check_memory_region((unsigned long)p, size, true, _RET_IP_);</span>
<span class="p_add">+}</span>
<span class="p_add">+EXPORT_SYMBOL(kasan_check_write);</span>
<span class="p_add">+</span>
<span class="p_add">+#undef memset</span>
<span class="p_add">+void *memset(void *addr, int c, size_t len)</span>
<span class="p_add">+{</span>
<span class="p_add">+	check_memory_region((unsigned long)addr, len, true, _RET_IP_);</span>
<span class="p_add">+</span>
<span class="p_add">+	return __memset(addr, c, len);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+#undef memmove</span>
<span class="p_add">+void *memmove(void *dest, const void *src, size_t len)</span>
<span class="p_add">+{</span>
<span class="p_add">+	check_memory_region((unsigned long)src, len, false, _RET_IP_);</span>
<span class="p_add">+	check_memory_region((unsigned long)dest, len, true, _RET_IP_);</span>
<span class="p_add">+</span>
<span class="p_add">+	return __memmove(dest, src, len);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+#undef memcpy</span>
<span class="p_add">+void *memcpy(void *dest, const void *src, size_t len)</span>
<span class="p_add">+{</span>
<span class="p_add">+	check_memory_region((unsigned long)src, len, false, _RET_IP_);</span>
<span class="p_add">+	check_memory_region((unsigned long)dest, len, true, _RET_IP_);</span>
<span class="p_add">+</span>
<span class="p_add">+	return __memcpy(dest, src, len);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void kasan_alloc_pages(struct page *page, unsigned int order)</span>
<span class="p_add">+{</span>
<span class="p_add">+	if (likely(!PageHighMem(page)))</span>
<span class="p_add">+		kasan_unpoison_shadow(page_address(page), PAGE_SIZE &lt;&lt; order);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void kasan_free_pages(struct page *page, unsigned int order)</span>
<span class="p_add">+{</span>
<span class="p_add">+	if (likely(!PageHighMem(page)))</span>
<span class="p_add">+		kasan_poison_shadow(page_address(page),</span>
<span class="p_add">+				PAGE_SIZE &lt;&lt; order,</span>
<span class="p_add">+				KASAN_FREE_PAGE);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void kasan_poison_slab(struct page *page)</span>
<span class="p_add">+{</span>
<span class="p_add">+	kasan_poison_shadow(page_address(page),</span>
<span class="p_add">+			PAGE_SIZE &lt;&lt; compound_order(page),</span>
<span class="p_add">+			KASAN_KMALLOC_REDZONE);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void kasan_unpoison_object_data(struct kmem_cache *cache, void *object)</span>
<span class="p_add">+{</span>
<span class="p_add">+	kasan_unpoison_shadow(object, cache-&gt;object_size);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void kasan_poison_object_data(struct kmem_cache *cache, void *object)</span>
<span class="p_add">+{</span>
<span class="p_add">+	kasan_poison_shadow(object,</span>
<span class="p_add">+			round_up(cache-&gt;object_size, KASAN_SHADOW_SCALE_SIZE),</span>
<span class="p_add">+			KASAN_KMALLOC_REDZONE);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void kasan_slab_alloc(struct kmem_cache *cache, void *object)</span>
<span class="p_add">+{</span>
<span class="p_add">+	kasan_kmalloc(cache, object, cache-&gt;object_size);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void kasan_slab_free(struct kmem_cache *cache, void *object)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long size = cache-&gt;object_size;</span>
<span class="p_add">+	unsigned long rounded_up_size = round_up(size, KASAN_SHADOW_SCALE_SIZE);</span>
<span class="p_add">+</span>
<span class="p_add">+	/* RCU slabs could be legally used after free within the RCU period */</span>
<span class="p_add">+	if (unlikely(cache-&gt;flags &amp; SLAB_DESTROY_BY_RCU))</span>
<span class="p_add">+		return;</span>
<span class="p_add">+</span>
<span class="p_add">+	kasan_poison_shadow(object, rounded_up_size, KASAN_KMALLOC_FREE);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void kasan_kmalloc(struct kmem_cache *cache, const void *object, size_t size)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long redzone_start;</span>
<span class="p_add">+	unsigned long redzone_end;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (unlikely(object == NULL))</span>
<span class="p_add">+		return;</span>
<span class="p_add">+</span>
<span class="p_add">+	redzone_start = round_up((unsigned long)(object + size),</span>
<span class="p_add">+				KASAN_SHADOW_SCALE_SIZE);</span>
<span class="p_add">+	redzone_end = round_up((unsigned long)object + cache-&gt;object_size,</span>
<span class="p_add">+				KASAN_SHADOW_SCALE_SIZE);</span>
<span class="p_add">+</span>
<span class="p_add">+	kasan_unpoison_shadow(object, size);</span>
<span class="p_add">+	kasan_poison_shadow((void *)redzone_start, redzone_end - redzone_start,</span>
<span class="p_add">+		KASAN_KMALLOC_REDZONE);</span>
<span class="p_add">+}</span>
<span class="p_add">+EXPORT_SYMBOL(kasan_kmalloc);</span>
<span class="p_add">+</span>
<span class="p_add">+void kasan_kmalloc_large(const void *ptr, size_t size)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct page *page;</span>
<span class="p_add">+	unsigned long redzone_start;</span>
<span class="p_add">+	unsigned long redzone_end;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (unlikely(ptr == NULL))</span>
<span class="p_add">+		return;</span>
<span class="p_add">+</span>
<span class="p_add">+	page = virt_to_page(ptr);</span>
<span class="p_add">+	redzone_start = round_up((unsigned long)(ptr + size),</span>
<span class="p_add">+				KASAN_SHADOW_SCALE_SIZE);</span>
<span class="p_add">+	redzone_end = (unsigned long)ptr + (PAGE_SIZE &lt;&lt; compound_order(page));</span>
<span class="p_add">+</span>
<span class="p_add">+	kasan_unpoison_shadow(ptr, size);</span>
<span class="p_add">+	kasan_poison_shadow((void *)redzone_start, redzone_end - redzone_start,</span>
<span class="p_add">+		KASAN_PAGE_REDZONE);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void kasan_krealloc(const void *object, size_t size)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct page *page;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (unlikely(object == ZERO_SIZE_PTR))</span>
<span class="p_add">+		return;</span>
<span class="p_add">+</span>
<span class="p_add">+	page = virt_to_head_page(object);</span>
<span class="p_add">+</span>
<span class="p_add">+	if (unlikely(!PageSlab(page)))</span>
<span class="p_add">+		kasan_kmalloc_large(object, size);</span>
<span class="p_add">+	else</span>
<span class="p_add">+		kasan_kmalloc(page-&gt;slab_cache, object, size);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void kasan_kfree_large(const void *ptr)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct page *page = virt_to_page(ptr);</span>
<span class="p_add">+</span>
<span class="p_add">+	kasan_poison_shadow(ptr, PAGE_SIZE &lt;&lt; compound_order(page),</span>
<span class="p_add">+			KASAN_FREE_PAGE);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+int kasan_module_alloc(void *addr, size_t size)</span>
<span class="p_add">+{</span>
<span class="p_add">+	void *ret;</span>
<span class="p_add">+	size_t shadow_size;</span>
<span class="p_add">+	unsigned long shadow_start;</span>
<span class="p_add">+</span>
<span class="p_add">+	shadow_start = (unsigned long)kasan_mem_to_shadow(addr);</span>
<span class="p_add">+	shadow_size = round_up(size &gt;&gt; KASAN_SHADOW_SCALE_SHIFT,</span>
<span class="p_add">+			PAGE_SIZE);</span>
<span class="p_add">+</span>
<span class="p_add">+</span>
<span class="p_add">+	ret = __vmalloc_node_range(shadow_size, 1, shadow_start,</span>
<span class="p_add">+			shadow_start + shadow_size,</span>
<span class="p_add">+			GFP_KERNEL | __GFP_HIGHMEM | __GFP_ZERO,</span>
<span class="p_add">+			PAGE_KERNEL, VM_NO_GUARD, NUMA_NO_NODE,</span>
<span class="p_add">+			__builtin_return_address(0));</span>
<span class="p_add">+</span>
<span class="p_add">+	if (ret) {</span>
<span class="p_add">+		find_vm_area(addr)-&gt;flags |= VM_KASAN;</span>
<span class="p_add">+		return 0;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	return -ENOMEM;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void kasan_free_shadow(const struct vm_struct *vm)</span>
<span class="p_add">+{</span>
<span class="p_add">+	if (vm-&gt;flags &amp; VM_KASAN)</span>
<span class="p_add">+		vfree(kasan_mem_to_shadow(vm-&gt;addr));</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static void register_global(struct kasan_global *global)</span>
<span class="p_add">+{</span>
<span class="p_add">+	size_t aligned_size = round_up(global-&gt;size, KASAN_SHADOW_SCALE_SIZE);</span>
<span class="p_add">+</span>
<span class="p_add">+	kasan_unpoison_shadow(global-&gt;beg, global-&gt;size);</span>
<span class="p_add">+</span>
<span class="p_add">+	kasan_poison_shadow(global-&gt;beg + aligned_size,</span>
<span class="p_add">+		global-&gt;size_with_redzone - aligned_size,</span>
<span class="p_add">+		KASAN_GLOBAL_REDZONE);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void __asan_register_globals(struct kasan_global *globals, size_t size)</span>
<span class="p_add">+{</span>
<span class="p_add">+	int i;</span>
<span class="p_add">+</span>
<span class="p_add">+	for (i = 0; i &lt; size; i++)</span>
<span class="p_add">+		register_global(&amp;globals[i]);</span>
<span class="p_add">+}</span>
<span class="p_add">+EXPORT_SYMBOL(__asan_register_globals);</span>
<span class="p_add">+</span>
<span class="p_add">+void __asan_unregister_globals(struct kasan_global *globals, size_t size)</span>
<span class="p_add">+{</span>
<span class="p_add">+}</span>
<span class="p_add">+EXPORT_SYMBOL(__asan_unregister_globals);</span>
<span class="p_add">+</span>
<span class="p_add">+#define DEFINE_ASAN_LOAD_STORE(size)					\</span>
<span class="p_add">+	void __asan_load##size(unsigned long addr)			\</span>
<span class="p_add">+	{								\</span>
<span class="p_add">+		check_memory_region_inline(addr, size, false, _RET_IP_);\</span>
<span class="p_add">+	}								\</span>
<span class="p_add">+	EXPORT_SYMBOL(__asan_load##size);				\</span>
<span class="p_add">+	__alias(__asan_load##size)					\</span>
<span class="p_add">+	void __asan_load##size##_noabort(unsigned long);		\</span>
<span class="p_add">+	EXPORT_SYMBOL(__asan_load##size##_noabort);			\</span>
<span class="p_add">+	void __asan_store##size(unsigned long addr)			\</span>
<span class="p_add">+	{								\</span>
<span class="p_add">+		check_memory_region_inline(addr, size, true, _RET_IP_);	\</span>
<span class="p_add">+	}								\</span>
<span class="p_add">+	EXPORT_SYMBOL(__asan_store##size);				\</span>
<span class="p_add">+	__alias(__asan_store##size)					\</span>
<span class="p_add">+	void __asan_store##size##_noabort(unsigned long);		\</span>
<span class="p_add">+	EXPORT_SYMBOL(__asan_store##size##_noabort)</span>
<span class="p_add">+</span>
<span class="p_add">+DEFINE_ASAN_LOAD_STORE(1);</span>
<span class="p_add">+DEFINE_ASAN_LOAD_STORE(2);</span>
<span class="p_add">+DEFINE_ASAN_LOAD_STORE(4);</span>
<span class="p_add">+DEFINE_ASAN_LOAD_STORE(8);</span>
<span class="p_add">+DEFINE_ASAN_LOAD_STORE(16);</span>
<span class="p_add">+</span>
<span class="p_add">+void __asan_loadN(unsigned long addr, size_t size)</span>
<span class="p_add">+{</span>
<span class="p_add">+	check_memory_region(addr, size, false, _RET_IP_);</span>
<span class="p_add">+}</span>
<span class="p_add">+EXPORT_SYMBOL(__asan_loadN);</span>
<span class="p_add">+</span>
<span class="p_add">+__alias(__asan_loadN)</span>
<span class="p_add">+void __asan_loadN_noabort(unsigned long, size_t);</span>
<span class="p_add">+EXPORT_SYMBOL(__asan_loadN_noabort);</span>
<span class="p_add">+</span>
<span class="p_add">+void __asan_storeN(unsigned long addr, size_t size)</span>
<span class="p_add">+{</span>
<span class="p_add">+	check_memory_region(addr, size, true, _RET_IP_);</span>
<span class="p_add">+}</span>
<span class="p_add">+EXPORT_SYMBOL(__asan_storeN);</span>
<span class="p_add">+</span>
<span class="p_add">+__alias(__asan_storeN)</span>
<span class="p_add">+void __asan_storeN_noabort(unsigned long, size_t);</span>
<span class="p_add">+EXPORT_SYMBOL(__asan_storeN_noabort);</span>
<span class="p_add">+</span>
<span class="p_add">+/* to shut up compiler complaints */</span>
<span class="p_add">+void __asan_handle_no_return(void) {}</span>
<span class="p_add">+EXPORT_SYMBOL(__asan_handle_no_return);</span>
<span class="p_add">+</span>
<span class="p_add">+#ifdef CONFIG_MEMORY_HOTPLUG</span>
<span class="p_add">+static int kasan_mem_notifier(struct notifier_block *nb,</span>
<span class="p_add">+			unsigned long action, void *data)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return (action == MEM_GOING_ONLINE) ? NOTIFY_BAD : NOTIFY_OK;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static int __init kasan_memhotplug_init(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	pr_err(&quot;WARNING: KASan doesn&#39;t support memory hot-add\n&quot;);</span>
<span class="p_add">+	pr_err(&quot;Memory hot-add will be disabled\n&quot;);</span>
<span class="p_add">+</span>
<span class="p_add">+	hotplug_memory_notifier(kasan_mem_notifier, 0);</span>
<span class="p_add">+</span>
<span class="p_add">+	return 0;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+module_init(kasan_memhotplug_init);</span>
<span class="p_add">+#endif</span>
<span class="p_header">diff --git a/mm/kasan/kasan.h b/mm/kasan/kasan.h</span>
new file mode 100644
<span class="p_header">index 0000000..14cdff3</span>
<span class="p_header">--- /dev/null</span>
<span class="p_header">+++ b/mm/kasan/kasan.h</span>
<span class="p_chunk">@@ -0,0 +1,72 @@</span> <span class="p_context"></span>
<span class="p_add">+#ifndef __MM_KASAN_KASAN_H</span>
<span class="p_add">+#define __MM_KASAN_KASAN_H</span>
<span class="p_add">+</span>
<span class="p_add">+#include &lt;linux/kasan.h&gt;</span>
<span class="p_add">+</span>
<span class="p_add">+#define KASAN_SHADOW_SCALE_SIZE (1UL &lt;&lt; KASAN_SHADOW_SCALE_SHIFT)</span>
<span class="p_add">+#define KASAN_SHADOW_MASK       (KASAN_SHADOW_SCALE_SIZE - 1)</span>
<span class="p_add">+</span>
<span class="p_add">+#define KASAN_FREE_PAGE         0xFF  /* page was freed */</span>
<span class="p_add">+#define KASAN_FREE_PAGE         0xFF  /* page was freed */</span>
<span class="p_add">+#define KASAN_PAGE_REDZONE      0xFE  /* redzone for kmalloc_large allocations */</span>
<span class="p_add">+#define KASAN_KMALLOC_REDZONE   0xFC  /* redzone inside slub object */</span>
<span class="p_add">+#define KASAN_KMALLOC_FREE      0xFB  /* object was freed (kmem_cache_free/kfree) */</span>
<span class="p_add">+#define KASAN_GLOBAL_REDZONE    0xFA  /* redzone for global variable */</span>
<span class="p_add">+</span>
<span class="p_add">+/*</span>
<span class="p_add">+ * Stack redzone shadow values</span>
<span class="p_add">+ * (Those are compiler&#39;s ABI, don&#39;t change them)</span>
<span class="p_add">+ */</span>
<span class="p_add">+#define KASAN_STACK_LEFT        0xF1</span>
<span class="p_add">+#define KASAN_STACK_MID         0xF2</span>
<span class="p_add">+#define KASAN_STACK_RIGHT       0xF3</span>
<span class="p_add">+#define KASAN_STACK_PARTIAL     0xF4</span>
<span class="p_add">+</span>
<span class="p_add">+/* Don&#39;t break randconfig/all*config builds */</span>
<span class="p_add">+#ifndef KASAN_ABI_VERSION</span>
<span class="p_add">+#define KASAN_ABI_VERSION 1</span>
<span class="p_add">+#endif</span>
<span class="p_add">+</span>
<span class="p_add">+struct kasan_access_info {</span>
<span class="p_add">+	const void *access_addr;</span>
<span class="p_add">+	const void *first_bad_addr;</span>
<span class="p_add">+	size_t access_size;</span>
<span class="p_add">+	bool is_write;</span>
<span class="p_add">+	unsigned long ip;</span>
<span class="p_add">+};</span>
<span class="p_add">+</span>
<span class="p_add">+/* The layout of struct dictated by compiler */</span>
<span class="p_add">+struct kasan_source_location {</span>
<span class="p_add">+	const char *filename;</span>
<span class="p_add">+	int line_no;</span>
<span class="p_add">+	int column_no;</span>
<span class="p_add">+};</span>
<span class="p_add">+</span>
<span class="p_add">+/* The layout of struct dictated by compiler */</span>
<span class="p_add">+struct kasan_global {</span>
<span class="p_add">+	const void *beg;		/* Address of the beginning of the global variable. */</span>
<span class="p_add">+	size_t size;			/* Size of the global variable. */</span>
<span class="p_add">+	size_t size_with_redzone;	/* Size of the variable + size of the red zone. 32 bytes aligned */</span>
<span class="p_add">+	const void *name;</span>
<span class="p_add">+	const void *module_name;	/* Name of the module where the global variable is declared. */</span>
<span class="p_add">+	unsigned long has_dynamic_init;	/* This needed for C++ */</span>
<span class="p_add">+#if KASAN_ABI_VERSION &gt;= 4</span>
<span class="p_add">+	struct kasan_source_location *location;</span>
<span class="p_add">+#endif</span>
<span class="p_add">+};</span>
<span class="p_add">+</span>
<span class="p_add">+static inline const void *kasan_shadow_to_mem(const void *shadow_addr)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return (void *)(((unsigned long)shadow_addr - KASAN_SHADOW_OFFSET)</span>
<span class="p_add">+		&lt;&lt; KASAN_SHADOW_SCALE_SHIFT);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline bool kasan_enabled(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return !current-&gt;kasan_depth;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void kasan_report(unsigned long addr, size_t size,</span>
<span class="p_add">+		bool is_write, unsigned long ip);</span>
<span class="p_add">+</span>
<span class="p_add">+#endif</span>
<span class="p_header">diff --git a/mm/kasan/report.c b/mm/kasan/report.c</span>
new file mode 100644
<span class="p_header">index 0000000..66ec459</span>
<span class="p_header">--- /dev/null</span>
<span class="p_header">+++ b/mm/kasan/report.c</span>
<span class="p_chunk">@@ -0,0 +1,285 @@</span> <span class="p_context"></span>
<span class="p_add">+/*</span>
<span class="p_add">+ * This file contains error reporting code.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * Copyright (c) 2014 Samsung Electronics Co., Ltd.</span>
<span class="p_add">+ * Author: Andrey Ryabinin &lt;a.ryabinin at samsung.com&gt;</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * Some of code borrowed from https://github.com/xairy/linux by</span>
<span class="p_add">+ *        Andrey Konovalov &lt;adech.fo at gmail.com&gt;</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * This program is free software; you can redistribute it and/or modify</span>
<span class="p_add">+ * it under the terms of the GNU General Public License version 2 as</span>
<span class="p_add">+ * published by the Free Software Foundation.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ */</span>
<span class="p_add">+</span>
<span class="p_add">+#include &lt;linux/kernel.h&gt;</span>
<span class="p_add">+#include &lt;linux/mm.h&gt;</span>
<span class="p_add">+#include &lt;linux/printk.h&gt;</span>
<span class="p_add">+#include &lt;linux/sched.h&gt;</span>
<span class="p_add">+#include &lt;linux/slab.h&gt;</span>
<span class="p_add">+#include &lt;linux/stacktrace.h&gt;</span>
<span class="p_add">+#include &lt;linux/string.h&gt;</span>
<span class="p_add">+#include &lt;linux/types.h&gt;</span>
<span class="p_add">+#include &lt;linux/kasan.h&gt;</span>
<span class="p_add">+</span>
<span class="p_add">+#include &lt;asm/sections.h&gt;</span>
<span class="p_add">+</span>
<span class="p_add">+#include &quot;kasan.h&quot;</span>
<span class="p_add">+#include &quot;../slab.h&quot;</span>
<span class="p_add">+</span>
<span class="p_add">+/* Shadow layout customization. */</span>
<span class="p_add">+#define SHADOW_BYTES_PER_BLOCK 1</span>
<span class="p_add">+#define SHADOW_BLOCKS_PER_ROW 16</span>
<span class="p_add">+#define SHADOW_BYTES_PER_ROW (SHADOW_BLOCKS_PER_ROW * SHADOW_BYTES_PER_BLOCK)</span>
<span class="p_add">+#define SHADOW_ROWS_AROUND_ADDR 2</span>
<span class="p_add">+</span>
<span class="p_add">+static const void *find_first_bad_addr(const void *addr, size_t size)</span>
<span class="p_add">+{</span>
<span class="p_add">+	u8 shadow_val = *(u8 *)kasan_mem_to_shadow(addr);</span>
<span class="p_add">+	const void *first_bad_addr = addr;</span>
<span class="p_add">+</span>
<span class="p_add">+	while (!shadow_val &amp;&amp; first_bad_addr &lt; addr + size) {</span>
<span class="p_add">+		first_bad_addr += KASAN_SHADOW_SCALE_SIZE;</span>
<span class="p_add">+		shadow_val = *(u8 *)kasan_mem_to_shadow(first_bad_addr);</span>
<span class="p_add">+	}</span>
<span class="p_add">+	return first_bad_addr;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static void print_error_description(struct kasan_access_info *info)</span>
<span class="p_add">+{</span>
<span class="p_add">+	const char *bug_type = &quot;unknown crash&quot;;</span>
<span class="p_add">+	u8 shadow_val;</span>
<span class="p_add">+</span>
<span class="p_add">+	info-&gt;first_bad_addr = find_first_bad_addr(info-&gt;access_addr,</span>
<span class="p_add">+						info-&gt;access_size);</span>
<span class="p_add">+</span>
<span class="p_add">+	shadow_val = *(u8 *)kasan_mem_to_shadow(info-&gt;first_bad_addr);</span>
<span class="p_add">+</span>
<span class="p_add">+	switch (shadow_val) {</span>
<span class="p_add">+	case KASAN_FREE_PAGE:</span>
<span class="p_add">+	case KASAN_KMALLOC_FREE:</span>
<span class="p_add">+		bug_type = &quot;use after free&quot;;</span>
<span class="p_add">+		break;</span>
<span class="p_add">+	case KASAN_PAGE_REDZONE:</span>
<span class="p_add">+	case KASAN_KMALLOC_REDZONE:</span>
<span class="p_add">+	case KASAN_GLOBAL_REDZONE:</span>
<span class="p_add">+	case 0 ... KASAN_SHADOW_SCALE_SIZE - 1:</span>
<span class="p_add">+		bug_type = &quot;out of bounds access&quot;;</span>
<span class="p_add">+		break;</span>
<span class="p_add">+	case KASAN_STACK_LEFT:</span>
<span class="p_add">+	case KASAN_STACK_MID:</span>
<span class="p_add">+	case KASAN_STACK_RIGHT:</span>
<span class="p_add">+	case KASAN_STACK_PARTIAL:</span>
<span class="p_add">+		bug_type = &quot;out of bounds on stack&quot;;</span>
<span class="p_add">+		break;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	pr_err(&quot;BUG: KASan: %s in %pS at addr %p\n&quot;,</span>
<span class="p_add">+		bug_type, (void *)info-&gt;ip,</span>
<span class="p_add">+		info-&gt;access_addr);</span>
<span class="p_add">+	pr_err(&quot;%s of size %zu by task %s/%d\n&quot;,</span>
<span class="p_add">+		info-&gt;is_write ? &quot;Write&quot; : &quot;Read&quot;,</span>
<span class="p_add">+		info-&gt;access_size, current-&gt;comm, task_pid_nr(current));</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline bool kernel_or_module_addr(const void *addr)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return (addr &gt;= (void *)_stext &amp;&amp; addr &lt; (void *)_end)</span>
<span class="p_add">+		|| (addr &gt;= (void *)MODULES_VADDR</span>
<span class="p_add">+			&amp;&amp; addr &lt; (void *)MODULES_END);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline bool init_task_stack_addr(const void *addr)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return addr &gt;= (void *)&amp;init_thread_union.stack &amp;&amp;</span>
<span class="p_add">+		(addr &lt;= (void *)&amp;init_thread_union.stack +</span>
<span class="p_add">+			sizeof(init_thread_union.stack));</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static void print_address_description(struct kasan_access_info *info)</span>
<span class="p_add">+{</span>
<span class="p_add">+	const void *addr = info-&gt;access_addr;</span>
<span class="p_add">+</span>
<span class="p_add">+	if ((addr &gt;= (void *)PAGE_OFFSET) &amp;&amp;</span>
<span class="p_add">+		(addr &lt; high_memory)) {</span>
<span class="p_add">+		struct page *page = virt_to_head_page(addr);</span>
<span class="p_add">+</span>
<span class="p_add">+		if (PageSlab(page)) {</span>
<span class="p_add">+			void *object;</span>
<span class="p_add">+			struct kmem_cache *cache = page-&gt;slab_cache;</span>
<span class="p_add">+			void *last_object;</span>
<span class="p_add">+</span>
<span class="p_add">+			object = virt_to_obj(cache, page_address(page), addr);</span>
<span class="p_add">+			last_object = page_address(page) +</span>
<span class="p_add">+				page-&gt;objects * cache-&gt;size;</span>
<span class="p_add">+</span>
<span class="p_add">+			if (unlikely(object &gt; last_object))</span>
<span class="p_add">+				object = last_object; /* we hit into padding */</span>
<span class="p_add">+</span>
<span class="p_add">+			object_err(cache, page, object,</span>
<span class="p_add">+				&quot;kasan: bad access detected&quot;);</span>
<span class="p_add">+			return;</span>
<span class="p_add">+		}</span>
<span class="p_add">+		dump_page(page);</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	if (kernel_or_module_addr(addr)) {</span>
<span class="p_add">+		if (!init_task_stack_addr(addr))</span>
<span class="p_add">+			pr_err(&quot;Address belongs to variable %pS\n&quot;, addr);</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	dump_stack();</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static bool row_is_guilty(const void *row, const void *guilty)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return (row &lt;= guilty) &amp;&amp; (guilty &lt; row + SHADOW_BYTES_PER_ROW);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static int shadow_pointer_offset(const void *row, const void *shadow)</span>
<span class="p_add">+{</span>
<span class="p_add">+	/* The length of &quot;&gt;ff00ff00ff00ff00: &quot; is</span>
<span class="p_add">+	 *    3 + (BITS_PER_LONG/8)*2 chars.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	return 3 + (BITS_PER_LONG/8)*2 + (shadow - row)*2 +</span>
<span class="p_add">+		(shadow - row) / SHADOW_BYTES_PER_BLOCK + 1;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static void print_shadow_for_address(const void *addr)</span>
<span class="p_add">+{</span>
<span class="p_add">+	int i;</span>
<span class="p_add">+	const void *shadow = kasan_mem_to_shadow(addr);</span>
<span class="p_add">+	const void *shadow_row;</span>
<span class="p_add">+</span>
<span class="p_add">+	shadow_row = (void *)round_down((unsigned long)shadow,</span>
<span class="p_add">+					SHADOW_BYTES_PER_ROW)</span>
<span class="p_add">+		- SHADOW_ROWS_AROUND_ADDR * SHADOW_BYTES_PER_ROW;</span>
<span class="p_add">+</span>
<span class="p_add">+	pr_err(&quot;Memory state around the buggy address:\n&quot;);</span>
<span class="p_add">+</span>
<span class="p_add">+	for (i = -SHADOW_ROWS_AROUND_ADDR; i &lt;= SHADOW_ROWS_AROUND_ADDR; i++) {</span>
<span class="p_add">+		const void *kaddr = kasan_shadow_to_mem(shadow_row);</span>
<span class="p_add">+		char buffer[4 + (BITS_PER_LONG/8)*2];</span>
<span class="p_add">+</span>
<span class="p_add">+		snprintf(buffer, sizeof(buffer),</span>
<span class="p_add">+			(i == 0) ? &quot;&gt;%p: &quot; : &quot; %p: &quot;, kaddr);</span>
<span class="p_add">+</span>
<span class="p_add">+		kasan_disable_current();</span>
<span class="p_add">+		print_hex_dump(KERN_ERR, buffer,</span>
<span class="p_add">+			DUMP_PREFIX_NONE, SHADOW_BYTES_PER_ROW, 1,</span>
<span class="p_add">+			shadow_row, SHADOW_BYTES_PER_ROW, 0);</span>
<span class="p_add">+		kasan_enable_current();</span>
<span class="p_add">+</span>
<span class="p_add">+		if (row_is_guilty(shadow_row, shadow))</span>
<span class="p_add">+			pr_err(&quot;%*c\n&quot;,</span>
<span class="p_add">+				shadow_pointer_offset(shadow_row, shadow),</span>
<span class="p_add">+				&#39;^&#39;);</span>
<span class="p_add">+</span>
<span class="p_add">+		shadow_row += SHADOW_BYTES_PER_ROW;</span>
<span class="p_add">+	}</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static DEFINE_SPINLOCK(report_lock);</span>
<span class="p_add">+</span>
<span class="p_add">+static void kasan_report_error(struct kasan_access_info *info)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long flags;</span>
<span class="p_add">+	const char *bug_type;</span>
<span class="p_add">+</span>
<span class="p_add">+	spin_lock_irqsave(&amp;report_lock, flags);</span>
<span class="p_add">+	pr_err(&quot;=================================&quot;</span>
<span class="p_add">+		&quot;=================================\n&quot;);</span>
<span class="p_add">+	if (info-&gt;access_addr &lt;</span>
<span class="p_add">+			kasan_shadow_to_mem((void *)KASAN_SHADOW_START)) {</span>
<span class="p_add">+		if ((unsigned long)info-&gt;access_addr &lt; PAGE_SIZE)</span>
<span class="p_add">+			bug_type = &quot;null-ptr-deref&quot;;</span>
<span class="p_add">+		else if ((unsigned long)info-&gt;access_addr &lt; TASK_SIZE)</span>
<span class="p_add">+			bug_type = &quot;user-memory-access&quot;;</span>
<span class="p_add">+		else</span>
<span class="p_add">+			bug_type = &quot;wild-memory-access&quot;;</span>
<span class="p_add">+		pr_err(&quot;BUG: KASan: %s on address %p\n&quot;,</span>
<span class="p_add">+			bug_type, info-&gt;access_addr);</span>
<span class="p_add">+		pr_err(&quot;%s of size %zu by task %s/%d\n&quot;,</span>
<span class="p_add">+			info-&gt;is_write ? &quot;Write&quot; : &quot;Read&quot;,</span>
<span class="p_add">+			info-&gt;access_size, current-&gt;comm,</span>
<span class="p_add">+			task_pid_nr(current));</span>
<span class="p_add">+		dump_stack();</span>
<span class="p_add">+	} else {</span>
<span class="p_add">+		print_error_description(info);</span>
<span class="p_add">+		print_address_description(info);</span>
<span class="p_add">+		print_shadow_for_address(info-&gt;first_bad_addr);</span>
<span class="p_add">+	}</span>
<span class="p_add">+	pr_err(&quot;=================================&quot;</span>
<span class="p_add">+		&quot;=================================\n&quot;);</span>
<span class="p_add">+	add_taint(TAINT_BAD_PAGE, LOCKDEP_NOW_UNRELIABLE);</span>
<span class="p_add">+	spin_unlock_irqrestore(&amp;report_lock, flags);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static bool print_till_death;</span>
<span class="p_add">+static int __init kasan_setup(char *arg)</span>
<span class="p_add">+{</span>
<span class="p_add">+	print_till_death = true;</span>
<span class="p_add">+	return 0;</span>
<span class="p_add">+}</span>
<span class="p_add">+__setup(&quot;kasan_print_till_death&quot;, kasan_setup);</span>
<span class="p_add">+</span>
<span class="p_add">+void kasan_report(unsigned long addr, size_t size,</span>
<span class="p_add">+		bool is_write, unsigned long ip)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct kasan_access_info info;</span>
<span class="p_add">+	static bool reported = false;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (likely(!kasan_enabled()))</span>
<span class="p_add">+		return;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (likely(!print_till_death)) {</span>
<span class="p_add">+		if (reported)</span>
<span class="p_add">+			return;</span>
<span class="p_add">+		reported = true;</span>
<span class="p_add">+	}</span>
<span class="p_add">+	info.access_addr = (void *)addr;</span>
<span class="p_add">+	info.access_size = size;</span>
<span class="p_add">+	info.is_write = is_write;</span>
<span class="p_add">+	info.ip = ip;</span>
<span class="p_add">+</span>
<span class="p_add">+	kasan_report_error(&amp;info);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+</span>
<span class="p_add">+#define DEFINE_ASAN_REPORT_LOAD(size)                     \</span>
<span class="p_add">+void __asan_report_load##size##_noabort(unsigned long addr) \</span>
<span class="p_add">+{                                                         \</span>
<span class="p_add">+	kasan_report(addr, size, false, _RET_IP_);	  \</span>
<span class="p_add">+}                                                         \</span>
<span class="p_add">+EXPORT_SYMBOL(__asan_report_load##size##_noabort)</span>
<span class="p_add">+</span>
<span class="p_add">+#define DEFINE_ASAN_REPORT_STORE(size)                     \</span>
<span class="p_add">+void __asan_report_store##size##_noabort(unsigned long addr) \</span>
<span class="p_add">+{                                                          \</span>
<span class="p_add">+	kasan_report(addr, size, true, _RET_IP_);	   \</span>
<span class="p_add">+}                                                          \</span>
<span class="p_add">+EXPORT_SYMBOL(__asan_report_store##size##_noabort)</span>
<span class="p_add">+</span>
<span class="p_add">+DEFINE_ASAN_REPORT_LOAD(1);</span>
<span class="p_add">+DEFINE_ASAN_REPORT_LOAD(2);</span>
<span class="p_add">+DEFINE_ASAN_REPORT_LOAD(4);</span>
<span class="p_add">+DEFINE_ASAN_REPORT_LOAD(8);</span>
<span class="p_add">+DEFINE_ASAN_REPORT_LOAD(16);</span>
<span class="p_add">+DEFINE_ASAN_REPORT_STORE(1);</span>
<span class="p_add">+DEFINE_ASAN_REPORT_STORE(2);</span>
<span class="p_add">+DEFINE_ASAN_REPORT_STORE(4);</span>
<span class="p_add">+DEFINE_ASAN_REPORT_STORE(8);</span>
<span class="p_add">+DEFINE_ASAN_REPORT_STORE(16);</span>
<span class="p_add">+</span>
<span class="p_add">+void __asan_report_load_n_noabort(unsigned long addr, size_t size)</span>
<span class="p_add">+{</span>
<span class="p_add">+	kasan_report(addr, size, false, _RET_IP_);</span>
<span class="p_add">+}</span>
<span class="p_add">+EXPORT_SYMBOL(__asan_report_load_n_noabort);</span>
<span class="p_add">+</span>
<span class="p_add">+void __asan_report_store_n_noabort(unsigned long addr, size_t size)</span>
<span class="p_add">+{</span>
<span class="p_add">+	kasan_report(addr, size, true, _RET_IP_);</span>
<span class="p_add">+}</span>
<span class="p_add">+EXPORT_SYMBOL(__asan_report_store_n_noabort);</span>
<span class="p_header">diff --git a/mm/kmemleak.c b/mm/kmemleak.c</span>
<span class="p_header">index c8d7f31..7dca1ef 100644</span>
<span class="p_header">--- a/mm/kmemleak.c</span>
<span class="p_header">+++ b/mm/kmemleak.c</span>
<span class="p_chunk">@@ -98,6 +98,7 @@</span> <span class="p_context"></span>
 #include &lt;asm/processor.h&gt;
 #include &lt;linux/atomic.h&gt;
 
<span class="p_add">+#include &lt;linux/kasan.h&gt;</span>
 #include &lt;linux/kmemcheck.h&gt;
 #include &lt;linux/kmemleak.h&gt;
 #include &lt;linux/memory_hotplug.h&gt;
<span class="p_chunk">@@ -1076,7 +1077,10 @@</span> <span class="p_context"> static bool update_checksum(struct kmemleak_object *object)</span>
 	if (!kmemcheck_is_obj_initialized(object-&gt;pointer, object-&gt;size))
 		return false;
 
<span class="p_add">+	kasan_disable_current();</span>
 	object-&gt;checksum = crc32(0, (void *)object-&gt;pointer, object-&gt;size);
<span class="p_add">+	kasan_enable_current();</span>
<span class="p_add">+</span>
 	return object-&gt;checksum != old_csum;
 }
 
<span class="p_chunk">@@ -1127,7 +1131,9 @@</span> <span class="p_context"> static void scan_block(void *_start, void *_end,</span>
 						  BYTES_PER_POINTER))
 			continue;
 
<span class="p_add">+		kasan_disable_current();</span>
 		pointer = *ptr;
<span class="p_add">+		kasan_enable_current();</span>
 
 		object = find_and_get_object(pointer, 1);
 		if (!object)
<span class="p_header">diff --git a/mm/mempool.c b/mm/mempool.c</span>
<span class="p_header">index 5499047..db146ad 100644</span>
<span class="p_header">--- a/mm/mempool.c</span>
<span class="p_header">+++ b/mm/mempool.c</span>
<span class="p_chunk">@@ -6,25 +6,115 @@</span> <span class="p_context"></span>
  *  extreme VM load.
  *
  *  started by Ingo Molnar, Copyright (C) 2001
<span class="p_add">+ *  debugging by David Rientjes, Copyright (C) 2015</span>
  */
 
 #include &lt;linux/mm.h&gt;
 #include &lt;linux/slab.h&gt;
<span class="p_add">+</span>
<span class="p_add">+#include &lt;linux/highmem.h&gt;</span>
<span class="p_add">+#include &lt;linux/kmemleak.h&gt;</span>
 #include &lt;linux/export.h&gt;
 #include &lt;linux/mempool.h&gt;
 #include &lt;linux/blkdev.h&gt;
 #include &lt;linux/writeback.h&gt;
 
<span class="p_add">+#if defined(CONFIG_DEBUG_SLAB) || defined(CONFIG_SLUB_DEBUG_ON)</span>
<span class="p_add">+static void poison_error(mempool_t *pool, void *element, size_t size,</span>
<span class="p_add">+			 size_t byte)</span>
<span class="p_add">+{</span>
<span class="p_add">+	const int nr = pool-&gt;curr_nr;</span>
<span class="p_add">+	const int start = max_t(int, byte - (BITS_PER_LONG / 8), 0);</span>
<span class="p_add">+	const int end = min_t(int, byte + (BITS_PER_LONG / 8), size);</span>
<span class="p_add">+	int i;</span>
<span class="p_add">+</span>
<span class="p_add">+	pr_err(&quot;BUG: mempool element poison mismatch\n&quot;);</span>
<span class="p_add">+	pr_err(&quot;Mempool %p size %zu\n&quot;, pool, size);</span>
<span class="p_add">+	pr_err(&quot; nr=%d @ %p: %s0x&quot;, nr, element, start &gt; 0 ? &quot;... &quot; : &quot;&quot;);</span>
<span class="p_add">+	for (i = start; i &lt; end; i++)</span>
<span class="p_add">+		pr_cont(&quot;%x &quot;, *(u8 *)(element + i));</span>
<span class="p_add">+	pr_cont(&quot;%s\n&quot;, end &lt; size ? &quot;...&quot; : &quot;&quot;);</span>
<span class="p_add">+	dump_stack();</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static void __check_element(mempool_t *pool, void *element, size_t size)</span>
<span class="p_add">+{</span>
<span class="p_add">+	u8 *obj = element;</span>
<span class="p_add">+	size_t i;</span>
<span class="p_add">+</span>
<span class="p_add">+	for (i = 0; i &lt; size; i++) {</span>
<span class="p_add">+		u8 exp = (i &lt; size - 1) ? POISON_FREE : POISON_END;</span>
<span class="p_add">+</span>
<span class="p_add">+		if (obj[i] != exp) {</span>
<span class="p_add">+			poison_error(pool, element, size, i);</span>
<span class="p_add">+			return;</span>
<span class="p_add">+		}</span>
<span class="p_add">+	}</span>
<span class="p_add">+	memset(obj, POISON_INUSE, size);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static void check_element(mempool_t *pool, void *element)</span>
<span class="p_add">+{</span>
<span class="p_add">+	/* Mempools backed by slab allocator */</span>
<span class="p_add">+	if (pool-&gt;free == mempool_free_slab || pool-&gt;free == mempool_kfree)</span>
<span class="p_add">+		__check_element(pool, element, ksize(element));</span>
<span class="p_add">+</span>
<span class="p_add">+	/* Mempools backed by page allocator */</span>
<span class="p_add">+	if (pool-&gt;free == mempool_free_pages) {</span>
<span class="p_add">+		int order = (int)(long)pool-&gt;pool_data;</span>
<span class="p_add">+		void *addr = kmap_atomic((struct page *)element);</span>
<span class="p_add">+</span>
<span class="p_add">+		__check_element(pool, addr, 1UL &lt;&lt; (PAGE_SHIFT + order));</span>
<span class="p_add">+		kunmap_atomic(addr);</span>
<span class="p_add">+	}</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static void __poison_element(void *element, size_t size)</span>
<span class="p_add">+{</span>
<span class="p_add">+	u8 *obj = element;</span>
<span class="p_add">+</span>
<span class="p_add">+	memset(obj, POISON_FREE, size - 1);</span>
<span class="p_add">+	obj[size - 1] = POISON_END;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static void poison_element(mempool_t *pool, void *element)</span>
<span class="p_add">+{</span>
<span class="p_add">+	/* Mempools backed by slab allocator */</span>
<span class="p_add">+	if (pool-&gt;alloc == mempool_alloc_slab || pool-&gt;alloc == mempool_kmalloc)</span>
<span class="p_add">+		__poison_element(element, ksize(element));</span>
<span class="p_add">+</span>
<span class="p_add">+	/* Mempools backed by page allocator */</span>
<span class="p_add">+	if (pool-&gt;alloc == mempool_alloc_pages) {</span>
<span class="p_add">+		int order = (int)(long)pool-&gt;pool_data;</span>
<span class="p_add">+		void *addr = kmap_atomic((struct page *)element);</span>
<span class="p_add">+</span>
<span class="p_add">+		__poison_element(addr, 1UL &lt;&lt; (PAGE_SHIFT + order));</span>
<span class="p_add">+		kunmap_atomic(addr);</span>
<span class="p_add">+	}</span>
<span class="p_add">+}</span>
<span class="p_add">+#else /* CONFIG_DEBUG_SLAB || CONFIG_SLUB_DEBUG_ON */</span>
<span class="p_add">+static inline void check_element(mempool_t *pool, void *element)</span>
<span class="p_add">+{</span>
<span class="p_add">+}</span>
<span class="p_add">+static inline void poison_element(mempool_t *pool, void *element)</span>
<span class="p_add">+{</span>
<span class="p_add">+}</span>
<span class="p_add">+#endif /* CONFIG_DEBUG_SLAB || CONFIG_SLUB_DEBUG_ON */</span>
<span class="p_add">+</span>
 static void add_element(mempool_t *pool, void *element)
 {
 	BUG_ON(pool-&gt;curr_nr &gt;= pool-&gt;min_nr);
<span class="p_add">+	poison_element(pool, element);</span>
 	pool-&gt;elements[pool-&gt;curr_nr++] = element;
 }
 
 static void *remove_element(mempool_t *pool)
 {
<span class="p_del">-	BUG_ON(pool-&gt;curr_nr &lt;= 0);</span>
<span class="p_del">-	return pool-&gt;elements[--pool-&gt;curr_nr];</span>
<span class="p_add">+	void *element = pool-&gt;elements[--pool-&gt;curr_nr];</span>
<span class="p_add">+</span>
<span class="p_add">+	BUG_ON(pool-&gt;curr_nr &lt; 0);</span>
<span class="p_add">+	check_element(pool, element);</span>
<span class="p_add">+	return element;</span>
 }
 
 /**
<span class="p_header">diff --git a/mm/page_alloc.c b/mm/page_alloc.c</span>
<span class="p_header">index 494a081..872e8cc 100644</span>
<span class="p_header">--- a/mm/page_alloc.c</span>
<span class="p_header">+++ b/mm/page_alloc.c</span>
<span class="p_chunk">@@ -25,6 +25,7 @@</span> <span class="p_context"></span>
 #include &lt;linux/compiler.h&gt;
 #include &lt;linux/kernel.h&gt;
 #include &lt;linux/kmemcheck.h&gt;
<span class="p_add">+#include &lt;linux/kasan.h&gt;</span>
 #include &lt;linux/module.h&gt;
 #include &lt;linux/suspend.h&gt;
 #include &lt;linux/pagevec.h&gt;
<span class="p_chunk">@@ -706,6 +707,7 @@</span> <span class="p_context"> static bool free_pages_prepare(struct page *page, unsigned int order)</span>
 
 	trace_mm_page_free(page, order);
 	kmemcheck_free_shadow(page, order);
<span class="p_add">+	kasan_free_pages(page, order);</span>
 
 	if (PageAnon(page))
 		page-&gt;mapping = NULL;
<span class="p_chunk">@@ -871,6 +873,7 @@</span> <span class="p_context"> static int prep_new_page(struct page *page, int order, gfp_t gfp_flags)</span>
 
 	arch_alloc_page(page, order);
 	kernel_map_pages(page, 1 &lt;&lt; order, 1);
<span class="p_add">+	kasan_alloc_pages(page, order);</span>
 
 	if (gfp_flags &amp; __GFP_ZERO)
 		prep_zero_page(page, order, gfp_flags);
<span class="p_header">diff --git a/mm/slab.c b/mm/slab.c</span>
<span class="p_header">index bd88411..dd8f844 100644</span>
<span class="p_header">--- a/mm/slab.c</span>
<span class="p_header">+++ b/mm/slab.c</span>
<span class="p_chunk">@@ -3637,6 +3637,7 @@</span> <span class="p_context"> kmem_cache_alloc_trace(struct kmem_cache *cachep, gfp_t flags, size_t size)</span>
 
 	trace_kmalloc(_RET_IP_, ret,
 		      size, cachep-&gt;size, flags);
<span class="p_add">+	kasan_kmalloc(cachep, ret, size);</span>
 	return ret;
 }
 EXPORT_SYMBOL(kmem_cache_alloc_trace);
<span class="p_chunk">@@ -3668,6 +3669,7 @@</span> <span class="p_context"> void *kmem_cache_alloc_node_trace(struct kmem_cache *cachep,</span>
 	trace_kmalloc_node(_RET_IP_, ret,
 			   size, cachep-&gt;size,
 			   flags, nodeid);
<span class="p_add">+	kasan_kmalloc(cachep, ret, size);</span>
 	return ret;
 }
 EXPORT_SYMBOL(kmem_cache_alloc_node_trace);
<span class="p_header">diff --git a/mm/slab.h b/mm/slab.h</span>
<span class="p_header">index 4d6d836..887eb4c 100644</span>
<span class="p_header">--- a/mm/slab.h</span>
<span class="p_header">+++ b/mm/slab.h</span>
<span class="p_chunk">@@ -227,7 +227,7 @@</span> <span class="p_context"> static inline struct kmem_cache *cache_from_obj(struct kmem_cache *s, void *x)</span>
 	 * to not do even the assignment. In that case, slab_equal_or_root
 	 * will also be a constant.
 	 */
<span class="p_del">-	if (!memcg_kmem_enabled() &amp;&amp; !unlikely(s-&gt;flags &amp; SLAB_DEBUG_FREE))</span>
<span class="p_add">+	if (!unlikely(s-&gt;flags &amp; SLAB_DEBUG_FREE))</span>
 		return s;
 
 	page = virt_to_head_page(x);
<span class="p_header">diff --git a/mm/slab_common.c b/mm/slab_common.c</span>
<span class="p_header">index 7d21d3f..dd1847f 100644</span>
<span class="p_header">--- a/mm/slab_common.c</span>
<span class="p_header">+++ b/mm/slab_common.c</span>
<span class="p_chunk">@@ -20,6 +20,10 @@</span> <span class="p_context"></span>
 #include &lt;asm/page.h&gt;
 #include &lt;linux/memcontrol.h&gt;
 
<span class="p_add">+#define CREATE_TRACE_POINTS</span>
<span class="p_add">+#include &lt;trace/events/kmem.h&gt;</span>
<span class="p_add">+</span>
<span class="p_add">+#include &lt;linux/kasan.h&gt;</span>
 #include &quot;slab.h&quot;
 
 enum slab_state slab_state;
<span class="p_chunk">@@ -640,3 +644,104 @@</span> <span class="p_context"> static int __init slab_proc_init(void)</span>
 }
 module_init(slab_proc_init);
 #endif /* CONFIG_SLABINFO */
<span class="p_add">+</span>
<span class="p_add">+static __always_inline void *__do_krealloc(const void *p, size_t new_size,</span>
<span class="p_add">+					   gfp_t flags)</span>
<span class="p_add">+{</span>
<span class="p_add">+	void *ret;</span>
<span class="p_add">+	size_t ks = 0;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (p)</span>
<span class="p_add">+		ks = ksize(p);</span>
<span class="p_add">+</span>
<span class="p_add">+	if (ks &gt;= new_size) {</span>
<span class="p_add">+		kasan_krealloc((void *)p, new_size);</span>
<span class="p_add">+		return (void *)p;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	ret = kmalloc_track_caller(new_size, flags);</span>
<span class="p_add">+	if (ret &amp;&amp; p)</span>
<span class="p_add">+		memcpy(ret, p, ks);</span>
<span class="p_add">+</span>
<span class="p_add">+	return ret;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+/**</span>
<span class="p_add">+ * __krealloc - like krealloc() but don&#39;t free @p.</span>
<span class="p_add">+ * @p: object to reallocate memory for.</span>
<span class="p_add">+ * @new_size: how many bytes of memory are required.</span>
<span class="p_add">+ * @flags: the type of memory to allocate.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * This function is like krealloc() except it never frees the originally</span>
<span class="p_add">+ * allocated buffer. Use this if you don&#39;t want to free the buffer immediately</span>
<span class="p_add">+ * like, for example, with RCU.</span>
<span class="p_add">+ */</span>
<span class="p_add">+void *__krealloc(const void *p, size_t new_size, gfp_t flags)</span>
<span class="p_add">+{</span>
<span class="p_add">+	if (unlikely(!new_size))</span>
<span class="p_add">+		return ZERO_SIZE_PTR;</span>
<span class="p_add">+</span>
<span class="p_add">+	return __do_krealloc(p, new_size, flags);</span>
<span class="p_add">+</span>
<span class="p_add">+}</span>
<span class="p_add">+EXPORT_SYMBOL(__krealloc);</span>
<span class="p_add">+</span>
<span class="p_add">+/**</span>
<span class="p_add">+ * krealloc - reallocate memory. The contents will remain unchanged.</span>
<span class="p_add">+ * @p: object to reallocate memory for.</span>
<span class="p_add">+ * @new_size: how many bytes of memory are required.</span>
<span class="p_add">+ * @flags: the type of memory to allocate.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * The contents of the object pointed to are preserved up to the</span>
<span class="p_add">+ * lesser of the new and old sizes.  If @p is %NULL, krealloc()</span>
<span class="p_add">+ * behaves exactly like kmalloc().  If @new_size is 0 and @p is not a</span>
<span class="p_add">+ * %NULL pointer, the object pointed to is freed.</span>
<span class="p_add">+ */</span>
<span class="p_add">+void *krealloc(const void *p, size_t new_size, gfp_t flags)</span>
<span class="p_add">+{</span>
<span class="p_add">+	void *ret;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (unlikely(!new_size)) {</span>
<span class="p_add">+		kfree(p);</span>
<span class="p_add">+		return ZERO_SIZE_PTR;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	ret = __do_krealloc(p, new_size, flags);</span>
<span class="p_add">+	if (ret &amp;&amp; p != ret)</span>
<span class="p_add">+		kfree(p);</span>
<span class="p_add">+</span>
<span class="p_add">+	return ret;</span>
<span class="p_add">+}</span>
<span class="p_add">+EXPORT_SYMBOL(krealloc);</span>
<span class="p_add">+</span>
<span class="p_add">+/**</span>
<span class="p_add">+ * kzfree - like kfree but zero memory</span>
<span class="p_add">+ * @p: object to free memory of</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * The memory of the object @p points to is zeroed before freed.</span>
<span class="p_add">+ * If @p is %NULL, kzfree() does nothing.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * Note: this function zeroes the whole allocated buffer which can be a good</span>
<span class="p_add">+ * deal bigger than the requested buffer size passed to kmalloc(). So be</span>
<span class="p_add">+ * careful when using this function in performance sensitive code.</span>
<span class="p_add">+ */</span>
<span class="p_add">+void kzfree(const void *p)</span>
<span class="p_add">+{</span>
<span class="p_add">+	size_t ks;</span>
<span class="p_add">+	void *mem = (void *)p;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (unlikely(ZERO_OR_NULL_PTR(mem)))</span>
<span class="p_add">+		return;</span>
<span class="p_add">+	ks = ksize(mem);</span>
<span class="p_add">+	memset(mem, 0, ks);</span>
<span class="p_add">+	kfree(mem);</span>
<span class="p_add">+}</span>
<span class="p_add">+EXPORT_SYMBOL(kzfree);</span>
<span class="p_add">+</span>
<span class="p_add">+/* Tracepoints definitions. */</span>
<span class="p_add">+EXPORT_TRACEPOINT_SYMBOL(kmalloc);</span>
<span class="p_add">+EXPORT_TRACEPOINT_SYMBOL(kmem_cache_alloc);</span>
<span class="p_add">+EXPORT_TRACEPOINT_SYMBOL(kmalloc_node);</span>
<span class="p_add">+EXPORT_TRACEPOINT_SYMBOL(kmem_cache_alloc_node);</span>
<span class="p_add">+EXPORT_TRACEPOINT_SYMBOL(kfree);</span>
<span class="p_add">+EXPORT_TRACEPOINT_SYMBOL(kmem_cache_free);</span>
<span class="p_header">diff --git a/mm/slub.c b/mm/slub.c</span>
<span class="p_header">index deaed7b..1320ba2 100644</span>
<span class="p_header">--- a/mm/slub.c</span>
<span class="p_header">+++ b/mm/slub.c</span>
<span class="p_chunk">@@ -20,6 +20,7 @@</span> <span class="p_context"></span>
 #include &lt;linux/proc_fs.h&gt;
 #include &lt;linux/notifier.h&gt;
 #include &lt;linux/seq_file.h&gt;
<span class="p_add">+#include &lt;linux/kasan.h&gt;</span>
 #include &lt;linux/kmemcheck.h&gt;
 #include &lt;linux/cpu.h&gt;
 #include &lt;linux/cpuset.h&gt;
<span class="p_chunk">@@ -444,6 +445,8 @@</span> <span class="p_context"> static void get_map(struct kmem_cache *s, struct page *page, unsigned long *map)</span>
  */
 #ifdef CONFIG_SLUB_DEBUG_ON
 static int slub_debug = DEBUG_DEFAULT_FLAGS;
<span class="p_add">+#elif defined (CONFIG_KASAN)</span>
<span class="p_add">+static int slub_debug = SLAB_STORE_USER;</span>
 #else
 static int slub_debug;
 #endif
<span class="p_chunk">@@ -452,12 +455,30 @@</span> <span class="p_context"> static char *slub_debug_slabs;</span>
 static int disable_higher_order_debug;
 
 /*
<span class="p_add">+ * slub is about to manipulate internal object metadata.  This memory lies</span>
<span class="p_add">+ * outside the range of the allocated object, so accessing it would normally</span>
<span class="p_add">+ * be reported by kasan as a bounds error.  metadata_access_enable() is used</span>
<span class="p_add">+ * to tell kasan that these accesses are OK.</span>
<span class="p_add">+ */</span>
<span class="p_add">+static inline void metadata_access_enable(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	kasan_disable_current();</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline void metadata_access_disable(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	kasan_enable_current();</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+/*</span>
  * Object debugging
  */
 static void print_section(char *text, u8 *addr, unsigned int length)
 {
<span class="p_add">+	metadata_access_enable();</span>
 	print_hex_dump(KERN_ERR, text, DUMP_PREFIX_ADDRESS, 16, 1, addr,
 			length, 1);
<span class="p_add">+	metadata_access_disable();</span>
 }
 
 static struct track *get_track(struct kmem_cache *s, void *object,
<span class="p_chunk">@@ -487,7 +508,9 @@</span> <span class="p_context"> static void set_track(struct kmem_cache *s, void *object,</span>
 		trace.max_entries = TRACK_ADDRS_COUNT;
 		trace.entries = p-&gt;addrs;
 		trace.skip = 3;
<span class="p_add">+		metadata_access_enable();</span>
 		save_stack_trace(&amp;trace);
<span class="p_add">+		metadata_access_disable();</span>
 
 		/* See rant in lockdep.c */
 		if (trace.nr_entries != 0 &amp;&amp;
<span class="p_chunk">@@ -613,7 +636,7 @@</span> <span class="p_context"> static void print_trailer(struct kmem_cache *s, struct page *page, u8 *p)</span>
 	dump_stack();
 }
 
<span class="p_del">-static void object_err(struct kmem_cache *s, struct page *page,</span>
<span class="p_add">+void object_err(struct kmem_cache *s, struct page *page,</span>
 			u8 *object, char *reason)
 {
 	slab_bug(s, &quot;%s&quot;, reason);
<span class="p_chunk">@@ -660,7 +683,9 @@</span> <span class="p_context"> static int check_bytes_and_report(struct kmem_cache *s, struct page *page,</span>
 	u8 *fault;
 	u8 *end;
 
<span class="p_add">+	metadata_access_enable();</span>
 	fault = memchr_inv(start, value, bytes);
<span class="p_add">+	metadata_access_disable();</span>
 	if (!fault)
 		return 1;
 
<span class="p_chunk">@@ -753,7 +778,9 @@</span> <span class="p_context"> static int slab_pad_check(struct kmem_cache *s, struct page *page)</span>
 	if (!remainder)
 		return 1;
 
<span class="p_add">+	metadata_access_enable();</span>
 	fault = memchr_inv(end - remainder, POISON_INUSE, remainder);
<span class="p_add">+	metadata_access_disable();</span>
 	if (!fault)
 		return 1;
 	while (end &gt; fault &amp;&amp; end[-1] == POISON_INUSE)
<span class="p_chunk">@@ -933,6 +960,7 @@</span> <span class="p_context"> static inline void slab_post_alloc_hook(struct kmem_cache *s, gfp_t flags, void</span>
 	flags &amp;= gfp_allowed_mask;
 	kmemcheck_slab_alloc(s, flags, object, slab_ksize(s));
 	kmemleak_alloc_recursive(object, s-&gt;object_size, 1, s-&gt;flags, flags);
<span class="p_add">+	kasan_slab_alloc(s, object);</span>
 }
 
 static inline void slab_free_hook(struct kmem_cache *s, void *x)
<span class="p_chunk">@@ -956,6 +984,8 @@</span> <span class="p_context"> static inline void slab_free_hook(struct kmem_cache *s, void *x)</span>
 #endif
 	if (!(s-&gt;flags &amp; SLAB_DEBUG_OBJECTS))
 		debug_check_no_obj_freed(x, s-&gt;object_size);
<span class="p_add">+</span>
<span class="p_add">+	kasan_slab_free(s, x);</span>
 }
 
 /*
<span class="p_chunk">@@ -1336,8 +1366,11 @@</span> <span class="p_context"> static void setup_object(struct kmem_cache *s, struct page *page,</span>
 				void *object)
 {
 	setup_object_debug(s, page, object);
<span class="p_del">-	if (unlikely(s-&gt;ctor))</span>
<span class="p_add">+	if (unlikely(s-&gt;ctor)) {</span>
<span class="p_add">+		kasan_unpoison_object_data(s, object);</span>
 		s-&gt;ctor(object);
<span class="p_add">+		kasan_poison_object_data(s, object);</span>
<span class="p_add">+	}</span>
 }
 
 static struct page *new_slab(struct kmem_cache *s, gfp_t flags, int node)
<span class="p_chunk">@@ -1368,6 +1401,8 @@</span> <span class="p_context"> static struct page *new_slab(struct kmem_cache *s, gfp_t flags, int node)</span>
 	if (unlikely(s-&gt;flags &amp; SLAB_POISON))
 		memset(start, POISON_INUSE, PAGE_SIZE &lt;&lt; order);
 
<span class="p_add">+	kasan_poison_slab(page);</span>
<span class="p_add">+</span>
 	last = start;
 	for_each_object(p, s, start, page-&gt;objects) {
 		setup_object(s, page, last);
<span class="p_chunk">@@ -2417,6 +2452,7 @@</span> <span class="p_context"> void *kmem_cache_alloc_trace(struct kmem_cache *s, gfp_t gfpflags, size_t size)</span>
 {
 	void *ret = slab_alloc(s, gfpflags, _RET_IP_);
 	trace_kmalloc(_RET_IP_, ret, size, s-&gt;size, gfpflags);
<span class="p_add">+	kasan_kmalloc(s, ret, size);</span>
 	return ret;
 }
 EXPORT_SYMBOL(kmem_cache_alloc_trace);
<span class="p_chunk">@@ -2451,6 +2487,8 @@</span> <span class="p_context"> void *kmem_cache_alloc_node_trace(struct kmem_cache *s,</span>
 
 	trace_kmalloc_node(_RET_IP_, ret,
 			   size, s-&gt;size, gfpflags, node);
<span class="p_add">+</span>
<span class="p_add">+	kasan_kmalloc(s, ret, size);</span>
 	return ret;
 }
 EXPORT_SYMBOL(kmem_cache_alloc_node_trace);
<span class="p_chunk">@@ -2838,6 +2876,7 @@</span> <span class="p_context"> static void early_kmem_cache_node_alloc(int node)</span>
 	init_object(kmem_cache_node, n, SLUB_RED_ACTIVE);
 	init_tracking(kmem_cache_node, n);
 #endif
<span class="p_add">+	kasan_kmalloc(kmem_cache_node, n, sizeof(struct kmem_cache_node));</span>
 	init_kmem_cache_node(n);
 	inc_slabs_node(kmem_cache_node, node, page-&gt;objects);
 
<span class="p_chunk">@@ -3235,6 +3274,8 @@</span> <span class="p_context"> void *__kmalloc(size_t size, gfp_t flags)</span>
 
 	trace_kmalloc(_RET_IP_, ret, size, s-&gt;size, flags);
 
<span class="p_add">+	kasan_kmalloc(s, ret, size);</span>
<span class="p_add">+</span>
 	return ret;
 }
 EXPORT_SYMBOL(__kmalloc);
<span class="p_chunk">@@ -3251,6 +3292,7 @@</span> <span class="p_context"> static void *kmalloc_large_node(size_t size, gfp_t flags, int node)</span>
 		ptr = page_address(page);
 
 	kmemleak_alloc(ptr, size, 1, flags);
<span class="p_add">+	kasan_kmalloc_large(ptr, size);</span>
 	return ptr;
 }
 
<span class="p_chunk">@@ -3278,12 +3320,14 @@</span> <span class="p_context"> void *__kmalloc_node(size_t size, gfp_t flags, int node)</span>
 
 	trace_kmalloc_node(_RET_IP_, ret, size, s-&gt;size, flags, node);
 
<span class="p_add">+	kasan_kmalloc(s, ret, size);</span>
<span class="p_add">+</span>
 	return ret;
 }
 EXPORT_SYMBOL(__kmalloc_node);
 #endif
 
<span class="p_del">-size_t ksize(const void *object)</span>
<span class="p_add">+static size_t __ksize(const void *object)</span>
 {
 	struct page *page;
 
<span class="p_chunk">@@ -3299,6 +3343,15 @@</span> <span class="p_context"> size_t ksize(const void *object)</span>
 
 	return slab_ksize(page-&gt;slab_cache);
 }
<span class="p_add">+</span>
<span class="p_add">+size_t ksize(const void *object)</span>
<span class="p_add">+{</span>
<span class="p_add">+	size_t size = __ksize(object);</span>
<span class="p_add">+	/* We assume that ksize callers could use whole allocated area,</span>
<span class="p_add">+	   so we need unpoison this area. */</span>
<span class="p_add">+	kasan_krealloc(object, size);</span>
<span class="p_add">+	return size;</span>
<span class="p_add">+}</span>
 EXPORT_SYMBOL(ksize);
 
 #ifdef CONFIG_SLUB_DEBUG
<span class="p_chunk">@@ -3351,6 +3404,7 @@</span> <span class="p_context"> void kfree(const void *x)</span>
 	if (unlikely(!PageSlab(page))) {
 		BUG_ON(!PageCompound(page));
 		kmemleak_free(x);
<span class="p_add">+		kasan_kfree_large(x);</span>
 		__free_memcg_kmem_pages(page, compound_order(page));
 		return;
 	}
<span class="p_header">diff --git a/mm/util.c b/mm/util.c</span>
<span class="p_header">index 0b17252..4b3c88b 100644</span>
<span class="p_header">--- a/mm/util.c</span>
<span class="p_header">+++ b/mm/util.c</span>
<span class="p_chunk">@@ -11,9 +11,6 @@</span> <span class="p_context"></span>
 
 #include &quot;internal.h&quot;
 
<span class="p_del">-#define CREATE_TRACE_POINTS</span>
<span class="p_del">-#include &lt;trace/events/kmem.h&gt;</span>
<span class="p_del">-</span>
 /**
  * kstrdup - allocate space for and copy an existing string
  * @s: the string to duplicate
<span class="p_chunk">@@ -107,97 +104,6 @@</span> <span class="p_context"> void *memdup_user(const void __user *src, size_t len)</span>
 }
 EXPORT_SYMBOL(memdup_user);
 
<span class="p_del">-static __always_inline void *__do_krealloc(const void *p, size_t new_size,</span>
<span class="p_del">-					   gfp_t flags)</span>
<span class="p_del">-{</span>
<span class="p_del">-	void *ret;</span>
<span class="p_del">-	size_t ks = 0;</span>
<span class="p_del">-</span>
<span class="p_del">-	if (p)</span>
<span class="p_del">-		ks = ksize(p);</span>
<span class="p_del">-</span>
<span class="p_del">-	if (ks &gt;= new_size)</span>
<span class="p_del">-		return (void *)p;</span>
<span class="p_del">-</span>
<span class="p_del">-	ret = kmalloc_track_caller(new_size, flags);</span>
<span class="p_del">-	if (ret &amp;&amp; p)</span>
<span class="p_del">-		memcpy(ret, p, ks);</span>
<span class="p_del">-</span>
<span class="p_del">-	return ret;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-/**</span>
<span class="p_del">- * __krealloc - like krealloc() but don&#39;t free @p.</span>
<span class="p_del">- * @p: object to reallocate memory for.</span>
<span class="p_del">- * @new_size: how many bytes of memory are required.</span>
<span class="p_del">- * @flags: the type of memory to allocate.</span>
<span class="p_del">- *</span>
<span class="p_del">- * This function is like krealloc() except it never frees the originally</span>
<span class="p_del">- * allocated buffer. Use this if you don&#39;t want to free the buffer immediately</span>
<span class="p_del">- * like, for example, with RCU.</span>
<span class="p_del">- */</span>
<span class="p_del">-void *__krealloc(const void *p, size_t new_size, gfp_t flags)</span>
<span class="p_del">-{</span>
<span class="p_del">-	if (unlikely(!new_size))</span>
<span class="p_del">-		return ZERO_SIZE_PTR;</span>
<span class="p_del">-</span>
<span class="p_del">-	return __do_krealloc(p, new_size, flags);</span>
<span class="p_del">-</span>
<span class="p_del">-}</span>
<span class="p_del">-EXPORT_SYMBOL(__krealloc);</span>
<span class="p_del">-</span>
<span class="p_del">-/**</span>
<span class="p_del">- * krealloc - reallocate memory. The contents will remain unchanged.</span>
<span class="p_del">- * @p: object to reallocate memory for.</span>
<span class="p_del">- * @new_size: how many bytes of memory are required.</span>
<span class="p_del">- * @flags: the type of memory to allocate.</span>
<span class="p_del">- *</span>
<span class="p_del">- * The contents of the object pointed to are preserved up to the</span>
<span class="p_del">- * lesser of the new and old sizes.  If @p is %NULL, krealloc()</span>
<span class="p_del">- * behaves exactly like kmalloc().  If @new_size is 0 and @p is not a</span>
<span class="p_del">- * %NULL pointer, the object pointed to is freed.</span>
<span class="p_del">- */</span>
<span class="p_del">-void *krealloc(const void *p, size_t new_size, gfp_t flags)</span>
<span class="p_del">-{</span>
<span class="p_del">-	void *ret;</span>
<span class="p_del">-</span>
<span class="p_del">-	if (unlikely(!new_size)) {</span>
<span class="p_del">-		kfree(p);</span>
<span class="p_del">-		return ZERO_SIZE_PTR;</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">-	ret = __do_krealloc(p, new_size, flags);</span>
<span class="p_del">-	if (ret &amp;&amp; p != ret)</span>
<span class="p_del">-		kfree(p);</span>
<span class="p_del">-</span>
<span class="p_del">-	return ret;</span>
<span class="p_del">-}</span>
<span class="p_del">-EXPORT_SYMBOL(krealloc);</span>
<span class="p_del">-</span>
<span class="p_del">-/**</span>
<span class="p_del">- * kzfree - like kfree but zero memory</span>
<span class="p_del">- * @p: object to free memory of</span>
<span class="p_del">- *</span>
<span class="p_del">- * The memory of the object @p points to is zeroed before freed.</span>
<span class="p_del">- * If @p is %NULL, kzfree() does nothing.</span>
<span class="p_del">- *</span>
<span class="p_del">- * Note: this function zeroes the whole allocated buffer which can be a good</span>
<span class="p_del">- * deal bigger than the requested buffer size passed to kmalloc(). So be</span>
<span class="p_del">- * careful when using this function in performance sensitive code.</span>
<span class="p_del">- */</span>
<span class="p_del">-void kzfree(const void *p)</span>
<span class="p_del">-{</span>
<span class="p_del">-	size_t ks;</span>
<span class="p_del">-	void *mem = (void *)p;</span>
<span class="p_del">-</span>
<span class="p_del">-	if (unlikely(ZERO_OR_NULL_PTR(mem)))</span>
<span class="p_del">-		return;</span>
<span class="p_del">-	ks = ksize(mem);</span>
<span class="p_del">-	memset(mem, 0, ks);</span>
<span class="p_del">-	kfree(mem);</span>
<span class="p_del">-}</span>
<span class="p_del">-EXPORT_SYMBOL(kzfree);</span>
<span class="p_del">-</span>
 /*
  * strndup_user - duplicate an existing string from user space
  * @s: The string to duplicate
<span class="p_chunk">@@ -400,9 +306,3 @@</span> <span class="p_context"> struct address_space *page_mapping(struct page *page)</span>
 }
 
 /* Tracepoints definitions. */
<span class="p_del">-EXPORT_TRACEPOINT_SYMBOL(kmalloc);</span>
<span class="p_del">-EXPORT_TRACEPOINT_SYMBOL(kmem_cache_alloc);</span>
<span class="p_del">-EXPORT_TRACEPOINT_SYMBOL(kmalloc_node);</span>
<span class="p_del">-EXPORT_TRACEPOINT_SYMBOL(kmem_cache_alloc_node);</span>
<span class="p_del">-EXPORT_TRACEPOINT_SYMBOL(kfree);</span>
<span class="p_del">-EXPORT_TRACEPOINT_SYMBOL(kmem_cache_free);</span>
<span class="p_header">diff --git a/mm/vmalloc.c b/mm/vmalloc.c</span>
<span class="p_header">index d456560..0c2e8f8 100644</span>
<span class="p_header">--- a/mm/vmalloc.c</span>
<span class="p_header">+++ b/mm/vmalloc.c</span>
<span class="p_chunk">@@ -31,7 +31,7 @@</span> <span class="p_context"></span>
 #include &lt;asm/uaccess.h&gt;
 #include &lt;asm/tlbflush.h&gt;
 #include &lt;asm/shmparam.h&gt;
<span class="p_del">-</span>
<span class="p_add">+#include &lt;linux/kasan.h&gt;</span>
 struct vfree_deferred {
 	struct llist_head list;
 	struct work_struct wq;
<span class="p_chunk">@@ -1285,7 +1285,7 @@</span> <span class="p_context"> void unmap_kernel_range(unsigned long addr, unsigned long size)</span>
 int map_vm_area(struct vm_struct *area, pgprot_t prot, struct page ***pages)
 {
 	unsigned long addr = (unsigned long)area-&gt;addr;
<span class="p_del">-	unsigned long end = addr + area-&gt;size - PAGE_SIZE;</span>
<span class="p_add">+	unsigned long end = addr + get_vm_area_size(area);</span>
 	int err;
 
 	err = vmap_page_range(addr, end, prot, *pages);
<span class="p_chunk">@@ -1356,10 +1356,8 @@</span> <span class="p_context"> static struct vm_struct *__get_vm_area_node(unsigned long size,</span>
 	if (unlikely(!area))
 		return NULL;
 
<span class="p_del">-	/*</span>
<span class="p_del">-	 * We always allocate a guard page.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	size += PAGE_SIZE;</span>
<span class="p_add">+	if (!(flags &amp; VM_NO_GUARD))</span>
<span class="p_add">+		size += PAGE_SIZE;</span>
 
 	va = alloc_vmap_area(size, align, start, end, node, gfp_mask);
 	if (IS_ERR(va)) {
<span class="p_chunk">@@ -1461,6 +1459,7 @@</span> <span class="p_context"> struct vm_struct *remove_vm_area(const void *addr)</span>
 		spin_unlock(&amp;vmap_area_lock);
 
 		vmap_debug_free_range(va-&gt;va_start, va-&gt;va_end);
<span class="p_add">+		kasan_free_shadow(vm);</span>
 		free_unmap_vmap_area(va);
 		vm-&gt;size -= PAGE_SIZE;
 
<span class="p_chunk">@@ -1606,7 +1605,7 @@</span> <span class="p_context"> static void *__vmalloc_area_node(struct vm_struct *area, gfp_t gfp_mask,</span>
 	unsigned int nr_pages, array_size, i;
 	gfp_t nested_gfp = (gfp_mask &amp; GFP_RECLAIM_MASK) | __GFP_ZERO;
 
<span class="p_del">-	nr_pages = (area-&gt;size - PAGE_SIZE) &gt;&gt; PAGE_SHIFT;</span>
<span class="p_add">+	nr_pages = get_vm_area_size(area) &gt;&gt; PAGE_SHIFT;</span>
 	array_size = (nr_pages * sizeof(struct page *));
 
 	area-&gt;nr_pages = nr_pages;
<span class="p_chunk">@@ -1663,6 +1662,7 @@</span> <span class="p_context"> fail:</span>
  *	@end:		vm area range end
  *	@gfp_mask:	flags for the page level allocator
  *	@prot:		protection mask for the allocated pages
<span class="p_add">+ *	@vm_flags:	additional vm area flags (e.g. %VM_NO_GUARD)</span>
  *	@node:		node to use for allocation or NUMA_NO_NODE
  *	@caller:	caller&#39;s return address
  *
<span class="p_chunk">@@ -1672,7 +1672,8 @@</span> <span class="p_context"> fail:</span>
  */
 void *__vmalloc_node_range(unsigned long size, unsigned long align,
 			unsigned long start, unsigned long end, gfp_t gfp_mask,
<span class="p_del">-			pgprot_t prot, int node, const void *caller)</span>
<span class="p_add">+			pgprot_t prot, unsigned long vm_flags, int node,</span>
<span class="p_add">+			const void *caller)</span>
 {
 	struct vm_struct *area;
 	void *addr;
<span class="p_chunk">@@ -1682,8 +1683,8 @@</span> <span class="p_context"> void *__vmalloc_node_range(unsigned long size, unsigned long align,</span>
 	if (!size || (size &gt;&gt; PAGE_SHIFT) &gt; totalram_pages)
 		goto fail;
 
<span class="p_del">-	area = __get_vm_area_node(size, align, VM_ALLOC | VM_UNLIST,</span>
<span class="p_del">-				  start, end, node, gfp_mask, caller);</span>
<span class="p_add">+	area = __get_vm_area_node(size, align, VM_ALLOC | VM_UNLIST |</span>
<span class="p_add">+				vm_flags, start, end, node, gfp_mask, caller);</span>
 	if (!area)
 		goto fail;
 
<span class="p_chunk">@@ -1732,7 +1733,7 @@</span> <span class="p_context"> static void *__vmalloc_node(unsigned long size, unsigned long align,</span>
 			    int node, const void *caller)
 {
 	return __vmalloc_node_range(size, align, VMALLOC_START, VMALLOC_END,
<span class="p_del">-				gfp_mask, prot, node, caller);</span>
<span class="p_add">+				gfp_mask, prot, 0, node, caller);</span>
 }
 
 void *__vmalloc(unsigned long size, gfp_t gfp_mask, pgprot_t prot)
<span class="p_chunk">@@ -2038,7 +2039,7 @@</span> <span class="p_context"> long vread(char *buf, char *addr, unsigned long count)</span>
 
 		vm = va-&gt;vm;
 		vaddr = (char *) vm-&gt;addr;
<span class="p_del">-		if (addr &gt;= vaddr + vm-&gt;size - PAGE_SIZE)</span>
<span class="p_add">+		if (addr &gt;= vaddr + get_vm_area_size(vm))</span>
 			continue;
 		while (addr &lt; vaddr) {
 			if (count == 0)
<span class="p_chunk">@@ -2048,7 +2049,7 @@</span> <span class="p_context"> long vread(char *buf, char *addr, unsigned long count)</span>
 			addr++;
 			count--;
 		}
<span class="p_del">-		n = vaddr + vm-&gt;size - PAGE_SIZE - addr;</span>
<span class="p_add">+		n = vaddr + get_vm_area_size(vm) - addr;</span>
 		if (n &gt; count)
 			n = count;
 		if (!(vm-&gt;flags &amp; VM_IOREMAP))
<span class="p_chunk">@@ -2120,7 +2121,7 @@</span> <span class="p_context"> long vwrite(char *buf, char *addr, unsigned long count)</span>
 
 		vm = va-&gt;vm;
 		vaddr = (char *) vm-&gt;addr;
<span class="p_del">-		if (addr &gt;= vaddr + vm-&gt;size - PAGE_SIZE)</span>
<span class="p_add">+		if (addr &gt;= vaddr + get_vm_area_size(vm))</span>
 			continue;
 		while (addr &lt; vaddr) {
 			if (count == 0)
<span class="p_chunk">@@ -2129,7 +2130,7 @@</span> <span class="p_context"> long vwrite(char *buf, char *addr, unsigned long count)</span>
 			addr++;
 			count--;
 		}
<span class="p_del">-		n = vaddr + vm-&gt;size - PAGE_SIZE - addr;</span>
<span class="p_add">+		n = vaddr + get_vm_area_size(vm) - addr;</span>
 		if (n &gt; count)
 			n = count;
 		if (!(vm-&gt;flags &amp; VM_IOREMAP)) {
<span class="p_header">diff --git a/scripts/Makefile.kasan b/scripts/Makefile.kasan</span>
new file mode 100644
<span class="p_header">index 0000000..3f874d2</span>
<span class="p_header">--- /dev/null</span>
<span class="p_header">+++ b/scripts/Makefile.kasan</span>
<span class="p_chunk">@@ -0,0 +1,29 @@</span> <span class="p_context"></span>
<span class="p_add">+ifdef CONFIG_KASAN</span>
<span class="p_add">+ifdef CONFIG_KASAN_INLINE</span>
<span class="p_add">+	call_threshold := 10000</span>
<span class="p_add">+else</span>
<span class="p_add">+	call_threshold := 0</span>
<span class="p_add">+endif</span>
<span class="p_add">+</span>
<span class="p_add">+CFLAGS_KASAN_MINIMAL := -fsanitize=kernel-address</span>
<span class="p_add">+</span>
<span class="p_add">+CFLAGS_KASAN := $(call cc-option, -fsanitize=kernel-address \</span>
<span class="p_add">+		-fasan-shadow-offset=$(CONFIG_KASAN_SHADOW_OFFSET) \</span>
<span class="p_add">+		--param asan-stack=1 --param asan-globals=1 \</span>
<span class="p_add">+		--param asan-instrumentation-with-call-threshold=$(call_threshold))</span>
<span class="p_add">+</span>
<span class="p_add">+ifeq ($(call cc-option, $(CFLAGS_KASAN_MINIMAL) -Werror),)</span>
<span class="p_add">+   ifneq ($(CONFIG_COMPILE_TEST),y)</span>
<span class="p_add">+        $(warning Cannot use CONFIG_KASAN: \</span>
<span class="p_add">+            -fsanitize=kernel-address is not supported by compiler)</span>
<span class="p_add">+   endif</span>
<span class="p_add">+else</span>
<span class="p_add">+    ifeq ($(CFLAGS_KASAN),)</span>
<span class="p_add">+        ifneq ($(CONFIG_COMPILE_TEST),y)</span>
<span class="p_add">+            $(warning CONFIG_KASAN: compiler does not support all options.\</span>
<span class="p_add">+                Trying minimal configuration)</span>
<span class="p_add">+        endif</span>
<span class="p_add">+        CFLAGS_KASAN := $(CFLAGS_KASAN_MINIMAL)</span>
<span class="p_add">+    endif</span>
<span class="p_add">+endif</span>
<span class="p_add">+endif</span>
<span class="p_header">diff --git a/scripts/Makefile.lib b/scripts/Makefile.lib</span>
<span class="p_header">index f97869f..b188171 100644</span>
<span class="p_header">--- a/scripts/Makefile.lib</span>
<span class="p_header">+++ b/scripts/Makefile.lib</span>
<span class="p_chunk">@@ -119,6 +119,16 @@</span> <span class="p_context"> _c_flags += $(if $(patsubst n%,, \</span>
 		$(CFLAGS_GCOV))
 endif
 
<span class="p_add">+#</span>
<span class="p_add">+# Enable address sanitizer flags for kernel except some files or directories</span>
<span class="p_add">+# we don&#39;t want to check (depends on variables KASAN_SANITIZE_obj.o, KASAN_SANITIZE)</span>
<span class="p_add">+#</span>
<span class="p_add">+ifeq ($(CONFIG_KASAN),y)</span>
<span class="p_add">+_c_flags += $(if $(patsubst n%,, \</span>
<span class="p_add">+		$(KASAN_SANITIZE_$(basetarget).o)$(KASAN_SANITIZE)y), \</span>
<span class="p_add">+		$(CFLAGS_KASAN))</span>
<span class="p_add">+endif</span>
<span class="p_add">+</span>
 # If building the kernel in a separate objtree expand all occurrences
 # of -Idir to -I$(srctree)/dir except for absolute paths (starting with &#39;/&#39;).
 
<span class="p_header">diff --git a/scripts/module-common.lds b/scripts/module-common.lds</span>
<span class="p_header">index 0865b3e..10fa8bf 100644</span>
<span class="p_header">--- a/scripts/module-common.lds</span>
<span class="p_header">+++ b/scripts/module-common.lds</span>
<span class="p_chunk">@@ -16,4 +16,8 @@</span> <span class="p_context"> SECTIONS {</span>
 	__kcrctab_unused	: { *(SORT(___kcrctab_unused+*)) }
 	__kcrctab_unused_gpl	: { *(SORT(___kcrctab_unused_gpl+*)) }
 	__kcrctab_gpl_future	: { *(SORT(___kcrctab_gpl_future+*)) }
<span class="p_add">+</span>
<span class="p_add">+</span>
<span class="p_add">+	. = ALIGN(8);</span>
<span class="p_add">+	.init_array		0 : { *(SORT(.init_array.*)) *(.init_array) }</span>
 }

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



