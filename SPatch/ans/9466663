
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>[RFC,PATCHv1,23/28] x86/mm: add support of additional page table level during early boot - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    [RFC,PATCHv1,23/28] x86/mm: add support of additional page table level during early boot</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=40781">Kirill A. Shutemov</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>Dec. 8, 2016, 4:21 p.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;20161208162150.148763-25-kirill.shutemov@linux.intel.com&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/9466663/mbox/"
   >mbox</a>
|
   <a href="/patch/9466663/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/9466663/">/patch/9466663/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
	[172.30.200.125])
	by pdx-korg-patchwork.web.codeaurora.org (Postfix) with ESMTP id
	335AA6071E for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Thu,  8 Dec 2016 16:27:51 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 21C3C285C4
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Thu,  8 Dec 2016 16:27:51 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id 1691E285C9; Thu,  8 Dec 2016 16:27:51 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-6.9 required=2.0 tests=BAYES_00,RCVD_IN_DNSWL_HI
	autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 13B2B285C6
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Thu,  8 Dec 2016 16:27:49 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S932817AbcLHQ1C (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Thu, 8 Dec 2016 11:27:02 -0500
Received: from mga03.intel.com ([134.134.136.65]:28580 &quot;EHLO mga03.intel.com&quot;
	rhost-flags-OK-OK-OK-OK) by vger.kernel.org with ESMTP
	id S932631AbcLHQWg (ORCPT &lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Thu, 8 Dec 2016 11:22:36 -0500
Received: from fmsmga004.fm.intel.com ([10.253.24.48])
	by orsmga103.jf.intel.com with ESMTP; 08 Dec 2016 08:22:35 -0800
X-ExtLoop1: 1
X-IronPort-AV: E=Sophos;i=&quot;5.33,320,1477983600&quot;; d=&quot;scan&#39;208&quot;;a=&quot;200496259&quot;
Received: from black.fi.intel.com ([10.237.72.28])
	by fmsmga004.fm.intel.com with ESMTP; 08 Dec 2016 08:22:32 -0800
Received: by black.fi.intel.com (Postfix, from userid 1000)
	id 1A024839; Thu,  8 Dec 2016 18:22:15 +0200 (EET)
From: &quot;Kirill A. Shutemov&quot; &lt;kirill.shutemov@linux.intel.com&gt;
To: Linus Torvalds &lt;torvalds@linux-foundation.org&gt;,
	Andrew Morton &lt;akpm@linux-foundation.org&gt;, x86@kernel.org,
	Thomas Gleixner &lt;tglx@linutronix.de&gt;,
	Ingo Molnar &lt;mingo@redhat.com&gt;, Arnd Bergmann &lt;arnd@arndb.de&gt;,
	&quot;H. Peter Anvin&quot; &lt;hpa@zytor.com&gt;
Cc: Andi Kleen &lt;ak@linux.intel.com&gt;, Dave Hansen &lt;dave.hansen@intel.com&gt;,
	Andy Lutomirski &lt;luto@amacapital.net&gt;,
	linux-arch@vger.kernel.org, linux-mm@kvack.org,
	linux-kernel@vger.kernel.org,
	&quot;Kirill A. Shutemov&quot; &lt;kirill.shutemov@linux.intel.com&gt;
Subject: [RFC,
	PATCHv1 23/28] x86/mm: add support of additional page table level
	during early boot
Date: Thu,  8 Dec 2016 19:21:45 +0300
Message-Id: &lt;20161208162150.148763-25-kirill.shutemov@linux.intel.com&gt;
X-Mailer: git-send-email 2.10.2
In-Reply-To: &lt;20161208162150.148763-1-kirill.shutemov@linux.intel.com&gt;
References: &lt;20161208162150.148763-1-kirill.shutemov@linux.intel.com&gt;
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=40781">Kirill A. Shutemov</a> - Dec. 8, 2016, 4:21 p.m.</div>
<pre class="content">
This patch adds support for 5-level paging during early boot.
It generalizes boot for 4- and 5-level paging on 64-bit systems with
compile-time switch between them.

TODO: XEN support is missing

Not-yet-Signed-off-by: Kirill A. Shutemov &lt;kirill.shutemov@linux.intel.com&gt;
---
 arch/x86/boot/compressed/head_64.S          | 23 ++++++++++--
 arch/x86/include/asm/pgtable.h              |  2 +-
 arch/x86/include/asm/pgtable_64.h           |  6 ++-
 arch/x86/include/uapi/asm/processor-flags.h |  2 +
 arch/x86/kernel/espfix_64.c                 |  2 +-
 arch/x86/kernel/head64.c                    | 40 ++++++++++++++------
 arch/x86/kernel/head_64.S                   | 58 ++++++++++++++++++++++-------
 arch/x86/kernel/machine_kexec_64.c          |  2 +-
 arch/x86/mm/dump_pagetables.c               |  2 +-
 arch/x86/mm/kasan_init_64.c                 | 12 +++---
 arch/x86/realmode/init.c                    |  2 +-
 11 files changed, 110 insertions(+), 41 deletions(-)
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/arch/x86/boot/compressed/head_64.S b/arch/x86/boot/compressed/head_64.S</span>
<span class="p_header">index 0d80a7ad65cd..725c5ee939d1 100644</span>
<span class="p_header">--- a/arch/x86/boot/compressed/head_64.S</span>
<span class="p_header">+++ b/arch/x86/boot/compressed/head_64.S</span>
<span class="p_chunk">@@ -123,9 +123,12 @@</span> <span class="p_context"> ENTRY(startup_32)</span>
 	movl	%eax, gdt+2(%ebp)
 	lgdt	gdt(%ebp)
 
<span class="p_del">-	/* Enable PAE mode */</span>
<span class="p_add">+	/* Enable PAE and LA57 mode */</span>
 	movl	%cr4, %eax
 	orl	$X86_CR4_PAE, %eax
<span class="p_add">+#ifdef CONFIG_X86_5LEVEL</span>
<span class="p_add">+	orl	$X86_CR4_LA57, %eax</span>
<span class="p_add">+#endif</span>
 	movl	%eax, %cr4
 
  /*
<span class="p_chunk">@@ -137,13 +140,24 @@</span> <span class="p_context"> ENTRY(startup_32)</span>
 	movl	$(BOOT_INIT_PGT_SIZE/4), %ecx
 	rep	stosl
 
<span class="p_add">+	xorl	%edx, %edx</span>
<span class="p_add">+</span>
<span class="p_add">+	/* Build Top Level */</span>
<span class="p_add">+	leal	pgtable(%ebx,%edx,1), %edi</span>
<span class="p_add">+	leal	0x1007 (%edi), %eax</span>
<span class="p_add">+	movl	%eax, 0(%edi)</span>
<span class="p_add">+</span>
<span class="p_add">+#ifdef CONFIG_X86_5LEVEL</span>
 	/* Build Level 4 */
<span class="p_del">-	leal	pgtable + 0(%ebx), %edi</span>
<span class="p_add">+	addl	$0x1000, %edx</span>
<span class="p_add">+	leal	pgtable(%ebx,%edx), %edi</span>
 	leal	0x1007 (%edi), %eax
 	movl	%eax, 0(%edi)
<span class="p_add">+#endif</span>
 
 	/* Build Level 3 */
<span class="p_del">-	leal	pgtable + 0x1000(%ebx), %edi</span>
<span class="p_add">+	addl	$0x1000, %edx</span>
<span class="p_add">+	leal	pgtable(%ebx,%edx), %edi</span>
 	leal	0x1007(%edi), %eax
 	movl	$4, %ecx
 1:	movl	%eax, 0x00(%edi)
<span class="p_chunk">@@ -153,7 +167,8 @@</span> <span class="p_context"> ENTRY(startup_32)</span>
 	jnz	1b
 
 	/* Build Level 2 */
<span class="p_del">-	leal	pgtable + 0x2000(%ebx), %edi</span>
<span class="p_add">+	addl	$0x1000, %edx</span>
<span class="p_add">+	leal	pgtable(%ebx,%edx), %edi</span>
 	movl	$0x00000183, %eax
 	movl	$2048, %ecx
 1:	movl	%eax, 0(%edi)
<span class="p_header">diff --git a/arch/x86/include/asm/pgtable.h b/arch/x86/include/asm/pgtable.h</span>
<span class="p_header">index 398adab9a167..8992f0a9ea3a 100644</span>
<span class="p_header">--- a/arch/x86/include/asm/pgtable.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/pgtable.h</span>
<span class="p_chunk">@@ -813,7 +813,7 @@</span> <span class="p_context"> extern pgd_t trampoline_pgd_entry;</span>
 static inline void __meminit init_trampoline_default(void)
 {
 	/* Default trampoline pgd value */
<span class="p_del">-	trampoline_pgd_entry = init_level4_pgt[pgd_index(__PAGE_OFFSET)];</span>
<span class="p_add">+	trampoline_pgd_entry = init_top_pgt[pgd_index(__PAGE_OFFSET)];</span>
 }
 # ifdef CONFIG_RANDOMIZE_MEMORY
 void __meminit init_trampoline(void);
<span class="p_header">diff --git a/arch/x86/include/asm/pgtable_64.h b/arch/x86/include/asm/pgtable_64.h</span>
<span class="p_header">index bfe276e9af1e..eab09641ef3f 100644</span>
<span class="p_header">--- a/arch/x86/include/asm/pgtable_64.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/pgtable_64.h</span>
<span class="p_chunk">@@ -14,15 +14,17 @@</span> <span class="p_context"></span>
 #include &lt;linux/bitops.h&gt;
 #include &lt;linux/threads.h&gt;
 
<span class="p_add">+extern p4d_t level4_kernel_pgt[512];</span>
<span class="p_add">+extern p4d_t level4_ident_pgt[512];</span>
 extern pud_t level3_kernel_pgt[512];
 extern pud_t level3_ident_pgt[512];
 extern pmd_t level2_kernel_pgt[512];
 extern pmd_t level2_fixmap_pgt[512];
 extern pmd_t level2_ident_pgt[512];
 extern pte_t level1_fixmap_pgt[512];
<span class="p_del">-extern pgd_t init_level4_pgt[];</span>
<span class="p_add">+extern pgd_t init_top_pgt[];</span>
 
<span class="p_del">-#define swapper_pg_dir init_level4_pgt</span>
<span class="p_add">+#define swapper_pg_dir init_top_pgt</span>
 
 extern void paging_init(void);
 
<span class="p_header">diff --git a/arch/x86/include/uapi/asm/processor-flags.h b/arch/x86/include/uapi/asm/processor-flags.h</span>
<span class="p_header">index 567de50a4c2a..185f3d10c194 100644</span>
<span class="p_header">--- a/arch/x86/include/uapi/asm/processor-flags.h</span>
<span class="p_header">+++ b/arch/x86/include/uapi/asm/processor-flags.h</span>
<span class="p_chunk">@@ -104,6 +104,8 @@</span> <span class="p_context"></span>
 #define X86_CR4_OSFXSR		_BITUL(X86_CR4_OSFXSR_BIT)
 #define X86_CR4_OSXMMEXCPT_BIT	10 /* enable unmasked SSE exceptions */
 #define X86_CR4_OSXMMEXCPT	_BITUL(X86_CR4_OSXMMEXCPT_BIT)
<span class="p_add">+#define X86_CR4_LA57_BIT	12 /* enable 5-level page tables */</span>
<span class="p_add">+#define X86_CR4_LA57		_BITUL(X86_CR4_LA57_BIT)</span>
 #define X86_CR4_VMXE_BIT	13 /* enable VMX virtualization */
 #define X86_CR4_VMXE		_BITUL(X86_CR4_VMXE_BIT)
 #define X86_CR4_SMXE_BIT	14 /* enable safer mode (TXT) */
<span class="p_header">diff --git a/arch/x86/kernel/espfix_64.c b/arch/x86/kernel/espfix_64.c</span>
<span class="p_header">index f0afa0af4237..e6838b12414b 100644</span>
<span class="p_header">--- a/arch/x86/kernel/espfix_64.c</span>
<span class="p_header">+++ b/arch/x86/kernel/espfix_64.c</span>
<span class="p_chunk">@@ -134,7 +134,7 @@</span> <span class="p_context"> void __init init_espfix_bsp(void)</span>
 	p4d_t *p4d;
 
 	/* Install the espfix pud into the kernel page directory */
<span class="p_del">-	pgd_p = &amp;init_level4_pgt[pgd_index(ESPFIX_BASE_ADDR)];</span>
<span class="p_add">+	pgd_p = &amp;init_top_pgt[pgd_index(ESPFIX_BASE_ADDR)];</span>
 	switch (CONFIG_PGTABLE_LEVELS) {
 	case 4:
 		p4d = p4d_offset(pgd_p, ESPFIX_BASE_ADDR);
<span class="p_header">diff --git a/arch/x86/kernel/head64.c b/arch/x86/kernel/head64.c</span>
<span class="p_header">index 54a2372f5dbb..f32d22986f47 100644</span>
<span class="p_header">--- a/arch/x86/kernel/head64.c</span>
<span class="p_header">+++ b/arch/x86/kernel/head64.c</span>
<span class="p_chunk">@@ -32,7 +32,7 @@</span> <span class="p_context"></span>
 /*
  * Manage page tables very early on.
  */
<span class="p_del">-extern pgd_t early_level4_pgt[PTRS_PER_PGD];</span>
<span class="p_add">+extern pgd_t early_top_pgt[PTRS_PER_PGD];</span>
 extern pmd_t early_dynamic_pgts[EARLY_DYNAMIC_PAGE_TABLES][PTRS_PER_PMD];
 static unsigned int __initdata next_early_pgt = 2;
 pmdval_t early_pmd_flags = __PAGE_KERNEL_LARGE &amp; ~(_PAGE_GLOBAL | _PAGE_NX);
<span class="p_chunk">@@ -40,9 +40,9 @@</span> <span class="p_context"> pmdval_t early_pmd_flags = __PAGE_KERNEL_LARGE &amp; ~(_PAGE_GLOBAL | _PAGE_NX);</span>
 /* Wipe all early page tables except for the kernel symbol map */
 static void __init reset_early_page_tables(void)
 {
<span class="p_del">-	memset(early_level4_pgt, 0, sizeof(pgd_t)*(PTRS_PER_PGD-1));</span>
<span class="p_add">+	memset(early_top_pgt, 0, sizeof(pgd_t)*(PTRS_PER_PGD-1));</span>
 	next_early_pgt = 0;
<span class="p_del">-	write_cr3(__pa_nodebug(early_level4_pgt));</span>
<span class="p_add">+	write_cr3(__pa_nodebug(early_top_pgt));</span>
 }
 
 /* Create a new PMD entry */
<span class="p_chunk">@@ -50,15 +50,16 @@</span> <span class="p_context"> int __init early_make_pgtable(unsigned long address)</span>
 {
 	unsigned long physaddr = address - __PAGE_OFFSET;
 	pgdval_t pgd, *pgd_p;
<span class="p_add">+	p4dval_t p4d, *p4d_p;</span>
 	pudval_t pud, *pud_p;
 	pmdval_t pmd, *pmd_p;
 
 	/* Invalid address or early pgt is done ?  */
<span class="p_del">-	if (physaddr &gt;= MAXMEM || read_cr3() != __pa_nodebug(early_level4_pgt))</span>
<span class="p_add">+	if (physaddr &gt;= MAXMEM || read_cr3() != __pa_nodebug(early_top_pgt))</span>
 		return -1;
 
 again:
<span class="p_del">-	pgd_p = &amp;early_level4_pgt[pgd_index(address)].pgd;</span>
<span class="p_add">+	pgd_p = &amp;early_top_pgt[pgd_index(address)].pgd;</span>
 	pgd = *pgd_p;
 
 	/*
<span class="p_chunk">@@ -66,8 +67,25 @@</span> <span class="p_context"> again:</span>
 	 * critical -- __PAGE_OFFSET would point us back into the dynamic
 	 * range and we might end up looping forever...
 	 */
<span class="p_del">-	if (pgd)</span>
<span class="p_del">-		pud_p = (pudval_t *)((pgd &amp; PTE_PFN_MASK) + __START_KERNEL_map - phys_base);</span>
<span class="p_add">+	if (!IS_ENABLED(CONFIG_X86_5LEVEL))</span>
<span class="p_add">+		p4d_p = pgd_p;</span>
<span class="p_add">+	else if (pgd)</span>
<span class="p_add">+		p4d_p = (p4dval_t *)((pgd &amp; PTE_PFN_MASK) + __START_KERNEL_map - phys_base);</span>
<span class="p_add">+	else {</span>
<span class="p_add">+		if (next_early_pgt &gt;= EARLY_DYNAMIC_PAGE_TABLES) {</span>
<span class="p_add">+			reset_early_page_tables();</span>
<span class="p_add">+			goto again;</span>
<span class="p_add">+		}</span>
<span class="p_add">+</span>
<span class="p_add">+		p4d_p = (p4dval_t *)early_dynamic_pgts[next_early_pgt++];</span>
<span class="p_add">+		memset(p4d_p, 0, sizeof(*p4d_p) * PTRS_PER_P4D);</span>
<span class="p_add">+		*pgd_p = (pgdval_t)p4d_p - __START_KERNEL_map + phys_base + _KERNPG_TABLE;</span>
<span class="p_add">+	}</span>
<span class="p_add">+	p4d_p += p4d_index(address);</span>
<span class="p_add">+	p4d = *p4d_p;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (p4d)</span>
<span class="p_add">+		pud_p = (pudval_t *)((p4d &amp; PTE_PFN_MASK) + __START_KERNEL_map - phys_base);</span>
 	else {
 		if (next_early_pgt &gt;= EARLY_DYNAMIC_PAGE_TABLES) {
 			reset_early_page_tables();
<span class="p_chunk">@@ -76,7 +94,7 @@</span> <span class="p_context"> again:</span>
 
 		pud_p = (pudval_t *)early_dynamic_pgts[next_early_pgt++];
 		memset(pud_p, 0, sizeof(*pud_p) * PTRS_PER_PUD);
<span class="p_del">-		*pgd_p = (pgdval_t)pud_p - __START_KERNEL_map + phys_base + _KERNPG_TABLE;</span>
<span class="p_add">+		*p4d_p = (p4dval_t)pud_p - __START_KERNEL_map + phys_base + _KERNPG_TABLE;</span>
 	}
 	pud_p += pud_index(address);
 	pud = *pud_p;
<span class="p_chunk">@@ -155,7 +173,7 @@</span> <span class="p_context"> asmlinkage __visible void __init x86_64_start_kernel(char * real_mode_data)</span>
 
 	clear_bss();
 
<span class="p_del">-	clear_page(init_level4_pgt);</span>
<span class="p_add">+	clear_page(init_top_pgt);</span>
 
 	kasan_early_init();
 
<span class="p_chunk">@@ -170,8 +188,8 @@</span> <span class="p_context"> asmlinkage __visible void __init x86_64_start_kernel(char * real_mode_data)</span>
 	 */
 	load_ucode_bsp();
 
<span class="p_del">-	/* set init_level4_pgt kernel high mapping*/</span>
<span class="p_del">-	init_level4_pgt[511] = early_level4_pgt[511];</span>
<span class="p_add">+	/* set init_top_pgt kernel high mapping*/</span>
<span class="p_add">+	init_top_pgt[511] = early_top_pgt[511];</span>
 
 	x86_64_start_reservations(real_mode_data);
 }
<span class="p_header">diff --git a/arch/x86/kernel/head_64.S b/arch/x86/kernel/head_64.S</span>
<span class="p_header">index 9f8efc9f0075..e1189003db50 100644</span>
<span class="p_header">--- a/arch/x86/kernel/head_64.S</span>
<span class="p_header">+++ b/arch/x86/kernel/head_64.S</span>
<span class="p_chunk">@@ -36,10 +36,14 @@</span> <span class="p_context"></span>
  *
  */
 
<span class="p_add">+#define p4d_index(x)	(((x) &gt;&gt; P4D_SHIFT) &amp; (PTRS_PER_P4D-1))</span>
 #define pud_index(x)	(((x) &gt;&gt; PUD_SHIFT) &amp; (PTRS_PER_PUD-1))
 
<span class="p_del">-L4_PAGE_OFFSET = pgd_index(__PAGE_OFFSET_BASE)</span>
<span class="p_del">-L4_START_KERNEL = pgd_index(__START_KERNEL_map)</span>
<span class="p_add">+PGD_PAGE_OFFSET = pgd_index(__PAGE_OFFSET_BASE)</span>
<span class="p_add">+PGD_START_KERNEL = pgd_index(__START_KERNEL_map)</span>
<span class="p_add">+#ifdef CONFIG_X86_5LEVEL</span>
<span class="p_add">+L4_START_KERNEL = p4d_index(__START_KERNEL_map)</span>
<span class="p_add">+#endif</span>
 L3_START_KERNEL = pud_index(__START_KERNEL_map)
 
 	.text
<span class="p_chunk">@@ -97,7 +101,11 @@</span> <span class="p_context"> startup_64:</span>
 	/*
 	 * Fixup the physical addresses in the page table
 	 */
<span class="p_del">-	addq	%rbp, early_level4_pgt + (L4_START_KERNEL*8)(%rip)</span>
<span class="p_add">+	addq	%rbp, early_top_pgt + (PGD_START_KERNEL*8)(%rip)</span>
<span class="p_add">+</span>
<span class="p_add">+#ifdef CONFIG_X86_5LEVEL</span>
<span class="p_add">+	addq	%rbp, level4_kernel_pgt + (511*8)(%rip)</span>
<span class="p_add">+#endif</span>
 
 	addq	%rbp, level3_kernel_pgt + (510*8)(%rip)
 	addq	%rbp, level3_kernel_pgt + (511*8)(%rip)
<span class="p_chunk">@@ -111,7 +119,7 @@</span> <span class="p_context"> startup_64:</span>
 	 * it avoids problems around wraparound.
 	 */
 	leaq	_text(%rip), %rdi
<span class="p_del">-	leaq	early_level4_pgt(%rip), %rbx</span>
<span class="p_add">+	leaq	early_top_pgt(%rip), %rbx</span>
 
 	movq	%rdi, %rax
 	shrq	$PGDIR_SHIFT, %rax
<span class="p_chunk">@@ -120,16 +128,26 @@</span> <span class="p_context"> startup_64:</span>
 	movq	%rdx, 0(%rbx,%rax,8)
 	movq	%rdx, 8(%rbx,%rax,8)
 
<span class="p_add">+#ifdef CONFIG_X86_5LEVEL</span>
<span class="p_add">+	addq	$4096, %rbx</span>
<span class="p_add">+	addq	$4096, %rdx</span>
<span class="p_add">+	movq	%rdi, %rax</span>
<span class="p_add">+	shrq	$P4D_SHIFT, %rax</span>
<span class="p_add">+	andl	$(PTRS_PER_P4D-1), %eax</span>
<span class="p_add">+	movq	%rdx, 0(%rbx,%rax,8)</span>
<span class="p_add">+#endif</span>
<span class="p_add">+</span>
<span class="p_add">+	addq	$4096, %rbx</span>
 	addq	$4096, %rdx
 	movq	%rdi, %rax
 	shrq	$PUD_SHIFT, %rax
 	andl	$(PTRS_PER_PUD-1), %eax
<span class="p_del">-	movq	%rdx, 4096(%rbx,%rax,8)</span>
<span class="p_add">+	movq	%rdx, 0(%rbx,%rax,8)</span>
 	incl	%eax
 	andl	$(PTRS_PER_PUD-1), %eax
<span class="p_del">-	movq	%rdx, 4096(%rbx,%rax,8)</span>
<span class="p_add">+	movq	%rdx, 0(%rbx,%rax,8)</span>
 
<span class="p_del">-	addq	$8192, %rbx</span>
<span class="p_add">+	addq	$4096, %rbx</span>
 	movq	%rdi, %rax
 	shrq	$PMD_SHIFT, %rdi
 	addq	$(__PAGE_KERNEL_LARGE_EXEC &amp; ~_PAGE_GLOBAL), %rax
<span class="p_chunk">@@ -166,7 +184,7 @@</span> <span class="p_context"> startup_64:</span>
 	/* Fixup phys_base */
 	addq	%rbp, phys_base(%rip)
 
<span class="p_del">-	movq	$(early_level4_pgt - __START_KERNEL_map), %rax</span>
<span class="p_add">+	movq	$(early_top_pgt - __START_KERNEL_map), %rax</span>
 	jmp 1f
 ENTRY(secondary_startup_64)
 	/*
<span class="p_chunk">@@ -186,14 +204,17 @@</span> <span class="p_context"> ENTRY(secondary_startup_64)</span>
 	/* Sanitize CPU configuration */
 	call verify_cpu
 
<span class="p_del">-	movq	$(init_level4_pgt - __START_KERNEL_map), %rax</span>
<span class="p_add">+	movq	$(init_top_pgt - __START_KERNEL_map), %rax</span>
 1:
 
<span class="p_del">-	/* Enable PAE mode and PGE */</span>
<span class="p_add">+	/* Enable PAE mode, PGE and LA57 */</span>
 	movl	$(X86_CR4_PAE | X86_CR4_PGE), %ecx
<span class="p_add">+#ifdef CONFIG_X86_5LEVEL</span>
<span class="p_add">+	orl	$X86_CR4_LA57, %ecx</span>
<span class="p_add">+#endif</span>
 	movq	%rcx, %cr4
 
<span class="p_del">-	/* Setup early boot stage 4 level pagetables. */</span>
<span class="p_add">+	/* Setup early boot stage 4-/5-level pagetables. */</span>
 	addq	phys_base(%rip), %rax
 	movq	%rax, %cr3
 
<span class="p_chunk">@@ -415,9 +436,13 @@</span> <span class="p_context"> GLOBAL(name)</span>
 	.endr
 
 	__INITDATA
<span class="p_del">-NEXT_PAGE(early_level4_pgt)</span>
<span class="p_add">+NEXT_PAGE(early_top_pgt)</span>
 	.fill	511,8,0
<span class="p_add">+#ifdef CONFIG_X86_5LEVEL</span>
<span class="p_add">+	.quad	level4_kernel_pgt - __START_KERNEL_map + _PAGE_TABLE</span>
<span class="p_add">+#else</span>
 	.quad	level3_kernel_pgt - __START_KERNEL_map + _PAGE_TABLE
<span class="p_add">+#endif</span>
 
 NEXT_PAGE(early_dynamic_pgts)
 	.fill	512*EARLY_DYNAMIC_PAGE_TABLES,8,0
<span class="p_chunk">@@ -425,9 +450,10 @@</span> <span class="p_context"> NEXT_PAGE(early_dynamic_pgts)</span>
 	.data
 
 #ifndef CONFIG_XEN
<span class="p_del">-NEXT_PAGE(init_level4_pgt)</span>
<span class="p_add">+NEXT_PAGE(init_top_pgt)</span>
 	.fill	512,8,0
 #else
<span class="p_add">+#error FIXME</span>
 NEXT_PAGE(init_level4_pgt)
 	.quad   level3_ident_pgt - __START_KERNEL_map + _KERNPG_TABLE
 	.org    init_level4_pgt + L4_PAGE_OFFSET*8, 0
<span class="p_chunk">@@ -446,6 +472,12 @@</span> <span class="p_context"> NEXT_PAGE(level2_ident_pgt)</span>
 	PMDS(0, __PAGE_KERNEL_IDENT_LARGE_EXEC, PTRS_PER_PMD)
 #endif
 
<span class="p_add">+#ifdef CONFIG_X86_5LEVEL</span>
<span class="p_add">+NEXT_PAGE(level4_kernel_pgt)</span>
<span class="p_add">+	.fill	511,8,0</span>
<span class="p_add">+	.quad	level3_kernel_pgt - __START_KERNEL_map + _PAGE_TABLE</span>
<span class="p_add">+#endif</span>
<span class="p_add">+</span>
 NEXT_PAGE(level3_kernel_pgt)
 	.fill	L3_START_KERNEL,8,0
 	/* (2^48-(2*1024*1024*1024)-((2^39)*511))/(2^30) = 510 */
<span class="p_header">diff --git a/arch/x86/kernel/machine_kexec_64.c b/arch/x86/kernel/machine_kexec_64.c</span>
<span class="p_header">index 0a44cf20f939..f9bf209b826c 100644</span>
<span class="p_header">--- a/arch/x86/kernel/machine_kexec_64.c</span>
<span class="p_header">+++ b/arch/x86/kernel/machine_kexec_64.c</span>
<span class="p_chunk">@@ -339,7 +339,7 @@</span> <span class="p_context"> void machine_kexec(struct kimage *image)</span>
 void arch_crash_save_vmcoreinfo(void)
 {
 	VMCOREINFO_SYMBOL(phys_base);
<span class="p_del">-	VMCOREINFO_SYMBOL(init_level4_pgt);</span>
<span class="p_add">+	VMCOREINFO_SYMBOL(init_top_pgt);</span>
 
 #ifdef CONFIG_NUMA
 	VMCOREINFO_SYMBOL(node_data);
<span class="p_header">diff --git a/arch/x86/mm/dump_pagetables.c b/arch/x86/mm/dump_pagetables.c</span>
<span class="p_header">index 15670b55861b..495ab353d576 100644</span>
<span class="p_header">--- a/arch/x86/mm/dump_pagetables.c</span>
<span class="p_header">+++ b/arch/x86/mm/dump_pagetables.c</span>
<span class="p_chunk">@@ -411,7 +411,7 @@</span> <span class="p_context"> static void ptdump_walk_pgd_level_core(struct seq_file *m, pgd_t *pgd,</span>
 				       bool checkwx)
 {
 #ifdef CONFIG_X86_64
<span class="p_del">-	pgd_t *start = (pgd_t *) &amp;init_level4_pgt;</span>
<span class="p_add">+	pgd_t *start = (pgd_t *) &amp;init_top_pgt;</span>
 #else
 	pgd_t *start = swapper_pg_dir;
 #endif
<span class="p_header">diff --git a/arch/x86/mm/kasan_init_64.c b/arch/x86/mm/kasan_init_64.c</span>
<span class="p_header">index e37504e94e8f..2d754cc4e02f 100644</span>
<span class="p_header">--- a/arch/x86/mm/kasan_init_64.c</span>
<span class="p_header">+++ b/arch/x86/mm/kasan_init_64.c</span>
<span class="p_chunk">@@ -9,7 +9,7 @@</span> <span class="p_context"></span>
 #include &lt;asm/tlbflush.h&gt;
 #include &lt;asm/sections.h&gt;
 
<span class="p_del">-extern pgd_t early_level4_pgt[PTRS_PER_PGD];</span>
<span class="p_add">+extern pgd_t early_top_pgt[PTRS_PER_PGD];</span>
 extern struct range pfn_mapped[E820_X_MAX];
 
 static int __init map_range(struct range *range)
<span class="p_chunk">@@ -103,8 +103,8 @@</span> <span class="p_context"> void __init kasan_early_init(void)</span>
 	for (i = 0; CONFIG_PGTABLE_LEVELS &gt;= 5 &amp;&amp; i &lt; PTRS_PER_P4D; i++)
 		kasan_zero_p4d[i] = __p4d(p4d_val);
 
<span class="p_del">-	kasan_map_early_shadow(early_level4_pgt);</span>
<span class="p_del">-	kasan_map_early_shadow(init_level4_pgt);</span>
<span class="p_add">+	kasan_map_early_shadow(early_top_pgt);</span>
<span class="p_add">+	kasan_map_early_shadow(init_top_pgt);</span>
 }
 
 void __init kasan_init(void)
<span class="p_chunk">@@ -115,8 +115,8 @@</span> <span class="p_context"> void __init kasan_init(void)</span>
 	register_die_notifier(&amp;kasan_die_notifier);
 #endif
 
<span class="p_del">-	memcpy(early_level4_pgt, init_level4_pgt, sizeof(early_level4_pgt));</span>
<span class="p_del">-	load_cr3(early_level4_pgt);</span>
<span class="p_add">+	memcpy(early_top_pgt, init_top_pgt, sizeof(early_top_pgt));</span>
<span class="p_add">+	load_cr3(early_top_pgt);</span>
 	__flush_tlb_all();
 
 	clear_pgds(KASAN_SHADOW_START, KASAN_SHADOW_END);
<span class="p_chunk">@@ -142,7 +142,7 @@</span> <span class="p_context"> void __init kasan_init(void)</span>
 	kasan_populate_zero_shadow(kasan_mem_to_shadow((void *)MODULES_END),
 			(void *)KASAN_SHADOW_END);
 
<span class="p_del">-	load_cr3(init_level4_pgt);</span>
<span class="p_add">+	load_cr3(init_top_pgt);</span>
 	__flush_tlb_all();
 
 	/*
<span class="p_header">diff --git a/arch/x86/realmode/init.c b/arch/x86/realmode/init.c</span>
<span class="p_header">index 5db706f14111..dc0836d5c5eb 100644</span>
<span class="p_header">--- a/arch/x86/realmode/init.c</span>
<span class="p_header">+++ b/arch/x86/realmode/init.c</span>
<span class="p_chunk">@@ -102,7 +102,7 @@</span> <span class="p_context"> static void __init setup_real_mode(void)</span>
 
 	trampoline_pgd = (u64 *) __va(real_mode_header-&gt;trampoline_pgd);
 	trampoline_pgd[0] = trampoline_pgd_entry.pgd;
<span class="p_del">-	trampoline_pgd[511] = init_level4_pgt[511].pgd;</span>
<span class="p_add">+	trampoline_pgd[511] = init_top_pgt[511].pgd;</span>
 #endif
 }
 

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



