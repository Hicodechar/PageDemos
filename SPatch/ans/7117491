
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>[PATCHv10,13/36] mm: drop tail page refcounting - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    [PATCHv10,13/36] mm: drop tail page refcounting</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=40781">Kirill A. Shutemov</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>Sept. 3, 2015, 3:12 p.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;1441293202-137314-14-git-send-email-kirill.shutemov@linux.intel.com&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/7117491/mbox/"
   >mbox</a>
|
   <a href="/patch/7117491/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/7117491/">/patch/7117491/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
X-Original-To: patchwork-LKML@patchwork.kernel.org
Delivered-To: patchwork-parsemail@patchwork2.web.kernel.org
Received: from mail.kernel.org (mail.kernel.org [198.145.29.136])
	by patchwork2.web.kernel.org (Postfix) with ESMTP id 1F000BEEC1
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Thu,  3 Sep 2015 15:22:39 +0000 (UTC)
Received: from mail.kernel.org (localhost [127.0.0.1])
	by mail.kernel.org (Postfix) with ESMTP id 1AE84204CF
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Thu,  3 Sep 2015 15:22:37 +0000 (UTC)
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.kernel.org (Postfix) with ESMTP id 6B5EC20713
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Thu,  3 Sep 2015 15:22:34 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1757273AbbICPW2 (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Thu, 3 Sep 2015 11:22:28 -0400
Received: from mga14.intel.com ([192.55.52.115]:1033 &quot;EHLO mga14.intel.com&quot;
	rhost-flags-OK-OK-OK-OK) by vger.kernel.org with ESMTP
	id S1756869AbbICPNo (ORCPT &lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Thu, 3 Sep 2015 11:13:44 -0400
Received: from orsmga001.jf.intel.com ([10.7.209.18])
	by fmsmga103.fm.intel.com with ESMTP; 03 Sep 2015 08:13:42 -0700
X-ExtLoop1: 1
X-IronPort-AV: E=Sophos;i=&quot;5.17,462,1437462000&quot;; d=&quot;scan&#39;208&quot;;a=&quot;761646504&quot;
Received: from black.fi.intel.com ([10.237.72.213])
	by orsmga001.jf.intel.com with ESMTP; 03 Sep 2015 08:13:37 -0700
Received: by black.fi.intel.com (Postfix, from userid 1000)
	id 5D81154C; Thu,  3 Sep 2015 18:13:25 +0300 (EEST)
From: &quot;Kirill A. Shutemov&quot; &lt;kirill.shutemov@linux.intel.com&gt;
To: Andrew Morton &lt;akpm@linux-foundation.org&gt;,
	Andrea Arcangeli &lt;aarcange@redhat.com&gt;, Hugh Dickins &lt;hughd@google.com&gt;
Cc: Dave Hansen &lt;dave.hansen@intel.com&gt;, Mel Gorman &lt;mgorman@suse.de&gt;,
	Rik van Riel &lt;riel@redhat.com&gt;, Vlastimil Babka &lt;vbabka@suse.cz&gt;,
	Christoph Lameter &lt;cl@gentwo.org&gt;,
	Naoya Horiguchi &lt;n-horiguchi@ah.jp.nec.com&gt;,
	Steve Capper &lt;steve.capper@linaro.org&gt;,
	&quot;Aneesh Kumar K.V&quot; &lt;aneesh.kumar@linux.vnet.ibm.com&gt;,
	Johannes Weiner &lt;hannes@cmpxchg.org&gt;, Michal Hocko &lt;mhocko@suse.cz&gt;,
	Jerome Marchand &lt;jmarchan@redhat.com&gt;,
	Sasha Levin &lt;sasha.levin@oracle.com&gt;,
	linux-kernel@vger.kernel.org, linux-mm@kvack.org,
	&quot;Kirill A. Shutemov&quot; &lt;kirill.shutemov@linux.intel.com&gt;
Subject: [PATCHv10 13/36] mm: drop tail page refcounting
Date: Thu,  3 Sep 2015 18:12:59 +0300
Message-Id: &lt;1441293202-137314-14-git-send-email-kirill.shutemov@linux.intel.com&gt;
X-Mailer: git-send-email 2.5.0
In-Reply-To: &lt;1441293202-137314-1-git-send-email-kirill.shutemov@linux.intel.com&gt;
References: &lt;1441293202-137314-1-git-send-email-kirill.shutemov@linux.intel.com&gt;
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Spam-Status: No, score=-6.9 required=5.0 tests=BAYES_00, RCVD_IN_DNSWL_HI, 
	T_RP_MATCHES_RCVD,
	UNPARSEABLE_RELAY autolearn=unavailable version=3.3.1
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on mail.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=40781">Kirill A. Shutemov</a> - Sept. 3, 2015, 3:12 p.m.</div>
<pre class="content">
Tail page refcounting is utterly complicated and painful to support.

It uses -&gt;_mapcount on tail pages to store how many times this page is
pinned. get_page() bumps -&gt;_mapcount on tail page in addition to
-&gt;_count on head. This information is required by split_huge_page() to
be able to distribute pins from head of compound page to tails during
the split.

We will need -&gt;_mapcount to account PTE mappings of subpages of the
compound page. We eliminate need in current meaning of -&gt;_mapcount in
tail pages by forbidding split entirely if the page is pinned.

The only user of tail page refcounting is THP which is marked BROKEN for
now.

Let&#39;s drop all this mess. It makes get_page() and put_page() much
simpler.
<span class="signed-off-by">
Signed-off-by: Kirill A. Shutemov &lt;kirill.shutemov@linux.intel.com&gt;</span>
<span class="tested-by">Tested-by: Sasha Levin &lt;sasha.levin@oracle.com&gt;</span>
<span class="tested-by">Tested-by: Aneesh Kumar K.V &lt;aneesh.kumar@linux.vnet.ibm.com&gt;</span>
<span class="acked-by">Acked-by: Vlastimil Babka &lt;vbabka@suse.cz&gt;</span>
<span class="acked-by">Acked-by: Jerome Marchand &lt;jmarchan@redhat.com&gt;</span>
---
 arch/mips/mm/gup.c            |   4 -
 arch/powerpc/mm/hugetlbpage.c |  13 +-
 arch/s390/mm/gup.c            |  13 +-
 arch/sparc/mm/gup.c           |  14 +--
 arch/x86/mm/gup.c             |   4 -
 include/linux/mm.h            |  47 ++------
 include/linux/mm_types.h      |  17 +--
 mm/gup.c                      |  34 +-----
 mm/huge_memory.c              |  41 +------
 mm/hugetlb.c                  |   2 +-
 mm/internal.h                 |  44 -------
 mm/swap.c                     | 273 +++---------------------------------------
 12 files changed, 40 insertions(+), 466 deletions(-)
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/arch/mips/mm/gup.c b/arch/mips/mm/gup.c</span>
<span class="p_header">index 349995d19c7f..36a35115dc2e 100644</span>
<span class="p_header">--- a/arch/mips/mm/gup.c</span>
<span class="p_header">+++ b/arch/mips/mm/gup.c</span>
<span class="p_chunk">@@ -87,8 +87,6 @@</span> <span class="p_context"> static int gup_huge_pmd(pmd_t pmd, unsigned long addr, unsigned long end,</span>
 	do {
 		VM_BUG_ON(compound_head(page) != head);
 		pages[*nr] = page;
<span class="p_del">-		if (PageTail(page))</span>
<span class="p_del">-			get_huge_page_tail(page);</span>
 		(*nr)++;
 		page++;
 		refs++;
<span class="p_chunk">@@ -153,8 +151,6 @@</span> <span class="p_context"> static int gup_huge_pud(pud_t pud, unsigned long addr, unsigned long end,</span>
 	do {
 		VM_BUG_ON(compound_head(page) != head);
 		pages[*nr] = page;
<span class="p_del">-		if (PageTail(page))</span>
<span class="p_del">-			get_huge_page_tail(page);</span>
 		(*nr)++;
 		page++;
 		refs++;
<span class="p_header">diff --git a/arch/powerpc/mm/hugetlbpage.c b/arch/powerpc/mm/hugetlbpage.c</span>
<span class="p_header">index bb0bd7025cb8..f357eec834e3 100644</span>
<span class="p_header">--- a/arch/powerpc/mm/hugetlbpage.c</span>
<span class="p_header">+++ b/arch/powerpc/mm/hugetlbpage.c</span>
<span class="p_chunk">@@ -1049,7 +1049,7 @@</span> <span class="p_context"> int gup_hugepte(pte_t *ptep, unsigned long sz, unsigned long addr,</span>
 {
 	unsigned long mask;
 	unsigned long pte_end;
<span class="p_del">-	struct page *head, *page, *tail;</span>
<span class="p_add">+	struct page *head, *page;</span>
 	pte_t pte;
 	int refs;
 
<span class="p_chunk">@@ -1072,7 +1072,6 @@</span> <span class="p_context"> int gup_hugepte(pte_t *ptep, unsigned long sz, unsigned long addr,</span>
 	head = pte_page(pte);
 
 	page = head + ((addr &amp; (sz-1)) &gt;&gt; PAGE_SHIFT);
<span class="p_del">-	tail = page;</span>
 	do {
 		VM_BUG_ON(compound_head(page) != head);
 		pages[*nr] = page;
<span class="p_chunk">@@ -1094,15 +1093,5 @@</span> <span class="p_context"> int gup_hugepte(pte_t *ptep, unsigned long sz, unsigned long addr,</span>
 		return 0;
 	}
 
<span class="p_del">-	/*</span>
<span class="p_del">-	 * Any tail page need their mapcount reference taken before we</span>
<span class="p_del">-	 * return.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	while (refs--) {</span>
<span class="p_del">-		if (PageTail(tail))</span>
<span class="p_del">-			get_huge_page_tail(tail);</span>
<span class="p_del">-		tail++;</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
 	return 1;
 }
<span class="p_header">diff --git a/arch/s390/mm/gup.c b/arch/s390/mm/gup.c</span>
<span class="p_header">index 1eb41bb3010c..f8112899f6fe 100644</span>
<span class="p_header">--- a/arch/s390/mm/gup.c</span>
<span class="p_header">+++ b/arch/s390/mm/gup.c</span>
<span class="p_chunk">@@ -52,7 +52,7 @@</span> <span class="p_context"> static inline int gup_huge_pmd(pmd_t *pmdp, pmd_t pmd, unsigned long addr,</span>
 		unsigned long end, int write, struct page **pages, int *nr)
 {
 	unsigned long mask, result;
<span class="p_del">-	struct page *head, *page, *tail;</span>
<span class="p_add">+	struct page *head, *page;</span>
 	int refs;
 
 	result = write ? 0 : _SEGMENT_ENTRY_PROTECT;
<span class="p_chunk">@@ -64,7 +64,6 @@</span> <span class="p_context"> static inline int gup_huge_pmd(pmd_t *pmdp, pmd_t pmd, unsigned long addr,</span>
 	refs = 0;
 	head = pmd_page(pmd);
 	page = head + ((addr &amp; ~PMD_MASK) &gt;&gt; PAGE_SHIFT);
<span class="p_del">-	tail = page;</span>
 	do {
 		VM_BUG_ON(compound_head(page) != head);
 		pages[*nr] = page;
<span class="p_chunk">@@ -85,16 +84,6 @@</span> <span class="p_context"> static inline int gup_huge_pmd(pmd_t *pmdp, pmd_t pmd, unsigned long addr,</span>
 		return 0;
 	}
 
<span class="p_del">-	/*</span>
<span class="p_del">-	 * Any tail page need their mapcount reference taken before we</span>
<span class="p_del">-	 * return.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	while (refs--) {</span>
<span class="p_del">-		if (PageTail(tail))</span>
<span class="p_del">-			get_huge_page_tail(tail);</span>
<span class="p_del">-		tail++;</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
 	return 1;
 }
 
<span class="p_header">diff --git a/arch/sparc/mm/gup.c b/arch/sparc/mm/gup.c</span>
<span class="p_header">index 2e5c4fc2daa9..9091c5daa2e1 100644</span>
<span class="p_header">--- a/arch/sparc/mm/gup.c</span>
<span class="p_header">+++ b/arch/sparc/mm/gup.c</span>
<span class="p_chunk">@@ -56,8 +56,6 @@</span> <span class="p_context"> static noinline int gup_pte_range(pmd_t pmd, unsigned long addr,</span>
 			put_page(head);
 			return 0;
 		}
<span class="p_del">-		if (head != page)</span>
<span class="p_del">-			get_huge_page_tail(page);</span>
 
 		pages[*nr] = page;
 		(*nr)++;
<span class="p_chunk">@@ -70,7 +68,7 @@</span> <span class="p_context"> static int gup_huge_pmd(pmd_t *pmdp, pmd_t pmd, unsigned long addr,</span>
 			unsigned long end, int write, struct page **pages,
 			int *nr)
 {
<span class="p_del">-	struct page *head, *page, *tail;</span>
<span class="p_add">+	struct page *head, *page;</span>
 	int refs;
 
 	if (!(pmd_val(pmd) &amp; _PAGE_VALID))
<span class="p_chunk">@@ -82,7 +80,6 @@</span> <span class="p_context"> static int gup_huge_pmd(pmd_t *pmdp, pmd_t pmd, unsigned long addr,</span>
 	refs = 0;
 	head = pmd_page(pmd);
 	page = head + ((addr &amp; ~PMD_MASK) &gt;&gt; PAGE_SHIFT);
<span class="p_del">-	tail = page;</span>
 	do {
 		VM_BUG_ON(compound_head(page) != head);
 		pages[*nr] = page;
<span class="p_chunk">@@ -103,15 +100,6 @@</span> <span class="p_context"> static int gup_huge_pmd(pmd_t *pmdp, pmd_t pmd, unsigned long addr,</span>
 		return 0;
 	}
 
<span class="p_del">-	/* Any tail page need their mapcount reference taken before we</span>
<span class="p_del">-	 * return.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	while (refs--) {</span>
<span class="p_del">-		if (PageTail(tail))</span>
<span class="p_del">-			get_huge_page_tail(tail);</span>
<span class="p_del">-		tail++;</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
 	return 1;
 }
 
<span class="p_header">diff --git a/arch/x86/mm/gup.c b/arch/x86/mm/gup.c</span>
<span class="p_header">index 81bf3d2af3eb..62a887a3cf50 100644</span>
<span class="p_header">--- a/arch/x86/mm/gup.c</span>
<span class="p_header">+++ b/arch/x86/mm/gup.c</span>
<span class="p_chunk">@@ -137,8 +137,6 @@</span> <span class="p_context"> static noinline int gup_huge_pmd(pmd_t pmd, unsigned long addr,</span>
 	do {
 		VM_BUG_ON_PAGE(compound_head(page) != head, page);
 		pages[*nr] = page;
<span class="p_del">-		if (PageTail(page))</span>
<span class="p_del">-			get_huge_page_tail(page);</span>
 		(*nr)++;
 		page++;
 		refs++;
<span class="p_chunk">@@ -214,8 +212,6 @@</span> <span class="p_context"> static noinline int gup_huge_pud(pud_t pud, unsigned long addr,</span>
 	do {
 		VM_BUG_ON_PAGE(compound_head(page) != head, page);
 		pages[*nr] = page;
<span class="p_del">-		if (PageTail(page))</span>
<span class="p_del">-			get_huge_page_tail(page);</span>
 		(*nr)++;
 		page++;
 		refs++;
<span class="p_header">diff --git a/include/linux/mm.h b/include/linux/mm.h</span>
<span class="p_header">index 188fe23dca26..c3a1fd44cd0a 100644</span>
<span class="p_header">--- a/include/linux/mm.h</span>
<span class="p_header">+++ b/include/linux/mm.h</span>
<span class="p_chunk">@@ -440,44 +440,9 @@</span> <span class="p_context"> static inline int page_count(struct page *page)</span>
 	return atomic_read(&amp;compound_head(page)-&gt;_count);
 }
 
<span class="p_del">-static inline bool __compound_tail_refcounted(struct page *page)</span>
<span class="p_del">-{</span>
<span class="p_del">-	return PageAnon(page) &amp;&amp; !PageSlab(page) &amp;&amp; !PageHeadHuge(page);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-/*</span>
<span class="p_del">- * This takes a head page as parameter and tells if the</span>
<span class="p_del">- * tail page reference counting can be skipped.</span>
<span class="p_del">- *</span>
<span class="p_del">- * For this to be safe, PageSlab and PageHeadHuge must remain true on</span>
<span class="p_del">- * any given page where they return true here, until all tail pins</span>
<span class="p_del">- * have been released.</span>
<span class="p_del">- */</span>
<span class="p_del">-static inline bool compound_tail_refcounted(struct page *page)</span>
<span class="p_del">-{</span>
<span class="p_del">-	VM_BUG_ON_PAGE(!PageHead(page), page);</span>
<span class="p_del">-	return __compound_tail_refcounted(page);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static inline void get_huge_page_tail(struct page *page)</span>
<span class="p_del">-{</span>
<span class="p_del">-	/*</span>
<span class="p_del">-	 * __split_huge_page_refcount() cannot run from under us.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	VM_BUG_ON_PAGE(!PageTail(page), page);</span>
<span class="p_del">-	VM_BUG_ON_PAGE(page_mapcount(page) &lt; 0, page);</span>
<span class="p_del">-	VM_BUG_ON_PAGE(atomic_read(&amp;page-&gt;_count) != 0, page);</span>
<span class="p_del">-	if (compound_tail_refcounted(compound_head(page)))</span>
<span class="p_del">-		atomic_inc(&amp;page-&gt;_mapcount);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-extern bool __get_page_tail(struct page *page);</span>
<span class="p_del">-</span>
 static inline void get_page(struct page *page)
 {
<span class="p_del">-	if (unlikely(PageTail(page)))</span>
<span class="p_del">-		if (likely(__get_page_tail(page)))</span>
<span class="p_del">-			return;</span>
<span class="p_add">+	page = compound_head(page);</span>
 	/*
 	 * Getting a normal page or the head of a compound page
 	 * requires to already have an elevated page-&gt;_count.
<span class="p_chunk">@@ -502,7 +467,15 @@</span> <span class="p_context"> static inline void init_page_count(struct page *page)</span>
 	atomic_set(&amp;page-&gt;_count, 1);
 }
 
<span class="p_del">-void put_page(struct page *page);</span>
<span class="p_add">+void __put_page(struct page *page);</span>
<span class="p_add">+</span>
<span class="p_add">+static inline void put_page(struct page *page)</span>
<span class="p_add">+{</span>
<span class="p_add">+	page = compound_head(page);</span>
<span class="p_add">+	if (put_page_testzero(page))</span>
<span class="p_add">+		__put_page(page);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 void put_pages_list(struct list_head *pages);
 
 void split_page(struct page *page, unsigned int order);
<span class="p_header">diff --git a/include/linux/mm_types.h b/include/linux/mm_types.h</span>
<span class="p_header">index c7de6f6058d3..6fa6682fc1ce 100644</span>
<span class="p_header">--- a/include/linux/mm_types.h</span>
<span class="p_header">+++ b/include/linux/mm_types.h</span>
<span class="p_chunk">@@ -81,20 +81,9 @@</span> <span class="p_context"> struct page {</span>
 
 				union {
 					/*
<span class="p_del">-					 * Count of ptes mapped in</span>
<span class="p_del">-					 * mms, to show when page is</span>
<span class="p_del">-					 * mapped &amp; limit reverse map</span>
<span class="p_del">-					 * searches.</span>
<span class="p_del">-					 *</span>
<span class="p_del">-					 * Used also for tail pages</span>
<span class="p_del">-					 * refcounting instead of</span>
<span class="p_del">-					 * _count. Tail pages cannot</span>
<span class="p_del">-					 * be mapped and keeping the</span>
<span class="p_del">-					 * tail page _count zero at</span>
<span class="p_del">-					 * all times guarantees</span>
<span class="p_del">-					 * get_page_unless_zero() will</span>
<span class="p_del">-					 * never succeed on tail</span>
<span class="p_del">-					 * pages.</span>
<span class="p_add">+					 * Count of ptes mapped in mms, to show</span>
<span class="p_add">+					 * when page is mapped &amp; limit reverse</span>
<span class="p_add">+					 * map searches.</span>
 					 */
 					atomic_t _mapcount;
 
<span class="p_header">diff --git a/mm/gup.c b/mm/gup.c</span>
<span class="p_header">index 1c50b506888d..7017abea9fd6 100644</span>
<span class="p_header">--- a/mm/gup.c</span>
<span class="p_header">+++ b/mm/gup.c</span>
<span class="p_chunk">@@ -130,7 +130,7 @@</span> <span class="p_context"> retry:</span>
 	}
 
 	if (flags &amp; FOLL_GET)
<span class="p_del">-		get_page_foll(page);</span>
<span class="p_add">+		get_page(page);</span>
 	if (flags &amp; FOLL_TOUCH) {
 		if ((flags &amp; FOLL_WRITE) &amp;&amp;
 		    !pte_dirty(pte) &amp;&amp; !PageDirty(page))
<span class="p_chunk">@@ -1153,7 +1153,7 @@</span> <span class="p_context"> static int gup_pte_range(pmd_t pmd, unsigned long addr, unsigned long end,</span>
 static int gup_huge_pmd(pmd_t orig, pmd_t *pmdp, unsigned long addr,
 		unsigned long end, int write, struct page **pages, int *nr)
 {
<span class="p_del">-	struct page *head, *page, *tail;</span>
<span class="p_add">+	struct page *head, *page;</span>
 	int refs;
 
 	if (write &amp;&amp; !pmd_write(orig))
<span class="p_chunk">@@ -1162,7 +1162,6 @@</span> <span class="p_context"> static int gup_huge_pmd(pmd_t orig, pmd_t *pmdp, unsigned long addr,</span>
 	refs = 0;
 	head = pmd_page(orig);
 	page = head + ((addr &amp; ~PMD_MASK) &gt;&gt; PAGE_SHIFT);
<span class="p_del">-	tail = page;</span>
 	do {
 		VM_BUG_ON_PAGE(compound_head(page) != head, page);
 		pages[*nr] = page;
<span class="p_chunk">@@ -1183,24 +1182,13 @@</span> <span class="p_context"> static int gup_huge_pmd(pmd_t orig, pmd_t *pmdp, unsigned long addr,</span>
 		return 0;
 	}
 
<span class="p_del">-	/*</span>
<span class="p_del">-	 * Any tail pages need their mapcount reference taken before we</span>
<span class="p_del">-	 * return. (This allows the THP code to bump their ref count when</span>
<span class="p_del">-	 * they are split into base pages).</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	while (refs--) {</span>
<span class="p_del">-		if (PageTail(tail))</span>
<span class="p_del">-			get_huge_page_tail(tail);</span>
<span class="p_del">-		tail++;</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
 	return 1;
 }
 
 static int gup_huge_pud(pud_t orig, pud_t *pudp, unsigned long addr,
 		unsigned long end, int write, struct page **pages, int *nr)
 {
<span class="p_del">-	struct page *head, *page, *tail;</span>
<span class="p_add">+	struct page *head, *page;</span>
 	int refs;
 
 	if (write &amp;&amp; !pud_write(orig))
<span class="p_chunk">@@ -1209,7 +1197,6 @@</span> <span class="p_context"> static int gup_huge_pud(pud_t orig, pud_t *pudp, unsigned long addr,</span>
 	refs = 0;
 	head = pud_page(orig);
 	page = head + ((addr &amp; ~PUD_MASK) &gt;&gt; PAGE_SHIFT);
<span class="p_del">-	tail = page;</span>
 	do {
 		VM_BUG_ON_PAGE(compound_head(page) != head, page);
 		pages[*nr] = page;
<span class="p_chunk">@@ -1230,12 +1217,6 @@</span> <span class="p_context"> static int gup_huge_pud(pud_t orig, pud_t *pudp, unsigned long addr,</span>
 		return 0;
 	}
 
<span class="p_del">-	while (refs--) {</span>
<span class="p_del">-		if (PageTail(tail))</span>
<span class="p_del">-			get_huge_page_tail(tail);</span>
<span class="p_del">-		tail++;</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
 	return 1;
 }
 
<span class="p_chunk">@@ -1244,7 +1225,7 @@</span> <span class="p_context"> static int gup_huge_pgd(pgd_t orig, pgd_t *pgdp, unsigned long addr,</span>
 			struct page **pages, int *nr)
 {
 	int refs;
<span class="p_del">-	struct page *head, *page, *tail;</span>
<span class="p_add">+	struct page *head, *page;</span>
 
 	if (write &amp;&amp; !pgd_write(orig))
 		return 0;
<span class="p_chunk">@@ -1252,7 +1233,6 @@</span> <span class="p_context"> static int gup_huge_pgd(pgd_t orig, pgd_t *pgdp, unsigned long addr,</span>
 	refs = 0;
 	head = pgd_page(orig);
 	page = head + ((addr &amp; ~PGDIR_MASK) &gt;&gt; PAGE_SHIFT);
<span class="p_del">-	tail = page;</span>
 	do {
 		VM_BUG_ON_PAGE(compound_head(page) != head, page);
 		pages[*nr] = page;
<span class="p_chunk">@@ -1273,12 +1253,6 @@</span> <span class="p_context"> static int gup_huge_pgd(pgd_t orig, pgd_t *pgdp, unsigned long addr,</span>
 		return 0;
 	}
 
<span class="p_del">-	while (refs--) {</span>
<span class="p_del">-		if (PageTail(tail))</span>
<span class="p_del">-			get_huge_page_tail(tail);</span>
<span class="p_del">-		tail++;</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
 	return 1;
 }
 
<span class="p_header">diff --git a/mm/huge_memory.c b/mm/huge_memory.c</span>
<span class="p_header">index 2a030f1aebf6..5dc2b822b692 100644</span>
<span class="p_header">--- a/mm/huge_memory.c</span>
<span class="p_header">+++ b/mm/huge_memory.c</span>
<span class="p_chunk">@@ -1010,37 +1010,6 @@</span> <span class="p_context"> unlock:</span>
 	spin_unlock(ptl);
 }
 
<span class="p_del">-/*</span>
<span class="p_del">- * Save CONFIG_DEBUG_PAGEALLOC from faulting falsely on tail pages</span>
<span class="p_del">- * during copy_user_huge_page()&#39;s copy_page_rep(): in the case when</span>
<span class="p_del">- * the source page gets split and a tail freed before copy completes.</span>
<span class="p_del">- * Called under pmd_lock of checked pmd, so safe from splitting itself.</span>
<span class="p_del">- */</span>
<span class="p_del">-static void get_user_huge_page(struct page *page)</span>
<span class="p_del">-{</span>
<span class="p_del">-	if (IS_ENABLED(CONFIG_DEBUG_PAGEALLOC)) {</span>
<span class="p_del">-		struct page *endpage = page + HPAGE_PMD_NR;</span>
<span class="p_del">-</span>
<span class="p_del">-		atomic_add(HPAGE_PMD_NR, &amp;page-&gt;_count);</span>
<span class="p_del">-		while (++page &lt; endpage)</span>
<span class="p_del">-			get_huge_page_tail(page);</span>
<span class="p_del">-	} else {</span>
<span class="p_del">-		get_page(page);</span>
<span class="p_del">-	}</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static void put_user_huge_page(struct page *page)</span>
<span class="p_del">-{</span>
<span class="p_del">-	if (IS_ENABLED(CONFIG_DEBUG_PAGEALLOC)) {</span>
<span class="p_del">-		struct page *endpage = page + HPAGE_PMD_NR;</span>
<span class="p_del">-</span>
<span class="p_del">-		while (page &lt; endpage)</span>
<span class="p_del">-			put_page(page++);</span>
<span class="p_del">-	} else {</span>
<span class="p_del">-		put_page(page);</span>
<span class="p_del">-	}</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
 static int do_huge_pmd_wp_page_fallback(struct mm_struct *mm,
 					struct vm_area_struct *vma,
 					unsigned long address,
<span class="p_chunk">@@ -1193,7 +1162,7 @@</span> <span class="p_context"> int do_huge_pmd_wp_page(struct mm_struct *mm, struct vm_area_struct *vma,</span>
 		ret |= VM_FAULT_WRITE;
 		goto out_unlock;
 	}
<span class="p_del">-	get_user_huge_page(page);</span>
<span class="p_add">+	get_page(page);</span>
 	spin_unlock(ptl);
 alloc:
 	if (transparent_hugepage_enabled(vma) &amp;&amp;
<span class="p_chunk">@@ -1214,7 +1183,7 @@</span> <span class="p_context"> alloc:</span>
 				split_huge_pmd(vma, pmd, address);
 				ret |= VM_FAULT_FALLBACK;
 			}
<span class="p_del">-			put_user_huge_page(page);</span>
<span class="p_add">+			put_page(page);</span>
 		}
 		count_vm_event(THP_FAULT_FALLBACK);
 		goto out;
<span class="p_chunk">@@ -1225,7 +1194,7 @@</span> <span class="p_context"> alloc:</span>
 		put_page(new_page);
 		if (page) {
 			split_huge_pmd(vma, pmd, address);
<span class="p_del">-			put_user_huge_page(page);</span>
<span class="p_add">+			put_page(page);</span>
 		} else
 			split_huge_pmd(vma, pmd, address);
 		ret |= VM_FAULT_FALLBACK;
<span class="p_chunk">@@ -1247,7 +1216,7 @@</span> <span class="p_context"> alloc:</span>
 
 	spin_lock(ptl);
 	if (page)
<span class="p_del">-		put_user_huge_page(page);</span>
<span class="p_add">+		put_page(page);</span>
 	if (unlikely(!pmd_same(*pmd, orig_pmd))) {
 		spin_unlock(ptl);
 		mem_cgroup_cancel_charge(new_page, memcg, true);
<span class="p_chunk">@@ -1332,7 +1301,7 @@</span> <span class="p_context"> struct page *follow_trans_huge_pmd(struct vm_area_struct *vma,</span>
 	page += (addr &amp; ~HPAGE_PMD_MASK) &gt;&gt; PAGE_SHIFT;
 	VM_BUG_ON_PAGE(!PageCompound(page), page);
 	if (flags &amp; FOLL_GET)
<span class="p_del">-		get_page_foll(page);</span>
<span class="p_add">+		get_page(page);</span>
 
 out:
 	return page;
<span class="p_header">diff --git a/mm/hugetlb.c b/mm/hugetlb.c</span>
<span class="p_header">index 3282bb157e4d..2053a6775dd8 100644</span>
<span class="p_header">--- a/mm/hugetlb.c</span>
<span class="p_header">+++ b/mm/hugetlb.c</span>
<span class="p_chunk">@@ -3818,7 +3818,7 @@</span> <span class="p_context"> long follow_hugetlb_page(struct mm_struct *mm, struct vm_area_struct *vma,</span>
 same_page:
 		if (pages) {
 			pages[i] = mem_map_offset(page, pfn_offset);
<span class="p_del">-			get_page_foll(pages[i]);</span>
<span class="p_add">+			get_page(pages[i]);</span>
 		}
 
 		if (vmas)
<span class="p_header">diff --git a/mm/internal.h b/mm/internal.h</span>
<span class="p_header">index f9c439536878..4ffe4746d28c 100644</span>
<span class="p_header">--- a/mm/internal.h</span>
<span class="p_header">+++ b/mm/internal.h</span>
<span class="p_chunk">@@ -47,50 +47,6 @@</span> <span class="p_context"> static inline void set_page_refcounted(struct page *page)</span>
 	set_page_count(page, 1);
 }
 
<span class="p_del">-static inline void __get_page_tail_foll(struct page *page,</span>
<span class="p_del">-					bool get_page_head)</span>
<span class="p_del">-{</span>
<span class="p_del">-	/*</span>
<span class="p_del">-	 * If we&#39;re getting a tail page, the elevated page-&gt;_count is</span>
<span class="p_del">-	 * required only in the head page and we will elevate the head</span>
<span class="p_del">-	 * page-&gt;_count and tail page-&gt;_mapcount.</span>
<span class="p_del">-	 *</span>
<span class="p_del">-	 * We elevate page_tail-&gt;_mapcount for tail pages to force</span>
<span class="p_del">-	 * page_tail-&gt;_count to be zero at all times to avoid getting</span>
<span class="p_del">-	 * false positives from get_page_unless_zero() with</span>
<span class="p_del">-	 * speculative page access (like in</span>
<span class="p_del">-	 * page_cache_get_speculative()) on tail pages.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	VM_BUG_ON_PAGE(atomic_read(&amp;compound_head(page)-&gt;_count) &lt;= 0, page);</span>
<span class="p_del">-	if (get_page_head)</span>
<span class="p_del">-		atomic_inc(&amp;compound_head(page)-&gt;_count);</span>
<span class="p_del">-	get_huge_page_tail(page);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-/*</span>
<span class="p_del">- * This is meant to be called as the FOLL_GET operation of</span>
<span class="p_del">- * follow_page() and it must be called while holding the proper PT</span>
<span class="p_del">- * lock while the pte (or pmd_trans_huge) is still mapping the page.</span>
<span class="p_del">- */</span>
<span class="p_del">-static inline void get_page_foll(struct page *page)</span>
<span class="p_del">-{</span>
<span class="p_del">-	if (unlikely(PageTail(page)))</span>
<span class="p_del">-		/*</span>
<span class="p_del">-		 * This is safe only because</span>
<span class="p_del">-		 * __split_huge_page_refcount() can&#39;t run under</span>
<span class="p_del">-		 * get_page_foll() because we hold the proper PT lock.</span>
<span class="p_del">-		 */</span>
<span class="p_del">-		__get_page_tail_foll(page, true);</span>
<span class="p_del">-	else {</span>
<span class="p_del">-		/*</span>
<span class="p_del">-		 * Getting a normal page or the head of a compound page</span>
<span class="p_del">-		 * requires to already have an elevated page-&gt;_count.</span>
<span class="p_del">-		 */</span>
<span class="p_del">-		VM_BUG_ON_PAGE(atomic_read(&amp;page-&gt;_count) &lt;= 0, page);</span>
<span class="p_del">-		atomic_inc(&amp;page-&gt;_count);</span>
<span class="p_del">-	}</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
 extern unsigned long highest_memmap_pfn;
 
 /*
<span class="p_header">diff --git a/mm/swap.c b/mm/swap.c</span>
<span class="p_header">index ecbfd50df347..d6abe8a4970e 100644</span>
<span class="p_header">--- a/mm/swap.c</span>
<span class="p_header">+++ b/mm/swap.c</span>
<span class="p_chunk">@@ -90,260 +90,14 @@</span> <span class="p_context"> static void __put_compound_page(struct page *page)</span>
 	(*dtor)(page);
 }
 
<span class="p_del">-/**</span>
<span class="p_del">- * Two special cases here: we could avoid taking compound_lock_irqsave</span>
<span class="p_del">- * and could skip the tail refcounting(in _mapcount).</span>
<span class="p_del">- *</span>
<span class="p_del">- * 1. Hugetlbfs page:</span>
<span class="p_del">- *</span>
<span class="p_del">- *    PageHeadHuge will remain true until the compound page</span>
<span class="p_del">- *    is released and enters the buddy allocator, and it could</span>
<span class="p_del">- *    not be split by __split_huge_page_refcount().</span>
<span class="p_del">- *</span>
<span class="p_del">- *    So if we see PageHeadHuge set, and we have the tail page pin,</span>
<span class="p_del">- *    then we could safely put head page.</span>
<span class="p_del">- *</span>
<span class="p_del">- * 2. Slab THP page:</span>
<span class="p_del">- *</span>
<span class="p_del">- *    PG_slab is cleared before the slab frees the head page, and</span>
<span class="p_del">- *    tail pin cannot be the last reference left on the head page,</span>
<span class="p_del">- *    because the slab code is free to reuse the compound page</span>
<span class="p_del">- *    after a kfree/kmem_cache_free without having to check if</span>
<span class="p_del">- *    there&#39;s any tail pin left.  In turn all tail pinsmust be always</span>
<span class="p_del">- *    released while the head is still pinned by the slab code</span>
<span class="p_del">- *    and so we know PG_slab will be still set too.</span>
<span class="p_del">- *</span>
<span class="p_del">- *    So if we see PageSlab set, and we have the tail page pin,</span>
<span class="p_del">- *    then we could safely put head page.</span>
<span class="p_del">- */</span>
<span class="p_del">-static __always_inline</span>
<span class="p_del">-void put_unrefcounted_compound_page(struct page *page_head, struct page *page)</span>
<span class="p_del">-{</span>
<span class="p_del">-	/*</span>
<span class="p_del">-	 * If @page is a THP tail, we must read the tail page</span>
<span class="p_del">-	 * flags after the head page flags. The</span>
<span class="p_del">-	 * __split_huge_page_refcount side enforces write memory barriers</span>
<span class="p_del">-	 * between clearing PageTail and before the head page</span>
<span class="p_del">-	 * can be freed and reallocated.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	smp_rmb();</span>
<span class="p_del">-	if (likely(PageTail(page))) {</span>
<span class="p_del">-		/*</span>
<span class="p_del">-		 * __split_huge_page_refcount cannot race</span>
<span class="p_del">-		 * here, see the comment above this function.</span>
<span class="p_del">-		 */</span>
<span class="p_del">-		VM_BUG_ON_PAGE(!PageHead(page_head), page_head);</span>
<span class="p_del">-		if (put_page_testzero(page_head)) {</span>
<span class="p_del">-			/*</span>
<span class="p_del">-			 * If this is the tail of a slab THP page,</span>
<span class="p_del">-			 * the tail pin must not be the last reference</span>
<span class="p_del">-			 * held on the page, because the PG_slab cannot</span>
<span class="p_del">-			 * be cleared before all tail pins (which skips</span>
<span class="p_del">-			 * the _mapcount tail refcounting) have been</span>
<span class="p_del">-			 * released.</span>
<span class="p_del">-			 *</span>
<span class="p_del">-			 * If this is the tail of a hugetlbfs page,</span>
<span class="p_del">-			 * the tail pin may be the last reference on</span>
<span class="p_del">-			 * the page instead, because PageHeadHuge will</span>
<span class="p_del">-			 * not go away until the compound page enters</span>
<span class="p_del">-			 * the buddy allocator.</span>
<span class="p_del">-			 */</span>
<span class="p_del">-			VM_BUG_ON_PAGE(PageSlab(page_head), page_head);</span>
<span class="p_del">-			__put_compound_page(page_head);</span>
<span class="p_del">-		}</span>
<span class="p_del">-	} else</span>
<span class="p_del">-		/*</span>
<span class="p_del">-		 * __split_huge_page_refcount run before us,</span>
<span class="p_del">-		 * @page was a THP tail. The split @page_head</span>
<span class="p_del">-		 * has been freed and reallocated as slab or</span>
<span class="p_del">-		 * hugetlbfs page of smaller order (only</span>
<span class="p_del">-		 * possible if reallocated as slab on x86).</span>
<span class="p_del">-		 */</span>
<span class="p_del">-		if (put_page_testzero(page))</span>
<span class="p_del">-			__put_single_page(page);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static __always_inline</span>
<span class="p_del">-void put_refcounted_compound_page(struct page *page_head, struct page *page)</span>
<span class="p_del">-{</span>
<span class="p_del">-	if (likely(page != page_head &amp;&amp; get_page_unless_zero(page_head))) {</span>
<span class="p_del">-		unsigned long flags;</span>
<span class="p_del">-</span>
<span class="p_del">-		/*</span>
<span class="p_del">-		 * @page_head wasn&#39;t a dangling pointer but it may not</span>
<span class="p_del">-		 * be a head page anymore by the time we obtain the</span>
<span class="p_del">-		 * lock. That is ok as long as it can&#39;t be freed from</span>
<span class="p_del">-		 * under us.</span>
<span class="p_del">-		 */</span>
<span class="p_del">-		flags = compound_lock_irqsave(page_head);</span>
<span class="p_del">-		if (unlikely(!PageTail(page))) {</span>
<span class="p_del">-			/* __split_huge_page_refcount run before us */</span>
<span class="p_del">-			compound_unlock_irqrestore(page_head, flags);</span>
<span class="p_del">-			if (put_page_testzero(page_head)) {</span>
<span class="p_del">-				/*</span>
<span class="p_del">-				 * The @page_head may have been freed</span>
<span class="p_del">-				 * and reallocated as a compound page</span>
<span class="p_del">-				 * of smaller order and then freed</span>
<span class="p_del">-				 * again.  All we know is that it</span>
<span class="p_del">-				 * cannot have become: a THP page, a</span>
<span class="p_del">-				 * compound page of higher order, a</span>
<span class="p_del">-				 * tail page.  That is because we</span>
<span class="p_del">-				 * still hold the refcount of the</span>
<span class="p_del">-				 * split THP tail and page_head was</span>
<span class="p_del">-				 * the THP head before the split.</span>
<span class="p_del">-				 */</span>
<span class="p_del">-				if (PageHead(page_head))</span>
<span class="p_del">-					__put_compound_page(page_head);</span>
<span class="p_del">-				else</span>
<span class="p_del">-					__put_single_page(page_head);</span>
<span class="p_del">-			}</span>
<span class="p_del">-out_put_single:</span>
<span class="p_del">-			if (put_page_testzero(page))</span>
<span class="p_del">-				__put_single_page(page);</span>
<span class="p_del">-			return;</span>
<span class="p_del">-		}</span>
<span class="p_del">-		VM_BUG_ON_PAGE(page_head != compound_head(page), page);</span>
<span class="p_del">-		/*</span>
<span class="p_del">-		 * We can release the refcount taken by</span>
<span class="p_del">-		 * get_page_unless_zero() now that</span>
<span class="p_del">-		 * __split_huge_page_refcount() is blocked on the</span>
<span class="p_del">-		 * compound_lock.</span>
<span class="p_del">-		 */</span>
<span class="p_del">-		if (put_page_testzero(page_head))</span>
<span class="p_del">-			VM_BUG_ON_PAGE(1, page_head);</span>
<span class="p_del">-		/* __split_huge_page_refcount will wait now */</span>
<span class="p_del">-		VM_BUG_ON_PAGE(page_mapcount(page) &lt;= 0, page);</span>
<span class="p_del">-		atomic_dec(&amp;page-&gt;_mapcount);</span>
<span class="p_del">-		VM_BUG_ON_PAGE(atomic_read(&amp;page_head-&gt;_count) &lt;= 0, page_head);</span>
<span class="p_del">-		VM_BUG_ON_PAGE(atomic_read(&amp;page-&gt;_count) != 0, page);</span>
<span class="p_del">-		compound_unlock_irqrestore(page_head, flags);</span>
<span class="p_del">-</span>
<span class="p_del">-		if (put_page_testzero(page_head)) {</span>
<span class="p_del">-			if (PageHead(page_head))</span>
<span class="p_del">-				__put_compound_page(page_head);</span>
<span class="p_del">-			else</span>
<span class="p_del">-				__put_single_page(page_head);</span>
<span class="p_del">-		}</span>
<span class="p_del">-	} else {</span>
<span class="p_del">-		/* @page_head is a dangling pointer */</span>
<span class="p_del">-		VM_BUG_ON_PAGE(PageTail(page), page);</span>
<span class="p_del">-		goto out_put_single;</span>
<span class="p_del">-	}</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static void put_compound_page(struct page *page)</span>
<span class="p_del">-{</span>
<span class="p_del">-	struct page *page_head;</span>
<span class="p_del">-</span>
<span class="p_del">-	/*</span>
<span class="p_del">-	 * We see the PageCompound set and PageTail not set, so @page maybe:</span>
<span class="p_del">-	 *  1. hugetlbfs head page, or</span>
<span class="p_del">-	 *  2. THP head page.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	if (likely(!PageTail(page))) {</span>
<span class="p_del">-		if (put_page_testzero(page)) {</span>
<span class="p_del">-			/*</span>
<span class="p_del">-			 * By the time all refcounts have been released</span>
<span class="p_del">-			 * split_huge_page cannot run anymore from under us.</span>
<span class="p_del">-			 */</span>
<span class="p_del">-			if (PageHead(page))</span>
<span class="p_del">-				__put_compound_page(page);</span>
<span class="p_del">-			else</span>
<span class="p_del">-				__put_single_page(page);</span>
<span class="p_del">-		}</span>
<span class="p_del">-		return;</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">-	/*</span>
<span class="p_del">-	 * We see the PageCompound set and PageTail set, so @page maybe:</span>
<span class="p_del">-	 *  1. a tail hugetlbfs page, or</span>
<span class="p_del">-	 *  2. a tail THP page, or</span>
<span class="p_del">-	 *  3. a split THP page.</span>
<span class="p_del">-	 *</span>
<span class="p_del">-	 *  Case 3 is possible, as we may race with</span>
<span class="p_del">-	 *  __split_huge_page_refcount tearing down a THP page.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	page_head = compound_head(page);</span>
<span class="p_del">-	if (!__compound_tail_refcounted(page_head))</span>
<span class="p_del">-		put_unrefcounted_compound_page(page_head, page);</span>
<span class="p_del">-	else</span>
<span class="p_del">-		put_refcounted_compound_page(page_head, page);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-void put_page(struct page *page)</span>
<span class="p_add">+void __put_page(struct page *page)</span>
 {
 	if (unlikely(PageCompound(page)))
<span class="p_del">-		put_compound_page(page);</span>
<span class="p_del">-	else if (put_page_testzero(page))</span>
<span class="p_add">+		__put_compound_page(page);</span>
<span class="p_add">+	else</span>
 		__put_single_page(page);
 }
<span class="p_del">-EXPORT_SYMBOL(put_page);</span>
<span class="p_del">-</span>
<span class="p_del">-/*</span>
<span class="p_del">- * This function is exported but must not be called by anything other</span>
<span class="p_del">- * than get_page(). It implements the slow path of get_page().</span>
<span class="p_del">- */</span>
<span class="p_del">-bool __get_page_tail(struct page *page)</span>
<span class="p_del">-{</span>
<span class="p_del">-	/*</span>
<span class="p_del">-	 * This takes care of get_page() if run on a tail page</span>
<span class="p_del">-	 * returned by one of the get_user_pages/follow_page variants.</span>
<span class="p_del">-	 * get_user_pages/follow_page itself doesn&#39;t need the compound</span>
<span class="p_del">-	 * lock because it runs __get_page_tail_foll() under the</span>
<span class="p_del">-	 * proper PT lock that already serializes against</span>
<span class="p_del">-	 * split_huge_page().</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	unsigned long flags;</span>
<span class="p_del">-	bool got;</span>
<span class="p_del">-	struct page *page_head = compound_head(page);</span>
<span class="p_del">-</span>
<span class="p_del">-	/* Ref to put_compound_page() comment. */</span>
<span class="p_del">-	if (!__compound_tail_refcounted(page_head)) {</span>
<span class="p_del">-		smp_rmb();</span>
<span class="p_del">-		if (likely(PageTail(page))) {</span>
<span class="p_del">-			/*</span>
<span class="p_del">-			 * This is a hugetlbfs page or a slab</span>
<span class="p_del">-			 * page. __split_huge_page_refcount</span>
<span class="p_del">-			 * cannot race here.</span>
<span class="p_del">-			 */</span>
<span class="p_del">-			VM_BUG_ON_PAGE(!PageHead(page_head), page_head);</span>
<span class="p_del">-			__get_page_tail_foll(page, true);</span>
<span class="p_del">-			return true;</span>
<span class="p_del">-		} else {</span>
<span class="p_del">-			/*</span>
<span class="p_del">-			 * __split_huge_page_refcount run</span>
<span class="p_del">-			 * before us, &quot;page&quot; was a THP</span>
<span class="p_del">-			 * tail. The split page_head has been</span>
<span class="p_del">-			 * freed and reallocated as slab or</span>
<span class="p_del">-			 * hugetlbfs page of smaller order</span>
<span class="p_del">-			 * (only possible if reallocated as</span>
<span class="p_del">-			 * slab on x86).</span>
<span class="p_del">-			 */</span>
<span class="p_del">-			return false;</span>
<span class="p_del">-		}</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">-	got = false;</span>
<span class="p_del">-	if (likely(page != page_head &amp;&amp; get_page_unless_zero(page_head))) {</span>
<span class="p_del">-		/*</span>
<span class="p_del">-		 * page_head wasn&#39;t a dangling pointer but it</span>
<span class="p_del">-		 * may not be a head page anymore by the time</span>
<span class="p_del">-		 * we obtain the lock. That is ok as long as it</span>
<span class="p_del">-		 * can&#39;t be freed from under us.</span>
<span class="p_del">-		 */</span>
<span class="p_del">-		flags = compound_lock_irqsave(page_head);</span>
<span class="p_del">-		/* here __split_huge_page_refcount won&#39;t run anymore */</span>
<span class="p_del">-		if (likely(PageTail(page))) {</span>
<span class="p_del">-			__get_page_tail_foll(page, false);</span>
<span class="p_del">-			got = true;</span>
<span class="p_del">-		}</span>
<span class="p_del">-		compound_unlock_irqrestore(page_head, flags);</span>
<span class="p_del">-		if (unlikely(!got))</span>
<span class="p_del">-			put_page(page_head);</span>
<span class="p_del">-	}</span>
<span class="p_del">-	return got;</span>
<span class="p_del">-}</span>
<span class="p_del">-EXPORT_SYMBOL(__get_page_tail);</span>
<span class="p_add">+EXPORT_SYMBOL(__put_page);</span>
 
 /**
  * put_pages_list() - release a list of pages
<span class="p_chunk">@@ -962,15 +716,6 @@</span> <span class="p_context"> void release_pages(struct page **pages, int nr, bool cold)</span>
 	for (i = 0; i &lt; nr; i++) {
 		struct page *page = pages[i];
 
<span class="p_del">-		if (unlikely(PageCompound(page))) {</span>
<span class="p_del">-			if (zone) {</span>
<span class="p_del">-				spin_unlock_irqrestore(&amp;zone-&gt;lru_lock, flags);</span>
<span class="p_del">-				zone = NULL;</span>
<span class="p_del">-			}</span>
<span class="p_del">-			put_compound_page(page);</span>
<span class="p_del">-			continue;</span>
<span class="p_del">-		}</span>
<span class="p_del">-</span>
 		/*
 		 * Make sure the IRQ-safe lock-holding time does not get
 		 * excessive with a continuous string of pages from the
<span class="p_chunk">@@ -981,9 +726,19 @@</span> <span class="p_context"> void release_pages(struct page **pages, int nr, bool cold)</span>
 			zone = NULL;
 		}
 
<span class="p_add">+		page = compound_head(page);</span>
 		if (!put_page_testzero(page))
 			continue;
 
<span class="p_add">+		if (PageCompound(page)) {</span>
<span class="p_add">+			if (zone) {</span>
<span class="p_add">+				spin_unlock_irqrestore(&amp;zone-&gt;lru_lock, flags);</span>
<span class="p_add">+				zone = NULL;</span>
<span class="p_add">+			}</span>
<span class="p_add">+			__put_compound_page(page);</span>
<span class="p_add">+			continue;</span>
<span class="p_add">+		}</span>
<span class="p_add">+</span>
 		if (PageLRU(page)) {
 			struct zone *pagezone = page_zone(page);
 

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



