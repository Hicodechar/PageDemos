
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>[5/9] PCI: host: brcmstb: add dma-ranges for inbound traffic - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    [5/9] PCI: host: brcmstb: add dma-ranges for inbound traffic</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=117971">Jim Quinlan</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>Oct. 11, 2017, 10:34 p.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;1507761269-7017-6-git-send-email-jim2101024@gmail.com&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/10000719/mbox/"
   >mbox</a>
|
   <a href="/patch/10000719/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/10000719/">/patch/10000719/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
	[172.30.200.125])
	by pdx-korg-patchwork.web.codeaurora.org (Postfix) with ESMTP id
	6F41C60216 for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Wed, 11 Oct 2017 22:35:10 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 55BB728BB9
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Wed, 11 Oct 2017 22:35:10 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id 49E5E28BBC; Wed, 11 Oct 2017 22:35:10 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-6.9 required=2.0 tests=BAYES_00,
	DKIM_ADSP_CUSTOM_MED, 
	FREEMAIL_FROM,RCVD_IN_DNSWL_HI autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id E8AFB28BB9
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Wed, 11 Oct 2017 22:35:08 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1752792AbdJKWfG (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Wed, 11 Oct 2017 18:35:06 -0400
Received: from rnd-relay.smtp.broadcom.com ([192.19.229.170]:55399 &quot;EHLO
	rnd-relay.smtp.broadcom.com&quot; rhost-flags-OK-OK-OK-OK)
	by vger.kernel.org with ESMTP id S1751964AbdJKWfA (ORCPT
	&lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Wed, 11 Oct 2017 18:35:00 -0400
Received: from mail-irv-17.broadcom.com (mail-irv-17.lvn.broadcom.net
	[10.75.224.233])
	by rnd-relay.smtp.broadcom.com (Postfix) with ESMTP id 12A1F30C030;
	Wed, 11 Oct 2017 15:34:59 -0700 (PDT)
Received: from stbsrv-and-3.and.broadcom.com (stbsrv-and-3.and.broadcom.com
	[10.28.16.21])
	by mail-irv-17.broadcom.com (Postfix) with ESMTP id C361181EAD;
	Wed, 11 Oct 2017 15:34:56 -0700 (PDT)
From: Jim Quinlan &lt;jim2101024@gmail.com&gt;
To: linux-kernel@vger.kernel.org
Cc: bcm-kernel-feedback-list@broadcom.com,
	linux-arm-kernel@lists.infradead.org, linux-mips@linux-mips.org,
	devicetree@vger.kernel.org, linux-pci@vger.kernel.org,
	Florian Fainelli &lt;f.fainelli@gmail.com&gt;,
	Ralf Baechle &lt;ralf@linux-mips.org&gt;,
	Catalin Marinas &lt;catalin.marinas@arm.com&gt;,
	Will Deacon &lt;will.deacon@arm.com&gt;, Bjorn Helgaas &lt;bhelgaas@google.com&gt;,
	Rob Herring &lt;robh+dt@kernel.org&gt;, Mark Rutland &lt;mark.rutland@arm.com&gt;,
	Gregory Fong &lt;gregory.0xf0@gmail.com&gt;,
	Kevin Cernekee &lt;cernekee@gmail.com&gt;,
	Brian Norris &lt;computersforpeace@gmail.com&gt;,
	Jim Quinlan &lt;jim2101024@gmail.com&gt;
Subject: [PATCH 5/9] PCI: host: brcmstb: add dma-ranges for inbound traffic
Date: Wed, 11 Oct 2017 18:34:25 -0400
Message-Id: &lt;1507761269-7017-6-git-send-email-jim2101024@gmail.com&gt;
X-Mailer: git-send-email 1.9.0.138.g2de3478
In-Reply-To: &lt;1507761269-7017-1-git-send-email-jim2101024@gmail.com&gt;
References: &lt;1507761269-7017-1-git-send-email-jim2101024@gmail.com&gt;
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=117971">Jim Quinlan</a> - Oct. 11, 2017, 10:34 p.m.</div>
<pre class="content">
The Broadcom STB PCIe host controller is intimately related to the
memory subsystem.  This close relationship adds complexity to how cpu
system memory is mapped to PCIe memory.  Ideally, this mapping is an
identity mapping, or an identity mapping off by a constant.  Not so in
this case.

Consider the Broadcom reference board BCM97445LCC_4X8 which has 6 GB
of system memory.  Here is how the PCIe controller maps the
system memory to PCIe memory:

  memc0-a@[        0....3fffffff] &lt;=&gt; pci@[        0....3fffffff]
  memc0-b@[100000000...13fffffff] &lt;=&gt; pci@[ 40000000....7fffffff]
  memc1-a@[ 40000000....7fffffff] &lt;=&gt; pci@[ 80000000....bfffffff]
  memc1-b@[300000000...33fffffff] &lt;=&gt; pci@[ c0000000....ffffffff]
  memc2-a@[ 80000000....bfffffff] &lt;=&gt; pci@[100000000...13fffffff]
  memc2-b@[c00000000...c3fffffff] &lt;=&gt; pci@[140000000...17fffffff]

Although there are some &quot;gaps&quot; that can be added between the
individual mappings by software, the permutation of memory regions for
the most part is fixed by HW.  The solution of having something close
to an identity mapping is not possible.

The idea behind this HW design is that the same PCIe module can
act as an RC or EP, and if it acts as an EP it concatenates all
of system memory into a BAR so anything can be accessed.  Unfortunately,
when the PCIe block is in the role of an RC it also presents this
&quot;BAR&quot; to downstream PCIe devices, rather than offering an identity map
between its system memory and PCIe space.

Suppose that an endpoint driver allocs some DMA memory.  Suppose this
memory is located at 0x6000_0000, which is in the middle of memc1-a.
The driver wants a dma_addr_t value that it can pass on to the EP to
use.  Without doing any custom mapping, the EP will use this value for
DMA: the driver will get a dma_addr_t equal to 0x6000_0000.  But this
won&#39;t work; the device needs a dma_addr_t that reflects the PCIe space
address, namely 0xa000_0000.

So, essentially the solution to this problem must modify the
dma_addr_t returned by the DMA routines routines.  There are two
ways (I know of) of doing this:

(a) overriding/redefining the dma_to_phys() and phys_to_dma() calls
that are used by the dma_ops routines.  This is the approach of

	arch/mips/cavium-octeon/dma-octeon.c

In ARM and ARM64 these two routines are defiend in asm/dma-mapping.h
as static inline functions.

(b) Subscribe to a notifier that notifies when a device is added to a
bus.  When this happens, set_dma_ops() can be called for the device.
This method is mentioned in:

    http://lxr.free-electrons.com/source/drivers/of/platform.c?v=3.16#L152

where it says as a comment

    &quot;In case if platform code need to use own special DMA
    configuration, it can use Platform bus notifier and
    handle BUS_NOTIFY_ADD_DEVICE event to fix up DMA
    configuration.&quot;

Solution (b) is what this commit does.  It uses the native dma_ops
as the base set of operations, and overrides some with custom
functions that translate the address and then call the base
function.
<span class="signed-off-by">
Signed-off-by: Jim Quinlan &lt;jim2101024@gmail.com&gt;</span>
---
 drivers/pci/host/Makefile          |   3 +-
 drivers/pci/host/pci-brcmstb-dma.c | 219 +++++++++++++++++++++++++++++++++++++
 drivers/pci/host/pci-brcmstb.c     | 150 +++++++++++++++++++++++--
 drivers/pci/host/pci-brcmstb.h     |   7 ++
 4 files changed, 368 insertions(+), 11 deletions(-)
 create mode 100644 drivers/pci/host/pci-brcmstb-dma.c
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=77581">Robin Murphy</a> - Oct. 12, 2017, 6:04 p.m.</div>
<pre class="content">
[+DMA API maintainers]

On 11/10/17 23:34, Jim Quinlan wrote:
<span class="quote">&gt; The Broadcom STB PCIe host controller is intimately related to the</span>
<span class="quote">&gt; memory subsystem.  This close relationship adds complexity to how cpu</span>
<span class="quote">&gt; system memory is mapped to PCIe memory.  Ideally, this mapping is an</span>
<span class="quote">&gt; identity mapping, or an identity mapping off by a constant.  Not so in</span>
<span class="quote">&gt; this case.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Consider the Broadcom reference board BCM97445LCC_4X8 which has 6 GB</span>
<span class="quote">&gt; of system memory.  Here is how the PCIe controller maps the</span>
<span class="quote">&gt; system memory to PCIe memory:</span>
<span class="quote">&gt; </span>
<span class="quote">&gt;   memc0-a@[        0....3fffffff] &lt;=&gt; pci@[        0....3fffffff]</span>
<span class="quote">&gt;   memc0-b@[100000000...13fffffff] &lt;=&gt; pci@[ 40000000....7fffffff]</span>
<span class="quote">&gt;   memc1-a@[ 40000000....7fffffff] &lt;=&gt; pci@[ 80000000....bfffffff]</span>
<span class="quote">&gt;   memc1-b@[300000000...33fffffff] &lt;=&gt; pci@[ c0000000....ffffffff]</span>
<span class="quote">&gt;   memc2-a@[ 80000000....bfffffff] &lt;=&gt; pci@[100000000...13fffffff]</span>
<span class="quote">&gt;   memc2-b@[c00000000...c3fffffff] &lt;=&gt; pci@[140000000...17fffffff]</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Although there are some &quot;gaps&quot; that can be added between the</span>
<span class="quote">&gt; individual mappings by software, the permutation of memory regions for</span>
<span class="quote">&gt; the most part is fixed by HW.  The solution of having something close</span>
<span class="quote">&gt; to an identity mapping is not possible.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; The idea behind this HW design is that the same PCIe module can</span>
<span class="quote">&gt; act as an RC or EP, and if it acts as an EP it concatenates all</span>
<span class="quote">&gt; of system memory into a BAR so anything can be accessed.  Unfortunately,</span>
<span class="quote">&gt; when the PCIe block is in the role of an RC it also presents this</span>
<span class="quote">&gt; &quot;BAR&quot; to downstream PCIe devices, rather than offering an identity map</span>
<span class="quote">&gt; between its system memory and PCIe space.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Suppose that an endpoint driver allocs some DMA memory.  Suppose this</span>
<span class="quote">&gt; memory is located at 0x6000_0000, which is in the middle of memc1-a.</span>
<span class="quote">&gt; The driver wants a dma_addr_t value that it can pass on to the EP to</span>
<span class="quote">&gt; use.  Without doing any custom mapping, the EP will use this value for</span>
<span class="quote">&gt; DMA: the driver will get a dma_addr_t equal to 0x6000_0000.  But this</span>
<span class="quote">&gt; won&#39;t work; the device needs a dma_addr_t that reflects the PCIe space</span>
<span class="quote">&gt; address, namely 0xa000_0000.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; So, essentially the solution to this problem must modify the</span>
<span class="quote">&gt; dma_addr_t returned by the DMA routines routines.  There are two</span>
<span class="quote">&gt; ways (I know of) of doing this:</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; (a) overriding/redefining the dma_to_phys() and phys_to_dma() calls</span>
<span class="quote">&gt; that are used by the dma_ops routines.  This is the approach of</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; 	arch/mips/cavium-octeon/dma-octeon.c</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; In ARM and ARM64 these two routines are defiend in asm/dma-mapping.h</span>
<span class="quote">&gt; as static inline functions.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; (b) Subscribe to a notifier that notifies when a device is added to a</span>
<span class="quote">&gt; bus.  When this happens, set_dma_ops() can be called for the device.</span>
<span class="quote">&gt; This method is mentioned in:</span>
<span class="quote">&gt; </span>
<span class="quote">&gt;     http://lxr.free-electrons.com/source/drivers/of/platform.c?v=3.16#L152</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; where it says as a comment</span>
<span class="quote">&gt; </span>
<span class="quote">&gt;     &quot;In case if platform code need to use own special DMA</span>
<span class="quote">&gt;     configuration, it can use Platform bus notifier and</span>
<span class="quote">&gt;     handle BUS_NOTIFY_ADD_DEVICE event to fix up DMA</span>
<span class="quote">&gt;     configuration.&quot;</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Solution (b) is what this commit does.  It uses the native dma_ops</span>
<span class="quote">&gt; as the base set of operations, and overrides some with custom</span>
<span class="quote">&gt; functions that translate the address and then call the base</span>
<span class="quote">&gt; function.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Signed-off-by: Jim Quinlan &lt;jim2101024@gmail.com&gt;</span>
<span class="quote">&gt; ---</span>
<span class="quote">&gt;  drivers/pci/host/Makefile          |   3 +-</span>
<span class="quote">&gt;  drivers/pci/host/pci-brcmstb-dma.c | 219 +++++++++++++++++++++++++++++++++++++</span>
<span class="quote">&gt;  drivers/pci/host/pci-brcmstb.c     | 150 +++++++++++++++++++++++--</span>
<span class="quote">&gt;  drivers/pci/host/pci-brcmstb.h     |   7 ++</span>
<span class="quote">&gt;  4 files changed, 368 insertions(+), 11 deletions(-)</span>
<span class="quote">&gt;  create mode 100644 drivers/pci/host/pci-brcmstb-dma.c</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; diff --git a/drivers/pci/host/Makefile b/drivers/pci/host/Makefile</span>
<span class="quote">&gt; index 4398d2c..c283321 100644</span>
<span class="quote">&gt; --- a/drivers/pci/host/Makefile</span>
<span class="quote">&gt; +++ b/drivers/pci/host/Makefile</span>
<span class="quote">&gt; @@ -21,7 +21,8 @@ obj-$(CONFIG_PCIE_ROCKCHIP) += pcie-rockchip.o</span>
<span class="quote">&gt;  obj-$(CONFIG_PCIE_MEDIATEK) += pcie-mediatek.o</span>
<span class="quote">&gt;  obj-$(CONFIG_PCIE_TANGO_SMP8759) += pcie-tango.o</span>
<span class="quote">&gt;  obj-$(CONFIG_VMD) += vmd.o</span>
<span class="quote">&gt; -obj-$(CONFIG_PCI_BRCMSTB) += pci-brcmstb.o</span>
<span class="quote">&gt; +obj-$(CONFIG_PCI_BRCMSTB) += brcmstb-pci.o</span>
<span class="quote">&gt; +brcmstb-pci-objs := pci-brcmstb.o pci-brcmstb-dma.o</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  # The following drivers are for devices that use the generic ACPI</span>
<span class="quote">&gt;  # pci_root.c driver but don&#39;t support standard ECAM config access.</span>
<span class="quote">&gt; diff --git a/drivers/pci/host/pci-brcmstb-dma.c b/drivers/pci/host/pci-brcmstb-dma.c</span>
<span class="quote">&gt; new file mode 100644</span>
<span class="quote">&gt; index 0000000..81ce122</span>
<span class="quote">&gt; --- /dev/null</span>
<span class="quote">&gt; +++ b/drivers/pci/host/pci-brcmstb-dma.c</span>
<span class="quote">&gt; @@ -0,0 +1,219 @@</span>
<span class="quote">&gt; +/*</span>
<span class="quote">&gt; + * Copyright (C) 2015-2017 Broadcom</span>
<span class="quote">&gt; + *</span>
<span class="quote">&gt; + * This program is free software; you can redistribute it and/or modify</span>
<span class="quote">&gt; + * it under the terms of the GNU General Public License version 2 as</span>
<span class="quote">&gt; + * published by the Free Software Foundation.</span>
<span class="quote">&gt; + *</span>
<span class="quote">&gt; + * This program is distributed in the hope that it will be useful,</span>
<span class="quote">&gt; + * but WITHOUT ANY WARRANTY; without even the implied warranty of</span>
<span class="quote">&gt; + * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the</span>
<span class="quote">&gt; + * GNU General Public License for more details.</span>
<span class="quote">&gt; + *</span>
<span class="quote">&gt; + */</span>
<span class="quote">&gt; +#include &lt;linux/dma-mapping.h&gt;</span>
<span class="quote">&gt; +#include &lt;linux/init.h&gt;</span>
<span class="quote">&gt; +#include &lt;linux/io.h&gt;</span>
<span class="quote">&gt; +#include &lt;linux/kernel.h&gt;</span>
<span class="quote">&gt; +#include &lt;linux/of_address.h&gt;</span>
<span class="quote">&gt; +#include &lt;linux/pci.h&gt;</span>
<span class="quote">&gt; +#include &lt;linux/platform_device.h&gt;</span>
<span class="quote">&gt; +#include &lt;linux/smp.h&gt;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +#include &quot;pci-brcmstb.h&quot;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +static const struct dma_map_ops *arch_dma_ops;</span>
<span class="quote">&gt; +static struct dma_map_ops brcm_dma_ops;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +static void *brcm_dma_alloc(struct device *dev, size_t size, dma_addr_t *handle,</span>
<span class="quote">&gt; +			    gfp_t gfp, unsigned long attrs)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	void *ret;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	ret = arch_dma_ops-&gt;alloc(dev, size, handle, gfp, attrs);</span>
<span class="quote">&gt; +	if (ret)</span>
<span class="quote">&gt; +		*handle = brcm_to_pci(*handle);</span>
<span class="quote">&gt; +	return ret;</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +static void brcm_dma_free(struct device *dev, size_t size, void *cpu_addr,</span>
<span class="quote">&gt; +			  dma_addr_t handle, unsigned long attrs)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	handle = brcm_to_cpu(handle);</span>
<span class="quote">&gt; +	arch_dma_ops-&gt;free(dev, size, cpu_addr, handle, attrs);</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +static int brcm_dma_mmap(struct device *dev, struct vm_area_struct *vma,</span>
<span class="quote">&gt; +			 void *cpu_addr, dma_addr_t dma_addr, size_t size,</span>
<span class="quote">&gt; +			 unsigned long attrs)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	dma_addr = brcm_to_cpu(dma_addr);</span>
<span class="quote">&gt; +	return arch_dma_ops-&gt;mmap(dev, vma, cpu_addr, dma_addr, size, attrs);</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +static int brcm_dma_get_sgtable(struct device *dev, struct sg_table *sgt,</span>
<span class="quote">&gt; +				void *cpu_addr, dma_addr_t handle, size_t size,</span>
<span class="quote">&gt; +				unsigned long attrs)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	handle = brcm_to_cpu(handle);</span>
<span class="quote">&gt; +	return arch_dma_ops-&gt;get_sgtable(dev, sgt, cpu_addr, handle, size,</span>
<span class="quote">&gt; +				       attrs);</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +static dma_addr_t brcm_dma_map_page(struct device *dev, struct page *page,</span>
<span class="quote">&gt; +				    unsigned long offset, size_t size,</span>
<span class="quote">&gt; +				    enum dma_data_direction dir,</span>
<span class="quote">&gt; +				    unsigned long attrs)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	return brcm_to_pci(arch_dma_ops-&gt;map_page(dev, page, offset, size,</span>
<span class="quote">&gt; +						  dir, attrs));</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +static void brcm_dma_unmap_page(struct device *dev, dma_addr_t handle,</span>
<span class="quote">&gt; +				size_t size, enum dma_data_direction dir,</span>
<span class="quote">&gt; +				unsigned long attrs)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	handle = brcm_to_cpu(handle);</span>
<span class="quote">&gt; +	arch_dma_ops-&gt;unmap_page(dev, handle, size, dir, attrs);</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +static int brcm_dma_map_sg(struct device *dev, struct scatterlist *sgl,</span>
<span class="quote">&gt; +			   int nents, enum dma_data_direction dir,</span>
<span class="quote">&gt; +			   unsigned long attrs)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	int ret, i;</span>
<span class="quote">&gt; +	struct scatterlist *sg;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	ret = arch_dma_ops-&gt;map_sg(dev, sgl, nents, dir, attrs);</span>
<span class="quote">&gt; +	/* The ARM and MIPS implementations of map_sg and unmap_sg</span>
<span class="quote">&gt; +	 * make calls to ops-&gt;map_page(), which we already intercept.</span>
<span class="quote">&gt; +	 * The ARM64 does not, so we must iterate through the SG list</span>
<span class="quote">&gt; +	 * and  convert each dma_address to one that is compatible</span>
<span class="quote">&gt; +	 * with our PCI RC implementation.</span>
<span class="quote">&gt; +	 */</span>

That&#39;s a pretty fragile assumption given that arch code is free to
change, and anyone doing so is unlikely to be aware of your driver.
You&#39;d be better off implementing these in terms of {brcm_dma_}map_page
directly.
<span class="quote">
&gt; +	if (IS_ENABLED(CONFIG_ARM64))</span>
<span class="quote">&gt; +		for_each_sg(sgl, sg, ret, i)</span>
<span class="quote">&gt; +			sg-&gt;dma_address = brcm_to_pci(sg-&gt;dma_address);</span>
<span class="quote">&gt; +	return ret;</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +static void brcm_dma_unmap_sg(struct device *dev,</span>
<span class="quote">&gt; +			      struct scatterlist *sgl, int nents,</span>
<span class="quote">&gt; +			      enum dma_data_direction dir,</span>
<span class="quote">&gt; +			      unsigned long attrs)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	int i;</span>
<span class="quote">&gt; +	struct scatterlist *sg;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	/* The ARM and MIPS implementations of map_sg and unmap_sg</span>
<span class="quote">&gt; +	 * make calls to ops-&gt;map_page(), which we already intercept.</span>
<span class="quote">&gt; +	 * The ARM64 does not, so we must iterate through the SG list</span>
<span class="quote">&gt; +	 * and  convert each dma_address to one that is compatible</span>
<span class="quote">&gt; +	 * with our PCI RC implementation.</span>
<span class="quote">&gt; +	 */</span>
<span class="quote">&gt; +	if (IS_ENABLED(CONFIG_ARM64))</span>
<span class="quote">&gt; +		for_each_sg(sgl, sg, nents, i)</span>
<span class="quote">&gt; +			sg-&gt;dma_address = brcm_to_cpu(sg-&gt;dma_address);</span>
<span class="quote">&gt; +	arch_dma_ops-&gt;map_sg(dev, sgl, nents, dir, attrs);</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +static void brcm_dma_sync_single_for_cpu(struct device *dev,</span>
<span class="quote">&gt; +					 dma_addr_t handle, size_t size,</span>
<span class="quote">&gt; +					 enum dma_data_direction dir)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	handle = brcm_to_cpu(handle);</span>
<span class="quote">&gt; +	arch_dma_ops-&gt;sync_single_for_cpu(dev, handle, size, dir);</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +static void brcm_dma_sync_single_for_device(struct device *dev,</span>
<span class="quote">&gt; +					    dma_addr_t handle, size_t size,</span>
<span class="quote">&gt; +					    enum dma_data_direction dir)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	handle = brcm_to_cpu(handle);</span>
<span class="quote">&gt; +	arch_dma_ops-&gt;sync_single_for_device(dev, handle, size, dir);</span>
<span class="quote">&gt; +}</span>

And sync_sg_*()? They might not be that commonly used by in-tree
drivers, but who knows what lurks beyond?
<span class="quote">
&gt; +</span>
<span class="quote">&gt; +static dma_addr_t brcm_dma_map_resource(struct device *dev, phys_addr_t phys,</span>
<span class="quote">&gt; +					size_t size,</span>
<span class="quote">&gt; +					enum dma_data_direction dir,</span>
<span class="quote">&gt; +					unsigned long attrs)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	return brcm_to_pci(arch_dma_ops-&gt;map_resource</span>
<span class="quote">&gt; +			   (dev, phys, size, dir, attrs));</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +static void brcm_dma_unmap_resource(struct device *dev, dma_addr_t handle,</span>
<span class="quote">&gt; +				    size_t size, enum dma_data_direction dir,</span>
<span class="quote">&gt; +				    unsigned long attrs)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	handle = brcm_to_cpu(handle);</span>
<span class="quote">&gt; +	arch_dma_ops-&gt;unmap_resource(dev, handle, size, dir, attrs);</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +static int brcm_mapping_error(struct device *dev, dma_addr_t dma_addr)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	return dma_addr == BRCMSTB_ERROR_CODE;</span>

Huh? How do you know this will work correctly with every platform&#39;s
-&gt;map_page implementation (hint: it doesn&#39;t).
<span class="quote">
&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +static const struct dma_map_ops *brcm_get_arch_dma_ops(struct device *dev)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +#if defined(CONFIG_MIPS)</span>
<span class="quote">&gt; +	return mips_dma_map_ops;</span>
<span class="quote">&gt; +#elif defined(CONFIG_ARM)</span>
<span class="quote">&gt; +	return &amp;arm_dma_ops;</span>
<span class="quote">&gt; +#elif defined(CONFIG_ARM64)</span>
<span class="quote">&gt; +	/* swiotlb_dma_ops is a static var, so we get ahold</span>
<span class="quote">&gt; +	 * of it by calling arch_setup_dma_ops(...).</span>
<span class="quote">&gt; +	 */</span>
<span class="quote">&gt; +	arch_setup_dma_ops(dev, 0, 0, NULL, false);</span>
<span class="quote">&gt; +	return dev-&gt;dma_ops;</span>
<span class="quote">&gt; +#endif</span>
<span class="quote">&gt; +	return 0;</span>
<span class="quote">&gt; +}</span>

As mentioned earlier, no. There are theoretical cases where it might not
be true, but in practice you can assume all PCI devices are going to get
the same DMA ops as their associated host controller (and that&#39;s still a
better assumption that what you have here), so you can just grab those
at the point you install the notifier.
<span class="quote">
&gt; +</span>
<span class="quote">&gt; +static void brcm_set_dma_ops(struct device *dev)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	arch_dma_ops = brcm_get_arch_dma_ops(dev);</span>
<span class="quote">&gt; +	if (!arch_dma_ops)</span>
<span class="quote">&gt; +		return;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	/* Set all of the base operations; some will be overridden */</span>
<span class="quote">&gt; +	brcm_dma_ops = *arch_dma_ops;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	/* Insert the Brcm-specific override operations */</span>
<span class="quote">&gt; +	brcm_dma_ops.alloc = brcm_dma_alloc;</span>
<span class="quote">&gt; +	brcm_dma_ops.free = brcm_dma_free;</span>
<span class="quote">&gt; +	brcm_dma_ops.mmap = brcm_dma_mmap;</span>
<span class="quote">&gt; +	brcm_dma_ops.get_sgtable = brcm_dma_get_sgtable;</span>
<span class="quote">&gt; +	brcm_dma_ops.map_page = brcm_dma_map_page;</span>
<span class="quote">&gt; +	brcm_dma_ops.unmap_page = brcm_dma_unmap_page;</span>
<span class="quote">&gt; +	brcm_dma_ops.sync_single_for_cpu = brcm_dma_sync_single_for_cpu;</span>
<span class="quote">&gt; +	brcm_dma_ops.sync_single_for_device = brcm_dma_sync_single_for_device;</span>
<span class="quote">&gt; +	brcm_dma_ops.map_sg = brcm_dma_map_sg;</span>
<span class="quote">&gt; +	brcm_dma_ops.unmap_sg = brcm_dma_unmap_sg;</span>
<span class="quote">&gt; +	if (arch_dma_ops-&gt;map_resource)</span>
<span class="quote">&gt; +		brcm_dma_ops.map_resource = brcm_dma_map_resource;</span>
<span class="quote">&gt; +	if (arch_dma_ops-&gt;unmap_resource)</span>
<span class="quote">&gt; +		brcm_dma_ops.unmap_resource = brcm_dma_unmap_resource;</span>
<span class="quote">&gt; +	brcm_dma_ops.mapping_error = brcm_mapping_error;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	/* Use our brcm_dma_ops for this driver */</span>
<span class="quote">&gt; +	set_dma_ops(dev, &amp;brcm_dma_ops);</span>
<span class="quote">&gt; +}</span>

Just have a static const set of ops like everyone else - you can handle
the conditionality of -&gt;{map,unmap}_resource inside the brcm_* wrappers.
<span class="quote">
&gt; +</span>
<span class="quote">&gt; +static int brcmstb_platform_notifier(struct notifier_block *nb,</span>
<span class="quote">&gt; +				     unsigned long event, void *__dev)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	struct device *dev = __dev;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	if (event != BUS_NOTIFY_ADD_DEVICE)</span>
<span class="quote">&gt; +		return NOTIFY_DONE;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	brcm_set_dma_ops(dev);</span>
<span class="quote">&gt; +	return NOTIFY_OK;</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +struct notifier_block brcmstb_platform_nb = {</span>
<span class="quote">&gt; +	.notifier_call = brcmstb_platform_notifier,</span>
<span class="quote">&gt; +};</span>
<span class="quote">&gt; +EXPORT_SYMBOL(brcmstb_platform_nb);</span>
<span class="quote">&gt; diff --git a/drivers/pci/host/pci-brcmstb.c b/drivers/pci/host/pci-brcmstb.c</span>
<span class="quote">&gt; index f4cd6e7..03c0da9 100644</span>
<span class="quote">&gt; --- a/drivers/pci/host/pci-brcmstb.c</span>
<span class="quote">&gt; +++ b/drivers/pci/host/pci-brcmstb.c</span>
<span class="quote">&gt; @@ -343,6 +343,8 @@ struct brcm_pcie {</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  static struct list_head brcm_pcie = LIST_HEAD_INIT(brcm_pcie);</span>
<span class="quote">&gt;  static phys_addr_t scb_size[BRCM_MAX_SCB];</span>
<span class="quote">&gt; +static struct of_pci_range *dma_ranges;</span>
<span class="quote">&gt; +static int num_dma_ranges;</span>
<span class="quote">&gt;  static int num_memc;</span>
<span class="quote">&gt;  static DEFINE_MUTEX(brcm_pcie_lock);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; @@ -362,6 +364,8 @@ static int brcm_pcie_add_controller(struct brcm_pcie *pcie)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	mutex_lock(&amp;brcm_pcie_lock);</span>
<span class="quote">&gt;  	snprintf(pcie-&gt;name, sizeof(pcie-&gt;name) - 1, &quot;PCIe%d&quot;, pcie-&gt;id);</span>
<span class="quote">&gt; +	if (list_empty(&amp;brcm_pcie))</span>
<span class="quote">&gt; +		bus_register_notifier(&amp;pci_bus_type, &amp;brcmstb_platform_nb);</span>
<span class="quote">&gt;  	list_add_tail(&amp;pcie-&gt;list, &amp;brcm_pcie);</span>
<span class="quote">&gt;  	mutex_unlock(&amp;brcm_pcie_lock);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; @@ -378,8 +382,14 @@ static void brcm_pcie_remove_controller(struct brcm_pcie *pcie)</span>
<span class="quote">&gt;  		tmp = list_entry(pos, struct brcm_pcie, list);</span>
<span class="quote">&gt;  		if (tmp == pcie) {</span>
<span class="quote">&gt;  			list_del(pos);</span>
<span class="quote">&gt; -			if (list_empty(&amp;brcm_pcie))</span>
<span class="quote">&gt; +			if (list_empty(&amp;brcm_pcie)) {</span>
<span class="quote">&gt; +				bus_unregister_notifier(&amp;pci_bus_type,</span>
<span class="quote">&gt; +							&amp;brcmstb_platform_nb);</span>
<span class="quote">&gt; +				kfree(dma_ranges);</span>
<span class="quote">&gt; +				dma_ranges = NULL;</span>
<span class="quote">&gt; +				num_dma_ranges = 0;</span>
<span class="quote">&gt;  				num_memc = 0;</span>
<span class="quote">&gt; +			}</span>
<span class="quote">&gt;  			break;</span>
<span class="quote">&gt;  		}</span>
<span class="quote">&gt;  	}</span>
<span class="quote">&gt; @@ -403,6 +413,35 @@ int encode_ibar_size(u64 size)</span>
<span class="quote">&gt;  	return 0;</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; +dma_addr_t brcm_to_pci(dma_addr_t addr)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	struct of_pci_range *p;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	if (!num_dma_ranges)</span>
<span class="quote">&gt; +		return addr;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	for (p = dma_ranges; p &lt; &amp;dma_ranges[num_dma_ranges]; p++)</span>
<span class="quote">&gt; +		if (addr &gt;= p-&gt;cpu_addr &amp;&amp; addr &lt; (p-&gt;cpu_addr + p-&gt;size))</span>
<span class="quote">&gt; +			return addr - p-&gt;cpu_addr + p-&gt;pci_addr;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	return BRCMSTB_ERROR_CODE;</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +EXPORT_SYMBOL(brcm_to_pci);</span>

AFAICS it doesn&#39;t make much sense for anyone outside this driver to ever
be calling these.
<span class="quote">
&gt; +dma_addr_t brcm_to_cpu(dma_addr_t addr)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	struct of_pci_range *p;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	if (!num_dma_ranges)</span>
<span class="quote">&gt; +		return addr;</span>
<span class="quote">&gt; +	for (p = dma_ranges; p &lt; &amp;dma_ranges[num_dma_ranges]; p++)</span>
<span class="quote">&gt; +		if (addr &gt;= p-&gt;pci_addr &amp;&amp; addr &lt; (p-&gt;pci_addr + p-&gt;size))</span>
<span class="quote">&gt; +			return addr - p-&gt;pci_addr + p-&gt;cpu_addr;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	return addr;</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +EXPORT_SYMBOL(brcm_to_cpu);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt;  static u32 mdio_form_pkt(int port, int regad, int cmd)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	u32 pkt = 0;</span>
<span class="quote">&gt; @@ -652,6 +691,74 @@ static int brcm_parse_ranges(struct brcm_pcie *pcie)</span>
<span class="quote">&gt;  	return 0;</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; +static int brcm_pci_dma_range_parser_init(struct of_pci_range_parser *parser,</span>
<span class="quote">&gt; +					  struct device_node *node)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	const int na = 3, ns = 2;</span>
<span class="quote">&gt; +	int rlen;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	parser-&gt;node = node;</span>
<span class="quote">&gt; +	parser-&gt;pna = of_n_addr_cells(node);</span>
<span class="quote">&gt; +	parser-&gt;np = parser-&gt;pna + na + ns;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	parser-&gt;range = of_get_property(node, &quot;dma-ranges&quot;, &amp;rlen);</span>
<span class="quote">&gt; +	if (!parser-&gt;range)</span>
<span class="quote">&gt; +		return -ENOENT;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	parser-&gt;end = parser-&gt;range + rlen / sizeof(__be32);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	return 0;</span>
<span class="quote">&gt; +}</span>

Note that we&#39;ve got a factored-out helper for this queued in -next
already - see here:

https://patchwork.kernel.org/patch/9927541/
<span class="quote">
&gt; +</span>
<span class="quote">&gt; +static int brcm_parse_dma_ranges(struct brcm_pcie *pcie)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	int i, ret = 0;</span>
<span class="quote">&gt; +	struct of_pci_range_parser parser;</span>
<span class="quote">&gt; +	struct device_node *dn = pcie-&gt;dn;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	mutex_lock(&amp;brcm_pcie_lock);</span>
<span class="quote">&gt; +	if (dma_ranges)</span>
<span class="quote">&gt; +		goto done;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	/* Parse dma-ranges property if present.  If there are multiple</span>
<span class="quote">&gt; +	 * PCI controllers, we only have to parse from one of them since</span>
<span class="quote">&gt; +	 * the others will have an identical mapping.</span>
<span class="quote">&gt; +	 */</span>
<span class="quote">&gt; +	if (!brcm_pci_dma_range_parser_init(&amp;parser, dn)) {</span>
<span class="quote">&gt; +		unsigned int max_ranges</span>
<span class="quote">&gt; +			= (parser.end - parser.range) / parser.np;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +		dma_ranges = kcalloc(max_ranges, sizeof(struct of_pci_range),</span>
<span class="quote">&gt; +				     GFP_KERNEL);</span>
<span class="quote">&gt; +		if (!dma_ranges) {</span>
<span class="quote">&gt; +			ret =  -ENOMEM;</span>
<span class="quote">&gt; +			goto done;</span>
<span class="quote">&gt; +		}</span>
<span class="quote">&gt; +		for (i = 0; of_pci_range_parser_one(&amp;parser, dma_ranges + i);</span>
<span class="quote">&gt; +		     i++)</span>
<span class="quote">&gt; +			num_dma_ranges++;</span>
<span class="quote">&gt; +	}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	for (i = 0, num_memc = 0; i &lt; BRCM_MAX_SCB; i++) {</span>
<span class="quote">&gt; +		u64 size = brcmstb_memory_memc_size(i);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +		if (size == (u64)-1) {</span>
<span class="quote">&gt; +			dev_err(pcie-&gt;dev, &quot;cannot get memc%d size&quot;, i);</span>
<span class="quote">&gt; +			ret = -EINVAL;</span>
<span class="quote">&gt; +			goto done;</span>
<span class="quote">&gt; +		} else if (size) {</span>
<span class="quote">&gt; +			scb_size[i] = roundup_pow_of_two_64(size);</span>
<span class="quote">&gt; +			num_memc++;</span>
<span class="quote">&gt; +		} else {</span>
<span class="quote">&gt; +			break;</span>
<span class="quote">&gt; +		}</span>
<span class="quote">&gt; +	}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +done:</span>
<span class="quote">&gt; +	mutex_unlock(&amp;brcm_pcie_lock);</span>
<span class="quote">&gt; +	return ret;</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt;  static void set_regulators(struct brcm_pcie *pcie, bool on)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	struct list_head *pos;</span>
<span class="quote">&gt; @@ -728,10 +835,34 @@ static void brcm_pcie_setup_prep(struct brcm_pcie *pcie)</span>
<span class="quote">&gt;  	 */</span>
<span class="quote">&gt;  	rc_bar2_size = roundup_pow_of_two_64(total_mem_size);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; -	/* Set simple configuration based on memory sizes</span>
<span class="quote">&gt; -	 * only.  We always start the viewport at address 0.</span>
<span class="quote">&gt; -	 */</span>
<span class="quote">&gt; -	rc_bar2_offset = 0;</span>
<span class="quote">&gt; +	if (dma_ranges) {</span>
<span class="quote">&gt; +		/* The best-case scenario is to place the inbound</span>
<span class="quote">&gt; +		 * region in the first 4GB of pci-space, as some</span>
<span class="quote">&gt; +		 * legacy devices can only address 32bits.</span>
<span class="quote">&gt; +		 * We would also like to put the MSI under 4GB</span>
<span class="quote">&gt; +		 * as well, since some devices require a 32bit</span>
<span class="quote">&gt; +		 * MSI target address.</span>
<span class="quote">&gt; +		 */</span>
<span class="quote">&gt; +		if (total_mem_size &lt;= 0xc0000000ULL &amp;&amp;</span>
<span class="quote">&gt; +		    rc_bar2_size &lt;= 0x100000000ULL) {</span>
<span class="quote">&gt; +			rc_bar2_offset = 0;</span>
<span class="quote">&gt; +		} else {</span>
<span class="quote">&gt; +			/* The system memory is 4GB or larger so we</span>
<span class="quote">&gt; +			 * cannot start the inbound region at location</span>
<span class="quote">&gt; +			 * 0 (since we have to allow some space for</span>
<span class="quote">&gt; +			 * outbound memory @ 3GB).  So instead we</span>
<span class="quote">&gt; +			 * start it at the 1x multiple of its size</span>
<span class="quote">&gt; +			 */</span>
<span class="quote">&gt; +			rc_bar2_offset = rc_bar2_size;</span>
<span class="quote">&gt; +		}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	} else {</span>
<span class="quote">&gt; +		/* Set simple configuration based on memory sizes</span>
<span class="quote">&gt; +		 * only.  We always start the viewport at address 0,</span>
<span class="quote">&gt; +		 * and set the MSI target address accordingly.</span>
<span class="quote">&gt; +		 */</span>
<span class="quote">&gt; +		rc_bar2_offset = 0;</span>
<span class="quote">&gt; +	}</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	tmp = lower_32_bits(rc_bar2_offset);</span>
<span class="quote">&gt;  	tmp = INSERT_FIELD(tmp, PCIE_MISC_RC_BAR2_CONFIG_LO, SIZE,</span>
<span class="quote">&gt; @@ -1040,11 +1171,6 @@ static int brcm_pcie_probe(struct platform_device *pdev)</span>
<span class="quote">&gt;  		return -EINVAL;</span>
<span class="quote">&gt;  	}</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; -	if (of_property_read_u32(dn, &quot;dma-ranges&quot;, &amp;tmp) == 0) {</span>
<span class="quote">&gt; -		pr_err(&quot;cannot yet handle dma-ranges\n&quot;);</span>
<span class="quote">&gt; -		return -EINVAL;</span>
<span class="quote">&gt; -	}</span>
<span class="quote">&gt; -</span>
<span class="quote">&gt;  	data = of_id-&gt;data;</span>
<span class="quote">&gt;  	pcie-&gt;reg_offsets = data-&gt;offsets;</span>
<span class="quote">&gt;  	pcie-&gt;reg_field_info = data-&gt;reg_field_info;</span>
<span class="quote">&gt; @@ -1113,6 +1239,10 @@ static int brcm_pcie_probe(struct platform_device *pdev)</span>
<span class="quote">&gt;  	if (ret)</span>
<span class="quote">&gt;  		return ret;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; +	ret = brcm_parse_dma_ranges(pcie);</span>
<span class="quote">&gt; +	if (ret)</span>
<span class="quote">&gt; +		return ret;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt;  	ret = clk_prepare_enable(pcie-&gt;clk);</span>
<span class="quote">&gt;  	if (ret) {</span>
<span class="quote">&gt;  		dev_err(&amp;pdev-&gt;dev, &quot;could not enable clock\n&quot;);</span>
<span class="quote">&gt; diff --git a/drivers/pci/host/pci-brcmstb.h b/drivers/pci/host/pci-brcmstb.h</span>
<span class="quote">&gt; index 86f9cd1..4851be8 100644</span>
<span class="quote">&gt; --- a/drivers/pci/host/pci-brcmstb.h</span>
<span class="quote">&gt; +++ b/drivers/pci/host/pci-brcmstb.h</span>
<span class="quote">&gt; @@ -21,6 +21,13 @@</span>
<span class="quote">&gt;  /* Broadcom PCIE Offsets */</span>
<span class="quote">&gt;  #define PCIE_INTR2_CPU_BASE		0x4300</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; +dma_addr_t brcm_to_pci(dma_addr_t addr);</span>
<span class="quote">&gt; +dma_addr_t brcm_to_cpu(dma_addr_t addr);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +extern struct notifier_block brcmstb_platform_nb;</span>

It seems a bit weird to have the notifier code split across two
compilation units in the way which requires this - it seems more
reasonable to have it all together on one side or the other, with the
common interface being either the callback for setting the ops or a
function for installing the notifier, depending on where things fall.

Robin.
<span class="quote">
&gt; +</span>
<span class="quote">&gt; +#define BRCMSTB_ERROR_CODE	(~(dma_addr_t)0x0)</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt;  #if defined(CONFIG_MIPS)</span>
<span class="quote">&gt;  /* Broadcom MIPs HW implicitly does the swapping if necessary */</span>
<span class="quote">&gt;  #define bcm_readl(a)		__raw_readl(a)</span>
<span class="quote">&gt;</span>
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=117971">Jim Quinlan</a> - Oct. 12, 2017, 9:43 p.m.</div>
<pre class="content">
On Thu, Oct 12, 2017 at 2:04 PM, Robin Murphy &lt;robin.murphy@arm.com&gt; wrote:
<span class="quote">&gt; [+DMA API maintainers]</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; On 11/10/17 23:34, Jim Quinlan wrote:</span>
<span class="quote">&gt;&gt; The Broadcom STB PCIe host controller is intimately related to the</span>
<span class="quote">&gt;&gt; memory subsystem.  This close relationship adds complexity to how cpu</span>
<span class="quote">&gt;&gt; system memory is mapped to PCIe memory.  Ideally, this mapping is an</span>
<span class="quote">&gt;&gt; identity mapping, or an identity mapping off by a constant.  Not so in</span>
<span class="quote">&gt;&gt; this case.</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; Consider the Broadcom reference board BCM97445LCC_4X8 which has 6 GB</span>
<span class="quote">&gt;&gt; of system memory.  Here is how the PCIe controller maps the</span>
<span class="quote">&gt;&gt; system memory to PCIe memory:</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt;   memc0-a@[        0....3fffffff] &lt;=&gt; pci@[        0....3fffffff]</span>
<span class="quote">&gt;&gt;   memc0-b@[100000000...13fffffff] &lt;=&gt; pci@[ 40000000....7fffffff]</span>
<span class="quote">&gt;&gt;   memc1-a@[ 40000000....7fffffff] &lt;=&gt; pci@[ 80000000....bfffffff]</span>
<span class="quote">&gt;&gt;   memc1-b@[300000000...33fffffff] &lt;=&gt; pci@[ c0000000....ffffffff]</span>
<span class="quote">&gt;&gt;   memc2-a@[ 80000000....bfffffff] &lt;=&gt; pci@[100000000...13fffffff]</span>
<span class="quote">&gt;&gt;   memc2-b@[c00000000...c3fffffff] &lt;=&gt; pci@[140000000...17fffffff]</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; Although there are some &quot;gaps&quot; that can be added between the</span>
<span class="quote">&gt;&gt; individual mappings by software, the permutation of memory regions for</span>
<span class="quote">&gt;&gt; the most part is fixed by HW.  The solution of having something close</span>
<span class="quote">&gt;&gt; to an identity mapping is not possible.</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; The idea behind this HW design is that the same PCIe module can</span>
<span class="quote">&gt;&gt; act as an RC or EP, and if it acts as an EP it concatenates all</span>
<span class="quote">&gt;&gt; of system memory into a BAR so anything can be accessed.  Unfortunately,</span>
<span class="quote">&gt;&gt; when the PCIe block is in the role of an RC it also presents this</span>
<span class="quote">&gt;&gt; &quot;BAR&quot; to downstream PCIe devices, rather than offering an identity map</span>
<span class="quote">&gt;&gt; between its system memory and PCIe space.</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; Suppose that an endpoint driver allocs some DMA memory.  Suppose this</span>
<span class="quote">&gt;&gt; memory is located at 0x6000_0000, which is in the middle of memc1-a.</span>
<span class="quote">&gt;&gt; The driver wants a dma_addr_t value that it can pass on to the EP to</span>
<span class="quote">&gt;&gt; use.  Without doing any custom mapping, the EP will use this value for</span>
<span class="quote">&gt;&gt; DMA: the driver will get a dma_addr_t equal to 0x6000_0000.  But this</span>
<span class="quote">&gt;&gt; won&#39;t work; the device needs a dma_addr_t that reflects the PCIe space</span>
<span class="quote">&gt;&gt; address, namely 0xa000_0000.</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; So, essentially the solution to this problem must modify the</span>
<span class="quote">&gt;&gt; dma_addr_t returned by the DMA routines routines.  There are two</span>
<span class="quote">&gt;&gt; ways (I know of) of doing this:</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; (a) overriding/redefining the dma_to_phys() and phys_to_dma() calls</span>
<span class="quote">&gt;&gt; that are used by the dma_ops routines.  This is the approach of</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt;       arch/mips/cavium-octeon/dma-octeon.c</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; In ARM and ARM64 these two routines are defiend in asm/dma-mapping.h</span>
<span class="quote">&gt;&gt; as static inline functions.</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; (b) Subscribe to a notifier that notifies when a device is added to a</span>
<span class="quote">&gt;&gt; bus.  When this happens, set_dma_ops() can be called for the device.</span>
<span class="quote">&gt;&gt; This method is mentioned in:</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt;     http://lxr.free-electrons.com/source/drivers/of/platform.c?v=3.16#L152</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; where it says as a comment</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt;     &quot;In case if platform code need to use own special DMA</span>
<span class="quote">&gt;&gt;     configuration, it can use Platform bus notifier and</span>
<span class="quote">&gt;&gt;     handle BUS_NOTIFY_ADD_DEVICE event to fix up DMA</span>
<span class="quote">&gt;&gt;     configuration.&quot;</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; Solution (b) is what this commit does.  It uses the native dma_ops</span>
<span class="quote">&gt;&gt; as the base set of operations, and overrides some with custom</span>
<span class="quote">&gt;&gt; functions that translate the address and then call the base</span>
<span class="quote">&gt;&gt; function.</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; Signed-off-by: Jim Quinlan &lt;jim2101024@gmail.com&gt;</span>
<span class="quote">&gt;&gt; ---</span>
<span class="quote">&gt;&gt;  drivers/pci/host/Makefile          |   3 +-</span>
<span class="quote">&gt;&gt;  drivers/pci/host/pci-brcmstb-dma.c | 219 +++++++++++++++++++++++++++++++++++++</span>
<span class="quote">&gt;&gt;  drivers/pci/host/pci-brcmstb.c     | 150 +++++++++++++++++++++++--</span>
<span class="quote">&gt;&gt;  drivers/pci/host/pci-brcmstb.h     |   7 ++</span>
<span class="quote">&gt;&gt;  4 files changed, 368 insertions(+), 11 deletions(-)</span>
<span class="quote">&gt;&gt;  create mode 100644 drivers/pci/host/pci-brcmstb-dma.c</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; diff --git a/drivers/pci/host/Makefile b/drivers/pci/host/Makefile</span>
<span class="quote">&gt;&gt; index 4398d2c..c283321 100644</span>
<span class="quote">&gt;&gt; --- a/drivers/pci/host/Makefile</span>
<span class="quote">&gt;&gt; +++ b/drivers/pci/host/Makefile</span>
<span class="quote">&gt;&gt; @@ -21,7 +21,8 @@ obj-$(CONFIG_PCIE_ROCKCHIP) += pcie-rockchip.o</span>
<span class="quote">&gt;&gt;  obj-$(CONFIG_PCIE_MEDIATEK) += pcie-mediatek.o</span>
<span class="quote">&gt;&gt;  obj-$(CONFIG_PCIE_TANGO_SMP8759) += pcie-tango.o</span>
<span class="quote">&gt;&gt;  obj-$(CONFIG_VMD) += vmd.o</span>
<span class="quote">&gt;&gt; -obj-$(CONFIG_PCI_BRCMSTB) += pci-brcmstb.o</span>
<span class="quote">&gt;&gt; +obj-$(CONFIG_PCI_BRCMSTB) += brcmstb-pci.o</span>
<span class="quote">&gt;&gt; +brcmstb-pci-objs := pci-brcmstb.o pci-brcmstb-dma.o</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt;  # The following drivers are for devices that use the generic ACPI</span>
<span class="quote">&gt;&gt;  # pci_root.c driver but don&#39;t support standard ECAM config access.</span>
<span class="quote">&gt;&gt; diff --git a/drivers/pci/host/pci-brcmstb-dma.c b/drivers/pci/host/pci-brcmstb-dma.c</span>
<span class="quote">&gt;&gt; new file mode 100644</span>
<span class="quote">&gt;&gt; index 0000000..81ce122</span>
<span class="quote">&gt;&gt; --- /dev/null</span>
<span class="quote">&gt;&gt; +++ b/drivers/pci/host/pci-brcmstb-dma.c</span>
<span class="quote">&gt;&gt; @@ -0,0 +1,219 @@</span>
<span class="quote">&gt;&gt; +/*</span>
<span class="quote">&gt;&gt; + * Copyright (C) 2015-2017 Broadcom</span>
<span class="quote">&gt;&gt; + *</span>
<span class="quote">&gt;&gt; + * This program is free software; you can redistribute it and/or modify</span>
<span class="quote">&gt;&gt; + * it under the terms of the GNU General Public License version 2 as</span>
<span class="quote">&gt;&gt; + * published by the Free Software Foundation.</span>
<span class="quote">&gt;&gt; + *</span>
<span class="quote">&gt;&gt; + * This program is distributed in the hope that it will be useful,</span>
<span class="quote">&gt;&gt; + * but WITHOUT ANY WARRANTY; without even the implied warranty of</span>
<span class="quote">&gt;&gt; + * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the</span>
<span class="quote">&gt;&gt; + * GNU General Public License for more details.</span>
<span class="quote">&gt;&gt; + *</span>
<span class="quote">&gt;&gt; + */</span>
<span class="quote">&gt;&gt; +#include &lt;linux/dma-mapping.h&gt;</span>
<span class="quote">&gt;&gt; +#include &lt;linux/init.h&gt;</span>
<span class="quote">&gt;&gt; +#include &lt;linux/io.h&gt;</span>
<span class="quote">&gt;&gt; +#include &lt;linux/kernel.h&gt;</span>
<span class="quote">&gt;&gt; +#include &lt;linux/of_address.h&gt;</span>
<span class="quote">&gt;&gt; +#include &lt;linux/pci.h&gt;</span>
<span class="quote">&gt;&gt; +#include &lt;linux/platform_device.h&gt;</span>
<span class="quote">&gt;&gt; +#include &lt;linux/smp.h&gt;</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +#include &quot;pci-brcmstb.h&quot;</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +static const struct dma_map_ops *arch_dma_ops;</span>
<span class="quote">&gt;&gt; +static struct dma_map_ops brcm_dma_ops;</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +static void *brcm_dma_alloc(struct device *dev, size_t size, dma_addr_t *handle,</span>
<span class="quote">&gt;&gt; +                         gfp_t gfp, unsigned long attrs)</span>
<span class="quote">&gt;&gt; +{</span>
<span class="quote">&gt;&gt; +     void *ret;</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +     ret = arch_dma_ops-&gt;alloc(dev, size, handle, gfp, attrs);</span>
<span class="quote">&gt;&gt; +     if (ret)</span>
<span class="quote">&gt;&gt; +             *handle = brcm_to_pci(*handle);</span>
<span class="quote">&gt;&gt; +     return ret;</span>
<span class="quote">&gt;&gt; +}</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +static void brcm_dma_free(struct device *dev, size_t size, void *cpu_addr,</span>
<span class="quote">&gt;&gt; +                       dma_addr_t handle, unsigned long attrs)</span>
<span class="quote">&gt;&gt; +{</span>
<span class="quote">&gt;&gt; +     handle = brcm_to_cpu(handle);</span>
<span class="quote">&gt;&gt; +     arch_dma_ops-&gt;free(dev, size, cpu_addr, handle, attrs);</span>
<span class="quote">&gt;&gt; +}</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +static int brcm_dma_mmap(struct device *dev, struct vm_area_struct *vma,</span>
<span class="quote">&gt;&gt; +                      void *cpu_addr, dma_addr_t dma_addr, size_t size,</span>
<span class="quote">&gt;&gt; +                      unsigned long attrs)</span>
<span class="quote">&gt;&gt; +{</span>
<span class="quote">&gt;&gt; +     dma_addr = brcm_to_cpu(dma_addr);</span>
<span class="quote">&gt;&gt; +     return arch_dma_ops-&gt;mmap(dev, vma, cpu_addr, dma_addr, size, attrs);</span>
<span class="quote">&gt;&gt; +}</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +static int brcm_dma_get_sgtable(struct device *dev, struct sg_table *sgt,</span>
<span class="quote">&gt;&gt; +                             void *cpu_addr, dma_addr_t handle, size_t size,</span>
<span class="quote">&gt;&gt; +                             unsigned long attrs)</span>
<span class="quote">&gt;&gt; +{</span>
<span class="quote">&gt;&gt; +     handle = brcm_to_cpu(handle);</span>
<span class="quote">&gt;&gt; +     return arch_dma_ops-&gt;get_sgtable(dev, sgt, cpu_addr, handle, size,</span>
<span class="quote">&gt;&gt; +                                    attrs);</span>
<span class="quote">&gt;&gt; +}</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +static dma_addr_t brcm_dma_map_page(struct device *dev, struct page *page,</span>
<span class="quote">&gt;&gt; +                                 unsigned long offset, size_t size,</span>
<span class="quote">&gt;&gt; +                                 enum dma_data_direction dir,</span>
<span class="quote">&gt;&gt; +                                 unsigned long attrs)</span>
<span class="quote">&gt;&gt; +{</span>
<span class="quote">&gt;&gt; +     return brcm_to_pci(arch_dma_ops-&gt;map_page(dev, page, offset, size,</span>
<span class="quote">&gt;&gt; +                                               dir, attrs));</span>
<span class="quote">&gt;&gt; +}</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +static void brcm_dma_unmap_page(struct device *dev, dma_addr_t handle,</span>
<span class="quote">&gt;&gt; +                             size_t size, enum dma_data_direction dir,</span>
<span class="quote">&gt;&gt; +                             unsigned long attrs)</span>
<span class="quote">&gt;&gt; +{</span>
<span class="quote">&gt;&gt; +     handle = brcm_to_cpu(handle);</span>
<span class="quote">&gt;&gt; +     arch_dma_ops-&gt;unmap_page(dev, handle, size, dir, attrs);</span>
<span class="quote">&gt;&gt; +}</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +static int brcm_dma_map_sg(struct device *dev, struct scatterlist *sgl,</span>
<span class="quote">&gt;&gt; +                        int nents, enum dma_data_direction dir,</span>
<span class="quote">&gt;&gt; +                        unsigned long attrs)</span>
<span class="quote">&gt;&gt; +{</span>
<span class="quote">&gt;&gt; +     int ret, i;</span>
<span class="quote">&gt;&gt; +     struct scatterlist *sg;</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +     ret = arch_dma_ops-&gt;map_sg(dev, sgl, nents, dir, attrs);</span>
<span class="quote">&gt;&gt; +     /* The ARM and MIPS implementations of map_sg and unmap_sg</span>
<span class="quote">&gt;&gt; +      * make calls to ops-&gt;map_page(), which we already intercept.</span>
<span class="quote">&gt;&gt; +      * The ARM64 does not, so we must iterate through the SG list</span>
<span class="quote">&gt;&gt; +      * and  convert each dma_address to one that is compatible</span>
<span class="quote">&gt;&gt; +      * with our PCI RC implementation.</span>
<span class="quote">&gt;&gt; +      */</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; That&#39;s a pretty fragile assumption given that arch code is free to</span>
<span class="quote">&gt; change, and anyone doing so is unlikely to be aware of your driver.</span>
<span class="quote">&gt; You&#39;d be better off implementing these in terms of {brcm_dma_}map_page</span>
<span class="quote">&gt; directly.</span>
<span class="quote">&gt;</span>
Will fix.
<span class="quote">
&gt;&gt; +     if (IS_ENABLED(CONFIG_ARM64))</span>
<span class="quote">&gt;&gt; +             for_each_sg(sgl, sg, ret, i)</span>
<span class="quote">&gt;&gt; +                     sg-&gt;dma_address = brcm_to_pci(sg-&gt;dma_address);</span>
<span class="quote">&gt;&gt; +     return ret;</span>
<span class="quote">&gt;&gt; +}</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +static void brcm_dma_unmap_sg(struct device *dev,</span>
<span class="quote">&gt;&gt; +                           struct scatterlist *sgl, int nents,</span>
<span class="quote">&gt;&gt; +                           enum dma_data_direction dir,</span>
<span class="quote">&gt;&gt; +                           unsigned long attrs)</span>
<span class="quote">&gt;&gt; +{</span>
<span class="quote">&gt;&gt; +     int i;</span>
<span class="quote">&gt;&gt; +     struct scatterlist *sg;</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +     /* The ARM and MIPS implementations of map_sg and unmap_sg</span>
<span class="quote">&gt;&gt; +      * make calls to ops-&gt;map_page(), which we already intercept.</span>
<span class="quote">&gt;&gt; +      * The ARM64 does not, so we must iterate through the SG list</span>
<span class="quote">&gt;&gt; +      * and  convert each dma_address to one that is compatible</span>
<span class="quote">&gt;&gt; +      * with our PCI RC implementation.</span>
<span class="quote">&gt;&gt; +      */</span>
<span class="quote">&gt;&gt; +     if (IS_ENABLED(CONFIG_ARM64))</span>
<span class="quote">&gt;&gt; +             for_each_sg(sgl, sg, nents, i)</span>
<span class="quote">&gt;&gt; +                     sg-&gt;dma_address = brcm_to_cpu(sg-&gt;dma_address);</span>
<span class="quote">&gt;&gt; +     arch_dma_ops-&gt;map_sg(dev, sgl, nents, dir, attrs);</span>
<span class="quote">&gt;&gt; +}</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +static void brcm_dma_sync_single_for_cpu(struct device *dev,</span>
<span class="quote">&gt;&gt; +                                      dma_addr_t handle, size_t size,</span>
<span class="quote">&gt;&gt; +                                      enum dma_data_direction dir)</span>
<span class="quote">&gt;&gt; +{</span>
<span class="quote">&gt;&gt; +     handle = brcm_to_cpu(handle);</span>
<span class="quote">&gt;&gt; +     arch_dma_ops-&gt;sync_single_for_cpu(dev, handle, size, dir);</span>
<span class="quote">&gt;&gt; +}</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +static void brcm_dma_sync_single_for_device(struct device *dev,</span>
<span class="quote">&gt;&gt; +                                         dma_addr_t handle, size_t size,</span>
<span class="quote">&gt;&gt; +                                         enum dma_data_direction dir)</span>
<span class="quote">&gt;&gt; +{</span>
<span class="quote">&gt;&gt; +     handle = brcm_to_cpu(handle);</span>
<span class="quote">&gt;&gt; +     arch_dma_ops-&gt;sync_single_for_device(dev, handle, size, dir);</span>
<span class="quote">&gt;&gt; +}</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; And sync_sg_*()? They might not be that commonly used by in-tree</span>
<span class="quote">&gt; drivers, but who knows what lurks beyond?</span>
<span class="quote">&gt;</span>
Will fix.
<span class="quote">
&gt;&gt; +</span>
<span class="quote">&gt;&gt; +static dma_addr_t brcm_dma_map_resource(struct device *dev, phys_addr_t phys,</span>
<span class="quote">&gt;&gt; +                                     size_t size,</span>
<span class="quote">&gt;&gt; +                                     enum dma_data_direction dir,</span>
<span class="quote">&gt;&gt; +                                     unsigned long attrs)</span>
<span class="quote">&gt;&gt; +{</span>
<span class="quote">&gt;&gt; +     return brcm_to_pci(arch_dma_ops-&gt;map_resource</span>
<span class="quote">&gt;&gt; +                        (dev, phys, size, dir, attrs));</span>
<span class="quote">&gt;&gt; +}</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +static void brcm_dma_unmap_resource(struct device *dev, dma_addr_t handle,</span>
<span class="quote">&gt;&gt; +                                 size_t size, enum dma_data_direction dir,</span>
<span class="quote">&gt;&gt; +                                 unsigned long attrs)</span>
<span class="quote">&gt;&gt; +{</span>
<span class="quote">&gt;&gt; +     handle = brcm_to_cpu(handle);</span>
<span class="quote">&gt;&gt; +     arch_dma_ops-&gt;unmap_resource(dev, handle, size, dir, attrs);</span>
<span class="quote">&gt;&gt; +}</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +static int brcm_mapping_error(struct device *dev, dma_addr_t dma_addr)</span>
<span class="quote">&gt;&gt; +{</span>
<span class="quote">&gt;&gt; +     return dma_addr == BRCMSTB_ERROR_CODE;</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; Huh? How do you know this will work correctly with every platform&#39;s</span>
<span class="quote">&gt; -&gt;map_page implementation (hint: it doesn&#39;t).</span>
<span class="quote">&gt;</span>
Will fix.
<span class="quote">
&gt;&gt; +}</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +static const struct dma_map_ops *brcm_get_arch_dma_ops(struct device *dev)</span>
<span class="quote">&gt;&gt; +{</span>
<span class="quote">&gt;&gt; +#if defined(CONFIG_MIPS)</span>
<span class="quote">&gt;&gt; +     return mips_dma_map_ops;</span>
<span class="quote">&gt;&gt; +#elif defined(CONFIG_ARM)</span>
<span class="quote">&gt;&gt; +     return &amp;arm_dma_ops;</span>
<span class="quote">&gt;&gt; +#elif defined(CONFIG_ARM64)</span>
<span class="quote">&gt;&gt; +     /* swiotlb_dma_ops is a static var, so we get ahold</span>
<span class="quote">&gt;&gt; +      * of it by calling arch_setup_dma_ops(...).</span>
<span class="quote">&gt;&gt; +      */</span>
<span class="quote">&gt;&gt; +     arch_setup_dma_ops(dev, 0, 0, NULL, false);</span>
<span class="quote">&gt;&gt; +     return dev-&gt;dma_ops;</span>
<span class="quote">&gt;&gt; +#endif</span>
<span class="quote">&gt;&gt; +     return 0;</span>
<span class="quote">&gt;&gt; +}</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; As mentioned earlier, no. There are theoretical cases where it might not</span>
<span class="quote">&gt; be true, but in practice you can assume all PCI devices are going to get</span>
<span class="quote">&gt; the same DMA ops as their associated host controller (and that&#39;s still a</span>
<span class="quote">&gt; better assumption that what you have here), so you can just grab those</span>
<span class="quote">&gt; at the point you install the notifier.</span>
<span class="quote">&gt;</span>
Yes, for some reason I did not know of get_dma_ops() and I wrote my
own, poorly.  Will fix.
<span class="quote">
&gt;&gt; +</span>
<span class="quote">&gt;&gt; +static void brcm_set_dma_ops(struct device *dev)</span>
<span class="quote">&gt;&gt; +{</span>
<span class="quote">&gt;&gt; +     arch_dma_ops = brcm_get_arch_dma_ops(dev);</span>
<span class="quote">&gt;&gt; +     if (!arch_dma_ops)</span>
<span class="quote">&gt;&gt; +             return;</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +     /* Set all of the base operations; some will be overridden */</span>
<span class="quote">&gt;&gt; +     brcm_dma_ops = *arch_dma_ops;</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +     /* Insert the Brcm-specific override operations */</span>
<span class="quote">&gt;&gt; +     brcm_dma_ops.alloc = brcm_dma_alloc;</span>
<span class="quote">&gt;&gt; +     brcm_dma_ops.free = brcm_dma_free;</span>
<span class="quote">&gt;&gt; +     brcm_dma_ops.mmap = brcm_dma_mmap;</span>
<span class="quote">&gt;&gt; +     brcm_dma_ops.get_sgtable = brcm_dma_get_sgtable;</span>
<span class="quote">&gt;&gt; +     brcm_dma_ops.map_page = brcm_dma_map_page;</span>
<span class="quote">&gt;&gt; +     brcm_dma_ops.unmap_page = brcm_dma_unmap_page;</span>
<span class="quote">&gt;&gt; +     brcm_dma_ops.sync_single_for_cpu = brcm_dma_sync_single_for_cpu;</span>
<span class="quote">&gt;&gt; +     brcm_dma_ops.sync_single_for_device = brcm_dma_sync_single_for_device;</span>
<span class="quote">&gt;&gt; +     brcm_dma_ops.map_sg = brcm_dma_map_sg;</span>
<span class="quote">&gt;&gt; +     brcm_dma_ops.unmap_sg = brcm_dma_unmap_sg;</span>
<span class="quote">&gt;&gt; +     if (arch_dma_ops-&gt;map_resource)</span>
<span class="quote">&gt;&gt; +             brcm_dma_ops.map_resource = brcm_dma_map_resource;</span>
<span class="quote">&gt;&gt; +     if (arch_dma_ops-&gt;unmap_resource)</span>
<span class="quote">&gt;&gt; +             brcm_dma_ops.unmap_resource = brcm_dma_unmap_resource;</span>
<span class="quote">&gt;&gt; +     brcm_dma_ops.mapping_error = brcm_mapping_error;</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +     /* Use our brcm_dma_ops for this driver */</span>
<span class="quote">&gt;&gt; +     set_dma_ops(dev, &amp;brcm_dma_ops);</span>
<span class="quote">&gt;&gt; +}</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; Just have a static const set of ops like everyone else - you can handle</span>
<span class="quote">&gt; the conditionality of -&gt;{map,unmap}_resource inside the brcm_* wrappers.</span>
<span class="quote">&gt;</span>
Will fix.
<span class="quote">
&gt;&gt; +</span>
<span class="quote">&gt;&gt; +static int brcmstb_platform_notifier(struct notifier_block *nb,</span>
<span class="quote">&gt;&gt; +                                  unsigned long event, void *__dev)</span>
<span class="quote">&gt;&gt; +{</span>
<span class="quote">&gt;&gt; +     struct device *dev = __dev;</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +     if (event != BUS_NOTIFY_ADD_DEVICE)</span>
<span class="quote">&gt;&gt; +             return NOTIFY_DONE;</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +     brcm_set_dma_ops(dev);</span>
<span class="quote">&gt;&gt; +     return NOTIFY_OK;</span>
<span class="quote">&gt;&gt; +}</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +struct notifier_block brcmstb_platform_nb = {</span>
<span class="quote">&gt;&gt; +     .notifier_call = brcmstb_platform_notifier,</span>
<span class="quote">&gt;&gt; +};</span>
<span class="quote">&gt;&gt; +EXPORT_SYMBOL(brcmstb_platform_nb);</span>
<span class="quote">&gt;&gt; diff --git a/drivers/pci/host/pci-brcmstb.c b/drivers/pci/host/pci-brcmstb.c</span>
<span class="quote">&gt;&gt; index f4cd6e7..03c0da9 100644</span>
<span class="quote">&gt;&gt; --- a/drivers/pci/host/pci-brcmstb.c</span>
<span class="quote">&gt;&gt; +++ b/drivers/pci/host/pci-brcmstb.c</span>
<span class="quote">&gt;&gt; @@ -343,6 +343,8 @@ struct brcm_pcie {</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt;  static struct list_head brcm_pcie = LIST_HEAD_INIT(brcm_pcie);</span>
<span class="quote">&gt;&gt;  static phys_addr_t scb_size[BRCM_MAX_SCB];</span>
<span class="quote">&gt;&gt; +static struct of_pci_range *dma_ranges;</span>
<span class="quote">&gt;&gt; +static int num_dma_ranges;</span>
<span class="quote">&gt;&gt;  static int num_memc;</span>
<span class="quote">&gt;&gt;  static DEFINE_MUTEX(brcm_pcie_lock);</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; @@ -362,6 +364,8 @@ static int brcm_pcie_add_controller(struct brcm_pcie *pcie)</span>
<span class="quote">&gt;&gt;  {</span>
<span class="quote">&gt;&gt;       mutex_lock(&amp;brcm_pcie_lock);</span>
<span class="quote">&gt;&gt;       snprintf(pcie-&gt;name, sizeof(pcie-&gt;name) - 1, &quot;PCIe%d&quot;, pcie-&gt;id);</span>
<span class="quote">&gt;&gt; +     if (list_empty(&amp;brcm_pcie))</span>
<span class="quote">&gt;&gt; +             bus_register_notifier(&amp;pci_bus_type, &amp;brcmstb_platform_nb);</span>
<span class="quote">&gt;&gt;       list_add_tail(&amp;pcie-&gt;list, &amp;brcm_pcie);</span>
<span class="quote">&gt;&gt;       mutex_unlock(&amp;brcm_pcie_lock);</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; @@ -378,8 +382,14 @@ static void brcm_pcie_remove_controller(struct brcm_pcie *pcie)</span>
<span class="quote">&gt;&gt;               tmp = list_entry(pos, struct brcm_pcie, list);</span>
<span class="quote">&gt;&gt;               if (tmp == pcie) {</span>
<span class="quote">&gt;&gt;                       list_del(pos);</span>
<span class="quote">&gt;&gt; -                     if (list_empty(&amp;brcm_pcie))</span>
<span class="quote">&gt;&gt; +                     if (list_empty(&amp;brcm_pcie)) {</span>
<span class="quote">&gt;&gt; +                             bus_unregister_notifier(&amp;pci_bus_type,</span>
<span class="quote">&gt;&gt; +                                                     &amp;brcmstb_platform_nb);</span>
<span class="quote">&gt;&gt; +                             kfree(dma_ranges);</span>
<span class="quote">&gt;&gt; +                             dma_ranges = NULL;</span>
<span class="quote">&gt;&gt; +                             num_dma_ranges = 0;</span>
<span class="quote">&gt;&gt;                               num_memc = 0;</span>
<span class="quote">&gt;&gt; +                     }</span>
<span class="quote">&gt;&gt;                       break;</span>
<span class="quote">&gt;&gt;               }</span>
<span class="quote">&gt;&gt;       }</span>
<span class="quote">&gt;&gt; @@ -403,6 +413,35 @@ int encode_ibar_size(u64 size)</span>
<span class="quote">&gt;&gt;       return 0;</span>
<span class="quote">&gt;&gt;  }</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; +dma_addr_t brcm_to_pci(dma_addr_t addr)</span>
<span class="quote">&gt;&gt; +{</span>
<span class="quote">&gt;&gt; +     struct of_pci_range *p;</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +     if (!num_dma_ranges)</span>
<span class="quote">&gt;&gt; +             return addr;</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +     for (p = dma_ranges; p &lt; &amp;dma_ranges[num_dma_ranges]; p++)</span>
<span class="quote">&gt;&gt; +             if (addr &gt;= p-&gt;cpu_addr &amp;&amp; addr &lt; (p-&gt;cpu_addr + p-&gt;size))</span>
<span class="quote">&gt;&gt; +                     return addr - p-&gt;cpu_addr + p-&gt;pci_addr;</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +     return BRCMSTB_ERROR_CODE;</span>
<span class="quote">&gt;&gt; +}</span>
<span class="quote">&gt;&gt; +EXPORT_SYMBOL(brcm_to_pci);</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; AFAICS it doesn&#39;t make much sense for anyone outside this driver to ever</span>
<span class="quote">&gt; be calling these.</span>
<span class="quote">&gt;</span>
Will fix.
<span class="quote">
&gt;&gt; +dma_addr_t brcm_to_cpu(dma_addr_t addr)</span>
<span class="quote">&gt;&gt; +{</span>
<span class="quote">&gt;&gt; +     struct of_pci_range *p;</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +     if (!num_dma_ranges)</span>
<span class="quote">&gt;&gt; +             return addr;</span>
<span class="quote">&gt;&gt; +     for (p = dma_ranges; p &lt; &amp;dma_ranges[num_dma_ranges]; p++)</span>
<span class="quote">&gt;&gt; +             if (addr &gt;= p-&gt;pci_addr &amp;&amp; addr &lt; (p-&gt;pci_addr + p-&gt;size))</span>
<span class="quote">&gt;&gt; +                     return addr - p-&gt;pci_addr + p-&gt;cpu_addr;</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +     return addr;</span>
<span class="quote">&gt;&gt; +}</span>
<span class="quote">&gt;&gt; +EXPORT_SYMBOL(brcm_to_cpu);</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt;  static u32 mdio_form_pkt(int port, int regad, int cmd)</span>
<span class="quote">&gt;&gt;  {</span>
<span class="quote">&gt;&gt;       u32 pkt = 0;</span>
<span class="quote">&gt;&gt; @@ -652,6 +691,74 @@ static int brcm_parse_ranges(struct brcm_pcie *pcie)</span>
<span class="quote">&gt;&gt;       return 0;</span>
<span class="quote">&gt;&gt;  }</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; +static int brcm_pci_dma_range_parser_init(struct of_pci_range_parser *parser,</span>
<span class="quote">&gt;&gt; +                                       struct device_node *node)</span>
<span class="quote">&gt;&gt; +{</span>
<span class="quote">&gt;&gt; +     const int na = 3, ns = 2;</span>
<span class="quote">&gt;&gt; +     int rlen;</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +     parser-&gt;node = node;</span>
<span class="quote">&gt;&gt; +     parser-&gt;pna = of_n_addr_cells(node);</span>
<span class="quote">&gt;&gt; +     parser-&gt;np = parser-&gt;pna + na + ns;</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +     parser-&gt;range = of_get_property(node, &quot;dma-ranges&quot;, &amp;rlen);</span>
<span class="quote">&gt;&gt; +     if (!parser-&gt;range)</span>
<span class="quote">&gt;&gt; +             return -ENOENT;</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +     parser-&gt;end = parser-&gt;range + rlen / sizeof(__be32);</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +     return 0;</span>
<span class="quote">&gt;&gt; +}</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; Note that we&#39;ve got a factored-out helper for this queued in -next</span>
<span class="quote">&gt; already - see here:</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; https://patchwork.kernel.org/patch/9927541/</span>
<span class="quote">&gt;</span>
I will submit a change when it gets merged.
<span class="quote">
&gt;&gt; +</span>
<span class="quote">&gt;&gt; +static int brcm_parse_dma_ranges(struct brcm_pcie *pcie)</span>
<span class="quote">&gt;&gt; +{</span>
<span class="quote">&gt;&gt; +     int i, ret = 0;</span>
<span class="quote">&gt;&gt; +     struct of_pci_range_parser parser;</span>
<span class="quote">&gt;&gt; +     struct device_node *dn = pcie-&gt;dn;</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +     mutex_lock(&amp;brcm_pcie_lock);</span>
<span class="quote">&gt;&gt; +     if (dma_ranges)</span>
<span class="quote">&gt;&gt; +             goto done;</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +     /* Parse dma-ranges property if present.  If there are multiple</span>
<span class="quote">&gt;&gt; +      * PCI controllers, we only have to parse from one of them since</span>
<span class="quote">&gt;&gt; +      * the others will have an identical mapping.</span>
<span class="quote">&gt;&gt; +      */</span>
<span class="quote">&gt;&gt; +     if (!brcm_pci_dma_range_parser_init(&amp;parser, dn)) {</span>
<span class="quote">&gt;&gt; +             unsigned int max_ranges</span>
<span class="quote">&gt;&gt; +                     = (parser.end - parser.range) / parser.np;</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +             dma_ranges = kcalloc(max_ranges, sizeof(struct of_pci_range),</span>
<span class="quote">&gt;&gt; +                                  GFP_KERNEL);</span>
<span class="quote">&gt;&gt; +             if (!dma_ranges) {</span>
<span class="quote">&gt;&gt; +                     ret =  -ENOMEM;</span>
<span class="quote">&gt;&gt; +                     goto done;</span>
<span class="quote">&gt;&gt; +             }</span>
<span class="quote">&gt;&gt; +             for (i = 0; of_pci_range_parser_one(&amp;parser, dma_ranges + i);</span>
<span class="quote">&gt;&gt; +                  i++)</span>
<span class="quote">&gt;&gt; +                     num_dma_ranges++;</span>
<span class="quote">&gt;&gt; +     }</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +     for (i = 0, num_memc = 0; i &lt; BRCM_MAX_SCB; i++) {</span>
<span class="quote">&gt;&gt; +             u64 size = brcmstb_memory_memc_size(i);</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +             if (size == (u64)-1) {</span>
<span class="quote">&gt;&gt; +                     dev_err(pcie-&gt;dev, &quot;cannot get memc%d size&quot;, i);</span>
<span class="quote">&gt;&gt; +                     ret = -EINVAL;</span>
<span class="quote">&gt;&gt; +                     goto done;</span>
<span class="quote">&gt;&gt; +             } else if (size) {</span>
<span class="quote">&gt;&gt; +                     scb_size[i] = roundup_pow_of_two_64(size);</span>
<span class="quote">&gt;&gt; +                     num_memc++;</span>
<span class="quote">&gt;&gt; +             } else {</span>
<span class="quote">&gt;&gt; +                     break;</span>
<span class="quote">&gt;&gt; +             }</span>
<span class="quote">&gt;&gt; +     }</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +done:</span>
<span class="quote">&gt;&gt; +     mutex_unlock(&amp;brcm_pcie_lock);</span>
<span class="quote">&gt;&gt; +     return ret;</span>
<span class="quote">&gt;&gt; +}</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt;  static void set_regulators(struct brcm_pcie *pcie, bool on)</span>
<span class="quote">&gt;&gt;  {</span>
<span class="quote">&gt;&gt;       struct list_head *pos;</span>
<span class="quote">&gt;&gt; @@ -728,10 +835,34 @@ static void brcm_pcie_setup_prep(struct brcm_pcie *pcie)</span>
<span class="quote">&gt;&gt;        */</span>
<span class="quote">&gt;&gt;       rc_bar2_size = roundup_pow_of_two_64(total_mem_size);</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; -     /* Set simple configuration based on memory sizes</span>
<span class="quote">&gt;&gt; -      * only.  We always start the viewport at address 0.</span>
<span class="quote">&gt;&gt; -      */</span>
<span class="quote">&gt;&gt; -     rc_bar2_offset = 0;</span>
<span class="quote">&gt;&gt; +     if (dma_ranges) {</span>
<span class="quote">&gt;&gt; +             /* The best-case scenario is to place the inbound</span>
<span class="quote">&gt;&gt; +              * region in the first 4GB of pci-space, as some</span>
<span class="quote">&gt;&gt; +              * legacy devices can only address 32bits.</span>
<span class="quote">&gt;&gt; +              * We would also like to put the MSI under 4GB</span>
<span class="quote">&gt;&gt; +              * as well, since some devices require a 32bit</span>
<span class="quote">&gt;&gt; +              * MSI target address.</span>
<span class="quote">&gt;&gt; +              */</span>
<span class="quote">&gt;&gt; +             if (total_mem_size &lt;= 0xc0000000ULL &amp;&amp;</span>
<span class="quote">&gt;&gt; +                 rc_bar2_size &lt;= 0x100000000ULL) {</span>
<span class="quote">&gt;&gt; +                     rc_bar2_offset = 0;</span>
<span class="quote">&gt;&gt; +             } else {</span>
<span class="quote">&gt;&gt; +                     /* The system memory is 4GB or larger so we</span>
<span class="quote">&gt;&gt; +                      * cannot start the inbound region at location</span>
<span class="quote">&gt;&gt; +                      * 0 (since we have to allow some space for</span>
<span class="quote">&gt;&gt; +                      * outbound memory @ 3GB).  So instead we</span>
<span class="quote">&gt;&gt; +                      * start it at the 1x multiple of its size</span>
<span class="quote">&gt;&gt; +                      */</span>
<span class="quote">&gt;&gt; +                     rc_bar2_offset = rc_bar2_size;</span>
<span class="quote">&gt;&gt; +             }</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +     } else {</span>
<span class="quote">&gt;&gt; +             /* Set simple configuration based on memory sizes</span>
<span class="quote">&gt;&gt; +              * only.  We always start the viewport at address 0,</span>
<span class="quote">&gt;&gt; +              * and set the MSI target address accordingly.</span>
<span class="quote">&gt;&gt; +              */</span>
<span class="quote">&gt;&gt; +             rc_bar2_offset = 0;</span>
<span class="quote">&gt;&gt; +     }</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt;       tmp = lower_32_bits(rc_bar2_offset);</span>
<span class="quote">&gt;&gt;       tmp = INSERT_FIELD(tmp, PCIE_MISC_RC_BAR2_CONFIG_LO, SIZE,</span>
<span class="quote">&gt;&gt; @@ -1040,11 +1171,6 @@ static int brcm_pcie_probe(struct platform_device *pdev)</span>
<span class="quote">&gt;&gt;               return -EINVAL;</span>
<span class="quote">&gt;&gt;       }</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; -     if (of_property_read_u32(dn, &quot;dma-ranges&quot;, &amp;tmp) == 0) {</span>
<span class="quote">&gt;&gt; -             pr_err(&quot;cannot yet handle dma-ranges\n&quot;);</span>
<span class="quote">&gt;&gt; -             return -EINVAL;</span>
<span class="quote">&gt;&gt; -     }</span>
<span class="quote">&gt;&gt; -</span>
<span class="quote">&gt;&gt;       data = of_id-&gt;data;</span>
<span class="quote">&gt;&gt;       pcie-&gt;reg_offsets = data-&gt;offsets;</span>
<span class="quote">&gt;&gt;       pcie-&gt;reg_field_info = data-&gt;reg_field_info;</span>
<span class="quote">&gt;&gt; @@ -1113,6 +1239,10 @@ static int brcm_pcie_probe(struct platform_device *pdev)</span>
<span class="quote">&gt;&gt;       if (ret)</span>
<span class="quote">&gt;&gt;               return ret;</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; +     ret = brcm_parse_dma_ranges(pcie);</span>
<span class="quote">&gt;&gt; +     if (ret)</span>
<span class="quote">&gt;&gt; +             return ret;</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt;       ret = clk_prepare_enable(pcie-&gt;clk);</span>
<span class="quote">&gt;&gt;       if (ret) {</span>
<span class="quote">&gt;&gt;               dev_err(&amp;pdev-&gt;dev, &quot;could not enable clock\n&quot;);</span>
<span class="quote">&gt;&gt; diff --git a/drivers/pci/host/pci-brcmstb.h b/drivers/pci/host/pci-brcmstb.h</span>
<span class="quote">&gt;&gt; index 86f9cd1..4851be8 100644</span>
<span class="quote">&gt;&gt; --- a/drivers/pci/host/pci-brcmstb.h</span>
<span class="quote">&gt;&gt; +++ b/drivers/pci/host/pci-brcmstb.h</span>
<span class="quote">&gt;&gt; @@ -21,6 +21,13 @@</span>
<span class="quote">&gt;&gt;  /* Broadcom PCIE Offsets */</span>
<span class="quote">&gt;&gt;  #define PCIE_INTR2_CPU_BASE          0x4300</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; +dma_addr_t brcm_to_pci(dma_addr_t addr);</span>
<span class="quote">&gt;&gt; +dma_addr_t brcm_to_cpu(dma_addr_t addr);</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +extern struct notifier_block brcmstb_platform_nb;</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; It seems a bit weird to have the notifier code split across two</span>
<span class="quote">&gt; compilation units in the way which requires this - it seems more</span>
<span class="quote">&gt; reasonable to have it all together on one side or the other, with the</span>
<span class="quote">&gt; common interface being either the callback for setting the ops or a</span>
<span class="quote">&gt; function for installing the notifier, depending on where things fall.</span>

Okay, I&#39;ll try to rework this.

Thanks Robin,
Jim
<span class="quote">
&gt;</span>
<span class="quote">&gt; Robin.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +#define BRCMSTB_ERROR_CODE   (~(dma_addr_t)0x0)</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt;  #if defined(CONFIG_MIPS)</span>
<span class="quote">&gt;&gt;  /* Broadcom MIPs HW implicitly does the swapping if necessary */</span>
<span class="quote">&gt;&gt;  #define bcm_readl(a)         __raw_readl(a)</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;</span>
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=99">Christoph Hellwig</a> - Oct. 17, 2017, 8:14 a.m.</div>
<pre class="content">
Just took a quick look over this and I basically agree with the comments
from Robin.

What I don&#39;t understand is why you&#39;re even trying to do all these
hacky things.

It seems like the controller should simply set dma_pfn_offset for
each device hanging off it, and all the supported architectures
should be updated to obey that if they don&#39;t do so yet, and
you&#39;re done without needing this giant mess.
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=117971">Jim Quinlan</a> - Oct. 17, 2017, 4:11 p.m.</div>
<pre class="content">
On Tue, Oct 17, 2017 at 4:14 AM, Christoph Hellwig &lt;hch@lst.de&gt; wrote:
<span class="quote">&gt; Just took a quick look over this and I basically agree with the comments</span>
<span class="quote">&gt; from Robin.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; What I don&#39;t understand is why you&#39;re even trying to do all these</span>
<span class="quote">&gt; hacky things.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; It seems like the controller should simply set dma_pfn_offset for</span>
<span class="quote">&gt; each device hanging off it, and all the supported architectures</span>
<span class="quote">&gt; should be updated to obey that if they don&#39;t do so yet, and</span>
<span class="quote">&gt; you&#39;re done without needing this giant mess.</span>

My understanding is that dma_pfn_offset is that it is a single
constant offset from RAM, in our case, to map to PCIe space.  But in
my commit message I detail how our PCIe controller presents memory
with multiple regions with multiple different offsets. If an EP device
maps to a region on the host memory, yes we can set the dma_pfn_offset
for that device for that location within that range,.  But if the
device then unmaps and allocates from another region with a different
offset, it won&#39;t work.  If  I set dma_pfn_offset I have to assume that
the device is using only one region of memory only, not more than one,
and that it is not unmapping that region and mapping another (with a
different offset).  Can I make those assumptions?
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=99">Christoph Hellwig</a> - Oct. 18, 2017, 6:53 a.m.</div>
<pre class="content">
On Tue, Oct 17, 2017 at 12:11:55PM -0400, Jim Quinlan wrote:
<span class="quote">&gt; My understanding is that dma_pfn_offset is that it is a single</span>
<span class="quote">&gt; constant offset from RAM, in our case, to map to PCIe space.</span>

Yes.
<span class="quote">
&gt; But in</span>
<span class="quote">&gt; my commit message I detail how our PCIe controller presents memory</span>
<span class="quote">&gt; with multiple regions with multiple different offsets. If an EP device</span>
<span class="quote">&gt; maps to a region on the host memory, yes we can set the dma_pfn_offset</span>
<span class="quote">&gt; for that device for that location within that range,.  But if the</span>
<span class="quote">&gt; device then unmaps and allocates from another region with a different</span>
<span class="quote">&gt; offset, it won&#39;t work.  If  I set dma_pfn_offset I have to assume that</span>
<span class="quote">&gt; the device is using only one region of memory only, not more than one,</span>
<span class="quote">&gt; and that it is not unmapping that region and mapping another (with a</span>
<span class="quote">&gt; different offset).  Can I make those assumptions?</span>

No, we can&#39;t make that assumption unfortunately.  But how is your
code going to work if the mapping spans multiple of your translation
regions?

Also I really don&#39;t think the stacking of dma_ops as in this patch
is a good idea.  For MIPS you should do the variant suggested in
the patch description and hook into dma_to_phys/phys_to_dma helpers,
and for ARM/ARM64 you should talk to the maintainers on how they
want the translation integrated.
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=117971">Jim Quinlan</a> - Oct. 18, 2017, 2:41 p.m.</div>
<pre class="content">
On Wed, Oct 18, 2017 at 2:53 AM, Christoph Hellwig &lt;hch@lst.de&gt; wrote:
<span class="quote">&gt; On Tue, Oct 17, 2017 at 12:11:55PM -0400, Jim Quinlan wrote:</span>
<span class="quote">&gt;&gt; My understanding is that dma_pfn_offset is that it is a single</span>
<span class="quote">&gt;&gt; constant offset from RAM, in our case, to map to PCIe space.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; Yes.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;&gt; But in</span>
<span class="quote">&gt;&gt; my commit message I detail how our PCIe controller presents memory</span>
<span class="quote">&gt;&gt; with multiple regions with multiple different offsets. If an EP device</span>
<span class="quote">&gt;&gt; maps to a region on the host memory, yes we can set the dma_pfn_offset</span>
<span class="quote">&gt;&gt; for that device for that location within that range,.  But if the</span>
<span class="quote">&gt;&gt; device then unmaps and allocates from another region with a different</span>
<span class="quote">&gt;&gt; offset, it won&#39;t work.  If  I set dma_pfn_offset I have to assume that</span>
<span class="quote">&gt;&gt; the device is using only one region of memory only, not more than one,</span>
<span class="quote">&gt;&gt; and that it is not unmapping that region and mapping another (with a</span>
<span class="quote">&gt;&gt; different offset).  Can I make those assumptions?</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; No, we can&#39;t make that assumption unfortunately.  But how is your</span>
<span class="quote">&gt; code going to work if the mapping spans multiple of your translation</span>
<span class="quote">&gt; regions?</span>

That&#39;s what brcm_to_{pci,cpu} are for -- they keep a list of the
dma-ranges given in the PCIe DT node, and translate from system memory
addresses to pci-space addresses, and vice versa.  As long as people
are using the DMA API it should work.  It works for all of the ARM,
ARM64, and MIPS Broadcom systems I&#39;ve tested, using eight different EP
devices.  Note that I am not thrilled to be advocating this mechanism
but it seemed the best alternative.
<span class="quote">
&gt;memorymaintiners</span>
<span class="quote">&gt; Also I really don&#39;t think the stacking of dma_ops as in this patch</span>
<span class="quote">&gt; is a good idea.  For MIPS you should do the variant suggested in</span>
<span class="quote">&gt; the patch description and hook into dma_to_phys/phys_to_dma helpers,</span>
<span class="quote">&gt; and for ARM/ARM64 you should talk to the maintainers on how they</span>
<span class="quote">&gt; want the translation integrated.</span>

I would prefer that the same code work for all three architectures.
What I would like from ARM/ARM64 is the ability to override
phys_to_dma() and dma_to_phys(); I thought the chances of that being
accepted would be slim.  But you are right, I should ask the
maintainers.
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=99">Christoph Hellwig</a> - Oct. 19, 2017, 9:16 a.m.</div>
<pre class="content">
On Wed, Oct 18, 2017 at 10:41:17AM -0400, Jim Quinlan wrote:
<span class="quote">&gt; That&#39;s what brcm_to_{pci,cpu} are for -- they keep a list of the</span>
<span class="quote">&gt; dma-ranges given in the PCIe DT node, and translate from system memory</span>
<span class="quote">&gt; addresses to pci-space addresses, and vice versa.  As long as people</span>
<span class="quote">&gt; are using the DMA API it should work.  It works for all of the ARM,</span>
<span class="quote">&gt; ARM64, and MIPS Broadcom systems I&#39;ve tested, using eight different EP</span>
<span class="quote">&gt; devices.  Note that I am not thrilled to be advocating this mechanism</span>
<span class="quote">&gt; but it seemed the best alternative.</span>

Say we are using your original example ranges:

 memc0-a@[        0....3fffffff] &lt;=&gt; pci@[        0....3fffffff]
 memc0-b@[100000000...13fffffff] &lt;=&gt; pci@[ 40000000....7fffffff]
 memc1-a@[ 40000000....7fffffff] &lt;=&gt; pci@[ 80000000....bfffffff]
 memc1-b@[300000000...33fffffff] &lt;=&gt; pci@[ c0000000....ffffffff]
 memc2-a@[ 80000000....bfffffff] &lt;=&gt; pci@[100000000...13fffffff]
 memc2-b@[c00000000...c3fffffff] &lt;=&gt; pci@[140000000...17fffffff]

and now you get a dma mapping request for physical addresses
3fffff00 to 4000000f, which would span two of your ranges.  How
is this going to work?
<span class="quote">
&gt; I would prefer that the same code work for all three architectures.</span>
<span class="quote">&gt; What I would like from ARM/ARM64 is the ability to override</span>
<span class="quote">&gt; phys_to_dma() and dma_to_phys(); I thought the chances of that being</span>
<span class="quote">&gt; accepted would be slim.  But you are right, I should ask the</span>
<span class="quote">&gt; maintainers.</span>

It is still better than trying to stack dma ops, which is a receipe
for problems down the road.
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=117971">Jim Quinlan</a> - Oct. 19, 2017, 10:47 p.m.</div>
<pre class="content">
On Thu, Oct 19, 2017 at 5:16 AM, Christoph Hellwig &lt;hch@lst.de&gt; wrote:
<span class="quote">&gt; On Wed, Oct 18, 2017 at 10:41:17AM -0400, Jim Quinlan wrote:</span>
<span class="quote">&gt;&gt; That&#39;s what brcm_to_{pci,cpu} are for -- they keep a list of the</span>
<span class="quote">&gt;&gt; dma-ranges given in the PCIe DT node, and translate from system memory</span>
<span class="quote">&gt;&gt; addresses to pci-space addresses, and vice versa.  As long as people</span>
<span class="quote">&gt;&gt; are using the DMA API it should work.  It works for all of the ARM,</span>
<span class="quote">&gt;&gt; ARM64, and MIPS Broadcom systems I&#39;ve tested, using eight different EP</span>
<span class="quote">&gt;&gt; devices.  Note that I am not thrilled to be advocating this mechanism</span>
<span class="quote">&gt;&gt; but it seemed the best alternative.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; Say we are using your original example ranges:</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;  memc0-a@[        0....3fffffff] &lt;=&gt; pci@[        0....3fffffff]</span>
<span class="quote">&gt;  memc0-b@[100000000...13fffffff] &lt;=&gt; pci@[ 40000000....7fffffff]</span>
<span class="quote">&gt;  memc1-a@[ 40000000....7fffffff] &lt;=&gt; pci@[ 80000000....bfffffff]</span>
<span class="quote">&gt;  memc1-b@[300000000...33fffffff] &lt;=&gt; pci@[ c0000000....ffffffff]</span>
<span class="quote">&gt;  memc2-a@[ 80000000....bfffffff] &lt;=&gt; pci@[100000000...13fffffff]</span>
<span class="quote">&gt;  memc2-b@[c00000000...c3fffffff] &lt;=&gt; pci@[140000000...17fffffff]</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; and now you get a dma mapping request for physical addresses</span>
<span class="quote">&gt; 3fffff00 to 4000000f, which would span two of your ranges.  How</span>
<span class="quote">&gt; is this going to work?</span>

The only way to prevent this is to reserve a single page at the end of
the first memory region of any pair that are adjacent in physical
memory.  A hack, yes, but I don&#39;t see an easier way out of this.  Many
if not most of our boards do not have adjacent regions and would not
need this.

Overriding phys_to_dma/dma_to_phys comes with the same overlap problem
(MIPS solution and possible ARM/ARM64 solution).
<span class="quote">
&gt;</span>
<span class="quote">&gt;&gt; I would prefer that the same code work for all three architectures.</span>
<span class="quote">&gt;&gt; What I would like from ARM/ARM64 is the ability to override</span>
<span class="quote">&gt;&gt; phys_to_dma() and dma_to_phys(); I thought the chances of that being</span>
<span class="quote">&gt;&gt; accepted would be slim.  But you are right, I should ask the</span>
<span class="quote">&gt;&gt; maintainers.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; It is still better than trying to stack dma ops, which is a receipe</span>
<span class="quote">&gt; for problems down the road.</span>

Let me send out V2 of my patchset and also send it to the ARM/ARM64
maintainers as you suggested; perhaps there is an alternative.
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=99">Christoph Hellwig</a> - Oct. 20, 2017, 7:37 a.m.</div>
<pre class="content">
On Thu, Oct 19, 2017 at 06:47:45PM -0400, Jim Quinlan wrote:
<span class="quote">&gt; The only way to prevent this is to reserve a single page at the end of</span>
<span class="quote">&gt; the first memory region of any pair that are adjacent in physical</span>
<span class="quote">&gt; memory.  A hack, yes, but I don&#39;t see an easier way out of this.  Many</span>
<span class="quote">&gt; if not most of our boards do not have adjacent regions and would not</span>
<span class="quote">&gt; need this.</span>

dma mappings can be much larger than a single page.  For the block
world take a look at __blk_segment_map_sg which does the merging
of contiguous pages into a single SG segment.  You&#39;d have to override
BIOVEC_PHYS_MERGEABLE to prevent this from happening in your supported
architectures for the block layer.
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=117971">Jim Quinlan</a> - Oct. 20, 2017, 2:41 p.m.</div>
<pre class="content">
On Fri, Oct 20, 2017 at 3:37 AM, Christoph Hellwig &lt;hch@lst.de&gt; wrote:
<span class="quote">&gt; On Thu, Oct 19, 2017 at 06:47:45PM -0400, Jim Quinlan wrote:</span>
<span class="quote">&gt;&gt; The only way to prevent this is to reserve a single page at the end of</span>
<span class="quote">&gt;&gt; the first memory region of any pair that are adjacent in physical</span>
<span class="quote">&gt;&gt; memory.  A hack, yes, but I don&#39;t see an easier way out of this.  Many</span>
<span class="quote">&gt;&gt; if not most of our boards do not have adjacent regions and would not</span>
<span class="quote">&gt;&gt; need this.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; dma mappings can be much larger than a single page.  For the block</span>
<span class="quote">&gt; world take a look at __blk_segment_map_sg which does the merging</span>
<span class="quote">&gt; of contiguous pages into a single SG segment.  You&#39;d have to override</span>
<span class="quote">&gt; BIOVEC_PHYS_MERGEABLE to prevent this from happening in your supported</span>
<span class="quote">&gt; architectures for the block layer.</span>

I am not sure I understand your comment -- the size of the request
shouldn&#39;t be a factor.  Let&#39;s look at your example of the DMA request
of 3fffff00 to 4000000f (physical memory).  Lets say it is for 15
pages.  If we block out  the last page [0x3ffff000..0x3fffffff] from
what is available, there is no 15 page span that can happen across the
0x40000000 boundary.  For SG, there can be no merge that connects a
page from one region to another region.  Can you give an example of
the scenario you are thinking of?
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=99">Christoph Hellwig</a> - Oct. 20, 2017, 2:57 p.m.</div>
<pre class="content">
On Fri, Oct 20, 2017 at 10:41:56AM -0400, Jim Quinlan wrote:
<span class="quote">&gt; I am not sure I understand your comment -- the size of the request</span>
<span class="quote">&gt; shouldn&#39;t be a factor.  Let&#39;s look at your example of the DMA request</span>
<span class="quote">&gt; of 3fffff00 to 4000000f (physical memory).  Lets say it is for 15</span>
<span class="quote">&gt; pages.  If we block out  the last page [0x3ffff000..0x3fffffff] from</span>
<span class="quote">&gt; what is available, there is no 15 page span that can happen across the</span>
<span class="quote">&gt; 0x40000000 boundary.  For SG, there can be no merge that connects a</span>
<span class="quote">&gt; page from one region to another region.  Can you give an example of</span>
<span class="quote">&gt; the scenario you are thinking of?</span>

What prevents a merge from say the regions of
0....3fffffff and 40000000....7fffffff?
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=117971">Jim Quinlan</a> - Oct. 20, 2017, 3:27 p.m.</div>
<pre class="content">
On Fri, Oct 20, 2017 at 10:57 AM, Christoph Hellwig &lt;hch@lst.de&gt; wrote:
<span class="quote">&gt; On Fri, Oct 20, 2017 at 10:41:56AM -0400, Jim Quinlan wrote:</span>
<span class="quote">&gt;&gt; I am not sure I understand your comment -- the size of the request</span>
<span class="quote">&gt;&gt; shouldn&#39;t be a factor.  Let&#39;s look at your example of the DMA request</span>
<span class="quote">&gt;&gt; of 3fffff00 to 4000000f (physical memory).  Lets say it is for 15</span>
<span class="quote">&gt;&gt; pages.  If we block out  the last page [0x3ffff000..0x3fffffff] from</span>
<span class="quote">&gt;&gt; what is available, there is no 15 page span that can happen across the</span>
<span class="quote">&gt;&gt; 0x40000000 boundary.  For SG, there can be no merge that connects a</span>
<span class="quote">&gt;&gt; page from one region to another region.  Can you give an example of</span>
<span class="quote">&gt;&gt; the scenario you are thinking of?</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; What prevents a merge from say the regions of</span>
<span class="quote">&gt; 0....3fffffff and 40000000....7fffffff?</span>

Huh? [0x3ffff000...x3ffffff] is not available to be used. Drawing from
the original example, we now have to tell Linux that these are now our
effective memory regions:

      memc0-a@[        0....3fffefff] &lt;=&gt; pci@[        0....3fffefff]
      memc0-b@[100000000...13fffefff] &lt;=&gt; pci@[ 40000000....7fffefff]
      memc1-a@[ 40000000....7fffefff] &lt;=&gt; pci@[ 80000000....bfffefff]
      memc1-b@[300000000...33fffefff] &lt;=&gt; pci@[ c0000000....ffffefff]
      memc2-a@[ 80000000....bfffefff] &lt;=&gt; pci@[100000000...13fffefff]
      memc2-b@[c00000000...c3fffffff] &lt;=&gt; pci@[140000000...17fffffff]

This leaves a one-page gap between phsyical memory regions which would
normally be contiguous. One cannot have a dma alloc that spans any two
regions.  This is a drastic step, but I don&#39;t see an alternative.
Perhaps  I may be missing what you are saying...
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=99">Christoph Hellwig</a> - Oct. 20, 2017, 4:17 p.m.</div>
<pre class="content">
On Fri, Oct 20, 2017 at 11:27:41AM -0400, Jim Quinlan wrote:
<span class="quote">&gt;       memc0-a@[        0....3fffefff] &lt;=&gt; pci@[        0....3fffefff]</span>
<span class="quote">&gt;       memc0-b@[100000000...13fffefff] &lt;=&gt; pci@[ 40000000....7fffefff]</span>
<span class="quote">&gt;       memc1-a@[ 40000000....7fffefff] &lt;=&gt; pci@[ 80000000....bfffefff]</span>
<span class="quote">&gt;       memc1-b@[300000000...33fffefff] &lt;=&gt; pci@[ c0000000....ffffefff]</span>
<span class="quote">&gt;       memc2-a@[ 80000000....bfffefff] &lt;=&gt; pci@[100000000...13fffefff]</span>
<span class="quote">&gt;       memc2-b@[c00000000...c3fffffff] &lt;=&gt; pci@[140000000...17fffffff]</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; This leaves a one-page gap between phsyical memory regions which would</span>
<span class="quote">&gt; normally be contiguous. One cannot have a dma alloc that spans any two</span>
<span class="quote">&gt; regions.  This is a drastic step, but I don&#39;t see an alternative.</span>
<span class="quote">&gt; Perhaps  I may be missing what you are saying...</span>

Ok, IFF we are guranteed to always have a gap between physical memory
locations we are fine indeed.
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=21121">David Laight</a> - Oct. 23, 2017, 9:06 a.m.</div>
<pre class="content">
<span class="from">From: Jim Quinlan</span>
<span class="quote">&gt; Sent: 20 October 2017 16:28</span>
<span class="quote">&gt; On Fri, Oct 20, 2017 at 10:57 AM, Christoph Hellwig &lt;hch@lst.de&gt; wrote:</span>
<span class="quote">&gt; &gt; On Fri, Oct 20, 2017 at 10:41:56AM -0400, Jim Quinlan wrote:</span>
<span class="quote">&gt; &gt;&gt; I am not sure I understand your comment -- the size of the request</span>
<span class="quote">&gt; &gt;&gt; shouldn&#39;t be a factor.  Let&#39;s look at your example of the DMA request</span>
<span class="quote">&gt; &gt;&gt; of 3fffff00 to 4000000f (physical memory).  Lets say it is for 15</span>
<span class="quote">&gt; &gt;&gt; pages.  If we block out  the last page [0x3ffff000..0x3fffffff] from</span>
<span class="quote">&gt; &gt;&gt; what is available, there is no 15 page span that can happen across the</span>
<span class="quote">&gt; &gt;&gt; 0x40000000 boundary.  For SG, there can be no merge that connects a</span>
<span class="quote">&gt; &gt;&gt; page from one region to another region.  Can you give an example of</span>
<span class="quote">&gt; &gt;&gt; the scenario you are thinking of?</span>
<span class="quote">&gt; &gt;</span>
<span class="quote">&gt; &gt; What prevents a merge from say the regions of</span>
<span class="quote">&gt; &gt; 0....3fffffff and 40000000....7fffffff?</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Huh? [0x3ffff000...x3ffffff] is not available to be used. Drawing from</span>
<span class="quote">&gt; the original example, we now have to tell Linux that these are now our</span>
<span class="quote">&gt; effective memory regions:</span>
<span class="quote">&gt; </span>
<span class="quote">&gt;       memc0-a@[        0....3fffefff] &lt;=&gt; pci@[        0....3fffefff]</span>
<span class="quote">&gt;       memc0-b@[100000000...13fffefff] &lt;=&gt; pci@[ 40000000....7fffefff]</span>
<span class="quote">&gt;       memc1-a@[ 40000000....7fffefff] &lt;=&gt; pci@[ 80000000....bfffefff]</span>
<span class="quote">&gt;       memc1-b@[300000000...33fffefff] &lt;=&gt; pci@[ c0000000....ffffefff]</span>
<span class="quote">&gt;       memc2-a@[ 80000000....bfffefff] &lt;=&gt; pci@[100000000...13fffefff]</span>
<span class="quote">&gt;       memc2-b@[c00000000...c3fffffff] &lt;=&gt; pci@[140000000...17fffffff]</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; This leaves a one-page gap between phsyical memory regions which would</span>
<span class="quote">&gt; normally be contiguous. One cannot have a dma alloc that spans any two</span>
<span class="quote">&gt; regions.  This is a drastic step, but I don&#39;t see an alternative.</span>
<span class="quote">&gt; Perhaps  I may be missing what you are saying...</span>

Isn&#39;t this all unnecessary?
Both kmalloc() and dma_alloc() are constrained to allocate memory
that doesn&#39;t cross an address boundary that is larger than the size.
So if you allocate 16k it won&#39;t cross a 16k physical address boundary.

	David
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=117971">Jim Quinlan</a> - Oct. 24, 2017, 6:08 p.m.</div>
<pre class="content">
On Mon, Oct 23, 2017 at 5:06 AM, David Laight &lt;David.Laight@aculab.com&gt; wrote:
<span class="quote">&gt; From: Jim Quinlan</span>
<span class="quote">&gt;&gt; Sent: 20 October 2017 16:28</span>
<span class="quote">&gt;&gt; On Fri, Oct 20, 2017 at 10:57 AM, Christoph Hellwig &lt;hch@lst.de&gt; wrote:</span>
<span class="quote">&gt;&gt; &gt; On Fri, Oct 20, 2017 at 10:41:56AM -0400, Jim Quinlan wrote:</span>
<span class="quote">&gt;&gt; &gt;&gt; I am not sure I understand your comment -- the size of the request</span>
<span class="quote">&gt;&gt; &gt;&gt; shouldn&#39;t be a factor.  Let&#39;s look at your example of the DMA request</span>
<span class="quote">&gt;&gt; &gt;&gt; of 3fffff00 to 4000000f (physical memory).  Lets say it is for 15</span>
<span class="quote">&gt;&gt; &gt;&gt; pages.  If we block out  the last page [0x3ffff000..0x3fffffff] from</span>
<span class="quote">&gt;&gt; &gt;&gt; what is available, there is no 15 page span that can happen across the</span>
<span class="quote">&gt;&gt; &gt;&gt; 0x40000000 boundary.  For SG, there can be no merge that connects a</span>
<span class="quote">&gt;&gt; &gt;&gt; page from one region to another region.  Can you give an example of</span>
<span class="quote">&gt;&gt; &gt;&gt; the scenario you are thinking of?</span>
<span class="quote">&gt;&gt; &gt;</span>
<span class="quote">&gt;&gt; &gt; What prevents a merge from say the regions of</span>
<span class="quote">&gt;&gt; &gt; 0....3fffffff and 40000000....7fffffff?</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; Huh? [0x3ffff000...x3ffffff] is not available to be used. Drawing from</span>
<span class="quote">&gt;&gt; the original example, we now have to tell Linux that these are now our</span>
<span class="quote">&gt;&gt; effective memory regions:</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt;       memc0-a@[        0....3fffefff] &lt;=&gt; pci@[        0....3fffefff]</span>
<span class="quote">&gt;&gt;       memc0-b@[100000000...13fffefff] &lt;=&gt; pci@[ 40000000....7fffefff]</span>
<span class="quote">&gt;&gt;       memc1-a@[ 40000000....7fffefff] &lt;=&gt; pci@[ 80000000....bfffefff]</span>
<span class="quote">&gt;&gt;       memc1-b@[300000000...33fffefff] &lt;=&gt; pci@[ c0000000....ffffefff]</span>
<span class="quote">&gt;&gt;       memc2-a@[ 80000000....bfffefff] &lt;=&gt; pci@[100000000...13fffefff]</span>
<span class="quote">&gt;&gt;       memc2-b@[c00000000...c3fffffff] &lt;=&gt; pci@[140000000...17fffffff]</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; This leaves a one-page gap between phsyical memory regions which would</span>
<span class="quote">&gt;&gt; normally be contiguous. One cannot have a dma alloc that spans any two</span>
<span class="quote">&gt;&gt; regions.  This is a drastic step, but I don&#39;t see an alternative.</span>
<span class="quote">&gt;&gt; Perhaps  I may be missing what you are saying...</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; Isn&#39;t this all unnecessary?</span>
<span class="quote">&gt; Both kmalloc() and dma_alloc() are constrained to allocate memory</span>
<span class="quote">&gt; that doesn&#39;t cross an address boundary that is larger than the size.</span>
<span class="quote">&gt; So if you allocate 16k it won&#39;t cross a 16k physical address boundary.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;         David</span>
<span class="quote">&gt;</span>
Hi David,  Christoph was also concerned about this:

&quot;For the block world take a look at __blk_segment_map_sg which does the merging
of contiguous pages into a single SG segment.  You&#39;d have to override
BIOVEC_PHYS_MERGEABLE to prevent this from happening in your supported
architectures for the block layer.&quot;

Do you consider this a non-issue as well or can this happen and span
memory regions?
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=21121">David Laight</a> - Oct. 25, 2017, 9:36 a.m.</div>
<pre class="content">
<span class="from">From: Jim Quinla</span>
<span class="quote">&gt; Sent: 24 October 2017 19:08</span>
...
<span class="quote">&gt; Hi David,  Christoph was also concerned about this:</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; &quot;For the block world take a look at __blk_segment_map_sg which does the merging</span>
<span class="quote">&gt; of contiguous pages into a single SG segment.  You&#39;d have to override</span>
<span class="quote">&gt; BIOVEC_PHYS_MERGEABLE to prevent this from happening in your supported</span>
<span class="quote">&gt; architectures for the block layer.&quot;</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Do you consider this a non-issue as well or can this happen and span</span>
<span class="quote">&gt; memory regions?</span>

Probably easiest to have an architecture limit on the addresses that
can be merged.

My guess is that this code only really ever merges pages that were
allocated contiguously, but have got converted to a list of VA.
So stopping merging over even 1MB boundaries would have minimal effect
(even if done unconditionally).

I even wonder if the merging is actually worthwhile at all?
Maybe if any code has limits on the SG list length.
(or reducing the number of cache lines the get dirtied...)

	David
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/drivers/pci/host/Makefile b/drivers/pci/host/Makefile</span>
<span class="p_header">index 4398d2c..c283321 100644</span>
<span class="p_header">--- a/drivers/pci/host/Makefile</span>
<span class="p_header">+++ b/drivers/pci/host/Makefile</span>
<span class="p_chunk">@@ -21,7 +21,8 @@</span> <span class="p_context"> obj-$(CONFIG_PCIE_ROCKCHIP) += pcie-rockchip.o</span>
 obj-$(CONFIG_PCIE_MEDIATEK) += pcie-mediatek.o
 obj-$(CONFIG_PCIE_TANGO_SMP8759) += pcie-tango.o
 obj-$(CONFIG_VMD) += vmd.o
<span class="p_del">-obj-$(CONFIG_PCI_BRCMSTB) += pci-brcmstb.o</span>
<span class="p_add">+obj-$(CONFIG_PCI_BRCMSTB) += brcmstb-pci.o</span>
<span class="p_add">+brcmstb-pci-objs := pci-brcmstb.o pci-brcmstb-dma.o</span>
 
 # The following drivers are for devices that use the generic ACPI
 # pci_root.c driver but don&#39;t support standard ECAM config access.
<span class="p_header">diff --git a/drivers/pci/host/pci-brcmstb-dma.c b/drivers/pci/host/pci-brcmstb-dma.c</span>
new file mode 100644
<span class="p_header">index 0000000..81ce122</span>
<span class="p_header">--- /dev/null</span>
<span class="p_header">+++ b/drivers/pci/host/pci-brcmstb-dma.c</span>
<span class="p_chunk">@@ -0,0 +1,219 @@</span> <span class="p_context"></span>
<span class="p_add">+/*</span>
<span class="p_add">+ * Copyright (C) 2015-2017 Broadcom</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * This program is free software; you can redistribute it and/or modify</span>
<span class="p_add">+ * it under the terms of the GNU General Public License version 2 as</span>
<span class="p_add">+ * published by the Free Software Foundation.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * This program is distributed in the hope that it will be useful,</span>
<span class="p_add">+ * but WITHOUT ANY WARRANTY; without even the implied warranty of</span>
<span class="p_add">+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the</span>
<span class="p_add">+ * GNU General Public License for more details.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ */</span>
<span class="p_add">+#include &lt;linux/dma-mapping.h&gt;</span>
<span class="p_add">+#include &lt;linux/init.h&gt;</span>
<span class="p_add">+#include &lt;linux/io.h&gt;</span>
<span class="p_add">+#include &lt;linux/kernel.h&gt;</span>
<span class="p_add">+#include &lt;linux/of_address.h&gt;</span>
<span class="p_add">+#include &lt;linux/pci.h&gt;</span>
<span class="p_add">+#include &lt;linux/platform_device.h&gt;</span>
<span class="p_add">+#include &lt;linux/smp.h&gt;</span>
<span class="p_add">+</span>
<span class="p_add">+#include &quot;pci-brcmstb.h&quot;</span>
<span class="p_add">+</span>
<span class="p_add">+static const struct dma_map_ops *arch_dma_ops;</span>
<span class="p_add">+static struct dma_map_ops brcm_dma_ops;</span>
<span class="p_add">+</span>
<span class="p_add">+static void *brcm_dma_alloc(struct device *dev, size_t size, dma_addr_t *handle,</span>
<span class="p_add">+			    gfp_t gfp, unsigned long attrs)</span>
<span class="p_add">+{</span>
<span class="p_add">+	void *ret;</span>
<span class="p_add">+</span>
<span class="p_add">+	ret = arch_dma_ops-&gt;alloc(dev, size, handle, gfp, attrs);</span>
<span class="p_add">+	if (ret)</span>
<span class="p_add">+		*handle = brcm_to_pci(*handle);</span>
<span class="p_add">+	return ret;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static void brcm_dma_free(struct device *dev, size_t size, void *cpu_addr,</span>
<span class="p_add">+			  dma_addr_t handle, unsigned long attrs)</span>
<span class="p_add">+{</span>
<span class="p_add">+	handle = brcm_to_cpu(handle);</span>
<span class="p_add">+	arch_dma_ops-&gt;free(dev, size, cpu_addr, handle, attrs);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static int brcm_dma_mmap(struct device *dev, struct vm_area_struct *vma,</span>
<span class="p_add">+			 void *cpu_addr, dma_addr_t dma_addr, size_t size,</span>
<span class="p_add">+			 unsigned long attrs)</span>
<span class="p_add">+{</span>
<span class="p_add">+	dma_addr = brcm_to_cpu(dma_addr);</span>
<span class="p_add">+	return arch_dma_ops-&gt;mmap(dev, vma, cpu_addr, dma_addr, size, attrs);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static int brcm_dma_get_sgtable(struct device *dev, struct sg_table *sgt,</span>
<span class="p_add">+				void *cpu_addr, dma_addr_t handle, size_t size,</span>
<span class="p_add">+				unsigned long attrs)</span>
<span class="p_add">+{</span>
<span class="p_add">+	handle = brcm_to_cpu(handle);</span>
<span class="p_add">+	return arch_dma_ops-&gt;get_sgtable(dev, sgt, cpu_addr, handle, size,</span>
<span class="p_add">+				       attrs);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static dma_addr_t brcm_dma_map_page(struct device *dev, struct page *page,</span>
<span class="p_add">+				    unsigned long offset, size_t size,</span>
<span class="p_add">+				    enum dma_data_direction dir,</span>
<span class="p_add">+				    unsigned long attrs)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return brcm_to_pci(arch_dma_ops-&gt;map_page(dev, page, offset, size,</span>
<span class="p_add">+						  dir, attrs));</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static void brcm_dma_unmap_page(struct device *dev, dma_addr_t handle,</span>
<span class="p_add">+				size_t size, enum dma_data_direction dir,</span>
<span class="p_add">+				unsigned long attrs)</span>
<span class="p_add">+{</span>
<span class="p_add">+	handle = brcm_to_cpu(handle);</span>
<span class="p_add">+	arch_dma_ops-&gt;unmap_page(dev, handle, size, dir, attrs);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static int brcm_dma_map_sg(struct device *dev, struct scatterlist *sgl,</span>
<span class="p_add">+			   int nents, enum dma_data_direction dir,</span>
<span class="p_add">+			   unsigned long attrs)</span>
<span class="p_add">+{</span>
<span class="p_add">+	int ret, i;</span>
<span class="p_add">+	struct scatterlist *sg;</span>
<span class="p_add">+</span>
<span class="p_add">+	ret = arch_dma_ops-&gt;map_sg(dev, sgl, nents, dir, attrs);</span>
<span class="p_add">+	/* The ARM and MIPS implementations of map_sg and unmap_sg</span>
<span class="p_add">+	 * make calls to ops-&gt;map_page(), which we already intercept.</span>
<span class="p_add">+	 * The ARM64 does not, so we must iterate through the SG list</span>
<span class="p_add">+	 * and  convert each dma_address to one that is compatible</span>
<span class="p_add">+	 * with our PCI RC implementation.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	if (IS_ENABLED(CONFIG_ARM64))</span>
<span class="p_add">+		for_each_sg(sgl, sg, ret, i)</span>
<span class="p_add">+			sg-&gt;dma_address = brcm_to_pci(sg-&gt;dma_address);</span>
<span class="p_add">+	return ret;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static void brcm_dma_unmap_sg(struct device *dev,</span>
<span class="p_add">+			      struct scatterlist *sgl, int nents,</span>
<span class="p_add">+			      enum dma_data_direction dir,</span>
<span class="p_add">+			      unsigned long attrs)</span>
<span class="p_add">+{</span>
<span class="p_add">+	int i;</span>
<span class="p_add">+	struct scatterlist *sg;</span>
<span class="p_add">+</span>
<span class="p_add">+	/* The ARM and MIPS implementations of map_sg and unmap_sg</span>
<span class="p_add">+	 * make calls to ops-&gt;map_page(), which we already intercept.</span>
<span class="p_add">+	 * The ARM64 does not, so we must iterate through the SG list</span>
<span class="p_add">+	 * and  convert each dma_address to one that is compatible</span>
<span class="p_add">+	 * with our PCI RC implementation.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	if (IS_ENABLED(CONFIG_ARM64))</span>
<span class="p_add">+		for_each_sg(sgl, sg, nents, i)</span>
<span class="p_add">+			sg-&gt;dma_address = brcm_to_cpu(sg-&gt;dma_address);</span>
<span class="p_add">+	arch_dma_ops-&gt;map_sg(dev, sgl, nents, dir, attrs);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static void brcm_dma_sync_single_for_cpu(struct device *dev,</span>
<span class="p_add">+					 dma_addr_t handle, size_t size,</span>
<span class="p_add">+					 enum dma_data_direction dir)</span>
<span class="p_add">+{</span>
<span class="p_add">+	handle = brcm_to_cpu(handle);</span>
<span class="p_add">+	arch_dma_ops-&gt;sync_single_for_cpu(dev, handle, size, dir);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static void brcm_dma_sync_single_for_device(struct device *dev,</span>
<span class="p_add">+					    dma_addr_t handle, size_t size,</span>
<span class="p_add">+					    enum dma_data_direction dir)</span>
<span class="p_add">+{</span>
<span class="p_add">+	handle = brcm_to_cpu(handle);</span>
<span class="p_add">+	arch_dma_ops-&gt;sync_single_for_device(dev, handle, size, dir);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static dma_addr_t brcm_dma_map_resource(struct device *dev, phys_addr_t phys,</span>
<span class="p_add">+					size_t size,</span>
<span class="p_add">+					enum dma_data_direction dir,</span>
<span class="p_add">+					unsigned long attrs)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return brcm_to_pci(arch_dma_ops-&gt;map_resource</span>
<span class="p_add">+			   (dev, phys, size, dir, attrs));</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static void brcm_dma_unmap_resource(struct device *dev, dma_addr_t handle,</span>
<span class="p_add">+				    size_t size, enum dma_data_direction dir,</span>
<span class="p_add">+				    unsigned long attrs)</span>
<span class="p_add">+{</span>
<span class="p_add">+	handle = brcm_to_cpu(handle);</span>
<span class="p_add">+	arch_dma_ops-&gt;unmap_resource(dev, handle, size, dir, attrs);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static int brcm_mapping_error(struct device *dev, dma_addr_t dma_addr)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return dma_addr == BRCMSTB_ERROR_CODE;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static const struct dma_map_ops *brcm_get_arch_dma_ops(struct device *dev)</span>
<span class="p_add">+{</span>
<span class="p_add">+#if defined(CONFIG_MIPS)</span>
<span class="p_add">+	return mips_dma_map_ops;</span>
<span class="p_add">+#elif defined(CONFIG_ARM)</span>
<span class="p_add">+	return &amp;arm_dma_ops;</span>
<span class="p_add">+#elif defined(CONFIG_ARM64)</span>
<span class="p_add">+	/* swiotlb_dma_ops is a static var, so we get ahold</span>
<span class="p_add">+	 * of it by calling arch_setup_dma_ops(...).</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	arch_setup_dma_ops(dev, 0, 0, NULL, false);</span>
<span class="p_add">+	return dev-&gt;dma_ops;</span>
<span class="p_add">+#endif</span>
<span class="p_add">+	return 0;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static void brcm_set_dma_ops(struct device *dev)</span>
<span class="p_add">+{</span>
<span class="p_add">+	arch_dma_ops = brcm_get_arch_dma_ops(dev);</span>
<span class="p_add">+	if (!arch_dma_ops)</span>
<span class="p_add">+		return;</span>
<span class="p_add">+</span>
<span class="p_add">+	/* Set all of the base operations; some will be overridden */</span>
<span class="p_add">+	brcm_dma_ops = *arch_dma_ops;</span>
<span class="p_add">+</span>
<span class="p_add">+	/* Insert the Brcm-specific override operations */</span>
<span class="p_add">+	brcm_dma_ops.alloc = brcm_dma_alloc;</span>
<span class="p_add">+	brcm_dma_ops.free = brcm_dma_free;</span>
<span class="p_add">+	brcm_dma_ops.mmap = brcm_dma_mmap;</span>
<span class="p_add">+	brcm_dma_ops.get_sgtable = brcm_dma_get_sgtable;</span>
<span class="p_add">+	brcm_dma_ops.map_page = brcm_dma_map_page;</span>
<span class="p_add">+	brcm_dma_ops.unmap_page = brcm_dma_unmap_page;</span>
<span class="p_add">+	brcm_dma_ops.sync_single_for_cpu = brcm_dma_sync_single_for_cpu;</span>
<span class="p_add">+	brcm_dma_ops.sync_single_for_device = brcm_dma_sync_single_for_device;</span>
<span class="p_add">+	brcm_dma_ops.map_sg = brcm_dma_map_sg;</span>
<span class="p_add">+	brcm_dma_ops.unmap_sg = brcm_dma_unmap_sg;</span>
<span class="p_add">+	if (arch_dma_ops-&gt;map_resource)</span>
<span class="p_add">+		brcm_dma_ops.map_resource = brcm_dma_map_resource;</span>
<span class="p_add">+	if (arch_dma_ops-&gt;unmap_resource)</span>
<span class="p_add">+		brcm_dma_ops.unmap_resource = brcm_dma_unmap_resource;</span>
<span class="p_add">+	brcm_dma_ops.mapping_error = brcm_mapping_error;</span>
<span class="p_add">+</span>
<span class="p_add">+	/* Use our brcm_dma_ops for this driver */</span>
<span class="p_add">+	set_dma_ops(dev, &amp;brcm_dma_ops);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static int brcmstb_platform_notifier(struct notifier_block *nb,</span>
<span class="p_add">+				     unsigned long event, void *__dev)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct device *dev = __dev;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (event != BUS_NOTIFY_ADD_DEVICE)</span>
<span class="p_add">+		return NOTIFY_DONE;</span>
<span class="p_add">+</span>
<span class="p_add">+	brcm_set_dma_ops(dev);</span>
<span class="p_add">+	return NOTIFY_OK;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+struct notifier_block brcmstb_platform_nb = {</span>
<span class="p_add">+	.notifier_call = brcmstb_platform_notifier,</span>
<span class="p_add">+};</span>
<span class="p_add">+EXPORT_SYMBOL(brcmstb_platform_nb);</span>
<span class="p_header">diff --git a/drivers/pci/host/pci-brcmstb.c b/drivers/pci/host/pci-brcmstb.c</span>
<span class="p_header">index f4cd6e7..03c0da9 100644</span>
<span class="p_header">--- a/drivers/pci/host/pci-brcmstb.c</span>
<span class="p_header">+++ b/drivers/pci/host/pci-brcmstb.c</span>
<span class="p_chunk">@@ -343,6 +343,8 @@</span> <span class="p_context"> struct brcm_pcie {</span>
 
 static struct list_head brcm_pcie = LIST_HEAD_INIT(brcm_pcie);
 static phys_addr_t scb_size[BRCM_MAX_SCB];
<span class="p_add">+static struct of_pci_range *dma_ranges;</span>
<span class="p_add">+static int num_dma_ranges;</span>
 static int num_memc;
 static DEFINE_MUTEX(brcm_pcie_lock);
 
<span class="p_chunk">@@ -362,6 +364,8 @@</span> <span class="p_context"> static int brcm_pcie_add_controller(struct brcm_pcie *pcie)</span>
 {
 	mutex_lock(&amp;brcm_pcie_lock);
 	snprintf(pcie-&gt;name, sizeof(pcie-&gt;name) - 1, &quot;PCIe%d&quot;, pcie-&gt;id);
<span class="p_add">+	if (list_empty(&amp;brcm_pcie))</span>
<span class="p_add">+		bus_register_notifier(&amp;pci_bus_type, &amp;brcmstb_platform_nb);</span>
 	list_add_tail(&amp;pcie-&gt;list, &amp;brcm_pcie);
 	mutex_unlock(&amp;brcm_pcie_lock);
 
<span class="p_chunk">@@ -378,8 +382,14 @@</span> <span class="p_context"> static void brcm_pcie_remove_controller(struct brcm_pcie *pcie)</span>
 		tmp = list_entry(pos, struct brcm_pcie, list);
 		if (tmp == pcie) {
 			list_del(pos);
<span class="p_del">-			if (list_empty(&amp;brcm_pcie))</span>
<span class="p_add">+			if (list_empty(&amp;brcm_pcie)) {</span>
<span class="p_add">+				bus_unregister_notifier(&amp;pci_bus_type,</span>
<span class="p_add">+							&amp;brcmstb_platform_nb);</span>
<span class="p_add">+				kfree(dma_ranges);</span>
<span class="p_add">+				dma_ranges = NULL;</span>
<span class="p_add">+				num_dma_ranges = 0;</span>
 				num_memc = 0;
<span class="p_add">+			}</span>
 			break;
 		}
 	}
<span class="p_chunk">@@ -403,6 +413,35 @@</span> <span class="p_context"> int encode_ibar_size(u64 size)</span>
 	return 0;
 }
 
<span class="p_add">+dma_addr_t brcm_to_pci(dma_addr_t addr)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct of_pci_range *p;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (!num_dma_ranges)</span>
<span class="p_add">+		return addr;</span>
<span class="p_add">+</span>
<span class="p_add">+	for (p = dma_ranges; p &lt; &amp;dma_ranges[num_dma_ranges]; p++)</span>
<span class="p_add">+		if (addr &gt;= p-&gt;cpu_addr &amp;&amp; addr &lt; (p-&gt;cpu_addr + p-&gt;size))</span>
<span class="p_add">+			return addr - p-&gt;cpu_addr + p-&gt;pci_addr;</span>
<span class="p_add">+</span>
<span class="p_add">+	return BRCMSTB_ERROR_CODE;</span>
<span class="p_add">+}</span>
<span class="p_add">+EXPORT_SYMBOL(brcm_to_pci);</span>
<span class="p_add">+</span>
<span class="p_add">+dma_addr_t brcm_to_cpu(dma_addr_t addr)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct of_pci_range *p;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (!num_dma_ranges)</span>
<span class="p_add">+		return addr;</span>
<span class="p_add">+	for (p = dma_ranges; p &lt; &amp;dma_ranges[num_dma_ranges]; p++)</span>
<span class="p_add">+		if (addr &gt;= p-&gt;pci_addr &amp;&amp; addr &lt; (p-&gt;pci_addr + p-&gt;size))</span>
<span class="p_add">+			return addr - p-&gt;pci_addr + p-&gt;cpu_addr;</span>
<span class="p_add">+</span>
<span class="p_add">+	return addr;</span>
<span class="p_add">+}</span>
<span class="p_add">+EXPORT_SYMBOL(brcm_to_cpu);</span>
<span class="p_add">+</span>
 static u32 mdio_form_pkt(int port, int regad, int cmd)
 {
 	u32 pkt = 0;
<span class="p_chunk">@@ -652,6 +691,74 @@</span> <span class="p_context"> static int brcm_parse_ranges(struct brcm_pcie *pcie)</span>
 	return 0;
 }
 
<span class="p_add">+static int brcm_pci_dma_range_parser_init(struct of_pci_range_parser *parser,</span>
<span class="p_add">+					  struct device_node *node)</span>
<span class="p_add">+{</span>
<span class="p_add">+	const int na = 3, ns = 2;</span>
<span class="p_add">+	int rlen;</span>
<span class="p_add">+</span>
<span class="p_add">+	parser-&gt;node = node;</span>
<span class="p_add">+	parser-&gt;pna = of_n_addr_cells(node);</span>
<span class="p_add">+	parser-&gt;np = parser-&gt;pna + na + ns;</span>
<span class="p_add">+</span>
<span class="p_add">+	parser-&gt;range = of_get_property(node, &quot;dma-ranges&quot;, &amp;rlen);</span>
<span class="p_add">+	if (!parser-&gt;range)</span>
<span class="p_add">+		return -ENOENT;</span>
<span class="p_add">+</span>
<span class="p_add">+	parser-&gt;end = parser-&gt;range + rlen / sizeof(__be32);</span>
<span class="p_add">+</span>
<span class="p_add">+	return 0;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static int brcm_parse_dma_ranges(struct brcm_pcie *pcie)</span>
<span class="p_add">+{</span>
<span class="p_add">+	int i, ret = 0;</span>
<span class="p_add">+	struct of_pci_range_parser parser;</span>
<span class="p_add">+	struct device_node *dn = pcie-&gt;dn;</span>
<span class="p_add">+</span>
<span class="p_add">+	mutex_lock(&amp;brcm_pcie_lock);</span>
<span class="p_add">+	if (dma_ranges)</span>
<span class="p_add">+		goto done;</span>
<span class="p_add">+</span>
<span class="p_add">+	/* Parse dma-ranges property if present.  If there are multiple</span>
<span class="p_add">+	 * PCI controllers, we only have to parse from one of them since</span>
<span class="p_add">+	 * the others will have an identical mapping.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	if (!brcm_pci_dma_range_parser_init(&amp;parser, dn)) {</span>
<span class="p_add">+		unsigned int max_ranges</span>
<span class="p_add">+			= (parser.end - parser.range) / parser.np;</span>
<span class="p_add">+</span>
<span class="p_add">+		dma_ranges = kcalloc(max_ranges, sizeof(struct of_pci_range),</span>
<span class="p_add">+				     GFP_KERNEL);</span>
<span class="p_add">+		if (!dma_ranges) {</span>
<span class="p_add">+			ret =  -ENOMEM;</span>
<span class="p_add">+			goto done;</span>
<span class="p_add">+		}</span>
<span class="p_add">+		for (i = 0; of_pci_range_parser_one(&amp;parser, dma_ranges + i);</span>
<span class="p_add">+		     i++)</span>
<span class="p_add">+			num_dma_ranges++;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	for (i = 0, num_memc = 0; i &lt; BRCM_MAX_SCB; i++) {</span>
<span class="p_add">+		u64 size = brcmstb_memory_memc_size(i);</span>
<span class="p_add">+</span>
<span class="p_add">+		if (size == (u64)-1) {</span>
<span class="p_add">+			dev_err(pcie-&gt;dev, &quot;cannot get memc%d size&quot;, i);</span>
<span class="p_add">+			ret = -EINVAL;</span>
<span class="p_add">+			goto done;</span>
<span class="p_add">+		} else if (size) {</span>
<span class="p_add">+			scb_size[i] = roundup_pow_of_two_64(size);</span>
<span class="p_add">+			num_memc++;</span>
<span class="p_add">+		} else {</span>
<span class="p_add">+			break;</span>
<span class="p_add">+		}</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+done:</span>
<span class="p_add">+	mutex_unlock(&amp;brcm_pcie_lock);</span>
<span class="p_add">+	return ret;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static void set_regulators(struct brcm_pcie *pcie, bool on)
 {
 	struct list_head *pos;
<span class="p_chunk">@@ -728,10 +835,34 @@</span> <span class="p_context"> static void brcm_pcie_setup_prep(struct brcm_pcie *pcie)</span>
 	 */
 	rc_bar2_size = roundup_pow_of_two_64(total_mem_size);
 
<span class="p_del">-	/* Set simple configuration based on memory sizes</span>
<span class="p_del">-	 * only.  We always start the viewport at address 0.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	rc_bar2_offset = 0;</span>
<span class="p_add">+	if (dma_ranges) {</span>
<span class="p_add">+		/* The best-case scenario is to place the inbound</span>
<span class="p_add">+		 * region in the first 4GB of pci-space, as some</span>
<span class="p_add">+		 * legacy devices can only address 32bits.</span>
<span class="p_add">+		 * We would also like to put the MSI under 4GB</span>
<span class="p_add">+		 * as well, since some devices require a 32bit</span>
<span class="p_add">+		 * MSI target address.</span>
<span class="p_add">+		 */</span>
<span class="p_add">+		if (total_mem_size &lt;= 0xc0000000ULL &amp;&amp;</span>
<span class="p_add">+		    rc_bar2_size &lt;= 0x100000000ULL) {</span>
<span class="p_add">+			rc_bar2_offset = 0;</span>
<span class="p_add">+		} else {</span>
<span class="p_add">+			/* The system memory is 4GB or larger so we</span>
<span class="p_add">+			 * cannot start the inbound region at location</span>
<span class="p_add">+			 * 0 (since we have to allow some space for</span>
<span class="p_add">+			 * outbound memory @ 3GB).  So instead we</span>
<span class="p_add">+			 * start it at the 1x multiple of its size</span>
<span class="p_add">+			 */</span>
<span class="p_add">+			rc_bar2_offset = rc_bar2_size;</span>
<span class="p_add">+		}</span>
<span class="p_add">+</span>
<span class="p_add">+	} else {</span>
<span class="p_add">+		/* Set simple configuration based on memory sizes</span>
<span class="p_add">+		 * only.  We always start the viewport at address 0,</span>
<span class="p_add">+		 * and set the MSI target address accordingly.</span>
<span class="p_add">+		 */</span>
<span class="p_add">+		rc_bar2_offset = 0;</span>
<span class="p_add">+	}</span>
 
 	tmp = lower_32_bits(rc_bar2_offset);
 	tmp = INSERT_FIELD(tmp, PCIE_MISC_RC_BAR2_CONFIG_LO, SIZE,
<span class="p_chunk">@@ -1040,11 +1171,6 @@</span> <span class="p_context"> static int brcm_pcie_probe(struct platform_device *pdev)</span>
 		return -EINVAL;
 	}
 
<span class="p_del">-	if (of_property_read_u32(dn, &quot;dma-ranges&quot;, &amp;tmp) == 0) {</span>
<span class="p_del">-		pr_err(&quot;cannot yet handle dma-ranges\n&quot;);</span>
<span class="p_del">-		return -EINVAL;</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
 	data = of_id-&gt;data;
 	pcie-&gt;reg_offsets = data-&gt;offsets;
 	pcie-&gt;reg_field_info = data-&gt;reg_field_info;
<span class="p_chunk">@@ -1113,6 +1239,10 @@</span> <span class="p_context"> static int brcm_pcie_probe(struct platform_device *pdev)</span>
 	if (ret)
 		return ret;
 
<span class="p_add">+	ret = brcm_parse_dma_ranges(pcie);</span>
<span class="p_add">+	if (ret)</span>
<span class="p_add">+		return ret;</span>
<span class="p_add">+</span>
 	ret = clk_prepare_enable(pcie-&gt;clk);
 	if (ret) {
 		dev_err(&amp;pdev-&gt;dev, &quot;could not enable clock\n&quot;);
<span class="p_header">diff --git a/drivers/pci/host/pci-brcmstb.h b/drivers/pci/host/pci-brcmstb.h</span>
<span class="p_header">index 86f9cd1..4851be8 100644</span>
<span class="p_header">--- a/drivers/pci/host/pci-brcmstb.h</span>
<span class="p_header">+++ b/drivers/pci/host/pci-brcmstb.h</span>
<span class="p_chunk">@@ -21,6 +21,13 @@</span> <span class="p_context"></span>
 /* Broadcom PCIE Offsets */
 #define PCIE_INTR2_CPU_BASE		0x4300
 
<span class="p_add">+dma_addr_t brcm_to_pci(dma_addr_t addr);</span>
<span class="p_add">+dma_addr_t brcm_to_cpu(dma_addr_t addr);</span>
<span class="p_add">+</span>
<span class="p_add">+extern struct notifier_block brcmstb_platform_nb;</span>
<span class="p_add">+</span>
<span class="p_add">+#define BRCMSTB_ERROR_CODE	(~(dma_addr_t)0x0)</span>
<span class="p_add">+</span>
 #if defined(CONFIG_MIPS)
 /* Broadcom MIPs HW implicitly does the swapping if necessary */
 #define bcm_readl(a)		__raw_readl(a)

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



