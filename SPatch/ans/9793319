
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>[v7,34/36] x86/mm: Add support to encrypt the kernel in-place - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    [v7,34/36] x86/mm: Add support to encrypt the kernel in-place</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=80801">Tom Lendacky</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>June 16, 2017, 6:56 p.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;20170616185619.18967.38945.stgit@tlendack-t1.amdoffice.net&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/9793319/mbox/"
   >mbox</a>
|
   <a href="/patch/9793319/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/9793319/">/patch/9793319/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
	[172.30.200.125])
	by pdx-korg-patchwork.web.codeaurora.org (Postfix) with ESMTP id
	C6D1860325 for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Fri, 16 Jun 2017 18:57:29 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id B42312865B
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Fri, 16 Jun 2017 18:57:29 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id A5A6D28671; Fri, 16 Jun 2017 18:57:29 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-6.9 required=2.0 tests=BAYES_00,DKIM_SIGNED,
	DKIM_VALID,RCVD_IN_DNSWL_HI autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 6DF4928670
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Fri, 16 Jun 2017 18:57:28 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1753111AbdFPS5U (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Fri, 16 Jun 2017 14:57:20 -0400
Received: from mail-bn3nam01on0052.outbound.protection.outlook.com
	([104.47.33.52]:18493
	&quot;EHLO NAM01-BN3-obe.outbound.protection.outlook.com&quot;
	rhost-flags-OK-OK-OK-FAIL) by vger.kernel.org with ESMTP
	id S1752037AbdFPS4e (ORCPT &lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Fri, 16 Jun 2017 14:56:34 -0400
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
	d=amdcloud.onmicrosoft.com; s=selector1-amd-com;
	h=From:Date:Subject:Message-ID:Content-Type:MIME-Version;
	bh=opaePQUn9s7KZMYV2IlQREGySikbfV01ZIqSuo6ofiM=;
	b=Bs6PjmNVibdUNOCRAuYmtcmHvSnlweGPdPpQWC653EANkFB9Q27NS8biDiH9rcWYtu4qimJ2EbfZrU+cFuVjyuE60i9agrQ+zikg2ccy2EGu/Wk214/als4//drLPxC5U/g9mcpkJHBRLx/kOyYubf7zt3qn/URLeRGQSHcywdI=
Authentication-Results: vger.kernel.org; dkim=none (message not signed)
	header.d=none; vger.kernel.org;
	dmarc=none action=none header.from=amd.com; 
Received: from tlendack-t1.amdoffice.net (165.204.77.1) by
	MWHPR12MB1151.namprd12.prod.outlook.com (10.169.204.15) with
	Microsoft SMTP Server (version=TLS1_2,
	cipher=TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256_P256) id
	15.1.1178.14; Fri, 16 Jun 2017 18:56:22 +0000
From: Tom Lendacky &lt;thomas.lendacky@amd.com&gt;
Subject: [PATCH v7 34/36] x86/mm: Add support to encrypt the kernel in-place
To: linux-arch@vger.kernel.org, linux-efi@vger.kernel.org,
	kvm@vger.kernel.org, linux-doc@vger.kernel.org, x86@kernel.org,
	kexec@lists.infradead.org, linux-kernel@vger.kernel.org,
	kasan-dev@googlegroups.com, xen-devel@lists.xen.org,
	linux-mm@kvack.org, iommu@lists.linux-foundation.org
Cc: Brijesh Singh &lt;brijesh.singh@amd.com&gt;,
	Toshimitsu Kani &lt;toshi.kani@hpe.com&gt;,
	Radim =?utf-8?b?S3LEjW3DocWZ?= &lt;rkrcmar@redhat.com&gt;,
	Matt Fleming &lt;matt@codeblueprint.co.uk&gt;,
	Alexander Potapenko &lt;glider@google.com&gt;,
	&quot;H. Peter Anvin&quot; &lt;hpa@zytor.com&gt;, Larry Woodman &lt;lwoodman@redhat.com&gt;,
	Jonathan Corbet &lt;corbet@lwn.net&gt;, Joerg Roedel &lt;joro@8bytes.org&gt;,
	&quot;Michael S. Tsirkin&quot; &lt;mst@redhat.com&gt;, Ingo Molnar &lt;mingo@redhat.com&gt;,
	Andrey Ryabinin &lt;aryabinin@virtuozzo.com&gt;,
	Dave Young &lt;dyoung@redhat.com&gt;, Rik van Riel &lt;riel@redhat.com&gt;,
	Arnd Bergmann &lt;arnd@arndb.de&gt;,
	Konrad Rzeszutek Wilk &lt;konrad.wilk@oracle.com&gt;,
	Borislav Petkov &lt;bp@alien8.de&gt;, Andy Lutomirski &lt;luto@kernel.org&gt;,
	Boris Ostrovsky &lt;boris.ostrovsky@oracle.com&gt;,
	Dmitry Vyukov &lt;dvyukov@google.com&gt;, Juergen Gross &lt;jgross@suse.com&gt;,
	Thomas Gleixner &lt;tglx@linutronix.de&gt;, Paolo Bonzini &lt;pbonzini@redhat.com&gt;
Date: Fri, 16 Jun 2017 13:56:19 -0500
Message-ID: &lt;20170616185619.18967.38945.stgit@tlendack-t1.amdoffice.net&gt;
In-Reply-To: &lt;20170616184947.18967.84890.stgit@tlendack-t1.amdoffice.net&gt;
References: &lt;20170616184947.18967.84890.stgit@tlendack-t1.amdoffice.net&gt;
User-Agent: StGit/0.17.1-dirty
MIME-Version: 1.0
Content-Type: text/plain; charset=&quot;utf-8&quot;
Content-Transfer-Encoding: 7bit
X-Originating-IP: [165.204.77.1]
X-ClientProxiedBy: DM5PR20CA0033.namprd20.prod.outlook.com (10.171.161.147)
	To MWHPR12MB1151.namprd12.prod.outlook.com (10.169.204.15)
X-MS-PublicTrafficType: Email
X-MS-Office365-Filtering-Correlation-Id: bc53a744-0d24-43e6-ba01-08d4b4e962f8
X-MS-Office365-Filtering-HT: Tenant
X-Microsoft-Antispam: UriScan:; BCL:0; PCL:0;
	RULEID:(22001)(48565401081)(201703131423075)(201703031133081);
	SRVR:MWHPR12MB1151; 
X-Microsoft-Exchange-Diagnostics: 1; MWHPR12MB1151;
	3:8XB7vyDh0de5zkzCv1eDPqmh/WDqMld19Opbe7ahzKv3NKd0oj0fnWAGZ9yMtaAQtt5qtQCM4B3/WwifklKkRSScs+yuA4T3tRcq06u1ZlVmMsVgPRXCj9VZOsmv5uU3/sERKtb/kP4nuXdKg7p/eHL7uggv5bteawo2OugPkE2bNEXBogSaLXQkNoltXnqIl/hJsJAc0incDluJLq4td9VpiaasQ+dBB3VLmapMOCCF0fl941dKWzPNrJStjB4XGfHeEIonNj32yZAvf1XLAtfUbU1lCTbVjHKHkZtQa7fFBh3KoFctVshpwbe4odGANkxDSLywe1zSYLlzQDdJlSWjggQBDe0g9gQh7BLNnEM=
X-MS-TrafficTypeDiagnostic: MWHPR12MB1151:
X-Microsoft-Exchange-Diagnostics: 1; MWHPR12MB1151;
	25:nt49jxUE44eoqSl9EohIADlUOjQ+RRuU5IlE6m3e6xOEnjOShSt9X5Y1bY+3xbowNAvuyFhkOcV6qQsTkK1fM9dJpNZf+qfXEZ2jcazmsQZWYixKEDkU6jhQt0sD2npBZoNVbMuh0r6gOuRXf2mON3bQTlRw9K/fDR5LmADmo3IVsczZDzMqQCuTo8mPE9d+XwEe00VXdvWSaPaGkIDgZpe52ktxqB9LL+wjyY/WlcBC3K9FSyGnpmOQTZ80dHWOp/g8dK6Te1lUhXvKSN6wfCNZRSkuo+XyaXpMVf9DE+EvaUKRZmaC1wC0gwl/Uk7jAvenkbEBmQQEWcd+9VO+yhSUrdg2Dd6MD4hc9+Gyw5y2McsOWkpmo3REeMZ96rDcCnSxoeVfrgV1B+whiXyKRs+rc9WQPf/WgL88lJ6hibDENeXHSl6dQajNHlxvB8xDZDLJ4ajnKinW6yTQ3CReHazn3dNUXl8KQMtbTB0qwUkf18K6lfAqYxK5MgE408DcIfmHrk6oASoC31fuLFvZnG7agjL/GXnekz+Ttj7mctaTH1MPll3SEviFlSUFH2r41d7acSOZLA6Q2cDIX+tcqqqFmvhBKUQiclI/e7l0UJkU/uUTCmtf5938aZb8/AMfpIN9vRjpBGhVN0+DWMnEfsIvDmSHqqoczifHpihlW7s5Orz98Vzb286lZPR3nCX34OmEC+aJC8Ba52DBFjMAndSY5HQci3zOyY7AWtnbOIy2OilQxiOwi9hkMs4m3CnrhJXxxJuSwl+C7B3dS1ZtloVEuBbRRpan8UHoOG9FFhLQ8laaVCwtjiUiviZMLE9qKhWl08mKprNwyDXMAc1WFZm1/E5AZa+ia402ovVAbBksNcOL9gvbSDbzn3Jq2wM0L98jCvMD4OpF6+M83xzTnOpfiizuoe5tL94EZuNao
	jc=
X-Microsoft-Exchange-Diagnostics: 1; MWHPR12MB1151;
	31:fKGdI6QzV8PErb9u2VGJbibR+AmocKGxl2LBkoMfVgTuoJ+ySr50nrz6qH/tr+T6uSpIBYs8H1R4KLg0RbqvdruVCRPPTHG8bWd1R4uNl01oCEWmRtAgfLxkXV59IbZboD+ru87ZK7Fqzc0Ho0iAfFQ646I6JjK+6OErUAbk9uA6lfaodGv1k9Q/OD+8hpgTbG3jk+roAn79Oq5wUX1MFqmBxksxF/xsQW+POHQ12aaU452v1y/fAUG5GeUHXQfhjo6cXJRBOBxvnBLcdc9IoQ0bzmE01TUbYz72pqS5J80Toy9Ef3ibK/ga8CEGNMjHtLO582xiYZdKrLtLvEO/53W7lH7nXGcqJHoeGWqEIrZ0g9O2HvY6fLvYwFp4UhC9x+3zMY8ADFhG+0/6s3ClDpTag5tsQaTq42NwZuWrUt9t2xJ6rLRo6LRpd4NBN7aI+jNFZPDz85RCbPKRwXwF22hcdv16zuapmupRYMXPF/fm6TPwh5LCUfSqG4R7V21x3zox8zCDD46c9zHmzDAAkNlA0h+3WPlYkOr7FTw1I7p8e8XfmKjJdDE+J8pf1bvCKrffzsECJh/xlkCJ4qyQBijNRjIMkI5Kva34iFdFect/V0UxLvDf+VpjZkuE2rt67F/DyTpOndrn4dPv+Ukmc0Pqxv++OyANzRUI+Pp3Meg=
X-Microsoft-Exchange-Diagnostics: 1; MWHPR12MB1151;
	20:ZlLJTXEgr6mQSmmFIMNv9X8qWwuq3H9IcNpI4qXLTVBaWIfDK/DhkZBc5v9fBTyDeC9HU6XKRmnhOFq3s/rC2tGcUfVZi4XBoee8+qslFtym9j7qsPpzFJ0arCo/6LMGt/zxmFFIZriNqk0n4jfwU6kr4buc/m0r8U+s+vClL7Eokv0BuTEzGWAZn0ocL4a4BRCSJ9HaWyVv/QAd1rtbmtP5BmkyP2h904exQRCyJ5gjLTRDhdDfmJkeh48B8QKvNTSiwx9SFya4SbYmbAxgiWecX+XZ+Gm3pmuOcnFae8TCnYl86DJEd9HrZR9K3Sds6lpPoowKkG8Aa9K3COQ57BpJXx3vTxuJxHezrIzLQhuNodW2OXRKpe6eMcNd0ckf9hwdHcGrSyW1pVW94zijlhcu+PPIKgB1nQu/Vak+aVa5GUmoiOTCi9w1wkrAjIMLAF9Bmqa+N0u9D8XKc8JdKjrjNza2a1amNwKO/+Er8iXQZBDWKKgAfB/tu8HqI9Ix
X-Microsoft-Antispam-PRVS: &lt;MWHPR12MB1151F2316BAABDB16328ABE7ECC10@MWHPR12MB1151.namprd12.prod.outlook.com&gt;
X-Exchange-Antispam-Report-Test: UriScan:(767451399110);
X-Exchange-Antispam-Report-CFA-Test: BCL:0; PCL:0;
	RULEID:(100000700101)(100105000095)(100000701101)(100105300095)(100000702101)(100105100095)(6040450)(601004)(2401047)(8121501046)(5005006)(93006095)(93001095)(3002001)(10201501046)(100000703101)(100105400095)(6055026)(6041248)(20161123558100)(20161123564025)(20161123562025)(20161123555025)(20161123560025)(201703131423075)(201702281528075)(201703061421075)(201703061406153)(6072148)(100000704101)(100105200095)(100000705101)(100105500095);
	SRVR:MWHPR12MB1151; BCL:0; PCL:0;
	RULEID:(100000800101)(100110000095)(100000801101)(100110300095)(100000802101)(100110100095)(100000803101)(100110400095)(100000804101)(100110200095)(100000805101)(100110500095);
	SRVR:MWHPR12MB1151; 
X-Microsoft-Exchange-Diagnostics: =?utf-8?B?MTtNV0hQUjEyTUIxMTUxOzQ6V3Y0WUxZRlo0WXFSVjAzb3hnSUY1aUxES05t?=
	=?utf-8?B?TEJ5NlI4clIrRUcyN2FPeXpXdkQybnV5NmRpRU1NQ21yMHk3citIMEEvYkpm?=
	=?utf-8?B?amdaWjlmYXdVZ0RWSGI1QWZYd3QrOG1hUDNDbXRlSm13L0RDeHBJZVBENGg2?=
	=?utf-8?B?ZjJEbkV3R2VLUXdqbnJYeHN6SjAxa3VIYXNBYVNQNVl5TnFmV1VpdmwvazQ5?=
	=?utf-8?B?K2RlMCtDWTBObzliazBmY3R4ak9EbGs5SzBmNjk4d0tMYjBvdjZjSkY2M0Vr?=
	=?utf-8?B?cDdXOXZVTnJIczBiMy9iVHV3ZzdERitoemxOZFpxM25MYVdCVzdmR0FISjRu?=
	=?utf-8?B?TGo0eTVaUklKYTR2b0RaaXZaV0lqWm1nYkdySXBYV3g5cTgvZ0Nxb285empU?=
	=?utf-8?B?bnBmREV6QWRpOVl6NW4wZDNvYzJjdEtJUk5LM3g0QXBjejFLSmVKTEgxN2I1?=
	=?utf-8?B?aVdMa0VRT2QwTVBVWi9IS2dkZFdJYk9HQjdDNVJTSEJ2S1VXa20yL2owQmxO?=
	=?utf-8?B?WTRKeWtMcXVNSy9ZbU1CZG40NU1icGgzc2tFekFER2MrKy9VNGNMaWZxcWlm?=
	=?utf-8?B?SGRnaFVrVEE5NW9PVDVkaDBkYUxFQ2ZFZWVnM0wwT3YzOUJpSEhyakhFWFpk?=
	=?utf-8?B?dStvTUlMRXdoL3Q1bUFBa2lTSnlOUFdOaXlJanRsY3l5OERVM01pdHh2QUJa?=
	=?utf-8?B?SlFSaVZ0WWVVbUxDVXZnNVJ6VTlGUWVzS1luWGkxTUVQSGVSR3Z5SjhQbktz?=
	=?utf-8?B?WEtrQnFFNGRjR3F1VDk2eFJxTUMxUUlkeVZQTnNiRHNqclhHRyt5NVdGd3B3?=
	=?utf-8?B?R1pxMTRVbk1IQWZKd0E4cVdyYStVV1M2WC80MytLNCtFR2VwVjJ0djRFaG5z?=
	=?utf-8?B?dVZhZFg2Tno5UWJCWGE5WXRNeSt0aTlUS3dkYms0R0Ewc2VsaFF6NTBuTVNE?=
	=?utf-8?B?N2UrSTR6aXhTVCtzZld3aDNTc0E1VTFoVkFBUDQvTm5FSjBnSmN6K29qK1I2?=
	=?utf-8?B?N3laUUlHL2pHMUtwYWNMNzhUai8xMFNTYkx4YitOckw0dEtVYnlvRU1qZGdW?=
	=?utf-8?B?SHhaVGVUVUtIQlc5RnIvUEdTS3pvUS9NdUViekQzcGh5NmxmUXZ6RVcyYnht?=
	=?utf-8?B?MHJoUHNEWTF4MjRCWmRJWVhwZy8rRzlUVUM1ZllBbE5jdXRucEZDSjNDRmY2?=
	=?utf-8?B?MU8yWWVnYVdQRFo1K2t6eTJhS3ZwbXJXcEdaVDlJYVpzN0lRaHN5ZGlRZVlu?=
	=?utf-8?B?SnVIQmwycDhoZDZLVVJFQmRNS1p5SEx2RW4wZURSMFRtbEhnNGpWOEp6Y2J1?=
	=?utf-8?B?REdzYkxQblRaUmlXZ2o4Z1hWdVNrZmFWdFlFVllBektYY1M5Y3FubXB1elBi?=
	=?utf-8?B?K0g5OVIyQXR3K3NJYTlwaTRyVkIwV1pLd1lBNEUwL3ZXTE5mQ1RtRStkWDdw?=
	=?utf-8?B?VDRxZXExZDAyelZDVHluSG9DVEo1aUFRQ1ZNOWsxQVhTYkRGVC9RYmVqRWpy?=
	=?utf-8?B?N1hBelYvWGFsdDJPMEkyc0l3RzJJOEFvdS9pbXNKcjF5TnVIdGZ4UEJMcEhK?=
	=?utf-8?B?VGxoMVdGTUcrM3UxN0l5ay9LdkhtN1A1bVMvMFA5ajc0UWJJZ2xFZ3RoZHR2?=
	=?utf-8?Q?79RZaYpwCpGEv709t6G?=
X-Forefront-PRVS: 0340850FCD
X-Forefront-Antispam-Report: SFV:NSPM;
	SFS:(10009020)(4630300001)(6009001)(39400400002)(39410400002)(39850400002)(39450400003)(39840400002)(39860400002)(9686003)(7406005)(305945005)(110136004)(38730400002)(83506001)(86362001)(5660300001)(81166006)(7416002)(103116003)(55016002)(8676002)(54906002)(25786009)(53936002)(4326008)(1076002)(230700001)(53416004)(42186005)(72206003)(76176999)(4001350100001)(2906002)(54356999)(6506006)(6116002)(6666003)(66066001)(3846002)(7736002)(33646002)(50986999)(2950100002)(47776003)(50466002)(23676002)(189998001)(478600001)(921003)(1121003);
	DIR:OUT; SFP:1101; SCL:1; SRVR:MWHPR12MB1151;
	H:tlendack-t1.amdoffice.net; FPR:; SPF:None; MLV:sfv; LANG:en;
X-Microsoft-Exchange-Diagnostics: =?utf-8?B?MTtNV0hQUjEyTUIxMTUxOzIzOklxMytLZ0lIejhNRTFXOUVrQ00zQWdwOXY5?=
	=?utf-8?B?dDhkZmdNdnVkZUN4Vk5BUEsyR3gzSnoxc1VlTVp1WHd4dVkzN2RBM3hpYkVH?=
	=?utf-8?B?by96T1o2S0hMQStPZHF2MG5TVVA0bEdZKzg2d3BvazJFSnpPeldMUlFscE5N?=
	=?utf-8?B?aml2UFduMzA4bkdhVDYwaFZNSmo1MmVac3hYeFNkQ3JHZkRsMmFTMjdEU09E?=
	=?utf-8?B?YjRjazZUelFoNk8ybW1XSlFUSHhJeStnSHpLcVJSQ2s4eXJ1ekc3WTVyMWJD?=
	=?utf-8?B?Y3poWnUwdzB2RVNWZGJ5aVlWLzB1cER1ZlhkQXlMOGxxUkQ4blkrOWZEa2Vp?=
	=?utf-8?B?TFp3dlNmT21CamNMTTVZd3N1ZTF6L1h2RExSS1h1azlsK2lzQXY0SEE2eGJr?=
	=?utf-8?B?ajA2WC83QUYxbkQyODAvb1JKNDQ5d3FWS0V0bzAvL2IyT1gyVFlOM0pET0s0?=
	=?utf-8?B?OUp4Q3lENzVpUG5IWFV5RFFyQmQ4bTlaUk5WMjlOOW9wODRZV2lsb01iZGR3?=
	=?utf-8?B?bWhHdm54Z0NEbmlIR1VVMUp0WURlU0pCUG9teXdZUVF1MmhwbjB6ejVsaUts?=
	=?utf-8?B?L2hNTFl6TVBqLzhlbTdSajU3bk55L295c3N1eWUyekxqVmlUK1FDWlVPWEJZ?=
	=?utf-8?B?ZUlVM3p2ZVp5ZXJYZVhHMWJnUGV4L2NFU3B2UW14Rzl6VHlzS2hBQ2VlU0lq?=
	=?utf-8?B?RzdyWXh1SVVCOXFWMmhKSktWRFR0MzF3eDRCc1NTSWIrNUxLdVl4YWFOS1Fy?=
	=?utf-8?B?eE5pYjNkUDFXZlJRek5ZQVp5aEVWTFBDSTBCV1p2KzdFd2YyN2RGL0Ewaktn?=
	=?utf-8?B?L2hMVHdDOSsvNXRDdVd3ZVNTU3VjRVdldzNHQzlVVTd5a0szZTJUUnhYdUIr?=
	=?utf-8?B?b3lrY3JxOC9PSTMvVkpoZTNZelRZeG9oeks0cngzcmF2Z1VrdnhsK2pSVmdv?=
	=?utf-8?B?Ky9Tc0dkc2hsdXFDcElpc2F4K0s4R3JVaWQ1WUtkMGZmb2ZubGxrV051SkZY?=
	=?utf-8?B?YXV6Um0zK1NaYzlaeDhqbHVaNkx1aWhpenNWTmM2TTliNHFqcTgyL1gzTWg3?=
	=?utf-8?B?NHdMbGovODlmalBVbkR3USs2WjByR1NrSXpWVHRTQlgvcEY5LzlVMmFWUll0?=
	=?utf-8?B?dFMxMTljdForYWNTbXpLWElXZmU2akRJWUNLVWFxUmhXZ2lySWFZbEdsZmJt?=
	=?utf-8?B?WURYSm1vREhpQUJjUTUwb1JwOEJCekM3L2ZqU080U1lLZWVFT3JCYTJlR1pR?=
	=?utf-8?B?VHpMZXlwRVBqYlAzMDJyTVJRdTRha01maDFOaHpxOWhLRFhnTDc4V1I0bm1M?=
	=?utf-8?B?bDVTZndnMHRkZkZ0NmFkNGlmcjJ3R0cwMHJNdFVteVBLakNTV2hNaFB1a2JE?=
	=?utf-8?B?L0V0SStoVHZvaTRNdlQyaE9IenJIb3NYc3lXRlluQzQxMTlKSVZvKzJEMTFJ?=
	=?utf-8?B?WGk2TTE0amxSWUp4T1pQcGJOWS9aeWVRRGRnaXZteVM3M053b3IvSzJ2MXhR?=
	=?utf-8?B?Qkc2L0RiMkZGa2ZBZ0xURTRxSzlhaDRid215WExpdjFYNGUyN0RjMmM3alhw?=
	=?utf-8?B?LzJUTjBjTzcrSlBnWitJTVRUdHh5WHNJMFRVWVFINjFJb0p1Z2xlQzdGR2lv?=
	=?utf-8?B?ejJiaTFJWitBUjJHenZnamVaVlJ3eGtuZ24xQmJqYmFGUG1TVWVuTWR3PT0=?=
X-Microsoft-Exchange-Diagnostics: =?utf-8?B?MTtNV0hQUjEyTUIxMTUxOzY6UjNuWnFORFIvK01NaUpnRUxIUXBWNkxqSHhD?=
	=?utf-8?B?bFF3aGdsZ2pVdi84WUE4VEZzNnpnUjNnN21sSWxuL242WlBIR0M3SjhPMlBw?=
	=?utf-8?B?K0dBWWhOT0ZPSlRDMkp2Uk9iNEhWWDJHZU5IanhoY25rczlxTEdNQ1hrVU5F?=
	=?utf-8?B?NHlrRWxuVDNLYTV3MkJOaDIrclhyU1V0UzBNOFlmT0JseGRaRTRYL3ozTUFz?=
	=?utf-8?B?ckV5SVZ3bm9TUnp0KzBKOWp4NkZLcEpxbFk5bWE4Q3pXbzRiLzZxNHQ0RHkr?=
	=?utf-8?B?dk5WK0VIWUZLZ1c5NVowVVFtVzlnUkNFZWE1bHVoRVlINnJpN2FPNmRmQlk2?=
	=?utf-8?B?azhKeTBWM1VCNFA0M3hJUkt4cDErQXl0Qjl3YkVmVnh3a3pTS1F1K1lyd1Yv?=
	=?utf-8?B?K2RrNDJyZ0dFU283aW9aM1RPRkVWNHRnOFE1MkJ4VWlPVWJtRjM5Q1J3ekNk?=
	=?utf-8?B?OWsySjFMWUZlTmw4eHN2ZFY5cER1eER5dC91L1lmRUNvSjdOdEZiSncvTmg0?=
	=?utf-8?B?OEo1bGQ5UlhHN2JBbkRSbW1na090ZndpT2pSNHJyMjkzaXRXVVUrMkNJYk9Y?=
	=?utf-8?B?SVhaZTFPR09FSzBOQkdoMk1YVjB0SWZIekJZK2pmNXBsSTFmVmNBclNqZ2cz?=
	=?utf-8?B?ZlhNSTlldy9DRGxURnFlNkVOdFVUOUxlaCtJcGpCRHpwdGZlU1l6cDZFdzBI?=
	=?utf-8?B?ODFJQm1IMVNaWG5KRm9xWUV2c01vK1RaalJIWnpYMnpxaDc0SzRMZnJ4ZUhM?=
	=?utf-8?B?cDhXVmFzaDJpK3dMR2MzWkdHVEtuVXZJdVVmZnkyMGpmNGVkU2ZXZTU0UXJl?=
	=?utf-8?B?a00vZHJYRHZ1a080am1rRHk4alhKaEdodm5LdmN3WFVLOGlsZ1dWcFo3NWNV?=
	=?utf-8?B?NWw3bTlJV0NQOXpIb1VqRDNSbmJ5OG5lSmdEWkx3eDloVFRZckFsNU5lc0FI?=
	=?utf-8?B?cXBlU2tLY1hESFJPK1lIb2tzTHNhRXdTTGlQMTdNMGd2MkRTajdMYmplUEtF?=
	=?utf-8?B?VjdOZXV4N2dyZjlQVm9kZVV6OXpiSml2N2RUQ09ZWlRpVlFFajZQcVQzenFH?=
	=?utf-8?B?WGtUSmhMZnNqRjkxL2RWNTUyMzB5bCtMOFhET29penZQUkFtTzF0ck1jVEtQ?=
	=?utf-8?B?WTd5TnI3Yi9ZRzdBSzJZQU1aRndXVDhVZkMzVlZ5T1owSVFZTFB1OUdYY3NF?=
	=?utf-8?B?ZGRLS3FGQTVtWllQUGxTTE5NaVdLTEt0RVRnK1pkbzVYdXJpMVg1OXRTeWRk?=
	=?utf-8?B?alVEOGFoNU9ZM0lCem9GM2ZlaHNUa3JIc0ZIdGNhTjBtVUlzZU1sakFIcWRC?=
	=?utf-8?B?cnVmT053SjQ1R0d6bHFMejhCTGFiWEUwU1BiaGpQblZESHloYlo4N05IUmdZ?=
	=?utf-8?Q?nAMaRda?=
X-Microsoft-Exchange-Diagnostics: 1; MWHPR12MB1151;
	5:eMTiSjfHhIvkAvgll271wiM23QVDCq+NhktxfxTiOV4Sr2accM22xW7k5tX8wY0Hh/ksL9qQ/aiEGz1uVrsCxATUQy3/RnR47upHjSAzr/gLl7R65os1Xm4s3Skg11upR7O2XjeKHRWvpejfjR7jI1m2+S4lLnO/0W0iHc/cAjSvPkZa9Ti+MX9XXIjIlUvEuL/9NczwSHzssaP3tW7b0pQ31Fu8mtxbA9ccZYXrwIJ3kJ8amRb5zSisVGEERA+eImgXrONEmnK17nLM/oHKNS1yAMZPGn3fRpYpZWdyiGJCSiyjYdRpNTinsbzXLEt4z2lLDC4YwP3/Twew88IPCgdsPwOunzMhTV61lGBbEooWvEvy2+8W3lUmDd3Gm+INdL7pifzANV88G+x0Sj2Os94DV2VP4W5bgRi4BeLC6Nlm3CHslXaR3dALsEdkPl5peRYND1GKtv+py5xH3zhrQ+QuNVhVnXVKllg+XBD5fAxcDbudfdZzd/oj9TUOhRJD;
	24:7NX5kuF8lA9eDw4mqwzf3uKYG7uOFZzW390MjH6nIab6giZgYlz35w/tsByoeSTrLQ2mLEpKBxa+pYWGxXxKInGrRGaQrK1CW7JMCgK3TmM=
SpamDiagnosticOutput: 1:99
SpamDiagnosticMetadata: NSPM
X-Microsoft-Exchange-Diagnostics: 1; MWHPR12MB1151;
	7:L4kDiTc49L7ItcKq0R2YvL7cL8BftLGSyVGfWCOJfEJqL6rAlOhT/SQHAfgQqOTeeCcotp2ROjaAGg2nhrPD4OnYrPPa2sHe8s1Lm0IwuiIDRFiFKCX1SSy8F5h2lM59VSYEQDApuM/zNkiP4wCA9PHklcdzHrS7Dv4h7+L40ocXLD7GF7Es7OmLRlzqw7KMckC2tL1D1kb9bsBXIUZiZhG6QQ5av6m6yR2dui7vcP3HejKjyjt3wFa99BeFhxgyr2m2Hm/YSySXGWQg+N5yEgoFmnp6AQ7gxyV5nsVVNfjR4ntUpJ6QtoCM5idfHeTJKpVkzyj0hqhEOelcg370dNcFky/VIOEYKSkxRrSlF8dnzdqTibHJ/Sc78MIp2o0yn1lh3WkP38fgCFRbUnDVf8oveKOWPcHlwUykxs+N/Ms3h/g+IqrfuvfOTgIESgm+9FRVvQZPUEA7l1RK4qQnRldrrmuiSSF2yRLwL9eKpy0z22Y7kGMNVIBtVWyBEGH2fjIjPnlrsJfE7oyuk46gNmJx3Vnjcb117ZiErnYI6+KsP6GuHjK6QD0bJueULrcWKFps1ilMvazB1mIHLyUhcXEpbZV75MmAPkTZpAsuYtAYj4XsWx68cIIU421UAmqi+iHtBNv+159RFbpGWgvCgCYmibb8KIKUevS8HCXdQbulT/275gtJ4D9178JPp1OMVPA4jNE+HcvA2zhIO/3X7z9t0DK+4Yf/nH68ffHOb8L+JU0lW6tUuaKsaqeW8l/MGhIHDu4j/nryhuAb7XiPjhZBxe9f0U6qHHH+Y/6lnoI=
X-Microsoft-Exchange-Diagnostics: 1; MWHPR12MB1151;
	20:hCYEFpCjUm9U2ckRkl+3Jwu1sBFkMXjT1yuiQsDSe7qRedfb5zrFPqU+likRQY6ZunF13NzMRX7H9OezvJX9o56/BoN+xYdNRww6eo/sTkobszaz9IJl3lDDT7oGLCVb21sEKbdCcESVj9d5zxSo3vJsWtlM3xwdVdpNEHjc/+EHjNzOZ95gCa/qGVqbe9uaJv1apzwbUNwI2Y/77G6Z2vjV3ORQ23oAljq8RGcZstReg7k3KuHLngq0FlRPUOJ4
X-OriginatorOrg: amd.com
X-MS-Exchange-CrossTenant-OriginalArrivalTime: 16 Jun 2017 18:56:22.5451
	(UTC)
X-MS-Exchange-CrossTenant-FromEntityHeader: Hosted
X-MS-Exchange-Transport-CrossTenantHeadersStamped: MWHPR12MB1151
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=80801">Tom Lendacky</a> - June 16, 2017, 6:56 p.m.</div>
<pre class="content">
Add the support to encrypt the kernel in-place. This is done by creating
new page mappings for the kernel - a decrypted write-protected mapping
and an encrypted mapping. The kernel is encrypted by copying it through
a temporary buffer.
<span class="signed-off-by">
Signed-off-by: Tom Lendacky &lt;thomas.lendacky@amd.com&gt;</span>
---
 arch/x86/include/asm/mem_encrypt.h |    6 +
 arch/x86/mm/Makefile               |    2 
 arch/x86/mm/mem_encrypt.c          |  314 ++++++++++++++++++++++++++++++++++++
 arch/x86/mm/mem_encrypt_boot.S     |  150 +++++++++++++++++
 4 files changed, 472 insertions(+)
 create mode 100644 arch/x86/mm/mem_encrypt_boot.S
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=7500">Borislav Petkov</a> - June 23, 2017, 10 a.m.</div>
<pre class="content">
On Fri, Jun 16, 2017 at 01:56:19PM -0500, Tom Lendacky wrote:
<span class="quote">&gt; Add the support to encrypt the kernel in-place. This is done by creating</span>
<span class="quote">&gt; new page mappings for the kernel - a decrypted write-protected mapping</span>
<span class="quote">&gt; and an encrypted mapping. The kernel is encrypted by copying it through</span>
<span class="quote">&gt; a temporary buffer.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Signed-off-by: Tom Lendacky &lt;thomas.lendacky@amd.com&gt;</span>
<span class="quote">&gt; ---</span>
<span class="quote">&gt;  arch/x86/include/asm/mem_encrypt.h |    6 +</span>
<span class="quote">&gt;  arch/x86/mm/Makefile               |    2 </span>
<span class="quote">&gt;  arch/x86/mm/mem_encrypt.c          |  314 ++++++++++++++++++++++++++++++++++++</span>
<span class="quote">&gt;  arch/x86/mm/mem_encrypt_boot.S     |  150 +++++++++++++++++</span>
<span class="quote">&gt;  4 files changed, 472 insertions(+)</span>
<span class="quote">&gt;  create mode 100644 arch/x86/mm/mem_encrypt_boot.S</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; diff --git a/arch/x86/include/asm/mem_encrypt.h b/arch/x86/include/asm/mem_encrypt.h</span>
<span class="quote">&gt; index af835cf..7da6de3 100644</span>
<span class="quote">&gt; --- a/arch/x86/include/asm/mem_encrypt.h</span>
<span class="quote">&gt; +++ b/arch/x86/include/asm/mem_encrypt.h</span>
<span class="quote">&gt; @@ -21,6 +21,12 @@</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  extern unsigned long sme_me_mask;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; +void sme_encrypt_execute(unsigned long encrypted_kernel_vaddr,</span>
<span class="quote">&gt; +			 unsigned long decrypted_kernel_vaddr,</span>
<span class="quote">&gt; +			 unsigned long kernel_len,</span>
<span class="quote">&gt; +			 unsigned long encryption_wa,</span>
<span class="quote">&gt; +			 unsigned long encryption_pgd);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt;  void __init sme_early_encrypt(resource_size_t paddr,</span>
<span class="quote">&gt;  			      unsigned long size);</span>
<span class="quote">&gt;  void __init sme_early_decrypt(resource_size_t paddr,</span>
<span class="quote">&gt; diff --git a/arch/x86/mm/Makefile b/arch/x86/mm/Makefile</span>
<span class="quote">&gt; index 9e13841..0633142 100644</span>
<span class="quote">&gt; --- a/arch/x86/mm/Makefile</span>
<span class="quote">&gt; +++ b/arch/x86/mm/Makefile</span>
<span class="quote">&gt; @@ -38,3 +38,5 @@ obj-$(CONFIG_NUMA_EMU)		+= numa_emulation.o</span>
<span class="quote">&gt;  obj-$(CONFIG_X86_INTEL_MPX)	+= mpx.o</span>
<span class="quote">&gt;  obj-$(CONFIG_X86_INTEL_MEMORY_PROTECTION_KEYS) += pkeys.o</span>
<span class="quote">&gt;  obj-$(CONFIG_RANDOMIZE_MEMORY) += kaslr.o</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +obj-$(CONFIG_AMD_MEM_ENCRYPT)	+= mem_encrypt_boot.o</span>
<span class="quote">&gt; diff --git a/arch/x86/mm/mem_encrypt.c b/arch/x86/mm/mem_encrypt.c</span>
<span class="quote">&gt; index 842c8a6..6e87662 100644</span>
<span class="quote">&gt; --- a/arch/x86/mm/mem_encrypt.c</span>
<span class="quote">&gt; +++ b/arch/x86/mm/mem_encrypt.c</span>
<span class="quote">&gt; @@ -24,6 +24,8 @@</span>
<span class="quote">&gt;  #include &lt;asm/setup.h&gt;</span>
<span class="quote">&gt;  #include &lt;asm/bootparam.h&gt;</span>
<span class="quote">&gt;  #include &lt;asm/set_memory.h&gt;</span>
<span class="quote">&gt; +#include &lt;asm/cacheflush.h&gt;</span>
<span class="quote">&gt; +#include &lt;asm/sections.h&gt;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  /*</span>
<span class="quote">&gt;   * Since SME related variables are set early in the boot process they must</span>
<span class="quote">&gt; @@ -209,8 +211,320 @@ void swiotlb_set_mem_attributes(void *vaddr, unsigned long size)</span>
<span class="quote">&gt;  	set_memory_decrypted((unsigned long)vaddr, size &gt;&gt; PAGE_SHIFT);</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; +static void __init sme_clear_pgd(pgd_t *pgd_base, unsigned long start,</span>
<span class="quote">&gt; +				 unsigned long end)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	unsigned long pgd_start, pgd_end, pgd_size;</span>
<span class="quote">&gt; +	pgd_t *pgd_p;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	pgd_start = start &amp; PGDIR_MASK;</span>
<span class="quote">&gt; +	pgd_end = end &amp; PGDIR_MASK;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	pgd_size = (((pgd_end - pgd_start) / PGDIR_SIZE) + 1);</span>
<span class="quote">&gt; +	pgd_size *= sizeof(pgd_t);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	pgd_p = pgd_base + pgd_index(start);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	memset(pgd_p, 0, pgd_size);</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +#ifndef CONFIG_X86_5LEVEL</span>
<span class="quote">&gt; +#define native_make_p4d(_x)	(p4d_t) { .pgd = native_make_pgd(_x) }</span>
<span class="quote">&gt; +#endif</span>

Huh, why isn&#39;t this in arch/x86/include/asm/pgtable_types.h in the #else
branch of #if CONFIG_PGTABLE_LEVELS &gt; 4 ?

Also

ERROR: Macros with complex values should be enclosed in parentheses
#105: FILE: arch/x86/mm/mem_encrypt.c:232:
+#define native_make_p4d(_x)    (p4d_t) { .pgd = native_make_pgd(_x) }

so why isn&#39;t it a function?
<span class="quote">
&gt; +</span>
<span class="quote">&gt; +#define PGD_FLAGS	_KERNPG_TABLE_NOENC</span>
<span class="quote">&gt; +#define P4D_FLAGS	_KERNPG_TABLE_NOENC</span>
<span class="quote">&gt; +#define PUD_FLAGS	_KERNPG_TABLE_NOENC</span>
<span class="quote">&gt; +#define PMD_FLAGS	(__PAGE_KERNEL_LARGE_EXEC &amp; ~_PAGE_GLOBAL)</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +static void __init *sme_populate_pgd(pgd_t *pgd_base, void *pgtable_area,</span>
<span class="quote">&gt; +				     unsigned long vaddr, pmdval_t pmd_val)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	pgd_t *pgd_p;</span>
<span class="quote">&gt; +	p4d_t *p4d_p;</span>
<span class="quote">&gt; +	pud_t *pud_p;</span>
<span class="quote">&gt; +	pmd_t *pmd_p;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	pgd_p = pgd_base + pgd_index(vaddr);</span>
<span class="quote">&gt; +	if (native_pgd_val(*pgd_p)) {</span>
<span class="quote">&gt; +		if (IS_ENABLED(CONFIG_X86_5LEVEL))</span>

Err, I don&#39;t understand: so this is a Kconfig symbol and when it is
enabled at build time, you do a 5level pagetable.

But you can&#39;t stick a 5level pagetable to a hardware which doesn&#39;t know
about it.

Or do you mean that p4d layer folding at runtime to happen? (I admit, I
haven&#39;t looked at that in detail.) But then I&#39;d hope that the generic
macros/functions would give you the ability to not care whether we have
a p4d or not and not add a whole bunch of ifdeffery to this code.

Hmmm.
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=80801">Tom Lendacky</a> - June 23, 2017, 5:44 p.m.</div>
<pre class="content">
On 6/23/2017 5:00 AM, Borislav Petkov wrote:
<span class="quote">&gt; On Fri, Jun 16, 2017 at 01:56:19PM -0500, Tom Lendacky wrote:</span>
<span class="quote">&gt;&gt; Add the support to encrypt the kernel in-place. This is done by creating</span>
<span class="quote">&gt;&gt; new page mappings for the kernel - a decrypted write-protected mapping</span>
<span class="quote">&gt;&gt; and an encrypted mapping. The kernel is encrypted by copying it through</span>
<span class="quote">&gt;&gt; a temporary buffer.</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; Signed-off-by: Tom Lendacky &lt;thomas.lendacky@amd.com&gt;</span>
<span class="quote">&gt;&gt; ---</span>
<span class="quote">&gt;&gt;   arch/x86/include/asm/mem_encrypt.h |    6 +</span>
<span class="quote">&gt;&gt;   arch/x86/mm/Makefile               |    2</span>
<span class="quote">&gt;&gt;   arch/x86/mm/mem_encrypt.c          |  314 ++++++++++++++++++++++++++++++++++++</span>
<span class="quote">&gt;&gt;   arch/x86/mm/mem_encrypt_boot.S     |  150 +++++++++++++++++</span>
<span class="quote">&gt;&gt;   4 files changed, 472 insertions(+)</span>
<span class="quote">&gt;&gt;   create mode 100644 arch/x86/mm/mem_encrypt_boot.S</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; diff --git a/arch/x86/include/asm/mem_encrypt.h b/arch/x86/include/asm/mem_encrypt.h</span>
<span class="quote">&gt;&gt; index af835cf..7da6de3 100644</span>
<span class="quote">&gt;&gt; --- a/arch/x86/include/asm/mem_encrypt.h</span>
<span class="quote">&gt;&gt; +++ b/arch/x86/include/asm/mem_encrypt.h</span>
<span class="quote">&gt;&gt; @@ -21,6 +21,12 @@</span>
<span class="quote">&gt;&gt;   </span>
<span class="quote">&gt;&gt;   extern unsigned long sme_me_mask;</span>
<span class="quote">&gt;&gt;   </span>
<span class="quote">&gt;&gt; +void sme_encrypt_execute(unsigned long encrypted_kernel_vaddr,</span>
<span class="quote">&gt;&gt; +			 unsigned long decrypted_kernel_vaddr,</span>
<span class="quote">&gt;&gt; +			 unsigned long kernel_len,</span>
<span class="quote">&gt;&gt; +			 unsigned long encryption_wa,</span>
<span class="quote">&gt;&gt; +			 unsigned long encryption_pgd);</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt;   void __init sme_early_encrypt(resource_size_t paddr,</span>
<span class="quote">&gt;&gt;   			      unsigned long size);</span>
<span class="quote">&gt;&gt;   void __init sme_early_decrypt(resource_size_t paddr,</span>
<span class="quote">&gt;&gt; diff --git a/arch/x86/mm/Makefile b/arch/x86/mm/Makefile</span>
<span class="quote">&gt;&gt; index 9e13841..0633142 100644</span>
<span class="quote">&gt;&gt; --- a/arch/x86/mm/Makefile</span>
<span class="quote">&gt;&gt; +++ b/arch/x86/mm/Makefile</span>
<span class="quote">&gt;&gt; @@ -38,3 +38,5 @@ obj-$(CONFIG_NUMA_EMU)		+= numa_emulation.o</span>
<span class="quote">&gt;&gt;   obj-$(CONFIG_X86_INTEL_MPX)	+= mpx.o</span>
<span class="quote">&gt;&gt;   obj-$(CONFIG_X86_INTEL_MEMORY_PROTECTION_KEYS) += pkeys.o</span>
<span class="quote">&gt;&gt;   obj-$(CONFIG_RANDOMIZE_MEMORY) += kaslr.o</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +obj-$(CONFIG_AMD_MEM_ENCRYPT)	+= mem_encrypt_boot.o</span>
<span class="quote">&gt;&gt; diff --git a/arch/x86/mm/mem_encrypt.c b/arch/x86/mm/mem_encrypt.c</span>
<span class="quote">&gt;&gt; index 842c8a6..6e87662 100644</span>
<span class="quote">&gt;&gt; --- a/arch/x86/mm/mem_encrypt.c</span>
<span class="quote">&gt;&gt; +++ b/arch/x86/mm/mem_encrypt.c</span>
<span class="quote">&gt;&gt; @@ -24,6 +24,8 @@</span>
<span class="quote">&gt;&gt;   #include &lt;asm/setup.h&gt;</span>
<span class="quote">&gt;&gt;   #include &lt;asm/bootparam.h&gt;</span>
<span class="quote">&gt;&gt;   #include &lt;asm/set_memory.h&gt;</span>
<span class="quote">&gt;&gt; +#include &lt;asm/cacheflush.h&gt;</span>
<span class="quote">&gt;&gt; +#include &lt;asm/sections.h&gt;</span>
<span class="quote">&gt;&gt;   </span>
<span class="quote">&gt;&gt;   /*</span>
<span class="quote">&gt;&gt;    * Since SME related variables are set early in the boot process they must</span>
<span class="quote">&gt;&gt; @@ -209,8 +211,320 @@ void swiotlb_set_mem_attributes(void *vaddr, unsigned long size)</span>
<span class="quote">&gt;&gt;   	set_memory_decrypted((unsigned long)vaddr, size &gt;&gt; PAGE_SHIFT);</span>
<span class="quote">&gt;&gt;   }</span>
<span class="quote">&gt;&gt;   </span>
<span class="quote">&gt;&gt; +static void __init sme_clear_pgd(pgd_t *pgd_base, unsigned long start,</span>
<span class="quote">&gt;&gt; +				 unsigned long end)</span>
<span class="quote">&gt;&gt; +{</span>
<span class="quote">&gt;&gt; +	unsigned long pgd_start, pgd_end, pgd_size;</span>
<span class="quote">&gt;&gt; +	pgd_t *pgd_p;</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +	pgd_start = start &amp; PGDIR_MASK;</span>
<span class="quote">&gt;&gt; +	pgd_end = end &amp; PGDIR_MASK;</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +	pgd_size = (((pgd_end - pgd_start) / PGDIR_SIZE) + 1);</span>
<span class="quote">&gt;&gt; +	pgd_size *= sizeof(pgd_t);</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +	pgd_p = pgd_base + pgd_index(start);</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +	memset(pgd_p, 0, pgd_size);</span>
<span class="quote">&gt;&gt; +}</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +#ifndef CONFIG_X86_5LEVEL</span>
<span class="quote">&gt;&gt; +#define native_make_p4d(_x)	(p4d_t) { .pgd = native_make_pgd(_x) }</span>
<span class="quote">&gt;&gt; +#endif</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Huh, why isn&#39;t this in arch/x86/include/asm/pgtable_types.h in the #else</span>
<span class="quote">&gt; branch of #if CONFIG_PGTABLE_LEVELS &gt; 4 ?</span>

Normally the __p4d() macro would be used and that would be ok whether
CONFIG_X86_5LEVEL is defined or not. But since __p4d() is part of the
paravirt ops path I have to use native_make_p4d(). I&#39;d be the only user
of the function and thought it would be best to localize it this way.
<span class="quote">
&gt; </span>
<span class="quote">&gt; Also</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; ERROR: Macros with complex values should be enclosed in parentheses</span>
<span class="quote">&gt; #105: FILE: arch/x86/mm/mem_encrypt.c:232:</span>
<span class="quote">&gt; +#define native_make_p4d(_x)    (p4d_t) { .pgd = native_make_pgd(_x) }</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; so why isn&#39;t it a function?</span>

I can define it as an inline function.
<span class="quote">
&gt; </span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +#define PGD_FLAGS	_KERNPG_TABLE_NOENC</span>
<span class="quote">&gt;&gt; +#define P4D_FLAGS	_KERNPG_TABLE_NOENC</span>
<span class="quote">&gt;&gt; +#define PUD_FLAGS	_KERNPG_TABLE_NOENC</span>
<span class="quote">&gt;&gt; +#define PMD_FLAGS	(__PAGE_KERNEL_LARGE_EXEC &amp; ~_PAGE_GLOBAL)</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +static void __init *sme_populate_pgd(pgd_t *pgd_base, void *pgtable_area,</span>
<span class="quote">&gt;&gt; +				     unsigned long vaddr, pmdval_t pmd_val)</span>
<span class="quote">&gt;&gt; +{</span>
<span class="quote">&gt;&gt; +	pgd_t *pgd_p;</span>
<span class="quote">&gt;&gt; +	p4d_t *p4d_p;</span>
<span class="quote">&gt;&gt; +	pud_t *pud_p;</span>
<span class="quote">&gt;&gt; +	pmd_t *pmd_p;</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +	pgd_p = pgd_base + pgd_index(vaddr);</span>
<span class="quote">&gt;&gt; +	if (native_pgd_val(*pgd_p)) {</span>
<span class="quote">&gt;&gt; +		if (IS_ENABLED(CONFIG_X86_5LEVEL))</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Err, I don&#39;t understand: so this is a Kconfig symbol and when it is</span>
<span class="quote">&gt; enabled at build time, you do a 5level pagetable.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; But you can&#39;t stick a 5level pagetable to a hardware which doesn&#39;t know</span>
<span class="quote">&gt; about it.</span>

True, 5-level will only be turned on for specific hardware which is why
I originally had this as only 4-level pagetables. But in a comment from
you back on the v5 version you said it needed to support 5-level. I
guess we should have discussed this more, but I also thought that should
our hardware ever support 5-level paging in the future then this would
be good to go.
<span class="quote">
&gt; </span>
<span class="quote">&gt; Or do you mean that p4d layer folding at runtime to happen? (I admit, I</span>
<span class="quote">&gt; haven&#39;t looked at that in detail.) But then I&#39;d hope that the generic</span>
<span class="quote">&gt; macros/functions would give you the ability to not care whether we have</span>
<span class="quote">&gt; a p4d or not and not add a whole bunch of ifdeffery to this code.</span>

The macros work great if you are not running identity mapped. You could
use p*d_offset() to move easily through the tables, but those functions
use __va() to generate table virtual addresses. I&#39;ve seen where
boot/compressed/pagetable.c #defines __va() to work with identity mapped
pages but that would only work if I create a separate file just for this
function.

Given when this occurs it&#39;s very similar to what __startup_64() does in
regards to the IS_ENABLED(CONFIG_X86_5LEVEL) checks.

Thanks,
Tom
<span class="quote">
&gt; </span>
<span class="quote">&gt; Hmmm.</span>
<span class="quote">&gt;</span>
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=7500">Borislav Petkov</a> - June 26, 2017, 3:45 p.m.</div>
<pre class="content">
On Fri, Jun 23, 2017 at 12:44:46PM -0500, Tom Lendacky wrote:
<span class="quote">&gt; Normally the __p4d() macro would be used and that would be ok whether</span>
<span class="quote">&gt; CONFIG_X86_5LEVEL is defined or not. But since __p4d() is part of the</span>
<span class="quote">&gt; paravirt ops path I have to use native_make_p4d().</span>

So __p4d is in !CONFIG_PARAVIRT path.

Regardless, we use the native_* variants in generic code to mean, not
paravirt. Just define it in a separate patch like the rest of the p4*
machinery and use it in your code. Sooner or later someone else will
need it.
<span class="quote">
&gt; True, 5-level will only be turned on for specific hardware which is why</span>
<span class="quote">&gt; I originally had this as only 4-level pagetables. But in a comment from</span>
<span class="quote">&gt; you back on the v5 version you said it needed to support 5-level. I</span>
<span class="quote">&gt; guess we should have discussed this more,</span>

AFAIR, I said something along the lines of &quot;what about 5-level page
tables?&quot; and whether we care.
<span class="quote">
&gt; but I also thought that should our hardware ever support 5-level</span>
<span class="quote">&gt; paging in the future then this would be good to go.</span>

There it is :-)
<span class="quote">
&gt; The macros work great if you are not running identity mapped. You could</span>
<span class="quote">&gt; use p*d_offset() to move easily through the tables, but those functions</span>
<span class="quote">&gt; use __va() to generate table virtual addresses. I&#39;ve seen where</span>
<span class="quote">&gt; boot/compressed/pagetable.c #defines __va() to work with identity mapped</span>
<span class="quote">&gt; pages but that would only work if I create a separate file just for this</span>
<span class="quote">&gt; function.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Given when this occurs it&#39;s very similar to what __startup_64() does in</span>
<span class="quote">&gt; regards to the IS_ENABLED(CONFIG_X86_5LEVEL) checks.</span>

Ok.
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=80801">Tom Lendacky</a> - June 26, 2017, 4:34 p.m.</div>
<pre class="content">
On 6/26/2017 10:45 AM, Borislav Petkov wrote:
<span class="quote">&gt; On Fri, Jun 23, 2017 at 12:44:46PM -0500, Tom Lendacky wrote:</span>
<span class="quote">&gt;&gt; Normally the __p4d() macro would be used and that would be ok whether</span>
<span class="quote">&gt;&gt; CONFIG_X86_5LEVEL is defined or not. But since __p4d() is part of the</span>
<span class="quote">&gt;&gt; paravirt ops path I have to use native_make_p4d().</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; So __p4d is in !CONFIG_PARAVIRT path.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Regardless, we use the native_* variants in generic code to mean, not</span>
<span class="quote">&gt; paravirt. Just define it in a separate patch like the rest of the p4*</span>
<span class="quote">&gt; machinery and use it in your code. Sooner or later someone else will</span>
<span class="quote">&gt; need it.</span>

Ok, will do.
<span class="quote">
&gt; </span>
<span class="quote">&gt;&gt; True, 5-level will only be turned on for specific hardware which is why</span>
<span class="quote">&gt;&gt; I originally had this as only 4-level pagetables. But in a comment from</span>
<span class="quote">&gt;&gt; you back on the v5 version you said it needed to support 5-level. I</span>
<span class="quote">&gt;&gt; guess we should have discussed this more,</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; AFAIR, I said something along the lines of &quot;what about 5-level page</span>
<span class="quote">&gt; tables?&quot; and whether we care.</span>

My bad, I took the meaning of that question the wrong way then.

Thanks,
Tom
<span class="quote">
&gt; </span>
<span class="quote">&gt;&gt; but I also thought that should our hardware ever support 5-level</span>
<span class="quote">&gt;&gt; paging in the future then this would be good to go.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; There it is :-)</span>
<span class="quote">&gt; </span>
<span class="quote">&gt;&gt; The macros work great if you are not running identity mapped. You could</span>
<span class="quote">&gt;&gt; use p*d_offset() to move easily through the tables, but those functions</span>
<span class="quote">&gt;&gt; use __va() to generate table virtual addresses. I&#39;ve seen where</span>
<span class="quote">&gt;&gt; boot/compressed/pagetable.c #defines __va() to work with identity mapped</span>
<span class="quote">&gt;&gt; pages but that would only work if I create a separate file just for this</span>
<span class="quote">&gt;&gt; function.</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; Given when this occurs it&#39;s very similar to what __startup_64() does in</span>
<span class="quote">&gt;&gt; regards to the IS_ENABLED(CONFIG_X86_5LEVEL) checks.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Ok.</span>
<span class="quote">&gt;</span>
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/arch/x86/include/asm/mem_encrypt.h b/arch/x86/include/asm/mem_encrypt.h</span>
<span class="p_header">index af835cf..7da6de3 100644</span>
<span class="p_header">--- a/arch/x86/include/asm/mem_encrypt.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/mem_encrypt.h</span>
<span class="p_chunk">@@ -21,6 +21,12 @@</span> <span class="p_context"></span>
 
 extern unsigned long sme_me_mask;
 
<span class="p_add">+void sme_encrypt_execute(unsigned long encrypted_kernel_vaddr,</span>
<span class="p_add">+			 unsigned long decrypted_kernel_vaddr,</span>
<span class="p_add">+			 unsigned long kernel_len,</span>
<span class="p_add">+			 unsigned long encryption_wa,</span>
<span class="p_add">+			 unsigned long encryption_pgd);</span>
<span class="p_add">+</span>
 void __init sme_early_encrypt(resource_size_t paddr,
 			      unsigned long size);
 void __init sme_early_decrypt(resource_size_t paddr,
<span class="p_header">diff --git a/arch/x86/mm/Makefile b/arch/x86/mm/Makefile</span>
<span class="p_header">index 9e13841..0633142 100644</span>
<span class="p_header">--- a/arch/x86/mm/Makefile</span>
<span class="p_header">+++ b/arch/x86/mm/Makefile</span>
<span class="p_chunk">@@ -38,3 +38,5 @@</span> <span class="p_context"> obj-$(CONFIG_NUMA_EMU)		+= numa_emulation.o</span>
 obj-$(CONFIG_X86_INTEL_MPX)	+= mpx.o
 obj-$(CONFIG_X86_INTEL_MEMORY_PROTECTION_KEYS) += pkeys.o
 obj-$(CONFIG_RANDOMIZE_MEMORY) += kaslr.o
<span class="p_add">+</span>
<span class="p_add">+obj-$(CONFIG_AMD_MEM_ENCRYPT)	+= mem_encrypt_boot.o</span>
<span class="p_header">diff --git a/arch/x86/mm/mem_encrypt.c b/arch/x86/mm/mem_encrypt.c</span>
<span class="p_header">index 842c8a6..6e87662 100644</span>
<span class="p_header">--- a/arch/x86/mm/mem_encrypt.c</span>
<span class="p_header">+++ b/arch/x86/mm/mem_encrypt.c</span>
<span class="p_chunk">@@ -24,6 +24,8 @@</span> <span class="p_context"></span>
 #include &lt;asm/setup.h&gt;
 #include &lt;asm/bootparam.h&gt;
 #include &lt;asm/set_memory.h&gt;
<span class="p_add">+#include &lt;asm/cacheflush.h&gt;</span>
<span class="p_add">+#include &lt;asm/sections.h&gt;</span>
 
 /*
  * Since SME related variables are set early in the boot process they must
<span class="p_chunk">@@ -209,8 +211,320 @@</span> <span class="p_context"> void swiotlb_set_mem_attributes(void *vaddr, unsigned long size)</span>
 	set_memory_decrypted((unsigned long)vaddr, size &gt;&gt; PAGE_SHIFT);
 }
 
<span class="p_add">+static void __init sme_clear_pgd(pgd_t *pgd_base, unsigned long start,</span>
<span class="p_add">+				 unsigned long end)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long pgd_start, pgd_end, pgd_size;</span>
<span class="p_add">+	pgd_t *pgd_p;</span>
<span class="p_add">+</span>
<span class="p_add">+	pgd_start = start &amp; PGDIR_MASK;</span>
<span class="p_add">+	pgd_end = end &amp; PGDIR_MASK;</span>
<span class="p_add">+</span>
<span class="p_add">+	pgd_size = (((pgd_end - pgd_start) / PGDIR_SIZE) + 1);</span>
<span class="p_add">+	pgd_size *= sizeof(pgd_t);</span>
<span class="p_add">+</span>
<span class="p_add">+	pgd_p = pgd_base + pgd_index(start);</span>
<span class="p_add">+</span>
<span class="p_add">+	memset(pgd_p, 0, pgd_size);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+#ifndef CONFIG_X86_5LEVEL</span>
<span class="p_add">+#define native_make_p4d(_x)	(p4d_t) { .pgd = native_make_pgd(_x) }</span>
<span class="p_add">+#endif</span>
<span class="p_add">+</span>
<span class="p_add">+#define PGD_FLAGS	_KERNPG_TABLE_NOENC</span>
<span class="p_add">+#define P4D_FLAGS	_KERNPG_TABLE_NOENC</span>
<span class="p_add">+#define PUD_FLAGS	_KERNPG_TABLE_NOENC</span>
<span class="p_add">+#define PMD_FLAGS	(__PAGE_KERNEL_LARGE_EXEC &amp; ~_PAGE_GLOBAL)</span>
<span class="p_add">+</span>
<span class="p_add">+static void __init *sme_populate_pgd(pgd_t *pgd_base, void *pgtable_area,</span>
<span class="p_add">+				     unsigned long vaddr, pmdval_t pmd_val)</span>
<span class="p_add">+{</span>
<span class="p_add">+	pgd_t *pgd_p;</span>
<span class="p_add">+	p4d_t *p4d_p;</span>
<span class="p_add">+	pud_t *pud_p;</span>
<span class="p_add">+	pmd_t *pmd_p;</span>
<span class="p_add">+</span>
<span class="p_add">+	pgd_p = pgd_base + pgd_index(vaddr);</span>
<span class="p_add">+	if (native_pgd_val(*pgd_p)) {</span>
<span class="p_add">+		if (IS_ENABLED(CONFIG_X86_5LEVEL))</span>
<span class="p_add">+			p4d_p = (p4d_t *)(native_pgd_val(*pgd_p) &amp; ~PTE_FLAGS_MASK);</span>
<span class="p_add">+		else</span>
<span class="p_add">+			pud_p = (pud_t *)(native_pgd_val(*pgd_p) &amp; ~PTE_FLAGS_MASK);</span>
<span class="p_add">+	} else {</span>
<span class="p_add">+		pgd_t pgd;</span>
<span class="p_add">+</span>
<span class="p_add">+		if (IS_ENABLED(CONFIG_X86_5LEVEL)) {</span>
<span class="p_add">+			p4d_p = pgtable_area;</span>
<span class="p_add">+			memset(p4d_p, 0, sizeof(*p4d_p) * PTRS_PER_P4D);</span>
<span class="p_add">+			pgtable_area += sizeof(*p4d_p) * PTRS_PER_P4D;</span>
<span class="p_add">+</span>
<span class="p_add">+			pgd = native_make_pgd((pgdval_t)p4d_p + PGD_FLAGS);</span>
<span class="p_add">+		} else {</span>
<span class="p_add">+			pud_p = pgtable_area;</span>
<span class="p_add">+			memset(pud_p, 0, sizeof(*pud_p) * PTRS_PER_PUD);</span>
<span class="p_add">+			pgtable_area += sizeof(*pud_p) * PTRS_PER_PUD;</span>
<span class="p_add">+</span>
<span class="p_add">+			pgd = native_make_pgd((pgdval_t)pud_p + PGD_FLAGS);</span>
<span class="p_add">+		}</span>
<span class="p_add">+		native_set_pgd(pgd_p, pgd);</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	if (IS_ENABLED(CONFIG_X86_5LEVEL)) {</span>
<span class="p_add">+		p4d_p += p4d_index(vaddr);</span>
<span class="p_add">+		if (native_p4d_val(*p4d_p)) {</span>
<span class="p_add">+			pud_p = (pud_t *)(native_p4d_val(*p4d_p) &amp; ~PTE_FLAGS_MASK);</span>
<span class="p_add">+		} else {</span>
<span class="p_add">+			p4d_t p4d;</span>
<span class="p_add">+</span>
<span class="p_add">+			pud_p = pgtable_area;</span>
<span class="p_add">+			memset(pud_p, 0, sizeof(*pud_p) * PTRS_PER_PUD);</span>
<span class="p_add">+			pgtable_area += sizeof(*pud_p) * PTRS_PER_PUD;</span>
<span class="p_add">+</span>
<span class="p_add">+			p4d = native_make_p4d((p4dval_t)pud_p + P4D_FLAGS);</span>
<span class="p_add">+			native_set_p4d(p4d_p, p4d);</span>
<span class="p_add">+		}</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	pud_p += pud_index(vaddr);</span>
<span class="p_add">+	if (native_pud_val(*pud_p)) {</span>
<span class="p_add">+		if (native_pud_val(*pud_p) &amp; _PAGE_PSE)</span>
<span class="p_add">+			goto out;</span>
<span class="p_add">+</span>
<span class="p_add">+		pmd_p = (pmd_t *)(native_pud_val(*pud_p) &amp; ~PTE_FLAGS_MASK);</span>
<span class="p_add">+	} else {</span>
<span class="p_add">+		pud_t pud;</span>
<span class="p_add">+</span>
<span class="p_add">+		pmd_p = pgtable_area;</span>
<span class="p_add">+		memset(pmd_p, 0, sizeof(*pmd_p) * PTRS_PER_PMD);</span>
<span class="p_add">+		pgtable_area += sizeof(*pmd_p) * PTRS_PER_PMD;</span>
<span class="p_add">+</span>
<span class="p_add">+		pud = native_make_pud((pudval_t)pmd_p + PUD_FLAGS);</span>
<span class="p_add">+		native_set_pud(pud_p, pud);</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	pmd_p += pmd_index(vaddr);</span>
<span class="p_add">+	if (!native_pmd_val(*pmd_p) || !(native_pmd_val(*pmd_p) &amp; _PAGE_PSE))</span>
<span class="p_add">+		native_set_pmd(pmd_p, native_make_pmd(pmd_val));</span>
<span class="p_add">+</span>
<span class="p_add">+out:</span>
<span class="p_add">+	return pgtable_area;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static unsigned long __init sme_pgtable_calc(unsigned long len)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long p4d_size, pud_size, pmd_size;</span>
<span class="p_add">+	unsigned long total;</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Perform a relatively simplistic calculation of the pagetable</span>
<span class="p_add">+	 * entries that are needed. That mappings will be covered by 2MB</span>
<span class="p_add">+	 * PMD entries so we can conservatively calculate the required</span>
<span class="p_add">+	 * number of P4D, PUD and PMD structures needed to perform the</span>
<span class="p_add">+	 * mappings. Incrementing the count for each covers the case where</span>
<span class="p_add">+	 * the addresses cross entries.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	if (IS_ENABLED(CONFIG_X86_5LEVEL)) {</span>
<span class="p_add">+		p4d_size = (ALIGN(len, PGDIR_SIZE) / PGDIR_SIZE) + 1;</span>
<span class="p_add">+		p4d_size *= sizeof(p4d_t) * PTRS_PER_P4D;</span>
<span class="p_add">+		pud_size = (ALIGN(len, P4D_SIZE) / P4D_SIZE) + 1;</span>
<span class="p_add">+		pud_size *= sizeof(pud_t) * PTRS_PER_PUD;</span>
<span class="p_add">+	} else {</span>
<span class="p_add">+		p4d_size = 0;</span>
<span class="p_add">+		pud_size = (ALIGN(len, PGDIR_SIZE) / PGDIR_SIZE) + 1;</span>
<span class="p_add">+		pud_size *= sizeof(pud_t) * PTRS_PER_PUD;</span>
<span class="p_add">+	}</span>
<span class="p_add">+	pmd_size = (ALIGN(len, PUD_SIZE) / PUD_SIZE) + 1;</span>
<span class="p_add">+	pmd_size *= sizeof(pmd_t) * PTRS_PER_PMD;</span>
<span class="p_add">+</span>
<span class="p_add">+	total = p4d_size + pud_size + pmd_size;</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Now calculate the added pagetable structures needed to populate</span>
<span class="p_add">+	 * the new pagetables.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	if (IS_ENABLED(CONFIG_X86_5LEVEL)) {</span>
<span class="p_add">+		p4d_size = ALIGN(total, PGDIR_SIZE) / PGDIR_SIZE;</span>
<span class="p_add">+		p4d_size *= sizeof(p4d_t) * PTRS_PER_P4D;</span>
<span class="p_add">+		pud_size = ALIGN(total, P4D_SIZE) / P4D_SIZE;</span>
<span class="p_add">+		pud_size *= sizeof(pud_t) * PTRS_PER_PUD;</span>
<span class="p_add">+	} else {</span>
<span class="p_add">+		p4d_size = 0;</span>
<span class="p_add">+		pud_size = ALIGN(total, PGDIR_SIZE) / PGDIR_SIZE;</span>
<span class="p_add">+		pud_size *= sizeof(pud_t) * PTRS_PER_PUD;</span>
<span class="p_add">+	}</span>
<span class="p_add">+	pmd_size = ALIGN(total, PUD_SIZE) / PUD_SIZE;</span>
<span class="p_add">+	pmd_size *= sizeof(pmd_t) * PTRS_PER_PMD;</span>
<span class="p_add">+</span>
<span class="p_add">+	total += p4d_size + pud_size + pmd_size;</span>
<span class="p_add">+</span>
<span class="p_add">+	return total;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 void __init sme_encrypt_kernel(void)
 {
<span class="p_add">+	unsigned long workarea_start, workarea_end, workarea_len;</span>
<span class="p_add">+	unsigned long execute_start, execute_end, execute_len;</span>
<span class="p_add">+	unsigned long kernel_start, kernel_end, kernel_len;</span>
<span class="p_add">+	unsigned long pgtable_area_len;</span>
<span class="p_add">+	unsigned long paddr, pmd_flags;</span>
<span class="p_add">+	unsigned long decrypted_base;</span>
<span class="p_add">+	void *pgtable_area;</span>
<span class="p_add">+	pgd_t *pgd;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (!sme_active())</span>
<span class="p_add">+		return;</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Prepare for encrypting the kernel by building new pagetables with</span>
<span class="p_add">+	 * the necessary attributes needed to encrypt the kernel in place.</span>
<span class="p_add">+	 *</span>
<span class="p_add">+	 *   One range of virtual addresses will map the memory occupied</span>
<span class="p_add">+	 *   by the kernel as encrypted.</span>
<span class="p_add">+	 *</span>
<span class="p_add">+	 *   Another range of virtual addresses will map the memory occupied</span>
<span class="p_add">+	 *   by the kernel as decrypted and write-protected.</span>
<span class="p_add">+	 *</span>
<span class="p_add">+	 *     The use of write-protect attribute will prevent any of the</span>
<span class="p_add">+	 *     memory from being cached.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+</span>
<span class="p_add">+	/* Physical addresses gives us the identity mapped virtual addresses */</span>
<span class="p_add">+	kernel_start = __pa_symbol(_text);</span>
<span class="p_add">+	kernel_end = ALIGN(__pa_symbol(_end), PMD_PAGE_SIZE);</span>
<span class="p_add">+	kernel_len = kernel_end - kernel_start;</span>
<span class="p_add">+</span>
<span class="p_add">+	/* Set the encryption workarea to be immediately after the kernel */</span>
<span class="p_add">+	workarea_start = kernel_end;</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Calculate required number of workarea bytes needed:</span>
<span class="p_add">+	 *   executable encryption area size:</span>
<span class="p_add">+	 *     stack page (PAGE_SIZE)</span>
<span class="p_add">+	 *     encryption routine page (PAGE_SIZE)</span>
<span class="p_add">+	 *     intermediate copy buffer (PMD_PAGE_SIZE)</span>
<span class="p_add">+	 *   pagetable structures for the encryption of the kernel</span>
<span class="p_add">+	 *   pagetable structures for workarea (in case not currently mapped)</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	execute_start = workarea_start;</span>
<span class="p_add">+	execute_end = execute_start + (PAGE_SIZE * 2) + PMD_PAGE_SIZE;</span>
<span class="p_add">+	execute_len = execute_end - execute_start;</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * One PGD for both encrypted and decrypted mappings and a set of</span>
<span class="p_add">+	 * PUDs and PMDs for each of the encrypted and decrypted mappings.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	pgtable_area_len = sizeof(pgd_t) * PTRS_PER_PGD;</span>
<span class="p_add">+	pgtable_area_len += sme_pgtable_calc(execute_end - kernel_start) * 2;</span>
<span class="p_add">+</span>
<span class="p_add">+	/* PUDs and PMDs needed in the current pagetables for the workarea */</span>
<span class="p_add">+	pgtable_area_len += sme_pgtable_calc(execute_len + pgtable_area_len);</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * The total workarea includes the executable encryption area and</span>
<span class="p_add">+	 * the pagetable area.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	workarea_len = execute_len + pgtable_area_len;</span>
<span class="p_add">+	workarea_end = workarea_start + workarea_len;</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Set the address to the start of where newly created pagetable</span>
<span class="p_add">+	 * structures (PGDs, PUDs and PMDs) will be allocated. New pagetable</span>
<span class="p_add">+	 * structures are created when the workarea is added to the current</span>
<span class="p_add">+	 * pagetables and when the new encrypted and decrypted kernel</span>
<span class="p_add">+	 * mappings are populated.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	pgtable_area = (void *)execute_end;</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Make sure the current pagetable structure has entries for</span>
<span class="p_add">+	 * addressing the workarea.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	pgd = (pgd_t *)native_read_cr3_pa();</span>
<span class="p_add">+	paddr = workarea_start;</span>
<span class="p_add">+	while (paddr &lt; workarea_end) {</span>
<span class="p_add">+		pgtable_area = sme_populate_pgd(pgd, pgtable_area,</span>
<span class="p_add">+						paddr,</span>
<span class="p_add">+						paddr + PMD_FLAGS);</span>
<span class="p_add">+</span>
<span class="p_add">+		paddr += PMD_PAGE_SIZE;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	/* Flush the TLB - no globals so cr3 is enough */</span>
<span class="p_add">+	native_write_cr3(__native_read_cr3());</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * A new pagetable structure is being built to allow for the kernel</span>
<span class="p_add">+	 * to be encrypted. It starts with an empty PGD that will then be</span>
<span class="p_add">+	 * populated with new PUDs and PMDs as the encrypted and decrypted</span>
<span class="p_add">+	 * kernel mappings are created.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	pgd = pgtable_area;</span>
<span class="p_add">+	memset(pgd, 0, sizeof(*pgd) * PTRS_PER_PGD);</span>
<span class="p_add">+	pgtable_area += sizeof(*pgd) * PTRS_PER_PGD;</span>
<span class="p_add">+</span>
<span class="p_add">+	/* Add encrypted kernel (identity) mappings */</span>
<span class="p_add">+	pmd_flags = PMD_FLAGS | _PAGE_ENC;</span>
<span class="p_add">+	paddr = kernel_start;</span>
<span class="p_add">+	while (paddr &lt; kernel_end) {</span>
<span class="p_add">+		pgtable_area = sme_populate_pgd(pgd, pgtable_area,</span>
<span class="p_add">+						paddr,</span>
<span class="p_add">+						paddr + pmd_flags);</span>
<span class="p_add">+</span>
<span class="p_add">+		paddr += PMD_PAGE_SIZE;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * A different PGD index/entry must be used to get different</span>
<span class="p_add">+	 * pagetable entries for the decrypted mapping. Choose the next</span>
<span class="p_add">+	 * PGD index and convert it to a virtual address to be used as</span>
<span class="p_add">+	 * the base of the mapping.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	decrypted_base = (pgd_index(workarea_end) + 1) &amp; (PTRS_PER_PGD - 1);</span>
<span class="p_add">+	decrypted_base &lt;&lt;= PGDIR_SHIFT;</span>
<span class="p_add">+</span>
<span class="p_add">+	/* Add decrypted, write-protected kernel (non-identity) mappings */</span>
<span class="p_add">+	pmd_flags = (PMD_FLAGS &amp; ~_PAGE_CACHE_MASK) | (_PAGE_PAT | _PAGE_PWT);</span>
<span class="p_add">+	paddr = kernel_start;</span>
<span class="p_add">+	while (paddr &lt; kernel_end) {</span>
<span class="p_add">+		pgtable_area = sme_populate_pgd(pgd, pgtable_area,</span>
<span class="p_add">+						paddr + decrypted_base,</span>
<span class="p_add">+						paddr + pmd_flags);</span>
<span class="p_add">+</span>
<span class="p_add">+		paddr += PMD_PAGE_SIZE;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	/* Add decrypted workarea mappings to both kernel mappings */</span>
<span class="p_add">+	paddr = workarea_start;</span>
<span class="p_add">+	while (paddr &lt; workarea_end) {</span>
<span class="p_add">+		pgtable_area = sme_populate_pgd(pgd, pgtable_area,</span>
<span class="p_add">+						paddr,</span>
<span class="p_add">+						paddr + PMD_FLAGS);</span>
<span class="p_add">+</span>
<span class="p_add">+		pgtable_area = sme_populate_pgd(pgd, pgtable_area,</span>
<span class="p_add">+						paddr + decrypted_base,</span>
<span class="p_add">+						paddr + PMD_FLAGS);</span>
<span class="p_add">+</span>
<span class="p_add">+		paddr += PMD_PAGE_SIZE;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	/* Perform the encryption */</span>
<span class="p_add">+	sme_encrypt_execute(kernel_start, kernel_start + decrypted_base,</span>
<span class="p_add">+			    kernel_len, workarea_start, (unsigned long)pgd);</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * At this point we are running encrypted.  Remove the mappings for</span>
<span class="p_add">+	 * the decrypted areas - all that is needed for this is to remove</span>
<span class="p_add">+	 * the PGD entry/entries.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	sme_clear_pgd(pgd, kernel_start + decrypted_base,</span>
<span class="p_add">+		      kernel_end + decrypted_base);</span>
<span class="p_add">+</span>
<span class="p_add">+	sme_clear_pgd(pgd, workarea_start + decrypted_base,</span>
<span class="p_add">+		      workarea_end + decrypted_base);</span>
<span class="p_add">+</span>
<span class="p_add">+	/* Flush the TLB - no globals so cr3 is enough */</span>
<span class="p_add">+	native_write_cr3(__native_read_cr3());</span>
 }
 
 void __init sme_enable(void)
<span class="p_header">diff --git a/arch/x86/mm/mem_encrypt_boot.S b/arch/x86/mm/mem_encrypt_boot.S</span>
new file mode 100644
<span class="p_header">index 0000000..7720b00</span>
<span class="p_header">--- /dev/null</span>
<span class="p_header">+++ b/arch/x86/mm/mem_encrypt_boot.S</span>
<span class="p_chunk">@@ -0,0 +1,150 @@</span> <span class="p_context"></span>
<span class="p_add">+/*</span>
<span class="p_add">+ * AMD Memory Encryption Support</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * Copyright (C) 2016 Advanced Micro Devices, Inc.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * Author: Tom Lendacky &lt;thomas.lendacky@amd.com&gt;</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * This program is free software; you can redistribute it and/or modify</span>
<span class="p_add">+ * it under the terms of the GNU General Public License version 2 as</span>
<span class="p_add">+ * published by the Free Software Foundation.</span>
<span class="p_add">+ */</span>
<span class="p_add">+</span>
<span class="p_add">+#include &lt;linux/linkage.h&gt;</span>
<span class="p_add">+#include &lt;asm/pgtable.h&gt;</span>
<span class="p_add">+#include &lt;asm/page.h&gt;</span>
<span class="p_add">+#include &lt;asm/processor-flags.h&gt;</span>
<span class="p_add">+#include &lt;asm/msr-index.h&gt;</span>
<span class="p_add">+</span>
<span class="p_add">+	.text</span>
<span class="p_add">+	.code64</span>
<span class="p_add">+ENTRY(sme_encrypt_execute)</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Entry parameters:</span>
<span class="p_add">+	 *   RDI - virtual address for the encrypted kernel mapping</span>
<span class="p_add">+	 *   RSI - virtual address for the decrypted kernel mapping</span>
<span class="p_add">+	 *   RDX - length of kernel</span>
<span class="p_add">+	 *   RCX - virtual address of the encryption workarea, including:</span>
<span class="p_add">+	 *     - stack page (PAGE_SIZE)</span>
<span class="p_add">+	 *     - encryption routine page (PAGE_SIZE)</span>
<span class="p_add">+	 *     - intermediate copy buffer (PMD_PAGE_SIZE)</span>
<span class="p_add">+	 *    R8 - physcial address of the pagetables to use for encryption</span>
<span class="p_add">+	 */</span>
<span class="p_add">+</span>
<span class="p_add">+	push	%rbp</span>
<span class="p_add">+	push	%r12</span>
<span class="p_add">+</span>
<span class="p_add">+	/* Set up a one page stack in the non-encrypted memory area */</span>
<span class="p_add">+	movq	%rsp, %rbp		/* Save current stack pointer */</span>
<span class="p_add">+	movq	%rcx, %rax		/* Workarea stack page */</span>
<span class="p_add">+	movq	%rax, %rsp		/* Set new stack pointer */</span>
<span class="p_add">+	addq	$PAGE_SIZE, %rsp	/* Stack grows from the bottom */</span>
<span class="p_add">+	addq	$PAGE_SIZE, %rax	/* Workarea encryption routine */</span>
<span class="p_add">+</span>
<span class="p_add">+	movq	%rdi, %r10		/* Encrypted kernel */</span>
<span class="p_add">+	movq	%rsi, %r11		/* Decrypted kernel */</span>
<span class="p_add">+	movq	%rdx, %r12		/* Kernel length */</span>
<span class="p_add">+</span>
<span class="p_add">+	/* Copy encryption routine into the workarea */</span>
<span class="p_add">+	movq	%rax, %rdi				/* Workarea encryption routine */</span>
<span class="p_add">+	leaq	__enc_copy(%rip), %rsi			/* Encryption routine */</span>
<span class="p_add">+	movq	$(.L__enc_copy_end - __enc_copy), %rcx	/* Encryption routine length */</span>
<span class="p_add">+	rep	movsb</span>
<span class="p_add">+</span>
<span class="p_add">+	/* Setup registers for call */</span>
<span class="p_add">+	movq	%r10, %rdi		/* Encrypted kernel */</span>
<span class="p_add">+	movq	%r11, %rsi		/* Decrypted kernel */</span>
<span class="p_add">+	movq	%r8, %rdx		/* Pagetables used for encryption */</span>
<span class="p_add">+	movq	%r12, %rcx		/* Kernel length */</span>
<span class="p_add">+	movq	%rax, %r8		/* Workarea encryption routine */</span>
<span class="p_add">+	addq	$PAGE_SIZE, %r8		/* Workarea intermediate copy buffer */</span>
<span class="p_add">+</span>
<span class="p_add">+	call	*%rax			/* Call the encryption routine */</span>
<span class="p_add">+</span>
<span class="p_add">+	movq	%rbp, %rsp		/* Restore original stack pointer */</span>
<span class="p_add">+</span>
<span class="p_add">+	pop	%r12</span>
<span class="p_add">+	pop	%rbp</span>
<span class="p_add">+</span>
<span class="p_add">+	ret</span>
<span class="p_add">+ENDPROC(sme_encrypt_execute)</span>
<span class="p_add">+</span>
<span class="p_add">+ENTRY(__enc_copy)</span>
<span class="p_add">+/*</span>
<span class="p_add">+ * Routine used to encrypt kernel.</span>
<span class="p_add">+ *   This routine must be run outside of the kernel proper since</span>
<span class="p_add">+ *   the kernel will be encrypted during the process. So this</span>
<span class="p_add">+ *   routine is defined here and then copied to an area outside</span>
<span class="p_add">+ *   of the kernel where it will remain and run decrypted</span>
<span class="p_add">+ *   during execution.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ *   On entry the registers must be:</span>
<span class="p_add">+ *     RDI - virtual address for the encrypted kernel mapping</span>
<span class="p_add">+ *     RSI - virtual address for the decrypted kernel mapping</span>
<span class="p_add">+ *     RDX - address of the pagetables to use for encryption</span>
<span class="p_add">+ *     RCX - length of kernel</span>
<span class="p_add">+ *      R8 - intermediate copy buffer</span>
<span class="p_add">+ *</span>
<span class="p_add">+ *     RAX - points to this routine</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * The kernel will be encrypted by copying from the non-encrypted</span>
<span class="p_add">+ * kernel space to an intermediate buffer and then copying from the</span>
<span class="p_add">+ * intermediate buffer back to the encrypted kernel space. The physical</span>
<span class="p_add">+ * addresses of the two kernel space mappings are the same which</span>
<span class="p_add">+ * results in the kernel being encrypted &quot;in place&quot;.</span>
<span class="p_add">+ */</span>
<span class="p_add">+	/* Enable the new page tables */</span>
<span class="p_add">+	mov	%rdx, %cr3</span>
<span class="p_add">+</span>
<span class="p_add">+	/* Flush any global TLBs */</span>
<span class="p_add">+	mov	%cr4, %rdx</span>
<span class="p_add">+	andq	$~X86_CR4_PGE, %rdx</span>
<span class="p_add">+	mov	%rdx, %cr4</span>
<span class="p_add">+	orq	$X86_CR4_PGE, %rdx</span>
<span class="p_add">+	mov	%rdx, %cr4</span>
<span class="p_add">+</span>
<span class="p_add">+	/* Set the PAT register PA5 entry to write-protect */</span>
<span class="p_add">+	push	%rcx</span>
<span class="p_add">+	movl	$MSR_IA32_CR_PAT, %ecx</span>
<span class="p_add">+	rdmsr</span>
<span class="p_add">+	push	%rdx			/* Save original PAT value */</span>
<span class="p_add">+	andl	$0xffff00ff, %edx	/* Clear PA5 */</span>
<span class="p_add">+	orl	$0x00000500, %edx	/* Set PA5 to WP */</span>
<span class="p_add">+	wrmsr</span>
<span class="p_add">+	pop	%rdx			/* RDX contains original PAT value */</span>
<span class="p_add">+	pop	%rcx</span>
<span class="p_add">+</span>
<span class="p_add">+	movq	%rcx, %r9		/* Save kernel length */</span>
<span class="p_add">+	movq	%rdi, %r10		/* Save encrypted kernel address */</span>
<span class="p_add">+	movq	%rsi, %r11		/* Save decrypted kernel address */</span>
<span class="p_add">+</span>
<span class="p_add">+	wbinvd				/* Invalidate any cache entries */</span>
<span class="p_add">+</span>
<span class="p_add">+	/* Copy/encrypt 2MB at a time */</span>
<span class="p_add">+1:</span>
<span class="p_add">+	movq	%r11, %rsi		/* Source - decrypted kernel */</span>
<span class="p_add">+	movq	%r8, %rdi		/* Dest   - intermediate copy buffer */</span>
<span class="p_add">+	movq	$PMD_PAGE_SIZE, %rcx	/* 2MB length */</span>
<span class="p_add">+	rep	movsb</span>
<span class="p_add">+</span>
<span class="p_add">+	movq	%r8, %rsi		/* Source - intermediate copy buffer */</span>
<span class="p_add">+	movq	%r10, %rdi		/* Dest   - encrypted kernel */</span>
<span class="p_add">+	movq	$PMD_PAGE_SIZE, %rcx	/* 2MB length */</span>
<span class="p_add">+	rep	movsb</span>
<span class="p_add">+</span>
<span class="p_add">+	addq	$PMD_PAGE_SIZE, %r11</span>
<span class="p_add">+	addq	$PMD_PAGE_SIZE, %r10</span>
<span class="p_add">+	subq	$PMD_PAGE_SIZE, %r9	/* Kernel length decrement */</span>
<span class="p_add">+	jnz	1b			/* Kernel length not zero? */</span>
<span class="p_add">+</span>
<span class="p_add">+	/* Restore PAT register */</span>
<span class="p_add">+	push	%rdx			/* Save original PAT value */</span>
<span class="p_add">+	movl	$MSR_IA32_CR_PAT, %ecx</span>
<span class="p_add">+	rdmsr</span>
<span class="p_add">+	pop	%rdx			/* Restore original PAT value */</span>
<span class="p_add">+	wrmsr</span>
<span class="p_add">+</span>
<span class="p_add">+	ret</span>
<span class="p_add">+.L__enc_copy_end:</span>
<span class="p_add">+ENDPROC(__enc_copy)</span>

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



