
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>[1/3] powerpc/32: Fix hugepage allocation on 8xx at hint address - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    [1/3] powerpc/32: Fix hugepage allocation on 8xx at hint address</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=11492">LEROY Christophe</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>Jan. 5, 2018, 4:44 p.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;9a5dadc10f88e2fc0ac9fb5d18c5424df33f3f4c.1515169256.git.christophe.leroy@c-s.fr&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/10146761/mbox/"
   >mbox</a>
|
   <a href="/patch/10146761/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/10146761/">/patch/10146761/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
	[172.30.200.125])
	by pdx-korg-patchwork.web.codeaurora.org (Postfix) with ESMTP id
	A0C5F6034B for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Fri,  5 Jan 2018 16:45:03 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 8A391209D8
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Fri,  5 Jan 2018 16:45:03 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id 7D99827E71; Fri,  5 Jan 2018 16:45:03 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-6.9 required=2.0 tests=BAYES_00,RCVD_IN_DNSWL_HI
	autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 2940A267EC
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Fri,  5 Jan 2018 16:45:02 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1752343AbeAEQoF (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Fri, 5 Jan 2018 11:44:05 -0500
Received: from pegase1.c-s.fr ([93.17.236.30]:11374 &quot;EHLO pegase1.c-s.fr&quot;
	rhost-flags-OK-OK-OK-OK) by vger.kernel.org with ESMTP
	id S1752123AbeAEQoD (ORCPT &lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Fri, 5 Jan 2018 11:44:03 -0500
Received: from localhost (mailhub1-int [192.168.12.234])
	by localhost (Postfix) with ESMTP id 3zCr8d58B3z9ttpd;
	Fri,  5 Jan 2018 17:43:45 +0100 (CET)
X-Virus-Scanned: Debian amavisd-new at c-s.fr
Received: from pegase1.c-s.fr ([192.168.12.234])
	by localhost (pegase1.c-s.fr [192.168.12.234]) (amavisd-new,
	port 10024)
	with ESMTP id rrOJxz7ao8CV; Fri,  5 Jan 2018 17:43:45 +0100 (CET)
Received: from messagerie.si.c-s.fr (messagerie.si.c-s.fr [192.168.25.192])
	by pegase1.c-s.fr (Postfix) with ESMTP id 3zCr8d4GgMz9ttpZ;
	Fri,  5 Jan 2018 17:43:45 +0100 (CET)
Received: from localhost (localhost [127.0.0.1])
	by messagerie.si.c-s.fr (Postfix) with ESMTP id 6E3548BDF1;
	Fri,  5 Jan 2018 17:44:01 +0100 (CET)
X-Virus-Scanned: amavisd-new at c-s.fr
Received: from messagerie.si.c-s.fr ([127.0.0.1])
	by localhost (messagerie.si.c-s.fr [127.0.0.1]) (amavisd-new,
	port 10023)
	with ESMTP id etDSu8IdWJeR; Fri,  5 Jan 2018 17:44:01 +0100 (CET)
Received: from PO15451.localdomain (po15451.idsi0.si.c-s.fr [172.25.231.40])
	by messagerie.si.c-s.fr (Postfix) with ESMTP id 8D1358BDEF;
	Fri,  5 Jan 2018 17:44:00 +0100 (CET)
Received: by localhost.localdomain (Postfix, from userid 0)
	id 367E66E941; Fri,  5 Jan 2018 17:44:00 +0100 (CET)
Message-Id: &lt;9a5dadc10f88e2fc0ac9fb5d18c5424df33f3f4c.1515169256.git.christophe.leroy@c-s.fr&gt;
From: Christophe Leroy &lt;christophe.leroy@c-s.fr&gt;
Subject: [PATCH 1/3] powerpc/32: Fix hugepage allocation on 8xx at hint
	address
To: Benjamin Herrenschmidt &lt;benh@kernel.crashing.org&gt;,
	Paul Mackerras &lt;paulus@samba.org&gt;, Michael Ellerman &lt;mpe@ellerman.id.au&gt;,
	Scott Wood &lt;oss@buserror.net&gt;,
	&quot;Aneesh Kumar K.V&quot; &lt;aneesh.kumar@linux.vnet.ibm.com&gt;,
	Nicholas Piggin &lt;npiggin@gmail.com&gt;
Cc: linux-kernel@vger.kernel.org, linuxppc-dev@lists.ozlabs.org
Date: Fri,  5 Jan 2018 17:44:00 +0100 (CET)
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=11492">LEROY Christophe</a> - Jan. 5, 2018, 4:44 p.m.</div>
<pre class="content">
When an app has some regular pages allocated (e.g. see below) and tries
to mmap() a huge page at a hint address covered by the same PMD entry,
the kernel accepts the hint allthough the 8xx cannot handle different
page sizes in the same PMD entry.

10000000-10001000 r-xp 00000000 00:0f 2597 /root/malloc
10010000-10011000 rwxp 00000000 00:0f 2597 /root/malloc

mmap(0x10080000, 524288, PROT_READ|PROT_WRITE,
     MAP_PRIVATE|MAP_ANONYMOUS|0x40000, -1, 0) = 0x10080000

This results in the following warning, and the app remains forever in
do_page_fault()/hugetlb_fault()

[162980.035629] WARNING: CPU: 0 PID: 2777 at arch/powerpc/mm/hugetlbpage.c:354 hugetlb_free_pgd_range+0xc8/0x1e4
[162980.035699] CPU: 0 PID: 2777 Comm: malloc Tainted: G W       4.14.6 #85
[162980.035744] task: c67e2c00 task.stack: c668e000
[162980.035783] NIP:  c000fe18 LR: c00e1eec CTR: c00f90c0
[162980.035830] REGS: c668fc20 TRAP: 0700   Tainted: G W        (4.14.6)
[162980.035854] MSR:  00029032 &lt;EE,ME,IR,DR,RI&gt;  CR: 24044224 XER: 20000000
[162980.036003]
[162980.036003] GPR00: c00e1eec c668fcd0 c67e2c00 00000010 c6869410 10080000 00000000 77fb4000
[162980.036003] GPR08: ffff0001 0683c001 00000000 ffffff80 44028228 10018a34 00004008 418004fc
[162980.036003] GPR16: c668e000 00040100 c668e000 c06c0000 c668fe78 c668e000 c6835ba0 c668fd48
[162980.036003] GPR24: 00000000 73ffffff 74000000 00000001 77fb4000 100fffff 10100000 10100000
[162980.036743] NIP [c000fe18] hugetlb_free_pgd_range+0xc8/0x1e4
[162980.036839] LR [c00e1eec] free_pgtables+0x12c/0x150
[162980.036861] Call Trace:
[162980.036939] [c668fcd0] [c00f0774] unlink_anon_vmas+0x1c4/0x214 (unreliable)
[162980.037040] [c668fd10] [c00e1eec] free_pgtables+0x12c/0x150
[162980.037118] [c668fd40] [c00eabac] exit_mmap+0xe8/0x1b4
[162980.037210] [c668fda0] [c0019710] mmput.part.9+0x20/0xd8
[162980.037301] [c668fdb0] [c001ecb0] do_exit+0x1f0/0x93c
[162980.037386] [c668fe00] [c001f478] do_group_exit+0x40/0xcc
[162980.037479] [c668fe10] [c002a76c] get_signal+0x47c/0x614
[162980.037570] [c668fe70] [c0007840] do_signal+0x54/0x244
[162980.037654] [c668ff30] [c0007ae8] do_notify_resume+0x34/0x88
[162980.037744] [c668ff40] [c000dae8] do_user_signal+0x74/0xc4
[162980.037781] Instruction dump:
[162980.037821] 7fdff378 81370000 54a3463a 80890020 7d24182e 7c841a14 712a0004 4082ff94
[162980.038014] 2f890000 419e0010 712a0ff0 408200e0 &lt;0fe00000&gt; 54a9000a 7f984840 419d0094
[162980.038216] ---[ end trace c0ceeca8e7a5800a ]---
[162980.038754] BUG: non-zero nr_ptes on freeing mm: 1
[162985.363322] BUG: non-zero nr_ptes on freeing mm: -1

In order to fix this, the address space &quot;slices&quot; implemented
for BOOK3S/64 is reused.

This patch:
1/ Modifies the &quot;slices&quot; implementation to support 32 bits CPUs,
based on using only the low slices.
2/ Moves &quot;slices&quot; functions prototypes from page64.h to page.h
3/ Modifies the context.id on the 8xx to be in the range [1:16]
instead of [0:15] in order to identify context.id == 0 as
not initialised contexts
4/ Activates CONFIG_PPC_MM_SLICES when CONFIG_HUGETLB_PAGE is
selected for the 8xx

Alltough we could in theory have as many slices as PMD entries, the current
slices implementation limits the number of low slices to 16.

Fixes: 4b91428699477 (&quot;powerpc/8xx: Implement support of hugepages&quot;)
<span class="signed-off-by">Signed-off-by: Christophe Leroy &lt;christophe.leroy@c-s.fr&gt;</span>
---
 arch/powerpc/include/asm/mmu-8xx.h     |  6 ++++
 arch/powerpc/include/asm/page.h        | 14 ++++++++
 arch/powerpc/include/asm/page_32.h     | 19 +++++++++++
 arch/powerpc/include/asm/page_64.h     | 21 ++----------
 arch/powerpc/kernel/setup-common.c     |  2 +-
 arch/powerpc/mm/8xx_mmu.c              |  2 +-
 arch/powerpc/mm/hash_utils_64.c        |  2 +-
 arch/powerpc/mm/hugetlbpage.c          |  2 ++
 arch/powerpc/mm/mmu_context_nohash.c   | 11 +++++--
 arch/powerpc/mm/slice.c                | 58 +++++++++++++++++++++++-----------
 arch/powerpc/platforms/Kconfig.cputype |  1 +
 11 files changed, 95 insertions(+), 43 deletions(-)
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=1141">Aneesh Kumar K.V</a> - Jan. 16, 2018, 3:49 p.m.</div>
<pre class="content">
Christophe Leroy &lt;christophe.leroy@c-s.fr&gt; writes:
<span class="quote">
&gt; When an app has some regular pages allocated (e.g. see below) and tries</span>
<span class="quote">&gt; to mmap() a huge page at a hint address covered by the same PMD entry,</span>
<span class="quote">&gt; the kernel accepts the hint allthough the 8xx cannot handle different</span>
<span class="quote">&gt; page sizes in the same PMD entry.</span>


So that is a bug in get_unmapped_area function that you are using and
you want to fix that by using the slice code. Can you describe here what
the allocation restrictions are w.r.t 8xx? Do they have segments and
base page size like hash64?
<span class="quote">
&gt;</span>
<span class="quote">&gt; 10000000-10001000 r-xp 00000000 00:0f 2597 /root/malloc</span>
<span class="quote">&gt; 10010000-10011000 rwxp 00000000 00:0f 2597 /root/malloc</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; mmap(0x10080000, 524288, PROT_READ|PROT_WRITE,</span>
<span class="quote">&gt;      MAP_PRIVATE|MAP_ANONYMOUS|0x40000, -1, 0) = 0x10080000</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; This results in the following warning, and the app remains forever in</span>
<span class="quote">&gt; do_page_fault()/hugetlb_fault()</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; [162980.035629] WARNING: CPU: 0 PID: 2777 at arch/powerpc/mm/hugetlbpage.c:354 hugetlb_free_pgd_range+0xc8/0x1e4</span>
<span class="quote">&gt; [162980.035699] CPU: 0 PID: 2777 Comm: malloc Tainted: G W       4.14.6 #85</span>
<span class="quote">&gt; [162980.035744] task: c67e2c00 task.stack: c668e000</span>
<span class="quote">&gt; [162980.035783] NIP:  c000fe18 LR: c00e1eec CTR: c00f90c0</span>
<span class="quote">&gt; [162980.035830] REGS: c668fc20 TRAP: 0700   Tainted: G W        (4.14.6)</span>
<span class="quote">&gt; [162980.035854] MSR:  00029032 &lt;EE,ME,IR,DR,RI&gt;  CR: 24044224 XER: 20000000</span>
<span class="quote">&gt; [162980.036003]</span>
<span class="quote">&gt; [162980.036003] GPR00: c00e1eec c668fcd0 c67e2c00 00000010 c6869410 10080000 00000000 77fb4000</span>
<span class="quote">&gt; [162980.036003] GPR08: ffff0001 0683c001 00000000 ffffff80 44028228 10018a34 00004008 418004fc</span>
<span class="quote">&gt; [162980.036003] GPR16: c668e000 00040100 c668e000 c06c0000 c668fe78 c668e000 c6835ba0 c668fd48</span>
<span class="quote">&gt; [162980.036003] GPR24: 00000000 73ffffff 74000000 00000001 77fb4000 100fffff 10100000 10100000</span>
<span class="quote">&gt; [162980.036743] NIP [c000fe18] hugetlb_free_pgd_range+0xc8/0x1e4</span>
<span class="quote">&gt; [162980.036839] LR [c00e1eec] free_pgtables+0x12c/0x150</span>
<span class="quote">&gt; [162980.036861] Call Trace:</span>
<span class="quote">&gt; [162980.036939] [c668fcd0] [c00f0774] unlink_anon_vmas+0x1c4/0x214 (unreliable)</span>
<span class="quote">&gt; [162980.037040] [c668fd10] [c00e1eec] free_pgtables+0x12c/0x150</span>
<span class="quote">&gt; [162980.037118] [c668fd40] [c00eabac] exit_mmap+0xe8/0x1b4</span>
<span class="quote">&gt; [162980.037210] [c668fda0] [c0019710] mmput.part.9+0x20/0xd8</span>
<span class="quote">&gt; [162980.037301] [c668fdb0] [c001ecb0] do_exit+0x1f0/0x93c</span>
<span class="quote">&gt; [162980.037386] [c668fe00] [c001f478] do_group_exit+0x40/0xcc</span>
<span class="quote">&gt; [162980.037479] [c668fe10] [c002a76c] get_signal+0x47c/0x614</span>
<span class="quote">&gt; [162980.037570] [c668fe70] [c0007840] do_signal+0x54/0x244</span>
<span class="quote">&gt; [162980.037654] [c668ff30] [c0007ae8] do_notify_resume+0x34/0x88</span>
<span class="quote">&gt; [162980.037744] [c668ff40] [c000dae8] do_user_signal+0x74/0xc4</span>
<span class="quote">&gt; [162980.037781] Instruction dump:</span>
<span class="quote">&gt; [162980.037821] 7fdff378 81370000 54a3463a 80890020 7d24182e 7c841a14 712a0004 4082ff94</span>
<span class="quote">&gt; [162980.038014] 2f890000 419e0010 712a0ff0 408200e0 &lt;0fe00000&gt; 54a9000a 7f984840 419d0094</span>
<span class="quote">&gt; [162980.038216] ---[ end trace c0ceeca8e7a5800a ]---</span>
<span class="quote">&gt; [162980.038754] BUG: non-zero nr_ptes on freeing mm: 1</span>
<span class="quote">&gt; [162985.363322] BUG: non-zero nr_ptes on freeing mm: -1</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; In order to fix this, the address space &quot;slices&quot; implemented</span>
<span class="quote">&gt; for BOOK3S/64 is reused.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; This patch:</span>
<span class="quote">&gt; 1/ Modifies the &quot;slices&quot; implementation to support 32 bits CPUs,</span>
<span class="quote">&gt; based on using only the low slices.</span>
<span class="quote">&gt; 2/ Moves &quot;slices&quot; functions prototypes from page64.h to page.h</span>
<span class="quote">&gt; 3/ Modifies the context.id on the 8xx to be in the range [1:16]</span>
<span class="quote">&gt; instead of [0:15] in order to identify context.id == 0 as</span>
<span class="quote">&gt; not initialised contexts</span>
<span class="quote">&gt; 4/ Activates CONFIG_PPC_MM_SLICES when CONFIG_HUGETLB_PAGE is</span>
<span class="quote">&gt; selected for the 8xx</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; Alltough we could in theory have as many slices as PMD entries, the current</span>
<span class="quote">&gt; slices implementation limits the number of low slices to 16.</span>

Can you explain this more? 
<span class="quote">

&gt;</span>
<span class="quote">&gt; Fixes: 4b91428699477 (&quot;powerpc/8xx: Implement support of hugepages&quot;)</span>
<span class="quote">&gt; Signed-off-by: Christophe Leroy &lt;christophe.leroy@c-s.fr&gt;</span>
<span class="quote">&gt; ---</span>
<span class="quote">&gt;  arch/powerpc/include/asm/mmu-8xx.h     |  6 ++++</span>
<span class="quote">&gt;  arch/powerpc/include/asm/page.h        | 14 ++++++++</span>
<span class="quote">&gt;  arch/powerpc/include/asm/page_32.h     | 19 +++++++++++</span>
<span class="quote">&gt;  arch/powerpc/include/asm/page_64.h     | 21 ++----------</span>
<span class="quote">&gt;  arch/powerpc/kernel/setup-common.c     |  2 +-</span>
<span class="quote">&gt;  arch/powerpc/mm/8xx_mmu.c              |  2 +-</span>
<span class="quote">&gt;  arch/powerpc/mm/hash_utils_64.c        |  2 +-</span>
<span class="quote">&gt;  arch/powerpc/mm/hugetlbpage.c          |  2 ++</span>
<span class="quote">&gt;  arch/powerpc/mm/mmu_context_nohash.c   | 11 +++++--</span>
<span class="quote">&gt;  arch/powerpc/mm/slice.c                | 58 +++++++++++++++++++++++-----------</span>
<span class="quote">&gt;  arch/powerpc/platforms/Kconfig.cputype |  1 +</span>
<span class="quote">&gt;  11 files changed, 95 insertions(+), 43 deletions(-)</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; diff --git a/arch/powerpc/include/asm/mmu-8xx.h b/arch/powerpc/include/asm/mmu-8xx.h</span>
<span class="quote">&gt; index 5bb3dbede41a..5f89b6010453 100644</span>
<span class="quote">&gt; --- a/arch/powerpc/include/asm/mmu-8xx.h</span>
<span class="quote">&gt; +++ b/arch/powerpc/include/asm/mmu-8xx.h</span>
<span class="quote">&gt; @@ -169,6 +169,12 @@ typedef struct {</span>
<span class="quote">&gt;  	unsigned int id;</span>
<span class="quote">&gt;  	unsigned int active;</span>
<span class="quote">&gt;  	unsigned long vdso_base;</span>
<span class="quote">&gt; +#ifdef CONFIG_PPC_MM_SLICES</span>
<span class="quote">&gt; +	u16 user_psize;		/* page size index */</span>
<span class="quote">&gt; +	u64 low_slices_psize;	/* page size encodings */</span>
<span class="quote">&gt; +	unsigned char high_slices_psize[0];</span>
<span class="quote">&gt; +	unsigned long slb_addr_limit;</span>
<span class="quote">&gt; +#endif</span>
<span class="quote">&gt;  } mm_context_t;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  #define PHYS_IMMR_BASE (mfspr(SPRN_IMMR) &amp; 0xfff80000)</span>
<span class="quote">&gt; diff --git a/arch/powerpc/include/asm/page.h b/arch/powerpc/include/asm/page.h</span>
<span class="quote">&gt; index 8da5d4c1cab2..d0384f9db9eb 100644</span>
<span class="quote">&gt; --- a/arch/powerpc/include/asm/page.h</span>
<span class="quote">&gt; +++ b/arch/powerpc/include/asm/page.h</span>
<span class="quote">&gt; @@ -342,6 +342,20 @@ typedef struct page *pgtable_t;</span>
<span class="quote">&gt;  #endif</span>
<span class="quote">&gt;  #endif</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; +#ifdef CONFIG_PPC_MM_SLICES</span>
<span class="quote">&gt; +struct mm_struct;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +unsigned long slice_get_unmapped_area(unsigned long addr, unsigned long len,</span>
<span class="quote">&gt; +				      unsigned long flags, unsigned int psize,</span>
<span class="quote">&gt; +				      int topdown);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +unsigned int get_slice_psize(struct mm_struct *mm, unsigned long addr);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +void slice_set_user_psize(struct mm_struct *mm, unsigned int psize);</span>
<span class="quote">&gt; +void slice_set_range_psize(struct mm_struct *mm, unsigned long start,</span>
<span class="quote">&gt; +			   unsigned long len, unsigned int psize);</span>
<span class="quote">&gt; +#endif</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt;  #include &lt;asm-generic/memory_model.h&gt;</span>
<span class="quote">&gt;  #endif /* __ASSEMBLY__ */</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; diff --git a/arch/powerpc/include/asm/page_32.h b/arch/powerpc/include/asm/page_32.h</span>
<span class="quote">&gt; index 5c378e9b78c8..f7d1bd1183c8 100644</span>
<span class="quote">&gt; --- a/arch/powerpc/include/asm/page_32.h</span>
<span class="quote">&gt; +++ b/arch/powerpc/include/asm/page_32.h</span>
<span class="quote">&gt; @@ -60,4 +60,23 @@ extern void copy_page(void *to, void *from);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  #endif /* __ASSEMBLY__ */</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; +#ifdef CONFIG_PPC_MM_SLICES</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +#define SLICE_LOW_SHIFT		28</span>
<span class="quote">&gt; +#define SLICE_HIGH_SHIFT	0</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +#define SLICE_LOW_TOP		(0xfffffffful)</span>
<span class="quote">&gt; +#define SLICE_NUM_LOW		((SLICE_LOW_TOP &gt;&gt; SLICE_LOW_SHIFT) + 1)</span>
<span class="quote">&gt; +#define SLICE_NUM_HIGH		0ul</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +#define GET_LOW_SLICE_INDEX(addr)	((addr) &gt;&gt; SLICE_LOW_SHIFT)</span>
<span class="quote">&gt; +#define GET_HIGH_SLICE_INDEX(addr)	(addr &amp; 0)</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +#ifdef CONFIG_HUGETLB_PAGE</span>
<span class="quote">&gt; +#define HAVE_ARCH_HUGETLB_UNMAPPED_AREA</span>
<span class="quote">&gt; +#endif</span>
<span class="quote">&gt; +#define HAVE_ARCH_UNMAPPED_AREA</span>
<span class="quote">&gt; +#define HAVE_ARCH_UNMAPPED_AREA_TOPDOWN</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +#endif</span>
<span class="quote">&gt;  #endif /* _ASM_POWERPC_PAGE_32_H */</span>
<span class="quote">&gt; diff --git a/arch/powerpc/include/asm/page_64.h b/arch/powerpc/include/asm/page_64.h</span>
<span class="quote">&gt; index 56234c6fcd61..a7baef5bbe5f 100644</span>
<span class="quote">&gt; --- a/arch/powerpc/include/asm/page_64.h</span>
<span class="quote">&gt; +++ b/arch/powerpc/include/asm/page_64.h</span>
<span class="quote">&gt; @@ -91,30 +91,13 @@ extern u64 ppc64_pft_size;</span>
<span class="quote">&gt;  #define SLICE_LOW_SHIFT		28</span>
<span class="quote">&gt;  #define SLICE_HIGH_SHIFT	40</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; -#define SLICE_LOW_TOP		(0x100000000ul)</span>
<span class="quote">&gt; -#define SLICE_NUM_LOW		(SLICE_LOW_TOP &gt;&gt; SLICE_LOW_SHIFT)</span>
<span class="quote">&gt; +#define SLICE_LOW_TOP		(0xfffffffful)</span>
<span class="quote">&gt; +#define SLICE_NUM_LOW		((SLICE_LOW_TOP &gt;&gt; SLICE_LOW_SHIFT) + 1)</span>
<span class="quote">&gt;  #define SLICE_NUM_HIGH		(H_PGTABLE_RANGE &gt;&gt; SLICE_HIGH_SHIFT)</span>


Why are you changing this? is this a bug fix?
<span class="quote">
&gt;  </span>
<span class="quote">&gt;  #define GET_LOW_SLICE_INDEX(addr)	((addr) &gt;&gt; SLICE_LOW_SHIFT)</span>
<span class="quote">&gt;  #define GET_HIGH_SLICE_INDEX(addr)	((addr) &gt;&gt; SLICE_HIGH_SHIFT)</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; -#ifndef __ASSEMBLY__</span>
<span class="quote">&gt; -struct mm_struct;</span>
<span class="quote">&gt; -</span>
<span class="quote">&gt; -extern unsigned long slice_get_unmapped_area(unsigned long addr,</span>
<span class="quote">&gt; -					     unsigned long len,</span>
<span class="quote">&gt; -					     unsigned long flags,</span>
<span class="quote">&gt; -					     unsigned int psize,</span>
<span class="quote">&gt; -					     int topdown);</span>
<span class="quote">&gt; -</span>
<span class="quote">&gt; -extern unsigned int get_slice_psize(struct mm_struct *mm,</span>
<span class="quote">&gt; -				    unsigned long addr);</span>
<span class="quote">&gt; -</span>
<span class="quote">&gt; -extern void slice_set_user_psize(struct mm_struct *mm, unsigned int psize);</span>
<span class="quote">&gt; -extern void slice_set_range_psize(struct mm_struct *mm, unsigned long start,</span>
<span class="quote">&gt; -				  unsigned long len, unsigned int psize);</span>
<span class="quote">&gt; -</span>
<span class="quote">&gt; -#endif /* __ASSEMBLY__ */</span>
<span class="quote">&gt;  #else</span>
<span class="quote">&gt;  #define slice_init()</span>
<span class="quote">&gt;  #ifdef CONFIG_PPC_BOOK3S_64</span>
<span class="quote">&gt; diff --git a/arch/powerpc/kernel/setup-common.c b/arch/powerpc/kernel/setup-common.c</span>
<span class="quote">&gt; index 9d213542a48b..a285e1067713 100644</span>
<span class="quote">&gt; --- a/arch/powerpc/kernel/setup-common.c</span>
<span class="quote">&gt; +++ b/arch/powerpc/kernel/setup-common.c</span>
<span class="quote">&gt; @@ -928,7 +928,7 @@ void __init setup_arch(char **cmdline_p)</span>
<span class="quote">&gt;  	if (!radix_enabled())</span>
<span class="quote">&gt;  		init_mm.context.slb_addr_limit = DEFAULT_MAP_WINDOW_USER64;</span>
<span class="quote">&gt;  #else</span>
<span class="quote">&gt; -#error	&quot;context.addr_limit not initialized.&quot;</span>
<span class="quote">&gt; +	init_mm.context.slb_addr_limit = DEFAULT_MAP_WINDOW;</span>
<span class="quote">&gt;  #endif</span>


May be put this within #ifdef 8XX and retain the error?
<span class="quote">
&gt;  #endif</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; diff --git a/arch/powerpc/mm/8xx_mmu.c b/arch/powerpc/mm/8xx_mmu.c</span>
<span class="quote">&gt; index f29212e40f40..0be77709446c 100644</span>
<span class="quote">&gt; --- a/arch/powerpc/mm/8xx_mmu.c</span>
<span class="quote">&gt; +++ b/arch/powerpc/mm/8xx_mmu.c</span>
<span class="quote">&gt; @@ -192,7 +192,7 @@ void set_context(unsigned long id, pgd_t *pgd)</span>
<span class="quote">&gt;  	mtspr(SPRN_M_TW, __pa(pgd) - offset);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	/* Update context */</span>
<span class="quote">&gt; -	mtspr(SPRN_M_CASID, id);</span>
<span class="quote">&gt; +	mtspr(SPRN_M_CASID, id - 1);</span>
<span class="quote">&gt;  	/* sync */</span>
<span class="quote">&gt;  	mb();</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt; diff --git a/arch/powerpc/mm/hash_utils_64.c b/arch/powerpc/mm/hash_utils_64.c</span>
<span class="quote">&gt; index 655a5a9a183d..3266b3326088 100644</span>
<span class="quote">&gt; --- a/arch/powerpc/mm/hash_utils_64.c</span>
<span class="quote">&gt; +++ b/arch/powerpc/mm/hash_utils_64.c</span>
<span class="quote">&gt; @@ -1101,7 +1101,7 @@ static unsigned int get_paca_psize(unsigned long addr)</span>
<span class="quote">&gt;  	unsigned char *hpsizes;</span>
<span class="quote">&gt;  	unsigned long index, mask_index;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; -	if (addr &lt; SLICE_LOW_TOP) {</span>
<span class="quote">&gt; +	if (addr &lt;= SLICE_LOW_TOP) {</span>

If this is part of bug fix, please do it as part of seperate patch with details
<span class="quote">

&gt;  		lpsizes = get_paca()-&gt;mm_ctx_low_slices_psize;</span>
<span class="quote">&gt;  		index = GET_LOW_SLICE_INDEX(addr);</span>
<span class="quote">&gt;  		return (lpsizes &gt;&gt; (index * 4)) &amp; 0xF;</span>
<span class="quote">&gt; diff --git a/arch/powerpc/mm/hugetlbpage.c b/arch/powerpc/mm/hugetlbpage.c</span>
<span class="quote">&gt; index a9b9083c5e49..79e1378ee303 100644</span>
<span class="quote">&gt; --- a/arch/powerpc/mm/hugetlbpage.c</span>
<span class="quote">&gt; +++ b/arch/powerpc/mm/hugetlbpage.c</span>
<span class="quote">&gt; @@ -553,9 +553,11 @@ unsigned long hugetlb_get_unmapped_area(struct file *file, unsigned long addr,</span>
<span class="quote">&gt;  	struct hstate *hstate = hstate_file(file);</span>
<span class="quote">&gt;  	int mmu_psize = shift_to_mmu_psize(huge_page_shift(hstate));</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; +#ifdef CONFIG_PPC_RADIX_MMU</span>
<span class="quote">&gt;  	if (radix_enabled())</span>
<span class="quote">&gt;  		return radix__hugetlb_get_unmapped_area(file, addr, len,</span>
<span class="quote">&gt;  						       pgoff, flags);</span>
<span class="quote">&gt; +#endif</span>
<span class="quote">&gt;  	return slice_get_unmapped_area(addr, len, flags, mmu_psize, 1);</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;  #endif</span>
<span class="quote">&gt; diff --git a/arch/powerpc/mm/mmu_context_nohash.c b/arch/powerpc/mm/mmu_context_nohash.c</span>
<span class="quote">&gt; index 4554d6527682..c1e1bf186871 100644</span>
<span class="quote">&gt; --- a/arch/powerpc/mm/mmu_context_nohash.c</span>
<span class="quote">&gt; +++ b/arch/powerpc/mm/mmu_context_nohash.c</span>
<span class="quote">&gt; @@ -331,6 +331,13 @@ int init_new_context(struct task_struct *t, struct mm_struct *mm)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	pr_hard(&quot;initing context for mm @%p\n&quot;, mm);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; +#ifdef CONFIG_PPC_MM_SLICES</span>
<span class="quote">&gt; +	if (!mm-&gt;context.slb_addr_limit)</span>
<span class="quote">&gt; +		mm-&gt;context.slb_addr_limit = DEFAULT_MAP_WINDOW;</span>
<span class="quote">&gt; +	if (!mm-&gt;context.id)</span>
<span class="quote">&gt; +		slice_set_user_psize(mm, mmu_virtual_psize);</span>
<span class="quote">&gt; +#endif</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt;  	mm-&gt;context.id = MMU_NO_CONTEXT;</span>
<span class="quote">&gt;  	mm-&gt;context.active = 0;</span>
<span class="quote">&gt;  	return 0;</span>
<span class="quote">&gt; @@ -428,8 +435,8 @@ void __init mmu_context_init(void)</span>
<span class="quote">&gt;  	 *      -- BenH</span>
<span class="quote">&gt;  	 */</span>
<span class="quote">&gt;  	if (mmu_has_feature(MMU_FTR_TYPE_8xx)) {</span>
<span class="quote">&gt; -		first_context = 0;</span>
<span class="quote">&gt; -		last_context = 15;</span>
<span class="quote">&gt; +		first_context = 1;</span>
<span class="quote">&gt; +		last_context = 16;</span>
<span class="quote">&gt;  		no_selective_tlbil = true;</span>
<span class="quote">&gt;  	} else if (mmu_has_feature(MMU_FTR_TYPE_47x)) {</span>
<span class="quote">&gt;  		first_context = 1;</span>
<span class="quote">&gt; diff --git a/arch/powerpc/mm/slice.c b/arch/powerpc/mm/slice.c</span>
<span class="quote">&gt; index 23ec2c5e3b78..1a66fafc3e45 100644</span>
<span class="quote">&gt; --- a/arch/powerpc/mm/slice.c</span>
<span class="quote">&gt; +++ b/arch/powerpc/mm/slice.c</span>
<span class="quote">&gt; @@ -73,10 +73,11 @@ static void slice_range_to_mask(unsigned long start, unsigned long len,</span>
<span class="quote">&gt;  	unsigned long end = start + len - 1;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	ret-&gt;low_slices = 0;</span>
<span class="quote">&gt; -	bitmap_zero(ret-&gt;high_slices, SLICE_NUM_HIGH);</span>
<span class="quote">&gt; +	if (SLICE_NUM_HIGH)</span>
<span class="quote">&gt; +		bitmap_zero(ret-&gt;high_slices, SLICE_NUM_HIGH);</span>

So you don&#39;t want to use high slices but just low slice? If so can you
add that as a different patch which implements just that. 
<span class="quote">

&gt;  </span>
<span class="quote">&gt; -	if (start &lt; SLICE_LOW_TOP) {</span>
<span class="quote">&gt; -		unsigned long mend = min(end, (SLICE_LOW_TOP - 1));</span>
<span class="quote">&gt; +	if (start &lt;= SLICE_LOW_TOP) {</span>
<span class="quote">&gt; +		unsigned long mend = min(end, SLICE_LOW_TOP);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  		ret-&gt;low_slices = (1u &lt;&lt; (GET_LOW_SLICE_INDEX(mend) + 1))</span>
<span class="quote">&gt;  			- (1u &lt;&lt; GET_LOW_SLICE_INDEX(start));</span>
<span class="quote">&gt; @@ -117,7 +118,7 @@ static int slice_high_has_vma(struct mm_struct *mm, unsigned long slice)</span>
<span class="quote">&gt;  	 * of the high or low area bitmaps, the first high area starts</span>
<span class="quote">&gt;  	 * at 4GB, not 0 */</span>
<span class="quote">&gt;  	if (start == 0)</span>
<span class="quote">&gt; -		start = SLICE_LOW_TOP;</span>
<span class="quote">&gt; +		start = SLICE_LOW_TOP + 1;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	return !slice_area_is_free(mm, start, end - start);</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt; @@ -128,7 +129,8 @@ static void slice_mask_for_free(struct mm_struct *mm, struct slice_mask *ret,</span>
<span class="quote">&gt;  	unsigned long i;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	ret-&gt;low_slices = 0;</span>
<span class="quote">&gt; -	bitmap_zero(ret-&gt;high_slices, SLICE_NUM_HIGH);</span>
<span class="quote">&gt; +	if (SLICE_NUM_HIGH)</span>
<span class="quote">&gt; +		bitmap_zero(ret-&gt;high_slices, SLICE_NUM_HIGH);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	for (i = 0; i &lt; SLICE_NUM_LOW; i++)</span>
<span class="quote">&gt;  		if (!slice_low_has_vma(mm, i))</span>
<span class="quote">&gt; @@ -151,7 +153,8 @@ static void slice_mask_for_size(struct mm_struct *mm, int psize, struct slice_ma</span>
<span class="quote">&gt;  	u64 lpsizes;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	ret-&gt;low_slices = 0;</span>
<span class="quote">&gt; -	bitmap_zero(ret-&gt;high_slices, SLICE_NUM_HIGH);</span>
<span class="quote">&gt; +	if (SLICE_NUM_HIGH)</span>
<span class="quote">&gt; +		bitmap_zero(ret-&gt;high_slices, SLICE_NUM_HIGH);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	lpsizes = mm-&gt;context.low_slices_psize;</span>
<span class="quote">&gt;  	for (i = 0; i &lt; SLICE_NUM_LOW; i++)</span>
<span class="quote">&gt; @@ -180,15 +183,18 @@ static int slice_check_fit(struct mm_struct *mm,</span>
<span class="quote">&gt;  	 */</span>
<span class="quote">&gt;  	unsigned long slice_count = GET_HIGH_SLICE_INDEX(mm-&gt;context.slb_addr_limit);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; -	bitmap_and(result, mask.high_slices,</span>
<span class="quote">&gt; -		   available.high_slices, slice_count);</span>
<span class="quote">&gt; +	if (SLICE_NUM_HIGH)</span>
<span class="quote">&gt; +		bitmap_and(result, mask.high_slices,</span>
<span class="quote">&gt; +			   available.high_slices, slice_count);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	return (mask.low_slices &amp; available.low_slices) == mask.low_slices &amp;&amp;</span>
<span class="quote">&gt; -		bitmap_equal(result, mask.high_slices, slice_count);</span>
<span class="quote">&gt; +		(!slice_count ||</span>
<span class="quote">&gt; +		 bitmap_equal(result, mask.high_slices, slice_count));</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  static void slice_flush_segments(void *parm)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt; +#ifdef CONFIG_PPC_BOOK3S_64</span>
<span class="quote">&gt;  	struct mm_struct *mm = parm;</span>
<span class="quote">&gt;  	unsigned long flags;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; @@ -200,6 +206,7 @@ static void slice_flush_segments(void *parm)</span>
<span class="quote">&gt;  	local_irq_save(flags);</span>
<span class="quote">&gt;  	slb_flush_and_rebolt();</span>
<span class="quote">&gt;  	local_irq_restore(flags);</span>
<span class="quote">&gt; +#endif</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  static void slice_convert(struct mm_struct *mm, struct slice_mask mask, int psize)</span>
<span class="quote">&gt; @@ -259,7 +266,7 @@ static bool slice_scan_available(unsigned long addr,</span>
<span class="quote">&gt;  				 unsigned long *boundary_addr)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	unsigned long slice;</span>
<span class="quote">&gt; -	if (addr &lt; SLICE_LOW_TOP) {</span>
<span class="quote">&gt; +	if (addr &lt;= SLICE_LOW_TOP) {</span>
<span class="quote">&gt;  		slice = GET_LOW_SLICE_INDEX(addr);</span>
<span class="quote">&gt;  		*boundary_addr = (slice + end) &lt;&lt; SLICE_LOW_SHIFT;</span>
<span class="quote">&gt;  		return !!(available.low_slices &amp; (1u &lt;&lt; slice));</span>
<span class="quote">&gt; @@ -391,8 +398,11 @@ static inline void slice_or_mask(struct slice_mask *dst, struct slice_mask *src)</span>
<span class="quote">&gt;  	DECLARE_BITMAP(result, SLICE_NUM_HIGH);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	dst-&gt;low_slices |= src-&gt;low_slices;</span>
<span class="quote">&gt; -	bitmap_or(result, dst-&gt;high_slices, src-&gt;high_slices, SLICE_NUM_HIGH);</span>
<span class="quote">&gt; -	bitmap_copy(dst-&gt;high_slices, result, SLICE_NUM_HIGH);</span>
<span class="quote">&gt; +	if (SLICE_NUM_HIGH) {</span>
<span class="quote">&gt; +		bitmap_or(result, dst-&gt;high_slices, src-&gt;high_slices,</span>
<span class="quote">&gt; +			  SLICE_NUM_HIGH);</span>
<span class="quote">&gt; +		bitmap_copy(dst-&gt;high_slices, result, SLICE_NUM_HIGH);</span>
<span class="quote">&gt; +	}</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  static inline void slice_andnot_mask(struct slice_mask *dst, struct slice_mask *src)</span>
<span class="quote">&gt; @@ -401,12 +411,17 @@ static inline void slice_andnot_mask(struct slice_mask *dst, struct slice_mask *</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	dst-&gt;low_slices &amp;= ~src-&gt;low_slices;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; -	bitmap_andnot(result, dst-&gt;high_slices, src-&gt;high_slices, SLICE_NUM_HIGH);</span>
<span class="quote">&gt; -	bitmap_copy(dst-&gt;high_slices, result, SLICE_NUM_HIGH);</span>
<span class="quote">&gt; +	if (SLICE_NUM_HIGH) {</span>
<span class="quote">&gt; +		bitmap_andnot(result, dst-&gt;high_slices, src-&gt;high_slices,</span>
<span class="quote">&gt; +			      SLICE_NUM_HIGH);</span>
<span class="quote">&gt; +		bitmap_copy(dst-&gt;high_slices, result, SLICE_NUM_HIGH);</span>
<span class="quote">&gt; +	}</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  #ifdef CONFIG_PPC_64K_PAGES</span>
<span class="quote">&gt;  #define MMU_PAGE_BASE	MMU_PAGE_64K</span>
<span class="quote">&gt; +#elif defined(CONFIG_PPC_16K_PAGES)</span>
<span class="quote">&gt; +#define MMU_PAGE_BASE	MMU_PAGE_16K</span>
<span class="quote">&gt;  #else</span>
<span class="quote">&gt;  #define MMU_PAGE_BASE	MMU_PAGE_4K</span>
<span class="quote">&gt;  #endif</span>

I am not sure we want them based on page size. The rule is we flush
segments on book3s63 if the page size is different from MMU_PAGE_BASE 
<span class="quote">

&gt; @@ -450,14 +465,17 @@ unsigned long slice_get_unmapped_area(unsigned long addr, unsigned long len,</span>
<span class="quote">&gt;  	 * init different masks</span>
<span class="quote">&gt;  	 */</span>
<span class="quote">&gt;  	mask.low_slices = 0;</span>
<span class="quote">&gt; -	bitmap_zero(mask.high_slices, SLICE_NUM_HIGH);</span>
<span class="quote">&gt; +	if (SLICE_NUM_HIGH)</span>
<span class="quote">&gt; +		bitmap_zero(mask.high_slices, SLICE_NUM_HIGH);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	/* silence stupid warning */;</span>
<span class="quote">&gt;  	potential_mask.low_slices = 0;</span>
<span class="quote">&gt; -	bitmap_zero(potential_mask.high_slices, SLICE_NUM_HIGH);</span>
<span class="quote">&gt; +	if (SLICE_NUM_HIGH)</span>
<span class="quote">&gt; +		bitmap_zero(potential_mask.high_slices, SLICE_NUM_HIGH);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	compat_mask.low_slices = 0;</span>
<span class="quote">&gt; -	bitmap_zero(compat_mask.high_slices, SLICE_NUM_HIGH);</span>
<span class="quote">&gt; +	if (SLICE_NUM_HIGH)</span>
<span class="quote">&gt; +		bitmap_zero(compat_mask.high_slices, SLICE_NUM_HIGH);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  	/* Sanity checks */</span>
<span class="quote">&gt;  	BUG_ON(mm-&gt;task_size == 0);</span>
<span class="quote">&gt; @@ -595,7 +613,9 @@ unsigned long slice_get_unmapped_area(unsigned long addr, unsigned long len,</span>
<span class="quote">&gt;   convert:</span>
<span class="quote">&gt;  	slice_andnot_mask(&amp;mask, &amp;good_mask);</span>
<span class="quote">&gt;  	slice_andnot_mask(&amp;mask, &amp;compat_mask);</span>
<span class="quote">&gt; -	if (mask.low_slices || !bitmap_empty(mask.high_slices, SLICE_NUM_HIGH)) {</span>
<span class="quote">&gt; +	if (mask.low_slices ||</span>
<span class="quote">&gt; +	    (SLICE_NUM_HIGH &amp;&amp;</span>
<span class="quote">&gt; +	     !bitmap_empty(mask.high_slices, SLICE_NUM_HIGH))) {</span>
<span class="quote">&gt;  		slice_convert(mm, mask, psize);</span>
<span class="quote">&gt;  		if (psize &gt; MMU_PAGE_BASE)</span>
<span class="quote">&gt;  			on_each_cpu(slice_flush_segments, mm, 1);</span>
<span class="quote">&gt; @@ -640,7 +660,7 @@ unsigned int get_slice_psize(struct mm_struct *mm, unsigned long addr)</span>
<span class="quote">&gt;  		return MMU_PAGE_4K;</span>
<span class="quote">&gt;  #endif</span>
<span class="quote">&gt;  	}</span>
<span class="quote">&gt; -	if (addr &lt; SLICE_LOW_TOP) {</span>
<span class="quote">&gt; +	if (addr &lt;= SLICE_LOW_TOP) {</span>
<span class="quote">&gt;  		u64 lpsizes;</span>
<span class="quote">&gt;  		lpsizes = mm-&gt;context.low_slices_psize;</span>
<span class="quote">&gt;  		index = GET_LOW_SLICE_INDEX(addr);</span>
<span class="quote">&gt; diff --git a/arch/powerpc/platforms/Kconfig.cputype b/arch/powerpc/platforms/Kconfig.cputype</span>
<span class="quote">&gt; index ae07470fde3c..73a7ea333e9e 100644</span>
<span class="quote">&gt; --- a/arch/powerpc/platforms/Kconfig.cputype</span>
<span class="quote">&gt; +++ b/arch/powerpc/platforms/Kconfig.cputype</span>
<span class="quote">&gt; @@ -334,6 +334,7 @@ config PPC_BOOK3E_MMU</span>
<span class="quote">&gt;  config PPC_MM_SLICES</span>
<span class="quote">&gt;  	bool</span>
<span class="quote">&gt;  	default y if PPC_BOOK3S_64</span>
<span class="quote">&gt; +	default y if PPC_8xx &amp;&amp; HUGETLB_PAGE</span>
<span class="quote">&gt;  	default n</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  config PPC_HAVE_PMU_SUPPORT</span>
<span class="quote">&gt; -- </span>
<span class="quote">&gt; 2.13.3</span>
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=11492">LEROY Christophe</a> - Jan. 16, 2018, 4:31 p.m.</div>
<pre class="content">
Le 16/01/2018 à 16:49, Aneesh Kumar K.V a écrit :
<span class="quote">&gt; Christophe Leroy &lt;christophe.leroy@c-s.fr&gt; writes:</span>
<span class="quote">&gt; </span>
<span class="quote">&gt;&gt; When an app has some regular pages allocated (e.g. see below) and tries</span>
<span class="quote">&gt;&gt; to mmap() a huge page at a hint address covered by the same PMD entry,</span>
<span class="quote">&gt;&gt; the kernel accepts the hint allthough the 8xx cannot handle different</span>
<span class="quote">&gt;&gt; page sizes in the same PMD entry.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; </span>
<span class="quote">&gt; So that is a bug in get_unmapped_area function that you are using and</span>
<span class="quote">&gt; you want to fix that by using the slice code. Can you describe here what</span>
<span class="quote">&gt; the allocation restrictions are w.r.t 8xx? Do they have segments and</span>
<span class="quote">&gt; base page size like hash64?</span>

I don&#39;t think it is a bug in get_unmapped_area() that is used by 
default. It is that some HW do support mixing any page size in the same 
page table (eg BOOK3E ?), but the 8xx doesn&#39;t.
In the 8xx, the page size is defined in the PGD entry, then all pages 
defined in a given page table pointed by a PGD entry have the same size.

So it is similar to segments if you consider each PGD entry as a kind of 
segment
<span class="quote">
&gt; </span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; 10000000-10001000 r-xp 00000000 00:0f 2597 /root/malloc</span>
<span class="quote">&gt;&gt; 10010000-10011000 rwxp 00000000 00:0f 2597 /root/malloc</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; mmap(0x10080000, 524288, PROT_READ|PROT_WRITE,</span>
<span class="quote">&gt;&gt;       MAP_PRIVATE|MAP_ANONYMOUS|0x40000, -1, 0) = 0x10080000</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; This results in the following warning, and the app remains forever in</span>
<span class="quote">&gt;&gt; do_page_fault()/hugetlb_fault()</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; [162980.035629] WARNING: CPU: 0 PID: 2777 at arch/powerpc/mm/hugetlbpage.c:354 hugetlb_free_pgd_range+0xc8/0x1e4</span>
<span class="quote">&gt;&gt; [162980.035699] CPU: 0 PID: 2777 Comm: malloc Tainted: G W       4.14.6 #85</span>
<span class="quote">&gt;&gt; [162980.035744] task: c67e2c00 task.stack: c668e000</span>
<span class="quote">&gt;&gt; [162980.035783] NIP:  c000fe18 LR: c00e1eec CTR: c00f90c0</span>
<span class="quote">&gt;&gt; [162980.035830] REGS: c668fc20 TRAP: 0700   Tainted: G W        (4.14.6)</span>
<span class="quote">&gt;&gt; [162980.035854] MSR:  00029032 &lt;EE,ME,IR,DR,RI&gt;  CR: 24044224 XER: 20000000</span>
<span class="quote">&gt;&gt; [162980.036003]</span>
<span class="quote">&gt;&gt; [162980.036003] GPR00: c00e1eec c668fcd0 c67e2c00 00000010 c6869410 10080000 00000000 77fb4000</span>
<span class="quote">&gt;&gt; [162980.036003] GPR08: ffff0001 0683c001 00000000 ffffff80 44028228 10018a34 00004008 418004fc</span>
<span class="quote">&gt;&gt; [162980.036003] GPR16: c668e000 00040100 c668e000 c06c0000 c668fe78 c668e000 c6835ba0 c668fd48</span>
<span class="quote">&gt;&gt; [162980.036003] GPR24: 00000000 73ffffff 74000000 00000001 77fb4000 100fffff 10100000 10100000</span>
<span class="quote">&gt;&gt; [162980.036743] NIP [c000fe18] hugetlb_free_pgd_range+0xc8/0x1e4</span>
<span class="quote">&gt;&gt; [162980.036839] LR [c00e1eec] free_pgtables+0x12c/0x150</span>
<span class="quote">&gt;&gt; [162980.036861] Call Trace:</span>
<span class="quote">&gt;&gt; [162980.036939] [c668fcd0] [c00f0774] unlink_anon_vmas+0x1c4/0x214 (unreliable)</span>
<span class="quote">&gt;&gt; [162980.037040] [c668fd10] [c00e1eec] free_pgtables+0x12c/0x150</span>
<span class="quote">&gt;&gt; [162980.037118] [c668fd40] [c00eabac] exit_mmap+0xe8/0x1b4</span>
<span class="quote">&gt;&gt; [162980.037210] [c668fda0] [c0019710] mmput.part.9+0x20/0xd8</span>
<span class="quote">&gt;&gt; [162980.037301] [c668fdb0] [c001ecb0] do_exit+0x1f0/0x93c</span>
<span class="quote">&gt;&gt; [162980.037386] [c668fe00] [c001f478] do_group_exit+0x40/0xcc</span>
<span class="quote">&gt;&gt; [162980.037479] [c668fe10] [c002a76c] get_signal+0x47c/0x614</span>
<span class="quote">&gt;&gt; [162980.037570] [c668fe70] [c0007840] do_signal+0x54/0x244</span>
<span class="quote">&gt;&gt; [162980.037654] [c668ff30] [c0007ae8] do_notify_resume+0x34/0x88</span>
<span class="quote">&gt;&gt; [162980.037744] [c668ff40] [c000dae8] do_user_signal+0x74/0xc4</span>
<span class="quote">&gt;&gt; [162980.037781] Instruction dump:</span>
<span class="quote">&gt;&gt; [162980.037821] 7fdff378 81370000 54a3463a 80890020 7d24182e 7c841a14 712a0004 4082ff94</span>
<span class="quote">&gt;&gt; [162980.038014] 2f890000 419e0010 712a0ff0 408200e0 &lt;0fe00000&gt; 54a9000a 7f984840 419d0094</span>
<span class="quote">&gt;&gt; [162980.038216] ---[ end trace c0ceeca8e7a5800a ]---</span>
<span class="quote">&gt;&gt; [162980.038754] BUG: non-zero nr_ptes on freeing mm: 1</span>
<span class="quote">&gt;&gt; [162985.363322] BUG: non-zero nr_ptes on freeing mm: -1</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; In order to fix this, the address space &quot;slices&quot; implemented</span>
<span class="quote">&gt;&gt; for BOOK3S/64 is reused.</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; This patch:</span>
<span class="quote">&gt;&gt; 1/ Modifies the &quot;slices&quot; implementation to support 32 bits CPUs,</span>
<span class="quote">&gt;&gt; based on using only the low slices.</span>
<span class="quote">&gt;&gt; 2/ Moves &quot;slices&quot; functions prototypes from page64.h to page.h</span>
<span class="quote">&gt;&gt; 3/ Modifies the context.id on the 8xx to be in the range [1:16]</span>
<span class="quote">&gt;&gt; instead of [0:15] in order to identify context.id == 0 as</span>
<span class="quote">&gt;&gt; not initialised contexts</span>
<span class="quote">&gt;&gt; 4/ Activates CONFIG_PPC_MM_SLICES when CONFIG_HUGETLB_PAGE is</span>
<span class="quote">&gt;&gt; selected for the 8xx</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; Alltough we could in theory have as many slices as PMD entries, the current</span>
<span class="quote">&gt;&gt; slices implementation limits the number of low slices to 16.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Can you explain this more?</span>

As you commented in your other mail, mm_context_t.low_slice_psize which 
is of type 64 and need 4 bits per each slice to store the segment base
page size details, so the maximum number of low slices is 64/4=16
<span class="quote">

&gt; </span>
<span class="quote">&gt; </span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; Fixes: 4b91428699477 (&quot;powerpc/8xx: Implement support of hugepages&quot;)</span>
<span class="quote">&gt;&gt; Signed-off-by: Christophe Leroy &lt;christophe.leroy@c-s.fr&gt;</span>
<span class="quote">&gt;&gt; ---</span>
<span class="quote">&gt;&gt;   arch/powerpc/include/asm/mmu-8xx.h     |  6 ++++</span>
<span class="quote">&gt;&gt;   arch/powerpc/include/asm/page.h        | 14 ++++++++</span>
<span class="quote">&gt;&gt;   arch/powerpc/include/asm/page_32.h     | 19 +++++++++++</span>
<span class="quote">&gt;&gt;   arch/powerpc/include/asm/page_64.h     | 21 ++----------</span>
<span class="quote">&gt;&gt;   arch/powerpc/kernel/setup-common.c     |  2 +-</span>
<span class="quote">&gt;&gt;   arch/powerpc/mm/8xx_mmu.c              |  2 +-</span>
<span class="quote">&gt;&gt;   arch/powerpc/mm/hash_utils_64.c        |  2 +-</span>
<span class="quote">&gt;&gt;   arch/powerpc/mm/hugetlbpage.c          |  2 ++</span>
<span class="quote">&gt;&gt;   arch/powerpc/mm/mmu_context_nohash.c   | 11 +++++--</span>
<span class="quote">&gt;&gt;   arch/powerpc/mm/slice.c                | 58 +++++++++++++++++++++++-----------</span>
<span class="quote">&gt;&gt;   arch/powerpc/platforms/Kconfig.cputype |  1 +</span>
<span class="quote">&gt;&gt;   11 files changed, 95 insertions(+), 43 deletions(-)</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; diff --git a/arch/powerpc/include/asm/mmu-8xx.h b/arch/powerpc/include/asm/mmu-8xx.h</span>
<span class="quote">&gt;&gt; index 5bb3dbede41a..5f89b6010453 100644</span>
<span class="quote">&gt;&gt; --- a/arch/powerpc/include/asm/mmu-8xx.h</span>
<span class="quote">&gt;&gt; +++ b/arch/powerpc/include/asm/mmu-8xx.h</span>
<span class="quote">&gt;&gt; @@ -169,6 +169,12 @@ typedef struct {</span>
<span class="quote">&gt;&gt;   	unsigned int id;</span>
<span class="quote">&gt;&gt;   	unsigned int active;</span>
<span class="quote">&gt;&gt;   	unsigned long vdso_base;</span>
<span class="quote">&gt;&gt; +#ifdef CONFIG_PPC_MM_SLICES</span>
<span class="quote">&gt;&gt; +	u16 user_psize;		/* page size index */</span>
<span class="quote">&gt;&gt; +	u64 low_slices_psize;	/* page size encodings */</span>
<span class="quote">&gt;&gt; +	unsigned char high_slices_psize[0];</span>
<span class="quote">&gt;&gt; +	unsigned long slb_addr_limit;</span>
<span class="quote">&gt;&gt; +#endif</span>
<span class="quote">&gt;&gt;   } mm_context_t;</span>
<span class="quote">&gt;&gt;   </span>
<span class="quote">&gt;&gt;   #define PHYS_IMMR_BASE (mfspr(SPRN_IMMR) &amp; 0xfff80000)</span>
<span class="quote">&gt;&gt; diff --git a/arch/powerpc/include/asm/page.h b/arch/powerpc/include/asm/page.h</span>
<span class="quote">&gt;&gt; index 8da5d4c1cab2..d0384f9db9eb 100644</span>
<span class="quote">&gt;&gt; --- a/arch/powerpc/include/asm/page.h</span>
<span class="quote">&gt;&gt; +++ b/arch/powerpc/include/asm/page.h</span>
<span class="quote">&gt;&gt; @@ -342,6 +342,20 @@ typedef struct page *pgtable_t;</span>
<span class="quote">&gt;&gt;   #endif</span>
<span class="quote">&gt;&gt;   #endif</span>
<span class="quote">&gt;&gt;   </span>
<span class="quote">&gt;&gt; +#ifdef CONFIG_PPC_MM_SLICES</span>
<span class="quote">&gt;&gt; +struct mm_struct;</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +unsigned long slice_get_unmapped_area(unsigned long addr, unsigned long len,</span>
<span class="quote">&gt;&gt; +				      unsigned long flags, unsigned int psize,</span>
<span class="quote">&gt;&gt; +				      int topdown);</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +unsigned int get_slice_psize(struct mm_struct *mm, unsigned long addr);</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +void slice_set_user_psize(struct mm_struct *mm, unsigned int psize);</span>
<span class="quote">&gt;&gt; +void slice_set_range_psize(struct mm_struct *mm, unsigned long start,</span>
<span class="quote">&gt;&gt; +			   unsigned long len, unsigned int psize);</span>
<span class="quote">&gt;&gt; +#endif</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt;   #include &lt;asm-generic/memory_model.h&gt;</span>
<span class="quote">&gt;&gt;   #endif /* __ASSEMBLY__ */</span>
<span class="quote">&gt;&gt;   </span>
<span class="quote">&gt;&gt; diff --git a/arch/powerpc/include/asm/page_32.h b/arch/powerpc/include/asm/page_32.h</span>
<span class="quote">&gt;&gt; index 5c378e9b78c8..f7d1bd1183c8 100644</span>
<span class="quote">&gt;&gt; --- a/arch/powerpc/include/asm/page_32.h</span>
<span class="quote">&gt;&gt; +++ b/arch/powerpc/include/asm/page_32.h</span>
<span class="quote">&gt;&gt; @@ -60,4 +60,23 @@ extern void copy_page(void *to, void *from);</span>
<span class="quote">&gt;&gt;   </span>
<span class="quote">&gt;&gt;   #endif /* __ASSEMBLY__ */</span>
<span class="quote">&gt;&gt;   </span>
<span class="quote">&gt;&gt; +#ifdef CONFIG_PPC_MM_SLICES</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +#define SLICE_LOW_SHIFT		28</span>
<span class="quote">&gt;&gt; +#define SLICE_HIGH_SHIFT	0</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +#define SLICE_LOW_TOP		(0xfffffffful)</span>
<span class="quote">&gt;&gt; +#define SLICE_NUM_LOW		((SLICE_LOW_TOP &gt;&gt; SLICE_LOW_SHIFT) + 1)</span>
<span class="quote">&gt;&gt; +#define SLICE_NUM_HIGH		0ul</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +#define GET_LOW_SLICE_INDEX(addr)	((addr) &gt;&gt; SLICE_LOW_SHIFT)</span>
<span class="quote">&gt;&gt; +#define GET_HIGH_SLICE_INDEX(addr)	(addr &amp; 0)</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +#ifdef CONFIG_HUGETLB_PAGE</span>
<span class="quote">&gt;&gt; +#define HAVE_ARCH_HUGETLB_UNMAPPED_AREA</span>
<span class="quote">&gt;&gt; +#endif</span>
<span class="quote">&gt;&gt; +#define HAVE_ARCH_UNMAPPED_AREA</span>
<span class="quote">&gt;&gt; +#define HAVE_ARCH_UNMAPPED_AREA_TOPDOWN</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +#endif</span>
<span class="quote">&gt;&gt;   #endif /* _ASM_POWERPC_PAGE_32_H */</span>
<span class="quote">&gt;&gt; diff --git a/arch/powerpc/include/asm/page_64.h b/arch/powerpc/include/asm/page_64.h</span>
<span class="quote">&gt;&gt; index 56234c6fcd61..a7baef5bbe5f 100644</span>
<span class="quote">&gt;&gt; --- a/arch/powerpc/include/asm/page_64.h</span>
<span class="quote">&gt;&gt; +++ b/arch/powerpc/include/asm/page_64.h</span>
<span class="quote">&gt;&gt; @@ -91,30 +91,13 @@ extern u64 ppc64_pft_size;</span>
<span class="quote">&gt;&gt;   #define SLICE_LOW_SHIFT		28</span>
<span class="quote">&gt;&gt;   #define SLICE_HIGH_SHIFT	40</span>
<span class="quote">&gt;&gt;   </span>
<span class="quote">&gt;&gt; -#define SLICE_LOW_TOP		(0x100000000ul)</span>
<span class="quote">&gt;&gt; -#define SLICE_NUM_LOW		(SLICE_LOW_TOP &gt;&gt; SLICE_LOW_SHIFT)</span>
<span class="quote">&gt;&gt; +#define SLICE_LOW_TOP		(0xfffffffful)</span>
<span class="quote">&gt;&gt; +#define SLICE_NUM_LOW		((SLICE_LOW_TOP &gt;&gt; SLICE_LOW_SHIFT) + 1)</span>
<span class="quote">&gt;&gt;   #define SLICE_NUM_HIGH		(H_PGTABLE_RANGE &gt;&gt; SLICE_HIGH_SHIFT)</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Why are you changing this? is this a bug fix?</span>

That&#39;s because 0x100000000ul is out of range of unsigned long on PPC32.
<span class="quote">
&gt; </span>
<span class="quote">&gt;&gt;   </span>
<span class="quote">&gt;&gt;   #define GET_LOW_SLICE_INDEX(addr)	((addr) &gt;&gt; SLICE_LOW_SHIFT)</span>
<span class="quote">&gt;&gt;   #define GET_HIGH_SLICE_INDEX(addr)	((addr) &gt;&gt; SLICE_HIGH_SHIFT)</span>
<span class="quote">&gt;&gt;   </span>
<span class="quote">&gt;&gt; -#ifndef __ASSEMBLY__</span>
<span class="quote">&gt;&gt; -struct mm_struct;</span>
<span class="quote">&gt;&gt; -</span>
<span class="quote">&gt;&gt; -extern unsigned long slice_get_unmapped_area(unsigned long addr,</span>
<span class="quote">&gt;&gt; -					     unsigned long len,</span>
<span class="quote">&gt;&gt; -					     unsigned long flags,</span>
<span class="quote">&gt;&gt; -					     unsigned int psize,</span>
<span class="quote">&gt;&gt; -					     int topdown);</span>
<span class="quote">&gt;&gt; -</span>
<span class="quote">&gt;&gt; -extern unsigned int get_slice_psize(struct mm_struct *mm,</span>
<span class="quote">&gt;&gt; -				    unsigned long addr);</span>
<span class="quote">&gt;&gt; -</span>
<span class="quote">&gt;&gt; -extern void slice_set_user_psize(struct mm_struct *mm, unsigned int psize);</span>
<span class="quote">&gt;&gt; -extern void slice_set_range_psize(struct mm_struct *mm, unsigned long start,</span>
<span class="quote">&gt;&gt; -				  unsigned long len, unsigned int psize);</span>
<span class="quote">&gt;&gt; -</span>
<span class="quote">&gt;&gt; -#endif /* __ASSEMBLY__ */</span>
<span class="quote">&gt;&gt;   #else</span>
<span class="quote">&gt;&gt;   #define slice_init()</span>
<span class="quote">&gt;&gt;   #ifdef CONFIG_PPC_BOOK3S_64</span>
<span class="quote">&gt;&gt; diff --git a/arch/powerpc/kernel/setup-common.c b/arch/powerpc/kernel/setup-common.c</span>
<span class="quote">&gt;&gt; index 9d213542a48b..a285e1067713 100644</span>
<span class="quote">&gt;&gt; --- a/arch/powerpc/kernel/setup-common.c</span>
<span class="quote">&gt;&gt; +++ b/arch/powerpc/kernel/setup-common.c</span>
<span class="quote">&gt;&gt; @@ -928,7 +928,7 @@ void __init setup_arch(char **cmdline_p)</span>
<span class="quote">&gt;&gt;   	if (!radix_enabled())</span>
<span class="quote">&gt;&gt;   		init_mm.context.slb_addr_limit = DEFAULT_MAP_WINDOW_USER64;</span>
<span class="quote">&gt;&gt;   #else</span>
<span class="quote">&gt;&gt; -#error	&quot;context.addr_limit not initialized.&quot;</span>
<span class="quote">&gt;&gt; +	init_mm.context.slb_addr_limit = DEFAULT_MAP_WINDOW;</span>
<span class="quote">&gt;&gt;   #endif</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; </span>
<span class="quote">&gt; May be put this within #ifdef 8XX and retain the error?</span>

Is this error really worth it ?
I wanted to avoid spreading too many #ifdef PPC_8xx, but ok I can do that.
<span class="quote">
&gt; </span>
<span class="quote">&gt;&gt;   #endif</span>
<span class="quote">&gt;&gt;   </span>
<span class="quote">&gt;&gt; diff --git a/arch/powerpc/mm/8xx_mmu.c b/arch/powerpc/mm/8xx_mmu.c</span>
<span class="quote">&gt;&gt; index f29212e40f40..0be77709446c 100644</span>
<span class="quote">&gt;&gt; --- a/arch/powerpc/mm/8xx_mmu.c</span>
<span class="quote">&gt;&gt; +++ b/arch/powerpc/mm/8xx_mmu.c</span>
<span class="quote">&gt;&gt; @@ -192,7 +192,7 @@ void set_context(unsigned long id, pgd_t *pgd)</span>
<span class="quote">&gt;&gt;   	mtspr(SPRN_M_TW, __pa(pgd) - offset);</span>
<span class="quote">&gt;&gt;   </span>
<span class="quote">&gt;&gt;   	/* Update context */</span>
<span class="quote">&gt;&gt; -	mtspr(SPRN_M_CASID, id);</span>
<span class="quote">&gt;&gt; +	mtspr(SPRN_M_CASID, id - 1);</span>
<span class="quote">&gt;&gt;   	/* sync */</span>
<span class="quote">&gt;&gt;   	mb();</span>
<span class="quote">&gt;&gt;   }</span>
<span class="quote">&gt;&gt; diff --git a/arch/powerpc/mm/hash_utils_64.c b/arch/powerpc/mm/hash_utils_64.c</span>
<span class="quote">&gt;&gt; index 655a5a9a183d..3266b3326088 100644</span>
<span class="quote">&gt;&gt; --- a/arch/powerpc/mm/hash_utils_64.c</span>
<span class="quote">&gt;&gt; +++ b/arch/powerpc/mm/hash_utils_64.c</span>
<span class="quote">&gt;&gt; @@ -1101,7 +1101,7 @@ static unsigned int get_paca_psize(unsigned long addr)</span>
<span class="quote">&gt;&gt;   	unsigned char *hpsizes;</span>
<span class="quote">&gt;&gt;   	unsigned long index, mask_index;</span>
<span class="quote">&gt;&gt;   </span>
<span class="quote">&gt;&gt; -	if (addr &lt; SLICE_LOW_TOP) {</span>
<span class="quote">&gt;&gt; +	if (addr &lt;= SLICE_LOW_TOP) {</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; If this is part of bug fix, please do it as part of seperate patch with details</span>

As explained above, in order to allow comparison to work on PPC32, 
SLICE_LOW_TOP has to be 0xffffffff instead of 0x100000000

How should I split in separate patches ? Something like ?
1/ Slice support for PPC32
2/ Activate slice for 8xx
<span class="quote">
&gt; </span>
<span class="quote">&gt; </span>
<span class="quote">&gt;&gt;   		lpsizes = get_paca()-&gt;mm_ctx_low_slices_psize;</span>
<span class="quote">&gt;&gt;   		index = GET_LOW_SLICE_INDEX(addr);</span>
<span class="quote">&gt;&gt;   		return (lpsizes &gt;&gt; (index * 4)) &amp; 0xF;</span>
<span class="quote">&gt;&gt; diff --git a/arch/powerpc/mm/hugetlbpage.c b/arch/powerpc/mm/hugetlbpage.c</span>
<span class="quote">&gt;&gt; index a9b9083c5e49..79e1378ee303 100644</span>
<span class="quote">&gt;&gt; --- a/arch/powerpc/mm/hugetlbpage.c</span>
<span class="quote">&gt;&gt; +++ b/arch/powerpc/mm/hugetlbpage.c</span>
<span class="quote">&gt;&gt; @@ -553,9 +553,11 @@ unsigned long hugetlb_get_unmapped_area(struct file *file, unsigned long addr,</span>
<span class="quote">&gt;&gt;   	struct hstate *hstate = hstate_file(file);</span>
<span class="quote">&gt;&gt;   	int mmu_psize = shift_to_mmu_psize(huge_page_shift(hstate));</span>
<span class="quote">&gt;&gt;   </span>
<span class="quote">&gt;&gt; +#ifdef CONFIG_PPC_RADIX_MMU</span>
<span class="quote">&gt;&gt;   	if (radix_enabled())</span>
<span class="quote">&gt;&gt;   		return radix__hugetlb_get_unmapped_area(file, addr, len,</span>
<span class="quote">&gt;&gt;   						       pgoff, flags);</span>
<span class="quote">&gt;&gt; +#endif</span>
<span class="quote">&gt;&gt;   	return slice_get_unmapped_area(addr, len, flags, mmu_psize, 1);</span>
<span class="quote">&gt;&gt;   }</span>
<span class="quote">&gt;&gt;   #endif</span>
<span class="quote">&gt;&gt; diff --git a/arch/powerpc/mm/mmu_context_nohash.c b/arch/powerpc/mm/mmu_context_nohash.c</span>
<span class="quote">&gt;&gt; index 4554d6527682..c1e1bf186871 100644</span>
<span class="quote">&gt;&gt; --- a/arch/powerpc/mm/mmu_context_nohash.c</span>
<span class="quote">&gt;&gt; +++ b/arch/powerpc/mm/mmu_context_nohash.c</span>
<span class="quote">&gt;&gt; @@ -331,6 +331,13 @@ int init_new_context(struct task_struct *t, struct mm_struct *mm)</span>
<span class="quote">&gt;&gt;   {</span>
<span class="quote">&gt;&gt;   	pr_hard(&quot;initing context for mm @%p\n&quot;, mm);</span>
<span class="quote">&gt;&gt;   </span>
<span class="quote">&gt;&gt; +#ifdef CONFIG_PPC_MM_SLICES</span>
<span class="quote">&gt;&gt; +	if (!mm-&gt;context.slb_addr_limit)</span>
<span class="quote">&gt;&gt; +		mm-&gt;context.slb_addr_limit = DEFAULT_MAP_WINDOW;</span>
<span class="quote">&gt;&gt; +	if (!mm-&gt;context.id)</span>
<span class="quote">&gt;&gt; +		slice_set_user_psize(mm, mmu_virtual_psize);</span>
<span class="quote">&gt;&gt; +#endif</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt;   	mm-&gt;context.id = MMU_NO_CONTEXT;</span>
<span class="quote">&gt;&gt;   	mm-&gt;context.active = 0;</span>
<span class="quote">&gt;&gt;   	return 0;</span>
<span class="quote">&gt;&gt; @@ -428,8 +435,8 @@ void __init mmu_context_init(void)</span>
<span class="quote">&gt;&gt;   	 *      -- BenH</span>
<span class="quote">&gt;&gt;   	 */</span>
<span class="quote">&gt;&gt;   	if (mmu_has_feature(MMU_FTR_TYPE_8xx)) {</span>
<span class="quote">&gt;&gt; -		first_context = 0;</span>
<span class="quote">&gt;&gt; -		last_context = 15;</span>
<span class="quote">&gt;&gt; +		first_context = 1;</span>
<span class="quote">&gt;&gt; +		last_context = 16;</span>
<span class="quote">&gt;&gt;   		no_selective_tlbil = true;</span>
<span class="quote">&gt;&gt;   	} else if (mmu_has_feature(MMU_FTR_TYPE_47x)) {</span>
<span class="quote">&gt;&gt;   		first_context = 1;</span>
<span class="quote">&gt;&gt; diff --git a/arch/powerpc/mm/slice.c b/arch/powerpc/mm/slice.c</span>
<span class="quote">&gt;&gt; index 23ec2c5e3b78..1a66fafc3e45 100644</span>
<span class="quote">&gt;&gt; --- a/arch/powerpc/mm/slice.c</span>
<span class="quote">&gt;&gt; +++ b/arch/powerpc/mm/slice.c</span>
<span class="quote">&gt;&gt; @@ -73,10 +73,11 @@ static void slice_range_to_mask(unsigned long start, unsigned long len,</span>
<span class="quote">&gt;&gt;   	unsigned long end = start + len - 1;</span>
<span class="quote">&gt;&gt;   </span>
<span class="quote">&gt;&gt;   	ret-&gt;low_slices = 0;</span>
<span class="quote">&gt;&gt; -	bitmap_zero(ret-&gt;high_slices, SLICE_NUM_HIGH);</span>
<span class="quote">&gt;&gt; +	if (SLICE_NUM_HIGH)</span>
<span class="quote">&gt;&gt; +		bitmap_zero(ret-&gt;high_slices, SLICE_NUM_HIGH);</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; So you don&#39;t want to use high slices but just low slice? If so can you</span>
<span class="quote">&gt; add that as a different patch which implements just that.</span>

high slices are over 0xffffffff, so pointless on PPC32.
<span class="quote">
&gt; </span>
<span class="quote">&gt; </span>
<span class="quote">&gt;&gt;   </span>
<span class="quote">&gt;&gt; -	if (start &lt; SLICE_LOW_TOP) {</span>
<span class="quote">&gt;&gt; -		unsigned long mend = min(end, (SLICE_LOW_TOP - 1));</span>
<span class="quote">&gt;&gt; +	if (start &lt;= SLICE_LOW_TOP) {</span>
<span class="quote">&gt;&gt; +		unsigned long mend = min(end, SLICE_LOW_TOP);</span>
<span class="quote">&gt;&gt;   </span>
<span class="quote">&gt;&gt;   		ret-&gt;low_slices = (1u &lt;&lt; (GET_LOW_SLICE_INDEX(mend) + 1))</span>
<span class="quote">&gt;&gt;   			- (1u &lt;&lt; GET_LOW_SLICE_INDEX(start));</span>
<span class="quote">&gt;&gt; @@ -117,7 +118,7 @@ static int slice_high_has_vma(struct mm_struct *mm, unsigned long slice)</span>
<span class="quote">&gt;&gt;   	 * of the high or low area bitmaps, the first high area starts</span>
<span class="quote">&gt;&gt;   	 * at 4GB, not 0 */</span>
<span class="quote">&gt;&gt;   	if (start == 0)</span>
<span class="quote">&gt;&gt; -		start = SLICE_LOW_TOP;</span>
<span class="quote">&gt;&gt; +		start = SLICE_LOW_TOP + 1;</span>
<span class="quote">&gt;&gt;   </span>
<span class="quote">&gt;&gt;   	return !slice_area_is_free(mm, start, end - start);</span>
<span class="quote">&gt;&gt;   }</span>
<span class="quote">&gt;&gt; @@ -128,7 +129,8 @@ static void slice_mask_for_free(struct mm_struct *mm, struct slice_mask *ret,</span>
<span class="quote">&gt;&gt;   	unsigned long i;</span>
<span class="quote">&gt;&gt;   </span>
<span class="quote">&gt;&gt;   	ret-&gt;low_slices = 0;</span>
<span class="quote">&gt;&gt; -	bitmap_zero(ret-&gt;high_slices, SLICE_NUM_HIGH);</span>
<span class="quote">&gt;&gt; +	if (SLICE_NUM_HIGH)</span>
<span class="quote">&gt;&gt; +		bitmap_zero(ret-&gt;high_slices, SLICE_NUM_HIGH);</span>
<span class="quote">&gt;&gt;   </span>
<span class="quote">&gt;&gt;   	for (i = 0; i &lt; SLICE_NUM_LOW; i++)</span>
<span class="quote">&gt;&gt;   		if (!slice_low_has_vma(mm, i))</span>
<span class="quote">&gt;&gt; @@ -151,7 +153,8 @@ static void slice_mask_for_size(struct mm_struct *mm, int psize, struct slice_ma</span>
<span class="quote">&gt;&gt;   	u64 lpsizes;</span>
<span class="quote">&gt;&gt;   </span>
<span class="quote">&gt;&gt;   	ret-&gt;low_slices = 0;</span>
<span class="quote">&gt;&gt; -	bitmap_zero(ret-&gt;high_slices, SLICE_NUM_HIGH);</span>
<span class="quote">&gt;&gt; +	if (SLICE_NUM_HIGH)</span>
<span class="quote">&gt;&gt; +		bitmap_zero(ret-&gt;high_slices, SLICE_NUM_HIGH);</span>
<span class="quote">&gt;&gt;   </span>
<span class="quote">&gt;&gt;   	lpsizes = mm-&gt;context.low_slices_psize;</span>
<span class="quote">&gt;&gt;   	for (i = 0; i &lt; SLICE_NUM_LOW; i++)</span>
<span class="quote">&gt;&gt; @@ -180,15 +183,18 @@ static int slice_check_fit(struct mm_struct *mm,</span>
<span class="quote">&gt;&gt;   	 */</span>
<span class="quote">&gt;&gt;   	unsigned long slice_count = GET_HIGH_SLICE_INDEX(mm-&gt;context.slb_addr_limit);</span>
<span class="quote">&gt;&gt;   </span>
<span class="quote">&gt;&gt; -	bitmap_and(result, mask.high_slices,</span>
<span class="quote">&gt;&gt; -		   available.high_slices, slice_count);</span>
<span class="quote">&gt;&gt; +	if (SLICE_NUM_HIGH)</span>
<span class="quote">&gt;&gt; +		bitmap_and(result, mask.high_slices,</span>
<span class="quote">&gt;&gt; +			   available.high_slices, slice_count);</span>
<span class="quote">&gt;&gt;   </span>
<span class="quote">&gt;&gt;   	return (mask.low_slices &amp; available.low_slices) == mask.low_slices &amp;&amp;</span>
<span class="quote">&gt;&gt; -		bitmap_equal(result, mask.high_slices, slice_count);</span>
<span class="quote">&gt;&gt; +		(!slice_count ||</span>
<span class="quote">&gt;&gt; +		 bitmap_equal(result, mask.high_slices, slice_count));</span>
<span class="quote">&gt;&gt;   }</span>
<span class="quote">&gt;&gt;   </span>
<span class="quote">&gt;&gt;   static void slice_flush_segments(void *parm)</span>
<span class="quote">&gt;&gt;   {</span>
<span class="quote">&gt;&gt; +#ifdef CONFIG_PPC_BOOK3S_64</span>
<span class="quote">&gt;&gt;   	struct mm_struct *mm = parm;</span>
<span class="quote">&gt;&gt;   	unsigned long flags;</span>
<span class="quote">&gt;&gt;   </span>
<span class="quote">&gt;&gt; @@ -200,6 +206,7 @@ static void slice_flush_segments(void *parm)</span>
<span class="quote">&gt;&gt;   	local_irq_save(flags);</span>
<span class="quote">&gt;&gt;   	slb_flush_and_rebolt();</span>
<span class="quote">&gt;&gt;   	local_irq_restore(flags);</span>
<span class="quote">&gt;&gt; +#endif</span>
<span class="quote">&gt;&gt;   }</span>
<span class="quote">&gt;&gt;   </span>
<span class="quote">&gt;&gt;   static void slice_convert(struct mm_struct *mm, struct slice_mask mask, int psize)</span>
<span class="quote">&gt;&gt; @@ -259,7 +266,7 @@ static bool slice_scan_available(unsigned long addr,</span>
<span class="quote">&gt;&gt;   				 unsigned long *boundary_addr)</span>
<span class="quote">&gt;&gt;   {</span>
<span class="quote">&gt;&gt;   	unsigned long slice;</span>
<span class="quote">&gt;&gt; -	if (addr &lt; SLICE_LOW_TOP) {</span>
<span class="quote">&gt;&gt; +	if (addr &lt;= SLICE_LOW_TOP) {</span>
<span class="quote">&gt;&gt;   		slice = GET_LOW_SLICE_INDEX(addr);</span>
<span class="quote">&gt;&gt;   		*boundary_addr = (slice + end) &lt;&lt; SLICE_LOW_SHIFT;</span>
<span class="quote">&gt;&gt;   		return !!(available.low_slices &amp; (1u &lt;&lt; slice));</span>
<span class="quote">&gt;&gt; @@ -391,8 +398,11 @@ static inline void slice_or_mask(struct slice_mask *dst, struct slice_mask *src)</span>
<span class="quote">&gt;&gt;   	DECLARE_BITMAP(result, SLICE_NUM_HIGH);</span>
<span class="quote">&gt;&gt;   </span>
<span class="quote">&gt;&gt;   	dst-&gt;low_slices |= src-&gt;low_slices;</span>
<span class="quote">&gt;&gt; -	bitmap_or(result, dst-&gt;high_slices, src-&gt;high_slices, SLICE_NUM_HIGH);</span>
<span class="quote">&gt;&gt; -	bitmap_copy(dst-&gt;high_slices, result, SLICE_NUM_HIGH);</span>
<span class="quote">&gt;&gt; +	if (SLICE_NUM_HIGH) {</span>
<span class="quote">&gt;&gt; +		bitmap_or(result, dst-&gt;high_slices, src-&gt;high_slices,</span>
<span class="quote">&gt;&gt; +			  SLICE_NUM_HIGH);</span>
<span class="quote">&gt;&gt; +		bitmap_copy(dst-&gt;high_slices, result, SLICE_NUM_HIGH);</span>
<span class="quote">&gt;&gt; +	}</span>
<span class="quote">&gt;&gt;   }</span>
<span class="quote">&gt;&gt;   </span>
<span class="quote">&gt;&gt;   static inline void slice_andnot_mask(struct slice_mask *dst, struct slice_mask *src)</span>
<span class="quote">&gt;&gt; @@ -401,12 +411,17 @@ static inline void slice_andnot_mask(struct slice_mask *dst, struct slice_mask *</span>
<span class="quote">&gt;&gt;   </span>
<span class="quote">&gt;&gt;   	dst-&gt;low_slices &amp;= ~src-&gt;low_slices;</span>
<span class="quote">&gt;&gt;   </span>
<span class="quote">&gt;&gt; -	bitmap_andnot(result, dst-&gt;high_slices, src-&gt;high_slices, SLICE_NUM_HIGH);</span>
<span class="quote">&gt;&gt; -	bitmap_copy(dst-&gt;high_slices, result, SLICE_NUM_HIGH);</span>
<span class="quote">&gt;&gt; +	if (SLICE_NUM_HIGH) {</span>
<span class="quote">&gt;&gt; +		bitmap_andnot(result, dst-&gt;high_slices, src-&gt;high_slices,</span>
<span class="quote">&gt;&gt; +			      SLICE_NUM_HIGH);</span>
<span class="quote">&gt;&gt; +		bitmap_copy(dst-&gt;high_slices, result, SLICE_NUM_HIGH);</span>
<span class="quote">&gt;&gt; +	}</span>
<span class="quote">&gt;&gt;   }</span>
<span class="quote">&gt;&gt;   </span>
<span class="quote">&gt;&gt;   #ifdef CONFIG_PPC_64K_PAGES</span>
<span class="quote">&gt;&gt;   #define MMU_PAGE_BASE	MMU_PAGE_64K</span>
<span class="quote">&gt;&gt; +#elif defined(CONFIG_PPC_16K_PAGES)</span>
<span class="quote">&gt;&gt; +#define MMU_PAGE_BASE	MMU_PAGE_16K</span>
<span class="quote">&gt;&gt;   #else</span>
<span class="quote">&gt;&gt;   #define MMU_PAGE_BASE	MMU_PAGE_4K</span>
<span class="quote">&gt;&gt;   #endif</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; I am not sure we want them based on page size. The rule is we flush</span>
<span class="quote">&gt; segments on book3s63 if the page size is different from MMU_PAGE_BASE</span>

Do you mean this definition is just useless for the 8xx as it doesn&#39;t 
have real segments ?
<span class="quote">
&gt; </span>
<span class="quote">&gt; </span>
<span class="quote">&gt;&gt; @@ -450,14 +465,17 @@ unsigned long slice_get_unmapped_area(unsigned long addr, unsigned long len,</span>
<span class="quote">&gt;&gt;   	 * init different masks</span>
<span class="quote">&gt;&gt;   	 */</span>
<span class="quote">&gt;&gt;   	mask.low_slices = 0;</span>
<span class="quote">&gt;&gt; -	bitmap_zero(mask.high_slices, SLICE_NUM_HIGH);</span>
<span class="quote">&gt;&gt; +	if (SLICE_NUM_HIGH)</span>
<span class="quote">&gt;&gt; +		bitmap_zero(mask.high_slices, SLICE_NUM_HIGH);</span>
<span class="quote">&gt;&gt;   </span>
<span class="quote">&gt;&gt;   	/* silence stupid warning */;</span>
<span class="quote">&gt;&gt;   	potential_mask.low_slices = 0;</span>
<span class="quote">&gt;&gt; -	bitmap_zero(potential_mask.high_slices, SLICE_NUM_HIGH);</span>
<span class="quote">&gt;&gt; +	if (SLICE_NUM_HIGH)</span>
<span class="quote">&gt;&gt; +		bitmap_zero(potential_mask.high_slices, SLICE_NUM_HIGH);</span>
<span class="quote">&gt;&gt;   </span>
<span class="quote">&gt;&gt;   	compat_mask.low_slices = 0;</span>
<span class="quote">&gt;&gt; -	bitmap_zero(compat_mask.high_slices, SLICE_NUM_HIGH);</span>
<span class="quote">&gt;&gt; +	if (SLICE_NUM_HIGH)</span>
<span class="quote">&gt;&gt; +		bitmap_zero(compat_mask.high_slices, SLICE_NUM_HIGH);</span>
<span class="quote">&gt;&gt;   </span>
<span class="quote">&gt;&gt;   	/* Sanity checks */</span>
<span class="quote">&gt;&gt;   	BUG_ON(mm-&gt;task_size == 0);</span>
<span class="quote">&gt;&gt; @@ -595,7 +613,9 @@ unsigned long slice_get_unmapped_area(unsigned long addr, unsigned long len,</span>
<span class="quote">&gt;&gt;    convert:</span>
<span class="quote">&gt;&gt;   	slice_andnot_mask(&amp;mask, &amp;good_mask);</span>
<span class="quote">&gt;&gt;   	slice_andnot_mask(&amp;mask, &amp;compat_mask);</span>
<span class="quote">&gt;&gt; -	if (mask.low_slices || !bitmap_empty(mask.high_slices, SLICE_NUM_HIGH)) {</span>
<span class="quote">&gt;&gt; +	if (mask.low_slices ||</span>
<span class="quote">&gt;&gt; +	    (SLICE_NUM_HIGH &amp;&amp;</span>
<span class="quote">&gt;&gt; +	     !bitmap_empty(mask.high_slices, SLICE_NUM_HIGH))) {</span>
<span class="quote">&gt;&gt;   		slice_convert(mm, mask, psize);</span>
<span class="quote">&gt;&gt;   		if (psize &gt; MMU_PAGE_BASE)</span>
<span class="quote">&gt;&gt;   			on_each_cpu(slice_flush_segments, mm, 1);</span>
<span class="quote">&gt;&gt; @@ -640,7 +660,7 @@ unsigned int get_slice_psize(struct mm_struct *mm, unsigned long addr)</span>
<span class="quote">&gt;&gt;   		return MMU_PAGE_4K;</span>
<span class="quote">&gt;&gt;   #endif</span>
<span class="quote">&gt;&gt;   	}</span>
<span class="quote">&gt;&gt; -	if (addr &lt; SLICE_LOW_TOP) {</span>
<span class="quote">&gt;&gt; +	if (addr &lt;= SLICE_LOW_TOP) {</span>
<span class="quote">&gt;&gt;   		u64 lpsizes;</span>
<span class="quote">&gt;&gt;   		lpsizes = mm-&gt;context.low_slices_psize;</span>
<span class="quote">&gt;&gt;   		index = GET_LOW_SLICE_INDEX(addr);</span>
<span class="quote">&gt;&gt; diff --git a/arch/powerpc/platforms/Kconfig.cputype b/arch/powerpc/platforms/Kconfig.cputype</span>
<span class="quote">&gt;&gt; index ae07470fde3c..73a7ea333e9e 100644</span>
<span class="quote">&gt;&gt; --- a/arch/powerpc/platforms/Kconfig.cputype</span>
<span class="quote">&gt;&gt; +++ b/arch/powerpc/platforms/Kconfig.cputype</span>
<span class="quote">&gt;&gt; @@ -334,6 +334,7 @@ config PPC_BOOK3E_MMU</span>
<span class="quote">&gt;&gt;   config PPC_MM_SLICES</span>
<span class="quote">&gt;&gt;   	bool</span>
<span class="quote">&gt;&gt;   	default y if PPC_BOOK3S_64</span>
<span class="quote">&gt;&gt; +	default y if PPC_8xx &amp;&amp; HUGETLB_PAGE</span>
<span class="quote">&gt;&gt;   	default n</span>
<span class="quote">&gt;&gt;   </span>
<span class="quote">&gt;&gt;   config PPC_HAVE_PMU_SUPPORT</span>
<span class="quote">&gt;&gt; -- </span>
<span class="quote">&gt;&gt; 2.13.3</span>
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=1141">Aneesh Kumar K.V</a> - Jan. 16, 2018, 4:41 p.m.</div>
<pre class="content">
On 01/16/2018 10:01 PM, Christophe LEROY wrote:
<span class="quote">&gt; </span>
<span class="quote">&gt;&gt;&gt; diff --git a/arch/powerpc/include/asm/page_64.h </span>
<span class="quote">&gt;&gt;&gt; b/arch/powerpc/include/asm/page_64.h</span>
<span class="quote">&gt;&gt;&gt; index 56234c6fcd61..a7baef5bbe5f 100644</span>
<span class="quote">&gt;&gt;&gt; --- a/arch/powerpc/include/asm/page_64.h</span>
<span class="quote">&gt;&gt;&gt; +++ b/arch/powerpc/include/asm/page_64.h</span>
<span class="quote">&gt;&gt;&gt; @@ -91,30 +91,13 @@ extern u64 ppc64_pft_size;</span>
<span class="quote">&gt;&gt;&gt;   #define SLICE_LOW_SHIFT        28</span>
<span class="quote">&gt;&gt;&gt;   #define SLICE_HIGH_SHIFT    40</span>
<span class="quote">&gt;&gt;&gt; -#define SLICE_LOW_TOP        (0x100000000ul)</span>
<span class="quote">&gt;&gt;&gt; -#define SLICE_NUM_LOW        (SLICE_LOW_TOP &gt;&gt; SLICE_LOW_SHIFT)</span>
<span class="quote">&gt;&gt;&gt; +#define SLICE_LOW_TOP        (0xfffffffful)</span>
<span class="quote">&gt;&gt;&gt; +#define SLICE_NUM_LOW        ((SLICE_LOW_TOP &gt;&gt; SLICE_LOW_SHIFT) + 1)</span>
<span class="quote">&gt;&gt;&gt;   #define SLICE_NUM_HIGH        (H_PGTABLE_RANGE &gt;&gt; SLICE_HIGH_SHIFT)</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; Why are you changing this? is this a bug fix?</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; That&#39;s because 0x100000000ul is out of range of unsigned long on PPC32.</span>

Ok that detail was important. I missed that.
<span class="quote">
&gt; </span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt;   #define GET_LOW_SLICE_INDEX(addr)    ((addr) &gt;&gt; SLICE_LOW_SHIFT)</span>
<span class="quote">&gt;&gt;&gt;   #define GET_HIGH_SLICE_INDEX(addr)    ((addr) &gt;&gt; SLICE_HIGH_SHIFT)</span>
<span class="quote">&gt;&gt;&gt; -#ifndef __ASSEMBLY__</span>
<span class="quote">&gt;&gt;&gt; -struct mm_struct;</span>
<span class="quote">&gt;&gt;&gt; -</span>
<span class="quote">&gt;&gt;&gt; -extern unsigned long slice_get_unmapped_area(unsigned long addr,</span>
<span class="quote">&gt;&gt;&gt; -                         unsigned long len,</span>
<span class="quote">&gt;&gt;&gt; -                         unsigned long flags,</span>
<span class="quote">&gt;&gt;&gt; -                         unsigned int psize,</span>
<span class="quote">&gt;&gt;&gt; -                         int topdown);</span>
<span class="quote">&gt;&gt;&gt; -</span>
<span class="quote">&gt;&gt;&gt; -extern unsigned int get_slice_psize(struct mm_struct *mm,</span>
<span class="quote">&gt;&gt;&gt; -                    unsigned long addr);</span>
<span class="quote">&gt;&gt;&gt; -</span>
<span class="quote">&gt;&gt;&gt; -extern void slice_set_user_psize(struct mm_struct *mm, unsigned int </span>
<span class="quote">&gt;&gt;&gt; psize);</span>
<span class="quote">&gt;&gt;&gt; -extern void slice_set_range_psize(struct mm_struct *mm, unsigned </span>
<span class="quote">&gt;&gt;&gt; long start,</span>
<span class="quote">&gt;&gt;&gt; -                  unsigned long len, unsigned int psize);</span>
<span class="quote">&gt;&gt;&gt; -</span>
<span class="quote">&gt;&gt;&gt; -#endif /* __ASSEMBLY__ */</span>
<span class="quote">&gt;&gt;&gt;   #else</span>
<span class="quote">&gt;&gt;&gt;   #define slice_init()</span>
<span class="quote">&gt;&gt;&gt;   #ifdef CONFIG_PPC_BOOK3S_64</span>
<span class="quote">&gt;&gt;&gt; diff --git a/arch/powerpc/kernel/setup-common.c </span>
<span class="quote">&gt;&gt;&gt; b/arch/powerpc/kernel/setup-common.c</span>
<span class="quote">&gt;&gt;&gt; index 9d213542a48b..a285e1067713 100644</span>
<span class="quote">&gt;&gt;&gt; --- a/arch/powerpc/kernel/setup-common.c</span>
<span class="quote">&gt;&gt;&gt; +++ b/arch/powerpc/kernel/setup-common.c</span>
<span class="quote">&gt;&gt;&gt; @@ -928,7 +928,7 @@ void __init setup_arch(char **cmdline_p)</span>
<span class="quote">&gt;&gt;&gt;       if (!radix_enabled())</span>
<span class="quote">&gt;&gt;&gt;           init_mm.context.slb_addr_limit = DEFAULT_MAP_WINDOW_USER64;</span>
<span class="quote">&gt;&gt;&gt;   #else</span>
<span class="quote">&gt;&gt;&gt; -#error    &quot;context.addr_limit not initialized.&quot;</span>
<span class="quote">&gt;&gt;&gt; +    init_mm.context.slb_addr_limit = DEFAULT_MAP_WINDOW;</span>
<span class="quote">&gt;&gt;&gt;   #endif</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; May be put this within #ifdef 8XX and retain the error?</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Is this error really worth it ?</span>
<span class="quote">&gt; I wanted to avoid spreading too many #ifdef PPC_8xx, but ok I can do that.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt;   #endif</span>
<span class="quote">&gt;&gt;&gt; diff --git a/arch/powerpc/mm/8xx_mmu.c b/arch/powerpc/mm/8xx_mmu.c</span>
<span class="quote">&gt;&gt;&gt; index f29212e40f40..0be77709446c 100644</span>
<span class="quote">&gt;&gt;&gt; --- a/arch/powerpc/mm/8xx_mmu.c</span>
<span class="quote">&gt;&gt;&gt; +++ b/arch/powerpc/mm/8xx_mmu.c</span>
<span class="quote">&gt;&gt;&gt; @@ -192,7 +192,7 @@ void set_context(unsigned long id, pgd_t *pgd)</span>
<span class="quote">&gt;&gt;&gt;       mtspr(SPRN_M_TW, __pa(pgd) - offset);</span>
<span class="quote">&gt;&gt;&gt;       /* Update context */</span>
<span class="quote">&gt;&gt;&gt; -    mtspr(SPRN_M_CASID, id);</span>
<span class="quote">&gt;&gt;&gt; +    mtspr(SPRN_M_CASID, id - 1);</span>
<span class="quote">&gt;&gt;&gt;       /* sync */</span>
<span class="quote">&gt;&gt;&gt;       mb();</span>
<span class="quote">&gt;&gt;&gt;   }</span>
<span class="quote">&gt;&gt;&gt; diff --git a/arch/powerpc/mm/hash_utils_64.c </span>
<span class="quote">&gt;&gt;&gt; b/arch/powerpc/mm/hash_utils_64.c</span>
<span class="quote">&gt;&gt;&gt; index 655a5a9a183d..3266b3326088 100644</span>
<span class="quote">&gt;&gt;&gt; --- a/arch/powerpc/mm/hash_utils_64.c</span>
<span class="quote">&gt;&gt;&gt; +++ b/arch/powerpc/mm/hash_utils_64.c</span>
<span class="quote">&gt;&gt;&gt; @@ -1101,7 +1101,7 @@ static unsigned int get_paca_psize(unsigned </span>
<span class="quote">&gt;&gt;&gt; long addr)</span>
<span class="quote">&gt;&gt;&gt;       unsigned char *hpsizes;</span>
<span class="quote">&gt;&gt;&gt;       unsigned long index, mask_index;</span>
<span class="quote">&gt;&gt;&gt; -    if (addr &lt; SLICE_LOW_TOP) {</span>
<span class="quote">&gt;&gt;&gt; +    if (addr &lt;= SLICE_LOW_TOP) {</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; If this is part of bug fix, please do it as part of seperate patch </span>
<span class="quote">&gt;&gt; with details</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; As explained above, in order to allow comparison to work on PPC32, </span>
<span class="quote">&gt; SLICE_LOW_TOP has to be 0xffffffff instead of 0x100000000</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; How should I split in separate patches ? Something like ?</span>
<span class="quote">&gt; 1/ Slice support for PPC32 &gt; 2/ Activate slice for 8xx</span>

Yes something like that. Will you  be able to avoid that
  if (SLICE_NUM_HIGH) from the code? That makes the code ugly. Right now 
i don&#39;t have definite suggestion on what we could do though.


-aneesh
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=1141">Aneesh Kumar K.V</a> - Jan. 16, 2018, 4:43 p.m.</div>
<pre class="content">
On 01/16/2018 10:01 PM, Christophe LEROY wrote:
<span class="quote">&gt; </span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Le 16/01/2018 à 16:49, Aneesh Kumar K.V a écrit :</span>
<span class="quote">&gt;&gt; Christophe Leroy &lt;christophe.leroy@c-s.fr&gt; writes:</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt; When an app has some regular pages allocated (e.g. see below) and tries</span>
<span class="quote">&gt;&gt;&gt; to mmap() a huge page at a hint address covered by the same PMD entry,</span>
<span class="quote">&gt;&gt;&gt; the kernel accepts the hint allthough the 8xx cannot handle different</span>
<span class="quote">&gt;&gt;&gt; page sizes in the same PMD entry.</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; So that is a bug in get_unmapped_area function that you are using and</span>
<span class="quote">&gt;&gt; you want to fix that by using the slice code. Can you describe here what</span>
<span class="quote">&gt;&gt; the allocation restrictions are w.r.t 8xx? Do they have segments and</span>
<span class="quote">&gt;&gt; base page size like hash64?</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; I don&#39;t think it is a bug in get_unmapped_area() that is used by </span>
<span class="quote">&gt; default. It is that some HW do support mixing any page size in the same </span>
<span class="quote">&gt; page table (eg BOOK3E ?), but the 8xx doesn&#39;t.</span>
<span class="quote">&gt; In the 8xx, the page size is defined in the PGD entry, then all pages </span>
<span class="quote">&gt; defined in a given page table pointed by a PGD entry have the same size.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; So it is similar to segments if you consider each PGD entry as a kind of </span>
<span class="quote">&gt; segment</span>
<span class="quote">&gt; </span>

so IIUC, hugepd format encodes the page size details and that require us 
to ensure that all the address range mapped at that hupge_pd entry is of 
same page size? Hence we want to avoid mmap handing over an address in 
that range when we already have a hugetlb mapping in that range?


-aneesh
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=11492">LEROY Christophe</a> - Jan. 16, 2018, 4:53 p.m.</div>
<pre class="content">
Le 16/01/2018 à 17:43, Aneesh Kumar K.V a écrit :
<span class="quote">&gt; </span>
<span class="quote">&gt; </span>
<span class="quote">&gt; On 01/16/2018 10:01 PM, Christophe LEROY wrote:</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; Le 16/01/2018 à 16:49, Aneesh Kumar K.V a écrit :</span>
<span class="quote">&gt;&gt;&gt; Christophe Leroy &lt;christophe.leroy@c-s.fr&gt; writes:</span>
<span class="quote">&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt;&gt; When an app has some regular pages allocated (e.g. see below) and tries</span>
<span class="quote">&gt;&gt;&gt;&gt; to mmap() a huge page at a hint address covered by the same PMD entry,</span>
<span class="quote">&gt;&gt;&gt;&gt; the kernel accepts the hint allthough the 8xx cannot handle different</span>
<span class="quote">&gt;&gt;&gt;&gt; page sizes in the same PMD entry.</span>
<span class="quote">&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt; So that is a bug in get_unmapped_area function that you are using and</span>
<span class="quote">&gt;&gt;&gt; you want to fix that by using the slice code. Can you describe here what</span>
<span class="quote">&gt;&gt;&gt; the allocation restrictions are w.r.t 8xx? Do they have segments and</span>
<span class="quote">&gt;&gt;&gt; base page size like hash64?</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; I don&#39;t think it is a bug in get_unmapped_area() that is used by </span>
<span class="quote">&gt;&gt; default. It is that some HW do support mixing any page size in the </span>
<span class="quote">&gt;&gt; same page table (eg BOOK3E ?), but the 8xx doesn&#39;t.</span>
<span class="quote">&gt;&gt; In the 8xx, the page size is defined in the PGD entry, then all pages </span>
<span class="quote">&gt;&gt; defined in a given page table pointed by a PGD entry have the same size.</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; So it is similar to segments if you consider each PGD entry as a kind </span>
<span class="quote">&gt;&gt; of segment</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; so IIUC, hugepd format encodes the page size details and that require us </span>
<span class="quote">&gt; to ensure that all the address range mapped at that hupge_pd entry is of </span>
<span class="quote">&gt; same page size? Hence we want to avoid mmap handing over an address in </span>
<span class="quote">&gt; that range when we already have a hugetlb mapping in that range?</span>

Exactly

And also avoid hugetlb_get_unmapped_area() accepting an hint address in 
that range when we already have a regular mapping in that range.

Christophe
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=11492">LEROY Christophe</a> - Jan. 16, 2018, 4:57 p.m.</div>
<pre class="content">
Le 16/01/2018 à 17:41, Aneesh Kumar K.V a écrit :
<span class="quote">&gt; </span>
<span class="quote">&gt; </span>
<span class="quote">&gt; On 01/16/2018 10:01 PM, Christophe LEROY wrote:</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt;&gt; diff --git a/arch/powerpc/include/asm/page_64.h </span>
<span class="quote">&gt;&gt;&gt;&gt; b/arch/powerpc/include/asm/page_64.h</span>
<span class="quote">&gt;&gt;&gt;&gt; index 56234c6fcd61..a7baef5bbe5f 100644</span>
<span class="quote">&gt;&gt;&gt;&gt; --- a/arch/powerpc/include/asm/page_64.h</span>
<span class="quote">&gt;&gt;&gt;&gt; +++ b/arch/powerpc/include/asm/page_64.h</span>
<span class="quote">&gt;&gt;&gt;&gt; @@ -91,30 +91,13 @@ extern u64 ppc64_pft_size;</span>
<span class="quote">&gt;&gt;&gt;&gt;   #define SLICE_LOW_SHIFT        28</span>
<span class="quote">&gt;&gt;&gt;&gt;   #define SLICE_HIGH_SHIFT    40</span>
<span class="quote">&gt;&gt;&gt;&gt; -#define SLICE_LOW_TOP        (0x100000000ul)</span>
<span class="quote">&gt;&gt;&gt;&gt; -#define SLICE_NUM_LOW        (SLICE_LOW_TOP &gt;&gt; SLICE_LOW_SHIFT)</span>
<span class="quote">&gt;&gt;&gt;&gt; +#define SLICE_LOW_TOP        (0xfffffffful)</span>
<span class="quote">&gt;&gt;&gt;&gt; +#define SLICE_NUM_LOW        ((SLICE_LOW_TOP &gt;&gt; SLICE_LOW_SHIFT) + 1)</span>
<span class="quote">&gt;&gt;&gt;&gt;   #define SLICE_NUM_HIGH        (H_PGTABLE_RANGE &gt;&gt; SLICE_HIGH_SHIFT)</span>
<span class="quote">&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt; Why are you changing this? is this a bug fix?</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; That&#39;s because 0x100000000ul is out of range of unsigned long on PPC32.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Ok that detail was important. I missed that.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt;&gt;   #define GET_LOW_SLICE_INDEX(addr)    ((addr) &gt;&gt; SLICE_LOW_SHIFT)</span>
<span class="quote">&gt;&gt;&gt;&gt;   #define GET_HIGH_SLICE_INDEX(addr)    ((addr) &gt;&gt; SLICE_HIGH_SHIFT)</span>
<span class="quote">&gt;&gt;&gt;&gt; -#ifndef __ASSEMBLY__</span>
<span class="quote">&gt;&gt;&gt;&gt; -struct mm_struct;</span>
<span class="quote">&gt;&gt;&gt;&gt; -</span>
<span class="quote">&gt;&gt;&gt;&gt; -extern unsigned long slice_get_unmapped_area(unsigned long addr,</span>
<span class="quote">&gt;&gt;&gt;&gt; -                         unsigned long len,</span>
<span class="quote">&gt;&gt;&gt;&gt; -                         unsigned long flags,</span>
<span class="quote">&gt;&gt;&gt;&gt; -                         unsigned int psize,</span>
<span class="quote">&gt;&gt;&gt;&gt; -                         int topdown);</span>
<span class="quote">&gt;&gt;&gt;&gt; -</span>
<span class="quote">&gt;&gt;&gt;&gt; -extern unsigned int get_slice_psize(struct mm_struct *mm,</span>
<span class="quote">&gt;&gt;&gt;&gt; -                    unsigned long addr);</span>
<span class="quote">&gt;&gt;&gt;&gt; -</span>
<span class="quote">&gt;&gt;&gt;&gt; -extern void slice_set_user_psize(struct mm_struct *mm, unsigned int </span>
<span class="quote">&gt;&gt;&gt;&gt; psize);</span>
<span class="quote">&gt;&gt;&gt;&gt; -extern void slice_set_range_psize(struct mm_struct *mm, unsigned </span>
<span class="quote">&gt;&gt;&gt;&gt; long start,</span>
<span class="quote">&gt;&gt;&gt;&gt; -                  unsigned long len, unsigned int psize);</span>
<span class="quote">&gt;&gt;&gt;&gt; -</span>
<span class="quote">&gt;&gt;&gt;&gt; -#endif /* __ASSEMBLY__ */</span>
<span class="quote">&gt;&gt;&gt;&gt;   #else</span>
<span class="quote">&gt;&gt;&gt;&gt;   #define slice_init()</span>
<span class="quote">&gt;&gt;&gt;&gt;   #ifdef CONFIG_PPC_BOOK3S_64</span>
<span class="quote">&gt;&gt;&gt;&gt; diff --git a/arch/powerpc/kernel/setup-common.c </span>
<span class="quote">&gt;&gt;&gt;&gt; b/arch/powerpc/kernel/setup-common.c</span>
<span class="quote">&gt;&gt;&gt;&gt; index 9d213542a48b..a285e1067713 100644</span>
<span class="quote">&gt;&gt;&gt;&gt; --- a/arch/powerpc/kernel/setup-common.c</span>
<span class="quote">&gt;&gt;&gt;&gt; +++ b/arch/powerpc/kernel/setup-common.c</span>
<span class="quote">&gt;&gt;&gt;&gt; @@ -928,7 +928,7 @@ void __init setup_arch(char **cmdline_p)</span>
<span class="quote">&gt;&gt;&gt;&gt;       if (!radix_enabled())</span>
<span class="quote">&gt;&gt;&gt;&gt;           init_mm.context.slb_addr_limit = DEFAULT_MAP_WINDOW_USER64;</span>
<span class="quote">&gt;&gt;&gt;&gt;   #else</span>
<span class="quote">&gt;&gt;&gt;&gt; -#error    &quot;context.addr_limit not initialized.&quot;</span>
<span class="quote">&gt;&gt;&gt;&gt; +    init_mm.context.slb_addr_limit = DEFAULT_MAP_WINDOW;</span>
<span class="quote">&gt;&gt;&gt;&gt;   #endif</span>
<span class="quote">&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt; May be put this within #ifdef 8XX and retain the error?</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; Is this error really worth it ?</span>
<span class="quote">&gt;&gt; I wanted to avoid spreading too many #ifdef PPC_8xx, but ok I can do </span>
<span class="quote">&gt;&gt; that.</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt;&gt;   #endif</span>
<span class="quote">&gt;&gt;&gt;&gt; diff --git a/arch/powerpc/mm/8xx_mmu.c b/arch/powerpc/mm/8xx_mmu.c</span>
<span class="quote">&gt;&gt;&gt;&gt; index f29212e40f40..0be77709446c 100644</span>
<span class="quote">&gt;&gt;&gt;&gt; --- a/arch/powerpc/mm/8xx_mmu.c</span>
<span class="quote">&gt;&gt;&gt;&gt; +++ b/arch/powerpc/mm/8xx_mmu.c</span>
<span class="quote">&gt;&gt;&gt;&gt; @@ -192,7 +192,7 @@ void set_context(unsigned long id, pgd_t *pgd)</span>
<span class="quote">&gt;&gt;&gt;&gt;       mtspr(SPRN_M_TW, __pa(pgd) - offset);</span>
<span class="quote">&gt;&gt;&gt;&gt;       /* Update context */</span>
<span class="quote">&gt;&gt;&gt;&gt; -    mtspr(SPRN_M_CASID, id);</span>
<span class="quote">&gt;&gt;&gt;&gt; +    mtspr(SPRN_M_CASID, id - 1);</span>
<span class="quote">&gt;&gt;&gt;&gt;       /* sync */</span>
<span class="quote">&gt;&gt;&gt;&gt;       mb();</span>
<span class="quote">&gt;&gt;&gt;&gt;   }</span>
<span class="quote">&gt;&gt;&gt;&gt; diff --git a/arch/powerpc/mm/hash_utils_64.c </span>
<span class="quote">&gt;&gt;&gt;&gt; b/arch/powerpc/mm/hash_utils_64.c</span>
<span class="quote">&gt;&gt;&gt;&gt; index 655a5a9a183d..3266b3326088 100644</span>
<span class="quote">&gt;&gt;&gt;&gt; --- a/arch/powerpc/mm/hash_utils_64.c</span>
<span class="quote">&gt;&gt;&gt;&gt; +++ b/arch/powerpc/mm/hash_utils_64.c</span>
<span class="quote">&gt;&gt;&gt;&gt; @@ -1101,7 +1101,7 @@ static unsigned int get_paca_psize(unsigned </span>
<span class="quote">&gt;&gt;&gt;&gt; long addr)</span>
<span class="quote">&gt;&gt;&gt;&gt;       unsigned char *hpsizes;</span>
<span class="quote">&gt;&gt;&gt;&gt;       unsigned long index, mask_index;</span>
<span class="quote">&gt;&gt;&gt;&gt; -    if (addr &lt; SLICE_LOW_TOP) {</span>
<span class="quote">&gt;&gt;&gt;&gt; +    if (addr &lt;= SLICE_LOW_TOP) {</span>
<span class="quote">&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt; If this is part of bug fix, please do it as part of seperate patch </span>
<span class="quote">&gt;&gt;&gt; with details</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; As explained above, in order to allow comparison to work on PPC32, </span>
<span class="quote">&gt;&gt; SLICE_LOW_TOP has to be 0xffffffff instead of 0x100000000</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; How should I split in separate patches ? Something like ?</span>
<span class="quote">&gt;&gt; 1/ Slice support for PPC32 &gt; 2/ Activate slice for 8xx</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Yes something like that. Will you  be able to avoid that</span>
<span class="quote">&gt;   if (SLICE_NUM_HIGH) from the code? That makes the code ugly. Right now </span>
<span class="quote">&gt; i don&#39;t have definite suggestion on what we could do though.</span>
<span class="quote">&gt; </span>

Could use #ifdefs instead, but in my mind it would be even more ugly.

I would have liked just doing nothing, but the issue is that at the 
moment bitmap_xxx() functions are not prepared to handle bitmaps of size 
zero. Should we try to change that ? Any chance to succeed ?

Christophe
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=1141">Aneesh Kumar K.V</a> - Jan. 17, 2018, 5:23 a.m.</div>
<pre class="content">
Christophe LEROY &lt;christophe.leroy@c-s.fr&gt; writes:
<span class="quote">
&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt; How should I split in separate patches ? Something like ?</span>
<span class="quote">&gt;&gt;&gt; 1/ Slice support for PPC32 &gt; 2/ Activate slice for 8xx</span>
<span class="quote">&gt;&gt; </span>
<span class="quote">&gt;&gt; Yes something like that. Will you  be able to avoid that</span>
<span class="quote">&gt;&gt;   if (SLICE_NUM_HIGH) from the code? That makes the code ugly. Right now </span>
<span class="quote">&gt;&gt; i don&#39;t have definite suggestion on what we could do though.</span>
<span class="quote">&gt;&gt; </span>
<span class="quote">&gt;</span>
<span class="quote">&gt; Could use #ifdefs instead, but in my mind it would be even more ugly.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; I would have liked just doing nothing, but the issue is that at the </span>
<span class="quote">&gt; moment bitmap_xxx() functions are not prepared to handle bitmaps of size </span>
<span class="quote">&gt; zero. Should we try to change that ? Any chance to succeed ?</span>
<span class="quote">&gt;</span>

How much code duplication it is to do slice_32.c?

Michael,

What do you suggest here?

-aneesh
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=11492">LEROY Christophe</a> - Jan. 17, 2018, 9:47 a.m.</div>
<pre class="content">
Le 17/01/2018 à 06:23, Aneesh Kumar K.V a écrit :
<span class="quote">&gt; Christophe LEROY &lt;christophe.leroy@c-s.fr&gt; writes:</span>
<span class="quote">&gt; </span>
<span class="quote">&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt;&gt; How should I split in separate patches ? Something like ?</span>
<span class="quote">&gt;&gt;&gt;&gt; 1/ Slice support for PPC32 &gt; 2/ Activate slice for 8xx</span>
<span class="quote">&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt; Yes something like that. Will you  be able to avoid that</span>
<span class="quote">&gt;&gt;&gt;    if (SLICE_NUM_HIGH) from the code? That makes the code ugly. Right now</span>
<span class="quote">&gt;&gt;&gt; i don&#39;t have definite suggestion on what we could do though.</span>
<span class="quote">&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; Could use #ifdefs instead, but in my mind it would be even more ugly.</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; I would have liked just doing nothing, but the issue is that at the</span>
<span class="quote">&gt;&gt; moment bitmap_xxx() functions are not prepared to handle bitmaps of size</span>
<span class="quote">&gt;&gt; zero. Should we try to change that ? Any chance to succeed ?</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; How much code duplication it is to do slice_32.c?</span>

Most functions use both .low_slices and .high_slices, so if your thought 
is to copy slice.c to slice_32.c and then remove all code handling 
.high_slices, we will at least duplicate 50% of the code

In v2 that I have just submitted, I have embedded this ugly test in 
macros called slice_bitmap_xxx() which handles the 0 nbits case. Tell me 
if it looks better that way.

Christophe
<span class="quote">
&gt; </span>
<span class="quote">&gt; Michael,</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; What do you suggest here?</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; -aneesh</span>
<span class="quote">&gt;</span>
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/arch/powerpc/include/asm/mmu-8xx.h b/arch/powerpc/include/asm/mmu-8xx.h</span>
<span class="p_header">index 5bb3dbede41a..5f89b6010453 100644</span>
<span class="p_header">--- a/arch/powerpc/include/asm/mmu-8xx.h</span>
<span class="p_header">+++ b/arch/powerpc/include/asm/mmu-8xx.h</span>
<span class="p_chunk">@@ -169,6 +169,12 @@</span> <span class="p_context"> typedef struct {</span>
 	unsigned int id;
 	unsigned int active;
 	unsigned long vdso_base;
<span class="p_add">+#ifdef CONFIG_PPC_MM_SLICES</span>
<span class="p_add">+	u16 user_psize;		/* page size index */</span>
<span class="p_add">+	u64 low_slices_psize;	/* page size encodings */</span>
<span class="p_add">+	unsigned char high_slices_psize[0];</span>
<span class="p_add">+	unsigned long slb_addr_limit;</span>
<span class="p_add">+#endif</span>
 } mm_context_t;
 
 #define PHYS_IMMR_BASE (mfspr(SPRN_IMMR) &amp; 0xfff80000)
<span class="p_header">diff --git a/arch/powerpc/include/asm/page.h b/arch/powerpc/include/asm/page.h</span>
<span class="p_header">index 8da5d4c1cab2..d0384f9db9eb 100644</span>
<span class="p_header">--- a/arch/powerpc/include/asm/page.h</span>
<span class="p_header">+++ b/arch/powerpc/include/asm/page.h</span>
<span class="p_chunk">@@ -342,6 +342,20 @@</span> <span class="p_context"> typedef struct page *pgtable_t;</span>
 #endif
 #endif
 
<span class="p_add">+#ifdef CONFIG_PPC_MM_SLICES</span>
<span class="p_add">+struct mm_struct;</span>
<span class="p_add">+</span>
<span class="p_add">+unsigned long slice_get_unmapped_area(unsigned long addr, unsigned long len,</span>
<span class="p_add">+				      unsigned long flags, unsigned int psize,</span>
<span class="p_add">+				      int topdown);</span>
<span class="p_add">+</span>
<span class="p_add">+unsigned int get_slice_psize(struct mm_struct *mm, unsigned long addr);</span>
<span class="p_add">+</span>
<span class="p_add">+void slice_set_user_psize(struct mm_struct *mm, unsigned int psize);</span>
<span class="p_add">+void slice_set_range_psize(struct mm_struct *mm, unsigned long start,</span>
<span class="p_add">+			   unsigned long len, unsigned int psize);</span>
<span class="p_add">+#endif</span>
<span class="p_add">+</span>
 #include &lt;asm-generic/memory_model.h&gt;
 #endif /* __ASSEMBLY__ */
 
<span class="p_header">diff --git a/arch/powerpc/include/asm/page_32.h b/arch/powerpc/include/asm/page_32.h</span>
<span class="p_header">index 5c378e9b78c8..f7d1bd1183c8 100644</span>
<span class="p_header">--- a/arch/powerpc/include/asm/page_32.h</span>
<span class="p_header">+++ b/arch/powerpc/include/asm/page_32.h</span>
<span class="p_chunk">@@ -60,4 +60,23 @@</span> <span class="p_context"> extern void copy_page(void *to, void *from);</span>
 
 #endif /* __ASSEMBLY__ */
 
<span class="p_add">+#ifdef CONFIG_PPC_MM_SLICES</span>
<span class="p_add">+</span>
<span class="p_add">+#define SLICE_LOW_SHIFT		28</span>
<span class="p_add">+#define SLICE_HIGH_SHIFT	0</span>
<span class="p_add">+</span>
<span class="p_add">+#define SLICE_LOW_TOP		(0xfffffffful)</span>
<span class="p_add">+#define SLICE_NUM_LOW		((SLICE_LOW_TOP &gt;&gt; SLICE_LOW_SHIFT) + 1)</span>
<span class="p_add">+#define SLICE_NUM_HIGH		0ul</span>
<span class="p_add">+</span>
<span class="p_add">+#define GET_LOW_SLICE_INDEX(addr)	((addr) &gt;&gt; SLICE_LOW_SHIFT)</span>
<span class="p_add">+#define GET_HIGH_SLICE_INDEX(addr)	(addr &amp; 0)</span>
<span class="p_add">+</span>
<span class="p_add">+#ifdef CONFIG_HUGETLB_PAGE</span>
<span class="p_add">+#define HAVE_ARCH_HUGETLB_UNMAPPED_AREA</span>
<span class="p_add">+#endif</span>
<span class="p_add">+#define HAVE_ARCH_UNMAPPED_AREA</span>
<span class="p_add">+#define HAVE_ARCH_UNMAPPED_AREA_TOPDOWN</span>
<span class="p_add">+</span>
<span class="p_add">+#endif</span>
 #endif /* _ASM_POWERPC_PAGE_32_H */
<span class="p_header">diff --git a/arch/powerpc/include/asm/page_64.h b/arch/powerpc/include/asm/page_64.h</span>
<span class="p_header">index 56234c6fcd61..a7baef5bbe5f 100644</span>
<span class="p_header">--- a/arch/powerpc/include/asm/page_64.h</span>
<span class="p_header">+++ b/arch/powerpc/include/asm/page_64.h</span>
<span class="p_chunk">@@ -91,30 +91,13 @@</span> <span class="p_context"> extern u64 ppc64_pft_size;</span>
 #define SLICE_LOW_SHIFT		28
 #define SLICE_HIGH_SHIFT	40
 
<span class="p_del">-#define SLICE_LOW_TOP		(0x100000000ul)</span>
<span class="p_del">-#define SLICE_NUM_LOW		(SLICE_LOW_TOP &gt;&gt; SLICE_LOW_SHIFT)</span>
<span class="p_add">+#define SLICE_LOW_TOP		(0xfffffffful)</span>
<span class="p_add">+#define SLICE_NUM_LOW		((SLICE_LOW_TOP &gt;&gt; SLICE_LOW_SHIFT) + 1)</span>
 #define SLICE_NUM_HIGH		(H_PGTABLE_RANGE &gt;&gt; SLICE_HIGH_SHIFT)
 
 #define GET_LOW_SLICE_INDEX(addr)	((addr) &gt;&gt; SLICE_LOW_SHIFT)
 #define GET_HIGH_SLICE_INDEX(addr)	((addr) &gt;&gt; SLICE_HIGH_SHIFT)
 
<span class="p_del">-#ifndef __ASSEMBLY__</span>
<span class="p_del">-struct mm_struct;</span>
<span class="p_del">-</span>
<span class="p_del">-extern unsigned long slice_get_unmapped_area(unsigned long addr,</span>
<span class="p_del">-					     unsigned long len,</span>
<span class="p_del">-					     unsigned long flags,</span>
<span class="p_del">-					     unsigned int psize,</span>
<span class="p_del">-					     int topdown);</span>
<span class="p_del">-</span>
<span class="p_del">-extern unsigned int get_slice_psize(struct mm_struct *mm,</span>
<span class="p_del">-				    unsigned long addr);</span>
<span class="p_del">-</span>
<span class="p_del">-extern void slice_set_user_psize(struct mm_struct *mm, unsigned int psize);</span>
<span class="p_del">-extern void slice_set_range_psize(struct mm_struct *mm, unsigned long start,</span>
<span class="p_del">-				  unsigned long len, unsigned int psize);</span>
<span class="p_del">-</span>
<span class="p_del">-#endif /* __ASSEMBLY__ */</span>
 #else
 #define slice_init()
 #ifdef CONFIG_PPC_BOOK3S_64
<span class="p_header">diff --git a/arch/powerpc/kernel/setup-common.c b/arch/powerpc/kernel/setup-common.c</span>
<span class="p_header">index 9d213542a48b..a285e1067713 100644</span>
<span class="p_header">--- a/arch/powerpc/kernel/setup-common.c</span>
<span class="p_header">+++ b/arch/powerpc/kernel/setup-common.c</span>
<span class="p_chunk">@@ -928,7 +928,7 @@</span> <span class="p_context"> void __init setup_arch(char **cmdline_p)</span>
 	if (!radix_enabled())
 		init_mm.context.slb_addr_limit = DEFAULT_MAP_WINDOW_USER64;
 #else
<span class="p_del">-#error	&quot;context.addr_limit not initialized.&quot;</span>
<span class="p_add">+	init_mm.context.slb_addr_limit = DEFAULT_MAP_WINDOW;</span>
 #endif
 #endif
 
<span class="p_header">diff --git a/arch/powerpc/mm/8xx_mmu.c b/arch/powerpc/mm/8xx_mmu.c</span>
<span class="p_header">index f29212e40f40..0be77709446c 100644</span>
<span class="p_header">--- a/arch/powerpc/mm/8xx_mmu.c</span>
<span class="p_header">+++ b/arch/powerpc/mm/8xx_mmu.c</span>
<span class="p_chunk">@@ -192,7 +192,7 @@</span> <span class="p_context"> void set_context(unsigned long id, pgd_t *pgd)</span>
 	mtspr(SPRN_M_TW, __pa(pgd) - offset);
 
 	/* Update context */
<span class="p_del">-	mtspr(SPRN_M_CASID, id);</span>
<span class="p_add">+	mtspr(SPRN_M_CASID, id - 1);</span>
 	/* sync */
 	mb();
 }
<span class="p_header">diff --git a/arch/powerpc/mm/hash_utils_64.c b/arch/powerpc/mm/hash_utils_64.c</span>
<span class="p_header">index 655a5a9a183d..3266b3326088 100644</span>
<span class="p_header">--- a/arch/powerpc/mm/hash_utils_64.c</span>
<span class="p_header">+++ b/arch/powerpc/mm/hash_utils_64.c</span>
<span class="p_chunk">@@ -1101,7 +1101,7 @@</span> <span class="p_context"> static unsigned int get_paca_psize(unsigned long addr)</span>
 	unsigned char *hpsizes;
 	unsigned long index, mask_index;
 
<span class="p_del">-	if (addr &lt; SLICE_LOW_TOP) {</span>
<span class="p_add">+	if (addr &lt;= SLICE_LOW_TOP) {</span>
 		lpsizes = get_paca()-&gt;mm_ctx_low_slices_psize;
 		index = GET_LOW_SLICE_INDEX(addr);
 		return (lpsizes &gt;&gt; (index * 4)) &amp; 0xF;
<span class="p_header">diff --git a/arch/powerpc/mm/hugetlbpage.c b/arch/powerpc/mm/hugetlbpage.c</span>
<span class="p_header">index a9b9083c5e49..79e1378ee303 100644</span>
<span class="p_header">--- a/arch/powerpc/mm/hugetlbpage.c</span>
<span class="p_header">+++ b/arch/powerpc/mm/hugetlbpage.c</span>
<span class="p_chunk">@@ -553,9 +553,11 @@</span> <span class="p_context"> unsigned long hugetlb_get_unmapped_area(struct file *file, unsigned long addr,</span>
 	struct hstate *hstate = hstate_file(file);
 	int mmu_psize = shift_to_mmu_psize(huge_page_shift(hstate));
 
<span class="p_add">+#ifdef CONFIG_PPC_RADIX_MMU</span>
 	if (radix_enabled())
 		return radix__hugetlb_get_unmapped_area(file, addr, len,
 						       pgoff, flags);
<span class="p_add">+#endif</span>
 	return slice_get_unmapped_area(addr, len, flags, mmu_psize, 1);
 }
 #endif
<span class="p_header">diff --git a/arch/powerpc/mm/mmu_context_nohash.c b/arch/powerpc/mm/mmu_context_nohash.c</span>
<span class="p_header">index 4554d6527682..c1e1bf186871 100644</span>
<span class="p_header">--- a/arch/powerpc/mm/mmu_context_nohash.c</span>
<span class="p_header">+++ b/arch/powerpc/mm/mmu_context_nohash.c</span>
<span class="p_chunk">@@ -331,6 +331,13 @@</span> <span class="p_context"> int init_new_context(struct task_struct *t, struct mm_struct *mm)</span>
 {
 	pr_hard(&quot;initing context for mm @%p\n&quot;, mm);
 
<span class="p_add">+#ifdef CONFIG_PPC_MM_SLICES</span>
<span class="p_add">+	if (!mm-&gt;context.slb_addr_limit)</span>
<span class="p_add">+		mm-&gt;context.slb_addr_limit = DEFAULT_MAP_WINDOW;</span>
<span class="p_add">+	if (!mm-&gt;context.id)</span>
<span class="p_add">+		slice_set_user_psize(mm, mmu_virtual_psize);</span>
<span class="p_add">+#endif</span>
<span class="p_add">+</span>
 	mm-&gt;context.id = MMU_NO_CONTEXT;
 	mm-&gt;context.active = 0;
 	return 0;
<span class="p_chunk">@@ -428,8 +435,8 @@</span> <span class="p_context"> void __init mmu_context_init(void)</span>
 	 *      -- BenH
 	 */
 	if (mmu_has_feature(MMU_FTR_TYPE_8xx)) {
<span class="p_del">-		first_context = 0;</span>
<span class="p_del">-		last_context = 15;</span>
<span class="p_add">+		first_context = 1;</span>
<span class="p_add">+		last_context = 16;</span>
 		no_selective_tlbil = true;
 	} else if (mmu_has_feature(MMU_FTR_TYPE_47x)) {
 		first_context = 1;
<span class="p_header">diff --git a/arch/powerpc/mm/slice.c b/arch/powerpc/mm/slice.c</span>
<span class="p_header">index 23ec2c5e3b78..1a66fafc3e45 100644</span>
<span class="p_header">--- a/arch/powerpc/mm/slice.c</span>
<span class="p_header">+++ b/arch/powerpc/mm/slice.c</span>
<span class="p_chunk">@@ -73,10 +73,11 @@</span> <span class="p_context"> static void slice_range_to_mask(unsigned long start, unsigned long len,</span>
 	unsigned long end = start + len - 1;
 
 	ret-&gt;low_slices = 0;
<span class="p_del">-	bitmap_zero(ret-&gt;high_slices, SLICE_NUM_HIGH);</span>
<span class="p_add">+	if (SLICE_NUM_HIGH)</span>
<span class="p_add">+		bitmap_zero(ret-&gt;high_slices, SLICE_NUM_HIGH);</span>
 
<span class="p_del">-	if (start &lt; SLICE_LOW_TOP) {</span>
<span class="p_del">-		unsigned long mend = min(end, (SLICE_LOW_TOP - 1));</span>
<span class="p_add">+	if (start &lt;= SLICE_LOW_TOP) {</span>
<span class="p_add">+		unsigned long mend = min(end, SLICE_LOW_TOP);</span>
 
 		ret-&gt;low_slices = (1u &lt;&lt; (GET_LOW_SLICE_INDEX(mend) + 1))
 			- (1u &lt;&lt; GET_LOW_SLICE_INDEX(start));
<span class="p_chunk">@@ -117,7 +118,7 @@</span> <span class="p_context"> static int slice_high_has_vma(struct mm_struct *mm, unsigned long slice)</span>
 	 * of the high or low area bitmaps, the first high area starts
 	 * at 4GB, not 0 */
 	if (start == 0)
<span class="p_del">-		start = SLICE_LOW_TOP;</span>
<span class="p_add">+		start = SLICE_LOW_TOP + 1;</span>
 
 	return !slice_area_is_free(mm, start, end - start);
 }
<span class="p_chunk">@@ -128,7 +129,8 @@</span> <span class="p_context"> static void slice_mask_for_free(struct mm_struct *mm, struct slice_mask *ret,</span>
 	unsigned long i;
 
 	ret-&gt;low_slices = 0;
<span class="p_del">-	bitmap_zero(ret-&gt;high_slices, SLICE_NUM_HIGH);</span>
<span class="p_add">+	if (SLICE_NUM_HIGH)</span>
<span class="p_add">+		bitmap_zero(ret-&gt;high_slices, SLICE_NUM_HIGH);</span>
 
 	for (i = 0; i &lt; SLICE_NUM_LOW; i++)
 		if (!slice_low_has_vma(mm, i))
<span class="p_chunk">@@ -151,7 +153,8 @@</span> <span class="p_context"> static void slice_mask_for_size(struct mm_struct *mm, int psize, struct slice_ma</span>
 	u64 lpsizes;
 
 	ret-&gt;low_slices = 0;
<span class="p_del">-	bitmap_zero(ret-&gt;high_slices, SLICE_NUM_HIGH);</span>
<span class="p_add">+	if (SLICE_NUM_HIGH)</span>
<span class="p_add">+		bitmap_zero(ret-&gt;high_slices, SLICE_NUM_HIGH);</span>
 
 	lpsizes = mm-&gt;context.low_slices_psize;
 	for (i = 0; i &lt; SLICE_NUM_LOW; i++)
<span class="p_chunk">@@ -180,15 +183,18 @@</span> <span class="p_context"> static int slice_check_fit(struct mm_struct *mm,</span>
 	 */
 	unsigned long slice_count = GET_HIGH_SLICE_INDEX(mm-&gt;context.slb_addr_limit);
 
<span class="p_del">-	bitmap_and(result, mask.high_slices,</span>
<span class="p_del">-		   available.high_slices, slice_count);</span>
<span class="p_add">+	if (SLICE_NUM_HIGH)</span>
<span class="p_add">+		bitmap_and(result, mask.high_slices,</span>
<span class="p_add">+			   available.high_slices, slice_count);</span>
 
 	return (mask.low_slices &amp; available.low_slices) == mask.low_slices &amp;&amp;
<span class="p_del">-		bitmap_equal(result, mask.high_slices, slice_count);</span>
<span class="p_add">+		(!slice_count ||</span>
<span class="p_add">+		 bitmap_equal(result, mask.high_slices, slice_count));</span>
 }
 
 static void slice_flush_segments(void *parm)
 {
<span class="p_add">+#ifdef CONFIG_PPC_BOOK3S_64</span>
 	struct mm_struct *mm = parm;
 	unsigned long flags;
 
<span class="p_chunk">@@ -200,6 +206,7 @@</span> <span class="p_context"> static void slice_flush_segments(void *parm)</span>
 	local_irq_save(flags);
 	slb_flush_and_rebolt();
 	local_irq_restore(flags);
<span class="p_add">+#endif</span>
 }
 
 static void slice_convert(struct mm_struct *mm, struct slice_mask mask, int psize)
<span class="p_chunk">@@ -259,7 +266,7 @@</span> <span class="p_context"> static bool slice_scan_available(unsigned long addr,</span>
 				 unsigned long *boundary_addr)
 {
 	unsigned long slice;
<span class="p_del">-	if (addr &lt; SLICE_LOW_TOP) {</span>
<span class="p_add">+	if (addr &lt;= SLICE_LOW_TOP) {</span>
 		slice = GET_LOW_SLICE_INDEX(addr);
 		*boundary_addr = (slice + end) &lt;&lt; SLICE_LOW_SHIFT;
 		return !!(available.low_slices &amp; (1u &lt;&lt; slice));
<span class="p_chunk">@@ -391,8 +398,11 @@</span> <span class="p_context"> static inline void slice_or_mask(struct slice_mask *dst, struct slice_mask *src)</span>
 	DECLARE_BITMAP(result, SLICE_NUM_HIGH);
 
 	dst-&gt;low_slices |= src-&gt;low_slices;
<span class="p_del">-	bitmap_or(result, dst-&gt;high_slices, src-&gt;high_slices, SLICE_NUM_HIGH);</span>
<span class="p_del">-	bitmap_copy(dst-&gt;high_slices, result, SLICE_NUM_HIGH);</span>
<span class="p_add">+	if (SLICE_NUM_HIGH) {</span>
<span class="p_add">+		bitmap_or(result, dst-&gt;high_slices, src-&gt;high_slices,</span>
<span class="p_add">+			  SLICE_NUM_HIGH);</span>
<span class="p_add">+		bitmap_copy(dst-&gt;high_slices, result, SLICE_NUM_HIGH);</span>
<span class="p_add">+	}</span>
 }
 
 static inline void slice_andnot_mask(struct slice_mask *dst, struct slice_mask *src)
<span class="p_chunk">@@ -401,12 +411,17 @@</span> <span class="p_context"> static inline void slice_andnot_mask(struct slice_mask *dst, struct slice_mask *</span>
 
 	dst-&gt;low_slices &amp;= ~src-&gt;low_slices;
 
<span class="p_del">-	bitmap_andnot(result, dst-&gt;high_slices, src-&gt;high_slices, SLICE_NUM_HIGH);</span>
<span class="p_del">-	bitmap_copy(dst-&gt;high_slices, result, SLICE_NUM_HIGH);</span>
<span class="p_add">+	if (SLICE_NUM_HIGH) {</span>
<span class="p_add">+		bitmap_andnot(result, dst-&gt;high_slices, src-&gt;high_slices,</span>
<span class="p_add">+			      SLICE_NUM_HIGH);</span>
<span class="p_add">+		bitmap_copy(dst-&gt;high_slices, result, SLICE_NUM_HIGH);</span>
<span class="p_add">+	}</span>
 }
 
 #ifdef CONFIG_PPC_64K_PAGES
 #define MMU_PAGE_BASE	MMU_PAGE_64K
<span class="p_add">+#elif defined(CONFIG_PPC_16K_PAGES)</span>
<span class="p_add">+#define MMU_PAGE_BASE	MMU_PAGE_16K</span>
 #else
 #define MMU_PAGE_BASE	MMU_PAGE_4K
 #endif
<span class="p_chunk">@@ -450,14 +465,17 @@</span> <span class="p_context"> unsigned long slice_get_unmapped_area(unsigned long addr, unsigned long len,</span>
 	 * init different masks
 	 */
 	mask.low_slices = 0;
<span class="p_del">-	bitmap_zero(mask.high_slices, SLICE_NUM_HIGH);</span>
<span class="p_add">+	if (SLICE_NUM_HIGH)</span>
<span class="p_add">+		bitmap_zero(mask.high_slices, SLICE_NUM_HIGH);</span>
 
 	/* silence stupid warning */;
 	potential_mask.low_slices = 0;
<span class="p_del">-	bitmap_zero(potential_mask.high_slices, SLICE_NUM_HIGH);</span>
<span class="p_add">+	if (SLICE_NUM_HIGH)</span>
<span class="p_add">+		bitmap_zero(potential_mask.high_slices, SLICE_NUM_HIGH);</span>
 
 	compat_mask.low_slices = 0;
<span class="p_del">-	bitmap_zero(compat_mask.high_slices, SLICE_NUM_HIGH);</span>
<span class="p_add">+	if (SLICE_NUM_HIGH)</span>
<span class="p_add">+		bitmap_zero(compat_mask.high_slices, SLICE_NUM_HIGH);</span>
 
 	/* Sanity checks */
 	BUG_ON(mm-&gt;task_size == 0);
<span class="p_chunk">@@ -595,7 +613,9 @@</span> <span class="p_context"> unsigned long slice_get_unmapped_area(unsigned long addr, unsigned long len,</span>
  convert:
 	slice_andnot_mask(&amp;mask, &amp;good_mask);
 	slice_andnot_mask(&amp;mask, &amp;compat_mask);
<span class="p_del">-	if (mask.low_slices || !bitmap_empty(mask.high_slices, SLICE_NUM_HIGH)) {</span>
<span class="p_add">+	if (mask.low_slices ||</span>
<span class="p_add">+	    (SLICE_NUM_HIGH &amp;&amp;</span>
<span class="p_add">+	     !bitmap_empty(mask.high_slices, SLICE_NUM_HIGH))) {</span>
 		slice_convert(mm, mask, psize);
 		if (psize &gt; MMU_PAGE_BASE)
 			on_each_cpu(slice_flush_segments, mm, 1);
<span class="p_chunk">@@ -640,7 +660,7 @@</span> <span class="p_context"> unsigned int get_slice_psize(struct mm_struct *mm, unsigned long addr)</span>
 		return MMU_PAGE_4K;
 #endif
 	}
<span class="p_del">-	if (addr &lt; SLICE_LOW_TOP) {</span>
<span class="p_add">+	if (addr &lt;= SLICE_LOW_TOP) {</span>
 		u64 lpsizes;
 		lpsizes = mm-&gt;context.low_slices_psize;
 		index = GET_LOW_SLICE_INDEX(addr);
<span class="p_header">diff --git a/arch/powerpc/platforms/Kconfig.cputype b/arch/powerpc/platforms/Kconfig.cputype</span>
<span class="p_header">index ae07470fde3c..73a7ea333e9e 100644</span>
<span class="p_header">--- a/arch/powerpc/platforms/Kconfig.cputype</span>
<span class="p_header">+++ b/arch/powerpc/platforms/Kconfig.cputype</span>
<span class="p_chunk">@@ -334,6 +334,7 @@</span> <span class="p_context"> config PPC_BOOK3E_MMU</span>
 config PPC_MM_SLICES
 	bool
 	default y if PPC_BOOK3S_64
<span class="p_add">+	default y if PPC_8xx &amp;&amp; HUGETLB_PAGE</span>
 	default n
 
 config PPC_HAVE_PMU_SUPPORT

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



