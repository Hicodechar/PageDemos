
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>[3.19.y-ckt,stable] Linux 3.19.8-ckt5 - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    [3.19.y-ckt,stable] Linux 3.19.8-ckt5</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=7718">Kamal Mostafa</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>Aug. 11, 2015, 4:40 p.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;1439311207-25694-2-git-send-email-kamal@canonical.com&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/6993551/mbox/"
   >mbox</a>
|
   <a href="/patch/6993551/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/6993551/">/patch/6993551/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
X-Original-To: patchwork-LKML@patchwork.kernel.org
Delivered-To: patchwork-parsemail@patchwork2.web.kernel.org
Received: from mail.kernel.org (mail.kernel.org [198.145.29.136])
	by patchwork2.web.kernel.org (Postfix) with ESMTP id 68E89C05AC
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Tue, 11 Aug 2015 16:41:10 +0000 (UTC)
Received: from mail.kernel.org (localhost [127.0.0.1])
	by mail.kernel.org (Postfix) with ESMTP id BFA2A2066B
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Tue, 11 Aug 2015 16:41:03 +0000 (UTC)
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.kernel.org (Postfix) with ESMTP id C74BE2038F
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Tue, 11 Aug 2015 16:40:56 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S965509AbbHKQku (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Tue, 11 Aug 2015 12:40:50 -0400
Received: from youngberry.canonical.com ([91.189.89.112]:52284 &quot;EHLO
	youngberry.canonical.com&quot; rhost-flags-OK-OK-OK-OK) by vger.kernel.org
	with ESMTP id S1755342AbbHKQkN (ORCPT
	&lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Tue, 11 Aug 2015 12:40:13 -0400
Received: from 1.general.kamal.us.vpn ([10.172.68.52] helo=fourier)
	by youngberry.canonical.com with esmtpsa
	(TLS1.0:DHE_RSA_AES_128_CBC_SHA1:16) (Exim 4.76)
	(envelope-from &lt;kamal@canonical.com&gt;)
	id 1ZPCaw-0007Km-MX; Tue, 11 Aug 2015 16:40:11 +0000
Received: from kamal by fourier with local (Exim 4.82)
	(envelope-from &lt;kamal@whence.com&gt;)
	id 1ZPCau-0006h2-Fm; Tue, 11 Aug 2015 09:40:08 -0700
From: Kamal Mostafa &lt;kamal@canonical.com&gt;
To: linux-kernel@vger.kernel.org, stable@vger.kernel.org,
	kernel-team@lists.ubuntu.com
Cc: lwn@lwn.net
Subject: Re: [3.19.y-ckt stable] Linux 3.19.8-ckt5
Date: Tue, 11 Aug 2015 09:40:07 -0700
Message-Id: &lt;1439311207-25694-2-git-send-email-kamal@canonical.com&gt;
X-Mailer: git-send-email 1.9.1
In-Reply-To: &lt;1439311207-25694-1-git-send-email-kamal@canonical.com&gt;
References: &lt;1439311207-25694-1-git-send-email-kamal@canonical.com&gt;
X-Extended-Stable: 3.19
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Spam-Status: No, score=-7.1 required=5.0 tests=BAYES_00, RCVD_IN_DNSWL_HI, 
	RP_MATCHES_RCVD,
	UNPARSEABLE_RELAY autolearn=unavailable version=3.3.1
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on mail.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=7718">Kamal Mostafa</a> - Aug. 11, 2015, 4:40 p.m.</div>
<pre class="content">
--
To unsubscribe from this list: send the line &quot;unsubscribe linux-kernel&quot; in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
Please read the FAQ at  http://www.tux.org/lkml/
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/Documentation/kbuild/makefiles.txt b/Documentation/kbuild/makefiles.txt</span>
<span class="p_header">index a311db8..59ff8f0 100644</span>
<span class="p_header">--- a/Documentation/kbuild/makefiles.txt</span>
<span class="p_header">+++ b/Documentation/kbuild/makefiles.txt</span>
<span class="p_chunk">@@ -952,6 +952,14 @@</span> <span class="p_context"> When kbuild executes, the following steps are followed (roughly):</span>
 	$(KBUILD_ARFLAGS) set by the top level Makefile to &quot;D&quot; (deterministic
 	mode) if this option is supported by $(AR).
 
<span class="p_add">+    ARCH_CPPFLAGS, ARCH_AFLAGS, ARCH_CFLAGS   Overrides the kbuild defaults</span>
<span class="p_add">+</span>
<span class="p_add">+	These variables are appended to the KBUILD_CPPFLAGS,</span>
<span class="p_add">+	KBUILD_AFLAGS, and KBUILD_CFLAGS, respectively, after the</span>
<span class="p_add">+	top-level Makefile has set any other flags. This provides a</span>
<span class="p_add">+	means for an architecture to override the defaults.</span>
<span class="p_add">+</span>
<span class="p_add">+</span>
 --- 6.2 Add prerequisites to archheaders:
 
 	The archheaders: rule is used to generate header files that
<span class="p_header">diff --git a/Makefile b/Makefile</span>
<span class="p_header">index ab8a985..b8ee707 100644</span>
<span class="p_header">--- a/Makefile</span>
<span class="p_header">+++ b/Makefile</span>
<span class="p_chunk">@@ -1,7 +1,7 @@</span> <span class="p_context"></span>
 VERSION = 3
 PATCHLEVEL = 19
 SUBLEVEL = 8
<span class="p_del">-EXTRAVERSION = -ckt4</span>
<span class="p_add">+EXTRAVERSION = -ckt5</span>
 NAME = Sedated Swine
 
 # *DOCUMENTATION*
<span class="p_chunk">@@ -779,10 +779,11 @@</span> <span class="p_context"> endif</span>
 
 include $(srctree)/scripts/Makefile.extrawarn
 
<span class="p_del">-# Add user supplied CPPFLAGS, AFLAGS and CFLAGS as the last assignments</span>
<span class="p_del">-KBUILD_CPPFLAGS += $(KCPPFLAGS)</span>
<span class="p_del">-KBUILD_AFLAGS += $(KAFLAGS)</span>
<span class="p_del">-KBUILD_CFLAGS += $(KCFLAGS)</span>
<span class="p_add">+# Add any arch overrides and user supplied CPPFLAGS, AFLAGS and CFLAGS as the</span>
<span class="p_add">+# last assignments</span>
<span class="p_add">+KBUILD_CPPFLAGS += $(ARCH_CPPFLAGS) $(KCPPFLAGS)</span>
<span class="p_add">+KBUILD_AFLAGS   += $(ARCH_AFLAGS)   $(KAFLAGS)</span>
<span class="p_add">+KBUILD_CFLAGS   += $(ARCH_CFLAGS)   $(KCFLAGS)</span>
 
 # Use --build-id when available.
 LDFLAGS_BUILD_ID = $(patsubst -Wl$(comma)%,%,\
<span class="p_header">diff --git a/arch/arc/Makefile b/arch/arc/Makefile</span>
<span class="p_header">index db72fec..2f21e1e 100644</span>
<span class="p_header">--- a/arch/arc/Makefile</span>
<span class="p_header">+++ b/arch/arc/Makefile</span>
<span class="p_chunk">@@ -43,7 +43,8 @@</span> <span class="p_context"> endif</span>
 
 ifndef CONFIG_CC_OPTIMIZE_FOR_SIZE
 # Generic build system uses -O2, we want -O3
<span class="p_del">-cflags-y  += -O3</span>
<span class="p_add">+# Note: No need to add to cflags-y as that happens anyways</span>
<span class="p_add">+ARCH_CFLAGS += -O3</span>
 endif
 
 # small data is default for elf32 tool-chain. If not usable, disable it
<span class="p_header">diff --git a/arch/arc/include/asm/ptrace.h b/arch/arc/include/asm/ptrace.h</span>
<span class="p_header">index 1bfeec2..2a58af7 100644</span>
<span class="p_header">--- a/arch/arc/include/asm/ptrace.h</span>
<span class="p_header">+++ b/arch/arc/include/asm/ptrace.h</span>
<span class="p_chunk">@@ -63,7 +63,7 @@</span> <span class="p_context"> struct callee_regs {</span>
 	long r25, r24, r23, r22, r21, r20, r19, r18, r17, r16, r15, r14, r13;
 };
 
<span class="p_del">-#define instruction_pointer(regs)	((regs)-&gt;ret)</span>
<span class="p_add">+#define instruction_pointer(regs)	(unsigned long)((regs)-&gt;ret)</span>
 #define profile_pc(regs)		instruction_pointer(regs)
 
 /* return 1 if user mode or 0 if kernel mode */
<span class="p_header">diff --git a/arch/arm/boot/dts/am57xx-beagle-x15.dts b/arch/arm/boot/dts/am57xx-beagle-x15.dts</span>
<span class="p_header">index bcc2f95..dcd2f5d 100644</span>
<span class="p_header">--- a/arch/arm/boot/dts/am57xx-beagle-x15.dts</span>
<span class="p_header">+++ b/arch/arm/boot/dts/am57xx-beagle-x15.dts</span>
<span class="p_chunk">@@ -398,6 +398,10 @@</span> <span class="p_context"></span>
 	phy-supply = &lt;&amp;ldousb_reg&gt;;
 };
 
<span class="p_add">+&amp;usb2_phy2 {</span>
<span class="p_add">+	phy-supply = &lt;&amp;ldousb_reg&gt;;</span>
<span class="p_add">+};</span>
<span class="p_add">+</span>
 &amp;usb1 {
 	dr_mode = &quot;host&quot;;
 	pinctrl-names = &quot;default&quot;;
<span class="p_header">diff --git a/arch/arm/boot/dts/dra7-evm.dts b/arch/arm/boot/dts/dra7-evm.dts</span>
<span class="p_header">index ad4118f..3af44b8 100644</span>
<span class="p_header">--- a/arch/arm/boot/dts/dra7-evm.dts</span>
<span class="p_header">+++ b/arch/arm/boot/dts/dra7-evm.dts</span>
<span class="p_chunk">@@ -657,7 +657,8 @@</span> <span class="p_context"></span>
 
 &amp;dcan1 {
 	status = &quot;ok&quot;;
<span class="p_del">-	pinctrl-names = &quot;default&quot;, &quot;sleep&quot;;</span>
<span class="p_del">-	pinctrl-0 = &lt;&amp;dcan1_pins_default&gt;;</span>
<span class="p_add">+	pinctrl-names = &quot;default&quot;, &quot;sleep&quot;, &quot;active&quot;;</span>
<span class="p_add">+	pinctrl-0 = &lt;&amp;dcan1_pins_sleep&gt;;</span>
 	pinctrl-1 = &lt;&amp;dcan1_pins_sleep&gt;;
<span class="p_add">+	pinctrl-2 = &lt;&amp;dcan1_pins_default&gt;;</span>
 };
<span class="p_header">diff --git a/arch/arm/boot/dts/dra72-evm.dts b/arch/arm/boot/dts/dra72-evm.dts</span>
<span class="p_header">index 89085d0..64da6bb 100644</span>
<span class="p_header">--- a/arch/arm/boot/dts/dra72-evm.dts</span>
<span class="p_header">+++ b/arch/arm/boot/dts/dra72-evm.dts</span>
<span class="p_chunk">@@ -457,7 +457,8 @@</span> <span class="p_context"></span>
 
 &amp;dcan1 {
 	status = &quot;ok&quot;;
<span class="p_del">-	pinctrl-names = &quot;default&quot;, &quot;sleep&quot;;</span>
<span class="p_del">-	pinctrl-0 = &lt;&amp;dcan1_pins_default&gt;;</span>
<span class="p_add">+	pinctrl-names = &quot;default&quot;, &quot;sleep&quot;, &quot;active&quot;;</span>
<span class="p_add">+	pinctrl-0 = &lt;&amp;dcan1_pins_sleep&gt;;</span>
 	pinctrl-1 = &lt;&amp;dcan1_pins_sleep&gt;;
<span class="p_add">+	pinctrl-2 = &lt;&amp;dcan1_pins_default&gt;;</span>
 };
<span class="p_header">diff --git a/arch/arm/boot/dts/imx23.dtsi b/arch/arm/boot/dts/imx23.dtsi</span>
<span class="p_header">index bbcfb5a..0cb8b0b 100644</span>
<span class="p_header">--- a/arch/arm/boot/dts/imx23.dtsi</span>
<span class="p_header">+++ b/arch/arm/boot/dts/imx23.dtsi</span>
<span class="p_chunk">@@ -435,6 +435,7 @@</span> <span class="p_context"></span>
 				interrupts = &lt;36 37 38 39 40 41 42 43 44&gt;;
 				status = &quot;disabled&quot;;
 				clocks = &lt;&amp;clks 26&gt;;
<span class="p_add">+				#io-channel-cells = &lt;1&gt;;</span>
 			};
 
 			spdif@80054000 {
<span class="p_header">diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c</span>
<span class="p_header">index 86ef244..f2a43a1 100644</span>
<span class="p_header">--- a/arch/arm/kernel/smp.c</span>
<span class="p_header">+++ b/arch/arm/kernel/smp.c</span>
<span class="p_chunk">@@ -571,7 +571,7 @@</span> <span class="p_context"> void handle_IPI(int ipinr, struct pt_regs *regs)</span>
 	struct pt_regs *old_regs = set_irq_regs(regs);
 
 	if ((unsigned)ipinr &lt; NR_IPI) {
<span class="p_del">-		trace_ipi_entry(ipi_types[ipinr]);</span>
<span class="p_add">+		trace_ipi_entry_rcuidle(ipi_types[ipinr]);</span>
 		__inc_irq_stat(cpu, ipi_irqs[ipinr]);
 	}
 
<span class="p_chunk">@@ -630,7 +630,7 @@</span> <span class="p_context"> void handle_IPI(int ipinr, struct pt_regs *regs)</span>
 	}
 
 	if ((unsigned)ipinr &lt; NR_IPI)
<span class="p_del">-		trace_ipi_exit(ipi_types[ipinr]);</span>
<span class="p_add">+		trace_ipi_exit_rcuidle(ipi_types[ipinr]);</span>
 	set_irq_regs(old_regs);
 }
 
<span class="p_header">diff --git a/arch/arm/mm/dma-mapping.c b/arch/arm/mm/dma-mapping.c</span>
<span class="p_header">index 903dba0..bc074ef 100644</span>
<span class="p_header">--- a/arch/arm/mm/dma-mapping.c</span>
<span class="p_header">+++ b/arch/arm/mm/dma-mapping.c</span>
<span class="p_chunk">@@ -1919,7 +1919,7 @@</span> <span class="p_context"> static int extend_iommu_mapping(struct dma_iommu_mapping *mapping)</span>
 {
 	int next_bitmap;
 
<span class="p_del">-	if (mapping-&gt;nr_bitmaps &gt; mapping-&gt;extensions)</span>
<span class="p_add">+	if (mapping-&gt;nr_bitmaps &gt;= mapping-&gt;extensions)</span>
 		return -EINVAL;
 
 	next_bitmap = mapping-&gt;nr_bitmaps;
<span class="p_header">diff --git a/arch/parisc/include/asm/pgtable.h b/arch/parisc/include/asm/pgtable.h</span>
<span class="p_header">index 22b89d1..5721793 100644</span>
<span class="p_header">--- a/arch/parisc/include/asm/pgtable.h</span>
<span class="p_header">+++ b/arch/parisc/include/asm/pgtable.h</span>
<span class="p_chunk">@@ -16,7 +16,7 @@</span> <span class="p_context"></span>
 #include &lt;asm/processor.h&gt;
 #include &lt;asm/cache.h&gt;
 
<span class="p_del">-extern spinlock_t pa_dbit_lock;</span>
<span class="p_add">+extern spinlock_t pa_tlb_lock;</span>
 
 /*
  * kern_addr_valid(ADDR) tests if ADDR is pointing to valid kernel
<span class="p_chunk">@@ -33,6 +33,19 @@</span> <span class="p_context"> extern spinlock_t pa_dbit_lock;</span>
  */
 #define kern_addr_valid(addr)	(1)
 
<span class="p_add">+/* Purge data and instruction TLB entries.  Must be called holding</span>
<span class="p_add">+ * the pa_tlb_lock.  The TLB purge instructions are slow on SMP</span>
<span class="p_add">+ * machines since the purge must be broadcast to all CPUs.</span>
<span class="p_add">+ */</span>
<span class="p_add">+</span>
<span class="p_add">+static inline void purge_tlb_entries(struct mm_struct *mm, unsigned long addr)</span>
<span class="p_add">+{</span>
<span class="p_add">+	mtsp(mm-&gt;context, 1);</span>
<span class="p_add">+	pdtlb(addr);</span>
<span class="p_add">+	if (unlikely(split_tlb))</span>
<span class="p_add">+		pitlb(addr);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 /* Certain architectures need to do special things when PTEs
  * within a page table are directly modified.  Thus, the following
  * hook is made available.
<span class="p_chunk">@@ -42,15 +55,20 @@</span> <span class="p_context"> extern spinlock_t pa_dbit_lock;</span>
                 *(pteptr) = (pteval);                           \
         } while(0)
 
<span class="p_del">-extern void purge_tlb_entries(struct mm_struct *, unsigned long);</span>
<span class="p_add">+#define pte_inserted(x)						\</span>
<span class="p_add">+	((pte_val(x) &amp; (_PAGE_PRESENT|_PAGE_ACCESSED))		\</span>
<span class="p_add">+	 == (_PAGE_PRESENT|_PAGE_ACCESSED))</span>
 
<span class="p_del">-#define set_pte_at(mm, addr, ptep, pteval)                      \</span>
<span class="p_del">-	do {                                                    \</span>
<span class="p_add">+#define set_pte_at(mm, addr, ptep, pteval)			\</span>
<span class="p_add">+	do {							\</span>
<span class="p_add">+		pte_t old_pte;					\</span>
 		unsigned long flags;				\
<span class="p_del">-		spin_lock_irqsave(&amp;pa_dbit_lock, flags);	\</span>
<span class="p_del">-		set_pte(ptep, pteval);                          \</span>
<span class="p_del">-		purge_tlb_entries(mm, addr);                    \</span>
<span class="p_del">-		spin_unlock_irqrestore(&amp;pa_dbit_lock, flags);	\</span>
<span class="p_add">+		spin_lock_irqsave(&amp;pa_tlb_lock, flags);		\</span>
<span class="p_add">+		old_pte = *ptep;				\</span>
<span class="p_add">+		set_pte(ptep, pteval);				\</span>
<span class="p_add">+		if (pte_inserted(old_pte))			\</span>
<span class="p_add">+			purge_tlb_entries(mm, addr);		\</span>
<span class="p_add">+		spin_unlock_irqrestore(&amp;pa_tlb_lock, flags);	\</span>
 	} while (0)
 
 #endif /* !__ASSEMBLY__ */
<span class="p_chunk">@@ -278,7 +296,7 @@</span> <span class="p_context"> extern unsigned long *empty_zero_page;</span>
 
 #define pte_none(x)     (pte_val(x) == 0)
 #define pte_present(x)	(pte_val(x) &amp; _PAGE_PRESENT)
<span class="p_del">-#define pte_clear(mm,addr,xp)	do { pte_val(*(xp)) = 0; } while (0)</span>
<span class="p_add">+#define pte_clear(mm, addr, xp)  set_pte_at(mm, addr, xp, __pte(0))</span>
 
 #define pmd_flag(x)	(pmd_val(x) &amp; PxD_FLAG_MASK)
 #define pmd_address(x)	((unsigned long)(pmd_val(x) &amp;~ PxD_FLAG_MASK) &lt;&lt; PxD_VALUE_SHIFT)
<span class="p_chunk">@@ -446,15 +464,15 @@</span> <span class="p_context"> static inline int ptep_test_and_clear_young(struct vm_area_struct *vma, unsigned</span>
 	if (!pte_young(*ptep))
 		return 0;
 
<span class="p_del">-	spin_lock_irqsave(&amp;pa_dbit_lock, flags);</span>
<span class="p_add">+	spin_lock_irqsave(&amp;pa_tlb_lock, flags);</span>
 	pte = *ptep;
 	if (!pte_young(pte)) {
<span class="p_del">-		spin_unlock_irqrestore(&amp;pa_dbit_lock, flags);</span>
<span class="p_add">+		spin_unlock_irqrestore(&amp;pa_tlb_lock, flags);</span>
 		return 0;
 	}
 	set_pte(ptep, pte_mkold(pte));
 	purge_tlb_entries(vma-&gt;vm_mm, addr);
<span class="p_del">-	spin_unlock_irqrestore(&amp;pa_dbit_lock, flags);</span>
<span class="p_add">+	spin_unlock_irqrestore(&amp;pa_tlb_lock, flags);</span>
 	return 1;
 }
 
<span class="p_chunk">@@ -464,11 +482,12 @@</span> <span class="p_context"> static inline pte_t ptep_get_and_clear(struct mm_struct *mm, unsigned long addr,</span>
 	pte_t old_pte;
 	unsigned long flags;
 
<span class="p_del">-	spin_lock_irqsave(&amp;pa_dbit_lock, flags);</span>
<span class="p_add">+	spin_lock_irqsave(&amp;pa_tlb_lock, flags);</span>
 	old_pte = *ptep;
<span class="p_del">-	pte_clear(mm,addr,ptep);</span>
<span class="p_del">-	purge_tlb_entries(mm, addr);</span>
<span class="p_del">-	spin_unlock_irqrestore(&amp;pa_dbit_lock, flags);</span>
<span class="p_add">+	set_pte(ptep, __pte(0));</span>
<span class="p_add">+	if (pte_inserted(old_pte))</span>
<span class="p_add">+		purge_tlb_entries(mm, addr);</span>
<span class="p_add">+	spin_unlock_irqrestore(&amp;pa_tlb_lock, flags);</span>
 
 	return old_pte;
 }
<span class="p_chunk">@@ -476,10 +495,10 @@</span> <span class="p_context"> static inline pte_t ptep_get_and_clear(struct mm_struct *mm, unsigned long addr,</span>
 static inline void ptep_set_wrprotect(struct mm_struct *mm, unsigned long addr, pte_t *ptep)
 {
 	unsigned long flags;
<span class="p_del">-	spin_lock_irqsave(&amp;pa_dbit_lock, flags);</span>
<span class="p_add">+	spin_lock_irqsave(&amp;pa_tlb_lock, flags);</span>
 	set_pte(ptep, pte_wrprotect(*ptep));
 	purge_tlb_entries(mm, addr);
<span class="p_del">-	spin_unlock_irqrestore(&amp;pa_dbit_lock, flags);</span>
<span class="p_add">+	spin_unlock_irqrestore(&amp;pa_tlb_lock, flags);</span>
 }
 
 #define pte_same(A,B)	(pte_val(A) == pte_val(B))
<span class="p_header">diff --git a/arch/parisc/include/asm/tlbflush.h b/arch/parisc/include/asm/tlbflush.h</span>
<span class="p_header">index 9d086a5..e84b964 100644</span>
<span class="p_header">--- a/arch/parisc/include/asm/tlbflush.h</span>
<span class="p_header">+++ b/arch/parisc/include/asm/tlbflush.h</span>
<span class="p_chunk">@@ -13,6 +13,9 @@</span> <span class="p_context"></span>
  * active at any one time on the Merced bus.  This tlb purge
  * synchronisation is fairly lightweight and harmless so we activate
  * it on all systems not just the N class.
<span class="p_add">+</span>
<span class="p_add">+ * It is also used to ensure PTE updates are atomic and consistent</span>
<span class="p_add">+ * with the TLB.</span>
  */
 extern spinlock_t pa_tlb_lock;
 
<span class="p_chunk">@@ -24,20 +27,24 @@</span> <span class="p_context"> extern void flush_tlb_all_local(void *);</span>
 
 #define smp_flush_tlb_all()	flush_tlb_all()
 
<span class="p_add">+int __flush_tlb_range(unsigned long sid,</span>
<span class="p_add">+	unsigned long start, unsigned long end);</span>
<span class="p_add">+</span>
<span class="p_add">+#define flush_tlb_range(vma, start, end) \</span>
<span class="p_add">+	__flush_tlb_range((vma)-&gt;vm_mm-&gt;context, start, end)</span>
<span class="p_add">+</span>
<span class="p_add">+#define flush_tlb_kernel_range(start, end) \</span>
<span class="p_add">+	__flush_tlb_range(0, start, end)</span>
<span class="p_add">+</span>
 /*
  * flush_tlb_mm()
  *
<span class="p_del">- * XXX This code is NOT valid for HP-UX compatibility processes,</span>
<span class="p_del">- * (although it will probably work 99% of the time). HP-UX</span>
<span class="p_del">- * processes are free to play with the space id&#39;s and save them</span>
<span class="p_del">- * over long periods of time, etc. so we have to preserve the</span>
<span class="p_del">- * space and just flush the entire tlb. We need to check the</span>
<span class="p_del">- * personality in order to do that, but the personality is not</span>
<span class="p_del">- * currently being set correctly.</span>
<span class="p_del">- *</span>
<span class="p_del">- * Of course, Linux processes could do the same thing, but</span>
<span class="p_del">- * we don&#39;t support that (and the compilers, dynamic linker,</span>
<span class="p_del">- * etc. do not do that).</span>
<span class="p_add">+ * The code to switch to a new context is NOT valid for processes</span>
<span class="p_add">+ * which play with the space id&#39;s.  Thus, we have to preserve the</span>
<span class="p_add">+ * space and just flush the entire tlb.  However, the compilers,</span>
<span class="p_add">+ * dynamic linker, etc, do not manipulate space id&#39;s, so there</span>
<span class="p_add">+ * could be a significant performance benefit in switching contexts</span>
<span class="p_add">+ * and not flushing the whole tlb.</span>
  */
 
 static inline void flush_tlb_mm(struct mm_struct *mm)
<span class="p_chunk">@@ -45,10 +52,18 @@</span> <span class="p_context"> static inline void flush_tlb_mm(struct mm_struct *mm)</span>
 	BUG_ON(mm == &amp;init_mm); /* Should never happen */
 
 #if 1 || defined(CONFIG_SMP)
<span class="p_add">+	/* Except for very small threads, flushing the whole TLB is</span>
<span class="p_add">+	 * faster than using __flush_tlb_range.  The pdtlb and pitlb</span>
<span class="p_add">+	 * instructions are very slow because of the TLB broadcast.</span>
<span class="p_add">+	 * It might be faster to do local range flushes on all CPUs</span>
<span class="p_add">+	 * on PA 2.0 systems.</span>
<span class="p_add">+	 */</span>
 	flush_tlb_all();
 #else
 	/* FIXME: currently broken, causing space id and protection ids
<span class="p_del">-	 *  to go out of sync, resulting in faults on userspace accesses.</span>
<span class="p_add">+	 * to go out of sync, resulting in faults on userspace accesses.</span>
<span class="p_add">+	 * This approach needs further investigation since running many</span>
<span class="p_add">+	 * small applications (e.g., GCC testsuite) is faster on HP-UX.</span>
 	 */
 	if (mm) {
 		if (mm-&gt;context != 0)
<span class="p_chunk">@@ -65,22 +80,12 @@</span> <span class="p_context"> static inline void flush_tlb_page(struct vm_area_struct *vma,</span>
 {
 	unsigned long flags, sid;
 
<span class="p_del">-	/* For one page, it&#39;s not worth testing the split_tlb variable */</span>
<span class="p_del">-</span>
<span class="p_del">-	mb();</span>
 	sid = vma-&gt;vm_mm-&gt;context;
 	purge_tlb_start(flags);
 	mtsp(sid, 1);
 	pdtlb(addr);
<span class="p_del">-	pitlb(addr);</span>
<span class="p_add">+	if (unlikely(split_tlb))</span>
<span class="p_add">+		pitlb(addr);</span>
 	purge_tlb_end(flags);
 }
<span class="p_del">-</span>
<span class="p_del">-void __flush_tlb_range(unsigned long sid,</span>
<span class="p_del">-	unsigned long start, unsigned long end);</span>
<span class="p_del">-</span>
<span class="p_del">-#define flush_tlb_range(vma,start,end) __flush_tlb_range((vma)-&gt;vm_mm-&gt;context,start,end)</span>
<span class="p_del">-</span>
<span class="p_del">-#define flush_tlb_kernel_range(start, end) __flush_tlb_range(0,start,end)</span>
<span class="p_del">-</span>
 #endif
<span class="p_header">diff --git a/arch/parisc/kernel/cache.c b/arch/parisc/kernel/cache.c</span>
<span class="p_header">index f6448c7..cda6dbb 100644</span>
<span class="p_header">--- a/arch/parisc/kernel/cache.c</span>
<span class="p_header">+++ b/arch/parisc/kernel/cache.c</span>
<span class="p_chunk">@@ -342,12 +342,15 @@</span> <span class="p_context"> EXPORT_SYMBOL(flush_data_cache_local);</span>
 EXPORT_SYMBOL(flush_kernel_icache_range_asm);
 
 #define FLUSH_THRESHOLD 0x80000 /* 0.5MB */
<span class="p_del">-int parisc_cache_flush_threshold __read_mostly = FLUSH_THRESHOLD;</span>
<span class="p_add">+static unsigned long parisc_cache_flush_threshold __read_mostly = FLUSH_THRESHOLD;</span>
<span class="p_add">+</span>
<span class="p_add">+#define FLUSH_TLB_THRESHOLD (2*1024*1024) /* 2MB initial TLB threshold */</span>
<span class="p_add">+static unsigned long parisc_tlb_flush_threshold __read_mostly = FLUSH_TLB_THRESHOLD;</span>
 
 void __init parisc_setup_cache_timing(void)
 {
 	unsigned long rangetime, alltime;
<span class="p_del">-	unsigned long size;</span>
<span class="p_add">+	unsigned long size, start;</span>
 
 	alltime = mfctl(16);
 	flush_data_cache();
<span class="p_chunk">@@ -364,14 +367,43 @@</span> <span class="p_context"> void __init parisc_setup_cache_timing(void)</span>
 	/* Racy, but if we see an intermediate value, it&#39;s ok too... */
 	parisc_cache_flush_threshold = size * alltime / rangetime;
 
<span class="p_del">-	parisc_cache_flush_threshold = (parisc_cache_flush_threshold + L1_CACHE_BYTES - 1) &amp;~ (L1_CACHE_BYTES - 1); </span>
<span class="p_add">+	parisc_cache_flush_threshold = L1_CACHE_ALIGN(parisc_cache_flush_threshold);</span>
 	if (!parisc_cache_flush_threshold)
 		parisc_cache_flush_threshold = FLUSH_THRESHOLD;
 
 	if (parisc_cache_flush_threshold &gt; cache_info.dc_size)
 		parisc_cache_flush_threshold = cache_info.dc_size;
 
<span class="p_del">-	printk(KERN_INFO &quot;Setting cache flush threshold to %x (%d CPUs online)\n&quot;, parisc_cache_flush_threshold, num_online_cpus());</span>
<span class="p_add">+	printk(KERN_INFO &quot;Setting cache flush threshold to %lu kB\n&quot;,</span>
<span class="p_add">+		parisc_cache_flush_threshold/1024);</span>
<span class="p_add">+</span>
<span class="p_add">+	/* calculate TLB flush threshold */</span>
<span class="p_add">+</span>
<span class="p_add">+	alltime = mfctl(16);</span>
<span class="p_add">+	flush_tlb_all();</span>
<span class="p_add">+	alltime = mfctl(16) - alltime;</span>
<span class="p_add">+</span>
<span class="p_add">+	size = PAGE_SIZE;</span>
<span class="p_add">+	start = (unsigned long) _text;</span>
<span class="p_add">+	rangetime = mfctl(16);</span>
<span class="p_add">+	while (start &lt; (unsigned long) _end) {</span>
<span class="p_add">+		flush_tlb_kernel_range(start, start + PAGE_SIZE);</span>
<span class="p_add">+		start += PAGE_SIZE;</span>
<span class="p_add">+		size += PAGE_SIZE;</span>
<span class="p_add">+	}</span>
<span class="p_add">+	rangetime = mfctl(16) - rangetime;</span>
<span class="p_add">+</span>
<span class="p_add">+	printk(KERN_DEBUG &quot;Whole TLB flush %lu cycles, flushing %lu bytes %lu cycles\n&quot;,</span>
<span class="p_add">+		alltime, size, rangetime);</span>
<span class="p_add">+</span>
<span class="p_add">+	parisc_tlb_flush_threshold = size * alltime / rangetime;</span>
<span class="p_add">+	parisc_tlb_flush_threshold *= num_online_cpus();</span>
<span class="p_add">+	parisc_tlb_flush_threshold = PAGE_ALIGN(parisc_tlb_flush_threshold);</span>
<span class="p_add">+	if (!parisc_tlb_flush_threshold)</span>
<span class="p_add">+		parisc_tlb_flush_threshold = FLUSH_TLB_THRESHOLD;</span>
<span class="p_add">+</span>
<span class="p_add">+	printk(KERN_INFO &quot;Setting TLB flush threshold to %lu kB\n&quot;,</span>
<span class="p_add">+		parisc_tlb_flush_threshold/1024);</span>
 }
 
 extern void purge_kernel_dcache_page_asm(unsigned long);
<span class="p_chunk">@@ -403,48 +435,45 @@</span> <span class="p_context"> void copy_user_page(void *vto, void *vfrom, unsigned long vaddr,</span>
 }
 EXPORT_SYMBOL(copy_user_page);
 
<span class="p_del">-void purge_tlb_entries(struct mm_struct *mm, unsigned long addr)</span>
<span class="p_del">-{</span>
<span class="p_del">-	unsigned long flags;</span>
<span class="p_del">-</span>
<span class="p_del">-	/* Note: purge_tlb_entries can be called at startup with</span>
<span class="p_del">-	   no context.  */</span>
<span class="p_del">-</span>
<span class="p_del">-	purge_tlb_start(flags);</span>
<span class="p_del">-	mtsp(mm-&gt;context, 1);</span>
<span class="p_del">-	pdtlb(addr);</span>
<span class="p_del">-	pitlb(addr);</span>
<span class="p_del">-	purge_tlb_end(flags);</span>
<span class="p_del">-}</span>
<span class="p_del">-EXPORT_SYMBOL(purge_tlb_entries);</span>
<span class="p_del">-</span>
<span class="p_del">-void __flush_tlb_range(unsigned long sid, unsigned long start,</span>
<span class="p_del">-		       unsigned long end)</span>
<span class="p_add">+/* __flush_tlb_range()</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * returns 1 if all TLBs were flushed.</span>
<span class="p_add">+ */</span>
<span class="p_add">+int __flush_tlb_range(unsigned long sid, unsigned long start,</span>
<span class="p_add">+		      unsigned long end)</span>
 {
<span class="p_del">-	unsigned long npages;</span>
<span class="p_add">+	unsigned long flags, size;</span>
 
<span class="p_del">-	npages = ((end - (start &amp; PAGE_MASK)) + (PAGE_SIZE - 1)) &gt;&gt; PAGE_SHIFT;</span>
<span class="p_del">-	if (npages &gt;= 512)  /* 2MB of space: arbitrary, should be tuned */</span>
<span class="p_add">+	size = (end - start);</span>
<span class="p_add">+	if (size &gt;= parisc_tlb_flush_threshold) {</span>
 		flush_tlb_all();
<span class="p_del">-	else {</span>
<span class="p_del">-		unsigned long flags;</span>
<span class="p_add">+		return 1;</span>
<span class="p_add">+	}</span>
 
<span class="p_add">+	/* Purge TLB entries for small ranges using the pdtlb and</span>
<span class="p_add">+	   pitlb instructions.  These instructions execute locally</span>
<span class="p_add">+	   but cause a purge request to be broadcast to other TLBs.  */</span>
<span class="p_add">+	if (likely(!split_tlb)) {</span>
<span class="p_add">+		while (start &lt; end) {</span>
<span class="p_add">+			purge_tlb_start(flags);</span>
<span class="p_add">+			mtsp(sid, 1);</span>
<span class="p_add">+			pdtlb(start);</span>
<span class="p_add">+			purge_tlb_end(flags);</span>
<span class="p_add">+			start += PAGE_SIZE;</span>
<span class="p_add">+		}</span>
<span class="p_add">+		return 0;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	/* split TLB case */</span>
<span class="p_add">+	while (start &lt; end) {</span>
 		purge_tlb_start(flags);
 		mtsp(sid, 1);
<span class="p_del">-		if (split_tlb) {</span>
<span class="p_del">-			while (npages--) {</span>
<span class="p_del">-				pdtlb(start);</span>
<span class="p_del">-				pitlb(start);</span>
<span class="p_del">-				start += PAGE_SIZE;</span>
<span class="p_del">-			}</span>
<span class="p_del">-		} else {</span>
<span class="p_del">-			while (npages--) {</span>
<span class="p_del">-				pdtlb(start);</span>
<span class="p_del">-				start += PAGE_SIZE;</span>
<span class="p_del">-			}</span>
<span class="p_del">-		}</span>
<span class="p_add">+		pdtlb(start);</span>
<span class="p_add">+		pitlb(start);</span>
 		purge_tlb_end(flags);
<span class="p_add">+		start += PAGE_SIZE;</span>
 	}
<span class="p_add">+	return 0;</span>
 }
 
 static void cacheflush_h_tmp_function(void *dummy)
<span class="p_header">diff --git a/arch/parisc/kernel/entry.S b/arch/parisc/kernel/entry.S</span>
<span class="p_header">index e8f07dd..fd377ef 100644</span>
<span class="p_header">--- a/arch/parisc/kernel/entry.S</span>
<span class="p_header">+++ b/arch/parisc/kernel/entry.S</span>
<span class="p_chunk">@@ -45,7 +45,7 @@</span> <span class="p_context"></span>
 	.level 2.0
 #endif
 
<span class="p_del">-	.import         pa_dbit_lock,data</span>
<span class="p_add">+	.import		pa_tlb_lock,data</span>
 
 	/* space_to_prot macro creates a prot id from a space id */
 
<span class="p_chunk">@@ -420,8 +420,8 @@</span> <span class="p_context"></span>
 	SHLREG		%r9,PxD_VALUE_SHIFT,\pmd
 	extru		\va,31-PAGE_SHIFT,ASM_BITS_PER_PTE,\index
 	dep		%r0,31,PAGE_SHIFT,\pmd  /* clear offset */
<span class="p_del">-	shladd		\index,BITS_PER_PTE_ENTRY,\pmd,\pmd</span>
<span class="p_del">-	LDREG		%r0(\pmd),\pte		/* pmd is now pte */</span>
<span class="p_add">+	shladd		\index,BITS_PER_PTE_ENTRY,\pmd,\pmd /* pmd is now pte */</span>
<span class="p_add">+	LDREG		%r0(\pmd),\pte</span>
 	bb,&gt;=,n		\pte,_PAGE_PRESENT_BIT,\fault
 	.endm
 
<span class="p_chunk">@@ -453,57 +453,53 @@</span> <span class="p_context"></span>
 	L2_ptep		\pgd,\pte,\index,\va,\fault
 	.endm
 
<span class="p_del">-	/* Acquire pa_dbit_lock lock. */</span>
<span class="p_del">-	.macro		dbit_lock	spc,tmp,tmp1</span>
<span class="p_add">+	/* Acquire pa_tlb_lock lock and recheck page is still present. */</span>
<span class="p_add">+	.macro		tlb_lock	spc,ptp,pte,tmp,tmp1,fault</span>
 #ifdef CONFIG_SMP
 	cmpib,COND(=),n	0,\spc,2f
<span class="p_del">-	load32		PA(pa_dbit_lock),\tmp</span>
<span class="p_add">+	load32		PA(pa_tlb_lock),\tmp</span>
 1:	LDCW		0(\tmp),\tmp1
 	cmpib,COND(=)	0,\tmp1,1b
 	nop
<span class="p_add">+	LDREG		0(\ptp),\pte</span>
<span class="p_add">+	bb,&lt;,n		\pte,_PAGE_PRESENT_BIT,2f</span>
<span class="p_add">+	b		\fault</span>
<span class="p_add">+	stw		 \spc,0(\tmp)</span>
 2:
 #endif
 	.endm
 
<span class="p_del">-	/* Release pa_dbit_lock lock without reloading lock address. */</span>
<span class="p_del">-	.macro		dbit_unlock0	spc,tmp</span>
<span class="p_add">+	/* Release pa_tlb_lock lock without reloading lock address. */</span>
<span class="p_add">+	.macro		tlb_unlock0	spc,tmp</span>
 #ifdef CONFIG_SMP
 	or,COND(=)	%r0,\spc,%r0
 	stw             \spc,0(\tmp)
 #endif
 	.endm
 
<span class="p_del">-	/* Release pa_dbit_lock lock. */</span>
<span class="p_del">-	.macro		dbit_unlock1	spc,tmp</span>
<span class="p_add">+	/* Release pa_tlb_lock lock. */</span>
<span class="p_add">+	.macro		tlb_unlock1	spc,tmp</span>
 #ifdef CONFIG_SMP
<span class="p_del">-	load32		PA(pa_dbit_lock),\tmp</span>
<span class="p_del">-	dbit_unlock0	\spc,\tmp</span>
<span class="p_add">+	load32		PA(pa_tlb_lock),\tmp</span>
<span class="p_add">+	tlb_unlock0	\spc,\tmp</span>
 #endif
 	.endm
 
 	/* Set the _PAGE_ACCESSED bit of the PTE.  Be clever and
 	 * don&#39;t needlessly dirty the cache line if it was already set */
<span class="p_del">-	.macro		update_ptep	spc,ptep,pte,tmp,tmp1</span>
<span class="p_del">-#ifdef CONFIG_SMP</span>
<span class="p_del">-	or,COND(=)	%r0,\spc,%r0</span>
<span class="p_del">-	LDREG		0(\ptep),\pte</span>
<span class="p_del">-#endif</span>
<span class="p_add">+	.macro		update_accessed	ptp,pte,tmp,tmp1</span>
 	ldi		_PAGE_ACCESSED,\tmp1
 	or		\tmp1,\pte,\tmp
 	and,COND(&lt;&gt;)	\tmp1,\pte,%r0
<span class="p_del">-	STREG		\tmp,0(\ptep)</span>
<span class="p_add">+	STREG		\tmp,0(\ptp)</span>
 	.endm
 
 	/* Set the dirty bit (and accessed bit).  No need to be
 	 * clever, this is only used from the dirty fault */
<span class="p_del">-	.macro		update_dirty	spc,ptep,pte,tmp</span>
<span class="p_del">-#ifdef CONFIG_SMP</span>
<span class="p_del">-	or,COND(=)	%r0,\spc,%r0</span>
<span class="p_del">-	LDREG		0(\ptep),\pte</span>
<span class="p_del">-#endif</span>
<span class="p_add">+	.macro		update_dirty	ptp,pte,tmp</span>
 	ldi		_PAGE_ACCESSED|_PAGE_DIRTY,\tmp
 	or		\tmp,\pte,\pte
<span class="p_del">-	STREG		\pte,0(\ptep)</span>
<span class="p_add">+	STREG		\pte,0(\ptp)</span>
 	.endm
 
 	/* bitshift difference between a PFN (based on kernel&#39;s PAGE_SIZE)
<span class="p_chunk">@@ -1148,14 +1144,14 @@</span> <span class="p_context"> dtlb_miss_20w:</span>
 
 	L3_ptep		ptp,pte,t0,va,dtlb_check_alias_20w
 
<span class="p_del">-	dbit_lock	spc,t0,t1</span>
<span class="p_del">-	update_ptep	spc,ptp,pte,t0,t1</span>
<span class="p_add">+	tlb_lock	spc,ptp,pte,t0,t1,dtlb_check_alias_20w</span>
<span class="p_add">+	update_accessed	ptp,pte,t0,t1</span>
 
 	make_insert_tlb	spc,pte,prot
 	
 	idtlbt          pte,prot
<span class="p_del">-	dbit_unlock1	spc,t0</span>
 
<span class="p_add">+	tlb_unlock1	spc,t0</span>
 	rfir
 	nop
 
<span class="p_chunk">@@ -1174,14 +1170,14 @@</span> <span class="p_context"> nadtlb_miss_20w:</span>
 
 	L3_ptep		ptp,pte,t0,va,nadtlb_check_alias_20w
 
<span class="p_del">-	dbit_lock	spc,t0,t1</span>
<span class="p_del">-	update_ptep	spc,ptp,pte,t0,t1</span>
<span class="p_add">+	tlb_lock	spc,ptp,pte,t0,t1,nadtlb_check_alias_20w</span>
<span class="p_add">+	update_accessed	ptp,pte,t0,t1</span>
 
 	make_insert_tlb	spc,pte,prot
 
 	idtlbt          pte,prot
<span class="p_del">-	dbit_unlock1	spc,t0</span>
 
<span class="p_add">+	tlb_unlock1	spc,t0</span>
 	rfir
 	nop
 
<span class="p_chunk">@@ -1202,20 +1198,20 @@</span> <span class="p_context"> dtlb_miss_11:</span>
 
 	L2_ptep		ptp,pte,t0,va,dtlb_check_alias_11
 
<span class="p_del">-	dbit_lock	spc,t0,t1</span>
<span class="p_del">-	update_ptep	spc,ptp,pte,t0,t1</span>
<span class="p_add">+	tlb_lock	spc,ptp,pte,t0,t1,dtlb_check_alias_11</span>
<span class="p_add">+	update_accessed	ptp,pte,t0,t1</span>
 
 	make_insert_tlb_11	spc,pte,prot
 
<span class="p_del">-	mfsp		%sr1,t0  /* Save sr1 so we can use it in tlb inserts */</span>
<span class="p_add">+	mfsp		%sr1,t1  /* Save sr1 so we can use it in tlb inserts */</span>
 	mtsp		spc,%sr1
 
 	idtlba		pte,(%sr1,va)
 	idtlbp		prot,(%sr1,va)
 
<span class="p_del">-	mtsp		t0, %sr1	/* Restore sr1 */</span>
<span class="p_del">-	dbit_unlock1	spc,t0</span>
<span class="p_add">+	mtsp		t1, %sr1	/* Restore sr1 */</span>
 
<span class="p_add">+	tlb_unlock1	spc,t0</span>
 	rfir
 	nop
 
<span class="p_chunk">@@ -1235,21 +1231,20 @@</span> <span class="p_context"> nadtlb_miss_11:</span>
 
 	L2_ptep		ptp,pte,t0,va,nadtlb_check_alias_11
 
<span class="p_del">-	dbit_lock	spc,t0,t1</span>
<span class="p_del">-	update_ptep	spc,ptp,pte,t0,t1</span>
<span class="p_add">+	tlb_lock	spc,ptp,pte,t0,t1,nadtlb_check_alias_11</span>
<span class="p_add">+	update_accessed	ptp,pte,t0,t1</span>
 
 	make_insert_tlb_11	spc,pte,prot
 
<span class="p_del">-</span>
<span class="p_del">-	mfsp		%sr1,t0  /* Save sr1 so we can use it in tlb inserts */</span>
<span class="p_add">+	mfsp		%sr1,t1  /* Save sr1 so we can use it in tlb inserts */</span>
 	mtsp		spc,%sr1
 
 	idtlba		pte,(%sr1,va)
 	idtlbp		prot,(%sr1,va)
 
<span class="p_del">-	mtsp		t0, %sr1	/* Restore sr1 */</span>
<span class="p_del">-	dbit_unlock1	spc,t0</span>
<span class="p_add">+	mtsp		t1, %sr1	/* Restore sr1 */</span>
 
<span class="p_add">+	tlb_unlock1	spc,t0</span>
 	rfir
 	nop
 
<span class="p_chunk">@@ -1269,16 +1264,16 @@</span> <span class="p_context"> dtlb_miss_20:</span>
 
 	L2_ptep		ptp,pte,t0,va,dtlb_check_alias_20
 
<span class="p_del">-	dbit_lock	spc,t0,t1</span>
<span class="p_del">-	update_ptep	spc,ptp,pte,t0,t1</span>
<span class="p_add">+	tlb_lock	spc,ptp,pte,t0,t1,dtlb_check_alias_20</span>
<span class="p_add">+	update_accessed	ptp,pte,t0,t1</span>
 
 	make_insert_tlb	spc,pte,prot
 
<span class="p_del">-	f_extend	pte,t0</span>
<span class="p_add">+	f_extend	pte,t1</span>
 
 	idtlbt          pte,prot
<span class="p_del">-	dbit_unlock1	spc,t0</span>
 
<span class="p_add">+	tlb_unlock1	spc,t0</span>
 	rfir
 	nop
 
<span class="p_chunk">@@ -1297,16 +1292,16 @@</span> <span class="p_context"> nadtlb_miss_20:</span>
 
 	L2_ptep		ptp,pte,t0,va,nadtlb_check_alias_20
 
<span class="p_del">-	dbit_lock	spc,t0,t1</span>
<span class="p_del">-	update_ptep	spc,ptp,pte,t0,t1</span>
<span class="p_add">+	tlb_lock	spc,ptp,pte,t0,t1,nadtlb_check_alias_20</span>
<span class="p_add">+	update_accessed	ptp,pte,t0,t1</span>
 
 	make_insert_tlb	spc,pte,prot
 
<span class="p_del">-	f_extend	pte,t0</span>
<span class="p_add">+	f_extend	pte,t1</span>
 	
<span class="p_del">-        idtlbt          pte,prot</span>
<span class="p_del">-	dbit_unlock1	spc,t0</span>
<span class="p_add">+	idtlbt		pte,prot</span>
 
<span class="p_add">+	tlb_unlock1	spc,t0</span>
 	rfir
 	nop
 
<span class="p_chunk">@@ -1406,14 +1401,14 @@</span> <span class="p_context"> itlb_miss_20w:</span>
 
 	L3_ptep		ptp,pte,t0,va,itlb_fault
 
<span class="p_del">-	dbit_lock	spc,t0,t1</span>
<span class="p_del">-	update_ptep	spc,ptp,pte,t0,t1</span>
<span class="p_add">+	tlb_lock	spc,ptp,pte,t0,t1,itlb_fault</span>
<span class="p_add">+	update_accessed	ptp,pte,t0,t1</span>
 
 	make_insert_tlb	spc,pte,prot
 	
 	iitlbt          pte,prot
<span class="p_del">-	dbit_unlock1	spc,t0</span>
 
<span class="p_add">+	tlb_unlock1	spc,t0</span>
 	rfir
 	nop
 
<span class="p_chunk">@@ -1430,14 +1425,14 @@</span> <span class="p_context"> naitlb_miss_20w:</span>
 
 	L3_ptep		ptp,pte,t0,va,naitlb_check_alias_20w
 
<span class="p_del">-	dbit_lock	spc,t0,t1</span>
<span class="p_del">-	update_ptep	spc,ptp,pte,t0,t1</span>
<span class="p_add">+	tlb_lock	spc,ptp,pte,t0,t1,naitlb_check_alias_20w</span>
<span class="p_add">+	update_accessed	ptp,pte,t0,t1</span>
 
 	make_insert_tlb	spc,pte,prot
 
 	iitlbt          pte,prot
<span class="p_del">-	dbit_unlock1	spc,t0</span>
 
<span class="p_add">+	tlb_unlock1	spc,t0</span>
 	rfir
 	nop
 
<span class="p_chunk">@@ -1458,20 +1453,20 @@</span> <span class="p_context"> itlb_miss_11:</span>
 
 	L2_ptep		ptp,pte,t0,va,itlb_fault
 
<span class="p_del">-	dbit_lock	spc,t0,t1</span>
<span class="p_del">-	update_ptep	spc,ptp,pte,t0,t1</span>
<span class="p_add">+	tlb_lock	spc,ptp,pte,t0,t1,itlb_fault</span>
<span class="p_add">+	update_accessed	ptp,pte,t0,t1</span>
 
 	make_insert_tlb_11	spc,pte,prot
 
<span class="p_del">-	mfsp		%sr1,t0  /* Save sr1 so we can use it in tlb inserts */</span>
<span class="p_add">+	mfsp		%sr1,t1  /* Save sr1 so we can use it in tlb inserts */</span>
 	mtsp		spc,%sr1
 
 	iitlba		pte,(%sr1,va)
 	iitlbp		prot,(%sr1,va)
 
<span class="p_del">-	mtsp		t0, %sr1	/* Restore sr1 */</span>
<span class="p_del">-	dbit_unlock1	spc,t0</span>
<span class="p_add">+	mtsp		t1, %sr1	/* Restore sr1 */</span>
 
<span class="p_add">+	tlb_unlock1	spc,t0</span>
 	rfir
 	nop
 
<span class="p_chunk">@@ -1482,20 +1477,20 @@</span> <span class="p_context"> naitlb_miss_11:</span>
 
 	L2_ptep		ptp,pte,t0,va,naitlb_check_alias_11
 
<span class="p_del">-	dbit_lock	spc,t0,t1</span>
<span class="p_del">-	update_ptep	spc,ptp,pte,t0,t1</span>
<span class="p_add">+	tlb_lock	spc,ptp,pte,t0,t1,naitlb_check_alias_11</span>
<span class="p_add">+	update_accessed	ptp,pte,t0,t1</span>
 
 	make_insert_tlb_11	spc,pte,prot
 
<span class="p_del">-	mfsp		%sr1,t0  /* Save sr1 so we can use it in tlb inserts */</span>
<span class="p_add">+	mfsp		%sr1,t1  /* Save sr1 so we can use it in tlb inserts */</span>
 	mtsp		spc,%sr1
 
 	iitlba		pte,(%sr1,va)
 	iitlbp		prot,(%sr1,va)
 
<span class="p_del">-	mtsp		t0, %sr1	/* Restore sr1 */</span>
<span class="p_del">-	dbit_unlock1	spc,t0</span>
<span class="p_add">+	mtsp		t1, %sr1	/* Restore sr1 */</span>
 
<span class="p_add">+	tlb_unlock1	spc,t0</span>
 	rfir
 	nop
 
<span class="p_chunk">@@ -1516,16 +1511,16 @@</span> <span class="p_context"> itlb_miss_20:</span>
 
 	L2_ptep		ptp,pte,t0,va,itlb_fault
 
<span class="p_del">-	dbit_lock	spc,t0,t1</span>
<span class="p_del">-	update_ptep	spc,ptp,pte,t0,t1</span>
<span class="p_add">+	tlb_lock	spc,ptp,pte,t0,t1,itlb_fault</span>
<span class="p_add">+	update_accessed	ptp,pte,t0,t1</span>
 
 	make_insert_tlb	spc,pte,prot
 
<span class="p_del">-	f_extend	pte,t0	</span>
<span class="p_add">+	f_extend	pte,t1</span>
 
 	iitlbt          pte,prot
<span class="p_del">-	dbit_unlock1	spc,t0</span>
 
<span class="p_add">+	tlb_unlock1	spc,t0</span>
 	rfir
 	nop
 
<span class="p_chunk">@@ -1536,16 +1531,16 @@</span> <span class="p_context"> naitlb_miss_20:</span>
 
 	L2_ptep		ptp,pte,t0,va,naitlb_check_alias_20
 
<span class="p_del">-	dbit_lock	spc,t0,t1</span>
<span class="p_del">-	update_ptep	spc,ptp,pte,t0,t1</span>
<span class="p_add">+	tlb_lock	spc,ptp,pte,t0,t1,naitlb_check_alias_20</span>
<span class="p_add">+	update_accessed	ptp,pte,t0,t1</span>
 
 	make_insert_tlb	spc,pte,prot
 
<span class="p_del">-	f_extend	pte,t0</span>
<span class="p_add">+	f_extend	pte,t1</span>
 
 	iitlbt          pte,prot
<span class="p_del">-	dbit_unlock1	spc,t0</span>
 
<span class="p_add">+	tlb_unlock1	spc,t0</span>
 	rfir
 	nop
 
<span class="p_chunk">@@ -1568,14 +1563,14 @@</span> <span class="p_context"> dbit_trap_20w:</span>
 
 	L3_ptep		ptp,pte,t0,va,dbit_fault
 
<span class="p_del">-	dbit_lock	spc,t0,t1</span>
<span class="p_del">-	update_dirty	spc,ptp,pte,t1</span>
<span class="p_add">+	tlb_lock	spc,ptp,pte,t0,t1,dbit_fault</span>
<span class="p_add">+	update_dirty	ptp,pte,t1</span>
 
 	make_insert_tlb	spc,pte,prot
 		
 	idtlbt          pte,prot
<span class="p_del">-	dbit_unlock0	spc,t0</span>
 
<span class="p_add">+	tlb_unlock0	spc,t0</span>
 	rfir
 	nop
 #else
<span class="p_chunk">@@ -1588,8 +1583,8 @@</span> <span class="p_context"> dbit_trap_11:</span>
 
 	L2_ptep		ptp,pte,t0,va,dbit_fault
 
<span class="p_del">-	dbit_lock	spc,t0,t1</span>
<span class="p_del">-	update_dirty	spc,ptp,pte,t1</span>
<span class="p_add">+	tlb_lock	spc,ptp,pte,t0,t1,dbit_fault</span>
<span class="p_add">+	update_dirty	ptp,pte,t1</span>
 
 	make_insert_tlb_11	spc,pte,prot
 
<span class="p_chunk">@@ -1600,8 +1595,8 @@</span> <span class="p_context"> dbit_trap_11:</span>
 	idtlbp		prot,(%sr1,va)
 
 	mtsp            t1, %sr1     /* Restore sr1 */
<span class="p_del">-	dbit_unlock0	spc,t0</span>
 
<span class="p_add">+	tlb_unlock0	spc,t0</span>
 	rfir
 	nop
 
<span class="p_chunk">@@ -1612,16 +1607,16 @@</span> <span class="p_context"> dbit_trap_20:</span>
 
 	L2_ptep		ptp,pte,t0,va,dbit_fault
 
<span class="p_del">-	dbit_lock	spc,t0,t1</span>
<span class="p_del">-	update_dirty	spc,ptp,pte,t1</span>
<span class="p_add">+	tlb_lock	spc,ptp,pte,t0,t1,dbit_fault</span>
<span class="p_add">+	update_dirty	ptp,pte,t1</span>
 
 	make_insert_tlb	spc,pte,prot
 
 	f_extend	pte,t1
 	
<span class="p_del">-        idtlbt          pte,prot</span>
<span class="p_del">-	dbit_unlock0	spc,t0</span>
<span class="p_add">+	idtlbt		pte,prot</span>
 
<span class="p_add">+	tlb_unlock0	spc,t0</span>
 	rfir
 	nop
 #endif
<span class="p_header">diff --git a/arch/parisc/kernel/traps.c b/arch/parisc/kernel/traps.c</span>
<span class="p_header">index 47ee620..7f67c4c 100644</span>
<span class="p_header">--- a/arch/parisc/kernel/traps.c</span>
<span class="p_header">+++ b/arch/parisc/kernel/traps.c</span>
<span class="p_chunk">@@ -43,10 +43,6 @@</span> <span class="p_context"></span>
 
 #include &quot;../math-emu/math-emu.h&quot;	/* for handle_fpe() */
 
<span class="p_del">-#if defined(CONFIG_SMP) || defined(CONFIG_DEBUG_SPINLOCK)</span>
<span class="p_del">-DEFINE_SPINLOCK(pa_dbit_lock);</span>
<span class="p_del">-#endif</span>
<span class="p_del">-</span>
 static void parisc_show_stack(struct task_struct *task, unsigned long *sp,
 	struct pt_regs *regs);
 
<span class="p_header">diff --git a/arch/powerpc/kernel/idle_power7.S b/arch/powerpc/kernel/idle_power7.S</span>
<span class="p_header">index 401d8d0..7bc5750 100644</span>
<span class="p_header">--- a/arch/powerpc/kernel/idle_power7.S</span>
<span class="p_header">+++ b/arch/powerpc/kernel/idle_power7.S</span>
<span class="p_chunk">@@ -52,6 +52,22 @@</span> <span class="p_context"></span>
 	.text
 
 /*
<span class="p_add">+ * Used by threads when the lock bit of core_idle_state is set.</span>
<span class="p_add">+ * Threads will spin in HMT_LOW until the lock bit is cleared.</span>
<span class="p_add">+ * r14 - pointer to core_idle_state</span>
<span class="p_add">+ * r15 - used to load contents of core_idle_state</span>
<span class="p_add">+ */</span>
<span class="p_add">+</span>
<span class="p_add">+core_idle_lock_held:</span>
<span class="p_add">+	HMT_LOW</span>
<span class="p_add">+3:	lwz	r15,0(r14)</span>
<span class="p_add">+	andi.   r15,r15,PNV_CORE_IDLE_LOCK_BIT</span>
<span class="p_add">+	bne	3b</span>
<span class="p_add">+	HMT_MEDIUM</span>
<span class="p_add">+	lwarx	r15,0,r14</span>
<span class="p_add">+	blr</span>
<span class="p_add">+</span>
<span class="p_add">+/*</span>
  * Pass requested state in r3:
  *	r3 - PNV_THREAD_NAP/SLEEP/WINKLE
  *
<span class="p_chunk">@@ -149,6 +165,10 @@</span> <span class="p_context"> power7_enter_nap_mode:</span>
 	ld	r14,PACA_CORE_IDLE_STATE_PTR(r13)
 lwarx_loop1:
 	lwarx	r15,0,r14
<span class="p_add">+</span>
<span class="p_add">+	andi.   r9,r15,PNV_CORE_IDLE_LOCK_BIT</span>
<span class="p_add">+	bnel	core_idle_lock_held</span>
<span class="p_add">+</span>
 	andc	r15,r15,r7			/* Clear thread bit */
 
 	andi.	r15,r15,PNV_CORE_IDLE_THREAD_BITS
<span class="p_chunk">@@ -293,7 +313,7 @@</span> <span class="p_context"> lwarx_loop2:</span>
 	 * workaround undo code or resyncing timebase or restoring context
 	 * In either case loop until the lock bit is cleared.
 	 */
<span class="p_del">-	bne	core_idle_lock_held</span>
<span class="p_add">+	bnel	core_idle_lock_held</span>
 
 	cmpwi	cr2,r15,0
 	lbz	r4,PACA_SUBCORE_SIBLING_MASK(r13)
<span class="p_chunk">@@ -318,15 +338,6 @@</span> <span class="p_context"> lwarx_loop2:</span>
 	isync
 	b	common_exit
 
<span class="p_del">-core_idle_lock_held:</span>
<span class="p_del">-	HMT_LOW</span>
<span class="p_del">-core_idle_lock_loop:</span>
<span class="p_del">-	lwz	r15,0(14)</span>
<span class="p_del">-	andi.   r9,r15,PNV_CORE_IDLE_LOCK_BIT</span>
<span class="p_del">-	bne	core_idle_lock_loop</span>
<span class="p_del">-	HMT_MEDIUM</span>
<span class="p_del">-	b	lwarx_loop2</span>
<span class="p_del">-</span>
 first_thread_in_subcore:
 	/* First thread in subcore to wakeup */
 	ori	r15,r15,PNV_CORE_IDLE_LOCK_BIT
<span class="p_header">diff --git a/arch/s390/kernel/process.c b/arch/s390/kernel/process.c</span>
<span class="p_header">index aa7a839..0f8e8f5 100644</span>
<span class="p_header">--- a/arch/s390/kernel/process.c</span>
<span class="p_header">+++ b/arch/s390/kernel/process.c</span>
<span class="p_chunk">@@ -172,7 +172,7 @@</span> <span class="p_context"> asmlinkage void execve_tail(void)</span>
 {
 	current-&gt;thread.fp_regs.fpc = 0;
 	if (MACHINE_HAS_IEEE)
<span class="p_del">-		asm volatile(&quot;sfpc %0,%0&quot; : : &quot;d&quot; (0));</span>
<span class="p_add">+		asm volatile(&quot;sfpc %0&quot; : : &quot;d&quot; (0));</span>
 }
 
 /*
<span class="p_header">diff --git a/arch/s390/kernel/sclp.S b/arch/s390/kernel/sclp.S</span>
<span class="p_header">index a41f2c9..a0c4e76 100644</span>
<span class="p_header">--- a/arch/s390/kernel/sclp.S</span>
<span class="p_header">+++ b/arch/s390/kernel/sclp.S</span>
<span class="p_chunk">@@ -277,6 +277,8 @@</span> <span class="p_context"> ENTRY(_sclp_print_early)</span>
 	jno	.Lesa2
 	ahi	%r15,-80
 	stmh	%r6,%r15,96(%r15)		# store upper register halves
<span class="p_add">+	basr	%r13,0</span>
<span class="p_add">+	lmh	%r0,%r15,.Lzeroes-.(%r13)	# clear upper register halves</span>
 .Lesa2:
 #endif
 	lr	%r10,%r2			# save string pointer
<span class="p_chunk">@@ -300,6 +302,8 @@</span> <span class="p_context"> ENTRY(_sclp_print_early)</span>
 #endif
 	lm	%r6,%r15,120(%r15)		# restore registers
 	br	%r14
<span class="p_add">+.Lzeroes:</span>
<span class="p_add">+	.fill	64,4,0</span>
 
 .LwritedataS4:
 	.long	0x00760005			# SCLP command for write data
<span class="p_header">diff --git a/arch/x86/kernel/entry_64.S b/arch/x86/kernel/entry_64.S</span>
<span class="p_header">index 4ee9a23..138e7af 100644</span>
<span class="p_header">--- a/arch/x86/kernel/entry_64.S</span>
<span class="p_header">+++ b/arch/x86/kernel/entry_64.S</span>
<span class="p_chunk">@@ -1438,19 +1438,7 @@</span> <span class="p_context"> ENTRY(error_exit)</span>
 	CFI_ENDPROC
 END(error_exit)
 
<span class="p_del">-/*</span>
<span class="p_del">- * Test if a given stack is an NMI stack or not.</span>
<span class="p_del">- */</span>
<span class="p_del">-	.macro test_in_nmi reg stack nmi_ret normal_ret</span>
<span class="p_del">-	cmpq %\reg, \stack</span>
<span class="p_del">-	ja \normal_ret</span>
<span class="p_del">-	subq $EXCEPTION_STKSZ, %\reg</span>
<span class="p_del">-	cmpq %\reg, \stack</span>
<span class="p_del">-	jb \normal_ret</span>
<span class="p_del">-	jmp \nmi_ret</span>
<span class="p_del">-	.endm</span>
<span class="p_del">-</span>
<span class="p_del">-	/* runs on exception stack */</span>
<span class="p_add">+/* Runs on exception stack */</span>
 ENTRY(nmi)
 	INTR_FRAME
 	PARAVIRT_ADJUST_EXCEPTION_FRAME
<span class="p_chunk">@@ -1471,11 +1459,12 @@</span> <span class="p_context"> ENTRY(nmi)</span>
 	 *  If the variable is not set and the stack is not the NMI
 	 *  stack then:
 	 *    o Set the special variable on the stack
<span class="p_del">-	 *    o Copy the interrupt frame into a &quot;saved&quot; location on the stack</span>
<span class="p_del">-	 *    o Copy the interrupt frame into a &quot;copy&quot; location on the stack</span>
<span class="p_add">+	 *    o Copy the interrupt frame into an &quot;outermost&quot; location on the</span>
<span class="p_add">+	 *      stack</span>
<span class="p_add">+	 *    o Copy the interrupt frame into an &quot;iret&quot; location on the stack</span>
 	 *    o Continue processing the NMI
 	 *  If the variable is set or the previous stack is the NMI stack:
<span class="p_del">-	 *    o Modify the &quot;copy&quot; location to jump to the repeate_nmi</span>
<span class="p_add">+	 *    o Modify the &quot;iret&quot; location to jump to the repeat_nmi</span>
 	 *    o return back to the first NMI
 	 *
 	 * Now on exit of the first NMI, we first clear the stack variable
<span class="p_chunk">@@ -1484,52 +1473,194 @@</span> <span class="p_context"> ENTRY(nmi)</span>
 	 * a nested NMI that updated the copy interrupt stack frame, a
 	 * jump will be made to the repeat_nmi code that will handle the second
 	 * NMI.
<span class="p_add">+	 *</span>
<span class="p_add">+	 * However, espfix prevents us from directly returning to userspace</span>
<span class="p_add">+	 * with a single IRET instruction.  Similarly, IRET to user mode</span>
<span class="p_add">+	 * can fault.  We therefore handle NMIs from user space like</span>
<span class="p_add">+	 * other IST entries.</span>
 	 */
 
 	/* Use %rdx as out temp variable throughout */
 	pushq_cfi %rdx
 	CFI_REL_OFFSET rdx, 0
 
<span class="p_add">+	testb	$3, CS-RIP+8(%rsp)</span>
<span class="p_add">+	jz	.Lnmi_from_kernel</span>
<span class="p_add">+</span>
 	/*
<span class="p_del">-	 * If %cs was not the kernel segment, then the NMI triggered in user</span>
<span class="p_del">-	 * space, which means it is definitely not nested.</span>
<span class="p_add">+	 * NMI from user mode.  We need to run on the thread stack, but we</span>
<span class="p_add">+	 * can&#39;t go through the normal entry paths: NMIs are masked, and</span>
<span class="p_add">+	 * we don&#39;t want to enable interrupts, because then we&#39;ll end</span>
<span class="p_add">+	 * up in an awkward situation in which IRQs are on but NMIs</span>
<span class="p_add">+	 * are off.</span>
 	 */
<span class="p_del">-	cmpl $__KERNEL_CS, 16(%rsp)</span>
<span class="p_del">-	jne first_nmi</span>
<span class="p_add">+</span>
<span class="p_add">+	SWAPGS</span>
<span class="p_add">+	cld</span>
<span class="p_add">+	movq	%rsp, %rdx</span>
<span class="p_add">+	movq	PER_CPU_VAR(kernel_stack), %rsp</span>
<span class="p_add">+	addq	$KERNEL_STACK_OFFSET, %rsp</span>
<span class="p_add">+	pushq	5*8(%rdx)	/* pt_regs-&gt;ss */</span>
<span class="p_add">+	pushq	4*8(%rdx)	/* pt_regs-&gt;rsp */</span>
<span class="p_add">+	pushq	3*8(%rdx)	/* pt_regs-&gt;flags */</span>
<span class="p_add">+	pushq	2*8(%rdx)	/* pt_regs-&gt;cs */</span>
<span class="p_add">+	pushq	1*8(%rdx)	/* pt_regs-&gt;rip */</span>
<span class="p_add">+	pushq   $-1		/* pt_regs-&gt;orig_ax */</span>
<span class="p_add">+	pushq   %rdi		/* pt_regs-&gt;di */</span>
<span class="p_add">+	pushq   %rsi		/* pt_regs-&gt;si */</span>
<span class="p_add">+	pushq   (%rdx)		/* pt_regs-&gt;dx */</span>
<span class="p_add">+	pushq   %rcx		/* pt_regs-&gt;cx */</span>
<span class="p_add">+	pushq   %rax		/* pt_regs-&gt;ax */</span>
<span class="p_add">+	pushq   %r8		/* pt_regs-&gt;r8 */</span>
<span class="p_add">+	pushq   %r9		/* pt_regs-&gt;r9 */</span>
<span class="p_add">+	pushq   %r10		/* pt_regs-&gt;r10 */</span>
<span class="p_add">+	pushq   %r11		/* pt_regs-&gt;r11 */</span>
<span class="p_add">+	pushq	%rbx		/* pt_regs-&gt;rbx */</span>
<span class="p_add">+	pushq	%rbp		/* pt_regs-&gt;rbp */</span>
<span class="p_add">+	pushq	%r12		/* pt_regs-&gt;r12 */</span>
<span class="p_add">+	pushq	%r13		/* pt_regs-&gt;r13 */</span>
<span class="p_add">+	pushq	%r14		/* pt_regs-&gt;r14 */</span>
<span class="p_add">+	pushq	%r15		/* pt_regs-&gt;r15 */</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * At this point we no longer need to worry about stack damage</span>
<span class="p_add">+	 * due to nesting -- we&#39;re on the normal thread stack and we&#39;re</span>
<span class="p_add">+	 * done with the NMI stack.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+</span>
<span class="p_add">+	movq	%rsp, %rdi</span>
<span class="p_add">+	movq	$-1, %rsi</span>
<span class="p_add">+	call	do_nmi</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Return back to user mode.  We must *not* do the normal exit</span>
<span class="p_add">+	 * work, because we don&#39;t want to enable interrupts.  Fortunately,</span>
<span class="p_add">+	 * do_nmi doesn&#39;t modify pt_regs.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	SWAPGS</span>
 
 	/*
<span class="p_del">-	 * Check the special variable on the stack to see if NMIs are</span>
<span class="p_del">-	 * executing.</span>
<span class="p_add">+	 * Open-code the entire return process for compatibility with varying</span>
<span class="p_add">+	 * register layouts across different kernel versions.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	addq	$6*8, %rsp	/* skip bx, bp, and r12-r15 */</span>
<span class="p_add">+	popq	%r11		/* pt_regs-&gt;r11 */</span>
<span class="p_add">+	popq	%r10		/* pt_regs-&gt;r10 */</span>
<span class="p_add">+	popq	%r9		/* pt_regs-&gt;r9 */</span>
<span class="p_add">+	popq	%r8		/* pt_regs-&gt;r8 */</span>
<span class="p_add">+	popq	%rax		/* pt_regs-&gt;ax */</span>
<span class="p_add">+	popq	%rcx		/* pt_regs-&gt;cx */</span>
<span class="p_add">+	popq	%rdx		/* pt_regs-&gt;dx */</span>
<span class="p_add">+	popq	%rsi		/* pt_regs-&gt;si */</span>
<span class="p_add">+	popq	%rdi		/* pt_regs-&gt;di */</span>
<span class="p_add">+	addq	$8, %rsp	/* skip orig_ax */</span>
<span class="p_add">+	INTERRUPT_RETURN</span>
<span class="p_add">+</span>
<span class="p_add">+.Lnmi_from_kernel:</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Here&#39;s what our stack frame will look like:</span>
<span class="p_add">+	 * +---------------------------------------------------------+</span>
<span class="p_add">+	 * | original SS                                             |</span>
<span class="p_add">+	 * | original Return RSP                                     |</span>
<span class="p_add">+	 * | original RFLAGS                                         |</span>
<span class="p_add">+	 * | original CS                                             |</span>
<span class="p_add">+	 * | original RIP                                            |</span>
<span class="p_add">+	 * +---------------------------------------------------------+</span>
<span class="p_add">+	 * | temp storage for rdx                                    |</span>
<span class="p_add">+	 * +---------------------------------------------------------+</span>
<span class="p_add">+	 * | &quot;NMI executing&quot; variable                                |</span>
<span class="p_add">+	 * +---------------------------------------------------------+</span>
<span class="p_add">+	 * | iret SS          } Copied from &quot;outermost&quot; frame        |</span>
<span class="p_add">+	 * | iret Return RSP  } on each loop iteration; overwritten  |</span>
<span class="p_add">+	 * | iret RFLAGS      } by a nested NMI to force another     |</span>
<span class="p_add">+	 * | iret CS          } iteration if needed.                 |</span>
<span class="p_add">+	 * | iret RIP         }                                      |</span>
<span class="p_add">+	 * +---------------------------------------------------------+</span>
<span class="p_add">+	 * | outermost SS          } initialized in first_nmi;       |</span>
<span class="p_add">+	 * | outermost Return RSP  } will not be changed before      |</span>
<span class="p_add">+	 * | outermost RFLAGS      } NMI processing is done.         |</span>
<span class="p_add">+	 * | outermost CS          } Copied to &quot;iret&quot; frame on each  |</span>
<span class="p_add">+	 * | outermost RIP         } iteration.                      |</span>
<span class="p_add">+	 * +---------------------------------------------------------+</span>
<span class="p_add">+	 * | pt_regs                                                 |</span>
<span class="p_add">+	 * +---------------------------------------------------------+</span>
<span class="p_add">+	 *</span>
<span class="p_add">+	 * The &quot;original&quot; frame is used by hardware.  Before re-enabling</span>
<span class="p_add">+	 * NMIs, we need to be done with it, and we need to leave enough</span>
<span class="p_add">+	 * space for the asm code here.</span>
<span class="p_add">+	 *</span>
<span class="p_add">+	 * We return by executing IRET while RSP points to the &quot;iret&quot; frame.</span>
<span class="p_add">+	 * That will either return for real or it will loop back into NMI</span>
<span class="p_add">+	 * processing.</span>
<span class="p_add">+	 *</span>
<span class="p_add">+	 * The &quot;outermost&quot; frame is copied to the &quot;iret&quot; frame on each</span>
<span class="p_add">+	 * iteration of the loop, so each iteration starts with the &quot;iret&quot;</span>
<span class="p_add">+	 * frame pointing to the final return target.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Determine whether we&#39;re a nested NMI.</span>
<span class="p_add">+	 *</span>
<span class="p_add">+	 * If we interrupted kernel code between repeat_nmi and</span>
<span class="p_add">+	 * end_repeat_nmi, then we are a nested NMI.  We must not</span>
<span class="p_add">+	 * modify the &quot;iret&quot; frame because it&#39;s being written by</span>
<span class="p_add">+	 * the outer NMI.  That&#39;s okay: the outer NMI handler is</span>
<span class="p_add">+	 * about to about to call do_nmi anyway, so we can just</span>
<span class="p_add">+	 * resume the outer NMI.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+</span>
<span class="p_add">+	movq	$repeat_nmi, %rdx</span>
<span class="p_add">+	cmpq	8(%rsp), %rdx</span>
<span class="p_add">+	ja	1f</span>
<span class="p_add">+	movq	$end_repeat_nmi, %rdx</span>
<span class="p_add">+	cmpq	8(%rsp), %rdx</span>
<span class="p_add">+	ja	nested_nmi_out</span>
<span class="p_add">+1:</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Now check &quot;NMI executing&quot;.  If it&#39;s set, then we&#39;re nested.</span>
<span class="p_add">+	 * This will not detect if we interrupted an outer NMI just</span>
<span class="p_add">+	 * before IRET.</span>
 	 */
 	cmpl $1, -8(%rsp)
 	je nested_nmi
 
 	/*
<span class="p_del">-	 * Now test if the previous stack was an NMI stack.</span>
<span class="p_del">-	 * We need the double check. We check the NMI stack to satisfy the</span>
<span class="p_del">-	 * race when the first NMI clears the variable before returning.</span>
<span class="p_del">-	 * We check the variable because the first NMI could be in a</span>
<span class="p_del">-	 * breakpoint routine using a breakpoint stack.</span>
<span class="p_add">+	 * Now test if the previous stack was an NMI stack.  This covers</span>
<span class="p_add">+	 * the case where we interrupt an outer NMI after it clears</span>
<span class="p_add">+	 * &quot;NMI executing&quot; but before IRET.  We need to be careful, though:</span>
<span class="p_add">+	 * there is one case in which RSP could point to the NMI stack</span>
<span class="p_add">+	 * despite there being no NMI active: naughty userspace controls</span>
<span class="p_add">+	 * RSP at the very beginning of the SYSCALL targets.  We can</span>
<span class="p_add">+	 * pull a fast one on naughty userspace, though: we program</span>
<span class="p_add">+	 * SYSCALL to mask DF, so userspace cannot cause DF to be set</span>
<span class="p_add">+	 * if it controls the kernel&#39;s RSP.  We set DF before we clear</span>
<span class="p_add">+	 * &quot;NMI executing&quot;.</span>
 	 */
<span class="p_del">-	lea 6*8(%rsp), %rdx</span>
<span class="p_del">-	test_in_nmi rdx, 4*8(%rsp), nested_nmi, first_nmi</span>
<span class="p_add">+	lea	6*8(%rsp), %rdx</span>
<span class="p_add">+	/* Compare the NMI stack (rdx) with the stack we came from (4*8(%rsp)) */</span>
<span class="p_add">+	cmpq	%rdx, 4*8(%rsp)</span>
<span class="p_add">+	/* If the stack pointer is above the NMI stack, this is a normal NMI */</span>
<span class="p_add">+	ja	first_nmi</span>
<span class="p_add">+	subq	$EXCEPTION_STKSZ, %rdx</span>
<span class="p_add">+	cmpq	%rdx, 4*8(%rsp)</span>
<span class="p_add">+	/* If it is below the NMI stack, it is a normal NMI */</span>
<span class="p_add">+	jb	first_nmi</span>
<span class="p_add">+</span>
<span class="p_add">+	/* Ah, it is within the NMI stack. */</span>
<span class="p_add">+</span>
<span class="p_add">+	testb	$(X86_EFLAGS_DF &gt;&gt; 8), (3*8 + 1)(%rsp)</span>
<span class="p_add">+	jz	first_nmi	/* RSP was user controlled. */</span>
<span class="p_add">+</span>
 	CFI_REMEMBER_STATE
 
<span class="p_add">+	/* This is a nested NMI. */</span>
<span class="p_add">+</span>
 nested_nmi:
 	/*
<span class="p_del">-	 * Do nothing if we interrupted the fixup in repeat_nmi.</span>
<span class="p_del">-	 * It&#39;s about to repeat the NMI handler, so we are fine</span>
<span class="p_del">-	 * with ignoring this one.</span>
<span class="p_add">+	 * Modify the &quot;iret&quot; frame to point to repeat_nmi, forcing another</span>
<span class="p_add">+	 * iteration of NMI handling.</span>
 	 */
<span class="p_del">-	movq $repeat_nmi, %rdx</span>
<span class="p_del">-	cmpq 8(%rsp), %rdx</span>
<span class="p_del">-	ja 1f</span>
<span class="p_del">-	movq $end_repeat_nmi, %rdx</span>
<span class="p_del">-	cmpq 8(%rsp), %rdx</span>
<span class="p_del">-	ja nested_nmi_out</span>
<span class="p_del">-</span>
<span class="p_del">-1:</span>
<span class="p_del">-	/* Set up the interrupted NMIs stack to jump to repeat_nmi */</span>
 	leaq -1*8(%rsp), %rdx
 	movq %rdx, %rsp
 	CFI_ADJUST_CFA_OFFSET 1*8
<span class="p_chunk">@@ -1548,60 +1679,23 @@</span> <span class="p_context"> nested_nmi_out:</span>
 	popq_cfi %rdx
 	CFI_RESTORE rdx
 
<span class="p_del">-	/* No need to check faults here */</span>
<span class="p_add">+	/* We are returning to kernel mode, so this cannot result in a fault. */</span>
 	INTERRUPT_RETURN
 
 	CFI_RESTORE_STATE
 first_nmi:
<span class="p_del">-	/*</span>
<span class="p_del">-	 * Because nested NMIs will use the pushed location that we</span>
<span class="p_del">-	 * stored in rdx, we must keep that space available.</span>
<span class="p_del">-	 * Here&#39;s what our stack frame will look like:</span>
<span class="p_del">-	 * +-------------------------+</span>
<span class="p_del">-	 * | original SS             |</span>
<span class="p_del">-	 * | original Return RSP     |</span>
<span class="p_del">-	 * | original RFLAGS         |</span>
<span class="p_del">-	 * | original CS             |</span>
<span class="p_del">-	 * | original RIP            |</span>
<span class="p_del">-	 * +-------------------------+</span>
<span class="p_del">-	 * | temp storage for rdx    |</span>
<span class="p_del">-	 * +-------------------------+</span>
<span class="p_del">-	 * | NMI executing variable  |</span>
<span class="p_del">-	 * +-------------------------+</span>
<span class="p_del">-	 * | copied SS               |</span>
<span class="p_del">-	 * | copied Return RSP       |</span>
<span class="p_del">-	 * | copied RFLAGS           |</span>
<span class="p_del">-	 * | copied CS               |</span>
<span class="p_del">-	 * | copied RIP              |</span>
<span class="p_del">-	 * +-------------------------+</span>
<span class="p_del">-	 * | Saved SS                |</span>
<span class="p_del">-	 * | Saved Return RSP        |</span>
<span class="p_del">-	 * | Saved RFLAGS            |</span>
<span class="p_del">-	 * | Saved CS                |</span>
<span class="p_del">-	 * | Saved RIP               |</span>
<span class="p_del">-	 * +-------------------------+</span>
<span class="p_del">-	 * | pt_regs                 |</span>
<span class="p_del">-	 * +-------------------------+</span>
<span class="p_del">-	 *</span>
<span class="p_del">-	 * The saved stack frame is used to fix up the copied stack frame</span>
<span class="p_del">-	 * that a nested NMI may change to make the interrupted NMI iret jump</span>
<span class="p_del">-	 * to the repeat_nmi. The original stack frame and the temp storage</span>
<span class="p_del">-	 * is also used by nested NMIs and can not be trusted on exit.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	/* Do not pop rdx, nested NMIs will corrupt that part of the stack */</span>
<span class="p_add">+	/* Restore rdx. */</span>
 	movq (%rsp), %rdx
 	CFI_RESTORE rdx
 
<span class="p_del">-	/* Set the NMI executing variable on the stack. */</span>
<span class="p_add">+	/* Set &quot;NMI executing&quot; on the stack. */</span>
 	pushq_cfi $1
 
<span class="p_del">-	/*</span>
<span class="p_del">-	 * Leave room for the &quot;copied&quot; frame</span>
<span class="p_del">-	 */</span>
<span class="p_add">+	/* Leave room for the &quot;iret&quot; frame */</span>
 	subq $(5*8), %rsp
 	CFI_ADJUST_CFA_OFFSET 5*8
 
<span class="p_del">-	/* Copy the stack frame to the Saved frame */</span>
<span class="p_add">+	/* Copy the &quot;original&quot; frame to the &quot;outermost&quot; frame */</span>
 	.rept 5
 	pushq_cfi 11*8(%rsp)
 	.endr
<span class="p_chunk">@@ -1609,6 +1703,7 @@</span> <span class="p_context"> first_nmi:</span>
 
 	/* Everything up to here is safe from nested NMIs */
 
<span class="p_add">+repeat_nmi:</span>
 	/*
 	 * If there was a nested NMI, the first NMI&#39;s iret will return
 	 * here. But NMIs are still enabled and we can take another
<span class="p_chunk">@@ -1617,16 +1712,21 @@</span> <span class="p_context"> first_nmi:</span>
 	 * it will just return, as we are about to repeat an NMI anyway.
 	 * This makes it safe to copy to the stack frame that a nested
 	 * NMI will update.
<span class="p_del">-	 */</span>
<span class="p_del">-repeat_nmi:</span>
<span class="p_del">-	/*</span>
<span class="p_del">-	 * Update the stack variable to say we are still in NMI (the update</span>
<span class="p_del">-	 * is benign for the non-repeat case, where 1 was pushed just above</span>
<span class="p_del">-	 * to this very stack slot).</span>
<span class="p_add">+	 *</span>
<span class="p_add">+	 * RSP is pointing to &quot;outermost RIP&quot;.  gsbase is unknown, but, if</span>
<span class="p_add">+	 * we&#39;re repeating an NMI, gsbase has the same value that it had on</span>
<span class="p_add">+	 * the first iteration.  paranoid_entry will load the kernel</span>
<span class="p_add">+	 * gsbase if needed before we call do_nmi.</span>
<span class="p_add">+	 *</span>
<span class="p_add">+	 * Set &quot;NMI executing&quot; in case we came back here via IRET.</span>
 	 */
 	movq $1, 10*8(%rsp)
 
<span class="p_del">-	/* Make another copy, this one may be modified by nested NMIs */</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Copy the &quot;outermost&quot; frame to the &quot;iret&quot; frame.  NMIs that nest</span>
<span class="p_add">+	 * here must not modify the &quot;iret&quot; frame while we&#39;re writing to</span>
<span class="p_add">+	 * it or it will end up containing garbage.</span>
<span class="p_add">+	 */</span>
 	addq $(10*8), %rsp
 	CFI_ADJUST_CFA_OFFSET -10*8
 	.rept 5
<span class="p_chunk">@@ -1637,9 +1737,9 @@</span> <span class="p_context"> repeat_nmi:</span>
 end_repeat_nmi:
 
 	/*
<span class="p_del">-	 * Everything below this point can be preempted by a nested</span>
<span class="p_del">-	 * NMI if the first NMI took an exception and reset our iret stack</span>
<span class="p_del">-	 * so that we repeat another NMI.</span>
<span class="p_add">+	 * Everything below this point can be preempted by a nested NMI.</span>
<span class="p_add">+	 * If this happens, then the inner NMI will change the &quot;iret&quot;</span>
<span class="p_add">+	 * frame to point back to repeat_nmi.</span>
 	 */
 	pushq_cfi $-1		/* ORIG_RAX: no syscall to restart */
 	subq $ORIG_RAX-R15, %rsp
<span class="p_chunk">@@ -1654,39 +1754,35 @@</span> <span class="p_context"> end_repeat_nmi:</span>
 	call save_paranoid
 	DEFAULT_FRAME 0
 
<span class="p_del">-	/*</span>
<span class="p_del">-	 * Save off the CR2 register. If we take a page fault in the NMI then</span>
<span class="p_del">-	 * it could corrupt the CR2 value. If the NMI preempts a page fault</span>
<span class="p_del">-	 * handler before it was able to read the CR2 register, and then the</span>
<span class="p_del">-	 * NMI itself takes a page fault, the page fault that was preempted</span>
<span class="p_del">-	 * will read the information from the NMI page fault and not the</span>
<span class="p_del">-	 * origin fault. Save it off and restore it if it changes.</span>
<span class="p_del">-	 * Use the r12 callee-saved register.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	movq %cr2, %r12</span>
<span class="p_del">-</span>
 	/* paranoidentry do_nmi, 0; without TRACE_IRQS_OFF */
 	movq %rsp,%rdi
 	movq $-1,%rsi
 	call do_nmi
 
<span class="p_del">-	/* Did the NMI take a page fault? Restore cr2 if it did */</span>
<span class="p_del">-	movq %cr2, %rcx</span>
<span class="p_del">-	cmpq %rcx, %r12</span>
<span class="p_del">-	je 1f</span>
<span class="p_del">-	movq %r12, %cr2</span>
<span class="p_del">-1:</span>
<span class="p_del">-	</span>
 	testl %ebx,%ebx				/* swapgs needed? */
 	jnz nmi_restore
 nmi_swapgs:
 	SWAPGS_UNSAFE_STACK
 nmi_restore:
<span class="p_del">-	/* Pop the extra iret frame at once */</span>
<span class="p_add">+</span>
 	RESTORE_ALL 6*8
 
<span class="p_del">-	/* Clear the NMI executing stack variable */</span>
<span class="p_del">-	movq $0, 5*8(%rsp)</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Clear &quot;NMI executing&quot;.  Set DF first so that we can easily</span>
<span class="p_add">+	 * distinguish the remaining code between here and IRET from</span>
<span class="p_add">+	 * the SYSCALL entry and exit paths.  On a native kernel, we</span>
<span class="p_add">+	 * could just inspect RIP, but, on paravirt kernels,</span>
<span class="p_add">+	 * INTERRUPT_RETURN can translate into a jump into a</span>
<span class="p_add">+	 * hypercall page.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	std</span>
<span class="p_add">+	movq	$0, 5*8(%rsp)		/* clear &quot;NMI executing&quot; */</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * INTERRUPT_RETURN reads the &quot;iret&quot; frame and exits the NMI</span>
<span class="p_add">+	 * stack in a single instruction.  We are returning to kernel</span>
<span class="p_add">+	 * mode, so this cannot result in a fault.</span>
<span class="p_add">+	 */</span>
 	jmp irq_return
 	CFI_ENDPROC
 END(nmi)
<span class="p_header">diff --git a/arch/x86/kernel/nmi.c b/arch/x86/kernel/nmi.c</span>
<span class="p_header">index c3e985d..d05bd2e 100644</span>
<span class="p_header">--- a/arch/x86/kernel/nmi.c</span>
<span class="p_header">+++ b/arch/x86/kernel/nmi.c</span>
<span class="p_chunk">@@ -408,15 +408,15 @@</span> <span class="p_context"> static void default_do_nmi(struct pt_regs *regs)</span>
 NOKPROBE_SYMBOL(default_do_nmi);
 
 /*
<span class="p_del">- * NMIs can hit breakpoints which will cause it to lose its</span>
<span class="p_del">- * NMI context with the CPU when the breakpoint does an iret.</span>
<span class="p_del">- */</span>
<span class="p_del">-#ifdef CONFIG_X86_32</span>
<span class="p_del">-/*</span>
<span class="p_del">- * For i386, NMIs use the same stack as the kernel, and we can</span>
<span class="p_del">- * add a workaround to the iret problem in C (preventing nested</span>
<span class="p_del">- * NMIs if an NMI takes a trap). Simply have 3 states the NMI</span>
<span class="p_del">- * can be in:</span>
<span class="p_add">+ * NMIs can page fault or hit breakpoints which will cause it to lose</span>
<span class="p_add">+ * its NMI context with the CPU when the breakpoint or page fault does an IRET.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * As a result, NMIs can nest if NMIs get unmasked due an IRET during</span>
<span class="p_add">+ * NMI processing.  On x86_64, the asm glue protects us from nested NMIs</span>
<span class="p_add">+ * if the outer NMI came from kernel mode, but we can still nest if the</span>
<span class="p_add">+ * outer NMI came from user mode.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * To handle these nested NMIs, we have three states:</span>
  *
  *  1) not running
  *  2) executing
<span class="p_chunk">@@ -430,15 +430,14 @@</span> <span class="p_context"> NOKPROBE_SYMBOL(default_do_nmi);</span>
  * (Note, the latch is binary, thus multiple NMIs triggering,
  *  when one is running, are ignored. Only one NMI is restarted.)
  *
<span class="p_del">- * If an NMI hits a breakpoint that executes an iret, another</span>
<span class="p_del">- * NMI can preempt it. We do not want to allow this new NMI</span>
<span class="p_del">- * to run, but we want to execute it when the first one finishes.</span>
<span class="p_del">- * We set the state to &quot;latched&quot;, and the exit of the first NMI will</span>
<span class="p_del">- * perform a dec_return, if the result is zero (NOT_RUNNING), then</span>
<span class="p_del">- * it will simply exit the NMI handler. If not, the dec_return</span>
<span class="p_del">- * would have set the state to NMI_EXECUTING (what we want it to</span>
<span class="p_del">- * be when we are running). In this case, we simply jump back</span>
<span class="p_del">- * to rerun the NMI handler again, and restart the &#39;latched&#39; NMI.</span>
<span class="p_add">+ * If an NMI executes an iret, another NMI can preempt it. We do not</span>
<span class="p_add">+ * want to allow this new NMI to run, but we want to execute it when the</span>
<span class="p_add">+ * first one finishes.  We set the state to &quot;latched&quot;, and the exit of</span>
<span class="p_add">+ * the first NMI will perform a dec_return, if the result is zero</span>
<span class="p_add">+ * (NOT_RUNNING), then it will simply exit the NMI handler. If not, the</span>
<span class="p_add">+ * dec_return would have set the state to NMI_EXECUTING (what we want it</span>
<span class="p_add">+ * to be when we are running). In this case, we simply jump back to</span>
<span class="p_add">+ * rerun the NMI handler again, and restart the &#39;latched&#39; NMI.</span>
  *
  * No trap (breakpoint or page fault) should be hit before nmi_restart,
  * thus there is no race between the first check of state for NOT_RUNNING
<span class="p_chunk">@@ -461,49 +460,36 @@</span> <span class="p_context"> enum nmi_states {</span>
 static DEFINE_PER_CPU(enum nmi_states, nmi_state);
 static DEFINE_PER_CPU(unsigned long, nmi_cr2);
 
<span class="p_del">-#define nmi_nesting_preprocess(regs)					\</span>
<span class="p_del">-	do {								\</span>
<span class="p_del">-		if (this_cpu_read(nmi_state) != NMI_NOT_RUNNING) {	\</span>
<span class="p_del">-			this_cpu_write(nmi_state, NMI_LATCHED);		\</span>
<span class="p_del">-			return;						\</span>
<span class="p_del">-		}							\</span>
<span class="p_del">-		this_cpu_write(nmi_state, NMI_EXECUTING);		\</span>
<span class="p_del">-		this_cpu_write(nmi_cr2, read_cr2());			\</span>
<span class="p_del">-	} while (0);							\</span>
<span class="p_del">-	nmi_restart:</span>
<span class="p_del">-</span>
<span class="p_del">-#define nmi_nesting_postprocess()					\</span>
<span class="p_del">-	do {								\</span>
<span class="p_del">-		if (unlikely(this_cpu_read(nmi_cr2) != read_cr2()))	\</span>
<span class="p_del">-			write_cr2(this_cpu_read(nmi_cr2));		\</span>
<span class="p_del">-		if (this_cpu_dec_return(nmi_state))			\</span>
<span class="p_del">-			goto nmi_restart;				\</span>
<span class="p_del">-	} while (0)</span>
<span class="p_del">-#else /* x86_64 */</span>
<span class="p_add">+#ifdef CONFIG_X86_64</span>
 /*
<span class="p_del">- * In x86_64 things are a bit more difficult. This has the same problem</span>
<span class="p_del">- * where an NMI hitting a breakpoint that calls iret will remove the</span>
<span class="p_del">- * NMI context, allowing a nested NMI to enter. What makes this more</span>
<span class="p_del">- * difficult is that both NMIs and breakpoints have their own stack.</span>
<span class="p_del">- * When a new NMI or breakpoint is executed, the stack is set to a fixed</span>
<span class="p_del">- * point. If an NMI is nested, it will have its stack set at that same</span>
<span class="p_del">- * fixed address that the first NMI had, and will start corrupting the</span>
<span class="p_del">- * stack. This is handled in entry_64.S, but the same problem exists with</span>
<span class="p_del">- * the breakpoint stack.</span>
<span class="p_add">+ * In x86_64, we need to handle breakpoint -&gt; NMI -&gt; breakpoint.  Without</span>
<span class="p_add">+ * some care, the inner breakpoint will clobber the outer breakpoint&#39;s</span>
<span class="p_add">+ * stack.</span>
  *
<span class="p_del">- * If a breakpoint is being processed, and the debug stack is being used,</span>
<span class="p_del">- * if an NMI comes in and also hits a breakpoint, the stack pointer</span>
<span class="p_del">- * will be set to the same fixed address as the breakpoint that was</span>
<span class="p_del">- * interrupted, causing that stack to be corrupted. To handle this case,</span>
<span class="p_del">- * check if the stack that was interrupted is the debug stack, and if</span>
<span class="p_del">- * so, change the IDT so that new breakpoints will use the current stack</span>
<span class="p_del">- * and not switch to the fixed address. On return of the NMI, switch back</span>
<span class="p_del">- * to the original IDT.</span>
<span class="p_add">+ * If a breakpoint is being processed, and the debug stack is being</span>
<span class="p_add">+ * used, if an NMI comes in and also hits a breakpoint, the stack</span>
<span class="p_add">+ * pointer will be set to the same fixed address as the breakpoint that</span>
<span class="p_add">+ * was interrupted, causing that stack to be corrupted. To handle this</span>
<span class="p_add">+ * case, check if the stack that was interrupted is the debug stack, and</span>
<span class="p_add">+ * if so, change the IDT so that new breakpoints will use the current</span>
<span class="p_add">+ * stack and not switch to the fixed address. On return of the NMI,</span>
<span class="p_add">+ * switch back to the original IDT.</span>
  */
 static DEFINE_PER_CPU(int, update_debug_stack);
<span class="p_add">+#endif</span>
 
<span class="p_del">-static inline void nmi_nesting_preprocess(struct pt_regs *regs)</span>
<span class="p_add">+dotraplinkage notrace void</span>
<span class="p_add">+do_nmi(struct pt_regs *regs, long error_code)</span>
 {
<span class="p_add">+	if (this_cpu_read(nmi_state) != NMI_NOT_RUNNING) {</span>
<span class="p_add">+		this_cpu_write(nmi_state, NMI_LATCHED);</span>
<span class="p_add">+		return;</span>
<span class="p_add">+	}</span>
<span class="p_add">+	this_cpu_write(nmi_state, NMI_EXECUTING);</span>
<span class="p_add">+	this_cpu_write(nmi_cr2, read_cr2());</span>
<span class="p_add">+nmi_restart:</span>
<span class="p_add">+</span>
<span class="p_add">+#ifdef CONFIG_X86_64</span>
 	/*
 	 * If we interrupted a breakpoint, it is possible that
 	 * the nmi handler will have breakpoints too. We need to
<span class="p_chunk">@@ -514,22 +500,8 @@</span> <span class="p_context"> static inline void nmi_nesting_preprocess(struct pt_regs *regs)</span>
 		debug_stack_set_zero();
 		this_cpu_write(update_debug_stack, 1);
 	}
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static inline void nmi_nesting_postprocess(void)</span>
<span class="p_del">-{</span>
<span class="p_del">-	if (unlikely(this_cpu_read(update_debug_stack))) {</span>
<span class="p_del">-		debug_stack_reset();</span>
<span class="p_del">-		this_cpu_write(update_debug_stack, 0);</span>
<span class="p_del">-	}</span>
<span class="p_del">-}</span>
 #endif
 
<span class="p_del">-dotraplinkage notrace void</span>
<span class="p_del">-do_nmi(struct pt_regs *regs, long error_code)</span>
<span class="p_del">-{</span>
<span class="p_del">-	nmi_nesting_preprocess(regs);</span>
<span class="p_del">-</span>
 	nmi_enter();
 
 	inc_irq_stat(__nmi_count);
<span class="p_chunk">@@ -539,8 +511,17 @@</span> <span class="p_context"> do_nmi(struct pt_regs *regs, long error_code)</span>
 
 	nmi_exit();
 
<span class="p_del">-	/* On i386, may loop back to preprocess */</span>
<span class="p_del">-	nmi_nesting_postprocess();</span>
<span class="p_add">+#ifdef CONFIG_X86_64</span>
<span class="p_add">+	if (unlikely(this_cpu_read(update_debug_stack))) {</span>
<span class="p_add">+		debug_stack_reset();</span>
<span class="p_add">+		this_cpu_write(update_debug_stack, 0);</span>
<span class="p_add">+	}</span>
<span class="p_add">+#endif</span>
<span class="p_add">+</span>
<span class="p_add">+	if (unlikely(this_cpu_read(nmi_cr2) != read_cr2()))</span>
<span class="p_add">+		write_cr2(this_cpu_read(nmi_cr2));</span>
<span class="p_add">+	if (this_cpu_dec_return(nmi_state))</span>
<span class="p_add">+		goto nmi_restart;</span>
 }
 NOKPROBE_SYMBOL(do_nmi);
 
<span class="p_header">diff --git a/arch/x86/kvm/cpuid.c b/arch/x86/kvm/cpuid.c</span>
<span class="p_header">index 307f9ec..f3e5375 100644</span>
<span class="p_header">--- a/arch/x86/kvm/cpuid.c</span>
<span class="p_header">+++ b/arch/x86/kvm/cpuid.c</span>
<span class="p_chunk">@@ -98,6 +98,8 @@</span> <span class="p_context"> int kvm_update_cpuid(struct kvm_vcpu *vcpu)</span>
 		best-&gt;ebx = xstate_required_size(vcpu-&gt;arch.xcr0, true);
 
 	vcpu-&gt;arch.eager_fpu = guest_cpuid_has_mpx(vcpu);
<span class="p_add">+	if (vcpu-&gt;arch.eager_fpu)</span>
<span class="p_add">+		kvm_x86_ops-&gt;fpu_activate(vcpu);</span>
 
 	/*
 	 * The existing code assumes virtual address is 48-bit in the canonical
<span class="p_header">diff --git a/arch/x86/kvm/x86.c b/arch/x86/kvm/x86.c</span>
<span class="p_header">index 4725957..a692f1c 100644</span>
<span class="p_header">--- a/arch/x86/kvm/x86.c</span>
<span class="p_header">+++ b/arch/x86/kvm/x86.c</span>
<span class="p_chunk">@@ -7028,11 +7028,6 @@</span> <span class="p_context"> struct kvm_vcpu *kvm_arch_vcpu_create(struct kvm *kvm,</span>
 
 	vcpu = kvm_x86_ops-&gt;vcpu_create(kvm, id);
 
<span class="p_del">-	/*</span>
<span class="p_del">-	 * Activate fpu unconditionally in case the guest needs eager FPU.  It will be</span>
<span class="p_del">-	 * deactivated soon if it doesn&#39;t.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	kvm_x86_ops-&gt;fpu_activate(vcpu);</span>
 	return vcpu;
 }
 
<span class="p_header">diff --git a/block/bio-integrity.c b/block/bio-integrity.c</span>
<span class="p_header">index 5cbd5d9..39ce74d 100644</span>
<span class="p_header">--- a/block/bio-integrity.c</span>
<span class="p_header">+++ b/block/bio-integrity.c</span>
<span class="p_chunk">@@ -51,7 +51,7 @@</span> <span class="p_context"> struct bio_integrity_payload *bio_integrity_alloc(struct bio *bio,</span>
 	unsigned long idx = BIO_POOL_NONE;
 	unsigned inline_vecs;
 
<span class="p_del">-	if (!bs) {</span>
<span class="p_add">+	if (!bs || !bs-&gt;bio_integrity_pool) {</span>
 		bip = kmalloc(sizeof(struct bio_integrity_payload) +
 			      sizeof(struct bio_vec) * nr_vecs, gfp_mask);
 		inline_vecs = nr_vecs;
<span class="p_chunk">@@ -104,7 +104,7 @@</span> <span class="p_context"> void bio_integrity_free(struct bio *bio)</span>
 		kfree(page_address(bip-&gt;bip_vec-&gt;bv_page) +
 		      bip-&gt;bip_vec-&gt;bv_offset);
 
<span class="p_del">-	if (bs) {</span>
<span class="p_add">+	if (bs &amp;&amp; bs-&gt;bio_integrity_pool) {</span>
 		if (bip-&gt;bip_slab != BIO_POOL_NONE)
 			bvec_free(bs-&gt;bvec_integrity_pool, bip-&gt;bip_vec,
 				  bip-&gt;bip_slab);
<span class="p_header">diff --git a/drivers/acpi/osl.c b/drivers/acpi/osl.c</span>
<span class="p_header">index 330bccb..4c25675 100644</span>
<span class="p_header">--- a/drivers/acpi/osl.c</span>
<span class="p_header">+++ b/drivers/acpi/osl.c</span>
<span class="p_chunk">@@ -175,10 +175,14 @@</span> <span class="p_context"> static void __init acpi_request_region (struct acpi_generic_address *gas,</span>
 	if (!addr || !length)
 		return;
 
<span class="p_del">-	acpi_reserve_region(addr, length, gas-&gt;space_id, 0, desc);</span>
<span class="p_add">+	/* Resources are never freed */</span>
<span class="p_add">+	if (gas-&gt;space_id == ACPI_ADR_SPACE_SYSTEM_IO)</span>
<span class="p_add">+		request_region(addr, length, desc);</span>
<span class="p_add">+	else if (gas-&gt;space_id == ACPI_ADR_SPACE_SYSTEM_MEMORY)</span>
<span class="p_add">+		request_mem_region(addr, length, desc);</span>
 }
 
<span class="p_del">-static void __init acpi_reserve_resources(void)</span>
<span class="p_add">+static int __init acpi_reserve_resources(void)</span>
 {
 	acpi_request_region(&amp;acpi_gbl_FADT.xpm1a_event_block, acpi_gbl_FADT.pm1_event_length,
 		&quot;ACPI PM1a_EVT_BLK&quot;);
<span class="p_chunk">@@ -207,7 +211,10 @@</span> <span class="p_context"> static void __init acpi_reserve_resources(void)</span>
 	if (!(acpi_gbl_FADT.gpe1_block_length &amp; 0x1))
 		acpi_request_region(&amp;acpi_gbl_FADT.xgpe1_block,
 			       acpi_gbl_FADT.gpe1_block_length, &quot;ACPI GPE1_BLK&quot;);
<span class="p_add">+</span>
<span class="p_add">+	return 0;</span>
 }
<span class="p_add">+fs_initcall_sync(acpi_reserve_resources);</span>
 
 void acpi_os_printf(const char *fmt, ...)
 {
<span class="p_chunk">@@ -1838,7 +1845,6 @@</span> <span class="p_context"> acpi_status __init acpi_os_initialize(void)</span>
 
 acpi_status __init acpi_os_initialize1(void)
 {
<span class="p_del">-	acpi_reserve_resources();</span>
 	kacpid_wq = alloc_workqueue(&quot;kacpid&quot;, 0, 1);
 	kacpi_notify_wq = alloc_workqueue(&quot;kacpi_notify&quot;, 0, 1);
 	kacpi_hotplug_wq = alloc_ordered_workqueue(&quot;kacpi_hotplug&quot;, 0);
<span class="p_header">diff --git a/drivers/acpi/resource.c b/drivers/acpi/resource.c</span>
<span class="p_header">index b73e09d..782a0d1 100644</span>
<span class="p_header">--- a/drivers/acpi/resource.c</span>
<span class="p_header">+++ b/drivers/acpi/resource.c</span>
<span class="p_chunk">@@ -26,7 +26,6 @@</span> <span class="p_context"></span>
 #include &lt;linux/device.h&gt;
 #include &lt;linux/export.h&gt;
 #include &lt;linux/ioport.h&gt;
<span class="p_del">-#include &lt;linux/list.h&gt;</span>
 #include &lt;linux/slab.h&gt;
 
 #ifdef CONFIG_X86
<span class="p_chunk">@@ -539,164 +538,3 @@</span> <span class="p_context"> int acpi_dev_get_resources(struct acpi_device *adev, struct list_head *list,</span>
 	return c.count;
 }
 EXPORT_SYMBOL_GPL(acpi_dev_get_resources);
<span class="p_del">-</span>
<span class="p_del">-struct reserved_region {</span>
<span class="p_del">-	struct list_head node;</span>
<span class="p_del">-	u64 start;</span>
<span class="p_del">-	u64 end;</span>
<span class="p_del">-};</span>
<span class="p_del">-</span>
<span class="p_del">-static LIST_HEAD(reserved_io_regions);</span>
<span class="p_del">-static LIST_HEAD(reserved_mem_regions);</span>
<span class="p_del">-</span>
<span class="p_del">-static int request_range(u64 start, u64 end, u8 space_id, unsigned long flags,</span>
<span class="p_del">-			 char *desc)</span>
<span class="p_del">-{</span>
<span class="p_del">-	unsigned int length = end - start + 1;</span>
<span class="p_del">-	struct resource *res;</span>
<span class="p_del">-</span>
<span class="p_del">-	res = space_id == ACPI_ADR_SPACE_SYSTEM_IO ?</span>
<span class="p_del">-		request_region(start, length, desc) :</span>
<span class="p_del">-		request_mem_region(start, length, desc);</span>
<span class="p_del">-	if (!res)</span>
<span class="p_del">-		return -EIO;</span>
<span class="p_del">-</span>
<span class="p_del">-	res-&gt;flags &amp;= ~flags;</span>
<span class="p_del">-	return 0;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static int add_region_before(u64 start, u64 end, u8 space_id,</span>
<span class="p_del">-			     unsigned long flags, char *desc,</span>
<span class="p_del">-			     struct list_head *head)</span>
<span class="p_del">-{</span>
<span class="p_del">-	struct reserved_region *reg;</span>
<span class="p_del">-	int error;</span>
<span class="p_del">-</span>
<span class="p_del">-	reg = kmalloc(sizeof(*reg), GFP_KERNEL);</span>
<span class="p_del">-	if (!reg)</span>
<span class="p_del">-		return -ENOMEM;</span>
<span class="p_del">-</span>
<span class="p_del">-	error = request_range(start, end, space_id, flags, desc);</span>
<span class="p_del">-	if (error) {</span>
<span class="p_del">-		kfree(reg);</span>
<span class="p_del">-		return error;</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">-	reg-&gt;start = start;</span>
<span class="p_del">-	reg-&gt;end = end;</span>
<span class="p_del">-	list_add_tail(&amp;reg-&gt;node, head);</span>
<span class="p_del">-	return 0;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-/**</span>
<span class="p_del">- * acpi_reserve_region - Reserve an I/O or memory region as a system resource.</span>
<span class="p_del">- * @start: Starting address of the region.</span>
<span class="p_del">- * @length: Length of the region.</span>
<span class="p_del">- * @space_id: Identifier of address space to reserve the region from.</span>
<span class="p_del">- * @flags: Resource flags to clear for the region after requesting it.</span>
<span class="p_del">- * @desc: Region description (for messages).</span>
<span class="p_del">- *</span>
<span class="p_del">- * Reserve an I/O or memory region as a system resource to prevent others from</span>
<span class="p_del">- * using it.  If the new region overlaps with one of the regions (in the given</span>
<span class="p_del">- * address space) already reserved by this routine, only the non-overlapping</span>
<span class="p_del">- * parts of it will be reserved.</span>
<span class="p_del">- *</span>
<span class="p_del">- * Returned is either 0 (success) or a negative error code indicating a resource</span>
<span class="p_del">- * reservation problem.  It is the code of the first encountered error, but the</span>
<span class="p_del">- * routine doesn&#39;t abort until it has attempted to request all of the parts of</span>
<span class="p_del">- * the new region that don&#39;t overlap with other regions reserved previously.</span>
<span class="p_del">- *</span>
<span class="p_del">- * The resources requested by this routine are never released.</span>
<span class="p_del">- */</span>
<span class="p_del">-int acpi_reserve_region(u64 start, unsigned int length, u8 space_id,</span>
<span class="p_del">-			unsigned long flags, char *desc)</span>
<span class="p_del">-{</span>
<span class="p_del">-	struct list_head *regions;</span>
<span class="p_del">-	struct reserved_region *reg;</span>
<span class="p_del">-	u64 end = start + length - 1;</span>
<span class="p_del">-	int ret = 0, error = 0;</span>
<span class="p_del">-</span>
<span class="p_del">-	if (space_id == ACPI_ADR_SPACE_SYSTEM_IO)</span>
<span class="p_del">-		regions = &amp;reserved_io_regions;</span>
<span class="p_del">-	else if (space_id == ACPI_ADR_SPACE_SYSTEM_MEMORY)</span>
<span class="p_del">-		regions = &amp;reserved_mem_regions;</span>
<span class="p_del">-	else</span>
<span class="p_del">-		return -EINVAL;</span>
<span class="p_del">-</span>
<span class="p_del">-	if (list_empty(regions))</span>
<span class="p_del">-		return add_region_before(start, end, space_id, flags, desc, regions);</span>
<span class="p_del">-</span>
<span class="p_del">-	list_for_each_entry(reg, regions, node)</span>
<span class="p_del">-		if (reg-&gt;start == end + 1) {</span>
<span class="p_del">-			/* The new region can be prepended to this one. */</span>
<span class="p_del">-			ret = request_range(start, end, space_id, flags, desc);</span>
<span class="p_del">-			if (!ret)</span>
<span class="p_del">-				reg-&gt;start = start;</span>
<span class="p_del">-</span>
<span class="p_del">-			return ret;</span>
<span class="p_del">-		} else if (reg-&gt;start &gt; end) {</span>
<span class="p_del">-			/* No overlap.  Add the new region here and get out. */</span>
<span class="p_del">-			return add_region_before(start, end, space_id, flags,</span>
<span class="p_del">-						 desc, &amp;reg-&gt;node);</span>
<span class="p_del">-		} else if (reg-&gt;end == start - 1) {</span>
<span class="p_del">-			goto combine;</span>
<span class="p_del">-		} else if (reg-&gt;end &gt;= start) {</span>
<span class="p_del">-			goto overlap;</span>
<span class="p_del">-		}</span>
<span class="p_del">-</span>
<span class="p_del">-	/* The new region goes after the last existing one. */</span>
<span class="p_del">-	return add_region_before(start, end, space_id, flags, desc, regions);</span>
<span class="p_del">-</span>
<span class="p_del">- overlap:</span>
<span class="p_del">-	/*</span>
<span class="p_del">-	 * The new region overlaps an existing one.</span>
<span class="p_del">-	 *</span>
<span class="p_del">-	 * The head part of the new region immediately preceding the existing</span>
<span class="p_del">-	 * overlapping one can be combined with it right away.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	if (reg-&gt;start &gt; start) {</span>
<span class="p_del">-		error = request_range(start, reg-&gt;start - 1, space_id, flags, desc);</span>
<span class="p_del">-		if (error)</span>
<span class="p_del">-			ret = error;</span>
<span class="p_del">-		else</span>
<span class="p_del">-			reg-&gt;start = start;</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">- combine:</span>
<span class="p_del">-	/*</span>
<span class="p_del">-	 * The new region is adjacent to an existing one.  If it extends beyond</span>
<span class="p_del">-	 * that region all the way to the next one, it is possible to combine</span>
<span class="p_del">-	 * all three of them.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	while (reg-&gt;end &lt; end) {</span>
<span class="p_del">-		struct reserved_region *next = NULL;</span>
<span class="p_del">-		u64 a = reg-&gt;end + 1, b = end;</span>
<span class="p_del">-</span>
<span class="p_del">-		if (!list_is_last(&amp;reg-&gt;node, regions)) {</span>
<span class="p_del">-			next = list_next_entry(reg, node);</span>
<span class="p_del">-			if (next-&gt;start &lt;= end)</span>
<span class="p_del">-				b = next-&gt;start - 1;</span>
<span class="p_del">-		}</span>
<span class="p_del">-		error = request_range(a, b, space_id, flags, desc);</span>
<span class="p_del">-		if (!error) {</span>
<span class="p_del">-			if (next &amp;&amp; next-&gt;start == b + 1) {</span>
<span class="p_del">-				reg-&gt;end = next-&gt;end;</span>
<span class="p_del">-				list_del(&amp;next-&gt;node);</span>
<span class="p_del">-				kfree(next);</span>
<span class="p_del">-			} else {</span>
<span class="p_del">-				reg-&gt;end = end;</span>
<span class="p_del">-				break;</span>
<span class="p_del">-			}</span>
<span class="p_del">-		} else if (next) {</span>
<span class="p_del">-			if (!ret)</span>
<span class="p_del">-				ret = error;</span>
<span class="p_del">-</span>
<span class="p_del">-			reg = next;</span>
<span class="p_del">-		} else {</span>
<span class="p_del">-			break;</span>
<span class="p_del">-		}</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">-	return ret ? ret : error;</span>
<span class="p_del">-}</span>
<span class="p_del">-EXPORT_SYMBOL_GPL(acpi_reserve_region);</span>
<span class="p_header">diff --git a/drivers/clk/qcom/clk-rcg2.c b/drivers/clk/qcom/clk-rcg2.c</span>
<span class="p_header">index 4fe9c01..05b7bbc 100644</span>
<span class="p_header">--- a/drivers/clk/qcom/clk-rcg2.c</span>
<span class="p_header">+++ b/drivers/clk/qcom/clk-rcg2.c</span>
<span class="p_chunk">@@ -508,18 +508,16 @@</span> <span class="p_context"> static int clk_pixel_set_rate(struct clk_hw *hw, unsigned long rate,</span>
 	struct clk_rcg2 *rcg = to_clk_rcg2(hw);
 	struct freq_tbl f = *rcg-&gt;freq_tbl;
 	const struct frac_entry *frac = frac_table_pixel;
<span class="p_del">-	unsigned long request, src_rate;</span>
<span class="p_add">+	unsigned long request;</span>
 	int delta = 100000;
 	u32 mask = BIT(rcg-&gt;hid_width) - 1;
 	u32 hid_div;
<span class="p_del">-	struct clk *parent = clk_get_parent_by_index(hw-&gt;clk, f.src);</span>
 
 	for (; frac-&gt;num; frac++) {
 		request = (rate * frac-&gt;den) / frac-&gt;num;
 
<span class="p_del">-		src_rate = __clk_round_rate(parent, request);</span>
<span class="p_del">-		if ((src_rate &lt; (request - delta)) ||</span>
<span class="p_del">-			(src_rate &gt; (request + delta)))</span>
<span class="p_add">+		if ((parent_rate &lt; (request - delta)) ||</span>
<span class="p_add">+			(parent_rate &gt; (request + delta)))</span>
 			continue;
 
 		regmap_read(rcg-&gt;clkr.regmap, rcg-&gt;cmd_rcgr + CFG_REG,
<span class="p_header">diff --git a/drivers/clk/st/clk-flexgen.c b/drivers/clk/st/clk-flexgen.c</span>
<span class="p_header">index 2282cef..97aa50a 100644</span>
<span class="p_header">--- a/drivers/clk/st/clk-flexgen.c</span>
<span class="p_header">+++ b/drivers/clk/st/clk-flexgen.c</span>
<span class="p_chunk">@@ -292,6 +292,8 @@</span> <span class="p_context"> void __init st_of_flexgen_setup(struct device_node *np)</span>
 	if (!rlock)
 		goto err;
 
<span class="p_add">+	spin_lock_init(rlock);</span>
<span class="p_add">+</span>
 	for (i = 0; i &lt; clk_data-&gt;clk_num; i++) {
 		struct clk *clk;
 		const char *clk_name;
<span class="p_header">diff --git a/drivers/clk/st/clkgen-fsyn.c b/drivers/clk/st/clkgen-fsyn.c</span>
<span class="p_header">index af94ed8..e5ab296 100644</span>
<span class="p_header">--- a/drivers/clk/st/clkgen-fsyn.c</span>
<span class="p_header">+++ b/drivers/clk/st/clkgen-fsyn.c</span>
<span class="p_chunk">@@ -340,7 +340,7 @@</span> <span class="p_context"> static const struct clkgen_quadfs_data st_fs660c32_C_407 = {</span>
 		    CLKGEN_FIELD(0x30c, 0xf, 20),
 		    CLKGEN_FIELD(0x310, 0xf, 20) },
 	.lockstatus_present = true,
<span class="p_del">-	.lock_status = CLKGEN_FIELD(0x2A0, 0x1, 24),</span>
<span class="p_add">+	.lock_status = CLKGEN_FIELD(0x2f0, 0x1, 24),</span>
 	.powerup_polarity = 1,
 	.standby_polarity = 1,
 	.pll_ops	= &amp;st_quadfs_pll_c32_ops,
<span class="p_header">diff --git a/drivers/clk/st/clkgen-mux.c b/drivers/clk/st/clkgen-mux.c</span>
<span class="p_header">index 79dc40b..986ee70 100644</span>
<span class="p_header">--- a/drivers/clk/st/clkgen-mux.c</span>
<span class="p_header">+++ b/drivers/clk/st/clkgen-mux.c</span>
<span class="p_chunk">@@ -582,7 +582,7 @@</span> <span class="p_context"> static struct clkgen_mux_data stih416_a9_mux_data = {</span>
 };
 static struct clkgen_mux_data stih407_a9_mux_data = {
 	.offset = 0x1a4,
<span class="p_del">-	.shift = 1,</span>
<span class="p_add">+	.shift = 0,</span>
 	.width = 2,
 };
 
<span class="p_header">diff --git a/drivers/crypto/omap-des.c b/drivers/crypto/omap-des.c</span>
<span class="p_header">index e350f5b..7dda730 100644</span>
<span class="p_header">--- a/drivers/crypto/omap-des.c</span>
<span class="p_header">+++ b/drivers/crypto/omap-des.c</span>
<span class="p_chunk">@@ -536,9 +536,6 @@</span> <span class="p_context"> static int omap_des_crypt_dma_stop(struct omap_des_dev *dd)</span>
 	dmaengine_terminate_all(dd-&gt;dma_lch_in);
 	dmaengine_terminate_all(dd-&gt;dma_lch_out);
 
<span class="p_del">-	dma_unmap_sg(dd-&gt;dev, dd-&gt;in_sg, dd-&gt;in_sg_len, DMA_TO_DEVICE);</span>
<span class="p_del">-	dma_unmap_sg(dd-&gt;dev, dd-&gt;out_sg, dd-&gt;out_sg_len, DMA_FROM_DEVICE);</span>
<span class="p_del">-</span>
 	return err;
 }
 
<span class="p_header">diff --git a/drivers/gpu/drm/drm_crtc.c b/drivers/gpu/drm/drm_crtc.c</span>
<span class="p_header">index 27a37e5..acb6e90 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/drm_crtc.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/drm_crtc.c</span>
<span class="p_chunk">@@ -2633,8 +2633,11 @@</span> <span class="p_context"> int drm_mode_setcrtc(struct drm_device *dev, void *data,</span>
 	if (!drm_core_check_feature(dev, DRIVER_MODESET))
 		return -EINVAL;
 
<span class="p_del">-	/* For some reason crtc x/y offsets are signed internally. */</span>
<span class="p_del">-	if (crtc_req-&gt;x &gt; INT_MAX || crtc_req-&gt;y &gt; INT_MAX)</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Universal plane src offsets are only 16.16, prevent havoc for</span>
<span class="p_add">+	 * drivers using universal plane code internally.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	if (crtc_req-&gt;x &amp; 0xffff0000 || crtc_req-&gt;y &amp; 0xffff0000)</span>
 		return -ERANGE;
 
 	drm_modeset_lock_all(dev);
<span class="p_header">diff --git a/drivers/gpu/drm/radeon/ci_dpm.c b/drivers/gpu/drm/radeon/ci_dpm.c</span>
<span class="p_header">index f373a81..c4dc1e1 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/radeon/ci_dpm.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/radeon/ci_dpm.c</span>
<span class="p_chunk">@@ -5781,7 +5781,7 @@</span> <span class="p_context"> int ci_dpm_init(struct radeon_device *rdev)</span>
 			tmp |= DPM_ENABLED;
 			break;
 		default:
<span class="p_del">-			DRM_ERROR(&quot;Invalid PCC GPIO: %u!\n&quot;, gpio.shift);</span>
<span class="p_add">+			DRM_DEBUG(&quot;Invalid PCC GPIO: %u!\n&quot;, gpio.shift);</span>
 			break;
 		}
 		WREG32_SMC(CNB_PWRMGT_CNTL, tmp);
<span class="p_header">diff --git a/drivers/gpu/drm/radeon/radeon_cursor.c b/drivers/gpu/drm/radeon/radeon_cursor.c</span>
<span class="p_header">index 45e5406..fa66174 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/radeon/radeon_cursor.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/radeon/radeon_cursor.c</span>
<span class="p_chunk">@@ -205,8 +205,9 @@</span> <span class="p_context"> static int radeon_cursor_move_locked(struct drm_crtc *crtc, int x, int y)</span>
 			| (x &lt;&lt; 16)
 			| y));
 		/* offset is from DISP(2)_BASE_ADDRESS */
<span class="p_del">-		WREG32(RADEON_CUR_OFFSET + radeon_crtc-&gt;crtc_offset, (radeon_crtc-&gt;legacy_cursor_offset +</span>
<span class="p_del">-								      (yorigin * 256)));</span>
<span class="p_add">+		WREG32(RADEON_CUR_OFFSET + radeon_crtc-&gt;crtc_offset,</span>
<span class="p_add">+		       radeon_crtc-&gt;cursor_addr - radeon_crtc-&gt;legacy_display_base_addr +</span>
<span class="p_add">+		       yorigin * 256);</span>
 	}
 
 	radeon_crtc-&gt;cursor_x = x;
<span class="p_chunk">@@ -227,51 +228,32 @@</span> <span class="p_context"> int radeon_crtc_cursor_move(struct drm_crtc *crtc,</span>
 	return ret;
 }
 
<span class="p_del">-static int radeon_set_cursor(struct drm_crtc *crtc, struct drm_gem_object *obj)</span>
<span class="p_add">+static void radeon_set_cursor(struct drm_crtc *crtc)</span>
 {
 	struct radeon_crtc *radeon_crtc = to_radeon_crtc(crtc);
 	struct radeon_device *rdev = crtc-&gt;dev-&gt;dev_private;
<span class="p_del">-	struct radeon_bo *robj = gem_to_radeon_bo(obj);</span>
<span class="p_del">-	uint64_t gpu_addr;</span>
<span class="p_del">-	int ret;</span>
<span class="p_del">-</span>
<span class="p_del">-	ret = radeon_bo_reserve(robj, false);</span>
<span class="p_del">-	if (unlikely(ret != 0))</span>
<span class="p_del">-		goto fail;</span>
<span class="p_del">-	/* Only 27 bit offset for legacy cursor */</span>
<span class="p_del">-	ret = radeon_bo_pin_restricted(robj, RADEON_GEM_DOMAIN_VRAM,</span>
<span class="p_del">-				       ASIC_IS_AVIVO(rdev) ? 0 : 1 &lt;&lt; 27,</span>
<span class="p_del">-				       &amp;gpu_addr);</span>
<span class="p_del">-	radeon_bo_unreserve(robj);</span>
<span class="p_del">-	if (ret)</span>
<span class="p_del">-		goto fail;</span>
 
 	if (ASIC_IS_DCE4(rdev)) {
 		WREG32(EVERGREEN_CUR_SURFACE_ADDRESS_HIGH + radeon_crtc-&gt;crtc_offset,
<span class="p_del">-		       upper_32_bits(gpu_addr));</span>
<span class="p_add">+		       upper_32_bits(radeon_crtc-&gt;cursor_addr));</span>
 		WREG32(EVERGREEN_CUR_SURFACE_ADDRESS + radeon_crtc-&gt;crtc_offset,
<span class="p_del">-		       gpu_addr &amp; 0xffffffff);</span>
<span class="p_add">+		       lower_32_bits(radeon_crtc-&gt;cursor_addr));</span>
 	} else if (ASIC_IS_AVIVO(rdev)) {
 		if (rdev-&gt;family &gt;= CHIP_RV770) {
 			if (radeon_crtc-&gt;crtc_id)
<span class="p_del">-				WREG32(R700_D2CUR_SURFACE_ADDRESS_HIGH, upper_32_bits(gpu_addr));</span>
<span class="p_add">+				WREG32(R700_D2CUR_SURFACE_ADDRESS_HIGH,</span>
<span class="p_add">+				       upper_32_bits(radeon_crtc-&gt;cursor_addr));</span>
 			else
<span class="p_del">-				WREG32(R700_D1CUR_SURFACE_ADDRESS_HIGH, upper_32_bits(gpu_addr));</span>
<span class="p_add">+				WREG32(R700_D1CUR_SURFACE_ADDRESS_HIGH,</span>
<span class="p_add">+				       upper_32_bits(radeon_crtc-&gt;cursor_addr));</span>
 		}
 		WREG32(AVIVO_D1CUR_SURFACE_ADDRESS + radeon_crtc-&gt;crtc_offset,
<span class="p_del">-		       gpu_addr &amp; 0xffffffff);</span>
<span class="p_add">+		       lower_32_bits(radeon_crtc-&gt;cursor_addr));</span>
 	} else {
<span class="p_del">-		radeon_crtc-&gt;legacy_cursor_offset = gpu_addr - radeon_crtc-&gt;legacy_display_base_addr;</span>
 		/* offset is from DISP(2)_BASE_ADDRESS */
<span class="p_del">-		WREG32(RADEON_CUR_OFFSET + radeon_crtc-&gt;crtc_offset, radeon_crtc-&gt;legacy_cursor_offset);</span>
<span class="p_add">+		WREG32(RADEON_CUR_OFFSET + radeon_crtc-&gt;crtc_offset,</span>
<span class="p_add">+		       radeon_crtc-&gt;cursor_addr - radeon_crtc-&gt;legacy_display_base_addr);</span>
 	}
<span class="p_del">-</span>
<span class="p_del">-	return 0;</span>
<span class="p_del">-</span>
<span class="p_del">-fail:</span>
<span class="p_del">-	drm_gem_object_unreference_unlocked(obj);</span>
<span class="p_del">-</span>
<span class="p_del">-	return ret;</span>
 }
 
 int radeon_crtc_cursor_set2(struct drm_crtc *crtc,
<span class="p_chunk">@@ -283,7 +265,9 @@</span> <span class="p_context"> int radeon_crtc_cursor_set2(struct drm_crtc *crtc,</span>
 			    int32_t hot_y)
 {
 	struct radeon_crtc *radeon_crtc = to_radeon_crtc(crtc);
<span class="p_add">+	struct radeon_device *rdev = crtc-&gt;dev-&gt;dev_private;</span>
 	struct drm_gem_object *obj;
<span class="p_add">+	struct radeon_bo *robj;</span>
 	int ret;
 
 	if (!handle) {
<span class="p_chunk">@@ -305,6 +289,23 @@</span> <span class="p_context"> int radeon_crtc_cursor_set2(struct drm_crtc *crtc,</span>
 		return -ENOENT;
 	}
 
<span class="p_add">+	robj = gem_to_radeon_bo(obj);</span>
<span class="p_add">+	ret = radeon_bo_reserve(robj, false);</span>
<span class="p_add">+	if (ret != 0) {</span>
<span class="p_add">+		drm_gem_object_unreference_unlocked(obj);</span>
<span class="p_add">+		return ret;</span>
<span class="p_add">+	}</span>
<span class="p_add">+	/* Only 27 bit offset for legacy cursor */</span>
<span class="p_add">+	ret = radeon_bo_pin_restricted(robj, RADEON_GEM_DOMAIN_VRAM,</span>
<span class="p_add">+				       ASIC_IS_AVIVO(rdev) ? 0 : 1 &lt;&lt; 27,</span>
<span class="p_add">+				       &amp;radeon_crtc-&gt;cursor_addr);</span>
<span class="p_add">+	radeon_bo_unreserve(robj);</span>
<span class="p_add">+	if (ret) {</span>
<span class="p_add">+		DRM_ERROR(&quot;Failed to pin new cursor BO (%d)\n&quot;, ret);</span>
<span class="p_add">+		drm_gem_object_unreference_unlocked(obj);</span>
<span class="p_add">+		return ret;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
 	radeon_crtc-&gt;cursor_width = width;
 	radeon_crtc-&gt;cursor_height = height;
 
<span class="p_chunk">@@ -323,13 +324,8 @@</span> <span class="p_context"> int radeon_crtc_cursor_set2(struct drm_crtc *crtc,</span>
 		radeon_crtc-&gt;cursor_hot_y = hot_y;
 	}
 
<span class="p_del">-	ret = radeon_set_cursor(crtc, obj);</span>
<span class="p_del">-</span>
<span class="p_del">-	if (ret)</span>
<span class="p_del">-		DRM_ERROR(&quot;radeon_set_cursor returned %d, not changing cursor\n&quot;,</span>
<span class="p_del">-			  ret);</span>
<span class="p_del">-	else</span>
<span class="p_del">-		radeon_show_cursor(crtc);</span>
<span class="p_add">+	radeon_set_cursor(crtc);</span>
<span class="p_add">+	radeon_show_cursor(crtc);</span>
 
 	radeon_lock_cursor(crtc, false);
 
<span class="p_chunk">@@ -341,8 +337,7 @@</span> <span class="p_context"> unpin:</span>
 			radeon_bo_unpin(robj);
 			radeon_bo_unreserve(robj);
 		}
<span class="p_del">-		if (radeon_crtc-&gt;cursor_bo != obj)</span>
<span class="p_del">-			drm_gem_object_unreference_unlocked(radeon_crtc-&gt;cursor_bo);</span>
<span class="p_add">+		drm_gem_object_unreference_unlocked(radeon_crtc-&gt;cursor_bo);</span>
 	}
 
 	radeon_crtc-&gt;cursor_bo = obj;
<span class="p_chunk">@@ -360,7 +355,6 @@</span> <span class="p_context"> unpin:</span>
 void radeon_cursor_reset(struct drm_crtc *crtc)
 {
 	struct radeon_crtc *radeon_crtc = to_radeon_crtc(crtc);
<span class="p_del">-	int ret;</span>
 
 	if (radeon_crtc-&gt;cursor_bo) {
 		radeon_lock_cursor(crtc, true);
<span class="p_chunk">@@ -368,12 +362,8 @@</span> <span class="p_context"> void radeon_cursor_reset(struct drm_crtc *crtc)</span>
 		radeon_cursor_move_locked(crtc, radeon_crtc-&gt;cursor_x,
 					  radeon_crtc-&gt;cursor_y);
 
<span class="p_del">-		ret = radeon_set_cursor(crtc, radeon_crtc-&gt;cursor_bo);</span>
<span class="p_del">-		if (ret)</span>
<span class="p_del">-			DRM_ERROR(&quot;radeon_set_cursor returned %d, not showing &quot;</span>
<span class="p_del">-				  &quot;cursor\n&quot;, ret);</span>
<span class="p_del">-		else</span>
<span class="p_del">-			radeon_show_cursor(crtc);</span>
<span class="p_add">+		radeon_set_cursor(crtc);</span>
<span class="p_add">+		radeon_show_cursor(crtc);</span>
 
 		radeon_lock_cursor(crtc, false);
 	}
<span class="p_header">diff --git a/drivers/gpu/drm/radeon/radeon_device.c b/drivers/gpu/drm/radeon/radeon_device.c</span>
<span class="p_header">index aa232fd..b3dfefb 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/radeon/radeon_device.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/radeon/radeon_device.c</span>
<span class="p_chunk">@@ -1567,11 +1567,21 @@</span> <span class="p_context"> int radeon_suspend_kms(struct drm_device *dev, bool suspend, bool fbcon)</span>
 		drm_helper_connector_dpms(connector, DRM_MODE_DPMS_OFF);
 	}
 
<span class="p_del">-	/* unpin the front buffers */</span>
<span class="p_add">+	/* unpin the front buffers and cursors */</span>
 	list_for_each_entry(crtc, &amp;dev-&gt;mode_config.crtc_list, head) {
<span class="p_add">+		struct radeon_crtc *radeon_crtc = to_radeon_crtc(crtc);</span>
 		struct radeon_framebuffer *rfb = to_radeon_framebuffer(crtc-&gt;primary-&gt;fb);
 		struct radeon_bo *robj;
 
<span class="p_add">+		if (radeon_crtc-&gt;cursor_bo) {</span>
<span class="p_add">+			struct radeon_bo *robj = gem_to_radeon_bo(radeon_crtc-&gt;cursor_bo);</span>
<span class="p_add">+			r = radeon_bo_reserve(robj, false);</span>
<span class="p_add">+			if (r == 0) {</span>
<span class="p_add">+				radeon_bo_unpin(robj);</span>
<span class="p_add">+				radeon_bo_unreserve(robj);</span>
<span class="p_add">+			}</span>
<span class="p_add">+		}</span>
<span class="p_add">+</span>
 		if (rfb == NULL || rfb-&gt;obj == NULL) {
 			continue;
 		}
<span class="p_chunk">@@ -1634,6 +1644,7 @@</span> <span class="p_context"> int radeon_resume_kms(struct drm_device *dev, bool resume, bool fbcon)</span>
 {
 	struct drm_connector *connector;
 	struct radeon_device *rdev = dev-&gt;dev_private;
<span class="p_add">+	struct drm_crtc *crtc;</span>
 	int r;
 
 	if (dev-&gt;switch_power_state == DRM_SWITCH_POWER_OFF)
<span class="p_chunk">@@ -1673,6 +1684,27 @@</span> <span class="p_context"> int radeon_resume_kms(struct drm_device *dev, bool resume, bool fbcon)</span>
 
 	radeon_restore_bios_scratch_regs(rdev);
 
<span class="p_add">+	/* pin cursors */</span>
<span class="p_add">+	list_for_each_entry(crtc, &amp;dev-&gt;mode_config.crtc_list, head) {</span>
<span class="p_add">+		struct radeon_crtc *radeon_crtc = to_radeon_crtc(crtc);</span>
<span class="p_add">+</span>
<span class="p_add">+		if (radeon_crtc-&gt;cursor_bo) {</span>
<span class="p_add">+			struct radeon_bo *robj = gem_to_radeon_bo(radeon_crtc-&gt;cursor_bo);</span>
<span class="p_add">+			r = radeon_bo_reserve(robj, false);</span>
<span class="p_add">+			if (r == 0) {</span>
<span class="p_add">+				/* Only 27 bit offset for legacy cursor */</span>
<span class="p_add">+				r = radeon_bo_pin_restricted(robj,</span>
<span class="p_add">+							     RADEON_GEM_DOMAIN_VRAM,</span>
<span class="p_add">+							     ASIC_IS_AVIVO(rdev) ?</span>
<span class="p_add">+							     0 : 1 &lt;&lt; 27,</span>
<span class="p_add">+							     &amp;radeon_crtc-&gt;cursor_addr);</span>
<span class="p_add">+				if (r != 0)</span>
<span class="p_add">+					DRM_ERROR(&quot;Failed to pin cursor BO (%d)\n&quot;, r);</span>
<span class="p_add">+				radeon_bo_unreserve(robj);</span>
<span class="p_add">+			}</span>
<span class="p_add">+		}</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
 	/* init dig PHYs, disp eng pll */
 	if (rdev-&gt;is_atom_bios) {
 		radeon_atom_encoder_init(rdev);
<span class="p_header">diff --git a/drivers/gpu/drm/radeon/radeon_gart.c b/drivers/gpu/drm/radeon/radeon_gart.c</span>
<span class="p_header">index 5450fa9..c4777c8 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/radeon/radeon_gart.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/radeon/radeon_gart.c</span>
<span class="p_chunk">@@ -260,8 +260,10 @@</span> <span class="p_context"> void radeon_gart_unbind(struct radeon_device *rdev, unsigned offset,</span>
 			}
 		}
 	}
<span class="p_del">-	mb();</span>
<span class="p_del">-	radeon_gart_tlb_flush(rdev);</span>
<span class="p_add">+	if (rdev-&gt;gart.ptr) {</span>
<span class="p_add">+		mb();</span>
<span class="p_add">+		radeon_gart_tlb_flush(rdev);</span>
<span class="p_add">+	}</span>
 }
 
 /**
<span class="p_chunk">@@ -306,8 +308,10 @@</span> <span class="p_context"> int radeon_gart_bind(struct radeon_device *rdev, unsigned offset,</span>
 			page_base += RADEON_GPU_PAGE_SIZE;
 		}
 	}
<span class="p_del">-	mb();</span>
<span class="p_del">-	radeon_gart_tlb_flush(rdev);</span>
<span class="p_add">+	if (rdev-&gt;gart.ptr) {</span>
<span class="p_add">+		mb();</span>
<span class="p_add">+		radeon_gart_tlb_flush(rdev);</span>
<span class="p_add">+	}</span>
 	return 0;
 }
 
<span class="p_header">diff --git a/drivers/gpu/drm/radeon/radeon_gem.c b/drivers/gpu/drm/radeon/radeon_gem.c</span>
<span class="p_header">index ac3c131..186d0b7 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/radeon/radeon_gem.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/radeon/radeon_gem.c</span>
<span class="p_chunk">@@ -36,6 +36,7 @@</span> <span class="p_context"> void radeon_gem_object_free(struct drm_gem_object *gobj)</span>
 	if (robj) {
 		if (robj-&gt;gem_base.import_attach)
 			drm_prime_gem_destroy(&amp;robj-&gt;gem_base, robj-&gt;tbo.sg);
<span class="p_add">+		radeon_mn_unregister(robj);</span>
 		radeon_bo_unref(&amp;robj);
 	}
 }
<span class="p_chunk">@@ -471,6 +472,7 @@</span> <span class="p_context"> int radeon_gem_wait_idle_ioctl(struct drm_device *dev, void *data,</span>
 		r = ret;
 
 	/* Flush HDP cache via MMIO if necessary */
<span class="p_add">+	cur_placement = ACCESS_ONCE(robj-&gt;tbo.mem.mem_type);</span>
 	if (rdev-&gt;asic-&gt;mmio_hdp_flush &amp;&amp;
 	    radeon_mem_type_to_domain(cur_placement) == RADEON_GEM_DOMAIN_VRAM)
 		robj-&gt;rdev-&gt;asic-&gt;mmio_hdp_flush(rdev);
<span class="p_header">diff --git a/drivers/gpu/drm/radeon/radeon_mode.h b/drivers/gpu/drm/radeon/radeon_mode.h</span>
<span class="p_header">index 390db89..4ca6695 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/radeon/radeon_mode.h</span>
<span class="p_header">+++ b/drivers/gpu/drm/radeon/radeon_mode.h</span>
<span class="p_chunk">@@ -330,7 +330,6 @@</span> <span class="p_context"> struct radeon_crtc {</span>
 	int max_cursor_width;
 	int max_cursor_height;
 	uint32_t legacy_display_base_addr;
<span class="p_del">-	uint32_t legacy_cursor_offset;</span>
 	enum radeon_rmx_type rmx_type;
 	u8 h_border;
 	u8 v_border;
<span class="p_header">diff --git a/drivers/gpu/drm/radeon/radeon_object.c b/drivers/gpu/drm/radeon/radeon_object.c</span>
<span class="p_header">index 24f7d30..12ea1e5 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/radeon/radeon_object.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/radeon/radeon_object.c</span>
<span class="p_chunk">@@ -75,7 +75,6 @@</span> <span class="p_context"> static void radeon_ttm_bo_destroy(struct ttm_buffer_object *tbo)</span>
 	bo = container_of(tbo, struct radeon_bo, tbo);
 
 	radeon_update_memory_usage(bo, bo-&gt;tbo.mem.mem_type, -1);
<span class="p_del">-	radeon_mn_unregister(bo);</span>
 
 	mutex_lock(&amp;bo-&gt;rdev-&gt;gem.mutex);
 	list_del_init(&amp;bo-&gt;list);
<span class="p_header">diff --git a/drivers/gpu/drm/radeon/si_dpm.c b/drivers/gpu/drm/radeon/si_dpm.c</span>
<span class="p_header">index 50313d7..fe252b0 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/radeon/si_dpm.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/radeon/si_dpm.c</span>
<span class="p_chunk">@@ -2922,6 +2922,7 @@</span> <span class="p_context"> static struct si_dpm_quirk si_dpm_quirk_list[] = {</span>
 	/* PITCAIRN - https://bugs.freedesktop.org/show_bug.cgi?id=76490 */
 	{ PCI_VENDOR_ID_ATI, 0x6810, 0x1462, 0x3036, 0, 120000 },
 	{ PCI_VENDOR_ID_ATI, 0x6811, 0x174b, 0xe271, 0, 120000 },
<span class="p_add">+	{ PCI_VENDOR_ID_ATI, 0x6810, 0x174b, 0xe271, 85000, 90000 },</span>
 	{ 0, 0, 0, 0 },
 };
 
<span class="p_header">diff --git a/drivers/gpu/drm/rockchip/rockchip_drm_gem.c b/drivers/gpu/drm/rockchip/rockchip_drm_gem.c</span>
<span class="p_header">index bc98a22..b79dc98 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/rockchip/rockchip_drm_gem.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/rockchip/rockchip_drm_gem.c</span>
<span class="p_chunk">@@ -54,55 +54,56 @@</span> <span class="p_context"> static void rockchip_gem_free_buf(struct rockchip_gem_object *rk_obj)</span>
 		       &amp;rk_obj-&gt;dma_attrs);
 }
 
<span class="p_del">-int rockchip_gem_mmap_buf(struct drm_gem_object *obj,</span>
<span class="p_del">-			  struct vm_area_struct *vma)</span>
<span class="p_add">+static int rockchip_drm_gem_object_mmap(struct drm_gem_object *obj,</span>
<span class="p_add">+					struct vm_area_struct *vma)</span>
<span class="p_add">+</span>
 {
<span class="p_add">+	int ret;</span>
 	struct rockchip_gem_object *rk_obj = to_rockchip_obj(obj);
 	struct drm_device *drm = obj-&gt;dev;
<span class="p_del">-	unsigned long vm_size;</span>
 
<span class="p_del">-	vma-&gt;vm_flags |= VM_IO | VM_DONTEXPAND | VM_DONTDUMP;</span>
<span class="p_del">-	vm_size = vma-&gt;vm_end - vma-&gt;vm_start;</span>
<span class="p_del">-</span>
<span class="p_del">-	if (vm_size &gt; obj-&gt;size)</span>
<span class="p_del">-		return -EINVAL;</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * dma_alloc_attrs() allocated a struct page table for rk_obj, so clear</span>
<span class="p_add">+	 * VM_PFNMAP flag that was set by drm_gem_mmap_obj()/drm_gem_mmap().</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	vma-&gt;vm_flags &amp;= ~VM_PFNMAP;</span>
 
<span class="p_del">-	return dma_mmap_attrs(drm-&gt;dev, vma, rk_obj-&gt;kvaddr, rk_obj-&gt;dma_addr,</span>
<span class="p_add">+	ret = dma_mmap_attrs(drm-&gt;dev, vma, rk_obj-&gt;kvaddr, rk_obj-&gt;dma_addr,</span>
 			     obj-&gt;size, &amp;rk_obj-&gt;dma_attrs);
<span class="p_add">+	if (ret)</span>
<span class="p_add">+		drm_gem_vm_close(vma);</span>
<span class="p_add">+</span>
<span class="p_add">+	return ret;</span>
 }
 
<span class="p_del">-/* drm driver mmap file operations */</span>
<span class="p_del">-int rockchip_gem_mmap(struct file *filp, struct vm_area_struct *vma)</span>
<span class="p_add">+int rockchip_gem_mmap_buf(struct drm_gem_object *obj,</span>
<span class="p_add">+			  struct vm_area_struct *vma)</span>
 {
<span class="p_del">-	struct drm_file *priv = filp-&gt;private_data;</span>
<span class="p_del">-	struct drm_device *dev = priv-&gt;minor-&gt;dev;</span>
<span class="p_del">-	struct drm_gem_object *obj;</span>
<span class="p_del">-	struct drm_vma_offset_node *node;</span>
<span class="p_add">+	struct drm_device *drm = obj-&gt;dev;</span>
 	int ret;
 
<span class="p_del">-	if (drm_device_is_unplugged(dev))</span>
<span class="p_del">-		return -ENODEV;</span>
<span class="p_add">+	mutex_lock(&amp;drm-&gt;struct_mutex);</span>
<span class="p_add">+	ret = drm_gem_mmap_obj(obj, obj-&gt;size, vma);</span>
<span class="p_add">+	mutex_unlock(&amp;drm-&gt;struct_mutex);</span>
<span class="p_add">+	if (ret)</span>
<span class="p_add">+		return ret;</span>
 
<span class="p_del">-	mutex_lock(&amp;dev-&gt;struct_mutex);</span>
<span class="p_add">+	return rockchip_drm_gem_object_mmap(obj, vma);</span>
<span class="p_add">+}</span>
 
<span class="p_del">-	node = drm_vma_offset_exact_lookup(dev-&gt;vma_offset_manager,</span>
<span class="p_del">-					   vma-&gt;vm_pgoff,</span>
<span class="p_del">-					   vma_pages(vma));</span>
<span class="p_del">-	if (!node) {</span>
<span class="p_del">-		mutex_unlock(&amp;dev-&gt;struct_mutex);</span>
<span class="p_del">-		DRM_ERROR(&quot;failed to find vma node.\n&quot;);</span>
<span class="p_del">-		return -EINVAL;</span>
<span class="p_del">-	} else if (!drm_vma_node_is_allowed(node, filp)) {</span>
<span class="p_del">-		mutex_unlock(&amp;dev-&gt;struct_mutex);</span>
<span class="p_del">-		return -EACCES;</span>
<span class="p_del">-	}</span>
<span class="p_add">+/* drm driver mmap file operations */</span>
<span class="p_add">+int rockchip_gem_mmap(struct file *filp, struct vm_area_struct *vma)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct drm_gem_object *obj;</span>
<span class="p_add">+	int ret;</span>
 
<span class="p_del">-	obj = container_of(node, struct drm_gem_object, vma_node);</span>
<span class="p_del">-	ret = rockchip_gem_mmap_buf(obj, vma);</span>
<span class="p_add">+	ret = drm_gem_mmap(filp, vma);</span>
<span class="p_add">+	if (ret)</span>
<span class="p_add">+		return ret;</span>
 
<span class="p_del">-	mutex_unlock(&amp;dev-&gt;struct_mutex);</span>
<span class="p_add">+	obj = vma-&gt;vm_private_data;</span>
 
<span class="p_del">-	return ret;</span>
<span class="p_add">+	return rockchip_drm_gem_object_mmap(obj, vma);</span>
 }
 
 struct rockchip_gem_object *
<span class="p_header">diff --git a/drivers/iio/adc/at91_adc.c b/drivers/iio/adc/at91_adc.c</span>
<span class="p_header">index ff61ae5..0047db4 100644</span>
<span class="p_header">--- a/drivers/iio/adc/at91_adc.c</span>
<span class="p_header">+++ b/drivers/iio/adc/at91_adc.c</span>
<span class="p_chunk">@@ -182,7 +182,7 @@</span> <span class="p_context"> struct at91_adc_caps {</span>
 	u8	ts_pen_detect_sensitivity;
 
 	/* startup time calculate function */
<span class="p_del">-	u32 (*calc_startup_ticks)(u8 startup_time, u32 adc_clk_khz);</span>
<span class="p_add">+	u32 (*calc_startup_ticks)(u32 startup_time, u32 adc_clk_khz);</span>
 
 	u8	num_channels;
 	struct at91_adc_reg_desc registers;
<span class="p_chunk">@@ -201,7 +201,7 @@</span> <span class="p_context"> struct at91_adc_state {</span>
 	u8			num_channels;
 	void __iomem		*reg_base;
 	struct at91_adc_reg_desc *registers;
<span class="p_del">-	u8			startup_time;</span>
<span class="p_add">+	u32			startup_time;</span>
 	u8			sample_hold_time;
 	bool			sleep_mode;
 	struct iio_trigger	**trig;
<span class="p_chunk">@@ -780,7 +780,7 @@</span> <span class="p_context"> ret:</span>
 	return ret;
 }
 
<span class="p_del">-static u32 calc_startup_ticks_9260(u8 startup_time, u32 adc_clk_khz)</span>
<span class="p_add">+static u32 calc_startup_ticks_9260(u32 startup_time, u32 adc_clk_khz)</span>
 {
 	/*
 	 * Number of ticks needed to cover the startup time of the ADC
<span class="p_chunk">@@ -791,7 +791,7 @@</span> <span class="p_context"> static u32 calc_startup_ticks_9260(u8 startup_time, u32 adc_clk_khz)</span>
 	return round_up((startup_time * adc_clk_khz / 1000) - 1, 8) / 8;
 }
 
<span class="p_del">-static u32 calc_startup_ticks_9x5(u8 startup_time, u32 adc_clk_khz)</span>
<span class="p_add">+static u32 calc_startup_ticks_9x5(u32 startup_time, u32 adc_clk_khz)</span>
 {
 	/*
 	 * For sama5d3x and at91sam9x5, the formula changes to:
<span class="p_header">diff --git a/drivers/iio/adc/rockchip_saradc.c b/drivers/iio/adc/rockchip_saradc.c</span>
<span class="p_header">index 8d4e019..9c311c1 100644</span>
<span class="p_header">--- a/drivers/iio/adc/rockchip_saradc.c</span>
<span class="p_header">+++ b/drivers/iio/adc/rockchip_saradc.c</span>
<span class="p_chunk">@@ -349,3 +349,7 @@</span> <span class="p_context"> static struct platform_driver rockchip_saradc_driver = {</span>
 };
 
 module_platform_driver(rockchip_saradc_driver);
<span class="p_add">+</span>
<span class="p_add">+MODULE_AUTHOR(&quot;Heiko Stuebner &lt;heiko@sntech.de&gt;&quot;);</span>
<span class="p_add">+MODULE_DESCRIPTION(&quot;Rockchip SARADC driver&quot;);</span>
<span class="p_add">+MODULE_LICENSE(&quot;GPL v2&quot;);</span>
<span class="p_header">diff --git a/drivers/iio/adc/twl4030-madc.c b/drivers/iio/adc/twl4030-madc.c</span>
<span class="p_header">index 94c5f05..4caecbe 100644</span>
<span class="p_header">--- a/drivers/iio/adc/twl4030-madc.c</span>
<span class="p_header">+++ b/drivers/iio/adc/twl4030-madc.c</span>
<span class="p_chunk">@@ -835,7 +835,8 @@</span> <span class="p_context"> static int twl4030_madc_probe(struct platform_device *pdev)</span>
 	irq = platform_get_irq(pdev, 0);
 	ret = devm_request_threaded_irq(&amp;pdev-&gt;dev, irq, NULL,
 				   twl4030_madc_threaded_irq_handler,
<span class="p_del">-				   IRQF_TRIGGER_RISING, &quot;twl4030_madc&quot;, madc);</span>
<span class="p_add">+				   IRQF_TRIGGER_RISING | IRQF_ONESHOT,</span>
<span class="p_add">+				   &quot;twl4030_madc&quot;, madc);</span>
 	if (ret) {
 		dev_err(&amp;pdev-&gt;dev, &quot;could not request irq\n&quot;);
 		goto err_i2c;
<span class="p_header">diff --git a/drivers/iio/dac/ad5624r_spi.c b/drivers/iio/dac/ad5624r_spi.c</span>
<span class="p_header">index 61bb9d4..e98428d 100644</span>
<span class="p_header">--- a/drivers/iio/dac/ad5624r_spi.c</span>
<span class="p_header">+++ b/drivers/iio/dac/ad5624r_spi.c</span>
<span class="p_chunk">@@ -22,7 +22,7 @@</span> <span class="p_context"></span>
 #include &quot;ad5624r.h&quot;
 
 static int ad5624r_spi_write(struct spi_device *spi,
<span class="p_del">-			     u8 cmd, u8 addr, u16 val, u8 len)</span>
<span class="p_add">+			     u8 cmd, u8 addr, u16 val, u8 shift)</span>
 {
 	u32 data;
 	u8 msg[3];
<span class="p_chunk">@@ -35,7 +35,7 @@</span> <span class="p_context"> static int ad5624r_spi_write(struct spi_device *spi,</span>
 	 * 14-, 12-bit input code followed by 0, 2, or 4 don&#39;t care bits,
 	 * for the AD5664R, AD5644R, and AD5624R, respectively.
 	 */
<span class="p_del">-	data = (0 &lt;&lt; 22) | (cmd &lt;&lt; 19) | (addr &lt;&lt; 16) | (val &lt;&lt; (16 - len));</span>
<span class="p_add">+	data = (0 &lt;&lt; 22) | (cmd &lt;&lt; 19) | (addr &lt;&lt; 16) | (val &lt;&lt; shift);</span>
 	msg[0] = data &gt;&gt; 16;
 	msg[1] = data &gt;&gt; 8;
 	msg[2] = data;
<span class="p_header">diff --git a/drivers/iio/imu/inv_mpu6050/inv_mpu_core.c b/drivers/iio/imu/inv_mpu6050/inv_mpu_core.c</span>
<span class="p_header">index b75519d..9b6bd13 100644</span>
<span class="p_header">--- a/drivers/iio/imu/inv_mpu6050/inv_mpu_core.c</span>
<span class="p_header">+++ b/drivers/iio/imu/inv_mpu6050/inv_mpu_core.c</span>
<span class="p_chunk">@@ -321,6 +321,24 @@</span> <span class="p_context"> error_read_raw:</span>
 	}
 }
 
<span class="p_add">+static int inv_write_raw_get_fmt(struct iio_dev *indio_dev,</span>
<span class="p_add">+				 struct iio_chan_spec const *chan, long mask)</span>
<span class="p_add">+{</span>
<span class="p_add">+	switch (mask) {</span>
<span class="p_add">+	case IIO_CHAN_INFO_SCALE:</span>
<span class="p_add">+		switch (chan-&gt;type) {</span>
<span class="p_add">+		case IIO_ANGL_VEL:</span>
<span class="p_add">+			return IIO_VAL_INT_PLUS_NANO;</span>
<span class="p_add">+		default:</span>
<span class="p_add">+			return IIO_VAL_INT_PLUS_MICRO;</span>
<span class="p_add">+		}</span>
<span class="p_add">+	default:</span>
<span class="p_add">+		return IIO_VAL_INT_PLUS_MICRO;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	return -EINVAL;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static int inv_mpu6050_write_fsr(struct inv_mpu6050_state *st, int fsr)
 {
 	int result;
<span class="p_chunk">@@ -603,6 +621,7 @@</span> <span class="p_context"> static const struct iio_info mpu_info = {</span>
 	.driver_module = THIS_MODULE,
 	.read_raw = &amp;inv_mpu6050_read_raw,
 	.write_raw = &amp;inv_mpu6050_write_raw,
<span class="p_add">+	.write_raw_get_fmt = &amp;inv_write_raw_get_fmt,</span>
 	.attrs = &amp;inv_attribute_group,
 	.validate_trigger = inv_mpu6050_validate_trigger,
 };
<span class="p_header">diff --git a/drivers/iio/light/tcs3414.c b/drivers/iio/light/tcs3414.c</span>
<span class="p_header">index a9e449b..e1feb31 100644</span>
<span class="p_header">--- a/drivers/iio/light/tcs3414.c</span>
<span class="p_header">+++ b/drivers/iio/light/tcs3414.c</span>
<span class="p_chunk">@@ -185,7 +185,7 @@</span> <span class="p_context"> static int tcs3414_write_raw(struct iio_dev *indio_dev,</span>
 		if (val != 0)
 			return -EINVAL;
 		for (i = 0; i &lt; ARRAY_SIZE(tcs3414_times); i++) {
<span class="p_del">-			if (val == tcs3414_times[i] * 1000) {</span>
<span class="p_add">+			if (val2 == tcs3414_times[i] * 1000) {</span>
 				data-&gt;timing &amp;= ~TCS3414_INTEG_MASK;
 				data-&gt;timing |= i;
 				return i2c_smbus_write_byte_data(
<span class="p_header">diff --git a/drivers/iio/temperature/tmp006.c b/drivers/iio/temperature/tmp006.c</span>
<span class="p_header">index 84a0789..7a80509 100644</span>
<span class="p_header">--- a/drivers/iio/temperature/tmp006.c</span>
<span class="p_header">+++ b/drivers/iio/temperature/tmp006.c</span>
<span class="p_chunk">@@ -132,6 +132,9 @@</span> <span class="p_context"> static int tmp006_write_raw(struct iio_dev *indio_dev,</span>
 	struct tmp006_data *data = iio_priv(indio_dev);
 	int i;
 
<span class="p_add">+	if (mask != IIO_CHAN_INFO_SAMP_FREQ)</span>
<span class="p_add">+		return -EINVAL;</span>
<span class="p_add">+</span>
 	for (i = 0; i &lt; ARRAY_SIZE(tmp006_freqs); i++)
 		if ((val == tmp006_freqs[i][0]) &amp;&amp;
 		    (val2 == tmp006_freqs[i][1])) {
<span class="p_header">diff --git a/drivers/md/dm-thin.c b/drivers/md/dm-thin.c</span>
<span class="p_header">index 159a113..d0a8ee4 100644</span>
<span class="p_header">--- a/drivers/md/dm-thin.c</span>
<span class="p_header">+++ b/drivers/md/dm-thin.c</span>
<span class="p_chunk">@@ -17,6 +17,7 @@</span> <span class="p_context"></span>
 #include &lt;linux/init.h&gt;
 #include &lt;linux/module.h&gt;
 #include &lt;linux/slab.h&gt;
<span class="p_add">+#include &lt;linux/vmalloc.h&gt;</span>
 #include &lt;linux/sort.h&gt;
 #include &lt;linux/rbtree.h&gt;
 
<span class="p_chunk">@@ -259,7 +260,7 @@</span> <span class="p_context"> struct pool {</span>
 	process_mapping_fn process_prepared_mapping;
 	process_mapping_fn process_prepared_discard;
 
<span class="p_del">-	struct dm_bio_prison_cell *cell_sort_array[CELL_SORT_ARRAY_SIZE];</span>
<span class="p_add">+	struct dm_bio_prison_cell **cell_sort_array;</span>
 };
 
 static enum pool_mode get_pool_mode(struct pool *pool);
<span class="p_chunk">@@ -2498,6 +2499,7 @@</span> <span class="p_context"> static void __pool_destroy(struct pool *pool)</span>
 {
 	__pool_table_remove(pool);
 
<span class="p_add">+	vfree(pool-&gt;cell_sort_array);</span>
 	if (dm_pool_metadata_close(pool-&gt;pmd) &lt; 0)
 		DMWARN(&quot;%s: dm_pool_metadata_close() failed.&quot;, __func__);
 
<span class="p_chunk">@@ -2610,6 +2612,13 @@</span> <span class="p_context"> static struct pool *pool_create(struct mapped_device *pool_md,</span>
 		goto bad_mapping_pool;
 	}
 
<span class="p_add">+	pool-&gt;cell_sort_array = vmalloc(sizeof(*pool-&gt;cell_sort_array) * CELL_SORT_ARRAY_SIZE);</span>
<span class="p_add">+	if (!pool-&gt;cell_sort_array) {</span>
<span class="p_add">+		*error = &quot;Error allocating cell sort array&quot;;</span>
<span class="p_add">+		err_p = ERR_PTR(-ENOMEM);</span>
<span class="p_add">+		goto bad_sort_array;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
 	pool-&gt;ref_count = 1;
 	pool-&gt;last_commit_jiffies = jiffies;
 	pool-&gt;pool_md = pool_md;
<span class="p_chunk">@@ -2618,6 +2627,8 @@</span> <span class="p_context"> static struct pool *pool_create(struct mapped_device *pool_md,</span>
 
 	return pool;
 
<span class="p_add">+bad_sort_array:</span>
<span class="p_add">+	mempool_destroy(pool-&gt;mapping_pool);</span>
 bad_mapping_pool:
 	dm_deferred_set_destroy(pool-&gt;all_io_ds);
 bad_all_io_ds:
<span class="p_header">diff --git a/drivers/md/persistent-data/dm-btree-remove.c b/drivers/md/persistent-data/dm-btree-remove.c</span>
<span class="p_header">index b88757c..a03178e 100644</span>
<span class="p_header">--- a/drivers/md/persistent-data/dm-btree-remove.c</span>
<span class="p_header">+++ b/drivers/md/persistent-data/dm-btree-remove.c</span>
<span class="p_chunk">@@ -309,8 +309,8 @@</span> <span class="p_context"> static void redistribute3(struct dm_btree_info *info, struct btree_node *parent,</span>
 
 		if (s &lt; 0 &amp;&amp; nr_center &lt; -s) {
 			/* not enough in central node */
<span class="p_del">-			shift(left, center, nr_center);</span>
<span class="p_del">-			s = nr_center - target;</span>
<span class="p_add">+			shift(left, center, -nr_center);</span>
<span class="p_add">+			s += nr_center;</span>
 			shift(left, right, s);
 			nr_right += s;
 		} else
<span class="p_chunk">@@ -323,7 +323,7 @@</span> <span class="p_context"> static void redistribute3(struct dm_btree_info *info, struct btree_node *parent,</span>
 		if (s &gt; 0 &amp;&amp; nr_center &lt; s) {
 			/* not enough in central node */
 			shift(center, right, nr_center);
<span class="p_del">-			s = target - nr_center;</span>
<span class="p_add">+			s -= nr_center;</span>
 			shift(left, right, s);
 			nr_left -= s;
 		} else
<span class="p_header">diff --git a/drivers/md/persistent-data/dm-btree.c b/drivers/md/persistent-data/dm-btree.c</span>
<span class="p_header">index 200ac12..fdd3793 100644</span>
<span class="p_header">--- a/drivers/md/persistent-data/dm-btree.c</span>
<span class="p_header">+++ b/drivers/md/persistent-data/dm-btree.c</span>
<span class="p_chunk">@@ -255,7 +255,7 @@</span> <span class="p_context"> int dm_btree_del(struct dm_btree_info *info, dm_block_t root)</span>
 	int r;
 	struct del_stack *s;
 
<span class="p_del">-	s = kmalloc(sizeof(*s), GFP_KERNEL);</span>
<span class="p_add">+	s = kmalloc(sizeof(*s), GFP_NOIO);</span>
 	if (!s)
 		return -ENOMEM;
 	s-&gt;info = info;
<span class="p_header">diff --git a/drivers/misc/cxl/context.c b/drivers/misc/cxl/context.c</span>
<span class="p_header">index d1b55fe..e4dc8cd 100644</span>
<span class="p_header">--- a/drivers/misc/cxl/context.c</span>
<span class="p_header">+++ b/drivers/misc/cxl/context.c</span>
<span class="p_chunk">@@ -113,11 +113,11 @@</span> <span class="p_context"> static int cxl_mmap_fault(struct vm_area_struct *vma, struct vm_fault *vmf)</span>
 
 	if (ctx-&gt;afu-&gt;current_mode == CXL_MODE_DEDICATED) {
 		area = ctx-&gt;afu-&gt;psn_phys;
<span class="p_del">-		if (offset &gt; ctx-&gt;afu-&gt;adapter-&gt;ps_size)</span>
<span class="p_add">+		if (offset &gt;= ctx-&gt;afu-&gt;adapter-&gt;ps_size)</span>
 			return VM_FAULT_SIGBUS;
 	} else {
 		area = ctx-&gt;psn_phys;
<span class="p_del">-		if (offset &gt; ctx-&gt;psn_size)</span>
<span class="p_add">+		if (offset &gt;= ctx-&gt;psn_size)</span>
 			return VM_FAULT_SIGBUS;
 	}
 
<span class="p_header">diff --git a/drivers/misc/cxl/main.c b/drivers/misc/cxl/main.c</span>
<span class="p_header">index 4cde9b6..619c7b4 100644</span>
<span class="p_header">--- a/drivers/misc/cxl/main.c</span>
<span class="p_header">+++ b/drivers/misc/cxl/main.c</span>
<span class="p_chunk">@@ -71,7 +71,7 @@</span> <span class="p_context"> static inline void cxl_slbia_core(struct mm_struct *mm)</span>
 		spin_lock(&amp;adapter-&gt;afu_list_lock);
 		for (slice = 0; slice &lt; adapter-&gt;slices; slice++) {
 			afu = adapter-&gt;afu[slice];
<span class="p_del">-			if (!afu-&gt;enabled)</span>
<span class="p_add">+			if (!afu || !afu-&gt;enabled)</span>
 				continue;
 			rcu_read_lock();
 			idr_for_each_entry(&amp;afu-&gt;contexts_idr, ctx, id)
<span class="p_header">diff --git a/drivers/net/can/c_can/c_can.c b/drivers/net/can/c_can/c_can.c</span>
<span class="p_header">index c672c4d..84540b0 100644</span>
<span class="p_header">--- a/drivers/net/can/c_can/c_can.c</span>
<span class="p_header">+++ b/drivers/net/can/c_can/c_can.c</span>
<span class="p_chunk">@@ -592,6 +592,7 @@</span> <span class="p_context"> static int c_can_start(struct net_device *dev)</span>
 {
 	struct c_can_priv *priv = netdev_priv(dev);
 	int err;
<span class="p_add">+	struct pinctrl *p;</span>
 
 	/* basic c_can configuration */
 	err = c_can_chip_config(dev);
<span class="p_chunk">@@ -604,8 +605,13 @@</span> <span class="p_context"> static int c_can_start(struct net_device *dev)</span>
 
 	priv-&gt;can.state = CAN_STATE_ERROR_ACTIVE;
 
<span class="p_del">-	/* activate pins */</span>
<span class="p_del">-	pinctrl_pm_select_default_state(dev-&gt;dev.parent);</span>
<span class="p_add">+	/* Attempt to use &quot;active&quot; if available else use &quot;default&quot; */</span>
<span class="p_add">+	p = pinctrl_get_select(priv-&gt;device, &quot;active&quot;);</span>
<span class="p_add">+	if (!IS_ERR(p))</span>
<span class="p_add">+		pinctrl_put(p);</span>
<span class="p_add">+	else</span>
<span class="p_add">+		pinctrl_pm_select_default_state(priv-&gt;device);</span>
<span class="p_add">+</span>
 	return 0;
 }
 
<span class="p_header">diff --git a/drivers/net/can/rcar_can.c b/drivers/net/can/rcar_can.c</span>
<span class="p_header">index 91cd48c..6acaeca 100644</span>
<span class="p_header">--- a/drivers/net/can/rcar_can.c</span>
<span class="p_header">+++ b/drivers/net/can/rcar_can.c</span>
<span class="p_chunk">@@ -757,8 +757,9 @@</span> <span class="p_context"> static int rcar_can_probe(struct platform_device *pdev)</span>
 	}
 
 	irq = platform_get_irq(pdev, 0);
<span class="p_del">-	if (!irq) {</span>
<span class="p_add">+	if (irq &lt; 0) {</span>
 		dev_err(&amp;pdev-&gt;dev, &quot;No IRQ resource\n&quot;);
<span class="p_add">+		err = irq;</span>
 		goto fail;
 	}
 
<span class="p_header">diff --git a/drivers/net/ethernet/ti/cpsw.c b/drivers/net/ethernet/ti/cpsw.c</span>
<span class="p_header">index a39131f..e22b0b8 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/ti/cpsw.c</span>
<span class="p_header">+++ b/drivers/net/ethernet/ti/cpsw.c</span>
<span class="p_chunk">@@ -511,9 +511,11 @@</span> <span class="p_context"> static const struct cpsw_stats cpsw_gstrings_stats[] = {</span>
 				(func)(slave++, ##arg);			\
 	} while (0)
 #define cpsw_get_slave_ndev(priv, __slave_no__)				\
<span class="p_del">-	(priv-&gt;slaves[__slave_no__].ndev)</span>
<span class="p_add">+	((__slave_no__ &lt; priv-&gt;data.slaves) ?				\</span>
<span class="p_add">+		priv-&gt;slaves[__slave_no__].ndev : NULL)</span>
 #define cpsw_get_slave_priv(priv, __slave_no__)				\
<span class="p_del">-	((priv-&gt;slaves[__slave_no__].ndev) ?				\</span>
<span class="p_add">+	(((__slave_no__ &lt; priv-&gt;data.slaves) &amp;&amp;				\</span>
<span class="p_add">+		(priv-&gt;slaves[__slave_no__].ndev)) ?			\</span>
 		netdev_priv(priv-&gt;slaves[__slave_no__].ndev) : NULL)	\
 
 #define cpsw_dual_emac_src_port_detect(status, priv, ndev, skb)		\
<span class="p_header">diff --git a/drivers/pnp/system.c b/drivers/pnp/system.c</span>
<span class="p_header">index 515f338..49c1720 100644</span>
<span class="p_header">--- a/drivers/pnp/system.c</span>
<span class="p_header">+++ b/drivers/pnp/system.c</span>
<span class="p_chunk">@@ -7,7 +7,6 @@</span> <span class="p_context"></span>
  *	Bjorn Helgaas &lt;bjorn.helgaas@hp.com&gt;
  */
 
<span class="p_del">-#include &lt;linux/acpi.h&gt;</span>
 #include &lt;linux/pnp.h&gt;
 #include &lt;linux/device.h&gt;
 #include &lt;linux/init.h&gt;
<span class="p_chunk">@@ -23,41 +22,25 @@</span> <span class="p_context"> static const struct pnp_device_id pnp_dev_table[] = {</span>
 	{&quot;&quot;, 0}
 };
 
<span class="p_del">-#ifdef CONFIG_ACPI</span>
<span class="p_del">-static bool __reserve_range(u64 start, unsigned int length, bool io, char *desc)</span>
<span class="p_del">-{</span>
<span class="p_del">-	u8 space_id = io ? ACPI_ADR_SPACE_SYSTEM_IO : ACPI_ADR_SPACE_SYSTEM_MEMORY;</span>
<span class="p_del">-	return !acpi_reserve_region(start, length, space_id, IORESOURCE_BUSY, desc);</span>
<span class="p_del">-}</span>
<span class="p_del">-#else</span>
<span class="p_del">-static bool __reserve_range(u64 start, unsigned int length, bool io, char *desc)</span>
<span class="p_del">-{</span>
<span class="p_del">-	struct resource *res;</span>
<span class="p_del">-</span>
<span class="p_del">-	res = io ? request_region(start, length, desc) :</span>
<span class="p_del">-		request_mem_region(start, length, desc);</span>
<span class="p_del">-	if (res) {</span>
<span class="p_del">-		res-&gt;flags &amp;= ~IORESOURCE_BUSY;</span>
<span class="p_del">-		return true;</span>
<span class="p_del">-	}</span>
<span class="p_del">-	return false;</span>
<span class="p_del">-}</span>
<span class="p_del">-#endif</span>
<span class="p_del">-</span>
 static void reserve_range(struct pnp_dev *dev, struct resource *r, int port)
 {
 	char *regionid;
 	const char *pnpid = dev_name(&amp;dev-&gt;dev);
 	resource_size_t start = r-&gt;start, end = r-&gt;end;
<span class="p_del">-	bool reserved;</span>
<span class="p_add">+	struct resource *res;</span>
 
 	regionid = kmalloc(16, GFP_KERNEL);
 	if (!regionid)
 		return;
 
 	snprintf(regionid, 16, &quot;pnp %s&quot;, pnpid);
<span class="p_del">-	reserved = __reserve_range(start, end - start + 1, !!port, regionid);</span>
<span class="p_del">-	if (!reserved)</span>
<span class="p_add">+	if (port)</span>
<span class="p_add">+		res = request_region(start, end - start + 1, regionid);</span>
<span class="p_add">+	else</span>
<span class="p_add">+		res = request_mem_region(start, end - start + 1, regionid);</span>
<span class="p_add">+	if (res)</span>
<span class="p_add">+		res-&gt;flags &amp;= ~IORESOURCE_BUSY;</span>
<span class="p_add">+	else</span>
 		kfree(regionid);
 
 	/*
<span class="p_chunk">@@ -66,7 +49,7 @@</span> <span class="p_context"> static void reserve_range(struct pnp_dev *dev, struct resource *r, int port)</span>
 	 * have double reservations.
 	 */
 	dev_info(&amp;dev-&gt;dev, &quot;%pR %s reserved\n&quot;, r,
<span class="p_del">-		 reserved ? &quot;has been&quot; : &quot;could not be&quot;);</span>
<span class="p_add">+		 res ? &quot;has been&quot; : &quot;could not be&quot;);</span>
 }
 
 static void reserve_resources_of_dev(struct pnp_dev *dev)
<span class="p_header">diff --git a/drivers/scsi/scsi_sysfs.c b/drivers/scsi/scsi_sysfs.c</span>
<span class="p_header">index 1ac38e7..9ad4116 100644</span>
<span class="p_header">--- a/drivers/scsi/scsi_sysfs.c</span>
<span class="p_header">+++ b/drivers/scsi/scsi_sysfs.c</span>
<span class="p_chunk">@@ -859,7 +859,7 @@</span> <span class="p_context"> sdev_store_queue_depth(struct device *dev, struct device_attribute *attr,</span>
 
 	depth = simple_strtoul(buf, NULL, 0);
 
<span class="p_del">-	if (depth &lt; 1 || depth &gt; sht-&gt;can_queue)</span>
<span class="p_add">+	if (depth &lt; 1 || depth &gt; sdev-&gt;host-&gt;can_queue)</span>
 		return -EINVAL;
 
 	retval = sht-&gt;change_queue_depth(sdev, depth);
<span class="p_header">diff --git a/drivers/scsi/sg.c b/drivers/scsi/sg.c</span>
<span class="p_header">index dbf8e77..9b6e7cb 100644</span>
<span class="p_header">--- a/drivers/scsi/sg.c</span>
<span class="p_header">+++ b/drivers/scsi/sg.c</span>
<span class="p_chunk">@@ -1759,6 +1759,9 @@</span> <span class="p_context"> sg_start_req(Sg_request *srp, unsigned char *cmd)</span>
 			md-&gt;from_user = 0;
 	}
 
<span class="p_add">+	if (unlikely(iov_count &gt; UIO_MAXIOV))</span>
<span class="p_add">+		return -EINVAL;</span>
<span class="p_add">+</span>
 	if (iov_count) {
 		int len, size = sizeof(struct sg_iovec) * iov_count;
 		struct iovec *iov;
<span class="p_header">diff --git a/drivers/scsi/st.c b/drivers/scsi/st.c</span>
<span class="p_header">index 128d3b5..69dd086 100644</span>
<span class="p_header">--- a/drivers/scsi/st.c</span>
<span class="p_header">+++ b/drivers/scsi/st.c</span>
<span class="p_chunk">@@ -1274,9 +1274,9 @@</span> <span class="p_context"> static int st_open(struct inode *inode, struct file *filp)</span>
 	spin_lock(&amp;st_use_lock);
 	STp-&gt;in_use = 0;
 	spin_unlock(&amp;st_use_lock);
<span class="p_del">-	scsi_tape_put(STp);</span>
 	if (resumed)
 		scsi_autopm_put_device(STp-&gt;device);
<span class="p_add">+	scsi_tape_put(STp);</span>
 	return retval;
 
 }
<span class="p_header">diff --git a/drivers/staging/vt6655/device_main.c b/drivers/staging/vt6655/device_main.c</span>
<span class="p_header">index fea0214..4968d8a 100644</span>
<span class="p_header">--- a/drivers/staging/vt6655/device_main.c</span>
<span class="p_header">+++ b/drivers/staging/vt6655/device_main.c</span>
<span class="p_chunk">@@ -1451,7 +1451,7 @@</span> <span class="p_context"> static void vnt_bss_info_changed(struct ieee80211_hw *hw,</span>
 
 	priv-&gt;current_aid = conf-&gt;aid;
 
<span class="p_del">-	if (changed &amp; BSS_CHANGED_BSSID) {</span>
<span class="p_add">+	if (changed &amp; BSS_CHANGED_BSSID &amp;&amp; conf-&gt;bssid) {</span>
 		unsigned long flags;
 
 		spin_lock_irqsave(&amp;priv-&gt;lock, flags);
<span class="p_header">diff --git a/drivers/staging/vt6656/main_usb.c b/drivers/staging/vt6656/main_usb.c</span>
<span class="p_header">index b95d5b1..30fbda6 100644</span>
<span class="p_header">--- a/drivers/staging/vt6656/main_usb.c</span>
<span class="p_header">+++ b/drivers/staging/vt6656/main_usb.c</span>
<span class="p_chunk">@@ -700,7 +700,7 @@</span> <span class="p_context"> static void vnt_bss_info_changed(struct ieee80211_hw *hw,</span>
 
 	priv-&gt;current_aid = conf-&gt;aid;
 
<span class="p_del">-	if (changed &amp; BSS_CHANGED_BSSID)</span>
<span class="p_add">+	if (changed &amp; BSS_CHANGED_BSSID &amp;&amp; conf-&gt;bssid)</span>
 		vnt_mac_set_bssid_addr(priv, (u8 *)conf-&gt;bssid);
 
 
<span class="p_header">diff --git a/drivers/usb/gadget/function/f_mass_storage.c b/drivers/usb/gadget/function/f_mass_storage.c</span>
<span class="p_header">index 811929c..eb80e97 100644</span>
<span class="p_header">--- a/drivers/usb/gadget/function/f_mass_storage.c</span>
<span class="p_header">+++ b/drivers/usb/gadget/function/f_mass_storage.c</span>
<span class="p_chunk">@@ -2819,7 +2819,7 @@</span> <span class="p_context"> int fsg_common_set_nluns(struct fsg_common *common, int nluns)</span>
 		return -EINVAL;
 	}
 
<span class="p_del">-	curlun = kcalloc(nluns, sizeof(*curlun), GFP_KERNEL);</span>
<span class="p_add">+	curlun = kcalloc(FSG_MAX_LUNS, sizeof(*curlun), GFP_KERNEL);</span>
 	if (unlikely(!curlun))
 		return -ENOMEM;
 
<span class="p_chunk">@@ -2829,8 +2829,6 @@</span> <span class="p_context"> int fsg_common_set_nluns(struct fsg_common *common, int nluns)</span>
 	common-&gt;luns = curlun;
 	common-&gt;nluns = nluns;
 
<span class="p_del">-	pr_info(&quot;Number of LUNs=%d\n&quot;, common-&gt;nluns);</span>
<span class="p_del">-</span>
 	return 0;
 }
 EXPORT_SYMBOL_GPL(fsg_common_set_nluns);
<span class="p_chunk">@@ -3604,14 +3602,26 @@</span> <span class="p_context"> static struct usb_function *fsg_alloc(struct usb_function_instance *fi)</span>
 	struct fsg_opts *opts = fsg_opts_from_func_inst(fi);
 	struct fsg_common *common = opts-&gt;common;
 	struct fsg_dev *fsg;
<span class="p_add">+	unsigned nluns, i;</span>
 
 	fsg = kzalloc(sizeof(*fsg), GFP_KERNEL);
 	if (unlikely(!fsg))
 		return ERR_PTR(-ENOMEM);
 
 	mutex_lock(&amp;opts-&gt;lock);
<span class="p_add">+	if (!opts-&gt;refcnt) {</span>
<span class="p_add">+		for (nluns = i = 0; i &lt; FSG_MAX_LUNS; ++i)</span>
<span class="p_add">+			if (common-&gt;luns[i])</span>
<span class="p_add">+				nluns = i + 1;</span>
<span class="p_add">+		if (!nluns)</span>
<span class="p_add">+			pr_warn(&quot;No LUNS defined, continuing anyway\n&quot;);</span>
<span class="p_add">+		else</span>
<span class="p_add">+			common-&gt;nluns = nluns;</span>
<span class="p_add">+		pr_info(&quot;Number of LUNs=%u\n&quot;, common-&gt;nluns);</span>
<span class="p_add">+	}</span>
 	opts-&gt;refcnt++;
 	mutex_unlock(&amp;opts-&gt;lock);
<span class="p_add">+</span>
 	fsg-&gt;function.name	= FSG_DRIVER_DESC;
 	fsg-&gt;function.bind	= fsg_bind;
 	fsg-&gt;function.unbind	= fsg_unbind;
<span class="p_header">diff --git a/drivers/usb/musb/musb_virthub.c b/drivers/usb/musb/musb_virthub.c</span>
<span class="p_header">index a9c47315..d91dac9 100644</span>
<span class="p_header">--- a/drivers/usb/musb/musb_virthub.c</span>
<span class="p_header">+++ b/drivers/usb/musb/musb_virthub.c</span>
<span class="p_chunk">@@ -274,9 +274,7 @@</span> <span class="p_context"> static int musb_has_gadget(struct musb *musb)</span>
 #ifdef CONFIG_USB_MUSB_HOST
 	return 1;
 #else
<span class="p_del">-	if (musb-&gt;port_mode == MUSB_PORT_MODE_HOST)</span>
<span class="p_del">-		return 1;</span>
<span class="p_del">-	return musb-&gt;g.dev.driver != NULL;</span>
<span class="p_add">+	return musb-&gt;port_mode == MUSB_PORT_MODE_HOST;</span>
 #endif
 }
 
<span class="p_header">diff --git a/drivers/usb/serial/cp210x.c b/drivers/usb/serial/cp210x.c</span>
<span class="p_header">index ffd739e..eac7cca 100644</span>
<span class="p_header">--- a/drivers/usb/serial/cp210x.c</span>
<span class="p_header">+++ b/drivers/usb/serial/cp210x.c</span>
<span class="p_chunk">@@ -187,6 +187,7 @@</span> <span class="p_context"> static const struct usb_device_id id_table[] = {</span>
 	{ USB_DEVICE(0x1FB9, 0x0602) }, /* Lake Shore Model 648 Magnet Power Supply */
 	{ USB_DEVICE(0x1FB9, 0x0700) }, /* Lake Shore Model 737 VSM Controller */
 	{ USB_DEVICE(0x1FB9, 0x0701) }, /* Lake Shore Model 776 Hall Matrix */
<span class="p_add">+	{ USB_DEVICE(0x2626, 0xEA60) }, /* Aruba Networks 7xxx USB Serial Console */</span>
 	{ USB_DEVICE(0x3195, 0xF190) }, /* Link Instruments MSO-19 */
 	{ USB_DEVICE(0x3195, 0xF280) }, /* Link Instruments MSO-28 */
 	{ USB_DEVICE(0x3195, 0xF281) }, /* Link Instruments MSO-28 */
<span class="p_header">diff --git a/drivers/usb/serial/option.c b/drivers/usb/serial/option.c</span>
<span class="p_header">index efdcee1..c8c4e50 100644</span>
<span class="p_header">--- a/drivers/usb/serial/option.c</span>
<span class="p_header">+++ b/drivers/usb/serial/option.c</span>
<span class="p_chunk">@@ -1773,6 +1773,7 @@</span> <span class="p_context"> static const struct usb_device_id option_ids[] = {</span>
 	{ USB_DEVICE_AND_INTERFACE_INFO(0x2001, 0x7d03, 0xff, 0x00, 0x00) },
 	{ USB_DEVICE_AND_INTERFACE_INFO(0x07d1, 0x3e01, 0xff, 0xff, 0xff) }, /* D-Link DWM-152/C1 */
 	{ USB_DEVICE_AND_INTERFACE_INFO(0x07d1, 0x3e02, 0xff, 0xff, 0xff) }, /* D-Link DWM-156/C1 */
<span class="p_add">+	{ USB_DEVICE_INTERFACE_CLASS(0x2020, 0x4000, 0xff) },                /* OLICARD300 - MT6225 */</span>
 	{ USB_DEVICE(INOVIA_VENDOR_ID, INOVIA_SEW858) },
 	{ USB_DEVICE(VIATELECOM_VENDOR_ID, VIATELECOM_PRODUCT_CDS7) },
 	{ } /* Terminating entry */
<span class="p_header">diff --git a/drivers/usb/serial/usb-serial.c b/drivers/usb/serial/usb-serial.c</span>
<span class="p_header">index 1984237..6fbfc8f 100644</span>
<span class="p_header">--- a/drivers/usb/serial/usb-serial.c</span>
<span class="p_header">+++ b/drivers/usb/serial/usb-serial.c</span>
<span class="p_chunk">@@ -1290,6 +1290,7 @@</span> <span class="p_context"> static void __exit usb_serial_exit(void)</span>
 	tty_unregister_driver(usb_serial_tty_driver);
 	put_tty_driver(usb_serial_tty_driver);
 	bus_unregister(&amp;usb_serial_bus_type);
<span class="p_add">+	idr_destroy(&amp;serial_minors);</span>
 }
 
 
<span class="p_header">diff --git a/fs/9p/vfs_inode.c b/fs/9p/vfs_inode.c</span>
<span class="p_header">index 9ee5343..2533005 100644</span>
<span class="p_header">--- a/fs/9p/vfs_inode.c</span>
<span class="p_header">+++ b/fs/9p/vfs_inode.c</span>
<span class="p_chunk">@@ -540,8 +540,7 @@</span> <span class="p_context"> static struct inode *v9fs_qid_iget(struct super_block *sb,</span>
 	unlock_new_inode(inode);
 	return inode;
 error:
<span class="p_del">-	unlock_new_inode(inode);</span>
<span class="p_del">-	iput(inode);</span>
<span class="p_add">+	iget_failed(inode);</span>
 	return ERR_PTR(retval);
 
 }
<span class="p_header">diff --git a/fs/9p/vfs_inode_dotl.c b/fs/9p/vfs_inode_dotl.c</span>
<span class="p_header">index 6054c16b..1254c7b 100644</span>
<span class="p_header">--- a/fs/9p/vfs_inode_dotl.c</span>
<span class="p_header">+++ b/fs/9p/vfs_inode_dotl.c</span>
<span class="p_chunk">@@ -149,8 +149,7 @@</span> <span class="p_context"> static struct inode *v9fs_qid_iget_dotl(struct super_block *sb,</span>
 	unlock_new_inode(inode);
 	return inode;
 error:
<span class="p_del">-	unlock_new_inode(inode);</span>
<span class="p_del">-	iput(inode);</span>
<span class="p_add">+	iget_failed(inode);</span>
 	return ERR_PTR(retval);
 
 }
<span class="p_header">diff --git a/fs/btrfs/inode-map.c b/fs/btrfs/inode-map.c</span>
<span class="p_header">index 74faea3a..66fd3ec 100644</span>
<span class="p_header">--- a/fs/btrfs/inode-map.c</span>
<span class="p_header">+++ b/fs/btrfs/inode-map.c</span>
<span class="p_chunk">@@ -246,6 +246,7 @@</span> <span class="p_context"> void btrfs_unpin_free_ino(struct btrfs_root *root)</span>
 {
 	struct btrfs_free_space_ctl *ctl = root-&gt;free_ino_ctl;
 	struct rb_root *rbroot = &amp;root-&gt;free_ino_pinned-&gt;free_space_offset;
<span class="p_add">+	spinlock_t *rbroot_lock = &amp;root-&gt;free_ino_pinned-&gt;tree_lock;</span>
 	struct btrfs_free_space *info;
 	struct rb_node *n;
 	u64 count;
<span class="p_chunk">@@ -254,24 +255,30 @@</span> <span class="p_context"> void btrfs_unpin_free_ino(struct btrfs_root *root)</span>
 		return;
 
 	while (1) {
<span class="p_add">+		bool add_to_ctl = true;</span>
<span class="p_add">+</span>
<span class="p_add">+		spin_lock(rbroot_lock);</span>
 		n = rb_first(rbroot);
<span class="p_del">-		if (!n)</span>
<span class="p_add">+		if (!n) {</span>
<span class="p_add">+			spin_unlock(rbroot_lock);</span>
 			break;
<span class="p_add">+		}</span>
 
 		info = rb_entry(n, struct btrfs_free_space, offset_index);
 		BUG_ON(info-&gt;bitmap); /* Logic error */
 
 		if (info-&gt;offset &gt; root-&gt;ino_cache_progress)
<span class="p_del">-			goto free;</span>
<span class="p_add">+			add_to_ctl = false;</span>
 		else if (info-&gt;offset + info-&gt;bytes &gt; root-&gt;ino_cache_progress)
 			count = root-&gt;ino_cache_progress - info-&gt;offset + 1;
 		else
 			count = info-&gt;bytes;
 
<span class="p_del">-		__btrfs_add_free_space(ctl, info-&gt;offset, count);</span>
<span class="p_del">-free:</span>
 		rb_erase(&amp;info-&gt;offset_index, rbroot);
<span class="p_del">-		kfree(info);</span>
<span class="p_add">+		spin_unlock(rbroot_lock);</span>
<span class="p_add">+		if (add_to_ctl)</span>
<span class="p_add">+			__btrfs_add_free_space(ctl, info-&gt;offset, count);</span>
<span class="p_add">+		kmem_cache_free(btrfs_free_space_cachep, info);</span>
 	}
 }
 
<span class="p_header">diff --git a/fs/btrfs/ioctl.c b/fs/btrfs/ioctl.c</span>
<span class="p_header">index 0dc23cd..d054504 100644</span>
<span class="p_header">--- a/fs/btrfs/ioctl.c</span>
<span class="p_header">+++ b/fs/btrfs/ioctl.c</span>
<span class="p_chunk">@@ -2931,7 +2931,7 @@</span> <span class="p_context"> out_unlock:</span>
 static long btrfs_ioctl_file_extent_same(struct file *file,
 			struct btrfs_ioctl_same_args __user *argp)
 {
<span class="p_del">-	struct btrfs_ioctl_same_args *same;</span>
<span class="p_add">+	struct btrfs_ioctl_same_args *same = NULL;</span>
 	struct btrfs_ioctl_same_extent_info *info;
 	struct inode *src = file_inode(file);
 	u64 off;
<span class="p_chunk">@@ -2961,6 +2961,7 @@</span> <span class="p_context"> static long btrfs_ioctl_file_extent_same(struct file *file,</span>
 
 	if (IS_ERR(same)) {
 		ret = PTR_ERR(same);
<span class="p_add">+		same = NULL;</span>
 		goto out;
 	}
 
<span class="p_chunk">@@ -3031,6 +3032,7 @@</span> <span class="p_context"> static long btrfs_ioctl_file_extent_same(struct file *file,</span>
 
 out:
 	mnt_drop_write_file(file);
<span class="p_add">+	kfree(same);</span>
 	return ret;
 }
 
<span class="p_chunk">@@ -3423,6 +3425,20 @@</span> <span class="p_context"> process_slot:</span>
 				u64 trim = 0;
 				u64 aligned_end = 0;
 
<span class="p_add">+				/*</span>
<span class="p_add">+				 * Don&#39;t copy an inline extent into an offset</span>
<span class="p_add">+				 * greater than zero. Having an inline extent</span>
<span class="p_add">+				 * at such an offset results in chaos as btrfs</span>
<span class="p_add">+				 * isn&#39;t prepared for such cases. Just skip</span>
<span class="p_add">+				 * this case for the same reasons as commented</span>
<span class="p_add">+				 * at btrfs_ioctl_clone().</span>
<span class="p_add">+				 */</span>
<span class="p_add">+				if (last_dest_end &gt; 0) {</span>
<span class="p_add">+					ret = -EOPNOTSUPP;</span>
<span class="p_add">+					btrfs_end_transaction(trans, root);</span>
<span class="p_add">+					goto out;</span>
<span class="p_add">+				}</span>
<span class="p_add">+</span>
 				if (off &gt; key.offset) {
 					skip = off - key.offset;
 					new_key.offset += skip;
<span class="p_header">diff --git a/fs/btrfs/transaction.c b/fs/btrfs/transaction.c</span>
<span class="p_header">index e88b59d..2818994 100644</span>
<span class="p_header">--- a/fs/btrfs/transaction.c</span>
<span class="p_header">+++ b/fs/btrfs/transaction.c</span>
<span class="p_chunk">@@ -750,7 +750,7 @@</span> <span class="p_context"> static int __btrfs_end_transaction(struct btrfs_trans_handle *trans,</span>
 
 	if (!list_empty(&amp;trans-&gt;ordered)) {
 		spin_lock(&amp;info-&gt;trans_lock);
<span class="p_del">-		list_splice(&amp;trans-&gt;ordered, &amp;cur_trans-&gt;pending_ordered);</span>
<span class="p_add">+		list_splice_init(&amp;trans-&gt;ordered, &amp;cur_trans-&gt;pending_ordered);</span>
 		spin_unlock(&amp;info-&gt;trans_lock);
 	}
 
<span class="p_chunk">@@ -1795,7 +1795,7 @@</span> <span class="p_context"> int btrfs_commit_transaction(struct btrfs_trans_handle *trans,</span>
 	}
 
 	spin_lock(&amp;root-&gt;fs_info-&gt;trans_lock);
<span class="p_del">-	list_splice(&amp;trans-&gt;ordered, &amp;cur_trans-&gt;pending_ordered);</span>
<span class="p_add">+	list_splice_init(&amp;trans-&gt;ordered, &amp;cur_trans-&gt;pending_ordered);</span>
 	if (cur_trans-&gt;state &gt;= TRANS_STATE_COMMIT_START) {
 		spin_unlock(&amp;root-&gt;fs_info-&gt;trans_lock);
 		atomic_inc(&amp;cur_trans-&gt;use_count);
<span class="p_header">diff --git a/fs/btrfs/tree-log.c b/fs/btrfs/tree-log.c</span>
<span class="p_header">index ef64903..7044953 100644</span>
<span class="p_header">--- a/fs/btrfs/tree-log.c</span>
<span class="p_header">+++ b/fs/btrfs/tree-log.c</span>
<span class="p_chunk">@@ -3983,6 +3983,7 @@</span> <span class="p_context"> static int btrfs_log_inode(struct btrfs_trans_handle *trans,</span>
 	u64 ino = btrfs_ino(inode);
 	struct extent_map_tree *em_tree = &amp;BTRFS_I(inode)-&gt;extent_tree;
 	u64 logged_isize = 0;
<span class="p_add">+	bool need_log_inode_item = true;</span>
 
 	path = btrfs_alloc_path();
 	if (!path)
<span class="p_chunk">@@ -4072,11 +4073,6 @@</span> <span class="p_context"> static int btrfs_log_inode(struct btrfs_trans_handle *trans,</span>
 		} else {
 			if (inode_only == LOG_INODE_ALL)
 				fast_search = true;
<span class="p_del">-			ret = log_inode_item(trans, log, dst_path, inode);</span>
<span class="p_del">-			if (ret) {</span>
<span class="p_del">-				err = ret;</span>
<span class="p_del">-				goto out_unlock;</span>
<span class="p_del">-			}</span>
 			goto log_extents;
 		}
 
<span class="p_chunk">@@ -4099,6 +4095,9 @@</span> <span class="p_context"> again:</span>
 		if (min_key.type &gt; max_key.type)
 			break;
 
<span class="p_add">+		if (min_key.type == BTRFS_INODE_ITEM_KEY)</span>
<span class="p_add">+			need_log_inode_item = false;</span>
<span class="p_add">+</span>
 		src = path-&gt;nodes[0];
 		if (ins_nr &amp;&amp; ins_start_slot + ins_nr == path-&gt;slots[0]) {
 			ins_nr++;
<span class="p_chunk">@@ -4169,6 +4168,11 @@</span> <span class="p_context"> next_slot:</span>
 log_extents:
 	btrfs_release_path(path);
 	btrfs_release_path(dst_path);
<span class="p_add">+	if (need_log_inode_item) {</span>
<span class="p_add">+		err = log_inode_item(trans, log, dst_path, inode);</span>
<span class="p_add">+		if (err)</span>
<span class="p_add">+			goto out_unlock;</span>
<span class="p_add">+	}</span>
 	if (fast_search) {
 		/*
 		 * Some ordered extents started by fsync might have completed
<span class="p_header">diff --git a/fs/dcache.c b/fs/dcache.c</span>
<span class="p_header">index 647bb88..c62a6d3 100644</span>
<span class="p_header">--- a/fs/dcache.c</span>
<span class="p_header">+++ b/fs/dcache.c</span>
<span class="p_chunk">@@ -629,6 +629,9 @@</span> <span class="p_context"> repeat:</span>
 	if (unlikely(d_unhashed(dentry)))
 		goto kill_it;
 
<span class="p_add">+	if (unlikely(dentry-&gt;d_flags &amp; DCACHE_DISCONNECTED))</span>
<span class="p_add">+		goto kill_it;</span>
<span class="p_add">+</span>
 	if (unlikely(dentry-&gt;d_flags &amp; DCACHE_OP_DELETE)) {
 		if (dentry-&gt;d_op-&gt;d_delete(dentry))
 			goto kill_it;
<span class="p_header">diff --git a/fs/ext4/extents.c b/fs/ext4/extents.c</span>
<span class="p_header">index 410841e..4252860 100644</span>
<span class="p_header">--- a/fs/ext4/extents.c</span>
<span class="p_header">+++ b/fs/ext4/extents.c</span>
<span class="p_chunk">@@ -503,7 +503,7 @@</span> <span class="p_context"> __read_extent_tree_block(const char *function, unsigned int line,</span>
 	struct buffer_head		*bh;
 	int				err;
 
<span class="p_del">-	bh = sb_getblk(inode-&gt;i_sb, pblk);</span>
<span class="p_add">+	bh = sb_getblk_gfp(inode-&gt;i_sb, pblk, __GFP_MOVABLE | GFP_NOFS);</span>
 	if (unlikely(!bh))
 		return ERR_PTR(-ENOMEM);
 
<span class="p_chunk">@@ -1088,7 +1088,7 @@</span> <span class="p_context"> static int ext4_ext_split(handle_t *handle, struct inode *inode,</span>
 		err = -EIO;
 		goto cleanup;
 	}
<span class="p_del">-	bh = sb_getblk(inode-&gt;i_sb, newblock);</span>
<span class="p_add">+	bh = sb_getblk_gfp(inode-&gt;i_sb, newblock, __GFP_MOVABLE | GFP_NOFS);</span>
 	if (unlikely(!bh)) {
 		err = -ENOMEM;
 		goto cleanup;
<span class="p_chunk">@@ -1282,7 +1282,7 @@</span> <span class="p_context"> static int ext4_ext_grow_indepth(handle_t *handle, struct inode *inode,</span>
 	if (newblock == 0)
 		return err;
 
<span class="p_del">-	bh = sb_getblk(inode-&gt;i_sb, newblock);</span>
<span class="p_add">+	bh = sb_getblk_gfp(inode-&gt;i_sb, newblock, __GFP_MOVABLE | GFP_NOFS);</span>
 	if (unlikely(!bh))
 		return -ENOMEM;
 	lock_buffer(bh);
<span class="p_header">diff --git a/fs/ext4/inode.c b/fs/ext4/inode.c</span>
<span class="p_header">index bd9967f..08063aed 100644</span>
<span class="p_header">--- a/fs/ext4/inode.c</span>
<span class="p_header">+++ b/fs/ext4/inode.c</span>
<span class="p_chunk">@@ -1224,7 +1224,7 @@</span> <span class="p_context"> static void ext4_da_page_release_reservation(struct page *page,</span>
 					     unsigned int offset,
 					     unsigned int length)
 {
<span class="p_del">-	int to_release = 0;</span>
<span class="p_add">+	int to_release = 0, contiguous_blks = 0;</span>
 	struct buffer_head *head, *bh;
 	unsigned int curr_off = 0;
 	struct inode *inode = page-&gt;mapping-&gt;host;
<span class="p_chunk">@@ -1245,14 +1245,23 @@</span> <span class="p_context"> static void ext4_da_page_release_reservation(struct page *page,</span>
 
 		if ((offset &lt;= curr_off) &amp;&amp; (buffer_delay(bh))) {
 			to_release++;
<span class="p_add">+			contiguous_blks++;</span>
 			clear_buffer_delay(bh);
<span class="p_add">+		} else if (contiguous_blks) {</span>
<span class="p_add">+			lblk = page-&gt;index &lt;&lt;</span>
<span class="p_add">+			       (PAGE_CACHE_SHIFT - inode-&gt;i_blkbits);</span>
<span class="p_add">+			lblk += (curr_off &gt;&gt; inode-&gt;i_blkbits) -</span>
<span class="p_add">+				contiguous_blks;</span>
<span class="p_add">+			ext4_es_remove_extent(inode, lblk, contiguous_blks);</span>
<span class="p_add">+			contiguous_blks = 0;</span>
 		}
 		curr_off = next_off;
 	} while ((bh = bh-&gt;b_this_page) != head);
 
<span class="p_del">-	if (to_release) {</span>
<span class="p_add">+	if (contiguous_blks) {</span>
 		lblk = page-&gt;index &lt;&lt; (PAGE_CACHE_SHIFT - inode-&gt;i_blkbits);
<span class="p_del">-		ext4_es_remove_extent(inode, lblk, to_release);</span>
<span class="p_add">+		lblk += (curr_off &gt;&gt; inode-&gt;i_blkbits) - contiguous_blks;</span>
<span class="p_add">+		ext4_es_remove_extent(inode, lblk, contiguous_blks);</span>
 	}
 
 	/* If we have released all the blocks belonging to a cluster, then we
<span class="p_header">diff --git a/fs/ext4/mballoc.c b/fs/ext4/mballoc.c</span>
<span class="p_header">index 8d1e602..4126048 100644</span>
<span class="p_header">--- a/fs/ext4/mballoc.c</span>
<span class="p_header">+++ b/fs/ext4/mballoc.c</span>
<span class="p_chunk">@@ -4800,18 +4800,12 @@</span> <span class="p_context"> do_more:</span>
 		/*
 		 * blocks being freed are metadata. these blocks shouldn&#39;t
 		 * be used until this transaction is committed
<span class="p_add">+		 *</span>
<span class="p_add">+		 * We use __GFP_NOFAIL because ext4_free_blocks() is not allowed</span>
<span class="p_add">+		 * to fail.</span>
 		 */
<span class="p_del">-	retry:</span>
<span class="p_del">-		new_entry = kmem_cache_alloc(ext4_free_data_cachep, GFP_NOFS);</span>
<span class="p_del">-		if (!new_entry) {</span>
<span class="p_del">-			/*</span>
<span class="p_del">-			 * We use a retry loop because</span>
<span class="p_del">-			 * ext4_free_blocks() is not allowed to fail.</span>
<span class="p_del">-			 */</span>
<span class="p_del">-			cond_resched();</span>
<span class="p_del">-			congestion_wait(BLK_RW_ASYNC, HZ/50);</span>
<span class="p_del">-			goto retry;</span>
<span class="p_del">-		}</span>
<span class="p_add">+		new_entry = kmem_cache_alloc(ext4_free_data_cachep,</span>
<span class="p_add">+				GFP_NOFS|__GFP_NOFAIL);</span>
 		new_entry-&gt;efd_start_cluster = bit;
 		new_entry-&gt;efd_group = block_group;
 		new_entry-&gt;efd_count = count_clusters;
<span class="p_header">diff --git a/fs/ext4/migrate.c b/fs/ext4/migrate.c</span>
<span class="p_header">index 3cb267a..bad30c6 100644</span>
<span class="p_header">--- a/fs/ext4/migrate.c</span>
<span class="p_header">+++ b/fs/ext4/migrate.c</span>
<span class="p_chunk">@@ -620,6 +620,7 @@</span> <span class="p_context"> int ext4_ind_migrate(struct inode *inode)</span>
 	struct ext4_inode_info		*ei = EXT4_I(inode);
 	struct ext4_extent		*ex;
 	unsigned int			i, len;
<span class="p_add">+	ext4_lblk_t			start, end;</span>
 	ext4_fsblk_t			blk;
 	handle_t			*handle;
 	int				ret;
<span class="p_chunk">@@ -633,6 +634,14 @@</span> <span class="p_context"> int ext4_ind_migrate(struct inode *inode)</span>
 				       EXT4_FEATURE_RO_COMPAT_BIGALLOC))
 		return -EOPNOTSUPP;
 
<span class="p_add">+	/*</span>
<span class="p_add">+	 * In order to get correct extent info, force all delayed allocation</span>
<span class="p_add">+	 * blocks to be allocated, otherwise delayed allocation blocks may not</span>
<span class="p_add">+	 * be reflected and bypass the checks on extent header.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	if (test_opt(inode-&gt;i_sb, DELALLOC))</span>
<span class="p_add">+		ext4_alloc_da_blocks(inode);</span>
<span class="p_add">+</span>
 	handle = ext4_journal_start(inode, EXT4_HT_MIGRATE, 1);
 	if (IS_ERR(handle))
 		return PTR_ERR(handle);
<span class="p_chunk">@@ -650,11 +659,13 @@</span> <span class="p_context"> int ext4_ind_migrate(struct inode *inode)</span>
 		goto errout;
 	}
 	if (eh-&gt;eh_entries == 0)
<span class="p_del">-		blk = len = 0;</span>
<span class="p_add">+		blk = len = start = end = 0;</span>
 	else {
 		len = le16_to_cpu(ex-&gt;ee_len);
 		blk = ext4_ext_pblock(ex);
<span class="p_del">-		if (len &gt; EXT4_NDIR_BLOCKS) {</span>
<span class="p_add">+		start = le32_to_cpu(ex-&gt;ee_block);</span>
<span class="p_add">+		end = start + len - 1;</span>
<span class="p_add">+		if (end &gt;= EXT4_NDIR_BLOCKS) {</span>
 			ret = -EOPNOTSUPP;
 			goto errout;
 		}
<span class="p_chunk">@@ -662,7 +673,7 @@</span> <span class="p_context"> int ext4_ind_migrate(struct inode *inode)</span>
 
 	ext4_clear_inode_flag(inode, EXT4_INODE_EXTENTS);
 	memset(ei-&gt;i_data, 0, sizeof(ei-&gt;i_data));
<span class="p_del">-	for (i=0; i &lt; len; i++)</span>
<span class="p_add">+	for (i = start; i &lt;= end; i++)</span>
 		ei-&gt;i_data[i] = cpu_to_le32(blk++);
 	ext4_mark_inode_dirty(handle, inode);
 errout:
<span class="p_header">diff --git a/fs/hpfs/super.c b/fs/hpfs/super.c</span>
<span class="p_header">index 7cd00d3..8685c65 100644</span>
<span class="p_header">--- a/fs/hpfs/super.c</span>
<span class="p_header">+++ b/fs/hpfs/super.c</span>
<span class="p_chunk">@@ -52,17 +52,20 @@</span> <span class="p_context"> static void unmark_dirty(struct super_block *s)</span>
 }
 
 /* Filesystem error... */
<span class="p_del">-static char err_buf[1024];</span>
<span class="p_del">-</span>
 void hpfs_error(struct super_block *s, const char *fmt, ...)
 {
<span class="p_add">+	struct va_format vaf;</span>
 	va_list args;
 
 	va_start(args, fmt);
<span class="p_del">-	vsnprintf(err_buf, sizeof(err_buf), fmt, args);</span>
<span class="p_add">+</span>
<span class="p_add">+	vaf.fmt = fmt;</span>
<span class="p_add">+	vaf.va = &amp;args;</span>
<span class="p_add">+</span>
<span class="p_add">+	pr_err(&quot;filesystem error: %pV&quot;, &amp;vaf);</span>
<span class="p_add">+</span>
 	va_end(args);
 
<span class="p_del">-	pr_err(&quot;filesystem error: %s&quot;, err_buf);</span>
 	if (!hpfs_sb(s)-&gt;sb_was_error) {
 		if (hpfs_sb(s)-&gt;sb_err == 2) {
 			pr_cont(&quot;; crashing the system because you wanted it\n&quot;);
<span class="p_chunk">@@ -424,11 +427,14 @@</span> <span class="p_context"> static int hpfs_remount_fs(struct super_block *s, int *flags, char *data)</span>
 	int o;
 	struct hpfs_sb_info *sbi = hpfs_sb(s);
 	char *new_opts = kstrdup(data, GFP_KERNEL);
<span class="p_del">-	</span>
<span class="p_add">+</span>
<span class="p_add">+	if (!new_opts)</span>
<span class="p_add">+		return -ENOMEM;</span>
<span class="p_add">+</span>
 	sync_filesystem(s);
 
 	*flags |= MS_NOATIME;
<span class="p_del">-	</span>
<span class="p_add">+</span>
 	hpfs_lock(s);
 	uid = sbi-&gt;sb_uid; gid = sbi-&gt;sb_gid;
 	umask = 0777 &amp; ~sbi-&gt;sb_mode;
<span class="p_header">diff --git a/include/linux/acpi.h b/include/linux/acpi.h</span>
<span class="p_header">index 2799d36..0e73e05 100644</span>
<span class="p_header">--- a/include/linux/acpi.h</span>
<span class="p_header">+++ b/include/linux/acpi.h</span>
<span class="p_chunk">@@ -312,9 +312,6 @@</span> <span class="p_context"> int acpi_check_region(resource_size_t start, resource_size_t n,</span>
 
 int acpi_resources_are_enforced(void);
 
<span class="p_del">-int acpi_reserve_region(u64 start, unsigned int length, u8 space_id,</span>
<span class="p_del">-			unsigned long flags, char *desc);</span>
<span class="p_del">-</span>
 #ifdef CONFIG_HIBERNATION
 void __init acpi_no_s4_hw_signature(void);
 #endif
<span class="p_chunk">@@ -505,13 +502,6 @@</span> <span class="p_context"> static inline int acpi_check_region(resource_size_t start, resource_size_t n,</span>
 	return 0;
 }
 
<span class="p_del">-static inline int acpi_reserve_region(u64 start, unsigned int length,</span>
<span class="p_del">-				      u8 space_id, unsigned long flags,</span>
<span class="p_del">-				      char *desc)</span>
<span class="p_del">-{</span>
<span class="p_del">-	return -ENXIO;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
 struct acpi_table_header;
 static inline int acpi_table_parse(char *id,
 				int (*handler)(struct acpi_table_header *))
<span class="p_header">diff --git a/include/linux/buffer_head.h b/include/linux/buffer_head.h</span>
<span class="p_header">index 73b4522..e6797de 100644</span>
<span class="p_header">--- a/include/linux/buffer_head.h</span>
<span class="p_header">+++ b/include/linux/buffer_head.h</span>
<span class="p_chunk">@@ -317,6 +317,13 @@</span> <span class="p_context"> sb_getblk(struct super_block *sb, sector_t block)</span>
 	return __getblk_gfp(sb-&gt;s_bdev, block, sb-&gt;s_blocksize, __GFP_MOVABLE);
 }
 
<span class="p_add">+</span>
<span class="p_add">+static inline struct buffer_head *</span>
<span class="p_add">+sb_getblk_gfp(struct super_block *sb, sector_t block, gfp_t gfp)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return __getblk_gfp(sb-&gt;s_bdev, block, sb-&gt;s_blocksize, gfp);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static inline struct buffer_head *
 sb_find_get_block(struct super_block *sb, sector_t block)
 {
<span class="p_header">diff --git a/kernel/irq/resend.c b/kernel/irq/resend.c</span>
<span class="p_header">index 9065107..7a5237a 100644</span>
<span class="p_header">--- a/kernel/irq/resend.c</span>
<span class="p_header">+++ b/kernel/irq/resend.c</span>
<span class="p_chunk">@@ -75,13 +75,21 @@</span> <span class="p_context"> void check_irq_resend(struct irq_desc *desc, unsigned int irq)</span>
 		    !desc-&gt;irq_data.chip-&gt;irq_retrigger(&amp;desc-&gt;irq_data)) {
 #ifdef CONFIG_HARDIRQS_SW_RESEND
 			/*
<span class="p_del">-			 * If the interrupt has a parent irq and runs</span>
<span class="p_del">-			 * in the thread context of the parent irq,</span>
<span class="p_del">-			 * retrigger the parent.</span>
<span class="p_add">+			 * If the interrupt is running in the thread</span>
<span class="p_add">+			 * context of the parent irq we need to be</span>
<span class="p_add">+			 * careful, because we cannot trigger it</span>
<span class="p_add">+			 * directly.</span>
 			 */
<span class="p_del">-			if (desc-&gt;parent_irq &amp;&amp;</span>
<span class="p_del">-			    irq_settings_is_nested_thread(desc))</span>
<span class="p_add">+			if (irq_settings_is_nested_thread(desc)) {</span>
<span class="p_add">+				/*</span>
<span class="p_add">+				 * If the parent_irq is valid, we</span>
<span class="p_add">+				 * retrigger the parent, otherwise we</span>
<span class="p_add">+				 * do nothing.</span>
<span class="p_add">+				 */</span>
<span class="p_add">+				if (!desc-&gt;parent_irq)</span>
<span class="p_add">+					return;</span>
 				irq = desc-&gt;parent_irq;
<span class="p_add">+			}</span>
 			/* Set it pending and activate the softirq: */
 			set_bit(irq, irqs_resend);
 			tasklet_schedule(&amp;resend_tasklet);
<span class="p_header">diff --git a/kernel/trace/trace.h b/kernel/trace/trace.h</span>
<span class="p_header">index 8de48ba..fb06e33 100644</span>
<span class="p_header">--- a/kernel/trace/trace.h</span>
<span class="p_header">+++ b/kernel/trace/trace.h</span>
<span class="p_chunk">@@ -443,6 +443,7 @@</span> <span class="p_context"> enum {</span>
 
 	TRACE_CONTROL_BIT,
 
<span class="p_add">+	TRACE_BRANCH_BIT,</span>
 /*
  * Abuse of the trace_recursion.
  * As we need a way to maintain state if we are tracing the function
<span class="p_header">diff --git a/kernel/trace/trace_branch.c b/kernel/trace/trace_branch.c</span>
<span class="p_header">index 7d6e2af..2c05718 100644</span>
<span class="p_header">--- a/kernel/trace/trace_branch.c</span>
<span class="p_header">+++ b/kernel/trace/trace_branch.c</span>
<span class="p_chunk">@@ -37,9 +37,12 @@</span> <span class="p_context"> probe_likely_condition(struct ftrace_branch_data *f, int val, int expect)</span>
 	struct trace_branch *entry;
 	struct ring_buffer *buffer;
 	unsigned long flags;
<span class="p_del">-	int cpu, pc;</span>
<span class="p_add">+	int pc;</span>
 	const char *p;
 
<span class="p_add">+	if (current-&gt;trace_recursion &amp; TRACE_BRANCH_BIT)</span>
<span class="p_add">+		return;</span>
<span class="p_add">+</span>
 	/*
 	 * I would love to save just the ftrace_likely_data pointer, but
 	 * this code can also be used by modules. Ugly things can happen
<span class="p_chunk">@@ -50,10 +53,10 @@</span> <span class="p_context"> probe_likely_condition(struct ftrace_branch_data *f, int val, int expect)</span>
 	if (unlikely(!tr))
 		return;
 
<span class="p_del">-	local_irq_save(flags);</span>
<span class="p_del">-	cpu = raw_smp_processor_id();</span>
<span class="p_del">-	data = per_cpu_ptr(tr-&gt;trace_buffer.data, cpu);</span>
<span class="p_del">-	if (atomic_inc_return(&amp;data-&gt;disabled) != 1)</span>
<span class="p_add">+	raw_local_irq_save(flags);</span>
<span class="p_add">+	current-&gt;trace_recursion |= TRACE_BRANCH_BIT;</span>
<span class="p_add">+	data = this_cpu_ptr(tr-&gt;trace_buffer.data);</span>
<span class="p_add">+	if (atomic_read(&amp;data-&gt;disabled))</span>
 		goto out;
 
 	pc = preempt_count();
<span class="p_chunk">@@ -82,8 +85,8 @@</span> <span class="p_context"> probe_likely_condition(struct ftrace_branch_data *f, int val, int expect)</span>
 		__buffer_unlock_commit(buffer, event);
 
  out:
<span class="p_del">-	atomic_dec(&amp;data-&gt;disabled);</span>
<span class="p_del">-	local_irq_restore(flags);</span>
<span class="p_add">+	current-&gt;trace_recursion &amp;= ~TRACE_BRANCH_BIT;</span>
<span class="p_add">+	raw_local_irq_restore(flags);</span>
 }
 
 static inline
<span class="p_header">diff --git a/lib/dma-debug.c b/lib/dma-debug.c</span>
<span class="p_header">index 9722bd2..d75c2f4 100644</span>
<span class="p_header">--- a/lib/dma-debug.c</span>
<span class="p_header">+++ b/lib/dma-debug.c</span>
<span class="p_chunk">@@ -574,6 +574,9 @@</span> <span class="p_context"> void debug_dma_assert_idle(struct page *page)</span>
 	unsigned long flags;
 	phys_addr_t cln;
 
<span class="p_add">+	if (dma_debug_disabled())</span>
<span class="p_add">+		return;</span>
<span class="p_add">+</span>
 	if (!page)
 		return;
 
<span class="p_header">diff --git a/mm/memory.c b/mm/memory.c</span>
<span class="p_header">index 6aa7822..f5d0e3d 100644</span>
<span class="p_header">--- a/mm/memory.c</span>
<span class="p_header">+++ b/mm/memory.c</span>
<span class="p_chunk">@@ -2630,6 +2630,10 @@</span> <span class="p_context"> static int do_anonymous_page(struct mm_struct *mm, struct vm_area_struct *vma,</span>
 
 	pte_unmap(page_table);
 
<span class="p_add">+	/* File mapping without -&gt;vm_ops ? */</span>
<span class="p_add">+	if (vma-&gt;vm_flags &amp; VM_SHARED)</span>
<span class="p_add">+		return VM_FAULT_SIGBUS;</span>
<span class="p_add">+</span>
 	/* Check if we need to add a guard page to the stack */
 	if (check_stack_guard_page(vma, address) &lt; 0)
 		return VM_FAULT_SIGSEGV;
<span class="p_chunk">@@ -3040,6 +3044,9 @@</span> <span class="p_context"> static int do_linear_fault(struct mm_struct *mm, struct vm_area_struct *vma,</span>
 			- vma-&gt;vm_start) &gt;&gt; PAGE_SHIFT) + vma-&gt;vm_pgoff;
 
 	pte_unmap(page_table);
<span class="p_add">+	/* The VMA was not fully populated on mmap() or missing VM_DONTEXPAND */</span>
<span class="p_add">+	if (!vma-&gt;vm_ops-&gt;fault)</span>
<span class="p_add">+		return VM_FAULT_SIGBUS;</span>
 	if (!(flags &amp; FAULT_FLAG_WRITE))
 		return do_read_fault(mm, vma, address, pmd, pgoff, flags,
 				orig_pte);
<span class="p_chunk">@@ -3214,13 +3221,12 @@</span> <span class="p_context"> static int handle_pte_fault(struct mm_struct *mm,</span>
 	barrier();
 	if (!pte_present(entry)) {
 		if (pte_none(entry)) {
<span class="p_del">-			if (vma-&gt;vm_ops) {</span>
<span class="p_del">-				if (likely(vma-&gt;vm_ops-&gt;fault))</span>
<span class="p_del">-					return do_linear_fault(mm, vma, address,</span>
<span class="p_del">-						pte, pmd, flags, entry);</span>
<span class="p_del">-			}</span>
<span class="p_del">-			return do_anonymous_page(mm, vma, address,</span>
<span class="p_del">-						 pte, pmd, flags);</span>
<span class="p_add">+			if (vma-&gt;vm_ops)</span>
<span class="p_add">+				return do_linear_fault(mm, vma, address, pte,</span>
<span class="p_add">+						pmd, flags, entry);</span>
<span class="p_add">+</span>
<span class="p_add">+			return do_anonymous_page(mm, vma, address, pte, pmd,</span>
<span class="p_add">+					flags);</span>
 		}
 		if (pte_file(entry))
 			return do_nonlinear_fault(mm, vma, address,
<span class="p_header">diff --git a/net/bridge/br_mdb.c b/net/bridge/br_mdb.c</span>
<span class="p_header">index d8b1833..4754f2d 100644</span>
<span class="p_header">--- a/net/bridge/br_mdb.c</span>
<span class="p_header">+++ b/net/bridge/br_mdb.c</span>
<span class="p_chunk">@@ -322,6 +322,7 @@</span> <span class="p_context"> static int br_mdb_add_group(struct net_bridge *br, struct net_bridge_port *port,</span>
 	struct net_bridge_port_group *p;
 	struct net_bridge_port_group __rcu **pp;
 	struct net_bridge_mdb_htable *mdb;
<span class="p_add">+	unsigned long now = jiffies;</span>
 	int err;
 
 	mdb = mlock_dereference(br-&gt;mdb, br);
<span class="p_chunk">@@ -346,6 +347,8 @@</span> <span class="p_context"> static int br_mdb_add_group(struct net_bridge *br, struct net_bridge_port *port,</span>
 	if (unlikely(!p))
 		return -ENOMEM;
 	rcu_assign_pointer(*pp, p);
<span class="p_add">+	if (state == MDB_TEMPORARY)</span>
<span class="p_add">+		mod_timer(&amp;p-&gt;timer, now + br-&gt;multicast_membership_interval);</span>
 
 	br_mdb_notify(br-&gt;dev, port, group, RTM_NEWMDB);
 	return 0;
<span class="p_chunk">@@ -370,6 +373,7 @@</span> <span class="p_context"> static int __br_mdb_add(struct net *net, struct net_bridge *br,</span>
 	if (!p || p-&gt;br != br || p-&gt;state == BR_STATE_DISABLED)
 		return -EINVAL;
 
<span class="p_add">+	memset(&amp;ip, 0, sizeof(ip));</span>
 	ip.proto = entry-&gt;addr.proto;
 	if (ip.proto == htons(ETH_P_IP))
 		ip.u.ip4 = entry-&gt;addr.u.ip4;
<span class="p_chunk">@@ -416,6 +420,7 @@</span> <span class="p_context"> static int __br_mdb_del(struct net_bridge *br, struct br_mdb_entry *entry)</span>
 	if (!netif_running(br-&gt;dev) || br-&gt;multicast_disabled)
 		return -EINVAL;
 
<span class="p_add">+	memset(&amp;ip, 0, sizeof(ip));</span>
 	ip.proto = entry-&gt;addr.proto;
 	if (ip.proto == htons(ETH_P_IP)) {
 		if (timer_pending(&amp;br-&gt;ip4_other_query.timer))
<span class="p_header">diff --git a/net/core/dev.c b/net/core/dev.c</span>
<span class="p_header">index 307e744f..9c14e87 100644</span>
<span class="p_header">--- a/net/core/dev.c</span>
<span class="p_header">+++ b/net/core/dev.c</span>
<span class="p_chunk">@@ -3277,6 +3277,8 @@</span> <span class="p_context"> static int enqueue_to_backlog(struct sk_buff *skb, int cpu,</span>
 	local_irq_save(flags);
 
 	rps_lock(sd);
<span class="p_add">+	if (!netif_running(skb-&gt;dev))</span>
<span class="p_add">+		goto drop;</span>
 	qlen = skb_queue_len(&amp;sd-&gt;input_pkt_queue);
 	if (qlen &lt;= netdev_max_backlog &amp;&amp; !skb_flow_limit(skb, qlen)) {
 		if (qlen) {
<span class="p_chunk">@@ -3298,6 +3300,7 @@</span> <span class="p_context"> enqueue:</span>
 		goto enqueue;
 	}
 
<span class="p_add">+drop:</span>
 	sd-&gt;dropped++;
 	rps_unlock(sd);
 
<span class="p_chunk">@@ -3606,8 +3609,6 @@</span> <span class="p_context"> static int __netif_receive_skb_core(struct sk_buff *skb, bool pfmemalloc)</span>
 
 	pt_prev = NULL;
 
<span class="p_del">-	rcu_read_lock();</span>
<span class="p_del">-</span>
 another_round:
 	skb-&gt;skb_iif = skb-&gt;dev-&gt;ifindex;
 
<span class="p_chunk">@@ -3617,7 +3618,7 @@</span> <span class="p_context"> another_round:</span>
 	    skb-&gt;protocol == cpu_to_be16(ETH_P_8021AD)) {
 		skb = skb_vlan_untag(skb);
 		if (unlikely(!skb))
<span class="p_del">-			goto unlock;</span>
<span class="p_add">+			goto out;</span>
 	}
 
 #ifdef CONFIG_NET_CLS_ACT
<span class="p_chunk">@@ -3642,7 +3643,7 @@</span> <span class="p_context"> skip_taps:</span>
 #ifdef CONFIG_NET_CLS_ACT
 	skb = handle_ing(skb, &amp;pt_prev, &amp;ret, orig_dev);
 	if (!skb)
<span class="p_del">-		goto unlock;</span>
<span class="p_add">+		goto out;</span>
 ncls:
 #endif
 
<span class="p_chunk">@@ -3657,7 +3658,7 @@</span> <span class="p_context"> ncls:</span>
 		if (vlan_do_receive(&amp;skb))
 			goto another_round;
 		else if (unlikely(!skb))
<span class="p_del">-			goto unlock;</span>
<span class="p_add">+			goto out;</span>
 	}
 
 	rx_handler = rcu_dereference(skb-&gt;dev-&gt;rx_handler);
<span class="p_chunk">@@ -3669,7 +3670,7 @@</span> <span class="p_context"> ncls:</span>
 		switch (rx_handler(&amp;skb)) {
 		case RX_HANDLER_CONSUMED:
 			ret = NET_RX_SUCCESS;
<span class="p_del">-			goto unlock;</span>
<span class="p_add">+			goto out;</span>
 		case RX_HANDLER_ANOTHER:
 			goto another_round;
 		case RX_HANDLER_EXACT:
<span class="p_chunk">@@ -3721,8 +3722,7 @@</span> <span class="p_context"> drop:</span>
 		ret = NET_RX_DROP;
 	}
 
<span class="p_del">-unlock:</span>
<span class="p_del">-	rcu_read_unlock();</span>
<span class="p_add">+out:</span>
 	return ret;
 }
 
<span class="p_chunk">@@ -3753,29 +3753,30 @@</span> <span class="p_context"> static int __netif_receive_skb(struct sk_buff *skb)</span>
 
 static int netif_receive_skb_internal(struct sk_buff *skb)
 {
<span class="p_add">+	int ret;</span>
<span class="p_add">+</span>
 	net_timestamp_check(netdev_tstamp_prequeue, skb);
 
 	if (skb_defer_rx_timestamp(skb))
 		return NET_RX_SUCCESS;
 
<span class="p_add">+	rcu_read_lock();</span>
<span class="p_add">+</span>
 #ifdef CONFIG_RPS
 	if (static_key_false(&amp;rps_needed)) {
 		struct rps_dev_flow voidflow, *rflow = &amp;voidflow;
<span class="p_del">-		int cpu, ret;</span>
<span class="p_del">-</span>
<span class="p_del">-		rcu_read_lock();</span>
<span class="p_del">-</span>
<span class="p_del">-		cpu = get_rps_cpu(skb-&gt;dev, skb, &amp;rflow);</span>
<span class="p_add">+		int cpu = get_rps_cpu(skb-&gt;dev, skb, &amp;rflow);</span>
 
 		if (cpu &gt;= 0) {
 			ret = enqueue_to_backlog(skb, cpu, &amp;rflow-&gt;last_qtail);
 			rcu_read_unlock();
 			return ret;
 		}
<span class="p_del">-		rcu_read_unlock();</span>
 	}
 #endif
<span class="p_del">-	return __netif_receive_skb(skb);</span>
<span class="p_add">+	ret = __netif_receive_skb(skb);</span>
<span class="p_add">+	rcu_read_unlock();</span>
<span class="p_add">+	return ret;</span>
 }
 
 /**
<span class="p_chunk">@@ -4319,8 +4320,10 @@</span> <span class="p_context"> static int process_backlog(struct napi_struct *napi, int quota)</span>
 		struct sk_buff *skb;
 
 		while ((skb = __skb_dequeue(&amp;sd-&gt;process_queue))) {
<span class="p_add">+			rcu_read_lock();</span>
 			local_irq_enable();
 			__netif_receive_skb(skb);
<span class="p_add">+			rcu_read_unlock();</span>
 			local_irq_disable();
 			input_queue_head_incr(sd);
 			if (++work &gt;= quota) {
<span class="p_chunk">@@ -5918,6 +5921,7 @@</span> <span class="p_context"> static void rollback_registered_many(struct list_head *head)</span>
 		unlist_netdevice(dev);
 
 		dev-&gt;reg_state = NETREG_UNREGISTERING;
<span class="p_add">+		on_each_cpu(flush_backlog, dev, 1);</span>
 	}
 
 	synchronize_net();
<span class="p_chunk">@@ -6185,7 +6189,8 @@</span> <span class="p_context"> static int netif_alloc_netdev_queues(struct net_device *dev)</span>
 	struct netdev_queue *tx;
 	size_t sz = count * sizeof(*tx);
 
<span class="p_del">-	BUG_ON(count &lt; 1 || count &gt; 0xffff);</span>
<span class="p_add">+	if (count &lt; 1 || count &gt; 0xffff)</span>
<span class="p_add">+		return -EINVAL;</span>
 
 	tx = kzalloc(sz, GFP_KERNEL | __GFP_NOWARN | __GFP_REPEAT);
 	if (!tx) {
<span class="p_chunk">@@ -6543,8 +6548,6 @@</span> <span class="p_context"> void netdev_run_todo(void)</span>
 
 		dev-&gt;reg_state = NETREG_UNREGISTERED;
 
<span class="p_del">-		on_each_cpu(flush_backlog, dev, 1);</span>
<span class="p_del">-</span>
 		netdev_wait_allrefs(dev);
 
 		/* paranoia */
<span class="p_header">diff --git a/net/dsa/dsa.c b/net/dsa/dsa.c</span>
<span class="p_header">index 3731714..43bc5c7 100644</span>
<span class="p_header">--- a/net/dsa/dsa.c</span>
<span class="p_header">+++ b/net/dsa/dsa.c</span>
<span class="p_chunk">@@ -627,7 +627,7 @@</span> <span class="p_context"> static int dsa_of_probe(struct platform_device *pdev)</span>
 			continue;
 
 		cd-&gt;sw_addr = be32_to_cpup(sw_addr);
<span class="p_del">-		if (cd-&gt;sw_addr &gt; PHY_MAX_ADDR)</span>
<span class="p_add">+		if (cd-&gt;sw_addr &gt;= PHY_MAX_ADDR)</span>
 			continue;
 
 		if (!of_property_read_u32(np, &quot;eeprom-length&quot;, &amp;eeprom_len))
<span class="p_chunk">@@ -639,6 +639,8 @@</span> <span class="p_context"> static int dsa_of_probe(struct platform_device *pdev)</span>
 				continue;
 
 			port_index = be32_to_cpup(port_reg);
<span class="p_add">+			if (port_index &gt;= DSA_MAX_PORTS)</span>
<span class="p_add">+				break;</span>
 
 			port_name = of_get_property(port, &quot;label&quot;, NULL);
 			if (!port_name)
<span class="p_chunk">@@ -663,8 +665,6 @@</span> <span class="p_context"> static int dsa_of_probe(struct platform_device *pdev)</span>
 					goto out_free_chip;
 			}
 
<span class="p_del">-			if (port_index == DSA_MAX_PORTS)</span>
<span class="p_del">-				break;</span>
 		}
 	}
 
<span class="p_header">diff --git a/net/ieee802154/dgram.c b/net/ieee802154/dgram.c</span>
<span class="p_header">index d1930b7..6101194 100644</span>
<span class="p_header">--- a/net/ieee802154/dgram.c</span>
<span class="p_header">+++ b/net/ieee802154/dgram.c</span>
<span class="p_chunk">@@ -326,6 +326,12 @@</span> <span class="p_context"> static int dgram_recvmsg(struct kiocb *iocb, struct sock *sk,</span>
 	sock_recv_ts_and_drops(msg, sk, skb);
 
 	if (saddr) {
<span class="p_add">+		/* Clear the implicit padding in struct sockaddr_ieee802154</span>
<span class="p_add">+		 * (16 bits between &#39;family&#39; and &#39;addr&#39;) and in struct</span>
<span class="p_add">+		 * ieee802154_addr_sa (16 bits at the end of the structure).</span>
<span class="p_add">+		 */</span>
<span class="p_add">+		memset(saddr, 0, sizeof(*saddr));</span>
<span class="p_add">+</span>
 		saddr-&gt;family = AF_IEEE802154;
 		ieee802154_addr_to_sa(&amp;saddr-&gt;addr, &amp;mac_cb(skb)-&gt;source);
 		*addr_len = sizeof(*saddr);
<span class="p_header">diff --git a/net/ipv4/ip_tunnel.c b/net/ipv4/ip_tunnel.c</span>
<span class="p_header">index d3e4479..d1e208b 100644</span>
<span class="p_header">--- a/net/ipv4/ip_tunnel.c</span>
<span class="p_header">+++ b/net/ipv4/ip_tunnel.c</span>
<span class="p_chunk">@@ -587,7 +587,8 @@</span> <span class="p_context"> int ip_tunnel_encap(struct sk_buff *skb, struct ip_tunnel *t,</span>
 EXPORT_SYMBOL(ip_tunnel_encap);
 
 static int tnl_update_pmtu(struct net_device *dev, struct sk_buff *skb,
<span class="p_del">-			    struct rtable *rt, __be16 df)</span>
<span class="p_add">+			    struct rtable *rt, __be16 df,</span>
<span class="p_add">+			    const struct iphdr *inner_iph)</span>
 {
 	struct ip_tunnel *tunnel = netdev_priv(dev);
 	int pkt_size = skb-&gt;len - tunnel-&gt;hlen - dev-&gt;hard_header_len;
<span class="p_chunk">@@ -604,7 +605,8 @@</span> <span class="p_context"> static int tnl_update_pmtu(struct net_device *dev, struct sk_buff *skb,</span>
 
 	if (skb-&gt;protocol == htons(ETH_P_IP)) {
 		if (!skb_is_gso(skb) &amp;&amp;
<span class="p_del">-		    (df &amp; htons(IP_DF)) &amp;&amp; mtu &lt; pkt_size) {</span>
<span class="p_add">+		    (inner_iph-&gt;frag_off &amp; htons(IP_DF)) &amp;&amp;</span>
<span class="p_add">+		    mtu &lt; pkt_size) {</span>
 			memset(IPCB(skb), 0, sizeof(*IPCB(skb)));
 			icmp_send(skb, ICMP_DEST_UNREACH, ICMP_FRAG_NEEDED, htonl(mtu));
 			return -E2BIG;
<span class="p_chunk">@@ -738,7 +740,7 @@</span> <span class="p_context"> void ip_tunnel_xmit(struct sk_buff *skb, struct net_device *dev,</span>
 		goto tx_error;
 	}
 
<span class="p_del">-	if (tnl_update_pmtu(dev, skb, rt, tnl_params-&gt;frag_off)) {</span>
<span class="p_add">+	if (tnl_update_pmtu(dev, skb, rt, tnl_params-&gt;frag_off, inner_iph)) {</span>
 		ip_rt_put(rt);
 		goto tx_error;
 	}
<span class="p_header">diff --git a/net/ipv6/ip6_input.c b/net/ipv6/ip6_input.c</span>
<span class="p_header">index aacdcb4..e87a7b0 100644</span>
<span class="p_header">--- a/net/ipv6/ip6_input.c</span>
<span class="p_header">+++ b/net/ipv6/ip6_input.c</span>
<span class="p_chunk">@@ -330,10 +330,10 @@</span> <span class="p_context"> int ip6_mc_input(struct sk_buff *skb)</span>
 				if (offset &lt; 0)
 					goto out;
 
<span class="p_del">-				if (!ipv6_is_mld(skb, nexthdr, offset))</span>
<span class="p_del">-					goto out;</span>
<span class="p_add">+				if (ipv6_is_mld(skb, nexthdr, offset))</span>
<span class="p_add">+					deliver = true;</span>
 
<span class="p_del">-				deliver = true;</span>
<span class="p_add">+				goto out;</span>
 			}
 			/* unknown RA - process it normally */
 		}
<span class="p_header">diff --git a/net/rds/ib_rdma.c b/net/rds/ib_rdma.c</span>
<span class="p_header">index 273b8bf..657ba9f 100644</span>
<span class="p_header">--- a/net/rds/ib_rdma.c</span>
<span class="p_header">+++ b/net/rds/ib_rdma.c</span>
<span class="p_chunk">@@ -759,8 +759,10 @@</span> <span class="p_context"> void *rds_ib_get_mr(struct scatterlist *sg, unsigned long nents,</span>
 	}
 
 	ibmr = rds_ib_alloc_fmr(rds_ibdev);
<span class="p_del">-	if (IS_ERR(ibmr))</span>
<span class="p_add">+	if (IS_ERR(ibmr)) {</span>
<span class="p_add">+		rds_ib_dev_put(rds_ibdev);</span>
 		return ibmr;
<span class="p_add">+	}</span>
 
 	ret = rds_ib_map_fmr(rds_ibdev, ibmr, sg, nents);
 	if (ret == 0)
<span class="p_header">diff --git a/security/integrity/evm/evm_main.c b/security/integrity/evm/evm_main.c</span>
<span class="p_header">index f589c9a0..02c6e4d 100644</span>
<span class="p_header">--- a/security/integrity/evm/evm_main.c</span>
<span class="p_header">+++ b/security/integrity/evm/evm_main.c</span>
<span class="p_chunk">@@ -296,6 +296,17 @@</span> <span class="p_context"> static int evm_protect_xattr(struct dentry *dentry, const char *xattr_name,</span>
 		iint = integrity_iint_find(dentry-&gt;d_inode);
 		if (iint &amp;&amp; (iint-&gt;flags &amp; IMA_NEW_FILE))
 			return 0;
<span class="p_add">+</span>
<span class="p_add">+		/* exception for pseudo filesystems */</span>
<span class="p_add">+		if (dentry-&gt;d_inode-&gt;i_sb-&gt;s_magic == TMPFS_MAGIC</span>
<span class="p_add">+		    || dentry-&gt;d_inode-&gt;i_sb-&gt;s_magic == SYSFS_MAGIC)</span>
<span class="p_add">+			return 0;</span>
<span class="p_add">+</span>
<span class="p_add">+		integrity_audit_msg(AUDIT_INTEGRITY_METADATA,</span>
<span class="p_add">+				    dentry-&gt;d_inode, dentry-&gt;d_name.name,</span>
<span class="p_add">+				    &quot;update_metadata&quot;,</span>
<span class="p_add">+				    integrity_status_msg[evm_status],</span>
<span class="p_add">+				    -EPERM, 0);</span>
 	}
 out:
 	if (evm_status != INTEGRITY_PASS)
<span class="p_header">diff --git a/security/keys/keyring.c b/security/keys/keyring.c</span>
<span class="p_header">index e72548b..d334370 100644</span>
<span class="p_header">--- a/security/keys/keyring.c</span>
<span class="p_header">+++ b/security/keys/keyring.c</span>
<span class="p_chunk">@@ -1181,9 +1181,11 @@</span> <span class="p_context"> void __key_link_end(struct key *keyring,</span>
 	if (index_key-&gt;type == &amp;key_type_keyring)
 		up_write(&amp;keyring_serialise_link_sem);
 
<span class="p_del">-	if (edit &amp;&amp; !edit-&gt;dead_leaf) {</span>
<span class="p_del">-		key_payload_reserve(keyring,</span>
<span class="p_del">-				    keyring-&gt;datalen - KEYQUOTA_LINK_BYTES);</span>
<span class="p_add">+	if (edit) {</span>
<span class="p_add">+		if (!edit-&gt;dead_leaf) {</span>
<span class="p_add">+			key_payload_reserve(keyring,</span>
<span class="p_add">+				keyring-&gt;datalen - KEYQUOTA_LINK_BYTES);</span>
<span class="p_add">+		}</span>
 		assoc_array_cancel_edit(edit);
 	}
 	up_write(&amp;keyring-&gt;sem);
<span class="p_header">diff --git a/security/selinux/ss/ebitmap.c b/security/selinux/ss/ebitmap.c</span>
<span class="p_header">index afe6a26..57644b1 100644</span>
<span class="p_header">--- a/security/selinux/ss/ebitmap.c</span>
<span class="p_header">+++ b/security/selinux/ss/ebitmap.c</span>
<span class="p_chunk">@@ -153,6 +153,12 @@</span> <span class="p_context"> int ebitmap_netlbl_import(struct ebitmap *ebmap,</span>
 		if (offset == (u32)-1)
 			return 0;
 
<span class="p_add">+		/* don&#39;t waste ebitmap space if the netlabel bitmap is empty */</span>
<span class="p_add">+		if (bitmap == 0) {</span>
<span class="p_add">+			offset += EBITMAP_UNIT_SIZE;</span>
<span class="p_add">+			continue;</span>
<span class="p_add">+		}</span>
<span class="p_add">+</span>
 		if (e_iter == NULL ||
 		    offset &gt;= e_iter-&gt;startbit + EBITMAP_SIZE) {
 			e_prev = e_iter;
<span class="p_header">diff --git a/sound/usb/quirks-table.h b/sound/usb/quirks-table.h</span>
<span class="p_header">index e61c167..b531993 100644</span>
<span class="p_header">--- a/sound/usb/quirks-table.h</span>
<span class="p_header">+++ b/sound/usb/quirks-table.h</span>
<span class="p_chunk">@@ -2516,6 +2516,74 @@</span> <span class="p_context"> YAMAHA_DEVICE(0x7010, &quot;UB99&quot;),</span>
 	}
 },
 
<span class="p_add">+/* Steinberg devices */</span>
<span class="p_add">+{</span>
<span class="p_add">+	/* Steinberg MI2 */</span>
<span class="p_add">+	USB_DEVICE_VENDOR_SPEC(0x0a4e, 0x2040),</span>
<span class="p_add">+	.driver_info = (unsigned long) &amp; (const struct snd_usb_audio_quirk) {</span>
<span class="p_add">+		.ifnum = QUIRK_ANY_INTERFACE,</span>
<span class="p_add">+		.type = QUIRK_COMPOSITE,</span>
<span class="p_add">+		.data = &amp; (const struct snd_usb_audio_quirk[]) {</span>
<span class="p_add">+			{</span>
<span class="p_add">+				.ifnum = 0,</span>
<span class="p_add">+				.type = QUIRK_AUDIO_STANDARD_INTERFACE</span>
<span class="p_add">+			},</span>
<span class="p_add">+			{</span>
<span class="p_add">+				.ifnum = 1,</span>
<span class="p_add">+				.type = QUIRK_AUDIO_STANDARD_INTERFACE</span>
<span class="p_add">+			},</span>
<span class="p_add">+			{</span>
<span class="p_add">+				.ifnum = 2,</span>
<span class="p_add">+				.type = QUIRK_AUDIO_STANDARD_INTERFACE</span>
<span class="p_add">+			},</span>
<span class="p_add">+			{</span>
<span class="p_add">+				.ifnum = 3,</span>
<span class="p_add">+				.type = QUIRK_MIDI_FIXED_ENDPOINT,</span>
<span class="p_add">+				.data = &amp;(const struct snd_usb_midi_endpoint_info) {</span>
<span class="p_add">+					.out_cables = 0x0001,</span>
<span class="p_add">+					.in_cables  = 0x0001</span>
<span class="p_add">+				}</span>
<span class="p_add">+			},</span>
<span class="p_add">+			{</span>
<span class="p_add">+				.ifnum = -1</span>
<span class="p_add">+			}</span>
<span class="p_add">+		}</span>
<span class="p_add">+	}</span>
<span class="p_add">+},</span>
<span class="p_add">+{</span>
<span class="p_add">+	/* Steinberg MI4 */</span>
<span class="p_add">+	USB_DEVICE_VENDOR_SPEC(0x0a4e, 0x4040),</span>
<span class="p_add">+	.driver_info = (unsigned long) &amp; (const struct snd_usb_audio_quirk) {</span>
<span class="p_add">+		.ifnum = QUIRK_ANY_INTERFACE,</span>
<span class="p_add">+		.type = QUIRK_COMPOSITE,</span>
<span class="p_add">+		.data = &amp; (const struct snd_usb_audio_quirk[]) {</span>
<span class="p_add">+			{</span>
<span class="p_add">+				.ifnum = 0,</span>
<span class="p_add">+				.type = QUIRK_AUDIO_STANDARD_INTERFACE</span>
<span class="p_add">+			},</span>
<span class="p_add">+			{</span>
<span class="p_add">+				.ifnum = 1,</span>
<span class="p_add">+				.type = QUIRK_AUDIO_STANDARD_INTERFACE</span>
<span class="p_add">+			},</span>
<span class="p_add">+			{</span>
<span class="p_add">+				.ifnum = 2,</span>
<span class="p_add">+				.type = QUIRK_AUDIO_STANDARD_INTERFACE</span>
<span class="p_add">+			},</span>
<span class="p_add">+			{</span>
<span class="p_add">+				.ifnum = 3,</span>
<span class="p_add">+				.type = QUIRK_MIDI_FIXED_ENDPOINT,</span>
<span class="p_add">+				.data = &amp;(const struct snd_usb_midi_endpoint_info) {</span>
<span class="p_add">+					.out_cables = 0x0001,</span>
<span class="p_add">+					.in_cables  = 0x0001</span>
<span class="p_add">+				}</span>
<span class="p_add">+			},</span>
<span class="p_add">+			{</span>
<span class="p_add">+				.ifnum = -1</span>
<span class="p_add">+			}</span>
<span class="p_add">+		}</span>
<span class="p_add">+	}</span>
<span class="p_add">+},</span>
<span class="p_add">+</span>
 /* TerraTec devices */
 {
 	USB_DEVICE_VENDOR_SPEC(0x0ccd, 0x0012),
<span class="p_header">diff --git a/tools/perf/ui/browsers/hists.c b/tools/perf/ui/browsers/hists.c</span>
<span class="p_header">index 788506e..0ccdec0 100644</span>
<span class="p_header">--- a/tools/perf/ui/browsers/hists.c</span>
<span class="p_header">+++ b/tools/perf/ui/browsers/hists.c</span>
<span class="p_chunk">@@ -45,7 +45,7 @@</span> <span class="p_context"> static struct rb_node *hists__filter_entries(struct rb_node *nd,</span>
 
 static bool hist_browser__has_filter(struct hist_browser *hb)
 {
<span class="p_del">-	return hists__has_filter(hb-&gt;hists) || hb-&gt;min_pcnt;</span>
<span class="p_add">+	return hists__has_filter(hb-&gt;hists) || hb-&gt;min_pcnt || symbol_conf.has_filter;</span>
 }
 
 static u32 hist_browser__nr_entries(struct hist_browser *hb)
<span class="p_header">diff --git a/tools/perf/util/symbol.c b/tools/perf/util/symbol.c</span>
<span class="p_header">index a194702..9aca000 100644</span>
<span class="p_header">--- a/tools/perf/util/symbol.c</span>
<span class="p_header">+++ b/tools/perf/util/symbol.c</span>
<span class="p_chunk">@@ -1856,6 +1856,8 @@</span> <span class="p_context"> int setup_list(struct strlist **list, const char *list_str,</span>
 		pr_err(&quot;problems parsing %s list\n&quot;, list_name);
 		return -1;
 	}
<span class="p_add">+</span>
<span class="p_add">+	symbol_conf.has_filter = true;</span>
 	return 0;
 }
 
<span class="p_header">diff --git a/tools/perf/util/symbol.h b/tools/perf/util/symbol.h</span>
<span class="p_header">index 1650dcb..c56dfac 100644</span>
<span class="p_header">--- a/tools/perf/util/symbol.h</span>
<span class="p_header">+++ b/tools/perf/util/symbol.h</span>
<span class="p_chunk">@@ -103,7 +103,8 @@</span> <span class="p_context"> struct symbol_conf {</span>
 			demangle_kernel,
 			filter_relative,
 			show_hist_headers,
<span class="p_del">-			branch_callstack;</span>
<span class="p_add">+			branch_callstack,</span>
<span class="p_add">+			has_filter;</span>
 	const char	*vmlinux_name,
 			*kallsyms_name,
 			*source_prefix,

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



