
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>[GIT,PULL] x86 fixes - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    [GIT,PULL] x86 fixes</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=35552">Ingo Molnar</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>Sept. 24, 2017, 11:28 a.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;20170924112829.vw7oy5zodhu2hvxn@gmail.com&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/9967947/mbox/"
   >mbox</a>
|
   <a href="/patch/9967947/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/9967947/">/patch/9967947/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
	[172.30.200.125])
	by pdx-korg-patchwork.web.codeaurora.org (Postfix) with ESMTP id
	B6C24602CB for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Sun, 24 Sep 2017 11:28:40 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 9AF4228B9A
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Sun, 24 Sep 2017 11:28:40 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id 8FAC128D4B; Sun, 24 Sep 2017 11:28:40 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-6.3 required=2.0 tests=BAYES_00,DKIM_SIGNED,
	RCVD_IN_DNSWL_HI, RCVD_IN_SORBS_SPAM,
	T_DKIM_INVALID autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 2ECAE28B9A
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Sun, 24 Sep 2017 11:28:39 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1752108AbdIXL2g (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Sun, 24 Sep 2017 07:28:36 -0400
Received: from mail-wr0-f194.google.com ([209.85.128.194]:34403 &quot;EHLO
	mail-wr0-f194.google.com&quot; rhost-flags-OK-OK-OK-OK) by vger.kernel.org
	with ESMTP id S1751799AbdIXL2e (ORCPT
	&lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Sun, 24 Sep 2017 07:28:34 -0400
Received: by mail-wr0-f194.google.com with SMTP id k20so2854672wre.1
	for &lt;linux-kernel@vger.kernel.org&gt;;
	Sun, 24 Sep 2017 04:28:33 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
	d=gmail.com; s=20161025;
	h=sender:date:from:to:cc:subject:message-id:mime-version
	:content-disposition:user-agent;
	bh=a+//6xfPmGsEP9EfRIBZjyX1s7c/K/9XoSszYznRnpc=;
	b=jHQ5d1evo9Sd6gr/s8okkz6r6rp7TyUsPKffUGzan3T5mqgOEE06BB67/bHHhlCoTX
	w4gK1B/EkgxAXewfetwydxZKjx+C0eOaHxVsS/yybRBCCTOgUuTOYoCdnhl/vzE5aVHo
	4AO33S7gHSvDQlg1ufsDXCrJCRMcN3DsrJohR0xhRGEib2KzjCQDcnEVSw7VIQdMC4ea
	Owj6vawRjLonhKNyfLVPr7E7TOW1z8WsaOefB/3raaHifQghTKCKxFhYpyQHaJ9yw9dC
	wpGYweSbwsRDGZncUW8JC7e80Kl22xBNH4G2oWlCTSyaOb9DomBKRLC8UAOGBi/l1bOA
	X2wQ==
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
	d=1e100.net; s=20161025;
	h=x-gm-message-state:sender:date:from:to:cc:subject:message-id
	:mime-version:content-disposition:user-agent;
	bh=a+//6xfPmGsEP9EfRIBZjyX1s7c/K/9XoSszYznRnpc=;
	b=rJfjVlJbuieNfn1GnuGfIb9E34IGqrdkT6OjuDum99p7t66K5JSam5IkzpEp79lyvZ
	IwNf8nMzsRNdQMBomOIcbkF2czUusZG7OWbVUJMmqfvi2m/uWF8x+QMiPGWNy0m6cXVA
	kNopcIvz7pX0JQqUE7jUtw5Ac2qNGi8DVuoRFomuHJqk1dtKer4wIkbukeO6d5UnJ0yQ
	0Ger0tPwlCbFzKE7gYSywFRQF3u0VdSHc7MIqAUSpWtbZMLT0r12qodzYA7pws2Hp9rp
	6NLOPWp6z0w+f1QGT8M0KlQvaPtTuNCksTJIQKreilCHOP7ohvCZMYg/4aFaw0/3CKZU
	9BFA==
X-Gm-Message-State: AHPjjUhzCfBTD4h+2Klnq8ni0WIfTIFplpMUHmK1lvceidHQSBnDs8jy
	b8m2YCNpEgM+Hfo3zBcp/Yg=
X-Google-Smtp-Source: AOwi7QBhkFbmbeIwymJpeRyYlmaHNyg2BSG6z2y6FJwMrp/WbUa/R+uEdKdQYeZZ2sTQBsG4Wd8+gw==
X-Received: by 10.223.139.200 with SMTP id w8mr4022620wra.172.1506252512300; 
	Sun, 24 Sep 2017 04:28:32 -0700 (PDT)
Received: from gmail.com (2E8B0CD5.catv.pool.telekom.hu. [46.139.12.213])
	by smtp.gmail.com with ESMTPSA id
	a69sm2133055wme.40.2017.09.24.04.28.31
	(version=TLS1_2 cipher=ECDHE-RSA-CHACHA20-POLY1305 bits=256/256);
	Sun, 24 Sep 2017 04:28:31 -0700 (PDT)
Date: Sun, 24 Sep 2017 13:28:29 +0200
From: Ingo Molnar &lt;mingo@kernel.org&gt;
To: Linus Torvalds &lt;torvalds@linux-foundation.org&gt;
Cc: linux-kernel@vger.kernel.org, Thomas Gleixner &lt;tglx@linutronix.de&gt;,
	&quot;H. Peter Anvin&quot; &lt;hpa@zytor.com&gt;,
	Peter Zijlstra &lt;a.p.zijlstra@chello.nl&gt;,
	Andrew Morton &lt;akpm@linux-foundation.org&gt;,
	Andy Lutomirski &lt;luto@kernel.org&gt;
Subject: [GIT PULL] x86 fixes
Message-ID: &lt;20170924112829.vw7oy5zodhu2hvxn@gmail.com&gt;
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Disposition: inline
User-Agent: NeoMutt/20170113 (1.7.2)
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=35552">Ingo Molnar</a> - Sept. 24, 2017, 11:28 a.m.</div>
<pre class="content">
Linus,

Please pull the latest x86-urgent-for-linus git tree from:

   git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip.git x86-urgent-for-linus

   # HEAD: f5caf621ee357279e759c0911daf6d55c7d36f03 x86/asm: Fix inline asm call constraints for Clang

Another round of CR3/PCID related fixes (I think this addresses all but one of the 
known problems with PCID support), an objtool fix plus a Clang fix that (finally) 
solves all Clang quirks to build a bootable x86 kernel as-is.


  out-of-topic modifications in x86-urgent-for-linus:
  -----------------------------------------------------
  tools/objtool/check.c              # 0d0970eef3b0: objtool: Handle another GCC 

 Thanks,

	Ingo

------------------&gt;
Andy Lutomirski (4):
      x86/mm: Factor out CR3-building code
      x86/mm/64: Stop using CR3.PCID == 0 in ASID-aware code
      x86/mm/32: Move setup_clear_cpu_cap(X86_FEATURE_PCID) earlier
      x86/mm/32: Load a sane CR3 before cpu_init() on secondary CPUs

Josh Poimboeuf (2):
      objtool: Handle another GCC stack pointer adjustment bug
      x86/asm: Fix inline asm call constraints for Clang


 arch/x86/include/asm/alternative.h               |  3 +-
 arch/x86/include/asm/asm.h                       | 11 ++++++
 arch/x86/include/asm/mmu_context.h               | 32 +++++++++++++++---
 arch/x86/include/asm/mshyperv.h                  | 10 +++---
 arch/x86/include/asm/paravirt_types.h            | 14 ++++----
 arch/x86/include/asm/preempt.h                   | 15 +++------
 arch/x86/include/asm/processor.h                 |  6 ++--
 arch/x86/include/asm/rwsem.h                     |  4 +--
 arch/x86/include/asm/uaccess.h                   |  4 +--
 arch/x86/include/asm/xen/hypercall.h             |  5 ++-
 arch/x86/kernel/cpu/bugs.c                       |  8 -----
 arch/x86/kernel/cpu/common.c                     |  8 +++++
 arch/x86/kernel/smpboot.c                        | 13 +++----
 arch/x86/kvm/emulate.c                           |  3 +-
 arch/x86/kvm/vmx.c                               |  3 +-
 arch/x86/mm/fault.c                              |  3 +-
 arch/x86/mm/tlb.c                                | 11 +++---
 tools/objtool/Documentation/stack-validation.txt |  6 ++--
 tools/objtool/arch/x86/decode.c                  |  6 ++--
 tools/objtool/check.c                            | 43 ++++++++++++++++--------
 20 files changed, 122 insertions(+), 86 deletions(-)
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/arch/x86/include/asm/alternative.h b/arch/x86/include/asm/alternative.h</span>
<span class="p_header">index 1b020381ab38..c096624137ae 100644</span>
<span class="p_header">--- a/arch/x86/include/asm/alternative.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/alternative.h</span>
<span class="p_chunk">@@ -218,10 +218,9 @@</span> <span class="p_context"> static inline int alternatives_text_reserved(void *start, void *end)</span>
 #define alternative_call_2(oldfunc, newfunc1, feature1, newfunc2, feature2,   \
 			   output, input...)				      \
 {									      \
<span class="p_del">-	register void *__sp asm(_ASM_SP);				      \</span>
 	asm volatile (ALTERNATIVE_2(&quot;call %P[old]&quot;, &quot;call %P[new1]&quot;, feature1,\
 		&quot;call %P[new2]&quot;, feature2)				      \
<span class="p_del">-		: output, &quot;+r&quot; (__sp)					      \</span>
<span class="p_add">+		: output, ASM_CALL_CONSTRAINT				      \</span>
 		: [old] &quot;i&quot; (oldfunc), [new1] &quot;i&quot; (newfunc1),		      \
 		  [new2] &quot;i&quot; (newfunc2), ## input);			      \
 }
<span class="p_header">diff --git a/arch/x86/include/asm/asm.h b/arch/x86/include/asm/asm.h</span>
<span class="p_header">index 676ee5807d86..c1eadbaf1115 100644</span>
<span class="p_header">--- a/arch/x86/include/asm/asm.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/asm.h</span>
<span class="p_chunk">@@ -132,4 +132,15 @@</span> <span class="p_context"></span>
 /* For C file, we already have NOKPROBE_SYMBOL macro */
 #endif
 
<span class="p_add">+#ifndef __ASSEMBLY__</span>
<span class="p_add">+/*</span>
<span class="p_add">+ * This output constraint should be used for any inline asm which has a &quot;call&quot;</span>
<span class="p_add">+ * instruction.  Otherwise the asm may be inserted before the frame pointer</span>
<span class="p_add">+ * gets set up by the containing function.  If you forget to do this, objtool</span>
<span class="p_add">+ * may print a &quot;call without frame pointer save/setup&quot; warning.</span>
<span class="p_add">+ */</span>
<span class="p_add">+register unsigned int __asm_call_sp asm(&quot;esp&quot;);</span>
<span class="p_add">+#define ASM_CALL_CONSTRAINT &quot;+r&quot; (__asm_call_sp)</span>
<span class="p_add">+#endif</span>
<span class="p_add">+</span>
 #endif /* _ASM_X86_ASM_H */
<span class="p_header">diff --git a/arch/x86/include/asm/mmu_context.h b/arch/x86/include/asm/mmu_context.h</span>
<span class="p_header">index 7ae318c340d9..c120b5db178a 100644</span>
<span class="p_header">--- a/arch/x86/include/asm/mmu_context.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/mmu_context.h</span>
<span class="p_chunk">@@ -286,6 +286,32 @@</span> <span class="p_context"> static inline bool arch_vma_access_permitted(struct vm_area_struct *vma,</span>
 	return __pkru_allows_pkey(vma_pkey(vma), write);
 }
 
<span class="p_add">+/*</span>
<span class="p_add">+ * If PCID is on, ASID-aware code paths put the ASID+1 into the PCID</span>
<span class="p_add">+ * bits.  This serves two purposes.  It prevents a nasty situation in</span>
<span class="p_add">+ * which PCID-unaware code saves CR3, loads some other value (with PCID</span>
<span class="p_add">+ * == 0), and then restores CR3, thus corrupting the TLB for ASID 0 if</span>
<span class="p_add">+ * the saved ASID was nonzero.  It also means that any bugs involving</span>
<span class="p_add">+ * loading a PCID-enabled CR3 with CR4.PCIDE off will trigger</span>
<span class="p_add">+ * deterministically.</span>
<span class="p_add">+ */</span>
<span class="p_add">+</span>
<span class="p_add">+static inline unsigned long build_cr3(struct mm_struct *mm, u16 asid)</span>
<span class="p_add">+{</span>
<span class="p_add">+	if (static_cpu_has(X86_FEATURE_PCID)) {</span>
<span class="p_add">+		VM_WARN_ON_ONCE(asid &gt; 4094);</span>
<span class="p_add">+		return __sme_pa(mm-&gt;pgd) | (asid + 1);</span>
<span class="p_add">+	} else {</span>
<span class="p_add">+		VM_WARN_ON_ONCE(asid != 0);</span>
<span class="p_add">+		return __sme_pa(mm-&gt;pgd);</span>
<span class="p_add">+	}</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline unsigned long build_cr3_noflush(struct mm_struct *mm, u16 asid)</span>
<span class="p_add">+{</span>
<span class="p_add">+	VM_WARN_ON_ONCE(asid &gt; 4094);</span>
<span class="p_add">+	return __sme_pa(mm-&gt;pgd) | (asid + 1) | CR3_NOFLUSH;</span>
<span class="p_add">+}</span>
 
 /*
  * This can be used from process context to figure out what the value of
<span class="p_chunk">@@ -296,10 +322,8 @@</span> <span class="p_context"> static inline bool arch_vma_access_permitted(struct vm_area_struct *vma,</span>
  */
 static inline unsigned long __get_current_cr3_fast(void)
 {
<span class="p_del">-	unsigned long cr3 = __pa(this_cpu_read(cpu_tlbstate.loaded_mm)-&gt;pgd);</span>
<span class="p_del">-</span>
<span class="p_del">-	if (static_cpu_has(X86_FEATURE_PCID))</span>
<span class="p_del">-		cr3 |= this_cpu_read(cpu_tlbstate.loaded_mm_asid);</span>
<span class="p_add">+	unsigned long cr3 = build_cr3(this_cpu_read(cpu_tlbstate.loaded_mm),</span>
<span class="p_add">+		this_cpu_read(cpu_tlbstate.loaded_mm_asid));</span>
 
 	/* For now, be very restrictive about when this can be called. */
 	VM_WARN_ON(in_nmi() || preemptible());
<span class="p_header">diff --git a/arch/x86/include/asm/mshyperv.h b/arch/x86/include/asm/mshyperv.h</span>
<span class="p_header">index 63cc96f064dc..738503e1f80c 100644</span>
<span class="p_header">--- a/arch/x86/include/asm/mshyperv.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/mshyperv.h</span>
<span class="p_chunk">@@ -179,7 +179,6 @@</span> <span class="p_context"> static inline u64 hv_do_hypercall(u64 control, void *input, void *output)</span>
 	u64 input_address = input ? virt_to_phys(input) : 0;
 	u64 output_address = output ? virt_to_phys(output) : 0;
 	u64 hv_status;
<span class="p_del">-	register void *__sp asm(_ASM_SP);</span>
 
 #ifdef CONFIG_X86_64
 	if (!hv_hypercall_pg)
<span class="p_chunk">@@ -187,7 +186,7 @@</span> <span class="p_context"> static inline u64 hv_do_hypercall(u64 control, void *input, void *output)</span>
 
 	__asm__ __volatile__(&quot;mov %4, %%r8\n&quot;
 			     &quot;call *%5&quot;
<span class="p_del">-			     : &quot;=a&quot; (hv_status), &quot;+r&quot; (__sp),</span>
<span class="p_add">+			     : &quot;=a&quot; (hv_status), ASM_CALL_CONSTRAINT,</span>
 			       &quot;+c&quot; (control), &quot;+d&quot; (input_address)
 			     :  &quot;r&quot; (output_address), &quot;m&quot; (hv_hypercall_pg)
 			     : &quot;cc&quot;, &quot;memory&quot;, &quot;r8&quot;, &quot;r9&quot;, &quot;r10&quot;, &quot;r11&quot;);
<span class="p_chunk">@@ -202,7 +201,7 @@</span> <span class="p_context"> static inline u64 hv_do_hypercall(u64 control, void *input, void *output)</span>
 
 	__asm__ __volatile__(&quot;call *%7&quot;
 			     : &quot;=A&quot; (hv_status),
<span class="p_del">-			       &quot;+c&quot; (input_address_lo), &quot;+r&quot; (__sp)</span>
<span class="p_add">+			       &quot;+c&quot; (input_address_lo), ASM_CALL_CONSTRAINT</span>
 			     : &quot;A&quot; (control),
 			       &quot;b&quot; (input_address_hi),
 			       &quot;D&quot;(output_address_hi), &quot;S&quot;(output_address_lo),
<span class="p_chunk">@@ -224,12 +223,11 @@</span> <span class="p_context"> static inline u64 hv_do_hypercall(u64 control, void *input, void *output)</span>
 static inline u64 hv_do_fast_hypercall8(u16 code, u64 input1)
 {
 	u64 hv_status, control = (u64)code | HV_HYPERCALL_FAST_BIT;
<span class="p_del">-	register void *__sp asm(_ASM_SP);</span>
 
 #ifdef CONFIG_X86_64
 	{
 		__asm__ __volatile__(&quot;call *%4&quot;
<span class="p_del">-				     : &quot;=a&quot; (hv_status), &quot;+r&quot; (__sp),</span>
<span class="p_add">+				     : &quot;=a&quot; (hv_status), ASM_CALL_CONSTRAINT,</span>
 				       &quot;+c&quot; (control), &quot;+d&quot; (input1)
 				     : &quot;m&quot; (hv_hypercall_pg)
 				     : &quot;cc&quot;, &quot;r8&quot;, &quot;r9&quot;, &quot;r10&quot;, &quot;r11&quot;);
<span class="p_chunk">@@ -242,7 +240,7 @@</span> <span class="p_context"> static inline u64 hv_do_fast_hypercall8(u16 code, u64 input1)</span>
 		__asm__ __volatile__ (&quot;call *%5&quot;
 				      : &quot;=A&quot;(hv_status),
 					&quot;+c&quot;(input1_lo),
<span class="p_del">-					&quot;+r&quot;(__sp)</span>
<span class="p_add">+					ASM_CALL_CONSTRAINT</span>
 				      :	&quot;A&quot; (control),
 					&quot;b&quot; (input1_hi),
 					&quot;m&quot; (hv_hypercall_pg)
<span class="p_header">diff --git a/arch/x86/include/asm/paravirt_types.h b/arch/x86/include/asm/paravirt_types.h</span>
<span class="p_header">index 42873edd9f9d..280d94c36dad 100644</span>
<span class="p_header">--- a/arch/x86/include/asm/paravirt_types.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/paravirt_types.h</span>
<span class="p_chunk">@@ -459,8 +459,8 @@</span> <span class="p_context"> int paravirt_disable_iospace(void);</span>
  */
 #ifdef CONFIG_X86_32
 #define PVOP_VCALL_ARGS							\
<span class="p_del">-	unsigned long __eax = __eax, __edx = __edx, __ecx = __ecx;	\</span>
<span class="p_del">-	register void *__sp asm(&quot;esp&quot;)</span>
<span class="p_add">+	unsigned long __eax = __eax, __edx = __edx, __ecx = __ecx;</span>
<span class="p_add">+</span>
 #define PVOP_CALL_ARGS			PVOP_VCALL_ARGS
 
 #define PVOP_CALL_ARG1(x)		&quot;a&quot; ((unsigned long)(x))
<span class="p_chunk">@@ -480,8 +480,8 @@</span> <span class="p_context"> int paravirt_disable_iospace(void);</span>
 /* [re]ax isn&#39;t an arg, but the return val */
 #define PVOP_VCALL_ARGS						\
 	unsigned long __edi = __edi, __esi = __esi,		\
<span class="p_del">-		__edx = __edx, __ecx = __ecx, __eax = __eax;	\</span>
<span class="p_del">-	register void *__sp asm(&quot;rsp&quot;)</span>
<span class="p_add">+		__edx = __edx, __ecx = __ecx, __eax = __eax;</span>
<span class="p_add">+</span>
 #define PVOP_CALL_ARGS		PVOP_VCALL_ARGS
 
 #define PVOP_CALL_ARG1(x)		&quot;D&quot; ((unsigned long)(x))
<span class="p_chunk">@@ -532,7 +532,7 @@</span> <span class="p_context"> int paravirt_disable_iospace(void);</span>
 			asm volatile(pre				\
 				     paravirt_alt(PARAVIRT_CALL)	\
 				     post				\
<span class="p_del">-				     : call_clbr, &quot;+r&quot; (__sp)		\</span>
<span class="p_add">+				     : call_clbr, ASM_CALL_CONSTRAINT	\</span>
 				     : paravirt_type(op),		\
 				       paravirt_clobber(clbr),		\
 				       ##__VA_ARGS__			\
<span class="p_chunk">@@ -542,7 +542,7 @@</span> <span class="p_context"> int paravirt_disable_iospace(void);</span>
 			asm volatile(pre				\
 				     paravirt_alt(PARAVIRT_CALL)	\
 				     post				\
<span class="p_del">-				     : call_clbr, &quot;+r&quot; (__sp)		\</span>
<span class="p_add">+				     : call_clbr, ASM_CALL_CONSTRAINT	\</span>
 				     : paravirt_type(op),		\
 				       paravirt_clobber(clbr),		\
 				       ##__VA_ARGS__			\
<span class="p_chunk">@@ -569,7 +569,7 @@</span> <span class="p_context"> int paravirt_disable_iospace(void);</span>
 		asm volatile(pre					\
 			     paravirt_alt(PARAVIRT_CALL)		\
 			     post					\
<span class="p_del">-			     : call_clbr, &quot;+r&quot; (__sp)			\</span>
<span class="p_add">+			     : call_clbr, ASM_CALL_CONSTRAINT		\</span>
 			     : paravirt_type(op),			\
 			       paravirt_clobber(clbr),			\
 			       ##__VA_ARGS__				\
<span class="p_header">diff --git a/arch/x86/include/asm/preempt.h b/arch/x86/include/asm/preempt.h</span>
<span class="p_header">index ec1f3c651150..4f44505dbf87 100644</span>
<span class="p_header">--- a/arch/x86/include/asm/preempt.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/preempt.h</span>
<span class="p_chunk">@@ -100,19 +100,14 @@</span> <span class="p_context"> static __always_inline bool should_resched(int preempt_offset)</span>
 
 #ifdef CONFIG_PREEMPT
   extern asmlinkage void ___preempt_schedule(void);
<span class="p_del">-# define __preempt_schedule()					\</span>
<span class="p_del">-({								\</span>
<span class="p_del">-	register void *__sp asm(_ASM_SP);			\</span>
<span class="p_del">-	asm volatile (&quot;call ___preempt_schedule&quot; : &quot;+r&quot;(__sp));	\</span>
<span class="p_del">-})</span>
<span class="p_add">+# define __preempt_schedule() \</span>
<span class="p_add">+	asm volatile (&quot;call ___preempt_schedule&quot; : ASM_CALL_CONSTRAINT)</span>
 
   extern asmlinkage void preempt_schedule(void);
   extern asmlinkage void ___preempt_schedule_notrace(void);
<span class="p_del">-# define __preempt_schedule_notrace()					\</span>
<span class="p_del">-({									\</span>
<span class="p_del">-	register void *__sp asm(_ASM_SP);				\</span>
<span class="p_del">-	asm volatile (&quot;call ___preempt_schedule_notrace&quot; : &quot;+r&quot;(__sp));	\</span>
<span class="p_del">-})</span>
<span class="p_add">+# define __preempt_schedule_notrace() \</span>
<span class="p_add">+	asm volatile (&quot;call ___preempt_schedule_notrace&quot; : ASM_CALL_CONSTRAINT)</span>
<span class="p_add">+</span>
   extern asmlinkage void preempt_schedule_notrace(void);
 #endif
 
<span class="p_header">diff --git a/arch/x86/include/asm/processor.h b/arch/x86/include/asm/processor.h</span>
<span class="p_header">index 3fa26a61eabc..b390ff76e58f 100644</span>
<span class="p_header">--- a/arch/x86/include/asm/processor.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/processor.h</span>
<span class="p_chunk">@@ -677,8 +677,6 @@</span> <span class="p_context"> static inline void sync_core(void)</span>
 	 * Like all of Linux&#39;s memory ordering operations, this is a
 	 * compiler barrier as well.
 	 */
<span class="p_del">-	register void *__sp asm(_ASM_SP);</span>
<span class="p_del">-</span>
 #ifdef CONFIG_X86_32
 	asm volatile (
 		&quot;pushfl\n\t&quot;
<span class="p_chunk">@@ -686,7 +684,7 @@</span> <span class="p_context"> static inline void sync_core(void)</span>
 		&quot;pushl $1f\n\t&quot;
 		&quot;iret\n\t&quot;
 		&quot;1:&quot;
<span class="p_del">-		: &quot;+r&quot; (__sp) : : &quot;memory&quot;);</span>
<span class="p_add">+		: ASM_CALL_CONSTRAINT : : &quot;memory&quot;);</span>
 #else
 	unsigned int tmp;
 
<span class="p_chunk">@@ -703,7 +701,7 @@</span> <span class="p_context"> static inline void sync_core(void)</span>
 		&quot;iretq\n\t&quot;
 		UNWIND_HINT_RESTORE
 		&quot;1:&quot;
<span class="p_del">-		: &quot;=&amp;r&quot; (tmp), &quot;+r&quot; (__sp) : : &quot;cc&quot;, &quot;memory&quot;);</span>
<span class="p_add">+		: &quot;=&amp;r&quot; (tmp), ASM_CALL_CONSTRAINT : : &quot;cc&quot;, &quot;memory&quot;);</span>
 #endif
 }
 
<span class="p_header">diff --git a/arch/x86/include/asm/rwsem.h b/arch/x86/include/asm/rwsem.h</span>
<span class="p_header">index a34e0d4b957d..7116b7931c7b 100644</span>
<span class="p_header">--- a/arch/x86/include/asm/rwsem.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/rwsem.h</span>
<span class="p_chunk">@@ -103,7 +103,6 @@</span> <span class="p_context"> static inline bool __down_read_trylock(struct rw_semaphore *sem)</span>
 ({							\
 	long tmp;					\
 	struct rw_semaphore* ret;			\
<span class="p_del">-	register void *__sp asm(_ASM_SP);		\</span>
 							\
 	asm volatile(&quot;# beginning down_write\n\t&quot;	\
 		     LOCK_PREFIX &quot;  xadd      %1,(%4)\n\t&quot;	\
<span class="p_chunk">@@ -114,7 +113,8 @@</span> <span class="p_context"> static inline bool __down_read_trylock(struct rw_semaphore *sem)</span>
 		     &quot;  call &quot; slow_path &quot;\n&quot;		\
 		     &quot;1:\n&quot;				\
 		     &quot;# ending down_write&quot;		\
<span class="p_del">-		     : &quot;+m&quot; (sem-&gt;count), &quot;=d&quot; (tmp), &quot;=a&quot; (ret), &quot;+r&quot; (__sp) \</span>
<span class="p_add">+		     : &quot;+m&quot; (sem-&gt;count), &quot;=d&quot; (tmp),	\</span>
<span class="p_add">+		       &quot;=a&quot; (ret), ASM_CALL_CONSTRAINT	\</span>
 		     : &quot;a&quot; (sem), &quot;1&quot; (RWSEM_ACTIVE_WRITE_BIAS) \
 		     : &quot;memory&quot;, &quot;cc&quot;);			\
 	ret;						\
<span class="p_header">diff --git a/arch/x86/include/asm/uaccess.h b/arch/x86/include/asm/uaccess.h</span>
<span class="p_header">index 184eb9894dae..78e8fcc87d4c 100644</span>
<span class="p_header">--- a/arch/x86/include/asm/uaccess.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/uaccess.h</span>
<span class="p_chunk">@@ -166,11 +166,11 @@</span> <span class="p_context"> __typeof__(__builtin_choose_expr(sizeof(x) &gt; sizeof(0UL), 0ULL, 0UL))</span>
 ({									\
 	int __ret_gu;							\
 	register __inttype(*(ptr)) __val_gu asm(&quot;%&quot;_ASM_DX);		\
<span class="p_del">-	register void *__sp asm(_ASM_SP);				\</span>
 	__chk_user_ptr(ptr);						\
 	might_fault();							\
 	asm volatile(&quot;call __get_user_%P4&quot;				\
<span class="p_del">-		     : &quot;=a&quot; (__ret_gu), &quot;=r&quot; (__val_gu), &quot;+r&quot; (__sp)	\</span>
<span class="p_add">+		     : &quot;=a&quot; (__ret_gu), &quot;=r&quot; (__val_gu),		\</span>
<span class="p_add">+			ASM_CALL_CONSTRAINT				\</span>
 		     : &quot;0&quot; (ptr), &quot;i&quot; (sizeof(*(ptr))));		\
 	(x) = (__force __typeof__(*(ptr))) __val_gu;			\
 	__builtin_expect(__ret_gu, 0);					\
<span class="p_header">diff --git a/arch/x86/include/asm/xen/hypercall.h b/arch/x86/include/asm/xen/hypercall.h</span>
<span class="p_header">index 9606688caa4b..128a1a0b1450 100644</span>
<span class="p_header">--- a/arch/x86/include/asm/xen/hypercall.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/xen/hypercall.h</span>
<span class="p_chunk">@@ -113,10 +113,9 @@</span> <span class="p_context"> extern struct { char _entry[32]; } hypercall_page[];</span>
 	register unsigned long __arg2 asm(__HYPERCALL_ARG2REG) = __arg2; \
 	register unsigned long __arg3 asm(__HYPERCALL_ARG3REG) = __arg3; \
 	register unsigned long __arg4 asm(__HYPERCALL_ARG4REG) = __arg4; \
<span class="p_del">-	register unsigned long __arg5 asm(__HYPERCALL_ARG5REG) = __arg5; \</span>
<span class="p_del">-	register void *__sp asm(_ASM_SP);</span>
<span class="p_add">+	register unsigned long __arg5 asm(__HYPERCALL_ARG5REG) = __arg5;</span>
 
<span class="p_del">-#define __HYPERCALL_0PARAM	&quot;=r&quot; (__res), &quot;+r&quot; (__sp)</span>
<span class="p_add">+#define __HYPERCALL_0PARAM	&quot;=r&quot; (__res), ASM_CALL_CONSTRAINT</span>
 #define __HYPERCALL_1PARAM	__HYPERCALL_0PARAM, &quot;+r&quot; (__arg1)
 #define __HYPERCALL_2PARAM	__HYPERCALL_1PARAM, &quot;+r&quot; (__arg2)
 #define __HYPERCALL_3PARAM	__HYPERCALL_2PARAM, &quot;+r&quot; (__arg3)
<span class="p_header">diff --git a/arch/x86/kernel/cpu/bugs.c b/arch/x86/kernel/cpu/bugs.c</span>
<span class="p_header">index db684880d74a..0af86d9242da 100644</span>
<span class="p_header">--- a/arch/x86/kernel/cpu/bugs.c</span>
<span class="p_header">+++ b/arch/x86/kernel/cpu/bugs.c</span>
<span class="p_chunk">@@ -21,14 +21,6 @@</span> <span class="p_context"></span>
 
 void __init check_bugs(void)
 {
<span class="p_del">-#ifdef CONFIG_X86_32</span>
<span class="p_del">-	/*</span>
<span class="p_del">-	 * Regardless of whether PCID is enumerated, the SDM says</span>
<span class="p_del">-	 * that it can&#39;t be enabled in 32-bit mode.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	setup_clear_cpu_cap(X86_FEATURE_PCID);</span>
<span class="p_del">-#endif</span>
<span class="p_del">-</span>
 	identify_boot_cpu();
 
 	if (!IS_ENABLED(CONFIG_SMP)) {
<span class="p_header">diff --git a/arch/x86/kernel/cpu/common.c b/arch/x86/kernel/cpu/common.c</span>
<span class="p_header">index 775f10100d7f..c9176bae7fd8 100644</span>
<span class="p_header">--- a/arch/x86/kernel/cpu/common.c</span>
<span class="p_header">+++ b/arch/x86/kernel/cpu/common.c</span>
<span class="p_chunk">@@ -904,6 +904,14 @@</span> <span class="p_context"> static void __init early_identify_cpu(struct cpuinfo_x86 *c)</span>
 
 	setup_force_cpu_cap(X86_FEATURE_ALWAYS);
 	fpu__init_system(c);
<span class="p_add">+</span>
<span class="p_add">+#ifdef CONFIG_X86_32</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Regardless of whether PCID is enumerated, the SDM says</span>
<span class="p_add">+	 * that it can&#39;t be enabled in 32-bit mode.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	setup_clear_cpu_cap(X86_FEATURE_PCID);</span>
<span class="p_add">+#endif</span>
 }
 
 void __init early_cpu_init(void)
<span class="p_header">diff --git a/arch/x86/kernel/smpboot.c b/arch/x86/kernel/smpboot.c</span>
<span class="p_header">index 0854ff169274..ad59edd84de7 100644</span>
<span class="p_header">--- a/arch/x86/kernel/smpboot.c</span>
<span class="p_header">+++ b/arch/x86/kernel/smpboot.c</span>
<span class="p_chunk">@@ -232,12 +232,6 @@</span> <span class="p_context"> static void notrace start_secondary(void *unused)</span>
 	 */
 	if (boot_cpu_has(X86_FEATURE_PCID))
 		__write_cr4(__read_cr4() | X86_CR4_PCIDE);
<span class="p_del">-	cpu_init();</span>
<span class="p_del">-	x86_cpuinit.early_percpu_clock_init();</span>
<span class="p_del">-	preempt_disable();</span>
<span class="p_del">-	smp_callin();</span>
<span class="p_del">-</span>
<span class="p_del">-	enable_start_cpu0 = 0;</span>
 
 #ifdef CONFIG_X86_32
 	/* switch away from the initial page table */
<span class="p_chunk">@@ -245,6 +239,13 @@</span> <span class="p_context"> static void notrace start_secondary(void *unused)</span>
 	__flush_tlb_all();
 #endif
 
<span class="p_add">+	cpu_init();</span>
<span class="p_add">+	x86_cpuinit.early_percpu_clock_init();</span>
<span class="p_add">+	preempt_disable();</span>
<span class="p_add">+	smp_callin();</span>
<span class="p_add">+</span>
<span class="p_add">+	enable_start_cpu0 = 0;</span>
<span class="p_add">+</span>
 	/* otherwise gcc will move up smp_processor_id before the cpu_init */
 	barrier();
 	/*
<span class="p_header">diff --git a/arch/x86/kvm/emulate.c b/arch/x86/kvm/emulate.c</span>
<span class="p_header">index 16bf6655aa85..f23f13403f33 100644</span>
<span class="p_header">--- a/arch/x86/kvm/emulate.c</span>
<span class="p_header">+++ b/arch/x86/kvm/emulate.c</span>
<span class="p_chunk">@@ -5296,7 +5296,6 @@</span> <span class="p_context"> static void fetch_possible_mmx_operand(struct x86_emulate_ctxt *ctxt,</span>
 
 static int fastop(struct x86_emulate_ctxt *ctxt, void (*fop)(struct fastop *))
 {
<span class="p_del">-	register void *__sp asm(_ASM_SP);</span>
 	ulong flags = (ctxt-&gt;eflags &amp; EFLAGS_MASK) | X86_EFLAGS_IF;
 
 	if (!(ctxt-&gt;d &amp; ByteOp))
<span class="p_chunk">@@ -5304,7 +5303,7 @@</span> <span class="p_context"> static int fastop(struct x86_emulate_ctxt *ctxt, void (*fop)(struct fastop *))</span>
 
 	asm(&quot;push %[flags]; popf; call *%[fastop]; pushf; pop %[flags]\n&quot;
 	    : &quot;+a&quot;(ctxt-&gt;dst.val), &quot;+d&quot;(ctxt-&gt;src.val), [flags]&quot;+D&quot;(flags),
<span class="p_del">-	      [fastop]&quot;+S&quot;(fop), &quot;+r&quot;(__sp)</span>
<span class="p_add">+	      [fastop]&quot;+S&quot;(fop), ASM_CALL_CONSTRAINT</span>
 	    : &quot;c&quot;(ctxt-&gt;src2.val));
 
 	ctxt-&gt;eflags = (ctxt-&gt;eflags &amp; ~EFLAGS_MASK) | (flags &amp; EFLAGS_MASK);
<span class="p_header">diff --git a/arch/x86/kvm/vmx.c b/arch/x86/kvm/vmx.c</span>
<span class="p_header">index 06c0c6d0541e..6ee237f509dc 100644</span>
<span class="p_header">--- a/arch/x86/kvm/vmx.c</span>
<span class="p_header">+++ b/arch/x86/kvm/vmx.c</span>
<span class="p_chunk">@@ -9036,7 +9036,6 @@</span> <span class="p_context"> static void vmx_complete_atomic_exit(struct vcpu_vmx *vmx)</span>
 static void vmx_handle_external_intr(struct kvm_vcpu *vcpu)
 {
 	u32 exit_intr_info = vmcs_read32(VM_EXIT_INTR_INFO);
<span class="p_del">-	register void *__sp asm(_ASM_SP);</span>
 
 	if ((exit_intr_info &amp; (INTR_INFO_VALID_MASK | INTR_INFO_INTR_TYPE_MASK))
 			== (INTR_INFO_VALID_MASK | INTR_TYPE_EXT_INTR)) {
<span class="p_chunk">@@ -9065,7 +9064,7 @@</span> <span class="p_context"> static void vmx_handle_external_intr(struct kvm_vcpu *vcpu)</span>
 #ifdef CONFIG_X86_64
 			[sp]&quot;=&amp;r&quot;(tmp),
 #endif
<span class="p_del">-			&quot;+r&quot;(__sp)</span>
<span class="p_add">+			ASM_CALL_CONSTRAINT</span>
 			:
 			[entry]&quot;r&quot;(entry),
 			[ss]&quot;i&quot;(__KERNEL_DS),
<span class="p_header">diff --git a/arch/x86/mm/fault.c b/arch/x86/mm/fault.c</span>
<span class="p_header">index b836a7274e12..39567b5c33da 100644</span>
<span class="p_header">--- a/arch/x86/mm/fault.c</span>
<span class="p_header">+++ b/arch/x86/mm/fault.c</span>
<span class="p_chunk">@@ -806,7 +806,6 @@</span> <span class="p_context"> no_context(struct pt_regs *regs, unsigned long error_code,</span>
 	if (is_vmalloc_addr((void *)address) &amp;&amp;
 	    (((unsigned long)tsk-&gt;stack - 1 - address &lt; PAGE_SIZE) ||
 	     address - ((unsigned long)tsk-&gt;stack + THREAD_SIZE) &lt; PAGE_SIZE)) {
<span class="p_del">-		register void *__sp asm(&quot;rsp&quot;);</span>
 		unsigned long stack = this_cpu_read(orig_ist.ist[DOUBLEFAULT_STACK]) - sizeof(void *);
 		/*
 		 * We&#39;re likely to be running with very little stack space
<span class="p_chunk">@@ -821,7 +820,7 @@</span> <span class="p_context"> no_context(struct pt_regs *regs, unsigned long error_code,</span>
 		asm volatile (&quot;movq %[stack], %%rsp\n\t&quot;
 			      &quot;call handle_stack_overflow\n\t&quot;
 			      &quot;1: jmp 1b&quot;
<span class="p_del">-			      : &quot;+r&quot; (__sp)</span>
<span class="p_add">+			      : ASM_CALL_CONSTRAINT</span>
 			      : &quot;D&quot; (&quot;kernel stack overflow (page fault)&quot;),
 				&quot;S&quot; (regs), &quot;d&quot; (address),
 				[stack] &quot;rm&quot; (stack));
<span class="p_header">diff --git a/arch/x86/mm/tlb.c b/arch/x86/mm/tlb.c</span>
<span class="p_header">index 1ab3821f9e26..93fe97cce581 100644</span>
<span class="p_header">--- a/arch/x86/mm/tlb.c</span>
<span class="p_header">+++ b/arch/x86/mm/tlb.c</span>
<span class="p_chunk">@@ -126,8 +126,7 @@</span> <span class="p_context"> void switch_mm_irqs_off(struct mm_struct *prev, struct mm_struct *next,</span>
 	 * isn&#39;t free.
 	 */
 #ifdef CONFIG_DEBUG_VM
<span class="p_del">-	if (WARN_ON_ONCE(__read_cr3() !=</span>
<span class="p_del">-			 (__sme_pa(real_prev-&gt;pgd) | prev_asid))) {</span>
<span class="p_add">+	if (WARN_ON_ONCE(__read_cr3() != build_cr3(real_prev, prev_asid))) {</span>
 		/*
 		 * If we were to BUG here, we&#39;d be very likely to kill
 		 * the system so hard that we don&#39;t see the call trace.
<span class="p_chunk">@@ -172,7 +171,7 @@</span> <span class="p_context"> void switch_mm_irqs_off(struct mm_struct *prev, struct mm_struct *next,</span>
 			 */
 			this_cpu_write(cpu_tlbstate.ctxs[prev_asid].tlb_gen,
 				       next_tlb_gen);
<span class="p_del">-			write_cr3(__sme_pa(next-&gt;pgd) | prev_asid);</span>
<span class="p_add">+			write_cr3(build_cr3(next, prev_asid));</span>
 			trace_tlb_flush(TLB_FLUSH_ON_TASK_SWITCH,
 					TLB_FLUSH_ALL);
 		}
<span class="p_chunk">@@ -216,12 +215,12 @@</span> <span class="p_context"> void switch_mm_irqs_off(struct mm_struct *prev, struct mm_struct *next,</span>
 		if (need_flush) {
 			this_cpu_write(cpu_tlbstate.ctxs[new_asid].ctx_id, next-&gt;context.ctx_id);
 			this_cpu_write(cpu_tlbstate.ctxs[new_asid].tlb_gen, next_tlb_gen);
<span class="p_del">-			write_cr3(__sme_pa(next-&gt;pgd) | new_asid);</span>
<span class="p_add">+			write_cr3(build_cr3(next, new_asid));</span>
 			trace_tlb_flush(TLB_FLUSH_ON_TASK_SWITCH,
 					TLB_FLUSH_ALL);
 		} else {
 			/* The new ASID is already up to date. */
<span class="p_del">-			write_cr3(__sme_pa(next-&gt;pgd) | new_asid | CR3_NOFLUSH);</span>
<span class="p_add">+			write_cr3(build_cr3_noflush(next, new_asid));</span>
 			trace_tlb_flush(TLB_FLUSH_ON_TASK_SWITCH, 0);
 		}
 
<span class="p_chunk">@@ -265,7 +264,7 @@</span> <span class="p_context"> void initialize_tlbstate_and_flush(void)</span>
 		!(cr4_read_shadow() &amp; X86_CR4_PCIDE));
 
 	/* Force ASID 0 and force a TLB flush. */
<span class="p_del">-	write_cr3(cr3 &amp; ~CR3_PCID_MASK);</span>
<span class="p_add">+	write_cr3(build_cr3(mm, 0));</span>
 
 	/* Reinitialize tlbstate. */
 	this_cpu_write(cpu_tlbstate.loaded_mm_asid, 0);
<span class="p_header">diff --git a/tools/objtool/Documentation/stack-validation.txt b/tools/objtool/Documentation/stack-validation.txt</span>
<span class="p_header">index 6a1af43862df..3995735a878f 100644</span>
<span class="p_header">--- a/tools/objtool/Documentation/stack-validation.txt</span>
<span class="p_header">+++ b/tools/objtool/Documentation/stack-validation.txt</span>
<span class="p_chunk">@@ -194,10 +194,10 @@</span> <span class="p_context"> they mean, and suggestions for how to fix them.</span>
    If it&#39;s a GCC-compiled .c file, the error may be because the function
    uses an inline asm() statement which has a &quot;call&quot; instruction.  An
    asm() statement with a call instruction must declare the use of the
<span class="p_del">-   stack pointer in its output operand.  For example, on x86_64:</span>
<span class="p_add">+   stack pointer in its output operand.  On x86_64, this means adding</span>
<span class="p_add">+   the ASM_CALL_CONSTRAINT as an output constraint:</span>
 
<span class="p_del">-     register void *__sp asm(&quot;rsp&quot;);</span>
<span class="p_del">-     asm volatile(&quot;call func&quot; : &quot;+r&quot; (__sp));</span>
<span class="p_add">+     asm volatile(&quot;call func&quot; : ASM_CALL_CONSTRAINT);</span>
 
    Otherwise the stack frame may not get created before the call.
 
<span class="p_header">diff --git a/tools/objtool/arch/x86/decode.c b/tools/objtool/arch/x86/decode.c</span>
<span class="p_header">index 0e8c8ec4fd4e..0f22768c0d4d 100644</span>
<span class="p_header">--- a/tools/objtool/arch/x86/decode.c</span>
<span class="p_header">+++ b/tools/objtool/arch/x86/decode.c</span>
<span class="p_chunk">@@ -208,14 +208,14 @@</span> <span class="p_context"> int arch_decode_instruction(struct elf *elf, struct section *sec,</span>
 		break;
 
 	case 0x89:
<span class="p_del">-		if (rex == 0x48 &amp;&amp; modrm == 0xe5) {</span>
<span class="p_add">+		if (rex_w &amp;&amp; !rex_r &amp;&amp; modrm_mod == 3 &amp;&amp; modrm_reg == 4) {</span>
 
<span class="p_del">-			/* mov %rsp, %rbp */</span>
<span class="p_add">+			/* mov %rsp, reg */</span>
 			*type = INSN_STACK;
 			op-&gt;src.type = OP_SRC_REG;
 			op-&gt;src.reg = CFI_SP;
 			op-&gt;dest.type = OP_DEST_REG;
<span class="p_del">-			op-&gt;dest.reg = CFI_BP;</span>
<span class="p_add">+			op-&gt;dest.reg = op_to_cfi_reg[modrm_rm][rex_b];</span>
 			break;
 		}
 
<span class="p_header">diff --git a/tools/objtool/check.c b/tools/objtool/check.c</span>
<span class="p_header">index f744617c9946..a0c518ecf085 100644</span>
<span class="p_header">--- a/tools/objtool/check.c</span>
<span class="p_header">+++ b/tools/objtool/check.c</span>
<span class="p_chunk">@@ -1203,24 +1203,39 @@</span> <span class="p_context"> static int update_insn_state(struct instruction *insn, struct insn_state *state)</span>
 		switch (op-&gt;src.type) {
 
 		case OP_SRC_REG:
<span class="p_del">-			if (op-&gt;src.reg == CFI_SP &amp;&amp; op-&gt;dest.reg == CFI_BP) {</span>
<span class="p_add">+			if (op-&gt;src.reg == CFI_SP &amp;&amp; op-&gt;dest.reg == CFI_BP &amp;&amp;</span>
<span class="p_add">+			    cfa-&gt;base == CFI_SP &amp;&amp;</span>
<span class="p_add">+			    regs[CFI_BP].base == CFI_CFA &amp;&amp;</span>
<span class="p_add">+			    regs[CFI_BP].offset == -cfa-&gt;offset) {</span>
<span class="p_add">+</span>
<span class="p_add">+				/* mov %rsp, %rbp */</span>
<span class="p_add">+				cfa-&gt;base = op-&gt;dest.reg;</span>
<span class="p_add">+				state-&gt;bp_scratch = false;</span>
<span class="p_add">+			}</span>
 
<span class="p_del">-				if (cfa-&gt;base == CFI_SP &amp;&amp;</span>
<span class="p_del">-				    regs[CFI_BP].base == CFI_CFA &amp;&amp;</span>
<span class="p_del">-				    regs[CFI_BP].offset == -cfa-&gt;offset) {</span>
<span class="p_add">+			else if (op-&gt;src.reg == CFI_SP &amp;&amp;</span>
<span class="p_add">+				 op-&gt;dest.reg == CFI_BP &amp;&amp; state-&gt;drap) {</span>
 
<span class="p_del">-					/* mov %rsp, %rbp */</span>
<span class="p_del">-					cfa-&gt;base = op-&gt;dest.reg;</span>
<span class="p_del">-					state-&gt;bp_scratch = false;</span>
<span class="p_del">-				}</span>
<span class="p_add">+				/* drap: mov %rsp, %rbp */</span>
<span class="p_add">+				regs[CFI_BP].base = CFI_BP;</span>
<span class="p_add">+				regs[CFI_BP].offset = -state-&gt;stack_size;</span>
<span class="p_add">+				state-&gt;bp_scratch = false;</span>
<span class="p_add">+			}</span>
 
<span class="p_del">-				else if (state-&gt;drap) {</span>
<span class="p_add">+			else if (op-&gt;src.reg == CFI_SP &amp;&amp; cfa-&gt;base == CFI_SP) {</span>
 
<span class="p_del">-					/* drap: mov %rsp, %rbp */</span>
<span class="p_del">-					regs[CFI_BP].base = CFI_BP;</span>
<span class="p_del">-					regs[CFI_BP].offset = -state-&gt;stack_size;</span>
<span class="p_del">-					state-&gt;bp_scratch = false;</span>
<span class="p_del">-				}</span>
<span class="p_add">+				/*</span>
<span class="p_add">+				 * mov %rsp, %reg</span>
<span class="p_add">+				 *</span>
<span class="p_add">+				 * This is needed for the rare case where GCC</span>
<span class="p_add">+				 * does:</span>
<span class="p_add">+				 *</span>
<span class="p_add">+				 *   mov    %rsp, %rax</span>
<span class="p_add">+				 *   ...</span>
<span class="p_add">+				 *   mov    %rax, %rsp</span>
<span class="p_add">+				 */</span>
<span class="p_add">+				state-&gt;vals[op-&gt;dest.reg].base = CFI_CFA;</span>
<span class="p_add">+				state-&gt;vals[op-&gt;dest.reg].offset = -state-&gt;stack_size;</span>
 			}
 
 			else if (op-&gt;dest.reg == cfa-&gt;base) {

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



