
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>[1/2] mm: Add kernel MMU notifier to manage IOTLB/DEVTLB - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    [1/2] mm: Add kernel MMU notifier to manage IOTLB/DEVTLB</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=99681">Lu Baolu</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>Dec. 14, 2017, 1:02 a.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;1513213366-22594-2-git-send-email-baolu.lu@linux.intel.com&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/10111297/mbox/"
   >mbox</a>
|
   <a href="/patch/10111297/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/10111297/">/patch/10111297/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
	[172.30.200.125])
	by pdx-korg-patchwork.web.codeaurora.org (Postfix) with ESMTP id
	B5E0160327 for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Thu, 14 Dec 2017 01:09:05 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id A7CFA28F7D
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Thu, 14 Dec 2017 01:09:05 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id 9C12528FF2; Thu, 14 Dec 2017 01:09:05 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-6.9 required=2.0 tests=BAYES_00,RCVD_IN_DNSWL_HI
	autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id C679628F7D
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Thu, 14 Dec 2017 01:09:04 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1751803AbdLNBJA (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Wed, 13 Dec 2017 20:09:00 -0500
Received: from mga11.intel.com ([192.55.52.93]:12940 &quot;EHLO mga11.intel.com&quot;
	rhost-flags-OK-OK-OK-OK) by vger.kernel.org with ESMTP
	id S1751092AbdLNBI5 (ORCPT &lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Wed, 13 Dec 2017 20:08:57 -0500
X-Amp-Result: SKIPPED(no attachment in message)
X-Amp-File-Uploaded: False
Received: from orsmga008.jf.intel.com ([10.7.209.65])
	by fmsmga102.fm.intel.com with ESMTP/TLS/DHE-RSA-AES256-GCM-SHA384;
	13 Dec 2017 17:08:56 -0800
X-ExtLoop1: 1
X-IronPort-AV: E=Sophos;i=&quot;5.45,399,1508828400&quot;; d=&quot;scan&#39;208&quot;;a=&quot;2612184&quot;
Received: from allen-box.sh.intel.com ([10.239.161.130])
	by orsmga008.jf.intel.com with ESMTP; 13 Dec 2017 17:08:52 -0800
From: Lu Baolu &lt;baolu.lu@linux.intel.com&gt;
To: Thomas Gleixner &lt;tglx@linutronix.de&gt;, Ingo Molnar &lt;mingo@redhat.com&gt;,
	&quot;H . Peter Anvin&quot; &lt;hpa@zytor.com&gt;,
	Alex Williamson &lt;alex.williamson@redhat.com&gt;,
	Joerg Roedel &lt;joro@8bytes.org&gt;, David Woodhouse &lt;dwmw2@infradead.org&gt;
Cc: iommu@lists.linux-foundation.org, x86@kernel.org,
	linux-mm@kvack.org, linux-kernel@vger.kernel.org,
	Huang Ying &lt;ying.huang@intel.com&gt;, Ashok Raj &lt;ashok.raj@intel.com&gt;,
	Dave Hansen &lt;dave.hansen@intel.com&gt;, Andy Lutomirski &lt;luto@kernel.org&gt;,
	Rik van Riel &lt;riel@redhat.com&gt;, Kees Cook &lt;keescook@chromium.org&gt;,
	Andrew Morton &lt;akpm@linux-foundation.org&gt;,
	&quot;Kirill A . Shutemov&quot; &lt;kirill.shutemov@linux.intel.com&gt;,
	Matthew Wilcox &lt;willy@linux.intel.com&gt;,
	Dave Jiang &lt;dave.jiang@intel.com&gt;, Michal Hocko &lt;mhocko@suse.com&gt;,
	&quot;Paul E . McKenney&quot; &lt;paulmck@linux.vnet.ibm.com&gt;,
	Vegard Nossum &lt;vegard.nossum@oracle.com&gt;,
	Lu Baolu &lt;baolu.lu@linux.intel.com&gt;
Subject: [PATCH 1/2] mm: Add kernel MMU notifier to manage IOTLB/DEVTLB
Date: Thu, 14 Dec 2017 09:02:45 +0800
Message-Id: &lt;1513213366-22594-2-git-send-email-baolu.lu@linux.intel.com&gt;
X-Mailer: git-send-email 2.7.4
In-Reply-To: &lt;1513213366-22594-1-git-send-email-baolu.lu@linux.intel.com&gt;
References: &lt;1513213366-22594-1-git-send-email-baolu.lu@linux.intel.com&gt;
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=99681">Lu Baolu</a> - Dec. 14, 2017, 1:02 a.m.</div>
<pre class="content">
<span class="from">From: Huang Ying &lt;ying.huang@intel.com&gt;</span>

Shared Virtual Memory (SVM) allows a kernel memory mapping to be
shared between CPU and and a device which requested a supervisor
PASID. Both devices and IOMMU units have TLBs that cache entries
from CPU&#39;s page tables. We need to get a chance to flush them at
the same time when we flush the CPU TLBs.

We already have an existing MMU notifiers for userspace updates,
however we lack the same thing for kernel page table updates. To
implement the MMU notification mechanism for the kernel address
space, a kernel MMU notifier chain is defined and will be called
whenever the CPU TLB is flushed for the kernel address space.

As consumer of this notifier, the IOMMU SVM implementations will
register callbacks on this notifier and manage the cache entries
in both IOTLB and DevTLB.

Cc: Ashok Raj &lt;ashok.raj@intel.com&gt;
Cc: Dave Hansen &lt;dave.hansen@intel.com&gt;
Cc: Thomas Gleixner &lt;tglx@linutronix.de&gt;
Cc: Ingo Molnar &lt;mingo@redhat.com&gt;
Cc: &quot;H. Peter Anvin&quot; &lt;hpa@zytor.com&gt;
Cc: Andy Lutomirski &lt;luto@kernel.org&gt;
Cc: Rik van Riel &lt;riel@redhat.com&gt;
Cc: Kees Cook &lt;keescook@chromium.org&gt;
Cc: Andrew Morton &lt;akpm@linux-foundation.org&gt;
Cc: Kirill A. Shutemov &lt;kirill.shutemov@linux.intel.com&gt;
Cc: Matthew Wilcox &lt;willy@linux.intel.com&gt;
Cc: Dave Jiang &lt;dave.jiang@intel.com&gt;
Cc: Michal Hocko &lt;mhocko@suse.com&gt;
Cc: Paul E. McKenney &lt;paulmck@linux.vnet.ibm.com&gt;
Cc: Vegard Nossum &lt;vegard.nossum@oracle.com&gt;
Cc: x86@kernel.org
Cc: linux-mm@kvack.org
<span class="tested-by">
Tested-by: CQ Tang &lt;cq.tang@intel.com&gt;</span>
<span class="signed-off-by">Signed-off-by: Huang Ying &lt;ying.huang@intel.com&gt;</span>
<span class="signed-off-by">Signed-off-by: Lu Baolu &lt;baolu.lu@linux.intel.com&gt;</span>
---
 arch/x86/mm/tlb.c            |  2 ++
 include/linux/mmu_notifier.h | 33 +++++++++++++++++++++++++++++++++
 mm/mmu_notifier.c            | 27 +++++++++++++++++++++++++++
 3 files changed, 62 insertions(+)
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=173273">Bob Liu</a> - Dec. 14, 2017, 3:10 a.m.</div>
<pre class="content">
On 2017/12/14 9:02, Lu Baolu wrote:
<span class="quote">&gt; From: Huang Ying &lt;ying.huang@intel.com&gt;</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Shared Virtual Memory (SVM) allows a kernel memory mapping to be</span>
<span class="quote">&gt; shared between CPU and and a device which requested a supervisor</span>
<span class="quote">&gt; PASID. Both devices and IOMMU units have TLBs that cache entries</span>
<span class="quote">&gt; from CPU&#39;s page tables. We need to get a chance to flush them at</span>
<span class="quote">&gt; the same time when we flush the CPU TLBs.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; We already have an existing MMU notifiers for userspace updates,</span>
<span class="quote">&gt; however we lack the same thing for kernel page table updates. To</span>

Sorry, I didn&#39;t get which situation need this notification.
Could you please describe the full scenario?

Thanks,
Liubo
<span class="quote">
&gt; implement the MMU notification mechanism for the kernel address</span>
<span class="quote">&gt; space, a kernel MMU notifier chain is defined and will be called</span>
<span class="quote">&gt; whenever the CPU TLB is flushed for the kernel address space.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; As consumer of this notifier, the IOMMU SVM implementations will</span>
<span class="quote">&gt; register callbacks on this notifier and manage the cache entries</span>
<span class="quote">&gt; in both IOTLB and DevTLB.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Cc: Ashok Raj &lt;ashok.raj@intel.com&gt;</span>
<span class="quote">&gt; Cc: Dave Hansen &lt;dave.hansen@intel.com&gt;</span>
<span class="quote">&gt; Cc: Thomas Gleixner &lt;tglx@linutronix.de&gt;</span>
<span class="quote">&gt; Cc: Ingo Molnar &lt;mingo@redhat.com&gt;</span>
<span class="quote">&gt; Cc: &quot;H. Peter Anvin&quot; &lt;hpa@zytor.com&gt;</span>
<span class="quote">&gt; Cc: Andy Lutomirski &lt;luto@kernel.org&gt;</span>
<span class="quote">&gt; Cc: Rik van Riel &lt;riel@redhat.com&gt;</span>
<span class="quote">&gt; Cc: Kees Cook &lt;keescook@chromium.org&gt;</span>
<span class="quote">&gt; Cc: Andrew Morton &lt;akpm@linux-foundation.org&gt;</span>
<span class="quote">&gt; Cc: Kirill A. Shutemov &lt;kirill.shutemov@linux.intel.com&gt;</span>
<span class="quote">&gt; Cc: Matthew Wilcox &lt;willy@linux.intel.com&gt;</span>
<span class="quote">&gt; Cc: Dave Jiang &lt;dave.jiang@intel.com&gt;</span>
<span class="quote">&gt; Cc: Michal Hocko &lt;mhocko@suse.com&gt;</span>
<span class="quote">&gt; Cc: Paul E. McKenney &lt;paulmck@linux.vnet.ibm.com&gt;</span>
<span class="quote">&gt; Cc: Vegard Nossum &lt;vegard.nossum@oracle.com&gt;</span>
<span class="quote">&gt; Cc: x86@kernel.org</span>
<span class="quote">&gt; Cc: linux-mm@kvack.org</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Tested-by: CQ Tang &lt;cq.tang@intel.com&gt;</span>
<span class="quote">&gt; Signed-off-by: Huang Ying &lt;ying.huang@intel.com&gt;</span>
<span class="quote">&gt; Signed-off-by: Lu Baolu &lt;baolu.lu@linux.intel.com&gt;</span>
<span class="quote">&gt; ---</span>
<span class="quote">&gt;  arch/x86/mm/tlb.c            |  2 ++</span>
<span class="quote">&gt;  include/linux/mmu_notifier.h | 33 +++++++++++++++++++++++++++++++++</span>
<span class="quote">&gt;  mm/mmu_notifier.c            | 27 +++++++++++++++++++++++++++</span>
<span class="quote">&gt;  3 files changed, 62 insertions(+)</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; diff --git a/arch/x86/mm/tlb.c b/arch/x86/mm/tlb.c</span>
<span class="quote">&gt; index 3118392cd..5ff104f 100644</span>
<span class="quote">&gt; --- a/arch/x86/mm/tlb.c</span>
<span class="quote">&gt; +++ b/arch/x86/mm/tlb.c</span>
<span class="quote">&gt; @@ -6,6 +6,7 @@</span>
<span class="quote">&gt;  #include &lt;linux/interrupt.h&gt;</span>
<span class="quote">&gt;  #include &lt;linux/export.h&gt;</span>
<span class="quote">&gt;  #include &lt;linux/cpu.h&gt;</span>
<span class="quote">&gt; +#include &lt;linux/mmu_notifier.h&gt;</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  #include &lt;asm/tlbflush.h&gt;</span>
<span class="quote">&gt;  #include &lt;asm/mmu_context.h&gt;</span>
<span class="quote">&gt; @@ -567,6 +568,7 @@ void flush_tlb_kernel_range(unsigned long start, unsigned long end)</span>
<span class="quote">&gt;  		info.end = end;</span>
<span class="quote">&gt;  		on_each_cpu(do_kernel_range_flush, &amp;info, 1);</span>
<span class="quote">&gt;  	}</span>
<span class="quote">&gt; +	kernel_mmu_notifier_invalidate_range(start, end);</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  void arch_tlbbatch_flush(struct arch_tlbflush_unmap_batch *batch)</span>
<span class="quote">&gt; diff --git a/include/linux/mmu_notifier.h b/include/linux/mmu_notifier.h</span>
<span class="quote">&gt; index b25dc9d..44d7c06 100644</span>
<span class="quote">&gt; --- a/include/linux/mmu_notifier.h</span>
<span class="quote">&gt; +++ b/include/linux/mmu_notifier.h</span>
<span class="quote">&gt; @@ -408,6 +408,25 @@ extern void mmu_notifier_call_srcu(struct rcu_head *rcu,</span>
<span class="quote">&gt;  				   void (*func)(struct rcu_head *rcu));</span>
<span class="quote">&gt;  extern void mmu_notifier_synchronize(void);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; +struct kernel_mmu_address_range {</span>
<span class="quote">&gt; +	unsigned long start;</span>
<span class="quote">&gt; +	unsigned long end;</span>
<span class="quote">&gt; +};</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +/*</span>
<span class="quote">&gt; + * Before the virtual address range managed by kernel (vmalloc/kmap)</span>
<span class="quote">&gt; + * is reused, That is, remapped to the new physical addresses, the</span>
<span class="quote">&gt; + * kernel MMU notifier will be called with KERNEL_MMU_INVALIDATE_RANGE</span>
<span class="quote">&gt; + * and struct kernel_mmu_address_range as parameters.  This is used to</span>
<span class="quote">&gt; + * manage the remote TLB.</span>
<span class="quote">&gt; + */</span>
<span class="quote">&gt; +#define KERNEL_MMU_INVALIDATE_RANGE		1</span>
<span class="quote">&gt; +extern int kernel_mmu_notifier_register(struct notifier_block *nb);</span>
<span class="quote">&gt; +extern int kernel_mmu_notifier_unregister(struct notifier_block *nb);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +extern int kernel_mmu_notifier_invalidate_range(unsigned long start,</span>
<span class="quote">&gt; +						unsigned long end);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt;  #else /* CONFIG_MMU_NOTIFIER */</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  static inline int mm_has_notifiers(struct mm_struct *mm)</span>
<span class="quote">&gt; @@ -474,6 +493,20 @@ static inline void mmu_notifier_mm_destroy(struct mm_struct *mm)</span>
<span class="quote">&gt;  #define pudp_huge_clear_flush_notify pudp_huge_clear_flush</span>
<span class="quote">&gt;  #define set_pte_at_notify set_pte_at</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; +static inline int kernel_mmu_notifier_register(struct notifier_block *nb)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	return 0;</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +static inline int kernel_mmu_notifier_unregister(struct notifier_block *nb)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	return 0;</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +static inline void kernel_mmu_notifier_invalidate_range(unsigned long start,</span>
<span class="quote">&gt; +							unsigned long end)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt;  #endif /* CONFIG_MMU_NOTIFIER */</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  #endif /* _LINUX_MMU_NOTIFIER_H */</span>
<span class="quote">&gt; diff --git a/mm/mmu_notifier.c b/mm/mmu_notifier.c</span>
<span class="quote">&gt; index 96edb33..52f816a 100644</span>
<span class="quote">&gt; --- a/mm/mmu_notifier.c</span>
<span class="quote">&gt; +++ b/mm/mmu_notifier.c</span>
<span class="quote">&gt; @@ -393,3 +393,30 @@ void mmu_notifier_unregister_no_release(struct mmu_notifier *mn,</span>
<span class="quote">&gt;  	mmdrop(mm);</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;  EXPORT_SYMBOL_GPL(mmu_notifier_unregister_no_release);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +static ATOMIC_NOTIFIER_HEAD(kernel_mmu_notifier_list);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +int kernel_mmu_notifier_register(struct notifier_block *nb)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	return atomic_notifier_chain_register(&amp;kernel_mmu_notifier_list, nb);</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +EXPORT_SYMBOL_GPL(kernel_mmu_notifier_register);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +int kernel_mmu_notifier_unregister(struct notifier_block *nb)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	return atomic_notifier_chain_unregister(&amp;kernel_mmu_notifier_list, nb);</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +EXPORT_SYMBOL_GPL(kernel_mmu_notifier_unregister);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +int kernel_mmu_notifier_invalidate_range(unsigned long start,</span>
<span class="quote">&gt; +					 unsigned long end)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	struct kernel_mmu_address_range range = {</span>
<span class="quote">&gt; +		.start	= start,</span>
<span class="quote">&gt; +		.end	= end,</span>
<span class="quote">&gt; +	};</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	return atomic_notifier_call_chain(&amp;kernel_mmu_notifier_list,</span>
<span class="quote">&gt; +					  KERNEL_MMU_INVALIDATE_RANGE,</span>
<span class="quote">&gt; +					  &amp;range);</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt;</span>
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=99681">Lu Baolu</a> - Dec. 14, 2017, 3:38 a.m.</div>
<pre class="content">
Hi,

On 12/14/2017 11:10 AM, Bob Liu wrote:
<span class="quote">&gt; On 2017/12/14 9:02, Lu Baolu wrote:</span>
<span class="quote">&gt;&gt; &gt; From: Huang Ying &lt;ying.huang@intel.com&gt;</span>
<span class="quote">&gt;&gt; &gt; </span>
<span class="quote">&gt;&gt; &gt; Shared Virtual Memory (SVM) allows a kernel memory mapping to be</span>
<span class="quote">&gt;&gt; &gt; shared between CPU and and a device which requested a supervisor</span>
<span class="quote">&gt;&gt; &gt; PASID. Both devices and IOMMU units have TLBs that cache entries</span>
<span class="quote">&gt;&gt; &gt; from CPU&#39;s page tables. We need to get a chance to flush them at</span>
<span class="quote">&gt;&gt; &gt; the same time when we flush the CPU TLBs.</span>
<span class="quote">&gt;&gt; &gt; </span>
<span class="quote">&gt;&gt; &gt; We already have an existing MMU notifiers for userspace updates,</span>
<span class="quote">&gt;&gt; &gt; however we lack the same thing for kernel page table updates. To</span>
<span class="quote">&gt; Sorry, I didn&#39;t get which situation need this notification.</span>
<span class="quote">&gt; Could you please describe the full scenario?</span>

Okay.

1. When an SVM capable driver calls intel_svm_bind_mm() with
    SVM_FLAG_SUPERVISOR_MODE set in the @flags, the kernel
    memory page mappings will be shared between CPUs and
    the DMA remapping agent (a.k.a. IOMMU). The page table
    entries will also be cached in both IOTLB (located in IOMMU)
    and the DEVTLB (located in device).

2. When vmalloc/vfree interfaces are called, the page mappings
    for kernel memory might get changed. And current code calls
    flush_tlb_kernel_range() to flush CPU TLBs only. The IOTLB or
    DevTLB will be stale compared to that on the cpu for kernel
    mappings.

We need a kernel mmu notification to flush TLBs in IOMMU and
devices as well.

Best regards,
Lu Baolu
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=173273">Bob Liu</a> - Dec. 14, 2017, 6:07 a.m.</div>
<pre class="content">
On 2017/12/14 11:38, Lu Baolu wrote:
<span class="quote">&gt; Hi,</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; On 12/14/2017 11:10 AM, Bob Liu wrote:</span>
<span class="quote">&gt;&gt; On 2017/12/14 9:02, Lu Baolu wrote:</span>
<span class="quote">&gt;&gt;&gt;&gt; From: Huang Ying &lt;ying.huang@intel.com&gt;</span>
<span class="quote">&gt;&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt;&gt; Shared Virtual Memory (SVM) allows a kernel memory mapping to be</span>
<span class="quote">&gt;&gt;&gt;&gt; shared between CPU and and a device which requested a supervisor</span>
<span class="quote">&gt;&gt;&gt;&gt; PASID. Both devices and IOMMU units have TLBs that cache entries</span>
<span class="quote">&gt;&gt;&gt;&gt; from CPU&#39;s page tables. We need to get a chance to flush them at</span>
<span class="quote">&gt;&gt;&gt;&gt; the same time when we flush the CPU TLBs.</span>
<span class="quote">&gt;&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt;&gt; We already have an existing MMU notifiers for userspace updates,</span>
<span class="quote">&gt;&gt;&gt;&gt; however we lack the same thing for kernel page table updates. To</span>
<span class="quote">&gt;&gt; Sorry, I didn&#39;t get which situation need this notification.</span>
<span class="quote">&gt;&gt; Could you please describe the full scenario?</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Okay.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; 1. When an SVM capable driver calls intel_svm_bind_mm() with</span>
<span class="quote">&gt;     SVM_FLAG_SUPERVISOR_MODE set in the @flags, the kernel</span>
<span class="quote">&gt;     memory page mappings will be shared between CPUs and</span>
<span class="quote">&gt;     the DMA remapping agent (a.k.a. IOMMU). The page table</span>
<span class="quote">&gt;     entries will also be cached in both IOTLB (located in IOMMU)</span>
<span class="quote">&gt;     and the DEVTLB (located in device).</span>
<span class="quote">&gt; </span>

But who/what kind of real device has the requirement to access a kernel VA?
Looks like SVM_FLAG_SUPERVISOR_MODE is used by nobody?

Cheers,
Liubo
<span class="quote">
&gt; 2. When vmalloc/vfree interfaces are called, the page mappings</span>
<span class="quote">&gt;     for kernel memory might get changed. And current code calls</span>
<span class="quote">&gt;     flush_tlb_kernel_range() to flush CPU TLBs only. The IOTLB or</span>
<span class="quote">&gt;     DevTLB will be stale compared to that on the cpu for kernel</span>
<span class="quote">&gt;     mappings.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; We need a kernel mmu notification to flush TLBs in IOMMU and</span>
<span class="quote">&gt; devices as well.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Best regards,</span>
<span class="quote">&gt; Lu Baolu</span>
<span class="quote">&gt;</span>
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=65121">Dave Hansen</a> - Dec. 14, 2017, 6:28 a.m.</div>
<pre class="content">
On 12/13/2017 07:38 PM, Lu Baolu wrote:
<span class="quote">&gt; 2. When vmalloc/vfree interfaces are called, the page mappings</span>
<span class="quote">&gt;     for kernel memory might get changed. And current code calls</span>
<span class="quote">&gt;     flush_tlb_kernel_range() to flush CPU TLBs only. The IOTLB or</span>
<span class="quote">&gt;     DevTLB will be stale compared to that on the cpu for kernel</span>
<span class="quote">&gt;     mappings.</span>

What&#39;s the plan to deal with all of the ways other than vmalloc() that
the kernel changes the page tables?
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=294">Huang Ying</a> - Dec. 14, 2017, 6:43 a.m.</div>
<pre class="content">
Hi, Dave,

Dave Hansen &lt;dave.hansen@intel.com&gt; writes:
<span class="quote">
&gt; On 12/13/2017 07:38 PM, Lu Baolu wrote:</span>
<span class="quote">&gt;&gt; 2. When vmalloc/vfree interfaces are called, the page mappings</span>
<span class="quote">&gt;&gt;     for kernel memory might get changed. And current code calls</span>
<span class="quote">&gt;&gt;     flush_tlb_kernel_range() to flush CPU TLBs only. The IOTLB or</span>
<span class="quote">&gt;&gt;     DevTLB will be stale compared to that on the cpu for kernel</span>
<span class="quote">&gt;&gt;     mappings.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; What&#39;s the plan to deal with all of the ways other than vmalloc() that</span>
<span class="quote">&gt; the kernel changes the page tables?</span>

The kernel MMU notifier is called in flush_tlb_kernel_range().  So IOMMU
will be notified for TLB flushing caused by all ways that the kernel
changes the page tables including vmalloc, kmap, etc.

Best Regards,
Huang, Ying
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=133401">Ashok Raj</a> - Dec. 15, 2017, 3:08 a.m.</div>
<pre class="content">
Hi Bob

On Thu, Dec 14, 2017 at 02:07:38PM +0800, Bob Liu wrote:
<span class="quote">&gt; On 2017/12/14 11:38, Lu Baolu wrote:</span>
<span class="quote">
&gt; &gt;&gt;&gt;&gt; We already have an existing MMU notifiers for userspace updates,</span>
<span class="quote">&gt; &gt;&gt;&gt;&gt; however we lack the same thing for kernel page table updates. To</span>
<span class="quote">&gt; &gt;&gt; Sorry, I didn&#39;t get which situation need this notification.</span>
<span class="quote">&gt; &gt;&gt; Could you please describe the full scenario?</span>
<span class="quote">&gt; &gt; </span>
<span class="quote">&gt; &gt; Okay.</span>
<span class="quote">&gt; &gt; </span>
<span class="quote">&gt; &gt; 1. When an SVM capable driver calls intel_svm_bind_mm() with</span>
<span class="quote">&gt; &gt;     SVM_FLAG_SUPERVISOR_MODE set in the @flags, the kernel</span>
<span class="quote">&gt; &gt;     memory page mappings will be shared between CPUs and</span>
<span class="quote">&gt; &gt;     the DMA remapping agent (a.k.a. IOMMU). The page table</span>
<span class="quote">&gt; &gt;     entries will also be cached in both IOTLB (located in IOMMU)</span>
<span class="quote">&gt; &gt;     and the DEVTLB (located in device).</span>
<span class="quote">&gt; &gt; </span>
<span class="quote">&gt; </span>
<span class="quote">&gt; But who/what kind of real device has the requirement to access a kernel VA?</span>
<span class="quote">&gt; Looks like SVM_FLAG_SUPERVISOR_MODE is used by nobody?</span>

That&#39;s right, there is no inkernel user at the moment, but we certainly see
them coming.

Maybe not the best example :-), but I&#39;m told Lustre and some of the 
modern NIC&#39;s also can benefit from SVM in kernel use.

Not a hypothetical use case certainly!


Cheers,
Ashok
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/arch/x86/mm/tlb.c b/arch/x86/mm/tlb.c</span>
<span class="p_header">index 3118392cd..5ff104f 100644</span>
<span class="p_header">--- a/arch/x86/mm/tlb.c</span>
<span class="p_header">+++ b/arch/x86/mm/tlb.c</span>
<span class="p_chunk">@@ -6,6 +6,7 @@</span> <span class="p_context"></span>
 #include &lt;linux/interrupt.h&gt;
 #include &lt;linux/export.h&gt;
 #include &lt;linux/cpu.h&gt;
<span class="p_add">+#include &lt;linux/mmu_notifier.h&gt;</span>
 
 #include &lt;asm/tlbflush.h&gt;
 #include &lt;asm/mmu_context.h&gt;
<span class="p_chunk">@@ -567,6 +568,7 @@</span> <span class="p_context"> void flush_tlb_kernel_range(unsigned long start, unsigned long end)</span>
 		info.end = end;
 		on_each_cpu(do_kernel_range_flush, &amp;info, 1);
 	}
<span class="p_add">+	kernel_mmu_notifier_invalidate_range(start, end);</span>
 }
 
 void arch_tlbbatch_flush(struct arch_tlbflush_unmap_batch *batch)
<span class="p_header">diff --git a/include/linux/mmu_notifier.h b/include/linux/mmu_notifier.h</span>
<span class="p_header">index b25dc9d..44d7c06 100644</span>
<span class="p_header">--- a/include/linux/mmu_notifier.h</span>
<span class="p_header">+++ b/include/linux/mmu_notifier.h</span>
<span class="p_chunk">@@ -408,6 +408,25 @@</span> <span class="p_context"> extern void mmu_notifier_call_srcu(struct rcu_head *rcu,</span>
 				   void (*func)(struct rcu_head *rcu));
 extern void mmu_notifier_synchronize(void);
 
<span class="p_add">+struct kernel_mmu_address_range {</span>
<span class="p_add">+	unsigned long start;</span>
<span class="p_add">+	unsigned long end;</span>
<span class="p_add">+};</span>
<span class="p_add">+</span>
<span class="p_add">+/*</span>
<span class="p_add">+ * Before the virtual address range managed by kernel (vmalloc/kmap)</span>
<span class="p_add">+ * is reused, That is, remapped to the new physical addresses, the</span>
<span class="p_add">+ * kernel MMU notifier will be called with KERNEL_MMU_INVALIDATE_RANGE</span>
<span class="p_add">+ * and struct kernel_mmu_address_range as parameters.  This is used to</span>
<span class="p_add">+ * manage the remote TLB.</span>
<span class="p_add">+ */</span>
<span class="p_add">+#define KERNEL_MMU_INVALIDATE_RANGE		1</span>
<span class="p_add">+extern int kernel_mmu_notifier_register(struct notifier_block *nb);</span>
<span class="p_add">+extern int kernel_mmu_notifier_unregister(struct notifier_block *nb);</span>
<span class="p_add">+</span>
<span class="p_add">+extern int kernel_mmu_notifier_invalidate_range(unsigned long start,</span>
<span class="p_add">+						unsigned long end);</span>
<span class="p_add">+</span>
 #else /* CONFIG_MMU_NOTIFIER */
 
 static inline int mm_has_notifiers(struct mm_struct *mm)
<span class="p_chunk">@@ -474,6 +493,20 @@</span> <span class="p_context"> static inline void mmu_notifier_mm_destroy(struct mm_struct *mm)</span>
 #define pudp_huge_clear_flush_notify pudp_huge_clear_flush
 #define set_pte_at_notify set_pte_at
 
<span class="p_add">+static inline int kernel_mmu_notifier_register(struct notifier_block *nb)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return 0;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline int kernel_mmu_notifier_unregister(struct notifier_block *nb)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return 0;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline void kernel_mmu_notifier_invalidate_range(unsigned long start,</span>
<span class="p_add">+							unsigned long end)</span>
<span class="p_add">+{</span>
<span class="p_add">+}</span>
 #endif /* CONFIG_MMU_NOTIFIER */
 
 #endif /* _LINUX_MMU_NOTIFIER_H */
<span class="p_header">diff --git a/mm/mmu_notifier.c b/mm/mmu_notifier.c</span>
<span class="p_header">index 96edb33..52f816a 100644</span>
<span class="p_header">--- a/mm/mmu_notifier.c</span>
<span class="p_header">+++ b/mm/mmu_notifier.c</span>
<span class="p_chunk">@@ -393,3 +393,30 @@</span> <span class="p_context"> void mmu_notifier_unregister_no_release(struct mmu_notifier *mn,</span>
 	mmdrop(mm);
 }
 EXPORT_SYMBOL_GPL(mmu_notifier_unregister_no_release);
<span class="p_add">+</span>
<span class="p_add">+static ATOMIC_NOTIFIER_HEAD(kernel_mmu_notifier_list);</span>
<span class="p_add">+</span>
<span class="p_add">+int kernel_mmu_notifier_register(struct notifier_block *nb)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return atomic_notifier_chain_register(&amp;kernel_mmu_notifier_list, nb);</span>
<span class="p_add">+}</span>
<span class="p_add">+EXPORT_SYMBOL_GPL(kernel_mmu_notifier_register);</span>
<span class="p_add">+</span>
<span class="p_add">+int kernel_mmu_notifier_unregister(struct notifier_block *nb)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return atomic_notifier_chain_unregister(&amp;kernel_mmu_notifier_list, nb);</span>
<span class="p_add">+}</span>
<span class="p_add">+EXPORT_SYMBOL_GPL(kernel_mmu_notifier_unregister);</span>
<span class="p_add">+</span>
<span class="p_add">+int kernel_mmu_notifier_invalidate_range(unsigned long start,</span>
<span class="p_add">+					 unsigned long end)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct kernel_mmu_address_range range = {</span>
<span class="p_add">+		.start	= start,</span>
<span class="p_add">+		.end	= end,</span>
<span class="p_add">+	};</span>
<span class="p_add">+</span>
<span class="p_add">+	return atomic_notifier_call_chain(&amp;kernel_mmu_notifier_list,</span>
<span class="p_add">+					  KERNEL_MMU_INVALIDATE_RANGE,</span>
<span class="p_add">+					  &amp;range);</span>
<span class="p_add">+}</span>

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



