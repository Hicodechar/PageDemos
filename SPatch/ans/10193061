
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>[v2,2/3] mm: memfd: split out memfd for use by multiple filesystems - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    [v2,2/3] mm: memfd: split out memfd for use by multiple filesystems</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=124511">Mike Kravetz</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>Jan. 31, 2018, 2:29 a.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;20180131022911.23947-3-mike.kravetz@oracle.com&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/10193061/mbox/"
   >mbox</a>
|
   <a href="/patch/10193061/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/10193061/">/patch/10193061/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
	[172.30.200.125])
	by pdx-korg-patchwork.web.codeaurora.org (Postfix) with ESMTP id
	A2A3360383 for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Wed, 31 Jan 2018 02:34:24 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 9189F268AE
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Wed, 31 Jan 2018 02:34:24 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id 8310128426; Wed, 31 Jan 2018 02:34:24 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-7.0 required=2.0 tests=BAYES_00,DKIM_SIGNED,
	DKIM_VALID, DKIM_VALID_AU, RCVD_IN_DNSWL_HI,
	UNPARSEABLE_RELAY autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 883D2268AE
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Wed, 31 Jan 2018 02:34:23 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1753359AbeAaCeS (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Tue, 30 Jan 2018 21:34:18 -0500
Received: from userp2120.oracle.com ([156.151.31.85]:60230 &quot;EHLO
	userp2120.oracle.com&quot; rhost-flags-OK-OK-OK-OK) by vger.kernel.org
	with ESMTP id S1751717AbeAaCeQ (ORCPT
	&lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Tue, 30 Jan 2018 21:34:16 -0500
Received: from pps.filterd (userp2120.oracle.com [127.0.0.1])
	by userp2120.oracle.com (8.16.0.22/8.16.0.22) with SMTP id
	w0V2WE29004041; Wed, 31 Jan 2018 02:34:09 GMT
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed; d=oracle.com;
	h=from : to : cc :
	subject : date : message-id : in-reply-to : references;
	s=corp-2017-10-26; 
	bh=A0/w+6hvDQsMY5Kdqzrf7SpoE+jhQN/IiGPh3a/7yjM=;
	b=Fu5+ZXv9aMD5PvqrNHqGH2uf3m1G4kbfgI/1lixE4v62Vls3Lt6Z+tqSmtzDeiXnYRne
	zuqQdUxpxLwaA1Ik/qUTIvefe34qqmzdUekjUI39Nk4vXCGxhE2yToHQ+fxwT+ODc1+x
	qkPZt+NuUZgJ8qQaFRBW2yDGHKGgpLzESGajJ1CYfjzbMGBHUQ7vF6IoQnH2XXcVhk0S
	Y5zFIh57Cy7wR0Uo2xFZGiv1nbnfRWo4hgC50dXHYUVK1xxSu763SHONCiCWFyRpB3p4
	9QrFdaC4dhCvEHr6MTXNKhaxOcRiG+peTUXX8QMnziN/WZzZ8aJeIV3d2u6PeuYB7GW5
	Qg== 
Received: from userv0021.oracle.com (userv0021.oracle.com [156.151.31.71])
	by userp2120.oracle.com with ESMTP id 2fu11frtkj-1
	(version=TLSv1.2 cipher=ECDHE-RSA-AES256-GCM-SHA384 bits=256
	verify=OK); Wed, 31 Jan 2018 02:34:07 +0000
Received: from aserv0122.oracle.com (aserv0122.oracle.com [141.146.126.236])
	by userv0021.oracle.com (8.14.4/8.14.4) with ESMTP id
	w0V2TTBC004395
	(version=TLSv1/SSLv3 cipher=DHE-RSA-AES256-GCM-SHA384 bits=256
	verify=FAIL); Wed, 31 Jan 2018 02:29:30 GMT
Received: from abhmp0010.oracle.com (abhmp0010.oracle.com [141.146.116.16])
	by aserv0122.oracle.com (8.14.4/8.14.4) with ESMTP id
	w0V2TTtQ022468; Wed, 31 Jan 2018 02:29:29 GMT
Received: from monkey.oracle.com (/98.246.252.205)
	by default (Oracle Beehive Gateway v4.0)
	with ESMTP ; Tue, 30 Jan 2018 18:29:29 -0800
From: Mike Kravetz &lt;mike.kravetz@oracle.com&gt;
To: linux-mm@kvack.org, linux-kernel@vger.kernel.org
Cc: Hugh Dickins &lt;hughd@google.com&gt;, Andrea Arcangeli &lt;aarcange@redhat.com&gt;,
	Michal Hocko &lt;mhocko@kernel.org&gt;,
	=?UTF-8?q?Marc-Andr=C3=A9=20Lureau?= &lt;marcandre.lureau@gmail.com&gt;,
	David Herrmann &lt;dh.herrmann@gmail.com&gt;,
	Khalid Aziz &lt;khalid.aziz@oracle.com&gt;,
	Andrew Morton &lt;akpm@linux-foundation.org&gt;,
	Mike Kravetz &lt;mike.kravetz@oracle.com&gt;
Subject: [PATCH v2 2/3] mm: memfd: split out memfd for use by multiple
	filesystems
Date: Tue, 30 Jan 2018 18:29:10 -0800
Message-Id: &lt;20180131022911.23947-3-mike.kravetz@oracle.com&gt;
X-Mailer: git-send-email 2.13.6
In-Reply-To: &lt;20180131022911.23947-1-mike.kravetz@oracle.com&gt;
References: &lt;20180131022911.23947-1-mike.kravetz@oracle.com&gt;
X-Proofpoint-Virus-Version: vendor=nai engine=5900 definitions=8790
	signatures=668657
X-Proofpoint-Spam-Details: rule=notspam policy=default score=0
	suspectscore=0 malwarescore=0
	phishscore=0 bulkscore=0 spamscore=0 mlxscore=0 mlxlogscore=999
	adultscore=0 classifier=spam adjust=0 reason=mlx scancount=1
	engine=8.0.1-1711220000 definitions=main-1801310029
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=124511">Mike Kravetz</a> - Jan. 31, 2018, 2:29 a.m.</div>
<pre class="content">
When memfd_create support was originally written, it only provided
support for tmpfs.  Hence, the code was added to files providing
tmpfs functionality and build when CONFIG_TMPFS was enabled.

memfd support has recently been added for hugetlbfs.  In an effort
to make it depend on tmpfs -or- hugetlbfs, split out the required
memfd code to separate files.

While moving code, fixed sparse warnings that existed in the
original code to keep kbuild test robot happy.

These files are not used until a subsequent patch which deletes
duplicate code in the orifinal files and enables their use.
<span class="signed-off-by">
Signed-off-by: Mike Kravetz &lt;mike.kravetz@oracle.com&gt;</span>
---
 include/linux/memfd.h |  16 +++
 mm/memfd.c            | 342 ++++++++++++++++++++++++++++++++++++++++++++++++++
 2 files changed, 358 insertions(+)
 create mode 100644 include/linux/memfd.h
 create mode 100644 mm/memfd.c
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/include/linux/memfd.h b/include/linux/memfd.h</span>
new file mode 100644
<span class="p_header">index 000000000000..4f1600413f91</span>
<span class="p_header">--- /dev/null</span>
<span class="p_header">+++ b/include/linux/memfd.h</span>
<span class="p_chunk">@@ -0,0 +1,16 @@</span> <span class="p_context"></span>
<span class="p_add">+/* SPDX-License-Identifier: GPL-2.0 */</span>
<span class="p_add">+#ifndef __LINUX_MEMFD_H</span>
<span class="p_add">+#define __LINUX_MEMFD_H</span>
<span class="p_add">+</span>
<span class="p_add">+#include &lt;linux/file.h&gt;</span>
<span class="p_add">+</span>
<span class="p_add">+#ifdef CONFIG_MEMFD_CREATE</span>
<span class="p_add">+extern long memfd_fcntl(struct file *file, unsigned int cmd, unsigned long arg);</span>
<span class="p_add">+#else</span>
<span class="p_add">+static inline long memfd_fcntl(struct file *f, unsigned int c, unsigned long a)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return -EINVAL;</span>
<span class="p_add">+}</span>
<span class="p_add">+#endif</span>
<span class="p_add">+</span>
<span class="p_add">+#endif /* __LINUX_MEMFD_H */</span>
<span class="p_header">diff --git a/mm/memfd.c b/mm/memfd.c</span>
new file mode 100644
<span class="p_header">index 000000000000..c913fbfa094a</span>
<span class="p_header">--- /dev/null</span>
<span class="p_header">+++ b/mm/memfd.c</span>
<span class="p_chunk">@@ -0,0 +1,342 @@</span> <span class="p_context"></span>
<span class="p_add">+/*</span>
<span class="p_add">+ * memfd_create system call and file sealing support</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * Code was originally included in shmem.c, and broken out to facilitate</span>
<span class="p_add">+ * use by hugetlbfs as well as tmpfs.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * This file is released under the GPL.</span>
<span class="p_add">+ */</span>
<span class="p_add">+</span>
<span class="p_add">+#include &lt;linux/fs.h&gt;</span>
<span class="p_add">+#include &lt;linux/vfs.h&gt;</span>
<span class="p_add">+#include &lt;linux/pagemap.h&gt;</span>
<span class="p_add">+#include &lt;linux/file.h&gt;</span>
<span class="p_add">+#include &lt;linux/mm.h&gt;</span>
<span class="p_add">+#include &lt;linux/sched/signal.h&gt;</span>
<span class="p_add">+#include &lt;linux/khugepaged.h&gt;</span>
<span class="p_add">+#include &lt;linux/syscalls.h&gt;</span>
<span class="p_add">+#include &lt;linux/hugetlb.h&gt;</span>
<span class="p_add">+#include &lt;linux/shmem_fs.h&gt;</span>
<span class="p_add">+#include &lt;linux/memfd.h&gt;</span>
<span class="p_add">+#include &lt;uapi/linux/memfd.h&gt;</span>
<span class="p_add">+</span>
<span class="p_add">+/*</span>
<span class="p_add">+ * We need a tag: a new tag would expand every radix_tree_node by 8 bytes,</span>
<span class="p_add">+ * so reuse a tag which we firmly believe is never set or cleared on shmem.</span>
<span class="p_add">+ */</span>
<span class="p_add">+#define SHMEM_TAG_PINNED        PAGECACHE_TAG_TOWRITE</span>
<span class="p_add">+#define LAST_SCAN               4       /* about 150ms max */</span>
<span class="p_add">+</span>
<span class="p_add">+static void shmem_tag_pins(struct address_space *mapping)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct radix_tree_iter iter;</span>
<span class="p_add">+	void __rcu **slot;</span>
<span class="p_add">+	pgoff_t start;</span>
<span class="p_add">+	struct page *page;</span>
<span class="p_add">+</span>
<span class="p_add">+	lru_add_drain();</span>
<span class="p_add">+	start = 0;</span>
<span class="p_add">+	rcu_read_lock();</span>
<span class="p_add">+</span>
<span class="p_add">+	radix_tree_for_each_slot(slot, &amp;mapping-&gt;page_tree, &amp;iter, start) {</span>
<span class="p_add">+		page = radix_tree_deref_slot(slot);</span>
<span class="p_add">+		if (!page || radix_tree_exception(page)) {</span>
<span class="p_add">+			if (radix_tree_deref_retry(page)) {</span>
<span class="p_add">+				slot = radix_tree_iter_retry(&amp;iter);</span>
<span class="p_add">+				continue;</span>
<span class="p_add">+			}</span>
<span class="p_add">+		} else if (page_count(page) - page_mapcount(page) &gt; 1) {</span>
<span class="p_add">+			spin_lock_irq(&amp;mapping-&gt;tree_lock);</span>
<span class="p_add">+			radix_tree_tag_set(&amp;mapping-&gt;page_tree, iter.index,</span>
<span class="p_add">+					   SHMEM_TAG_PINNED);</span>
<span class="p_add">+			spin_unlock_irq(&amp;mapping-&gt;tree_lock);</span>
<span class="p_add">+		}</span>
<span class="p_add">+</span>
<span class="p_add">+		if (need_resched()) {</span>
<span class="p_add">+			slot = radix_tree_iter_resume(slot, &amp;iter);</span>
<span class="p_add">+			cond_resched_rcu();</span>
<span class="p_add">+		}</span>
<span class="p_add">+	}</span>
<span class="p_add">+	rcu_read_unlock();</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+/*</span>
<span class="p_add">+ * Setting SEAL_WRITE requires us to verify there&#39;s no pending writer. However,</span>
<span class="p_add">+ * via get_user_pages(), drivers might have some pending I/O without any active</span>
<span class="p_add">+ * user-space mappings (eg., direct-IO, AIO). Therefore, we look at all pages</span>
<span class="p_add">+ * and see whether it has an elevated ref-count. If so, we tag them and wait for</span>
<span class="p_add">+ * them to be dropped.</span>
<span class="p_add">+ * The caller must guarantee that no new user will acquire writable references</span>
<span class="p_add">+ * to those pages to avoid races.</span>
<span class="p_add">+ */</span>
<span class="p_add">+static int shmem_wait_for_pins(struct address_space *mapping)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct radix_tree_iter iter;</span>
<span class="p_add">+	void __rcu **slot;</span>
<span class="p_add">+	pgoff_t start;</span>
<span class="p_add">+	struct page *page;</span>
<span class="p_add">+	int error, scan;</span>
<span class="p_add">+</span>
<span class="p_add">+	shmem_tag_pins(mapping);</span>
<span class="p_add">+</span>
<span class="p_add">+	error = 0;</span>
<span class="p_add">+	for (scan = 0; scan &lt;= LAST_SCAN; scan++) {</span>
<span class="p_add">+		if (!radix_tree_tagged(&amp;mapping-&gt;page_tree, SHMEM_TAG_PINNED))</span>
<span class="p_add">+			break;</span>
<span class="p_add">+</span>
<span class="p_add">+		if (!scan)</span>
<span class="p_add">+			lru_add_drain_all();</span>
<span class="p_add">+		else if (schedule_timeout_killable((HZ &lt;&lt; scan) / 200))</span>
<span class="p_add">+			scan = LAST_SCAN;</span>
<span class="p_add">+</span>
<span class="p_add">+		start = 0;</span>
<span class="p_add">+		rcu_read_lock();</span>
<span class="p_add">+		radix_tree_for_each_tagged(slot, &amp;mapping-&gt;page_tree, &amp;iter,</span>
<span class="p_add">+					   start, SHMEM_TAG_PINNED) {</span>
<span class="p_add">+</span>
<span class="p_add">+			page = radix_tree_deref_slot(slot);</span>
<span class="p_add">+			if (radix_tree_exception(page)) {</span>
<span class="p_add">+				if (radix_tree_deref_retry(page)) {</span>
<span class="p_add">+					slot = radix_tree_iter_retry(&amp;iter);</span>
<span class="p_add">+					continue;</span>
<span class="p_add">+				}</span>
<span class="p_add">+</span>
<span class="p_add">+				page = NULL;</span>
<span class="p_add">+			}</span>
<span class="p_add">+</span>
<span class="p_add">+			if (page &amp;&amp;</span>
<span class="p_add">+			    page_count(page) - page_mapcount(page) != 1) {</span>
<span class="p_add">+				if (scan &lt; LAST_SCAN)</span>
<span class="p_add">+					goto continue_resched;</span>
<span class="p_add">+</span>
<span class="p_add">+				/*</span>
<span class="p_add">+				 * On the last scan, we clean up all those tags</span>
<span class="p_add">+				 * we inserted; but make a note that we still</span>
<span class="p_add">+				 * found pages pinned.</span>
<span class="p_add">+				 */</span>
<span class="p_add">+				error = -EBUSY;</span>
<span class="p_add">+			}</span>
<span class="p_add">+</span>
<span class="p_add">+			spin_lock_irq(&amp;mapping-&gt;tree_lock);</span>
<span class="p_add">+			radix_tree_tag_clear(&amp;mapping-&gt;page_tree,</span>
<span class="p_add">+					     iter.index, SHMEM_TAG_PINNED);</span>
<span class="p_add">+			spin_unlock_irq(&amp;mapping-&gt;tree_lock);</span>
<span class="p_add">+continue_resched:</span>
<span class="p_add">+			if (need_resched()) {</span>
<span class="p_add">+				slot = radix_tree_iter_resume(slot, &amp;iter);</span>
<span class="p_add">+				cond_resched_rcu();</span>
<span class="p_add">+			}</span>
<span class="p_add">+		}</span>
<span class="p_add">+		rcu_read_unlock();</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	return error;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static unsigned int *memfd_file_seals_ptr(struct file *file)</span>
<span class="p_add">+{</span>
<span class="p_add">+	if (shmem_file(file))</span>
<span class="p_add">+		return &amp;SHMEM_I(file_inode(file))-&gt;seals;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (is_file_hugepages(file))</span>
<span class="p_add">+		return &amp;HUGETLBFS_I(file_inode(file))-&gt;seals;</span>
<span class="p_add">+</span>
<span class="p_add">+	return NULL;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+#define F_ALL_SEALS (F_SEAL_SEAL | \</span>
<span class="p_add">+		     F_SEAL_SHRINK | \</span>
<span class="p_add">+		     F_SEAL_GROW | \</span>
<span class="p_add">+		     F_SEAL_WRITE)</span>
<span class="p_add">+</span>
<span class="p_add">+static int memfd_add_seals(struct file *file, unsigned int seals)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct inode *inode = file_inode(file);</span>
<span class="p_add">+	unsigned int *file_seals;</span>
<span class="p_add">+	int error;</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * SEALING</span>
<span class="p_add">+	 * Sealing allows multiple parties to share a tmpfs or hugetlbfs file</span>
<span class="p_add">+	 * but restrict access to a specific subset of file operations. Seals</span>
<span class="p_add">+	 * can only be added, but never removed. This way, mutually untrusted</span>
<span class="p_add">+	 * parties can share common memory regions with a well-defined policy.</span>
<span class="p_add">+	 * A malicious peer can thus never perform unwanted operations on a</span>
<span class="p_add">+	 * shared object.</span>
<span class="p_add">+	 *</span>
<span class="p_add">+	 * Seals are only supported on special tmpfs or hugetlbfs files and</span>
<span class="p_add">+	 * always affect the whole underlying inode. Once a seal is set, it</span>
<span class="p_add">+	 * may prevent some kinds of access to the file. Currently, the</span>
<span class="p_add">+	 * following seals are defined:</span>
<span class="p_add">+	 *   SEAL_SEAL: Prevent further seals from being set on this file</span>
<span class="p_add">+	 *   SEAL_SHRINK: Prevent the file from shrinking</span>
<span class="p_add">+	 *   SEAL_GROW: Prevent the file from growing</span>
<span class="p_add">+	 *   SEAL_WRITE: Prevent write access to the file</span>
<span class="p_add">+	 *</span>
<span class="p_add">+	 * As we don&#39;t require any trust relationship between two parties, we</span>
<span class="p_add">+	 * must prevent seals from being removed. Therefore, sealing a file</span>
<span class="p_add">+	 * only adds a given set of seals to the file, it never touches</span>
<span class="p_add">+	 * existing seals. Furthermore, the &quot;setting seals&quot;-operation can be</span>
<span class="p_add">+	 * sealed itself, which basically prevents any further seal from being</span>
<span class="p_add">+	 * added.</span>
<span class="p_add">+	 *</span>
<span class="p_add">+	 * Semantics of sealing are only defined on volatile files. Only</span>
<span class="p_add">+	 * anonymous tmpfs and hugetlbfs files support sealing. More</span>
<span class="p_add">+	 * importantly, seals are never written to disk. Therefore, there&#39;s</span>
<span class="p_add">+	 * no plan to support it on other file types.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+</span>
<span class="p_add">+	if (!(file-&gt;f_mode &amp; FMODE_WRITE))</span>
<span class="p_add">+		return -EPERM;</span>
<span class="p_add">+	if (seals &amp; ~(unsigned int)F_ALL_SEALS)</span>
<span class="p_add">+		return -EINVAL;</span>
<span class="p_add">+</span>
<span class="p_add">+	inode_lock(inode);</span>
<span class="p_add">+</span>
<span class="p_add">+	file_seals = memfd_file_seals_ptr(file);</span>
<span class="p_add">+	if (!file_seals) {</span>
<span class="p_add">+		error = -EINVAL;</span>
<span class="p_add">+		goto unlock;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	if (*file_seals &amp; F_SEAL_SEAL) {</span>
<span class="p_add">+		error = -EPERM;</span>
<span class="p_add">+		goto unlock;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	if ((seals &amp; F_SEAL_WRITE) &amp;&amp; !(*file_seals &amp; F_SEAL_WRITE)) {</span>
<span class="p_add">+		error = mapping_deny_writable(file-&gt;f_mapping);</span>
<span class="p_add">+		if (error)</span>
<span class="p_add">+			goto unlock;</span>
<span class="p_add">+</span>
<span class="p_add">+		error = shmem_wait_for_pins(file-&gt;f_mapping);</span>
<span class="p_add">+		if (error) {</span>
<span class="p_add">+			mapping_allow_writable(file-&gt;f_mapping);</span>
<span class="p_add">+			goto unlock;</span>
<span class="p_add">+		}</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	*file_seals |= seals;</span>
<span class="p_add">+	error = 0;</span>
<span class="p_add">+</span>
<span class="p_add">+unlock:</span>
<span class="p_add">+	inode_unlock(inode);</span>
<span class="p_add">+	return error;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static int memfd_get_seals(struct file *file)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned int *seals = memfd_file_seals_ptr(file);</span>
<span class="p_add">+</span>
<span class="p_add">+	return seals ? *seals : -EINVAL;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+long memfd_fcntl(struct file *file, unsigned int cmd, unsigned long arg)</span>
<span class="p_add">+{</span>
<span class="p_add">+	long error;</span>
<span class="p_add">+</span>
<span class="p_add">+	switch (cmd) {</span>
<span class="p_add">+	case F_ADD_SEALS:</span>
<span class="p_add">+		/* disallow upper 32bit */</span>
<span class="p_add">+		if (arg &gt; UINT_MAX)</span>
<span class="p_add">+			return -EINVAL;</span>
<span class="p_add">+</span>
<span class="p_add">+		error = memfd_add_seals(file, arg);</span>
<span class="p_add">+		break;</span>
<span class="p_add">+	case F_GET_SEALS:</span>
<span class="p_add">+		error = memfd_get_seals(file);</span>
<span class="p_add">+		break;</span>
<span class="p_add">+	default:</span>
<span class="p_add">+		error = -EINVAL;</span>
<span class="p_add">+		break;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	return error;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+#define MFD_NAME_PREFIX &quot;memfd:&quot;</span>
<span class="p_add">+#define MFD_NAME_PREFIX_LEN (sizeof(MFD_NAME_PREFIX) - 1)</span>
<span class="p_add">+#define MFD_NAME_MAX_LEN (NAME_MAX - MFD_NAME_PREFIX_LEN)</span>
<span class="p_add">+</span>
<span class="p_add">+#define MFD_ALL_FLAGS (MFD_CLOEXEC | MFD_ALLOW_SEALING | MFD_HUGETLB)</span>
<span class="p_add">+</span>
<span class="p_add">+SYSCALL_DEFINE2(memfd_create,</span>
<span class="p_add">+		const char __user *, uname,</span>
<span class="p_add">+		unsigned int, flags)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned int *file_seals;</span>
<span class="p_add">+	struct file *file;</span>
<span class="p_add">+	int fd, error;</span>
<span class="p_add">+	char *name;</span>
<span class="p_add">+	long len;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (!(flags &amp; MFD_HUGETLB)) {</span>
<span class="p_add">+		if (flags &amp; ~(unsigned int)MFD_ALL_FLAGS)</span>
<span class="p_add">+			return -EINVAL;</span>
<span class="p_add">+	} else {</span>
<span class="p_add">+		/* Allow huge page size encoding in flags. */</span>
<span class="p_add">+		if (flags &amp; ~(unsigned int)(MFD_ALL_FLAGS |</span>
<span class="p_add">+				(MFD_HUGE_MASK &lt;&lt; MFD_HUGE_SHIFT)))</span>
<span class="p_add">+			return -EINVAL;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	/* length includes terminating zero */</span>
<span class="p_add">+	len = strnlen_user(uname, MFD_NAME_MAX_LEN + 1);</span>
<span class="p_add">+	if (len &lt;= 0)</span>
<span class="p_add">+		return -EFAULT;</span>
<span class="p_add">+	if (len &gt; MFD_NAME_MAX_LEN + 1)</span>
<span class="p_add">+		return -EINVAL;</span>
<span class="p_add">+</span>
<span class="p_add">+	name = kmalloc(len + MFD_NAME_PREFIX_LEN, GFP_KERNEL);</span>
<span class="p_add">+	if (!name)</span>
<span class="p_add">+		return -ENOMEM;</span>
<span class="p_add">+</span>
<span class="p_add">+	strcpy(name, MFD_NAME_PREFIX);</span>
<span class="p_add">+	if (copy_from_user(&amp;name[MFD_NAME_PREFIX_LEN], uname, len)) {</span>
<span class="p_add">+		error = -EFAULT;</span>
<span class="p_add">+		goto err_name;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	/* terminating-zero may have changed after strnlen_user() returned */</span>
<span class="p_add">+	if (name[len + MFD_NAME_PREFIX_LEN - 1]) {</span>
<span class="p_add">+		error = -EFAULT;</span>
<span class="p_add">+		goto err_name;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	fd = get_unused_fd_flags((flags &amp; MFD_CLOEXEC) ? O_CLOEXEC : 0);</span>
<span class="p_add">+	if (fd &lt; 0) {</span>
<span class="p_add">+		error = fd;</span>
<span class="p_add">+		goto err_name;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	if (flags &amp; MFD_HUGETLB) {</span>
<span class="p_add">+		struct user_struct *user = NULL;</span>
<span class="p_add">+</span>
<span class="p_add">+		file = hugetlb_file_setup(name, 0, VM_NORESERVE, &amp;user,</span>
<span class="p_add">+					HUGETLB_ANONHUGE_INODE,</span>
<span class="p_add">+					(flags &gt;&gt; MFD_HUGE_SHIFT) &amp;</span>
<span class="p_add">+					MFD_HUGE_MASK);</span>
<span class="p_add">+	} else</span>
<span class="p_add">+		file = shmem_file_setup(name, 0, VM_NORESERVE);</span>
<span class="p_add">+	if (IS_ERR(file)) {</span>
<span class="p_add">+		error = PTR_ERR(file);</span>
<span class="p_add">+		goto err_fd;</span>
<span class="p_add">+	}</span>
<span class="p_add">+	file-&gt;f_mode |= FMODE_LSEEK | FMODE_PREAD | FMODE_PWRITE;</span>
<span class="p_add">+	file-&gt;f_flags |= O_RDWR | O_LARGEFILE;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (flags &amp; MFD_ALLOW_SEALING) {</span>
<span class="p_add">+		file_seals = memfd_file_seals_ptr(file);</span>
<span class="p_add">+		*file_seals &amp;= ~F_SEAL_SEAL;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	fd_install(fd, file);</span>
<span class="p_add">+	kfree(name);</span>
<span class="p_add">+	return fd;</span>
<span class="p_add">+</span>
<span class="p_add">+err_fd:</span>
<span class="p_add">+	put_unused_fd(fd);</span>
<span class="p_add">+err_name:</span>
<span class="p_add">+	kfree(name);</span>
<span class="p_add">+	return error;</span>
<span class="p_add">+}</span>

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



