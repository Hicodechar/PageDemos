
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>[01/31] huge tmpfs: prepare counts in meminfo, vmstat and SysRq-m - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    [01/31] huge tmpfs: prepare counts in meminfo, vmstat and SysRq-m</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=7851">Hugh Dickins</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>April 5, 2016, 9:12 p.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;alpine.LSU.2.11.1604051410260.5965@eggly.anvils&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/8755161/mbox/"
   >mbox</a>
|
   <a href="/patch/8755161/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/8755161/">/patch/8755161/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
X-Original-To: patchwork-LKML@patchwork.kernel.org
Delivered-To: patchwork-parsemail@patchwork1.web.kernel.org
Received: from mail.kernel.org (mail.kernel.org [198.145.29.136])
	by patchwork1.web.kernel.org (Postfix) with ESMTP id 43B769F336
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Tue,  5 Apr 2016 21:12:41 +0000 (UTC)
Received: from mail.kernel.org (localhost [127.0.0.1])
	by mail.kernel.org (Postfix) with ESMTP id 2D6E520351
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Tue,  5 Apr 2016 21:12:40 +0000 (UTC)
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.kernel.org (Postfix) with ESMTP id E4A5120373
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Tue,  5 Apr 2016 21:12:38 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1760084AbcDEVMd (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Tue, 5 Apr 2016 17:12:33 -0400
Received: from mail-pf0-f169.google.com ([209.85.192.169]:36761 &quot;EHLO
	mail-pf0-f169.google.com&quot; rhost-flags-OK-OK-OK-OK) by vger.kernel.org
	with ESMTP id S1752392AbcDEVMb (ORCPT
	&lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Tue, 5 Apr 2016 17:12:31 -0400
Received: by mail-pf0-f169.google.com with SMTP id e128so18296593pfe.3
	for &lt;linux-kernel@vger.kernel.org&gt;;
	Tue, 05 Apr 2016 14:12:31 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
	d=google.com; s=20120113;
	h=date:from:to:cc:subject:in-reply-to:message-id:references
	:user-agent:mime-version;
	bh=zsP3udxM74MvaO9BrtO1dWx4pdZuzdCy3jMCQdksHwg=;
	b=UdMSQo+WzgULdu2OmqD/ZIUfLcZGAL4ZFAmZrc+tKi7ZCiwGj50e+c4bJ9rZdYVDDz
	Cxg1jaDAnEgUMa6XjTTatNCxX1YbD3RVZy1nFrRjWjToVCTCATIXVWs9JlFDhSGmcpaH
	/6Ob1fiVvvXLMRqIzIHbNat8Xl1fnGEa6svz5dCLXhqLIggEtMaFekk/Xq2BHx4tOPBV
	tFTbwxz9PNiwPxmoeo21PYZFb/P37IYv2/ZtmgqJ7Z6SKjlWxEQtIKb9x+XCUyySHl9T
	uKC8cJ+zKvZGSWBOiZ+sEaeAwAM80mfYAFALyQg3zikglT480xPUWP3G9mTclM3U2UwI
	mHbw==
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
	d=1e100.net; s=20130820;
	h=x-gm-message-state:date:from:to:cc:subject:in-reply-to:message-id
	:references:user-agent:mime-version;
	bh=zsP3udxM74MvaO9BrtO1dWx4pdZuzdCy3jMCQdksHwg=;
	b=EkyBR0gJGIK9Vd9dYNVrrhYm9Ng01xduhdyxOEtT/TSnTj7Gx9KycWGNdgQZlNOfS7
	PyAu26vh7eLvsiz+KnsY4pOZgXIMnHo9Y7qVMT3KNuU4UaME9/MjzeQALiXC2d7SEHKq
	iW9SnBhKFjefl+Vb4IApc3H5JMlkB/JlbAT2eMm7lxXc+yR0NiKr3YBzW0jcq4AUlHFC
	iAr2HeS9AY7AyM2rY9Zh+xAhHVjwvD/RqZlUBdX1Pxv07c+xDiKx2RP7TgS6QJpKv49d
	H+oKxKWjsU9P050NchRE5JvOAQN0MSX61LmzWsbAjw1XnzO1D2V214nJ2kW0jDrUnWSO
	Qcbw==
X-Gm-Message-State: AD7BkJJnZYwr1j2BRfT7lHu7Ru7xsoLFbEh/vTJd/UWr1sz17kycqnEGVKx9w7Q/Hd5xf1kn
X-Received: by 10.98.65.215 with SMTP id g84mr32668770pfd.94.1459890749008; 
	Tue, 05 Apr 2016 14:12:29 -0700 (PDT)
Received: from eggly.attlocal.net
	(172-10-233-147.lightspeed.sntcca.sbcglobal.net. [172.10.233.147])
	by smtp.gmail.com with ESMTPSA id
	fn3sm9853867pab.20.2016.04.05.14.12.26
	(version=TLS1 cipher=ECDHE-RSA-AES128-SHA bits=128/128);
	Tue, 05 Apr 2016 14:12:27 -0700 (PDT)
Date: Tue, 5 Apr 2016 14:12:26 -0700 (PDT)
From: Hugh Dickins &lt;hughd@google.com&gt;
X-X-Sender: hugh@eggly.anvils
To: Andrew Morton &lt;akpm@linux-foundation.org&gt;
cc: &quot;Kirill A. Shutemov&quot; &lt;kirill.shutemov@linux.intel.com&gt;,
	Andrea Arcangeli &lt;aarcange@redhat.com&gt;,
	Andres Lagar-Cavilla &lt;andreslc@google.com&gt;,
	Yang Shi &lt;yang.shi@linaro.org&gt;, Ning Qu &lt;quning@gmail.com&gt;,
	linux-kernel@vger.kernel.org, linux-mm@kvack.org
Subject: [PATCH 01/31] huge tmpfs: prepare counts in meminfo, vmstat and
	SysRq-m
In-Reply-To: &lt;alpine.LSU.2.11.1604051403210.5965@eggly.anvils&gt;
Message-ID: &lt;alpine.LSU.2.11.1604051410260.5965@eggly.anvils&gt;
References: &lt;alpine.LSU.2.11.1604051403210.5965@eggly.anvils&gt;
User-Agent: Alpine 2.11 (LSU 23 2013-08-11)
MIME-Version: 1.0
Content-Type: TEXT/PLAIN; charset=US-ASCII
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Spam-Status: No, score=-8.0 required=5.0 tests=BAYES_00,DKIM_SIGNED,
	DKIM_VALID, DKIM_VALID_AU, RCVD_IN_DNSWL_HI, RP_MATCHES_RCVD,
	UNPARSEABLE_RELAY autolearn=unavailable version=3.3.1
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on mail.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=7851">Hugh Dickins</a> - April 5, 2016, 9:12 p.m.</div>
<pre class="content">
Abbreviate NR_ANON_TRANSPARENT_HUGEPAGES to NR_ANON_HUGEPAGES,
add NR_SHMEM_HUGEPAGES, NR_SHMEM_PMDMAPPED, NR_SHMEM_FREEHOLES:
to be accounted in later commits, when we shall need some visibility.

Shown in /proc/meminfo and /sys/devices/system/node/nodeN/meminfo
as AnonHugePages (as before), ShmemHugePages, ShmemPmdMapped,
ShmemFreeHoles; /proc/vmstat and /sys/devices/system/node/nodeN/vmstat
as nr_anon_transparent_hugepages (as before), nr_shmem_hugepages,
nr_shmem_pmdmapped, nr_shmem_freeholes.

Be upfront about this being Shmem, neither file nor anon: Shmem
is sometimes counted as file (as in Cached) and sometimes as anon
(as in Active(anon)); which is too confusing.  Shmem is already
shown in meminfo, so use that term, rather than tmpfs or shm.

ShmemHugePages will show that portion of Shmem which is allocated
on complete huge pages.  ShmemPmdMapped (named not to misalign the
%8lu) will show that portion of ShmemHugePages which is mapped into
userspace with huge pmds.  ShmemFreeHoles will show the wastage
from using huge pages for small, or sparsely occupied, or unrounded
files: wastage not included in Shmem or MemFree, but will be freed
under memory pressure.  (But no count for the partially occupied
portions of huge pages: seems less important, but could be added.)

Since shmem_freeholes are otherwise hidden, they ought to be shown by
show_free_areas(), in OOM-kill or ALT-SysRq-m or /proc/sysrq-trigger m.
shmem_hugepages is a subset of shmem, and shmem_pmdmapped a subset of
shmem_hugepages: there is not a strong argument for adding them here
(anon_hugepages is not shown), but include them anyway for reassurance.
Note that shmem_hugepages (and _pmdmapped and _freeholes) page counts
are shown in smallpage units, like other fields: not in hugepage units.

The lines get rather long: abbreviate thus
  mapped:19778 shmem:38 pagetables:1153 bounce:0
  shmem_hugepages:0 _pmdmapped:0 _freeholes:2044
  free:3261805 free_pcp:9444 free_cma:0
and
... shmem:92kB _hugepages:0kB _pmdmapped:0kB _freeholes:0kB ...

Tidy up the CONFIG_TRANSPARENT_HUGEPAGE printf blocks in
fs/proc/meminfo.c and drivers/base/node.c: the shorter names help.
Clarify a comment in page_remove_rmap() to refer to &quot;hugetlbfs pages&quot;
rather than hugepages generally.  I left arch/tile/mm/pgtable.c&#39;s
show_mem() unchanged: tile does not HAVE_ARCH_TRANSPARENT_HUGEPAGE.
<span class="signed-off-by">
Signed-off-by: Hugh Dickins &lt;hughd@google.com&gt;</span>
---
 Documentation/filesystems/proc.txt |   10 ++++++++--
 drivers/base/node.c                |   20 +++++++++++---------
 fs/proc/meminfo.c                  |   11 ++++++++---
 include/linux/mmzone.h             |    5 ++++-
 mm/huge_memory.c                   |    2 +-
 mm/page_alloc.c                    |   17 +++++++++++++++++
 mm/rmap.c                          |   14 ++++++--------
 mm/vmstat.c                        |    3 +++
 8 files changed, 58 insertions(+), 24 deletions(-)
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=874">Kirill A. Shutemov</a> - April 11, 2016, 11:05 a.m.</div>
<pre class="content">
On Tue, Apr 05, 2016 at 02:12:26PM -0700, Hugh Dickins wrote:
<span class="quote">&gt; ShmemFreeHoles will show the wastage from using huge pages for small, or</span>
<span class="quote">&gt; sparsely occupied, or unrounded files: wastage not included in Shmem or</span>
<span class="quote">&gt; MemFree, but will be freed under memory pressure.  (But no count for the</span>
<span class="quote">&gt; partially occupied portions of huge pages: seems less important, but</span>
<span class="quote">&gt; could be added.)</span>

And here first difference in interfaces comes: I don&#39;t have an
equivalent in my implementation, as I don&#39;t track such information.
It looks like an implementation detail for team-pages based huge tmpfs.

We don&#39;t track anything similar for anon-THP.
<span class="quote">
&gt; --- a/mm/page_alloc.c</span>
<span class="quote">&gt; +++ b/mm/page_alloc.c</span>
<span class="quote">&gt; @@ -3830,6 +3830,11 @@ out:</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  #define K(x) ((x) &lt;&lt; (PAGE_SHIFT-10))</span>
<span class="quote">&gt; +#ifdef CONFIG_TRANSPARENT_HUGEPAGE</span>
<span class="quote">&gt; +#define THPAGE_PMD_NR	HPAGE_PMD_NR</span>
<span class="quote">&gt; +#else</span>
<span class="quote">&gt; +#define THPAGE_PMD_NR	0	/* Avoid BUILD_BUG() */</span>
<span class="quote">&gt; +#endif</span>

I&#39;ve just put THP-related counters on separate line and wrap it into
#ifdef.
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=7851">Hugh Dickins</a> - April 17, 2016, 2:28 a.m.</div>
<pre class="content">
On Mon, 11 Apr 2016, Kirill A. Shutemov wrote:
<span class="quote">&gt; On Tue, Apr 05, 2016 at 02:12:26PM -0700, Hugh Dickins wrote:</span>
<span class="quote">&gt; &gt; ShmemFreeHoles will show the wastage from using huge pages for small, or</span>
<span class="quote">&gt; &gt; sparsely occupied, or unrounded files: wastage not included in Shmem or</span>
<span class="quote">&gt; &gt; MemFree, but will be freed under memory pressure.  (But no count for the</span>
<span class="quote">&gt; &gt; partially occupied portions of huge pages: seems less important, but</span>
<span class="quote">&gt; &gt; could be added.)</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; And here first difference in interfaces comes: I don&#39;t have an</span>
<span class="quote">&gt; equivalent in my implementation, as I don&#39;t track such information.</span>
<span class="quote">&gt; It looks like an implementation detail for team-pages based huge tmpfs.</span>

It&#39;s an implementation detail insofar as that you&#39;ve not yet implemented
the equivalent with compound pages - and I think you&#39;re hoping never to
do so.

Of course, nobody wants ShmemFreeHoles as such, but they do want
the filesize flexibility that comes with them.  And they may be an
important detail if free memory is vanishing into a black hole.

They are definitely a peculiar category, which is itself a strong
reason for making them visible in some way.  But I don&#39;t think I&#39;d
mind if we decided they&#39;re not quite up to /proc/meminfo standards,
and should be shown somewhere else instead.  [Quiet sob.]

But if we do move them out of /proc/meminfo, I&#39;ll argue that they
should then be added in to the user-visible MemFree (though not to
the internal NR_FREE_PAGES): at different times I&#39;ve felt differently
on that, and when MemAvailable came in, then it was so clear that they
belong in that category, that I didn&#39;t want them in MemFree; but if
they&#39;re not themselves high-level visible in /proc/meminfo, then
I think that probably they should go into MemFree.

But really, here, we want distro advice rather than my musings.
<span class="quote">
&gt; </span>
<span class="quote">&gt; We don&#39;t track anything similar for anon-THP.</span>

The case just doesn&#39;t arise with anon THP (or didn&#39;t arise before
your recent changes anyway): the object could only be a pmd-mapped
entity, and always showing AnonFreeHoles 0kB is just boring.
<span class="quote">
&gt; </span>
<span class="quote">&gt; &gt; --- a/mm/page_alloc.c</span>
<span class="quote">&gt; &gt; +++ b/mm/page_alloc.c</span>
<span class="quote">&gt; &gt; @@ -3830,6 +3830,11 @@ out:</span>
<span class="quote">&gt; &gt;  }</span>
<span class="quote">&gt; &gt;  </span>
<span class="quote">&gt; &gt;  #define K(x) ((x) &lt;&lt; (PAGE_SHIFT-10))</span>
<span class="quote">&gt; &gt; +#ifdef CONFIG_TRANSPARENT_HUGEPAGE</span>
<span class="quote">&gt; &gt; +#define THPAGE_PMD_NR	HPAGE_PMD_NR</span>
<span class="quote">&gt; &gt; +#else</span>
<span class="quote">&gt; &gt; +#define THPAGE_PMD_NR	0	/* Avoid BUILD_BUG() */</span>
<span class="quote">&gt; &gt; +#endif</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; I&#39;ve just put THP-related counters on separate line and wrap it into</span>
<span class="quote">&gt; #ifdef.</span>

Time and time again I get very annoyed by that BUILD_BUG() buried
inside HPAGE_PMD_NR.  I expect you do too.  But it&#39;s true that it
does sometimes alert us to some large chunk of code that ought to
be slightly reorganized to get it optimized away.  So I never
quite summon up the courage to un-BUILD_BUG it.

I think we need a secret definition that only you and I know,
THPAGE_PMD_NR or whatever, to get around it on occasion.

Hugh
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">--- a/Documentation/filesystems/proc.txt</span>
<span class="p_header">+++ b/Documentation/filesystems/proc.txt</span>
<span class="p_chunk">@@ -853,7 +853,7 @@</span> <span class="p_context"> Dirty:             968 kB</span>
 Writeback:           0 kB
 AnonPages:      861800 kB
 Mapped:         280372 kB
<span class="p_del">-Shmem:             644 kB</span>
<span class="p_add">+Shmem:           26396 kB</span>
 Slab:           284364 kB
 SReclaimable:   159856 kB
 SUnreclaim:     124508 kB
<span class="p_chunk">@@ -867,6 +867,9 @@</span> <span class="p_context"> VmallocTotal:   112216 kB</span>
 VmallocUsed:       428 kB
 VmallocChunk:   111088 kB
 AnonHugePages:   49152 kB
<span class="p_add">+ShmemHugePages:  20480 kB</span>
<span class="p_add">+ShmemPmdMapped:  12288 kB</span>
<span class="p_add">+ShmemFreeHoles:      0 kB</span>
 
     MemTotal: Total usable ram (i.e. physical ram minus a few reserved
               bits and the kernel binary code)
<span class="p_chunk">@@ -908,7 +911,6 @@</span> <span class="p_context"> MemAvailable: An estimate of how much me</span>
        Dirty: Memory which is waiting to get written back to the disk
    Writeback: Memory which is actively being written back to the disk
    AnonPages: Non-file backed pages mapped into userspace page tables
<span class="p_del">-AnonHugePages: Non-file backed huge pages mapped into userspace page tables</span>
       Mapped: files which have been mmaped, such as libraries
        Shmem: Total memory used by shared memory (shmem) and tmpfs
         Slab: in-kernel data structures cache
<span class="p_chunk">@@ -949,6 +951,10 @@</span> <span class="p_context"> Committed_AS: The amount of memory prese</span>
 VmallocTotal: total size of vmalloc memory area
  VmallocUsed: amount of vmalloc area which is used
 VmallocChunk: largest contiguous block of vmalloc area which is free
<span class="p_add">+ AnonHugePages: Non-file backed huge pages mapped into userspace page tables</span>
<span class="p_add">+ShmemHugePages: tmpfs-file backed huge pages completed (subset of Shmem)</span>
<span class="p_add">+ShmemPmdMapped: tmpfs-file backed huge pages with huge mappings into userspace</span>
<span class="p_add">+ShmemFreeHoles: Space reserved for tmpfs team pages but available to shrinker</span>
 
 ..............................................................................
 
<span class="p_header">--- a/drivers/base/node.c</span>
<span class="p_header">+++ b/drivers/base/node.c</span>
<span class="p_chunk">@@ -111,9 +111,6 @@</span> <span class="p_context"> static ssize_t node_read_meminfo(struct</span>
 		       &quot;Node %d Slab:           %8lu kB\n&quot;
 		       &quot;Node %d SReclaimable:   %8lu kB\n&quot;
 		       &quot;Node %d SUnreclaim:     %8lu kB\n&quot;
<span class="p_del">-#ifdef CONFIG_TRANSPARENT_HUGEPAGE</span>
<span class="p_del">-		       &quot;Node %d AnonHugePages:  %8lu kB\n&quot;</span>
<span class="p_del">-#endif</span>
 			,
 		       nid, K(node_page_state(nid, NR_FILE_DIRTY)),
 		       nid, K(node_page_state(nid, NR_WRITEBACK)),
<span class="p_chunk">@@ -130,13 +127,18 @@</span> <span class="p_context"> static ssize_t node_read_meminfo(struct</span>
 		       nid, K(node_page_state(nid, NR_SLAB_RECLAIMABLE) +
 				node_page_state(nid, NR_SLAB_UNRECLAIMABLE)),
 		       nid, K(node_page_state(nid, NR_SLAB_RECLAIMABLE)),
<span class="p_del">-#ifdef CONFIG_TRANSPARENT_HUGEPAGE</span>
<span class="p_del">-		       nid, K(node_page_state(nid, NR_SLAB_UNRECLAIMABLE))</span>
<span class="p_del">-			, nid,</span>
<span class="p_del">-			K(node_page_state(nid, NR_ANON_TRANSPARENT_HUGEPAGES) *</span>
<span class="p_del">-			HPAGE_PMD_NR));</span>
<span class="p_del">-#else</span>
 		       nid, K(node_page_state(nid, NR_SLAB_UNRECLAIMABLE)));
<span class="p_add">+</span>
<span class="p_add">+#ifdef CONFIG_TRANSPARENT_HUGEPAGE</span>
<span class="p_add">+	n += sprintf(buf + n,</span>
<span class="p_add">+		&quot;Node %d AnonHugePages:  %8lu kB\n&quot;</span>
<span class="p_add">+		&quot;Node %d ShmemHugePages: %8lu kB\n&quot;</span>
<span class="p_add">+		&quot;Node %d ShmemPmdMapped: %8lu kB\n&quot;</span>
<span class="p_add">+		&quot;Node %d ShmemFreeHoles: %8lu kB\n&quot;,</span>
<span class="p_add">+		nid, K(node_page_state(nid, NR_ANON_HUGEPAGES)*HPAGE_PMD_NR),</span>
<span class="p_add">+		nid, K(node_page_state(nid, NR_SHMEM_HUGEPAGES)*HPAGE_PMD_NR),</span>
<span class="p_add">+		nid, K(node_page_state(nid, NR_SHMEM_PMDMAPPED)*HPAGE_PMD_NR),</span>
<span class="p_add">+		nid, K(node_page_state(nid, NR_SHMEM_FREEHOLES)));</span>
 #endif
 	n += hugetlb_report_node_meminfo(nid, buf + n);
 	return n;
<span class="p_header">--- a/fs/proc/meminfo.c</span>
<span class="p_header">+++ b/fs/proc/meminfo.c</span>
<span class="p_chunk">@@ -105,6 +105,9 @@</span> <span class="p_context"> static int meminfo_proc_show(struct seq_</span>
 #endif
 #ifdef CONFIG_TRANSPARENT_HUGEPAGE
 		&quot;AnonHugePages:  %8lu kB\n&quot;
<span class="p_add">+		&quot;ShmemHugePages: %8lu kB\n&quot;</span>
<span class="p_add">+		&quot;ShmemPmdMapped: %8lu kB\n&quot;</span>
<span class="p_add">+		&quot;ShmemFreeHoles: %8lu kB\n&quot;</span>
 #endif
 #ifdef CONFIG_CMA
 		&quot;CmaTotal:       %8lu kB\n&quot;
<span class="p_chunk">@@ -159,11 +162,13 @@</span> <span class="p_context"> static int meminfo_proc_show(struct seq_</span>
 		0ul, // used to be vmalloc &#39;used&#39;
 		0ul  // used to be vmalloc &#39;largest_chunk&#39;
 #ifdef CONFIG_MEMORY_FAILURE
<span class="p_del">-		, atomic_long_read(&amp;num_poisoned_pages) &lt;&lt; (PAGE_SHIFT - 10)</span>
<span class="p_add">+		, K(atomic_long_read(&amp;num_poisoned_pages))</span>
 #endif
 #ifdef CONFIG_TRANSPARENT_HUGEPAGE
<span class="p_del">-		, K(global_page_state(NR_ANON_TRANSPARENT_HUGEPAGES) *</span>
<span class="p_del">-		   HPAGE_PMD_NR)</span>
<span class="p_add">+		, K(global_page_state(NR_ANON_HUGEPAGES) * HPAGE_PMD_NR)</span>
<span class="p_add">+		, K(global_page_state(NR_SHMEM_HUGEPAGES) * HPAGE_PMD_NR)</span>
<span class="p_add">+		, K(global_page_state(NR_SHMEM_PMDMAPPED) * HPAGE_PMD_NR)</span>
<span class="p_add">+		, K(global_page_state(NR_SHMEM_FREEHOLES))</span>
 #endif
 #ifdef CONFIG_CMA
 		, K(totalcma_pages)
<span class="p_header">--- a/include/linux/mmzone.h</span>
<span class="p_header">+++ b/include/linux/mmzone.h</span>
<span class="p_chunk">@@ -158,7 +158,10 @@</span> <span class="p_context"> enum zone_stat_item {</span>
 	WORKINGSET_REFAULT,
 	WORKINGSET_ACTIVATE,
 	WORKINGSET_NODERECLAIM,
<span class="p_del">-	NR_ANON_TRANSPARENT_HUGEPAGES,</span>
<span class="p_add">+	NR_ANON_HUGEPAGES,	/* transparent anon huge pages */</span>
<span class="p_add">+	NR_SHMEM_HUGEPAGES,	/* transparent shmem huge pages */</span>
<span class="p_add">+	NR_SHMEM_PMDMAPPED,	/* shmem huge pages currently mapped hugely */</span>
<span class="p_add">+	NR_SHMEM_FREEHOLES,	/* unused memory of high-order allocations */</span>
 	NR_FREE_CMA_PAGES,
 	NR_VM_ZONE_STAT_ITEMS };
 
<span class="p_header">--- a/mm/huge_memory.c</span>
<span class="p_header">+++ b/mm/huge_memory.c</span>
<span class="p_chunk">@@ -2943,7 +2943,7 @@</span> <span class="p_context"> static void __split_huge_pmd_locked(stru</span>
 
 	if (atomic_add_negative(-1, compound_mapcount_ptr(page))) {
 		/* Last compound_mapcount is gone. */
<span class="p_del">-		__dec_zone_page_state(page, NR_ANON_TRANSPARENT_HUGEPAGES);</span>
<span class="p_add">+		__dec_zone_page_state(page, NR_ANON_HUGEPAGES);</span>
 		if (TestClearPageDoubleMap(page)) {
 			/* No need in mapcount reference anymore */
 			for (i = 0; i &lt; HPAGE_PMD_NR; i++)
<span class="p_header">--- a/mm/page_alloc.c</span>
<span class="p_header">+++ b/mm/page_alloc.c</span>
<span class="p_chunk">@@ -3830,6 +3830,11 @@</span> <span class="p_context"> out:</span>
 }
 
 #define K(x) ((x) &lt;&lt; (PAGE_SHIFT-10))
<span class="p_add">+#ifdef CONFIG_TRANSPARENT_HUGEPAGE</span>
<span class="p_add">+#define THPAGE_PMD_NR	HPAGE_PMD_NR</span>
<span class="p_add">+#else</span>
<span class="p_add">+#define THPAGE_PMD_NR	0	/* Avoid BUILD_BUG() */</span>
<span class="p_add">+#endif</span>
 
 static void show_migration_types(unsigned char type)
 {
<span class="p_chunk">@@ -3886,6 +3891,7 @@</span> <span class="p_context"> void show_free_areas(unsigned int filter</span>
 		&quot; unevictable:%lu dirty:%lu writeback:%lu unstable:%lu\n&quot;
 		&quot; slab_reclaimable:%lu slab_unreclaimable:%lu\n&quot;
 		&quot; mapped:%lu shmem:%lu pagetables:%lu bounce:%lu\n&quot;
<span class="p_add">+		&quot; shmem_hugepages:%lu _pmdmapped:%lu _freeholes:%lu\n&quot;</span>
 		&quot; free:%lu free_pcp:%lu free_cma:%lu\n&quot;,
 		global_page_state(NR_ACTIVE_ANON),
 		global_page_state(NR_INACTIVE_ANON),
<span class="p_chunk">@@ -3903,6 +3909,9 @@</span> <span class="p_context"> void show_free_areas(unsigned int filter</span>
 		global_page_state(NR_SHMEM),
 		global_page_state(NR_PAGETABLE),
 		global_page_state(NR_BOUNCE),
<span class="p_add">+		global_page_state(NR_SHMEM_HUGEPAGES) * THPAGE_PMD_NR,</span>
<span class="p_add">+		global_page_state(NR_SHMEM_PMDMAPPED) * THPAGE_PMD_NR,</span>
<span class="p_add">+		global_page_state(NR_SHMEM_FREEHOLES),</span>
 		global_page_state(NR_FREE_PAGES),
 		free_pcp,
 		global_page_state(NR_FREE_CMA_PAGES));
<span class="p_chunk">@@ -3937,6 +3946,9 @@</span> <span class="p_context"> void show_free_areas(unsigned int filter</span>
 			&quot; writeback:%lukB&quot;
 			&quot; mapped:%lukB&quot;
 			&quot; shmem:%lukB&quot;
<span class="p_add">+			&quot; _hugepages:%lukB&quot;</span>
<span class="p_add">+			&quot; _pmdmapped:%lukB&quot;</span>
<span class="p_add">+			&quot; _freeholes:%lukB&quot;</span>
 			&quot; slab_reclaimable:%lukB&quot;
 			&quot; slab_unreclaimable:%lukB&quot;
 			&quot; kernel_stack:%lukB&quot;
<span class="p_chunk">@@ -3969,6 +3981,11 @@</span> <span class="p_context"> void show_free_areas(unsigned int filter</span>
 			K(zone_page_state(zone, NR_WRITEBACK)),
 			K(zone_page_state(zone, NR_FILE_MAPPED)),
 			K(zone_page_state(zone, NR_SHMEM)),
<span class="p_add">+			K(zone_page_state(zone, NR_SHMEM_HUGEPAGES) *</span>
<span class="p_add">+							THPAGE_PMD_NR),</span>
<span class="p_add">+			K(zone_page_state(zone, NR_SHMEM_PMDMAPPED) *</span>
<span class="p_add">+							THPAGE_PMD_NR),</span>
<span class="p_add">+			K(zone_page_state(zone, NR_SHMEM_FREEHOLES)),</span>
 			K(zone_page_state(zone, NR_SLAB_RECLAIMABLE)),
 			K(zone_page_state(zone, NR_SLAB_UNRECLAIMABLE)),
 			zone_page_state(zone, NR_KERNEL_STACK) *
<span class="p_header">--- a/mm/rmap.c</span>
<span class="p_header">+++ b/mm/rmap.c</span>
<span class="p_chunk">@@ -1213,10 +1213,8 @@</span> <span class="p_context"> void do_page_add_anon_rmap(struct page *</span>
 		 * pte lock(a spinlock) is held, which implies preemption
 		 * disabled.
 		 */
<span class="p_del">-		if (compound) {</span>
<span class="p_del">-			__inc_zone_page_state(page,</span>
<span class="p_del">-					      NR_ANON_TRANSPARENT_HUGEPAGES);</span>
<span class="p_del">-		}</span>
<span class="p_add">+		if (compound)</span>
<span class="p_add">+			__inc_zone_page_state(page, NR_ANON_HUGEPAGES);</span>
 		__mod_zone_page_state(page_zone(page), NR_ANON_PAGES, nr);
 	}
 	if (unlikely(PageKsm(page)))
<span class="p_chunk">@@ -1254,7 +1252,7 @@</span> <span class="p_context"> void page_add_new_anon_rmap(struct page</span>
 		VM_BUG_ON_PAGE(!PageTransHuge(page), page);
 		/* increment count (starts at -1) */
 		atomic_set(compound_mapcount_ptr(page), 0);
<span class="p_del">-		__inc_zone_page_state(page, NR_ANON_TRANSPARENT_HUGEPAGES);</span>
<span class="p_add">+		__inc_zone_page_state(page, NR_ANON_HUGEPAGES);</span>
 	} else {
 		/* Anon THP always mapped first with PMD */
 		VM_BUG_ON_PAGE(PageTransCompound(page), page);
<span class="p_chunk">@@ -1285,7 +1283,7 @@</span> <span class="p_context"> static void page_remove_file_rmap(struct</span>
 {
 	lock_page_memcg(page);
 
<span class="p_del">-	/* Hugepages are not counted in NR_FILE_MAPPED for now. */</span>
<span class="p_add">+	/* hugetlbfs pages are not counted in NR_FILE_MAPPED for now. */</span>
 	if (unlikely(PageHuge(page))) {
 		/* hugetlb pages are always mapped with pmds */
 		atomic_dec(compound_mapcount_ptr(page));
<span class="p_chunk">@@ -1317,14 +1315,14 @@</span> <span class="p_context"> static void page_remove_anon_compound_rm</span>
 	if (!atomic_add_negative(-1, compound_mapcount_ptr(page)))
 		return;
 
<span class="p_del">-	/* Hugepages are not counted in NR_ANON_PAGES for now. */</span>
<span class="p_add">+	/* hugetlbfs pages are not counted in NR_ANON_PAGES for now. */</span>
 	if (unlikely(PageHuge(page)))
 		return;
 
 	if (!IS_ENABLED(CONFIG_TRANSPARENT_HUGEPAGE))
 		return;
 
<span class="p_del">-	__dec_zone_page_state(page, NR_ANON_TRANSPARENT_HUGEPAGES);</span>
<span class="p_add">+	__dec_zone_page_state(page, NR_ANON_HUGEPAGES);</span>
 
 	if (TestClearPageDoubleMap(page)) {
 		/*
<span class="p_header">--- a/mm/vmstat.c</span>
<span class="p_header">+++ b/mm/vmstat.c</span>
<span class="p_chunk">@@ -762,6 +762,9 @@</span> <span class="p_context"> const char * const vmstat_text[] = {</span>
 	&quot;workingset_activate&quot;,
 	&quot;workingset_nodereclaim&quot;,
 	&quot;nr_anon_transparent_hugepages&quot;,
<span class="p_add">+	&quot;nr_shmem_hugepages&quot;,</span>
<span class="p_add">+	&quot;nr_shmem_pmdmapped&quot;,</span>
<span class="p_add">+	&quot;nr_shmem_freeholes&quot;,</span>
 	&quot;nr_free_cma&quot;,
 
 	/* enum writeback_stat_item counters */

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



