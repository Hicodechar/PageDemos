
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>[v6,2/4] KVM: X86: Add Paravirt TLB Shootdown - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    [v6,2/4] KVM: X86: Add Paravirt TLB Shootdown</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=104371">Wanpeng Li</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>Nov. 28, 2017, 4:05 a.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;1511841955-7375-3-git-send-email-wanpeng.li@hotmail.com&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/10078631/mbox/"
   >mbox</a>
|
   <a href="/patch/10078631/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/10078631/">/patch/10078631/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
	[172.30.200.125])
	by pdx-korg-patchwork.web.codeaurora.org (Postfix) with ESMTP id
	A737E60234 for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Tue, 28 Nov 2017 04:06:15 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 8CCC028D4A
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Tue, 28 Nov 2017 04:06:15 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id 734B52916C; Tue, 28 Nov 2017 04:06:15 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-7.0 required=2.0 tests=BAYES_00,DKIM_SIGNED,
	DKIM_VALID, DKIM_VALID_AU, FREEMAIL_FROM,
	RCVD_IN_DNSWL_HI autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id BC92C28D4A
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Tue, 28 Nov 2017 04:06:14 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1753658AbdK1EGM (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Mon, 27 Nov 2017 23:06:12 -0500
Received: from mail-pg0-f65.google.com ([74.125.83.65]:44555 &quot;EHLO
	mail-pg0-f65.google.com&quot; rhost-flags-OK-OK-OK-OK) by vger.kernel.org
	with ESMTP id S1753398AbdK1EGI (ORCPT
	&lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Mon, 27 Nov 2017 23:06:08 -0500
Received: by mail-pg0-f65.google.com with SMTP id c123so19713361pga.11;
	Mon, 27 Nov 2017 20:06:07 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
	d=gmail.com; s=20161025;
	h=from:to:cc:subject:date:message-id:in-reply-to:references
	:mime-version:content-transfer-encoding;
	bh=curLrs3NqJIcGAkduRd+DBQiN1PT/KRaZ4eFWSaf5G8=;
	b=Axk0T0/sdl549qe59TBDHZphvd8nc0nDG47lnUyanG/3FlJi0FgybgsEpJyQcIM029
	CYa7mCgwgQzmTnhQQkVbaLz+ugJrAAvCAZ7BwKKosjXJJDrJ09/rFzq4bEZUS9+1EUAX
	ad2qymjSpcIcuyFmt5vJjRY0AGH8Hw4PrTnA2EISBpZKScDU5TqjHFXVX/0KbZpqSOQE
	vjnSyaHkFbAkbOcSFzb+dKd8X6hKKaqgZuApBVAsLrFHr1p39r1ppqry//p1LlPolJS3
	3BU43P28IkCenrT1PLSlVoADj001WEWISHLI/i4NuQVl9VdDlFR3lndWvn7fmu4dVTBU
	kmqg==
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
	d=1e100.net; s=20161025;
	h=x-gm-message-state:from:to:cc:subject:date:message-id:in-reply-to
	:references:mime-version:content-transfer-encoding;
	bh=curLrs3NqJIcGAkduRd+DBQiN1PT/KRaZ4eFWSaf5G8=;
	b=dHQ03EdWPSasR6VBZ/HBS05/aw53d3DiTRLabGKHL//TYo5QOwDP7bOKOH5BcyLfKw
	2f3lClQwz5OixuxWQgU97wAA3LMRQ/xYApAxV79x1W057ratkdcr4nZEnA4Jj9vjjIdR
	CQSBCVgfBYFFkuKdDw8eT2PicbAMf3wQoKbojYc1IS1sSFjYRgukVYOS03FELwCVE5Y5
	qUbpbVYzH3sbdiBXKjmq3oZKvZrxMchV3khwV5zocUT3QE9lL3DYGCD7uxsVK5zoVCqJ
	Mfm+USaL4+Nnp+pUiOV3WgToL/xIgeACUaKlgriVtvn8eLF2vsbEXI7k6KVh3pyHZ6yJ
	JqFA==
X-Gm-Message-State: AJaThX7y6WwszQyk2czH1rndpaaF4wc48RWANpYvkPNHOmJL/yDIqiod
	AozfR9Cj29f/A69oZ6uDaj4DKQ==
X-Google-Smtp-Source: AGs4zMZtbdfSaCYZkzxRxfPSGZji5X1iTGMwRjAZ3xrjdko00sDAeFNCWwUnQMEUbOR7WJ1Q8X912A==
X-Received: by 10.101.75.78 with SMTP id k14mr38825416pgt.272.1511841967246; 
	Mon, 27 Nov 2017 20:06:07 -0800 (PST)
Received: from localhost ([203.205.141.123])
	by smtp.gmail.com with ESMTPSA id
	a24sm56501884pfc.79.2017.11.27.20.06.06
	(version=TLS1_2 cipher=ECDHE-RSA-AES128-GCM-SHA256 bits=128/128);
	Mon, 27 Nov 2017 20:06:06 -0800 (PST)
From: Wanpeng Li &lt;kernellwp@gmail.com&gt;
X-Google-Original-From: Wanpeng Li &lt;wanpeng.li@hotmail.com&gt;
To: linux-kernel@vger.kernel.org, kvm@vger.kernel.org
Cc: Paolo Bonzini &lt;pbonzini@redhat.com&gt;,
	=?UTF-8?q?Radim=20Kr=C4=8Dm=C3=A1=C5=99?= &lt;rkrcmar@redhat.com&gt;,
	Wanpeng Li &lt;wanpeng.li@hotmail.com&gt;,
	Peter Zijlstra &lt;peterz@infradead.org&gt;
Subject: [PATCH v6 2/4] KVM: X86: Add Paravirt TLB Shootdown
Date: Mon, 27 Nov 2017 20:05:53 -0800
Message-Id: &lt;1511841955-7375-3-git-send-email-wanpeng.li@hotmail.com&gt;
X-Mailer: git-send-email 2.7.4
In-Reply-To: &lt;1511841955-7375-1-git-send-email-wanpeng.li@hotmail.com&gt;
References: &lt;1511841955-7375-1-git-send-email-wanpeng.li@hotmail.com&gt;
MIME-Version: 1.0
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 8bit
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=104371">Wanpeng Li</a> - Nov. 28, 2017, 4:05 a.m.</div>
<pre class="content">
<span class="from">From: Wanpeng Li &lt;wanpeng.li@hotmail.com&gt;</span>

Remote flushing api&#39;s does a busy wait which is fine in bare-metal
scenario. But with-in the guest, the vcpus might have been pre-empted
or blocked. In this scenario, the initator vcpu would end up
busy-waiting for a long amount of time.

This patch set implements para-virt flush tlbs making sure that it
does not wait for vcpus that are sleeping. And all the sleeping vcpus
flush the tlb on guest enter.

The best result is achieved when we&#39;re overcommiting the host by running 
multiple vCPUs on each pCPU. In this case PV tlb flush avoids touching 
vCPUs which are not scheduled and avoid the wait on the main CPU.

Testing on a Xeon Gold 6142 2.6GHz 2 sockets, 32 cores, 64 threads,
so 64 pCPUs, and each VM is 64 vCPUs.

ebizzy -M 
              vanilla    optimized     boost
1VM            46799         48670        4%
2VM            23962         42691       78%
3VM            16152         37539      132%

Cc: Paolo Bonzini &lt;pbonzini@redhat.com&gt;
Cc: Radim Krčmář &lt;rkrcmar@redhat.com&gt;
Cc: Peter Zijlstra &lt;peterz@infradead.org&gt;
<span class="signed-off-by">Signed-off-by: Wanpeng Li &lt;wanpeng.li@hotmail.com&gt;</span>
---
 Documentation/virtual/kvm/cpuid.txt  |  4 ++++
 arch/x86/include/uapi/asm/kvm_para.h |  2 ++
 arch/x86/kernel/kvm.c                | 34 ++++++++++++++++++++++++++++++++++
 3 files changed, 40 insertions(+)
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=69351">Radim Kr?má?</a> - Nov. 29, 2017, 4:21 p.m.</div>
<pre class="content">
2017-11-27 20:05-0800, Wanpeng Li:
<span class="quote">&gt; From: Wanpeng Li &lt;wanpeng.li@hotmail.com&gt;</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Remote flushing api&#39;s does a busy wait which is fine in bare-metal</span>
<span class="quote">&gt; scenario. But with-in the guest, the vcpus might have been pre-empted</span>
<span class="quote">&gt; or blocked. In this scenario, the initator vcpu would end up</span>
<span class="quote">&gt; busy-waiting for a long amount of time.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; This patch set implements para-virt flush tlbs making sure that it</span>
<span class="quote">&gt; does not wait for vcpus that are sleeping. And all the sleeping vcpus</span>
<span class="quote">&gt; flush the tlb on guest enter.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; The best result is achieved when we&#39;re overcommiting the host by running </span>
<span class="quote">&gt; multiple vCPUs on each pCPU. In this case PV tlb flush avoids touching </span>
<span class="quote">&gt; vCPUs which are not scheduled and avoid the wait on the main CPU.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Testing on a Xeon Gold 6142 2.6GHz 2 sockets, 32 cores, 64 threads,</span>
<span class="quote">&gt; so 64 pCPUs, and each VM is 64 vCPUs.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; ebizzy -M </span>
<span class="quote">&gt;               vanilla    optimized     boost</span>
<span class="quote">&gt; 1VM            46799         48670        4%</span>
<span class="quote">&gt; 2VM            23962         42691       78%</span>
<span class="quote">&gt; 3VM            16152         37539      132%</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Cc: Paolo Bonzini &lt;pbonzini@redhat.com&gt;</span>
<span class="quote">&gt; Cc: Radim Krčmář &lt;rkrcmar@redhat.com&gt;</span>
<span class="quote">&gt; Cc: Peter Zijlstra &lt;peterz@infradead.org&gt;</span>
<span class="quote">&gt; Signed-off-by: Wanpeng Li &lt;wanpeng.li@hotmail.com&gt;</span>
<span class="quote">&gt; ---</span>
<span class="quote">&gt; diff --git a/arch/x86/kernel/kvm.c b/arch/x86/kernel/kvm.c</span>
<span class="quote">&gt; @@ -498,6 +498,37 @@ static void __init kvm_apf_trap_init(void)</span>
<span class="quote">&gt;  	update_intr_gate(X86_TRAP_PF, async_page_fault);</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; +static DEFINE_PER_CPU(cpumask_t, __pv_tlb_mask);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +static void kvm_flush_tlb_others(const struct cpumask *cpumask,</span>
<span class="quote">&gt; +			const struct flush_tlb_info *info)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	u8 state;</span>
<span class="quote">&gt; +	int cpu;</span>
<span class="quote">&gt; +	struct kvm_steal_time *src;</span>
<span class="quote">&gt; +	cpumask_t *flushmask = &amp;per_cpu(__pv_tlb_mask, smp_processor_id());</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	if (unlikely(!flushmask))</span>
<span class="quote">&gt; +		return;</span>

I don&#39;t see how this can be NULL and if it could, we&#39;d have to call
native_flush_tlb_others() instead of returning anyway.

Also, Peter mentioned that we&#39;re wasting memory (default is 1k per CPU)
when not running on KVM.  Hyper-V hijacks x86_platform.apic_post_init()
to achieve late allocation.  smp_ops.smp_prepare_cpus seems slightly
better for our purposes, but I don&#39;t really like either.

Couldn&#39;t we use use arch_initcall(), or early_initcall() if there are
complications with allocating after smp_init()?

Thanks.
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=104371">Wanpeng Li</a> - Nov. 30, 2017, 6:24 a.m.</div>
<pre class="content">
2017-11-30 0:21 GMT+08:00 Radim Krčmář &lt;rkrcmar@redhat.com&gt;:
<span class="quote">&gt; 2017-11-27 20:05-0800, Wanpeng Li:</span>
<span class="quote">&gt;&gt; From: Wanpeng Li &lt;wanpeng.li@hotmail.com&gt;</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; Remote flushing api&#39;s does a busy wait which is fine in bare-metal</span>
<span class="quote">&gt;&gt; scenario. But with-in the guest, the vcpus might have been pre-empted</span>
<span class="quote">&gt;&gt; or blocked. In this scenario, the initator vcpu would end up</span>
<span class="quote">&gt;&gt; busy-waiting for a long amount of time.</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; This patch set implements para-virt flush tlbs making sure that it</span>
<span class="quote">&gt;&gt; does not wait for vcpus that are sleeping. And all the sleeping vcpus</span>
<span class="quote">&gt;&gt; flush the tlb on guest enter.</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; The best result is achieved when we&#39;re overcommiting the host by running</span>
<span class="quote">&gt;&gt; multiple vCPUs on each pCPU. In this case PV tlb flush avoids touching</span>
<span class="quote">&gt;&gt; vCPUs which are not scheduled and avoid the wait on the main CPU.</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; Testing on a Xeon Gold 6142 2.6GHz 2 sockets, 32 cores, 64 threads,</span>
<span class="quote">&gt;&gt; so 64 pCPUs, and each VM is 64 vCPUs.</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; ebizzy -M</span>
<span class="quote">&gt;&gt;               vanilla    optimized     boost</span>
<span class="quote">&gt;&gt; 1VM            46799         48670        4%</span>
<span class="quote">&gt;&gt; 2VM            23962         42691       78%</span>
<span class="quote">&gt;&gt; 3VM            16152         37539      132%</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; Cc: Paolo Bonzini &lt;pbonzini@redhat.com&gt;</span>
<span class="quote">&gt;&gt; Cc: Radim Krčmář &lt;rkrcmar@redhat.com&gt;</span>
<span class="quote">&gt;&gt; Cc: Peter Zijlstra &lt;peterz@infradead.org&gt;</span>
<span class="quote">&gt;&gt; Signed-off-by: Wanpeng Li &lt;wanpeng.li@hotmail.com&gt;</span>
<span class="quote">&gt;&gt; ---</span>
<span class="quote">&gt;&gt; diff --git a/arch/x86/kernel/kvm.c b/arch/x86/kernel/kvm.c</span>
<span class="quote">&gt;&gt; @@ -498,6 +498,37 @@ static void __init kvm_apf_trap_init(void)</span>
<span class="quote">&gt;&gt;       update_intr_gate(X86_TRAP_PF, async_page_fault);</span>
<span class="quote">&gt;&gt;  }</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; +static DEFINE_PER_CPU(cpumask_t, __pv_tlb_mask);</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +static void kvm_flush_tlb_others(const struct cpumask *cpumask,</span>
<span class="quote">&gt;&gt; +                     const struct flush_tlb_info *info)</span>
<span class="quote">&gt;&gt; +{</span>
<span class="quote">&gt;&gt; +     u8 state;</span>
<span class="quote">&gt;&gt; +     int cpu;</span>
<span class="quote">&gt;&gt; +     struct kvm_steal_time *src;</span>
<span class="quote">&gt;&gt; +     cpumask_t *flushmask = &amp;per_cpu(__pv_tlb_mask, smp_processor_id());</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +     if (unlikely(!flushmask))</span>
<span class="quote">&gt;&gt; +             return;</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; I don&#39;t see how this can be NULL and if it could, we&#39;d have to call</span>
<span class="quote">&gt; native_flush_tlb_others() instead of returning anyway.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; Also, Peter mentioned that we&#39;re wasting memory (default is 1k per CPU)</span>
<span class="quote">&gt; when not running on KVM.  Hyper-V hijacks x86_platform.apic_post_init()</span>
<span class="quote">&gt; to achieve late allocation.  smp_ops.smp_prepare_cpus seems slightly</span>
<span class="quote">&gt; better for our purposes, but I don&#39;t really like either.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; Couldn&#39;t we use use arch_initcall(), or early_initcall() if there are</span>
<span class="quote">&gt; complications with allocating after smp_init()?</span>

Do it in v7. In addition, move pv_mmu_ops.flush_tlb_others =
kvm_flush_tlb_others to the arch_initcall() fails to work even if I
disable rodata through grub. So I continue to keep the callback
replacement in kvm_guest_init() and late allocation in
arch_initcall().

Regards,
Wanpeng Li
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=69351">Radim Kr?má?</a> - Nov. 30, 2017, 3:14 p.m.</div>
<pre class="content">
2017-11-30 14:24+0800, Wanpeng Li:
<span class="quote">&gt; 2017-11-30 0:21 GMT+08:00 Radim Krčmář &lt;rkrcmar@redhat.com&gt;:</span>
<span class="quote">&gt; &gt; 2017-11-27 20:05-0800, Wanpeng Li:</span>
<span class="quote">&gt; &gt;&gt; From: Wanpeng Li &lt;wanpeng.li@hotmail.com&gt;</span>
<span class="quote">&gt; &gt;&gt; diff --git a/arch/x86/kernel/kvm.c b/arch/x86/kernel/kvm.c</span>
<span class="quote">&gt; &gt;&gt; @@ -498,6 +498,37 @@ static void __init kvm_apf_trap_init(void)</span>
<span class="quote">&gt; &gt;&gt;       update_intr_gate(X86_TRAP_PF, async_page_fault);</span>
<span class="quote">&gt; &gt;&gt;  }</span>
<span class="quote">&gt; &gt;&gt;</span>
<span class="quote">&gt; &gt;&gt; +static DEFINE_PER_CPU(cpumask_t, __pv_tlb_mask);</span>
<span class="quote">&gt; &gt;&gt; +</span>
<span class="quote">&gt; &gt;&gt; +static void kvm_flush_tlb_others(const struct cpumask *cpumask,</span>
<span class="quote">&gt; &gt;&gt; +                     const struct flush_tlb_info *info)</span>
<span class="quote">&gt; &gt;&gt; +{</span>
<span class="quote">&gt; &gt;&gt; +     u8 state;</span>
<span class="quote">&gt; &gt;&gt; +     int cpu;</span>
<span class="quote">&gt; &gt;&gt; +     struct kvm_steal_time *src;</span>
<span class="quote">&gt; &gt;&gt; +     cpumask_t *flushmask = &amp;per_cpu(__pv_tlb_mask, smp_processor_id());</span>
<span class="quote">&gt; &gt;&gt; +</span>
<span class="quote">&gt; &gt;&gt; +     if (unlikely(!flushmask))</span>
<span class="quote">&gt; &gt;&gt; +             return;</span>
<span class="quote">&gt; &gt;</span>
<span class="quote">&gt; &gt; I don&#39;t see how this can be NULL and if it could, we&#39;d have to call</span>
<span class="quote">&gt; &gt; native_flush_tlb_others() instead of returning anyway.</span>
<span class="quote">&gt; &gt;</span>
<span class="quote">&gt; &gt; Also, Peter mentioned that we&#39;re wasting memory (default is 1k per CPU)</span>
<span class="quote">&gt; &gt; when not running on KVM.  Hyper-V hijacks x86_platform.apic_post_init()</span>
<span class="quote">&gt; &gt; to achieve late allocation.  smp_ops.smp_prepare_cpus seems slightly</span>
<span class="quote">&gt; &gt; better for our purposes, but I don&#39;t really like either.</span>
<span class="quote">&gt; &gt;</span>
<span class="quote">&gt; &gt; Couldn&#39;t we use use arch_initcall(), or early_initcall() if there are</span>
<span class="quote">&gt; &gt; complications with allocating after smp_init()?</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Do it in v7. In addition, move pv_mmu_ops.flush_tlb_others =</span>
<span class="quote">&gt; kvm_flush_tlb_others to the arch_initcall() fails to work even if I</span>
<span class="quote">&gt; disable rodata through grub. So I continue to keep the callback</span>
<span class="quote">&gt; replacement in kvm_guest_init() and late allocation in</span>
<span class="quote">&gt; arch_initcall().</span>

I think it has to do with the patching -- you&#39;d need to re-patch
flush_tlb_others callsites for the change to take effect or add a
hypervisor late init just before check_bugs(), where the patching is
currently done.

Not sure how either of those is acceptable, though.
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/Documentation/virtual/kvm/cpuid.txt b/Documentation/virtual/kvm/cpuid.txt</span>
<span class="p_header">index 3c65feb..dcab6dc 100644</span>
<span class="p_header">--- a/Documentation/virtual/kvm/cpuid.txt</span>
<span class="p_header">+++ b/Documentation/virtual/kvm/cpuid.txt</span>
<span class="p_chunk">@@ -54,6 +54,10 @@</span> <span class="p_context"> KVM_FEATURE_PV_UNHALT              ||     7 || guest checks this feature bit</span>
                                    ||       || before enabling paravirtualized
                                    ||       || spinlock support.
 ------------------------------------------------------------------------------
<span class="p_add">+KVM_FEATURE_PV_TLB_FLUSH           ||     9 || guest checks this feature bit</span>
<span class="p_add">+                                   ||       || before enabling paravirtualized</span>
<span class="p_add">+                                   ||       || tlb flush.</span>
<span class="p_add">+------------------------------------------------------------------------------</span>
 KVM_FEATURE_CLOCKSOURCE_STABLE_BIT ||    24 || host will warn if no guest-side
                                    ||       || per-cpu warps are expected in
                                    ||       || kvmclock.
<span class="p_header">diff --git a/arch/x86/include/uapi/asm/kvm_para.h b/arch/x86/include/uapi/asm/kvm_para.h</span>
<span class="p_header">index 763b692..8fbcc16 100644</span>
<span class="p_header">--- a/arch/x86/include/uapi/asm/kvm_para.h</span>
<span class="p_header">+++ b/arch/x86/include/uapi/asm/kvm_para.h</span>
<span class="p_chunk">@@ -25,6 +25,7 @@</span> <span class="p_context"></span>
 #define KVM_FEATURE_STEAL_TIME		5
 #define KVM_FEATURE_PV_EOI		6
 #define KVM_FEATURE_PV_UNHALT		7
<span class="p_add">+#define KVM_FEATURE_PV_TLB_FLUSH	9</span>
 
 /* The last 8 bits are used to indicate how to interpret the flags field
  * in pvclock structure. If no bits are set, all flags are ignored.
<span class="p_chunk">@@ -53,6 +54,7 @@</span> <span class="p_context"> struct kvm_steal_time {</span>
 
 #define KVM_VCPU_NOT_PREEMPTED      (0 &lt;&lt; 0)
 #define KVM_VCPU_PREEMPTED          (1 &lt;&lt; 0)
<span class="p_add">+#define KVM_VCPU_SHOULD_FLUSH       (1 &lt;&lt; 1)</span>
 
 #define KVM_CLOCK_PAIRING_WALLCLOCK 0
 struct kvm_clock_pairing {
<span class="p_header">diff --git a/arch/x86/kernel/kvm.c b/arch/x86/kernel/kvm.c</span>
<span class="p_header">index 6610b92..5645ed6 100644</span>
<span class="p_header">--- a/arch/x86/kernel/kvm.c</span>
<span class="p_header">+++ b/arch/x86/kernel/kvm.c</span>
<span class="p_chunk">@@ -498,6 +498,37 @@</span> <span class="p_context"> static void __init kvm_apf_trap_init(void)</span>
 	update_intr_gate(X86_TRAP_PF, async_page_fault);
 }
 
<span class="p_add">+static DEFINE_PER_CPU(cpumask_t, __pv_tlb_mask);</span>
<span class="p_add">+</span>
<span class="p_add">+static void kvm_flush_tlb_others(const struct cpumask *cpumask,</span>
<span class="p_add">+			const struct flush_tlb_info *info)</span>
<span class="p_add">+{</span>
<span class="p_add">+	u8 state;</span>
<span class="p_add">+	int cpu;</span>
<span class="p_add">+	struct kvm_steal_time *src;</span>
<span class="p_add">+	cpumask_t *flushmask = &amp;per_cpu(__pv_tlb_mask, smp_processor_id());</span>
<span class="p_add">+</span>
<span class="p_add">+	if (unlikely(!flushmask))</span>
<span class="p_add">+		return;</span>
<span class="p_add">+</span>
<span class="p_add">+	cpumask_copy(flushmask, cpumask);</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * We have to call flush only on online vCPUs. And</span>
<span class="p_add">+	 * queue flush_on_enter for pre-empted vCPUs</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	for_each_cpu(cpu, flushmask) {</span>
<span class="p_add">+		src = &amp;per_cpu(steal_time, cpu);</span>
<span class="p_add">+		state = READ_ONCE(src-&gt;preempted);</span>
<span class="p_add">+		if ((state &amp; KVM_VCPU_PREEMPTED)) {</span>
<span class="p_add">+			if (try_cmpxchg(&amp;src-&gt;preempted, &amp;state,</span>
<span class="p_add">+				state | KVM_VCPU_SHOULD_FLUSH))</span>
<span class="p_add">+				__cpumask_clear_cpu(cpu, flushmask);</span>
<span class="p_add">+		}</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	native_flush_tlb_others(flushmask, info);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static void __init kvm_guest_init(void)
 {
 	int i;
<span class="p_chunk">@@ -517,6 +548,9 @@</span> <span class="p_context"> static void __init kvm_guest_init(void)</span>
 		pv_time_ops.steal_clock = kvm_steal_clock;
 	}
 
<span class="p_add">+	if (kvm_para_has_feature(KVM_FEATURE_PV_TLB_FLUSH))</span>
<span class="p_add">+		pv_mmu_ops.flush_tlb_others = kvm_flush_tlb_others;</span>
<span class="p_add">+</span>
 	if (kvm_para_has_feature(KVM_FEATURE_PV_EOI))
 		apic_set_eoi_write(kvm_guest_apic_eoi_write);
 

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



