
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>[RFC] x86/hweight: Get rid of the special calling convention - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    [RFC] x86/hweight: Get rid of the special calling convention</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=57321">Borislav Petkov</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>May 4, 2016, 6:46 p.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;20160504184612.GC23257@pd.tnic&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/9017461/mbox/"
   >mbox</a>
|
   <a href="/patch/9017461/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/9017461/">/patch/9017461/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
X-Original-To: patchwork-LKML@patchwork.kernel.org
Delivered-To: patchwork-parsemail@patchwork1.web.kernel.org
Received: from mail.kernel.org (mail.kernel.org [198.145.29.136])
	by patchwork1.web.kernel.org (Postfix) with ESMTP id 1C30D9F1C1
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Wed,  4 May 2016 18:46:27 +0000 (UTC)
Received: from mail.kernel.org (localhost [127.0.0.1])
	by mail.kernel.org (Postfix) with ESMTP id 5F983203C1
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Wed,  4 May 2016 18:46:25 +0000 (UTC)
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.kernel.org (Postfix) with ESMTP id 1CF3F203DB
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Wed,  4 May 2016 18:46:23 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1752714AbcEDSqS (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Wed, 4 May 2016 14:46:18 -0400
Received: from mx2.suse.de ([195.135.220.15]:43568 &quot;EHLO mx2.suse.de&quot;
	rhost-flags-OK-OK-OK-OK) by vger.kernel.org with ESMTP
	id S1751088AbcEDSqR (ORCPT &lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Wed, 4 May 2016 14:46:17 -0400
X-Virus-Scanned: by amavisd-new at test-mx.suse.de
Received: from relay2.suse.de (charybdis-ext.suse.de [195.135.220.254])
	by mx2.suse.de (Postfix) with ESMTP id D3A6CAD6F;
	Wed,  4 May 2016 18:46:14 +0000 (UTC)
Received: by pd.tnic (Postfix, from userid 1000)
	id 356651618E4; Wed,  4 May 2016 20:46:12 +0200 (CEST)
Date: Wed, 4 May 2016 20:46:12 +0200
From: Borislav Petkov &lt;bp@suse.de&gt;
To: LKML &lt;linux-kernel@vger.kernel.org&gt;
Cc: Dmitry Vyukov &lt;dvyukov@google.com&gt;,
	Andi Kleen &lt;andi@firstfloor.org&gt;, zengzhaoxiu@163.com,
	Thomas Gleixner &lt;tglx@linutronix.de&gt;, Ingo Molnar &lt;mingo@redhat.com&gt;,
	&quot;H. Peter Anvin&quot; &lt;hpa@zytor.com&gt;, Denys Vlasenko &lt;dvlasenk@redhat.com&gt;,
	Andrew Morton &lt;akpm@linux-foundation.org&gt;,
	Kees Cook &lt;keescook@chromium.org&gt;, Zhaoxiu Zeng &lt;zhaoxiu.zeng@gmail.com&gt;,
	Andy Lutomirski &lt;luto@amacapital.net&gt;,
	Peter Zijlstra &lt;peterz@infradead.org&gt;
Subject: [RFC PATCH] x86/hweight: Get rid of the special calling convention
Message-ID: &lt;20160504184612.GC23257@pd.tnic&gt;
References: &lt;57031D9D.801@gmail.com&gt;
	&lt;1459934085-7152-1-git-send-email-zengzhaoxiu@163.com&gt;
	&lt;87wpoay10o.fsf@tassilo.jf.intel.com&gt;
	&lt;CACT4Y+ZGbzTJj5G1EYW6fcuHxEB8NezfzB9nKBgtBEETpGPtHQ@mail.gmail.com&gt;
	&lt;20160407094333.GD3866@pd.tnic&gt;
MIME-Version: 1.0
Content-Type: text/plain; charset=utf-8
Content-Disposition: inline
Content-Transfer-Encoding: 8bit
In-Reply-To: &lt;20160407094333.GD3866@pd.tnic&gt;
User-Agent: Mutt/1.5.24 (2015-08-30)
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Spam-Status: No, score=-9.0 required=5.0 tests=BAYES_00, RCVD_IN_DNSWL_HI, 
	RP_MATCHES_RCVD,
	UNPARSEABLE_RELAY autolearn=unavailable version=3.3.1
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on mail.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=57321">Borislav Petkov</a> - May 4, 2016, 6:46 p.m.</div>
<pre class="content">
On Thu, Apr 07, 2016 at 11:43:33AM +0200, Borislav Petkov wrote:
<span class="quote">&gt; I guess we can do something like this:</span>
<span class="quote">&gt; </span>
<span class="quote">&gt;        if (likely(static_cpu_has(X86_FEATURE_POPCNT)))</span>
<span class="quote">&gt;                asm volatile(POPCNT32</span>
<span class="quote">&gt;                             : &quot;=&quot;REG_OUT (res)</span>
<span class="quote">&gt;                             : REG_IN (w));</span>
<span class="quote">&gt;        else</span>
<span class="quote">&gt;                res = __sw_hweight32(w);</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; and get rid of the custom calling convention.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Along with some numbers showing that the change doesn&#39;t cause any</span>
<span class="quote">&gt; noticeable slowdown...</span>

Ok, here&#39;s something which seems to build and boot in kvm.

I like how we don&#39;t need the special calling conventions anymore and we
can actually say &quot;popcnt ..&quot; and gcc selects registers.

The include files hackery is kinda nasty but I had to do it because I
needed to be able to use static_cpu_has() in a header and including
asm/cpufeature.h pulls in all kinds of nasty dependencies. I&#39;m certainly
open for better ideas...

---
<span class="from">From: Borislav Petkov &lt;bp@suse.de&gt;</span>
Date: Wed, 4 May 2016 18:52:09 +0200
Subject: [PATCH] x86/hweight: Get rid of the special calling convention

People complained about ARCH_HWEIGHT_CFLAGS and how it throws a wrench
into kcov, lto, etc, experimentation.

And its not like we absolutely need it so let&#39;s get rid of it and
streamline it a bit. I had to do some carving out of facilities so
that the include hell doesn&#39;t swallow me but other than that, the new
__arch_hweight*() versions look much more palatable and gcc is more free
to select registers than us hardcoding them in the insn bytes.
<span class="signed-off-by">
Signed-off-by: Borislav Petkov &lt;bp@suse.de&gt;</span>
---
 arch/x86/Kconfig                      |   5 --
 arch/x86/include/asm/arch_hweight.h   |  43 ++++---------
 arch/x86/include/asm/cpufeature.h     | 112 +-------------------------------
 arch/x86/include/asm/cpuinfo.h        |  65 +++++++++++++++++++
 arch/x86/include/asm/processor.h      |  63 +-----------------
 arch/x86/include/asm/static_cpu_has.h | 116 ++++++++++++++++++++++++++++++++++
 lib/Makefile                          |   5 --
 7 files changed, 197 insertions(+), 212 deletions(-)
 create mode 100644 arch/x86/include/asm/cpuinfo.h
 create mode 100644 arch/x86/include/asm/static_cpu_has.h
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=188">Brian Gerst</a> - May 4, 2016, 7:31 p.m.</div>
<pre class="content">
On Wed, May 4, 2016 at 2:46 PM, Borislav Petkov &lt;bp@suse.de&gt; wrote:
<span class="quote">&gt; On Thu, Apr 07, 2016 at 11:43:33AM +0200, Borislav Petkov wrote:</span>
<span class="quote">&gt;&gt; I guess we can do something like this:</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt;        if (likely(static_cpu_has(X86_FEATURE_POPCNT)))</span>
<span class="quote">&gt;&gt;                asm volatile(POPCNT32</span>
<span class="quote">&gt;&gt;                             : &quot;=&quot;REG_OUT (res)</span>
<span class="quote">&gt;&gt;                             : REG_IN (w));</span>
<span class="quote">&gt;&gt;        else</span>
<span class="quote">&gt;&gt;                res = __sw_hweight32(w);</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; and get rid of the custom calling convention.</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; Along with some numbers showing that the change doesn&#39;t cause any</span>
<span class="quote">&gt;&gt; noticeable slowdown...</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; Ok, here&#39;s something which seems to build and boot in kvm.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; I like how we don&#39;t need the special calling conventions anymore and we</span>
<span class="quote">&gt; can actually say &quot;popcnt ..&quot; and gcc selects registers.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; The include files hackery is kinda nasty but I had to do it because I</span>
<span class="quote">&gt; needed to be able to use static_cpu_has() in a header and including</span>
<span class="quote">&gt; asm/cpufeature.h pulls in all kinds of nasty dependencies. I&#39;m certainly</span>
<span class="quote">&gt; open for better ideas...</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; ---</span>
<span class="quote">&gt; From: Borislav Petkov &lt;bp@suse.de&gt;</span>
<span class="quote">&gt; Date: Wed, 4 May 2016 18:52:09 +0200</span>
<span class="quote">&gt; Subject: [PATCH] x86/hweight: Get rid of the special calling convention</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; People complained about ARCH_HWEIGHT_CFLAGS and how it throws a wrench</span>
<span class="quote">&gt; into kcov, lto, etc, experimentation.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; And its not like we absolutely need it so let&#39;s get rid of it and</span>
<span class="quote">&gt; streamline it a bit. I had to do some carving out of facilities so</span>
<span class="quote">&gt; that the include hell doesn&#39;t swallow me but other than that, the new</span>
<span class="quote">&gt; __arch_hweight*() versions look much more palatable and gcc is more free</span>
<span class="quote">&gt; to select registers than us hardcoding them in the insn bytes.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; Signed-off-by: Borislav Petkov &lt;bp@suse.de&gt;</span>
<span class="quote">&gt; ---</span>
<span class="quote">&gt;  arch/x86/Kconfig                      |   5 --</span>
<span class="quote">&gt;  arch/x86/include/asm/arch_hweight.h   |  43 ++++---------</span>
<span class="quote">&gt;  arch/x86/include/asm/cpufeature.h     | 112 +-------------------------------</span>
<span class="quote">&gt;  arch/x86/include/asm/cpuinfo.h        |  65 +++++++++++++++++++</span>
<span class="quote">&gt;  arch/x86/include/asm/processor.h      |  63 +-----------------</span>
<span class="quote">&gt;  arch/x86/include/asm/static_cpu_has.h | 116 ++++++++++++++++++++++++++++++++++</span>
<span class="quote">&gt;  lib/Makefile                          |   5 --</span>
<span class="quote">&gt;  7 files changed, 197 insertions(+), 212 deletions(-)</span>
<span class="quote">&gt;  create mode 100644 arch/x86/include/asm/cpuinfo.h</span>
<span class="quote">&gt;  create mode 100644 arch/x86/include/asm/static_cpu_has.h</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; diff --git a/arch/x86/Kconfig b/arch/x86/Kconfig</span>
<span class="quote">&gt; index 7bb15747fea2..79e0bcd61cb1 100644</span>
<span class="quote">&gt; --- a/arch/x86/Kconfig</span>
<span class="quote">&gt; +++ b/arch/x86/Kconfig</span>
<span class="quote">&gt; @@ -292,11 +292,6 @@ config X86_32_LAZY_GS</span>
<span class="quote">&gt;         def_bool y</span>
<span class="quote">&gt;         depends on X86_32 &amp;&amp; !CC_STACKPROTECTOR</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; -config ARCH_HWEIGHT_CFLAGS</span>
<span class="quote">&gt; -       string</span>
<span class="quote">&gt; -       default &quot;-fcall-saved-ecx -fcall-saved-edx&quot; if X86_32</span>
<span class="quote">&gt; -       default &quot;-fcall-saved-rdi -fcall-saved-rsi -fcall-saved-rdx -fcall-saved-rcx -fcall-saved-r8 -fcall-saved-r9 -fcall-saved-r10 -fcall-saved-r11&quot; if X86_64</span>
<span class="quote">&gt; -</span>
<span class="quote">&gt;  config ARCH_SUPPORTS_UPROBES</span>
<span class="quote">&gt;         def_bool y</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; diff --git a/arch/x86/include/asm/arch_hweight.h b/arch/x86/include/asm/arch_hweight.h</span>
<span class="quote">&gt; index 02e799fa43d1..6c1a2d500c4c 100644</span>
<span class="quote">&gt; --- a/arch/x86/include/asm/arch_hweight.h</span>
<span class="quote">&gt; +++ b/arch/x86/include/asm/arch_hweight.h</span>
<span class="quote">&gt; @@ -2,36 +2,18 @@</span>
<span class="quote">&gt;  #define _ASM_X86_HWEIGHT_H</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;  #include &lt;asm/cpufeatures.h&gt;</span>
<span class="quote">&gt; +#include &lt;asm/static_cpu_has.h&gt;</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; -#ifdef CONFIG_64BIT</span>
<span class="quote">&gt; -/* popcnt %edi, %eax -- redundant REX prefix for alignment */</span>
<span class="quote">&gt; -#define POPCNT32 &quot;.byte 0xf3,0x40,0x0f,0xb8,0xc7&quot;</span>
<span class="quote">&gt; -/* popcnt %rdi, %rax */</span>
<span class="quote">&gt; -#define POPCNT64 &quot;.byte 0xf3,0x48,0x0f,0xb8,0xc7&quot;</span>
<span class="quote">&gt; -#define REG_IN &quot;D&quot;</span>
<span class="quote">&gt; -#define REG_OUT &quot;a&quot;</span>
<span class="quote">&gt; -#else</span>
<span class="quote">&gt; -/* popcnt %eax, %eax */</span>
<span class="quote">&gt; -#define POPCNT32 &quot;.byte 0xf3,0x0f,0xb8,0xc0&quot;</span>
<span class="quote">&gt; -#define REG_IN &quot;a&quot;</span>
<span class="quote">&gt; -#define REG_OUT &quot;a&quot;</span>
<span class="quote">&gt; -#endif</span>
<span class="quote">&gt; -</span>
<span class="quote">&gt; -/*</span>
<span class="quote">&gt; - * __sw_hweightXX are called from within the alternatives below</span>
<span class="quote">&gt; - * and callee-clobbered registers need to be taken care of. See</span>
<span class="quote">&gt; - * ARCH_HWEIGHT_CFLAGS in &lt;arch/x86/Kconfig&gt; for the respective</span>
<span class="quote">&gt; - * compiler switches.</span>
<span class="quote">&gt; - */</span>
<span class="quote">&gt;  static __always_inline unsigned int __arch_hweight32(unsigned int w)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt; -       unsigned int res = 0;</span>
<span class="quote">&gt; +       unsigned int res;</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; -       asm (ALTERNATIVE(&quot;call __sw_hweight32&quot;, POPCNT32, X86_FEATURE_POPCNT)</span>
<span class="quote">&gt; -                    : &quot;=&quot;REG_OUT (res)</span>
<span class="quote">&gt; -                    : REG_IN (w));</span>
<span class="quote">&gt; +       if (likely(static_cpu_has(X86_FEATURE_POPCNT))) {</span>
<span class="quote">&gt; +               asm volatile(&quot;popcnt %[w], %[res]&quot; : [res] &quot;=r&quot; (res) : [w] &quot;r&quot; (w));</span>

Do all supported versions of the assembler know of the popcnt
instruction?  That&#39;s why is was open coded before.  The problem is
Intel and AMD are constantly adding new instructions and it&#39;s a long
cycle for the user&#39;s assembler to get updated.

--
Brian Gerst
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=42">H. Peter Anvin</a> - May 4, 2016, 7:33 p.m.</div>
<pre class="content">
On 05/04/2016 12:31 PM, Brian Gerst wrote:
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; -       asm (ALTERNATIVE(&quot;call __sw_hweight32&quot;, POPCNT32, X86_FEATURE_POPCNT)</span>
<span class="quote">&gt;&gt; -                    : &quot;=&quot;REG_OUT (res)</span>
<span class="quote">&gt;&gt; -                    : REG_IN (w));</span>
<span class="quote">&gt;&gt; +       if (likely(static_cpu_has(X86_FEATURE_POPCNT))) {</span>
<span class="quote">&gt;&gt; +               asm volatile(&quot;popcnt %[w], %[res]&quot; : [res] &quot;=r&quot; (res) : [w] &quot;r&quot; (w));</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Do all supported versions of the assembler know of the popcnt</span>
<span class="quote">&gt; instruction?  That&#39;s why is was open coded before.  The problem is</span>
<span class="quote">&gt; Intel and AMD are constantly adding new instructions and it&#39;s a long</span>
<span class="quote">&gt; cycle for the user&#39;s assembler to get updated.</span>
<span class="quote">&gt; </span>

Most likely not.  It would be nice to have some more uniform solution to
that.  I&#39;m wondering if we could use the -Wa option to load some kind of
macro package.

	-hpa
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=57321">Borislav Petkov</a> - May 4, 2016, 7:41 p.m.</div>
<pre class="content">
On Wed, May 04, 2016 at 12:33:24PM -0700, H. Peter Anvin wrote:
<span class="quote">&gt; Most likely not.  It would be nice to have some more uniform solution to</span>
<span class="quote">&gt; that.  I&#39;m wondering if we could use the -Wa option to load some kind of</span>
<span class="quote">&gt; macro package.</span>

Lemme try out some old compilers first, I&#39;m guessing 3.2 won&#39;t know
about popcnt...
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=42">H. Peter Anvin</a> - May 4, 2016, 7:49 p.m.</div>
<pre class="content">
On 05/04/2016 12:41 PM, Borislav Petkov wrote:
<span class="quote">&gt; On Wed, May 04, 2016 at 12:33:24PM -0700, H. Peter Anvin wrote:</span>
<span class="quote">&gt;&gt; Most likely not.  It would be nice to have some more uniform solution to</span>
<span class="quote">&gt;&gt; that.  I&#39;m wondering if we could use the -Wa option to load some kind of</span>
<span class="quote">&gt;&gt; macro package.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Lemme try out some old compilers first, I&#39;m guessing 3.2 won&#39;t know</span>
<span class="quote">&gt; about popcnt...</span>
<span class="quote">&gt; </span>

Sigh.  Doesn&#39;t look like -Wa is going to help due to the lack of the
equivalent of an -include option in gas.

	-hpa
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=57321">Borislav Petkov</a> - May 4, 2016, 8:22 p.m.</div>
<pre class="content">
On Wed, May 04, 2016 at 12:49:17PM -0700, H. Peter Anvin wrote:
<span class="quote">&gt; Sigh.  Doesn&#39;t look like -Wa is going to help due to the lack of the</span>
<span class="quote">&gt; equivalent of an -include option in gas.</span>

So much for the register &quot;freedom&quot; - I&#39;ll resurrect the hardcoded insn
bytes. :-\

Unless my gcc friends have some other ideas...

sarge:~# gcc --version
gcc (GCC) 3.3.5 (Debian 1:3.3.5-13)
Copyright (C) 2003 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.

sarge:~# cat popcnt.c
int main(void)
{
        int a, b;

        asm volatile(&quot;popcnt %0, %1&quot; : &quot;=r&quot; (a) : &quot;r&quot; (b));

        return 0;
}
sarge:~# gcc -Wall -o popcnt{,.c}
/tmp/ccHmmgjH.s: Assembler messages:
/tmp/ccHmmgjH.s:14: Error: no such instruction: `popcnt %eax,%eax&#39;
sarge:~#
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=42">H. Peter Anvin</a> - May 4, 2016, 8:51 p.m.</div>
<pre class="content">
On 05/04/2016 01:22 PM, Borislav Petkov wrote:
<span class="quote">&gt; On Wed, May 04, 2016 at 12:49:17PM -0700, H. Peter Anvin wrote:</span>
<span class="quote">&gt;&gt; Sigh.  Doesn&#39;t look like -Wa is going to help due to the lack of the</span>
<span class="quote">&gt;&gt; equivalent of an -include option in gas.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; So much for the register &quot;freedom&quot; - I&#39;ll resurrect the hardcoded insn</span>
<span class="quote">&gt; bytes. :-\</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Unless my gcc friends have some other ideas...</span>

There is the option of looking for assembler support for popcnt and only
hard-code the register if not supported.  This is where being able to
insert a macro package would help...

	-hpa
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=104">Andi Kleen</a> - May 4, 2016, 9:09 p.m.</div>
<pre class="content">
On Wed, May 04, 2016 at 10:22:13PM +0200, Borislav Petkov wrote:
<span class="quote">&gt; On Wed, May 04, 2016 at 12:49:17PM -0700, H. Peter Anvin wrote:</span>
<span class="quote">&gt; &gt; Sigh.  Doesn&#39;t look like -Wa is going to help due to the lack of the</span>
<span class="quote">&gt; &gt; equivalent of an -include option in gas.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; So much for the register &quot;freedom&quot; - I&#39;ll resurrect the hardcoded insn</span>
<span class="quote">&gt; bytes. :-\</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Unless my gcc friends have some other ideas...</span>

You can probe the assembler in the Makefile and pass a define,
like it is done by the dwarf code.  When the define is not
set use the hard coded registers

Not very scalable, but may work in this case.

Longer term would probably need compiler probes at Kconfig
time (this would be useful for a lot of things)

-Andi
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=59711">Denys Vlasenko</a> - May 5, 2016, 1:02 p.m.</div>
<pre class="content">
On 05/04/2016 10:22 PM, Borislav Petkov wrote:
<span class="quote">&gt; On Wed, May 04, 2016 at 12:49:17PM -0700, H. Peter Anvin wrote:</span>
<span class="quote">&gt;&gt; Sigh.  Doesn&#39;t look like -Wa is going to help due to the lack of the</span>
<span class="quote">&gt;&gt; equivalent of an -include option in gas.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; So much for the register &quot;freedom&quot; - I&#39;ll resurrect the hardcoded insn</span>
<span class="quote">&gt; bytes. :-\</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Unless my gcc friends have some other ideas...</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; sarge:~# gcc --version</span>
<span class="quote">&gt; gcc (GCC) 3.3.5 (Debian 1:3.3.5-13)</span>
<span class="quote">&gt; Copyright (C) 2003 Free Software Foundation, Inc.</span>
<span class="quote">&gt; This is free software; see the source for copying conditions.  There is NO</span>
<span class="quote">&gt; warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; sarge:~# cat popcnt.c</span>
<span class="quote">&gt; int main(void)</span>
<span class="quote">&gt; {</span>
<span class="quote">&gt;         int a, b;</span>
<span class="quote">&gt; </span>
<span class="quote">&gt;         asm volatile(&quot;popcnt %0, %1&quot; : &quot;=r&quot; (a) : &quot;r&quot; (b));</span>
<span class="quote">&gt; </span>
<span class="quote">&gt;         return 0;</span>
<span class="quote">&gt; }</span>
<span class="quote">&gt; sarge:~# gcc -Wall -o popcnt{,.c}</span>
<span class="quote">&gt; /tmp/ccHmmgjH.s: Assembler messages:</span>
<span class="quote">&gt; /tmp/ccHmmgjH.s:14: Error: no such instruction: `popcnt %eax,%eax&#39;</span>
<span class="quote">&gt; sarge:~#</span>

You are looking at the version of a wrong program.
gcc doesn&#39;t process assembly, it generates it.
as is part of binutils, not gcc. &quot;as --version&quot;.
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=57321">Borislav Petkov</a> - May 5, 2016, 2:04 p.m.</div>
<pre class="content">
On Thu, May 05, 2016 at 03:02:37PM +0200, Denys Vlasenko wrote:
<span class="quote">&gt; You are looking at the version of a wrong program.</span>
<span class="quote">&gt; gcc doesn&#39;t process assembly, it generates it.</span>
<span class="quote">&gt; as is part of binutils, not gcc. &quot;as --version&quot;.</span>

I know. It doesn&#39;t matter a whole lot in this case if there&#39;s a subset
of gas versions which simply don&#39;t know about POPCNT and we do use
those in the kernel build.

Pending a better solution, I&#39;ll simply revert to the old, spelled POPCNT
bytes and don&#39;t bother with versions. Especially if someone tries to
build the kernel with some other compiler...
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/arch/x86/Kconfig b/arch/x86/Kconfig</span>
<span class="p_header">index 7bb15747fea2..79e0bcd61cb1 100644</span>
<span class="p_header">--- a/arch/x86/Kconfig</span>
<span class="p_header">+++ b/arch/x86/Kconfig</span>
<span class="p_chunk">@@ -292,11 +292,6 @@</span> <span class="p_context"> config X86_32_LAZY_GS</span>
 	def_bool y
 	depends on X86_32 &amp;&amp; !CC_STACKPROTECTOR
 
<span class="p_del">-config ARCH_HWEIGHT_CFLAGS</span>
<span class="p_del">-	string</span>
<span class="p_del">-	default &quot;-fcall-saved-ecx -fcall-saved-edx&quot; if X86_32</span>
<span class="p_del">-	default &quot;-fcall-saved-rdi -fcall-saved-rsi -fcall-saved-rdx -fcall-saved-rcx -fcall-saved-r8 -fcall-saved-r9 -fcall-saved-r10 -fcall-saved-r11&quot; if X86_64</span>
<span class="p_del">-</span>
 config ARCH_SUPPORTS_UPROBES
 	def_bool y
 
<span class="p_header">diff --git a/arch/x86/include/asm/arch_hweight.h b/arch/x86/include/asm/arch_hweight.h</span>
<span class="p_header">index 02e799fa43d1..6c1a2d500c4c 100644</span>
<span class="p_header">--- a/arch/x86/include/asm/arch_hweight.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/arch_hweight.h</span>
<span class="p_chunk">@@ -2,36 +2,18 @@</span> <span class="p_context"></span>
 #define _ASM_X86_HWEIGHT_H
 
 #include &lt;asm/cpufeatures.h&gt;
<span class="p_add">+#include &lt;asm/static_cpu_has.h&gt;</span>
 
<span class="p_del">-#ifdef CONFIG_64BIT</span>
<span class="p_del">-/* popcnt %edi, %eax -- redundant REX prefix for alignment */</span>
<span class="p_del">-#define POPCNT32 &quot;.byte 0xf3,0x40,0x0f,0xb8,0xc7&quot;</span>
<span class="p_del">-/* popcnt %rdi, %rax */</span>
<span class="p_del">-#define POPCNT64 &quot;.byte 0xf3,0x48,0x0f,0xb8,0xc7&quot;</span>
<span class="p_del">-#define REG_IN &quot;D&quot;</span>
<span class="p_del">-#define REG_OUT &quot;a&quot;</span>
<span class="p_del">-#else</span>
<span class="p_del">-/* popcnt %eax, %eax */</span>
<span class="p_del">-#define POPCNT32 &quot;.byte 0xf3,0x0f,0xb8,0xc0&quot;</span>
<span class="p_del">-#define REG_IN &quot;a&quot;</span>
<span class="p_del">-#define REG_OUT &quot;a&quot;</span>
<span class="p_del">-#endif</span>
<span class="p_del">-</span>
<span class="p_del">-/*</span>
<span class="p_del">- * __sw_hweightXX are called from within the alternatives below</span>
<span class="p_del">- * and callee-clobbered registers need to be taken care of. See</span>
<span class="p_del">- * ARCH_HWEIGHT_CFLAGS in &lt;arch/x86/Kconfig&gt; for the respective</span>
<span class="p_del">- * compiler switches.</span>
<span class="p_del">- */</span>
 static __always_inline unsigned int __arch_hweight32(unsigned int w)
 {
<span class="p_del">-	unsigned int res = 0;</span>
<span class="p_add">+	unsigned int res;</span>
 
<span class="p_del">-	asm (ALTERNATIVE(&quot;call __sw_hweight32&quot;, POPCNT32, X86_FEATURE_POPCNT)</span>
<span class="p_del">-		     : &quot;=&quot;REG_OUT (res)</span>
<span class="p_del">-		     : REG_IN (w));</span>
<span class="p_add">+	if (likely(static_cpu_has(X86_FEATURE_POPCNT))) {</span>
<span class="p_add">+		asm volatile(&quot;popcnt %[w], %[res]&quot; : [res] &quot;=r&quot; (res) : [w] &quot;r&quot; (w));</span>
 
<span class="p_del">-	return res;</span>
<span class="p_add">+		return res;</span>
<span class="p_add">+	}</span>
<span class="p_add">+	return __sw_hweight32(w);</span>
 }
 
 static inline unsigned int __arch_hweight16(unsigned int w)
<span class="p_chunk">@@ -53,13 +35,14 @@</span> <span class="p_context"> static inline unsigned long __arch_hweight64(__u64 w)</span>
 #else
 static __always_inline unsigned long __arch_hweight64(__u64 w)
 {
<span class="p_del">-	unsigned long res = 0;</span>
<span class="p_add">+	unsigned long res;</span>
 
<span class="p_del">-	asm (ALTERNATIVE(&quot;call __sw_hweight64&quot;, POPCNT64, X86_FEATURE_POPCNT)</span>
<span class="p_del">-		     : &quot;=&quot;REG_OUT (res)</span>
<span class="p_del">-		     : REG_IN (w));</span>
<span class="p_add">+	if (likely(static_cpu_has(X86_FEATURE_POPCNT))) {</span>
<span class="p_add">+		asm volatile(&quot;popcnt %[w], %[res]&quot; : [res] &quot;=r&quot; (res) : [w] &quot;r&quot; (w));</span>
 
<span class="p_del">-	return res;</span>
<span class="p_add">+		return res;</span>
<span class="p_add">+	}</span>
<span class="p_add">+	return __sw_hweight64(w);</span>
 }
 #endif /* CONFIG_X86_32 */
 
<span class="p_header">diff --git a/arch/x86/include/asm/cpufeature.h b/arch/x86/include/asm/cpufeature.h</span>
<span class="p_header">index 07c942d84662..9a70b12ae8df 100644</span>
<span class="p_header">--- a/arch/x86/include/asm/cpufeature.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/cpufeature.h</span>
<span class="p_chunk">@@ -6,6 +6,8 @@</span> <span class="p_context"></span>
 #if defined(__KERNEL__) &amp;&amp; !defined(__ASSEMBLY__)
 
 #include &lt;asm/asm.h&gt;
<span class="p_add">+#include &lt;asm/static_cpu_has.h&gt;</span>
<span class="p_add">+</span>
 #include &lt;linux/bitops.h&gt;
 
 enum cpuid_leafs
<span class="p_chunk">@@ -45,51 +47,6 @@</span> <span class="p_context"> extern const char * const x86_power_flags[32];</span>
  */
 extern const char * const x86_bug_flags[NBUGINTS*32];
 
<span class="p_del">-#define test_cpu_cap(c, bit)						\</span>
<span class="p_del">-	 test_bit(bit, (unsigned long *)((c)-&gt;x86_capability))</span>
<span class="p_del">-</span>
<span class="p_del">-#define REQUIRED_MASK_BIT_SET(bit)					\</span>
<span class="p_del">-	 ( (((bit)&gt;&gt;5)==0  &amp;&amp; (1UL&lt;&lt;((bit)&amp;31) &amp; REQUIRED_MASK0 )) ||	\</span>
<span class="p_del">-	   (((bit)&gt;&gt;5)==1  &amp;&amp; (1UL&lt;&lt;((bit)&amp;31) &amp; REQUIRED_MASK1 )) ||	\</span>
<span class="p_del">-	   (((bit)&gt;&gt;5)==2  &amp;&amp; (1UL&lt;&lt;((bit)&amp;31) &amp; REQUIRED_MASK2 )) ||	\</span>
<span class="p_del">-	   (((bit)&gt;&gt;5)==3  &amp;&amp; (1UL&lt;&lt;((bit)&amp;31) &amp; REQUIRED_MASK3 )) ||	\</span>
<span class="p_del">-	   (((bit)&gt;&gt;5)==4  &amp;&amp; (1UL&lt;&lt;((bit)&amp;31) &amp; REQUIRED_MASK4 )) ||	\</span>
<span class="p_del">-	   (((bit)&gt;&gt;5)==5  &amp;&amp; (1UL&lt;&lt;((bit)&amp;31) &amp; REQUIRED_MASK5 )) ||	\</span>
<span class="p_del">-	   (((bit)&gt;&gt;5)==6  &amp;&amp; (1UL&lt;&lt;((bit)&amp;31) &amp; REQUIRED_MASK6 )) ||	\</span>
<span class="p_del">-	   (((bit)&gt;&gt;5)==7  &amp;&amp; (1UL&lt;&lt;((bit)&amp;31) &amp; REQUIRED_MASK7 )) ||	\</span>
<span class="p_del">-	   (((bit)&gt;&gt;5)==8  &amp;&amp; (1UL&lt;&lt;((bit)&amp;31) &amp; REQUIRED_MASK8 )) ||	\</span>
<span class="p_del">-	   (((bit)&gt;&gt;5)==9  &amp;&amp; (1UL&lt;&lt;((bit)&amp;31) &amp; REQUIRED_MASK9 )) ||	\</span>
<span class="p_del">-	   (((bit)&gt;&gt;5)==10 &amp;&amp; (1UL&lt;&lt;((bit)&amp;31) &amp; REQUIRED_MASK10)) ||	\</span>
<span class="p_del">-	   (((bit)&gt;&gt;5)==11 &amp;&amp; (1UL&lt;&lt;((bit)&amp;31) &amp; REQUIRED_MASK11)) ||	\</span>
<span class="p_del">-	   (((bit)&gt;&gt;5)==12 &amp;&amp; (1UL&lt;&lt;((bit)&amp;31) &amp; REQUIRED_MASK12)) ||	\</span>
<span class="p_del">-	   (((bit)&gt;&gt;5)==13 &amp;&amp; (1UL&lt;&lt;((bit)&amp;31) &amp; REQUIRED_MASK13)) ||	\</span>
<span class="p_del">-	   (((bit)&gt;&gt;5)==13 &amp;&amp; (1UL&lt;&lt;((bit)&amp;31) &amp; REQUIRED_MASK14)) ||	\</span>
<span class="p_del">-	   (((bit)&gt;&gt;5)==13 &amp;&amp; (1UL&lt;&lt;((bit)&amp;31) &amp; REQUIRED_MASK15)) ||	\</span>
<span class="p_del">-	   (((bit)&gt;&gt;5)==14 &amp;&amp; (1UL&lt;&lt;((bit)&amp;31) &amp; REQUIRED_MASK16)) )</span>
<span class="p_del">-</span>
<span class="p_del">-#define DISABLED_MASK_BIT_SET(bit)					\</span>
<span class="p_del">-	 ( (((bit)&gt;&gt;5)==0  &amp;&amp; (1UL&lt;&lt;((bit)&amp;31) &amp; DISABLED_MASK0 )) ||	\</span>
<span class="p_del">-	   (((bit)&gt;&gt;5)==1  &amp;&amp; (1UL&lt;&lt;((bit)&amp;31) &amp; DISABLED_MASK1 )) ||	\</span>
<span class="p_del">-	   (((bit)&gt;&gt;5)==2  &amp;&amp; (1UL&lt;&lt;((bit)&amp;31) &amp; DISABLED_MASK2 )) ||	\</span>
<span class="p_del">-	   (((bit)&gt;&gt;5)==3  &amp;&amp; (1UL&lt;&lt;((bit)&amp;31) &amp; DISABLED_MASK3 )) ||	\</span>
<span class="p_del">-	   (((bit)&gt;&gt;5)==4  &amp;&amp; (1UL&lt;&lt;((bit)&amp;31) &amp; DISABLED_MASK4 )) ||	\</span>
<span class="p_del">-	   (((bit)&gt;&gt;5)==5  &amp;&amp; (1UL&lt;&lt;((bit)&amp;31) &amp; DISABLED_MASK5 )) ||	\</span>
<span class="p_del">-	   (((bit)&gt;&gt;5)==6  &amp;&amp; (1UL&lt;&lt;((bit)&amp;31) &amp; DISABLED_MASK6 )) ||	\</span>
<span class="p_del">-	   (((bit)&gt;&gt;5)==7  &amp;&amp; (1UL&lt;&lt;((bit)&amp;31) &amp; DISABLED_MASK7 )) ||	\</span>
<span class="p_del">-	   (((bit)&gt;&gt;5)==8  &amp;&amp; (1UL&lt;&lt;((bit)&amp;31) &amp; DISABLED_MASK8 )) ||	\</span>
<span class="p_del">-	   (((bit)&gt;&gt;5)==9  &amp;&amp; (1UL&lt;&lt;((bit)&amp;31) &amp; DISABLED_MASK9 )) ||	\</span>
<span class="p_del">-	   (((bit)&gt;&gt;5)==10 &amp;&amp; (1UL&lt;&lt;((bit)&amp;31) &amp; DISABLED_MASK10)) ||	\</span>
<span class="p_del">-	   (((bit)&gt;&gt;5)==11 &amp;&amp; (1UL&lt;&lt;((bit)&amp;31) &amp; DISABLED_MASK11)) ||	\</span>
<span class="p_del">-	   (((bit)&gt;&gt;5)==12 &amp;&amp; (1UL&lt;&lt;((bit)&amp;31) &amp; DISABLED_MASK12)) ||	\</span>
<span class="p_del">-	   (((bit)&gt;&gt;5)==13 &amp;&amp; (1UL&lt;&lt;((bit)&amp;31) &amp; DISABLED_MASK13)) ||	\</span>
<span class="p_del">-	   (((bit)&gt;&gt;5)==13 &amp;&amp; (1UL&lt;&lt;((bit)&amp;31) &amp; DISABLED_MASK14)) ||	\</span>
<span class="p_del">-	   (((bit)&gt;&gt;5)==13 &amp;&amp; (1UL&lt;&lt;((bit)&amp;31) &amp; DISABLED_MASK15)) ||	\</span>
<span class="p_del">-	   (((bit)&gt;&gt;5)==14 &amp;&amp; (1UL&lt;&lt;((bit)&amp;31) &amp; DISABLED_MASK16)) )</span>
<span class="p_del">-</span>
<span class="p_del">-#define cpu_has(c, bit)							\</span>
<span class="p_del">-	(__builtin_constant_p(bit) &amp;&amp; REQUIRED_MASK_BIT_SET(bit) ? 1 :	\</span>
<span class="p_del">-	 test_cpu_cap(c, bit))</span>
<span class="p_del">-</span>
 #define this_cpu_has(bit)						\
 	(__builtin_constant_p(bit) &amp;&amp; REQUIRED_MASK_BIT_SET(bit) ? 1 : 	\
 	 x86_this_cpu_test_bit(bit, (unsigned long *)&amp;cpu_info.x86_capability))
<span class="p_chunk">@@ -105,8 +62,6 @@</span> <span class="p_context"> extern const char * const x86_bug_flags[NBUGINTS*32];</span>
 #define cpu_feature_enabled(bit)	\
 	(__builtin_constant_p(bit) &amp;&amp; DISABLED_MASK_BIT_SET(bit) ? 0 : static_cpu_has(bit))
 
<span class="p_del">-#define boot_cpu_has(bit)	cpu_has(&amp;boot_cpu_data, bit)</span>
<span class="p_del">-</span>
 #define set_cpu_cap(c, bit)	set_bit(bit, (unsigned long *)((c)-&gt;x86_capability))
 #define clear_cpu_cap(c, bit)	clear_bit(bit, (unsigned long *)((c)-&gt;x86_capability))
 #define setup_clear_cpu_cap(bit) do { \
<span class="p_chunk">@@ -118,69 +73,6 @@</span> <span class="p_context"> extern const char * const x86_bug_flags[NBUGINTS*32];</span>
 	set_bit(bit, (unsigned long *)cpu_caps_set);	\
 } while (0)
 
<span class="p_del">-#if defined(CC_HAVE_ASM_GOTO) &amp;&amp; defined(CONFIG_X86_FAST_FEATURE_TESTS)</span>
<span class="p_del">-/*</span>
<span class="p_del">- * Static testing of CPU features.  Used the same as boot_cpu_has().</span>
<span class="p_del">- * These will statically patch the target code for additional</span>
<span class="p_del">- * performance.</span>
<span class="p_del">- */</span>
<span class="p_del">-static __always_inline __pure bool _static_cpu_has(u16 bit)</span>
<span class="p_del">-{</span>
<span class="p_del">-		asm_volatile_goto(&quot;1: jmp 6f\n&quot;</span>
<span class="p_del">-			 &quot;2:\n&quot;</span>
<span class="p_del">-			 &quot;.skip -(((5f-4f) - (2b-1b)) &gt; 0) * &quot;</span>
<span class="p_del">-			         &quot;((5f-4f) - (2b-1b)),0x90\n&quot;</span>
<span class="p_del">-			 &quot;3:\n&quot;</span>
<span class="p_del">-			 &quot;.section .altinstructions,\&quot;a\&quot;\n&quot;</span>
<span class="p_del">-			 &quot; .long 1b - .\n&quot;		/* src offset */</span>
<span class="p_del">-			 &quot; .long 4f - .\n&quot;		/* repl offset */</span>
<span class="p_del">-			 &quot; .word %P1\n&quot;			/* always replace */</span>
<span class="p_del">-			 &quot; .byte 3b - 1b\n&quot;		/* src len */</span>
<span class="p_del">-			 &quot; .byte 5f - 4f\n&quot;		/* repl len */</span>
<span class="p_del">-			 &quot; .byte 3b - 2b\n&quot;		/* pad len */</span>
<span class="p_del">-			 &quot;.previous\n&quot;</span>
<span class="p_del">-			 &quot;.section .altinstr_replacement,\&quot;ax\&quot;\n&quot;</span>
<span class="p_del">-			 &quot;4: jmp %l[t_no]\n&quot;</span>
<span class="p_del">-			 &quot;5:\n&quot;</span>
<span class="p_del">-			 &quot;.previous\n&quot;</span>
<span class="p_del">-			 &quot;.section .altinstructions,\&quot;a\&quot;\n&quot;</span>
<span class="p_del">-			 &quot; .long 1b - .\n&quot;		/* src offset */</span>
<span class="p_del">-			 &quot; .long 0\n&quot;			/* no replacement */</span>
<span class="p_del">-			 &quot; .word %P0\n&quot;			/* feature bit */</span>
<span class="p_del">-			 &quot; .byte 3b - 1b\n&quot;		/* src len */</span>
<span class="p_del">-			 &quot; .byte 0\n&quot;			/* repl len */</span>
<span class="p_del">-			 &quot; .byte 0\n&quot;			/* pad len */</span>
<span class="p_del">-			 &quot;.previous\n&quot;</span>
<span class="p_del">-			 &quot;.section .altinstr_aux,\&quot;ax\&quot;\n&quot;</span>
<span class="p_del">-			 &quot;6:\n&quot;</span>
<span class="p_del">-			 &quot; testb %[bitnum],%[cap_byte]\n&quot;</span>
<span class="p_del">-			 &quot; jnz %l[t_yes]\n&quot;</span>
<span class="p_del">-			 &quot; jmp %l[t_no]\n&quot;</span>
<span class="p_del">-			 &quot;.previous\n&quot;</span>
<span class="p_del">-			 : : &quot;i&quot; (bit), &quot;i&quot; (X86_FEATURE_ALWAYS),</span>
<span class="p_del">-			     [bitnum] &quot;i&quot; (1 &lt;&lt; (bit &amp; 7)),</span>
<span class="p_del">-			     [cap_byte] &quot;m&quot; (((const char *)boot_cpu_data.x86_capability)[bit &gt;&gt; 3])</span>
<span class="p_del">-			 : : t_yes, t_no);</span>
<span class="p_del">-	t_yes:</span>
<span class="p_del">-		return true;</span>
<span class="p_del">-	t_no:</span>
<span class="p_del">-		return false;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-#define static_cpu_has(bit)					\</span>
<span class="p_del">-(								\</span>
<span class="p_del">-	__builtin_constant_p(boot_cpu_has(bit)) ?		\</span>
<span class="p_del">-		boot_cpu_has(bit) :				\</span>
<span class="p_del">-		_static_cpu_has(bit)				\</span>
<span class="p_del">-)</span>
<span class="p_del">-#else</span>
<span class="p_del">-/*</span>
<span class="p_del">- * Fall back to dynamic for gcc versions which don&#39;t support asm goto. Should be</span>
<span class="p_del">- * a minority now anyway.</span>
<span class="p_del">- */</span>
<span class="p_del">-#define static_cpu_has(bit)		boot_cpu_has(bit)</span>
<span class="p_del">-#endif</span>
<span class="p_del">-</span>
 #define cpu_has_bug(c, bit)		cpu_has(c, (bit))
 #define set_cpu_bug(c, bit)		set_cpu_cap(c, (bit))
 #define clear_cpu_bug(c, bit)		clear_cpu_cap(c, (bit))
<span class="p_header">diff --git a/arch/x86/include/asm/cpuinfo.h b/arch/x86/include/asm/cpuinfo.h</span>
new file mode 100644
<span class="p_header">index 000000000000..a6632044f199</span>
<span class="p_header">--- /dev/null</span>
<span class="p_header">+++ b/arch/x86/include/asm/cpuinfo.h</span>
<span class="p_chunk">@@ -0,0 +1,65 @@</span> <span class="p_context"></span>
<span class="p_add">+#ifndef _ASM_X86_CPUINFO_H_</span>
<span class="p_add">+#define _ASM_X86_CPUINFO_H_</span>
<span class="p_add">+</span>
<span class="p_add">+/*</span>
<span class="p_add">+ *  CPU type and hardware bug flags. Kept separately for each CPU.</span>
<span class="p_add">+ *  Members of this structure are referenced in head.S, so think twice</span>
<span class="p_add">+ *  before touching them. [mj]</span>
<span class="p_add">+ */</span>
<span class="p_add">+struct cpuinfo_x86 {</span>
<span class="p_add">+	__u8			x86;		/* CPU family */</span>
<span class="p_add">+	__u8			x86_vendor;	/* CPU vendor */</span>
<span class="p_add">+	__u8			x86_model;</span>
<span class="p_add">+	__u8			x86_mask;</span>
<span class="p_add">+#ifdef CONFIG_X86_32</span>
<span class="p_add">+	char			wp_works_ok;	/* It doesn&#39;t on 386&#39;s */</span>
<span class="p_add">+</span>
<span class="p_add">+	/* Problems on some 486Dx4&#39;s and old 386&#39;s: */</span>
<span class="p_add">+	char			rfu;</span>
<span class="p_add">+	char			pad0;</span>
<span class="p_add">+	char			pad1;</span>
<span class="p_add">+#else</span>
<span class="p_add">+	/* Number of 4K pages in DTLB/ITLB combined(in pages): */</span>
<span class="p_add">+	int			x86_tlbsize;</span>
<span class="p_add">+#endif</span>
<span class="p_add">+	__u8			x86_virt_bits;</span>
<span class="p_add">+	__u8			x86_phys_bits;</span>
<span class="p_add">+	/* CPUID returned core id bits: */</span>
<span class="p_add">+	__u8			x86_coreid_bits;</span>
<span class="p_add">+	/* Max extended CPUID function supported: */</span>
<span class="p_add">+	__u32			extended_cpuid_level;</span>
<span class="p_add">+	/* Maximum supported CPUID level, -1=no CPUID: */</span>
<span class="p_add">+	int			cpuid_level;</span>
<span class="p_add">+	__u32			x86_capability[NCAPINTS + NBUGINTS];</span>
<span class="p_add">+	char			x86_vendor_id[16];</span>
<span class="p_add">+	char			x86_model_id[64];</span>
<span class="p_add">+	/* in KB - valid for CPUS which support this call: */</span>
<span class="p_add">+	int			x86_cache_size;</span>
<span class="p_add">+	int			x86_cache_alignment;	/* In bytes */</span>
<span class="p_add">+	/* Cache QoS architectural values: */</span>
<span class="p_add">+	int			x86_cache_max_rmid;	/* max index */</span>
<span class="p_add">+	int			x86_cache_occ_scale;	/* scale to bytes */</span>
<span class="p_add">+	int			x86_power;</span>
<span class="p_add">+	unsigned long		loops_per_jiffy;</span>
<span class="p_add">+	/* cpuid returned max cores value: */</span>
<span class="p_add">+	u16			 x86_max_cores;</span>
<span class="p_add">+	u16			apicid;</span>
<span class="p_add">+	u16			initial_apicid;</span>
<span class="p_add">+	u16			x86_clflush_size;</span>
<span class="p_add">+	/* number of cores as seen by the OS: */</span>
<span class="p_add">+	u16			booted_cores;</span>
<span class="p_add">+	/* Physical processor id: */</span>
<span class="p_add">+	u16			phys_proc_id;</span>
<span class="p_add">+	/* Logical processor id: */</span>
<span class="p_add">+	u16			logical_proc_id;</span>
<span class="p_add">+	/* Core id: */</span>
<span class="p_add">+	u16			cpu_core_id;</span>
<span class="p_add">+	/* Index into per_cpu list: */</span>
<span class="p_add">+	u16			cpu_index;</span>
<span class="p_add">+	u32			microcode;</span>
<span class="p_add">+};</span>
<span class="p_add">+</span>
<span class="p_add">+extern struct cpuinfo_x86	boot_cpu_data;</span>
<span class="p_add">+extern struct cpuinfo_x86	new_cpu_data;</span>
<span class="p_add">+</span>
<span class="p_add">+#endif /* _ASM_X86_CPUINFO_H_ */</span>
<span class="p_header">diff --git a/arch/x86/include/asm/processor.h b/arch/x86/include/asm/processor.h</span>
<span class="p_header">index 62c6cc3cc5d3..6f6555b20e3d 100644</span>
<span class="p_header">--- a/arch/x86/include/asm/processor.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/processor.h</span>
<span class="p_chunk">@@ -22,6 +22,7 @@</span> <span class="p_context"> struct vm86;</span>
 #include &lt;asm/nops.h&gt;
 #include &lt;asm/special_insns.h&gt;
 #include &lt;asm/fpu/types.h&gt;
<span class="p_add">+#include &lt;asm/cpuinfo.h&gt;</span>
 
 #include &lt;linux/personality.h&gt;
 #include &lt;linux/cache.h&gt;
<span class="p_chunk">@@ -78,65 +79,6 @@</span> <span class="p_context"> extern u16 __read_mostly tlb_lld_2m[NR_INFO];</span>
 extern u16 __read_mostly tlb_lld_4m[NR_INFO];
 extern u16 __read_mostly tlb_lld_1g[NR_INFO];
 
<span class="p_del">-/*</span>
<span class="p_del">- *  CPU type and hardware bug flags. Kept separately for each CPU.</span>
<span class="p_del">- *  Members of this structure are referenced in head.S, so think twice</span>
<span class="p_del">- *  before touching them. [mj]</span>
<span class="p_del">- */</span>
<span class="p_del">-</span>
<span class="p_del">-struct cpuinfo_x86 {</span>
<span class="p_del">-	__u8			x86;		/* CPU family */</span>
<span class="p_del">-	__u8			x86_vendor;	/* CPU vendor */</span>
<span class="p_del">-	__u8			x86_model;</span>
<span class="p_del">-	__u8			x86_mask;</span>
<span class="p_del">-#ifdef CONFIG_X86_32</span>
<span class="p_del">-	char			wp_works_ok;	/* It doesn&#39;t on 386&#39;s */</span>
<span class="p_del">-</span>
<span class="p_del">-	/* Problems on some 486Dx4&#39;s and old 386&#39;s: */</span>
<span class="p_del">-	char			rfu;</span>
<span class="p_del">-	char			pad0;</span>
<span class="p_del">-	char			pad1;</span>
<span class="p_del">-#else</span>
<span class="p_del">-	/* Number of 4K pages in DTLB/ITLB combined(in pages): */</span>
<span class="p_del">-	int			x86_tlbsize;</span>
<span class="p_del">-#endif</span>
<span class="p_del">-	__u8			x86_virt_bits;</span>
<span class="p_del">-	__u8			x86_phys_bits;</span>
<span class="p_del">-	/* CPUID returned core id bits: */</span>
<span class="p_del">-	__u8			x86_coreid_bits;</span>
<span class="p_del">-	/* Max extended CPUID function supported: */</span>
<span class="p_del">-	__u32			extended_cpuid_level;</span>
<span class="p_del">-	/* Maximum supported CPUID level, -1=no CPUID: */</span>
<span class="p_del">-	int			cpuid_level;</span>
<span class="p_del">-	__u32			x86_capability[NCAPINTS + NBUGINTS];</span>
<span class="p_del">-	char			x86_vendor_id[16];</span>
<span class="p_del">-	char			x86_model_id[64];</span>
<span class="p_del">-	/* in KB - valid for CPUS which support this call: */</span>
<span class="p_del">-	int			x86_cache_size;</span>
<span class="p_del">-	int			x86_cache_alignment;	/* In bytes */</span>
<span class="p_del">-	/* Cache QoS architectural values: */</span>
<span class="p_del">-	int			x86_cache_max_rmid;	/* max index */</span>
<span class="p_del">-	int			x86_cache_occ_scale;	/* scale to bytes */</span>
<span class="p_del">-	int			x86_power;</span>
<span class="p_del">-	unsigned long		loops_per_jiffy;</span>
<span class="p_del">-	/* cpuid returned max cores value: */</span>
<span class="p_del">-	u16			 x86_max_cores;</span>
<span class="p_del">-	u16			apicid;</span>
<span class="p_del">-	u16			initial_apicid;</span>
<span class="p_del">-	u16			x86_clflush_size;</span>
<span class="p_del">-	/* number of cores as seen by the OS: */</span>
<span class="p_del">-	u16			booted_cores;</span>
<span class="p_del">-	/* Physical processor id: */</span>
<span class="p_del">-	u16			phys_proc_id;</span>
<span class="p_del">-	/* Logical processor id: */</span>
<span class="p_del">-	u16			logical_proc_id;</span>
<span class="p_del">-	/* Core id: */</span>
<span class="p_del">-	u16			cpu_core_id;</span>
<span class="p_del">-	/* Index into per_cpu list: */</span>
<span class="p_del">-	u16			cpu_index;</span>
<span class="p_del">-	u32			microcode;</span>
<span class="p_del">-};</span>
<span class="p_del">-</span>
 #define X86_VENDOR_INTEL	0
 #define X86_VENDOR_CYRIX	1
 #define X86_VENDOR_AMD		2
<span class="p_chunk">@@ -151,9 +93,6 @@</span> <span class="p_context"> struct cpuinfo_x86 {</span>
 /*
  * capabilities of CPUs
  */
<span class="p_del">-extern struct cpuinfo_x86	boot_cpu_data;</span>
<span class="p_del">-extern struct cpuinfo_x86	new_cpu_data;</span>
<span class="p_del">-</span>
 extern struct tss_struct	doublefault_tss;
 extern __u32			cpu_caps_cleared[NCAPINTS];
 extern __u32			cpu_caps_set[NCAPINTS];
<span class="p_header">diff --git a/arch/x86/include/asm/static_cpu_has.h b/arch/x86/include/asm/static_cpu_has.h</span>
new file mode 100644
<span class="p_header">index 000000000000..648ada0c7ffe</span>
<span class="p_header">--- /dev/null</span>
<span class="p_header">+++ b/arch/x86/include/asm/static_cpu_has.h</span>
<span class="p_chunk">@@ -0,0 +1,116 @@</span> <span class="p_context"></span>
<span class="p_add">+#ifndef _ASM_X86_STATIC_CPU_HAS_H</span>
<span class="p_add">+#define _ASM_X86_STATIC_CPU_HAS_H</span>
<span class="p_add">+</span>
<span class="p_add">+#include &lt;asm/cpuinfo.h&gt;</span>
<span class="p_add">+</span>
<span class="p_add">+#define test_cpu_cap(c, bit)						\</span>
<span class="p_add">+	 test_bit(bit, (unsigned long *)((c)-&gt;x86_capability))</span>
<span class="p_add">+</span>
<span class="p_add">+#define REQUIRED_MASK_BIT_SET(bit)					\</span>
<span class="p_add">+	 ( (((bit)&gt;&gt;5)==0  &amp;&amp; (1UL&lt;&lt;((bit)&amp;31) &amp; REQUIRED_MASK0 )) ||	\</span>
<span class="p_add">+	   (((bit)&gt;&gt;5)==1  &amp;&amp; (1UL&lt;&lt;((bit)&amp;31) &amp; REQUIRED_MASK1 )) ||	\</span>
<span class="p_add">+	   (((bit)&gt;&gt;5)==2  &amp;&amp; (1UL&lt;&lt;((bit)&amp;31) &amp; REQUIRED_MASK2 )) ||	\</span>
<span class="p_add">+	   (((bit)&gt;&gt;5)==3  &amp;&amp; (1UL&lt;&lt;((bit)&amp;31) &amp; REQUIRED_MASK3 )) ||	\</span>
<span class="p_add">+	   (((bit)&gt;&gt;5)==4  &amp;&amp; (1UL&lt;&lt;((bit)&amp;31) &amp; REQUIRED_MASK4 )) ||	\</span>
<span class="p_add">+	   (((bit)&gt;&gt;5)==5  &amp;&amp; (1UL&lt;&lt;((bit)&amp;31) &amp; REQUIRED_MASK5 )) ||	\</span>
<span class="p_add">+	   (((bit)&gt;&gt;5)==6  &amp;&amp; (1UL&lt;&lt;((bit)&amp;31) &amp; REQUIRED_MASK6 )) ||	\</span>
<span class="p_add">+	   (((bit)&gt;&gt;5)==7  &amp;&amp; (1UL&lt;&lt;((bit)&amp;31) &amp; REQUIRED_MASK7 )) ||	\</span>
<span class="p_add">+	   (((bit)&gt;&gt;5)==8  &amp;&amp; (1UL&lt;&lt;((bit)&amp;31) &amp; REQUIRED_MASK8 )) ||	\</span>
<span class="p_add">+	   (((bit)&gt;&gt;5)==9  &amp;&amp; (1UL&lt;&lt;((bit)&amp;31) &amp; REQUIRED_MASK9 )) ||	\</span>
<span class="p_add">+	   (((bit)&gt;&gt;5)==10 &amp;&amp; (1UL&lt;&lt;((bit)&amp;31) &amp; REQUIRED_MASK10)) ||	\</span>
<span class="p_add">+	   (((bit)&gt;&gt;5)==11 &amp;&amp; (1UL&lt;&lt;((bit)&amp;31) &amp; REQUIRED_MASK11)) ||	\</span>
<span class="p_add">+	   (((bit)&gt;&gt;5)==12 &amp;&amp; (1UL&lt;&lt;((bit)&amp;31) &amp; REQUIRED_MASK12)) ||	\</span>
<span class="p_add">+	   (((bit)&gt;&gt;5)==13 &amp;&amp; (1UL&lt;&lt;((bit)&amp;31) &amp; REQUIRED_MASK13)) ||	\</span>
<span class="p_add">+	   (((bit)&gt;&gt;5)==13 &amp;&amp; (1UL&lt;&lt;((bit)&amp;31) &amp; REQUIRED_MASK14)) ||	\</span>
<span class="p_add">+	   (((bit)&gt;&gt;5)==13 &amp;&amp; (1UL&lt;&lt;((bit)&amp;31) &amp; REQUIRED_MASK15)) ||	\</span>
<span class="p_add">+	   (((bit)&gt;&gt;5)==14 &amp;&amp; (1UL&lt;&lt;((bit)&amp;31) &amp; REQUIRED_MASK16)) )</span>
<span class="p_add">+</span>
<span class="p_add">+#define DISABLED_MASK_BIT_SET(bit)					\</span>
<span class="p_add">+	 ( (((bit)&gt;&gt;5)==0  &amp;&amp; (1UL&lt;&lt;((bit)&amp;31) &amp; DISABLED_MASK0 )) ||	\</span>
<span class="p_add">+	   (((bit)&gt;&gt;5)==1  &amp;&amp; (1UL&lt;&lt;((bit)&amp;31) &amp; DISABLED_MASK1 )) ||	\</span>
<span class="p_add">+	   (((bit)&gt;&gt;5)==2  &amp;&amp; (1UL&lt;&lt;((bit)&amp;31) &amp; DISABLED_MASK2 )) ||	\</span>
<span class="p_add">+	   (((bit)&gt;&gt;5)==3  &amp;&amp; (1UL&lt;&lt;((bit)&amp;31) &amp; DISABLED_MASK3 )) ||	\</span>
<span class="p_add">+	   (((bit)&gt;&gt;5)==4  &amp;&amp; (1UL&lt;&lt;((bit)&amp;31) &amp; DISABLED_MASK4 )) ||	\</span>
<span class="p_add">+	   (((bit)&gt;&gt;5)==5  &amp;&amp; (1UL&lt;&lt;((bit)&amp;31) &amp; DISABLED_MASK5 )) ||	\</span>
<span class="p_add">+	   (((bit)&gt;&gt;5)==6  &amp;&amp; (1UL&lt;&lt;((bit)&amp;31) &amp; DISABLED_MASK6 )) ||	\</span>
<span class="p_add">+	   (((bit)&gt;&gt;5)==7  &amp;&amp; (1UL&lt;&lt;((bit)&amp;31) &amp; DISABLED_MASK7 )) ||	\</span>
<span class="p_add">+	   (((bit)&gt;&gt;5)==8  &amp;&amp; (1UL&lt;&lt;((bit)&amp;31) &amp; DISABLED_MASK8 )) ||	\</span>
<span class="p_add">+	   (((bit)&gt;&gt;5)==9  &amp;&amp; (1UL&lt;&lt;((bit)&amp;31) &amp; DISABLED_MASK9 )) ||	\</span>
<span class="p_add">+	   (((bit)&gt;&gt;5)==10 &amp;&amp; (1UL&lt;&lt;((bit)&amp;31) &amp; DISABLED_MASK10)) ||	\</span>
<span class="p_add">+	   (((bit)&gt;&gt;5)==11 &amp;&amp; (1UL&lt;&lt;((bit)&amp;31) &amp; DISABLED_MASK11)) ||	\</span>
<span class="p_add">+	   (((bit)&gt;&gt;5)==12 &amp;&amp; (1UL&lt;&lt;((bit)&amp;31) &amp; DISABLED_MASK12)) ||	\</span>
<span class="p_add">+	   (((bit)&gt;&gt;5)==13 &amp;&amp; (1UL&lt;&lt;((bit)&amp;31) &amp; DISABLED_MASK13)) ||	\</span>
<span class="p_add">+	   (((bit)&gt;&gt;5)==13 &amp;&amp; (1UL&lt;&lt;((bit)&amp;31) &amp; DISABLED_MASK14)) ||	\</span>
<span class="p_add">+	   (((bit)&gt;&gt;5)==13 &amp;&amp; (1UL&lt;&lt;((bit)&amp;31) &amp; DISABLED_MASK15)) ||	\</span>
<span class="p_add">+	   (((bit)&gt;&gt;5)==14 &amp;&amp; (1UL&lt;&lt;((bit)&amp;31) &amp; DISABLED_MASK16)) )</span>
<span class="p_add">+</span>
<span class="p_add">+#define cpu_has(c, bit)							\</span>
<span class="p_add">+	(__builtin_constant_p(bit) &amp;&amp; REQUIRED_MASK_BIT_SET(bit) ? 1 :	\</span>
<span class="p_add">+	 test_cpu_cap(c, bit))</span>
<span class="p_add">+</span>
<span class="p_add">+#define boot_cpu_has(bit)	cpu_has(&amp;boot_cpu_data, bit)</span>
<span class="p_add">+</span>
<span class="p_add">+#if defined(CC_HAVE_ASM_GOTO) &amp;&amp; defined(CONFIG_X86_FAST_FEATURE_TESTS)</span>
<span class="p_add">+/*</span>
<span class="p_add">+ * Static testing of CPU features.  Used the same as boot_cpu_has().</span>
<span class="p_add">+ * These will statically patch the target code for additional</span>
<span class="p_add">+ * performance.</span>
<span class="p_add">+ */</span>
<span class="p_add">+static __always_inline __pure bool _static_cpu_has(u16 bit)</span>
<span class="p_add">+{</span>
<span class="p_add">+		asm_volatile_goto(&quot;1: jmp 6f\n&quot;</span>
<span class="p_add">+			 &quot;2:\n&quot;</span>
<span class="p_add">+			 &quot;.skip -(((5f-4f) - (2b-1b)) &gt; 0) * &quot;</span>
<span class="p_add">+			         &quot;((5f-4f) - (2b-1b)),0x90\n&quot;</span>
<span class="p_add">+			 &quot;3:\n&quot;</span>
<span class="p_add">+			 &quot;.section .altinstructions,\&quot;a\&quot;\n&quot;</span>
<span class="p_add">+			 &quot; .long 1b - .\n&quot;		/* src offset */</span>
<span class="p_add">+			 &quot; .long 4f - .\n&quot;		/* repl offset */</span>
<span class="p_add">+			 &quot; .word %P1\n&quot;			/* always replace */</span>
<span class="p_add">+			 &quot; .byte 3b - 1b\n&quot;		/* src len */</span>
<span class="p_add">+			 &quot; .byte 5f - 4f\n&quot;		/* repl len */</span>
<span class="p_add">+			 &quot; .byte 3b - 2b\n&quot;		/* pad len */</span>
<span class="p_add">+			 &quot;.previous\n&quot;</span>
<span class="p_add">+			 &quot;.section .altinstr_replacement,\&quot;ax\&quot;\n&quot;</span>
<span class="p_add">+			 &quot;4: jmp %l[t_no]\n&quot;</span>
<span class="p_add">+			 &quot;5:\n&quot;</span>
<span class="p_add">+			 &quot;.previous\n&quot;</span>
<span class="p_add">+			 &quot;.section .altinstructions,\&quot;a\&quot;\n&quot;</span>
<span class="p_add">+			 &quot; .long 1b - .\n&quot;		/* src offset */</span>
<span class="p_add">+			 &quot; .long 0\n&quot;			/* no replacement */</span>
<span class="p_add">+			 &quot; .word %P0\n&quot;			/* feature bit */</span>
<span class="p_add">+			 &quot; .byte 3b - 1b\n&quot;		/* src len */</span>
<span class="p_add">+			 &quot; .byte 0\n&quot;			/* repl len */</span>
<span class="p_add">+			 &quot; .byte 0\n&quot;			/* pad len */</span>
<span class="p_add">+			 &quot;.previous\n&quot;</span>
<span class="p_add">+			 &quot;.section .altinstr_aux,\&quot;ax\&quot;\n&quot;</span>
<span class="p_add">+			 &quot;6:\n&quot;</span>
<span class="p_add">+			 &quot; testb %[bitnum],%[cap_byte]\n&quot;</span>
<span class="p_add">+			 &quot; jnz %l[t_yes]\n&quot;</span>
<span class="p_add">+			 &quot; jmp %l[t_no]\n&quot;</span>
<span class="p_add">+			 &quot;.previous\n&quot;</span>
<span class="p_add">+			 : : &quot;i&quot; (bit), &quot;i&quot; (X86_FEATURE_ALWAYS),</span>
<span class="p_add">+			     [bitnum] &quot;i&quot; (1 &lt;&lt; (bit &amp; 7)),</span>
<span class="p_add">+			     [cap_byte] &quot;m&quot; (((const char *)boot_cpu_data.x86_capability)[bit &gt;&gt; 3])</span>
<span class="p_add">+			 : : t_yes, t_no);</span>
<span class="p_add">+	t_yes:</span>
<span class="p_add">+		return true;</span>
<span class="p_add">+	t_no:</span>
<span class="p_add">+		return false;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+#define static_cpu_has(bit)					\</span>
<span class="p_add">+(								\</span>
<span class="p_add">+	__builtin_constant_p(boot_cpu_has(bit)) ?		\</span>
<span class="p_add">+		boot_cpu_has(bit) :				\</span>
<span class="p_add">+		_static_cpu_has(bit)				\</span>
<span class="p_add">+)</span>
<span class="p_add">+#else</span>
<span class="p_add">+/*</span>
<span class="p_add">+ * Fall back to dynamic for gcc versions which don&#39;t support asm goto. Should be</span>
<span class="p_add">+ * a minority now anyway.</span>
<span class="p_add">+ */</span>
<span class="p_add">+#define static_cpu_has(bit)		boot_cpu_has(bit)</span>
<span class="p_add">+#endif</span>
<span class="p_add">+</span>
<span class="p_add">+#endif /* _ASM_X86_STATIC_CPU_HAS_H */</span>
<span class="p_header">diff --git a/lib/Makefile b/lib/Makefile</span>
<span class="p_header">index a65e9a861535..55ad20701dc0 100644</span>
<span class="p_header">--- a/lib/Makefile</span>
<span class="p_header">+++ b/lib/Makefile</span>
<span class="p_chunk">@@ -15,9 +15,6 @@</span> <span class="p_context"> KCOV_INSTRUMENT_rbtree.o := n</span>
 KCOV_INSTRUMENT_list_debug.o := n
 KCOV_INSTRUMENT_debugobjects.o := n
 KCOV_INSTRUMENT_dynamic_debug.o := n
<span class="p_del">-# Kernel does not boot if we instrument this file as it uses custom calling</span>
<span class="p_del">-# convention (see CONFIG_ARCH_HWEIGHT_CFLAGS).</span>
<span class="p_del">-KCOV_INSTRUMENT_hweight.o := n</span>
 
 lib-y := ctype.o string.o vsprintf.o cmdline.o \
 	 rbtree.o radix-tree.o dump_stack.o timerqueue.o\
<span class="p_chunk">@@ -72,8 +69,6 @@</span> <span class="p_context"> obj-$(CONFIG_HAS_IOMEM) += iomap_copy.o devres.o</span>
 obj-$(CONFIG_CHECK_SIGNATURE) += check_signature.o
 obj-$(CONFIG_DEBUG_LOCKING_API_SELFTESTS) += locking-selftest.o
 
<span class="p_del">-GCOV_PROFILE_hweight.o := n</span>
<span class="p_del">-CFLAGS_hweight.o = $(subst $(quote),,$(CONFIG_ARCH_HWEIGHT_CFLAGS))</span>
 obj-$(CONFIG_GENERIC_HWEIGHT) += hweight.o
 
 obj-$(CONFIG_BTREE) += btree.o

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



