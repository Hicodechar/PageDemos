
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>KVM: Remove redundant smp_mb() in the kvm_mmu_commit_zap_page() - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    KVM: Remove redundant smp_mb() in the kvm_mmu_commit_zap_page()</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=119561">Xiao Guangrong</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>March 10, 2016, 2:40 p.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;56E1875E.8060007@linux.intel.com&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/8557581/mbox/"
   >mbox</a>
|
   <a href="/patch/8557581/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/8557581/">/patch/8557581/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
X-Original-To: patchwork-LKML@patchwork.kernel.org
Delivered-To: patchwork-parsemail@patchwork2.web.kernel.org
Received: from mail.kernel.org (mail.kernel.org [198.145.29.136])
	by patchwork2.web.kernel.org (Postfix) with ESMTP id 8146EC0553
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Thu, 10 Mar 2016 14:41:15 +0000 (UTC)
Received: from mail.kernel.org (localhost [127.0.0.1])
	by mail.kernel.org (Postfix) with ESMTP id 899872037C
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Thu, 10 Mar 2016 14:41:14 +0000 (UTC)
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.kernel.org (Postfix) with ESMTP id B4BF720380
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Thu, 10 Mar 2016 14:41:13 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1752542AbcCJOlK (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Thu, 10 Mar 2016 09:41:10 -0500
Received: from mga02.intel.com ([134.134.136.20]:28474 &quot;EHLO mga02.intel.com&quot;
	rhost-flags-OK-OK-OK-OK) by vger.kernel.org with ESMTP
	id S1751939AbcCJOk7 (ORCPT &lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Thu, 10 Mar 2016 09:40:59 -0500
Received: from fmsmga004.fm.intel.com ([10.253.24.48])
	by orsmga101.jf.intel.com with ESMTP; 10 Mar 2016 06:40:57 -0800
X-ExtLoop1: 1
X-IronPort-AV: E=Sophos;i=&quot;5.24,316,1455004800&quot;; d=&quot;scan&#39;208&quot;;a=&quot;63571406&quot;
Received: from xiao.sh.intel.com ([10.239.159.134])
	by fmsmga004.fm.intel.com with ESMTP; 10 Mar 2016 06:40:55 -0800
Subject: Re: [PATCH] KVM: Remove redundant smp_mb() in the
	kvm_mmu_commit_zap_page()
To: Paolo Bonzini &lt;pbonzini@redhat.com&gt;, Lan Tianyu &lt;tianyu.lan@intel.com&gt;,
	Thomas Gleixner &lt;tglx@linutronix.de&gt;
References: &lt;1457055312-27067-1-git-send-email-tianyu.lan@intel.com&gt;
	&lt;alpine.DEB.2.11.1603040820100.3597@nanos&gt;
	&lt;56D9354E.9040908@intel.com&gt;
	&lt;56D94BFE.1080406@redhat.com&gt; &lt;56DE8F1A.9000401@intel.com&gt;
	&lt;56DEEF69.20208@redhat.com&gt;
Cc: gleb@kernel.org, mingo@redhat.com, hpa@zytor.com, x86@kernel.org,
	kvm@vger.kernel.org, linux-kernel@vger.kernel.org
From: Xiao Guangrong &lt;guangrong.xiao@linux.intel.com&gt;
Message-ID: &lt;56E1875E.8060007@linux.intel.com&gt;
Date: Thu, 10 Mar 2016 22:40:30 +0800
User-Agent: Mozilla/5.0 (X11; Linux x86_64; rv:38.0) Gecko/20100101
	Thunderbird/38.5.1
MIME-Version: 1.0
In-Reply-To: &lt;56DEEF69.20208@redhat.com&gt;
Content-Type: text/plain; charset=utf-8; format=flowed
Content-Transfer-Encoding: 7bit
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Spam-Status: No, score=-6.9 required=5.0 tests=BAYES_00, RCVD_IN_DNSWL_HI, 
	RP_MATCHES_RCVD,
	UNPARSEABLE_RELAY autolearn=unavailable version=3.3.1
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on mail.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=119561">Xiao Guangrong</a> - March 10, 2016, 2:40 p.m.</div>
<pre class="content">
On 03/08/2016 11:27 PM, Paolo Bonzini wrote:
<span class="quote">&gt;</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; On 08/03/2016 09:36, Lan Tianyu wrote:</span>
<span class="quote">&gt;&gt; Summary about smp_mb()s we met in this thread. If misunderstood, please</span>
<span class="quote">&gt;&gt; correct me. Thanks.</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; The smp_mb() in the kvm_flush_remote_tlbs() was introduced by the commit</span>
<span class="quote">&gt;&gt; a4ee1ca4 and it seems to keep the order of reading and cmpxchg</span>
<span class="quote">&gt;&gt; kvm-&gt;tlbs_dirty.</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt;      Quote from Avi:</span>
<span class="quote">&gt;&gt;      | I don&#39;t think we need to flush immediately; set a &quot;tlb dirty&quot; bit</span>
<span class="quote">&gt;&gt; somewhere</span>
<span class="quote">&gt;&gt;      | that is cleareded when we flush the tlb.</span>
<span class="quote">&gt;&gt; kvm_mmu_notifier_invalidate_page()</span>
<span class="quote">&gt;&gt;      | can consult the bit and force a flush if set.</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt;      Signed-off-by: Xiao Guangrong &lt;xiaoguangrong@cn.fujitsu.com&gt;</span>
<span class="quote">&gt;&gt;      Signed-off-by: Marcelo Tosatti &lt;mtosatti@redhat.com&gt;</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; Unfortunately that patch added a bad memory barrier: 1) it lacks a</span>
<span class="quote">&gt; comment; 2) it lacks obvious pairing; 3) it is an smp_mb() after a read,</span>
<span class="quote">&gt; so it&#39;s not even obvious that this memory barrier has to do with the</span>
<span class="quote">&gt; immediately preceding read of kvm-&gt;tlbs_dirty.  It also is not</span>
<span class="quote">&gt; documented in Documentation/virtual/kvm/mmu.txt (Guangrong documented</span>
<span class="quote">&gt; there most of his other work, back in 2013, but not this one :)).</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; The cmpxchg is ordered anyway against the read, because 1) x86 has</span>
<span class="quote">&gt; implicit ordering between earlier loads and later stores; 2) even</span>
<span class="quote">&gt; store-load barriers are unnecessary for accesses to the same variable</span>
<span class="quote">&gt; (in this case kvm-&gt;tlbs_dirty).</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; So offhand, I cannot say what it orders.  There are two possibilities:</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; 1) it orders the read of tlbs_dirty with the read of mode.  In this</span>
<span class="quote">&gt; case, a smp_rmb() would have been enough, and it&#39;s not clear where is</span>
<span class="quote">&gt; the matching smp_wmb().</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; 2) it orders the read of tlbs_dirty with the KVM_REQ_TLB_FLUSH request.</span>
<span class="quote">&gt;   In this case a smp_load_acquire would be better.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; 3) it does the same as kvm_mmu_commit_zap_page&#39;s smp_mb() but for other</span>
<span class="quote">&gt; callers of kvm_flush_remote_tlbs().  In this case, we know what&#39;s the</span>
<span class="quote">&gt; matching memory barrier (walk_shadow_page_lockless_*).</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; 4) it is completely unnecessary.</span>

Sorry, memory barriers were missed in sync_page(), this diff should fix it:



Any comment?
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=2536">Paolo Bonzini</a> - March 10, 2016, 3:26 p.m.</div>
<pre class="content">
On 10/03/2016 15:40, Xiao Guangrong wrote:
<span class="quote">&gt;      long dirty_count = kvm-&gt;tlbs_dirty;</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; +        /*</span>
<span class="quote">&gt; +         * read tlbs_dirty before doing tlb flush to make sure not tlb</span>
<span class="quote">&gt; request is</span>
<span class="quote">&gt; +         * lost.</span>
<span class="quote">&gt; +         */</span>
<span class="quote">&gt;      smp_mb();</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt;      if (kvm_make_all_cpus_request(kvm, KVM_REQ_TLB_FLUSH))</span>
<span class="quote">&gt;          ++kvm-&gt;stat.remote_tlb_flush;</span>
<span class="quote">&gt;      cmpxchg(&amp;kvm-&gt;tlbs_dirty, dirty_count, 0);</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Any comment?</span>

Compared to smp_load_acquire(), smp_mb() adds an ordering between stores
and loads.  Is the

The load of kvm-&gt;tlbs_dirty should then be

	/*
	 * Read tlbs_dirty before setting KVM_REQ_TLB_FLUSH in
	 * kvm_make_all_cpus_request.  This
	 */
	long dirty_count = smp_load_acquire(kvm-&gt;tlbs_dirty);

Tianyu, I think Xiao provided the information that I was missing.  Would
you like to prepare the patch?

Thanks,

Paolo
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=2536">Paolo Bonzini</a> - March 10, 2016, 3:31 p.m.</div>
<pre class="content">
On 10/03/2016 16:26, Paolo Bonzini wrote:
<span class="quote">&gt; Compared to smp_load_acquire(), smp_mb() adds an ordering between stores</span>
<span class="quote">&gt; and loads.</span>

Here, the ordering is load-store, hence...
<span class="quote">
&gt; The load of kvm-&gt;tlbs_dirty should then be</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; 	/*</span>
<span class="quote">&gt; 	 * Read tlbs_dirty before setting KVM_REQ_TLB_FLUSH in</span>
<span class="quote">&gt; 	 * kvm_make_all_cpus_request.  This</span>
<span class="quote">&gt; 	 */</span>
<span class="quote">&gt; 	long dirty_count = smp_load_acquire(kvm-&gt;tlbs_dirty);</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Tianyu, I think Xiao provided the information that I was missing.  Would</span>
<span class="quote">&gt; you like to prepare the patch?</span>

Thanks,

Paolo
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=119561">Xiao Guangrong</a> - March 10, 2016, 3:45 p.m.</div>
<pre class="content">
On 03/10/2016 11:31 PM, Paolo Bonzini wrote:
<span class="quote">&gt;</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; On 10/03/2016 16:26, Paolo Bonzini wrote:</span>
<span class="quote">&gt;&gt; Compared to smp_load_acquire(), smp_mb() adds an ordering between stores</span>
<span class="quote">&gt;&gt; and loads.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; Here, the ordering is load-store, hence...</span>

Yes, this is why i put smp_mb() in the code. :)
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=2536">Paolo Bonzini</a> - March 10, 2016, 4:04 p.m.</div>
<pre class="content">
On 10/03/2016 16:45, Xiao Guangrong wrote:
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt; Compared to smp_load_acquire(), smp_mb() adds an ordering between stores</span>
<span class="quote">&gt;&gt;&gt; and loads.</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; Here, the ordering is load-store, hence...</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Yes, this is why i put smp_mb() in the code. :)</span>

Here is a table of barriers:


    &#39;. after|                   |
before &#39;.   |    load           |    store
__________&#39;.|___________________|________________________
            |                   |
            |  smp_rmb          | smp_load_acquire
load        |  smp_load_acquire | smp_store_release    XX
            |  smp_mb           | smp_mb
____________|___________________|________________________
            |                   |
            |                   | smp_wmb
store       |  smp_mb           | smp_store_release
            |                   | smp_mb
            |                   |

Your case is the one marked with XX, so a smp_load_acquire() is
enough---and it&#39;s preferrable, because it&#39;s cheaper than smp_mb() and
more self-documenting.

Paolo
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=119561">Xiao Guangrong</a> - March 10, 2016, 5:57 p.m.</div>
<pre class="content">
On 03/11/2016 12:04 AM, Paolo Bonzini wrote:
<span class="quote">&gt;</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; On 10/03/2016 16:45, Xiao Guangrong wrote:</span>
<span class="quote">&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt;&gt; Compared to smp_load_acquire(), smp_mb() adds an ordering between stores</span>
<span class="quote">&gt;&gt;&gt;&gt; and loads.</span>
<span class="quote">&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt; Here, the ordering is load-store, hence...</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; Yes, this is why i put smp_mb() in the code. :)</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; Here is a table of barriers:</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;      &#39;. after|                   |</span>
<span class="quote">&gt; before &#39;.   |    load           |    store</span>
<span class="quote">&gt; __________&#39;.|___________________|________________________</span>
<span class="quote">&gt;              |                   |</span>
<span class="quote">&gt;              |  smp_rmb          | smp_load_acquire</span>
<span class="quote">&gt; load        |  smp_load_acquire | smp_store_release    XX</span>
<span class="quote">&gt;              |  smp_mb           | smp_mb</span>
<span class="quote">&gt; ____________|___________________|________________________</span>
<span class="quote">&gt;              |                   |</span>
<span class="quote">&gt;              |                   | smp_wmb</span>
<span class="quote">&gt; store       |  smp_mb           | smp_store_release</span>
<span class="quote">&gt;              |                   | smp_mb</span>
<span class="quote">&gt;              |                   |</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; Your case is the one marked with XX, so a smp_load_acquire() is</span>
<span class="quote">&gt; enough---and it&#39;s preferrable, because it&#39;s cheaper than smp_mb() and</span>
<span class="quote">&gt; more self-documenting.</span>

Yes, you are right and thank you for pointing it out.
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=27472">lan,Tianyu</a> - March 11, 2016, 1:13 a.m.</div>
<pre class="content">
On 2016?03?10? 23:26, Paolo Bonzini wrote:
<span class="quote">&gt; </span>
<span class="quote">&gt; </span>
<span class="quote">&gt; On 10/03/2016 15:40, Xiao Guangrong wrote:</span>
<span class="quote">&gt;&gt;      long dirty_count = kvm-&gt;tlbs_dirty;</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; +        /*</span>
<span class="quote">&gt;&gt; +         * read tlbs_dirty before doing tlb flush to make sure not tlb</span>
<span class="quote">&gt;&gt; request is</span>
<span class="quote">&gt;&gt; +         * lost.</span>
<span class="quote">&gt;&gt; +         */</span>
<span class="quote">&gt;&gt;      smp_mb();</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt;      if (kvm_make_all_cpus_request(kvm, KVM_REQ_TLB_FLUSH))</span>
<span class="quote">&gt;&gt;          ++kvm-&gt;stat.remote_tlb_flush;</span>
<span class="quote">&gt;&gt;      cmpxchg(&amp;kvm-&gt;tlbs_dirty, dirty_count, 0);</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; Any comment?</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Compared to smp_load_acquire(), smp_mb() adds an ordering between stores</span>
<span class="quote">&gt; and loads.  Is the</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; The load of kvm-&gt;tlbs_dirty should then be</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; 	/*</span>
<span class="quote">&gt; 	 * Read tlbs_dirty before setting KVM_REQ_TLB_FLUSH in</span>
<span class="quote">&gt; 	 * kvm_make_all_cpus_request.  This</span>
<span class="quote">&gt; 	 */</span>
<span class="quote">&gt; 	long dirty_count = smp_load_acquire(kvm-&gt;tlbs_dirty);</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Tianyu, I think Xiao provided the information that I was missing.  Would</span>
<span class="quote">&gt; you like to prepare the patch?</span>

Paolo:
	Sure. I will do that.

Guangrong:
	Thanks a lot for your input.
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/arch/x86/kvm/paging_tmpl.h b/arch/x86/kvm/paging_tmpl.h</span>
<span class="p_header">index 91e939b..4cad57f 100644</span>
<span class="p_header">--- a/arch/x86/kvm/paging_tmpl.h</span>
<span class="p_header">+++ b/arch/x86/kvm/paging_tmpl.h</span>
<span class="p_chunk">@@ -948,6 +948,12 @@</span> <span class="p_context"> static int FNAME(sync_page)(struct kvm_vcpu *vcpu, struct kvm_mmu_page *sp)</span>
  			return -EINVAL;

  		if (FNAME(prefetch_invalid_gpte)(vcpu, sp, &amp;sp-&gt;spt[i], gpte)) {
<span class="p_add">+			/*</span>
<span class="p_add">+			 * update spte before increasing tlbs_dirty to make sure no tlb</span>
<span class="p_add">+			 * flush in lost after spte is zapped, see the comments in</span>
<span class="p_add">+			 * kvm_flush_remote_tlbs().</span>
<span class="p_add">+			 */</span>
<span class="p_add">+			smp_wmb();</span>
  			vcpu-&gt;kvm-&gt;tlbs_dirty++;
  			continue;
  		}
<span class="p_chunk">@@ -963,6 +969,8 @@</span> <span class="p_context"> static int FNAME(sync_page)(struct kvm_vcpu *vcpu, struct kvm_mmu_page *sp)</span>

  		if (gfn != sp-&gt;gfns[i]) {
  			drop_spte(vcpu-&gt;kvm, &amp;sp-&gt;spt[i]);
<span class="p_add">+			/* the same as above where we are doing prefetch_invalid_gpte(). */</span>
<span class="p_add">+			smp_wmb();</span>
  			vcpu-&gt;kvm-&gt;tlbs_dirty++;
  			continue;
  		}
<span class="p_header">diff --git a/virt/kvm/kvm_main.c b/virt/kvm/kvm_main.c</span>
<span class="p_header">index 314c777..82c86ea 100644</span>
<span class="p_header">--- a/virt/kvm/kvm_main.c</span>
<span class="p_header">+++ b/virt/kvm/kvm_main.c</span>
<span class="p_chunk">@@ -193,7 +193,12 @@</span> <span class="p_context"> void kvm_flush_remote_tlbs(struct kvm *kvm)</span>
  {
  	long dirty_count = kvm-&gt;tlbs_dirty;

<span class="p_add">+        /*</span>
<span class="p_add">+         * read tlbs_dirty before doing tlb flush to make sure not tlb request is</span>
<span class="p_add">+         * lost.</span>
<span class="p_add">+         */</span>
  	smp_mb();
<span class="p_add">+</span>
  	if (kvm_make_all_cpus_request(kvm, KVM_REQ_TLB_FLUSH))
  		++kvm-&gt;stat.remote_tlb_flush;
  	cmpxchg(&amp;kvm-&gt;tlbs_dirty, dirty_count, 0);

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



