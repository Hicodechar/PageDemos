
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>arm64: Add support for PTE contiguous bit. - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    arm64: Add support for PTE contiguous bit.</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=142331">David Woods</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>Sept. 15, 2015, 6:01 p.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;1442340117-3964-1-git-send-email-dwoods@ezchip.com&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/7189101/mbox/"
   >mbox</a>
|
   <a href="/patch/7189101/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/7189101/">/patch/7189101/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
X-Original-To: patchwork-LKML@patchwork.kernel.org
Delivered-To: patchwork-parsemail@patchwork2.web.kernel.org
Received: from mail.kernel.org (mail.kernel.org [198.145.29.136])
	by patchwork2.web.kernel.org (Postfix) with ESMTP id 82D40BEEC1
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Tue, 15 Sep 2015 18:17:48 +0000 (UTC)
Received: from mail.kernel.org (localhost [127.0.0.1])
	by mail.kernel.org (Postfix) with ESMTP id 449D32083B
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Tue, 15 Sep 2015 18:17:47 +0000 (UTC)
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.kernel.org (Postfix) with ESMTP id BC6962083A
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Tue, 15 Sep 2015 18:17:45 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1752183AbbIOSRm (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Tue, 15 Sep 2015 14:17:42 -0400
Received: from mail-db3on0089.outbound.protection.outlook.com
	([157.55.234.89]:49264
	&quot;EHLO emea01-db3-obe.outbound.protection.outlook.com&quot;
	rhost-flags-OK-OK-OK-FAIL) by vger.kernel.org with ESMTP
	id S1751074AbbIOSRk (ORCPT &lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Tue, 15 Sep 2015 14:17:40 -0400
X-Greylist: delayed 893 seconds by postgrey-1.27 at vger.kernel.org;
	Tue, 15 Sep 2015 14:17:39 EDT
Received: from HE1PR02CA0032.eurprd02.prod.outlook.com (10.162.33.42) by
	AM2PR02MB0772.eurprd02.prod.outlook.com (10.163.146.16) with
	Microsoft SMTP
	Server (TLS) id 15.1.268.17; Tue, 15 Sep 2015 18:02:43 +0000
Received: from DB3FFO11FD050.protection.gbl (2a01:111:f400:7e04::148) by
	HE1PR02CA0032.outlook.office365.com (2a01:111:e400:5149::42) with
	Microsoft SMTP Server (TLS) id 15.1.268.17 via Frontend Transport;
	Tue, 15 Sep 2015 18:02:43 +0000
Authentication-Results: spf=fail (sender IP is 12.216.194.146)
	smtp.mailfrom=ezchip.com; kvack.org; dkim=none (message not signed)
	header.d=none; kvack.org;
	dmarc=none action=none header.from=ezchip.com; 
Received-SPF: Fail (protection.outlook.com: domain of ezchip.com does not
	designate 12.216.194.146 as permitted sender)
	receiver=protection.outlook.com; client-ip=12.216.194.146;
	helo=ld-2.internal.tilera.com;
Received: from ld-2.internal.tilera.com (12.216.194.146) by
	DB3FFO11FD050.mail.protection.outlook.com (10.47.217.81) with
	Microsoft SMTP Server (TLS) id 15.1.262.18 via Frontend Transport;
	Tue, 15 Sep 2015 18:02:41 +0000
Received: (from dwoods@localhost)
	by ld-2.internal.tilera.com (8.14.4/8.14.4/Submit) id t8FI2cxe004019; 
	Tue, 15 Sep 2015 14:02:38 -0400
From: David Woods &lt;dwoods@ezchip.com&gt;
To: Chris Metcalf &lt;cmetcalf@ezchip.com&gt;
CC: David Woods &lt;dwoods@ezchip.com&gt;,
	Catalin Marinas &lt;catalin.marinas@arm.com&gt;,
	Will Deacon &lt;will.deacon@arm.com&gt;,
	Steve Capper &lt;steve.capper@linaro.org&gt;,
	Marc Zyngier &lt;marc.zyngier@arm.com&gt;, Hugh Dickins &lt;hughd@google.com&gt;,
	Mike Kravetz &lt;mike.kravetz@oracle.com&gt;,
	Naoya Horiguchi &lt;n-horiguchi@ah.jp.nec.com&gt;,
	Andrew Morton &lt;akpm@linux-foundation.org&gt;,
	&lt;linux-arm-kernel@lists.infradead.org&gt;,
	&lt;linux-kernel@vger.kernel.org&gt;, &lt;linux-mm@kvack.org&gt;
Subject: [PATCH] arm64: Add support for PTE contiguous bit.
Date: Tue, 15 Sep 2015 14:01:57 -0400
Message-ID: &lt;1442340117-3964-1-git-send-email-dwoods@ezchip.com&gt;
X-Mailer: git-send-email 2.1.2
X-EOPAttributedMessage: 0
X-Microsoft-Exchange-Diagnostics: 1; DB3FFO11FD050;
	1:9HrloFEGBNoFlPnTX9gg0KgDOsTNmhcvM7JHjVdgLHBzY1gN/SIlQsPUzvBuQSC2oqs2dzCoM2KU+nVEiao6HxYJUlGJVqEMZ9hty6mauhK7nXQk3NTHEcl884PKF3wJ/ytvMawg8yshXBwp1AJIsTGkcwjI2/h1qPTuYqWyZ/xuehYyrMph5YrqRt0nvNJUjsObCWRDxb1FL+mmCOUHfZ6FRGchG+oj1+z4tH2GKzvY0b1YflKa4IP7GBljN4PTUtn7Y2MrlylFbihzkc7hvr0ag0HYQaLsr50IVWb3C/QzrUqY7ls7Gkg8zJzvgJqPvldVE9efnfUSxt/9jz+lKNfAMTZQG0h0jDdnVN4wjzXyhUCO8EWv8JecFS4z1BrGQPwSYBk5SzJ+EDaYv2B0hQ==
X-Forefront-Antispam-Report: CIP:12.216.194.146; CTRY:US; IPV:NLI; EFV:NLI;
	SFV:NSPM;
	SFS:(10009020)(6009001)(2980300002)(1110001)(1109001)(339900001)(189002)(199003)(77156002)(6806004)(42186005)(19580395003)(47776003)(92566002)(68736005)(5007970100001)(64706001)(11100500001)(110136002)(33646002)(19580405001)(5001960100002)(50986999)(4001450100002)(50226001)(189998001)(46102003)(106476002)(86362001)(106356001)(48376002)(97736004)(85426001)(104016003)(62966003)(50466002)(229853001)(105606002)(81156007)(106466001)(5003940100001)(4001540100001)(87936001)(36756003)(5001860100001)(5001830100001)(9376005);
	DIR:OUT; SFP:1101; SCL:1; SRVR:AM2PR02MB0772;
	H:ld-2.internal.tilera.com; FPR:; SPF:Fail; PTR:InfoNoRecords;
	MX:1; A:1; LANG:en; 
MIME-Version: 1.0
Content-Type: text/plain
X-Microsoft-Exchange-Diagnostics: 1; AM2PR02MB0772;
	2:QDP6w52cqgbZ4Q1vXYq2llBIzWCCV96f8mtbJQgB9td4rQc3X7PEAoIXQhreGDSPkhcEHYWz4PuiH6TNysy1bcXaP0cjCxC9tRgfBlUD0Rt4pJMzpx10/UNaaClPe8+KgCIf3bNCTfnu+p67lsqBQX+qhmoPAOqvri4a4J3Dkk8=;
	3:H5tG8guKO1TE4bJRNnIauY5OQDISuxLNXlvd/1Gthh2rIxCri5+f4X9UtyhxUQQGqlo6mAi9qxRqCiZusvlmjtZmG+egqFEawWGhwxyxRZq2PyCRy6/Yo5Z6W2rcuPvdwG5p4dRbiotiZwBPlA3/vgTowvvA44ZFWAKIvxOkX8+kDTW7RkF7sonlGhCZwOrmiYzVpAQPT4m2z09MhhckxVkaydkkwvXCCTwgKmjuHNTuEQC4rUPI1OG3xoCLkLlT;
	25:Ag7iwLTLlbSbmnq5FgfVD3QAloOVH1rsX3VjXnFfsT7A1SX/yj/XHNea5oQ8lCJb4JQHeHikXxiv0gq9NGzRhk0J+UKjTkTBZCgusax4HN9qJKGtXyqTOwWq9xykrA9zSSEtv6L8soZYCRvEo6W/O0b6bwkAV8LOdyBmmM/nwSW40xr1C6kG50RDj1HJh6E+XteBejPviubF5ktvAYwodgJ28nffsxqD+IR89irryVp8EbkT1yVVDoc65qlMY0kRxPG6FXREzaj9rFmALZR53w==;
	20:9pG0oTjLAKmi+9Qm3YJdL6usF1i5I+7RQc0/siGGUcJYC/P+LxT37xHgWygraeqRQQQDtf/UVsSwVHVSthYtlUukMySPrPjkSBJdrSgXB6GUn4jFKzfWYYTaSimNstYOHRlkE+W9IVEG8ecQDj6V0i2/EMc7AxvlWvkV19vWQIQ=
X-Microsoft-Antispam: UriScan:;BCL:0;PCL:0;RULEID:;SRVR:AM2PR02MB0772;
X-Microsoft-Antispam-PRVS: &lt;AM2PR02MB077240B96299A77251FE27F2BC5C0@AM2PR02MB0772.eurprd02.prod.outlook.com&gt;
X-Exchange-Antispam-Report-Test: UriScan:;
X-Exchange-Antispam-Report-CFA-Test: BCL:0; PCL:0;
	RULEID:(601004)(8121501046)(520075)(5005006)(520078)(3002001);
	SRVR:AM2PR02MB0772; BCL:0; PCL:0; RULEID:; SRVR:AM2PR02MB0772;
X-Microsoft-Exchange-Diagnostics: 1; AM2PR02MB0772;
	4:rM/IBuynJjY3PrLw71gZcCe5gutel22fFe79WpxBWfz5W3VmRo1n9zy+o/fylt7rww9cS8Ot2vq7KXtewFx5YRV6Tl70arpm4HuszV78KK0+gE3biZlybE2wVM8dxDs0G7nuBb9omqACMH8qW3+rExYQKX54YkP6D2CpYKyDXeABw5e3ni+VXlCZhwAbjp6OkAfxyXX6rF2eW5DjLGjgOatu4O3cs+q++iVZx2vzjm3ARJDaXrT5KGaUyrpUIBdHkjpSY9DI2x+xYDHQROXYXgHOG9WTZ/4249ie/h/YpYDd+jdgT3HOkH1hQHXGzHj7qu+V9l6U+kFWxOawtOWVlhh2HaLzzry5BmhMwAQgH1s=
X-Forefront-PRVS: 070092A9D3
X-Microsoft-Exchange-Diagnostics: =?us-ascii?Q?1; AM2PR02MB0772;
	23:1KWYwLDT1/DBo1taakYGAn4XNxV/nbNhJ68EZsm/k?=
	=?us-ascii?Q?6sh+y1RH9by4mDIJ3bWVo3NpV3bveqzgvFVRORUNOAtx83BxCPmxQLJcqo/y?=
	=?us-ascii?Q?zuvgTkpqo1cqcMFuO6I/JZ6PfP3l+Id5Cw9/DF6n2N5ZH7ZQwpDNgIINKsqQ?=
	=?us-ascii?Q?uPh/1elk/TMle65dwMPzV70zkIO4DpvJYAlni8xkDU0c+AUlTY58qcyJSX8z?=
	=?us-ascii?Q?WrmhaLkj4Msu9ur+emXtmY7aNsnwNl0rjKfUShSlH5Z9EkVDJl6fwebr1ttD?=
	=?us-ascii?Q?0Y0g6lZqIGeePaTpSaaohgOX/YdOnXylcRtVY3QdJa3I2dzXV9h0s8PSUl9R?=
	=?us-ascii?Q?e2qv8+h5mlMrXj7taXxEzpABBDauM7kskoS2YHs2G+GmWu9vc10XKq/cq3zB?=
	=?us-ascii?Q?IgQRhiNf+kt+z6O8N5G9eF7FWAgyj6R0tDz4wGDM9LhBhxbiR4oT669nznDI?=
	=?us-ascii?Q?B8uEN2V3yKmVe8UV87+npFVfRejpB1weXOdoeTP/bqQk8R4S8IQ6MmGvzMhC?=
	=?us-ascii?Q?Hrb0AgTXN6GzU2mL2TTR8N4bxd0WZI1oyX6OuNtpQJSXs+sIFxYemzmHEY8e?=
	=?us-ascii?Q?yRvkV5/xOG4SDiDaBCVqwcnSysDRMhFMzyWMCe3V/wtCSQfhD1n8ZARtCxhW?=
	=?us-ascii?Q?hqbEeVywyZ5bYbeIr43xJmt1OpfWeeXsEs2d5u73pGhU2P7YalUuxND8rVxi?=
	=?us-ascii?Q?kNmvhC9szMYUgI7Qkd1ViKPSEbkVwZd8PBcNXC17JvoGpgLgprnpiEwPcs6E?=
	=?us-ascii?Q?+s0Lo+hdCTM2pT7HTR1JVBDbtDHyfqUL+HubwaM9BizElgthgS6p/u0Op924?=
	=?us-ascii?Q?nBZdqbbf52JiMejxCralIi7vKF8WW5xQGTTar8MfQsB0RLGXUkm4DfHGewCV?=
	=?us-ascii?Q?q5qVNSXOxWNKuyI5RHZuLlXdZzpjn0pQfuiu3AG1RYLIPFPOnPoYzi5t875r?=
	=?us-ascii?Q?cU9azp0sV3bm0vhZ5e3kBrv+tI5ab4Ru9k4SRDifEsJs04ziQSe6/L0sUaVS?=
	=?us-ascii?Q?qqk7t4j+fa1eQBXWub01lKtr2YePHwSG/h7GuW6oHVaqMjCmYYpmymg1SHeS?=
	=?us-ascii?Q?O6e5wyJ2DVPKe1ZtEabcB5FpMS7u7YIXBNM6bDKu+hyyIENfVND+qzQznkfG?=
	=?us-ascii?Q?IBiyNFThhrVqe+un0BepxO6pruL1/BfljIAVJQ8ftm+YgNHoFQvA+6cn2Vjp?=
	=?us-ascii?Q?b3VZQFE/tt+YPthiwGSiCqk2wxaBMaqZ1CKrYP0Qpyljip1d2Jhp6mxFcAt3?=
	=?us-ascii?Q?SGwBfsXQFtu5QmrtNA=3D?=
X-Microsoft-Exchange-Diagnostics: 1; AM2PR02MB0772;
	5:ibGlVElNgxELLii9Xw6YySEZBl33Fb2jSWPzSEdzABkLs9BNruJGCZ2FoAv3EiI30fZZ+UQlyxhQXGkZIbfkZh8EqHE1W81GP2iD96VpS4hSjNSI48xXy2G1NXSDjy6OwelqeEpFY4rlJYSBM1LjAw==;
	24:0Pc9ucz+cMhJLbsIeCpDJVgU29Yzdz4MTc0ySiTsZG4/z5v9hQf7fJu6HwvAswzykdRgA1oXcsYzF2adCALOXbkHE+igWy6d0Yaj6hnqrJQ=;
	20:XT7d8hkvAZd0JcnRy8xcQuFHx8BPjbAO8ZruXHEiFeyJcvx0ijt7PxVvsQLf68pOWPxm0R1nmIYxCmsm7yfOQw==
SpamDiagnosticOutput: 1:23
SpamDiagnosticMetadata: NSPM
X-OriginatorOrg: ezchip.com
X-MS-Exchange-CrossTenant-OriginalArrivalTime: 15 Sep 2015 18:02:41.6534
	(UTC)
X-MS-Exchange-CrossTenant-Id: 0fc16e0a-3cd3-4092-8b2f-0a42cff122c3
X-MS-Exchange-CrossTenant-OriginalAttributedTenantConnectingIp: TenantId=0fc16e0a-3cd3-4092-8b2f-0a42cff122c3;
	Ip=[12.216.194.146]; Helo=[ld-2.internal.tilera.com]
X-MS-Exchange-CrossTenant-FromEntityHeader: HybridOnPrem
X-MS-Exchange-Transport-CrossTenantHeadersStamped: AM2PR02MB0772
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Spam-Status: No, score=-6.9 required=5.0 tests=BAYES_00, RCVD_IN_DNSWL_HI, 
	T_RP_MATCHES_RCVD,
	UNPARSEABLE_RELAY autolearn=unavailable version=3.3.1
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on mail.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=142331">David Woods</a> - Sept. 15, 2015, 6:01 p.m.</div>
<pre class="content">
The arm64 MMU supports a Contiguous bit which is a hint that the TTE
is one of a set of contiguous entries which can be cached in a single
TLB entry.  Supporting this bit adds new intermediate huge page sizes.

The set of huge page sizes available depends on the base page size.
Without using contiguous pages the huge page sizes are as follows.

 4KB:   2MB  1GB
64KB: 512MB  4TB

With 4KB pages, the contiguous bit groups together sets of 16 pages
and with 64KB pages it groups sets of 32 pages.  This enables two new
huge page sizes in each case, so that the full set of available sizes
is as follows.

 4KB:  64KB   2MB  32MB  1GB
64KB:   2MB 512MB  16GB  4TB

If the base page size is set to 64KB then 2MB pages are enabled by
default.  It is possible in the future to make 2MB the default huge
page size for both 4KB and 64KB pages.
<span class="signed-off-by">
Signed-off-by: David Woods &lt;dwoods@ezchip.com&gt;</span>
<span class="reviewed-by">Reviewed-by: Chris Metcalf &lt;cmetcalf@ezchip.com&gt;</span>
---
 arch/arm64/Kconfig                     |   3 -
 arch/arm64/include/asm/hugetlb.h       |   4 +
 arch/arm64/include/asm/pgtable-hwdef.h |  15 +++
 arch/arm64/include/asm/pgtable.h       |  30 +++++-
 arch/arm64/mm/hugetlbpage.c            | 165 ++++++++++++++++++++++++++++++++-
 5 files changed, 210 insertions(+), 7 deletions(-)
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=64911">Steve Capper</a> - Sept. 16, 2015, 8:46 a.m.</div>
<pre class="content">
On 15 September 2015 at 19:01, David Woods &lt;dwoods@ezchip.com&gt; wrote:
<span class="quote">&gt; The arm64 MMU supports a Contiguous bit which is a hint that the TTE</span>
<span class="quote">&gt; is one of a set of contiguous entries which can be cached in a single</span>
<span class="quote">&gt; TLB entry.  Supporting this bit adds new intermediate huge page sizes.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; The set of huge page sizes available depends on the base page size.</span>
<span class="quote">&gt; Without using contiguous pages the huge page sizes are as follows.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;  4KB:   2MB  1GB</span>
<span class="quote">&gt; 64KB: 512MB  4TB</span>

We just have 512MB for a 64KB granule.
As per [1] D4.2.6 - &quot;The VMSAv8-64 translation table format&quot; page D4-1668.
<span class="quote">
&gt;</span>
<span class="quote">&gt; With 4KB pages, the contiguous bit groups together sets of 16 pages</span>
<span class="quote">&gt; and with 64KB pages it groups sets of 32 pages.  This enables two new</span>
<span class="quote">&gt; huge page sizes in each case, so that the full set of available sizes</span>
<span class="quote">&gt; is as follows.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;  4KB:  64KB   2MB  32MB  1GB</span>
<span class="quote">&gt; 64KB:   2MB 512MB  16GB  4TB</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; If the base page size is set to 64KB then 2MB pages are enabled by</span>
<span class="quote">&gt; default.  It is possible in the future to make 2MB the default huge</span>
<span class="quote">&gt; page size for both 4KB and 64KB pages.</span>
<span class="quote">&gt;</span>

Hi David,
Thanks for posting this, and apologies in advance for talking about
the ARM ARM[1]...

D4.4.2 &quot;Other fields in the VMSAv8-64 translation table format
descriptors&quot; (page D4-1715)
Only gives examples of the contiguous bit being used for level 3
descriptors (i.e. PTEs) when running with a 4KB and 64KB granule.

With a 16KB granule we *can* have a contiguous bit being used by level
2 descriptors (i.e. PMDs), so the pmd_contig logic could perhaps be
used in combination with Suzuki&#39;s 16KB PAGE_SIZE series at:
http://lists.infradead.org/pipermail/linux-arm-kernel/2015-September/370117.html

I will read through the rest of the patch and post more feedback

Cheers,
--
Steve

[1] - http://infocenter.arm.com/help/topic/com.arm.doc.ddi0487a.g/index.html
<span class="quote">



&gt; Signed-off-by: David Woods &lt;dwoods@ezchip.com&gt;</span>
<span class="quote">&gt; Reviewed-by: Chris Metcalf &lt;cmetcalf@ezchip.com&gt;</span>
<span class="quote">&gt; ---</span>
<span class="quote">&gt;  arch/arm64/Kconfig                     |   3 -</span>
<span class="quote">&gt;  arch/arm64/include/asm/hugetlb.h       |   4 +</span>
<span class="quote">&gt;  arch/arm64/include/asm/pgtable-hwdef.h |  15 +++</span>
<span class="quote">&gt;  arch/arm64/include/asm/pgtable.h       |  30 +++++-</span>
<span class="quote">&gt;  arch/arm64/mm/hugetlbpage.c            | 165 ++++++++++++++++++++++++++++++++-</span>
<span class="quote">&gt;  5 files changed, 210 insertions(+), 7 deletions(-)</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; diff --git a/arch/arm64/Kconfig b/arch/arm64/Kconfig</span>
<span class="quote">&gt; index 7d95663..8310e38 100644</span>
<span class="quote">&gt; --- a/arch/arm64/Kconfig</span>
<span class="quote">&gt; +++ b/arch/arm64/Kconfig</span>
<span class="quote">&gt; @@ -447,9 +447,6 @@ config HW_PERF_EVENTS</span>
<span class="quote">&gt;  config SYS_SUPPORTS_HUGETLBFS</span>
<span class="quote">&gt;         def_bool y</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; -config ARCH_WANT_GENERAL_HUGETLB</span>
<span class="quote">&gt; -       def_bool y</span>
<span class="quote">&gt; -</span>
<span class="quote">&gt;  config ARCH_WANT_HUGE_PMD_SHARE</span>
<span class="quote">&gt;         def_bool y if !ARM64_64K_PAGES</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; diff --git a/arch/arm64/include/asm/hugetlb.h b/arch/arm64/include/asm/hugetlb.h</span>
<span class="quote">&gt; index bb4052e..e5af553 100644</span>
<span class="quote">&gt; --- a/arch/arm64/include/asm/hugetlb.h</span>
<span class="quote">&gt; +++ b/arch/arm64/include/asm/hugetlb.h</span>
<span class="quote">&gt; @@ -97,4 +97,8 @@ static inline void arch_clear_hugepage_flags(struct page *page)</span>
<span class="quote">&gt;         clear_bit(PG_dcache_clean, &amp;page-&gt;flags);</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; +extern pte_t arch_make_huge_pte(pte_t entry, struct vm_area_struct *vma,</span>
<span class="quote">&gt; +                               struct page *page, int writable);</span>
<span class="quote">&gt; +#define arch_make_huge_pte arch_make_huge_pte</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt;  #endif /* __ASM_HUGETLB_H */</span>
<span class="quote">&gt; diff --git a/arch/arm64/include/asm/pgtable-hwdef.h b/arch/arm64/include/asm/pgtable-hwdef.h</span>
<span class="quote">&gt; index 24154b0..da73243 100644</span>
<span class="quote">&gt; --- a/arch/arm64/include/asm/pgtable-hwdef.h</span>
<span class="quote">&gt; +++ b/arch/arm64/include/asm/pgtable-hwdef.h</span>
<span class="quote">&gt; @@ -55,6 +55,19 @@</span>
<span class="quote">&gt;  #define SECTION_MASK           (~(SECTION_SIZE-1))</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;  /*</span>
<span class="quote">&gt; + * Contiguous large page definitions.</span>
<span class="quote">&gt; + */</span>
<span class="quote">&gt; +#ifdef CONFIG_ARM64_64K_PAGES</span>
<span class="quote">&gt; +#define        CONTIG_SHIFT            5</span>
<span class="quote">&gt; +#define CONTIG_PAGES           32</span>
<span class="quote">&gt; +#else</span>
<span class="quote">&gt; +#define        CONTIG_SHIFT            4</span>
<span class="quote">&gt; +#define CONTIG_PAGES           16</span>
<span class="quote">&gt; +#endif</span>
<span class="quote">&gt; +#define        CONTIG_PTE_SIZE         (CONTIG_PAGES * PAGE_SIZE)</span>
<span class="quote">&gt; +#define        CONTIG_PTE_MASK         (~(CONTIG_PTE_SIZE - 1))</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +/*</span>
<span class="quote">&gt;   * Hardware page table definitions.</span>
<span class="quote">&gt;   *</span>
<span class="quote">&gt;   * Level 1 descriptor (PUD).</span>
<span class="quote">&gt; @@ -83,6 +96,7 @@</span>
<span class="quote">&gt;  #define PMD_SECT_S             (_AT(pmdval_t, 3) &lt;&lt; 8)</span>
<span class="quote">&gt;  #define PMD_SECT_AF            (_AT(pmdval_t, 1) &lt;&lt; 10)</span>
<span class="quote">&gt;  #define PMD_SECT_NG            (_AT(pmdval_t, 1) &lt;&lt; 11)</span>
<span class="quote">&gt; +#define PMD_SECT_CONTIG                (_AT(pmdval_t, 1) &lt;&lt; 52)</span>
<span class="quote">&gt;  #define PMD_SECT_PXN           (_AT(pmdval_t, 1) &lt;&lt; 53)</span>
<span class="quote">&gt;  #define PMD_SECT_UXN           (_AT(pmdval_t, 1) &lt;&lt; 54)</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; @@ -105,6 +119,7 @@</span>
<span class="quote">&gt;  #define PTE_AF                 (_AT(pteval_t, 1) &lt;&lt; 10)        /* Access Flag */</span>
<span class="quote">&gt;  #define PTE_NG                 (_AT(pteval_t, 1) &lt;&lt; 11)        /* nG */</span>
<span class="quote">&gt;  #define PTE_DBM                        (_AT(pteval_t, 1) &lt;&lt; 51)        /* Dirty Bit Management */</span>
<span class="quote">&gt; +#define PTE_CONTIG             (_AT(pteval_t, 1) &lt;&lt; 52)        /* Contiguous */</span>
<span class="quote">&gt;  #define PTE_PXN                        (_AT(pteval_t, 1) &lt;&lt; 53)        /* Privileged XN */</span>
<span class="quote">&gt;  #define PTE_UXN                        (_AT(pteval_t, 1) &lt;&lt; 54)        /* User XN */</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; diff --git a/arch/arm64/include/asm/pgtable.h b/arch/arm64/include/asm/pgtable.h</span>
<span class="quote">&gt; index 6900b2d9..df5ec64 100644</span>
<span class="quote">&gt; --- a/arch/arm64/include/asm/pgtable.h</span>
<span class="quote">&gt; +++ b/arch/arm64/include/asm/pgtable.h</span>
<span class="quote">&gt; @@ -144,6 +144,7 @@ extern struct page *empty_zero_page;</span>
<span class="quote">&gt;  #define pte_special(pte)       (!!(pte_val(pte) &amp; PTE_SPECIAL))</span>
<span class="quote">&gt;  #define pte_write(pte)         (!!(pte_val(pte) &amp; PTE_WRITE))</span>
<span class="quote">&gt;  #define pte_exec(pte)          (!(pte_val(pte) &amp; PTE_UXN))</span>
<span class="quote">&gt; +#define pte_contig(pte)                (!!(pte_val(pte) &amp; PTE_CONTIG))</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;  #ifdef CONFIG_ARM64_HW_AFDBM</span>
<span class="quote">&gt;  #define pte_hw_dirty(pte)      (!(pte_val(pte) &amp; PTE_RDONLY))</span>
<span class="quote">&gt; @@ -206,6 +207,9 @@ static inline pte_t pte_mkspecial(pte_t pte)</span>
<span class="quote">&gt;         return set_pte_bit(pte, __pgprot(PTE_SPECIAL));</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; +extern pte_t pte_mkcontig(pte_t pte);</span>
<span class="quote">&gt; +extern pmd_t pmd_mkcontig(pmd_t pmd);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt;  static inline void set_pte(pte_t *ptep, pte_t pte)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;         *ptep = pte;</span>
<span class="quote">&gt; @@ -275,7 +279,7 @@ static inline void set_pte_at(struct mm_struct *mm, unsigned long addr,</span>
<span class="quote">&gt;  /*</span>
<span class="quote">&gt;   * Hugetlb definitions.</span>
<span class="quote">&gt;   */</span>
<span class="quote">&gt; -#define HUGE_MAX_HSTATE                2</span>
<span class="quote">&gt; +#define HUGE_MAX_HSTATE                ((2 * CONFIG_PGTABLE_LEVELS) - 1)</span>
<span class="quote">&gt;  #define HPAGE_SHIFT            PMD_SHIFT</span>
<span class="quote">&gt;  #define HPAGE_SIZE             (_AC(1, UL) &lt;&lt; HPAGE_SHIFT)</span>
<span class="quote">&gt;  #define HPAGE_MASK             (~(HPAGE_SIZE - 1))</span>
<span class="quote">&gt; @@ -372,7 +376,8 @@ extern pgprot_t phys_mem_access_prot(struct file *file, unsigned long pfn,</span>
<span class="quote">&gt;  #define pmd_none(pmd)          (!pmd_val(pmd))</span>
<span class="quote">&gt;  #define pmd_present(pmd)       (pmd_val(pmd))</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; -#define pmd_bad(pmd)           (!(pmd_val(pmd) &amp; 2))</span>
<span class="quote">&gt; +#define pmd_bad(pmd)           (!(pmd_val(pmd) &amp; \</span>
<span class="quote">&gt; +                                  (PMD_TABLE_BIT | PMD_SECT_CONTIG)))</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;  #define pmd_table(pmd)         ((pmd_val(pmd) &amp; PMD_TYPE_MASK) == \</span>
<span class="quote">&gt;                                  PMD_TYPE_TABLE)</span>
<span class="quote">&gt; @@ -500,7 +505,8 @@ static inline pud_t *pud_offset(pgd_t *pgd, unsigned long addr)</span>
<span class="quote">&gt;  static inline pte_t pte_modify(pte_t pte, pgprot_t newprot)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;         const pteval_t mask = PTE_USER | PTE_PXN | PTE_UXN | PTE_RDONLY |</span>
<span class="quote">&gt; -                             PTE_PROT_NONE | PTE_WRITE | PTE_TYPE_MASK;</span>
<span class="quote">&gt; +                             PTE_PROT_NONE | PTE_WRITE | PTE_TYPE_MASK |</span>
<span class="quote">&gt; +                             PTE_CONTIG;</span>
<span class="quote">&gt;         /* preserve the hardware dirty information */</span>
<span class="quote">&gt;         if (pte_hw_dirty(pte))</span>
<span class="quote">&gt;                 newprot |= PTE_DIRTY;</span>
<span class="quote">&gt; @@ -513,6 +519,24 @@ static inline pmd_t pmd_modify(pmd_t pmd, pgprot_t newprot)</span>
<span class="quote">&gt;         return pte_pmd(pte_modify(pmd_pte(pmd), newprot));</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; +static inline pte_t pte_modify_pfn(pte_t pte, unsigned long newpfn)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +       const pteval_t mask = PHYS_MASK &amp; PAGE_MASK;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +       pte_val(pte) = pfn_pte(newpfn, (pte_val(pte) &amp; ~mask));</span>
<span class="quote">&gt; +       return pte;</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +#if CONFIG_PGTABLE_LEVELS &gt; 2</span>
<span class="quote">&gt; +static inline pmd_t pmd_modify_pfn(pmd_t pmd, unsigned long newpfn)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +       const pmdval_t mask = PHYS_MASK &amp; PAGE_MASK;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +       pmd = pfn_pmd(newpfn, (pmd_val(pmd) &amp; ~mask));</span>
<span class="quote">&gt; +       return pmd;</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +#endif</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt;  #ifdef CONFIG_ARM64_HW_AFDBM</span>
<span class="quote">&gt;  /*</span>
<span class="quote">&gt;   * Atomic pte/pmd modifications.</span>
<span class="quote">&gt; diff --git a/arch/arm64/mm/hugetlbpage.c b/arch/arm64/mm/hugetlbpage.c</span>
<span class="quote">&gt; index 383b03f..f5bbbbc 100644</span>
<span class="quote">&gt; --- a/arch/arm64/mm/hugetlbpage.c</span>
<span class="quote">&gt; +++ b/arch/arm64/mm/hugetlbpage.c</span>
<span class="quote">&gt; @@ -41,6 +41,155 @@ int pud_huge(pud_t pud)</span>
<span class="quote">&gt;  #endif</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; +pte_t *huge_pte_alloc(struct mm_struct *mm,</span>
<span class="quote">&gt; +                       unsigned long addr, unsigned long sz)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +       pgd_t *pgd;</span>
<span class="quote">&gt; +       pud_t *pud;</span>
<span class="quote">&gt; +       pte_t *pte = NULL;</span>
<span class="quote">&gt; +       int i;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +       pgd = pgd_offset(mm, addr);</span>
<span class="quote">&gt; +       pud = pud_alloc(mm, pgd, addr);</span>
<span class="quote">&gt; +       if (pud) {</span>
<span class="quote">&gt; +               if (sz == PUD_SIZE) {</span>
<span class="quote">&gt; +                       pte = (pte_t *)pud;</span>
<span class="quote">&gt; +               } else if (sz == PMD_SIZE) {</span>
<span class="quote">&gt; +#ifdef CONFIG_ARCH_WANT_HUGE_PMD_SHARE</span>
<span class="quote">&gt; +                       if (pud_none(*pud))</span>
<span class="quote">&gt; +                               pte = huge_pmd_share(mm, addr, pud);</span>
<span class="quote">&gt; +                       else</span>
<span class="quote">&gt; +#endif</span>
<span class="quote">&gt; +                               pte = (pte_t *)pmd_alloc(mm, pud, addr);</span>
<span class="quote">&gt; +               } else if (sz == (PAGE_SIZE * CONTIG_PAGES)) {</span>
<span class="quote">&gt; +                       pmd_t *pmd = pmd_alloc(mm, pud, addr);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +                       WARN_ON(addr &amp; (sz - 1));</span>
<span class="quote">&gt; +                       pte = pte_alloc_map(mm, NULL, pmd, addr);</span>
<span class="quote">&gt; +                       if (pte_present(*pte)) {</span>
<span class="quote">&gt; +                               unsigned long pfn;</span>
<span class="quote">&gt; +                               *pte = pte_mkcontig(*pte);</span>
<span class="quote">&gt; +                               pfn = pte_pfn(*pte);</span>
<span class="quote">&gt; +                               for (i = 0; i &lt; CONTIG_PAGES; i++) {</span>
<span class="quote">&gt; +                                       set_pte(&amp;pte[i],</span>
<span class="quote">&gt; +                                               pte_modify_pfn(*pte, pfn + i));</span>
<span class="quote">&gt; +                               }</span>
<span class="quote">&gt; +                       }</span>
<span class="quote">&gt; +#if CONFIG_PGTABLE_LEVELS &gt; 2</span>
<span class="quote">&gt; +               } else if (sz == (PMD_SIZE * CONTIG_PAGES)) {</span>
<span class="quote">&gt; +                       pmd_t *pmd;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +                       pmd = pmd_alloc(mm, pud, addr);</span>
<span class="quote">&gt; +                       WARN_ON(addr &amp; (sz - 1));</span>
<span class="quote">&gt; +                       if (pmd &amp;&amp; pmd_present(*pmd)) {</span>
<span class="quote">&gt; +                               unsigned long pfn;</span>
<span class="quote">&gt; +                               pmd_t pmdval;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +                               pmdval = *pmd = pmd_mkcontig(*pmd);</span>
<span class="quote">&gt; +                               pfn = pmd_pfn(*pmd);</span>
<span class="quote">&gt; +                               for (i = 0; i &lt; CONTIG_PAGES; i++) {</span>
<span class="quote">&gt; +                                       unsigned long newpfn = pfn +</span>
<span class="quote">&gt; +                                               (i &lt;&lt; (PMD_SHIFT - PAGE_SHIFT));</span>
<span class="quote">&gt; +                                       if (!pmd_present(pmd[i]))</span>
<span class="quote">&gt; +                                               atomic_long_inc(&amp;mm-&gt;nr_ptes);</span>
<span class="quote">&gt; +                                       set_pmd(&amp;pmd[i],</span>
<span class="quote">&gt; +                                               pmd_modify_pfn(pmdval, newpfn));</span>
<span class="quote">&gt; +                               }</span>
<span class="quote">&gt; +                       }</span>
<span class="quote">&gt; +                       return pmd;</span>
<span class="quote">&gt; +#endif</span>
<span class="quote">&gt; +               }</span>
<span class="quote">&gt; +       }</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +       return pte;</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +pte_t *huge_pte_offset(struct mm_struct *mm, unsigned long addr)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +       pgd_t *pgd;</span>
<span class="quote">&gt; +       pud_t *pud;</span>
<span class="quote">&gt; +       pmd_t *pmd = NULL;</span>
<span class="quote">&gt; +       pte_t *pte = NULL;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +       pgd = pgd_offset(mm, addr);</span>
<span class="quote">&gt; +       if (pgd_present(*pgd)) {</span>
<span class="quote">&gt; +               pud = pud_offset(pgd, addr);</span>
<span class="quote">&gt; +               if (pud_present(*pud)) {</span>
<span class="quote">&gt; +                       if (pud_huge(*pud))</span>
<span class="quote">&gt; +                               return (pte_t *)pud;</span>
<span class="quote">&gt; +                       pmd = pmd_offset(pud, addr);</span>
<span class="quote">&gt; +                       if (pmd_present(*pmd)) {</span>
<span class="quote">&gt; +                               if (pmd_huge(*pmd))</span>
<span class="quote">&gt; +                                       return (pte_t *)pmd;</span>
<span class="quote">&gt; +                               pte = pte_offset_kernel(pmd, addr);</span>
<span class="quote">&gt; +                               if (pte_present(*pte) &amp;&amp; pte_contig(*pte)) {</span>
<span class="quote">&gt; +                                       pte = pte_offset_kernel(</span>
<span class="quote">&gt; +                                               pmd, (addr &amp; CONTIG_PTE_MASK));</span>
<span class="quote">&gt; +                                       return pte;</span>
<span class="quote">&gt; +                               }</span>
<span class="quote">&gt; +                       }</span>
<span class="quote">&gt; +               }</span>
<span class="quote">&gt; +       }</span>
<span class="quote">&gt; +       return (pte_t *) NULL;</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +pte_t arch_make_huge_pte(pte_t entry, struct vm_area_struct *vma,</span>
<span class="quote">&gt; +                        struct page *page, int writable)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +       size_t pagesize = huge_page_size(hstate_vma(vma));</span>
<span class="quote">&gt; +       pte_t nent = {0};</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +       if (pagesize == PUD_SIZE || pagesize == PMD_SIZE)</span>
<span class="quote">&gt; +               nent = entry;</span>
<span class="quote">&gt; +       else if (pagesize == (PAGE_SIZE * CONTIG_PAGES))</span>
<span class="quote">&gt; +               nent = pte_mkcontig(entry);</span>
<span class="quote">&gt; +#if CONFIG_PGTABLE_LEVELS &gt; 2</span>
<span class="quote">&gt; +       else if (pagesize == (PMD_SIZE * CONTIG_PAGES) ||</span>
<span class="quote">&gt; +                pagesize == (PUD_SIZE * CONTIG_PAGES))</span>
<span class="quote">&gt; +               nent = pmd_mkcontig(entry);</span>
<span class="quote">&gt; +#endif</span>
<span class="quote">&gt; +       else {</span>
<span class="quote">&gt; +               pr_warn(&quot;%s: unrecognized huge page size 0x%lx\n&quot;,</span>
<span class="quote">&gt; +                      __func__, pagesize);</span>
<span class="quote">&gt; +       }</span>
<span class="quote">&gt; +       return nent;</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +pte_t pte_mkcontig(pte_t pte)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +       pte = set_pte_bit(pte, __pgprot(PTE_CONTIG));</span>
<span class="quote">&gt; +       pte = set_pte_bit(pte, __pgprot(PTE_TYPE_PAGE));</span>
<span class="quote">&gt; +       return pte;</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +pmd_t pmd_mkcontig(pmd_t pmd)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +       pmd = __pmd(pmd_val(pmd) | PMD_SECT_CONTIG);</span>
<span class="quote">&gt; +       return pmd;</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +struct page *follow_huge_pmd(struct mm_struct *mm, unsigned long address,</span>
<span class="quote">&gt; +               pmd_t *pmd, int write)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +       struct page *page;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +       page = pte_page(*(pte_t *)pmd);</span>
<span class="quote">&gt; +       if (page)</span>
<span class="quote">&gt; +               page += ((address &amp; ~PMD_MASK) &gt;&gt; PAGE_SHIFT);</span>
<span class="quote">&gt; +       return page;</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +struct page *follow_huge_pud(struct mm_struct *mm, unsigned long address,</span>
<span class="quote">&gt; +               pud_t *pud, int write)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +       struct page *page;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +       page = pte_page(*(pte_t *)pud);</span>
<span class="quote">&gt; +       if (page)</span>
<span class="quote">&gt; +               page += ((address &amp; ~PUD_MASK) &gt;&gt; PAGE_SHIFT);</span>
<span class="quote">&gt; +       return page;</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt;  static __init int setup_hugepagesz(char *opt)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;         unsigned long ps = memparse(opt, &amp;opt);</span>
<span class="quote">&gt; @@ -48,10 +197,24 @@ static __init int setup_hugepagesz(char *opt)</span>
<span class="quote">&gt;                 hugetlb_add_hstate(PMD_SHIFT - PAGE_SHIFT);</span>
<span class="quote">&gt;         } else if (ps == PUD_SIZE) {</span>
<span class="quote">&gt;                 hugetlb_add_hstate(PUD_SHIFT - PAGE_SHIFT);</span>
<span class="quote">&gt; +       } else if (ps == (PAGE_SIZE * CONTIG_PAGES)) {</span>
<span class="quote">&gt; +               hugetlb_add_hstate(CONTIG_SHIFT);</span>
<span class="quote">&gt; +       } else if (ps == (PMD_SIZE * CONTIG_PAGES)) {</span>
<span class="quote">&gt; +               hugetlb_add_hstate((PMD_SHIFT + CONTIG_SHIFT) - PAGE_SHIFT);</span>
<span class="quote">&gt;         } else {</span>
<span class="quote">&gt; -               pr_err(&quot;hugepagesz: Unsupported page size %lu M\n&quot;, ps &gt;&gt; 20);</span>
<span class="quote">&gt; +               pr_err(&quot;hugepagesz: Unsupported page size %lu K\n&quot;, ps &gt;&gt; 10);</span>
<span class="quote">&gt;                 return 0;</span>
<span class="quote">&gt;         }</span>
<span class="quote">&gt;         return 1;</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;  __setup(&quot;hugepagesz=&quot;, setup_hugepagesz);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +#ifdef CONFIG_ARM64_64K_PAGES</span>
<span class="quote">&gt; +static __init int add_default_hugepagesz(void)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +       if (size_to_hstate(CONTIG_PAGES * PAGE_SIZE) == NULL)</span>
<span class="quote">&gt; +               hugetlb_add_hstate(CONTIG_SHIFT);</span>
<span class="quote">&gt; +       return 0;</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +arch_initcall(add_default_hugepagesz);</span>
<span class="quote">&gt; +#endif</span>
<span class="quote">&gt; --</span>
<span class="quote">&gt; 2.1.2</span>
<span class="quote">&gt;</span>
--
To unsubscribe from this list: send the line &quot;unsubscribe linux-kernel&quot; in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
Please read the FAQ at  http://www.tux.org/lkml/
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=64911">Steve Capper</a> - Sept. 16, 2015, 2:06 p.m.</div>
<pre class="content">
Hi David,
Some initial comments below.

Cheers,
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=7096">Will Deacon</a> - Sept. 16, 2015, 5:05 p.m.</div>
<pre class="content">
Hi David,

On Tue, Sep 15, 2015 at 07:01:57PM +0100, David Woods wrote:
<span class="quote">&gt; The arm64 MMU supports a Contiguous bit which is a hint that the TTE</span>
<span class="quote">&gt; is one of a set of contiguous entries which can be cached in a single</span>
<span class="quote">&gt; TLB entry.  Supporting this bit adds new intermediate huge page sizes.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; The set of huge page sizes available depends on the base page size.</span>
<span class="quote">&gt; Without using contiguous pages the huge page sizes are as follows.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt;  4KB:   2MB  1GB</span>
<span class="quote">&gt; 64KB: 512MB  4TB</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; With 4KB pages, the contiguous bit groups together sets of 16 pages</span>
<span class="quote">&gt; and with 64KB pages it groups sets of 32 pages.  This enables two new</span>
<span class="quote">&gt; huge page sizes in each case, so that the full set of available sizes</span>
<span class="quote">&gt; is as follows.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt;  4KB:  64KB   2MB  32MB  1GB</span>
<span class="quote">&gt; 64KB:   2MB 512MB  16GB  4TB</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; If the base page size is set to 64KB then 2MB pages are enabled by</span>
<span class="quote">&gt; default.  It is possible in the future to make 2MB the default huge</span>
<span class="quote">&gt; page size for both 4KB and 64KB pages.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Signed-off-by: David Woods &lt;dwoods@ezchip.com&gt;</span>
<span class="quote">&gt; Reviewed-by: Chris Metcalf &lt;cmetcalf@ezchip.com&gt;</span>
<span class="quote">&gt; ---</span>
<span class="quote">&gt;  arch/arm64/Kconfig                     |   3 -</span>
<span class="quote">&gt;  arch/arm64/include/asm/hugetlb.h       |   4 +</span>
<span class="quote">&gt;  arch/arm64/include/asm/pgtable-hwdef.h |  15 +++</span>
<span class="quote">&gt;  arch/arm64/include/asm/pgtable.h       |  30 +++++-</span>
<span class="quote">&gt;  arch/arm64/mm/hugetlbpage.c            | 165 ++++++++++++++++++++++++++++++++-</span>
<span class="quote">&gt;  5 files changed, 210 insertions(+), 7 deletions(-)</span>

I glanced briefly at this, and I think you&#39;ll need to do some extra work
for the CONFIG_HW_AFDBM=y case, where the CPU can set access/dirty bits
in any (i.e. not necessarily all) of the page table entries in a
contiguous mapping. In this case, things like huge_pte_dirty might need
overriding.

Will
--
To unsubscribe from this list: send the line &quot;unsubscribe linux-kernel&quot; in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
Please read the FAQ at  http://www.tux.org/lkml/
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=142331">David Woods</a> - Sept. 21, 2015, 4:44 p.m.</div>
<pre class="content">
Steve,

Thanks for your review and comments.  I take your points about the 16k 
granule - it&#39;s helpful to know that support is in the works. However, 
I&#39;m not sure I agree with your reading of section 4.4.2. It&#39;s clear that 
for 16k granules, the number of contiguous pages is different for the 
PTE and PMD levels.  But I don&#39;t see anywhere it says that for 4K and 
64K that the contig bit is not supported at the PMD level - just that 
the number of contiguous pages is the same at each level.

I tried using the tarmac trace module of the ARM simulator to support 
this idea by turning on MMU tracing.  Using 4k granule, I created 64k 
and 32m pages and touched each location in the page.  In both cases, the 
trace recorded just one TLB fill (rather than the 16 you&#39;d expect if the 
contiguous bit were being ignored) and it indicated the expected page size.

1817498494 clk cpu2 TLB FILL cpu2.S1TLB 64K 0x2000000000_NS vmid=0, nG 
asid=303:0x08fa360000_NS Normal InnerShareable 
Inner=WriteBackWriteAllocate Outer=WriteBackWriteAllocate xn=0 pxn=1 
ContiguousHint=1

1263366314 clk cpu2 TLB FILL cpu2.UTLB 32M 0x2000000000_NS vmid=0, nG 
asid=300:0x08f6000000_NS Normal InnerShareable 
Inner=WriteBackWriteAllocate Outer=WriteBackWriteAllocate xn=0 pxn=1 
ContiguousHint=1

I&#39;ll try this with a 64k granule next.  I&#39;m not sure what will happen 
with 16G pages since we are using an A53 model which I don&#39;t think 
supports such large pages.

-Dave

On 09/16/2015 04:46 AM, Steve Capper wrote:
<span class="quote">&gt; On 15 September 2015 at 19:01, David Woods &lt;dwoods@ezchip.com&gt; wrote:</span>
<span class="quote">&gt;&gt; The arm64 MMU supports a Contiguous bit which is a hint that the TTE</span>
<span class="quote">&gt;&gt; is one of a set of contiguous entries which can be cached in a single</span>
<span class="quote">&gt;&gt; TLB entry.  Supporting this bit adds new intermediate huge page sizes.</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; The set of huge page sizes available depends on the base page size.</span>
<span class="quote">&gt;&gt; Without using contiguous pages the huge page sizes are as follows.</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt;   4KB:   2MB  1GB</span>
<span class="quote">&gt;&gt; 64KB: 512MB  4TB</span>
<span class="quote">&gt; We just have 512MB for a 64KB granule.</span>
<span class="quote">&gt; As per [1] D4.2.6 - &quot;The VMSAv8-64 translation table format&quot; page D4-1668.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;&gt; With 4KB pages, the contiguous bit groups together sets of 16 pages</span>
<span class="quote">&gt;&gt; and with 64KB pages it groups sets of 32 pages.  This enables two new</span>
<span class="quote">&gt;&gt; huge page sizes in each case, so that the full set of available sizes</span>
<span class="quote">&gt;&gt; is as follows.</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt;   4KB:  64KB   2MB  32MB  1GB</span>
<span class="quote">&gt;&gt; 64KB:   2MB 512MB  16GB  4TB</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; If the base page size is set to 64KB then 2MB pages are enabled by</span>
<span class="quote">&gt;&gt; default.  It is possible in the future to make 2MB the default huge</span>
<span class="quote">&gt;&gt; page size for both 4KB and 64KB pages.</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt; Hi David,</span>
<span class="quote">&gt; Thanks for posting this, and apologies in advance for talking about</span>
<span class="quote">&gt; the ARM ARM[1]...</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; D4.4.2 &quot;Other fields in the VMSAv8-64 translation table format</span>
<span class="quote">&gt; descriptors&quot; (page D4-1715)</span>
<span class="quote">&gt; Only gives examples of the contiguous bit being used for level 3</span>
<span class="quote">&gt; descriptors (i.e. PTEs) when running with a 4KB and 64KB granule.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; With a 16KB granule we *can* have a contiguous bit being used by level</span>
<span class="quote">&gt; 2 descriptors (i.e. PMDs), so the pmd_contig logic could perhaps be</span>
<span class="quote">&gt; used in combination with Suzuki&#39;s 16KB PAGE_SIZE series at:</span>
<span class="quote">&gt; http://lists.infradead.org/pipermail/linux-arm-kernel/2015-September/370117.html</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; I will read through the rest of the patch and post more feedback</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; Cheers,</span>
<span class="quote">&gt; --</span>
<span class="quote">&gt; Steve</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; [1] - http://infocenter.arm.com/help/topic/com.arm.doc.ddi0487a.g/index.html</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;&gt; Signed-off-by: David Woods &lt;dwoods@ezchip.com&gt;</span>
<span class="quote">&gt;&gt; Reviewed-by: Chris Metcalf &lt;cmetcalf@ezchip.com&gt;</span>
<span class="quote">&gt;&gt; ---</span>
<span class="quote">&gt;&gt;   arch/arm64/Kconfig                     |   3 -</span>
<span class="quote">&gt;&gt;   arch/arm64/include/asm/hugetlb.h       |   4 +</span>
<span class="quote">&gt;&gt;   arch/arm64/include/asm/pgtable-hwdef.h |  15 +++</span>
<span class="quote">&gt;&gt;   arch/arm64/include/asm/pgtable.h       |  30 +++++-</span>
<span class="quote">&gt;&gt;   arch/arm64/mm/hugetlbpage.c            | 165 ++++++++++++++++++++++++++++++++-</span>
<span class="quote">&gt;&gt;   5 files changed, 210 insertions(+), 7 deletions(-)</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; diff --git a/arch/arm64/Kconfig b/arch/arm64/Kconfig</span>
<span class="quote">&gt;&gt; index 7d95663..8310e38 100644</span>
<span class="quote">&gt;&gt; --- a/arch/arm64/Kconfig</span>
<span class="quote">&gt;&gt; +++ b/arch/arm64/Kconfig</span>
<span class="quote">&gt;&gt; @@ -447,9 +447,6 @@ config HW_PERF_EVENTS</span>
<span class="quote">&gt;&gt;   config SYS_SUPPORTS_HUGETLBFS</span>
<span class="quote">&gt;&gt;          def_bool y</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; -config ARCH_WANT_GENERAL_HUGETLB</span>
<span class="quote">&gt;&gt; -       def_bool y</span>
<span class="quote">&gt;&gt; -</span>
<span class="quote">&gt;&gt;   config ARCH_WANT_HUGE_PMD_SHARE</span>
<span class="quote">&gt;&gt;          def_bool y if !ARM64_64K_PAGES</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; diff --git a/arch/arm64/include/asm/hugetlb.h b/arch/arm64/include/asm/hugetlb.h</span>
<span class="quote">&gt;&gt; index bb4052e..e5af553 100644</span>
<span class="quote">&gt;&gt; --- a/arch/arm64/include/asm/hugetlb.h</span>
<span class="quote">&gt;&gt; +++ b/arch/arm64/include/asm/hugetlb.h</span>
<span class="quote">&gt;&gt; @@ -97,4 +97,8 @@ static inline void arch_clear_hugepage_flags(struct page *page)</span>
<span class="quote">&gt;&gt;          clear_bit(PG_dcache_clean, &amp;page-&gt;flags);</span>
<span class="quote">&gt;&gt;   }</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; +extern pte_t arch_make_huge_pte(pte_t entry, struct vm_area_struct *vma,</span>
<span class="quote">&gt;&gt; +                               struct page *page, int writable);</span>
<span class="quote">&gt;&gt; +#define arch_make_huge_pte arch_make_huge_pte</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt;   #endif /* __ASM_HUGETLB_H */</span>
<span class="quote">&gt;&gt; diff --git a/arch/arm64/include/asm/pgtable-hwdef.h b/arch/arm64/include/asm/pgtable-hwdef.h</span>
<span class="quote">&gt;&gt; index 24154b0..da73243 100644</span>
<span class="quote">&gt;&gt; --- a/arch/arm64/include/asm/pgtable-hwdef.h</span>
<span class="quote">&gt;&gt; +++ b/arch/arm64/include/asm/pgtable-hwdef.h</span>
<span class="quote">&gt;&gt; @@ -55,6 +55,19 @@</span>
<span class="quote">&gt;&gt;   #define SECTION_MASK           (~(SECTION_SIZE-1))</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt;   /*</span>
<span class="quote">&gt;&gt; + * Contiguous large page definitions.</span>
<span class="quote">&gt;&gt; + */</span>
<span class="quote">&gt;&gt; +#ifdef CONFIG_ARM64_64K_PAGES</span>
<span class="quote">&gt;&gt; +#define        CONTIG_SHIFT            5</span>
<span class="quote">&gt;&gt; +#define CONTIG_PAGES           32</span>
<span class="quote">&gt;&gt; +#else</span>
<span class="quote">&gt;&gt; +#define        CONTIG_SHIFT            4</span>
<span class="quote">&gt;&gt; +#define CONTIG_PAGES           16</span>
<span class="quote">&gt;&gt; +#endif</span>
<span class="quote">&gt;&gt; +#define        CONTIG_PTE_SIZE         (CONTIG_PAGES * PAGE_SIZE)</span>
<span class="quote">&gt;&gt; +#define        CONTIG_PTE_MASK         (~(CONTIG_PTE_SIZE - 1))</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +/*</span>
<span class="quote">&gt;&gt;    * Hardware page table definitions.</span>
<span class="quote">&gt;&gt;    *</span>
<span class="quote">&gt;&gt;    * Level 1 descriptor (PUD).</span>
<span class="quote">&gt;&gt; @@ -83,6 +96,7 @@</span>
<span class="quote">&gt;&gt;   #define PMD_SECT_S             (_AT(pmdval_t, 3) &lt;&lt; 8)</span>
<span class="quote">&gt;&gt;   #define PMD_SECT_AF            (_AT(pmdval_t, 1) &lt;&lt; 10)</span>
<span class="quote">&gt;&gt;   #define PMD_SECT_NG            (_AT(pmdval_t, 1) &lt;&lt; 11)</span>
<span class="quote">&gt;&gt; +#define PMD_SECT_CONTIG                (_AT(pmdval_t, 1) &lt;&lt; 52)</span>
<span class="quote">&gt;&gt;   #define PMD_SECT_PXN           (_AT(pmdval_t, 1) &lt;&lt; 53)</span>
<span class="quote">&gt;&gt;   #define PMD_SECT_UXN           (_AT(pmdval_t, 1) &lt;&lt; 54)</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; @@ -105,6 +119,7 @@</span>
<span class="quote">&gt;&gt;   #define PTE_AF                 (_AT(pteval_t, 1) &lt;&lt; 10)        /* Access Flag */</span>
<span class="quote">&gt;&gt;   #define PTE_NG                 (_AT(pteval_t, 1) &lt;&lt; 11)        /* nG */</span>
<span class="quote">&gt;&gt;   #define PTE_DBM                        (_AT(pteval_t, 1) &lt;&lt; 51)        /* Dirty Bit Management */</span>
<span class="quote">&gt;&gt; +#define PTE_CONTIG             (_AT(pteval_t, 1) &lt;&lt; 52)        /* Contiguous */</span>
<span class="quote">&gt;&gt;   #define PTE_PXN                        (_AT(pteval_t, 1) &lt;&lt; 53)        /* Privileged XN */</span>
<span class="quote">&gt;&gt;   #define PTE_UXN                        (_AT(pteval_t, 1) &lt;&lt; 54)        /* User XN */</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; diff --git a/arch/arm64/include/asm/pgtable.h b/arch/arm64/include/asm/pgtable.h</span>
<span class="quote">&gt;&gt; index 6900b2d9..df5ec64 100644</span>
<span class="quote">&gt;&gt; --- a/arch/arm64/include/asm/pgtable.h</span>
<span class="quote">&gt;&gt; +++ b/arch/arm64/include/asm/pgtable.h</span>
<span class="quote">&gt;&gt; @@ -144,6 +144,7 @@ extern struct page *empty_zero_page;</span>
<span class="quote">&gt;&gt;   #define pte_special(pte)       (!!(pte_val(pte) &amp; PTE_SPECIAL))</span>
<span class="quote">&gt;&gt;   #define pte_write(pte)         (!!(pte_val(pte) &amp; PTE_WRITE))</span>
<span class="quote">&gt;&gt;   #define pte_exec(pte)          (!(pte_val(pte) &amp; PTE_UXN))</span>
<span class="quote">&gt;&gt; +#define pte_contig(pte)                (!!(pte_val(pte) &amp; PTE_CONTIG))</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt;   #ifdef CONFIG_ARM64_HW_AFDBM</span>
<span class="quote">&gt;&gt;   #define pte_hw_dirty(pte)      (!(pte_val(pte) &amp; PTE_RDONLY))</span>
<span class="quote">&gt;&gt; @@ -206,6 +207,9 @@ static inline pte_t pte_mkspecial(pte_t pte)</span>
<span class="quote">&gt;&gt;          return set_pte_bit(pte, __pgprot(PTE_SPECIAL));</span>
<span class="quote">&gt;&gt;   }</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; +extern pte_t pte_mkcontig(pte_t pte);</span>
<span class="quote">&gt;&gt; +extern pmd_t pmd_mkcontig(pmd_t pmd);</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt;   static inline void set_pte(pte_t *ptep, pte_t pte)</span>
<span class="quote">&gt;&gt;   {</span>
<span class="quote">&gt;&gt;          *ptep = pte;</span>
<span class="quote">&gt;&gt; @@ -275,7 +279,7 @@ static inline void set_pte_at(struct mm_struct *mm, unsigned long addr,</span>
<span class="quote">&gt;&gt;   /*</span>
<span class="quote">&gt;&gt;    * Hugetlb definitions.</span>
<span class="quote">&gt;&gt;    */</span>
<span class="quote">&gt;&gt; -#define HUGE_MAX_HSTATE                2</span>
<span class="quote">&gt;&gt; +#define HUGE_MAX_HSTATE                ((2 * CONFIG_PGTABLE_LEVELS) - 1)</span>
<span class="quote">&gt;&gt;   #define HPAGE_SHIFT            PMD_SHIFT</span>
<span class="quote">&gt;&gt;   #define HPAGE_SIZE             (_AC(1, UL) &lt;&lt; HPAGE_SHIFT)</span>
<span class="quote">&gt;&gt;   #define HPAGE_MASK             (~(HPAGE_SIZE - 1))</span>
<span class="quote">&gt;&gt; @@ -372,7 +376,8 @@ extern pgprot_t phys_mem_access_prot(struct file *file, unsigned long pfn,</span>
<span class="quote">&gt;&gt;   #define pmd_none(pmd)          (!pmd_val(pmd))</span>
<span class="quote">&gt;&gt;   #define pmd_present(pmd)       (pmd_val(pmd))</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; -#define pmd_bad(pmd)           (!(pmd_val(pmd) &amp; 2))</span>
<span class="quote">&gt;&gt; +#define pmd_bad(pmd)           (!(pmd_val(pmd) &amp; \</span>
<span class="quote">&gt;&gt; +                                  (PMD_TABLE_BIT | PMD_SECT_CONTIG)))</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt;   #define pmd_table(pmd)         ((pmd_val(pmd) &amp; PMD_TYPE_MASK) == \</span>
<span class="quote">&gt;&gt;                                   PMD_TYPE_TABLE)</span>
<span class="quote">&gt;&gt; @@ -500,7 +505,8 @@ static inline pud_t *pud_offset(pgd_t *pgd, unsigned long addr)</span>
<span class="quote">&gt;&gt;   static inline pte_t pte_modify(pte_t pte, pgprot_t newprot)</span>
<span class="quote">&gt;&gt;   {</span>
<span class="quote">&gt;&gt;          const pteval_t mask = PTE_USER | PTE_PXN | PTE_UXN | PTE_RDONLY |</span>
<span class="quote">&gt;&gt; -                             PTE_PROT_NONE | PTE_WRITE | PTE_TYPE_MASK;</span>
<span class="quote">&gt;&gt; +                             PTE_PROT_NONE | PTE_WRITE | PTE_TYPE_MASK |</span>
<span class="quote">&gt;&gt; +                             PTE_CONTIG;</span>
<span class="quote">&gt;&gt;          /* preserve the hardware dirty information */</span>
<span class="quote">&gt;&gt;          if (pte_hw_dirty(pte))</span>
<span class="quote">&gt;&gt;                  newprot |= PTE_DIRTY;</span>
<span class="quote">&gt;&gt; @@ -513,6 +519,24 @@ static inline pmd_t pmd_modify(pmd_t pmd, pgprot_t newprot)</span>
<span class="quote">&gt;&gt;          return pte_pmd(pte_modify(pmd_pte(pmd), newprot));</span>
<span class="quote">&gt;&gt;   }</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; +static inline pte_t pte_modify_pfn(pte_t pte, unsigned long newpfn)</span>
<span class="quote">&gt;&gt; +{</span>
<span class="quote">&gt;&gt; +       const pteval_t mask = PHYS_MASK &amp; PAGE_MASK;</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +       pte_val(pte) = pfn_pte(newpfn, (pte_val(pte) &amp; ~mask));</span>
<span class="quote">&gt;&gt; +       return pte;</span>
<span class="quote">&gt;&gt; +}</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +#if CONFIG_PGTABLE_LEVELS &gt; 2</span>
<span class="quote">&gt;&gt; +static inline pmd_t pmd_modify_pfn(pmd_t pmd, unsigned long newpfn)</span>
<span class="quote">&gt;&gt; +{</span>
<span class="quote">&gt;&gt; +       const pmdval_t mask = PHYS_MASK &amp; PAGE_MASK;</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +       pmd = pfn_pmd(newpfn, (pmd_val(pmd) &amp; ~mask));</span>
<span class="quote">&gt;&gt; +       return pmd;</span>
<span class="quote">&gt;&gt; +}</span>
<span class="quote">&gt;&gt; +#endif</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt;   #ifdef CONFIG_ARM64_HW_AFDBM</span>
<span class="quote">&gt;&gt;   /*</span>
<span class="quote">&gt;&gt;    * Atomic pte/pmd modifications.</span>
<span class="quote">&gt;&gt; diff --git a/arch/arm64/mm/hugetlbpage.c b/arch/arm64/mm/hugetlbpage.c</span>
<span class="quote">&gt;&gt; index 383b03f..f5bbbbc 100644</span>
<span class="quote">&gt;&gt; --- a/arch/arm64/mm/hugetlbpage.c</span>
<span class="quote">&gt;&gt; +++ b/arch/arm64/mm/hugetlbpage.c</span>
<span class="quote">&gt;&gt; @@ -41,6 +41,155 @@ int pud_huge(pud_t pud)</span>
<span class="quote">&gt;&gt;   #endif</span>
<span class="quote">&gt;&gt;   }</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; +pte_t *huge_pte_alloc(struct mm_struct *mm,</span>
<span class="quote">&gt;&gt; +                       unsigned long addr, unsigned long sz)</span>
<span class="quote">&gt;&gt; +{</span>
<span class="quote">&gt;&gt; +       pgd_t *pgd;</span>
<span class="quote">&gt;&gt; +       pud_t *pud;</span>
<span class="quote">&gt;&gt; +       pte_t *pte = NULL;</span>
<span class="quote">&gt;&gt; +       int i;</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +       pgd = pgd_offset(mm, addr);</span>
<span class="quote">&gt;&gt; +       pud = pud_alloc(mm, pgd, addr);</span>
<span class="quote">&gt;&gt; +       if (pud) {</span>
<span class="quote">&gt;&gt; +               if (sz == PUD_SIZE) {</span>
<span class="quote">&gt;&gt; +                       pte = (pte_t *)pud;</span>
<span class="quote">&gt;&gt; +               } else if (sz == PMD_SIZE) {</span>
<span class="quote">&gt;&gt; +#ifdef CONFIG_ARCH_WANT_HUGE_PMD_SHARE</span>
<span class="quote">&gt;&gt; +                       if (pud_none(*pud))</span>
<span class="quote">&gt;&gt; +                               pte = huge_pmd_share(mm, addr, pud);</span>
<span class="quote">&gt;&gt; +                       else</span>
<span class="quote">&gt;&gt; +#endif</span>
<span class="quote">&gt;&gt; +                               pte = (pte_t *)pmd_alloc(mm, pud, addr);</span>
<span class="quote">&gt;&gt; +               } else if (sz == (PAGE_SIZE * CONTIG_PAGES)) {</span>
<span class="quote">&gt;&gt; +                       pmd_t *pmd = pmd_alloc(mm, pud, addr);</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +                       WARN_ON(addr &amp; (sz - 1));</span>
<span class="quote">&gt;&gt; +                       pte = pte_alloc_map(mm, NULL, pmd, addr);</span>
<span class="quote">&gt;&gt; +                       if (pte_present(*pte)) {</span>
<span class="quote">&gt;&gt; +                               unsigned long pfn;</span>
<span class="quote">&gt;&gt; +                               *pte = pte_mkcontig(*pte);</span>
<span class="quote">&gt;&gt; +                               pfn = pte_pfn(*pte);</span>
<span class="quote">&gt;&gt; +                               for (i = 0; i &lt; CONTIG_PAGES; i++) {</span>
<span class="quote">&gt;&gt; +                                       set_pte(&amp;pte[i],</span>
<span class="quote">&gt;&gt; +                                               pte_modify_pfn(*pte, pfn + i));</span>
<span class="quote">&gt;&gt; +                               }</span>
<span class="quote">&gt;&gt; +                       }</span>
<span class="quote">&gt;&gt; +#if CONFIG_PGTABLE_LEVELS &gt; 2</span>
<span class="quote">&gt;&gt; +               } else if (sz == (PMD_SIZE * CONTIG_PAGES)) {</span>
<span class="quote">&gt;&gt; +                       pmd_t *pmd;</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +                       pmd = pmd_alloc(mm, pud, addr);</span>
<span class="quote">&gt;&gt; +                       WARN_ON(addr &amp; (sz - 1));</span>
<span class="quote">&gt;&gt; +                       if (pmd &amp;&amp; pmd_present(*pmd)) {</span>
<span class="quote">&gt;&gt; +                               unsigned long pfn;</span>
<span class="quote">&gt;&gt; +                               pmd_t pmdval;</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +                               pmdval = *pmd = pmd_mkcontig(*pmd);</span>
<span class="quote">&gt;&gt; +                               pfn = pmd_pfn(*pmd);</span>
<span class="quote">&gt;&gt; +                               for (i = 0; i &lt; CONTIG_PAGES; i++) {</span>
<span class="quote">&gt;&gt; +                                       unsigned long newpfn = pfn +</span>
<span class="quote">&gt;&gt; +                                               (i &lt;&lt; (PMD_SHIFT - PAGE_SHIFT));</span>
<span class="quote">&gt;&gt; +                                       if (!pmd_present(pmd[i]))</span>
<span class="quote">&gt;&gt; +                                               atomic_long_inc(&amp;mm-&gt;nr_ptes);</span>
<span class="quote">&gt;&gt; +                                       set_pmd(&amp;pmd[i],</span>
<span class="quote">&gt;&gt; +                                               pmd_modify_pfn(pmdval, newpfn));</span>
<span class="quote">&gt;&gt; +                               }</span>
<span class="quote">&gt;&gt; +                       }</span>
<span class="quote">&gt;&gt; +                       return pmd;</span>
<span class="quote">&gt;&gt; +#endif</span>
<span class="quote">&gt;&gt; +               }</span>
<span class="quote">&gt;&gt; +       }</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +       return pte;</span>
<span class="quote">&gt;&gt; +}</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +pte_t *huge_pte_offset(struct mm_struct *mm, unsigned long addr)</span>
<span class="quote">&gt;&gt; +{</span>
<span class="quote">&gt;&gt; +       pgd_t *pgd;</span>
<span class="quote">&gt;&gt; +       pud_t *pud;</span>
<span class="quote">&gt;&gt; +       pmd_t *pmd = NULL;</span>
<span class="quote">&gt;&gt; +       pte_t *pte = NULL;</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +       pgd = pgd_offset(mm, addr);</span>
<span class="quote">&gt;&gt; +       if (pgd_present(*pgd)) {</span>
<span class="quote">&gt;&gt; +               pud = pud_offset(pgd, addr);</span>
<span class="quote">&gt;&gt; +               if (pud_present(*pud)) {</span>
<span class="quote">&gt;&gt; +                       if (pud_huge(*pud))</span>
<span class="quote">&gt;&gt; +                               return (pte_t *)pud;</span>
<span class="quote">&gt;&gt; +                       pmd = pmd_offset(pud, addr);</span>
<span class="quote">&gt;&gt; +                       if (pmd_present(*pmd)) {</span>
<span class="quote">&gt;&gt; +                               if (pmd_huge(*pmd))</span>
<span class="quote">&gt;&gt; +                                       return (pte_t *)pmd;</span>
<span class="quote">&gt;&gt; +                               pte = pte_offset_kernel(pmd, addr);</span>
<span class="quote">&gt;&gt; +                               if (pte_present(*pte) &amp;&amp; pte_contig(*pte)) {</span>
<span class="quote">&gt;&gt; +                                       pte = pte_offset_kernel(</span>
<span class="quote">&gt;&gt; +                                               pmd, (addr &amp; CONTIG_PTE_MASK));</span>
<span class="quote">&gt;&gt; +                                       return pte;</span>
<span class="quote">&gt;&gt; +                               }</span>
<span class="quote">&gt;&gt; +                       }</span>
<span class="quote">&gt;&gt; +               }</span>
<span class="quote">&gt;&gt; +       }</span>
<span class="quote">&gt;&gt; +       return (pte_t *) NULL;</span>
<span class="quote">&gt;&gt; +}</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +pte_t arch_make_huge_pte(pte_t entry, struct vm_area_struct *vma,</span>
<span class="quote">&gt;&gt; +                        struct page *page, int writable)</span>
<span class="quote">&gt;&gt; +{</span>
<span class="quote">&gt;&gt; +       size_t pagesize = huge_page_size(hstate_vma(vma));</span>
<span class="quote">&gt;&gt; +       pte_t nent = {0};</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +       if (pagesize == PUD_SIZE || pagesize == PMD_SIZE)</span>
<span class="quote">&gt;&gt; +               nent = entry;</span>
<span class="quote">&gt;&gt; +       else if (pagesize == (PAGE_SIZE * CONTIG_PAGES))</span>
<span class="quote">&gt;&gt; +               nent = pte_mkcontig(entry);</span>
<span class="quote">&gt;&gt; +#if CONFIG_PGTABLE_LEVELS &gt; 2</span>
<span class="quote">&gt;&gt; +       else if (pagesize == (PMD_SIZE * CONTIG_PAGES) ||</span>
<span class="quote">&gt;&gt; +                pagesize == (PUD_SIZE * CONTIG_PAGES))</span>
<span class="quote">&gt;&gt; +               nent = pmd_mkcontig(entry);</span>
<span class="quote">&gt;&gt; +#endif</span>
<span class="quote">&gt;&gt; +       else {</span>
<span class="quote">&gt;&gt; +               pr_warn(&quot;%s: unrecognized huge page size 0x%lx\n&quot;,</span>
<span class="quote">&gt;&gt; +                      __func__, pagesize);</span>
<span class="quote">&gt;&gt; +       }</span>
<span class="quote">&gt;&gt; +       return nent;</span>
<span class="quote">&gt;&gt; +}</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +pte_t pte_mkcontig(pte_t pte)</span>
<span class="quote">&gt;&gt; +{</span>
<span class="quote">&gt;&gt; +       pte = set_pte_bit(pte, __pgprot(PTE_CONTIG));</span>
<span class="quote">&gt;&gt; +       pte = set_pte_bit(pte, __pgprot(PTE_TYPE_PAGE));</span>
<span class="quote">&gt;&gt; +       return pte;</span>
<span class="quote">&gt;&gt; +}</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +pmd_t pmd_mkcontig(pmd_t pmd)</span>
<span class="quote">&gt;&gt; +{</span>
<span class="quote">&gt;&gt; +       pmd = __pmd(pmd_val(pmd) | PMD_SECT_CONTIG);</span>
<span class="quote">&gt;&gt; +       return pmd;</span>
<span class="quote">&gt;&gt; +}</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +struct page *follow_huge_pmd(struct mm_struct *mm, unsigned long address,</span>
<span class="quote">&gt;&gt; +               pmd_t *pmd, int write)</span>
<span class="quote">&gt;&gt; +{</span>
<span class="quote">&gt;&gt; +       struct page *page;</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +       page = pte_page(*(pte_t *)pmd);</span>
<span class="quote">&gt;&gt; +       if (page)</span>
<span class="quote">&gt;&gt; +               page += ((address &amp; ~PMD_MASK) &gt;&gt; PAGE_SHIFT);</span>
<span class="quote">&gt;&gt; +       return page;</span>
<span class="quote">&gt;&gt; +}</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +struct page *follow_huge_pud(struct mm_struct *mm, unsigned long address,</span>
<span class="quote">&gt;&gt; +               pud_t *pud, int write)</span>
<span class="quote">&gt;&gt; +{</span>
<span class="quote">&gt;&gt; +       struct page *page;</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +       page = pte_page(*(pte_t *)pud);</span>
<span class="quote">&gt;&gt; +       if (page)</span>
<span class="quote">&gt;&gt; +               page += ((address &amp; ~PUD_MASK) &gt;&gt; PAGE_SHIFT);</span>
<span class="quote">&gt;&gt; +       return page;</span>
<span class="quote">&gt;&gt; +}</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt;   static __init int setup_hugepagesz(char *opt)</span>
<span class="quote">&gt;&gt;   {</span>
<span class="quote">&gt;&gt;          unsigned long ps = memparse(opt, &amp;opt);</span>
<span class="quote">&gt;&gt; @@ -48,10 +197,24 @@ static __init int setup_hugepagesz(char *opt)</span>
<span class="quote">&gt;&gt;                  hugetlb_add_hstate(PMD_SHIFT - PAGE_SHIFT);</span>
<span class="quote">&gt;&gt;          } else if (ps == PUD_SIZE) {</span>
<span class="quote">&gt;&gt;                  hugetlb_add_hstate(PUD_SHIFT - PAGE_SHIFT);</span>
<span class="quote">&gt;&gt; +       } else if (ps == (PAGE_SIZE * CONTIG_PAGES)) {</span>
<span class="quote">&gt;&gt; +               hugetlb_add_hstate(CONTIG_SHIFT);</span>
<span class="quote">&gt;&gt; +       } else if (ps == (PMD_SIZE * CONTIG_PAGES)) {</span>
<span class="quote">&gt;&gt; +               hugetlb_add_hstate((PMD_SHIFT + CONTIG_SHIFT) - PAGE_SHIFT);</span>
<span class="quote">&gt;&gt;          } else {</span>
<span class="quote">&gt;&gt; -               pr_err(&quot;hugepagesz: Unsupported page size %lu M\n&quot;, ps &gt;&gt; 20);</span>
<span class="quote">&gt;&gt; +               pr_err(&quot;hugepagesz: Unsupported page size %lu K\n&quot;, ps &gt;&gt; 10);</span>
<span class="quote">&gt;&gt;                  return 0;</span>
<span class="quote">&gt;&gt;          }</span>
<span class="quote">&gt;&gt;          return 1;</span>
<span class="quote">&gt;&gt;   }</span>
<span class="quote">&gt;&gt;   __setup(&quot;hugepagesz=&quot;, setup_hugepagesz);</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +#ifdef CONFIG_ARM64_64K_PAGES</span>
<span class="quote">&gt;&gt; +static __init int add_default_hugepagesz(void)</span>
<span class="quote">&gt;&gt; +{</span>
<span class="quote">&gt;&gt; +       if (size_to_hstate(CONTIG_PAGES * PAGE_SIZE) == NULL)</span>
<span class="quote">&gt;&gt; +               hugetlb_add_hstate(CONTIG_SHIFT);</span>
<span class="quote">&gt;&gt; +       return 0;</span>
<span class="quote">&gt;&gt; +}</span>
<span class="quote">&gt;&gt; +arch_initcall(add_default_hugepagesz);</span>
<span class="quote">&gt;&gt; +#endif</span>
<span class="quote">&gt;&gt; --</span>
<span class="quote">&gt;&gt; 2.1.2</span>
<span class="quote">&gt;&gt;</span>

--
To unsubscribe from this list: send the line &quot;unsubscribe linux-kernel&quot; in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
Please read the FAQ at  http://www.tux.org/lkml/
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=64911">Steve Capper</a> - Sept. 25, 2015, 5:53 p.m.</div>
<pre class="content">
On 21 September 2015 at 09:44, David Woods &lt;dwoods@ezchip.com&gt; wrote:
<span class="quote">&gt;</span>
<span class="quote">&gt; Steve,</span>

Hi Dave,
<span class="quote">
&gt;</span>
<span class="quote">&gt; Thanks for your review and comments.  I take your points about the 16k</span>
<span class="quote">&gt; granule - it&#39;s helpful to know that support is in the works. However, I&#39;m</span>
<span class="quote">&gt; not sure I agree with your reading of section 4.4.2. It&#39;s clear that for 16k</span>
<span class="quote">&gt; granules, the number of contiguous pages is different for the PTE and PMD</span>
<span class="quote">&gt; levels.  But I don&#39;t see anywhere it says that for 4K and 64K that the</span>
<span class="quote">&gt; contig bit is not supported at the PMD level - just that the number of</span>
<span class="quote">&gt; contiguous pages is the same at each level.</span>

Many apologies, I appear to have led you down the garden path there.
Having double checked at ARM, the valid contiguous page sizes are indeed:
4K granule:
16 x ptes = 64K
16 x pmds = 32M
16 x puds = 16G

16K granule:
128 x ptes = 2M
32 x pmds = 1G

64K granule:
32 x ptes = 2M
32 x pmds = 16G
<span class="quote">
&gt;</span>
<span class="quote">&gt; I tried using the tarmac trace module of the ARM simulator to support this</span>
<span class="quote">&gt; idea by turning on MMU tracing.  Using 4k granule, I created 64k and 32m</span>
<span class="quote">&gt; pages and touched each location in the page.  In both cases, the trace</span>
<span class="quote">&gt; recorded just one TLB fill (rather than the 16 you&#39;d expect if the</span>
<span class="quote">&gt; contiguous bit were being ignored) and it indicated the expected page size.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; 1817498494 clk cpu2 TLB FILL cpu2.S1TLB 64K 0x2000000000_NS vmid=0, nG</span>
<span class="quote">&gt; asid=303:0x08fa360000_NS Normal InnerShareable Inner=WriteBackWriteAllocate</span>
<span class="quote">&gt; Outer=WriteBackWriteAllocate xn=0 pxn=1 ContiguousHint=1</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; 1263366314 clk cpu2 TLB FILL cpu2.UTLB 32M 0x2000000000_NS vmid=0, nG</span>
<span class="quote">&gt; asid=300:0x08f6000000_NS Normal InnerShareable Inner=WriteBackWriteAllocate</span>
<span class="quote">&gt; Outer=WriteBackWriteAllocate xn=0 pxn=1 ContiguousHint=1</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; I&#39;ll try this with a 64k granule next.  I&#39;m not sure what will happen with</span>
<span class="quote">&gt; 16G pages since we are using an A53 model which I don&#39;t think supports such</span>
<span class="quote">&gt; large pages.</span>

The Cortex-A53 supported TLB sizes can be found in the TRM:
http://infocenter.arm.com/help/topic/com.arm.doc.ddi0500f/Chddiifa.html

My understanding is that the core is allowed to ignore the contiguous
bit if it doesn&#39;t support the particular TLB entry size, or substitute
in a slightly smaller TLB entry than hinted possible. Anyway, do give
it a go :-).

Cheers,
--
Steve
--
To unsubscribe from this list: send the line &quot;unsubscribe linux-kernel&quot; in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
Please read the FAQ at  http://www.tux.org/lkml/
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=142331">David Woods</a> - Oct. 19, 2015, 6:43 p.m.</div>
<pre class="content">
On 09/16/2015 10:06 AM, Steve Capper wrote:
<span class="quote">&gt; Hi David,</span>
<span class="quote">&gt; Some initial comments below.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; Cheers,</span>
<span class="quote">&gt; -- Steve On Tue, Sep 15, 2015 at 02:01:57PM -0400, David Woods wrote:</span>
<span class="quote">&gt;&gt; &gt;The arm64 MMU supports a Contiguous bit which is a hint that the TTE</span>
<span class="quote">&gt;&gt; &gt;is one of a set of contiguous entries which can be cached in a single</span>
<span class="quote">&gt;&gt; &gt;TLB entry.  Supporting this bit adds new intermediate huge page sizes.</span>
<span class="quote">&gt;&gt; &gt;</span>
<span class="quote">&gt;&gt; &gt;The set of huge page sizes available depends on the base page size.</span>
<span class="quote">&gt;&gt; &gt;Without using contiguous pages the huge page sizes are as follows.</span>
<span class="quote">&gt;&gt; &gt;</span>
<span class="quote">&gt;&gt; &gt;  4KB:   2MB  1GB</span>
<span class="quote">&gt;&gt; &gt;64KB: 512MB  4TB</span>
<span class="quote">&gt;&gt; &gt;</span>
<span class="quote">&gt;&gt; &gt;With 4KB pages, the contiguous bit groups together sets of 16 pages</span>
<span class="quote">&gt;&gt; &gt;and with 64KB pages it groups sets of 32 pages.  This enables two new</span>
<span class="quote">&gt;&gt; &gt;huge page sizes in each case, so that the full set of available sizes</span>
<span class="quote">&gt;&gt; &gt;is as follows.</span>
<span class="quote">&gt;&gt; &gt;</span>
<span class="quote">&gt;&gt; &gt;  4KB:  64KB   2MB  32MB  1GB</span>
<span class="quote">&gt;&gt; &gt;64KB:   2MB 512MB  16GB  4TB</span>
<span class="quote">&gt;&gt; &gt;</span>
<span class="quote">&gt;&gt; &gt;If the base page size is set to 64KB then 2MB pages are enabled by</span>
<span class="quote">&gt;&gt; &gt;default.  It is possible in the future to make 2MB the default huge</span>
<span class="quote">&gt;&gt; &gt;page size for both 4KB and 64KB pages.</span>
<span class="quote">&gt;&gt; &gt;</span>
<span class="quote">&gt;&gt; &gt;Signed-off-by: David Woods&lt;dwoods@ezchip.com&gt;</span>
<span class="quote">&gt;&gt; &gt;Reviewed-by: Chris Metcalf&lt;cmetcalf@ezchip.com&gt;</span>
<span class="quote">&gt;&gt; &gt;---</span>
<span class="quote">&gt;&gt; &gt;  arch/arm64/Kconfig                     |   3 -</span>
<span class="quote">&gt;&gt; &gt;  arch/arm64/include/asm/hugetlb.h       |   4 +</span>
<span class="quote">&gt;&gt; &gt;  arch/arm64/include/asm/pgtable-hwdef.h |  15 +++</span>
<span class="quote">&gt;&gt; &gt;  arch/arm64/include/asm/pgtable.h       |  30 +++++-</span>
<span class="quote">&gt;&gt; &gt;  arch/arm64/mm/hugetlbpage.c            | 165 ++++++++++++++++++++++++++++++++-</span>
<span class="quote">&gt;&gt; &gt;  5 files changed, 210 insertions(+), 7 deletions(-)</span>
<span class="quote">&gt;&gt; &gt;</span>
<span class="quote">&gt;&gt; &gt;</span>
<span class="quote">&gt;&gt; &gt;diff --git a/arch/arm64/include/asm/pgtable-hwdef.h b/arch/arm64/include/asm/pgtable-hwdef.h</span>
<span class="quote">&gt;&gt; &gt;index 24154b0..da73243 100644</span>
<span class="quote">&gt;&gt; &gt;--- a/arch/arm64/include/asm/pgtable-hwdef.h</span>
<span class="quote">&gt;&gt; &gt;+++ b/arch/arm64/include/asm/pgtable-hwdef.h</span>
<span class="quote">&gt;&gt; &gt;@@ -55,6 +55,19 @@</span>
<span class="quote">&gt;&gt; &gt;  #define SECTION_MASK		(~(SECTION_SIZE-1))</span>
<span class="quote">&gt;&gt; &gt;  </span>
<span class="quote">&gt;&gt; &gt;  /*</span>
<span class="quote">&gt;&gt; &gt;+ * Contiguous large page definitions.</span>
<span class="quote">&gt;&gt; &gt;+ */</span>
<span class="quote">&gt;&gt; &gt;+#ifdef CONFIG_ARM64_64K_PAGES</span>
<span class="quote">&gt;&gt; &gt;+#define	CONTIG_SHIFT		5</span>
<span class="quote">&gt;&gt; &gt;+#define CONTIG_PAGES		32</span>
<span class="quote">&gt;&gt; &gt;+#else</span>
<span class="quote">&gt;&gt; &gt;+#define	CONTIG_SHIFT		4</span>
<span class="quote">&gt;&gt; &gt;+#define CONTIG_PAGES		16</span>
<span class="quote">&gt;&gt; &gt;+#endif</span>
<span class="quote">&gt;&gt; &gt;+#define	CONTIG_PTE_SIZE		(CONTIG_PAGES * PAGE_SIZE)</span>
<span class="quote">&gt;&gt; &gt;+#define	CONTIG_PTE_MASK		(~(CONTIG_PTE_SIZE - 1))</span>
<span class="quote">&gt; Careful here, CONTIG_PAGES should really be CONTIG_PTES.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; If support is added for a 16KB granule case we are allowed:</span>
<span class="quote">&gt; 128 x 16KB pages (ptes) to make a 2MB huge page, or</span>
<span class="quote">&gt; 32 x 32MB blocks (pmds) to make a 1GB huge page.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; i.e we CONTIG_PTES != CONTIG_PMDs</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; For 4KB or 64KB pages we are only allowed contiguous pte&#39;s so</span>
<span class="quote">&gt; CONTIG_PMDS == 0 in these cases.</span>


Steve,

Thanks for pointing this out.  I changed it to allow for different
values for CONT_PTES and CONT_PMDS.  As you say, that should
make it easier to merge with the 16K granule support.
<span class="quote">
&gt;&gt; &gt;+</span>
<span class="quote">&gt;&gt; &gt;+/*</span>
<span class="quote">&gt;&gt; &gt;   * Hardware page table definitions.</span>
<span class="quote">&gt;&gt; &gt;   *</span>
<span class="quote">&gt;&gt; &gt;   * Level 1 descriptor (PUD).</span>
<span class="quote">&gt;&gt; &gt;@@ -83,6 +96,7 @@</span>
<span class="quote">&gt;&gt; &gt;  #define PMD_SECT_S		(_AT(pmdval_t, 3) &lt;&lt; 8)</span>
<span class="quote">&gt;&gt; &gt;  #define PMD_SECT_AF		(_AT(pmdval_t, 1) &lt;&lt; 10)</span>
<span class="quote">&gt;&gt; &gt;  #define PMD_SECT_NG		(_AT(pmdval_t, 1) &lt;&lt; 11)</span>
<span class="quote">&gt;&gt; &gt;+#define PMD_SECT_CONTIG		(_AT(pmdval_t, 1) &lt;&lt; 52)</span>
<span class="quote">&gt;&gt; &gt;  #define PMD_SECT_PXN		(_AT(pmdval_t, 1) &lt;&lt; 53)</span>
<span class="quote">&gt;&gt; &gt;  #define PMD_SECT_UXN		(_AT(pmdval_t, 1) &lt;&lt; 54)</span>
<span class="quote">&gt;&gt; &gt;  </span>
<span class="quote">&gt;&gt; &gt;@@ -105,6 +119,7 @@</span>
<span class="quote">&gt;&gt; &gt;  #define PTE_AF			(_AT(pteval_t, 1) &lt;&lt; 10)	/* Access Flag */</span>
<span class="quote">&gt;&gt; &gt;  #define PTE_NG			(_AT(pteval_t, 1) &lt;&lt; 11)	/* nG */</span>
<span class="quote">&gt;&gt; &gt;  #define PTE_DBM			(_AT(pteval_t, 1) &lt;&lt; 51)	/* Dirty Bit Management */</span>
<span class="quote">&gt;&gt; &gt;+#define PTE_CONTIG		(_AT(pteval_t, 1) &lt;&lt; 52)	/* Contiguous */</span>
<span class="quote">&gt;&gt; &gt;  #define PTE_PXN			(_AT(pteval_t, 1) &lt;&lt; 53)	/* Privileged XN */</span>
<span class="quote">&gt;&gt; &gt;  #define PTE_UXN			(_AT(pteval_t, 1) &lt;&lt; 54)	/* User XN */</span>
<span class="quote">&gt;&gt; &gt;  </span>
<span class="quote">&gt;&gt; &gt;diff --git a/arch/arm64/include/asm/pgtable.h b/arch/arm64/include/asm/pgtable.h</span>
<span class="quote">&gt;&gt; &gt;index 6900b2d9..df5ec64 100644</span>
<span class="quote">&gt;&gt; &gt;--- a/arch/arm64/include/asm/pgtable.h</span>
<span class="quote">&gt;&gt; &gt;+++ b/arch/arm64/include/asm/pgtable.h</span>
<span class="quote">&gt;&gt; &gt;@@ -144,6 +144,7 @@ extern struct page *empty_zero_page;</span>
<span class="quote">&gt;&gt; &gt;  #define pte_special(pte)	(!!(pte_val(pte) &amp; PTE_SPECIAL))</span>
<span class="quote">&gt;&gt; &gt;  #define pte_write(pte)		(!!(pte_val(pte) &amp; PTE_WRITE))</span>
<span class="quote">&gt;&gt; &gt;  #define pte_exec(pte)		(!(pte_val(pte) &amp; PTE_UXN))</span>
<span class="quote">&gt;&gt; &gt;+#define pte_contig(pte)		(!!(pte_val(pte) &amp; PTE_CONTIG))</span>
<span class="quote">&gt;&gt; &gt;  </span>
<span class="quote">&gt;&gt; &gt;  #ifdef CONFIG_ARM64_HW_AFDBM</span>
<span class="quote">&gt;&gt; &gt;  #define pte_hw_dirty(pte)	(!(pte_val(pte) &amp; PTE_RDONLY))</span>
<span class="quote">&gt;&gt; &gt;@@ -206,6 +207,9 @@ static inline pte_t pte_mkspecial(pte_t pte)</span>
<span class="quote">&gt;&gt; &gt;  	return set_pte_bit(pte, __pgprot(PTE_SPECIAL));</span>
<span class="quote">&gt;&gt; &gt;  }</span>
<span class="quote">&gt;&gt; &gt;  </span>
<span class="quote">&gt;&gt; &gt;+extern pte_t pte_mkcontig(pte_t pte);</span>
<span class="quote">&gt;&gt; &gt;+extern pmd_t pmd_mkcontig(pmd_t pmd);</span>
<span class="quote">&gt;&gt; &gt;+</span>
<span class="quote">&gt;&gt; &gt;  static inline void set_pte(pte_t *ptep, pte_t pte)</span>
<span class="quote">&gt;&gt; &gt;  {</span>
<span class="quote">&gt;&gt; &gt;  	*ptep = pte;</span>
<span class="quote">&gt;&gt; &gt;@@ -275,7 +279,7 @@ static inline void set_pte_at(struct mm_struct *mm, unsigned long addr,</span>
<span class="quote">&gt;&gt; &gt;  /*</span>
<span class="quote">&gt;&gt; &gt;   * Hugetlb definitions.</span>
<span class="quote">&gt;&gt; &gt;   */</span>
<span class="quote">&gt;&gt; &gt;-#define HUGE_MAX_HSTATE		2</span>
<span class="quote">&gt;&gt; &gt;+#define HUGE_MAX_HSTATE		((2 * CONFIG_PGTABLE_LEVELS) - 1)</span>
<span class="quote">&gt;&gt; &gt;  #define HPAGE_SHIFT		PMD_SHIFT</span>
<span class="quote">&gt;&gt; &gt;  #define HPAGE_SIZE		(_AC(1, UL) &lt;&lt; HPAGE_SHIFT)</span>
<span class="quote">&gt;&gt; &gt;  #define HPAGE_MASK		(~(HPAGE_SIZE - 1))</span>
<span class="quote">&gt;&gt; &gt;@@ -372,7 +376,8 @@ extern pgprot_t phys_mem_access_prot(struct file *file, unsigned long pfn,</span>
<span class="quote">&gt;&gt; &gt;  #define pmd_none(pmd)		(!pmd_val(pmd))</span>
<span class="quote">&gt;&gt; &gt;  #define pmd_present(pmd)	(pmd_val(pmd))</span>
<span class="quote">&gt;&gt; &gt;  </span>
<span class="quote">&gt;&gt; &gt;-#define pmd_bad(pmd)		(!(pmd_val(pmd) &amp; 2))</span>
<span class="quote">&gt;&gt; &gt;+#define pmd_bad(pmd)		(!(pmd_val(pmd) &amp; \</span>
<span class="quote">&gt;&gt; &gt;+				   (PMD_TABLE_BIT | PMD_SECT_CONTIG)))</span>
<span class="quote">&gt; I&#39;m not sure about this. A contiguous pmd (which will be a block descriptor)</span>
<span class="quote">&gt; will no longer be bad?</span>

Right, this was not correct.  The problem was that on process exit,
it was only clearing the first PTE in each contiguous block.  The other
15 (or 31) would still be non-zero and get reported as &quot;bad&quot; on the
console.  Fixing huge_ptep_get_and_clear() solved that problem and
made this hack to pmd_bad() unnecessary.
<span class="quote">
&gt;</span>
<span class="quote">&gt;&gt; &gt;  </span>
<span class="quote">&gt;&gt; &gt;  #define pmd_table(pmd)		((pmd_val(pmd) &amp; PMD_TYPE_MASK) == \</span>
<span class="quote">&gt;&gt; &gt;  				 PMD_TYPE_TABLE)</span>
<span class="quote">&gt;&gt; &gt;@@ -500,7 +505,8 @@ static inline pud_t *pud_offset(pgd_t *pgd, unsigned long addr)</span>
<span class="quote">&gt;&gt; &gt;  static inline pte_t pte_modify(pte_t pte, pgprot_t newprot)</span>
<span class="quote">&gt;&gt; &gt;  {</span>
<span class="quote">&gt;&gt; &gt;  	const pteval_t mask = PTE_USER | PTE_PXN | PTE_UXN | PTE_RDONLY |</span>
<span class="quote">&gt;&gt; &gt;-			      PTE_PROT_NONE | PTE_WRITE | PTE_TYPE_MASK;</span>
<span class="quote">&gt;&gt; &gt;+			      PTE_PROT_NONE | PTE_WRITE | PTE_TYPE_MASK |</span>
<span class="quote">&gt;&gt; &gt;+			      PTE_CONTIG;</span>
<span class="quote">&gt;&gt; &gt;  	/* preserve the hardware dirty information */</span>
<span class="quote">&gt;&gt; &gt;  	if (pte_hw_dirty(pte))</span>
<span class="quote">&gt;&gt; &gt;  		newprot |= PTE_DIRTY;</span>
<span class="quote">&gt;&gt; &gt;@@ -513,6 +519,24 @@ static inline pmd_t pmd_modify(pmd_t pmd, pgprot_t newprot)</span>
<span class="quote">&gt;&gt; &gt;  	return pte_pmd(pte_modify(pmd_pte(pmd), newprot));</span>
<span class="quote">&gt;&gt; &gt;  }</span>
<span class="quote">&gt;&gt; &gt;  </span>
<span class="quote">&gt;&gt; &gt;+static inline pte_t pte_modify_pfn(pte_t pte, unsigned long newpfn)</span>
<span class="quote">&gt;&gt; &gt;+{</span>
<span class="quote">&gt;&gt; &gt;+	const pteval_t mask = PHYS_MASK &amp; PAGE_MASK;</span>
<span class="quote">&gt;&gt; &gt;+</span>
<span class="quote">&gt;&gt; &gt;+	pte_val(pte) = pfn_pte(newpfn, (pte_val(pte) &amp; ~mask));</span>
<span class="quote">&gt;&gt; &gt;+	return pte;</span>
<span class="quote">&gt;&gt; &gt;+}</span>
<span class="quote">&gt;&gt; &gt;+</span>
<span class="quote">&gt;&gt; &gt;+#if CONFIG_PGTABLE_LEVELS &gt; 2</span>
<span class="quote">&gt;&gt; &gt;+static inline pmd_t pmd_modify_pfn(pmd_t pmd, unsigned long newpfn)</span>
<span class="quote">&gt;&gt; &gt;+{</span>
<span class="quote">&gt;&gt; &gt;+	const pmdval_t mask = PHYS_MASK &amp; PAGE_MASK;</span>
<span class="quote">&gt;&gt; &gt;+</span>
<span class="quote">&gt;&gt; &gt;+	pmd = pfn_pmd(newpfn, (pmd_val(pmd) &amp; ~mask));</span>
<span class="quote">&gt;&gt; &gt;+	return pmd;</span>
<span class="quote">&gt;&gt; &gt;+}</span>
<span class="quote">&gt;&gt; &gt;+#endif</span>
<span class="quote">&gt; We can probably get rid of these two functions, please see below.</span>

Ok, I&#39;ve changed it as you suggested.
<span class="quote">
&gt; &gt;diff --git a/arch/arm64/mm/hugetlbpage.c b/arch/arm64/mm/hugetlbpage.c</span>
<span class="quote">&gt; &gt;index 383b03f..f5bbbbc 100644</span>
<span class="quote">&gt; &gt;--- a/arch/arm64/mm/hugetlbpage.c</span>
<span class="quote">&gt; &gt;+++ b/arch/arm64/mm/hugetlbpage.c</span>
<span class="quote">&gt; &gt;@@ -41,6 +41,155 @@ int pud_huge(pud_t pud)</span>
<span class="quote">&gt; &gt;  #endif</span>
<span class="quote">&gt; &gt;  }</span>
<span class="quote">&gt; &gt;  </span>
<span class="quote">&gt; &gt;+pte_t *huge_pte_alloc(struct mm_struct *mm,</span>
<span class="quote">&gt; &gt;+			unsigned long addr, unsigned long sz)</span>
<span class="quote">&gt; &gt;+{</span>
<span class="quote">&gt; &gt;+	pgd_t *pgd;</span>
<span class="quote">&gt; &gt;+	pud_t *pud;</span>
<span class="quote">&gt; &gt;+	pte_t *pte = NULL;</span>
<span class="quote">&gt; &gt;+	int i;</span>
<span class="quote">&gt; &gt;+</span>
<span class="quote">&gt; &gt;+	pgd = pgd_offset(mm, addr);</span>
<span class="quote">&gt; &gt;+	pud = pud_alloc(mm, pgd, addr);</span>
<span class="quote">&gt; &gt;+	if (pud) {</span>
<span class="quote">&gt; &gt;+		if (sz == PUD_SIZE) {</span>
<span class="quote">&gt; &gt;+			pte = (pte_t *)pud;</span>
<span class="quote">&gt; &gt;+		} else if (sz == PMD_SIZE) {</span>
<span class="quote">&gt; &gt;+#ifdef CONFIG_ARCH_WANT_HUGE_PMD_SHARE</span>
<span class="quote">&gt; &gt;+			if (pud_none(*pud))</span>
<span class="quote">&gt; &gt;+				pte = huge_pmd_share(mm, addr, pud);</span>
<span class="quote">&gt; &gt;+			else</span>
<span class="quote">&gt; &gt;+#endif</span>
<span class="quote">&gt; &gt;+				pte = (pte_t *)pmd_alloc(mm, pud, addr);</span>
<span class="quote">&gt; &gt;+		} else if (sz == (PAGE_SIZE * CONTIG_PAGES)) {</span>
<span class="quote">&gt; &gt;+			pmd_t *pmd = pmd_alloc(mm, pud, addr);</span>
<span class="quote">&gt; &gt;+</span>
<span class="quote">&gt; &gt;+			WARN_ON(addr &amp; (sz - 1));</span>
<span class="quote">&gt; &gt;+			pte = pte_alloc_map(mm, NULL, pmd, addr);</span>
<span class="quote">&gt; &gt;+			if (pte_present(*pte)) {</span>
<span class="quote">&gt; &gt;+				unsigned long pfn;</span>
<span class="quote">&gt; &gt;+				*pte = pte_mkcontig(*pte);</span>
<span class="quote">&gt; &gt;+				pfn = pte_pfn(*pte);</span>
<span class="quote">&gt; &gt;+				for (i = 0; i &lt; CONTIG_PAGES; i++) {</span>
<span class="quote">&gt; &gt;+					set_pte(&amp;pte[i],</span>
<span class="quote">&gt; &gt;+						pte_modify_pfn(*pte, pfn + i));</span>
<span class="quote">&gt; &gt;+				}</span>
<span class="quote">&gt; &gt;+			}</span>
<span class="quote">&gt; &gt;+#if CONFIG_PGTABLE_LEVELS &gt; 2</span>
<span class="quote">&gt; &gt;+		} else if (sz == (PMD_SIZE * CONTIG_PAGES)) {</span>
<span class="quote">&gt; &gt;+			pmd_t *pmd;</span>
<span class="quote">&gt; &gt;+</span>
<span class="quote">&gt; &gt;+			pmd = pmd_alloc(mm, pud, addr);</span>
<span class="quote">&gt; &gt;+			WARN_ON(addr &amp; (sz - 1));</span>
<span class="quote">&gt; &gt;+			if (pmd &amp;&amp; pmd_present(*pmd)) {</span>
<span class="quote">&gt; &gt;+				unsigned long pfn;</span>
<span class="quote">&gt; &gt;+				pmd_t pmdval;</span>
<span class="quote">&gt; &gt;+</span>
<span class="quote">&gt; &gt;+				pmdval = *pmd = pmd_mkcontig(*pmd);</span>
<span class="quote">&gt; &gt;+				pfn = pmd_pfn(*pmd);</span>
<span class="quote">&gt; &gt;+				for (i = 0; i &lt; CONTIG_PAGES; i++) {</span>
<span class="quote">&gt; &gt;+					unsigned long newpfn = pfn +</span>
<span class="quote">&gt; &gt;+						(i &lt;&lt; (PMD_SHIFT - PAGE_SHIFT));</span>
<span class="quote">&gt; &gt;+					if (!pmd_present(pmd[i]))</span>
<span class="quote">&gt; &gt;+						atomic_long_inc(&amp;mm-&gt;nr_ptes);</span>
<span class="quote">&gt; &gt;+					set_pmd(&amp;pmd[i],</span>
<span class="quote">&gt; &gt;+						pmd_modify_pfn(pmdval, newpfn));</span>
<span class="quote">&gt; &gt;+				}</span>
<span class="quote">&gt; &gt;+			}</span>
<span class="quote">&gt; &gt;+			return pmd;</span>
<span class="quote">&gt; &gt;+#endif</span>
<span class="quote">&gt; &gt;+		}</span>
<span class="quote">&gt; &gt;+	}</span>
<span class="quote">&gt; &gt;+</span>
<span class="quote">&gt; &gt;+	return pte;</span>
<span class="quote">&gt; &gt;+}</span>
<span class="quote">&gt; Why are we writing pte&#39;s/pmd&#39;s in the huge_pte_alloc function?</span>
<span class="quote">&gt; What happened to set_huge_pte_at?</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; Also, rather than call pte_modify_pfn, I would recommend something like:</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; 	int loop;</span>
<span class="quote">&gt; 	unsigned long pfn = pte_pfn(pte);</span>
<span class="quote">&gt; 	pgprot_t hugeprot = __pgprot(pte_val(pfn_pte(pfn, 0) ^ pte_val(pte)));</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; 	for (loop = 0; loop &lt; CONTIG_PTES; loop++) {</span>
<span class="quote">&gt; 		set_pte_at(mm, addr, ptep++, pfn_pte(pfn++, hugeprot));</span>
<span class="quote">&gt; 		addr += PAGE_SIZE;</span>
<span class="quote">&gt; 	}</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; i.e. extract a pgprot_t and combine with the pfn in the loop rather than</span>
<span class="quote">&gt; calling out.</span>

I agree, it&#39;s better this way.  I moved all this stuff out of 
huge_pte_alloc()
and into set_huge_pte_at().
<span class="quote">
&gt;&gt; &gt;+}</span>
<span class="quote">&gt;&gt; &gt;+</span>
<span class="quote">&gt;&gt; &gt;+pte_t pte_mkcontig(pte_t pte)</span>
<span class="quote">&gt;&gt; &gt;+{</span>
<span class="quote">&gt;&gt; &gt;+	pte = set_pte_bit(pte, __pgprot(PTE_CONTIG));</span>
<span class="quote">&gt;&gt; &gt;+	pte = set_pte_bit(pte, __pgprot(PTE_TYPE_PAGE));</span>
<span class="quote">&gt;&gt; &gt;+	return pte;</span>
<span class="quote">&gt;&gt; &gt;+}</span>
<span class="quote">&gt;&gt; &gt;+</span>
<span class="quote">&gt;&gt; &gt;+pmd_t pmd_mkcontig(pmd_t pmd)</span>
<span class="quote">&gt;&gt; &gt;+{</span>
<span class="quote">&gt;&gt; &gt;+	pmd = __pmd(pmd_val(pmd) | PMD_SECT_CONTIG);</span>
<span class="quote">&gt;&gt; &gt;+	return pmd;</span>
<span class="quote">&gt;&gt; &gt;+}</span>
<span class="quote">&gt; Can these be folded into arch_make_huge_pte?</span>

I left these as separate functions but made them inline in pgtable.h
to follow Jeremy Linton&#39;s patch for the kernel linear mappings.
<span class="quote">
&gt;</span>
<span class="quote">&gt;&gt; &gt;+</span>
<span class="quote">&gt;&gt; &gt;+struct page *follow_huge_pmd(struct mm_struct *mm, unsigned long address,</span>
<span class="quote">&gt;&gt; &gt;+		pmd_t *pmd, int write)</span>
<span class="quote">&gt;&gt; &gt;+{</span>
<span class="quote">&gt;&gt; &gt;+	struct page *page;</span>
<span class="quote">&gt;&gt; &gt;+</span>
<span class="quote">&gt;&gt; &gt;+	page = pte_page(*(pte_t *)pmd);</span>
<span class="quote">&gt;&gt; &gt;+	if (page)</span>
<span class="quote">&gt;&gt; &gt;+		page += ((address &amp; ~PMD_MASK) &gt;&gt; PAGE_SHIFT);</span>
<span class="quote">&gt;&gt; &gt;+	return page;</span>
<span class="quote">&gt;&gt; &gt;+}</span>
<span class="quote">&gt; Do we need to think about contiguous pmd&#39;s here?</span>
<span class="quote">&gt; It may be worth implementing follow_huge_addr?</span>

It turned out to be unnecessary to override follow_huge_pmd/pud.

-Dave



--
To unsubscribe from this list: send the line &quot;unsubscribe linux-kernel&quot; in
the body of a message to majordomo@vger.kernel.org
More majordomo info at  http://vger.kernel.org/majordomo-info.html
Please read the FAQ at  http://www.tux.org/lkml/
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/arch/arm64/Kconfig b/arch/arm64/Kconfig</span>
<span class="p_header">index 7d95663..8310e38 100644</span>
<span class="p_header">--- a/arch/arm64/Kconfig</span>
<span class="p_header">+++ b/arch/arm64/Kconfig</span>
<span class="p_chunk">@@ -447,9 +447,6 @@</span> <span class="p_context"> config HW_PERF_EVENTS</span>
 config SYS_SUPPORTS_HUGETLBFS
 	def_bool y
 
<span class="p_del">-config ARCH_WANT_GENERAL_HUGETLB</span>
<span class="p_del">-	def_bool y</span>
<span class="p_del">-</span>
 config ARCH_WANT_HUGE_PMD_SHARE
 	def_bool y if !ARM64_64K_PAGES
 
<span class="p_header">diff --git a/arch/arm64/include/asm/hugetlb.h b/arch/arm64/include/asm/hugetlb.h</span>
<span class="p_header">index bb4052e..e5af553 100644</span>
<span class="p_header">--- a/arch/arm64/include/asm/hugetlb.h</span>
<span class="p_header">+++ b/arch/arm64/include/asm/hugetlb.h</span>
<span class="p_chunk">@@ -97,4 +97,8 @@</span> <span class="p_context"> static inline void arch_clear_hugepage_flags(struct page *page)</span>
 	clear_bit(PG_dcache_clean, &amp;page-&gt;flags);
 }
 
<span class="p_add">+extern pte_t arch_make_huge_pte(pte_t entry, struct vm_area_struct *vma,</span>
<span class="p_add">+				struct page *page, int writable);</span>
<span class="p_add">+#define arch_make_huge_pte arch_make_huge_pte</span>
<span class="p_add">+</span>
 #endif /* __ASM_HUGETLB_H */
<span class="p_header">diff --git a/arch/arm64/include/asm/pgtable-hwdef.h b/arch/arm64/include/asm/pgtable-hwdef.h</span>
<span class="p_header">index 24154b0..da73243 100644</span>
<span class="p_header">--- a/arch/arm64/include/asm/pgtable-hwdef.h</span>
<span class="p_header">+++ b/arch/arm64/include/asm/pgtable-hwdef.h</span>
<span class="p_chunk">@@ -55,6 +55,19 @@</span> <span class="p_context"></span>
 #define SECTION_MASK		(~(SECTION_SIZE-1))
 
 /*
<span class="p_add">+ * Contiguous large page definitions.</span>
<span class="p_add">+ */</span>
<span class="p_add">+#ifdef CONFIG_ARM64_64K_PAGES</span>
<span class="p_add">+#define	CONTIG_SHIFT		5</span>
<span class="p_add">+#define CONTIG_PAGES		32</span>
<span class="p_add">+#else</span>
<span class="p_add">+#define	CONTIG_SHIFT		4</span>
<span class="p_add">+#define CONTIG_PAGES		16</span>
<span class="p_add">+#endif</span>
<span class="p_add">+#define	CONTIG_PTE_SIZE		(CONTIG_PAGES * PAGE_SIZE)</span>
<span class="p_add">+#define	CONTIG_PTE_MASK		(~(CONTIG_PTE_SIZE - 1))</span>
<span class="p_add">+</span>
<span class="p_add">+/*</span>
  * Hardware page table definitions.
  *
  * Level 1 descriptor (PUD).
<span class="p_chunk">@@ -83,6 +96,7 @@</span> <span class="p_context"></span>
 #define PMD_SECT_S		(_AT(pmdval_t, 3) &lt;&lt; 8)
 #define PMD_SECT_AF		(_AT(pmdval_t, 1) &lt;&lt; 10)
 #define PMD_SECT_NG		(_AT(pmdval_t, 1) &lt;&lt; 11)
<span class="p_add">+#define PMD_SECT_CONTIG		(_AT(pmdval_t, 1) &lt;&lt; 52)</span>
 #define PMD_SECT_PXN		(_AT(pmdval_t, 1) &lt;&lt; 53)
 #define PMD_SECT_UXN		(_AT(pmdval_t, 1) &lt;&lt; 54)
 
<span class="p_chunk">@@ -105,6 +119,7 @@</span> <span class="p_context"></span>
 #define PTE_AF			(_AT(pteval_t, 1) &lt;&lt; 10)	/* Access Flag */
 #define PTE_NG			(_AT(pteval_t, 1) &lt;&lt; 11)	/* nG */
 #define PTE_DBM			(_AT(pteval_t, 1) &lt;&lt; 51)	/* Dirty Bit Management */
<span class="p_add">+#define PTE_CONTIG		(_AT(pteval_t, 1) &lt;&lt; 52)	/* Contiguous */</span>
 #define PTE_PXN			(_AT(pteval_t, 1) &lt;&lt; 53)	/* Privileged XN */
 #define PTE_UXN			(_AT(pteval_t, 1) &lt;&lt; 54)	/* User XN */
 
<span class="p_header">diff --git a/arch/arm64/include/asm/pgtable.h b/arch/arm64/include/asm/pgtable.h</span>
<span class="p_header">index 6900b2d9..df5ec64 100644</span>
<span class="p_header">--- a/arch/arm64/include/asm/pgtable.h</span>
<span class="p_header">+++ b/arch/arm64/include/asm/pgtable.h</span>
<span class="p_chunk">@@ -144,6 +144,7 @@</span> <span class="p_context"> extern struct page *empty_zero_page;</span>
 #define pte_special(pte)	(!!(pte_val(pte) &amp; PTE_SPECIAL))
 #define pte_write(pte)		(!!(pte_val(pte) &amp; PTE_WRITE))
 #define pte_exec(pte)		(!(pte_val(pte) &amp; PTE_UXN))
<span class="p_add">+#define pte_contig(pte)		(!!(pte_val(pte) &amp; PTE_CONTIG))</span>
 
 #ifdef CONFIG_ARM64_HW_AFDBM
 #define pte_hw_dirty(pte)	(!(pte_val(pte) &amp; PTE_RDONLY))
<span class="p_chunk">@@ -206,6 +207,9 @@</span> <span class="p_context"> static inline pte_t pte_mkspecial(pte_t pte)</span>
 	return set_pte_bit(pte, __pgprot(PTE_SPECIAL));
 }
 
<span class="p_add">+extern pte_t pte_mkcontig(pte_t pte);</span>
<span class="p_add">+extern pmd_t pmd_mkcontig(pmd_t pmd);</span>
<span class="p_add">+</span>
 static inline void set_pte(pte_t *ptep, pte_t pte)
 {
 	*ptep = pte;
<span class="p_chunk">@@ -275,7 +279,7 @@</span> <span class="p_context"> static inline void set_pte_at(struct mm_struct *mm, unsigned long addr,</span>
 /*
  * Hugetlb definitions.
  */
<span class="p_del">-#define HUGE_MAX_HSTATE		2</span>
<span class="p_add">+#define HUGE_MAX_HSTATE		((2 * CONFIG_PGTABLE_LEVELS) - 1)</span>
 #define HPAGE_SHIFT		PMD_SHIFT
 #define HPAGE_SIZE		(_AC(1, UL) &lt;&lt; HPAGE_SHIFT)
 #define HPAGE_MASK		(~(HPAGE_SIZE - 1))
<span class="p_chunk">@@ -372,7 +376,8 @@</span> <span class="p_context"> extern pgprot_t phys_mem_access_prot(struct file *file, unsigned long pfn,</span>
 #define pmd_none(pmd)		(!pmd_val(pmd))
 #define pmd_present(pmd)	(pmd_val(pmd))
 
<span class="p_del">-#define pmd_bad(pmd)		(!(pmd_val(pmd) &amp; 2))</span>
<span class="p_add">+#define pmd_bad(pmd)		(!(pmd_val(pmd) &amp; \</span>
<span class="p_add">+				   (PMD_TABLE_BIT | PMD_SECT_CONTIG)))</span>
 
 #define pmd_table(pmd)		((pmd_val(pmd) &amp; PMD_TYPE_MASK) == \
 				 PMD_TYPE_TABLE)
<span class="p_chunk">@@ -500,7 +505,8 @@</span> <span class="p_context"> static inline pud_t *pud_offset(pgd_t *pgd, unsigned long addr)</span>
 static inline pte_t pte_modify(pte_t pte, pgprot_t newprot)
 {
 	const pteval_t mask = PTE_USER | PTE_PXN | PTE_UXN | PTE_RDONLY |
<span class="p_del">-			      PTE_PROT_NONE | PTE_WRITE | PTE_TYPE_MASK;</span>
<span class="p_add">+			      PTE_PROT_NONE | PTE_WRITE | PTE_TYPE_MASK |</span>
<span class="p_add">+			      PTE_CONTIG;</span>
 	/* preserve the hardware dirty information */
 	if (pte_hw_dirty(pte))
 		newprot |= PTE_DIRTY;
<span class="p_chunk">@@ -513,6 +519,24 @@</span> <span class="p_context"> static inline pmd_t pmd_modify(pmd_t pmd, pgprot_t newprot)</span>
 	return pte_pmd(pte_modify(pmd_pte(pmd), newprot));
 }
 
<span class="p_add">+static inline pte_t pte_modify_pfn(pte_t pte, unsigned long newpfn)</span>
<span class="p_add">+{</span>
<span class="p_add">+	const pteval_t mask = PHYS_MASK &amp; PAGE_MASK;</span>
<span class="p_add">+</span>
<span class="p_add">+	pte_val(pte) = pfn_pte(newpfn, (pte_val(pte) &amp; ~mask));</span>
<span class="p_add">+	return pte;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+#if CONFIG_PGTABLE_LEVELS &gt; 2</span>
<span class="p_add">+static inline pmd_t pmd_modify_pfn(pmd_t pmd, unsigned long newpfn)</span>
<span class="p_add">+{</span>
<span class="p_add">+	const pmdval_t mask = PHYS_MASK &amp; PAGE_MASK;</span>
<span class="p_add">+</span>
<span class="p_add">+	pmd = pfn_pmd(newpfn, (pmd_val(pmd) &amp; ~mask));</span>
<span class="p_add">+	return pmd;</span>
<span class="p_add">+}</span>
<span class="p_add">+#endif</span>
<span class="p_add">+</span>
 #ifdef CONFIG_ARM64_HW_AFDBM
 /*
  * Atomic pte/pmd modifications.
<span class="p_header">diff --git a/arch/arm64/mm/hugetlbpage.c b/arch/arm64/mm/hugetlbpage.c</span>
<span class="p_header">index 383b03f..f5bbbbc 100644</span>
<span class="p_header">--- a/arch/arm64/mm/hugetlbpage.c</span>
<span class="p_header">+++ b/arch/arm64/mm/hugetlbpage.c</span>
<span class="p_chunk">@@ -41,6 +41,155 @@</span> <span class="p_context"> int pud_huge(pud_t pud)</span>
 #endif
 }
 
<span class="p_add">+pte_t *huge_pte_alloc(struct mm_struct *mm,</span>
<span class="p_add">+			unsigned long addr, unsigned long sz)</span>
<span class="p_add">+{</span>
<span class="p_add">+	pgd_t *pgd;</span>
<span class="p_add">+	pud_t *pud;</span>
<span class="p_add">+	pte_t *pte = NULL;</span>
<span class="p_add">+	int i;</span>
<span class="p_add">+</span>
<span class="p_add">+	pgd = pgd_offset(mm, addr);</span>
<span class="p_add">+	pud = pud_alloc(mm, pgd, addr);</span>
<span class="p_add">+	if (pud) {</span>
<span class="p_add">+		if (sz == PUD_SIZE) {</span>
<span class="p_add">+			pte = (pte_t *)pud;</span>
<span class="p_add">+		} else if (sz == PMD_SIZE) {</span>
<span class="p_add">+#ifdef CONFIG_ARCH_WANT_HUGE_PMD_SHARE</span>
<span class="p_add">+			if (pud_none(*pud))</span>
<span class="p_add">+				pte = huge_pmd_share(mm, addr, pud);</span>
<span class="p_add">+			else</span>
<span class="p_add">+#endif</span>
<span class="p_add">+				pte = (pte_t *)pmd_alloc(mm, pud, addr);</span>
<span class="p_add">+		} else if (sz == (PAGE_SIZE * CONTIG_PAGES)) {</span>
<span class="p_add">+			pmd_t *pmd = pmd_alloc(mm, pud, addr);</span>
<span class="p_add">+</span>
<span class="p_add">+			WARN_ON(addr &amp; (sz - 1));</span>
<span class="p_add">+			pte = pte_alloc_map(mm, NULL, pmd, addr);</span>
<span class="p_add">+			if (pte_present(*pte)) {</span>
<span class="p_add">+				unsigned long pfn;</span>
<span class="p_add">+				*pte = pte_mkcontig(*pte);</span>
<span class="p_add">+				pfn = pte_pfn(*pte);</span>
<span class="p_add">+				for (i = 0; i &lt; CONTIG_PAGES; i++) {</span>
<span class="p_add">+					set_pte(&amp;pte[i],</span>
<span class="p_add">+						pte_modify_pfn(*pte, pfn + i));</span>
<span class="p_add">+				}</span>
<span class="p_add">+			}</span>
<span class="p_add">+#if CONFIG_PGTABLE_LEVELS &gt; 2</span>
<span class="p_add">+		} else if (sz == (PMD_SIZE * CONTIG_PAGES)) {</span>
<span class="p_add">+			pmd_t *pmd;</span>
<span class="p_add">+</span>
<span class="p_add">+			pmd = pmd_alloc(mm, pud, addr);</span>
<span class="p_add">+			WARN_ON(addr &amp; (sz - 1));</span>
<span class="p_add">+			if (pmd &amp;&amp; pmd_present(*pmd)) {</span>
<span class="p_add">+				unsigned long pfn;</span>
<span class="p_add">+				pmd_t pmdval;</span>
<span class="p_add">+</span>
<span class="p_add">+				pmdval = *pmd = pmd_mkcontig(*pmd);</span>
<span class="p_add">+				pfn = pmd_pfn(*pmd);</span>
<span class="p_add">+				for (i = 0; i &lt; CONTIG_PAGES; i++) {</span>
<span class="p_add">+					unsigned long newpfn = pfn +</span>
<span class="p_add">+						(i &lt;&lt; (PMD_SHIFT - PAGE_SHIFT));</span>
<span class="p_add">+					if (!pmd_present(pmd[i]))</span>
<span class="p_add">+						atomic_long_inc(&amp;mm-&gt;nr_ptes);</span>
<span class="p_add">+					set_pmd(&amp;pmd[i],</span>
<span class="p_add">+						pmd_modify_pfn(pmdval, newpfn));</span>
<span class="p_add">+				}</span>
<span class="p_add">+			}</span>
<span class="p_add">+			return pmd;</span>
<span class="p_add">+#endif</span>
<span class="p_add">+		}</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	return pte;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+pte_t *huge_pte_offset(struct mm_struct *mm, unsigned long addr)</span>
<span class="p_add">+{</span>
<span class="p_add">+	pgd_t *pgd;</span>
<span class="p_add">+	pud_t *pud;</span>
<span class="p_add">+	pmd_t *pmd = NULL;</span>
<span class="p_add">+	pte_t *pte = NULL;</span>
<span class="p_add">+</span>
<span class="p_add">+	pgd = pgd_offset(mm, addr);</span>
<span class="p_add">+	if (pgd_present(*pgd)) {</span>
<span class="p_add">+		pud = pud_offset(pgd, addr);</span>
<span class="p_add">+		if (pud_present(*pud)) {</span>
<span class="p_add">+			if (pud_huge(*pud))</span>
<span class="p_add">+				return (pte_t *)pud;</span>
<span class="p_add">+			pmd = pmd_offset(pud, addr);</span>
<span class="p_add">+			if (pmd_present(*pmd)) {</span>
<span class="p_add">+				if (pmd_huge(*pmd))</span>
<span class="p_add">+					return (pte_t *)pmd;</span>
<span class="p_add">+				pte = pte_offset_kernel(pmd, addr);</span>
<span class="p_add">+				if (pte_present(*pte) &amp;&amp; pte_contig(*pte)) {</span>
<span class="p_add">+					pte = pte_offset_kernel(</span>
<span class="p_add">+						pmd, (addr &amp; CONTIG_PTE_MASK));</span>
<span class="p_add">+					return pte;</span>
<span class="p_add">+				}</span>
<span class="p_add">+			}</span>
<span class="p_add">+		}</span>
<span class="p_add">+	}</span>
<span class="p_add">+	return (pte_t *) NULL;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+pte_t arch_make_huge_pte(pte_t entry, struct vm_area_struct *vma,</span>
<span class="p_add">+			 struct page *page, int writable)</span>
<span class="p_add">+{</span>
<span class="p_add">+	size_t pagesize = huge_page_size(hstate_vma(vma));</span>
<span class="p_add">+	pte_t nent = {0};</span>
<span class="p_add">+</span>
<span class="p_add">+	if (pagesize == PUD_SIZE || pagesize == PMD_SIZE)</span>
<span class="p_add">+		nent = entry;</span>
<span class="p_add">+	else if (pagesize == (PAGE_SIZE * CONTIG_PAGES))</span>
<span class="p_add">+		nent = pte_mkcontig(entry);</span>
<span class="p_add">+#if CONFIG_PGTABLE_LEVELS &gt; 2</span>
<span class="p_add">+	else if (pagesize == (PMD_SIZE * CONTIG_PAGES) ||</span>
<span class="p_add">+		 pagesize == (PUD_SIZE * CONTIG_PAGES))</span>
<span class="p_add">+		nent = pmd_mkcontig(entry);</span>
<span class="p_add">+#endif</span>
<span class="p_add">+	else {</span>
<span class="p_add">+		pr_warn(&quot;%s: unrecognized huge page size 0x%lx\n&quot;,</span>
<span class="p_add">+		       __func__, pagesize);</span>
<span class="p_add">+	}</span>
<span class="p_add">+	return nent;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+pte_t pte_mkcontig(pte_t pte)</span>
<span class="p_add">+{</span>
<span class="p_add">+	pte = set_pte_bit(pte, __pgprot(PTE_CONTIG));</span>
<span class="p_add">+	pte = set_pte_bit(pte, __pgprot(PTE_TYPE_PAGE));</span>
<span class="p_add">+	return pte;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+pmd_t pmd_mkcontig(pmd_t pmd)</span>
<span class="p_add">+{</span>
<span class="p_add">+	pmd = __pmd(pmd_val(pmd) | PMD_SECT_CONTIG);</span>
<span class="p_add">+	return pmd;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+struct page *follow_huge_pmd(struct mm_struct *mm, unsigned long address,</span>
<span class="p_add">+		pmd_t *pmd, int write)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct page *page;</span>
<span class="p_add">+</span>
<span class="p_add">+	page = pte_page(*(pte_t *)pmd);</span>
<span class="p_add">+	if (page)</span>
<span class="p_add">+		page += ((address &amp; ~PMD_MASK) &gt;&gt; PAGE_SHIFT);</span>
<span class="p_add">+	return page;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+struct page *follow_huge_pud(struct mm_struct *mm, unsigned long address,</span>
<span class="p_add">+		pud_t *pud, int write)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct page *page;</span>
<span class="p_add">+</span>
<span class="p_add">+	page = pte_page(*(pte_t *)pud);</span>
<span class="p_add">+	if (page)</span>
<span class="p_add">+		page += ((address &amp; ~PUD_MASK) &gt;&gt; PAGE_SHIFT);</span>
<span class="p_add">+	return page;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static __init int setup_hugepagesz(char *opt)
 {
 	unsigned long ps = memparse(opt, &amp;opt);
<span class="p_chunk">@@ -48,10 +197,24 @@</span> <span class="p_context"> static __init int setup_hugepagesz(char *opt)</span>
 		hugetlb_add_hstate(PMD_SHIFT - PAGE_SHIFT);
 	} else if (ps == PUD_SIZE) {
 		hugetlb_add_hstate(PUD_SHIFT - PAGE_SHIFT);
<span class="p_add">+	} else if (ps == (PAGE_SIZE * CONTIG_PAGES)) {</span>
<span class="p_add">+		hugetlb_add_hstate(CONTIG_SHIFT);</span>
<span class="p_add">+	} else if (ps == (PMD_SIZE * CONTIG_PAGES)) {</span>
<span class="p_add">+		hugetlb_add_hstate((PMD_SHIFT + CONTIG_SHIFT) - PAGE_SHIFT);</span>
 	} else {
<span class="p_del">-		pr_err(&quot;hugepagesz: Unsupported page size %lu M\n&quot;, ps &gt;&gt; 20);</span>
<span class="p_add">+		pr_err(&quot;hugepagesz: Unsupported page size %lu K\n&quot;, ps &gt;&gt; 10);</span>
 		return 0;
 	}
 	return 1;
 }
 __setup(&quot;hugepagesz=&quot;, setup_hugepagesz);
<span class="p_add">+</span>
<span class="p_add">+#ifdef CONFIG_ARM64_64K_PAGES</span>
<span class="p_add">+static __init int add_default_hugepagesz(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	if (size_to_hstate(CONTIG_PAGES * PAGE_SIZE) == NULL)</span>
<span class="p_add">+		hugetlb_add_hstate(CONTIG_SHIFT);</span>
<span class="p_add">+	return 0;</span>
<span class="p_add">+}</span>
<span class="p_add">+arch_initcall(add_default_hugepagesz);</span>
<span class="p_add">+#endif</span>

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



