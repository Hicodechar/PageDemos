
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>[6/7] x86/hyper-v: use hypercall for remove TLB flush - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    [6/7] x86/hyper-v: use hypercall for remove TLB flush</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=99981">Vitaly Kuznetsov</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>April 7, 2017, 11:27 a.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;20170407112701.17157-7-vkuznets@redhat.com&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/9669319/mbox/"
   >mbox</a>
|
   <a href="/patch/9669319/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/9669319/">/patch/9669319/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
	[172.30.200.125])
	by pdx-korg-patchwork.web.codeaurora.org (Postfix) with ESMTP id
	AF85D602B3 for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Fri,  7 Apr 2017 11:27:49 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id A05DC20373
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Fri,  7 Apr 2017 11:27:49 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id 9526326E48; Fri,  7 Apr 2017 11:27:49 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-6.9 required=2.0 tests=BAYES_00,RCVD_IN_DNSWL_HI
	autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id F2BD120373
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Fri,  7 Apr 2017 11:27:48 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S932925AbdDGL1o (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Fri, 7 Apr 2017 07:27:44 -0400
Received: from mx1.redhat.com ([209.132.183.28]:48914 &quot;EHLO mx1.redhat.com&quot;
	rhost-flags-OK-OK-OK-OK) by vger.kernel.org with ESMTP
	id S932812AbdDGL12 (ORCPT &lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Fri, 7 Apr 2017 07:27:28 -0400
Received: from smtp.corp.redhat.com
	(int-mx06.intmail.prod.int.phx2.redhat.com [10.5.11.16])
	(using TLSv1.2 with cipher AECDH-AES256-SHA (256/256 bits))
	(No client certificate requested)
	by mx1.redhat.com (Postfix) with ESMTPS id AEDD17F7AD;
	Fri,  7 Apr 2017 11:27:22 +0000 (UTC)
DMARC-Filter: OpenDMARC Filter v1.3.2 mx1.redhat.com AEDD17F7AD
Authentication-Results: ext-mx04.extmail.prod.ext.phx2.redhat.com;
	dmarc=none (p=none dis=none) header.from=redhat.com
Authentication-Results: ext-mx04.extmail.prod.ext.phx2.redhat.com;
	spf=pass smtp.mailfrom=vkuznets@redhat.com
DKIM-Filter: OpenDKIM Filter v2.11.0 mx1.redhat.com AEDD17F7AD
Received: from vitty.brq.redhat.com (vitty.brq.redhat.com [10.34.26.3])
	by smtp.corp.redhat.com (Postfix) with ESMTP id 6CDBF1800C;
	Fri,  7 Apr 2017 11:27:20 +0000 (UTC)
From: Vitaly Kuznetsov &lt;vkuznets@redhat.com&gt;
To: devel@linuxdriverproject.org, x86@kernel.org
Cc: linux-kernel@vger.kernel.org, &quot;K. Y. Srinivasan&quot; &lt;kys@microsoft.com&gt;,
	Haiyang Zhang &lt;haiyangz@microsoft.com&gt;,
	Stephen Hemminger &lt;sthemmin@microsoft.com&gt;,
	Thomas Gleixner &lt;tglx@linutronix.de&gt;, Ingo Molnar &lt;mingo@redhat.com&gt;,
	&quot;H. Peter Anvin&quot; &lt;hpa@zytor.com&gt;, Steven Rostedt &lt;rostedt@goodmis.org&gt;,
	Jork Loeser &lt;Jork.Loeser@microsoft.com&gt;
Subject: [PATCH 6/7] x86/hyper-v: use hypercall for remove TLB flush
Date: Fri,  7 Apr 2017 13:27:00 +0200
Message-Id: &lt;20170407112701.17157-7-vkuznets@redhat.com&gt;
In-Reply-To: &lt;20170407112701.17157-1-vkuznets@redhat.com&gt;
References: &lt;20170407112701.17157-1-vkuznets@redhat.com&gt;
X-Scanned-By: MIMEDefang 2.79 on 10.5.11.16
X-Greylist: Sender IP whitelisted, not delayed by milter-greylist-4.5.16
	(mx1.redhat.com [10.5.110.28]);
	Fri, 07 Apr 2017 11:27:22 +0000 (UTC)
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=99981">Vitaly Kuznetsov</a> - April 7, 2017, 11:27 a.m.</div>
<pre class="content">
Hyper-V host can suggest us to use hypercall for doing remote TLB flush,
this is supposed to work faster than IPIs.

Implementation details: to do HvFlushVirtualAddress{Space,List} hypercalls
we need to put the input somewhere in memory and we don&#39;t really want to
have memory allocation on each call so we pre-allocate per cpu memory areas
on boot. These areas are of fixes size, limit them with an arbitrary number
of 16 (16 gvas are able to specify 16 * 4096 pages).

pv_ops patching is happening very early so we need to separate
hyperv_setup_mmu_ops() and hyper_alloc_mmu().

It is possible and easy to implement local TLB flushing too and there is
even a hint for that. However, I don&#39;t see a room for optimization on the
host side as both hypercall and native tlb flush will result in vmexit. The
hint is also not set on modern Hyper-V versions.
<span class="signed-off-by">
Signed-off-by: Vitaly Kuznetsov &lt;vkuznets@redhat.com&gt;</span>
---
 arch/x86/hyperv/Makefile           |   2 +-
 arch/x86/hyperv/hv_init.c          |   2 +
 arch/x86/hyperv/mmu.c              | 128 +++++++++++++++++++++++++++++++++++++
 arch/x86/include/asm/mshyperv.h    |   2 +
 arch/x86/include/uapi/asm/hyperv.h |   7 ++
 arch/x86/kernel/cpu/mshyperv.c     |   1 +
 6 files changed, 141 insertions(+), 1 deletion(-)
 create mode 100644 arch/x86/hyperv/mmu.c
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=173691">Jork Loeser</a> - April 7, 2017, 8:46 p.m.</div>
<pre class="content">
<span class="quote">&gt; -----Original Message-----</span>
<span class="quote">&gt; From: Vitaly Kuznetsov [mailto:vkuznets@redhat.com]</span>
<span class="quote">&gt; Sent: Friday, April 7, 2017 04:27</span>
<span class="quote">&gt; To: devel@linuxdriverproject.org; x86@kernel.org</span>
<span class="quote">&gt; Cc: linux-kernel@vger.kernel.org; KY Srinivasan &lt;kys@microsoft.com&gt;;</span>
<span class="quote">&gt; Haiyang Zhang &lt;haiyangz@microsoft.com&gt;; Stephen Hemminger</span>
<span class="quote">&gt; &lt;sthemmin@microsoft.com&gt;; Thomas Gleixner &lt;tglx@linutronix.de&gt;; Ingo</span>
<span class="quote">&gt; Molnar &lt;mingo@redhat.com&gt;; H. Peter Anvin &lt;hpa@zytor.com&gt;; Steven</span>
<span class="quote">&gt; Rostedt &lt;rostedt@goodmis.org&gt;; Jork Loeser &lt;Jork.Loeser@microsoft.com&gt;</span>
<span class="quote">&gt; Subject: [PATCH 6/7] x86/hyper-v: use hypercall for remove TLB flush</span>
<span class="quote">
&gt; diff --git a/arch/x86/hyperv/mmu.c b/arch/x86/hyperv/mmu.c new file</span>
<span class="quote">&gt; mode 100644 index 0000000..fb487cb</span>
<span class="quote">&gt; --- /dev/null</span>
<span class="quote">&gt; +++ b/arch/x86/hyperv/mmu.c</span>
<span class="quote">&gt; @@ -0,0 +1,128 @@</span>
<span class="quote">&gt; +#include &lt;linux/types.h&gt;</span>
<span class="quote">&gt; +#include &lt;linux/hyperv.h&gt;</span>
<span class="quote">&gt; +#include &lt;linux/slab.h&gt;</span>
<span class="quote">&gt; +#include &lt;asm/mshyperv.h&gt;</span>
<span class="quote">&gt; +#include &lt;asm/tlbflush.h&gt;</span>
<span class="quote">&gt; +#include &lt;asm/msr.h&gt;</span>
<span class="quote">&gt; +#include &lt;asm/fpu/api.h&gt;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +/*</span>
<span class="quote">&gt; + * Arbitrary number; we need to pre-allocate per-cpu struct for doing</span>
<span class="quote">&gt; +TLB</span>
<span class="quote">&gt; + * flush hypercalls and we need to pick a size. &#39;16&#39; means we&#39;ll be</span>
<span class="quote">&gt; +able</span>
<span class="quote">&gt; + * to flush 16 * 4096 pages (256MB) with one hypercall.</span>
<span class="quote">&gt; + */</span>
<span class="quote">&gt; +#define HV_MMU_MAX_GVAS 16</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +/* HvFlushVirtualAddressSpace*, HvFlushVirtualAddressList hypercalls */</span>
<span class="quote">&gt; +struct hv_flush_pcpu {</span>
<span class="quote">&gt; +	struct {</span>
<span class="quote">&gt; +		__u64 address_space;</span>
<span class="quote">&gt; +		__u64 flags;</span>
<span class="quote">&gt; +		__u64 processor_mask;</span>
<span class="quote">&gt; +		__u64 gva_list[HV_MMU_MAX_GVAS];</span>
<span class="quote">&gt; +	} flush;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	spinlock_t lock;</span>
<span class="quote">&gt; +};</span>
Does this need an alignment declaration, so that the flush portion never crosses a page boundary when allocated with alloc_percpu()?
<span class="quote">
&gt; +</span>
<span class="quote">&gt; +static struct hv_flush_pcpu __percpu *pcpu_flush;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +static void hyperv_flush_tlb_others(const struct cpumask *cpus,</span>
<span class="quote">&gt; +				    struct mm_struct *mm, unsigned long</span>
<span class="quote">&gt; start,</span>
<span class="quote">&gt; +				    unsigned long end)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	struct hv_flush_pcpu *flush;</span>
<span class="quote">&gt; +	unsigned long cur, flags;</span>
<span class="quote">&gt; +	u64 status = -1ULL;</span>
<span class="quote">&gt; +	int cpu, vcpu, gva_n;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	if (!pcpu_flush || !hv_hypercall_pg)</span>
<span class="quote">&gt; +		goto do_native;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	if (cpumask_empty(cpus))</span>
<span class="quote">&gt; +		return;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	flush = this_cpu_ptr(pcpu_flush);</span>
<span class="quote">&gt; +	spin_lock_irqsave(&amp;flush-&gt;lock, flags);</span>

What purpose does the spinlock on the CPU-local struct serve? Would a local_irq_save() do?

Could this be called from NMI context, such as from the debugger?

Could this be a long-running loop, e.g. due to a large start/end range? If so, consider disabling interrupts only in the inner loop / flush the entire space?

Regards,
Jork
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=22291">K. Y. Srinivasan</a> - April 8, 2017, 4:47 p.m.</div>
<pre class="content">
<span class="quote">&gt; -----Original Message-----</span>
<span class="quote">&gt; From: Vitaly Kuznetsov [mailto:vkuznets@redhat.com]</span>
<span class="quote">&gt; Sent: Friday, April 7, 2017 4:27 AM</span>
<span class="quote">&gt; To: devel@linuxdriverproject.org; x86@kernel.org</span>
<span class="quote">&gt; Cc: linux-kernel@vger.kernel.org; KY Srinivasan &lt;kys@microsoft.com&gt;;</span>
<span class="quote">&gt; Haiyang Zhang &lt;haiyangz@microsoft.com&gt;; Stephen Hemminger</span>
<span class="quote">&gt; &lt;sthemmin@microsoft.com&gt;; Thomas Gleixner &lt;tglx@linutronix.de&gt;; Ingo</span>
<span class="quote">&gt; Molnar &lt;mingo@redhat.com&gt;; H. Peter Anvin &lt;hpa@zytor.com&gt;; Steven</span>
<span class="quote">&gt; Rostedt &lt;rostedt@goodmis.org&gt;; Jork Loeser &lt;Jork.Loeser@microsoft.com&gt;</span>
<span class="quote">&gt; Subject: [PATCH 6/7] x86/hyper-v: use hypercall for remove TLB flush</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Hyper-V host can suggest us to use hypercall for doing remote TLB flush,</span>
<span class="quote">&gt; this is supposed to work faster than IPIs.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Implementation details: to do HvFlushVirtualAddress{Space,List} hypercalls</span>
<span class="quote">&gt; we need to put the input somewhere in memory and we don&#39;t really want to</span>
<span class="quote">&gt; have memory allocation on each call so we pre-allocate per cpu memory</span>
<span class="quote">&gt; areas</span>
<span class="quote">&gt; on boot. These areas are of fixes size, limit them with an arbitrary number</span>
<span class="quote">&gt; of 16 (16 gvas are able to specify 16 * 4096 pages).</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; pv_ops patching is happening very early so we need to separate</span>
<span class="quote">&gt; hyperv_setup_mmu_ops() and hyper_alloc_mmu().</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; It is possible and easy to implement local TLB flushing too and there is</span>
<span class="quote">&gt; even a hint for that. However, I don&#39;t see a room for optimization on the</span>
<span class="quote">&gt; host side as both hypercall and native tlb flush will result in vmexit. The</span>
<span class="quote">&gt; hint is also not set on modern Hyper-V versions.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Signed-off-by: Vitaly Kuznetsov &lt;vkuznets@redhat.com&gt;</span>
<span class="quote">&gt; ---</span>
<span class="quote">&gt;  arch/x86/hyperv/Makefile           |   2 +-</span>
<span class="quote">&gt;  arch/x86/hyperv/hv_init.c          |   2 +</span>
<span class="quote">&gt;  arch/x86/hyperv/mmu.c              | 128</span>
<span class="quote">&gt; +++++++++++++++++++++++++++++++++++++</span>
<span class="quote">&gt;  arch/x86/include/asm/mshyperv.h    |   2 +</span>
<span class="quote">&gt;  arch/x86/include/uapi/asm/hyperv.h |   7 ++</span>
<span class="quote">&gt;  arch/x86/kernel/cpu/mshyperv.c     |   1 +</span>
<span class="quote">&gt;  6 files changed, 141 insertions(+), 1 deletion(-)</span>
<span class="quote">&gt;  create mode 100644 arch/x86/hyperv/mmu.c</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; diff --git a/arch/x86/hyperv/Makefile b/arch/x86/hyperv/Makefile</span>
<span class="quote">&gt; index 171ae09..367a820 100644</span>
<span class="quote">&gt; --- a/arch/x86/hyperv/Makefile</span>
<span class="quote">&gt; +++ b/arch/x86/hyperv/Makefile</span>
<span class="quote">&gt; @@ -1 +1 @@</span>
<span class="quote">&gt; -obj-y		:= hv_init.o</span>
<span class="quote">&gt; +obj-y		:= hv_init.o mmu.o</span>
<span class="quote">&gt; diff --git a/arch/x86/hyperv/hv_init.c b/arch/x86/hyperv/hv_init.c</span>
<span class="quote">&gt; index 1c14088..2cf8a98 100644</span>
<span class="quote">&gt; --- a/arch/x86/hyperv/hv_init.c</span>
<span class="quote">&gt; +++ b/arch/x86/hyperv/hv_init.c</span>
<span class="quote">&gt; @@ -163,6 +163,8 @@ void hyperv_init(void)</span>
<span class="quote">&gt;  	hypercall_msr.guest_physical_address =</span>
<span class="quote">&gt; vmalloc_to_pfn(hv_hypercall_pg);</span>
<span class="quote">&gt;  	wrmsrl(HV_X64_MSR_HYPERCALL, hypercall_msr.as_uint64);</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; +	hyper_alloc_mmu();</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt;  	/*</span>
<span class="quote">&gt;  	 * Register Hyper-V specific clocksource.</span>
<span class="quote">&gt;  	 */</span>
<span class="quote">&gt; diff --git a/arch/x86/hyperv/mmu.c b/arch/x86/hyperv/mmu.c</span>
<span class="quote">&gt; new file mode 100644</span>
<span class="quote">&gt; index 0000000..fb487cb</span>
<span class="quote">&gt; --- /dev/null</span>
<span class="quote">&gt; +++ b/arch/x86/hyperv/mmu.c</span>
<span class="quote">&gt; @@ -0,0 +1,128 @@</span>
<span class="quote">&gt; +#include &lt;linux/types.h&gt;</span>
<span class="quote">&gt; +#include &lt;linux/hyperv.h&gt;</span>
<span class="quote">&gt; +#include &lt;linux/slab.h&gt;</span>
<span class="quote">&gt; +#include &lt;asm/mshyperv.h&gt;</span>
<span class="quote">&gt; +#include &lt;asm/tlbflush.h&gt;</span>
<span class="quote">&gt; +#include &lt;asm/msr.h&gt;</span>
<span class="quote">&gt; +#include &lt;asm/fpu/api.h&gt;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +/*</span>
<span class="quote">&gt; + * Arbitrary number; we need to pre-allocate per-cpu struct for doing TLB</span>
<span class="quote">&gt; + * flush hypercalls and we need to pick a size. &#39;16&#39; means we&#39;ll be able</span>
<span class="quote">&gt; + * to flush 16 * 4096 pages (256MB) with one hypercall.</span>
<span class="quote">&gt; + */</span>
<span class="quote">&gt; +#define HV_MMU_MAX_GVAS 16</span>

Did you experiment with different sizes here.
<span class="quote">&gt; +</span>
<span class="quote">&gt; +/* HvFlushVirtualAddressSpace*, HvFlushVirtualAddressList hypercalls */</span>
<span class="quote">&gt; +struct hv_flush_pcpu {</span>
<span class="quote">&gt; +	struct {</span>
<span class="quote">&gt; +		__u64 address_space;</span>
<span class="quote">&gt; +		__u64 flags;</span>
<span class="quote">&gt; +		__u64 processor_mask;</span>
<span class="quote">&gt; +		__u64 gva_list[HV_MMU_MAX_GVAS];</span>
<span class="quote">&gt; +	} flush;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	spinlock_t lock;</span>
<span class="quote">&gt; +};</span>
<span class="quote">&gt; +</span>
We may be supporting more than 64 CPUs in this hypercall. I am going to inquire with
the Windows folks and get back to you.
<span class="quote">
&gt; +static struct hv_flush_pcpu __percpu *pcpu_flush;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +static void hyperv_flush_tlb_others(const struct cpumask *cpus,</span>
<span class="quote">&gt; +				    struct mm_struct *mm, unsigned long</span>
<span class="quote">&gt; start,</span>
<span class="quote">&gt; +				    unsigned long end)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	struct hv_flush_pcpu *flush;</span>
<span class="quote">&gt; +	unsigned long cur, flags;</span>
<span class="quote">&gt; +	u64 status = -1ULL;</span>
<span class="quote">&gt; +	int cpu, vcpu, gva_n;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	if (!pcpu_flush || !hv_hypercall_pg)</span>
<span class="quote">&gt; +		goto do_native;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	if (cpumask_empty(cpus))</span>
<span class="quote">&gt; +		return;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	flush = this_cpu_ptr(pcpu_flush);</span>
<span class="quote">&gt; +	spin_lock_irqsave(&amp;flush-&gt;lock, flags);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	flush-&gt;flush.address_space = virt_to_phys(mm-&gt;pgd);</span>
<span class="quote">&gt; +	flush-&gt;flush.processor_mask = 0;</span>
<span class="quote">&gt; +	if (cpumask_equal(cpus, cpu_present_mask)) {</span>
<span class="quote">&gt; +		flush-&gt;flush.flags = HV_FLUSH_ALL_PROCESSORS;</span>
<span class="quote">&gt; +	} else {</span>
<span class="quote">&gt; +		flush-&gt;flush.flags = 0;</span>
<span class="quote">&gt; +		for_each_cpu(cpu, cpus) {</span>
<span class="quote">&gt; +			vcpu = vmbus_cpu_number_to_vp_number(cpu);</span>
<span class="quote">&gt; +			if (vcpu != -1 &amp;&amp; vcpu &lt; 64)</span>
<span class="quote">&gt; +				flush-&gt;flush.processor_mask |= 1 &lt;&lt; vcpu;</span>
<span class="quote">&gt; +			else</span>
<span class="quote">&gt; +				goto unlock_do_native;</span>
<span class="quote">&gt; +		}</span>
<span class="quote">&gt; +	}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	if (end == TLB_FLUSH_ALL) {</span>
<span class="quote">&gt; +		flush-&gt;flush.flags =</span>
<span class="quote">&gt; HV_FLUSH_NON_GLOBAL_MAPPINGS_ONLY;</span>
<span class="quote">&gt; +		status =</span>
<span class="quote">&gt; hv_do_hypercall(HVCALL_FLUSH_VIRTUAL_ADDRESS_SPACE,</span>
<span class="quote">&gt; +					 &amp;flush-&gt;flush, NULL);</span>
<span class="quote">&gt; +	} else {</span>
<span class="quote">&gt; +		cur = start;</span>
<span class="quote">&gt; +more_gvas:</span>
<span class="quote">&gt; +		gva_n = 0;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +		do {</span>
<span class="quote">&gt; +			flush-&gt;flush.gva_list[gva_n] = cur &amp; PAGE_MASK;</span>
<span class="quote">&gt; +			/*</span>
<span class="quote">&gt; +			 * Lower 12 bits encode the number of additional</span>
<span class="quote">&gt; +			 * pages to flush (in addition to the &#39;cur&#39; page).</span>
<span class="quote">&gt; +			 */</span>
<span class="quote">&gt; +			if (end &gt;= cur + PAGE_SIZE * PAGE_SIZE)</span>
<span class="quote">&gt; +				flush-&gt;flush.gva_list[gva_n] |=</span>
<span class="quote">&gt; ~PAGE_MASK;</span>
<span class="quote">&gt; +			else if (end &gt; cur)</span>
<span class="quote">&gt; +				flush-&gt;flush.gva_list[gva_n] |=</span>
<span class="quote">&gt; +					(end - cur - 1) &gt;&gt; PAGE_SHIFT;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +			cur += PAGE_SIZE * PAGE_SIZE;</span>
<span class="quote">&gt; +			++gva_n;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +		} while (cur &lt; end &amp;&amp; gva_n &lt; HV_MMU_MAX_GVAS);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +		status =</span>
<span class="quote">&gt; hv_do_rep_hypercall(HVCALL_FLUSH_VIRTUAL_ADDRESS_LIST,</span>
<span class="quote">&gt; +					     gva_n, &amp;flush-&gt;flush, NULL);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +		if (!(status &amp; 0xffff) &amp;&amp; cur &lt; end)</span>
<span class="quote">&gt; +			goto more_gvas;</span>
<span class="quote">&gt; +	}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +unlock_do_native:</span>
<span class="quote">&gt; +	spin_unlock_irqrestore(&amp;flush-&gt;lock, flags);</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	if (!(status &amp; 0xffff))</span>
<span class="quote">&gt; +		return;</span>
<span class="quote">&gt; +do_native:</span>
<span class="quote">&gt; +	native_flush_tlb_others(cpus, mm, start, end);</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +void hyperv_setup_mmu_ops(void)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	if (ms_hyperv.hints &amp;</span>
<span class="quote">&gt; HV_X64_REMOTE_TLB_FLUSH_RECOMMENDED) {</span>
<span class="quote">&gt; +		pr_info(&quot;Hyper-V: Using hypercall for remote TLB flush\n&quot;);</span>
<span class="quote">&gt; +		pv_mmu_ops.flush_tlb_others = hyperv_flush_tlb_others;</span>
<span class="quote">&gt; +	}</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +void hyper_alloc_mmu(void)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	int cpu;</span>
<span class="quote">&gt; +	struct hv_flush_pcpu *flush;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	if (ms_hyperv.hints &amp;</span>
<span class="quote">&gt; HV_X64_REMOTE_TLB_FLUSH_RECOMMENDED) {</span>
<span class="quote">&gt; +		pcpu_flush = alloc_percpu(struct hv_flush_pcpu);</span>
<span class="quote">&gt; +		if (!pcpu_flush)</span>
<span class="quote">&gt; +			return;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +		for_each_possible_cpu(cpu) {</span>
<span class="quote">&gt; +			flush = per_cpu_ptr(pcpu_flush, cpu);</span>
<span class="quote">&gt; +			spin_lock_init(&amp;flush-&gt;lock);</span>
<span class="quote">&gt; +		}</span>
<span class="quote">&gt; +	}</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; diff --git a/arch/x86/include/asm/mshyperv.h</span>
<span class="quote">&gt; b/arch/x86/include/asm/mshyperv.h</span>
<span class="quote">&gt; index 1293c84..a5041c3 100644</span>
<span class="quote">&gt; --- a/arch/x86/include/asm/mshyperv.h</span>
<span class="quote">&gt; +++ b/arch/x86/include/asm/mshyperv.h</span>
<span class="quote">&gt; @@ -301,6 +301,8 @@ static inline int</span>
<span class="quote">&gt; vmbus_cpu_number_to_vp_number(int cpu_number)</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt; </span>
<span class="quote">&gt;  void hyperv_init(void);</span>
<span class="quote">&gt; +void hyperv_setup_mmu_ops(void);</span>
<span class="quote">&gt; +void hyper_alloc_mmu(void);</span>
<span class="quote">&gt;  void hyperv_report_panic(struct pt_regs *regs);</span>
<span class="quote">&gt;  bool hv_is_hypercall_page_setup(void);</span>
<span class="quote">&gt;  void hyperv_cleanup(void);</span>
<span class="quote">&gt; diff --git a/arch/x86/include/uapi/asm/hyperv.h</span>
<span class="quote">&gt; b/arch/x86/include/uapi/asm/hyperv.h</span>
<span class="quote">&gt; index c87e900..3d44036 100644</span>
<span class="quote">&gt; --- a/arch/x86/include/uapi/asm/hyperv.h</span>
<span class="quote">&gt; +++ b/arch/x86/include/uapi/asm/hyperv.h</span>
<span class="quote">&gt; @@ -239,6 +239,8 @@</span>
<span class="quote">&gt;  		(~((1ull &lt;&lt;</span>
<span class="quote">&gt; HV_X64_MSR_HYPERCALL_PAGE_ADDRESS_SHIFT) - 1))</span>
<span class="quote">&gt; </span>
<span class="quote">&gt;  /* Declare the various hypercall operations. */</span>
<span class="quote">&gt; +#define HVCALL_FLUSH_VIRTUAL_ADDRESS_SPACE	0x0002</span>
<span class="quote">&gt; +#define HVCALL_FLUSH_VIRTUAL_ADDRESS_LIST	0x0003</span>
<span class="quote">&gt;  #define HVCALL_NOTIFY_LONG_SPIN_WAIT		0x0008</span>
<span class="quote">&gt;  #define HVCALL_POST_MESSAGE			0x005c</span>
<span class="quote">&gt;  #define HVCALL_SIGNAL_EVENT			0x005d</span>
<span class="quote">&gt; @@ -256,6 +258,11 @@</span>
<span class="quote">&gt;  #define HV_PROCESSOR_POWER_STATE_C2		2</span>
<span class="quote">&gt;  #define HV_PROCESSOR_POWER_STATE_C3		3</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; +#define HV_FLUSH_ALL_PROCESSORS			0x00000001</span>
<span class="quote">&gt; +#define HV_FLUSH_ALL_VIRTUAL_ADDRESS_SPACES	0x00000002</span>
<span class="quote">&gt; +#define HV_FLUSH_NON_GLOBAL_MAPPINGS_ONLY	0x00000004</span>
<span class="quote">&gt; +#define HV_FLUSH_USE_EXTENDED_RANGE_FORMAT	0x00000008</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt;  /* Hypercall interface */</span>
<span class="quote">&gt;  union hv_hypercall_input {</span>
<span class="quote">&gt;  	u64 as_uint64;</span>
<span class="quote">&gt; diff --git a/arch/x86/kernel/cpu/mshyperv.c</span>
<span class="quote">&gt; b/arch/x86/kernel/cpu/mshyperv.c</span>
<span class="quote">&gt; index 04cb8d3..fc228d8 100644</span>
<span class="quote">&gt; --- a/arch/x86/kernel/cpu/mshyperv.c</span>
<span class="quote">&gt; +++ b/arch/x86/kernel/cpu/mshyperv.c</span>
<span class="quote">&gt; @@ -233,6 +233,7 @@ static void __init ms_hyperv_init_platform(void)</span>
<span class="quote">&gt;  	 * Setup the hook to get control post apic initialization.</span>
<span class="quote">&gt;  	 */</span>
<span class="quote">&gt;  	x86_platform.apic_post_init = hyperv_init;</span>
<span class="quote">&gt; +	hyperv_setup_mmu_ops();</span>
<span class="quote">&gt;  #endif</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; --</span>
<span class="quote">&gt; 2.9.3</span>
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=99981">Vitaly Kuznetsov</a> - April 10, 2017, 2:44 p.m.</div>
<pre class="content">
KY Srinivasan &lt;kys@microsoft.com&gt; writes:
<span class="quote">
&gt;&gt; -----Original Message-----</span>
<span class="quote">&gt;&gt; From: Vitaly Kuznetsov [mailto:vkuznets@redhat.com]</span>
<span class="quote">&gt;&gt; Sent: Friday, April 7, 2017 4:27 AM</span>
<span class="quote">&gt;&gt; To: devel@linuxdriverproject.org; x86@kernel.org</span>
<span class="quote">&gt;&gt; Cc: linux-kernel@vger.kernel.org; KY Srinivasan &lt;kys@microsoft.com&gt;;</span>
<span class="quote">&gt;&gt; Haiyang Zhang &lt;haiyangz@microsoft.com&gt;; Stephen Hemminger</span>
<span class="quote">&gt;&gt; &lt;sthemmin@microsoft.com&gt;; Thomas Gleixner &lt;tglx@linutronix.de&gt;; Ingo</span>
<span class="quote">&gt;&gt; Molnar &lt;mingo@redhat.com&gt;; H. Peter Anvin &lt;hpa@zytor.com&gt;; Steven</span>
<span class="quote">&gt;&gt; Rostedt &lt;rostedt@goodmis.org&gt;; Jork Loeser &lt;Jork.Loeser@microsoft.com&gt;</span>
<span class="quote">&gt;&gt; Subject: [PATCH 6/7] x86/hyper-v: use hypercall for remove TLB flush</span>
<span class="quote">&gt;&gt; </span>
<span class="quote">&gt;&gt; Hyper-V host can suggest us to use hypercall for doing remote TLB flush,</span>
<span class="quote">&gt;&gt; this is supposed to work faster than IPIs.</span>
<span class="quote">&gt;&gt; </span>
<span class="quote">&gt;&gt; Implementation details: to do HvFlushVirtualAddress{Space,List} hypercalls</span>
<span class="quote">&gt;&gt; we need to put the input somewhere in memory and we don&#39;t really want to</span>
<span class="quote">&gt;&gt; have memory allocation on each call so we pre-allocate per cpu memory</span>
<span class="quote">&gt;&gt; areas</span>
<span class="quote">&gt;&gt; on boot. These areas are of fixes size, limit them with an arbitrary number</span>
<span class="quote">&gt;&gt; of 16 (16 gvas are able to specify 16 * 4096 pages).</span>
<span class="quote">&gt;&gt; </span>
<span class="quote">&gt;&gt; pv_ops patching is happening very early so we need to separate</span>
<span class="quote">&gt;&gt; hyperv_setup_mmu_ops() and hyper_alloc_mmu().</span>
<span class="quote">&gt;&gt; </span>
<span class="quote">&gt;&gt; It is possible and easy to implement local TLB flushing too and there is</span>
<span class="quote">&gt;&gt; even a hint for that. However, I don&#39;t see a room for optimization on the</span>
<span class="quote">&gt;&gt; host side as both hypercall and native tlb flush will result in vmexit. The</span>
<span class="quote">&gt;&gt; hint is also not set on modern Hyper-V versions.</span>
<span class="quote">&gt;&gt; </span>
<span class="quote">&gt;&gt; Signed-off-by: Vitaly Kuznetsov &lt;vkuznets@redhat.com&gt;</span>
<span class="quote">&gt;&gt; ---</span>
<span class="quote">&gt;&gt;  arch/x86/hyperv/Makefile           |   2 +-</span>
<span class="quote">&gt;&gt;  arch/x86/hyperv/hv_init.c          |   2 +</span>
<span class="quote">&gt;&gt;  arch/x86/hyperv/mmu.c              | 128</span>
<span class="quote">&gt;&gt; +++++++++++++++++++++++++++++++++++++</span>
<span class="quote">&gt;&gt;  arch/x86/include/asm/mshyperv.h    |   2 +</span>
<span class="quote">&gt;&gt;  arch/x86/include/uapi/asm/hyperv.h |   7 ++</span>
<span class="quote">&gt;&gt;  arch/x86/kernel/cpu/mshyperv.c     |   1 +</span>
<span class="quote">&gt;&gt;  6 files changed, 141 insertions(+), 1 deletion(-)</span>
<span class="quote">&gt;&gt;  create mode 100644 arch/x86/hyperv/mmu.c</span>
<span class="quote">&gt;&gt; </span>
<span class="quote">&gt;&gt; diff --git a/arch/x86/hyperv/Makefile b/arch/x86/hyperv/Makefile</span>
<span class="quote">&gt;&gt; index 171ae09..367a820 100644</span>
<span class="quote">&gt;&gt; --- a/arch/x86/hyperv/Makefile</span>
<span class="quote">&gt;&gt; +++ b/arch/x86/hyperv/Makefile</span>
<span class="quote">&gt;&gt; @@ -1 +1 @@</span>
<span class="quote">&gt;&gt; -obj-y		:= hv_init.o</span>
<span class="quote">&gt;&gt; +obj-y		:= hv_init.o mmu.o</span>
<span class="quote">&gt;&gt; diff --git a/arch/x86/hyperv/hv_init.c b/arch/x86/hyperv/hv_init.c</span>
<span class="quote">&gt;&gt; index 1c14088..2cf8a98 100644</span>
<span class="quote">&gt;&gt; --- a/arch/x86/hyperv/hv_init.c</span>
<span class="quote">&gt;&gt; +++ b/arch/x86/hyperv/hv_init.c</span>
<span class="quote">&gt;&gt; @@ -163,6 +163,8 @@ void hyperv_init(void)</span>
<span class="quote">&gt;&gt;  	hypercall_msr.guest_physical_address =</span>
<span class="quote">&gt;&gt; vmalloc_to_pfn(hv_hypercall_pg);</span>
<span class="quote">&gt;&gt;  	wrmsrl(HV_X64_MSR_HYPERCALL, hypercall_msr.as_uint64);</span>
<span class="quote">&gt;&gt; </span>
<span class="quote">&gt;&gt; +	hyper_alloc_mmu();</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt;  	/*</span>
<span class="quote">&gt;&gt;  	 * Register Hyper-V specific clocksource.</span>
<span class="quote">&gt;&gt;  	 */</span>
<span class="quote">&gt;&gt; diff --git a/arch/x86/hyperv/mmu.c b/arch/x86/hyperv/mmu.c</span>
<span class="quote">&gt;&gt; new file mode 100644</span>
<span class="quote">&gt;&gt; index 0000000..fb487cb</span>
<span class="quote">&gt;&gt; --- /dev/null</span>
<span class="quote">&gt;&gt; +++ b/arch/x86/hyperv/mmu.c</span>
<span class="quote">&gt;&gt; @@ -0,0 +1,128 @@</span>
<span class="quote">&gt;&gt; +#include &lt;linux/types.h&gt;</span>
<span class="quote">&gt;&gt; +#include &lt;linux/hyperv.h&gt;</span>
<span class="quote">&gt;&gt; +#include &lt;linux/slab.h&gt;</span>
<span class="quote">&gt;&gt; +#include &lt;asm/mshyperv.h&gt;</span>
<span class="quote">&gt;&gt; +#include &lt;asm/tlbflush.h&gt;</span>
<span class="quote">&gt;&gt; +#include &lt;asm/msr.h&gt;</span>
<span class="quote">&gt;&gt; +#include &lt;asm/fpu/api.h&gt;</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +/*</span>
<span class="quote">&gt;&gt; + * Arbitrary number; we need to pre-allocate per-cpu struct for doing TLB</span>
<span class="quote">&gt;&gt; + * flush hypercalls and we need to pick a size. &#39;16&#39; means we&#39;ll be able</span>
<span class="quote">&gt;&gt; + * to flush 16 * 4096 pages (256MB) with one hypercall.</span>
<span class="quote">&gt;&gt; + */</span>
<span class="quote">&gt;&gt; +#define HV_MMU_MAX_GVAS 16</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; Did you experiment with different sizes here.</span>

Actually, I was never able to see kernel trying to flush more than 4096
pages so we can get away with HV_MMU_MAX_GVAS=1. I went through the code
and didn&#39;t see any &#39;limit&#39; for the number of pages we can ask to flush
so it can be a coincidence. Each addition gva_list item requires 8 bytes
only so I put and arbitrary &#39;16&#39; here.
<span class="quote">
&gt;&gt; +</span>
<span class="quote">&gt;&gt; +/* HvFlushVirtualAddressSpace*, HvFlushVirtualAddressList hypercalls */</span>
<span class="quote">&gt;&gt; +struct hv_flush_pcpu {</span>
<span class="quote">&gt;&gt; +	struct {</span>
<span class="quote">&gt;&gt; +		__u64 address_space;</span>
<span class="quote">&gt;&gt; +		__u64 flags;</span>
<span class="quote">&gt;&gt; +		__u64 processor_mask;</span>
<span class="quote">&gt;&gt; +		__u64 gva_list[HV_MMU_MAX_GVAS];</span>
<span class="quote">&gt;&gt; +	} flush;</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +	spinlock_t lock;</span>
<span class="quote">&gt;&gt; +};</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt; We may be supporting more than 64 CPUs in this hypercall. I am going to inquire with</span>
<span class="quote">&gt; the Windows folks and get back to you.</span>

Thanks! It is even specified in the specification:
&quot;Future versions of the hypervisor may support more than 64 virtual processors per partition. In that
case, a new field will be added to the flags value that allows the caller to define the “processor bank” to
which the processor mask applies.&quot;

We, however, need to know where to put this in flags.
<span class="quote">
&gt;</span>
<span class="quote">&gt;&gt; +static struct hv_flush_pcpu __percpu *pcpu_flush;</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +static void hyperv_flush_tlb_others(const struct cpumask *cpus,</span>
<span class="quote">&gt;&gt; +				    struct mm_struct *mm, unsigned long</span>
<span class="quote">&gt;&gt; start,</span>
<span class="quote">&gt;&gt; +				    unsigned long end)</span>
<span class="quote">&gt;&gt; +{</span>
<span class="quote">&gt;&gt; +	struct hv_flush_pcpu *flush;</span>
<span class="quote">&gt;&gt; +	unsigned long cur, flags;</span>
<span class="quote">&gt;&gt; +	u64 status = -1ULL;</span>
<span class="quote">&gt;&gt; +	int cpu, vcpu, gva_n;</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +	if (!pcpu_flush || !hv_hypercall_pg)</span>
<span class="quote">&gt;&gt; +		goto do_native;</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +	if (cpumask_empty(cpus))</span>
<span class="quote">&gt;&gt; +		return;</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +	flush = this_cpu_ptr(pcpu_flush);</span>
<span class="quote">&gt;&gt; +	spin_lock_irqsave(&amp;flush-&gt;lock, flags);</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +	flush-&gt;flush.address_space = virt_to_phys(mm-&gt;pgd);</span>
<span class="quote">&gt;&gt; +	flush-&gt;flush.processor_mask = 0;</span>
<span class="quote">&gt;&gt; +	if (cpumask_equal(cpus, cpu_present_mask)) {</span>
<span class="quote">&gt;&gt; +		flush-&gt;flush.flags = HV_FLUSH_ALL_PROCESSORS;</span>
<span class="quote">&gt;&gt; +	} else {</span>
<span class="quote">&gt;&gt; +		flush-&gt;flush.flags = 0;</span>
<span class="quote">&gt;&gt; +		for_each_cpu(cpu, cpus) {</span>
<span class="quote">&gt;&gt; +			vcpu = vmbus_cpu_number_to_vp_number(cpu);</span>
<span class="quote">&gt;&gt; +			if (vcpu != -1 &amp;&amp; vcpu &lt; 64)</span>
<span class="quote">&gt;&gt; +				flush-&gt;flush.processor_mask |= 1 &lt;&lt; vcpu;</span>
<span class="quote">&gt;&gt; +			else</span>
<span class="quote">&gt;&gt; +				goto unlock_do_native;</span>
<span class="quote">&gt;&gt; +		}</span>
<span class="quote">&gt;&gt; +	}</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +	if (end == TLB_FLUSH_ALL) {</span>
<span class="quote">&gt;&gt; +		flush-&gt;flush.flags =</span>
<span class="quote">&gt;&gt; HV_FLUSH_NON_GLOBAL_MAPPINGS_ONLY;</span>
<span class="quote">&gt;&gt; +		status =</span>
<span class="quote">&gt;&gt; hv_do_hypercall(HVCALL_FLUSH_VIRTUAL_ADDRESS_SPACE,</span>
<span class="quote">&gt;&gt; +					 &amp;flush-&gt;flush, NULL);</span>
<span class="quote">&gt;&gt; +	} else {</span>
<span class="quote">&gt;&gt; +		cur = start;</span>
<span class="quote">&gt;&gt; +more_gvas:</span>
<span class="quote">&gt;&gt; +		gva_n = 0;</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +		do {</span>
<span class="quote">&gt;&gt; +			flush-&gt;flush.gva_list[gva_n] = cur &amp; PAGE_MASK;</span>
<span class="quote">&gt;&gt; +			/*</span>
<span class="quote">&gt;&gt; +			 * Lower 12 bits encode the number of additional</span>
<span class="quote">&gt;&gt; +			 * pages to flush (in addition to the &#39;cur&#39; page).</span>
<span class="quote">&gt;&gt; +			 */</span>
<span class="quote">&gt;&gt; +			if (end &gt;= cur + PAGE_SIZE * PAGE_SIZE)</span>
<span class="quote">&gt;&gt; +				flush-&gt;flush.gva_list[gva_n] |=</span>
<span class="quote">&gt;&gt; ~PAGE_MASK;</span>
<span class="quote">&gt;&gt; +			else if (end &gt; cur)</span>
<span class="quote">&gt;&gt; +				flush-&gt;flush.gva_list[gva_n] |=</span>
<span class="quote">&gt;&gt; +					(end - cur - 1) &gt;&gt; PAGE_SHIFT;</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +			cur += PAGE_SIZE * PAGE_SIZE;</span>
<span class="quote">&gt;&gt; +			++gva_n;</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +		} while (cur &lt; end &amp;&amp; gva_n &lt; HV_MMU_MAX_GVAS);</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +		status =</span>
<span class="quote">&gt;&gt; hv_do_rep_hypercall(HVCALL_FLUSH_VIRTUAL_ADDRESS_LIST,</span>
<span class="quote">&gt;&gt; +					     gva_n, &amp;flush-&gt;flush, NULL);</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +		if (!(status &amp; 0xffff) &amp;&amp; cur &lt; end)</span>
<span class="quote">&gt;&gt; +			goto more_gvas;</span>
<span class="quote">&gt;&gt; +	}</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +unlock_do_native:</span>
<span class="quote">&gt;&gt; +	spin_unlock_irqrestore(&amp;flush-&gt;lock, flags);</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +	if (!(status &amp; 0xffff))</span>
<span class="quote">&gt;&gt; +		return;</span>
<span class="quote">&gt;&gt; +do_native:</span>
<span class="quote">&gt;&gt; +	native_flush_tlb_others(cpus, mm, start, end);</span>
<span class="quote">&gt;&gt; +}</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +void hyperv_setup_mmu_ops(void)</span>
<span class="quote">&gt;&gt; +{</span>
<span class="quote">&gt;&gt; +	if (ms_hyperv.hints &amp;</span>
<span class="quote">&gt;&gt; HV_X64_REMOTE_TLB_FLUSH_RECOMMENDED) {</span>
<span class="quote">&gt;&gt; +		pr_info(&quot;Hyper-V: Using hypercall for remote TLB flush\n&quot;);</span>
<span class="quote">&gt;&gt; +		pv_mmu_ops.flush_tlb_others = hyperv_flush_tlb_others;</span>
<span class="quote">&gt;&gt; +	}</span>
<span class="quote">&gt;&gt; +}</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +void hyper_alloc_mmu(void)</span>
<span class="quote">&gt;&gt; +{</span>
<span class="quote">&gt;&gt; +	int cpu;</span>
<span class="quote">&gt;&gt; +	struct hv_flush_pcpu *flush;</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +	if (ms_hyperv.hints &amp;</span>
<span class="quote">&gt;&gt; HV_X64_REMOTE_TLB_FLUSH_RECOMMENDED) {</span>
<span class="quote">&gt;&gt; +		pcpu_flush = alloc_percpu(struct hv_flush_pcpu);</span>
<span class="quote">&gt;&gt; +		if (!pcpu_flush)</span>
<span class="quote">&gt;&gt; +			return;</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +		for_each_possible_cpu(cpu) {</span>
<span class="quote">&gt;&gt; +			flush = per_cpu_ptr(pcpu_flush, cpu);</span>
<span class="quote">&gt;&gt; +			spin_lock_init(&amp;flush-&gt;lock);</span>
<span class="quote">&gt;&gt; +		}</span>
<span class="quote">&gt;&gt; +	}</span>
<span class="quote">&gt;&gt; +}</span>
<span class="quote">&gt;&gt; diff --git a/arch/x86/include/asm/mshyperv.h</span>
<span class="quote">&gt;&gt; b/arch/x86/include/asm/mshyperv.h</span>
<span class="quote">&gt;&gt; index 1293c84..a5041c3 100644</span>
<span class="quote">&gt;&gt; --- a/arch/x86/include/asm/mshyperv.h</span>
<span class="quote">&gt;&gt; +++ b/arch/x86/include/asm/mshyperv.h</span>
<span class="quote">&gt;&gt; @@ -301,6 +301,8 @@ static inline int</span>
<span class="quote">&gt;&gt; vmbus_cpu_number_to_vp_number(int cpu_number)</span>
<span class="quote">&gt;&gt;  }</span>
<span class="quote">&gt;&gt; </span>
<span class="quote">&gt;&gt;  void hyperv_init(void);</span>
<span class="quote">&gt;&gt; +void hyperv_setup_mmu_ops(void);</span>
<span class="quote">&gt;&gt; +void hyper_alloc_mmu(void);</span>
<span class="quote">&gt;&gt;  void hyperv_report_panic(struct pt_regs *regs);</span>
<span class="quote">&gt;&gt;  bool hv_is_hypercall_page_setup(void);</span>
<span class="quote">&gt;&gt;  void hyperv_cleanup(void);</span>
<span class="quote">&gt;&gt; diff --git a/arch/x86/include/uapi/asm/hyperv.h</span>
<span class="quote">&gt;&gt; b/arch/x86/include/uapi/asm/hyperv.h</span>
<span class="quote">&gt;&gt; index c87e900..3d44036 100644</span>
<span class="quote">&gt;&gt; --- a/arch/x86/include/uapi/asm/hyperv.h</span>
<span class="quote">&gt;&gt; +++ b/arch/x86/include/uapi/asm/hyperv.h</span>
<span class="quote">&gt;&gt; @@ -239,6 +239,8 @@</span>
<span class="quote">&gt;&gt;  		(~((1ull &lt;&lt;</span>
<span class="quote">&gt;&gt; HV_X64_MSR_HYPERCALL_PAGE_ADDRESS_SHIFT) - 1))</span>
<span class="quote">&gt;&gt; </span>
<span class="quote">&gt;&gt;  /* Declare the various hypercall operations. */</span>
<span class="quote">&gt;&gt; +#define HVCALL_FLUSH_VIRTUAL_ADDRESS_SPACE	0x0002</span>
<span class="quote">&gt;&gt; +#define HVCALL_FLUSH_VIRTUAL_ADDRESS_LIST	0x0003</span>
<span class="quote">&gt;&gt;  #define HVCALL_NOTIFY_LONG_SPIN_WAIT		0x0008</span>
<span class="quote">&gt;&gt;  #define HVCALL_POST_MESSAGE			0x005c</span>
<span class="quote">&gt;&gt;  #define HVCALL_SIGNAL_EVENT			0x005d</span>
<span class="quote">&gt;&gt; @@ -256,6 +258,11 @@</span>
<span class="quote">&gt;&gt;  #define HV_PROCESSOR_POWER_STATE_C2		2</span>
<span class="quote">&gt;&gt;  #define HV_PROCESSOR_POWER_STATE_C3		3</span>
<span class="quote">&gt;&gt; </span>
<span class="quote">&gt;&gt; +#define HV_FLUSH_ALL_PROCESSORS			0x00000001</span>
<span class="quote">&gt;&gt; +#define HV_FLUSH_ALL_VIRTUAL_ADDRESS_SPACES	0x00000002</span>
<span class="quote">&gt;&gt; +#define HV_FLUSH_NON_GLOBAL_MAPPINGS_ONLY	0x00000004</span>
<span class="quote">&gt;&gt; +#define HV_FLUSH_USE_EXTENDED_RANGE_FORMAT	0x00000008</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt;  /* Hypercall interface */</span>
<span class="quote">&gt;&gt;  union hv_hypercall_input {</span>
<span class="quote">&gt;&gt;  	u64 as_uint64;</span>
<span class="quote">&gt;&gt; diff --git a/arch/x86/kernel/cpu/mshyperv.c</span>
<span class="quote">&gt;&gt; b/arch/x86/kernel/cpu/mshyperv.c</span>
<span class="quote">&gt;&gt; index 04cb8d3..fc228d8 100644</span>
<span class="quote">&gt;&gt; --- a/arch/x86/kernel/cpu/mshyperv.c</span>
<span class="quote">&gt;&gt; +++ b/arch/x86/kernel/cpu/mshyperv.c</span>
<span class="quote">&gt;&gt; @@ -233,6 +233,7 @@ static void __init ms_hyperv_init_platform(void)</span>
<span class="quote">&gt;&gt;  	 * Setup the hook to get control post apic initialization.</span>
<span class="quote">&gt;&gt;  	 */</span>
<span class="quote">&gt;&gt;  	x86_platform.apic_post_init = hyperv_init;</span>
<span class="quote">&gt;&gt; +	hyperv_setup_mmu_ops();</span>
<span class="quote">&gt;&gt;  #endif</span>
<span class="quote">&gt;&gt;  }</span>
<span class="quote">&gt;&gt; </span>
<span class="quote">&gt;&gt; --</span>
<span class="quote">&gt;&gt; 2.9.3</span>
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=99981">Vitaly Kuznetsov</a> - April 10, 2017, 5:21 p.m.</div>
<pre class="content">
Jork Loeser &lt;Jork.Loeser@microsoft.com&gt; writes:
<span class="quote">
&gt;&gt; -----Original Message-----</span>
<span class="quote">&gt;&gt; From: Vitaly Kuznetsov [mailto:vkuznets@redhat.com]</span>
<span class="quote">&gt;&gt; Sent: Friday, April 7, 2017 04:27</span>
<span class="quote">&gt;&gt; To: devel@linuxdriverproject.org; x86@kernel.org</span>
<span class="quote">&gt;&gt; Cc: linux-kernel@vger.kernel.org; KY Srinivasan &lt;kys@microsoft.com&gt;;</span>
<span class="quote">&gt;&gt; Haiyang Zhang &lt;haiyangz@microsoft.com&gt;; Stephen Hemminger</span>
<span class="quote">&gt;&gt; &lt;sthemmin@microsoft.com&gt;; Thomas Gleixner &lt;tglx@linutronix.de&gt;; Ingo</span>
<span class="quote">&gt;&gt; Molnar &lt;mingo@redhat.com&gt;; H. Peter Anvin &lt;hpa@zytor.com&gt;; Steven</span>
<span class="quote">&gt;&gt; Rostedt &lt;rostedt@goodmis.org&gt;; Jork Loeser &lt;Jork.Loeser@microsoft.com&gt;</span>
<span class="quote">&gt;&gt; Subject: [PATCH 6/7] x86/hyper-v: use hypercall for remove TLB flush</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;&gt; diff --git a/arch/x86/hyperv/mmu.c b/arch/x86/hyperv/mmu.c new file</span>
<span class="quote">&gt;&gt; mode 100644 index 0000000..fb487cb</span>
<span class="quote">&gt;&gt; --- /dev/null</span>
<span class="quote">&gt;&gt; +++ b/arch/x86/hyperv/mmu.c</span>
<span class="quote">&gt;&gt; @@ -0,0 +1,128 @@</span>
<span class="quote">&gt;&gt; +#include &lt;linux/types.h&gt;</span>
<span class="quote">&gt;&gt; +#include &lt;linux/hyperv.h&gt;</span>
<span class="quote">&gt;&gt; +#include &lt;linux/slab.h&gt;</span>
<span class="quote">&gt;&gt; +#include &lt;asm/mshyperv.h&gt;</span>
<span class="quote">&gt;&gt; +#include &lt;asm/tlbflush.h&gt;</span>
<span class="quote">&gt;&gt; +#include &lt;asm/msr.h&gt;</span>
<span class="quote">&gt;&gt; +#include &lt;asm/fpu/api.h&gt;</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +/*</span>
<span class="quote">&gt;&gt; + * Arbitrary number; we need to pre-allocate per-cpu struct for doing</span>
<span class="quote">&gt;&gt; +TLB</span>
<span class="quote">&gt;&gt; + * flush hypercalls and we need to pick a size. &#39;16&#39; means we&#39;ll be</span>
<span class="quote">&gt;&gt; +able</span>
<span class="quote">&gt;&gt; + * to flush 16 * 4096 pages (256MB) with one hypercall.</span>
<span class="quote">&gt;&gt; + */</span>
<span class="quote">&gt;&gt; +#define HV_MMU_MAX_GVAS 16</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +/* HvFlushVirtualAddressSpace*, HvFlushVirtualAddressList hypercalls */</span>
<span class="quote">&gt;&gt; +struct hv_flush_pcpu {</span>
<span class="quote">&gt;&gt; +	struct {</span>
<span class="quote">&gt;&gt; +		__u64 address_space;</span>
<span class="quote">&gt;&gt; +		__u64 flags;</span>
<span class="quote">&gt;&gt; +		__u64 processor_mask;</span>
<span class="quote">&gt;&gt; +		__u64 gva_list[HV_MMU_MAX_GVAS];</span>
<span class="quote">&gt;&gt; +	} flush;</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +	spinlock_t lock;</span>
<span class="quote">&gt;&gt; +};</span>
<span class="quote">&gt; Does this need an alignment declaration, so that the flush portion never crosses a page boundary when allocated with alloc_percpu()?</span>
<span class="quote">&gt;</span>

Thanks for pointing this out! I would slightly prefer we use
__alloc_percpu() and specify something like roundup_pow_of_two()
alignment.
<span class="quote">
&gt;&gt; +</span>
<span class="quote">&gt;&gt; +static struct hv_flush_pcpu __percpu *pcpu_flush;</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +static void hyperv_flush_tlb_others(const struct cpumask *cpus,</span>
<span class="quote">&gt;&gt; +				    struct mm_struct *mm, unsigned long</span>
<span class="quote">&gt;&gt; start,</span>
<span class="quote">&gt;&gt; +				    unsigned long end)</span>
<span class="quote">&gt;&gt; +{</span>
<span class="quote">&gt;&gt; +	struct hv_flush_pcpu *flush;</span>
<span class="quote">&gt;&gt; +	unsigned long cur, flags;</span>
<span class="quote">&gt;&gt; +	u64 status = -1ULL;</span>
<span class="quote">&gt;&gt; +	int cpu, vcpu, gva_n;</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +	if (!pcpu_flush || !hv_hypercall_pg)</span>
<span class="quote">&gt;&gt; +		goto do_native;</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +	if (cpumask_empty(cpus))</span>
<span class="quote">&gt;&gt; +		return;</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +	flush = this_cpu_ptr(pcpu_flush);</span>
<span class="quote">&gt;&gt; +	spin_lock_irqsave(&amp;flush-&gt;lock, flags);</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; What purpose does the spinlock on the CPU-local struct serve? Would a</span>
<span class="quote">&gt; local_irq_save() do?</span>

Now I&#39;m not sure why I put it here in the first place :-) Yes, it would
probably do.
<span class="quote">
&gt; Could this be called from NMI context, such as from the debugger?</span>
<span class="quote">&gt;</span>

NMI - I don&#39;t think so, native function does smp_call_function_many()
which WARNs even if it&#39;s called with interrupts disabled.
<span class="quote">
&gt; Could this be a long-running loop, e.g. due to a large start/end</span>
<span class="quote">&gt; range? If so, consider disabling interrupts only in the inner loop /</span>
<span class="quote">&gt; flush the entire space?</span>

The decision for flushing the entire space should probably be done
elsewhere as it is not implementation-specific (and I think it&#39;s done
somewhere as I never see requests to flush more than 4096 pages in my
testing).

I can disable interrupts in the inner loop but we&#39;ll have to stash flags
and calculated cpu_mask to some local variables. This is not supposed to
be expensive.
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=173691">Jork Loeser</a> - April 10, 2017, 5:34 p.m.</div>
<pre class="content">
<span class="quote">&gt; -----Original Message-----</span>
<span class="quote">&gt; From: Vitaly Kuznetsov [mailto:vkuznets@redhat.com]</span>
<span class="quote">
&gt; &gt; We may be supporting more than 64 CPUs in this hypercall. I am going</span>
<span class="quote">&gt; &gt; to inquire with the Windows folks and get back to you.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Thanks! It is even specified in the specification:</span>
<span class="quote">&gt; &quot;Future versions of the hypervisor may support more than 64 virtual</span>
<span class="quote">&gt; processors per partition. In that case, a new field will be added to the flags</span>
<span class="quote">&gt; value that allows the caller to define the “processor bank” to which the</span>
<span class="quote">&gt; processor mask applies.&quot;</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; We, however, need to know where to put this in flags.</span>

Would the HvFlushVirtualAddressListEx hypercall do? Is there a doc update/clarification needed?

Regards,
Jork
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=22291">K. Y. Srinivasan</a> - April 10, 2017, 10:03 p.m.</div>
<pre class="content">
<span class="quote">&gt; -----Original Message-----</span>
<span class="quote">&gt; From: Vitaly Kuznetsov [mailto:vkuznets@redhat.com]</span>
<span class="quote">&gt; Sent: Monday, April 10, 2017 7:44 AM</span>
<span class="quote">&gt; To: KY Srinivasan &lt;kys@microsoft.com&gt;</span>
<span class="quote">&gt; Cc: devel@linuxdriverproject.org; x86@kernel.org; linux-</span>
<span class="quote">&gt; kernel@vger.kernel.org; Haiyang Zhang &lt;haiyangz@microsoft.com&gt;;</span>
<span class="quote">&gt; Stephen Hemminger &lt;sthemmin@microsoft.com&gt;; Thomas Gleixner</span>
<span class="quote">&gt; &lt;tglx@linutronix.de&gt;; Ingo Molnar &lt;mingo@redhat.com&gt;; H. Peter Anvin</span>
<span class="quote">&gt; &lt;hpa@zytor.com&gt;; Steven Rostedt &lt;rostedt@goodmis.org&gt;; Jork Loeser</span>
<span class="quote">&gt; &lt;Jork.Loeser@microsoft.com&gt;</span>
<span class="quote">&gt; Subject: Re: [PATCH 6/7] x86/hyper-v: use hypercall for remove TLB flush</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; KY Srinivasan &lt;kys@microsoft.com&gt; writes:</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; &gt;&gt; -----Original Message-----</span>
<span class="quote">&gt; &gt;&gt; From: Vitaly Kuznetsov [mailto:vkuznets@redhat.com]</span>
<span class="quote">&gt; &gt;&gt; Sent: Friday, April 7, 2017 4:27 AM</span>
<span class="quote">&gt; &gt;&gt; To: devel@linuxdriverproject.org; x86@kernel.org</span>
<span class="quote">&gt; &gt;&gt; Cc: linux-kernel@vger.kernel.org; KY Srinivasan &lt;kys@microsoft.com&gt;;</span>
<span class="quote">&gt; &gt;&gt; Haiyang Zhang &lt;haiyangz@microsoft.com&gt;; Stephen Hemminger</span>
<span class="quote">&gt; &gt;&gt; &lt;sthemmin@microsoft.com&gt;; Thomas Gleixner &lt;tglx@linutronix.de&gt;;</span>
<span class="quote">&gt; Ingo</span>
<span class="quote">&gt; &gt;&gt; Molnar &lt;mingo@redhat.com&gt;; H. Peter Anvin &lt;hpa@zytor.com&gt;; Steven</span>
<span class="quote">&gt; &gt;&gt; Rostedt &lt;rostedt@goodmis.org&gt;; Jork Loeser</span>
<span class="quote">&gt; &lt;Jork.Loeser@microsoft.com&gt;</span>
<span class="quote">&gt; &gt;&gt; Subject: [PATCH 6/7] x86/hyper-v: use hypercall for remove TLB flush</span>
<span class="quote">&gt; &gt;&gt;</span>
<span class="quote">&gt; &gt;&gt; Hyper-V host can suggest us to use hypercall for doing remote TLB flush,</span>
<span class="quote">&gt; &gt;&gt; this is supposed to work faster than IPIs.</span>
<span class="quote">&gt; &gt;&gt;</span>
<span class="quote">&gt; &gt;&gt; Implementation details: to do HvFlushVirtualAddress{Space,List}</span>
<span class="quote">&gt; hypercalls</span>
<span class="quote">&gt; &gt;&gt; we need to put the input somewhere in memory and we don&#39;t really</span>
<span class="quote">&gt; want to</span>
<span class="quote">&gt; &gt;&gt; have memory allocation on each call so we pre-allocate per cpu memory</span>
<span class="quote">&gt; &gt;&gt; areas</span>
<span class="quote">&gt; &gt;&gt; on boot. These areas are of fixes size, limit them with an arbitrary number</span>
<span class="quote">&gt; &gt;&gt; of 16 (16 gvas are able to specify 16 * 4096 pages).</span>
<span class="quote">&gt; &gt;&gt;</span>
<span class="quote">&gt; &gt;&gt; pv_ops patching is happening very early so we need to separate</span>
<span class="quote">&gt; &gt;&gt; hyperv_setup_mmu_ops() and hyper_alloc_mmu().</span>
<span class="quote">&gt; &gt;&gt;</span>
<span class="quote">&gt; &gt;&gt; It is possible and easy to implement local TLB flushing too and there is</span>
<span class="quote">&gt; &gt;&gt; even a hint for that. However, I don&#39;t see a room for optimization on the</span>
<span class="quote">&gt; &gt;&gt; host side as both hypercall and native tlb flush will result in vmexit. The</span>
<span class="quote">&gt; &gt;&gt; hint is also not set on modern Hyper-V versions.</span>
<span class="quote">&gt; &gt;&gt;</span>
<span class="quote">&gt; &gt;&gt; Signed-off-by: Vitaly Kuznetsov &lt;vkuznets@redhat.com&gt;</span>
<span class="quote">&gt; &gt;&gt; ---</span>
<span class="quote">&gt; &gt;&gt;  arch/x86/hyperv/Makefile           |   2 +-</span>
<span class="quote">&gt; &gt;&gt;  arch/x86/hyperv/hv_init.c          |   2 +</span>
<span class="quote">&gt; &gt;&gt;  arch/x86/hyperv/mmu.c              | 128</span>
<span class="quote">&gt; &gt;&gt; +++++++++++++++++++++++++++++++++++++</span>
<span class="quote">&gt; &gt;&gt;  arch/x86/include/asm/mshyperv.h    |   2 +</span>
<span class="quote">&gt; &gt;&gt;  arch/x86/include/uapi/asm/hyperv.h |   7 ++</span>
<span class="quote">&gt; &gt;&gt;  arch/x86/kernel/cpu/mshyperv.c     |   1 +</span>
<span class="quote">&gt; &gt;&gt;  6 files changed, 141 insertions(+), 1 deletion(-)</span>
<span class="quote">&gt; &gt;&gt;  create mode 100644 arch/x86/hyperv/mmu.c</span>
<span class="quote">&gt; &gt;&gt;</span>
<span class="quote">&gt; &gt;&gt; diff --git a/arch/x86/hyperv/Makefile b/arch/x86/hyperv/Makefile</span>
<span class="quote">&gt; &gt;&gt; index 171ae09..367a820 100644</span>
<span class="quote">&gt; &gt;&gt; --- a/arch/x86/hyperv/Makefile</span>
<span class="quote">&gt; &gt;&gt; +++ b/arch/x86/hyperv/Makefile</span>
<span class="quote">&gt; &gt;&gt; @@ -1 +1 @@</span>
<span class="quote">&gt; &gt;&gt; -obj-y		:= hv_init.o</span>
<span class="quote">&gt; &gt;&gt; +obj-y		:= hv_init.o mmu.o</span>
<span class="quote">&gt; &gt;&gt; diff --git a/arch/x86/hyperv/hv_init.c b/arch/x86/hyperv/hv_init.c</span>
<span class="quote">&gt; &gt;&gt; index 1c14088..2cf8a98 100644</span>
<span class="quote">&gt; &gt;&gt; --- a/arch/x86/hyperv/hv_init.c</span>
<span class="quote">&gt; &gt;&gt; +++ b/arch/x86/hyperv/hv_init.c</span>
<span class="quote">&gt; &gt;&gt; @@ -163,6 +163,8 @@ void hyperv_init(void)</span>
<span class="quote">&gt; &gt;&gt;  	hypercall_msr.guest_physical_address =</span>
<span class="quote">&gt; &gt;&gt; vmalloc_to_pfn(hv_hypercall_pg);</span>
<span class="quote">&gt; &gt;&gt;  	wrmsrl(HV_X64_MSR_HYPERCALL, hypercall_msr.as_uint64);</span>
<span class="quote">&gt; &gt;&gt;</span>
<span class="quote">&gt; &gt;&gt; +	hyper_alloc_mmu();</span>
<span class="quote">&gt; &gt;&gt; +</span>
<span class="quote">&gt; &gt;&gt;  	/*</span>
<span class="quote">&gt; &gt;&gt;  	 * Register Hyper-V specific clocksource.</span>
<span class="quote">&gt; &gt;&gt;  	 */</span>
<span class="quote">&gt; &gt;&gt; diff --git a/arch/x86/hyperv/mmu.c b/arch/x86/hyperv/mmu.c</span>
<span class="quote">&gt; &gt;&gt; new file mode 100644</span>
<span class="quote">&gt; &gt;&gt; index 0000000..fb487cb</span>
<span class="quote">&gt; &gt;&gt; --- /dev/null</span>
<span class="quote">&gt; &gt;&gt; +++ b/arch/x86/hyperv/mmu.c</span>
<span class="quote">&gt; &gt;&gt; @@ -0,0 +1,128 @@</span>
<span class="quote">&gt; &gt;&gt; +#include &lt;linux/types.h&gt;</span>
<span class="quote">&gt; &gt;&gt; +#include &lt;linux/hyperv.h&gt;</span>
<span class="quote">&gt; &gt;&gt; +#include &lt;linux/slab.h&gt;</span>
<span class="quote">&gt; &gt;&gt; +#include &lt;asm/mshyperv.h&gt;</span>
<span class="quote">&gt; &gt;&gt; +#include &lt;asm/tlbflush.h&gt;</span>
<span class="quote">&gt; &gt;&gt; +#include &lt;asm/msr.h&gt;</span>
<span class="quote">&gt; &gt;&gt; +#include &lt;asm/fpu/api.h&gt;</span>
<span class="quote">&gt; &gt;&gt; +</span>
<span class="quote">&gt; &gt;&gt; +/*</span>
<span class="quote">&gt; &gt;&gt; + * Arbitrary number; we need to pre-allocate per-cpu struct for doing</span>
<span class="quote">&gt; TLB</span>
<span class="quote">&gt; &gt;&gt; + * flush hypercalls and we need to pick a size. &#39;16&#39; means we&#39;ll be able</span>
<span class="quote">&gt; &gt;&gt; + * to flush 16 * 4096 pages (256MB) with one hypercall.</span>
<span class="quote">&gt; &gt;&gt; + */</span>
<span class="quote">&gt; &gt;&gt; +#define HV_MMU_MAX_GVAS 16</span>
<span class="quote">&gt; &gt;</span>
<span class="quote">&gt; &gt; Did you experiment with different sizes here.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Actually, I was never able to see kernel trying to flush more than 4096</span>
<span class="quote">&gt; pages so we can get away with HV_MMU_MAX_GVAS=1. I went through the</span>
<span class="quote">&gt; code</span>
<span class="quote">&gt; and didn&#39;t see any &#39;limit&#39; for the number of pages we can ask to flush</span>
<span class="quote">&gt; so it can be a coincidence. Each addition gva_list item requires 8 bytes</span>
<span class="quote">&gt; only so I put and arbitrary &#39;16&#39; here.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; &gt;&gt; +</span>
<span class="quote">&gt; &gt;&gt; +/* HvFlushVirtualAddressSpace*, HvFlushVirtualAddressList hypercalls</span>
<span class="quote">&gt; */</span>
<span class="quote">&gt; &gt;&gt; +struct hv_flush_pcpu {</span>
<span class="quote">&gt; &gt;&gt; +	struct {</span>
<span class="quote">&gt; &gt;&gt; +		__u64 address_space;</span>
<span class="quote">&gt; &gt;&gt; +		__u64 flags;</span>
<span class="quote">&gt; &gt;&gt; +		__u64 processor_mask;</span>
<span class="quote">&gt; &gt;&gt; +		__u64 gva_list[HV_MMU_MAX_GVAS];</span>
<span class="quote">&gt; &gt;&gt; +	} flush;</span>
<span class="quote">&gt; &gt;&gt; +</span>
<span class="quote">&gt; &gt;&gt; +	spinlock_t lock;</span>
<span class="quote">&gt; &gt;&gt; +};</span>
<span class="quote">&gt; &gt;&gt; +</span>
<span class="quote">&gt; &gt; We may be supporting more than 64 CPUs in this hypercall. I am going to</span>
<span class="quote">&gt; inquire with</span>
<span class="quote">&gt; &gt; the Windows folks and get back to you.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Thanks! It is even specified in the specification:</span>
<span class="quote">&gt; &quot;Future versions of the hypervisor may support more than 64 virtual</span>
<span class="quote">&gt; processors per partition. In that</span>
<span class="quote">&gt; case, a new field will be added to the flags value that allows the caller to</span>
<span class="quote">&gt; define the “processor bank” to</span>
<span class="quote">&gt; which the processor mask applies.&quot;</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; We, however, need to know where to put this in flags.</span>

There is a new Hypercall for targeting more than 64 VCPUs. For now, we can check if the CPU mask
Is specifying more than 64 CPUs and use native call if that is the case.

K. Y
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/arch/x86/hyperv/Makefile b/arch/x86/hyperv/Makefile</span>
<span class="p_header">index 171ae09..367a820 100644</span>
<span class="p_header">--- a/arch/x86/hyperv/Makefile</span>
<span class="p_header">+++ b/arch/x86/hyperv/Makefile</span>
<span class="p_chunk">@@ -1 +1 @@</span> <span class="p_context"></span>
<span class="p_del">-obj-y		:= hv_init.o</span>
<span class="p_add">+obj-y		:= hv_init.o mmu.o</span>
<span class="p_header">diff --git a/arch/x86/hyperv/hv_init.c b/arch/x86/hyperv/hv_init.c</span>
<span class="p_header">index 1c14088..2cf8a98 100644</span>
<span class="p_header">--- a/arch/x86/hyperv/hv_init.c</span>
<span class="p_header">+++ b/arch/x86/hyperv/hv_init.c</span>
<span class="p_chunk">@@ -163,6 +163,8 @@</span> <span class="p_context"> void hyperv_init(void)</span>
 	hypercall_msr.guest_physical_address = vmalloc_to_pfn(hv_hypercall_pg);
 	wrmsrl(HV_X64_MSR_HYPERCALL, hypercall_msr.as_uint64);
 
<span class="p_add">+	hyper_alloc_mmu();</span>
<span class="p_add">+</span>
 	/*
 	 * Register Hyper-V specific clocksource.
 	 */
<span class="p_header">diff --git a/arch/x86/hyperv/mmu.c b/arch/x86/hyperv/mmu.c</span>
new file mode 100644
<span class="p_header">index 0000000..fb487cb</span>
<span class="p_header">--- /dev/null</span>
<span class="p_header">+++ b/arch/x86/hyperv/mmu.c</span>
<span class="p_chunk">@@ -0,0 +1,128 @@</span> <span class="p_context"></span>
<span class="p_add">+#include &lt;linux/types.h&gt;</span>
<span class="p_add">+#include &lt;linux/hyperv.h&gt;</span>
<span class="p_add">+#include &lt;linux/slab.h&gt;</span>
<span class="p_add">+#include &lt;asm/mshyperv.h&gt;</span>
<span class="p_add">+#include &lt;asm/tlbflush.h&gt;</span>
<span class="p_add">+#include &lt;asm/msr.h&gt;</span>
<span class="p_add">+#include &lt;asm/fpu/api.h&gt;</span>
<span class="p_add">+</span>
<span class="p_add">+/*</span>
<span class="p_add">+ * Arbitrary number; we need to pre-allocate per-cpu struct for doing TLB</span>
<span class="p_add">+ * flush hypercalls and we need to pick a size. &#39;16&#39; means we&#39;ll be able</span>
<span class="p_add">+ * to flush 16 * 4096 pages (256MB) with one hypercall.</span>
<span class="p_add">+ */</span>
<span class="p_add">+#define HV_MMU_MAX_GVAS 16</span>
<span class="p_add">+</span>
<span class="p_add">+/* HvFlushVirtualAddressSpace*, HvFlushVirtualAddressList hypercalls */</span>
<span class="p_add">+struct hv_flush_pcpu {</span>
<span class="p_add">+	struct {</span>
<span class="p_add">+		__u64 address_space;</span>
<span class="p_add">+		__u64 flags;</span>
<span class="p_add">+		__u64 processor_mask;</span>
<span class="p_add">+		__u64 gva_list[HV_MMU_MAX_GVAS];</span>
<span class="p_add">+	} flush;</span>
<span class="p_add">+</span>
<span class="p_add">+	spinlock_t lock;</span>
<span class="p_add">+};</span>
<span class="p_add">+</span>
<span class="p_add">+static struct hv_flush_pcpu __percpu *pcpu_flush;</span>
<span class="p_add">+</span>
<span class="p_add">+static void hyperv_flush_tlb_others(const struct cpumask *cpus,</span>
<span class="p_add">+				    struct mm_struct *mm, unsigned long start,</span>
<span class="p_add">+				    unsigned long end)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct hv_flush_pcpu *flush;</span>
<span class="p_add">+	unsigned long cur, flags;</span>
<span class="p_add">+	u64 status = -1ULL;</span>
<span class="p_add">+	int cpu, vcpu, gva_n;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (!pcpu_flush || !hv_hypercall_pg)</span>
<span class="p_add">+		goto do_native;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (cpumask_empty(cpus))</span>
<span class="p_add">+		return;</span>
<span class="p_add">+</span>
<span class="p_add">+	flush = this_cpu_ptr(pcpu_flush);</span>
<span class="p_add">+	spin_lock_irqsave(&amp;flush-&gt;lock, flags);</span>
<span class="p_add">+</span>
<span class="p_add">+	flush-&gt;flush.address_space = virt_to_phys(mm-&gt;pgd);</span>
<span class="p_add">+	flush-&gt;flush.processor_mask = 0;</span>
<span class="p_add">+	if (cpumask_equal(cpus, cpu_present_mask)) {</span>
<span class="p_add">+		flush-&gt;flush.flags = HV_FLUSH_ALL_PROCESSORS;</span>
<span class="p_add">+	} else {</span>
<span class="p_add">+		flush-&gt;flush.flags = 0;</span>
<span class="p_add">+		for_each_cpu(cpu, cpus) {</span>
<span class="p_add">+			vcpu = vmbus_cpu_number_to_vp_number(cpu);</span>
<span class="p_add">+			if (vcpu != -1 &amp;&amp; vcpu &lt; 64)</span>
<span class="p_add">+				flush-&gt;flush.processor_mask |= 1 &lt;&lt; vcpu;</span>
<span class="p_add">+			else</span>
<span class="p_add">+				goto unlock_do_native;</span>
<span class="p_add">+		}</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	if (end == TLB_FLUSH_ALL) {</span>
<span class="p_add">+		flush-&gt;flush.flags = HV_FLUSH_NON_GLOBAL_MAPPINGS_ONLY;</span>
<span class="p_add">+		status = hv_do_hypercall(HVCALL_FLUSH_VIRTUAL_ADDRESS_SPACE,</span>
<span class="p_add">+					 &amp;flush-&gt;flush, NULL);</span>
<span class="p_add">+	} else {</span>
<span class="p_add">+		cur = start;</span>
<span class="p_add">+more_gvas:</span>
<span class="p_add">+		gva_n = 0;</span>
<span class="p_add">+</span>
<span class="p_add">+		do {</span>
<span class="p_add">+			flush-&gt;flush.gva_list[gva_n] = cur &amp; PAGE_MASK;</span>
<span class="p_add">+			/*</span>
<span class="p_add">+			 * Lower 12 bits encode the number of additional</span>
<span class="p_add">+			 * pages to flush (in addition to the &#39;cur&#39; page).</span>
<span class="p_add">+			 */</span>
<span class="p_add">+			if (end &gt;= cur + PAGE_SIZE * PAGE_SIZE)</span>
<span class="p_add">+				flush-&gt;flush.gva_list[gva_n] |= ~PAGE_MASK;</span>
<span class="p_add">+			else if (end &gt; cur)</span>
<span class="p_add">+				flush-&gt;flush.gva_list[gva_n] |=</span>
<span class="p_add">+					(end - cur - 1) &gt;&gt; PAGE_SHIFT;</span>
<span class="p_add">+</span>
<span class="p_add">+			cur += PAGE_SIZE * PAGE_SIZE;</span>
<span class="p_add">+			++gva_n;</span>
<span class="p_add">+</span>
<span class="p_add">+		} while (cur &lt; end &amp;&amp; gva_n &lt; HV_MMU_MAX_GVAS);</span>
<span class="p_add">+</span>
<span class="p_add">+		status = hv_do_rep_hypercall(HVCALL_FLUSH_VIRTUAL_ADDRESS_LIST,</span>
<span class="p_add">+					     gva_n, &amp;flush-&gt;flush, NULL);</span>
<span class="p_add">+</span>
<span class="p_add">+		if (!(status &amp; 0xffff) &amp;&amp; cur &lt; end)</span>
<span class="p_add">+			goto more_gvas;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+unlock_do_native:</span>
<span class="p_add">+	spin_unlock_irqrestore(&amp;flush-&gt;lock, flags);</span>
<span class="p_add">+</span>
<span class="p_add">+	if (!(status &amp; 0xffff))</span>
<span class="p_add">+		return;</span>
<span class="p_add">+do_native:</span>
<span class="p_add">+	native_flush_tlb_others(cpus, mm, start, end);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void hyperv_setup_mmu_ops(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	if (ms_hyperv.hints &amp; HV_X64_REMOTE_TLB_FLUSH_RECOMMENDED) {</span>
<span class="p_add">+		pr_info(&quot;Hyper-V: Using hypercall for remote TLB flush\n&quot;);</span>
<span class="p_add">+		pv_mmu_ops.flush_tlb_others = hyperv_flush_tlb_others;</span>
<span class="p_add">+	}</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+void hyper_alloc_mmu(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	int cpu;</span>
<span class="p_add">+	struct hv_flush_pcpu *flush;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (ms_hyperv.hints &amp; HV_X64_REMOTE_TLB_FLUSH_RECOMMENDED) {</span>
<span class="p_add">+		pcpu_flush = alloc_percpu(struct hv_flush_pcpu);</span>
<span class="p_add">+		if (!pcpu_flush)</span>
<span class="p_add">+			return;</span>
<span class="p_add">+</span>
<span class="p_add">+		for_each_possible_cpu(cpu) {</span>
<span class="p_add">+			flush = per_cpu_ptr(pcpu_flush, cpu);</span>
<span class="p_add">+			spin_lock_init(&amp;flush-&gt;lock);</span>
<span class="p_add">+		}</span>
<span class="p_add">+	}</span>
<span class="p_add">+}</span>
<span class="p_header">diff --git a/arch/x86/include/asm/mshyperv.h b/arch/x86/include/asm/mshyperv.h</span>
<span class="p_header">index 1293c84..a5041c3 100644</span>
<span class="p_header">--- a/arch/x86/include/asm/mshyperv.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/mshyperv.h</span>
<span class="p_chunk">@@ -301,6 +301,8 @@</span> <span class="p_context"> static inline int vmbus_cpu_number_to_vp_number(int cpu_number)</span>
 }
 
 void hyperv_init(void);
<span class="p_add">+void hyperv_setup_mmu_ops(void);</span>
<span class="p_add">+void hyper_alloc_mmu(void);</span>
 void hyperv_report_panic(struct pt_regs *regs);
 bool hv_is_hypercall_page_setup(void);
 void hyperv_cleanup(void);
<span class="p_header">diff --git a/arch/x86/include/uapi/asm/hyperv.h b/arch/x86/include/uapi/asm/hyperv.h</span>
<span class="p_header">index c87e900..3d44036 100644</span>
<span class="p_header">--- a/arch/x86/include/uapi/asm/hyperv.h</span>
<span class="p_header">+++ b/arch/x86/include/uapi/asm/hyperv.h</span>
<span class="p_chunk">@@ -239,6 +239,8 @@</span> <span class="p_context"></span>
 		(~((1ull &lt;&lt; HV_X64_MSR_HYPERCALL_PAGE_ADDRESS_SHIFT) - 1))
 
 /* Declare the various hypercall operations. */
<span class="p_add">+#define HVCALL_FLUSH_VIRTUAL_ADDRESS_SPACE	0x0002</span>
<span class="p_add">+#define HVCALL_FLUSH_VIRTUAL_ADDRESS_LIST	0x0003</span>
 #define HVCALL_NOTIFY_LONG_SPIN_WAIT		0x0008
 #define HVCALL_POST_MESSAGE			0x005c
 #define HVCALL_SIGNAL_EVENT			0x005d
<span class="p_chunk">@@ -256,6 +258,11 @@</span> <span class="p_context"></span>
 #define HV_PROCESSOR_POWER_STATE_C2		2
 #define HV_PROCESSOR_POWER_STATE_C3		3
 
<span class="p_add">+#define HV_FLUSH_ALL_PROCESSORS			0x00000001</span>
<span class="p_add">+#define HV_FLUSH_ALL_VIRTUAL_ADDRESS_SPACES	0x00000002</span>
<span class="p_add">+#define HV_FLUSH_NON_GLOBAL_MAPPINGS_ONLY	0x00000004</span>
<span class="p_add">+#define HV_FLUSH_USE_EXTENDED_RANGE_FORMAT	0x00000008</span>
<span class="p_add">+</span>
 /* Hypercall interface */
 union hv_hypercall_input {
 	u64 as_uint64;
<span class="p_header">diff --git a/arch/x86/kernel/cpu/mshyperv.c b/arch/x86/kernel/cpu/mshyperv.c</span>
<span class="p_header">index 04cb8d3..fc228d8 100644</span>
<span class="p_header">--- a/arch/x86/kernel/cpu/mshyperv.c</span>
<span class="p_header">+++ b/arch/x86/kernel/cpu/mshyperv.c</span>
<span class="p_chunk">@@ -233,6 +233,7 @@</span> <span class="p_context"> static void __init ms_hyperv_init_platform(void)</span>
 	 * Setup the hook to get control post apic initialization.
 	 */
 	x86_platform.apic_post_init = hyperv_init;
<span class="p_add">+	hyperv_setup_mmu_ops();</span>
 #endif
 }
 

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



