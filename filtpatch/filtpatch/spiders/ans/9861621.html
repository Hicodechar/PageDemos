
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>mm: Always flush VMA ranges affected by zap_page_range v2 - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    mm: Always flush VMA ranges affected by zap_page_range v2</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=138281">Mel Gorman</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>July 25, 2017, 10:12 a.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;20170725101230.5v7gvnjmcnkzzql3@techsingularity.net&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/9861621/mbox/"
   >mbox</a>
|
   <a href="/patch/9861621/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/9861621/">/patch/9861621/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
	[172.30.200.125])
	by pdx-korg-patchwork.web.codeaurora.org (Postfix) with ESMTP id
	01DD0602B1 for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Tue, 25 Jul 2017 10:12:39 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 019AE285F7
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Tue, 25 Jul 2017 10:12:39 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id E9F092860E; Tue, 25 Jul 2017 10:12:38 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-6.9 required=2.0 tests=BAYES_00,RCVD_IN_DNSWL_HI
	autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 302B3285F7
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Tue, 25 Jul 2017 10:12:38 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1751403AbdGYKMe (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Tue, 25 Jul 2017 06:12:34 -0400
Received: from outbound-smtp09.blacknight.com ([46.22.139.14]:44157 &quot;EHLO
	outbound-smtp09.blacknight.com&quot; rhost-flags-OK-OK-OK-OK)
	by vger.kernel.org with ESMTP id S1751089AbdGYKMc (ORCPT
	&lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Tue, 25 Jul 2017 06:12:32 -0400
Received: from mail.blacknight.com (pemlinmail04.blacknight.ie
	[81.17.254.17])
	by outbound-smtp09.blacknight.com (Postfix) with ESMTPS id
	8277F1C1656 for &lt;linux-kernel@vger.kernel.org&gt;;
	Tue, 25 Jul 2017 11:12:31 +0100 (IST)
Received: (qmail 9214 invoked from network); 25 Jul 2017 10:12:31 -0000
Received: from unknown (HELO techsingularity.net)
	(mgorman@techsingularity.net@[37.228.242.123])
	by 81.17.254.9 with ESMTPSA (DHE-RSA-AES256-SHA encrypted,
	authenticated); 25 Jul 2017 10:12:31 -0000
Date: Tue, 25 Jul 2017 11:12:30 +0100
From: Mel Gorman &lt;mgorman@techsingularity.net&gt;
To: Andrew Morton &lt;akpm@linux-foundation.org&gt;
Cc: Nadav Amit &lt;nadav.amit@gmail.com&gt;,
	Andy Lutomirski &lt;luto@kernel.org&gt;, linux-mm@kvack.org,
	linux-kernel@vger.kernel.org
Subject: [PATCH] mm: Always flush VMA ranges affected by zap_page_range v2
Message-ID: &lt;20170725101230.5v7gvnjmcnkzzql3@techsingularity.net&gt;
MIME-Version: 1.0
Content-Type: text/plain; charset=iso-8859-15
Content-Disposition: inline
User-Agent: NeoMutt/20170421 (1.8.2)
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=138281">Mel Gorman</a> - July 25, 2017, 10:12 a.m.</div>
<pre class="content">
Changelog since V1
o Do not poke at mmu_gather internals (fixes kbuild bug)
o Rebase to 4.13-rc2

Nadav Amit report zap_page_range only specifies that the caller protect
the VMA list but does not specify whether it is held for read or write
with callers using either. madvise holds mmap_sem for read meaning that a
parallel zap operation can unmap PTEs which are then potentially skipped
by madvise which potentially returns with stale TLB entries present. While
the API could be extended, it would be a difficult API to use. This patch
causes zap_page_range() to always consider flushing the full affected
range. For small ranges or sparsely populated mappings, this may result
in one additional spurious TLB flush. For larger ranges, it is possible
that the TLB has already been flushed and the overhead is negligible.
Either way, this approach is safer overall and avoids stale entries being
present when madvise returns.

This can be illustrated with the following program provided by Nadav
Amit and slightly modified. With the patch applied, it has an exit
code of 0 indicating a stale TLB entry did not leak to userspace.

---8&lt;---

volatile int sync_step = 0;
volatile char *p;

static inline unsigned long rdtsc()
{
	unsigned long hi, lo;
	__asm__ __volatile__ (&quot;rdtsc&quot; : &quot;=a&quot;(lo), &quot;=d&quot;(hi));
	 return lo | (hi &lt;&lt; 32);
}

static inline void wait_rdtsc(unsigned long cycles)
{
	unsigned long tsc = rdtsc();

	while (rdtsc() - tsc &lt; cycles);
}

void *big_madvise_thread(void *ign)
{
	sync_step = 1;
	while (sync_step != 2);
	madvise((void*)p, PAGE_SIZE * N_PAGES, MADV_DONTNEED);
}

int main(void)
{
	pthread_t aux_thread;

	p = mmap(0, PAGE_SIZE * N_PAGES, PROT_READ|PROT_WRITE,
		 MAP_PRIVATE|MAP_ANONYMOUS, -1, 0);

	memset((void*)p, 8, PAGE_SIZE * N_PAGES);

	pthread_create(&amp;aux_thread, NULL, big_madvise_thread, NULL);
	while (sync_step != 1);

	*p = 8;		// Cache in TLB
	sync_step = 2;
	wait_rdtsc(100000);
	madvise((void*)p, PAGE_SIZE, MADV_DONTNEED);
	printf(&quot;data: %d (%s)\n&quot;, *p, (*p == 8 ? &quot;stale, broken&quot; : &quot;cleared, fine&quot;));
	return *p == 8 ? -1 : 0;
}
---8&lt;---

Reported-by: Nadav Amit &lt;nadav.amit@gmail.com&gt;
<span class="signed-off-by">Signed-off-by: Mel Gorman &lt;mgorman@suse.de&gt;</span>
---
 mm/memory.c | 14 +++++++++++++-
 1 file changed, 13 insertions(+), 1 deletion(-)
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/mm/memory.c b/mm/memory.c</span>
<span class="p_header">index 0e517be91a89..8f256d0cd48b 100644</span>
<span class="p_header">--- a/mm/memory.c</span>
<span class="p_header">+++ b/mm/memory.c</span>
<span class="p_chunk">@@ -1483,8 +1483,20 @@</span> <span class="p_context"> void zap_page_range(struct vm_area_struct *vma, unsigned long start,</span>
 	tlb_gather_mmu(&amp;tlb, mm, start, end);
 	update_hiwater_rss(mm);
 	mmu_notifier_invalidate_range_start(mm, start, end);
<span class="p_del">-	for ( ; vma &amp;&amp; vma-&gt;vm_start &lt; end; vma = vma-&gt;vm_next)</span>
<span class="p_add">+	for ( ; vma &amp;&amp; vma-&gt;vm_start &lt; end; vma = vma-&gt;vm_next) {</span>
 		unmap_single_vma(&amp;tlb, vma, start, end, NULL);
<span class="p_add">+</span>
<span class="p_add">+		/*</span>
<span class="p_add">+		 * zap_page_range does not specify whether mmap_sem should be</span>
<span class="p_add">+		 * held for read or write. That allows parallel zap_page_range</span>
<span class="p_add">+		 * operations to unmap a PTE and defer a flush meaning that</span>
<span class="p_add">+		 * this call observes pte_none and fails to flush the TLB.</span>
<span class="p_add">+		 * Rather than adding a complex API, ensure that no stale</span>
<span class="p_add">+		 * TLB entries exist when this call returns.</span>
<span class="p_add">+		 */</span>
<span class="p_add">+		flush_tlb_range(vma, start, end);</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
 	mmu_notifier_invalidate_range_end(mm, start, end);
 	tlb_finish_mmu(&amp;tlb, start, end);
 }

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



