
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>[6/6] powerpc/8xx: implementation of huge pages - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    [6/6] powerpc/8xx: implementation of huge pages</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=11492">LEROY Christophe</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>Aug. 12, 2016, 4:55 p.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;15e0fa7a312245e681cb9ca18ffb875c7820e5fc.1471020647.git.christophe.leroy@c-s.fr&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/9277489/mbox/"
   >mbox</a>
|
   <a href="/patch/9277489/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/9277489/">/patch/9277489/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
	[172.30.200.125])
	by pdx-korg-patchwork.web.codeaurora.org (Postfix) with ESMTP id
	B13FD60752 for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Fri, 12 Aug 2016 16:56:38 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 9F17F28A9C
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Fri, 12 Aug 2016 16:56:38 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id 9317328ABE; Fri, 12 Aug 2016 16:56:38 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-6.9 required=2.0 tests=BAYES_00,RCVD_IN_DNSWL_HI
	autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id DFA0828A9C
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Fri, 12 Aug 2016 16:56:36 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S932308AbcHLQ4Z (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Fri, 12 Aug 2016 12:56:25 -0400
Received: from pegase1.c-s.fr ([93.17.236.30]:36552 &quot;EHLO pegase1.c-s.fr&quot;
	rhost-flags-OK-OK-OK-OK) by vger.kernel.org with ESMTP
	id S932111AbcHLQz7 (ORCPT &lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Fri, 12 Aug 2016 12:55:59 -0400
Received: from localhost (unknown [192.168.12.234])
	by localhost (Postfix) with ESMTP id 3s9rcX1GT3z9ttFZ;
	Fri, 12 Aug 2016 18:55:56 +0200 (CEST)
X-Virus-Scanned: Debian amavisd-new at c-s.fr
Received: from pegase1.c-s.fr ([192.168.12.234])
	by localhost (pegase1.c-s.fr [192.168.12.234]) (amavisd-new,
	port 10024)
	with ESMTP id RDxeZPWrwN3L; Fri, 12 Aug 2016 18:55:56 +0200 (CEST)
Received: from messagerie.si.c-s.fr (messagerie.si.c-s.fr [192.168.25.192])
	by pegase1.c-s.fr (Postfix) with ESMTP id 3s9rcX0LQ8z9ttFP;
	Fri, 12 Aug 2016 18:55:56 +0200 (CEST)
Received: from localhost (localhost [127.0.0.1])
	by messagerie.si.c-s.fr (Postfix) with ESMTP id 290A38B966;
	Fri, 12 Aug 2016 18:55:57 +0200 (CEST)
X-Virus-Scanned: amavisd-new at c-s.fr
Received: from messagerie.si.c-s.fr ([127.0.0.1])
	by localhost (messagerie.si.c-s.fr [127.0.0.1]) (amavisd-new,
	port 10023)
	with ESMTP id brmbPQhgzLGw; Fri, 12 Aug 2016 18:55:57 +0200 (CEST)
Received: from PO10863.localdomain (po10863.idsi0.si.c-s.fr [172.25.231.6])
	by messagerie.si.c-s.fr (Postfix) with ESMTP id DEFDF8B8BC;
	Fri, 12 Aug 2016 18:55:56 +0200 (CEST)
Received: by localhost.localdomain (Postfix, from userid 0)
	id DC9731A2456; Fri, 12 Aug 2016 18:55:56 +0200 (CEST)
Message-Id: &lt;15e0fa7a312245e681cb9ca18ffb875c7820e5fc.1471020647.git.christophe.leroy@c-s.fr&gt;
In-Reply-To: &lt;cover.1471020646.git.christophe.leroy@c-s.fr&gt;
References: &lt;cover.1471020646.git.christophe.leroy@c-s.fr&gt;
From: Christophe Leroy &lt;christophe.leroy@c-s.fr&gt;
Subject: [PATCH 6/6] powerpc/8xx: implementation of huge pages
To: Benjamin Herrenschmidt &lt;benh@kernel.crashing.org&gt;,
	Paul Mackerras &lt;paulus@samba.org&gt;, Michael Ellerman &lt;mpe@ellerman.id.au&gt;,
	Scott Wood &lt;oss@buserror.net&gt;
Cc: linux-kernel@vger.kernel.org, linuxppc-dev@lists.ozlabs.org
Date: Fri, 12 Aug 2016 18:55:56 +0200 (CEST)
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=11492">LEROY Christophe</a> - Aug. 12, 2016, 4:55 p.m.</div>
<pre class="content">
The 8xx has 512k and 8M pages. This patch implements hugepages using
those sizes.

On the 8xx, the size of pages is in the PGD entry,
using PS field (bits 28-29):
00 : Small pages (4k or 16k)
01 : 512k pages
10 : reserved
11 : 8M pages

The implementation uses a mix of what is used on BOOKS and BOOKE,
as 512k pages are in HUGEPTE tables while for 8M pages we have
several PGD entries pointing on a leaf HUGEPTE entry

For the time being, we do not support CPU15 ERRATA if HUGETLB is
selected
<span class="signed-off-by">
Signed-off-by: Christophe Leroy &lt;christophe.leroy@c-s.fr&gt;</span>
---
 arch/powerpc/include/asm/hugetlb.h           |  18 ++-
 arch/powerpc/include/asm/mmu-8xx.h           |  35 ++++++
 arch/powerpc/include/asm/mmu.h               |  25 ++--
 arch/powerpc/include/asm/nohash/32/pte-8xx.h |   1 +
 arch/powerpc/include/asm/nohash/pgtable.h    |   4 +
 arch/powerpc/include/asm/reg_8xx.h           |   2 +-
 arch/powerpc/kernel/head_8xx.S               | 119 +++++++++++++++++-
 arch/powerpc/mm/hugetlbpage.c                | 176 ++++++++++-----------------
 arch/powerpc/mm/tlb_nohash.c                 |  21 +++-
 arch/powerpc/platforms/8xx/Kconfig           |   1 +
 arch/powerpc/platforms/Kconfig.cputype       |   1 +
 11 files changed, 267 insertions(+), 136 deletions(-)
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=1141">Aneesh Kumar K.V</a> - Aug. 14, 2016, 2:25 p.m.</div>
<pre class="content">
Christophe Leroy &lt;christophe.leroy@c-s.fr&gt; writes:
<span class="quote">
&gt; The 8xx has 512k and 8M pages. This patch implements hugepages using</span>
<span class="quote">&gt; those sizes.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; On the 8xx, the size of pages is in the PGD entry,</span>
<span class="quote">&gt; using PS field (bits 28-29):</span>
<span class="quote">&gt; 00 : Small pages (4k or 16k)</span>
<span class="quote">&gt; 01 : 512k pages</span>
<span class="quote">&gt; 10 : reserved</span>
<span class="quote">&gt; 11 : 8M pages</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; The implementation uses a mix of what is used on BOOKS and BOOKE,</span>
<span class="quote">&gt; as 512k pages are in HUGEPTE tables while for 8M pages we have</span>
<span class="quote">&gt; several PGD entries pointing on a leaf HUGEPTE entry</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; For the time being, we do not support CPU15 ERRATA if HUGETLB is</span>
<span class="quote">&gt; selected</span>

Can you also document here the format for linux page table with different
huge page size. ?
<span class="quote">
&gt;</span>
<span class="quote">&gt; Signed-off-by: Christophe Leroy &lt;christophe.leroy@c-s.fr&gt;</span>
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=11492">LEROY Christophe</a> - Aug. 14, 2016, 5:38 p.m.</div>
<pre class="content">
Le 14/08/2016 à 16:25, Aneesh Kumar K.V a écrit :
<span class="quote">&gt; Christophe Leroy &lt;christophe.leroy@c-s.fr&gt; writes:</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;&gt; The 8xx has 512k and 8M pages. This patch implements hugepages using</span>
<span class="quote">&gt;&gt; those sizes.</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; On the 8xx, the size of pages is in the PGD entry,</span>
<span class="quote">&gt;&gt; using PS field (bits 28-29):</span>
<span class="quote">&gt;&gt; 00 : Small pages (4k or 16k)</span>
<span class="quote">&gt;&gt; 01 : 512k pages</span>
<span class="quote">&gt;&gt; 10 : reserved</span>
<span class="quote">&gt;&gt; 11 : 8M pages</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; The implementation uses a mix of what is used on BOOKS and BOOKE,</span>
<span class="quote">&gt;&gt; as 512k pages are in HUGEPTE tables while for 8M pages we have</span>
<span class="quote">&gt;&gt; several PGD entries pointing on a leaf HUGEPTE entry</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; For the time being, we do not support CPU15 ERRATA if HUGETLB is</span>
<span class="quote">&gt;&gt; selected</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; Can you also document here the format for linux page table with different</span>
<span class="quote">&gt; huge page size. ?</span>

Euh ... isn&#39;t it what I do when explaining the use of the PS field in 
the PGD entry ? That&#39;s the thing, that&#39;s how the 8xx knows how it is a 
huge page, and that&#39;s how Linux will know it is one. On the 8xx, the 
Linux PGD entry (almost) match the L1 MMU entry and the Linux PTE almost 
match the L2 MMU entry (some bits are copied from the PTE to the L1 
entry and then removed from the value writen to the L2 MMU entry)

Christophe
<span class="quote">
&gt;</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; Signed-off-by: Christophe Leroy &lt;christophe.leroy@c-s.fr&gt;</span>

---
L&#39;absence de virus dans ce courrier électronique a été vérifiée par le logiciel antivirus Avast.
https://www.avast.com/antivirus
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=1141">Aneesh Kumar K.V</a> - Aug. 15, 2016, 10:30 a.m.</div>
<pre class="content">
christophe leroy &lt;christophe.leroy@c-s.fr&gt; writes:
<span class="quote">
&gt; Le 14/08/2016 à 16:25, Aneesh Kumar K.V a écrit :</span>
<span class="quote">&gt;&gt; Christophe Leroy &lt;christophe.leroy@c-s.fr&gt; writes:</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt; The 8xx has 512k and 8M pages. This patch implements hugepages using</span>
<span class="quote">&gt;&gt;&gt; those sizes.</span>
<span class="quote">&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt; On the 8xx, the size of pages is in the PGD entry,</span>
<span class="quote">&gt;&gt;&gt; using PS field (bits 28-29):</span>
<span class="quote">&gt;&gt;&gt; 00 : Small pages (4k or 16k)</span>
<span class="quote">&gt;&gt;&gt; 01 : 512k pages</span>
<span class="quote">&gt;&gt;&gt; 10 : reserved</span>
<span class="quote">&gt;&gt;&gt; 11 : 8M pages</span>
<span class="quote">&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt; The implementation uses a mix of what is used on BOOKS and BOOKE,</span>
<span class="quote">&gt;&gt;&gt; as 512k pages are in HUGEPTE tables while for 8M pages we have</span>
<span class="quote">&gt;&gt;&gt; several PGD entries pointing on a leaf HUGEPTE entry</span>
<span class="quote">&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt; For the time being, we do not support CPU15 ERRATA if HUGETLB is</span>
<span class="quote">&gt;&gt;&gt; selected</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; Can you also document here the format for linux page table with different</span>
<span class="quote">&gt;&gt; huge page size. ?</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; Euh ... isn&#39;t it what I do when explaining the use of the PS field in </span>
<span class="quote">&gt; the PGD entry ? That&#39;s the thing, that&#39;s how the 8xx knows how it is a </span>
<span class="quote">&gt; huge page, and that&#39;s how Linux will know it is one. On the 8xx, the </span>
<span class="quote">&gt; Linux PGD entry (almost) match the L1 MMU entry and the Linux PTE almost </span>
<span class="quote">&gt; match the L2 MMU entry (some bits are copied from the PTE to the L1 </span>
<span class="quote">&gt; entry and then removed from the value writen to the L2 MMU entry)</span>
<span class="quote">&gt;</span>

Sorry if that answer was obvious in the commit message. I haven&#39;t looked
at 8xx pagetable format closely to understand the details. Now with your
reply to the earlier email, I looked at the changes again and wonder
whether we can document details like.

8xx uses a two level page table with two different linux page size
support (4k and 16k). 8xx also support two different hugepage sizes
512k and 8M. Inorder to support then on linux we define two different
page table layout.

For 512K hugepage size a pgd entry have the below format
[&lt;hugepte address &gt;0100] . The hugepte table allocated will contain &lt;x&gt;
entries pointing to 512K huge pte.

For 8M multiple pgd entries point to the same hugepte address. and pgd
entry will have the below format
[&lt;hugepte address&gt;1100]. The hugepte table allocated will only have one
entry.

I agree that this is the same details you explained in the commit
messages. But calling out all details will help anybody reading the code
later.

-aneesh
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/arch/powerpc/include/asm/hugetlb.h b/arch/powerpc/include/asm/hugetlb.h</span>
<span class="p_header">index c201cd6..96b3219 100644</span>
<span class="p_header">--- a/arch/powerpc/include/asm/hugetlb.h</span>
<span class="p_header">+++ b/arch/powerpc/include/asm/hugetlb.h</span>
<span class="p_chunk">@@ -49,12 +49,20 @@</span> <span class="p_context"> static inline void __local_flush_hugetlb_page(struct vm_area_struct *vma,</span>
 static inline pte_t *hugepd_page(hugepd_t hpd)
 {
 	BUG_ON(!hugepd_ok(hpd));
<span class="p_add">+#ifdef CONFIG_PPC_8xx</span>
<span class="p_add">+	return (pte_t *)__va(hpd.pd &amp; ~(_PMD_PAGE_MASK | _PMD_PRESENT_MASK));</span>
<span class="p_add">+#else</span>
 	return (pte_t *)((hpd.pd &amp; ~HUGEPD_SHIFT_MASK) | PD_HUGE);
<span class="p_add">+#endif</span>
 }
 
 static inline unsigned int hugepd_shift(hugepd_t hpd)
 {
<span class="p_add">+#ifdef CONFIG_PPC_8xx</span>
<span class="p_add">+	return ((hpd.pd &amp; _PMD_PAGE_MASK) &gt;&gt; 1) + 17;</span>
<span class="p_add">+#else</span>
 	return hpd.pd &amp; HUGEPD_SHIFT_MASK;
<span class="p_add">+#endif</span>
 }
 
 #endif /* CONFIG_PPC_BOOK3S_64 */
<span class="p_chunk">@@ -97,7 +105,14 @@</span> <span class="p_context"> static inline int is_hugepage_only_range(struct mm_struct *mm,</span>
 
 void book3e_hugetlb_preload(struct vm_area_struct *vma, unsigned long ea,
 			    pte_t pte);
<span class="p_add">+#ifdef CONFIG_PPC_8xx</span>
<span class="p_add">+static inline void flush_hugetlb_page(struct vm_area_struct *vma, unsigned long vmaddr)</span>
<span class="p_add">+{</span>
<span class="p_add">+	flush_tlb_page(vma, vmaddr);</span>
<span class="p_add">+}</span>
<span class="p_add">+#else</span>
 void flush_hugetlb_page(struct vm_area_struct *vma, unsigned long vmaddr);
<span class="p_add">+#endif</span>
 
 void hugetlb_free_pgd_range(struct mmu_gather *tlb, unsigned long addr,
 			    unsigned long end, unsigned long floor,
<span class="p_chunk">@@ -203,7 +218,8 @@</span> <span class="p_context"> static inline pte_t *hugepte_offset(hugepd_t hpd, unsigned long addr,</span>
  * are reserved early in the boot process by memblock instead of via
  * the .dts as on IBM platforms.
  */
<span class="p_del">-#if defined(CONFIG_HUGETLB_PAGE) &amp;&amp; defined(CONFIG_PPC_FSL_BOOK3E)</span>
<span class="p_add">+#if defined(CONFIG_HUGETLB_PAGE) &amp;&amp; (defined(CONFIG_PPC_FSL_BOOK3E) || \</span>
<span class="p_add">+    defined(CONFIG_PPC_8xx))</span>
 extern void __init reserve_hugetlb_gpages(void);
 #else
 static inline void reserve_hugetlb_gpages(void)
<span class="p_header">diff --git a/arch/powerpc/include/asm/mmu-8xx.h b/arch/powerpc/include/asm/mmu-8xx.h</span>
<span class="p_header">index 3e0e492..3179688 100644</span>
<span class="p_header">--- a/arch/powerpc/include/asm/mmu-8xx.h</span>
<span class="p_header">+++ b/arch/powerpc/include/asm/mmu-8xx.h</span>
<span class="p_chunk">@@ -172,6 +172,41 @@</span> <span class="p_context"> typedef struct {</span>
 
 #define PHYS_IMMR_BASE (mfspr(SPRN_IMMR) &amp; 0xfff80000)
 #define VIRT_IMMR_BASE (__fix_to_virt(FIX_IMMR_BASE))
<span class="p_add">+</span>
<span class="p_add">+/* Page size definitions, common between 32 and 64-bit</span>
<span class="p_add">+ *</span>
<span class="p_add">+ *    shift : is the &quot;PAGE_SHIFT&quot; value for that page size</span>
<span class="p_add">+ *    penc  : is the pte encoding mask</span>
<span class="p_add">+ *</span>
<span class="p_add">+ */</span>
<span class="p_add">+struct mmu_psize_def</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned int	shift;	/* number of bits */</span>
<span class="p_add">+	unsigned int	enc;	/* PTE encoding */</span>
<span class="p_add">+	unsigned int    ind;    /* Corresponding indirect page size shift */</span>
<span class="p_add">+	unsigned int	flags;</span>
<span class="p_add">+#define MMU_PAGE_SIZE_DIRECT	0x1	/* Supported as a direct size */</span>
<span class="p_add">+#define MMU_PAGE_SIZE_INDIRECT	0x2	/* Supported as an indirect size */</span>
<span class="p_add">+};</span>
<span class="p_add">+extern struct mmu_psize_def mmu_psize_defs[MMU_PAGE_COUNT];</span>
<span class="p_add">+</span>
<span class="p_add">+static inline int shift_to_mmu_psize(unsigned int shift)</span>
<span class="p_add">+{</span>
<span class="p_add">+	int psize;</span>
<span class="p_add">+</span>
<span class="p_add">+	for (psize = 0; psize &lt; MMU_PAGE_COUNT; ++psize)</span>
<span class="p_add">+		if (mmu_psize_defs[psize].shift == shift)</span>
<span class="p_add">+			return psize;</span>
<span class="p_add">+	return -1;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline unsigned int mmu_psize_to_shift(unsigned int mmu_psize)</span>
<span class="p_add">+{</span>
<span class="p_add">+	if (mmu_psize_defs[mmu_psize].shift)</span>
<span class="p_add">+		return mmu_psize_defs[mmu_psize].shift;</span>
<span class="p_add">+	BUG();</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 #endif /* !__ASSEMBLY__ */
 
 #if defined(CONFIG_PPC_4K_PAGES)
<span class="p_header">diff --git a/arch/powerpc/include/asm/mmu.h b/arch/powerpc/include/asm/mmu.h</span>
<span class="p_header">index e2fb408..beccfbe 100644</span>
<span class="p_header">--- a/arch/powerpc/include/asm/mmu.h</span>
<span class="p_header">+++ b/arch/powerpc/include/asm/mmu.h</span>
<span class="p_chunk">@@ -260,18 +260,19 @@</span> <span class="p_context"> static inline bool early_radix_enabled(void)</span>
 #define MMU_PAGE_64K	2
 #define MMU_PAGE_64K_AP	3	/* &quot;Admixed pages&quot; (hash64 only) */
 #define MMU_PAGE_256K	4
<span class="p_del">-#define MMU_PAGE_1M	5</span>
<span class="p_del">-#define MMU_PAGE_2M	6</span>
<span class="p_del">-#define MMU_PAGE_4M	7</span>
<span class="p_del">-#define MMU_PAGE_8M	8</span>
<span class="p_del">-#define MMU_PAGE_16M	9</span>
<span class="p_del">-#define MMU_PAGE_64M	10</span>
<span class="p_del">-#define MMU_PAGE_256M	11</span>
<span class="p_del">-#define MMU_PAGE_1G	12</span>
<span class="p_del">-#define MMU_PAGE_16G	13</span>
<span class="p_del">-#define MMU_PAGE_64G	14</span>
<span class="p_del">-</span>
<span class="p_del">-#define MMU_PAGE_COUNT	15</span>
<span class="p_add">+#define MMU_PAGE_512K	5</span>
<span class="p_add">+#define MMU_PAGE_1M	6</span>
<span class="p_add">+#define MMU_PAGE_2M	7</span>
<span class="p_add">+#define MMU_PAGE_4M	8</span>
<span class="p_add">+#define MMU_PAGE_8M	9</span>
<span class="p_add">+#define MMU_PAGE_16M	10</span>
<span class="p_add">+#define MMU_PAGE_64M	11</span>
<span class="p_add">+#define MMU_PAGE_256M	12</span>
<span class="p_add">+#define MMU_PAGE_1G	13</span>
<span class="p_add">+#define MMU_PAGE_16G	14</span>
<span class="p_add">+#define MMU_PAGE_64G	15</span>
<span class="p_add">+</span>
<span class="p_add">+#define MMU_PAGE_COUNT	16</span>
 
 #ifdef CONFIG_PPC_BOOK3S_64
 #include &lt;asm/book3s/64/mmu.h&gt;
<span class="p_header">diff --git a/arch/powerpc/include/asm/nohash/32/pte-8xx.h b/arch/powerpc/include/asm/nohash/32/pte-8xx.h</span>
<span class="p_header">index 3742b19..b4df273 100644</span>
<span class="p_header">--- a/arch/powerpc/include/asm/nohash/32/pte-8xx.h</span>
<span class="p_header">+++ b/arch/powerpc/include/asm/nohash/32/pte-8xx.h</span>
<span class="p_chunk">@@ -49,6 +49,7 @@</span> <span class="p_context"></span>
 #define _PMD_BAD	0x0ff0
 #define _PMD_PAGE_MASK	0x000c
 #define _PMD_PAGE_8M	0x000c
<span class="p_add">+#define _PMD_PAGE_512K	0x0004</span>
 
 /* Until my rework is finished, 8xx still needs atomic PTE updates */
 #define PTE_ATOMIC_UPDATES	1
<span class="p_header">diff --git a/arch/powerpc/include/asm/nohash/pgtable.h b/arch/powerpc/include/asm/nohash/pgtable.h</span>
<span class="p_header">index 1263c22..1728497 100644</span>
<span class="p_header">--- a/arch/powerpc/include/asm/nohash/pgtable.h</span>
<span class="p_header">+++ b/arch/powerpc/include/asm/nohash/pgtable.h</span>
<span class="p_chunk">@@ -226,7 +226,11 @@</span> <span class="p_context"> extern pgprot_t phys_mem_access_prot(struct file *file, unsigned long pfn,</span>
 #ifdef CONFIG_HUGETLB_PAGE
 static inline int hugepd_ok(hugepd_t hpd)
 {
<span class="p_add">+#ifdef CONFIG_PPC_8xx</span>
<span class="p_add">+	return ((hpd.pd &amp; 0x4) != 0);</span>
<span class="p_add">+#else</span>
 	return (hpd.pd &gt; 0);
<span class="p_add">+#endif</span>
 }
 
 static inline int pmd_huge(pmd_t pmd)
<span class="p_header">diff --git a/arch/powerpc/include/asm/reg_8xx.h b/arch/powerpc/include/asm/reg_8xx.h</span>
<span class="p_header">index 94d01f8..feaf641 100644</span>
<span class="p_header">--- a/arch/powerpc/include/asm/reg_8xx.h</span>
<span class="p_header">+++ b/arch/powerpc/include/asm/reg_8xx.h</span>
<span class="p_chunk">@@ -4,7 +4,7 @@</span> <span class="p_context"></span>
 #ifndef _ASM_POWERPC_REG_8xx_H
 #define _ASM_POWERPC_REG_8xx_H
 
<span class="p_del">-#include &lt;asm/mmu-8xx.h&gt;</span>
<span class="p_add">+#include &lt;asm/mmu.h&gt;</span>
 
 /* Cache control on the MPC8xx is provided through some additional
  * special purpose registers.
<span class="p_header">diff --git a/arch/powerpc/kernel/head_8xx.S b/arch/powerpc/kernel/head_8xx.S</span>
<span class="p_header">index 5ce67f2..c77e0c6 100644</span>
<span class="p_header">--- a/arch/powerpc/kernel/head_8xx.S</span>
<span class="p_header">+++ b/arch/powerpc/kernel/head_8xx.S</span>
<span class="p_chunk">@@ -72,6 +72,9 @@</span> <span class="p_context"></span>
 #define RPN_PATTERN	0x00f0
 #endif
 
<span class="p_add">+#define PAGE_SHIFT_512K		19</span>
<span class="p_add">+#define PAGE_SHIFT_8M		23</span>
<span class="p_add">+</span>
 	__HEAD
 _ENTRY(_stext);
 _ENTRY(_start);
<span class="p_chunk">@@ -322,7 +325,7 @@</span> <span class="p_context"> SystemCall:</span>
 #endif
 
 InstructionTLBMiss:
<span class="p_del">-#if defined(CONFIG_8xx_CPU6) || defined(CONFIG_MODULES) || defined (CONFIG_DEBUG_PAGEALLOC)</span>
<span class="p_add">+#if defined(CONFIG_8xx_CPU6) || defined(CONFIG_MODULES) || defined (CONFIG_DEBUG_PAGEALLOC) || defined (CONFIG_HUGETLB_PAGE)</span>
 	mtspr	SPRN_SPRG_SCRATCH2, r3
 #endif
 	EXCEPTION_PROLOG_0
<span class="p_chunk">@@ -332,10 +335,12 @@</span> <span class="p_context"> InstructionTLBMiss:</span>
 	 */
 	mfspr	r10, SPRN_SRR0	/* Get effective address of fault */
 	INVALIDATE_ADJACENT_PAGES_CPU15(r11, r10)
<span class="p_del">-#if defined(CONFIG_MODULES) || defined (CONFIG_DEBUG_PAGEALLOC)</span>
 	/* Only modules will cause ITLB Misses as we always
 	 * pin the first 8MB of kernel memory */
<span class="p_add">+#if defined(CONFIG_MODULES) || defined (CONFIG_DEBUG_PAGEALLOC) || defined (CONFIG_HUGETLB_PAGE)</span>
 	mfcr	r3
<span class="p_add">+#endif</span>
<span class="p_add">+#if defined(CONFIG_MODULES) || defined (CONFIG_DEBUG_PAGEALLOC)</span>
 	IS_KERNEL(r11, r10)
 #endif
 	mfspr	r11, SPRN_M_TW	/* Get level 1 table */
<span class="p_chunk">@@ -343,7 +348,6 @@</span> <span class="p_context"> InstructionTLBMiss:</span>
 	BRANCH_UNLESS_KERNEL(3f)
 	lis	r11, (swapper_pg_dir-PAGE_OFFSET)@ha
 3:
<span class="p_del">-	mtcr	r3</span>
 #endif
 	/* Insert level 1 index */
 	rlwimi	r11, r10, 32 - ((PAGE_SHIFT - 2) &lt;&lt; 1), (PAGE_SHIFT - 2) &lt;&lt; 1, 29
<span class="p_chunk">@@ -351,14 +355,25 @@</span> <span class="p_context"> InstructionTLBMiss:</span>
 
 	/* Extract level 2 index */
 	rlwinm	r10, r10, 32 - (PAGE_SHIFT - 2), 32 - PAGE_SHIFT, 29
<span class="p_add">+#ifdef CONFIG_HUGETLB_PAGE</span>
<span class="p_add">+	mtcr	r11</span>
<span class="p_add">+	bt-	28, 10f		/* bit 28 = Large page (8M) */</span>
<span class="p_add">+	bt-	29, 20f		/* bit 29 = Large page (8M or 512k) */</span>
<span class="p_add">+#endif</span>
 	rlwimi	r10, r11, 0, 0, 32 - PAGE_SHIFT - 1	/* Add level 2 base */
 	lwz	r10, 0(r10)	/* Get the pte */
<span class="p_del">-</span>
<span class="p_add">+4:</span>
<span class="p_add">+#if defined(CONFIG_MODULES) || defined (CONFIG_DEBUG_PAGEALLOC) || defined (CONFIG_HUGETLB_PAGE)</span>
<span class="p_add">+	mtcr	r3</span>
<span class="p_add">+#endif</span>
 	/* Insert the APG into the TWC from the Linux PTE. */
 	rlwimi	r11, r10, 0, 25, 26
 	/* Load the MI_TWC with the attributes for this &quot;segment.&quot; */
 	MTSPR_CPU6(SPRN_MI_TWC, r11, r3)	/* Set segment attributes */
 
<span class="p_add">+#if defined (CONFIG_HUGETLB_PAGE) &amp;&amp; defined (CONFIG_PPC_4K_PAGES)</span>
<span class="p_add">+	rlwimi	r10, r11, 1, MI_SPS16K</span>
<span class="p_add">+#endif</span>
 #ifdef CONFIG_SWAP
 	rlwinm	r11, r10, 32-5, _PAGE_PRESENT
 	and	r11, r11, r10
<span class="p_chunk">@@ -371,16 +386,45 @@</span> <span class="p_context"> InstructionTLBMiss:</span>
 	 * set.  All other Linux PTE bits control the behavior
 	 * of the MMU.
 	 */
<span class="p_add">+#if defined (CONFIG_HUGETLB_PAGE) &amp;&amp; defined (CONFIG_PPC_4K_PAGES)</span>
<span class="p_add">+	rlwimi	r10, r11, 0, 0x0ff0	/* Set 24-27, clear 20-23 */</span>
<span class="p_add">+#else</span>
 	rlwimi	r10, r11, 0, 0x0ff8	/* Set 24-27, clear 20-23,28 */
<span class="p_add">+#endif</span>
 	MTSPR_CPU6(SPRN_MI_RPN, r10, r3)	/* Update TLB entry */
 
 	/* Restore registers */
<span class="p_del">-#if defined(CONFIG_8xx_CPU6) || defined(CONFIG_MODULES) || defined (CONFIG_DEBUG_PAGEALLOC)</span>
<span class="p_add">+#if defined(CONFIG_8xx_CPU6) || defined(CONFIG_MODULES) || defined (CONFIG_DEBUG_PAGEALLOC) || defined (CONFIG_HUGETLB_PAGE)</span>
 	mfspr	r3, SPRN_SPRG_SCRATCH2
 #endif
 	EXCEPTION_EPILOG_0
 	rfi
 
<span class="p_add">+#ifdef CONFIG_HUGETLB_PAGE</span>
<span class="p_add">+10:	/* 8M pages */</span>
<span class="p_add">+#ifdef CONFIG_PPC_16K_PAGES</span>
<span class="p_add">+	/* Extract level 2 index */</span>
<span class="p_add">+	rlwinm	r10, r10, 32 - (PAGE_SHIFT_8M - PAGE_SHIFT), 32 + PAGE_SHIFT_8M - (PAGE_SHIFT &lt;&lt; 1), 29</span>
<span class="p_add">+	/* Add level 2 base */</span>
<span class="p_add">+	rlwimi	r10, r11, 0, 0, 32 + PAGE_SHIFT_8M - (PAGE_SHIFT &lt;&lt; 1) - 1</span>
<span class="p_add">+#else</span>
<span class="p_add">+	/* Level 2 base */</span>
<span class="p_add">+	rlwinm	r10, r11, 0, 0, 32 + PAGE_SHIFT_8M - (PAGE_SHIFT &lt;&lt; 1) - 1 - 1</span>
<span class="p_add">+#endif</span>
<span class="p_add">+	lwz	r10, 0(r10)	/* Get the pte */</span>
<span class="p_add">+	rlwinm	r11, r11, 0, 0xf</span>
<span class="p_add">+	b	4b</span>
<span class="p_add">+</span>
<span class="p_add">+20:	/* 512k pages */</span>
<span class="p_add">+	/* Extract level 2 index */</span>
<span class="p_add">+	rlwinm	r10, r10, 32 - (PAGE_SHIFT_512K - PAGE_SHIFT), 32 + PAGE_SHIFT_512K - (PAGE_SHIFT &lt;&lt; 1), 29</span>
<span class="p_add">+	/* Add level 2 base */</span>
<span class="p_add">+	rlwimi	r10, r11, 0, 0, 32 + PAGE_SHIFT_512K - (PAGE_SHIFT &lt;&lt; 1) - 1</span>
<span class="p_add">+	lwz	r10, 0(r10)	/* Get the pte */</span>
<span class="p_add">+	rlwinm	r11, r11, 0, 0xf</span>
<span class="p_add">+	b	4b</span>
<span class="p_add">+#endif</span>
<span class="p_add">+</span>
 	. = 0x1200
 DataStoreTLBMiss:
 	mtspr	SPRN_SPRG_SCRATCH2, r3
<span class="p_chunk">@@ -407,7 +451,6 @@</span> <span class="p_context"> _ENTRY(DTLBMiss_jmp)</span>
 #endif
 	blt	cr7, DTLBMissLinear
 3:
<span class="p_del">-	mtcr	r3</span>
 	mfspr	r10, SPRN_MD_EPN
 
 	/* Insert level 1 index */
<span class="p_chunk">@@ -418,8 +461,15 @@</span> <span class="p_context"> _ENTRY(DTLBMiss_jmp)</span>
 	 */
 	/* Extract level 2 index */
 	rlwinm	r10, r10, 32 - (PAGE_SHIFT - 2), 32 - PAGE_SHIFT, 29
<span class="p_add">+#ifdef CONFIG_HUGETLB_PAGE</span>
<span class="p_add">+	mtcr	r11</span>
<span class="p_add">+	bt-	28, 10f		/* bit 28 = Large page (8M) */</span>
<span class="p_add">+	bt-	29, 20f		/* bit 29 = Large page (8M or 512k) */</span>
<span class="p_add">+#endif</span>
 	rlwimi	r10, r11, 0, 0, 32 - PAGE_SHIFT - 1	/* Add level 2 base */
 	lwz	r10, 0(r10)	/* Get the pte */
<span class="p_add">+4:</span>
<span class="p_add">+	mtcr	r3</span>
 
 	/* Insert the Guarded flag and APG into the TWC from the Linux PTE.
 	 * It is bit 26-27 of both the Linux PTE and the TWC (at least
<span class="p_chunk">@@ -434,6 +484,11 @@</span> <span class="p_context"> _ENTRY(DTLBMiss_jmp)</span>
 	rlwimi	r11, r10, 32-5, 30, 30
 	MTSPR_CPU6(SPRN_MD_TWC, r11, r3)
 
<span class="p_add">+	/* In 4k pages mode, SPS (bit 28) in RPN must match PS[1] (bit 29)</span>
<span class="p_add">+	 * In 16k pages mode, SPS is always 1 */</span>
<span class="p_add">+#if defined (CONFIG_HUGETLB_PAGE) &amp;&amp; defined (CONFIG_PPC_4K_PAGES)</span>
<span class="p_add">+	rlwimi	r10, r11, 1, MD_SPS16K</span>
<span class="p_add">+#endif</span>
 	/* Both _PAGE_ACCESSED and _PAGE_PRESENT has to be set.
 	 * We also need to know if the insn is a load/store, so:
 	 * Clear _PAGE_PRESENT and load that which will
<span class="p_chunk">@@ -455,7 +510,11 @@</span> <span class="p_context"> _ENTRY(DTLBMiss_jmp)</span>
 	 * of the MMU.
 	 */
 	li	r11, RPN_PATTERN
<span class="p_add">+#if defined (CONFIG_HUGETLB_PAGE) &amp;&amp; defined (CONFIG_PPC_4K_PAGES)</span>
<span class="p_add">+	rlwimi	r10, r11, 0, 24, 27	/* Set 24-27 */</span>
<span class="p_add">+#else</span>
 	rlwimi	r10, r11, 0, 24, 28	/* Set 24-27, clear 28 */
<span class="p_add">+#endif</span>
 	rlwimi	r10, r11, 0, 20, 20	/* clear 20 */
 	MTSPR_CPU6(SPRN_MD_RPN, r10, r3)	/* Update TLB entry */
 
<span class="p_chunk">@@ -465,6 +524,30 @@</span> <span class="p_context"> _ENTRY(DTLBMiss_jmp)</span>
 	EXCEPTION_EPILOG_0
 	rfi
 
<span class="p_add">+#ifdef CONFIG_HUGETLB_PAGE</span>
<span class="p_add">+10:	/* 8M pages */</span>
<span class="p_add">+	/* Extract level 2 index */</span>
<span class="p_add">+#ifdef CONFIG_PPC_16K_PAGES</span>
<span class="p_add">+	rlwinm	r10, r10, 32 - (PAGE_SHIFT_8M - PAGE_SHIFT), 32 + PAGE_SHIFT_8M - (PAGE_SHIFT &lt;&lt; 1), 29</span>
<span class="p_add">+	/* Add level 2 base */</span>
<span class="p_add">+	rlwimi	r10, r11, 0, 0, 32 + PAGE_SHIFT_8M - (PAGE_SHIFT &lt;&lt; 1) - 1</span>
<span class="p_add">+#else</span>
<span class="p_add">+	/* Level 2 base */</span>
<span class="p_add">+	rlwinm	r10, r11, 0, 0, 32 + PAGE_SHIFT_8M - (PAGE_SHIFT &lt;&lt; 1) - 1 - 1</span>
<span class="p_add">+#endif</span>
<span class="p_add">+	lwz	r10, 0(r10)	/* Get the pte */</span>
<span class="p_add">+	rlwinm	r11, r11, 0, 0xf</span>
<span class="p_add">+	b	4b</span>
<span class="p_add">+</span>
<span class="p_add">+20:	/* 512k pages */</span>
<span class="p_add">+	/* Extract level 2 index */</span>
<span class="p_add">+	rlwinm	r10, r10, 32 - (PAGE_SHIFT_512K - PAGE_SHIFT), 32 + PAGE_SHIFT_512K - (PAGE_SHIFT &lt;&lt; 1), 29</span>
<span class="p_add">+	/* Add level 2 base */</span>
<span class="p_add">+	rlwimi	r10, r11, 0, 0, 32 + PAGE_SHIFT_512K - (PAGE_SHIFT &lt;&lt; 1) - 1</span>
<span class="p_add">+	lwz	r10, 0(r10)	/* Get the pte */</span>
<span class="p_add">+	rlwinm	r11, r11, 0, 0xf</span>
<span class="p_add">+	b	4b</span>
<span class="p_add">+#endif</span>
 
 /* This is an instruction TLB error on the MPC8xx.  This could be due
  * to many reasons, such as executing guarded memory or illegal instruction
<span class="p_chunk">@@ -586,6 +669,9 @@</span> <span class="p_context"> _ENTRY(FixupDAR_cmp)</span>
 	/* Insert level 1 index */
 3:	rlwimi	r11, r10, 32 - ((PAGE_SHIFT - 2) &lt;&lt; 1), (PAGE_SHIFT - 2) &lt;&lt; 1, 29
 	lwz	r11, (swapper_pg_dir-PAGE_OFFSET)@l(r11)	/* Get the level 1 entry */
<span class="p_add">+	mtcr	r11</span>
<span class="p_add">+	bt	28,200f		/* bit 28 = Large page (8M) */</span>
<span class="p_add">+	bt	29,202f		/* bit 29 = Large page (8M or 512K) */</span>
 	rlwinm	r11, r11,0,0,19	/* Extract page descriptor page address */
 	/* Insert level 2 index */
 	rlwimi	r11, r10, 32 - (PAGE_SHIFT - 2), 32 - PAGE_SHIFT, 29
<span class="p_chunk">@@ -611,6 +697,27 @@</span> <span class="p_context"> _ENTRY(FixupDAR_cmp)</span>
 141:	mfspr	r10,SPRN_SPRG_SCRATCH2
 	b	DARFixed	/* Nope, go back to normal TLB processing */
 
<span class="p_add">+	/* concat physical page address(r11) and page offset(r10) */</span>
<span class="p_add">+200:</span>
<span class="p_add">+#ifdef CONFIG_PPC_16K_PAGES</span>
<span class="p_add">+	rlwinm	r11, r11, 0, 0, 32 + PAGE_SHIFT_8M - (PAGE_SHIFT &lt;&lt; 1) - 1</span>
<span class="p_add">+	rlwimi	r11, r10, 32 - (PAGE_SHIFT_8M - 2), 32 + PAGE_SHIFT_8M - (PAGE_SHIFT &lt;&lt; 1), 29</span>
<span class="p_add">+#else</span>
<span class="p_add">+	rlwinm	r11, r10, 0, 0, 32 + PAGE_SHIFT_8M - (PAGE_SHIFT &lt;&lt; 1) - 1 - 1</span>
<span class="p_add">+#endif</span>
<span class="p_add">+	lwz	r11, 0(r11)	/* Get the pte */</span>
<span class="p_add">+	/* concat physical page address(r11) and page offset(r10) */</span>
<span class="p_add">+	rlwimi	r11, r10, 0, 32 - PAGE_SHIFT_8M, 31</span>
<span class="p_add">+	b	201b</span>
<span class="p_add">+</span>
<span class="p_add">+202:</span>
<span class="p_add">+	rlwinm	r11, r11, 0, 0, 32 + PAGE_SHIFT_512K - (PAGE_SHIFT &lt;&lt; 1) - 1</span>
<span class="p_add">+	rlwimi	r11, r10, 32 - (PAGE_SHIFT_512K - 2), 32 + PAGE_SHIFT_512K - (PAGE_SHIFT &lt;&lt; 1), 29</span>
<span class="p_add">+	lwz	r11, 0(r11)	/* Get the pte */</span>
<span class="p_add">+	/* concat physical page address(r11) and page offset(r10) */</span>
<span class="p_add">+	rlwimi	r11, r10, 0, 32 - PAGE_SHIFT_512K, 31</span>
<span class="p_add">+	b	201b</span>
<span class="p_add">+</span>
 144:	mfspr	r10, SPRN_DSISR
 	rlwinm	r10, r10,0,7,5	/* Clear store bit for buggy dcbst insn */
 	mtspr	SPRN_DSISR, r10
<span class="p_header">diff --git a/arch/powerpc/mm/hugetlbpage.c b/arch/powerpc/mm/hugetlbpage.c</span>
<span class="p_header">index 03fcb7e..20934db 100644</span>
<span class="p_header">--- a/arch/powerpc/mm/hugetlbpage.c</span>
<span class="p_header">+++ b/arch/powerpc/mm/hugetlbpage.c</span>
<span class="p_chunk">@@ -26,6 +26,8 @@</span> <span class="p_context"></span>
 #ifdef CONFIG_HUGETLB_PAGE
 
 #define PAGE_SHIFT_64K	16
<span class="p_add">+#define PAGE_SHIFT_512K	19</span>
<span class="p_add">+#define PAGE_SHIFT_8M	23</span>
 #define PAGE_SHIFT_16M	24
 #define PAGE_SHIFT_16G	34
 
<span class="p_chunk">@@ -38,7 +40,7 @@</span> <span class="p_context"> unsigned int HPAGE_SHIFT;</span>
  * implementations may have more than one gpage size, so we need multiple
  * arrays
  */
<span class="p_del">-#ifdef CONFIG_PPC_FSL_BOOK3E</span>
<span class="p_add">+#if defined(CONFIG_PPC_FSL_BOOK3E) || defined(CONFIG_PPC_8xx)</span>
 #define MAX_NUMBER_GPAGES	128
 struct psize_gpages {
 	u64 gpage_list[MAX_NUMBER_GPAGES];
<span class="p_chunk">@@ -64,14 +66,10 @@</span> <span class="p_context"> static int __hugepte_alloc(struct mm_struct *mm, hugepd_t *hpdp,</span>
 {
 	struct kmem_cache *cachep;
 	pte_t *new;
<span class="p_del">-</span>
<span class="p_del">-#ifdef CONFIG_PPC_FSL_BOOK3E</span>
 	int i;
<span class="p_del">-	int num_hugepd = 1 &lt;&lt; (pshift - pdshift);</span>
<span class="p_del">-	cachep = PGT_CACHE(1);</span>
<span class="p_del">-#else</span>
<span class="p_del">-	cachep = PGT_CACHE(pdshift - pshift);</span>
<span class="p_del">-#endif</span>
<span class="p_add">+	int num_hugepd = 1 &lt;&lt; (pshift - pdshift) ? : 1;</span>
<span class="p_add">+</span>
<span class="p_add">+	cachep = PGT_CACHE(pdshift &gt; pshift ? pdshift - pshift : 1);</span>
 
 	new = kmem_cache_zalloc(cachep, GFP_KERNEL);
 
<span class="p_chunk">@@ -89,7 +87,6 @@</span> <span class="p_context"> static int __hugepte_alloc(struct mm_struct *mm, hugepd_t *hpdp,</span>
 	smp_wmb();
 
 	spin_lock(&amp;mm-&gt;page_table_lock);
<span class="p_del">-#ifdef CONFIG_PPC_FSL_BOOK3E</span>
 	/*
 	 * We have multiple higher-level entries that point to the same
 	 * actual pte location.  Fill in each as we go and backtrack on error.
<span class="p_chunk">@@ -100,8 +97,18 @@</span> <span class="p_context"> static int __hugepte_alloc(struct mm_struct *mm, hugepd_t *hpdp,</span>
 		if (unlikely(!hugepd_none(*hpdp)))
 			break;
 		else
<span class="p_add">+#ifdef CONFIG_PPC_BOOK3S_64</span>
<span class="p_add">+			hpdp-&gt;pd = __pa(new) |</span>
<span class="p_add">+				   (shift_to_mmu_psize(pshift) &lt;&lt; 2);</span>
<span class="p_add">+#elif defined(CONFIG_PPC_8xx)</span>
<span class="p_add">+			hpdp-&gt;pd = ((unsigned long)__pa(new)) |</span>
<span class="p_add">+				   (pshift == PAGE_SHIFT_8M ? _PMD_PAGE_8M :</span>
<span class="p_add">+							      _PMD_PAGE_512K) |</span>
<span class="p_add">+				   _PMD_PRESENT;</span>
<span class="p_add">+#else</span>
 			/* We use the old format for PPC_FSL_BOOK3E */
 			hpdp-&gt;pd = ((unsigned long)new &amp; ~PD_HUGE) | pshift;
<span class="p_add">+#endif</span>
 	}
 	/* If we bailed from the for loop early, an error occurred, clean up */
 	if (i &lt; num_hugepd) {
<span class="p_chunk">@@ -109,17 +116,6 @@</span> <span class="p_context"> static int __hugepte_alloc(struct mm_struct *mm, hugepd_t *hpdp,</span>
 			hpdp-&gt;pd = 0;
 		kmem_cache_free(cachep, new);
 	}
<span class="p_del">-#else</span>
<span class="p_del">-	if (!hugepd_none(*hpdp))</span>
<span class="p_del">-		kmem_cache_free(cachep, new);</span>
<span class="p_del">-	else {</span>
<span class="p_del">-#ifdef CONFIG_PPC_BOOK3S_64</span>
<span class="p_del">-		hpdp-&gt;pd = __pa(new) | (shift_to_mmu_psize(pshift) &lt;&lt; 2);</span>
<span class="p_del">-#else</span>
<span class="p_del">-		hpdp-&gt;pd = ((unsigned long)new &amp; ~PD_HUGE) | pshift;</span>
<span class="p_del">-#endif</span>
<span class="p_del">-	}</span>
<span class="p_del">-#endif</span>
 	spin_unlock(&amp;mm-&gt;page_table_lock);
 	return 0;
 }
<span class="p_chunk">@@ -128,7 +124,7 @@</span> <span class="p_context"> static int __hugepte_alloc(struct mm_struct *mm, hugepd_t *hpdp,</span>
  * These macros define how to determine which level of the page table holds
  * the hpdp.
  */
<span class="p_del">-#ifdef CONFIG_PPC_FSL_BOOK3E</span>
<span class="p_add">+#if defined(CONFIG_PPC_FSL_BOOK3E) || defined(CONFIG_PPC_8xx)</span>
 #define HUGEPD_PGD_SHIFT PGDIR_SHIFT
 #define HUGEPD_PUD_SHIFT PUD_SHIFT
 #else
<span class="p_chunk">@@ -136,7 +132,6 @@</span> <span class="p_context"> static int __hugepte_alloc(struct mm_struct *mm, hugepd_t *hpdp,</span>
 #define HUGEPD_PUD_SHIFT PMD_SHIFT
 #endif
 
<span class="p_del">-#ifdef CONFIG_PPC_BOOK3S_64</span>
 /*
  * At this point we do the placement change only for BOOK3S 64. This would
  * possibly work on other subarchs.
<span class="p_chunk">@@ -153,6 +148,7 @@</span> <span class="p_context"> pte_t *huge_pte_alloc(struct mm_struct *mm, unsigned long addr, unsigned long sz</span>
 	addr &amp;= ~(sz-1);
 	pg = pgd_offset(mm, addr);
 
<span class="p_add">+#ifdef CONFIG_PPC_BOOK3S_64</span>
 	if (pshift == PGDIR_SHIFT)
 		/* 16GB huge page */
 		return (pte_t *) pg;
<span class="p_chunk">@@ -178,32 +174,7 @@</span> <span class="p_context"> pte_t *huge_pte_alloc(struct mm_struct *mm, unsigned long addr, unsigned long sz</span>
 				hpdp = (hugepd_t *)pm;
 		}
 	}
<span class="p_del">-	if (!hpdp)</span>
<span class="p_del">-		return NULL;</span>
<span class="p_del">-</span>
<span class="p_del">-	BUG_ON(!hugepd_none(*hpdp) &amp;&amp; !hugepd_ok(*hpdp));</span>
<span class="p_del">-</span>
<span class="p_del">-	if (hugepd_none(*hpdp) &amp;&amp; __hugepte_alloc(mm, hpdp, addr, pdshift, pshift))</span>
<span class="p_del">-		return NULL;</span>
<span class="p_del">-</span>
<span class="p_del">-	return hugepte_offset(*hpdp, addr, pdshift);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
 #else
<span class="p_del">-</span>
<span class="p_del">-pte_t *huge_pte_alloc(struct mm_struct *mm, unsigned long addr, unsigned long sz)</span>
<span class="p_del">-{</span>
<span class="p_del">-	pgd_t *pg;</span>
<span class="p_del">-	pud_t *pu;</span>
<span class="p_del">-	pmd_t *pm;</span>
<span class="p_del">-	hugepd_t *hpdp = NULL;</span>
<span class="p_del">-	unsigned pshift = __ffs(sz);</span>
<span class="p_del">-	unsigned pdshift = PGDIR_SHIFT;</span>
<span class="p_del">-</span>
<span class="p_del">-	addr &amp;= ~(sz-1);</span>
<span class="p_del">-</span>
<span class="p_del">-	pg = pgd_offset(mm, addr);</span>
<span class="p_del">-</span>
 	if (pshift &gt;= HUGEPD_PGD_SHIFT) {
 		hpdp = (hugepd_t *)pg;
 	} else {
<span class="p_chunk">@@ -217,7 +188,7 @@</span> <span class="p_context"> pte_t *huge_pte_alloc(struct mm_struct *mm, unsigned long addr, unsigned long sz</span>
 			hpdp = (hugepd_t *)pm;
 		}
 	}
<span class="p_del">-</span>
<span class="p_add">+#endif</span>
 	if (!hpdp)
 		return NULL;
 
<span class="p_chunk">@@ -228,9 +199,8 @@</span> <span class="p_context"> pte_t *huge_pte_alloc(struct mm_struct *mm, unsigned long addr, unsigned long sz</span>
 
 	return hugepte_offset(*hpdp, addr, pdshift);
 }
<span class="p_del">-#endif</span>
 
<span class="p_del">-#ifdef CONFIG_PPC_FSL_BOOK3E</span>
<span class="p_add">+#if defined(CONFIG_PPC_FSL_BOOK3E) || defined(CONFIG_PPC_8xx)</span>
 /* Build list of addresses of gigantic pages.  This function is used in early
  * boot before the buddy allocator is setup.
  */
<span class="p_chunk">@@ -310,7 +280,11 @@</span> <span class="p_context"> static int __init do_gpage_early_setup(char *param, char *val,</span>
 				npages = 0;
 			if (npages &gt; MAX_NUMBER_GPAGES) {
 				pr_warn(&quot;MMU: %lu pages requested for page &quot;
<span class="p_add">+#ifdef CONFIG_PPC64</span>
 					&quot;size %llu KB, limiting to &quot;
<span class="p_add">+#else</span>
<span class="p_add">+					&quot;size %u KB, limiting to &quot;</span>
<span class="p_add">+#endif</span>
 					__stringify(MAX_NUMBER_GPAGES) &quot;\n&quot;,
 					npages, size / 1024);
 				npages = MAX_NUMBER_GPAGES;
<span class="p_chunk">@@ -392,7 +366,7 @@</span> <span class="p_context"> int alloc_bootmem_huge_page(struct hstate *hstate)</span>
 }
 #endif
 
<span class="p_del">-#ifdef CONFIG_PPC_FSL_BOOK3E</span>
<span class="p_add">+#if defined(CONFIG_PPC_FSL_BOOK3E) || defined(CONFIG_PPC_8xx)</span>
 #define HUGEPD_FREELIST_SIZE \
 	((PAGE_SIZE - sizeof(struct hugepd_freelist)) / sizeof(pte_t))
 
<span class="p_chunk">@@ -442,6 +416,12 @@</span> <span class="p_context"> static void hugepd_free(struct mmu_gather *tlb, void *hugepte)</span>
 	}
 	put_cpu_var(hugepd_freelist_cur);
 }
<span class="p_add">+#else</span>
<span class="p_add">+static void hugepd_free(struct mmu_gather *tlb, void *hugepte)</span>
<span class="p_add">+{</span>
<span class="p_add">+	BUG();</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 #endif
 
 static void free_hugepd_range(struct mmu_gather *tlb, hugepd_t *hpdp, int pdshift,
<span class="p_chunk">@@ -452,14 +432,9 @@</span> <span class="p_context"> static void free_hugepd_range(struct mmu_gather *tlb, hugepd_t *hpdp, int pdshif</span>
 	int i;
 
 	unsigned long pdmask = ~((1UL &lt;&lt; pdshift) - 1);
<span class="p_del">-	unsigned int num_hugepd = 1;</span>
<span class="p_del">-</span>
<span class="p_del">-#ifdef CONFIG_PPC_FSL_BOOK3E</span>
<span class="p_del">-	/* Note: On fsl the hpdp may be the first of several */</span>
<span class="p_del">-	num_hugepd = (1 &lt;&lt; (hugepd_shift(*hpdp) - pdshift));</span>
<span class="p_del">-#else</span>
 	unsigned int shift = hugepd_shift(*hpdp);
<span class="p_del">-#endif</span>
<span class="p_add">+	/* Note: On fsl the hpdp may be the first of several */</span>
<span class="p_add">+	unsigned int num_hugepd = (1 &lt;&lt; (shift - pdshift)) ? : 1;</span>
 
 	start &amp;= pdmask;
 	if (start &lt; floor)
<span class="p_chunk">@@ -475,11 +450,10 @@</span> <span class="p_context"> static void free_hugepd_range(struct mmu_gather *tlb, hugepd_t *hpdp, int pdshif</span>
 	for (i = 0; i &lt; num_hugepd; i++, hpdp++)
 		hpdp-&gt;pd = 0;
 
<span class="p_del">-#ifdef CONFIG_PPC_FSL_BOOK3E</span>
<span class="p_del">-	hugepd_free(tlb, hugepte);</span>
<span class="p_del">-#else</span>
<span class="p_del">-	pgtable_free_tlb(tlb, hugepte, pdshift - shift);</span>
<span class="p_del">-#endif</span>
<span class="p_add">+	if (pdshift &lt;= shift)</span>
<span class="p_add">+		hugepd_free(tlb, hugepte);</span>
<span class="p_add">+	else</span>
<span class="p_add">+		pgtable_free_tlb(tlb, hugepte, pdshift - shift);</span>
 }
 
 static void hugetlb_free_pmd_range(struct mmu_gather *tlb, pud_t *pud,
<span class="p_chunk">@@ -502,7 +476,7 @@</span> <span class="p_context"> static void hugetlb_free_pmd_range(struct mmu_gather *tlb, pud_t *pud,</span>
 			WARN_ON(!pmd_none_or_clear_bad(pmd));
 			continue;
 		}
<span class="p_del">-#ifdef CONFIG_PPC_FSL_BOOK3E</span>
<span class="p_add">+#if defined(CONFIG_PPC_FSL_BOOK3E) || defined(CONFIG_PPC_8xx)</span>
 		/*
 		 * Increment next by the size of the huge mapping since
 		 * there may be more than one entry at this level for a
<span class="p_chunk">@@ -550,7 +524,7 @@</span> <span class="p_context"> static void hugetlb_free_pud_range(struct mmu_gather *tlb, pgd_t *pgd,</span>
 			hugetlb_free_pmd_range(tlb, pud, addr, next, floor,
 					       ceiling);
 		} else {
<span class="p_del">-#ifdef CONFIG_PPC_FSL_BOOK3E</span>
<span class="p_add">+#if defined(CONFIG_PPC_FSL_BOOK3E) || defined(CONFIG_PPC_8xx)</span>
 			/*
 			 * Increment next by the size of the huge mapping since
 			 * there may be more than one entry at this level for a
<span class="p_chunk">@@ -615,7 +589,7 @@</span> <span class="p_context"> void hugetlb_free_pgd_range(struct mmu_gather *tlb,</span>
 				continue;
 			hugetlb_free_pud_range(tlb, pgd, addr, next, floor, ceiling);
 		} else {
<span class="p_del">-#ifdef CONFIG_PPC_FSL_BOOK3E</span>
<span class="p_add">+#if defined(CONFIG_PPC_FSL_BOOK3E) || defined(CONFIG_PPC_8xx)</span>
 			/*
 			 * Increment next by the size of the huge mapping since
 			 * there may be more than one entry at the pgd level
<span class="p_chunk">@@ -753,12 +727,13 @@</span> <span class="p_context"> static int __init add_huge_page_size(unsigned long long size)</span>
 
 	/* Check that it is a page size supported by the hardware and
 	 * that it fits within pagetable and slice limits. */
<span class="p_del">-#ifdef CONFIG_PPC_FSL_BOOK3E</span>
<span class="p_del">-	if ((size &lt; PAGE_SIZE) || !is_power_of_4(size))</span>
<span class="p_add">+	if ((size &lt;= PAGE_SIZE))</span>
 		return -EINVAL;
<span class="p_del">-#else</span>
<span class="p_del">-	if (!is_power_of_2(size)</span>
<span class="p_del">-	    || (shift &gt; SLICE_HIGH_SHIFT) || (shift &lt;= PAGE_SHIFT))</span>
<span class="p_add">+#if defined(CONFIG_PPC_FSL_BOOK3E)</span>
<span class="p_add">+	if (!is_power_of_4(size))</span>
<span class="p_add">+		return -EINVAL;</span>
<span class="p_add">+#elif !defined(CONFIG_PPC_8xx)</span>
<span class="p_add">+	if (!is_power_of_2(size) || (shift &gt; SLICE_HIGH_SHIFT))</span>
 		return -EINVAL;
 #endif
 
<span class="p_chunk">@@ -791,51 +766,14 @@</span> <span class="p_context"> static int __init hugepage_setup_sz(char *str)</span>
 }
 __setup(&quot;hugepagesz=&quot;, hugepage_setup_sz);
 
<span class="p_del">-#ifdef CONFIG_PPC_FSL_BOOK3E</span>
<span class="p_del">-static int __init hugetlbpage_init(void)</span>
<span class="p_del">-{</span>
<span class="p_del">-	int psize;</span>
<span class="p_del">-</span>
<span class="p_del">-	for (psize = 0; psize &lt; MMU_PAGE_COUNT; ++psize) {</span>
<span class="p_del">-		unsigned shift;</span>
<span class="p_del">-</span>
<span class="p_del">-		if (!mmu_psize_defs[psize].shift)</span>
<span class="p_del">-			continue;</span>
<span class="p_del">-</span>
<span class="p_del">-		shift = mmu_psize_to_shift(psize);</span>
<span class="p_del">-</span>
<span class="p_del">-		/* Don&#39;t treat normal page sizes as huge... */</span>
<span class="p_del">-		if (shift != PAGE_SHIFT)</span>
<span class="p_del">-			if (add_huge_page_size(1ULL &lt;&lt; shift) &lt; 0)</span>
<span class="p_del">-				continue;</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
<span class="p_del">-	/*</span>
<span class="p_del">-	 * Create a kmem cache for hugeptes.  The bottom bits in the pte have</span>
<span class="p_del">-	 * size information encoded in them, so align them to allow this</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	pgtable_cache_add(1, NULL);</span>
<span class="p_del">-	if (!PGT_CACHE(1))</span>
<span class="p_del">-		panic(&quot;%s: Unable to create kmem cache for hugeptes\n&quot;,</span>
<span class="p_del">-		      __func__);</span>
<span class="p_del">-</span>
<span class="p_del">-	/* Default hpage size = 4M */</span>
<span class="p_del">-	if (mmu_psize_defs[MMU_PAGE_4M].shift)</span>
<span class="p_del">-		HPAGE_SHIFT = mmu_psize_defs[MMU_PAGE_4M].shift;</span>
<span class="p_del">-	else</span>
<span class="p_del">-		panic(&quot;%s: Unable to set default huge page size\n&quot;, __func__);</span>
<span class="p_del">-</span>
<span class="p_del">-</span>
<span class="p_del">-	return 0;</span>
<span class="p_del">-}</span>
<span class="p_del">-#else</span>
 static int __init hugetlbpage_init(void)
 {
 	int psize;
 
<span class="p_add">+#if !defined(CONFIG_PPC_FSL_BOOK3E) &amp;&amp; !defined(CONFIG_PPC_8xx)</span>
 	if (!radix_enabled() &amp;&amp; !mmu_has_feature(MMU_FTR_16M_PAGE))
 		return -ENODEV;
<span class="p_del">-</span>
<span class="p_add">+#endif</span>
 	for (psize = 0; psize &lt; MMU_PAGE_COUNT; ++psize) {
 		unsigned shift;
 		unsigned pdshift;
<span class="p_chunk">@@ -859,15 +797,18 @@</span> <span class="p_context"> static int __init hugetlbpage_init(void)</span>
 		 * use pgt cache for hugepd.
 		 */
 		if (pdshift != shift) {
<span class="p_del">-			pgtable_cache_add(pdshift - shift, NULL);</span>
<span class="p_del">-			if (!PGT_CACHE(pdshift - shift))</span>
<span class="p_add">+			int size_hugepd = pdshift &gt; shift ? pdshift - shift : 1;</span>
<span class="p_add">+</span>
<span class="p_add">+			pgtable_cache_add(size_hugepd, NULL);</span>
<span class="p_add">+			if (!PGT_CACHE(size_hugepd))</span>
 				panic(&quot;hugetlbpage_init(): could not create &quot;
 				      &quot;pgtable cache for %d bit pagesize\n&quot;, shift);
 		}
 	}
 
 	/* Set default large page size. Currently, we pick 16M or 1M
<span class="p_del">-	 * depending on what is available</span>
<span class="p_add">+	 * depending on what is available. On PPC_8xx we select 512K.</span>
<span class="p_add">+	 * We select 4M on other ones.</span>
 	 */
 	if (mmu_psize_defs[MMU_PAGE_16M].shift)
 		HPAGE_SHIFT = mmu_psize_defs[MMU_PAGE_16M].shift;
<span class="p_chunk">@@ -875,11 +816,16 @@</span> <span class="p_context"> static int __init hugetlbpage_init(void)</span>
 		HPAGE_SHIFT = mmu_psize_defs[MMU_PAGE_1M].shift;
 	else if (mmu_psize_defs[MMU_PAGE_2M].shift)
 		HPAGE_SHIFT = mmu_psize_defs[MMU_PAGE_2M].shift;
<span class="p_del">-</span>
<span class="p_add">+	else if (mmu_psize_defs[MMU_PAGE_4M].shift)</span>
<span class="p_add">+		HPAGE_SHIFT = mmu_psize_defs[MMU_PAGE_4M].shift;</span>
<span class="p_add">+	else if (mmu_psize_defs[MMU_PAGE_512K].shift)</span>
<span class="p_add">+		HPAGE_SHIFT = mmu_psize_defs[MMU_PAGE_512K].shift;</span>
<span class="p_add">+	else</span>
<span class="p_add">+		panic(&quot;%s: Unable to set default huge page size\n&quot;, __func__);</span>
 
 	return 0;
 }
<span class="p_del">-#endif</span>
<span class="p_add">+</span>
 arch_initcall(hugetlbpage_init);
 
 void flush_dcache_icache_hugepage(struct page *page)
<span class="p_header">diff --git a/arch/powerpc/mm/tlb_nohash.c b/arch/powerpc/mm/tlb_nohash.c</span>
<span class="p_header">index 050badc..a33522b 100644</span>
<span class="p_header">--- a/arch/powerpc/mm/tlb_nohash.c</span>
<span class="p_header">+++ b/arch/powerpc/mm/tlb_nohash.c</span>
<span class="p_chunk">@@ -53,7 +53,7 @@</span> <span class="p_context"></span>
  * other sizes not listed here.   The .ind field is only used on MMUs that have
  * indirect page table entries.
  */
<span class="p_del">-#ifdef CONFIG_PPC_BOOK3E_MMU</span>
<span class="p_add">+#if defined(CONFIG_PPC_BOOK3E_MMU) || defined (CONFIG_PPC_8xx)</span>
 #ifdef CONFIG_PPC_FSL_BOOK3E
 struct mmu_psize_def mmu_psize_defs[MMU_PAGE_COUNT] = {
 	[MMU_PAGE_4K] = {
<span class="p_chunk">@@ -85,6 +85,25 @@</span> <span class="p_context"> struct mmu_psize_def mmu_psize_defs[MMU_PAGE_COUNT] = {</span>
 		.enc	= BOOK3E_PAGESZ_1GB,
 	},
 };
<span class="p_add">+#elif defined (CONFIG_PPC_8xx)</span>
<span class="p_add">+struct mmu_psize_def mmu_psize_defs[MMU_PAGE_COUNT] = {</span>
<span class="p_add">+	/* we only manage 4k and 16k pages as normal pages */</span>
<span class="p_add">+#ifdef CONFIG_PPC_4K_PAGES</span>
<span class="p_add">+	[MMU_PAGE_4K] = {</span>
<span class="p_add">+		.shift	= 12,</span>
<span class="p_add">+	},</span>
<span class="p_add">+#else</span>
<span class="p_add">+	[MMU_PAGE_16K] = {</span>
<span class="p_add">+		.shift	= 14,</span>
<span class="p_add">+	},</span>
<span class="p_add">+#endif</span>
<span class="p_add">+	[MMU_PAGE_512K] = {</span>
<span class="p_add">+		.shift	= 19,</span>
<span class="p_add">+	},</span>
<span class="p_add">+	[MMU_PAGE_8M] = {</span>
<span class="p_add">+		.shift	= 23,</span>
<span class="p_add">+	},</span>
<span class="p_add">+};</span>
 #else
 struct mmu_psize_def mmu_psize_defs[MMU_PAGE_COUNT] = {
 	[MMU_PAGE_4K] = {
<span class="p_header">diff --git a/arch/powerpc/platforms/8xx/Kconfig b/arch/powerpc/platforms/8xx/Kconfig</span>
<span class="p_header">index 564d99b..80cbcb0 100644</span>
<span class="p_header">--- a/arch/powerpc/platforms/8xx/Kconfig</span>
<span class="p_header">+++ b/arch/powerpc/platforms/8xx/Kconfig</span>
<span class="p_chunk">@@ -130,6 +130,7 @@</span> <span class="p_context"> config 8xx_CPU6</span>
 
 config 8xx_CPU15
 	bool &quot;CPU15 Silicon Errata&quot;
<span class="p_add">+	depends on !HUGETLB_PAGE</span>
 	default y
 	help
 	  This enables a workaround for erratum CPU15 on MPC8xx chips.
<span class="p_header">diff --git a/arch/powerpc/platforms/Kconfig.cputype b/arch/powerpc/platforms/Kconfig.cputype</span>
<span class="p_header">index f32edec..59887ad 100644</span>
<span class="p_header">--- a/arch/powerpc/platforms/Kconfig.cputype</span>
<span class="p_header">+++ b/arch/powerpc/platforms/Kconfig.cputype</span>
<span class="p_chunk">@@ -34,6 +34,7 @@</span> <span class="p_context"> config PPC_8xx</span>
 	select FSL_SOC
 	select 8xx
 	select PPC_LIB_RHEAP
<span class="p_add">+	select SYS_SUPPORTS_HUGETLBFS</span>
 
 config 40x
 	bool &quot;AMCC 40x&quot;

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



