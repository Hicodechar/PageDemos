
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>Linux 4.12.6 - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    Linux 4.12.6</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=37061">gregkh@linuxfoundation.org</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>Aug. 11, 2017, 3:48 p.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;20170811154813.GB8411@kroah.com&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/9896247/mbox/"
   >mbox</a>
|
   <a href="/patch/9896247/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/9896247/">/patch/9896247/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
	[172.30.200.125])
	by pdx-korg-patchwork.web.codeaurora.org (Postfix) with ESMTP id
	4700760325 for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Fri, 11 Aug 2017 15:49:11 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 2097F2857E
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Fri, 11 Aug 2017 15:49:11 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id 14815285A3; Fri, 11 Aug 2017 15:49:11 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-6.9 required=2.0 tests=BAYES_00,RCVD_IN_DNSWL_HI
	autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id BB72328943
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Fri, 11 Aug 2017 15:49:04 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1753346AbdHKPsY (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Fri, 11 Aug 2017 11:48:24 -0400
Received: from mail.linuxfoundation.org ([140.211.169.12]:39748 &quot;EHLO
	mail.linuxfoundation.org&quot; rhost-flags-OK-OK-OK-OK) by vger.kernel.org
	with ESMTP id S1752703AbdHKPsP (ORCPT
	&lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Fri, 11 Aug 2017 11:48:15 -0400
Received: from localhost (unknown [104.132.0.100])
	by mail.linuxfoundation.org (Postfix) with ESMTPSA id 7A89EA70;
	Fri, 11 Aug 2017 15:48:13 +0000 (UTC)
Date: Fri, 11 Aug 2017 08:48:13 -0700
From: Greg KH &lt;gregkh@linuxfoundation.org&gt;
To: linux-kernel@vger.kernel.org, Andrew Morton &lt;akpm@linux-foundation.org&gt;,
	torvalds@linux-foundation.org, stable@vger.kernel.org
Cc: lwn@lwn.net, Jiri Slaby &lt;jslaby@suse.cz&gt;
Subject: Re: Linux 4.12.6
Message-ID: &lt;20170811154813.GB8411@kroah.com&gt;
References: &lt;20170811154805.GA8411@kroah.com&gt;
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Disposition: inline
In-Reply-To: &lt;20170811154805.GA8411@kroah.com&gt;
User-Agent: Mutt/1.8.3 (2017-05-23)
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=37061">gregkh@linuxfoundation.org</a> - Aug. 11, 2017, 3:48 p.m.</div>
<pre class="content">

</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/Makefile b/Makefile</span>
<span class="p_header">index 382e967b0792..c8d80b50495a 100644</span>
<span class="p_header">--- a/Makefile</span>
<span class="p_header">+++ b/Makefile</span>
<span class="p_chunk">@@ -1,6 +1,6 @@</span> <span class="p_context"></span>
 VERSION = 4
 PATCHLEVEL = 12
<span class="p_del">-SUBLEVEL = 5</span>
<span class="p_add">+SUBLEVEL = 6</span>
 EXTRAVERSION =
 NAME = Fearless Coyote
 
<span class="p_header">diff --git a/arch/arm/boot/dts/armada-388-gp.dts b/arch/arm/boot/dts/armada-388-gp.dts</span>
<span class="p_header">index 895fa6cfa15a..563901e0ec07 100644</span>
<span class="p_header">--- a/arch/arm/boot/dts/armada-388-gp.dts</span>
<span class="p_header">+++ b/arch/arm/boot/dts/armada-388-gp.dts</span>
<span class="p_chunk">@@ -75,7 +75,7 @@</span> <span class="p_context"></span>
 					pinctrl-names = &quot;default&quot;;
 					pinctrl-0 = &lt;&amp;pca0_pins&gt;;
 					interrupt-parent = &lt;&amp;gpio0&gt;;
<span class="p_del">-					interrupts = &lt;18 IRQ_TYPE_EDGE_FALLING&gt;;</span>
<span class="p_add">+					interrupts = &lt;18 IRQ_TYPE_LEVEL_LOW&gt;;</span>
 					gpio-controller;
 					#gpio-cells = &lt;2&gt;;
 					interrupt-controller;
<span class="p_chunk">@@ -87,7 +87,7 @@</span> <span class="p_context"></span>
 					compatible = &quot;nxp,pca9555&quot;;
 					pinctrl-names = &quot;default&quot;;
 					interrupt-parent = &lt;&amp;gpio0&gt;;
<span class="p_del">-					interrupts = &lt;18 IRQ_TYPE_EDGE_FALLING&gt;;</span>
<span class="p_add">+					interrupts = &lt;18 IRQ_TYPE_LEVEL_LOW&gt;;</span>
 					gpio-controller;
 					#gpio-cells = &lt;2&gt;;
 					interrupt-controller;
<span class="p_header">diff --git a/arch/arm/boot/dts/tango4-vantage-1172.dts b/arch/arm/boot/dts/tango4-vantage-1172.dts</span>
<span class="p_header">index 86d8df98802f..13bcc460bcb2 100644</span>
<span class="p_header">--- a/arch/arm/boot/dts/tango4-vantage-1172.dts</span>
<span class="p_header">+++ b/arch/arm/boot/dts/tango4-vantage-1172.dts</span>
<span class="p_chunk">@@ -22,7 +22,7 @@</span> <span class="p_context"></span>
 };
 
 &amp;eth0 {
<span class="p_del">-	phy-connection-type = &quot;rgmii&quot;;</span>
<span class="p_add">+	phy-connection-type = &quot;rgmii-id&quot;;</span>
 	phy-handle = &lt;&amp;eth0_phy&gt;;
 	#address-cells = &lt;1&gt;;
 	#size-cells = &lt;0&gt;;
<span class="p_header">diff --git a/arch/arm/mach-mvebu/platsmp.c b/arch/arm/mach-mvebu/platsmp.c</span>
<span class="p_header">index e62273aacb43..4ffbbd217e82 100644</span>
<span class="p_header">--- a/arch/arm/mach-mvebu/platsmp.c</span>
<span class="p_header">+++ b/arch/arm/mach-mvebu/platsmp.c</span>
<span class="p_chunk">@@ -211,7 +211,7 @@</span> <span class="p_context"> static int mv98dx3236_resume_set_cpu_boot_addr(int hw_cpu, void *boot_addr)</span>
 		return PTR_ERR(base);
 
 	writel(0, base + MV98DX3236_CPU_RESUME_CTRL_REG);
<span class="p_del">-	writel(virt_to_phys(boot_addr), base + MV98DX3236_CPU_RESUME_ADDR_REG);</span>
<span class="p_add">+	writel(__pa_symbol(boot_addr), base + MV98DX3236_CPU_RESUME_ADDR_REG);</span>
 
 	iounmap(base);
 
<span class="p_header">diff --git a/arch/arm64/boot/dts/marvell/armada-37xx.dtsi b/arch/arm64/boot/dts/marvell/armada-37xx.dtsi</span>
<span class="p_header">index bc179efb10ef..b69e4a4ecdd8 100644</span>
<span class="p_header">--- a/arch/arm64/boot/dts/marvell/armada-37xx.dtsi</span>
<span class="p_header">+++ b/arch/arm64/boot/dts/marvell/armada-37xx.dtsi</span>
<span class="p_chunk">@@ -219,7 +219,7 @@</span> <span class="p_context"></span>
 				reg = &lt;0x18800 0x100&gt;, &lt;0x18C00 0x20&gt;;
 				gpiosb: gpio {
 					#gpio-cells = &lt;2&gt;;
<span class="p_del">-					gpio-ranges = &lt;&amp;pinctrl_sb 0 0 29&gt;;</span>
<span class="p_add">+					gpio-ranges = &lt;&amp;pinctrl_sb 0 0 30&gt;;</span>
 					gpio-controller;
 					interrupts =
 					&lt;GIC_SPI 160 IRQ_TYPE_LEVEL_HIGH&gt;,
<span class="p_header">diff --git a/arch/mips/include/asm/mach-ralink/ralink_regs.h b/arch/mips/include/asm/mach-ralink/ralink_regs.h</span>
<span class="p_header">index 9df1a53bcb36..b4e7dfa214eb 100644</span>
<span class="p_header">--- a/arch/mips/include/asm/mach-ralink/ralink_regs.h</span>
<span class="p_header">+++ b/arch/mips/include/asm/mach-ralink/ralink_regs.h</span>
<span class="p_chunk">@@ -13,6 +13,8 @@</span> <span class="p_context"></span>
 #ifndef _RALINK_REGS_H_
 #define _RALINK_REGS_H_
 
<span class="p_add">+#include &lt;linux/io.h&gt;</span>
<span class="p_add">+</span>
 enum ralink_soc_type {
 	RALINK_UNKNOWN = 0,
 	RT2880_SOC,
<span class="p_header">diff --git a/arch/parisc/include/asm/thread_info.h b/arch/parisc/include/asm/thread_info.h</span>
<span class="p_header">index 88fe0aad4390..bc208136bbb2 100644</span>
<span class="p_header">--- a/arch/parisc/include/asm/thread_info.h</span>
<span class="p_header">+++ b/arch/parisc/include/asm/thread_info.h</span>
<span class="p_chunk">@@ -34,7 +34,7 @@</span> <span class="p_context"> struct thread_info {</span>
 
 /* thread information allocation */
 
<span class="p_del">-#define THREAD_SIZE_ORDER	2 /* PA-RISC requires at least 16k stack */</span>
<span class="p_add">+#define THREAD_SIZE_ORDER	3 /* PA-RISC requires at least 32k stack */</span>
 /* Be sure to hunt all references to this down when you change the size of
  * the kernel stack */
 #define THREAD_SIZE             (PAGE_SIZE &lt;&lt; THREAD_SIZE_ORDER)
<span class="p_header">diff --git a/arch/parisc/kernel/cache.c b/arch/parisc/kernel/cache.c</span>
<span class="p_header">index 85a92db70afc..19c0c141bc3f 100644</span>
<span class="p_header">--- a/arch/parisc/kernel/cache.c</span>
<span class="p_header">+++ b/arch/parisc/kernel/cache.c</span>
<span class="p_chunk">@@ -587,13 +587,12 @@</span> <span class="p_context"> void flush_cache_range(struct vm_area_struct *vma,</span>
 	if (parisc_requires_coherency())
 		flush_tlb_range(vma, start, end);
 
<span class="p_del">-	if ((end - start) &gt;= parisc_cache_flush_threshold) {</span>
<span class="p_add">+	if ((end - start) &gt;= parisc_cache_flush_threshold</span>
<span class="p_add">+	    || vma-&gt;vm_mm-&gt;context != mfsp(3)) {</span>
 		flush_cache_all();
 		return;
 	}
 
<span class="p_del">-	BUG_ON(vma-&gt;vm_mm-&gt;context != mfsp(3));</span>
<span class="p_del">-</span>
 	flush_user_dcache_range_asm(start, end);
 	if (vma-&gt;vm_flags &amp; VM_EXEC)
 		flush_user_icache_range_asm(start, end);
<span class="p_header">diff --git a/arch/parisc/kernel/irq.c b/arch/parisc/kernel/irq.c</span>
<span class="p_header">index ba5e1c7b1f17..ef9a4eea662f 100644</span>
<span class="p_header">--- a/arch/parisc/kernel/irq.c</span>
<span class="p_header">+++ b/arch/parisc/kernel/irq.c</span>
<span class="p_chunk">@@ -380,7 +380,7 @@</span> <span class="p_context"> static inline int eirr_to_irq(unsigned long eirr)</span>
 /*
  * IRQ STACK - used for irq handler
  */
<span class="p_del">-#define IRQ_STACK_SIZE      (4096 &lt;&lt; 2) /* 16k irq stack size */</span>
<span class="p_add">+#define IRQ_STACK_SIZE      (4096 &lt;&lt; 3) /* 32k irq stack size */</span>
 
 union irq_stack_union {
 	unsigned long stack[IRQ_STACK_SIZE/sizeof(unsigned long)];
<span class="p_header">diff --git a/arch/powerpc/kernel/irq.c b/arch/powerpc/kernel/irq.c</span>
<span class="p_header">index 5c291df30fe3..40d8b552d15a 100644</span>
<span class="p_header">--- a/arch/powerpc/kernel/irq.c</span>
<span class="p_header">+++ b/arch/powerpc/kernel/irq.c</span>
<span class="p_chunk">@@ -145,6 +145,19 @@</span> <span class="p_context"> notrace unsigned int __check_irq_replay(void)</span>
 
 	/* Clear bit 0 which we wouldn&#39;t clear otherwise */
 	local_paca-&gt;irq_happened &amp;= ~PACA_IRQ_HARD_DIS;
<span class="p_add">+	if (happened &amp; PACA_IRQ_HARD_DIS) {</span>
<span class="p_add">+		/*</span>
<span class="p_add">+		 * We may have missed a decrementer interrupt if hard disabled.</span>
<span class="p_add">+		 * Check the decrementer register in case we had a rollover</span>
<span class="p_add">+		 * while hard disabled.</span>
<span class="p_add">+		 */</span>
<span class="p_add">+		if (!(happened &amp; PACA_IRQ_DEC)) {</span>
<span class="p_add">+			if (decrementer_check_overflow()) {</span>
<span class="p_add">+				local_paca-&gt;irq_happened |= PACA_IRQ_DEC;</span>
<span class="p_add">+				happened |= PACA_IRQ_DEC;</span>
<span class="p_add">+			}</span>
<span class="p_add">+		}</span>
<span class="p_add">+	}</span>
 
 	/*
 	 * Force the delivery of pending soft-disabled interrupts on PS3.
<span class="p_chunk">@@ -170,7 +183,7 @@</span> <span class="p_context"> notrace unsigned int __check_irq_replay(void)</span>
 	 * in case we also had a rollover while hard disabled
 	 */
 	local_paca-&gt;irq_happened &amp;= ~PACA_IRQ_DEC;
<span class="p_del">-	if ((happened &amp; PACA_IRQ_DEC) || decrementer_check_overflow())</span>
<span class="p_add">+	if (happened &amp; PACA_IRQ_DEC)</span>
 		return 0x900;
 
 	/* Finally check if an external interrupt happened */
<span class="p_header">diff --git a/arch/powerpc/kernel/ptrace.c b/arch/powerpc/kernel/ptrace.c</span>
<span class="p_header">index 925a4ef90559..660ed39e9c9a 100644</span>
<span class="p_header">--- a/arch/powerpc/kernel/ptrace.c</span>
<span class="p_header">+++ b/arch/powerpc/kernel/ptrace.c</span>
<span class="p_chunk">@@ -127,12 +127,19 @@</span> <span class="p_context"> static void flush_tmregs_to_thread(struct task_struct *tsk)</span>
 	 * If task is not current, it will have been flushed already to
 	 * it&#39;s thread_struct during __switch_to().
 	 *
<span class="p_del">-	 * A reclaim flushes ALL the state.</span>
<span class="p_add">+	 * A reclaim flushes ALL the state or if not in TM save TM SPRs</span>
<span class="p_add">+	 * in the appropriate thread structures from live.</span>
 	 */
 
<span class="p_del">-	if (tsk == current &amp;&amp; MSR_TM_SUSPENDED(mfmsr()))</span>
<span class="p_del">-		tm_reclaim_current(TM_CAUSE_SIGNAL);</span>
<span class="p_add">+	if (tsk != current)</span>
<span class="p_add">+		return;</span>
 
<span class="p_add">+	if (MSR_TM_SUSPENDED(mfmsr())) {</span>
<span class="p_add">+		tm_reclaim_current(TM_CAUSE_SIGNAL);</span>
<span class="p_add">+	} else {</span>
<span class="p_add">+		tm_enable();</span>
<span class="p_add">+		tm_save_sprs(&amp;(tsk-&gt;thread));</span>
<span class="p_add">+	}</span>
 }
 #else
 static inline void flush_tmregs_to_thread(struct task_struct *tsk) { }
<span class="p_header">diff --git a/arch/sparc/include/asm/mmu_context_64.h b/arch/sparc/include/asm/mmu_context_64.h</span>
<span class="p_header">index 2cddcda4f85f..87841d687f8d 100644</span>
<span class="p_header">--- a/arch/sparc/include/asm/mmu_context_64.h</span>
<span class="p_header">+++ b/arch/sparc/include/asm/mmu_context_64.h</span>
<span class="p_chunk">@@ -27,9 +27,11 @@</span> <span class="p_context"> void destroy_context(struct mm_struct *mm);</span>
 void __tsb_context_switch(unsigned long pgd_pa,
 			  struct tsb_config *tsb_base,
 			  struct tsb_config *tsb_huge,
<span class="p_del">-			  unsigned long tsb_descr_pa);</span>
<span class="p_add">+			  unsigned long tsb_descr_pa,</span>
<span class="p_add">+			  unsigned long secondary_ctx);</span>
 
<span class="p_del">-static inline void tsb_context_switch(struct mm_struct *mm)</span>
<span class="p_add">+static inline void tsb_context_switch_ctx(struct mm_struct *mm,</span>
<span class="p_add">+					  unsigned long ctx)</span>
 {
 	__tsb_context_switch(__pa(mm-&gt;pgd),
 			     &amp;mm-&gt;context.tsb_block[MM_TSB_BASE],
<span class="p_chunk">@@ -40,9 +42,12 @@</span> <span class="p_context"> static inline void tsb_context_switch(struct mm_struct *mm)</span>
 #else
 			     NULL
 #endif
<span class="p_del">-			     , __pa(&amp;mm-&gt;context.tsb_descr[MM_TSB_BASE]));</span>
<span class="p_add">+			     , __pa(&amp;mm-&gt;context.tsb_descr[MM_TSB_BASE]),</span>
<span class="p_add">+			     ctx);</span>
 }
 
<span class="p_add">+#define tsb_context_switch(X) tsb_context_switch_ctx(X, 0)</span>
<span class="p_add">+</span>
 void tsb_grow(struct mm_struct *mm,
 	      unsigned long tsb_index,
 	      unsigned long mm_rss);
<span class="p_chunk">@@ -112,8 +117,7 @@</span> <span class="p_context"> static inline void switch_mm(struct mm_struct *old_mm, struct mm_struct *mm, str</span>
 	 * cpu0 to update it&#39;s TSB because at that point the cpu_vm_mask
 	 * only had cpu1 set in it.
 	 */
<span class="p_del">-	load_secondary_context(mm);</span>
<span class="p_del">-	tsb_context_switch(mm);</span>
<span class="p_add">+	tsb_context_switch_ctx(mm, CTX_HWBITS(mm-&gt;context));</span>
 
 	/* Any time a processor runs a context on an address space
 	 * for the first time, we must flush that context out of the
<span class="p_header">diff --git a/arch/sparc/include/asm/trap_block.h b/arch/sparc/include/asm/trap_block.h</span>
<span class="p_header">index ec9c04de3664..ff05992dae7a 100644</span>
<span class="p_header">--- a/arch/sparc/include/asm/trap_block.h</span>
<span class="p_header">+++ b/arch/sparc/include/asm/trap_block.h</span>
<span class="p_chunk">@@ -54,6 +54,7 @@</span> <span class="p_context"> extern struct trap_per_cpu trap_block[NR_CPUS];</span>
 void init_cur_cpu_trap(struct thread_info *);
 void setup_tba(void);
 extern int ncpus_probed;
<span class="p_add">+extern u64 cpu_mondo_counter[NR_CPUS];</span>
 
 unsigned long real_hard_smp_processor_id(void);
 
<span class="p_header">diff --git a/arch/sparc/kernel/smp_64.c b/arch/sparc/kernel/smp_64.c</span>
<span class="p_header">index fdf31040a7dc..3218bc43302e 100644</span>
<span class="p_header">--- a/arch/sparc/kernel/smp_64.c</span>
<span class="p_header">+++ b/arch/sparc/kernel/smp_64.c</span>
<span class="p_chunk">@@ -622,22 +622,48 @@</span> <span class="p_context"> static void cheetah_xcall_deliver(struct trap_per_cpu *tb, int cnt)</span>
 	}
 }
 
<span class="p_del">-/* Multi-cpu list version.  */</span>
<span class="p_add">+#define	CPU_MONDO_COUNTER(cpuid)	(cpu_mondo_counter[cpuid])</span>
<span class="p_add">+#define	MONDO_USEC_WAIT_MIN		2</span>
<span class="p_add">+#define	MONDO_USEC_WAIT_MAX		100</span>
<span class="p_add">+#define	MONDO_RETRY_LIMIT		500000</span>
<span class="p_add">+</span>
<span class="p_add">+/* Multi-cpu list version.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * Deliver xcalls to &#39;cnt&#39; number of cpus in &#39;cpu_list&#39;.</span>
<span class="p_add">+ * Sometimes not all cpus receive the mondo, requiring us to re-send</span>
<span class="p_add">+ * the mondo until all cpus have received, or cpus are truly stuck</span>
<span class="p_add">+ * unable to receive mondo, and we timeout.</span>
<span class="p_add">+ * Occasionally a target cpu strand is borrowed briefly by hypervisor to</span>
<span class="p_add">+ * perform guest service, such as PCIe error handling. Consider the</span>
<span class="p_add">+ * service time, 1 second overall wait is reasonable for 1 cpu.</span>
<span class="p_add">+ * Here two in-between mondo check wait time are defined: 2 usec for</span>
<span class="p_add">+ * single cpu quick turn around and up to 100usec for large cpu count.</span>
<span class="p_add">+ * Deliver mondo to large number of cpus could take longer, we adjusts</span>
<span class="p_add">+ * the retry count as long as target cpus are making forward progress.</span>
<span class="p_add">+ */</span>
 static void hypervisor_xcall_deliver(struct trap_per_cpu *tb, int cnt)
 {
<span class="p_del">-	int retries, this_cpu, prev_sent, i, saw_cpu_error;</span>
<span class="p_add">+	int this_cpu, tot_cpus, prev_sent, i, rem;</span>
<span class="p_add">+	int usec_wait, retries, tot_retries;</span>
<span class="p_add">+	u16 first_cpu = 0xffff;</span>
<span class="p_add">+	unsigned long xc_rcvd = 0;</span>
 	unsigned long status;
<span class="p_add">+	int ecpuerror_id = 0;</span>
<span class="p_add">+	int enocpu_id = 0;</span>
 	u16 *cpu_list;
<span class="p_add">+	u16 cpu;</span>
 
 	this_cpu = smp_processor_id();
<span class="p_del">-</span>
 	cpu_list = __va(tb-&gt;cpu_list_pa);
<span class="p_del">-</span>
<span class="p_del">-	saw_cpu_error = 0;</span>
<span class="p_del">-	retries = 0;</span>
<span class="p_add">+	usec_wait = cnt * MONDO_USEC_WAIT_MIN;</span>
<span class="p_add">+	if (usec_wait &gt; MONDO_USEC_WAIT_MAX)</span>
<span class="p_add">+		usec_wait = MONDO_USEC_WAIT_MAX;</span>
<span class="p_add">+	retries = tot_retries = 0;</span>
<span class="p_add">+	tot_cpus = cnt;</span>
 	prev_sent = 0;
<span class="p_add">+</span>
 	do {
<span class="p_del">-		int forward_progress, n_sent;</span>
<span class="p_add">+		int n_sent, mondo_delivered, target_cpu_busy;</span>
 
 		status = sun4v_cpu_mondo_send(cnt,
 					      tb-&gt;cpu_list_pa,
<span class="p_chunk">@@ -645,94 +671,113 @@</span> <span class="p_context"> static void hypervisor_xcall_deliver(struct trap_per_cpu *tb, int cnt)</span>
 
 		/* HV_EOK means all cpus received the xcall, we&#39;re done.  */
 		if (likely(status == HV_EOK))
<span class="p_del">-			break;</span>
<span class="p_add">+			goto xcall_done;</span>
<span class="p_add">+</span>
<span class="p_add">+		/* If not these non-fatal errors, panic */</span>
<span class="p_add">+		if (unlikely((status != HV_EWOULDBLOCK) &amp;&amp;</span>
<span class="p_add">+			(status != HV_ECPUERROR) &amp;&amp;</span>
<span class="p_add">+			(status != HV_ENOCPU)))</span>
<span class="p_add">+			goto fatal_errors;</span>
 
 		/* First, see if we made any forward progress.
<span class="p_add">+		 *</span>
<span class="p_add">+		 * Go through the cpu_list, count the target cpus that have</span>
<span class="p_add">+		 * received our mondo (n_sent), and those that did not (rem).</span>
<span class="p_add">+		 * Re-pack cpu_list with the cpus remain to be retried in the</span>
<span class="p_add">+		 * front - this simplifies tracking the truly stalled cpus.</span>
 		 *
 		 * The hypervisor indicates successful sends by setting
 		 * cpu list entries to the value 0xffff.
<span class="p_add">+		 *</span>
<span class="p_add">+		 * EWOULDBLOCK means some target cpus did not receive the</span>
<span class="p_add">+		 * mondo and retry usually helps.</span>
<span class="p_add">+		 *</span>
<span class="p_add">+		 * ECPUERROR means at least one target cpu is in error state,</span>
<span class="p_add">+		 * it&#39;s usually safe to skip the faulty cpu and retry.</span>
<span class="p_add">+		 *</span>
<span class="p_add">+		 * ENOCPU means one of the target cpu doesn&#39;t belong to the</span>
<span class="p_add">+		 * domain, perhaps offlined which is unexpected, but not</span>
<span class="p_add">+		 * fatal and it&#39;s okay to skip the offlined cpu.</span>
 		 */
<span class="p_add">+		rem = 0;</span>
 		n_sent = 0;
 		for (i = 0; i &lt; cnt; i++) {
<span class="p_del">-			if (likely(cpu_list[i] == 0xffff))</span>
<span class="p_add">+			cpu = cpu_list[i];</span>
<span class="p_add">+			if (likely(cpu == 0xffff)) {</span>
 				n_sent++;
<span class="p_add">+			} else if ((status == HV_ECPUERROR) &amp;&amp;</span>
<span class="p_add">+				(sun4v_cpu_state(cpu) == HV_CPU_STATE_ERROR)) {</span>
<span class="p_add">+				ecpuerror_id = cpu + 1;</span>
<span class="p_add">+			} else if (status == HV_ENOCPU &amp;&amp; !cpu_online(cpu)) {</span>
<span class="p_add">+				enocpu_id = cpu + 1;</span>
<span class="p_add">+			} else {</span>
<span class="p_add">+				cpu_list[rem++] = cpu;</span>
<span class="p_add">+			}</span>
 		}
 
<span class="p_del">-		forward_progress = 0;</span>
<span class="p_del">-		if (n_sent &gt; prev_sent)</span>
<span class="p_del">-			forward_progress = 1;</span>
<span class="p_add">+		/* No cpu remained, we&#39;re done. */</span>
<span class="p_add">+		if (rem == 0)</span>
<span class="p_add">+			break;</span>
 
<span class="p_del">-		prev_sent = n_sent;</span>
<span class="p_add">+		/* Otherwise, update the cpu count for retry. */</span>
<span class="p_add">+		cnt = rem;</span>
 
<span class="p_del">-		/* If we get a HV_ECPUERROR, then one or more of the cpus</span>
<span class="p_del">-		 * in the list are in error state.  Use the cpu_state()</span>
<span class="p_del">-		 * hypervisor call to find out which cpus are in error state.</span>
<span class="p_add">+		/* Record the overall number of mondos received by the</span>
<span class="p_add">+		 * first of the remaining cpus.</span>
 		 */
<span class="p_del">-		if (unlikely(status == HV_ECPUERROR)) {</span>
<span class="p_del">-			for (i = 0; i &lt; cnt; i++) {</span>
<span class="p_del">-				long err;</span>
<span class="p_del">-				u16 cpu;</span>
<span class="p_add">+		if (first_cpu != cpu_list[0]) {</span>
<span class="p_add">+			first_cpu = cpu_list[0];</span>
<span class="p_add">+			xc_rcvd = CPU_MONDO_COUNTER(first_cpu);</span>
<span class="p_add">+		}</span>
 
<span class="p_del">-				cpu = cpu_list[i];</span>
<span class="p_del">-				if (cpu == 0xffff)</span>
<span class="p_del">-					continue;</span>
<span class="p_add">+		/* Was any mondo delivered successfully? */</span>
<span class="p_add">+		mondo_delivered = (n_sent &gt; prev_sent);</span>
<span class="p_add">+		prev_sent = n_sent;</span>
 
<span class="p_del">-				err = sun4v_cpu_state(cpu);</span>
<span class="p_del">-				if (err == HV_CPU_STATE_ERROR) {</span>
<span class="p_del">-					saw_cpu_error = (cpu + 1);</span>
<span class="p_del">-					cpu_list[i] = 0xffff;</span>
<span class="p_del">-				}</span>
<span class="p_del">-			}</span>
<span class="p_del">-		} else if (unlikely(status != HV_EWOULDBLOCK))</span>
<span class="p_del">-			goto fatal_mondo_error;</span>
<span class="p_add">+		/* or, was any target cpu busy processing other mondos? */</span>
<span class="p_add">+		target_cpu_busy = (xc_rcvd &lt; CPU_MONDO_COUNTER(first_cpu));</span>
<span class="p_add">+		xc_rcvd = CPU_MONDO_COUNTER(first_cpu);</span>
 
<span class="p_del">-		/* Don&#39;t bother rewriting the CPU list, just leave the</span>
<span class="p_del">-		 * 0xffff and non-0xffff entries in there and the</span>
<span class="p_del">-		 * hypervisor will do the right thing.</span>
<span class="p_del">-		 *</span>
<span class="p_del">-		 * Only advance timeout state if we didn&#39;t make any</span>
<span class="p_del">-		 * forward progress.</span>
<span class="p_add">+		/* Retry count is for no progress. If we&#39;re making progress,</span>
<span class="p_add">+		 * reset the retry count.</span>
 		 */
<span class="p_del">-		if (unlikely(!forward_progress)) {</span>
<span class="p_del">-			if (unlikely(++retries &gt; 10000))</span>
<span class="p_del">-				goto fatal_mondo_timeout;</span>
<span class="p_del">-</span>
<span class="p_del">-			/* Delay a little bit to let other cpus catch up</span>
<span class="p_del">-			 * on their cpu mondo queue work.</span>
<span class="p_del">-			 */</span>
<span class="p_del">-			udelay(2 * cnt);</span>
<span class="p_add">+		if (likely(mondo_delivered || target_cpu_busy)) {</span>
<span class="p_add">+			tot_retries += retries;</span>
<span class="p_add">+			retries = 0;</span>
<span class="p_add">+		} else if (unlikely(retries &gt; MONDO_RETRY_LIMIT)) {</span>
<span class="p_add">+			goto fatal_mondo_timeout;</span>
 		}
<span class="p_del">-	} while (1);</span>
 
<span class="p_del">-	if (unlikely(saw_cpu_error))</span>
<span class="p_del">-		goto fatal_mondo_cpu_error;</span>
<span class="p_add">+		/* Delay a little bit to let other cpus catch up on</span>
<span class="p_add">+		 * their cpu mondo queue work.</span>
<span class="p_add">+		 */</span>
<span class="p_add">+		if (!mondo_delivered)</span>
<span class="p_add">+			udelay(usec_wait);</span>
 
<span class="p_del">-	return;</span>
<span class="p_add">+		retries++;</span>
<span class="p_add">+	} while (1);</span>
 
<span class="p_del">-fatal_mondo_cpu_error:</span>
<span class="p_del">-	printk(KERN_CRIT &quot;CPU[%d]: SUN4V mondo cpu error, some target cpus &quot;</span>
<span class="p_del">-	       &quot;(including %d) were in error state\n&quot;,</span>
<span class="p_del">-	       this_cpu, saw_cpu_error - 1);</span>
<span class="p_add">+xcall_done:</span>
<span class="p_add">+	if (unlikely(ecpuerror_id &gt; 0)) {</span>
<span class="p_add">+		pr_crit(&quot;CPU[%d]: SUN4V mondo cpu error, target cpu(%d) was in error state\n&quot;,</span>
<span class="p_add">+		       this_cpu, ecpuerror_id - 1);</span>
<span class="p_add">+	} else if (unlikely(enocpu_id &gt; 0)) {</span>
<span class="p_add">+		pr_crit(&quot;CPU[%d]: SUN4V mondo cpu error, target cpu(%d) does not belong to the domain\n&quot;,</span>
<span class="p_add">+		       this_cpu, enocpu_id - 1);</span>
<span class="p_add">+	}</span>
 	return;
 
<span class="p_add">+fatal_errors:</span>
<span class="p_add">+	/* fatal errors include bad alignment, etc */</span>
<span class="p_add">+	pr_crit(&quot;CPU[%d]: Args were cnt(%d) cpulist_pa(%lx) mondo_block_pa(%lx)\n&quot;,</span>
<span class="p_add">+	       this_cpu, tot_cpus, tb-&gt;cpu_list_pa, tb-&gt;cpu_mondo_block_pa);</span>
<span class="p_add">+	panic(&quot;Unexpected SUN4V mondo error %lu\n&quot;, status);</span>
<span class="p_add">+</span>
 fatal_mondo_timeout:
<span class="p_del">-	printk(KERN_CRIT &quot;CPU[%d]: SUN4V mondo timeout, no forward &quot;</span>
<span class="p_del">-	       &quot; progress after %d retries.\n&quot;,</span>
<span class="p_del">-	       this_cpu, retries);</span>
<span class="p_del">-	goto dump_cpu_list_and_out;</span>
<span class="p_del">-</span>
<span class="p_del">-fatal_mondo_error:</span>
<span class="p_del">-	printk(KERN_CRIT &quot;CPU[%d]: Unexpected SUN4V mondo error %lu\n&quot;,</span>
<span class="p_del">-	       this_cpu, status);</span>
<span class="p_del">-	printk(KERN_CRIT &quot;CPU[%d]: Args were cnt(%d) cpulist_pa(%lx) &quot;</span>
<span class="p_del">-	       &quot;mondo_block_pa(%lx)\n&quot;,</span>
<span class="p_del">-	       this_cpu, cnt, tb-&gt;cpu_list_pa, tb-&gt;cpu_mondo_block_pa);</span>
<span class="p_del">-</span>
<span class="p_del">-dump_cpu_list_and_out:</span>
<span class="p_del">-	printk(KERN_CRIT &quot;CPU[%d]: CPU list [ &quot;, this_cpu);</span>
<span class="p_del">-	for (i = 0; i &lt; cnt; i++)</span>
<span class="p_del">-		printk(&quot;%u &quot;, cpu_list[i]);</span>
<span class="p_del">-	printk(&quot;]\n&quot;);</span>
<span class="p_add">+	/* some cpus being non-responsive to the cpu mondo */</span>
<span class="p_add">+	pr_crit(&quot;CPU[%d]: SUN4V mondo timeout, cpu(%d) made no forward progress after %d retries. Total target cpus(%d).\n&quot;,</span>
<span class="p_add">+	       this_cpu, first_cpu, (tot_retries + retries), tot_cpus);</span>
<span class="p_add">+	panic(&quot;SUN4V mondo timeout panic\n&quot;);</span>
 }
 
 static void (*xcall_deliver_impl)(struct trap_per_cpu *, int);
<span class="p_header">diff --git a/arch/sparc/kernel/sun4v_ivec.S b/arch/sparc/kernel/sun4v_ivec.S</span>
<span class="p_header">index 559bc5e9c199..34631995859a 100644</span>
<span class="p_header">--- a/arch/sparc/kernel/sun4v_ivec.S</span>
<span class="p_header">+++ b/arch/sparc/kernel/sun4v_ivec.S</span>
<span class="p_chunk">@@ -26,6 +26,21 @@</span> <span class="p_context"> sun4v_cpu_mondo:</span>
 	ldxa	[%g0] ASI_SCRATCHPAD, %g4
 	sub	%g4, TRAP_PER_CPU_FAULT_INFO, %g4
 
<span class="p_add">+	/* Get smp_processor_id() into %g3 */</span>
<span class="p_add">+	sethi	%hi(trap_block), %g5</span>
<span class="p_add">+	or	%g5, %lo(trap_block), %g5</span>
<span class="p_add">+	sub	%g4, %g5, %g3</span>
<span class="p_add">+	srlx	%g3, TRAP_BLOCK_SZ_SHIFT, %g3</span>
<span class="p_add">+</span>
<span class="p_add">+	/* Increment cpu_mondo_counter[smp_processor_id()] */</span>
<span class="p_add">+	sethi	%hi(cpu_mondo_counter), %g5</span>
<span class="p_add">+	or	%g5, %lo(cpu_mondo_counter), %g5</span>
<span class="p_add">+	sllx	%g3, 3, %g3</span>
<span class="p_add">+	add	%g5, %g3, %g5</span>
<span class="p_add">+	ldx	[%g5], %g3</span>
<span class="p_add">+	add	%g3, 1, %g3</span>
<span class="p_add">+	stx	%g3, [%g5]</span>
<span class="p_add">+</span>
 	/* Get CPU mondo queue base phys address into %g7.  */
 	ldx	[%g4 + TRAP_PER_CPU_CPU_MONDO_PA], %g7
 
<span class="p_header">diff --git a/arch/sparc/kernel/traps_64.c b/arch/sparc/kernel/traps_64.c</span>
<span class="p_header">index 196ee5eb4d48..ad31af1dd726 100644</span>
<span class="p_header">--- a/arch/sparc/kernel/traps_64.c</span>
<span class="p_header">+++ b/arch/sparc/kernel/traps_64.c</span>
<span class="p_chunk">@@ -2733,6 +2733,7 @@</span> <span class="p_context"> void do_getpsr(struct pt_regs *regs)</span>
 	}
 }
 
<span class="p_add">+u64 cpu_mondo_counter[NR_CPUS] = {0};</span>
 struct trap_per_cpu trap_block[NR_CPUS];
 EXPORT_SYMBOL(trap_block);
 
<span class="p_header">diff --git a/arch/sparc/kernel/tsb.S b/arch/sparc/kernel/tsb.S</span>
<span class="p_header">index 07c0df924960..db872dbfafe9 100644</span>
<span class="p_header">--- a/arch/sparc/kernel/tsb.S</span>
<span class="p_header">+++ b/arch/sparc/kernel/tsb.S</span>
<span class="p_chunk">@@ -360,6 +360,7 @@</span> <span class="p_context"> tsb_flush:</span>
 	 * %o1:	TSB base config pointer
 	 * %o2:	TSB huge config pointer, or NULL if none
 	 * %o3:	Hypervisor TSB descriptor physical address
<span class="p_add">+	 * %o4: Secondary context to load, if non-zero</span>
 	 *
 	 * We have to run this whole thing with interrupts
 	 * disabled so that the current cpu doesn&#39;t change
<span class="p_chunk">@@ -372,6 +373,17 @@</span> <span class="p_context"> __tsb_context_switch:</span>
 	rdpr	%pstate, %g1
 	wrpr	%g1, PSTATE_IE, %pstate
 
<span class="p_add">+	brz,pn	%o4, 1f</span>
<span class="p_add">+	 mov	SECONDARY_CONTEXT, %o5</span>
<span class="p_add">+</span>
<span class="p_add">+661:	stxa	%o4, [%o5] ASI_DMMU</span>
<span class="p_add">+	.section .sun4v_1insn_patch, &quot;ax&quot;</span>
<span class="p_add">+	.word	661b</span>
<span class="p_add">+	stxa	%o4, [%o5] ASI_MMU</span>
<span class="p_add">+	.previous</span>
<span class="p_add">+	flush	%g6</span>
<span class="p_add">+</span>
<span class="p_add">+1:</span>
 	TRAP_LOAD_TRAP_BLOCK(%g2, %g3)
 
 	stx	%o0, [%g2 + TRAP_PER_CPU_PGD_PADDR]
<span class="p_header">diff --git a/arch/sparc/lib/U3memcpy.S b/arch/sparc/lib/U3memcpy.S</span>
<span class="p_header">index 54f98706b03b..5a8cb37f0a3b 100644</span>
<span class="p_header">--- a/arch/sparc/lib/U3memcpy.S</span>
<span class="p_header">+++ b/arch/sparc/lib/U3memcpy.S</span>
<span class="p_chunk">@@ -145,13 +145,13 @@</span> <span class="p_context"> ENDPROC(U3_retl_o2_plus_GS_plus_0x08)</span>
 ENTRY(U3_retl_o2_and_7_plus_GS)
 	and	%o2, 7, %o2
 	retl
<span class="p_del">-	 add	%o2, GLOBAL_SPARE, %o2</span>
<span class="p_add">+	 add	%o2, GLOBAL_SPARE, %o0</span>
 ENDPROC(U3_retl_o2_and_7_plus_GS)
 ENTRY(U3_retl_o2_and_7_plus_GS_plus_8)
 	add	GLOBAL_SPARE, 8, GLOBAL_SPARE
 	and	%o2, 7, %o2
 	retl
<span class="p_del">-	 add	%o2, GLOBAL_SPARE, %o2</span>
<span class="p_add">+	 add	%o2, GLOBAL_SPARE, %o0</span>
 ENDPROC(U3_retl_o2_and_7_plus_GS_plus_8)
 #endif
 
<span class="p_header">diff --git a/arch/sparc/mm/init_64.c b/arch/sparc/mm/init_64.c</span>
<span class="p_header">index 3c40ebd50f92..fed73f14aa49 100644</span>
<span class="p_header">--- a/arch/sparc/mm/init_64.c</span>
<span class="p_header">+++ b/arch/sparc/mm/init_64.c</span>
<span class="p_chunk">@@ -325,6 +325,29 @@</span> <span class="p_context"> static void __update_mmu_tsb_insert(struct mm_struct *mm, unsigned long tsb_inde</span>
 }
 
 #ifdef CONFIG_HUGETLB_PAGE
<span class="p_add">+static void __init add_huge_page_size(unsigned long size)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned int order;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (size_to_hstate(size))</span>
<span class="p_add">+		return;</span>
<span class="p_add">+</span>
<span class="p_add">+	order = ilog2(size) - PAGE_SHIFT;</span>
<span class="p_add">+	hugetlb_add_hstate(order);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static int __init hugetlbpage_init(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	add_huge_page_size(1UL &lt;&lt; HPAGE_64K_SHIFT);</span>
<span class="p_add">+	add_huge_page_size(1UL &lt;&lt; HPAGE_SHIFT);</span>
<span class="p_add">+	add_huge_page_size(1UL &lt;&lt; HPAGE_256MB_SHIFT);</span>
<span class="p_add">+	add_huge_page_size(1UL &lt;&lt; HPAGE_2GB_SHIFT);</span>
<span class="p_add">+</span>
<span class="p_add">+	return 0;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+arch_initcall(hugetlbpage_init);</span>
<span class="p_add">+</span>
 static int __init setup_hugepagesz(char *string)
 {
 	unsigned long long hugepage_size;
<span class="p_chunk">@@ -364,7 +387,7 @@</span> <span class="p_context"> static int __init setup_hugepagesz(char *string)</span>
 		goto out;
 	}
 
<span class="p_del">-	hugetlb_add_hstate(hugepage_shift - PAGE_SHIFT);</span>
<span class="p_add">+	add_huge_page_size(hugepage_size);</span>
 	rc = 1;
 
 out:
<span class="p_header">diff --git a/arch/sparc/power/hibernate.c b/arch/sparc/power/hibernate.c</span>
<span class="p_header">index 17bd2e167e07..df707a8ad311 100644</span>
<span class="p_header">--- a/arch/sparc/power/hibernate.c</span>
<span class="p_header">+++ b/arch/sparc/power/hibernate.c</span>
<span class="p_chunk">@@ -35,6 +35,5 @@</span> <span class="p_context"> void restore_processor_state(void)</span>
 {
 	struct mm_struct *mm = current-&gt;active_mm;
 
<span class="p_del">-	load_secondary_context(mm);</span>
<span class="p_del">-	tsb_context_switch(mm);</span>
<span class="p_add">+	tsb_context_switch_ctx(mm, CTX_HWBITS(mm-&gt;context));</span>
 }
<span class="p_header">diff --git a/arch/x86/kernel/kvm.c b/arch/x86/kernel/kvm.c</span>
<span class="p_header">index 43e10d6fdbed..44adcde7a0ca 100644</span>
<span class="p_header">--- a/arch/x86/kernel/kvm.c</span>
<span class="p_header">+++ b/arch/x86/kernel/kvm.c</span>
<span class="p_chunk">@@ -151,6 +151,8 @@</span> <span class="p_context"> void kvm_async_pf_task_wait(u32 token)</span>
 		if (hlist_unhashed(&amp;n.link))
 			break;
 
<span class="p_add">+		rcu_irq_exit();</span>
<span class="p_add">+</span>
 		if (!n.halted) {
 			local_irq_enable();
 			schedule();
<span class="p_chunk">@@ -159,11 +161,11 @@</span> <span class="p_context"> void kvm_async_pf_task_wait(u32 token)</span>
 			/*
 			 * We cannot reschedule. So halt.
 			 */
<span class="p_del">-			rcu_irq_exit();</span>
 			native_safe_halt();
 			local_irq_disable();
<span class="p_del">-			rcu_irq_enter();</span>
 		}
<span class="p_add">+</span>
<span class="p_add">+		rcu_irq_enter();</span>
 	}
 	if (!n.halted)
 		finish_swait(&amp;n.wq, &amp;wait);
<span class="p_header">diff --git a/block/blk-core.c b/block/blk-core.c</span>
<span class="p_header">index a7421b772d0e..56a7fac71439 100644</span>
<span class="p_header">--- a/block/blk-core.c</span>
<span class="p_header">+++ b/block/blk-core.c</span>
<span class="p_chunk">@@ -3307,6 +3307,10 @@</span> <span class="p_context"> EXPORT_SYMBOL(blk_finish_plug);</span>
  */
 void blk_pm_runtime_init(struct request_queue *q, struct device *dev)
 {
<span class="p_add">+	/* not support for RQF_PM and -&gt;rpm_status in blk-mq yet */</span>
<span class="p_add">+	if (q-&gt;mq_ops)</span>
<span class="p_add">+		return;</span>
<span class="p_add">+</span>
 	q-&gt;dev = dev;
 	q-&gt;rpm_status = RPM_ACTIVE;
 	pm_runtime_set_autosuspend_delay(q-&gt;dev, -1);
<span class="p_header">diff --git a/block/blk-mq-cpumap.c b/block/blk-mq-cpumap.c</span>
<span class="p_header">index 8e61e8640e17..5eaecd40f701 100644</span>
<span class="p_header">--- a/block/blk-mq-cpumap.c</span>
<span class="p_header">+++ b/block/blk-mq-cpumap.c</span>
<span class="p_chunk">@@ -35,7 +35,6 @@</span> <span class="p_context"> int blk_mq_map_queues(struct blk_mq_tag_set *set)</span>
 {
 	unsigned int *map = set-&gt;mq_map;
 	unsigned int nr_queues = set-&gt;nr_hw_queues;
<span class="p_del">-	const struct cpumask *online_mask = cpu_online_mask;</span>
 	unsigned int i, nr_cpus, nr_uniq_cpus, queue, first_sibling;
 	cpumask_var_t cpus;
 
<span class="p_chunk">@@ -44,7 +43,7 @@</span> <span class="p_context"> int blk_mq_map_queues(struct blk_mq_tag_set *set)</span>
 
 	cpumask_clear(cpus);
 	nr_cpus = nr_uniq_cpus = 0;
<span class="p_del">-	for_each_cpu(i, online_mask) {</span>
<span class="p_add">+	for_each_present_cpu(i) {</span>
 		nr_cpus++;
 		first_sibling = get_first_sibling(i);
 		if (!cpumask_test_cpu(first_sibling, cpus))
<span class="p_chunk">@@ -54,7 +53,7 @@</span> <span class="p_context"> int blk_mq_map_queues(struct blk_mq_tag_set *set)</span>
 
 	queue = 0;
 	for_each_possible_cpu(i) {
<span class="p_del">-		if (!cpumask_test_cpu(i, online_mask)) {</span>
<span class="p_add">+		if (!cpumask_test_cpu(i, cpu_present_mask)) {</span>
 			map[i] = 0;
 			continue;
 		}
<span class="p_header">diff --git a/block/blk-mq.c b/block/blk-mq.c</span>
<span class="p_header">index 958cedaff8b8..7353e0080062 100644</span>
<span class="p_header">--- a/block/blk-mq.c</span>
<span class="p_header">+++ b/block/blk-mq.c</span>
<span class="p_chunk">@@ -37,9 +37,6 @@</span> <span class="p_context"></span>
 #include &quot;blk-wbt.h&quot;
 #include &quot;blk-mq-sched.h&quot;
 
<span class="p_del">-static DEFINE_MUTEX(all_q_mutex);</span>
<span class="p_del">-static LIST_HEAD(all_q_list);</span>
<span class="p_del">-</span>
 static void blk_mq_poll_stats_start(struct request_queue *q);
 static void blk_mq_poll_stats_fn(struct blk_stat_callback *cb);
 static void __blk_mq_stop_hw_queues(struct request_queue *q, bool sync);
<span class="p_chunk">@@ -1975,8 +1972,8 @@</span> <span class="p_context"> static void blk_mq_init_cpu_queues(struct request_queue *q,</span>
 		INIT_LIST_HEAD(&amp;__ctx-&gt;rq_list);
 		__ctx-&gt;queue = q;
 
<span class="p_del">-		/* If the cpu isn&#39;t online, the cpu is mapped to first hctx */</span>
<span class="p_del">-		if (!cpu_online(i))</span>
<span class="p_add">+		/* If the cpu isn&#39;t present, the cpu is mapped to first hctx */</span>
<span class="p_add">+		if (!cpu_present(i))</span>
 			continue;
 
 		hctx = blk_mq_map_queue(q, i);
<span class="p_chunk">@@ -2019,8 +2016,7 @@</span> <span class="p_context"> static void blk_mq_free_map_and_requests(struct blk_mq_tag_set *set,</span>
 	}
 }
 
<span class="p_del">-static void blk_mq_map_swqueue(struct request_queue *q,</span>
<span class="p_del">-			       const struct cpumask *online_mask)</span>
<span class="p_add">+static void blk_mq_map_swqueue(struct request_queue *q)</span>
 {
 	unsigned int i, hctx_idx;
 	struct blk_mq_hw_ctx *hctx;
<span class="p_chunk">@@ -2038,13 +2034,11 @@</span> <span class="p_context"> static void blk_mq_map_swqueue(struct request_queue *q,</span>
 	}
 
 	/*
<span class="p_del">-	 * Map software to hardware queues</span>
<span class="p_add">+	 * Map software to hardware queues.</span>
<span class="p_add">+	 *</span>
<span class="p_add">+	 * If the cpu isn&#39;t present, the cpu is mapped to first hctx.</span>
 	 */
<span class="p_del">-	for_each_possible_cpu(i) {</span>
<span class="p_del">-		/* If the cpu isn&#39;t online, the cpu is mapped to first hctx */</span>
<span class="p_del">-		if (!cpumask_test_cpu(i, online_mask))</span>
<span class="p_del">-			continue;</span>
<span class="p_del">-</span>
<span class="p_add">+	for_each_present_cpu(i) {</span>
 		hctx_idx = q-&gt;mq_map[i];
 		/* unmapped hw queue can be remapped after CPU topo changed */
 		if (!set-&gt;tags[hctx_idx] &amp;&amp;
<span class="p_chunk">@@ -2340,16 +2334,8 @@</span> <span class="p_context"> struct request_queue *blk_mq_init_allocated_queue(struct blk_mq_tag_set *set,</span>
 		blk_queue_softirq_done(q, set-&gt;ops-&gt;complete);
 
 	blk_mq_init_cpu_queues(q, set-&gt;nr_hw_queues);
<span class="p_del">-</span>
<span class="p_del">-	get_online_cpus();</span>
<span class="p_del">-	mutex_lock(&amp;all_q_mutex);</span>
<span class="p_del">-</span>
<span class="p_del">-	list_add_tail(&amp;q-&gt;all_q_node, &amp;all_q_list);</span>
 	blk_mq_add_queue_tag_set(set, q);
<span class="p_del">-	blk_mq_map_swqueue(q, cpu_online_mask);</span>
<span class="p_del">-</span>
<span class="p_del">-	mutex_unlock(&amp;all_q_mutex);</span>
<span class="p_del">-	put_online_cpus();</span>
<span class="p_add">+	blk_mq_map_swqueue(q);</span>
 
 	if (!(set-&gt;flags &amp; BLK_MQ_F_NO_SCHED)) {
 		int ret;
<span class="p_chunk">@@ -2375,18 +2361,12 @@</span> <span class="p_context"> void blk_mq_free_queue(struct request_queue *q)</span>
 {
 	struct blk_mq_tag_set	*set = q-&gt;tag_set;
 
<span class="p_del">-	mutex_lock(&amp;all_q_mutex);</span>
<span class="p_del">-	list_del_init(&amp;q-&gt;all_q_node);</span>
<span class="p_del">-	mutex_unlock(&amp;all_q_mutex);</span>
<span class="p_del">-</span>
 	blk_mq_del_queue_tag_set(q);
<span class="p_del">-</span>
 	blk_mq_exit_hw_queues(q, set, set-&gt;nr_hw_queues);
 }
 
 /* Basically redo blk_mq_init_queue with queue frozen */
<span class="p_del">-static void blk_mq_queue_reinit(struct request_queue *q,</span>
<span class="p_del">-				const struct cpumask *online_mask)</span>
<span class="p_add">+static void blk_mq_queue_reinit(struct request_queue *q)</span>
 {
 	WARN_ON_ONCE(!atomic_read(&amp;q-&gt;mq_freeze_depth));
 
<span class="p_chunk">@@ -2399,76 +2379,12 @@</span> <span class="p_context"> static void blk_mq_queue_reinit(struct request_queue *q,</span>
 	 * involves free and re-allocate memory, worthy doing?)
 	 */
 
<span class="p_del">-	blk_mq_map_swqueue(q, online_mask);</span>
<span class="p_add">+	blk_mq_map_swqueue(q);</span>
 
 	blk_mq_sysfs_register(q);
 	blk_mq_debugfs_register_hctxs(q);
 }
 
<span class="p_del">-/*</span>
<span class="p_del">- * New online cpumask which is going to be set in this hotplug event.</span>
<span class="p_del">- * Declare this cpumasks as global as cpu-hotplug operation is invoked</span>
<span class="p_del">- * one-by-one and dynamically allocating this could result in a failure.</span>
<span class="p_del">- */</span>
<span class="p_del">-static struct cpumask cpuhp_online_new;</span>
<span class="p_del">-</span>
<span class="p_del">-static void blk_mq_queue_reinit_work(void)</span>
<span class="p_del">-{</span>
<span class="p_del">-	struct request_queue *q;</span>
<span class="p_del">-</span>
<span class="p_del">-	mutex_lock(&amp;all_q_mutex);</span>
<span class="p_del">-	/*</span>
<span class="p_del">-	 * We need to freeze and reinit all existing queues.  Freezing</span>
<span class="p_del">-	 * involves synchronous wait for an RCU grace period and doing it</span>
<span class="p_del">-	 * one by one may take a long time.  Start freezing all queues in</span>
<span class="p_del">-	 * one swoop and then wait for the completions so that freezing can</span>
<span class="p_del">-	 * take place in parallel.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	list_for_each_entry(q, &amp;all_q_list, all_q_node)</span>
<span class="p_del">-		blk_freeze_queue_start(q);</span>
<span class="p_del">-	list_for_each_entry(q, &amp;all_q_list, all_q_node)</span>
<span class="p_del">-		blk_mq_freeze_queue_wait(q);</span>
<span class="p_del">-</span>
<span class="p_del">-	list_for_each_entry(q, &amp;all_q_list, all_q_node)</span>
<span class="p_del">-		blk_mq_queue_reinit(q, &amp;cpuhp_online_new);</span>
<span class="p_del">-</span>
<span class="p_del">-	list_for_each_entry(q, &amp;all_q_list, all_q_node)</span>
<span class="p_del">-		blk_mq_unfreeze_queue(q);</span>
<span class="p_del">-</span>
<span class="p_del">-	mutex_unlock(&amp;all_q_mutex);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static int blk_mq_queue_reinit_dead(unsigned int cpu)</span>
<span class="p_del">-{</span>
<span class="p_del">-	cpumask_copy(&amp;cpuhp_online_new, cpu_online_mask);</span>
<span class="p_del">-	blk_mq_queue_reinit_work();</span>
<span class="p_del">-	return 0;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-/*</span>
<span class="p_del">- * Before hotadded cpu starts handling requests, new mappings must be</span>
<span class="p_del">- * established.  Otherwise, these requests in hw queue might never be</span>
<span class="p_del">- * dispatched.</span>
<span class="p_del">- *</span>
<span class="p_del">- * For example, there is a single hw queue (hctx) and two CPU queues (ctx0</span>
<span class="p_del">- * for CPU0, and ctx1 for CPU1).</span>
<span class="p_del">- *</span>
<span class="p_del">- * Now CPU1 is just onlined and a request is inserted into ctx1-&gt;rq_list</span>
<span class="p_del">- * and set bit0 in pending bitmap as ctx1-&gt;index_hw is still zero.</span>
<span class="p_del">- *</span>
<span class="p_del">- * And then while running hw queue, blk_mq_flush_busy_ctxs() finds bit0 is set</span>
<span class="p_del">- * in pending bitmap and tries to retrieve requests in hctx-&gt;ctxs[0]-&gt;rq_list.</span>
<span class="p_del">- * But htx-&gt;ctxs[0] is a pointer to ctx0, so the request in ctx1-&gt;rq_list is</span>
<span class="p_del">- * ignored.</span>
<span class="p_del">- */</span>
<span class="p_del">-static int blk_mq_queue_reinit_prepare(unsigned int cpu)</span>
<span class="p_del">-{</span>
<span class="p_del">-	cpumask_copy(&amp;cpuhp_online_new, cpu_online_mask);</span>
<span class="p_del">-	cpumask_set_cpu(cpu, &amp;cpuhp_online_new);</span>
<span class="p_del">-	blk_mq_queue_reinit_work();</span>
<span class="p_del">-	return 0;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
 static int __blk_mq_alloc_rq_maps(struct blk_mq_tag_set *set)
 {
 	int i;
<span class="p_chunk">@@ -2679,7 +2595,7 @@</span> <span class="p_context"> static void __blk_mq_update_nr_hw_queues(struct blk_mq_tag_set *set,</span>
 	blk_mq_update_queue_map(set);
 	list_for_each_entry(q, &amp;set-&gt;tag_list, tag_set_list) {
 		blk_mq_realloc_hw_ctxs(set, q);
<span class="p_del">-		blk_mq_queue_reinit(q, cpu_online_mask);</span>
<span class="p_add">+		blk_mq_queue_reinit(q);</span>
 	}
 
 	list_for_each_entry(q, &amp;set-&gt;tag_list, tag_set_list)
<span class="p_chunk">@@ -2895,24 +2811,10 @@</span> <span class="p_context"> bool blk_mq_poll(struct request_queue *q, blk_qc_t cookie)</span>
 }
 EXPORT_SYMBOL_GPL(blk_mq_poll);
 
<span class="p_del">-void blk_mq_disable_hotplug(void)</span>
<span class="p_del">-{</span>
<span class="p_del">-	mutex_lock(&amp;all_q_mutex);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-void blk_mq_enable_hotplug(void)</span>
<span class="p_del">-{</span>
<span class="p_del">-	mutex_unlock(&amp;all_q_mutex);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
 static int __init blk_mq_init(void)
 {
 	cpuhp_setup_state_multi(CPUHP_BLK_MQ_DEAD, &quot;block/mq:dead&quot;, NULL,
 				blk_mq_hctx_notify_dead);
<span class="p_del">-</span>
<span class="p_del">-	cpuhp_setup_state_nocalls(CPUHP_BLK_MQ_PREPARE, &quot;block/mq:prepare&quot;,</span>
<span class="p_del">-				  blk_mq_queue_reinit_prepare,</span>
<span class="p_del">-				  blk_mq_queue_reinit_dead);</span>
 	return 0;
 }
 subsys_initcall(blk_mq_init);
<span class="p_header">diff --git a/block/blk-mq.h b/block/blk-mq.h</span>
<span class="p_header">index cc67b48e3551..558df56544d2 100644</span>
<span class="p_header">--- a/block/blk-mq.h</span>
<span class="p_header">+++ b/block/blk-mq.h</span>
<span class="p_chunk">@@ -56,11 +56,6 @@</span> <span class="p_context"> void __blk_mq_insert_request(struct blk_mq_hw_ctx *hctx, struct request *rq,</span>
 				bool at_head);
 void blk_mq_insert_requests(struct blk_mq_hw_ctx *hctx, struct blk_mq_ctx *ctx,
 				struct list_head *list);
<span class="p_del">-/*</span>
<span class="p_del">- * CPU hotplug helpers</span>
<span class="p_del">- */</span>
<span class="p_del">-void blk_mq_enable_hotplug(void);</span>
<span class="p_del">-void blk_mq_disable_hotplug(void);</span>
 
 /*
  * CPU -&gt; queue mappings
<span class="p_header">diff --git a/drivers/acpi/acpi_lpss.c b/drivers/acpi/acpi_lpss.c</span>
<span class="p_header">index 10347e3d73ad..5bd58bd4ab05 100644</span>
<span class="p_header">--- a/drivers/acpi/acpi_lpss.c</span>
<span class="p_header">+++ b/drivers/acpi/acpi_lpss.c</span>
<span class="p_chunk">@@ -85,6 +85,7 @@</span> <span class="p_context"> static const struct lpss_device_desc lpss_dma_desc = {</span>
 };
 
 struct lpss_private_data {
<span class="p_add">+	struct acpi_device *adev;</span>
 	void __iomem *mmio_base;
 	resource_size_t mmio_size;
 	unsigned int fixed_clk_rate;
<span class="p_chunk">@@ -155,6 +156,12 @@</span> <span class="p_context"> static struct pwm_lookup byt_pwm_lookup[] = {</span>
 
 static void byt_pwm_setup(struct lpss_private_data *pdata)
 {
<span class="p_add">+	struct acpi_device *adev = pdata-&gt;adev;</span>
<span class="p_add">+</span>
<span class="p_add">+	/* Only call pwm_add_table for the first PWM controller */</span>
<span class="p_add">+	if (!adev-&gt;pnp.unique_id || strcmp(adev-&gt;pnp.unique_id, &quot;1&quot;))</span>
<span class="p_add">+		return;</span>
<span class="p_add">+</span>
 	if (!acpi_dev_present(&quot;INT33FD&quot;, NULL, -1))
 		pwm_add_table(byt_pwm_lookup, ARRAY_SIZE(byt_pwm_lookup));
 }
<span class="p_chunk">@@ -180,6 +187,12 @@</span> <span class="p_context"> static struct pwm_lookup bsw_pwm_lookup[] = {</span>
 
 static void bsw_pwm_setup(struct lpss_private_data *pdata)
 {
<span class="p_add">+	struct acpi_device *adev = pdata-&gt;adev;</span>
<span class="p_add">+</span>
<span class="p_add">+	/* Only call pwm_add_table for the first PWM controller */</span>
<span class="p_add">+	if (!adev-&gt;pnp.unique_id || strcmp(adev-&gt;pnp.unique_id, &quot;1&quot;))</span>
<span class="p_add">+		return;</span>
<span class="p_add">+</span>
 	pwm_add_table(bsw_pwm_lookup, ARRAY_SIZE(bsw_pwm_lookup));
 }
 
<span class="p_chunk">@@ -456,6 +469,7 @@</span> <span class="p_context"> static int acpi_lpss_create_device(struct acpi_device *adev,</span>
 		goto err_out;
 	}
 
<span class="p_add">+	pdata-&gt;adev = adev;</span>
 	pdata-&gt;dev_desc = dev_desc;
 
 	if (dev_desc-&gt;setup)
<span class="p_header">diff --git a/drivers/ata/libata-scsi.c b/drivers/ata/libata-scsi.c</span>
<span class="p_header">index 49ba9834c715..12d59968020f 100644</span>
<span class="p_header">--- a/drivers/ata/libata-scsi.c</span>
<span class="p_header">+++ b/drivers/ata/libata-scsi.c</span>
<span class="p_chunk">@@ -3028,10 +3028,12 @@</span> <span class="p_context"> static unsigned int atapi_xlat(struct ata_queued_cmd *qc)</span>
 static struct ata_device *ata_find_dev(struct ata_port *ap, int devno)
 {
 	if (!sata_pmp_attached(ap)) {
<span class="p_del">-		if (likely(devno &lt; ata_link_max_devices(&amp;ap-&gt;link)))</span>
<span class="p_add">+		if (likely(devno &gt;= 0 &amp;&amp;</span>
<span class="p_add">+			   devno &lt; ata_link_max_devices(&amp;ap-&gt;link)))</span>
 			return &amp;ap-&gt;link.device[devno];
 	} else {
<span class="p_del">-		if (likely(devno &lt; ap-&gt;nr_pmp_links))</span>
<span class="p_add">+		if (likely(devno &gt;= 0 &amp;&amp;</span>
<span class="p_add">+			   devno &lt; ap-&gt;nr_pmp_links))</span>
 			return &amp;ap-&gt;pmp_link[devno].device[0];
 	}
 
<span class="p_header">diff --git a/drivers/clk/sunxi-ng/ccu-sun5i.c b/drivers/clk/sunxi-ng/ccu-sun5i.c</span>
<span class="p_header">index 5372bf8be5e6..31d7ffda9aab 100644</span>
<span class="p_header">--- a/drivers/clk/sunxi-ng/ccu-sun5i.c</span>
<span class="p_header">+++ b/drivers/clk/sunxi-ng/ccu-sun5i.c</span>
<span class="p_chunk">@@ -184,7 +184,7 @@</span> <span class="p_context"> static struct ccu_mux cpu_clk = {</span>
 		.hw.init	= CLK_HW_INIT_PARENTS(&quot;cpu&quot;,
 						      cpu_parents,
 						      &amp;ccu_mux_ops,
<span class="p_del">-						      CLK_IS_CRITICAL),</span>
<span class="p_add">+						      CLK_SET_RATE_PARENT | CLK_IS_CRITICAL),</span>
 	}
 };
 
<span class="p_header">diff --git a/drivers/gpio/gpiolib.c b/drivers/gpio/gpiolib.c</span>
<span class="p_header">index a42a1eea5714..2e96b3d46e0c 100644</span>
<span class="p_header">--- a/drivers/gpio/gpiolib.c</span>
<span class="p_header">+++ b/drivers/gpio/gpiolib.c</span>
<span class="p_chunk">@@ -704,24 +704,23 @@</span> <span class="p_context"> static irqreturn_t lineevent_irq_thread(int irq, void *p)</span>
 {
 	struct lineevent_state *le = p;
 	struct gpioevent_data ge;
<span class="p_del">-	int ret;</span>
<span class="p_add">+	int ret, level;</span>
 
 	ge.timestamp = ktime_get_real_ns();
<span class="p_add">+	level = gpiod_get_value_cansleep(le-&gt;desc);</span>
 
 	if (le-&gt;eflags &amp; GPIOEVENT_REQUEST_RISING_EDGE
 	    &amp;&amp; le-&gt;eflags &amp; GPIOEVENT_REQUEST_FALLING_EDGE) {
<span class="p_del">-		int level = gpiod_get_value_cansleep(le-&gt;desc);</span>
<span class="p_del">-</span>
 		if (level)
 			/* Emit low-to-high event */
 			ge.id = GPIOEVENT_EVENT_RISING_EDGE;
 		else
 			/* Emit high-to-low event */
 			ge.id = GPIOEVENT_EVENT_FALLING_EDGE;
<span class="p_del">-	} else if (le-&gt;eflags &amp; GPIOEVENT_REQUEST_RISING_EDGE) {</span>
<span class="p_add">+	} else if (le-&gt;eflags &amp; GPIOEVENT_REQUEST_RISING_EDGE &amp;&amp; level) {</span>
 		/* Emit low-to-high event */
 		ge.id = GPIOEVENT_EVENT_RISING_EDGE;
<span class="p_del">-	} else if (le-&gt;eflags &amp; GPIOEVENT_REQUEST_FALLING_EDGE) {</span>
<span class="p_add">+	} else if (le-&gt;eflags &amp; GPIOEVENT_REQUEST_FALLING_EDGE &amp;&amp; !level) {</span>
 		/* Emit high-to-low event */
 		ge.id = GPIOEVENT_EVENT_FALLING_EDGE;
 	} else {
<span class="p_header">diff --git a/drivers/gpu/drm/amd/amdgpu/clearstate_gfx9.h b/drivers/gpu/drm/amd/amdgpu/clearstate_gfx9.h</span>
<span class="p_header">index 18fd01f3e4b2..003a131bad47 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/amd/amdgpu/clearstate_gfx9.h</span>
<span class="p_header">+++ b/drivers/gpu/drm/amd/amdgpu/clearstate_gfx9.h</span>
<span class="p_chunk">@@ -1,24 +1,25 @@</span> <span class="p_context"></span>
<span class="p_del">-</span>
 /*
<span class="p_del">-***************************************************************************************************</span>
<span class="p_del">-*</span>
<span class="p_del">-*  Trade secret of Advanced Micro Devices, Inc.</span>
<span class="p_del">-*  Copyright (c) 2010 Advanced Micro Devices, Inc. (unpublished)</span>
<span class="p_del">-*</span>
<span class="p_del">-*  All rights reserved.  This notice is intended as a precaution against inadvertent publication and</span>
<span class="p_del">-*  does not imply publication or any waiver of confidentiality.  The year included in the foregoing</span>
<span class="p_del">-*  notice is the year of creation of the work.</span>
<span class="p_del">-*</span>
<span class="p_del">-***************************************************************************************************</span>
<span class="p_del">-*/</span>
<span class="p_del">-/**</span>
<span class="p_del">-***************************************************************************************************</span>
<span class="p_del">-* @brief gfx9 Clearstate Definitions</span>
<span class="p_del">-***************************************************************************************************</span>
<span class="p_del">-*</span>
<span class="p_del">-*   Do not edit! This is a machine-generated file!</span>
<span class="p_del">-*</span>
<span class="p_del">-*/</span>
<span class="p_add">+ * Copyright 2017 Advanced Micro Devices, Inc.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * Permission is hereby granted, free of charge, to any person obtaining a</span>
<span class="p_add">+ * copy of this software and associated documentation files (the &quot;Software&quot;),</span>
<span class="p_add">+ * to deal in the Software without restriction, including without limitation</span>
<span class="p_add">+ * the rights to use, copy, modify, merge, publish, distribute, sublicense,</span>
<span class="p_add">+ * and/or sell copies of the Software, and to permit persons to whom the</span>
<span class="p_add">+ * Software is furnished to do so, subject to the following conditions:</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * The above copyright notice and this permission notice shall be included in</span>
<span class="p_add">+ * all copies or substantial portions of the Software.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * THE SOFTWARE IS PROVIDED &quot;AS IS&quot;, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR</span>
<span class="p_add">+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,</span>
<span class="p_add">+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL</span>
<span class="p_add">+ * THE COPYRIGHT HOLDER(S) OR AUTHOR(S) BE LIABLE FOR ANY CLAIM, DAMAGES OR</span>
<span class="p_add">+ * OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,</span>
<span class="p_add">+ * ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR</span>
<span class="p_add">+ * OTHER DEALINGS IN THE SOFTWARE.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ */</span>
 
 static const unsigned int gfx9_SECT_CONTEXT_def_1[] =
 {
<span class="p_header">diff --git a/drivers/gpu/drm/amd/amdgpu/si.c b/drivers/gpu/drm/amd/amdgpu/si.c</span>
<span class="p_header">index c0b1aabf282f..7dbb7cf47986 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/amd/amdgpu/si.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/amd/amdgpu/si.c</span>
<span class="p_chunk">@@ -1385,6 +1385,7 @@</span> <span class="p_context"> static void si_init_golden_registers(struct amdgpu_device *adev)</span>
 		amdgpu_program_register_sequence(adev,
 						 pitcairn_mgcg_cgcg_init,
 						 (const u32)ARRAY_SIZE(pitcairn_mgcg_cgcg_init));
<span class="p_add">+		break;</span>
 	case CHIP_VERDE:
 		amdgpu_program_register_sequence(adev,
 						 verde_golden_registers,
<span class="p_chunk">@@ -1409,6 +1410,7 @@</span> <span class="p_context"> static void si_init_golden_registers(struct amdgpu_device *adev)</span>
 		amdgpu_program_register_sequence(adev,
 						 oland_mgcg_cgcg_init,
 						 (const u32)ARRAY_SIZE(oland_mgcg_cgcg_init));
<span class="p_add">+		break;</span>
 	case CHIP_HAINAN:
 		amdgpu_program_register_sequence(adev,
 						 hainan_golden_registers,
<span class="p_header">diff --git a/drivers/gpu/drm/vmwgfx/vmwgfx_kms.c b/drivers/gpu/drm/vmwgfx/vmwgfx_kms.c</span>
<span class="p_header">index 1d2db5d912b0..f8a977f86ec7 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/vmwgfx/vmwgfx_kms.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/vmwgfx/vmwgfx_kms.c</span>
<span class="p_chunk">@@ -384,6 +384,12 @@</span> <span class="p_context"> vmw_du_cursor_plane_atomic_update(struct drm_plane *plane,</span>
 
 	hotspot_x = du-&gt;hotspot_x;
 	hotspot_y = du-&gt;hotspot_y;
<span class="p_add">+</span>
<span class="p_add">+	if (plane-&gt;fb) {</span>
<span class="p_add">+		hotspot_x += plane-&gt;fb-&gt;hot_x;</span>
<span class="p_add">+		hotspot_y += plane-&gt;fb-&gt;hot_y;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
 	du-&gt;cursor_surface = vps-&gt;surf;
 	du-&gt;cursor_dmabuf = vps-&gt;dmabuf;
 
<span class="p_chunk">@@ -411,6 +417,9 @@</span> <span class="p_context"> vmw_du_cursor_plane_atomic_update(struct drm_plane *plane,</span>
 		vmw_cursor_update_position(dev_priv, true,
 					   du-&gt;cursor_x + hotspot_x,
 					   du-&gt;cursor_y + hotspot_y);
<span class="p_add">+</span>
<span class="p_add">+		du-&gt;core_hotspot_x = hotspot_x - du-&gt;hotspot_x;</span>
<span class="p_add">+		du-&gt;core_hotspot_y = hotspot_y - du-&gt;hotspot_y;</span>
 	} else {
 		DRM_ERROR(&quot;Failed to update cursor image\n&quot;);
 	}
<span class="p_header">diff --git a/drivers/iommu/amd_iommu.c b/drivers/iommu/amd_iommu.c</span>
<span class="p_header">index 0f1219fa8561..28fbc81c6e9e 100644</span>
<span class="p_header">--- a/drivers/iommu/amd_iommu.c</span>
<span class="p_header">+++ b/drivers/iommu/amd_iommu.c</span>
<span class="p_chunk">@@ -4316,6 +4316,7 @@</span> <span class="p_context"> static int amd_ir_set_vcpu_affinity(struct irq_data *data, void *vcpu_info)</span>
 		/* Setting */
 		irte-&gt;hi.fields.ga_root_ptr = (pi_data-&gt;base &gt;&gt; 12);
 		irte-&gt;hi.fields.vector = vcpu_pi_info-&gt;vector;
<span class="p_add">+		irte-&gt;lo.fields_vapic.ga_log_intr = 1;</span>
 		irte-&gt;lo.fields_vapic.guest_mode = 1;
 		irte-&gt;lo.fields_vapic.ga_tag = pi_data-&gt;ga_tag;
 
<span class="p_header">diff --git a/drivers/media/pci/saa7164/saa7164-bus.c b/drivers/media/pci/saa7164/saa7164-bus.c</span>
<span class="p_header">index b2ff82fa7116..ecfeac5cdbed 100644</span>
<span class="p_header">--- a/drivers/media/pci/saa7164/saa7164-bus.c</span>
<span class="p_header">+++ b/drivers/media/pci/saa7164/saa7164-bus.c</span>
<span class="p_chunk">@@ -389,11 +389,11 @@</span> <span class="p_context"> int saa7164_bus_get(struct saa7164_dev *dev, struct tmComResInfo* msg,</span>
 	msg_tmp.size = le16_to_cpu((__force __le16)msg_tmp.size);
 	msg_tmp.command = le32_to_cpu((__force __le32)msg_tmp.command);
 	msg_tmp.controlselector = le16_to_cpu((__force __le16)msg_tmp.controlselector);
<span class="p_add">+	memcpy(msg, &amp;msg_tmp, sizeof(*msg));</span>
 
 	/* No need to update the read positions, because this was a peek */
 	/* If the caller specifically want to peek, return */
 	if (peekonly) {
<span class="p_del">-		memcpy(msg, &amp;msg_tmp, sizeof(*msg));</span>
 		goto peekout;
 	}
 
<span class="p_chunk">@@ -438,21 +438,15 @@</span> <span class="p_context"> int saa7164_bus_get(struct saa7164_dev *dev, struct tmComResInfo* msg,</span>
 		space_rem = bus-&gt;m_dwSizeGetRing - curr_grp;
 
 		if (space_rem &lt; sizeof(*msg)) {
<span class="p_del">-			/* msg wraps around the ring */</span>
<span class="p_del">-			memcpy_fromio(msg, bus-&gt;m_pdwGetRing + curr_grp, space_rem);</span>
<span class="p_del">-			memcpy_fromio((u8 *)msg + space_rem, bus-&gt;m_pdwGetRing,</span>
<span class="p_del">-				sizeof(*msg) - space_rem);</span>
 			if (buf)
 				memcpy_fromio(buf, bus-&gt;m_pdwGetRing + sizeof(*msg) -
 					space_rem, buf_size);
 
 		} else if (space_rem == sizeof(*msg)) {
<span class="p_del">-			memcpy_fromio(msg, bus-&gt;m_pdwGetRing + curr_grp, sizeof(*msg));</span>
 			if (buf)
 				memcpy_fromio(buf, bus-&gt;m_pdwGetRing, buf_size);
 		} else {
 			/* Additional data wraps around the ring */
<span class="p_del">-			memcpy_fromio(msg, bus-&gt;m_pdwGetRing + curr_grp, sizeof(*msg));</span>
 			if (buf) {
 				memcpy_fromio(buf, bus-&gt;m_pdwGetRing + curr_grp +
 					sizeof(*msg), space_rem - sizeof(*msg));
<span class="p_chunk">@@ -465,15 +459,10 @@</span> <span class="p_context"> int saa7164_bus_get(struct saa7164_dev *dev, struct tmComResInfo* msg,</span>
 
 	} else {
 		/* No wrapping */
<span class="p_del">-		memcpy_fromio(msg, bus-&gt;m_pdwGetRing + curr_grp, sizeof(*msg));</span>
 		if (buf)
 			memcpy_fromio(buf, bus-&gt;m_pdwGetRing + curr_grp + sizeof(*msg),
 				buf_size);
 	}
<span class="p_del">-	/* Convert from little endian to CPU */</span>
<span class="p_del">-	msg-&gt;size = le16_to_cpu((__force __le16)msg-&gt;size);</span>
<span class="p_del">-	msg-&gt;command = le32_to_cpu((__force __le32)msg-&gt;command);</span>
<span class="p_del">-	msg-&gt;controlselector = le16_to_cpu((__force __le16)msg-&gt;controlselector);</span>
 
 	/* Update the read positions, adjusting the ring */
 	saa7164_writel(bus-&gt;m_dwGetReadPos, new_grp);
<span class="p_header">diff --git a/drivers/media/platform/davinci/vpfe_capture.c b/drivers/media/platform/davinci/vpfe_capture.c</span>
<span class="p_header">index e3fe3e0635aa..1831bf5ccca5 100644</span>
<span class="p_header">--- a/drivers/media/platform/davinci/vpfe_capture.c</span>
<span class="p_header">+++ b/drivers/media/platform/davinci/vpfe_capture.c</span>
<span class="p_chunk">@@ -1719,27 +1719,9 @@</span> <span class="p_context"> static long vpfe_param_handler(struct file *file, void *priv,</span>
 
 	switch (cmd) {
 	case VPFE_CMD_S_CCDC_RAW_PARAMS:
<span class="p_add">+		ret = -EINVAL;</span>
 		v4l2_warn(&amp;vpfe_dev-&gt;v4l2_dev,
<span class="p_del">-			  &quot;VPFE_CMD_S_CCDC_RAW_PARAMS: experimental ioctl\n&quot;);</span>
<span class="p_del">-		if (ccdc_dev-&gt;hw_ops.set_params) {</span>
<span class="p_del">-			ret = ccdc_dev-&gt;hw_ops.set_params(param);</span>
<span class="p_del">-			if (ret) {</span>
<span class="p_del">-				v4l2_dbg(1, debug, &amp;vpfe_dev-&gt;v4l2_dev,</span>
<span class="p_del">-					&quot;Error setting parameters in CCDC\n&quot;);</span>
<span class="p_del">-				goto unlock_out;</span>
<span class="p_del">-			}</span>
<span class="p_del">-			ret = vpfe_get_ccdc_image_format(vpfe_dev,</span>
<span class="p_del">-							 &amp;vpfe_dev-&gt;fmt);</span>
<span class="p_del">-			if (ret &lt; 0) {</span>
<span class="p_del">-				v4l2_dbg(1, debug, &amp;vpfe_dev-&gt;v4l2_dev,</span>
<span class="p_del">-					&quot;Invalid image format at CCDC\n&quot;);</span>
<span class="p_del">-				goto unlock_out;</span>
<span class="p_del">-			}</span>
<span class="p_del">-		} else {</span>
<span class="p_del">-			ret = -EINVAL;</span>
<span class="p_del">-			v4l2_dbg(1, debug, &amp;vpfe_dev-&gt;v4l2_dev,</span>
<span class="p_del">-				&quot;VPFE_CMD_S_CCDC_RAW_PARAMS not supported\n&quot;);</span>
<span class="p_del">-		}</span>
<span class="p_add">+			&quot;VPFE_CMD_S_CCDC_RAW_PARAMS not supported\n&quot;);</span>
 		break;
 	default:
 		ret = -ENOTTY;
<span class="p_header">diff --git a/drivers/media/rc/ir-lirc-codec.c b/drivers/media/rc/ir-lirc-codec.c</span>
<span class="p_header">index de85f1d7ce43..c01b655571a2 100644</span>
<span class="p_header">--- a/drivers/media/rc/ir-lirc-codec.c</span>
<span class="p_header">+++ b/drivers/media/rc/ir-lirc-codec.c</span>
<span class="p_chunk">@@ -266,7 +266,7 @@</span> <span class="p_context"> static long ir_lirc_ioctl(struct file *filep, unsigned int cmd,</span>
 		if (!dev-&gt;rx_resolution)
 			return -ENOTTY;
 
<span class="p_del">-		val = dev-&gt;rx_resolution;</span>
<span class="p_add">+		val = dev-&gt;rx_resolution / 1000;</span>
 		break;
 
 	case LIRC_SET_WIDEBAND_RECEIVER:
<span class="p_header">diff --git a/drivers/media/rc/ir-spi.c b/drivers/media/rc/ir-spi.c</span>
<span class="p_header">index c8863f36686a..f39cf8cb639f 100644</span>
<span class="p_header">--- a/drivers/media/rc/ir-spi.c</span>
<span class="p_header">+++ b/drivers/media/rc/ir-spi.c</span>
<span class="p_chunk">@@ -57,10 +57,13 @@</span> <span class="p_context"> static int ir_spi_tx(struct rc_dev *dev,</span>
 
 	/* convert the pulse/space signal to raw binary signal */
 	for (i = 0; i &lt; count; i++) {
<span class="p_add">+		unsigned int periods;</span>
 		int j;
 		u16 val = ((i + 1) % 2) ? idata-&gt;pulse : idata-&gt;space;
 
<span class="p_del">-		if (len + buffer[i] &gt;= IR_SPI_MAX_BUFSIZE)</span>
<span class="p_add">+		periods = DIV_ROUND_CLOSEST(buffer[i] * idata-&gt;freq, 1000000);</span>
<span class="p_add">+</span>
<span class="p_add">+		if (len + periods &gt;= IR_SPI_MAX_BUFSIZE)</span>
 			return -EINVAL;
 
 		/*
<span class="p_chunk">@@ -69,13 +72,13 @@</span> <span class="p_context"> static int ir_spi_tx(struct rc_dev *dev,</span>
 		 * contain a space duration.
 		 */
 		val = (i % 2) ? idata-&gt;space : idata-&gt;pulse;
<span class="p_del">-		for (j = 0; j &lt; buffer[i]; j++)</span>
<span class="p_add">+		for (j = 0; j &lt; periods; j++)</span>
 			idata-&gt;tx_buf[len++] = val;
 	}
 
 	memset(&amp;xfer, 0, sizeof(xfer));
 
<span class="p_del">-	xfer.speed_hz = idata-&gt;freq;</span>
<span class="p_add">+	xfer.speed_hz = idata-&gt;freq * 16;</span>
 	xfer.len = len * sizeof(*idata-&gt;tx_buf);
 	xfer.tx_buf = idata-&gt;tx_buf;
 
<span class="p_header">diff --git a/drivers/media/usb/pulse8-cec/pulse8-cec.c b/drivers/media/usb/pulse8-cec/pulse8-cec.c</span>
<span class="p_header">index 1dfc2de1fe77..4767f4341ba9 100644</span>
<span class="p_header">--- a/drivers/media/usb/pulse8-cec/pulse8-cec.c</span>
<span class="p_header">+++ b/drivers/media/usb/pulse8-cec/pulse8-cec.c</span>
<span class="p_chunk">@@ -51,7 +51,7 @@</span> <span class="p_context"> MODULE_DESCRIPTION(&quot;Pulse Eight HDMI CEC driver&quot;);</span>
 MODULE_LICENSE(&quot;GPL&quot;);
 
 static int debug;
<span class="p_del">-static int persistent_config = 1;</span>
<span class="p_add">+static int persistent_config;</span>
 module_param(debug, int, 0644);
 module_param(persistent_config, int, 0644);
 MODULE_PARM_DESC(debug, &quot;debug level (0-1)&quot;);
<span class="p_header">diff --git a/drivers/mmc/core/host.c b/drivers/mmc/core/host.c</span>
<span class="p_header">index 3f8c85d5aa09..88fa03142e92 100644</span>
<span class="p_header">--- a/drivers/mmc/core/host.c</span>
<span class="p_header">+++ b/drivers/mmc/core/host.c</span>
<span class="p_chunk">@@ -176,19 +176,17 @@</span> <span class="p_context"> static void mmc_retune_timer(unsigned long data)</span>
  */
 int mmc_of_parse(struct mmc_host *host)
 {
<span class="p_del">-	struct device_node *np;</span>
<span class="p_add">+	struct device *dev = host-&gt;parent;</span>
 	u32 bus_width;
 	int ret;
 	bool cd_cap_invert, cd_gpio_invert = false;
 	bool ro_cap_invert, ro_gpio_invert = false;
 
<span class="p_del">-	if (!host-&gt;parent || !host-&gt;parent-&gt;of_node)</span>
<span class="p_add">+	if (!dev || !dev_fwnode(dev))</span>
 		return 0;
 
<span class="p_del">-	np = host-&gt;parent-&gt;of_node;</span>
<span class="p_del">-</span>
 	/* &quot;bus-width&quot; is translated to MMC_CAP_*_BIT_DATA flags */
<span class="p_del">-	if (of_property_read_u32(np, &quot;bus-width&quot;, &amp;bus_width) &lt; 0) {</span>
<span class="p_add">+	if (device_property_read_u32(dev, &quot;bus-width&quot;, &amp;bus_width) &lt; 0) {</span>
 		dev_dbg(host-&gt;parent,
 			&quot;\&quot;bus-width\&quot; property is missing, assuming 1 bit.\n&quot;);
 		bus_width = 1;
<span class="p_chunk">@@ -210,7 +208,7 @@</span> <span class="p_context"> int mmc_of_parse(struct mmc_host *host)</span>
 	}
 
 	/* f_max is obtained from the optional &quot;max-frequency&quot; property */
<span class="p_del">-	of_property_read_u32(np, &quot;max-frequency&quot;, &amp;host-&gt;f_max);</span>
<span class="p_add">+	device_property_read_u32(dev, &quot;max-frequency&quot;, &amp;host-&gt;f_max);</span>
 
 	/*
 	 * Configure CD and WP pins. They are both by default active low to
<span class="p_chunk">@@ -225,12 +223,12 @@</span> <span class="p_context"> int mmc_of_parse(struct mmc_host *host)</span>
 	 */
 
 	/* Parse Card Detection */
<span class="p_del">-	if (of_property_read_bool(np, &quot;non-removable&quot;)) {</span>
<span class="p_add">+	if (device_property_read_bool(dev, &quot;non-removable&quot;)) {</span>
 		host-&gt;caps |= MMC_CAP_NONREMOVABLE;
 	} else {
<span class="p_del">-		cd_cap_invert = of_property_read_bool(np, &quot;cd-inverted&quot;);</span>
<span class="p_add">+		cd_cap_invert = device_property_read_bool(dev, &quot;cd-inverted&quot;);</span>
 
<span class="p_del">-		if (of_property_read_bool(np, &quot;broken-cd&quot;))</span>
<span class="p_add">+		if (device_property_read_bool(dev, &quot;broken-cd&quot;))</span>
 			host-&gt;caps |= MMC_CAP_NEEDS_POLL;
 
 		ret = mmc_gpiod_request_cd(host, &quot;cd&quot;, 0, true,
<span class="p_chunk">@@ -256,7 +254,7 @@</span> <span class="p_context"> int mmc_of_parse(struct mmc_host *host)</span>
 	}
 
 	/* Parse Write Protection */
<span class="p_del">-	ro_cap_invert = of_property_read_bool(np, &quot;wp-inverted&quot;);</span>
<span class="p_add">+	ro_cap_invert = device_property_read_bool(dev, &quot;wp-inverted&quot;);</span>
 
 	ret = mmc_gpiod_request_ro(host, &quot;wp&quot;, 0, false, 0, &amp;ro_gpio_invert);
 	if (!ret)
<span class="p_chunk">@@ -264,64 +262,64 @@</span> <span class="p_context"> int mmc_of_parse(struct mmc_host *host)</span>
 	else if (ret != -ENOENT &amp;&amp; ret != -ENOSYS)
 		return ret;
 
<span class="p_del">-	if (of_property_read_bool(np, &quot;disable-wp&quot;))</span>
<span class="p_add">+	if (device_property_read_bool(dev, &quot;disable-wp&quot;))</span>
 		host-&gt;caps2 |= MMC_CAP2_NO_WRITE_PROTECT;
 
 	/* See the comment on CD inversion above */
 	if (ro_cap_invert ^ ro_gpio_invert)
 		host-&gt;caps2 |= MMC_CAP2_RO_ACTIVE_HIGH;
 
<span class="p_del">-	if (of_property_read_bool(np, &quot;cap-sd-highspeed&quot;))</span>
<span class="p_add">+	if (device_property_read_bool(dev, &quot;cap-sd-highspeed&quot;))</span>
 		host-&gt;caps |= MMC_CAP_SD_HIGHSPEED;
<span class="p_del">-	if (of_property_read_bool(np, &quot;cap-mmc-highspeed&quot;))</span>
<span class="p_add">+	if (device_property_read_bool(dev, &quot;cap-mmc-highspeed&quot;))</span>
 		host-&gt;caps |= MMC_CAP_MMC_HIGHSPEED;
<span class="p_del">-	if (of_property_read_bool(np, &quot;sd-uhs-sdr12&quot;))</span>
<span class="p_add">+	if (device_property_read_bool(dev, &quot;sd-uhs-sdr12&quot;))</span>
 		host-&gt;caps |= MMC_CAP_UHS_SDR12;
<span class="p_del">-	if (of_property_read_bool(np, &quot;sd-uhs-sdr25&quot;))</span>
<span class="p_add">+	if (device_property_read_bool(dev, &quot;sd-uhs-sdr25&quot;))</span>
 		host-&gt;caps |= MMC_CAP_UHS_SDR25;
<span class="p_del">-	if (of_property_read_bool(np, &quot;sd-uhs-sdr50&quot;))</span>
<span class="p_add">+	if (device_property_read_bool(dev, &quot;sd-uhs-sdr50&quot;))</span>
 		host-&gt;caps |= MMC_CAP_UHS_SDR50;
<span class="p_del">-	if (of_property_read_bool(np, &quot;sd-uhs-sdr104&quot;))</span>
<span class="p_add">+	if (device_property_read_bool(dev, &quot;sd-uhs-sdr104&quot;))</span>
 		host-&gt;caps |= MMC_CAP_UHS_SDR104;
<span class="p_del">-	if (of_property_read_bool(np, &quot;sd-uhs-ddr50&quot;))</span>
<span class="p_add">+	if (device_property_read_bool(dev, &quot;sd-uhs-ddr50&quot;))</span>
 		host-&gt;caps |= MMC_CAP_UHS_DDR50;
<span class="p_del">-	if (of_property_read_bool(np, &quot;cap-power-off-card&quot;))</span>
<span class="p_add">+	if (device_property_read_bool(dev, &quot;cap-power-off-card&quot;))</span>
 		host-&gt;caps |= MMC_CAP_POWER_OFF_CARD;
<span class="p_del">-	if (of_property_read_bool(np, &quot;cap-mmc-hw-reset&quot;))</span>
<span class="p_add">+	if (device_property_read_bool(dev, &quot;cap-mmc-hw-reset&quot;))</span>
 		host-&gt;caps |= MMC_CAP_HW_RESET;
<span class="p_del">-	if (of_property_read_bool(np, &quot;cap-sdio-irq&quot;))</span>
<span class="p_add">+	if (device_property_read_bool(dev, &quot;cap-sdio-irq&quot;))</span>
 		host-&gt;caps |= MMC_CAP_SDIO_IRQ;
<span class="p_del">-	if (of_property_read_bool(np, &quot;full-pwr-cycle&quot;))</span>
<span class="p_add">+	if (device_property_read_bool(dev, &quot;full-pwr-cycle&quot;))</span>
 		host-&gt;caps2 |= MMC_CAP2_FULL_PWR_CYCLE;
<span class="p_del">-	if (of_property_read_bool(np, &quot;keep-power-in-suspend&quot;))</span>
<span class="p_add">+	if (device_property_read_bool(dev, &quot;keep-power-in-suspend&quot;))</span>
 		host-&gt;pm_caps |= MMC_PM_KEEP_POWER;
<span class="p_del">-	if (of_property_read_bool(np, &quot;wakeup-source&quot;) ||</span>
<span class="p_del">-	    of_property_read_bool(np, &quot;enable-sdio-wakeup&quot;)) /* legacy */</span>
<span class="p_add">+	if (device_property_read_bool(dev, &quot;wakeup-source&quot;) ||</span>
<span class="p_add">+	    device_property_read_bool(dev, &quot;enable-sdio-wakeup&quot;)) /* legacy */</span>
 		host-&gt;pm_caps |= MMC_PM_WAKE_SDIO_IRQ;
<span class="p_del">-	if (of_property_read_bool(np, &quot;mmc-ddr-3_3v&quot;))</span>
<span class="p_add">+	if (device_property_read_bool(dev, &quot;mmc-ddr-3_3v&quot;))</span>
 		host-&gt;caps |= MMC_CAP_3_3V_DDR;
<span class="p_del">-	if (of_property_read_bool(np, &quot;mmc-ddr-1_8v&quot;))</span>
<span class="p_add">+	if (device_property_read_bool(dev, &quot;mmc-ddr-1_8v&quot;))</span>
 		host-&gt;caps |= MMC_CAP_1_8V_DDR;
<span class="p_del">-	if (of_property_read_bool(np, &quot;mmc-ddr-1_2v&quot;))</span>
<span class="p_add">+	if (device_property_read_bool(dev, &quot;mmc-ddr-1_2v&quot;))</span>
 		host-&gt;caps |= MMC_CAP_1_2V_DDR;
<span class="p_del">-	if (of_property_read_bool(np, &quot;mmc-hs200-1_8v&quot;))</span>
<span class="p_add">+	if (device_property_read_bool(dev, &quot;mmc-hs200-1_8v&quot;))</span>
 		host-&gt;caps2 |= MMC_CAP2_HS200_1_8V_SDR;
<span class="p_del">-	if (of_property_read_bool(np, &quot;mmc-hs200-1_2v&quot;))</span>
<span class="p_add">+	if (device_property_read_bool(dev, &quot;mmc-hs200-1_2v&quot;))</span>
 		host-&gt;caps2 |= MMC_CAP2_HS200_1_2V_SDR;
<span class="p_del">-	if (of_property_read_bool(np, &quot;mmc-hs400-1_8v&quot;))</span>
<span class="p_add">+	if (device_property_read_bool(dev, &quot;mmc-hs400-1_8v&quot;))</span>
 		host-&gt;caps2 |= MMC_CAP2_HS400_1_8V | MMC_CAP2_HS200_1_8V_SDR;
<span class="p_del">-	if (of_property_read_bool(np, &quot;mmc-hs400-1_2v&quot;))</span>
<span class="p_add">+	if (device_property_read_bool(dev, &quot;mmc-hs400-1_2v&quot;))</span>
 		host-&gt;caps2 |= MMC_CAP2_HS400_1_2V | MMC_CAP2_HS200_1_2V_SDR;
<span class="p_del">-	if (of_property_read_bool(np, &quot;mmc-hs400-enhanced-strobe&quot;))</span>
<span class="p_add">+	if (device_property_read_bool(dev, &quot;mmc-hs400-enhanced-strobe&quot;))</span>
 		host-&gt;caps2 |= MMC_CAP2_HS400_ES;
<span class="p_del">-	if (of_property_read_bool(np, &quot;no-sdio&quot;))</span>
<span class="p_add">+	if (device_property_read_bool(dev, &quot;no-sdio&quot;))</span>
 		host-&gt;caps2 |= MMC_CAP2_NO_SDIO;
<span class="p_del">-	if (of_property_read_bool(np, &quot;no-sd&quot;))</span>
<span class="p_add">+	if (device_property_read_bool(dev, &quot;no-sd&quot;))</span>
 		host-&gt;caps2 |= MMC_CAP2_NO_SD;
<span class="p_del">-	if (of_property_read_bool(np, &quot;no-mmc&quot;))</span>
<span class="p_add">+	if (device_property_read_bool(dev, &quot;no-mmc&quot;))</span>
 		host-&gt;caps2 |= MMC_CAP2_NO_MMC;
 
<span class="p_del">-	host-&gt;dsr_req = !of_property_read_u32(np, &quot;dsr&quot;, &amp;host-&gt;dsr);</span>
<span class="p_add">+	host-&gt;dsr_req = !device_property_read_u32(dev, &quot;dsr&quot;, &amp;host-&gt;dsr);</span>
 	if (host-&gt;dsr_req &amp;&amp; (host-&gt;dsr &amp; ~0xffff)) {
 		dev_err(host-&gt;parent,
 			&quot;device tree specified broken value for DSR: 0x%x, ignoring\n&quot;,
<span class="p_header">diff --git a/drivers/mmc/host/dw_mmc.c b/drivers/mmc/host/dw_mmc.c</span>
<span class="p_header">index e45129f48174..efde0f20dd24 100644</span>
<span class="p_header">--- a/drivers/mmc/host/dw_mmc.c</span>
<span class="p_header">+++ b/drivers/mmc/host/dw_mmc.c</span>
<span class="p_chunk">@@ -2707,8 +2707,8 @@</span> <span class="p_context"> static int dw_mci_init_slot(struct dw_mci *host, unsigned int id)</span>
 	host-&gt;slot[id] = slot;
 
 	mmc-&gt;ops = &amp;dw_mci_ops;
<span class="p_del">-	if (of_property_read_u32_array(host-&gt;dev-&gt;of_node,</span>
<span class="p_del">-				       &quot;clock-freq-min-max&quot;, freq, 2)) {</span>
<span class="p_add">+	if (device_property_read_u32_array(host-&gt;dev, &quot;clock-freq-min-max&quot;,</span>
<span class="p_add">+					   freq, 2)) {</span>
 		mmc-&gt;f_min = DW_MCI_FREQ_MIN;
 		mmc-&gt;f_max = DW_MCI_FREQ_MAX;
 	} else {
<span class="p_chunk">@@ -2808,7 +2808,6 @@</span> <span class="p_context"> static void dw_mci_init_dma(struct dw_mci *host)</span>
 {
 	int addr_config;
 	struct device *dev = host-&gt;dev;
<span class="p_del">-	struct device_node *np = dev-&gt;of_node;</span>
 
 	/*
 	* Check tansfer mode from HCON[17:16]
<span class="p_chunk">@@ -2869,8 +2868,9 @@</span> <span class="p_context"> static void dw_mci_init_dma(struct dw_mci *host)</span>
 		dev_info(host-&gt;dev, &quot;Using internal DMA controller.\n&quot;);
 	} else {
 		/* TRANS_MODE_EDMAC: check dma bindings again */
<span class="p_del">-		if ((of_property_count_strings(np, &quot;dma-names&quot;) &lt; 0) ||</span>
<span class="p_del">-		    (!of_find_property(np, &quot;dmas&quot;, NULL))) {</span>
<span class="p_add">+		if ((device_property_read_string_array(dev, &quot;dma-names&quot;,</span>
<span class="p_add">+						       NULL, 0) &lt; 0) ||</span>
<span class="p_add">+		    !device_property_present(dev, &quot;dmas&quot;)) {</span>
 			goto no_dma;
 		}
 		host-&gt;dma_ops = &amp;dw_mci_edmac_ops;
<span class="p_chunk">@@ -2937,7 +2937,6 @@</span> <span class="p_context"> static struct dw_mci_board *dw_mci_parse_dt(struct dw_mci *host)</span>
 {
 	struct dw_mci_board *pdata;
 	struct device *dev = host-&gt;dev;
<span class="p_del">-	struct device_node *np = dev-&gt;of_node;</span>
 	const struct dw_mci_drv_data *drv_data = host-&gt;drv_data;
 	int ret;
 	u32 clock_frequency;
<span class="p_chunk">@@ -2954,20 +2953,21 @@</span> <span class="p_context"> static struct dw_mci_board *dw_mci_parse_dt(struct dw_mci *host)</span>
 	}
 
 	/* find out number of slots supported */
<span class="p_del">-	of_property_read_u32(np, &quot;num-slots&quot;, &amp;pdata-&gt;num_slots);</span>
<span class="p_add">+	device_property_read_u32(dev, &quot;num-slots&quot;, &amp;pdata-&gt;num_slots);</span>
 
<span class="p_del">-	if (of_property_read_u32(np, &quot;fifo-depth&quot;, &amp;pdata-&gt;fifo_depth))</span>
<span class="p_add">+	if (device_property_read_u32(dev, &quot;fifo-depth&quot;, &amp;pdata-&gt;fifo_depth))</span>
 		dev_info(dev,
 			 &quot;fifo-depth property not found, using value of FIFOTH register as default\n&quot;);
 
<span class="p_del">-	of_property_read_u32(np, &quot;card-detect-delay&quot;, &amp;pdata-&gt;detect_delay_ms);</span>
<span class="p_add">+	device_property_read_u32(dev, &quot;card-detect-delay&quot;,</span>
<span class="p_add">+				 &amp;pdata-&gt;detect_delay_ms);</span>
 
<span class="p_del">-	of_property_read_u32(np, &quot;data-addr&quot;, &amp;host-&gt;data_addr_override);</span>
<span class="p_add">+	device_property_read_u32(dev, &quot;data-addr&quot;, &amp;host-&gt;data_addr_override);</span>
 
<span class="p_del">-	if (of_get_property(np, &quot;fifo-watermark-aligned&quot;, NULL))</span>
<span class="p_add">+	if (device_property_present(dev, &quot;fifo-watermark-aligned&quot;))</span>
 		host-&gt;wm_aligned = true;
 
<span class="p_del">-	if (!of_property_read_u32(np, &quot;clock-frequency&quot;, &amp;clock_frequency))</span>
<span class="p_add">+	if (!device_property_read_u32(dev, &quot;clock-frequency&quot;, &amp;clock_frequency))</span>
 		pdata-&gt;bus_hz = clock_frequency;
 
 	if (drv_data &amp;&amp; drv_data-&gt;parse_dt) {
<span class="p_header">diff --git a/drivers/mmc/host/sdhci-of-at91.c b/drivers/mmc/host/sdhci-of-at91.c</span>
<span class="p_header">index 7611fd679f1a..1485530c3592 100644</span>
<span class="p_header">--- a/drivers/mmc/host/sdhci-of-at91.c</span>
<span class="p_header">+++ b/drivers/mmc/host/sdhci-of-at91.c</span>
<span class="p_chunk">@@ -31,6 +31,7 @@</span> <span class="p_context"></span>
 
 #define SDMMC_MC1R	0x204
 #define		SDMMC_MC1R_DDR		BIT(3)
<span class="p_add">+#define		SDMMC_MC1R_FCD		BIT(7)</span>
 #define SDMMC_CACR	0x230
 #define		SDMMC_CACR_CAPWREN	BIT(0)
 #define		SDMMC_CACR_KEY		(0x46 &lt;&lt; 8)
<span class="p_chunk">@@ -43,6 +44,15 @@</span> <span class="p_context"> struct sdhci_at91_priv {</span>
 	struct clk *mainck;
 };
 
<span class="p_add">+static void sdhci_at91_set_force_card_detect(struct sdhci_host *host)</span>
<span class="p_add">+{</span>
<span class="p_add">+	u8 mc1r;</span>
<span class="p_add">+</span>
<span class="p_add">+	mc1r = readb(host-&gt;ioaddr + SDMMC_MC1R);</span>
<span class="p_add">+	mc1r |= SDMMC_MC1R_FCD;</span>
<span class="p_add">+	writeb(mc1r, host-&gt;ioaddr + SDMMC_MC1R);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static void sdhci_at91_set_clock(struct sdhci_host *host, unsigned int clock)
 {
 	u16 clk;
<span class="p_chunk">@@ -110,10 +120,18 @@</span> <span class="p_context"> void sdhci_at91_set_uhs_signaling(struct sdhci_host *host, unsigned int timing)</span>
 	sdhci_set_uhs_signaling(host, timing);
 }
 
<span class="p_add">+static void sdhci_at91_reset(struct sdhci_host *host, u8 mask)</span>
<span class="p_add">+{</span>
<span class="p_add">+	sdhci_reset(host, mask);</span>
<span class="p_add">+</span>
<span class="p_add">+	if (host-&gt;mmc-&gt;caps &amp; MMC_CAP_NONREMOVABLE)</span>
<span class="p_add">+		sdhci_at91_set_force_card_detect(host);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static const struct sdhci_ops sdhci_at91_sama5d2_ops = {
 	.set_clock		= sdhci_at91_set_clock,
 	.set_bus_width		= sdhci_set_bus_width,
<span class="p_del">-	.reset			= sdhci_reset,</span>
<span class="p_add">+	.reset			= sdhci_at91_reset,</span>
 	.set_uhs_signaling	= sdhci_at91_set_uhs_signaling,
 	.set_power		= sdhci_at91_set_power,
 };
<span class="p_chunk">@@ -324,6 +342,21 @@</span> <span class="p_context"> static int sdhci_at91_probe(struct platform_device *pdev)</span>
 		host-&gt;quirks &amp;= ~SDHCI_QUIRK_BROKEN_CARD_DETECTION;
 	}
 
<span class="p_add">+	/*</span>
<span class="p_add">+	 * If the device attached to the MMC bus is not removable, it is safer</span>
<span class="p_add">+	 * to set the Force Card Detect bit. People often don&#39;t connect the</span>
<span class="p_add">+	 * card detect signal and use this pin for another purpose. If the card</span>
<span class="p_add">+	 * detect pin is not muxed to SDHCI controller, a default value is</span>
<span class="p_add">+	 * used. This value can be different from a SoC revision to another</span>
<span class="p_add">+	 * one. Problems come when this default value is not card present. To</span>
<span class="p_add">+	 * avoid this case, if the device is non removable then the card</span>
<span class="p_add">+	 * detection procedure using the SDMCC_CD signal is bypassed.</span>
<span class="p_add">+	 * This bit is reset when a software reset for all command is performed</span>
<span class="p_add">+	 * so we need to implement our own reset function to set back this bit.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	if (host-&gt;mmc-&gt;caps &amp; MMC_CAP_NONREMOVABLE)</span>
<span class="p_add">+		sdhci_at91_set_force_card_detect(host);</span>
<span class="p_add">+</span>
 	pm_runtime_put_autosuspend(&amp;pdev-&gt;dev);
 
 	return 0;
<span class="p_header">diff --git a/drivers/net/bonding/bond_main.c b/drivers/net/bonding/bond_main.c</span>
<span class="p_header">index 8ab6bdbe1682..224e93aa6d23 100644</span>
<span class="p_header">--- a/drivers/net/bonding/bond_main.c</span>
<span class="p_header">+++ b/drivers/net/bonding/bond_main.c</span>
<span class="p_chunk">@@ -2047,6 +2047,7 @@</span> <span class="p_context"> static int bond_miimon_inspect(struct bonding *bond)</span>
 				continue;
 
 			bond_propose_link_state(slave, BOND_LINK_FAIL);
<span class="p_add">+			commit++;</span>
 			slave-&gt;delay = bond-&gt;params.downdelay;
 			if (slave-&gt;delay) {
 				netdev_info(bond-&gt;dev, &quot;link status down for %sinterface %s, disabling it in %d ms\n&quot;,
<span class="p_chunk">@@ -2085,6 +2086,7 @@</span> <span class="p_context"> static int bond_miimon_inspect(struct bonding *bond)</span>
 				continue;
 
 			bond_propose_link_state(slave, BOND_LINK_BACK);
<span class="p_add">+			commit++;</span>
 			slave-&gt;delay = bond-&gt;params.updelay;
 
 			if (slave-&gt;delay) {
<span class="p_chunk">@@ -4598,7 +4600,7 @@</span> <span class="p_context"> static int bond_check_params(struct bond_params *params)</span>
 	}
 	ad_user_port_key = valptr-&gt;value;
 
<span class="p_del">-	if (bond_mode == BOND_MODE_TLB) {</span>
<span class="p_add">+	if ((bond_mode == BOND_MODE_TLB) || (bond_mode == BOND_MODE_ALB)) {</span>
 		bond_opt_initstr(&amp;newval, &quot;default&quot;);
 		valptr = bond_opt_parse(bond_opt_get(BOND_OPT_TLB_DYNAMIC_LB),
 					&amp;newval);
<span class="p_header">diff --git a/drivers/net/dsa/b53/b53_common.c b/drivers/net/dsa/b53/b53_common.c</span>
<span class="p_header">index fa0eece21eef..d9cc94a7d44e 100644</span>
<span class="p_header">--- a/drivers/net/dsa/b53/b53_common.c</span>
<span class="p_header">+++ b/drivers/net/dsa/b53/b53_common.c</span>
<span class="p_chunk">@@ -1668,6 +1668,7 @@</span> <span class="p_context"> static const struct b53_chip_data b53_switch_chips[] = {</span>
 		.dev_name = &quot;BCM53125&quot;,
 		.vlans = 4096,
 		.enabled_ports = 0xff,
<span class="p_add">+		.arl_entries = 4,</span>
 		.cpu_port = B53_CPU_PORT,
 		.vta_regs = B53_VTA_REGS,
 		.duplex_reg = B53_DUPLEX_STAT_GE,
<span class="p_header">diff --git a/drivers/net/dsa/mv88e6xxx/chip.c b/drivers/net/dsa/mv88e6xxx/chip.c</span>
<span class="p_header">index d034d8cd7d22..32864a47c4c1 100644</span>
<span class="p_header">--- a/drivers/net/dsa/mv88e6xxx/chip.c</span>
<span class="p_header">+++ b/drivers/net/dsa/mv88e6xxx/chip.c</span>
<span class="p_chunk">@@ -3377,6 +3377,7 @@</span> <span class="p_context"> static const struct mv88e6xxx_ops mv88e6390x_ops = {</span>
 	.port_jumbo_config = mv88e6165_port_jumbo_config,
 	.port_egress_rate_limiting = mv88e6097_port_egress_rate_limiting,
 	.port_pause_config = mv88e6390_port_pause_config,
<span class="p_add">+	.port_set_cmode = mv88e6390x_port_set_cmode,</span>
 	.port_disable_learn_limit = mv88e6xxx_port_disable_learn_limit,
 	.port_disable_pri_override = mv88e6xxx_port_disable_pri_override,
 	.stats_snapshot = mv88e6390_g1_stats_snapshot,
<span class="p_header">diff --git a/drivers/net/ethernet/aurora/nb8800.c b/drivers/net/ethernet/aurora/nb8800.c</span>
<span class="p_header">index 5711fbbd6ae3..878cffd37e1f 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/aurora/nb8800.c</span>
<span class="p_header">+++ b/drivers/net/ethernet/aurora/nb8800.c</span>
<span class="p_chunk">@@ -609,7 +609,7 @@</span> <span class="p_context"> static void nb8800_mac_config(struct net_device *dev)</span>
 		mac_mode |= HALF_DUPLEX;
 
 	if (gigabit) {
<span class="p_del">-		if (priv-&gt;phy_mode == PHY_INTERFACE_MODE_RGMII)</span>
<span class="p_add">+		if (phy_interface_is_rgmii(dev-&gt;phydev))</span>
 			mac_mode |= RGMII_MODE;
 
 		mac_mode |= GMAC_MODE;
<span class="p_chunk">@@ -1268,11 +1268,10 @@</span> <span class="p_context"> static int nb8800_tangox_init(struct net_device *dev)</span>
 		break;
 
 	case PHY_INTERFACE_MODE_RGMII:
<span class="p_del">-		pad_mode = PAD_MODE_RGMII;</span>
<span class="p_del">-		break;</span>
<span class="p_del">-</span>
<span class="p_add">+	case PHY_INTERFACE_MODE_RGMII_ID:</span>
<span class="p_add">+	case PHY_INTERFACE_MODE_RGMII_RXID:</span>
 	case PHY_INTERFACE_MODE_RGMII_TXID:
<span class="p_del">-		pad_mode = PAD_MODE_RGMII | PAD_MODE_GTX_CLK_DELAY;</span>
<span class="p_add">+		pad_mode = PAD_MODE_RGMII;</span>
 		break;
 
 	default:
<span class="p_header">diff --git a/drivers/net/ethernet/mellanox/mlx5/core/cmd.c b/drivers/net/ethernet/mellanox/mlx5/core/cmd.c</span>
<span class="p_header">index 10d282841f5b..ac0a460c006a 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/mellanox/mlx5/core/cmd.c</span>
<span class="p_header">+++ b/drivers/net/ethernet/mellanox/mlx5/core/cmd.c</span>
<span class="p_chunk">@@ -777,6 +777,10 @@</span> <span class="p_context"> static void cb_timeout_handler(struct work_struct *work)</span>
 	mlx5_cmd_comp_handler(dev, 1UL &lt;&lt; ent-&gt;idx, true);
 }
 
<span class="p_add">+static void free_msg(struct mlx5_core_dev *dev, struct mlx5_cmd_msg *msg);</span>
<span class="p_add">+static void mlx5_free_cmd_msg(struct mlx5_core_dev *dev,</span>
<span class="p_add">+			      struct mlx5_cmd_msg *msg);</span>
<span class="p_add">+</span>
 static void cmd_work_handler(struct work_struct *work)
 {
 	struct mlx5_cmd_work_ent *ent = container_of(work, struct mlx5_cmd_work_ent, work);
<span class="p_chunk">@@ -786,16 +790,27 @@</span> <span class="p_context"> static void cmd_work_handler(struct work_struct *work)</span>
 	struct mlx5_cmd_layout *lay;
 	struct semaphore *sem;
 	unsigned long flags;
<span class="p_add">+	int alloc_ret;</span>
 
 	sem = ent-&gt;page_queue ? &amp;cmd-&gt;pages_sem : &amp;cmd-&gt;sem;
 	down(sem);
 	if (!ent-&gt;page_queue) {
<span class="p_del">-		ent-&gt;idx = alloc_ent(cmd);</span>
<span class="p_del">-		if (ent-&gt;idx &lt; 0) {</span>
<span class="p_add">+		alloc_ret = alloc_ent(cmd);</span>
<span class="p_add">+		if (alloc_ret &lt; 0) {</span>
 			mlx5_core_err(dev, &quot;failed to allocate command entry\n&quot;);
<span class="p_add">+			if (ent-&gt;callback) {</span>
<span class="p_add">+				ent-&gt;callback(-EAGAIN, ent-&gt;context);</span>
<span class="p_add">+				mlx5_free_cmd_msg(dev, ent-&gt;out);</span>
<span class="p_add">+				free_msg(dev, ent-&gt;in);</span>
<span class="p_add">+				free_cmd(ent);</span>
<span class="p_add">+			} else {</span>
<span class="p_add">+				ent-&gt;ret = -EAGAIN;</span>
<span class="p_add">+				complete(&amp;ent-&gt;done);</span>
<span class="p_add">+			}</span>
 			up(sem);
 			return;
 		}
<span class="p_add">+		ent-&gt;idx = alloc_ret;</span>
 	} else {
 		ent-&gt;idx = cmd-&gt;max_reg_cmds;
 		spin_lock_irqsave(&amp;cmd-&gt;alloc_lock, flags);
<span class="p_chunk">@@ -955,7 +970,7 @@</span> <span class="p_context"> static int mlx5_cmd_invoke(struct mlx5_core_dev *dev, struct mlx5_cmd_msg *in,</span>
 
 	err = wait_func(dev, ent);
 	if (err == -ETIMEDOUT)
<span class="p_del">-		goto out_free;</span>
<span class="p_add">+		goto out;</span>
 
 	ds = ent-&gt;ts2 - ent-&gt;ts1;
 	op = MLX5_GET(mbox_in, in-&gt;first.data, opcode);
<span class="p_chunk">@@ -1419,6 +1434,7 @@</span> <span class="p_context"> void mlx5_cmd_comp_handler(struct mlx5_core_dev *dev, u64 vec, bool forced)</span>
 					mlx5_core_err(dev, &quot;Command completion arrived after timeout (entry idx = %d).\n&quot;,
 						      ent-&gt;idx);
 					free_ent(cmd, ent-&gt;idx);
<span class="p_add">+					free_cmd(ent);</span>
 				}
 				continue;
 			}
<span class="p_chunk">@@ -1477,7 +1493,8 @@</span> <span class="p_context"> void mlx5_cmd_comp_handler(struct mlx5_core_dev *dev, u64 vec, bool forced)</span>
 				free_msg(dev, ent-&gt;in);
 
 				err = err ? err : ent-&gt;status;
<span class="p_del">-				free_cmd(ent);</span>
<span class="p_add">+				if (!forced)</span>
<span class="p_add">+					free_cmd(ent);</span>
 				callback(err, context);
 			} else {
 				complete(&amp;ent-&gt;done);
<span class="p_header">diff --git a/drivers/net/ethernet/mellanox/mlx5/core/en.h b/drivers/net/ethernet/mellanox/mlx5/core/en.h</span>
<span class="p_header">index 944fc1742464..3b39dbd97e57 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/mellanox/mlx5/core/en.h</span>
<span class="p_header">+++ b/drivers/net/ethernet/mellanox/mlx5/core/en.h</span>
<span class="p_chunk">@@ -261,6 +261,14 @@</span> <span class="p_context"> struct mlx5e_dcbx {</span>
 };
 #endif
 
<span class="p_add">+#define MAX_PIN_NUM	8</span>
<span class="p_add">+struct mlx5e_pps {</span>
<span class="p_add">+	u8                         pin_caps[MAX_PIN_NUM];</span>
<span class="p_add">+	struct work_struct         out_work;</span>
<span class="p_add">+	u64                        start[MAX_PIN_NUM];</span>
<span class="p_add">+	u8                         enabled;</span>
<span class="p_add">+};</span>
<span class="p_add">+</span>
 struct mlx5e_tstamp {
 	rwlock_t                   lock;
 	struct cyclecounter        cycles;
<span class="p_chunk">@@ -272,7 +280,7 @@</span> <span class="p_context"> struct mlx5e_tstamp {</span>
 	struct mlx5_core_dev      *mdev;
 	struct ptp_clock          *ptp;
 	struct ptp_clock_info      ptp_info;
<span class="p_del">-	u8                        *pps_pin_caps;</span>
<span class="p_add">+	struct mlx5e_pps           pps_info;</span>
 };
 
 enum {
<span class="p_header">diff --git a/drivers/net/ethernet/mellanox/mlx5/core/en_clock.c b/drivers/net/ethernet/mellanox/mlx5/core/en_clock.c</span>
<span class="p_header">index e706a87fc8b2..80c500f87ab6 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/mellanox/mlx5/core/en_clock.c</span>
<span class="p_header">+++ b/drivers/net/ethernet/mellanox/mlx5/core/en_clock.c</span>
<span class="p_chunk">@@ -53,6 +53,15 @@</span> <span class="p_context"> enum {</span>
 	MLX5E_EVENT_MODE_ONCE_TILL_ARM	= 0x2,
 };
 
<span class="p_add">+enum {</span>
<span class="p_add">+	MLX5E_MTPPS_FS_ENABLE			= BIT(0x0),</span>
<span class="p_add">+	MLX5E_MTPPS_FS_PATTERN			= BIT(0x2),</span>
<span class="p_add">+	MLX5E_MTPPS_FS_PIN_MODE			= BIT(0x3),</span>
<span class="p_add">+	MLX5E_MTPPS_FS_TIME_STAMP		= BIT(0x4),</span>
<span class="p_add">+	MLX5E_MTPPS_FS_OUT_PULSE_DURATION	= BIT(0x5),</span>
<span class="p_add">+	MLX5E_MTPPS_FS_ENH_OUT_PER_ADJ		= BIT(0x7),</span>
<span class="p_add">+};</span>
<span class="p_add">+</span>
 void mlx5e_fill_hwstamp(struct mlx5e_tstamp *tstamp, u64 timestamp,
 			struct skb_shared_hwtstamps *hwts)
 {
<span class="p_chunk">@@ -73,17 +82,46 @@</span> <span class="p_context"> static u64 mlx5e_read_internal_timer(const struct cyclecounter *cc)</span>
 	return mlx5_read_internal_timer(tstamp-&gt;mdev) &amp; cc-&gt;mask;
 }
 
<span class="p_add">+static void mlx5e_pps_out(struct work_struct *work)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct mlx5e_pps *pps_info = container_of(work, struct mlx5e_pps,</span>
<span class="p_add">+						  out_work);</span>
<span class="p_add">+	struct mlx5e_tstamp *tstamp = container_of(pps_info, struct mlx5e_tstamp,</span>
<span class="p_add">+						   pps_info);</span>
<span class="p_add">+	u32 in[MLX5_ST_SZ_DW(mtpps_reg)] = {0};</span>
<span class="p_add">+	unsigned long flags;</span>
<span class="p_add">+	int i;</span>
<span class="p_add">+</span>
<span class="p_add">+	for (i = 0; i &lt; tstamp-&gt;ptp_info.n_pins; i++) {</span>
<span class="p_add">+		u64 tstart;</span>
<span class="p_add">+</span>
<span class="p_add">+		write_lock_irqsave(&amp;tstamp-&gt;lock, flags);</span>
<span class="p_add">+		tstart = tstamp-&gt;pps_info.start[i];</span>
<span class="p_add">+		tstamp-&gt;pps_info.start[i] = 0;</span>
<span class="p_add">+		write_unlock_irqrestore(&amp;tstamp-&gt;lock, flags);</span>
<span class="p_add">+		if (!tstart)</span>
<span class="p_add">+			continue;</span>
<span class="p_add">+</span>
<span class="p_add">+		MLX5_SET(mtpps_reg, in, pin, i);</span>
<span class="p_add">+		MLX5_SET64(mtpps_reg, in, time_stamp, tstart);</span>
<span class="p_add">+		MLX5_SET(mtpps_reg, in, field_select, MLX5E_MTPPS_FS_TIME_STAMP);</span>
<span class="p_add">+		mlx5_set_mtpps(tstamp-&gt;mdev, in, sizeof(in));</span>
<span class="p_add">+	}</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static void mlx5e_timestamp_overflow(struct work_struct *work)
 {
 	struct delayed_work *dwork = to_delayed_work(work);
 	struct mlx5e_tstamp *tstamp = container_of(dwork, struct mlx5e_tstamp,
 						   overflow_work);
<span class="p_add">+	struct mlx5e_priv *priv = container_of(tstamp, struct mlx5e_priv, tstamp);</span>
 	unsigned long flags;
 
 	write_lock_irqsave(&amp;tstamp-&gt;lock, flags);
 	timecounter_read(&amp;tstamp-&gt;clock);
 	write_unlock_irqrestore(&amp;tstamp-&gt;lock, flags);
<span class="p_del">-	schedule_delayed_work(&amp;tstamp-&gt;overflow_work, tstamp-&gt;overflow_period);</span>
<span class="p_add">+	queue_delayed_work(priv-&gt;wq, &amp;tstamp-&gt;overflow_work,</span>
<span class="p_add">+			   msecs_to_jiffies(tstamp-&gt;overflow_period * 1000));</span>
 }
 
 int mlx5e_hwstamp_set(struct net_device *dev, struct ifreq *ifr)
<span class="p_chunk">@@ -214,18 +252,6 @@</span> <span class="p_context"> static int mlx5e_ptp_adjfreq(struct ptp_clock_info *ptp, s32 delta)</span>
 	int neg_adj = 0;
 	struct mlx5e_tstamp *tstamp = container_of(ptp, struct mlx5e_tstamp,
 						  ptp_info);
<span class="p_del">-	struct mlx5e_priv *priv =</span>
<span class="p_del">-		container_of(tstamp, struct mlx5e_priv, tstamp);</span>
<span class="p_del">-</span>
<span class="p_del">-	if (MLX5_CAP_GEN(priv-&gt;mdev, pps_modify)) {</span>
<span class="p_del">-		u32 in[MLX5_ST_SZ_DW(mtpps_reg)] = {0};</span>
<span class="p_del">-</span>
<span class="p_del">-		/* For future use need to add a loop for finding all 1PPS out pins */</span>
<span class="p_del">-		MLX5_SET(mtpps_reg, in, pin_mode, MLX5E_PIN_MODE_OUT);</span>
<span class="p_del">-		MLX5_SET(mtpps_reg, in, out_periodic_adjustment, delta &amp; 0xFFFF);</span>
<span class="p_del">-</span>
<span class="p_del">-		mlx5_set_mtpps(priv-&gt;mdev, in, sizeof(in));</span>
<span class="p_del">-	}</span>
 
 	if (delta &lt; 0) {
 		neg_adj = 1;
<span class="p_chunk">@@ -254,12 +280,13 @@</span> <span class="p_context"> static int mlx5e_extts_configure(struct ptp_clock_info *ptp,</span>
 	struct mlx5e_priv *priv =
 		container_of(tstamp, struct mlx5e_priv, tstamp);
 	u32 in[MLX5_ST_SZ_DW(mtpps_reg)] = {0};
<span class="p_add">+	u32 field_select = 0;</span>
<span class="p_add">+	u8 pin_mode = 0;</span>
 	u8 pattern = 0;
 	int pin = -1;
 	int err = 0;
 
<span class="p_del">-	if (!MLX5_CAP_GEN(priv-&gt;mdev, pps) ||</span>
<span class="p_del">-	    !MLX5_CAP_GEN(priv-&gt;mdev, pps_modify))</span>
<span class="p_add">+	if (!MLX5_PPS_CAP(priv-&gt;mdev))</span>
 		return -EOPNOTSUPP;
 
 	if (rq-&gt;extts.index &gt;= tstamp-&gt;ptp_info.n_pins)
<span class="p_chunk">@@ -269,15 +296,21 @@</span> <span class="p_context"> static int mlx5e_extts_configure(struct ptp_clock_info *ptp,</span>
 		pin = ptp_find_pin(tstamp-&gt;ptp, PTP_PF_EXTTS, rq-&gt;extts.index);
 		if (pin &lt; 0)
 			return -EBUSY;
<span class="p_add">+		pin_mode = MLX5E_PIN_MODE_IN;</span>
<span class="p_add">+		pattern = !!(rq-&gt;extts.flags &amp; PTP_FALLING_EDGE);</span>
<span class="p_add">+		field_select = MLX5E_MTPPS_FS_PIN_MODE |</span>
<span class="p_add">+			       MLX5E_MTPPS_FS_PATTERN |</span>
<span class="p_add">+			       MLX5E_MTPPS_FS_ENABLE;</span>
<span class="p_add">+	} else {</span>
<span class="p_add">+		pin = rq-&gt;extts.index;</span>
<span class="p_add">+		field_select = MLX5E_MTPPS_FS_ENABLE;</span>
 	}
 
<span class="p_del">-	if (rq-&gt;extts.flags &amp; PTP_FALLING_EDGE)</span>
<span class="p_del">-		pattern = 1;</span>
<span class="p_del">-</span>
 	MLX5_SET(mtpps_reg, in, pin, pin);
<span class="p_del">-	MLX5_SET(mtpps_reg, in, pin_mode, MLX5E_PIN_MODE_IN);</span>
<span class="p_add">+	MLX5_SET(mtpps_reg, in, pin_mode, pin_mode);</span>
 	MLX5_SET(mtpps_reg, in, pattern, pattern);
 	MLX5_SET(mtpps_reg, in, enable, on);
<span class="p_add">+	MLX5_SET(mtpps_reg, in, field_select, field_select);</span>
 
 	err = mlx5_set_mtpps(priv-&gt;mdev, in, sizeof(in));
 	if (err)
<span class="p_chunk">@@ -296,14 +329,18 @@</span> <span class="p_context"> static int mlx5e_perout_configure(struct ptp_clock_info *ptp,</span>
 	struct mlx5e_priv *priv =
 		container_of(tstamp, struct mlx5e_priv, tstamp);
 	u32 in[MLX5_ST_SZ_DW(mtpps_reg)] = {0};
<span class="p_del">-	u64 nsec_now, nsec_delta, time_stamp;</span>
<span class="p_add">+	u64 nsec_now, nsec_delta, time_stamp = 0;</span>
 	u64 cycles_now, cycles_delta;
 	struct timespec64 ts;
 	unsigned long flags;
<span class="p_add">+	u32 field_select = 0;</span>
<span class="p_add">+	u8 pin_mode = 0;</span>
<span class="p_add">+	u8 pattern = 0;</span>
 	int pin = -1;
<span class="p_add">+	int err = 0;</span>
 	s64 ns;
 
<span class="p_del">-	if (!MLX5_CAP_GEN(priv-&gt;mdev, pps_modify))</span>
<span class="p_add">+	if (!MLX5_PPS_CAP(priv-&gt;mdev))</span>
 		return -EOPNOTSUPP;
 
 	if (rq-&gt;perout.index &gt;= tstamp-&gt;ptp_info.n_pins)
<span class="p_chunk">@@ -314,32 +351,60 @@</span> <span class="p_context"> static int mlx5e_perout_configure(struct ptp_clock_info *ptp,</span>
 				   rq-&gt;perout.index);
 		if (pin &lt; 0)
 			return -EBUSY;
<span class="p_del">-	}</span>
 
<span class="p_del">-	ts.tv_sec = rq-&gt;perout.period.sec;</span>
<span class="p_del">-	ts.tv_nsec = rq-&gt;perout.period.nsec;</span>
<span class="p_del">-	ns = timespec64_to_ns(&amp;ts);</span>
<span class="p_del">-	if (on)</span>
<span class="p_add">+		pin_mode = MLX5E_PIN_MODE_OUT;</span>
<span class="p_add">+		pattern = MLX5E_OUT_PATTERN_PERIODIC;</span>
<span class="p_add">+		ts.tv_sec = rq-&gt;perout.period.sec;</span>
<span class="p_add">+		ts.tv_nsec = rq-&gt;perout.period.nsec;</span>
<span class="p_add">+		ns = timespec64_to_ns(&amp;ts);</span>
<span class="p_add">+</span>
 		if ((ns &gt;&gt; 1) != 500000000LL)
 			return -EINVAL;
<span class="p_del">-	ts.tv_sec = rq-&gt;perout.start.sec;</span>
<span class="p_del">-	ts.tv_nsec = rq-&gt;perout.start.nsec;</span>
<span class="p_del">-	ns = timespec64_to_ns(&amp;ts);</span>
<span class="p_del">-	cycles_now = mlx5_read_internal_timer(tstamp-&gt;mdev);</span>
<span class="p_del">-	write_lock_irqsave(&amp;tstamp-&gt;lock, flags);</span>
<span class="p_del">-	nsec_now = timecounter_cyc2time(&amp;tstamp-&gt;clock, cycles_now);</span>
<span class="p_del">-	nsec_delta = ns - nsec_now;</span>
<span class="p_del">-	cycles_delta = div64_u64(nsec_delta &lt;&lt; tstamp-&gt;cycles.shift,</span>
<span class="p_del">-				 tstamp-&gt;cycles.mult);</span>
<span class="p_del">-	write_unlock_irqrestore(&amp;tstamp-&gt;lock, flags);</span>
<span class="p_del">-	time_stamp = cycles_now + cycles_delta;</span>
<span class="p_add">+</span>
<span class="p_add">+		ts.tv_sec = rq-&gt;perout.start.sec;</span>
<span class="p_add">+		ts.tv_nsec = rq-&gt;perout.start.nsec;</span>
<span class="p_add">+		ns = timespec64_to_ns(&amp;ts);</span>
<span class="p_add">+		cycles_now = mlx5_read_internal_timer(tstamp-&gt;mdev);</span>
<span class="p_add">+		write_lock_irqsave(&amp;tstamp-&gt;lock, flags);</span>
<span class="p_add">+		nsec_now = timecounter_cyc2time(&amp;tstamp-&gt;clock, cycles_now);</span>
<span class="p_add">+		nsec_delta = ns - nsec_now;</span>
<span class="p_add">+		cycles_delta = div64_u64(nsec_delta &lt;&lt; tstamp-&gt;cycles.shift,</span>
<span class="p_add">+					 tstamp-&gt;cycles.mult);</span>
<span class="p_add">+		write_unlock_irqrestore(&amp;tstamp-&gt;lock, flags);</span>
<span class="p_add">+		time_stamp = cycles_now + cycles_delta;</span>
<span class="p_add">+		field_select = MLX5E_MTPPS_FS_PIN_MODE |</span>
<span class="p_add">+			       MLX5E_MTPPS_FS_PATTERN |</span>
<span class="p_add">+			       MLX5E_MTPPS_FS_ENABLE |</span>
<span class="p_add">+			       MLX5E_MTPPS_FS_TIME_STAMP;</span>
<span class="p_add">+	} else {</span>
<span class="p_add">+		pin = rq-&gt;perout.index;</span>
<span class="p_add">+		field_select = MLX5E_MTPPS_FS_ENABLE;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
 	MLX5_SET(mtpps_reg, in, pin, pin);
<span class="p_del">-	MLX5_SET(mtpps_reg, in, pin_mode, MLX5E_PIN_MODE_OUT);</span>
<span class="p_del">-	MLX5_SET(mtpps_reg, in, pattern, MLX5E_OUT_PATTERN_PERIODIC);</span>
<span class="p_add">+	MLX5_SET(mtpps_reg, in, pin_mode, pin_mode);</span>
<span class="p_add">+	MLX5_SET(mtpps_reg, in, pattern, pattern);</span>
 	MLX5_SET(mtpps_reg, in, enable, on);
 	MLX5_SET64(mtpps_reg, in, time_stamp, time_stamp);
<span class="p_add">+	MLX5_SET(mtpps_reg, in, field_select, field_select);</span>
<span class="p_add">+</span>
<span class="p_add">+	err = mlx5_set_mtpps(priv-&gt;mdev, in, sizeof(in));</span>
<span class="p_add">+	if (err)</span>
<span class="p_add">+		return err;</span>
 
<span class="p_del">-	return mlx5_set_mtpps(priv-&gt;mdev, in, sizeof(in));</span>
<span class="p_add">+	return mlx5_set_mtppse(priv-&gt;mdev, pin, 0,</span>
<span class="p_add">+			       MLX5E_EVENT_MODE_REPETETIVE &amp; on);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static int mlx5e_pps_configure(struct ptp_clock_info *ptp,</span>
<span class="p_add">+			       struct ptp_clock_request *rq,</span>
<span class="p_add">+			       int on)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct mlx5e_tstamp *tstamp =</span>
<span class="p_add">+		container_of(ptp, struct mlx5e_tstamp, ptp_info);</span>
<span class="p_add">+</span>
<span class="p_add">+	tstamp-&gt;pps_info.enabled = !!on;</span>
<span class="p_add">+	return 0;</span>
 }
 
 static int mlx5e_ptp_enable(struct ptp_clock_info *ptp,
<span class="p_chunk">@@ -351,6 +416,8 @@</span> <span class="p_context"> static int mlx5e_ptp_enable(struct ptp_clock_info *ptp,</span>
 		return mlx5e_extts_configure(ptp, rq, on);
 	case PTP_CLK_REQ_PEROUT:
 		return mlx5e_perout_configure(ptp, rq, on);
<span class="p_add">+	case PTP_CLK_REQ_PPS:</span>
<span class="p_add">+		return mlx5e_pps_configure(ptp, rq, on);</span>
 	default:
 		return -EOPNOTSUPP;
 	}
<span class="p_chunk">@@ -396,6 +463,7 @@</span> <span class="p_context"> static int mlx5e_init_pin_config(struct mlx5e_tstamp *tstamp)</span>
 		return -ENOMEM;
 	tstamp-&gt;ptp_info.enable = mlx5e_ptp_enable;
 	tstamp-&gt;ptp_info.verify = mlx5e_ptp_verify;
<span class="p_add">+	tstamp-&gt;ptp_info.pps = 1;</span>
 
 	for (i = 0; i &lt; tstamp-&gt;ptp_info.n_pins; i++) {
 		snprintf(tstamp-&gt;ptp_info.pin_config[i].name,
<span class="p_chunk">@@ -423,22 +491,56 @@</span> <span class="p_context"> static void mlx5e_get_pps_caps(struct mlx5e_priv *priv,</span>
 	tstamp-&gt;ptp_info.n_per_out = MLX5_GET(mtpps_reg, out,
 					      cap_max_num_of_pps_out_pins);
 
<span class="p_del">-	tstamp-&gt;pps_pin_caps[0] = MLX5_GET(mtpps_reg, out, cap_pin_0_mode);</span>
<span class="p_del">-	tstamp-&gt;pps_pin_caps[1] = MLX5_GET(mtpps_reg, out, cap_pin_1_mode);</span>
<span class="p_del">-	tstamp-&gt;pps_pin_caps[2] = MLX5_GET(mtpps_reg, out, cap_pin_2_mode);</span>
<span class="p_del">-	tstamp-&gt;pps_pin_caps[3] = MLX5_GET(mtpps_reg, out, cap_pin_3_mode);</span>
<span class="p_del">-	tstamp-&gt;pps_pin_caps[4] = MLX5_GET(mtpps_reg, out, cap_pin_4_mode);</span>
<span class="p_del">-	tstamp-&gt;pps_pin_caps[5] = MLX5_GET(mtpps_reg, out, cap_pin_5_mode);</span>
<span class="p_del">-	tstamp-&gt;pps_pin_caps[6] = MLX5_GET(mtpps_reg, out, cap_pin_6_mode);</span>
<span class="p_del">-	tstamp-&gt;pps_pin_caps[7] = MLX5_GET(mtpps_reg, out, cap_pin_7_mode);</span>
<span class="p_add">+	tstamp-&gt;pps_info.pin_caps[0] = MLX5_GET(mtpps_reg, out, cap_pin_0_mode);</span>
<span class="p_add">+	tstamp-&gt;pps_info.pin_caps[1] = MLX5_GET(mtpps_reg, out, cap_pin_1_mode);</span>
<span class="p_add">+	tstamp-&gt;pps_info.pin_caps[2] = MLX5_GET(mtpps_reg, out, cap_pin_2_mode);</span>
<span class="p_add">+	tstamp-&gt;pps_info.pin_caps[3] = MLX5_GET(mtpps_reg, out, cap_pin_3_mode);</span>
<span class="p_add">+	tstamp-&gt;pps_info.pin_caps[4] = MLX5_GET(mtpps_reg, out, cap_pin_4_mode);</span>
<span class="p_add">+	tstamp-&gt;pps_info.pin_caps[5] = MLX5_GET(mtpps_reg, out, cap_pin_5_mode);</span>
<span class="p_add">+	tstamp-&gt;pps_info.pin_caps[6] = MLX5_GET(mtpps_reg, out, cap_pin_6_mode);</span>
<span class="p_add">+	tstamp-&gt;pps_info.pin_caps[7] = MLX5_GET(mtpps_reg, out, cap_pin_7_mode);</span>
 }
 
 void mlx5e_pps_event_handler(struct mlx5e_priv *priv,
 			     struct ptp_clock_event *event)
 {
<span class="p_add">+	struct net_device *netdev = priv-&gt;netdev;</span>
 	struct mlx5e_tstamp *tstamp = &amp;priv-&gt;tstamp;
<span class="p_add">+	struct timespec64 ts;</span>
<span class="p_add">+	u64 nsec_now, nsec_delta;</span>
<span class="p_add">+	u64 cycles_now, cycles_delta;</span>
<span class="p_add">+	int pin = event-&gt;index;</span>
<span class="p_add">+	s64 ns;</span>
<span class="p_add">+	unsigned long flags;</span>
 
<span class="p_del">-	ptp_clock_event(tstamp-&gt;ptp, event);</span>
<span class="p_add">+	switch (tstamp-&gt;ptp_info.pin_config[pin].func) {</span>
<span class="p_add">+	case PTP_PF_EXTTS:</span>
<span class="p_add">+		if (tstamp-&gt;pps_info.enabled) {</span>
<span class="p_add">+			event-&gt;type = PTP_CLOCK_PPSUSR;</span>
<span class="p_add">+			event-&gt;pps_times.ts_real = ns_to_timespec64(event-&gt;timestamp);</span>
<span class="p_add">+		} else {</span>
<span class="p_add">+			event-&gt;type = PTP_CLOCK_EXTTS;</span>
<span class="p_add">+		}</span>
<span class="p_add">+		ptp_clock_event(tstamp-&gt;ptp, event);</span>
<span class="p_add">+		break;</span>
<span class="p_add">+	case PTP_PF_PEROUT:</span>
<span class="p_add">+		mlx5e_ptp_gettime(&amp;tstamp-&gt;ptp_info, &amp;ts);</span>
<span class="p_add">+		cycles_now = mlx5_read_internal_timer(tstamp-&gt;mdev);</span>
<span class="p_add">+		ts.tv_sec += 1;</span>
<span class="p_add">+		ts.tv_nsec = 0;</span>
<span class="p_add">+		ns = timespec64_to_ns(&amp;ts);</span>
<span class="p_add">+		write_lock_irqsave(&amp;tstamp-&gt;lock, flags);</span>
<span class="p_add">+		nsec_now = timecounter_cyc2time(&amp;tstamp-&gt;clock, cycles_now);</span>
<span class="p_add">+		nsec_delta = ns - nsec_now;</span>
<span class="p_add">+		cycles_delta = div64_u64(nsec_delta &lt;&lt; tstamp-&gt;cycles.shift,</span>
<span class="p_add">+					 tstamp-&gt;cycles.mult);</span>
<span class="p_add">+		tstamp-&gt;pps_info.start[pin] = cycles_now + cycles_delta;</span>
<span class="p_add">+		queue_work(priv-&gt;wq, &amp;tstamp-&gt;pps_info.out_work);</span>
<span class="p_add">+		write_unlock_irqrestore(&amp;tstamp-&gt;lock, flags);</span>
<span class="p_add">+		break;</span>
<span class="p_add">+	default:</span>
<span class="p_add">+		netdev_err(netdev, &quot;%s: Unhandled event\n&quot;, __func__);</span>
<span class="p_add">+	}</span>
 }
 
 void mlx5e_timestamp_init(struct mlx5e_priv *priv)
<span class="p_chunk">@@ -474,9 +576,10 @@</span> <span class="p_context"> void mlx5e_timestamp_init(struct mlx5e_priv *priv)</span>
 	do_div(ns, NSEC_PER_SEC / 2 / HZ);
 	tstamp-&gt;overflow_period = ns;
 
<span class="p_add">+	INIT_WORK(&amp;tstamp-&gt;pps_info.out_work, mlx5e_pps_out);</span>
 	INIT_DELAYED_WORK(&amp;tstamp-&gt;overflow_work, mlx5e_timestamp_overflow);
 	if (tstamp-&gt;overflow_period)
<span class="p_del">-		schedule_delayed_work(&amp;tstamp-&gt;overflow_work, 0);</span>
<span class="p_add">+		queue_delayed_work(priv-&gt;wq, &amp;tstamp-&gt;overflow_work, 0);</span>
 	else
 		mlx5_core_warn(priv-&gt;mdev, &quot;invalid overflow period, overflow_work is not scheduled\n&quot;);
 
<span class="p_chunk">@@ -485,16 +588,10 @@</span> <span class="p_context"> void mlx5e_timestamp_init(struct mlx5e_priv *priv)</span>
 	snprintf(tstamp-&gt;ptp_info.name, 16, &quot;mlx5 ptp&quot;);
 
 	/* Initialize 1PPS data structures */
<span class="p_del">-#define MAX_PIN_NUM	8</span>
<span class="p_del">-	tstamp-&gt;pps_pin_caps = kzalloc(sizeof(u8) * MAX_PIN_NUM, GFP_KERNEL);</span>
<span class="p_del">-	if (tstamp-&gt;pps_pin_caps) {</span>
<span class="p_del">-		if (MLX5_CAP_GEN(priv-&gt;mdev, pps))</span>
<span class="p_del">-			mlx5e_get_pps_caps(priv, tstamp);</span>
<span class="p_del">-		if (tstamp-&gt;ptp_info.n_pins)</span>
<span class="p_del">-			mlx5e_init_pin_config(tstamp);</span>
<span class="p_del">-	} else {</span>
<span class="p_del">-		mlx5_core_warn(priv-&gt;mdev, &quot;1PPS initialization failed\n&quot;);</span>
<span class="p_del">-	}</span>
<span class="p_add">+	if (MLX5_PPS_CAP(priv-&gt;mdev))</span>
<span class="p_add">+		mlx5e_get_pps_caps(priv, tstamp);</span>
<span class="p_add">+	if (tstamp-&gt;ptp_info.n_pins)</span>
<span class="p_add">+		mlx5e_init_pin_config(tstamp);</span>
 
 	tstamp-&gt;ptp = ptp_clock_register(&amp;tstamp-&gt;ptp_info,
 					 &amp;priv-&gt;mdev-&gt;pdev-&gt;dev);
<span class="p_chunk">@@ -517,8 +614,7 @@</span> <span class="p_context"> void mlx5e_timestamp_cleanup(struct mlx5e_priv *priv)</span>
 		priv-&gt;tstamp.ptp = NULL;
 	}
 
<span class="p_del">-	kfree(tstamp-&gt;pps_pin_caps);</span>
<span class="p_del">-	kfree(tstamp-&gt;ptp_info.pin_config);</span>
<span class="p_del">-</span>
<span class="p_add">+	cancel_work_sync(&amp;tstamp-&gt;pps_info.out_work);</span>
 	cancel_delayed_work_sync(&amp;tstamp-&gt;overflow_work);
<span class="p_add">+	kfree(tstamp-&gt;ptp_info.pin_config);</span>
 }
<span class="p_header">diff --git a/drivers/net/ethernet/mellanox/mlx5/core/en_fs_ethtool.c b/drivers/net/ethernet/mellanox/mlx5/core/en_fs_ethtool.c</span>
<span class="p_header">index 85bf4a389295..986387de13ee 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/mellanox/mlx5/core/en_fs_ethtool.c</span>
<span class="p_header">+++ b/drivers/net/ethernet/mellanox/mlx5/core/en_fs_ethtool.c</span>
<span class="p_chunk">@@ -276,7 +276,7 @@</span> <span class="p_context"> static void add_rule_to_list(struct mlx5e_priv *priv,</span>
 
 static bool outer_header_zero(u32 *match_criteria)
 {
<span class="p_del">-	int size = MLX5_ST_SZ_BYTES(fte_match_param);</span>
<span class="p_add">+	int size = MLX5_FLD_SZ_BYTES(fte_match_param, outer_headers);</span>
 	char *outer_headers_c = MLX5_ADDR_OF(fte_match_param, match_criteria,
 					     outer_headers);
 
<span class="p_chunk">@@ -320,7 +320,7 @@</span> <span class="p_context"> add_ethtool_flow_rule(struct mlx5e_priv *priv,</span>
 
 	spec-&gt;match_criteria_enable = (!outer_header_zero(spec-&gt;match_criteria));
 	flow_act.flow_tag = MLX5_FS_DEFAULT_FLOW_TAG;
<span class="p_del">-	rule = mlx5_add_flow_rules(ft, spec, &amp;flow_act, dst, 1);</span>
<span class="p_add">+	rule = mlx5_add_flow_rules(ft, spec, &amp;flow_act, dst, dst ? 1 : 0);</span>
 	if (IS_ERR(rule)) {
 		err = PTR_ERR(rule);
 		netdev_err(priv-&gt;netdev, &quot;%s: failed to add ethtool steering rule: %d\n&quot;,
<span class="p_header">diff --git a/drivers/net/ethernet/mellanox/mlx5/core/en_main.c b/drivers/net/ethernet/mellanox/mlx5/core/en_main.c</span>
<span class="p_header">index 7819fe9ede22..072aa8a13a0a 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/mellanox/mlx5/core/en_main.c</span>
<span class="p_header">+++ b/drivers/net/ethernet/mellanox/mlx5/core/en_main.c</span>
<span class="p_chunk">@@ -365,7 +365,6 @@</span> <span class="p_context"> static void mlx5e_async_event(struct mlx5_core_dev *mdev, void *vpriv,</span>
 		break;
 	case MLX5_DEV_EVENT_PPS:
 		eqe = (struct mlx5_eqe *)param;
<span class="p_del">-		ptp_event.type = PTP_CLOCK_EXTTS;</span>
 		ptp_event.index = eqe-&gt;data.pps.pin;
 		ptp_event.timestamp =
 			timecounter_cyc2time(&amp;priv-&gt;tstamp.clock,
<span class="p_header">diff --git a/drivers/net/ethernet/mellanox/mlx5/core/eq.c b/drivers/net/ethernet/mellanox/mlx5/core/eq.c</span>
<span class="p_header">index 33eae5ad2fb0..58a9f5c96d10 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/mellanox/mlx5/core/eq.c</span>
<span class="p_header">+++ b/drivers/net/ethernet/mellanox/mlx5/core/eq.c</span>
<span class="p_chunk">@@ -690,7 +690,7 @@</span> <span class="p_context"> int mlx5_start_eqs(struct mlx5_core_dev *dev)</span>
 	else
 		mlx5_core_dbg(dev, &quot;port_module_event is not set\n&quot;);
 
<span class="p_del">-	if (MLX5_CAP_GEN(dev, pps))</span>
<span class="p_add">+	if (MLX5_PPS_CAP(dev))</span>
 		async_event_mask |= (1ull &lt;&lt; MLX5_EVENT_TYPE_PPS_EVENT);
 
 	err = mlx5_create_map_eq(dev, &amp;table-&gt;cmd_eq, MLX5_EQ_VEC_CMD,
<span class="p_header">diff --git a/drivers/net/ethernet/mellanox/mlx5/core/ipoib.c b/drivers/net/ethernet/mellanox/mlx5/core/ipoib.c</span>
<span class="p_header">index cc1858752e70..6d90e9e3bfd1 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/mellanox/mlx5/core/ipoib.c</span>
<span class="p_header">+++ b/drivers/net/ethernet/mellanox/mlx5/core/ipoib.c</span>
<span class="p_chunk">@@ -160,8 +160,6 @@</span> <span class="p_context"> static int mlx5i_create_underlay_qp(struct mlx5_core_dev *mdev, struct mlx5_core</span>
 
 static void mlx5i_destroy_underlay_qp(struct mlx5_core_dev *mdev, struct mlx5_core_qp *qp)
 {
<span class="p_del">-	mlx5_fs_remove_rx_underlay_qpn(mdev, qp-&gt;qpn);</span>
<span class="p_del">-</span>
 	mlx5_core_destroy_qp(mdev, qp);
 }
 
<span class="p_chunk">@@ -176,8 +174,6 @@</span> <span class="p_context"> static int mlx5i_init_tx(struct mlx5e_priv *priv)</span>
 		return err;
 	}
 
<span class="p_del">-	mlx5_fs_add_rx_underlay_qpn(priv-&gt;mdev, ipriv-&gt;qp.qpn);</span>
<span class="p_del">-</span>
 	err = mlx5e_create_tis(priv-&gt;mdev, 0 /* tc */, ipriv-&gt;qp.qpn, &amp;priv-&gt;tisn[0]);
 	if (err) {
 		mlx5_core_warn(priv-&gt;mdev, &quot;create tis failed, %d\n&quot;, err);
<span class="p_chunk">@@ -235,6 +231,7 @@</span> <span class="p_context"> static void mlx5i_destroy_flow_steering(struct mlx5e_priv *priv)</span>
 
 static int mlx5i_init_rx(struct mlx5e_priv *priv)
 {
<span class="p_add">+	struct mlx5i_priv *ipriv  = priv-&gt;ppriv;</span>
 	int err;
 
 	err = mlx5e_create_indirect_rqt(priv);
<span class="p_chunk">@@ -253,12 +250,18 @@</span> <span class="p_context"> static int mlx5i_init_rx(struct mlx5e_priv *priv)</span>
 	if (err)
 		goto err_destroy_indirect_tirs;
 
<span class="p_del">-	err = mlx5i_create_flow_steering(priv);</span>
<span class="p_add">+	err = mlx5_fs_add_rx_underlay_qpn(priv-&gt;mdev, ipriv-&gt;qp.qpn);</span>
 	if (err)
 		goto err_destroy_direct_tirs;
 
<span class="p_add">+	err = mlx5i_create_flow_steering(priv);</span>
<span class="p_add">+	if (err)</span>
<span class="p_add">+		goto err_remove_rx_underlay_qpn;</span>
<span class="p_add">+</span>
 	return 0;
 
<span class="p_add">+err_remove_rx_underlay_qpn:</span>
<span class="p_add">+	mlx5_fs_remove_rx_underlay_qpn(priv-&gt;mdev, ipriv-&gt;qp.qpn);</span>
 err_destroy_direct_tirs:
 	mlx5e_destroy_direct_tirs(priv);
 err_destroy_indirect_tirs:
<span class="p_chunk">@@ -272,6 +275,9 @@</span> <span class="p_context"> static int mlx5i_init_rx(struct mlx5e_priv *priv)</span>
 
 static void mlx5i_cleanup_rx(struct mlx5e_priv *priv)
 {
<span class="p_add">+	struct mlx5i_priv *ipriv  = priv-&gt;ppriv;</span>
<span class="p_add">+</span>
<span class="p_add">+	mlx5_fs_remove_rx_underlay_qpn(priv-&gt;mdev, ipriv-&gt;qp.qpn);</span>
 	mlx5i_destroy_flow_steering(priv);
 	mlx5e_destroy_direct_tirs(priv);
 	mlx5e_destroy_indirect_tirs(priv);
<span class="p_header">diff --git a/drivers/net/ethernet/mellanox/mlx5/core/lag.c b/drivers/net/ethernet/mellanox/mlx5/core/lag.c</span>
<span class="p_header">index b5d5519542e8..0ca4623bda6b 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/mellanox/mlx5/core/lag.c</span>
<span class="p_header">+++ b/drivers/net/ethernet/mellanox/mlx5/core/lag.c</span>
<span class="p_chunk">@@ -157,22 +157,17 @@</span> <span class="p_context"> static bool mlx5_lag_is_bonded(struct mlx5_lag *ldev)</span>
 static void mlx5_infer_tx_affinity_mapping(struct lag_tracker *tracker,
 					   u8 *port1, u8 *port2)
 {
<span class="p_del">-	if (tracker-&gt;tx_type == NETDEV_LAG_TX_TYPE_ACTIVEBACKUP) {</span>
<span class="p_del">-		if (tracker-&gt;netdev_state[0].tx_enabled) {</span>
<span class="p_del">-			*port1 = 1;</span>
<span class="p_del">-			*port2 = 1;</span>
<span class="p_del">-		} else {</span>
<span class="p_del">-			*port1 = 2;</span>
<span class="p_del">-			*port2 = 2;</span>
<span class="p_del">-		}</span>
<span class="p_del">-	} else {</span>
<span class="p_del">-		*port1 = 1;</span>
<span class="p_del">-		*port2 = 2;</span>
<span class="p_del">-		if (!tracker-&gt;netdev_state[0].link_up)</span>
<span class="p_del">-			*port1 = 2;</span>
<span class="p_del">-		else if (!tracker-&gt;netdev_state[1].link_up)</span>
<span class="p_del">-			*port2 = 1;</span>
<span class="p_add">+	*port1 = 1;</span>
<span class="p_add">+	*port2 = 2;</span>
<span class="p_add">+	if (!tracker-&gt;netdev_state[0].tx_enabled ||</span>
<span class="p_add">+	    !tracker-&gt;netdev_state[0].link_up) {</span>
<span class="p_add">+		*port1 = 2;</span>
<span class="p_add">+		return;</span>
 	}
<span class="p_add">+</span>
<span class="p_add">+	if (!tracker-&gt;netdev_state[1].tx_enabled ||</span>
<span class="p_add">+	    !tracker-&gt;netdev_state[1].link_up)</span>
<span class="p_add">+		*port2 = 1;</span>
 }
 
 static void mlx5_activate_lag(struct mlx5_lag *ldev,
<span class="p_header">diff --git a/drivers/net/ethernet/mellanox/mlx5/core/mlx5_core.h b/drivers/net/ethernet/mellanox/mlx5/core/mlx5_core.h</span>
<span class="p_header">index fbc6e9e9e305..1874aa96c1a1 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/mellanox/mlx5/core/mlx5_core.h</span>
<span class="p_header">+++ b/drivers/net/ethernet/mellanox/mlx5/core/mlx5_core.h</span>
<span class="p_chunk">@@ -153,6 +153,11 @@</span> <span class="p_context"> int mlx5_set_mtpps(struct mlx5_core_dev *mdev, u32 *mtpps, u32 mtpps_size);</span>
 int mlx5_query_mtppse(struct mlx5_core_dev *mdev, u8 pin, u8 *arm, u8 *mode);
 int mlx5_set_mtppse(struct mlx5_core_dev *mdev, u8 pin, u8 arm, u8 mode);
 
<span class="p_add">+#define MLX5_PPS_CAP(mdev) (MLX5_CAP_GEN((mdev), pps) &amp;&amp;		\</span>
<span class="p_add">+			    MLX5_CAP_GEN((mdev), pps_modify) &amp;&amp;		\</span>
<span class="p_add">+			    MLX5_CAP_MCAM_FEATURE((mdev), mtpps_fs) &amp;&amp;	\</span>
<span class="p_add">+			    MLX5_CAP_MCAM_FEATURE((mdev), mtpps_enh_out_per_adj))</span>
<span class="p_add">+</span>
 void mlx5e_init(void);
 void mlx5e_cleanup(void);
 
<span class="p_header">diff --git a/drivers/net/irda/mcs7780.c b/drivers/net/irda/mcs7780.c</span>
<span class="p_header">index 6f6ed75b63c9..765de3bedb88 100644</span>
<span class="p_header">--- a/drivers/net/irda/mcs7780.c</span>
<span class="p_header">+++ b/drivers/net/irda/mcs7780.c</span>
<span class="p_chunk">@@ -141,9 +141,19 @@</span> <span class="p_context"> static int mcs_set_reg(struct mcs_cb *mcs, __u16 reg, __u16 val)</span>
 static int mcs_get_reg(struct mcs_cb *mcs, __u16 reg, __u16 * val)
 {
 	struct usb_device *dev = mcs-&gt;usbdev;
<span class="p_del">-	int ret = usb_control_msg(dev, usb_rcvctrlpipe(dev, 0), MCS_RDREQ,</span>
<span class="p_del">-				  MCS_RD_RTYPE, 0, reg, val, 2,</span>
<span class="p_del">-				  msecs_to_jiffies(MCS_CTRL_TIMEOUT));</span>
<span class="p_add">+	void *dmabuf;</span>
<span class="p_add">+	int ret;</span>
<span class="p_add">+</span>
<span class="p_add">+	dmabuf = kmalloc(sizeof(__u16), GFP_KERNEL);</span>
<span class="p_add">+	if (!dmabuf)</span>
<span class="p_add">+		return -ENOMEM;</span>
<span class="p_add">+</span>
<span class="p_add">+	ret = usb_control_msg(dev, usb_rcvctrlpipe(dev, 0), MCS_RDREQ,</span>
<span class="p_add">+			      MCS_RD_RTYPE, 0, reg, dmabuf, 2,</span>
<span class="p_add">+			      msecs_to_jiffies(MCS_CTRL_TIMEOUT));</span>
<span class="p_add">+</span>
<span class="p_add">+	memcpy(val, dmabuf, sizeof(__u16));</span>
<span class="p_add">+	kfree(dmabuf);</span>
 
 	return ret;
 }
<span class="p_header">diff --git a/drivers/net/phy/phy.c b/drivers/net/phy/phy.c</span>
<span class="p_header">index eebb0e1c70ff..b30d9ceee8bc 100644</span>
<span class="p_header">--- a/drivers/net/phy/phy.c</span>
<span class="p_header">+++ b/drivers/net/phy/phy.c</span>
<span class="p_chunk">@@ -749,6 +749,9 @@</span> <span class="p_context"> void phy_stop_machine(struct phy_device *phydev)</span>
 	if (phydev-&gt;state &gt; PHY_UP &amp;&amp; phydev-&gt;state != PHY_HALTED)
 		phydev-&gt;state = PHY_UP;
 	mutex_unlock(&amp;phydev-&gt;lock);
<span class="p_add">+</span>
<span class="p_add">+	/* Now we can run the state machine synchronously */</span>
<span class="p_add">+	phy_state_machine(&amp;phydev-&gt;state_queue.work);</span>
 }
 
 /**
<span class="p_header">diff --git a/drivers/net/virtio_net.c b/drivers/net/virtio_net.c</span>
<span class="p_header">index 6633dd4bb649..acb754eb1ccb 100644</span>
<span class="p_header">--- a/drivers/net/virtio_net.c</span>
<span class="p_header">+++ b/drivers/net/virtio_net.c</span>
<span class="p_chunk">@@ -889,21 +889,20 @@</span> <span class="p_context"> static int add_recvbuf_mergeable(struct virtnet_info *vi,</span>
 
 	buf = (char *)page_address(alloc_frag-&gt;page) + alloc_frag-&gt;offset;
 	buf += headroom; /* advance address leaving hole at front of pkt */
<span class="p_del">-	ctx = (void *)(unsigned long)len;</span>
 	get_page(alloc_frag-&gt;page);
 	alloc_frag-&gt;offset += len + headroom;
 	hole = alloc_frag-&gt;size - alloc_frag-&gt;offset;
 	if (hole &lt; len + headroom) {
 		/* To avoid internal fragmentation, if there is very likely not
 		 * enough space for another buffer, add the remaining space to
<span class="p_del">-		 * the current buffer. This extra space is not included in</span>
<span class="p_del">-		 * the truesize stored in ctx.</span>
<span class="p_add">+		 * the current buffer.</span>
 		 */
 		len += hole;
 		alloc_frag-&gt;offset += hole;
 	}
 
 	sg_init_one(rq-&gt;sg, buf, len);
<span class="p_add">+	ctx = (void *)(unsigned long)len;</span>
 	err = virtqueue_add_inbuf_ctx(rq-&gt;vq, rq-&gt;sg, 1, buf, ctx, gfp);
 	if (err &lt; 0)
 		put_page(virt_to_head_page(buf));
<span class="p_header">diff --git a/drivers/net/wireless/broadcom/brcm80211/brcmfmac/sdio.c b/drivers/net/wireless/broadcom/brcm80211/brcmfmac/sdio.c</span>
<span class="p_header">index 5653d6dd38f6..d44f59ef4f72 100644</span>
<span class="p_header">--- a/drivers/net/wireless/broadcom/brcm80211/brcmfmac/sdio.c</span>
<span class="p_header">+++ b/drivers/net/wireless/broadcom/brcm80211/brcmfmac/sdio.c</span>
<span class="p_chunk">@@ -4168,11 +4168,6 @@</span> <span class="p_context"> struct brcmf_sdio *brcmf_sdio_probe(struct brcmf_sdio_dev *sdiodev)</span>
 		goto fail;
 	}
 
<span class="p_del">-	/* allocate scatter-gather table. sg support</span>
<span class="p_del">-	 * will be disabled upon allocation failure.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	brcmf_sdiod_sgtable_alloc(bus-&gt;sdiodev);</span>
<span class="p_del">-</span>
 	/* Query the F2 block size, set roundup accordingly */
 	bus-&gt;blocksize = bus-&gt;sdiodev-&gt;func[2]-&gt;cur_blksize;
 	bus-&gt;roundup = min(max_roundup, bus-&gt;blocksize);
<span class="p_header">diff --git a/drivers/net/wireless/intel/iwlwifi/dvm/tx.c b/drivers/net/wireless/intel/iwlwifi/dvm/tx.c</span>
<span class="p_header">index 4b97371c3b42..838946d17b59 100644</span>
<span class="p_header">--- a/drivers/net/wireless/intel/iwlwifi/dvm/tx.c</span>
<span class="p_header">+++ b/drivers/net/wireless/intel/iwlwifi/dvm/tx.c</span>
<span class="p_chunk">@@ -1190,11 +1190,11 @@</span> <span class="p_context"> void iwlagn_rx_reply_tx(struct iwl_priv *priv, struct iwl_rx_cmd_buffer *rxb)</span>
 				next_reclaimed;
 			IWL_DEBUG_TX_REPLY(priv, &quot;Next reclaimed packet:%d\n&quot;,
 						  next_reclaimed);
<span class="p_add">+			iwlagn_check_ratid_empty(priv, sta_id, tid);</span>
 		}
 
 		iwl_trans_reclaim(priv-&gt;trans, txq_id, ssn, &amp;skbs);
 
<span class="p_del">-		iwlagn_check_ratid_empty(priv, sta_id, tid);</span>
 		freed = 0;
 
 		/* process frames */
<span class="p_header">diff --git a/drivers/scsi/Kconfig b/drivers/scsi/Kconfig</span>
<span class="p_header">index 3c52867dfe28..d145e0d90227 100644</span>
<span class="p_header">--- a/drivers/scsi/Kconfig</span>
<span class="p_header">+++ b/drivers/scsi/Kconfig</span>
<span class="p_chunk">@@ -1241,6 +1241,8 @@</span> <span class="p_context"> config SCSI_LPFC</span>
 	tristate &quot;Emulex LightPulse Fibre Channel Support&quot;
 	depends on PCI &amp;&amp; SCSI
 	depends on SCSI_FC_ATTRS
<span class="p_add">+	depends on NVME_TARGET_FC || NVME_TARGET_FC=n</span>
<span class="p_add">+	depends on NVME_FC || NVME_FC=n</span>
 	select CRC_T10DIF
 	---help---
           This lpfc driver supports the Emulex LightPulse
<span class="p_header">diff --git a/drivers/target/target_core_user.c b/drivers/target/target_core_user.c</span>
<span class="p_header">index beb5f098f32d..05804227234d 100644</span>
<span class="p_header">--- a/drivers/target/target_core_user.c</span>
<span class="p_header">+++ b/drivers/target/target_core_user.c</span>
<span class="p_chunk">@@ -437,7 +437,7 @@</span> <span class="p_context"> static int scatter_data_area(struct tcmu_dev *udev,</span>
 			to_offset = get_block_offset_user(udev, dbi,
 					block_remaining);
 			offset = DATA_BLOCK_SIZE - block_remaining;
<span class="p_del">-			to = (void *)(unsigned long)to + offset;</span>
<span class="p_add">+			to += offset;</span>
 
 			if (*iov_cnt != 0 &amp;&amp;
 			    to_offset == iov_tail(udev, *iov)) {
<span class="p_chunk">@@ -510,7 +510,7 @@</span> <span class="p_context"> static void gather_data_area(struct tcmu_dev *udev, struct tcmu_cmd *cmd,</span>
 			copy_bytes = min_t(size_t, sg_remaining,
 					block_remaining);
 			offset = DATA_BLOCK_SIZE - block_remaining;
<span class="p_del">-			from = (void *)(unsigned long)from + offset;</span>
<span class="p_add">+			from += offset;</span>
 			tcmu_flush_dcache_range(from, copy_bytes);
 			memcpy(to + sg-&gt;length - sg_remaining, from,
 					copy_bytes);
<span class="p_chunk">@@ -699,25 +699,24 @@</span> <span class="p_context"> tcmu_queue_cmd_ring(struct tcmu_cmd *tcmu_cmd)</span>
 		size_t pad_size = head_to_end(cmd_head, udev-&gt;cmdr_size);
 
 		entry = (void *) mb + CMDR_OFF + cmd_head;
<span class="p_del">-		tcmu_flush_dcache_range(entry, sizeof(*entry));</span>
 		tcmu_hdr_set_op(&amp;entry-&gt;hdr.len_op, TCMU_OP_PAD);
 		tcmu_hdr_set_len(&amp;entry-&gt;hdr.len_op, pad_size);
 		entry-&gt;hdr.cmd_id = 0; /* not used for PAD */
 		entry-&gt;hdr.kflags = 0;
 		entry-&gt;hdr.uflags = 0;
<span class="p_add">+		tcmu_flush_dcache_range(entry, sizeof(*entry));</span>
 
 		UPDATE_HEAD(mb-&gt;cmd_head, pad_size, udev-&gt;cmdr_size);
<span class="p_add">+		tcmu_flush_dcache_range(mb, sizeof(*mb));</span>
 
 		cmd_head = mb-&gt;cmd_head % udev-&gt;cmdr_size; /* UAM */
 		WARN_ON(cmd_head != 0);
 	}
 
 	entry = (void *) mb + CMDR_OFF + cmd_head;
<span class="p_del">-	tcmu_flush_dcache_range(entry, sizeof(*entry));</span>
<span class="p_add">+	memset(entry, 0, command_size);</span>
 	tcmu_hdr_set_op(&amp;entry-&gt;hdr.len_op, TCMU_OP_CMD);
 	entry-&gt;hdr.cmd_id = tcmu_cmd-&gt;cmd_id;
<span class="p_del">-	entry-&gt;hdr.kflags = 0;</span>
<span class="p_del">-	entry-&gt;hdr.uflags = 0;</span>
 
 	/* Handle allocating space from the data area */
 	tcmu_cmd_reset_dbi_cur(tcmu_cmd);
<span class="p_chunk">@@ -736,11 +735,10 @@</span> <span class="p_context"> tcmu_queue_cmd_ring(struct tcmu_cmd *tcmu_cmd)</span>
 		return TCM_LOGICAL_UNIT_COMMUNICATION_FAILURE;
 	}
 	entry-&gt;req.iov_cnt = iov_cnt;
<span class="p_del">-	entry-&gt;req.iov_dif_cnt = 0;</span>
 
 	/* Handle BIDI commands */
<span class="p_add">+	iov_cnt = 0;</span>
 	if (se_cmd-&gt;se_cmd_flags &amp; SCF_BIDI) {
<span class="p_del">-		iov_cnt = 0;</span>
 		iov++;
 		ret = scatter_data_area(udev, tcmu_cmd,
 					se_cmd-&gt;t_bidi_data_sg,
<span class="p_chunk">@@ -753,8 +751,8 @@</span> <span class="p_context"> tcmu_queue_cmd_ring(struct tcmu_cmd *tcmu_cmd)</span>
 			pr_err(&quot;tcmu: alloc and scatter bidi data failed\n&quot;);
 			return TCM_LOGICAL_UNIT_COMMUNICATION_FAILURE;
 		}
<span class="p_del">-		entry-&gt;req.iov_bidi_cnt = iov_cnt;</span>
 	}
<span class="p_add">+	entry-&gt;req.iov_bidi_cnt = iov_cnt;</span>
 
 	/*
 	 * Recalaulate the command&#39;s base size and size according
<span class="p_header">diff --git a/fs/btrfs/extent-tree.c b/fs/btrfs/extent-tree.c</span>
<span class="p_header">index 33d979e9ea2a..83eecd33ad96 100644</span>
<span class="p_header">--- a/fs/btrfs/extent-tree.c</span>
<span class="p_header">+++ b/fs/btrfs/extent-tree.c</span>
<span class="p_chunk">@@ -4776,10 +4776,6 @@</span> <span class="p_context"> static void shrink_delalloc(struct btrfs_root *root, u64 to_reclaim, u64 orig,</span>
 		else
 			flush = BTRFS_RESERVE_NO_FLUSH;
 		spin_lock(&amp;space_info-&gt;lock);
<span class="p_del">-		if (can_overcommit(root, space_info, orig, flush)) {</span>
<span class="p_del">-			spin_unlock(&amp;space_info-&gt;lock);</span>
<span class="p_del">-			break;</span>
<span class="p_del">-		}</span>
 		if (list_empty(&amp;space_info-&gt;tickets) &amp;&amp;
 		    list_empty(&amp;space_info-&gt;priority_tickets)) {
 			spin_unlock(&amp;space_info-&gt;lock);
<span class="p_header">diff --git a/fs/ext4/acl.c b/fs/ext4/acl.c</span>
<span class="p_header">index 3ec0e46de95f..22a8d532cca6 100644</span>
<span class="p_header">--- a/fs/ext4/acl.c</span>
<span class="p_header">+++ b/fs/ext4/acl.c</span>
<span class="p_chunk">@@ -193,13 +193,6 @@</span> <span class="p_context"> __ext4_set_acl(handle_t *handle, struct inode *inode, int type,</span>
 	switch (type) {
 	case ACL_TYPE_ACCESS:
 		name_index = EXT4_XATTR_INDEX_POSIX_ACL_ACCESS;
<span class="p_del">-		if (acl) {</span>
<span class="p_del">-			error = posix_acl_update_mode(inode, &amp;inode-&gt;i_mode, &amp;acl);</span>
<span class="p_del">-			if (error)</span>
<span class="p_del">-				return error;</span>
<span class="p_del">-			inode-&gt;i_ctime = current_time(inode);</span>
<span class="p_del">-			ext4_mark_inode_dirty(handle, inode);</span>
<span class="p_del">-		}</span>
 		break;
 
 	case ACL_TYPE_DEFAULT:
<span class="p_chunk">@@ -221,8 +214,9 @@</span> <span class="p_context"> __ext4_set_acl(handle_t *handle, struct inode *inode, int type,</span>
 				      value, size, 0);
 
 	kfree(value);
<span class="p_del">-	if (!error)</span>
<span class="p_add">+	if (!error) {</span>
 		set_cached_acl(inode, type, acl);
<span class="p_add">+	}</span>
 
 	return error;
 }
<span class="p_chunk">@@ -232,6 +226,8 @@</span> <span class="p_context"> ext4_set_acl(struct inode *inode, struct posix_acl *acl, int type)</span>
 {
 	handle_t *handle;
 	int error, retries = 0;
<span class="p_add">+	umode_t mode = inode-&gt;i_mode;</span>
<span class="p_add">+	int update_mode = 0;</span>
 
 	error = dquot_initialize(inode);
 	if (error)
<span class="p_chunk">@@ -242,7 +238,20 @@</span> <span class="p_context"> ext4_set_acl(struct inode *inode, struct posix_acl *acl, int type)</span>
 	if (IS_ERR(handle))
 		return PTR_ERR(handle);
 
<span class="p_add">+	if ((type == ACL_TYPE_ACCESS) &amp;&amp; acl) {</span>
<span class="p_add">+		error = posix_acl_update_mode(inode, &amp;mode, &amp;acl);</span>
<span class="p_add">+		if (error)</span>
<span class="p_add">+			goto out_stop;</span>
<span class="p_add">+		update_mode = 1;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
 	error = __ext4_set_acl(handle, inode, type, acl);
<span class="p_add">+	if (!error &amp;&amp; update_mode) {</span>
<span class="p_add">+		inode-&gt;i_mode = mode;</span>
<span class="p_add">+		inode-&gt;i_ctime = current_time(inode);</span>
<span class="p_add">+		ext4_mark_inode_dirty(handle, inode);</span>
<span class="p_add">+	}</span>
<span class="p_add">+out_stop:</span>
 	ext4_journal_stop(handle);
 	if (error == -ENOSPC &amp;&amp; ext4_should_retry_alloc(inode-&gt;i_sb, &amp;retries))
 		goto retry;
<span class="p_header">diff --git a/fs/ext4/file.c b/fs/ext4/file.c</span>
<span class="p_header">index 02ce7e7bbdf5..407fc5aa32a7 100644</span>
<span class="p_header">--- a/fs/ext4/file.c</span>
<span class="p_header">+++ b/fs/ext4/file.c</span>
<span class="p_chunk">@@ -521,6 +521,8 @@</span> <span class="p_context"> static int ext4_find_unwritten_pgoff(struct inode *inode,</span>
 				lastoff = page_offset(page);
 				bh = head = page_buffers(page);
 				do {
<span class="p_add">+					if (lastoff + bh-&gt;b_size &lt;= startoff)</span>
<span class="p_add">+						goto next;</span>
 					if (buffer_uptodate(bh) ||
 					    buffer_unwritten(bh)) {
 						if (whence == SEEK_DATA)
<span class="p_chunk">@@ -535,6 +537,7 @@</span> <span class="p_context"> static int ext4_find_unwritten_pgoff(struct inode *inode,</span>
 						unlock_page(page);
 						goto out;
 					}
<span class="p_add">+next:</span>
 					lastoff += bh-&gt;b_size;
 					bh = bh-&gt;b_this_page;
 				} while (bh != head);
<span class="p_header">diff --git a/fs/ext4/resize.c b/fs/ext4/resize.c</span>
<span class="p_header">index c3ed9021b781..035cd3f4785e 100644</span>
<span class="p_header">--- a/fs/ext4/resize.c</span>
<span class="p_header">+++ b/fs/ext4/resize.c</span>
<span class="p_chunk">@@ -1927,7 +1927,8 @@</span> <span class="p_context"> int ext4_resize_fs(struct super_block *sb, ext4_fsblk_t n_blocks_count)</span>
 			n_desc_blocks = o_desc_blocks +
 				le16_to_cpu(es-&gt;s_reserved_gdt_blocks);
 			n_group = n_desc_blocks * EXT4_DESC_PER_BLOCK(sb);
<span class="p_del">-			n_blocks_count = n_group * EXT4_BLOCKS_PER_GROUP(sb);</span>
<span class="p_add">+			n_blocks_count = (ext4_fsblk_t)n_group *</span>
<span class="p_add">+				EXT4_BLOCKS_PER_GROUP(sb);</span>
 			n_group--; /* set to last group number */
 		}
 
<span class="p_header">diff --git a/fs/nfs/nfs4proc.c b/fs/nfs/nfs4proc.c</span>
<span class="p_header">index f5a7faac39a7..074169a54162 100644</span>
<span class="p_header">--- a/fs/nfs/nfs4proc.c</span>
<span class="p_header">+++ b/fs/nfs/nfs4proc.c</span>
<span class="p_chunk">@@ -7407,7 +7407,7 @@</span> <span class="p_context"> static void nfs4_exchange_id_done(struct rpc_task *task, void *data)</span>
 			cdata-&gt;res.server_scope = NULL;
 		}
 		/* Save the EXCHANGE_ID verifier session trunk tests */
<span class="p_del">-		memcpy(clp-&gt;cl_confirm.data, cdata-&gt;args.verifier-&gt;data,</span>
<span class="p_add">+		memcpy(clp-&gt;cl_confirm.data, cdata-&gt;args.verifier.data,</span>
 		       sizeof(clp-&gt;cl_confirm.data));
 	}
 out:
<span class="p_chunk">@@ -7444,7 +7444,6 @@</span> <span class="p_context"> static const struct rpc_call_ops nfs4_exchange_id_call_ops = {</span>
 static int _nfs4_proc_exchange_id(struct nfs_client *clp, struct rpc_cred *cred,
 			u32 sp4_how, struct rpc_xprt *xprt)
 {
<span class="p_del">-	nfs4_verifier verifier;</span>
 	struct rpc_message msg = {
 		.rpc_proc = &amp;nfs4_procedures[NFSPROC4_CLNT_EXCHANGE_ID],
 		.rpc_cred = cred,
<span class="p_chunk">@@ -7468,8 +7467,7 @@</span> <span class="p_context"> static int _nfs4_proc_exchange_id(struct nfs_client *clp, struct rpc_cred *cred,</span>
 		return -ENOMEM;
 	}
 
<span class="p_del">-	if (!xprt)</span>
<span class="p_del">-		nfs4_init_boot_verifier(clp, &amp;verifier);</span>
<span class="p_add">+	nfs4_init_boot_verifier(clp, &amp;calldata-&gt;args.verifier);</span>
 
 	status = nfs4_init_uniform_client_string(clp);
 	if (status)
<span class="p_chunk">@@ -7510,9 +7508,8 @@</span> <span class="p_context"> static int _nfs4_proc_exchange_id(struct nfs_client *clp, struct rpc_cred *cred,</span>
 		task_setup_data.rpc_xprt = xprt;
 		task_setup_data.flags =
 				RPC_TASK_SOFT|RPC_TASK_SOFTCONN|RPC_TASK_ASYNC;
<span class="p_del">-		calldata-&gt;args.verifier = &amp;clp-&gt;cl_confirm;</span>
<span class="p_del">-	} else {</span>
<span class="p_del">-		calldata-&gt;args.verifier = &amp;verifier;</span>
<span class="p_add">+		memcpy(calldata-&gt;args.verifier.data, clp-&gt;cl_confirm.data,</span>
<span class="p_add">+				sizeof(calldata-&gt;args.verifier.data));</span>
 	}
 	calldata-&gt;args.client = clp;
 #ifdef CONFIG_NFS_V4_1_MIGRATION
<span class="p_header">diff --git a/fs/nfs/nfs4xdr.c b/fs/nfs/nfs4xdr.c</span>
<span class="p_header">index 3aebfdc82b30..b0cbee2b2422 100644</span>
<span class="p_header">--- a/fs/nfs/nfs4xdr.c</span>
<span class="p_header">+++ b/fs/nfs/nfs4xdr.c</span>
<span class="p_chunk">@@ -1765,7 +1765,7 @@</span> <span class="p_context"> static void encode_exchange_id(struct xdr_stream *xdr,</span>
 	int len = 0;
 
 	encode_op_hdr(xdr, OP_EXCHANGE_ID, decode_exchange_id_maxsz, hdr);
<span class="p_del">-	encode_nfs4_verifier(xdr, args-&gt;verifier);</span>
<span class="p_add">+	encode_nfs4_verifier(xdr, &amp;args-&gt;verifier);</span>
 
 	encode_string(xdr, strlen(args-&gt;client-&gt;cl_owner_id),
 			args-&gt;client-&gt;cl_owner_id);
<span class="p_header">diff --git a/fs/ocfs2/acl.c b/fs/ocfs2/acl.c</span>
<span class="p_header">index dc22ba8c710f..e50a387959bf 100644</span>
<span class="p_header">--- a/fs/ocfs2/acl.c</span>
<span class="p_header">+++ b/fs/ocfs2/acl.c</span>
<span class="p_chunk">@@ -240,18 +240,6 @@</span> <span class="p_context"> int ocfs2_set_acl(handle_t *handle,</span>
 	switch (type) {
 	case ACL_TYPE_ACCESS:
 		name_index = OCFS2_XATTR_INDEX_POSIX_ACL_ACCESS;
<span class="p_del">-		if (acl) {</span>
<span class="p_del">-			umode_t mode;</span>
<span class="p_del">-</span>
<span class="p_del">-			ret = posix_acl_update_mode(inode, &amp;mode, &amp;acl);</span>
<span class="p_del">-			if (ret)</span>
<span class="p_del">-				return ret;</span>
<span class="p_del">-</span>
<span class="p_del">-			ret = ocfs2_acl_set_mode(inode, di_bh,</span>
<span class="p_del">-						 handle, mode);</span>
<span class="p_del">-			if (ret)</span>
<span class="p_del">-				return ret;</span>
<span class="p_del">-		}</span>
 		break;
 	case ACL_TYPE_DEFAULT:
 		name_index = OCFS2_XATTR_INDEX_POSIX_ACL_DEFAULT;
<span class="p_chunk">@@ -289,7 +277,19 @@</span> <span class="p_context"> int ocfs2_iop_set_acl(struct inode *inode, struct posix_acl *acl, int type)</span>
 	had_lock = ocfs2_inode_lock_tracker(inode, &amp;bh, 1, &amp;oh);
 	if (had_lock &lt; 0)
 		return had_lock;
<span class="p_add">+	if (type == ACL_TYPE_ACCESS &amp;&amp; acl) {</span>
<span class="p_add">+		umode_t mode;</span>
<span class="p_add">+</span>
<span class="p_add">+		status = posix_acl_update_mode(inode, &amp;mode, &amp;acl);</span>
<span class="p_add">+		if (status)</span>
<span class="p_add">+			goto unlock;</span>
<span class="p_add">+</span>
<span class="p_add">+		status = ocfs2_acl_set_mode(inode, bh, NULL, mode);</span>
<span class="p_add">+		if (status)</span>
<span class="p_add">+			goto unlock;</span>
<span class="p_add">+	}</span>
 	status = ocfs2_set_acl(NULL, inode, bh, type, acl, NULL, NULL);
<span class="p_add">+unlock:</span>
 	ocfs2_inode_unlock_tracker(inode, 1, &amp;oh, had_lock);
 	brelse(bh);
 	return status;
<span class="p_header">diff --git a/fs/userfaultfd.c b/fs/userfaultfd.c</span>
<span class="p_header">index 1d622f276e3a..26f9591b04b1 100644</span>
<span class="p_header">--- a/fs/userfaultfd.c</span>
<span class="p_header">+++ b/fs/userfaultfd.c</span>
<span class="p_chunk">@@ -851,6 +851,9 @@</span> <span class="p_context"> static int userfaultfd_release(struct inode *inode, struct file *file)</span>
 	__wake_up_locked_key(&amp;ctx-&gt;fault_wqh, TASK_NORMAL, &amp;range);
 	spin_unlock(&amp;ctx-&gt;fault_pending_wqh.lock);
 
<span class="p_add">+	/* Flush pending events that may still wait on event_wqh */</span>
<span class="p_add">+	wake_up_all(&amp;ctx-&gt;event_wqh);</span>
<span class="p_add">+</span>
 	wake_up_poll(&amp;ctx-&gt;fd_wqh, POLLHUP);
 	userfaultfd_ctx_put(ctx);
 	return 0;
<span class="p_chunk">@@ -1645,6 +1648,8 @@</span> <span class="p_context"> static int userfaultfd_zeropage(struct userfaultfd_ctx *ctx,</span>
 		ret = mfill_zeropage(ctx-&gt;mm, uffdio_zeropage.range.start,
 				     uffdio_zeropage.range.len);
 		mmput(ctx-&gt;mm);
<span class="p_add">+	} else {</span>
<span class="p_add">+		return -ENOSPC;</span>
 	}
 	if (unlikely(put_user(ret, &amp;user_uffdio_zeropage-&gt;zeropage)))
 		return -EFAULT;
<span class="p_header">diff --git a/include/linux/cpuhotplug.h b/include/linux/cpuhotplug.h</span>
<span class="p_header">index 0f2a80377520..30b86efea2bc 100644</span>
<span class="p_header">--- a/include/linux/cpuhotplug.h</span>
<span class="p_header">+++ b/include/linux/cpuhotplug.h</span>
<span class="p_chunk">@@ -58,7 +58,6 @@</span> <span class="p_context"> enum cpuhp_state {</span>
 	CPUHP_XEN_EVTCHN_PREPARE,
 	CPUHP_ARM_SHMOBILE_SCU_PREPARE,
 	CPUHP_SH_SH3X_PREPARE,
<span class="p_del">-	CPUHP_BLK_MQ_PREPARE,</span>
 	CPUHP_NET_FLOW_PREPARE,
 	CPUHP_TOPOLOGY_PREPARE,
 	CPUHP_NET_IUCV_PREPARE,
<span class="p_header">diff --git a/include/linux/cpuset.h b/include/linux/cpuset.h</span>
<span class="p_header">index 119a3f9604b0..898cfe2eeb42 100644</span>
<span class="p_header">--- a/include/linux/cpuset.h</span>
<span class="p_header">+++ b/include/linux/cpuset.h</span>
<span class="p_chunk">@@ -18,6 +18,19 @@</span> <span class="p_context"></span>
 
 #ifdef CONFIG_CPUSETS
 
<span class="p_add">+/*</span>
<span class="p_add">+ * Static branch rewrites can happen in an arbitrary order for a given</span>
<span class="p_add">+ * key. In code paths where we need to loop with read_mems_allowed_begin() and</span>
<span class="p_add">+ * read_mems_allowed_retry() to get a consistent view of mems_allowed, we need</span>
<span class="p_add">+ * to ensure that begin() always gets rewritten before retry() in the</span>
<span class="p_add">+ * disabled -&gt; enabled transition. If not, then if local irqs are disabled</span>
<span class="p_add">+ * around the loop, we can deadlock since retry() would always be</span>
<span class="p_add">+ * comparing the latest value of the mems_allowed seqcount against 0 as</span>
<span class="p_add">+ * begin() still would see cpusets_enabled() as false. The enabled -&gt; disabled</span>
<span class="p_add">+ * transition should happen in reverse order for the same reasons (want to stop</span>
<span class="p_add">+ * looking at real value of mems_allowed.sequence in retry() first).</span>
<span class="p_add">+ */</span>
<span class="p_add">+extern struct static_key_false cpusets_pre_enable_key;</span>
 extern struct static_key_false cpusets_enabled_key;
 static inline bool cpusets_enabled(void)
 {
<span class="p_chunk">@@ -32,12 +45,14 @@</span> <span class="p_context"> static inline int nr_cpusets(void)</span>
 
 static inline void cpuset_inc(void)
 {
<span class="p_add">+	static_branch_inc(&amp;cpusets_pre_enable_key);</span>
 	static_branch_inc(&amp;cpusets_enabled_key);
 }
 
 static inline void cpuset_dec(void)
 {
 	static_branch_dec(&amp;cpusets_enabled_key);
<span class="p_add">+	static_branch_dec(&amp;cpusets_pre_enable_key);</span>
 }
 
 extern int cpuset_init(void);
<span class="p_chunk">@@ -115,7 +130,7 @@</span> <span class="p_context"> extern void cpuset_print_current_mems_allowed(void);</span>
  */
 static inline unsigned int read_mems_allowed_begin(void)
 {
<span class="p_del">-	if (!cpusets_enabled())</span>
<span class="p_add">+	if (!static_branch_unlikely(&amp;cpusets_pre_enable_key))</span>
 		return 0;
 
 	return read_seqcount_begin(&amp;current-&gt;mems_allowed_seq);
<span class="p_chunk">@@ -129,7 +144,7 @@</span> <span class="p_context"> static inline unsigned int read_mems_allowed_begin(void)</span>
  */
 static inline bool read_mems_allowed_retry(unsigned int seq)
 {
<span class="p_del">-	if (!cpusets_enabled())</span>
<span class="p_add">+	if (!static_branch_unlikely(&amp;cpusets_enabled_key))</span>
 		return false;
 
 	return read_seqcount_retry(&amp;current-&gt;mems_allowed_seq, seq);
<span class="p_header">diff --git a/include/linux/mlx5/mlx5_ifc.h b/include/linux/mlx5/mlx5_ifc.h</span>
<span class="p_header">index edafedb7b509..e21a0b3d6454 100644</span>
<span class="p_header">--- a/include/linux/mlx5/mlx5_ifc.h</span>
<span class="p_header">+++ b/include/linux/mlx5/mlx5_ifc.h</span>
<span class="p_chunk">@@ -7718,8 +7718,10 @@</span> <span class="p_context"> struct mlx5_ifc_pcam_reg_bits {</span>
 };
 
 struct mlx5_ifc_mcam_enhanced_features_bits {
<span class="p_del">-	u8         reserved_at_0[0x7f];</span>
<span class="p_add">+	u8         reserved_at_0[0x7d];</span>
 
<span class="p_add">+	u8         mtpps_enh_out_per_adj[0x1];</span>
<span class="p_add">+	u8         mtpps_fs[0x1];</span>
 	u8         pcie_performance_group[0x1];
 };
 
<span class="p_chunk">@@ -8115,7 +8117,8 @@</span> <span class="p_context"> struct mlx5_ifc_mtpps_reg_bits {</span>
 	u8         reserved_at_78[0x4];
 	u8         cap_pin_4_mode[0x4];
 
<span class="p_del">-	u8         reserved_at_80[0x80];</span>
<span class="p_add">+	u8         field_select[0x20];</span>
<span class="p_add">+	u8         reserved_at_a0[0x60];</span>
 
 	u8         enable[0x1];
 	u8         reserved_at_101[0xb];
<span class="p_chunk">@@ -8130,8 +8133,9 @@</span> <span class="p_context"> struct mlx5_ifc_mtpps_reg_bits {</span>
 
 	u8         out_pulse_duration[0x10];
 	u8         out_periodic_adjustment[0x10];
<span class="p_add">+	u8         enhanced_out_periodic_adjustment[0x20];</span>
 
<span class="p_del">-	u8         reserved_at_1a0[0x60];</span>
<span class="p_add">+	u8         reserved_at_1c0[0x20];</span>
 };
 
 struct mlx5_ifc_mtppse_reg_bits {
<span class="p_header">diff --git a/include/linux/mm_types.h b/include/linux/mm_types.h</span>
<span class="p_header">index 45cdb27791a3..ab8f7e11c160 100644</span>
<span class="p_header">--- a/include/linux/mm_types.h</span>
<span class="p_header">+++ b/include/linux/mm_types.h</span>
<span class="p_chunk">@@ -494,6 +494,10 @@</span> <span class="p_context"> struct mm_struct {</span>
 	 * PROT_NONE or PROT_NUMA mapped page.
 	 */
 	bool tlb_flush_pending;
<span class="p_add">+#endif</span>
<span class="p_add">+#ifdef CONFIG_ARCH_WANT_BATCHED_UNMAP_TLB_FLUSH</span>
<span class="p_add">+	/* See flush_tlb_batched_pending() */</span>
<span class="p_add">+	bool tlb_flush_batched;</span>
 #endif
 	struct uprobes_state uprobes_state;
 #ifdef CONFIG_HUGETLB_PAGE
<span class="p_header">diff --git a/include/linux/nfs_xdr.h b/include/linux/nfs_xdr.h</span>
<span class="p_header">index b28c83475ee8..7882a07d973e 100644</span>
<span class="p_header">--- a/include/linux/nfs_xdr.h</span>
<span class="p_header">+++ b/include/linux/nfs_xdr.h</span>
<span class="p_chunk">@@ -1222,7 +1222,7 @@</span> <span class="p_context"> struct nfs41_state_protection {</span>
 
 struct nfs41_exchange_id_args {
 	struct nfs_client		*client;
<span class="p_del">-	nfs4_verifier			*verifier;</span>
<span class="p_add">+	nfs4_verifier			verifier;</span>
 	u32				flags;
 	struct nfs41_state_protection	state_protect;
 };
<span class="p_header">diff --git a/include/linux/workqueue.h b/include/linux/workqueue.h</span>
<span class="p_header">index c102ef65cb64..db6dc9dc0482 100644</span>
<span class="p_header">--- a/include/linux/workqueue.h</span>
<span class="p_header">+++ b/include/linux/workqueue.h</span>
<span class="p_chunk">@@ -323,6 +323,7 @@</span> <span class="p_context"> enum {</span>
 
 	__WQ_DRAINING		= 1 &lt;&lt; 16, /* internal: workqueue is draining */
 	__WQ_ORDERED		= 1 &lt;&lt; 17, /* internal: workqueue is ordered */
<span class="p_add">+	__WQ_ORDERED_EXPLICIT	= 1 &lt;&lt; 18, /* internal: alloc_ordered_workqueue() */</span>
 	__WQ_LEGACY		= 1 &lt;&lt; 18, /* internal: create*_workqueue() */
 
 	WQ_MAX_ACTIVE		= 512,	  /* I like 512, better ideas? */
<span class="p_chunk">@@ -422,7 +423,8 @@</span> <span class="p_context"> __alloc_workqueue_key(const char *fmt, unsigned int flags, int max_active,</span>
  * Pointer to the allocated workqueue on success, %NULL on failure.
  */
 #define alloc_ordered_workqueue(fmt, flags, args...)			\
<span class="p_del">-	alloc_workqueue(fmt, WQ_UNBOUND | __WQ_ORDERED | (flags), 1, ##args)</span>
<span class="p_add">+	alloc_workqueue(fmt, WQ_UNBOUND | __WQ_ORDERED |		\</span>
<span class="p_add">+			__WQ_ORDERED_EXPLICIT | (flags), 1, ##args)</span>
 
 #define create_workqueue(name)						\
 	alloc_workqueue(&quot;%s&quot;, __WQ_LEGACY | WQ_MEM_RECLAIM, 1, (name))
<span class="p_header">diff --git a/include/net/sctp/sctp.h b/include/net/sctp/sctp.h</span>
<span class="p_header">index 069582ee5d7f..06db0c3ec384 100644</span>
<span class="p_header">--- a/include/net/sctp/sctp.h</span>
<span class="p_header">+++ b/include/net/sctp/sctp.h</span>
<span class="p_chunk">@@ -469,6 +469,8 @@</span> <span class="p_context"> _sctp_walk_params((pos), (chunk), ntohs((chunk)-&gt;chunk_hdr.length), member)</span>
 
 #define _sctp_walk_params(pos, chunk, end, member)\
 for (pos.v = chunk-&gt;member;\
<span class="p_add">+     (pos.v + offsetof(struct sctp_paramhdr, length) + sizeof(pos.p-&gt;length) &lt;=\</span>
<span class="p_add">+      (void *)chunk + end) &amp;&amp;\</span>
      pos.v &lt;= (void *)chunk + end - ntohs(pos.p-&gt;length) &amp;&amp;\
      ntohs(pos.p-&gt;length) &gt;= sizeof(sctp_paramhdr_t);\
      pos.v += SCTP_PAD4(ntohs(pos.p-&gt;length)))
<span class="p_chunk">@@ -479,6 +481,8 @@</span> <span class="p_context"> _sctp_walk_errors((err), (chunk_hdr), ntohs((chunk_hdr)-&gt;length))</span>
 #define _sctp_walk_errors(err, chunk_hdr, end)\
 for (err = (sctp_errhdr_t *)((void *)chunk_hdr + \
 	    sizeof(sctp_chunkhdr_t));\
<span class="p_add">+     ((void *)err + offsetof(sctp_errhdr_t, length) + sizeof(err-&gt;length) &lt;=\</span>
<span class="p_add">+      (void *)chunk_hdr + end) &amp;&amp;\</span>
      (void *)err &lt;= (void *)chunk_hdr + end - ntohs(err-&gt;length) &amp;&amp;\
      ntohs(err-&gt;length) &gt;= sizeof(sctp_errhdr_t); \
      err = (sctp_errhdr_t *)((void *)err + SCTP_PAD4(ntohs(err-&gt;length))))
<span class="p_header">diff --git a/include/net/udp.h b/include/net/udp.h</span>
<span class="p_header">index 3391dbd73959..1933442cf1a6 100644</span>
<span class="p_header">--- a/include/net/udp.h</span>
<span class="p_header">+++ b/include/net/udp.h</span>
<span class="p_chunk">@@ -265,6 +265,7 @@</span> <span class="p_context"> static inline struct sk_buff *skb_recv_udp(struct sock *sk, unsigned int flags,</span>
 }
 
 void udp_v4_early_demux(struct sk_buff *skb);
<span class="p_add">+void udp_sk_rx_dst_set(struct sock *sk, struct dst_entry *dst);</span>
 int udp_get_port(struct sock *sk, unsigned short snum,
 		 int (*saddr_cmp)(const struct sock *,
 				  const struct sock *));
<span class="p_header">diff --git a/include/sound/soc.h b/include/sound/soc.h</span>
<span class="p_header">index 5170fd81e1fd..375893d8d4a5 100644</span>
<span class="p_header">--- a/include/sound/soc.h</span>
<span class="p_header">+++ b/include/sound/soc.h</span>
<span class="p_chunk">@@ -795,10 +795,6 @@</span> <span class="p_context"> struct snd_soc_component_driver {</span>
 	int (*suspend)(struct snd_soc_component *);
 	int (*resume)(struct snd_soc_component *);
 
<span class="p_del">-	/* pcm creation and destruction */</span>
<span class="p_del">-	int (*pcm_new)(struct snd_soc_pcm_runtime *);</span>
<span class="p_del">-	void (*pcm_free)(struct snd_pcm *);</span>
<span class="p_del">-</span>
 	/* DT */
 	int (*of_xlate_dai_name)(struct snd_soc_component *component,
 				 struct of_phandle_args *args,
<span class="p_chunk">@@ -872,8 +868,6 @@</span> <span class="p_context"> struct snd_soc_component {</span>
 	void (*remove)(struct snd_soc_component *);
 	int (*suspend)(struct snd_soc_component *);
 	int (*resume)(struct snd_soc_component *);
<span class="p_del">-	int (*pcm_new)(struct snd_soc_pcm_runtime *);</span>
<span class="p_del">-	void (*pcm_free)(struct snd_pcm *);</span>
 
 	/* machine specific init */
 	int (*init)(struct snd_soc_component *component);
<span class="p_header">diff --git a/kernel/cgroup/cgroup-internal.h b/kernel/cgroup/cgroup-internal.h</span>
<span class="p_header">index 00f4d6bf048f..7a01568e5e22 100644</span>
<span class="p_header">--- a/kernel/cgroup/cgroup-internal.h</span>
<span class="p_header">+++ b/kernel/cgroup/cgroup-internal.h</span>
<span class="p_chunk">@@ -33,6 +33,9 @@</span> <span class="p_context"> struct cgroup_taskset {</span>
 	struct list_head	src_csets;
 	struct list_head	dst_csets;
 
<span class="p_add">+	/* the number of tasks in the set */</span>
<span class="p_add">+	int			nr_tasks;</span>
<span class="p_add">+</span>
 	/* the subsys currently being processed */
 	int			ssid;
 
<span class="p_header">diff --git a/kernel/cgroup/cgroup.c b/kernel/cgroup/cgroup.c</span>
<span class="p_header">index 8d4e85eae42c..2c62e4b3f198 100644</span>
<span class="p_header">--- a/kernel/cgroup/cgroup.c</span>
<span class="p_header">+++ b/kernel/cgroup/cgroup.c</span>
<span class="p_chunk">@@ -1948,6 +1948,8 @@</span> <span class="p_context"> static void cgroup_migrate_add_task(struct task_struct *task,</span>
 	if (!cset-&gt;mg_src_cgrp)
 		return;
 
<span class="p_add">+	mgctx-&gt;tset.nr_tasks++;</span>
<span class="p_add">+</span>
 	list_move_tail(&amp;task-&gt;cg_list, &amp;cset-&gt;mg_tasks);
 	if (list_empty(&amp;cset-&gt;mg_node))
 		list_add_tail(&amp;cset-&gt;mg_node,
<span class="p_chunk">@@ -2036,21 +2038,19 @@</span> <span class="p_context"> static int cgroup_migrate_execute(struct cgroup_mgctx *mgctx)</span>
 	struct css_set *cset, *tmp_cset;
 	int ssid, failed_ssid, ret;
 
<span class="p_del">-	/* methods shouldn&#39;t be called if no task is actually migrating */</span>
<span class="p_del">-	if (list_empty(&amp;tset-&gt;src_csets))</span>
<span class="p_del">-		return 0;</span>
<span class="p_del">-</span>
 	/* check that we can legitimately attach to the cgroup */
<span class="p_del">-	do_each_subsys_mask(ss, ssid, mgctx-&gt;ss_mask) {</span>
<span class="p_del">-		if (ss-&gt;can_attach) {</span>
<span class="p_del">-			tset-&gt;ssid = ssid;</span>
<span class="p_del">-			ret = ss-&gt;can_attach(tset);</span>
<span class="p_del">-			if (ret) {</span>
<span class="p_del">-				failed_ssid = ssid;</span>
<span class="p_del">-				goto out_cancel_attach;</span>
<span class="p_add">+	if (tset-&gt;nr_tasks) {</span>
<span class="p_add">+		do_each_subsys_mask(ss, ssid, mgctx-&gt;ss_mask) {</span>
<span class="p_add">+			if (ss-&gt;can_attach) {</span>
<span class="p_add">+				tset-&gt;ssid = ssid;</span>
<span class="p_add">+				ret = ss-&gt;can_attach(tset);</span>
<span class="p_add">+				if (ret) {</span>
<span class="p_add">+					failed_ssid = ssid;</span>
<span class="p_add">+					goto out_cancel_attach;</span>
<span class="p_add">+				}</span>
 			}
<span class="p_del">-		}</span>
<span class="p_del">-	} while_each_subsys_mask();</span>
<span class="p_add">+		} while_each_subsys_mask();</span>
<span class="p_add">+	}</span>
 
 	/*
 	 * Now that we&#39;re guaranteed success, proceed to move all tasks to
<span class="p_chunk">@@ -2077,25 +2077,29 @@</span> <span class="p_context"> static int cgroup_migrate_execute(struct cgroup_mgctx *mgctx)</span>
 	 */
 	tset-&gt;csets = &amp;tset-&gt;dst_csets;
 
<span class="p_del">-	do_each_subsys_mask(ss, ssid, mgctx-&gt;ss_mask) {</span>
<span class="p_del">-		if (ss-&gt;attach) {</span>
<span class="p_del">-			tset-&gt;ssid = ssid;</span>
<span class="p_del">-			ss-&gt;attach(tset);</span>
<span class="p_del">-		}</span>
<span class="p_del">-	} while_each_subsys_mask();</span>
<span class="p_add">+	if (tset-&gt;nr_tasks) {</span>
<span class="p_add">+		do_each_subsys_mask(ss, ssid, mgctx-&gt;ss_mask) {</span>
<span class="p_add">+			if (ss-&gt;attach) {</span>
<span class="p_add">+				tset-&gt;ssid = ssid;</span>
<span class="p_add">+				ss-&gt;attach(tset);</span>
<span class="p_add">+			}</span>
<span class="p_add">+		} while_each_subsys_mask();</span>
<span class="p_add">+	}</span>
 
 	ret = 0;
 	goto out_release_tset;
 
 out_cancel_attach:
<span class="p_del">-	do_each_subsys_mask(ss, ssid, mgctx-&gt;ss_mask) {</span>
<span class="p_del">-		if (ssid == failed_ssid)</span>
<span class="p_del">-			break;</span>
<span class="p_del">-		if (ss-&gt;cancel_attach) {</span>
<span class="p_del">-			tset-&gt;ssid = ssid;</span>
<span class="p_del">-			ss-&gt;cancel_attach(tset);</span>
<span class="p_del">-		}</span>
<span class="p_del">-	} while_each_subsys_mask();</span>
<span class="p_add">+	if (tset-&gt;nr_tasks) {</span>
<span class="p_add">+		do_each_subsys_mask(ss, ssid, mgctx-&gt;ss_mask) {</span>
<span class="p_add">+			if (ssid == failed_ssid)</span>
<span class="p_add">+				break;</span>
<span class="p_add">+			if (ss-&gt;cancel_attach) {</span>
<span class="p_add">+				tset-&gt;ssid = ssid;</span>
<span class="p_add">+				ss-&gt;cancel_attach(tset);</span>
<span class="p_add">+			}</span>
<span class="p_add">+		} while_each_subsys_mask();</span>
<span class="p_add">+	}</span>
 out_release_tset:
 	spin_lock_irq(&amp;css_set_lock);
 	list_splice_init(&amp;tset-&gt;dst_csets, &amp;tset-&gt;src_csets);
<span class="p_chunk">@@ -2917,11 +2921,11 @@</span> <span class="p_context"> static ssize_t cgroup_subtree_control_write(struct kernfs_open_file *of,</span>
 	cgrp-&gt;subtree_control &amp;= ~disable;
 
 	ret = cgroup_apply_control(cgrp);
<span class="p_del">-</span>
 	cgroup_finalize_control(cgrp, ret);
<span class="p_add">+	if (ret)</span>
<span class="p_add">+		goto out_unlock;</span>
 
 	kernfs_activate(cgrp-&gt;kn);
<span class="p_del">-	ret = 0;</span>
 out_unlock:
 	cgroup_kn_unlock(of-&gt;kn);
 	return ret ?: nbytes;
<span class="p_chunk">@@ -4574,6 +4578,10 @@</span> <span class="p_context"> int __init cgroup_init(void)</span>
 
 		if (ss-&gt;bind)
 			ss-&gt;bind(init_css_set.subsys[ssid]);
<span class="p_add">+</span>
<span class="p_add">+		mutex_lock(&amp;cgroup_mutex);</span>
<span class="p_add">+		css_populate_dir(init_css_set.subsys[ssid]);</span>
<span class="p_add">+		mutex_unlock(&amp;cgroup_mutex);</span>
 	}
 
 	/* init_css_set.subsys[] has been updated, re-hash */
<span class="p_header">diff --git a/kernel/cgroup/cpuset.c b/kernel/cgroup/cpuset.c</span>
<span class="p_header">index ae643412948a..8f26927f16a1 100644</span>
<span class="p_header">--- a/kernel/cgroup/cpuset.c</span>
<span class="p_header">+++ b/kernel/cgroup/cpuset.c</span>
<span class="p_chunk">@@ -63,6 +63,7 @@</span> <span class="p_context"></span>
 #include &lt;linux/cgroup.h&gt;
 #include &lt;linux/wait.h&gt;
 
<span class="p_add">+DEFINE_STATIC_KEY_FALSE(cpusets_pre_enable_key);</span>
 DEFINE_STATIC_KEY_FALSE(cpusets_enabled_key);
 
 /* See &quot;Frequency meter&quot; comments, below. */
<span class="p_header">diff --git a/kernel/time/timer.c b/kernel/time/timer.c</span>
<span class="p_header">index 152a706ef8b8..d3f33020a06b 100644</span>
<span class="p_header">--- a/kernel/time/timer.c</span>
<span class="p_header">+++ b/kernel/time/timer.c</span>
<span class="p_chunk">@@ -1495,7 +1495,7 @@</span> <span class="p_context"> u64 get_next_timer_interrupt(unsigned long basej, u64 basem)</span>
 		base-&gt;is_idle = false;
 	} else {
 		if (!is_max_delta)
<span class="p_del">-			expires = basem + (nextevt - basej) * TICK_NSEC;</span>
<span class="p_add">+			expires = basem + (u64)(nextevt - basej) * TICK_NSEC;</span>
 		/*
 		 * If we expect to sleep more than a tick, mark the base idle:
 		 */
<span class="p_header">diff --git a/kernel/workqueue.c b/kernel/workqueue.c</span>
<span class="p_header">index c74bf39ef764..6effbcb7a3d6 100644</span>
<span class="p_header">--- a/kernel/workqueue.c</span>
<span class="p_header">+++ b/kernel/workqueue.c</span>
<span class="p_chunk">@@ -3744,8 +3744,12 @@</span> <span class="p_context"> static int apply_workqueue_attrs_locked(struct workqueue_struct *wq,</span>
 		return -EINVAL;
 
 	/* creating multiple pwqs breaks ordering guarantee */
<span class="p_del">-	if (WARN_ON((wq-&gt;flags &amp; __WQ_ORDERED) &amp;&amp; !list_empty(&amp;wq-&gt;pwqs)))</span>
<span class="p_del">-		return -EINVAL;</span>
<span class="p_add">+	if (!list_empty(&amp;wq-&gt;pwqs)) {</span>
<span class="p_add">+		if (WARN_ON(wq-&gt;flags &amp; __WQ_ORDERED_EXPLICIT))</span>
<span class="p_add">+			return -EINVAL;</span>
<span class="p_add">+</span>
<span class="p_add">+		wq-&gt;flags &amp;= ~__WQ_ORDERED;</span>
<span class="p_add">+	}</span>
 
 	ctx = apply_wqattrs_prepare(wq, attrs);
 	if (!ctx)
<span class="p_chunk">@@ -3929,6 +3933,16 @@</span> <span class="p_context"> struct workqueue_struct *__alloc_workqueue_key(const char *fmt,</span>
 	struct workqueue_struct *wq;
 	struct pool_workqueue *pwq;
 
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Unbound &amp;&amp; max_active == 1 used to imply ordered, which is no</span>
<span class="p_add">+	 * longer the case on NUMA machines due to per-node pools.  While</span>
<span class="p_add">+	 * alloc_ordered_workqueue() is the right way to create an ordered</span>
<span class="p_add">+	 * workqueue, keep the previous behavior to avoid subtle breakages</span>
<span class="p_add">+	 * on NUMA.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	if ((flags &amp; WQ_UNBOUND) &amp;&amp; max_active == 1)</span>
<span class="p_add">+		flags |= __WQ_ORDERED;</span>
<span class="p_add">+</span>
 	/* see the comment above the definition of WQ_POWER_EFFICIENT */
 	if ((flags &amp; WQ_POWER_EFFICIENT) &amp;&amp; wq_power_efficient)
 		flags |= WQ_UNBOUND;
<span class="p_chunk">@@ -4119,13 +4133,14 @@</span> <span class="p_context"> void workqueue_set_max_active(struct workqueue_struct *wq, int max_active)</span>
 	struct pool_workqueue *pwq;
 
 	/* disallow meddling with max_active for ordered workqueues */
<span class="p_del">-	if (WARN_ON(wq-&gt;flags &amp; __WQ_ORDERED))</span>
<span class="p_add">+	if (WARN_ON(wq-&gt;flags &amp; __WQ_ORDERED_EXPLICIT))</span>
 		return;
 
 	max_active = wq_clamp_max_active(max_active, wq-&gt;flags, wq-&gt;name);
 
 	mutex_lock(&amp;wq-&gt;mutex);
 
<span class="p_add">+	wq-&gt;flags &amp;= ~__WQ_ORDERED;</span>
 	wq-&gt;saved_max_active = max_active;
 
 	for_each_pwq(pwq, wq)
<span class="p_chunk">@@ -5253,7 +5268,7 @@</span> <span class="p_context"> int workqueue_sysfs_register(struct workqueue_struct *wq)</span>
 	 * attributes breaks ordering guarantee.  Disallow exposing ordered
 	 * workqueues.
 	 */
<span class="p_del">-	if (WARN_ON(wq-&gt;flags &amp; __WQ_ORDERED))</span>
<span class="p_add">+	if (WARN_ON(wq-&gt;flags &amp; __WQ_ORDERED_EXPLICIT))</span>
 		return -EINVAL;
 
 	wq-&gt;wq_dev = wq_dev = kzalloc(sizeof(*wq_dev), GFP_KERNEL);
<span class="p_header">diff --git a/mm/hugetlb.c b/mm/hugetlb.c</span>
<span class="p_header">index 3eedb187e549..cc289933f462 100644</span>
<span class="p_header">--- a/mm/hugetlb.c</span>
<span class="p_header">+++ b/mm/hugetlb.c</span>
<span class="p_chunk">@@ -4095,6 +4095,7 @@</span> <span class="p_context"> long follow_hugetlb_page(struct mm_struct *mm, struct vm_area_struct *vma,</span>
 	unsigned long vaddr = *position;
 	unsigned long remainder = *nr_pages;
 	struct hstate *h = hstate_vma(vma);
<span class="p_add">+	int err = -EFAULT;</span>
 
 	while (vaddr &lt; vma-&gt;vm_end &amp;&amp; remainder) {
 		pte_t *pte;
<span class="p_chunk">@@ -4170,11 +4171,7 @@</span> <span class="p_context"> long follow_hugetlb_page(struct mm_struct *mm, struct vm_area_struct *vma,</span>
 			}
 			ret = hugetlb_fault(mm, vma, vaddr, fault_flags);
 			if (ret &amp; VM_FAULT_ERROR) {
<span class="p_del">-				int err = vm_fault_to_errno(ret, flags);</span>
<span class="p_del">-</span>
<span class="p_del">-				if (err)</span>
<span class="p_del">-					return err;</span>
<span class="p_del">-</span>
<span class="p_add">+				err = vm_fault_to_errno(ret, flags);</span>
 				remainder = 0;
 				break;
 			}
<span class="p_chunk">@@ -4229,7 +4226,7 @@</span> <span class="p_context"> long follow_hugetlb_page(struct mm_struct *mm, struct vm_area_struct *vma,</span>
 	 */
 	*position = vaddr;
 
<span class="p_del">-	return i ? i : -EFAULT;</span>
<span class="p_add">+	return i ? i : err;</span>
 }
 
 #ifndef __HAVE_ARCH_FLUSH_HUGETLB_TLB_RANGE
<span class="p_header">diff --git a/mm/internal.h b/mm/internal.h</span>
<span class="p_header">index 0e4f558412fb..9c8a2bfb975c 100644</span>
<span class="p_header">--- a/mm/internal.h</span>
<span class="p_header">+++ b/mm/internal.h</span>
<span class="p_chunk">@@ -498,6 +498,7 @@</span> <span class="p_context"> extern struct workqueue_struct *mm_percpu_wq;</span>
 #ifdef CONFIG_ARCH_WANT_BATCHED_UNMAP_TLB_FLUSH
 void try_to_unmap_flush(void);
 void try_to_unmap_flush_dirty(void);
<span class="p_add">+void flush_tlb_batched_pending(struct mm_struct *mm);</span>
 #else
 static inline void try_to_unmap_flush(void)
 {
<span class="p_chunk">@@ -505,7 +506,9 @@</span> <span class="p_context"> static inline void try_to_unmap_flush(void)</span>
 static inline void try_to_unmap_flush_dirty(void)
 {
 }
<span class="p_del">-</span>
<span class="p_add">+static inline void flush_tlb_batched_pending(struct mm_struct *mm)</span>
<span class="p_add">+{</span>
<span class="p_add">+}</span>
 #endif /* CONFIG_ARCH_WANT_BATCHED_UNMAP_TLB_FLUSH */
 
 extern const struct trace_print_flags pageflag_names[];
<span class="p_header">diff --git a/mm/madvise.c b/mm/madvise.c</span>
<span class="p_header">index 25b78ee4fc2c..75d2cffbe61d 100644</span>
<span class="p_header">--- a/mm/madvise.c</span>
<span class="p_header">+++ b/mm/madvise.c</span>
<span class="p_chunk">@@ -320,6 +320,7 @@</span> <span class="p_context"> static int madvise_free_pte_range(pmd_t *pmd, unsigned long addr,</span>
 
 	tlb_remove_check_page_size_change(tlb, PAGE_SIZE);
 	orig_pte = pte = pte_offset_map_lock(mm, pmd, addr, &amp;ptl);
<span class="p_add">+	flush_tlb_batched_pending(mm);</span>
 	arch_enter_lazy_mmu_mode();
 	for (; addr != end; pte++, addr += PAGE_SIZE) {
 		ptent = *pte;
<span class="p_header">diff --git a/mm/memory.c b/mm/memory.c</span>
<span class="p_header">index bb11c474857e..b0c3d1556a94 100644</span>
<span class="p_header">--- a/mm/memory.c</span>
<span class="p_header">+++ b/mm/memory.c</span>
<span class="p_chunk">@@ -1197,6 +1197,7 @@</span> <span class="p_context"> static unsigned long zap_pte_range(struct mmu_gather *tlb,</span>
 	init_rss_vec(rss);
 	start_pte = pte_offset_map_lock(mm, pmd, addr, &amp;ptl);
 	pte = start_pte;
<span class="p_add">+	flush_tlb_batched_pending(mm);</span>
 	arch_enter_lazy_mmu_mode();
 	do {
 		pte_t ptent = *pte;
<span class="p_header">diff --git a/mm/mprotect.c b/mm/mprotect.c</span>
<span class="p_header">index 8edd0d576254..f42749e6bf4e 100644</span>
<span class="p_header">--- a/mm/mprotect.c</span>
<span class="p_header">+++ b/mm/mprotect.c</span>
<span class="p_chunk">@@ -66,6 +66,7 @@</span> <span class="p_context"> static unsigned long change_pte_range(struct vm_area_struct *vma, pmd_t *pmd,</span>
 	    atomic_read(&amp;vma-&gt;vm_mm-&gt;mm_users) == 1)
 		target_node = numa_node_id();
 
<span class="p_add">+	flush_tlb_batched_pending(vma-&gt;vm_mm);</span>
 	arch_enter_lazy_mmu_mode();
 	do {
 		oldpte = *pte;
<span class="p_header">diff --git a/mm/mremap.c b/mm/mremap.c</span>
<span class="p_header">index cd8a1b199ef9..3f23715d3c69 100644</span>
<span class="p_header">--- a/mm/mremap.c</span>
<span class="p_header">+++ b/mm/mremap.c</span>
<span class="p_chunk">@@ -152,6 +152,7 @@</span> <span class="p_context"> static void move_ptes(struct vm_area_struct *vma, pmd_t *old_pmd,</span>
 	new_ptl = pte_lockptr(mm, new_pmd);
 	if (new_ptl != old_ptl)
 		spin_lock_nested(new_ptl, SINGLE_DEPTH_NESTING);
<span class="p_add">+	flush_tlb_batched_pending(vma-&gt;vm_mm);</span>
 	arch_enter_lazy_mmu_mode();
 
 	for (; old_addr &lt; old_end; old_pte++, old_addr += PAGE_SIZE,
<span class="p_chunk">@@ -428,6 +429,7 @@</span> <span class="p_context"> static struct vm_area_struct *vma_to_resize(unsigned long addr,</span>
 static unsigned long mremap_to(unsigned long addr, unsigned long old_len,
 		unsigned long new_addr, unsigned long new_len, bool *locked,
 		struct vm_userfaultfd_ctx *uf,
<span class="p_add">+		struct list_head *uf_unmap_early,</span>
 		struct list_head *uf_unmap)
 {
 	struct mm_struct *mm = current-&gt;mm;
<span class="p_chunk">@@ -446,7 +448,7 @@</span> <span class="p_context"> static unsigned long mremap_to(unsigned long addr, unsigned long old_len,</span>
 	if (addr + old_len &gt; new_addr &amp;&amp; new_addr + new_len &gt; addr)
 		goto out;
 
<span class="p_del">-	ret = do_munmap(mm, new_addr, new_len, NULL);</span>
<span class="p_add">+	ret = do_munmap(mm, new_addr, new_len, uf_unmap_early);</span>
 	if (ret)
 		goto out;
 
<span class="p_chunk">@@ -514,6 +516,7 @@</span> <span class="p_context"> SYSCALL_DEFINE5(mremap, unsigned long, addr, unsigned long, old_len,</span>
 	unsigned long charged = 0;
 	bool locked = false;
 	struct vm_userfaultfd_ctx uf = NULL_VM_UFFD_CTX;
<span class="p_add">+	LIST_HEAD(uf_unmap_early);</span>
 	LIST_HEAD(uf_unmap);
 
 	if (flags &amp; ~(MREMAP_FIXED | MREMAP_MAYMOVE))
<span class="p_chunk">@@ -541,7 +544,7 @@</span> <span class="p_context"> SYSCALL_DEFINE5(mremap, unsigned long, addr, unsigned long, old_len,</span>
 
 	if (flags &amp; MREMAP_FIXED) {
 		ret = mremap_to(addr, old_len, new_addr, new_len,
<span class="p_del">-				&amp;locked, &amp;uf, &amp;uf_unmap);</span>
<span class="p_add">+				&amp;locked, &amp;uf, &amp;uf_unmap_early, &amp;uf_unmap);</span>
 		goto out;
 	}
 
<span class="p_chunk">@@ -621,6 +624,7 @@</span> <span class="p_context"> SYSCALL_DEFINE5(mremap, unsigned long, addr, unsigned long, old_len,</span>
 	up_write(&amp;current-&gt;mm-&gt;mmap_sem);
 	if (locked &amp;&amp; new_len &gt; old_len)
 		mm_populate(new_addr + old_len, new_len - old_len);
<span class="p_add">+	userfaultfd_unmap_complete(mm, &amp;uf_unmap_early);</span>
 	mremap_userfaultfd_complete(&amp;uf, addr, new_addr, old_len);
 	userfaultfd_unmap_complete(mm, &amp;uf_unmap);
 	return ret;
<span class="p_header">diff --git a/mm/rmap.c b/mm/rmap.c</span>
<span class="p_header">index d405f0e0ee96..9835d19fe143 100644</span>
<span class="p_header">--- a/mm/rmap.c</span>
<span class="p_header">+++ b/mm/rmap.c</span>
<span class="p_chunk">@@ -616,6 +616,13 @@</span> <span class="p_context"> static void set_tlb_ubc_flush_pending(struct mm_struct *mm, bool writable)</span>
 	cpumask_or(&amp;tlb_ubc-&gt;cpumask, &amp;tlb_ubc-&gt;cpumask, mm_cpumask(mm));
 	tlb_ubc-&gt;flush_required = true;
 
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Ensure compiler does not re-order the setting of tlb_flush_batched</span>
<span class="p_add">+	 * before the PTE is cleared.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	barrier();</span>
<span class="p_add">+	mm-&gt;tlb_flush_batched = true;</span>
<span class="p_add">+</span>
 	/*
 	 * If the PTE was dirty then it&#39;s best to assume it&#39;s writable. The
 	 * caller must use try_to_unmap_flush_dirty() or try_to_unmap_flush()
<span class="p_chunk">@@ -643,6 +650,35 @@</span> <span class="p_context"> static bool should_defer_flush(struct mm_struct *mm, enum ttu_flags flags)</span>
 
 	return should_defer;
 }
<span class="p_add">+</span>
<span class="p_add">+/*</span>
<span class="p_add">+ * Reclaim unmaps pages under the PTL but do not flush the TLB prior to</span>
<span class="p_add">+ * releasing the PTL if TLB flushes are batched. It&#39;s possible for a parallel</span>
<span class="p_add">+ * operation such as mprotect or munmap to race between reclaim unmapping</span>
<span class="p_add">+ * the page and flushing the page. If this race occurs, it potentially allows</span>
<span class="p_add">+ * access to data via a stale TLB entry. Tracking all mm&#39;s that have TLB</span>
<span class="p_add">+ * batching in flight would be expensive during reclaim so instead track</span>
<span class="p_add">+ * whether TLB batching occurred in the past and if so then do a flush here</span>
<span class="p_add">+ * if required. This will cost one additional flush per reclaim cycle paid</span>
<span class="p_add">+ * by the first operation at risk such as mprotect and mumap.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * This must be called under the PTL so that an access to tlb_flush_batched</span>
<span class="p_add">+ * that is potentially a &quot;reclaim vs mprotect/munmap/etc&quot; race will synchronise</span>
<span class="p_add">+ * via the PTL.</span>
<span class="p_add">+ */</span>
<span class="p_add">+void flush_tlb_batched_pending(struct mm_struct *mm)</span>
<span class="p_add">+{</span>
<span class="p_add">+	if (mm-&gt;tlb_flush_batched) {</span>
<span class="p_add">+		flush_tlb_mm(mm);</span>
<span class="p_add">+</span>
<span class="p_add">+		/*</span>
<span class="p_add">+		 * Do not allow the compiler to re-order the clearing of</span>
<span class="p_add">+		 * tlb_flush_batched before the tlb is flushed.</span>
<span class="p_add">+		 */</span>
<span class="p_add">+		barrier();</span>
<span class="p_add">+		mm-&gt;tlb_flush_batched = false;</span>
<span class="p_add">+	}</span>
<span class="p_add">+}</span>
 #else
 static void set_tlb_ubc_flush_pending(struct mm_struct *mm, bool writable)
 {
<span class="p_header">diff --git a/net/core/dev_ioctl.c b/net/core/dev_ioctl.c</span>
<span class="p_header">index 27fad31784a8..18f9cb9aa87d 100644</span>
<span class="p_header">--- a/net/core/dev_ioctl.c</span>
<span class="p_header">+++ b/net/core/dev_ioctl.c</span>
<span class="p_chunk">@@ -28,6 +28,7 @@</span> <span class="p_context"> static int dev_ifname(struct net *net, struct ifreq __user *arg)</span>
 
 	if (copy_from_user(&amp;ifr, arg, sizeof(struct ifreq)))
 		return -EFAULT;
<span class="p_add">+	ifr.ifr_name[IFNAMSIZ-1] = 0;</span>
 
 	error = netdev_get_name(net, ifr.ifr_name, ifr.ifr_ifindex);
 	if (error)
<span class="p_chunk">@@ -423,6 +424,8 @@</span> <span class="p_context"> int dev_ioctl(struct net *net, unsigned int cmd, void __user *arg)</span>
 		if (copy_from_user(&amp;iwr, arg, sizeof(iwr)))
 			return -EFAULT;
 
<span class="p_add">+		iwr.ifr_name[sizeof(iwr.ifr_name) - 1] = 0;</span>
<span class="p_add">+</span>
 		return wext_handle_ioctl(net, &amp;iwr, cmd, arg);
 	}
 
<span class="p_header">diff --git a/net/core/rtnetlink.c b/net/core/rtnetlink.c</span>
<span class="p_header">index 467a2f4510a7..52bfeb60c886 100644</span>
<span class="p_header">--- a/net/core/rtnetlink.c</span>
<span class="p_header">+++ b/net/core/rtnetlink.c</span>
<span class="p_chunk">@@ -1977,7 +1977,8 @@</span> <span class="p_context"> static int do_setlink(const struct sk_buff *skb,</span>
 		struct sockaddr *sa;
 		int len;
 
<span class="p_del">-		len = sizeof(sa_family_t) + dev-&gt;addr_len;</span>
<span class="p_add">+		len = sizeof(sa_family_t) + max_t(size_t, dev-&gt;addr_len,</span>
<span class="p_add">+						  sizeof(*sa));</span>
 		sa = kmalloc(len, GFP_KERNEL);
 		if (!sa) {
 			err = -ENOMEM;
<span class="p_chunk">@@ -4165,6 +4166,7 @@</span> <span class="p_context"> static int rtnetlink_event(struct notifier_block *this, unsigned long event, voi</span>
 
 	switch (event) {
 	case NETDEV_REBOOT:
<span class="p_add">+	case NETDEV_CHANGEADDR:</span>
 	case NETDEV_CHANGENAME:
 	case NETDEV_FEAT_CHANGE:
 	case NETDEV_BONDING_FAILOVER:
<span class="p_header">diff --git a/net/dccp/feat.c b/net/dccp/feat.c</span>
<span class="p_header">index 1704948e6a12..f227f002c73d 100644</span>
<span class="p_header">--- a/net/dccp/feat.c</span>
<span class="p_header">+++ b/net/dccp/feat.c</span>
<span class="p_chunk">@@ -1471,9 +1471,12 @@</span> <span class="p_context"> int dccp_feat_init(struct sock *sk)</span>
 	 * singleton values (which always leads to failure).
 	 * These settings can still (later) be overridden via sockopts.
 	 */
<span class="p_del">-	if (ccid_get_builtin_ccids(&amp;tx.val, &amp;tx.len) ||</span>
<span class="p_del">-	    ccid_get_builtin_ccids(&amp;rx.val, &amp;rx.len))</span>
<span class="p_add">+	if (ccid_get_builtin_ccids(&amp;tx.val, &amp;tx.len))</span>
 		return -ENOBUFS;
<span class="p_add">+	if (ccid_get_builtin_ccids(&amp;rx.val, &amp;rx.len)) {</span>
<span class="p_add">+		kfree(tx.val);</span>
<span class="p_add">+		return -ENOBUFS;</span>
<span class="p_add">+	}</span>
 
 	if (!dccp_feat_prefer(sysctl_dccp_tx_ccid, tx.val, tx.len) ||
 	    !dccp_feat_prefer(sysctl_dccp_rx_ccid, rx.val, rx.len))
<span class="p_header">diff --git a/net/dccp/ipv4.c b/net/dccp/ipv4.c</span>
<span class="p_header">index f75482bdee9a..97368f229876 100644</span>
<span class="p_header">--- a/net/dccp/ipv4.c</span>
<span class="p_header">+++ b/net/dccp/ipv4.c</span>
<span class="p_chunk">@@ -631,6 +631,7 @@</span> <span class="p_context"> int dccp_v4_conn_request(struct sock *sk, struct sk_buff *skb)</span>
 		goto drop_and_free;
 
 	inet_csk_reqsk_queue_hash_add(sk, req, DCCP_TIMEOUT_INIT);
<span class="p_add">+	reqsk_put(req);</span>
 	return 0;
 
 drop_and_free:
<span class="p_header">diff --git a/net/dccp/ipv6.c b/net/dccp/ipv6.c</span>
<span class="p_header">index 992621172220..cf3e40df4765 100644</span>
<span class="p_header">--- a/net/dccp/ipv6.c</span>
<span class="p_header">+++ b/net/dccp/ipv6.c</span>
<span class="p_chunk">@@ -380,6 +380,7 @@</span> <span class="p_context"> static int dccp_v6_conn_request(struct sock *sk, struct sk_buff *skb)</span>
 		goto drop_and_free;
 
 	inet_csk_reqsk_queue_hash_add(sk, req, DCCP_TIMEOUT_INIT);
<span class="p_add">+	reqsk_put(req);</span>
 	return 0;
 
 drop_and_free:
<span class="p_header">diff --git a/net/ipv4/fib_frontend.c b/net/ipv4/fib_frontend.c</span>
<span class="p_header">index 83e3ed258467..3acc8261477c 100644</span>
<span class="p_header">--- a/net/ipv4/fib_frontend.c</span>
<span class="p_header">+++ b/net/ipv4/fib_frontend.c</span>
<span class="p_chunk">@@ -1327,13 +1327,14 @@</span> <span class="p_context"> static struct pernet_operations fib_net_ops = {</span>
 
 void __init ip_fib_init(void)
 {
<span class="p_del">-	rtnl_register(PF_INET, RTM_NEWROUTE, inet_rtm_newroute, NULL, NULL);</span>
<span class="p_del">-	rtnl_register(PF_INET, RTM_DELROUTE, inet_rtm_delroute, NULL, NULL);</span>
<span class="p_del">-	rtnl_register(PF_INET, RTM_GETROUTE, NULL, inet_dump_fib, NULL);</span>
<span class="p_add">+	fib_trie_init();</span>
 
 	register_pernet_subsys(&amp;fib_net_ops);
<span class="p_add">+</span>
 	register_netdevice_notifier(&amp;fib_netdev_notifier);
 	register_inetaddr_notifier(&amp;fib_inetaddr_notifier);
 
<span class="p_del">-	fib_trie_init();</span>
<span class="p_add">+	rtnl_register(PF_INET, RTM_NEWROUTE, inet_rtm_newroute, NULL, NULL);</span>
<span class="p_add">+	rtnl_register(PF_INET, RTM_DELROUTE, inet_rtm_delroute, NULL, NULL);</span>
<span class="p_add">+	rtnl_register(PF_INET, RTM_GETROUTE, NULL, inet_dump_fib, NULL);</span>
 }
<span class="p_header">diff --git a/net/ipv4/fib_semantics.c b/net/ipv4/fib_semantics.c</span>
<span class="p_header">index ad9ad4aab5da..ce7bc2e5175a 100644</span>
<span class="p_header">--- a/net/ipv4/fib_semantics.c</span>
<span class="p_header">+++ b/net/ipv4/fib_semantics.c</span>
<span class="p_chunk">@@ -1372,7 +1372,7 @@</span> <span class="p_context"> static int call_fib_nh_notifiers(struct fib_nh *fib_nh,</span>
 		return call_fib_notifiers(dev_net(fib_nh-&gt;nh_dev), event_type,
 					  &amp;info.info);
 	case FIB_EVENT_NH_DEL:
<span class="p_del">-		if ((IN_DEV_IGNORE_ROUTES_WITH_LINKDOWN(in_dev) &amp;&amp;</span>
<span class="p_add">+		if ((in_dev &amp;&amp; IN_DEV_IGNORE_ROUTES_WITH_LINKDOWN(in_dev) &amp;&amp;</span>
 		     fib_nh-&gt;nh_flags &amp; RTNH_F_LINKDOWN) ||
 		    (fib_nh-&gt;nh_flags &amp; RTNH_F_DEAD))
 			return call_fib_notifiers(dev_net(fib_nh-&gt;nh_dev),
<span class="p_header">diff --git a/net/ipv4/syncookies.c b/net/ipv4/syncookies.c</span>
<span class="p_header">index 0257d965f111..4a97fe20f59e 100644</span>
<span class="p_header">--- a/net/ipv4/syncookies.c</span>
<span class="p_header">+++ b/net/ipv4/syncookies.c</span>
<span class="p_chunk">@@ -332,6 +332,7 @@</span> <span class="p_context"> struct sock *cookie_v4_check(struct sock *sk, struct sk_buff *skb)</span>
 	treq-&gt;rcv_isn		= ntohl(th-&gt;seq) - 1;
 	treq-&gt;snt_isn		= cookie;
 	treq-&gt;ts_off		= 0;
<span class="p_add">+	treq-&gt;txhash		= net_tx_rndhash();</span>
 	req-&gt;mss		= mss;
 	ireq-&gt;ir_num		= ntohs(th-&gt;dest);
 	ireq-&gt;ir_rmt_port	= th-&gt;source;
<span class="p_header">diff --git a/net/ipv4/tcp_bbr.c b/net/ipv4/tcp_bbr.c</span>
<span class="p_header">index b89bce4c721e..96c95c8d981e 100644</span>
<span class="p_header">--- a/net/ipv4/tcp_bbr.c</span>
<span class="p_header">+++ b/net/ipv4/tcp_bbr.c</span>
<span class="p_chunk">@@ -113,7 +113,8 @@</span> <span class="p_context"> struct bbr {</span>
 		cwnd_gain:10,	/* current gain for setting cwnd */
 		full_bw_cnt:3,	/* number of rounds without large bw gains */
 		cycle_idx:3,	/* current index in pacing_gain cycle array */
<span class="p_del">-		unused_b:6;</span>
<span class="p_add">+		has_seen_rtt:1, /* have we seen an RTT sample yet? */</span>
<span class="p_add">+		unused_b:5;</span>
 	u32	prior_cwnd;	/* prior cwnd upon entering loss recovery */
 	u32	full_bw;	/* recent bw, to estimate if pipe is full */
 };
<span class="p_chunk">@@ -212,6 +213,35 @@</span> <span class="p_context"> static u64 bbr_rate_bytes_per_sec(struct sock *sk, u64 rate, int gain)</span>
 	return rate &gt;&gt; BW_SCALE;
 }
 
<span class="p_add">+/* Convert a BBR bw and gain factor to a pacing rate in bytes per second. */</span>
<span class="p_add">+static u32 bbr_bw_to_pacing_rate(struct sock *sk, u32 bw, int gain)</span>
<span class="p_add">+{</span>
<span class="p_add">+	u64 rate = bw;</span>
<span class="p_add">+</span>
<span class="p_add">+	rate = bbr_rate_bytes_per_sec(sk, rate, gain);</span>
<span class="p_add">+	rate = min_t(u64, rate, sk-&gt;sk_max_pacing_rate);</span>
<span class="p_add">+	return rate;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+/* Initialize pacing rate to: high_gain * init_cwnd / RTT. */</span>
<span class="p_add">+static void bbr_init_pacing_rate_from_rtt(struct sock *sk)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct tcp_sock *tp = tcp_sk(sk);</span>
<span class="p_add">+	struct bbr *bbr = inet_csk_ca(sk);</span>
<span class="p_add">+	u64 bw;</span>
<span class="p_add">+	u32 rtt_us;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (tp-&gt;srtt_us) {		/* any RTT sample yet? */</span>
<span class="p_add">+		rtt_us = max(tp-&gt;srtt_us &gt;&gt; 3, 1U);</span>
<span class="p_add">+		bbr-&gt;has_seen_rtt = 1;</span>
<span class="p_add">+	} else {			 /* no RTT sample yet */</span>
<span class="p_add">+		rtt_us = USEC_PER_MSEC;	 /* use nominal default RTT */</span>
<span class="p_add">+	}</span>
<span class="p_add">+	bw = (u64)tp-&gt;snd_cwnd * BW_UNIT;</span>
<span class="p_add">+	do_div(bw, rtt_us);</span>
<span class="p_add">+	sk-&gt;sk_pacing_rate = bbr_bw_to_pacing_rate(sk, bw, bbr_high_gain);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 /* Pace using current bw estimate and a gain factor. In order to help drive the
  * network toward lower queues while maintaining high utilization and low
  * latency, the average pacing rate aims to be slightly (~1%) lower than the
<span class="p_chunk">@@ -221,12 +251,13 @@</span> <span class="p_context"> static u64 bbr_rate_bytes_per_sec(struct sock *sk, u64 rate, int gain)</span>
  */
 static void bbr_set_pacing_rate(struct sock *sk, u32 bw, int gain)
 {
<span class="p_add">+	struct tcp_sock *tp = tcp_sk(sk);</span>
 	struct bbr *bbr = inet_csk_ca(sk);
<span class="p_del">-	u64 rate = bw;</span>
<span class="p_add">+	u32 rate = bbr_bw_to_pacing_rate(sk, bw, gain);</span>
 
<span class="p_del">-	rate = bbr_rate_bytes_per_sec(sk, rate, gain);</span>
<span class="p_del">-	rate = min_t(u64, rate, sk-&gt;sk_max_pacing_rate);</span>
<span class="p_del">-	if (bbr-&gt;mode != BBR_STARTUP || rate &gt; sk-&gt;sk_pacing_rate)</span>
<span class="p_add">+	if (unlikely(!bbr-&gt;has_seen_rtt &amp;&amp; tp-&gt;srtt_us))</span>
<span class="p_add">+		bbr_init_pacing_rate_from_rtt(sk);</span>
<span class="p_add">+	if (bbr_full_bw_reached(sk) || rate &gt; sk-&gt;sk_pacing_rate)</span>
 		sk-&gt;sk_pacing_rate = rate;
 }
 
<span class="p_chunk">@@ -799,7 +830,6 @@</span> <span class="p_context"> static void bbr_init(struct sock *sk)</span>
 {
 	struct tcp_sock *tp = tcp_sk(sk);
 	struct bbr *bbr = inet_csk_ca(sk);
<span class="p_del">-	u64 bw;</span>
 
 	bbr-&gt;prior_cwnd = 0;
 	bbr-&gt;tso_segs_goal = 0;	 /* default segs per skb until first ACK */
<span class="p_chunk">@@ -815,11 +845,8 @@</span> <span class="p_context"> static void bbr_init(struct sock *sk)</span>
 
 	minmax_reset(&amp;bbr-&gt;bw, bbr-&gt;rtt_cnt, 0);  /* init max bw to 0 */
 
<span class="p_del">-	/* Initialize pacing rate to: high_gain * init_cwnd / RTT. */</span>
<span class="p_del">-	bw = (u64)tp-&gt;snd_cwnd * BW_UNIT;</span>
<span class="p_del">-	do_div(bw, (tp-&gt;srtt_us &gt;&gt; 3) ? : USEC_PER_MSEC);</span>
<span class="p_del">-	sk-&gt;sk_pacing_rate = 0;		/* force an update of sk_pacing_rate */</span>
<span class="p_del">-	bbr_set_pacing_rate(sk, bw, bbr_high_gain);</span>
<span class="p_add">+	bbr-&gt;has_seen_rtt = 0;</span>
<span class="p_add">+	bbr_init_pacing_rate_from_rtt(sk);</span>
 
 	bbr-&gt;restore_cwnd = 0;
 	bbr-&gt;round_start = 0;
<span class="p_header">diff --git a/net/ipv4/udp.c b/net/ipv4/udp.c</span>
<span class="p_header">index 1d6219bf2d6b..b9a84eba60b8 100644</span>
<span class="p_header">--- a/net/ipv4/udp.c</span>
<span class="p_header">+++ b/net/ipv4/udp.c</span>
<span class="p_chunk">@@ -1762,7 +1762,7 @@</span> <span class="p_context"> static int udp_queue_rcv_skb(struct sock *sk, struct sk_buff *skb)</span>
 /* For TCP sockets, sk_rx_dst is protected by socket lock
  * For UDP, we use xchg() to guard against concurrent changes.
  */
<span class="p_del">-static void udp_sk_rx_dst_set(struct sock *sk, struct dst_entry *dst)</span>
<span class="p_add">+void udp_sk_rx_dst_set(struct sock *sk, struct dst_entry *dst)</span>
 {
 	struct dst_entry *old;
 
<span class="p_chunk">@@ -2120,6 +2120,7 @@</span> <span class="p_context"> void udp_destroy_sock(struct sock *sk)</span>
 			encap_destroy(sk);
 	}
 }
<span class="p_add">+EXPORT_SYMBOL(udp_sk_rx_dst_set);</span>
 
 /*
  *	Socket option code for UDP
<span class="p_header">diff --git a/net/ipv6/ip6_output.c b/net/ipv6/ip6_output.c</span>
<span class="p_header">index 1699acb2fa2c..be0306778938 100644</span>
<span class="p_header">--- a/net/ipv6/ip6_output.c</span>
<span class="p_header">+++ b/net/ipv6/ip6_output.c</span>
<span class="p_chunk">@@ -673,8 +673,6 @@</span> <span class="p_context"> int ip6_fragment(struct net *net, struct sock *sk, struct sk_buff *skb,</span>
 		*prevhdr = NEXTHDR_FRAGMENT;
 		tmp_hdr = kmemdup(skb_network_header(skb), hlen, GFP_ATOMIC);
 		if (!tmp_hdr) {
<span class="p_del">-			IP6_INC_STATS(net, ip6_dst_idev(skb_dst(skb)),</span>
<span class="p_del">-				      IPSTATS_MIB_FRAGFAILS);</span>
 			err = -ENOMEM;
 			goto fail;
 		}
<span class="p_chunk">@@ -793,8 +791,6 @@</span> <span class="p_context"> int ip6_fragment(struct net *net, struct sock *sk, struct sk_buff *skb,</span>
 		frag = alloc_skb(len + hlen + sizeof(struct frag_hdr) +
 				 hroom + troom, GFP_ATOMIC);
 		if (!frag) {
<span class="p_del">-			IP6_INC_STATS(net, ip6_dst_idev(skb_dst(skb)),</span>
<span class="p_del">-				      IPSTATS_MIB_FRAGFAILS);</span>
 			err = -ENOMEM;
 			goto fail;
 		}
<span class="p_header">diff --git a/net/ipv6/output_core.c b/net/ipv6/output_core.c</span>
<span class="p_header">index e9065b8d3af8..abb2c307fbe8 100644</span>
<span class="p_header">--- a/net/ipv6/output_core.c</span>
<span class="p_header">+++ b/net/ipv6/output_core.c</span>
<span class="p_chunk">@@ -78,7 +78,7 @@</span> <span class="p_context"> EXPORT_SYMBOL(ipv6_select_ident);</span>
 
 int ip6_find_1stfragopt(struct sk_buff *skb, u8 **nexthdr)
 {
<span class="p_del">-	u16 offset = sizeof(struct ipv6hdr);</span>
<span class="p_add">+	unsigned int offset = sizeof(struct ipv6hdr);</span>
 	unsigned int packet_len = skb_tail_pointer(skb) -
 		skb_network_header(skb);
 	int found_rhdr = 0;
<span class="p_chunk">@@ -86,6 +86,7 @@</span> <span class="p_context"> int ip6_find_1stfragopt(struct sk_buff *skb, u8 **nexthdr)</span>
 
 	while (offset &lt;= packet_len) {
 		struct ipv6_opt_hdr *exthdr;
<span class="p_add">+		unsigned int len;</span>
 
 		switch (**nexthdr) {
 
<span class="p_chunk">@@ -111,7 +112,10 @@</span> <span class="p_context"> int ip6_find_1stfragopt(struct sk_buff *skb, u8 **nexthdr)</span>
 
 		exthdr = (struct ipv6_opt_hdr *)(skb_network_header(skb) +
 						 offset);
<span class="p_del">-		offset += ipv6_optlen(exthdr);</span>
<span class="p_add">+		len = ipv6_optlen(exthdr);</span>
<span class="p_add">+		if (len + offset &gt;= IPV6_MAXPLEN)</span>
<span class="p_add">+			return -EINVAL;</span>
<span class="p_add">+		offset += len;</span>
 		*nexthdr = &amp;exthdr-&gt;nexthdr;
 	}
 
<span class="p_header">diff --git a/net/ipv6/syncookies.c b/net/ipv6/syncookies.c</span>
<span class="p_header">index 5abc3692b901..ca7895454cec 100644</span>
<span class="p_header">--- a/net/ipv6/syncookies.c</span>
<span class="p_header">+++ b/net/ipv6/syncookies.c</span>
<span class="p_chunk">@@ -215,6 +215,7 @@</span> <span class="p_context"> struct sock *cookie_v6_check(struct sock *sk, struct sk_buff *skb)</span>
 	treq-&gt;rcv_isn = ntohl(th-&gt;seq) - 1;
 	treq-&gt;snt_isn = cookie;
 	treq-&gt;ts_off = 0;
<span class="p_add">+	treq-&gt;txhash = net_tx_rndhash();</span>
 
 	/*
 	 * We need to lookup the dst_entry to get the correct window size.
<span class="p_header">diff --git a/net/ipv6/udp.c b/net/ipv6/udp.c</span>
<span class="p_header">index 75703fda23e7..592270c310f4 100644</span>
<span class="p_header">--- a/net/ipv6/udp.c</span>
<span class="p_header">+++ b/net/ipv6/udp.c</span>
<span class="p_chunk">@@ -291,11 +291,7 @@</span> <span class="p_context"> static struct sock *__udp6_lib_lookup_skb(struct sk_buff *skb,</span>
 					  struct udp_table *udptable)
 {
 	const struct ipv6hdr *iph = ipv6_hdr(skb);
<span class="p_del">-	struct sock *sk;</span>
 
<span class="p_del">-	sk = skb_steal_sock(skb);</span>
<span class="p_del">-	if (unlikely(sk))</span>
<span class="p_del">-		return sk;</span>
 	return __udp6_lib_lookup(dev_net(skb-&gt;dev), &amp;iph-&gt;saddr, sport,
 				 &amp;iph-&gt;daddr, dport, inet6_iif(skb),
 				 udptable, skb);
<span class="p_chunk">@@ -798,6 +794,24 @@</span> <span class="p_context"> int __udp6_lib_rcv(struct sk_buff *skb, struct udp_table *udptable,</span>
 	if (udp6_csum_init(skb, uh, proto))
 		goto csum_error;
 
<span class="p_add">+	/* Check if the socket is already available, e.g. due to early demux */</span>
<span class="p_add">+	sk = skb_steal_sock(skb);</span>
<span class="p_add">+	if (sk) {</span>
<span class="p_add">+		struct dst_entry *dst = skb_dst(skb);</span>
<span class="p_add">+		int ret;</span>
<span class="p_add">+</span>
<span class="p_add">+		if (unlikely(sk-&gt;sk_rx_dst != dst))</span>
<span class="p_add">+			udp_sk_rx_dst_set(sk, dst);</span>
<span class="p_add">+</span>
<span class="p_add">+		ret = udpv6_queue_rcv_skb(sk, skb);</span>
<span class="p_add">+		sock_put(sk);</span>
<span class="p_add">+</span>
<span class="p_add">+		/* a return value &gt; 0 means to resubmit the input */</span>
<span class="p_add">+		if (ret &gt; 0)</span>
<span class="p_add">+			return ret;</span>
<span class="p_add">+		return 0;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
 	/*
 	 *	Multicast receive code
 	 */
<span class="p_chunk">@@ -806,11 +820,6 @@</span> <span class="p_context"> int __udp6_lib_rcv(struct sk_buff *skb, struct udp_table *udptable,</span>
 				saddr, daddr, udptable, proto);
 
 	/* Unicast */
<span class="p_del">-</span>
<span class="p_del">-	/*</span>
<span class="p_del">-	 * check socket cache ... must talk to Alan about his plans</span>
<span class="p_del">-	 * for sock caches... i&#39;ll skip this for now.</span>
<span class="p_del">-	 */</span>
 	sk = __udp6_lib_lookup_skb(skb, uh-&gt;source, uh-&gt;dest, udptable);
 	if (sk) {
 		int ret;
<span class="p_header">diff --git a/net/openvswitch/conntrack.c b/net/openvswitch/conntrack.c</span>
<span class="p_header">index 08679ebb3068..b3bf66bbf4dc 100644</span>
<span class="p_header">--- a/net/openvswitch/conntrack.c</span>
<span class="p_header">+++ b/net/openvswitch/conntrack.c</span>
<span class="p_chunk">@@ -1289,8 +1289,8 @@</span> <span class="p_context"> static int parse_ct(const struct nlattr *attr, struct ovs_conntrack_info *info,</span>
 
 	nla_for_each_nested(a, attr, rem) {
 		int type = nla_type(a);
<span class="p_del">-		int maxlen = ovs_ct_attr_lens[type].maxlen;</span>
<span class="p_del">-		int minlen = ovs_ct_attr_lens[type].minlen;</span>
<span class="p_add">+		int maxlen;</span>
<span class="p_add">+		int minlen;</span>
 
 		if (type &gt; OVS_CT_ATTR_MAX) {
 			OVS_NLERR(log,
<span class="p_chunk">@@ -1298,6 +1298,9 @@</span> <span class="p_context"> static int parse_ct(const struct nlattr *attr, struct ovs_conntrack_info *info,</span>
 				  type, OVS_CT_ATTR_MAX);
 			return -EINVAL;
 		}
<span class="p_add">+</span>
<span class="p_add">+		maxlen = ovs_ct_attr_lens[type].maxlen;</span>
<span class="p_add">+		minlen = ovs_ct_attr_lens[type].minlen;</span>
 		if (nla_len(a) &lt; minlen || nla_len(a) &gt; maxlen) {
 			OVS_NLERR(log,
 				  &quot;Conntrack attr type has unexpected length (type=%d, length=%d, expected=%d)&quot;,
<span class="p_header">diff --git a/net/packet/af_packet.c b/net/packet/af_packet.c</span>
<span class="p_header">index e3eeed19cc7a..0880e0a9d151 100644</span>
<span class="p_header">--- a/net/packet/af_packet.c</span>
<span class="p_header">+++ b/net/packet/af_packet.c</span>
<span class="p_chunk">@@ -4334,7 +4334,7 @@</span> <span class="p_context"> static int packet_set_ring(struct sock *sk, union tpacket_req_u *req_u,</span>
 		register_prot_hook(sk);
 	}
 	spin_unlock(&amp;po-&gt;bind_lock);
<span class="p_del">-	if (closing &amp;&amp; (po-&gt;tp_version &gt; TPACKET_V2)) {</span>
<span class="p_add">+	if (pg_vec &amp;&amp; (po-&gt;tp_version &gt; TPACKET_V2)) {</span>
 		/* Because we don&#39;t support block-based V3 on tx-ring */
 		if (!tx_ring)
 			prb_shutdown_retire_blk_timer(po, rb_queue);
<span class="p_header">diff --git a/net/sctp/sm_make_chunk.c b/net/sctp/sm_make_chunk.c</span>
<span class="p_header">index 92e332e17391..961a6f81ae64 100644</span>
<span class="p_header">--- a/net/sctp/sm_make_chunk.c</span>
<span class="p_header">+++ b/net/sctp/sm_make_chunk.c</span>
<span class="p_chunk">@@ -228,7 +228,7 @@</span> <span class="p_context"> struct sctp_chunk *sctp_make_init(const struct sctp_association *asoc,</span>
 	sctp_adaptation_ind_param_t aiparam;
 	sctp_supported_ext_param_t ext_param;
 	int num_ext = 0;
<span class="p_del">-	__u8 extensions[3];</span>
<span class="p_add">+	__u8 extensions[4];</span>
 	sctp_paramhdr_t *auth_chunks = NULL,
 			*auth_hmacs = NULL;
 
<span class="p_chunk">@@ -396,7 +396,7 @@</span> <span class="p_context"> struct sctp_chunk *sctp_make_init_ack(const struct sctp_association *asoc,</span>
 	sctp_adaptation_ind_param_t aiparam;
 	sctp_supported_ext_param_t ext_param;
 	int num_ext = 0;
<span class="p_del">-	__u8 extensions[3];</span>
<span class="p_add">+	__u8 extensions[4];</span>
 	sctp_paramhdr_t *auth_chunks = NULL,
 			*auth_hmacs = NULL,
 			*auth_random = NULL;
<span class="p_header">diff --git a/sound/pci/hda/patch_realtek.c b/sound/pci/hda/patch_realtek.c</span>
<span class="p_header">index a808332d02d0..606d5333ff98 100644</span>
<span class="p_header">--- a/sound/pci/hda/patch_realtek.c</span>
<span class="p_header">+++ b/sound/pci/hda/patch_realtek.c</span>
<span class="p_chunk">@@ -2296,6 +2296,7 @@</span> <span class="p_context"> static const struct snd_pci_quirk alc882_fixup_tbl[] = {</span>
 	SND_PCI_QUIRK(0x1043, 0x8691, &quot;ASUS ROG Ranger VIII&quot;, ALC882_FIXUP_GPIO3),
 	SND_PCI_QUIRK(0x104d, 0x9047, &quot;Sony Vaio TT&quot;, ALC889_FIXUP_VAIO_TT),
 	SND_PCI_QUIRK(0x104d, 0x905a, &quot;Sony Vaio Z&quot;, ALC882_FIXUP_NO_PRIMARY_HP),
<span class="p_add">+	SND_PCI_QUIRK(0x104d, 0x9060, &quot;Sony Vaio VPCL14M1R&quot;, ALC882_FIXUP_NO_PRIMARY_HP),</span>
 	SND_PCI_QUIRK(0x104d, 0x9043, &quot;Sony Vaio VGC-LN51JGB&quot;, ALC882_FIXUP_NO_PRIMARY_HP),
 	SND_PCI_QUIRK(0x104d, 0x9044, &quot;Sony VAIO AiO&quot;, ALC882_FIXUP_NO_PRIMARY_HP),
 
<span class="p_header">diff --git a/sound/soc/soc-core.c b/sound/soc/soc-core.c</span>
<span class="p_header">index 754e3ef8d7ae..d05acc8eed1f 100644</span>
<span class="p_header">--- a/sound/soc/soc-core.c</span>
<span class="p_header">+++ b/sound/soc/soc-core.c</span>
<span class="p_chunk">@@ -3139,8 +3139,6 @@</span> <span class="p_context"> static int snd_soc_component_initialize(struct snd_soc_component *component,</span>
 	component-&gt;remove = component-&gt;driver-&gt;remove;
 	component-&gt;suspend = component-&gt;driver-&gt;suspend;
 	component-&gt;resume = component-&gt;driver-&gt;resume;
<span class="p_del">-	component-&gt;pcm_new = component-&gt;driver-&gt;pcm_new;</span>
<span class="p_del">-	component-&gt;pcm_free = component-&gt;driver-&gt;pcm_free;</span>
 
 	dapm = &amp;component-&gt;dapm;
 	dapm-&gt;dev = dev;
<span class="p_chunk">@@ -3328,25 +3326,6 @@</span> <span class="p_context"> static void snd_soc_platform_drv_remove(struct snd_soc_component *component)</span>
 	platform-&gt;driver-&gt;remove(platform);
 }
 
<span class="p_del">-static int snd_soc_platform_drv_pcm_new(struct snd_soc_pcm_runtime *rtd)</span>
<span class="p_del">-{</span>
<span class="p_del">-	struct snd_soc_platform *platform = rtd-&gt;platform;</span>
<span class="p_del">-</span>
<span class="p_del">-	if (platform-&gt;driver-&gt;pcm_new)</span>
<span class="p_del">-		return platform-&gt;driver-&gt;pcm_new(rtd);</span>
<span class="p_del">-	else</span>
<span class="p_del">-		return 0;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-static void snd_soc_platform_drv_pcm_free(struct snd_pcm *pcm)</span>
<span class="p_del">-{</span>
<span class="p_del">-	struct snd_soc_pcm_runtime *rtd = pcm-&gt;private_data;</span>
<span class="p_del">-	struct snd_soc_platform *platform = rtd-&gt;platform;</span>
<span class="p_del">-</span>
<span class="p_del">-	if (platform-&gt;driver-&gt;pcm_free)</span>
<span class="p_del">-		platform-&gt;driver-&gt;pcm_free(pcm);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
 /**
  * snd_soc_add_platform - Add a platform to the ASoC core
  * @dev: The parent device for the platform
<span class="p_chunk">@@ -3370,10 +3349,6 @@</span> <span class="p_context"> int snd_soc_add_platform(struct device *dev, struct snd_soc_platform *platform,</span>
 		platform-&gt;component.probe = snd_soc_platform_drv_probe;
 	if (platform_drv-&gt;remove)
 		platform-&gt;component.remove = snd_soc_platform_drv_remove;
<span class="p_del">-	if (platform_drv-&gt;pcm_new)</span>
<span class="p_del">-		platform-&gt;component.pcm_new = snd_soc_platform_drv_pcm_new;</span>
<span class="p_del">-	if (platform_drv-&gt;pcm_free)</span>
<span class="p_del">-		platform-&gt;component.pcm_free = snd_soc_platform_drv_pcm_free;</span>
 
 #ifdef CONFIG_DEBUG_FS
 	platform-&gt;component.debugfs_prefix = &quot;platform&quot;;
<span class="p_header">diff --git a/sound/soc/soc-pcm.c b/sound/soc/soc-pcm.c</span>
<span class="p_header">index efc5831f205d..8ff7cd3b8c1f 100644</span>
<span class="p_header">--- a/sound/soc/soc-pcm.c</span>
<span class="p_header">+++ b/sound/soc/soc-pcm.c</span>
<span class="p_chunk">@@ -181,6 +181,10 @@</span> <span class="p_context"> int dpcm_dapm_stream_event(struct snd_soc_pcm_runtime *fe, int dir,</span>
 		dev_dbg(be-&gt;dev, &quot;ASoC: BE %s event %d dir %d\n&quot;,
 				be-&gt;dai_link-&gt;name, event, dir);
 
<span class="p_add">+		if ((event == SND_SOC_DAPM_STREAM_STOP) &amp;&amp;</span>
<span class="p_add">+		    (be-&gt;dpcm[dir].users &gt;= 1))</span>
<span class="p_add">+			continue;</span>
<span class="p_add">+</span>
 		snd_soc_dapm_stream_event(be, dir, event);
 	}
 
<span class="p_chunk">@@ -2628,25 +2632,12 @@</span> <span class="p_context"> static int dpcm_fe_dai_close(struct snd_pcm_substream *fe_substream)</span>
 	return ret;
 }
 
<span class="p_del">-static void soc_pcm_free(struct snd_pcm *pcm)</span>
<span class="p_del">-{</span>
<span class="p_del">-	struct snd_soc_pcm_runtime *rtd = pcm-&gt;private_data;</span>
<span class="p_del">-	struct snd_soc_component *component;</span>
<span class="p_del">-</span>
<span class="p_del">-	list_for_each_entry(component, &amp;rtd-&gt;card-&gt;component_dev_list,</span>
<span class="p_del">-			    card_list) {</span>
<span class="p_del">-		if (component-&gt;pcm_free)</span>
<span class="p_del">-			component-&gt;pcm_free(pcm);</span>
<span class="p_del">-	}</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
 /* create a new pcm */
 int soc_new_pcm(struct snd_soc_pcm_runtime *rtd, int num)
 {
 	struct snd_soc_platform *platform = rtd-&gt;platform;
 	struct snd_soc_dai *codec_dai;
 	struct snd_soc_dai *cpu_dai = rtd-&gt;cpu_dai;
<span class="p_del">-	struct snd_soc_component *component;</span>
 	struct snd_pcm *pcm;
 	char new_name[64];
 	int ret = 0, playback = 0, capture = 0;
<span class="p_chunk">@@ -2755,18 +2746,17 @@</span> <span class="p_context"> int soc_new_pcm(struct snd_soc_pcm_runtime *rtd, int num)</span>
 	if (capture)
 		snd_pcm_set_ops(pcm, SNDRV_PCM_STREAM_CAPTURE, &amp;rtd-&gt;ops);
 
<span class="p_del">-	list_for_each_entry(component, &amp;rtd-&gt;card-&gt;component_dev_list, card_list) {</span>
<span class="p_del">-		if (component-&gt;pcm_new) {</span>
<span class="p_del">-			ret = component-&gt;pcm_new(rtd);</span>
<span class="p_del">-			if (ret &lt; 0) {</span>
<span class="p_del">-				dev_err(component-&gt;dev,</span>
<span class="p_del">-					&quot;ASoC: pcm constructor failed: %d\n&quot;,</span>
<span class="p_del">-					ret);</span>
<span class="p_del">-				return ret;</span>
<span class="p_del">-			}</span>
<span class="p_add">+	if (platform-&gt;driver-&gt;pcm_new) {</span>
<span class="p_add">+		ret = platform-&gt;driver-&gt;pcm_new(rtd);</span>
<span class="p_add">+		if (ret &lt; 0) {</span>
<span class="p_add">+			dev_err(platform-&gt;dev,</span>
<span class="p_add">+				&quot;ASoC: pcm constructor failed: %d\n&quot;,</span>
<span class="p_add">+				ret);</span>
<span class="p_add">+			return ret;</span>
 		}
 	}
<span class="p_del">-	pcm-&gt;private_free = soc_pcm_free;</span>
<span class="p_add">+</span>
<span class="p_add">+	pcm-&gt;private_free = platform-&gt;driver-&gt;pcm_free;</span>
 out:
 	dev_info(rtd-&gt;card-&gt;dev, &quot;%s &lt;-&gt; %s mapping ok\n&quot;,
 		 (rtd-&gt;num_codecs &gt; 1) ? &quot;multicodec&quot; : rtd-&gt;codec_dai-&gt;name,
<span class="p_header">diff --git a/sound/soc/ux500/mop500.c b/sound/soc/ux500/mop500.c</span>
<span class="p_header">index b50f68a439ce..ba9fc099cf67 100644</span>
<span class="p_header">--- a/sound/soc/ux500/mop500.c</span>
<span class="p_header">+++ b/sound/soc/ux500/mop500.c</span>
<span class="p_chunk">@@ -33,6 +33,7 @@</span> <span class="p_context"> static struct snd_soc_dai_link mop500_dai_links[] = {</span>
 		.stream_name = &quot;ab8500_0&quot;,
 		.cpu_dai_name = &quot;ux500-msp-i2s.1&quot;,
 		.codec_dai_name = &quot;ab8500-codec-dai.0&quot;,
<span class="p_add">+		.platform_name = &quot;ux500-msp-i2s.1&quot;,</span>
 		.codec_name = &quot;ab8500-codec.0&quot;,
 		.init = mop500_ab8500_machine_init,
 		.ops = mop500_ab8500_ops,
<span class="p_chunk">@@ -42,6 +43,7 @@</span> <span class="p_context"> static struct snd_soc_dai_link mop500_dai_links[] = {</span>
 		.stream_name = &quot;ab8500_1&quot;,
 		.cpu_dai_name = &quot;ux500-msp-i2s.3&quot;,
 		.codec_dai_name = &quot;ab8500-codec-dai.1&quot;,
<span class="p_add">+		.platform_name = &quot;ux500-msp-i2s.3&quot;,</span>
 		.codec_name = &quot;ab8500-codec.0&quot;,
 		.init = NULL,
 		.ops = mop500_ab8500_ops,
<span class="p_chunk">@@ -85,6 +87,8 @@</span> <span class="p_context"> static int mop500_of_probe(struct platform_device *pdev,</span>
 	for (i = 0; i &lt; 2; i++) {
 		mop500_dai_links[i].cpu_of_node = msp_np[i];
 		mop500_dai_links[i].cpu_dai_name = NULL;
<span class="p_add">+		mop500_dai_links[i].platform_of_node = msp_np[i];</span>
<span class="p_add">+		mop500_dai_links[i].platform_name = NULL;</span>
 		mop500_dai_links[i].codec_of_node = codec_np;
 		mop500_dai_links[i].codec_name = NULL;
 	}
<span class="p_header">diff --git a/virt/kvm/arm/mmu.c b/virt/kvm/arm/mmu.c</span>
<span class="p_header">index e2e5effba2a9..db1c7b25a44c 100644</span>
<span class="p_header">--- a/virt/kvm/arm/mmu.c</span>
<span class="p_header">+++ b/virt/kvm/arm/mmu.c</span>
<span class="p_chunk">@@ -1665,12 +1665,16 @@</span> <span class="p_context"> static int kvm_test_age_hva_handler(struct kvm *kvm, gpa_t gpa, u64 size, void *</span>
 
 int kvm_age_hva(struct kvm *kvm, unsigned long start, unsigned long end)
 {
<span class="p_add">+	if (!kvm-&gt;arch.pgd)</span>
<span class="p_add">+		return 0;</span>
 	trace_kvm_age_hva(start, end);
 	return handle_hva_to_gpa(kvm, start, end, kvm_age_hva_handler, NULL);
 }
 
 int kvm_test_age_hva(struct kvm *kvm, unsigned long hva)
 {
<span class="p_add">+	if (!kvm-&gt;arch.pgd)</span>
<span class="p_add">+		return 0;</span>
 	trace_kvm_test_age_hva(hva);
 	return handle_hva_to_gpa(kvm, hva, hva, kvm_test_age_hva_handler, NULL);
 }

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



