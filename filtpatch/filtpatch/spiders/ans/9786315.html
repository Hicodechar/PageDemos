
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>Linux 4.4.72 - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    Linux 4.4.72</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=37061">gregkh@linuxfoundation.org</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>June 14, 2017, 1:45 p.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;20170614134555.GB17414@kroah.com&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/9786315/mbox/"
   >mbox</a>
|
   <a href="/patch/9786315/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/9786315/">/patch/9786315/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
	[172.30.200.125])
	by pdx-korg-patchwork.web.codeaurora.org (Postfix) with ESMTP id
	2AFC860384 for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Wed, 14 Jun 2017 13:46:39 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 0903526224
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Wed, 14 Jun 2017 13:46:39 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id F151E283A6; Wed, 14 Jun 2017 13:46:38 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-6.9 required=2.0 tests=BAYES_00,RCVD_IN_DNSWL_HI
	autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id A596F26224
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Wed, 14 Jun 2017 13:46:33 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1752098AbdFNNqT (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Wed, 14 Jun 2017 09:46:19 -0400
Received: from mail.linuxfoundation.org ([140.211.169.12]:56144 &quot;EHLO
	mail.linuxfoundation.org&quot; rhost-flags-OK-OK-OK-OK) by vger.kernel.org
	with ESMTP id S1751707AbdFNNqP (ORCPT
	&lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Wed, 14 Jun 2017 09:46:15 -0400
Received: from localhost (LFbn-1-12060-104.w90-92.abo.wanadoo.fr
	[90.92.122.104])
	by mail.linuxfoundation.org (Postfix) with ESMTPSA id 28A91B5A;
	Wed, 14 Jun 2017 13:46:02 +0000 (UTC)
Date: Wed, 14 Jun 2017 15:45:55 +0200
From: Greg KH &lt;gregkh@linuxfoundation.org&gt;
To: linux-kernel@vger.kernel.org, Andrew Morton &lt;akpm@linux-foundation.org&gt;,
	torvalds@linux-foundation.org, stable@vger.kernel.org
Cc: lwn@lwn.net, Jiri Slaby &lt;jslaby@suse.cz&gt;
Subject: Re: Linux 4.4.72
Message-ID: &lt;20170614134555.GB17414@kroah.com&gt;
References: &lt;20170614134550.GA17414@kroah.com&gt;
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Disposition: inline
In-Reply-To: &lt;20170614134550.GA17414@kroah.com&gt;
User-Agent: Mutt/1.8.3 (2017-05-23)
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=37061">gregkh@linuxfoundation.org</a> - June 14, 2017, 1:45 p.m.</div>
<pre class="content">

</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/Makefile b/Makefile</span>
<span class="p_header">index ad91a79aed51..94d663c935c0 100644</span>
<span class="p_header">--- a/Makefile</span>
<span class="p_header">+++ b/Makefile</span>
<span class="p_chunk">@@ -1,6 +1,6 @@</span> <span class="p_context"></span>
 VERSION = 4
 PATCHLEVEL = 4
<span class="p_del">-SUBLEVEL = 71</span>
<span class="p_add">+SUBLEVEL = 72</span>
 EXTRAVERSION =
 NAME = Blurry Fish Butt
 
<span class="p_header">diff --git a/arch/arm/kvm/init.S b/arch/arm/kvm/init.S</span>
<span class="p_header">index 3988e72d16ff..bfc5aae0c280 100644</span>
<span class="p_header">--- a/arch/arm/kvm/init.S</span>
<span class="p_header">+++ b/arch/arm/kvm/init.S</span>
<span class="p_chunk">@@ -110,7 +110,6 @@</span> <span class="p_context"> __do_hyp_init:</span>
 	@  - Write permission implies XN: disabled
 	@  - Instruction cache: enabled
 	@  - Data/Unified cache: enabled
<span class="p_del">-	@  - Memory alignment checks: enabled</span>
 	@  - MMU: enabled (this code must be run from an identity mapping)
 	mrc	p15, 4, r0, c1, c0, 0	@ HSCR
 	ldr	r2, =HSCTLR_MASK
<span class="p_chunk">@@ -118,8 +117,8 @@</span> <span class="p_context"> __do_hyp_init:</span>
 	mrc	p15, 0, r1, c1, c0, 0	@ SCTLR
 	ldr	r2, =(HSCTLR_EE | HSCTLR_FI | HSCTLR_I | HSCTLR_C)
 	and	r1, r1, r2
<span class="p_del">- ARM(	ldr	r2, =(HSCTLR_M | HSCTLR_A)			)</span>
<span class="p_del">- THUMB(	ldr	r2, =(HSCTLR_M | HSCTLR_A | HSCTLR_TE)		)</span>
<span class="p_add">+ ARM(	ldr	r2, =(HSCTLR_M)					)</span>
<span class="p_add">+ THUMB(	ldr	r2, =(HSCTLR_M | HSCTLR_TE)			)</span>
 	orr	r1, r1, r2
 	orr	r0, r0, r1
 	isb
<span class="p_header">diff --git a/arch/arm/kvm/mmu.c b/arch/arm/kvm/mmu.c</span>
<span class="p_header">index 01cf10556081..1f1ff7e7b9cf 100644</span>
<span class="p_header">--- a/arch/arm/kvm/mmu.c</span>
<span class="p_header">+++ b/arch/arm/kvm/mmu.c</span>
<span class="p_chunk">@@ -869,6 +869,9 @@</span> <span class="p_context"> static pmd_t *stage2_get_pmd(struct kvm *kvm, struct kvm_mmu_memory_cache *cache</span>
 	pmd_t *pmd;
 
 	pud = stage2_get_pud(kvm, cache, addr);
<span class="p_add">+	if (!pud)</span>
<span class="p_add">+		return NULL;</span>
<span class="p_add">+</span>
 	if (pud_none(*pud)) {
 		if (!cache)
 			return NULL;
<span class="p_header">diff --git a/arch/arm64/include/asm/asm-uaccess.h b/arch/arm64/include/asm/asm-uaccess.h</span>
new file mode 100644
<span class="p_header">index 000000000000..be2d2347d995</span>
<span class="p_header">--- /dev/null</span>
<span class="p_header">+++ b/arch/arm64/include/asm/asm-uaccess.h</span>
<span class="p_chunk">@@ -0,0 +1,13 @@</span> <span class="p_context"></span>
<span class="p_add">+#ifndef __ASM_ASM_UACCESS_H</span>
<span class="p_add">+#define __ASM_ASM_UACCESS_H</span>
<span class="p_add">+</span>
<span class="p_add">+/*</span>
<span class="p_add">+ * Remove the address tag from a virtual address, if present.</span>
<span class="p_add">+ */</span>
<span class="p_add">+	.macro	clear_address_tag, dst, addr</span>
<span class="p_add">+	tst	\addr, #(1 &lt;&lt; 55)</span>
<span class="p_add">+	bic	\dst, \addr, #(0xff &lt;&lt; 56)</span>
<span class="p_add">+	csel	\dst, \dst, \addr, eq</span>
<span class="p_add">+	.endm</span>
<span class="p_add">+</span>
<span class="p_add">+#endif</span>
<span class="p_header">diff --git a/arch/arm64/include/asm/barrier.h b/arch/arm64/include/asm/barrier.h</span>
<span class="p_header">index 9622eb48f894..f2d2c0bbe21b 100644</span>
<span class="p_header">--- a/arch/arm64/include/asm/barrier.h</span>
<span class="p_header">+++ b/arch/arm64/include/asm/barrier.h</span>
<span class="p_chunk">@@ -41,23 +41,33 @@</span> <span class="p_context"></span>
 
 #define smp_store_release(p, v)						\
 do {									\
<span class="p_add">+	union { typeof(*p) __val; char __c[1]; } __u =			\</span>
<span class="p_add">+		{ .__val = (__force typeof(*p)) (v) }; 			\</span>
 	compiletime_assert_atomic_type(*p);				\
 	switch (sizeof(*p)) {						\
 	case 1:								\
 		asm volatile (&quot;stlrb %w1, %0&quot;				\
<span class="p_del">-				: &quot;=Q&quot; (*p) : &quot;r&quot; (v) : &quot;memory&quot;);	\</span>
<span class="p_add">+				: &quot;=Q&quot; (*p)				\</span>
<span class="p_add">+				: &quot;r&quot; (*(__u8 *)__u.__c)		\</span>
<span class="p_add">+				: &quot;memory&quot;);				\</span>
 		break;							\
 	case 2:								\
 		asm volatile (&quot;stlrh %w1, %0&quot;				\
<span class="p_del">-				: &quot;=Q&quot; (*p) : &quot;r&quot; (v) : &quot;memory&quot;);	\</span>
<span class="p_add">+				: &quot;=Q&quot; (*p)				\</span>
<span class="p_add">+				: &quot;r&quot; (*(__u16 *)__u.__c)		\</span>
<span class="p_add">+				: &quot;memory&quot;);				\</span>
 		break;							\
 	case 4:								\
 		asm volatile (&quot;stlr %w1, %0&quot;				\
<span class="p_del">-				: &quot;=Q&quot; (*p) : &quot;r&quot; (v) : &quot;memory&quot;);	\</span>
<span class="p_add">+				: &quot;=Q&quot; (*p)				\</span>
<span class="p_add">+				: &quot;r&quot; (*(__u32 *)__u.__c)		\</span>
<span class="p_add">+				: &quot;memory&quot;);				\</span>
 		break;							\
 	case 8:								\
 		asm volatile (&quot;stlr %1, %0&quot;				\
<span class="p_del">-				: &quot;=Q&quot; (*p) : &quot;r&quot; (v) : &quot;memory&quot;);	\</span>
<span class="p_add">+				: &quot;=Q&quot; (*p)				\</span>
<span class="p_add">+				: &quot;r&quot; (*(__u64 *)__u.__c)		\</span>
<span class="p_add">+				: &quot;memory&quot;);				\</span>
 		break;							\
 	}								\
 } while (0)
<span class="p_header">diff --git a/arch/arm64/include/asm/uaccess.h b/arch/arm64/include/asm/uaccess.h</span>
<span class="p_header">index d9ca1f2c0ea8..829fa6d3e561 100644</span>
<span class="p_header">--- a/arch/arm64/include/asm/uaccess.h</span>
<span class="p_header">+++ b/arch/arm64/include/asm/uaccess.h</span>
<span class="p_chunk">@@ -21,6 +21,7 @@</span> <span class="p_context"></span>
 /*
  * User space memory access functions
  */
<span class="p_add">+#include &lt;linux/bitops.h&gt;</span>
 #include &lt;linux/string.h&gt;
 #include &lt;linux/thread_info.h&gt;
 
<span class="p_chunk">@@ -103,6 +104,13 @@</span> <span class="p_context"> static inline void set_fs(mm_segment_t fs)</span>
 	flag;								\
 })
 
<span class="p_add">+/*</span>
<span class="p_add">+ * When dealing with data aborts, watchpoints, or instruction traps we may end</span>
<span class="p_add">+ * up with a tagged userland pointer. Clear the tag to get a sane pointer to</span>
<span class="p_add">+ * pass on to access_ok(), for instance.</span>
<span class="p_add">+ */</span>
<span class="p_add">+#define untagged_addr(addr)		sign_extend64(addr, 55)</span>
<span class="p_add">+</span>
 #define access_ok(type, addr, size)	__range_ok(addr, size)
 #define user_addr_max			get_fs
 
<span class="p_header">diff --git a/arch/arm64/kernel/armv8_deprecated.c b/arch/arm64/kernel/armv8_deprecated.c</span>
<span class="p_header">index 937f5e58a4d3..478a00b9732b 100644</span>
<span class="p_header">--- a/arch/arm64/kernel/armv8_deprecated.c</span>
<span class="p_header">+++ b/arch/arm64/kernel/armv8_deprecated.c</span>
<span class="p_chunk">@@ -305,7 +305,8 @@</span> <span class="p_context"> static void register_insn_emulation_sysctl(struct ctl_table *table)</span>
 	ALTERNATIVE(&quot;nop&quot;, SET_PSTATE_PAN(1), ARM64_HAS_PAN,	\
 		CONFIG_ARM64_PAN)				\
 	: &quot;=&amp;r&quot; (res), &quot;+r&quot; (data), &quot;=&amp;r&quot; (temp)		\
<span class="p_del">-	: &quot;r&quot; (addr), &quot;i&quot; (-EAGAIN), &quot;i&quot; (-EFAULT)		\</span>
<span class="p_add">+	: &quot;r&quot; ((unsigned long)addr), &quot;i&quot; (-EAGAIN),		\</span>
<span class="p_add">+	  &quot;i&quot; (-EFAULT)						\</span>
 	: &quot;memory&quot;)
 
 #define __user_swp_asm(data, addr, res, temp) \
<span class="p_header">diff --git a/arch/arm64/kernel/entry.S b/arch/arm64/kernel/entry.S</span>
<span class="p_header">index bd14849beb73..dccd0c2e9023 100644</span>
<span class="p_header">--- a/arch/arm64/kernel/entry.S</span>
<span class="p_header">+++ b/arch/arm64/kernel/entry.S</span>
<span class="p_chunk">@@ -29,6 +29,7 @@</span> <span class="p_context"></span>
 #include &lt;asm/esr.h&gt;
 #include &lt;asm/memory.h&gt;
 #include &lt;asm/thread_info.h&gt;
<span class="p_add">+#include &lt;asm/asm-uaccess.h&gt;</span>
 #include &lt;asm/unistd.h&gt;
 
 /*
<span class="p_chunk">@@ -316,12 +317,13 @@</span> <span class="p_context"> el1_da:</span>
 	/*
 	 * Data abort handling
 	 */
<span class="p_del">-	mrs	x0, far_el1</span>
<span class="p_add">+	mrs	x3, far_el1</span>
 	enable_dbg
 	// re-enable interrupts if they were enabled in the aborted context
 	tbnz	x23, #7, 1f			// PSR_I_BIT
 	enable_irq
 1:
<span class="p_add">+	clear_address_tag x0, x3</span>
 	mov	x2, sp				// struct pt_regs
 	bl	do_mem_abort
 
<span class="p_chunk">@@ -483,7 +485,7 @@</span> <span class="p_context"> el0_da:</span>
 	// enable interrupts before calling the main handler
 	enable_dbg_and_irq
 	ct_user_exit
<span class="p_del">-	bic	x0, x26, #(0xff &lt;&lt; 56)</span>
<span class="p_add">+	clear_address_tag x0, x26</span>
 	mov	x1, x25
 	mov	x2, sp
 	bl	do_mem_abort
<span class="p_header">diff --git a/arch/arm64/kernel/hw_breakpoint.c b/arch/arm64/kernel/hw_breakpoint.c</span>
<span class="p_header">index b45c95d34b83..eeebfc315526 100644</span>
<span class="p_header">--- a/arch/arm64/kernel/hw_breakpoint.c</span>
<span class="p_header">+++ b/arch/arm64/kernel/hw_breakpoint.c</span>
<span class="p_chunk">@@ -35,6 +35,7 @@</span> <span class="p_context"></span>
 #include &lt;asm/traps.h&gt;
 #include &lt;asm/cputype.h&gt;
 #include &lt;asm/system_misc.h&gt;
<span class="p_add">+#include &lt;asm/uaccess.h&gt;</span>
 
 /* Breakpoint currently in use for each BRP. */
 static DEFINE_PER_CPU(struct perf_event *, bp_on_reg[ARM_MAX_BRP]);
<span class="p_chunk">@@ -690,7 +691,7 @@</span> <span class="p_context"> static int watchpoint_handler(unsigned long addr, unsigned int esr,</span>
 
 		/* Check if the watchpoint value matches. */
 		val = read_wb_reg(AARCH64_DBG_REG_WVR, i);
<span class="p_del">-		if (val != (addr &amp; ~alignment_mask))</span>
<span class="p_add">+		if (val != (untagged_addr(addr) &amp; ~alignment_mask))</span>
 			goto unlock;
 
 		/* Possible match, check the byte address select to confirm. */
<span class="p_header">diff --git a/arch/powerpc/include/asm/topology.h b/arch/powerpc/include/asm/topology.h</span>
<span class="p_header">index 8b3b46b7b0f2..329771559cbb 100644</span>
<span class="p_header">--- a/arch/powerpc/include/asm/topology.h</span>
<span class="p_header">+++ b/arch/powerpc/include/asm/topology.h</span>
<span class="p_chunk">@@ -44,8 +44,22 @@</span> <span class="p_context"> extern void __init dump_numa_cpu_topology(void);</span>
 extern int sysfs_add_device_to_node(struct device *dev, int nid);
 extern void sysfs_remove_device_from_node(struct device *dev, int nid);
 
<span class="p_add">+static inline int early_cpu_to_node(int cpu)</span>
<span class="p_add">+{</span>
<span class="p_add">+	int nid;</span>
<span class="p_add">+</span>
<span class="p_add">+	nid = numa_cpu_lookup_table[cpu];</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Fall back to node 0 if nid is unset (it should be, except bugs).</span>
<span class="p_add">+	 * This allows callers to safely do NODE_DATA(early_cpu_to_node(cpu)).</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	return (nid &lt; 0) ? 0 : nid;</span>
<span class="p_add">+}</span>
 #else
 
<span class="p_add">+static inline int early_cpu_to_node(int cpu) { return 0; }</span>
<span class="p_add">+</span>
 static inline void dump_numa_cpu_topology(void) {}
 
 static inline int sysfs_add_device_to_node(struct device *dev, int nid)
<span class="p_header">diff --git a/arch/powerpc/kernel/eeh_driver.c b/arch/powerpc/kernel/eeh_driver.c</span>
<span class="p_header">index c314db8b798c..9837c98caabe 100644</span>
<span class="p_header">--- a/arch/powerpc/kernel/eeh_driver.c</span>
<span class="p_header">+++ b/arch/powerpc/kernel/eeh_driver.c</span>
<span class="p_chunk">@@ -655,7 +655,7 @@</span> <span class="p_context"> static int eeh_reset_device(struct eeh_pe *pe, struct pci_bus *bus)</span>
  */
 #define MAX_WAIT_FOR_RECOVERY 300
 
<span class="p_del">-static void eeh_handle_normal_event(struct eeh_pe *pe)</span>
<span class="p_add">+static bool eeh_handle_normal_event(struct eeh_pe *pe)</span>
 {
 	struct pci_bus *frozen_bus;
 	int rc = 0;
<span class="p_chunk">@@ -665,7 +665,7 @@</span> <span class="p_context"> static void eeh_handle_normal_event(struct eeh_pe *pe)</span>
 	if (!frozen_bus) {
 		pr_err(&quot;%s: Cannot find PCI bus for PHB#%d-PE#%x\n&quot;,
 			__func__, pe-&gt;phb-&gt;global_number, pe-&gt;addr);
<span class="p_del">-		return;</span>
<span class="p_add">+		return false;</span>
 	}
 
 	eeh_pe_update_time_stamp(pe);
<span class="p_chunk">@@ -790,7 +790,7 @@</span> <span class="p_context"> static void eeh_handle_normal_event(struct eeh_pe *pe)</span>
 	pr_info(&quot;EEH: Notify device driver to resume\n&quot;);
 	eeh_pe_dev_traverse(pe, eeh_report_resume, NULL);
 
<span class="p_del">-	return;</span>
<span class="p_add">+	return false;</span>
 
 excess_failures:
 	/*
<span class="p_chunk">@@ -831,7 +831,11 @@</span> <span class="p_context"> perm_error:</span>
 		pci_lock_rescan_remove();
 		pcibios_remove_pci_devices(frozen_bus);
 		pci_unlock_rescan_remove();
<span class="p_add">+</span>
<span class="p_add">+		/* The passed PE should no longer be used */</span>
<span class="p_add">+		return true;</span>
 	}
<span class="p_add">+	return false;</span>
 }
 
 static void eeh_handle_special_event(void)
<span class="p_chunk">@@ -897,7 +901,14 @@</span> <span class="p_context"> static void eeh_handle_special_event(void)</span>
 		 */
 		if (rc == EEH_NEXT_ERR_FROZEN_PE ||
 		    rc == EEH_NEXT_ERR_FENCED_PHB) {
<span class="p_del">-			eeh_handle_normal_event(pe);</span>
<span class="p_add">+			/*</span>
<span class="p_add">+			 * eeh_handle_normal_event() can make the PE stale if it</span>
<span class="p_add">+			 * determines that the PE cannot possibly be recovered.</span>
<span class="p_add">+			 * Don&#39;t modify the PE state if that&#39;s the case.</span>
<span class="p_add">+			 */</span>
<span class="p_add">+			if (eeh_handle_normal_event(pe))</span>
<span class="p_add">+				continue;</span>
<span class="p_add">+</span>
 			eeh_pe_state_clear(pe, EEH_PE_RECOVERING);
 		} else {
 			pci_lock_rescan_remove();
<span class="p_header">diff --git a/arch/powerpc/kernel/setup_64.c b/arch/powerpc/kernel/setup_64.c</span>
<span class="p_header">index a20823210ac0..fe6e800c1357 100644</span>
<span class="p_header">--- a/arch/powerpc/kernel/setup_64.c</span>
<span class="p_header">+++ b/arch/powerpc/kernel/setup_64.c</span>
<span class="p_chunk">@@ -751,7 +751,7 @@</span> <span class="p_context"> void __init setup_arch(char **cmdline_p)</span>
 
 static void * __init pcpu_fc_alloc(unsigned int cpu, size_t size, size_t align)
 {
<span class="p_del">-	return __alloc_bootmem_node(NODE_DATA(cpu_to_node(cpu)), size, align,</span>
<span class="p_add">+	return __alloc_bootmem_node(NODE_DATA(early_cpu_to_node(cpu)), size, align,</span>
 				    __pa(MAX_DMA_ADDRESS));
 }
 
<span class="p_chunk">@@ -762,7 +762,7 @@</span> <span class="p_context"> static void __init pcpu_fc_free(void *ptr, size_t size)</span>
 
 static int pcpu_cpu_distance(unsigned int from, unsigned int to)
 {
<span class="p_del">-	if (cpu_to_node(from) == cpu_to_node(to))</span>
<span class="p_add">+	if (early_cpu_to_node(from) == early_cpu_to_node(to))</span>
 		return LOCAL_DISTANCE;
 	else
 		return REMOTE_DISTANCE;
<span class="p_header">diff --git a/arch/powerpc/platforms/pseries/hotplug-memory.c b/arch/powerpc/platforms/pseries/hotplug-memory.c</span>
<span class="p_header">index e9ff44cd5d86..e8b1027e1b5b 100644</span>
<span class="p_header">--- a/arch/powerpc/platforms/pseries/hotplug-memory.c</span>
<span class="p_header">+++ b/arch/powerpc/platforms/pseries/hotplug-memory.c</span>
<span class="p_chunk">@@ -110,6 +110,7 @@</span> <span class="p_context"> static struct property *dlpar_clone_drconf_property(struct device_node *dn)</span>
 	for (i = 0; i &lt; num_lmbs; i++) {
 		lmbs[i].base_addr = be64_to_cpu(lmbs[i].base_addr);
 		lmbs[i].drc_index = be32_to_cpu(lmbs[i].drc_index);
<span class="p_add">+		lmbs[i].aa_index = be32_to_cpu(lmbs[i].aa_index);</span>
 		lmbs[i].flags = be32_to_cpu(lmbs[i].flags);
 	}
 
<span class="p_chunk">@@ -553,6 +554,7 @@</span> <span class="p_context"> static void dlpar_update_drconf_property(struct device_node *dn,</span>
 	for (i = 0; i &lt; num_lmbs; i++) {
 		lmbs[i].base_addr = cpu_to_be64(lmbs[i].base_addr);
 		lmbs[i].drc_index = cpu_to_be32(lmbs[i].drc_index);
<span class="p_add">+		lmbs[i].aa_index = cpu_to_be32(lmbs[i].aa_index);</span>
 		lmbs[i].flags = cpu_to_be32(lmbs[i].flags);
 	}
 
<span class="p_header">diff --git a/arch/sparc/Kconfig b/arch/sparc/Kconfig</span>
<span class="p_header">index 56442d2d7bbc..eb9487470141 100644</span>
<span class="p_header">--- a/arch/sparc/Kconfig</span>
<span class="p_header">+++ b/arch/sparc/Kconfig</span>
<span class="p_chunk">@@ -182,9 +182,9 @@</span> <span class="p_context"> config NR_CPUS</span>
 	int &quot;Maximum number of CPUs&quot;
 	depends on SMP
 	range 2 32 if SPARC32
<span class="p_del">-	range 2 1024 if SPARC64</span>
<span class="p_add">+	range 2 4096 if SPARC64</span>
 	default 32 if SPARC32
<span class="p_del">-	default 64 if SPARC64</span>
<span class="p_add">+	default 4096 if SPARC64</span>
 
 source kernel/Kconfig.hz
 
<span class="p_header">diff --git a/arch/sparc/include/asm/mmu_64.h b/arch/sparc/include/asm/mmu_64.h</span>
<span class="p_header">index f7de0dbc38af..83b36a5371ff 100644</span>
<span class="p_header">--- a/arch/sparc/include/asm/mmu_64.h</span>
<span class="p_header">+++ b/arch/sparc/include/asm/mmu_64.h</span>
<span class="p_chunk">@@ -52,7 +52,7 @@</span> <span class="p_context"></span>
 #define CTX_NR_MASK		TAG_CONTEXT_BITS
 #define CTX_HW_MASK		(CTX_NR_MASK | CTX_PGSZ_MASK)
 
<span class="p_del">-#define CTX_FIRST_VERSION	((_AC(1,UL) &lt;&lt; CTX_VERSION_SHIFT) + _AC(1,UL))</span>
<span class="p_add">+#define CTX_FIRST_VERSION	BIT(CTX_VERSION_SHIFT)</span>
 #define CTX_VALID(__ctx)	\
 	 (!(((__ctx.sparc64_ctx_val) ^ tlb_context_cache) &amp; CTX_VERSION_MASK))
 #define CTX_HWBITS(__ctx)	((__ctx.sparc64_ctx_val) &amp; CTX_HW_MASK)
<span class="p_header">diff --git a/arch/sparc/include/asm/mmu_context_64.h b/arch/sparc/include/asm/mmu_context_64.h</span>
<span class="p_header">index b84be675e507..349dd23e2876 100644</span>
<span class="p_header">--- a/arch/sparc/include/asm/mmu_context_64.h</span>
<span class="p_header">+++ b/arch/sparc/include/asm/mmu_context_64.h</span>
<span class="p_chunk">@@ -17,13 +17,8 @@</span> <span class="p_context"> extern spinlock_t ctx_alloc_lock;</span>
 extern unsigned long tlb_context_cache;
 extern unsigned long mmu_context_bmap[];
 
<span class="p_add">+DECLARE_PER_CPU(struct mm_struct *, per_cpu_secondary_mm);</span>
 void get_new_mmu_context(struct mm_struct *mm);
<span class="p_del">-#ifdef CONFIG_SMP</span>
<span class="p_del">-void smp_new_mmu_context_version(void);</span>
<span class="p_del">-#else</span>
<span class="p_del">-#define smp_new_mmu_context_version() do { } while (0)</span>
<span class="p_del">-#endif</span>
<span class="p_del">-</span>
 int init_new_context(struct task_struct *tsk, struct mm_struct *mm);
 void destroy_context(struct mm_struct *mm);
 
<span class="p_chunk">@@ -74,8 +69,9 @@</span> <span class="p_context"> void __flush_tlb_mm(unsigned long, unsigned long);</span>
 static inline void switch_mm(struct mm_struct *old_mm, struct mm_struct *mm, struct task_struct *tsk)
 {
 	unsigned long ctx_valid, flags;
<span class="p_del">-	int cpu;</span>
<span class="p_add">+	int cpu = smp_processor_id();</span>
 
<span class="p_add">+	per_cpu(per_cpu_secondary_mm, cpu) = mm;</span>
 	if (unlikely(mm == &amp;init_mm))
 		return;
 
<span class="p_chunk">@@ -121,7 +117,6 @@</span> <span class="p_context"> static inline void switch_mm(struct mm_struct *old_mm, struct mm_struct *mm, str</span>
 	 * for the first time, we must flush that context out of the
 	 * local TLB.
 	 */
<span class="p_del">-	cpu = smp_processor_id();</span>
 	if (!ctx_valid || !cpumask_test_cpu(cpu, mm_cpumask(mm))) {
 		cpumask_set_cpu(cpu, mm_cpumask(mm));
 		__flush_tlb_mm(CTX_HWBITS(mm-&gt;context),
<span class="p_chunk">@@ -131,26 +126,7 @@</span> <span class="p_context"> static inline void switch_mm(struct mm_struct *old_mm, struct mm_struct *mm, str</span>
 }
 
 #define deactivate_mm(tsk,mm)	do { } while (0)
<span class="p_del">-</span>
<span class="p_del">-/* Activate a new MM instance for the current task. */</span>
<span class="p_del">-static inline void activate_mm(struct mm_struct *active_mm, struct mm_struct *mm)</span>
<span class="p_del">-{</span>
<span class="p_del">-	unsigned long flags;</span>
<span class="p_del">-	int cpu;</span>
<span class="p_del">-</span>
<span class="p_del">-	spin_lock_irqsave(&amp;mm-&gt;context.lock, flags);</span>
<span class="p_del">-	if (!CTX_VALID(mm-&gt;context))</span>
<span class="p_del">-		get_new_mmu_context(mm);</span>
<span class="p_del">-	cpu = smp_processor_id();</span>
<span class="p_del">-	if (!cpumask_test_cpu(cpu, mm_cpumask(mm)))</span>
<span class="p_del">-		cpumask_set_cpu(cpu, mm_cpumask(mm));</span>
<span class="p_del">-</span>
<span class="p_del">-	load_secondary_context(mm);</span>
<span class="p_del">-	__flush_tlb_mm(CTX_HWBITS(mm-&gt;context), SECONDARY_CONTEXT);</span>
<span class="p_del">-	tsb_context_switch(mm);</span>
<span class="p_del">-	spin_unlock_irqrestore(&amp;mm-&gt;context.lock, flags);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_add">+#define activate_mm(active_mm, mm) switch_mm(active_mm, mm, NULL)</span>
 #endif /* !(__ASSEMBLY__) */
 
 #endif /* !(__SPARC64_MMU_CONTEXT_H) */
<span class="p_header">diff --git a/arch/sparc/include/asm/pil.h b/arch/sparc/include/asm/pil.h</span>
<span class="p_header">index 266937030546..522b43db2ed3 100644</span>
<span class="p_header">--- a/arch/sparc/include/asm/pil.h</span>
<span class="p_header">+++ b/arch/sparc/include/asm/pil.h</span>
<span class="p_chunk">@@ -20,7 +20,6 @@</span> <span class="p_context"></span>
 #define PIL_SMP_CALL_FUNC	1
 #define PIL_SMP_RECEIVE_SIGNAL	2
 #define PIL_SMP_CAPTURE		3
<span class="p_del">-#define PIL_SMP_CTX_NEW_VERSION	4</span>
 #define PIL_DEVICE_IRQ		5
 #define PIL_SMP_CALL_FUNC_SNGL	6
 #define PIL_DEFERRED_PCR_WORK	7
<span class="p_header">diff --git a/arch/sparc/include/asm/vio.h b/arch/sparc/include/asm/vio.h</span>
<span class="p_header">index 8174f6cdbbbb..9dca7a892978 100644</span>
<span class="p_header">--- a/arch/sparc/include/asm/vio.h</span>
<span class="p_header">+++ b/arch/sparc/include/asm/vio.h</span>
<span class="p_chunk">@@ -327,6 +327,7 @@</span> <span class="p_context"> struct vio_dev {</span>
 	int			compat_len;
 
 	u64			dev_no;
<span class="p_add">+	u64			id;</span>
 
 	unsigned long		channel_id;
 
<span class="p_header">diff --git a/arch/sparc/kernel/irq_64.c b/arch/sparc/kernel/irq_64.c</span>
<span class="p_header">index e22416ce56ea..bfbde8c4ffb2 100644</span>
<span class="p_header">--- a/arch/sparc/kernel/irq_64.c</span>
<span class="p_header">+++ b/arch/sparc/kernel/irq_64.c</span>
<span class="p_chunk">@@ -1034,17 +1034,26 @@</span> <span class="p_context"> static void __init init_cpu_send_mondo_info(struct trap_per_cpu *tb)</span>
 {
 #ifdef CONFIG_SMP
 	unsigned long page;
<span class="p_add">+	void *mondo, *p;</span>
 
<span class="p_del">-	BUILD_BUG_ON((NR_CPUS * sizeof(u16)) &gt; (PAGE_SIZE - 64));</span>
<span class="p_add">+	BUILD_BUG_ON((NR_CPUS * sizeof(u16)) &gt; PAGE_SIZE);</span>
<span class="p_add">+</span>
<span class="p_add">+	/* Make sure mondo block is 64byte aligned */</span>
<span class="p_add">+	p = kzalloc(127, GFP_KERNEL);</span>
<span class="p_add">+	if (!p) {</span>
<span class="p_add">+		prom_printf(&quot;SUN4V: Error, cannot allocate mondo block.\n&quot;);</span>
<span class="p_add">+		prom_halt();</span>
<span class="p_add">+	}</span>
<span class="p_add">+	mondo = (void *)(((unsigned long)p + 63) &amp; ~0x3f);</span>
<span class="p_add">+	tb-&gt;cpu_mondo_block_pa = __pa(mondo);</span>
 
 	page = get_zeroed_page(GFP_KERNEL);
 	if (!page) {
<span class="p_del">-		prom_printf(&quot;SUN4V: Error, cannot allocate cpu mondo page.\n&quot;);</span>
<span class="p_add">+		prom_printf(&quot;SUN4V: Error, cannot allocate cpu list page.\n&quot;);</span>
 		prom_halt();
 	}
 
<span class="p_del">-	tb-&gt;cpu_mondo_block_pa = __pa(page);</span>
<span class="p_del">-	tb-&gt;cpu_list_pa = __pa(page + 64);</span>
<span class="p_add">+	tb-&gt;cpu_list_pa = __pa(page);</span>
 #endif
 }
 
<span class="p_header">diff --git a/arch/sparc/kernel/kernel.h b/arch/sparc/kernel/kernel.h</span>
<span class="p_header">index e7f652be9e61..44f32dd4477f 100644</span>
<span class="p_header">--- a/arch/sparc/kernel/kernel.h</span>
<span class="p_header">+++ b/arch/sparc/kernel/kernel.h</span>
<span class="p_chunk">@@ -37,7 +37,6 @@</span> <span class="p_context"> void handle_stdfmna(struct pt_regs *regs, unsigned long sfar, unsigned long sfsr</span>
 /* smp_64.c */
 void __irq_entry smp_call_function_client(int irq, struct pt_regs *regs);
 void __irq_entry smp_call_function_single_client(int irq, struct pt_regs *regs);
<span class="p_del">-void __irq_entry smp_new_mmu_context_version_client(int irq, struct pt_regs *regs);</span>
 void __irq_entry smp_penguin_jailcell(int irq, struct pt_regs *regs);
 void __irq_entry smp_receive_signal_client(int irq, struct pt_regs *regs);
 
<span class="p_header">diff --git a/arch/sparc/kernel/smp_64.c b/arch/sparc/kernel/smp_64.c</span>
<span class="p_header">index 19cd08d18672..95a9fa0d2195 100644</span>
<span class="p_header">--- a/arch/sparc/kernel/smp_64.c</span>
<span class="p_header">+++ b/arch/sparc/kernel/smp_64.c</span>
<span class="p_chunk">@@ -959,37 +959,6 @@</span> <span class="p_context"> void flush_dcache_page_all(struct mm_struct *mm, struct page *page)</span>
 	preempt_enable();
 }
 
<span class="p_del">-void __irq_entry smp_new_mmu_context_version_client(int irq, struct pt_regs *regs)</span>
<span class="p_del">-{</span>
<span class="p_del">-	struct mm_struct *mm;</span>
<span class="p_del">-	unsigned long flags;</span>
<span class="p_del">-</span>
<span class="p_del">-	clear_softint(1 &lt;&lt; irq);</span>
<span class="p_del">-</span>
<span class="p_del">-	/* See if we need to allocate a new TLB context because</span>
<span class="p_del">-	 * the version of the one we are using is now out of date.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	mm = current-&gt;active_mm;</span>
<span class="p_del">-	if (unlikely(!mm || (mm == &amp;init_mm)))</span>
<span class="p_del">-		return;</span>
<span class="p_del">-</span>
<span class="p_del">-	spin_lock_irqsave(&amp;mm-&gt;context.lock, flags);</span>
<span class="p_del">-</span>
<span class="p_del">-	if (unlikely(!CTX_VALID(mm-&gt;context)))</span>
<span class="p_del">-		get_new_mmu_context(mm);</span>
<span class="p_del">-</span>
<span class="p_del">-	spin_unlock_irqrestore(&amp;mm-&gt;context.lock, flags);</span>
<span class="p_del">-</span>
<span class="p_del">-	load_secondary_context(mm);</span>
<span class="p_del">-	__flush_tlb_mm(CTX_HWBITS(mm-&gt;context),</span>
<span class="p_del">-		       SECONDARY_CONTEXT);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-void smp_new_mmu_context_version(void)</span>
<span class="p_del">-{</span>
<span class="p_del">-	smp_cross_call(&amp;xcall_new_mmu_context_version, 0, 0, 0);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
 #ifdef CONFIG_KGDB
 void kgdb_roundup_cpus(unsigned long flags)
 {
<span class="p_header">diff --git a/arch/sparc/kernel/tsb.S b/arch/sparc/kernel/tsb.S</span>
<span class="p_header">index d568c8207af7..395ec1800530 100644</span>
<span class="p_header">--- a/arch/sparc/kernel/tsb.S</span>
<span class="p_header">+++ b/arch/sparc/kernel/tsb.S</span>
<span class="p_chunk">@@ -470,13 +470,16 @@</span> <span class="p_context"> __tsb_context_switch:</span>
 	.type	copy_tsb,#function
 copy_tsb:		/* %o0=old_tsb_base, %o1=old_tsb_size
 			 * %o2=new_tsb_base, %o3=new_tsb_size
<span class="p_add">+			 * %o4=page_size_shift</span>
 			 */
 	sethi		%uhi(TSB_PASS_BITS), %g7
 	srlx		%o3, 4, %o3
<span class="p_del">-	add		%o0, %o1, %g1	/* end of old tsb */</span>
<span class="p_add">+	add		%o0, %o1, %o1	/* end of old tsb */</span>
 	sllx		%g7, 32, %g7
 	sub		%o3, 1, %o3	/* %o3 == new tsb hash mask */
 
<span class="p_add">+	mov		%o4, %g1	/* page_size_shift */</span>
<span class="p_add">+</span>
 661:	prefetcha	[%o0] ASI_N, #one_read
 	.section	.tsb_phys_patch, &quot;ax&quot;
 	.word		661b
<span class="p_chunk">@@ -501,9 +504,9 @@</span> <span class="p_context"> copy_tsb:		/* %o0=old_tsb_base, %o1=old_tsb_size</span>
 	/* This can definitely be computed faster... */
 	srlx		%o0, 4, %o5	/* Build index */
 	and		%o5, 511, %o5	/* Mask index */
<span class="p_del">-	sllx		%o5, PAGE_SHIFT, %o5 /* Put into vaddr position */</span>
<span class="p_add">+	sllx		%o5, %g1, %o5	/* Put into vaddr position */</span>
 	or		%o4, %o5, %o4	/* Full VADDR. */
<span class="p_del">-	srlx		%o4, PAGE_SHIFT, %o4 /* Shift down to create index */</span>
<span class="p_add">+	srlx		%o4, %g1, %o4	/* Shift down to create index */</span>
 	and		%o4, %o3, %o4	/* Mask with new_tsb_nents-1 */
 	sllx		%o4, 4, %o4	/* Shift back up into tsb ent offset */
 	TSB_STORE(%o2 + %o4, %g2)	/* Store TAG */
<span class="p_chunk">@@ -511,7 +514,7 @@</span> <span class="p_context"> copy_tsb:		/* %o0=old_tsb_base, %o1=old_tsb_size</span>
 	TSB_STORE(%o2 + %o4, %g3)	/* Store TTE */
 
 80:	add		%o0, 16, %o0
<span class="p_del">-	cmp		%o0, %g1</span>
<span class="p_add">+	cmp		%o0, %o1</span>
 	bne,pt		%xcc, 90b
 	 nop
 
<span class="p_header">diff --git a/arch/sparc/kernel/ttable_64.S b/arch/sparc/kernel/ttable_64.S</span>
<span class="p_header">index c6dfdaa29e20..170ead662f2a 100644</span>
<span class="p_header">--- a/arch/sparc/kernel/ttable_64.S</span>
<span class="p_header">+++ b/arch/sparc/kernel/ttable_64.S</span>
<span class="p_chunk">@@ -50,7 +50,7 @@</span> <span class="p_context"> tl0_resv03e:	BTRAP(0x3e) BTRAP(0x3f) BTRAP(0x40)</span>
 tl0_irq1:	TRAP_IRQ(smp_call_function_client, 1)
 tl0_irq2:	TRAP_IRQ(smp_receive_signal_client, 2)
 tl0_irq3:	TRAP_IRQ(smp_penguin_jailcell, 3)
<span class="p_del">-tl0_irq4:	TRAP_IRQ(smp_new_mmu_context_version_client, 4)</span>
<span class="p_add">+tl0_irq4:       BTRAP(0x44)</span>
 #else
 tl0_irq1:	BTRAP(0x41)
 tl0_irq2:	BTRAP(0x42)
<span class="p_header">diff --git a/arch/sparc/kernel/vio.c b/arch/sparc/kernel/vio.c</span>
<span class="p_header">index cb5789c9f961..34824ca396f0 100644</span>
<span class="p_header">--- a/arch/sparc/kernel/vio.c</span>
<span class="p_header">+++ b/arch/sparc/kernel/vio.c</span>
<span class="p_chunk">@@ -284,13 +284,16 @@</span> <span class="p_context"> static struct vio_dev *vio_create_one(struct mdesc_handle *hp, u64 mp,</span>
 	if (!id) {
 		dev_set_name(&amp;vdev-&gt;dev, &quot;%s&quot;, bus_id_name);
 		vdev-&gt;dev_no = ~(u64)0;
<span class="p_add">+		vdev-&gt;id = ~(u64)0;</span>
 	} else if (!cfg_handle) {
 		dev_set_name(&amp;vdev-&gt;dev, &quot;%s-%llu&quot;, bus_id_name, *id);
 		vdev-&gt;dev_no = *id;
<span class="p_add">+		vdev-&gt;id = ~(u64)0;</span>
 	} else {
 		dev_set_name(&amp;vdev-&gt;dev, &quot;%s-%llu-%llu&quot;, bus_id_name,
 			     *cfg_handle, *id);
 		vdev-&gt;dev_no = *cfg_handle;
<span class="p_add">+		vdev-&gt;id = *id;</span>
 	}
 
 	vdev-&gt;dev.parent = parent;
<span class="p_chunk">@@ -333,27 +336,84 @@</span> <span class="p_context"> static void vio_add(struct mdesc_handle *hp, u64 node)</span>
 	(void) vio_create_one(hp, node, &amp;root_vdev-&gt;dev);
 }
 
<span class="p_add">+struct vio_md_node_query {</span>
<span class="p_add">+	const char *type;</span>
<span class="p_add">+	u64 dev_no;</span>
<span class="p_add">+	u64 id;</span>
<span class="p_add">+};</span>
<span class="p_add">+</span>
 static int vio_md_node_match(struct device *dev, void *arg)
 {
<span class="p_add">+	struct vio_md_node_query *query = (struct vio_md_node_query *) arg;</span>
 	struct vio_dev *vdev = to_vio_dev(dev);
 
<span class="p_del">-	if (vdev-&gt;mp == (u64) arg)</span>
<span class="p_del">-		return 1;</span>
<span class="p_add">+	if (vdev-&gt;dev_no != query-&gt;dev_no)</span>
<span class="p_add">+		return 0;</span>
<span class="p_add">+	if (vdev-&gt;id != query-&gt;id)</span>
<span class="p_add">+		return 0;</span>
<span class="p_add">+	if (strcmp(vdev-&gt;type, query-&gt;type))</span>
<span class="p_add">+		return 0;</span>
 
<span class="p_del">-	return 0;</span>
<span class="p_add">+	return 1;</span>
 }
 
 static void vio_remove(struct mdesc_handle *hp, u64 node)
 {
<span class="p_add">+	const char *type;</span>
<span class="p_add">+	const u64 *id, *cfg_handle;</span>
<span class="p_add">+	u64 a;</span>
<span class="p_add">+	struct vio_md_node_query query;</span>
 	struct device *dev;
 
<span class="p_del">-	dev = device_find_child(&amp;root_vdev-&gt;dev, (void *) node,</span>
<span class="p_add">+	type = mdesc_get_property(hp, node, &quot;device-type&quot;, NULL);</span>
<span class="p_add">+	if (!type) {</span>
<span class="p_add">+		type = mdesc_get_property(hp, node, &quot;name&quot;, NULL);</span>
<span class="p_add">+		if (!type)</span>
<span class="p_add">+			type = mdesc_node_name(hp, node);</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	query.type = type;</span>
<span class="p_add">+</span>
<span class="p_add">+	id = mdesc_get_property(hp, node, &quot;id&quot;, NULL);</span>
<span class="p_add">+	cfg_handle = NULL;</span>
<span class="p_add">+	mdesc_for_each_arc(a, hp, node, MDESC_ARC_TYPE_BACK) {</span>
<span class="p_add">+		u64 target;</span>
<span class="p_add">+</span>
<span class="p_add">+		target = mdesc_arc_target(hp, a);</span>
<span class="p_add">+		cfg_handle = mdesc_get_property(hp, target,</span>
<span class="p_add">+						&quot;cfg-handle&quot;, NULL);</span>
<span class="p_add">+		if (cfg_handle)</span>
<span class="p_add">+			break;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	if (!id) {</span>
<span class="p_add">+		query.dev_no = ~(u64)0;</span>
<span class="p_add">+		query.id = ~(u64)0;</span>
<span class="p_add">+	} else if (!cfg_handle) {</span>
<span class="p_add">+		query.dev_no = *id;</span>
<span class="p_add">+		query.id = ~(u64)0;</span>
<span class="p_add">+	} else {</span>
<span class="p_add">+		query.dev_no = *cfg_handle;</span>
<span class="p_add">+		query.id = *id;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	dev = device_find_child(&amp;root_vdev-&gt;dev, &amp;query,</span>
 				vio_md_node_match);
 	if (dev) {
 		printk(KERN_INFO &quot;VIO: Removing device %s\n&quot;, dev_name(dev));
 
 		device_unregister(dev);
 		put_device(dev);
<span class="p_add">+	} else {</span>
<span class="p_add">+		if (!id)</span>
<span class="p_add">+			printk(KERN_ERR &quot;VIO: Removed unknown %s node.\n&quot;,</span>
<span class="p_add">+			       type);</span>
<span class="p_add">+		else if (!cfg_handle)</span>
<span class="p_add">+			printk(KERN_ERR &quot;VIO: Removed unknown %s node %llu.\n&quot;,</span>
<span class="p_add">+			       type, *id);</span>
<span class="p_add">+		else</span>
<span class="p_add">+			printk(KERN_ERR &quot;VIO: Removed unknown %s node %llu-%llu.\n&quot;,</span>
<span class="p_add">+			       type, *cfg_handle, *id);</span>
 	}
 }
 
<span class="p_header">diff --git a/arch/sparc/mm/init_64.c b/arch/sparc/mm/init_64.c</span>
<span class="p_header">index 965655afdbb6..384aba109d7c 100644</span>
<span class="p_header">--- a/arch/sparc/mm/init_64.c</span>
<span class="p_header">+++ b/arch/sparc/mm/init_64.c</span>
<span class="p_chunk">@@ -656,10 +656,58 @@</span> <span class="p_context"> EXPORT_SYMBOL(__flush_dcache_range);</span>
 
 /* get_new_mmu_context() uses &quot;cache + 1&quot;.  */
 DEFINE_SPINLOCK(ctx_alloc_lock);
<span class="p_del">-unsigned long tlb_context_cache = CTX_FIRST_VERSION - 1;</span>
<span class="p_add">+unsigned long tlb_context_cache = CTX_FIRST_VERSION;</span>
 #define MAX_CTX_NR	(1UL &lt;&lt; CTX_NR_BITS)
 #define CTX_BMAP_SLOTS	BITS_TO_LONGS(MAX_CTX_NR)
 DECLARE_BITMAP(mmu_context_bmap, MAX_CTX_NR);
<span class="p_add">+DEFINE_PER_CPU(struct mm_struct *, per_cpu_secondary_mm) = {0};</span>
<span class="p_add">+</span>
<span class="p_add">+static void mmu_context_wrap(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long old_ver = tlb_context_cache &amp; CTX_VERSION_MASK;</span>
<span class="p_add">+	unsigned long new_ver, new_ctx, old_ctx;</span>
<span class="p_add">+	struct mm_struct *mm;</span>
<span class="p_add">+	int cpu;</span>
<span class="p_add">+</span>
<span class="p_add">+	bitmap_zero(mmu_context_bmap, 1 &lt;&lt; CTX_NR_BITS);</span>
<span class="p_add">+</span>
<span class="p_add">+	/* Reserve kernel context */</span>
<span class="p_add">+	set_bit(0, mmu_context_bmap);</span>
<span class="p_add">+</span>
<span class="p_add">+	new_ver = (tlb_context_cache &amp; CTX_VERSION_MASK) + CTX_FIRST_VERSION;</span>
<span class="p_add">+	if (unlikely(new_ver == 0))</span>
<span class="p_add">+		new_ver = CTX_FIRST_VERSION;</span>
<span class="p_add">+	tlb_context_cache = new_ver;</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Make sure that any new mm that are added into per_cpu_secondary_mm,</span>
<span class="p_add">+	 * are going to go through get_new_mmu_context() path.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	mb();</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Updated versions to current on those CPUs that had valid secondary</span>
<span class="p_add">+	 * contexts</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	for_each_online_cpu(cpu) {</span>
<span class="p_add">+		/*</span>
<span class="p_add">+		 * If a new mm is stored after we took this mm from the array,</span>
<span class="p_add">+		 * it will go into get_new_mmu_context() path, because we</span>
<span class="p_add">+		 * already bumped the version in tlb_context_cache.</span>
<span class="p_add">+		 */</span>
<span class="p_add">+		mm = per_cpu(per_cpu_secondary_mm, cpu);</span>
<span class="p_add">+</span>
<span class="p_add">+		if (unlikely(!mm || mm == &amp;init_mm))</span>
<span class="p_add">+			continue;</span>
<span class="p_add">+</span>
<span class="p_add">+		old_ctx = mm-&gt;context.sparc64_ctx_val;</span>
<span class="p_add">+		if (likely((old_ctx &amp; CTX_VERSION_MASK) == old_ver)) {</span>
<span class="p_add">+			new_ctx = (old_ctx &amp; ~CTX_VERSION_MASK) | new_ver;</span>
<span class="p_add">+			set_bit(new_ctx &amp; CTX_NR_MASK, mmu_context_bmap);</span>
<span class="p_add">+			mm-&gt;context.sparc64_ctx_val = new_ctx;</span>
<span class="p_add">+		}</span>
<span class="p_add">+	}</span>
<span class="p_add">+}</span>
 
 /* Caller does TLB context flushing on local CPU if necessary.
  * The caller also ensures that CTX_VALID(mm-&gt;context) is false.
<span class="p_chunk">@@ -675,48 +723,30 @@</span> <span class="p_context"> void get_new_mmu_context(struct mm_struct *mm)</span>
 {
 	unsigned long ctx, new_ctx;
 	unsigned long orig_pgsz_bits;
<span class="p_del">-	int new_version;</span>
 
 	spin_lock(&amp;ctx_alloc_lock);
<span class="p_add">+retry:</span>
<span class="p_add">+	/* wrap might have happened, test again if our context became valid */</span>
<span class="p_add">+	if (unlikely(CTX_VALID(mm-&gt;context)))</span>
<span class="p_add">+		goto out;</span>
 	orig_pgsz_bits = (mm-&gt;context.sparc64_ctx_val &amp; CTX_PGSZ_MASK);
 	ctx = (tlb_context_cache + 1) &amp; CTX_NR_MASK;
 	new_ctx = find_next_zero_bit(mmu_context_bmap, 1 &lt;&lt; CTX_NR_BITS, ctx);
<span class="p_del">-	new_version = 0;</span>
 	if (new_ctx &gt;= (1 &lt;&lt; CTX_NR_BITS)) {
 		new_ctx = find_next_zero_bit(mmu_context_bmap, ctx, 1);
 		if (new_ctx &gt;= ctx) {
<span class="p_del">-			int i;</span>
<span class="p_del">-			new_ctx = (tlb_context_cache &amp; CTX_VERSION_MASK) +</span>
<span class="p_del">-				CTX_FIRST_VERSION;</span>
<span class="p_del">-			if (new_ctx == 1)</span>
<span class="p_del">-				new_ctx = CTX_FIRST_VERSION;</span>
<span class="p_del">-</span>
<span class="p_del">-			/* Don&#39;t call memset, for 16 entries that&#39;s just</span>
<span class="p_del">-			 * plain silly...</span>
<span class="p_del">-			 */</span>
<span class="p_del">-			mmu_context_bmap[0] = 3;</span>
<span class="p_del">-			mmu_context_bmap[1] = 0;</span>
<span class="p_del">-			mmu_context_bmap[2] = 0;</span>
<span class="p_del">-			mmu_context_bmap[3] = 0;</span>
<span class="p_del">-			for (i = 4; i &lt; CTX_BMAP_SLOTS; i += 4) {</span>
<span class="p_del">-				mmu_context_bmap[i + 0] = 0;</span>
<span class="p_del">-				mmu_context_bmap[i + 1] = 0;</span>
<span class="p_del">-				mmu_context_bmap[i + 2] = 0;</span>
<span class="p_del">-				mmu_context_bmap[i + 3] = 0;</span>
<span class="p_del">-			}</span>
<span class="p_del">-			new_version = 1;</span>
<span class="p_del">-			goto out;</span>
<span class="p_add">+			mmu_context_wrap();</span>
<span class="p_add">+			goto retry;</span>
 		}
 	}
<span class="p_add">+	if (mm-&gt;context.sparc64_ctx_val)</span>
<span class="p_add">+		cpumask_clear(mm_cpumask(mm));</span>
 	mmu_context_bmap[new_ctx&gt;&gt;6] |= (1UL &lt;&lt; (new_ctx &amp; 63));
 	new_ctx |= (tlb_context_cache &amp; CTX_VERSION_MASK);
<span class="p_del">-out:</span>
 	tlb_context_cache = new_ctx;
 	mm-&gt;context.sparc64_ctx_val = new_ctx | orig_pgsz_bits;
<span class="p_add">+out:</span>
 	spin_unlock(&amp;ctx_alloc_lock);
<span class="p_del">-</span>
<span class="p_del">-	if (unlikely(new_version))</span>
<span class="p_del">-		smp_new_mmu_context_version();</span>
 }
 
 static int numa_enabled = 1;
<span class="p_header">diff --git a/arch/sparc/mm/tsb.c b/arch/sparc/mm/tsb.c</span>
<span class="p_header">index 9cdeca0fa955..266411291634 100644</span>
<span class="p_header">--- a/arch/sparc/mm/tsb.c</span>
<span class="p_header">+++ b/arch/sparc/mm/tsb.c</span>
<span class="p_chunk">@@ -451,7 +451,8 @@</span> <span class="p_context"> retry_tsb_alloc:</span>
 		extern void copy_tsb(unsigned long old_tsb_base,
 				     unsigned long old_tsb_size,
 				     unsigned long new_tsb_base,
<span class="p_del">-				     unsigned long new_tsb_size);</span>
<span class="p_add">+				     unsigned long new_tsb_size,</span>
<span class="p_add">+				     unsigned long page_size_shift);</span>
 		unsigned long old_tsb_base = (unsigned long) old_tsb;
 		unsigned long new_tsb_base = (unsigned long) new_tsb;
 
<span class="p_chunk">@@ -459,7 +460,9 @@</span> <span class="p_context"> retry_tsb_alloc:</span>
 			old_tsb_base = __pa(old_tsb_base);
 			new_tsb_base = __pa(new_tsb_base);
 		}
<span class="p_del">-		copy_tsb(old_tsb_base, old_size, new_tsb_base, new_size);</span>
<span class="p_add">+		copy_tsb(old_tsb_base, old_size, new_tsb_base, new_size,</span>
<span class="p_add">+			tsb_index == MM_TSB_BASE ?</span>
<span class="p_add">+			PAGE_SHIFT : REAL_HPAGE_SHIFT);</span>
 	}
 
 	mm-&gt;context.tsb_block[tsb_index].tsb = new_tsb;
<span class="p_header">diff --git a/arch/sparc/mm/ultra.S b/arch/sparc/mm/ultra.S</span>
<span class="p_header">index 5d2fd6cd3189..fcf4d27a38fb 100644</span>
<span class="p_header">--- a/arch/sparc/mm/ultra.S</span>
<span class="p_header">+++ b/arch/sparc/mm/ultra.S</span>
<span class="p_chunk">@@ -971,11 +971,6 @@</span> <span class="p_context"> xcall_capture:</span>
 	wr		%g0, (1 &lt;&lt; PIL_SMP_CAPTURE), %set_softint
 	retry
 
<span class="p_del">-	.globl		xcall_new_mmu_context_version</span>
<span class="p_del">-xcall_new_mmu_context_version:</span>
<span class="p_del">-	wr		%g0, (1 &lt;&lt; PIL_SMP_CTX_NEW_VERSION), %set_softint</span>
<span class="p_del">-	retry</span>
<span class="p_del">-</span>
 #ifdef CONFIG_KGDB
 	.globl		xcall_kgdb_capture
 xcall_kgdb_capture:
<span class="p_header">diff --git a/arch/x86/kernel/kvm.c b/arch/x86/kernel/kvm.c</span>
<span class="p_header">index 47190bd399e7..cec49ecf5f31 100644</span>
<span class="p_header">--- a/arch/x86/kernel/kvm.c</span>
<span class="p_header">+++ b/arch/x86/kernel/kvm.c</span>
<span class="p_chunk">@@ -161,8 +161,8 @@</span> <span class="p_context"> void kvm_async_pf_task_wait(u32 token)</span>
 			 */
 			rcu_irq_exit();
 			native_safe_halt();
<span class="p_del">-			rcu_irq_enter();</span>
 			local_irq_disable();
<span class="p_add">+			rcu_irq_enter();</span>
 		}
 	}
 	if (!n.halted)
<span class="p_header">diff --git a/arch/x86/kvm/cpuid.c b/arch/x86/kvm/cpuid.c</span>
<span class="p_header">index 642e9c93a097..9357b29de9bc 100644</span>
<span class="p_header">--- a/arch/x86/kvm/cpuid.c</span>
<span class="p_header">+++ b/arch/x86/kvm/cpuid.c</span>
<span class="p_chunk">@@ -737,18 +737,20 @@</span> <span class="p_context"> out:</span>
 static int move_to_next_stateful_cpuid_entry(struct kvm_vcpu *vcpu, int i)
 {
 	struct kvm_cpuid_entry2 *e = &amp;vcpu-&gt;arch.cpuid_entries[i];
<span class="p_del">-	int j, nent = vcpu-&gt;arch.cpuid_nent;</span>
<span class="p_add">+	struct kvm_cpuid_entry2 *ej;</span>
<span class="p_add">+	int j = i;</span>
<span class="p_add">+	int nent = vcpu-&gt;arch.cpuid_nent;</span>
 
 	e-&gt;flags &amp;= ~KVM_CPUID_FLAG_STATE_READ_NEXT;
 	/* when no next entry is found, the current entry[i] is reselected */
<span class="p_del">-	for (j = i + 1; ; j = (j + 1) % nent) {</span>
<span class="p_del">-		struct kvm_cpuid_entry2 *ej = &amp;vcpu-&gt;arch.cpuid_entries[j];</span>
<span class="p_del">-		if (ej-&gt;function == e-&gt;function) {</span>
<span class="p_del">-			ej-&gt;flags |= KVM_CPUID_FLAG_STATE_READ_NEXT;</span>
<span class="p_del">-			return j;</span>
<span class="p_del">-		}</span>
<span class="p_del">-	}</span>
<span class="p_del">-	return 0; /* silence gcc, even though control never reaches here */</span>
<span class="p_add">+	do {</span>
<span class="p_add">+		j = (j + 1) % nent;</span>
<span class="p_add">+		ej = &amp;vcpu-&gt;arch.cpuid_entries[j];</span>
<span class="p_add">+	} while (ej-&gt;function != e-&gt;function);</span>
<span class="p_add">+</span>
<span class="p_add">+	ej-&gt;flags |= KVM_CPUID_FLAG_STATE_READ_NEXT;</span>
<span class="p_add">+</span>
<span class="p_add">+	return j;</span>
 }
 
 /* find an entry with matching function, matching index (if needed), and that
<span class="p_header">diff --git a/arch/x86/kvm/mmu.c b/arch/x86/kvm/mmu.c</span>
<span class="p_header">index 8eb8a934b531..1049c3c9b877 100644</span>
<span class="p_header">--- a/arch/x86/kvm/mmu.c</span>
<span class="p_header">+++ b/arch/x86/kvm/mmu.c</span>
<span class="p_chunk">@@ -3433,12 +3433,15 @@</span> <span class="p_context"> static int kvm_arch_setup_async_pf(struct kvm_vcpu *vcpu, gva_t gva, gfn_t gfn)</span>
 	return kvm_setup_async_pf(vcpu, gva, kvm_vcpu_gfn_to_hva(vcpu, gfn), &amp;arch);
 }
 
<span class="p_del">-static bool can_do_async_pf(struct kvm_vcpu *vcpu)</span>
<span class="p_add">+bool kvm_can_do_async_pf(struct kvm_vcpu *vcpu)</span>
 {
 	if (unlikely(!lapic_in_kernel(vcpu) ||
 		     kvm_event_needs_reinjection(vcpu)))
 		return false;
 
<span class="p_add">+	if (is_guest_mode(vcpu))</span>
<span class="p_add">+		return false;</span>
<span class="p_add">+</span>
 	return kvm_x86_ops-&gt;interrupt_allowed(vcpu);
 }
 
<span class="p_chunk">@@ -3454,7 +3457,7 @@</span> <span class="p_context"> static bool try_async_pf(struct kvm_vcpu *vcpu, bool prefault, gfn_t gfn,</span>
 	if (!async)
 		return false; /* *pfn has correct page already */
 
<span class="p_del">-	if (!prefault &amp;&amp; can_do_async_pf(vcpu)) {</span>
<span class="p_add">+	if (!prefault &amp;&amp; kvm_can_do_async_pf(vcpu)) {</span>
 		trace_kvm_try_async_get_page(gva, gfn);
 		if (kvm_find_async_pf_gfn(vcpu, gfn)) {
 			trace_kvm_async_pf_doublefault(gva, gfn);
<span class="p_header">diff --git a/arch/x86/kvm/mmu.h b/arch/x86/kvm/mmu.h</span>
<span class="p_header">index 55ffb7b0f95e..e60fc80f8a9c 100644</span>
<span class="p_header">--- a/arch/x86/kvm/mmu.h</span>
<span class="p_header">+++ b/arch/x86/kvm/mmu.h</span>
<span class="p_chunk">@@ -74,6 +74,7 @@</span> <span class="p_context"> enum {</span>
 int handle_mmio_page_fault(struct kvm_vcpu *vcpu, u64 addr, bool direct);
 void kvm_init_shadow_mmu(struct kvm_vcpu *vcpu);
 void kvm_init_shadow_ept_mmu(struct kvm_vcpu *vcpu, bool execonly);
<span class="p_add">+bool kvm_can_do_async_pf(struct kvm_vcpu *vcpu);</span>
 
 static inline unsigned int kvm_mmu_available_pages(struct kvm *kvm)
 {
<span class="p_header">diff --git a/arch/x86/kvm/x86.c b/arch/x86/kvm/x86.c</span>
<span class="p_header">index ae2b9cd358f2..6c82792487e9 100644</span>
<span class="p_header">--- a/arch/x86/kvm/x86.c</span>
<span class="p_header">+++ b/arch/x86/kvm/x86.c</span>
<span class="p_chunk">@@ -8245,8 +8245,7 @@</span> <span class="p_context"> bool kvm_arch_can_inject_async_page_present(struct kvm_vcpu *vcpu)</span>
 	if (!(vcpu-&gt;arch.apf.msr_val &amp; KVM_ASYNC_PF_ENABLED))
 		return true;
 	else
<span class="p_del">-		return !kvm_event_needs_reinjection(vcpu) &amp;&amp;</span>
<span class="p_del">-			kvm_x86_ops-&gt;interrupt_allowed(vcpu);</span>
<span class="p_add">+		return kvm_can_do_async_pf(vcpu);</span>
 }
 
 void kvm_arch_start_assignment(struct kvm *kvm)
<span class="p_header">diff --git a/crypto/gcm.c b/crypto/gcm.c</span>
<span class="p_header">index 1238b3c5a321..0a12c09d7cb2 100644</span>
<span class="p_header">--- a/crypto/gcm.c</span>
<span class="p_header">+++ b/crypto/gcm.c</span>
<span class="p_chunk">@@ -152,10 +152,8 @@</span> <span class="p_context"> static int crypto_gcm_setkey(struct crypto_aead *aead, const u8 *key,</span>
 
 	err = crypto_ablkcipher_encrypt(&amp;data-&gt;req);
 	if (err == -EINPROGRESS || err == -EBUSY) {
<span class="p_del">-		err = wait_for_completion_interruptible(</span>
<span class="p_del">-			&amp;data-&gt;result.completion);</span>
<span class="p_del">-		if (!err)</span>
<span class="p_del">-			err = data-&gt;result.err;</span>
<span class="p_add">+		wait_for_completion(&amp;data-&gt;result.completion);</span>
<span class="p_add">+		err = data-&gt;result.err;</span>
 	}
 
 	if (err)
<span class="p_header">diff --git a/drivers/char/mem.c b/drivers/char/mem.c</span>
<span class="p_header">index 0975d23031ea..2898d19fadf5 100644</span>
<span class="p_header">--- a/drivers/char/mem.c</span>
<span class="p_header">+++ b/drivers/char/mem.c</span>
<span class="p_chunk">@@ -346,7 +346,7 @@</span> <span class="p_context"> static int mmap_mem(struct file *file, struct vm_area_struct *vma)</span>
 	phys_addr_t offset = (phys_addr_t)vma-&gt;vm_pgoff &lt;&lt; PAGE_SHIFT;
 
 	/* It&#39;s illegal to wrap around the end of the physical address space. */
<span class="p_del">-	if (offset + (phys_addr_t)size &lt; offset)</span>
<span class="p_add">+	if (offset + (phys_addr_t)size - 1 &lt; offset)</span>
 		return -EINVAL;
 
 	if (!valid_mmap_phys_addr_range(vma-&gt;vm_pgoff, size))
<span class="p_header">diff --git a/drivers/char/random.c b/drivers/char/random.c</span>
<span class="p_header">index 491a4dce13fe..1822472dffab 100644</span>
<span class="p_header">--- a/drivers/char/random.c</span>
<span class="p_header">+++ b/drivers/char/random.c</span>
<span class="p_chunk">@@ -1798,13 +1798,15 @@</span> <span class="p_context"> int random_int_secret_init(void)</span>
 	return 0;
 }
 
<span class="p_add">+static DEFINE_PER_CPU(__u32 [MD5_DIGEST_WORDS], get_random_int_hash)</span>
<span class="p_add">+		__aligned(sizeof(unsigned long));</span>
<span class="p_add">+</span>
 /*
  * Get a random word for internal kernel use only. Similar to urandom but
  * with the goal of minimal entropy pool depletion. As a result, the random
  * value is not cryptographically secure but for several uses the cost of
  * depleting entropy is too high
  */
<span class="p_del">-static DEFINE_PER_CPU(__u32 [MD5_DIGEST_WORDS], get_random_int_hash);</span>
 unsigned int get_random_int(void)
 {
 	__u32 *hash;
<span class="p_chunk">@@ -1825,6 +1827,28 @@</span> <span class="p_context"> unsigned int get_random_int(void)</span>
 EXPORT_SYMBOL(get_random_int);
 
 /*
<span class="p_add">+ * Same as get_random_int(), but returns unsigned long.</span>
<span class="p_add">+ */</span>
<span class="p_add">+unsigned long get_random_long(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	__u32 *hash;</span>
<span class="p_add">+	unsigned long ret;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (arch_get_random_long(&amp;ret))</span>
<span class="p_add">+		return ret;</span>
<span class="p_add">+</span>
<span class="p_add">+	hash = get_cpu_var(get_random_int_hash);</span>
<span class="p_add">+</span>
<span class="p_add">+	hash[0] += current-&gt;pid + jiffies + random_get_entropy();</span>
<span class="p_add">+	md5_transform(hash, random_int_secret);</span>
<span class="p_add">+	ret = *(unsigned long *)hash;</span>
<span class="p_add">+	put_cpu_var(get_random_int_hash);</span>
<span class="p_add">+</span>
<span class="p_add">+	return ret;</span>
<span class="p_add">+}</span>
<span class="p_add">+EXPORT_SYMBOL(get_random_long);</span>
<span class="p_add">+</span>
<span class="p_add">+/*</span>
  * randomize_range() returns a start address such that
  *
  *    [...... &lt;range&gt; .....]
<span class="p_header">diff --git a/drivers/cpufreq/cpufreq.c b/drivers/cpufreq/cpufreq.c</span>
<span class="p_header">index 38b363f4316b..ebed319657e7 100644</span>
<span class="p_header">--- a/drivers/cpufreq/cpufreq.c</span>
<span class="p_header">+++ b/drivers/cpufreq/cpufreq.c</span>
<span class="p_chunk">@@ -2451,6 +2451,7 @@</span> <span class="p_context"> int cpufreq_register_driver(struct cpufreq_driver *driver_data)</span>
 	if (!(cpufreq_driver-&gt;flags &amp; CPUFREQ_STICKY) &amp;&amp;
 	    list_empty(&amp;cpufreq_policy_list)) {
 		/* if all -&gt;init() calls failed, unregister */
<span class="p_add">+		ret = -ENODEV;</span>
 		pr_debug(&quot;%s: No CPU initialized for driver %s\n&quot;, __func__,
 			 driver_data-&gt;name);
 		goto err_if_unreg;
<span class="p_header">diff --git a/drivers/dma/ep93xx_dma.c b/drivers/dma/ep93xx_dma.c</span>
<span class="p_header">index 57ff46284f15..c97336a2ba92 100644</span>
<span class="p_header">--- a/drivers/dma/ep93xx_dma.c</span>
<span class="p_header">+++ b/drivers/dma/ep93xx_dma.c</span>
<span class="p_chunk">@@ -325,6 +325,8 @@</span> <span class="p_context"> static int m2p_hw_setup(struct ep93xx_dma_chan *edmac)</span>
 		| M2P_CONTROL_ENABLE;
 	m2p_set_control(edmac, control);
 
<span class="p_add">+	edmac-&gt;buffer = 0;</span>
<span class="p_add">+</span>
 	return 0;
 }
 
<span class="p_header">diff --git a/drivers/dma/sh/usb-dmac.c b/drivers/dma/sh/usb-dmac.c</span>
<span class="p_header">index b1bc945f008f..56410ea75ac5 100644</span>
<span class="p_header">--- a/drivers/dma/sh/usb-dmac.c</span>
<span class="p_header">+++ b/drivers/dma/sh/usb-dmac.c</span>
<span class="p_chunk">@@ -117,7 +117,7 @@</span> <span class="p_context"> struct usb_dmac {</span>
 #define USB_DMASWR			0x0008
 #define USB_DMASWR_SWR			(1 &lt;&lt; 0)
 #define USB_DMAOR			0x0060
<span class="p_del">-#define USB_DMAOR_AE			(1 &lt;&lt; 2)</span>
<span class="p_add">+#define USB_DMAOR_AE			(1 &lt;&lt; 1)</span>
 #define USB_DMAOR_DME			(1 &lt;&lt; 0)
 
 #define USB_DMASAR			0x0000
<span class="p_header">diff --git a/drivers/gpu/drm/amd/amdgpu/ci_dpm.c b/drivers/gpu/drm/amd/amdgpu/ci_dpm.c</span>
<span class="p_header">index 57a2e347f04d..0f0094b58d1f 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/amd/amdgpu/ci_dpm.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/amd/amdgpu/ci_dpm.c</span>
<span class="p_chunk">@@ -893,6 +893,12 @@</span> <span class="p_context"> static bool ci_dpm_vblank_too_short(struct amdgpu_device *adev)</span>
 	u32 vblank_time = amdgpu_dpm_get_vblank_time(adev);
 	u32 switch_limit = adev-&gt;mc.vram_type == AMDGPU_VRAM_TYPE_GDDR5 ? 450 : 300;
 
<span class="p_add">+	/* disable mclk switching if the refresh is &gt;120Hz, even if the</span>
<span class="p_add">+	 * blanking period would allow it</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	if (amdgpu_dpm_get_vrefresh(adev) &gt; 120)</span>
<span class="p_add">+		return true;</span>
<span class="p_add">+</span>
 	if (vblank_time &lt; switch_limit)
 		return true;
 	else
<span class="p_header">diff --git a/drivers/gpu/drm/msm/msm_drv.c b/drivers/gpu/drm/msm/msm_drv.c</span>
<span class="p_header">index b88ce514eb8e..24d45fc7716c 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/msm/msm_drv.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/msm/msm_drv.c</span>
<span class="p_chunk">@@ -986,6 +986,7 @@</span> <span class="p_context"> static struct drm_driver msm_driver = {</span>
 	.prime_fd_to_handle = drm_gem_prime_fd_to_handle,
 	.gem_prime_export   = drm_gem_prime_export,
 	.gem_prime_import   = drm_gem_prime_import,
<span class="p_add">+	.gem_prime_res_obj  = msm_gem_prime_res_obj,</span>
 	.gem_prime_pin      = msm_gem_prime_pin,
 	.gem_prime_unpin    = msm_gem_prime_unpin,
 	.gem_prime_get_sg_table = msm_gem_prime_get_sg_table,
<span class="p_header">diff --git a/drivers/gpu/drm/msm/msm_drv.h b/drivers/gpu/drm/msm/msm_drv.h</span>
<span class="p_header">index 3be7a56b14f1..026e156e519c 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/msm/msm_drv.h</span>
<span class="p_header">+++ b/drivers/gpu/drm/msm/msm_drv.h</span>
<span class="p_chunk">@@ -212,6 +212,7 @@</span> <span class="p_context"> struct sg_table *msm_gem_prime_get_sg_table(struct drm_gem_object *obj);</span>
 void *msm_gem_prime_vmap(struct drm_gem_object *obj);
 void msm_gem_prime_vunmap(struct drm_gem_object *obj, void *vaddr);
 int msm_gem_prime_mmap(struct drm_gem_object *obj, struct vm_area_struct *vma);
<span class="p_add">+struct reservation_object *msm_gem_prime_res_obj(struct drm_gem_object *obj);</span>
 struct drm_gem_object *msm_gem_prime_import_sg_table(struct drm_device *dev,
 		struct dma_buf_attachment *attach, struct sg_table *sg);
 int msm_gem_prime_pin(struct drm_gem_object *obj);
<span class="p_header">diff --git a/drivers/gpu/drm/msm/msm_gem_prime.c b/drivers/gpu/drm/msm/msm_gem_prime.c</span>
<span class="p_header">index 121975b07cd4..1fbddc5c7281 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/msm/msm_gem_prime.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/msm/msm_gem_prime.c</span>
<span class="p_chunk">@@ -70,3 +70,10 @@</span> <span class="p_context"> void msm_gem_prime_unpin(struct drm_gem_object *obj)</span>
 	if (!obj-&gt;import_attach)
 		msm_gem_put_pages(obj);
 }
<span class="p_add">+</span>
<span class="p_add">+struct reservation_object *msm_gem_prime_res_obj(struct drm_gem_object *obj)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct msm_gem_object *msm_obj = to_msm_bo(obj);</span>
<span class="p_add">+</span>
<span class="p_add">+	return msm_obj-&gt;resv;</span>
<span class="p_add">+}</span>
<span class="p_header">diff --git a/drivers/gpu/drm/nouveau/include/nvkm/subdev/timer.h b/drivers/gpu/drm/nouveau/include/nvkm/subdev/timer.h</span>
<span class="p_header">index 82d3e28918fd..7e4f24ae7de8 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/nouveau/include/nvkm/subdev/timer.h</span>
<span class="p_header">+++ b/drivers/gpu/drm/nouveau/include/nvkm/subdev/timer.h</span>
<span class="p_chunk">@@ -4,6 +4,7 @@</span> <span class="p_context"></span>
 
 struct nvkm_alarm {
 	struct list_head head;
<span class="p_add">+	struct list_head exec;</span>
 	u64 timestamp;
 	void (*func)(struct nvkm_alarm *);
 };
<span class="p_header">diff --git a/drivers/gpu/drm/nouveau/nvkm/subdev/timer/base.c b/drivers/gpu/drm/nouveau/nvkm/subdev/timer/base.c</span>
<span class="p_header">index 79fcdb43e174..46033909d950 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/nouveau/nvkm/subdev/timer/base.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/nouveau/nvkm/subdev/timer/base.c</span>
<span class="p_chunk">@@ -50,7 +50,8 @@</span> <span class="p_context"> nvkm_timer_alarm_trigger(struct nvkm_timer *tmr)</span>
 		/* Move to completed list.  We&#39;ll drop the lock before
 		 * executing the callback so it can reschedule itself.
 		 */
<span class="p_del">-		list_move_tail(&amp;alarm-&gt;head, &amp;exec);</span>
<span class="p_add">+		list_del_init(&amp;alarm-&gt;head);</span>
<span class="p_add">+		list_add(&amp;alarm-&gt;exec, &amp;exec);</span>
 	}
 
 	/* Shut down interrupt if no more pending alarms. */
<span class="p_chunk">@@ -59,8 +60,8 @@</span> <span class="p_context"> nvkm_timer_alarm_trigger(struct nvkm_timer *tmr)</span>
 	spin_unlock_irqrestore(&amp;tmr-&gt;lock, flags);
 
 	/* Execute completed callbacks. */
<span class="p_del">-	list_for_each_entry_safe(alarm, atemp, &amp;exec, head) {</span>
<span class="p_del">-		list_del_init(&amp;alarm-&gt;head);</span>
<span class="p_add">+	list_for_each_entry_safe(alarm, atemp, &amp;exec, exec) {</span>
<span class="p_add">+		list_del(&amp;alarm-&gt;exec);</span>
 		alarm-&gt;func(alarm);
 	}
 }
<span class="p_header">diff --git a/drivers/gpu/drm/vmwgfx/vmwgfx_fifo.c b/drivers/gpu/drm/vmwgfx/vmwgfx_fifo.c</span>
<span class="p_header">index b6a0806b06bf..a1c68e6a689e 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/vmwgfx/vmwgfx_fifo.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/vmwgfx/vmwgfx_fifo.c</span>
<span class="p_chunk">@@ -368,6 +368,8 @@</span> <span class="p_context"> static void *vmw_local_fifo_reserve(struct vmw_private *dev_priv,</span>
 				return fifo_state-&gt;static_buffer;
 			else {
 				fifo_state-&gt;dynamic_buffer = vmalloc(bytes);
<span class="p_add">+				if (!fifo_state-&gt;dynamic_buffer)</span>
<span class="p_add">+					goto out_err;</span>
 				return fifo_state-&gt;dynamic_buffer;
 			}
 		}
<span class="p_header">diff --git a/drivers/gpu/drm/vmwgfx/vmwgfx_surface.c b/drivers/gpu/drm/vmwgfx/vmwgfx_surface.c</span>
<span class="p_header">index c9c04ccccdd9..027987023400 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/vmwgfx/vmwgfx_surface.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/vmwgfx/vmwgfx_surface.c</span>
<span class="p_chunk">@@ -1288,11 +1288,14 @@</span> <span class="p_context"> int vmw_gb_surface_define_ioctl(struct drm_device *dev, void *data,</span>
 	struct ttm_object_file *tfile = vmw_fpriv(file_priv)-&gt;tfile;
 	int ret;
 	uint32_t size;
<span class="p_del">-	uint32_t backup_handle;</span>
<span class="p_add">+	uint32_t backup_handle = 0;</span>
 
 	if (req-&gt;multisample_count != 0)
 		return -EINVAL;
 
<span class="p_add">+	if (req-&gt;mip_levels &gt; DRM_VMW_MAX_MIP_LEVELS)</span>
<span class="p_add">+		return -EINVAL;</span>
<span class="p_add">+</span>
 	if (unlikely(vmw_user_surface_size == 0))
 		vmw_user_surface_size = ttm_round_pot(sizeof(*user_srf)) +
 			128;
<span class="p_chunk">@@ -1328,12 +1331,16 @@</span> <span class="p_context"> int vmw_gb_surface_define_ioctl(struct drm_device *dev, void *data,</span>
 		ret = vmw_user_dmabuf_lookup(tfile, req-&gt;buffer_handle,
 					     &amp;res-&gt;backup,
 					     &amp;user_srf-&gt;backup_base);
<span class="p_del">-		if (ret == 0 &amp;&amp; res-&gt;backup-&gt;base.num_pages * PAGE_SIZE &lt;</span>
<span class="p_del">-		    res-&gt;backup_size) {</span>
<span class="p_del">-			DRM_ERROR(&quot;Surface backup buffer is too small.\n&quot;);</span>
<span class="p_del">-			vmw_dmabuf_unreference(&amp;res-&gt;backup);</span>
<span class="p_del">-			ret = -EINVAL;</span>
<span class="p_del">-			goto out_unlock;</span>
<span class="p_add">+		if (ret == 0) {</span>
<span class="p_add">+			if (res-&gt;backup-&gt;base.num_pages * PAGE_SIZE &lt;</span>
<span class="p_add">+			    res-&gt;backup_size) {</span>
<span class="p_add">+				DRM_ERROR(&quot;Surface backup buffer is too small.\n&quot;);</span>
<span class="p_add">+				vmw_dmabuf_unreference(&amp;res-&gt;backup);</span>
<span class="p_add">+				ret = -EINVAL;</span>
<span class="p_add">+				goto out_unlock;</span>
<span class="p_add">+			} else {</span>
<span class="p_add">+				backup_handle = req-&gt;buffer_handle;</span>
<span class="p_add">+			}</span>
 		}
 	} else if (req-&gt;drm_surface_flags &amp; drm_vmw_surface_flag_create_buffer)
 		ret = vmw_user_dmabuf_alloc(dev_priv, tfile,
<span class="p_header">diff --git a/drivers/iio/light/ltr501.c b/drivers/iio/light/ltr501.c</span>
<span class="p_header">index 6bf89d8f3741..b9d1e5c58ec5 100644</span>
<span class="p_header">--- a/drivers/iio/light/ltr501.c</span>
<span class="p_header">+++ b/drivers/iio/light/ltr501.c</span>
<span class="p_chunk">@@ -74,9 +74,9 @@</span> <span class="p_context"> static const int int_time_mapping[] = {100000, 50000, 200000, 400000};</span>
 static const struct reg_field reg_field_it =
 				REG_FIELD(LTR501_ALS_MEAS_RATE, 3, 4);
 static const struct reg_field reg_field_als_intr =
<span class="p_del">-				REG_FIELD(LTR501_INTR, 0, 0);</span>
<span class="p_del">-static const struct reg_field reg_field_ps_intr =</span>
 				REG_FIELD(LTR501_INTR, 1, 1);
<span class="p_add">+static const struct reg_field reg_field_ps_intr =</span>
<span class="p_add">+				REG_FIELD(LTR501_INTR, 0, 0);</span>
 static const struct reg_field reg_field_als_rate =
 				REG_FIELD(LTR501_ALS_MEAS_RATE, 0, 2);
 static const struct reg_field reg_field_ps_rate =
<span class="p_header">diff --git a/drivers/iio/proximity/as3935.c b/drivers/iio/proximity/as3935.c</span>
<span class="p_header">index bf0bd7e03aff..9e6d1cdb7fcd 100644</span>
<span class="p_header">--- a/drivers/iio/proximity/as3935.c</span>
<span class="p_header">+++ b/drivers/iio/proximity/as3935.c</span>
<span class="p_chunk">@@ -40,9 +40,9 @@</span> <span class="p_context"></span>
 #define AS3935_AFE_PWR_BIT	BIT(0)
 
 #define AS3935_INT		0x03
<span class="p_del">-#define AS3935_INT_MASK		0x07</span>
<span class="p_add">+#define AS3935_INT_MASK		0x0f</span>
 #define AS3935_EVENT_INT	BIT(3)
<span class="p_del">-#define AS3935_NOISE_INT	BIT(1)</span>
<span class="p_add">+#define AS3935_NOISE_INT	BIT(0)</span>
 
 #define AS3935_DATA		0x07
 #define AS3935_DATA_MASK	0x3F
<span class="p_header">diff --git a/drivers/infiniband/hw/qib/qib_rc.c b/drivers/infiniband/hw/qib/qib_rc.c</span>
<span class="p_header">index e6b7556d5221..cbc4216091c9 100644</span>
<span class="p_header">--- a/drivers/infiniband/hw/qib/qib_rc.c</span>
<span class="p_header">+++ b/drivers/infiniband/hw/qib/qib_rc.c</span>
<span class="p_chunk">@@ -2088,8 +2088,10 @@</span> <span class="p_context"> send_last:</span>
 		ret = qib_get_rwqe(qp, 1);
 		if (ret &lt; 0)
 			goto nack_op_err;
<span class="p_del">-		if (!ret)</span>
<span class="p_add">+		if (!ret) {</span>
<span class="p_add">+			qib_put_ss(&amp;qp-&gt;r_sge);</span>
 			goto rnr_nak;
<span class="p_add">+		}</span>
 		wc.ex.imm_data = ohdr-&gt;u.rc.imm_data;
 		hdrsize += 4;
 		wc.wc_flags = IB_WC_WITH_IMM;
<span class="p_header">diff --git a/drivers/input/mouse/elantech.c b/drivers/input/mouse/elantech.c</span>
<span class="p_header">index 1a2b2620421e..6f4dc0fd2ca3 100644</span>
<span class="p_header">--- a/drivers/input/mouse/elantech.c</span>
<span class="p_header">+++ b/drivers/input/mouse/elantech.c</span>
<span class="p_chunk">@@ -1122,8 +1122,10 @@</span> <span class="p_context"> static int elantech_get_resolution_v4(struct psmouse *psmouse,</span>
  * Asus UX32VD             0x361f02        00, 15, 0e      clickpad
  * Avatar AVIU-145A2       0x361f00        ?               clickpad
  * Fujitsu LIFEBOOK E544   0x470f00        d0, 12, 09      2 hw buttons
<span class="p_add">+ * Fujitsu LIFEBOOK E546   0x470f00        50, 12, 09      2 hw buttons</span>
  * Fujitsu LIFEBOOK E547   0x470f00        50, 12, 09      2 hw buttons
  * Fujitsu LIFEBOOK E554   0x570f01        40, 14, 0c      2 hw buttons
<span class="p_add">+ * Fujitsu LIFEBOOK E557   0x570f01        40, 14, 0c      2 hw buttons</span>
  * Fujitsu T725            0x470f01        05, 12, 09      2 hw buttons
  * Fujitsu H730            0x570f00        c0, 14, 0c      3 hw buttons (**)
  * Gigabyte U2442          0x450f01        58, 17, 0c      2 hw buttons
<span class="p_chunk">@@ -1529,6 +1531,13 @@</span> <span class="p_context"> static const struct dmi_system_id elantech_dmi_force_crc_enabled[] = {</span>
 		},
 	},
 	{
<span class="p_add">+		/* Fujitsu LIFEBOOK E546  does not work with crc_enabled == 0 */</span>
<span class="p_add">+		.matches = {</span>
<span class="p_add">+			DMI_MATCH(DMI_SYS_VENDOR, &quot;FUJITSU&quot;),</span>
<span class="p_add">+			DMI_MATCH(DMI_PRODUCT_NAME, &quot;LIFEBOOK E546&quot;),</span>
<span class="p_add">+		},</span>
<span class="p_add">+	},</span>
<span class="p_add">+	{</span>
 		/* Fujitsu LIFEBOOK E547 does not work with crc_enabled == 0 */
 		.matches = {
 			DMI_MATCH(DMI_SYS_VENDOR, &quot;FUJITSU&quot;),
<span class="p_chunk">@@ -1550,6 +1559,13 @@</span> <span class="p_context"> static const struct dmi_system_id elantech_dmi_force_crc_enabled[] = {</span>
 		},
 	},
 	{
<span class="p_add">+		/* Fujitsu LIFEBOOK E557 does not work with crc_enabled == 0 */</span>
<span class="p_add">+		.matches = {</span>
<span class="p_add">+			DMI_MATCH(DMI_SYS_VENDOR, &quot;FUJITSU&quot;),</span>
<span class="p_add">+			DMI_MATCH(DMI_PRODUCT_NAME, &quot;LIFEBOOK E557&quot;),</span>
<span class="p_add">+		},</span>
<span class="p_add">+	},</span>
<span class="p_add">+	{</span>
 		/* Fujitsu LIFEBOOK U745 does not work with crc_enabled == 0 */
 		.matches = {
 			DMI_MATCH(DMI_SYS_VENDOR, &quot;FUJITSU&quot;),
<span class="p_header">diff --git a/drivers/misc/cxl/file.c b/drivers/misc/cxl/file.c</span>
<span class="p_header">index 783337d22f36..10a02934bfc0 100644</span>
<span class="p_header">--- a/drivers/misc/cxl/file.c</span>
<span class="p_header">+++ b/drivers/misc/cxl/file.c</span>
<span class="p_chunk">@@ -158,11 +158,8 @@</span> <span class="p_context"> static long afu_ioctl_start_work(struct cxl_context *ctx,</span>
 
 	/* Do this outside the status_mutex to avoid a circular dependency with
 	 * the locking in cxl_mmap_fault() */
<span class="p_del">-	if (copy_from_user(&amp;work, uwork,</span>
<span class="p_del">-			   sizeof(struct cxl_ioctl_start_work))) {</span>
<span class="p_del">-		rc = -EFAULT;</span>
<span class="p_del">-		goto out;</span>
<span class="p_del">-	}</span>
<span class="p_add">+	if (copy_from_user(&amp;work, uwork, sizeof(work)))</span>
<span class="p_add">+		return -EFAULT;</span>
 
 	mutex_lock(&amp;ctx-&gt;status_mutex);
 	if (ctx-&gt;status != OPENED) {
<span class="p_header">diff --git a/drivers/net/ethernet/broadcom/bnx2x/bnx2x_cmn.c b/drivers/net/ethernet/broadcom/bnx2x/bnx2x_cmn.c</span>
<span class="p_header">index c82ab87fcbe8..e5911ccb2148 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/broadcom/bnx2x/bnx2x_cmn.c</span>
<span class="p_header">+++ b/drivers/net/ethernet/broadcom/bnx2x/bnx2x_cmn.c</span>
<span class="p_chunk">@@ -1949,7 +1949,7 @@</span> <span class="p_context"> u16 bnx2x_select_queue(struct net_device *dev, struct sk_buff *skb,</span>
 	}
 
 	/* select a non-FCoE queue */
<span class="p_del">-	return fallback(dev, skb) % BNX2X_NUM_ETH_QUEUES(bp);</span>
<span class="p_add">+	return fallback(dev, skb) % (BNX2X_NUM_ETH_QUEUES(bp) * bp-&gt;max_cos);</span>
 }
 
 void bnx2x_set_num_queues(struct bnx2x *bp)
<span class="p_header">diff --git a/drivers/net/ethernet/chelsio/cxgb4/cxgb4_main.c b/drivers/net/ethernet/chelsio/cxgb4/cxgb4_main.c</span>
<span class="p_header">index 0d147610a06f..090e00650601 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/chelsio/cxgb4/cxgb4_main.c</span>
<span class="p_header">+++ b/drivers/net/ethernet/chelsio/cxgb4/cxgb4_main.c</span>
<span class="p_chunk">@@ -2714,10 +2714,14 @@</span> <span class="p_context"> static int cxgb_up(struct adapter *adap)</span>
 		if (err)
 			goto irq_err;
 	}
<span class="p_add">+</span>
<span class="p_add">+	mutex_lock(&amp;uld_mutex);</span>
 	enable_rx(adap);
 	t4_sge_start(adap);
 	t4_intr_enable(adap);
 	adap-&gt;flags |= FULL_INIT_DONE;
<span class="p_add">+	mutex_unlock(&amp;uld_mutex);</span>
<span class="p_add">+</span>
 	notify_ulds(adap, CXGB4_STATE_UP);
 #if IS_ENABLED(CONFIG_IPV6)
 	update_clip(adap);
<span class="p_header">diff --git a/drivers/net/ethernet/ethoc.c b/drivers/net/ethernet/ethoc.c</span>
<span class="p_header">index ff665493ca97..52f2230062e7 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/ethoc.c</span>
<span class="p_header">+++ b/drivers/net/ethernet/ethoc.c</span>
<span class="p_chunk">@@ -713,6 +713,8 @@</span> <span class="p_context"> static int ethoc_open(struct net_device *dev)</span>
 	if (ret)
 		return ret;
 
<span class="p_add">+	napi_enable(&amp;priv-&gt;napi);</span>
<span class="p_add">+</span>
 	ethoc_init_ring(priv, dev-&gt;mem_start);
 	ethoc_reset(priv);
 
<span class="p_chunk">@@ -725,7 +727,6 @@</span> <span class="p_context"> static int ethoc_open(struct net_device *dev)</span>
 	}
 
 	phy_start(priv-&gt;phy);
<span class="p_del">-	napi_enable(&amp;priv-&gt;napi);</span>
 
 	if (netif_msg_ifup(priv)) {
 		dev_info(&amp;dev-&gt;dev, &quot;I/O: %08lx Memory: %08lx-%08lx\n&quot;,
<span class="p_header">diff --git a/drivers/net/vxlan.c b/drivers/net/vxlan.c</span>
<span class="p_header">index 590750ab6564..9a986ccd42e5 100644</span>
<span class="p_header">--- a/drivers/net/vxlan.c</span>
<span class="p_header">+++ b/drivers/net/vxlan.c</span>
<span class="p_chunk">@@ -77,6 +77,8 @@</span> <span class="p_context"> static const u8 all_zeros_mac[ETH_ALEN];</span>
 
 static int vxlan_sock_add(struct vxlan_dev *vxlan);
 
<span class="p_add">+static void vxlan_vs_del_dev(struct vxlan_dev *vxlan);</span>
<span class="p_add">+</span>
 /* per-network namespace private data for this module */
 struct vxlan_net {
 	struct list_head  vxlan_list;
<span class="p_chunk">@@ -1052,6 +1054,8 @@</span> <span class="p_context"> static void __vxlan_sock_release(struct vxlan_sock *vs)</span>
 
 static void vxlan_sock_release(struct vxlan_dev *vxlan)
 {
<span class="p_add">+	vxlan_vs_del_dev(vxlan);</span>
<span class="p_add">+</span>
 	__vxlan_sock_release(vxlan-&gt;vn4_sock);
 #if IS_ENABLED(CONFIG_IPV6)
 	__vxlan_sock_release(vxlan-&gt;vn6_sock);
<span class="p_chunk">@@ -2255,6 +2259,15 @@</span> <span class="p_context"> static void vxlan_cleanup(unsigned long arg)</span>
 	mod_timer(&amp;vxlan-&gt;age_timer, next_timer);
 }
 
<span class="p_add">+static void vxlan_vs_del_dev(struct vxlan_dev *vxlan)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct vxlan_net *vn = net_generic(vxlan-&gt;net, vxlan_net_id);</span>
<span class="p_add">+</span>
<span class="p_add">+	spin_lock(&amp;vn-&gt;sock_lock);</span>
<span class="p_add">+	hlist_del_init_rcu(&amp;vxlan-&gt;hlist);</span>
<span class="p_add">+	spin_unlock(&amp;vn-&gt;sock_lock);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static void vxlan_vs_add_dev(struct vxlan_sock *vs, struct vxlan_dev *vxlan)
 {
 	struct vxlan_net *vn = net_generic(vxlan-&gt;net, vxlan_net_id);
<span class="p_chunk">@@ -3028,12 +3041,6 @@</span> <span class="p_context"> static int vxlan_newlink(struct net *src_net, struct net_device *dev,</span>
 static void vxlan_dellink(struct net_device *dev, struct list_head *head)
 {
 	struct vxlan_dev *vxlan = netdev_priv(dev);
<span class="p_del">-	struct vxlan_net *vn = net_generic(vxlan-&gt;net, vxlan_net_id);</span>
<span class="p_del">-</span>
<span class="p_del">-	spin_lock(&amp;vn-&gt;sock_lock);</span>
<span class="p_del">-	if (!hlist_unhashed(&amp;vxlan-&gt;hlist))</span>
<span class="p_del">-		hlist_del_rcu(&amp;vxlan-&gt;hlist);</span>
<span class="p_del">-	spin_unlock(&amp;vn-&gt;sock_lock);</span>
 
 	gro_cells_destroy(&amp;vxlan-&gt;gro_cells);
 	list_del(&amp;vxlan-&gt;next);
<span class="p_header">diff --git a/drivers/net/xen-netfront.c b/drivers/net/xen-netfront.c</span>
<span class="p_header">index 1f445f357da1..888e9cfef51a 100644</span>
<span class="p_header">--- a/drivers/net/xen-netfront.c</span>
<span class="p_header">+++ b/drivers/net/xen-netfront.c</span>
<span class="p_chunk">@@ -304,7 +304,7 @@</span> <span class="p_context"> static void xennet_alloc_rx_buffers(struct netfront_queue *queue)</span>
 		queue-&gt;rx_skbs[id] = skb;
 
 		ref = gnttab_claim_grant_reference(&amp;queue-&gt;gref_rx_head);
<span class="p_del">-		BUG_ON((signed short)ref &lt; 0);</span>
<span class="p_add">+		WARN_ON_ONCE(IS_ERR_VALUE((unsigned long)(int)ref));</span>
 		queue-&gt;grant_rx_ref[id] = ref;
 
 		page = skb_frag_page(&amp;skb_shinfo(skb)-&gt;frags[0]);
<span class="p_chunk">@@ -437,7 +437,7 @@</span> <span class="p_context"> static void xennet_tx_setup_grant(unsigned long gfn, unsigned int offset,</span>
 	id = get_id_from_freelist(&amp;queue-&gt;tx_skb_freelist, queue-&gt;tx_skbs);
 	tx = RING_GET_REQUEST(&amp;queue-&gt;tx, queue-&gt;tx.req_prod_pvt++);
 	ref = gnttab_claim_grant_reference(&amp;queue-&gt;gref_tx_head);
<span class="p_del">-	BUG_ON((signed short)ref &lt; 0);</span>
<span class="p_add">+	WARN_ON_ONCE(IS_ERR_VALUE((unsigned long)(int)ref));</span>
 
 	gnttab_grant_foreign_access_ref(ref, queue-&gt;info-&gt;xbdev-&gt;otherend_id,
 					gfn, GNTMAP_readonly);
<span class="p_header">diff --git a/drivers/scsi/qla2xxx/qla_os.c b/drivers/scsi/qla2xxx/qla_os.c</span>
<span class="p_header">index 3588a56aabb4..5cbf20ab94aa 100644</span>
<span class="p_header">--- a/drivers/scsi/qla2xxx/qla_os.c</span>
<span class="p_header">+++ b/drivers/scsi/qla2xxx/qla_os.c</span>
<span class="p_chunk">@@ -2311,10 +2311,10 @@</span> <span class="p_context"> qla2x00_probe_one(struct pci_dev *pdev, const struct pci_device_id *id)</span>
 
 	if (mem_only) {
 		if (pci_enable_device_mem(pdev))
<span class="p_del">-			goto probe_out;</span>
<span class="p_add">+			return ret;</span>
 	} else {
 		if (pci_enable_device(pdev))
<span class="p_del">-			goto probe_out;</span>
<span class="p_add">+			return ret;</span>
 	}
 
 	/* This may fail but that&#39;s ok */
<span class="p_chunk">@@ -2324,7 +2324,7 @@</span> <span class="p_context"> qla2x00_probe_one(struct pci_dev *pdev, const struct pci_device_id *id)</span>
 	if (!ha) {
 		ql_log_pci(ql_log_fatal, pdev, 0x0009,
 		    &quot;Unable to allocate memory for ha.\n&quot;);
<span class="p_del">-		goto probe_out;</span>
<span class="p_add">+		goto disable_device;</span>
 	}
 	ql_dbg_pci(ql_dbg_init, pdev, 0x000a,
 	    &quot;Memory allocated for ha=%p.\n&quot;, ha);
<span class="p_chunk">@@ -2923,7 +2923,7 @@</span> <span class="p_context"> iospace_config_failed:</span>
 	kfree(ha);
 	ha = NULL;
 
<span class="p_del">-probe_out:</span>
<span class="p_add">+disable_device:</span>
 	pci_disable_device(pdev);
 	return ret;
 }
<span class="p_header">diff --git a/drivers/staging/lustre/lustre/lov/lov_pack.c b/drivers/staging/lustre/lustre/lov/lov_pack.c</span>
<span class="p_header">index 2fb1e974cc70..e11b1001d1f6 100644</span>
<span class="p_header">--- a/drivers/staging/lustre/lustre/lov/lov_pack.c</span>
<span class="p_header">+++ b/drivers/staging/lustre/lustre/lov/lov_pack.c</span>
<span class="p_chunk">@@ -399,18 +399,10 @@</span> <span class="p_context"> int lov_getstripe(struct obd_export *exp, struct lov_stripe_md *lsm,</span>
 	struct lov_mds_md *lmmk = NULL;
 	int rc, lmm_size;
 	int lum_size;
<span class="p_del">-	mm_segment_t seg;</span>
 
 	if (!lsm)
 		return -ENODATA;
 
<span class="p_del">-	/*</span>
<span class="p_del">-	 * &quot;Switch to kernel segment&quot; to allow copying from kernel space by</span>
<span class="p_del">-	 * copy_{to,from}_user().</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	seg = get_fs();</span>
<span class="p_del">-	set_fs(KERNEL_DS);</span>
<span class="p_del">-</span>
 	/* we only need the header part from user space to get lmm_magic and
 	 * lmm_stripe_count, (the header part is common to v1 and v3) */
 	lum_size = sizeof(struct lov_user_md_v1);
<span class="p_chunk">@@ -485,6 +477,5 @@</span> <span class="p_context"> int lov_getstripe(struct obd_export *exp, struct lov_stripe_md *lsm,</span>
 
 	obd_free_diskmd(exp, &amp;lmmk);
 out_set:
<span class="p_del">-	set_fs(seg);</span>
 	return rc;
 }
<span class="p_header">diff --git a/drivers/target/target_core_transport.c b/drivers/target/target_core_transport.c</span>
<span class="p_header">index af301414a9f3..60743bf27f37 100644</span>
<span class="p_header">--- a/drivers/target/target_core_transport.c</span>
<span class="p_header">+++ b/drivers/target/target_core_transport.c</span>
<span class="p_chunk">@@ -1154,15 +1154,28 @@</span> <span class="p_context"> target_cmd_size_check(struct se_cmd *cmd, unsigned int size)</span>
 	if (cmd-&gt;unknown_data_length) {
 		cmd-&gt;data_length = size;
 	} else if (size != cmd-&gt;data_length) {
<span class="p_del">-		pr_warn(&quot;TARGET_CORE[%s]: Expected Transfer Length:&quot;</span>
<span class="p_add">+		pr_warn_ratelimited(&quot;TARGET_CORE[%s]: Expected Transfer Length:&quot;</span>
 			&quot; %u does not match SCSI CDB Length: %u for SAM Opcode:&quot;
 			&quot; 0x%02x\n&quot;, cmd-&gt;se_tfo-&gt;get_fabric_name(),
 				cmd-&gt;data_length, size, cmd-&gt;t_task_cdb[0]);
 
<span class="p_del">-		if (cmd-&gt;data_direction == DMA_TO_DEVICE &amp;&amp;</span>
<span class="p_del">-		    cmd-&gt;se_cmd_flags &amp; SCF_SCSI_DATA_CDB) {</span>
<span class="p_del">-			pr_err(&quot;Rejecting underflow/overflow WRITE data\n&quot;);</span>
<span class="p_del">-			return TCM_INVALID_CDB_FIELD;</span>
<span class="p_add">+		if (cmd-&gt;data_direction == DMA_TO_DEVICE) {</span>
<span class="p_add">+			if (cmd-&gt;se_cmd_flags &amp; SCF_SCSI_DATA_CDB) {</span>
<span class="p_add">+				pr_err_ratelimited(&quot;Rejecting underflow/overflow&quot;</span>
<span class="p_add">+						   &quot; for WRITE data CDB\n&quot;);</span>
<span class="p_add">+				return TCM_INVALID_CDB_FIELD;</span>
<span class="p_add">+			}</span>
<span class="p_add">+			/*</span>
<span class="p_add">+			 * Some fabric drivers like iscsi-target still expect to</span>
<span class="p_add">+			 * always reject overflow writes.  Reject this case until</span>
<span class="p_add">+			 * full fabric driver level support for overflow writes</span>
<span class="p_add">+			 * is introduced tree-wide.</span>
<span class="p_add">+			 */</span>
<span class="p_add">+			if (size &gt; cmd-&gt;data_length) {</span>
<span class="p_add">+				pr_err_ratelimited(&quot;Rejecting overflow for&quot;</span>
<span class="p_add">+						   &quot; WRITE control CDB\n&quot;);</span>
<span class="p_add">+				return TCM_INVALID_CDB_FIELD;</span>
<span class="p_add">+			}</span>
 		}
 		/*
 		 * Reject READ_* or WRITE_* with overflow/underflow for
<span class="p_header">diff --git a/drivers/tty/serial/ifx6x60.c b/drivers/tty/serial/ifx6x60.c</span>
<span class="p_header">index 88246f7e435a..0f23dda60011 100644</span>
<span class="p_header">--- a/drivers/tty/serial/ifx6x60.c</span>
<span class="p_header">+++ b/drivers/tty/serial/ifx6x60.c</span>
<span class="p_chunk">@@ -1378,9 +1378,9 @@</span> <span class="p_context"> static struct spi_driver ifx_spi_driver = {</span>
 static void __exit ifx_spi_exit(void)
 {
 	/* unregister */
<span class="p_add">+	spi_unregister_driver(&amp;ifx_spi_driver);</span>
 	tty_unregister_driver(tty_drv);
 	put_tty_driver(tty_drv);
<span class="p_del">-	spi_unregister_driver(&amp;ifx_spi_driver);</span>
 	unregister_reboot_notifier(&amp;ifx_modem_reboot_notifier_block);
 }
 
<span class="p_header">diff --git a/drivers/tty/serial/sh-sci.c b/drivers/tty/serial/sh-sci.c</span>
<span class="p_header">index 63a06ab6ba03..235e150d7b81 100644</span>
<span class="p_header">--- a/drivers/tty/serial/sh-sci.c</span>
<span class="p_header">+++ b/drivers/tty/serial/sh-sci.c</span>
<span class="p_chunk">@@ -1800,11 +1800,13 @@</span> <span class="p_context"> static int sci_startup(struct uart_port *port)</span>
 
 	dev_dbg(port-&gt;dev, &quot;%s(%d)\n&quot;, __func__, port-&gt;line);
 
<span class="p_add">+	sci_request_dma(port);</span>
<span class="p_add">+</span>
 	ret = sci_request_irq(s);
<span class="p_del">-	if (unlikely(ret &lt; 0))</span>
<span class="p_add">+	if (unlikely(ret &lt; 0)) {</span>
<span class="p_add">+		sci_free_dma(port);</span>
 		return ret;
<span class="p_del">-</span>
<span class="p_del">-	sci_request_dma(port);</span>
<span class="p_add">+	}</span>
 
 	spin_lock_irqsave(&amp;port-&gt;lock, flags);
 	sci_start_tx(port);
<span class="p_chunk">@@ -1834,8 +1836,8 @@</span> <span class="p_context"> static void sci_shutdown(struct uart_port *port)</span>
 	}
 #endif
 
<span class="p_del">-	sci_free_dma(port);</span>
 	sci_free_irq(s);
<span class="p_add">+	sci_free_dma(port);</span>
 }
 
 static unsigned int sci_scbrr_calc(struct sci_port *s, unsigned int bps,
<span class="p_header">diff --git a/drivers/tty/tty_io.c b/drivers/tty/tty_io.c</span>
<span class="p_header">index 7cef54334b12..1bb629ab8ecc 100644</span>
<span class="p_header">--- a/drivers/tty/tty_io.c</span>
<span class="p_header">+++ b/drivers/tty/tty_io.c</span>
<span class="p_chunk">@@ -2070,13 +2070,12 @@</span> <span class="p_context"> retry_open:</span>
 		if (tty) {
 			mutex_unlock(&amp;tty_mutex);
 			retval = tty_lock_interruptible(tty);
<span class="p_add">+			tty_kref_put(tty);  /* drop kref from tty_driver_lookup_tty() */</span>
 			if (retval) {
 				if (retval == -EINTR)
 					retval = -ERESTARTSYS;
 				goto err_unref;
 			}
<span class="p_del">-			/* safe to drop the kref from tty_driver_lookup_tty() */</span>
<span class="p_del">-			tty_kref_put(tty);</span>
 			retval = tty_reopen(tty);
 			if (retval &lt; 0) {
 				tty_unlock(tty);
<span class="p_header">diff --git a/drivers/tty/tty_mutex.c b/drivers/tty/tty_mutex.c</span>
<span class="p_header">index d09293bc0e04..cff304abb619 100644</span>
<span class="p_header">--- a/drivers/tty/tty_mutex.c</span>
<span class="p_header">+++ b/drivers/tty/tty_mutex.c</span>
<span class="p_chunk">@@ -24,10 +24,15 @@</span> <span class="p_context"> EXPORT_SYMBOL(tty_lock);</span>
 
 int tty_lock_interruptible(struct tty_struct *tty)
 {
<span class="p_add">+	int ret;</span>
<span class="p_add">+</span>
 	if (WARN(tty-&gt;magic != TTY_MAGIC, &quot;L Bad %p\n&quot;, tty))
 		return -EIO;
 	tty_kref_get(tty);
<span class="p_del">-	return mutex_lock_interruptible(&amp;tty-&gt;legacy_mutex);</span>
<span class="p_add">+	ret = mutex_lock_interruptible(&amp;tty-&gt;legacy_mutex);</span>
<span class="p_add">+	if (ret)</span>
<span class="p_add">+		tty_kref_put(tty);</span>
<span class="p_add">+	return ret;</span>
 }
 
 void __lockfunc tty_unlock(struct tty_struct *tty)
<span class="p_header">diff --git a/drivers/usb/chipidea/debug.c b/drivers/usb/chipidea/debug.c</span>
<span class="p_header">index 58c8485a0715..923379972707 100644</span>
<span class="p_header">--- a/drivers/usb/chipidea/debug.c</span>
<span class="p_header">+++ b/drivers/usb/chipidea/debug.c</span>
<span class="p_chunk">@@ -295,7 +295,8 @@</span> <span class="p_context"> static int ci_role_show(struct seq_file *s, void *data)</span>
 {
 	struct ci_hdrc *ci = s-&gt;private;
 
<span class="p_del">-	seq_printf(s, &quot;%s\n&quot;, ci_role(ci)-&gt;name);</span>
<span class="p_add">+	if (ci-&gt;role != CI_ROLE_END)</span>
<span class="p_add">+		seq_printf(s, &quot;%s\n&quot;, ci_role(ci)-&gt;name);</span>
 
 	return 0;
 }
<span class="p_header">diff --git a/drivers/usb/chipidea/udc.c b/drivers/usb/chipidea/udc.c</span>
<span class="p_header">index d8a045fc1fdb..aff086ca97e4 100644</span>
<span class="p_header">--- a/drivers/usb/chipidea/udc.c</span>
<span class="p_header">+++ b/drivers/usb/chipidea/udc.c</span>
<span class="p_chunk">@@ -1982,6 +1982,7 @@</span> <span class="p_context"> static void udc_id_switch_for_host(struct ci_hdrc *ci)</span>
 int ci_hdrc_gadget_init(struct ci_hdrc *ci)
 {
 	struct ci_role_driver *rdrv;
<span class="p_add">+	int ret;</span>
 
 	if (!hw_read(ci, CAP_DCCPARAMS, DCCPARAMS_DC))
 		return -ENXIO;
<span class="p_chunk">@@ -1994,7 +1995,10 @@</span> <span class="p_context"> int ci_hdrc_gadget_init(struct ci_hdrc *ci)</span>
 	rdrv-&gt;stop	= udc_id_switch_for_host;
 	rdrv-&gt;irq	= udc_irq;
 	rdrv-&gt;name	= &quot;gadget&quot;;
<span class="p_del">-	ci-&gt;roles[CI_ROLE_GADGET] = rdrv;</span>
 
<span class="p_del">-	return udc_start(ci);</span>
<span class="p_add">+	ret = udc_start(ci);</span>
<span class="p_add">+	if (!ret)</span>
<span class="p_add">+		ci-&gt;roles[CI_ROLE_GADGET] = rdrv;</span>
<span class="p_add">+</span>
<span class="p_add">+	return ret;</span>
 }
<span class="p_header">diff --git a/drivers/usb/gadget/function/f_mass_storage.c b/drivers/usb/gadget/function/f_mass_storage.c</span>
<span class="p_header">index a4f664062e0c..a069726da72a 100644</span>
<span class="p_header">--- a/drivers/usb/gadget/function/f_mass_storage.c</span>
<span class="p_header">+++ b/drivers/usb/gadget/function/f_mass_storage.c</span>
<span class="p_chunk">@@ -399,7 +399,11 @@</span> <span class="p_context"> static int fsg_set_halt(struct fsg_dev *fsg, struct usb_ep *ep)</span>
 /* Caller must hold fsg-&gt;lock */
 static void wakeup_thread(struct fsg_common *common)
 {
<span class="p_del">-	smp_wmb();	/* ensure the write of bh-&gt;state is complete */</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Ensure the reading of thread_wakeup_needed</span>
<span class="p_add">+	 * and the writing of bh-&gt;state are completed</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	smp_mb();</span>
 	/* Tell the main thread that something has happened */
 	common-&gt;thread_wakeup_needed = 1;
 	if (common-&gt;thread_task)
<span class="p_chunk">@@ -630,7 +634,12 @@</span> <span class="p_context"> static int sleep_thread(struct fsg_common *common, bool can_freeze)</span>
 	}
 	__set_current_state(TASK_RUNNING);
 	common-&gt;thread_wakeup_needed = 0;
<span class="p_del">-	smp_rmb();	/* ensure the latest bh-&gt;state is visible */</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Ensure the writing of thread_wakeup_needed</span>
<span class="p_add">+	 * and the reading of bh-&gt;state are completed</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	smp_mb();</span>
 	return rc;
 }
 
<span class="p_header">diff --git a/drivers/xen/privcmd.c b/drivers/xen/privcmd.c</span>
<span class="p_header">index df2e6f783318..527de56f832f 100644</span>
<span class="p_header">--- a/drivers/xen/privcmd.c</span>
<span class="p_header">+++ b/drivers/xen/privcmd.c</span>
<span class="p_chunk">@@ -335,8 +335,8 @@</span> <span class="p_context"> static int mmap_batch_fn(void *data, int nr, void *state)</span>
 				st-&gt;global_error = 1;
 		}
 	}
<span class="p_del">-	st-&gt;va += PAGE_SIZE * nr;</span>
<span class="p_del">-	st-&gt;index += nr;</span>
<span class="p_add">+	st-&gt;va += XEN_PAGE_SIZE * nr;</span>
<span class="p_add">+	st-&gt;index += nr / XEN_PFN_PER_PAGE;</span>
 
 	return 0;
 }
<span class="p_header">diff --git a/fs/btrfs/extent-tree.c b/fs/btrfs/extent-tree.c</span>
<span class="p_header">index 2a2e370399ba..c36a03fa7678 100644</span>
<span class="p_header">--- a/fs/btrfs/extent-tree.c</span>
<span class="p_header">+++ b/fs/btrfs/extent-tree.c</span>
<span class="p_chunk">@@ -3854,6 +3854,7 @@</span> <span class="p_context"> static int update_space_info(struct btrfs_fs_info *info, u64 flags,</span>
 				    info-&gt;space_info_kobj, &quot;%s&quot;,
 				    alloc_name(found-&gt;flags));
 	if (ret) {
<span class="p_add">+		percpu_counter_destroy(&amp;found-&gt;total_bytes_pinned);</span>
 		kfree(found);
 		return ret;
 	}
<span class="p_header">diff --git a/fs/btrfs/file.c b/fs/btrfs/file.c</span>
<span class="p_header">index 353f4bae658c..d4a6eef31854 100644</span>
<span class="p_header">--- a/fs/btrfs/file.c</span>
<span class="p_header">+++ b/fs/btrfs/file.c</span>
<span class="p_chunk">@@ -2771,7 +2771,7 @@</span> <span class="p_context"> static long btrfs_fallocate(struct file *file, int mode,</span>
 		if (!ret)
 			ret = btrfs_prealloc_file_range(inode, mode,
 					range-&gt;start,
<span class="p_del">-					range-&gt;len, 1 &lt;&lt; inode-&gt;i_blkbits,</span>
<span class="p_add">+					range-&gt;len, i_blocksize(inode),</span>
 					offset + len, &amp;alloc_hint);
 		list_del(&amp;range-&gt;list);
 		kfree(range);
<span class="p_header">diff --git a/fs/btrfs/inode.c b/fs/btrfs/inode.c</span>
<span class="p_header">index 3cff6523f27d..863fa0f1972b 100644</span>
<span class="p_header">--- a/fs/btrfs/inode.c</span>
<span class="p_header">+++ b/fs/btrfs/inode.c</span>
<span class="p_chunk">@@ -7318,8 +7318,8 @@</span> <span class="p_context"> bool btrfs_page_exists_in_range(struct inode *inode, loff_t start, loff_t end)</span>
 	int found = false;
 	void **pagep = NULL;
 	struct page *page = NULL;
<span class="p_del">-	int start_idx;</span>
<span class="p_del">-	int end_idx;</span>
<span class="p_add">+	unsigned long start_idx;</span>
<span class="p_add">+	unsigned long end_idx;</span>
 
 	start_idx = start &gt;&gt; PAGE_CACHE_SHIFT;
 
<span class="p_header">diff --git a/fs/buffer.c b/fs/buffer.c</span>
<span class="p_header">index 4f4cd959da7c..6f7d519a093b 100644</span>
<span class="p_header">--- a/fs/buffer.c</span>
<span class="p_header">+++ b/fs/buffer.c</span>
<span class="p_chunk">@@ -2298,7 +2298,7 @@</span> <span class="p_context"> static int cont_expand_zero(struct file *file, struct address_space *mapping,</span>
 			    loff_t pos, loff_t *bytes)
 {
 	struct inode *inode = mapping-&gt;host;
<span class="p_del">-	unsigned blocksize = 1 &lt;&lt; inode-&gt;i_blkbits;</span>
<span class="p_add">+	unsigned int blocksize = i_blocksize(inode);</span>
 	struct page *page;
 	void *fsdata;
 	pgoff_t index, curidx;
<span class="p_chunk">@@ -2378,8 +2378,8 @@</span> <span class="p_context"> int cont_write_begin(struct file *file, struct address_space *mapping,</span>
 			get_block_t *get_block, loff_t *bytes)
 {
 	struct inode *inode = mapping-&gt;host;
<span class="p_del">-	unsigned blocksize = 1 &lt;&lt; inode-&gt;i_blkbits;</span>
<span class="p_del">-	unsigned zerofrom;</span>
<span class="p_add">+	unsigned int blocksize = i_blocksize(inode);</span>
<span class="p_add">+	unsigned int zerofrom;</span>
 	int err;
 
 	err = cont_expand_zero(file, mapping, pos, bytes);
<span class="p_chunk">@@ -2741,7 +2741,7 @@</span> <span class="p_context"> int nobh_truncate_page(struct address_space *mapping,</span>
 	struct buffer_head map_bh;
 	int err;
 
<span class="p_del">-	blocksize = 1 &lt;&lt; inode-&gt;i_blkbits;</span>
<span class="p_add">+	blocksize = i_blocksize(inode);</span>
 	length = offset &amp; (blocksize - 1);
 
 	/* Block boundary? Nothing to do */
<span class="p_chunk">@@ -2819,7 +2819,7 @@</span> <span class="p_context"> int block_truncate_page(struct address_space *mapping,</span>
 	struct buffer_head *bh;
 	int err;
 
<span class="p_del">-	blocksize = 1 &lt;&lt; inode-&gt;i_blkbits;</span>
<span class="p_add">+	blocksize = i_blocksize(inode);</span>
 	length = offset &amp; (blocksize - 1);
 
 	/* Block boundary? Nothing to do */
<span class="p_chunk">@@ -2931,7 +2931,7 @@</span> <span class="p_context"> sector_t generic_block_bmap(struct address_space *mapping, sector_t block,</span>
 	struct inode *inode = mapping-&gt;host;
 	tmp.b_state = 0;
 	tmp.b_blocknr = 0;
<span class="p_del">-	tmp.b_size = 1 &lt;&lt; inode-&gt;i_blkbits;</span>
<span class="p_add">+	tmp.b_size = i_blocksize(inode);</span>
 	get_block(inode, block, &amp;tmp, 0);
 	return tmp.b_blocknr;
 }
<span class="p_header">diff --git a/fs/ceph/addr.c b/fs/ceph/addr.c</span>
<span class="p_header">index b7d218a168fb..c6a1ec110c01 100644</span>
<span class="p_header">--- a/fs/ceph/addr.c</span>
<span class="p_header">+++ b/fs/ceph/addr.c</span>
<span class="p_chunk">@@ -697,7 +697,7 @@</span> <span class="p_context"> static int ceph_writepages_start(struct address_space *mapping,</span>
 	struct pagevec pvec;
 	int done = 0;
 	int rc = 0;
<span class="p_del">-	unsigned wsize = 1 &lt;&lt; inode-&gt;i_blkbits;</span>
<span class="p_add">+	unsigned int wsize = i_blocksize(inode);</span>
 	struct ceph_osd_request *req = NULL;
 	int do_sync = 0;
 	loff_t snap_size, i_size;
<span class="p_header">diff --git a/fs/direct-io.c b/fs/direct-io.c</span>
<span class="p_header">index 01171d8a6ee9..c772fdf36cd9 100644</span>
<span class="p_header">--- a/fs/direct-io.c</span>
<span class="p_header">+++ b/fs/direct-io.c</span>
<span class="p_chunk">@@ -575,7 +575,7 @@</span> <span class="p_context"> static int dio_set_defer_completion(struct dio *dio)</span>
 /*
  * Call into the fs to map some more disk blocks.  We record the current number
  * of available blocks at sdio-&gt;blocks_available.  These are in units of the
<span class="p_del">- * fs blocksize, (1 &lt;&lt; inode-&gt;i_blkbits).</span>
<span class="p_add">+ * fs blocksize, i_blocksize(inode).</span>
  *
  * The fs is allowed to map lots of blocks at once.  If it wants to do that,
  * it uses the passed inode-relative block number as the file offset, as usual.
<span class="p_header">diff --git a/fs/ext4/extents.c b/fs/ext4/extents.c</span>
<span class="p_header">index 8a456f9b8a44..61d5bfc7318c 100644</span>
<span class="p_header">--- a/fs/ext4/extents.c</span>
<span class="p_header">+++ b/fs/ext4/extents.c</span>
<span class="p_chunk">@@ -4902,6 +4902,8 @@</span> <span class="p_context"> static long ext4_zero_range(struct file *file, loff_t offset,</span>
 
 	/* Zero out partial block at the edges of the range */
 	ret = ext4_zero_partial_blocks(handle, inode, offset, len);
<span class="p_add">+	if (ret &gt;= 0)</span>
<span class="p_add">+		ext4_update_inode_fsync_trans(handle, inode, 1);</span>
 
 	if (file-&gt;f_flags &amp; O_SYNC)
 		ext4_handle_sync(handle);
<span class="p_chunk">@@ -5597,6 +5599,7 @@</span> <span class="p_context"> int ext4_collapse_range(struct inode *inode, loff_t offset, loff_t len)</span>
 		ext4_handle_sync(handle);
 	inode-&gt;i_mtime = inode-&gt;i_ctime = ext4_current_time(inode);
 	ext4_mark_inode_dirty(handle, inode);
<span class="p_add">+	ext4_update_inode_fsync_trans(handle, inode, 1);</span>
 
 out_stop:
 	ext4_journal_stop(handle);
<span class="p_chunk">@@ -5770,6 +5773,8 @@</span> <span class="p_context"> int ext4_insert_range(struct inode *inode, loff_t offset, loff_t len)</span>
 	up_write(&amp;EXT4_I(inode)-&gt;i_data_sem);
 	if (IS_SYNC(inode))
 		ext4_handle_sync(handle);
<span class="p_add">+	if (ret &gt;= 0)</span>
<span class="p_add">+		ext4_update_inode_fsync_trans(handle, inode, 1);</span>
 
 out_stop:
 	ext4_journal_stop(handle);
<span class="p_header">diff --git a/fs/ext4/file.c b/fs/ext4/file.c</span>
<span class="p_header">index 0d24ebcd7c9e..8772bfc3415b 100644</span>
<span class="p_header">--- a/fs/ext4/file.c</span>
<span class="p_header">+++ b/fs/ext4/file.c</span>
<span class="p_chunk">@@ -463,47 +463,27 @@</span> <span class="p_context"> static int ext4_find_unwritten_pgoff(struct inode *inode,</span>
 		num = min_t(pgoff_t, end - index, PAGEVEC_SIZE);
 		nr_pages = pagevec_lookup(&amp;pvec, inode-&gt;i_mapping, index,
 					  (pgoff_t)num);
<span class="p_del">-		if (nr_pages == 0) {</span>
<span class="p_del">-			if (whence == SEEK_DATA)</span>
<span class="p_del">-				break;</span>
<span class="p_del">-</span>
<span class="p_del">-			BUG_ON(whence != SEEK_HOLE);</span>
<span class="p_del">-			/*</span>
<span class="p_del">-			 * If this is the first time to go into the loop and</span>
<span class="p_del">-			 * offset is not beyond the end offset, it will be a</span>
<span class="p_del">-			 * hole at this offset</span>
<span class="p_del">-			 */</span>
<span class="p_del">-			if (lastoff == startoff || lastoff &lt; endoff)</span>
<span class="p_del">-				found = 1;</span>
<span class="p_add">+		if (nr_pages == 0)</span>
 			break;
<span class="p_del">-		}</span>
<span class="p_del">-</span>
<span class="p_del">-		/*</span>
<span class="p_del">-		 * If this is the first time to go into the loop and</span>
<span class="p_del">-		 * offset is smaller than the first page offset, it will be a</span>
<span class="p_del">-		 * hole at this offset.</span>
<span class="p_del">-		 */</span>
<span class="p_del">-		if (lastoff == startoff &amp;&amp; whence == SEEK_HOLE &amp;&amp;</span>
<span class="p_del">-		    lastoff &lt; page_offset(pvec.pages[0])) {</span>
<span class="p_del">-			found = 1;</span>
<span class="p_del">-			break;</span>
<span class="p_del">-		}</span>
 
 		for (i = 0; i &lt; nr_pages; i++) {
 			struct page *page = pvec.pages[i];
 			struct buffer_head *bh, *head;
 
 			/*
<span class="p_del">-			 * If the current offset is not beyond the end of given</span>
<span class="p_del">-			 * range, it will be a hole.</span>
<span class="p_add">+			 * If current offset is smaller than the page offset,</span>
<span class="p_add">+			 * there is a hole at this offset.</span>
 			 */
<span class="p_del">-			if (lastoff &lt; endoff &amp;&amp; whence == SEEK_HOLE &amp;&amp;</span>
<span class="p_del">-			    page-&gt;index &gt; end) {</span>
<span class="p_add">+			if (whence == SEEK_HOLE &amp;&amp; lastoff &lt; endoff &amp;&amp;</span>
<span class="p_add">+			    lastoff &lt; page_offset(pvec.pages[i])) {</span>
 				found = 1;
 				*offset = lastoff;
 				goto out;
 			}
 
<span class="p_add">+			if (page-&gt;index &gt; end)</span>
<span class="p_add">+				goto out;</span>
<span class="p_add">+</span>
 			lock_page(page);
 
 			if (unlikely(page-&gt;mapping != inode-&gt;i_mapping)) {
<span class="p_chunk">@@ -543,20 +523,18 @@</span> <span class="p_context"> static int ext4_find_unwritten_pgoff(struct inode *inode,</span>
 			unlock_page(page);
 		}
 
<span class="p_del">-		/*</span>
<span class="p_del">-		 * The no. of pages is less than our desired, that would be a</span>
<span class="p_del">-		 * hole in there.</span>
<span class="p_del">-		 */</span>
<span class="p_del">-		if (nr_pages &lt; num &amp;&amp; whence == SEEK_HOLE) {</span>
<span class="p_del">-			found = 1;</span>
<span class="p_del">-			*offset = lastoff;</span>
<span class="p_add">+		/* The no. of pages is less than our desired, we are done. */</span>
<span class="p_add">+		if (nr_pages &lt; num)</span>
 			break;
<span class="p_del">-		}</span>
 
 		index = pvec.pages[i - 1]-&gt;index + 1;
 		pagevec_release(&amp;pvec);
 	} while (index &lt;= end);
 
<span class="p_add">+	if (whence == SEEK_HOLE &amp;&amp; lastoff &lt; endoff) {</span>
<span class="p_add">+		found = 1;</span>
<span class="p_add">+		*offset = lastoff;</span>
<span class="p_add">+	}</span>
 out:
 	pagevec_release(&amp;pvec);
 	return found;
<span class="p_header">diff --git a/fs/ext4/inode.c b/fs/ext4/inode.c</span>
<span class="p_header">index ccae64dad40c..1796d1bd9a1d 100644</span>
<span class="p_header">--- a/fs/ext4/inode.c</span>
<span class="p_header">+++ b/fs/ext4/inode.c</span>
<span class="p_chunk">@@ -2044,7 +2044,7 @@</span> <span class="p_context"> static int mpage_process_page_bufs(struct mpage_da_data *mpd,</span>
 {
 	struct inode *inode = mpd-&gt;inode;
 	int err;
<span class="p_del">-	ext4_lblk_t blocks = (i_size_read(inode) + (1 &lt;&lt; inode-&gt;i_blkbits) - 1)</span>
<span class="p_add">+	ext4_lblk_t blocks = (i_size_read(inode) + i_blocksize(inode) - 1)</span>
 							&gt;&gt; inode-&gt;i_blkbits;
 
 	do {
<span class="p_chunk">@@ -3793,6 +3793,8 @@</span> <span class="p_context"> int ext4_punch_hole(struct inode *inode, loff_t offset, loff_t length)</span>
 
 	inode-&gt;i_mtime = inode-&gt;i_ctime = ext4_current_time(inode);
 	ext4_mark_inode_dirty(handle, inode);
<span class="p_add">+	if (ret &gt;= 0)</span>
<span class="p_add">+		ext4_update_inode_fsync_trans(handle, inode, 1);</span>
 out_stop:
 	ext4_journal_stop(handle);
 out_dio:
<span class="p_chunk">@@ -5162,8 +5164,9 @@</span> <span class="p_context"> static int ext4_expand_extra_isize(struct inode *inode,</span>
 	/* No extended attributes present */
 	if (!ext4_test_inode_state(inode, EXT4_STATE_XATTR) ||
 	    header-&gt;h_magic != cpu_to_le32(EXT4_XATTR_MAGIC)) {
<span class="p_del">-		memset((void *)raw_inode + EXT4_GOOD_OLD_INODE_SIZE, 0,</span>
<span class="p_del">-			new_extra_isize);</span>
<span class="p_add">+		memset((void *)raw_inode + EXT4_GOOD_OLD_INODE_SIZE +</span>
<span class="p_add">+		       EXT4_I(inode)-&gt;i_extra_isize, 0,</span>
<span class="p_add">+		       new_extra_isize - EXT4_I(inode)-&gt;i_extra_isize);</span>
 		EXT4_I(inode)-&gt;i_extra_isize = new_extra_isize;
 		return 0;
 	}
<span class="p_header">diff --git a/fs/ext4/move_extent.c b/fs/ext4/move_extent.c</span>
<span class="p_header">index 7861d801b048..05048fcfd602 100644</span>
<span class="p_header">--- a/fs/ext4/move_extent.c</span>
<span class="p_header">+++ b/fs/ext4/move_extent.c</span>
<span class="p_chunk">@@ -187,7 +187,7 @@</span> <span class="p_context"> mext_page_mkuptodate(struct page *page, unsigned from, unsigned to)</span>
 	if (PageUptodate(page))
 		return 0;
 
<span class="p_del">-	blocksize = 1 &lt;&lt; inode-&gt;i_blkbits;</span>
<span class="p_add">+	blocksize = i_blocksize(inode);</span>
 	if (!page_has_buffers(page))
 		create_empty_buffers(page, blocksize, 0);
 
<span class="p_header">diff --git a/fs/jfs/super.c b/fs/jfs/super.c</span>
<span class="p_header">index 8f9176caf098..c8d58c5ac8ae 100644</span>
<span class="p_header">--- a/fs/jfs/super.c</span>
<span class="p_header">+++ b/fs/jfs/super.c</span>
<span class="p_chunk">@@ -758,7 +758,7 @@</span> <span class="p_context"> static ssize_t jfs_quota_read(struct super_block *sb, int type, char *data,</span>
 				sb-&gt;s_blocksize - offset : toread;
 
 		tmp_bh.b_state = 0;
<span class="p_del">-		tmp_bh.b_size = 1 &lt;&lt; inode-&gt;i_blkbits;</span>
<span class="p_add">+		tmp_bh.b_size = i_blocksize(inode);</span>
 		err = jfs_get_block(inode, blk, &amp;tmp_bh, 0);
 		if (err)
 			return err;
<span class="p_chunk">@@ -798,7 +798,7 @@</span> <span class="p_context"> static ssize_t jfs_quota_write(struct super_block *sb, int type,</span>
 				sb-&gt;s_blocksize - offset : towrite;
 
 		tmp_bh.b_state = 0;
<span class="p_del">-		tmp_bh.b_size = 1 &lt;&lt; inode-&gt;i_blkbits;</span>
<span class="p_add">+		tmp_bh.b_size = i_blocksize(inode);</span>
 		err = jfs_get_block(inode, blk, &amp;tmp_bh, 1);
 		if (err)
 			goto out;
<span class="p_header">diff --git a/fs/mpage.c b/fs/mpage.c</span>
<span class="p_header">index 1480d3a18037..6ade29b19494 100644</span>
<span class="p_header">--- a/fs/mpage.c</span>
<span class="p_header">+++ b/fs/mpage.c</span>
<span class="p_chunk">@@ -111,7 +111,7 @@</span> <span class="p_context"> map_buffer_to_page(struct page *page, struct buffer_head *bh, int page_block)</span>
 			SetPageUptodate(page);    
 			return;
 		}
<span class="p_del">-		create_empty_buffers(page, 1 &lt;&lt; inode-&gt;i_blkbits, 0);</span>
<span class="p_add">+		create_empty_buffers(page, i_blocksize(inode), 0);</span>
 	}
 	head = page_buffers(page);
 	page_bh = head;
<span class="p_header">diff --git a/fs/nfs/dir.c b/fs/nfs/dir.c</span>
<span class="p_header">index 52ee0b73ab4a..5b21b1ca2341 100644</span>
<span class="p_header">--- a/fs/nfs/dir.c</span>
<span class="p_header">+++ b/fs/nfs/dir.c</span>
<span class="p_chunk">@@ -2421,6 +2421,20 @@</span> <span class="p_context"> int nfs_may_open(struct inode *inode, struct rpc_cred *cred, int openflags)</span>
 }
 EXPORT_SYMBOL_GPL(nfs_may_open);
 
<span class="p_add">+static int nfs_execute_ok(struct inode *inode, int mask)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct nfs_server *server = NFS_SERVER(inode);</span>
<span class="p_add">+	int ret;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (mask &amp; MAY_NOT_BLOCK)</span>
<span class="p_add">+		ret = nfs_revalidate_inode_rcu(server, inode);</span>
<span class="p_add">+	else</span>
<span class="p_add">+		ret = nfs_revalidate_inode(server, inode);</span>
<span class="p_add">+	if (ret == 0 &amp;&amp; !execute_ok(inode))</span>
<span class="p_add">+		ret = -EACCES;</span>
<span class="p_add">+	return ret;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 int nfs_permission(struct inode *inode, int mask)
 {
 	struct rpc_cred *cred;
<span class="p_chunk">@@ -2438,6 +2452,9 @@</span> <span class="p_context"> int nfs_permission(struct inode *inode, int mask)</span>
 		case S_IFLNK:
 			goto out;
 		case S_IFREG:
<span class="p_add">+			if ((mask &amp; MAY_OPEN) &amp;&amp;</span>
<span class="p_add">+			   nfs_server_capable(inode, NFS_CAP_ATOMIC_OPEN))</span>
<span class="p_add">+				return 0;</span>
 			break;
 		case S_IFDIR:
 			/*
<span class="p_chunk">@@ -2470,8 +2487,8 @@</span> <span class="p_context"> force_lookup:</span>
 			res = PTR_ERR(cred);
 	}
 out:
<span class="p_del">-	if (!res &amp;&amp; (mask &amp; MAY_EXEC) &amp;&amp; !execute_ok(inode))</span>
<span class="p_del">-		res = -EACCES;</span>
<span class="p_add">+	if (!res &amp;&amp; (mask &amp; MAY_EXEC))</span>
<span class="p_add">+		res = nfs_execute_ok(inode, mask);</span>
 
 	dfprintk(VFS, &quot;NFS: permission(%s/%lu), mask=0x%x, res=%d\n&quot;,
 		inode-&gt;i_sb-&gt;s_id, inode-&gt;i_ino, mask, res);
<span class="p_header">diff --git a/fs/nfsd/blocklayout.c b/fs/nfsd/blocklayout.c</span>
<span class="p_header">index c29d9421bd5e..0976f8dad4ce 100644</span>
<span class="p_header">--- a/fs/nfsd/blocklayout.c</span>
<span class="p_header">+++ b/fs/nfsd/blocklayout.c</span>
<span class="p_chunk">@@ -50,7 +50,7 @@</span> <span class="p_context"> nfsd4_block_proc_layoutget(struct inode *inode, const struct svc_fh *fhp,</span>
 {
 	struct nfsd4_layout_seg *seg = &amp;args-&gt;lg_seg;
 	struct super_block *sb = inode-&gt;i_sb;
<span class="p_del">-	u32 block_size = (1 &lt;&lt; inode-&gt;i_blkbits);</span>
<span class="p_add">+	u32 block_size = i_blocksize(inode);</span>
 	struct pnfs_block_extent *bex;
 	struct iomap iomap;
 	u32 device_generation = 0;
<span class="p_chunk">@@ -151,7 +151,7 @@</span> <span class="p_context"> nfsd4_block_proc_layoutcommit(struct inode *inode,</span>
 	int error;
 
 	nr_iomaps = nfsd4_block_decode_layoutupdate(lcp-&gt;lc_up_layout,
<span class="p_del">-			lcp-&gt;lc_up_len, &amp;iomaps, 1 &lt;&lt; inode-&gt;i_blkbits);</span>
<span class="p_add">+			lcp-&gt;lc_up_len, &amp;iomaps, i_blocksize(inode));</span>
 	if (nr_iomaps &lt; 0)
 		return nfserrno(nr_iomaps);
 
<span class="p_header">diff --git a/fs/nfsd/nfs4proc.c b/fs/nfsd/nfs4proc.c</span>
<span class="p_header">index 7d5351cd67fb..209dbfc50cd4 100644</span>
<span class="p_header">--- a/fs/nfsd/nfs4proc.c</span>
<span class="p_header">+++ b/fs/nfsd/nfs4proc.c</span>
<span class="p_chunk">@@ -1690,6 +1690,12 @@</span> <span class="p_context"> nfsd4_proc_compound(struct svc_rqst *rqstp,</span>
 			opdesc-&gt;op_get_currentstateid(cstate, &amp;op-&gt;u);
 		op-&gt;status = opdesc-&gt;op_func(rqstp, cstate, &amp;op-&gt;u);
 
<span class="p_add">+		/* Only from SEQUENCE */</span>
<span class="p_add">+		if (cstate-&gt;status == nfserr_replay_cache) {</span>
<span class="p_add">+			dprintk(&quot;%s NFS4.1 replay from cache\n&quot;, __func__);</span>
<span class="p_add">+			status = op-&gt;status;</span>
<span class="p_add">+			goto out;</span>
<span class="p_add">+		}</span>
 		if (!op-&gt;status) {
 			if (opdesc-&gt;op_set_currentstateid)
 				opdesc-&gt;op_set_currentstateid(cstate, &amp;op-&gt;u);
<span class="p_chunk">@@ -1700,14 +1706,7 @@</span> <span class="p_context"> nfsd4_proc_compound(struct svc_rqst *rqstp,</span>
 			if (need_wrongsec_check(rqstp))
 				op-&gt;status = check_nfsd_access(current_fh-&gt;fh_export, rqstp);
 		}
<span class="p_del">-</span>
 encode_op:
<span class="p_del">-		/* Only from SEQUENCE */</span>
<span class="p_del">-		if (cstate-&gt;status == nfserr_replay_cache) {</span>
<span class="p_del">-			dprintk(&quot;%s NFS4.1 replay from cache\n&quot;, __func__);</span>
<span class="p_del">-			status = op-&gt;status;</span>
<span class="p_del">-			goto out;</span>
<span class="p_del">-		}</span>
 		if (op-&gt;status == nfserr_replay_me) {
 			op-&gt;replay = &amp;cstate-&gt;replay_owner-&gt;so_replay;
 			nfsd4_encode_replay(&amp;resp-&gt;xdr, op);
<span class="p_header">diff --git a/fs/nfsd/nfs4xdr.c b/fs/nfsd/nfs4xdr.c</span>
<span class="p_header">index c3e1cb481fe0..3f68a25f2169 100644</span>
<span class="p_header">--- a/fs/nfsd/nfs4xdr.c</span>
<span class="p_header">+++ b/fs/nfsd/nfs4xdr.c</span>
<span class="p_chunk">@@ -2753,9 +2753,16 @@</span> <span class="p_context"> out_acl:</span>
 	}
 #endif /* CONFIG_NFSD_PNFS */
 	if (bmval2 &amp; FATTR4_WORD2_SUPPATTR_EXCLCREAT) {
<span class="p_del">-		status = nfsd4_encode_bitmap(xdr, NFSD_SUPPATTR_EXCLCREAT_WORD0,</span>
<span class="p_del">-						  NFSD_SUPPATTR_EXCLCREAT_WORD1,</span>
<span class="p_del">-						  NFSD_SUPPATTR_EXCLCREAT_WORD2);</span>
<span class="p_add">+		u32 supp[3];</span>
<span class="p_add">+</span>
<span class="p_add">+		supp[0] = nfsd_suppattrs0(minorversion);</span>
<span class="p_add">+		supp[1] = nfsd_suppattrs1(minorversion);</span>
<span class="p_add">+		supp[2] = nfsd_suppattrs2(minorversion);</span>
<span class="p_add">+		supp[0] &amp;= NFSD_SUPPATTR_EXCLCREAT_WORD0;</span>
<span class="p_add">+		supp[1] &amp;= NFSD_SUPPATTR_EXCLCREAT_WORD1;</span>
<span class="p_add">+		supp[2] &amp;= NFSD_SUPPATTR_EXCLCREAT_WORD2;</span>
<span class="p_add">+</span>
<span class="p_add">+		status = nfsd4_encode_bitmap(xdr, supp[0], supp[1], supp[2]);</span>
 		if (status)
 			goto out;
 	}
<span class="p_header">diff --git a/fs/nilfs2/btnode.c b/fs/nilfs2/btnode.c</span>
<span class="p_header">index a35ae35e6932..cd39b57288c2 100644</span>
<span class="p_header">--- a/fs/nilfs2/btnode.c</span>
<span class="p_header">+++ b/fs/nilfs2/btnode.c</span>
<span class="p_chunk">@@ -55,7 +55,7 @@</span> <span class="p_context"> nilfs_btnode_create_block(struct address_space *btnc, __u64 blocknr)</span>
 		brelse(bh);
 		BUG();
 	}
<span class="p_del">-	memset(bh-&gt;b_data, 0, 1 &lt;&lt; inode-&gt;i_blkbits);</span>
<span class="p_add">+	memset(bh-&gt;b_data, 0, i_blocksize(inode));</span>
 	bh-&gt;b_bdev = inode-&gt;i_sb-&gt;s_bdev;
 	bh-&gt;b_blocknr = blocknr;
 	set_buffer_mapped(bh);
<span class="p_header">diff --git a/fs/nilfs2/inode.c b/fs/nilfs2/inode.c</span>
<span class="p_header">index ac2f64943ff4..00877ef0b120 100644</span>
<span class="p_header">--- a/fs/nilfs2/inode.c</span>
<span class="p_header">+++ b/fs/nilfs2/inode.c</span>
<span class="p_chunk">@@ -55,7 +55,7 @@</span> <span class="p_context"> void nilfs_inode_add_blocks(struct inode *inode, int n)</span>
 {
 	struct nilfs_root *root = NILFS_I(inode)-&gt;i_root;
 
<span class="p_del">-	inode_add_bytes(inode, (1 &lt;&lt; inode-&gt;i_blkbits) * n);</span>
<span class="p_add">+	inode_add_bytes(inode, i_blocksize(inode) * n);</span>
 	if (root)
 		atomic64_add(n, &amp;root-&gt;blocks_count);
 }
<span class="p_chunk">@@ -64,7 +64,7 @@</span> <span class="p_context"> void nilfs_inode_sub_blocks(struct inode *inode, int n)</span>
 {
 	struct nilfs_root *root = NILFS_I(inode)-&gt;i_root;
 
<span class="p_del">-	inode_sub_bytes(inode, (1 &lt;&lt; inode-&gt;i_blkbits) * n);</span>
<span class="p_add">+	inode_sub_bytes(inode, i_blocksize(inode) * n);</span>
 	if (root)
 		atomic64_sub(n, &amp;root-&gt;blocks_count);
 }
<span class="p_header">diff --git a/fs/nilfs2/mdt.c b/fs/nilfs2/mdt.c</span>
<span class="p_header">index 1125f40233ff..612a2457243d 100644</span>
<span class="p_header">--- a/fs/nilfs2/mdt.c</span>
<span class="p_header">+++ b/fs/nilfs2/mdt.c</span>
<span class="p_chunk">@@ -60,7 +60,7 @@</span> <span class="p_context"> nilfs_mdt_insert_new_block(struct inode *inode, unsigned long block,</span>
 	set_buffer_mapped(bh);
 
 	kaddr = kmap_atomic(bh-&gt;b_page);
<span class="p_del">-	memset(kaddr + bh_offset(bh), 0, 1 &lt;&lt; inode-&gt;i_blkbits);</span>
<span class="p_add">+	memset(kaddr + bh_offset(bh), 0, i_blocksize(inode));</span>
 	if (init_block)
 		init_block(inode, bh, kaddr);
 	flush_dcache_page(bh-&gt;b_page);
<span class="p_chunk">@@ -503,7 +503,7 @@</span> <span class="p_context"> void nilfs_mdt_set_entry_size(struct inode *inode, unsigned entry_size,</span>
 	struct nilfs_mdt_info *mi = NILFS_MDT(inode);
 
 	mi-&gt;mi_entry_size = entry_size;
<span class="p_del">-	mi-&gt;mi_entries_per_block = (1 &lt;&lt; inode-&gt;i_blkbits) / entry_size;</span>
<span class="p_add">+	mi-&gt;mi_entries_per_block = i_blocksize(inode) / entry_size;</span>
 	mi-&gt;mi_first_entry_offset = DIV_ROUND_UP(header_size, entry_size);
 }
 
<span class="p_header">diff --git a/fs/nilfs2/segment.c b/fs/nilfs2/segment.c</span>
<span class="p_header">index 3b65adaae7e4..2f27c935bd57 100644</span>
<span class="p_header">--- a/fs/nilfs2/segment.c</span>
<span class="p_header">+++ b/fs/nilfs2/segment.c</span>
<span class="p_chunk">@@ -719,7 +719,7 @@</span> <span class="p_context"> static size_t nilfs_lookup_dirty_data_buffers(struct inode *inode,</span>
 
 		lock_page(page);
 		if (!page_has_buffers(page))
<span class="p_del">-			create_empty_buffers(page, 1 &lt;&lt; inode-&gt;i_blkbits, 0);</span>
<span class="p_add">+			create_empty_buffers(page, i_blocksize(inode), 0);</span>
 		unlock_page(page);
 
 		bh = head = page_buffers(page);
<span class="p_header">diff --git a/fs/ocfs2/aops.c b/fs/ocfs2/aops.c</span>
<span class="p_header">index e6795c7c76a8..e4184bd2a954 100644</span>
<span class="p_header">--- a/fs/ocfs2/aops.c</span>
<span class="p_header">+++ b/fs/ocfs2/aops.c</span>
<span class="p_chunk">@@ -1103,7 +1103,7 @@</span> <span class="p_context"> int ocfs2_map_page_blocks(struct page *page, u64 *p_blkno,</span>
 	int ret = 0;
 	struct buffer_head *head, *bh, *wait[2], **wait_bh = wait;
 	unsigned int block_end, block_start;
<span class="p_del">-	unsigned int bsize = 1 &lt;&lt; inode-&gt;i_blkbits;</span>
<span class="p_add">+	unsigned int bsize = i_blocksize(inode);</span>
 
 	if (!page_has_buffers(page))
 		create_empty_buffers(page, bsize, 0);
<span class="p_header">diff --git a/fs/ocfs2/file.c b/fs/ocfs2/file.c</span>
<span class="p_header">index 56dd3957cc91..1d738723a41a 100644</span>
<span class="p_header">--- a/fs/ocfs2/file.c</span>
<span class="p_header">+++ b/fs/ocfs2/file.c</span>
<span class="p_chunk">@@ -808,7 +808,7 @@</span> <span class="p_context"> static int ocfs2_write_zero_page(struct inode *inode, u64 abs_from,</span>
 	/* We know that zero_from is block aligned */
 	for (block_start = zero_from; block_start &lt; zero_to;
 	     block_start = block_end) {
<span class="p_del">-		block_end = block_start + (1 &lt;&lt; inode-&gt;i_blkbits);</span>
<span class="p_add">+		block_end = block_start + i_blocksize(inode);</span>
 
 		/*
 		 * block_start is block-aligned.  Bump it by one to force
<span class="p_header">diff --git a/fs/reiserfs/file.c b/fs/reiserfs/file.c</span>
<span class="p_header">index 8f5ccdf81c25..38187300a2b4 100644</span>
<span class="p_header">--- a/fs/reiserfs/file.c</span>
<span class="p_header">+++ b/fs/reiserfs/file.c</span>
<span class="p_chunk">@@ -189,7 +189,7 @@</span> <span class="p_context"> int reiserfs_commit_page(struct inode *inode, struct page *page,</span>
 	int ret = 0;
 
 	th.t_trans_id = 0;
<span class="p_del">-	blocksize = 1 &lt;&lt; inode-&gt;i_blkbits;</span>
<span class="p_add">+	blocksize = i_blocksize(inode);</span>
 
 	if (logit) {
 		reiserfs_write_lock(s);
<span class="p_header">diff --git a/fs/reiserfs/inode.c b/fs/reiserfs/inode.c</span>
<span class="p_header">index 3d8e7e671d5b..60ba35087d12 100644</span>
<span class="p_header">--- a/fs/reiserfs/inode.c</span>
<span class="p_header">+++ b/fs/reiserfs/inode.c</span>
<span class="p_chunk">@@ -524,7 +524,7 @@</span> <span class="p_context"> static int reiserfs_get_blocks_direct_io(struct inode *inode,</span>
 	 * referenced in convert_tail_for_hole() that may be called from
 	 * reiserfs_get_block()
 	 */
<span class="p_del">-	bh_result-&gt;b_size = (1 &lt;&lt; inode-&gt;i_blkbits);</span>
<span class="p_add">+	bh_result-&gt;b_size = i_blocksize(inode);</span>
 
 	ret = reiserfs_get_block(inode, iblock, bh_result,
 				 create | GET_BLOCK_NO_DANGLE);
<span class="p_header">diff --git a/fs/stat.c b/fs/stat.c</span>
<span class="p_header">index d4a61d8dc021..004dd77c3b93 100644</span>
<span class="p_header">--- a/fs/stat.c</span>
<span class="p_header">+++ b/fs/stat.c</span>
<span class="p_chunk">@@ -31,7 +31,7 @@</span> <span class="p_context"> void generic_fillattr(struct inode *inode, struct kstat *stat)</span>
 	stat-&gt;atime = inode-&gt;i_atime;
 	stat-&gt;mtime = inode-&gt;i_mtime;
 	stat-&gt;ctime = inode-&gt;i_ctime;
<span class="p_del">-	stat-&gt;blksize = (1 &lt;&lt; inode-&gt;i_blkbits);</span>
<span class="p_add">+	stat-&gt;blksize = i_blocksize(inode);</span>
 	stat-&gt;blocks = inode-&gt;i_blocks;
 }
 
<span class="p_chunk">@@ -454,6 +454,7 @@</span> <span class="p_context"> void __inode_add_bytes(struct inode *inode, loff_t bytes)</span>
 		inode-&gt;i_bytes -= 512;
 	}
 }
<span class="p_add">+EXPORT_SYMBOL(__inode_add_bytes);</span>
 
 void inode_add_bytes(struct inode *inode, loff_t bytes)
 {
<span class="p_header">diff --git a/fs/udf/inode.c b/fs/udf/inode.c</span>
<span class="p_header">index 566df9b5a6cb..7be3166ba553 100644</span>
<span class="p_header">--- a/fs/udf/inode.c</span>
<span class="p_header">+++ b/fs/udf/inode.c</span>
<span class="p_chunk">@@ -1206,7 +1206,7 @@</span> <span class="p_context"> int udf_setsize(struct inode *inode, loff_t newsize)</span>
 {
 	int err;
 	struct udf_inode_info *iinfo;
<span class="p_del">-	int bsize = 1 &lt;&lt; inode-&gt;i_blkbits;</span>
<span class="p_add">+	int bsize = i_blocksize(inode);</span>
 
 	if (!(S_ISREG(inode-&gt;i_mode) || S_ISDIR(inode-&gt;i_mode) ||
 	      S_ISLNK(inode-&gt;i_mode)))
<span class="p_header">diff --git a/fs/ufs/balloc.c b/fs/ufs/balloc.c</span>
<span class="p_header">index dc5fae601c24..637e17cb0edd 100644</span>
<span class="p_header">--- a/fs/ufs/balloc.c</span>
<span class="p_header">+++ b/fs/ufs/balloc.c</span>
<span class="p_chunk">@@ -81,7 +81,8 @@</span> <span class="p_context"> void ufs_free_fragments(struct inode *inode, u64 fragment, unsigned count)</span>
 			ufs_error (sb, &quot;ufs_free_fragments&quot;,
 				   &quot;bit already cleared for fragment %u&quot;, i);
 	}
<span class="p_del">-	</span>
<span class="p_add">+</span>
<span class="p_add">+	inode_sub_bytes(inode, count &lt;&lt; uspi-&gt;s_fshift);</span>
 	fs32_add(sb, &amp;ucg-&gt;cg_cs.cs_nffree, count);
 	uspi-&gt;cs_total.cs_nffree += count;
 	fs32_add(sb, &amp;UFS_SB(sb)-&gt;fs_cs(cgno).cs_nffree, count);
<span class="p_chunk">@@ -183,6 +184,7 @@</span> <span class="p_context"> do_more:</span>
 			ufs_error(sb, &quot;ufs_free_blocks&quot;, &quot;freeing free fragment&quot;);
 		}
 		ubh_setblock(UCPI_UBH(ucpi), ucpi-&gt;c_freeoff, blkno);
<span class="p_add">+		inode_sub_bytes(inode, uspi-&gt;s_fpb &lt;&lt; uspi-&gt;s_fshift);</span>
 		if ((UFS_SB(sb)-&gt;s_flags &amp; UFS_CG_MASK) == UFS_CG_44BSD)
 			ufs_clusteracct (sb, ucpi, blkno, 1);
 
<span class="p_chunk">@@ -494,6 +496,20 @@</span> <span class="p_context"> u64 ufs_new_fragments(struct inode *inode, void *p, u64 fragment,</span>
 	return 0;
 }		
 
<span class="p_add">+static bool try_add_frags(struct inode *inode, unsigned frags)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned size = frags * i_blocksize(inode);</span>
<span class="p_add">+	spin_lock(&amp;inode-&gt;i_lock);</span>
<span class="p_add">+	__inode_add_bytes(inode, size);</span>
<span class="p_add">+	if (unlikely((u32)inode-&gt;i_blocks != inode-&gt;i_blocks)) {</span>
<span class="p_add">+		__inode_sub_bytes(inode, size);</span>
<span class="p_add">+		spin_unlock(&amp;inode-&gt;i_lock);</span>
<span class="p_add">+		return false;</span>
<span class="p_add">+	}</span>
<span class="p_add">+	spin_unlock(&amp;inode-&gt;i_lock);</span>
<span class="p_add">+	return true;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static u64 ufs_add_fragments(struct inode *inode, u64 fragment,
 			     unsigned oldcount, unsigned newcount)
 {
<span class="p_chunk">@@ -530,6 +546,9 @@</span> <span class="p_context"> static u64 ufs_add_fragments(struct inode *inode, u64 fragment,</span>
 	for (i = oldcount; i &lt; newcount; i++)
 		if (ubh_isclr (UCPI_UBH(ucpi), ucpi-&gt;c_freeoff, fragno + i))
 			return 0;
<span class="p_add">+</span>
<span class="p_add">+	if (!try_add_frags(inode, count))</span>
<span class="p_add">+		return 0;</span>
 	/*
 	 * Block can be extended
 	 */
<span class="p_chunk">@@ -647,6 +666,7 @@</span> <span class="p_context"> cg_found:</span>
 			ubh_setbit (UCPI_UBH(ucpi), ucpi-&gt;c_freeoff, goal + i);
 		i = uspi-&gt;s_fpb - count;
 
<span class="p_add">+		inode_sub_bytes(inode, i &lt;&lt; uspi-&gt;s_fshift);</span>
 		fs32_add(sb, &amp;ucg-&gt;cg_cs.cs_nffree, i);
 		uspi-&gt;cs_total.cs_nffree += i;
 		fs32_add(sb, &amp;UFS_SB(sb)-&gt;fs_cs(cgno).cs_nffree, i);
<span class="p_chunk">@@ -657,6 +677,8 @@</span> <span class="p_context"> cg_found:</span>
 	result = ufs_bitmap_search (sb, ucpi, goal, allocsize);
 	if (result == INVBLOCK)
 		return 0;
<span class="p_add">+	if (!try_add_frags(inode, count))</span>
<span class="p_add">+		return 0;</span>
 	for (i = 0; i &lt; count; i++)
 		ubh_clrbit (UCPI_UBH(ucpi), ucpi-&gt;c_freeoff, result + i);
 	
<span class="p_chunk">@@ -716,6 +738,8 @@</span> <span class="p_context"> norot:</span>
 		return INVBLOCK;
 	ucpi-&gt;c_rotor = result;
 gotit:
<span class="p_add">+	if (!try_add_frags(inode, uspi-&gt;s_fpb))</span>
<span class="p_add">+		return 0;</span>
 	blkno = ufs_fragstoblks(result);
 	ubh_clrblock (UCPI_UBH(ucpi), ucpi-&gt;c_freeoff, blkno);
 	if ((UFS_SB(sb)-&gt;s_flags &amp; UFS_CG_MASK) == UFS_CG_44BSD)
<span class="p_header">diff --git a/fs/ufs/inode.c b/fs/ufs/inode.c</span>
<span class="p_header">index a064cf44b143..1f69bb9b1e9d 100644</span>
<span class="p_header">--- a/fs/ufs/inode.c</span>
<span class="p_header">+++ b/fs/ufs/inode.c</span>
<span class="p_chunk">@@ -235,7 +235,8 @@</span> <span class="p_context"> ufs_extend_tail(struct inode *inode, u64 writes_to,</span>
 
 	p = ufs_get_direct_data_ptr(uspi, ufsi, block);
 	tmp = ufs_new_fragments(inode, p, lastfrag, ufs_data_ptr_to_cpu(sb, p),
<span class="p_del">-				new_size, err, locked_page);</span>
<span class="p_add">+				new_size - (lastfrag &amp; uspi-&gt;s_fpbmask), err,</span>
<span class="p_add">+				locked_page);</span>
 	return tmp != 0;
 }
 
<span class="p_chunk">@@ -284,7 +285,7 @@</span> <span class="p_context"> ufs_inode_getfrag(struct inode *inode, unsigned index,</span>
 			goal += uspi-&gt;s_fpb;
 	}
 	tmp = ufs_new_fragments(inode, p, ufs_blknum(new_fragment),
<span class="p_del">-				goal, uspi-&gt;s_fpb, err, locked_page);</span>
<span class="p_add">+				goal, nfrags, err, locked_page);</span>
 
 	if (!tmp) {
 		*err = -ENOSPC;
<span class="p_chunk">@@ -402,7 +403,9 @@</span> <span class="p_context"> static int ufs_getfrag_block(struct inode *inode, sector_t fragment, struct buff</span>
 
 	if (!create) {
 		phys64 = ufs_frag_map(inode, offsets, depth);
<span class="p_del">-		goto out;</span>
<span class="p_add">+		if (phys64)</span>
<span class="p_add">+			map_bh(bh_result, sb, phys64 + frag);</span>
<span class="p_add">+		return 0;</span>
 	}
 
         /* This code entered only while writing ....? */
<span class="p_header">diff --git a/fs/ufs/super.c b/fs/ufs/super.c</span>
<span class="p_header">index f6390eec02ca..10f364490833 100644</span>
<span class="p_header">--- a/fs/ufs/super.c</span>
<span class="p_header">+++ b/fs/ufs/super.c</span>
<span class="p_chunk">@@ -746,6 +746,23 @@</span> <span class="p_context"> static void ufs_put_super(struct super_block *sb)</span>
 	return;
 }
 
<span class="p_add">+static u64 ufs_max_bytes(struct super_block *sb)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct ufs_sb_private_info *uspi = UFS_SB(sb)-&gt;s_uspi;</span>
<span class="p_add">+	int bits = uspi-&gt;s_apbshift;</span>
<span class="p_add">+	u64 res;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (bits &gt; 21)</span>
<span class="p_add">+		res = ~0ULL;</span>
<span class="p_add">+	else</span>
<span class="p_add">+		res = UFS_NDADDR + (1LL &lt;&lt; bits) + (1LL &lt;&lt; (2*bits)) +</span>
<span class="p_add">+			(1LL &lt;&lt; (3*bits));</span>
<span class="p_add">+</span>
<span class="p_add">+	if (res &gt;= (MAX_LFS_FILESIZE &gt;&gt; uspi-&gt;s_bshift))</span>
<span class="p_add">+		return MAX_LFS_FILESIZE;</span>
<span class="p_add">+	return res &lt;&lt; uspi-&gt;s_bshift;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static int ufs_fill_super(struct super_block *sb, void *data, int silent)
 {
 	struct ufs_sb_info * sbi;
<span class="p_chunk">@@ -1212,6 +1229,7 @@</span> <span class="p_context"> magic_found:</span>
 			    &quot;fast symlink size (%u)\n&quot;, uspi-&gt;s_maxsymlinklen);
 		uspi-&gt;s_maxsymlinklen = maxsymlen;
 	}
<span class="p_add">+	sb-&gt;s_maxbytes = ufs_max_bytes(sb);</span>
 	sb-&gt;s_max_links = UFS_LINK_MAX;
 
 	inode = ufs_iget(sb, UFS_ROOTINO);
<span class="p_header">diff --git a/fs/ufs/util.h b/fs/ufs/util.h</span>
<span class="p_header">index 954175928240..3f9463f8cf2f 100644</span>
<span class="p_header">--- a/fs/ufs/util.h</span>
<span class="p_header">+++ b/fs/ufs/util.h</span>
<span class="p_chunk">@@ -473,15 +473,19 @@</span> <span class="p_context"> static inline unsigned _ubh_find_last_zero_bit_(</span>
 static inline int _ubh_isblockset_(struct ufs_sb_private_info * uspi,
 	struct ufs_buffer_head * ubh, unsigned begin, unsigned block)
 {
<span class="p_add">+	u8 mask;</span>
 	switch (uspi-&gt;s_fpb) {
 	case 8:
 	    	return (*ubh_get_addr (ubh, begin + block) == 0xff);
 	case 4:
<span class="p_del">-		return (*ubh_get_addr (ubh, begin + (block &gt;&gt; 1)) == (0x0f &lt;&lt; ((block &amp; 0x01) &lt;&lt; 2)));</span>
<span class="p_add">+		mask = 0x0f &lt;&lt; ((block &amp; 0x01) &lt;&lt; 2);</span>
<span class="p_add">+		return (*ubh_get_addr (ubh, begin + (block &gt;&gt; 1)) &amp; mask) == mask;</span>
 	case 2:
<span class="p_del">-		return (*ubh_get_addr (ubh, begin + (block &gt;&gt; 2)) == (0x03 &lt;&lt; ((block &amp; 0x03) &lt;&lt; 1)));</span>
<span class="p_add">+		mask = 0x03 &lt;&lt; ((block &amp; 0x03) &lt;&lt; 1);</span>
<span class="p_add">+		return (*ubh_get_addr (ubh, begin + (block &gt;&gt; 2)) &amp; mask) == mask;</span>
 	case 1:
<span class="p_del">-		return (*ubh_get_addr (ubh, begin + (block &gt;&gt; 3)) == (0x01 &lt;&lt; (block &amp; 0x07)));</span>
<span class="p_add">+		mask = 0x01 &lt;&lt; (block &amp; 0x07);</span>
<span class="p_add">+		return (*ubh_get_addr (ubh, begin + (block &gt;&gt; 3)) &amp; mask) == mask;</span>
 	}
 	return 0;	
 }
<span class="p_header">diff --git a/fs/xfs/xfs_aops.c b/fs/xfs/xfs_aops.c</span>
<span class="p_header">index 29e7e5dd5178..187b80267ff9 100644</span>
<span class="p_header">--- a/fs/xfs/xfs_aops.c</span>
<span class="p_header">+++ b/fs/xfs/xfs_aops.c</span>
<span class="p_chunk">@@ -288,7 +288,7 @@</span> <span class="p_context"> xfs_map_blocks(</span>
 {
 	struct xfs_inode	*ip = XFS_I(inode);
 	struct xfs_mount	*mp = ip-&gt;i_mount;
<span class="p_del">-	ssize_t			count = 1 &lt;&lt; inode-&gt;i_blkbits;</span>
<span class="p_add">+	ssize_t			count = i_blocksize(inode);</span>
 	xfs_fileoff_t		offset_fsb, end_fsb;
 	int			error = 0;
 	int			bmapi_flags = XFS_BMAPI_ENTIRE;
<span class="p_chunk">@@ -921,7 +921,7 @@</span> <span class="p_context"> xfs_aops_discard_page(</span>
 			break;
 		}
 next_buffer:
<span class="p_del">-		offset += 1 &lt;&lt; inode-&gt;i_blkbits;</span>
<span class="p_add">+		offset += i_blocksize(inode);</span>
 
 	} while ((bh = bh-&gt;b_this_page) != head);
 
<span class="p_chunk">@@ -1363,7 +1363,7 @@</span> <span class="p_context"> xfs_map_trim_size(</span>
 	    offset + mapping_size &gt;= i_size_read(inode)) {
 		/* limit mapping to block that spans EOF */
 		mapping_size = roundup_64(i_size_read(inode) - offset,
<span class="p_del">-					  1 &lt;&lt; inode-&gt;i_blkbits);</span>
<span class="p_add">+					  i_blocksize(inode));</span>
 	}
 	if (mapping_size &gt; LONG_MAX)
 		mapping_size = LONG_MAX;
<span class="p_chunk">@@ -1395,7 +1395,7 @@</span> <span class="p_context"> __xfs_get_blocks(</span>
 		return -EIO;
 
 	offset = (xfs_off_t)iblock &lt;&lt; inode-&gt;i_blkbits;
<span class="p_del">-	ASSERT(bh_result-&gt;b_size &gt;= (1 &lt;&lt; inode-&gt;i_blkbits));</span>
<span class="p_add">+	ASSERT(bh_result-&gt;b_size &gt;= i_blocksize(inode));</span>
 	size = bh_result-&gt;b_size;
 
 	if (!create &amp;&amp; direct &amp;&amp; offset &gt;= i_size_read(inode))
<span class="p_chunk">@@ -1968,7 +1968,7 @@</span> <span class="p_context"> xfs_vm_set_page_dirty(</span>
 			if (offset &lt; end_offset)
 				set_buffer_dirty(bh);
 			bh = bh-&gt;b_this_page;
<span class="p_del">-			offset += 1 &lt;&lt; inode-&gt;i_blkbits;</span>
<span class="p_add">+			offset += i_blocksize(inode);</span>
 		} while (bh != head);
 	}
 	/*
<span class="p_header">diff --git a/fs/xfs/xfs_file.c b/fs/xfs/xfs_file.c</span>
<span class="p_header">index ceea444dafb4..3dd47307363f 100644</span>
<span class="p_header">--- a/fs/xfs/xfs_file.c</span>
<span class="p_header">+++ b/fs/xfs/xfs_file.c</span>
<span class="p_chunk">@@ -947,7 +947,7 @@</span> <span class="p_context"> xfs_file_fallocate(</span>
 		if (error)
 			goto out_unlock;
 	} else if (mode &amp; FALLOC_FL_COLLAPSE_RANGE) {
<span class="p_del">-		unsigned blksize_mask = (1 &lt;&lt; inode-&gt;i_blkbits) - 1;</span>
<span class="p_add">+		unsigned int blksize_mask = i_blocksize(inode) - 1;</span>
 
 		if (offset &amp; blksize_mask || len &amp; blksize_mask) {
 			error = -EINVAL;
<span class="p_chunk">@@ -969,7 +969,7 @@</span> <span class="p_context"> xfs_file_fallocate(</span>
 		if (error)
 			goto out_unlock;
 	} else if (mode &amp; FALLOC_FL_INSERT_RANGE) {
<span class="p_del">-		unsigned blksize_mask = (1 &lt;&lt; inode-&gt;i_blkbits) - 1;</span>
<span class="p_add">+		unsigned int blksize_mask = i_blocksize(inode) - 1;</span>
 
 		new_size = i_size_read(inode) + len;
 		if (offset &amp; blksize_mask || len &amp; blksize_mask) {
<span class="p_header">diff --git a/fs/xfs/xfs_xattr.c b/fs/xfs/xfs_xattr.c</span>
<span class="p_header">index e6dae28dfa1a..9beaf192b4bb 100644</span>
<span class="p_header">--- a/fs/xfs/xfs_xattr.c</span>
<span class="p_header">+++ b/fs/xfs/xfs_xattr.c</span>
<span class="p_chunk">@@ -180,6 +180,7 @@</span> <span class="p_context"> xfs_xattr_put_listent(</span>
 	arraytop = context-&gt;count + prefix_len + namelen + 1;
 	if (arraytop &gt; context-&gt;firstu) {
 		context-&gt;count = -1;	/* insufficient space */
<span class="p_add">+		context-&gt;seen_enough = 1;</span>
 		return 0;
 	}
 	offset = (char *)context-&gt;alist + context-&gt;count;
<span class="p_header">diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h</span>
<span class="p_header">index ad2bcf647b9a..210ccc4ea44b 100644</span>
<span class="p_header">--- a/include/linux/cgroup.h</span>
<span class="p_header">+++ b/include/linux/cgroup.h</span>
<span class="p_chunk">@@ -340,6 +340,26 @@</span> <span class="p_context"> static inline bool css_tryget_online(struct cgroup_subsys_state *css)</span>
 }
 
 /**
<span class="p_add">+ * css_is_dying - test whether the specified css is dying</span>
<span class="p_add">+ * @css: target css</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * Test whether @css is in the process of offlining or already offline.  In</span>
<span class="p_add">+ * most cases, -&gt;css_online() and -&gt;css_offline() callbacks should be</span>
<span class="p_add">+ * enough; however, the actual offline operations are RCU delayed and this</span>
<span class="p_add">+ * test returns %true also when @css is scheduled to be offlined.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * This is useful, for example, when the use case requires synchronous</span>
<span class="p_add">+ * behavior with respect to cgroup removal.  cgroup removal schedules css</span>
<span class="p_add">+ * offlining but the css can seem alive while the operation is being</span>
<span class="p_add">+ * delayed.  If the delay affects user visible semantics, this test can be</span>
<span class="p_add">+ * used to resolve the situation.</span>
<span class="p_add">+ */</span>
<span class="p_add">+static inline bool css_is_dying(struct cgroup_subsys_state *css)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return !(css-&gt;flags &amp; CSS_NO_REF) &amp;&amp; percpu_ref_is_dying(&amp;css-&gt;refcnt);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+/**</span>
  * css_put - put a css reference
  * @css: target css
  *
<span class="p_header">diff --git a/include/linux/fs.h b/include/linux/fs.h</span>
<span class="p_header">index e1a123760dbf..c8decb7075d6 100644</span>
<span class="p_header">--- a/include/linux/fs.h</span>
<span class="p_header">+++ b/include/linux/fs.h</span>
<span class="p_chunk">@@ -680,6 +680,11 @@</span> <span class="p_context"> struct inode {</span>
 	void			*i_private; /* fs or device private pointer */
 };
 
<span class="p_add">+static inline unsigned int i_blocksize(const struct inode *node)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return (1 &lt;&lt; node-&gt;i_blkbits);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static inline int inode_unhashed(struct inode *inode)
 {
 	return hlist_unhashed(&amp;inode-&gt;i_hash);
<span class="p_header">diff --git a/include/linux/memblock.h b/include/linux/memblock.h</span>
<span class="p_header">index 24daf8fc4d7c..76b502c6258f 100644</span>
<span class="p_header">--- a/include/linux/memblock.h</span>
<span class="p_header">+++ b/include/linux/memblock.h</span>
<span class="p_chunk">@@ -408,12 +408,20 @@</span> <span class="p_context"> static inline void early_memtest(phys_addr_t start, phys_addr_t end)</span>
 }
 #endif
 
<span class="p_add">+extern unsigned long memblock_reserved_memory_within(phys_addr_t start_addr,</span>
<span class="p_add">+		phys_addr_t end_addr);</span>
 #else
 static inline phys_addr_t memblock_alloc(phys_addr_t size, phys_addr_t align)
 {
 	return 0;
 }
 
<span class="p_add">+static inline unsigned long memblock_reserved_memory_within(phys_addr_t start_addr,</span>
<span class="p_add">+		phys_addr_t end_addr)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return 0;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 #endif /* CONFIG_HAVE_MEMBLOCK */
 
 #endif /* __KERNEL__ */
<span class="p_header">diff --git a/include/linux/mmzone.h b/include/linux/mmzone.h</span>
<span class="p_header">index e23a9e704536..5b609a3ce3d7 100644</span>
<span class="p_header">--- a/include/linux/mmzone.h</span>
<span class="p_header">+++ b/include/linux/mmzone.h</span>
<span class="p_chunk">@@ -688,6 +688,7 @@</span> <span class="p_context"> typedef struct pglist_data {</span>
 	 * is the first PFN that needs to be initialised.
 	 */
 	unsigned long first_deferred_pfn;
<span class="p_add">+	unsigned long static_init_size;</span>
 #endif /* CONFIG_DEFERRED_STRUCT_PAGE_INIT */
 } pg_data_t;
 
<span class="p_header">diff --git a/include/linux/ptrace.h b/include/linux/ptrace.h</span>
<span class="p_header">index e13bfdf7f314..81fdf4b8aba4 100644</span>
<span class="p_header">--- a/include/linux/ptrace.h</span>
<span class="p_header">+++ b/include/linux/ptrace.h</span>
<span class="p_chunk">@@ -50,7 +50,8 @@</span> <span class="p_context"> extern int ptrace_request(struct task_struct *child, long request,</span>
 			  unsigned long addr, unsigned long data);
 extern void ptrace_notify(int exit_code);
 extern void __ptrace_link(struct task_struct *child,
<span class="p_del">-			  struct task_struct *new_parent);</span>
<span class="p_add">+			  struct task_struct *new_parent,</span>
<span class="p_add">+			  const struct cred *ptracer_cred);</span>
 extern void __ptrace_unlink(struct task_struct *child);
 extern void exit_ptrace(struct task_struct *tracer, struct list_head *dead);
 #define PTRACE_MODE_READ	0x01
<span class="p_chunk">@@ -202,7 +203,7 @@</span> <span class="p_context"> static inline void ptrace_init_task(struct task_struct *child, bool ptrace)</span>
 
 	if (unlikely(ptrace) &amp;&amp; current-&gt;ptrace) {
 		child-&gt;ptrace = current-&gt;ptrace;
<span class="p_del">-		__ptrace_link(child, current-&gt;parent);</span>
<span class="p_add">+		__ptrace_link(child, current-&gt;parent, current-&gt;ptracer_cred);</span>
 
 		if (child-&gt;ptrace &amp; PT_SEIZED)
 			task_set_jobctl_pending(child, JOBCTL_TRAP_STOP);
<span class="p_chunk">@@ -211,6 +212,8 @@</span> <span class="p_context"> static inline void ptrace_init_task(struct task_struct *child, bool ptrace)</span>
 
 		set_tsk_thread_flag(child, TIF_SIGPENDING);
 	}
<span class="p_add">+	else</span>
<span class="p_add">+		child-&gt;ptracer_cred = NULL;</span>
 }
 
 /**
<span class="p_header">diff --git a/include/linux/random.h b/include/linux/random.h</span>
<span class="p_header">index a75840c1aa71..9c29122037f9 100644</span>
<span class="p_header">--- a/include/linux/random.h</span>
<span class="p_header">+++ b/include/linux/random.h</span>
<span class="p_chunk">@@ -34,6 +34,7 @@</span> <span class="p_context"> extern const struct file_operations random_fops, urandom_fops;</span>
 #endif
 
 unsigned int get_random_int(void);
<span class="p_add">+unsigned long get_random_long(void);</span>
 unsigned long randomize_range(unsigned long start, unsigned long end, unsigned long len);
 
 u32 prandom_u32(void);
<span class="p_header">diff --git a/include/linux/skbuff.h b/include/linux/skbuff.h</span>
<span class="p_header">index d443d9ab0236..3f61c647fc5c 100644</span>
<span class="p_header">--- a/include/linux/skbuff.h</span>
<span class="p_header">+++ b/include/linux/skbuff.h</span>
<span class="p_chunk">@@ -1084,9 +1084,6 @@</span> <span class="p_context"> static inline void skb_copy_hash(struct sk_buff *to, const struct sk_buff *from)</span>
 
 static inline void skb_sender_cpu_clear(struct sk_buff *skb)
 {
<span class="p_del">-#ifdef CONFIG_XPS</span>
<span class="p_del">-	skb-&gt;sender_cpu = 0;</span>
<span class="p_del">-#endif</span>
 }
 
 #ifdef NET_SKBUFF_DATA_USES_OFFSET
<span class="p_header">diff --git a/include/net/ipv6.h b/include/net/ipv6.h</span>
<span class="p_header">index 9a5c9f013784..ad1d6039185d 100644</span>
<span class="p_header">--- a/include/net/ipv6.h</span>
<span class="p_header">+++ b/include/net/ipv6.h</span>
<span class="p_chunk">@@ -958,6 +958,7 @@</span> <span class="p_context"> int inet6_hash_connect(struct inet_timewait_death_row *death_row,</span>
  */
 extern const struct proto_ops inet6_stream_ops;
 extern const struct proto_ops inet6_dgram_ops;
<span class="p_add">+extern const struct proto_ops inet6_sockraw_ops;</span>
 
 struct group_source_req;
 struct group_filter;
<span class="p_header">diff --git a/kernel/cpuset.c b/kernel/cpuset.c</span>
<span class="p_header">index b271353d5202..3b5e5430f5d0 100644</span>
<span class="p_header">--- a/kernel/cpuset.c</span>
<span class="p_header">+++ b/kernel/cpuset.c</span>
<span class="p_chunk">@@ -173,9 +173,9 @@</span> <span class="p_context"> typedef enum {</span>
 } cpuset_flagbits_t;
 
 /* convenient tests for these bits */
<span class="p_del">-static inline bool is_cpuset_online(const struct cpuset *cs)</span>
<span class="p_add">+static inline bool is_cpuset_online(struct cpuset *cs)</span>
 {
<span class="p_del">-	return test_bit(CS_ONLINE, &amp;cs-&gt;flags);</span>
<span class="p_add">+	return test_bit(CS_ONLINE, &amp;cs-&gt;flags) &amp;&amp; !css_is_dying(&amp;cs-&gt;css);</span>
 }
 
 static inline int is_cpu_exclusive(const struct cpuset *cs)
<span class="p_header">diff --git a/kernel/events/core.c b/kernel/events/core.c</span>
<span class="p_header">index 784ab8fe8714..22350b15b4e7 100644</span>
<span class="p_header">--- a/kernel/events/core.c</span>
<span class="p_header">+++ b/kernel/events/core.c</span>
<span class="p_chunk">@@ -6410,6 +6410,21 @@</span> <span class="p_context"> static void perf_log_itrace_start(struct perf_event *event)</span>
 	perf_output_end(&amp;handle);
 }
 
<span class="p_add">+static bool sample_is_allowed(struct perf_event *event, struct pt_regs *regs)</span>
<span class="p_add">+{</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Due to interrupt latency (AKA &quot;skid&quot;), we may enter the</span>
<span class="p_add">+	 * kernel before taking an overflow, even if the PMU is only</span>
<span class="p_add">+	 * counting user events.</span>
<span class="p_add">+	 * To avoid leaking information to userspace, we must always</span>
<span class="p_add">+	 * reject kernel samples when exclude_kernel is set.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	if (event-&gt;attr.exclude_kernel &amp;&amp; !user_mode(regs))</span>
<span class="p_add">+		return false;</span>
<span class="p_add">+</span>
<span class="p_add">+	return true;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 /*
  * Generic event overflow handling, sampling.
  */
<span class="p_chunk">@@ -6457,6 +6472,12 @@</span> <span class="p_context"> static int __perf_event_overflow(struct perf_event *event,</span>
 	}
 
 	/*
<span class="p_add">+	 * For security, drop the skid kernel samples if necessary.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	if (!sample_is_allowed(event, regs))</span>
<span class="p_add">+		return ret;</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
 	 * XXX event_limit might not quite work as expected on inherited
 	 * events
 	 */
<span class="p_header">diff --git a/kernel/fork.c b/kernel/fork.c</span>
<span class="p_header">index 0ee630f3ad4b..68cfda1c1800 100644</span>
<span class="p_header">--- a/kernel/fork.c</span>
<span class="p_header">+++ b/kernel/fork.c</span>
<span class="p_chunk">@@ -368,7 +368,7 @@</span> <span class="p_context"> static struct task_struct *dup_task_struct(struct task_struct *orig, int node)</span>
 	set_task_stack_end_magic(tsk);
 
 #ifdef CONFIG_CC_STACKPROTECTOR
<span class="p_del">-	tsk-&gt;stack_canary = get_random_int();</span>
<span class="p_add">+	tsk-&gt;stack_canary = get_random_long();</span>
 #endif
 
 	/*
<span class="p_header">diff --git a/kernel/ptrace.c b/kernel/ptrace.c</span>
<span class="p_header">index c7e8ed99c953..5e2cd1030702 100644</span>
<span class="p_header">--- a/kernel/ptrace.c</span>
<span class="p_header">+++ b/kernel/ptrace.c</span>
<span class="p_chunk">@@ -28,19 +28,25 @@</span> <span class="p_context"></span>
 #include &lt;linux/compat.h&gt;
 
 
<span class="p_add">+void __ptrace_link(struct task_struct *child, struct task_struct *new_parent,</span>
<span class="p_add">+		   const struct cred *ptracer_cred)</span>
<span class="p_add">+{</span>
<span class="p_add">+	BUG_ON(!list_empty(&amp;child-&gt;ptrace_entry));</span>
<span class="p_add">+	list_add(&amp;child-&gt;ptrace_entry, &amp;new_parent-&gt;ptraced);</span>
<span class="p_add">+	child-&gt;parent = new_parent;</span>
<span class="p_add">+	child-&gt;ptracer_cred = get_cred(ptracer_cred);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 /*
  * ptrace a task: make the debugger its new parent and
  * move it to the ptrace list.
  *
  * Must be called with the tasklist lock write-held.
  */
<span class="p_del">-void __ptrace_link(struct task_struct *child, struct task_struct *new_parent)</span>
<span class="p_add">+static void ptrace_link(struct task_struct *child, struct task_struct *new_parent)</span>
 {
<span class="p_del">-	BUG_ON(!list_empty(&amp;child-&gt;ptrace_entry));</span>
<span class="p_del">-	list_add(&amp;child-&gt;ptrace_entry, &amp;new_parent-&gt;ptraced);</span>
<span class="p_del">-	child-&gt;parent = new_parent;</span>
 	rcu_read_lock();
<span class="p_del">-	child-&gt;ptracer_cred = get_cred(__task_cred(new_parent));</span>
<span class="p_add">+	__ptrace_link(child, new_parent, __task_cred(new_parent));</span>
 	rcu_read_unlock();
 }
 
<span class="p_chunk">@@ -353,7 +359,7 @@</span> <span class="p_context"> static int ptrace_attach(struct task_struct *task, long request,</span>
 		flags |= PT_SEIZED;
 	task-&gt;ptrace = flags;
 
<span class="p_del">-	__ptrace_link(task, current);</span>
<span class="p_add">+	ptrace_link(task, current);</span>
 
 	/* SEIZE doesn&#39;t trap tracee on attach */
 	if (!seize)
<span class="p_chunk">@@ -420,7 +426,7 @@</span> <span class="p_context"> static int ptrace_traceme(void)</span>
 		 */
 		if (!ret &amp;&amp; !(current-&gt;real_parent-&gt;flags &amp; PF_EXITING)) {
 			current-&gt;ptrace = PT_PTRACED;
<span class="p_del">-			__ptrace_link(current, current-&gt;real_parent);</span>
<span class="p_add">+			ptrace_link(current, current-&gt;real_parent);</span>
 		}
 	}
 	write_unlock_irq(&amp;tasklist_lock);
<span class="p_header">diff --git a/lib/test_user_copy.c b/lib/test_user_copy.c</span>
<span class="p_header">index 0ecef3e4690e..5e6db6b1e3bd 100644</span>
<span class="p_header">--- a/lib/test_user_copy.c</span>
<span class="p_header">+++ b/lib/test_user_copy.c</span>
<span class="p_chunk">@@ -58,7 +58,9 @@</span> <span class="p_context"> static int __init test_user_copy_init(void)</span>
 	usermem = (char __user *)user_addr;
 	bad_usermem = (char *)user_addr;
 
<span class="p_del">-	/* Legitimate usage: none of these should fail. */</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Legitimate usage: none of these copies should fail.</span>
<span class="p_add">+	 */</span>
 	ret |= test(copy_from_user(kmem, usermem, PAGE_SIZE),
 		    &quot;legitimate copy_from_user failed&quot;);
 	ret |= test(copy_to_user(usermem, kmem, PAGE_SIZE),
<span class="p_chunk">@@ -68,19 +70,33 @@</span> <span class="p_context"> static int __init test_user_copy_init(void)</span>
 	ret |= test(put_user(value, (unsigned long __user *)usermem),
 		    &quot;legitimate put_user failed&quot;);
 
<span class="p_del">-	/* Invalid usage: none of these should succeed. */</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Invalid usage: none of these copies should succeed.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+</span>
<span class="p_add">+	/* Reject kernel-to-kernel copies through copy_from_user(). */</span>
 	ret |= test(!copy_from_user(kmem, (char __user *)(kmem + PAGE_SIZE),
 				    PAGE_SIZE),
 		    &quot;illegal all-kernel copy_from_user passed&quot;);
<span class="p_add">+</span>
<span class="p_add">+#if 0</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * When running with SMAP/PAN/etc, this will Oops the kernel</span>
<span class="p_add">+	 * due to the zeroing of userspace memory on failure. This needs</span>
<span class="p_add">+	 * to be tested in LKDTM instead, since this test module does not</span>
<span class="p_add">+	 * expect to explode.</span>
<span class="p_add">+	 */</span>
 	ret |= test(!copy_from_user(bad_usermem, (char __user *)kmem,
 				    PAGE_SIZE),
 		    &quot;illegal reversed copy_from_user passed&quot;);
<span class="p_add">+#endif</span>
 	ret |= test(!copy_to_user((char __user *)kmem, kmem + PAGE_SIZE,
 				  PAGE_SIZE),
 		    &quot;illegal all-kernel copy_to_user passed&quot;);
 	ret |= test(!copy_to_user((char __user *)kmem, bad_usermem,
 				  PAGE_SIZE),
 		    &quot;illegal reversed copy_to_user passed&quot;);
<span class="p_add">+</span>
 	ret |= test(!get_user(value, (unsigned long __user *)kmem),
 		    &quot;illegal get_user passed&quot;);
 	ret |= test(!put_user(value, (unsigned long __user *)kmem),
<span class="p_header">diff --git a/mm/memblock.c b/mm/memblock.c</span>
<span class="p_header">index d300f1329814..f8fab45bfdb7 100644</span>
<span class="p_header">--- a/mm/memblock.c</span>
<span class="p_header">+++ b/mm/memblock.c</span>
<span class="p_chunk">@@ -1634,6 +1634,30 @@</span> <span class="p_context"> static void __init_memblock memblock_dump(struct memblock_type *type, char *name</span>
 	}
 }
 
<span class="p_add">+extern unsigned long __init_memblock</span>
<span class="p_add">+memblock_reserved_memory_within(phys_addr_t start_addr, phys_addr_t end_addr)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct memblock_type *type = &amp;memblock.reserved;</span>
<span class="p_add">+	unsigned long size = 0;</span>
<span class="p_add">+	int idx;</span>
<span class="p_add">+</span>
<span class="p_add">+	for (idx = 0; idx &lt; type-&gt;cnt; idx++) {</span>
<span class="p_add">+		struct memblock_region *rgn = &amp;type-&gt;regions[idx];</span>
<span class="p_add">+		phys_addr_t start, end;</span>
<span class="p_add">+</span>
<span class="p_add">+		if (rgn-&gt;base + rgn-&gt;size &lt; start_addr)</span>
<span class="p_add">+			continue;</span>
<span class="p_add">+		if (rgn-&gt;base &gt; end_addr)</span>
<span class="p_add">+			continue;</span>
<span class="p_add">+</span>
<span class="p_add">+		start = rgn-&gt;base;</span>
<span class="p_add">+		end = start + rgn-&gt;size;</span>
<span class="p_add">+		size += end - start;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	return size;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 void __init_memblock __memblock_dump_all(void)
 {
 	pr_info(&quot;MEMBLOCK configuration:\n&quot;);
<span class="p_header">diff --git a/mm/page_alloc.c b/mm/page_alloc.c</span>
<span class="p_header">index 6f9005dcca2e..bd17a6bdf131 100644</span>
<span class="p_header">--- a/mm/page_alloc.c</span>
<span class="p_header">+++ b/mm/page_alloc.c</span>
<span class="p_chunk">@@ -269,6 +269,26 @@</span> <span class="p_context"> int page_group_by_mobility_disabled __read_mostly;</span>
 #ifdef CONFIG_DEFERRED_STRUCT_PAGE_INIT
 static inline void reset_deferred_meminit(pg_data_t *pgdat)
 {
<span class="p_add">+	unsigned long max_initialise;</span>
<span class="p_add">+	unsigned long reserved_lowmem;</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Initialise at least 2G of a node but also take into account that</span>
<span class="p_add">+	 * two large system hashes that can take up 1GB for 0.25TB/node.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	max_initialise = max(2UL &lt;&lt; (30 - PAGE_SHIFT),</span>
<span class="p_add">+		(pgdat-&gt;node_spanned_pages &gt;&gt; 8));</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Compensate the all the memblock reservations (e.g. crash kernel)</span>
<span class="p_add">+	 * from the initial estimation to make sure we will initialize enough</span>
<span class="p_add">+	 * memory to boot.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	reserved_lowmem = memblock_reserved_memory_within(pgdat-&gt;node_start_pfn,</span>
<span class="p_add">+			pgdat-&gt;node_start_pfn + max_initialise);</span>
<span class="p_add">+	max_initialise += reserved_lowmem;</span>
<span class="p_add">+</span>
<span class="p_add">+	pgdat-&gt;static_init_size = min(max_initialise, pgdat-&gt;node_spanned_pages);</span>
 	pgdat-&gt;first_deferred_pfn = ULONG_MAX;
 }
 
<span class="p_chunk">@@ -302,10 +322,9 @@</span> <span class="p_context"> static inline bool update_defer_init(pg_data_t *pgdat,</span>
 	/* Always populate low zones for address-contrained allocations */
 	if (zone_end &lt; pgdat_end_pfn(pgdat))
 		return true;
<span class="p_del">-</span>
 	/* Initialise at least 2G of the highest zone */
 	(*nr_initialised)++;
<span class="p_del">-	if (*nr_initialised &gt; (2UL &lt;&lt; (30 - PAGE_SHIFT)) &amp;&amp;</span>
<span class="p_add">+	if ((*nr_initialised &gt; pgdat-&gt;static_init_size) &amp;&amp;</span>
 	    (pfn &amp; (PAGES_PER_SECTION - 1)) == 0) {
 		pgdat-&gt;first_deferred_pfn = pfn;
 		return false;
<span class="p_chunk">@@ -5343,7 +5362,6 @@</span> <span class="p_context"> void __paginginit free_area_init_node(int nid, unsigned long *zones_size,</span>
 	/* pg_data_t should be reset to zero when it&#39;s allocated */
 	WARN_ON(pgdat-&gt;nr_zones || pgdat-&gt;classzone_idx);
 
<span class="p_del">-	reset_deferred_meminit(pgdat);</span>
 	pgdat-&gt;node_id = nid;
 	pgdat-&gt;node_start_pfn = node_start_pfn;
 #ifdef CONFIG_HAVE_MEMBLOCK_NODE_MAP
<span class="p_chunk">@@ -5362,6 +5380,7 @@</span> <span class="p_context"> void __paginginit free_area_init_node(int nid, unsigned long *zones_size,</span>
 		(unsigned long)pgdat-&gt;node_mem_map);
 #endif
 
<span class="p_add">+	reset_deferred_meminit(pgdat);</span>
 	free_area_init_core(pgdat);
 }
 
<span class="p_header">diff --git a/mm/truncate.c b/mm/truncate.c</span>
<span class="p_header">index 76e35ad97102..f4c8270f7b84 100644</span>
<span class="p_header">--- a/mm/truncate.c</span>
<span class="p_header">+++ b/mm/truncate.c</span>
<span class="p_chunk">@@ -732,7 +732,7 @@</span> <span class="p_context"> EXPORT_SYMBOL(truncate_setsize);</span>
  */
 void pagecache_isize_extended(struct inode *inode, loff_t from, loff_t to)
 {
<span class="p_del">-	int bsize = 1 &lt;&lt; inode-&gt;i_blkbits;</span>
<span class="p_add">+	int bsize = i_blocksize(inode);</span>
 	loff_t rounded_from;
 	struct page *page;
 	pgoff_t index;
<span class="p_header">diff --git a/net/bridge/br_stp_if.c b/net/bridge/br_stp_if.c</span>
<span class="p_header">index 57be733a99bc..bcb4559e735d 100644</span>
<span class="p_header">--- a/net/bridge/br_stp_if.c</span>
<span class="p_header">+++ b/net/bridge/br_stp_if.c</span>
<span class="p_chunk">@@ -166,7 +166,8 @@</span> <span class="p_context"> static void br_stp_start(struct net_bridge *br)</span>
 		br_debug(br, &quot;using kernel STP\n&quot;);
 
 		/* To start timers on any ports left in blocking */
<span class="p_del">-		mod_timer(&amp;br-&gt;hello_timer, jiffies + br-&gt;hello_time);</span>
<span class="p_add">+		if (br-&gt;dev-&gt;flags &amp; IFF_UP)</span>
<span class="p_add">+			mod_timer(&amp;br-&gt;hello_timer, jiffies + br-&gt;hello_time);</span>
 		br_port_state_selection(br);
 	}
 
<span class="p_header">diff --git a/net/core/dev.c b/net/core/dev.c</span>
<span class="p_header">index 48399d8ce614..87b8754f34ac 100644</span>
<span class="p_header">--- a/net/core/dev.c</span>
<span class="p_header">+++ b/net/core/dev.c</span>
<span class="p_chunk">@@ -182,7 +182,7 @@</span> <span class="p_context"> EXPORT_SYMBOL(dev_base_lock);</span>
 /* protects napi_hash addition/deletion and napi_gen_id */
 static DEFINE_SPINLOCK(napi_hash_lock);
 
<span class="p_del">-static unsigned int napi_gen_id;</span>
<span class="p_add">+static unsigned int napi_gen_id = NR_CPUS;</span>
 static DEFINE_HASHTABLE(napi_hash, 8);
 
 static seqcount_t devnet_rename_seq;
<span class="p_chunk">@@ -3049,7 +3049,9 @@</span> <span class="p_context"> struct netdev_queue *netdev_pick_tx(struct net_device *dev,</span>
 	int queue_index = 0;
 
 #ifdef CONFIG_XPS
<span class="p_del">-	if (skb-&gt;sender_cpu == 0)</span>
<span class="p_add">+	u32 sender_cpu = skb-&gt;sender_cpu - 1;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (sender_cpu &gt;= (u32)NR_CPUS)</span>
 		skb-&gt;sender_cpu = raw_smp_processor_id() + 1;
 #endif
 
<span class="p_chunk">@@ -4726,25 +4728,22 @@</span> <span class="p_context"> EXPORT_SYMBOL_GPL(napi_by_id);</span>
 
 void napi_hash_add(struct napi_struct *napi)
 {
<span class="p_del">-	if (!test_and_set_bit(NAPI_STATE_HASHED, &amp;napi-&gt;state)) {</span>
<span class="p_add">+	if (test_and_set_bit(NAPI_STATE_HASHED, &amp;napi-&gt;state))</span>
<span class="p_add">+		return;</span>
 
<span class="p_del">-		spin_lock(&amp;napi_hash_lock);</span>
<span class="p_add">+	spin_lock(&amp;napi_hash_lock);</span>
 
<span class="p_del">-		/* 0 is not a valid id, we also skip an id that is taken</span>
<span class="p_del">-		 * we expect both events to be extremely rare</span>
<span class="p_del">-		 */</span>
<span class="p_del">-		napi-&gt;napi_id = 0;</span>
<span class="p_del">-		while (!napi-&gt;napi_id) {</span>
<span class="p_del">-			napi-&gt;napi_id = ++napi_gen_id;</span>
<span class="p_del">-			if (napi_by_id(napi-&gt;napi_id))</span>
<span class="p_del">-				napi-&gt;napi_id = 0;</span>
<span class="p_del">-		}</span>
<span class="p_add">+	/* 0..NR_CPUS+1 range is reserved for sender_cpu use */</span>
<span class="p_add">+	do {</span>
<span class="p_add">+		if (unlikely(++napi_gen_id &lt; NR_CPUS + 1))</span>
<span class="p_add">+			napi_gen_id = NR_CPUS + 1;</span>
<span class="p_add">+	} while (napi_by_id(napi_gen_id));</span>
<span class="p_add">+	napi-&gt;napi_id = napi_gen_id;</span>
 
<span class="p_del">-		hlist_add_head_rcu(&amp;napi-&gt;napi_hash_node,</span>
<span class="p_del">-			&amp;napi_hash[napi-&gt;napi_id % HASH_SIZE(napi_hash)]);</span>
<span class="p_add">+	hlist_add_head_rcu(&amp;napi-&gt;napi_hash_node,</span>
<span class="p_add">+			   &amp;napi_hash[napi-&gt;napi_id % HASH_SIZE(napi_hash)]);</span>
 
<span class="p_del">-		spin_unlock(&amp;napi_hash_lock);</span>
<span class="p_del">-	}</span>
<span class="p_add">+	spin_unlock(&amp;napi_hash_lock);</span>
 }
 EXPORT_SYMBOL_GPL(napi_hash_add);
 
<span class="p_header">diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c</span>
<span class="p_header">index afc18e9ca94a..967a47ff78a4 100644</span>
<span class="p_header">--- a/net/ipv4/af_inet.c</span>
<span class="p_header">+++ b/net/ipv4/af_inet.c</span>
<span class="p_chunk">@@ -1014,7 +1014,7 @@</span> <span class="p_context"> static struct inet_protosw inetsw_array[] =</span>
 		.type =       SOCK_DGRAM,
 		.protocol =   IPPROTO_ICMP,
 		.prot =       &amp;ping_prot,
<span class="p_del">-		.ops =        &amp;inet_dgram_ops,</span>
<span class="p_add">+		.ops =        &amp;inet_sockraw_ops,</span>
 		.flags =      INET_PROTOSW_REUSE,
        },
 
<span class="p_header">diff --git a/net/ipv4/tcp_cong.c b/net/ipv4/tcp_cong.c</span>
<span class="p_header">index 882caa4e72bc..aafe68134763 100644</span>
<span class="p_header">--- a/net/ipv4/tcp_cong.c</span>
<span class="p_header">+++ b/net/ipv4/tcp_cong.c</span>
<span class="p_chunk">@@ -183,6 +183,7 @@</span> <span class="p_context"> void tcp_init_congestion_control(struct sock *sk)</span>
 {
 	const struct inet_connection_sock *icsk = inet_csk(sk);
 
<span class="p_add">+	tcp_sk(sk)-&gt;prior_ssthresh = 0;</span>
 	if (icsk-&gt;icsk_ca_ops-&gt;init)
 		icsk-&gt;icsk_ca_ops-&gt;init(sk);
 	if (tcp_ca_needs_ecn(sk))
<span class="p_header">diff --git a/net/ipv6/ip6_offload.c b/net/ipv6/ip6_offload.c</span>
<span class="p_header">index 568bc0a52ca1..9e2ea4ae840d 100644</span>
<span class="p_header">--- a/net/ipv6/ip6_offload.c</span>
<span class="p_header">+++ b/net/ipv6/ip6_offload.c</span>
<span class="p_chunk">@@ -121,8 +121,10 @@</span> <span class="p_context"> static struct sk_buff *ipv6_gso_segment(struct sk_buff *skb,</span>
 
 		if (udpfrag) {
 			int err = ip6_find_1stfragopt(skb, &amp;prevhdr);
<span class="p_del">-			if (err &lt; 0)</span>
<span class="p_add">+			if (err &lt; 0) {</span>
<span class="p_add">+				kfree_skb_list(segs);</span>
 				return ERR_PTR(err);
<span class="p_add">+			}</span>
 			fptr = (struct frag_hdr *)((u8 *)ipv6h + err);
 			fptr-&gt;frag_off = htons(offset);
 			if (skb-&gt;next)
<span class="p_header">diff --git a/net/ipv6/ping.c b/net/ipv6/ping.c</span>
<span class="p_header">index 3e55447b63a4..a830b68e63c9 100644</span>
<span class="p_header">--- a/net/ipv6/ping.c</span>
<span class="p_header">+++ b/net/ipv6/ping.c</span>
<span class="p_chunk">@@ -50,7 +50,7 @@</span> <span class="p_context"> static struct inet_protosw pingv6_protosw = {</span>
 	.type =      SOCK_DGRAM,
 	.protocol =  IPPROTO_ICMPV6,
 	.prot =      &amp;pingv6_prot,
<span class="p_del">-	.ops =       &amp;inet6_dgram_ops,</span>
<span class="p_add">+	.ops =       &amp;inet6_sockraw_ops,</span>
 	.flags =     INET_PROTOSW_REUSE,
 };
 
<span class="p_header">diff --git a/net/ipv6/raw.c b/net/ipv6/raw.c</span>
<span class="p_header">index c93ede16795d..4d52a0e2f60d 100644</span>
<span class="p_header">--- a/net/ipv6/raw.c</span>
<span class="p_header">+++ b/net/ipv6/raw.c</span>
<span class="p_chunk">@@ -1303,7 +1303,7 @@</span> <span class="p_context"> void raw6_proc_exit(void)</span>
 #endif	/* CONFIG_PROC_FS */
 
 /* Same as inet6_dgram_ops, sans udp_poll.  */
<span class="p_del">-static const struct proto_ops inet6_sockraw_ops = {</span>
<span class="p_add">+const struct proto_ops inet6_sockraw_ops = {</span>
 	.family		   = PF_INET6,
 	.owner		   = THIS_MODULE,
 	.release	   = inet6_release,
<span class="p_header">diff --git a/net/ipv6/xfrm6_mode_ro.c b/net/ipv6/xfrm6_mode_ro.c</span>
<span class="p_header">index 0e015906f9ca..07d36573f50b 100644</span>
<span class="p_header">--- a/net/ipv6/xfrm6_mode_ro.c</span>
<span class="p_header">+++ b/net/ipv6/xfrm6_mode_ro.c</span>
<span class="p_chunk">@@ -47,6 +47,8 @@</span> <span class="p_context"> static int xfrm6_ro_output(struct xfrm_state *x, struct sk_buff *skb)</span>
 	iph = ipv6_hdr(skb);
 
 	hdr_len = x-&gt;type-&gt;hdr_offset(x, skb, &amp;prevhdr);
<span class="p_add">+	if (hdr_len &lt; 0)</span>
<span class="p_add">+		return hdr_len;</span>
 	skb_set_mac_header(skb, (prevhdr - x-&gt;props.header_len) - skb-&gt;data);
 	skb_set_network_header(skb, -x-&gt;props.header_len);
 	skb-&gt;transport_header = skb-&gt;network_header + hdr_len;
<span class="p_header">diff --git a/net/ipv6/xfrm6_mode_transport.c b/net/ipv6/xfrm6_mode_transport.c</span>
<span class="p_header">index 4e344105b3fd..1d3bbe6e1183 100644</span>
<span class="p_header">--- a/net/ipv6/xfrm6_mode_transport.c</span>
<span class="p_header">+++ b/net/ipv6/xfrm6_mode_transport.c</span>
<span class="p_chunk">@@ -28,6 +28,8 @@</span> <span class="p_context"> static int xfrm6_transport_output(struct xfrm_state *x, struct sk_buff *skb)</span>
 	iph = ipv6_hdr(skb);
 
 	hdr_len = x-&gt;type-&gt;hdr_offset(x, skb, &amp;prevhdr);
<span class="p_add">+	if (hdr_len &lt; 0)</span>
<span class="p_add">+		return hdr_len;</span>
 	skb_set_mac_header(skb, (prevhdr - x-&gt;props.header_len) - skb-&gt;data);
 	skb_set_network_header(skb, -x-&gt;props.header_len);
 	skb-&gt;transport_header = skb-&gt;network_header + hdr_len;
<span class="p_header">diff --git a/security/keys/key.c b/security/keys/key.c</span>
<span class="p_header">index 534808915371..09c10b181881 100644</span>
<span class="p_header">--- a/security/keys/key.c</span>
<span class="p_header">+++ b/security/keys/key.c</span>
<span class="p_chunk">@@ -934,12 +934,11 @@</span> <span class="p_context"> int key_update(key_ref_t key_ref, const void *payload, size_t plen)</span>
 	/* the key must be writable */
 	ret = key_permission(key_ref, KEY_NEED_WRITE);
 	if (ret &lt; 0)
<span class="p_del">-		goto error;</span>
<span class="p_add">+		return ret;</span>
 
 	/* attempt to update it if supported */
<span class="p_del">-	ret = -EOPNOTSUPP;</span>
 	if (!key-&gt;type-&gt;update)
<span class="p_del">-		goto error;</span>
<span class="p_add">+		return -EOPNOTSUPP;</span>
 
 	memset(&amp;prep, 0, sizeof(prep));
 	prep.data = payload;
<span class="p_header">diff --git a/security/keys/keyctl.c b/security/keys/keyctl.c</span>
<span class="p_header">index 442e350c209d..671709d8610d 100644</span>
<span class="p_header">--- a/security/keys/keyctl.c</span>
<span class="p_header">+++ b/security/keys/keyctl.c</span>
<span class="p_chunk">@@ -97,7 +97,7 @@</span> <span class="p_context"> SYSCALL_DEFINE5(add_key, const char __user *, _type,</span>
 	/* pull the payload in if one was supplied */
 	payload = NULL;
 
<span class="p_del">-	if (_payload) {</span>
<span class="p_add">+	if (plen) {</span>
 		ret = -ENOMEM;
 		payload = kmalloc(plen, GFP_KERNEL | __GFP_NOWARN);
 		if (!payload) {
<span class="p_chunk">@@ -327,7 +327,7 @@</span> <span class="p_context"> long keyctl_update_key(key_serial_t id,</span>
 
 	/* pull the payload in if one was supplied */
 	payload = NULL;
<span class="p_del">-	if (_payload) {</span>
<span class="p_add">+	if (plen) {</span>
 		ret = -ENOMEM;
 		payload = kmalloc(plen, GFP_KERNEL);
 		if (!payload)
<span class="p_header">diff --git a/sound/core/timer.c b/sound/core/timer.c</span>
<span class="p_header">index 278a332f97bd..48eaccba82a3 100644</span>
<span class="p_header">--- a/sound/core/timer.c</span>
<span class="p_header">+++ b/sound/core/timer.c</span>
<span class="p_chunk">@@ -1621,6 +1621,7 @@</span> <span class="p_context"> static int snd_timer_user_tselect(struct file *file,</span>
 	if (err &lt; 0)
 		goto __err;
 
<span class="p_add">+	tu-&gt;qhead = tu-&gt;qtail = tu-&gt;qused = 0;</span>
 	kfree(tu-&gt;queue);
 	tu-&gt;queue = NULL;
 	kfree(tu-&gt;tqueue);
<span class="p_chunk">@@ -1958,6 +1959,7 @@</span> <span class="p_context"> static ssize_t snd_timer_user_read(struct file *file, char __user *buffer,</span>
 
 	tu = file-&gt;private_data;
 	unit = tu-&gt;tread ? sizeof(struct snd_timer_tread) : sizeof(struct snd_timer_read);
<span class="p_add">+	mutex_lock(&amp;tu-&gt;ioctl_lock);</span>
 	spin_lock_irq(&amp;tu-&gt;qlock);
 	while ((long)count - result &gt;= unit) {
 		while (!tu-&gt;qused) {
<span class="p_chunk">@@ -1973,7 +1975,9 @@</span> <span class="p_context"> static ssize_t snd_timer_user_read(struct file *file, char __user *buffer,</span>
 			add_wait_queue(&amp;tu-&gt;qchange_sleep, &amp;wait);
 
 			spin_unlock_irq(&amp;tu-&gt;qlock);
<span class="p_add">+			mutex_unlock(&amp;tu-&gt;ioctl_lock);</span>
 			schedule();
<span class="p_add">+			mutex_lock(&amp;tu-&gt;ioctl_lock);</span>
 			spin_lock_irq(&amp;tu-&gt;qlock);
 
 			remove_wait_queue(&amp;tu-&gt;qchange_sleep, &amp;wait);
<span class="p_chunk">@@ -1993,7 +1997,6 @@</span> <span class="p_context"> static ssize_t snd_timer_user_read(struct file *file, char __user *buffer,</span>
 		tu-&gt;qused--;
 		spin_unlock_irq(&amp;tu-&gt;qlock);
 
<span class="p_del">-		mutex_lock(&amp;tu-&gt;ioctl_lock);</span>
 		if (tu-&gt;tread) {
 			if (copy_to_user(buffer, &amp;tu-&gt;tqueue[qhead],
 					 sizeof(struct snd_timer_tread)))
<span class="p_chunk">@@ -2003,7 +2006,6 @@</span> <span class="p_context"> static ssize_t snd_timer_user_read(struct file *file, char __user *buffer,</span>
 					 sizeof(struct snd_timer_read)))
 				err = -EFAULT;
 		}
<span class="p_del">-		mutex_unlock(&amp;tu-&gt;ioctl_lock);</span>
 
 		spin_lock_irq(&amp;tu-&gt;qlock);
 		if (err &lt; 0)
<span class="p_chunk">@@ -2013,6 +2015,7 @@</span> <span class="p_context"> static ssize_t snd_timer_user_read(struct file *file, char __user *buffer,</span>
 	}
  _error:
 	spin_unlock_irq(&amp;tu-&gt;qlock);
<span class="p_add">+	mutex_unlock(&amp;tu-&gt;ioctl_lock);</span>
 	return result &gt; 0 ? result : err;
 }
 
<span class="p_header">diff --git a/sound/soc/soc-core.c b/sound/soc/soc-core.c</span>
<span class="p_header">index a1305f827a98..fa6b74a304a7 100644</span>
<span class="p_header">--- a/sound/soc/soc-core.c</span>
<span class="p_header">+++ b/sound/soc/soc-core.c</span>
<span class="p_chunk">@@ -1775,6 +1775,9 @@</span> <span class="p_context"> static int soc_cleanup_card_resources(struct snd_soc_card *card)</span>
 	for (i = 0; i &lt; card-&gt;num_aux_devs; i++)
 		soc_remove_aux_dev(card, i);
 
<span class="p_add">+	/* free the ALSA card at first; this syncs with pending operations */</span>
<span class="p_add">+	snd_card_free(card-&gt;snd_card);</span>
<span class="p_add">+</span>
 	/* remove and free each DAI */
 	soc_remove_dai_links(card);
 
<span class="p_chunk">@@ -1786,9 +1789,7 @@</span> <span class="p_context"> static int soc_cleanup_card_resources(struct snd_soc_card *card)</span>
 
 	snd_soc_dapm_free(&amp;card-&gt;dapm);
 
<span class="p_del">-	snd_card_free(card-&gt;snd_card);</span>
 	return 0;
<span class="p_del">-</span>
 }
 
 /* removes a socdev */

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



