
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>[v2,2/4] KVM: Add paravirt remote TLB flush - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    [v2,2/4] KVM: Add paravirt remote TLB flush</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=104371">Wanpeng Li</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>Nov. 10, 2017, 7:04 a.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;1510297497-10063-3-git-send-email-wanpeng.li@hotmail.com&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/10052475/mbox/"
   >mbox</a>
|
   <a href="/patch/10052475/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/10052475/">/patch/10052475/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
	[172.30.200.125])
	by pdx-korg-patchwork.web.codeaurora.org (Postfix) with ESMTP id
	7F10D6032D for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Fri, 10 Nov 2017 07:05:58 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 70D5F2B0F4
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Fri, 10 Nov 2017 07:05:58 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id 658512B297; Fri, 10 Nov 2017 07:05:58 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-7.0 required=2.0 tests=BAYES_00,DKIM_SIGNED,
	DKIM_VALID, DKIM_VALID_AU, FREEMAIL_FROM,
	RCVD_IN_DNSWL_HI autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id E88422B0F4
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Fri, 10 Nov 2017 07:05:57 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1755899AbdKJHFy (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Fri, 10 Nov 2017 02:05:54 -0500
Received: from mail-pg0-f66.google.com ([74.125.83.66]:48807 &quot;EHLO
	mail-pg0-f66.google.com&quot; rhost-flags-OK-OK-OK-OK) by vger.kernel.org
	with ESMTP id S1755398AbdKJHFI (ORCPT
	&lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Fri, 10 Nov 2017 02:05:08 -0500
Received: by mail-pg0-f66.google.com with SMTP id s11so1302044pgc.5;
	Thu, 09 Nov 2017 23:05:08 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
	d=gmail.com; s=20161025;
	h=from:to:cc:subject:date:message-id:in-reply-to:references
	:mime-version:content-transfer-encoding;
	bh=J1Dn+fIiqHe///vGc47gR+QKzpFmHrxhLypvLYO3POw=;
	b=AuBLjQHaw21hj1lGk2nn4HPbbWW2bl7NQ1dCN1gvN21IdQXdZHe4dWNfm57R62rDdb
	VPD1S/MuR6XQVRzKQR31T/15CuwPJlSukBzZxhvz/g6oMbSGa298UNbXGhcP+eq4tuvz
	KntveZTsgMxXYLjqbyH1uSpUfIfgfSFC9LHUa7AZOlvTjIGKTC7nq5OhulYfsjGwqW+E
	dhnSMfF8anCER7G0GtZ2Z3EfcL6D2EmCDndpR+qh5Z3kBSJkoJ5bf2+SLkR7IO9d3+P2
	4Y3RuKiwCestYZDm2zABmzsvQGBTCr1Yt725lNGQ9/YahXIIhybJXdI5p4ocqoGJnbs5
	wmgA==
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
	d=1e100.net; s=20161025;
	h=x-gm-message-state:from:to:cc:subject:date:message-id:in-reply-to
	:references:mime-version:content-transfer-encoding;
	bh=J1Dn+fIiqHe///vGc47gR+QKzpFmHrxhLypvLYO3POw=;
	b=bPvbnQqiDdpwxkgv30dxu+9QtMETO8zAUYtfEVPWFacbwHv7gwMYRk734zRE8FRxW0
	/95xhrKppcDCzzSm+W+HypiaFJyw3zBNTtZ617IiSRfun+lIi0SKIowWG6KMAyojdJdH
	m4JSGoe/Rfp7r5Kc8VuwCjAAI5poPcfn2p/gIW45QSLEWctnzlS9o4RtLarmWM2630Xv
	D08Hm31bEh9R6TfUneFgsmI50VwNQanlCyJAinEPSssB/hpF3HaTrQxSkcbNIi2+LWHX
	bMC0WYDh82Zwsi77gvmT59AkNRyg5Nj6pVVGGb61jDNtWRLUo2HE1RmKAjXYixBijxcK
	+Atw==
X-Gm-Message-State: AJaThX7GNKA9vEW8HlS93CNoFJAYxVYk6bJCrUrYSmnBflnjGSUYK58x
	c6eUECuBtfzWqnVqSg8kB8XGMQ==
X-Google-Smtp-Source: ABhQp+RxKjBIw/0c2zXLVpgBgCgJukK2Eo51krDGpJhtjq15X1hymiIDCqVpJr6BIJQ7ujlGw0IH6Q==
X-Received: by 10.99.126.78 with SMTP id o14mr3140977pgn.159.1510297507808; 
	Thu, 09 Nov 2017 23:05:07 -0800 (PST)
Received: from localhost ([203.205.141.123])
	by smtp.gmail.com with ESMTPSA id
	b9sm13486597pgu.20.2017.11.09.23.05.06
	(version=TLS1_2 cipher=ECDHE-RSA-AES128-GCM-SHA256 bits=128/128);
	Thu, 09 Nov 2017 23:05:07 -0800 (PST)
From: Wanpeng Li &lt;kernellwp@gmail.com&gt;
X-Google-Original-From: Wanpeng Li &lt;wanpeng.li@hotmail.com&gt;
To: linux-kernel@vger.kernel.org, kvm@vger.kernel.org
Cc: Paolo Bonzini &lt;pbonzini@redhat.com&gt;,
	=?UTF-8?q?Radim=20Kr=C4=8Dm=C3=A1=C5=99?= &lt;rkrcmar@redhat.com&gt;,
	Wanpeng Li &lt;wanpeng.li@hotmail.com&gt;
Subject: [PATCH v2 2/4] KVM: Add paravirt remote TLB flush
Date: Thu,  9 Nov 2017 23:04:55 -0800
Message-Id: &lt;1510297497-10063-3-git-send-email-wanpeng.li@hotmail.com&gt;
X-Mailer: git-send-email 2.7.4
In-Reply-To: &lt;1510297497-10063-1-git-send-email-wanpeng.li@hotmail.com&gt;
References: &lt;1510297497-10063-1-git-send-email-wanpeng.li@hotmail.com&gt;
MIME-Version: 1.0
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 8bit
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=104371">Wanpeng Li</a> - Nov. 10, 2017, 7:04 a.m.</div>
<pre class="content">
<span class="from">From: Wanpeng Li &lt;wanpeng.li@hotmail.com&gt;</span>

Remote flushing api&#39;s does a busy wait which is fine in bare-metal
scenario. But with-in the guest, the vcpus might have been pre-empted
or blocked. In this scenario, the initator vcpu would end up
busy-waiting for a long amount of time.

This patch set implements para-virt flush tlbs making sure that it
does not wait for vcpus that are sleeping. And all the sleeping vcpus
flush the tlb on guest enter.

The best result is achieved when we&#39;re overcommiting the host by running 
multiple vCPUs on each pCPU. In this case PV tlb flush avoids touching 
vCPUs which are not scheduled and avoid the wait on the main CPU.

Test on a Haswell i7 desktop 4 cores (2HT), so 8 pCPUs, running ebizzy in 
one linux guest.

ebizzy -M 
              vanilla    optimized     boost
 8 vCPUs       10152       10083       -0.68% 
16 vCPUs        1224        4866       297.5% 
24 vCPUs        1109        3871       249%
32 vCPUs        1025        3375       229.3% 

Cc: Paolo Bonzini &lt;pbonzini@redhat.com&gt;
Cc: Radim Krčmář &lt;rkrcmar@redhat.com&gt;
<span class="signed-off-by">Signed-off-by: Wanpeng Li &lt;wanpeng.li@hotmail.com&gt;</span>
---
 Documentation/virtual/kvm/cpuid.txt  |  4 ++++
 arch/x86/include/uapi/asm/kvm_para.h |  2 ++
 arch/x86/kernel/kvm.c                | 31 +++++++++++++++++++++++++++++++
 3 files changed, 37 insertions(+)
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=2536">Paolo Bonzini</a> - Nov. 10, 2017, 8:24 a.m.</div>
<pre class="content">
On 10/11/2017 08:04, Wanpeng Li wrote:
<span class="quote">&gt; From: Wanpeng Li &lt;wanpeng.li@hotmail.com&gt;</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Remote flushing api&#39;s does a busy wait which is fine in bare-metal</span>
<span class="quote">&gt; scenario. But with-in the guest, the vcpus might have been pre-empted</span>
<span class="quote">&gt; or blocked. In this scenario, the initator vcpu would end up</span>
<span class="quote">&gt; busy-waiting for a long amount of time.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; This patch set implements para-virt flush tlbs making sure that it</span>
<span class="quote">&gt; does not wait for vcpus that are sleeping. And all the sleeping vcpus</span>
<span class="quote">&gt; flush the tlb on guest enter.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; The best result is achieved when we&#39;re overcommiting the host by running </span>
<span class="quote">&gt; multiple vCPUs on each pCPU. In this case PV tlb flush avoids touching </span>
<span class="quote">&gt; vCPUs which are not scheduled and avoid the wait on the main CPU.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Test on a Haswell i7 desktop 4 cores (2HT), so 8 pCPUs, running ebizzy in </span>
<span class="quote">&gt; one linux guest.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; ebizzy -M </span>
<span class="quote">&gt;               vanilla    optimized     boost</span>
<span class="quote">&gt;  8 vCPUs       10152       10083       -0.68% </span>
<span class="quote">&gt; 16 vCPUs        1224        4866       297.5% </span>
<span class="quote">&gt; 24 vCPUs        1109        3871       249%</span>
<span class="quote">&gt; 32 vCPUs        1025        3375       229.3% </span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Cc: Paolo Bonzini &lt;pbonzini@redhat.com&gt;</span>
<span class="quote">&gt; Cc: Radim Krčmář &lt;rkrcmar@redhat.com&gt;</span>
<span class="quote">&gt; Signed-off-by: Wanpeng Li &lt;wanpeng.li@hotmail.com&gt;</span>
<span class="quote">&gt; ---</span>
<span class="quote">&gt;  Documentation/virtual/kvm/cpuid.txt  |  4 ++++</span>
<span class="quote">&gt;  arch/x86/include/uapi/asm/kvm_para.h |  2 ++</span>
<span class="quote">&gt;  arch/x86/kernel/kvm.c                | 31 +++++++++++++++++++++++++++++++</span>
<span class="quote">&gt;  3 files changed, 37 insertions(+)</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; diff --git a/Documentation/virtual/kvm/cpuid.txt b/Documentation/virtual/kvm/cpuid.txt</span>
<span class="quote">&gt; index 117066a..9693fcc 100644</span>
<span class="quote">&gt; --- a/Documentation/virtual/kvm/cpuid.txt</span>
<span class="quote">&gt; +++ b/Documentation/virtual/kvm/cpuid.txt</span>
<span class="quote">&gt; @@ -60,6 +60,10 @@ KVM_FEATURE_PV_DEDICATED           ||     8 || guest checks this feature bit</span>
<span class="quote">&gt;                                     ||       || mizations such as usage of</span>
<span class="quote">&gt;                                     ||       || qspinlocks.</span>
<span class="quote">&gt;  ------------------------------------------------------------------------------</span>
<span class="quote">&gt; +KVM_FEATURE_PV_TLB_FLUSH           ||     9 || guest checks this feature bit</span>
<span class="quote">&gt; +                                   ||       || before enabling paravirtualized</span>
<span class="quote">&gt; +                                   ||       || tlb flush.</span>
<span class="quote">&gt; +------------------------------------------------------------------------------</span>
<span class="quote">&gt;  KVM_FEATURE_CLOCKSOURCE_STABLE_BIT ||    24 || host will warn if no guest-side</span>
<span class="quote">&gt;                                     ||       || per-cpu warps are expected in</span>
<span class="quote">&gt;                                     ||       || kvmclock.</span>
<span class="quote">&gt; diff --git a/arch/x86/include/uapi/asm/kvm_para.h b/arch/x86/include/uapi/asm/kvm_para.h</span>
<span class="quote">&gt; index 9ead1ed..a028479 100644</span>
<span class="quote">&gt; --- a/arch/x86/include/uapi/asm/kvm_para.h</span>
<span class="quote">&gt; +++ b/arch/x86/include/uapi/asm/kvm_para.h</span>
<span class="quote">&gt; @@ -25,6 +25,7 @@</span>
<span class="quote">&gt;  #define KVM_FEATURE_PV_EOI		6</span>
<span class="quote">&gt;  #define KVM_FEATURE_PV_UNHALT		7</span>
<span class="quote">&gt;  #define KVM_FEATURE_PV_DEDICATED	8</span>
<span class="quote">&gt; +#define KVM_FEATURE_PV_TLB_FLUSH	9</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  /* The last 8 bits are used to indicate how to interpret the flags field</span>
<span class="quote">&gt;   * in pvclock structure. If no bits are set, all flags are ignored.</span>
<span class="quote">&gt; @@ -53,6 +54,7 @@ struct kvm_steal_time {</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  #define KVM_VCPU_NOT_PREEMPTED      (0 &lt;&lt; 0)</span>
<span class="quote">&gt;  #define KVM_VCPU_PREEMPTED          (1 &lt;&lt; 0)</span>
<span class="quote">&gt; +#define KVM_VCPU_SHOULD_FLUSH       (1 &lt;&lt; 1)</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;  #define KVM_CLOCK_PAIRING_WALLCLOCK 0</span>
<span class="quote">&gt;  struct kvm_clock_pairing {</span>
<span class="quote">&gt; diff --git a/arch/x86/kernel/kvm.c b/arch/x86/kernel/kvm.c</span>
<span class="quote">&gt; index 66ed3bc..50f4b6a 100644</span>
<span class="quote">&gt; --- a/arch/x86/kernel/kvm.c</span>
<span class="quote">&gt; +++ b/arch/x86/kernel/kvm.c</span>
<span class="quote">&gt; @@ -465,6 +465,33 @@ static void __init kvm_apf_trap_init(void)</span>
<span class="quote">&gt;  	update_intr_gate(X86_TRAP_PF, async_page_fault);</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; +static cpumask_t flushmask;</span>

Hi Wanpeng,

are you going to send v3 with a percpu variable?

Paolo
<span class="quote">
&gt; +static void kvm_flush_tlb_others(const struct cpumask *cpumask,</span>
<span class="quote">&gt; +			const struct flush_tlb_info *info)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +	u8 state;</span>
<span class="quote">&gt; +	int cpu;</span>
<span class="quote">&gt; +	struct kvm_steal_time *src;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	cpumask_copy(&amp;flushmask, cpumask);</span>
<span class="quote">&gt; +	/*</span>
<span class="quote">&gt; +	 * We have to call flush only on online vCPUs. And</span>
<span class="quote">&gt; +	 * queue flush_on_enter for pre-empted vCPUs</span>
<span class="quote">&gt; +	 */</span>
<span class="quote">&gt; +	for_each_cpu(cpu, cpumask) {</span>
<span class="quote">&gt; +		src = &amp;per_cpu(steal_time, cpu);</span>
<span class="quote">&gt; +		state = src-&gt;preempted;</span>
<span class="quote">&gt; +		if ((state &amp; KVM_VCPU_PREEMPTED)) {</span>
<span class="quote">&gt; +			if (cmpxchg(&amp;src-&gt;preempted, state, state |</span>
<span class="quote">&gt; +				KVM_VCPU_SHOULD_FLUSH) == state)</span>
<span class="quote">&gt; +				__cpumask_clear_cpu(cpu, &amp;flushmask);</span>
<span class="quote">&gt; +		}</span>
<span class="quote">&gt; +	}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +	native_flush_tlb_others(&amp;flushmask, info);</span>
<span class="quote">&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt;  void __init kvm_guest_init(void)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;  	int i;</span>
<span class="quote">&gt; @@ -484,6 +511,10 @@ void __init kvm_guest_init(void)</span>
<span class="quote">&gt;  		pv_time_ops.steal_clock = kvm_steal_clock;</span>
<span class="quote">&gt;  	}</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt; +	if (kvm_para_has_feature(KVM_FEATURE_PV_TLB_FLUSH) &amp;&amp;</span>
<span class="quote">&gt; +		!kvm_para_has_feature(KVM_FEATURE_PV_DEDICATED))</span>
<span class="quote">&gt; +		pv_mmu_ops.flush_tlb_others = kvm_flush_tlb_others;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt;  	if (kvm_para_has_feature(KVM_FEATURE_PV_EOI))</span>
<span class="quote">&gt;  		apic_set_eoi_write(kvm_guest_apic_eoi_write);</span>
<span class="quote">&gt;  </span>
<span class="quote">&gt;</span>
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=104371">Wanpeng Li</a> - Nov. 10, 2017, 8:33 a.m.</div>
<pre class="content">
2017-11-10 16:24 GMT+08:00 Paolo Bonzini &lt;pbonzini@redhat.com&gt;:
<span class="quote">&gt; On 10/11/2017 08:04, Wanpeng Li wrote:</span>
<span class="quote">&gt;&gt; From: Wanpeng Li &lt;wanpeng.li@hotmail.com&gt;</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; Remote flushing api&#39;s does a busy wait which is fine in bare-metal</span>
<span class="quote">&gt;&gt; scenario. But with-in the guest, the vcpus might have been pre-empted</span>
<span class="quote">&gt;&gt; or blocked. In this scenario, the initator vcpu would end up</span>
<span class="quote">&gt;&gt; busy-waiting for a long amount of time.</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; This patch set implements para-virt flush tlbs making sure that it</span>
<span class="quote">&gt;&gt; does not wait for vcpus that are sleeping. And all the sleeping vcpus</span>
<span class="quote">&gt;&gt; flush the tlb on guest enter.</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; The best result is achieved when we&#39;re overcommiting the host by running</span>
<span class="quote">&gt;&gt; multiple vCPUs on each pCPU. In this case PV tlb flush avoids touching</span>
<span class="quote">&gt;&gt; vCPUs which are not scheduled and avoid the wait on the main CPU.</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; Test on a Haswell i7 desktop 4 cores (2HT), so 8 pCPUs, running ebizzy in</span>
<span class="quote">&gt;&gt; one linux guest.</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; ebizzy -M</span>
<span class="quote">&gt;&gt;               vanilla    optimized     boost</span>
<span class="quote">&gt;&gt;  8 vCPUs       10152       10083       -0.68%</span>
<span class="quote">&gt;&gt; 16 vCPUs        1224        4866       297.5%</span>
<span class="quote">&gt;&gt; 24 vCPUs        1109        3871       249%</span>
<span class="quote">&gt;&gt; 32 vCPUs        1025        3375       229.3%</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; Cc: Paolo Bonzini &lt;pbonzini@redhat.com&gt;</span>
<span class="quote">&gt;&gt; Cc: Radim Krčmář &lt;rkrcmar@redhat.com&gt;</span>
<span class="quote">&gt;&gt; Signed-off-by: Wanpeng Li &lt;wanpeng.li@hotmail.com&gt;</span>
<span class="quote">&gt;&gt; ---</span>
<span class="quote">&gt;&gt;  Documentation/virtual/kvm/cpuid.txt  |  4 ++++</span>
<span class="quote">&gt;&gt;  arch/x86/include/uapi/asm/kvm_para.h |  2 ++</span>
<span class="quote">&gt;&gt;  arch/x86/kernel/kvm.c                | 31 +++++++++++++++++++++++++++++++</span>
<span class="quote">&gt;&gt;  3 files changed, 37 insertions(+)</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; diff --git a/Documentation/virtual/kvm/cpuid.txt b/Documentation/virtual/kvm/cpuid.txt</span>
<span class="quote">&gt;&gt; index 117066a..9693fcc 100644</span>
<span class="quote">&gt;&gt; --- a/Documentation/virtual/kvm/cpuid.txt</span>
<span class="quote">&gt;&gt; +++ b/Documentation/virtual/kvm/cpuid.txt</span>
<span class="quote">&gt;&gt; @@ -60,6 +60,10 @@ KVM_FEATURE_PV_DEDICATED           ||     8 || guest checks this feature bit</span>
<span class="quote">&gt;&gt;                                     ||       || mizations such as usage of</span>
<span class="quote">&gt;&gt;                                     ||       || qspinlocks.</span>
<span class="quote">&gt;&gt;  ------------------------------------------------------------------------------</span>
<span class="quote">&gt;&gt; +KVM_FEATURE_PV_TLB_FLUSH           ||     9 || guest checks this feature bit</span>
<span class="quote">&gt;&gt; +                                   ||       || before enabling paravirtualized</span>
<span class="quote">&gt;&gt; +                                   ||       || tlb flush.</span>
<span class="quote">&gt;&gt; +------------------------------------------------------------------------------</span>
<span class="quote">&gt;&gt;  KVM_FEATURE_CLOCKSOURCE_STABLE_BIT ||    24 || host will warn if no guest-side</span>
<span class="quote">&gt;&gt;                                     ||       || per-cpu warps are expected in</span>
<span class="quote">&gt;&gt;                                     ||       || kvmclock.</span>
<span class="quote">&gt;&gt; diff --git a/arch/x86/include/uapi/asm/kvm_para.h b/arch/x86/include/uapi/asm/kvm_para.h</span>
<span class="quote">&gt;&gt; index 9ead1ed..a028479 100644</span>
<span class="quote">&gt;&gt; --- a/arch/x86/include/uapi/asm/kvm_para.h</span>
<span class="quote">&gt;&gt; +++ b/arch/x86/include/uapi/asm/kvm_para.h</span>
<span class="quote">&gt;&gt; @@ -25,6 +25,7 @@</span>
<span class="quote">&gt;&gt;  #define KVM_FEATURE_PV_EOI           6</span>
<span class="quote">&gt;&gt;  #define KVM_FEATURE_PV_UNHALT                7</span>
<span class="quote">&gt;&gt;  #define KVM_FEATURE_PV_DEDICATED     8</span>
<span class="quote">&gt;&gt; +#define KVM_FEATURE_PV_TLB_FLUSH     9</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt;  /* The last 8 bits are used to indicate how to interpret the flags field</span>
<span class="quote">&gt;&gt;   * in pvclock structure. If no bits are set, all flags are ignored.</span>
<span class="quote">&gt;&gt; @@ -53,6 +54,7 @@ struct kvm_steal_time {</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt;  #define KVM_VCPU_NOT_PREEMPTED      (0 &lt;&lt; 0)</span>
<span class="quote">&gt;&gt;  #define KVM_VCPU_PREEMPTED          (1 &lt;&lt; 0)</span>
<span class="quote">&gt;&gt; +#define KVM_VCPU_SHOULD_FLUSH       (1 &lt;&lt; 1)</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt;  #define KVM_CLOCK_PAIRING_WALLCLOCK 0</span>
<span class="quote">&gt;&gt;  struct kvm_clock_pairing {</span>
<span class="quote">&gt;&gt; diff --git a/arch/x86/kernel/kvm.c b/arch/x86/kernel/kvm.c</span>
<span class="quote">&gt;&gt; index 66ed3bc..50f4b6a 100644</span>
<span class="quote">&gt;&gt; --- a/arch/x86/kernel/kvm.c</span>
<span class="quote">&gt;&gt; +++ b/arch/x86/kernel/kvm.c</span>
<span class="quote">&gt;&gt; @@ -465,6 +465,33 @@ static void __init kvm_apf_trap_init(void)</span>
<span class="quote">&gt;&gt;       update_intr_gate(X86_TRAP_PF, async_page_fault);</span>
<span class="quote">&gt;&gt;  }</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; +static cpumask_t flushmask;</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; Hi Wanpeng,</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; are you going to send v3 with a percpu variable?</span>

Yeah, I just complete v3 according to Peterz&#39;s comments in another
guy&#39;s thread, I will send out them after completing the testing.

Regards,
Wanpeng Li
<span class="quote">
&gt;</span>
<span class="quote">&gt; Paolo</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;&gt; +static void kvm_flush_tlb_others(const struct cpumask *cpumask,</span>
<span class="quote">&gt;&gt; +                     const struct flush_tlb_info *info)</span>
<span class="quote">&gt;&gt; +{</span>
<span class="quote">&gt;&gt; +     u8 state;</span>
<span class="quote">&gt;&gt; +     int cpu;</span>
<span class="quote">&gt;&gt; +     struct kvm_steal_time *src;</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +     cpumask_copy(&amp;flushmask, cpumask);</span>
<span class="quote">&gt;&gt; +     /*</span>
<span class="quote">&gt;&gt; +      * We have to call flush only on online vCPUs. And</span>
<span class="quote">&gt;&gt; +      * queue flush_on_enter for pre-empted vCPUs</span>
<span class="quote">&gt;&gt; +      */</span>
<span class="quote">&gt;&gt; +     for_each_cpu(cpu, cpumask) {</span>
<span class="quote">&gt;&gt; +             src = &amp;per_cpu(steal_time, cpu);</span>
<span class="quote">&gt;&gt; +             state = src-&gt;preempted;</span>
<span class="quote">&gt;&gt; +             if ((state &amp; KVM_VCPU_PREEMPTED)) {</span>
<span class="quote">&gt;&gt; +                     if (cmpxchg(&amp;src-&gt;preempted, state, state |</span>
<span class="quote">&gt;&gt; +                             KVM_VCPU_SHOULD_FLUSH) == state)</span>
<span class="quote">&gt;&gt; +                             __cpumask_clear_cpu(cpu, &amp;flushmask);</span>
<span class="quote">&gt;&gt; +             }</span>
<span class="quote">&gt;&gt; +     }</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +     native_flush_tlb_others(&amp;flushmask, info);</span>
<span class="quote">&gt;&gt; +}</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt;  void __init kvm_guest_init(void)</span>
<span class="quote">&gt;&gt;  {</span>
<span class="quote">&gt;&gt;       int i;</span>
<span class="quote">&gt;&gt; @@ -484,6 +511,10 @@ void __init kvm_guest_init(void)</span>
<span class="quote">&gt;&gt;               pv_time_ops.steal_clock = kvm_steal_clock;</span>
<span class="quote">&gt;&gt;       }</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; +     if (kvm_para_has_feature(KVM_FEATURE_PV_TLB_FLUSH) &amp;&amp;</span>
<span class="quote">&gt;&gt; +             !kvm_para_has_feature(KVM_FEATURE_PV_DEDICATED))</span>
<span class="quote">&gt;&gt; +             pv_mmu_ops.flush_tlb_others = kvm_flush_tlb_others;</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt;       if (kvm_para_has_feature(KVM_FEATURE_PV_EOI))</span>
<span class="quote">&gt;&gt;               apic_set_eoi_write(kvm_guest_apic_eoi_write);</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;</span>
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=104371">Wanpeng Li</a> - Nov. 10, 2017, 8:35 a.m.</div>
<pre class="content">
2017-11-10 16:33 GMT+08:00 Wanpeng Li &lt;kernellwp@gmail.com&gt;:
<span class="quote">&gt; 2017-11-10 16:24 GMT+08:00 Paolo Bonzini &lt;pbonzini@redhat.com&gt;:</span>
<span class="quote">&gt;&gt; On 10/11/2017 08:04, Wanpeng Li wrote:</span>
<span class="quote">&gt;&gt;&gt; From: Wanpeng Li &lt;wanpeng.li@hotmail.com&gt;</span>
<span class="quote">&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt; Remote flushing api&#39;s does a busy wait which is fine in bare-metal</span>
<span class="quote">&gt;&gt;&gt; scenario. But with-in the guest, the vcpus might have been pre-empted</span>
<span class="quote">&gt;&gt;&gt; or blocked. In this scenario, the initator vcpu would end up</span>
<span class="quote">&gt;&gt;&gt; busy-waiting for a long amount of time.</span>
<span class="quote">&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt; This patch set implements para-virt flush tlbs making sure that it</span>
<span class="quote">&gt;&gt;&gt; does not wait for vcpus that are sleeping. And all the sleeping vcpus</span>
<span class="quote">&gt;&gt;&gt; flush the tlb on guest enter.</span>
<span class="quote">&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt; The best result is achieved when we&#39;re overcommiting the host by running</span>
<span class="quote">&gt;&gt;&gt; multiple vCPUs on each pCPU. In this case PV tlb flush avoids touching</span>
<span class="quote">&gt;&gt;&gt; vCPUs which are not scheduled and avoid the wait on the main CPU.</span>
<span class="quote">&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt; Test on a Haswell i7 desktop 4 cores (2HT), so 8 pCPUs, running ebizzy in</span>
<span class="quote">&gt;&gt;&gt; one linux guest.</span>
<span class="quote">&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt; ebizzy -M</span>
<span class="quote">&gt;&gt;&gt;               vanilla    optimized     boost</span>
<span class="quote">&gt;&gt;&gt;  8 vCPUs       10152       10083       -0.68%</span>
<span class="quote">&gt;&gt;&gt; 16 vCPUs        1224        4866       297.5%</span>
<span class="quote">&gt;&gt;&gt; 24 vCPUs        1109        3871       249%</span>
<span class="quote">&gt;&gt;&gt; 32 vCPUs        1025        3375       229.3%</span>
<span class="quote">&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt; Cc: Paolo Bonzini &lt;pbonzini@redhat.com&gt;</span>
<span class="quote">&gt;&gt;&gt; Cc: Radim Krčmář &lt;rkrcmar@redhat.com&gt;</span>
<span class="quote">&gt;&gt;&gt; Signed-off-by: Wanpeng Li &lt;wanpeng.li@hotmail.com&gt;</span>
<span class="quote">&gt;&gt;&gt; ---</span>
<span class="quote">&gt;&gt;&gt;  Documentation/virtual/kvm/cpuid.txt  |  4 ++++</span>
<span class="quote">&gt;&gt;&gt;  arch/x86/include/uapi/asm/kvm_para.h |  2 ++</span>
<span class="quote">&gt;&gt;&gt;  arch/x86/kernel/kvm.c                | 31 +++++++++++++++++++++++++++++++</span>
<span class="quote">&gt;&gt;&gt;  3 files changed, 37 insertions(+)</span>
<span class="quote">&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt; diff --git a/Documentation/virtual/kvm/cpuid.txt b/Documentation/virtual/kvm/cpuid.txt</span>
<span class="quote">&gt;&gt;&gt; index 117066a..9693fcc 100644</span>
<span class="quote">&gt;&gt;&gt; --- a/Documentation/virtual/kvm/cpuid.txt</span>
<span class="quote">&gt;&gt;&gt; +++ b/Documentation/virtual/kvm/cpuid.txt</span>
<span class="quote">&gt;&gt;&gt; @@ -60,6 +60,10 @@ KVM_FEATURE_PV_DEDICATED           ||     8 || guest checks this feature bit</span>
<span class="quote">&gt;&gt;&gt;                                     ||       || mizations such as usage of</span>
<span class="quote">&gt;&gt;&gt;                                     ||       || qspinlocks.</span>
<span class="quote">&gt;&gt;&gt;  ------------------------------------------------------------------------------</span>
<span class="quote">&gt;&gt;&gt; +KVM_FEATURE_PV_TLB_FLUSH           ||     9 || guest checks this feature bit</span>
<span class="quote">&gt;&gt;&gt; +                                   ||       || before enabling paravirtualized</span>
<span class="quote">&gt;&gt;&gt; +                                   ||       || tlb flush.</span>
<span class="quote">&gt;&gt;&gt; +------------------------------------------------------------------------------</span>
<span class="quote">&gt;&gt;&gt;  KVM_FEATURE_CLOCKSOURCE_STABLE_BIT ||    24 || host will warn if no guest-side</span>
<span class="quote">&gt;&gt;&gt;                                     ||       || per-cpu warps are expected in</span>
<span class="quote">&gt;&gt;&gt;                                     ||       || kvmclock.</span>
<span class="quote">&gt;&gt;&gt; diff --git a/arch/x86/include/uapi/asm/kvm_para.h b/arch/x86/include/uapi/asm/kvm_para.h</span>
<span class="quote">&gt;&gt;&gt; index 9ead1ed..a028479 100644</span>
<span class="quote">&gt;&gt;&gt; --- a/arch/x86/include/uapi/asm/kvm_para.h</span>
<span class="quote">&gt;&gt;&gt; +++ b/arch/x86/include/uapi/asm/kvm_para.h</span>
<span class="quote">&gt;&gt;&gt; @@ -25,6 +25,7 @@</span>
<span class="quote">&gt;&gt;&gt;  #define KVM_FEATURE_PV_EOI           6</span>
<span class="quote">&gt;&gt;&gt;  #define KVM_FEATURE_PV_UNHALT                7</span>
<span class="quote">&gt;&gt;&gt;  #define KVM_FEATURE_PV_DEDICATED     8</span>
<span class="quote">&gt;&gt;&gt; +#define KVM_FEATURE_PV_TLB_FLUSH     9</span>
<span class="quote">&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt;  /* The last 8 bits are used to indicate how to interpret the flags field</span>
<span class="quote">&gt;&gt;&gt;   * in pvclock structure. If no bits are set, all flags are ignored.</span>
<span class="quote">&gt;&gt;&gt; @@ -53,6 +54,7 @@ struct kvm_steal_time {</span>
<span class="quote">&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt;  #define KVM_VCPU_NOT_PREEMPTED      (0 &lt;&lt; 0)</span>
<span class="quote">&gt;&gt;&gt;  #define KVM_VCPU_PREEMPTED          (1 &lt;&lt; 0)</span>
<span class="quote">&gt;&gt;&gt; +#define KVM_VCPU_SHOULD_FLUSH       (1 &lt;&lt; 1)</span>
<span class="quote">&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt;  #define KVM_CLOCK_PAIRING_WALLCLOCK 0</span>
<span class="quote">&gt;&gt;&gt;  struct kvm_clock_pairing {</span>
<span class="quote">&gt;&gt;&gt; diff --git a/arch/x86/kernel/kvm.c b/arch/x86/kernel/kvm.c</span>
<span class="quote">&gt;&gt;&gt; index 66ed3bc..50f4b6a 100644</span>
<span class="quote">&gt;&gt;&gt; --- a/arch/x86/kernel/kvm.c</span>
<span class="quote">&gt;&gt;&gt; +++ b/arch/x86/kernel/kvm.c</span>
<span class="quote">&gt;&gt;&gt; @@ -465,6 +465,33 @@ static void __init kvm_apf_trap_init(void)</span>
<span class="quote">&gt;&gt;&gt;       update_intr_gate(X86_TRAP_PF, async_page_fault);</span>
<span class="quote">&gt;&gt;&gt;  }</span>
<span class="quote">&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt; +static cpumask_t flushmask;</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; Hi Wanpeng,</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; are you going to send v3 with a percpu variable?</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; Yeah, I just complete v3 according to Peterz&#39;s comments in another</span>
<span class="quote">&gt; guy&#39;s thread, I will send out them after completing the testing.</span>

This is how it looks it. https://pastebin.com/raw/L2vqu4cZ

Regards,
Wanpeng Li
<span class="quote">
&gt;</span>
<span class="quote">&gt; Regards,</span>
<span class="quote">&gt; Wanpeng Li</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; Paolo</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt; +static void kvm_flush_tlb_others(const struct cpumask *cpumask,</span>
<span class="quote">&gt;&gt;&gt; +                     const struct flush_tlb_info *info)</span>
<span class="quote">&gt;&gt;&gt; +{</span>
<span class="quote">&gt;&gt;&gt; +     u8 state;</span>
<span class="quote">&gt;&gt;&gt; +     int cpu;</span>
<span class="quote">&gt;&gt;&gt; +     struct kvm_steal_time *src;</span>
<span class="quote">&gt;&gt;&gt; +</span>
<span class="quote">&gt;&gt;&gt; +     cpumask_copy(&amp;flushmask, cpumask);</span>
<span class="quote">&gt;&gt;&gt; +     /*</span>
<span class="quote">&gt;&gt;&gt; +      * We have to call flush only on online vCPUs. And</span>
<span class="quote">&gt;&gt;&gt; +      * queue flush_on_enter for pre-empted vCPUs</span>
<span class="quote">&gt;&gt;&gt; +      */</span>
<span class="quote">&gt;&gt;&gt; +     for_each_cpu(cpu, cpumask) {</span>
<span class="quote">&gt;&gt;&gt; +             src = &amp;per_cpu(steal_time, cpu);</span>
<span class="quote">&gt;&gt;&gt; +             state = src-&gt;preempted;</span>
<span class="quote">&gt;&gt;&gt; +             if ((state &amp; KVM_VCPU_PREEMPTED)) {</span>
<span class="quote">&gt;&gt;&gt; +                     if (cmpxchg(&amp;src-&gt;preempted, state, state |</span>
<span class="quote">&gt;&gt;&gt; +                             KVM_VCPU_SHOULD_FLUSH) == state)</span>
<span class="quote">&gt;&gt;&gt; +                             __cpumask_clear_cpu(cpu, &amp;flushmask);</span>
<span class="quote">&gt;&gt;&gt; +             }</span>
<span class="quote">&gt;&gt;&gt; +     }</span>
<span class="quote">&gt;&gt;&gt; +</span>
<span class="quote">&gt;&gt;&gt; +     native_flush_tlb_others(&amp;flushmask, info);</span>
<span class="quote">&gt;&gt;&gt; +}</span>
<span class="quote">&gt;&gt;&gt; +</span>
<span class="quote">&gt;&gt;&gt;  void __init kvm_guest_init(void)</span>
<span class="quote">&gt;&gt;&gt;  {</span>
<span class="quote">&gt;&gt;&gt;       int i;</span>
<span class="quote">&gt;&gt;&gt; @@ -484,6 +511,10 @@ void __init kvm_guest_init(void)</span>
<span class="quote">&gt;&gt;&gt;               pv_time_ops.steal_clock = kvm_steal_clock;</span>
<span class="quote">&gt;&gt;&gt;       }</span>
<span class="quote">&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt; +     if (kvm_para_has_feature(KVM_FEATURE_PV_TLB_FLUSH) &amp;&amp;</span>
<span class="quote">&gt;&gt;&gt; +             !kvm_para_has_feature(KVM_FEATURE_PV_DEDICATED))</span>
<span class="quote">&gt;&gt;&gt; +             pv_mmu_ops.flush_tlb_others = kvm_flush_tlb_others;</span>
<span class="quote">&gt;&gt;&gt; +</span>
<span class="quote">&gt;&gt;&gt;       if (kvm_para_has_feature(KVM_FEATURE_PV_EOI))</span>
<span class="quote">&gt;&gt;&gt;               apic_set_eoi_write(kvm_guest_apic_eoi_write);</span>
<span class="quote">&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;&gt;</span>
<span class="quote">&gt;&gt;</span>
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=104371">Wanpeng Li</a> - Nov. 15, 2017, 8:43 a.m.</div>
<pre class="content">
2017-11-10 16:24 GMT+08:00 Paolo Bonzini &lt;pbonzini@redhat.com&gt;:
<span class="quote">&gt; On 10/11/2017 08:04, Wanpeng Li wrote:</span>
<span class="quote">&gt;&gt; From: Wanpeng Li &lt;wanpeng.li@hotmail.com&gt;</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; Remote flushing api&#39;s does a busy wait which is fine in bare-metal</span>
<span class="quote">&gt;&gt; scenario. But with-in the guest, the vcpus might have been pre-empted</span>
<span class="quote">&gt;&gt; or blocked. In this scenario, the initator vcpu would end up</span>
<span class="quote">&gt;&gt; busy-waiting for a long amount of time.</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; This patch set implements para-virt flush tlbs making sure that it</span>
<span class="quote">&gt;&gt; does not wait for vcpus that are sleeping. And all the sleeping vcpus</span>
<span class="quote">&gt;&gt; flush the tlb on guest enter.</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; The best result is achieved when we&#39;re overcommiting the host by running</span>
<span class="quote">&gt;&gt; multiple vCPUs on each pCPU. In this case PV tlb flush avoids touching</span>
<span class="quote">&gt;&gt; vCPUs which are not scheduled and avoid the wait on the main CPU.</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; Test on a Haswell i7 desktop 4 cores (2HT), so 8 pCPUs, running ebizzy in</span>
<span class="quote">&gt;&gt; one linux guest.</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; ebizzy -M</span>
<span class="quote">&gt;&gt;               vanilla    optimized     boost</span>
<span class="quote">&gt;&gt;  8 vCPUs       10152       10083       -0.68%</span>
<span class="quote">&gt;&gt; 16 vCPUs        1224        4866       297.5%</span>
<span class="quote">&gt;&gt; 24 vCPUs        1109        3871       249%</span>
<span class="quote">&gt;&gt; 32 vCPUs        1025        3375       229.3%</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; Cc: Paolo Bonzini &lt;pbonzini@redhat.com&gt;</span>
<span class="quote">&gt;&gt; Cc: Radim Krčmář &lt;rkrcmar@redhat.com&gt;</span>
<span class="quote">&gt;&gt; Signed-off-by: Wanpeng Li &lt;wanpeng.li@hotmail.com&gt;</span>
<span class="quote">&gt;&gt; ---</span>
<span class="quote">&gt;&gt;  Documentation/virtual/kvm/cpuid.txt  |  4 ++++</span>
<span class="quote">&gt;&gt;  arch/x86/include/uapi/asm/kvm_para.h |  2 ++</span>
<span class="quote">&gt;&gt;  arch/x86/kernel/kvm.c                | 31 +++++++++++++++++++++++++++++++</span>
<span class="quote">&gt;&gt;  3 files changed, 37 insertions(+)</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; diff --git a/Documentation/virtual/kvm/cpuid.txt b/Documentation/virtual/kvm/cpuid.txt</span>
<span class="quote">&gt;&gt; index 117066a..9693fcc 100644</span>
<span class="quote">&gt;&gt; --- a/Documentation/virtual/kvm/cpuid.txt</span>
<span class="quote">&gt;&gt; +++ b/Documentation/virtual/kvm/cpuid.txt</span>
<span class="quote">&gt;&gt; @@ -60,6 +60,10 @@ KVM_FEATURE_PV_DEDICATED           ||     8 || guest checks this feature bit</span>
<span class="quote">&gt;&gt;                                     ||       || mizations such as usage of</span>
<span class="quote">&gt;&gt;                                     ||       || qspinlocks.</span>
<span class="quote">&gt;&gt;  ------------------------------------------------------------------------------</span>
<span class="quote">&gt;&gt; +KVM_FEATURE_PV_TLB_FLUSH           ||     9 || guest checks this feature bit</span>
<span class="quote">&gt;&gt; +                                   ||       || before enabling paravirtualized</span>
<span class="quote">&gt;&gt; +                                   ||       || tlb flush.</span>
<span class="quote">&gt;&gt; +------------------------------------------------------------------------------</span>
<span class="quote">&gt;&gt;  KVM_FEATURE_CLOCKSOURCE_STABLE_BIT ||    24 || host will warn if no guest-side</span>
<span class="quote">&gt;&gt;                                     ||       || per-cpu warps are expected in</span>
<span class="quote">&gt;&gt;                                     ||       || kvmclock.</span>
<span class="quote">&gt;&gt; diff --git a/arch/x86/include/uapi/asm/kvm_para.h b/arch/x86/include/uapi/asm/kvm_para.h</span>
<span class="quote">&gt;&gt; index 9ead1ed..a028479 100644</span>
<span class="quote">&gt;&gt; --- a/arch/x86/include/uapi/asm/kvm_para.h</span>
<span class="quote">&gt;&gt; +++ b/arch/x86/include/uapi/asm/kvm_para.h</span>
<span class="quote">&gt;&gt; @@ -25,6 +25,7 @@</span>
<span class="quote">&gt;&gt;  #define KVM_FEATURE_PV_EOI           6</span>
<span class="quote">&gt;&gt;  #define KVM_FEATURE_PV_UNHALT                7</span>
<span class="quote">&gt;&gt;  #define KVM_FEATURE_PV_DEDICATED     8</span>
<span class="quote">&gt;&gt; +#define KVM_FEATURE_PV_TLB_FLUSH     9</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt;  /* The last 8 bits are used to indicate how to interpret the flags field</span>
<span class="quote">&gt;&gt;   * in pvclock structure. If no bits are set, all flags are ignored.</span>
<span class="quote">&gt;&gt; @@ -53,6 +54,7 @@ struct kvm_steal_time {</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt;  #define KVM_VCPU_NOT_PREEMPTED      (0 &lt;&lt; 0)</span>
<span class="quote">&gt;&gt;  #define KVM_VCPU_PREEMPTED          (1 &lt;&lt; 0)</span>
<span class="quote">&gt;&gt; +#define KVM_VCPU_SHOULD_FLUSH       (1 &lt;&lt; 1)</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt;  #define KVM_CLOCK_PAIRING_WALLCLOCK 0</span>
<span class="quote">&gt;&gt;  struct kvm_clock_pairing {</span>
<span class="quote">&gt;&gt; diff --git a/arch/x86/kernel/kvm.c b/arch/x86/kernel/kvm.c</span>
<span class="quote">&gt;&gt; index 66ed3bc..50f4b6a 100644</span>
<span class="quote">&gt;&gt; --- a/arch/x86/kernel/kvm.c</span>
<span class="quote">&gt;&gt; +++ b/arch/x86/kernel/kvm.c</span>
<span class="quote">&gt;&gt; @@ -465,6 +465,33 @@ static void __init kvm_apf_trap_init(void)</span>
<span class="quote">&gt;&gt;       update_intr_gate(X86_TRAP_PF, async_page_fault);</span>
<span class="quote">&gt;&gt;  }</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; +static cpumask_t flushmask;</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; Hi Wanpeng,</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; are you going to send v3 with a percpu variable?</span>

Hi Peterz,

I found big performance difference as I discuss with you several days ago.

ebizzy -M
                        vanilla    static/local cpumask     per-cpu cpumask
 8 vCPUs       10152            10083                          10117
16 vCPUs        1224              4866                          10008
24 vCPUs        1109              3871                            9928
32 vCPUs        1025              3375                            9811

In addition, I can observe ~50% perf top time is occupied by
smp_call_function_many(), ~30% perf top time is occupied by
call_function_interrupt() in the guest when running ebizzy for
static/local cpumask variable. However, I almost can&#39;t observe these
IPI stuffs after changing to per-cpu variable. Any opinions?

Regards,
Wanpeng Li
<span class="quote">
&gt;</span>
<span class="quote">&gt; Paolo</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;&gt; +static void kvm_flush_tlb_others(const struct cpumask *cpumask,</span>
<span class="quote">&gt;&gt; +                     const struct flush_tlb_info *info)</span>
<span class="quote">&gt;&gt; +{</span>
<span class="quote">&gt;&gt; +     u8 state;</span>
<span class="quote">&gt;&gt; +     int cpu;</span>
<span class="quote">&gt;&gt; +     struct kvm_steal_time *src;</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +     cpumask_copy(&amp;flushmask, cpumask);</span>
<span class="quote">&gt;&gt; +     /*</span>
<span class="quote">&gt;&gt; +      * We have to call flush only on online vCPUs. And</span>
<span class="quote">&gt;&gt; +      * queue flush_on_enter for pre-empted vCPUs</span>
<span class="quote">&gt;&gt; +      */</span>
<span class="quote">&gt;&gt; +     for_each_cpu(cpu, cpumask) {</span>
<span class="quote">&gt;&gt; +             src = &amp;per_cpu(steal_time, cpu);</span>
<span class="quote">&gt;&gt; +             state = src-&gt;preempted;</span>
<span class="quote">&gt;&gt; +             if ((state &amp; KVM_VCPU_PREEMPTED)) {</span>
<span class="quote">&gt;&gt; +                     if (cmpxchg(&amp;src-&gt;preempted, state, state |</span>
<span class="quote">&gt;&gt; +                             KVM_VCPU_SHOULD_FLUSH) == state)</span>
<span class="quote">&gt;&gt; +                             __cpumask_clear_cpu(cpu, &amp;flushmask);</span>
<span class="quote">&gt;&gt; +             }</span>
<span class="quote">&gt;&gt; +     }</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +     native_flush_tlb_others(&amp;flushmask, info);</span>
<span class="quote">&gt;&gt; +}</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt;  void __init kvm_guest_init(void)</span>
<span class="quote">&gt;&gt;  {</span>
<span class="quote">&gt;&gt;       int i;</span>
<span class="quote">&gt;&gt; @@ -484,6 +511,10 @@ void __init kvm_guest_init(void)</span>
<span class="quote">&gt;&gt;               pv_time_ops.steal_clock = kvm_steal_clock;</span>
<span class="quote">&gt;&gt;       }</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; +     if (kvm_para_has_feature(KVM_FEATURE_PV_TLB_FLUSH) &amp;&amp;</span>
<span class="quote">&gt;&gt; +             !kvm_para_has_feature(KVM_FEATURE_PV_DEDICATED))</span>
<span class="quote">&gt;&gt; +             pv_mmu_ops.flush_tlb_others = kvm_flush_tlb_others;</span>
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt;       if (kvm_para_has_feature(KVM_FEATURE_PV_EOI))</span>
<span class="quote">&gt;&gt;               apic_set_eoi_write(kvm_guest_apic_eoi_write);</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;</span>
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=137">Peter Zijlstra</a> - Nov. 15, 2017, 9:54 a.m.</div>
<pre class="content">
On Wed, Nov 15, 2017 at 04:43:32PM +0800, Wanpeng Li wrote:
<span class="quote">&gt; Hi Peterz,</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; I found big performance difference as I discuss with you several days ago.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; ebizzy -M</span>
<span class="quote">&gt;                         vanilla    static/local cpumask     per-cpu cpumask</span>
<span class="quote">&gt;  8 vCPUs       10152            10083                          10117</span>
<span class="quote">&gt; 16 vCPUs        1224              4866                          10008</span>
<span class="quote">&gt; 24 vCPUs        1109              3871                            9928</span>
<span class="quote">&gt; 32 vCPUs        1025              3375                            9811</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; In addition, I can observe ~50% perf top time is occupied by</span>
<span class="quote">&gt; smp_call_function_many(), ~30% perf top time is occupied by</span>
<span class="quote">&gt; call_function_interrupt() in the guest when running ebizzy for</span>
<span class="quote">&gt; static/local cpumask variable. However, I almost can&#39;t observe these</span>
<span class="quote">&gt; IPI stuffs after changing to per-cpu variable. Any opinions?</span>

That doesn&#39;t really make sense.. :/

So a single static variable is broken (multiple CPUs can call
flush_tlb_others() concurrently and overwrite each others masks). But I
don&#39;t see why a per-cpu variable would be much slower than an on-stack
variable.
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=104371">Wanpeng Li</a> - Nov. 15, 2017, 12:20 p.m.</div>
<pre class="content">
2017-11-15 17:54 GMT+08:00 Peter Zijlstra &lt;peterz@infradead.org&gt;:
<span class="quote">&gt; On Wed, Nov 15, 2017 at 04:43:32PM +0800, Wanpeng Li wrote:</span>
<span class="quote">&gt;&gt; Hi Peterz,</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; I found big performance difference as I discuss with you several days ago.</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; ebizzy -M</span>
<span class="quote">&gt;&gt;                         vanilla    static/local cpumask     per-cpu cpumask</span>
<span class="quote">&gt;&gt;  8 vCPUs       10152            10083                          10117</span>
<span class="quote">&gt;&gt; 16 vCPUs        1224              4866                          10008</span>
<span class="quote">&gt;&gt; 24 vCPUs        1109              3871                            9928</span>
<span class="quote">&gt;&gt; 32 vCPUs        1025              3375                            9811</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; In addition, I can observe ~50% perf top time is occupied by</span>
<span class="quote">&gt;&gt; smp_call_function_many(), ~30% perf top time is occupied by</span>
<span class="quote">&gt;&gt; call_function_interrupt() in the guest when running ebizzy for</span>
<span class="quote">&gt;&gt; static/local cpumask variable. However, I almost can&#39;t observe these</span>
<span class="quote">&gt;&gt; IPI stuffs after changing to per-cpu variable. Any opinions?</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; That doesn&#39;t really make sense.. :/</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; So a single static variable is broken (multiple CPUs can call</span>
<span class="quote">&gt; flush_tlb_others() concurrently and overwrite each others masks). But I</span>
<span class="quote">&gt; don&#39;t see why a per-cpu variable would be much slower than an on-stack</span>
<span class="quote">&gt; variable.</span>

The score of ebizzy, bigger is better, so per-cpu variable 2~3 times
better than on-stack. Actually I find what happens here. :)

+ for_each_possible_cpu(cpu) {
+     zalloc_cpumask_var_node(per_cpu_ptr(&amp;__pv_tlb_mask, cpu),
+         GFP_KERNEL, cpu_to_node(cpu));
+ }

This zalloc_cpumask_var_node() returns NULL and fails to alloc per-cpu
memory. There is a check in my kvm_flush_tlb_others():

+ if (unlikely(!flushmask))
+     return;

So the kvm_flush_tlb_others() skips all the tlbs shutdown, I think
that&#39;s the reason why the score of overcommit is as high as
non-overcommit, in addition, it also explains why I can&#39;t observe IPI
related functions by perf top.

Regards,
Wanpeng Li
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/Documentation/virtual/kvm/cpuid.txt b/Documentation/virtual/kvm/cpuid.txt</span>
<span class="p_header">index 117066a..9693fcc 100644</span>
<span class="p_header">--- a/Documentation/virtual/kvm/cpuid.txt</span>
<span class="p_header">+++ b/Documentation/virtual/kvm/cpuid.txt</span>
<span class="p_chunk">@@ -60,6 +60,10 @@</span> <span class="p_context"> KVM_FEATURE_PV_DEDICATED           ||     8 || guest checks this feature bit</span>
                                    ||       || mizations such as usage of
                                    ||       || qspinlocks.
 ------------------------------------------------------------------------------
<span class="p_add">+KVM_FEATURE_PV_TLB_FLUSH           ||     9 || guest checks this feature bit</span>
<span class="p_add">+                                   ||       || before enabling paravirtualized</span>
<span class="p_add">+                                   ||       || tlb flush.</span>
<span class="p_add">+------------------------------------------------------------------------------</span>
 KVM_FEATURE_CLOCKSOURCE_STABLE_BIT ||    24 || host will warn if no guest-side
                                    ||       || per-cpu warps are expected in
                                    ||       || kvmclock.
<span class="p_header">diff --git a/arch/x86/include/uapi/asm/kvm_para.h b/arch/x86/include/uapi/asm/kvm_para.h</span>
<span class="p_header">index 9ead1ed..a028479 100644</span>
<span class="p_header">--- a/arch/x86/include/uapi/asm/kvm_para.h</span>
<span class="p_header">+++ b/arch/x86/include/uapi/asm/kvm_para.h</span>
<span class="p_chunk">@@ -25,6 +25,7 @@</span> <span class="p_context"></span>
 #define KVM_FEATURE_PV_EOI		6
 #define KVM_FEATURE_PV_UNHALT		7
 #define KVM_FEATURE_PV_DEDICATED	8
<span class="p_add">+#define KVM_FEATURE_PV_TLB_FLUSH	9</span>
 
 /* The last 8 bits are used to indicate how to interpret the flags field
  * in pvclock structure. If no bits are set, all flags are ignored.
<span class="p_chunk">@@ -53,6 +54,7 @@</span> <span class="p_context"> struct kvm_steal_time {</span>
 
 #define KVM_VCPU_NOT_PREEMPTED      (0 &lt;&lt; 0)
 #define KVM_VCPU_PREEMPTED          (1 &lt;&lt; 0)
<span class="p_add">+#define KVM_VCPU_SHOULD_FLUSH       (1 &lt;&lt; 1)</span>
 
 #define KVM_CLOCK_PAIRING_WALLCLOCK 0
 struct kvm_clock_pairing {
<span class="p_header">diff --git a/arch/x86/kernel/kvm.c b/arch/x86/kernel/kvm.c</span>
<span class="p_header">index 66ed3bc..50f4b6a 100644</span>
<span class="p_header">--- a/arch/x86/kernel/kvm.c</span>
<span class="p_header">+++ b/arch/x86/kernel/kvm.c</span>
<span class="p_chunk">@@ -465,6 +465,33 @@</span> <span class="p_context"> static void __init kvm_apf_trap_init(void)</span>
 	update_intr_gate(X86_TRAP_PF, async_page_fault);
 }
 
<span class="p_add">+static cpumask_t flushmask;</span>
<span class="p_add">+</span>
<span class="p_add">+static void kvm_flush_tlb_others(const struct cpumask *cpumask,</span>
<span class="p_add">+			const struct flush_tlb_info *info)</span>
<span class="p_add">+{</span>
<span class="p_add">+	u8 state;</span>
<span class="p_add">+	int cpu;</span>
<span class="p_add">+	struct kvm_steal_time *src;</span>
<span class="p_add">+</span>
<span class="p_add">+	cpumask_copy(&amp;flushmask, cpumask);</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * We have to call flush only on online vCPUs. And</span>
<span class="p_add">+	 * queue flush_on_enter for pre-empted vCPUs</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	for_each_cpu(cpu, cpumask) {</span>
<span class="p_add">+		src = &amp;per_cpu(steal_time, cpu);</span>
<span class="p_add">+		state = src-&gt;preempted;</span>
<span class="p_add">+		if ((state &amp; KVM_VCPU_PREEMPTED)) {</span>
<span class="p_add">+			if (cmpxchg(&amp;src-&gt;preempted, state, state |</span>
<span class="p_add">+				KVM_VCPU_SHOULD_FLUSH) == state)</span>
<span class="p_add">+				__cpumask_clear_cpu(cpu, &amp;flushmask);</span>
<span class="p_add">+		}</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	native_flush_tlb_others(&amp;flushmask, info);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 void __init kvm_guest_init(void)
 {
 	int i;
<span class="p_chunk">@@ -484,6 +511,10 @@</span> <span class="p_context"> void __init kvm_guest_init(void)</span>
 		pv_time_ops.steal_clock = kvm_steal_clock;
 	}
 
<span class="p_add">+	if (kvm_para_has_feature(KVM_FEATURE_PV_TLB_FLUSH) &amp;&amp;</span>
<span class="p_add">+		!kvm_para_has_feature(KVM_FEATURE_PV_DEDICATED))</span>
<span class="p_add">+		pv_mmu_ops.flush_tlb_others = kvm_flush_tlb_others;</span>
<span class="p_add">+</span>
 	if (kvm_para_has_feature(KVM_FEATURE_PV_EOI))
 		apic_set_eoi_write(kvm_guest_apic_eoi_write);
 

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



