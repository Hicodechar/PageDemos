
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>[v2,2/2] mm/rmap: batched invalidations should use existing api - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    [v2,2/2] mm/rmap: batched invalidations should use existing api</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=159401">Nadav Amit</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>March 26, 2016, 8:25 a.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;1458980705-121507-3-git-send-email-namit@vmware.com&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/8679881/mbox/"
   >mbox</a>
|
   <a href="/patch/8679881/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/8679881/">/patch/8679881/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
X-Original-To: patchwork-LKML@patchwork.kernel.org
Delivered-To: patchwork-parsemail@patchwork2.web.kernel.org
Received: from mail.kernel.org (mail.kernel.org [198.145.29.136])
	by patchwork2.web.kernel.org (Postfix) with ESMTP id 2932EC0553
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Mon, 28 Mar 2016 16:43:10 +0000 (UTC)
Received: from mail.kernel.org (localhost [127.0.0.1])
	by mail.kernel.org (Postfix) with ESMTP id DF1F120211
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Mon, 28 Mar 2016 16:43:05 +0000 (UTC)
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.kernel.org (Postfix) with ESMTP id 26F7B20225
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Mon, 28 Mar 2016 16:43:05 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1755217AbcC1QnD (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Mon, 28 Mar 2016 12:43:03 -0400
Received: from smtp-outbound-2.vmware.com ([208.91.2.13]:36953 &quot;EHLO
	smtp-outbound-2.vmware.com&quot; rhost-flags-OK-OK-OK-OK)
	by vger.kernel.org with ESMTP id S1755146AbcC1Qm4 (ORCPT
	&lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Mon, 28 Mar 2016 12:42:56 -0400
Received: from sc9-mailhost3.vmware.com (sc9-mailhost3.vmware.com
	[10.113.161.73])
	by smtp-outbound-2.vmware.com (Postfix) with ESMTP id AE938284A0;
	Mon, 28 Mar 2016 09:42:54 -0700 (PDT)
Received: from ubuntu.localdomain (htb-2n-eng-dhcp436.eng.vmware.com
	[10.33.83.180])
	by sc9-mailhost3.vmware.com (Postfix) with ESMTP id 64C79409C9;
	Mon, 28 Mar 2016 09:42:55 -0700 (PDT)
From: Nadav Amit &lt;namit@vmware.com&gt;
To: linux-mm@kvack.org
Cc: tglx@linutronix.de, mingo@redhat.com, hpa@zytor.com,
	x86@kernel.org, mgorman@suse.de, sasha.levin@oracle.com,
	akpm@linux-foundation.org, namit@vmware.com, riel@redhat.com,
	dave.hansen@linux.intel.com, luto@kernel.org,
	kirill.shutemov@linux.intel.com, mhocko@suse.com,
	jmarchan@redhat.com, hughd@google.com, vdavydov@virtuozzo.com,
	minchan@kernel.org, linux-kernel@vger.kernel.org
Subject: [PATCH v2 2/2] mm/rmap: batched invalidations should use existing
	api
Date: Sat, 26 Mar 2016 01:25:05 -0700
Message-Id: &lt;1458980705-121507-3-git-send-email-namit@vmware.com&gt;
X-Mailer: git-send-email 2.5.0
In-Reply-To: &lt;1458980705-121507-1-git-send-email-namit@vmware.com&gt;
References: &lt;1458980705-121507-1-git-send-email-namit@vmware.com&gt;
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Spam-Status: No, score=-7.9 required=5.0 tests=BAYES_00, RCVD_IN_DNSWL_HI, 
	RP_MATCHES_RCVD,
	UNPARSEABLE_RELAY autolearn=unavailable version=3.3.1
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on mail.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=159401">Nadav Amit</a> - March 26, 2016, 8:25 a.m.</div>
<pre class="content">
The recently introduced batched invalidations mechanism uses its own
mechanism for shootdown. However, it does wrong accounting of interrupts
(e.g., inc_irq_stat is called for local invalidations), trace-points
(e.g., TLB_REMOTE_SHOOTDOWN for local invalidations) and may break some
platforms as it bypasses the invalidation mechanisms of Xen and SGI UV.

This patch reuses the existing TLB flushing mechnaisms instead. We use
NULL as mm to indicate a global invalidation is required.
<span class="signed-off-by">
Signed-off-by: Nadav Amit &lt;namit@vmware.com&gt;</span>
---
 arch/x86/include/asm/tlbflush.h |  6 ------
 arch/x86/mm/tlb.c               |  2 +-
 mm/rmap.c                       | 28 +++++++---------------------
 3 files changed, 8 insertions(+), 28 deletions(-)
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/arch/x86/include/asm/tlbflush.h b/arch/x86/include/asm/tlbflush.h</span>
<span class="p_header">index 6df2029..cd79194 100644</span>
<span class="p_header">--- a/arch/x86/include/asm/tlbflush.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/tlbflush.h</span>
<span class="p_chunk">@@ -261,12 +261,6 @@</span> <span class="p_context"> static inline void reset_lazy_tlbstate(void)</span>
 
 #endif	/* SMP */
 
<span class="p_del">-/* Not inlined due to inc_irq_stat not being defined yet */</span>
<span class="p_del">-#define flush_tlb_local() {		\</span>
<span class="p_del">-	inc_irq_stat(irq_tlb_count);	\</span>
<span class="p_del">-	local_flush_tlb();		\</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
 #ifndef CONFIG_PARAVIRT
 #define flush_tlb_others(mask, mm, start, end)	\
 	native_flush_tlb_others(mask, mm, start, end)
<span class="p_header">diff --git a/arch/x86/mm/tlb.c b/arch/x86/mm/tlb.c</span>
<span class="p_header">index 5fb6ada..fe9b9f7 100644</span>
<span class="p_header">--- a/arch/x86/mm/tlb.c</span>
<span class="p_header">+++ b/arch/x86/mm/tlb.c</span>
<span class="p_chunk">@@ -104,7 +104,7 @@</span> <span class="p_context"> static void flush_tlb_func(void *info)</span>
 
 	inc_irq_stat(irq_tlb_count);
 
<span class="p_del">-	if (f-&gt;flush_mm != this_cpu_read(cpu_tlbstate.active_mm))</span>
<span class="p_add">+	if (f-&gt;flush_mm &amp;&amp; f-&gt;flush_mm != this_cpu_read(cpu_tlbstate.active_mm))</span>
 		return;
 
 	count_vm_tlb_event(NR_TLB_REMOTE_FLUSH_RECEIVED);
<span class="p_header">diff --git a/mm/rmap.c b/mm/rmap.c</span>
<span class="p_header">index 79f3bf0..37fb08f 100644</span>
<span class="p_header">--- a/mm/rmap.c</span>
<span class="p_header">+++ b/mm/rmap.c</span>
<span class="p_chunk">@@ -569,19 +569,6 @@</span> <span class="p_context"> void page_unlock_anon_vma_read(struct anon_vma *anon_vma)</span>
 }
 
 #ifdef CONFIG_ARCH_WANT_BATCHED_UNMAP_TLB_FLUSH
<span class="p_del">-static void percpu_flush_tlb_batch_pages(void *data)</span>
<span class="p_del">-{</span>
<span class="p_del">-	/*</span>
<span class="p_del">-	 * All TLB entries are flushed on the assumption that it is</span>
<span class="p_del">-	 * cheaper to flush all TLBs and let them be refilled than</span>
<span class="p_del">-	 * flushing individual PFNs. Note that we do not track mm&#39;s</span>
<span class="p_del">-	 * to flush as that might simply be multiple full TLB flushes</span>
<span class="p_del">-	 * for no gain.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	count_vm_tlb_event(NR_TLB_REMOTE_FLUSH_RECEIVED);</span>
<span class="p_del">-	flush_tlb_local();</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
 /*
  * Flush TLB entries for recently unmapped pages from remote CPUs. It is
  * important if a PTE was dirty when it was unmapped that it&#39;s flushed
<span class="p_chunk">@@ -598,15 +585,14 @@</span> <span class="p_context"> void try_to_unmap_flush(void)</span>
 
 	cpu = get_cpu();
 
<span class="p_del">-	trace_tlb_flush(TLB_REMOTE_SHOOTDOWN, -1UL);</span>
<span class="p_del">-</span>
<span class="p_del">-	if (cpumask_test_cpu(cpu, &amp;tlb_ubc-&gt;cpumask))</span>
<span class="p_del">-		percpu_flush_tlb_batch_pages(&amp;tlb_ubc-&gt;cpumask);</span>
<span class="p_del">-</span>
<span class="p_del">-	if (cpumask_any_but(&amp;tlb_ubc-&gt;cpumask, cpu) &lt; nr_cpu_ids) {</span>
<span class="p_del">-		smp_call_function_many(&amp;tlb_ubc-&gt;cpumask,</span>
<span class="p_del">-			percpu_flush_tlb_batch_pages, (void *)tlb_ubc, true);</span>
<span class="p_add">+	if (cpumask_test_cpu(cpu, &amp;tlb_ubc-&gt;cpumask)) {</span>
<span class="p_add">+		count_vm_tlb_event(NR_TLB_LOCAL_FLUSH_ALL);</span>
<span class="p_add">+		local_flush_tlb();</span>
<span class="p_add">+		trace_tlb_flush(TLB_LOCAL_SHOOTDOWN, TLB_FLUSH_ALL);</span>
 	}
<span class="p_add">+</span>
<span class="p_add">+	if (cpumask_any_but(&amp;tlb_ubc-&gt;cpumask, cpu) &lt; nr_cpu_ids)</span>
<span class="p_add">+		flush_tlb_others(&amp;tlb_ubc-&gt;cpumask, NULL, 0, TLB_FLUSH_ALL);</span>
 	cpumask_clear(&amp;tlb_ubc-&gt;cpumask);
 	tlb_ubc-&gt;flush_required = false;
 	tlb_ubc-&gt;writable = false;

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



