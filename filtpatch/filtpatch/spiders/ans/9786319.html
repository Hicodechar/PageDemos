
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>Linux 4.11.5 - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    Linux 4.11.5</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=37061">gregkh@linuxfoundation.org</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>June 14, 2017, 1:47 p.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;20170614134722.GB22853@kroah.com&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/9786319/mbox/"
   >mbox</a>
|
   <a href="/patch/9786319/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/9786319/">/patch/9786319/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
	[172.30.200.125])
	by pdx-korg-patchwork.web.codeaurora.org (Postfix) with ESMTP id
	DB24460384 for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Wed, 14 Jun 2017 13:48:04 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id AE93726224
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Wed, 14 Jun 2017 13:48:04 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id A1550285D8; Wed, 14 Jun 2017 13:48:04 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-5.2 required=2.0 tests=BAYES_00, RCVD_IN_DNSWL_HI, 
	URIBL_BLACK autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id A40F426224
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Wed, 14 Jun 2017 13:47:56 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1752202AbdFNNrs (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Wed, 14 Jun 2017 09:47:48 -0400
Received: from mail.linuxfoundation.org ([140.211.169.12]:56202 &quot;EHLO
	mail.linuxfoundation.org&quot; rhost-flags-OK-OK-OK-OK) by vger.kernel.org
	with ESMTP id S1751922AbdFNNrb (ORCPT
	&lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Wed, 14 Jun 2017 09:47:31 -0400
Received: from localhost (LFbn-1-12060-104.w90-92.abo.wanadoo.fr
	[90.92.122.104])
	by mail.linuxfoundation.org (Postfix) with ESMTPSA id 827E1B5A;
	Wed, 14 Jun 2017 13:47:29 +0000 (UTC)
Date: Wed, 14 Jun 2017 15:47:22 +0200
From: Greg KH &lt;gregkh@linuxfoundation.org&gt;
To: linux-kernel@vger.kernel.org, Andrew Morton &lt;akpm@linux-foundation.org&gt;,
	torvalds@linux-foundation.org, stable@vger.kernel.org
Cc: lwn@lwn.net, Jiri Slaby &lt;jslaby@suse.cz&gt;
Subject: Re: Linux 4.11.5
Message-ID: &lt;20170614134722.GB22853@kroah.com&gt;
References: &lt;20170614134717.GA22853@kroah.com&gt;
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Disposition: inline
In-Reply-To: &lt;20170614134717.GA22853@kroah.com&gt;
User-Agent: Mutt/1.8.3 (2017-05-23)
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=37061">gregkh@linuxfoundation.org</a> - June 14, 2017, 1:47 p.m.</div>
<pre class="content">

</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/Makefile b/Makefile</span>
<span class="p_header">index 741814dca844..5b3a81d3262e 100644</span>
<span class="p_header">--- a/Makefile</span>
<span class="p_header">+++ b/Makefile</span>
<span class="p_chunk">@@ -1,6 +1,6 @@</span> <span class="p_context"></span>
 VERSION = 4
 PATCHLEVEL = 11
<span class="p_del">-SUBLEVEL = 4</span>
<span class="p_add">+SUBLEVEL = 5</span>
 EXTRAVERSION =
 NAME = Fearless Coyote
 
<span class="p_header">diff --git a/arch/arm/boot/dts/keystone-k2l-netcp.dtsi b/arch/arm/boot/dts/keystone-k2l-netcp.dtsi</span>
<span class="p_header">index b6f26824e83a..66f615a74118 100644</span>
<span class="p_header">--- a/arch/arm/boot/dts/keystone-k2l-netcp.dtsi</span>
<span class="p_header">+++ b/arch/arm/boot/dts/keystone-k2l-netcp.dtsi</span>
<span class="p_chunk">@@ -137,8 +137,8 @@</span> <span class="p_context"> netcp: netcp@26000000 {</span>
 	/* NetCP address range */
 	ranges = &lt;0 0x26000000 0x1000000&gt;;
 
<span class="p_del">-	clocks = &lt;&amp;clkpa&gt;, &lt;&amp;clkcpgmac&gt;, &lt;&amp;chipclk12&gt;, &lt;&amp;clkosr&gt;;</span>
<span class="p_del">-	clock-names = &quot;pa_clk&quot;, &quot;ethss_clk&quot;, &quot;cpts&quot;, &quot;osr_clk&quot;;</span>
<span class="p_add">+	clocks = &lt;&amp;clkpa&gt;, &lt;&amp;clkcpgmac&gt;, &lt;&amp;chipclk12&gt;;</span>
<span class="p_add">+	clock-names = &quot;pa_clk&quot;, &quot;ethss_clk&quot;, &quot;cpts&quot;;</span>
 	dma-coherent;
 
 	ti,navigator-dmas = &lt;&amp;dma_gbe 0&gt;,
<span class="p_header">diff --git a/arch/arm/boot/dts/keystone-k2l.dtsi b/arch/arm/boot/dts/keystone-k2l.dtsi</span>
<span class="p_header">index b58e7ebc0919..148650406cf7 100644</span>
<span class="p_header">--- a/arch/arm/boot/dts/keystone-k2l.dtsi</span>
<span class="p_header">+++ b/arch/arm/boot/dts/keystone-k2l.dtsi</span>
<span class="p_chunk">@@ -232,6 +232,14 @@</span> <span class="p_context"></span>
 			};
 		};
 
<span class="p_add">+		osr: sram@70000000 {</span>
<span class="p_add">+			compatible = &quot;mmio-sram&quot;;</span>
<span class="p_add">+			reg = &lt;0x70000000 0x10000&gt;;</span>
<span class="p_add">+			#address-cells = &lt;1&gt;;</span>
<span class="p_add">+			#size-cells = &lt;1&gt;;</span>
<span class="p_add">+			clocks = &lt;&amp;clkosr&gt;;</span>
<span class="p_add">+		};</span>
<span class="p_add">+</span>
 		dspgpio0: keystone_dsp_gpio@02620240 {
 			compatible = &quot;ti,keystone-dsp-gpio&quot;;
 			gpio-controller;
<span class="p_header">diff --git a/arch/arm/kvm/init.S b/arch/arm/kvm/init.S</span>
<span class="p_header">index bf89c919efc1..bd0ee7fc304c 100644</span>
<span class="p_header">--- a/arch/arm/kvm/init.S</span>
<span class="p_header">+++ b/arch/arm/kvm/init.S</span>
<span class="p_chunk">@@ -95,7 +95,6 @@</span> <span class="p_context"> __do_hyp_init:</span>
 	@  - Write permission implies XN: disabled
 	@  - Instruction cache: enabled
 	@  - Data/Unified cache: enabled
<span class="p_del">-	@  - Memory alignment checks: enabled</span>
 	@  - MMU: enabled (this code must be run from an identity mapping)
 	mrc	p15, 4, r0, c1, c0, 0	@ HSCR
 	ldr	r2, =HSCTLR_MASK
<span class="p_chunk">@@ -103,8 +102,8 @@</span> <span class="p_context"> __do_hyp_init:</span>
 	mrc	p15, 0, r1, c1, c0, 0	@ SCTLR
 	ldr	r2, =(HSCTLR_EE | HSCTLR_FI | HSCTLR_I | HSCTLR_C)
 	and	r1, r1, r2
<span class="p_del">- ARM(	ldr	r2, =(HSCTLR_M | HSCTLR_A)			)</span>
<span class="p_del">- THUMB(	ldr	r2, =(HSCTLR_M | HSCTLR_A | HSCTLR_TE)		)</span>
<span class="p_add">+ ARM(	ldr	r2, =(HSCTLR_M)					)</span>
<span class="p_add">+ THUMB(	ldr	r2, =(HSCTLR_M | HSCTLR_TE)			)</span>
 	orr	r1, r1, r2
 	orr	r0, r0, r1
 	mcr	p15, 4, r0, c1, c0, 0	@ HSCR
<span class="p_header">diff --git a/arch/arm/kvm/mmu.c b/arch/arm/kvm/mmu.c</span>
<span class="p_header">index 3837b096e1a6..b97bc12812ab 100644</span>
<span class="p_header">--- a/arch/arm/kvm/mmu.c</span>
<span class="p_header">+++ b/arch/arm/kvm/mmu.c</span>
<span class="p_chunk">@@ -879,6 +879,9 @@</span> <span class="p_context"> static pmd_t *stage2_get_pmd(struct kvm *kvm, struct kvm_mmu_memory_cache *cache</span>
 	pmd_t *pmd;
 
 	pud = stage2_get_pud(kvm, cache, addr);
<span class="p_add">+	if (!pud)</span>
<span class="p_add">+		return NULL;</span>
<span class="p_add">+</span>
 	if (stage2_pud_none(*pud)) {
 		if (!cache)
 			return NULL;
<span class="p_header">diff --git a/arch/arm64/include/asm/sysreg.h b/arch/arm64/include/asm/sysreg.h</span>
<span class="p_header">index ac24b6e798b1..2d3e155b185f 100644</span>
<span class="p_header">--- a/arch/arm64/include/asm/sysreg.h</span>
<span class="p_header">+++ b/arch/arm64/include/asm/sysreg.h</span>
<span class="p_chunk">@@ -138,6 +138,10 @@</span> <span class="p_context"></span>
 #define SCTLR_ELx_A	(1 &lt;&lt; 1)
 #define SCTLR_ELx_M	1
 
<span class="p_add">+#define SCTLR_EL2_RES1	((1 &lt;&lt; 4)  | (1 &lt;&lt; 5)  | (1 &lt;&lt; 11) | (1 &lt;&lt; 16) | \</span>
<span class="p_add">+			 (1 &lt;&lt; 16) | (1 &lt;&lt; 18) | (1 &lt;&lt; 22) | (1 &lt;&lt; 23) | \</span>
<span class="p_add">+			 (1 &lt;&lt; 28) | (1 &lt;&lt; 29))</span>
<span class="p_add">+</span>
 #define SCTLR_ELx_FLAGS	(SCTLR_ELx_M | SCTLR_ELx_A | SCTLR_ELx_C | \
 			 SCTLR_ELx_SA | SCTLR_ELx_I)
 
<span class="p_header">diff --git a/arch/arm64/kvm/hyp-init.S b/arch/arm64/kvm/hyp-init.S</span>
<span class="p_header">index 6b29d3d9e1f2..4bbff904169d 100644</span>
<span class="p_header">--- a/arch/arm64/kvm/hyp-init.S</span>
<span class="p_header">+++ b/arch/arm64/kvm/hyp-init.S</span>
<span class="p_chunk">@@ -102,10 +102,13 @@</span> <span class="p_context"> __do_hyp_init:</span>
 	tlbi	alle2
 	dsb	sy
 
<span class="p_del">-	mrs	x4, sctlr_el2</span>
<span class="p_del">-	and	x4, x4, #SCTLR_ELx_EE	// preserve endianness of EL2</span>
<span class="p_del">-	ldr	x5, =SCTLR_ELx_FLAGS</span>
<span class="p_del">-	orr	x4, x4, x5</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Preserve all the RES1 bits while setting the default flags,</span>
<span class="p_add">+	 * as well as the EE bit on BE. Drop the A flag since the compiler</span>
<span class="p_add">+	 * is allowed to generate unaligned accesses.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	ldr	x4, =(SCTLR_EL2_RES1 | (SCTLR_ELx_FLAGS &amp; ~SCTLR_ELx_A))</span>
<span class="p_add">+CPU_BE(	orr	x4, x4, #SCTLR_ELx_EE)</span>
 	msr	sctlr_el2, x4
 	isb
 
<span class="p_header">diff --git a/arch/mips/kernel/process.c b/arch/mips/kernel/process.c</span>
<span class="p_header">index b68e10fc453d..0f88015f3bfa 100644</span>
<span class="p_header">--- a/arch/mips/kernel/process.c</span>
<span class="p_header">+++ b/arch/mips/kernel/process.c</span>
<span class="p_chunk">@@ -120,7 +120,6 @@</span> <span class="p_context"> int copy_thread(unsigned long clone_flags, unsigned long usp,</span>
 	struct thread_info *ti = task_thread_info(p);
 	struct pt_regs *childregs, *regs = current_pt_regs();
 	unsigned long childksp;
<span class="p_del">-	p-&gt;set_child_tid = p-&gt;clear_child_tid = NULL;</span>
 
 	childksp = (unsigned long)task_stack_page(p) + THREAD_SIZE - 32;
 
<span class="p_header">diff --git a/arch/openrisc/kernel/process.c b/arch/openrisc/kernel/process.c</span>
<span class="p_header">index f8da545854f9..106859ae27ff 100644</span>
<span class="p_header">--- a/arch/openrisc/kernel/process.c</span>
<span class="p_header">+++ b/arch/openrisc/kernel/process.c</span>
<span class="p_chunk">@@ -167,8 +167,6 @@</span> <span class="p_context"> copy_thread(unsigned long clone_flags, unsigned long usp,</span>
 
 	top_of_kernel_stack = sp;
 
<span class="p_del">-	p-&gt;set_child_tid = p-&gt;clear_child_tid = NULL;</span>
<span class="p_del">-</span>
 	/* Locate userspace context on stack... */
 	sp -= STACK_FRAME_OVERHEAD;	/* redzone */
 	sp -= sizeof(struct pt_regs);
<span class="p_header">diff --git a/arch/powerpc/include/asm/topology.h b/arch/powerpc/include/asm/topology.h</span>
<span class="p_header">index 8b3b46b7b0f2..329771559cbb 100644</span>
<span class="p_header">--- a/arch/powerpc/include/asm/topology.h</span>
<span class="p_header">+++ b/arch/powerpc/include/asm/topology.h</span>
<span class="p_chunk">@@ -44,8 +44,22 @@</span> <span class="p_context"> extern void __init dump_numa_cpu_topology(void);</span>
 extern int sysfs_add_device_to_node(struct device *dev, int nid);
 extern void sysfs_remove_device_from_node(struct device *dev, int nid);
 
<span class="p_add">+static inline int early_cpu_to_node(int cpu)</span>
<span class="p_add">+{</span>
<span class="p_add">+	int nid;</span>
<span class="p_add">+</span>
<span class="p_add">+	nid = numa_cpu_lookup_table[cpu];</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Fall back to node 0 if nid is unset (it should be, except bugs).</span>
<span class="p_add">+	 * This allows callers to safely do NODE_DATA(early_cpu_to_node(cpu)).</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	return (nid &lt; 0) ? 0 : nid;</span>
<span class="p_add">+}</span>
 #else
 
<span class="p_add">+static inline int early_cpu_to_node(int cpu) { return 0; }</span>
<span class="p_add">+</span>
 static inline void dump_numa_cpu_topology(void) {}
 
 static inline int sysfs_add_device_to_node(struct device *dev, int nid)
<span class="p_header">diff --git a/arch/powerpc/kernel/process.c b/arch/powerpc/kernel/process.c</span>
<span class="p_header">index baae104b16c7..2ad725ef4368 100644</span>
<span class="p_header">--- a/arch/powerpc/kernel/process.c</span>
<span class="p_header">+++ b/arch/powerpc/kernel/process.c</span>
<span class="p_chunk">@@ -1666,6 +1666,7 @@</span> <span class="p_context"> void start_thread(struct pt_regs *regs, unsigned long start, unsigned long sp)</span>
 #ifdef CONFIG_VSX
 	current-&gt;thread.used_vsr = 0;
 #endif
<span class="p_add">+	current-&gt;thread.load_fp = 0;</span>
 	memset(&amp;current-&gt;thread.fp_state, 0, sizeof(current-&gt;thread.fp_state));
 	current-&gt;thread.fp_save_area = NULL;
 #ifdef CONFIG_ALTIVEC
<span class="p_chunk">@@ -1674,6 +1675,7 @@</span> <span class="p_context"> void start_thread(struct pt_regs *regs, unsigned long start, unsigned long sp)</span>
 	current-&gt;thread.vr_save_area = NULL;
 	current-&gt;thread.vrsave = 0;
 	current-&gt;thread.used_vr = 0;
<span class="p_add">+	current-&gt;thread.load_vec = 0;</span>
 #endif /* CONFIG_ALTIVEC */
 #ifdef CONFIG_SPE
 	memset(current-&gt;thread.evr, 0, sizeof(current-&gt;thread.evr));
<span class="p_chunk">@@ -1685,6 +1687,7 @@</span> <span class="p_context"> void start_thread(struct pt_regs *regs, unsigned long start, unsigned long sp)</span>
 	current-&gt;thread.tm_tfhar = 0;
 	current-&gt;thread.tm_texasr = 0;
 	current-&gt;thread.tm_tfiar = 0;
<span class="p_add">+	current-&gt;thread.load_tm = 0;</span>
 #endif /* CONFIG_PPC_TRANSACTIONAL_MEM */
 }
 EXPORT_SYMBOL(start_thread);
<span class="p_header">diff --git a/arch/powerpc/kernel/setup_64.c b/arch/powerpc/kernel/setup_64.c</span>
<span class="p_header">index f997154dfc41..7183c43d4e81 100644</span>
<span class="p_header">--- a/arch/powerpc/kernel/setup_64.c</span>
<span class="p_header">+++ b/arch/powerpc/kernel/setup_64.c</span>
<span class="p_chunk">@@ -650,7 +650,7 @@</span> <span class="p_context"> void __init emergency_stack_init(void)</span>
 
 static void * __init pcpu_fc_alloc(unsigned int cpu, size_t size, size_t align)
 {
<span class="p_del">-	return __alloc_bootmem_node(NODE_DATA(cpu_to_node(cpu)), size, align,</span>
<span class="p_add">+	return __alloc_bootmem_node(NODE_DATA(early_cpu_to_node(cpu)), size, align,</span>
 				    __pa(MAX_DMA_ADDRESS));
 }
 
<span class="p_chunk">@@ -661,7 +661,7 @@</span> <span class="p_context"> static void __init pcpu_fc_free(void *ptr, size_t size)</span>
 
 static int pcpu_cpu_distance(unsigned int from, unsigned int to)
 {
<span class="p_del">-	if (cpu_to_node(from) == cpu_to_node(to))</span>
<span class="p_add">+	if (early_cpu_to_node(from) == early_cpu_to_node(to))</span>
 		return LOCAL_DISTANCE;
 	else
 		return REMOTE_DISTANCE;
<span class="p_header">diff --git a/arch/powerpc/platforms/pseries/hotplug-memory.c b/arch/powerpc/platforms/pseries/hotplug-memory.c</span>
<span class="p_header">index e104c71ea44a..1fb162ba9d1c 100644</span>
<span class="p_header">--- a/arch/powerpc/platforms/pseries/hotplug-memory.c</span>
<span class="p_header">+++ b/arch/powerpc/platforms/pseries/hotplug-memory.c</span>
<span class="p_chunk">@@ -124,6 +124,7 @@</span> <span class="p_context"> static struct property *dlpar_clone_drconf_property(struct device_node *dn)</span>
 	for (i = 0; i &lt; num_lmbs; i++) {
 		lmbs[i].base_addr = be64_to_cpu(lmbs[i].base_addr);
 		lmbs[i].drc_index = be32_to_cpu(lmbs[i].drc_index);
<span class="p_add">+		lmbs[i].aa_index = be32_to_cpu(lmbs[i].aa_index);</span>
 		lmbs[i].flags = be32_to_cpu(lmbs[i].flags);
 	}
 
<span class="p_chunk">@@ -147,6 +148,7 @@</span> <span class="p_context"> static void dlpar_update_drconf_property(struct device_node *dn,</span>
 	for (i = 0; i &lt; num_lmbs; i++) {
 		lmbs[i].base_addr = cpu_to_be64(lmbs[i].base_addr);
 		lmbs[i].drc_index = cpu_to_be32(lmbs[i].drc_index);
<span class="p_add">+		lmbs[i].aa_index = cpu_to_be32(lmbs[i].aa_index);</span>
 		lmbs[i].flags = cpu_to_be32(lmbs[i].flags);
 	}
 
<span class="p_header">diff --git a/arch/powerpc/sysdev/simple_gpio.c b/arch/powerpc/sysdev/simple_gpio.c</span>
<span class="p_header">index ef470b470b04..6afddae2fb47 100644</span>
<span class="p_header">--- a/arch/powerpc/sysdev/simple_gpio.c</span>
<span class="p_header">+++ b/arch/powerpc/sysdev/simple_gpio.c</span>
<span class="p_chunk">@@ -75,7 +75,8 @@</span> <span class="p_context"> static int u8_gpio_dir_out(struct gpio_chip *gc, unsigned int gpio, int val)</span>
 
 static void u8_gpio_save_regs(struct of_mm_gpio_chip *mm_gc)
 {
<span class="p_del">-	struct u8_gpio_chip *u8_gc = gpiochip_get_data(&amp;mm_gc-&gt;gc);</span>
<span class="p_add">+	struct u8_gpio_chip *u8_gc =</span>
<span class="p_add">+		container_of(mm_gc, struct u8_gpio_chip, mm_gc);</span>
 
 	u8_gc-&gt;data = in_8(mm_gc-&gt;regs);
 }
<span class="p_header">diff --git a/arch/sparc/Kconfig b/arch/sparc/Kconfig</span>
<span class="p_header">index 3db2543733a5..1384d4c9764b 100644</span>
<span class="p_header">--- a/arch/sparc/Kconfig</span>
<span class="p_header">+++ b/arch/sparc/Kconfig</span>
<span class="p_chunk">@@ -192,9 +192,9 @@</span> <span class="p_context"> config NR_CPUS</span>
 	int &quot;Maximum number of CPUs&quot;
 	depends on SMP
 	range 2 32 if SPARC32
<span class="p_del">-	range 2 1024 if SPARC64</span>
<span class="p_add">+	range 2 4096 if SPARC64</span>
 	default 32 if SPARC32
<span class="p_del">-	default 64 if SPARC64</span>
<span class="p_add">+	default 4096 if SPARC64</span>
 
 source kernel/Kconfig.hz
 
<span class="p_header">diff --git a/arch/sparc/include/asm/mmu_64.h b/arch/sparc/include/asm/mmu_64.h</span>
<span class="p_header">index f7de0dbc38af..83b36a5371ff 100644</span>
<span class="p_header">--- a/arch/sparc/include/asm/mmu_64.h</span>
<span class="p_header">+++ b/arch/sparc/include/asm/mmu_64.h</span>
<span class="p_chunk">@@ -52,7 +52,7 @@</span> <span class="p_context"></span>
 #define CTX_NR_MASK		TAG_CONTEXT_BITS
 #define CTX_HW_MASK		(CTX_NR_MASK | CTX_PGSZ_MASK)
 
<span class="p_del">-#define CTX_FIRST_VERSION	((_AC(1,UL) &lt;&lt; CTX_VERSION_SHIFT) + _AC(1,UL))</span>
<span class="p_add">+#define CTX_FIRST_VERSION	BIT(CTX_VERSION_SHIFT)</span>
 #define CTX_VALID(__ctx)	\
 	 (!(((__ctx.sparc64_ctx_val) ^ tlb_context_cache) &amp; CTX_VERSION_MASK))
 #define CTX_HWBITS(__ctx)	((__ctx.sparc64_ctx_val) &amp; CTX_HW_MASK)
<span class="p_header">diff --git a/arch/sparc/include/asm/mmu_context_64.h b/arch/sparc/include/asm/mmu_context_64.h</span>
<span class="p_header">index 22fede6eba11..2cddcda4f85f 100644</span>
<span class="p_header">--- a/arch/sparc/include/asm/mmu_context_64.h</span>
<span class="p_header">+++ b/arch/sparc/include/asm/mmu_context_64.h</span>
<span class="p_chunk">@@ -19,13 +19,8 @@</span> <span class="p_context"> extern spinlock_t ctx_alloc_lock;</span>
 extern unsigned long tlb_context_cache;
 extern unsigned long mmu_context_bmap[];
 
<span class="p_add">+DECLARE_PER_CPU(struct mm_struct *, per_cpu_secondary_mm);</span>
 void get_new_mmu_context(struct mm_struct *mm);
<span class="p_del">-#ifdef CONFIG_SMP</span>
<span class="p_del">-void smp_new_mmu_context_version(void);</span>
<span class="p_del">-#else</span>
<span class="p_del">-#define smp_new_mmu_context_version() do { } while (0)</span>
<span class="p_del">-#endif</span>
<span class="p_del">-</span>
 int init_new_context(struct task_struct *tsk, struct mm_struct *mm);
 void destroy_context(struct mm_struct *mm);
 
<span class="p_chunk">@@ -76,8 +71,9 @@</span> <span class="p_context"> void __flush_tlb_mm(unsigned long, unsigned long);</span>
 static inline void switch_mm(struct mm_struct *old_mm, struct mm_struct *mm, struct task_struct *tsk)
 {
 	unsigned long ctx_valid, flags;
<span class="p_del">-	int cpu;</span>
<span class="p_add">+	int cpu = smp_processor_id();</span>
 
<span class="p_add">+	per_cpu(per_cpu_secondary_mm, cpu) = mm;</span>
 	if (unlikely(mm == &amp;init_mm))
 		return;
 
<span class="p_chunk">@@ -123,7 +119,6 @@</span> <span class="p_context"> static inline void switch_mm(struct mm_struct *old_mm, struct mm_struct *mm, str</span>
 	 * for the first time, we must flush that context out of the
 	 * local TLB.
 	 */
<span class="p_del">-	cpu = smp_processor_id();</span>
 	if (!ctx_valid || !cpumask_test_cpu(cpu, mm_cpumask(mm))) {
 		cpumask_set_cpu(cpu, mm_cpumask(mm));
 		__flush_tlb_mm(CTX_HWBITS(mm-&gt;context),
<span class="p_chunk">@@ -133,26 +128,7 @@</span> <span class="p_context"> static inline void switch_mm(struct mm_struct *old_mm, struct mm_struct *mm, str</span>
 }
 
 #define deactivate_mm(tsk,mm)	do { } while (0)
<span class="p_del">-</span>
<span class="p_del">-/* Activate a new MM instance for the current task. */</span>
<span class="p_del">-static inline void activate_mm(struct mm_struct *active_mm, struct mm_struct *mm)</span>
<span class="p_del">-{</span>
<span class="p_del">-	unsigned long flags;</span>
<span class="p_del">-	int cpu;</span>
<span class="p_del">-</span>
<span class="p_del">-	spin_lock_irqsave(&amp;mm-&gt;context.lock, flags);</span>
<span class="p_del">-	if (!CTX_VALID(mm-&gt;context))</span>
<span class="p_del">-		get_new_mmu_context(mm);</span>
<span class="p_del">-	cpu = smp_processor_id();</span>
<span class="p_del">-	if (!cpumask_test_cpu(cpu, mm_cpumask(mm)))</span>
<span class="p_del">-		cpumask_set_cpu(cpu, mm_cpumask(mm));</span>
<span class="p_del">-</span>
<span class="p_del">-	load_secondary_context(mm);</span>
<span class="p_del">-	__flush_tlb_mm(CTX_HWBITS(mm-&gt;context), SECONDARY_CONTEXT);</span>
<span class="p_del">-	tsb_context_switch(mm);</span>
<span class="p_del">-	spin_unlock_irqrestore(&amp;mm-&gt;context.lock, flags);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_add">+#define activate_mm(active_mm, mm) switch_mm(active_mm, mm, NULL)</span>
 #endif /* !(__ASSEMBLY__) */
 
 #endif /* !(__SPARC64_MMU_CONTEXT_H) */
<span class="p_header">diff --git a/arch/sparc/include/asm/pil.h b/arch/sparc/include/asm/pil.h</span>
<span class="p_header">index 266937030546..522b43db2ed3 100644</span>
<span class="p_header">--- a/arch/sparc/include/asm/pil.h</span>
<span class="p_header">+++ b/arch/sparc/include/asm/pil.h</span>
<span class="p_chunk">@@ -20,7 +20,6 @@</span> <span class="p_context"></span>
 #define PIL_SMP_CALL_FUNC	1
 #define PIL_SMP_RECEIVE_SIGNAL	2
 #define PIL_SMP_CAPTURE		3
<span class="p_del">-#define PIL_SMP_CTX_NEW_VERSION	4</span>
 #define PIL_DEVICE_IRQ		5
 #define PIL_SMP_CALL_FUNC_SNGL	6
 #define PIL_DEFERRED_PCR_WORK	7
<span class="p_header">diff --git a/arch/sparc/include/asm/vio.h b/arch/sparc/include/asm/vio.h</span>
<span class="p_header">index 8174f6cdbbbb..9dca7a892978 100644</span>
<span class="p_header">--- a/arch/sparc/include/asm/vio.h</span>
<span class="p_header">+++ b/arch/sparc/include/asm/vio.h</span>
<span class="p_chunk">@@ -327,6 +327,7 @@</span> <span class="p_context"> struct vio_dev {</span>
 	int			compat_len;
 
 	u64			dev_no;
<span class="p_add">+	u64			id;</span>
 
 	unsigned long		channel_id;
 
<span class="p_header">diff --git a/arch/sparc/kernel/irq_64.c b/arch/sparc/kernel/irq_64.c</span>
<span class="p_header">index 4d0248aa0928..99dd133a029f 100644</span>
<span class="p_header">--- a/arch/sparc/kernel/irq_64.c</span>
<span class="p_header">+++ b/arch/sparc/kernel/irq_64.c</span>
<span class="p_chunk">@@ -1034,17 +1034,26 @@</span> <span class="p_context"> static void __init init_cpu_send_mondo_info(struct trap_per_cpu *tb)</span>
 {
 #ifdef CONFIG_SMP
 	unsigned long page;
<span class="p_add">+	void *mondo, *p;</span>
 
<span class="p_del">-	BUILD_BUG_ON((NR_CPUS * sizeof(u16)) &gt; (PAGE_SIZE - 64));</span>
<span class="p_add">+	BUILD_BUG_ON((NR_CPUS * sizeof(u16)) &gt; PAGE_SIZE);</span>
<span class="p_add">+</span>
<span class="p_add">+	/* Make sure mondo block is 64byte aligned */</span>
<span class="p_add">+	p = kzalloc(127, GFP_KERNEL);</span>
<span class="p_add">+	if (!p) {</span>
<span class="p_add">+		prom_printf(&quot;SUN4V: Error, cannot allocate mondo block.\n&quot;);</span>
<span class="p_add">+		prom_halt();</span>
<span class="p_add">+	}</span>
<span class="p_add">+	mondo = (void *)(((unsigned long)p + 63) &amp; ~0x3f);</span>
<span class="p_add">+	tb-&gt;cpu_mondo_block_pa = __pa(mondo);</span>
 
 	page = get_zeroed_page(GFP_KERNEL);
 	if (!page) {
<span class="p_del">-		prom_printf(&quot;SUN4V: Error, cannot allocate cpu mondo page.\n&quot;);</span>
<span class="p_add">+		prom_printf(&quot;SUN4V: Error, cannot allocate cpu list page.\n&quot;);</span>
 		prom_halt();
 	}
 
<span class="p_del">-	tb-&gt;cpu_mondo_block_pa = __pa(page);</span>
<span class="p_del">-	tb-&gt;cpu_list_pa = __pa(page + 64);</span>
<span class="p_add">+	tb-&gt;cpu_list_pa = __pa(page);</span>
 #endif
 }
 
<span class="p_header">diff --git a/arch/sparc/kernel/kernel.h b/arch/sparc/kernel/kernel.h</span>
<span class="p_header">index c9804551262c..6ae1e77be0bf 100644</span>
<span class="p_header">--- a/arch/sparc/kernel/kernel.h</span>
<span class="p_header">+++ b/arch/sparc/kernel/kernel.h</span>
<span class="p_chunk">@@ -37,7 +37,6 @@</span> <span class="p_context"> void handle_stdfmna(struct pt_regs *regs, unsigned long sfar, unsigned long sfsr</span>
 /* smp_64.c */
 void __irq_entry smp_call_function_client(int irq, struct pt_regs *regs);
 void __irq_entry smp_call_function_single_client(int irq, struct pt_regs *regs);
<span class="p_del">-void __irq_entry smp_new_mmu_context_version_client(int irq, struct pt_regs *regs);</span>
 void __irq_entry smp_penguin_jailcell(int irq, struct pt_regs *regs);
 void __irq_entry smp_receive_signal_client(int irq, struct pt_regs *regs);
 
<span class="p_header">diff --git a/arch/sparc/kernel/smp_64.c b/arch/sparc/kernel/smp_64.c</span>
<span class="p_header">index b3bc0ac757cc..fdf31040a7dc 100644</span>
<span class="p_header">--- a/arch/sparc/kernel/smp_64.c</span>
<span class="p_header">+++ b/arch/sparc/kernel/smp_64.c</span>
<span class="p_chunk">@@ -964,37 +964,6 @@</span> <span class="p_context"> void flush_dcache_page_all(struct mm_struct *mm, struct page *page)</span>
 	preempt_enable();
 }
 
<span class="p_del">-void __irq_entry smp_new_mmu_context_version_client(int irq, struct pt_regs *regs)</span>
<span class="p_del">-{</span>
<span class="p_del">-	struct mm_struct *mm;</span>
<span class="p_del">-	unsigned long flags;</span>
<span class="p_del">-</span>
<span class="p_del">-	clear_softint(1 &lt;&lt; irq);</span>
<span class="p_del">-</span>
<span class="p_del">-	/* See if we need to allocate a new TLB context because</span>
<span class="p_del">-	 * the version of the one we are using is now out of date.</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	mm = current-&gt;active_mm;</span>
<span class="p_del">-	if (unlikely(!mm || (mm == &amp;init_mm)))</span>
<span class="p_del">-		return;</span>
<span class="p_del">-</span>
<span class="p_del">-	spin_lock_irqsave(&amp;mm-&gt;context.lock, flags);</span>
<span class="p_del">-</span>
<span class="p_del">-	if (unlikely(!CTX_VALID(mm-&gt;context)))</span>
<span class="p_del">-		get_new_mmu_context(mm);</span>
<span class="p_del">-</span>
<span class="p_del">-	spin_unlock_irqrestore(&amp;mm-&gt;context.lock, flags);</span>
<span class="p_del">-</span>
<span class="p_del">-	load_secondary_context(mm);</span>
<span class="p_del">-	__flush_tlb_mm(CTX_HWBITS(mm-&gt;context),</span>
<span class="p_del">-		       SECONDARY_CONTEXT);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-void smp_new_mmu_context_version(void)</span>
<span class="p_del">-{</span>
<span class="p_del">-	smp_cross_call(&amp;xcall_new_mmu_context_version, 0, 0, 0);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
 #ifdef CONFIG_KGDB
 void kgdb_roundup_cpus(unsigned long flags)
 {
<span class="p_header">diff --git a/arch/sparc/kernel/tsb.S b/arch/sparc/kernel/tsb.S</span>
<span class="p_header">index 10689cfd0ad4..07c0df924960 100644</span>
<span class="p_header">--- a/arch/sparc/kernel/tsb.S</span>
<span class="p_header">+++ b/arch/sparc/kernel/tsb.S</span>
<span class="p_chunk">@@ -455,13 +455,16 @@</span> <span class="p_context"> __tsb_context_switch:</span>
 	.type	copy_tsb,#function
 copy_tsb:		/* %o0=old_tsb_base, %o1=old_tsb_size
 			 * %o2=new_tsb_base, %o3=new_tsb_size
<span class="p_add">+			 * %o4=page_size_shift</span>
 			 */
 	sethi		%uhi(TSB_PASS_BITS), %g7
 	srlx		%o3, 4, %o3
<span class="p_del">-	add		%o0, %o1, %g1	/* end of old tsb */</span>
<span class="p_add">+	add		%o0, %o1, %o1	/* end of old tsb */</span>
 	sllx		%g7, 32, %g7
 	sub		%o3, 1, %o3	/* %o3 == new tsb hash mask */
 
<span class="p_add">+	mov		%o4, %g1	/* page_size_shift */</span>
<span class="p_add">+</span>
 661:	prefetcha	[%o0] ASI_N, #one_read
 	.section	.tsb_phys_patch, &quot;ax&quot;
 	.word		661b
<span class="p_chunk">@@ -486,9 +489,9 @@</span> <span class="p_context"> copy_tsb:		/* %o0=old_tsb_base, %o1=old_tsb_size</span>
 	/* This can definitely be computed faster... */
 	srlx		%o0, 4, %o5	/* Build index */
 	and		%o5, 511, %o5	/* Mask index */
<span class="p_del">-	sllx		%o5, PAGE_SHIFT, %o5 /* Put into vaddr position */</span>
<span class="p_add">+	sllx		%o5, %g1, %o5	/* Put into vaddr position */</span>
 	or		%o4, %o5, %o4	/* Full VADDR. */
<span class="p_del">-	srlx		%o4, PAGE_SHIFT, %o4 /* Shift down to create index */</span>
<span class="p_add">+	srlx		%o4, %g1, %o4	/* Shift down to create index */</span>
 	and		%o4, %o3, %o4	/* Mask with new_tsb_nents-1 */
 	sllx		%o4, 4, %o4	/* Shift back up into tsb ent offset */
 	TSB_STORE(%o2 + %o4, %g2)	/* Store TAG */
<span class="p_chunk">@@ -496,7 +499,7 @@</span> <span class="p_context"> copy_tsb:		/* %o0=old_tsb_base, %o1=old_tsb_size</span>
 	TSB_STORE(%o2 + %o4, %g3)	/* Store TTE */
 
 80:	add		%o0, 16, %o0
<span class="p_del">-	cmp		%o0, %g1</span>
<span class="p_add">+	cmp		%o0, %o1</span>
 	bne,pt		%xcc, 90b
 	 nop
 
<span class="p_header">diff --git a/arch/sparc/kernel/ttable_64.S b/arch/sparc/kernel/ttable_64.S</span>
<span class="p_header">index 7bd8f6556352..efe93ab4a9c0 100644</span>
<span class="p_header">--- a/arch/sparc/kernel/ttable_64.S</span>
<span class="p_header">+++ b/arch/sparc/kernel/ttable_64.S</span>
<span class="p_chunk">@@ -50,7 +50,7 @@</span> <span class="p_context"> tl0_resv03e:	BTRAP(0x3e) BTRAP(0x3f) BTRAP(0x40)</span>
 tl0_irq1:	TRAP_IRQ(smp_call_function_client, 1)
 tl0_irq2:	TRAP_IRQ(smp_receive_signal_client, 2)
 tl0_irq3:	TRAP_IRQ(smp_penguin_jailcell, 3)
<span class="p_del">-tl0_irq4:	TRAP_IRQ(smp_new_mmu_context_version_client, 4)</span>
<span class="p_add">+tl0_irq4:       BTRAP(0x44)</span>
 #else
 tl0_irq1:	BTRAP(0x41)
 tl0_irq2:	BTRAP(0x42)
<span class="p_header">diff --git a/arch/sparc/kernel/vio.c b/arch/sparc/kernel/vio.c</span>
<span class="p_header">index f6bb857254fc..075d38980dee 100644</span>
<span class="p_header">--- a/arch/sparc/kernel/vio.c</span>
<span class="p_header">+++ b/arch/sparc/kernel/vio.c</span>
<span class="p_chunk">@@ -302,13 +302,16 @@</span> <span class="p_context"> static struct vio_dev *vio_create_one(struct mdesc_handle *hp, u64 mp,</span>
 	if (!id) {
 		dev_set_name(&amp;vdev-&gt;dev, &quot;%s&quot;, bus_id_name);
 		vdev-&gt;dev_no = ~(u64)0;
<span class="p_add">+		vdev-&gt;id = ~(u64)0;</span>
 	} else if (!cfg_handle) {
 		dev_set_name(&amp;vdev-&gt;dev, &quot;%s-%llu&quot;, bus_id_name, *id);
 		vdev-&gt;dev_no = *id;
<span class="p_add">+		vdev-&gt;id = ~(u64)0;</span>
 	} else {
 		dev_set_name(&amp;vdev-&gt;dev, &quot;%s-%llu-%llu&quot;, bus_id_name,
 			     *cfg_handle, *id);
 		vdev-&gt;dev_no = *cfg_handle;
<span class="p_add">+		vdev-&gt;id = *id;</span>
 	}
 
 	vdev-&gt;dev.parent = parent;
<span class="p_chunk">@@ -351,27 +354,84 @@</span> <span class="p_context"> static void vio_add(struct mdesc_handle *hp, u64 node)</span>
 	(void) vio_create_one(hp, node, &amp;root_vdev-&gt;dev);
 }
 
<span class="p_add">+struct vio_md_node_query {</span>
<span class="p_add">+	const char *type;</span>
<span class="p_add">+	u64 dev_no;</span>
<span class="p_add">+	u64 id;</span>
<span class="p_add">+};</span>
<span class="p_add">+</span>
 static int vio_md_node_match(struct device *dev, void *arg)
 {
<span class="p_add">+	struct vio_md_node_query *query = (struct vio_md_node_query *) arg;</span>
 	struct vio_dev *vdev = to_vio_dev(dev);
 
<span class="p_del">-	if (vdev-&gt;mp == (u64) arg)</span>
<span class="p_del">-		return 1;</span>
<span class="p_add">+	if (vdev-&gt;dev_no != query-&gt;dev_no)</span>
<span class="p_add">+		return 0;</span>
<span class="p_add">+	if (vdev-&gt;id != query-&gt;id)</span>
<span class="p_add">+		return 0;</span>
<span class="p_add">+	if (strcmp(vdev-&gt;type, query-&gt;type))</span>
<span class="p_add">+		return 0;</span>
 
<span class="p_del">-	return 0;</span>
<span class="p_add">+	return 1;</span>
 }
 
 static void vio_remove(struct mdesc_handle *hp, u64 node)
 {
<span class="p_add">+	const char *type;</span>
<span class="p_add">+	const u64 *id, *cfg_handle;</span>
<span class="p_add">+	u64 a;</span>
<span class="p_add">+	struct vio_md_node_query query;</span>
 	struct device *dev;
 
<span class="p_del">-	dev = device_find_child(&amp;root_vdev-&gt;dev, (void *) node,</span>
<span class="p_add">+	type = mdesc_get_property(hp, node, &quot;device-type&quot;, NULL);</span>
<span class="p_add">+	if (!type) {</span>
<span class="p_add">+		type = mdesc_get_property(hp, node, &quot;name&quot;, NULL);</span>
<span class="p_add">+		if (!type)</span>
<span class="p_add">+			type = mdesc_node_name(hp, node);</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	query.type = type;</span>
<span class="p_add">+</span>
<span class="p_add">+	id = mdesc_get_property(hp, node, &quot;id&quot;, NULL);</span>
<span class="p_add">+	cfg_handle = NULL;</span>
<span class="p_add">+	mdesc_for_each_arc(a, hp, node, MDESC_ARC_TYPE_BACK) {</span>
<span class="p_add">+		u64 target;</span>
<span class="p_add">+</span>
<span class="p_add">+		target = mdesc_arc_target(hp, a);</span>
<span class="p_add">+		cfg_handle = mdesc_get_property(hp, target,</span>
<span class="p_add">+						&quot;cfg-handle&quot;, NULL);</span>
<span class="p_add">+		if (cfg_handle)</span>
<span class="p_add">+			break;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	if (!id) {</span>
<span class="p_add">+		query.dev_no = ~(u64)0;</span>
<span class="p_add">+		query.id = ~(u64)0;</span>
<span class="p_add">+	} else if (!cfg_handle) {</span>
<span class="p_add">+		query.dev_no = *id;</span>
<span class="p_add">+		query.id = ~(u64)0;</span>
<span class="p_add">+	} else {</span>
<span class="p_add">+		query.dev_no = *cfg_handle;</span>
<span class="p_add">+		query.id = *id;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	dev = device_find_child(&amp;root_vdev-&gt;dev, &amp;query,</span>
 				vio_md_node_match);
 	if (dev) {
 		printk(KERN_INFO &quot;VIO: Removing device %s\n&quot;, dev_name(dev));
 
 		device_unregister(dev);
 		put_device(dev);
<span class="p_add">+	} else {</span>
<span class="p_add">+		if (!id)</span>
<span class="p_add">+			printk(KERN_ERR &quot;VIO: Removed unknown %s node.\n&quot;,</span>
<span class="p_add">+			       type);</span>
<span class="p_add">+		else if (!cfg_handle)</span>
<span class="p_add">+			printk(KERN_ERR &quot;VIO: Removed unknown %s node %llu.\n&quot;,</span>
<span class="p_add">+			       type, *id);</span>
<span class="p_add">+		else</span>
<span class="p_add">+			printk(KERN_ERR &quot;VIO: Removed unknown %s node %llu-%llu.\n&quot;,</span>
<span class="p_add">+			       type, *cfg_handle, *id);</span>
 	}
 }
 
<span class="p_header">diff --git a/arch/sparc/lib/Makefile b/arch/sparc/lib/Makefile</span>
<span class="p_header">index 69912d2f8b54..07c03e72d812 100644</span>
<span class="p_header">--- a/arch/sparc/lib/Makefile</span>
<span class="p_header">+++ b/arch/sparc/lib/Makefile</span>
<span class="p_chunk">@@ -15,6 +15,7 @@</span> <span class="p_context"> lib-$(CONFIG_SPARC32) += copy_user.o locks.o</span>
 lib-$(CONFIG_SPARC64) += atomic_64.o
 lib-$(CONFIG_SPARC32) += lshrdi3.o ashldi3.o
 lib-$(CONFIG_SPARC32) += muldi3.o bitext.o cmpdi2.o
<span class="p_add">+lib-$(CONFIG_SPARC64) += multi3.o</span>
 
 lib-$(CONFIG_SPARC64) += copy_page.o clear_page.o bzero.o
 lib-$(CONFIG_SPARC64) += csum_copy.o csum_copy_from_user.o csum_copy_to_user.o
<span class="p_header">diff --git a/arch/sparc/lib/multi3.S b/arch/sparc/lib/multi3.S</span>
new file mode 100644
<span class="p_header">index 000000000000..d6b6c97fe3c7</span>
<span class="p_header">--- /dev/null</span>
<span class="p_header">+++ b/arch/sparc/lib/multi3.S</span>
<span class="p_chunk">@@ -0,0 +1,35 @@</span> <span class="p_context"></span>
<span class="p_add">+#include &lt;linux/linkage.h&gt;</span>
<span class="p_add">+#include &lt;asm/export.h&gt;</span>
<span class="p_add">+</span>
<span class="p_add">+	.text</span>
<span class="p_add">+	.align	4</span>
<span class="p_add">+ENTRY(__multi3) /* %o0 = u, %o1 = v */</span>
<span class="p_add">+	mov	%o1, %g1</span>
<span class="p_add">+	srl	%o3, 0, %g4</span>
<span class="p_add">+	mulx	%g4, %g1, %o1</span>
<span class="p_add">+	srlx	%g1, 0x20, %g3</span>
<span class="p_add">+	mulx	%g3, %g4, %g5</span>
<span class="p_add">+	sllx	%g5, 0x20, %o5</span>
<span class="p_add">+	srl	%g1, 0, %g4</span>
<span class="p_add">+	sub	%o1, %o5, %o5</span>
<span class="p_add">+	srlx	%o5, 0x20, %o5</span>
<span class="p_add">+	addcc	%g5, %o5, %g5</span>
<span class="p_add">+	srlx	%o3, 0x20, %o5</span>
<span class="p_add">+	mulx	%g4, %o5, %g4</span>
<span class="p_add">+	mulx	%g3, %o5, %o5</span>
<span class="p_add">+	sethi	%hi(0x80000000), %g3</span>
<span class="p_add">+	addcc	%g5, %g4, %g5</span>
<span class="p_add">+	srlx	%g5, 0x20, %g5</span>
<span class="p_add">+	add	%g3, %g3, %g3</span>
<span class="p_add">+	movcc	%xcc, %g0, %g3</span>
<span class="p_add">+	addcc	%o5, %g5, %o5</span>
<span class="p_add">+	sllx	%g4, 0x20, %g4</span>
<span class="p_add">+	add	%o1, %g4, %o1</span>
<span class="p_add">+	add	%o5, %g3, %g2</span>
<span class="p_add">+	mulx	%g1, %o2, %g1</span>
<span class="p_add">+	add	%g1, %g2, %g1</span>
<span class="p_add">+	mulx	%o0, %o3, %o0</span>
<span class="p_add">+	retl</span>
<span class="p_add">+	 add	%g1, %o0, %o0</span>
<span class="p_add">+ENDPROC(__multi3)</span>
<span class="p_add">+EXPORT_SYMBOL(__multi3)</span>
<span class="p_header">diff --git a/arch/sparc/mm/init_64.c b/arch/sparc/mm/init_64.c</span>
<span class="p_header">index 0cda653ae007..3c40ebd50f92 100644</span>
<span class="p_header">--- a/arch/sparc/mm/init_64.c</span>
<span class="p_header">+++ b/arch/sparc/mm/init_64.c</span>
<span class="p_chunk">@@ -358,7 +358,8 @@</span> <span class="p_context"> static int __init setup_hugepagesz(char *string)</span>
 	}
 
 	if ((hv_pgsz_mask &amp; cpu_pgsz_mask) == 0U) {
<span class="p_del">-		pr_warn(&quot;hugepagesz=%llu not supported by MMU.\n&quot;,</span>
<span class="p_add">+		hugetlb_bad_size();</span>
<span class="p_add">+		pr_err(&quot;hugepagesz=%llu not supported by MMU.\n&quot;,</span>
 			hugepage_size);
 		goto out;
 	}
<span class="p_chunk">@@ -706,10 +707,58 @@</span> <span class="p_context"> EXPORT_SYMBOL(__flush_dcache_range);</span>
 
 /* get_new_mmu_context() uses &quot;cache + 1&quot;.  */
 DEFINE_SPINLOCK(ctx_alloc_lock);
<span class="p_del">-unsigned long tlb_context_cache = CTX_FIRST_VERSION - 1;</span>
<span class="p_add">+unsigned long tlb_context_cache = CTX_FIRST_VERSION;</span>
 #define MAX_CTX_NR	(1UL &lt;&lt; CTX_NR_BITS)
 #define CTX_BMAP_SLOTS	BITS_TO_LONGS(MAX_CTX_NR)
 DECLARE_BITMAP(mmu_context_bmap, MAX_CTX_NR);
<span class="p_add">+DEFINE_PER_CPU(struct mm_struct *, per_cpu_secondary_mm) = {0};</span>
<span class="p_add">+</span>
<span class="p_add">+static void mmu_context_wrap(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned long old_ver = tlb_context_cache &amp; CTX_VERSION_MASK;</span>
<span class="p_add">+	unsigned long new_ver, new_ctx, old_ctx;</span>
<span class="p_add">+	struct mm_struct *mm;</span>
<span class="p_add">+	int cpu;</span>
<span class="p_add">+</span>
<span class="p_add">+	bitmap_zero(mmu_context_bmap, 1 &lt;&lt; CTX_NR_BITS);</span>
<span class="p_add">+</span>
<span class="p_add">+	/* Reserve kernel context */</span>
<span class="p_add">+	set_bit(0, mmu_context_bmap);</span>
<span class="p_add">+</span>
<span class="p_add">+	new_ver = (tlb_context_cache &amp; CTX_VERSION_MASK) + CTX_FIRST_VERSION;</span>
<span class="p_add">+	if (unlikely(new_ver == 0))</span>
<span class="p_add">+		new_ver = CTX_FIRST_VERSION;</span>
<span class="p_add">+	tlb_context_cache = new_ver;</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Make sure that any new mm that are added into per_cpu_secondary_mm,</span>
<span class="p_add">+	 * are going to go through get_new_mmu_context() path.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	mb();</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Updated versions to current on those CPUs that had valid secondary</span>
<span class="p_add">+	 * contexts</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	for_each_online_cpu(cpu) {</span>
<span class="p_add">+		/*</span>
<span class="p_add">+		 * If a new mm is stored after we took this mm from the array,</span>
<span class="p_add">+		 * it will go into get_new_mmu_context() path, because we</span>
<span class="p_add">+		 * already bumped the version in tlb_context_cache.</span>
<span class="p_add">+		 */</span>
<span class="p_add">+		mm = per_cpu(per_cpu_secondary_mm, cpu);</span>
<span class="p_add">+</span>
<span class="p_add">+		if (unlikely(!mm || mm == &amp;init_mm))</span>
<span class="p_add">+			continue;</span>
<span class="p_add">+</span>
<span class="p_add">+		old_ctx = mm-&gt;context.sparc64_ctx_val;</span>
<span class="p_add">+		if (likely((old_ctx &amp; CTX_VERSION_MASK) == old_ver)) {</span>
<span class="p_add">+			new_ctx = (old_ctx &amp; ~CTX_VERSION_MASK) | new_ver;</span>
<span class="p_add">+			set_bit(new_ctx &amp; CTX_NR_MASK, mmu_context_bmap);</span>
<span class="p_add">+			mm-&gt;context.sparc64_ctx_val = new_ctx;</span>
<span class="p_add">+		}</span>
<span class="p_add">+	}</span>
<span class="p_add">+}</span>
 
 /* Caller does TLB context flushing on local CPU if necessary.
  * The caller also ensures that CTX_VALID(mm-&gt;context) is false.
<span class="p_chunk">@@ -725,48 +774,30 @@</span> <span class="p_context"> void get_new_mmu_context(struct mm_struct *mm)</span>
 {
 	unsigned long ctx, new_ctx;
 	unsigned long orig_pgsz_bits;
<span class="p_del">-	int new_version;</span>
 
 	spin_lock(&amp;ctx_alloc_lock);
<span class="p_add">+retry:</span>
<span class="p_add">+	/* wrap might have happened, test again if our context became valid */</span>
<span class="p_add">+	if (unlikely(CTX_VALID(mm-&gt;context)))</span>
<span class="p_add">+		goto out;</span>
 	orig_pgsz_bits = (mm-&gt;context.sparc64_ctx_val &amp; CTX_PGSZ_MASK);
 	ctx = (tlb_context_cache + 1) &amp; CTX_NR_MASK;
 	new_ctx = find_next_zero_bit(mmu_context_bmap, 1 &lt;&lt; CTX_NR_BITS, ctx);
<span class="p_del">-	new_version = 0;</span>
 	if (new_ctx &gt;= (1 &lt;&lt; CTX_NR_BITS)) {
 		new_ctx = find_next_zero_bit(mmu_context_bmap, ctx, 1);
 		if (new_ctx &gt;= ctx) {
<span class="p_del">-			int i;</span>
<span class="p_del">-			new_ctx = (tlb_context_cache &amp; CTX_VERSION_MASK) +</span>
<span class="p_del">-				CTX_FIRST_VERSION;</span>
<span class="p_del">-			if (new_ctx == 1)</span>
<span class="p_del">-				new_ctx = CTX_FIRST_VERSION;</span>
<span class="p_del">-</span>
<span class="p_del">-			/* Don&#39;t call memset, for 16 entries that&#39;s just</span>
<span class="p_del">-			 * plain silly...</span>
<span class="p_del">-			 */</span>
<span class="p_del">-			mmu_context_bmap[0] = 3;</span>
<span class="p_del">-			mmu_context_bmap[1] = 0;</span>
<span class="p_del">-			mmu_context_bmap[2] = 0;</span>
<span class="p_del">-			mmu_context_bmap[3] = 0;</span>
<span class="p_del">-			for (i = 4; i &lt; CTX_BMAP_SLOTS; i += 4) {</span>
<span class="p_del">-				mmu_context_bmap[i + 0] = 0;</span>
<span class="p_del">-				mmu_context_bmap[i + 1] = 0;</span>
<span class="p_del">-				mmu_context_bmap[i + 2] = 0;</span>
<span class="p_del">-				mmu_context_bmap[i + 3] = 0;</span>
<span class="p_del">-			}</span>
<span class="p_del">-			new_version = 1;</span>
<span class="p_del">-			goto out;</span>
<span class="p_add">+			mmu_context_wrap();</span>
<span class="p_add">+			goto retry;</span>
 		}
 	}
<span class="p_add">+	if (mm-&gt;context.sparc64_ctx_val)</span>
<span class="p_add">+		cpumask_clear(mm_cpumask(mm));</span>
 	mmu_context_bmap[new_ctx&gt;&gt;6] |= (1UL &lt;&lt; (new_ctx &amp; 63));
 	new_ctx |= (tlb_context_cache &amp; CTX_VERSION_MASK);
<span class="p_del">-out:</span>
 	tlb_context_cache = new_ctx;
 	mm-&gt;context.sparc64_ctx_val = new_ctx | orig_pgsz_bits;
<span class="p_add">+out:</span>
 	spin_unlock(&amp;ctx_alloc_lock);
<span class="p_del">-</span>
<span class="p_del">-	if (unlikely(new_version))</span>
<span class="p_del">-		smp_new_mmu_context_version();</span>
 }
 
 static int numa_enabled = 1;
<span class="p_header">diff --git a/arch/sparc/mm/tsb.c b/arch/sparc/mm/tsb.c</span>
<span class="p_header">index bedf08b22a47..0d4b998c7d7b 100644</span>
<span class="p_header">--- a/arch/sparc/mm/tsb.c</span>
<span class="p_header">+++ b/arch/sparc/mm/tsb.c</span>
<span class="p_chunk">@@ -496,7 +496,8 @@</span> <span class="p_context"> void tsb_grow(struct mm_struct *mm, unsigned long tsb_index, unsigned long rss)</span>
 		extern void copy_tsb(unsigned long old_tsb_base,
 				     unsigned long old_tsb_size,
 				     unsigned long new_tsb_base,
<span class="p_del">-				     unsigned long new_tsb_size);</span>
<span class="p_add">+				     unsigned long new_tsb_size,</span>
<span class="p_add">+				     unsigned long page_size_shift);</span>
 		unsigned long old_tsb_base = (unsigned long) old_tsb;
 		unsigned long new_tsb_base = (unsigned long) new_tsb;
 
<span class="p_chunk">@@ -504,7 +505,9 @@</span> <span class="p_context"> void tsb_grow(struct mm_struct *mm, unsigned long tsb_index, unsigned long rss)</span>
 			old_tsb_base = __pa(old_tsb_base);
 			new_tsb_base = __pa(new_tsb_base);
 		}
<span class="p_del">-		copy_tsb(old_tsb_base, old_size, new_tsb_base, new_size);</span>
<span class="p_add">+		copy_tsb(old_tsb_base, old_size, new_tsb_base, new_size,</span>
<span class="p_add">+			tsb_index == MM_TSB_BASE ?</span>
<span class="p_add">+			PAGE_SHIFT : REAL_HPAGE_SHIFT);</span>
 	}
 
 	mm-&gt;context.tsb_block[tsb_index].tsb = new_tsb;
<span class="p_header">diff --git a/arch/sparc/mm/ultra.S b/arch/sparc/mm/ultra.S</span>
<span class="p_header">index 5d2fd6cd3189..fcf4d27a38fb 100644</span>
<span class="p_header">--- a/arch/sparc/mm/ultra.S</span>
<span class="p_header">+++ b/arch/sparc/mm/ultra.S</span>
<span class="p_chunk">@@ -971,11 +971,6 @@</span> <span class="p_context"> xcall_capture:</span>
 	wr		%g0, (1 &lt;&lt; PIL_SMP_CAPTURE), %set_softint
 	retry
 
<span class="p_del">-	.globl		xcall_new_mmu_context_version</span>
<span class="p_del">-xcall_new_mmu_context_version:</span>
<span class="p_del">-	wr		%g0, (1 &lt;&lt; PIL_SMP_CTX_NEW_VERSION), %set_softint</span>
<span class="p_del">-	retry</span>
<span class="p_del">-</span>
 #ifdef CONFIG_KGDB
 	.globl		xcall_kgdb_capture
 xcall_kgdb_capture:
<span class="p_header">diff --git a/arch/x86/kernel/cpu/microcode/intel.c b/arch/x86/kernel/cpu/microcode/intel.c</span>
<span class="p_header">index 8325d8a09ab0..91eb813e8917 100644</span>
<span class="p_header">--- a/arch/x86/kernel/cpu/microcode/intel.c</span>
<span class="p_header">+++ b/arch/x86/kernel/cpu/microcode/intel.c</span>
<span class="p_chunk">@@ -619,6 +619,9 @@</span> <span class="p_context"> int __init save_microcode_in_initrd_intel(void)</span>
 
 	show_saved_mc();
 
<span class="p_add">+	/* initrd is going away, clear patch ptr. */</span>
<span class="p_add">+	intel_ucode_patch = NULL;</span>
<span class="p_add">+</span>
 	return 0;
 }
 
<span class="p_header">diff --git a/arch/x86/kernel/kvm.c b/arch/x86/kernel/kvm.c</span>
<span class="p_header">index 14f65a5f938e..2a7835932b71 100644</span>
<span class="p_header">--- a/arch/x86/kernel/kvm.c</span>
<span class="p_header">+++ b/arch/x86/kernel/kvm.c</span>
<span class="p_chunk">@@ -161,8 +161,8 @@</span> <span class="p_context"> void kvm_async_pf_task_wait(u32 token)</span>
 			 */
 			rcu_irq_exit();
 			native_safe_halt();
<span class="p_del">-			rcu_irq_enter();</span>
 			local_irq_disable();
<span class="p_add">+			rcu_irq_enter();</span>
 		}
 	}
 	if (!n.halted)
<span class="p_header">diff --git a/arch/x86/kvm/cpuid.c b/arch/x86/kvm/cpuid.c</span>
<span class="p_header">index efde6cc50875..3665f755baa3 100644</span>
<span class="p_header">--- a/arch/x86/kvm/cpuid.c</span>
<span class="p_header">+++ b/arch/x86/kvm/cpuid.c</span>
<span class="p_chunk">@@ -780,18 +780,20 @@</span> <span class="p_context"> int kvm_dev_ioctl_get_cpuid(struct kvm_cpuid2 *cpuid,</span>
 static int move_to_next_stateful_cpuid_entry(struct kvm_vcpu *vcpu, int i)
 {
 	struct kvm_cpuid_entry2 *e = &amp;vcpu-&gt;arch.cpuid_entries[i];
<span class="p_del">-	int j, nent = vcpu-&gt;arch.cpuid_nent;</span>
<span class="p_add">+	struct kvm_cpuid_entry2 *ej;</span>
<span class="p_add">+	int j = i;</span>
<span class="p_add">+	int nent = vcpu-&gt;arch.cpuid_nent;</span>
 
 	e-&gt;flags &amp;= ~KVM_CPUID_FLAG_STATE_READ_NEXT;
 	/* when no next entry is found, the current entry[i] is reselected */
<span class="p_del">-	for (j = i + 1; ; j = (j + 1) % nent) {</span>
<span class="p_del">-		struct kvm_cpuid_entry2 *ej = &amp;vcpu-&gt;arch.cpuid_entries[j];</span>
<span class="p_del">-		if (ej-&gt;function == e-&gt;function) {</span>
<span class="p_del">-			ej-&gt;flags |= KVM_CPUID_FLAG_STATE_READ_NEXT;</span>
<span class="p_del">-			return j;</span>
<span class="p_del">-		}</span>
<span class="p_del">-	}</span>
<span class="p_del">-	return 0; /* silence gcc, even though control never reaches here */</span>
<span class="p_add">+	do {</span>
<span class="p_add">+		j = (j + 1) % nent;</span>
<span class="p_add">+		ej = &amp;vcpu-&gt;arch.cpuid_entries[j];</span>
<span class="p_add">+	} while (ej-&gt;function != e-&gt;function);</span>
<span class="p_add">+</span>
<span class="p_add">+	ej-&gt;flags |= KVM_CPUID_FLAG_STATE_READ_NEXT;</span>
<span class="p_add">+</span>
<span class="p_add">+	return j;</span>
 }
 
 /* find an entry with matching function, matching index (if needed), and that
<span class="p_header">diff --git a/arch/x86/kvm/mmu.c b/arch/x86/kvm/mmu.c</span>
<span class="p_header">index ac7810513d0e..732c0270a489 100644</span>
<span class="p_header">--- a/arch/x86/kvm/mmu.c</span>
<span class="p_header">+++ b/arch/x86/kvm/mmu.c</span>
<span class="p_chunk">@@ -3683,12 +3683,15 @@</span> <span class="p_context"> static int kvm_arch_setup_async_pf(struct kvm_vcpu *vcpu, gva_t gva, gfn_t gfn)</span>
 	return kvm_setup_async_pf(vcpu, gva, kvm_vcpu_gfn_to_hva(vcpu, gfn), &amp;arch);
 }
 
<span class="p_del">-static bool can_do_async_pf(struct kvm_vcpu *vcpu)</span>
<span class="p_add">+bool kvm_can_do_async_pf(struct kvm_vcpu *vcpu)</span>
 {
 	if (unlikely(!lapic_in_kernel(vcpu) ||
 		     kvm_event_needs_reinjection(vcpu)))
 		return false;
 
<span class="p_add">+	if (is_guest_mode(vcpu))</span>
<span class="p_add">+		return false;</span>
<span class="p_add">+</span>
 	return kvm_x86_ops-&gt;interrupt_allowed(vcpu);
 }
 
<span class="p_chunk">@@ -3704,7 +3707,7 @@</span> <span class="p_context"> static bool try_async_pf(struct kvm_vcpu *vcpu, bool prefault, gfn_t gfn,</span>
 	if (!async)
 		return false; /* *pfn has correct page already */
 
<span class="p_del">-	if (!prefault &amp;&amp; can_do_async_pf(vcpu)) {</span>
<span class="p_add">+	if (!prefault &amp;&amp; kvm_can_do_async_pf(vcpu)) {</span>
 		trace_kvm_try_async_get_page(gva, gfn);
 		if (kvm_find_async_pf_gfn(vcpu, gfn)) {
 			trace_kvm_async_pf_doublefault(gva, gfn);
<span class="p_header">diff --git a/arch/x86/kvm/mmu.h b/arch/x86/kvm/mmu.h</span>
<span class="p_header">index ddc56e91f2e4..c92834c55c59 100644</span>
<span class="p_header">--- a/arch/x86/kvm/mmu.h</span>
<span class="p_header">+++ b/arch/x86/kvm/mmu.h</span>
<span class="p_chunk">@@ -75,6 +75,7 @@</span> <span class="p_context"> enum {</span>
 int handle_mmio_page_fault(struct kvm_vcpu *vcpu, u64 addr, bool direct);
 void kvm_init_shadow_mmu(struct kvm_vcpu *vcpu);
 void kvm_init_shadow_ept_mmu(struct kvm_vcpu *vcpu, bool execonly);
<span class="p_add">+bool kvm_can_do_async_pf(struct kvm_vcpu *vcpu);</span>
 
 static inline unsigned int kvm_mmu_available_pages(struct kvm *kvm)
 {
<span class="p_header">diff --git a/arch/x86/kvm/x86.c b/arch/x86/kvm/x86.c</span>
<span class="p_header">index a4a2bae7c274..6557c790c8c1 100644</span>
<span class="p_header">--- a/arch/x86/kvm/x86.c</span>
<span class="p_header">+++ b/arch/x86/kvm/x86.c</span>
<span class="p_chunk">@@ -8623,8 +8623,7 @@</span> <span class="p_context"> bool kvm_arch_can_inject_async_page_present(struct kvm_vcpu *vcpu)</span>
 	if (!(vcpu-&gt;arch.apf.msr_val &amp; KVM_ASYNC_PF_ENABLED))
 		return true;
 	else
<span class="p_del">-		return !kvm_event_needs_reinjection(vcpu) &amp;&amp;</span>
<span class="p_del">-			kvm_x86_ops-&gt;interrupt_allowed(vcpu);</span>
<span class="p_add">+		return kvm_can_do_async_pf(vcpu);</span>
 }
 
 void kvm_arch_start_assignment(struct kvm *kvm)
<span class="p_header">diff --git a/arch/x86/platform/efi/efi-bgrt.c b/arch/x86/platform/efi/efi-bgrt.c</span>
<span class="p_header">index 04ca8764f0c0..8bf27323f7a3 100644</span>
<span class="p_header">--- a/arch/x86/platform/efi/efi-bgrt.c</span>
<span class="p_header">+++ b/arch/x86/platform/efi/efi-bgrt.c</span>
<span class="p_chunk">@@ -36,6 +36,9 @@</span> <span class="p_context"> void __init efi_bgrt_init(struct acpi_table_header *table)</span>
 	if (acpi_disabled)
 		return;
 
<span class="p_add">+	if (!efi_enabled(EFI_BOOT))</span>
<span class="p_add">+		return;</span>
<span class="p_add">+</span>
 	if (table-&gt;length &lt; sizeof(bgrt_tab)) {
 		pr_notice(&quot;Ignoring BGRT: invalid length %u (expected %zu)\n&quot;,
 		       table-&gt;length, sizeof(bgrt_tab));
<span class="p_header">diff --git a/arch/x86/platform/efi/quirks.c b/arch/x86/platform/efi/quirks.c</span>
<span class="p_header">index cdfe8c628959..393a0c0288d1 100644</span>
<span class="p_header">--- a/arch/x86/platform/efi/quirks.c</span>
<span class="p_header">+++ b/arch/x86/platform/efi/quirks.c</span>
<span class="p_chunk">@@ -358,6 +358,9 @@</span> <span class="p_context"> void __init efi_free_boot_services(void)</span>
 		free_bootmem_late(start, size);
 	}
 
<span class="p_add">+	if (!num_entries)</span>
<span class="p_add">+		return;</span>
<span class="p_add">+</span>
 	new_size = efi.memmap.desc_size * num_entries;
 	new_phys = efi_memmap_alloc(num_entries);
 	if (!new_phys) {
<span class="p_header">diff --git a/block/blk-cgroup.c b/block/blk-cgroup.c</span>
<span class="p_header">index bbe7ee00bd3d..a981cc916a13 100644</span>
<span class="p_header">--- a/block/blk-cgroup.c</span>
<span class="p_header">+++ b/block/blk-cgroup.c</span>
<span class="p_chunk">@@ -74,7 +74,7 @@</span> <span class="p_context"> static void blkg_free(struct blkcg_gq *blkg)</span>
 			blkcg_policy[i]-&gt;pd_free_fn(blkg-&gt;pd[i]);
 
 	if (blkg-&gt;blkcg != &amp;blkcg_root)
<span class="p_del">-		blk_exit_rl(&amp;blkg-&gt;rl);</span>
<span class="p_add">+		blk_exit_rl(blkg-&gt;q, &amp;blkg-&gt;rl);</span>
 
 	blkg_rwstat_exit(&amp;blkg-&gt;stat_ios);
 	blkg_rwstat_exit(&amp;blkg-&gt;stat_bytes);
<span class="p_header">diff --git a/block/blk-core.c b/block/blk-core.c</span>
<span class="p_header">index d772c221cc17..1fb277501017 100644</span>
<span class="p_header">--- a/block/blk-core.c</span>
<span class="p_header">+++ b/block/blk-core.c</span>
<span class="p_chunk">@@ -643,13 +643,19 @@</span> <span class="p_context"> int blk_init_rl(struct request_list *rl, struct request_queue *q,</span>
 	if (!rl-&gt;rq_pool)
 		return -ENOMEM;
 
<span class="p_add">+	if (rl != &amp;q-&gt;root_rl)</span>
<span class="p_add">+		WARN_ON_ONCE(!blk_get_queue(q));</span>
<span class="p_add">+</span>
 	return 0;
 }
 
<span class="p_del">-void blk_exit_rl(struct request_list *rl)</span>
<span class="p_add">+void blk_exit_rl(struct request_queue *q, struct request_list *rl)</span>
 {
<span class="p_del">-	if (rl-&gt;rq_pool)</span>
<span class="p_add">+	if (rl-&gt;rq_pool) {</span>
 		mempool_destroy(rl-&gt;rq_pool);
<span class="p_add">+		if (rl != &amp;q-&gt;root_rl)</span>
<span class="p_add">+			blk_put_queue(q);</span>
<span class="p_add">+	}</span>
 }
 
 struct request_queue *blk_alloc_queue(gfp_t gfp_mask)
<span class="p_header">diff --git a/block/blk-sysfs.c b/block/blk-sysfs.c</span>
<span class="p_header">index 37f0b3ad635e..6a13d0924a66 100644</span>
<span class="p_header">--- a/block/blk-sysfs.c</span>
<span class="p_header">+++ b/block/blk-sysfs.c</span>
<span class="p_chunk">@@ -819,7 +819,7 @@</span> <span class="p_context"> static void blk_release_queue(struct kobject *kobj)</span>
 		elevator_exit(q, q-&gt;elevator);
 	}
 
<span class="p_del">-	blk_exit_rl(&amp;q-&gt;root_rl);</span>
<span class="p_add">+	blk_exit_rl(q, &amp;q-&gt;root_rl);</span>
 
 	if (q-&gt;queue_tags)
 		__blk_queue_free_tags(q);
<span class="p_header">diff --git a/block/blk.h b/block/blk.h</span>
<span class="p_header">index d1ea4bd9b9a3..8701d0a74eb1 100644</span>
<span class="p_header">--- a/block/blk.h</span>
<span class="p_header">+++ b/block/blk.h</span>
<span class="p_chunk">@@ -59,7 +59,7 @@</span> <span class="p_context"> void blk_free_flush_queue(struct blk_flush_queue *q);</span>
 
 int blk_init_rl(struct request_list *rl, struct request_queue *q,
 		gfp_t gfp_mask);
<span class="p_del">-void blk_exit_rl(struct request_list *rl);</span>
<span class="p_add">+void blk_exit_rl(struct request_queue *q, struct request_list *rl);</span>
 void init_request_from_bio(struct request *req, struct bio *bio);
 void blk_rq_bio_prep(struct request_queue *q, struct request *rq,
 			struct bio *bio);
<span class="p_header">diff --git a/block/cfq-iosched.c b/block/cfq-iosched.c</span>
<span class="p_header">index 440b95ee593c..2762505664a6 100644</span>
<span class="p_header">--- a/block/cfq-iosched.c</span>
<span class="p_header">+++ b/block/cfq-iosched.c</span>
<span class="p_chunk">@@ -38,9 +38,13 @@</span> <span class="p_context"> static const u64 cfq_target_latency = (u64)NSEC_PER_SEC * 3/10; /* 300 ms */</span>
 static const int cfq_hist_divisor = 4;
 
 /*
<span class="p_del">- * offset from end of service tree</span>
<span class="p_add">+ * offset from end of queue service tree for idle class</span>
  */
 #define CFQ_IDLE_DELAY		(NSEC_PER_SEC / 5)
<span class="p_add">+/* offset from end of group service tree under time slice mode */</span>
<span class="p_add">+#define CFQ_SLICE_MODE_GROUP_DELAY (NSEC_PER_SEC / 5)</span>
<span class="p_add">+/* offset from end of group service under IOPS mode */</span>
<span class="p_add">+#define CFQ_IOPS_MODE_GROUP_DELAY (HZ / 5)</span>
 
 /*
  * below this threshold, we consider thinktime immediate
<span class="p_chunk">@@ -1362,6 +1366,14 @@</span> <span class="p_context"> cfq_group_service_tree_add(struct cfq_rb_root *st, struct cfq_group *cfqg)</span>
 	cfqg-&gt;vfraction = max_t(unsigned, vfr, 1);
 }
 
<span class="p_add">+static inline u64 cfq_get_cfqg_vdisktime_delay(struct cfq_data *cfqd)</span>
<span class="p_add">+{</span>
<span class="p_add">+	if (!iops_mode(cfqd))</span>
<span class="p_add">+		return CFQ_SLICE_MODE_GROUP_DELAY;</span>
<span class="p_add">+	else</span>
<span class="p_add">+		return CFQ_IOPS_MODE_GROUP_DELAY;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static void
 cfq_group_notify_queue_add(struct cfq_data *cfqd, struct cfq_group *cfqg)
 {
<span class="p_chunk">@@ -1381,7 +1393,8 @@</span> <span class="p_context"> cfq_group_notify_queue_add(struct cfq_data *cfqd, struct cfq_group *cfqg)</span>
 	n = rb_last(&amp;st-&gt;rb);
 	if (n) {
 		__cfqg = rb_entry_cfqg(n);
<span class="p_del">-		cfqg-&gt;vdisktime = __cfqg-&gt;vdisktime + CFQ_IDLE_DELAY;</span>
<span class="p_add">+		cfqg-&gt;vdisktime = __cfqg-&gt;vdisktime +</span>
<span class="p_add">+			cfq_get_cfqg_vdisktime_delay(cfqd);</span>
 	} else
 		cfqg-&gt;vdisktime = st-&gt;min_vdisktime;
 	cfq_group_service_tree_add(st, cfqg);
<span class="p_header">diff --git a/crypto/asymmetric_keys/public_key.c b/crypto/asymmetric_keys/public_key.c</span>
<span class="p_header">index d3a989e718f5..3cd6e12cfc46 100644</span>
<span class="p_header">--- a/crypto/asymmetric_keys/public_key.c</span>
<span class="p_header">+++ b/crypto/asymmetric_keys/public_key.c</span>
<span class="p_chunk">@@ -141,7 +141,7 @@</span> <span class="p_context"> int public_key_verify_signature(const struct public_key *pkey,</span>
 	 * signature and returns that to us.
 	 */
 	ret = crypto_akcipher_verify(req);
<span class="p_del">-	if (ret == -EINPROGRESS) {</span>
<span class="p_add">+	if ((ret == -EINPROGRESS) || (ret == -EBUSY)) {</span>
 		wait_for_completion(&amp;compl.completion);
 		ret = compl.err;
 	}
<span class="p_header">diff --git a/crypto/drbg.c b/crypto/drbg.c</span>
<span class="p_header">index 8a4d98b4adba..5efc2b22a831 100644</span>
<span class="p_header">--- a/crypto/drbg.c</span>
<span class="p_header">+++ b/crypto/drbg.c</span>
<span class="p_chunk">@@ -1768,9 +1768,8 @@</span> <span class="p_context"> static int drbg_kcapi_sym_ctr(struct drbg_state *drbg,</span>
 			break;
 		case -EINPROGRESS:
 		case -EBUSY:
<span class="p_del">-			ret = wait_for_completion_interruptible(</span>
<span class="p_del">-				&amp;drbg-&gt;ctr_completion);</span>
<span class="p_del">-			if (!ret &amp;&amp; !drbg-&gt;ctr_async_err) {</span>
<span class="p_add">+			wait_for_completion(&amp;drbg-&gt;ctr_completion);</span>
<span class="p_add">+			if (!drbg-&gt;ctr_async_err) {</span>
 				reinit_completion(&amp;drbg-&gt;ctr_completion);
 				break;
 			}
<span class="p_header">diff --git a/crypto/gcm.c b/crypto/gcm.c</span>
<span class="p_header">index b7ad808be3d4..3841b5eafa7e 100644</span>
<span class="p_header">--- a/crypto/gcm.c</span>
<span class="p_header">+++ b/crypto/gcm.c</span>
<span class="p_chunk">@@ -152,10 +152,8 @@</span> <span class="p_context"> static int crypto_gcm_setkey(struct crypto_aead *aead, const u8 *key,</span>
 
 	err = crypto_skcipher_encrypt(&amp;data-&gt;req);
 	if (err == -EINPROGRESS || err == -EBUSY) {
<span class="p_del">-		err = wait_for_completion_interruptible(</span>
<span class="p_del">-			&amp;data-&gt;result.completion);</span>
<span class="p_del">-		if (!err)</span>
<span class="p_del">-			err = data-&gt;result.err;</span>
<span class="p_add">+		wait_for_completion(&amp;data-&gt;result.completion);</span>
<span class="p_add">+		err = data-&gt;result.err;</span>
 	}
 
 	if (err)
<span class="p_header">diff --git a/drivers/ata/ahci.c b/drivers/ata/ahci.c</span>
<span class="p_header">index 2fc52407306c..c69954023c2e 100644</span>
<span class="p_header">--- a/drivers/ata/ahci.c</span>
<span class="p_header">+++ b/drivers/ata/ahci.c</span>
<span class="p_chunk">@@ -1364,6 +1364,40 @@</span> <span class="p_context"> static inline void ahci_gtf_filter_workaround(struct ata_host *host)</span>
 {}
 #endif
 
<span class="p_add">+/*</span>
<span class="p_add">+ * On the Acer Aspire Switch Alpha 12, sometimes all SATA ports are detected</span>
<span class="p_add">+ * as DUMMY, or detected but eventually get a &quot;link down&quot; and never get up</span>
<span class="p_add">+ * again. When this happens, CAP.NP may hold a value of 0x00 or 0x01, and the</span>
<span class="p_add">+ * port_map may hold a value of 0x00.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * Overriding CAP.NP to 0x02 and the port_map to 0x7 will reveal all 3 ports</span>
<span class="p_add">+ * and can significantly reduce the occurrence of the problem.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * https://bugzilla.kernel.org/show_bug.cgi?id=189471</span>
<span class="p_add">+ */</span>
<span class="p_add">+static void acer_sa5_271_workaround(struct ahci_host_priv *hpriv,</span>
<span class="p_add">+				    struct pci_dev *pdev)</span>
<span class="p_add">+{</span>
<span class="p_add">+	static const struct dmi_system_id sysids[] = {</span>
<span class="p_add">+		{</span>
<span class="p_add">+			.ident = &quot;Acer Switch Alpha 12&quot;,</span>
<span class="p_add">+			.matches = {</span>
<span class="p_add">+				DMI_MATCH(DMI_SYS_VENDOR, &quot;Acer&quot;),</span>
<span class="p_add">+				DMI_MATCH(DMI_PRODUCT_NAME, &quot;Switch SA5-271&quot;)</span>
<span class="p_add">+			},</span>
<span class="p_add">+		},</span>
<span class="p_add">+		{ }</span>
<span class="p_add">+	};</span>
<span class="p_add">+</span>
<span class="p_add">+	if (dmi_check_system(sysids)) {</span>
<span class="p_add">+		dev_info(&amp;pdev-&gt;dev, &quot;enabling Acer Switch Alpha 12 workaround\n&quot;);</span>
<span class="p_add">+		if ((hpriv-&gt;saved_cap &amp; 0xC734FF00) == 0xC734FF00) {</span>
<span class="p_add">+			hpriv-&gt;port_map = 0x7;</span>
<span class="p_add">+			hpriv-&gt;cap = 0xC734FF02;</span>
<span class="p_add">+		}</span>
<span class="p_add">+	}</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 #ifdef CONFIG_ARM64
 /*
  * Due to ERRATA#22536, ThunderX needs to handle HOST_IRQ_STAT differently.
<span class="p_chunk">@@ -1636,6 +1670,10 @@</span> <span class="p_context"> static int ahci_init_one(struct pci_dev *pdev, const struct pci_device_id *ent)</span>
 			 &quot;online status unreliable, applying workaround\n&quot;);
 	}
 
<span class="p_add">+</span>
<span class="p_add">+	/* Acer SA5-271 workaround modifies private_data */</span>
<span class="p_add">+	acer_sa5_271_workaround(hpriv, pdev);</span>
<span class="p_add">+</span>
 	/* CAP.NP sometimes indicate the index of the last enabled
 	 * port, at other times, that of the last possible port, so
 	 * determining the maximum port number requires looking at
<span class="p_header">diff --git a/drivers/ata/sata_mv.c b/drivers/ata/sata_mv.c</span>
<span class="p_header">index 00ce26d0c047..6eed4a72d328 100644</span>
<span class="p_header">--- a/drivers/ata/sata_mv.c</span>
<span class="p_header">+++ b/drivers/ata/sata_mv.c</span>
<span class="p_chunk">@@ -4067,7 +4067,6 @@</span> <span class="p_context"> static int mv_platform_probe(struct platform_device *pdev)</span>
 	struct ata_host *host;
 	struct mv_host_priv *hpriv;
 	struct resource *res;
<span class="p_del">-	void __iomem *mmio;</span>
 	int n_ports = 0, irq = 0;
 	int rc;
 	int port;
<span class="p_chunk">@@ -4086,9 +4085,8 @@</span> <span class="p_context"> static int mv_platform_probe(struct platform_device *pdev)</span>
 	 * Get the register base first
 	 */
 	res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
<span class="p_del">-	mmio = devm_ioremap_resource(&amp;pdev-&gt;dev, res);</span>
<span class="p_del">-	if (IS_ERR(mmio))</span>
<span class="p_del">-		return PTR_ERR(mmio);</span>
<span class="p_add">+	if (res == NULL)</span>
<span class="p_add">+		return -EINVAL;</span>
 
 	/* allocate host */
 	if (pdev-&gt;dev.of_node) {
<span class="p_chunk">@@ -4132,7 +4130,12 @@</span> <span class="p_context"> static int mv_platform_probe(struct platform_device *pdev)</span>
 	hpriv-&gt;board_idx = chip_soc;
 
 	host-&gt;iomap = NULL;
<span class="p_del">-	hpriv-&gt;base = mmio - SATAHC0_REG_BASE;</span>
<span class="p_add">+	hpriv-&gt;base = devm_ioremap(&amp;pdev-&gt;dev, res-&gt;start,</span>
<span class="p_add">+				   resource_size(res));</span>
<span class="p_add">+	if (!hpriv-&gt;base)</span>
<span class="p_add">+		return -ENOMEM;</span>
<span class="p_add">+</span>
<span class="p_add">+	hpriv-&gt;base -= SATAHC0_REG_BASE;</span>
 
 	hpriv-&gt;clk = clk_get(&amp;pdev-&gt;dev, NULL);
 	if (IS_ERR(hpriv-&gt;clk))
<span class="p_header">diff --git a/drivers/char/mem.c b/drivers/char/mem.c</span>
<span class="p_header">index 6e0cbe092220..593a8818aca9 100644</span>
<span class="p_header">--- a/drivers/char/mem.c</span>
<span class="p_header">+++ b/drivers/char/mem.c</span>
<span class="p_chunk">@@ -343,7 +343,7 @@</span> <span class="p_context"> static int mmap_mem(struct file *file, struct vm_area_struct *vma)</span>
 	phys_addr_t offset = (phys_addr_t)vma-&gt;vm_pgoff &lt;&lt; PAGE_SHIFT;
 
 	/* It&#39;s illegal to wrap around the end of the physical address space. */
<span class="p_del">-	if (offset + (phys_addr_t)size &lt; offset)</span>
<span class="p_add">+	if (offset + (phys_addr_t)size - 1 &lt; offset)</span>
 		return -EINVAL;
 
 	if (!valid_mmap_phys_addr_range(vma-&gt;vm_pgoff, size))
<span class="p_header">diff --git a/drivers/char/random.c b/drivers/char/random.c</span>
<span class="p_header">index 0ab024918907..2291e6224ed3 100644</span>
<span class="p_header">--- a/drivers/char/random.c</span>
<span class="p_header">+++ b/drivers/char/random.c</span>
<span class="p_chunk">@@ -1,6 +1,9 @@</span> <span class="p_context"></span>
 /*
  * random.c -- A strong random number generator
  *
<span class="p_add">+ * Copyright (C) 2017 Jason A. Donenfeld &lt;Jason@zx2c4.com&gt;. All</span>
<span class="p_add">+ * Rights Reserved.</span>
<span class="p_add">+ *</span>
  * Copyright Matt Mackall &lt;mpm@selenic.com&gt;, 2003, 2004, 2005
  *
  * Copyright Theodore Ts&#39;o, 1994, 1995, 1996, 1997, 1998, 1999.  All
<span class="p_chunk">@@ -762,6 +765,8 @@</span> <span class="p_context"> static DECLARE_WAIT_QUEUE_HEAD(crng_init_wait);</span>
 static struct crng_state **crng_node_pool __read_mostly;
 #endif
 
<span class="p_add">+static void invalidate_batched_entropy(void);</span>
<span class="p_add">+</span>
 static void crng_initialize(struct crng_state *crng)
 {
 	int		i;
<span class="p_chunk">@@ -799,6 +804,7 @@</span> <span class="p_context"> static int crng_fast_load(const char *cp, size_t len)</span>
 		cp++; crng_init_cnt++; len--;
 	}
 	if (crng_init_cnt &gt;= CRNG_INIT_CNT_THRESH) {
<span class="p_add">+		invalidate_batched_entropy();</span>
 		crng_init = 1;
 		wake_up_interruptible(&amp;crng_init_wait);
 		pr_notice(&quot;random: fast init done\n&quot;);
<span class="p_chunk">@@ -836,6 +842,7 @@</span> <span class="p_context"> static void crng_reseed(struct crng_state *crng, struct entropy_store *r)</span>
 	memzero_explicit(&amp;buf, sizeof(buf));
 	crng-&gt;init_time = jiffies;
 	if (crng == &amp;primary_crng &amp;&amp; crng_init &lt; 2) {
<span class="p_add">+		invalidate_batched_entropy();</span>
 		crng_init = 2;
 		process_random_ready_list();
 		wake_up_interruptible(&amp;crng_init_wait);
<span class="p_chunk">@@ -2019,6 +2026,7 @@</span> <span class="p_context"> struct batched_entropy {</span>
 	};
 	unsigned int position;
 };
<span class="p_add">+static rwlock_t batched_entropy_reset_lock = __RW_LOCK_UNLOCKED(batched_entropy_reset_lock);</span>
 
 /*
  * Get a random word for internal kernel use only. The quality of the random
<span class="p_chunk">@@ -2029,6 +2037,8 @@</span> <span class="p_context"> static DEFINE_PER_CPU(struct batched_entropy, batched_entropy_u64);</span>
 u64 get_random_u64(void)
 {
 	u64 ret;
<span class="p_add">+	bool use_lock = crng_init &lt; 2;</span>
<span class="p_add">+	unsigned long flags;</span>
 	struct batched_entropy *batch;
 
 #if BITS_PER_LONG == 64
<span class="p_chunk">@@ -2041,11 +2051,15 @@</span> <span class="p_context"> u64 get_random_u64(void)</span>
 #endif
 
 	batch = &amp;get_cpu_var(batched_entropy_u64);
<span class="p_add">+	if (use_lock)</span>
<span class="p_add">+		read_lock_irqsave(&amp;batched_entropy_reset_lock, flags);</span>
 	if (batch-&gt;position % ARRAY_SIZE(batch-&gt;entropy_u64) == 0) {
 		extract_crng((u8 *)batch-&gt;entropy_u64);
 		batch-&gt;position = 0;
 	}
 	ret = batch-&gt;entropy_u64[batch-&gt;position++];
<span class="p_add">+	if (use_lock)</span>
<span class="p_add">+		read_unlock_irqrestore(&amp;batched_entropy_reset_lock, flags);</span>
 	put_cpu_var(batched_entropy_u64);
 	return ret;
 }
<span class="p_chunk">@@ -2055,22 +2069,45 @@</span> <span class="p_context"> static DEFINE_PER_CPU(struct batched_entropy, batched_entropy_u32);</span>
 u32 get_random_u32(void)
 {
 	u32 ret;
<span class="p_add">+	bool use_lock = crng_init &lt; 2;</span>
<span class="p_add">+	unsigned long flags;</span>
 	struct batched_entropy *batch;
 
 	if (arch_get_random_int(&amp;ret))
 		return ret;
 
 	batch = &amp;get_cpu_var(batched_entropy_u32);
<span class="p_add">+	if (use_lock)</span>
<span class="p_add">+		read_lock_irqsave(&amp;batched_entropy_reset_lock, flags);</span>
 	if (batch-&gt;position % ARRAY_SIZE(batch-&gt;entropy_u32) == 0) {
 		extract_crng((u8 *)batch-&gt;entropy_u32);
 		batch-&gt;position = 0;
 	}
 	ret = batch-&gt;entropy_u32[batch-&gt;position++];
<span class="p_add">+	if (use_lock)</span>
<span class="p_add">+		read_unlock_irqrestore(&amp;batched_entropy_reset_lock, flags);</span>
 	put_cpu_var(batched_entropy_u32);
 	return ret;
 }
 EXPORT_SYMBOL(get_random_u32);
 
<span class="p_add">+/* It&#39;s important to invalidate all potential batched entropy that might</span>
<span class="p_add">+ * be stored before the crng is initialized, which we can do lazily by</span>
<span class="p_add">+ * simply resetting the counter to zero so that it&#39;s re-extracted on the</span>
<span class="p_add">+ * next usage. */</span>
<span class="p_add">+static void invalidate_batched_entropy(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	int cpu;</span>
<span class="p_add">+	unsigned long flags;</span>
<span class="p_add">+</span>
<span class="p_add">+	write_lock_irqsave(&amp;batched_entropy_reset_lock, flags);</span>
<span class="p_add">+	for_each_possible_cpu (cpu) {</span>
<span class="p_add">+		per_cpu_ptr(&amp;batched_entropy_u32, cpu)-&gt;position = 0;</span>
<span class="p_add">+		per_cpu_ptr(&amp;batched_entropy_u64, cpu)-&gt;position = 0;</span>
<span class="p_add">+	}</span>
<span class="p_add">+	write_unlock_irqrestore(&amp;batched_entropy_reset_lock, flags);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 /**
  * randomize_page - Generate a random, page aligned address
  * @start:	The smallest acceptable address the caller will take.
<span class="p_header">diff --git a/drivers/cpufreq/cpufreq.c b/drivers/cpufreq/cpufreq.c</span>
<span class="p_header">index 0e3f6496524d..26b643d57847 100644</span>
<span class="p_header">--- a/drivers/cpufreq/cpufreq.c</span>
<span class="p_header">+++ b/drivers/cpufreq/cpufreq.c</span>
<span class="p_chunk">@@ -2468,6 +2468,7 @@</span> <span class="p_context"> int cpufreq_register_driver(struct cpufreq_driver *driver_data)</span>
 	if (!(cpufreq_driver-&gt;flags &amp; CPUFREQ_STICKY) &amp;&amp;
 	    list_empty(&amp;cpufreq_policy_list)) {
 		/* if all -&gt;init() calls failed, unregister */
<span class="p_add">+		ret = -ENODEV;</span>
 		pr_debug(&quot;%s: No CPU initialized for driver %s\n&quot;, __func__,
 			 driver_data-&gt;name);
 		goto err_if_unreg;
<span class="p_header">diff --git a/drivers/dma/ep93xx_dma.c b/drivers/dma/ep93xx_dma.c</span>
<span class="p_header">index d37e8dda8079..ec240592f5c8 100644</span>
<span class="p_header">--- a/drivers/dma/ep93xx_dma.c</span>
<span class="p_header">+++ b/drivers/dma/ep93xx_dma.c</span>
<span class="p_chunk">@@ -201,6 +201,7 @@</span> <span class="p_context"> struct ep93xx_dma_engine {</span>
 	struct dma_device	dma_dev;
 	bool			m2m;
 	int			(*hw_setup)(struct ep93xx_dma_chan *);
<span class="p_add">+	void			(*hw_synchronize)(struct ep93xx_dma_chan *);</span>
 	void			(*hw_shutdown)(struct ep93xx_dma_chan *);
 	void			(*hw_submit)(struct ep93xx_dma_chan *);
 	int			(*hw_interrupt)(struct ep93xx_dma_chan *);
<span class="p_chunk">@@ -323,6 +324,8 @@</span> <span class="p_context"> static int m2p_hw_setup(struct ep93xx_dma_chan *edmac)</span>
 		| M2P_CONTROL_ENABLE;
 	m2p_set_control(edmac, control);
 
<span class="p_add">+	edmac-&gt;buffer = 0;</span>
<span class="p_add">+</span>
 	return 0;
 }
 
<span class="p_chunk">@@ -331,21 +334,27 @@</span> <span class="p_context"> static inline u32 m2p_channel_state(struct ep93xx_dma_chan *edmac)</span>
 	return (readl(edmac-&gt;regs + M2P_STATUS) &gt;&gt; 4) &amp; 0x3;
 }
 
<span class="p_del">-static void m2p_hw_shutdown(struct ep93xx_dma_chan *edmac)</span>
<span class="p_add">+static void m2p_hw_synchronize(struct ep93xx_dma_chan *edmac)</span>
 {
<span class="p_add">+	unsigned long flags;</span>
 	u32 control;
 
<span class="p_add">+	spin_lock_irqsave(&amp;edmac-&gt;lock, flags);</span>
 	control = readl(edmac-&gt;regs + M2P_CONTROL);
 	control &amp;= ~(M2P_CONTROL_STALLINT | M2P_CONTROL_NFBINT);
 	m2p_set_control(edmac, control);
<span class="p_add">+	spin_unlock_irqrestore(&amp;edmac-&gt;lock, flags);</span>
 
 	while (m2p_channel_state(edmac) &gt;= M2P_STATE_ON)
<span class="p_del">-		cpu_relax();</span>
<span class="p_add">+		schedule();</span>
<span class="p_add">+}</span>
 
<span class="p_add">+static void m2p_hw_shutdown(struct ep93xx_dma_chan *edmac)</span>
<span class="p_add">+{</span>
 	m2p_set_control(edmac, 0);
 
<span class="p_del">-	while (m2p_channel_state(edmac) == M2P_STATE_STALL)</span>
<span class="p_del">-		cpu_relax();</span>
<span class="p_add">+	while (m2p_channel_state(edmac) != M2P_STATE_IDLE)</span>
<span class="p_add">+		dev_warn(chan2dev(edmac), &quot;M2P: Not yet IDLE\n&quot;);</span>
 }
 
 static void m2p_fill_desc(struct ep93xx_dma_chan *edmac)
<span class="p_chunk">@@ -1161,6 +1170,26 @@</span> <span class="p_context"> ep93xx_dma_prep_dma_cyclic(struct dma_chan *chan, dma_addr_t dma_addr,</span>
 }
 
 /**
<span class="p_add">+ * ep93xx_dma_synchronize - Synchronizes the termination of transfers to the</span>
<span class="p_add">+ * current context.</span>
<span class="p_add">+ * @chan: channel</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * Synchronizes the DMA channel termination to the current context. When this</span>
<span class="p_add">+ * function returns it is guaranteed that all transfers for previously issued</span>
<span class="p_add">+ * descriptors have stopped and and it is safe to free the memory associated</span>
<span class="p_add">+ * with them. Furthermore it is guaranteed that all complete callback functions</span>
<span class="p_add">+ * for a previously submitted descriptor have finished running and it is safe to</span>
<span class="p_add">+ * free resources accessed from within the complete callbacks.</span>
<span class="p_add">+ */</span>
<span class="p_add">+static void ep93xx_dma_synchronize(struct dma_chan *chan)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct ep93xx_dma_chan *edmac = to_ep93xx_dma_chan(chan);</span>
<span class="p_add">+</span>
<span class="p_add">+	if (edmac-&gt;edma-&gt;hw_synchronize)</span>
<span class="p_add">+		edmac-&gt;edma-&gt;hw_synchronize(edmac);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+/**</span>
  * ep93xx_dma_terminate_all - terminate all transactions
  * @chan: channel
  *
<span class="p_chunk">@@ -1323,6 +1352,7 @@</span> <span class="p_context"> static int __init ep93xx_dma_probe(struct platform_device *pdev)</span>
 	dma_dev-&gt;device_prep_slave_sg = ep93xx_dma_prep_slave_sg;
 	dma_dev-&gt;device_prep_dma_cyclic = ep93xx_dma_prep_dma_cyclic;
 	dma_dev-&gt;device_config = ep93xx_dma_slave_config;
<span class="p_add">+	dma_dev-&gt;device_synchronize = ep93xx_dma_synchronize;</span>
 	dma_dev-&gt;device_terminate_all = ep93xx_dma_terminate_all;
 	dma_dev-&gt;device_issue_pending = ep93xx_dma_issue_pending;
 	dma_dev-&gt;device_tx_status = ep93xx_dma_tx_status;
<span class="p_chunk">@@ -1340,6 +1370,7 @@</span> <span class="p_context"> static int __init ep93xx_dma_probe(struct platform_device *pdev)</span>
 	} else {
 		dma_cap_set(DMA_PRIVATE, dma_dev-&gt;cap_mask);
 
<span class="p_add">+		edma-&gt;hw_synchronize = m2p_hw_synchronize;</span>
 		edma-&gt;hw_setup = m2p_hw_setup;
 		edma-&gt;hw_shutdown = m2p_hw_shutdown;
 		edma-&gt;hw_submit = m2p_hw_submit;
<span class="p_header">diff --git a/drivers/dma/mv_xor_v2.c b/drivers/dma/mv_xor_v2.c</span>
<span class="p_header">index a28a01fcba67..f3e211f8f6c5 100644</span>
<span class="p_header">--- a/drivers/dma/mv_xor_v2.c</span>
<span class="p_header">+++ b/drivers/dma/mv_xor_v2.c</span>
<span class="p_chunk">@@ -161,6 +161,7 @@</span> <span class="p_context"> struct mv_xor_v2_device {</span>
 	struct mv_xor_v2_sw_desc *sw_desq;
 	int desc_size;
 	unsigned int npendings;
<span class="p_add">+	unsigned int hw_queue_idx;</span>
 };
 
 /**
<span class="p_chunk">@@ -214,18 +215,6 @@</span> <span class="p_context"> static void mv_xor_v2_set_data_buffers(struct mv_xor_v2_device *xor_dev,</span>
 }
 
 /*
<span class="p_del">- * Return the next available index in the DESQ.</span>
<span class="p_del">- */</span>
<span class="p_del">-static int mv_xor_v2_get_desq_write_ptr(struct mv_xor_v2_device *xor_dev)</span>
<span class="p_del">-{</span>
<span class="p_del">-	/* read the index for the next available descriptor in the DESQ */</span>
<span class="p_del">-	u32 reg = readl(xor_dev-&gt;dma_base + MV_XOR_V2_DMA_DESQ_ALLOC_OFF);</span>
<span class="p_del">-</span>
<span class="p_del">-	return ((reg &gt;&gt; MV_XOR_V2_DMA_DESQ_ALLOC_WRPTR_SHIFT)</span>
<span class="p_del">-		&amp; MV_XOR_V2_DMA_DESQ_ALLOC_WRPTR_MASK);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-/*</span>
  * notify the engine of new descriptors, and update the available index.
  */
 static void mv_xor_v2_add_desc_to_desq(struct mv_xor_v2_device *xor_dev,
<span class="p_chunk">@@ -257,22 +246,6 @@</span> <span class="p_context"> static int mv_xor_v2_set_desc_size(struct mv_xor_v2_device *xor_dev)</span>
 	return MV_XOR_V2_EXT_DESC_SIZE;
 }
 
<span class="p_del">-/*</span>
<span class="p_del">- * Set the IMSG threshold</span>
<span class="p_del">- */</span>
<span class="p_del">-static inline</span>
<span class="p_del">-void mv_xor_v2_set_imsg_thrd(struct mv_xor_v2_device *xor_dev, int thrd_val)</span>
<span class="p_del">-{</span>
<span class="p_del">-	u32 reg;</span>
<span class="p_del">-</span>
<span class="p_del">-	reg = readl(xor_dev-&gt;dma_base + MV_XOR_V2_DMA_IMSG_THRD_OFF);</span>
<span class="p_del">-</span>
<span class="p_del">-	reg &amp;= (~MV_XOR_V2_DMA_IMSG_THRD_MASK &lt;&lt; MV_XOR_V2_DMA_IMSG_THRD_SHIFT);</span>
<span class="p_del">-	reg |= (thrd_val &lt;&lt; MV_XOR_V2_DMA_IMSG_THRD_SHIFT);</span>
<span class="p_del">-</span>
<span class="p_del">-	writel(reg, xor_dev-&gt;dma_base + MV_XOR_V2_DMA_IMSG_THRD_OFF);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
 static irqreturn_t mv_xor_v2_interrupt_handler(int irq, void *data)
 {
 	struct mv_xor_v2_device *xor_dev = data;
<span class="p_chunk">@@ -288,12 +261,6 @@</span> <span class="p_context"> static irqreturn_t mv_xor_v2_interrupt_handler(int irq, void *data)</span>
 	if (!ndescs)
 		return IRQ_NONE;
 
<span class="p_del">-	/*</span>
<span class="p_del">-	 * Update IMSG threshold, to disable new IMSG interrupts until</span>
<span class="p_del">-	 * end of the tasklet</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	mv_xor_v2_set_imsg_thrd(xor_dev, MV_XOR_V2_DESC_NUM);</span>
<span class="p_del">-</span>
 	/* schedule a tasklet to handle descriptors callbacks */
 	tasklet_schedule(&amp;xor_dev-&gt;irq_tasklet);
 
<span class="p_chunk">@@ -306,7 +273,6 @@</span> <span class="p_context"> static irqreturn_t mv_xor_v2_interrupt_handler(int irq, void *data)</span>
 static dma_cookie_t
 mv_xor_v2_tx_submit(struct dma_async_tx_descriptor *tx)
 {
<span class="p_del">-	int desq_ptr;</span>
 	void *dest_hw_desc;
 	dma_cookie_t cookie;
 	struct mv_xor_v2_sw_desc *sw_desc =
<span class="p_chunk">@@ -322,15 +288,15 @@</span> <span class="p_context"> mv_xor_v2_tx_submit(struct dma_async_tx_descriptor *tx)</span>
 	spin_lock_bh(&amp;xor_dev-&gt;lock);
 	cookie = dma_cookie_assign(tx);
 
<span class="p_del">-	/* get the next available slot in the DESQ */</span>
<span class="p_del">-	desq_ptr = mv_xor_v2_get_desq_write_ptr(xor_dev);</span>
<span class="p_del">-</span>
 	/* copy the HW descriptor from the SW descriptor to the DESQ */
<span class="p_del">-	dest_hw_desc = xor_dev-&gt;hw_desq_virt + desq_ptr;</span>
<span class="p_add">+	dest_hw_desc = xor_dev-&gt;hw_desq_virt + xor_dev-&gt;hw_queue_idx;</span>
 
 	memcpy(dest_hw_desc, &amp;sw_desc-&gt;hw_desc, xor_dev-&gt;desc_size);
 
 	xor_dev-&gt;npendings++;
<span class="p_add">+	xor_dev-&gt;hw_queue_idx++;</span>
<span class="p_add">+	if (xor_dev-&gt;hw_queue_idx &gt;= MV_XOR_V2_DESC_NUM)</span>
<span class="p_add">+		xor_dev-&gt;hw_queue_idx = 0;</span>
 
 	spin_unlock_bh(&amp;xor_dev-&gt;lock);
 
<span class="p_chunk">@@ -344,6 +310,7 @@</span> <span class="p_context"> static struct mv_xor_v2_sw_desc	*</span>
 mv_xor_v2_prep_sw_desc(struct mv_xor_v2_device *xor_dev)
 {
 	struct mv_xor_v2_sw_desc *sw_desc;
<span class="p_add">+	bool found = false;</span>
 
 	/* Lock the channel */
 	spin_lock_bh(&amp;xor_dev-&gt;lock);
<span class="p_chunk">@@ -355,19 +322,23 @@</span> <span class="p_context"> mv_xor_v2_prep_sw_desc(struct mv_xor_v2_device *xor_dev)</span>
 		return NULL;
 	}
 
<span class="p_del">-	/* get a free SW descriptor from the SW DESQ */</span>
<span class="p_del">-	sw_desc = list_first_entry(&amp;xor_dev-&gt;free_sw_desc,</span>
<span class="p_del">-				   struct mv_xor_v2_sw_desc, free_list);</span>
<span class="p_add">+	list_for_each_entry(sw_desc, &amp;xor_dev-&gt;free_sw_desc, free_list) {</span>
<span class="p_add">+		if (async_tx_test_ack(&amp;sw_desc-&gt;async_tx)) {</span>
<span class="p_add">+			found = true;</span>
<span class="p_add">+			break;</span>
<span class="p_add">+		}</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	if (!found) {</span>
<span class="p_add">+		spin_unlock_bh(&amp;xor_dev-&gt;lock);</span>
<span class="p_add">+		return NULL;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
 	list_del(&amp;sw_desc-&gt;free_list);
 
 	/* Release the channel */
 	spin_unlock_bh(&amp;xor_dev-&gt;lock);
 
<span class="p_del">-	/* set the async tx descriptor */</span>
<span class="p_del">-	dma_async_tx_descriptor_init(&amp;sw_desc-&gt;async_tx, &amp;xor_dev-&gt;dmachan);</span>
<span class="p_del">-	sw_desc-&gt;async_tx.tx_submit = mv_xor_v2_tx_submit;</span>
<span class="p_del">-	async_tx_ack(&amp;sw_desc-&gt;async_tx);</span>
<span class="p_del">-</span>
 	return sw_desc;
 }
 
<span class="p_chunk">@@ -389,6 +360,8 @@</span> <span class="p_context"> mv_xor_v2_prep_dma_memcpy(struct dma_chan *chan, dma_addr_t dest,</span>
 		__func__, len, &amp;src, &amp;dest, flags);
 
 	sw_desc = mv_xor_v2_prep_sw_desc(xor_dev);
<span class="p_add">+	if (!sw_desc)</span>
<span class="p_add">+		return NULL;</span>
 
 	sw_desc-&gt;async_tx.flags = flags;
 
<span class="p_chunk">@@ -443,6 +416,8 @@</span> <span class="p_context"> mv_xor_v2_prep_dma_xor(struct dma_chan *chan, dma_addr_t dest, dma_addr_t *src,</span>
 		__func__, src_cnt, len, &amp;dest, flags);
 
 	sw_desc = mv_xor_v2_prep_sw_desc(xor_dev);
<span class="p_add">+	if (!sw_desc)</span>
<span class="p_add">+		return NULL;</span>
 
 	sw_desc-&gt;async_tx.flags = flags;
 
<span class="p_chunk">@@ -491,6 +466,8 @@</span> <span class="p_context"> mv_xor_v2_prep_dma_interrupt(struct dma_chan *chan, unsigned long flags)</span>
 		container_of(chan, struct mv_xor_v2_device, dmachan);
 
 	sw_desc = mv_xor_v2_prep_sw_desc(xor_dev);
<span class="p_add">+	if (!sw_desc)</span>
<span class="p_add">+		return NULL;</span>
 
 	/* set the HW descriptor */
 	hw_descriptor = &amp;sw_desc-&gt;hw_desc;
<span class="p_chunk">@@ -554,7 +531,6 @@</span> <span class="p_context"> static void mv_xor_v2_tasklet(unsigned long data)</span>
 {
 	struct mv_xor_v2_device *xor_dev = (struct mv_xor_v2_device *) data;
 	int pending_ptr, num_of_pending, i;
<span class="p_del">-	struct mv_xor_v2_descriptor *next_pending_hw_desc = NULL;</span>
 	struct mv_xor_v2_sw_desc *next_pending_sw_desc = NULL;
 
 	dev_dbg(xor_dev-&gt;dmadev.dev, &quot;%s %d\n&quot;, __func__, __LINE__);
<span class="p_chunk">@@ -562,17 +538,10 @@</span> <span class="p_context"> static void mv_xor_v2_tasklet(unsigned long data)</span>
 	/* get the pending descriptors parameters */
 	num_of_pending = mv_xor_v2_get_pending_params(xor_dev, &amp;pending_ptr);
 
<span class="p_del">-	/* next HW descriptor */</span>
<span class="p_del">-	next_pending_hw_desc = xor_dev-&gt;hw_desq_virt + pending_ptr;</span>
<span class="p_del">-</span>
 	/* loop over free descriptors */
 	for (i = 0; i &lt; num_of_pending; i++) {
<span class="p_del">-</span>
<span class="p_del">-		if (pending_ptr &gt; MV_XOR_V2_DESC_NUM)</span>
<span class="p_del">-			pending_ptr = 0;</span>
<span class="p_del">-</span>
<span class="p_del">-		if (next_pending_sw_desc != NULL)</span>
<span class="p_del">-			next_pending_hw_desc++;</span>
<span class="p_add">+		struct mv_xor_v2_descriptor *next_pending_hw_desc =</span>
<span class="p_add">+			xor_dev-&gt;hw_desq_virt + pending_ptr;</span>
 
 		/* get the SW descriptor related to the HW descriptor */
 		next_pending_sw_desc =
<span class="p_chunk">@@ -608,15 +577,14 @@</span> <span class="p_context"> static void mv_xor_v2_tasklet(unsigned long data)</span>
 
 		/* increment the next descriptor */
 		pending_ptr++;
<span class="p_add">+		if (pending_ptr &gt;= MV_XOR_V2_DESC_NUM)</span>
<span class="p_add">+			pending_ptr = 0;</span>
 	}
 
 	if (num_of_pending != 0) {
 		/* free the descriptores */
 		mv_xor_v2_free_desc_from_desq(xor_dev, num_of_pending);
 	}
<span class="p_del">-</span>
<span class="p_del">-	/* Update IMSG threshold, to enable new IMSG interrupts */</span>
<span class="p_del">-	mv_xor_v2_set_imsg_thrd(xor_dev, 0);</span>
 }
 
 /*
<span class="p_chunk">@@ -648,9 +616,6 @@</span> <span class="p_context"> static int mv_xor_v2_descq_init(struct mv_xor_v2_device *xor_dev)</span>
 	writel((xor_dev-&gt;hw_desq &amp; 0xFFFF00000000) &gt;&gt; 32,
 	       xor_dev-&gt;dma_base + MV_XOR_V2_DMA_DESQ_BAHR_OFF);
 
<span class="p_del">-	/* enable the DMA engine */</span>
<span class="p_del">-	writel(0, xor_dev-&gt;dma_base + MV_XOR_V2_DMA_DESQ_STOP_OFF);</span>
<span class="p_del">-</span>
 	/*
 	 * This is a temporary solution, until we activate the
 	 * SMMU. Set the attributes for reading &amp; writing data buffers
<span class="p_chunk">@@ -694,6 +659,9 @@</span> <span class="p_context"> static int mv_xor_v2_descq_init(struct mv_xor_v2_device *xor_dev)</span>
 	reg |= MV_XOR_V2_GLOB_PAUSE_AXI_TIME_DIS_VAL;
 	writel(reg, xor_dev-&gt;glob_base + MV_XOR_V2_GLOB_PAUSE);
 
<span class="p_add">+	/* enable the DMA engine */</span>
<span class="p_add">+	writel(0, xor_dev-&gt;dma_base + MV_XOR_V2_DMA_DESQ_STOP_OFF);</span>
<span class="p_add">+</span>
 	return 0;
 }
 
<span class="p_chunk">@@ -725,6 +693,10 @@</span> <span class="p_context"> static int mv_xor_v2_probe(struct platform_device *pdev)</span>
 
 	platform_set_drvdata(pdev, xor_dev);
 
<span class="p_add">+	ret = dma_set_mask_and_coherent(&amp;pdev-&gt;dev, DMA_BIT_MASK(40));</span>
<span class="p_add">+	if (ret)</span>
<span class="p_add">+		return ret;</span>
<span class="p_add">+</span>
 	xor_dev-&gt;clk = devm_clk_get(&amp;pdev-&gt;dev, NULL);
 	if (IS_ERR(xor_dev-&gt;clk) &amp;&amp; PTR_ERR(xor_dev-&gt;clk) == -EPROBE_DEFER)
 		return -EPROBE_DEFER;
<span class="p_chunk">@@ -785,8 +757,15 @@</span> <span class="p_context"> static int mv_xor_v2_probe(struct platform_device *pdev)</span>
 
 	/* add all SW descriptors to the free list */
 	for (i = 0; i &lt; MV_XOR_V2_DESC_NUM; i++) {
<span class="p_del">-		xor_dev-&gt;sw_desq[i].idx = i;</span>
<span class="p_del">-		list_add(&amp;xor_dev-&gt;sw_desq[i].free_list,</span>
<span class="p_add">+		struct mv_xor_v2_sw_desc *sw_desc =</span>
<span class="p_add">+			xor_dev-&gt;sw_desq + i;</span>
<span class="p_add">+		sw_desc-&gt;idx = i;</span>
<span class="p_add">+		dma_async_tx_descriptor_init(&amp;sw_desc-&gt;async_tx,</span>
<span class="p_add">+					     &amp;xor_dev-&gt;dmachan);</span>
<span class="p_add">+		sw_desc-&gt;async_tx.tx_submit = mv_xor_v2_tx_submit;</span>
<span class="p_add">+		async_tx_ack(&amp;sw_desc-&gt;async_tx);</span>
<span class="p_add">+</span>
<span class="p_add">+		list_add(&amp;sw_desc-&gt;free_list,</span>
 			 &amp;xor_dev-&gt;free_sw_desc);
 	}
 
<span class="p_header">diff --git a/drivers/dma/sh/usb-dmac.c b/drivers/dma/sh/usb-dmac.c</span>
<span class="p_header">index 72c649713ace..31a145154e9f 100644</span>
<span class="p_header">--- a/drivers/dma/sh/usb-dmac.c</span>
<span class="p_header">+++ b/drivers/dma/sh/usb-dmac.c</span>
<span class="p_chunk">@@ -117,7 +117,7 @@</span> <span class="p_context"> struct usb_dmac {</span>
 #define USB_DMASWR			0x0008
 #define USB_DMASWR_SWR			(1 &lt;&lt; 0)
 #define USB_DMAOR			0x0060
<span class="p_del">-#define USB_DMAOR_AE			(1 &lt;&lt; 2)</span>
<span class="p_add">+#define USB_DMAOR_AE			(1 &lt;&lt; 1)</span>
 #define USB_DMAOR_DME			(1 &lt;&lt; 0)
 
 #define USB_DMASAR			0x0000
<span class="p_header">diff --git a/drivers/gpu/drm/amd/amdgpu/ci_dpm.c b/drivers/gpu/drm/amd/amdgpu/ci_dpm.c</span>
<span class="p_header">index f97ecb49972e..167f029f5fad 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/amd/amdgpu/ci_dpm.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/amd/amdgpu/ci_dpm.c</span>
<span class="p_chunk">@@ -906,6 +906,12 @@</span> <span class="p_context"> static bool ci_dpm_vblank_too_short(struct amdgpu_device *adev)</span>
 	u32 vblank_time = amdgpu_dpm_get_vblank_time(adev);
 	u32 switch_limit = adev-&gt;mc.vram_type == AMDGPU_VRAM_TYPE_GDDR5 ? 450 : 300;
 
<span class="p_add">+	/* disable mclk switching if the refresh is &gt;120Hz, even if the</span>
<span class="p_add">+	 * blanking period would allow it</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	if (amdgpu_dpm_get_vrefresh(adev) &gt; 120)</span>
<span class="p_add">+		return true;</span>
<span class="p_add">+</span>
 	if (vblank_time &lt; switch_limit)
 		return true;
 	else
<span class="p_header">diff --git a/drivers/gpu/drm/drm_drv.c b/drivers/gpu/drm/drm_drv.c</span>
<span class="p_header">index b5c6bb46a425..37b8ad3e30d8 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/drm_drv.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/drm_drv.c</span>
<span class="p_chunk">@@ -358,7 +358,12 @@</span> <span class="p_context"> EXPORT_SYMBOL(drm_put_dev);</span>
 void drm_unplug_dev(struct drm_device *dev)
 {
 	/* for a USB device */
<span class="p_del">-	drm_dev_unregister(dev);</span>
<span class="p_add">+	if (drm_core_check_feature(dev, DRIVER_MODESET))</span>
<span class="p_add">+		drm_modeset_unregister_all(dev);</span>
<span class="p_add">+</span>
<span class="p_add">+	drm_minor_unregister(dev, DRM_MINOR_PRIMARY);</span>
<span class="p_add">+	drm_minor_unregister(dev, DRM_MINOR_RENDER);</span>
<span class="p_add">+	drm_minor_unregister(dev, DRM_MINOR_CONTROL);</span>
 
 	mutex_lock(&amp;drm_global_mutex);
 
<span class="p_header">diff --git a/drivers/gpu/drm/i915/i915_drv.c b/drivers/gpu/drm/i915/i915_drv.c</span>
<span class="p_header">index 5c089b3c2a7e..66dbb3c4c6d8 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/i915/i915_drv.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/i915/i915_drv.c</span>
<span class="p_chunk">@@ -565,9 +565,7 @@</span> <span class="p_context"> static int i915_load_modeset_init(struct drm_device *dev)</span>
 	if (i915_inject_load_failure())
 		return -ENODEV;
 
<span class="p_del">-	ret = intel_bios_init(dev_priv);</span>
<span class="p_del">-	if (ret)</span>
<span class="p_del">-		DRM_INFO(&quot;failed to find VBIOS tables\n&quot;);</span>
<span class="p_add">+	intel_bios_init(dev_priv);</span>
 
 	/* If we have &gt; 1 VGA cards, then we need to arbitrate access
 	 * to the common VGA resources.
<span class="p_header">diff --git a/drivers/gpu/drm/i915/i915_drv.h b/drivers/gpu/drm/i915/i915_drv.h</span>
<span class="p_header">index 46fcd8b7080a..959e22dc94ba 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/i915/i915_drv.h</span>
<span class="p_header">+++ b/drivers/gpu/drm/i915/i915_drv.h</span>
<span class="p_chunk">@@ -3629,7 +3629,7 @@</span> <span class="p_context"> static inline bool intel_gmbus_is_forced_bit(struct i2c_adapter *adapter)</span>
 extern void intel_i2c_reset(struct drm_i915_private *dev_priv);
 
 /* intel_bios.c */
<span class="p_del">-int intel_bios_init(struct drm_i915_private *dev_priv);</span>
<span class="p_add">+void intel_bios_init(struct drm_i915_private *dev_priv);</span>
 bool intel_bios_is_valid_vbt(const void *buf, size_t size);
 bool intel_bios_is_tv_present(struct drm_i915_private *dev_priv);
 bool intel_bios_is_lvds_present(struct drm_i915_private *dev_priv, u8 *i2c_pin);
<span class="p_header">diff --git a/drivers/gpu/drm/i915/intel_bios.c b/drivers/gpu/drm/i915/intel_bios.c</span>
<span class="p_header">index e144f033f4b5..639d45c1dd2e 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/i915/intel_bios.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/i915/intel_bios.c</span>
<span class="p_chunk">@@ -1341,6 +1341,7 @@</span> <span class="p_context"> parse_device_mapping(struct drm_i915_private *dev_priv,</span>
 	return;
 }
 
<span class="p_add">+/* Common defaults which may be overridden by VBT. */</span>
 static void
 init_vbt_defaults(struct drm_i915_private *dev_priv)
 {
<span class="p_chunk">@@ -1377,6 +1378,18 @@</span> <span class="p_context"> init_vbt_defaults(struct drm_i915_private *dev_priv)</span>
 			&amp;dev_priv-&gt;vbt.ddi_port_info[port];
 
 		info-&gt;hdmi_level_shift = HDMI_LEVEL_SHIFT_UNKNOWN;
<span class="p_add">+	}</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+/* Defaults to initialize only if there is no VBT. */</span>
<span class="p_add">+static void</span>
<span class="p_add">+init_vbt_missing_defaults(struct drm_i915_private *dev_priv)</span>
<span class="p_add">+{</span>
<span class="p_add">+	enum port port;</span>
<span class="p_add">+</span>
<span class="p_add">+	for (port = PORT_A; port &lt; I915_MAX_PORTS; port++) {</span>
<span class="p_add">+		struct ddi_vbt_port_info *info =</span>
<span class="p_add">+			&amp;dev_priv-&gt;vbt.ddi_port_info[port];</span>
 
 		info-&gt;supports_dvi = (port != PORT_A &amp;&amp; port != PORT_E);
 		info-&gt;supports_hdmi = info-&gt;supports_dvi;
<span class="p_chunk">@@ -1462,36 +1475,35 @@</span> <span class="p_context"> static const struct vbt_header *find_vbt(void __iomem *bios, size_t size)</span>
  * intel_bios_init - find VBT and initialize settings from the BIOS
  * @dev_priv: i915 device instance
  *
<span class="p_del">- * Loads the Video BIOS and checks that the VBT exists.  Sets scratch registers</span>
<span class="p_del">- * to appropriate values.</span>
<span class="p_del">- *</span>
<span class="p_del">- * Returns 0 on success, nonzero on failure.</span>
<span class="p_add">+ * Parse and initialize settings from the Video BIOS Tables (VBT). If the VBT</span>
<span class="p_add">+ * was not found in ACPI OpRegion, try to find it in PCI ROM first. Also</span>
<span class="p_add">+ * initialize some defaults if the VBT is not present at all.</span>
  */
<span class="p_del">-int</span>
<span class="p_del">-intel_bios_init(struct drm_i915_private *dev_priv)</span>
<span class="p_add">+void intel_bios_init(struct drm_i915_private *dev_priv)</span>
 {
 	struct pci_dev *pdev = dev_priv-&gt;drm.pdev;
 	const struct vbt_header *vbt = dev_priv-&gt;opregion.vbt;
 	const struct bdb_header *bdb;
 	u8 __iomem *bios = NULL;
 
<span class="p_del">-	if (HAS_PCH_NOP(dev_priv))</span>
<span class="p_del">-		return -ENODEV;</span>
<span class="p_add">+	if (HAS_PCH_NOP(dev_priv)) {</span>
<span class="p_add">+		DRM_DEBUG_KMS(&quot;Skipping VBT init due to disabled display.\n&quot;);</span>
<span class="p_add">+		return;</span>
<span class="p_add">+	}</span>
 
 	init_vbt_defaults(dev_priv);
 
<span class="p_add">+	/* If the OpRegion does not have VBT, look in PCI ROM. */</span>
 	if (!vbt) {
 		size_t size;
 
 		bios = pci_map_rom(pdev, &amp;size);
 		if (!bios)
<span class="p_del">-			return -1;</span>
<span class="p_add">+			goto out;</span>
 
 		vbt = find_vbt(bios, size);
<span class="p_del">-		if (!vbt) {</span>
<span class="p_del">-			pci_unmap_rom(pdev, bios);</span>
<span class="p_del">-			return -1;</span>
<span class="p_del">-		}</span>
<span class="p_add">+		if (!vbt)</span>
<span class="p_add">+			goto out;</span>
 
 		DRM_DEBUG_KMS(&quot;Found valid VBT in PCI ROM\n&quot;);
 	}
<span class="p_chunk">@@ -1516,10 +1528,14 @@</span> <span class="p_context"> intel_bios_init(struct drm_i915_private *dev_priv)</span>
 	parse_mipi_sequence(dev_priv, bdb);
 	parse_ddi_ports(dev_priv, bdb);
 
<span class="p_add">+out:</span>
<span class="p_add">+	if (!vbt) {</span>
<span class="p_add">+		DRM_INFO(&quot;Failed to find VBIOS tables (VBT)\n&quot;);</span>
<span class="p_add">+		init_vbt_missing_defaults(dev_priv);</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
 	if (bios)
 		pci_unmap_rom(pdev, bios);
<span class="p_del">-</span>
<span class="p_del">-	return 0;</span>
 }
 
 /**
<span class="p_header">diff --git a/drivers/gpu/drm/i915/intel_lpe_audio.c b/drivers/gpu/drm/i915/intel_lpe_audio.c</span>
<span class="p_header">index 7a5b41b1c024..999cb31ba63d 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/i915/intel_lpe_audio.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/i915/intel_lpe_audio.c</span>
<span class="p_chunk">@@ -63,6 +63,7 @@</span> <span class="p_context"></span>
 #include &lt;linux/acpi.h&gt;
 #include &lt;linux/device.h&gt;
 #include &lt;linux/pci.h&gt;
<span class="p_add">+#include &lt;linux/pm_runtime.h&gt;</span>
 
 #include &quot;i915_drv.h&quot;
 #include &lt;linux/delay.h&gt;
<span class="p_chunk">@@ -121,6 +122,10 @@</span> <span class="p_context"> lpe_audio_platdev_create(struct drm_i915_private *dev_priv)</span>
 
 	kfree(rsc);
 
<span class="p_add">+	pm_runtime_forbid(&amp;platdev-&gt;dev);</span>
<span class="p_add">+	pm_runtime_set_active(&amp;platdev-&gt;dev);</span>
<span class="p_add">+	pm_runtime_enable(&amp;platdev-&gt;dev);</span>
<span class="p_add">+</span>
 	return platdev;
 
 err:
<span class="p_header">diff --git a/drivers/gpu/drm/msm/mdp/mdp5/mdp5_plane.c b/drivers/gpu/drm/msm/mdp/mdp5/mdp5_plane.c</span>
<span class="p_header">index 0ffb8affef35..4a81d67b0d69 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/msm/mdp/mdp5/mdp5_plane.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/msm/mdp/mdp5/mdp5_plane.c</span>
<span class="p_chunk">@@ -220,9 +220,10 @@</span> <span class="p_context"> mdp5_plane_duplicate_state(struct drm_plane *plane)</span>
 
 	mdp5_state = kmemdup(to_mdp5_plane_state(plane-&gt;state),
 			sizeof(*mdp5_state), GFP_KERNEL);
<span class="p_add">+	if (!mdp5_state)</span>
<span class="p_add">+		return NULL;</span>
 
<span class="p_del">-	if (mdp5_state &amp;&amp; mdp5_state-&gt;base.fb)</span>
<span class="p_del">-		drm_framebuffer_reference(mdp5_state-&gt;base.fb);</span>
<span class="p_add">+	__drm_atomic_helper_plane_duplicate_state(plane, &amp;mdp5_state-&gt;base);</span>
 
 	return &amp;mdp5_state-&gt;base;
 }
<span class="p_header">diff --git a/drivers/gpu/drm/msm/msm_drv.c b/drivers/gpu/drm/msm/msm_drv.c</span>
<span class="p_header">index 70226eaa5cac..eba4c3e8e156 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/msm/msm_drv.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/msm/msm_drv.c</span>
<span class="p_chunk">@@ -828,6 +828,7 @@</span> <span class="p_context"> static struct drm_driver msm_driver = {</span>
 	.prime_fd_to_handle = drm_gem_prime_fd_to_handle,
 	.gem_prime_export   = drm_gem_prime_export,
 	.gem_prime_import   = drm_gem_prime_import,
<span class="p_add">+	.gem_prime_res_obj  = msm_gem_prime_res_obj,</span>
 	.gem_prime_pin      = msm_gem_prime_pin,
 	.gem_prime_unpin    = msm_gem_prime_unpin,
 	.gem_prime_get_sg_table = msm_gem_prime_get_sg_table,
<span class="p_header">diff --git a/drivers/gpu/drm/msm/msm_drv.h b/drivers/gpu/drm/msm/msm_drv.h</span>
<span class="p_header">index c3b14876edaa..0e56a8bb7b59 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/msm/msm_drv.h</span>
<span class="p_header">+++ b/drivers/gpu/drm/msm/msm_drv.h</span>
<span class="p_chunk">@@ -223,6 +223,7 @@</span> <span class="p_context"> struct sg_table *msm_gem_prime_get_sg_table(struct drm_gem_object *obj);</span>
 void *msm_gem_prime_vmap(struct drm_gem_object *obj);
 void msm_gem_prime_vunmap(struct drm_gem_object *obj, void *vaddr);
 int msm_gem_prime_mmap(struct drm_gem_object *obj, struct vm_area_struct *vma);
<span class="p_add">+struct reservation_object *msm_gem_prime_res_obj(struct drm_gem_object *obj);</span>
 struct drm_gem_object *msm_gem_prime_import_sg_table(struct drm_device *dev,
 		struct dma_buf_attachment *attach, struct sg_table *sg);
 int msm_gem_prime_pin(struct drm_gem_object *obj);
<span class="p_header">diff --git a/drivers/gpu/drm/msm/msm_gem_prime.c b/drivers/gpu/drm/msm/msm_gem_prime.c</span>
<span class="p_header">index 60bb290700ce..13403c6da6c7 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/msm/msm_gem_prime.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/msm/msm_gem_prime.c</span>
<span class="p_chunk">@@ -70,3 +70,10 @@</span> <span class="p_context"> void msm_gem_prime_unpin(struct drm_gem_object *obj)</span>
 	if (!obj-&gt;import_attach)
 		msm_gem_put_pages(obj);
 }
<span class="p_add">+</span>
<span class="p_add">+struct reservation_object *msm_gem_prime_res_obj(struct drm_gem_object *obj)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct msm_gem_object *msm_obj = to_msm_bo(obj);</span>
<span class="p_add">+</span>
<span class="p_add">+	return msm_obj-&gt;resv;</span>
<span class="p_add">+}</span>
<span class="p_header">diff --git a/drivers/gpu/drm/nouveau/include/nvkm/subdev/timer.h b/drivers/gpu/drm/nouveau/include/nvkm/subdev/timer.h</span>
<span class="p_header">index 6a567fe347b3..820a4805916f 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/nouveau/include/nvkm/subdev/timer.h</span>
<span class="p_header">+++ b/drivers/gpu/drm/nouveau/include/nvkm/subdev/timer.h</span>
<span class="p_chunk">@@ -4,6 +4,7 @@</span> <span class="p_context"></span>
 
 struct nvkm_alarm {
 	struct list_head head;
<span class="p_add">+	struct list_head exec;</span>
 	u64 timestamp;
 	void (*func)(struct nvkm_alarm *);
 };
<span class="p_header">diff --git a/drivers/gpu/drm/nouveau/nvkm/subdev/timer/base.c b/drivers/gpu/drm/nouveau/nvkm/subdev/timer/base.c</span>
<span class="p_header">index f2a86eae0a0d..2437f7d41ca2 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/nouveau/nvkm/subdev/timer/base.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/nouveau/nvkm/subdev/timer/base.c</span>
<span class="p_chunk">@@ -50,7 +50,8 @@</span> <span class="p_context"> nvkm_timer_alarm_trigger(struct nvkm_timer *tmr)</span>
 		/* Move to completed list.  We&#39;ll drop the lock before
 		 * executing the callback so it can reschedule itself.
 		 */
<span class="p_del">-		list_move_tail(&amp;alarm-&gt;head, &amp;exec);</span>
<span class="p_add">+		list_del_init(&amp;alarm-&gt;head);</span>
<span class="p_add">+		list_add(&amp;alarm-&gt;exec, &amp;exec);</span>
 	}
 
 	/* Shut down interrupt if no more pending alarms. */
<span class="p_chunk">@@ -59,8 +60,8 @@</span> <span class="p_context"> nvkm_timer_alarm_trigger(struct nvkm_timer *tmr)</span>
 	spin_unlock_irqrestore(&amp;tmr-&gt;lock, flags);
 
 	/* Execute completed callbacks. */
<span class="p_del">-	list_for_each_entry_safe(alarm, atemp, &amp;exec, head) {</span>
<span class="p_del">-		list_del_init(&amp;alarm-&gt;head);</span>
<span class="p_add">+	list_for_each_entry_safe(alarm, atemp, &amp;exec, exec) {</span>
<span class="p_add">+		list_del(&amp;alarm-&gt;exec);</span>
 		alarm-&gt;func(alarm);
 	}
 }
<span class="p_header">diff --git a/drivers/gpu/drm/vmwgfx/vmwgfx_fifo.c b/drivers/gpu/drm/vmwgfx/vmwgfx_fifo.c</span>
<span class="p_header">index b6a0806b06bf..a1c68e6a689e 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/vmwgfx/vmwgfx_fifo.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/vmwgfx/vmwgfx_fifo.c</span>
<span class="p_chunk">@@ -368,6 +368,8 @@</span> <span class="p_context"> static void *vmw_local_fifo_reserve(struct vmw_private *dev_priv,</span>
 				return fifo_state-&gt;static_buffer;
 			else {
 				fifo_state-&gt;dynamic_buffer = vmalloc(bytes);
<span class="p_add">+				if (!fifo_state-&gt;dynamic_buffer)</span>
<span class="p_add">+					goto out_err;</span>
 				return fifo_state-&gt;dynamic_buffer;
 			}
 		}
<span class="p_header">diff --git a/drivers/gpu/drm/vmwgfx/vmwgfx_surface.c b/drivers/gpu/drm/vmwgfx/vmwgfx_surface.c</span>
<span class="p_header">index 05fa092c942b..56b803384ea2 100644</span>
<span class="p_header">--- a/drivers/gpu/drm/vmwgfx/vmwgfx_surface.c</span>
<span class="p_header">+++ b/drivers/gpu/drm/vmwgfx/vmwgfx_surface.c</span>
<span class="p_chunk">@@ -1275,11 +1275,14 @@</span> <span class="p_context"> int vmw_gb_surface_define_ioctl(struct drm_device *dev, void *data,</span>
 	struct ttm_object_file *tfile = vmw_fpriv(file_priv)-&gt;tfile;
 	int ret;
 	uint32_t size;
<span class="p_del">-	uint32_t backup_handle;</span>
<span class="p_add">+	uint32_t backup_handle = 0;</span>
 
 	if (req-&gt;multisample_count != 0)
 		return -EINVAL;
 
<span class="p_add">+	if (req-&gt;mip_levels &gt; DRM_VMW_MAX_MIP_LEVELS)</span>
<span class="p_add">+		return -EINVAL;</span>
<span class="p_add">+</span>
 	if (unlikely(vmw_user_surface_size == 0))
 		vmw_user_surface_size = ttm_round_pot(sizeof(*user_srf)) +
 			128;
<span class="p_chunk">@@ -1315,12 +1318,16 @@</span> <span class="p_context"> int vmw_gb_surface_define_ioctl(struct drm_device *dev, void *data,</span>
 		ret = vmw_user_dmabuf_lookup(tfile, req-&gt;buffer_handle,
 					     &amp;res-&gt;backup,
 					     &amp;user_srf-&gt;backup_base);
<span class="p_del">-		if (ret == 0 &amp;&amp; res-&gt;backup-&gt;base.num_pages * PAGE_SIZE &lt;</span>
<span class="p_del">-		    res-&gt;backup_size) {</span>
<span class="p_del">-			DRM_ERROR(&quot;Surface backup buffer is too small.\n&quot;);</span>
<span class="p_del">-			vmw_dmabuf_unreference(&amp;res-&gt;backup);</span>
<span class="p_del">-			ret = -EINVAL;</span>
<span class="p_del">-			goto out_unlock;</span>
<span class="p_add">+		if (ret == 0) {</span>
<span class="p_add">+			if (res-&gt;backup-&gt;base.num_pages * PAGE_SIZE &lt;</span>
<span class="p_add">+			    res-&gt;backup_size) {</span>
<span class="p_add">+				DRM_ERROR(&quot;Surface backup buffer is too small.\n&quot;);</span>
<span class="p_add">+				vmw_dmabuf_unreference(&amp;res-&gt;backup);</span>
<span class="p_add">+				ret = -EINVAL;</span>
<span class="p_add">+				goto out_unlock;</span>
<span class="p_add">+			} else {</span>
<span class="p_add">+				backup_handle = req-&gt;buffer_handle;</span>
<span class="p_add">+			}</span>
 		}
 	} else if (req-&gt;drm_surface_flags &amp; drm_vmw_surface_flag_create_buffer)
 		ret = vmw_user_dmabuf_alloc(dev_priv, tfile,
<span class="p_header">diff --git a/drivers/hwmon/coretemp.c b/drivers/hwmon/coretemp.c</span>
<span class="p_header">index 3ac4c03ba77b..c13a4fd86b3c 100644</span>
<span class="p_header">--- a/drivers/hwmon/coretemp.c</span>
<span class="p_header">+++ b/drivers/hwmon/coretemp.c</span>
<span class="p_chunk">@@ -605,6 +605,13 @@</span> <span class="p_context"> static int coretemp_cpu_online(unsigned int cpu)</span>
 	struct platform_data *pdata;
 
 	/*
<span class="p_add">+	 * Don&#39;t execute this on resume as the offline callback did</span>
<span class="p_add">+	 * not get executed on suspend.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	if (cpuhp_tasks_frozen)</span>
<span class="p_add">+		return 0;</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
 	 * CPUID.06H.EAX[0] indicates whether the CPU has thermal
 	 * sensors. We check this bit only, all the early CPUs
 	 * without thermal sensors will be filtered out.
<span class="p_chunk">@@ -654,6 +661,13 @@</span> <span class="p_context"> static int coretemp_cpu_offline(unsigned int cpu)</span>
 	struct temp_data *tdata;
 	int indx, target;
 
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Don&#39;t execute this on suspend as the device remove locks</span>
<span class="p_add">+	 * up the machine.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	if (cpuhp_tasks_frozen)</span>
<span class="p_add">+		return 0;</span>
<span class="p_add">+</span>
 	/* If the physical CPU device does not exist, just return */
 	if (!pdev)
 		return 0;
<span class="p_header">diff --git a/drivers/iio/adc/bcm_iproc_adc.c b/drivers/iio/adc/bcm_iproc_adc.c</span>
<span class="p_header">index 21d38c8af21e..7f4f9c4150e3 100644</span>
<span class="p_header">--- a/drivers/iio/adc/bcm_iproc_adc.c</span>
<span class="p_header">+++ b/drivers/iio/adc/bcm_iproc_adc.c</span>
<span class="p_chunk">@@ -143,7 +143,7 @@</span> <span class="p_context"> static void iproc_adc_reg_dump(struct iio_dev *indio_dev)</span>
 	iproc_adc_dbg_reg(dev, adc_priv, IPROC_SOFT_BYPASS_DATA);
 }
 
<span class="p_del">-static irqreturn_t iproc_adc_interrupt_handler(int irq, void *data)</span>
<span class="p_add">+static irqreturn_t iproc_adc_interrupt_thread(int irq, void *data)</span>
 {
 	u32 channel_intr_status;
 	u32 intr_status;
<span class="p_chunk">@@ -167,7 +167,7 @@</span> <span class="p_context"> static irqreturn_t iproc_adc_interrupt_handler(int irq, void *data)</span>
 	return IRQ_NONE;
 }
 
<span class="p_del">-static irqreturn_t iproc_adc_interrupt_thread(int irq, void *data)</span>
<span class="p_add">+static irqreturn_t iproc_adc_interrupt_handler(int irq, void *data)</span>
 {
 	irqreturn_t retval = IRQ_NONE;
 	struct iproc_adc_priv *adc_priv;
<span class="p_chunk">@@ -181,7 +181,7 @@</span> <span class="p_context"> static irqreturn_t iproc_adc_interrupt_thread(int irq, void *data)</span>
 	adc_priv = iio_priv(indio_dev);
 
 	regmap_read(adc_priv-&gt;regmap, IPROC_INTERRUPT_STATUS, &amp;intr_status);
<span class="p_del">-	dev_dbg(&amp;indio_dev-&gt;dev, &quot;iproc_adc_interrupt_thread(),INTRPT_STS:%x\n&quot;,</span>
<span class="p_add">+	dev_dbg(&amp;indio_dev-&gt;dev, &quot;iproc_adc_interrupt_handler(),INTRPT_STS:%x\n&quot;,</span>
 			intr_status);
 
 	intr_channels = (intr_status &amp; IPROC_ADC_INTR_MASK) &gt;&gt; IPROC_ADC_INTR;
<span class="p_chunk">@@ -566,8 +566,8 @@</span> <span class="p_context"> static int iproc_adc_probe(struct platform_device *pdev)</span>
 	}
 
 	ret = devm_request_threaded_irq(&amp;pdev-&gt;dev, adc_priv-&gt;irqno,
<span class="p_del">-				iproc_adc_interrupt_thread,</span>
 				iproc_adc_interrupt_handler,
<span class="p_add">+				iproc_adc_interrupt_thread,</span>
 				IRQF_SHARED, &quot;iproc-adc&quot;, indio_dev);
 	if (ret) {
 		dev_err(&amp;pdev-&gt;dev, &quot;request_irq error %d\n&quot;, ret);
<span class="p_header">diff --git a/drivers/iio/industrialio-trigger.c b/drivers/iio/industrialio-trigger.c</span>
<span class="p_header">index 978e1592c2a3..4061fed93f1f 100644</span>
<span class="p_header">--- a/drivers/iio/industrialio-trigger.c</span>
<span class="p_header">+++ b/drivers/iio/industrialio-trigger.c</span>
<span class="p_chunk">@@ -451,7 +451,8 @@</span> <span class="p_context"> static ssize_t iio_trigger_write_current(struct device *dev,</span>
 	return len;
 
 out_trigger_put:
<span class="p_del">-	iio_trigger_put(trig);</span>
<span class="p_add">+	if (trig)</span>
<span class="p_add">+		iio_trigger_put(trig);</span>
 	return ret;
 }
 
<span class="p_header">diff --git a/drivers/iio/light/ltr501.c b/drivers/iio/light/ltr501.c</span>
<span class="p_header">index b30e0c1c6cc4..67838edd8b37 100644</span>
<span class="p_header">--- a/drivers/iio/light/ltr501.c</span>
<span class="p_header">+++ b/drivers/iio/light/ltr501.c</span>
<span class="p_chunk">@@ -74,9 +74,9 @@</span> <span class="p_context"> static const int int_time_mapping[] = {100000, 50000, 200000, 400000};</span>
 static const struct reg_field reg_field_it =
 				REG_FIELD(LTR501_ALS_MEAS_RATE, 3, 4);
 static const struct reg_field reg_field_als_intr =
<span class="p_del">-				REG_FIELD(LTR501_INTR, 0, 0);</span>
<span class="p_del">-static const struct reg_field reg_field_ps_intr =</span>
 				REG_FIELD(LTR501_INTR, 1, 1);
<span class="p_add">+static const struct reg_field reg_field_ps_intr =</span>
<span class="p_add">+				REG_FIELD(LTR501_INTR, 0, 0);</span>
 static const struct reg_field reg_field_als_rate =
 				REG_FIELD(LTR501_ALS_MEAS_RATE, 0, 2);
 static const struct reg_field reg_field_ps_rate =
<span class="p_header">diff --git a/drivers/iio/proximity/as3935.c b/drivers/iio/proximity/as3935.c</span>
<span class="p_header">index 020459513384..268210ea4990 100644</span>
<span class="p_header">--- a/drivers/iio/proximity/as3935.c</span>
<span class="p_header">+++ b/drivers/iio/proximity/as3935.c</span>
<span class="p_chunk">@@ -40,9 +40,9 @@</span> <span class="p_context"></span>
 #define AS3935_AFE_PWR_BIT	BIT(0)
 
 #define AS3935_INT		0x03
<span class="p_del">-#define AS3935_INT_MASK		0x07</span>
<span class="p_add">+#define AS3935_INT_MASK		0x0f</span>
 #define AS3935_EVENT_INT	BIT(3)
<span class="p_del">-#define AS3935_NOISE_INT	BIT(1)</span>
<span class="p_add">+#define AS3935_NOISE_INT	BIT(0)</span>
 
 #define AS3935_DATA		0x07
 #define AS3935_DATA_MASK	0x3F
<span class="p_chunk">@@ -215,7 +215,7 @@</span> <span class="p_context"> static irqreturn_t as3935_trigger_handler(int irq, void *private)</span>
 
 	st-&gt;buffer[0] = val &amp; AS3935_DATA_MASK;
 	iio_push_to_buffers_with_timestamp(indio_dev, &amp;st-&gt;buffer,
<span class="p_del">-					   pf-&gt;timestamp);</span>
<span class="p_add">+					   iio_get_time_ns(indio_dev));</span>
 err_read:
 	iio_trigger_notify_done(indio_dev-&gt;trig);
 
<span class="p_chunk">@@ -244,7 +244,7 @@</span> <span class="p_context"> static void as3935_event_work(struct work_struct *work)</span>
 
 	switch (val) {
 	case AS3935_EVENT_INT:
<span class="p_del">-		iio_trigger_poll(st-&gt;trig);</span>
<span class="p_add">+		iio_trigger_poll_chained(st-&gt;trig);</span>
 		break;
 	case AS3935_NOISE_INT:
 		dev_warn(&amp;st-&gt;spi-&gt;dev, &quot;noise level is too high\n&quot;);
<span class="p_header">diff --git a/drivers/input/mouse/elantech.c b/drivers/input/mouse/elantech.c</span>
<span class="p_header">index e73d968023f7..f1fa1f172107 100644</span>
<span class="p_header">--- a/drivers/input/mouse/elantech.c</span>
<span class="p_header">+++ b/drivers/input/mouse/elantech.c</span>
<span class="p_chunk">@@ -1118,8 +1118,10 @@</span> <span class="p_context"> static int elantech_get_resolution_v4(struct psmouse *psmouse,</span>
  * Asus UX32VD             0x361f02        00, 15, 0e      clickpad
  * Avatar AVIU-145A2       0x361f00        ?               clickpad
  * Fujitsu LIFEBOOK E544   0x470f00        d0, 12, 09      2 hw buttons
<span class="p_add">+ * Fujitsu LIFEBOOK E546   0x470f00        50, 12, 09      2 hw buttons</span>
  * Fujitsu LIFEBOOK E547   0x470f00        50, 12, 09      2 hw buttons
  * Fujitsu LIFEBOOK E554   0x570f01        40, 14, 0c      2 hw buttons
<span class="p_add">+ * Fujitsu LIFEBOOK E557   0x570f01        40, 14, 0c      2 hw buttons</span>
  * Fujitsu T725            0x470f01        05, 12, 09      2 hw buttons
  * Fujitsu H730            0x570f00        c0, 14, 0c      3 hw buttons (**)
  * Gigabyte U2442          0x450f01        58, 17, 0c      2 hw buttons
<span class="p_chunk">@@ -1525,6 +1527,13 @@</span> <span class="p_context"> static const struct dmi_system_id elantech_dmi_force_crc_enabled[] = {</span>
 		},
 	},
 	{
<span class="p_add">+		/* Fujitsu LIFEBOOK E546  does not work with crc_enabled == 0 */</span>
<span class="p_add">+		.matches = {</span>
<span class="p_add">+			DMI_MATCH(DMI_SYS_VENDOR, &quot;FUJITSU&quot;),</span>
<span class="p_add">+			DMI_MATCH(DMI_PRODUCT_NAME, &quot;LIFEBOOK E546&quot;),</span>
<span class="p_add">+		},</span>
<span class="p_add">+	},</span>
<span class="p_add">+	{</span>
 		/* Fujitsu LIFEBOOK E547 does not work with crc_enabled == 0 */
 		.matches = {
 			DMI_MATCH(DMI_SYS_VENDOR, &quot;FUJITSU&quot;),
<span class="p_chunk">@@ -1546,6 +1555,13 @@</span> <span class="p_context"> static const struct dmi_system_id elantech_dmi_force_crc_enabled[] = {</span>
 		},
 	},
 	{
<span class="p_add">+		/* Fujitsu LIFEBOOK E557 does not work with crc_enabled == 0 */</span>
<span class="p_add">+		.matches = {</span>
<span class="p_add">+			DMI_MATCH(DMI_SYS_VENDOR, &quot;FUJITSU&quot;),</span>
<span class="p_add">+			DMI_MATCH(DMI_PRODUCT_NAME, &quot;LIFEBOOK E557&quot;),</span>
<span class="p_add">+		},</span>
<span class="p_add">+	},</span>
<span class="p_add">+	{</span>
 		/* Fujitsu LIFEBOOK U745 does not work with crc_enabled == 0 */
 		.matches = {
 			DMI_MATCH(DMI_SYS_VENDOR, &quot;FUJITSU&quot;),
<span class="p_header">diff --git a/drivers/media/rc/rc-ir-raw.c b/drivers/media/rc/rc-ir-raw.c</span>
<span class="p_header">index 7fa84b64a2ae..0bdc161c76cd 100644</span>
<span class="p_header">--- a/drivers/media/rc/rc-ir-raw.c</span>
<span class="p_header">+++ b/drivers/media/rc/rc-ir-raw.c</span>
<span class="p_chunk">@@ -211,7 +211,7 @@</span> <span class="p_context"> EXPORT_SYMBOL_GPL(ir_raw_event_set_idle);</span>
  */
 void ir_raw_event_handle(struct rc_dev *dev)
 {
<span class="p_del">-	if (!dev-&gt;raw)</span>
<span class="p_add">+	if (!dev-&gt;raw || !dev-&gt;raw-&gt;thread)</span>
 		return;
 
 	wake_up_process(dev-&gt;raw-&gt;thread);
<span class="p_chunk">@@ -490,6 +490,7 @@</span> <span class="p_context"> int ir_raw_event_register(struct rc_dev *dev)</span>
 {
 	int rc;
 	struct ir_raw_handler *handler;
<span class="p_add">+	struct task_struct *thread;</span>
 
 	if (!dev)
 		return -EINVAL;
<span class="p_chunk">@@ -507,13 +508,15 @@</span> <span class="p_context"> int ir_raw_event_register(struct rc_dev *dev)</span>
 	 * because the event is coming from userspace
 	 */
 	if (dev-&gt;driver_type != RC_DRIVER_IR_RAW_TX) {
<span class="p_del">-		dev-&gt;raw-&gt;thread = kthread_run(ir_raw_event_thread, dev-&gt;raw,</span>
<span class="p_del">-					       &quot;rc%u&quot;, dev-&gt;minor);</span>
<span class="p_add">+		thread = kthread_run(ir_raw_event_thread, dev-&gt;raw, &quot;rc%u&quot;,</span>
<span class="p_add">+				     dev-&gt;minor);</span>
 
<span class="p_del">-		if (IS_ERR(dev-&gt;raw-&gt;thread)) {</span>
<span class="p_del">-			rc = PTR_ERR(dev-&gt;raw-&gt;thread);</span>
<span class="p_add">+		if (IS_ERR(thread)) {</span>
<span class="p_add">+			rc = PTR_ERR(thread);</span>
 			goto out;
 		}
<span class="p_add">+</span>
<span class="p_add">+		dev-&gt;raw-&gt;thread = thread;</span>
 	}
 
 	mutex_lock(&amp;ir_raw_handler_lock);
<span class="p_header">diff --git a/drivers/misc/cxl/file.c b/drivers/misc/cxl/file.c</span>
<span class="p_header">index e7139c76f961..072064220707 100644</span>
<span class="p_header">--- a/drivers/misc/cxl/file.c</span>
<span class="p_header">+++ b/drivers/misc/cxl/file.c</span>
<span class="p_chunk">@@ -158,11 +158,8 @@</span> <span class="p_context"> static long afu_ioctl_start_work(struct cxl_context *ctx,</span>
 
 	/* Do this outside the status_mutex to avoid a circular dependency with
 	 * the locking in cxl_mmap_fault() */
<span class="p_del">-	if (copy_from_user(&amp;work, uwork,</span>
<span class="p_del">-			   sizeof(struct cxl_ioctl_start_work))) {</span>
<span class="p_del">-		rc = -EFAULT;</span>
<span class="p_del">-		goto out;</span>
<span class="p_del">-	}</span>
<span class="p_add">+	if (copy_from_user(&amp;work, uwork, sizeof(work)))</span>
<span class="p_add">+		return -EFAULT;</span>
 
 	mutex_lock(&amp;ctx-&gt;status_mutex);
 	if (ctx-&gt;status != OPENED) {
<span class="p_header">diff --git a/drivers/misc/cxl/native.c b/drivers/misc/cxl/native.c</span>
<span class="p_header">index 7ae710585267..47b777234c54 100644</span>
<span class="p_header">--- a/drivers/misc/cxl/native.c</span>
<span class="p_header">+++ b/drivers/misc/cxl/native.c</span>
<span class="p_chunk">@@ -1075,13 +1075,16 @@</span> <span class="p_context"> int cxl_native_register_psl_err_irq(struct cxl *adapter)</span>
 
 void cxl_native_release_psl_err_irq(struct cxl *adapter)
 {
<span class="p_del">-	if (adapter-&gt;native-&gt;err_virq != irq_find_mapping(NULL, adapter-&gt;native-&gt;err_hwirq))</span>
<span class="p_add">+	if (adapter-&gt;native-&gt;err_virq == 0 ||</span>
<span class="p_add">+	    adapter-&gt;native-&gt;err_virq !=</span>
<span class="p_add">+	    irq_find_mapping(NULL, adapter-&gt;native-&gt;err_hwirq))</span>
 		return;
 
 	cxl_p1_write(adapter, CXL_PSL_ErrIVTE, 0x0000000000000000);
 	cxl_unmap_irq(adapter-&gt;native-&gt;err_virq, adapter);
 	cxl_ops-&gt;release_one_irq(adapter, adapter-&gt;native-&gt;err_hwirq);
 	kfree(adapter-&gt;irq_name);
<span class="p_add">+	adapter-&gt;native-&gt;err_virq = 0;</span>
 }
 
 int cxl_native_register_serr_irq(struct cxl_afu *afu)
<span class="p_chunk">@@ -1111,13 +1114,15 @@</span> <span class="p_context"> int cxl_native_register_serr_irq(struct cxl_afu *afu)</span>
 
 void cxl_native_release_serr_irq(struct cxl_afu *afu)
 {
<span class="p_del">-	if (afu-&gt;serr_virq != irq_find_mapping(NULL, afu-&gt;serr_hwirq))</span>
<span class="p_add">+	if (afu-&gt;serr_virq == 0 ||</span>
<span class="p_add">+	    afu-&gt;serr_virq != irq_find_mapping(NULL, afu-&gt;serr_hwirq))</span>
 		return;
 
 	cxl_p1n_write(afu, CXL_PSL_SERR_An, 0x0000000000000000);
 	cxl_unmap_irq(afu-&gt;serr_virq, afu);
 	cxl_ops-&gt;release_one_irq(afu-&gt;adapter, afu-&gt;serr_hwirq);
 	kfree(afu-&gt;err_irq_name);
<span class="p_add">+	afu-&gt;serr_virq = 0;</span>
 }
 
 int cxl_native_register_psl_irq(struct cxl_afu *afu)
<span class="p_chunk">@@ -1140,12 +1145,15 @@</span> <span class="p_context"> int cxl_native_register_psl_irq(struct cxl_afu *afu)</span>
 
 void cxl_native_release_psl_irq(struct cxl_afu *afu)
 {
<span class="p_del">-	if (afu-&gt;native-&gt;psl_virq != irq_find_mapping(NULL, afu-&gt;native-&gt;psl_hwirq))</span>
<span class="p_add">+	if (afu-&gt;native-&gt;psl_virq == 0 ||</span>
<span class="p_add">+	    afu-&gt;native-&gt;psl_virq !=</span>
<span class="p_add">+	    irq_find_mapping(NULL, afu-&gt;native-&gt;psl_hwirq))</span>
 		return;
 
 	cxl_unmap_irq(afu-&gt;native-&gt;psl_virq, afu);
 	cxl_ops-&gt;release_one_irq(afu-&gt;adapter, afu-&gt;native-&gt;psl_hwirq);
 	kfree(afu-&gt;psl_irq_name);
<span class="p_add">+	afu-&gt;native-&gt;psl_virq = 0;</span>
 }
 
 static void recover_psl_err(struct cxl_afu *afu, u64 errstat)
<span class="p_header">diff --git a/drivers/misc/mei/bus.c b/drivers/misc/mei/bus.c</span>
<span class="p_header">index df5f78ae3d25..8b96c074799c 100644</span>
<span class="p_header">--- a/drivers/misc/mei/bus.c</span>
<span class="p_header">+++ b/drivers/misc/mei/bus.c</span>
<span class="p_chunk">@@ -763,8 +763,10 @@</span> <span class="p_context"> static ssize_t modalias_show(struct device *dev, struct device_attribute *a,</span>
 {
 	struct mei_cl_device *cldev = to_mei_cl_device(dev);
 	const uuid_le *uuid = mei_me_cl_uuid(cldev-&gt;me_cl);
<span class="p_add">+	u8 version = mei_me_cl_ver(cldev-&gt;me_cl);</span>
 
<span class="p_del">-	return scnprintf(buf, PAGE_SIZE, &quot;mei:%s:%pUl:&quot;, cldev-&gt;name, uuid);</span>
<span class="p_add">+	return scnprintf(buf, PAGE_SIZE, &quot;mei:%s:%pUl:%02X:&quot;,</span>
<span class="p_add">+			 cldev-&gt;name, uuid, version);</span>
 }
 static DEVICE_ATTR_RO(modalias);
 
<span class="p_header">diff --git a/drivers/mtd/nand/tango_nand.c b/drivers/mtd/nand/tango_nand.c</span>
<span class="p_header">index 4a5e948c62df..25b7b930e02a 100644</span>
<span class="p_header">--- a/drivers/mtd/nand/tango_nand.c</span>
<span class="p_header">+++ b/drivers/mtd/nand/tango_nand.c</span>
<span class="p_chunk">@@ -55,10 +55,10 @@</span> <span class="p_context"></span>
  * byte 1 for other packets in the page (PKT_N, for N &gt; 0)
  * ERR_COUNT_PKT_N is the max error count over all but the first packet.
  */
<span class="p_del">-#define DECODE_OK_PKT_0(v)	((v) &amp; BIT(7))</span>
<span class="p_del">-#define DECODE_OK_PKT_N(v)	((v) &amp; BIT(15))</span>
 #define ERR_COUNT_PKT_0(v)	(((v) &gt;&gt; 0) &amp; 0x3f)
 #define ERR_COUNT_PKT_N(v)	(((v) &gt;&gt; 8) &amp; 0x3f)
<span class="p_add">+#define DECODE_FAIL_PKT_0(v)	(((v) &amp; BIT(7)) == 0)</span>
<span class="p_add">+#define DECODE_FAIL_PKT_N(v)	(((v) &amp; BIT(15)) == 0)</span>
 
 /* Offsets relative to pbus_base */
 #define PBUS_CS_CTRL	0x83c
<span class="p_chunk">@@ -193,6 +193,8 @@</span> <span class="p_context"> static int check_erased_page(struct nand_chip *chip, u8 *buf)</span>
 						  chip-&gt;ecc.strength);
 		if (res &lt; 0)
 			mtd-&gt;ecc_stats.failed++;
<span class="p_add">+		else</span>
<span class="p_add">+			mtd-&gt;ecc_stats.corrected += res;</span>
 
 		bitflips = max(res, bitflips);
 		buf += pkt_size;
<span class="p_chunk">@@ -202,9 +204,11 @@</span> <span class="p_context"> static int check_erased_page(struct nand_chip *chip, u8 *buf)</span>
 	return bitflips;
 }
 
<span class="p_del">-static int decode_error_report(struct tango_nfc *nfc)</span>
<span class="p_add">+static int decode_error_report(struct nand_chip *chip)</span>
 {
 	u32 status, res;
<span class="p_add">+	struct mtd_info *mtd = nand_to_mtd(chip);</span>
<span class="p_add">+	struct tango_nfc *nfc = to_tango_nfc(chip-&gt;controller);</span>
 
 	status = readl_relaxed(nfc-&gt;reg_base + NFC_XFER_STATUS);
 	if (status &amp; PAGE_IS_EMPTY)
<span class="p_chunk">@@ -212,10 +216,14 @@</span> <span class="p_context"> static int decode_error_report(struct tango_nfc *nfc)</span>
 
 	res = readl_relaxed(nfc-&gt;mem_base + ERROR_REPORT);
 
<span class="p_del">-	if (DECODE_OK_PKT_0(res) &amp;&amp; DECODE_OK_PKT_N(res))</span>
<span class="p_del">-		return max(ERR_COUNT_PKT_0(res), ERR_COUNT_PKT_N(res));</span>
<span class="p_add">+	if (DECODE_FAIL_PKT_0(res) || DECODE_FAIL_PKT_N(res))</span>
<span class="p_add">+		return -EBADMSG;</span>
<span class="p_add">+</span>
<span class="p_add">+	/* ERR_COUNT_PKT_N is max, not sum, but that&#39;s all we have */</span>
<span class="p_add">+	mtd-&gt;ecc_stats.corrected +=</span>
<span class="p_add">+		ERR_COUNT_PKT_0(res) + ERR_COUNT_PKT_N(res);</span>
 
<span class="p_del">-	return -EBADMSG;</span>
<span class="p_add">+	return max(ERR_COUNT_PKT_0(res), ERR_COUNT_PKT_N(res));</span>
 }
 
 static void tango_dma_callback(void *arg)
<span class="p_chunk">@@ -280,7 +288,7 @@</span> <span class="p_context"> static int tango_read_page(struct mtd_info *mtd, struct nand_chip *chip,</span>
 	if (err)
 		return err;
 
<span class="p_del">-	res = decode_error_report(nfc);</span>
<span class="p_add">+	res = decode_error_report(chip);</span>
 	if (res &lt; 0) {
 		chip-&gt;ecc.read_oob_raw(mtd, chip, page);
 		res = check_erased_page(chip, buf);
<span class="p_chunk">@@ -661,6 +669,7 @@</span> <span class="p_context"> static const struct of_device_id tango_nand_ids[] = {</span>
 	{ .compatible = &quot;sigma,smp8758-nand&quot; },
 	{ /* sentinel */ }
 };
<span class="p_add">+MODULE_DEVICE_TABLE(of, tango_nand_ids);</span>
 
 static struct platform_driver tango_nand_driver = {
 	.probe	= tango_nand_probe,
<span class="p_header">diff --git a/drivers/net/ethernet/broadcom/bcmsysport.c b/drivers/net/ethernet/broadcom/bcmsysport.c</span>
<span class="p_header">index a68d4889f5db..a96916a63fa3 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/broadcom/bcmsysport.c</span>
<span class="p_header">+++ b/drivers/net/ethernet/broadcom/bcmsysport.c</span>
<span class="p_chunk">@@ -1968,9 +1968,12 @@</span> <span class="p_context"> static int bcm_sysport_probe(struct platform_device *pdev)</span>
 	priv-&gt;num_rx_desc_words = params-&gt;num_rx_desc_words;
 
 	priv-&gt;irq0 = platform_get_irq(pdev, 0);
<span class="p_del">-	if (!priv-&gt;is_lite)</span>
<span class="p_add">+	if (!priv-&gt;is_lite) {</span>
 		priv-&gt;irq1 = platform_get_irq(pdev, 1);
<span class="p_del">-	priv-&gt;wol_irq = platform_get_irq(pdev, 2);</span>
<span class="p_add">+		priv-&gt;wol_irq = platform_get_irq(pdev, 2);</span>
<span class="p_add">+	} else {</span>
<span class="p_add">+		priv-&gt;wol_irq = platform_get_irq(pdev, 1);</span>
<span class="p_add">+	}</span>
 	if (priv-&gt;irq0 &lt;= 0 || (priv-&gt;irq1 &lt;= 0 &amp;&amp; !priv-&gt;is_lite)) {
 		dev_err(&amp;pdev-&gt;dev, &quot;invalid interrupts\n&quot;);
 		ret = -EINVAL;
<span class="p_header">diff --git a/drivers/net/ethernet/broadcom/bnx2x/bnx2x_cmn.c b/drivers/net/ethernet/broadcom/bnx2x/bnx2x_cmn.c</span>
<span class="p_header">index 9e8c06130c09..c2f9a1f93c70 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/broadcom/bnx2x/bnx2x_cmn.c</span>
<span class="p_header">+++ b/drivers/net/ethernet/broadcom/bnx2x/bnx2x_cmn.c</span>
<span class="p_chunk">@@ -1926,7 +1926,7 @@</span> <span class="p_context"> u16 bnx2x_select_queue(struct net_device *dev, struct sk_buff *skb,</span>
 	}
 
 	/* select a non-FCoE queue */
<span class="p_del">-	return fallback(dev, skb) % BNX2X_NUM_ETH_QUEUES(bp);</span>
<span class="p_add">+	return fallback(dev, skb) % (BNX2X_NUM_ETH_QUEUES(bp) * bp-&gt;max_cos);</span>
 }
 
 void bnx2x_set_num_queues(struct bnx2x *bp)
<span class="p_header">diff --git a/drivers/net/ethernet/chelsio/cxgb4/cxgb4_main.c b/drivers/net/ethernet/chelsio/cxgb4/cxgb4_main.c</span>
<span class="p_header">index afb0967d2ce6..012194bc92d3 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/chelsio/cxgb4/cxgb4_main.c</span>
<span class="p_header">+++ b/drivers/net/ethernet/chelsio/cxgb4/cxgb4_main.c</span>
<span class="p_chunk">@@ -2217,10 +2217,14 @@</span> <span class="p_context"> static int cxgb_up(struct adapter *adap)</span>
 		if (err)
 			goto irq_err;
 	}
<span class="p_add">+</span>
<span class="p_add">+	mutex_lock(&amp;uld_mutex);</span>
 	enable_rx(adap);
 	t4_sge_start(adap);
 	t4_intr_enable(adap);
 	adap-&gt;flags |= FULL_INIT_DONE;
<span class="p_add">+	mutex_unlock(&amp;uld_mutex);</span>
<span class="p_add">+</span>
 	notify_ulds(adap, CXGB4_STATE_UP);
 #if IS_ENABLED(CONFIG_IPV6)
 	update_clip(adap);
<span class="p_header">diff --git a/drivers/net/ethernet/ethoc.c b/drivers/net/ethernet/ethoc.c</span>
<span class="p_header">index 23d82748f52b..4f33660134b8 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/ethoc.c</span>
<span class="p_header">+++ b/drivers/net/ethernet/ethoc.c</span>
<span class="p_chunk">@@ -739,6 +739,8 @@</span> <span class="p_context"> static int ethoc_open(struct net_device *dev)</span>
 	if (ret)
 		return ret;
 
<span class="p_add">+	napi_enable(&amp;priv-&gt;napi);</span>
<span class="p_add">+</span>
 	ethoc_init_ring(priv, dev-&gt;mem_start);
 	ethoc_reset(priv);
 
<span class="p_chunk">@@ -754,7 +756,6 @@</span> <span class="p_context"> static int ethoc_open(struct net_device *dev)</span>
 	priv-&gt;old_duplex = -1;
 
 	phy_start(dev-&gt;phydev);
<span class="p_del">-	napi_enable(&amp;priv-&gt;napi);</span>
 
 	if (netif_msg_ifup(priv)) {
 		dev_info(&amp;dev-&gt;dev, &quot;I/O: %08lx Memory: %08lx-%08lx\n&quot;,
<span class="p_header">diff --git a/drivers/net/ethernet/qualcomm/emac/emac-mac.c b/drivers/net/ethernet/qualcomm/emac/emac-mac.c</span>
<span class="p_header">index cc065ffbe4b5..bcd4708b3745 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/qualcomm/emac/emac-mac.c</span>
<span class="p_header">+++ b/drivers/net/ethernet/qualcomm/emac/emac-mac.c</span>
<span class="p_chunk">@@ -931,7 +931,7 @@</span> <span class="p_context"> int emac_mac_up(struct emac_adapter *adpt)</span>
 	emac_mac_config(adpt);
 	emac_mac_rx_descs_refill(adpt, &amp;adpt-&gt;rx_q);
 
<span class="p_del">-	adpt-&gt;phydev-&gt;irq = PHY_IGNORE_INTERRUPT;</span>
<span class="p_add">+	adpt-&gt;phydev-&gt;irq = PHY_POLL;</span>
 	ret = phy_connect_direct(netdev, adpt-&gt;phydev, emac_adjust_link,
 				 PHY_INTERFACE_MODE_SGMII);
 	if (ret) {
<span class="p_header">diff --git a/drivers/net/ethernet/qualcomm/emac/emac-phy.c b/drivers/net/ethernet/qualcomm/emac/emac-phy.c</span>
<span class="p_header">index 441c19366489..18461fcb9815 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/qualcomm/emac/emac-phy.c</span>
<span class="p_header">+++ b/drivers/net/ethernet/qualcomm/emac/emac-phy.c</span>
<span class="p_chunk">@@ -13,15 +13,11 @@</span> <span class="p_context"></span>
 /* Qualcomm Technologies, Inc. EMAC PHY Controller driver.
  */
 
<span class="p_del">-#include &lt;linux/module.h&gt;</span>
<span class="p_del">-#include &lt;linux/of.h&gt;</span>
<span class="p_del">-#include &lt;linux/of_net.h&gt;</span>
 #include &lt;linux/of_mdio.h&gt;
 #include &lt;linux/phy.h&gt;
 #include &lt;linux/iopoll.h&gt;
 #include &lt;linux/acpi.h&gt;
 #include &quot;emac.h&quot;
<span class="p_del">-#include &quot;emac-mac.h&quot;</span>
 
 /* EMAC base register offsets */
 #define EMAC_MDIO_CTRL                                        0x001414
<span class="p_chunk">@@ -52,62 +48,10 @@</span> <span class="p_context"></span>
 
 #define MDIO_WAIT_TIMES                                           1000
 
<span class="p_del">-#define EMAC_LINK_SPEED_DEFAULT (\</span>
<span class="p_del">-		EMAC_LINK_SPEED_10_HALF  |\</span>
<span class="p_del">-		EMAC_LINK_SPEED_10_FULL  |\</span>
<span class="p_del">-		EMAC_LINK_SPEED_100_HALF |\</span>
<span class="p_del">-		EMAC_LINK_SPEED_100_FULL |\</span>
<span class="p_del">-		EMAC_LINK_SPEED_1GB_FULL)</span>
<span class="p_del">-</span>
<span class="p_del">-/**</span>
<span class="p_del">- * emac_phy_mdio_autopoll_disable() - disable mdio autopoll</span>
<span class="p_del">- * @adpt: the emac adapter</span>
<span class="p_del">- *</span>
<span class="p_del">- * The autopoll feature takes over the MDIO bus.  In order for</span>
<span class="p_del">- * the PHY driver to be able to talk to the PHY over the MDIO</span>
<span class="p_del">- * bus, we need to temporarily disable the autopoll feature.</span>
<span class="p_del">- */</span>
<span class="p_del">-static int emac_phy_mdio_autopoll_disable(struct emac_adapter *adpt)</span>
<span class="p_del">-{</span>
<span class="p_del">-	u32 val;</span>
<span class="p_del">-</span>
<span class="p_del">-	/* disable autopoll */</span>
<span class="p_del">-	emac_reg_update32(adpt-&gt;base + EMAC_MDIO_CTRL, MDIO_AP_EN, 0);</span>
<span class="p_del">-</span>
<span class="p_del">-	/* wait for any mdio polling to complete */</span>
<span class="p_del">-	if (!readl_poll_timeout(adpt-&gt;base + EMAC_MDIO_CTRL, val,</span>
<span class="p_del">-				!(val &amp; MDIO_BUSY), 100, MDIO_WAIT_TIMES * 100))</span>
<span class="p_del">-		return 0;</span>
<span class="p_del">-</span>
<span class="p_del">-	/* failed to disable; ensure it is enabled before returning */</span>
<span class="p_del">-	emac_reg_update32(adpt-&gt;base + EMAC_MDIO_CTRL, 0, MDIO_AP_EN);</span>
<span class="p_del">-</span>
<span class="p_del">-	return -EBUSY;</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
<span class="p_del">-/**</span>
<span class="p_del">- * emac_phy_mdio_autopoll_disable() - disable mdio autopoll</span>
<span class="p_del">- * @adpt: the emac adapter</span>
<span class="p_del">- *</span>
<span class="p_del">- * The EMAC has the ability to poll the external PHY on the MDIO</span>
<span class="p_del">- * bus for link state changes.  This eliminates the need for the</span>
<span class="p_del">- * driver to poll the phy.  If if the link state does change,</span>
<span class="p_del">- * the EMAC issues an interrupt on behalf of the PHY.</span>
<span class="p_del">- */</span>
<span class="p_del">-static void emac_phy_mdio_autopoll_enable(struct emac_adapter *adpt)</span>
<span class="p_del">-{</span>
<span class="p_del">-	emac_reg_update32(adpt-&gt;base + EMAC_MDIO_CTRL, 0, MDIO_AP_EN);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
 static int emac_mdio_read(struct mii_bus *bus, int addr, int regnum)
 {
 	struct emac_adapter *adpt = bus-&gt;priv;
 	u32 reg;
<span class="p_del">-	int ret;</span>
<span class="p_del">-</span>
<span class="p_del">-	ret = emac_phy_mdio_autopoll_disable(adpt);</span>
<span class="p_del">-	if (ret)</span>
<span class="p_del">-		return ret;</span>
 
 	emac_reg_update32(adpt-&gt;base + EMAC_PHY_STS, PHY_ADDR_BMSK,
 			  (addr &lt;&lt; PHY_ADDR_SHFT));
<span class="p_chunk">@@ -122,24 +66,15 @@</span> <span class="p_context"> static int emac_mdio_read(struct mii_bus *bus, int addr, int regnum)</span>
 	if (readl_poll_timeout(adpt-&gt;base + EMAC_MDIO_CTRL, reg,
 			       !(reg &amp; (MDIO_START | MDIO_BUSY)),
 			       100, MDIO_WAIT_TIMES * 100))
<span class="p_del">-		ret = -EIO;</span>
<span class="p_del">-	else</span>
<span class="p_del">-		ret = (reg &gt;&gt; MDIO_DATA_SHFT) &amp; MDIO_DATA_BMSK;</span>
<span class="p_add">+		return -EIO;</span>
 
<span class="p_del">-	emac_phy_mdio_autopoll_enable(adpt);</span>
<span class="p_del">-</span>
<span class="p_del">-	return ret;</span>
<span class="p_add">+	return (reg &gt;&gt; MDIO_DATA_SHFT) &amp; MDIO_DATA_BMSK;</span>
 }
 
 static int emac_mdio_write(struct mii_bus *bus, int addr, int regnum, u16 val)
 {
 	struct emac_adapter *adpt = bus-&gt;priv;
 	u32 reg;
<span class="p_del">-	int ret;</span>
<span class="p_del">-</span>
<span class="p_del">-	ret = emac_phy_mdio_autopoll_disable(adpt);</span>
<span class="p_del">-	if (ret)</span>
<span class="p_del">-		return ret;</span>
 
 	emac_reg_update32(adpt-&gt;base + EMAC_PHY_STS, PHY_ADDR_BMSK,
 			  (addr &lt;&lt; PHY_ADDR_SHFT));
<span class="p_chunk">@@ -155,11 +90,9 @@</span> <span class="p_context"> static int emac_mdio_write(struct mii_bus *bus, int addr, int regnum, u16 val)</span>
 	if (readl_poll_timeout(adpt-&gt;base + EMAC_MDIO_CTRL, reg,
 			       !(reg &amp; (MDIO_START | MDIO_BUSY)), 100,
 			       MDIO_WAIT_TIMES * 100))
<span class="p_del">-		ret = -EIO;</span>
<span class="p_add">+		return -EIO;</span>
 
<span class="p_del">-	emac_phy_mdio_autopoll_enable(adpt);</span>
<span class="p_del">-</span>
<span class="p_del">-	return ret;</span>
<span class="p_add">+	return 0;</span>
 }
 
 /* Configure the MDIO bus and connect the external PHY */
<span class="p_header">diff --git a/drivers/net/ethernet/qualcomm/emac/emac.c b/drivers/net/ethernet/qualcomm/emac/emac.c</span>
<span class="p_header">index 28a8cdc36485..98a326faea29 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/qualcomm/emac/emac.c</span>
<span class="p_header">+++ b/drivers/net/ethernet/qualcomm/emac/emac.c</span>
<span class="p_chunk">@@ -50,19 +50,7 @@</span> <span class="p_context"></span>
 #define DMAR_DLY_CNT_DEF				    15
 #define DMAW_DLY_CNT_DEF				     4
 
<span class="p_del">-#define IMR_NORMAL_MASK         (\</span>
<span class="p_del">-		ISR_ERROR       |\</span>
<span class="p_del">-		ISR_GPHY_LINK   |\</span>
<span class="p_del">-		ISR_TX_PKT      |\</span>
<span class="p_del">-		GPHY_WAKEUP_INT)</span>
<span class="p_del">-</span>
<span class="p_del">-#define IMR_EXTENDED_MASK       (\</span>
<span class="p_del">-		SW_MAN_INT      |\</span>
<span class="p_del">-		ISR_OVER        |\</span>
<span class="p_del">-		ISR_ERROR       |\</span>
<span class="p_del">-		ISR_GPHY_LINK   |\</span>
<span class="p_del">-		ISR_TX_PKT      |\</span>
<span class="p_del">-		GPHY_WAKEUP_INT)</span>
<span class="p_add">+#define IMR_NORMAL_MASK		(ISR_ERROR | ISR_OVER | ISR_TX_PKT)</span>
 
 #define ISR_TX_PKT      (\
 	TX_PKT_INT      |\
<span class="p_chunk">@@ -70,10 +58,6 @@</span> <span class="p_context"></span>
 	TX_PKT_INT2     |\
 	TX_PKT_INT3)
 
<span class="p_del">-#define ISR_GPHY_LINK        (\</span>
<span class="p_del">-	GPHY_LINK_UP_INT     |\</span>
<span class="p_del">-	GPHY_LINK_DOWN_INT)</span>
<span class="p_del">-</span>
 #define ISR_OVER        (\
 	RFD0_UR_INT     |\
 	RFD1_UR_INT     |\
<span class="p_chunk">@@ -187,10 +171,6 @@</span> <span class="p_context"> irqreturn_t emac_isr(int _irq, void *data)</span>
 	if (status &amp; ISR_OVER)
 		net_warn_ratelimited(&quot;warning: TX/RX overflow\n&quot;);
 
<span class="p_del">-	/* link event */</span>
<span class="p_del">-	if (status &amp; ISR_GPHY_LINK)</span>
<span class="p_del">-		phy_mac_interrupt(adpt-&gt;phydev, !!(status &amp; GPHY_LINK_UP_INT));</span>
<span class="p_del">-</span>
 exit:
 	/* enable the interrupt */
 	writel(irq-&gt;mask, adpt-&gt;base + EMAC_INT_MASK);
<span class="p_header">diff --git a/drivers/net/ethernet/renesas/ravb_main.c b/drivers/net/ethernet/renesas/ravb_main.c</span>
<span class="p_header">index 3cd7989c007d..784782da3a85 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/renesas/ravb_main.c</span>
<span class="p_header">+++ b/drivers/net/ethernet/renesas/ravb_main.c</span>
<span class="p_chunk">@@ -230,18 +230,6 @@</span> <span class="p_context"> static void ravb_ring_free(struct net_device *ndev, int q)</span>
 	int ring_size;
 	int i;
 
<span class="p_del">-	/* Free RX skb ringbuffer */</span>
<span class="p_del">-	if (priv-&gt;rx_skb[q]) {</span>
<span class="p_del">-		for (i = 0; i &lt; priv-&gt;num_rx_ring[q]; i++)</span>
<span class="p_del">-			dev_kfree_skb(priv-&gt;rx_skb[q][i]);</span>
<span class="p_del">-	}</span>
<span class="p_del">-	kfree(priv-&gt;rx_skb[q]);</span>
<span class="p_del">-	priv-&gt;rx_skb[q] = NULL;</span>
<span class="p_del">-</span>
<span class="p_del">-	/* Free aligned TX buffers */</span>
<span class="p_del">-	kfree(priv-&gt;tx_align[q]);</span>
<span class="p_del">-	priv-&gt;tx_align[q] = NULL;</span>
<span class="p_del">-</span>
 	if (priv-&gt;rx_ring[q]) {
 		for (i = 0; i &lt; priv-&gt;num_rx_ring[q]; i++) {
 			struct ravb_ex_rx_desc *desc = &amp;priv-&gt;rx_ring[q][i];
<span class="p_chunk">@@ -270,6 +258,18 @@</span> <span class="p_context"> static void ravb_ring_free(struct net_device *ndev, int q)</span>
 		priv-&gt;tx_ring[q] = NULL;
 	}
 
<span class="p_add">+	/* Free RX skb ringbuffer */</span>
<span class="p_add">+	if (priv-&gt;rx_skb[q]) {</span>
<span class="p_add">+		for (i = 0; i &lt; priv-&gt;num_rx_ring[q]; i++)</span>
<span class="p_add">+			dev_kfree_skb(priv-&gt;rx_skb[q][i]);</span>
<span class="p_add">+	}</span>
<span class="p_add">+	kfree(priv-&gt;rx_skb[q]);</span>
<span class="p_add">+	priv-&gt;rx_skb[q] = NULL;</span>
<span class="p_add">+</span>
<span class="p_add">+	/* Free aligned TX buffers */</span>
<span class="p_add">+	kfree(priv-&gt;tx_align[q]);</span>
<span class="p_add">+	priv-&gt;tx_align[q] = NULL;</span>
<span class="p_add">+</span>
 	/* Free TX skb ringbuffer.
 	 * SKBs are freed by ravb_tx_free() call above.
 	 */
<span class="p_header">diff --git a/drivers/net/ethernet/stmicro/stmmac/stmmac_main.c b/drivers/net/ethernet/stmicro/stmmac/stmmac_main.c</span>
<span class="p_header">index 4498a3861aa3..67e86ace5d92 100644</span>
<span class="p_header">--- a/drivers/net/ethernet/stmicro/stmmac/stmmac_main.c</span>
<span class="p_header">+++ b/drivers/net/ethernet/stmicro/stmmac/stmmac_main.c</span>
<span class="p_chunk">@@ -1950,7 +1950,7 @@</span> <span class="p_context"> static void stmmac_tso_allocator(struct stmmac_priv *priv, unsigned int des,</span>
 
 		priv-&gt;hw-&gt;desc-&gt;prepare_tso_tx_desc(desc, 0, buff_size,
 			0, 1,
<span class="p_del">-			(last_segment) &amp;&amp; (buff_size &lt; TSO_MAX_BUFF_SIZE),</span>
<span class="p_add">+			(last_segment) &amp;&amp; (tmp_len &lt;= TSO_MAX_BUFF_SIZE),</span>
 			0, 0);
 
 		tmp_len -= TSO_MAX_BUFF_SIZE;
<span class="p_header">diff --git a/drivers/net/geneve.c b/drivers/net/geneve.c</span>
<span class="p_header">index 959fd12d2e67..6ebb0f559a42 100644</span>
<span class="p_header">--- a/drivers/net/geneve.c</span>
<span class="p_header">+++ b/drivers/net/geneve.c</span>
<span class="p_chunk">@@ -1133,7 +1133,7 @@</span> <span class="p_context"> static int geneve_configure(struct net *net, struct net_device *dev,</span>
 
 	/* make enough headroom for basic scenario */
 	encap_len = GENEVE_BASE_HLEN + ETH_HLEN;
<span class="p_del">-	if (ip_tunnel_info_af(info) == AF_INET) {</span>
<span class="p_add">+	if (!metadata &amp;&amp; ip_tunnel_info_af(info) == AF_INET) {</span>
 		encap_len += sizeof(struct iphdr);
 		dev-&gt;max_mtu -= sizeof(struct iphdr);
 	} else {
<span class="p_header">diff --git a/drivers/net/vxlan.c b/drivers/net/vxlan.c</span>
<span class="p_header">index bdb6ae16d4a8..70dbd5a48b6b 100644</span>
<span class="p_header">--- a/drivers/net/vxlan.c</span>
<span class="p_header">+++ b/drivers/net/vxlan.c</span>
<span class="p_chunk">@@ -59,6 +59,8 @@</span> <span class="p_context"> static const u8 all_zeros_mac[ETH_ALEN + 2];</span>
 
 static int vxlan_sock_add(struct vxlan_dev *vxlan);
 
<span class="p_add">+static void vxlan_vs_del_dev(struct vxlan_dev *vxlan);</span>
<span class="p_add">+</span>
 /* per-network namespace private data for this module */
 struct vxlan_net {
 	struct list_head  vxlan_list;
<span class="p_chunk">@@ -740,6 +742,22 @@</span> <span class="p_context"> static void vxlan_fdb_destroy(struct vxlan_dev *vxlan, struct vxlan_fdb *f)</span>
 	call_rcu(&amp;f-&gt;rcu, vxlan_fdb_free);
 }
 
<span class="p_add">+static void vxlan_dst_free(struct rcu_head *head)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct vxlan_rdst *rd = container_of(head, struct vxlan_rdst, rcu);</span>
<span class="p_add">+</span>
<span class="p_add">+	dst_cache_destroy(&amp;rd-&gt;dst_cache);</span>
<span class="p_add">+	kfree(rd);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static void vxlan_fdb_dst_destroy(struct vxlan_dev *vxlan, struct vxlan_fdb *f,</span>
<span class="p_add">+				  struct vxlan_rdst *rd)</span>
<span class="p_add">+{</span>
<span class="p_add">+	list_del_rcu(&amp;rd-&gt;list);</span>
<span class="p_add">+	vxlan_fdb_notify(vxlan, f, rd, RTM_DELNEIGH);</span>
<span class="p_add">+	call_rcu(&amp;rd-&gt;rcu, vxlan_dst_free);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static int vxlan_fdb_parse(struct nlattr *tb[], struct vxlan_dev *vxlan,
 			   union vxlan_addr *ip, __be16 *port, __be32 *src_vni,
 			   __be32 *vni, u32 *ifindex)
<span class="p_chunk">@@ -864,9 +882,7 @@</span> <span class="p_context"> static int __vxlan_fdb_delete(struct vxlan_dev *vxlan,</span>
 	 * otherwise destroy the fdb entry
 	 */
 	if (rd &amp;&amp; !list_is_singular(&amp;f-&gt;remotes)) {
<span class="p_del">-		list_del_rcu(&amp;rd-&gt;list);</span>
<span class="p_del">-		vxlan_fdb_notify(vxlan, f, rd, RTM_DELNEIGH);</span>
<span class="p_del">-		kfree_rcu(rd, rcu);</span>
<span class="p_add">+		vxlan_fdb_dst_destroy(vxlan, f, rd);</span>
 		goto out;
 	}
 
<span class="p_chunk">@@ -1067,6 +1083,8 @@</span> <span class="p_context"> static void vxlan_sock_release(struct vxlan_dev *vxlan)</span>
 	rcu_assign_pointer(vxlan-&gt;vn4_sock, NULL);
 	synchronize_net();
 
<span class="p_add">+	vxlan_vs_del_dev(vxlan);</span>
<span class="p_add">+</span>
 	if (__vxlan_sock_release_prep(sock4)) {
 		udp_tunnel_sock_release(sock4-&gt;sock);
 		kfree(sock4);
<span class="p_chunk">@@ -2338,6 +2356,15 @@</span> <span class="p_context"> static void vxlan_cleanup(unsigned long arg)</span>
 	mod_timer(&amp;vxlan-&gt;age_timer, next_timer);
 }
 
<span class="p_add">+static void vxlan_vs_del_dev(struct vxlan_dev *vxlan)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct vxlan_net *vn = net_generic(vxlan-&gt;net, vxlan_net_id);</span>
<span class="p_add">+</span>
<span class="p_add">+	spin_lock(&amp;vn-&gt;sock_lock);</span>
<span class="p_add">+	hlist_del_init_rcu(&amp;vxlan-&gt;hlist);</span>
<span class="p_add">+	spin_unlock(&amp;vn-&gt;sock_lock);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static void vxlan_vs_add_dev(struct vxlan_sock *vs, struct vxlan_dev *vxlan)
 {
 	struct vxlan_net *vn = net_generic(vxlan-&gt;net, vxlan_net_id);
<span class="p_chunk">@@ -3275,15 +3302,9 @@</span> <span class="p_context"> static int vxlan_changelink(struct net_device *dev, struct nlattr *tb[],</span>
 static void vxlan_dellink(struct net_device *dev, struct list_head *head)
 {
 	struct vxlan_dev *vxlan = netdev_priv(dev);
<span class="p_del">-	struct vxlan_net *vn = net_generic(vxlan-&gt;net, vxlan_net_id);</span>
 
 	vxlan_flush(vxlan, true);
 
<span class="p_del">-	spin_lock(&amp;vn-&gt;sock_lock);</span>
<span class="p_del">-	if (!hlist_unhashed(&amp;vxlan-&gt;hlist))</span>
<span class="p_del">-		hlist_del_rcu(&amp;vxlan-&gt;hlist);</span>
<span class="p_del">-	spin_unlock(&amp;vn-&gt;sock_lock);</span>
<span class="p_del">-</span>
 	gro_cells_destroy(&amp;vxlan-&gt;gro_cells);
 	list_del(&amp;vxlan-&gt;next);
 	unregister_netdevice_queue(dev, head);
<span class="p_header">diff --git a/drivers/pinctrl/intel/pinctrl-cherryview.c b/drivers/pinctrl/intel/pinctrl-cherryview.c</span>
<span class="p_header">index 9ff790174906..1d09097dec88 100644</span>
<span class="p_header">--- a/drivers/pinctrl/intel/pinctrl-cherryview.c</span>
<span class="p_header">+++ b/drivers/pinctrl/intel/pinctrl-cherryview.c</span>
<span class="p_chunk">@@ -1542,7 +1542,8 @@</span> <span class="p_context"> static const struct dmi_system_id chv_no_valid_mask[] = {</span>
 			DMI_MATCH(DMI_PRODUCT_NAME, &quot;Edgar&quot;),
 			DMI_MATCH(DMI_BIOS_DATE, &quot;05/21/2016&quot;),
 		},
<span class="p_del">-	}</span>
<span class="p_add">+	},</span>
<span class="p_add">+	{}</span>
 };
 
 static int chv_gpio_probe(struct chv_pinctrl *pctrl, int irq)
<span class="p_header">diff --git a/drivers/scsi/qla2xxx/qla_bsg.c b/drivers/scsi/qla2xxx/qla_bsg.c</span>
<span class="p_header">index 84c9098cc089..aea10682e0fc 100644</span>
<span class="p_header">--- a/drivers/scsi/qla2xxx/qla_bsg.c</span>
<span class="p_header">+++ b/drivers/scsi/qla2xxx/qla_bsg.c</span>
<span class="p_chunk">@@ -730,6 +730,8 @@</span> <span class="p_context"> qla2x00_process_loopback(struct bsg_job *bsg_job)</span>
 		return -EIO;
 	}
 
<span class="p_add">+	memset(&amp;elreq, 0, sizeof(elreq));</span>
<span class="p_add">+</span>
 	elreq.req_sg_cnt = dma_map_sg(&amp;ha-&gt;pdev-&gt;dev,
 		bsg_job-&gt;request_payload.sg_list, bsg_job-&gt;request_payload.sg_cnt,
 		DMA_TO_DEVICE);
<span class="p_chunk">@@ -795,10 +797,9 @@</span> <span class="p_context"> qla2x00_process_loopback(struct bsg_job *bsg_job)</span>
 
 	if (atomic_read(&amp;vha-&gt;loop_state) == LOOP_READY &amp;&amp;
 	    (ha-&gt;current_topology == ISP_CFG_F ||
<span class="p_del">-	    ((IS_QLA81XX(ha) || IS_QLA8031(ha) || IS_QLA8044(ha)) &amp;&amp;</span>
<span class="p_del">-	    le32_to_cpu(*(uint32_t *)req_data) == ELS_OPCODE_BYTE</span>
<span class="p_del">-	    &amp;&amp; req_data_len == MAX_ELS_FRAME_PAYLOAD)) &amp;&amp;</span>
<span class="p_del">-		elreq.options == EXTERNAL_LOOPBACK) {</span>
<span class="p_add">+	    (le32_to_cpu(*(uint32_t *)req_data) == ELS_OPCODE_BYTE &amp;&amp;</span>
<span class="p_add">+	     req_data_len == MAX_ELS_FRAME_PAYLOAD)) &amp;&amp;</span>
<span class="p_add">+	    elreq.options == EXTERNAL_LOOPBACK) {</span>
 		type = &quot;FC_BSG_HST_VENDOR_ECHO_DIAG&quot;;
 		ql_dbg(ql_dbg_user, vha, 0x701e,
 		    &quot;BSG request type: %s.\n&quot;, type);
<span class="p_header">diff --git a/drivers/scsi/qla2xxx/qla_dbg.c b/drivers/scsi/qla2xxx/qla_dbg.c</span>
<span class="p_header">index 51b4179469d1..88748a6ab73f 100644</span>
<span class="p_header">--- a/drivers/scsi/qla2xxx/qla_dbg.c</span>
<span class="p_header">+++ b/drivers/scsi/qla2xxx/qla_dbg.c</span>
<span class="p_chunk">@@ -1131,7 +1131,7 @@</span> <span class="p_context"> qla24xx_fw_dump(scsi_qla_host_t *vha, int hardware_locked)</span>
 
 	/* Mailbox registers. */
 	mbx_reg = &amp;reg-&gt;mailbox0;
<span class="p_del">-	for (cnt = 0; cnt &lt; sizeof(fw-&gt;mailbox_reg) / 2; cnt++, dmp_reg++)</span>
<span class="p_add">+	for (cnt = 0; cnt &lt; sizeof(fw-&gt;mailbox_reg) / 2; cnt++, mbx_reg++)</span>
 		fw-&gt;mailbox_reg[cnt] = htons(RD_REG_WORD(mbx_reg));
 
 	/* Transfer sequence registers. */
<span class="p_chunk">@@ -2090,7 +2090,7 @@</span> <span class="p_context"> qla83xx_fw_dump(scsi_qla_host_t *vha, int hardware_locked)</span>
 
 	/* Mailbox registers. */
 	mbx_reg = &amp;reg-&gt;mailbox0;
<span class="p_del">-	for (cnt = 0; cnt &lt; sizeof(fw-&gt;mailbox_reg) / 2; cnt++, dmp_reg++)</span>
<span class="p_add">+	for (cnt = 0; cnt &lt; sizeof(fw-&gt;mailbox_reg) / 2; cnt++, mbx_reg++)</span>
 		fw-&gt;mailbox_reg[cnt] = htons(RD_REG_WORD(mbx_reg));
 
 	/* Transfer sequence registers. */
<span class="p_header">diff --git a/drivers/scsi/qla2xxx/qla_def.h b/drivers/scsi/qla2xxx/qla_def.h</span>
<span class="p_header">index ae119018dfaa..eddbc1218a39 100644</span>
<span class="p_header">--- a/drivers/scsi/qla2xxx/qla_def.h</span>
<span class="p_header">+++ b/drivers/scsi/qla2xxx/qla_def.h</span>
<span class="p_chunk">@@ -3425,6 +3425,7 @@</span> <span class="p_context"> struct qla_hw_data {</span>
 	uint8_t 	max_req_queues;
 	uint8_t 	max_rsp_queues;
 	uint8_t		max_qpairs;
<span class="p_add">+	uint8_t		num_qpairs;</span>
 	struct qla_qpair *base_qpair;
 	struct qla_npiv_entry *npiv_info;
 	uint16_t	nvram_npiv_size;
<span class="p_header">diff --git a/drivers/scsi/qla2xxx/qla_init.c b/drivers/scsi/qla2xxx/qla_init.c</span>
<span class="p_header">index f9d2fe7b1ade..98a2ca4fe03c 100644</span>
<span class="p_header">--- a/drivers/scsi/qla2xxx/qla_init.c</span>
<span class="p_header">+++ b/drivers/scsi/qla2xxx/qla_init.c</span>
<span class="p_chunk">@@ -7543,12 +7543,13 @@</span> <span class="p_context"> struct qla_qpair *qla2xxx_create_qpair(struct scsi_qla_host *vha, int qos, int v</span>
 		/* Assign available que pair id */
 		mutex_lock(&amp;ha-&gt;mq_lock);
 		qpair_id = find_first_zero_bit(ha-&gt;qpair_qid_map, ha-&gt;max_qpairs);
<span class="p_del">-		if (qpair_id &gt;= ha-&gt;max_qpairs) {</span>
<span class="p_add">+		if (ha-&gt;num_qpairs &gt;= ha-&gt;max_qpairs) {</span>
 			mutex_unlock(&amp;ha-&gt;mq_lock);
 			ql_log(ql_log_warn, vha, 0x0183,
 			    &quot;No resources to create additional q pair.\n&quot;);
 			goto fail_qid_map;
 		}
<span class="p_add">+		ha-&gt;num_qpairs++;</span>
 		set_bit(qpair_id, ha-&gt;qpair_qid_map);
 		ha-&gt;queue_pair_map[qpair_id] = qpair;
 		qpair-&gt;id = qpair_id;
<span class="p_chunk">@@ -7635,6 +7636,7 @@</span> <span class="p_context"> struct qla_qpair *qla2xxx_create_qpair(struct scsi_qla_host *vha, int qos, int v</span>
 fail_msix:
 	ha-&gt;queue_pair_map[qpair_id] = NULL;
 	clear_bit(qpair_id, ha-&gt;qpair_qid_map);
<span class="p_add">+	ha-&gt;num_qpairs--;</span>
 	mutex_unlock(&amp;ha-&gt;mq_lock);
 fail_qid_map:
 	kfree(qpair);
<span class="p_chunk">@@ -7660,6 +7662,7 @@</span> <span class="p_context"> int qla2xxx_delete_qpair(struct scsi_qla_host *vha, struct qla_qpair *qpair)</span>
 	mutex_lock(&amp;ha-&gt;mq_lock);
 	ha-&gt;queue_pair_map[qpair-&gt;id] = NULL;
 	clear_bit(qpair-&gt;id, ha-&gt;qpair_qid_map);
<span class="p_add">+	ha-&gt;num_qpairs--;</span>
 	list_del(&amp;qpair-&gt;qp_list_elem);
 	if (list_empty(&amp;vha-&gt;qp_list))
 		vha-&gt;flags.qpairs_available = 0;
<span class="p_header">diff --git a/drivers/scsi/qla2xxx/qla_isr.c b/drivers/scsi/qla2xxx/qla_isr.c</span>
<span class="p_header">index 3203367a4f42..189f72d5aa4f 100644</span>
<span class="p_header">--- a/drivers/scsi/qla2xxx/qla_isr.c</span>
<span class="p_header">+++ b/drivers/scsi/qla2xxx/qla_isr.c</span>
<span class="p_chunk">@@ -3282,7 +3282,7 @@</span> <span class="p_context"> qla24xx_enable_msix(struct qla_hw_data *ha, struct rsp_que *rsp)</span>
 	}
 
 	/* Enable MSI-X vector for response queue update for queue 0 */
<span class="p_del">-	if (IS_QLA83XX(ha) || IS_QLA27XX(ha)) {</span>
<span class="p_add">+	if (IS_QLA25XX(ha) || IS_QLA83XX(ha) || IS_QLA27XX(ha)) {</span>
 		if (ha-&gt;msixbase &amp;&amp; ha-&gt;mqiobase &amp;&amp;
 		    (ha-&gt;max_rsp_queues &gt; 1 || ha-&gt;max_req_queues &gt; 1 ||
 		     ql2xmqsupport))
<span class="p_header">diff --git a/drivers/scsi/qla2xxx/qla_mbx.c b/drivers/scsi/qla2xxx/qla_mbx.c</span>
<span class="p_header">index a113ab3592a7..cba1fc5e8be9 100644</span>
<span class="p_header">--- a/drivers/scsi/qla2xxx/qla_mbx.c</span>
<span class="p_header">+++ b/drivers/scsi/qla2xxx/qla_mbx.c</span>
<span class="p_chunk">@@ -3676,15 +3676,6 @@</span> <span class="p_context"> qla24xx_report_id_acquisition(scsi_qla_host_t *vha,</span>
 				qlt_update_host_map(vha, id);
 			}
 
<span class="p_del">-			fc_host_port_name(vha-&gt;host) =</span>
<span class="p_del">-			    wwn_to_u64(vha-&gt;port_name);</span>
<span class="p_del">-</span>
<span class="p_del">-			if (qla_ini_mode_enabled(vha))</span>
<span class="p_del">-				ql_dbg(ql_dbg_mbx, vha, 0x1018,</span>
<span class="p_del">-				    &quot;FA-WWN portname %016llx (%x)\n&quot;,</span>
<span class="p_del">-				    fc_host_port_name(vha-&gt;host),</span>
<span class="p_del">-				    rptid_entry-&gt;vp_status);</span>
<span class="p_del">-</span>
 			set_bit(REGISTER_FC4_NEEDED, &amp;vha-&gt;dpc_flags);
 			set_bit(REGISTER_FDMI_NEEDED, &amp;vha-&gt;dpc_flags);
 		} else {
<span class="p_chunk">@@ -4821,9 +4812,9 @@</span> <span class="p_context"> qla2x00_echo_test(scsi_qla_host_t *vha, struct msg_echo_lb *mreq,</span>
 
 	memset(mcp-&gt;mb, 0 , sizeof(mcp-&gt;mb));
 	mcp-&gt;mb[0] = MBC_DIAGNOSTIC_ECHO;
<span class="p_del">-	mcp-&gt;mb[1] = mreq-&gt;options | BIT_6;	/* BIT_6 specifies 64bit address */</span>
<span class="p_add">+	/* BIT_6 specifies 64bit address */</span>
<span class="p_add">+	mcp-&gt;mb[1] = mreq-&gt;options | BIT_15 | BIT_6;</span>
 	if (IS_CNA_CAPABLE(ha)) {
<span class="p_del">-		mcp-&gt;mb[1] |= BIT_15;</span>
 		mcp-&gt;mb[2] = vha-&gt;fcoe_fcf_idx;
 	}
 	mcp-&gt;mb[16] = LSW(mreq-&gt;rcv_dma);
<span class="p_header">diff --git a/drivers/scsi/qla2xxx/qla_os.c b/drivers/scsi/qla2xxx/qla_os.c</span>
<span class="p_header">index 83d61d2142e9..190f609317af 100644</span>
<span class="p_header">--- a/drivers/scsi/qla2xxx/qla_os.c</span>
<span class="p_header">+++ b/drivers/scsi/qla2xxx/qla_os.c</span>
<span class="p_chunk">@@ -2626,10 +2626,10 @@</span> <span class="p_context"> qla2x00_probe_one(struct pci_dev *pdev, const struct pci_device_id *id)</span>
 
 	if (mem_only) {
 		if (pci_enable_device_mem(pdev))
<span class="p_del">-			goto probe_out;</span>
<span class="p_add">+			return ret;</span>
 	} else {
 		if (pci_enable_device(pdev))
<span class="p_del">-			goto probe_out;</span>
<span class="p_add">+			return ret;</span>
 	}
 
 	/* This may fail but that&#39;s ok */
<span class="p_chunk">@@ -2639,7 +2639,7 @@</span> <span class="p_context"> qla2x00_probe_one(struct pci_dev *pdev, const struct pci_device_id *id)</span>
 	if (!ha) {
 		ql_log_pci(ql_log_fatal, pdev, 0x0009,
 		    &quot;Unable to allocate memory for ha.\n&quot;);
<span class="p_del">-		goto probe_out;</span>
<span class="p_add">+		goto disable_device;</span>
 	}
 	ql_dbg_pci(ql_dbg_init, pdev, 0x000a,
 	    &quot;Memory allocated for ha=%p.\n&quot;, ha);
<span class="p_chunk">@@ -3258,7 +3258,7 @@</span> <span class="p_context"> qla2x00_probe_one(struct pci_dev *pdev, const struct pci_device_id *id)</span>
 	kfree(ha);
 	ha = NULL;
 
<span class="p_del">-probe_out:</span>
<span class="p_add">+disable_device:</span>
 	pci_disable_device(pdev);
 	return ret;
 }
<span class="p_header">diff --git a/drivers/scsi/qla2xxx/qla_tmpl.c b/drivers/scsi/qla2xxx/qla_tmpl.c</span>
<span class="p_header">index 8a58ef3adab4..c197972a3e2d 100644</span>
<span class="p_header">--- a/drivers/scsi/qla2xxx/qla_tmpl.c</span>
<span class="p_header">+++ b/drivers/scsi/qla2xxx/qla_tmpl.c</span>
<span class="p_chunk">@@ -371,7 +371,7 @@</span> <span class="p_context"> qla27xx_fwdt_entry_t262(struct scsi_qla_host *vha,</span>
 		goto done;
 	}
 
<span class="p_del">-	if (end &lt;= start || start == 0 || end == 0) {</span>
<span class="p_add">+	if (end &lt; start || start == 0 || end == 0) {</span>
 		ql_dbg(ql_dbg_misc, vha, 0xd023,
 		    &quot;%s: unusable range (start=%x end=%x)\n&quot;, __func__,
 		    ent-&gt;t262.end_addr, ent-&gt;t262.start_addr);
<span class="p_header">diff --git a/drivers/staging/lustre/lustre/lov/lov_pack.c b/drivers/staging/lustre/lustre/lov/lov_pack.c</span>
<span class="p_header">index 2e1bd47337fd..e6727cefde05 100644</span>
<span class="p_header">--- a/drivers/staging/lustre/lustre/lov/lov_pack.c</span>
<span class="p_header">+++ b/drivers/staging/lustre/lustre/lov/lov_pack.c</span>
<span class="p_chunk">@@ -293,18 +293,10 @@</span> <span class="p_context"> int lov_getstripe(struct lov_object *obj, struct lov_stripe_md *lsm,</span>
 	size_t lmmk_size;
 	size_t lum_size;
 	int rc;
<span class="p_del">-	mm_segment_t seg;</span>
 
 	if (!lsm)
 		return -ENODATA;
 
<span class="p_del">-	/*</span>
<span class="p_del">-	 * &quot;Switch to kernel segment&quot; to allow copying from kernel space by</span>
<span class="p_del">-	 * copy_{to,from}_user().</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	seg = get_fs();</span>
<span class="p_del">-	set_fs(KERNEL_DS);</span>
<span class="p_del">-</span>
 	if (lsm-&gt;lsm_magic != LOV_MAGIC_V1 &amp;&amp; lsm-&gt;lsm_magic != LOV_MAGIC_V3) {
 		CERROR(&quot;bad LSM MAGIC: 0x%08X != 0x%08X nor 0x%08X\n&quot;,
 		       lsm-&gt;lsm_magic, LOV_MAGIC_V1, LOV_MAGIC_V3);
<span class="p_chunk">@@ -406,6 +398,5 @@</span> <span class="p_context"> int lov_getstripe(struct lov_object *obj, struct lov_stripe_md *lsm,</span>
 out_free:
 	kvfree(lmmk);
 out:
<span class="p_del">-	set_fs(seg);</span>
 	return rc;
 }
<span class="p_header">diff --git a/drivers/target/target_core_transport.c b/drivers/target/target_core_transport.c</span>
<span class="p_header">index a0cd56ee5fe9..ff26626d94ef 100644</span>
<span class="p_header">--- a/drivers/target/target_core_transport.c</span>
<span class="p_header">+++ b/drivers/target/target_core_transport.c</span>
<span class="p_chunk">@@ -1160,15 +1160,28 @@</span> <span class="p_context"> target_cmd_size_check(struct se_cmd *cmd, unsigned int size)</span>
 	if (cmd-&gt;unknown_data_length) {
 		cmd-&gt;data_length = size;
 	} else if (size != cmd-&gt;data_length) {
<span class="p_del">-		pr_warn(&quot;TARGET_CORE[%s]: Expected Transfer Length:&quot;</span>
<span class="p_add">+		pr_warn_ratelimited(&quot;TARGET_CORE[%s]: Expected Transfer Length:&quot;</span>
 			&quot; %u does not match SCSI CDB Length: %u for SAM Opcode:&quot;
 			&quot; 0x%02x\n&quot;, cmd-&gt;se_tfo-&gt;get_fabric_name(),
 				cmd-&gt;data_length, size, cmd-&gt;t_task_cdb[0]);
 
<span class="p_del">-		if (cmd-&gt;data_direction == DMA_TO_DEVICE &amp;&amp;</span>
<span class="p_del">-		    cmd-&gt;se_cmd_flags &amp; SCF_SCSI_DATA_CDB) {</span>
<span class="p_del">-			pr_err(&quot;Rejecting underflow/overflow WRITE data\n&quot;);</span>
<span class="p_del">-			return TCM_INVALID_CDB_FIELD;</span>
<span class="p_add">+		if (cmd-&gt;data_direction == DMA_TO_DEVICE) {</span>
<span class="p_add">+			if (cmd-&gt;se_cmd_flags &amp; SCF_SCSI_DATA_CDB) {</span>
<span class="p_add">+				pr_err_ratelimited(&quot;Rejecting underflow/overflow&quot;</span>
<span class="p_add">+						   &quot; for WRITE data CDB\n&quot;);</span>
<span class="p_add">+				return TCM_INVALID_CDB_FIELD;</span>
<span class="p_add">+			}</span>
<span class="p_add">+			/*</span>
<span class="p_add">+			 * Some fabric drivers like iscsi-target still expect to</span>
<span class="p_add">+			 * always reject overflow writes.  Reject this case until</span>
<span class="p_add">+			 * full fabric driver level support for overflow writes</span>
<span class="p_add">+			 * is introduced tree-wide.</span>
<span class="p_add">+			 */</span>
<span class="p_add">+			if (size &gt; cmd-&gt;data_length) {</span>
<span class="p_add">+				pr_err_ratelimited(&quot;Rejecting overflow for&quot;</span>
<span class="p_add">+						   &quot; WRITE control CDB\n&quot;);</span>
<span class="p_add">+				return TCM_INVALID_CDB_FIELD;</span>
<span class="p_add">+			}</span>
 		}
 		/*
 		 * Reject READ_* or WRITE_* with overflow/underflow for
<span class="p_header">diff --git a/drivers/tty/serial/8250/8250_port.c b/drivers/tty/serial/8250/8250_port.c</span>
<span class="p_header">index 4c26d15ad7d9..579706d36f5c 100644</span>
<span class="p_header">--- a/drivers/tty/serial/8250/8250_port.c</span>
<span class="p_header">+++ b/drivers/tty/serial/8250/8250_port.c</span>
<span class="p_chunk">@@ -47,6 +47,7 @@</span> <span class="p_context"></span>
 /*
  * These are definitions for the Exar XR17V35X and XR17(C|D)15X
  */
<span class="p_add">+#define UART_EXAR_INT0		0x80</span>
 #define UART_EXAR_SLEEP		0x8b	/* Sleep mode */
 #define UART_EXAR_DVID		0x8d	/* Device identification */
 
<span class="p_chunk">@@ -1869,17 +1870,13 @@</span> <span class="p_context"> static int serial8250_default_handle_irq(struct uart_port *port)</span>
 static int exar_handle_irq(struct uart_port *port)
 {
 	unsigned int iir = serial_port_in(port, UART_IIR);
<span class="p_del">-	int ret;</span>
<span class="p_add">+	int ret = 0;</span>
 
<span class="p_del">-	ret = serial8250_handle_irq(port, iir);</span>
<span class="p_add">+	if (((port-&gt;type == PORT_XR17V35X) || (port-&gt;type == PORT_XR17D15X)) &amp;&amp;</span>
<span class="p_add">+	    serial_port_in(port, UART_EXAR_INT0) != 0)</span>
<span class="p_add">+		ret = 1;</span>
 
<span class="p_del">-	if ((port-&gt;type == PORT_XR17V35X) ||</span>
<span class="p_del">-	   (port-&gt;type == PORT_XR17D15X)) {</span>
<span class="p_del">-		serial_port_in(port, 0x80);</span>
<span class="p_del">-		serial_port_in(port, 0x81);</span>
<span class="p_del">-		serial_port_in(port, 0x82);</span>
<span class="p_del">-		serial_port_in(port, 0x83);</span>
<span class="p_del">-	}</span>
<span class="p_add">+	ret |= serial8250_handle_irq(port, iir);</span>
 
 	return ret;
 }
<span class="p_chunk">@@ -2177,6 +2174,8 @@</span> <span class="p_context"> int serial8250_do_startup(struct uart_port *port)</span>
 	serial_port_in(port, UART_RX);
 	serial_port_in(port, UART_IIR);
 	serial_port_in(port, UART_MSR);
<span class="p_add">+	if ((port-&gt;type == PORT_XR17V35X) || (port-&gt;type == PORT_XR17D15X))</span>
<span class="p_add">+		serial_port_in(port, UART_EXAR_INT0);</span>
 
 	/*
 	 * At this point, there&#39;s no way the LSR could still be 0xff;
<span class="p_chunk">@@ -2335,6 +2334,8 @@</span> <span class="p_context"> int serial8250_do_startup(struct uart_port *port)</span>
 	serial_port_in(port, UART_RX);
 	serial_port_in(port, UART_IIR);
 	serial_port_in(port, UART_MSR);
<span class="p_add">+	if ((port-&gt;type == PORT_XR17V35X) || (port-&gt;type == PORT_XR17D15X))</span>
<span class="p_add">+		serial_port_in(port, UART_EXAR_INT0);</span>
 	up-&gt;lsr_saved_flags = 0;
 	up-&gt;msr_saved_flags = 0;
 
<span class="p_header">diff --git a/drivers/tty/serial/ifx6x60.c b/drivers/tty/serial/ifx6x60.c</span>
<span class="p_header">index 157883653256..f190a84a0246 100644</span>
<span class="p_header">--- a/drivers/tty/serial/ifx6x60.c</span>
<span class="p_header">+++ b/drivers/tty/serial/ifx6x60.c</span>
<span class="p_chunk">@@ -1382,9 +1382,9 @@</span> <span class="p_context"> static struct spi_driver ifx_spi_driver = {</span>
 static void __exit ifx_spi_exit(void)
 {
 	/* unregister */
<span class="p_add">+	spi_unregister_driver(&amp;ifx_spi_driver);</span>
 	tty_unregister_driver(tty_drv);
 	put_tty_driver(tty_drv);
<span class="p_del">-	spi_unregister_driver(&amp;ifx_spi_driver);</span>
 	unregister_reboot_notifier(&amp;ifx_modem_reboot_notifier_block);
 }
 
<span class="p_header">diff --git a/drivers/tty/serial/serial_core.c b/drivers/tty/serial/serial_core.c</span>
<span class="p_header">index 3fe56894974a..7f9139445f2a 100644</span>
<span class="p_header">--- a/drivers/tty/serial/serial_core.c</span>
<span class="p_header">+++ b/drivers/tty/serial/serial_core.c</span>
<span class="p_chunk">@@ -2083,7 +2083,7 @@</span> <span class="p_context"> int uart_suspend_port(struct uart_driver *drv, struct uart_port *uport)</span>
 	mutex_lock(&amp;port-&gt;mutex);
 
 	tty_dev = device_find_child(uport-&gt;dev, &amp;match, serial_match_port);
<span class="p_del">-	if (device_may_wakeup(tty_dev)) {</span>
<span class="p_add">+	if (tty_dev &amp;&amp; device_may_wakeup(tty_dev)) {</span>
 		if (!enable_irq_wake(uport-&gt;irq))
 			uport-&gt;irq_wake = 1;
 		put_device(tty_dev);
<span class="p_header">diff --git a/drivers/tty/serial/sh-sci.c b/drivers/tty/serial/sh-sci.c</span>
<span class="p_header">index 9a47cc4f16a2..1df57461ece4 100644</span>
<span class="p_header">--- a/drivers/tty/serial/sh-sci.c</span>
<span class="p_header">+++ b/drivers/tty/serial/sh-sci.c</span>
<span class="p_chunk">@@ -1985,11 +1985,13 @@</span> <span class="p_context"> static int sci_startup(struct uart_port *port)</span>
 
 	dev_dbg(port-&gt;dev, &quot;%s(%d)\n&quot;, __func__, port-&gt;line);
 
<span class="p_add">+	sci_request_dma(port);</span>
<span class="p_add">+</span>
 	ret = sci_request_irq(s);
<span class="p_del">-	if (unlikely(ret &lt; 0))</span>
<span class="p_add">+	if (unlikely(ret &lt; 0)) {</span>
<span class="p_add">+		sci_free_dma(port);</span>
 		return ret;
<span class="p_del">-</span>
<span class="p_del">-	sci_request_dma(port);</span>
<span class="p_add">+	}</span>
 
 	return 0;
 }
<span class="p_chunk">@@ -2021,8 +2023,8 @@</span> <span class="p_context"> static void sci_shutdown(struct uart_port *port)</span>
 	}
 #endif
 
<span class="p_del">-	sci_free_dma(port);</span>
 	sci_free_irq(s);
<span class="p_add">+	sci_free_dma(port);</span>
 }
 
 static int sci_sck_calc(struct sci_port *s, unsigned int bps,
<span class="p_header">diff --git a/drivers/usb/chipidea/debug.c b/drivers/usb/chipidea/debug.c</span>
<span class="p_header">index 6d23eede4d8c..1c31e8a08810 100644</span>
<span class="p_header">--- a/drivers/usb/chipidea/debug.c</span>
<span class="p_header">+++ b/drivers/usb/chipidea/debug.c</span>
<span class="p_chunk">@@ -294,7 +294,8 @@</span> <span class="p_context"> static int ci_role_show(struct seq_file *s, void *data)</span>
 {
 	struct ci_hdrc *ci = s-&gt;private;
 
<span class="p_del">-	seq_printf(s, &quot;%s\n&quot;, ci_role(ci)-&gt;name);</span>
<span class="p_add">+	if (ci-&gt;role != CI_ROLE_END)</span>
<span class="p_add">+		seq_printf(s, &quot;%s\n&quot;, ci_role(ci)-&gt;name);</span>
 
 	return 0;
 }
<span class="p_header">diff --git a/drivers/usb/chipidea/udc.c b/drivers/usb/chipidea/udc.c</span>
<span class="p_header">index f88e9157fad0..60a786c87c06 100644</span>
<span class="p_header">--- a/drivers/usb/chipidea/udc.c</span>
<span class="p_header">+++ b/drivers/usb/chipidea/udc.c</span>
<span class="p_chunk">@@ -1984,6 +1984,7 @@</span> <span class="p_context"> static void udc_id_switch_for_host(struct ci_hdrc *ci)</span>
 int ci_hdrc_gadget_init(struct ci_hdrc *ci)
 {
 	struct ci_role_driver *rdrv;
<span class="p_add">+	int ret;</span>
 
 	if (!hw_read(ci, CAP_DCCPARAMS, DCCPARAMS_DC))
 		return -ENXIO;
<span class="p_chunk">@@ -1996,7 +1997,10 @@</span> <span class="p_context"> int ci_hdrc_gadget_init(struct ci_hdrc *ci)</span>
 	rdrv-&gt;stop	= udc_id_switch_for_host;
 	rdrv-&gt;irq	= udc_irq;
 	rdrv-&gt;name	= &quot;gadget&quot;;
<span class="p_del">-	ci-&gt;roles[CI_ROLE_GADGET] = rdrv;</span>
 
<span class="p_del">-	return udc_start(ci);</span>
<span class="p_add">+	ret = udc_start(ci);</span>
<span class="p_add">+	if (!ret)</span>
<span class="p_add">+		ci-&gt;roles[CI_ROLE_GADGET] = rdrv;</span>
<span class="p_add">+</span>
<span class="p_add">+	return ret;</span>
 }
<span class="p_header">diff --git a/drivers/usb/chipidea/usbmisc_imx.c b/drivers/usb/chipidea/usbmisc_imx.c</span>
<span class="p_header">index e77a4ed4f021..9f4a0185dd60 100644</span>
<span class="p_header">--- a/drivers/usb/chipidea/usbmisc_imx.c</span>
<span class="p_header">+++ b/drivers/usb/chipidea/usbmisc_imx.c</span>
<span class="p_chunk">@@ -108,6 +108,8 @@</span> <span class="p_context"> struct imx_usbmisc {</span>
 	const struct usbmisc_ops *ops;
 };
 
<span class="p_add">+static inline bool is_imx53_usbmisc(struct imx_usbmisc_data *data);</span>
<span class="p_add">+</span>
 static int usbmisc_imx25_init(struct imx_usbmisc_data *data)
 {
 	struct imx_usbmisc *usbmisc = dev_get_drvdata(data-&gt;dev);
<span class="p_chunk">@@ -242,10 +244,15 @@</span> <span class="p_context"> static int usbmisc_imx53_init(struct imx_usbmisc_data *data)</span>
 			val = readl(reg) | MX53_USB_UHx_CTRL_WAKE_UP_EN
 				| MX53_USB_UHx_CTRL_ULPI_INT_EN;
 			writel(val, reg);
<span class="p_del">-			/* Disable internal 60Mhz clock */</span>
<span class="p_del">-			reg = usbmisc-&gt;base + MX53_USB_CLKONOFF_CTRL_OFFSET;</span>
<span class="p_del">-			val = readl(reg) | MX53_USB_CLKONOFF_CTRL_H2_INT60CKOFF;</span>
<span class="p_del">-			writel(val, reg);</span>
<span class="p_add">+			if (is_imx53_usbmisc(data)) {</span>
<span class="p_add">+				/* Disable internal 60Mhz clock */</span>
<span class="p_add">+				reg = usbmisc-&gt;base +</span>
<span class="p_add">+					MX53_USB_CLKONOFF_CTRL_OFFSET;</span>
<span class="p_add">+				val = readl(reg) |</span>
<span class="p_add">+					MX53_USB_CLKONOFF_CTRL_H2_INT60CKOFF;</span>
<span class="p_add">+				writel(val, reg);</span>
<span class="p_add">+			}</span>
<span class="p_add">+</span>
 		}
 		if (data-&gt;disable_oc) {
 			reg = usbmisc-&gt;base + MX53_USB_UH2_CTRL_OFFSET;
<span class="p_chunk">@@ -267,10 +274,15 @@</span> <span class="p_context"> static int usbmisc_imx53_init(struct imx_usbmisc_data *data)</span>
 			val = readl(reg) | MX53_USB_UHx_CTRL_WAKE_UP_EN
 				| MX53_USB_UHx_CTRL_ULPI_INT_EN;
 			writel(val, reg);
<span class="p_del">-			/* Disable internal 60Mhz clock */</span>
<span class="p_del">-			reg = usbmisc-&gt;base + MX53_USB_CLKONOFF_CTRL_OFFSET;</span>
<span class="p_del">-			val = readl(reg) | MX53_USB_CLKONOFF_CTRL_H3_INT60CKOFF;</span>
<span class="p_del">-			writel(val, reg);</span>
<span class="p_add">+</span>
<span class="p_add">+			if (is_imx53_usbmisc(data)) {</span>
<span class="p_add">+				/* Disable internal 60Mhz clock */</span>
<span class="p_add">+				reg = usbmisc-&gt;base +</span>
<span class="p_add">+					MX53_USB_CLKONOFF_CTRL_OFFSET;</span>
<span class="p_add">+				val = readl(reg) |</span>
<span class="p_add">+					MX53_USB_CLKONOFF_CTRL_H3_INT60CKOFF;</span>
<span class="p_add">+				writel(val, reg);</span>
<span class="p_add">+			}</span>
 		}
 		if (data-&gt;disable_oc) {
 			reg = usbmisc-&gt;base + MX53_USB_UH3_CTRL_OFFSET;
<span class="p_chunk">@@ -456,6 +468,10 @@</span> <span class="p_context"> static const struct usbmisc_ops imx27_usbmisc_ops = {</span>
 	.init = usbmisc_imx27_init,
 };
 
<span class="p_add">+static const struct usbmisc_ops imx51_usbmisc_ops = {</span>
<span class="p_add">+	.init = usbmisc_imx53_init,</span>
<span class="p_add">+};</span>
<span class="p_add">+</span>
 static const struct usbmisc_ops imx53_usbmisc_ops = {
 	.init = usbmisc_imx53_init,
 };
<span class="p_chunk">@@ -479,6 +495,13 @@</span> <span class="p_context"> static const struct usbmisc_ops imx7d_usbmisc_ops = {</span>
 	.set_wakeup = usbmisc_imx7d_set_wakeup,
 };
 
<span class="p_add">+static inline bool is_imx53_usbmisc(struct imx_usbmisc_data *data)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct imx_usbmisc *usbmisc = dev_get_drvdata(data-&gt;dev);</span>
<span class="p_add">+</span>
<span class="p_add">+	return usbmisc-&gt;ops == &amp;imx53_usbmisc_ops;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 int imx_usbmisc_init(struct imx_usbmisc_data *data)
 {
 	struct imx_usbmisc *usbmisc;
<span class="p_chunk">@@ -536,7 +559,7 @@</span> <span class="p_context"> static const struct of_device_id usbmisc_imx_dt_ids[] = {</span>
 	},
 	{
 		.compatible = &quot;fsl,imx51-usbmisc&quot;,
<span class="p_del">-		.data = &amp;imx53_usbmisc_ops,</span>
<span class="p_add">+		.data = &amp;imx51_usbmisc_ops,</span>
 	},
 	{
 		.compatible = &quot;fsl,imx53-usbmisc&quot;,
<span class="p_header">diff --git a/drivers/usb/gadget/function/f_mass_storage.c b/drivers/usb/gadget/function/f_mass_storage.c</span>
<span class="p_header">index 4c8aacc232c0..74d57d6994da 100644</span>
<span class="p_header">--- a/drivers/usb/gadget/function/f_mass_storage.c</span>
<span class="p_header">+++ b/drivers/usb/gadget/function/f_mass_storage.c</span>
<span class="p_chunk">@@ -396,7 +396,11 @@</span> <span class="p_context"> static int fsg_set_halt(struct fsg_dev *fsg, struct usb_ep *ep)</span>
 /* Caller must hold fsg-&gt;lock */
 static void wakeup_thread(struct fsg_common *common)
 {
<span class="p_del">-	smp_wmb();	/* ensure the write of bh-&gt;state is complete */</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Ensure the reading of thread_wakeup_needed</span>
<span class="p_add">+	 * and the writing of bh-&gt;state are completed</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	smp_mb();</span>
 	/* Tell the main thread that something has happened */
 	common-&gt;thread_wakeup_needed = 1;
 	if (common-&gt;thread_task)
<span class="p_chunk">@@ -627,7 +631,12 @@</span> <span class="p_context"> static int sleep_thread(struct fsg_common *common, bool can_freeze)</span>
 	}
 	__set_current_state(TASK_RUNNING);
 	common-&gt;thread_wakeup_needed = 0;
<span class="p_del">-	smp_rmb();	/* ensure the latest bh-&gt;state is visible */</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Ensure the writing of thread_wakeup_needed</span>
<span class="p_add">+	 * and the reading of bh-&gt;state are completed</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	smp_mb();</span>
 	return rc;
 }
 
<span class="p_header">diff --git a/drivers/usb/musb/musb_dsps.c b/drivers/usb/musb/musb_dsps.c</span>
<span class="p_header">index 9c7ee26ef388..bc6a9be2ccc5 100644</span>
<span class="p_header">--- a/drivers/usb/musb/musb_dsps.c</span>
<span class="p_header">+++ b/drivers/usb/musb/musb_dsps.c</span>
<span class="p_chunk">@@ -245,6 +245,11 @@</span> <span class="p_context"> static int dsps_check_status(struct musb *musb, void *unused)</span>
 		dsps_mod_timer_optional(glue);
 		break;
 	case OTG_STATE_A_WAIT_BCON:
<span class="p_add">+		/* keep VBUS on for host-only mode */</span>
<span class="p_add">+		if (musb-&gt;port_mode == MUSB_PORT_MODE_HOST) {</span>
<span class="p_add">+			dsps_mod_timer_optional(glue);</span>
<span class="p_add">+			break;</span>
<span class="p_add">+		}</span>
 		musb_writeb(musb-&gt;mregs, MUSB_DEVCTL, 0);
 		skip_session = 1;
 		/* fall */
<span class="p_header">diff --git a/drivers/xen/privcmd.c b/drivers/xen/privcmd.c</span>
<span class="p_header">index 7a92a5e1d40c..feca75b07fdd 100644</span>
<span class="p_header">--- a/drivers/xen/privcmd.c</span>
<span class="p_header">+++ b/drivers/xen/privcmd.c</span>
<span class="p_chunk">@@ -362,8 +362,8 @@</span> <span class="p_context"> static int mmap_batch_fn(void *data, int nr, void *state)</span>
 				st-&gt;global_error = 1;
 		}
 	}
<span class="p_del">-	st-&gt;va += PAGE_SIZE * nr;</span>
<span class="p_del">-	st-&gt;index += nr;</span>
<span class="p_add">+	st-&gt;va += XEN_PAGE_SIZE * nr;</span>
<span class="p_add">+	st-&gt;index += nr / XEN_PFN_PER_PAGE;</span>
 
 	return 0;
 }
<span class="p_header">diff --git a/fs/btrfs/ctree.h b/fs/btrfs/ctree.h</span>
<span class="p_header">index c4115901d906..7a945a1f076b 100644</span>
<span class="p_header">--- a/fs/btrfs/ctree.h</span>
<span class="p_header">+++ b/fs/btrfs/ctree.h</span>
<span class="p_chunk">@@ -2547,7 +2547,7 @@</span> <span class="p_context"> u64 btrfs_csum_bytes_to_leaves(struct btrfs_fs_info *fs_info, u64 csum_bytes);</span>
 static inline u64 btrfs_calc_trans_metadata_size(struct btrfs_fs_info *fs_info,
 						 unsigned num_items)
 {
<span class="p_del">-	return fs_info-&gt;nodesize * BTRFS_MAX_LEVEL * 2 * num_items;</span>
<span class="p_add">+	return (u64)fs_info-&gt;nodesize * BTRFS_MAX_LEVEL * 2 * num_items;</span>
 }
 
 /*
<span class="p_chunk">@@ -2557,7 +2557,7 @@</span> <span class="p_context"> static inline u64 btrfs_calc_trans_metadata_size(struct btrfs_fs_info *fs_info,</span>
 static inline u64 btrfs_calc_trunc_metadata_size(struct btrfs_fs_info *fs_info,
 						 unsigned num_items)
 {
<span class="p_del">-	return fs_info-&gt;nodesize * BTRFS_MAX_LEVEL * num_items;</span>
<span class="p_add">+	return (u64)fs_info-&gt;nodesize * BTRFS_MAX_LEVEL * num_items;</span>
 }
 
 int btrfs_should_throttle_delayed_refs(struct btrfs_trans_handle *trans,
<span class="p_header">diff --git a/fs/btrfs/extent-tree.c b/fs/btrfs/extent-tree.c</span>
<span class="p_header">index be5477676cc8..ed3fefc9e5e7 100644</span>
<span class="p_header">--- a/fs/btrfs/extent-tree.c</span>
<span class="p_header">+++ b/fs/btrfs/extent-tree.c</span>
<span class="p_chunk">@@ -3983,6 +3983,7 @@</span> <span class="p_context"> static int update_space_info(struct btrfs_fs_info *info, u64 flags,</span>
 				    info-&gt;space_info_kobj, &quot;%s&quot;,
 				    alloc_name(found-&gt;flags));
 	if (ret) {
<span class="p_add">+		percpu_counter_destroy(&amp;found-&gt;total_bytes_pinned);</span>
 		kfree(found);
 		return ret;
 	}
<span class="p_chunk">@@ -4834,7 +4835,7 @@</span> <span class="p_context"> static int may_commit_transaction(struct btrfs_fs_info *fs_info,</span>
 	spin_unlock(&amp;delayed_rsv-&gt;lock);
 
 commit:
<span class="p_del">-	trans = btrfs_join_transaction(fs_info-&gt;fs_root);</span>
<span class="p_add">+	trans = btrfs_join_transaction(fs_info-&gt;extent_root);</span>
 	if (IS_ERR(trans))
 		return -ENOSPC;
 
<span class="p_chunk">@@ -4852,7 +4853,7 @@</span> <span class="p_context"> static int flush_space(struct btrfs_fs_info *fs_info,</span>
 		       struct btrfs_space_info *space_info, u64 num_bytes,
 		       u64 orig_bytes, int state)
 {
<span class="p_del">-	struct btrfs_root *root = fs_info-&gt;fs_root;</span>
<span class="p_add">+	struct btrfs_root *root = fs_info-&gt;extent_root;</span>
 	struct btrfs_trans_handle *trans;
 	int nr;
 	int ret = 0;
<span class="p_chunk">@@ -5052,7 +5053,7 @@</span> <span class="p_context"> static void priority_reclaim_metadata_space(struct btrfs_fs_info *fs_info,</span>
 	int flush_state = FLUSH_DELAYED_ITEMS_NR;
 
 	spin_lock(&amp;space_info-&gt;lock);
<span class="p_del">-	to_reclaim = btrfs_calc_reclaim_metadata_size(fs_info-&gt;fs_root,</span>
<span class="p_add">+	to_reclaim = btrfs_calc_reclaim_metadata_size(fs_info-&gt;extent_root,</span>
 						      space_info);
 	if (!to_reclaim) {
 		spin_unlock(&amp;space_info-&gt;lock);
<span class="p_header">diff --git a/fs/btrfs/inode.c b/fs/btrfs/inode.c</span>
<span class="p_header">index 5e71f1ea3391..65fc76a47094 100644</span>
<span class="p_header">--- a/fs/btrfs/inode.c</span>
<span class="p_header">+++ b/fs/btrfs/inode.c</span>
<span class="p_chunk">@@ -7359,8 +7359,8 @@</span> <span class="p_context"> bool btrfs_page_exists_in_range(struct inode *inode, loff_t start, loff_t end)</span>
 	int found = false;
 	void **pagep = NULL;
 	struct page *page = NULL;
<span class="p_del">-	int start_idx;</span>
<span class="p_del">-	int end_idx;</span>
<span class="p_add">+	unsigned long start_idx;</span>
<span class="p_add">+	unsigned long end_idx;</span>
 
 	start_idx = start &gt;&gt; PAGE_SHIFT;
 
<span class="p_header">diff --git a/fs/ext4/extents.c b/fs/ext4/extents.c</span>
<span class="p_header">index 2a97dff87b96..3e36508610b7 100644</span>
<span class="p_header">--- a/fs/ext4/extents.c</span>
<span class="p_header">+++ b/fs/ext4/extents.c</span>
<span class="p_chunk">@@ -3413,13 +3413,13 @@</span> <span class="p_context"> static int ext4_ext_convert_to_initialized(handle_t *handle,</span>
 	struct ext4_sb_info *sbi;
 	struct ext4_extent_header *eh;
 	struct ext4_map_blocks split_map;
<span class="p_del">-	struct ext4_extent zero_ex;</span>
<span class="p_add">+	struct ext4_extent zero_ex1, zero_ex2;</span>
 	struct ext4_extent *ex, *abut_ex;
 	ext4_lblk_t ee_block, eof_block;
 	unsigned int ee_len, depth, map_len = map-&gt;m_len;
 	int allocated = 0, max_zeroout = 0;
 	int err = 0;
<span class="p_del">-	int split_flag = 0;</span>
<span class="p_add">+	int split_flag = EXT4_EXT_DATA_VALID2;</span>
 
 	ext_debug(&quot;ext4_ext_convert_to_initialized: inode %lu, logical&quot;
 		&quot;block %llu, max_blocks %u\n&quot;, inode-&gt;i_ino,
<span class="p_chunk">@@ -3436,7 +3436,8 @@</span> <span class="p_context"> static int ext4_ext_convert_to_initialized(handle_t *handle,</span>
 	ex = path[depth].p_ext;
 	ee_block = le32_to_cpu(ex-&gt;ee_block);
 	ee_len = ext4_ext_get_actual_len(ex);
<span class="p_del">-	zero_ex.ee_len = 0;</span>
<span class="p_add">+	zero_ex1.ee_len = 0;</span>
<span class="p_add">+	zero_ex2.ee_len = 0;</span>
 
 	trace_ext4_ext_convert_to_initialized_enter(inode, map, ex);
 
<span class="p_chunk">@@ -3576,62 +3577,52 @@</span> <span class="p_context"> static int ext4_ext_convert_to_initialized(handle_t *handle,</span>
 	if (ext4_encrypted_inode(inode))
 		max_zeroout = 0;
 
<span class="p_del">-	/* If extent is less than s_max_zeroout_kb, zeroout directly */</span>
<span class="p_del">-	if (max_zeroout &amp;&amp; (ee_len &lt;= max_zeroout)) {</span>
<span class="p_del">-		err = ext4_ext_zeroout(inode, ex);</span>
<span class="p_del">-		if (err)</span>
<span class="p_del">-			goto out;</span>
<span class="p_del">-		zero_ex.ee_block = ex-&gt;ee_block;</span>
<span class="p_del">-		zero_ex.ee_len = cpu_to_le16(ext4_ext_get_actual_len(ex));</span>
<span class="p_del">-		ext4_ext_store_pblock(&amp;zero_ex, ext4_ext_pblock(ex));</span>
<span class="p_del">-</span>
<span class="p_del">-		err = ext4_ext_get_access(handle, inode, path + depth);</span>
<span class="p_del">-		if (err)</span>
<span class="p_del">-			goto out;</span>
<span class="p_del">-		ext4_ext_mark_initialized(ex);</span>
<span class="p_del">-		ext4_ext_try_to_merge(handle, inode, path, ex);</span>
<span class="p_del">-		err = ext4_ext_dirty(handle, inode, path + path-&gt;p_depth);</span>
<span class="p_del">-		goto out;</span>
<span class="p_del">-	}</span>
<span class="p_del">-</span>
 	/*
<span class="p_del">-	 * four cases:</span>
<span class="p_add">+	 * five cases:</span>
 	 * 1. split the extent into three extents.
<span class="p_del">-	 * 2. split the extent into two extents, zeroout the first half.</span>
<span class="p_del">-	 * 3. split the extent into two extents, zeroout the second half.</span>
<span class="p_add">+	 * 2. split the extent into two extents, zeroout the head of the first</span>
<span class="p_add">+	 *    extent.</span>
<span class="p_add">+	 * 3. split the extent into two extents, zeroout the tail of the second</span>
<span class="p_add">+	 *    extent.</span>
 	 * 4. split the extent into two extents with out zeroout.
<span class="p_add">+	 * 5. no splitting needed, just possibly zeroout the head and / or the</span>
<span class="p_add">+	 *    tail of the extent.</span>
 	 */
 	split_map.m_lblk = map-&gt;m_lblk;
 	split_map.m_len = map-&gt;m_len;
 
<span class="p_del">-	if (max_zeroout &amp;&amp; (allocated &gt; map-&gt;m_len)) {</span>
<span class="p_add">+	if (max_zeroout &amp;&amp; (allocated &gt; split_map.m_len)) {</span>
 		if (allocated &lt;= max_zeroout) {
<span class="p_del">-			/* case 3 */</span>
<span class="p_del">-			zero_ex.ee_block =</span>
<span class="p_del">-					 cpu_to_le32(map-&gt;m_lblk);</span>
<span class="p_del">-			zero_ex.ee_len = cpu_to_le16(allocated);</span>
<span class="p_del">-			ext4_ext_store_pblock(&amp;zero_ex,</span>
<span class="p_del">-				ext4_ext_pblock(ex) + map-&gt;m_lblk - ee_block);</span>
<span class="p_del">-			err = ext4_ext_zeroout(inode, &amp;zero_ex);</span>
<span class="p_add">+			/* case 3 or 5 */</span>
<span class="p_add">+			zero_ex1.ee_block =</span>
<span class="p_add">+				 cpu_to_le32(split_map.m_lblk +</span>
<span class="p_add">+					     split_map.m_len);</span>
<span class="p_add">+			zero_ex1.ee_len =</span>
<span class="p_add">+				cpu_to_le16(allocated - split_map.m_len);</span>
<span class="p_add">+			ext4_ext_store_pblock(&amp;zero_ex1,</span>
<span class="p_add">+				ext4_ext_pblock(ex) + split_map.m_lblk +</span>
<span class="p_add">+				split_map.m_len - ee_block);</span>
<span class="p_add">+			err = ext4_ext_zeroout(inode, &amp;zero_ex1);</span>
 			if (err)
 				goto out;
<span class="p_del">-			split_map.m_lblk = map-&gt;m_lblk;</span>
 			split_map.m_len = allocated;
<span class="p_del">-		} else if (map-&gt;m_lblk - ee_block + map-&gt;m_len &lt; max_zeroout) {</span>
<span class="p_del">-			/* case 2 */</span>
<span class="p_del">-			if (map-&gt;m_lblk != ee_block) {</span>
<span class="p_del">-				zero_ex.ee_block = ex-&gt;ee_block;</span>
<span class="p_del">-				zero_ex.ee_len = cpu_to_le16(map-&gt;m_lblk -</span>
<span class="p_add">+		}</span>
<span class="p_add">+		if (split_map.m_lblk - ee_block + split_map.m_len &lt;</span>
<span class="p_add">+								max_zeroout) {</span>
<span class="p_add">+			/* case 2 or 5 */</span>
<span class="p_add">+			if (split_map.m_lblk != ee_block) {</span>
<span class="p_add">+				zero_ex2.ee_block = ex-&gt;ee_block;</span>
<span class="p_add">+				zero_ex2.ee_len = cpu_to_le16(split_map.m_lblk -</span>
 							ee_block);
<span class="p_del">-				ext4_ext_store_pblock(&amp;zero_ex,</span>
<span class="p_add">+				ext4_ext_store_pblock(&amp;zero_ex2,</span>
 						      ext4_ext_pblock(ex));
<span class="p_del">-				err = ext4_ext_zeroout(inode, &amp;zero_ex);</span>
<span class="p_add">+				err = ext4_ext_zeroout(inode, &amp;zero_ex2);</span>
 				if (err)
 					goto out;
 			}
 
<span class="p_add">+			split_map.m_len += split_map.m_lblk - ee_block;</span>
 			split_map.m_lblk = ee_block;
<span class="p_del">-			split_map.m_len = map-&gt;m_lblk - ee_block + map-&gt;m_len;</span>
 			allocated = map-&gt;m_len;
 		}
 	}
<span class="p_chunk">@@ -3642,8 +3633,11 @@</span> <span class="p_context"> static int ext4_ext_convert_to_initialized(handle_t *handle,</span>
 		err = 0;
 out:
 	/* If we have gotten a failure, don&#39;t zero out status tree */
<span class="p_del">-	if (!err)</span>
<span class="p_del">-		err = ext4_zeroout_es(inode, &amp;zero_ex);</span>
<span class="p_add">+	if (!err) {</span>
<span class="p_add">+		err = ext4_zeroout_es(inode, &amp;zero_ex1);</span>
<span class="p_add">+		if (!err)</span>
<span class="p_add">+			err = ext4_zeroout_es(inode, &amp;zero_ex2);</span>
<span class="p_add">+	}</span>
 	return err ? err : allocated;
 }
 
<span class="p_chunk">@@ -4883,6 +4877,8 @@</span> <span class="p_context"> static long ext4_zero_range(struct file *file, loff_t offset,</span>
 
 	/* Zero out partial block at the edges of the range */
 	ret = ext4_zero_partial_blocks(handle, inode, offset, len);
<span class="p_add">+	if (ret &gt;= 0)</span>
<span class="p_add">+		ext4_update_inode_fsync_trans(handle, inode, 1);</span>
 
 	if (file-&gt;f_flags &amp; O_SYNC)
 		ext4_handle_sync(handle);
<span class="p_chunk">@@ -5569,6 +5565,7 @@</span> <span class="p_context"> int ext4_collapse_range(struct inode *inode, loff_t offset, loff_t len)</span>
 		ext4_handle_sync(handle);
 	inode-&gt;i_mtime = inode-&gt;i_ctime = current_time(inode);
 	ext4_mark_inode_dirty(handle, inode);
<span class="p_add">+	ext4_update_inode_fsync_trans(handle, inode, 1);</span>
 
 out_stop:
 	ext4_journal_stop(handle);
<span class="p_chunk">@@ -5742,6 +5739,8 @@</span> <span class="p_context"> int ext4_insert_range(struct inode *inode, loff_t offset, loff_t len)</span>
 	up_write(&amp;EXT4_I(inode)-&gt;i_data_sem);
 	if (IS_SYNC(inode))
 		ext4_handle_sync(handle);
<span class="p_add">+	if (ret &gt;= 0)</span>
<span class="p_add">+		ext4_update_inode_fsync_trans(handle, inode, 1);</span>
 
 out_stop:
 	ext4_journal_stop(handle);
<span class="p_header">diff --git a/fs/ext4/file.c b/fs/ext4/file.c</span>
<span class="p_header">index 831fd6beebf0..bbea2dccd584 100644</span>
<span class="p_header">--- a/fs/ext4/file.c</span>
<span class="p_header">+++ b/fs/ext4/file.c</span>
<span class="p_chunk">@@ -484,47 +484,27 @@</span> <span class="p_context"> static int ext4_find_unwritten_pgoff(struct inode *inode,</span>
 		num = min_t(pgoff_t, end - index, PAGEVEC_SIZE);
 		nr_pages = pagevec_lookup(&amp;pvec, inode-&gt;i_mapping, index,
 					  (pgoff_t)num);
<span class="p_del">-		if (nr_pages == 0) {</span>
<span class="p_del">-			if (whence == SEEK_DATA)</span>
<span class="p_del">-				break;</span>
<span class="p_del">-</span>
<span class="p_del">-			BUG_ON(whence != SEEK_HOLE);</span>
<span class="p_del">-			/*</span>
<span class="p_del">-			 * If this is the first time to go into the loop and</span>
<span class="p_del">-			 * offset is not beyond the end offset, it will be a</span>
<span class="p_del">-			 * hole at this offset</span>
<span class="p_del">-			 */</span>
<span class="p_del">-			if (lastoff == startoff || lastoff &lt; endoff)</span>
<span class="p_del">-				found = 1;</span>
<span class="p_del">-			break;</span>
<span class="p_del">-		}</span>
<span class="p_del">-</span>
<span class="p_del">-		/*</span>
<span class="p_del">-		 * If this is the first time to go into the loop and</span>
<span class="p_del">-		 * offset is smaller than the first page offset, it will be a</span>
<span class="p_del">-		 * hole at this offset.</span>
<span class="p_del">-		 */</span>
<span class="p_del">-		if (lastoff == startoff &amp;&amp; whence == SEEK_HOLE &amp;&amp;</span>
<span class="p_del">-		    lastoff &lt; page_offset(pvec.pages[0])) {</span>
<span class="p_del">-			found = 1;</span>
<span class="p_add">+		if (nr_pages == 0)</span>
 			break;
<span class="p_del">-		}</span>
 
 		for (i = 0; i &lt; nr_pages; i++) {
 			struct page *page = pvec.pages[i];
 			struct buffer_head *bh, *head;
 
 			/*
<span class="p_del">-			 * If the current offset is not beyond the end of given</span>
<span class="p_del">-			 * range, it will be a hole.</span>
<span class="p_add">+			 * If current offset is smaller than the page offset,</span>
<span class="p_add">+			 * there is a hole at this offset.</span>
 			 */
<span class="p_del">-			if (lastoff &lt; endoff &amp;&amp; whence == SEEK_HOLE &amp;&amp;</span>
<span class="p_del">-			    page-&gt;index &gt; end) {</span>
<span class="p_add">+			if (whence == SEEK_HOLE &amp;&amp; lastoff &lt; endoff &amp;&amp;</span>
<span class="p_add">+			    lastoff &lt; page_offset(pvec.pages[i])) {</span>
 				found = 1;
 				*offset = lastoff;
 				goto out;
 			}
 
<span class="p_add">+			if (page-&gt;index &gt; end)</span>
<span class="p_add">+				goto out;</span>
<span class="p_add">+</span>
 			lock_page(page);
 
 			if (unlikely(page-&gt;mapping != inode-&gt;i_mapping)) {
<span class="p_chunk">@@ -564,20 +544,18 @@</span> <span class="p_context"> static int ext4_find_unwritten_pgoff(struct inode *inode,</span>
 			unlock_page(page);
 		}
 
<span class="p_del">-		/*</span>
<span class="p_del">-		 * The no. of pages is less than our desired, that would be a</span>
<span class="p_del">-		 * hole in there.</span>
<span class="p_del">-		 */</span>
<span class="p_del">-		if (nr_pages &lt; num &amp;&amp; whence == SEEK_HOLE) {</span>
<span class="p_del">-			found = 1;</span>
<span class="p_del">-			*offset = lastoff;</span>
<span class="p_add">+		/* The no. of pages is less than our desired, we are done. */</span>
<span class="p_add">+		if (nr_pages &lt; num)</span>
 			break;
<span class="p_del">-		}</span>
 
 		index = pvec.pages[i - 1]-&gt;index + 1;
 		pagevec_release(&amp;pvec);
 	} while (index &lt;= end);
 
<span class="p_add">+	if (whence == SEEK_HOLE &amp;&amp; lastoff &lt; endoff) {</span>
<span class="p_add">+		found = 1;</span>
<span class="p_add">+		*offset = lastoff;</span>
<span class="p_add">+	}</span>
 out:
 	pagevec_release(&amp;pvec);
 	return found;
<span class="p_header">diff --git a/fs/ext4/inode.c b/fs/ext4/inode.c</span>
<span class="p_header">index 88203ae5b154..7090752ec2cb 100644</span>
<span class="p_header">--- a/fs/ext4/inode.c</span>
<span class="p_header">+++ b/fs/ext4/inode.c</span>
<span class="p_chunk">@@ -4165,6 +4165,8 @@</span> <span class="p_context"> int ext4_punch_hole(struct inode *inode, loff_t offset, loff_t length)</span>
 
 	inode-&gt;i_mtime = inode-&gt;i_ctime = current_time(inode);
 	ext4_mark_inode_dirty(handle, inode);
<span class="p_add">+	if (ret &gt;= 0)</span>
<span class="p_add">+		ext4_update_inode_fsync_trans(handle, inode, 1);</span>
 out_stop:
 	ext4_journal_stop(handle);
 out_dio:
<span class="p_chunk">@@ -5621,8 +5623,9 @@</span> <span class="p_context"> static int ext4_expand_extra_isize(struct inode *inode,</span>
 	/* No extended attributes present */
 	if (!ext4_test_inode_state(inode, EXT4_STATE_XATTR) ||
 	    header-&gt;h_magic != cpu_to_le32(EXT4_XATTR_MAGIC)) {
<span class="p_del">-		memset((void *)raw_inode + EXT4_GOOD_OLD_INODE_SIZE, 0,</span>
<span class="p_del">-			new_extra_isize);</span>
<span class="p_add">+		memset((void *)raw_inode + EXT4_GOOD_OLD_INODE_SIZE +</span>
<span class="p_add">+		       EXT4_I(inode)-&gt;i_extra_isize, 0,</span>
<span class="p_add">+		       new_extra_isize - EXT4_I(inode)-&gt;i_extra_isize);</span>
 		EXT4_I(inode)-&gt;i_extra_isize = new_extra_isize;
 		return 0;
 	}
<span class="p_header">diff --git a/fs/gfs2/log.c b/fs/gfs2/log.c</span>
<span class="p_header">index f865b96374df..d2955daf17a4 100644</span>
<span class="p_header">--- a/fs/gfs2/log.c</span>
<span class="p_header">+++ b/fs/gfs2/log.c</span>
<span class="p_chunk">@@ -659,7 +659,7 @@</span> <span class="p_context"> static void log_write_header(struct gfs2_sbd *sdp, u32 flags)</span>
 	struct gfs2_log_header *lh;
 	unsigned int tail;
 	u32 hash;
<span class="p_del">-	int op_flags = REQ_PREFLUSH | REQ_FUA | REQ_META;</span>
<span class="p_add">+	int op_flags = REQ_PREFLUSH | REQ_FUA | REQ_META | REQ_SYNC;</span>
 	struct page *page = mempool_alloc(gfs2_page_pool, GFP_NOIO);
 	enum gfs2_freeze_state state = atomic_read(&amp;sdp-&gt;sd_freeze_state);
 	lh = page_address(page);
<span class="p_header">diff --git a/fs/iomap.c b/fs/iomap.c</span>
<span class="p_header">index 1c25ae30500e..258fb4100b1d 100644</span>
<span class="p_header">--- a/fs/iomap.c</span>
<span class="p_header">+++ b/fs/iomap.c</span>
<span class="p_chunk">@@ -909,6 +909,9 @@</span> <span class="p_context"> iomap_dio_rw(struct kiocb *iocb, struct iov_iter *iter,</span>
 			break;
 		}
 		pos += ret;
<span class="p_add">+</span>
<span class="p_add">+		if (iov_iter_rw(iter) == READ &amp;&amp; pos &gt;= dio-&gt;i_size)</span>
<span class="p_add">+			break;</span>
 	} while ((count = iov_iter_count(iter)) &gt; 0);
 	blk_finish_plug(&amp;plug);
 
<span class="p_header">diff --git a/fs/nfsd/nfs4proc.c b/fs/nfsd/nfs4proc.c</span>
<span class="p_header">index c453a1998e00..dadb3bf305b2 100644</span>
<span class="p_header">--- a/fs/nfsd/nfs4proc.c</span>
<span class="p_header">+++ b/fs/nfsd/nfs4proc.c</span>
<span class="p_chunk">@@ -1769,6 +1769,12 @@</span> <span class="p_context"> nfsd4_proc_compound(struct svc_rqst *rqstp,</span>
 			opdesc-&gt;op_get_currentstateid(cstate, &amp;op-&gt;u);
 		op-&gt;status = opdesc-&gt;op_func(rqstp, cstate, &amp;op-&gt;u);
 
<span class="p_add">+		/* Only from SEQUENCE */</span>
<span class="p_add">+		if (cstate-&gt;status == nfserr_replay_cache) {</span>
<span class="p_add">+			dprintk(&quot;%s NFS4.1 replay from cache\n&quot;, __func__);</span>
<span class="p_add">+			status = op-&gt;status;</span>
<span class="p_add">+			goto out;</span>
<span class="p_add">+		}</span>
 		if (!op-&gt;status) {
 			if (opdesc-&gt;op_set_currentstateid)
 				opdesc-&gt;op_set_currentstateid(cstate, &amp;op-&gt;u);
<span class="p_chunk">@@ -1779,14 +1785,7 @@</span> <span class="p_context"> nfsd4_proc_compound(struct svc_rqst *rqstp,</span>
 			if (need_wrongsec_check(rqstp))
 				op-&gt;status = check_nfsd_access(current_fh-&gt;fh_export, rqstp);
 		}
<span class="p_del">-</span>
 encode_op:
<span class="p_del">-		/* Only from SEQUENCE */</span>
<span class="p_del">-		if (cstate-&gt;status == nfserr_replay_cache) {</span>
<span class="p_del">-			dprintk(&quot;%s NFS4.1 replay from cache\n&quot;, __func__);</span>
<span class="p_del">-			status = op-&gt;status;</span>
<span class="p_del">-			goto out;</span>
<span class="p_del">-		}</span>
 		if (op-&gt;status == nfserr_replay_me) {
 			op-&gt;replay = &amp;cstate-&gt;replay_owner-&gt;so_replay;
 			nfsd4_encode_replay(&amp;resp-&gt;xdr, op);
<span class="p_header">diff --git a/fs/overlayfs/copy_up.c b/fs/overlayfs/copy_up.c</span>
<span class="p_header">index 906ea6c93260..5b14c16d1b77 100644</span>
<span class="p_header">--- a/fs/overlayfs/copy_up.c</span>
<span class="p_header">+++ b/fs/overlayfs/copy_up.c</span>
<span class="p_chunk">@@ -269,12 +269,13 @@</span> <span class="p_context"> static int ovl_copy_up_locked(struct dentry *workdir, struct dentry *upperdir,</span>
 		temp = ovl_do_tmpfile(upperdir, stat-&gt;mode);
 	else
 		temp = ovl_lookup_temp(workdir, dentry);
<span class="p_del">-	err = PTR_ERR(temp);</span>
<span class="p_del">-	if (IS_ERR(temp))</span>
<span class="p_del">-		goto out1;</span>
<span class="p_del">-</span>
 	err = 0;
<span class="p_del">-	if (!tmpfile)</span>
<span class="p_add">+	if (IS_ERR(temp)) {</span>
<span class="p_add">+		err = PTR_ERR(temp);</span>
<span class="p_add">+		temp = NULL;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	if (!err &amp;&amp; !tmpfile)</span>
 		err = ovl_create_real(wdir, temp, &amp;cattr, NULL, true);
 
 	if (new_creds) {
<span class="p_header">diff --git a/fs/reiserfs/journal.c b/fs/reiserfs/journal.c</span>
<span class="p_header">index aa40c242f1db..64a4d3c82125 100644</span>
<span class="p_header">--- a/fs/reiserfs/journal.c</span>
<span class="p_header">+++ b/fs/reiserfs/journal.c</span>
<span class="p_chunk">@@ -1112,7 +1112,7 @@</span> <span class="p_context"> static int flush_commit_list(struct super_block *s,</span>
 		depth = reiserfs_write_unlock_nested(s);
 		if (reiserfs_barrier_flush(s))
 			__sync_dirty_buffer(jl-&gt;j_commit_bh,
<span class="p_del">-					REQ_PREFLUSH | REQ_FUA);</span>
<span class="p_add">+					REQ_SYNC | REQ_PREFLUSH | REQ_FUA);</span>
 		else
 			sync_dirty_buffer(jl-&gt;j_commit_bh);
 		reiserfs_write_lock_nested(s, depth);
<span class="p_chunk">@@ -1271,7 +1271,7 @@</span> <span class="p_context"> static int _update_journal_header_block(struct super_block *sb,</span>
 
 		if (reiserfs_barrier_flush(sb))
 			__sync_dirty_buffer(journal-&gt;j_header_bh,
<span class="p_del">-					REQ_PREFLUSH | REQ_FUA);</span>
<span class="p_add">+					REQ_SYNC | REQ_PREFLUSH | REQ_FUA);</span>
 		else
 			sync_dirty_buffer(journal-&gt;j_header_bh);
 
<span class="p_header">diff --git a/fs/stat.c b/fs/stat.c</span>
<span class="p_header">index a257b872a53d..ea6235a31ec8 100644</span>
<span class="p_header">--- a/fs/stat.c</span>
<span class="p_header">+++ b/fs/stat.c</span>
<span class="p_chunk">@@ -586,6 +586,7 @@</span> <span class="p_context"> void __inode_add_bytes(struct inode *inode, loff_t bytes)</span>
 		inode-&gt;i_bytes -= 512;
 	}
 }
<span class="p_add">+EXPORT_SYMBOL(__inode_add_bytes);</span>
 
 void inode_add_bytes(struct inode *inode, loff_t bytes)
 {
<span class="p_header">diff --git a/fs/ufs/balloc.c b/fs/ufs/balloc.c</span>
<span class="p_header">index a0376a2c1c29..d642cc0a8271 100644</span>
<span class="p_header">--- a/fs/ufs/balloc.c</span>
<span class="p_header">+++ b/fs/ufs/balloc.c</span>
<span class="p_chunk">@@ -82,7 +82,8 @@</span> <span class="p_context"> void ufs_free_fragments(struct inode *inode, u64 fragment, unsigned count)</span>
 			ufs_error (sb, &quot;ufs_free_fragments&quot;,
 				   &quot;bit already cleared for fragment %u&quot;, i);
 	}
<span class="p_del">-	</span>
<span class="p_add">+</span>
<span class="p_add">+	inode_sub_bytes(inode, count &lt;&lt; uspi-&gt;s_fshift);</span>
 	fs32_add(sb, &amp;ucg-&gt;cg_cs.cs_nffree, count);
 	uspi-&gt;cs_total.cs_nffree += count;
 	fs32_add(sb, &amp;UFS_SB(sb)-&gt;fs_cs(cgno).cs_nffree, count);
<span class="p_chunk">@@ -184,6 +185,7 @@</span> <span class="p_context"> void ufs_free_blocks(struct inode *inode, u64 fragment, unsigned count)</span>
 			ufs_error(sb, &quot;ufs_free_blocks&quot;, &quot;freeing free fragment&quot;);
 		}
 		ubh_setblock(UCPI_UBH(ucpi), ucpi-&gt;c_freeoff, blkno);
<span class="p_add">+		inode_sub_bytes(inode, uspi-&gt;s_fpb &lt;&lt; uspi-&gt;s_fshift);</span>
 		if ((UFS_SB(sb)-&gt;s_flags &amp; UFS_CG_MASK) == UFS_CG_44BSD)
 			ufs_clusteracct (sb, ucpi, blkno, 1);
 
<span class="p_chunk">@@ -494,6 +496,20 @@</span> <span class="p_context"> u64 ufs_new_fragments(struct inode *inode, void *p, u64 fragment,</span>
 	return 0;
 }		
 
<span class="p_add">+static bool try_add_frags(struct inode *inode, unsigned frags)</span>
<span class="p_add">+{</span>
<span class="p_add">+	unsigned size = frags * i_blocksize(inode);</span>
<span class="p_add">+	spin_lock(&amp;inode-&gt;i_lock);</span>
<span class="p_add">+	__inode_add_bytes(inode, size);</span>
<span class="p_add">+	if (unlikely((u32)inode-&gt;i_blocks != inode-&gt;i_blocks)) {</span>
<span class="p_add">+		__inode_sub_bytes(inode, size);</span>
<span class="p_add">+		spin_unlock(&amp;inode-&gt;i_lock);</span>
<span class="p_add">+		return false;</span>
<span class="p_add">+	}</span>
<span class="p_add">+	spin_unlock(&amp;inode-&gt;i_lock);</span>
<span class="p_add">+	return true;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static u64 ufs_add_fragments(struct inode *inode, u64 fragment,
 			     unsigned oldcount, unsigned newcount)
 {
<span class="p_chunk">@@ -530,6 +546,9 @@</span> <span class="p_context"> static u64 ufs_add_fragments(struct inode *inode, u64 fragment,</span>
 	for (i = oldcount; i &lt; newcount; i++)
 		if (ubh_isclr (UCPI_UBH(ucpi), ucpi-&gt;c_freeoff, fragno + i))
 			return 0;
<span class="p_add">+</span>
<span class="p_add">+	if (!try_add_frags(inode, count))</span>
<span class="p_add">+		return 0;</span>
 	/*
 	 * Block can be extended
 	 */
<span class="p_chunk">@@ -647,6 +666,7 @@</span> <span class="p_context"> static u64 ufs_alloc_fragments(struct inode *inode, unsigned cgno,</span>
 			ubh_setbit (UCPI_UBH(ucpi), ucpi-&gt;c_freeoff, goal + i);
 		i = uspi-&gt;s_fpb - count;
 
<span class="p_add">+		inode_sub_bytes(inode, i &lt;&lt; uspi-&gt;s_fshift);</span>
 		fs32_add(sb, &amp;ucg-&gt;cg_cs.cs_nffree, i);
 		uspi-&gt;cs_total.cs_nffree += i;
 		fs32_add(sb, &amp;UFS_SB(sb)-&gt;fs_cs(cgno).cs_nffree, i);
<span class="p_chunk">@@ -657,6 +677,8 @@</span> <span class="p_context"> static u64 ufs_alloc_fragments(struct inode *inode, unsigned cgno,</span>
 	result = ufs_bitmap_search (sb, ucpi, goal, allocsize);
 	if (result == INVBLOCK)
 		return 0;
<span class="p_add">+	if (!try_add_frags(inode, count))</span>
<span class="p_add">+		return 0;</span>
 	for (i = 0; i &lt; count; i++)
 		ubh_clrbit (UCPI_UBH(ucpi), ucpi-&gt;c_freeoff, result + i);
 	
<span class="p_chunk">@@ -716,6 +738,8 @@</span> <span class="p_context"> static u64 ufs_alloccg_block(struct inode *inode,</span>
 		return INVBLOCK;
 	ucpi-&gt;c_rotor = result;
 gotit:
<span class="p_add">+	if (!try_add_frags(inode, uspi-&gt;s_fpb))</span>
<span class="p_add">+		return 0;</span>
 	blkno = ufs_fragstoblks(result);
 	ubh_clrblock (UCPI_UBH(ucpi), ucpi-&gt;c_freeoff, blkno);
 	if ((UFS_SB(sb)-&gt;s_flags &amp; UFS_CG_MASK) == UFS_CG_44BSD)
<span class="p_header">diff --git a/fs/ufs/inode.c b/fs/ufs/inode.c</span>
<span class="p_header">index 7e41aee7b69a..34f11cf0900a 100644</span>
<span class="p_header">--- a/fs/ufs/inode.c</span>
<span class="p_header">+++ b/fs/ufs/inode.c</span>
<span class="p_chunk">@@ -235,7 +235,8 @@</span> <span class="p_context"> ufs_extend_tail(struct inode *inode, u64 writes_to,</span>
 
 	p = ufs_get_direct_data_ptr(uspi, ufsi, block);
 	tmp = ufs_new_fragments(inode, p, lastfrag, ufs_data_ptr_to_cpu(sb, p),
<span class="p_del">-				new_size, err, locked_page);</span>
<span class="p_add">+				new_size - (lastfrag &amp; uspi-&gt;s_fpbmask), err,</span>
<span class="p_add">+				locked_page);</span>
 	return tmp != 0;
 }
 
<span class="p_chunk">@@ -284,7 +285,7 @@</span> <span class="p_context"> ufs_inode_getfrag(struct inode *inode, unsigned index,</span>
 			goal += uspi-&gt;s_fpb;
 	}
 	tmp = ufs_new_fragments(inode, p, ufs_blknum(new_fragment),
<span class="p_del">-				goal, uspi-&gt;s_fpb, err, locked_page);</span>
<span class="p_add">+				goal, nfrags, err, locked_page);</span>
 
 	if (!tmp) {
 		*err = -ENOSPC;
<span class="p_chunk">@@ -402,7 +403,9 @@</span> <span class="p_context"> static int ufs_getfrag_block(struct inode *inode, sector_t fragment, struct buff</span>
 
 	if (!create) {
 		phys64 = ufs_frag_map(inode, offsets, depth);
<span class="p_del">-		goto out;</span>
<span class="p_add">+		if (phys64)</span>
<span class="p_add">+			map_bh(bh_result, sb, phys64 + frag);</span>
<span class="p_add">+		return 0;</span>
 	}
 
         /* This code entered only while writing ....? */
<span class="p_chunk">@@ -841,7 +844,9 @@</span> <span class="p_context"> void ufs_evict_inode(struct inode * inode)</span>
 	truncate_inode_pages_final(&amp;inode-&gt;i_data);
 	if (want_delete) {
 		inode-&gt;i_size = 0;
<span class="p_del">-		if (inode-&gt;i_blocks)</span>
<span class="p_add">+		if (inode-&gt;i_blocks &amp;&amp;</span>
<span class="p_add">+		    (S_ISREG(inode-&gt;i_mode) || S_ISDIR(inode-&gt;i_mode) ||</span>
<span class="p_add">+		     S_ISLNK(inode-&gt;i_mode)))</span>
 			ufs_truncate_blocks(inode);
 	}
 
<span class="p_chunk">@@ -1100,7 +1105,7 @@</span> <span class="p_context"> static int ufs_alloc_lastblock(struct inode *inode, loff_t size)</span>
        return err;
 }
 
<span class="p_del">-static void __ufs_truncate_blocks(struct inode *inode)</span>
<span class="p_add">+static void ufs_truncate_blocks(struct inode *inode)</span>
 {
 	struct ufs_inode_info *ufsi = UFS_I(inode);
 	struct super_block *sb = inode-&gt;i_sb;
<span class="p_chunk">@@ -1183,7 +1188,7 @@</span> <span class="p_context"> static int ufs_truncate(struct inode *inode, loff_t size)</span>
 
 	truncate_setsize(inode, size);
 
<span class="p_del">-	__ufs_truncate_blocks(inode);</span>
<span class="p_add">+	ufs_truncate_blocks(inode);</span>
 	inode-&gt;i_mtime = inode-&gt;i_ctime = current_time(inode);
 	mark_inode_dirty(inode);
 out:
<span class="p_chunk">@@ -1191,16 +1196,6 @@</span> <span class="p_context"> static int ufs_truncate(struct inode *inode, loff_t size)</span>
 	return err;
 }
 
<span class="p_del">-static void ufs_truncate_blocks(struct inode *inode)</span>
<span class="p_del">-{</span>
<span class="p_del">-	if (!(S_ISREG(inode-&gt;i_mode) || S_ISDIR(inode-&gt;i_mode) ||</span>
<span class="p_del">-	      S_ISLNK(inode-&gt;i_mode)))</span>
<span class="p_del">-		return;</span>
<span class="p_del">-	if (IS_APPEND(inode) || IS_IMMUTABLE(inode))</span>
<span class="p_del">-		return;</span>
<span class="p_del">-	__ufs_truncate_blocks(inode);</span>
<span class="p_del">-}</span>
<span class="p_del">-</span>
 int ufs_setattr(struct dentry *dentry, struct iattr *attr)
 {
 	struct inode *inode = d_inode(dentry);
<span class="p_header">diff --git a/fs/ufs/super.c b/fs/ufs/super.c</span>
<span class="p_header">index 29ecaf739449..878cc6264f1a 100644</span>
<span class="p_header">--- a/fs/ufs/super.c</span>
<span class="p_header">+++ b/fs/ufs/super.c</span>
<span class="p_chunk">@@ -746,6 +746,23 @@</span> <span class="p_context"> static void ufs_put_super(struct super_block *sb)</span>
 	return;
 }
 
<span class="p_add">+static u64 ufs_max_bytes(struct super_block *sb)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct ufs_sb_private_info *uspi = UFS_SB(sb)-&gt;s_uspi;</span>
<span class="p_add">+	int bits = uspi-&gt;s_apbshift;</span>
<span class="p_add">+	u64 res;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (bits &gt; 21)</span>
<span class="p_add">+		res = ~0ULL;</span>
<span class="p_add">+	else</span>
<span class="p_add">+		res = UFS_NDADDR + (1LL &lt;&lt; bits) + (1LL &lt;&lt; (2*bits)) +</span>
<span class="p_add">+			(1LL &lt;&lt; (3*bits));</span>
<span class="p_add">+</span>
<span class="p_add">+	if (res &gt;= (MAX_LFS_FILESIZE &gt;&gt; uspi-&gt;s_bshift))</span>
<span class="p_add">+		return MAX_LFS_FILESIZE;</span>
<span class="p_add">+	return res &lt;&lt; uspi-&gt;s_bshift;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 static int ufs_fill_super(struct super_block *sb, void *data, int silent)
 {
 	struct ufs_sb_info * sbi;
<span class="p_chunk">@@ -1211,6 +1228,7 @@</span> <span class="p_context"> static int ufs_fill_super(struct super_block *sb, void *data, int silent)</span>
 			    &quot;fast symlink size (%u)\n&quot;, uspi-&gt;s_maxsymlinklen);
 		uspi-&gt;s_maxsymlinklen = maxsymlen;
 	}
<span class="p_add">+	sb-&gt;s_maxbytes = ufs_max_bytes(sb);</span>
 	sb-&gt;s_max_links = UFS_LINK_MAX;
 
 	inode = ufs_iget(sb, UFS_ROOTINO);
<span class="p_header">diff --git a/fs/ufs/util.h b/fs/ufs/util.h</span>
<span class="p_header">index b7fbf53dbc81..398019fb1448 100644</span>
<span class="p_header">--- a/fs/ufs/util.h</span>
<span class="p_header">+++ b/fs/ufs/util.h</span>
<span class="p_chunk">@@ -473,15 +473,19 @@</span> <span class="p_context"> static inline unsigned _ubh_find_last_zero_bit_(</span>
 static inline int _ubh_isblockset_(struct ufs_sb_private_info * uspi,
 	struct ufs_buffer_head * ubh, unsigned begin, unsigned block)
 {
<span class="p_add">+	u8 mask;</span>
 	switch (uspi-&gt;s_fpb) {
 	case 8:
 	    	return (*ubh_get_addr (ubh, begin + block) == 0xff);
 	case 4:
<span class="p_del">-		return (*ubh_get_addr (ubh, begin + (block &gt;&gt; 1)) == (0x0f &lt;&lt; ((block &amp; 0x01) &lt;&lt; 2)));</span>
<span class="p_add">+		mask = 0x0f &lt;&lt; ((block &amp; 0x01) &lt;&lt; 2);</span>
<span class="p_add">+		return (*ubh_get_addr (ubh, begin + (block &gt;&gt; 1)) &amp; mask) == mask;</span>
 	case 2:
<span class="p_del">-		return (*ubh_get_addr (ubh, begin + (block &gt;&gt; 2)) == (0x03 &lt;&lt; ((block &amp; 0x03) &lt;&lt; 1)));</span>
<span class="p_add">+		mask = 0x03 &lt;&lt; ((block &amp; 0x03) &lt;&lt; 1);</span>
<span class="p_add">+		return (*ubh_get_addr (ubh, begin + (block &gt;&gt; 2)) &amp; mask) == mask;</span>
 	case 1:
<span class="p_del">-		return (*ubh_get_addr (ubh, begin + (block &gt;&gt; 3)) == (0x01 &lt;&lt; (block &amp; 0x07)));</span>
<span class="p_add">+		mask = 0x01 &lt;&lt; (block &amp; 0x07);</span>
<span class="p_add">+		return (*ubh_get_addr (ubh, begin + (block &gt;&gt; 3)) &amp; mask) == mask;</span>
 	}
 	return 0;	
 }
<span class="p_header">diff --git a/include/drm/i915_pciids.h b/include/drm/i915_pciids.h</span>
<span class="p_header">index a1dd21d6b723..466c71592a6f 100644</span>
<span class="p_header">--- a/include/drm/i915_pciids.h</span>
<span class="p_header">+++ b/include/drm/i915_pciids.h</span>
<span class="p_chunk">@@ -265,7 +265,8 @@</span> <span class="p_context"></span>
 	INTEL_VGA_DEVICE(0x1923, info), /* ULT GT3 */ \
 	INTEL_VGA_DEVICE(0x1926, info), /* ULT GT3 */ \
 	INTEL_VGA_DEVICE(0x1927, info), /* ULT GT3 */ \
<span class="p_del">-	INTEL_VGA_DEVICE(0x192B, info)  /* Halo GT3 */ \</span>
<span class="p_add">+	INTEL_VGA_DEVICE(0x192B, info), /* Halo GT3 */ \</span>
<span class="p_add">+	INTEL_VGA_DEVICE(0x192D, info)  /* SRV GT3 */</span>
 
 #define INTEL_SKL_GT4_IDS(info) \
 	INTEL_VGA_DEVICE(0x1932, info), /* DT GT4 */ \
<span class="p_header">diff --git a/include/linux/cgroup-defs.h b/include/linux/cgroup-defs.h</span>
<span class="p_header">index 6a3f850cabab..14db95e9b529 100644</span>
<span class="p_header">--- a/include/linux/cgroup-defs.h</span>
<span class="p_header">+++ b/include/linux/cgroup-defs.h</span>
<span class="p_chunk">@@ -47,6 +47,7 @@</span> <span class="p_context"> enum {</span>
 	CSS_ONLINE	= (1 &lt;&lt; 1), /* between -&gt;css_online() and -&gt;css_offline() */
 	CSS_RELEASED	= (1 &lt;&lt; 2), /* refcnt reached zero, released */
 	CSS_VISIBLE	= (1 &lt;&lt; 3), /* css is visible to userland */
<span class="p_add">+	CSS_DYING	= (1 &lt;&lt; 4), /* css is dying */</span>
 };
 
 /* bits in struct cgroup flags field */
<span class="p_header">diff --git a/include/linux/cgroup.h b/include/linux/cgroup.h</span>
<span class="p_header">index af9c86e958bd..b48579d9b806 100644</span>
<span class="p_header">--- a/include/linux/cgroup.h</span>
<span class="p_header">+++ b/include/linux/cgroup.h</span>
<span class="p_chunk">@@ -344,6 +344,26 @@</span> <span class="p_context"> static inline bool css_tryget_online(struct cgroup_subsys_state *css)</span>
 }
 
 /**
<span class="p_add">+ * css_is_dying - test whether the specified css is dying</span>
<span class="p_add">+ * @css: target css</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * Test whether @css is in the process of offlining or already offline.  In</span>
<span class="p_add">+ * most cases, -&gt;css_online() and -&gt;css_offline() callbacks should be</span>
<span class="p_add">+ * enough; however, the actual offline operations are RCU delayed and this</span>
<span class="p_add">+ * test returns %true also when @css is scheduled to be offlined.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * This is useful, for example, when the use case requires synchronous</span>
<span class="p_add">+ * behavior with respect to cgroup removal.  cgroup removal schedules css</span>
<span class="p_add">+ * offlining but the css can seem alive while the operation is being</span>
<span class="p_add">+ * delayed.  If the delay affects user visible semantics, this test can be</span>
<span class="p_add">+ * used to resolve the situation.</span>
<span class="p_add">+ */</span>
<span class="p_add">+static inline bool css_is_dying(struct cgroup_subsys_state *css)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return !(css-&gt;flags &amp; CSS_NO_REF) &amp;&amp; percpu_ref_is_dying(&amp;css-&gt;refcnt);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+/**</span>
  * css_put - put a css reference
  * @css: target css
  *
<span class="p_header">diff --git a/include/linux/ptrace.h b/include/linux/ptrace.h</span>
<span class="p_header">index 422bc2e4cb6a..ef3eb8bbfee4 100644</span>
<span class="p_header">--- a/include/linux/ptrace.h</span>
<span class="p_header">+++ b/include/linux/ptrace.h</span>
<span class="p_chunk">@@ -54,7 +54,8 @@</span> <span class="p_context"> extern int ptrace_request(struct task_struct *child, long request,</span>
 			  unsigned long addr, unsigned long data);
 extern void ptrace_notify(int exit_code);
 extern void __ptrace_link(struct task_struct *child,
<span class="p_del">-			  struct task_struct *new_parent);</span>
<span class="p_add">+			  struct task_struct *new_parent,</span>
<span class="p_add">+			  const struct cred *ptracer_cred);</span>
 extern void __ptrace_unlink(struct task_struct *child);
 extern void exit_ptrace(struct task_struct *tracer, struct list_head *dead);
 #define PTRACE_MODE_READ	0x01
<span class="p_chunk">@@ -206,7 +207,7 @@</span> <span class="p_context"> static inline void ptrace_init_task(struct task_struct *child, bool ptrace)</span>
 
 	if (unlikely(ptrace) &amp;&amp; current-&gt;ptrace) {
 		child-&gt;ptrace = current-&gt;ptrace;
<span class="p_del">-		__ptrace_link(child, current-&gt;parent);</span>
<span class="p_add">+		__ptrace_link(child, current-&gt;parent, current-&gt;ptracer_cred);</span>
 
 		if (child-&gt;ptrace &amp; PT_SEIZED)
 			task_set_jobctl_pending(child, JOBCTL_TRAP_STOP);
<span class="p_chunk">@@ -215,6 +216,8 @@</span> <span class="p_context"> static inline void ptrace_init_task(struct task_struct *child, bool ptrace)</span>
 
 		set_tsk_thread_flag(child, TIF_SIGPENDING);
 	}
<span class="p_add">+	else</span>
<span class="p_add">+		child-&gt;ptracer_cred = NULL;</span>
 }
 
 /**
<span class="p_header">diff --git a/include/linux/srcu.h b/include/linux/srcu.h</span>
<span class="p_header">index a598cf3ac70c..8a95e5d0fdf9 100644</span>
<span class="p_header">--- a/include/linux/srcu.h</span>
<span class="p_header">+++ b/include/linux/srcu.h</span>
<span class="p_chunk">@@ -232,9 +232,7 @@</span> <span class="p_context"> static inline int srcu_read_lock(struct srcu_struct *sp) __acquires(sp)</span>
 {
 	int retval;
 
<span class="p_del">-	preempt_disable();</span>
 	retval = __srcu_read_lock(sp);
<span class="p_del">-	preempt_enable();</span>
 	rcu_lock_acquire(&amp;(sp)-&gt;dep_map);
 	return retval;
 }
<span class="p_header">diff --git a/include/net/ipv6.h b/include/net/ipv6.h</span>
<span class="p_header">index dbf0abba33b8..3e505bbff8ca 100644</span>
<span class="p_header">--- a/include/net/ipv6.h</span>
<span class="p_header">+++ b/include/net/ipv6.h</span>
<span class="p_chunk">@@ -1007,6 +1007,7 @@</span> <span class="p_context"> int inet6_hash_connect(struct inet_timewait_death_row *death_row,</span>
  */
 extern const struct proto_ops inet6_stream_ops;
 extern const struct proto_ops inet6_dgram_ops;
<span class="p_add">+extern const struct proto_ops inet6_sockraw_ops;</span>
 
 struct group_source_req;
 struct group_filter;
<span class="p_header">diff --git a/kernel/audit.c b/kernel/audit.c</span>
<span class="p_header">index a871bf80fde1..dd2c339c8eb9 100644</span>
<span class="p_header">--- a/kernel/audit.c</span>
<span class="p_header">+++ b/kernel/audit.c</span>
<span class="p_chunk">@@ -110,18 +110,19 @@</span> <span class="p_context"> struct audit_net {</span>
  * @pid: auditd PID
  * @portid: netlink portid
  * @net: the associated network namespace
<span class="p_del">- * @lock: spinlock to protect write access</span>
<span class="p_add">+ * @rcu: RCU head</span>
  *
  * Description:
  * This struct is RCU protected; you must either hold the RCU lock for reading
<span class="p_del">- * or the included spinlock for writing.</span>
<span class="p_add">+ * or the associated spinlock for writing.</span>
  */
 static struct auditd_connection {
 	int pid;
 	u32 portid;
 	struct net *net;
<span class="p_del">-	spinlock_t lock;</span>
<span class="p_del">-} auditd_conn;</span>
<span class="p_add">+	struct rcu_head rcu;</span>
<span class="p_add">+} *auditd_conn = NULL;</span>
<span class="p_add">+static DEFINE_SPINLOCK(auditd_conn_lock);</span>
 
 /* If audit_rate_limit is non-zero, limit the rate of sending audit records
  * to that number per second.  This prevents DoS attacks, but results in
<span class="p_chunk">@@ -223,15 +224,39 @@</span> <span class="p_context"> struct audit_reply {</span>
 int auditd_test_task(const struct task_struct *task)
 {
 	int rc;
<span class="p_add">+	struct auditd_connection *ac;</span>
 
 	rcu_read_lock();
<span class="p_del">-	rc = (auditd_conn.pid &amp;&amp; task-&gt;tgid == auditd_conn.pid ? 1 : 0);</span>
<span class="p_add">+	ac = rcu_dereference(auditd_conn);</span>
<span class="p_add">+	rc = (ac &amp;&amp; ac-&gt;pid == task-&gt;tgid ? 1 : 0);</span>
 	rcu_read_unlock();
 
 	return rc;
 }
 
 /**
<span class="p_add">+ * auditd_pid_vnr - Return the auditd PID relative to the namespace</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * Description:</span>
<span class="p_add">+ * Returns the PID in relation to the namespace, 0 on failure.</span>
<span class="p_add">+ */</span>
<span class="p_add">+static pid_t auditd_pid_vnr(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	pid_t pid;</span>
<span class="p_add">+	const struct auditd_connection *ac;</span>
<span class="p_add">+</span>
<span class="p_add">+	rcu_read_lock();</span>
<span class="p_add">+	ac = rcu_dereference(auditd_conn);</span>
<span class="p_add">+	if (!ac)</span>
<span class="p_add">+		pid = 0;</span>
<span class="p_add">+	else</span>
<span class="p_add">+		pid = ac-&gt;pid;</span>
<span class="p_add">+	rcu_read_unlock();</span>
<span class="p_add">+</span>
<span class="p_add">+	return pid;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+/**</span>
  * audit_get_sk - Return the audit socket for the given network namespace
  * @net: the destination network namespace
  *
<span class="p_chunk">@@ -427,6 +452,23 @@</span> <span class="p_context"> static int audit_set_failure(u32 state)</span>
 }
 
 /**
<span class="p_add">+ * auditd_conn_free - RCU helper to release an auditd connection struct</span>
<span class="p_add">+ * @rcu: RCU head</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * Description:</span>
<span class="p_add">+ * Drop any references inside the auditd connection tracking struct and free</span>
<span class="p_add">+ * the memory.</span>
<span class="p_add">+ */</span>
<span class="p_add">+static void auditd_conn_free(struct rcu_head *rcu)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct auditd_connection *ac;</span>
<span class="p_add">+</span>
<span class="p_add">+	ac = container_of(rcu, struct auditd_connection, rcu);</span>
<span class="p_add">+	put_net(ac-&gt;net);</span>
<span class="p_add">+	kfree(ac);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+/**</span>
  * auditd_set - Set/Reset the auditd connection state
  * @pid: auditd PID
  * @portid: auditd netlink portid
<span class="p_chunk">@@ -434,22 +476,33 @@</span> <span class="p_context"> static int audit_set_failure(u32 state)</span>
  *
  * Description:
  * This function will obtain and drop network namespace references as
<span class="p_del">- * necessary.</span>
<span class="p_add">+ * necessary.  Returns zero on success, negative values on failure.</span>
  */
<span class="p_del">-static void auditd_set(int pid, u32 portid, struct net *net)</span>
<span class="p_add">+static int auditd_set(int pid, u32 portid, struct net *net)</span>
 {
 	unsigned long flags;
<span class="p_add">+	struct auditd_connection *ac_old, *ac_new;</span>
 
<span class="p_del">-	spin_lock_irqsave(&amp;auditd_conn.lock, flags);</span>
<span class="p_del">-	auditd_conn.pid = pid;</span>
<span class="p_del">-	auditd_conn.portid = portid;</span>
<span class="p_del">-	if (auditd_conn.net)</span>
<span class="p_del">-		put_net(auditd_conn.net);</span>
<span class="p_del">-	if (net)</span>
<span class="p_del">-		auditd_conn.net = get_net(net);</span>
<span class="p_del">-	else</span>
<span class="p_del">-		auditd_conn.net = NULL;</span>
<span class="p_del">-	spin_unlock_irqrestore(&amp;auditd_conn.lock, flags);</span>
<span class="p_add">+	if (!pid || !net)</span>
<span class="p_add">+		return -EINVAL;</span>
<span class="p_add">+</span>
<span class="p_add">+	ac_new = kzalloc(sizeof(*ac_new), GFP_KERNEL);</span>
<span class="p_add">+	if (!ac_new)</span>
<span class="p_add">+		return -ENOMEM;</span>
<span class="p_add">+	ac_new-&gt;pid = pid;</span>
<span class="p_add">+	ac_new-&gt;portid = portid;</span>
<span class="p_add">+	ac_new-&gt;net = get_net(net);</span>
<span class="p_add">+</span>
<span class="p_add">+	spin_lock_irqsave(&amp;auditd_conn_lock, flags);</span>
<span class="p_add">+	ac_old = rcu_dereference_protected(auditd_conn,</span>
<span class="p_add">+					   lockdep_is_held(&amp;auditd_conn_lock));</span>
<span class="p_add">+	rcu_assign_pointer(auditd_conn, ac_new);</span>
<span class="p_add">+	spin_unlock_irqrestore(&amp;auditd_conn_lock, flags);</span>
<span class="p_add">+</span>
<span class="p_add">+	if (ac_old)</span>
<span class="p_add">+		call_rcu(&amp;ac_old-&gt;rcu, auditd_conn_free);</span>
<span class="p_add">+</span>
<span class="p_add">+	return 0;</span>
 }
 
 /**
<span class="p_chunk">@@ -544,13 +597,19 @@</span> <span class="p_context"> static void kauditd_retry_skb(struct sk_buff *skb)</span>
  */
 static void auditd_reset(void)
 {
<span class="p_add">+	unsigned long flags;</span>
 	struct sk_buff *skb;
<span class="p_add">+	struct auditd_connection *ac_old;</span>
 
 	/* if it isn&#39;t already broken, break the connection */
<span class="p_del">-	rcu_read_lock();</span>
<span class="p_del">-	if (auditd_conn.pid)</span>
<span class="p_del">-		auditd_set(0, 0, NULL);</span>
<span class="p_del">-	rcu_read_unlock();</span>
<span class="p_add">+	spin_lock_irqsave(&amp;auditd_conn_lock, flags);</span>
<span class="p_add">+	ac_old = rcu_dereference_protected(auditd_conn,</span>
<span class="p_add">+					   lockdep_is_held(&amp;auditd_conn_lock));</span>
<span class="p_add">+	rcu_assign_pointer(auditd_conn, NULL);</span>
<span class="p_add">+	spin_unlock_irqrestore(&amp;auditd_conn_lock, flags);</span>
<span class="p_add">+</span>
<span class="p_add">+	if (ac_old)</span>
<span class="p_add">+		call_rcu(&amp;ac_old-&gt;rcu, auditd_conn_free);</span>
 
 	/* flush all of the main and retry queues to the hold queue */
 	while ((skb = skb_dequeue(&amp;audit_retry_queue)))
<span class="p_chunk">@@ -576,6 +635,7 @@</span> <span class="p_context"> static int auditd_send_unicast_skb(struct sk_buff *skb)</span>
 	u32 portid;
 	struct net *net;
 	struct sock *sk;
<span class="p_add">+	struct auditd_connection *ac;</span>
 
 	/* NOTE: we can&#39;t call netlink_unicast while in the RCU section so
 	 *       take a reference to the network namespace and grab local
<span class="p_chunk">@@ -585,15 +645,15 @@</span> <span class="p_context"> static int auditd_send_unicast_skb(struct sk_buff *skb)</span>
 	 *       section netlink_unicast() should safely return an error */
 
 	rcu_read_lock();
<span class="p_del">-	if (!auditd_conn.pid) {</span>
<span class="p_add">+	ac = rcu_dereference(auditd_conn);</span>
<span class="p_add">+	if (!ac) {</span>
 		rcu_read_unlock();
 		rc = -ECONNREFUSED;
 		goto err;
 	}
<span class="p_del">-	net = auditd_conn.net;</span>
<span class="p_del">-	get_net(net);</span>
<span class="p_add">+	net = get_net(ac-&gt;net);</span>
 	sk = audit_get_sk(net);
<span class="p_del">-	portid = auditd_conn.portid;</span>
<span class="p_add">+	portid = ac-&gt;portid;</span>
 	rcu_read_unlock();
 
 	rc = netlink_unicast(sk, skb, portid, 0);
<span class="p_chunk">@@ -728,6 +788,7 @@</span> <span class="p_context"> static int kauditd_thread(void *dummy)</span>
 	u32 portid = 0;
 	struct net *net = NULL;
 	struct sock *sk = NULL;
<span class="p_add">+	struct auditd_connection *ac;</span>
 
 #define UNICAST_RETRIES 5
 
<span class="p_chunk">@@ -735,14 +796,14 @@</span> <span class="p_context"> static int kauditd_thread(void *dummy)</span>
 	while (!kthread_should_stop()) {
 		/* NOTE: see the lock comments in auditd_send_unicast_skb() */
 		rcu_read_lock();
<span class="p_del">-		if (!auditd_conn.pid) {</span>
<span class="p_add">+		ac = rcu_dereference(auditd_conn);</span>
<span class="p_add">+		if (!ac) {</span>
 			rcu_read_unlock();
 			goto main_queue;
 		}
<span class="p_del">-		net = auditd_conn.net;</span>
<span class="p_del">-		get_net(net);</span>
<span class="p_add">+		net = get_net(ac-&gt;net);</span>
 		sk = audit_get_sk(net);
<span class="p_del">-		portid = auditd_conn.portid;</span>
<span class="p_add">+		portid = ac-&gt;portid;</span>
 		rcu_read_unlock();
 
 		/* attempt to flush the hold queue */
<span class="p_chunk">@@ -1102,9 +1163,7 @@</span> <span class="p_context"> static int audit_receive_msg(struct sk_buff *skb, struct nlmsghdr *nlh)</span>
 		memset(&amp;s, 0, sizeof(s));
 		s.enabled		= audit_enabled;
 		s.failure		= audit_failure;
<span class="p_del">-		rcu_read_lock();</span>
<span class="p_del">-		s.pid			= auditd_conn.pid;</span>
<span class="p_del">-		rcu_read_unlock();</span>
<span class="p_add">+		s.pid			= auditd_pid_vnr();</span>
 		s.rate_limit		= audit_rate_limit;
 		s.backlog_limit		= audit_backlog_limit;
 		s.lost			= atomic_read(&amp;audit_lost);
<span class="p_chunk">@@ -1143,38 +1202,44 @@</span> <span class="p_context"> static int audit_receive_msg(struct sk_buff *skb, struct nlmsghdr *nlh)</span>
 			/* test the auditd connection */
 			audit_replace(requesting_pid);
 
<span class="p_del">-			rcu_read_lock();</span>
<span class="p_del">-			auditd_pid = auditd_conn.pid;</span>
<span class="p_add">+			auditd_pid = auditd_pid_vnr();</span>
 			/* only the current auditd can unregister itself */
 			if ((!new_pid) &amp;&amp; (requesting_pid != auditd_pid)) {
<span class="p_del">-				rcu_read_unlock();</span>
 				audit_log_config_change(&quot;audit_pid&quot;, new_pid,
 							auditd_pid, 0);
 				return -EACCES;
 			}
 			/* replacing a healthy auditd is not allowed */
 			if (auditd_pid &amp;&amp; new_pid) {
<span class="p_del">-				rcu_read_unlock();</span>
 				audit_log_config_change(&quot;audit_pid&quot;, new_pid,
 							auditd_pid, 0);
 				return -EEXIST;
 			}
<span class="p_del">-			rcu_read_unlock();</span>
<span class="p_del">-</span>
<span class="p_del">-			if (audit_enabled != AUDIT_OFF)</span>
<span class="p_del">-				audit_log_config_change(&quot;audit_pid&quot;, new_pid,</span>
<span class="p_del">-							auditd_pid, 1);</span>
 
 			if (new_pid) {
 				/* register a new auditd connection */
<span class="p_del">-				auditd_set(new_pid,</span>
<span class="p_del">-					   NETLINK_CB(skb).portid,</span>
<span class="p_del">-					   sock_net(NETLINK_CB(skb).sk));</span>
<span class="p_add">+				err = auditd_set(new_pid,</span>
<span class="p_add">+						 NETLINK_CB(skb).portid,</span>
<span class="p_add">+						 sock_net(NETLINK_CB(skb).sk));</span>
<span class="p_add">+				if (audit_enabled != AUDIT_OFF)</span>
<span class="p_add">+					audit_log_config_change(&quot;audit_pid&quot;,</span>
<span class="p_add">+								new_pid,</span>
<span class="p_add">+								auditd_pid,</span>
<span class="p_add">+								err ? 0 : 1);</span>
<span class="p_add">+				if (err)</span>
<span class="p_add">+					return err;</span>
<span class="p_add">+</span>
 				/* try to process any backlog */
 				wake_up_interruptible(&amp;kauditd_wait);
<span class="p_del">-			} else</span>
<span class="p_add">+			} else {</span>
<span class="p_add">+				if (audit_enabled != AUDIT_OFF)</span>
<span class="p_add">+					audit_log_config_change(&quot;audit_pid&quot;,</span>
<span class="p_add">+								new_pid,</span>
<span class="p_add">+								auditd_pid, 1);</span>
<span class="p_add">+</span>
 				/* unregister the auditd connection */
 				auditd_reset();
<span class="p_add">+			}</span>
 		}
 		if (s.mask &amp; AUDIT_STATUS_RATE_LIMIT) {
 			err = audit_set_rate_limit(s.rate_limit);
<span class="p_chunk">@@ -1447,10 +1512,11 @@</span> <span class="p_context"> static void __net_exit audit_net_exit(struct net *net)</span>
 {
 	struct audit_net *aunet = net_generic(net, audit_net_id);
 
<span class="p_del">-	rcu_read_lock();</span>
<span class="p_del">-	if (net == auditd_conn.net)</span>
<span class="p_del">-		auditd_reset();</span>
<span class="p_del">-	rcu_read_unlock();</span>
<span class="p_add">+	/* NOTE: you would think that we would want to check the auditd</span>
<span class="p_add">+	 * connection and potentially reset it here if it lives in this</span>
<span class="p_add">+	 * namespace, but since the auditd connection tracking struct holds a</span>
<span class="p_add">+	 * reference to this namespace (see auditd_set()) we are only ever</span>
<span class="p_add">+	 * going to get here after that connection has been released */</span>
 
 	netlink_kernel_release(aunet-&gt;sk);
 }
<span class="p_chunk">@@ -1470,9 +1536,6 @@</span> <span class="p_context"> static int __init audit_init(void)</span>
 	if (audit_initialized == AUDIT_DISABLED)
 		return 0;
 
<span class="p_del">-	memset(&amp;auditd_conn, 0, sizeof(auditd_conn));</span>
<span class="p_del">-	spin_lock_init(&amp;auditd_conn.lock);</span>
<span class="p_del">-</span>
 	skb_queue_head_init(&amp;audit_queue);
 	skb_queue_head_init(&amp;audit_retry_queue);
 	skb_queue_head_init(&amp;audit_hold_queue);
<span class="p_header">diff --git a/kernel/cgroup/cgroup.c b/kernel/cgroup/cgroup.c</span>
<span class="p_header">index b507f1889a72..e21c9321101f 100644</span>
<span class="p_header">--- a/kernel/cgroup/cgroup.c</span>
<span class="p_header">+++ b/kernel/cgroup/cgroup.c</span>
<span class="p_chunk">@@ -436,7 +436,7 @@</span> <span class="p_context"> struct cgroup_subsys_state *cgroup_get_e_css(struct cgroup *cgrp,</span>
 	return css;
 }
 
<span class="p_del">-static void cgroup_get(struct cgroup *cgrp)</span>
<span class="p_add">+static void __maybe_unused cgroup_get(struct cgroup *cgrp)</span>
 {
 	css_get(&amp;cgrp-&gt;self);
 }
<span class="p_chunk">@@ -4265,6 +4265,11 @@</span> <span class="p_context"> static void kill_css(struct cgroup_subsys_state *css)</span>
 {
 	lockdep_assert_held(&amp;cgroup_mutex);
 
<span class="p_add">+	if (css-&gt;flags &amp; CSS_DYING)</span>
<span class="p_add">+		return;</span>
<span class="p_add">+</span>
<span class="p_add">+	css-&gt;flags |= CSS_DYING;</span>
<span class="p_add">+</span>
 	/*
 	 * This must happen before css is disassociated with its cgroup.
 	 * See seq_css() for details.
<span class="p_header">diff --git a/kernel/cgroup/cpuset.c b/kernel/cgroup/cpuset.c</span>
<span class="p_header">index 0f41292be0fb..943481230cf8 100644</span>
<span class="p_header">--- a/kernel/cgroup/cpuset.c</span>
<span class="p_header">+++ b/kernel/cgroup/cpuset.c</span>
<span class="p_chunk">@@ -176,9 +176,9 @@</span> <span class="p_context"> typedef enum {</span>
 } cpuset_flagbits_t;
 
 /* convenient tests for these bits */
<span class="p_del">-static inline bool is_cpuset_online(const struct cpuset *cs)</span>
<span class="p_add">+static inline bool is_cpuset_online(struct cpuset *cs)</span>
 {
<span class="p_del">-	return test_bit(CS_ONLINE, &amp;cs-&gt;flags);</span>
<span class="p_add">+	return test_bit(CS_ONLINE, &amp;cs-&gt;flags) &amp;&amp; !css_is_dying(&amp;cs-&gt;css);</span>
 }
 
 static inline int is_cpu_exclusive(const struct cpuset *cs)
<span class="p_header">diff --git a/kernel/cpu.c b/kernel/cpu.c</span>
<span class="p_header">index 37b223e4fc05..e27838ab275d 100644</span>
<span class="p_header">--- a/kernel/cpu.c</span>
<span class="p_header">+++ b/kernel/cpu.c</span>
<span class="p_chunk">@@ -1656,13 +1656,13 @@</span> <span class="p_context"> static ssize_t write_cpuhp_target(struct device *dev,</span>
 	ret = !sp-&gt;name || sp-&gt;cant_stop ? -EINVAL : 0;
 	mutex_unlock(&amp;cpuhp_state_mutex);
 	if (ret)
<span class="p_del">-		return ret;</span>
<span class="p_add">+		goto out;</span>
 
 	if (st-&gt;state &lt; target)
 		ret = do_cpu_up(dev-&gt;id, target);
 	else
 		ret = do_cpu_down(dev-&gt;id, target);
<span class="p_del">-</span>
<span class="p_add">+out:</span>
 	unlock_device_hotplug();
 	return ret ? ret : count;
 }
<span class="p_header">diff --git a/kernel/events/core.c b/kernel/events/core.c</span>
<span class="p_header">index ff01cba86f43..95c7fa675009 100644</span>
<span class="p_header">--- a/kernel/events/core.c</span>
<span class="p_header">+++ b/kernel/events/core.c</span>
<span class="p_chunk">@@ -7184,6 +7184,21 @@</span> <span class="p_context"> int perf_event_account_interrupt(struct perf_event *event)</span>
 	return __perf_event_account_interrupt(event, 1);
 }
 
<span class="p_add">+static bool sample_is_allowed(struct perf_event *event, struct pt_regs *regs)</span>
<span class="p_add">+{</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Due to interrupt latency (AKA &quot;skid&quot;), we may enter the</span>
<span class="p_add">+	 * kernel before taking an overflow, even if the PMU is only</span>
<span class="p_add">+	 * counting user events.</span>
<span class="p_add">+	 * To avoid leaking information to userspace, we must always</span>
<span class="p_add">+	 * reject kernel samples when exclude_kernel is set.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	if (event-&gt;attr.exclude_kernel &amp;&amp; !user_mode(regs))</span>
<span class="p_add">+		return false;</span>
<span class="p_add">+</span>
<span class="p_add">+	return true;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 /*
  * Generic event overflow handling, sampling.
  */
<span class="p_chunk">@@ -7205,6 +7220,12 @@</span> <span class="p_context"> static int __perf_event_overflow(struct perf_event *event,</span>
 	ret = __perf_event_account_interrupt(event, throttle);
 
 	/*
<span class="p_add">+	 * For security, drop the skid kernel samples if necessary.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	if (!sample_is_allowed(event, regs))</span>
<span class="p_add">+		return ret;</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
 	 * XXX event_limit might not quite work as expected on inherited
 	 * events
 	 */
<span class="p_header">diff --git a/kernel/fork.c b/kernel/fork.c</span>
<span class="p_header">index 4cc564ece2cf..4f7151d1716b 100644</span>
<span class="p_header">--- a/kernel/fork.c</span>
<span class="p_header">+++ b/kernel/fork.c</span>
<span class="p_chunk">@@ -1552,6 +1552,18 @@</span> <span class="p_context"> static __latent_entropy struct task_struct *copy_process(</span>
 	if (!p)
 		goto fork_out;
 
<span class="p_add">+	/*</span>
<span class="p_add">+	 * This _must_ happen before we call free_task(), i.e. before we jump</span>
<span class="p_add">+	 * to any of the bad_fork_* labels. This is to avoid freeing</span>
<span class="p_add">+	 * p-&gt;set_child_tid which is (ab)used as a kthread&#39;s data pointer for</span>
<span class="p_add">+	 * kernel threads (PF_KTHREAD).</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	p-&gt;set_child_tid = (clone_flags &amp; CLONE_CHILD_SETTID) ? child_tidptr : NULL;</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Clear TID on mm_release()?</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	p-&gt;clear_child_tid = (clone_flags &amp; CLONE_CHILD_CLEARTID) ? child_tidptr : NULL;</span>
<span class="p_add">+</span>
 	ftrace_graph_init_task(p);
 
 	rt_mutex_init_task(p);
<span class="p_chunk">@@ -1715,11 +1727,6 @@</span> <span class="p_context"> static __latent_entropy struct task_struct *copy_process(</span>
 		}
 	}
 
<span class="p_del">-	p-&gt;set_child_tid = (clone_flags &amp; CLONE_CHILD_SETTID) ? child_tidptr : NULL;</span>
<span class="p_del">-	/*</span>
<span class="p_del">-	 * Clear TID on mm_release()?</span>
<span class="p_del">-	 */</span>
<span class="p_del">-	p-&gt;clear_child_tid = (clone_flags &amp; CLONE_CHILD_CLEARTID) ? child_tidptr : NULL;</span>
 #ifdef CONFIG_BLOCK
 	p-&gt;plug = NULL;
 #endif
<span class="p_header">diff --git a/kernel/ptrace.c b/kernel/ptrace.c</span>
<span class="p_header">index 266ddcc1d8bb..60f356d91060 100644</span>
<span class="p_header">--- a/kernel/ptrace.c</span>
<span class="p_header">+++ b/kernel/ptrace.c</span>
<span class="p_chunk">@@ -60,19 +60,25 @@</span> <span class="p_context"> int ptrace_access_vm(struct task_struct *tsk, unsigned long addr,</span>
 }
 
 
<span class="p_add">+void __ptrace_link(struct task_struct *child, struct task_struct *new_parent,</span>
<span class="p_add">+		   const struct cred *ptracer_cred)</span>
<span class="p_add">+{</span>
<span class="p_add">+	BUG_ON(!list_empty(&amp;child-&gt;ptrace_entry));</span>
<span class="p_add">+	list_add(&amp;child-&gt;ptrace_entry, &amp;new_parent-&gt;ptraced);</span>
<span class="p_add">+	child-&gt;parent = new_parent;</span>
<span class="p_add">+	child-&gt;ptracer_cred = get_cred(ptracer_cred);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 /*
  * ptrace a task: make the debugger its new parent and
  * move it to the ptrace list.
  *
  * Must be called with the tasklist lock write-held.
  */
<span class="p_del">-void __ptrace_link(struct task_struct *child, struct task_struct *new_parent)</span>
<span class="p_add">+static void ptrace_link(struct task_struct *child, struct task_struct *new_parent)</span>
 {
<span class="p_del">-	BUG_ON(!list_empty(&amp;child-&gt;ptrace_entry));</span>
<span class="p_del">-	list_add(&amp;child-&gt;ptrace_entry, &amp;new_parent-&gt;ptraced);</span>
<span class="p_del">-	child-&gt;parent = new_parent;</span>
 	rcu_read_lock();
<span class="p_del">-	child-&gt;ptracer_cred = get_cred(__task_cred(new_parent));</span>
<span class="p_add">+	__ptrace_link(child, new_parent, __task_cred(new_parent));</span>
 	rcu_read_unlock();
 }
 
<span class="p_chunk">@@ -386,7 +392,7 @@</span> <span class="p_context"> static int ptrace_attach(struct task_struct *task, long request,</span>
 		flags |= PT_SEIZED;
 	task-&gt;ptrace = flags;
 
<span class="p_del">-	__ptrace_link(task, current);</span>
<span class="p_add">+	ptrace_link(task, current);</span>
 
 	/* SEIZE doesn&#39;t trap tracee on attach */
 	if (!seize)
<span class="p_chunk">@@ -459,7 +465,7 @@</span> <span class="p_context"> static int ptrace_traceme(void)</span>
 		 */
 		if (!ret &amp;&amp; !(current-&gt;real_parent-&gt;flags &amp; PF_EXITING)) {
 			current-&gt;ptrace = PT_PTRACED;
<span class="p_del">-			__ptrace_link(current, current-&gt;real_parent);</span>
<span class="p_add">+			ptrace_link(current, current-&gt;real_parent);</span>
 		}
 	}
 	write_unlock_irq(&amp;tasklist_lock);
<span class="p_header">diff --git a/kernel/rcu/srcu.c b/kernel/rcu/srcu.c</span>
<span class="p_header">index ef3bcfb15b39..6e48a6b6a564 100644</span>
<span class="p_header">--- a/kernel/rcu/srcu.c</span>
<span class="p_header">+++ b/kernel/rcu/srcu.c</span>
<span class="p_chunk">@@ -257,7 +257,7 @@</span> <span class="p_context"> EXPORT_SYMBOL_GPL(cleanup_srcu_struct);</span>
 
 /*
  * Counts the new reader in the appropriate per-CPU element of the
<span class="p_del">- * srcu_struct.  Must be called from process context.</span>
<span class="p_add">+ * srcu_struct.</span>
  * Returns an index that must be passed to the matching srcu_read_unlock().
  */
 int __srcu_read_lock(struct srcu_struct *sp)
<span class="p_chunk">@@ -265,7 +265,7 @@</span> <span class="p_context"> int __srcu_read_lock(struct srcu_struct *sp)</span>
 	int idx;
 
 	idx = READ_ONCE(sp-&gt;completed) &amp; 0x1;
<span class="p_del">-	__this_cpu_inc(sp-&gt;per_cpu_ref-&gt;lock_count[idx]);</span>
<span class="p_add">+	this_cpu_inc(sp-&gt;per_cpu_ref-&gt;lock_count[idx]);</span>
 	smp_mb(); /* B */  /* Avoid leaking the critical section. */
 	return idx;
 }
<span class="p_chunk">@@ -275,7 +275,6 @@</span> <span class="p_context"> EXPORT_SYMBOL_GPL(__srcu_read_lock);</span>
  * Removes the count for the old reader from the appropriate per-CPU
  * element of the srcu_struct.  Note that this may well be a different
  * CPU than that which was incremented by the corresponding srcu_read_lock().
<span class="p_del">- * Must be called from process context.</span>
  */
 void __srcu_read_unlock(struct srcu_struct *sp, int idx)
 {
<span class="p_header">diff --git a/kernel/trace/ftrace.c b/kernel/trace/ftrace.c</span>
<span class="p_header">index dd3e91d68dc7..8827ee31cbf5 100644</span>
<span class="p_header">--- a/kernel/trace/ftrace.c</span>
<span class="p_header">+++ b/kernel/trace/ftrace.c</span>
<span class="p_chunk">@@ -4859,7 +4859,7 @@</span> <span class="p_context"> ftrace_graph_release(struct inode *inode, struct file *file)</span>
 	}
 
  out:
<span class="p_del">-	kfree(fgd-&gt;new_hash);</span>
<span class="p_add">+	free_ftrace_hash(fgd-&gt;new_hash);</span>
 	kfree(fgd);
 
 	return ret;
<span class="p_header">diff --git a/net/bridge/br_netlink.c b/net/bridge/br_netlink.c</span>
<span class="p_header">index 0488c6735c46..8a05a98a8666 100644</span>
<span class="p_header">--- a/net/bridge/br_netlink.c</span>
<span class="p_header">+++ b/net/bridge/br_netlink.c</span>
<span class="p_chunk">@@ -591,7 +591,7 @@</span> <span class="p_context"> static int br_afspec(struct net_bridge *br,</span>
 		err = 0;
 		switch (nla_type(attr)) {
 		case IFLA_BRIDGE_VLAN_TUNNEL_INFO:
<span class="p_del">-			if (!(p-&gt;flags &amp; BR_VLAN_TUNNEL))</span>
<span class="p_add">+			if (!p || !(p-&gt;flags &amp; BR_VLAN_TUNNEL))</span>
 				return -EINVAL;
 			err = br_parse_vlan_tunnel_info(attr, &amp;tinfo_curr);
 			if (err)
<span class="p_header">diff --git a/net/bridge/br_stp_if.c b/net/bridge/br_stp_if.c</span>
<span class="p_header">index 0db8102995a5..6f12a5271219 100644</span>
<span class="p_header">--- a/net/bridge/br_stp_if.c</span>
<span class="p_header">+++ b/net/bridge/br_stp_if.c</span>
<span class="p_chunk">@@ -179,7 +179,8 @@</span> <span class="p_context"> static void br_stp_start(struct net_bridge *br)</span>
 		br_debug(br, &quot;using kernel STP\n&quot;);
 
 		/* To start timers on any ports left in blocking */
<span class="p_del">-		mod_timer(&amp;br-&gt;hello_timer, jiffies + br-&gt;hello_time);</span>
<span class="p_add">+		if (br-&gt;dev-&gt;flags &amp; IFF_UP)</span>
<span class="p_add">+			mod_timer(&amp;br-&gt;hello_timer, jiffies + br-&gt;hello_time);</span>
 		br_port_state_selection(br);
 	}
 
<span class="p_header">diff --git a/net/core/skbuff.c b/net/core/skbuff.c</span>
<span class="p_header">index f1d04592ace0..ac5059aad313 100644</span>
<span class="p_header">--- a/net/core/skbuff.c</span>
<span class="p_header">+++ b/net/core/skbuff.c</span>
<span class="p_chunk">@@ -3755,8 +3755,11 @@</span> <span class="p_context"> struct sk_buff *sock_dequeue_err_skb(struct sock *sk)</span>
 
 	spin_lock_irqsave(&amp;q-&gt;lock, flags);
 	skb = __skb_dequeue(q);
<span class="p_del">-	if (skb &amp;&amp; (skb_next = skb_peek(q)))</span>
<span class="p_add">+	if (skb &amp;&amp; (skb_next = skb_peek(q))) {</span>
 		icmp_next = is_icmp_err_skb(skb_next);
<span class="p_add">+		if (icmp_next)</span>
<span class="p_add">+			sk-&gt;sk_err = SKB_EXT_ERR(skb_next)-&gt;ee.ee_origin;</span>
<span class="p_add">+	}</span>
 	spin_unlock_irqrestore(&amp;q-&gt;lock, flags);
 
 	if (is_icmp_err_skb(skb) &amp;&amp; !icmp_next)
<span class="p_header">diff --git a/net/dsa/dsa2.c b/net/dsa/dsa2.c</span>
<span class="p_header">index 737be6470c7f..ffaa4fb33d0a 100644</span>
<span class="p_header">--- a/net/dsa/dsa2.c</span>
<span class="p_header">+++ b/net/dsa/dsa2.c</span>
<span class="p_chunk">@@ -440,8 +440,10 @@</span> <span class="p_context"> static void dsa_dst_unapply(struct dsa_switch_tree *dst)</span>
 		dsa_ds_unapply(dst, ds);
 	}
 
<span class="p_del">-	if (dst-&gt;cpu_switch)</span>
<span class="p_add">+	if (dst-&gt;cpu_switch) {</span>
 		dsa_cpu_port_ethtool_restore(dst-&gt;cpu_switch);
<span class="p_add">+		dst-&gt;cpu_switch = NULL;</span>
<span class="p_add">+	}</span>
 
 	pr_info(&quot;DSA: tree %d unapplied\n&quot;, dst-&gt;tree);
 	dst-&gt;applied = false;
<span class="p_header">diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c</span>
<span class="p_header">index 13a9a3297eae..b9c1bc5e54db 100644</span>
<span class="p_header">--- a/net/ipv4/af_inet.c</span>
<span class="p_header">+++ b/net/ipv4/af_inet.c</span>
<span class="p_chunk">@@ -1043,7 +1043,7 @@</span> <span class="p_context"> static struct inet_protosw inetsw_array[] =</span>
 		.type =       SOCK_DGRAM,
 		.protocol =   IPPROTO_ICMP,
 		.prot =       &amp;ping_prot,
<span class="p_del">-		.ops =        &amp;inet_dgram_ops,</span>
<span class="p_add">+		.ops =        &amp;inet_sockraw_ops,</span>
 		.flags =      INET_PROTOSW_REUSE,
        },
 
<span class="p_header">diff --git a/net/ipv4/tcp_cong.c b/net/ipv4/tcp_cong.c</span>
<span class="p_header">index 6e3c512054a6..324c9bcc5456 100644</span>
<span class="p_header">--- a/net/ipv4/tcp_cong.c</span>
<span class="p_header">+++ b/net/ipv4/tcp_cong.c</span>
<span class="p_chunk">@@ -180,6 +180,7 @@</span> <span class="p_context"> void tcp_init_congestion_control(struct sock *sk)</span>
 {
 	const struct inet_connection_sock *icsk = inet_csk(sk);
 
<span class="p_add">+	tcp_sk(sk)-&gt;prior_ssthresh = 0;</span>
 	if (icsk-&gt;icsk_ca_ops-&gt;init)
 		icsk-&gt;icsk_ca_ops-&gt;init(sk);
 	if (tcp_ca_needs_ecn(sk))
<span class="p_header">diff --git a/net/ipv6/calipso.c b/net/ipv6/calipso.c</span>
<span class="p_header">index 37ac9de713c6..8d772fea1dde 100644</span>
<span class="p_header">--- a/net/ipv6/calipso.c</span>
<span class="p_header">+++ b/net/ipv6/calipso.c</span>
<span class="p_chunk">@@ -1319,7 +1319,7 @@</span> <span class="p_context"> static int calipso_skbuff_setattr(struct sk_buff *skb,</span>
 	struct ipv6hdr *ip6_hdr;
 	struct ipv6_opt_hdr *hop;
 	unsigned char buf[CALIPSO_MAX_BUFFER];
<span class="p_del">-	int len_delta, new_end, pad;</span>
<span class="p_add">+	int len_delta, new_end, pad, payload;</span>
 	unsigned int start, end;
 
 	ip6_hdr = ipv6_hdr(skb);
<span class="p_chunk">@@ -1346,6 +1346,8 @@</span> <span class="p_context"> static int calipso_skbuff_setattr(struct sk_buff *skb,</span>
 	if (ret_val &lt; 0)
 		return ret_val;
 
<span class="p_add">+	ip6_hdr = ipv6_hdr(skb); /* Reset as skb_cow() may have moved it */</span>
<span class="p_add">+</span>
 	if (len_delta) {
 		if (len_delta &gt; 0)
 			skb_push(skb, len_delta);
<span class="p_chunk">@@ -1355,6 +1357,8 @@</span> <span class="p_context"> static int calipso_skbuff_setattr(struct sk_buff *skb,</span>
 			sizeof(*ip6_hdr) + start);
 		skb_reset_network_header(skb);
 		ip6_hdr = ipv6_hdr(skb);
<span class="p_add">+		payload = ntohs(ip6_hdr-&gt;payload_len);</span>
<span class="p_add">+		ip6_hdr-&gt;payload_len = htons(payload + len_delta);</span>
 	}
 
 	hop = (struct ipv6_opt_hdr *)(ip6_hdr + 1);
<span class="p_header">diff --git a/net/ipv6/ip6_offload.c b/net/ipv6/ip6_offload.c</span>
<span class="p_header">index 280268f1dd7b..cdb3728faca7 100644</span>
<span class="p_header">--- a/net/ipv6/ip6_offload.c</span>
<span class="p_header">+++ b/net/ipv6/ip6_offload.c</span>
<span class="p_chunk">@@ -116,8 +116,10 @@</span> <span class="p_context"> static struct sk_buff *ipv6_gso_segment(struct sk_buff *skb,</span>
 
 		if (udpfrag) {
 			int err = ip6_find_1stfragopt(skb, &amp;prevhdr);
<span class="p_del">-			if (err &lt; 0)</span>
<span class="p_add">+			if (err &lt; 0) {</span>
<span class="p_add">+				kfree_skb_list(segs);</span>
 				return ERR_PTR(err);
<span class="p_add">+			}</span>
 			fptr = (struct frag_hdr *)((u8 *)ipv6h + err);
 			fptr-&gt;frag_off = htons(offset);
 			if (skb-&gt;next)
<span class="p_header">diff --git a/net/ipv6/ip6_tunnel.c b/net/ipv6/ip6_tunnel.c</span>
<span class="p_header">index 15ff33934f79..e2d7867f3112 100644</span>
<span class="p_header">--- a/net/ipv6/ip6_tunnel.c</span>
<span class="p_header">+++ b/net/ipv6/ip6_tunnel.c</span>
<span class="p_chunk">@@ -1095,6 +1095,9 @@</span> <span class="p_context"> int ip6_tnl_xmit(struct sk_buff *skb, struct net_device *dev, __u8 dsfield,</span>
 
 	if (!dst) {
 route_lookup:
<span class="p_add">+		/* add dsfield to flowlabel for route lookup */</span>
<span class="p_add">+		fl6-&gt;flowlabel = ip6_make_flowinfo(dsfield, fl6-&gt;flowlabel);</span>
<span class="p_add">+</span>
 		dst = ip6_route_output(net, NULL, fl6);
 
 		if (dst-&gt;error)
<span class="p_header">diff --git a/net/ipv6/ping.c b/net/ipv6/ping.c</span>
<span class="p_header">index 9b522fa90e6d..ac826dd338ff 100644</span>
<span class="p_header">--- a/net/ipv6/ping.c</span>
<span class="p_header">+++ b/net/ipv6/ping.c</span>
<span class="p_chunk">@@ -192,7 +192,7 @@</span> <span class="p_context"> static struct inet_protosw pingv6_protosw = {</span>
 	.type =      SOCK_DGRAM,
 	.protocol =  IPPROTO_ICMPV6,
 	.prot =      &amp;pingv6_prot,
<span class="p_del">-	.ops =       &amp;inet6_dgram_ops,</span>
<span class="p_add">+	.ops =       &amp;inet6_sockraw_ops,</span>
 	.flags =     INET_PROTOSW_REUSE,
 };
 
<span class="p_header">diff --git a/net/ipv6/raw.c b/net/ipv6/raw.c</span>
<span class="p_header">index 1f992d9e261d..60be012fe708 100644</span>
<span class="p_header">--- a/net/ipv6/raw.c</span>
<span class="p_header">+++ b/net/ipv6/raw.c</span>
<span class="p_chunk">@@ -1338,7 +1338,7 @@</span> <span class="p_context"> void raw6_proc_exit(void)</span>
 #endif	/* CONFIG_PROC_FS */
 
 /* Same as inet6_dgram_ops, sans udp_poll.  */
<span class="p_del">-static const struct proto_ops inet6_sockraw_ops = {</span>
<span class="p_add">+const struct proto_ops inet6_sockraw_ops = {</span>
 	.family		   = PF_INET6,
 	.owner		   = THIS_MODULE,
 	.release	   = inet6_release,
<span class="p_header">diff --git a/net/ipv6/xfrm6_mode_ro.c b/net/ipv6/xfrm6_mode_ro.c</span>
<span class="p_header">index 0e015906f9ca..07d36573f50b 100644</span>
<span class="p_header">--- a/net/ipv6/xfrm6_mode_ro.c</span>
<span class="p_header">+++ b/net/ipv6/xfrm6_mode_ro.c</span>
<span class="p_chunk">@@ -47,6 +47,8 @@</span> <span class="p_context"> static int xfrm6_ro_output(struct xfrm_state *x, struct sk_buff *skb)</span>
 	iph = ipv6_hdr(skb);
 
 	hdr_len = x-&gt;type-&gt;hdr_offset(x, skb, &amp;prevhdr);
<span class="p_add">+	if (hdr_len &lt; 0)</span>
<span class="p_add">+		return hdr_len;</span>
 	skb_set_mac_header(skb, (prevhdr - x-&gt;props.header_len) - skb-&gt;data);
 	skb_set_network_header(skb, -x-&gt;props.header_len);
 	skb-&gt;transport_header = skb-&gt;network_header + hdr_len;
<span class="p_header">diff --git a/net/ipv6/xfrm6_mode_transport.c b/net/ipv6/xfrm6_mode_transport.c</span>
<span class="p_header">index 4439ee44c8b0..5e304102287c 100644</span>
<span class="p_header">--- a/net/ipv6/xfrm6_mode_transport.c</span>
<span class="p_header">+++ b/net/ipv6/xfrm6_mode_transport.c</span>
<span class="p_chunk">@@ -28,6 +28,8 @@</span> <span class="p_context"> static int xfrm6_transport_output(struct xfrm_state *x, struct sk_buff *skb)</span>
 	iph = ipv6_hdr(skb);
 
 	hdr_len = x-&gt;type-&gt;hdr_offset(x, skb, &amp;prevhdr);
<span class="p_add">+	if (hdr_len &lt; 0)</span>
<span class="p_add">+		return hdr_len;</span>
 	skb_set_mac_header(skb, (prevhdr - x-&gt;props.header_len) - skb-&gt;data);
 	skb_set_network_header(skb, -x-&gt;props.header_len);
 	skb-&gt;transport_header = skb-&gt;network_header + hdr_len;
<span class="p_header">diff --git a/net/netfilter/nft_set_rbtree.c b/net/netfilter/nft_set_rbtree.c</span>
<span class="p_header">index 78dfbf9588b3..99aff9618fb8 100644</span>
<span class="p_header">--- a/net/netfilter/nft_set_rbtree.c</span>
<span class="p_header">+++ b/net/netfilter/nft_set_rbtree.c</span>
<span class="p_chunk">@@ -117,17 +117,17 @@</span> <span class="p_context"> static int __nft_rbtree_insert(const struct net *net, const struct nft_set *set,</span>
 		else if (d &gt; 0)
 			p = &amp;parent-&gt;rb_right;
 		else {
<span class="p_del">-			if (nft_set_elem_active(&amp;rbe-&gt;ext, genmask)) {</span>
<span class="p_del">-				if (nft_rbtree_interval_end(rbe) &amp;&amp;</span>
<span class="p_del">-				    !nft_rbtree_interval_end(new))</span>
<span class="p_del">-					p = &amp;parent-&gt;rb_left;</span>
<span class="p_del">-				else if (!nft_rbtree_interval_end(rbe) &amp;&amp;</span>
<span class="p_del">-					 nft_rbtree_interval_end(new))</span>
<span class="p_del">-					p = &amp;parent-&gt;rb_right;</span>
<span class="p_del">-				else {</span>
<span class="p_del">-					*ext = &amp;rbe-&gt;ext;</span>
<span class="p_del">-					return -EEXIST;</span>
<span class="p_del">-				}</span>
<span class="p_add">+			if (nft_rbtree_interval_end(rbe) &amp;&amp;</span>
<span class="p_add">+			    !nft_rbtree_interval_end(new)) {</span>
<span class="p_add">+				p = &amp;parent-&gt;rb_left;</span>
<span class="p_add">+			} else if (!nft_rbtree_interval_end(rbe) &amp;&amp;</span>
<span class="p_add">+				   nft_rbtree_interval_end(new)) {</span>
<span class="p_add">+				p = &amp;parent-&gt;rb_right;</span>
<span class="p_add">+			} else if (nft_set_elem_active(&amp;rbe-&gt;ext, genmask)) {</span>
<span class="p_add">+				*ext = &amp;rbe-&gt;ext;</span>
<span class="p_add">+				return -EEXIST;</span>
<span class="p_add">+			} else {</span>
<span class="p_add">+				p = &amp;parent-&gt;rb_left;</span>
 			}
 		}
 	}
<span class="p_header">diff --git a/security/keys/encrypted-keys/encrypted.c b/security/keys/encrypted-keys/encrypted.c</span>
<span class="p_header">index 0010955d7876..1845d47474a0 100644</span>
<span class="p_header">--- a/security/keys/encrypted-keys/encrypted.c</span>
<span class="p_header">+++ b/security/keys/encrypted-keys/encrypted.c</span>
<span class="p_chunk">@@ -480,12 +480,9 @@</span> <span class="p_context"> static int derived_key_encrypt(struct encrypted_key_payload *epayload,</span>
 	struct skcipher_request *req;
 	unsigned int encrypted_datalen;
 	u8 iv[AES_BLOCK_SIZE];
<span class="p_del">-	unsigned int padlen;</span>
<span class="p_del">-	char pad[16];</span>
 	int ret;
 
 	encrypted_datalen = roundup(epayload-&gt;decrypted_datalen, blksize);
<span class="p_del">-	padlen = encrypted_datalen - epayload-&gt;decrypted_datalen;</span>
 
 	req = init_skcipher_req(derived_key, derived_keylen);
 	ret = PTR_ERR(req);
<span class="p_chunk">@@ -493,11 +490,10 @@</span> <span class="p_context"> static int derived_key_encrypt(struct encrypted_key_payload *epayload,</span>
 		goto out;
 	dump_decrypted_data(epayload);
 
<span class="p_del">-	memset(pad, 0, sizeof pad);</span>
 	sg_init_table(sg_in, 2);
 	sg_set_buf(&amp;sg_in[0], epayload-&gt;decrypted_data,
 		   epayload-&gt;decrypted_datalen);
<span class="p_del">-	sg_set_buf(&amp;sg_in[1], pad, padlen);</span>
<span class="p_add">+	sg_set_page(&amp;sg_in[1], ZERO_PAGE(0), AES_BLOCK_SIZE, 0);</span>
 
 	sg_init_table(sg_out, 1);
 	sg_set_buf(sg_out, epayload-&gt;encrypted_data, encrypted_datalen);
<span class="p_chunk">@@ -584,9 +580,14 @@</span> <span class="p_context"> static int derived_key_decrypt(struct encrypted_key_payload *epayload,</span>
 	struct skcipher_request *req;
 	unsigned int encrypted_datalen;
 	u8 iv[AES_BLOCK_SIZE];
<span class="p_del">-	char pad[16];</span>
<span class="p_add">+	u8 *pad;</span>
 	int ret;
 
<span class="p_add">+	/* Throwaway buffer to hold the unused zero padding at the end */</span>
<span class="p_add">+	pad = kmalloc(AES_BLOCK_SIZE, GFP_KERNEL);</span>
<span class="p_add">+	if (!pad)</span>
<span class="p_add">+		return -ENOMEM;</span>
<span class="p_add">+</span>
 	encrypted_datalen = roundup(epayload-&gt;decrypted_datalen, blksize);
 	req = init_skcipher_req(derived_key, derived_keylen);
 	ret = PTR_ERR(req);
<span class="p_chunk">@@ -594,13 +595,12 @@</span> <span class="p_context"> static int derived_key_decrypt(struct encrypted_key_payload *epayload,</span>
 		goto out;
 	dump_encrypted_data(epayload, encrypted_datalen);
 
<span class="p_del">-	memset(pad, 0, sizeof pad);</span>
 	sg_init_table(sg_in, 1);
 	sg_init_table(sg_out, 2);
 	sg_set_buf(sg_in, epayload-&gt;encrypted_data, encrypted_datalen);
 	sg_set_buf(&amp;sg_out[0], epayload-&gt;decrypted_data,
 		   epayload-&gt;decrypted_datalen);
<span class="p_del">-	sg_set_buf(&amp;sg_out[1], pad, sizeof pad);</span>
<span class="p_add">+	sg_set_buf(&amp;sg_out[1], pad, AES_BLOCK_SIZE);</span>
 
 	memcpy(iv, epayload-&gt;iv, sizeof(iv));
 	skcipher_request_set_crypt(req, sg_in, sg_out, encrypted_datalen, iv);
<span class="p_chunk">@@ -612,6 +612,7 @@</span> <span class="p_context"> static int derived_key_decrypt(struct encrypted_key_payload *epayload,</span>
 		goto out;
 	dump_decrypted_data(epayload);
 out:
<span class="p_add">+	kfree(pad);</span>
 	return ret;
 }
 
<span class="p_header">diff --git a/security/keys/key.c b/security/keys/key.c</span>
<span class="p_header">index 346fbf201c22..2f4ce35ae2aa 100644</span>
<span class="p_header">--- a/security/keys/key.c</span>
<span class="p_header">+++ b/security/keys/key.c</span>
<span class="p_chunk">@@ -962,12 +962,11 @@</span> <span class="p_context"> int key_update(key_ref_t key_ref, const void *payload, size_t plen)</span>
 	/* the key must be writable */
 	ret = key_permission(key_ref, KEY_NEED_WRITE);
 	if (ret &lt; 0)
<span class="p_del">-		goto error;</span>
<span class="p_add">+		return ret;</span>
 
 	/* attempt to update it if supported */
<span class="p_del">-	ret = -EOPNOTSUPP;</span>
 	if (!key-&gt;type-&gt;update)
<span class="p_del">-		goto error;</span>
<span class="p_add">+		return -EOPNOTSUPP;</span>
 
 	memset(&amp;prep, 0, sizeof(prep));
 	prep.data = payload;
<span class="p_header">diff --git a/security/keys/keyctl.c b/security/keys/keyctl.c</span>
<span class="p_header">index 4ad3212adebe..3663a98b473d 100644</span>
<span class="p_header">--- a/security/keys/keyctl.c</span>
<span class="p_header">+++ b/security/keys/keyctl.c</span>
<span class="p_chunk">@@ -99,7 +99,7 @@</span> <span class="p_context"> SYSCALL_DEFINE5(add_key, const char __user *, _type,</span>
 	/* pull the payload in if one was supplied */
 	payload = NULL;
 
<span class="p_del">-	if (_payload) {</span>
<span class="p_add">+	if (plen) {</span>
 		ret = -ENOMEM;
 		payload = kmalloc(plen, GFP_KERNEL | __GFP_NOWARN);
 		if (!payload) {
<span class="p_chunk">@@ -329,7 +329,7 @@</span> <span class="p_context"> long keyctl_update_key(key_serial_t id,</span>
 
 	/* pull the payload in if one was supplied */
 	payload = NULL;
<span class="p_del">-	if (_payload) {</span>
<span class="p_add">+	if (plen) {</span>
 		ret = -ENOMEM;
 		payload = kmalloc(plen, GFP_KERNEL);
 		if (!payload)
<span class="p_header">diff --git a/sound/core/timer.c b/sound/core/timer.c</span>
<span class="p_header">index 6d4fbc439246..171c01ad9375 100644</span>
<span class="p_header">--- a/sound/core/timer.c</span>
<span class="p_header">+++ b/sound/core/timer.c</span>
<span class="p_chunk">@@ -1623,6 +1623,7 @@</span> <span class="p_context"> static int snd_timer_user_tselect(struct file *file,</span>
 	if (err &lt; 0)
 		goto __err;
 
<span class="p_add">+	tu-&gt;qhead = tu-&gt;qtail = tu-&gt;qused = 0;</span>
 	kfree(tu-&gt;queue);
 	tu-&gt;queue = NULL;
 	kfree(tu-&gt;tqueue);
<span class="p_chunk">@@ -1964,6 +1965,7 @@</span> <span class="p_context"> static ssize_t snd_timer_user_read(struct file *file, char __user *buffer,</span>
 
 	tu = file-&gt;private_data;
 	unit = tu-&gt;tread ? sizeof(struct snd_timer_tread) : sizeof(struct snd_timer_read);
<span class="p_add">+	mutex_lock(&amp;tu-&gt;ioctl_lock);</span>
 	spin_lock_irq(&amp;tu-&gt;qlock);
 	while ((long)count - result &gt;= unit) {
 		while (!tu-&gt;qused) {
<span class="p_chunk">@@ -1979,7 +1981,9 @@</span> <span class="p_context"> static ssize_t snd_timer_user_read(struct file *file, char __user *buffer,</span>
 			add_wait_queue(&amp;tu-&gt;qchange_sleep, &amp;wait);
 
 			spin_unlock_irq(&amp;tu-&gt;qlock);
<span class="p_add">+			mutex_unlock(&amp;tu-&gt;ioctl_lock);</span>
 			schedule();
<span class="p_add">+			mutex_lock(&amp;tu-&gt;ioctl_lock);</span>
 			spin_lock_irq(&amp;tu-&gt;qlock);
 
 			remove_wait_queue(&amp;tu-&gt;qchange_sleep, &amp;wait);
<span class="p_chunk">@@ -1999,7 +2003,6 @@</span> <span class="p_context"> static ssize_t snd_timer_user_read(struct file *file, char __user *buffer,</span>
 		tu-&gt;qused--;
 		spin_unlock_irq(&amp;tu-&gt;qlock);
 
<span class="p_del">-		mutex_lock(&amp;tu-&gt;ioctl_lock);</span>
 		if (tu-&gt;tread) {
 			if (copy_to_user(buffer, &amp;tu-&gt;tqueue[qhead],
 					 sizeof(struct snd_timer_tread)))
<span class="p_chunk">@@ -2009,7 +2012,6 @@</span> <span class="p_context"> static ssize_t snd_timer_user_read(struct file *file, char __user *buffer,</span>
 					 sizeof(struct snd_timer_read)))
 				err = -EFAULT;
 		}
<span class="p_del">-		mutex_unlock(&amp;tu-&gt;ioctl_lock);</span>
 
 		spin_lock_irq(&amp;tu-&gt;qlock);
 		if (err &lt; 0)
<span class="p_chunk">@@ -2019,6 +2021,7 @@</span> <span class="p_context"> static ssize_t snd_timer_user_read(struct file *file, char __user *buffer,</span>
 	}
  _error:
 	spin_unlock_irq(&amp;tu-&gt;qlock);
<span class="p_add">+	mutex_unlock(&amp;tu-&gt;ioctl_lock);</span>
 	return result &gt; 0 ? result : err;
 }
 
<span class="p_header">diff --git a/sound/soc/soc-core.c b/sound/soc/soc-core.c</span>
<span class="p_header">index 2722bb0c5573..98d60f471c5d 100644</span>
<span class="p_header">--- a/sound/soc/soc-core.c</span>
<span class="p_header">+++ b/sound/soc/soc-core.c</span>
<span class="p_chunk">@@ -2286,6 +2286,9 @@</span> <span class="p_context"> static int soc_cleanup_card_resources(struct snd_soc_card *card)</span>
 	list_for_each_entry(rtd, &amp;card-&gt;rtd_list, list)
 		flush_delayed_work(&amp;rtd-&gt;delayed_work);
 
<span class="p_add">+	/* free the ALSA card at first; this syncs with pending operations */</span>
<span class="p_add">+	snd_card_free(card-&gt;snd_card);</span>
<span class="p_add">+</span>
 	/* remove and free each DAI */
 	soc_remove_dai_links(card);
 	soc_remove_pcm_runtimes(card);
<span class="p_chunk">@@ -2300,9 +2303,7 @@</span> <span class="p_context"> static int soc_cleanup_card_resources(struct snd_soc_card *card)</span>
 	if (card-&gt;remove)
 		card-&gt;remove(card);
 
<span class="p_del">-	snd_card_free(card-&gt;snd_card);</span>
 	return 0;
<span class="p_del">-</span>
 }
 
 /* removes a socdev */
<span class="p_header">diff --git a/sound/x86/intel_hdmi_audio.c b/sound/x86/intel_hdmi_audio.c</span>
<span class="p_header">index c505b019e09c..bfac6f21ae5e 100644</span>
<span class="p_header">--- a/sound/x86/intel_hdmi_audio.c</span>
<span class="p_header">+++ b/sound/x86/intel_hdmi_audio.c</span>
<span class="p_chunk">@@ -1809,10 +1809,6 @@</span> <span class="p_context"> static int hdmi_lpe_audio_probe(struct platform_device *pdev)</span>
 	pdata-&gt;notify_pending = false;
 	spin_unlock_irq(&amp;pdata-&gt;lpe_audio_slock);
 
<span class="p_del">-	/* runtime PM isn&#39;t enabled as default, since it won&#39;t save much on</span>
<span class="p_del">-	 * BYT/CHT devices; user who want the runtime PM should adjust the</span>
<span class="p_del">-	 * power/ontrol and power/autosuspend_delay_ms sysfs entries instead</span>
<span class="p_del">-	 */</span>
 	pm_runtime_use_autosuspend(&amp;pdev-&gt;dev);
 	pm_runtime_mark_last_busy(&amp;pdev-&gt;dev);
 	pm_runtime_set_active(&amp;pdev-&gt;dev);

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



