
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>[RESEND,3/4] iommu: add qcom_iommu - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    [RESEND,3/4] iommu: add qcom_iommu</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=25981">Rob Clark</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>Aug. 9, 2017, 2:43 p.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;20170809144310.22855-4-robdclark@gmail.com&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/9890765/mbox/"
   >mbox</a>
|
   <a href="/patch/9890765/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/9890765/">/patch/9890765/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
	[172.30.200.125])
	by pdx-korg-patchwork.web.codeaurora.org (Postfix) with ESMTP id
	37528601EB for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Wed,  9 Aug 2017 14:43:48 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 2CD2F28A82
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Wed,  9 Aug 2017 14:43:48 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id 2171328A96; Wed,  9 Aug 2017 14:43:48 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-6.5 required=2.0 tests=BAYES_00,DKIM_SIGNED,
	DKIM_VALID, DKIM_VALID_AU, FREEMAIL_FROM, RCVD_IN_DNSWL_HI,
	RCVD_IN_SORBS_SPAM autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id A6EA628A82
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Wed,  9 Aug 2017 14:43:46 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1753388AbdHIOnl (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Wed, 9 Aug 2017 10:43:41 -0400
Received: from mail-qt0-f194.google.com ([209.85.216.194]:36285 &quot;EHLO
	mail-qt0-f194.google.com&quot; rhost-flags-OK-OK-OK-OK) by vger.kernel.org
	with ESMTP id S1753265AbdHIOni (ORCPT
	&lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Wed, 9 Aug 2017 10:43:38 -0400
Received: by mail-qt0-f194.google.com with SMTP id c15so5969153qta.3;
	Wed, 09 Aug 2017 07:43:38 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
	d=gmail.com; s=20161025;
	h=from:to:cc:subject:date:message-id:in-reply-to:references;
	bh=OsORIMV0T/2g5OMl7S4UQusc8zKovABBhfi6pOoM+OA=;
	b=NkmaEroUTy3FQg+qh0m9yZnej+nFs6t+Gb2ael1FhVLzo3G5q0zneN+UfWeygcbux1
	cv+zt0o7QsGh5BS6+6ghIvlX/Crscns+Njsx3QDqTtMj70mBrpyxELrTW+3ZyQeo83ok
	U364MrJfMTSjTpj3wBQ2cVVCPYDhZawH+PebQOVo+pO3/mnMYXOjD17PAOc+YTtaiSyO
	MzghbAhMMpbT5rjB6vfvOb9x+p/FwfPBCGD9bKAihG/fOXsYYeejgycS8DOPYGEGTpXe
	IcOtY5rvCiOEhL7lV6DJxlI3a03BfeVrxVhIdUBIawlTOhB7SPQkSMfQfbsTFTfB2+Mq
	WVHg==
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
	d=1e100.net; s=20161025;
	h=x-gm-message-state:from:to:cc:subject:date:message-id:in-reply-to
	:references;
	bh=OsORIMV0T/2g5OMl7S4UQusc8zKovABBhfi6pOoM+OA=;
	b=BK/YNpB3qV1LHZDzIQWOv7Js0GRgJt2j18xEYtyr4PA9bD+gkWTGPf0WRCLTBHA2Rv
	B9nD61LrijZ6xwWneCkyklbPQkhygNZO+PjP7IYUv7251S8jh89gpAPBa1uEKaaW6+St
	bGJzKsRCRx0WNz5uAq7rxbsWym9hjVb4PvFopJusSkWHQMmAOPHDHvGvKm2HAr+T0oe4
	z1BeZjausWZ7o+EDcWwERqkUZ/xlwV1qiqUrX+zpebJ1ZuXO/kle6Nacsg/iUGrqfW8A
	cIsJlWnGjBHQJBXFBchCrTUE6OKmkP3aPZDuxugslpHld2YzoVdKjklCffyOjgWI3NgU
	0wmQ==
X-Gm-Message-State: AHYfb5h9dOgl8//FfLBetf/JwhBY5JykeQHdxxdCphFgzyrWdnrFvuuF
	KDTO8n2PcyBWQw==
X-Received: by 10.237.54.227 with SMTP id f90mr11852538qtb.256.1502289817259;
	Wed, 09 Aug 2017 07:43:37 -0700 (PDT)
Received: from localhost ([2601:184:4780:aac0:25f8:dd96:a084:785a])
	by smtp.gmail.com with ESMTPSA id
	g1sm594503qta.65.2017.08.09.07.43.35
	(version=TLS1_2 cipher=ECDHE-RSA-CHACHA20-POLY1305 bits=256/256);
	Wed, 09 Aug 2017 07:43:36 -0700 (PDT)
From: Rob Clark &lt;robdclark@gmail.com&gt;
To: iommu@lists.linux-foundation.org
Cc: linux-arm-msm@vger.kernel.org, Archit Taneja &lt;architt@codeaurora.org&gt;,
	Rob Herring &lt;robh@kernel.org&gt;, Will Deacon &lt;will.deacon@arm.com&gt;,
	Sricharan &lt;sricharan@codeaurora.org&gt;,
	Mark Rutland &lt;mark.rutland@arm.com&gt;, Robin Murphy &lt;robin.murphy@arm.com&gt;,
	Rob Clark &lt;robdclark@gmail.com&gt;,
	Joerg Roedel &lt;joro@8bytes.org&gt;, linux-kernel@vger.kernel.org
Subject: [RESEND PATCH 3/4] iommu: add qcom_iommu
Date: Wed,  9 Aug 2017 10:43:04 -0400
Message-Id: &lt;20170809144310.22855-4-robdclark@gmail.com&gt;
X-Mailer: git-send-email 2.13.0
In-Reply-To: &lt;20170809144310.22855-1-robdclark@gmail.com&gt;
References: &lt;20170809144310.22855-1-robdclark@gmail.com&gt;
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=25981">Rob Clark</a> - Aug. 9, 2017, 2:43 p.m.</div>
<pre class="content">
An iommu driver for Qualcomm &quot;B&quot; family devices which do implement the
ARM SMMU spec, but not in a way that is compatible with how the arm-smmu
driver is designed.  It seems SMMU_SCR1.GASRAE=1 so the global register
space is not accessible.  This means it needs to get configuration from
devicetree instead of setting it up dynamically.

In the end, other than register definitions, there is not much code to
share with arm-smmu (other than what has already been refactored out
into the pgtable helpers).
<span class="signed-off-by">
Signed-off-by: Rob Clark &lt;robdclark@gmail.com&gt;</span>
<span class="tested-by">Tested-by: Riku Voipio &lt;riku.voipio@linaro.org&gt;</span>
---
 drivers/iommu/Kconfig      |  10 +
 drivers/iommu/Makefile     |   1 +
 drivers/iommu/qcom_iommu.c | 868 +++++++++++++++++++++++++++++++++++++++++++++
 3 files changed, 879 insertions(+)
 create mode 100644 drivers/iommu/qcom_iommu.c
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">diff --git a/drivers/iommu/Kconfig b/drivers/iommu/Kconfig</span>
<span class="p_header">index f73ff28f77e2..92f5fd2e0e4b 100644</span>
<span class="p_header">--- a/drivers/iommu/Kconfig</span>
<span class="p_header">+++ b/drivers/iommu/Kconfig</span>
<span class="p_chunk">@@ -367,4 +367,14 @@</span> <span class="p_context"> config MTK_IOMMU_V1</span>
 
 	  if unsure, say N here.
 
<span class="p_add">+config QCOM_IOMMU</span>
<span class="p_add">+	# Note: iommu drivers cannot (yet?) be built as modules</span>
<span class="p_add">+	bool &quot;Qualcomm IOMMU Support&quot;</span>
<span class="p_add">+	depends on ARCH_QCOM || COMPILE_TEST</span>
<span class="p_add">+	select IOMMU_API</span>
<span class="p_add">+	select IOMMU_IO_PGTABLE_LPAE</span>
<span class="p_add">+	select ARM_DMA_USE_IOMMU</span>
<span class="p_add">+	help</span>
<span class="p_add">+	  Support for IOMMU on certain Qualcomm SoCs.</span>
<span class="p_add">+</span>
 endif # IOMMU_SUPPORT
<span class="p_header">diff --git a/drivers/iommu/Makefile b/drivers/iommu/Makefile</span>
<span class="p_header">index 195f7b997d8e..b910aea813a1 100644</span>
<span class="p_header">--- a/drivers/iommu/Makefile</span>
<span class="p_header">+++ b/drivers/iommu/Makefile</span>
<span class="p_chunk">@@ -27,3 +27,4 @@</span> <span class="p_context"> obj-$(CONFIG_TEGRA_IOMMU_SMMU) += tegra-smmu.o</span>
 obj-$(CONFIG_EXYNOS_IOMMU) += exynos-iommu.o
 obj-$(CONFIG_FSL_PAMU) += fsl_pamu.o fsl_pamu_domain.o
 obj-$(CONFIG_S390_IOMMU) += s390-iommu.o
<span class="p_add">+obj-$(CONFIG_QCOM_IOMMU) += qcom_iommu.o</span>
<span class="p_header">diff --git a/drivers/iommu/qcom_iommu.c b/drivers/iommu/qcom_iommu.c</span>
new file mode 100644
<span class="p_header">index 000000000000..860cad1cb167</span>
<span class="p_header">--- /dev/null</span>
<span class="p_header">+++ b/drivers/iommu/qcom_iommu.c</span>
<span class="p_chunk">@@ -0,0 +1,868 @@</span> <span class="p_context"></span>
<span class="p_add">+/*</span>
<span class="p_add">+ * IOMMU API for QCOM secure IOMMUs.  Somewhat based on arm-smmu.c</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * This program is free software; you can redistribute it and/or modify</span>
<span class="p_add">+ * it under the terms of the GNU General Public License version 2 as</span>
<span class="p_add">+ * published by the Free Software Foundation.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * This program is distributed in the hope that it will be useful,</span>
<span class="p_add">+ * but WITHOUT ANY WARRANTY; without even the implied warranty of</span>
<span class="p_add">+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the</span>
<span class="p_add">+ * GNU General Public License for more details.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * You should have received a copy of the GNU General Public License</span>
<span class="p_add">+ * along with this program.  If not, see &lt;http://www.gnu.org/licenses/&gt;.</span>
<span class="p_add">+ *</span>
<span class="p_add">+ * Copyright (C) 2013 ARM Limited</span>
<span class="p_add">+ * Copyright (C) 2017 Red Hat</span>
<span class="p_add">+ */</span>
<span class="p_add">+</span>
<span class="p_add">+#include &lt;linux/atomic.h&gt;</span>
<span class="p_add">+#include &lt;linux/clk.h&gt;</span>
<span class="p_add">+#include &lt;linux/delay.h&gt;</span>
<span class="p_add">+#include &lt;linux/dma-iommu.h&gt;</span>
<span class="p_add">+#include &lt;linux/dma-mapping.h&gt;</span>
<span class="p_add">+#include &lt;linux/err.h&gt;</span>
<span class="p_add">+#include &lt;linux/interrupt.h&gt;</span>
<span class="p_add">+#include &lt;linux/io.h&gt;</span>
<span class="p_add">+#include &lt;linux/io-64-nonatomic-hi-lo.h&gt;</span>
<span class="p_add">+#include &lt;linux/iommu.h&gt;</span>
<span class="p_add">+#include &lt;linux/iopoll.h&gt;</span>
<span class="p_add">+#include &lt;linux/kconfig.h&gt;</span>
<span class="p_add">+#include &lt;linux/module.h&gt;</span>
<span class="p_add">+#include &lt;linux/mutex.h&gt;</span>
<span class="p_add">+#include &lt;linux/of.h&gt;</span>
<span class="p_add">+#include &lt;linux/of_address.h&gt;</span>
<span class="p_add">+#include &lt;linux/of_device.h&gt;</span>
<span class="p_add">+#include &lt;linux/of_iommu.h&gt;</span>
<span class="p_add">+#include &lt;linux/platform_device.h&gt;</span>
<span class="p_add">+#include &lt;linux/pm.h&gt;</span>
<span class="p_add">+#include &lt;linux/pm_runtime.h&gt;</span>
<span class="p_add">+#include &lt;linux/qcom_scm.h&gt;</span>
<span class="p_add">+#include &lt;linux/slab.h&gt;</span>
<span class="p_add">+#include &lt;linux/spinlock.h&gt;</span>
<span class="p_add">+</span>
<span class="p_add">+#include &quot;io-pgtable.h&quot;</span>
<span class="p_add">+#include &quot;arm-smmu-regs.h&quot;</span>
<span class="p_add">+</span>
<span class="p_add">+#define SMMU_INTR_SEL_NS     0x2000</span>
<span class="p_add">+</span>
<span class="p_add">+struct qcom_iommu_ctx;</span>
<span class="p_add">+</span>
<span class="p_add">+struct qcom_iommu_dev {</span>
<span class="p_add">+	/* IOMMU core code handle */</span>
<span class="p_add">+	struct iommu_device	 iommu;</span>
<span class="p_add">+	struct device		*dev;</span>
<span class="p_add">+	struct clk		*iface_clk;</span>
<span class="p_add">+	struct clk		*bus_clk;</span>
<span class="p_add">+	void __iomem		*local_base;</span>
<span class="p_add">+	u32			 sec_id;</span>
<span class="p_add">+	u8			 num_ctxs;</span>
<span class="p_add">+	struct qcom_iommu_ctx	*ctxs[0];   /* indexed by asid-1 */</span>
<span class="p_add">+};</span>
<span class="p_add">+</span>
<span class="p_add">+struct qcom_iommu_ctx {</span>
<span class="p_add">+	struct device		*dev;</span>
<span class="p_add">+	void __iomem		*base;</span>
<span class="p_add">+	bool			 secure_init;</span>
<span class="p_add">+	u8			 asid;      /* asid and ctx bank # are 1:1 */</span>
<span class="p_add">+};</span>
<span class="p_add">+</span>
<span class="p_add">+struct qcom_iommu_domain {</span>
<span class="p_add">+	struct io_pgtable_ops	*pgtbl_ops;</span>
<span class="p_add">+	spinlock_t		 pgtbl_lock;</span>
<span class="p_add">+	struct mutex		 init_mutex; /* Protects iommu pointer */</span>
<span class="p_add">+	struct iommu_domain	 domain;</span>
<span class="p_add">+	struct qcom_iommu_dev	*iommu;</span>
<span class="p_add">+};</span>
<span class="p_add">+</span>
<span class="p_add">+static struct qcom_iommu_domain *to_qcom_iommu_domain(struct iommu_domain *dom)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return container_of(dom, struct qcom_iommu_domain, domain);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static const struct iommu_ops qcom_iommu_ops;</span>
<span class="p_add">+</span>
<span class="p_add">+static struct qcom_iommu_dev * to_iommu(struct iommu_fwspec *fwspec)</span>
<span class="p_add">+{</span>
<span class="p_add">+	if (!fwspec || fwspec-&gt;ops != &amp;qcom_iommu_ops)</span>
<span class="p_add">+		return NULL;</span>
<span class="p_add">+	return fwspec-&gt;iommu_priv;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static struct qcom_iommu_ctx * to_ctx(struct iommu_fwspec *fwspec, unsigned asid)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct qcom_iommu_dev *qcom_iommu = to_iommu(fwspec);</span>
<span class="p_add">+	if (!qcom_iommu)</span>
<span class="p_add">+		return NULL;</span>
<span class="p_add">+	return qcom_iommu-&gt;ctxs[asid - 1];</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline void</span>
<span class="p_add">+iommu_writel(struct qcom_iommu_ctx *ctx, unsigned reg, u32 val)</span>
<span class="p_add">+{</span>
<span class="p_add">+	writel_relaxed(val, ctx-&gt;base + reg);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline void</span>
<span class="p_add">+iommu_writeq(struct qcom_iommu_ctx *ctx, unsigned reg, u64 val)</span>
<span class="p_add">+{</span>
<span class="p_add">+	writeq_relaxed(val, ctx-&gt;base + reg);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline u32</span>
<span class="p_add">+iommu_readl(struct qcom_iommu_ctx *ctx, unsigned reg)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return readl_relaxed(ctx-&gt;base + reg);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static inline u64</span>
<span class="p_add">+iommu_readq(struct qcom_iommu_ctx *ctx, unsigned reg)</span>
<span class="p_add">+{</span>
<span class="p_add">+	return readq_relaxed(ctx-&gt;base + reg);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static void qcom_iommu_tlb_sync(void *cookie)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct iommu_fwspec *fwspec = cookie;</span>
<span class="p_add">+	unsigned i;</span>
<span class="p_add">+</span>
<span class="p_add">+	for (i = 0; i &lt; fwspec-&gt;num_ids; i++) {</span>
<span class="p_add">+		struct qcom_iommu_ctx *ctx = to_ctx(fwspec, fwspec-&gt;ids[i]);</span>
<span class="p_add">+		unsigned int val, ret;</span>
<span class="p_add">+</span>
<span class="p_add">+		iommu_writel(ctx, ARM_SMMU_CB_TLBSYNC, 0);</span>
<span class="p_add">+</span>
<span class="p_add">+		ret = readl_poll_timeout(ctx-&gt;base + ARM_SMMU_CB_TLBSTATUS, val,</span>
<span class="p_add">+					 (val &amp; 0x1) == 0, 0, 5000000);</span>
<span class="p_add">+		if (ret)</span>
<span class="p_add">+			dev_err(ctx-&gt;dev, &quot;timeout waiting for TLB SYNC\n&quot;);</span>
<span class="p_add">+	}</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static void qcom_iommu_tlb_inv_context(void *cookie)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct iommu_fwspec *fwspec = cookie;</span>
<span class="p_add">+	unsigned i;</span>
<span class="p_add">+</span>
<span class="p_add">+	for (i = 0; i &lt; fwspec-&gt;num_ids; i++) {</span>
<span class="p_add">+		struct qcom_iommu_ctx *ctx = to_ctx(fwspec, fwspec-&gt;ids[i]);</span>
<span class="p_add">+		iommu_writel(ctx, ARM_SMMU_CB_S1_TLBIASID, ctx-&gt;asid);</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	qcom_iommu_tlb_sync(cookie);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static void qcom_iommu_tlb_inv_range_nosync(unsigned long iova, size_t size,</span>
<span class="p_add">+					    size_t granule, bool leaf, void *cookie)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct iommu_fwspec *fwspec = cookie;</span>
<span class="p_add">+	unsigned i, reg;</span>
<span class="p_add">+</span>
<span class="p_add">+	reg = leaf ? ARM_SMMU_CB_S1_TLBIVAL : ARM_SMMU_CB_S1_TLBIVA;</span>
<span class="p_add">+</span>
<span class="p_add">+	for (i = 0; i &lt; fwspec-&gt;num_ids; i++) {</span>
<span class="p_add">+		struct qcom_iommu_ctx *ctx = to_ctx(fwspec, fwspec-&gt;ids[i]);</span>
<span class="p_add">+		size_t s = size;</span>
<span class="p_add">+</span>
<span class="p_add">+		iova &amp;= ~12UL;</span>
<span class="p_add">+		iova |= ctx-&gt;asid;</span>
<span class="p_add">+		do {</span>
<span class="p_add">+			iommu_writel(ctx, reg, iova);</span>
<span class="p_add">+			iova += granule;</span>
<span class="p_add">+		} while (s -= granule);</span>
<span class="p_add">+	}</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static const struct iommu_gather_ops qcom_gather_ops = {</span>
<span class="p_add">+	.tlb_flush_all	= qcom_iommu_tlb_inv_context,</span>
<span class="p_add">+	.tlb_add_flush	= qcom_iommu_tlb_inv_range_nosync,</span>
<span class="p_add">+	.tlb_sync	= qcom_iommu_tlb_sync,</span>
<span class="p_add">+};</span>
<span class="p_add">+</span>
<span class="p_add">+static irqreturn_t qcom_iommu_fault(int irq, void *dev)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct qcom_iommu_ctx *ctx = dev;</span>
<span class="p_add">+	u32 fsr, fsynr;</span>
<span class="p_add">+	u64 iova;</span>
<span class="p_add">+</span>
<span class="p_add">+	fsr = iommu_readl(ctx, ARM_SMMU_CB_FSR);</span>
<span class="p_add">+</span>
<span class="p_add">+	if (!(fsr &amp; FSR_FAULT))</span>
<span class="p_add">+		return IRQ_NONE;</span>
<span class="p_add">+</span>
<span class="p_add">+	fsynr = iommu_readl(ctx, ARM_SMMU_CB_FSYNR0);</span>
<span class="p_add">+	iova = iommu_readq(ctx, ARM_SMMU_CB_FAR);</span>
<span class="p_add">+</span>
<span class="p_add">+	dev_err_ratelimited(ctx-&gt;dev,</span>
<span class="p_add">+			    &quot;Unhandled context fault: fsr=0x%x, &quot;</span>
<span class="p_add">+			    &quot;iova=0x%016llx, fsynr=0x%x, cb=%d\n&quot;,</span>
<span class="p_add">+			    fsr, iova, fsynr, ctx-&gt;asid);</span>
<span class="p_add">+</span>
<span class="p_add">+	iommu_writel(ctx, ARM_SMMU_CB_FSR, fsr);</span>
<span class="p_add">+</span>
<span class="p_add">+	return IRQ_HANDLED;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static int qcom_iommu_init_domain(struct iommu_domain *domain,</span>
<span class="p_add">+				  struct qcom_iommu_dev *qcom_iommu,</span>
<span class="p_add">+				  struct iommu_fwspec *fwspec)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct qcom_iommu_domain *qcom_domain = to_qcom_iommu_domain(domain);</span>
<span class="p_add">+	struct io_pgtable_ops *pgtbl_ops;</span>
<span class="p_add">+	struct io_pgtable_cfg pgtbl_cfg;</span>
<span class="p_add">+	int i, ret = 0;</span>
<span class="p_add">+	u32 reg;</span>
<span class="p_add">+</span>
<span class="p_add">+	mutex_lock(&amp;qcom_domain-&gt;init_mutex);</span>
<span class="p_add">+	if (qcom_domain-&gt;iommu)</span>
<span class="p_add">+		goto out_unlock;</span>
<span class="p_add">+</span>
<span class="p_add">+	pgtbl_cfg = (struct io_pgtable_cfg) {</span>
<span class="p_add">+		.pgsize_bitmap	= qcom_iommu_ops.pgsize_bitmap,</span>
<span class="p_add">+		.ias		= 32,</span>
<span class="p_add">+		.oas		= 40,</span>
<span class="p_add">+		.tlb		= &amp;qcom_gather_ops,</span>
<span class="p_add">+		.iommu_dev	= qcom_iommu-&gt;dev,</span>
<span class="p_add">+	};</span>
<span class="p_add">+</span>
<span class="p_add">+	qcom_domain-&gt;iommu = qcom_iommu;</span>
<span class="p_add">+	pgtbl_ops = alloc_io_pgtable_ops(ARM_32_LPAE_S1, &amp;pgtbl_cfg, fwspec);</span>
<span class="p_add">+	if (!pgtbl_ops) {</span>
<span class="p_add">+		dev_err(qcom_iommu-&gt;dev, &quot;failed to allocate pagetable ops\n&quot;);</span>
<span class="p_add">+		ret = -ENOMEM;</span>
<span class="p_add">+		goto out_clear_iommu;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	/* Update the domain&#39;s page sizes to reflect the page table format */</span>
<span class="p_add">+	domain-&gt;pgsize_bitmap = pgtbl_cfg.pgsize_bitmap;</span>
<span class="p_add">+	domain-&gt;geometry.aperture_end = (1ULL &lt;&lt; pgtbl_cfg.ias) - 1;</span>
<span class="p_add">+	domain-&gt;geometry.force_aperture = true;</span>
<span class="p_add">+</span>
<span class="p_add">+	for (i = 0; i &lt; fwspec-&gt;num_ids; i++) {</span>
<span class="p_add">+		struct qcom_iommu_ctx *ctx = to_ctx(fwspec, fwspec-&gt;ids[i]);</span>
<span class="p_add">+</span>
<span class="p_add">+		if (!ctx-&gt;secure_init) {</span>
<span class="p_add">+			ret = qcom_scm_restore_sec_cfg(qcom_iommu-&gt;sec_id, ctx-&gt;asid);</span>
<span class="p_add">+			if (ret) {</span>
<span class="p_add">+				dev_err(qcom_iommu-&gt;dev, &quot;secure init failed: %d\n&quot;, ret);</span>
<span class="p_add">+				goto out_clear_iommu;</span>
<span class="p_add">+			}</span>
<span class="p_add">+			ctx-&gt;secure_init = true;</span>
<span class="p_add">+		}</span>
<span class="p_add">+</span>
<span class="p_add">+		/* TTBRs */</span>
<span class="p_add">+		iommu_writeq(ctx, ARM_SMMU_CB_TTBR0,</span>
<span class="p_add">+				pgtbl_cfg.arm_lpae_s1_cfg.ttbr[0] |</span>
<span class="p_add">+				((u64)ctx-&gt;asid &lt;&lt; TTBRn_ASID_SHIFT));</span>
<span class="p_add">+		iommu_writeq(ctx, ARM_SMMU_CB_TTBR1,</span>
<span class="p_add">+				pgtbl_cfg.arm_lpae_s1_cfg.ttbr[1] |</span>
<span class="p_add">+				((u64)ctx-&gt;asid &lt;&lt; TTBRn_ASID_SHIFT));</span>
<span class="p_add">+</span>
<span class="p_add">+		/* TTBCR */</span>
<span class="p_add">+		iommu_writel(ctx, ARM_SMMU_CB_TTBCR2,</span>
<span class="p_add">+				(pgtbl_cfg.arm_lpae_s1_cfg.tcr &gt;&gt; 32) |</span>
<span class="p_add">+				TTBCR2_SEP_UPSTREAM);</span>
<span class="p_add">+		iommu_writel(ctx, ARM_SMMU_CB_TTBCR,</span>
<span class="p_add">+				pgtbl_cfg.arm_lpae_s1_cfg.tcr);</span>
<span class="p_add">+</span>
<span class="p_add">+		/* MAIRs (stage-1 only) */</span>
<span class="p_add">+		iommu_writel(ctx, ARM_SMMU_CB_S1_MAIR0,</span>
<span class="p_add">+				pgtbl_cfg.arm_lpae_s1_cfg.mair[0]);</span>
<span class="p_add">+		iommu_writel(ctx, ARM_SMMU_CB_S1_MAIR1,</span>
<span class="p_add">+				pgtbl_cfg.arm_lpae_s1_cfg.mair[1]);</span>
<span class="p_add">+</span>
<span class="p_add">+		/* SCTLR */</span>
<span class="p_add">+		reg = SCTLR_CFIE | SCTLR_CFRE | SCTLR_AFE | SCTLR_TRE |</span>
<span class="p_add">+			SCTLR_M | SCTLR_S1_ASIDPNE;</span>
<span class="p_add">+</span>
<span class="p_add">+		if (IS_ENABLED(CONFIG_BIG_ENDIAN))</span>
<span class="p_add">+			reg |= SCTLR_E;</span>
<span class="p_add">+</span>
<span class="p_add">+		iommu_writel(ctx, ARM_SMMU_CB_SCTLR, reg);</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	mutex_unlock(&amp;qcom_domain-&gt;init_mutex);</span>
<span class="p_add">+</span>
<span class="p_add">+	/* Publish page table ops for map/unmap */</span>
<span class="p_add">+	qcom_domain-&gt;pgtbl_ops = pgtbl_ops;</span>
<span class="p_add">+</span>
<span class="p_add">+	return 0;</span>
<span class="p_add">+</span>
<span class="p_add">+out_clear_iommu:</span>
<span class="p_add">+	qcom_domain-&gt;iommu = NULL;</span>
<span class="p_add">+out_unlock:</span>
<span class="p_add">+	mutex_unlock(&amp;qcom_domain-&gt;init_mutex);</span>
<span class="p_add">+	return ret;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static struct iommu_domain *qcom_iommu_domain_alloc(unsigned type)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct qcom_iommu_domain *qcom_domain;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (type != IOMMU_DOMAIN_UNMANAGED &amp;&amp; type != IOMMU_DOMAIN_DMA)</span>
<span class="p_add">+		return NULL;</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Allocate the domain and initialise some of its data structures.</span>
<span class="p_add">+	 * We can&#39;t really do anything meaningful until we&#39;ve added a</span>
<span class="p_add">+	 * master.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	qcom_domain = kzalloc(sizeof(*qcom_domain), GFP_KERNEL);</span>
<span class="p_add">+	if (!qcom_domain)</span>
<span class="p_add">+		return NULL;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (type == IOMMU_DOMAIN_DMA &amp;&amp;</span>
<span class="p_add">+	    iommu_get_dma_cookie(&amp;qcom_domain-&gt;domain)) {</span>
<span class="p_add">+		kfree(qcom_domain);</span>
<span class="p_add">+		return NULL;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	mutex_init(&amp;qcom_domain-&gt;init_mutex);</span>
<span class="p_add">+	spin_lock_init(&amp;qcom_domain-&gt;pgtbl_lock);</span>
<span class="p_add">+</span>
<span class="p_add">+	return &amp;qcom_domain-&gt;domain;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static void qcom_iommu_domain_free(struct iommu_domain *domain)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct qcom_iommu_domain *qcom_domain = to_qcom_iommu_domain(domain);</span>
<span class="p_add">+</span>
<span class="p_add">+	if (WARN_ON(qcom_domain-&gt;iommu))    /* forgot to detach? */</span>
<span class="p_add">+		return;</span>
<span class="p_add">+</span>
<span class="p_add">+	iommu_put_dma_cookie(domain);</span>
<span class="p_add">+</span>
<span class="p_add">+	/* NOTE: unmap can be called after client device is powered off,</span>
<span class="p_add">+	 * for example, with GPUs or anything involving dma-buf.  So we</span>
<span class="p_add">+	 * cannot rely on the device_link.  Make sure the IOMMU is on to</span>
<span class="p_add">+	 * avoid unclocked accesses in the TLB inv path:</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	pm_runtime_get_sync(qcom_domain-&gt;iommu-&gt;dev);</span>
<span class="p_add">+</span>
<span class="p_add">+	free_io_pgtable_ops(qcom_domain-&gt;pgtbl_ops);</span>
<span class="p_add">+</span>
<span class="p_add">+	pm_runtime_put_sync(qcom_domain-&gt;iommu-&gt;dev);</span>
<span class="p_add">+</span>
<span class="p_add">+	kfree(qcom_domain);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static int qcom_iommu_attach_dev(struct iommu_domain *domain, struct device *dev)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct qcom_iommu_dev *qcom_iommu = to_iommu(dev-&gt;iommu_fwspec);</span>
<span class="p_add">+	struct qcom_iommu_domain *qcom_domain = to_qcom_iommu_domain(domain);</span>
<span class="p_add">+	int ret;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (!qcom_iommu) {</span>
<span class="p_add">+		dev_err(dev, &quot;cannot attach to IOMMU, is it on the same bus?\n&quot;);</span>
<span class="p_add">+		return -ENXIO;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	/* Ensure that the domain is finalized */</span>
<span class="p_add">+	pm_runtime_get_sync(qcom_iommu-&gt;dev);</span>
<span class="p_add">+	ret = qcom_iommu_init_domain(domain, qcom_iommu, dev-&gt;iommu_fwspec);</span>
<span class="p_add">+	pm_runtime_put_sync(qcom_iommu-&gt;dev);</span>
<span class="p_add">+	if (ret &lt; 0)</span>
<span class="p_add">+		return ret;</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Sanity check the domain. We don&#39;t support domains across</span>
<span class="p_add">+	 * different IOMMUs.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	if (qcom_domain-&gt;iommu != qcom_iommu) {</span>
<span class="p_add">+		dev_err(dev, &quot;cannot attach to IOMMU %s while already &quot;</span>
<span class="p_add">+			&quot;attached to domain on IOMMU %s\n&quot;,</span>
<span class="p_add">+			dev_name(qcom_domain-&gt;iommu-&gt;dev),</span>
<span class="p_add">+			dev_name(qcom_iommu-&gt;dev));</span>
<span class="p_add">+		return -EINVAL;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	return 0;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static void qcom_iommu_detach_dev(struct iommu_domain *domain, struct device *dev)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct iommu_fwspec *fwspec = dev-&gt;iommu_fwspec;</span>
<span class="p_add">+	struct qcom_iommu_dev *qcom_iommu = to_iommu(fwspec);</span>
<span class="p_add">+	struct qcom_iommu_domain *qcom_domain = to_qcom_iommu_domain(domain);</span>
<span class="p_add">+	unsigned i;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (!qcom_domain-&gt;iommu)</span>
<span class="p_add">+		return;</span>
<span class="p_add">+</span>
<span class="p_add">+	pm_runtime_get_sync(qcom_iommu-&gt;dev);</span>
<span class="p_add">+	for (i = 0; i &lt; fwspec-&gt;num_ids; i++) {</span>
<span class="p_add">+		struct qcom_iommu_ctx *ctx = to_ctx(fwspec, fwspec-&gt;ids[i]);</span>
<span class="p_add">+</span>
<span class="p_add">+		/* Disable the context bank: */</span>
<span class="p_add">+		iommu_writel(ctx, ARM_SMMU_CB_SCTLR, 0);</span>
<span class="p_add">+	}</span>
<span class="p_add">+	pm_runtime_put_sync(qcom_iommu-&gt;dev);</span>
<span class="p_add">+</span>
<span class="p_add">+	qcom_domain-&gt;iommu = NULL;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static int qcom_iommu_map(struct iommu_domain *domain, unsigned long iova,</span>
<span class="p_add">+			  phys_addr_t paddr, size_t size, int prot)</span>
<span class="p_add">+{</span>
<span class="p_add">+	int ret;</span>
<span class="p_add">+	unsigned long flags;</span>
<span class="p_add">+	struct qcom_iommu_domain *qcom_domain = to_qcom_iommu_domain(domain);</span>
<span class="p_add">+	struct io_pgtable_ops *ops = qcom_domain-&gt;pgtbl_ops;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (!ops)</span>
<span class="p_add">+		return -ENODEV;</span>
<span class="p_add">+</span>
<span class="p_add">+	spin_lock_irqsave(&amp;qcom_domain-&gt;pgtbl_lock, flags);</span>
<span class="p_add">+	ret = ops-&gt;map(ops, iova, paddr, size, prot);</span>
<span class="p_add">+	spin_unlock_irqrestore(&amp;qcom_domain-&gt;pgtbl_lock, flags);</span>
<span class="p_add">+	return ret;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static size_t qcom_iommu_unmap(struct iommu_domain *domain, unsigned long iova,</span>
<span class="p_add">+			       size_t size)</span>
<span class="p_add">+{</span>
<span class="p_add">+	size_t ret;</span>
<span class="p_add">+	unsigned long flags;</span>
<span class="p_add">+	struct qcom_iommu_domain *qcom_domain = to_qcom_iommu_domain(domain);</span>
<span class="p_add">+	struct io_pgtable_ops *ops = qcom_domain-&gt;pgtbl_ops;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (!ops)</span>
<span class="p_add">+		return 0;</span>
<span class="p_add">+</span>
<span class="p_add">+	/* NOTE: unmap can be called after client device is powered off,</span>
<span class="p_add">+	 * for example, with GPUs or anything involving dma-buf.  So we</span>
<span class="p_add">+	 * cannot rely on the device_link.  Make sure the IOMMU is on to</span>
<span class="p_add">+	 * avoid unclocked accesses in the TLB inv path:</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	pm_runtime_get_sync(qcom_domain-&gt;iommu-&gt;dev);</span>
<span class="p_add">+	spin_lock_irqsave(&amp;qcom_domain-&gt;pgtbl_lock, flags);</span>
<span class="p_add">+	ret = ops-&gt;unmap(ops, iova, size);</span>
<span class="p_add">+	spin_unlock_irqrestore(&amp;qcom_domain-&gt;pgtbl_lock, flags);</span>
<span class="p_add">+	pm_runtime_put_sync(qcom_domain-&gt;iommu-&gt;dev);</span>
<span class="p_add">+</span>
<span class="p_add">+	return ret;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static phys_addr_t qcom_iommu_iova_to_phys(struct iommu_domain *domain,</span>
<span class="p_add">+					   dma_addr_t iova)</span>
<span class="p_add">+{</span>
<span class="p_add">+	phys_addr_t ret;</span>
<span class="p_add">+	unsigned long flags;</span>
<span class="p_add">+	struct qcom_iommu_domain *qcom_domain = to_qcom_iommu_domain(domain);</span>
<span class="p_add">+	struct io_pgtable_ops *ops = qcom_domain-&gt;pgtbl_ops;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (!ops)</span>
<span class="p_add">+		return 0;</span>
<span class="p_add">+</span>
<span class="p_add">+	spin_lock_irqsave(&amp;qcom_domain-&gt;pgtbl_lock, flags);</span>
<span class="p_add">+	ret = ops-&gt;iova_to_phys(ops, iova);</span>
<span class="p_add">+	spin_unlock_irqrestore(&amp;qcom_domain-&gt;pgtbl_lock, flags);</span>
<span class="p_add">+</span>
<span class="p_add">+	return ret;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static bool qcom_iommu_capable(enum iommu_cap cap)</span>
<span class="p_add">+{</span>
<span class="p_add">+	switch (cap) {</span>
<span class="p_add">+	case IOMMU_CAP_CACHE_COHERENCY:</span>
<span class="p_add">+		/*</span>
<span class="p_add">+		 * Return true here as the SMMU can always send out coherent</span>
<span class="p_add">+		 * requests.</span>
<span class="p_add">+		 */</span>
<span class="p_add">+		return true;</span>
<span class="p_add">+	case IOMMU_CAP_NOEXEC:</span>
<span class="p_add">+		return true;</span>
<span class="p_add">+	default:</span>
<span class="p_add">+		return false;</span>
<span class="p_add">+	}</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static int qcom_iommu_add_device(struct device *dev)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct qcom_iommu_dev *qcom_iommu = to_iommu(dev-&gt;iommu_fwspec);</span>
<span class="p_add">+	struct iommu_group *group;</span>
<span class="p_add">+	struct device_link *link;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (!qcom_iommu)</span>
<span class="p_add">+		return -ENODEV;</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Establish the link between iommu and master, so that the</span>
<span class="p_add">+	 * iommu gets runtime enabled/disabled as per the master&#39;s</span>
<span class="p_add">+	 * needs.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	link = device_link_add(dev, qcom_iommu-&gt;dev, DL_FLAG_PM_RUNTIME);</span>
<span class="p_add">+	if (!link) {</span>
<span class="p_add">+		dev_err(qcom_iommu-&gt;dev, &quot;Unable to create device link between %s and %s\n&quot;,</span>
<span class="p_add">+			dev_name(qcom_iommu-&gt;dev), dev_name(dev));</span>
<span class="p_add">+		return -ENODEV;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	group = iommu_group_get_for_dev(dev);</span>
<span class="p_add">+	if (IS_ERR_OR_NULL(group))</span>
<span class="p_add">+		return PTR_ERR_OR_ZERO(group);</span>
<span class="p_add">+</span>
<span class="p_add">+	iommu_group_put(group);</span>
<span class="p_add">+	iommu_device_link(&amp;qcom_iommu-&gt;iommu, dev);</span>
<span class="p_add">+</span>
<span class="p_add">+	return 0;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static void qcom_iommu_remove_device(struct device *dev)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct qcom_iommu_dev *qcom_iommu = to_iommu(dev-&gt;iommu_fwspec);</span>
<span class="p_add">+</span>
<span class="p_add">+	if (!qcom_iommu)</span>
<span class="p_add">+		return;</span>
<span class="p_add">+</span>
<span class="p_add">+	iommu_device_unlink(&amp;qcom_iommu-&gt;iommu, dev);</span>
<span class="p_add">+	iommu_group_remove_device(dev);</span>
<span class="p_add">+	iommu_fwspec_free(dev);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static int qcom_iommu_of_xlate(struct device *dev, struct of_phandle_args *args)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct qcom_iommu_dev *qcom_iommu;</span>
<span class="p_add">+	struct platform_device *iommu_pdev;</span>
<span class="p_add">+	unsigned asid = args-&gt;args[0];</span>
<span class="p_add">+</span>
<span class="p_add">+	if (args-&gt;args_count != 1) {</span>
<span class="p_add">+		dev_err(dev, &quot;incorrect number of iommu params found for %s &quot;</span>
<span class="p_add">+			&quot;(found %d, expected 1)\n&quot;,</span>
<span class="p_add">+			args-&gt;np-&gt;full_name, args-&gt;args_count);</span>
<span class="p_add">+		return -EINVAL;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	iommu_pdev = of_find_device_by_node(args-&gt;np);</span>
<span class="p_add">+	if (WARN_ON(!iommu_pdev))</span>
<span class="p_add">+		return -EINVAL;</span>
<span class="p_add">+</span>
<span class="p_add">+	qcom_iommu = platform_get_drvdata(iommu_pdev);</span>
<span class="p_add">+</span>
<span class="p_add">+	/* make sure the asid specified in dt is valid, so we don&#39;t have</span>
<span class="p_add">+	 * to sanity check this elsewhere, since &#39;asid - 1&#39; is used to</span>
<span class="p_add">+	 * index into qcom_iommu-&gt;ctxs:</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	if (WARN_ON(asid &lt; 1) ||</span>
<span class="p_add">+	    WARN_ON(asid &gt; qcom_iommu-&gt;num_ctxs))</span>
<span class="p_add">+		return -EINVAL;</span>
<span class="p_add">+</span>
<span class="p_add">+	if (!dev-&gt;iommu_fwspec-&gt;iommu_priv) {</span>
<span class="p_add">+		dev-&gt;iommu_fwspec-&gt;iommu_priv = qcom_iommu;</span>
<span class="p_add">+	} else {</span>
<span class="p_add">+		/* make sure devices iommus dt node isn&#39;t referring to</span>
<span class="p_add">+		 * multiple different iommu devices.  Multiple context</span>
<span class="p_add">+		 * banks are ok, but multiple devices are not:</span>
<span class="p_add">+		 */</span>
<span class="p_add">+		if (WARN_ON(qcom_iommu != dev-&gt;iommu_fwspec-&gt;iommu_priv))</span>
<span class="p_add">+			return -EINVAL;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	return iommu_fwspec_add_ids(dev, &amp;asid, 1);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static const struct iommu_ops qcom_iommu_ops = {</span>
<span class="p_add">+	.capable	= qcom_iommu_capable,</span>
<span class="p_add">+	.domain_alloc	= qcom_iommu_domain_alloc,</span>
<span class="p_add">+	.domain_free	= qcom_iommu_domain_free,</span>
<span class="p_add">+	.attach_dev	= qcom_iommu_attach_dev,</span>
<span class="p_add">+	.detach_dev	= qcom_iommu_detach_dev,</span>
<span class="p_add">+	.map		= qcom_iommu_map,</span>
<span class="p_add">+	.unmap		= qcom_iommu_unmap,</span>
<span class="p_add">+	.map_sg		= default_iommu_map_sg,</span>
<span class="p_add">+	.iova_to_phys	= qcom_iommu_iova_to_phys,</span>
<span class="p_add">+	.add_device	= qcom_iommu_add_device,</span>
<span class="p_add">+	.remove_device	= qcom_iommu_remove_device,</span>
<span class="p_add">+	.device_group	= generic_device_group,</span>
<span class="p_add">+	.of_xlate	= qcom_iommu_of_xlate,</span>
<span class="p_add">+	.pgsize_bitmap	= SZ_4K | SZ_64K | SZ_1M | SZ_16M,</span>
<span class="p_add">+};</span>
<span class="p_add">+</span>
<span class="p_add">+static int qcom_iommu_enable_clocks(struct qcom_iommu_dev *qcom_iommu)</span>
<span class="p_add">+{</span>
<span class="p_add">+	int ret;</span>
<span class="p_add">+</span>
<span class="p_add">+	ret = clk_prepare_enable(qcom_iommu-&gt;iface_clk);</span>
<span class="p_add">+	if (ret) {</span>
<span class="p_add">+		dev_err(qcom_iommu-&gt;dev, &quot;Couldn&#39;t enable iface_clk\n&quot;);</span>
<span class="p_add">+		return ret;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	ret = clk_prepare_enable(qcom_iommu-&gt;bus_clk);</span>
<span class="p_add">+	if (ret) {</span>
<span class="p_add">+		dev_err(qcom_iommu-&gt;dev, &quot;Couldn&#39;t enable bus_clk\n&quot;);</span>
<span class="p_add">+		clk_disable_unprepare(qcom_iommu-&gt;iface_clk);</span>
<span class="p_add">+		return ret;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	return 0;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static void qcom_iommu_disable_clocks(struct qcom_iommu_dev *qcom_iommu)</span>
<span class="p_add">+{</span>
<span class="p_add">+	clk_disable_unprepare(qcom_iommu-&gt;bus_clk);</span>
<span class="p_add">+	clk_disable_unprepare(qcom_iommu-&gt;iface_clk);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static int get_asid(const struct device_node *np)</span>
<span class="p_add">+{</span>
<span class="p_add">+	u32 reg;</span>
<span class="p_add">+</span>
<span class="p_add">+	/* read the &quot;reg&quot; property directly to get the relative address</span>
<span class="p_add">+	 * of the context bank, and calculate the asid from that:</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	if (of_property_read_u32_index(np, &quot;reg&quot;, 0, &amp;reg))</span>
<span class="p_add">+		return -ENODEV;</span>
<span class="p_add">+</span>
<span class="p_add">+	return reg / 0x1000;      /* context banks are 0x1000 apart */</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static int qcom_iommu_ctx_probe(struct platform_device *pdev)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct qcom_iommu_ctx *ctx;</span>
<span class="p_add">+	struct device *dev = &amp;pdev-&gt;dev;</span>
<span class="p_add">+	struct qcom_iommu_dev *qcom_iommu = dev_get_drvdata(dev-&gt;parent);</span>
<span class="p_add">+	struct resource *res;</span>
<span class="p_add">+	int ret, irq;</span>
<span class="p_add">+</span>
<span class="p_add">+	ctx = devm_kzalloc(dev, sizeof(*ctx), GFP_KERNEL);</span>
<span class="p_add">+	if (!ctx)</span>
<span class="p_add">+		return -ENOMEM;</span>
<span class="p_add">+</span>
<span class="p_add">+	ctx-&gt;dev = dev;</span>
<span class="p_add">+	platform_set_drvdata(pdev, ctx);</span>
<span class="p_add">+</span>
<span class="p_add">+	res = platform_get_resource(pdev, IORESOURCE_MEM, 0);</span>
<span class="p_add">+	ctx-&gt;base = devm_ioremap_resource(dev, res);</span>
<span class="p_add">+	if (IS_ERR(ctx-&gt;base))</span>
<span class="p_add">+		return PTR_ERR(ctx-&gt;base);</span>
<span class="p_add">+</span>
<span class="p_add">+	irq = platform_get_irq(pdev, 0);</span>
<span class="p_add">+	if (irq &lt; 0) {</span>
<span class="p_add">+		dev_err(dev, &quot;failed to get irq\n&quot;);</span>
<span class="p_add">+		return -ENODEV;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	/* clear IRQs before registering fault handler, just in case the</span>
<span class="p_add">+	 * boot-loader left us a surprise:</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	iommu_writel(ctx, ARM_SMMU_CB_FSR, iommu_readl(ctx, ARM_SMMU_CB_FSR));</span>
<span class="p_add">+</span>
<span class="p_add">+	ret = devm_request_irq(dev, irq,</span>
<span class="p_add">+			       qcom_iommu_fault,</span>
<span class="p_add">+			       IRQF_SHARED,</span>
<span class="p_add">+			       &quot;qcom-iommu-fault&quot;,</span>
<span class="p_add">+			       ctx);</span>
<span class="p_add">+	if (ret) {</span>
<span class="p_add">+		dev_err(dev, &quot;failed to request IRQ %u\n&quot;, irq);</span>
<span class="p_add">+		return ret;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	ret = get_asid(dev-&gt;of_node);</span>
<span class="p_add">+	if (ret &lt; 0) {</span>
<span class="p_add">+		dev_err(dev, &quot;missing reg property\n&quot;);</span>
<span class="p_add">+		return ret;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	ctx-&gt;asid = ret;</span>
<span class="p_add">+</span>
<span class="p_add">+	dev_dbg(dev, &quot;found asid %u\n&quot;, ctx-&gt;asid);</span>
<span class="p_add">+</span>
<span class="p_add">+	qcom_iommu-&gt;ctxs[ctx-&gt;asid - 1] = ctx;</span>
<span class="p_add">+</span>
<span class="p_add">+	return 0;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static int qcom_iommu_ctx_remove(struct platform_device *pdev)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct qcom_iommu_dev *qcom_iommu = dev_get_drvdata(pdev-&gt;dev.parent);</span>
<span class="p_add">+	struct qcom_iommu_ctx *ctx = platform_get_drvdata(pdev);</span>
<span class="p_add">+</span>
<span class="p_add">+	platform_set_drvdata(pdev, NULL);</span>
<span class="p_add">+</span>
<span class="p_add">+	qcom_iommu-&gt;ctxs[ctx-&gt;asid - 1] = NULL;</span>
<span class="p_add">+</span>
<span class="p_add">+	return 0;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static const struct of_device_id ctx_of_match[] = {</span>
<span class="p_add">+	{ .compatible = &quot;qcom,msm-iommu-v1-ns&quot; },</span>
<span class="p_add">+	{ .compatible = &quot;qcom,msm-iommu-v1-sec&quot; },</span>
<span class="p_add">+	{ /* sentinel */ }</span>
<span class="p_add">+};</span>
<span class="p_add">+</span>
<span class="p_add">+static struct platform_driver qcom_iommu_ctx_driver = {</span>
<span class="p_add">+	.driver	= {</span>
<span class="p_add">+		.name		= &quot;qcom-iommu-ctx&quot;,</span>
<span class="p_add">+		.of_match_table	= of_match_ptr(ctx_of_match),</span>
<span class="p_add">+	},</span>
<span class="p_add">+	.probe	= qcom_iommu_ctx_probe,</span>
<span class="p_add">+	.remove = qcom_iommu_ctx_remove,</span>
<span class="p_add">+};</span>
<span class="p_add">+</span>
<span class="p_add">+static int qcom_iommu_device_probe(struct platform_device *pdev)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct device_node *child;</span>
<span class="p_add">+	struct qcom_iommu_dev *qcom_iommu;</span>
<span class="p_add">+	struct device *dev = &amp;pdev-&gt;dev;</span>
<span class="p_add">+	struct resource *res;</span>
<span class="p_add">+	int ret, sz, max_asid = 0;</span>
<span class="p_add">+</span>
<span class="p_add">+	/* find the max asid (which is 1:1 to ctx bank idx), so we know how</span>
<span class="p_add">+	 * many child ctx devices we have:</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	for_each_child_of_node(dev-&gt;of_node, child)</span>
<span class="p_add">+		max_asid = max(max_asid, get_asid(child));</span>
<span class="p_add">+</span>
<span class="p_add">+	sz = sizeof(*qcom_iommu) + (max_asid * sizeof(qcom_iommu-&gt;ctxs[0]));</span>
<span class="p_add">+</span>
<span class="p_add">+	qcom_iommu = devm_kzalloc(dev, sz, GFP_KERNEL);</span>
<span class="p_add">+	if (!qcom_iommu)</span>
<span class="p_add">+		return -ENOMEM;</span>
<span class="p_add">+	qcom_iommu-&gt;num_ctxs = max_asid;</span>
<span class="p_add">+	qcom_iommu-&gt;dev = dev;</span>
<span class="p_add">+</span>
<span class="p_add">+	res = platform_get_resource(pdev, IORESOURCE_MEM, 0);</span>
<span class="p_add">+	if (res)</span>
<span class="p_add">+		qcom_iommu-&gt;local_base = devm_ioremap_resource(dev, res);</span>
<span class="p_add">+</span>
<span class="p_add">+	qcom_iommu-&gt;iface_clk = devm_clk_get(dev, &quot;iface&quot;);</span>
<span class="p_add">+	if (IS_ERR(qcom_iommu-&gt;iface_clk)) {</span>
<span class="p_add">+		dev_err(dev, &quot;failed to get iface clock\n&quot;);</span>
<span class="p_add">+		return PTR_ERR(qcom_iommu-&gt;iface_clk);</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	qcom_iommu-&gt;bus_clk = devm_clk_get(dev, &quot;bus&quot;);</span>
<span class="p_add">+	if (IS_ERR(qcom_iommu-&gt;bus_clk)) {</span>
<span class="p_add">+		dev_err(dev, &quot;failed to get bus clock\n&quot;);</span>
<span class="p_add">+		return PTR_ERR(qcom_iommu-&gt;bus_clk);</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	if (of_property_read_u32(dev-&gt;of_node, &quot;qcom,iommu-secure-id&quot;,</span>
<span class="p_add">+				 &amp;qcom_iommu-&gt;sec_id)) {</span>
<span class="p_add">+		dev_err(dev, &quot;missing qcom,iommu-secure-id property\n&quot;);</span>
<span class="p_add">+		return -ENODEV;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	platform_set_drvdata(pdev, qcom_iommu);</span>
<span class="p_add">+</span>
<span class="p_add">+	pm_runtime_enable(dev);</span>
<span class="p_add">+</span>
<span class="p_add">+	/* register context bank devices, which are child nodes: */</span>
<span class="p_add">+	ret = devm_of_platform_populate(dev);</span>
<span class="p_add">+	if (ret) {</span>
<span class="p_add">+		dev_err(dev, &quot;Failed to populate iommu contexts\n&quot;);</span>
<span class="p_add">+		return ret;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	ret = iommu_device_sysfs_add(&amp;qcom_iommu-&gt;iommu, dev, NULL,</span>
<span class="p_add">+				     dev_name(dev));</span>
<span class="p_add">+	if (ret) {</span>
<span class="p_add">+		dev_err(dev, &quot;Failed to register iommu in sysfs\n&quot;);</span>
<span class="p_add">+		return ret;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	iommu_device_set_ops(&amp;qcom_iommu-&gt;iommu, &amp;qcom_iommu_ops);</span>
<span class="p_add">+	iommu_device_set_fwnode(&amp;qcom_iommu-&gt;iommu, dev-&gt;fwnode);</span>
<span class="p_add">+</span>
<span class="p_add">+	ret = iommu_device_register(&amp;qcom_iommu-&gt;iommu);</span>
<span class="p_add">+	if (ret) {</span>
<span class="p_add">+		dev_err(dev, &quot;Failed to register iommu\n&quot;);</span>
<span class="p_add">+		return ret;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	bus_set_iommu(&amp;platform_bus_type, &amp;qcom_iommu_ops);</span>
<span class="p_add">+</span>
<span class="p_add">+	if (qcom_iommu-&gt;local_base) {</span>
<span class="p_add">+		pm_runtime_get_sync(dev);</span>
<span class="p_add">+		writel_relaxed(0xffffffff, qcom_iommu-&gt;local_base + SMMU_INTR_SEL_NS);</span>
<span class="p_add">+		pm_runtime_put_sync(dev);</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	return 0;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static int qcom_iommu_device_remove(struct platform_device *pdev)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct qcom_iommu_dev *qcom_iommu = platform_get_drvdata(pdev);</span>
<span class="p_add">+</span>
<span class="p_add">+	bus_set_iommu(&amp;platform_bus_type, NULL);</span>
<span class="p_add">+</span>
<span class="p_add">+	pm_runtime_force_suspend(&amp;pdev-&gt;dev);</span>
<span class="p_add">+	platform_set_drvdata(pdev, NULL);</span>
<span class="p_add">+	iommu_device_sysfs_remove(&amp;qcom_iommu-&gt;iommu);</span>
<span class="p_add">+	iommu_device_unregister(&amp;qcom_iommu-&gt;iommu);</span>
<span class="p_add">+</span>
<span class="p_add">+	return 0;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+#ifdef CONFIG_PM</span>
<span class="p_add">+static int qcom_iommu_resume(struct device *dev)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct platform_device *pdev = to_platform_device(dev);</span>
<span class="p_add">+	struct qcom_iommu_dev *qcom_iommu = platform_get_drvdata(pdev);</span>
<span class="p_add">+</span>
<span class="p_add">+	return qcom_iommu_enable_clocks(qcom_iommu);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static int qcom_iommu_suspend(struct device *dev)</span>
<span class="p_add">+{</span>
<span class="p_add">+	struct platform_device *pdev = to_platform_device(dev);</span>
<span class="p_add">+	struct qcom_iommu_dev *qcom_iommu = platform_get_drvdata(pdev);</span>
<span class="p_add">+</span>
<span class="p_add">+	qcom_iommu_disable_clocks(qcom_iommu);</span>
<span class="p_add">+</span>
<span class="p_add">+	return 0;</span>
<span class="p_add">+}</span>
<span class="p_add">+#endif</span>
<span class="p_add">+</span>
<span class="p_add">+static const struct dev_pm_ops qcom_iommu_pm_ops = {</span>
<span class="p_add">+	SET_RUNTIME_PM_OPS(qcom_iommu_suspend, qcom_iommu_resume, NULL)</span>
<span class="p_add">+	SET_SYSTEM_SLEEP_PM_OPS(pm_runtime_force_suspend,</span>
<span class="p_add">+				pm_runtime_force_resume)</span>
<span class="p_add">+};</span>
<span class="p_add">+</span>
<span class="p_add">+static const struct of_device_id qcom_iommu_of_match[] = {</span>
<span class="p_add">+	{ .compatible = &quot;qcom,msm-iommu-v1&quot; },</span>
<span class="p_add">+	{ /* sentinel */ }</span>
<span class="p_add">+};</span>
<span class="p_add">+MODULE_DEVICE_TABLE(of, qcom_iommu_of_match);</span>
<span class="p_add">+</span>
<span class="p_add">+static struct platform_driver qcom_iommu_driver = {</span>
<span class="p_add">+	.driver	= {</span>
<span class="p_add">+		.name		= &quot;qcom-iommu&quot;,</span>
<span class="p_add">+		.of_match_table	= of_match_ptr(qcom_iommu_of_match),</span>
<span class="p_add">+		.pm		= &amp;qcom_iommu_pm_ops,</span>
<span class="p_add">+	},</span>
<span class="p_add">+	.probe	= qcom_iommu_device_probe,</span>
<span class="p_add">+	.remove	= qcom_iommu_device_remove,</span>
<span class="p_add">+};</span>
<span class="p_add">+</span>
<span class="p_add">+static int __init qcom_iommu_init(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	int ret;</span>
<span class="p_add">+</span>
<span class="p_add">+	ret = platform_driver_register(&amp;qcom_iommu_ctx_driver);</span>
<span class="p_add">+	if (ret)</span>
<span class="p_add">+		return ret;</span>
<span class="p_add">+</span>
<span class="p_add">+	ret = platform_driver_register(&amp;qcom_iommu_driver);</span>
<span class="p_add">+	if (ret)</span>
<span class="p_add">+		platform_driver_unregister(&amp;qcom_iommu_ctx_driver);</span>
<span class="p_add">+</span>
<span class="p_add">+	return ret;</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+static void __exit qcom_iommu_exit(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	platform_driver_unregister(&amp;qcom_iommu_driver);</span>
<span class="p_add">+	platform_driver_unregister(&amp;qcom_iommu_ctx_driver);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
<span class="p_add">+module_init(qcom_iommu_init);</span>
<span class="p_add">+module_exit(qcom_iommu_exit);</span>
<span class="p_add">+</span>
<span class="p_add">+IOMMU_OF_DECLARE(qcom_iommu_dev, &quot;qcom,msm-iommu-v1&quot;, NULL);</span>
<span class="p_add">+</span>
<span class="p_add">+MODULE_DESCRIPTION(&quot;IOMMU API for QCOM IOMMU v1 implementations&quot;);</span>
<span class="p_add">+MODULE_LICENSE(&quot;GPL v2&quot;);</span>

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



