
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>[51/60] x86/mm: Allow flushing for future ASID switches - Patchwork</title>
  <link rel="stylesheet" type="text/css" href="/static/css/style.css"/>
  <script type="text/javascript" src="/static/js/common.js"></script>
  <script type="text/javascript" src="/static/js/jquery-1.10.1.min.js"></script>

 </head>
 <body>
  <div id="title">
  <h1 style="float: left;">
     <a
      href="/">Patchwork</a>
    [51/60] x86/mm: Allow flushing for future ASID switches</h1>
  <div id="auth">

     <a href="/user/login/">login</a>
     <br/>
     <a href="/register/">register</a>
     <br/>
     <a href="/mail/">mail settings</a>

   </div>
   <div style="clear: both;"></div>
  </div>
  <div id="nav">
   <div id="navleft">
   
    <strong>Project</strong>: LKML
     :
     <a href="/project/LKML/list/"
      >patches</a>
     :
     <a href="/project/LKML/"
      >project info</a>
    
     :
     <a href="/"
     >other projects</a>
     
    
   </div>
   <div id="navright">
    <a href="/help/about/">about</a>
   </div>
   <div style="clear: both"></div>
  </div>

  <div id="content">

<script language="JavaScript" type="text/javascript">
function toggle_headers(link_id, headers_id)
{
    var link = document.getElementById(link_id)
    var headers = document.getElementById(headers_id)

    var hidden = headers.style['display'] == 'none';

    if (hidden) {
        link.innerHTML = 'hide';
        headers.style['display'] = 'block';
    } else {
        link.innerHTML = 'show';
        headers.style['display'] = 'none';
    }

}
</script>

<table class="patchmeta">
 <tr>
  <th>Submitter</th>
  <td><a href="/project/LKML/list/?submitter=107">Thomas Gleixner</a></td>
 </tr>
 <tr>
  <th>Date</th>
  <td>Dec. 4, 2017, 2:07 p.m.</td>
 </tr>
 <tr>
  <th>Message ID</th>
  <td>&lt;20171204150609.002009374@linutronix.de&gt;</td>
 </tr>
 <tr>
  <th>Download</th>
  <td>
   <a href="/patch/10091045/mbox/"
   >mbox</a>
|
   <a href="/patch/10091045/raw/"
   >patch</a>

   </td>
 </tr>
 <tr>
  <th>Permalink</th>
  <td><a href="/patch/10091045/">/patch/10091045/</a>
 </tr>
  <tr>
   <th>State</th>
   <td>New</td>
  </tr>


 <tr>
  <th>Headers</th>
  <td><a id="togglepatchheaders"
   href="javascript:toggle_headers('togglepatchheaders', 'patchheaders')"
   >show</a>
   <div id="patchheaders" class="patchheaders" style="display:none;">
    <pre>Return-Path: &lt;linux-kernel-owner@kernel.org&gt;
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
	[172.30.200.125])
	by pdx-korg-patchwork.web.codeaurora.org (Postfix) with ESMTP id
	E8FB76056E for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Mon,  4 Dec 2017 16:52:46 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id D769828CFF
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Mon,  4 Dec 2017 16:52:46 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id CA93B28D0F; Mon,  4 Dec 2017 16:52:46 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-6.9 required=2.0 tests=BAYES_00,RCVD_IN_DNSWL_HI
	autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 2DA3A28CFF
	for &lt;patchwork-LKML@patchwork.kernel.org&gt;;
	Mon,  4 Dec 2017 16:52:46 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
	id S1751864AbdLDQwm (ORCPT
	&lt;rfc822;patchwork-LKML@patchwork.kernel.org&gt;);
	Mon, 4 Dec 2017 11:52:42 -0500
Received: from Galois.linutronix.de ([146.0.238.70]:60564 &quot;EHLO
	Galois.linutronix.de&quot; rhost-flags-OK-OK-OK-OK) by vger.kernel.org
	with ESMTP id S1752649AbdLDQvu (ORCPT
	&lt;rfc822;linux-kernel@vger.kernel.org&gt;);
	Mon, 4 Dec 2017 11:51:50 -0500
Received: from localhost ([127.0.0.1] helo=[127.0.1.1])
	by Galois.linutronix.de with esmtp (Exim 4.80)
	(envelope-from &lt;tglx@linutronix.de&gt;)
	id 1eLtws-0007dE-0t; Mon, 04 Dec 2017 17:50:30 +0100
Message-Id: &lt;20171204150609.002009374@linutronix.de&gt;
User-Agent: quilt/0.63-1
Date: Mon, 04 Dec 2017 15:07:57 +0100
From: Thomas Gleixner &lt;tglx@linutronix.de&gt;
To: LKML &lt;linux-kernel@vger.kernel.org&gt;
Cc: x86@kernel.org, Linus Torvalds &lt;torvalds@linux-foundation.org&gt;,
	Andy Lutomirsky &lt;luto@kernel.org&gt;, Peter Zijlstra &lt;peterz@infradead.org&gt;,
	Dave Hansen &lt;dave.hansen@intel.com&gt;, Borislav Petkov &lt;bpetkov@suse.de&gt;,
	Greg KH &lt;gregkh@linuxfoundation.org&gt;, keescook@google.com,
	hughd@google.com, Brian Gerst &lt;brgerst@gmail.com&gt;,
	Josh Poimboeuf &lt;jpoimboe@redhat.com&gt;,
	Denys Vlasenko &lt;dvlasenk@redhat.com&gt;, Rik van Riel &lt;riel@redhat.com&gt;,
	Boris Ostrovsky &lt;boris.ostrovsky@oracle.com&gt;,
	Juergen Gross &lt;jgross@suse.com&gt;, David Laight &lt;David.Laight@aculab.com&gt;,
	Eduardo Valentin &lt;eduval@amazon.com&gt;, aliguori@amazon.com,
	Will Deacon &lt;will.deacon@arm.com&gt;, daniel.gruss@iaik.tugraz.at,
	Dave Hansen &lt;dave.hansen@linux.intel.com&gt;,
	Ingo Molnar &lt;mingo@kernel.org&gt;, michael.schwarz@iaik.tugraz.at,
	Borislav Petkov &lt;bp@alien8.de&gt;, moritz.lipp@iaik.tugraz.at,
	richard.fellner@student.tugraz.at
Subject: [patch 51/60] x86/mm: Allow flushing for future ASID switches
References: &lt;20171204140706.296109558@linutronix.de&gt;
MIME-Version: 1.0
Content-Type: text/plain; charset=ISO-8859-15
Content-Disposition: inline;
	filename=x86-mm--Allow_flushing_for_future_ASID_switches.patch
Sender: linux-kernel-owner@vger.kernel.org
Precedence: bulk
List-ID: &lt;linux-kernel.vger.kernel.org&gt;
X-Mailing-List: linux-kernel@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP
</pre>
   </div>
  </td>
 </tr>
</table>

<div class="patchforms">





 <div style="clear: both;">
 </div>
</div>



<h2>Comments</h2>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=107">Thomas Gleixner</a> - Dec. 4, 2017, 2:07 p.m.</div>
<pre class="content">
<span class="from">From: Dave Hansen &lt;dave.hansen@linux.intel.com&gt;</span>

If changing the page tables in such a way that an invalidation of all
contexts (aka. PCIDs / ASIDs) is required, they can be actively invalidated
by:

 1. INVPCID for each PCID (works for single pages too).

 2. Load CR3 with each PCID without the NOFLUSH bit set

 3. Load CR3 with the NOFLUSH bit set for each and do INVLPG for each address.

But, none of these are really feasible since there are ~6 ASIDs (12 with
KERNEL_PAGE_TABLE_ISOLATION) at the time that invalidation is required.
Instead of actively invalidating them, invalidate the *current* context and
also mark the cpu_tlbstate _quickly_ to indicate future invalidation to be
required.

At the next context-switch, look for this indicator
(&#39;invalidate_other&#39; being set) invalidate all of the
cpu_tlbstate.ctxs[] entries.

This ensures that any future context switches will do a full flush
of the TLB, picking up the previous changes.
<span class="signed-off-by">
Signed-off-by: Dave Hansen &lt;dave.hansen@linux.intel.com&gt;</span>
<span class="signed-off-by">Signed-off-by: Ingo Molnar &lt;mingo@kernel.org&gt;</span>
<span class="signed-off-by">Signed-off-by: Thomas Gleixner &lt;tglx@linutronix.de&gt;</span>
<span class="signed-off-by">Signed-off-by: Peter Zijlstra (Intel) &lt;peterz@infradead.org&gt;</span>
Cc: Rik van Riel &lt;riel@redhat.com&gt;
Cc: Denys Vlasenko &lt;dvlasenk@redhat.com&gt;
Cc: Andy Lutomirski &lt;luto@kernel.org&gt;
Cc: michael.schwarz@iaik.tugraz.at
Cc: daniel.gruss@iaik.tugraz.at
Cc: Brian Gerst &lt;brgerst@gmail.com&gt;
Cc: Josh Poimboeuf &lt;jpoimboe@redhat.com&gt;
Cc: hughd@google.com
Cc: Borislav Petkov &lt;bp@alien8.de&gt;
Cc: moritz.lipp@iaik.tugraz.at
Cc: keescook@google.com
Cc: Linus Torvalds &lt;torvalds@linux-foundation.org&gt;
Cc: richard.fellner@student.tugraz.at
Link: https://lkml.kernel.org/r/20171123003507.E8C327F5@viggo.jf.intel.com

---
 arch/x86/include/asm/tlbflush.h |   42 ++++++++++++++++++++++++++++++----------
 arch/x86/mm/tlb.c               |   37 +++++++++++++++++++++++++++++++++++
 2 files changed, 69 insertions(+), 10 deletions(-)
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=125831">Andrew Lutomirski</a> - Dec. 4, 2017, 10:22 p.m.</div>
<pre class="content">
On Mon, Dec 4, 2017 at 6:07 AM, Thomas Gleixner &lt;tglx@linutronix.de&gt; wrote:
<span class="quote">&gt; From: Dave Hansen &lt;dave.hansen@linux.intel.com&gt;</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; If changing the page tables in such a way that an invalidation of all</span>
<span class="quote">&gt; contexts (aka. PCIDs / ASIDs) is required, they can be actively invalidated</span>
<span class="quote">&gt; by:</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;  1. INVPCID for each PCID (works for single pages too).</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;  2. Load CR3 with each PCID without the NOFLUSH bit set</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;  3. Load CR3 with the NOFLUSH bit set for each and do INVLPG for each address.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; But, none of these are really feasible since there are ~6 ASIDs (12 with</span>
<span class="quote">&gt; KERNEL_PAGE_TABLE_ISOLATION) at the time that invalidation is required.</span>
<span class="quote">&gt; Instead of actively invalidating them, invalidate the *current* context and</span>
<span class="quote">&gt; also mark the cpu_tlbstate _quickly_ to indicate future invalidation to be</span>
<span class="quote">&gt; required.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; At the next context-switch, look for this indicator</span>
<span class="quote">&gt; (&#39;invalidate_other&#39; being set) invalidate all of the</span>
<span class="quote">&gt; cpu_tlbstate.ctxs[] entries.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; This ensures that any future context switches will do a full flush</span>
<span class="quote">&gt; of the TLB, picking up the previous changes.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; Signed-off-by: Dave Hansen &lt;dave.hansen@linux.intel.com&gt;</span>
<span class="quote">&gt; Signed-off-by: Ingo Molnar &lt;mingo@kernel.org&gt;</span>
<span class="quote">&gt; Signed-off-by: Thomas Gleixner &lt;tglx@linutronix.de&gt;</span>
<span class="quote">&gt; Signed-off-by: Peter Zijlstra (Intel) &lt;peterz@infradead.org&gt;</span>
<span class="quote">&gt; Cc: Rik van Riel &lt;riel@redhat.com&gt;</span>
<span class="quote">&gt; Cc: Denys Vlasenko &lt;dvlasenk@redhat.com&gt;</span>
<span class="quote">&gt; Cc: Andy Lutomirski &lt;luto@kernel.org&gt;</span>
<span class="quote">&gt; Cc: michael.schwarz@iaik.tugraz.at</span>
<span class="quote">&gt; Cc: daniel.gruss@iaik.tugraz.at</span>
<span class="quote">&gt; Cc: Brian Gerst &lt;brgerst@gmail.com&gt;</span>
<span class="quote">&gt; Cc: Josh Poimboeuf &lt;jpoimboe@redhat.com&gt;</span>
<span class="quote">&gt; Cc: hughd@google.com</span>
<span class="quote">&gt; Cc: Borislav Petkov &lt;bp@alien8.de&gt;</span>
<span class="quote">&gt; Cc: moritz.lipp@iaik.tugraz.at</span>
<span class="quote">&gt; Cc: keescook@google.com</span>
<span class="quote">&gt; Cc: Linus Torvalds &lt;torvalds@linux-foundation.org&gt;</span>
<span class="quote">&gt; Cc: richard.fellner@student.tugraz.at</span>
<span class="quote">&gt; Link: https://lkml.kernel.org/r/20171123003507.E8C327F5@viggo.jf.intel.com</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; ---</span>
<span class="quote">&gt;  arch/x86/include/asm/tlbflush.h |   42 ++++++++++++++++++++++++++++++----------</span>
<span class="quote">&gt;  arch/x86/mm/tlb.c               |   37 +++++++++++++++++++++++++++++++++++</span>
<span class="quote">&gt;  2 files changed, 69 insertions(+), 10 deletions(-)</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; --- a/arch/x86/include/asm/tlbflush.h</span>
<span class="quote">&gt; +++ b/arch/x86/include/asm/tlbflush.h</span>
<span class="quote">&gt; @@ -188,6 +188,17 @@ struct tlb_state {</span>
<span class="quote">&gt;         bool is_lazy;</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;         /*</span>
<span class="quote">&gt; +        * If set we changed the page tables in such a way that we</span>
<span class="quote">&gt; +        * needed an invalidation of all contexts (aka. PCIDs / ASIDs).</span>
<span class="quote">&gt; +        * This tells us to go invalidate all the non-loaded ctxs[]</span>
<span class="quote">&gt; +        * on the next context switch.</span>
<span class="quote">&gt; +        *</span>
<span class="quote">&gt; +        * The current ctx was kept up-to-date as it ran and does not</span>
<span class="quote">&gt; +        * need to be invalidated.</span>
<span class="quote">&gt; +        */</span>
<span class="quote">&gt; +       bool invalidate_other;</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt; +       /*</span>
<span class="quote">&gt;          * Access to this CR4 shadow and to H/W CR4 is protected by</span>
<span class="quote">&gt;          * disabling interrupts when modifying either one.</span>
<span class="quote">&gt;          */</span>
<span class="quote">&gt; @@ -267,6 +278,19 @@ static inline unsigned long cr4_read_sha</span>
<span class="quote">&gt;         return this_cpu_read(cpu_tlbstate.cr4);</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; +static inline void invalidate_pcid_other(void)</span>
<span class="quote">&gt; +{</span>
<span class="quote">&gt; +       /*</span>
<span class="quote">&gt; +        * With global pages, all of the shared kenel page tables</span>
<span class="quote">&gt; +        * are set as _PAGE_GLOBAL.  We have no shared nonglobals</span>
<span class="quote">&gt; +        * and nothing to do here.</span>
<span class="quote">&gt; +        */</span>
<span class="quote">&gt; +       if (!static_cpu_has_bug(X86_BUG_CPU_SECURE_MODE_KPTI))</span>
<span class="quote">&gt; +               return;</span>

I think I&#39;d be more comfortable if this check were in the caller, not
here.  Shouldn&#39;t a function called invalidate_pcid_other() do what the
name says?
<span class="quote">
&gt; +</span>
<span class="quote">&gt; +       this_cpu_write(cpu_tlbstate.invalidate_other, true);</span>

Why do we need this extra variable instead of just looping over all
other ASIDs and invalidating them?  It would be something like:

        for (i = 1; i &lt; TLB_NR_DYN_ASIDS; i++) {
                if (i != this_cpu_read(cpu_tlbstate.loaded_mm_asid))
                       this_cpu_write(cpu_tlbstate.ctxs[i].ctx_id, 0);
        }

modulo epic whitespace damage and possible typos.
<span class="quote">
&gt; +}</span>
<span class="quote">&gt; +</span>
<span class="quote">&gt;  /*</span>
<span class="quote">&gt;   * Save some of cr4 feature set we&#39;re using (e.g.  Pentium 4MB</span>
<span class="quote">&gt;   * enable and PPro Global page enable), so that any CPU&#39;s that boot</span>
<span class="quote">&gt; @@ -341,24 +365,22 @@ static inline void __native_flush_tlb_si</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;  static inline void __flush_tlb_all(void)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt; -       if (boot_cpu_has(X86_FEATURE_PGE))</span>
<span class="quote">&gt; +       if (boot_cpu_has(X86_FEATURE_PGE)) {</span>
<span class="quote">&gt;                 __flush_tlb_global();</span>
<span class="quote">&gt; -       else</span>
<span class="quote">&gt; +       } else {</span>
<span class="quote">&gt;                 __flush_tlb();</span>
<span class="quote">&gt; -</span>
<span class="quote">&gt; -       /*</span>
<span class="quote">&gt; -        * Note: if we somehow had PCID but not PGE, then this wouldn&#39;t work --</span>
<span class="quote">&gt; -        * we&#39;d end up flushing kernel translations for the current ASID but</span>
<span class="quote">&gt; -        * we might fail to flush kernel translations for other cached ASIDs.</span>
<span class="quote">&gt; -        *</span>
<span class="quote">&gt; -        * To avoid this issue, we force PCID off if PGE is off.</span>
<span class="quote">&gt; -        */</span>
<span class="quote">&gt; +       }</span>
<span class="quote">&gt;  }</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;  static inline void __flush_tlb_one(unsigned long addr)</span>
<span class="quote">&gt;  {</span>
<span class="quote">&gt;         count_vm_tlb_event(NR_TLB_LOCAL_FLUSH_ONE);</span>
<span class="quote">&gt;         __flush_tlb_single(addr);</span>
<span class="quote">&gt; +       /*</span>
<span class="quote">&gt; +        * Invalidate other address spaces inaccessible to single-page</span>
<span class="quote">&gt; +        * invalidation:</span>
<span class="quote">&gt; +        */</span>

Ugh.  If I&#39;m reading this right, __flush_tlb_single() means &quot;flush one
user address&quot; and __flush_tlb_one() means &quot;flush one kernel address&quot;.
That&#39;s, um, not exactly obvious.  Could this be at least commented
better?

--Andy
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=65121">Dave Hansen</a> - Dec. 4, 2017, 10:34 p.m.</div>
<pre class="content">
On 12/04/2017 02:22 PM, Andy Lutomirski wrote:
<span class="quote">&gt;&gt; +</span>
<span class="quote">&gt;&gt; +       this_cpu_write(cpu_tlbstate.invalidate_other, true);</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Why do we need this extra variable instead of just looping over all</span>
<span class="quote">&gt; other ASIDs and invalidating them?  It would be something like:</span>
<span class="quote">&gt; </span>
<span class="quote">&gt;         for (i = 1; i &lt; TLB_NR_DYN_ASIDS; i++) {</span>
<span class="quote">&gt;                 if (i != this_cpu_read(cpu_tlbstate.loaded_mm_asid))</span>
<span class="quote">&gt;                        this_cpu_write(cpu_tlbstate.ctxs[i].ctx_id, 0);</span>
<span class="quote">&gt;         }</span>

We have loops like this:

	for (addr = start; addr &lt; end; addr += PAGE_SIZE)
		flush_tlb_single();

Where flush_tlb_single() does a invalidate_pcid_other().  So, inlining
flush_tlb_single() rougly looks like:

	for (addr = start; addr &lt; end; addr += PAGE_SIZE) {
		invlpg;
		for (i = 1; i &lt; TLB_NR_DYN_ASIDS; i++) {
			this_cpu_write(cpu_tlbstate.ctxs[i].ctx_id, 0);
	}

or, with a &quot;invalidate_other&quot; variable:

	for (addr = start; addr &lt; end; addr += PAGE_SIZE) {
		invlpg;
		this_cpu_write(cpu_tlbstate.ctxs.invalidate_other, 1);
	}

The double-for-loop looks a bit wasteful to me.
<span class="quote">

&gt;&gt;  static inline void __flush_tlb_one(unsigned long addr)</span>
<span class="quote">&gt;&gt;  {</span>
<span class="quote">&gt;&gt;         count_vm_tlb_event(NR_TLB_LOCAL_FLUSH_ONE);</span>
<span class="quote">&gt;&gt;         __flush_tlb_single(addr);</span>
<span class="quote">&gt;&gt; +       /*</span>
<span class="quote">&gt;&gt; +        * Invalidate other address spaces inaccessible to single-page</span>
<span class="quote">&gt;&gt; +        * invalidation:</span>
<span class="quote">&gt;&gt; +        */</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Ugh.  If I&#39;m reading this right, __flush_tlb_single() means &quot;flush one</span>
<span class="quote">&gt; user address&quot; and __flush_tlb_one() means &quot;flush one kernel address&quot;.</span>
<span class="quote">&gt; That&#39;s, um, not exactly obvious.  Could this be at least commented</span>
<span class="quote">&gt; better?</span>

That sounds sane, but let me take a look at it.

Didn&#39;t Peter have some patches to do some of that rename?
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=125831">Andrew Lutomirski</a> - Dec. 4, 2017, 10:36 p.m.</div>
<pre class="content">
On Mon, Dec 4, 2017 at 2:34 PM, Dave Hansen &lt;dave.hansen@intel.com&gt; wrote:
<span class="quote">&gt; On 12/04/2017 02:22 PM, Andy Lutomirski wrote:</span>
<span class="quote">&gt;&gt;&gt; +</span>
<span class="quote">&gt;&gt;&gt; +       this_cpu_write(cpu_tlbstate.invalidate_other, true);</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; Why do we need this extra variable instead of just looping over all</span>
<span class="quote">&gt;&gt; other ASIDs and invalidating them?  It would be something like:</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt;         for (i = 1; i &lt; TLB_NR_DYN_ASIDS; i++) {</span>
<span class="quote">&gt;&gt;                 if (i != this_cpu_read(cpu_tlbstate.loaded_mm_asid))</span>
<span class="quote">&gt;&gt;                        this_cpu_write(cpu_tlbstate.ctxs[i].ctx_id, 0);</span>
<span class="quote">&gt;&gt;         }</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; We have loops like this:</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;         for (addr = start; addr &lt; end; addr += PAGE_SIZE)</span>
<span class="quote">&gt;                 flush_tlb_single();</span>

Couldn&#39;t we just make those looks more intelligent:

for (...)
  flush_tlb_kernelmode_single(...);

if (kpti)
  invalidate_asid_other();

(Isn&#39;t there only one such look now, in flush_tlb_func_common()?)

--Andy
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=137">Peter Zijlstra</a> - Dec. 4, 2017, 10:47 p.m.</div>
<pre class="content">
On Mon, Dec 04, 2017 at 02:22:54PM -0800, Andy Lutomirski wrote:
<span class="quote">
&gt; &gt; +static inline void invalidate_pcid_other(void)</span>
<span class="quote">&gt; &gt; +{</span>
<span class="quote">&gt; &gt; +       /*</span>
<span class="quote">&gt; &gt; +        * With global pages, all of the shared kenel page tables</span>
<span class="quote">&gt; &gt; +        * are set as _PAGE_GLOBAL.  We have no shared nonglobals</span>
<span class="quote">&gt; &gt; +        * and nothing to do here.</span>
<span class="quote">&gt; &gt; +        */</span>
<span class="quote">&gt; &gt; +       if (!static_cpu_has_bug(X86_BUG_CPU_SECURE_MODE_KPTI))</span>
<span class="quote">&gt; &gt; +               return;</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; I think I&#39;d be more comfortable if this check were in the caller, not</span>
<span class="quote">&gt; here.  Shouldn&#39;t a function called invalidate_pcid_other() do what the</span>
<span class="quote">&gt; name says?</span>

Yeah, you&#39;re probably right. The thing is course that we only ever need
that operation for kpti (as of now). But me renaming this stuff made
this problem :/
<span class="quote">
&gt; &gt; +       this_cpu_write(cpu_tlbstate.invalidate_other, true);</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Why do we need this extra variable instead of just looping over all</span>
<span class="quote">&gt; other ASIDs and invalidating them?  It would be something like:</span>
<span class="quote">&gt; </span>
<span class="quote">&gt;         for (i = 1; i &lt; TLB_NR_DYN_ASIDS; i++) {</span>
<span class="quote">&gt;                 if (i != this_cpu_read(cpu_tlbstate.loaded_mm_asid))</span>
<span class="quote">&gt;                        this_cpu_write(cpu_tlbstate.ctxs[i].ctx_id, 0);</span>
<span class="quote">&gt;         }</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; modulo epic whitespace damage and possible typos.</span>

I think the point is that we can do many invalidate_other&#39;s before we
ever do a switch_mm(). The above would be more expensive.

Not sure it would matter in practise though.
<span class="quote">
&gt; &gt;  static inline void __flush_tlb_one(unsigned long addr)</span>
<span class="quote">&gt; &gt;  {</span>
<span class="quote">&gt; &gt;         count_vm_tlb_event(NR_TLB_LOCAL_FLUSH_ONE);</span>
<span class="quote">&gt; &gt;         __flush_tlb_single(addr);</span>
<span class="quote">&gt; &gt; +       /*</span>
<span class="quote">&gt; &gt; +        * Invalidate other address spaces inaccessible to single-page</span>
<span class="quote">&gt; &gt; +        * invalidation:</span>
<span class="quote">&gt; &gt; +        */</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Ugh.  If I&#39;m reading this right, __flush_tlb_single() means &quot;flush one</span>
<span class="quote">&gt; user address&quot; and __flush_tlb_one() means &quot;flush one kernel address&quot;.</span>

That would make sense, woulnd&#39;t it? :-) But afaict the __flush_tlb_one()
user in tlb_uv.c is in fact for userspace and should be
__flush_tlb_single().

Andrew, Mike, can either of you shed light on what exactly you need
invalidated there?
<span class="quote">
&gt; That&#39;s, um, not exactly obvious.  Could this be at least commented</span>
<span class="quote">&gt; better?</span>

As is __flush_tlb_single() does user and __flush_tlb_one() does
user+kernel.
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=125831">Andrew Lutomirski</a> - Dec. 4, 2017, 10:54 p.m.</div>
<pre class="content">
On Mon, Dec 4, 2017 at 2:47 PM, Peter Zijlstra &lt;peterz@infradead.org&gt; wrote:
<span class="quote">&gt; On Mon, Dec 04, 2017 at 02:22:54PM -0800, Andy Lutomirski wrote:</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;&gt; &gt; +static inline void invalidate_pcid_other(void)</span>
<span class="quote">&gt;&gt; &gt; +{</span>
<span class="quote">&gt;&gt; &gt; +       /*</span>
<span class="quote">&gt;&gt; &gt; +        * With global pages, all of the shared kenel page tables</span>
<span class="quote">&gt;&gt; &gt; +        * are set as _PAGE_GLOBAL.  We have no shared nonglobals</span>
<span class="quote">&gt;&gt; &gt; +        * and nothing to do here.</span>
<span class="quote">&gt;&gt; &gt; +        */</span>
<span class="quote">&gt;&gt; &gt; +       if (!static_cpu_has_bug(X86_BUG_CPU_SECURE_MODE_KPTI))</span>
<span class="quote">&gt;&gt; &gt; +               return;</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; I think I&#39;d be more comfortable if this check were in the caller, not</span>
<span class="quote">&gt;&gt; here.  Shouldn&#39;t a function called invalidate_pcid_other() do what the</span>
<span class="quote">&gt;&gt; name says?</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; Yeah, you&#39;re probably right. The thing is course that we only ever need</span>
<span class="quote">&gt; that operation for kpti (as of now). But me renaming this stuff made</span>
<span class="quote">&gt; this problem :/</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;&gt; &gt; +       this_cpu_write(cpu_tlbstate.invalidate_other, true);</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; Why do we need this extra variable instead of just looping over all</span>
<span class="quote">&gt;&gt; other ASIDs and invalidating them?  It would be something like:</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt;         for (i = 1; i &lt; TLB_NR_DYN_ASIDS; i++) {</span>
<span class="quote">&gt;&gt;                 if (i != this_cpu_read(cpu_tlbstate.loaded_mm_asid))</span>
<span class="quote">&gt;&gt;                        this_cpu_write(cpu_tlbstate.ctxs[i].ctx_id, 0);</span>
<span class="quote">&gt;&gt;         }</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; modulo epic whitespace damage and possible typos.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; I think the point is that we can do many invalidate_other&#39;s before we</span>
<span class="quote">&gt; ever do a switch_mm(). The above would be more expensive.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; Not sure it would matter in practise though.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;&gt; &gt;  static inline void __flush_tlb_one(unsigned long addr)</span>
<span class="quote">&gt;&gt; &gt;  {</span>
<span class="quote">&gt;&gt; &gt;         count_vm_tlb_event(NR_TLB_LOCAL_FLUSH_ONE);</span>
<span class="quote">&gt;&gt; &gt;         __flush_tlb_single(addr);</span>
<span class="quote">&gt;&gt; &gt; +       /*</span>
<span class="quote">&gt;&gt; &gt; +        * Invalidate other address spaces inaccessible to single-page</span>
<span class="quote">&gt;&gt; &gt; +        * invalidation:</span>
<span class="quote">&gt;&gt; &gt; +        */</span>
<span class="quote">&gt;&gt;</span>
<span class="quote">&gt;&gt; Ugh.  If I&#39;m reading this right, __flush_tlb_single() means &quot;flush one</span>
<span class="quote">&gt;&gt; user address&quot; and __flush_tlb_one() means &quot;flush one kernel address&quot;.</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; That would make sense, woulnd&#39;t it? :-) But afaict the __flush_tlb_one()</span>
<span class="quote">&gt; user in tlb_uv.c is in fact for userspace and should be</span>
<span class="quote">&gt; __flush_tlb_single().</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; Andrew, Mike, can either of you shed light on what exactly you need</span>
<span class="quote">&gt; invalidated there?</span>
<span class="quote">&gt;</span>
<span class="quote">&gt;&gt; That&#39;s, um, not exactly obvious.  Could this be at least commented</span>
<span class="quote">&gt;&gt; better?</span>
<span class="quote">&gt;</span>
<span class="quote">&gt; As is __flush_tlb_single() does user and __flush_tlb_one() does</span>
<span class="quote">&gt; user+kernel.</span>

Yep.  A one-liner above the function to that effect would make it
*way* clearer what&#39;s going on.
</pre>
</div>

<div class="comment">
<div class="meta"><a href="/project/LKML/list/?submitter=137">Peter Zijlstra</a> - Dec. 4, 2017, 11:06 p.m.</div>
<pre class="content">
On Mon, Dec 04, 2017 at 02:54:46PM -0800, Andy Lutomirski wrote:
<span class="quote">&gt; On Mon, Dec 4, 2017 at 2:47 PM, Peter Zijlstra &lt;peterz@infradead.org&gt; wrote:</span>
<span class="quote">
&gt; &gt; As is __flush_tlb_single() does user and __flush_tlb_one() does</span>
<span class="quote">&gt; &gt; user+kernel.</span>
<span class="quote">&gt; </span>
<span class="quote">&gt; Yep.  A one-liner above the function to that effect would make it</span>
<span class="quote">&gt; *way* clearer what&#39;s going on.</span>

Bah, since my notes are upstairs I actually got that wrong,
do_kernel_range_flush() also uses __flush_tlb_single(), but then it
finishes with invalidate_pcid_other(), so effectively it shoots down
world.

So we should probably switch do_kernel_range_flush() to
__flush_tlb_one() and tlb_uv.c (pending SGI approval) to
__flush_tlb_single().

I&#39;ll dig through my notes in the morning and do a patch with comments.
</pre>
</div>



<h2>Patch</h2>
<div class="patch">
<pre class="content">
<span class="p_header">--- a/arch/x86/include/asm/tlbflush.h</span>
<span class="p_header">+++ b/arch/x86/include/asm/tlbflush.h</span>
<span class="p_chunk">@@ -188,6 +188,17 @@</span> <span class="p_context"> struct tlb_state {</span>
 	bool is_lazy;
 
 	/*
<span class="p_add">+	 * If set we changed the page tables in such a way that we</span>
<span class="p_add">+	 * needed an invalidation of all contexts (aka. PCIDs / ASIDs).</span>
<span class="p_add">+	 * This tells us to go invalidate all the non-loaded ctxs[]</span>
<span class="p_add">+	 * on the next context switch.</span>
<span class="p_add">+	 *</span>
<span class="p_add">+	 * The current ctx was kept up-to-date as it ran and does not</span>
<span class="p_add">+	 * need to be invalidated.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	bool invalidate_other;</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
 	 * Access to this CR4 shadow and to H/W CR4 is protected by
 	 * disabling interrupts when modifying either one.
 	 */
<span class="p_chunk">@@ -267,6 +278,19 @@</span> <span class="p_context"> static inline unsigned long cr4_read_sha</span>
 	return this_cpu_read(cpu_tlbstate.cr4);
 }
 
<span class="p_add">+static inline void invalidate_pcid_other(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * With global pages, all of the shared kenel page tables</span>
<span class="p_add">+	 * are set as _PAGE_GLOBAL.  We have no shared nonglobals</span>
<span class="p_add">+	 * and nothing to do here.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	if (!static_cpu_has_bug(X86_BUG_CPU_SECURE_MODE_KPTI))</span>
<span class="p_add">+		return;</span>
<span class="p_add">+</span>
<span class="p_add">+	this_cpu_write(cpu_tlbstate.invalidate_other, true);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 /*
  * Save some of cr4 feature set we&#39;re using (e.g.  Pentium 4MB
  * enable and PPro Global page enable), so that any CPU&#39;s that boot
<span class="p_chunk">@@ -341,24 +365,22 @@</span> <span class="p_context"> static inline void __native_flush_tlb_si</span>
 
 static inline void __flush_tlb_all(void)
 {
<span class="p_del">-	if (boot_cpu_has(X86_FEATURE_PGE))</span>
<span class="p_add">+	if (boot_cpu_has(X86_FEATURE_PGE)) {</span>
 		__flush_tlb_global();
<span class="p_del">-	else</span>
<span class="p_add">+	} else {</span>
 		__flush_tlb();
<span class="p_del">-</span>
<span class="p_del">-	/*</span>
<span class="p_del">-	 * Note: if we somehow had PCID but not PGE, then this wouldn&#39;t work --</span>
<span class="p_del">-	 * we&#39;d end up flushing kernel translations for the current ASID but</span>
<span class="p_del">-	 * we might fail to flush kernel translations for other cached ASIDs.</span>
<span class="p_del">-	 *</span>
<span class="p_del">-	 * To avoid this issue, we force PCID off if PGE is off.</span>
<span class="p_del">-	 */</span>
<span class="p_add">+	}</span>
 }
 
 static inline void __flush_tlb_one(unsigned long addr)
 {
 	count_vm_tlb_event(NR_TLB_LOCAL_FLUSH_ONE);
 	__flush_tlb_single(addr);
<span class="p_add">+	/*</span>
<span class="p_add">+	 * Invalidate other address spaces inaccessible to single-page</span>
<span class="p_add">+	 * invalidation:</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	invalidate_pcid_other();</span>
 }
 
 #define TLB_FLUSH_ALL	-1UL
<span class="p_header">--- a/arch/x86/mm/tlb.c</span>
<span class="p_header">+++ b/arch/x86/mm/tlb.c</span>
<span class="p_chunk">@@ -28,6 +28,38 @@</span> <span class="p_context"></span>
  *	Implement flush IPI by CALL_FUNCTION_VECTOR, Alex Shi
  */
 
<span class="p_add">+/*</span>
<span class="p_add">+ * We get here when we do something requiring a TLB invalidation</span>
<span class="p_add">+ * but could not go invalidate all of the contexts.  We do the</span>
<span class="p_add">+ * necessary invalidation by clearing out the &#39;ctx_id&#39; which</span>
<span class="p_add">+ * forces a TLB flush when the context is loaded.</span>
<span class="p_add">+ */</span>
<span class="p_add">+void clear_asid_other(void)</span>
<span class="p_add">+{</span>
<span class="p_add">+	u16 asid;</span>
<span class="p_add">+</span>
<span class="p_add">+	/*</span>
<span class="p_add">+	 * This is only expected to be set if we have disabled</span>
<span class="p_add">+	 * kernel _PAGE_GLOBAL pages.</span>
<span class="p_add">+	 */</span>
<span class="p_add">+	if (!static_cpu_has_bug(X86_BUG_CPU_SECURE_MODE_KPTI)) {</span>
<span class="p_add">+		WARN_ON_ONCE(1);</span>
<span class="p_add">+		return;</span>
<span class="p_add">+	}</span>
<span class="p_add">+</span>
<span class="p_add">+	for (asid = 0; asid &lt; TLB_NR_DYN_ASIDS; asid++) {</span>
<span class="p_add">+		/* Do not need to flush the current asid */</span>
<span class="p_add">+		if (asid == this_cpu_read(cpu_tlbstate.loaded_mm_asid))</span>
<span class="p_add">+			continue;</span>
<span class="p_add">+		/*</span>
<span class="p_add">+		 * Make sure the next time we go to switch to</span>
<span class="p_add">+		 * this asid, we do a flush:</span>
<span class="p_add">+		 */</span>
<span class="p_add">+		this_cpu_write(cpu_tlbstate.ctxs[asid].ctx_id, 0);</span>
<span class="p_add">+	}</span>
<span class="p_add">+	this_cpu_write(cpu_tlbstate.invalidate_other, false);</span>
<span class="p_add">+}</span>
<span class="p_add">+</span>
 atomic64_t last_mm_ctx_id = ATOMIC64_INIT(1);
 
 
<span class="p_chunk">@@ -42,6 +74,9 @@</span> <span class="p_context"> static void choose_new_asid(struct mm_st</span>
 		return;
 	}
 
<span class="p_add">+	if (this_cpu_read(cpu_tlbstate.invalidate_other))</span>
<span class="p_add">+		clear_asid_other();</span>
<span class="p_add">+</span>
 	for (asid = 0; asid &lt; TLB_NR_DYN_ASIDS; asid++) {
 		if (this_cpu_read(cpu_tlbstate.ctxs[asid].ctx_id) !=
 		    next-&gt;context.ctx_id)
<span class="p_chunk">@@ -552,6 +587,8 @@</span> <span class="p_context"> static void do_kernel_range_flush(void *</span>
 	/* flush range by one by one &#39;invlpg&#39; */
 	for (addr = f-&gt;start; addr &lt; f-&gt;end; addr += PAGE_SIZE)
 		__flush_tlb_single(addr);
<span class="p_add">+</span>
<span class="p_add">+	invalidate_pcid_other();</span>
 }
 
 void flush_tlb_kernel_range(unsigned long start, unsigned long end)

</pre>
</div>




  </div>
  <div id="footer">
   <a href="http://jk.ozlabs.org/projects/patchwork/">patchwork</a>
   patch tracking system
  </div>
 </body>
</html>



